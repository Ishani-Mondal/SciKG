document	O
:	O
Attention	B-Method
Boosted	I-Method
Sequential	I-Method
Inference	I-Method
Model	I-Method
	
Attention	B-Method
mechanism	I-Method
has	O
been	O
proven	O
effective	O
on	O
natural	B-Task
language	I-Task
processing	I-Task
.	O
	
This	O
paper	O
proposes	O
an	O
attention	B-Method
boosted	I-Method
natural	I-Method
language	I-Method
inference	I-Method
model	I-Method
named	O
aESIM	B-Method
by	O
adding	O
word	B-Method
attention	I-Method
and	O
adaptive	B-Method
direction	I-Method
-	I-Method
oriented	I-Method
attention	I-Method
mechanisms	I-Method
to	O
the	O
traditional	O
Bi	B-Method
-	I-Method
LSTM	I-Method
layer	I-Method
of	I-Method
natural	I-Method
language	I-Method
inference	I-Method
models	I-Method
,	O
e.g.	O
ESIM	B-Method
.	O
	
This	O
makes	O
the	O
inference	B-Method
model	I-Method
aESIM	I-Method
has	O
the	O
ability	O
to	O
effectively	O
learn	O
the	O
representation	O
of	O
words	O
and	O
model	O
the	O
local	B-Task
subsentential	I-Task
inference	I-Task
between	O
pairs	O
of	O
premise	O
and	O
hypothesis	O
.	O
	
The	O
empirical	O
studies	O
on	O
the	O
SNLI	B-Material
,	O
MultiNLI	B-Material
and	O
Quora	B-Material
benchmarks	O
manifest	O
that	O
aESIM	B-Method
is	O
superior	O
to	O
the	O
original	O
ESIM	B-Method
model	I-Method
.	O
	
acmlicensed	O
[	O
DAPA’19	O
]	O
DAPA2019WSDMWorkshoponDeepmatchinginPracticalApplicationsFebruary15th	O
,	O
2019Melbourne	O
,	O
Australia	O
2019	O
	
2019	O
printacmref	O
=	O
	
false	O
1234	O
-	O
5678	O
-	O
9012	O
1234	O
-	O
5678	O
-	O
9012	O
	
1234	O
-	O
5678	O
-	O
9012	O
	
section	O
:	O
Introduction	O
	
Natural	B-Task
language	I-Task
inference	I-Task
(	O
NLI	B-Task
)	I-Task
is	O
an	O
important	O
and	O
significant	O
task	O
in	O
natural	B-Task
language	I-Task
processing	I-Task
(	I-Task
NLP	I-Task
)	I-Task
.	O
	
It	O
concerns	O
whether	O
a	O
hypothesis	O
can	O
be	O
inferred	O
from	O
a	O
premise	O
,	O
requiring	O
understanding	O
of	O
the	O
semantic	O
similarity	O
between	O
the	O
hypothesis	O
and	O
the	O
premise	O
to	O
discriminate	O
their	O
relation	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
several	O
samples	O
of	O
natural	B-Task
language	I-Task
inference	I-Task
from	O
SNLI	B-Material
(	O
Stanford	O
Natural	O
Language	O
Inference	O
)	O
corpus	O
.	O
	
In	O
the	O
literature	O
,	O
the	O
task	O
of	O
NLI	B-Task
is	O
usually	O
viewed	O
as	O
a	O
relation	B-Task
classification	I-Task
.	O
	
It	O
learns	O
the	O
relation	O
between	O
a	O
premise	O
and	O
a	O
hypothesis	O
in	O
a	O
large	O
training	O
set	O
,	O
then	O
predicts	O
the	O
relation	O
between	O
a	O
new	O
pair	O
of	O
premise	O
and	O
hypothesis	O
.	O
	
The	O
existing	O
methods	O
of	O
NLI	B-Task
can	O
be	O
roughly	O
partitioned	O
into	O
two	O
categories	O
:	O
feature	B-Method
-	I-Method
based	I-Method
models	I-Method
and	O
neural	B-Method
network	I-Method
-	I-Method
based	I-Method
models	I-Method
.	O
	
Feature	B-Method
-	I-Method
based	I-Method
models	I-Method
represent	O
a	O
premise	O
and	O
a	O
hypothesis	O
by	O
their	O
unlexicalized	O
and	O
lexicalized	O
features	O
,	O
such	O
as	O
-	O
gram	O
length	O
and	O
the	O
real	O
-	O
valued	O
feature	O
of	O
length	O
difference	O
,	O
then	O
train	O
a	O
classifier	B-Method
to	O
perform	O
relation	B-Task
classification	I-Task
.	O
	
Recently	O
,	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
neural	I-Method
network	I-Method
-	I-Method
based	I-Method
models	I-Method
have	O
drawn	O
worldwide	O
attention	O
since	O
they	O
have	O
demonstrated	O
excellent	O
performance	O
on	O
quite	O
a	O
few	O
NLP	B-Task
tasks	I-Task
including	O
machine	B-Task
translation	I-Task
,	O
natural	B-Task
language	I-Task
inference	I-Task
,	O
etc	O
.	O
	
On	O
the	O
basis	O
of	O
their	O
model	O
structures	O
,	O
we	O
can	O
divide	O
neural	B-Method
network	I-Method
-	I-Method
based	I-Method
models	I-Method
for	O
NLI	B-Task
into	O
two	O
classes	O
,	O
sentence	B-Method
encoding	I-Method
models	I-Method
and	O
sentence	B-Method
interaction	I-Method
-	I-Method
aggregation	I-Method
models	I-Method
.	O
	
The	O
architectures	O
of	O
the	O
two	O
types	O
of	O
models	O
are	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Sentence	B-Method
encoding	I-Method
models	I-Method
(	O
their	O
main	O
architecture	O
is	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.a	O
)	O
independently	O
encode	O
a	O
pair	O
of	O
sentences	O
,	O
a	O
premise	O
and	O
a	O
hypothesis	O
using	O
pre	O
-	O
trained	O
word	O
embedding	O
vectors	O
,	O
then	O
learn	O
semantic	O
relation	O
between	O
two	O
sentences	O
with	O
a	O
multi	B-Method
-	I-Method
layer	I-Method
perceptron	I-Method
(	I-Method
MLP	I-Method
)	O
.	O
	
In	O
these	O
models	O
,	O
LSTM	B-Method
(	I-Method
Long	I-Method
Short	I-Method
-	I-Method
Term	I-Method
Memory	I-Method
networks	I-Method
)	O
,	O
its	O
variants	O
GRU	B-Method
(	I-Method
Gated	I-Method
Recurrent	I-Method
Units	I-Method
)	O
and	O
Bi	B-Method
-	I-Method
LSTM	I-Method
,	O
are	O
usually	O
utilized	O
to	O
encode	O
the	O
sentences	O
since	O
they	O
were	O
capable	O
of	O
learning	O
long	O
-	O
term	O
dependencies	O
inside	O
sentences	O
.	O
	
For	O
example	O
,	O
Conneau	O
et	O
al	O
.	O
proposed	O
a	O
generic	O
NLI	B-Task
training	I-Task
scheme	I-Task
and	O
compared	O
several	O
sentence	B-Method
encoding	I-Method
architectures	I-Method
:	O
LSTM	B-Method
or	I-Method
GRU	I-Method
,	O
Bi	B-Method
-	I-Method
LSTM	I-Method
with	O
mean	B-Method
/	I-Method
max	I-Method
pooling	I-Method
,	O
self	B-Method
-	I-Method
attention	I-Method
network	I-Method
and	O
hierarchical	B-Method
convolutional	I-Method
networks	I-Method
.	O
	
The	O
experimental	O
results	O
demonstrated	O
that	O
the	O
Bi	B-Method
-	I-Method
LSTM	I-Method
with	O
max	B-Method
pooling	I-Method
achieved	O
the	O
best	O
performance	O
.	O
	
Talman	O
et	O
al	O
.	O
designed	O
a	O
hierarchical	B-Method
Bi	I-Method
-	I-Method
LSTM	I-Method
max	I-Method
pooling	I-Method
(	I-Method
HBMP	I-Method
)	I-Method
model	I-Method
to	O
encode	O
sentences	O
.	O
	
This	O
model	O
applied	O
parameters	O
of	O
one	O
Bi	B-Method
-	I-Method
LSTM	I-Method
to	O
initialize	O
the	O
next	O
Bi	B-Method
-	I-Method
LSTM	I-Method
to	O
convey	O
information	O
,	O
which	O
shown	O
better	O
results	O
than	O
the	O
model	O
with	O
a	O
single	O
Bi	B-Method
-	I-Method
LSTM	I-Method
.	O
	
Besides	O
LSTM	B-Method
,	O
attention	B-Method
mechanisms	I-Method
could	O
also	O
be	O
used	O
to	O
boost	O
the	O
effectiveness	O
of	O
sentence	B-Task
encoding	I-Task
.	O
	
The	O
model	O
developed	O
by	O
Ghaeini	O
et	O
al	O
.	O
added	O
self	O
-	O
attention	O
to	O
LSTM	B-Method
model	I-Method
,	O
and	O
achieved	O
better	O
performance	O
.	O
	
Sentence	B-Method
interaction	I-Method
-	I-Method
aggregation	I-Method
models	I-Method
(	O
their	O
main	O
architecture	O
is	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.b	O
)	O
learn	O
vector	B-Method
representations	I-Method
of	O
pairs	O
of	O
sentences	O
in	O
the	O
way	O
similar	O
to	O
sentence	B-Method
encoding	I-Method
models	I-Method
and	O
calculate	O
pairwise	O
word	O
interaction	O
matrix	O
between	O
two	O
sentences	O
using	O
the	O
newly	O
updated	O
word	O
vectors	O
,	O
and	O
then	O
the	O
matching	O
results	O
are	O
aggregated	O
into	O
a	O
vector	O
to	O
make	O
the	O
final	O
decision	O
.	O
	
Compared	O
with	O
sentence	B-Method
encoding	I-Method
model	I-Method
,	O
sentence	B-Method
interaction	I-Method
-	I-Method
aggregation	I-Method
models	I-Method
aggregate	O
word	O
similarities	O
between	O
a	O
pair	O
of	O
sentences	O
,	O
are	O
capable	O
of	O
capturing	O
the	O
relevant	O
information	O
between	O
two	O
sentences	O
,	O
a	O
premise	O
and	O
a	O
hypothesis	O
.	O
	
Bahdanau	O
et	O
al	O
.	O
translated	O
and	O
aligned	O
text	O
simultaneously	O
in	O
machine	B-Task
translation	I-Task
task	I-Task
,	O
innovatively	O
introducing	O
attention	B-Method
mechanism	I-Method
to	O
natural	B-Task
language	I-Task
process	I-Task
(	O
NLP	B-Task
)	O
.	O
	
He	O
et	O
al	O
.	O
designed	O
a	O
pairwise	B-Method
word	I-Method
interaction	I-Method
model	I-Method
(	O
PWIM	B-Method
)	I-Method
,	O
which	O
made	O
full	O
use	O
of	O
word	O
-	O
level	O
fine	O
-	O
grained	O
information	O
.	O
	
Wang	O
et	O
al	O
.	O
put	O
forward	O
a	O
bilateral	B-Method
multi	I-Method
-	I-Method
perspective	I-Method
matching	I-Method
(	I-Method
BiMPM	I-Method
)	I-Method
model	I-Method
,	O
focusing	O
on	O
various	O
matching	B-Method
strategies	I-Method
that	O
could	O
be	O
seen	O
as	O
different	O
types	O
of	O
attention	O
.	O
	
The	O
empirical	O
studies	O
of	O
Lan	O
et	O
al	O
.	O
and	O
Chen	O
et	O
al	O
.	O
concluded	O
that	O
sentence	B-Method
interation	I-Method
-	I-Method
aggregation	I-Method
models	I-Method
,	O
especially	O
ESIM	B-Method
(	O
Enhanced	B-Method
Sequential	I-Method
Inference	I-Method
Model	I-Method
)	O
,	O
a	O
carefully	O
designed	O
sequential	B-Method
inference	I-Method
model	I-Method
based	O
on	O
chain	B-Method
LSTMs	I-Method
,	O
outperformed	O
all	O
previous	O
sentence	B-Method
encoding	I-Method
models	I-Method
.	O
	
Although	O
ESIM	B-Method
has	O
achieved	O
excellent	O
achievements	O
,	O
this	O
model	O
does	O
n’t	O
consider	O
the	O
attention	O
along	O
the	O
words	O
in	O
a	O
sentence	O
in	O
its	O
Bi	B-Method
-	I-Method
LSTM	I-Method
layer	I-Method
.	O
	
Word	B-Task
attention	I-Task
can	O
characterize	O
the	O
different	O
contribution	O
of	O
each	O
word	O
.	O
	
Therefore	O
,	O
it	O
will	O
be	O
beneficial	O
to	O
put	O
word	O
attention	O
into	O
the	O
Bi	B-Method
-	I-Method
LTSM	I-Method
layer	I-Method
.	O
	
Moreover	O
,	O
the	O
orientation	O
of	O
the	O
words	O
represents	O
the	O
direction	O
of	O
the	O
information	O
flow	O
,	O
either	O
forward	O
or	O
backward	O
,	O
should	O
not	O
be	O
ignored	O
.	O
	
In	O
traditional	O
Bi	B-Method
-	I-Method
LSTM	I-Method
model	I-Method
,	O
the	O
forward	O
and	O
the	O
backward	O
vectors	O
learnt	O
by	O
Bi	B-Method
-	I-Method
LSTM	I-Method
are	O
simply	O
jointed	O
.	O
	
It	O
’s	O
necessary	O
to	O
consider	O
whether	O
each	O
orientation	O
(	O
forward	O
or	O
backward	O
)	O
has	O
different	O
importance	O
on	O
word	B-Task
encoding	I-Task
,	O
thus	O
adaptively	O
joint	O
the	O
two	O
orientation	O
vectors	O
together	O
with	O
different	O
weights	O
.	O
	
Therefore	O
,	O
in	O
this	O
study	O
,	O
using	O
ESIM	B-Method
model	I-Method
as	O
the	O
baseline	O
,	O
we	O
add	O
an	O
attention	B-Method
layer	I-Method
behind	O
each	O
Bi	B-Method
-	I-Method
LSTM	I-Method
layer	I-Method
,	O
then	O
use	O
an	O
adaptive	B-Method
orientation	I-Method
embedding	I-Method
layer	I-Method
to	O
jointly	O
represent	O
the	O
forward	O
and	O
backward	O
vectors	O
.	O
	
We	O
name	O
this	O
attention	B-Method
boosted	I-Method
Bi	I-Method
-	I-Method
LSTM	I-Method
as	O
Bi	B-Method
-	I-Method
aLSTM	I-Method
,	O
and	O
denote	O
the	O
modified	O
ESIM	B-Method
as	O
aESIM	B-Method
.	O
	
Experimental	O
results	O
on	O
SNLI	B-Material
,	O
MultiNLI	B-Material
and	O
Quora	B-Material
benchmarks	O
have	O
demonstrated	O
better	O
performance	O
of	O
aESIM	B-Method
model	I-Method
than	O
that	O
of	O
the	O
baseline	O
ESIM	B-Method
and	O
the	O
other	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
.	O
	
We	O
believe	O
that	O
the	O
architecture	O
of	O
Bi	B-Method
-	I-Method
aLSTM	I-Method
has	O
potentially	O
to	O
be	O
used	O
in	O
other	O
NLP	B-Task
tasks	I-Task
such	O
as	O
text	B-Task
classification	I-Task
,	O
machine	B-Task
translation	I-Task
and	O
so	O
on	O
.	O
	
This	O
paper	O
is	O
organized	O
as	O
follows	O
.	O
	
We	O
introduce	O
the	O
general	O
frameworks	O
of	O
ESIM	B-Method
and	O
aESIM	B-Method
in	O
Section	O
2	O
.	O
	
We	O
describe	O
the	O
datasets	O
and	O
the	O
experiment	O
settings	O
,	O
and	O
analyze	O
our	O
experimental	O
results	O
in	O
Section	O
3	O
.	O
	
We	O
then	O
draw	O
conclusions	O
in	O
Section	O
4	O
.	O
	
section	O
:	O
Attention	B-Method
Boosted	I-Method
Sequential	I-Method
Inference	I-Method
Model	I-Method
	
Supposed	O
that	O
we	O
have	O
two	O
sentences	O
and	O
,	O
where	O
represents	O
premise	O
and	O
represents	O
hypothesis	O
.	O
	
The	O
goal	O
is	O
to	O
predict	O
the	O
label	O
meaning	O
for	O
their	O
relation	O
.	O
	
subsection	O
:	O
ESIM	B-Method
model	I-Method
	
Enhanced	B-Method
Sequential	I-Method
Inference	I-Method
Model	I-Method
(	O
ESIM	B-Method
)	O
is	O
composed	O
of	O
four	O
main	O
components	O
:	O
input	B-Method
encoding	I-Method
layer	I-Method
,	O
local	B-Method
inference	I-Method
modeling	I-Method
layer	I-Method
,	O
inference	B-Method
composition	I-Method
layer	I-Method
and	O
classification	B-Method
layer	I-Method
.	O
	
In	O
the	O
input	B-Method
encoding	I-Method
layer	I-Method
,	O
ESIM	B-Method
first	O
uses	O
Bi	B-Method
-	I-Method
LSTM	I-Method
layer	I-Method
to	O
encode	O
input	O
sentence	O
pairs	O
(	O
Equations	O
1	O
-	O
2	O
)	O
,	O
which	O
can	O
be	O
initialized	O
using	O
pre	O
-	O
trained	O
word	B-Method
embeddings	I-Method
(	O
e.g.	O
Glove	O
840B	O
vectors	O
)	O
,	O
where	O
is	O
the	O
word	O
embedding	O
vector	O
of	O
the	O
-	O
th	O
word	O
in	O
,	O
is	O
that	O
of	O
word	O
in	O
.	O
	
Secondly	O
,	O
ESIM	B-Method
implements	O
the	O
local	B-Method
inference	I-Method
layer	I-Method
for	O
enhancing	O
the	O
sentence	O
information	O
.	O
	
First	O
it	O
calculates	O
a	O
similarity	O
matrix	O
based	O
on	O
and	O
.	O
	
It	O
then	O
gets	O
the	O
new	O
expression	O
for	O
and	O
with	O
the	O
equation	O
below	O
:	O
where	O
and	O
represent	O
the	O
weighted	O
summation	O
of	O
and	O
.	O
	
It	O
further	O
enhances	O
the	O
local	O
inference	O
information	O
collected	O
as	O
below	O
.	O
	
After	O
the	O
enhancement	O
of	O
local	B-Task
inference	I-Task
,	O
another	O
Bi	B-Method
-	I-Method
LSTM	I-Method
layer	I-Method
is	O
used	O
to	O
capture	O
local	O
inference	O
information	O
and	O
their	O
context	O
for	O
inference	B-Task
composition	I-Task
.	O
	
Instead	O
of	O
summation	B-Method
adopted	O
by	O
Parikh	O
et	O
al	O
.	O
,	O
ESIM	B-Method
proposes	O
to	O
compute	O
both	O
max	B-Method
and	I-Method
average	I-Method
pooling	I-Method
and	O
feeds	O
the	O
concatenate	O
fixed	O
length	O
vector	O
to	O
the	O
final	O
classifier	B-Method
:	O
a	O
fully	B-Method
connected	I-Method
multi	I-Method
-	I-Method
layer	I-Method
perceptron	I-Method
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
a	O
high	O
-	O
level	O
view	O
of	O
the	O
ESIM	B-Method
architecture	O
,	O
where	O
the	O
bottom	O
LSTM1	B-Method
layer	I-Method
of	O
Figure	O
[	O
reference	O
]	O
is	O
the	O
input	O
encoding	B-Method
layer	I-Method
,	O
	
the	O
middle	O
part	O
with	O
LSTM2	B-Method
layer	I-Method
is	O
the	O
local	B-Method
inference	I-Method
layer	I-Method
,	O
the	O
upper	O
part	O
is	O
the	O
inference	B-Method
composition	I-Method
layer	I-Method
.	O
	
subsection	O
:	O
aESIM	B-Method
model	I-Method
	
The	O
overall	O
architecture	O
of	O
our	O
newly	O
proposed	O
attention	B-Method
boosted	I-Method
sequential	I-Method
inference	I-Method
model	I-Method
(	O
named	O
aESIM	B-Method
)	I-Method
based	O
on	O
ESIM	B-Method
is	O
similar	O
to	O
ESIM	B-Method
.	O
	
In	O
detail	O
,	O
aESIM	B-Method
also	O
consists	O
of	O
four	O
main	O
parts	O
:	O
encoding	B-Method
layer	I-Method
,	O
local	B-Method
inference	I-Method
modeling	I-Method
layer	I-Method
,	O
decoding	B-Method
layer	I-Method
and	O
classification	B-Method
layer	I-Method
.	O
	
The	O
only	O
difference	O
between	O
ESIM	B-Method
and	O
aESIM	B-Method
is	O
that	O
we	O
substitute	O
the	O
two	O
Bi	B-Method
-	I-Method
LSTM	I-Method
layers	I-Method
(	O
LSTM1	B-Method
and	O
LSTM2	B-Method
)	O
in	O
ESIM	B-Method
with	O
two	O
Bi	B-Method
-	I-Method
aLSTM	I-Method
layers	I-Method
in	O
aESIM	B-Method
.	O
	
Therefore	O
,	O
as	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
the	O
layers	O
with	O
red	O
-	O
dotted	O
circles	O
in	O
ESIM	B-Method
will	O
be	O
replaced	O
by	O
the	O
Bi	B-Method
-	I-Method
aLSTM	I-Method
layers	I-Method
shown	O
in	O
the	O
right	O
upper	O
corner	O
of	O
the	O
Figure	O
[	O
reference	O
]	O
and	O
the	O
details	O
of	O
Bi	B-Method
-	I-Method
aLSTM	I-Method
can	O
be	O
found	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Given	O
the	O
word	O
vector	O
of	O
the	O
-	O
th	O
word	O
in	O
sentence	O
,	O
which	O
can	O
be	O
obtained	O
by	O
pre	O
-	O
trained	O
word	B-Method
embeddings	I-Method
such	O
as	O
Glove	O
840B	O
vectors	O
in	O
the	O
first	O
Bi	B-Method
-	I-Method
aLSTM	I-Method
layer	I-Method
or	O
obtained	O
from	O
the	O
local	B-Method
inference	I-Method
modeling	I-Method
layer	I-Method
in	O
the	O
second	O
Bi	B-Method
-	I-Method
aLSTM	I-Method
layer	I-Method
.	O
	
We	O
utilize	O
a	O
forward	B-Method
LSTM	I-Method
layer	I-Method
and	O
a	O
backward	B-Method
LSTM	I-Method
layer	I-Method
to	O
collect	O
both	O
direction	O
information	O
and	O
.	O
	
As	O
described	O
in	O
introduction	O
section	O
,	O
in	O
the	O
following	O
newly	O
proposed	O
Bi	B-Method
-	I-Method
aLSTM	I-Method
,	O
we	O
add	O
word	O
attention	O
and	O
additive	B-Method
operation	I-Method
on	O
both	O
orientations	O
of	O
traditional	O
Bi	B-Method
-	I-Method
LSTM	I-Method
layer	I-Method
.	O
	
Word	B-Method
attention	I-Method
layer	I-Method
	
It	O
’s	O
obvious	O
that	O
not	O
all	O
words	O
contribute	O
equally	O
to	O
the	O
representation	O
of	O
a	O
sentence	O
.	O
	
Attention	B-Method
mechanism	I-Method
,	O
which	O
is	O
introduced	O
in	O
,	O
is	O
extremely	O
effective	O
to	O
extract	O
vital	O
words	O
from	O
the	O
whole	O
sentence	O
,	O
and	O
is	O
particularly	O
beneficial	O
to	O
generate	O
the	O
sentence	O
vector	O
.	O
	
Therefore	O
,	O
we	O
use	O
the	O
following	O
attention	B-Method
mechanism	I-Method
after	O
we	O
get	O
and	O
.	O
	
Suppose	O
,	O
we	O
then	O
have	O
where	O
is	O
obtained	O
after	O
one	B-Method
-	I-Method
layer	I-Method
MLP	I-Method
for	O
the	O
input	O
,	O
is	O
the	O
importance	O
of	O
word	O
,	O
is	O
calculated	O
by	O
the	O
SoftMax	B-Method
unit	I-Method
on	O
the	O
context	O
vector	O
of	O
the	O
sentence	O
which	O
is	O
randomly	O
initialized	O
and	O
modified	O
during	O
the	O
training	O
,	O
is	O
the	O
attention	O
enhanced	O
vector	O
through	O
multiplying	O
the	O
weight	O
and	O
original	O
vector	O
,	O
where	O
correspond	O
to	O
the	O
forward	O
vector	O
and	O
the	O
backward	O
vector	O
,	O
respectively	O
.	O
	
Adaptive	B-Method
word	I-Method
direction	I-Method
layer	I-Method
In	O
traditional	O
Bi	B-Method
-	I-Method
LSTM	I-Method
model	I-Method
,	O
the	O
forward	O
and	O
the	O
backward	O
vectors	O
of	O
a	O
word	O
are	O
considered	O
to	O
have	O
equal	O
importance	O
on	O
the	O
word	B-Method
representation	I-Method
.	O
	
The	O
model	O
simply	O
connects	O
the	O
forward	O
and	O
backward	O
vectors	O
head	O
and	O
tail	O
without	O
weighing	O
their	O
importance	O
.	O
	
For	O
a	O
word	O
in	O
different	O
direction	O
or	O
orientation	O
,	O
the	O
former	O
and	O
the	O
latter	O
words	O
are	O
reversed	O
.	O
	
Thus	O
,	O
different	O
direction	O
vectors	O
of	O
a	O
word	O
make	O
different	O
contribution	O
to	O
the	O
representation	O
,	O
especially	O
the	O
words	O
in	O
a	O
long	O
sentence	O
.	O
	
Therefore	O
,	O
we	O
propose	O
a	O
new	O
adaptive	B-Method
direction	I-Method
layer	I-Method
to	O
learn	O
the	O
contribution	O
of	O
different	O
directions	O
for	O
a	O
single	O
word	O
.	O
	
Formally	O
,	O
given	O
two	O
direction	O
word	O
vectors	O
and	O
,	O
the	O
whole	O
word	O
vector	O
can	O
be	O
expressed	O
as	O
:	O
where	O
,	O
and	O
denote	O
weight	O
matrix	O
and	O
the	O
bias	O
,	O
denotes	O
the	O
nonlinear	O
function	O
,	O
denotes	O
the	O
concentration	O
.	O
	
All	O
the	O
parameters	O
can	O
be	O
learned	O
during	O
training	O
.	O
	
Then	O
we	O
can	O
get	O
the	O
whole	O
sentence	O
vector	O
as	O
below	O
:	O
This	O
word	B-Method
and	I-Method
orientation	I-Method
enhanced	I-Method
Bi	I-Method
-	I-Method
LSTM	I-Method
is	O
called	O
Bi	B-Method
-	I-Method
aLSTM	I-Method
.	O
	
Its	O
whole	O
architecture	O
is	O
shown	O
in	O
the	O
Figure	O
[	O
reference	O
]	O
,	O
is	O
applied	O
in	O
ESIM	B-Method
model	I-Method
to	O
replace	O
the	O
two	O
Bi	B-Method
-	I-Method
LSTM	I-Method
layers	I-Method
for	O
the	O
task	O
of	O
natural	B-Task
language	I-Task
inference	I-Task
.	O
	
Besides	O
,	O
this	O
Bi	B-Method
-	I-Method
aLSTM	I-Method
can	O
be	O
used	O
to	O
other	O
natural	B-Task
language	I-Task
processing	I-Task
tasks	O
and	O
our	O
preliminary	O
experiments	O
have	O
demonstrated	O
that	O
Bi	B-Method
-	I-Method
aLSTM	I-Method
is	O
capable	O
of	O
improving	O
the	O
performance	O
of	O
Bi	B-Method
-	I-Method
LSTM	I-Method
models	I-Method
on	O
sentimental	B-Task
classification	I-Task
task	I-Task
(	O
for	O
space	O
limitation	O
,	O
this	O
results	O
will	O
not	O
be	O
shown	O
in	O
the	O
paper	O
)	O
.	O
	
section	O
:	O
Experiment	O
Setup	O
	
subsection	O
:	O
Datasets	O
	
We	O
evaluated	O
our	O
model	O
on	O
three	O
datasets	O
:	O
	
the	O
Stanford	O
Natural	O
Language	O
Inference	O
(	O
SNLI	B-Material
)	O
corpus	O
,	O
the	O
Multi	O
-	O
Genre	O
Natural	O
Language	O
Inference	O
(	O
MultiNLI	B-Material
)	O
corpus	O
,	O
and	O
Quora	B-Material
duplicate	O
question	O
dataset	O
.	O
	
We	O
selected	O
these	O
three	O
relatively	O
large	O
corpora	O
out	O
of	O
eight	O
corpora	O
in	O
since	O
deep	B-Method
learning	I-Method
models	I-Method
usually	O
show	O
better	O
generalization	B-Metric
ability	I-Metric
on	O
large	O
training	O
sets	O
and	O
produce	O
more	O
convincing	O
results	O
than	O
on	O
small	O
training	O
sets	O
.	O
	
SNLI	B-Material
	
The	O
Stanford	O
Natural	O
Language	O
Inference	O
(	O
SNLI	B-Material
	
)	O
corpus	O
contains	O
570	O
,	O
152	O
sentence	O
pairs	O
,	O
including	O
549	O
K	O
training	O
pairs	O
,	O
10	O
K	O
validation	O
pairs	O
and	O
10	O
K	O
testing	O
pairs	O
.	O
	
Each	O
pair	O
has	O
one	O
of	O
relation	O
classes	O
(	O
entailment	O
,	O
neutral	O
,	O
contradiction	O
and	O
‘	O
-	O
’	O
)	O
.	O
	
The	O
‘	O
-	O
’	O
class	O
indicates	O
there	O
is	O
no	O
conclusion	O
between	O
the	O
two	O
sentences	O
.	O
	
Consequently	O
,	O
we	O
remove	O
all	O
pairs	O
with	O
relation	O
’	O
-	O
’	O
during	O
training	O
,	O
validating	O
and	O
testing	O
processes	O
.	O
	
MultiNLI	B-Material
	
This	O
corpus	O
is	O
a	O
crowd	O
-	O
sourced	O
collection	O
of	O
433	O
K	O
sentence	O
pairs	O
annotated	O
with	O
textual	O
entailment	O
information	O
.	O
	
The	O
corpus	O
is	O
modeled	O
on	O
the	O
SNLI	B-Material
corpus	O
,	O
but	O
differs	O
in	O
that	O
covers	O
a	O
range	O
of	O
genres	O
of	O
spoken	O
and	O
written	O
text	O
,	O
and	O
supports	O
a	O
distinctive	O
cross	B-Task
-	I-Task
genre	I-Task
generation	I-Task
evaluation	I-Task
.	O
	
Quora	B-Material
	
The	O
Quora	B-Material
dataset	O
contains	O
400	O
,	O
000	O
question	O
pairs	O
.	O
	
The	O
task	O
of	O
this	O
corpus	O
is	O
to	O
judge	O
whether	O
the	O
two	O
sentences	O
means	O
the	O
same	O
affair	O
.	O
	
subsection	O
:	O
Setting	O
	
We	O
use	O
the	O
validation	O
set	O
to	O
select	O
models	O
for	O
testing	O
.	O
	
The	O
hyper	O
-	O
parameters	O
of	O
aESIM	B-Method
model	I-Method
are	O
listed	O
as	O
follows	O
.	O
	
We	O
use	O
the	O
Adam	B-Method
method	I-Method
for	O
optimization	B-Task
.	O
	
The	O
first	O
momentum	O
is	O
set	O
to	O
be	O
0.9	O
and	O
the	O
second	O
0.999	O
.	O
	
The	O
initial	O
learning	B-Metric
rate	I-Metric
is	O
set	O
to	O
0.0005	O
,	O
and	O
the	O
batch	O
size	O
is	O
128	O
.	O
	
The	O
dimensions	O
of	O
all	O
hidden	O
states	O
of	O
Bi	B-Method
-	I-Method
aLSTM	I-Method
and	O
word	B-Method
embedding	I-Method
are	O
300	O
.	O
	
We	O
employ	O
non	O
-	O
linearity	O
function	O
replacing	O
rectified	B-Method
linear	I-Method
unit	I-Method
on	O
account	O
of	O
its	O
faster	O
convergence	B-Metric
rate	I-Metric
.	O
	
Dropout	B-Metric
rate	I-Metric
is	O
set	O
to	O
0.2	O
during	O
training	O
.	O
	
We	O
use	O
pre	O
-	O
trained	O
300	O
-	O
D	O
Glove	O
840B	O
vectors	O
to	O
initialize	O
word	O
embeddings	O
.	O
	
Out	B-Task
-	I-Task
of	I-Task
-	I-Task
vocabulary	I-Task
(	I-Task
OOV	I-Task
)	I-Task
words	I-Task
are	O
initialized	O
randomly	O
with	O
Gaussian	B-Method
samples	I-Method
.	O
	
All	O
vectors	O
are	O
updated	O
during	O
training	O
.	O
	
subsection	O
:	O
Experiment	O
results	O
	
Except	O
for	O
comparing	O
our	O
method	O
aESIM	B-Method
with	O
ESIM	B-Method
,	O
we	O
listed	O
the	O
experimental	O
results	O
of	O
methods	O
with	O
their	O
references	O
in	O
Table	O
[	O
reference	O
]	O
on	O
SNIL	B-Material
.	O
	
In	O
Table	O
[	O
reference	O
]	O
,	O
the	O
method	O
in	O
the	O
first	O
block	O
is	O
a	O
traditional	O
feature	B-Method
engineering	I-Method
method	I-Method
,	O
those	O
in	O
the	O
second	O
are	O
the	O
sentence	B-Method
vector	I-Method
-	I-Method
based	I-Method
models	I-Method
,	O
those	O
in	O
the	O
third	O
are	O
attention	B-Method
-	I-Method
based	I-Method
models	I-Method
,	O
and	O
ESIM	B-Method
and	O
our	O
aESIM	B-Method
are	O
shown	O
in	O
the	O
fourth	O
block	O
.	O
	
Where	O
the	O
results	O
of	O
ESIM	B-Method
and	O
aESIM	B-Method
are	O
implemented	O
by	O
ourselves	O
on	O
Keras	B-Method
,	O
the	O
results	O
of	O
the	O
others	O
are	O
taken	O
from	O
their	O
original	O
publications	O
.	O
	
We	O
then	O
compare	O
the	O
baseline	O
models	O
,	O
CBOW	B-Method
,	O
Bi	B-Method
-	I-Method
LSTM	I-Method
with	O
ESIM	B-Method
and	O
our	O
aESIM	B-Method
on	O
MultiNLI	B-Material
corpus	O
shown	O
In	O
Table	O
[	O
reference	O
]	O
,	O
where	O
the	O
results	O
of	O
the	O
baselines	O
are	O
taken	O
from	O
.	O
	
Finally	O
,	O
we	O
compare	O
several	O
types	O
of	O
CNN	B-Method
and	O
RNN	B-Method
models	I-Method
on	O
Quroa	B-Material
corpus	I-Material
shown	O
in	O
Table	O
[	O
reference	O
]	O
,	O
the	O
results	O
of	O
theses	O
CNN	B-Method
and	O
RNN	B-Method
models	I-Method
are	O
taken	O
from	O
.	O
	
The	O
accuracy	B-Metric
(	O
ACC	B-Metric
)	O
of	O
each	O
method	O
is	O
measured	O
by	O
the	O
commonly	O
used	O
precision	B-Metric
score	I-Metric
,	O
and	O
the	O
methods	O
with	O
the	O
best	O
accuracy	B-Metric
are	O
marked	O
in	O
bold	O
.	O
	
According	O
to	O
the	O
results	O
in	O
Tables	O
2	O
-	O
4	O
,	O
aESIM	B-Method
model	I-Method
achieved	O
88.1	O
%	O
on	O
SNLI	B-Material
corpus	O
,	O
elevating	O
0.8	O
percent	O
higher	O
than	O
ESIM	B-Method
model	I-Method
.	O
	
It	O
promoted	O
almost	O
0.5	O
percent	O
accuracy	B-Metric
and	O
outperformed	O
the	O
baselines	O
on	O
MultiNLI	B-Material
.	O
	
It	O
also	O
achieved	O
88.01	O
%	O
on	O
Quora	B-Material
.	O
	
Therefore	O
,	O
we	O
concluded	O
that	O
aESIM	B-Method
with	O
further	O
word	O
attention	O
and	O
word	O
orientation	O
operation	O
was	O
superior	O
to	O
ESIM	B-Method
model	I-Method
.	O
	
subsection	O
:	O
Attention	B-Task
visualization	I-Task
	
We	O
selected	O
three	O
types	O
of	O
sentence	O
pairs	O
from	O
a	O
premise	O
and	O
its	O
three	O
hypothesis	O
sentences	O
in	O
the	O
test	O
set	O
of	O
SNLI	B-Material
corpus	O
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
where	O
the	O
premise	O
sentence	O
is	O
‘	O
A	O
woman	O
with	O
a	O
green	O
headscarf	O
,	O
blue	O
shirt	O
and	O
a	O
very	O
big	O
grin	O
’	O
,	O
and	O
three	O
hypothesis	O
sentences	O
are	O
‘	O
the	O
woman	O
has	O
been	O
shot	O
’	O
,	O
	
‘	O
the	O
woman	O
is	O
very	O
happy	O
’	O
and	O
‘	O
the	O
woman	O
is	O
young	O
’	O
with	O
relation	O
labels	O
	
‘	O
contradiction	O
’	O
,	O
	
‘	O
entailment	O
’	O
,	O
and	O
‘	O
neutral	O
’	O
,	O
respectively	O
.	O
	
Each	O
pair	O
of	O
sentences	O
has	O
their	O
key	O
word	O
pairs	O
:	O
grin	O
-	O
shot	O
,	O
grin	O
-	O
happy	O
and	O
grin	O
-	O
young	O
,	O
which	O
determines	O
whether	O
the	O
premise	O
can	O
entail	O
the	O
hypothesis	O
.	O
	
Figures	O
4.a	O
-	O
4.c	O
are	O
the	O
visualization	O
of	O
the	O
attention	O
layer	O
between	O
sentence	O
pairs	O
after	O
the	O
Bi	B-Method
-	I-Method
LSTM	I-Method
layer	I-Method
in	O
ESIM	B-Method
model	I-Method
and	O
that	O
after	O
Bi	B-Method
-	I-Method
aLSTM	I-Method
layer	I-Method
in	O
aESIM	B-Method
model	I-Method
for	O
contrasting	O
ESIM	B-Method
and	O
aESIM	B-Method
.	O
	
By	O
doing	O
so	O
,	O
we	O
could	O
understand	O
how	O
the	O
models	O
judge	O
the	O
relation	O
between	O
two	O
sentences	O
.	O
	
In	O
each	O
Figure	O
,	O
the	O
brighter	O
the	O
color	O
,	O
the	O
higher	O
the	O
weight	O
is	O
.	O
	
We	O
could	O
conclude	O
that	O
our	O
aESIM	B-Method
model	I-Method
had	O
the	O
higher	O
weight	O
than	O
ESIM	B-Method
model	I-Method
on	O
each	O
key	O
word	O
pair	O
,	O
especially	O
in	O
Figure	O
[	O
reference	O
]	O
	
.b	O
,	O
where	O
the	O
similarity	O
of	O
‘	O
happy	O
’	O
and	O
‘	O
grin	O
’	O
in	O
aESIM	B-Method
model	I-Method
is	O
much	O
higher	O
than	O
that	O
in	O
ESIM	B-Method
model	I-Method
.	O
	
Therefore	O
,	O
our	O
aESIM	B-Method
model	I-Method
was	O
able	O
to	O
capture	O
the	O
most	O
important	O
word	O
pair	O
in	O
each	O
pair	O
of	O
sentences	O
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
study	O
,	O
we	O
propose	O
an	O
improved	O
version	O
of	O
ESIM	B-Method
named	O
aESIM	B-Method
for	O
NLI	B-Task
.	O
	
It	O
modifies	O
the	O
Bi	B-Method
-	I-Method
LSTM	I-Method
layer	I-Method
to	O
collect	O
more	O
information	O
.	O
	
We	O
evaluate	O
our	O
aESIM	B-Method
model	I-Method
on	O
three	O
NLI	O
corpora	O
.	O
	
Experimental	O
results	O
show	O
that	O
aESIM	B-Method
model	I-Method
achieves	O
better	O
performance	O
than	O
ESIM	B-Method
model	I-Method
.	O
	
In	O
the	O
future	O
,	O
we	O
will	O
evaluate	O
how	O
attention	B-Method
mechanisms	I-Method
can	O
be	O
applied	O
on	O
other	O
tasks	O
and	O
explore	O
a	O
way	O
to	O
use	O
less	O
time	O
and	O
space	O
with	O
guaranteed	O
accuracy	B-Metric
.	O
	
section	O
:	O
Acknowledgement	O
	
This	O
work	O
is	O
supported	O
in	O
part	O
by	O
the	O
National	O
Nature	O
Science	O
Foundation	O
of	O
China	O
	
(	O
No	O
.	O
61876016	O
	
and	O
No	O
.	O
61632004	O
)	O
,	O
the	O
Fundamental	O
Research	O
Funds	O
for	O
the	O
Central	O
Universities	O
	
(	O
No	O
.	O
2018JBZ006	O
)	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
All	O
you	O
need	O
is	O
a	O
good	O
init	O
	
Layer	O
-	O
sequential	O
unit	O
-	O
variance	O
(	O
LSUV	B-Method
)	O
initialization	O
–	O
	
a	O
simple	O
method	O
for	O
weight	B-Task
initialization	I-Task
for	O
deep	B-Task
net	I-Task
learning	I-Task
–	O
is	O
proposed	O
.	O
	
The	O
method	O
consists	O
of	O
the	O
two	O
steps	O
.	O
	
First	O
,	O
pre	O
-	O
initialize	O
weights	O
of	O
each	O
convolution	B-Method
or	I-Method
inner	I-Method
-	I-Method
product	I-Method
layer	I-Method
with	O
orthonormal	B-Method
matrices	I-Method
.	O
	
Second	O
,	O
proceed	O
from	O
the	O
first	O
to	O
the	O
final	O
layer	O
,	O
normalizing	O
the	O
variance	O
of	O
the	O
output	O
of	O
each	O
layer	O
to	O
be	O
equal	O
to	O
one	O
.	O
	
Experiment	O
with	O
different	O
activation	O
functions	O
(	O
maxout	O
,	O
ReLU	B-Method
-	I-Method
family	I-Method
,	O
tanh	B-Method
)	O
show	O
that	O
the	O
proposed	O
initialization	O
leads	O
to	O
learning	B-Task
of	I-Task
very	I-Task
deep	I-Task
nets	I-Task
that	O
(	O
i	O
)	O
produces	O
networks	O
with	O
test	B-Metric
accuracy	I-Metric
better	O
or	O
equal	O
to	O
standard	O
methods	O
and	O
(	O
ii	O
)	O
is	O
at	O
least	O
as	O
fast	O
as	O
the	O
complex	O
schemes	O
proposed	O
specifically	O
for	O
very	B-Task
deep	I-Task
nets	I-Task
such	O
as	O
FitNets	B-Method
(	O
)	O
and	O
Highway	B-Method
(	O
)	O
.	O
	
Performance	O
is	O
evaluated	O
on	O
GoogLeNet	B-Method
,	O
CaffeNet	B-Method
,	O
FitNets	B-Method
and	O
Residual	B-Method
nets	I-Method
and	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
,	O
or	O
very	O
close	O
to	O
it	O
,	O
is	O
achieved	O
on	O
the	O
MNIST	B-Material
,	O
CIFAR	B-Material
-	I-Material
10	I-Material
/	O
100	B-Material
and	O
ImageNet	O
datasets	O
.	O
	
update	O
	
section	O
:	O
Introduction	O
	
Deep	B-Method
nets	I-Method
have	O
demonstrated	O
impressive	O
results	O
on	O
a	O
number	O
of	O
computer	B-Task
vision	I-Task
and	I-Task
natural	I-Task
language	I-Task
processing	I-Task
problems	I-Task
.	O
	
At	O
present	O
,	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
in	O
image	B-Task
classification	I-Task
(	O
)	O
and	O
speech	B-Task
recognition	I-Task
(	O
)	O
,	O
etc	O
.	O
,	O
have	O
been	O
achieved	O
with	O
very	O
deep	B-Method
(	I-Method
layer	I-Method
)	I-Method
CNNs	I-Method
.	O
	
Thin	B-Method
deep	I-Method
nets	I-Method
are	O
of	O
particular	O
interest	O
,	O
since	O
they	O
are	O
accurate	O
and	O
at	O
the	O
same	O
inference	O
-	O
time	O
efficient	O
(	O
)	O
.	O
	
One	O
of	O
the	O
main	O
obstacles	O
preventing	O
the	O
wide	O
adoption	O
of	O
very	O
deep	B-Method
nets	I-Method
is	O
the	O
absence	O
of	O
a	O
general	O
,	O
repeatable	O
and	O
efficient	O
procedure	O
for	O
their	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
training	I-Task
.	O
	
For	O
example	O
,	O
VGGNet	B-Method
(	I-Method
)	I-Method
was	O
optimized	O
by	O
a	O
four	O
stage	B-Method
procedure	I-Method
that	O
started	O
by	O
training	O
a	O
network	O
with	O
moderate	O
depth	O
,	O
adding	O
progressively	O
more	O
layers	O
.	O
	
stated	O
that	O
deep	B-Method
and	I-Method
thin	I-Method
networks	I-Method
are	O
very	O
hard	O
to	O
train	O
by	O
backpropagation	B-Method
if	O
deeper	O
than	O
five	O
layers	O
,	O
especially	O
with	O
uniform	O
initialization	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
showed	O
that	O
it	O
is	O
possible	O
to	O
train	O
the	O
VGGNet	B-Method
in	O
a	O
single	O
optimization	O
run	O
if	O
the	O
network	O
weights	O
are	O
initialized	O
with	O
a	O
specific	O
ReLU	B-Method
-	I-Method
aware	I-Method
initialization	I-Method
.	O
	
The	O
procedure	O
generalizes	O
to	O
the	O
ReLU	O
non	O
-	O
linearity	O
the	O
idea	O
of	O
filter	B-Method
-	I-Method
size	I-Method
dependent	I-Method
initialization	I-Method
,	O
introduced	O
for	O
the	O
linear	B-Task
case	I-Task
by	O
(	O
)	O
.	O
	
Batch	B-Method
normalization	I-Method
(	O
)	O
,	O
a	O
technique	O
that	O
inserts	O
layers	O
into	O
the	O
the	O
deep	B-Method
net	I-Method
that	O
transform	O
the	O
output	O
for	O
the	O
batch	O
to	O
be	O
zero	O
mean	O
unit	O
variance	O
,	O
has	O
successfully	O
facilitated	O
training	O
of	O
the	O
twenty	O
-	O
two	B-Method
layer	I-Method
GoogLeNet	I-Method
(	O
)	O
.	O
	
However	O
,	O
batch	B-Method
normalization	I-Method
adds	O
a	O
30	O
%	O
computational	B-Metric
overhead	I-Metric
to	O
each	O
iteration	O
.	O
	
The	O
main	O
contribution	O
of	O
the	O
paper	O
is	O
a	O
proposal	O
of	O
a	O
simple	O
initialization	B-Method
procedure	I-Method
that	O
,	O
in	O
connection	O
with	O
standard	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
(	O
SGD	B-Method
)	I-Method
,	O
leads	O
to	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
thin	O
and	O
very	O
deep	B-Method
neural	I-Method
nets	I-Method
.	O
	
The	O
result	O
highlights	O
the	O
importance	O
of	O
initialization	B-Task
in	O
very	B-Task
deep	I-Task
nets	I-Task
.	O
	
We	O
review	O
the	O
history	O
of	O
CNN	B-Task
initialization	I-Task
in	O
Section	O
[	O
reference	O
]	O
,	O
which	O
is	O
followed	O
by	O
a	O
detailed	O
description	O
of	O
the	O
novel	O
initialization	B-Method
method	I-Method
in	O
Section	O
[	O
reference	O
]	O
.	O
	
The	O
method	O
is	O
experimentally	O
validated	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
Initialization	B-Task
in	O
neural	B-Method
networks	I-Method
	
After	O
the	O
success	O
of	O
CNNs	B-Method
in	O
IVSRC	O
2012	O
(	O
)	O
,	O
initialization	B-Method
with	O
Gaussian	O
noise	O
with	O
mean	O
equal	O
to	O
zero	O
and	O
standard	O
deviation	O
set	O
to	O
0.01	O
and	O
adding	O
bias	O
equal	O
to	O
one	O
for	O
some	O
layers	O
become	O
very	O
popular	O
.	O
	
But	O
,	O
as	O
mentioned	O
before	O
,	O
it	O
is	O
not	O
possible	O
to	O
train	O
very	O
deep	B-Method
network	I-Method
from	O
scratch	O
with	O
it	O
(	O
)	O
.	O
	
The	O
problem	O
is	O
caused	O
by	O
the	O
activation	O
(	O
and	O
/	O
or	O
	
)	O
gradient	O
magnitude	O
in	O
final	O
layers	O
(	O
)	O
.	O
	
If	O
each	O
layer	O
,	O
not	O
properly	O
initialized	O
,	O
scales	O
input	O
by	O
,	O
the	O
final	O
scale	O
would	O
be	O
,	O
where	O
is	O
a	O
number	O
of	O
layers	O
.	O
	
Values	O
of	O
lead	O
to	O
extremely	O
large	O
values	O
of	O
output	O
layers	O
,	O
leads	O
to	O
a	O
diminishing	O
signal	O
and	O
gradient	O
.	O
	
proposed	O
a	O
formula	O
for	O
estimating	O
the	O
standard	B-Metric
deviation	I-Metric
on	O
the	O
basis	O
of	O
the	O
number	O
of	O
input	O
and	O
output	O
channels	O
of	O
the	O
layers	O
under	O
assumption	O
of	O
no	O
non	O
-	O
linearity	O
between	O
layers	O
.	O
	
Despite	O
invalidity	O
of	O
the	O
assumption	O
,	O
Glorot	B-Method
initialization	I-Method
works	O
well	O
in	O
many	O
applications	O
.	O
	
extended	O
this	O
formula	O
to	O
the	O
ReLU	O
(	O
)	O
non	O
-	O
linearity	O
and	O
showed	O
its	O
superior	O
performance	O
for	O
ReLU	B-Method
-	I-Method
based	I-Method
nets	I-Method
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
why	O
scaling	O
is	O
important	O
.	O
	
Large	O
weights	O
lead	O
to	O
divergence	O
via	O
updates	O
larger	O
than	O
the	O
initial	O
values	O
,	O
small	O
initial	O
weights	O
do	O
not	O
allow	O
the	O
network	O
to	O
learn	O
since	O
the	O
updates	O
are	O
of	O
the	O
order	O
of	O
0.0001	O
per	O
iteration	O
.	O
	
The	O
optimal	O
scaling	B-Method
for	O
ReLU	B-Task
-	I-Task
net	I-Task
is	O
around	O
1.4	O
,	O
which	O
is	O
in	O
line	O
with	O
the	O
theoretically	O
derived	O
by	O
.	O
	
proposed	O
the	O
so	O
called	O
Random	B-Method
walk	I-Method
initialization	I-Method
,	O
RWI	B-Method
,	O
which	O
keeps	O
constant	O
the	O
log	O
of	O
the	O
norms	O
of	O
the	O
backpropagated	O
errors	O
.	O
	
In	O
our	O
experiments	O
,	O
we	O
have	O
not	O
been	O
able	O
to	O
obtain	O
good	O
results	O
with	O
our	O
implementation	O
of	O
RWI	B-Method
,	O
that	O
is	O
why	O
this	O
method	O
is	O
not	O
evaluated	O
in	O
experimental	O
section	O
.	O
	
and	O
take	O
another	O
approach	O
to	O
initialization	B-Task
and	O
formulate	O
training	B-Task
as	O
mimicking	O
teacher	O
network	O
predictions	O
(	O
so	O
called	O
knowledge	B-Task
distillation	I-Task
)	O
and	O
internal	O
representations	O
(	O
so	O
called	O
Hints	B-Method
initialization	I-Method
)	O
rather	O
than	O
minimizing	O
the	O
softmax	O
loss	O
.	O
	
proposed	O
a	O
LSTM	B-Method
-	I-Method
inspired	I-Method
gating	I-Method
scheme	I-Method
to	O
control	O
information	O
and	O
gradient	O
flow	O
through	O
the	O
network	O
.	O
	
They	O
trained	O
a	O
1000	B-Method
-	I-Method
layers	I-Method
MLP	I-Method
network	I-Method
on	O
MNIST	B-Material
.	O
	
Basically	O
,	O
this	O
kind	O
of	O
networks	O
implicitly	O
learns	O
the	O
depth	O
needed	O
for	O
the	O
given	O
task	O
.	O
	
Independently	O
,	O
showed	O
that	O
orthonormal	B-Method
matrix	I-Method
initialization	I-Method
works	O
much	O
better	O
for	O
linear	B-Task
networks	I-Task
than	O
Gaussian	O
noise	O
,	O
which	O
is	O
only	O
approximate	O
orthogonal	O
.	O
	
It	O
also	O
work	O
for	O
networks	O
with	O
non	B-Task
-	I-Task
linearities	I-Task
.	O
	
The	O
approach	O
of	O
layer	B-Method
-	I-Method
wise	I-Method
pre	I-Method
-	I-Method
training	I-Method
(	I-Method
)	I-Method
which	O
is	O
still	O
useful	O
for	O
multi	B-Task
-	I-Task
layer	I-Task
-	I-Task
perceptron	I-Task
,	O
is	O
not	O
popular	O
for	O
training	O
discriminative	B-Method
convolution	I-Method
networks	I-Method
.	O
	
section	O
:	O
Layer	B-Method
-	I-Method
sequential	I-Method
unit	I-Method
-	I-Method
variance	I-Method
initialization	I-Method
	
To	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
there	O
have	O
been	O
no	O
attempts	O
to	O
generalize	O
formulas	O
to	O
non	O
-	O
linearities	O
other	O
than	O
ReLU	O
,	O
such	O
as	O
tanh	O
,	O
maxout	O
,	O
etc	O
.	O
	
Also	O
,	O
the	O
formula	O
does	O
not	O
cover	O
max	B-Method
-	I-Method
pooling	I-Method
,	O
local	O
normalization	O
layers	O
and	O
other	O
types	O
of	O
layers	O
which	O
influences	O
activations	O
variance	O
.	O
	
Instead	O
of	O
theoretical	O
derivation	O
for	O
all	O
possible	O
layer	O
types	O
,	O
or	O
doing	O
extensive	O
parameters	O
search	O
as	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
we	O
propose	O
a	O
data	B-Method
-	I-Method
driven	I-Method
weights	I-Method
initialization	I-Method
.	O
	
We	O
thus	O
extend	O
the	O
orthonormal	B-Method
initialization	I-Method
to	O
an	O
iterative	B-Method
procedure	I-Method
,	O
described	O
in	O
Algorithm	O
[	O
reference	O
]	O
.	O
could	O
be	O
implemented	O
in	O
two	O
steps	O
.	O
	
First	O
,	O
fill	O
the	O
weights	O
with	O
Gaussian	O
noise	O
with	O
unit	O
variance	O
.	O
	
Second	O
,	O
decompose	O
them	O
to	O
orthonormal	O
basis	O
with	O
QR	B-Method
or	I-Method
SVD	I-Method
-	I-Method
decomposition	I-Method
and	O
replace	O
weights	O
with	O
one	O
of	O
the	O
components	O
.	O
	
The	O
LSUV	B-Method
process	O
then	O
estimates	O
output	O
variance	O
of	O
each	O
convolution	B-Method
and	I-Method
inner	I-Method
product	I-Method
layer	I-Method
and	O
scales	O
the	O
weight	O
to	O
make	O
variance	O
equal	O
to	O
one	O
.	O
	
The	O
influence	O
of	O
selected	O
mini	O
-	O
batch	O
size	O
on	O
estimated	B-Metric
variance	I-Metric
is	O
negligible	O
in	O
wide	O
margins	O
,	O
see	O
Appendix	O
.	O
	
The	O
proposed	O
scheme	O
can	O
be	O
viewed	O
as	O
an	O
orthonormal	B-Method
initialization	I-Method
combined	O
with	O
batch	B-Method
normalization	I-Method
performed	O
only	O
on	O
the	O
first	O
mini	O
-	O
batch	O
.	O
	
The	O
similarity	O
to	O
batch	B-Method
normalization	I-Method
is	O
the	O
unit	B-Method
variance	I-Method
normalization	I-Method
procedure	I-Method
,	O
while	O
initial	O
ortho	B-Method
-	I-Method
normalization	I-Method
of	I-Method
weights	I-Method
matrices	I-Method
efficiently	O
de	O
-	O
correlates	O
layer	O
activations	O
,	O
which	O
is	O
not	O
done	O
in	O
.	O
	
Experiments	O
show	O
that	O
such	O
normalization	B-Method
is	O
sufficient	O
and	O
computationally	O
highly	O
efficient	O
in	O
comparison	O
with	O
full	B-Method
batch	I-Method
normalization	I-Method
.	O
	
[	O
b	O
]	O
Layer	O
-	O
sequential	B-Method
unit	I-Method
-	I-Method
variance	I-Method
orthogonal	I-Method
initialization	I-Method
.	O
	
L	O
–	O
convolution	B-Method
or	I-Method
full	I-Method
-	I-Method
connected	I-Method
layer	I-Method
,	O
WL	O
-	O
its	O
weights	O
,	O
BL	O
-	O
its	O
output	O
blob	O
.	O
	
,	O
Tolvar	O
-	O
variance	O
tolerance	O
,	O
Ti	O
–	O
current	O
trial	O
,	O
Tmax	O
–	O
max	O
number	O
of	O
trials	O
.	O
	
Pre	O
-	O
initialize	O
network	O
with	O
orthonormal	O
matrices	O
as	O
in	O
[	O
]	O
layer	O
L	O
|Var	O
(	O
BL	O
)-	O
1.0|≥Tolvar	O
	
and	O
	
(	O
Ti	O
<	O
Tmax	O
)	O
	
Forward	B-Method
pass	I-Method
with	O
a	O
mini	O
-	O
batch	O
⁢Var	O
(	O
BL	O
)	O
=	O
	
WL	O
/	O
⁢Var	O
(	O
BL	O
)	O
	
The	O
LSUV	B-Method
algorithm	O
is	O
summarized	O
in	O
Algorithm	O
[	O
reference	O
]	O
.	O
	
The	O
single	O
parameter	O
influences	O
convergence	O
of	O
the	O
initialization	B-Method
procedure	I-Method
,	O
not	O
the	O
properties	O
of	O
the	O
trained	B-Method
network	I-Method
.	O
	
Its	O
value	O
does	O
not	O
noticeably	O
influence	O
the	O
performance	O
in	O
a	O
broad	O
range	O
of	O
0.01	O
to	O
0.1	O
.	O
	
Because	O
of	O
data	O
variations	O
,	O
it	O
is	O
often	O
not	O
possible	O
to	O
normalize	O
variance	O
with	O
the	O
desired	O
precision	B-Metric
.	O
	
To	O
eliminate	O
the	O
possibility	O
of	O
an	O
infinite	O
loop	O
,	O
we	O
restricted	O
number	O
of	O
trials	O
to	O
.	O
	
However	O
,	O
in	O
experiments	O
described	O
in	O
paper	O
,	O
the	O
was	O
never	O
reached	O
.	O
	
The	O
desired	O
variance	O
was	O
achieved	O
in	O
1	O
-	O
5	O
iterations	O
.	O
	
We	O
tested	O
a	O
variant	O
LSUV	B-Method
initialization	O
which	O
was	O
normalizing	O
input	O
activations	O
of	O
the	O
each	O
layer	O
instead	O
of	O
output	O
ones	O
.	O
	
Normalizing	O
the	O
input	O
or	O
output	O
is	O
identical	O
for	O
standard	O
feed	B-Method
-	I-Method
forward	I-Method
nets	I-Method
,	O
but	O
normalizing	O
input	O
is	O
much	O
more	O
complicated	O
for	O
networks	O
with	O
maxout	B-Method
(	I-Method
)	O
or	O
for	O
networks	O
like	O
GoogLeNet	B-Method
(	I-Method
)	O
which	O
use	O
the	O
output	O
of	O
multiple	O
layers	O
as	O
input	O
.	O
	
Input	B-Task
normalization	I-Task
brought	O
no	O
improvement	O
of	O
results	O
when	O
tested	O
against	O
the	O
LSUV	B-Method
Algorithm	I-Method
[	O
reference	O
]	O
,	O
LSUV	B-Method
was	O
also	O
tested	O
with	O
pre	O
-	O
initialization	O
of	O
weights	O
with	O
Gaussian	O
noise	O
instead	O
of	O
orthonormal	O
matrices	O
.	O
	
The	O
Gaussian	B-Method
initialization	I-Method
led	O
to	O
small	O
,	O
but	O
consistent	O
,	O
decrease	O
in	O
performance	O
.	O
	
section	O
:	O
Experimental	O
validation	O
	
Here	O
we	O
show	O
that	O
very	O
deep	B-Method
and	I-Method
thin	I-Method
nets	I-Method
could	O
be	O
trained	O
in	O
a	O
single	O
stage	O
.	O
	
Network	B-Method
architectures	I-Method
are	O
exactly	O
as	O
proposed	O
by	O
.	O
	
The	O
architectures	O
are	O
presented	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
subsection	O
:	O
MNIST	B-Material
	
First	O
,	O
as	O
a	O
”	O
sanity	O
check	O
”	O
,	O
we	O
performed	O
an	O
experiment	O
on	O
the	O
MNIST	B-Material
dataset	O
(	O
)	O
.	O
	
It	O
consists	O
of	O
60	O
,	O
000	O
28x28	O
grayscale	O
images	O
of	O
handwritten	O
digits	O
0	O
to	O
9	O
.	O
	
We	O
selected	O
the	O
FitNet	O
-	O
MNIST	B-Material
architecture	O
(	O
see	O
Table	O
[	O
reference	O
]	O
)	O
of	O
and	O
trained	O
it	O
with	O
the	O
proposed	O
initialization	B-Method
strategy	I-Method
,	O
without	O
data	B-Method
augmentation	I-Method
.	O
	
Recognition	B-Task
results	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
,	O
right	O
block	O
.	O
	
LSUV	B-Method
outperforms	O
orthonormal	B-Method
initialization	I-Method
and	O
both	O
LSUV	B-Method
and	O
orthonormal	B-Method
outperform	O
Hints	B-Method
initialization	I-Method
.	O
	
The	O
error	B-Metric
rates	I-Metric
of	O
the	O
Deeply	B-Method
-	I-Method
Supervised	I-Method
Nets	I-Method
(	I-Method
DSN	I-Method
,	I-Method
)	I-Method
and	O
maxout	B-Method
networks	I-Method
,	O
the	O
current	O
state	O
-	O
of	O
-	O
art	O
,	O
are	O
provided	O
for	O
reference	O
.	O
	
Since	O
the	O
widely	O
cited	O
DSN	B-Metric
error	I-Metric
rate	I-Metric
of	O
0.39	O
%	O
,	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
(	O
until	O
recently	O
)	O
was	O
obtained	O
after	O
replacing	O
the	O
softmax	B-Method
classifier	I-Method
with	O
SVM	B-Method
,	O
we	O
do	O
the	O
same	O
and	O
also	O
observe	O
improved	O
results	O
(	O
line	O
FitNet	O
-	O
LSUV	B-Method
-	O
SVM	B-Method
in	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
subsection	O
:	O
CIFAR	B-Material
-	I-Material
10	I-Material
/	O
100	B-Material
	
We	O
validated	O
the	O
proposed	O
initialization	O
LSUV	B-Method
strategy	O
on	O
the	O
CIFAR	B-Material
-	I-Material
10	I-Material
/	O
100	B-Material
(	O
)	O
dataset	O
.	O
	
It	O
contains	O
60	O
,	O
000	O
32x32	O
RGB	O
images	O
,	O
which	O
are	O
divided	O
into	O
10	O
and	O
100	B-Material
classes	O
,	O
respectively	O
.	O
	
The	O
FitNets	B-Method
are	O
trained	O
with	O
the	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
with	O
momentum	O
set	O
to	O
0.9	O
,	O
the	O
initial	O
learning	B-Metric
rate	I-Metric
set	O
to	O
0.01	O
and	O
reduced	O
by	O
a	O
factor	O
of	O
10	O
after	O
the	O
100th	O
,	O
150th	O
and	O
200th	O
epoch	O
,	O
finishing	O
at	O
230th	O
epoch	O
.	O
and	O
trained	O
their	O
networks	O
for	O
500	O
epochs	O
.	O
	
Of	O
course	O
,	O
training	B-Metric
time	I-Metric
is	O
a	O
trade	O
-	O
off	O
dependent	O
on	O
the	O
desired	O
accuracy	B-Metric
;	O
one	O
could	O
train	O
a	O
slightly	O
less	O
accurate	O
network	O
much	O
faster	O
.	O
	
Like	O
in	O
the	O
MNIST	B-Material
experiment	O
,	O
LSUV	B-Method
and	O
orthonormal	O
initialized	O
nets	O
outperformed	O
Hints	O
-	O
trained	O
Fitnets	B-Method
,	O
leading	O
to	O
the	O
new	O
state	O
-	O
of	O
-	O
art	O
when	O
using	O
commonly	O
used	O
augmentation	B-Method
–	O
mirroring	B-Method
and	O
random	B-Method
shifts	I-Method
.	O
	
The	O
gain	O
on	O
the	O
fine	B-Material
-	I-Material
grained	I-Material
CIFAR	I-Material
-	I-Material
100	I-Material
is	O
much	O
larger	O
than	O
on	O
CIFAR	B-Material
-	I-Material
10	I-Material
.	O
	
Also	O
,	O
note	O
that	O
FitNets	B-Method
with	O
LSUV	B-Method
initialization	O
outperform	O
even	O
much	O
larger	O
networks	O
like	O
Large	B-Method
-	I-Method
All	I-Method
-	I-Method
CNN	I-Method
and	O
Fractional	B-Method
Max	I-Method
-	I-Method
pooling	I-Method
trained	O
with	O
affine	O
and	O
color	O
dataset	O
augmentation	O
on	O
CIFAR	B-Material
-	I-Material
100	I-Material
.	O
	
The	O
results	O
of	O
LSUV	B-Method
are	O
virtually	O
identical	O
to	O
the	O
orthonormal	B-Method
initialization	I-Method
.	O
	
section	O
:	O
Analysis	O
of	O
empirical	O
results	O
	
subsection	O
:	O
Initialization	B-Method
strategies	I-Method
and	O
non	O
-	O
linearities	O
	
For	O
the	O
FitNet	B-Method
-	I-Method
1	I-Method
architecture	I-Method
,	O
we	O
have	O
not	O
experienced	O
any	O
difficulties	O
training	O
the	O
network	O
with	O
any	O
of	O
the	O
activation	O
functions	O
(	O
ReLU	O
,	O
maxout	O
,	O
tanh	O
)	O
,	O
optimizers	B-Method
(	O
SGD	B-Method
,	O
RMSProp	B-Method
)	O
or	O
initialization	B-Method
(	O
Xavier	B-Method
,	O
MSRA	O
,	O
Ortho	O
,	O
LSUV	B-Method
)	O
,	O
unlike	O
the	O
uniform	B-Method
initialization	I-Method
used	O
in	O
.	O
	
The	O
most	O
probable	O
cause	O
is	O
that	O
CNNs	B-Method
tolerate	O
a	O
wide	O
variety	O
of	O
mediocre	O
initialization	O
,	O
only	O
the	O
learning	B-Metric
time	I-Metric
increases	O
.	O
	
The	O
differences	O
in	O
the	O
final	O
accuracy	B-Metric
between	O
the	O
different	O
initialization	B-Method
methods	I-Method
for	O
the	O
FitNet	B-Method
-	I-Method
1	I-Method
architecture	I-Method
is	O
rather	O
small	O
and	O
are	O
therefore	O
not	O
presented	O
here	O
.	O
	
The	O
FitNet	B-Method
-	I-Method
4	I-Method
architecture	I-Method
is	O
much	O
more	O
difficult	O
to	O
optimize	O
and	O
thus	O
we	O
focus	O
on	O
it	O
in	O
the	O
experiments	O
presented	O
in	O
this	O
section	O
.	O
	
We	O
have	O
explored	O
the	O
initializations	O
with	O
different	O
activation	O
functions	O
in	O
very	O
deep	B-Method
networks	I-Method
.	O
	
More	O
specifically	O
,	O
ReLU	B-Method
,	O
hyperbolic	O
tangent	O
,	O
sigmoid	B-Method
,	O
maxout	B-Method
and	O
the	O
VLReLU	B-Method
–	O
very	O
leaky	O
	
ReLU	O
(	O
)	O
	
–	O
a	O
variant	O
of	O
leaky	B-Method
ReLU	I-Method
(	O
,	O
with	O
a	O
large	O
value	O
of	O
the	O
negative	O
slope	O
0.333	O
,	O
instead	O
of	O
the	O
originally	O
proposed	O
0.01	O
)	O
which	O
is	O
popular	O
in	O
Kaggle	O
competitions	O
,	O
)	O
.	O
	
Testing	O
was	O
performed	O
on	O
CIFAR	B-Material
-	I-Material
10	I-Material
and	O
results	O
are	O
in	O
Table	O
[	O
reference	O
]	O
and	O
Figure	O
[	O
reference	O
]	O
.	O
	
Performance	O
of	O
orthonormal	B-Method
-	I-Method
based	I-Method
methods	I-Method
is	O
superior	O
to	O
the	O
scaled	B-Method
Gaussian	I-Method
-	I-Method
noise	I-Method
approaches	I-Method
for	O
all	O
tested	O
types	O
of	O
activation	O
functions	O
,	O
except	O
tanh	B-Method
.	O
	
Proposed	O
LSUV	B-Method
strategy	O
outperforms	O
orthonormal	B-Method
initialization	I-Method
by	O
smaller	O
margin	O
,	O
but	O
still	O
consistently	O
(	O
see	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
All	O
the	O
methods	O
failed	O
to	O
train	O
sigmoid	B-Method
-	I-Method
based	I-Method
very	I-Method
deep	I-Method
network	I-Method
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
that	O
LSUV	B-Method
method	O
not	O
only	O
leads	O
to	O
better	O
generalization	B-Metric
error	I-Metric
,	O
but	O
also	O
converges	O
faster	O
for	O
all	O
tested	O
activation	O
functions	O
,	O
except	O
tanh	B-Method
.	O
	
We	O
have	O
also	O
tested	O
how	O
the	O
different	O
initializations	O
work	O
”	O
out	O
-	O
of	O
-	O
the	O
-	O
box	O
”	O
with	O
the	O
Residual	B-Method
net	I-Method
training	I-Method
;	O
a	O
residual	B-Method
net	I-Method
won	O
the	O
ILSVRC	O
-	O
2015	O
challenge	O
.	O
	
The	O
original	O
paper	O
proposed	O
different	O
implementations	O
of	O
residual	B-Method
learning	I-Method
.	O
	
We	O
adopted	O
the	O
simplest	O
one	O
,	O
showed	O
in	O
Table	O
[	O
reference	O
]	O
,	O
FitResNet	B-Method
-	I-Method
4	I-Method
.	O
	
The	O
output	O
of	O
each	O
even	B-Method
convolutional	I-Method
layer	I-Method
is	O
summed	O
with	O
the	O
output	O
of	O
the	O
previous	O
non	B-Method
-	I-Method
linearity	I-Method
layer	I-Method
and	O
then	O
fed	O
into	O
the	O
next	O
non	B-Method
-	I-Method
linearity	I-Method
.	O
	
Results	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
LSUV	B-Method
is	O
the	O
only	O
initialization	B-Method
algorithm	I-Method
which	O
leads	O
nets	O
to	O
convergence	O
with	O
all	O
tested	O
non	O
-	O
linearities	O
without	O
any	O
additional	O
tuning	O
,	O
except	O
,	O
again	O
,	O
sigmoid	O
.	O
	
It	O
is	O
worth	O
nothing	O
that	O
the	O
residual	B-Method
training	I-Method
improves	O
results	O
for	O
ReLU	B-Task
and	O
maxout	B-Task
,	O
but	O
does	O
not	O
help	O
tanh	B-Method
-	I-Method
based	I-Method
network	I-Method
.	O
	
subsection	O
:	O
Comparison	O
to	O
batch	B-Method
normalization	I-Method
(	O
BN	B-Method
)	O
	
LSUV	B-Method
procedure	O
could	O
be	O
viewed	O
as	O
batch	O
normalization	O
of	O
layer	O
output	O
done	O
only	O
before	O
the	O
start	O
of	O
training	O
.	O
	
Therefore	O
,	O
it	O
is	O
natural	O
to	O
compare	O
LSUV	B-Method
against	O
a	O
batch	B-Method
-	I-Method
normalized	I-Method
network	I-Method
,	O
initialized	O
with	O
the	O
standard	O
method	O
.	O
	
subsubsection	O
:	O
Where	O
to	O
put	O
BN	O
–	O
before	O
or	O
after	O
non	O
-	O
linearity	O
?	O
	
It	O
is	O
not	O
clear	O
from	O
the	O
paper	O
where	O
to	O
put	O
the	O
batch	B-Method
-	I-Method
normalization	I-Method
layer	I-Method
–	O
before	O
input	O
of	O
each	O
layer	O
as	O
stated	O
in	O
Section	O
3.1	O
,	O
or	O
before	O
non	O
-	O
linearity	O
,	O
as	O
stated	O
in	O
section	O
3.2	O
,	O
so	O
we	O
have	O
conducted	O
an	O
experiment	O
with	O
FitNet4	B-Method
on	O
CIFAR	B-Material
-	I-Material
10	I-Material
to	O
clarify	O
this	O
.	O
	
Results	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Exact	O
numbers	O
vary	O
from	O
run	O
to	O
run	O
,	O
but	O
in	O
the	O
most	O
cases	O
,	O
batch	B-Method
normalization	I-Method
put	O
after	O
non	B-Method
-	I-Method
linearity	I-Method
performs	O
better	O
.	O
	
In	O
the	O
next	O
experiment	O
we	O
compare	O
BN	O
-	O
FitNet4	B-Method
,	O
initialized	O
with	O
Xavier	B-Method
and	O
LSUV	B-Method
-	I-Method
initialized	I-Method
	
FitNet4	B-Method
.	O
	
Batch	B-Method
-	I-Method
normalization	I-Method
reduces	O
training	B-Metric
time	I-Metric
in	O
terms	O
of	O
needed	O
number	O
of	O
iterations	O
,	O
but	O
each	O
iteration	O
becomes	O
slower	O
because	O
of	O
extra	O
computations	O
.	O
	
The	O
accuracy	B-Metric
versus	O
wall	B-Metric
-	I-Metric
clock	I-Metric
-	I-Metric
time	I-Metric
graphs	I-Metric
are	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
LSUV	B-Method
-	O
initialized	O
network	O
is	O
as	O
good	O
as	O
batch	B-Method
-	I-Method
normalized	I-Method
one	I-Method
.	O
	
However	O
,	O
we	O
are	O
not	O
claiming	O
that	O
batch	B-Method
normalization	I-Method
can	O
always	O
be	O
replaced	O
by	O
proper	O
initialization	B-Method
,	O
especially	O
in	O
large	O
datasets	O
like	O
ImageNet	O
.	O
	
subsection	O
:	O
Imagenet	B-Task
training	I-Task
	
We	O
trained	O
CaffeNet	B-Method
(	O
)	O
and	O
GoogLeNet	B-Method
(	I-Method
)	O
on	O
the	O
ImageNet	O
-	O
1000	O
dataset	O
(	O
)	O
with	O
the	O
original	O
initialization	B-Method
and	O
LSUV	B-Method
.	O
	
CaffeNet	B-Method
is	O
a	O
variant	O
of	O
AlexNet	B-Method
with	O
the	O
nearly	O
identical	O
performance	O
,	O
where	O
the	O
order	O
of	O
pooling	O
and	O
normalization	O
layers	O
is	O
switched	O
to	O
reduce	O
the	O
memory	O
footprint	O
.	O
	
LSUV	B-Method
initialization	O
reduces	O
the	O
starting	O
flat	B-Metric
-	I-Metric
loss	I-Metric
time	I-Metric
from	O
0.5	O
epochs	O
to	O
0.05	O
for	O
CaffeNet	B-Method
,	O
and	O
starts	O
to	O
converge	O
faster	O
,	O
but	O
it	O
is	O
overtaken	O
by	O
a	O
standard	O
CaffeNet	B-Method
at	O
the	O
30	O
-	O
th	O
epoch	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
and	O
its	O
final	O
precision	B-Metric
is	O
1.3	O
%	O
lower	O
.	O
	
We	O
have	O
no	O
explanation	O
for	O
this	O
empirical	O
phenomenon	O
.	O
	
On	O
the	O
contrary	O
,	O
the	O
LSUV	B-Method
-	O
initialized	O
GoogLeNet	O
learns	O
faster	O
than	O
hen	O
then	O
original	O
one	O
and	O
shows	O
better	O
test	O
accuracy	B-Metric
all	O
the	O
time	O
–	O
see	O
Figure	O
[	O
reference	O
]	O
.	O
	
The	O
final	O
accuracy	B-Metric
is	O
0.680	O
vs.	O
0.672	O
respectively	O
.	O
	
subsection	O
:	O
Timings	O
	
A	O
significant	O
part	O
of	O
LSUV	B-Method
initialization	O
is	O
SVD	B-Method
-	I-Method
decomposition	I-Method
of	I-Method
the	I-Method
weight	I-Method
matrices	I-Method
,	O
e.g.	O
for	O
the	O
fc6	B-Method
layer	I-Method
of	O
CaffeNet	B-Method
,	O
an	O
SVD	B-Method
of	O
a	O
9216x4096	O
matrix	O
is	O
required	O
.	O
	
The	O
computational	B-Metric
overhead	I-Metric
on	O
top	O
of	O
generating	O
almost	O
instantly	O
the	O
scaled	O
random	O
Gaussian	O
samples	O
is	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
In	O
the	O
slowest	O
case	O
–	O
CaffeNet	O
–	O
LSUV	B-Method
initialization	O
takes	O
3.5	O
minutes	O
,	O
which	O
is	O
negligible	O
in	O
comparison	O
the	O
training	B-Metric
time	I-Metric
.	O
	
section	O
:	O
Conclusions	O
	
LSUV	B-Method
,	O
layer	B-Method
sequential	I-Method
uniform	I-Method
variance	I-Method
,	O
a	O
simple	O
strategy	O
for	O
weight	B-Task
initialization	I-Task
for	O
deep	B-Task
net	I-Task
learning	I-Task
,	O
is	O
proposed	O
.	O
	
We	O
have	O
showed	O
that	O
the	O
LSUV	B-Method
initialization	O
,	O
described	O
fully	O
in	O
six	O
lines	O
of	O
pseudocode	O
,	O
is	O
as	O
good	O
as	O
complex	O
learning	B-Method
schemes	I-Method
which	O
need	O
,	O
for	O
instance	O
,	O
auxiliary	O
nets	O
.	O
	
The	O
LSUV	B-Method
initialization	O
allows	O
learning	B-Task
of	I-Task
very	I-Task
deep	I-Task
nets	I-Task
via	O
standard	O
SGD	B-Method
,	O
is	O
fast	O
,	O
and	O
leads	O
to	O
(	O
near	O
)	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
MNIST	B-Material
,	O
CIFAR	B-Material
,	O
ImageNet	O
datasets	O
,	O
outperforming	O
the	O
sophisticated	O
systems	O
designed	O
specifically	O
for	O
very	B-Task
deep	I-Task
nets	I-Task
such	O
as	O
FitNets	B-Method
(	O
)	O
and	O
Highway	B-Method
(	O
)	O
.	O
	
The	O
proposed	O
initialization	O
works	O
well	O
with	O
different	O
activation	O
functions	O
.	O
	
Our	O
experiments	O
confirm	O
the	O
finding	O
of	O
that	O
very	O
thin	O
,	O
thus	O
fast	O
and	O
low	O
in	O
parameters	O
,	O
but	O
deep	B-Method
networks	I-Method
obtain	O
comparable	O
or	O
even	O
better	O
performance	O
than	O
wider	O
,	O
but	O
shallower	O
ones	O
.	O
	
subsubsection	O
:	O
Acknowledgments	O
	
The	O
authors	O
were	O
supported	O
by	O
The	O
Czech	O
Science	O
Foundation	O
Project	O
GACR	O
P103	O
/	O
12	O
/	O
G084	O
and	O
CTU	O
student	O
grant	O
SGS15	O
/	O
155	O
/	O
OHK3	O
/	O
2T	O
/	O
13	O
.	O
	
bibliography	O
:	O
References	O
	
appendix	O
:	O
Technical	O
details	O
	
subsection	O
:	O
Influence	O
of	O
mini	O
-	O
batch	O
size	O
to	O
LSUV	B-Method
initialization	O
	
We	O
have	O
selected	O
tanh	B-Method
activation	I-Method
as	O
one	O
,	O
where	O
LSUV	B-Method
initialization	O
shows	O
the	O
worst	O
performance	O
and	O
tested	O
the	O
influence	O
of	O
mini	O
-	O
batch	O
size	O
to	O
training	O
process	O
.	O
	
Note	O
,	O
that	O
training	O
mini	O
-	O
batch	O
is	O
the	O
same	O
for	O
all	O
initializations	O
,	O
the	O
only	O
difference	O
is	O
mini	O
-	O
batch	O
used	O
for	O
variance	B-Task
estimation	I-Task
.	O
	
One	O
can	O
see	O
from	O
Table	O
[	O
reference	O
]	O
that	O
there	O
is	O
no	O
difference	O
between	O
small	O
or	O
large	O
mini	O
-	O
batch	O
,	O
except	O
extreme	O
cases	O
,	O
where	O
only	O
two	O
sample	O
are	O
used	O
.	O
	
subsection	O
:	O
LSUV	B-Method
weight	O
standard	O
deviations	O
in	O
different	O
networks	O
	
Tables	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
show	O
the	O
standard	O
deviations	O
of	O
the	O
filter	O
weights	O
,	O
found	O
by	O
the	O
LSUV	B-Method
procedure	O
and	O
by	O
other	O
initialization	B-Method
schemes	I-Method
.	O
	
subsection	O
:	O
Gradients	O
	
To	O
check	O
how	O
the	O
activation	B-Method
variance	I-Method
normalization	I-Method
influences	O
the	O
variance	O
of	O
the	O
gradient	O
,	O
we	O
measure	O
the	O
average	B-Metric
variance	I-Metric
of	O
the	O
gradient	O
at	O
all	O
layers	O
after	O
10	O
mini	O
-	O
batches	O
.	O
	
The	O
variance	O
is	O
close	O
to	O
for	O
all	O
convolutional	B-Method
layers	I-Method
.	O
	
It	O
is	O
much	O
more	O
stable	O
than	O
for	O
the	O
reference	O
methods	O
,	O
except	O
MSRA	B-Method
;	O
see	O
Table	O
[	O
reference	O
]	O
.	O
	
CALIBRATING	B-Method
ENERGY	I-Method
-	I-Method
BASED	I-Method
GENERATIVE	I-Method
ADVER	I-Method
-	I-Method
SARIAL	I-Method
NETWORKS	I-Method
	
section	O
:	O
ABSTRACT	O
	
In	O
this	O
paper	O
we	O
propose	O
equipping	O
Generative	B-Method
Adversarial	I-Method
Networks	I-Method
with	O
the	O
ability	O
to	O
produce	O
direct	O
energy	O
estimates	O
for	O
samples	O
.	O
	
Specifically	O
,	O
we	O
develop	O
a	O
flexible	O
adversarial	B-Method
training	I-Method
framework	I-Method
,	O
and	O
prove	O
this	O
framework	O
not	O
only	O
ensures	O
the	O
generator	B-Method
converges	O
to	O
the	O
true	O
data	O
distribution	O
,	O
but	O
also	O
enables	O
the	O
discriminator	B-Method
to	O
retain	O
the	O
density	O
information	O
at	O
the	O
global	O
optimum	O
.	O
	
We	O
derive	O
the	O
analytic	O
form	O
of	O
the	O
induced	B-Method
solution	I-Method
,	O
and	O
analyze	O
its	O
properties	O
.	O
	
In	O
order	O
to	O
make	O
the	O
proposed	O
framework	O
trainable	O
in	O
practice	O
,	O
we	O
introduce	O
two	O
effective	O
approximation	B-Method
techniques	I-Method
.	O
	
Empirically	O
,	O
the	O
experiment	O
results	O
closely	O
match	O
our	O
theoretical	O
analysis	O
,	O
verifying	O
that	O
the	O
discriminator	B-Method
is	O
able	O
to	O
recover	O
the	O
energy	O
of	O
data	O
distribution	O
.	O
	
section	O
:	O
INTRODUCTION	O
	
Generative	B-Method
Adversarial	I-Method
Networks	I-Method
(	O
GANs	B-Method
)	O
	
[	O
reference	O
]	O
represent	O
an	O
important	O
milestone	O
on	O
the	O
path	O
towards	O
more	O
effective	O
generative	B-Method
models	I-Method
.	O
	
GANs	B-Method
cast	O
generative	B-Method
model	I-Method
training	I-Method
as	O
a	O
minimax	B-Method
game	I-Method
between	O
a	O
generative	B-Method
network	I-Method
(	O
generator	B-Method
)	O
,	O
which	O
maps	O
a	O
random	O
vector	O
into	O
the	O
data	O
space	O
,	O
and	O
a	O
discriminative	B-Method
network	I-Method
(	O
discriminator	B-Method
)	O
,	O
whose	O
objective	O
is	O
to	O
distinguish	O
generated	O
samples	O
from	O
real	O
samples	O
.	O
	
Multiple	O
researchers	O
[	O
reference	O
]	O
;	O
[	O
reference	O
]	O
;	O
[	O
reference	O
]	O
have	O
shown	O
that	O
the	O
adversarial	O
interaction	O
with	O
the	O
discriminator	B-Method
can	O
result	O
in	O
a	O
generator	B-Method
that	O
produces	O
compelling	O
samples	O
.	O
	
The	O
empirical	O
successes	O
of	O
the	O
GAN	B-Method
framework	O
were	O
also	O
supported	O
by	O
the	O
theoretical	O
analysis	O
of	O
[	O
reference	O
]	O
	
showed	O
that	O
,	O
under	O
certain	O
conditions	O
,	O
the	O
distribution	O
produced	O
by	O
the	O
generator	B-Method
converges	O
to	O
the	O
true	O
data	O
distribution	O
,	O
while	O
the	O
discriminator	B-Method
converges	O
to	O
a	O
degenerate	B-Method
uniform	I-Method
solution	I-Method
.	O
	
While	O
GANs	B-Method
have	O
excelled	O
as	O
compelling	O
sample	B-Method
generators	I-Method
,	O
their	O
use	O
as	O
general	B-Method
purpose	I-Method
probabilistic	I-Method
generative	I-Method
models	I-Method
has	O
been	O
limited	O
by	O
the	O
difficulty	O
in	O
using	O
them	O
to	O
provide	O
density	B-Method
estimates	I-Method
or	O
even	O
unnormalized	O
energy	O
values	O
for	O
sample	B-Task
evaluation	I-Task
.	O
	
It	O
is	O
tempting	O
to	O
consider	O
the	O
GAN	B-Method
discriminator	O
as	O
a	O
candidate	O
for	O
providing	O
this	O
sort	O
of	O
scoring	O
function	O
.	O
	
Conceptually	O
,	O
it	O
is	O
a	O
trainable	B-Method
sample	I-Method
evaluation	I-Method
mechanism	I-Method
that	O
-	O
owing	O
to	O
GAN	B-Method
training	O
paradigm	O
-	O
could	O
be	O
closely	O
calibrated	O
to	O
the	O
distribution	O
modeled	O
by	O
the	O
generator	B-Method
.	O
	
If	O
the	O
discriminator	O
could	O
retain	O
fine	O
-	O
grained	O
information	O
of	O
the	O
relative	O
quality	O
of	O
samples	O
,	O
measured	O
for	O
instance	O
by	O
probability	O
density	O
or	O
unnormalized	O
energy	O
,	O
it	O
could	O
be	O
used	O
as	O
an	O
evaluation	B-Metric
metric	I-Metric
.	O
	
Such	O
data	B-Method
-	I-Method
driven	I-Method
evaluators	I-Method
would	O
be	O
highly	O
desirable	O
for	O
problems	O
where	O
it	O
is	O
difficult	O
to	O
define	O
evaluation	B-Metric
criteria	I-Metric
that	O
correlate	O
well	O
with	O
human	O
judgment	O
.	O
	
Indeed	O
,	O
the	O
real	B-Method
-	I-Method
valued	I-Method
discriminator	I-Method
of	O
the	O
recently	O
introduced	O
energy	B-Method
-	I-Method
based	I-Method
GANs	I-Method
[	O
reference	O
]	O
might	O
seem	O
like	O
an	O
ideal	O
candidate	O
energy	O
function	O
.	O
	
Unfortunately	O
,	O
as	O
we	O
will	O
show	O
,	O
the	O
degenerate	O
fate	O
of	O
the	O
GAN	B-Method
discriminator	O
at	O
the	O
optimum	O
equally	O
afflicts	O
the	O
energy	O
-	O
based	O
GAN	B-Method
of	O
[	O
reference	O
]	O
	
In	O
this	O
paper	O
we	O
consider	O
the	O
questions	O
:	O
(	O
i	O
)	O
does	O
there	O
exists	O
an	O
adversarial	B-Method
framework	I-Method
that	O
induces	O
a	O
non	O
-	O
degenerate	B-Method
discriminator	I-Method
,	O
and	O
(	O
ii	O
)	O
if	O
so	O
,	O
what	O
form	O
will	O
the	O
resulting	O
discriminator	B-Method
take	O
?	O
	
We	O
introduce	O
a	O
novel	O
adversarial	B-Method
learning	I-Method
formulation	I-Method
,	O
which	O
leads	O
to	O
a	O
non	B-Method
-	I-Method
degenerate	I-Method
discriminator	I-Method
while	O
ensuring	O
the	O
generator	O
distribution	O
matches	O
the	O
data	O
distribution	O
at	O
the	O
global	O
optimum	O
.	O
	
We	O
derive	O
a	O
general	O
analytic	B-Method
form	I-Method
of	O
the	O
optimal	B-Method
discriminator	I-Method
,	O
and	O
discuss	O
its	O
properties	O
and	O
their	O
Following	O
the	O
original	O
work	O
on	O
GANs	B-Method
[	O
reference	O
]	O
,	O
our	O
analysis	O
focuses	O
on	O
the	O
nonparametric	B-Task
case	I-Task
,	O
where	O
all	O
models	O
are	O
assumed	O
to	O
have	O
infinite	O
capacities	O
.	O
	
While	O
many	O
of	O
the	O
nonparametric	O
intuitions	O
can	O
directly	O
transfer	O
to	O
the	O
parametric	B-Task
case	I-Task
,	O
we	O
will	O
point	O
out	O
cases	O
where	O
this	O
transfer	O
fails	O
.	O
	
We	O
assume	O
a	O
finite	O
data	O
space	O
throughout	O
the	O
analysis	O
,	O
to	O
avoid	O
technical	O
machinery	O
out	O
of	O
the	O
scope	O
of	O
this	O
paper	O
.	O
	
Our	O
results	O
,	O
however	O
,	O
can	O
be	O
extended	O
to	O
continuous	O
data	O
spaces	O
,	O
and	O
our	O
experiments	O
are	O
indeed	O
performed	O
on	O
continuous	O
data	O
.	O
	
Let	O
X	O
be	O
the	O
data	O
space	O
under	O
consideration	O
,	O
and	O
P	O
=	O
{	O
p	O
|	O
p	O
(	O
x	O
)	O
≥	O
0	O
,	O
∀x	O
∈	O
X	O
,	O
x∈X	O
p	O
(	O
x	O
)	O
=	O
	
1	O
}	O
be	O
the	O
set	O
of	O
all	O
proper	O
distributions	O
defined	O
on	O
X	O
.	O
	
Then	O
,	O
p	O
data	O
∈	O
P	O
:	O
X	O
→	O
R	O
and	O
p	O
gen	O
∈	O
P	O
:	O
	
X	O
→	O
R	O
will	O
denote	O
the	O
true	O
data	O
distribution	O
and	O
the	O
generator	B-Method
distribution	I-Method
.	O
	
E	O
x∼p	O
	
f	O
(	O
x	O
)	O
denotes	O
the	O
expectation	O
of	O
the	O
quantity	O
f	O
(	O
x	O
)	O
w.r.t	O
.	O
	
x	O
drawn	O
from	O
p.	O
Finally	O
,	O
the	O
term	O
"	O
discriminator	B-Method
"	O
will	O
refer	O
to	O
any	O
structure	O
that	O
provides	O
training	O
signals	O
to	O
the	O
generator	O
based	O
on	O
some	O
measure	O
of	O
difference	O
between	O
the	O
generator	B-Method
distribution	I-Method
and	O
the	O
real	O
data	O
distribution	O
,	O
which	O
which	O
includes	O
but	O
is	O
not	O
limited	O
to	O
f	O
-	O
divergence	O
.	O
	
section	O
:	O
PROPOSED	O
FORMULATION	O
	
In	O
order	O
to	O
understand	O
the	O
motivation	O
of	O
the	O
proposed	O
approach	O
,	O
it	O
is	O
helpful	O
to	O
analyze	O
the	O
optimization	B-Method
dynamics	I-Method
near	I-Method
convergence	I-Method
in	O
GANs	B-Method
first	O
.	O
	
When	O
the	O
generator	B-Method
distribution	I-Method
matches	O
the	O
data	O
distribution	O
,	O
the	O
training	O
signal	O
(	O
gradient	O
)	O
w.r.t	O
.	O
	
the	O
discriminator	B-Method
vanishes	O
.	O
	
At	O
this	O
point	O
,	O
assume	O
the	O
discriminator	O
still	O
retains	O
density	O
information	O
,	O
and	O
views	O
some	O
samples	O
as	O
more	O
real	O
and	O
others	O
as	O
less	O
.	O
	
This	O
discriminator	O
will	O
produce	O
a	O
training	O
signal	O
(	O
gradient	O
)	O
w.r.t	O
.	O
	
the	O
generator	O
,	O
pushing	O
the	O
generator	O
to	O
generate	O
samples	O
that	O
appear	O
more	O
real	O
to	O
the	O
discriminator	O
.	O
	
Critically	O
,	O
this	O
training	O
signal	O
is	O
the	O
sole	O
driver	O
of	O
the	O
generator	B-Method
's	I-Method
training	I-Method
.	O
	
Hence	O
,	O
the	O
generator	B-Method
distribution	I-Method
will	O
diverge	O
from	O
the	O
data	B-Method
distribution	I-Method
.	O
	
In	O
other	O
words	O
,	O
as	O
long	O
as	O
the	O
discriminator	O
retains	O
relative	O
density	O
information	O
,	O
the	O
generator	B-Method
distribution	I-Method
can	O
not	O
stably	O
match	O
the	O
data	O
distribution	O
.	O
	
Thus	O
,	O
in	O
order	O
to	O
keep	O
the	O
generator	O
stationary	O
as	O
the	O
data	O
distribution	O
,	O
the	O
discriminator	B-Method
must	O
assign	O
flat	O
(	O
exactly	O
the	O
same	O
)	O
density	O
to	O
all	O
samples	O
at	O
the	O
optimal	O
.	O
	
From	O
the	O
analysis	O
above	O
,	O
the	O
fundamental	O
difficulty	O
is	O
that	O
the	O
generator	B-Method
only	O
receives	O
a	O
single	O
training	O
signal	O
(	O
gradient	O
)	O
from	O
the	O
discriminator	B-Method
,	O
which	O
it	O
has	O
to	O
follow	O
.	O
	
To	O
keep	O
the	O
generator	O
stationary	O
,	O
this	O
single	O
training	O
signal	O
(	O
gradient	O
)	O
must	O
vanish	O
,	O
which	O
requires	O
a	O
degenerate	B-Method
discriminator	I-Method
.	O
	
In	O
this	O
work	O
,	O
we	O
propose	O
to	O
tackle	O
this	O
single	O
training	O
signal	O
constraint	O
directly	O
.	O
	
Specifically	O
,	O
we	O
introduce	O
a	O
novel	O
adversarial	B-Method
learning	I-Method
formulation	I-Method
which	O
incorporates	O
an	O
additional	O
training	O
signal	O
to	O
the	O
generator	O
,	O
such	O
that	O
this	O
additional	O
signal	O
can	O
	
•	O
	
balance	O
(	O
cancel	O
out	O
)	O
the	O
discriminator	O
signal	O
at	O
the	O
optimum	O
,	O
so	O
that	O
the	O
generator	O
can	O
stay	O
stationary	O
even	O
if	O
the	O
discriminator	O
assigns	O
non	O
-	O
flat	O
density	O
to	O
samples	O
	
•	O
cooperate	O
with	O
the	O
discriminator	O
signal	O
to	O
make	O
sure	O
the	O
generator	B-Method
converges	O
to	O
the	O
data	O
distribution	O
,	O
and	O
the	O
discriminator	O
retains	O
the	O
correct	O
relative	O
density	O
information	O
	
The	O
proposed	O
formulation	O
can	O
be	O
written	O
as	O
the	O
following	O
minimax	B-Task
training	I-Task
objective	I-Task
,	O
	
where	O
c	O
(	O
x	O
)	O
	
:	O
X	O
→	O
R	O
is	O
the	O
discriminator	B-Method
that	O
assigns	O
each	O
data	O
point	O
an	O
unbounded	O
scalar	O
cost	O
,	O
and	O
K	B-Method
(	I-Method
p	I-Method
gen	I-Method
)	O
:	O
	
P	O
→	O
R	O
is	O
some	O
(	O
functionally	O
)	O
differentiable	O
,	O
convex	O
function	O
of	O
p	O
gen	O
.	O
	
Compared	O
to	O
the	O
original	O
GAN	B-Method
,	O
despite	O
the	O
similar	O
minimax	O
surface	O
form	O
,	O
the	O
proposed	O
fomulation	B-Method
has	O
two	O
crucial	O
distinctions	O
.	O
	
Firstly	O
,	O
while	O
the	O
GAN	B-Method
discriminator	O
tries	O
to	O
distinguish	O
"	O
fake	O
"	O
samples	O
from	O
real	O
ones	O
using	O
binary	B-Method
classification	I-Method
,	O
the	O
proposed	O
discriminator	O
achieves	O
that	O
by	O
assigning	O
lower	O
cost	O
to	O
real	O
samples	O
and	O
higher	O
cost	O
to	O
"	O
fake	O
"	O
one	O
.	O
	
This	O
distinction	O
can	O
be	O
seen	O
from	O
the	O
first	O
two	O
terms	O
of	O
Eqn	O
.	O
	
(	O
1	O
)	O
,	O
where	O
the	O
discriminator	B-Method
c	I-Method
(	I-Method
x	I-Method
)	O
is	O
trained	O
to	O
widen	O
the	O
expected	B-Metric
cost	I-Metric
gap	I-Metric
between	O
"	O
fake	O
"	O
and	O
real	O
samples	O
,	O
while	O
the	O
generator	O
is	O
adversarially	O
trained	O
to	O
minimize	O
it	O
.	O
	
In	O
addition	O
to	O
the	O
different	O
adversarial	B-Method
mechanism	I-Method
,	O
a	O
calibrating	B-Method
term	I-Method
K	I-Method
(	I-Method
p	I-Method
gen	I-Method
)	O
is	O
introduced	O
to	O
provide	O
a	O
countervailing	O
source	O
of	O
training	O
signal	O
for	O
p	O
gen	O
as	O
we	O
motivated	O
above	O
.	O
	
For	O
now	O
,	O
the	O
form	O
of	O
K	O
(	O
p	O
gen	O
)	O
has	O
not	O
been	O
specified	O
.	O
	
But	O
as	O
we	O
will	O
see	O
later	O
,	O
its	O
choice	O
will	O
directly	O
decide	O
the	O
form	O
of	O
the	O
optimal	B-Method
discriminator	I-Method
c	O
	
*	O
(	O
x	O
)	O
.	O
	
With	O
the	O
specific	O
optimization	B-Metric
objective	I-Metric
,	O
we	O
next	O
provide	O
theoretical	O
characterization	O
of	O
both	O
the	O
generator	B-Method
and	O
the	O
discriminator	B-Method
at	O
the	O
global	O
optimum	O
.	O
	
is	O
the	O
Lagrange	O
dual	O
function	O
of	O
the	O
following	O
optimization	B-Task
problem	I-Task
	
where	O
c	O
(	O
x	O
)	O
,	O
∀x	O
appears	O
in	O
L	O
(	O
p	O
gen	O
,	O
c	O
)	O
as	O
the	O
dual	O
variables	O
introduced	O
for	O
the	O
equality	O
constraints	O
.	O
	
This	O
duality	O
relationship	O
has	O
been	O
observed	O
previously	O
in	O
[	O
reference	O
]	O
)	O
under	O
the	O
adversarial	B-Task
imitation	I-Task
learning	I-Task
setting	I-Task
.	O
	
However	O
,	O
in	O
their	O
case	O
,	O
the	O
focus	O
was	O
fully	O
on	O
the	O
generator	O
side	O
(	O
induced	B-Method
policy	I-Method
)	O
,	O
and	O
no	O
analysis	O
was	O
provided	O
for	O
the	O
discriminator	B-Method
(	O
reward	O
function	O
)	O
.	O
	
In	O
order	O
to	O
characterize	O
c	O
*	O
,	O
we	O
first	O
expand	O
the	O
set	O
constraint	O
on	O
p	O
gen	O
into	O
explicit	O
equality	O
and	O
inequality	O
constraints	O
:	O
min	O
	
Notice	O
that	O
K	O
(	O
p	O
gen	O
)	O
is	O
a	O
convex	O
function	O
of	O
p	O
gen	O
(	O
x	O
)	O
by	O
definition	O
,	O
and	O
both	O
the	O
equality	O
and	O
inequality	O
constraints	O
are	O
affine	O
functions	O
of	O
p	O
gen	O
(	O
x	O
)	O
.	O
	
Thus	O
,	O
problem	O
(	O
2	O
)	O
is	O
a	O
convex	B-Task
optimization	I-Task
problem	I-Task
.	O
	
What	O
's	O
more	O
,	O
since	O
(	O
i	O
)	O
dom	O
K	O
is	O
open	O
,	O
and	O
(	O
ii	O
)	O
there	O
exists	O
a	O
feasible	O
solution	O
p	O
gen	O
=	O
p	O
data	O
to	O
(	O
3	O
)	O
,	O
by	O
the	O
refined	O
Slater	O
's	O
condition	O
[	O
reference	O
]	O
,	O
page	O
226	O
)	O
,	O
we	O
can	O
further	O
verify	O
that	O
strong	O
duality	O
holds	O
for	O
(	O
3	O
)	O
.	O
	
With	O
strong	B-Method
duality	I-Method
,	O
a	O
typical	O
approach	O
to	O
characterizing	O
the	O
optimal	B-Task
solution	I-Task
is	O
to	O
apply	O
the	O
Karush	B-Method
-	I-Method
Kuhn	I-Method
-	I-Method
Tucker	I-Method
(	O
KKT	O
)	O
conditions	O
,	O
which	O
gives	O
rise	O
to	O
this	O
theorem	O
:	O
	
Proposition	O
3.1	O
.	O
	
By	O
the	O
KKT	O
conditions	O
of	O
the	O
convex	B-Task
problem	I-Task
(	O
3	O
)	O
,	O
at	O
the	O
global	O
optimum	O
,	O
the	O
optimal	O
generator	B-Method
distribution	I-Method
p	O
*	O
gen	O
matches	O
the	O
true	O
data	O
distribution	O
p	O
data	O
,	O
and	O
the	O
optimal	O
discriminator	B-Method
c	O
	
*	O
(	O
x	O
)	O
has	O
the	O
following	O
form	O
:	O
	
is	O
an	O
under	O
-	O
determined	O
real	O
number	O
independent	O
of	O
x	O
,	O
u	O
x	O
∈	O
R	O
+	O
,	O
is	O
an	O
under	O
-	O
determined	O
non	O
-	O
negative	O
real	O
number	O
.	O
	
The	O
detailed	O
proof	O
of	O
proposition	O
3.1	O
is	O
provided	O
in	O
appendix	O
A.1	O
.	O
	
From	O
(	O
4	O
)	O
,	O
we	O
can	O
see	O
the	O
exact	O
form	O
of	O
the	O
optimal	B-Method
discriminator	I-Method
depends	O
on	O
the	O
term	O
K	O
(	O
p	O
gen	O
)	O
,	O
or	O
more	O
specifically	O
its	O
gradient	O
.	O
	
But	O
,	O
before	O
we	O
instantiate	O
K	O
(	O
p	O
gen	O
)	O
with	O
specific	O
choices	O
and	O
show	O
the	O
corresponding	O
forms	O
of	O
c	O
	
*	O
(	O
x	O
)	O
,	O
we	O
first	O
discuss	O
some	O
general	O
properties	O
of	O
c	O
	
*	O
(	O
x	O
)	O
that	O
do	O
not	O
depend	O
on	O
the	O
choice	O
of	O
K.	O
	
Weak	B-Method
Support	I-Method
Discriminator	I-Method
.	O
	
As	O
part	O
of	O
the	O
optimal	B-Method
discriminator	I-Method
function	I-Method
,	O
the	O
term	O
µ	O
	
*	O
(	O
x	O
)	O
plays	O
the	O
role	O
of	O
support	O
discriminator	O
.	O
	
That	O
is	O
,	O
it	O
tries	O
to	O
distinguish	O
the	O
support	O
of	O
the	O
data	O
distribution	O
,	O
i.e.	O
SUPP	O
(	O
p	O
data	O
)	O
=	O
	
{	O
x	O
∈	O
X	O
|	O
p	O
data	O
(	O
x	O
)	O
>	O
0	O
}	O
,	O
from	O
its	O
complement	O
set	O
with	O
zeroprobability	O
,	O
i.e.	O
SUPP	O
(	O
p	O
data	O
)	O
=	O
	
{	O
x	O
∈	O
X	O
|	O
p	O
data	O
(	O
x	O
)	O
	
=	O
	
0}.	O
	
Specifically	O
,	O
for	O
any	O
x	O
∈	O
SUPP	O
(	O
p	O
data	O
)	O
and	O
x	O
∈	O
SUPP	O
(	O
p	O
data	O
)	O
,	O
it	O
is	O
guaranteed	O
that	O
µ	O
	
*	O
(	O
x	O
)	O
≤	O
µ	O
	
*	O
(	O
x	O
)	O
.	O
	
However	O
,	O
because	O
µ	O
*	O
(	O
·	O
)	O
is	O
underdetermined	O
,	O
there	O
is	O
nothing	O
preventing	O
the	O
inequality	O
from	O
degenerating	O
into	O
an	O
equality	O
.	O
	
Therefore	O
,	O
we	O
name	O
it	O
the	O
weak	B-Method
support	I-Method
discriminator	I-Method
.	O
	
But	O
,	O
in	O
all	O
cases	O
,	O
µ	O
*	O
(	O
·	O
)	O
assigns	O
zero	O
cost	O
to	O
all	O
data	O
points	O
within	O
the	O
support	O
.	O
	
As	O
a	O
result	O
,	O
it	O
does	O
not	O
possess	O
any	O
fine	O
-	O
grained	O
density	O
information	O
inside	O
of	O
the	O
data	O
support	O
.	O
	
It	O
is	O
worth	O
pointing	O
out	O
that	O
,	O
in	O
the	O
parametric	B-Task
case	I-Task
,	O
because	O
of	O
the	O
smoothness	O
and	O
the	O
generalization	O
properties	O
of	O
the	O
parametric	B-Method
model	I-Method
,	O
the	O
learned	O
discriminator	B-Method
may	O
generalize	O
beyond	O
the	O
data	O
support	O
.	O
	
Global	B-Metric
Bias	I-Metric
.	O
	
In	O
(	O
4	O
)	O
,	O
the	O
term	O
λ	O
*	O
is	O
a	O
scalar	O
value	O
shared	O
for	O
all	O
x.	O
	
As	O
a	O
result	O
,	O
it	O
does	O
not	O
affect	O
the	O
relative	O
cost	O
among	O
data	O
points	O
,	O
and	O
only	O
serves	O
as	O
a	O
global	O
bias	O
for	O
the	O
discriminator	B-Method
function	I-Method
.	O
	
Having	O
discussed	O
general	O
properties	O
,	O
we	O
now	O
consider	O
some	O
specific	O
cases	O
of	O
the	O
convex	O
function	O
K	O
,	O
and	O
analyze	O
the	O
resulting	O
optimal	B-Method
discriminator	I-Method
c	O
	
*	O
(	O
x	O
)	O
in	O
detail	O
.	O
	
1	O
.	O
	
First	O
,	O
let	O
us	O
consider	O
the	O
case	O
where	O
K	O
is	O
the	O
negative	O
entropy	O
of	O
the	O
generator	B-Method
distribution	I-Method
,	O
i.e.	O
K	O
(	O
p	O
gen	O
)	O
	
=	O
−H	O
(	O
p	O
gen	O
)	O
.	O
	
Taking	O
the	O
derivative	O
of	O
the	O
negative	O
entropy	O
w.r.t	O
.	O
	
p	O
gen	O
(	O
x	O
)	O
	
,	O
we	O
have	O
	
where	O
µ	O
	
*	O
(	O
x	O
)	O
	
and	O
λ	O
*	O
have	O
the	O
same	O
definitions	O
as	O
in	O
(	O
4	O
)	O
.	O
	
Up	O
to	O
a	O
constant	O
,	O
this	O
form	O
of	O
c	O
*	O
ent	O
(	O
x	O
)	O
is	O
exactly	O
the	O
energy	O
function	O
of	O
the	O
data	B-Method
distribution	I-Method
p	O
data	O
(	O
x	O
)	O
.	O
	
This	O
elegant	O
result	O
has	O
deep	O
connections	O
to	O
several	O
existing	O
formulations	O
,	O
which	O
include	O
max	B-Method
-	I-Method
entropy	I-Method
imitation	I-Method
learning	I-Method
[	O
reference	O
]	O
and	O
the	O
directed	B-Method
-	I-Method
generator	I-Method
-	I-Method
trained	I-Method
energybased	I-Method
model	I-Method
[	O
reference	O
]	O
.	O
	
The	O
core	O
difference	O
is	O
that	O
these	O
previous	O
formulations	O
are	O
originally	O
derived	O
from	O
maximum	B-Method
-	I-Method
likelihood	I-Method
estimation	I-Method
,	O
and	O
thus	O
the	O
minimax	B-Task
optimization	I-Task
is	O
only	O
implicit	O
.	O
	
In	O
contrast	O
,	O
with	O
an	O
explicit	O
minimax	B-Method
formulation	I-Method
we	O
can	O
develop	O
a	O
better	O
understanding	O
of	O
the	O
induced	B-Task
solution	I-Task
.	O
	
For	O
example	O
,	O
the	O
global	O
bias	O
λ	O
*	O
suggests	O
that	O
there	O
exists	O
more	O
than	O
one	O
stable	O
equilibrium	O
the	O
optimal	O
discriminator	B-Method
can	O
actually	O
reach	O
.	O
	
Further	O
,	O
µ	O
*	O
(	O
x	O
)	O
can	O
be	O
understood	O
as	O
a	O
support	B-Method
discriminator	I-Method
that	O
poses	O
extra	O
cost	O
on	O
generator	O
samples	O
which	O
fall	O
in	O
zero	O
-	O
probability	O
regions	O
of	O
data	O
space	O
.	O
	
,	O
which	O
can	O
be	O
understood	O
as	O
posing	O
2	O
regularization	O
on	O
p	O
gen	O
,	O
we	O
have	O
	
with	O
µ	O
	
*	O
(	O
x	O
)	O
,	O
λ	O
*	O
similarly	O
defined	O
as	O
in	O
(	O
4	O
)	O
.	O
	
Surprisingly	O
,	O
the	O
result	O
suggests	O
that	O
the	O
optimal	O
discriminator	O
c	O
*	O
2	O
(	O
x	O
)	O
directly	O
recovers	O
the	O
negative	O
probability	O
−p	O
data	O
(	O
x	O
)	O
,	O
shifted	O
by	O
a	O
constant	O
.	O
	
Thus	O
,	O
similar	O
to	O
the	O
entropy	B-Method
solution	I-Method
(	O
5	O
)	O
,	O
it	O
fully	O
retains	O
the	O
relative	O
density	O
information	O
of	O
data	O
points	O
within	O
the	O
support	O
.	O
	
However	O
,	O
because	O
of	O
the	O
under	O
-	O
determined	O
term	O
µ	O
	
*	O
(	O
x	O
)	O
,	O
we	O
can	O
not	O
recover	O
the	O
distribution	O
density	O
p	O
data	O
exactly	O
from	O
either	O
c	O
*	O
2	O
or	O
c	O
	
*	O
ent	O
if	O
the	O
data	O
support	O
is	O
finite	O
.	O
	
Whether	O
this	O
ambiguity	O
can	O
be	O
resolved	O
is	O
beyond	O
the	O
scope	O
of	O
this	O
paper	O
,	O
but	O
poses	O
an	O
interesting	O
research	O
problem	O
.	O
	
3	O
.	O
	
Finally	O
,	O
let	O
's	O
consider	O
consider	O
a	O
degenerate	O
case	O
,	O
where	O
K	O
(	O
p	O
gen	O
)	O
is	O
a	O
constant	O
.	O
	
That	O
is	O
,	O
we	O
do	O
nt	O
provide	O
any	O
additional	O
training	O
signal	O
for	O
pgen	B-Method
at	O
all	O
.	O
	
With	O
K	O
(	O
p	O
gen	O
)	O
=	O
const	O
,	O
we	O
simply	O
have	O
	
whose	O
discriminative	B-Metric
power	I-Metric
is	O
fully	O
controlled	O
by	O
the	O
weak	B-Method
support	I-Method
discriminator	I-Method
µ	O
	
*	O
(	O
x	O
)	O
.	O
	
Thus	O
,	O
it	O
follows	O
that	O
c	O
*	O
cst	O
(	O
x	O
)	O
wo	O
n't	O
be	O
able	O
to	O
discriminate	O
data	O
points	O
within	O
the	O
support	O
of	O
p	O
data	O
,	O
and	O
its	O
power	O
to	O
distinguish	O
data	O
from	O
SUPP	O
(	O
p	O
data	O
)	O
and	O
SUPP	O
(	O
p	O
data	O
)	O
is	O
weak	O
.	O
	
This	O
closely	O
matches	O
the	O
intuitive	O
argument	O
in	O
the	O
beginning	O
of	O
this	O
section	O
.	O
	
Note	O
that	O
when	O
K	O
(	O
p	O
gen	O
)	O
is	O
a	O
constant	O
,	O
the	O
objective	O
function	O
(	O
1	O
)	O
simplifies	O
to	O
:	O
	
which	O
is	O
very	O
similar	O
to	O
the	O
EBGAN	O
objective	O
[	O
reference	O
]	O
(	O
2	O
)	O
and	O
(	O
4	O
)	O
)	O
.	O
	
As	O
we	O
show	O
in	O
appendix	O
A.2	O
,	O
compared	O
to	O
the	O
objective	O
in	O
(	O
8	O
)	O
,	O
the	O
EBGAN	O
objective	O
puts	O
extra	O
constraints	O
on	O
the	O
allowed	O
discriminator	O
function	O
.	O
	
In	O
spite	O
of	O
that	O
,	O
the	O
EBGAN	B-Method
objective	I-Method
suffers	O
from	O
the	O
single	B-Task
-	I-Task
training	I-Task
-	I-Task
signal	I-Task
problem	I-Task
and	O
does	O
not	O
guarantee	O
that	O
the	O
discriminator	B-Method
will	O
recover	O
the	O
real	O
energy	O
function	O
(	O
see	O
appendix	O
A.2	O
for	O
detailed	O
analysis	O
)	O
.	O
	
As	O
we	O
finish	O
the	O
theoretical	O
analysis	O
of	O
the	O
proposed	O
formulation	O
,	O
we	O
want	O
to	O
point	O
out	O
that	O
simply	O
adding	O
the	O
same	O
term	O
K	O
(	O
p	O
gen	O
)	O
to	O
the	O
original	O
GAN	B-Method
formulation	O
will	O
not	O
lead	O
to	O
both	O
a	O
generator	B-Method
that	O
matches	O
the	O
data	O
distribution	O
,	O
and	O
a	O
discriminator	B-Method
that	O
retains	O
the	O
density	O
information	O
(	O
see	O
appendix	O
A.3	O
for	O
detailed	O
analysis	O
)	O
.	O
	
section	O
:	O
PARAMETRIC	B-Method
INSTANTIATION	I-Method
WITH	O
ENTROPY	B-Method
APPROXIMATION	I-Method
	
While	O
the	O
discussion	O
in	O
previous	O
sections	O
focused	O
on	O
the	O
non	B-Task
-	I-Task
parametric	I-Task
case	I-Task
,	O
in	O
practice	O
we	O
are	O
limited	O
to	O
a	O
finite	O
amount	O
of	O
data	O
,	O
and	O
the	O
actual	O
problem	O
involves	O
high	O
dimensional	O
continuous	O
spaces	O
.	O
	
Thus	O
,	O
we	O
resort	O
to	O
parametric	B-Method
representations	I-Method
for	O
both	O
the	O
generator	B-Method
and	O
the	O
discriminator	B-Method
.	O
	
In	O
order	O
to	O
train	O
the	O
generator	B-Method
using	O
standard	O
back	B-Method
-	I-Method
propagation	I-Method
,	O
we	O
do	O
not	O
parametrize	O
the	O
generator	B-Method
distribution	I-Method
directly	O
.	O
	
Instead	O
,	O
we	O
parametrize	O
a	O
directed	B-Method
generator	I-Method
network	I-Method
that	O
transforms	O
random	O
noise	O
z	O
∼	O
	
p	O
z	O
(	O
z	O
)	O
to	O
samples	O
from	O
a	O
continuous	O
data	O
space	O
R	O
n	O
.	O
	
Consequently	O
,	O
we	O
do	O
n't	O
have	O
analytical	O
access	O
to	O
the	O
generator	B-Method
distribution	I-Method
,	O
which	O
is	O
defined	O
implicitly	O
by	O
the	O
generator	B-Method
network	I-Method
's	I-Method
noise→data	I-Method
mapping	I-Method
.	O
	
However	O
,	O
the	O
regularization	O
term	O
K	O
(	O
p	O
gen	O
)	O
in	O
the	O
training	B-Task
objective	I-Task
(	O
1	O
)	O
requires	O
the	O
generator	O
distribution	O
.	O
	
Faced	O
with	O
this	O
problem	O
,	O
we	O
focus	O
on	O
the	O
max	B-Method
-	I-Method
entropy	I-Method
formulation	I-Method
,	O
and	O
exploit	O
two	O
different	O
approximations	O
of	O
the	O
regularization	B-Method
term	I-Method
K	I-Method
(	I-Method
p	I-Method
gen	I-Method
)	O
=	O
−H	O
(	O
p	O
gen	O
)	O
.	O
	
section	O
:	O
NEAREST	B-Method
-	I-Method
NEIGHBOR	I-Method
ENTROPY	I-Method
GRADIENT	I-Method
APPROXIMATION	I-Method
	
The	O
first	O
proposed	O
solution	O
is	O
built	O
upon	O
an	O
intuitive	O
interpretation	O
of	O
the	O
entropy	B-Method
gradient	I-Method
.	O
	
Firstly	O
,	O
since	O
we	O
construct	O
p	B-Method
gen	I-Method
by	O
applying	O
a	O
deterministic	B-Method
,	I-Method
differentiable	I-Method
transform	I-Method
g	I-Method
θ	I-Method
to	O
samples	O
z	O
from	O
a	O
fixed	O
distribution	O
p	O
z	O
,	O
we	O
can	O
write	O
the	O
gradient	B-Method
of	I-Method
H	I-Method
(	I-Method
p	I-Method
gen	I-Method
)	O
with	O
respect	O
to	O
the	O
generator	O
parameters	O
θ	O
as	O
follows	O
:	O
	
where	O
the	O
first	O
equality	O
relies	O
on	O
the	O
"	O
reparametrization	O
trick	O
"	O
.	O
	
Equation	O
9	O
implies	O
that	O
,	O
if	O
we	O
can	O
compute	O
the	O
gradient	O
of	O
the	O
generator	B-Method
log	I-Method
-	I-Method
density	I-Method
log	I-Method
p	I-Method
gen	O
	
(	O
x	O
)	O
w.r.t	O
.	O
	
any	O
x	O
=	O
g	O
θ	O
(	O
z	O
)	O
	
,	O
then	O
we	O
can	O
directly	O
construct	O
the	O
Monte	B-Method
-	I-Method
Carlo	I-Method
estimation	I-Method
of	I-Method
the	I-Method
entropy	I-Method
gradient	I-Method
∇	O
	
θ	B-Method
H	I-Method
(	I-Method
p	I-Method
gen	I-Method
)	O
using	O
samples	O
from	O
the	O
generator	B-Method
.	O
	
Intuitively	O
,	O
for	O
any	O
generated	O
data	O
x	O
=	O
g	O
θ	O
(	O
z	O
)	O
,	O
the	O
term	O
	
essentially	O
describes	O
the	O
direction	O
of	O
local	O
change	O
in	O
the	O
sample	O
space	O
that	O
will	O
increase	O
the	O
log	O
-	O
density	O
.	O
	
Motivated	O
by	O
this	O
intuition	O
,	O
we	O
propose	O
to	O
form	O
a	O
local	B-Method
Gaussian	I-Method
approximation	I-Method
	
p	O
	
i	O
gen	O
of	O
p	O
gen	O
around	O
each	O
point	O
	
x	O
i	O
in	O
a	O
batch	O
of	O
samples	O
{	O
x	O
1	O
,	O
...	O
,	O
x	O
n	O
}	O
from	O
the	O
generator	B-Method
,	O
and	O
then	O
compute	O
the	O
gradient	O
∂	O
log	O
pgen	O
(	O
xi	O
)	O
∂xi	O
based	O
on	O
the	O
Gaussian	B-Method
approximation	I-Method
.	O
	
Specifically	O
,	O
each	O
local	B-Method
Gaussian	I-Method
approximation	I-Method
p	O
i	O
gen	O
is	O
formed	O
by	O
finding	O
the	O
k	O
nearest	O
neighbors	O
of	O
x	O
i	O
in	O
the	O
batch	O
{	O
x	O
1	O
,	O
...	O
,	O
x	O
n	O
}	O
,	O
and	O
then	O
placing	O
an	O
isotropic	B-Method
Gaussian	I-Method
distribution	I-Method
at	O
their	O
mean	O
(	O
i.e.	O
maximimum	O
likelihood	O
)	O
.	O
	
Based	O
on	O
the	O
isotropic	B-Method
Gaussian	I-Method
approximation	I-Method
,	O
the	O
resulting	O
gradient	O
has	O
the	O
following	O
form	O
	
x	O
is	O
the	O
mean	O
of	O
the	O
Gaussian	O
(	O
10	O
)	O
	
Finally	O
,	O
note	O
the	O
scale	O
of	O
this	O
gradient	B-Method
approximation	I-Method
may	O
not	O
be	O
reliable	O
.	O
	
To	O
fix	O
this	O
problem	O
,	O
we	O
normalize	O
the	O
approximated	O
gradient	O
into	O
unit	O
norm	O
,	O
and	O
use	O
a	O
single	O
hyper	O
-	O
parameter	O
to	O
model	O
the	O
scale	O
for	O
all	O
x	O
,	O
leading	O
to	O
the	O
following	O
entropy	B-Method
gradient	I-Method
approximation	I-Method
	
where	O
α	O
is	O
the	O
hyper	O
-	O
parameter	O
and	O
µ	O
	
i	O
is	O
defined	O
as	O
in	O
equation	O
(	O
10	O
)	O
.	O
	
An	O
obvious	O
weakness	O
of	O
this	O
approximation	O
is	O
that	O
it	O
relies	O
on	O
Euclidean	O
distance	O
to	O
find	O
the	O
k	O
nearest	O
neighbors	O
.	O
	
However	O
,	O
Euclidean	O
distance	O
is	O
usually	O
not	O
the	O
proper	O
metric	O
to	O
use	O
when	O
the	O
effective	B-Metric
dimension	I-Metric
is	O
very	O
high	O
.	O
	
As	O
the	O
problem	O
is	O
highly	O
challenging	O
,	O
we	O
leave	O
it	O
for	O
future	O
work	O
.	O
	
section	O
:	O
VARIATIONAL	B-Metric
LOWER	I-Metric
BOUND	I-Metric
ON	O
THE	O
ENTROPY	O
	
Another	O
approach	O
we	O
consider	O
relies	O
on	O
defining	O
and	O
maximizing	O
a	O
variational	B-Metric
lower	I-Metric
bound	I-Metric
on	O
the	O
entropy	B-Metric
H	I-Metric
(	I-Metric
p	I-Metric
gen	I-Metric
(	O
x	O
)	O
)	O
of	O
the	O
generator	B-Method
distribution	I-Method
.	O
	
We	O
can	O
define	O
the	O
joint	O
distribution	O
over	O
observed	O
data	O
and	O
the	O
noise	O
variables	O
as	O
	
is	O
a	O
fixed	O
prior	O
.	O
	
Using	O
the	O
joint	O
,	O
we	O
can	O
also	O
define	O
the	O
marginal	O
p	O
gen	O
(	O
x	O
)	O
and	O
the	O
posterior	O
p	O
gen	O
(	O
z	O
|	O
x	O
)	O
.	O
	
We	O
can	O
also	O
write	O
the	O
mutual	O
information	O
between	O
the	O
observed	O
data	O
and	O
noise	O
variables	O
as	O
:	O
	
where	O
H	O
(	O
p	O
gen	O
(	O
.	O
	
|	O
.	O
)	O
)	O
denotes	O
the	O
conditional	O
entropy	O
.	O
	
By	O
reorganizing	O
terms	O
in	O
this	O
definition	O
,	O
we	O
can	O
write	O
the	O
entropy	O
H	O
(	O
p	O
gen	O
(	O
x	O
)	O
)	O
as	O
:	O
	
We	O
can	O
think	O
of	O
p	O
gen	O
(	O
x	O
|	O
z	O
)	O
as	O
a	O
peaked	B-Method
Gaussian	I-Method
with	O
a	O
fixed	O
,	O
diagonal	O
covariance	O
,	O
and	O
hence	O
its	O
conditional	B-Metric
entropy	I-Metric
is	O
constant	O
and	O
can	O
be	O
dropped	O
.	O
	
Furthermore	O
,	O
H	O
(	O
p	O
gen	O
(	O
z	O
)	O
)	O
is	O
also	O
assumed	O
to	O
be	O
fixed	O
a	O
priori	O
.	O
	
Hence	O
,	O
we	O
can	O
maximize	O
H	O
(	O
p	O
gen	O
(	O
x	O
)	O
)	O
by	O
minimizing	O
the	O
conditional	B-Metric
entropy	I-Metric
:	O
	
Optimizing	O
this	O
term	O
is	O
still	O
problematic	O
,	O
because	O
(	O
i	O
)	O
we	O
do	O
not	O
have	O
access	O
to	O
the	O
posterior	O
p	O
gen	O
(	O
z	O
|	O
x	O
)	O
,	O
and	O
(	O
ii	O
)	O
we	O
can	O
not	O
sample	O
from	O
it	O
.	O
	
Therefore	O
,	O
we	O
instead	O
minimize	O
a	O
variational	B-Method
upper	I-Method
bound	I-Method
defined	O
by	O
an	O
approximate	B-Method
posterior	I-Method
q	I-Method
gen	I-Method
(	O
z	O
|	O
x	O
)	O
:	O
	
We	O
can	O
also	O
rewrite	O
the	O
variational	O
upper	O
bound	O
as	O
:	O
	
which	O
can	O
be	O
optimized	O
efficiently	O
with	O
standard	O
back	B-Method
-	I-Method
propagation	I-Method
and	O
Monte	B-Method
Carlo	I-Method
integration	I-Method
of	O
the	O
relevant	O
expectations	O
based	O
on	O
independent	O
samples	O
drawn	O
from	O
the	O
joint	O
p	O
gen	O
(	O
x	O
,	O
z	O
)	O
.	O
	
By	O
minimizing	O
this	O
upper	O
bound	O
on	O
the	O
conditional	O
entropy	O
H	O
(	O
p	O
gen	O
(	O
z	O
|	O
x	O
)	O
)	O
,	O
we	O
are	O
effectively	O
maximizing	O
a	O
variational	B-Metric
lower	I-Metric
bound	I-Metric
on	O
the	O
entropy	O
H	O
(	O
p	O
gen	O
(	O
x	O
)	O
)	O
.	O
	
section	O
:	O
EXPERIMENTS	O
	
In	O
this	O
section	O
,	O
we	O
verify	O
our	O
theoretical	O
results	O
empirically	O
on	O
several	O
synthetic	O
and	O
real	O
datasets	O
.	O
	
In	O
particular	O
,	O
we	O
evaluate	O
whether	O
the	O
discriminator	B-Method
obtained	O
from	O
the	O
entropy	B-Method
-	I-Method
regularized	I-Method
adversarial	I-Method
training	I-Method
can	O
capture	O
the	O
density	O
information	O
(	O
in	O
the	O
form	O
of	O
energy	O
)	O
,	O
while	O
making	O
sure	O
the	O
generator	O
distribution	O
matches	O
the	O
data	O
distribution	O
.	O
	
For	O
convenience	O
,	O
we	O
refer	O
to	O
the	O
obtained	O
models	O
as	O
EGAN	O
-	O
Ent	O
.	O
	
Our	O
experimental	O
setting	O
follows	O
closely	O
recommendations	O
from	O
[	O
reference	O
]	O
,	O
except	O
in	O
Sec	O
.	O
	
5.1	O
where	O
we	O
use	O
fully	B-Method
-	I-Method
connected	I-Method
models	I-Method
(	O
see	O
appendix	O
B.1	O
for	O
details	O
)	O
.	O
	
Gaussians	B-Method
arranged	O
as	O
two	O
spirals	O
(	O
100	O
components	O
each	O
spiral	O
)	O
,	O
and	O
(	O
iii	O
)	O
Mixture	B-Method
of	I-Method
2	I-Method
Gaussians	I-Method
with	O
highly	O
biased	O
mixture	O
weights	O
,	O
P	O
(	O
c	O
1	O
)	O
=	O
0.9	O
,	O
P	O
(	O
c	O
2	O
)	O
=	O
0.1	O
.	O
	
We	O
visualize	O
the	O
ground	O
-	O
truth	O
energy	O
of	O
these	O
distributions	O
along	O
with	O
100	O
K	O
training	O
samples	O
in	O
Figure	O
1	O
.	O
	
Since	O
the	O
data	O
lies	O
in	O
2	O
-	O
dimensional	O
space	O
,	O
we	O
can	O
easily	O
visualize	O
both	O
the	O
learned	B-Method
generator	I-Method
(	O
by	O
drawing	O
samples	O
)	O
and	O
the	O
discriminator	B-Method
for	O
direct	O
comparison	O
and	O
evaluation	B-Task
.	O
	
We	O
evaluate	O
here	O
our	O
EGAN	B-Method
-	I-Method
Ent	I-Method
model	I-Method
using	O
both	O
approximations	O
:	O
the	O
nearest	B-Method
-	I-Method
neighbor	I-Method
based	I-Method
approximation	I-Method
(	O
EGAN	B-Method
-	I-Method
Ent	I-Method
-	I-Method
NN	I-Method
)	O
and	O
the	O
variational	B-Method
-	I-Method
inference	I-Method
based	I-Method
approximation	I-Method
(	O
EGAN	B-Method
-	I-Method
Ent	I-Method
-	I-Method
VI	I-Method
)	O
,	O
and	O
compare	O
them	O
with	O
two	O
baselines	O
:	O
the	O
original	O
GAN	B-Method
and	O
the	O
energy	O
based	O
GAN	B-Method
with	O
no	B-Method
regularization	I-Method
(	O
EGAN	B-Method
-	I-Method
Const	I-Method
)	O
.	O
	
Experiment	O
results	O
are	O
summarized	O
in	O
Figure	O
2	O
for	O
baseline	O
models	O
,	O
and	O
Figure	O
3	O
for	O
the	O
proposed	O
models	O
.	O
	
As	O
we	O
can	O
see	O
,	O
all	O
four	O
models	O
can	O
generate	O
perfect	O
samples	O
.	O
	
However	O
,	O
for	O
the	O
discriminator	B-Method
,	O
both	O
GAN	B-Method
and	O
EGAN	O
-	O
Const	O
lead	O
to	O
degenerate	O
solution	O
,	O
assigning	O
flat	O
energy	O
inside	O
the	O
empirical	O
data	O
support	O
.	O
	
In	O
comparison	O
,	O
EGAN	B-Method
-	I-Method
Ent	I-Method
-	I-Method
VI	I-Method
and	O
EGAN	B-Method
-	I-Method
Ent	I-Method
-	I-Method
NN	I-Method
clearly	O
capture	O
the	O
density	O
information	O
,	O
though	O
to	O
different	O
degrees	O
.	O
	
Specifically	O
,	O
on	O
the	O
equally	B-Method
weighted	I-Method
Gaussian	I-Method
mixture	I-Method
and	O
the	O
two	O
-	O
spiral	O
mixture	O
datasets	O
,	O
EGAN	B-Method
-	I-Method
Ent	I-Method
-	I-Method
NN	I-Method
tends	O
to	O
give	O
more	O
accurate	O
and	O
fine	O
-	O
grained	O
solutions	O
compared	O
to	O
EGAN	B-Method
-	I-Method
Ent	I-Method
-	I-Method
VI	I-Method
.	O
	
However	O
,	O
on	O
the	O
biased	O
weighted	O
Gaussian	O
mixture	O
dataset	O
,	O
EGAN	B-Method
-	I-Method
Ent	I-Method
-	I-Method
VI	I-Method
actually	O
fails	O
to	O
captures	O
the	O
correct	O
mixture	O
weights	O
of	O
the	O
two	O
modes	O
,	O
incorrectly	O
assigning	O
lower	O
energy	O
to	O
the	O
mode	O
with	O
lower	O
probability	O
(	O
smaller	O
weight	O
)	O
.	O
	
In	O
contrast	O
,	O
EGANEnt	B-Method
-	I-Method
NN	I-Method
perfectly	O
captures	O
the	O
bias	O
in	O
mixture	O
weight	O
,	O
and	O
obtains	O
a	O
contour	O
very	O
close	O
to	O
the	O
ground	O
truth	O
.	O
	
To	O
better	O
quantify	O
these	O
differences	O
,	O
we	O
present	O
detailed	O
comparison	O
based	O
on	O
KL	O
divergence	O
in	O
appendix	O
B.2	O
.	O
	
What	O
's	O
more	O
,	O
the	O
performance	O
difference	O
between	O
EGAN	B-Method
-	I-Method
Ent	I-Method
-	I-Method
VI	I-Method
and	O
EGAN	B-Method
-	I-Method
Ent	I-Method
-	I-Method
NN	I-Method
on	O
biased	B-Method
Gaussian	I-Method
mixture	I-Method
reveals	O
the	O
limitations	O
of	O
the	O
variational	B-Method
inference	I-Method
based	I-Method
approximation	I-Method
,	O
i.e.	O
providing	O
inaccurate	O
gradients	O
.	O
	
Due	O
to	O
space	O
consideratiosn	O
,	O
we	O
refer	O
interested	O
readers	O
to	O
the	O
appendix	O
B.3	O
for	O
a	O
detailed	O
discussion	O
.	O
	
section	O
:	O
RANKING	B-Task
NIST	I-Task
DIGITS	I-Task
	
In	O
this	O
experiment	O
,	O
we	O
verify	O
that	O
the	O
results	O
in	O
synthetic	O
datasets	O
can	O
translate	O
into	O
data	O
with	O
higher	O
dimensions	O
.	O
	
While	O
visualizing	O
the	O
learned	O
energy	O
function	O
is	O
not	O
feasible	O
in	O
high	O
-	O
dimensional	O
space	O
,	O
we	O
can	O
verify	O
whether	O
the	O
learned	O
energy	O
function	O
learns	O
relative	O
densities	O
by	O
inspecting	O
the	O
ranking	O
of	O
samples	O
according	O
to	O
their	O
assigned	O
energies	O
.	O
	
We	O
train	O
on	O
28	O
×	O
28	O
images	O
of	O
a	O
single	O
handwritten	O
Figure	O
2	O
:	O
Learned	O
energies	O
and	O
samples	O
from	O
baseline	B-Method
models	I-Method
whose	O
discriminator	B-Method
can	O
not	O
retain	O
density	O
information	O
at	O
the	O
optimal	O
.	O
	
In	O
the	O
sample	O
plots	O
,	O
blue	O
dots	O
indicate	O
generated	O
samples	O
,	O
and	O
red	O
dots	O
indicate	O
real	O
ones	O
.	O
	
section	O
:	O
(	O
a	O
)	O
Entropy	O
regularized	O
Energy	O
GAN	B-Method
with	O
variational	B-Method
inference	I-Method
approximation	I-Method
(	O
EGAN	B-Method
-	I-Method
Ent	I-Method
-	I-Method
VI	I-Method
)	O
(	O
b	O
)	O
Entropy	O
regularized	O
Energy	O
GAN	B-Method
with	O
nearest	B-Method
neighbor	I-Method
approximation	I-Method
(	O
EGAN	B-Method
-	I-Method
Ent	I-Method
-	I-Method
NN	I-Method
)	O
	
Figure	O
3	O
:	O
Learned	O
energies	O
and	O
samples	O
from	O
proposed	O
models	O
whose	O
discriminator	B-Method
can	O
retain	O
density	O
information	O
at	O
the	O
optimal	O
.	O
	
Blue	O
dots	O
are	O
generated	O
samples	O
,	O
and	O
red	O
dots	O
are	O
real	O
ones	O
.	O
	
digit	O
from	O
the	O
NIST	O
dataset	O
.	O
	
[	O
reference	O
]	O
	
We	O
compare	O
the	O
ability	O
of	O
EGAN	B-Method
-	I-Method
Ent	I-Method
-	I-Method
NN	I-Method
with	O
both	O
EGAN	B-Method
-	I-Method
Const	I-Method
and	O
GAN	B-Method
on	O
ranking	B-Task
a	O
set	O
of	O
1	O
,	O
000	O
images	O
,	O
half	O
of	O
which	O
are	O
generated	O
samples	O
and	O
the	O
rest	O
are	O
real	O
test	O
images	O
.	O
	
Figures	O
4	O
and	O
5	O
show	O
the	O
top	O
-	O
100	O
and	O
bottom	O
-	O
100	O
ranked	O
images	O
respectively	O
for	O
each	O
model	O
,	O
after	O
training	O
them	O
on	O
digit	O
1	O
.	O
	
We	O
also	O
show	O
in	O
Figure	O
7	O
the	O
mean	O
of	O
all	O
training	O
samples	O
,	O
so	O
we	O
can	O
get	O
a	O
sense	O
of	O
what	O
is	O
the	O
most	O
common	O
style	O
(	O
highest	O
density	O
)	O
of	O
digit	O
1	O
in	O
NIST	O
.	O
	
We	O
can	O
notice	O
that	O
all	O
of	O
the	O
top	O
-	O
ranked	O
images	O
by	O
EGAN	B-Method
-	I-Method
Ent	I-Method
-	I-Method
NN	I-Method
look	O
similar	O
to	O
the	O
mean	O
sample	O
.	O
	
In	O
addition	O
,	O
the	O
lowest	O
-	O
ranked	O
images	O
are	O
clearly	O
different	O
from	O
the	O
mean	O
image	O
,	O
with	O
either	O
high	O
(	O
clockwise	O
or	O
counter	O
-	O
clockwise	O
)	O
rotation	O
degrees	O
from	O
the	O
mean	O
,	O
or	O
an	O
extreme	O
thickness	O
level	O
.	O
	
We	O
do	O
not	O
see	O
such	O
clear	O
distinction	O
in	O
other	O
models	O
.	O
	
We	O
provide	O
in	O
the	O
appendix	O
B.4	O
the	O
ranking	B-Task
of	O
the	O
full	O
set	O
of	O
images	O
.	O
	
section	O
:	O
SAMPLE	B-Metric
QUALITY	I-Metric
ON	O
NATURAL	O
IMAGE	O
DATASETS	O
	
In	O
this	O
last	O
set	O
of	O
experiments	O
,	O
we	O
evaluate	O
the	O
visual	B-Metric
quality	I-Metric
of	I-Metric
samples	I-Metric
generated	O
by	O
our	O
model	O
in	O
two	O
datasets	O
of	O
natural	O
images	O
,	O
namely	O
CIFAR	B-Material
-	I-Material
10	I-Material
	
and	O
CelebA.	O
	
We	O
employ	O
here	O
the	O
variationalbased	B-Method
approximation	I-Method
for	O
entropy	B-Task
regularization	I-Task
,	O
which	O
can	O
scale	O
well	O
to	O
high	O
-	O
dimensional	O
data	O
.	O
	
Figure	O
6	O
shows	O
samples	O
generated	O
by	O
EGAN	B-Method
-	I-Method
Ent	I-Method
-	I-Method
VI	I-Method
.	O
	
We	O
can	O
see	O
that	O
despite	O
the	O
noisy	O
gradients	O
provided	O
by	O
the	O
variational	B-Method
approximation	I-Method
,	O
our	O
model	O
is	O
able	O
to	O
generate	O
high	O
-	O
quality	O
samples	O
.	O
	
We	O
futher	O
validate	O
the	O
quality	O
of	O
our	O
model	O
's	O
samples	O
on	O
CIFAR	B-Material
-	I-Material
10	I-Material
using	O
the	O
Inception	B-Metric
score	I-Metric
proposed	O
by	O
[	O
reference	O
]	O
3	O
.	O
	
Table	O
1	O
shows	O
the	O
scores	O
of	O
our	O
EGAN	B-Method
-	I-Method
Ent	I-Method
-	I-Method
VI	I-Method
,	O
the	O
best	O
GAN	B-Method
model	O
from	O
[	O
reference	O
]	O
which	O
uses	O
only	O
unlabeled	O
data	O
,	O
and	O
an	O
EGAN	B-Method
-	I-Method
Const	I-Method
model	I-Method
which	O
has	O
the	O
same	O
architecture	O
as	O
our	O
model	O
.	O
	
We	O
notice	O
that	O
even	O
without	O
employing	O
suggested	O
techniques	O
in	O
[	O
reference	O
]	O
,	O
energy	B-Method
-	I-Method
based	I-Method
models	I-Method
perform	O
quite	O
similarly	O
to	O
the	O
GAN	B-Method
model	O
.	O
	
Furthermore	O
,	O
the	O
fact	O
that	O
our	O
model	O
scores	O
higher	O
than	O
EGAN	B-Method
-	I-Method
Const	I-Method
highlights	O
the	O
importance	O
of	O
entropy	B-Method
regularization	I-Method
in	O
obtaining	O
good	O
quality	O
samples	O
.	O
	
section	O
:	O
CONCLUSION	O
	
In	O
this	O
paper	O
we	O
have	O
addressed	O
a	O
fundamental	O
limitation	O
in	O
adversarial	B-Method
learning	I-Method
approaches	I-Method
,	O
which	O
is	O
their	O
inability	O
of	O
providing	O
sensible	O
energy	O
estimates	O
for	O
samples	O
.	O
	
We	O
proposed	O
a	O
novel	O
adversarial	B-Method
learning	I-Method
formulation	I-Method
which	O
results	O
in	O
a	O
discriminator	B-Method
function	I-Method
that	O
recovers	O
the	O
true	O
data	O
energy	O
.	O
	
We	O
provided	O
a	O
rigorous	O
characterization	O
of	O
the	O
learned	B-Method
discriminator	I-Method
in	O
the	O
non	B-Task
-	I-Task
parametric	I-Task
setting	I-Task
,	O
and	O
proposed	O
two	O
methods	O
for	O
instantiating	O
it	O
in	O
the	O
typical	O
parametric	B-Task
setting	I-Task
.	O
	
Our	O
experimental	O
results	O
verify	O
our	O
theoretical	O
analysis	O
about	O
the	O
discriminator	O
properties	O
,	O
and	O
show	O
that	O
we	O
can	O
also	O
obtain	O
samples	O
of	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
quality	O
.	O
	
Figure	O
6	O
:	O
	
Samples	O
generated	O
from	O
our	O
model	O
.	O
	
section	O
:	O
Model	O
Our	O
model	O
Improved	O
GAN	B-Method
†	O
EGAN	O
-	O
Const	O
	
Score	O
±	O
std	O
.	O
	
7.07	O
±	O
	
.10	O
6.86	O
±	O
	
.06	O
	
6.7447	O
±	O
0.09	O
Table	O
1	O
:	O
Inception	B-Metric
scores	I-Metric
on	O
CIFAR	B-Material
-	I-Material
10	I-Material
.	O
	
†	O
As	O
reported	O
in	O
Salimans	O
et	O
al	O
.	O
	
(	O
2016	O
)	O
without	O
using	O
labeled	O
data	O
.	O
	
(	O
17	O
)	O
where	O
c	O
(	O
x	O
)	O
∈	O
R	O
,	O
∀x	O
,	O
µ	O
(	O
x	O
)	O
∈	O
R	O
+	O
,	O
∀x	O
,	O
and	O
λ	O
∈	O
R	O
are	O
the	O
dual	O
variables	O
.	O
	
The	O
KKT	O
conditions	O
for	O
the	O
optimal	O
primal	O
and	O
dual	O
variables	O
are	O
as	O
follows	O
	
Rearranging	O
the	O
conditions	O
above	O
,	O
we	O
get	O
p	O
*	O
gen	O
(	O
x	O
)	O
	
=	O
	
p	O
data	O
(	O
x	O
)	O
,	O
∀x	O
∈	O
X	O
as	O
well	O
as	O
equation	O
(	O
4	O
)	O
,	O
which	O
concludes	O
the	O
proof	O
.	O
	
section	O
:	O
A.2	O
OPTIMAL	O
CONDITIONS	O
OF	O
EBGAN	B-Method
	
In	O
[	O
reference	O
]	O
,	O
the	O
training	O
objectives	O
of	O
the	O
generator	B-Method
and	O
the	O
discriminator	B-Method
can	O
not	O
be	O
written	O
as	O
a	O
single	O
minimax	B-Task
optimization	I-Task
problem	I-Task
since	O
the	O
margin	O
structure	O
is	O
only	O
applied	O
to	O
the	O
objective	O
of	O
the	O
discriminator	O
.	O
	
In	O
addition	O
,	O
the	O
discriminator	B-Method
is	O
designed	O
to	O
produce	O
the	O
mean	B-Metric
squared	I-Metric
reconstruction	I-Metric
error	I-Metric
of	O
an	O
auto	B-Method
-	I-Method
encoder	I-Method
structure	I-Method
.	O
	
This	O
restricted	O
the	O
range	O
of	O
the	O
discriminator	O
output	O
to	O
be	O
non	O
-	O
negative	O
,	O
which	O
is	O
equivalent	O
to	O
posing	O
a	O
set	O
constraint	O
on	O
the	O
discriminator	O
under	O
the	O
non	O
-	O
parametric	O
setting	O
.	O
	
Thus	O
,	O
to	O
characterize	O
the	O
optimal	B-Method
generator	I-Method
and	I-Method
discriminator	I-Method
,	O
we	O
adapt	O
the	O
same	O
analyzing	O
logic	O
used	O
in	O
the	O
proof	O
sketch	O
of	O
the	O
original	O
GAN	B-Method
[	O
reference	O
]	O
.	O
Specifically	O
,	O
given	O
a	O
specific	O
generator	B-Method
distribution	I-Method
p	O
gen	O
,	O
the	O
optimal	O
discriminator	B-Method
function	I-Method
given	O
the	O
generator	B-Method
distribution	I-Method
c	O
	
*	O
(	O
x	O
;	O
p	O
gen	O
)	O
can	O
be	O
derived	O
by	O
examining	O
the	O
objective	O
of	O
the	O
discriminator	O
.	O
	
Then	O
,	O
the	O
conditional	B-Method
optimal	I-Method
discriminator	I-Method
function	I-Method
is	O
substituted	O
into	O
the	O
training	B-Metric
objective	I-Metric
of	O
p	B-Method
gen	I-Method
,	O
simplifying	O
the	O
"	O
adversarial	B-Task
"	I-Task
training	I-Task
as	O
a	O
minimizing	B-Task
problem	I-Task
only	O
w.r.t	O
.	O
	
p	O
gen	O
,	O
which	O
can	O
be	O
well	O
analyzed	O
.	O
	
Firstly	O
,	O
given	O
any	O
generator	B-Method
distribution	I-Method
p	I-Method
gen	I-Method
,	O
the	O
EBGAN	B-Metric
training	I-Metric
objective	I-Metric
for	O
the	O
discriminator	B-Method
can	O
be	O
written	O
as	O
the	O
following	O
form	O
	
where	O
C	O
=	O
{	O
c	O
:	O
c	O
(	O
x	O
)	O
≥	O
0	O
,	O
∀x	O
∈	O
X	O
}	O
is	O
the	O
set	O
of	O
allowed	O
non	O
-	O
negative	O
discriminator	O
functions	O
.	O
	
Note	O
this	O
set	O
constraint	O
comes	O
from	O
the	O
fact	O
the	O
mean	B-Metric
squared	I-Metric
reconstruction	I-Metric
error	I-Metric
as	O
discussed	O
above	O
.	O
	
Since	O
the	O
problem	O
(	O
19	O
)	O
is	O
independent	O
w.r.t	O
.	O
	
each	O
x	O
,	O
the	O
optimal	O
solution	O
can	O
be	O
easily	O
derived	O
as	O
	
where	O
α	O
x	O
∈	O
[	O
0	O
,	O
m	O
]	O
is	O
an	O
under	O
-	O
determined	O
number	O
,	O
	
a	O
β	O
x	O
∈	O
[	O
0	O
,	O
∞	O
)	O
is	O
another	O
under	O
-	O
determined	O
nonnegative	O
real	O
number	O
,	O
and	O
the	O
subscripts	O
in	O
m	O
,	O
α	O
x	O
	
,	O
β	O
x	O
reflect	O
that	O
fact	O
that	O
these	O
under	O
-	O
determined	O
values	O
can	O
be	O
distinct	O
for	O
different	O
x.	O
	
This	O
way	O
,	O
the	O
overall	O
training	B-Metric
objective	I-Metric
can	O
be	O
cast	O
into	O
a	O
minimization	B-Task
problem	I-Task
w.r.t	O
.	O
p	O
gen	O
,	O
	
where	O
the	O
second	O
term	O
of	O
the	O
first	O
line	O
is	O
implicitly	O
defined	O
as	O
the	O
problem	O
is	O
an	O
adversarial	B-Method
game	I-Method
between	O
p	O
gen	O
and	O
c.	O
Proposition	O
A.1	O
.	O
	
The	O
global	O
optimal	O
of	O
the	O
EBGAN	B-Task
training	I-Task
objective	I-Task
is	O
achieved	O
if	O
and	O
only	O
if	O
p	O
gen	O
=	O
p	O
data	O
.	O
	
At	O
that	O
point	O
,	O
c	O
*	O
(	O
x	O
)	O
is	O
fully	O
under	O
-	O
determined	O
.	O
	
Proof	O
.	O
	
The	O
proof	O
is	O
established	O
by	O
showing	O
contradiction	O
.	O
	
Firstly	O
,	O
assume	O
the	O
optimal	O
p	O
*	O
gen	O
=	O
p	O
data	O
.	O
	
Thus	O
,	O
there	O
must	O
exist	O
a	O
non	O
-	O
equal	O
set	O
X	O
	
=	O
=	O
{	O
x	O
|	O
p	O
data	O
(	O
x	O
)	O
	
=	O
	
p	O
*	O
gen	O
(	O
x	O
)	O
}	O
,	O
which	O
can	O
be	O
further	O
splitted	O
into	O
two	O
subsets	O
,	O
the	O
greater	O
-	O
than	O
set	O
X	O
>	O
=	O
	
{	O
	
x	O
|	O
p	O
*	O
gen	O
(	O
x	O
)	O
>	O
	
p	O
data	O
(	O
x	O
)	O
}	O
,	O
and	O
	
the	O
less	O
-	O
than	O
set	O
X	O
<	O
=	O
	
{	O
x	O
|	O
p	O
*	O
gen	O
(	O
x	O
)	O
<	O
p	O
data	O
(	O
x	O
)	O
}.	O
Similarly	O
,	O
we	O
define	O
the	O
equal	O
set	O
	
,	O
substituting	O
the	O
results	O
from	O
equation	O
(	O
20	O
)	O
into	O
(	O
21	O
)	O
,	O
the	O
L	O
(	O
p	O
gen	O
)	O
*	O
can	O
be	O
written	O
as	O
	
However	O
,	O
when	O
p	O
gen	O
=	O
p	O
data	O
,	O
we	O
have	O
	
which	O
contradicts	O
the	O
optimal	O
(	O
miminum	O
)	O
assumption	O
of	O
p	O
*	O
gen	O
.	O
	
Hence	O
,	O
the	O
contradiction	O
concludes	O
that	O
at	O
the	O
global	O
optimal	O
,	O
p	O
*	O
gen	O
=	O
p	O
data	O
.	O
	
By	O
equation	O
(	O
20	O
)	O
,	O
it	O
directly	O
follows	O
that	O
c	O
*	O
(	O
x	O
;	O
	
p	O
*	O
gen	O
)	O
=	O
	
α	O
x	O
,	O
which	O
completes	O
the	O
proof	O
.	O
	
section	O
:	O
A.3	O
ANALYSIS	O
OF	O
ADDING	B-Task
ADDITIONAL	I-Task
TRAINING	I-Task
SIGNAL	I-Task
TO	O
GAN	B-Method
FORMULATION	O
	
To	O
show	O
that	O
simply	O
adding	O
the	O
same	O
training	O
signal	O
to	O
GAN	B-Method
will	O
not	O
lead	O
to	O
the	O
same	O
result	O
,	O
it	O
is	O
more	O
convenient	O
to	O
directly	O
work	O
with	O
the	O
formulation	O
of	O
f	O
-	O
GAN	B-Method
[	O
reference	O
]	O
)	O
	
family	O
,	O
which	O
include	O
the	O
original	O
GAN	B-Method
formulation	O
as	O
a	O
special	O
case	O
.	O
	
Specifically	O
,	O
the	O
general	O
f	O
-	O
GAN	B-Method
formulation	O
takes	O
the	O
following	O
form	O
	
where	O
the	O
f	O
(	O
·	O
)	O
denotes	O
the	O
convex	O
conjugate	O
[	O
reference	O
]	O
of	O
the	O
f	O
-	O
divergence	O
function	O
.	O
	
The	O
optimal	O
condition	O
of	O
the	O
discriminator	O
can	O
be	O
found	O
by	O
taking	O
the	O
variation	O
w.r.t	O
.	O
	
c	O
,	O
which	O
gives	O
the	O
optimal	O
discriminator	O
	
where	O
f	O
(	O
·	O
)	O
is	O
the	O
first	O
-	O
order	O
derivative	O
of	O
f	O
(	O
·	O
)	O
.	O
	
Note	O
that	O
,	O
even	O
when	O
we	O
add	O
an	O
extra	O
term	O
L	O
(	O
p	O
gen	O
)	O
to	O
equation	O
(	O
24	O
)	O
,	O
since	O
the	O
term	O
K	O
(	O
p	O
gen	O
)	O
is	O
a	O
constant	O
w.r.t	O
.	O
	
the	O
discriminator	B-Method
,	O
it	O
does	O
not	O
change	O
the	O
result	O
given	O
by	O
equation	O
(	O
25	O
)	O
about	O
the	O
optimal	B-Method
discriminator	I-Method
.	O
	
As	O
a	O
consequence	O
,	O
for	O
the	O
optimal	O
discriminator	B-Method
to	O
retain	O
the	O
density	O
information	O
,	O
it	O
effectively	O
means	O
p	O
gen	O
=	O
p	O
data	O
.	O
	
Hence	O
,	O
there	O
will	O
be	O
a	O
contradiction	O
if	O
both	O
c	O
	
*	O
(	O
x	O
)	O
retains	O
the	O
density	O
information	O
,	O
and	O
the	O
generator	B-Method
matches	O
the	O
data	O
distribution	O
.	O
	
Intuitively	O
,	O
this	O
problem	O
roots	O
in	O
the	O
fact	O
that	O
f	B-Method
-	I-Method
divergence	I-Method
is	O
quite	O
"	O
rigid	O
"	O
in	O
the	O
sense	O
that	O
given	O
the	O
p	O
gen	O
(	O
x	O
)	O
it	O
only	O
allows	O
one	O
fixed	O
point	O
for	O
the	O
discriminator	B-Method
.	O
	
In	O
comparison	O
,	O
the	O
divergence	O
used	O
in	O
our	O
proposed	O
formulation	O
,	O
which	O
is	O
the	O
expected	O
cost	O
gap	O
,	O
is	O
much	O
more	O
flexible	O
.	O
	
By	O
the	O
expected	B-Metric
cost	I-Metric
gap	I-Metric
itself	O
,	O
i.e.	O
without	O
the	O
K	O
(	O
p	O
gen	O
)	O
term	O
,	O
the	O
optimal	O
discriminator	B-Method
is	O
actually	O
under	O
-	O
determined	O
.	O
	
section	O
:	O
B	O
SUPPLEMENTARY	O
MATERIALS	O
FOR	O
SECTION	O
5	O
B.1	O
EXPERIMENT	O
SETTING	O
	
Here	O
,	O
we	O
specify	O
the	O
neural	B-Method
architectures	I-Method
used	O
for	O
experiements	O
presented	O
in	O
Section	O
5	O
.	O
	
Firstly	O
,	O
for	O
the	O
Egan	B-Method
-	I-Method
Ent	I-Method
-	I-Method
VI	I-Method
model	I-Method
,	O
we	O
parameterize	O
the	O
approximate	B-Method
posterior	I-Method
distribution	I-Method
q	I-Method
gen	I-Method
(	O
z	O
|	O
x	O
)	O
with	O
a	O
diagonal	B-Method
Gaussian	I-Method
distribution	I-Method
,	O
whose	O
mean	O
and	O
covariance	O
matrix	O
are	O
the	O
output	O
of	O
a	O
trainable	B-Method
inference	I-Method
network	I-Method
,	O
i.e.	O
	
where	O
f	O
infer	O
denotes	O
the	O
inference	B-Method
network	I-Method
,	O
and	O
I	O
is	O
the	O
identity	O
matrix	O
.	O
	
Note	O
that	O
the	O
Inference	B-Method
Network	I-Method
only	O
appears	O
in	O
the	O
Egan	B-Method
-	I-Method
Ent	I-Method
-	I-Method
VI	I-Method
model	I-Method
.	O
	
For	O
experiments	O
with	O
the	O
synthetic	O
datasets	O
,	O
the	O
following	O
fully	B-Method
-	I-Method
connected	I-Method
feed	I-Method
forward	I-Method
neural	I-Method
networks	I-Method
are	O
employed	O
where	O
FC	B-Method
and	O
BN	B-Method
denote	O
fully	B-Method
-	I-Method
connected	I-Method
layer	I-Method
and	O
batch	B-Method
normalization	I-Method
layer	I-Method
respectively	O
.	O
	
Note	O
that	O
since	O
the	O
input	O
noise	O
to	O
the	O
generator	B-Method
has	O
dimension	O
4	O
,	O
the	O
Inference	O
Net	O
output	O
has	O
dimension	O
4	O
*	O
2	O
,	O
where	O
the	O
first	O
4	O
elements	O
correspond	O
the	O
inferred	O
mean	O
,	O
and	O
the	O
last	O
4	O
elements	O
correspond	O
to	O
the	O
inferred	O
diagonal	O
covariance	O
matrix	O
in	O
log	O
scale	O
.	O
	
For	O
the	O
handwritten	B-Task
digit	I-Task
experiment	I-Task
,	O
we	O
closely	O
follow	O
the	O
DCGAN	B-Method
[	O
reference	O
]	O
architecture	O
with	O
the	O
following	O
configuration	O
Here	O
,	O
LRec	B-Method
is	O
the	O
leaky	O
rectified	O
non	O
-	O
linearity	O
recommended	O
by	O
	
[	O
reference	O
]	O
.	O
In	O
addition	O
,	O
CV	B-Method
(	I-Method
128	I-Method
,	I-Method
256	I-Method
,	I-Method
4c2s	I-Method
)	I-Method
denotes	O
a	O
convolutional	B-Method
layer	I-Method
with	O
128	O
input	O
channels	O
,	O
256	O
output	O
channels	O
,	O
and	O
kernel	O
size	O
4	O
with	O
stride	O
2	O
.	O
	
Similarly	O
,	O
DC	B-Method
(	I-Method
256	I-Method
,	I-Method
128	I-Method
,	I-Method
4c2s	I-Method
)	I-Method
denotes	O
a	O
corresponding	O
transposed	B-Method
convolutional	I-Method
operation	I-Method
.	O
	
Compared	O
to	O
the	O
original	O
DCGAN	B-Method
architecture	I-Method
,	O
the	O
discriminator	B-Method
under	O
our	O
formulation	O
does	O
not	O
have	O
the	O
last	O
sigmoid	B-Method
layer	I-Method
which	O
squashes	O
a	O
scalar	O
value	O
into	O
a	O
probability	O
in	O
[	O
reference	O
][	O
reference	O
]	O
.	O
	
For	O
celebA	B-Task
experiment	O
with	O
64	O
×	O
64	O
color	O
images	O
,	O
we	O
use	O
the	O
following	O
architecture	O
Given	O
the	O
chosen	O
architectures	O
,	O
we	O
follow	O
[	O
reference	O
]	O
and	O
use	O
Adam	B-Method
as	O
the	O
optimization	B-Method
algorithm	I-Method
.	O
	
For	O
more	O
detailed	O
hyper	O
-	O
parameters	O
,	O
please	O
refer	O
to	O
the	O
code	O
.	O
	
In	O
order	O
to	O
quantify	O
the	O
quality	O
of	O
recovered	O
distributions	O
,	O
we	O
compute	O
the	O
pairwise	B-Metric
KL	I-Metric
divergence	I-Metric
of	O
the	O
following	O
four	O
distributions	O
:	O
	
section	O
:	O
B.2	O
QUANTITATIVE	O
COMPARISON	O
OF	O
DIFFERENT	O
MODELS	O
	
•	O
	
The	O
real	O
data	O
distribution	O
with	O
analytic	O
form	O
,	O
denoted	O
as	O
p	O
data	O
	
•	O
	
The	O
empirical	O
data	O
distribution	O
approximated	O
from	O
the	O
100	O
K	O
training	O
data	O
,	O
denoted	O
as	O
p	O
emp	O
	
•	O
	
The	O
generator	B-Method
distribution	I-Method
approximated	O
from	O
100	O
K	O
generated	O
data	O
,	O
denoted	O
as	O
p	O
gen	O
	
•	O
	
The	O
discriminator	O
distribution	O
re	O
-	O
normalized	O
from	O
the	O
learned	O
energy	O
,	O
denoted	O
as	O
p	O
disc	O
	
Since	O
the	O
synthetic	O
datasets	O
are	O
two	O
dimensional	O
,	O
we	O
approximate	O
both	O
the	O
empirical	B-Method
data	I-Method
distribution	I-Method
and	O
the	O
generator	B-Method
distribution	I-Method
using	O
the	O
simple	O
histogram	B-Method
estimation	I-Method
.	O
	
Specifically	O
,	O
we	O
divide	O
the	O
canvas	O
into	O
a	O
100	O
-	O
by	O
-	O
100	O
grid	O
,	O
and	O
assign	O
each	O
sample	O
into	O
its	O
nearest	O
grid	O
cell	O
based	O
on	O
euclidean	O
distance	O
.	O
	
Then	O
,	O
we	O
normalize	O
the	O
number	O
of	O
samples	O
in	O
each	O
cell	O
into	O
a	O
proper	O
distribution	O
.	O
	
When	O
recovering	O
the	O
discriminator	O
distribution	O
from	O
the	O
learned	O
energy	O
,	O
we	O
assume	O
that	O
µ	O
*	O
(	O
x	O
)	O
=	O
0	O
	
(	O
i.e.	O
infinite	O
data	O
support	O
)	O
,	O
and	O
discretize	O
the	O
distribution	O
into	O
the	O
same	O
grid	O
cells	O
	
,	O
∀x	O
∈	O
Grid	O
Based	O
on	O
these	O
approximation	O
,	O
Table	O
2	O
summarizes	O
the	O
results	O
.	O
	
For	O
all	O
measures	O
related	O
to	O
the	O
discriminator	O
distribution	O
,	O
EGAN	B-Method
-	I-Method
Ent	I-Method
-	I-Method
VI	I-Method
and	O
EGAN	B-Method
-	I-Method
Ent	I-Method
-	I-Method
NN	I-Method
significantly	O
outperform	O
the	O
other	O
two	O
baseline	O
models	O
,	O
which	O
matches	O
our	O
visual	O
assessment	O
in	O
Figure	O
2	O
and	O
3	O
.	O
	
Meanwhile	O
,	O
the	O
generator	B-Method
distributions	I-Method
learned	O
from	O
our	O
proposed	O
framework	O
also	O
achieve	O
relatively	O
lower	O
divergence	B-Metric
to	O
both	O
the	O
empirical	O
data	O
distribution	O
and	O
the	O
true	O
data	O
distribution	O
.	O
	
section	O
:	O
B.3	O
COMPARISON	O
OF	O
THE	O
ENTROPY	B-Method
(	I-Method
GRADIENT	I-Method
)	I-Method
APPROXIMATION	I-Method
METHODS	I-Method
	
In	O
order	O
to	O
understand	O
the	O
performance	O
difference	O
between	O
EGAN	B-Method
-	I-Method
Ent	I-Method
-	I-Method
VI	I-Method
and	O
EGAN	B-Method
-	I-Method
Ent	I-Method
-	I-Method
NN	I-Method
,	O
we	O
analyze	O
the	O
quality	O
of	O
the	O
entropy	B-Method
gradient	I-Method
approximation	I-Method
during	O
training	O
.	O
	
To	O
do	O
that	O
,	O
we	O
visualize	O
some	O
detailed	O
training	O
information	O
in	O
Figure	O
8	O
.	O
	
Fig	O
.	O
	
(	O
1	O
,	O
2	O
)	O
:	O
frequency	O
map	O
of	O
generated	O
samples	O
in	O
the	O
current	O
batch	O
.	O
	
Fig	O
.	O
	
(	O
1	O
,	O
3	O
)	O
:	O
frequency	O
map	O
of	O
real	O
samples	O
in	O
the	O
current	O
batch	O
.	O
	
Fig	O
-(	O
1	O
,	O
4	O
)	O
:	O
frequency	O
difference	O
between	O
real	O
and	O
generated	O
samples	O
.	O
	
Fig	O
.	O
	
(	O
2	O
,	O
1	O
)	O
comparison	O
between	O
more	O
generated	O
from	O
current	O
model	O
and	O
real	O
sample	O
.	O
	
Fig	O
.	O
	
(	O
2	O
,	O
2	O
)	O
:	O
the	O
discriminator	O
gradient	O
w.r.t	O
.	O
	
each	O
training	O
sample	O
.	O
	
Fig	O
.	O
	
(	O
2	O
,	O
3	O
)	O
:	O
the	O
entropy	O
gradient	O
w.r.t	O
.	O
	
each	O
training	O
samples	O
.	O
	
Fig	O
.	O
	
(	O
2	O
,	O
4	O
)	O
:	O
all	O
gradient	O
(	O
discriminator	B-Method
+	I-Method
entropy	I-Method
)	O
	
w.r.t	O
.	O
	
each	O
training	O
sample	O
.	O
	
As	O
we	O
can	O
see	O
in	O
figure	O
8a	O
,	O
the	O
viarational	B-Method
entropy	I-Method
gradient	I-Method
approximation	I-Method
w.r.t	I-Method
.	O
	
samples	O
is	O
not	O
accurate	O
:	O
	
•	O
	
It	O
is	O
inaccurate	O
in	O
terms	O
of	O
gradient	O
direction	O
.	O
	
Ideally	O
,	O
the	O
direction	O
of	O
the	O
entropy	O
gradient	O
should	O
be	O
pointing	O
from	O
the	O
center	O
of	O
its	O
closest	O
mode	O
towards	O
the	O
surroundings	O
,	O
with	O
the	O
direction	O
orthogonal	O
to	O
the	O
implicit	O
contour	O
in	O
Fig	O
.	O
	
(	O
1	O
,	O
2	O
)	O
.	O
	
However	O
,	O
the	O
direction	O
of	O
gradients	O
in	O
the	O
Fig	O
.	O
	
(	O
2	O
,	O
3	O
)	O
does	O
not	O
match	O
this	O
.	O
	
•	O
	
It	O
is	O
inaccurate	O
in	O
magnitude	O
.	O
	
As	O
we	O
can	O
see	O
,	O
the	O
entropy	O
approximation	O
gradient	O
(	O
Fig	O
.	O
	
(	O
2	O
,	O
3	O
)	O
)	O
has	O
much	O
larger	O
norm	O
than	O
the	O
discriminator	O
gradient	O
(	O
Fig	O
.	O
	
(	O
2	O
,	O
2	O
)	O
)	O
.	O
	
As	O
a	O
result	O
,	O
the	O
total	O
gradient	O
(	O
Fig	O
.	O
	
(	O
2	O
,	O
4	O
)	O
)	O
is	O
fully	O
dominated	O
by	O
the	O
entropy	O
approximation	O
gradient	O
.	O
	
Thus	O
,	O
it	O
usually	O
takes	O
much	O
longer	O
for	O
the	O
generator	B-Method
to	O
learn	O
to	O
generate	O
rare	O
samples	O
,	O
and	O
the	O
training	O
also	O
proceeds	O
much	O
slower	O
compared	O
to	O
the	O
nearest	B-Method
neighbor	I-Method
based	I-Method
approximation	I-Method
.	O
	
In	O
comparison	O
,	O
the	O
nearest	B-Method
neighbor	I-Method
based	I-Method
gradient	I-Method
approximation	I-Method
is	O
much	O
more	O
accurate	O
as	O
shown	O
in	O
8b	O
.	O
	
As	O
a	O
result	O
,	O
it	O
leads	O
to	O
more	O
accurate	O
energy	O
contour	O
,	O
as	O
well	O
as	O
faster	O
training	B-Task
.	O
	
What	O
's	O
more	O
,	O
from	O
Figure	O
8b	O
Fig	O
.	O
	
(	O
2	O
,	O
4	O
)	O
,	O
we	O
can	O
see	O
the	O
entropy	O
gradient	O
does	O
have	O
the	O
cancel	O
-	O
out	O
effect	O
on	O
the	O
discriminator	O
gradient	O
,	O
which	O
again	O
matches	O
our	O
theory	O
.	O
	
B.4	O
RANKING	B-Metric
NIST	I-Metric
DIGITS	I-Metric
Figure	O
9	O
shows	O
the	O
ranking	O
of	O
all	O
1000	O
generated	O
and	O
real	O
images	O
(	O
from	O
the	O
test	O
set	O
)	O
for	O
three	O
models	O
:	O
EGAN	B-Method
-	I-Method
Ent	I-Method
-	I-Method
NN	I-Method
,	O
EGAN	B-Method
-	I-Method
Const	I-Method
,	O
and	O
GAN	B-Method
.	O
	
We	O
can	O
clearly	O
notice	O
that	O
in	O
EGAN	B-Method
-	I-Method
Ent	I-Method
-	I-Method
NN	I-Method
the	O
topranked	O
digits	O
look	O
very	O
similar	O
to	O
the	O
mean	O
digit	O
.	O
	
From	O
the	O
upper	O
-	O
left	O
corner	O
to	O
the	O
lower	O
-	O
right	O
corner	O
,	O
the	O
transition	O
trend	O
is	O
:	O
the	O
rotation	O
degree	O
increases	O
,	O
and	O
the	O
digits	O
become	O
increasingly	O
thick	O
or	O
thin	O
compared	O
to	O
the	O
mean	O
.	O
	
In	O
addition	O
,	O
samples	O
in	O
the	O
last	O
few	O
rows	O
do	O
diverge	O
away	O
from	O
the	O
mean	O
image	O
:	O
either	O
highly	O
diagonal	O
to	O
the	O
right	O
or	O
left	O
,	O
or	O
have	O
different	O
shape	O
:	O
very	O
thin	O
or	O
thick	O
,	O
or	O
typewriter	O
script	O
.	O
	
Other	O
models	O
are	O
not	O
able	O
to	O
achieve	O
a	O
similar	O
clear	O
distinction	O
for	O
high	O
versus	O
low	O
probability	O
images	O
.	O
	
Finally	O
,	O
we	O
consistently	O
observe	O
the	O
same	O
trend	O
in	O
modeling	O
other	O
digits	O
,	O
which	O
are	O
not	O
shown	O
in	O
this	O
paper	O
due	O
to	O
space	O
constraint	O
.	O
	
section	O
:	O
B.5	O
CLASSIFIER	B-Metric
PERFORMANCE	I-Metric
AS	O
A	O
PROXY	B-Metric
MEASURE	I-Metric
	
As	O
mentioned	O
in	O
Section	O
5	O
,	O
evaluating	O
the	O
proposed	O
formulation	O
quantitatively	O
on	O
high	O
-	O
dimensional	O
data	O
is	O
extremely	O
challenging	O
.	O
	
Here	O
,	O
in	O
order	O
to	O
provide	O
more	O
quantitative	O
intuitions	O
on	O
the	O
learned	O
discriminator	B-Method
at	O
convergence	O
,	O
we	O
adopt	O
a	O
proxy	B-Metric
measure	I-Metric
.	O
	
Specifically	O
,	O
we	O
take	O
the	O
last	O
-	O
layer	O
activation	O
of	O
the	O
converged	B-Method
discriminator	I-Method
network	I-Method
as	O
fixed	O
pretrained	O
feature	O
,	O
and	O
build	O
a	O
linear	B-Method
classifier	I-Method
upon	O
it	O
.	O
	
Hypothetically	O
,	O
if	O
the	O
discriminator	B-Method
does	O
not	O
degenerate	O
,	O
the	O
extracted	O
last	O
-	O
layer	O
feature	O
should	O
maintain	O
more	O
information	O
about	O
the	O
data	O
points	O
,	O
especially	O
compared	O
to	O
features	O
from	O
degenerated	B-Method
discriminators	I-Method
.	O
	
Following	O
this	O
idea	O
,	O
we	O
first	O
train	O
EGAN	B-Method
-	I-Method
Ent	I-Method
-	I-Method
NN	I-Method
,	O
EGAN	B-Method
-	I-Method
Const	I-Method
,	O
and	O
GAN	B-Method
on	O
the	O
MNIST	B-Method
till	O
convergence	O
,	O
and	O
then	O
extract	O
the	O
last	O
-	O
layer	O
activation	O
from	O
their	O
discriminator	B-Method
networks	I-Method
as	O
fixed	O
feature	O
input	O
.	O
	
Based	O
on	O
fixed	O
feature	O
,	O
a	O
randomly	B-Method
initialized	I-Method
linear	I-Method
classifier	I-Method
is	O
trained	O
to	O
do	O
classification	B-Task
on	O
MNIST	B-Task
.	O
	
Based	O
on	O
10	O
runs	O
(	O
with	O
different	O
initialization	O
)	O
of	O
each	O
of	O
the	O
three	O
models	O
,	O
the	O
test	B-Metric
classification	I-Metric
performance	I-Metric
is	O
summarized	O
in	O
Table	O
3	O
.	O
	
For	O
comparison	O
purpose	O
,	O
we	O
also	O
include	O
a	O
baseline	O
where	O
the	O
input	O
features	O
are	O
extracted	O
from	O
a	O
discriminator	B-Method
network	I-Method
with	O
random	O
weights	O
.	O
	
Table	O
3	O
:	O
	
Test	O
performance	O
of	O
linear	B-Method
classifiers	I-Method
based	O
on	O
last	B-Method
-	I-Method
layer	I-Method
discriminator	I-Method
features	I-Method
.	O
	
Based	O
on	O
the	O
proxy	B-Metric
measure	I-Metric
,	O
EGAN	B-Method
-	I-Method
Ent	I-Method
-	I-Method
NN	I-Method
seems	O
to	O
maintain	O
more	O
information	O
of	O
data	O
,	O
which	O
suggests	O
that	O
the	O
discriminator	O
from	O
our	O
proposed	O
formulation	O
is	O
more	O
informative	O
.	O
	
Despite	O
the	O
positive	O
result	O
,	O
it	O
is	O
important	O
to	O
point	O
out	O
that	O
maintaining	O
information	O
about	O
categories	O
does	O
not	O
necessarily	O
mean	O
maintaining	O
information	O
about	O
the	O
energy	O
(	O
density	O
)	O
.	O
	
Thus	O
,	O
this	O
proxy	B-Metric
measure	I-Metric
should	O
be	O
understood	O
cautiously	O
.	O
	
section	O
:	O
	
section	O
:	O
ACKNOWLEDGEMENTS	O
	
We	O
would	O
like	O
to	O
thank	O
the	O
developers	O
of	O
Theano	O
(	O
Theano	O
Development	O
Team	O
,	O
2016	O
)	O
for	O
developing	O
such	O
a	O
powerful	O
tool	O
for	O
scientific	B-Task
computing	I-Task
.	O
	
Amjad	O
Almahairi	O
was	O
supported	O
by	O
funding	O
from	O
Maluuba	O
Research	O
.	O
	
section	O
:	O
	
document	O
:	O
End	O
-	O
to	O
-	O
End	O
Answer	B-Method
Chunk	I-Method
Extraction	I-Method
and	O
Ranking	B-Method
for	O
Reading	B-Task
Comprehension	I-Task
	
This	O
paper	O
proposes	O
dynamic	B-Method
chunk	I-Method
reader	I-Method
(	O
DCR	B-Method
)	O
,	O
an	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
neural	I-Method
reading	I-Method
comprehension	I-Method
(	I-Method
RC	I-Method
)	I-Method
model	I-Method
that	O
is	O
able	O
to	O
extract	O
and	O
rank	O
a	O
set	O
of	O
answer	O
candidates	O
from	O
a	O
given	O
document	O
to	O
answer	O
questions	O
.	O
	
DCR	B-Method
is	O
able	O
to	O
predict	O
answers	O
of	O
variable	O
lengths	O
,	O
whereas	O
previous	O
neural	B-Method
RC	I-Method
models	I-Method
primarily	O
focused	O
on	O
predicting	O
single	O
tokens	O
or	O
entities	O
.	O
	
DCR	B-Method
encodes	O
a	O
document	O
and	O
an	O
input	O
question	O
with	O
recurrent	B-Method
neural	I-Method
networks	I-Method
,	O
and	O
then	O
applies	O
a	O
word	B-Method
-	I-Method
by	I-Method
-	I-Method
word	I-Method
attention	I-Method
mechanism	I-Method
to	O
acquire	O
question	B-Method
-	I-Method
aware	I-Method
representations	I-Method
for	O
the	O
document	O
,	O
followed	O
by	O
the	O
generation	O
of	O
chunk	B-Method
representations	I-Method
and	O
a	O
ranking	B-Method
module	I-Method
to	O
propose	O
the	O
top	O
-	O
ranked	O
chunk	O
as	O
the	O
answer	O
.	O
	
Experimental	O
results	O
show	O
that	O
DCR	B-Method
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
exact	B-Metric
match	I-Metric
and	O
F1	B-Metric
scores	I-Metric
on	O
the	O
SQuAD	B-Material
dataset	I-Material
.	O
	
section	O
:	O
Introduction	O
	
Reading	B-Task
comprehension	I-Task
-	I-Task
based	I-Task
question	I-Task
answering	I-Task
(	O
RCQA	B-Task
)	O
is	O
the	O
task	O
of	O
answering	O
a	O
question	O
with	O
a	O
chunk	O
of	O
text	O
taken	O
from	O
related	O
document	O
(	O
s	O
)	O
.	O
	
A	O
variety	O
of	O
neural	B-Method
models	I-Method
have	O
been	O
proposed	O
recently	O
either	O
for	O
extracting	O
a	O
single	O
entity	O
or	O
a	O
single	O
token	O
as	O
an	O
answer	O
from	O
a	O
given	O
text	O
;	O
or	O
for	O
selecting	O
the	O
correct	O
answer	O
by	O
ranking	O
a	O
small	O
set	O
of	O
human	O
-	O
provided	O
candidates	O
.	O
	
In	O
both	O
cases	O
,	O
an	O
answer	O
boundary	O
is	O
either	O
easy	O
to	O
determine	O
or	O
already	O
given	O
.	O
	
Different	O
from	O
the	O
above	O
two	O
assumptions	O
for	O
RCQA	B-Task
,	O
in	O
the	O
real	B-Task
-	I-Task
world	I-Task
QA	I-Task
scenario	I-Task
,	O
people	O
may	O
ask	O
questions	O
about	O
both	O
entities	O
(	O
factoid	O
)	O
and	O
non	O
-	O
entities	O
such	O
as	O
explanations	O
and	O
reasons	O
(	O
non	O
-	O
factoid	O
)	O
(	O
see	O
Table	O
[	O
reference	O
]	O
for	O
examples	O
)	O
.	O
	
In	O
this	O
regard	O
,	O
RCQA	B-Task
has	O
the	O
potential	O
to	O
complement	O
other	O
QA	B-Method
approaches	I-Method
that	O
leverage	O
structured	O
data	O
(	O
e.g.	O
,	O
knowledge	O
bases	O
)	O
for	O
both	O
the	O
above	O
question	O
types	O
.	O
	
This	O
is	O
because	O
RCQA	B-Task
can	O
exploit	O
the	O
textual	O
evidences	O
to	O
ensure	O
increased	O
answer	O
coverage	O
,	O
which	O
is	O
particularly	O
helpful	O
for	O
non	O
-	O
factoid	O
answers	O
.	O
	
However	O
,	O
it	O
is	O
also	O
challenging	O
for	O
RCQA	B-Task
to	O
identify	O
answer	O
in	O
arbitrary	O
position	O
in	O
the	O
passage	O
with	O
arbitrary	O
length	O
,	O
especially	O
for	O
non	O
-	O
factoid	O
answers	O
which	O
might	O
be	O
clauses	O
or	O
sentences	O
.	O
	
As	O
a	O
result	O
,	O
apart	O
from	O
a	O
few	O
exceptions	O
,	O
this	O
research	O
direction	O
has	O
not	O
been	O
fully	O
explored	O
yet	O
.	O
	
Compared	O
to	O
the	O
relatively	O
easier	O
RC	B-Task
task	I-Task
of	O
predicting	B-Task
single	I-Task
tokens	I-Task
/	I-Task
entities	I-Task
,	O
predicting	O
answers	O
of	O
arbitrary	O
lengths	O
and	O
positions	O
significantly	O
increase	O
the	O
search	B-Metric
space	I-Metric
complexity	I-Metric
:	O
the	O
number	O
of	O
possible	O
candidates	O
to	O
consider	O
is	O
in	O
the	O
order	O
of	O
,	O
where	O
is	O
the	O
number	O
of	O
passage	O
words	O
.	O
	
In	O
contrast	O
,	O
for	O
previous	O
works	O
in	O
which	O
answers	O
are	O
single	O
tokens	O
/	O
entities	O
or	O
from	O
candidate	O
lists	O
,	O
the	O
complexity	B-Metric
is	O
in	O
or	O
the	O
size	O
of	O
candidate	O
lists	O
(	O
usually	O
5	O
)	O
,	O
respectively	O
.	O
	
To	O
address	O
the	O
above	O
complexity	O
,	O
Rajpurkar	O
et	O
al	O
.	O
	
rajpurkar2016squad	O
used	O
a	O
two	O
-	O
step	O
chunk	B-Method
-	I-Method
and	I-Method
-	I-Method
rank	I-Method
approach	I-Method
that	O
employs	O
a	O
rule	B-Method
-	I-Method
based	I-Method
algorithm	I-Method
to	O
extract	O
answer	O
candidates	O
from	O
a	O
passage	O
,	O
followed	O
by	O
a	O
ranking	B-Method
approach	I-Method
with	O
hand	O
-	O
crafted	O
features	O
to	O
select	O
the	O
best	O
answer	O
.	O
	
The	O
rule	B-Method
-	I-Method
based	I-Method
chunking	I-Method
approach	I-Method
suffered	O
from	O
low	B-Metric
coverage	I-Metric
(	O
70	O
%	O
recall	B-Metric
of	O
answer	O
chunks	O
)	O
that	O
can	O
not	O
be	O
improved	O
during	O
training	O
;	O
and	O
candidate	B-Task
ranking	I-Task
performance	O
depends	O
greatly	O
on	O
the	O
quality	O
of	O
the	O
hand	O
-	O
crafted	O
features	O
.	O
	
More	O
recently	O
,	O
Wang	O
and	O
Jiang	O
wang2016machine	O
proposed	O
two	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
neural	I-Method
network	I-Method
models	I-Method
,	O
one	O
of	O
which	O
chunks	O
a	O
candidate	O
answer	O
by	O
predicting	O
the	O
answer	O
’s	O
two	O
boundary	O
indices	O
and	O
the	O
other	O
classifies	O
each	O
passage	O
word	O
into	O
answer	O
/	O
not	O
-	O
answer	O
.	O
	
Both	O
models	O
improved	O
significantly	O
over	O
the	O
method	O
proposed	O
by	O
Rajpurkar	O
et	O
al	O
.	O
rajpurkar2016squad	O
.	O
	
Our	O
proposed	O
model	O
,	O
called	O
dynamic	B-Method
chunk	I-Method
reader	I-Method
(	O
DCR	B-Method
)	O
,	O
not	O
only	O
significantly	O
differs	O
from	O
both	O
the	O
above	O
systems	O
in	O
the	O
way	O
that	O
answer	O
candidates	O
are	O
generated	O
and	O
ranked	O
,	O
but	O
also	O
shares	O
merits	O
with	O
both	O
works	O
.	O
	
First	O
,	O
our	O
model	O
uses	O
deep	B-Method
networks	I-Method
to	O
learn	O
better	O
representations	O
for	O
candidate	O
answer	O
chunks	O
,	O
instead	O
of	O
using	O
fixed	B-Method
feature	I-Method
representations	I-Method
as	O
in	O
.	O
	
Second	O
,	O
it	O
represents	O
answer	O
candidates	O
as	O
chunks	O
,	O
as	O
in	O
,	O
instead	O
of	O
word	B-Method
-	I-Method
level	I-Method
representations	I-Method
,	O
to	O
make	O
the	O
model	O
aware	O
of	O
the	O
subtle	O
differences	O
among	O
candidates	O
(	O
importantly	O
,	O
overlapping	O
candidates	O
)	O
.	O
	
The	O
contributions	O
of	O
this	O
paper	O
are	O
three	O
-	O
fold	O
.	O
	
(	O
1	O
)	O
	
We	O
propose	O
a	O
novel	O
neural	B-Method
network	I-Method
model	I-Method
for	O
joint	B-Task
candidate	I-Task
answer	I-Task
chunking	I-Task
and	I-Task
ranking	I-Task
,	O
where	O
the	O
candidate	O
answer	O
chunks	O
are	O
dynamically	O
constructed	O
and	O
ranked	O
in	O
an	O
end	O
-	O
to	O
-	O
end	O
manner	O
.	O
	
(	O
2	O
)	O
we	O
propose	O
a	O
new	O
question	B-Method
-	I-Method
attention	I-Method
mechanism	I-Method
to	O
enhance	O
passage	B-Task
word	I-Task
representation	I-Task
,	O
which	O
is	O
subsequently	O
used	O
to	O
construct	O
chunk	B-Method
representations	I-Method
.	O
	
(	O
3	O
)	O
We	O
also	O
propose	O
several	O
simple	O
but	O
effective	O
features	O
to	O
strengthen	O
the	O
attention	B-Method
mechanism	I-Method
,	O
which	O
fundamentally	O
improves	O
candidate	B-Task
ranking	I-Task
,	O
with	O
the	O
by	O
-	O
product	O
of	O
higher	O
exact	B-Metric
boundary	I-Metric
match	I-Metric
accuracy	I-Metric
.	O
	
The	O
experiments	O
on	O
the	O
Stanford	B-Material
Question	I-Material
Answering	I-Material
Dataset	I-Material
(	O
SQuAD	B-Material
)	I-Material
,	O
which	O
contains	O
a	O
variety	O
of	O
human	O
-	O
generated	O
factoid	O
and	O
non	O
-	O
factoid	O
questions	O
,	O
have	O
shown	O
the	O
effectiveness	O
of	O
above	O
three	O
contributions	O
.	O
	
Our	O
paper	O
is	O
organized	O
as	O
follows	O
.	O
	
We	O
formally	O
define	O
the	O
RCQA	B-Task
problem	I-Task
first	O
.	O
	
Next	O
,	O
we	O
describe	O
our	O
baseline	O
with	O
a	O
neural	B-Method
network	I-Method
component	I-Method
.	O
	
We	O
present	O
the	O
end	O
-	O
to	O
-	O
end	O
dynamic	B-Method
chunk	I-Method
reader	I-Method
model	O
next	O
.	O
	
Finally	O
,	O
we	O
analyze	O
our	O
experimental	O
results	O
and	O
discuss	O
the	O
related	O
work	O
.	O
	
section	O
:	O
Problem	O
Definition	O
	
Table	O
[	O
reference	O
]	O
shows	O
an	O
example	O
of	O
our	O
RC	O
setting	O
where	O
the	O
goal	O
is	O
to	O
answer	O
a	O
question	O
,	O
factoid	O
(	O
Q1	O
)	O
or	O
non	O
-	O
factoid	O
(	O
Q2	O
and	O
Q3	O
)	O
,	O
based	O
on	O
a	O
supporting	O
passage	O
,	O
by	O
selecting	O
a	O
continuous	O
sequence	O
of	O
text	O
as	O
answer	O
.	O
	
,	O
,	O
and	O
are	O
all	O
word	O
sequences	O
,	O
where	O
each	O
word	O
is	O
drawn	O
from	O
a	O
vocabulary	O
,	O
.	O
	
The	O
-	O
th	O
instance	O
in	O
the	O
training	O
set	O
is	O
a	O
triple	O
in	O
the	O
form	O
of	O
,	O
where	O
,	O
,	O
and	O
(	O
)	O
.	O
	
Owing	O
to	O
the	O
disagreement	O
among	O
annotators	O
,	O
there	O
could	O
be	O
more	O
than	O
one	O
correct	O
answer	O
for	O
the	O
same	O
question	O
;	O
and	O
the	O
-	O
th	O
answer	O
to	O
is	O
denoted	O
by	O
.	O
	
An	O
answer	O
candidate	O
for	O
the	O
-	O
th	O
training	O
example	O
is	O
defined	O
as	O
,	O
a	O
sub	O
-	O
sequence	O
in	O
,	O
that	O
spans	O
from	O
position	O
to	O
(	O
)	O
.	O
	
The	O
ground	O
truth	O
answer	O
could	O
be	O
included	O
in	O
the	O
set	O
of	O
all	O
candidates	O
,	O
where	O
is	O
the	O
constraint	O
put	O
on	O
the	O
candidate	O
chunk	O
for	O
,	O
such	O
as	O
,	O
“	O
can	O
have	O
at	O
most	O
10	O
tokens	O
”	O
,	O
or	O
“	O
must	O
have	O
a	O
pre	O
-	O
defined	O
POS	O
pattern	O
”	O
.	O
	
To	O
evaluate	O
a	O
system	O
	
’s	O
performance	O
,	O
its	O
top	O
answer	O
to	O
a	O
question	O
is	O
matched	O
against	O
the	O
corresponding	O
gold	O
standard	O
answer	O
(	O
s	O
)	O
.	O
	
paragraph	O
:	O
Remark	O
:	O
Categories	O
of	O
RC	B-Task
Tasks	I-Task
	
Other	O
simpler	O
variants	O
of	O
the	O
aforementioned	O
RC	B-Task
task	I-Task
were	O
explored	O
in	O
the	O
past	O
.	O
	
For	O
example	O
,	O
quiz	O
-	O
style	O
datasets	O
(	O
e.g.	O
,	O
MCTest	O
,	O
MovieQA	O
)	O
have	O
multiple	O
-	O
choice	O
questions	O
with	O
answer	O
options	O
.	O
	
Cloze	O
-	O
style	O
datesets	O
,	O
usually	O
automatically	O
generated	O
,	O
have	O
factoid	O
	
“	O
question”s	O
created	O
by	O
replacing	O
the	O
answer	O
in	O
a	O
sentence	O
from	O
the	O
text	O
with	O
blank	O
.	O
	
For	O
the	O
answer	B-Task
selection	I-Task
task	I-Task
this	O
paper	O
focuses	O
on	O
,	O
several	O
datasets	O
exist	O
,	O
e.g.	O
TREC	O
-	O
QA	O
for	O
factoid	B-Task
answer	I-Task
extraction	I-Task
from	O
multiple	O
given	O
passages	O
,	O
bAbI	B-Method
designed	O
for	O
inference	B-Task
purpose	I-Task
,	O
and	O
the	O
SQuAD	B-Material
dataset	I-Material
used	O
in	O
this	O
paper	O
.	O
	
To	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
the	O
SQuAD	B-Material
dataset	I-Material
is	O
the	O
only	O
one	O
for	O
both	O
factoid	B-Task
and	I-Task
non	I-Task
-	I-Task
factoid	I-Task
answer	I-Task
extraction	I-Task
with	O
a	O
question	O
distribution	O
more	O
close	O
to	O
real	O
-	O
world	O
applications	O
.	O
	
section	O
:	O
Baseline	O
:	O
Chunk	B-Task
-	I-Task
and	I-Task
-	I-Task
Rank	I-Task
Pipeline	I-Task
with	O
Neural	B-Method
RC	I-Method
	
In	O
this	O
section	O
we	O
modified	O
a	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
RC	B-Method
system	I-Method
for	O
cloze	B-Task
-	I-Task
style	I-Task
tasks	I-Task
for	O
our	O
answer	B-Task
extraction	I-Task
purpose	I-Task
,	O
to	O
see	O
how	O
much	O
gap	O
we	O
have	O
for	O
the	O
two	O
type	O
of	O
tasks	O
,	O
and	O
to	O
inspire	O
our	O
end	O
-	O
to	O
-	O
end	O
system	O
in	O
the	O
next	O
section	O
.	O
	
In	O
order	O
to	O
make	O
the	O
cloze	B-Method
-	I-Method
style	I-Method
RC	I-Method
system	I-Method
to	O
make	O
chunk	B-Method
-	I-Method
level	I-Method
decision	I-Method
,	O
we	O
use	O
the	O
RC	B-Method
model	I-Method
to	O
generate	O
features	O
for	O
chunks	O
,	O
which	O
are	O
further	O
used	O
in	O
a	O
feature	B-Method
-	I-Method
based	I-Method
ranker	I-Method
like	O
in	O
.	O
	
As	O
a	O
result	O
,	O
this	O
baseline	O
can	O
be	O
viewed	O
as	O
a	O
deep	B-Method
learning	I-Method
based	I-Method
counterpart	I-Method
of	O
the	O
system	O
in	O
.	O
	
It	O
has	O
two	O
main	O
components	O
:	O
1	O
)	O
a	O
stand	B-Method
-	I-Method
alone	I-Method
answer	I-Method
chunker	I-Method
,	O
which	O
is	O
trained	O
to	O
produce	O
overlapping	O
candidate	O
chunks	O
,	O
and	O
2	O
)	O
a	O
neural	B-Method
RC	I-Method
model	I-Method
,	O
which	O
is	O
used	O
to	O
score	O
each	O
word	O
in	O
a	O
given	O
passage	O
to	O
be	O
used	O
thereafter	O
for	O
generating	O
chunk	O
scores	O
.	O
	
Answer	B-Method
Chunking	I-Method
	
To	O
reduce	O
the	O
errors	O
generated	O
by	O
the	O
rule	B-Method
-	I-Method
based	I-Method
chunker	I-Method
in	O
,	O
first	O
,	O
we	O
capture	O
the	O
part	O
-	O
of	O
-	O
speech	O
(	O
POS	O
)	O
pattern	O
of	O
all	O
	
answer	O
sub	O
-	O
sequences	O
in	O
the	O
training	O
dataset	O
to	O
form	O
a	O
POS	O
pattern	O
trie	O
tree	O
,	O
and	O
then	O
apply	O
the	O
answer	O
POS	O
patterns	O
to	O
passage	O
to	O
acquire	O
a	O
collection	O
of	O
all	O
subsequences	O
(	O
chunk	O
candidates	O
)	O
whose	O
POS	O
patterns	O
can	O
be	O
matched	O
to	O
the	O
POS	B-Method
pattern	I-Method
trie	I-Method
.	O
	
This	O
is	O
equivalent	O
to	O
putting	O
an	O
constraint	O
to	O
candidate	O
answer	B-Task
chunk	I-Task
generation	I-Task
process	I-Task
that	O
only	O
choose	O
the	O
chunk	O
with	O
a	O
POS	O
pattern	O
seen	O
for	O
answers	O
in	O
the	O
training	O
data	O
.	O
	
Then	O
the	O
sub	O
-	O
sequences	O
are	O
used	O
as	O
answer	O
candidates	O
for	O
.	O
	
Note	O
that	O
overlapping	O
chunks	O
could	O
be	O
generated	O
for	O
a	O
passage	O
,	O
and	O
we	O
rely	O
on	O
the	O
ranker	O
to	O
choose	O
the	O
best	O
candidate	O
based	O
on	O
features	O
from	O
the	O
cloze	B-Method
-	I-Method
style	I-Method
RC	I-Method
system	I-Method
.	O
	
Experiments	O
showed	O
that	O
for	O
of	O
the	O
questions	O
on	O
the	O
development	O
set	O
,	O
the	O
ground	O
truth	O
answer	O
is	O
included	O
in	O
the	O
candidate	O
set	O
constructed	O
in	O
such	O
manner	O
.	O
	
Feature	B-Task
Extraction	I-Task
and	O
Ranking	B-Task
	
For	O
chunk	B-Task
ranking	I-Task
,	O
we	O
(	O
1	O
)	O
use	O
neural	O
RCQA	B-Task
model	O
to	O
annotate	O
each	O
in	O
passage	O
to	O
get	O
score	O
,	O
then	O
(	O
2	O
)	O
for	O
every	O
chunk	O
in	O
passage	O
,	O
collect	O
scores	O
for	O
all	O
the	O
contained	O
within	O
,	O
and	O
(	O
3	O
)	O
extract	O
features	O
on	O
the	O
sequence	O
of	O
scores	O
to	O
characterize	O
its	O
scale	O
and	O
distribution	O
information	O
,	O
which	O
serves	O
as	O
the	O
feature	B-Method
representation	I-Method
of	O
.	O
	
In	O
step	O
(	O
1	O
)	O
to	O
acquire	O
we	O
train	O
and	O
apply	O
a	O
word	B-Method
-	I-Method
level	I-Method
single	I-Method
-	I-Method
layer	I-Method
Gated	I-Method
Attention	I-Method
Reader	I-Method
,	O
which	O
has	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
CNN	B-Task
/	I-Task
DailyMail	I-Task
cloze	I-Task
-	I-Task
style	I-Task
RC	I-Task
task	I-Task
.	O
	
In	O
step	O
(	O
3	O
)	O
for	O
chunk	B-Task
,	O
we	O
designed	O
5	O
features	O
,	O
including	O
4	O
statistics	O
on	O
:	O
maximum	O
,	O
minimum	O
,	O
average	O
and	O
sum	O
;	O
as	O
well	O
as	O
the	O
count	O
of	O
matched	O
POS	O
pattern	O
within	O
the	O
chunk	O
,	O
which	O
serves	O
as	O
an	O
answer	O
prior	O
.	O
	
We	O
use	O
these	O
5	O
features	O
in	O
a	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
ranker	B-Method
.	O
	
section	O
:	O
Dynamic	B-Method
Chunk	I-Method
Reader	I-Method
	
The	O
dynamic	B-Method
chunk	I-Method
reader	I-Method
(	O
DCR	B-Method
)	O
model	O
is	O
presented	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Inspired	O
by	O
the	O
baseline	O
we	O
built	O
,	O
DCR	B-Method
is	O
deemed	O
to	O
be	O
superior	O
to	O
the	O
baseline	O
for	O
3	O
reasons	O
.	O
	
First	O
,	O
each	O
chunk	O
has	O
a	O
representation	O
constructed	O
dynamically	O
,	O
instead	O
of	O
having	O
a	O
set	O
of	O
pre	O
-	O
defined	O
feature	O
values	O
.	O
	
Second	O
,	O
each	O
passage	O
word	O
’s	O
representation	O
is	O
enhanced	O
by	O
word	O
-	O
by	O
-	O
word	O
attention	O
that	O
evaluates	O
the	O
relevance	O
of	O
the	O
passage	O
word	O
to	O
the	O
question	O
.	O
	
Third	O
,	O
these	O
components	O
are	O
all	O
within	O
a	O
single	O
,	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
model	I-Method
that	O
can	O
be	O
trained	O
in	O
a	O
joint	O
manner	O
.	O
	
DCR	B-Method
works	O
in	O
four	O
steps	O
.	O
	
First	O
,	O
the	O
encoder	B-Method
layer	I-Method
encodes	O
passage	O
and	O
question	O
separately	O
,	O
by	O
using	O
bidirectional	B-Method
recurrent	I-Method
neural	I-Method
networks	I-Method
(	O
RNN	B-Method
)	O
.	O
	
Second	O
,	O
the	O
attention	B-Method
layer	I-Method
calculates	O
the	O
relevance	O
of	O
each	O
passage	O
word	O
to	O
the	O
question	O
.	O
	
Third	O
,	O
the	O
chunk	B-Method
representation	I-Method
layer	I-Method
dynamically	O
extracts	O
the	O
candidate	O
chunks	O
from	O
the	O
given	O
passage	O
,	O
and	O
create	O
chunk	B-Method
representation	I-Method
that	O
encodes	O
the	O
contextual	O
information	O
of	O
each	O
chunk	O
.	O
	
Fourth	O
,	O
the	O
ranker	B-Method
layer	I-Method
scores	O
the	O
relevance	O
between	O
the	O
representations	O
of	O
a	O
chunk	O
and	O
the	O
given	O
question	O
,	O
and	O
ranks	O
all	O
candidate	O
chunks	O
using	O
a	O
softmax	B-Method
layer	I-Method
.	O
	
We	O
describe	O
each	O
step	O
in	O
details	O
below	O
.	O
	
Encoder	B-Method
Layer	I-Method
	
We	O
use	O
bi	B-Method
-	I-Method
directional	I-Method
RNN	I-Method
encoder	I-Method
to	O
encode	O
and	O
of	O
example	O
,	O
and	O
get	O
hidden	O
state	O
for	O
each	O
word	O
position	O
and	O
.	O
	
As	O
RNN	O
input	O
,	O
a	O
word	O
is	O
represented	O
by	O
a	O
row	O
vector	O
.	O
	
can	O
be	O
the	O
concatenation	O
of	O
word	O
embedding	O
and	O
word	O
features	O
(	O
see	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
The	O
word	O
vector	O
for	O
the	O
-	O
th	O
word	O
is	O
.	O
	
A	O
word	O
sequence	O
is	O
processed	O
using	O
an	O
RNN	B-Method
encoder	I-Method
with	O
gated	B-Method
recurrent	I-Method
units	I-Method
(	O
GRU	B-Method
)	I-Method
,	O
which	O
was	O
proved	O
to	O
be	O
effective	O
in	O
RC	B-Task
and	I-Task
neural	I-Task
machine	I-Task
translation	I-Task
tasks	I-Task
.	O
	
For	O
each	O
position	O
,	O
GRU	B-Method
computes	O
with	O
input	O
and	O
previous	O
state	O
,	O
as	O
:	O
where	O
,	O
,	O
and	O
are	O
d	O
-	O
dimensional	O
hidden	O
state	O
,	O
reset	O
gate	O
,	O
and	O
update	O
gate	O
,	O
respectively	O
;	O
,	O
and	O
,	O
are	O
the	O
parameters	O
of	O
the	O
GRU	B-Method
;	O
is	O
the	O
sigmoid	O
function	O
,	O
and	O
denotes	O
element	B-Method
-	I-Method
wise	I-Method
production	I-Method
.	O
	
For	O
a	O
word	O
at	O
,	O
we	O
use	O
the	O
hidden	O
state	O
from	O
the	O
forward	B-Method
RNN	I-Method
as	O
a	O
representation	O
of	O
the	O
preceding	O
context	O
,	O
and	O
the	O
from	O
a	O
backward	B-Method
RNN	I-Method
that	O
encodes	O
text	O
reversely	O
,	O
to	O
incorporate	O
the	O
context	O
after	O
.	O
	
Next	O
,	O
,	O
the	O
bi	O
-	O
directional	O
contextual	O
encoding	O
of	O
,	O
is	O
formed	O
.	O
	
is	O
the	O
concatenation	O
operator	O
.	O
	
To	O
distinguish	O
hidden	O
states	O
from	O
different	O
sources	O
,	O
we	O
denote	O
the	O
of	O
-	O
th	O
word	O
in	O
and	O
the	O
of	O
-	O
th	O
word	O
in	O
as	O
and	O
respectively	O
.	O
	
Attention	B-Method
Layer	I-Method
Attention	I-Method
mechanism	I-Method
in	O
previous	O
RC	B-Task
tasks	I-Task
enables	O
question	B-Task
-	I-Task
aware	I-Task
passage	I-Task
representations	I-Task
.	O
	
We	O
propose	O
a	O
novel	O
attention	B-Method
mechanism	I-Method
inspired	O
by	O
word	B-Method
-	I-Method
by	I-Method
-	I-Method
word	I-Method
style	I-Method
attention	I-Method
methods	I-Method
.	O
	
For	O
each	O
,	O
a	O
question	B-Method
-	I-Method
attended	I-Method
representation	I-Method
is	O
computed	O
as	O
follows	O
(	O
example	O
index	O
is	O
omitted	O
for	O
simplicity	O
)	O
:	O
where	O
and	O
are	O
hidden	O
states	O
from	O
the	O
bi	B-Method
-	I-Method
directional	I-Method
RNN	I-Method
encoders	I-Method
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
An	O
inner	O
product	O
,	O
,	O
is	O
calculated	O
between	O
and	O
every	O
question	O
word	O
.	O
	
It	O
indicates	O
how	O
well	O
the	O
passage	O
word	O
matches	O
with	O
every	O
question	O
word	O
.	O
	
is	O
a	O
weighted	B-Method
pooling	I-Method
of	I-Method
question	I-Method
hidden	I-Method
states	I-Method
,	O
which	O
serves	O
as	O
a	O
-	B-Method
aware	I-Method
question	I-Method
representation	I-Method
.	O
	
The	O
concatenation	O
of	O
and	O
leads	O
to	O
a	O
passage	B-Method
-	I-Method
question	I-Method
joint	I-Method
representation	I-Method
,	O
.	O
	
Next	O
,	O
we	O
apply	O
a	O
second	O
bi	B-Method
-	I-Method
GRU	I-Method
layer	I-Method
taking	O
the	O
s	O
as	O
inputs	O
,	O
and	O
obtain	O
forward	O
and	O
backward	O
representations	O
and	O
,	O
and	O
in	O
turn	O
their	O
concatenation	O
,	O
.	O
	
Chunk	B-Method
Representation	I-Method
Layer	I-Method
	
A	O
candidate	O
answer	B-Method
chunk	I-Method
representation	I-Method
is	O
dynamically	O
created	O
given	O
attention	O
layer	O
output	O
.	O
	
We	O
first	O
decide	O
the	O
text	O
boundary	O
for	O
the	O
candidate	O
chunk	O
,	O
and	O
then	O
form	O
a	O
chunk	B-Method
representation	I-Method
using	O
all	O
or	O
part	O
of	O
those	O
outputs	O
inside	O
the	O
chunk	O
.	O
	
To	O
decide	O
a	O
candidate	O
chunk	O
(	O
boundary	O
)	O
:	O
we	O
tried	O
two	O
ways	O
:	O
(	O
1	O
)	O
adopt	O
the	O
POS	B-Method
trie	I-Method
-	I-Method
based	I-Method
approach	I-Method
used	O
in	O
our	O
baseline	O
,	O
and	O
(	O
2	O
)	O
enumerate	O
all	O
possible	O
chunks	O
up	O
to	O
a	O
maximum	O
number	O
of	O
tokens	O
.	O
	
For	O
(	O
2	O
)	O
,	O
we	O
create	O
up	O
to	O
(	O
max	O
chunk	O
length	O
)	O
chunks	O
starting	O
from	O
any	O
position	O
in	O
.	O
	
Approach	O
(	O
1	O
)	O
can	O
generate	O
candidates	O
with	O
arbitrary	O
lengths	O
,	O
but	O
fails	O
to	O
recall	O
candidates	O
whose	O
POS	O
pattern	O
is	O
unseen	O
in	O
training	O
set	O
;	O
whereas	O
approach	O
(	O
2	O
)	O
considers	O
all	O
possible	O
candidates	O
within	O
a	O
window	O
and	O
is	O
more	O
flexible	O
,	O
but	O
over	O
-	O
generates	O
invalid	O
candidates	O
.	O
	
For	O
a	O
candidate	O
answer	O
chunk	O
spanning	O
from	O
position	O
to	O
inclusively	O
,	O
we	O
construct	O
chunk	B-Method
representation	I-Method
using	O
every	O
within	O
range	O
,	O
with	O
a	O
function	O
.	O
	
Formally	O
,	O
We	O
experimented	O
with	O
several	O
pooling	B-Method
functions	I-Method
(	O
e.g.	O
,	O
max	O
,	O
average	O
)	O
for	O
,	O
and	O
found	O
out	O
that	O
,	O
instead	O
of	O
pooling	B-Method
,	O
the	O
best	O
function	O
is	O
to	O
concatenate	O
the	O
hidden	O
state	O
of	O
the	O
first	O
word	O
in	O
a	O
chunk	O
in	O
forward	B-Method
RNN	I-Method
and	O
that	O
of	O
the	O
last	O
word	O
in	O
backward	B-Method
RNN	I-Method
.	O
	
Formally	O
,	O
We	O
hypothesize	O
that	O
the	O
hidden	O
states	O
at	O
that	O
two	O
ends	O
can	O
better	O
represent	O
the	O
chunk	O
’s	O
contexts	O
,	O
which	O
is	O
critical	O
for	O
this	O
task	O
,	O
than	O
the	O
states	O
within	O
the	O
chunk	O
.	O
	
This	O
observation	O
also	O
agrees	O
with	O
.	O
	
Ranker	B-Method
Layer	I-Method
	
Each	O
chunk	O
is	O
evaluated	O
on	O
its	O
context	O
similarity	O
to	O
the	O
question	O
,	O
by	O
taking	O
the	O
cosine	O
similarity	O
between	O
the	O
chunk	B-Method
context	I-Method
representation	I-Method
acquired	O
from	O
chunk	B-Method
representation	I-Method
layer	I-Method
,	O
and	O
the	O
question	B-Method
representation	I-Method
which	O
is	O
the	O
concatenation	O
of	O
the	O
last	O
hidden	O
state	O
in	O
forward	B-Method
RNN	I-Method
and	O
the	O
first	O
hidden	O
state	O
in	O
backward	B-Method
RNN	I-Method
.	O
	
Thus	O
,	O
for	O
training	O
example	O
,	O
we	O
have	O
the	O
probability	O
of	O
the	O
chunk	O
as	O
where	O
denotes	O
representation	O
of	O
the	O
chunk	O
,	O
or	O
is	O
the	O
-	O
th	O
hidden	O
state	O
output	O
from	O
question	O
’s	O
forward	O
and	O
backward	B-Method
RNN	I-Method
encoder	I-Method
,	O
respectively	O
.	O
	
In	O
runtime	O
,	O
the	O
chunk	O
with	O
the	O
highest	O
probability	O
is	O
taken	O
as	O
the	O
answer	O
.	O
	
In	O
training	B-Task
,	O
the	O
following	O
negative	O
log	O
likelihood	O
is	O
minimized	O
:	O
Note	O
that	O
the	O
-	O
th	O
training	O
instance	O
is	O
only	O
used	O
when	O
is	O
included	O
in	O
the	O
corresponding	O
candidate	O
chunk	O
set	O
,	O
i.e.	O
.	O
	
The	O
softmax	O
in	O
the	O
final	O
layer	O
serves	O
as	O
the	O
list	B-Method
-	I-Method
wise	I-Method
ranking	I-Method
module	I-Method
similar	O
in	O
spirit	O
to	O
.	O
	
section	O
:	O
Experiments	O
	
paragraph	O
:	O
Dataset	O
	
We	O
used	O
the	O
Stanford	B-Material
Question	I-Material
Answering	I-Material
Dataset	I-Material
(	O
SQuAD	B-Material
)	O
for	O
the	O
experiment	O
.	O
	
SQuAD	B-Material
came	O
into	O
our	O
sight	O
because	O
it	O
is	O
a	O
mix	O
of	O
factoid	O
and	O
non	O
-	O
factoid	O
questions	O
,	O
a	O
real	O
-	O
world	O
data	O
(	O
crowd	O
-	O
sourced	O
)	O
,	O
and	O
of	O
large	O
scale	O
(	O
over	O
100	O
K	O
question	O
-	O
answer	O
pairs	O
collected	O
from	O
536	O
Wikipedia	O
articles	O
)	O
.	O
	
Answers	O
range	O
from	O
single	O
words	O
to	O
long	O
,	O
variable	O
-	O
length	O
phrase	O
/	O
clauses	O
.	O
	
It	O
is	O
a	O
relaxation	O
of	O
assumptions	O
by	O
the	O
cloze	B-Method
-	I-Method
style	I-Method
and	I-Method
quiz	I-Method
-	I-Method
style	I-Method
RC	I-Method
datasets	I-Method
in	O
the	O
Problem	O
Definition	O
section	O
.	O
	
Features	O
The	O
input	O
vector	B-Method
representation	I-Method
of	O
each	O
word	O
to	O
encoder	B-Method
RNNs	I-Method
has	O
six	O
parts	O
including	O
a	O
pre	O
-	O
trained	O
300	B-Method
-	I-Method
dimensional	I-Method
GloVe	I-Method
embedding	I-Method
and	O
five	O
features	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
	
)	O
:	O
	
(	O
1	O
)	O
a	O
one	B-Method
-	I-Method
hot	I-Method
encoding	I-Method
(	O
46	O
dimensions	O
)	O
for	O
the	O
part	O
-	O
of	O
-	O
speech	O
(	O
POS	O
)	O
tag	O
of	O
;	O
(	O
2	O
)	O
a	O
one	B-Method
-	I-Method
hot	I-Method
encoding	I-Method
(	O
14	O
dimensions	O
)	O
for	O
named	O
entity	O
(	O
	
NE	O
)	O
tag	O
of	O
;	O
(	O
3	O
)	O
a	O
binary	O
value	O
indicating	O
whether	O
’s	O
surface	O
form	O
is	O
the	O
same	O
to	O
any	O
word	O
in	O
the	O
quesiton	O
;	O
(	O
4	O
)	O
if	O
the	O
lemma	O
form	O
of	O
is	O
the	O
same	O
to	O
any	O
word	O
in	O
the	O
question	O
;	O
and	O
(	O
5	O
)	O
if	O
is	O
caplitalized	O
.	O
	
Feature	O
(	O
3	O
)	O
and	O
(	O
4	O
)	O
are	O
designed	O
to	O
help	O
the	O
model	O
align	O
the	O
passage	O
text	O
with	O
question	O
.	O
	
Note	O
that	O
some	O
types	O
of	O
questions	O
(	O
e.g.	O
,	O
“	O
who	O
”	O
,	O
“	O
when	O
”	O
questions	O
)	O
have	O
answers	O
that	O
have	O
a	O
specific	O
POS	O
/	O
NE	O
tag	O
pattern	O
.	O
	
For	O
instance	O
,	O
“	O
who	O
”	O
questions	O
mostly	O
have	O
proper	O
nouns	O
/	O
persons	O
as	O
answers	O
and	O
“	O
when	O
”	O
questions	O
may	O
frequently	O
have	O
numbers	O
/	O
dates	O
(	O
e.g.	O
,	O
a	O
year	O
)	O
as	O
answers	O
.	O
	
Thus	O
,	O
we	O
believe	O
that	O
the	O
model	O
could	O
exploit	O
the	O
co	O
-	O
relation	O
between	O
question	O
types	O
and	O
answer	O
POS	O
/	O
NE	O
patterns	O
easier	O
with	O
POS	O
and	O
NE	O
tag	O
features	O
.	O
	
Implementation	O
Details	O
	
We	O
pre	O
-	O
processed	O
the	O
SQuAD	B-Material
dataset	I-Material
using	O
Stanford	B-Method
CoreNLP	I-Method
tool	I-Method
with	O
its	O
default	O
setting	O
to	O
tokenize	O
the	O
text	O
and	O
obtain	O
the	O
POS	O
and	O
NE	O
annotations	O
.	O
	
To	O
train	O
our	O
model	O
,	O
we	O
used	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
with	O
the	O
ADAM	B-Method
optimizer	I-Method
,	O
with	O
an	O
initial	O
learning	B-Metric
rate	I-Metric
of	O
0.001	O
.	O
	
All	O
GRU	O
weights	O
were	O
initialized	O
from	O
a	O
uniform	O
distribution	O
between	O
(	O
-	O
0.01	O
,	O
0.01	O
)	O
.	O
	
The	O
hidden	O
state	O
size	O
,	O
,	O
was	O
set	O
to	O
300	O
for	O
all	O
GRUs	O
.	O
	
The	O
question	B-Method
bi	I-Method
-	I-Method
GRU	I-Method
shared	O
parameters	O
with	O
the	O
passage	B-Method
bi	I-Method
-	I-Method
GRU	I-Method
,	O
while	O
the	O
attention	B-Method
-	I-Method
based	I-Method
passage	I-Method
bi	I-Method
-	I-Method
GRU	I-Method
had	O
its	O
own	O
parameters	O
.	O
	
We	O
shuffled	O
all	O
training	O
examples	O
at	O
the	O
beginning	O
of	O
each	O
epoch	O
and	O
adopted	O
a	O
curriculum	B-Method
learning	I-Method
approach	I-Method
,	O
by	O
sorting	O
training	O
instances	O
by	O
length	O
in	O
every	O
10	O
batches	O
,	O
to	O
enable	O
the	O
model	O
start	O
learning	O
from	O
relatively	O
easier	O
instances	O
and	O
to	O
harder	O
ones	O
.	O
	
We	O
also	O
applied	O
dropout	O
of	O
rate	O
0.2	O
to	O
the	O
embedding	B-Method
layer	I-Method
of	I-Method
input	I-Method
bi	I-Method
-	I-Method
GRU	I-Method
encoder	I-Method
,	O
and	O
gradient	B-Method
clipping	I-Method
when	O
the	O
norm	O
of	O
gradients	O
exceeded	O
10	O
.	O
	
We	O
trained	O
in	O
mini	B-Method
-	I-Method
batch	I-Method
style	I-Method
(	O
mini	O
-	O
batch	O
size	O
is	O
180	O
)	O
and	O
applied	O
zero	B-Method
-	I-Method
padding	I-Method
to	O
the	O
passage	O
and	O
question	O
inputs	O
in	O
each	O
batch	O
.	O
	
We	O
also	O
set	O
the	O
maximum	O
passage	O
length	O
to	O
be	O
300	O
tokens	O
,	O
and	O
pruned	O
all	O
the	O
tokens	O
after	O
the	O
300	O
-	O
th	O
token	O
in	O
the	O
training	O
set	O
to	O
save	O
memory	O
and	O
speed	O
up	O
the	O
training	O
process	O
.	O
	
This	O
step	O
reduced	O
the	O
training	O
set	O
size	O
by	O
about	O
1.6	O
%	O
.	O
	
During	O
test	O
,	O
we	O
test	O
on	O
the	O
full	O
length	O
of	O
passage	O
,	O
so	O
that	O
we	O
do	O
	
n’t	O
prune	O
out	O
the	O
potential	O
candidates	O
.	O
	
We	O
trained	O
the	O
model	O
for	O
at	O
most	O
30	O
epochs	O
,	O
and	O
in	O
case	O
the	O
accuracy	B-Metric
did	O
not	O
improve	O
for	O
10	O
epochs	O
,	O
we	O
stopped	O
training	O
.	O
	
For	O
the	O
feature	B-Method
ranking	I-Method
-	I-Method
based	I-Method
system	I-Method
,	O
we	O
used	O
jforest	B-Method
ranker	I-Method
with	O
LambdaMART	B-Method
-	I-Method
RegressionTree	I-Method
algorithm	I-Method
and	O
the	O
ranking	B-Metric
metric	I-Metric
was	O
NDCG@10	B-Method
.	O
	
For	O
the	O
Gated	B-Task
Attention	I-Task
Reader	I-Task
in	O
baseline	O
system	O
,	O
we	O
replicated	O
the	O
method	O
and	O
use	O
the	O
same	O
configurations	O
as	O
in	O
.	O
	
Results	O
Table	O
[	O
reference	O
]	O
shows	O
our	O
main	O
results	O
on	O
the	O
SQuAD	B-Material
dataset	I-Material
.	O
	
Compared	O
to	O
the	O
scores	O
reported	O
in	O
,	O
our	O
exact	B-Metric
match	I-Metric
(	O
EM	B-Metric
)	O
and	O
F1	B-Metric
on	O
the	O
development	O
set	O
and	O
EM	B-Metric
score	O
on	O
the	O
test	O
set	O
are	O
better	O
,	O
and	O
F1	B-Metric
on	O
the	O
test	O
set	O
is	O
comparable	O
.	O
	
We	O
also	O
studied	O
how	O
each	O
component	O
in	O
our	O
model	O
contributes	O
to	O
the	O
overall	O
performance	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
details	O
as	O
well	O
as	O
the	O
results	O
of	O
the	O
baseline	O
ranker	O
.	O
	
As	O
the	O
first	O
row	O
of	O
Table	O
[	O
reference	O
]	O
shows	O
,	O
our	O
baseline	O
system	O
improves	O
10	O
%	O
(	O
EM	B-Metric
)	O
over	O
Rajpurkar	O
et	O
al	O
.	O
	
rajpurkar2016squad	O
(	O
Table	O
[	O
reference	O
]	O
,	O
row	O
1	O
)	O
,	O
the	O
feature	B-Method
-	I-Method
based	I-Method
ranking	I-Method
system	I-Method
.	O
	
However	O
when	O
compared	O
to	O
our	O
DCR	B-Method
model	I-Method
(	O
Table	O
[	O
reference	O
]	O
,	O
row	O
2	O
)	O
,	O
the	O
baseline	O
(	O
row	O
1	O
)	O
is	O
more	O
than	O
12	O
%	O
(	O
EM	B-Metric
)	O
behind	O
even	O
though	O
it	O
is	O
based	O
on	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
model	O
for	O
cloze	B-Task
-	I-Task
style	I-Task
RC	I-Task
tasks	I-Task
.	O
	
This	O
can	O
be	O
attributed	O
to	O
the	O
advanced	O
model	O
structure	O
and	O
end	O
-	O
to	O
-	O
end	O
manner	O
of	O
DCR	B-Method
.	O
	
We	O
also	O
did	O
ablation	O
tests	O
on	O
our	O
DCR	B-Method
model	I-Method
.	O
	
First	O
,	O
replacing	O
the	O
word	O
-	O
by	O
-	O
word	O
attention	O
with	O
Attentive	O
Reader	O
style	O
attention	O
decreases	O
the	O
EM	B-Metric
score	O
by	O
about	O
4.5	O
%	O
,	O
showing	O
the	O
strength	O
of	O
our	O
proposed	O
attention	B-Method
mechanism	I-Method
.	O
	
Second	O
,	O
we	O
remove	O
the	O
features	O
in	O
input	O
to	O
see	O
the	O
contribution	O
of	O
each	O
feature	O
.	O
	
The	O
result	O
shows	O
that	O
POS	O
feature	O
(	O
1	O
)	O
and	O
question	O
-	O
word	O
feature	O
(	O
3	O
)	O
are	O
the	O
two	O
most	O
important	O
features	O
.	O
	
Finally	O
,	O
combining	O
the	O
DCR	B-Method
model	I-Method
with	O
the	O
proposed	O
POS	O
-	O
trie	O
constraints	O
yields	O
a	O
score	O
similar	O
to	O
the	O
one	O
obtained	O
using	O
the	O
DCR	B-Method
model	I-Method
with	O
all	O
possible	O
-	O
gram	O
chunks	O
.	O
	
The	O
result	O
shows	O
that	O
(	O
1	O
)	O
our	O
chunk	B-Method
representations	I-Method
are	O
powerful	O
enough	O
to	O
differentiate	O
even	O
a	O
huge	O
amount	O
of	O
chunks	O
when	O
no	O
constraints	O
are	O
applied	O
;	O
and	O
(	O
2	O
)	O
the	O
proposed	O
POS	B-Method
-	I-Method
trie	I-Method
reduces	O
the	O
search	O
space	O
at	O
the	O
cost	O
of	O
a	O
small	O
drop	O
in	O
performance	O
.	O
	
Analysis	O
To	O
better	O
understand	O
our	O
system	O
,	O
we	O
calculated	O
the	O
accuracy	B-Metric
of	O
the	O
attention	B-Method
mechanism	I-Method
of	O
the	O
gated	B-Method
attention	I-Method
reader	I-Method
used	O
in	O
our	O
deep	B-Method
learning	I-Method
-	I-Method
based	I-Method
baseline	I-Method
.	O
	
We	O
found	O
that	O
it	O
is	O
72	O
%	O
accurate	O
i.e.	O
,	O
72	O
%	O
of	O
the	O
times	O
a	O
word	O
with	O
the	O
highest	O
attention	O
score	O
is	O
inside	O
the	O
correct	O
answer	O
span	O
.	O
	
This	O
means	O
that	O
,	O
if	O
we	O
could	O
accurately	O
detect	O
the	O
boundary	O
around	O
the	O
word	O
with	O
the	O
highest	O
attention	O
score	O
to	O
form	O
the	O
answer	O
span	O
,	O
we	O
could	O
achieve	O
an	O
accuracy	B-Metric
close	O
to	O
72	O
%	O
.	O
	
In	O
addition	O
,	O
we	O
checked	O
the	O
answer	B-Metric
recall	I-Metric
of	O
our	O
candidate	B-Method
chunking	I-Method
approach	I-Method
.	O
	
When	O
we	O
use	O
a	O
window	O
size	O
of	O
10	O
,	O
92	O
%	O
of	O
the	O
time	O
,	O
the	O
ground	O
truth	O
answer	O
will	O
be	O
included	O
in	O
the	O
extracted	O
Candidate	O
chunk	O
set	O
.	O
	
Thus	O
the	O
upper	O
bound	O
of	O
the	O
exact	B-Metric
match	I-Metric
score	O
of	O
our	O
baseline	O
system	O
is	O
around	O
66	O
%	O
(	O
92	O
%	O
(	O
the	O
answer	B-Metric
recall	I-Metric
)	O
72	O
%	O
)	O
.	O
	
From	O
the	O
results	O
,	O
we	O
see	O
our	O
DCR	B-Method
system	I-Method
	
’s	O
exact	B-Metric
match	I-Metric
score	O
is	O
at	O
62	O
%	O
.	O
	
This	O
shows	O
that	O
DCR	B-Method
is	O
proficient	O
at	O
differentiating	O
answer	O
spans	O
dynamically	O
.	O
	
[	O
]	O
[	O
]	O
To	O
further	O
analyze	O
the	O
system	O
	
’s	O
performance	O
	
while	O
predicting	O
answers	O
of	O
different	O
lengths	O
,	O
we	O
show	O
the	O
exact	B-Metric
match	I-Metric
(	O
EM	B-Metric
)	O
and	O
F1	B-Metric
scores	I-Metric
for	O
answers	O
with	O
lengths	O
up	O
to	O
10	O
tokens	O
in	O
Figure	O
2	O
(	O
a	O
)	O
.	O
	
From	O
the	O
graph	O
,	O
we	O
can	O
see	O
that	O
,	O
with	O
the	O
increase	O
of	O
answer	O
length	O
,	O
both	O
EM	B-Metric
and	O
F1	B-Metric
drops	O
,	O
but	O
in	O
different	O
speed	O
.	O
	
The	O
gap	O
between	O
F1	B-Metric
and	O
exact	B-Metric
match	I-Metric
also	O
widens	O
as	O
answer	O
length	O
increases	O
.	O
	
However	O
,	O
the	O
model	O
still	O
yields	O
a	O
decent	O
accuracy	B-Metric
when	O
the	O
answer	O
is	O
longer	O
than	O
a	O
single	O
word	O
.	O
	
Additionally	O
,	O
Figure	O
2	O
(	O
b	O
)	O
shows	O
that	O
the	O
system	O
is	O
better	O
at	O
“	O
when	O
”	O
and	O
“	O
who	O
”	O
questions	O
,	O
but	O
performs	O
poorly	O
on	O
“	O
why	O
”	O
questions	O
.	O
	
The	O
large	O
gap	O
between	O
exact	B-Metric
match	I-Metric
and	O
F1	B-Metric
on	O
“	O
why	O
”	O
questions	O
means	O
that	O
perfectly	O
identifying	O
the	O
span	O
is	O
harder	O
than	O
locating	O
the	O
core	O
of	O
the	O
answer	O
span	O
.	O
	
Since	O
“	O
what	O
”	O
,	O
“	O
which	O
”	O
,	O
and	O
“	O
how	O
”	O
questions	O
contain	O
a	O
broad	O
range	O
of	O
question	O
types	O
,	O
we	O
split	O
them	O
further	O
based	O
on	O
the	O
bigram	O
a	O
question	O
starts	O
with	O
,	O
and	O
Figure	O
[	O
reference	O
]	O
shows	O
the	O
breakdown	O
for	O
“	O
	
what	O
”	O
questions	O
.	O
	
We	O
can	O
see	O
that	O
“	O
what	O
”	O
questions	O
asking	O
for	O
explanations	O
such	O
as	O
“	O
	
what	O
happens	O
”	O
and	O
	
“	O
what	O
happened	O
”	O
have	O
lower	O
EM	B-Metric
and	O
F1	B-Metric
scores	O
.	O
	
In	O
contrast	O
,	O
“	O
what	O
”	O
questions	O
asking	O
for	O
year	O
and	O
numbers	O
have	O
much	O
higher	O
scores	O
and	O
,	O
for	O
these	O
questions	O
,	O
exact	B-Metric
match	I-Metric
scores	O
are	O
close	O
to	O
F1	B-Metric
scores	I-Metric
,	O
which	O
means	O
chunking	O
for	O
these	O
questions	O
are	O
easier	O
for	O
DCR	B-Method
.	O
	
section	O
:	O
Related	O
Work	O
	
Attentive	B-Method
Reader	I-Method
was	O
the	O
first	O
neural	B-Method
model	I-Method
for	O
factoid	B-Task
RCQA	I-Task
.	O
	
It	O
uses	O
Bidirectional	B-Method
RNN	I-Method
(	O
Cho	O
et	O
al	O
.	O
,	O
2014	O
;	O
Chung	O
et	O
al.	O
,	O
2014	O
)	O
to	O
encode	O
document	O
and	O
query	O
respectively	O
,	O
and	O
use	O
query	B-Method
representation	I-Method
to	O
match	O
with	O
every	O
token	O
from	O
the	O
document	O
.	O
	
Attention	O
Sum	O
Reader	O
simplifies	O
the	O
model	O
to	O
just	O
predicting	O
positions	O
of	O
correct	O
answer	O
in	O
the	O
document	O
and	O
the	O
training	B-Metric
speed	I-Metric
and	O
test	B-Metric
accuracy	I-Metric
are	O
both	O
greatly	O
improved	O
on	O
the	O
CNN	O
/	O
Daily	O
Mail	O
dataset	O
.	O
	
also	O
simplified	O
Attentive	B-Method
Reader	I-Method
and	O
reported	O
higher	O
accuracy	B-Metric
.	O
	
Window	B-Method
-	I-Method
based	I-Method
Memory	I-Method
Networks	I-Method
(	O
MemN2N	B-Method
)	I-Method
is	O
introduced	O
along	O
with	O
the	O
CBT	O
dataset	O
,	O
which	O
does	O
not	O
use	O
RNN	B-Method
encoders	I-Method
,	O
but	O
embeds	O
contexts	O
as	O
memory	O
and	O
matches	O
questions	O
with	O
embedded	O
contexts	O
.	O
	
Those	O
models	O
’	O
mechanism	O
is	O
to	O
learn	O
the	O
match	O
between	O
answer	O
context	O
with	O
question	B-Method
/	I-Method
query	I-Method
representation	I-Method
.	O
	
In	O
contrast	O
,	O
memory	B-Method
enhanced	I-Method
neural	I-Method
networks	I-Method
like	O
Neural	B-Method
Turing	I-Method
Machines	I-Method
and	O
its	O
variants	O
were	O
also	O
potential	O
candidates	O
for	O
the	O
task	O
,	O
and	O
Gulcehre	O
et	O
al	O
.	O
	
gulcehre2016dynamic	B-Method
reported	O
results	O
on	O
the	O
bAbI	B-Task
task	I-Task
,	O
which	O
is	O
worse	O
than	O
memory	B-Method
networks	I-Method
.	O
	
Similarly	O
,	O
sequence	B-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
models	I-Method
were	O
also	O
used	O
,	O
but	O
they	O
did	O
not	O
yield	O
better	O
results	O
either	O
.	O
	
Recently	O
,	O
several	O
models	O
have	O
been	O
proposed	O
to	O
enable	O
more	O
complex	O
inference	B-Method
for	O
RC	B-Task
task	I-Task
.	O
	
For	O
instance	O
,	O
gated	B-Method
attention	I-Method
model	I-Method
employs	O
a	O
multi	B-Method
-	I-Method
layer	I-Method
architecture	I-Method
,	O
where	O
each	O
layer	O
encodes	O
the	O
same	O
document	O
,	O
but	O
the	O
attention	O
is	O
updated	O
from	O
layer	O
to	O
layer	O
.	O
	
EpiReader	B-Method
adopted	O
a	O
joint	B-Method
training	I-Method
model	I-Method
for	O
answer	B-Task
extractor	I-Task
and	O
reasoner	B-Task
,	O
where	O
the	O
extractor	O
proposes	O
top	O
candidates	O
,	O
and	O
the	O
reasoner	B-Method
weighs	O
each	O
candidate	O
by	O
examining	O
entailment	O
relationship	O
between	O
question	B-Method
-	I-Method
answer	I-Method
representation	I-Method
and	O
the	O
document	O
.	O
	
An	O
iterative	B-Method
alternating	I-Method
attention	I-Method
mechanism	I-Method
and	O
gating	B-Method
strategies	I-Method
were	O
proposed	O
in	O
to	O
optimize	O
the	O
attention	O
through	O
several	O
hops	O
.	O
	
In	O
contrast	O
,	O
Cui	O
et	O
al	O
.	O
cui2016aoa	O
,	O
cui2016consensus	O
introduced	O
fine	O
-	O
grained	O
document	O
attention	O
from	O
each	O
question	O
word	O
and	O
then	O
aggregated	O
those	O
attentions	O
from	O
each	O
question	O
token	O
by	O
summation	O
with	O
or	O
without	O
weights	O
.	O
	
This	O
system	O
achieved	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
score	O
on	O
the	O
CNN	O
dataset	O
.	O
	
Those	O
different	O
variations	O
all	O
result	O
in	O
roughly	O
3	O
-	O
5	O
%	O
improvement	O
over	O
attention	B-Metric
sum	I-Metric
reader	I-Metric
,	O
but	O
none	O
of	O
those	O
could	O
achieve	O
higher	O
than	O
that	O
.	O
	
Other	O
methods	O
include	O
using	O
dynamic	B-Method
entity	I-Method
representation	I-Method
with	O
max	B-Method
-	I-Method
pooling	I-Method
that	O
aims	O
to	O
change	O
entity	B-Method
representation	I-Method
with	O
context	O
,	O
and	O
Weissenborn	B-Method
’s	I-Method
weissenborn2016separating	I-Method
system	I-Method
,	O
which	O
tries	O
to	O
separate	O
entity	O
from	O
the	O
context	O
and	O
then	O
matches	O
the	O
question	O
to	O
context	O
,	O
scoring	O
an	O
accuracy	B-Metric
around	O
70	O
%	O
on	O
the	O
CNN	O
dataset	O
.	O
	
However	O
,	O
all	O
of	O
those	O
models	O
assume	O
that	O
the	O
answers	O
are	O
single	O
tokens	O
.	O
	
This	O
limits	O
the	O
type	O
of	O
questions	O
the	O
models	O
can	O
answer	O
.	O
	
Wang	O
and	O
Jiang	O
wang2016machine	O
proposed	O
a	O
match	B-Method
-	I-Method
lstm	I-Method
and	O
achieved	O
good	O
results	O
on	O
SQuAD	B-Material
.	O
	
However	O
,	O
this	O
approach	O
predicts	O
a	O
chunk	O
boundary	O
or	O
whether	O
a	O
word	O
is	O
part	O
of	O
a	O
chunk	O
or	O
not	O
.	O
	
In	O
contrast	O
,	O
our	O
approach	O
explicitly	O
constructs	O
the	O
chunk	B-Method
representations	I-Method
and	O
similar	O
chunks	O
are	O
compared	O
directly	O
to	O
determine	O
correct	O
answer	O
boundaries	O
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
paper	O
we	O
proposed	O
a	O
novel	O
neural	B-Method
reading	I-Method
comprehension	I-Method
model	I-Method
for	O
question	B-Task
answering	I-Task
.	O
	
Different	O
from	O
the	O
previously	O
proposed	O
models	O
for	O
factoid	B-Task
RCQA	I-Task
,	O
the	O
proposed	O
model	O
,	O
dynamic	B-Method
chunk	I-Method
reader	I-Method
,	O
is	O
not	O
restricted	O
to	O
predicting	O
a	O
single	O
named	O
entity	O
as	O
an	O
answer	O
or	O
selecting	O
an	O
answer	O
from	O
a	O
small	O
,	O
pre	O
-	O
defined	O
candidate	O
list	O
.	O
	
Instead	O
,	O
it	O
is	O
capable	O
of	O
answering	O
both	O
factoid	B-Task
and	I-Task
non	I-Task
-	I-Task
factoid	I-Task
questions	I-Task
as	O
it	O
learns	O
to	O
select	O
answer	O
chunks	O
that	O
are	O
suitable	O
for	O
an	O
input	O
question	O
.	O
	
DCR	B-Method
achieves	O
this	O
goal	O
with	O
a	O
joint	B-Method
deep	I-Method
learning	I-Method
model	I-Method
enhanced	O
with	O
a	O
novel	O
attention	B-Method
mechanism	I-Method
and	O
five	O
simple	O
yet	O
effective	O
features	O
.	O
	
Error	B-Task
analysis	I-Task
shows	O
that	O
the	O
DCR	B-Method
model	I-Method
achieves	O
good	O
performance	O
,	O
but	O
still	O
needs	O
to	O
improve	O
on	O
predicting	O
longer	O
answers	O
,	O
which	O
are	O
usually	O
non	O
-	O
factoid	O
in	O
nature	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Semantic	B-Task
Image	I-Task
Segmentation	I-Task
with	O
Deep	B-Method
Convolutional	I-Method
Nets	I-Method
and	O
Fully	B-Method
Connected	I-Method
CRFs	I-Method
	
Deep	B-Method
Convolutional	I-Method
Neural	I-Method
Networks	I-Method
(	O
DCNNs	B-Method
)	O
have	O
recently	O
shown	O
state	O
of	O
the	O
art	O
performance	O
in	O
high	B-Task
level	I-Task
vision	I-Task
tasks	I-Task
,	O
such	O
as	O
image	B-Task
classification	I-Task
and	O
object	B-Task
detection	I-Task
.	O
	
This	O
work	O
brings	O
together	O
methods	O
from	O
DCNNs	B-Method
and	O
probabilistic	B-Method
graphical	I-Method
models	I-Method
for	O
addressing	O
the	O
task	O
of	O
pixel	B-Task
-	I-Task
level	I-Task
classification	I-Task
(	O
also	O
called	O
”	O
semantic	O
image	B-Task
segmentation	I-Task
”	O
)	O
.	O
	
We	O
show	O
that	O
responses	O
at	O
the	O
final	O
layer	O
of	O
DCNNs	B-Method
are	O
not	O
sufficiently	O
localized	O
for	O
accurate	B-Task
object	I-Task
segmentation	I-Task
.	O
	
This	O
is	O
due	O
to	O
the	O
very	O
invariance	O
properties	O
that	O
make	O
DCNNs	B-Method
good	O
for	O
high	B-Task
level	I-Task
tasks	I-Task
.	O
	
We	O
overcome	O
this	O
poor	O
localization	B-Metric
property	I-Metric
of	O
deep	B-Method
networks	I-Method
by	O
combining	O
the	O
responses	O
at	O
the	O
final	O
DCNN	B-Method
layer	I-Method
with	O
a	O
fully	B-Method
connected	I-Method
Conditional	I-Method
Random	I-Method
Field	I-Method
(	O
CRF	B-Method
)	O
.	O
	
Qualitatively	O
,	O
our	O
“	O
DeepLab	B-Method
”	I-Method
system	I-Method
is	O
able	O
to	O
localize	O
segment	O
boundaries	O
at	O
a	O
level	O
of	O
accuracy	B-Metric
which	O
is	O
beyond	O
previous	O
methods	O
.	O
	
Quantitatively	O
,	O
our	O
method	O
sets	O
the	O
new	O
state	O
-	O
of	O
-	O
art	O
at	O
the	O
PASCAL	O
VOC	O
-	O
2012	O
semantic	O
image	B-Task
segmentation	I-Task
task	O
,	O
reaching	O
71.6	O
%	O
IOU	B-Metric
accuracy	O
in	O
the	O
test	O
set	O
.	O
	
We	O
show	O
how	O
these	O
results	O
can	O
be	O
obtained	O
efficiently	O
:	O
Careful	B-Method
network	I-Method
re	I-Method
-	I-Method
purposing	I-Method
and	O
a	O
novel	O
application	O
of	O
the	O
’	B-Method
hole	I-Method
’	I-Method
algorithm	I-Method
from	O
the	O
wavelet	B-Method
community	I-Method
allow	O
dense	O
computation	O
of	O
neural	O
net	O
responses	O
at	O
8	O
frames	B-Metric
per	I-Metric
second	I-Metric
on	O
a	O
modern	O
GPU	B-Method
.	O
	
section	O
:	O
Introduction	O
	
Deep	B-Method
Convolutional	I-Method
Neural	I-Method
Networks	I-Method
(	O
DCNNs	B-Method
)	O
had	O
been	O
the	O
method	O
of	O
choice	O
for	O
document	B-Task
recognition	I-Task
since	O
LeCun1998	O
,	O
but	O
have	O
only	O
recently	O
become	O
the	O
mainstream	O
of	O
high	B-Task
-	I-Task
level	I-Task
vision	I-Task
research	I-Task
.	O
	
Over	O
the	O
past	O
two	O
years	O
DCNNs	B-Method
have	O
pushed	O
the	O
performance	O
of	O
computer	B-Method
vision	I-Method
systems	I-Method
to	O
soaring	O
heights	O
on	O
a	O
broad	O
array	O
of	O
high	O
-	O
level	O
problems	O
,	O
including	O
image	B-Task
classification	I-Task
KrizhevskyNIPS2013	O
,	O
sermanet2013overfeat	O
,	O
simonyan2014very	O
,	O
szegedy2014going	O
,	O
papandreou2014untangling	O
,	O
object	B-Task
detection	I-Task
girshick2014rcnn	O
,	O
fine	B-Task
-	I-Task
grained	I-Task
categorization	I-Task
zhang2014part	O
,	O
among	O
others	O
.	O
	
A	O
common	O
theme	O
in	O
these	O
works	O
is	O
that	O
DCNNs	B-Method
trained	O
in	O
an	O
end	O
-	O
to	O
-	O
end	O
manner	O
deliver	O
strikingly	O
better	O
results	O
than	O
systems	O
relying	O
on	O
carefully	O
engineered	B-Method
representations	I-Method
,	O
such	O
as	O
SIFT	O
or	O
HOG	O
features	O
.	O
	
This	O
success	O
can	O
be	O
partially	O
attributed	O
to	O
the	O
built	O
-	O
in	O
invariance	O
of	O
DCNNs	B-Method
to	O
local	O
image	O
transformations	O
,	O
which	O
underpins	O
their	O
ability	O
to	O
learn	O
hierarchical	O
abstractions	O
of	O
data	O
zeiler2014visualizing	O
.	O
	
While	O
this	O
invariance	O
is	O
clearly	O
desirable	O
for	O
high	B-Task
-	I-Task
level	I-Task
vision	I-Task
tasks	I-Task
,	O
it	O
can	O
hamper	O
low	B-Task
-	I-Task
level	I-Task
tasks	I-Task
,	O
such	O
as	O
pose	B-Task
estimation	I-Task
chen2014articulated	O
,	O
tompson2014joint	O
and	O
semantic	B-Task
segmentation	I-Task
-	O
where	O
we	O
want	O
precise	B-Task
localization	I-Task
,	O
rather	O
than	O
abstraction	O
of	O
spatial	O
details	O
.	O
	
There	O
are	O
two	O
technical	O
hurdles	O
in	O
the	O
application	O
of	O
DCNNs	B-Method
to	O
image	B-Task
labeling	I-Task
tasks	I-Task
:	O
signal	B-Task
downsampling	I-Task
,	O
and	O
spatial	O
	
‘	O
	
insensitivity	O
’	O
(	O
invariance	O
)	O
.	O
	
The	O
first	O
problem	O
relates	O
to	O
the	O
reduction	B-Task
of	I-Task
signal	I-Task
resolution	I-Task
incurred	O
by	O
the	O
repeated	O
combination	O
of	O
max	B-Method
-	I-Method
pooling	I-Method
and	O
downsampling	B-Method
(	O
‘	O
striding	O
’	O
)	O
performed	O
at	O
every	O
layer	O
of	O
standard	O
DCNNs	B-Method
KrizhevskyNIPS2013	O
,	O
simonyan2014very	O
,	O
szegedy2014going	O
.	O
	
Instead	O
,	O
as	O
in	O
papandreou2014untangling	O
,	O
we	O
employ	O
the	O
‘	O
atrous	B-Method
’	I-Method
(	I-Method
with	I-Method
holes	I-Method
)	I-Method
algorithm	I-Method
originally	O
developed	O
for	O
efficiently	O
computing	O
the	O
undecimated	B-Method
discrete	I-Method
wavelet	I-Method
transform	I-Method
Mall99	O
.	O
	
This	O
allows	O
efficient	O
dense	B-Task
computation	I-Task
of	I-Task
DCNN	I-Task
responses	I-Task
in	O
a	O
scheme	O
substantially	O
simpler	O
than	O
earlier	O
solutions	O
to	O
this	O
problem	O
GCMG	B-Method
+	I-Method
13	I-Method
,	O
sermanet2013overfeat	O
.	O
	
The	O
second	O
problem	O
relates	O
to	O
the	O
fact	O
that	O
obtaining	O
object	O
-	O
centric	O
decisions	O
from	O
a	O
classifier	B-Method
requires	O
invariance	O
to	O
spatial	O
transformations	O
,	O
inherently	O
limiting	O
the	O
spatial	B-Metric
accuracy	I-Metric
of	O
the	O
DCNN	B-Method
model	I-Method
.	O
	
We	O
boost	O
our	O
model	O
	
’s	O
ability	O
to	O
capture	O
fine	O
details	O
by	O
employing	O
a	O
fully	B-Method
-	I-Method
connected	I-Method
Conditional	I-Method
Random	I-Method
Field	I-Method
(	O
CRF	B-Method
)	O
.	O
	
Conditional	B-Method
Random	I-Method
Fields	I-Method
have	O
been	O
broadly	O
used	O
in	O
semantic	B-Task
segmentation	I-Task
to	O
combine	O
class	O
scores	O
computed	O
by	O
multi	B-Method
-	I-Method
way	I-Method
classifiers	I-Method
with	O
the	O
low	O
-	O
level	O
information	O
captured	O
by	O
the	O
local	O
interactions	O
of	O
pixels	O
and	O
edges	O
rother2004grabcut	O
,	O
shotton2009textonboost	O
or	O
superpixels	O
lucchi2011spatial	O
.	O
	
Even	O
though	O
works	O
of	O
increased	O
sophistication	O
have	O
been	O
proposed	O
to	O
model	O
the	O
hierarchical	O
dependency	O
he2004multiscale	O
,	O
ladicky2009associative	O
,	O
lempitsky2011pylon	O
and	O
/	O
or	O
high	O
-	O
order	O
dependencies	O
of	O
segments	O
delong2012fast	O
,	O
gonfaus2010harmony	O
,	O
kohli2009robust	O
,	O
CPY13	B-Method
,	O
Wang15	O
,	O
we	O
use	O
the	O
fully	O
connected	O
pairwise	O
CRF	B-Method
proposed	O
by	O
krahenbuhl2011efficient	O
for	O
its	O
efficient	O
computation	O
,	O
and	O
ability	O
to	O
capture	O
fine	O
edge	O
details	O
while	O
also	O
catering	O
for	O
long	O
range	O
dependencies	O
.	O
	
That	O
model	O
was	O
shown	O
in	O
krahenbuhl2011efficient	O
to	O
largely	O
improve	O
the	O
performance	O
of	O
a	O
boosting	B-Method
-	I-Method
based	I-Method
pixel	I-Method
-	I-Method
level	I-Method
classifier	I-Method
,	O
and	O
in	O
our	O
work	O
we	O
demonstrate	O
that	O
it	O
leads	O
to	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
when	O
coupled	O
with	O
a	O
DCNN	B-Method
-	I-Method
based	I-Method
pixel	I-Method
-	I-Method
level	I-Method
classifier	I-Method
.	O
	
The	O
three	O
main	O
advantages	O
of	O
our	O
“	O
DeepLab	B-Method
”	I-Method
system	I-Method
are	O
(	O
i	O
)	O
speed	B-Metric
:	O
by	O
virtue	O
of	O
the	O
‘	O
atrous	B-Method
’	I-Method
algorithm	I-Method
,	O
our	O
dense	B-Method
DCNN	I-Method
operates	O
at	O
8	O
fps	O
,	O
while	O
Mean	B-Method
Field	I-Method
Inference	I-Method
for	O
the	O
fully	O
-	O
connected	O
CRF	B-Method
requires	O
0.5	O
second	O
,	O
	
(	O
ii	O
)	O
accuracy	B-Metric
:	O
	
we	O
obtain	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
the	O
PASCAL	B-Task
semantic	I-Task
segmentation	I-Task
challenge	I-Task
,	O
outperforming	O
the	O
second	O
-	O
best	O
approach	O
of	O
mostajabi2014feedforward	O
by	O
a	O
margin	O
of	O
7.2	O
and	O
(	O
iii	O
)	O
simplicity	B-Metric
:	O
our	O
system	O
is	O
composed	O
of	O
a	O
cascade	B-Method
of	O
two	O
fairly	O
well	O
-	O
established	O
modules	O
,	O
DCNNs	B-Method
and	O
CRFs	B-Method
.	O
	
section	O
:	O
Related	O
Work	O
	
Our	O
system	O
works	O
directly	O
on	O
the	O
pixel	B-Method
representation	I-Method
,	O
similarly	O
to	O
long2014fully	O
.	O
	
This	O
is	O
in	O
contrast	O
to	O
the	O
two	B-Method
-	I-Method
stage	I-Method
approaches	I-Method
that	O
are	O
now	O
most	O
common	O
in	O
semantic	B-Task
segmentation	I-Task
with	O
DCNNs	B-Method
:	O
such	O
techniques	O
typically	O
use	O
a	O
cascade	O
of	O
bottom	O
-	O
up	O
image	B-Task
segmentation	I-Task
and	O
DCNN	B-Method
-	I-Method
based	I-Method
region	I-Method
classification	I-Method
,	O
which	O
makes	O
the	O
system	O
commit	O
to	O
potential	O
errors	O
of	O
the	O
front	B-Method
-	I-Method
end	I-Method
segmentation	I-Method
system	I-Method
.	O
	
For	O
instance	O
,	O
the	O
bounding	O
box	O
proposals	O
and	O
masked	O
regions	O
delivered	O
by	O
arbelaez2014multiscale	O
,	O
Uijlings13	O
are	O
used	O
in	O
girshick2014rcnn	O
and	O
hariharan2014simultaneous	O
as	O
inputs	O
to	O
a	O
DCNN	B-Method
to	O
introduce	O
shape	O
information	O
into	O
the	O
classification	B-Method
process	I-Method
.	O
	
Similarly	O
,	O
the	O
authors	O
of	O
mostajabi2014feedforward	O
rely	O
on	O
a	O
superpixel	B-Method
representation	I-Method
.	O
	
A	O
celebrated	O
non	B-Method
-	I-Method
DCNN	I-Method
precursor	I-Method
to	O
these	O
works	O
is	O
the	O
second	B-Method
order	I-Method
pooling	I-Method
method	I-Method
of	O
carreira2012semantic	O
which	O
also	O
assigns	O
labels	O
to	O
the	O
regions	O
proposals	O
delivered	O
by	O
carreira2012cpmc	O
.	O
	
Understanding	O
the	O
perils	O
of	O
committing	O
to	O
a	O
single	O
segmentation	O
,	O
the	O
authors	O
of	O
cogswell2014combining	O
build	O
on	O
yadollahpour2013discriminative	O
to	O
explore	O
a	O
diverse	O
set	O
of	O
CRF	B-Method
-	O
based	O
segmentation	O
proposals	O
,	O
computed	O
also	O
by	O
carreira2012cpmc	O
.	O
	
These	O
segmentation	O
proposals	O
are	O
then	O
re	O
-	O
ranked	O
according	O
to	O
a	O
DCNN	B-Method
trained	O
in	O
particular	O
for	O
this	O
reranking	B-Task
task	I-Task
.	O
	
Even	O
though	O
this	O
approach	O
explicitly	O
tries	O
to	O
handle	O
the	O
temperamental	O
nature	O
of	O
a	O
front	B-Method
-	I-Method
end	I-Method
segmentation	I-Method
algorithm	I-Method
,	O
there	O
is	O
still	O
no	O
explicit	O
exploitation	O
of	O
the	O
DCNN	B-Method
scores	I-Method
in	O
the	O
CRF	B-Method
-	O
based	O
segmentation	O
algorithm	O
:	O
the	O
DCNN	B-Method
is	O
only	O
applied	O
post	O
-	O
hoc	O
,	O
while	O
it	O
would	O
make	O
sense	O
to	O
directly	O
try	O
to	O
use	O
its	O
results	O
during	O
segmentation	B-Task
.	O
	
Moving	O
towards	O
works	O
that	O
lie	O
closer	O
to	O
our	O
approach	O
,	O
several	O
other	O
researchers	O
have	O
considered	O
the	O
use	O
of	O
convolutionally	B-Method
computed	I-Method
DCNN	I-Method
features	I-Method
for	O
dense	B-Task
image	I-Task
labeling	I-Task
.	O
	
Among	O
the	O
first	O
have	O
been	O
farabet2013learning	O
who	O
apply	O
DCNNs	B-Method
at	O
multiple	O
image	O
resolutions	O
and	O
then	O
employ	O
a	O
segmentation	B-Method
tree	I-Method
to	O
smooth	O
the	O
prediction	O
results	O
;	O
more	O
recently	O
,	O
hariharan2014hypercolumns	O
propose	O
to	O
concatenate	O
the	O
computed	O
inter	O
-	O
mediate	O
feature	O
maps	O
within	O
the	O
DCNNs	B-Method
for	O
pixel	B-Task
classification	I-Task
,	O
and	O
dai2014convolutional	O
propose	O
to	O
pool	O
the	O
inter	O
-	O
mediate	O
feature	O
maps	O
by	O
region	B-Method
proposals	I-Method
.	O
	
Even	O
though	O
these	O
works	O
still	O
employ	O
segmentation	B-Method
algorithms	I-Method
that	O
are	O
decoupled	O
from	O
the	O
DCNN	B-Method
classifier	I-Method
’s	O
results	O
,	O
we	O
believe	O
it	O
is	O
advantageous	O
that	O
segmentation	B-Task
is	O
only	O
used	O
at	O
a	O
later	O
stage	O
,	O
avoiding	O
the	O
commitment	O
to	O
premature	O
decisions	O
.	O
	
More	O
recently	O
,	O
the	O
segmentation	B-Method
-	I-Method
free	I-Method
techniques	I-Method
of	O
long2014fully	O
,	O
eigen2014predicting	O
directly	O
apply	O
DCNNs	B-Method
to	O
the	O
whole	O
image	O
in	O
a	O
sliding	O
window	O
fashion	O
,	O
replacing	O
the	O
last	O
fully	B-Method
connected	I-Method
layers	I-Method
of	O
a	O
DCNN	B-Method
by	O
convolutional	B-Method
layers	I-Method
.	O
	
In	O
order	O
to	O
deal	O
with	O
the	O
spatial	B-Task
localization	I-Task
issues	I-Task
outlined	O
in	O
the	O
beginning	O
of	O
the	O
introduction	O
,	O
long2014fully	O
upsample	O
and	O
concatenate	O
the	O
scores	O
from	O
inter	O
-	O
mediate	O
feature	O
maps	O
,	O
while	O
eigen2014predicting	O
refine	O
the	O
prediction	O
result	O
from	O
coarse	O
to	O
fine	O
by	O
propagating	O
the	O
coarse	O
results	O
to	O
another	O
DCNN	B-Method
.	O
	
The	O
main	O
difference	O
between	O
our	O
model	O
and	O
other	O
state	B-Method
-	I-Method
of	I-Method
-	I-Method
the	I-Method
-	I-Method
art	I-Method
models	I-Method
is	O
the	O
combination	O
of	O
pixel	B-Method
-	I-Method
level	I-Method
CRFs	I-Method
and	O
DCNN	B-Method
-	I-Method
based	O
	
‘	O
unary	O
terms	O
’	O
.	O
	
Focusing	O
on	O
the	O
closest	O
works	O
in	O
this	O
direction	O
,	O
cogswell2014combining	O
use	O
CRFs	B-Method
as	O
a	O
proposal	B-Method
mechanism	I-Method
for	O
a	O
DCNN	B-Method
-	I-Method
based	I-Method
reranking	I-Method
system	I-Method
,	O
while	O
farabet2013learning	O
treat	O
superpixels	O
as	O
nodes	O
for	O
a	O
local	O
pairwise	O
CRF	B-Method
and	O
use	O
graph	B-Method
-	I-Method
cuts	I-Method
for	O
discrete	B-Task
inference	I-Task
;	O
as	O
such	O
their	O
results	O
can	O
be	O
limited	O
by	O
errors	O
in	O
superpixel	O
computations	O
,	O
while	O
ignoring	O
long	O
-	O
range	O
superpixel	O
dependencies	O
.	O
	
Our	O
approach	O
instead	O
treats	O
every	O
pixel	O
as	O
a	O
CRF	B-Method
node	O
,	O
exploits	O
long	O
-	O
range	O
dependencies	O
,	O
and	O
uses	O
CRF	B-Method
inference	O
to	O
directly	O
optimize	O
a	O
DCNN	B-Method
-	I-Method
driven	I-Method
cost	I-Method
function	I-Method
.	O
	
We	O
note	O
that	O
mean	B-Method
field	I-Method
had	O
been	O
extensively	O
studied	O
for	O
traditional	O
image	B-Task
segmentation	I-Task
/	O
edge	B-Task
detection	I-Task
tasks	I-Task
,	O
e.g	O
.	O
,	O
geiger1991parallel	O
,	O
geiger1991common	O
,	O
kokkinos2008computational	O
,	O
but	O
recently	O
krahenbuhl2011efficient	O
showed	O
that	O
the	O
inference	B-Method
can	O
be	O
very	O
efficient	O
for	O
fully	O
connected	O
CRF	B-Method
and	O
particularly	O
effective	O
in	O
the	O
context	O
of	O
semantic	B-Task
segmentation	I-Task
.	O
	
After	O
the	O
first	O
version	O
of	O
our	O
manuscript	O
was	O
made	O
publicly	O
available	O
,	O
it	O
came	O
to	O
our	O
attention	O
that	O
two	O
other	O
groups	O
have	O
independently	O
and	O
concurrently	O
pursued	O
a	O
very	O
similar	O
direction	O
,	O
combining	O
DCNNs	B-Method
and	O
densely	B-Method
connected	I-Method
CRFs	I-Method
bell2014material	O
,	O
zheng2015crfrnn	O
.	O
	
There	O
are	O
several	O
differences	O
in	O
technical	O
aspects	O
of	O
the	O
respective	O
models	O
.	O
	
bell2014material	O
focus	O
on	O
the	O
problem	O
of	O
material	B-Task
classification	I-Task
,	O
while	O
zheng2015crfrnn	O
unroll	O
the	O
CRF	B-Method
mean	O
-	O
field	O
inference	O
steps	O
to	O
convert	O
the	O
whole	O
system	O
into	O
an	O
end	O
-	O
to	O
-	O
end	O
trainable	B-Method
feed	I-Method
-	I-Method
forward	I-Method
network	I-Method
.	O
	
We	O
have	O
updated	O
our	O
proposed	O
“	O
DeepLab	B-Method
”	I-Method
system	I-Method
with	O
much	O
improved	O
methods	O
and	O
results	O
in	O
our	O
latest	O
work	O
chen2016deeplab	O
.	O
	
We	O
refer	O
the	O
interested	O
reader	O
to	O
the	O
paper	O
for	O
details	O
.	O
	
section	O
:	O
Convolutional	B-Method
Neural	I-Method
Networks	I-Method
for	O
Dense	B-Task
Image	I-Task
Labeling	I-Task
	
Herein	O
we	O
describe	O
how	O
we	O
have	O
re	O
-	O
purposed	O
and	O
finetuned	O
the	O
publicly	O
available	O
Imagenet	O
-	O
pretrained	O
state	O
-	O
of	O
-	O
art	O
16	B-Method
-	I-Method
layer	I-Method
classification	I-Method
network	I-Method
of	O
simonyan2014very	O
(	O
VGG	B-Method
-	I-Method
16	I-Method
)	O
into	O
an	O
efficient	O
and	O
effective	O
dense	B-Method
feature	I-Method
extractor	I-Method
for	O
our	O
dense	O
semantic	O
image	B-Task
segmentation	I-Task
system	O
.	O
	
subsection	O
:	O
Efficient	O
Dense	B-Method
Sliding	I-Method
Window	I-Method
Feature	I-Method
Extraction	I-Method
with	O
the	O
Hole	B-Method
Algorithm	I-Method
	
Dense	B-Method
spatial	I-Method
score	I-Method
evaluation	I-Method
is	O
instrumental	O
in	O
the	O
success	O
of	O
our	O
dense	B-Method
CNN	I-Method
feature	I-Method
extractor	I-Method
.	O
	
As	O
a	O
first	O
step	O
to	O
implement	O
this	O
,	O
we	O
convert	O
the	O
fully	B-Method
-	I-Method
connected	I-Method
layers	I-Method
of	O
VGG	B-Method
-	I-Method
16	I-Method
into	O
convolutional	B-Method
ones	I-Method
and	O
run	O
the	O
network	O
in	O
a	O
convolutional	B-Method
fashion	I-Method
on	O
the	O
image	O
at	O
its	O
original	O
resolution	O
.	O
	
However	O
this	O
is	O
not	O
enough	O
as	O
it	O
yields	O
very	O
sparsely	O
computed	O
detection	O
scores	O
(	O
with	O
a	O
stride	O
of	O
32	O
pixels	O
)	O
.	O
	
To	O
compute	O
scores	O
more	O
densely	O
at	O
our	O
target	O
stride	O
of	O
8	O
pixels	O
,	O
we	O
develop	O
a	O
variation	O
of	O
the	O
method	O
previously	O
employed	O
by	O
GCMG	B-Method
+	I-Method
13	I-Method
,	O
sermanet2013overfeat	O
.	O
	
We	O
skip	O
subsampling	O
after	O
the	O
last	O
two	O
max	B-Method
-	I-Method
pooling	I-Method
layers	I-Method
in	O
the	O
network	O
of	O
simonyan2014very	O
and	O
modify	O
the	O
convolutional	B-Method
filters	I-Method
in	O
the	O
layers	O
that	O
follow	O
them	O
by	O
introducing	O
zeros	O
to	O
increase	O
their	O
length	O
(	O
in	O
the	O
last	O
three	O
convolutional	B-Method
layers	I-Method
and	O
in	O
the	O
first	O
fully	B-Method
connected	I-Method
layer	I-Method
)	O
.	O
	
We	O
can	O
implement	O
this	O
more	O
efficiently	O
by	O
keeping	O
the	O
filters	O
intact	O
and	O
instead	O
sparsely	O
sample	O
the	O
feature	O
maps	O
on	O
which	O
they	O
are	O
applied	O
on	O
using	O
an	O
input	O
stride	O
of	O
2	O
or	O
4	O
pixels	O
,	O
respectively	O
.	O
	
This	O
approach	O
,	O
illustrated	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
is	O
known	O
as	O
the	O
‘	O
hole	B-Method
algorithm	I-Method
’	O
(	O
‘	O
atrous	B-Method
algorithm	I-Method
’	O
)	O
and	O
has	O
been	O
developed	O
before	O
for	O
efficient	O
computation	O
of	O
the	O
undecimated	B-Method
wavelet	I-Method
transform	I-Method
Mall99	O
.	O
	
We	O
have	O
implemented	O
this	O
within	O
the	O
Caffe	B-Method
framework	I-Method
jia2014caffe	O
by	O
adding	O
to	O
the	O
im2col	B-Method
function	I-Method
(	O
it	O
converts	O
multi	O
-	O
channel	O
feature	O
maps	O
to	O
vectorized	O
patches	O
)	O
the	O
option	O
to	O
sparsely	O
sample	O
the	O
underlying	O
feature	O
map	O
.	O
	
This	O
approach	O
is	O
generally	O
applicable	O
and	O
allows	O
us	O
to	O
efficiently	O
compute	O
dense	O
CNN	O
feature	O
maps	O
at	O
any	O
target	O
subsampling	B-Metric
rate	I-Metric
without	O
introducing	O
any	O
approximations	O
.	O
	
We	O
finetune	O
the	O
model	O
weights	O
of	O
the	O
Imagenet	B-Method
-	I-Method
pretrained	I-Method
VGG	I-Method
-	I-Method
16	I-Method
network	I-Method
to	O
adapt	O
it	O
to	O
the	O
image	B-Task
classification	I-Task
task	I-Task
in	O
a	O
straightforward	O
fashion	O
,	O
following	O
the	O
procedure	O
of	O
long2014fully	O
.	O
	
We	O
replace	O
the	O
1000	B-Method
-	I-Method
way	I-Method
Imagenet	I-Method
classifier	I-Method
in	O
the	O
last	O
layer	O
of	O
VGG	B-Method
-	I-Method
16	I-Method
with	O
a	O
21	B-Method
-	I-Method
way	I-Method
one	I-Method
.	O
	
Our	O
loss	B-Method
function	I-Method
is	O
the	O
sum	O
of	O
cross	O
-	O
entropy	O
terms	O
for	O
each	O
spatial	O
position	O
in	O
the	O
CNN	O
output	O
map	O
(	O
subsampled	O
by	O
8	O
compared	O
to	O
the	O
original	O
image	O
)	O
.	O
	
All	O
positions	O
and	O
labels	O
are	O
equally	O
weighted	O
in	O
the	O
overall	O
loss	B-Metric
function	I-Metric
.	O
	
Our	O
targets	O
are	O
the	O
ground	O
truth	O
labels	O
(	O
subsampled	O
by	O
8	O
)	O
.	O
	
We	O
optimize	O
the	O
objective	B-Metric
function	I-Metric
with	O
respect	O
to	O
the	O
weights	O
at	O
all	O
network	O
layers	O
by	O
the	O
standard	O
SGD	B-Method
procedure	I-Method
of	O
KrizhevskyNIPS2013	O
.	O
	
During	O
testing	O
,	O
we	O
need	O
class	O
score	O
maps	O
at	O
the	O
original	O
image	O
resolution	O
.	O
	
As	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
and	O
further	O
elaborated	O
in	O
Section	O
[	O
reference	O
]	O
,	O
the	O
class	O
score	O
maps	O
(	O
corresponding	O
to	O
log	O
-	O
probabilities	O
)	O
are	O
quite	O
smooth	O
,	O
which	O
allows	O
us	O
to	O
use	O
simple	O
bilinear	B-Method
interpolation	I-Method
to	O
increase	O
their	O
resolution	O
by	O
a	O
factor	O
of	O
8	O
at	O
a	O
negligible	O
computational	B-Metric
cost	I-Metric
.	O
	
Note	O
that	O
the	O
method	O
of	O
long2014fully	O
does	O
not	O
use	O
the	O
hole	B-Method
algorithm	I-Method
and	O
produces	O
very	O
coarse	O
scores	O
(	O
subsampled	O
by	O
a	O
factor	O
of	O
32	O
)	O
at	O
the	O
CNN	O
output	O
.	O
	
This	O
forced	O
them	O
to	O
use	O
learned	O
upsampling	B-Method
layers	I-Method
,	O
significantly	O
increasing	O
the	O
complexity	B-Metric
and	O
training	B-Metric
time	I-Metric
of	O
their	O
system	O
:	O
	
Fine	O
-	O
tuning	O
our	O
network	O
on	O
PASCAL	B-Material
VOC	I-Material
2012	I-Material
takes	O
about	O
10	O
hours	O
,	O
while	O
they	O
report	O
a	O
training	B-Metric
time	I-Metric
of	O
several	O
days	O
(	O
both	O
timings	O
on	O
a	O
modern	O
GPU	B-Method
)	O
.	O
	
subsection	O
:	O
Controlling	O
the	O
Receptive	O
Field	O
Size	O
and	O
Accelerating	O
Dense	B-Task
Computation	I-Task
with	O
Convolutional	B-Method
Nets	I-Method
	
Another	O
key	O
ingredient	O
in	O
re	O
-	O
purposing	O
our	O
network	O
for	O
dense	B-Task
score	I-Task
computation	I-Task
is	O
explicitly	O
controlling	O
the	O
network	O
’s	O
receptive	O
field	O
size	O
.	O
	
Most	O
recent	O
DCNN	B-Method
-	I-Method
based	I-Method
image	I-Method
recognition	I-Method
methods	I-Method
rely	O
on	O
networks	B-Method
pre	O
-	O
trained	O
on	O
the	O
Imagenet	B-Task
large	I-Task
-	I-Task
scale	I-Task
classification	I-Task
task	I-Task
.	O
	
These	O
networks	O
typically	O
have	O
large	O
receptive	O
field	O
size	O
:	O
in	O
the	O
case	O
of	O
the	O
VGG	B-Method
-	I-Method
16	I-Method
net	I-Method
we	O
consider	O
,	O
its	O
receptive	O
field	O
is	O
(	O
with	O
zero	O
-	O
padding	O
)	O
and	O
pixels	O
if	O
the	O
net	O
is	O
applied	O
convolutionally	B-Method
.	O
	
After	O
converting	O
the	O
network	O
to	O
a	O
fully	B-Method
convolutional	I-Method
one	I-Method
,	O
the	O
first	O
fully	B-Method
connected	I-Method
layer	I-Method
has	O
4	O
,	O
096	O
filters	O
of	O
large	O
spatial	O
size	O
and	O
becomes	O
the	O
computational	O
bottleneck	O
in	O
our	O
dense	B-Task
score	I-Task
map	I-Task
computation	I-Task
.	O
	
We	O
have	O
addressed	O
this	O
practical	O
problem	O
by	O
spatially	B-Method
subsampling	I-Method
(	O
by	O
simple	O
decimation	B-Method
)	O
the	O
first	B-Method
FC	I-Method
layer	I-Method
to	O
(	O
or	O
)	O
spatial	O
size	O
.	O
	
This	O
has	O
reduced	O
the	O
receptive	O
field	O
of	O
the	O
network	O
down	O
to	O
(	O
with	O
zero	O
-	O
padding	O
)	O
or	O
(	O
in	O
convolutional	O
mode	O
)	O
and	O
has	O
reduced	O
computation	B-Metric
time	I-Metric
for	O
the	O
first	O
FC	B-Method
layer	I-Method
by	O
times	O
.	O
	
Using	O
our	O
Caffe	B-Method
-	I-Method
based	I-Method
implementation	I-Method
and	O
a	O
Titan	B-Method
GPU	I-Method
,	O
the	O
resulting	O
VGG	B-Method
-	I-Method
derived	I-Method
network	I-Method
is	O
very	O
efficient	O
:	O
	
Given	O
a	O
input	O
image	O
,	O
it	O
produces	O
dense	O
raw	O
feature	O
scores	O
at	O
the	O
top	O
of	O
the	O
network	O
at	O
a	O
rate	O
of	O
about	O
8	O
frames	B-Metric
/	I-Metric
sec	I-Metric
during	O
testing	O
.	O
	
The	O
speed	O
during	O
training	B-Task
is	O
3	O
frames	B-Metric
/	I-Metric
sec	I-Metric
.	O
	
We	O
have	O
also	O
successfully	O
experimented	O
with	O
reducing	O
the	O
number	O
of	O
channels	O
at	O
the	O
fully	O
connected	O
layers	O
from	O
4	O
,	O
096	O
down	O
to	O
1	O
,	O
024	O
,	O
considerably	O
further	O
decreasing	O
computation	B-Metric
time	I-Metric
and	O
memory	B-Metric
footprint	I-Metric
without	O
sacrificing	O
performance	O
,	O
as	O
detailed	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Using	O
smaller	B-Method
networks	I-Method
such	O
as	O
KrizhevskyNIPS2013	O
could	O
allow	O
video	O
-	O
rate	O
test	O
-	O
time	O
dense	B-Task
feature	I-Task
computation	I-Task
even	O
on	O
light	O
-	O
weight	O
GPUs	O
.	O
	
section	O
:	O
Detailed	B-Task
Boundary	I-Task
Recovery	I-Task
:	O
Fully	B-Task
-	I-Task
Connected	I-Task
Conditional	I-Task
Random	I-Task
Fields	I-Task
and	O
Multi	B-Task
-	I-Task
scale	I-Task
Prediction	I-Task
	
subsection	O
:	O
Deep	B-Method
Convolutional	I-Method
Networks	I-Method
and	O
the	O
Localization	B-Task
Challenge	I-Task
	
As	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
DCNN	B-Method
score	I-Method
maps	I-Method
can	O
reliably	O
predict	O
the	O
presence	O
and	O
rough	O
position	O
of	O
objects	O
in	O
an	O
image	O
but	O
are	O
less	O
well	O
suited	O
for	O
pin	O
-	O
pointing	O
their	O
exact	O
outline	O
.	O
	
There	O
is	O
a	O
natural	O
trade	O
-	O
off	O
between	O
classification	B-Metric
accuracy	I-Metric
and	O
localization	B-Metric
accuracy	I-Metric
with	O
convolutional	B-Method
networks	I-Method
:	O
Deeper	B-Method
models	I-Method
with	O
multiple	O
max	B-Method
-	I-Method
pooling	I-Method
layers	I-Method
have	O
proven	O
most	O
successful	O
in	O
classification	B-Task
tasks	I-Task
,	O
however	O
their	O
increased	O
invariance	O
and	O
large	O
receptive	O
fields	O
make	O
the	O
problem	O
of	O
inferring	O
position	O
from	O
the	O
scores	O
at	O
their	O
top	O
output	O
levels	O
more	O
challenging	O
.	O
	
Recent	O
work	O
has	O
pursued	O
two	O
directions	O
to	O
address	O
this	O
localization	B-Task
challenge	I-Task
.	O
	
The	O
first	O
approach	O
is	O
to	O
harness	O
information	O
from	O
multiple	O
layers	O
in	O
the	O
convolutional	B-Method
network	I-Method
in	O
order	O
to	O
better	O
estimate	O
the	O
object	O
boundaries	O
long2014fully	O
,	O
eigen2014predicting	O
.	O
	
The	O
second	O
approach	O
is	O
to	O
employ	O
a	O
super	B-Method
-	I-Method
pixel	I-Method
representation	I-Method
,	O
essentially	O
delegating	O
the	O
localization	B-Task
task	I-Task
to	O
a	O
low	B-Method
-	I-Method
level	I-Method
segmentation	I-Method
method	I-Method
.	O
	
This	O
route	O
is	O
followed	O
by	O
the	O
very	O
successful	O
recent	O
method	O
of	O
mostajabi2014feedforward	O
.	O
	
In	O
Section	O
[	O
reference	O
]	O
,	O
we	O
pursue	O
a	O
novel	O
alternative	O
direction	O
based	O
on	O
coupling	O
the	O
recognition	B-Metric
capacity	I-Metric
of	O
DCNNs	B-Method
and	O
the	O
fine	B-Metric
-	I-Metric
grained	I-Metric
localization	I-Metric
accuracy	I-Metric
of	O
fully	B-Method
connected	I-Method
CRFs	I-Method
and	O
show	O
that	O
it	O
is	O
remarkably	O
successful	O
in	O
addressing	O
the	O
localization	B-Task
challenge	I-Task
,	O
producing	O
accurate	O
semantic	B-Task
segmentation	I-Task
results	O
and	O
recovering	O
object	O
boundaries	O
at	O
a	O
level	O
of	O
detail	O
that	O
is	O
well	O
beyond	O
the	O
reach	O
of	O
existing	O
methods	O
.	O
	
subsection	O
:	O
Fully	B-Method
-	I-Method
Connected	I-Method
Conditional	I-Method
Random	I-Method
Fields	I-Method
for	O
Accurate	B-Task
Localization	I-Task
	
Traditionally	O
,	O
conditional	B-Method
random	I-Method
fields	I-Method
(	O
CRFs	B-Method
)	O
have	O
been	O
employed	O
to	O
smooth	O
noisy	O
segmentation	O
maps	O
rother2004grabcut	O
,	O
kohli2009robust	O
.	O
	
Typically	O
these	O
models	O
contain	O
energy	O
terms	O
that	O
couple	O
neighboring	O
nodes	O
,	O
favoring	O
same	O
-	O
label	O
assignments	O
to	O
spatially	O
proximal	O
pixels	O
.	O
	
Qualitatively	O
,	O
the	O
primary	O
function	O
of	O
these	O
short	B-Method
-	I-Method
range	I-Method
CRFs	I-Method
has	O
been	O
to	O
clean	O
up	O
the	O
spurious	O
predictions	O
of	O
weak	B-Method
classifiers	I-Method
built	O
on	O
top	O
of	O
local	O
hand	O
-	O
engineered	O
features	O
.	O
	
Compared	O
to	O
these	O
weaker	O
classifiers	B-Method
,	O
modern	O
DCNN	B-Method
architectures	I-Method
such	O
as	O
the	O
one	O
we	O
use	O
in	O
this	O
work	O
produce	O
score	B-Metric
maps	I-Metric
and	O
semantic	B-Task
label	I-Task
predictions	I-Task
which	O
are	O
qualitatively	O
different	O
.	O
	
As	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
the	O
score	B-Metric
maps	I-Metric
are	O
typically	O
quite	O
smooth	O
and	O
produce	O
homogeneous	O
classification	B-Task
results	O
.	O
	
In	O
this	O
regime	O
,	O
using	O
short	B-Method
-	I-Method
range	I-Method
CRFs	I-Method
can	O
be	O
detrimental	O
,	O
as	O
our	O
goal	O
should	O
be	O
to	O
recover	O
detailed	O
local	O
structure	O
rather	O
than	O
further	O
smooth	O
it	O
.	O
	
Using	O
contrast	O
-	O
sensitive	O
potentials	O
rother2004grabcut	O
in	O
conjunction	O
to	O
local	B-Method
-	I-Method
range	I-Method
CRFs	I-Method
can	O
potentially	O
improve	O
localization	B-Task
but	O
still	O
miss	O
thin	O
-	O
structures	O
and	O
typically	O
requires	O
solving	O
an	O
expensive	O
discrete	B-Task
optimization	I-Task
problem	I-Task
.	O
	
To	O
overcome	O
these	O
limitations	O
of	O
short	B-Method
-	I-Method
range	I-Method
CRFs	I-Method
,	O
we	O
integrate	O
into	O
our	O
system	O
the	O
fully	O
connected	O
CRF	B-Method
model	O
of	O
krahenbuhl2011efficient	O
.	O
	
The	O
model	O
employs	O
the	O
energy	O
function	O
where	O
is	O
the	O
label	O
assignment	O
for	O
pixels	O
.	O
	
We	O
use	O
as	O
unary	O
potential	O
,	O
where	O
is	O
the	O
label	O
assignment	O
probability	O
at	O
pixel	O
as	O
computed	O
by	O
DCNN	B-Method
.	O
	
The	O
pairwise	O
potential	O
is	O
,	O
where	O
,	O
and	O
zero	O
otherwise	O
(	O
i.e	O
.	O
,	O
Potts	B-Method
Model	I-Method
)	O
.	O
	
There	O
is	O
one	O
pairwise	O
term	O
for	O
each	O
pair	O
of	O
pixels	O
and	O
in	O
the	O
image	O
no	O
matter	O
how	O
far	O
from	O
each	O
other	O
they	O
lie	O
,	O
i.e	O
.	O
	
the	O
model	O
	
’s	O
factor	B-Method
graph	I-Method
is	O
fully	O
connected	O
.	O
	
Each	O
is	O
the	O
Gaussian	B-Method
kernel	I-Method
depends	O
on	O
features	O
(	O
denoted	O
as	O
)	O
extracted	O
for	O
pixel	O
and	O
and	O
is	O
weighted	O
by	O
parameter	O
.	O
	
We	O
adopt	O
bilateral	O
position	O
and	O
color	O
terms	O
,	O
specifically	O
,	O
the	O
kernels	O
are	O
where	O
the	O
first	O
kernel	O
depends	O
on	O
both	O
pixel	O
positions	O
(	O
denoted	O
as	O
)	O
and	O
pixel	O
color	O
intensities	O
(	O
denoted	O
as	O
)	O
,	O
and	O
the	O
second	O
kernel	O
only	O
depends	O
on	O
pixel	O
positions	O
.	O
	
The	O
hyper	O
parameters	O
,	O
and	O
control	O
the	O
“	O
scale	O
”	O
of	O
the	O
Gaussian	B-Method
kernels	I-Method
.	O
	
Crucially	O
,	O
this	O
model	O
is	O
amenable	O
to	O
efficient	O
approximate	B-Task
probabilistic	I-Task
inference	I-Task
krahenbuhl2011efficient	O
.	O
	
The	O
message	B-Method
passing	I-Method
updates	I-Method
under	O
a	O
fully	B-Method
decomposable	I-Method
mean	I-Method
field	I-Method
approximation	I-Method
can	O
be	O
expressed	O
as	O
convolutions	B-Method
with	O
a	O
Gaussian	B-Method
kernel	I-Method
in	O
feature	O
space	O
.	O
	
High	B-Method
-	I-Method
dimensional	I-Method
filtering	I-Method
algorithms	I-Method
	
adams2010fast	O
significantly	O
speed	O
-	O
up	O
	
this	O
computation	O
resulting	O
in	O
an	O
algorithm	O
that	O
is	O
very	O
fast	O
in	O
practice	O
,	O
less	O
that	O
0.5	O
sec	O
on	O
average	O
for	O
Pascal	B-Material
VOC	I-Material
images	I-Material
using	O
the	O
publicly	O
available	O
implementation	O
of	O
krahenbuhl2011efficient	O
.	O
	
subsection	O
:	O
Multi	B-Task
-	I-Task
Scale	I-Task
Prediction	I-Task
	
Following	O
the	O
promising	O
recent	O
results	O
of	O
hariharan2014hypercolumns	O
,	O
long2014fully	O
we	O
have	O
also	O
explored	O
a	O
multi	B-Method
-	I-Method
scale	I-Method
prediction	I-Method
method	I-Method
to	O
increase	O
the	O
boundary	B-Metric
localization	I-Metric
accuracy	I-Metric
.	O
	
Specifically	O
,	O
we	O
attach	O
to	O
the	O
input	O
image	O
and	O
the	O
output	O
of	O
each	O
of	O
the	O
first	O
four	O
max	B-Method
pooling	I-Method
layers	I-Method
a	O
two	O
-	O
layer	B-Method
MLP	I-Method
(	O
first	O
layer	O
:	O
128	O
3x3	B-Method
convolutional	I-Method
filters	I-Method
,	O
second	O
layer	O
:	O
128	O
1x1	O
convolutional	B-Method
filters	I-Method
)	O
whose	O
feature	O
map	O
is	O
concatenated	O
to	O
the	O
main	B-Method
network	I-Method
’s	O
last	B-Method
layer	I-Method
feature	I-Method
map	I-Method
.	O
	
The	O
aggregate	O
feature	O
map	O
fed	O
into	O
the	O
softmax	B-Method
layer	I-Method
is	O
thus	O
enhanced	O
by	O
5	O
*	O
128	O
=	O
640	O
channels	O
.	O
	
We	O
only	O
adjust	O
the	O
newly	O
added	O
weights	O
,	O
keeping	O
the	O
other	O
network	O
parameters	O
to	O
the	O
values	O
learned	O
by	O
the	O
method	O
of	O
Section	O
[	O
reference	O
]	O
.	O
	
As	O
discussed	O
in	O
the	O
experimental	O
section	O
,	O
introducing	O
these	O
extra	O
direct	O
connections	O
from	O
fine	O
-	O
resolution	O
layers	O
improves	O
localization	B-Task
performance	O
,	O
yet	O
the	O
effect	O
is	O
not	O
as	O
dramatic	O
as	O
the	O
one	O
obtained	O
with	O
the	O
fully	O
-	O
connected	O
CRF	B-Method
.	O
	
section	O
:	O
Experimental	O
Evaluation	O
	
paragraph	O
:	O
Dataset	O
	
We	O
test	O
our	O
DeepLab	B-Method
model	I-Method
on	O
the	O
PASCAL	B-Material
VOC	I-Material
2012	I-Material
segmentation	O
benchmark	O
everingham2014pascal	O
,	O
consisting	O
of	O
20	O
foreground	O
object	O
classes	O
and	O
one	O
background	O
class	O
.	O
	
The	O
original	O
dataset	O
contains	O
,	O
,	O
and	O
images	O
for	O
training	O
,	O
validation	B-Task
,	O
and	O
testing	B-Task
,	O
respectively	O
.	O
	
The	O
dataset	O
is	O
augmented	O
by	O
the	O
extra	O
annotations	O
provided	O
by	O
hariharan2011semantic	O
,	O
resulting	O
in	O
training	O
images	O
.	O
	
The	O
performance	O
is	O
measured	O
in	O
terms	O
of	O
pixel	B-Metric
intersection	I-Metric
-	I-Metric
over	I-Metric
-	I-Metric
union	I-Metric
(	O
IOU	B-Metric
)	O
averaged	O
across	O
the	O
21	O
classes	O
.	O
	
paragraph	O
:	O
Training	O
	
We	O
adopt	O
the	O
simplest	O
form	O
of	O
piecewise	B-Method
training	I-Method
,	O
decoupling	O
the	O
DCNN	O
and	O
CRF	B-Method
training	O
stages	O
,	O
assuming	O
the	O
unary	O
terms	O
provided	O
by	O
the	O
DCNN	B-Method
are	O
fixed	O
during	O
CRF	B-Method
training	O
.	O
	
For	O
DCNN	B-Task
training	I-Task
we	O
employ	O
the	O
VGG	B-Method
-	I-Method
16	I-Method
network	I-Method
which	O
has	O
been	O
pre	O
-	O
trained	O
on	O
ImageNet	O
.	O
	
We	O
fine	O
-	O
tuned	O
the	O
VGG	B-Method
-	I-Method
16	I-Method
network	I-Method
on	O
the	O
VOC	B-Task
21	I-Task
-	I-Task
way	I-Task
pixel	I-Task
-	I-Task
classification	I-Task
task	I-Task
by	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
on	O
the	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
loss	I-Metric
function	I-Metric
,	O
as	O
described	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
We	O
use	O
a	O
mini	O
-	O
batch	O
of	O
20	O
images	O
and	O
initial	O
learning	B-Metric
rate	I-Metric
of	O
(	O
for	O
the	O
final	O
classifier	B-Method
layer	I-Method
)	O
,	O
multiplying	O
the	O
learning	B-Metric
rate	I-Metric
by	O
0.1	O
at	O
every	O
2000	O
iterations	O
.	O
	
We	O
use	O
momentum	O
of	O
and	O
a	O
weight	O
decay	O
of	O
.	O
	
After	O
the	O
DCNN	B-Method
has	O
been	O
fine	O
-	O
tuned	O
,	O
we	O
cross	O
-	O
validate	O
the	O
parameters	O
of	O
the	O
fully	O
connected	O
CRF	B-Method
model	O
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
along	O
the	O
lines	O
of	O
krahenbuhl2011efficient	O
.	O
	
We	O
use	O
the	O
default	O
values	O
of	O
	
and	O
	
and	O
we	O
search	O
for	O
the	O
best	O
values	O
of	O
,	O
,	O
and	O
by	O
cross	B-Method
-	I-Method
validation	I-Method
on	O
a	O
small	O
subset	O
of	O
the	O
validation	O
set	O
(	O
we	O
use	O
100	O
images	O
)	O
.	O
	
We	O
employ	O
coarse	B-Method
-	I-Method
to	I-Method
-	I-Method
fine	I-Method
search	I-Method
scheme	I-Method
.	O
	
Specifically	O
,	O
the	O
initial	O
search	O
range	O
of	O
the	O
parameters	O
are	O
,	O
and	O
(	O
MATLAB	O
notation	O
)	O
,	O
and	O
then	O
we	O
refine	O
the	O
search	O
step	O
sizes	O
around	O
the	O
first	O
round	O
’s	O
best	O
values	O
.	O
	
We	O
fix	O
the	O
number	O
of	O
mean	O
field	O
iterations	O
to	O
10	O
for	O
all	O
reported	O
experiments	O
.	O
	
paragraph	O
:	O
Evaluation	O
on	O
Validation	B-Metric
set	I-Metric
	
We	O
conduct	O
the	O
majority	O
of	O
our	O
evaluations	O
on	O
the	O
PASCAL	B-Material
	
‘	O
val	O
’	O
set	O
,	O
training	O
our	O
model	O
on	O
the	O
augmented	B-Material
PASCAL	I-Material
‘	I-Material
train	I-Material
’	I-Material
set	I-Material
.	O
	
As	O
shown	O
in	O
Tab	O
.	O
	
[	O
reference	O
]	O
(	O
a	O
)	O
,	O
incorporating	O
the	O
fully	O
connected	O
CRF	B-Method
to	O
our	O
model	O
(	O
denoted	O
by	O
DeepLab	B-Method
-	I-Method
CRF	I-Method
)	O
yields	O
a	O
substantial	O
performance	O
boost	O
,	O
about	O
4	O
%	O
improvement	O
over	O
DeepLab	B-Method
.	O
	
We	O
note	O
that	O
the	O
work	O
of	O
krahenbuhl2011efficient	O
improved	O
the	O
result	O
of	O
TextonBoost	O
shotton2009textonboost	O
to	O
,	O
which	O
makes	O
the	O
improvement	O
we	O
report	O
here	O
(	O
from	O
to	O
)	O
all	O
the	O
more	O
impressive	O
.	O
	
Turning	O
to	O
qualitative	O
results	O
,	O
we	O
provide	O
visual	O
comparisons	O
between	O
DeepLab	B-Method
and	O
DeepLab	B-Method
-	I-Method
CRF	I-Method
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Employing	O
a	O
fully	O
connected	O
CRF	B-Method
significantly	O
improves	O
the	O
results	O
,	O
allowing	O
the	O
model	O
to	O
accurately	O
capture	O
intricate	O
object	O
boundaries	O
.	O
	
paragraph	O
:	O
Multi	O
-	O
Scale	O
features	O
	
We	O
also	O
exploit	O
the	O
features	O
from	O
the	O
intermediate	O
layers	O
,	O
similar	O
to	O
hariharan2014hypercolumns	O
,	O
long2014fully	O
.	O
	
As	O
shown	O
in	O
Tab	O
.	O
	
[	O
reference	O
]	O
(	O
a	O
)	O
,	O
adding	O
the	O
multi	O
-	O
scale	O
features	O
to	O
our	O
DeepLab	B-Method
model	I-Method
(	O
denoted	O
as	O
DeepLab	B-Method
-	I-Method
MSc	I-Method
)	O
improves	O
about	O
performance	O
,	O
and	O
	
further	O
incorporating	O
the	O
fully	O
connected	O
CRF	B-Method
(	O
denoted	O
as	O
DeepLab	B-Method
-	I-Method
MSc	I-Method
-	I-Method
CRF	I-Method
)	O
yields	O
about	O
4	O
%	O
improvement	O
.	O
	
The	O
qualitative	O
comparisons	O
between	O
DeepLab	B-Method
and	O
DeepLab	B-Method
-	I-Method
MSc	I-Method
are	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Leveraging	O
the	O
multi	O
-	O
scale	O
features	O
can	O
slightly	O
refine	O
the	O
object	O
boundaries	O
.	O
	
paragraph	O
:	O
Field	O
of	O
View	O
	
The	O
‘	O
atrous	B-Method
algorithm	I-Method
’	O
we	O
employed	O
allows	O
us	O
to	O
arbitrarily	O
control	O
the	O
Field	O
-	O
of	O
-	O
View	O
(	O
FOV	O
)	O
of	O
the	O
models	O
by	O
adjusting	O
the	O
input	O
stride	O
,	O
as	O
illustrated	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
In	O
Tab	O
.	O
	
[	O
reference	O
]	O
	
,	O
we	O
experiment	O
with	O
several	O
kernel	O
sizes	O
and	O
input	O
strides	O
at	O
the	O
first	O
fully	B-Method
connected	I-Method
layer	I-Method
.	O
	
The	O
method	O
,	O
DeepLab	B-Method
-	I-Method
CRF	I-Method
-	I-Method
7x7	I-Method
,	O
is	O
the	O
direct	O
modification	O
from	O
VGG	B-Method
-	I-Method
16	I-Method
net	I-Method
,	O
where	O
the	O
kernel	O
size	O
=	O
and	O
input	O
stride	O
=	O
4	O
.	O
	
This	O
model	O
yields	O
performance	O
of	O
on	O
the	O
‘	O
val	O
’	O
set	O
,	O
but	O
it	O
is	O
relatively	O
slow	O
(	O
images	O
per	O
second	O
during	O
training	O
)	O
.	O
	
We	O
have	O
improved	O
model	B-Metric
speed	I-Metric
to	O
images	O
per	O
second	O
by	O
reducing	O
the	O
kernel	O
size	O
to	O
.	O
	
We	O
have	O
experimented	O
with	O
two	O
such	O
network	B-Method
variants	I-Method
with	O
different	O
FOV	O
sizes	O
,	O
DeepLab	B-Method
-	I-Method
CRF	I-Method
and	O
DeepLab	B-Method
-	I-Method
CRF	I-Method
-	I-Method
4x4	I-Method
;	O
the	O
latter	O
has	O
large	O
FOV	O
(	O
i.e	O
.	O
,	O
large	O
input	O
stride	O
)	O
and	O
attains	O
better	O
performance	O
.	O
	
Finally	O
,	O
we	O
employ	O
kernel	O
size	O
and	O
input	O
stride	O
=	O
12	O
,	O
and	O
further	O
change	O
the	O
filter	O
sizes	O
from	O
4096	O
to	O
1024	O
for	O
the	O
last	O
two	O
layers	O
.	O
	
Interestingly	O
,	O
the	O
resulting	O
model	O
,	O
DeepLab	B-Method
-	I-Method
CRF	I-Method
-	I-Method
LargeFOV	I-Method
,	O
matches	O
the	O
performance	O
of	O
the	O
expensive	O
DeepLab	B-Method
-	I-Method
CRF	I-Method
-	I-Method
7x7	I-Method
.	O
	
At	O
the	O
same	O
time	O
,	O
it	O
is	O
times	O
faster	O
to	O
run	O
and	O
has	O
significantly	O
fewer	O
parameters	O
(	O
20.5	O
M	O
instead	O
of	O
134.3	O
M	O
)	O
.	O
	
The	O
performance	O
of	O
several	O
model	O
variants	O
is	O
summarized	O
in	O
Tab	O
.	O
	
[	O
reference	O
]	O
,	O
showing	O
the	O
benefit	O
of	O
exploiting	O
multi	O
-	O
scale	O
features	O
and	O
large	O
FOV	O
.	O
	
paragraph	O
:	O
Mean	B-Metric
Pixel	I-Metric
IOU	I-Metric
along	O
Object	O
Boundaries	O
	
To	O
quantify	O
the	O
accuracy	B-Metric
of	O
the	O
proposed	O
model	O
near	O
object	O
boundaries	O
,	O
we	O
evaluate	O
the	O
segmentation	B-Metric
accuracy	I-Metric
with	O
an	O
experiment	O
similar	O
to	O
kohli2009robust	O
,	O
krahenbuhl2011efficient	O
.	O
	
Specifically	O
,	O
we	O
use	O
the	O
‘	O
void	O
’	O
label	O
annotated	O
in	O
val	O
set	O
,	O
which	O
usually	O
occurs	O
around	O
object	O
boundaries	O
.	O
	
We	O
compute	O
the	O
mean	B-Metric
IOU	I-Metric
for	O
those	O
pixels	O
that	O
are	O
located	O
within	O
a	O
narrow	O
band	O
(	O
called	O
trimap	O
)	O
of	O
‘	O
void	O
’	O
labels	O
.	O
	
As	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
exploiting	O
the	O
multi	O
-	O
scale	O
features	O
from	O
the	O
intermediate	O
layers	O
and	O
refining	O
the	O
segmentation	B-Task
results	O
by	O
a	O
fully	O
connected	O
CRF	B-Method
significantly	O
improve	O
the	O
results	O
around	O
object	O
boundaries	O
.	O
	
paragraph	O
:	O
Comparison	O
with	O
State	O
-	O
of	O
-	O
art	O
	
In	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
we	O
qualitatively	O
compare	O
our	O
proposed	O
model	O
,	O
DeepLab	B-Method
-	I-Method
CRF	I-Method
,	O
with	O
two	O
state	O
-	O
of	O
-	O
art	O
models	O
:	O
	
FCN	B-Method
-	I-Method
8s	I-Method
	
long2014fully	O
and	O
TTI	O
-	O
Zoomout	O
-	O
16	O
mostajabi2014feedforward	O
on	O
the	O
‘	O
val	O
’	O
set	O
(	O
the	O
results	O
are	O
extracted	O
from	O
their	O
papers	O
)	O
.	O
	
Our	O
model	O
is	O
able	O
to	O
capture	O
the	O
intricate	O
object	O
boundaries	O
.	O
	
paragraph	O
:	O
Reproducibility	O
	
We	O
have	O
implemented	O
the	O
proposed	O
methods	O
by	O
extending	O
the	O
excellent	B-Method
Caffe	I-Method
framework	I-Method
jia2014caffe	O
.	O
	
We	O
share	O
our	O
source	O
code	O
,	O
configuration	O
files	O
,	O
and	O
trained	O
models	O
that	O
allow	O
reproducing	O
the	O
results	O
in	O
this	O
paper	O
at	O
a	O
companion	O
web	O
site	O
.	O
	
paragraph	O
:	O
Test	O
set	O
results	O
	
Having	O
set	O
our	O
model	O
choices	O
on	O
the	O
validation	O
set	O
,	O
we	O
evaluate	O
our	O
model	O
variants	O
on	O
the	O
PASCAL	B-Material
	
VOC	B-Material
2012	I-Material
official	O
‘	O
test	O
’	O
set	O
.	O
	
As	O
shown	O
in	O
Tab	O
.	O
	
[	O
reference	O
]	O
,	O
	
our	O
DeepLab	B-Method
-	I-Method
CRF	I-Method
and	O
DeepLab	B-Method
-	I-Method
MSc	I-Method
-	I-Method
CRF	I-Method
models	O
achieve	O
performance	O
of	O
and	O
mean	B-Metric
IOU	I-Metric
,	O
respectively	O
.	O
	
Our	O
models	O
outperform	O
all	O
the	O
other	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
(	O
specifically	O
,	O
TTI	O
-	O
Zoomout	O
-	O
16	O
mostajabi2014feedforward	O
,	O
	
FCN	B-Method
-	I-Method
8s	I-Method
	
long2014fully	O
,	O
and	O
MSRA	O
-	O
CFM	O
dai2014convolutional	O
)	O
.	O
	
When	O
we	O
increase	O
the	O
FOV	O
of	O
the	O
models	O
,	O
DeepLab	B-Method
-	I-Method
CRF	I-Method
-	I-Method
LargeFOV	I-Method
yields	O
performance	O
of	O
,	O
the	O
same	O
as	O
DeepLab	B-Method
-	I-Method
CRF	I-Method
-	I-Method
7x7	I-Method
,	O
while	O
its	O
training	B-Metric
speed	I-Metric
is	O
faster	O
.	O
	
Furthermore	O
,	O
our	O
best	O
model	O
,	O
DeepLab	B-Method
-	I-Method
MSc	I-Method
-	I-Method
CRF	I-Method
-	I-Method
LargeFOV	I-Method
,	O
attains	O
the	O
best	O
performance	O
of	O
by	O
employing	O
both	O
multi	O
-	O
scale	O
features	O
and	O
large	O
FOV	O
.	O
	
section	O
:	O
Discussion	O
	
Our	O
work	O
combines	O
ideas	O
from	O
deep	B-Method
convolutional	I-Method
neural	I-Method
networks	I-Method
and	O
fully	B-Method
-	I-Method
connected	I-Method
conditional	I-Method
random	I-Method
fields	I-Method
,	O
yielding	O
a	O
novel	O
method	O
able	O
to	O
produce	O
semantically	B-Task
accurate	I-Task
predictions	I-Task
and	O
detailed	B-Task
segmentation	I-Task
maps	I-Task
,	O
while	O
being	O
computationally	O
efficient	O
.	O
	
Our	O
experimental	O
results	O
show	O
that	O
the	O
proposed	O
method	O
significantly	O
advances	O
the	O
state	O
-	O
of	O
-	O
art	O
in	O
the	O
challenging	O
PASCAL	B-Material
VOC	I-Material
2012	I-Material
semantic	O
image	B-Task
segmentation	I-Task
task	O
.	O
	
There	O
are	O
multiple	O
aspects	O
in	O
our	O
model	O
that	O
we	O
intend	O
to	O
refine	O
,	O
such	O
as	O
fully	O
integrating	O
its	O
two	O
main	O
components	O
(	O
CNN	B-Method
and	O
CRF	B-Method
)	O
and	O
train	O
the	O
whole	O
system	O
in	O
an	O
end	O
-	O
to	O
-	O
end	O
fashion	O
,	O
similar	O
to	O
Koltun13	O
,	O
chen2014learning	O
,	O
zheng2015crfrnn	O
.	O
	
We	O
also	O
plan	O
to	O
experiment	O
with	O
more	O
datasets	O
and	O
apply	O
our	O
method	O
to	O
other	O
sources	O
of	O
data	O
such	O
as	O
depth	O
maps	O
or	O
videos	O
.	O
	
Recently	O
,	O
we	O
have	O
pursued	O
model	B-Task
training	I-Task
with	O
weakly	O
supervised	O
annotations	O
,	O
in	O
the	O
form	O
of	O
bounding	O
boxes	O
or	O
image	O
-	O
level	O
labels	O
papandreou15weak	O
.	O
	
At	O
a	O
higher	O
level	O
,	O
our	O
work	O
lies	O
in	O
the	O
intersection	O
of	O
convolutional	B-Method
neural	I-Method
networks	I-Method
and	O
probabilistic	B-Method
graphical	I-Method
models	I-Method
.	O
	
We	O
plan	O
to	O
further	O
investigate	O
the	O
interplay	O
of	O
these	O
two	O
powerful	O
classes	O
of	O
methods	O
and	O
explore	O
their	O
synergistic	O
potential	O
for	O
solving	O
challenging	O
computer	B-Task
vision	I-Task
tasks	I-Task
.	O
	
subsection	O
:	O
Acknowledgments	O
	
This	O
work	O
was	O
partly	O
supported	O
by	O
ARO	O
62250	O
-	O
CS	O
,	O
NIH	O
Grant	O
5R01EY022247	O
-	O
03	O
,	O
EU	O
Project	O
RECONFIG	O
FP7	O
-	O
ICT	O
-	O
600825	O
and	O
EU	O
Project	O
MOBOT	O
FP7	O
-	O
ICT	O
-	O
2011	O
-	O
600796	O
.	O
	
We	O
also	O
gratefully	O
acknowledge	O
the	O
support	O
of	O
NVIDIA	O
Corporation	O
with	O
the	O
donation	O
of	O
GPUs	O
used	O
for	O
this	O
research	O
.	O
	
We	O
would	O
like	O
to	O
thank	O
the	O
anonymous	O
reviewers	O
for	O
their	O
detailed	O
comments	O
and	O
constructive	O
feedback	O
.	O
	
subsection	O
:	O
Paper	O
Revisions	O
	
Here	O
we	O
present	O
the	O
list	O
of	O
major	O
paper	O
revisions	O
for	O
the	O
convenience	O
of	O
the	O
readers	O
.	O
	
paragraph	O
:	O
v1	O
	
Submission	O
to	O
ICLR	O
2015	O
.	O
	
Introduces	O
the	O
model	B-Method
DeepLab	I-Method
-	I-Method
CRF	I-Method
,	O
which	O
attains	O
the	O
performance	O
of	O
on	O
PASCAL	B-Material
VOC	I-Material
2012	I-Material
test	O
set	O
.	O
	
paragraph	O
:	O
v2	O
	
Rebuttal	O
for	O
ICLR	O
2015	O
.	O
	
Adds	O
the	O
model	B-Method
DeepLab	I-Method
-	I-Method
MSc	I-Method
-	I-Method
CRF	I-Method
,	O
which	O
incorporates	O
multi	O
-	O
scale	O
features	O
from	O
the	O
intermediate	O
layers	O
.	O
	
DeepLab	B-Method
-	I-Method
MSc	I-Method
-	I-Method
CRF	I-Method
yields	O
the	O
performance	O
of	O
on	O
PASCAL	B-Material
VOC	I-Material
2012	I-Material
test	O
set	O
.	O
	
paragraph	O
:	O
v3	O
	
Camera	O
-	O
ready	O
for	O
ICLR	O
2015	O
.	O
	
Experiments	O
with	O
large	O
Field	O
-	O
Of	O
-	O
View	O
.	O
	
On	O
PASCAL	B-Material
VOC	I-Material
2012	I-Material
test	O
set	O
,	O
DeepLab	B-Method
-	I-Method
CRF	I-Method
-	I-Method
LargeFOV	I-Method
achieves	O
the	O
performance	O
of	O
.	O
	
When	O
exploiting	O
both	O
mutli	O
-	O
scale	O
features	O
and	O
large	O
FOV	O
,	O
DeepLab	B-Method
-	I-Method
MSc	I-Method
-	O
	
CRF	B-Method
-	O
LargeFOV	O
attains	O
the	O
performance	O
of	O
.	O
	
paragraph	O
:	O
v4	O
	
Reference	O
to	O
our	O
updated	O
“	O
DeepLab	B-Method
”	I-Method
system	I-Method
chen2016deeplab	O
with	O
much	O
improved	O
results	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
A	O
Decomposable	B-Method
Attention	I-Method
Model	I-Method
for	O
Natural	B-Task
Language	I-Task
Inference	I-Task
	
We	O
propose	O
a	O
simple	O
neural	B-Method
architecture	I-Method
for	O
natural	B-Task
language	I-Task
inference	I-Task
.	O
	
Our	O
approach	O
uses	O
attention	O
to	O
decompose	O
the	O
problem	O
into	O
subproblems	O
that	O
can	O
be	O
solved	O
separately	O
,	O
thus	O
making	O
it	O
trivially	O
parallelizable	O
.	O
	
On	O
the	O
Stanford	B-Material
Natural	I-Material
Language	I-Material
Inference	I-Material
(	O
SNLI	B-Material
)	I-Material
dataset	I-Material
,	O
we	O
obtain	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
with	O
almost	O
an	O
order	O
of	O
magnitude	O
fewer	O
parameters	O
than	O
previous	O
work	O
and	O
without	O
relying	O
on	O
any	O
word	O
-	O
order	O
information	O
.	O
	
Adding	O
intra	O
-	O
sentence	O
attention	O
that	O
takes	O
a	O
minimum	O
amount	O
of	O
order	O
into	O
account	O
yields	O
further	O
improvements	O
.	O
	
section	O
:	O
Introduction	O
	
Natural	B-Task
language	I-Task
inference	I-Task
(	O
NLI	B-Task
)	O
refers	O
to	O
the	O
problem	O
of	O
determining	B-Task
entailment	I-Task
and	I-Task
contradiction	I-Task
relationships	I-Task
between	O
a	O
premise	O
and	O
a	O
hypothesis	O
.	O
	
NLI	B-Task
is	O
a	O
central	O
problem	O
in	O
language	B-Task
understanding	I-Task
and	O
recently	O
the	O
large	O
SNLI	B-Material
corpus	I-Material
of	O
570	O
K	O
sentence	O
pairs	O
was	O
created	O
for	O
this	O
task	O
.	O
	
We	O
present	O
a	O
new	O
model	O
for	O
NLI	B-Task
and	O
leverage	O
this	O
corpus	O
for	O
comparison	O
with	O
prior	O
work	O
.	O
	
A	O
large	O
body	O
of	O
work	O
based	O
on	O
neural	B-Method
networks	I-Method
for	O
text	B-Task
similarity	I-Task
tasks	I-Task
including	O
NLI	B-Task
has	O
been	O
published	O
in	O
recent	O
years	O
.	O
	
The	O
dominating	O
trend	O
in	O
these	O
models	O
is	O
to	O
build	O
complex	O
,	O
deep	B-Method
text	I-Method
representation	I-Method
models	I-Method
,	O
for	O
example	O
,	O
with	O
convolutional	B-Method
networks	I-Method
or	O
long	B-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
networks	I-Method
with	O
the	O
goal	O
of	O
deeper	B-Task
sentence	I-Task
comprehension	I-Task
.	O
	
While	O
these	O
approaches	O
have	O
yielded	O
impressive	O
results	O
,	O
they	O
are	O
often	O
computationally	O
very	O
expensive	O
,	O
and	O
result	O
in	O
models	O
having	O
millions	O
of	O
parameters	O
(	O
excluding	O
embeddings	O
)	O
.	O
	
Here	O
,	O
we	O
take	O
a	O
different	O
approach	O
,	O
arguing	O
that	O
for	O
natural	B-Task
language	I-Task
inference	I-Task
it	O
can	O
often	O
suffice	O
to	O
simply	O
align	O
bits	O
of	O
local	O
text	O
substructure	O
and	O
then	O
aggregate	O
this	O
information	O
.	O
	
For	O
example	O
,	O
consider	O
the	O
following	O
sentences	O
:	O
Bob	O
is	O
in	O
his	O
room	O
,	O
but	O
because	O
of	O
the	O
thunder	O
and	O
lightning	O
outside	O
,	O
he	O
can	O
not	O
sleep	O
.	O
	
Bob	O
is	O
awake	O
.	O
	
It	O
is	O
sunny	O
outside	O
.	O
	
The	O
first	O
sentence	O
is	O
complex	O
in	O
structure	O
and	O
it	O
is	O
challenging	O
to	O
construct	O
a	O
compact	B-Method
representation	I-Method
that	O
expresses	O
its	O
entire	O
meaning	O
.	O
	
However	O
,	O
it	O
is	O
fairly	O
easy	O
to	O
conclude	O
that	O
the	O
second	O
sentence	O
follows	O
from	O
the	O
first	O
one	O
,	O
by	O
simply	O
aligning	O
Bob	O
with	O
Bob	O
and	O
can	O
not	O
sleep	O
with	O
awake	O
and	O
recognizing	O
that	O
these	O
are	O
synonyms	O
.	O
	
Similarly	O
,	O
one	O
can	O
conclude	O
that	O
It	O
is	O
sunny	O
outside	O
contradicts	O
the	O
first	O
sentence	O
,	O
by	O
aligning	O
thunder	O
and	O
lightning	O
with	O
sunny	O
and	O
recognizing	O
that	O
these	O
are	O
most	O
likely	O
incompatible	O
.	O
	
We	O
leverage	O
this	O
intuition	O
to	O
build	O
a	O
simpler	O
and	O
more	O
lightweight	O
approach	O
to	O
NLI	B-Task
within	O
a	O
neural	B-Method
framework	I-Method
;	O
with	O
considerably	O
fewer	O
parameters	O
,	O
our	O
model	O
outperforms	O
more	O
complex	O
existing	O
neural	B-Method
architectures	I-Method
.	O
	
In	O
contrast	O
to	O
existing	O
approaches	O
,	O
our	O
approach	O
only	O
relies	O
on	O
alignment	B-Method
and	O
is	O
fully	O
computationally	O
decomposable	O
with	O
respect	O
to	O
the	O
input	O
text	O
.	O
	
An	O
overview	O
of	O
our	O
approach	O
is	O
given	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Given	O
two	O
sentences	O
,	O
where	O
each	O
word	O
is	O
represented	O
by	O
an	O
embedding	O
vector	O
,	O
we	O
first	O
create	O
a	O
soft	O
alignment	O
matrix	O
using	O
neural	B-Method
attention	I-Method
.	O
	
We	O
then	O
use	O
the	O
(	O
soft	O
)	O
alignment	O
to	O
decompose	O
the	O
task	O
into	O
subproblems	O
that	O
are	O
solved	O
separately	O
.	O
	
Finally	O
,	O
the	O
results	O
of	O
these	O
subproblems	O
are	O
merged	O
to	O
produce	O
the	O
final	O
classification	B-Task
.	O
	
In	O
addition	O
,	O
we	O
optionally	O
apply	O
intra	O
-	O
sentence	O
attention	O
to	O
endow	O
the	O
model	O
with	O
a	O
richer	O
encoding	O
of	O
substructures	O
prior	O
to	O
the	O
alignment	B-Task
step	I-Task
.	O
	
Asymptotically	O
our	O
approach	O
does	O
the	O
same	O
total	O
work	O
as	O
a	O
vanilla	B-Method
LSTM	I-Method
encoder	I-Method
,	O
while	O
being	O
trivially	O
parallelizable	O
across	O
sentence	O
length	O
,	O
which	O
can	O
allow	O
for	O
considerable	O
speedups	O
in	O
low	B-Task
-	I-Task
latency	I-Task
settings	I-Task
.	O
	
Empirical	O
results	O
on	O
the	O
SNLI	B-Material
corpus	I-Material
show	O
that	O
our	O
approach	O
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
,	O
while	O
using	O
almost	O
an	O
order	O
of	O
magnitude	O
fewer	O
parameters	O
compared	O
to	O
complex	O
LSTM	B-Method
-	I-Method
based	I-Method
approaches	I-Method
.	O
	
section	O
:	O
Related	O
Work	O
	
Our	O
method	O
is	O
motivated	O
by	O
the	O
central	O
role	O
played	O
by	O
alignment	B-Task
in	O
machine	B-Task
translation	I-Task
and	O
previous	O
approaches	O
to	O
sentence	B-Task
similarity	I-Task
modeling	I-Task
,	O
natural	B-Task
language	I-Task
inference	I-Task
,	O
and	O
semantic	B-Task
parsing	I-Task
.	O
	
The	O
neural	B-Method
counterpart	I-Method
to	O
alignment	B-Task
,	O
attention	B-Task
,	O
which	O
is	O
a	O
key	O
part	O
of	O
our	O
approach	O
,	O
was	O
originally	O
proposed	O
and	O
has	O
been	O
predominantly	O
used	O
in	O
conjunction	O
with	O
LSTMs	B-Method
and	O
to	O
a	O
lesser	O
extent	O
with	O
CNNs	B-Method
.	O
	
In	O
contrast	O
,	O
our	O
use	O
of	O
attention	B-Method
is	O
purely	O
based	O
on	O
word	B-Method
embeddings	I-Method
and	O
our	O
method	O
essentially	O
consists	O
of	O
feed	B-Method
-	I-Method
forward	I-Method
networks	I-Method
that	O
operate	O
largely	O
independently	O
of	O
word	O
order	O
.	O
	
section	O
:	O
Approach	O
	
Let	O
and	O
be	O
the	O
two	O
input	O
sentences	O
of	O
length	O
and	O
,	O
respectively	O
.	O
	
We	O
assume	O
that	O
each	O
,	O
is	O
a	O
word	O
embedding	O
vector	O
of	O
dimension	O
and	O
that	O
each	O
sentence	O
is	O
prepended	O
with	O
a	O
“	O
NULL	O
”	O
token	O
.	O
	
Our	O
training	O
data	O
comes	O
in	O
the	O
form	O
of	O
labeled	O
pairs	O
,	O
where	O
is	O
an	O
indicator	O
vector	O
encoding	O
the	O
label	O
and	O
is	O
the	O
number	O
of	O
output	O
classes	O
.	O
	
At	O
test	O
time	O
,	O
we	O
receive	O
a	O
pair	O
of	O
sentences	O
and	O
our	O
goal	O
is	O
to	O
predict	O
the	O
correct	O
label	O
.	O
	
paragraph	O
:	O
Input	B-Method
representation	I-Method
.	O
	
Let	O
and	O
denote	O
the	O
input	O
representation	O
of	O
each	O
fragment	O
that	O
is	O
fed	O
to	O
subsequent	O
steps	O
of	O
the	O
algorithm	O
.	O
	
The	O
vanilla	O
version	O
of	O
our	O
model	O
simply	O
defines	O
and	O
.	O
	
With	O
this	O
input	O
representation	O
,	O
our	O
model	O
does	O
not	O
make	O
use	O
of	O
word	O
order	O
.	O
	
However	O
,	O
we	O
discuss	O
an	O
extension	O
using	O
intra	B-Task
-	I-Task
sentence	I-Task
attention	I-Task
in	O
Section	O
[	O
reference	O
]	O
that	O
uses	O
a	O
minimal	O
amount	O
of	O
sequence	O
information	O
.	O
	
The	O
core	B-Method
model	I-Method
consists	O
of	O
the	O
following	O
three	O
components	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
,	O
which	O
are	O
trained	O
jointly	O
:	O
	
paragraph	O
:	O
Attend	O
.	O
	
First	O
,	O
soft	O
-	O
align	O
the	O
elements	O
of	O
and	O
using	O
a	O
variant	O
of	O
neural	B-Method
attention	I-Method
and	O
decompose	O
the	O
problem	O
into	O
the	O
comparison	B-Task
of	I-Task
aligned	I-Task
subphrases	I-Task
.	O
	
paragraph	O
:	O
Compare	O
.	O
	
Second	O
,	O
separately	O
compare	O
each	O
aligned	O
subphrase	O
to	O
produce	O
a	O
set	O
of	O
vectors	O
for	O
and	O
for	O
.	O
	
Each	O
is	O
a	O
nonlinear	O
combination	O
of	O
and	O
its	O
(	O
softly	O
)	O
aligned	O
subphrase	O
in	O
(	O
and	O
analogously	O
for	O
)	O
.	O
	
paragraph	O
:	O
Aggregate	O
.	O
	
Finally	O
,	O
aggregate	O
the	O
sets	O
and	O
from	O
the	O
previous	O
step	O
and	O
use	O
the	O
result	O
to	O
predict	O
the	O
label	O
.	O
	
subsection	O
:	O
Attend	O
	
We	O
first	O
obtain	O
unnormalized	O
attention	O
weights	O
,	O
computed	O
by	O
a	O
function	O
,	O
which	O
decomposes	O
as	O
:	O
This	O
decomposition	O
avoids	O
the	O
quadratic	B-Metric
complexity	I-Metric
that	O
would	O
be	O
associated	O
with	O
separately	O
applying	O
times	O
.	O
	
Instead	O
,	O
only	O
applications	O
of	O
are	O
needed	O
.	O
	
We	O
take	O
to	O
be	O
a	O
feed	B-Method
-	I-Method
forward	I-Method
neural	I-Method
network	I-Method
with	O
ReLU	B-Method
activations	I-Method
.	O
	
These	O
attention	O
weights	O
are	O
normalized	O
as	O
follows	O
:	O
Here	O
is	O
the	O
subphrase	O
in	O
that	O
is	O
(	O
softly	O
)	O
aligned	O
to	O
and	O
vice	O
versa	O
for	O
.	O
	
subsection	O
:	O
Compare	O
	
Next	O
,	O
we	O
separately	O
compare	O
the	O
aligned	O
phrases	O
and	O
using	O
a	O
function	O
,	O
which	O
in	O
this	O
work	O
is	O
again	O
a	O
feed	B-Method
-	I-Method
forward	I-Method
network	I-Method
:	O
where	O
the	O
brackets	O
denote	O
concatenation	O
.	O
	
Note	O
that	O
since	O
there	O
are	O
only	O
a	O
linear	O
number	O
of	O
terms	O
in	O
this	O
case	O
,	O
we	O
do	O
not	O
need	O
to	O
apply	O
a	O
decomposition	O
as	O
was	O
done	O
in	O
the	O
previous	O
step	O
.	O
	
Thus	O
can	O
jointly	O
take	O
into	O
account	O
both	O
and	O
.	O
	
subsection	O
:	O
Aggregate	O
	
We	O
now	O
have	O
two	O
sets	O
of	O
comparison	O
vectors	O
and	O
.	O
	
We	O
first	O
aggregate	O
over	O
each	O
set	O
by	O
summation	O
:	O
and	O
feed	O
the	O
result	O
through	O
a	O
final	O
classifier	B-Method
,	O
that	O
is	O
a	O
feed	B-Method
forward	I-Method
network	I-Method
followed	O
by	O
a	O
linear	B-Method
layer	I-Method
:	O
where	O
represents	O
the	O
predicted	O
(	O
unnormalized	O
)	O
scores	O
for	O
each	O
class	O
and	O
consequently	O
the	O
predicted	O
class	O
is	O
given	O
by	O
.	O
	
For	O
training	B-Task
,	O
we	O
use	O
multi	B-Method
-	I-Method
class	I-Method
cross	I-Method
-	I-Method
entropy	I-Method
loss	I-Method
with	O
dropout	B-Method
regularization	I-Method
:	O
Here	O
denote	O
the	O
learnable	O
parameters	O
of	O
the	O
functions	O
F	O
,	O
G	O
and	O
H	O
,	O
respectively	O
.	O
	
subsection	O
:	O
Intra	B-Task
-	I-Task
Sentence	I-Task
Attention	I-Task
(	O
Optional	O
)	O
	
In	O
the	O
above	O
model	O
,	O
the	O
input	O
representations	O
are	O
simple	O
word	B-Method
embeddings	I-Method
.	O
	
However	O
,	O
we	O
can	O
augment	O
this	O
input	O
representation	O
with	O
intra	O
-	O
sentence	O
attention	O
to	O
encode	O
compositional	O
relationships	O
between	O
words	O
within	O
each	O
sentence	O
,	O
as	O
proposed	O
by	O
cheng2016long	O
.	O
	
Similar	O
to	O
Eqs	O
.	O
	
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
	
,	O
we	O
define	O
where	O
is	O
a	O
feed	B-Method
-	I-Method
forward	I-Method
network	I-Method
.	O
	
We	O
then	O
create	O
the	O
self	O
-	O
aligned	O
phrases	O
The	O
distance	O
-	O
sensitive	O
bias	O
terms	O
provides	O
the	O
model	O
with	O
a	O
minimal	O
amount	O
of	O
sequence	O
information	O
,	O
while	O
remaining	O
parallelizable	O
.	O
	
These	O
terms	O
are	O
bucketed	O
such	O
that	O
all	O
distances	O
greater	O
than	O
10	O
words	O
share	O
the	O
same	O
bias	O
.	O
	
The	O
input	O
representation	O
for	O
subsequent	O
steps	O
is	O
then	O
defined	O
as	O
and	O
analogously	O
.	O
	
section	O
:	O
Computational	B-Metric
Complexity	I-Metric
	
We	O
now	O
discuss	O
the	O
asymptotic	B-Metric
complexity	I-Metric
of	O
our	O
approach	O
and	O
how	O
it	O
offers	O
a	O
higher	O
degree	O
of	O
parallelism	O
than	O
LSTM	B-Method
-	I-Method
based	I-Method
approaches	I-Method
.	O
	
Recall	O
that	O
denotes	O
embedding	O
dimension	O
and	O
means	O
sentence	O
length	O
.	O
	
For	O
simplicity	O
we	O
assume	O
that	O
all	O
hidden	O
dimensions	O
are	O
and	O
that	O
the	O
complexity	O
of	O
matrix	B-Method
(	I-Method
)	I-Method
-	I-Method
vector	I-Method
(	I-Method
)	I-Method
multiplication	I-Method
is	O
.	O
	
A	O
key	O
assumption	O
of	O
our	O
analysis	O
is	O
that	O
,	O
which	O
we	O
believe	O
is	O
reasonable	O
and	O
is	O
true	O
of	O
the	O
SNLI	B-Material
dataset	I-Material
where	O
,	O
whereas	O
recent	O
LSTM	B-Method
-	I-Method
based	I-Method
approaches	I-Method
have	O
used	O
.	O
	
This	O
assumption	O
allows	O
us	O
to	O
bound	O
the	O
complexity	O
of	O
computing	O
the	O
attention	O
weights	O
.	O
	
paragraph	O
:	O
Complexity	B-Metric
of	O
LSTMs	B-Method
.	O
	
The	O
complexity	B-Metric
of	O
an	O
LSTM	B-Method
cell	I-Method
is	O
,	O
resulting	O
in	O
a	O
complexity	O
of	O
to	O
encode	O
the	O
sentence	O
.	O
	
Adding	O
attention	O
as	O
in	O
rocktaschel2015reasoning	O
increases	O
this	O
complexity	O
to	O
.	O
	
paragraph	O
:	O
Complexity	O
of	O
our	O
Approach	O
.	O
	
Application	O
of	O
a	O
feed	B-Method
-	I-Method
forward	I-Method
network	I-Method
requires	O
steps	O
.	O
	
Thus	O
,	O
the	O
Compare	B-Metric
and	I-Metric
Aggregate	I-Metric
steps	I-Metric
have	O
complexity	O
and	O
respectively	O
.	O
	
For	O
the	O
Attend	O
step	O
,	O
is	O
evaluated	O
times	O
,	O
giving	O
a	O
complexity	B-Metric
of	O
.	O
	
Each	O
attention	O
weight	O
requires	O
one	O
dot	O
product	O
,	O
resulting	O
in	O
a	O
complexity	B-Metric
of	O
.	O
	
Thus	O
the	O
total	O
complexity	B-Metric
of	O
the	O
model	O
is	O
,	O
which	O
is	O
equal	O
to	O
that	O
of	O
an	O
LSTM	B-Method
with	I-Method
attention	I-Method
.	O
	
However	O
,	O
note	O
that	O
with	O
the	O
assumption	O
that	O
,	O
this	O
becomes	O
which	O
is	O
the	O
same	O
complexity	B-Metric
as	O
a	O
regular	B-Method
LSTM	I-Method
.	O
	
Moreover	O
,	O
unlike	O
the	O
LSTM	B-Method
,	O
our	O
approach	O
has	O
the	O
advantage	O
of	O
being	O
parallelizable	O
over	O
,	O
which	O
can	O
be	O
useful	O
at	O
test	O
time	O
.	O
	
section	O
:	O
Experiments	O
	
We	O
evaluate	O
our	O
approach	O
on	O
the	O
Stanford	B-Material
Natural	I-Material
Language	I-Material
Inference	I-Material
(	O
SNLI	B-Material
)	I-Material
dataset	I-Material
.	O
	
Given	O
a	O
sentences	O
pair	O
,	O
the	O
task	O
is	O
to	O
predict	O
whether	O
is	O
entailed	O
by	O
,	O
contradicts	O
,	O
or	O
whether	O
their	O
relationship	O
is	O
neutral	O
.	O
	
subsection	O
:	O
Implementation	O
Details	O
	
The	O
method	O
was	O
implemented	O
in	O
TensorFlow	B-Method
.	O
	
Data	B-Task
preprocessing	I-Task
:	O
Following	O
bowman2015large	O
,	O
we	O
remove	O
examples	O
labeled	O
“	O
–	O
”	O
	
(	O
no	O
gold	O
label	O
)	O
from	O
the	O
dataset	O
,	O
which	O
leaves	O
549	O
,	O
367	O
pairs	O
for	O
training	O
,	O
9	O
,	O
842	O
for	O
development	B-Task
,	O
and	O
9	O
,	O
824	O
for	O
testing	O
.	O
	
We	O
use	O
the	O
tokenized	O
sentences	O
from	O
the	O
non	O
-	O
binary	O
parse	O
provided	O
in	O
the	O
dataset	O
and	O
prepend	O
each	O
sentence	O
with	O
a	O
“	O
NULL	O
”	O
token	O
.	O
	
During	O
training	O
,	O
each	O
sentence	O
was	O
padded	O
up	O
to	O
the	O
maximum	O
length	O
of	O
the	O
batch	O
for	O
efficient	O
training	B-Task
(	O
the	O
padding	O
was	O
explicitly	O
masked	O
out	O
so	O
as	O
not	O
to	O
affect	O
the	O
objective	O
/	O
gradients	O
)	O
.	O
	
For	O
efficient	O
batching	B-Task
in	O
TensorFlow	B-Task
,	O
we	O
semi	O
-	O
sorted	O
the	O
training	O
data	O
to	O
first	O
contain	O
examples	O
where	O
both	O
sentences	O
had	O
length	O
less	O
than	O
20	O
,	O
followed	O
by	O
those	O
with	O
length	O
less	O
than	O
50	O
,	O
and	O
then	O
the	O
rest	O
.	O
	
This	O
ensured	O
that	O
most	O
training	O
batches	O
contained	O
examples	O
of	O
similar	O
length	O
.	O
	
Embeddings	B-Task
:	O
	
We	O
use	O
300	B-Method
dimensional	I-Method
GloVe	I-Method
embeddings	I-Method
to	O
represent	O
words	O
.	O
	
Each	O
embedding	O
vector	O
was	O
normalized	O
to	O
have	O
norm	O
of	O
1	O
and	O
projected	O
down	O
to	O
200	O
dimensions	O
,	O
a	O
number	O
determined	O
via	O
hyperparameter	B-Method
tuning	I-Method
.	O
	
Out	O
-	O
of	O
-	O
vocabulary	O
(	O
OOV	O
)	O
words	O
are	O
hashed	O
to	O
one	O
of	O
100	O
random	B-Method
embeddings	I-Method
each	O
initialized	O
to	O
mean	O
0	O
and	O
standard	O
deviation	O
1	O
.	O
	
All	O
embeddings	O
remain	O
fixed	O
during	O
training	O
,	O
but	O
the	O
projection	O
matrix	O
is	O
trained	O
.	O
	
All	O
other	O
parameter	O
weights	O
(	O
hidden	O
layers	O
etc	O
.	O
)	O
were	O
initialized	O
from	O
random	O
Gaussians	O
with	O
mean	O
0	O
and	O
standard	O
deviation	O
0.01	O
.	O
	
Each	O
hyperparameter	O
setting	O
was	O
run	O
on	O
a	O
single	O
machine	O
with	O
10	O
asynchronous	B-Method
gradient	I-Method
-	I-Method
update	I-Method
threads	I-Method
,	O
using	O
Adagrad	B-Method
for	O
optimization	B-Task
with	O
the	O
default	O
initial	O
accumulator	O
value	O
of	O
0.1	O
.	O
	
Dropout	B-Method
regularization	I-Method
was	O
used	O
for	O
all	O
ReLU	B-Method
layers	I-Method
,	O
but	O
not	O
for	O
the	O
final	O
linear	B-Method
layer	I-Method
.	O
	
We	O
additionally	O
tuned	O
the	O
following	O
hyperparameters	O
and	O
present	O
their	O
chosen	O
values	O
in	O
parentheses	O
:	O
network	B-Metric
size	I-Metric
(	O
2	O
-	O
layers	O
,	O
each	O
with	O
200	O
neurons	O
)	O
,	O
batch	B-Metric
size	I-Metric
(	O
4	O
)	O
,	O
dropout	B-Material
ratio	I-Material
(	O
0.2	O
)	O
and	O
learning	B-Metric
rate	I-Metric
(	O
0.05–vanilla	O
,	O
0.025–intra	O
-	O
attention	O
)	O
.	O
	
All	O
settings	O
were	O
run	O
for	O
50	O
million	O
steps	O
(	O
each	O
step	O
indicates	O
one	O
batch	O
)	O
but	O
model	O
parameters	O
were	O
saved	O
frequently	O
as	O
training	O
progressed	O
and	O
we	O
chose	O
the	O
model	O
that	O
did	O
best	O
on	O
the	O
development	O
set	O
.	O
	
subsection	O
:	O
Results	O
	
Results	O
in	O
terms	O
of	O
3	O
-	O
class	O
accuracy	B-Metric
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Our	O
vanilla	B-Method
approach	I-Method
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
with	O
almost	O
an	O
order	O
of	O
magnitude	O
fewer	O
parameters	O
than	O
the	O
LSTMN	B-Metric
of	O
cheng2016long	O
.	O
	
Adding	O
intra	O
-	O
sentence	O
attention	O
gives	O
a	O
considerable	O
improvement	O
of	O
0.5	O
percentage	O
points	O
over	O
the	O
existing	O
state	O
of	O
the	O
art	O
.	O
	
Table	O
[	O
reference	O
]	O
gives	O
a	O
breakdown	O
of	O
accuracy	B-Metric
on	O
the	O
development	O
set	O
showing	O
that	O
most	O
of	O
our	O
gains	O
stem	O
from	O
neutral	O
,	O
while	O
most	O
losses	O
come	O
from	O
contradiction	O
pairs	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
some	O
wins	O
and	O
losses	O
.	O
	
Examples	O
A	O
-	O
C	O
are	O
cases	O
where	O
both	O
variants	O
of	O
our	O
approach	O
are	O
correct	O
while	O
both	O
SPINN	B-Method
-	I-Method
PI	I-Method
and	O
the	O
mLSTM	B-Method
are	O
incorrect	O
.	O
	
In	O
the	O
first	O
two	O
cases	O
,	O
both	O
sentences	O
contain	O
phrases	O
that	O
are	O
either	O
identical	O
or	O
highly	O
lexically	O
related	O
(	O
e.g.	O
“	O
Two	O
kids	O
”	O
and	O
“	O
ocean	O
/	O
beach	O
”	O
)	O
and	O
our	O
approach	O
correctly	O
favors	O
neutral	O
in	O
these	O
cases	O
.	O
	
In	O
Example	O
C	O
,	O
it	O
is	O
possible	O
that	O
relying	O
on	O
word	O
-	O
order	O
may	O
confuse	O
SPINN	B-Method
-	I-Method
PI	I-Method
and	O
the	O
mLSTM	B-Method
	
due	O
to	O
how	O
“	O
fountain	O
”	O
is	O
the	O
object	O
of	O
a	O
preposition	O
in	O
the	O
first	O
sentence	O
but	O
the	O
subject	O
of	O
the	O
second	O
.	O
	
The	O
second	O
set	O
of	O
examples	O
(	O
D	O
-	O
F	O
)	O
are	O
cases	O
where	O
our	O
vanilla	B-Method
approach	I-Method
is	O
incorrect	O
but	O
mLSTM	B-Method
and	O
SPINN	B-Method
-	I-Method
PI	I-Method
are	O
correct	O
.	O
	
Example	O
F	O
requires	O
sequential	O
information	O
and	O
neither	O
variant	O
of	O
our	O
approach	O
can	O
predict	O
the	O
correct	O
class	O
.	O
	
Examples	O
D	O
-	O
E	O
are	O
interesting	O
however	O
,	O
since	O
they	O
do	O
	
n’t	O
require	O
word	O
order	O
information	O
,	O
yet	O
intra	O
-	O
attention	O
seems	O
to	O
help	O
.	O
	
We	O
suspect	O
this	O
may	O
be	O
because	O
the	O
word	O
embeddings	O
are	O
not	O
fine	O
-	O
grained	O
enough	O
for	O
the	O
algorithm	O
to	O
conclude	O
that	O
“	O
play	O
/	O
watch	O
”	O
is	O
a	O
contradiction	O
,	O
but	O
intra	O
-	O
attention	O
,	O
by	O
adding	O
an	O
extra	O
layer	O
of	O
composition	O
/	O
nonlinearity	O
to	O
incorporate	O
context	O
,	O
compensates	O
for	O
this	O
.	O
	
Finally	O
,	O
Examples	O
G	O
-	O
I	O
are	O
cases	O
that	O
all	O
methods	O
get	O
wrong	O
.	O
	
The	O
first	O
is	O
actually	O
representative	O
of	O
many	O
examples	O
in	O
this	O
category	O
where	O
there	O
is	O
one	O
critical	O
word	O
that	O
separates	O
the	O
two	O
sentences	O
(	O
close	O
vs	O
open	O
in	O
this	O
case	O
)	O
and	O
goes	O
unnoticed	O
by	O
the	O
algorithms	O
.	O
	
Examples	O
H	O
requires	O
inference	O
about	O
numbers	O
and	O
Example	O
I	O
needs	O
sequence	O
information	O
.	O
	
section	O
:	O
Conclusion	O
	
We	O
presented	O
a	O
simple	O
attention	B-Method
-	I-Method
based	I-Method
approach	I-Method
to	O
natural	B-Task
language	I-Task
inference	I-Task
that	O
is	O
trivially	O
parallelizable	O
.	O
	
The	O
approach	O
outperforms	O
considerably	O
more	O
complex	O
neural	B-Method
methods	I-Method
aiming	O
for	O
text	B-Task
understanding	I-Task
.	O
	
Our	O
results	O
suggest	O
that	O
,	O
at	O
least	O
for	O
this	O
task	O
,	O
pairwise	B-Task
comparisons	I-Task
are	O
relatively	O
more	O
important	O
than	O
global	B-Method
sentence	I-Method
-	I-Method
level	I-Method
representations	I-Method
.	O
	
section	O
:	O
Acknowledgements	O
	
We	O
thank	O
Slav	O
Petrov	O
,	O
Tom	O
Kwiatkowski	O
,	O
Yoon	O
Kim	O
,	O
Erick	O
Fonseca	O
,	O
Mark	O
Neumann	O
for	O
useful	O
discussion	O
and	O
Sam	O
Bowman	O
and	O
Shuohang	O
Wang	O
for	O
providing	O
us	O
their	O
model	O
outputs	O
for	O
error	B-Task
analysis	I-Task
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Fully	B-Method
Convolutional	I-Method
Networks	I-Method
for	O
Semantic	B-Task
Segmentation	I-Task
	
Convolutional	B-Method
networks	I-Method
are	O
powerful	O
visual	B-Method
models	I-Method
that	O
yield	O
hierarchies	O
of	O
features	O
.	O
	
We	O
show	O
that	O
convolutional	B-Method
networks	I-Method
by	O
themselves	O
,	O
trained	O
end	O
-	O
to	O
-	O
end	O
,	O
pixels	O
-	O
to	O
-	O
pixels	O
,	O
improve	O
on	O
the	O
previous	O
best	O
result	O
in	O
semantic	B-Task
segmentation	I-Task
.	O
	
Our	O
key	O
insight	O
is	O
to	O
build	O
“	O
fully	B-Method
convolutional	I-Method
”	O
networks	O
that	O
take	O
input	O
of	O
arbitrary	O
size	O
and	O
produce	O
correspondingly	O
-	O
sized	O
output	O
with	O
efficient	O
inference	B-Task
and	O
learning	B-Task
.	O
	
We	O
define	O
and	O
detail	O
the	O
space	O
of	O
fully	B-Method
convolutional	I-Method
networks	O
,	O
explain	O
their	O
application	O
to	O
spatially	B-Task
dense	I-Task
prediction	I-Task
tasks	I-Task
,	O
and	O
draw	O
connections	O
to	O
prior	B-Method
models	I-Method
.	O
	
We	O
adapt	O
contemporary	O
classification	B-Method
networks	I-Method
(	O
AlexNet	B-Method
,	O
the	O
VGG	B-Method
net	I-Method
,	O
and	O
GoogLeNet	B-Method
)	O
into	O
fully	B-Method
convolutional	I-Method
networks	O
and	O
transfer	O
their	O
learned	O
representations	O
by	O
fine	O
-	O
tuning	O
to	O
the	O
segmentation	B-Task
task	I-Task
.	O
	
We	O
then	O
define	O
a	O
skip	B-Method
architecture	I-Method
that	O
combines	O
semantic	O
information	O
from	O
a	O
deep	O
,	O
coarse	O
layer	O
with	O
appearance	O
information	O
from	O
a	O
shallow	O
,	O
fine	O
layer	O
to	O
produce	O
accurate	B-Task
and	I-Task
detailed	I-Task
segmentations	I-Task
.	O
	
Our	O
fully	B-Method
convolutional	I-Method
network	O
achieves	O
improved	O
segmentation	B-Task
of	O
PASCAL	B-Material
VOC	I-Material
(	O
30	O
%	O
relative	O
improvement	O
to	O
67.2	O
%	O
mean	B-Metric
IU	I-Metric
on	O
2012	O
)	O
,	O
NYUDv2	O
,	O
SIFT	O
Flow	O
,	O
and	O
PASCAL	B-Material
-	I-Material
Context	I-Material
,	O
while	O
inference	B-Task
takes	O
one	O
tenth	O
of	O
a	O
second	O
for	O
a	O
typical	O
image	O
.	O
	
Semantic	B-Task
Segmentation	I-Task
,	O
Convolutional	B-Method
Networks	I-Method
,	O
Deep	B-Method
Learning	I-Method
,	O
Transfer	B-Method
Learning	I-Method
	
section	O
:	O
Introduction	O
	
Convolutional	B-Method
networks	I-Method
are	O
driving	O
advances	O
in	O
recognition	B-Task
.	O
	
Convnets	B-Method
are	O
not	O
only	O
improving	O
for	O
whole	O
-	O
image	B-Method
classification	I-Method
,	O
but	O
also	O
making	O
progress	O
on	O
local	B-Task
tasks	I-Task
with	O
structured	O
output	O
.	O
	
These	O
include	O
advances	O
in	O
bounding	O
box	O
object	O
detection	B-Task
,	O
part	B-Task
and	I-Task
keypoint	I-Task
prediction	I-Task
,	O
and	O
local	B-Task
correspondence	I-Task
.	O
	
The	O
natural	O
next	O
step	O
in	O
the	O
progression	O
from	O
coarse	B-Task
to	I-Task
fine	I-Task
inference	I-Task
is	O
to	O
make	O
a	O
prediction	O
at	O
every	O
pixel	O
.	O
	
Prior	O
approaches	O
have	O
used	O
convnets	B-Method
for	O
semantic	B-Task
segmentation	I-Task
,	O
in	O
which	O
each	O
pixel	O
is	O
labeled	O
with	O
the	O
class	O
of	O
its	O
enclosing	O
object	O
or	O
region	O
,	O
but	O
with	O
shortcomings	O
that	O
this	O
work	O
addresses	O
.	O
	
We	O
show	O
that	O
fully	B-Method
convolutional	I-Method
networks	O
(	O
FCNs	B-Method
)	O
trained	O
end	O
-	O
to	O
-	O
end	O
,	O
pixels	O
-	O
to	O
-	O
pixels	O
on	O
semantic	B-Task
segmentation	I-Task
exceed	O
the	O
previous	O
best	O
results	O
without	O
further	O
machinery	O
.	O
	
To	O
our	O
knowledge	O
,	O
this	O
is	O
the	O
first	O
work	O
to	O
train	O
FCNs	B-Method
end	O
-	O
to	O
-	O
end	O
(	O
1	O
)	O
for	O
pixelwise	B-Task
prediction	I-Task
and	O
(	O
2	O
)	O
from	O
supervised	B-Task
pre	I-Task
-	I-Task
training	I-Task
.	O
	
Fully	B-Method
convolutional	I-Method
versions	I-Method
of	O
existing	O
networks	O
predict	O
dense	O
outputs	O
from	O
arbitrary	O
-	O
sized	O
inputs	O
.	O
	
Both	O
learning	B-Task
and	O
inference	B-Task
are	O
performed	O
whole	O
-	O
image	O
-	O
at	O
-	O
a	O
-	O
time	O
by	O
dense	B-Method
feedforward	I-Method
computation	I-Method
and	O
backpropagation	B-Method
.	O
	
In	B-Method
-	I-Method
network	I-Method
upsampling	I-Method
layers	I-Method
enable	O
pixelwise	B-Task
prediction	I-Task
and	O
learning	B-Task
in	I-Task
nets	I-Task
with	O
subsampling	B-Method
.	O
	
This	O
method	O
is	O
efficient	O
,	O
both	O
asymptotically	O
and	O
absolutely	O
,	O
and	O
precludes	O
the	O
need	O
for	O
the	O
complications	O
in	O
other	O
works	O
.	O
	
Patchwise	B-Method
training	I-Method
is	O
common	O
,	O
but	O
lacks	O
the	O
efficiency	O
of	O
fully	B-Method
convolutional	I-Method
training	I-Method
.	O
	
Our	O
approach	O
does	O
not	O
make	O
use	O
of	O
pre	O
-	O
and	O
post	O
-	O
processing	O
complications	O
,	O
including	O
superpixels	O
,	O
proposals	O
,	O
or	O
post	B-Method
-	I-Method
hoc	I-Method
refinement	I-Method
by	O
random	B-Method
fields	I-Method
or	O
local	B-Method
classifiers	I-Method
.	O
	
Our	O
model	O
transfers	O
recent	O
success	O
in	O
classification	B-Task
to	O
dense	B-Task
prediction	I-Task
by	O
reinterpreting	O
classification	B-Method
nets	I-Method
as	O
fully	B-Method
convolutional	I-Method
and	O
fine	O
-	O
tuning	O
from	O
their	O
learned	O
representations	O
.	O
	
In	O
contrast	O
,	O
previous	O
works	O
have	O
applied	O
small	B-Method
convnets	I-Method
without	O
supervised	B-Method
pre	I-Method
-	I-Method
training	I-Method
.	O
	
Semantic	B-Task
segmentation	I-Task
faces	O
an	O
inherent	O
tension	O
between	O
semantics	O
and	O
location	O
:	O
global	O
information	O
resolves	O
what	O
while	O
local	O
information	O
resolves	O
where	O
.	O
	
What	O
can	O
be	O
done	O
to	O
navigate	O
this	O
spectrum	O
from	O
location	O
to	O
semantics	O
?	O
	
How	O
can	O
local	O
decisions	O
respect	O
global	O
structure	O
?	O
	
It	O
is	O
not	O
immediately	O
clear	O
that	O
deep	B-Method
networks	I-Method
for	O
image	B-Method
classification	I-Method
yield	O
representations	B-Task
sufficient	O
for	O
accurate	B-Task
,	I-Task
pixelwise	I-Task
recognition	I-Task
.	O
	
In	O
the	O
conference	O
version	O
of	O
this	O
paper	O
,	O
we	O
cast	O
pre	B-Method
-	I-Method
trained	I-Method
networks	I-Method
into	O
fully	B-Method
convolutional	I-Method
form	I-Method
,	O
and	O
augment	O
them	O
with	O
a	O
skip	B-Method
architecture	I-Method
that	O
takes	O
advantage	O
of	O
the	O
full	O
feature	O
spectrum	O
.	O
	
The	O
skip	B-Method
architecture	I-Method
fuses	O
the	O
feature	O
hierarchy	O
to	O
combine	O
deep	O
,	O
coarse	O
,	O
semantic	O
information	O
and	O
shallow	O
,	O
fine	O
,	O
appearance	O
information	O
(	O
see	O
Section	O
[	O
reference	O
]	O
and	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
In	O
this	O
light	O
,	O
deep	O
feature	O
hierarchies	O
encode	O
location	O
and	O
semantics	O
in	O
a	O
nonlinear	O
local	O
-	O
to	O
-	O
global	O
pyramid	O
.	O
	
This	O
journal	O
paper	O
extends	O
our	O
earlier	O
work	O
through	O
further	O
tuning	O
,	O
analysis	B-Task
,	O
and	O
more	O
results	O
.	O
	
Alternative	O
choices	O
,	O
ablations	O
,	O
and	O
implementation	O
details	O
better	O
cover	O
the	O
space	O
of	O
FCNs	B-Method
.	O
	
Tuning	B-Task
optimization	I-Task
leads	O
to	O
more	O
accurate	O
networks	O
and	O
a	O
means	O
to	O
learn	O
skip	B-Method
architectures	I-Method
	
all	O
-	O
at	O
-	O
once	O
instead	O
of	O
in	O
stages	O
.	O
	
Experiments	O
that	O
mask	O
foreground	O
and	O
background	O
investigate	O
the	O
role	O
of	O
context	O
and	O
shape	O
.	O
	
Results	O
on	O
the	O
object	O
and	O
scene	O
labeling	O
of	O
PASCAL	B-Material
-	I-Material
Context	I-Material
reinforce	O
merging	B-Task
object	I-Task
segmentation	I-Task
and	O
scene	B-Task
parsing	I-Task
as	O
unified	B-Task
pixelwise	I-Task
prediction	I-Task
.	O
	
In	O
the	O
next	O
section	O
,	O
we	O
review	O
related	O
work	O
on	O
deep	B-Method
classification	I-Method
nets	I-Method
,	O
FCNs	B-Method
,	O
recent	O
approaches	O
to	O
semantic	B-Task
segmentation	I-Task
using	O
convnets	B-Method
,	O
and	O
extensions	O
to	O
FCNs	B-Method
.	O
	
The	O
following	O
sections	O
explain	O
FCN	B-Method
design	O
,	O
introduce	O
our	O
architecture	O
with	O
in	B-Method
-	I-Method
network	I-Method
upsampling	I-Method
and	I-Method
skip	I-Method
layers	I-Method
,	O
and	O
describe	O
our	O
experimental	O
framework	O
.	O
	
Next	O
,	O
we	O
demonstrate	O
improved	O
accuracy	B-Metric
on	O
PASCAL	B-Material
VOC	I-Material
2011	O
-	O
2	O
,	O
NYUDv2	O
,	O
SIFT	O
Flow	O
,	O
and	O
PASCAL	B-Material
-	I-Material
Context	I-Material
.	O
	
Finally	O
,	O
we	O
analyze	O
design	O
choices	O
,	O
examine	O
what	O
cues	O
can	O
be	O
learned	O
by	O
an	O
FCN	B-Method
,	O
and	O
calculate	O
recognition	B-Method
bounds	I-Method
for	O
semantic	B-Task
segmentation	I-Task
.	O
	
section	O
:	O
Related	O
Work	O
	
Our	O
approach	O
draws	O
on	O
recent	O
successes	O
of	O
deep	B-Method
nets	I-Method
for	O
image	B-Method
classification	I-Method
and	O
transfer	B-Task
learning	I-Task
.	O
	
Transfer	B-Task
was	O
first	O
demonstrated	O
on	O
various	O
visual	B-Task
recognition	I-Task
tasks	I-Task
,	O
then	O
on	O
detection	B-Task
,	O
and	O
on	O
both	O
instance	O
and	O
semantic	B-Task
segmentation	I-Task
in	O
hybrid	B-Method
proposal	I-Method
-	I-Method
classifier	I-Method
models	I-Method
.	O
	
We	O
now	O
re	O
-	O
architect	O
and	O
fine	O
-	O
tune	O
classification	B-Method
nets	I-Method
to	O
direct	O
,	O
dense	O
prediction	O
of	O
semantic	B-Task
segmentation	I-Task
.	O
	
We	O
chart	O
the	O
space	O
of	O
FCNs	B-Method
and	O
relate	O
prior	B-Method
models	I-Method
both	O
historical	O
and	O
recent	O
.	O
	
Fully	B-Method
convolutional	I-Method
networks	I-Method
To	O
our	O
knowledge	O
,	O
	
the	O
idea	O
of	O
extending	O
a	O
convnet	B-Method
to	O
arbitrary	O
-	O
sized	O
inputs	O
first	O
appeared	O
in	O
Matan	O
et	O
al	O
.	O
,	O
which	O
extended	O
the	O
classic	O
LeNet	B-Method
to	O
recognize	O
strings	O
of	O
digits	O
.	O
	
Because	O
their	O
net	O
was	O
limited	O
to	O
one	O
-	O
dimensional	O
input	O
strings	O
,	O
Matan	O
et	O
al	O
.	O
	
used	O
Viterbi	B-Method
decoding	I-Method
to	O
obtain	O
their	O
outputs	O
.	O
	
Wolf	O
and	O
Platt	O
expand	O
convnet	B-Method
outputs	I-Method
to	O
2	O
-	O
dimensional	O
maps	O
of	O
detection	B-Task
scores	O
for	O
the	O
four	O
corners	O
of	O
postal	O
address	O
blocks	O
.	O
	
Both	O
of	O
these	O
historical	O
works	O
do	O
inference	B-Task
and	O
learning	B-Method
fully	I-Method
convolutionally	I-Method
for	O
detection	B-Task
.	O
	
Ning	O
et	O
al	O
.	O
define	O
a	O
convnet	B-Method
for	O
coarse	B-Task
multiclass	I-Task
segmentation	I-Task
of	I-Task
C.	I-Task
elegans	I-Task
tissues	I-Task
with	O
fully	B-Method
convolutional	I-Method
inference	I-Method
.	O
	
Fully	B-Method
convolutional	I-Method
computation	I-Method
has	O
also	O
been	O
exploited	O
in	O
the	O
present	O
era	O
of	O
many	B-Task
-	I-Task
layered	I-Task
nets	I-Task
.	O
	
Sliding	O
window	O
detection	B-Task
by	O
Sermanet	O
et	O
al	O
.	O
,	O
semantic	B-Task
segmentation	I-Task
by	O
Pinheiro	O
and	O
Collobert	O
,	O
and	O
image	B-Task
restoration	I-Task
by	O
Eigen	O
et	O
al	O
.	O
do	O
fully	B-Method
convolutional	I-Method
inference	I-Method
.	O
	
Fully	B-Method
convolutional	I-Method
training	I-Method
is	O
rare	O
,	O
but	O
used	O
effectively	O
by	O
Tompson	O
et	O
al	O
.	O
to	O
learn	O
an	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
part	I-Method
detector	I-Method
and	O
spatial	B-Method
model	I-Method
for	O
pose	B-Task
estimation	I-Task
,	O
although	O
they	O
do	O
not	O
exposit	O
on	O
or	O
analyze	O
this	O
method	O
.	O
	
Dense	B-Task
prediction	I-Task
with	O
convnets	B-Method
Several	O
recent	O
works	O
have	O
applied	O
convnets	B-Method
to	O
dense	B-Task
prediction	I-Task
problems	I-Task
,	O
including	O
semantic	B-Task
segmentation	I-Task
by	O
Ning	O
et	O
al	O
.	O
,	O
Farabet	O
et	O
al	O
.	O
,	O
and	O
Pinheiro	O
and	O
Collobert	O
;	O
boundary	B-Task
prediction	I-Task
for	O
electron	B-Task
microscopy	I-Task
by	O
Ciresan	O
et	O
al	O
.	O
and	O
for	O
natural	O
images	O
by	O
a	O
hybrid	B-Method
convnet	I-Method
/	I-Method
nearest	I-Method
neighbor	I-Method
model	I-Method
by	O
Ganin	O
and	O
Lempitsky	O
;	O
and	O
image	B-Task
restoration	I-Task
and	O
depth	B-Task
estimation	I-Task
by	O
Eigen	O
et	O
al	O
.	O
.	O
	
Common	O
elements	O
of	O
these	O
approaches	O
include	O
small	B-Method
models	I-Method
restricting	I-Method
capacity	I-Method
and	I-Method
receptive	I-Method
fields	I-Method
;	O
patchwise	B-Method
training	I-Method
;	O
refinement	B-Method
by	O
superpixel	B-Method
projection	I-Method
,	O
random	B-Method
field	I-Method
regularization	I-Method
,	O
filtering	B-Method
,	O
or	O
local	B-Method
classification	I-Method
;	O
	
“	O
interlacing	O
”	O
to	O
obtain	O
dense	O
output	O
;	O
multi	B-Method
-	I-Method
scale	I-Method
pyramid	I-Method
processing	I-Method
;	O
saturating	O
nonlinearities	O
;	O
and	O
ensembles	O
,	O
whereas	O
our	O
method	O
does	O
without	O
this	O
machinery	O
.	O
	
However	O
,	O
we	O
do	O
study	O
patchwise	B-Method
training	I-Method
(	O
Section	O
[	O
reference	O
]	O
)	O
and	O
“	O
shift	O
-	O
and	O
-	O
stitch	O
”	O
dense	O
output	O
(	O
Section	O
[	O
reference	O
]	O
)	O
from	O
the	O
perspective	O
of	O
FCNs	B-Method
.	O
	
We	O
also	O
discuss	O
in	B-Task
-	I-Task
network	I-Task
upsampling	I-Task
(	O
Section	O
[	O
reference	O
]	O
)	O
,	O
of	O
which	O
the	O
fully	B-Method
connected	I-Method
prediction	I-Method
by	O
Eigen	O
et	O
al	O
.	O
is	O
a	O
special	O
case	O
.	O
	
Unlike	O
these	O
existing	O
methods	O
,	O
we	O
adapt	O
and	O
extend	O
deep	B-Method
classification	I-Method
architectures	I-Method
,	O
using	O
image	B-Method
classification	I-Method
as	O
supervised	B-Task
pre	I-Task
-	I-Task
training	I-Task
,	O
and	O
fine	O
-	O
tune	O
fully	B-Method
convolutionally	I-Method
to	O
learn	O
simply	O
and	O
efficiently	O
from	O
whole	O
image	O
inputs	O
and	O
whole	O
image	O
ground	O
thruths	O
.	O
	
Hariharan	O
et	O
al	O
.	O
and	O
Gupta	O
	
et	O
al	O
.	O
	
likewise	O
adapt	O
deep	B-Method
classification	I-Method
nets	I-Method
to	O
semantic	B-Task
segmentation	I-Task
,	O
but	O
do	O
so	O
in	O
hybrid	B-Method
proposal	I-Method
-	I-Method
classifier	I-Method
models	I-Method
.	O
	
These	O
approaches	O
fine	O
-	O
tune	O
an	O
R	B-Method
-	I-Method
CNN	I-Method
system	I-Method
by	O
sampling	O
bounding	O
boxes	O
and	O
/	O
or	O
region	B-Method
proposals	I-Method
for	O
detection	B-Task
,	O
semantic	B-Task
segmentation	I-Task
,	O
and	O
instance	B-Task
segmentation	I-Task
.	O
	
Neither	O
method	O
is	O
learned	O
end	O
-	O
to	O
-	O
end	O
.	O
	
They	O
achieve	O
the	O
previous	O
best	O
segmentation	B-Task
results	O
on	O
PASCAL	B-Material
VOC	I-Material
and	O
NYUDv2	O
respectively	O
,	O
so	O
we	O
directly	O
compare	O
our	O
standalone	O
,	O
end	O
-	O
to	O
-	O
end	O
FCN	B-Method
to	O
their	O
semantic	B-Task
segmentation	I-Task
results	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Combining	O
feature	B-Method
hierarchies	I-Method
	
We	O
fuse	O
features	O
across	O
layers	O
to	O
define	O
a	O
nonlinear	B-Method
local	I-Method
-	I-Method
to	I-Method
-	I-Method
global	I-Method
representation	I-Method
that	O
we	O
tune	O
end	O
-	O
to	O
-	O
end	O
.	O
	
The	O
Laplacian	B-Method
pyramid	I-Method
is	O
a	O
classic	O
multi	B-Method
-	I-Method
scale	I-Method
representation	I-Method
made	O
of	O
fixed	B-Method
smoothing	I-Method
and	O
differencing	B-Method
.	O
	
The	O
jet	O
of	O
Koenderink	O
and	O
van	O
Doorn	O
is	O
a	O
rich	O
,	O
local	O
feature	O
defined	O
by	O
compositions	B-Method
of	I-Method
partial	I-Method
derivatives	I-Method
.	O
	
In	O
the	O
context	O
of	O
deep	B-Method
networks	I-Method
,	O
Sermanet	O
et	O
al	O
.	O
fuse	O
intermediate	O
layers	O
but	O
discard	O
resolution	O
in	O
doing	O
so	O
.	O
	
In	O
contemporary	O
work	O
Hariharan	O
et	O
al	O
.	O
and	O
Mostajabi	O
et	O
al	O
.	O
also	O
fuse	O
multiple	O
layers	O
but	O
do	O
not	O
learn	O
end	O
-	O
to	O
-	O
end	O
and	O
rely	O
on	O
fixed	B-Method
bottom	I-Method
-	I-Method
up	I-Method
grouping	I-Method
.	O
	
FCN	B-Method
extensions	O
Following	O
the	O
conference	O
version	O
of	O
this	O
paper	O
,	O
FCNs	B-Method
have	O
been	O
extended	O
to	O
new	O
tasks	O
and	O
data	O
.	O
	
Tasks	O
include	O
region	B-Task
proposals	I-Task
,	O
contour	O
detection	B-Task
,	O
depth	B-Task
regression	I-Task
,	O
optical	B-Task
flow	I-Task
,	O
and	O
weakly	O
-	O
supervised	O
semantic	B-Task
segmentation	I-Task
.	O
	
In	O
addition	O
,	O
new	O
works	O
have	O
improved	O
the	O
FCNs	B-Method
presented	O
here	O
to	O
further	O
advance	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
in	O
semantic	B-Task
segmentation	I-Task
.	O
	
The	O
DeepLab	B-Method
models	I-Method
raise	O
output	O
resolution	O
by	O
dilated	B-Method
convolution	I-Method
and	O
dense	B-Method
CRF	I-Method
inference	I-Method
.	O
	
The	O
joint	B-Method
CRFasRNN	I-Method
model	I-Method
is	O
an	O
end	O
-	O
to	O
-	O
end	O
integration	O
of	O
the	O
CRF	B-Method
for	O
further	O
improvement	O
.	O
	
ParseNet	O
normalizes	O
features	O
for	O
fusion	B-Task
and	O
captures	O
context	O
with	O
global	B-Method
pooling	I-Method
.	O
	
The	O
“	O
deconvolutional	B-Method
network	I-Method
”	I-Method
approach	I-Method
of	O
restores	B-Task
resolution	I-Task
by	O
proposals	O
,	O
stacks	B-Method
of	I-Method
learned	I-Method
deconvolution	I-Method
,	O
and	O
unpooling	B-Method
.	O
	
U	B-Method
-	I-Method
Net	I-Method
combines	O
skip	B-Method
layers	I-Method
and	O
learned	B-Method
deconvolution	I-Method
for	O
pixel	B-Task
labeling	I-Task
of	I-Task
microscopy	I-Task
images	I-Task
.	O
	
The	O
dilation	B-Method
architecture	I-Method
of	O
makes	O
thorough	O
use	O
of	O
dilated	B-Method
convolution	I-Method
for	O
pixel	O
-	O
precise	O
output	O
without	O
a	O
random	O
field	O
or	O
skip	O
layers	O
.	O
	
section	O
:	O
Fully	B-Method
Convolutional	I-Method
Networks	I-Method
	
Each	O
layer	O
output	O
in	O
a	O
convnet	B-Method
is	O
a	O
three	O
-	O
dimensional	O
array	O
of	O
size	O
,	O
where	O
and	O
are	O
spatial	O
dimensions	O
,	O
and	O
is	O
the	O
feature	O
or	O
channel	O
dimension	O
.	O
	
The	O
first	O
layer	O
is	O
the	O
image	O
,	O
with	O
pixel	O
size	O
,	O
and	O
channels	O
.	O
	
Locations	O
in	O
higher	O
layers	O
correspond	O
to	O
the	O
locations	O
in	O
the	O
image	O
they	O
are	O
path	O
-	O
connected	O
to	O
,	O
which	O
are	O
called	O
their	O
receptive	O
fields	O
.	O
	
Convnets	B-Method
are	O
inherently	O
translation	O
invariant	O
.	O
	
Their	O
basic	O
components	O
(	O
convolution	B-Method
,	O
pooling	B-Method
,	O
and	O
activation	B-Method
functions	I-Method
)	O
operate	O
on	O
local	O
input	O
regions	O
,	O
and	O
depend	O
only	O
on	O
relative	O
spatial	O
coordinates	O
.	O
	
Writing	O
for	O
the	O
data	O
vector	O
at	O
location	O
in	O
a	O
particular	O
layer	O
,	O
and	O
for	O
the	O
following	O
layer	O
,	O
these	O
functions	O
compute	O
outputs	O
by	O
where	O
is	O
called	O
the	O
kernel	O
size	O
,	O
is	O
the	O
stride	O
or	O
subsampling	O
factor	O
,	O
and	O
determines	O
the	O
layer	O
type	O
:	O
a	O
matrix	B-Method
multiplication	I-Method
for	O
convolution	B-Method
or	O
average	B-Method
pooling	I-Method
,	O
a	O
spatial	B-Method
max	I-Method
for	O
max	B-Method
pooling	I-Method
,	O
or	O
an	O
elementwise	B-Method
nonlinearity	I-Method
for	O
an	O
activation	B-Method
function	I-Method
,	O
and	O
so	O
on	O
for	O
other	O
types	O
of	O
layers	O
.	O
	
This	O
functional	O
form	O
is	O
maintained	O
under	O
composition	O
,	O
with	O
kernel	O
size	O
and	O
stride	O
obeying	O
the	O
transformation	B-Method
rule	I-Method
	
While	O
a	O
general	B-Method
net	I-Method
computes	O
a	O
general	O
nonlinear	O
function	O
,	O
a	O
net	O
with	O
only	O
layers	O
of	O
this	O
form	O
computes	O
a	O
nonlinear	B-Method
filter	I-Method
,	O
which	O
we	O
call	O
a	O
deep	B-Method
filter	I-Method
or	O
fully	B-Method
convolutional	I-Method
network	O
.	O
	
An	O
FCN	B-Method
naturally	O
operates	O
on	O
an	O
input	O
of	O
any	O
size	O
,	O
and	O
produces	O
an	O
output	O
of	O
corresponding	O
(	O
possibly	O
resampled	O
)	O
spatial	O
dimensions	O
.	O
	
A	O
real	B-Method
-	I-Method
valued	I-Method
loss	I-Method
function	I-Method
composed	O
with	O
an	O
FCN	B-Method
defines	O
a	O
task	O
.	O
	
If	O
the	O
loss	O
function	O
is	O
a	O
sum	O
over	O
the	O
spatial	O
dimensions	O
of	O
the	O
final	O
layer	O
,	O
,	O
its	O
parameter	O
gradient	O
will	O
be	O
a	O
sum	O
over	O
the	O
parameter	O
gradients	O
of	O
each	O
of	O
its	O
spatial	B-Method
components	I-Method
.	O
	
Thus	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
on	O
computed	O
on	O
whole	O
images	O
will	O
be	O
the	O
same	O
as	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
on	O
,	O
taking	O
all	O
of	O
the	O
final	O
layer	O
receptive	O
fields	O
as	O
a	O
minibatch	O
.	O
	
When	O
these	O
receptive	O
fields	O
overlap	O
significantly	O
,	O
both	O
feedforward	B-Method
computation	I-Method
and	O
backpropagation	B-Method
are	O
much	O
more	O
efficient	O
when	O
computed	O
layer	O
-	O
by	O
-	O
layer	O
over	O
an	O
entire	O
image	O
instead	O
of	O
independently	O
patch	O
-	O
by	O
-	O
patch	O
.	O
	
We	O
next	O
explain	O
how	O
to	O
convert	O
classification	B-Method
nets	I-Method
into	O
fully	B-Method
convolutional	I-Method
nets	O
that	O
produce	O
coarse	O
output	O
maps	O
.	O
	
For	O
pixelwise	B-Task
prediction	I-Task
,	O
we	O
need	O
to	O
connect	O
these	O
coarse	O
outputs	O
back	O
to	O
the	O
pixels	O
.	O
	
Section	O
[	O
reference	O
]	O
describes	O
a	O
trick	O
used	O
for	O
this	O
purpose	O
(	O
e.g.	O
,	O
by	O
“	O
fast	B-Method
scanning	I-Method
”	O
)	O
.	O
	
We	O
explain	O
this	O
trick	O
in	O
terms	O
of	O
network	B-Task
modification	I-Task
.	O
	
As	O
an	O
efficient	O
,	O
effective	O
alternative	O
,	O
we	O
upsample	O
in	O
Section	O
[	O
reference	O
]	O
,	O
reusing	O
our	O
implementation	O
of	O
convolution	B-Method
.	O
	
In	O
Section	O
[	O
reference	O
]	O
we	O
consider	O
training	B-Task
by	O
patchwise	B-Method
sampling	I-Method
,	O
and	O
give	O
evidence	O
in	O
Section	O
[	O
reference	O
]	O
that	O
our	O
whole	O
image	B-Task
training	I-Task
is	O
faster	O
and	O
equally	O
effective	O
.	O
	
subsection	O
:	O
Adapting	O
classifiers	B-Method
for	O
dense	B-Task
prediction	I-Task
	
Typical	O
recognition	B-Method
nets	I-Method
,	O
including	O
LeNet	B-Method
,	O
AlexNet	B-Method
,	O
and	O
its	O
deeper	O
successors	O
,	O
ostensibly	O
take	O
fixed	O
-	O
sized	O
inputs	O
and	O
produce	O
non	O
-	O
spatial	O
outputs	O
.	O
	
The	O
fully	B-Method
connected	I-Method
layers	I-Method
of	O
these	O
nets	O
have	O
fixed	O
dimensions	O
and	O
throw	O
away	O
spatial	O
coordinates	O
.	O
	
However	O
,	O
fully	B-Method
connected	I-Method
layers	I-Method
can	O
also	O
be	O
viewed	O
as	O
convolutions	B-Method
with	I-Method
kernels	I-Method
that	O
cover	O
their	O
entire	O
input	O
regions	O
.	O
	
Doing	O
so	O
casts	O
these	O
nets	O
into	O
fully	B-Method
convolutional	I-Method
networks	O
that	O
take	O
input	O
of	O
any	O
size	O
and	O
make	O
spatial	O
output	O
maps	O
.	O
	
This	O
transformation	O
is	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Furthermore	O
,	O
while	O
the	O
resulting	O
maps	O
are	O
equivalent	O
to	O
the	O
evaluation	O
of	O
the	O
original	O
net	O
on	O
particular	O
input	O
patches	O
,	O
the	O
computation	O
is	O
highly	O
amortized	O
over	O
the	O
overlapping	O
regions	O
of	O
those	O
patches	O
.	O
	
For	O
example	O
,	O
while	O
AlexNet	B-Method
takes	O
ms	B-Metric
(	O
on	O
a	O
typical	O
GPU	O
)	O
to	O
infer	O
the	O
classification	O
scores	O
of	O
a	O
image	O
,	O
the	O
fully	B-Method
convolutional	I-Method
net	O
takes	O
ms	B-Metric
to	O
produce	O
a	O
grid	O
of	O
outputs	O
from	O
a	O
image	O
,	O
which	O
is	O
more	O
than	O
times	O
faster	O
than	O
the	O
naïve	O
approach	O
.	O
	
The	O
spatial	O
output	O
maps	O
of	O
these	O
convolutionalized	B-Method
models	I-Method
make	O
them	O
a	O
natural	O
choice	O
for	O
dense	B-Task
problems	I-Task
like	O
semantic	B-Task
segmentation	I-Task
.	O
	
With	O
ground	O
truth	O
available	O
at	O
every	O
output	O
cell	O
,	O
both	O
the	O
forward	O
and	O
backward	O
passes	O
are	O
straightforward	O
,	O
and	O
both	O
take	O
advantage	O
of	O
the	O
inherent	O
computational	B-Metric
efficiency	I-Metric
(	O
and	O
aggressive	O
optimization	B-Task
)	O
of	O
convolution	B-Method
.	O
	
The	O
corresponding	O
backward	O
times	O
for	O
the	O
AlexNet	O
example	O
are	O
ms	B-Metric
for	O
a	O
single	O
image	O
and	O
ms	B-Metric
for	O
a	O
fully	B-Method
convolutional	I-Method
output	I-Method
map	I-Method
,	O
resulting	O
in	O
a	O
speedup	O
similar	O
to	O
that	O
of	O
the	O
forward	O
pass	O
.	O
	
While	O
our	O
reinterpretation	O
of	O
classification	B-Method
nets	I-Method
as	O
fully	B-Method
convolutional	I-Method
yields	O
output	O
maps	O
for	O
inputs	O
of	O
any	O
size	O
,	O
the	O
output	O
dimensions	O
are	O
typically	O
reduced	O
by	O
subsampling	B-Method
.	O
	
The	O
classification	B-Method
nets	I-Method
subsample	O
to	O
keep	O
filters	O
small	O
and	O
computational	O
requirements	O
reasonable	O
.	O
	
This	O
coarsens	O
the	O
output	O
of	O
a	O
fully	B-Method
convolutional	I-Method
version	I-Method
of	O
these	O
nets	O
,	O
reducing	O
it	O
from	O
the	O
size	O
of	O
the	O
input	O
by	O
a	O
factor	O
equal	O
to	O
the	O
pixel	O
stride	O
of	O
the	O
receptive	O
fields	O
of	O
the	O
output	O
units	O
.	O
	
subsection	O
:	O
Shift	B-Method
-	I-Method
and	I-Method
-	I-Method
stitch	I-Method
is	O
filter	B-Method
dilation	I-Method
	
Dense	B-Task
predictions	I-Task
can	O
be	O
obtained	O
from	O
coarse	O
outputs	O
by	O
stitching	O
together	O
outputs	O
from	O
shifted	O
versions	O
of	O
the	O
input	O
.	O
	
If	O
the	O
output	O
is	O
downsampled	O
by	O
a	O
factor	O
of	O
,	O
shift	O
the	O
input	O
pixels	O
to	O
the	O
right	O
and	O
pixels	O
down	O
,	O
once	O
for	O
every	O
such	O
that	O
.	O
	
Process	O
each	O
of	O
these	O
inputs	O
,	O
and	O
interlace	O
the	O
outputs	O
so	O
that	O
the	O
predictions	O
correspond	O
to	O
the	O
pixels	O
at	O
the	O
centers	O
of	O
their	O
receptive	O
fields	O
.	O
	
Although	O
this	O
transformation	O
naïvely	O
increases	O
the	O
cost	B-Metric
by	O
a	O
factor	O
of	O
,	O
there	O
is	O
a	O
well	O
-	O
known	O
trick	O
for	O
efficiently	O
producing	O
identical	O
results	O
.	O
	
(	O
This	O
trick	O
is	O
also	O
used	O
in	O
the	O
algorithme	O
à	O
trous	O
for	O
wavelet	B-Task
transforms	I-Task
and	O
related	O
to	O
the	O
Noble	O
identities	O
from	O
signal	B-Task
processing	I-Task
.	O
)	O
	
Consider	O
a	O
layer	O
(	O
convolution	B-Method
or	I-Method
pooling	I-Method
)	O
with	O
input	O
stride	O
,	O
and	O
a	O
subsequent	O
convolution	B-Method
layer	I-Method
with	O
filter	O
weights	O
(	O
eliding	O
the	O
irrelevant	O
feature	O
dimensions	O
)	O
.	O
	
Setting	O
the	O
earlier	O
layer	O
’s	O
input	O
stride	O
to	O
one	O
upsamples	O
its	O
output	O
by	O
a	O
factor	O
of	O
.	O
	
However	O
,	O
convolving	O
the	O
original	B-Method
filter	I-Method
with	O
the	O
upsampled	O
output	O
does	O
not	O
produce	O
the	O
same	O
result	O
as	O
shift	O
-	O
and	O
-	O
stitch	O
,	O
because	O
the	O
original	O
filter	O
only	O
sees	O
a	O
reduced	O
portion	O
of	O
its	O
(	O
now	O
upsampled	O
)	O
input	O
.	O
	
To	O
produce	O
the	O
same	O
result	O
,	O
dilate	O
(	O
or	O
“	O
rarefy	O
”	O
)	O
the	O
filter	O
by	O
forming	O
(	O
with	O
and	O
zero	B-Method
-	I-Method
based	I-Method
)	O
.	O
	
Reproducing	O
the	O
full	O
net	O
output	O
of	O
shift	B-Method
-	I-Method
and	I-Method
-	I-Method
stitch	I-Method
involves	O
repeating	O
this	O
filter	O
enlargement	O
layer	O
-	O
by	O
-	O
layer	O
until	O
all	O
subsampling	O
is	O
removed	O
.	O
	
(	O
In	O
practice	O
,	O
this	O
can	O
be	O
done	O
efficiently	O
by	O
processing	O
subsampled	B-Method
versions	I-Method
of	I-Method
the	I-Method
upsampled	I-Method
input	I-Method
.	O
)	O
	
Simply	O
decreasing	O
subsampling	O
within	O
a	O
net	O
is	O
a	O
tradeoff	O
:	O
the	O
filters	O
see	O
finer	O
information	O
,	O
but	O
have	O
smaller	O
receptive	O
fields	O
and	O
take	O
longer	O
to	O
compute	O
.	O
	
This	O
dilation	B-Method
trick	I-Method
is	O
another	O
kind	O
of	O
tradeoff	O
:	O
the	O
output	O
is	O
denser	O
without	O
decreasing	O
the	O
receptive	O
field	O
sizes	O
of	O
the	O
filters	O
,	O
but	O
the	O
filters	O
are	O
prohibited	O
from	O
accessing	O
information	O
at	O
a	O
finer	O
scale	O
than	O
their	O
original	O
design	O
.	O
	
Although	O
we	O
have	O
done	O
preliminary	O
experiments	O
with	O
dilation	B-Method
,	O
we	O
do	O
not	O
use	O
it	O
in	O
our	O
model	O
.	O
	
We	O
find	O
learning	B-Task
through	O
upsampling	B-Method
,	O
as	O
described	O
in	O
the	O
next	O
section	O
,	O
to	O
be	O
effective	O
and	O
efficient	O
,	O
especially	O
when	O
combined	O
with	O
the	O
skip	B-Method
layer	I-Method
fusion	I-Method
described	O
later	O
on	O
.	O
	
For	O
further	O
detail	O
regarding	O
dilation	B-Task
,	O
refer	O
to	O
the	O
dilated	O
FCN	B-Method
of	O
.	O
	
subsection	O
:	O
Upsampling	B-Method
is	O
(	O
fractionally	B-Method
strided	I-Method
)	I-Method
convolution	I-Method
	
Another	O
way	O
to	O
connect	O
coarse	O
outputs	O
to	O
dense	O
pixels	O
is	O
interpolation	O
.	O
	
For	O
instance	O
,	O
simple	O
bilinear	B-Method
interpolation	I-Method
computes	O
each	O
output	O
from	O
the	O
nearest	O
four	O
inputs	O
by	O
a	O
linear	B-Method
map	I-Method
that	O
depends	O
only	O
on	O
the	O
relative	O
positions	O
of	O
the	O
input	O
and	O
output	O
cells	O
:	O
where	O
is	O
the	O
upsampling	O
factor	O
,	O
and	O
denotes	O
the	O
fractional	O
part	O
.	O
	
In	O
a	O
sense	O
,	O
upsampling	B-Method
with	I-Method
factor	I-Method
is	O
convolution	B-Method
with	O
a	O
fractional	O
input	O
stride	O
of	O
.	O
	
So	O
long	O
as	O
is	O
integral	O
,	O
it	O
’s	O
natural	O
to	O
implement	O
upsampling	B-Method
through	O
“	O
backward	B-Method
convolution	I-Method
”	O
by	O
reversing	O
the	O
forward	O
and	O
backward	O
passes	O
of	O
more	O
typical	O
input	B-Method
-	I-Method
strided	I-Method
convolution	I-Method
.	O
	
Thus	O
upsampling	B-Method
is	O
performed	O
in	O
-	B-Method
network	I-Method
for	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
learning	I-Task
by	O
backpropagation	B-Method
from	O
the	O
pixelwise	O
loss	O
.	O
	
Per	O
their	O
use	O
in	O
deconvolution	B-Method
networks	I-Method
(	O
esp	O
.	O
)	O
	
,	O
these	O
(	O
convolution	B-Method
)	I-Method
layers	I-Method
are	O
sometimes	O
referred	O
to	O
as	O
deconvolution	B-Method
layers	I-Method
.	O
	
Note	O
that	O
the	O
convolution	B-Method
filter	I-Method
in	O
such	O
a	O
layer	O
need	O
not	O
be	O
fixed	O
(	O
e.g.	O
,	O
to	O
bilinear	O
upsampling	O
)	O
,	O
but	O
can	O
be	O
learned	O
.	O
	
A	O
stack	B-Method
of	I-Method
deconvolution	I-Method
layers	I-Method
and	O
activation	B-Method
functions	I-Method
can	O
even	O
learn	O
a	O
nonlinear	B-Method
upsampling	I-Method
.	O
	
In	O
our	O
experiments	O
,	O
we	O
find	O
that	O
in	B-Method
-	I-Method
network	I-Method
upsampling	I-Method
is	O
fast	O
and	O
effective	O
for	O
learning	B-Task
dense	I-Task
prediction	I-Task
.	O
	
subsection	O
:	O
Patchwise	B-Task
training	I-Task
is	O
loss	B-Method
sampling	I-Method
	
In	O
stochastic	B-Task
optimization	I-Task
,	O
gradient	B-Task
computation	I-Task
is	O
driven	O
by	O
the	O
training	O
distribution	O
.	O
	
Both	O
patchwise	B-Method
training	I-Method
and	O
fully	B-Method
convolutional	I-Method
training	I-Method
can	O
be	O
made	O
to	O
produce	O
any	O
distribution	O
of	O
the	O
inputs	O
,	O
although	O
their	O
relative	O
computational	B-Metric
efficiency	I-Metric
depends	O
on	O
overlap	O
and	O
minibatch	O
size	O
.	O
	
Whole	B-Method
image	I-Method
fully	I-Method
convolutional	I-Method
training	I-Method
is	O
identical	O
to	O
patchwise	B-Method
training	I-Method
where	O
each	O
batch	O
consists	O
of	O
all	O
the	O
receptive	O
fields	O
of	O
the	O
output	O
units	O
for	O
an	O
image	O
(	O
or	O
collection	O
of	O
images	O
)	O
.	O
	
While	O
this	O
is	O
more	O
efficient	O
than	O
uniform	B-Method
sampling	I-Method
of	I-Method
patches	I-Method
,	O
it	O
reduces	O
the	O
number	O
of	O
possible	O
batches	O
.	O
	
However	O
,	O
random	B-Method
sampling	I-Method
of	I-Method
patches	I-Method
within	O
an	O
image	O
may	O
be	O
easily	O
recovered	O
.	O
	
Restricting	O
the	O
loss	O
to	O
a	O
randomly	O
sampled	O
subset	O
of	O
its	O
spatial	O
terms	O
(	O
or	O
,	O
equivalently	O
applying	O
a	O
DropConnect	O
mask	O
between	O
the	O
output	O
and	O
the	O
loss	O
)	O
excludes	O
patches	O
from	O
the	O
gradient	O
.	O
	
If	O
the	O
kept	O
patches	O
still	O
have	O
significant	O
overlap	O
,	O
fully	B-Method
convolutional	I-Method
computation	I-Method
will	O
still	O
speed	O
up	O
training	B-Task
.	O
	
If	O
gradients	O
are	O
accumulated	O
over	O
multiple	O
backward	O
passes	O
,	O
batches	O
can	O
include	O
patches	O
from	O
several	O
images	O
.	O
	
If	O
inputs	O
are	O
shifted	O
by	O
values	O
up	O
to	O
the	O
output	O
stride	O
,	O
random	O
selection	O
of	O
all	O
possible	O
patches	O
is	O
possible	O
even	O
though	O
the	O
output	O
units	O
lie	O
on	O
a	O
fixed	O
,	O
strided	O
grid	O
.	O
	
Sampling	B-Method
in	O
patchwise	B-Task
training	I-Task
can	O
correct	O
class	B-Task
imbalance	I-Task
and	O
mitigate	O
the	O
spatial	O
correlation	O
of	O
dense	O
patches	O
.	O
	
In	O
fully	B-Method
convolutional	I-Method
training	I-Method
,	O
class	B-Task
balance	I-Task
can	O
also	O
be	O
achieved	O
by	O
weighting	O
the	O
loss	O
,	O
and	O
loss	B-Method
sampling	I-Method
can	O
be	O
used	O
to	O
address	O
spatial	O
correlation	O
.	O
	
We	O
explore	O
training	O
with	O
sampling	B-Method
in	O
Section	O
[	O
reference	O
]	O
,	O
and	O
do	O
not	O
find	O
that	O
it	O
yields	O
faster	O
or	O
better	O
convergence	B-Metric
for	O
dense	B-Task
prediction	I-Task
.	O
	
Whole	B-Task
image	I-Task
training	I-Task
is	O
effective	O
and	O
efficient	O
.	O
	
section	O
:	O
Segmentation	B-Method
Architecture	I-Method
	
We	O
cast	O
ILSVRC	B-Method
classifiers	I-Method
into	O
FCNs	B-Method
and	O
augment	O
them	O
for	O
dense	B-Task
prediction	I-Task
with	O
in	B-Task
-	I-Task
network	I-Task
upsampling	I-Task
and	O
a	O
pixelwise	O
loss	O
.	O
	
We	O
train	O
for	O
segmentation	B-Task
by	O
fine	B-Task
-	I-Task
tuning	I-Task
.	O
	
Next	O
,	O
we	O
add	O
skips	O
between	O
layers	O
to	O
fuse	O
coarse	O
,	O
semantic	O
and	O
local	O
,	O
appearance	O
information	O
.	O
	
This	O
skip	B-Method
architecture	I-Method
is	O
learned	O
end	O
-	O
to	O
-	O
end	O
to	O
refine	O
the	O
semantics	O
and	O
spatial	O
precision	O
of	O
the	O
output	O
.	O
	
For	O
this	O
investigation	O
,	O
we	O
train	O
and	O
validate	O
on	O
the	O
PASCAL	B-Material
VOC	I-Material
2011	O
segmentation	O
challenge	O
.	O
	
We	O
train	O
with	O
a	O
per	B-Metric
-	I-Metric
pixel	I-Metric
softmax	I-Metric
loss	I-Metric
and	O
validate	O
with	O
the	O
standard	O
metric	O
of	O
mean	B-Metric
pixel	I-Metric
intersection	I-Metric
over	I-Metric
union	I-Metric
,	O
with	O
the	O
mean	O
taken	O
over	O
all	O
classes	O
,	O
including	O
background	O
.	O
	
The	O
training	O
ignores	O
pixels	O
that	O
are	O
masked	O
out	O
(	O
as	O
ambiguous	O
or	O
difficult	O
)	O
in	O
the	O
ground	O
truth	O
.	O
	
subsection	O
:	O
From	O
classifier	B-Method
to	O
dense	O
FCN	B-Method
	
We	O
begin	O
by	O
convolutionalizing	O
proven	O
classification	B-Method
architectures	I-Method
as	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
We	O
consider	O
the	O
AlexNet	B-Method
architecture	I-Method
that	O
won	O
ILSVRC12	B-Method
,	O
as	O
well	O
as	O
the	O
VGG	B-Method
nets	I-Method
and	O
the	O
GoogLeNet	B-Method
which	O
did	O
exceptionally	O
well	O
in	O
ILSVRC14	B-Task
.	O
	
We	O
pick	O
the	O
VGG	B-Method
16	I-Method
-	I-Method
layer	I-Method
net	I-Method
,	O
which	O
we	O
found	O
to	O
be	O
equivalent	O
to	O
the	O
19	O
-	O
layer	O
net	O
on	O
this	O
task	O
.	O
	
For	O
GoogLeNet	B-Method
,	O
we	O
use	O
only	O
the	O
final	O
loss	O
layer	O
,	O
and	O
improve	O
performance	O
by	O
discarding	O
the	O
final	O
average	B-Method
pooling	I-Method
layer	I-Method
.	O
	
We	O
decapitate	O
each	O
net	O
by	O
discarding	O
the	O
final	O
classifier	B-Method
layer	I-Method
,	O
and	O
convert	O
all	O
fully	B-Method
connected	I-Method
layers	I-Method
to	O
convolutions	B-Method
.	O
	
We	O
append	O
a	O
convolution	B-Method
with	I-Method
channel	I-Method
dimension	I-Method
to	O
predict	O
scores	O
for	O
each	O
of	O
the	O
PASCAL	B-Material
classes	I-Material
(	O
including	O
background	O
)	O
at	O
each	O
of	O
the	O
coarse	O
output	O
locations	O
,	O
followed	O
by	O
a	O
(	O
backward	B-Method
)	I-Method
convolution	I-Method
layer	I-Method
to	O
bilinearly	O
upsample	O
the	O
coarse	O
outputs	O
to	O
pixelwise	O
outputs	O
as	O
described	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Table	O
[	O
reference	O
]	O
compares	O
the	O
preliminary	O
validation	O
results	O
along	O
with	O
the	O
basic	O
characteristics	O
of	O
each	O
net	O
.	O
	
We	O
report	O
the	O
best	O
results	O
achieved	O
after	O
convergence	O
at	O
a	O
fixed	O
learning	B-Metric
rate	I-Metric
(	O
at	O
least	O
175	O
epochs	O
)	O
.	O
	
Our	O
training	O
for	O
this	O
comparison	O
follows	O
the	O
practices	O
for	O
classification	B-Method
networks	I-Method
.	O
	
We	O
train	O
by	O
SGD	B-Method
with	O
momentum	B-Method
.	O
	
Gradients	O
are	O
accumulated	O
over	O
20	O
images	O
.	O
	
We	O
set	O
fixed	O
learning	B-Metric
rates	I-Metric
of	O
,	O
,	O
and	O
for	O
FCN	B-Method
-	O
AlexNet	O
,	O
FCN	B-Method
-	O
VGG16	O
,	O
and	O
FCN	B-Method
-	O
GoogLeNet	O
,	O
respectively	O
,	O
chosen	O
by	O
line	B-Method
search	I-Method
.	O
	
We	O
use	O
momentum	O
,	O
weight	O
decay	O
of	O
or	O
,	O
and	O
doubled	O
learning	B-Metric
rate	I-Metric
for	O
biases	O
.	O
	
We	O
zero	O
-	O
initialize	O
the	O
class	B-Method
scoring	I-Method
layer	I-Method
,	O
as	O
random	B-Method
initialization	I-Method
yielded	O
neither	O
better	O
performance	O
nor	O
faster	O
convergence	B-Metric
.	O
	
Dropout	B-Method
is	O
included	O
where	O
used	O
in	O
the	O
original	O
classifier	B-Method
nets	I-Method
(	O
however	O
,	O
training	O
without	O
it	O
made	O
little	O
to	O
no	O
difference	O
)	O
.	O
	
Fine	B-Task
-	I-Task
tuning	I-Task
from	O
classification	B-Task
to	O
segmentation	B-Task
gives	O
reasonable	O
predictions	O
from	O
each	O
net	O
.	O
	
Even	O
the	O
worst	O
model	O
achieved	O
of	O
the	O
previous	O
best	O
performance	O
.	O
	
FCN	B-Method
-	O
VGG16	O
already	O
appears	O
to	O
be	O
better	O
than	O
previous	O
methods	O
at	O
56.0	O
mean	B-Metric
IU	I-Metric
on	O
val	B-Metric
,	O
compared	O
to	O
52.6	O
on	O
test	O
.	O
	
Although	O
VGG	B-Method
and	O
GoogLeNet	B-Method
are	O
similarly	O
accurate	O
as	O
classifiers	B-Method
,	O
our	O
FCN	B-Method
-	O
GoogLeNet	O
did	O
not	O
match	O
FCN	B-Method
-	O
VGG16	O
.	O
	
We	O
select	O
FCN	B-Method
-	O
VGG16	O
as	O
our	O
base	O
network	O
.	O
	
subsection	O
:	O
Image	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
learning	I-Task
	
batch	B-Metric
size	I-Metric
pixel	I-Metric
acc	I-Metric
.	O
	
mean	B-Metric
acc	I-Metric
.	O
	
mean	B-Metric
	
IU	B-Metric
f.w	O
.	O
	
IU	B-Metric
	
The	O
image	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
learning	I-Task
setting	I-Task
includes	O
high	O
effective	O
batch	O
size	O
and	O
correlated	O
inputs	O
.	O
	
This	O
optimization	B-Task
requires	O
some	O
attention	O
to	O
properly	O
tune	O
FCNs	B-Method
.	O
	
We	O
begin	O
with	O
the	O
loss	O
.	O
	
We	O
do	O
not	O
normalize	O
the	O
loss	O
,	O
so	O
that	O
every	O
pixel	O
has	O
the	O
same	O
weight	O
regardless	O
of	O
the	O
batch	O
and	O
image	O
dimensions	O
.	O
	
Thus	O
we	O
use	O
a	O
small	O
learning	B-Metric
rate	I-Metric
since	O
the	O
loss	O
is	O
summed	O
spatially	O
over	O
all	O
pixels	O
.	O
	
We	O
consider	O
two	O
regimes	O
for	O
batch	B-Task
size	I-Task
.	O
	
In	O
the	O
first	O
,	O
gradients	O
are	O
accumulated	O
over	O
20	O
images	O
.	O
	
Accumulation	B-Method
reduces	O
the	O
memory	O
required	O
and	O
respects	O
the	O
different	O
dimensions	O
of	O
each	O
input	O
by	O
reshaping	O
the	O
network	O
.	O
	
We	O
picked	O
this	O
batch	O
size	O
empirically	O
to	O
result	O
in	O
reasonable	O
convergence	B-Metric
.	O
	
Learning	B-Task
in	O
this	O
way	O
is	O
similar	O
to	O
standard	O
classification	B-Task
training	I-Task
:	O
each	O
minibatch	O
contains	O
several	O
images	O
and	O
has	O
a	O
varied	O
distribution	O
of	O
class	O
labels	O
.	O
	
The	O
nets	O
compared	O
in	O
Table	O
[	O
reference	O
]	O
are	O
optimized	O
in	O
this	O
fashion	O
.	O
	
However	O
,	O
batching	B-Method
is	O
not	O
the	O
only	O
way	O
to	O
do	O
image	B-Task
-	I-Task
wise	I-Task
learning	I-Task
.	O
	
In	O
the	O
second	O
regime	O
,	O
batch	O
size	O
one	O
is	O
used	O
for	O
online	B-Task
learning	I-Task
.	O
	
Properly	O
tuned	O
,	O
online	B-Method
learning	I-Method
achieves	O
higher	O
accuracy	B-Metric
and	O
faster	O
convergence	B-Metric
in	O
both	O
number	O
of	O
iterations	B-Metric
and	O
wall	B-Metric
clock	I-Metric
time	I-Metric
.	O
	
Additionally	O
,	O
we	O
try	O
a	O
higher	O
momentum	O
of	O
,	O
which	O
increases	O
the	O
weight	O
on	O
recent	O
gradients	O
in	O
a	O
similar	O
way	O
to	O
batching	B-Task
.	O
	
See	O
Table	O
[	O
reference	O
]	O
for	O
the	O
comparison	O
of	O
accumulation	B-Task
,	O
online	B-Task
,	O
and	O
high	O
momentum	O
or	O
“	O
heavy	O
”	O
learning	O
(	O
discussed	O
further	O
in	O
Section	O
[	O
reference	O
]	O
)	O
.	O
	
subsection	O
:	O
Combining	O
what	O
and	O
where	O
	
We	O
define	O
a	O
new	O
fully	B-Method
convolutional	I-Method
net	O
for	O
segmentation	B-Task
that	O
combines	O
layers	O
of	O
the	O
feature	O
hierarchy	O
and	O
refines	O
the	O
spatial	O
precision	O
of	O
the	O
output	O
.	O
	
See	O
Figure	O
[	O
reference	O
]	O
.	O
	
While	O
fully	B-Method
convolutionalized	I-Method
classifiers	I-Method
fine	O
-	O
tuned	O
to	O
semantic	B-Task
segmentation	I-Task
both	O
recognize	O
and	O
localize	B-Task
,	O
as	O
shown	O
in	O
Section	O
[	O
reference	O
]	O
,	O
these	O
networks	O
can	O
be	O
improved	O
to	O
make	O
direct	O
use	O
of	O
shallower	O
,	O
more	O
local	O
features	O
.	O
	
Even	O
though	O
these	O
base	O
networks	O
score	O
highly	O
on	O
the	O
standard	O
metrics	O
,	O
their	O
output	O
is	O
dissatisfyingly	O
coarse	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
The	O
stride	O
of	O
the	O
network	B-Method
prediction	I-Method
limits	O
the	O
scale	O
of	O
detail	O
in	O
the	O
upsampled	O
output	O
.	O
	
We	O
address	O
this	O
by	O
adding	O
skips	O
that	O
fuse	O
layer	O
outputs	O
,	O
in	O
particular	O
to	O
include	O
shallower	O
layers	O
with	O
finer	O
strides	O
in	O
prediction	B-Task
.	O
	
This	O
turns	O
a	O
line	O
topology	O
into	O
a	O
DAG	O
:	O
edges	O
skip	O
ahead	O
from	O
shallower	O
to	O
deeper	O
layers	O
.	O
	
It	O
is	O
natural	O
to	O
make	O
more	O
local	O
predictions	O
from	O
shallower	O
layers	O
since	O
their	O
receptive	O
fields	O
are	O
smaller	O
and	O
see	O
fewer	O
pixels	O
.	O
	
Once	O
augmented	O
with	O
skips	B-Method
,	O
the	O
network	O
makes	O
and	O
fuses	O
predictions	O
from	O
several	O
streams	O
that	O
are	O
learned	O
jointly	O
and	O
end	O
-	O
to	O
-	O
end	O
.	O
	
Combining	O
fine	O
layers	O
and	O
coarse	O
layers	O
lets	O
the	O
model	O
make	O
local	O
predictions	O
that	O
respect	O
global	O
structure	O
.	O
	
This	O
crossing	O
of	O
layers	O
and	O
resolutions	O
is	O
a	O
learned	O
,	O
nonlinear	B-Method
counterpart	I-Method
to	O
the	O
multi	B-Method
-	I-Method
scale	I-Method
representation	I-Method
of	I-Method
the	I-Method
Laplacian	I-Method
pyramid	I-Method
.	O
	
By	O
analogy	O
to	O
the	O
jet	O
of	O
Koenderick	O
and	O
van	O
Doorn	O
,	O
we	O
call	O
our	O
feature	O
hierarchy	O
the	O
deep	O
jet	O
.	O
	
Layer	B-Method
fusion	I-Method
is	O
essentially	O
an	O
elementwise	B-Method
operation	I-Method
.	O
	
However	O
,	O
the	O
correspondence	O
of	O
elements	O
across	O
layers	O
is	O
complicated	O
by	O
resampling	O
and	O
padding	O
.	O
	
Thus	O
,	O
in	O
general	O
,	O
layers	O
to	O
be	O
fused	O
must	O
be	O
aligned	O
by	O
scaling	O
and	O
cropping	O
.	O
	
We	O
bring	O
two	O
layers	O
into	O
scale	O
agreement	O
by	O
upsampling	O
the	O
lower	O
-	O
resolution	O
layer	O
,	O
doing	O
so	O
in	O
-	O
network	O
as	O
explained	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Cropping	B-Method
removes	O
any	O
portion	O
of	O
the	O
upsampled	O
layer	O
which	O
extends	O
beyond	O
the	O
other	O
layer	O
due	O
to	O
padding	O
.	O
	
This	O
results	O
in	O
layers	O
of	O
equal	O
dimensions	O
in	O
exact	O
alignment	O
.	O
	
The	O
offset	O
of	O
the	O
cropped	O
region	O
depends	O
on	O
the	O
resampling	O
and	O
padding	O
parameters	O
of	O
all	O
intermediate	O
layers	O
.	O
	
Determining	O
the	O
crop	O
that	O
results	O
in	O
exact	O
correspondence	O
can	O
be	O
intricate	O
,	O
but	O
it	O
follows	O
automatically	O
from	O
the	O
network	B-Method
definition	I-Method
(	O
and	O
we	O
include	O
code	O
for	O
it	O
in	O
Caffe	B-Task
)	O
.	O
	
Having	O
spatially	O
aligned	O
the	O
layers	O
,	O
we	O
next	O
pick	O
a	O
fusion	B-Method
operation	I-Method
.	O
	
We	O
fuse	O
features	O
by	O
concatenation	O
,	O
and	O
immediately	O
follow	O
with	O
classification	B-Task
by	O
a	O
“	O
score	B-Method
layer	I-Method
”	O
consisting	O
of	O
a	O
convolution	B-Method
.	O
	
Rather	O
than	O
storing	O
concatenated	O
features	O
in	O
memory	O
,	O
we	O
commute	O
the	O
concatenation	O
and	O
subsequent	O
classification	B-Task
(	O
as	O
both	O
are	O
linear	O
)	O
.	O
	
Thus	O
,	O
our	O
skips	B-Method
are	O
implemented	O
by	O
first	O
scoring	O
each	O
layer	O
to	O
be	O
fused	O
by	O
convolution	B-Method
,	O
carrying	O
out	O
any	O
necessary	O
interpolation	O
and	O
alignment	O
,	O
and	O
then	O
summing	O
the	O
scores	O
.	O
	
We	O
also	O
considered	O
max	B-Task
fusion	I-Task
,	O
but	O
found	O
learning	B-Task
to	O
be	O
difficult	O
due	O
to	O
gradient	B-Method
switching	I-Method
.	O
	
The	O
score	O
layer	O
parameters	O
are	O
zero	O
-	O
initialized	O
when	O
a	O
skip	O
is	O
added	O
,	O
so	O
that	O
they	O
do	O
not	O
interfere	O
with	O
existing	O
predictions	O
of	O
other	O
streams	O
.	O
	
Once	O
all	O
layers	O
have	O
been	O
fused	O
,	O
the	O
final	O
prediction	B-Task
is	O
then	O
upsampled	O
back	O
to	O
image	O
resolution	O
.	O
	
Skip	B-Method
Architectures	I-Method
for	O
Segmentation	B-Task
	
We	O
define	O
a	O
skip	B-Method
architecture	I-Method
to	O
extend	O
FCN	B-Method
-	O
VGG16	O
to	O
a	O
three	O
-	O
stream	B-Method
net	I-Method
with	O
eight	O
pixel	O
stride	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Adding	O
a	O
skip	O
from	O
pool4	O
halves	O
the	O
stride	O
by	O
scoring	O
from	O
this	O
stride	O
sixteen	O
layer	O
.	O
	
The	O
interpolation	B-Method
layer	I-Method
of	O
the	O
skip	B-Method
is	O
initialized	O
to	O
bilinear	B-Task
interpolation	I-Task
,	O
but	O
is	O
not	O
fixed	O
so	O
that	O
it	O
can	O
be	O
learned	O
as	O
described	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
We	O
call	O
this	O
two	O
-	O
stream	O
net	O
FCN	B-Method
-	O
16s	O
,	O
and	O
likewise	O
define	O
FCN	B-Method
-	I-Method
8s	I-Method
by	O
adding	O
a	O
further	O
skip	O
from	O
pool3	O
to	O
make	O
stride	O
eight	O
predictions	O
.	O
	
(	O
Note	O
that	O
predicting	O
at	O
stride	O
eight	O
does	O
not	O
significantly	O
limit	O
the	O
maximum	O
achievable	O
mean	B-Metric
IU	I-Metric
;	O
see	O
Section	O
[	O
reference	O
]	O
.	O
)	O
	
We	O
experiment	O
with	O
both	O
staged	B-Method
training	I-Method
and	O
all	B-Task
-	I-Task
at	I-Task
-	I-Task
once	I-Task
training	I-Task
.	O
	
In	O
the	O
staged	O
version	O
,	O
we	O
learn	O
the	O
single	O
-	O
stream	O
FCN	B-Method
-	O
32s	O
,	O
then	O
upgrade	O
to	O
the	O
two	O
-	O
stream	O
FCN	B-Method
-	O
16s	O
and	O
continue	O
learning	B-Task
,	O
and	O
finally	O
upgrade	O
to	O
the	O
three	O
-	O
stream	O
FCN	B-Method
-	O
8s	O
and	O
finish	O
learning	B-Task
.	O
	
At	O
each	O
stage	O
the	O
net	O
is	O
learned	O
end	O
-	O
to	O
-	O
end	O
,	O
initialized	O
with	O
the	O
parameters	O
of	O
the	O
earlier	O
net	O
.	O
	
The	O
learning	B-Metric
rate	I-Metric
is	O
dropped	O
from	O
FCN	B-Method
-	O
32s	O
to	O
FCN	B-Method
-	O
16s	O
and	O
more	O
from	O
FCN	B-Method
-	O
16s	O
to	O
FCN	B-Method
-	I-Method
8s	I-Method
,	O
which	O
we	O
found	O
to	O
be	O
necessary	O
for	O
continued	O
improvements	O
.	O
	
Learning	O
all	O
-	O
at	O
-	O
once	O
rather	O
than	O
in	O
stages	O
gives	O
nearly	O
equivalent	O
results	O
,	O
while	O
training	B-Method
is	O
faster	O
and	O
less	O
tedious	O
.	O
	
However	O
,	O
disparate	O
feature	O
scales	O
make	O
naïve	B-Method
training	I-Method
prone	O
to	O
divergence	O
.	O
	
To	O
remedy	O
this	O
we	O
scale	O
each	O
stream	O
by	O
a	O
fixed	O
constant	O
,	O
for	O
a	O
similar	O
in	O
-	O
network	O
effect	O
to	O
the	O
staged	B-Method
learning	I-Method
rate	I-Method
adjustments	I-Method
.	O
	
These	O
constants	O
are	O
picked	O
to	O
approximately	O
equalize	O
average	O
feature	O
norms	O
across	O
streams	O
.	O
	
(	O
Other	O
normalization	B-Method
schemes	I-Method
should	O
have	O
similar	O
effect	O
.	O
)	O
	
With	O
FCN	B-Method
-	O
16s	O
validation	O
score	O
improves	O
to	O
65.0	O
mean	B-Metric
IU	I-Metric
,	O
and	O
FCN	B-Method
-	I-Method
8s	I-Method
brings	O
a	O
minor	O
improvement	O
to	O
65.5	O
.	O
	
At	O
this	O
point	O
our	O
fusion	O
improvements	O
have	O
met	O
diminishing	O
returns	O
,	O
so	O
we	O
do	O
not	O
continue	O
fusing	O
even	O
shallower	O
layers	O
.	O
	
To	O
identify	O
the	O
contribution	O
of	O
the	O
skips	O
we	O
compare	O
scoring	O
from	O
the	O
intermediate	O
layers	O
in	O
isolation	O
,	O
which	O
results	O
in	O
poor	O
performance	O
,	O
or	O
dropping	O
the	O
learning	B-Metric
rate	I-Metric
without	O
adding	O
skips	O
,	O
which	O
gives	O
negligible	O
improvement	O
in	O
score	O
without	O
refining	O
the	O
visual	B-Metric
quality	I-Metric
of	I-Metric
output	I-Metric
.	O
	
All	O
skip	O
comparisons	O
are	O
reported	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
the	O
progressively	O
finer	O
structure	O
of	O
the	O
output	O
.	O
	
pixel	B-Metric
acc	I-Metric
.	O
	
mean	B-Metric
acc	I-Metric
.	O
	
mean	B-Metric
	
IU	B-Metric
f.w	O
.	O
	
IU	B-Metric
	
subsection	O
:	O
Experimental	O
framework	O
	
Fine	B-Task
-	I-Task
tuning	I-Task
	
We	O
fine	O
-	O
tune	O
all	O
layers	O
by	O
backpropagation	B-Method
through	O
the	O
whole	O
net	O
.	O
	
Fine	O
-	O
tuning	O
the	O
output	B-Method
classifier	I-Method
alone	O
yields	O
only	O
73	O
%	O
of	O
the	O
full	O
fine	B-Metric
-	I-Metric
tuning	I-Metric
performance	O
as	O
compared	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Fine	B-Task
-	I-Task
tuning	I-Task
in	I-Task
stages	I-Task
takes	O
36	O
hours	O
on	O
a	O
single	O
GPU	O
.	O
	
Learning	O
FCN	B-Method
-	O
8s	O
	
all	O
-	O
at	O
-	O
once	O
takes	O
half	O
the	O
time	O
to	O
reach	O
comparable	O
accuracy	B-Metric
.	O
	
Training	O
from	O
scratch	O
gives	O
substantially	O
lower	O
accuracy	B-Metric
.	O
	
More	O
training	O
data	O
	
The	O
PASCAL	B-Material
VOC	I-Material
2011	O
segmentation	O
training	O
set	O
labels	O
1	O
,	O
112	O
images	O
.	O
	
Hariharan	O
et	O
al	O
.	O
collected	O
labels	O
for	O
a	O
larger	O
set	O
of	O
8	O
,	O
498	O
PASCAL	B-Material
training	I-Material
images	I-Material
,	O
which	O
was	O
used	O
to	O
train	O
the	O
previous	O
best	O
system	O
,	O
SDS	B-Method
.	O
	
This	O
training	O
data	O
improves	O
the	O
FCN	B-Method
-	O
32s	O
validation	O
score	O
from	O
57.7	O
to	O
63.6	O
mean	B-Metric
IU	I-Metric
and	O
improves	O
the	O
FCN	B-Method
-	O
AlexNet	O
score	O
from	O
39.8	O
to	O
48.0	O
mean	B-Metric
IU	I-Metric
.	O
	
Loss	O
	
The	O
per	B-Task
-	I-Task
pixel	I-Task
,	I-Task
unnormalized	I-Task
softmax	I-Task
loss	I-Task
is	O
a	O
natural	O
choice	O
for	O
segmenting	B-Task
images	I-Task
of	O
any	O
size	O
into	O
disjoint	O
classes	O
,	O
so	O
we	O
train	O
our	O
nets	O
with	O
it	O
.	O
	
The	O
softmax	B-Method
operation	I-Method
induces	O
competition	O
between	O
classes	O
and	O
promotes	O
the	O
most	O
confident	O
prediction	O
,	O
but	O
it	O
is	O
not	O
clear	O
that	O
this	O
is	O
necessary	O
or	O
helpful	O
.	O
	
For	O
comparison	O
,	O
we	O
train	O
with	O
the	O
sigmoid	B-Method
cross	I-Method
-	I-Method
entropy	I-Method
loss	I-Method
and	O
find	O
that	O
it	O
gives	O
similar	O
results	O
,	O
even	O
though	O
it	O
normalizes	O
each	O
class	B-Method
prediction	I-Method
independently	O
.	O
	
Patch	B-Method
sampling	I-Method
As	O
explained	O
in	O
Section	O
[	O
reference	O
]	O
,	O
our	O
whole	O
image	B-Task
training	I-Task
effectively	O
batches	O
each	O
image	O
into	O
a	O
regular	O
grid	O
of	O
large	O
,	O
overlapping	O
patches	O
.	O
	
By	O
contrast	O
,	O
prior	O
work	O
randomly	O
samples	O
patches	O
over	O
a	O
full	O
dataset	O
,	O
potentially	O
resulting	O
in	O
higher	O
variance	O
batches	O
that	O
may	O
accelerate	O
convergence	B-Metric
.	O
	
We	O
study	O
this	O
tradeoff	O
by	O
spatially	O
sampling	O
the	O
loss	O
in	O
the	O
manner	O
described	O
earlier	O
,	O
making	O
an	O
independent	O
choice	O
to	O
ignore	O
each	O
final	O
layer	O
cell	O
with	O
some	O
probability	O
.	O
	
To	O
avoid	O
changing	O
the	O
effective	O
batch	O
size	O
,	O
we	O
simultaneously	O
increase	O
the	O
number	O
of	O
images	O
per	O
batch	O
by	O
a	O
factor	O
.	O
	
Note	O
that	O
due	O
to	O
the	O
efficiency	O
of	O
convolution	B-Method
,	O
this	O
form	O
of	O
rejection	B-Method
sampling	I-Method
is	O
still	O
faster	O
than	O
patchwise	B-Method
training	I-Method
for	O
large	O
enough	O
values	O
of	O
(	O
e.g.	O
,	O
at	O
least	O
for	O
according	O
to	O
the	O
numbers	O
in	O
Section	O
[	O
reference	O
]	O
)	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
the	O
effect	O
of	O
this	O
form	O
of	O
sampling	B-Method
on	O
convergence	B-Task
.	O
	
We	O
find	O
that	O
sampling	B-Method
does	O
not	O
have	O
a	O
significant	O
effect	O
on	O
convergence	B-Metric
rate	I-Metric
compared	O
to	O
whole	B-Task
image	I-Task
training	I-Task
,	O
but	O
takes	O
significantly	O
more	O
time	O
due	O
to	O
the	O
larger	O
number	O
of	O
images	O
that	O
need	O
to	O
be	O
considered	O
per	O
batch	O
.	O
	
We	O
therefore	O
choose	O
unsampled	B-Task
,	I-Task
whole	I-Task
image	I-Task
training	I-Task
in	O
our	O
other	O
experiments	O
.	O
	
Class	O
balancing	O
Fully	B-Method
convolutional	I-Method
training	I-Method
can	O
balance	O
classes	O
by	O
weighting	O
or	O
sampling	O
the	O
loss	O
.	O
	
Although	O
our	O
labels	O
are	O
mildly	O
unbalanced	O
(	O
about	O
are	O
background	O
)	O
,	O
we	O
find	O
class	B-Method
balancing	I-Method
unnecessary	O
.	O
	
Dense	B-Task
Prediction	I-Task
	
The	O
scores	O
are	O
upsampled	O
to	O
the	O
input	O
dimensions	O
by	O
backward	B-Method
convolution	I-Method
layers	I-Method
within	O
the	O
net	O
.	O
	
Final	O
layer	O
backward	O
convolution	O
weights	O
are	O
fixed	O
to	O
bilinear	B-Method
interpolation	I-Method
,	O
while	O
intermediate	B-Method
upsampling	I-Method
layers	I-Method
are	O
initialized	O
to	O
bilinear	O
interpolation	O
,	O
and	O
then	O
learned	O
.	O
	
This	O
simple	O
,	O
end	O
-	O
to	O
-	O
end	O
method	O
is	O
accurate	O
and	O
fast	O
.	O
	
Augmentation	B-Task
	
We	O
tried	O
augmenting	O
the	O
training	O
data	O
by	O
randomly	O
mirroring	O
and	O
“	O
jittering	O
”	O
the	O
images	O
by	O
translating	O
them	O
up	O
to	O
32	O
pixels	O
(	O
the	O
coarsest	O
scale	O
of	O
prediction	O
)	O
in	O
each	O
direction	O
.	O
	
This	O
yielded	O
no	O
noticeable	O
improvement	O
.	O
	
Implementation	O
	
All	O
models	O
are	O
trained	O
and	O
tested	O
with	O
Caffe	B-Method
on	O
a	O
single	O
NVIDIA	O
Titan	O
X.	O
Our	O
models	O
and	O
code	O
are	O
publicly	O
available	O
at	O
.	O
	
section	O
:	O
Results	O
	
We	O
test	O
our	O
FCN	B-Method
on	O
semantic	B-Task
segmentation	I-Task
and	O
scene	B-Task
parsing	I-Task
,	O
exploring	O
PASCAL	B-Material
VOC	I-Material
,	O
NYUDv2	O
,	O
SIFT	O
Flow	O
,	O
and	O
PASCAL	B-Material
-	I-Material
Context	I-Material
.	O
	
Although	O
these	O
tasks	O
have	O
historically	O
distinguished	O
between	O
objects	O
and	O
regions	O
,	O
we	O
treat	O
both	O
uniformly	O
as	O
pixel	B-Task
prediction	I-Task
.	O
	
We	O
evaluate	O
our	O
FCN	B-Method
skip	O
architecture	O
on	O
each	O
of	O
these	O
datasets	O
,	O
and	O
then	O
extend	O
it	O
to	O
multi	B-Method
-	I-Method
modal	I-Method
input	I-Method
for	O
NYUDv2	O
and	O
multi	B-Task
-	I-Task
task	I-Task
prediction	I-Task
for	O
the	O
semantic	O
and	O
geometric	B-Task
labels	I-Task
of	I-Task
SIFT	I-Task
Flow	I-Task
.	O
	
All	O
experiments	O
follow	O
the	O
same	O
network	B-Method
architecture	I-Method
and	O
optimization	O
settings	O
decided	O
on	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Metrics	O
	
We	O
report	O
metrics	O
from	O
common	O
semantic	B-Task
segmentation	I-Task
and	O
scene	B-Task
parsing	I-Task
evaluations	I-Task
that	O
are	O
variations	O
on	O
pixel	B-Metric
accuracy	I-Metric
and	O
region	B-Metric
intersection	I-Metric
over	I-Metric
union	I-Metric
(	O
IU	B-Metric
)	O
:	O
	
pixel	B-Metric
accuracy	I-Metric
:	O
	
mean	B-Metric
accuraccy	I-Metric
:	O
mean	B-Metric
IU	I-Metric
:	O
frequency	O
weighted	O
IU	B-Metric
:	O
where	O
is	O
the	O
number	O
of	O
pixels	O
of	O
class	O
predicted	O
to	O
belong	O
to	O
class	O
,	O
there	O
are	O
different	O
classes	O
,	O
and	O
is	O
the	O
total	O
number	O
of	O
pixels	O
of	O
class	O
.	O
	
PASCAL	B-Material
VOC	I-Material
Table	O
[	O
reference	O
]	O
gives	O
the	O
performance	O
of	O
our	O
FCN	B-Method
-	I-Method
8s	I-Method
on	O
the	O
test	O
sets	O
of	O
PASCAL	B-Material
VOC	I-Material
2011	O
and	O
2012	B-Material
,	O
and	O
compares	O
it	O
to	O
the	O
previous	O
best	O
,	O
SDS	B-Method
,	O
and	O
the	O
well	O
-	O
known	O
R	B-Method
-	I-Method
CNN	I-Method
.	O
	
We	O
achieve	O
the	O
best	O
results	O
on	O
mean	B-Metric
IU	I-Metric
by	O
30	O
%	O
relative	O
.	O
	
Inference	B-Metric
time	I-Metric
is	O
reduced	O
(	O
convnet	B-Method
only	O
,	O
ignoring	O
proposals	O
and	O
refinement	O
)	O
or	O
(	O
overall	O
)	O
.	O
	
NYUDv2	O
is	O
an	O
RGB	O
-	O
D	O
dataset	O
collected	O
using	O
the	O
Microsoft	O
Kinect	O
.	O
	
It	O
has	O
1	O
,	O
449	O
RGB	O
-	O
D	O
images	O
,	O
with	O
pixelwise	O
labels	O
that	O
have	O
been	O
coalesced	O
into	O
a	O
40	O
class	O
semantic	B-Task
segmentation	I-Task
task	O
by	O
Gupta	O
et	O
al	O
.	O
.	O
	
We	O
report	O
results	O
on	O
the	O
standard	O
split	O
of	O
795	O
training	O
images	O
and	O
654	O
testing	O
images	O
.	O
	
Table	O
[	O
reference	O
]	O
gives	O
the	O
performance	O
of	O
several	O
net	O
variations	O
.	O
	
First	O
we	O
train	O
our	O
unmodified	B-Method
coarse	I-Method
model	I-Method
(	O
FCN	B-Method
-	O
32s	O
)	O
on	O
RGB	O
images	O
.	O
	
To	O
add	O
depth	O
information	O
,	O
we	O
train	O
on	O
a	O
model	O
upgraded	O
to	O
take	O
four	O
-	O
channel	O
RGB	O
-	O
D	O
input	O
(	O
early	B-Task
fusion	I-Task
)	O
.	O
	
This	O
provides	O
little	O
benefit	O
,	O
perhaps	O
due	O
to	O
similar	O
number	O
of	O
parameters	O
or	O
the	O
difficulty	O
of	O
propagating	O
meaningful	O
gradients	O
all	O
the	O
way	O
through	O
the	O
net	O
.	O
	
Following	O
the	O
success	O
of	O
Gupta	O
et	O
al	O
.	O
,	O
we	O
try	O
the	O
three	B-Method
-	I-Method
dimensional	I-Method
HHA	I-Method
encoding	I-Method
of	I-Method
depth	I-Method
and	O
train	O
a	O
net	O
on	O
just	O
this	O
information	O
.	O
	
To	O
effectively	O
combine	O
color	O
and	O
depth	O
,	O
we	O
define	O
a	O
“	O
late	B-Method
fusion	I-Method
”	O
of	O
RGB	B-Method
and	O
HHA	B-Method
that	O
averages	O
the	O
final	O
layer	O
scores	O
from	O
both	O
nets	O
and	O
learn	O
the	O
resulting	O
two	O
-	O
stream	B-Method
net	I-Method
end	O
-	O
to	O
-	O
end	O
.	O
	
This	O
late	B-Method
fusion	I-Method
RGB	I-Method
-	I-Method
HHA	I-Method
net	I-Method
is	O
the	O
most	O
accurate	O
.	O
	
SIFT	B-Method
Flow	I-Method
is	O
a	O
dataset	O
of	O
2	O
,	O
688	O
images	O
with	O
pixel	O
labels	O
for	O
33	O
semantic	O
classes	O
(	O
“	O
bridge	O
”	O
,	O
“	O
mountain	O
”	O
,	O
“	O
sun	O
”	O
)	O
,	O
as	O
well	O
as	O
three	O
geometric	O
classes	O
(	O
“	O
horizontal	O
”	O
,	O
“	O
vertical	O
”	O
,	O
and	O
“	O
sky	O
”	O
)	O
.	O
	
An	O
FCN	B-Method
can	O
naturally	O
learn	O
a	O
joint	B-Method
representation	I-Method
that	O
simultaneously	O
predicts	O
both	O
types	O
of	O
labels	O
.	O
	
We	O
learn	O
a	O
two	O
-	O
headed	O
version	O
of	O
FCN	B-Method
-	O
32	O
/	O
16	O
/	O
8s	O
with	O
semantic	B-Method
and	I-Method
geometric	I-Method
prediction	I-Method
layers	I-Method
and	O
losses	B-Method
.	O
	
This	O
net	O
performs	O
as	O
well	O
on	O
both	O
tasks	O
as	O
two	O
independently	O
trained	O
nets	O
,	O
while	O
learning	B-Task
and	O
inference	B-Task
are	O
essentially	O
as	O
fast	O
as	O
each	O
independent	O
net	O
by	O
itself	O
.	O
	
The	O
results	O
in	O
Table	O
[	O
reference	O
]	O
,	O
computed	O
on	O
the	O
standard	O
split	O
into	O
2	O
,	O
488	O
training	O
and	O
200	O
test	O
images	O
,	O
show	O
better	O
performance	O
on	O
both	O
tasks	O
.	O
	
pixel	B-Metric
acc	I-Metric
.	O
	
mean	B-Metric
acc	I-Metric
.	O
	
mean	B-Metric
	
IU	B-Metric
f.w	O
.	O
	
IU	B-Metric
pixel	O
acc	O
.	O
	
mean	B-Metric
acc	I-Metric
.	O
	
mean	B-Metric
	
IU	B-Metric
f.w	O
.	O
	
IU	B-Metric
geom	O
.	O
	
acc	B-Metric
.	O
	
pixel	B-Metric
acc	I-Metric
.	O
	
mean	B-Metric
acc	I-Metric
.	O
	
mean	B-Metric
	
IU	B-Metric
f.w	O
.	O
	
IU	B-Metric
PASCAL	I-Material
-	I-Material
Context	I-Material
provides	O
whole	O
scene	O
annotations	O
of	O
PASCAL	B-Material
VOC	I-Material
2010	O
.	O
	
While	O
there	O
are	O
400	O
+	O
classes	O
,	O
we	O
follow	O
the	O
59	O
class	B-Task
task	I-Task
defined	O
by	O
that	O
picks	O
the	O
most	O
frequent	O
classes	O
.	O
	
We	O
train	O
and	O
evaluate	O
on	O
the	O
training	O
and	O
val	B-Metric
sets	O
respectively	O
.	O
	
In	O
Table	O
[	O
reference	O
]	O
we	O
compare	O
to	O
the	O
previous	O
best	O
result	O
on	O
this	O
task	O
.	O
	
FCN	B-Method
-	I-Method
8s	I-Method
scores	O
39.1	O
mean	B-Metric
IU	I-Metric
for	O
a	O
relative	O
improvement	O
of	O
more	O
than	O
10	O
%	O
.	O
	
section	O
:	O
Analysis	O
	
We	O
examine	O
the	O
learning	O
and	O
inference	O
of	O
fully	B-Method
convolutional	I-Method
networks	O
.	O
	
Masking	O
experiments	O
investigate	O
the	O
role	O
of	O
context	O
and	O
shape	O
by	O
reducing	O
the	O
input	O
to	O
only	O
foreground	O
,	O
only	O
background	O
,	O
or	O
shape	O
alone	O
.	O
	
Defining	O
a	O
“	O
null	B-Method
”	I-Method
background	I-Method
model	I-Method
checks	O
the	O
necessity	O
of	O
learning	O
a	O
background	B-Method
classifier	I-Method
for	O
semantic	B-Task
segmentation	I-Task
.	O
	
We	O
detail	O
an	O
approximation	O
between	O
momentum	O
and	O
batch	O
size	O
to	O
further	O
tune	O
whole	B-Task
image	I-Task
learning	I-Task
.	O
	
Finally	O
,	O
we	O
measure	O
bounds	O
on	O
task	B-Metric
accuracy	I-Metric
for	O
given	O
output	O
resolutions	O
to	O
show	O
there	O
is	O
still	O
much	O
to	O
improve	O
.	O
	
subsection	O
:	O
Cues	O
	
Given	O
the	O
large	O
receptive	O
field	O
size	O
of	O
an	O
FCN	B-Method
,	O
it	O
is	O
natural	O
to	O
wonder	O
about	O
the	O
relative	O
importance	O
of	O
foreground	O
and	O
background	O
pixels	O
in	O
the	O
prediction	B-Task
.	O
	
Is	O
foreground	O
appearance	O
sufficient	O
for	O
inference	B-Task
,	O
or	O
does	O
the	O
context	O
influence	O
the	O
output	O
?	O
	
Conversely	O
,	O
can	O
a	O
network	O
learn	O
to	O
recognize	O
a	O
class	O
by	O
its	O
shape	O
and	O
context	O
alone	O
?	O
	
Masking	B-Task
To	O
explore	O
these	O
issues	O
we	O
experiment	O
with	O
masked	B-Method
versions	I-Method
of	O
the	O
standard	O
PASCAL	B-Material
VOC	I-Material
segmentation	O
challenge	O
.	O
	
We	O
both	O
mask	O
input	O
to	O
networks	O
trained	O
on	O
normal	B-Material
PASCAL	I-Material
,	O
and	O
learn	O
new	O
networks	O
on	O
the	O
masked	B-Material
PASCAL	I-Material
.	O
	
See	O
Table	O
[	O
reference	O
]	O
for	O
masked	O
results	O
.	O
	
Masking	O
the	O
foreground	O
at	O
inference	O
time	O
is	O
catastrophic	O
.	O
	
However	O
,	O
masking	O
the	O
foreground	O
during	O
learning	O
yields	O
a	O
network	O
capable	O
of	O
recognizing	B-Task
object	I-Task
segments	I-Task
without	O
observing	O
a	O
single	O
pixel	O
of	O
the	O
labeled	O
class	O
.	O
	
Masking	O
the	O
background	O
has	O
little	O
effect	O
overall	O
but	O
does	O
lead	O
to	O
class	O
confusion	O
in	O
certain	O
cases	O
.	O
	
When	O
the	O
background	O
is	O
masked	O
during	O
both	O
learning	B-Task
and	O
inference	B-Task
,	O
the	O
network	O
unsurprisingly	O
achieves	O
nearly	O
perfect	O
background	B-Metric
accuracy	I-Metric
;	O
however	O
certain	O
classes	O
are	O
more	O
confused	O
.	O
	
All	O
-	O
in	O
-	O
all	O
this	O
suggests	O
that	O
FCNs	B-Method
do	O
incorporate	O
context	O
even	O
though	O
decisions	O
are	O
driven	O
by	O
foreground	O
pixels	O
.	O
	
To	O
separate	O
the	O
contribution	O
of	O
shape	O
,	O
we	O
learn	O
a	O
net	O
restricted	O
to	O
the	O
simple	O
input	O
of	O
foreground	O
/	O
background	O
masks	O
.	O
	
The	O
accuracy	B-Metric
in	O
this	O
shape	O
-	O
only	O
condition	O
is	O
lower	O
than	O
when	O
only	O
the	O
foreground	O
is	O
masked	O
,	O
suggesting	O
that	O
the	O
net	O
is	O
capable	O
of	O
learning	O
context	O
to	O
boost	O
recognition	B-Task
.	O
	
Nonetheless	O
,	O
it	O
is	O
surprisingly	O
accurate	O
.	O
	
See	O
Figure	O
[	O
reference	O
]	O
.	O
	
Background	B-Method
modeling	I-Method
	
It	O
is	O
standard	O
in	O
detection	B-Task
and	O
semantic	B-Task
segmentation	I-Task
to	O
have	O
a	O
background	B-Method
model	I-Method
.	O
	
This	O
model	O
usually	O
takes	O
the	O
same	O
form	O
as	O
the	O
models	O
for	O
the	O
classes	O
of	O
interest	O
,	O
but	O
is	O
supervised	O
by	O
negative	O
instances	O
.	O
	
In	O
our	O
experiments	O
we	O
have	O
followed	O
the	O
same	O
approach	O
,	O
learning	O
parameters	O
to	O
score	O
all	O
classes	O
including	O
background	O
.	O
	
Is	O
this	O
actually	O
necessary	O
,	O
or	O
do	O
class	B-Method
models	I-Method
suffice	O
?	O
	
To	O
investigate	O
,	O
we	O
define	O
a	O
net	B-Method
with	O
a	O
“	O
null	B-Method
”	I-Method
background	I-Method
model	I-Method
that	O
gives	O
a	O
constant	O
score	O
of	O
zero	O
.	O
	
Instead	O
of	O
training	O
with	O
the	O
softmax	O
loss	O
,	O
which	O
induces	O
competition	O
by	O
normalizing	O
across	O
classes	O
,	O
we	O
train	O
with	O
the	O
sigmoid	B-Method
cross	I-Method
-	I-Method
entropy	I-Method
loss	I-Method
,	O
which	O
independently	O
normalizes	O
each	O
score	O
.	O
	
For	O
inference	O
each	O
pixel	O
is	O
assigned	O
the	O
highest	O
scoring	O
class	O
.	O
	
In	O
all	O
other	O
respects	O
the	O
experiment	O
is	O
identical	O
to	O
our	O
FCN	B-Method
-	O
32s	O
on	O
PASCAL	B-Material
VOC	I-Material
.	O
	
The	O
null	O
background	O
net	O
scores	O
1	O
point	O
lower	O
than	O
the	O
reference	O
FCN	B-Method
-	O
32s	O
and	O
a	O
control	O
FCN	B-Method
-	O
32s	O
trained	O
on	O
all	O
classes	O
including	O
background	O
with	O
the	O
sigmoid	O
cross	O
-	O
entropy	O
loss	O
.	O
	
To	O
put	O
this	O
drop	O
in	O
perspective	O
,	O
note	O
that	O
discarding	O
the	O
background	B-Method
model	I-Method
in	O
this	O
way	O
reduces	O
the	O
total	O
number	O
of	O
parameters	O
by	O
less	O
than	O
0.1	O
%	O
.	O
	
Nonetheless	O
,	O
this	O
result	O
suggests	O
that	O
learning	O
a	O
dedicated	O
background	B-Method
model	I-Method
for	O
semantic	B-Task
segmentation	I-Task
is	O
not	O
vital	O
.	O
	
Image	O
Ground	O
Truth	O
Output	O
Input	O
	
subsection	O
:	O
Momentum	O
and	O
batch	B-Metric
size	I-Metric
	
In	O
comparing	O
optimization	B-Method
schemes	I-Method
for	O
FCNs	B-Method
,	O
we	O
find	O
that	O
“	O
heavy	O
”	O
online	B-Method
learning	I-Method
with	O
high	O
momentum	O
trains	O
more	O
accurate	O
models	O
in	O
less	O
wall	O
clock	O
time	O
(	O
see	O
Section	O
[	O
reference	O
]	O
)	O
.	O
	
Here	O
we	O
detail	O
a	O
relationship	O
between	O
momentum	O
and	O
batch	O
size	O
that	O
motivates	O
heavy	B-Method
learning	I-Method
.	O
	
By	O
writing	O
the	O
updates	O
computed	O
by	O
gradient	B-Method
accumulation	I-Method
as	O
a	O
non	B-Method
-	I-Method
recursive	I-Method
sum	I-Method
,	O
we	O
will	O
see	O
that	O
momentum	O
and	O
batch	O
size	O
can	O
be	O
approximately	O
traded	O
off	O
,	O
which	O
suggests	O
alternative	O
training	O
parameters	O
.	O
	
Let	O
be	O
the	O
step	O
taken	O
by	O
minibatch	B-Method
SGD	I-Method
with	O
momentum	O
at	O
time	O
,	O
where	O
is	O
the	O
loss	O
for	O
example	O
and	O
parameters	O
,	O
is	O
the	O
momentum	O
,	O
is	O
the	O
batch	O
size	O
,	O
and	O
is	O
the	O
learning	B-Metric
rate	I-Metric
.	O
	
Expanding	O
this	O
recurrence	O
as	O
an	O
infinite	O
sum	O
with	O
geometric	O
coefficients	O
,	O
we	O
have	O
	
In	O
other	O
words	O
,	O
each	O
example	O
is	O
included	O
in	O
the	O
sum	O
with	O
coefficient	O
,	O
where	O
the	O
index	O
orders	O
the	O
examples	O
from	O
most	O
recently	O
considered	O
to	O
least	O
recently	O
considered	O
.	O
	
Approximating	O
this	O
expression	O
by	O
dropping	O
the	O
floor	O
,	O
we	O
see	O
that	O
learning	O
with	O
momentum	O
and	O
batch	O
size	O
appears	O
to	O
be	O
similar	O
to	O
learning	O
with	O
momentum	B-Method
and	O
batch	O
size	O
if	O
.	O
	
Note	O
that	O
this	O
is	O
not	O
an	O
exact	O
equivalence	O
:	O
	
a	O
smaller	O
batch	O
size	O
results	O
in	O
more	O
frequent	O
weight	O
updates	O
,	O
and	O
may	O
make	O
more	O
learning	O
progress	O
for	O
the	O
same	O
number	O
of	O
gradient	O
computations	O
.	O
	
For	O
typical	O
FCN	B-Method
values	O
of	O
momentum	B-Method
and	O
a	O
batch	O
size	O
of	O
20	O
images	O
,	O
an	O
approximately	O
equivalent	O
training	B-Method
regime	I-Method
uses	O
momentum	B-Method
and	O
a	O
batch	O
size	O
of	O
one	O
,	O
resulting	O
in	O
online	B-Method
learning	I-Method
.	O
	
In	O
practice	O
,	O
we	O
find	O
that	O
online	B-Method
learning	I-Method
works	O
well	O
and	O
yields	O
better	O
FCN	B-Method
models	O
in	O
less	O
wall	B-Metric
clock	I-Metric
time	I-Metric
.	O
	
subsection	O
:	O
Upper	B-Metric
bounds	I-Metric
on	O
IU	B-Metric
	
FCNs	B-Method
achieve	O
good	O
performance	O
on	O
the	O
mean	B-Metric
IU	I-Metric
segmentation	O
metric	O
even	O
with	O
spatially	B-Task
coarse	I-Task
semantic	I-Task
prediction	I-Task
.	O
	
To	O
better	O
understand	O
this	O
metric	O
and	O
the	O
limits	O
of	O
this	O
approach	O
with	O
respect	O
to	O
it	O
,	O
we	O
compute	O
approximate	O
upper	O
bounds	O
on	O
performance	O
with	O
prediction	B-Task
at	O
various	O
resolutions	O
.	O
	
We	O
do	O
this	O
by	O
downsampling	O
ground	O
truth	O
images	O
and	O
then	O
upsampling	O
back	O
to	O
simulate	O
the	O
best	O
results	O
obtainable	O
with	O
a	O
particular	O
downsampling	O
factor	O
.	O
	
The	O
following	O
table	O
gives	O
the	O
mean	B-Metric
IU	I-Metric
on	O
a	O
subset	O
of	O
PASCAL	O
2011	O
val	B-Metric
for	O
various	O
downsampling	O
factors	O
.	O
	
Pixel	B-Task
-	I-Task
perfect	I-Task
prediction	I-Task
is	O
clearly	O
not	O
necessary	O
to	O
achieve	O
mean	B-Metric
IU	I-Metric
well	O
above	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
,	O
and	O
,	O
conversely	O
,	O
mean	B-Metric
IU	I-Metric
is	O
a	O
not	O
a	O
good	O
measure	O
of	O
fine	B-Metric
-	I-Metric
scale	I-Metric
accuracy	I-Metric
.	O
	
The	O
gaps	O
between	O
oracle	O
and	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
accuracy	B-Metric
at	O
every	O
stride	O
suggest	O
that	O
recognition	B-Task
and	O
not	O
resolution	B-Task
is	O
the	O
bottleneck	O
for	O
this	O
metric	O
.	O
	
section	O
:	O
Conclusion	O
	
Fully	B-Method
convolutional	I-Method
networks	I-Method
are	O
a	O
rich	O
class	O
of	O
models	O
that	O
address	O
many	O
pixelwise	B-Task
tasks	I-Task
.	O
	
FCNs	B-Method
for	O
semantic	B-Task
segmentation	I-Task
dramatically	O
improve	O
accuracy	B-Metric
by	O
transferring	O
pre	O
-	O
trained	O
classifier	O
weights	O
,	O
fusing	O
different	O
layer	B-Method
representations	I-Method
,	O
and	O
learning	O
end	O
-	O
to	O
-	O
end	O
on	O
whole	O
images	O
.	O
	
End	O
-	O
to	O
-	O
end	O
,	O
pixel	O
-	O
to	O
-	O
pixel	O
operation	O
simultaneously	O
simplifies	O
and	O
speeds	O
up	O
learning	B-Task
and	I-Task
inference	I-Task
.	O
	
All	O
code	O
for	O
this	O
paper	O
is	O
open	O
source	O
in	O
Caffe	O
,	O
and	O
all	O
models	O
are	O
freely	O
available	O
in	O
the	O
Caffe	O
Model	O
Zoo	O
.	O
	
Further	O
works	O
have	O
demonstrated	O
the	O
generality	O
of	O
fully	B-Method
convolutional	I-Method
networks	O
for	O
a	O
variety	O
of	O
image	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
tasks	I-Task
.	O
	
section	O
:	O
Acknowledgements	O
	
This	O
work	O
was	O
supported	O
in	O
part	O
by	O
DARPA	O
’s	O
MSEE	O
and	O
SMISC	O
programs	O
,	O
NSF	O
awards	O
IIS	O
-	O
1427425	O
,	O
IIS	O
-	O
1212798	O
,	O
IIS	O
-	O
1116411	O
,	O
and	O
the	O
NSF	O
GRFP	O
,	O
Toyota	O
,	O
and	O
the	O
Berkeley	O
Vision	O
and	O
Learning	O
Center	O
.	O
	
We	O
gratefully	O
acknowledge	O
NVIDIA	O
for	O
GPU	O
donation	O
.	O
	
We	O
thank	O
Bharath	O
Hariharan	O
and	O
Saurabh	O
Gupta	O
for	O
their	O
advice	O
and	O
dataset	O
tools	O
.	O
	
We	O
thank	O
Sergio	O
Guadarrama	O
for	O
reproducing	O
GoogLeNet	O
in	O
Caffe	O
.	O
	
We	O
thank	O
Jitendra	O
Malik	O
for	O
his	O
helpful	O
comments	O
.	O
	
Thanks	O
to	O
Wei	O
Liu	O
for	O
pointing	O
out	O
an	O
issue	O
wth	O
	
our	O
SIFT	O
Flow	O
mean	B-Metric
IU	I-Metric
computation	O
and	O
an	O
error	O
in	O
our	O
frequency	O
	
weighted	O
mean	B-Metric
IU	I-Metric
formula	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Long	B-Method
Short	I-Method
-	I-Method
Term	I-Method
Memory	I-Method
-	I-Method
Networks	I-Method
for	O
Machine	B-Task
Reading	I-Task
	
In	O
this	O
paper	O
we	O
address	O
the	O
question	O
of	O
how	O
to	O
render	O
sequence	B-Method
-	I-Method
level	I-Method
networks	I-Method
better	O
at	O
handling	O
structured	O
input	O
.	O
	
We	O
propose	O
a	O
machine	B-Method
reading	I-Method
simulator	I-Method
which	O
processes	O
text	O
incrementally	O
from	O
left	O
to	O
right	O
and	O
performs	O
shallow	B-Method
reasoning	I-Method
with	O
memory	O
and	O
attention	O
.	O
	
The	O
reader	O
extends	O
the	O
Long	B-Method
Short	I-Method
-	I-Method
Term	I-Method
Memory	I-Method
architecture	O
with	O
a	O
memory	B-Method
network	I-Method
in	O
place	O
of	O
a	O
single	O
memory	O
cell	O
.	O
	
This	O
enables	O
adaptive	O
memory	O
usage	O
during	O
recurrence	B-Task
with	O
neural	O
attention	O
,	O
offering	O
a	O
way	O
to	O
weakly	O
induce	O
relations	O
among	O
tokens	O
.	O
	
The	O
system	O
is	O
initially	O
designed	O
to	O
process	O
a	O
single	O
sequence	O
but	O
we	O
also	O
demonstrate	O
how	O
to	O
integrate	O
it	O
with	O
an	O
encoder	B-Method
-	I-Method
decoder	I-Method
architecture	I-Method
.	O
	
Experiments	O
on	O
language	B-Task
modeling	I-Task
,	O
sentiment	B-Task
analysis	I-Task
,	O
and	O
natural	B-Task
language	I-Task
inference	I-Task
show	O
that	O
our	O
model	O
matches	O
or	O
outperforms	O
the	O
state	O
of	O
the	O
art	O
.	O
	
section	O
:	O
Introduction	O
	
How	O
can	O
a	O
sequence	B-Method
-	I-Method
level	I-Method
network	I-Method
induce	O
relations	O
which	O
are	O
presumed	O
latent	O
during	O
text	B-Task
processing	I-Task
?	O
	
How	O
can	O
a	O
recurrent	B-Method
network	I-Method
attentively	O
memorize	O
longer	O
sequences	O
in	O
a	O
way	O
that	O
humans	O
do	O
?	O
	
In	O
this	O
paper	O
we	O
design	O
a	O
machine	B-Method
reader	I-Method
that	O
automatically	O
learns	O
to	O
understand	O
text	O
.	O
	
The	O
term	O
machine	B-Task
reading	I-Task
is	O
related	O
to	O
a	O
wide	O
range	O
of	O
tasks	O
from	O
answering	B-Task
reading	I-Task
comprehension	I-Task
questions	I-Task
,	O
to	O
fact	B-Task
and	I-Task
relation	I-Task
extraction	I-Task
,	O
ontology	B-Task
learning	I-Task
,	O
and	O
textual	B-Task
entailment	I-Task
.	O
	
Rather	O
than	O
focusing	O
on	O
a	O
specific	O
task	O
,	O
we	O
develop	O
a	O
general	B-Method
-	I-Method
purpose	I-Method
reading	I-Method
simulator	I-Method
,	O
drawing	O
inspiration	O
from	O
human	B-Task
language	I-Task
processing	I-Task
and	O
the	O
fact	B-Task
language	I-Task
comprehension	I-Task
is	O
incremental	O
with	O
readers	O
continuously	O
extracting	O
the	O
meaning	O
of	O
utterances	O
on	O
a	O
word	O
-	O
by	O
-	O
word	O
basis	O
.	O
	
In	O
order	O
to	O
understand	O
texts	O
,	O
our	O
machine	B-Method
reader	I-Method
should	O
provide	O
facilities	O
for	O
extracting	B-Task
and	I-Task
representing	I-Task
meaning	I-Task
from	O
natural	O
language	O
text	O
,	O
storing	O
meanings	O
internally	O
,	O
and	O
working	O
with	O
stored	O
meanings	O
to	O
derive	O
further	O
consequences	O
.	O
	
Ideally	O
,	O
such	O
a	O
system	O
should	O
be	O
robust	O
,	O
open	O
-	O
domain	O
,	O
and	O
degrade	O
gracefully	O
in	O
the	O
presence	O
of	O
semantic	B-Method
representations	I-Method
which	O
may	O
be	O
incomplete	O
,	O
inaccurate	O
,	O
or	O
incomprehensible	O
.	O
	
It	O
would	O
also	O
be	O
desirable	O
to	O
simulate	O
the	O
behavior	O
of	O
English	O
speakers	O
who	O
process	O
text	O
sequentially	O
,	O
from	O
left	O
to	O
right	O
,	O
fixating	O
nearly	O
every	O
word	O
while	O
they	O
read	O
and	O
creating	O
partial	B-Method
representations	I-Method
for	O
sentence	O
prefixes	O
.	O
	
Language	B-Method
modeling	I-Method
tools	I-Method
such	O
as	O
recurrent	B-Method
neural	I-Method
networks	I-Method
	
(	O
RNN	B-Method
)	O
bode	O
well	O
with	O
human	O
reading	O
behavior	O
.	O
	
RNNs	B-Method
treat	O
each	O
sentence	O
as	O
a	O
sequence	O
of	O
words	O
and	O
recursively	O
compose	O
each	O
word	O
with	O
its	O
previous	O
memory	O
,	O
until	O
the	O
meaning	O
of	O
the	O
whole	O
sentence	O
has	O
been	O
derived	O
.	O
	
In	O
practice	O
,	O
however	O
,	O
sequence	B-Method
-	I-Method
level	I-Method
networks	I-Method
are	O
met	O
with	O
at	O
least	O
three	O
challenges	O
.	O
	
The	O
first	O
one	O
concerns	O
model	B-Task
training	I-Task
problems	I-Task
associated	O
with	O
vanishing	B-Task
and	I-Task
exploding	I-Task
gradients	I-Task
,	O
which	O
can	O
be	O
partially	O
ameliorated	O
with	O
gated	B-Method
activation	I-Method
functions	I-Method
,	O
such	O
as	O
the	O
Long	B-Method
Short	I-Method
-	I-Method
Term	I-Method
Memory	I-Method
(	O
LSTM	B-Method
)	O
,	O
and	O
gradient	B-Method
clipping	I-Method
.	O
	
The	O
second	O
issue	O
relates	O
to	O
memory	B-Task
compression	I-Task
problems	I-Task
.	O
	
As	O
the	O
input	O
sequence	O
gets	O
compressed	O
and	O
blended	O
into	O
a	O
single	O
dense	O
vector	O
,	O
sufficiently	O
large	O
memory	O
capacity	O
is	O
required	O
to	O
store	O
past	O
information	O
.	O
	
As	O
a	O
result	O
,	O
the	O
network	O
generalizes	O
poorly	O
to	O
long	O
sequences	O
while	O
wasting	O
memory	O
on	O
shorter	O
ones	O
.	O
	
Finally	O
,	O
it	O
should	O
be	O
acknowledged	O
that	O
sequence	B-Method
-	I-Method
level	I-Method
networks	I-Method
lack	O
a	O
mechanism	O
for	O
handling	O
the	O
structure	O
of	O
the	O
input	O
.	O
	
This	O
imposes	O
an	O
inductive	O
bias	O
which	O
is	O
at	O
odds	O
with	O
the	O
fact	O
that	O
language	O
has	O
inherent	O
structure	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
develop	O
a	O
text	B-Method
processing	I-Method
system	I-Method
which	O
addresses	O
these	O
limitations	O
while	O
maintaining	O
the	O
incremental	O
,	O
generative	O
property	O
of	O
a	O
recurrent	B-Method
language	I-Method
model	I-Method
.	O
	
The	O
The	O
The	O
The	O
FBI	O
FBI	O
	
The	O
The	O
FBI	B-Method
FBI	O
is	O
is	O
	
The	O
The	O
FBI	O
FBI	O
is	O
is	O
chasing	O
chasing	O
	
The	O
The	O
FBI	O
FBI	O
is	O
is	O
chasing	O
chasing	O
	
a	O
a	O
The	O
The	O
FBI	O
FBI	O
is	O
is	O
chasing	O
chasing	O
a	O
a	O
criminal	O
criminal	O
The	O
The	O
FBI	O
FBI	O
is	O
is	O
chasing	O
chasing	O
a	O
a	O
criminal	O
criminal	O
on	O
on	O
The	O
The	O
FBI	O
FBI	O
is	O
is	O
chasing	O
chasing	O
a	O
a	O
criminal	O
criminal	O
on	O
on	O
the	O
the	O
The	O
The	O
FBI	O
FBI	O
is	O
is	O
chasing	O
chasing	O
a	O
a	O
criminal	O
criminal	O
on	O
on	O
the	O
the	O
run	O
run	O
Recent	O
attempts	O
to	O
render	O
neural	B-Method
networks	I-Method
more	O
structure	O
aware	O
have	O
seen	O
the	O
incorporation	O
of	O
external	O
memories	O
in	O
the	O
context	O
of	O
recurrent	B-Method
neural	I-Method
networks	I-Method
.	O
	
The	O
idea	O
is	O
to	O
use	O
multiple	O
memory	O
slots	O
outside	O
the	O
recurrence	O
to	O
piece	O
-	O
wise	O
store	O
representations	O
of	O
the	O
input	O
;	O
read	O
and	O
write	O
operations	O
for	O
each	O
slot	O
can	O
be	O
modeled	O
as	O
an	O
attention	B-Method
mechanism	I-Method
with	O
a	O
recurrent	B-Method
controller	I-Method
.	O
	
We	O
also	O
leverage	O
memory	O
and	O
attention	O
to	O
empower	O
a	O
recurrent	B-Method
network	I-Method
with	O
stronger	O
memorization	O
capability	O
and	O
more	O
importantly	O
the	O
ability	O
to	O
discover	O
relations	O
among	O
tokens	O
.	O
	
This	O
is	O
realized	O
by	O
inserting	O
a	O
memory	B-Method
network	I-Method
module	I-Method
in	O
the	O
update	O
of	O
a	O
recurrent	B-Method
network	I-Method
together	O
with	O
attention	B-Method
for	O
memory	B-Task
addressing	I-Task
.	O
	
The	O
attention	B-Method
acts	O
as	O
a	O
weak	O
inductive	B-Method
module	I-Method
discovering	O
relations	O
between	O
input	O
tokens	O
,	O
and	O
is	O
trained	O
without	O
direct	O
supervision	O
.	O
	
As	O
a	O
point	O
of	O
departure	O
from	O
previous	O
work	O
,	O
the	O
memory	B-Method
network	I-Method
we	O
employ	O
is	O
internal	O
to	O
the	O
recurrence	O
,	O
thus	O
strengthening	O
the	O
interaction	O
of	O
the	O
two	O
and	O
leading	O
to	O
a	O
representation	B-Method
learner	I-Method
which	O
is	O
able	O
to	O
reason	O
over	O
shallow	O
structures	O
.	O
	
The	O
resulting	O
model	O
,	O
which	O
we	O
term	O
Long	B-Method
Short	I-Method
-	I-Method
Term	I-Method
Memory	I-Method
-	I-Method
Network	I-Method
(	O
LSTMN	B-Method
)	O
,	O
is	O
a	O
reading	B-Method
simulator	I-Method
that	O
can	O
be	O
used	O
for	O
sequence	B-Task
processing	I-Task
tasks	I-Task
.	O
	
Figure	O
[	O
reference	O
]	O
illustrates	O
the	O
reading	O
behavior	O
of	O
the	O
LSTMN	B-Method
.	O
	
The	O
model	O
processes	O
text	O
incrementally	O
while	O
learning	O
which	O
past	O
tokens	O
in	O
the	O
memory	O
and	O
to	O
what	O
extent	O
they	O
relate	O
to	O
the	O
current	O
token	O
being	O
processed	O
.	O
	
As	O
a	O
result	O
,	O
the	O
model	O
induces	O
undirected	O
relations	O
among	O
tokens	O
as	O
an	O
intermediate	O
step	O
of	O
learning	B-Method
representations	I-Method
.	O
	
We	O
validate	O
the	O
performance	O
of	O
the	O
LSTMN	B-Method
in	O
language	B-Task
modeling	I-Task
,	O
sentiment	B-Task
analysis	I-Task
,	O
and	O
natural	B-Task
language	I-Task
inference	I-Task
.	O
	
In	O
all	O
cases	O
,	O
we	O
train	O
LSTMN	B-Method
models	I-Method
end	O
-	O
to	O
-	O
end	O
with	O
task	O
-	O
specific	O
supervision	O
signals	O
,	O
achieving	O
performance	O
comparable	O
or	O
better	O
to	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
and	O
superior	O
to	O
vanilla	O
LSTMs	B-Method
.	O
	
section	O
:	O
Related	O
Work	O
	
Our	O
machine	B-Method
reader	I-Method
is	O
a	O
recurrent	B-Method
neural	I-Method
network	I-Method
exhibiting	O
two	O
important	O
properties	O
:	O
it	O
is	O
incremental	O
,	O
simulating	O
human	O
behavior	O
,	O
and	O
performs	O
shallow	B-Method
structure	I-Method
reasoning	I-Method
over	O
input	O
streams	O
.	O
	
Recurrent	B-Method
neural	I-Method
network	I-Method
(	O
RNNs	B-Method
)	O
have	O
been	O
successfully	O
applied	O
to	O
various	O
sequence	B-Task
modeling	I-Task
and	O
sequence	B-Task
-	I-Task
to	I-Task
-	I-Task
sequence	I-Task
transduction	I-Task
tasks	I-Task
.	O
	
The	O
latter	O
have	O
assumed	O
several	O
guises	O
in	O
the	O
literature	O
such	O
as	O
machine	B-Task
translation	I-Task
,	O
sentence	B-Task
compression	I-Task
,	O
and	O
reading	B-Task
comprehension	I-Task
.	O
	
A	O
key	O
contributing	O
factor	O
to	O
their	O
success	O
has	O
been	O
the	O
ability	O
to	O
handle	O
well	O
-	O
known	O
problems	O
with	O
exploding	O
or	O
vanishing	O
gradients	O
,	O
leading	O
to	O
models	O
with	O
gated	O
activation	O
functions	O
,	O
and	O
more	O
advanced	O
architectures	O
that	O
enhance	O
the	O
information	O
flow	O
within	O
the	O
network	O
.	O
	
A	O
remaining	O
practical	O
bottleneck	O
for	O
RNNs	B-Method
is	O
memory	B-Task
compression	I-Task
:	O
since	O
the	O
inputs	O
are	O
recursively	O
combined	O
into	O
a	O
single	O
memory	B-Method
representation	I-Method
which	O
is	O
typically	O
too	O
small	O
in	O
terms	O
of	O
parameters	B-Metric
,	O
it	O
becomes	O
difficult	O
to	O
accurately	O
memorize	O
sequences	O
.	O
	
In	O
the	O
encoder	B-Method
-	I-Method
decoder	I-Method
architecture	I-Method
,	O
this	O
problem	O
can	O
be	O
sidestepped	O
with	O
an	O
attention	B-Method
mechanism	I-Method
which	O
learns	O
soft	O
alignments	O
between	O
the	O
decoding	O
states	O
and	O
the	O
encoded	O
memories	O
.	O
	
In	O
our	O
model	O
,	O
memory	O
and	O
attention	O
are	O
added	O
within	O
a	O
sequence	B-Method
encoder	I-Method
allowing	O
the	O
network	O
to	O
uncover	O
lexical	O
relations	O
between	O
tokens	O
.	O
	
The	O
idea	O
of	O
introducing	O
a	O
structural	O
bias	O
to	O
neural	B-Method
models	I-Method
is	O
by	O
no	O
means	O
new	O
.	O
	
For	O
example	O
,	O
it	O
is	O
reflected	O
in	O
the	O
work	O
of	O
socher	O
-	O
EtAl:2013:EMNLP	O
who	O
apply	O
recursive	B-Method
neural	I-Method
networks	I-Method
for	O
learning	O
natural	B-Task
language	I-Task
representations	I-Task
.	O
	
In	O
the	O
context	O
of	O
recurrent	B-Method
neural	I-Method
networks	I-Method
,	O
efforts	O
to	O
build	O
modular	B-Method
,	I-Method
structured	I-Method
neural	I-Method
models	I-Method
date	O
back	O
to	O
das1992learning	O
who	O
connect	O
a	O
recurrent	B-Method
neural	I-Method
network	I-Method
with	O
an	O
external	B-Method
memory	I-Method
stack	I-Method
for	O
learning	O
context	B-Method
free	I-Method
grammars	I-Method
.	O
	
Recently	O
,	O
weston2014memory	O
propose	O
Memory	B-Method
Networks	I-Method
to	O
explicitly	O
segregate	O
memory	O
storage	O
from	O
the	O
computation	O
of	O
neural	B-Method
networks	I-Method
in	O
general	O
.	O
	
Their	O
model	O
is	O
trained	O
end	O
-	O
to	O
-	O
end	O
with	O
a	O
memory	B-Method
addressing	I-Method
mechanism	I-Method
closely	O
related	O
to	O
soft	O
attention	O
and	O
has	O
been	O
applied	O
to	O
machine	B-Task
translation	I-Task
.	O
	
grefenstette2015learning	O
define	O
a	O
set	O
of	O
differentiable	O
data	O
structures	O
(	O
stacks	O
,	O
queues	O
,	O
and	O
dequeues	O
)	O
as	O
memories	O
controlled	O
by	O
a	O
recurrent	B-Method
neural	I-Method
network	I-Method
.	O
	
ke2016memory	O
combine	O
the	O
LSTM	B-Method
with	O
an	O
external	B-Method
memory	I-Method
block	I-Method
component	I-Method
which	O
interacts	O
with	O
its	O
hidden	O
state	O
.	O
	
kumar2015ask	O
employ	O
a	O
structured	B-Method
neural	I-Method
network	I-Method
with	O
episodic	B-Method
memory	I-Method
modules	I-Method
for	O
natural	B-Task
language	I-Task
and	O
also	O
visual	B-Task
question	I-Task
answering	I-Task
.	O
	
Similar	O
to	O
the	O
above	O
work	O
,	O
we	O
leverage	O
memory	B-Method
and	I-Method
attention	I-Method
in	O
a	O
recurrent	B-Method
neural	I-Method
network	I-Method
for	O
inducing	O
relations	O
between	O
tokens	O
as	O
a	O
module	O
in	O
a	O
larger	O
network	O
responsible	O
for	O
representation	B-Task
learning	I-Task
.	O
	
As	O
a	O
property	O
of	O
soft	O
attention	O
,	O
all	O
intermediate	O
relations	O
we	O
aim	O
to	O
capture	O
are	O
soft	O
and	O
differentiable	O
.	O
	
This	O
is	O
in	O
contrast	O
to	O
shift	B-Method
-	I-Method
reduce	I-Method
type	I-Method
neural	I-Method
models	I-Method
where	O
the	O
intermediate	O
decisions	O
are	O
hard	O
and	O
induction	B-Task
is	O
more	O
difficult	O
.	O
	
Finally	O
,	O
note	O
that	O
our	O
model	O
captures	O
undirected	O
lexical	O
relations	O
and	O
is	O
thus	O
distinct	O
from	O
work	O
on	O
dependency	B-Task
grammar	I-Task
induction	I-Task
where	O
the	O
learned	O
head	O
-	O
modifier	O
relations	O
are	O
directed	O
.	O
	
section	O
:	O
The	O
Machine	O
Reader	O
	
In	O
this	O
section	O
we	O
present	O
our	O
machine	B-Method
reader	I-Method
which	O
is	O
designed	O
to	O
process	O
structured	O
input	O
while	O
retaining	O
the	O
incrementality	O
of	O
a	O
recurrent	B-Method
neural	I-Method
network	I-Method
.	O
	
The	O
core	O
of	O
our	O
model	O
is	O
a	O
Long	B-Method
Short	I-Method
-	I-Method
Term	I-Method
Memory	I-Method
(	O
LSTM	B-Method
)	O
unit	O
with	O
an	O
extended	O
memory	O
tape	O
that	O
explicitly	O
simulates	O
the	O
human	O
memory	O
span	O
.	O
	
The	O
model	O
performs	O
implicit	B-Task
relation	I-Task
analysis	I-Task
between	O
tokens	O
with	O
an	O
attention	B-Method
-	I-Method
based	I-Method
memory	I-Method
addressing	I-Method
mechanism	I-Method
at	O
every	O
time	O
step	O
.	O
	
In	O
the	O
following	O
,	O
we	O
first	O
review	O
the	O
standard	O
Long	B-Method
Short	I-Method
-	I-Method
Term	I-Method
Memory	I-Method
and	O
then	O
describe	O
our	O
model	O
.	O
	
subsection	O
:	O
Long	B-Method
Short	I-Method
-	I-Method
Term	I-Method
Memory	I-Method
	
A	O
Long	B-Method
Short	I-Method
-	I-Method
Term	I-Method
Memory	I-Method
(	O
LSTM	B-Method
)	O
recurrent	O
neural	O
network	O
processes	O
a	O
variable	O
-	O
length	O
sequence	O
by	O
incrementally	O
adding	O
new	O
content	O
into	O
a	O
single	O
memory	O
slot	O
,	O
with	O
gates	O
controlling	O
the	O
extent	O
to	O
which	O
new	O
content	O
should	O
be	O
memorized	O
,	O
old	O
content	O
should	O
be	O
erased	O
,	O
and	O
current	O
content	O
should	O
be	O
exposed	O
.	O
	
At	O
time	O
step	O
,	O
the	O
memory	O
and	O
the	O
hidden	O
state	O
are	O
updated	O
with	O
the	O
following	O
equations	O
:	O
where	O
,	O
,	O
and	O
are	O
gate	O
activations	O
.	O
	
Compared	O
to	O
the	O
standard	O
RNN	B-Method
,	O
the	O
LSTM	B-Method
uses	O
additive	B-Method
memory	I-Method
updates	I-Method
and	O
it	O
separates	O
the	O
memory	O
from	O
the	O
hidden	O
state	O
,	O
which	O
interacts	O
with	O
the	O
environment	O
when	O
making	O
predictions	B-Task
.	O
	
subsection	O
:	O
Long	B-Method
Short	I-Method
-	I-Method
Term	I-Method
Memory	I-Method
-	I-Method
Network	I-Method
	
The	O
first	O
question	O
that	O
arises	O
with	O
LSTMs	B-Method
is	O
the	O
extent	O
to	O
which	O
they	O
are	O
able	O
to	O
memorize	O
sequences	O
under	O
recursive	B-Method
compression	I-Method
.	O
	
LSTMs	B-Method
can	O
produce	O
a	O
list	O
of	O
state	B-Method
representations	I-Method
during	O
composition	B-Task
,	O
however	O
,	O
the	O
next	O
state	O
is	O
always	O
computed	O
from	O
the	O
current	O
state	O
.	O
	
That	O
is	O
to	O
say	O
,	O
given	O
the	O
current	O
state	O
,	O
the	O
next	O
state	O
is	O
conditionally	O
independent	O
of	O
states	O
and	O
tokens	O
.	O
	
While	O
the	O
recursive	B-Method
state	I-Method
update	I-Method
is	O
performed	O
in	O
a	O
Markov	B-Method
manner	I-Method
,	O
it	O
is	O
assumed	O
that	O
LSTMs	B-Method
maintain	O
unbounded	O
memory	O
(	O
i.e.	O
,	O
the	O
current	O
state	O
alone	O
summarizes	O
well	O
the	O
tokens	O
it	O
has	O
seen	O
so	O
far	O
)	O
.	O
	
This	O
assumption	O
may	O
fail	O
in	O
practice	O
,	O
for	O
example	O
when	O
the	O
sequence	O
is	O
long	O
or	O
when	O
the	O
memory	O
size	O
is	O
not	O
large	O
enough	O
.	O
	
Another	O
undesired	O
property	O
of	O
LSTMs	B-Method
concerns	O
modeling	B-Task
structured	I-Task
input	I-Task
.	O
	
An	O
LSTM	B-Method
aggregates	O
information	O
on	O
a	O
token	O
-	O
by	O
-	O
token	O
basis	O
in	O
sequential	O
order	O
,	O
but	O
there	O
is	O
no	O
explicit	O
mechanism	O
for	O
reasoning	O
over	O
structure	O
and	O
modeling	O
relations	O
between	O
tokens	O
.	O
	
Our	O
model	O
aims	O
to	O
address	O
both	O
limitations	O
.	O
	
Our	O
solution	O
is	O
to	O
modify	O
the	O
standard	O
LSTM	B-Method
structure	O
by	O
replacing	O
the	O
memory	O
cell	O
with	O
a	O
memory	B-Method
network	I-Method
.	O
	
The	O
resulting	O
Long	B-Method
Short	I-Method
-	I-Method
Term	I-Method
Memory	I-Method
-	I-Method
Network	I-Method
(	O
LSTMN	B-Method
)	O
stores	O
the	O
contextual	B-Method
representation	I-Method
of	O
each	O
input	O
token	O
with	O
a	O
unique	O
memory	O
slot	O
and	O
the	O
size	O
of	O
the	O
memory	O
grows	O
with	O
time	O
until	O
an	O
upper	O
bound	O
of	O
the	O
memory	O
span	O
is	O
reached	O
.	O
	
This	O
design	O
enables	O
the	O
LSTM	B-Method
to	O
reason	O
about	O
relations	O
between	O
tokens	O
with	O
a	O
neural	O
attention	B-Method
layer	I-Method
and	O
then	O
perform	O
non	B-Method
-	I-Method
Markov	I-Method
state	I-Method
updates	I-Method
.	O
	
Although	O
it	O
is	O
feasible	O
to	O
apply	O
both	O
write	O
and	O
read	O
operations	O
to	O
the	O
memories	O
with	O
attention	O
,	O
we	O
concentrate	O
on	O
the	O
latter	O
.	O
	
We	O
conceptualize	O
the	O
read	B-Method
operation	I-Method
as	O
attentively	O
linking	O
the	O
current	O
token	O
to	O
previous	O
memories	O
and	O
selecting	O
useful	O
content	O
when	O
processing	O
it	O
.	O
	
Although	O
not	O
the	O
focus	O
of	O
this	O
work	O
,	O
the	O
significance	O
of	O
the	O
write	B-Method
operation	I-Method
can	O
be	O
analogously	O
justified	O
as	O
a	O
way	O
of	O
incrementally	B-Task
updating	I-Task
previous	I-Task
memories	I-Task
,	O
e.g.	O
,	O
to	O
correct	O
wrong	O
interpretations	O
when	O
processing	O
garden	O
path	O
sentences	O
.	O
	
The	O
architecture	O
of	O
the	O
LSTMN	B-Method
is	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
and	O
the	O
formal	O
definition	O
is	O
provided	O
as	O
follows	O
.	O
	
The	O
model	O
maintains	O
two	O
sets	O
of	O
vectors	O
stored	O
in	O
a	O
hidden	O
state	O
tape	O
used	O
to	O
interact	O
with	O
the	O
environment	O
(	O
e.g.	O
,	O
computing	O
attention	O
)	O
,	O
and	O
a	O
memory	O
tape	O
used	O
to	O
represent	O
what	O
is	O
actually	O
stored	O
in	O
memory	O
.	O
	
Therefore	O
,	O
each	O
token	O
is	O
associated	O
with	O
a	O
hidden	O
vector	O
and	O
a	O
memory	O
vector	O
.	O
	
Let	O
denote	O
the	O
current	O
input	O
;	O
denotes	O
the	O
current	O
memory	O
tape	O
,	O
and	O
the	O
previous	O
hidden	O
tape	O
.	O
	
At	O
time	O
step	O
,	O
the	O
model	O
computes	O
the	O
relation	O
between	O
and	O
through	O
with	O
an	O
attention	B-Method
layer	I-Method
:	O
This	O
yields	O
a	O
probability	O
distribution	O
over	O
the	O
hidden	O
state	O
vectors	O
of	O
previous	O
tokens	O
.	O
	
We	O
can	O
then	O
compute	O
an	O
adaptive	O
summary	O
vector	O
for	O
the	O
previous	O
hidden	O
tape	O
and	O
memory	O
tape	O
denoted	O
by	O
and	O
,	O
respectively	O
:	O
and	O
use	O
them	O
for	O
computing	O
the	O
values	O
of	O
and	O
in	O
the	O
recurrent	O
update	O
as	O
:	O
where	O
,	O
,	O
and	O
are	O
the	O
new	O
weight	O
terms	O
of	O
the	O
network	O
.	O
	
A	O
key	O
idea	O
behind	O
the	O
LSTMN	B-Method
is	O
to	O
use	O
attention	O
for	O
inducing	B-Task
relations	I-Task
between	I-Task
tokens	I-Task
.	O
	
These	O
relations	O
are	O
soft	O
and	O
differentiable	O
,	O
and	O
components	O
of	O
a	O
larger	O
representation	B-Method
learning	I-Method
network	I-Method
.	O
	
Although	O
it	O
is	O
appealing	O
to	O
provide	O
direct	O
supervision	O
for	O
the	O
attention	B-Method
layer	I-Method
,	O
e.g.	O
,	O
with	O
evidence	O
collected	O
from	O
a	O
dependency	O
treebank	O
,	O
we	O
treat	O
it	O
as	O
a	O
submodule	O
being	O
optimized	O
within	O
the	O
larger	O
network	O
in	O
a	O
downstream	B-Task
task	I-Task
.	O
	
It	O
is	O
also	O
possible	O
to	O
have	O
a	O
more	O
structured	O
relational	B-Method
reasoning	I-Method
module	I-Method
by	O
stacking	O
multiple	O
memory	B-Method
and	I-Method
hidden	I-Method
layers	I-Method
in	O
an	O
alternating	O
fashion	O
,	O
resembling	O
a	O
stacked	B-Method
LSTM	I-Method
or	O
a	O
multi	B-Method
-	I-Method
hop	I-Method
memory	I-Method
network	I-Method
.	O
	
This	O
can	O
be	O
achieved	O
by	O
feeding	O
the	O
output	O
of	O
the	O
lower	O
layer	O
as	O
input	O
to	O
the	O
upper	O
layer	O
.	O
	
The	O
attention	O
at	O
the	O
th	O
layer	O
is	O
computed	O
as	O
:	O
Skip	O
-	O
connections	O
can	O
be	O
applied	O
to	O
feed	O
to	O
upper	O
layers	O
as	O
well	O
.	O
	
[	O
Decoder	B-Method
with	O
shallow	B-Method
attention	I-Method
fusion	I-Method
.	O
]	O
	
[	O
Decoder	B-Method
with	O
deep	B-Method
attention	I-Method
fusion	I-Method
.	O
]	O
	
section	O
:	O
Modeling	B-Task
Two	I-Task
Sequences	I-Task
with	O
LSTMN	B-Method
	
Natural	B-Task
language	I-Task
processing	I-Task
tasks	I-Task
such	O
as	O
machine	B-Task
translation	I-Task
and	O
textual	B-Task
entailment	I-Task
are	O
concerned	O
with	O
modeling	O
two	O
sequences	O
rather	O
than	O
a	O
single	O
one	O
.	O
	
A	O
standard	O
tool	O
for	O
modeling	B-Task
two	I-Task
sequences	I-Task
with	O
recurrent	B-Method
networks	I-Method
is	O
the	O
encoder	B-Method
-	I-Method
decoder	I-Method
architecture	I-Method
where	O
the	O
second	O
sequence	O
(	O
also	O
known	O
as	O
the	O
target	O
)	O
is	O
being	O
processed	O
conditioned	O
on	O
the	O
first	O
one	O
(	O
also	O
known	O
as	O
the	O
source	O
)	O
.	O
	
In	O
this	O
section	O
we	O
explain	O
how	O
to	O
combine	O
the	O
LSTMN	B-Method
which	O
applies	O
attention	B-Method
for	O
intra	B-Task
-	I-Task
relation	I-Task
reasoning	I-Task
,	O
with	O
the	O
encoder	B-Method
-	I-Method
decoder	I-Method
network	I-Method
whose	O
attention	B-Method
module	I-Method
learns	O
the	O
inter	O
-	O
alignment	O
between	O
two	O
sequences	O
.	O
	
Figures	O
[	O
reference	O
]	O
a	O
and	O
[	O
reference	O
]	O
b	O
illustrate	O
two	O
types	O
of	O
combination	O
.	O
	
We	O
describe	O
the	O
models	O
more	O
formally	O
below	O
.	O
	
paragraph	O
:	O
Shallow	B-Method
Attention	I-Method
Fusion	I-Method
	
Shallow	B-Method
fusion	I-Method
simply	O
treats	O
the	O
LSTMN	B-Method
as	O
a	O
separate	O
module	O
that	O
can	O
be	O
readily	O
used	O
in	O
an	O
encoder	B-Method
-	I-Method
decoder	I-Method
architecture	I-Method
,	O
in	O
lieu	O
of	O
a	O
standard	O
RNN	B-Method
or	O
LSTM	B-Method
.	O
	
As	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
a	O
,	O
both	O
encoder	O
and	O
decoder	B-Method
are	O
modeled	O
as	O
LSTMNs	B-Method
with	I-Method
intra	I-Method
-	I-Method
attention	I-Method
.	O
	
Meanwhile	O
,	O
inter	O
-	O
attention	O
is	O
triggered	O
when	O
the	O
decoder	O
reads	O
a	O
target	O
token	O
,	O
similar	O
to	O
the	O
inter	O
-	O
attention	O
introduced	O
in	O
bahdanau2014neural	O
.	O
	
paragraph	O
:	O
Deep	B-Method
Attention	I-Method
Fusion	I-Method
	
Deep	B-Method
fusion	I-Method
combines	O
inter	O
-	O
and	O
intra	O
-	O
attention	O
(	O
initiated	O
by	O
the	O
decoder	B-Method
)	O
when	O
computing	O
state	B-Task
updates	I-Task
.	O
	
We	O
use	O
different	O
notation	O
to	O
represent	O
the	O
two	O
sets	O
of	O
attention	O
.	O
	
Following	O
Section	O
[	O
reference	O
]	O
,	O
and	O
denote	O
the	O
target	O
memory	O
tape	O
and	O
hidden	O
tape	O
,	O
which	O
store	O
representations	O
of	O
the	O
target	O
symbols	O
that	O
have	O
been	O
processed	O
so	O
far	O
.	O
	
The	O
computation	B-Task
of	I-Task
intra	I-Task
-	I-Task
attention	I-Task
follows	O
Equations	O
(	O
[	O
reference	O
]	O
)	O
	
–	O
(	O
[	O
reference	O
]	O
)	O
.	O
	
Additionally	O
,	O
we	O
use	O
and	O
to	O
represent	O
the	O
source	O
memory	O
tape	O
and	O
hidden	O
tape	O
,	O
with	O
being	O
the	O
length	O
of	O
the	O
source	O
sequence	O
conditioned	O
upon	O
.	O
	
We	O
compute	O
inter	O
-	O
attention	O
between	O
the	O
input	O
at	O
time	O
step	O
and	O
tokens	O
in	O
the	O
entire	O
source	O
sequence	O
as	O
follows	O
:	O
After	O
that	O
we	O
compute	O
the	O
adaptive	B-Method
representation	I-Method
of	O
the	O
source	O
memory	O
tape	O
and	O
hidden	O
tape	O
as	O
:	O
We	O
can	O
then	O
transfer	O
the	O
adaptive	B-Method
source	I-Method
representation	I-Method
to	O
the	O
target	O
memory	O
with	O
another	O
gating	B-Method
operation	I-Method
,	O
analogous	O
to	O
the	O
gates	O
in	O
Equation	O
(	O
[	O
reference	O
]	O
)	O
.	O
	
The	O
new	O
target	O
memory	O
includes	O
inter	O
-	O
alignment	O
,	O
intra	O
-	O
relation	O
,	O
and	O
the	O
new	O
input	O
information	O
:	O
As	O
shown	O
in	O
the	O
equations	O
above	O
and	O
Figure	O
[	O
reference	O
]	O
b	O
,	O
the	O
major	O
change	O
of	O
deep	B-Method
fusion	I-Method
lies	O
in	O
the	O
recurrent	B-Method
storage	I-Method
of	O
the	O
inter	O
-	O
alignment	O
vector	O
in	O
the	O
target	O
memory	B-Method
network	I-Method
,	O
as	O
a	O
way	O
to	O
help	O
the	O
target	O
network	O
review	O
source	O
information	O
.	O
	
section	O
:	O
Experiments	O
	
In	O
this	O
section	O
we	O
present	O
our	O
experiments	O
for	O
evaluating	O
the	O
performance	O
of	O
the	O
LSTMN	B-Method
machine	O
reader	O
.	O
	
We	O
start	O
with	O
language	B-Method
modeling	I-Method
as	O
it	O
is	O
a	O
natural	O
testbed	O
for	O
our	O
model	O
.	O
	
We	O
then	O
assess	O
the	O
model	O
	
’s	O
ability	O
to	O
extract	O
meaning	B-Method
representations	I-Method
for	O
generic	B-Task
sentence	I-Task
classification	I-Task
tasks	I-Task
such	O
as	O
sentiment	B-Task
analysis	I-Task
.	O
	
Finally	O
,	O
we	O
examine	O
whether	O
the	O
LSTMN	B-Method
can	O
recognize	O
the	O
semantic	O
relationship	O
between	O
two	O
sentences	O
by	O
applying	O
it	O
to	O
a	O
natural	B-Task
language	I-Task
inference	I-Task
task	O
.	O
	
Our	O
code	O
is	O
available	O
at	O
.	O
	
subsection	O
:	O
Language	B-Method
Modeling	I-Method
	
Our	O
language	B-Method
modeling	I-Method
experiments	O
were	O
conducted	O
on	O
the	O
English	O
Penn	O
Treebank	O
dataset	O
.	O
	
Following	O
common	O
practice	O
,	O
we	O
trained	O
on	O
sections	O
0–20	O
(	O
1	O
M	O
words	O
)	O
,	O
used	O
sections	O
21–22	O
for	O
validation	O
(	O
80	O
K	O
words	O
)	O
,	O
and	O
sections	O
23–24	O
(	O
90	O
K	O
words	O
for	O
testing	O
)	O
.	O
	
The	O
dataset	O
contains	O
approximately	O
1	O
million	O
tokens	O
and	O
a	O
vocabulary	O
size	O
of	O
10K.	O
	
The	O
average	B-Metric
sentence	I-Metric
length	I-Metric
is	O
21	O
.	O
	
We	O
use	O
perplexity	B-Method
as	O
our	O
evaluation	B-Metric
metric	I-Metric
:	O
,	O
where	O
denotes	O
the	O
negative	O
log	O
likelihood	O
of	O
the	O
entire	O
test	O
set	O
and	O
the	O
corresponding	O
number	O
of	O
tokens	O
.	O
	
We	O
used	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
for	O
optimization	B-Task
with	O
an	O
initial	O
learning	B-Metric
rate	I-Metric
of	I-Metric
0.65	I-Metric
,	O
which	O
decays	O
by	O
a	O
factor	O
of	O
0.85	O
per	O
epoch	O
if	O
no	O
significant	O
improvement	O
has	O
been	O
observed	O
on	O
the	O
validation	O
set	O
.	O
	
We	O
renormalize	O
the	O
gradient	O
if	O
its	O
norm	O
is	O
greater	O
than	O
5	O
.	O
	
The	O
mini	O
-	O
batch	O
size	O
was	O
set	O
to	O
40	O
.	O
	
The	O
dimensions	O
of	O
the	O
word	O
embeddings	O
were	O
set	O
to	O
150	O
for	O
all	O
models	O
.	O
	
In	O
this	O
suite	O
of	O
experiments	O
we	O
compared	O
the	O
LSTMN	B-Method
against	O
a	O
variety	O
of	O
baselines	O
.	O
	
The	O
first	O
one	O
is	O
a	O
Kneser	B-Method
-	I-Method
Ney	I-Method
5	I-Method
-	I-Method
gram	I-Method
language	I-Method
model	I-Method
(	O
KN5	B-Method
)	O
which	O
generally	O
serves	O
as	O
a	O
non	B-Method
-	I-Method
neural	I-Method
baseline	I-Method
for	O
the	O
language	B-Task
modeling	I-Task
task	I-Task
.	O
	
We	O
also	O
present	O
perplexity	O
results	O
for	O
the	O
standard	O
RNN	O
and	O
LSTM	B-Method
models	O
.	O
	
We	O
also	O
implemented	O
more	O
sophisticated	O
LSTM	B-Method
architectures	O
,	O
such	O
as	O
a	O
stacked	B-Method
LSTM	I-Method
(	O
sLSTM	B-Method
)	O
,	O
a	O
gated	O
-	O
feedback	O
LSTM	B-Method
(	O
gLSTM	B-Method
;	O
chung2015gated	O
)	O
and	O
a	O
depth	O
-	O
gated	O
LSTM	B-Method
(	O
dLSTM	B-Method
;	O
yao2015depth	O
)	O
.	O
	
The	O
gated	O
-	O
feedback	O
LSTM	B-Method
has	O
feedback	O
gates	O
connecting	O
the	O
hidden	O
states	O
across	O
multiple	O
time	O
steps	O
as	O
an	O
adaptive	O
control	O
of	O
the	O
information	O
flow	O
.	O
	
The	O
depth	O
-	O
gated	O
LSTM	B-Method
uses	O
a	O
depth	O
gate	O
to	O
connect	O
memory	O
cells	O
of	O
vertically	O
adjacent	O
layers	O
.	O
	
In	O
general	O
,	O
both	O
gLSTM	B-Method
and	O
dLSTM	B-Method
are	O
able	O
to	O
capture	O
long	O
-	O
term	O
dependencies	O
to	O
some	O
degree	O
,	O
but	O
they	O
do	O
not	O
explicitly	O
keep	O
past	O
memories	O
.	O
	
We	O
set	O
the	O
number	O
of	O
layers	O
to	O
3	O
in	O
this	O
experiment	O
,	O
mainly	O
to	O
agree	O
with	O
the	O
language	B-Method
modeling	I-Method
experiments	O
of	O
chung2015gated	O
.	O
	
Also	O
note	O
that	O
that	O
there	O
are	O
no	O
single	B-Method
-	I-Method
layer	I-Method
variants	I-Method
for	O
gLSTM	B-Method
and	O
dLSTM	B-Method
;	O
they	O
have	O
to	O
be	O
implemented	O
as	O
multi	B-Method
-	I-Method
layer	I-Method
systems	I-Method
.	O
	
The	O
hidden	O
unit	O
size	O
of	O
the	O
LSTMN	B-Method
and	O
all	O
comparison	B-Method
models	I-Method
(	O
except	O
KN5	B-Method
)	O
was	O
set	O
to	O
300	B-Method
.	O
	
The	O
results	O
of	O
the	O
language	B-Task
modeling	I-Task
task	I-Task
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Perplexity	B-Method
results	O
for	O
KN5	B-Method
and	O
RNN	B-Method
are	O
taken	O
from	O
mikolov2015learning	O
.	O
	
As	O
can	O
be	O
seen	O
,	O
the	O
single	O
-	O
layer	O
LSTMN	B-Method
outperforms	O
these	O
two	O
baselines	O
and	O
the	O
LSTM	B-Method
by	O
a	O
significant	O
margin	O
.	O
	
Amongst	O
all	O
deep	B-Method
architectures	I-Method
,	O
the	O
three	O
-	O
layer	O
LSTMN	B-Method
also	O
performs	O
best	O
.	O
	
We	O
can	O
study	O
the	O
memory	B-Method
activation	I-Method
mechanism	I-Method
of	O
the	O
machine	B-Task
reader	I-Task
by	O
visualizing	O
the	O
attention	B-Metric
scores	I-Metric
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
four	O
sentences	O
sampled	O
from	O
the	O
Penn	O
Treebank	O
validation	O
set	O
.	O
	
Although	O
we	O
explicitly	O
encourage	O
the	O
reader	O
to	O
attend	O
to	O
any	O
memory	O
slot	O
,	O
much	O
attention	O
focuses	O
on	O
recent	O
memories	O
.	O
	
This	O
agrees	O
with	O
the	O
linguistic	O
intuition	O
that	O
long	O
-	O
term	O
dependencies	O
are	O
relatively	O
rare	O
.	O
	
As	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
the	O
model	O
captures	O
some	O
valid	O
lexical	O
relations	O
(	O
e.g.	O
,	O
the	O
dependency	O
between	O
sits	O
and	O
at	O
,	O
sits	O
and	O
plays	O
,	O
everyone	O
and	O
is	O
,	O
is	O
and	O
watching	O
)	O
.	O
	
Note	O
that	O
arcs	O
here	O
are	O
undirected	O
and	O
are	O
different	O
from	O
the	O
directed	O
arcs	O
denoting	O
head	O
-	O
modifier	O
relations	O
in	O
dependency	O
graphs	O
.	O
	
subsection	O
:	O
Sentiment	B-Task
Analysis	I-Task
	
Our	O
second	O
task	O
concerns	O
the	O
prediction	B-Task
of	I-Task
sentiment	I-Task
labels	I-Task
of	I-Task
sentences	I-Task
.	O
	
We	O
used	O
the	O
Stanford	O
Sentiment	O
Treebank	O
,	O
which	O
contains	O
fine	O
-	O
grained	O
sentiment	O
labels	O
(	O
very	O
positive	O
,	O
positive	O
,	O
neutral	O
,	O
negative	O
,	O
very	O
negative	O
)	O
for	O
11	O
,	O
855	O
sentences	O
.	O
	
Following	O
previous	O
work	O
on	O
this	O
dataset	O
,	O
we	O
used	O
8	O
,	O
544	O
sentences	O
for	O
training	B-Task
,	O
1	O
,	O
101	O
for	O
validation	B-Task
,	O
and	O
2	O
,	O
210	O
for	O
testing	B-Task
.	O
	
The	O
average	B-Metric
sentence	I-Metric
length	I-Metric
is	O
19.1	O
.	O
	
In	O
addition	O
,	O
we	O
also	O
performed	O
a	O
binary	B-Task
classification	I-Task
task	I-Task
(	O
positive	O
,	O
negative	O
)	O
after	O
removing	O
the	O
neutral	O
label	O
.	O
	
This	O
resulted	O
in	O
6	O
,	O
920	O
sentences	O
for	O
training	B-Task
,	O
872	O
for	O
validation	B-Task
and	O
1	O
,	O
821	O
for	O
testing	B-Task
.	O
	
Table	O
[	O
reference	O
]	O
reports	O
results	O
on	O
both	O
fine	B-Task
-	I-Task
grained	I-Task
and	O
binary	B-Task
classification	I-Task
tasks	I-Task
.	O
	
We	O
experimented	O
with	O
1	O
-	O
and	O
2	B-Method
-	I-Method
layer	I-Method
LSTMNs	I-Method
.	O
	
For	O
the	O
latter	O
model	O
,	O
we	O
predict	O
the	O
sentiment	O
label	O
of	O
the	O
sentence	O
based	O
on	O
the	O
averaged	O
hidden	O
vector	O
passed	O
to	O
a	O
2	B-Method
-	I-Method
layer	I-Method
neural	I-Method
network	I-Method
classifier	I-Method
with	O
ReLU	B-Method
as	O
the	O
activation	O
function	O
.	O
	
The	O
memory	B-Metric
size	I-Metric
for	O
both	O
LSTMN	B-Method
models	I-Method
was	O
set	O
to	O
168	O
to	O
be	O
compatible	O
with	O
previous	O
LSTM	B-Method
models	O
applied	O
to	O
the	O
same	O
task	O
.	O
	
We	O
used	O
pre	O
-	O
trained	O
300	B-Method
-	I-Method
D	I-Method
Glove	I-Method
840B	I-Method
vectors	O
to	O
initialize	O
the	O
word	O
embeddings	O
.	O
	
The	O
gradient	O
for	O
words	O
with	O
Glove	O
embeddings	O
,	O
was	O
scaled	O
by	O
0.35	O
in	O
the	O
first	O
epoch	O
after	O
which	O
all	O
word	O
embeddings	O
were	O
updated	O
normally	O
.	O
	
We	O
used	O
Adam	B-Method
for	O
optimization	B-Task
with	O
the	O
two	O
momentum	O
parameters	B-Metric
set	O
to	O
0.9	O
and	O
0.999	O
respectively	O
.	O
	
The	O
initial	O
learning	B-Metric
rate	I-Metric
was	O
set	O
to	O
2E	O
-	O
3	O
.	O
	
The	O
regularization	O
constant	O
was	O
1E	O
-	O
4	O
and	O
	
the	O
mini	O
-	O
batch	O
size	O
was	O
5	O
.	O
	
A	O
dropout	B-Metric
rate	I-Metric
of	I-Metric
0.5	I-Metric
was	O
applied	O
to	O
the	O
neural	B-Method
network	I-Method
classifier	I-Method
.	O
	
We	O
compared	O
our	O
model	O
with	O
a	O
wide	O
range	O
of	O
top	O
-	O
performing	O
systems	O
.	O
	
Most	O
of	O
these	O
models	O
(	O
including	O
ours	O
)	O
are	O
LSTM	B-Method
variants	O
(	O
third	O
block	O
in	O
Table	O
[	O
reference	O
]	O
)	O
,	O
recursive	B-Method
neural	I-Method
networks	I-Method
(	O
first	O
block	O
)	O
,	O
or	O
convolutional	B-Method
neural	I-Method
networks	I-Method
(	O
CNNs	B-Method
;	O
second	O
block	O
)	O
.	O
	
Recursive	B-Method
models	I-Method
assume	O
the	O
input	O
sentences	O
are	O
represented	O
as	O
parse	O
trees	O
and	O
can	O
take	O
advantage	O
of	O
annotations	O
at	O
the	O
phrase	O
level	O
.	O
	
LSTM	B-Method
-	O
type	O
models	O
and	O
CNNs	B-Method
are	O
trained	O
on	O
sequential	O
input	O
,	O
with	O
the	O
exception	O
of	O
CT	O
-	O
LSTM	B-Method
which	O
operates	O
over	O
tree	B-Method
-	I-Method
structured	I-Method
network	I-Method
topologies	I-Method
such	O
as	O
constituent	O
trees	O
.	O
	
For	O
comparison	O
,	O
we	O
also	O
report	O
the	O
performance	O
of	O
the	O
paragraph	B-Method
vector	I-Method
model	I-Method
(	O
PV	B-Method
;	O
le2014distributed	O
;	O
see	O
Table	O
[	O
reference	O
]	O
,	O
second	O
block	O
)	O
which	O
neither	O
operates	O
on	O
trees	O
nor	O
sequences	O
but	O
learns	O
distributed	B-Method
document	I-Method
representations	I-Method
parameterized	O
directly	O
.	O
	
The	O
results	O
in	O
Table	O
[	O
reference	O
]	O
show	O
that	O
both	O
1	O
-	O
and	O
2	B-Method
-	I-Method
layer	I-Method
LSTMNs	I-Method
outperform	O
the	O
LSTM	B-Method
baselines	O
while	O
achieving	O
numbers	O
comparable	O
to	O
state	O
of	O
the	O
art	O
.	O
	
The	O
number	O
of	O
layers	O
for	O
our	O
models	O
was	O
set	O
to	O
be	O
comparable	O
to	O
previously	O
published	O
results	O
.	O
	
On	O
the	O
fine	B-Task
-	I-Task
grained	I-Task
and	I-Task
binary	I-Task
classification	I-Task
tasks	I-Task
our	O
2	B-Method
-	I-Method
layer	I-Method
LSTMN	I-Method
performs	O
close	O
to	O
the	O
best	O
system	O
T	B-Method
-	I-Method
CNN	I-Method
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
examples	O
of	O
intra	O
-	O
attention	O
for	O
sentiment	O
words	O
.	O
	
Interestingly	O
,	O
the	O
network	O
learns	O
to	O
associate	O
sentiment	O
important	O
words	O
such	O
as	O
though	O
and	O
fantastic	O
or	O
not	O
and	O
good	O
.	O
	
subsection	O
:	O
Natural	B-Task
Language	I-Task
Inference	I-Task
	
The	O
ability	O
to	O
reason	O
about	O
the	O
semantic	O
relationship	O
between	O
two	O
sentences	O
is	O
an	O
integral	O
part	O
of	O
text	B-Task
understanding	I-Task
.	O
	
We	O
therefore	O
evaluate	O
our	O
model	O
on	O
recognizing	B-Task
textual	I-Task
entailment	I-Task
,	O
i.e.	O
,	O
whether	O
two	O
premise	O
-	O
hypothesis	O
pairs	O
are	O
entailing	O
,	O
contradictory	O
,	O
or	O
neutral	O
.	O
	
For	O
this	O
task	O
we	O
used	O
the	O
Stanford	B-Material
Natural	I-Material
Language	I-Material
Inference	I-Material
(	O
SNLI	B-Material
)	O
dataset	O
,	O
which	O
contains	O
premise	O
-	O
hypothesis	O
pairs	O
and	O
target	O
labels	O
indicating	O
their	O
relation	O
.	O
	
After	O
removing	O
sentences	O
with	O
unknown	O
labels	O
,	O
we	O
end	O
up	O
with	O
549	O
,	O
367	O
pairs	O
for	O
training	O
,	O
9	O
,	O
842	O
for	O
development	B-Task
and	O
9	O
,	O
824	O
for	O
testing	O
.	O
	
The	O
vocabulary	B-Metric
size	I-Metric
is	O
36	O
,	O
809	O
and	O
the	O
average	B-Metric
sentence	I-Metric
length	I-Metric
is	O
22	O
.	O
	
We	O
performed	O
lower	B-Method
-	I-Method
casing	I-Method
and	O
tokenization	B-Task
for	O
the	O
entire	O
dataset	O
.	O
	
Recent	O
approaches	O
use	O
two	O
sequential	B-Method
LSTMs	I-Method
to	O
encode	O
the	O
premise	O
and	O
the	O
hypothesis	O
respectively	O
,	O
and	O
apply	O
neural	B-Method
attention	I-Method
to	O
reason	O
about	O
their	O
logical	O
relationship	O
.	O
	
Furthermore	O
,	O
rocktaschel2015reasoning	O
show	O
that	O
a	O
non	O
-	O
standard	O
encoder	B-Method
-	I-Method
decoder	I-Method
architecture	I-Method
which	O
processes	O
the	O
hypothesis	O
conditioned	O
on	O
the	O
premise	O
results	O
significantly	O
boosts	O
performance	O
.	O
	
We	O
use	O
a	O
similar	O
approach	O
to	O
tackle	O
this	O
task	O
with	O
LSTMNs	B-Method
.	O
	
Specifically	O
,	O
we	O
use	O
two	O
LSTMNs	B-Method
to	O
read	O
the	O
premise	O
and	O
hypothesis	O
,	O
and	O
then	O
match	O
them	O
by	O
comparing	O
their	O
hidden	O
state	O
tapes	O
.	O
	
We	O
perform	O
average	B-Method
pooling	I-Method
for	O
the	O
hidden	O
state	O
tape	O
of	O
each	O
LSTMN	B-Method
,	O
and	O
concatenate	O
the	O
two	O
averages	O
to	O
form	O
the	O
input	O
to	O
a	O
2	B-Method
-	I-Method
layer	I-Method
neural	I-Method
network	I-Method
classifier	I-Method
with	O
ReLU	B-Method
as	O
the	O
activation	O
function	O
.	O
	
We	O
used	O
pre	O
-	O
trained	O
300	B-Method
-	I-Method
D	I-Method
Glove	I-Method
840B	I-Method
vectors	O
to	O
initialize	O
the	O
word	O
embeddings	O
.	O
	
Out	O
-	O
of	O
-	O
vocabulary	O
(	O
OOV	O
)	O
words	O
were	O
initialized	O
randomly	O
with	O
Gaussian	O
samples	O
(	O
=	O
0	O
,	O
=	O
1	O
)	O
.	O
	
We	O
only	O
updated	O
OOV	O
vectors	O
in	O
the	O
first	O
epoch	O
,	O
after	O
which	O
all	O
word	O
embeddings	O
were	O
updated	O
normally	O
.	O
	
The	O
dropout	B-Metric
rate	I-Metric
was	O
selected	O
from	O
[	O
0.1	O
,	O
0.2	O
,	O
0.3	O
,	O
0.4	O
]	O
.	O
	
We	O
used	O
Adam	B-Method
for	O
optimization	B-Task
with	O
the	O
two	O
momentum	O
parameters	B-Metric
set	O
to	O
0.9	O
and	O
0.999	O
respectively	O
,	O
and	O
the	O
initial	O
learning	B-Metric
rate	I-Metric
set	O
to	O
1E	O
-	O
3	O
.	O
	
The	O
mini	O
-	O
batch	O
size	O
was	O
set	O
to	O
16	O
or	O
32	O
.	O
	
For	O
a	O
fair	O
comparison	O
against	O
previous	O
work	O
,	O
we	O
report	O
results	O
with	O
different	O
hidden	O
/	O
memory	O
dimensions	O
(	O
i.e.	O
,	O
100	O
,	O
300	B-Method
,	O
and	O
450	B-Method
)	O
.	O
	
We	O
compared	O
variants	O
of	O
our	O
model	O
against	O
different	O
types	O
of	O
LSTMs	B-Method
(	O
see	O
the	O
second	O
block	O
in	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
Specifically	O
,	O
these	O
include	O
a	O
model	O
which	O
encodes	O
the	O
premise	O
and	O
hypothesis	O
independently	O
with	O
two	O
LSTMs	B-Method
,	O
a	O
shared	O
LSTM	B-Method
,	O
a	O
word	B-Method
-	I-Method
by	I-Method
-	I-Method
word	I-Method
attention	I-Method
model	I-Method
,	O
and	O
a	O
matching	O
LSTM	B-Method
(	O
mLSTM	B-Method
;	O
wang2015learning	O
)	O
.	O
	
This	O
model	O
sequentially	O
processes	O
the	O
hypothesis	O
,	O
and	O
at	O
each	O
position	O
tries	O
to	O
match	O
the	O
current	O
word	O
with	O
an	O
attention	O
-	O
weighted	O
representation	O
of	O
the	O
premise	O
(	O
rather	O
than	O
basing	O
its	O
predictions	O
on	O
whole	O
sentence	O
embeddings	O
)	O
.	O
	
We	O
also	O
compared	O
our	O
models	O
with	O
a	O
bag	B-Method
-	I-Method
of	I-Method
-	I-Method
words	I-Method
baseline	I-Method
which	O
averages	O
the	O
pre	O
-	O
trained	O
embeddings	O
for	O
the	O
words	O
in	O
each	O
sentence	O
and	O
concatenates	O
them	O
to	O
create	O
features	O
for	O
a	O
logistic	B-Method
regression	I-Method
classifier	I-Method
(	O
first	O
block	O
in	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
LSTMNs	B-Method
achieve	O
better	O
performance	O
compared	O
to	O
LSTMs	B-Method
(	O
with	O
and	O
without	O
attention	O
;	O
2nd	O
block	O
in	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
We	O
also	O
observe	O
that	O
fusion	B-Task
is	O
generally	O
beneficial	O
,	O
and	O
that	O
deep	B-Method
fusion	I-Method
slightly	O
improves	O
over	O
shallow	B-Method
fusion	I-Method
.	O
	
One	O
explanation	O
is	O
that	O
with	O
deep	B-Method
fusion	I-Method
the	O
inter	O
-	O
attention	O
vectors	O
are	O
recurrently	O
memorized	O
by	O
the	O
decoder	B-Method
with	O
a	O
gating	B-Method
operation	I-Method
,	O
which	O
also	O
improves	O
the	O
information	O
flow	O
of	O
the	O
network	O
.	O
	
With	O
standard	O
training	B-Method
,	O
our	O
deep	B-Method
fusion	I-Method
yields	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
in	O
this	O
task	O
.	O
	
Although	O
encouraging	O
,	O
this	O
result	O
should	O
be	O
interpreted	O
with	O
caution	O
since	O
our	O
model	O
has	O
substantially	O
more	O
parameters	B-Metric
compared	O
to	O
related	O
systems	O
.	O
	
We	O
could	O
compare	O
different	O
models	O
using	O
the	O
same	O
number	O
of	O
total	O
parameters	B-Metric
.	O
	
However	O
,	O
this	O
would	O
inevitably	O
introduce	O
other	O
biases	O
,	O
e.g.	O
,	O
the	O
number	O
of	O
hyper	B-Metric
-	I-Metric
parameters	I-Metric
would	O
become	O
different	O
.	O
	
section	O
:	O
Conclusions	O
	
In	O
this	O
paper	O
we	O
proposed	O
a	O
machine	B-Method
reading	I-Method
simulator	I-Method
to	O
address	O
the	O
limitations	O
of	O
recurrent	B-Method
neural	I-Method
networks	I-Method
when	O
processing	O
inherently	O
structured	O
input	O
.	O
	
Our	O
model	O
is	O
based	O
on	O
a	O
Long	B-Method
Short	I-Method
-	I-Method
Term	I-Method
Memory	I-Method
architecture	O
embedded	O
with	O
a	O
memory	B-Method
network	I-Method
,	O
explicitly	O
storing	O
contextual	B-Method
representations	I-Method
of	O
input	O
tokens	O
without	O
recursively	O
compressing	O
them	O
.	O
	
More	O
importantly	O
,	O
an	O
intra	B-Method
-	I-Method
attention	I-Method
mechanism	I-Method
is	O
employed	O
for	O
memory	B-Task
addressing	I-Task
,	O
as	O
a	O
way	O
to	O
induce	O
undirected	O
relations	O
among	O
tokens	O
.	O
	
The	O
attention	B-Method
layer	I-Method
is	O
not	O
optimized	O
with	O
a	O
direct	O
supervision	O
signal	O
but	O
with	O
the	O
entire	O
network	O
in	O
downstream	B-Task
tasks	I-Task
.	O
	
Experimental	O
results	O
across	O
three	O
tasks	O
show	O
that	O
our	O
model	O
yields	O
performance	O
comparable	O
or	O
superior	O
to	O
state	O
of	O
the	O
art	O
.	O
	
Although	O
our	O
experiments	O
focused	O
on	O
LSTMs	B-Method
,	O
the	O
idea	O
of	O
building	O
more	O
structure	B-Method
aware	I-Method
neural	I-Method
models	I-Method
is	O
general	O
and	O
can	O
be	O
applied	O
to	O
other	O
types	O
of	O
networks	O
.	O
	
When	O
direct	O
supervision	O
is	O
provided	O
,	O
similar	O
architectures	O
can	O
be	O
adapted	O
to	O
tasks	O
such	O
as	O
dependency	B-Task
parsing	I-Task
and	O
relation	B-Task
extraction	I-Task
.	O
	
In	O
the	O
future	O
,	O
we	O
hope	O
to	O
develop	O
more	O
linguistically	B-Method
plausible	I-Method
neural	I-Method
architectures	I-Method
able	O
to	O
reason	O
over	O
nested	O
structures	O
and	O
neural	B-Method
models	I-Method
that	O
learn	O
to	O
discover	O
compositionality	O
with	O
weak	O
or	O
indirect	O
supervision	O
.	O
	
section	O
:	O
Acknowledgments	O
	
We	O
thank	O
members	O
of	O
the	O
ILCC	O
at	O
the	O
School	O
of	O
Informatics	O
and	O
the	O
anonymous	O
reviewers	O
for	O
helpful	O
comments	O
.	O
	
The	O
support	O
of	O
the	O
European	O
Research	O
Council	O
under	O
award	O
number	O
681760	O
“	O
	
Translating	O
Multiple	O
Modalities	O
into	O
Text	O
”	O
is	O
gratefully	O
acknowledged	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Hierarchical	B-Method
Question	I-Method
-	I-Method
Image	I-Method
Co	I-Method
-	I-Method
Attention	I-Method
for	O
Visual	B-Task
Question	I-Task
Answering	I-Task
	
A	O
number	O
of	O
recent	O
works	O
have	O
proposed	O
attention	B-Method
models	I-Method
for	O
Visual	B-Task
Question	I-Task
Answering	I-Task
(	O
VQA	B-Task
)	O
that	O
generate	O
spatial	B-Task
maps	I-Task
highlighting	I-Task
image	I-Task
regions	I-Task
relevant	O
to	O
answering	O
the	O
question	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
argue	O
that	O
in	O
addition	O
to	O
modeling	O
	
‘	O
	
‘	O
where	O
to	O
look	O
’	O
’	O
or	O
visual	O
attention	O
,	O
it	O
is	O
equally	O
important	O
to	O
model	O
	
‘	O
	
‘	O
what	O
words	O
to	O
listen	O
to	O
’	O
’	O
or	O
question	O
attention	O
.	O
	
We	O
present	O
a	O
novel	O
co	B-Method
-	I-Method
attention	I-Method
model	I-Method
for	O
VQA	B-Task
that	O
jointly	O
reasons	O
about	O
image	B-Task
and	I-Task
question	I-Task
attention	I-Task
.	O
	
In	O
addition	O
,	O
our	O
model	O
reasons	O
about	O
the	O
question	O
(	O
and	O
consequently	O
the	O
image	O
via	O
the	O
co	B-Method
-	I-Method
attention	I-Method
mechanism	I-Method
)	O
in	O
a	O
hierarchical	B-Method
fashion	I-Method
via	O
a	O
novel	O
1	B-Method
-	I-Method
dimensional	I-Method
convolution	I-Method
neural	I-Method
networks	I-Method
(	O
CNN	B-Method
)	O
.	O
	
Our	O
model	O
improves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
on	O
the	O
VQA	B-Material
dataset	I-Material
from	O
60.3	O
%	O
to	O
60.5	O
%	O
,	O
and	O
from	O
61.6	O
%	O
to	O
63.3	O
%	O
on	O
the	O
COCO	O
-	O
QA	O
dataset	O
.	O
	
By	O
using	O
ResNet	B-Method
,	O
the	O
performance	O
is	O
further	O
improved	O
to	O
62.1	O
%	O
for	O
VQA	B-Task
and	O
65.4	O
%	O
for	O
COCO	O
-	O
QA	O
.	O
.	O
	
[	O
itemize	O
]	O
leftmargin=20pt	O
	
section	O
:	O
Introduction	O
	
Visual	B-Task
Question	I-Task
Answering	I-Task
(	O
VQA	B-Task
)	O
has	O
emerged	O
as	O
a	O
prominent	O
multi	B-Task
-	I-Task
discipline	I-Task
research	I-Task
problem	I-Task
in	O
both	O
academia	O
and	O
industry	O
.	O
	
To	O
correctly	O
answer	O
visual	O
questions	O
about	O
an	O
image	O
,	O
the	O
machine	O
needs	O
to	O
understand	O
both	O
the	O
image	O
and	O
question	O
.	O
	
Recently	O
,	O
visual	B-Method
attention	I-Method
based	I-Method
models	I-Method
have	O
been	O
explored	O
for	O
VQA	B-Task
,	O
where	O
the	O
attention	B-Method
mechanism	I-Method
typically	O
produces	O
a	O
spatial	O
map	O
highlighting	O
image	O
regions	O
relevant	O
to	O
answering	O
the	O
question	O
.	O
	
So	O
far	O
,	O
all	O
attention	B-Method
models	I-Method
for	O
VQA	B-Task
in	O
literature	O
have	O
focused	O
on	O
the	O
problem	O
of	O
identifying	O
‘	O
	
‘	O
where	O
to	O
look	O
’	O
’	O
or	O
visual	B-Task
attention	I-Task
.	O
	
In	O
this	O
paper	O
,	O
we	O
argue	O
that	O
the	O
problem	O
of	O
identifying	O
‘	O
‘	O
which	O
words	O
to	O
listen	O
to	O
’	O
’	O
or	O
question	O
attention	O
is	O
equally	O
important	O
.	O
	
Consider	O
the	O
questions	O
	
‘	O
‘	O
	
how	O
many	O
horses	O
are	O
in	O
this	O
image	O
?	O
’	O
’	O
and	O
	
‘	O
‘	O
	
how	O
many	O
horses	O
can	O
you	O
see	O
in	O
this	O
image	O
?	O
"	O
.	O
	
They	O
have	O
the	O
same	O
meaning	O
,	O
essentially	O
captured	O
by	O
the	O
first	O
three	O
words	O
.	O
	
A	O
machine	B-Method
that	O
attends	O
to	O
the	O
first	O
three	O
words	O
would	O
arguably	O
be	O
more	O
robust	O
to	O
linguistic	O
variations	O
irrelevant	O
to	O
the	O
meaning	O
and	O
answer	O
of	O
the	O
question	O
.	O
	
Motivated	O
by	O
this	O
observation	O
,	O
in	O
addition	O
to	O
reasoning	O
about	O
visual	B-Task
attention	I-Task
,	O
we	O
also	O
address	O
the	O
problem	O
of	O
question	B-Task
attention	I-Task
.	O
	
Specifically	O
,	O
we	O
present	O
a	O
novel	O
multi	B-Method
-	I-Method
modal	I-Method
attention	I-Method
model	I-Method
for	O
VQA	B-Task
with	O
the	O
following	O
two	O
unique	O
features	O
:	O
	
Co	B-Task
-	I-Task
Attention	I-Task
:	O
We	O
propose	O
a	O
novel	O
mechanism	O
that	O
jointly	O
reasons	O
about	O
visual	B-Task
attention	I-Task
and	O
question	B-Task
attention	I-Task
,	O
which	O
we	O
refer	O
to	O
as	O
co	B-Task
-	I-Task
attention	I-Task
.	O
	
Unlike	O
previous	O
works	O
,	O
which	O
only	O
focus	O
on	O
visual	B-Task
attention	I-Task
,	O
our	O
model	O
has	O
a	O
natural	O
symmetry	O
between	O
the	O
image	O
and	O
question	O
,	O
in	O
the	O
sense	O
that	O
the	O
image	B-Method
representation	I-Method
is	O
used	O
to	O
guide	O
the	O
question	O
attention	O
and	O
the	O
question	B-Method
representation	I-Method
(	I-Method
s	I-Method
)	O
are	O
used	O
to	O
guide	O
image	B-Task
attention	I-Task
.	O
	
Question	O
Hierarchy	O
:	O
We	O
build	O
a	O
hierarchical	B-Method
architecture	I-Method
that	O
co	O
-	O
attends	O
to	O
the	O
image	O
and	O
question	O
at	O
three	O
levels	O
:	O
(	O
a	O
)	O
word	O
level	O
,	O
(	O
b	O
)	O
phrase	O
level	O
and	O
(	O
c	O
)	O
question	O
level	O
.	O
	
At	O
the	O
word	O
level	O
,	O
we	O
embed	O
the	O
words	O
to	O
a	O
vector	O
space	O
through	O
an	O
embedding	B-Method
matrix	I-Method
.	O
	
At	O
the	O
phrase	O
level	O
,	O
1	B-Method
-	I-Method
dimensional	I-Method
convolution	I-Method
neural	I-Method
networks	I-Method
are	O
used	O
to	O
capture	O
the	O
information	O
contained	O
in	O
unigrams	O
,	O
bigrams	O
and	O
trigrams	O
.	O
	
Specifically	O
,	O
we	O
convolve	O
word	B-Method
representations	I-Method
with	O
temporal	B-Method
filters	I-Method
of	O
varying	O
support	O
,	O
and	O
then	O
combine	O
the	O
various	O
n	O
-	O
gram	O
responses	O
by	O
pooling	O
them	O
into	O
a	O
single	O
phrase	B-Method
level	I-Method
representation	I-Method
.	O
	
At	O
the	O
question	O
level	O
,	O
we	O
use	O
recurrent	B-Method
neural	I-Method
networks	I-Method
to	O
encode	O
the	O
entire	O
question	O
.	O
	
For	O
each	O
level	O
of	O
the	O
question	B-Method
representation	I-Method
in	O
this	O
hierarchy	O
,	O
we	O
construct	O
joint	O
question	O
and	O
image	O
co	O
-	O
attention	O
maps	O
,	O
which	O
are	O
then	O
combined	O
recursively	O
to	O
ultimately	O
predict	O
a	O
distribution	O
over	O
the	O
answers	O
.	O
	
Overall	O
,	O
the	O
main	O
contributions	O
of	O
our	O
work	O
are	O
:	O
We	O
propose	O
a	O
novel	O
co	B-Method
-	I-Method
attention	I-Method
mechanism	I-Method
for	O
VQA	B-Task
that	O
jointly	O
performs	O
question	B-Task
-	I-Task
guided	I-Task
visual	I-Task
attention	I-Task
and	O
image	B-Task
-	I-Task
guided	I-Task
question	I-Task
attention	I-Task
.	O
	
We	O
explore	O
this	O
mechanism	O
with	O
two	O
strategies	O
,	O
parallel	B-Method
and	I-Method
alternating	I-Method
co	I-Method
-	I-Method
attention	I-Method
,	O
which	O
are	O
described	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
	
;	O
We	O
propose	O
a	O
hierarchical	B-Method
architecture	I-Method
to	O
represent	O
the	O
question	O
,	O
and	O
consequently	O
construct	O
image	B-Task
-	I-Task
question	I-Task
co	I-Task
-	I-Task
attention	I-Task
maps	I-Task
at	O
3	O
different	O
levels	O
:	O
word	O
level	O
,	O
phrase	O
level	O
and	O
question	O
level	O
.	O
	
These	O
co	O
-	O
attended	O
features	O
are	O
then	O
recursively	O
combined	O
from	O
word	O
level	O
to	O
question	O
level	O
for	O
the	O
final	O
answer	B-Task
prediction	I-Task
;	O
At	O
the	O
phrase	O
level	O
,	O
we	O
propose	O
a	O
novel	O
convolution	B-Method
-	I-Method
pooling	I-Method
strategy	I-Method
to	O
adaptively	O
select	O
the	O
phrase	O
sizes	O
whose	O
representations	O
are	O
passed	O
to	O
the	O
question	B-Method
level	I-Method
representation	I-Method
;	O
Finally	O
,	O
we	O
evaluate	O
our	O
proposed	O
model	O
on	O
two	O
large	O
datasets	O
,	O
VQA	B-Task
and	O
COCO	O
-	O
QA	O
.	O
	
We	O
also	O
perform	O
ablation	B-Task
studies	I-Task
to	O
quantify	O
the	O
roles	O
of	O
different	O
components	O
in	O
our	O
model	O
.	O
	
section	O
:	O
Related	O
Work	O
	
Many	O
recent	O
works	O
have	O
proposed	O
models	O
for	O
VQA	B-Task
.	O
	
We	O
compare	O
and	O
relate	O
our	O
proposed	O
co	B-Method
-	I-Method
attention	I-Method
mechanism	I-Method
to	O
other	O
vision	B-Task
and	I-Task
language	I-Task
attention	I-Task
mechanisms	I-Task
in	O
literature	O
.	O
	
Image	B-Task
attention	I-Task
.	O
	
Instead	O
of	O
directly	O
using	O
the	O
holistic	B-Method
entire	I-Method
-	I-Method
image	I-Method
embedding	I-Method
from	O
the	O
fully	B-Method
connected	I-Method
layer	I-Method
of	O
a	O
deep	B-Method
CNN	I-Method
(	O
as	O
in	O
)	O
,	O
a	O
number	O
of	O
recent	O
works	O
have	O
explored	O
image	B-Method
attention	I-Method
models	I-Method
for	O
VQA	B-Task
.	O
	
Zhu	O
add	O
spatial	O
attention	O
to	O
the	O
standard	O
LSTM	B-Method
model	I-Method
for	O
pointing	B-Task
and	I-Task
grounded	I-Task
QA	I-Task
.	O
	
Andreas	O
propose	O
a	O
compositional	B-Method
scheme	I-Method
that	O
consists	O
of	O
a	O
language	B-Method
parser	I-Method
and	O
a	O
number	O
of	O
neural	B-Method
modules	I-Method
networks	I-Method
.	O
	
The	O
language	B-Method
parser	I-Method
predicts	O
which	O
neural	B-Method
module	I-Method
network	I-Method
should	O
be	O
instantiated	O
to	O
answer	O
the	O
question	O
.	O
	
Some	O
other	O
works	O
perform	O
image	B-Task
attention	I-Task
multiple	O
times	O
in	O
a	O
stacked	O
manner	O
.	O
	
In	O
,	O
the	O
authors	O
propose	O
a	O
stacked	B-Method
attention	I-Method
network	I-Method
,	O
which	O
runs	O
multiple	O
hops	O
to	O
infer	O
the	O
answer	O
progressively	O
.	O
	
To	O
capture	O
fine	O
-	O
grained	O
information	O
from	O
the	O
question	O
,	O
Xu	O
propose	O
a	O
multi	B-Method
-	I-Method
hop	I-Method
image	I-Method
attention	I-Method
scheme	I-Method
.	O
	
It	O
aligns	O
words	O
to	O
image	O
patches	O
in	O
the	O
first	O
hop	O
,	O
and	O
then	O
refers	O
to	O
the	O
entire	O
question	O
for	O
obtaining	O
image	B-Task
attention	I-Task
maps	I-Task
in	O
the	O
second	O
hop	O
.	O
	
In	O
,	O
the	O
authors	O
generate	O
image	O
regions	O
with	O
object	O
proposals	O
and	O
then	O
select	O
the	O
regions	O
relevant	O
to	O
the	O
question	O
and	O
answer	O
choice	O
.	O
	
Xiong	O
augments	O
dynamic	B-Method
memory	I-Method
network	I-Method
with	O
a	O
new	O
input	B-Method
fusion	I-Method
module	I-Method
and	O
retrieves	O
an	O
answer	O
from	O
an	O
attention	B-Method
based	I-Method
GRU	I-Method
.	O
	
In	O
concurrent	O
work	O
,	O
collected	O
‘	O
human	O
attention	O
maps	O
’	O
that	O
are	O
used	O
to	O
evaluate	O
the	O
attention	O
maps	O
generated	O
by	O
attention	B-Method
models	I-Method
for	O
VQA	B-Task
.	O
	
Note	O
that	O
all	O
of	O
these	O
approaches	O
model	O
visual	B-Task
attention	I-Task
alone	O
,	O
and	O
do	O
not	O
model	O
question	O
attention	O
.	O
	
Moreover	O
,	O
model	O
attention	O
sequentially	O
,	O
i.e.	O
,	O
later	O
attention	O
is	O
based	O
on	O
earlier	O
attention	O
,	O
which	O
is	O
prone	O
to	O
error	O
propagation	O
.	O
	
In	O
contrast	O
,	O
we	O
conduct	O
co	O
-	O
attention	O
at	O
three	O
levels	O
independently	O
.	O
	
Language	B-Task
Attention	I-Task
.	O
	
Though	O
no	O
prior	O
work	O
has	O
explored	O
question	B-Task
attention	I-Task
in	O
VQA	B-Task
,	O
there	O
are	O
some	O
related	O
works	O
in	O
natural	B-Task
language	I-Task
processing	I-Task
(	O
NLP	B-Task
)	O
in	O
general	O
that	O
have	O
modeled	O
language	B-Task
attention	I-Task
.	O
	
In	O
order	O
to	O
overcome	O
difficulty	O
in	O
translation	B-Task
of	I-Task
long	I-Task
sentences	I-Task
,	O
Bahdanau	O
propose	O
RNNSearch	B-Method
to	O
learn	O
an	O
alignment	O
over	O
the	O
input	O
sentences	O
.	O
	
In	O
,	O
the	O
authors	O
propose	O
an	O
attention	B-Method
model	I-Method
to	O
circumvent	O
the	O
bottleneck	O
caused	O
by	O
fixed	O
width	O
hidden	O
vector	O
in	O
text	B-Task
reading	I-Task
and	I-Task
comprehension	I-Task
.	O
	
A	O
more	O
fine	O
-	O
grained	B-Method
attention	I-Method
mechanism	I-Method
is	O
proposed	O
in	O
.	O
	
The	O
authors	O
employ	O
a	O
word	B-Method
-	I-Method
by	I-Method
-	I-Method
word	I-Method
neural	I-Method
attention	I-Method
mechanism	I-Method
to	O
reason	O
about	O
the	O
entailment	O
in	O
two	O
sentences	O
.	O
	
Also	O
focused	O
on	O
modeling	O
sentence	B-Task
pairs	I-Task
,	O
the	O
authors	O
in	O
propose	O
an	O
attention	B-Method
-	I-Method
based	I-Method
bigram	I-Method
CNN	I-Method
for	O
jointly	O
performing	O
attention	B-Task
between	O
two	O
CNN	B-Method
hierarchies	I-Method
.	O
	
In	O
their	O
work	O
,	O
three	O
attention	B-Method
schemes	I-Method
are	O
proposed	O
and	O
evaluated	O
.	O
	
In	O
,	O
the	O
authors	O
propose	O
a	O
two	O
-	O
way	B-Method
attention	I-Method
mechanism	I-Method
to	O
project	O
the	O
paired	O
inputs	O
into	O
a	O
common	O
representation	O
space	O
.	O
	
section	O
:	O
Method	O
	
We	O
begin	O
by	O
introducing	O
the	O
notation	O
used	O
in	O
this	O
paper	O
.	O
	
To	O
ease	O
understanding	O
,	O
our	O
full	O
model	O
is	O
described	O
in	O
parts	O
.	O
	
First	O
,	O
our	O
hierarchical	B-Method
question	I-Method
representation	I-Method
is	O
described	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
and	O
the	O
proposed	O
co	B-Method
-	I-Method
attention	I-Method
mechanism	I-Method
is	O
then	O
described	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
.	O
	
Finally	O
,	O
Sec	O
.	O
	
[	O
reference	O
]	O
shows	O
how	O
to	O
recursively	O
combine	O
the	O
attended	O
question	O
and	O
image	O
features	O
to	O
output	O
answers	O
.	O
	
subsection	O
:	O
Notation	O
	
Given	O
a	O
question	O
with	O
words	O
,	O
its	O
representation	O
is	O
denoted	O
by	O
,	O
where	O
is	O
the	O
feature	O
vector	O
for	O
the	O
-	O
th	O
word	O
.	O
	
We	O
denote	O
,	O
and	O
as	O
word	O
embedding	O
,	O
phrase	O
embedding	O
and	O
question	O
embedding	O
at	O
position	O
,	O
respectively	O
.	O
	
The	O
image	O
feature	O
is	O
denoted	O
by	O
,	O
where	O
is	O
the	O
feature	O
vector	O
at	O
the	O
spatial	O
location	O
.	O
	
The	O
co	O
-	O
attention	O
features	O
of	O
image	O
and	O
question	O
at	O
each	O
level	O
in	O
the	O
hierarchy	O
are	O
denoted	O
as	O
and	O
where	O
.	O
	
The	O
weights	O
in	O
different	O
modules	O
/	O
layers	O
are	O
denoted	O
with	O
,	O
with	O
appropriate	O
sub	O
/	O
super	O
-	O
scripts	O
as	O
necessary	O
.	O
	
In	O
the	O
exposition	O
that	O
follows	O
,	O
we	O
omit	O
the	O
bias	O
term	O
to	O
avoid	O
notational	O
clutter	O
.	O
	
subsection	O
:	O
Question	O
Hierarchy	O
	
Given	O
the	O
1	B-Method
-	I-Method
hot	I-Method
encoding	I-Method
of	O
the	O
question	O
words	O
,	O
we	O
first	O
embed	O
the	O
words	O
to	O
a	O
vector	O
space	O
(	O
learnt	O
end	O
-	O
to	O
-	O
end	O
)	O
to	O
get	O
.	O
	
To	O
compute	O
the	O
phrase	O
features	O
,	O
we	O
apply	O
1	B-Method
-	I-Method
D	I-Method
convolution	I-Method
on	O
the	O
word	O
embedding	O
vectors	O
.	O
	
Concretely	O
,	O
at	O
each	O
word	O
location	O
,	O
we	O
compute	O
the	O
inner	O
product	O
of	O
the	O
word	O
vectors	O
with	O
filters	B-Method
of	O
three	O
window	O
sizes	O
:	O
unigram	B-Method
,	O
bigram	B-Method
and	O
trigram	B-Method
.	O
	
For	O
the	O
-	O
th	O
word	O
,	O
the	O
convolution	O
output	O
with	O
window	O
size	O
is	O
given	O
by	O
where	O
is	O
the	O
weight	O
parameters	O
.	O
	
The	O
word	O
-	O
level	O
features	O
are	O
appropriately	O
0	O
-	O
padded	O
before	O
feeding	O
into	O
bigram	B-Method
and	I-Method
trigram	I-Method
convolutions	I-Method
to	O
maintain	O
the	O
length	O
of	O
the	O
sequence	O
after	O
convolution	O
.	O
	
Given	O
the	O
convolution	O
result	O
,	O
we	O
then	O
apply	O
max	B-Method
-	I-Method
pooling	I-Method
across	O
different	O
n	O
-	O
grams	O
at	O
each	O
word	O
location	O
to	O
obtain	O
	
phrase	B-Method
-	I-Method
level	I-Method
features	I-Method
Our	O
pooling	B-Method
method	I-Method
differs	O
from	O
those	O
used	O
in	O
previous	O
works	O
in	O
that	O
it	O
adaptively	O
selects	O
different	O
gram	O
features	O
at	O
each	O
time	O
step	O
,	O
while	O
preserving	O
the	O
original	O
sequence	O
length	O
and	O
order	O
.	O
	
We	O
use	O
a	O
LSTM	B-Method
to	O
encode	O
the	O
sequence	O
after	O
max	B-Method
-	I-Method
pooling	I-Method
.	O
	
The	O
corresponding	O
question	O
-	O
level	O
feature	O
is	O
the	O
LSTM	O
hidden	O
vector	O
at	O
time	O
.	O
	
Our	O
hierarchical	B-Method
representation	I-Method
of	O
the	O
question	O
is	O
depicted	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
a	O
)	O
.	O
	
subsection	O
:	O
Co	O
-	O
Attention	O
	
We	O
propose	O
two	O
co	B-Method
-	I-Method
attention	I-Method
mechanisms	I-Method
that	O
differ	O
in	O
the	O
order	O
in	O
which	O
image	O
and	O
question	O
attention	O
maps	O
are	O
generated	O
.	O
	
The	O
first	O
mechanism	O
,	O
which	O
we	O
call	O
parallel	B-Task
co	I-Task
-	I-Task
attention	I-Task
,	O
generates	O
image	B-Task
and	I-Task
question	I-Task
attention	I-Task
simultaneously	O
.	O
	
The	O
second	O
mechanism	O
,	O
which	O
we	O
call	O
alternating	B-Task
co	I-Task
-	I-Task
attention	I-Task
,	O
sequentially	O
alternates	O
between	O
generating	B-Task
image	I-Task
and	I-Task
question	I-Task
attentions	I-Task
.	O
	
See	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
These	O
co	B-Method
-	I-Method
attention	I-Method
mechanisms	I-Method
are	O
executed	O
at	O
all	O
three	O
levels	O
of	O
the	O
question	O
hierarchy	O
.	O
	
Parallel	B-Task
Co	I-Task
-	I-Task
Attention	I-Task
.	O
	
Parallel	B-Task
co	I-Task
-	I-Task
attention	I-Task
attends	O
to	O
the	O
image	O
and	O
question	O
simultaneously	O
.	O
	
Similar	O
to	O
,	O
we	O
connect	O
the	O
image	O
and	O
question	O
by	O
calculating	O
the	O
similarity	O
between	O
image	O
and	O
question	O
features	O
at	O
all	O
pairs	O
of	O
image	O
-	O
locations	O
and	O
question	O
-	O
locations	O
.	O
	
Specifically	O
,	O
given	O
an	O
image	O
feature	O
map	O
,	O
and	O
the	O
question	B-Method
representation	I-Method
,	O
the	O
affinity	O
matrix	O
is	O
calculated	O
by	O
where	O
contains	O
the	O
weights	O
.	O
	
After	O
computing	O
this	O
affinity	O
matrix	O
,	O
one	O
possible	O
way	O
of	O
computing	O
the	O
image	B-Task
(	I-Task
or	I-Task
question	I-Task
)	I-Task
attention	I-Task
is	O
to	O
simply	O
maximize	O
out	O
the	O
affinity	O
over	O
the	O
locations	O
of	O
other	O
modality	O
,	O
and	O
.	O
	
Instead	O
of	O
choosing	O
the	O
max	O
activation	O
,	O
we	O
find	O
that	O
performance	O
is	O
improved	O
if	O
we	O
consider	O
this	O
affinity	O
matrix	O
as	O
a	O
feature	O
and	O
learn	O
to	O
predict	O
image	B-Task
and	I-Task
question	I-Task
attention	I-Task
maps	I-Task
via	O
the	O
following	O
where	O
,	O
are	O
the	O
weight	O
parameters	O
.	O
	
and	O
are	O
the	O
attention	O
probabilities	O
of	O
each	O
image	O
region	O
and	O
word	O
respectively	O
.	O
	
The	O
affinity	O
matrix	O
transforms	O
question	O
attention	O
space	O
to	O
image	O
attention	O
space	O
(	O
vice	O
versa	O
for	O
)	O
.	O
	
Based	O
on	O
the	O
above	O
attention	O
weights	O
,	O
the	O
image	O
and	O
question	O
attention	O
vectors	O
are	O
calculated	O
as	O
the	O
weighted	O
sum	O
of	O
the	O
image	O
features	O
and	O
question	O
features	O
,	O
i.e.	O
,	O
The	O
parallel	B-Task
co	I-Task
-	I-Task
attention	I-Task
is	O
done	O
at	O
each	O
level	O
in	O
the	O
hierarchy	O
,	O
leading	O
to	O
and	O
where	O
.	O
	
Alternating	B-Task
Co	I-Task
-	I-Task
Attention	I-Task
.	O
	
In	O
this	O
attention	B-Method
mechanism	I-Method
,	O
we	O
sequentially	O
alternate	O
between	O
generating	B-Task
image	I-Task
and	I-Task
question	I-Task
attention	I-Task
.	O
	
Briefly	O
,	O
this	O
consists	O
of	O
three	O
steps	O
(	O
marked	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
b	O
)	O
	
:	O
1	O
)	O
summarize	O
the	O
question	O
into	O
a	O
single	O
vector	O
;	O
2	O
)	O
attend	O
to	O
the	O
image	O
based	O
on	O
the	O
question	O
summary	O
;	O
3	O
)	O
attend	O
to	O
the	O
question	O
based	O
on	O
the	O
attended	O
image	O
feature	O
.	O
	
Concretely	O
,	O
we	O
define	O
an	O
attention	B-Method
operation	I-Method
,	O
which	O
takes	O
the	O
image	O
(	O
or	O
question	O
)	O
features	O
and	O
attention	O
guidance	O
derived	O
from	O
question	O
(	O
or	O
image	O
)	O
as	O
inputs	O
,	O
and	O
outputs	O
the	O
attended	O
image	O
(	O
or	O
question	O
)	O
vector	O
.	O
	
The	O
operation	O
can	O
be	O
expressed	O
in	O
the	O
following	O
steps	O
where	O
is	O
a	O
vector	O
with	O
all	O
elements	O
to	O
be	O
1	O
.	O
and	O
are	O
parameters	O
.	O
	
is	O
the	O
attention	O
weight	O
of	O
feature	O
.	O
	
The	O
alternating	B-Method
co	I-Method
-	I-Method
attention	I-Method
process	I-Method
is	O
illustrated	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
b	O
)	O
.	O
	
At	O
the	O
first	O
step	O
of	O
alternating	B-Task
co	I-Task
-	I-Task
attention	I-Task
,	O
,	O
and	O
is	O
;	O
At	O
the	O
second	O
step	O
,	O
where	O
is	O
the	O
image	O
features	O
,	O
and	O
the	O
guidance	O
is	O
intermediate	O
attended	O
question	O
feature	O
from	O
the	O
first	O
step	O
;	O
Finally	O
,	O
we	O
use	O
the	O
attended	O
image	O
feature	O
as	O
the	O
guidance	O
to	O
attend	O
the	O
question	O
again	O
,	O
i.e.	O
,	O
and	O
.	O
	
Similar	O
to	O
the	O
parallel	B-Task
co	I-Task
-	I-Task
attention	I-Task
,	O
the	O
alternating	B-Task
co	I-Task
-	I-Task
attention	I-Task
is	O
also	O
done	O
at	O
each	O
level	O
of	O
the	O
hierarchy	O
.	O
	
subsection	O
:	O
Encoding	O
for	O
Predicting	B-Task
Answers	I-Task
	
Following	O
,	O
we	O
treat	O
VQA	B-Task
as	O
a	O
classification	B-Task
task	I-Task
.	O
	
We	O
predict	O
the	O
answer	O
based	O
on	O
the	O
co	O
-	O
attended	O
image	O
and	O
question	O
features	O
from	O
all	O
three	O
levels	O
.	O
	
We	O
use	O
a	O
multi	B-Method
-	I-Method
layer	I-Method
perceptron	I-Method
(	I-Method
MLP	I-Method
)	O
to	O
recursively	O
encode	O
the	O
attention	O
features	O
as	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
(	O
b	O
)	O
.	O
where	O
and	O
are	O
the	O
weight	O
parameters	O
.	O
	
is	O
the	O
concatenation	O
operation	O
on	O
two	O
vectors	O
.	O
	
is	O
the	O
probability	O
of	O
the	O
final	O
answer	O
.	O
	
section	O
:	O
Experiment	O
	
subsection	O
:	O
Datasets	O
	
We	O
evaluate	O
the	O
proposed	O
model	O
on	O
two	O
datasets	O
,	O
the	O
VQA	B-Material
dataset	I-Material
and	O
the	O
COCO	O
-	O
QA	O
dataset	O
.	O
	
VQA	B-Material
dataset	I-Material
is	O
the	O
largest	O
dataset	O
for	O
this	O
problem	O
,	O
containing	O
human	O
annotated	O
questions	O
and	O
answers	O
on	O
Microsoft	B-Material
COCO	I-Material
dataset	I-Material
.	O
	
The	O
dataset	O
contains	O
248	O
,	O
349	O
training	O
questions	O
,	O
121	O
,	O
512	O
validation	O
questions	O
,	O
244	O
,	O
302	O
testing	O
questions	O
,	O
and	O
a	O
total	O
of	O
6	O
,	O
141	O
,	O
630	O
question	O
-	O
answers	O
pairs	O
.	O
	
There	O
are	O
three	O
sub	O
-	O
categories	O
according	O
to	O
answer	O
-	O
types	O
including	O
yes	O
/	O
no	O
,	O
number	O
,	O
and	O
other	O
.	O
	
Each	O
question	O
has	O
10	O
free	O
-	O
response	O
answers	O
.	O
	
We	O
use	O
the	O
top	O
1000	O
most	O
frequent	O
answers	O
as	O
the	O
possible	O
outputs	O
similar	O
to	O
.	O
	
This	O
set	O
of	O
answers	O
covers	O
86.54	O
%	O
of	O
the	O
train	O
+	O
val	O
answers	O
.	O
	
For	O
testing	O
,	O
we	O
train	O
our	O
model	O
on	O
VQA	B-Material
train	I-Material
+	I-Material
val	I-Material
and	O
report	O
the	O
test	B-Metric
-	I-Metric
dev	I-Metric
and	O
test	O
-	O
standard	O
results	O
from	O
the	O
VQA	B-Task
evaluation	I-Task
server	I-Task
.	O
	
We	O
use	O
the	O
evaluation	O
protocol	O
of	O
in	O
the	O
experiment	O
.	O
	
COCO	O
-	O
QA	O
dataset	O
is	O
automatically	O
generated	O
from	O
captions	O
in	O
the	O
Microsoft	B-Material
COCO	I-Material
dataset	I-Material
.	O
	
There	O
are	O
78	O
,	O
736	O
train	O
questions	O
and	O
38	O
,	O
948	O
test	O
questions	O
in	O
the	O
dataset	O
.	O
	
These	O
questions	O
are	O
based	O
on	O
8	O
,	O
000	O
and	O
4	O
,	O
000	O
images	O
respectively	O
.	O
	
There	O
are	O
four	O
types	O
of	O
questions	O
including	O
object	O
,	O
number	O
,	O
color	O
,	O
and	O
location	O
.	O
	
Each	O
type	O
takes	O
,	O
,	O
,	O
and	O
of	O
the	O
whole	O
dataset	O
,	O
respectively	O
.	O
	
All	O
answers	O
in	O
this	O
data	O
set	O
are	O
single	O
word	O
.	O
	
As	O
in	O
,	O
we	O
report	O
classification	B-Metric
accuracy	I-Metric
as	O
well	O
as	O
	
Wu	B-Metric
-	I-Metric
Palmer	I-Metric
similarity	I-Metric
(	O
WUPS	B-Metric
)	O
in	O
Table	O
2	O
.	O
	
subsection	O
:	O
Setup	O
	
We	O
use	O
Torch	B-Method
to	O
develop	O
our	O
model	O
.	O
	
We	O
use	O
the	O
Rmsprop	B-Method
optimizer	I-Method
with	O
a	O
base	B-Method
learning	I-Method
rate	I-Method
of	O
4e	O
-	O
4	O
,	O
momentum	O
0.99	O
and	O
weight	B-Method
-	I-Method
decay	I-Method
1e	O
-	O
8	O
.	O
	
We	O
set	O
batch	O
size	O
to	O
be	O
300	O
and	O
train	O
for	O
up	O
to	O
256	O
epochs	O
with	O
early	O
stopping	O
if	O
the	O
validation	B-Metric
accuracy	I-Metric
has	O
not	O
improved	O
in	O
the	O
last	O
5	O
epochs	O
.	O
	
For	O
COCO	O
-	O
QA	O
,	O
the	O
size	O
of	O
hidden	O
layer	O
is	O
set	O
to	O
512	O
and	O
1024	O
for	O
VQA	B-Task
since	O
it	O
is	O
a	O
much	O
larger	O
dataset	O
.	O
	
All	O
the	O
other	O
word	B-Method
embedding	I-Method
and	O
hidden	B-Method
layers	I-Method
were	O
vectors	O
of	O
size	O
512	O
.	O
	
We	O
apply	O
dropout	B-Method
with	O
probability	O
on	O
each	O
layer	O
.	O
	
Following	O
,	O
we	O
rescale	O
the	O
image	O
to	O
,	O
and	O
then	O
take	O
the	O
activation	O
from	O
the	O
last	O
pooling	B-Method
layer	I-Method
of	O
VGGNet	B-Method
or	O
ResNet	B-Method
as	O
its	O
feature	O
.	O
	
subsection	O
:	O
Results	O
and	O
Analysis	O
	
There	O
are	O
two	O
test	O
scenarios	O
on	O
VQA	B-Task
:	O
open	B-Material
-	I-Material
ended	I-Material
and	O
multiple	B-Material
-	I-Material
choice	I-Material
.	O
	
The	O
best	O
performing	O
method	O
deeper	O
LSTM	B-Method
Q	I-Method
+	I-Method
norm	I-Method
I	I-Method
from	O
is	O
used	O
as	O
our	O
baseline	O
.	O
	
For	O
open	B-Material
-	I-Material
ended	I-Material
test	O
scenario	O
,	O
we	O
compare	O
our	O
method	O
with	O
the	O
recent	O
proposed	O
SMem	B-Method
,	O
SAN	B-Method
,	O
FDA	B-Method
and	O
DMN	B-Method
+	I-Method
.	O
	
For	O
multiple	B-Task
choice	I-Task
,	O
we	O
compare	O
with	O
Region	B-Method
Sel	I-Method
.	O
	
and	O
FDA	O
.	O
	
We	O
compare	O
with	O
2	B-Method
-	I-Method
VIS	I-Method
+	I-Method
BLSTM	I-Method
,	O
IMG	B-Method
-	I-Method
CNN	I-Method
and	O
SAN	B-Method
on	O
COCO	O
-	O
QA	O
.	O
	
We	O
use	O
to	O
refer	O
to	O
our	O
parallel	B-Method
co	I-Method
-	I-Method
attention	I-Method
,	O
for	O
alternating	B-Task
co	I-Task
-	I-Task
attention	I-Task
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
results	O
on	O
the	O
VQA	B-Material
test	I-Material
sets	I-Material
for	O
both	O
open	B-Material
-	I-Material
ended	I-Material
and	O
multiple	B-Material
-	I-Material
choice	I-Material
settings	O
.	O
	
We	O
can	O
see	O
that	O
our	O
approach	O
improves	O
the	O
state	O
of	O
art	O
from	O
60.4	O
%	O
(	O
DMN	B-Method
+	I-Method
)	O
to	O
62.1	O
%	O
(	O
+	O
ResNet	B-Method
)	O
on	O
open	B-Material
-	I-Material
ended	I-Material
and	O
from	O
64.2	O
%	O
(	O
FDA	B-Method
)	O
to	O
66.1	O
%	O
(	O
+	O
ResNet	B-Method
)	O
on	O
multiple	B-Material
-	I-Material
choice	I-Material
.	O
	
Notably	O
,	O
for	O
the	O
question	O
type	O
Other	O
and	O
Num	O
,	O
we	O
achieve	O
3.4	O
%	O
and	O
1.4	O
%	O
improvement	O
on	O
open	B-Material
-	I-Material
ended	I-Material
questions	I-Material
,	O
and	O
4.0	O
%	O
and	O
1.1	O
%	O
on	O
multiple	B-Material
-	I-Material
choice	I-Material
questions	I-Material
.	O
	
As	O
we	O
can	O
see	O
,	O
ResNet	B-Method
features	O
outperform	O
or	O
match	O
VGG	O
features	O
in	O
all	O
cases	O
.	O
	
Our	O
improvements	O
are	O
not	O
solely	O
due	O
to	O
the	O
use	O
of	O
a	O
better	O
CNN	B-Method
.	O
	
Specifically	O
,	O
FDA	B-Method
also	O
uses	O
ResNet	B-Method
,	O
but	O
+	O
ResNet	B-Method
outperforms	O
it	O
by	O
1.8	O
%	O
on	O
test	O
-	O
dev	O
.	O
	
SMem	B-Method
uses	O
GoogLeNet	B-Method
and	O
the	O
rest	O
all	O
use	O
VGGNet	B-Method
,	O
and	O
Ours	O
+	O
VGG	O
outperforms	O
them	O
by	O
0.2	O
%	O
on	O
test	O
-	O
dev	O
(	O
DMN	B-Method
+	I-Method
)	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
results	O
on	O
the	O
COCO	O
-	O
QA	O
test	O
set	O
.	O
	
Similar	O
to	O
the	O
result	O
on	O
VQA	B-Task
,	O
our	O
model	O
improves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
from	O
61.6	O
%	O
(	O
SAN	B-Method
(	I-Method
2	I-Method
,	I-Method
CNN	I-Method
)	O
)	O
to	O
65.4	O
%	O
(	O
+	O
ResNet	B-Method
)	O
.	O
	
We	O
observe	O
that	O
parallel	B-Method
co	I-Method
-	I-Method
attention	I-Method
performs	O
better	O
than	O
alternating	B-Method
co	I-Method
-	I-Method
attention	I-Method
in	O
this	O
setup	O
.	O
	
Both	O
attention	B-Method
mechanisms	I-Method
have	O
their	O
advantages	O
and	O
disadvantages	O
:	O
parallel	B-Task
co	I-Task
-	I-Task
attention	I-Task
is	O
harder	O
to	O
train	O
because	O
of	O
the	O
dot	O
product	O
between	O
image	O
and	O
text	O
which	O
compresses	O
two	O
vectors	O
into	O
a	O
single	O
value	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
alternating	B-Task
co	I-Task
-	I-Task
attention	I-Task
may	O
suffer	O
from	O
errors	O
being	O
accumulated	O
at	O
each	O
round	O
.	O
	
subsection	O
:	O
Ablation	B-Task
Study	I-Task
	
In	O
this	O
section	O
,	O
we	O
perform	O
ablation	B-Task
studies	I-Task
to	O
quantify	O
the	O
role	O
of	O
each	O
component	O
in	O
our	O
model	O
.	O
	
Specifically	O
,	O
we	O
re	O
-	O
train	O
our	O
approach	O
by	O
ablating	O
certain	O
components	O
:	O
	
Image	B-Task
Attention	I-Task
alone	O
,	O
where	O
in	O
a	O
manner	O
similar	O
to	O
previous	O
works	O
,	O
we	O
do	O
not	O
use	O
any	O
question	O
attention	O
.	O
	
The	O
goal	O
of	O
this	O
comparison	O
is	O
to	O
verify	O
that	O
our	O
improvements	O
are	O
not	O
the	O
result	O
of	O
orthogonal	O
contributions	O
.	O
	
(	O
say	O
better	O
optimization	B-Task
or	O
better	O
CNN	O
features	O
)	O
.	O
	
Question	B-Task
Attention	I-Task
alone	O
,	O
where	O
no	O
image	O
attention	O
is	O
performed	O
.	O
	
W	B-Method
/	I-Method
O	I-Method
Conv	I-Method
,	O
where	O
no	O
convolution	B-Method
and	I-Method
pooling	I-Method
is	O
performed	O
to	O
represent	O
phrases	O
.	O
	
Instead	O
,	O
we	O
stack	O
another	O
word	B-Method
embedding	I-Method
layer	I-Method
on	O
the	O
top	O
of	O
word	O
level	O
outputs	O
.	O
	
W	O
/	O
O	O
W	O
-	O
Atten	O
,	O
where	O
no	O
word	O
level	O
co	O
-	O
attention	O
is	O
performed	O
.	O
	
We	O
replace	O
the	O
word	O
level	O
attention	O
with	O
a	O
uniform	B-Method
distribution	I-Method
.	O
	
Phrase	O
and	O
question	O
level	O
co	O
-	O
attentions	O
are	O
still	O
modeled	O
.	O
	
W	O
/	O
O	O
P	O
-	O
Atten	O
,	O
where	O
no	O
phrase	O
level	O
co	O
-	O
attention	O
is	O
performed	O
,	O
and	O
the	O
phrase	O
level	O
attention	O
is	O
set	O
to	O
be	O
uniform	O
.	O
	
Word	O
and	O
question	O
level	O
co	O
-	O
attentions	O
are	O
still	O
modeled	O
.	O
	
W	O
/	O
O	O
Q	O
-	O
Atten	O
,	O
where	O
no	O
question	O
level	O
co	O
-	O
attention	O
is	O
performed	O
.	O
	
We	O
replace	O
the	O
question	O
level	O
attention	O
with	O
a	O
uniform	O
distribution	O
.	O
	
Word	O
and	O
phrase	O
level	O
co	O
-	O
attentions	O
are	O
still	O
modeled	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
comparison	O
of	O
our	O
full	O
approach	O
w.r.t	O
these	O
ablations	O
on	O
the	O
VQA	B-Material
validation	I-Material
set	I-Material
(	O
test	O
sets	O
are	O
not	O
recommended	O
to	O
be	O
used	O
for	O
such	O
experiments	O
)	O
.	O
	
The	O
deeper	B-Method
LSTM	I-Method
Q	I-Method
+	I-Method
norm	I-Method
I	I-Method
baseline	I-Method
in	O
antol2015vqa	O
is	O
also	O
reported	O
for	O
comparison	O
.	O
	
We	O
can	O
see	O
that	O
image	B-Method
-	I-Method
attention	I-Method
-	O
alone	O
does	O
improve	O
performance	O
over	O
the	O
holistic	O
image	O
feature	O
(	O
deeper	O
LSTM	B-Method
Q	I-Method
+	I-Method
norm	I-Method
I	I-Method
)	O
,	O
which	O
is	O
consistent	O
with	O
findings	O
of	O
previous	O
attention	B-Method
models	I-Method
for	O
VQA	B-Task
.	O
	
Ablation	O
study	O
on	O
the	O
VQA	B-Material
dataset	I-Material
using	O
Oursa	B-Method
+	I-Method
VGG	I-Method
.	O
	
validationMethodY	O
/	O
NNumOtherAllLSTM	O
Q	O
+	O
I79.832.940.754.3Image	O
Atten79.833.943.655.9Question	O
	
Atten79.433.341.754.8W	O
/	O
O	O
Q	O
-	O
Atten79.632.142.955.3W	O
/	O
O	O
P	O
-	O
Atten79.534.145.456.7W	O
	
/	O
O	O
W	O
-	O
Atten79.634.445.656.8Full	O
Model79.635.045.757.0	O
	
Comparing	O
the	O
full	O
model	O
ablated	O
versions	O
without	O
word	O
,	O
phrase	O
,	O
question	O
level	O
attentions	O
reveals	O
a	O
clear	O
interesting	O
trend	O
–	O
	
the	O
attention	B-Method
mechanisms	I-Method
closest	O
to	O
the	O
‘	O
top	O
’	O
of	O
the	O
hierarchy	O
(	O
question	O
)	O
matter	O
most	O
,	O
with	O
a	O
drop	O
of	O
1.7	O
%	O
in	O
accuracy	B-Metric
if	O
not	O
modeled	O
;	O
followed	O
by	O
the	O
intermediate	O
level	O
(	O
phrase	O
)	O
,	O
with	O
a	O
drop	O
of	O
0.3	O
%	O
;	O
finally	O
followed	O
by	O
the	O
‘	O
bottom	O
’	O
of	O
the	O
hierarchy	O
(	O
word	O
)	O
,	O
with	O
a	O
drop	O
of	O
0.2	O
%	O
in	O
accuracy	B-Metric
.	O
	
We	O
hypothesize	O
that	O
this	O
is	O
because	O
the	O
question	O
level	O
is	O
the	O
‘	O
closest	O
’	O
to	O
the	O
answer	O
prediction	O
layers	O
in	O
our	O
model	O
.	O
	
Note	O
that	O
all	O
levels	O
are	O
important	O
,	O
and	O
our	O
final	O
model	O
significantly	O
outperforms	O
not	O
using	O
any	O
linguistic	O
attention	O
(	O
1.1	O
%	O
difference	O
between	O
Full	B-Method
Model	I-Method
and	O
Image	B-Method
Atten	I-Method
)	O
.	O
	
The	O
question	B-Method
attention	I-Method
alone	I-Method
model	I-Method
is	O
better	O
than	O
LSTM	B-Method
Q	I-Method
+	I-Method
I	I-Method
,	O
with	O
an	O
improvement	O
of	O
0.5	O
%	O
and	O
worse	O
than	O
image	B-Method
attention	I-Method
alone	I-Method
,	O
with	O
a	O
drop	O
of	O
1.1	O
%	O
.	O
	
further	O
improves	O
if	O
we	O
performed	O
alternating	B-Method
co	I-Method
-	I-Method
attention	I-Method
for	O
one	O
more	O
round	O
,	O
with	O
an	O
improvement	O
of	O
0.3	O
%	O
.	O
	
subsection	O
:	O
Qualitative	O
Results	O
	
We	O
now	O
visualize	O
some	O
co	O
-	O
attention	O
maps	O
generated	O
by	O
our	O
method	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
At	O
the	O
word	O
level	O
,	O
our	O
model	O
attends	O
mostly	O
to	O
the	O
object	O
regions	O
in	O
an	O
image	O
,	O
e.g.	O
,	O
heads	O
,	O
bird	O
.	O
	
At	O
the	O
phrase	O
level	O
,	O
the	O
image	B-Task
attention	I-Task
has	O
different	O
patterns	O
across	O
images	O
.	O
	
For	O
the	O
first	O
two	O
images	O
,	O
the	O
attention	O
transfers	O
from	O
objects	O
to	O
background	O
regions	O
.	O
	
For	O
the	O
third	O
image	O
,	O
the	O
attention	O
becomes	O
more	O
focused	O
on	O
the	O
objects	O
.	O
	
We	O
suspect	O
that	O
this	O
is	O
caused	O
by	O
the	O
different	O
question	O
types	O
.	O
	
On	O
the	O
question	O
side	O
,	O
our	O
model	O
is	O
capable	O
of	O
localizing	O
the	O
key	O
phrases	O
in	O
the	O
question	O
,	O
thus	O
essentially	O
discovering	O
the	O
question	O
types	O
in	O
the	O
dataset	O
.	O
	
For	O
example	O
,	O
our	O
model	O
pays	O
attention	O
to	O
the	O
phrases	O
	
‘	O
‘	O
	
what	O
color	O
’	O
’	O
and	O
	
‘	O
‘	O
how	O
many	O
snowboarders	O
’	O
’	O
.	O
	
Our	O
model	O
successfully	O
attends	O
to	O
the	O
regions	O
in	O
images	O
and	O
phrases	O
in	O
the	O
questions	O
appropriate	O
for	O
answering	O
the	O
question	O
,	O
e.g.	O
,	O
‘	O
	
‘	O
color	O
of	O
the	O
bird	O
’	O
’	O
and	O
bird	O
region	O
.	O
	
Because	O
our	O
model	O
performs	O
co	O
-	O
attention	O
at	O
three	O
levels	O
,	O
it	O
often	O
captures	O
complementary	O
information	O
from	O
each	O
level	O
,	O
and	O
then	O
combines	O
them	O
to	O
predict	O
the	O
answer	O
.	O
	
Q	O
:	O
what	O
is	O
the	O
man	O
holding	O
a	O
snowboard	O
on	O
top	O
of	O
a	O
snow	O
covered	O
?	O
	
A	O
:	O
mountain	O
what	O
is	O
the	O
man	O
holding	O
a	O
snowboard	O
on	O
top	O
of	O
a	O
snow	O
covered	O
what	O
is	O
the	O
man	O
holding	O
a	O
snowboard	O
on	O
top	O
of	O
a	O
snow	O
covered	O
?	O
	
what	O
is	O
the	O
man	O
holding	O
a	O
snowboard	O
on	O
top	O
of	O
a	O
snow	O
covered	O
?	O
	
Q	O
:	O
what	O
is	O
the	O
color	O
of	O
the	O
bird	O
?	O
	
A	O
:	O
white	O
what	O
is	O
the	O
color	O
of	O
the	O
bird	O
?	O
	
what	O
is	O
the	O
color	O
of	O
the	O
bird	O
?	O
	
what	O
is	O
the	O
color	O
of	O
the	O
bird	O
?	O
	
Q	O
:	O
how	O
many	O
snowboarders	O
in	O
formation	O
in	O
the	O
snow	O
,	O
four	O
is	O
sitting	O
?	O
	
A	O
:	O
5	O
how	O
many	O
snowboarders	O
in	O
formation	O
in	O
the	O
snow	O
,	O
four	O
is	O
sitting	O
?	O
	
how	O
many	O
snowboarders	O
in	O
formation	O
in	O
the	O
snow	O
,	O
four	O
is	O
sitting	O
?	O
	
how	O
many	O
snowboarders	O
in	O
formation	O
in	O
the	O
snow	O
,	O
four	O
is	O
sitting	O
?	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
paper	O
,	O
we	O
proposed	O
a	O
hierarchical	B-Method
co	I-Method
-	I-Method
attention	I-Method
model	I-Method
for	O
visual	B-Task
question	I-Task
answering	I-Task
.	O
	
Co	B-Method
-	I-Method
attention	I-Method
allows	O
our	O
model	O
to	O
attend	O
to	O
different	O
regions	O
of	O
the	O
image	O
as	O
well	O
as	O
different	O
fragments	O
of	O
the	O
question	O
.	O
	
We	O
model	O
the	O
question	O
hierarchically	O
at	O
three	O
levels	O
to	O
capture	O
information	O
from	O
different	O
granularities	O
.	O
	
The	O
ablation	O
studies	O
further	O
demonstrate	O
the	O
roles	O
of	O
co	O
-	O
attention	O
and	O
question	O
hierarchy	O
in	O
our	O
final	O
performance	O
.	O
	
Through	O
visualizations	O
,	O
we	O
can	O
see	O
that	O
our	O
model	O
co	O
-	O
attends	O
to	O
interpretable	O
regions	O
of	O
images	O
and	O
questions	O
for	O
predicting	O
the	O
answer	O
.	O
	
Though	O
our	O
model	O
was	O
evaluated	O
on	O
visual	B-Task
question	I-Task
answering	I-Task
,	O
it	O
can	O
be	O
potentially	O
applied	O
to	O
other	O
tasks	O
involving	O
vision	B-Task
and	O
language	B-Task
.	O
	
Acknowledgements	O
This	O
work	O
was	O
funded	O
in	O
part	O
by	O
NSF	O
CAREER	O
awards	O
to	O
DP	O
and	O
DB	O
,	O
an	O
ONR	O
YIP	O
award	O
to	O
DP	O
,	O
ONR	O
Grant	O
N00014	O
-	O
14	O
-	O
1	O
-	O
0679	O
to	O
DB	O
,	O
a	O
Sloan	O
Fellowship	O
to	O
DP	O
,	O
ARO	O
YIP	O
awards	O
to	O
DB	O
and	O
DP	O
,	O
a	O
Allen	O
Distinguished	O
Investigator	O
award	O
to	O
DP	O
from	O
the	O
Paul	O
G.	O
Allen	O
Family	O
Foundation	O
,	O
ICTAS	O
Junior	O
Faculty	O
awards	O
to	O
DB	O
and	O
DP	O
,	O
Google	O
Faculty	O
Research	O
Awards	O
to	O
DP	O
and	O
DB	O
,	O
AWS	O
in	O
Education	O
Research	O
grant	O
to	O
DB	O
,	O
and	O
NVIDIA	O
GPU	O
donations	O
to	O
DB	O
.	O
	
The	O
views	O
and	O
conclusions	O
contained	O
herein	O
are	O
those	O
of	O
the	O
authors	O
and	O
should	O
not	O
be	O
interpreted	O
as	O
necessarily	O
representing	O
the	O
official	O
policies	O
or	O
endorsements	O
,	O
either	O
expressed	O
or	O
implied	O
,	O
of	O
the	O
U.S.	O
Government	O
or	O
any	O
sponsor	O
.	O
	
Q	O
:	O
what	O
is	O
the	O
color	O
of	O
the	O
kitten	O
?	O
	
A	O
:	O
black	O
Q	O
:	O
what	O
are	O
standing	O
in	O
tall	O
dry	O
grass	O
look	O
at	O
the	O
tourists	O
?	O
	
A	O
:	O
zebras	O
Q	O
:	O
where	O
is	O
the	O
woman	O
while	O
her	O
baby	O
is	O
sleeping	O
?	O
	
A	O
:	O
kitchen	O
Q	O
:	O
what	O
seating	O
area	O
is	O
on	O
the	O
right	O
?	O
	
A	O
:	O
park	O
Q	O
:	O
is	O
the	O
person	O
dressed	O
properly	O
for	O
this	O
sport	O
?	O
	
A	O
:	O
yes	O
what	O
is	O
the	O
color	O
of	O
the	O
kitten	O
?	O
	
what	O
are	O
standing	O
in	O
tall	O
dry	O
grass	O
look	O
at	O
the	O
tourists	O
?	O
	
where	O
is	O
the	O
woman	O
while	O
her	O
baby	O
is	O
sleeping	O
?	O
	
what	O
seating	O
area	O
is	O
on	O
the	O
right	O
?	O
	
is	O
the	O
person	O
dressed	O
properly	O
for	O
the	O
sport	O
?	O
	
what	O
is	O
the	O
color	O
of	O
the	O
kitten	O
?	O
	
what	O
are	O
standing	O
in	O
tall	O
dry	O
grass	O
look	O
at	O
the	O
tourists	O
?	O
	
where	O
is	O
the	O
woman	O
while	O
her	O
baby	O
is	O
sleeping	O
?	O
	
what	O
seating	O
area	O
is	O
on	O
the	O
right	O
?	O
	
is	O
the	O
person	O
dressed	O
properly	O
for	O
the	O
sport	O
?	O
	
what	O
is	O
the	O
color	O
of	O
the	O
kitten	O
?	O
	
what	O
are	O
standing	O
in	O
tall	O
dry	O
grass	O
look	O
at	O
the	O
tourists	O
?	O
	
where	O
is	O
the	O
woman	O
while	O
her	O
baby	O
is	O
sleeping	O
?	O
	
what	O
seating	O
area	O
is	O
on	O
the	O
right	O
?	O
	
is	O
the	O
person	O
dressed	O
properly	O
for	O
the	O
sport	O
?	O
	
Q	O
:	O
how	O
many	O
red	O
motorcycles	O
with	O
riders	O
in	O
protective	O
gear	O
are	O
on	O
the	O
street	O
?	O
	
A	O
	
:	O
two	O
(	O
three	O
)	O
Q	O
:	O
what	O
is	O
the	O
color	O
of	O
the	O
bus	O
?	O
	
A	O
	
:	O
green	O
(	O
red	O
)	O
Q	O
:	O
what	O
is	O
shown	O
in	O
different	O
places	O
?	O
	
A	O
	
:	O
hydrant	O
(	O
toy	O
)	O
Q	O
:	O
do	O
the	O
doors	O
open	O
in	O
or	O
out	O
?	O
	
A	O
:	O
	
open	O
(	O
in	O
)	O
Q	O
:	O
is	O
this	O
an	O
open	O
market	O
at	O
night	O
?	O
	
A	O
:	O
yes	O
(	O
no	O
)	O
how	O
many	O
red	O
motorcycles	O
with	O
riders	O
in	O
protective	O
gear	O
are	O
on	O
the	O
street	O
?	O
	
what	O
is	O
the	O
color	O
of	O
the	O
bus	O
?	O
	
what	O
is	O
shown	O
in	O
different	O
places	O
?	O
	
do	O
the	O
doors	O
open	O
in	O
or	O
out	O
?	O
	
is	O
this	O
an	O
open	O
market	O
at	O
night	O
?	O
	
how	O
many	O
red	O
motorcycles	O
with	O
riders	O
in	O
protective	O
gear	O
are	O
on	O
the	O
street	O
?	O
	
what	O
is	O
the	O
color	O
of	O
the	O
bus	O
?	O
	
what	O
is	O
shown	O
in	O
different	O
places	O
?	O
	
do	O
the	O
doors	O
open	O
in	O
or	O
out	O
?	O
	
is	O
this	O
an	O
open	O
market	O
at	O
night	O
?	O
	
how	O
many	O
red	O
motorcycles	O
with	O
riders	O
in	O
protective	O
gear	O
are	O
on	O
the	O
street	O
?	O
	
what	O
is	O
the	O
color	O
of	O
the	O
bus	O
?	O
	
what	O
is	O
shown	O
in	O
different	O
places	O
?	O
	
do	O
the	O
doors	O
open	O
in	O
or	O
out	O
?	O
	
is	O
this	O
an	O
open	O
market	O
at	O
night	O
?	O
	
bibliography	O
:	O
References	O
	
We	O
propose	O
a	O
meta	B-Method
-	I-Method
parameter	I-Method
free	I-Method
,	I-Method
off	I-Method
-	I-Method
the	I-Method
-	I-Method
shelf	I-Method
,	I-Method
simple	I-Method
and	I-Method
fast	I-Method
unsupervised	I-Method
feature	I-Method
learning	I-Method
algorithm	I-Method
,	O
which	O
exploits	O
a	O
new	O
way	O
of	O
optimizing	O
for	O
sparsity	B-Task
.	O
	
Experiments	O
on	O
STL	B-Material
-	I-Material
10	I-Material
show	O
that	O
the	O
method	O
presents	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
and	O
provides	O
discriminative	O
features	O
that	O
generalize	O
well	O
.	O
	
Nomoremeta	O
-	O
parametertuninginunsupervisedsparsefeaturelearning	O
	
section	O
:	O
Introduction	O
	
Significant	O
effort	O
has	O
been	O
devoted	O
to	O
handcraft	O
appropriate	O
feature	B-Method
representations	I-Method
of	I-Method
data	I-Method
in	O
several	O
fields	O
.	O
	
In	O
tasks	O
such	O
as	O
image	B-Task
classification	I-Task
and	O
object	B-Task
recognition	I-Task
,	O
unsupervised	O
learned	O
features	O
have	O
shown	O
to	O
compete	O
well	O
or	O
even	O
outperform	O
manually	O
designed	O
ones	O
.	O
	
Unsupervised	B-Method
feature	I-Method
learning	I-Method
has	O
also	O
shown	O
to	O
be	O
helpful	O
in	O
greedy	B-Task
layerwise	I-Task
pre	I-Task
-	I-Task
training	I-Task
of	I-Task
deep	I-Task
architectures	I-Task
.	O
	
In	O
,	O
the	O
author	O
claims	O
that	O
potentially	O
interesting	O
research	O
involves	O
pre	B-Method
-	I-Method
training	I-Method
algorithms	I-Method
,	O
which	O
“	O
[	O
…	O
]	O
would	O
be	O
proficient	O
at	O
extracting	O
good	O
features	O
but	O
involving	O
an	O
easier	O
optimization	B-Task
problem	I-Task
.	O
	
”	O
	
In	O
addition	O
to	O
that	O
,	O
one	O
of	O
the	O
main	O
criticisms	O
to	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
is	O
that	O
they	O
require	O
a	O
significant	O
amount	O
of	O
meta	O
-	O
parameters	O
.	O
	
As	O
stated	O
in	O
,	O
the	O
tuning	O
of	O
these	O
meta	O
-	O
parameters	O
is	O
a	O
laborious	O
task	O
that	O
requires	O
expert	O
knowledge	O
,	O
rules	O
of	O
thumb	O
or	O
extensive	O
search	O
and	O
,	O
whose	O
setting	O
can	O
vary	O
for	O
different	O
tasks	O
.	O
	
Therefore	O
,	O
there	O
is	O
great	O
interest	O
for	O
meta	B-Method
-	I-Method
parameter	I-Method
free	I-Method
methods	I-Method
and	O
automatic	B-Method
approaches	I-Method
to	O
optimize	O
the	O
performance	O
of	O
learning	B-Method
algorithms	I-Method
.	O
	
Nevertheless	O
,	O
little	O
effort	O
has	O
been	O
devoted	O
to	O
address	O
this	O
problem	O
(	O
see	O
Table	O
[	O
reference	O
]	O
for	O
a	O
comparison	O
of	O
meta	O
-	O
parameters	O
required	O
by	O
unsupervised	B-Method
feature	I-Method
learning	I-Method
methods	I-Method
)	O
.	O
	
To	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
work	O
in	O
this	O
direction	O
includes	O
ICA	B-Method
and	O
sparse	B-Method
filtering	I-Method
.	O
	
Although	O
ICA	B-Method
provides	O
good	O
results	O
at	O
object	B-Task
recognition	I-Task
tasks	I-Task
,	O
the	O
method	O
scales	O
poorly	O
to	O
large	O
datasets	O
and	O
high	O
input	O
dimensionality	O
.	O
	
Computational	B-Metric
complexity	I-Metric
is	O
also	O
a	O
major	O
drawback	O
of	O
many	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
.	O
	
ICA	B-Method
requires	O
an	O
expensive	O
orthogonalization	O
to	O
be	O
computed	O
at	O
each	O
iteration	O
.	O
	
Sparse	B-Method
coding	I-Method
has	O
an	O
expensive	O
inference	B-Task
,	O
which	O
requires	O
a	O
prohibitive	O
iterative	B-Method
optimization	I-Method
.	O
	
Significant	O
amount	O
of	O
work	O
has	O
been	O
done	O
in	O
order	O
to	O
overcome	O
this	O
limitation	O
.	O
	
Predictive	B-Method
Sparse	I-Method
Decomposition	I-Method
(	O
PSD	B-Method
)	O
is	O
a	O
successful	O
variant	O
of	O
sparse	B-Method
coding	I-Method
,	O
which	O
uses	O
a	O
predictor	B-Method
to	O
approximate	O
the	O
sparse	B-Method
representation	I-Method
and	O
solves	O
the	O
sparse	B-Method
coding	I-Method
computationally	O
expensive	O
encoding	B-Method
step	I-Method
.	O
	
In	O
this	O
paper	O
,	O
we	O
aim	O
to	O
solve	O
some	O
of	O
the	O
above	O
-	O
mentioned	O
problems	O
.	O
	
We	O
propose	O
a	O
meta	B-Method
-	I-Method
parameter	I-Method
free	O
,	O
off	O
-	O
the	O
-	O
shelf	O
,	O
simple	O
and	O
fast	O
approach	O
,	O
which	O
exploits	O
a	O
new	O
way	O
of	O
optimizing	O
for	O
a	O
sparsity	O
,	O
without	O
explicitly	O
modeling	O
the	O
data	O
distribution	O
.	O
	
The	O
method	O
iteratively	O
builds	O
an	O
ideally	O
sparse	O
target	O
and	O
optimizes	O
the	O
dictionary	O
by	O
minimizing	O
the	O
error	B-Metric
between	O
the	O
system	O
output	O
and	O
the	O
ideally	O
sparse	O
target	O
.	O
	
Defining	O
sparsity	O
concepts	O
in	O
terms	O
of	O
expected	O
output	O
allows	O
to	O
exploit	O
a	O
new	O
strategy	O
in	O
unsupervised	B-Task
training	I-Task
.	O
	
It	O
is	O
worth	O
stressing	O
that	O
many	O
optimization	B-Method
strategies	I-Method
can	O
be	O
used	O
to	O
minimize	O
the	O
above	O
-	O
mentioned	O
error	O
and	O
that	O
parameters	O
of	O
these	O
optimization	B-Method
techniques	I-Method
must	O
not	O
be	O
considered	O
as	O
belonging	O
to	O
our	O
approach	O
.	O
	
Experiments	O
on	O
STL	B-Material
-	I-Material
10	I-Material
dataset	I-Material
show	O
that	O
the	O
method	O
outperforms	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
in	O
single	O
layer	O
image	B-Task
classification	I-Task
,	O
providing	O
discriminative	O
features	O
that	O
generalize	O
well	O
.	O
	
Linear	B-Method
feature	I-Method
extraction	I-Method
methods	I-Method
combined	O
with	O
sparse	B-Method
coding	I-Method
encodings	I-Method
are	O
among	O
best	O
performers	O
on	O
object	O
recognition	O
datasets	O
.	O
	
The	O
importance	O
of	O
properly	O
combining	O
training	B-Method
/	I-Method
encoding	I-Method
and	I-Method
encoding	I-Method
/	I-Method
pooling	I-Method
strategies	I-Method
has	O
been	O
argued	O
in	O
and	O
respectively	O
.	O
	
Since	O
the	O
goal	O
of	O
this	O
paper	O
is	O
to	O
propose	O
a	O
new	O
method	O
for	O
unsupervised	B-Method
feature	I-Method
learning	I-Method
,	O
dealing	O
with	O
all	O
the	O
possible	O
combinations	O
of	O
encoding	O
and	O
pooling	B-Task
could	O
mask	O
the	O
benefits	O
of	O
the	O
method	O
that	O
we	O
propose	O
.	O
	
However	O
,	O
for	O
the	O
sake	O
of	O
fair	O
comparison	O
with	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
,	O
we	O
test	O
the	O
method	O
with	O
sparse	B-Method
coding	I-Method
and	O
soft	B-Method
-	I-Method
threshold	I-Method
encodings	I-Method
combined	O
with	O
sum	B-Method
pooling	I-Method
,	O
following	O
the	O
experimental	O
pipeline	O
of	O
.	O
	
section	O
:	O
State	O
-	O
of	O
-	O
the	O
-	O
art	O
	
Commonly	O
used	O
algorithms	O
for	O
unsupervised	B-Method
feature	I-Method
learning	I-Method
include	O
Restricted	B-Method
Boltzmann	I-Method
Machines	I-Method
(	O
RBM	B-Method
)	O
,	O
auto	B-Method
-	I-Method
encoders	I-Method
,	O
sparse	B-Method
coding	I-Method
and	O
hybrids	B-Method
such	O
as	O
PSD	B-Method
.	O
	
Many	O
other	O
methods	O
such	O
as	O
ICA	B-Method
,	O
Reconstruction	B-Method
ICA	I-Method
(	O
RICA	B-Method
)	O
,	O
Sparse	B-Method
Filtering	I-Method
and	O
methods	O
related	O
to	O
vector	B-Method
quantization	I-Method
such	O
as	O
Orthogonal	B-Method
Matching	I-Method
Pursuit	I-Method
(	O
OMP	B-Method
-	I-Method
k	I-Method
)	O
have	O
also	O
been	O
used	O
in	O
the	O
literature	O
to	O
extract	O
unsupervised	B-Task
feature	I-Task
representations	I-Task
.	O
	
These	O
algorithms	O
could	O
be	O
divided	O
into	O
two	O
categories	O
:	O
explicitly	O
modeling	O
or	O
not	O
the	O
input	O
distribution	O
.	O
	
Sparse	B-Method
auto	I-Method
-	I-Method
encoders	I-Method
,	O
sparse	B-Method
RBM	I-Method
,	O
sparse	B-Method
coding	I-Method
,	O
PSD	B-Method
,	O
OMP	B-Method
-	I-Method
k	I-Method
and	O
Reconstruction	B-Method
ICA	I-Method
(	O
RICA	B-Method
)	O
explicitly	O
model	O
the	O
data	O
distribution	O
by	O
minimizing	O
the	O
reconstruction	B-Metric
error	I-Metric
.	O
	
Although	O
learning	O
a	O
good	O
approximation	O
of	O
the	O
data	O
distribution	O
may	O
be	O
desirable	O
,	O
approaches	O
such	O
as	O
sparse	B-Method
filtering	I-Method
show	O
that	O
this	O
seems	O
not	O
so	O
important	O
if	O
the	O
goal	O
is	O
to	O
have	O
a	O
discriminative	B-Method
sparse	I-Method
system	I-Method
.	O
	
Sparse	B-Method
filtering	I-Method
does	O
not	O
attempt	O
to	O
explicitly	O
model	O
the	O
input	O
distribution	O
but	O
focuses	O
on	O
the	O
properties	O
of	O
the	O
output	O
distribution	O
instead	O
.	O
	
Sparsity	B-Method
is	O
among	O
the	O
desirable	O
properties	O
of	O
a	O
good	O
output	B-Method
representation	I-Method
.	O
	
Sparse	O
features	O
consist	O
of	O
a	O
large	O
amount	O
of	O
outputs	O
,	O
which	O
respond	O
rarely	O
and	O
provide	O
high	O
responses	O
when	O
they	O
do	O
respond	O
.	O
	
Sparsity	B-Method
can	O
be	O
described	O
in	O
terms	O
of	O
population	O
sparsity	O
and	O
lifetime	O
sparsity	O
.	O
	
Both	O
lifetime	O
and	O
population	O
sparsity	O
are	O
important	O
properties	O
of	O
the	O
output	O
distribution	O
.	O
	
On	O
one	O
hand	O
,	O
lifetime	O
sparsity	O
plays	O
an	O
important	O
role	O
in	O
preventing	O
bad	O
solutions	O
such	O
as	O
numerous	O
dead	O
outputs	O
.	O
	
There	O
seems	O
to	O
be	O
a	O
consensus	O
to	O
overcome	O
such	O
degenerate	O
solutions	O
,	O
which	O
is	O
to	O
ensure	O
similar	O
statistics	O
among	O
outputs	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
population	O
sparsity	O
helps	O
providing	O
a	O
simple	O
interpretation	O
of	O
the	O
input	O
data	O
such	O
as	O
the	O
ones	O
found	O
in	O
early	O
visual	O
areas	O
.	O
	
To	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
the	O
definition	O
of	O
population	B-Task
sparsity	I-Task
remains	O
ambiguous	O
.	O
	
State	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
optimize	O
either	O
for	O
one	O
or	O
both	O
sparsity	O
forms	O
in	O
their	O
objective	B-Metric
function	I-Metric
.	O
	
The	O
great	O
majority	O
seeks	O
sparsity	O
using	O
the	O
penalty	B-Method
and	O
does	O
not	O
optimize	O
for	O
an	O
explicit	O
level	O
of	O
sparsity	O
in	O
their	O
outputs	O
.	O
	
Sparse	B-Method
auto	I-Method
-	I-Method
encoders	I-Method
optimize	O
for	O
a	O
target	O
activation	O
allowing	O
to	O
deal	O
with	O
lifetime	O
sparsity	O
;	O
nevertheless	O
,	O
the	O
target	O
activation	O
requires	O
tuning	O
and	O
does	O
not	O
explicitly	O
control	O
the	O
level	O
of	O
population	O
sparsity	O
.	O
	
OMP	B-Method
-	I-Method
k	I-Method
defines	O
the	O
level	O
of	O
population	O
sparsity	O
by	O
setting	O
to	O
the	O
maximum	O
expected	O
number	O
of	O
non	O
-	O
zero	O
elements	O
per	O
output	O
code	O
,	O
whereas	O
the	O
methods	O
in	O
do	O
not	O
explicitly	O
define	O
the	O
proportion	O
of	O
outputs	O
expected	O
to	O
be	O
active	O
at	O
the	O
same	O
time	O
.	O
	
section	O
:	O
Method	O
	
In	O
this	O
section	O
,	O
we	O
describe	O
how	O
the	O
proposed	O
method	O
learns	O
a	O
sparse	B-Method
feature	I-Method
representation	I-Method
of	I-Method
the	I-Method
data	I-Method
in	O
terms	O
of	O
population	O
and	O
lifetime	O
sparsity	O
.	O
	
The	O
method	O
iteratively	O
builds	O
an	O
ideally	O
sparse	O
target	O
and	O
optimizes	O
the	O
dictionary	O
by	O
minimizing	O
the	O
error	B-Metric
between	O
the	O
system	O
output	O
and	O
the	O
ideally	O
sparse	O
target	O
.	O
	
Subsection	O
[	O
reference	O
]	O
highlights	O
the	O
algorithm	O
to	O
enforce	O
lifetime	O
and	O
population	O
sparsity	O
in	O
the	O
ideally	O
sparse	O
target	O
.	O
	
Subsection	O
[	O
reference	O
]	O
provides	O
implementation	O
details	O
on	O
the	O
system	O
and	O
optimization	B-Method
strategies	I-Method
used	O
to	O
minimize	O
the	O
error	O
between	O
the	O
system	O
output	O
and	O
the	O
ideally	O
sparse	O
target	O
.	O
	
subsection	O
:	O
Enforcing	O
Population	B-Task
and	O
Lifetime	B-Task
Sparsity	I-Task
by	O
defining	O
an	O
ideal	O
target	O
	
We	O
define	O
population	O
and	O
lifetime	O
sparsity	O
as	O
properties	O
of	O
an	O
ideal	O
sparse	O
output	O
.	O
	
Given	O
training	O
samples	O
and	O
an	O
output	O
of	O
dimensionality	O
,	O
we	O
define	O
the	O
first	O
property	O
of	O
the	O
output	O
as	O
:	O
Strong	O
Lifetime	O
Sparsity	O
:	O
The	O
output	O
vectors	O
must	O
be	O
composed	O
solely	O
of	O
active	O
and	O
inactive	O
units	O
(	O
no	O
intermediate	O
values	O
between	O
two	O
fixed	O
scalars	O
are	O
allowed	O
)	O
and	O
all	O
outputs	O
must	O
activate	O
for	O
an	O
equal	O
number	O
of	O
inputs	O
.	O
	
Activation	O
is	O
exactly	O
distributed	O
among	O
the	O
outputs	O
.	O
	
Our	O
Strong	B-Method
Lifetime	I-Method
Sparsity	I-Method
definition	I-Method
is	O
a	O
more	O
strict	O
requirement	O
than	O
the	O
high	O
dispersal	O
concept	O
introduced	O
in	O
,	O
since	O
they	O
only	O
require	O
that	O
“	O
the	O
mean	O
squared	O
activations	O
of	O
each	O
feature	O
(	O
output	O
)	O
	
[	O
…	O
]	O
should	O
be	O
roughly	O
the	O
same	O
for	O
all	O
features	O
(	O
outputs	O
)	O
”	O
.	O
	
While	O
high	O
dispersal	O
attempts	O
to	O
diversify	O
the	O
learned	O
bases	O
,	O
it	O
does	O
not	O
guarantee	O
the	O
output	O
distribution	O
,	O
in	O
the	O
lifetime	O
sense	O
,	O
to	O
be	O
composed	O
of	O
only	O
a	O
few	O
activations	O
.	O
	
Furthermore	O
,	O
our	O
definition	O
ensures	O
the	O
absence	O
of	O
dead	O
outputs	O
.	O
	
Given	O
our	O
definition	O
of	O
Strong	B-Task
Lifetime	I-Task
Sparsity	I-Task
,	O
the	O
population	O
sparsity	O
must	O
require	O
that	O
,	O
for	O
each	O
training	O
sample	O
,	O
only	O
one	O
output	O
element	O
is	O
active	O
:	O
	
Strong	O
Population	O
Sparsity	O
:	O
For	O
each	O
training	O
sample	O
only	O
one	O
output	O
must	O
be	O
active	O
.	O
	
The	O
rationale	O
of	O
our	O
approach	O
is	O
to	O
appropriately	O
generate	O
an	O
ideal	O
output	O
target	O
that	O
fulfils	O
properties	O
(	O
1	O
)	O
and	O
(	O
2	O
)	O
,	O
and	O
then	O
learn	O
the	O
parameters	O
of	O
the	O
system	O
by	O
minimizing	O
the	O
error	O
between	O
the	O
output	O
target	O
and	O
the	O
output	O
generated	O
by	O
the	O
system	O
during	O
training	O
.	O
	
In	O
this	O
way	O
,	O
we	O
seek	O
a	O
system	O
optimized	O
for	O
both	O
population	B-Task
and	O
lifetime	B-Task
sparsity	I-Task
in	O
an	O
explicit	O
way	O
.	O
	
The	O
key	O
component	O
of	O
our	O
approach	O
is	O
how	O
to	O
define	O
the	O
ideal	O
output	O
target	O
based	O
on	O
the	O
above	O
-	O
mentioned	O
properties	O
.	O
	
However	O
,	O
to	O
ensure	O
that	O
the	O
optimization	O
of	O
the	O
system	O
parameters	O
converges	O
,	O
we	O
add	O
a	O
third	O
property	O
:	O
	
Minimal	O
Perturbation	O
:	O
The	O
ideal	O
output	O
target	O
should	O
be	O
defined	O
as	O
the	O
best	O
approximation	O
of	O
the	O
system	O
output	O
by	O
means	O
of	O
error	O
fulfilling	O
properties	O
(	O
1	O
)	O
&	O
(	O
2	O
)	O
.	O
	
Creating	O
the	O
output	O
target	O
that	O
ensures	O
the	O
above	O
-	O
mentioned	O
properties	O
is	O
analogous	O
to	O
solving	O
an	O
assignment	B-Task
problem	I-Task
.	O
	
The	O
Hungarian	B-Method
method	I-Method
is	O
a	O
combinatorial	B-Method
optimization	I-Method
algorithm	I-Method
,	O
which	O
solves	O
the	O
assignment	B-Task
problem	I-Task
.	O
	
However	O
,	O
its	O
computational	B-Metric
cost	I-Metric
is	O
prohibitive	O
.	O
	
Therefore	O
,	O
in	O
the	O
next	O
section	O
we	O
propose	O
a	O
simple	O
and	O
fast	O
algorithm	O
to	O
generate	O
the	O
ideal	O
output	O
target	O
,	O
which	O
ensures	O
sparsity	O
properties	O
(	O
1	O
)	O
and	O
(	O
2	O
)	O
and	O
provides	O
an	O
approximate	B-Method
solution	I-Method
for	O
minimal	O
perturbation	O
property	O
(	O
3	O
)	O
.	O
	
subsubsection	O
:	O
Ideal	B-Method
target	I-Method
generation	I-Method
:	O
the	O
Enforcing	B-Method
Population	I-Method
and	I-Method
Lifetime	I-Method
Sparsity	I-Method
(	I-Method
EPLS	I-Method
)	I-Method
algorithm	I-Method
	
Let	O
us	O
assume	O
that	O
we	O
have	O
a	O
system	O
,	O
which	O
produces	O
a	O
row	O
output	O
vector	O
.	O
	
We	O
use	O
the	O
notation	O
to	O
refer	O
to	O
one	O
element	O
of	O
.	O
	
We	O
define	O
an	O
output	O
matrix	O
composed	O
of	O
output	O
vectors	O
of	O
dimensionality	O
,	O
such	O
that	O
.	O
	
Likewise	O
,	O
we	O
define	O
an	O
ideal	O
target	O
output	O
matrix	O
of	O
the	O
same	O
size	O
.	O
	
Algorithm	O
[	O
reference	O
]	O
details	O
the	O
EPLS	B-Method
algorithm	I-Method
to	O
generate	O
the	O
ideal	O
target	O
from	O
.	O
	
For	O
the	O
sake	O
of	O
simplicity	O
,	O
every	O
step	O
of	O
the	O
algorithm	O
where	O
the	O
subscript	O
appears	O
must	O
be	O
applied	O
.	O
	
EPLS	B-Method
[	O
1	O
]	O
,	O
a	O
,	O
N	O
a	O
T	O
to	O
active	O
/	O
inactive	O
values	O
of	O
the	O
corresponding	O
function	O
.	O
	
Starting	O
with	O
no	O
activation	O
in	O
(	O
line	O
1	O
)	O
,	O
the	O
algorithm	O
proceeds	O
as	O
follows	O
.	O
	
A	O
row	O
vector	O
from	O
is	O
processed	O
at	O
each	O
iteration	O
(	O
line	O
3	O
)	O
.	O
	
The	O
crucial	O
step	O
is	O
performed	O
in	O
line	O
4	O
:	O
the	O
output	O
that	O
has	O
to	O
be	O
activated	O
in	O
the	O
row	O
of	O
is	O
selected	O
as	O
the	O
one	O
that	O
has	O
the	O
maximal	O
activation	O
value	O
minus	O
the	O
inhibitor	O
.	O
	
The	O
inhibitor	O
can	O
be	O
seen	O
as	O
an	O
accumulator	O
that	O
“	O
counts	O
”	O
the	O
number	O
of	O
times	O
an	O
output	O
has	O
been	O
selected	O
,	O
increasing	O
its	O
inhibition	O
progressively	O
by	O
until	O
reaching	O
maximal	O
inhibition	O
.	O
	
This	O
prevents	O
the	O
selection	O
of	O
an	O
output	O
that	O
has	O
already	O
been	O
activated	O
times	O
.	O
	
The	O
rationale	O
behind	O
the	O
equation	O
in	O
line	O
4	O
is	O
that	O
,	O
while	O
selecting	O
the	O
maximal	O
responses	O
in	O
the	O
matrix	O
,	O
we	O
have	O
to	O
take	O
care	O
to	O
distribute	O
them	O
evenly	O
among	O
all	O
outputs	O
(	O
in	O
order	O
to	O
ensure	O
Strong	O
Lifetime	O
Sparsity	O
)	O
.	O
	
Using	O
this	O
strategy	O
,	O
it	O
can	O
be	O
demonstrated	O
that	O
the	O
resulting	O
matrix	O
perfectly	O
fulfills	O
properties	O
(	O
1	O
)	O
and	O
(	O
2	O
)	O
.	O
	
In	O
line	O
5	O
,	O
the	O
algorithm	O
activates	O
the	O
element	O
of	O
row	O
of	O
the	O
target	O
matrix	O
.	O
	
By	O
activating	O
the	O
“	O
relative	O
”	O
maximum	O
,	O
we	O
approximate	O
property	O
(	O
3	O
)	O
.	O
	
Finally	O
,	O
the	O
inhibitor	O
is	O
updated	O
in	O
line	O
6	O
.	O
	
subsection	O
:	O
System	O
and	O
Optimization	B-Method
strategies	I-Method
	
Let	O
us	O
assume	O
that	O
we	O
have	O
a	O
system	O
parameterized	O
by	O
,	O
with	O
activation	B-Method
function	I-Method
,	O
which	O
takes	O
as	O
input	O
a	O
data	O
vector	O
and	O
produces	O
an	O
output	O
vector	O
.	O
	
We	O
use	O
the	O
same	O
notation	O
as	O
in	O
Section	O
[	O
reference	O
]	O
and	O
define	O
a	O
data	O
matrix	O
composed	O
of	O
rows	O
and	O
columns	O
,	O
where	O
is	O
the	O
input	O
dimensionality	O
.	O
	
To	O
compare	O
our	O
training	B-Method
strategy	I-Method
to	O
previous	O
well	O
known	O
systems	O
,	O
we	O
tested	O
our	O
algorithm	O
using	O
where	O
is	O
a	O
logistic	O
non	O
-	O
linearity	O
.	O
	
subsubsection	O
:	O
Optimization	B-Method
strategy	I-Method
	
The	O
system	O
might	O
be	O
trained	O
by	O
means	O
of	O
an	O
off	B-Method
-	I-Method
the	I-Method
-	I-Method
shelf	I-Method
mini	I-Method
-	I-Method
batch	I-Method
Stochastic	I-Method
Gradient	I-Method
Descent	I-Method
(	I-Method
SGD	I-Method
)	I-Method
method	I-Method
with	O
adaptive	B-Method
learning	I-Method
rates	I-Method
such	O
as	O
variance	B-Method
-	I-Method
based	I-Method
SGD	I-Method
(	O
vSGD	B-Method
)	O
.	O
	
Algorithm	O
[	O
reference	O
]	O
details	O
the	O
latter	O
training	O
process	O
.	O
	
The	O
mini	O
-	O
batch	O
size	O
can	O
be	O
set	O
to	O
any	O
value	O
,	O
in	O
all	O
the	O
experiments	O
we	O
have	O
set	O
.	O
	
Starting	O
with	O
set	O
to	O
small	O
random	O
numbers	O
as	O
in	O
(	O
line	O
1	O
)	O
,	O
at	O
each	O
epoch	O
we	O
shuffle	O
the	O
samples	O
of	O
the	O
training	O
set	O
(	O
line	O
3	O
)	O
,	O
reset	O
the	O
EPLS	B-Method
inhibitor	I-Method
to	O
a	O
flat	O
activation	O
(	O
line	O
4	O
)	O
and	O
process	O
all	O
mini	O
-	O
batches	O
.	O
	
For	O
each	O
mini	O
-	O
batch	O
,	O
samples	O
are	O
selected	O
(	O
line	O
6	O
)	O
.	O
	
Then	O
,	O
the	O
output	O
is	O
computed	O
(	O
line	O
7	O
)	O
and	O
the	O
EPLS	B-Method
is	O
invoked	O
to	O
compute	O
and	O
update	O
(	O
line	O
8	O
)	O
.	O
	
After	O
that	O
,	O
the	O
gradient	O
of	O
the	O
error	O
is	O
computed	O
(	O
line	O
9	O
)	O
and	O
the	O
learning	B-Metric
rate	I-Metric
is	O
estimated	O
as	O
in	O
(	O
line	O
10	O
)	O
.	O
	
The	O
system	O
parameters	O
are	O
then	O
updated	O
to	O
minimize	O
the	O
error	O
(	O
line	O
11	O
)	O
.	O
	
Finally	O
,	O
the	O
bases	O
in	O
are	O
limited	O
to	O
have	O
unit	O
norm	O
to	O
avoid	O
degenerate	O
solutions	O
(	O
line	O
13	O
)	O
.	O
	
This	O
procedure	O
is	O
repeated	O
until	O
a	O
stop	O
condition	O
is	O
met	O
;	O
in	O
our	O
experiments	O
,	O
the	O
training	O
stops	O
when	O
the	O
relative	B-Metric
decrement	I-Metric
error	I-Metric
between	O
epochs	O
is	O
small	O
(	O
)	O
.	O
	
When	O
updating	O
the	O
system	O
parameters	O
,	O
we	O
assume	O
that	O
does	O
not	O
depend	O
on	O
,	O
thus	O
;	O
we	O
carried	O
out	O
experiments	O
that	O
show	O
that	O
this	O
approximation	O
does	O
not	O
significantly	O
influence	O
the	O
gradient	B-Metric
descent	I-Metric
convergence	I-Metric
nor	O
the	O
quality	B-Metric
of	O
the	O
minimization	B-Task
.	O
	
Moreover	O
,	O
this	O
assumption	O
makes	O
the	O
algorithm	O
faster	O
,	O
since	O
we	O
remove	O
the	O
need	O
of	O
computing	O
the	O
numerical	O
partial	O
derivatives	O
of	O
.	O
	
The	O
mini	B-Method
-	I-Method
batch	I-Method
vSGD	I-Method
allows	O
to	O
scale	O
the	O
algorithm	O
easily	O
,	O
especially	O
with	O
respect	O
to	O
the	O
number	O
of	O
samples	O
.	O
	
Standard	O
EPLS	B-Method
training	I-Method
[	O
1	O
]	O
small	O
random	O
values	O
D	O
randomly	O
flat	O
activation	O
mini	O
-	O
batch	O
samples	O
D	O
(	O
b	O
)	O
learning	B-Metric
rate	I-Metric
η	I-Metric
as	O
in	O
(	O
)	O
the	O
bases	O
W	O
in	O
Γ	O
to	O
have	O
unit	O
norm	O
condition	O
verified	O
	
section	O
:	O
Experiments	O
	
The	O
performance	O
of	O
training	B-Method
and	I-Method
encoding	I-Method
strategies	I-Method
in	O
single	B-Method
layer	I-Method
networks	I-Method
has	O
been	O
extensively	O
analyzed	O
in	O
the	O
literature	O
on	O
STL	B-Material
-	I-Material
10	I-Material
dataset	I-Material
.	O
	
STL	B-Material
-	I-Material
10	I-Material
	
dataset	O
consists	O
of	O
96x96	O
pixels	O
color	O
images	O
belonging	O
to	O
10	O
different	O
classes	O
.	O
	
The	O
dataset	O
is	O
divided	O
into	O
a	O
large	O
unlabeled	O
training	O
set	O
containing	O
100	O
K	O
images	O
and	O
smaller	O
labeled	O
training	O
and	O
test	O
sets	O
,	O
containing	O
5000	O
and	O
8000	O
images	O
,	O
respectively	O
.	O
	
It	O
has	O
to	O
be	O
considered	O
that	O
in	O
STL	B-Material
-	I-Material
10	I-Material
,	O
the	O
primary	O
challenge	O
is	O
to	O
make	O
use	O
of	O
the	O
unlabeled	O
data	O
(	O
100	O
K	O
images	O
)	O
,	O
which	O
is	O
100	O
times	O
bigger	O
than	O
the	O
labeled	O
data	O
used	O
to	O
train	O
the	O
classifier	B-Method
(	O
1000	O
images	O
per	O
fold	O
)	O
.	O
	
In	O
this	O
case	O
,	O
the	O
supervised	B-Task
training	I-Task
must	O
strongly	O
rely	O
on	O
the	O
ability	O
of	O
the	O
unsupervised	B-Method
method	I-Method
to	O
learn	O
discriminative	O
features	O
.	O
	
Moreover	O
,	O
since	O
the	O
unlabeled	O
dataset	O
contains	O
other	O
types	O
of	O
animals	O
(	O
bears	O
,	O
rabbits	O
,	O
etc	O
.	O
)	O
and	O
vehicles	O
(	O
trains	O
,	O
buses	O
,	O
etc	O
.	O
)	O
	
in	O
addition	O
to	O
the	O
ones	O
in	O
the	O
labeled	O
set	O
,	O
the	O
unsupervised	B-Method
method	I-Method
should	O
be	O
able	O
to	O
generalize	O
well	O
.	O
	
To	O
validate	O
our	O
method	O
,	O
we	O
follow	O
the	O
experimental	O
pipeline	O
of	O
.	O
	
We	O
first	O
extract	O
random	O
patches	O
and	O
normalize	O
them	O
for	O
local	O
brightness	O
and	O
contrast	O
.	O
	
Note	O
that	O
EPLS	B-Method
does	O
not	O
require	O
any	O
whitening	O
of	O
the	O
input	O
data	O
,	O
since	O
it	O
decorrelates	O
the	O
data	O
during	O
the	O
training	O
by	O
means	O
of	O
the	O
imposed	O
strong	O
sparsity	O
properties	O
of	O
the	O
output	O
target	O
.	O
	
Then	O
,	O
we	O
apply	O
the	O
system	O
to	O
retrieve	O
sparse	O
features	O
of	O
patches	O
covering	O
the	O
input	O
image	O
,	O
pool	O
them	O
into	O
4	O
quadrants	O
and	O
finally	O
train	O
a	O
SVM	B-Method
for	O
classification	B-Task
purposes	I-Task
.	O
	
We	O
tune	O
the	O
SVM	B-Method
parameter	I-Method
using	O
5	B-Method
-	I-Method
fold	I-Method
cross	I-Method
-	I-Method
validation	I-Method
.	O
	
As	O
in	O
,	O
we	O
use	O
a	O
receptive	O
field	O
of	O
10x10	O
pixels	O
and	O
a	O
stride	O
of	O
1	O
.	O
	
The	O
number	O
of	O
outputs	O
is	O
set	O
to	O
for	O
fair	O
comparison	O
with	O
the	O
other	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
.	O
	
We	O
also	O
provide	O
the	O
results	O
of	O
our	O
method	O
with	O
sign	O
split	O
(	O
x	O
,	O
using	O
and	O
for	O
encoding	O
as	O
in	O
)	O
and	O
using	O
the	O
sparse	B-Method
coding	I-Method
(	I-Method
SC	I-Method
)	I-Method
encoder	I-Method
,	O
which	O
found	O
to	O
be	O
the	O
best	O
when	O
small	O
number	O
of	O
labeled	O
data	O
is	O
available	O
.	O
	
For	O
this	O
encoder	O
,	O
we	O
searched	O
over	O
the	O
same	O
set	O
of	O
parameter	O
values	O
as	O
,	O
i.e.	O
,	O
.	O
	
The	O
parameter	O
is	O
tuned	O
to	O
consider	O
the	O
use	O
of	O
sparse	B-Method
coding	I-Method
as	O
encoder	B-Method
after	O
the	O
training	O
and	O
,	O
thus	O
,	O
does	O
not	O
belong	O
to	O
the	O
method	O
that	O
we	O
propose	O
.	O
	
Table	O
[	O
reference	O
]	O
summarizes	O
the	O
results	O
obtained	O
on	O
this	O
dataset	O
compared	O
to	O
other	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
.	O
	
When	O
pairing	O
each	O
training	O
method	O
with	O
its	O
associated	O
natural	B-Method
encoding	I-Method
,	O
EPLS	B-Method
outperforms	O
all	O
the	O
other	O
methods	O
.	O
	
When	O
pairing	O
the	O
training	B-Method
methods	I-Method
with	O
sparse	B-Method
coding	I-Method
,	O
EPLS	B-Method
outperforms	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
best	O
performer	O
in	O
single	B-Method
layer	I-Method
networks	I-Method
as	O
well	O
,	O
achieving	O
accuracy	B-Metric
.	O
	
Moreover	O
,	O
the	O
standard	O
deviation	O
of	O
the	O
folds	O
is	O
lower	O
than	O
the	O
one	O
provided	O
by	O
OMP	B-Method
-	I-Method
1	I-Method
with	I-Method
sparse	I-Method
coding	I-Method
encoding	I-Method
.	O
	
Results	O
are	O
even	O
more	O
impressive	O
if	O
we	O
compare	O
them	O
to	O
meta	B-Method
-	I-Method
parameter	I-Method
free	I-Method
algorithms	I-Method
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
a	O
subset	O
of	O
100	O
randomly	O
selected	O
bases	O
learned	O
by	O
our	O
method	O
,	O
10x10	O
pixel	O
receptive	O
field	O
and	O
a	O
system	O
of	O
outputs	O
.	O
	
As	O
shown	O
in	O
the	O
figure	O
,	O
the	O
method	O
learns	O
not	O
only	O
common	O
bases	O
such	O
as	O
oriented	O
edges	O
/	O
ridges	O
in	O
many	O
directions	O
and	O
colors	O
but	O
also	O
corner	B-Method
detectors	I-Method
,	O
tri	B-Method
-	I-Method
banded	I-Method
colored	I-Method
filters	I-Method
,	O
center	O
surrounds	O
and	O
Laplacian	B-Method
of	I-Method
Gaussians	I-Method
among	O
others	O
.	O
	
This	O
suggests	O
that	O
enforcing	O
lifetime	O
sparsity	O
helps	O
the	O
system	O
to	O
learn	O
a	O
set	O
of	O
complex	O
,	O
rich	O
and	O
diversified	O
bases	O
.	O
	
section	O
:	O
Computational	B-Metric
complexity	I-Metric
	
The	O
EPLS	B-Method
algorithm	I-Method
requires	O
the	O
computation	O
of	O
,	O
which	O
has	O
cost	O
,	O
and	O
therefore	O
scales	O
linearly	O
on	O
both	O
and	O
.	O
	
Since	O
we	O
can	O
use	O
vSGD	B-Method
for	O
optimization	B-Task
,	O
the	O
method	O
scales	O
linearly	O
on	O
given	O
a	O
fixed	O
number	O
of	O
epochs	O
.	O
	
Finally	O
,	O
applying	O
the	O
activation	B-Method
function	I-Method
,	O
the	O
cost	O
of	O
computing	O
the	O
derivative	O
is	O
linear	O
with	O
,	O
since	O
we	O
use	O
a	O
closed	O
form	O
for	O
.	O
	
The	O
memory	B-Metric
complexity	I-Metric
is	O
related	O
to	O
the	O
mini	O
-	O
batch	O
size	O
.	O
	
Consequently	O
,	O
the	O
method	O
can	O
scale	O
gracefully	O
to	O
very	O
large	O
datasets	O
:	O
theoretically	O
,	O
it	O
requires	O
to	O
store	O
in	O
memory	O
the	O
mini	O
-	O
batch	O
input	O
data	O
(	O
elements	O
)	O
,	O
output	O
(	O
elements	O
)	O
,	O
target	O
(	O
elements	O
)	O
and	O
the	O
system	O
parameters	O
to	O
optimize	O
(	O
elements	O
)	O
;	O
a	O
total	O
amount	O
of	O
elements	O
.	O
	
section	O
:	O
Discussion	O
	
Our	O
results	O
show	O
that	O
simultaneously	O
enforcing	O
both	O
population	O
and	O
lifetime	O
sparsity	O
helps	O
in	O
learning	O
discriminative	B-Task
dictionaries	I-Task
,	O
which	O
reflect	O
in	O
better	O
performance	O
,	O
especially	O
when	O
compared	O
to	O
meta	B-Method
-	I-Method
parameter	I-Method
free	I-Method
methods	I-Method
.	O
	
Experiments	O
suggest	O
that	O
our	O
algorithm	O
is	O
able	O
to	O
extract	O
features	O
that	O
generalize	O
well	O
on	O
unseen	O
data	O
.	O
	
When	O
comparing	O
the	O
performance	O
STL	B-Material
-	I-Material
10	I-Material
dataset	I-Material
,	O
our	O
algorithm	O
outperforms	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
best	O
performers	O
.	O
	
Results	O
suggest	O
that	O
our	O
algorithm	O
helps	O
the	O
classifier	B-Method
in	O
generalizing	O
with	O
a	O
few	O
training	O
examples	O
(	O
of	O
the	O
dataset	O
)	O
,	O
gaining	O
accuracy	B-Metric
w.r.t	O
.	O
	
the	O
state	O
-	O
of	O
-	O
the	O
art	O
best	O
performer	O
(	O
OMP	B-Method
-	I-Method
1	I-Method
paired	O
with	O
sparse	B-Method
coding	I-Method
)	O
with	O
a	O
lower	O
standard	O
deviation	O
across	O
folds	O
,	O
suggesting	O
more	O
robustness	O
to	O
variations	O
in	O
the	O
training	O
folds	O
.	O
	
It	O
is	O
important	O
to	O
highlight	O
that	O
OMP	B-Method
-	I-Method
1	I-Method
can	O
be	O
seen	O
as	O
a	O
special	O
case	O
of	O
our	O
algorithm	O
,	O
where	O
the	O
activation	O
function	O
is	O
and	O
lifetime	O
sparsity	O
is	O
not	O
taken	O
into	O
account	O
in	O
the	O
optimization	B-Task
process	I-Task
(	O
potentially	O
leading	O
to	O
dead	O
outputs	O
)	O
.	O
	
Our	O
algorithm	O
has	O
several	O
advantages	O
over	O
OMP	B-Method
-	I-Method
1	I-Method
:	O
(	O
1	O
)	O
It	O
can	O
use	O
any	O
activation	B-Method
function	I-Method
;	O
(	O
2	O
)	O
by	O
enforcing	O
lifetime	B-Method
sparsity	I-Method
it	O
does	O
not	O
suffer	O
of	O
the	O
dead	B-Task
output	I-Task
problem	I-Task
,	O
thus	O
not	O
requiring	O
ad	O
-	O
hoc	O
tricks	O
to	O
avoid	O
it	O
;	O
(	O
3	O
)	O
it	O
does	O
not	O
require	O
whitening	O
,	O
which	O
can	O
be	O
a	O
problem	O
if	O
the	O
input	O
dimensionality	O
is	O
large	O
.	O
	
With	O
our	O
proposal	O
,	O
we	O
advance	O
in	O
the	O
meta	O
-	O
parameter	O
free	O
line	O
of	O
ICA	B-Method
and	O
sparse	B-Method
filtering	I-Method
.	O
	
It	O
is	O
clear	O
that	O
the	O
advantage	O
of	O
sparse	B-Method
filtering	I-Method
over	O
ICA	B-Method
comes	O
from	O
removing	O
the	O
orthogonality	O
constraint	O
,	O
and	O
imposing	O
some	O
sort	O
of	O
“	O
competition	O
”	O
between	O
outputs	O
,	O
which	O
also	O
permits	O
overcomplete	B-Method
representations	I-Method
.	O
	
Following	O
this	O
spirit	O
,	O
our	O
algorithm	O
imposes	O
an	O
even	O
more	O
strict	O
form	O
of	O
competition	O
to	O
prevent	O
dead	O
outputs	O
by	O
means	O
of	O
Strong	O
Lifetime	O
Sparsity	O
and	O
confirms	O
the	O
trend	O
of	O
that	O
data	B-Task
reconstruction	I-Task
seems	O
not	O
so	O
important	O
if	O
the	O
goal	O
is	O
to	O
have	O
a	O
discriminative	B-Method
sparse	I-Method
system	I-Method
.	O
	
Last	O
and	O
most	O
importantly	O
,	O
it	O
is	O
worth	O
highlighting	O
five	O
interesting	O
properties	O
of	O
the	O
EPLS	B-Method
algorithm	I-Method
.	O
	
First	O
,	O
the	O
method	O
is	O
meta	O
-	O
parameter	O
free	O
,	O
which	O
highly	O
simplifies	O
the	O
training	B-Task
process	I-Task
for	O
practitioners	B-Task
,	O
especially	O
when	O
used	O
as	O
a	O
greedy	B-Method
pre	I-Method
-	I-Method
training	I-Method
method	I-Method
in	O
deep	B-Method
architectures	I-Method
.	O
	
Second	O
,	O
the	O
method	O
is	O
fast	O
and	O
scales	O
linearly	O
with	O
the	O
number	O
of	O
training	O
samples	O
and	O
the	O
input	O
/	O
output	O
dimensionalities	O
.	O
	
Third	O
,	O
EPLS	B-Method
is	O
easy	O
to	O
implement	O
.	O
	
We	O
implemented	O
the	O
EPLS	B-Method
in	O
Algorithm	O
[	O
reference	O
]	O
in	O
less	O
than	O
50	O
lines	O
of	O
C	O
code	O
.	O
	
The	O
mini	B-Method
-	I-Method
batch	I-Method
vSGD	I-Method
is	O
a	O
general	B-Method
purpose	I-Method
optimizer	I-Method
;	O
our	O
Matlab	B-Method
implementation	I-Method
of	O
vSGD	B-Method
plus	O
the	O
EPLS	B-Method
mex	I-Method
source	I-Method
will	O
be	O
publicly	O
available	O
after	O
publication	O
.	O
	
Fourth	O
,	O
the	O
proposed	O
learning	B-Method
strategy	I-Method
is	O
not	O
limited	O
to	O
perceptrons	B-Method
.	O
	
Fifth	O
,	O
there	O
is	O
an	O
interest	O
in	O
the	O
literature	O
in	O
avoiding	O
redundancy	O
in	O
the	O
image	B-Task
representation	I-Task
by	O
using	O
the	O
algorithms	O
in	O
a	O
convolutional	B-Method
fashion	I-Method
.	O
	
For	O
this	O
purpose	O
,	O
the	O
EPLS	B-Method
can	O
be	O
slightly	O
modified	O
to	O
apply	O
the	O
procedure	O
to	O
a	O
whole	O
image	O
at	O
once	O
and	O
consider	O
the	O
mini	O
-	O
batch	O
size	O
to	O
be	O
the	O
image	O
divided	O
into	O
patches	O
.	O
	
This	O
aspect	O
is	O
not	O
considered	O
in	O
the	O
paper	O
and	O
is	O
left	O
for	O
future	O
investigation	O
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
paper	O
,	O
we	O
introduced	O
the	O
Enforcing	B-Method
Population	I-Method
and	I-Method
Lifetime	I-Method
Sparsity	I-Method
method	I-Method
.	O
	
The	O
algorithm	O
provides	O
a	O
meta	O
-	O
parameter	O
free	O
,	O
off	O
-	O
the	O
-	O
shelf	O
,	O
simple	O
and	O
computationally	O
efficient	O
approach	O
for	O
unsupervised	B-Method
sparse	I-Method
feature	I-Method
learning	I-Method
.	O
	
It	O
seeks	O
both	O
lifetime	O
and	O
population	O
sparsity	O
in	O
an	O
explicit	O
way	O
in	O
order	O
to	O
learn	O
discriminative	O
features	O
,	O
thus	O
preventing	O
dead	O
outputs	O
.	O
	
Results	O
show	O
that	O
the	O
method	O
significantly	O
outperforms	O
all	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
on	O
STL	B-Material
-	I-Material
10	I-Material
dataset	I-Material
with	O
lower	O
standard	O
deviation	O
across	O
folds	O
,	O
suggesting	O
more	O
robustness	O
across	O
training	O
sets	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Effective	O
LSTMs	B-Method
for	O
Target	B-Task
-	I-Task
Dependent	I-Task
Sentiment	I-Task
Classification	I-Task
	
Target	B-Task
-	I-Task
dependent	I-Task
sentiment	I-Task
classification	I-Task
remains	O
a	O
challenge	O
:	O
modeling	O
the	O
semantic	O
relatedness	O
of	O
a	O
target	O
with	O
its	O
context	O
words	O
in	O
a	O
sentence	O
.	O
	
Different	O
context	O
words	O
have	O
different	O
influences	O
on	O
determining	O
the	O
sentiment	O
polarity	O
of	O
a	O
sentence	O
towards	O
the	O
target	O
.	O
	
Therefore	O
,	O
it	O
is	O
desirable	O
to	O
integrate	O
the	O
connections	O
between	O
target	O
word	O
and	O
context	O
words	O
when	O
building	O
a	O
learning	B-Method
system	I-Method
.	O
	
In	O
this	O
paper	O
,	O
we	O
develop	O
two	O
target	B-Method
dependent	I-Method
long	I-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
(	O
LSTM	B-Method
)	O
models	O
,	O
where	O
target	O
information	O
is	O
automatically	O
taken	O
into	O
account	O
.	O
	
We	O
evaluate	O
our	O
methods	O
on	O
a	O
benchmark	O
dataset	O
from	O
Twitter	O
.	O
	
Empirical	O
results	O
show	O
that	O
modeling	O
sentence	B-Method
representation	I-Method
with	O
standard	O
LSTM	B-Method
does	O
not	O
perform	O
well	O
.	O
	
Incorporating	O
target	O
information	O
into	O
LSTM	B-Method
can	O
significantly	O
boost	O
the	O
classification	O
accuracy	B-Metric
.	O
	
The	O
target	O
-	O
dependent	O
LSTM	B-Method
models	O
achieve	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performances	O
without	O
using	O
syntactic	B-Method
parser	I-Method
or	O
external	O
sentiment	O
lexicons	O
.	O
	
section	O
:	O
Introduction	O
	
This	O
work	O
is	O
licensed	O
under	O
a	O
Creative	O
Commons	O
Attribution	O
4.0	O
International	O
License	O
.	O
	
License	O
details	O
:	O
	
Sentiment	B-Task
analysis	I-Task
,	O
also	O
known	O
as	O
opinion	B-Task
mining	I-Task
,	O
is	O
a	O
fundamental	O
task	O
in	O
natural	B-Task
language	I-Task
processing	I-Task
and	O
computational	B-Task
linguistics	I-Task
.	O
	
Sentiment	B-Task
analysis	I-Task
is	O
crucial	O
to	O
understanding	O
user	O
generated	O
text	O
in	O
social	O
networks	O
or	O
product	O
reviews	O
,	O
and	O
has	O
drawn	O
a	O
lot	O
of	O
attentions	O
from	O
both	O
industry	O
and	O
academic	O
communities	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
focus	O
on	O
target	B-Task
-	I-Task
dependent	I-Task
sentiment	I-Task
classification	I-Task
,	O
which	O
is	O
a	O
fundamental	O
and	O
extensively	O
studied	O
task	O
in	O
the	O
field	O
of	O
sentiment	B-Task
analysis	I-Task
.	O
	
Given	O
a	O
sentence	O
and	O
a	O
target	O
mention	O
,	O
the	O
task	O
calls	O
for	O
inferring	O
the	O
sentiment	O
polarity	O
(	O
e.g.	O
positive	O
,	O
negative	O
,	O
neutral	O
)	O
of	O
the	O
sentence	O
towards	O
the	O
target	O
.	O
	
For	O
example	O
,	O
let	O
us	O
consider	O
the	O
sentence	O
:	O
	
“	O
	
I	O
bought	O
a	O
new	O
camera	O
.	O
	
The	O
picture	O
quality	O
is	O
amazing	O
but	O
the	O
battery	O
life	O
is	O
too	O
short	O
”	O
.	O
	
If	O
the	O
target	O
string	O
is	O
picture	O
quality	O
,	O
the	O
expected	O
sentiment	O
polarity	O
is	O
“	O
positive	O
”	O
as	O
the	O
sentence	O
expresses	O
a	O
positive	O
opinion	O
towards	O
picture	O
quality	O
.	O
	
If	O
we	O
consider	O
the	O
target	O
as	O
battery	O
life	O
,	O
the	O
correct	O
sentiment	O
polarity	O
should	O
be	O
“	O
negative	O
”	O
.	O
	
Target	B-Task
-	I-Task
dependent	I-Task
sentiment	I-Task
classification	I-Task
is	O
typically	O
regarded	O
as	O
a	O
kind	O
of	O
text	B-Task
classification	I-Task
problem	I-Task
in	O
literature	O
.	O
	
Majority	O
of	O
existing	O
studies	O
build	O
sentiment	B-Method
classifiers	I-Method
with	O
supervised	B-Method
machine	I-Method
learning	I-Method
approach	I-Method
,	O
such	O
as	O
feature	B-Method
based	I-Method
Supported	I-Method
Vector	I-Method
Machine	I-Method
or	O
neural	B-Method
network	I-Method
approaches	I-Method
.	O
	
Despite	O
the	O
effectiveness	O
of	O
these	O
approaches	O
,	O
we	O
argue	O
that	O
target	B-Task
-	I-Task
dependent	I-Task
sentiment	I-Task
classification	I-Task
remains	O
a	O
challenge	O
:	O
how	O
to	O
effectively	O
model	O
the	O
semantic	O
relatedness	O
of	O
a	O
target	O
word	O
with	O
its	O
context	O
words	O
in	O
a	O
sentence	O
.	O
	
One	O
straight	O
forward	O
way	O
to	O
address	O
this	O
problem	O
is	O
to	O
manually	O
design	O
a	O
set	O
of	O
target	O
-	O
dependent	O
features	O
,	O
and	O
integrate	O
them	O
into	O
existing	O
feature	B-Method
-	I-Method
based	I-Method
SVM	I-Method
.	O
	
However	O
,	O
feature	B-Method
engineering	I-Method
is	O
labor	O
intensive	O
and	O
the	O
“	O
sparse	O
”	O
and	O
“	O
discrete	O
”	O
features	O
are	O
clumsy	O
in	O
encoding	O
side	O
information	O
like	O
target	O
-	O
context	O
relatedness	O
.	O
	
In	O
addition	O
,	O
a	O
person	O
asked	O
to	O
do	O
this	O
task	O
will	O
naturally	O
“	O
look	O
at	O
”	O
parts	O
of	O
relevant	O
context	O
words	O
which	O
are	O
helpful	O
to	O
determine	O
the	O
sentiment	O
polarity	O
of	O
a	O
sentence	O
towards	O
the	O
target	O
.	O
	
These	O
motivate	O
us	O
to	O
develop	O
a	O
powerful	O
neural	B-Method
network	I-Method
approach	I-Method
,	O
which	O
is	O
capable	O
of	O
learning	O
continuous	O
features	O
(	O
representations	O
)	O
without	O
feature	B-Method
engineering	I-Method
and	O
meanwhile	O
capturing	O
the	O
intricate	O
relatedness	O
between	O
target	O
and	O
context	O
words	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
present	O
neural	B-Method
network	I-Method
models	I-Method
to	O
deal	O
with	O
target	B-Task
-	I-Task
dependent	I-Task
sentiment	I-Task
classification	I-Task
.	O
	
The	O
approach	O
is	O
an	O
extension	O
on	O
long	B-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
(	O
LSTM	B-Method
)	O
by	O
incorporating	O
target	O
information	O
.	O
	
Such	O
target	O
-	O
dependent	O
LSTM	B-Method
approach	O
models	O
the	O
relatedness	O
of	O
a	O
target	O
word	O
with	O
its	O
context	O
words	O
,	O
and	O
selects	O
the	O
relevant	O
parts	O
of	O
contexts	O
to	O
infer	O
the	O
sentiment	O
polarity	O
towards	O
the	O
target	O
.	O
	
The	O
model	O
could	O
be	O
trained	O
in	O
an	O
end	O
-	O
to	O
-	O
end	O
way	O
with	O
standard	O
backpropagation	B-Method
,	O
where	O
the	O
loss	O
function	O
is	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
error	I-Metric
of	O
supervised	B-Method
sentiment	I-Method
classification	I-Method
.	O
	
We	O
apply	O
the	O
neural	B-Method
model	I-Method
to	O
target	B-Task
-	I-Task
dependent	I-Task
sentiment	I-Task
classification	I-Task
on	O
a	O
benchmark	O
dataset	O
.	O
	
We	O
compare	O
with	O
feature	B-Method
-	I-Method
based	I-Method
SVM	I-Method
,	O
adaptive	B-Method
recursive	I-Method
neural	I-Method
network	I-Method
and	O
lexicon	B-Method
-	I-Method
enhanced	I-Method
neural	I-Method
network	I-Method
.	O
	
Empirical	O
results	O
show	O
that	O
the	O
proposed	O
approach	O
without	O
using	O
syntactic	B-Method
parser	I-Method
or	O
external	O
sentiment	O
lexicon	O
obtains	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
classification	O
accuracy	B-Metric
.	O
	
In	O
addition	O
,	O
we	O
find	O
that	O
modeling	O
sentence	O
with	O
standard	O
LSTM	B-Method
does	O
not	O
perform	O
well	O
on	O
this	O
target	B-Task
-	I-Task
dependent	I-Task
task	I-Task
.	O
	
Integrating	O
target	O
information	O
into	O
LSTM	B-Method
could	O
significantly	O
improve	O
the	O
classification	O
accuracy	B-Metric
.	O
	
section	O
:	O
The	O
Approach	O
	
We	O
describe	O
the	O
proposed	O
approach	O
for	O
target	B-Task
-	I-Task
dependent	I-Task
sentiment	I-Task
classification	I-Task
in	O
this	O
section	O
.	O
	
We	O
first	O
present	O
a	O
basic	O
long	B-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
(	O
LSTM	B-Method
)	O
approach	O
,	O
which	O
models	O
the	O
semantic	B-Method
representation	I-Method
of	O
a	O
sentence	O
without	O
considering	O
the	O
target	O
word	O
being	O
evaluated	O
.	O
	
Afterwards	O
,	O
we	O
extend	O
LSTM	B-Method
by	O
considering	O
the	O
target	O
word	O
,	O
obtaining	O
the	O
Target	B-Method
-	I-Method
Dependent	I-Method
Long	I-Method
Short	I-Method
-	I-Method
Term	I-Method
Memory	I-Method
(	O
TD	B-Method
-	I-Method
LSTM	I-Method
)	O
model	O
.	O
	
Finally	O
,	O
we	O
extend	O
TD	B-Method
-	I-Method
LSTM	I-Method
with	O
target	O
connection	O
,	O
where	O
the	O
semantic	O
relatedness	O
of	O
target	O
with	O
its	O
context	O
words	O
are	O
incorporated	O
.	O
	
subsection	O
:	O
Long	B-Method
Short	I-Method
-	I-Method
Term	I-Method
Memory	I-Method
(	O
LSTM	B-Method
)	O
	
In	O
this	O
part	O
,	O
we	O
describe	O
a	O
long	B-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
(	O
LSTM	B-Method
)	O
model	O
for	O
target	B-Task
-	I-Task
dependent	I-Task
sentiment	I-Task
classification	I-Task
.	O
	
It	O
is	O
a	O
basic	O
version	O
of	O
our	O
approach	O
.	O
	
In	O
this	O
setting	O
,	O
the	O
target	O
to	O
be	O
evaluated	O
is	O
ignored	O
so	O
that	O
the	O
task	O
is	O
considered	O
in	O
a	O
target	O
independent	O
way	O
.	O
	
We	O
use	O
LSTM	B-Method
as	O
it	O
is	O
a	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performer	O
for	O
semantic	B-Task
composition	I-Task
in	O
the	O
area	O
of	O
sentiment	B-Task
analysis	I-Task
.	O
	
It	O
is	O
capable	O
of	O
computing	O
the	O
representation	O
of	O
a	O
longer	O
expression	O
(	O
e.g.	O
a	O
sentence	O
)	O
from	O
the	O
representation	O
of	O
its	O
children	O
with	O
multi	O
levels	O
of	O
abstraction	O
.	O
	
The	O
sentence	B-Method
representation	I-Method
can	O
be	O
naturally	O
considered	O
as	O
the	O
feature	O
to	O
predict	O
the	O
sentiment	B-Task
polarity	I-Task
of	I-Task
sentence	I-Task
.	O
	
Specifically	O
,	O
each	O
word	O
is	O
represented	O
as	O
a	O
low	O
dimensional	O
,	O
continuous	O
and	O
real	O
-	O
valued	O
vector	O
,	O
also	O
known	O
as	O
word	B-Method
embedding	I-Method
.	O
	
All	O
the	O
word	O
vectors	O
are	O
stacked	O
in	O
a	O
word	B-Method
embedding	I-Method
matrix	I-Method
,	O
where	O
is	O
the	O
dimension	O
of	O
word	O
vector	O
and	O
is	O
vocabulary	O
size	O
.	O
	
In	O
this	O
work	O
,	O
we	O
pre	O
-	O
train	O
the	O
values	O
of	O
word	O
vectors	O
from	O
text	O
corpus	O
with	O
embedding	B-Method
learning	I-Method
algorithms	I-Method
to	O
make	O
better	O
use	O
of	O
semantic	O
and	O
grammatical	O
associations	O
of	O
words	O
.	O
	
We	O
use	O
LSTM	B-Method
to	O
compute	O
the	O
vector	O
of	O
a	O
sentence	O
from	O
the	O
vectors	O
of	O
words	O
it	O
contains	O
,	O
an	O
illustration	O
of	O
the	O
model	O
is	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
LSTM	B-Method
is	O
a	O
kind	O
of	O
recurrent	B-Method
neural	I-Method
network	I-Method
(	O
RNN	B-Method
)	O
,	O
which	O
is	O
capable	O
of	O
mapping	O
vectors	O
of	O
words	O
with	O
variable	O
length	O
to	O
a	O
fixed	O
-	O
length	O
vector	O
by	O
recursively	O
transforming	O
current	O
word	O
vector	O
with	O
the	O
output	O
vector	O
of	O
the	O
previous	O
step	O
.	O
	
The	O
transition	O
function	O
of	O
standard	O
RNN	B-Method
is	O
a	O
linear	B-Method
layer	I-Method
followed	O
by	O
a	O
pointwise	B-Method
non	I-Method
-	I-Method
linear	I-Method
layer	I-Method
such	O
as	O
hyperbolic	B-Method
tangent	I-Method
function	I-Method
(	O
)	O
.	O
	
where	O
,	O
,	O
is	O
dimension	O
of	O
word	O
vector	O
.	O
	
However	O
,	O
standard	O
RNN	B-Method
suffers	O
the	O
problem	O
of	O
gradient	B-Task
vanishing	I-Task
or	O
exploding	B-Task
,	O
where	O
gradients	O
may	O
grow	O
or	O
decay	O
exponentially	O
over	O
long	O
sequences	O
.	O
	
Many	O
researchers	O
use	O
a	O
more	O
sophisticated	O
and	O
powerful	O
LSTM	B-Method
cell	I-Method
as	O
the	O
transition	O
function	O
,	O
so	O
that	O
long	O
-	O
distance	O
semantic	O
correlations	O
in	O
a	O
sequence	O
could	O
be	O
better	O
modeled	O
.	O
	
Compared	O
with	O
standard	O
RNN	B-Method
,	O
LSTM	B-Method
cell	I-Method
contains	O
three	O
additional	O
neural	O
gates	O
:	O
an	O
input	O
gate	O
,	O
a	O
forget	O
gate	O
and	O
an	O
output	O
gate	O
.	O
	
These	O
gates	O
adaptively	O
remember	O
input	O
vector	O
,	O
forget	O
previous	O
history	O
and	O
generate	O
output	O
vector	O
.	O
	
LSTM	B-Method
cell	I-Method
is	O
calculated	O
as	O
follows	O
.	O
	
where	O
stands	O
for	O
element	O
-	O
wise	O
multiplication	O
,	O
is	O
sigmoid	O
function	O
,	O
,	O
,	O
,	O
,	O
,	O
are	O
the	O
parameters	O
of	O
input	O
,	O
forget	O
and	O
output	O
gates	O
.	O
	
After	O
calculating	O
the	O
hidden	O
vector	O
of	O
each	O
position	O
,	O
we	O
regard	O
the	O
last	O
hidden	O
vector	O
as	O
the	O
sentence	B-Method
representation	I-Method
.	O
	
We	O
feed	O
it	O
to	O
a	O
linear	B-Method
layer	I-Method
whose	O
output	O
length	O
is	O
class	O
number	O
,	O
and	O
add	O
a	O
layer	O
to	O
output	O
the	O
probability	O
of	O
classifying	O
the	O
sentence	O
as	O
positive	O
,	O
negative	O
or	O
neutral	O
.	O
	
Softmax	O
function	O
is	O
calculated	O
as	O
follows	O
,	O
where	O
is	O
the	O
number	O
of	O
sentiment	O
categories	O
.	O
	
subsection	O
:	O
Target	B-Method
-	I-Method
Dependent	I-Method
LSTM	I-Method
(	O
TD	B-Method
-	I-Method
LSTM	I-Method
)	O
	
The	O
aforementioned	O
LSTM	B-Method
model	I-Method
solves	O
target	B-Task
-	I-Task
dependent	I-Task
sentiment	I-Task
classification	I-Task
in	O
a	O
target	O
-	O
independent	O
way	O
.	O
	
That	O
is	O
to	O
say	O
,	O
the	O
feature	B-Method
representation	I-Method
used	O
for	O
sentiment	B-Task
classification	I-Task
remains	O
the	O
same	O
without	O
considering	O
the	O
target	O
words	O
.	O
	
Let	O
us	O
again	O
take	O
“	O
	
I	O
bought	O
a	O
new	O
camera	O
.	O
	
The	O
picture	O
quality	O
is	O
amazing	O
but	O
the	O
battery	O
life	O
is	O
too	O
short	O
”	O
as	O
an	O
example	O
.	O
	
The	O
representations	O
of	O
this	O
sentence	O
with	O
regard	O
to	O
picture	B-Metric
quality	I-Metric
and	O
battery	B-Metric
life	I-Metric
are	O
identical	O
.	O
	
This	O
is	O
evidently	O
problematic	O
as	O
the	O
sentiment	O
polarity	O
labels	O
towards	O
these	O
two	O
targets	O
are	O
different	O
.	O
	
To	O
take	O
into	O
account	O
of	O
the	O
target	O
information	O
,	O
we	O
make	O
a	O
slight	O
modification	O
on	O
the	O
aforementioned	O
LSTM	B-Method
model	I-Method
and	O
introduce	O
a	O
target	B-Method
-	I-Method
dependent	I-Method
LSTM	I-Method
(	O
TD	B-Method
-	I-Method
LSTM	I-Method
)	O
in	O
this	O
subsection	O
.	O
	
The	O
basic	O
idea	O
is	O
to	O
model	O
the	O
preceding	O
and	O
following	O
contexts	O
surrounding	O
the	O
target	O
string	O
,	O
so	O
that	O
contexts	O
in	O
both	O
directions	O
could	O
be	O
used	O
as	O
feature	B-Method
representations	I-Method
for	O
sentiment	B-Task
classification	I-Task
.	O
	
We	O
believe	O
that	O
capturing	O
such	O
target	O
-	O
dependent	O
context	O
information	O
could	O
improve	O
the	O
accuracy	B-Metric
of	O
target	B-Task
-	I-Task
dependent	I-Task
sentiment	I-Task
classification	I-Task
.	O
	
Specifically	O
,	O
we	O
use	O
two	O
LSTM	B-Method
neural	O
networks	O
,	O
a	O
left	B-Method
one	I-Method
LSTM	I-Method
and	O
a	O
right	O
one	O
LSTM	B-Method
,	O
to	O
model	O
the	O
preceding	O
and	O
following	O
contexts	O
respectively	O
.	O
	
An	O
illustration	O
of	O
the	O
model	O
is	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
The	O
input	O
of	O
LSTM	B-Method
is	O
the	O
preceding	O
contexts	O
plus	O
target	O
string	O
,	O
and	O
the	O
input	O
of	O
LSTM	B-Method
is	O
the	O
following	O
contexts	O
plus	O
target	O
string	O
.	O
	
We	O
run	O
LSTM	B-Method
from	O
left	O
to	O
right	O
,	O
and	O
run	O
LSTM	B-Method
from	O
right	O
to	O
left	O
.	O
	
We	O
favor	O
this	O
strategy	O
as	O
we	O
believe	O
that	O
regarding	O
target	O
string	O
as	O
the	O
last	O
unit	O
could	O
better	O
utilize	O
the	O
semantics	O
of	O
target	O
string	O
when	O
using	O
the	O
composed	B-Method
representation	I-Method
for	O
sentiment	B-Task
classification	I-Task
.	O
	
Afterwards	O
,	O
we	O
concatenate	O
the	O
last	O
hidden	O
vectors	O
of	O
LSTM	B-Method
and	O
LSTM	B-Method
,	O
and	O
feed	O
them	O
to	O
a	O
layer	O
to	O
classify	O
the	O
sentiment	O
polarity	O
label	O
.	O
	
One	O
could	O
also	O
try	O
averaging	O
or	O
summing	O
the	O
last	O
hidden	O
vectors	O
of	O
LSTM	B-Method
and	O
LSTM	B-Method
as	O
alternatives	O
.	O
	
subsection	O
:	O
Target	B-Method
-	I-Method
Connection	I-Method
LSTM	I-Method
(	O
TC	B-Method
-	I-Method
LSTM	I-Method
)	O
	
Compared	O
with	O
LSTM	B-Method
model	I-Method
,	O
target	B-Method
-	I-Method
dependent	I-Method
LSTM	I-Method
(	O
TD	B-Method
-	I-Method
LSTM	I-Method
)	O
could	O
make	O
better	O
use	O
of	O
the	O
target	O
information	O
.	O
	
However	O
,	O
we	O
think	O
TD	B-Method
-	I-Method
LSTM	I-Method
is	O
still	O
not	O
good	O
enough	O
because	O
it	O
does	O
not	O
capture	O
the	O
interactions	O
between	O
target	O
word	O
and	O
its	O
contexts	O
.	O
	
Furthermore	O
,	O
a	O
person	O
asked	O
to	O
do	O
target	B-Task
-	I-Task
dependent	I-Task
sentiment	I-Task
classification	I-Task
will	O
select	O
the	O
relevant	O
context	O
words	O
which	O
are	O
helpful	O
to	O
determine	O
the	O
sentiment	O
polarity	O
of	O
a	O
sentence	O
towards	O
the	O
target	O
.	O
	
Based	O
on	O
the	O
consideration	O
mentioned	O
above	O
,	O
we	O
go	O
one	O
step	O
further	O
and	O
develop	O
a	O
target	O
-	O
connection	O
long	B-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
(	O
TC	B-Method
-	I-Method
LSTM	I-Method
)	O
.	O
	
This	O
model	O
extends	O
TD	B-Method
-	I-Method
LSTM	I-Method
by	O
incorporating	O
an	O
target	B-Method
connection	I-Method
component	I-Method
,	O
which	O
explicitly	O
utilizes	O
the	O
connections	O
between	O
target	O
word	O
and	O
each	O
context	O
word	O
when	O
composing	O
the	O
representation	O
of	O
a	O
sentence	O
.	O
	
An	O
overview	O
of	O
TC	B-Method
-	I-Method
LSTM	I-Method
is	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
The	O
input	O
of	O
TC	B-Method
-	I-Method
LSTM	I-Method
is	O
a	O
sentence	O
consisting	O
of	O
words	O
and	O
a	O
target	O
string	O
occurs	O
in	O
the	O
sentence	O
.	O
	
We	O
represent	O
target	O
as	O
because	O
a	O
target	O
could	O
be	O
a	O
word	O
sequence	O
of	O
variable	O
length	O
,	O
such	O
as	O
“	O
google	O
”	O
or	O
“	O
harry	O
potter	O
”	O
.	O
	
When	O
processing	O
a	O
sentence	O
,	O
we	O
split	O
it	O
into	O
three	O
components	O
:	O
target	O
words	O
,	O
preceding	O
context	O
words	O
and	O
following	O
context	O
words	O
.	O
	
We	O
obtain	O
target	O
vector	O
by	O
averaging	O
the	O
vectors	O
of	O
words	O
it	O
contains	O
,	O
which	O
has	O
been	O
proven	O
to	O
be	O
simple	O
and	O
effective	O
in	O
representing	O
named	O
entities	O
.	O
	
When	O
compute	O
the	O
hidden	O
vectors	O
of	O
preceding	O
and	O
following	O
context	O
words	O
,	O
we	O
use	O
two	O
separate	O
long	B-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
models	O
,	O
which	O
are	O
similar	O
with	O
the	O
strategy	O
used	O
in	O
TD	B-Method
-	I-Method
LSTM	I-Method
.	O
	
The	O
difference	O
is	O
that	O
in	O
TC	B-Method
-	I-Method
LSTM	I-Method
	
the	O
input	O
at	O
each	O
position	O
is	O
the	O
concatenation	O
of	O
word	O
embedding	O
and	O
target	O
vector	O
,	O
while	O
in	O
TD	B-Method
-	I-Method
LSTM	I-Method
the	O
input	O
at	O
each	O
position	O
	
only	O
includes	O
the	O
embedding	O
of	O
current	O
word	O
.	O
	
We	O
believe	O
that	O
TC	B-Method
-	I-Method
LSTM	I-Method
could	O
make	O
better	O
use	O
of	O
the	O
connection	O
between	O
target	O
and	O
each	O
context	O
word	O
when	O
building	O
the	O
representation	O
of	O
a	O
sentence	O
.	O
	
subsection	O
:	O
Model	B-Method
Training	I-Method
	
We	O
train	O
LSTM	B-Method
,	O
TD	B-Method
-	I-Method
LSTM	I-Method
and	O
TC	B-Method
-	I-Method
LSTM	I-Method
in	O
an	O
end	O
-	O
to	O
-	O
end	O
way	O
in	O
a	O
supervised	B-Method
learning	I-Method
framework	I-Method
.	O
	
The	O
loss	B-Metric
function	I-Metric
is	O
the	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
error	I-Metric
of	O
sentiment	B-Task
classification	I-Task
.	O
	
where	O
is	O
the	O
training	O
data	O
,	O
is	O
the	O
number	O
of	O
sentiment	O
categories	O
,	O
means	O
a	O
sentence	O
,	O
is	O
the	O
probability	O
of	O
predicting	O
as	O
class	O
given	O
by	O
the	O
layer	O
,	O
indicates	O
whether	O
class	O
is	O
the	O
correct	O
sentiment	O
category	O
,	O
whose	O
value	O
is	O
1	O
or	O
0	O
.	O
	
We	O
take	O
the	O
derivative	O
of	O
loss	O
function	O
through	O
back	B-Method
-	I-Method
propagation	I-Method
with	O
respect	O
to	O
all	O
parameters	O
,	O
and	O
update	O
parameters	O
with	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
.	O
	
section	O
:	O
Experiment	O
	
We	O
apply	O
the	O
proposed	O
method	O
to	O
target	B-Task
-	I-Task
dependent	I-Task
sentiment	I-Task
classification	I-Task
to	O
evaluate	O
its	O
effectiveness	O
.	O
	
We	O
describe	O
experimental	O
setting	O
and	O
empirical	O
results	O
in	O
this	O
section	O
.	O
	
subsection	O
:	O
Experimental	O
Settings	O
	
We	O
conduct	O
experiment	O
in	O
a	O
supervised	B-Task
setting	I-Task
on	O
a	O
benchmark	O
dataset	O
.	O
	
Each	O
instance	O
in	O
the	O
training	O
/	O
test	O
set	O
has	O
a	O
manually	O
labeled	O
sentiment	O
polarity	O
.	O
	
Training	O
set	O
contains	O
6	O
,	O
248	O
sentences	O
and	O
test	O
set	O
has	O
692	O
sentences	O
.	O
	
The	O
percentages	O
of	O
positive	O
,	O
negative	O
and	O
neutral	O
in	O
training	O
and	O
test	O
sets	O
are	O
both	O
25	O
%	O
,	O
25	O
%	O
,	O
50	O
%	O
.	O
	
We	O
train	O
the	O
model	O
on	O
training	O
set	O
,	O
and	O
evaluate	O
the	O
performance	O
on	O
test	O
set	O
.	O
	
Evaluation	B-Metric
metrics	I-Metric
are	O
accuracy	B-Metric
and	O
macro	B-Metric
-	I-Metric
F1	I-Metric
score	I-Metric
over	O
positive	O
,	O
negative	O
and	O
neutral	O
categories	O
.	O
	
subsection	O
:	O
Comparison	O
to	O
Other	O
Methods	O
	
We	O
compare	O
with	O
several	O
baseline	O
methods	O
,	O
including	O
:	O
	
In	O
SVM	B-Method
-	I-Method
indep	I-Method
,	O
SVM	B-Method
classifier	I-Method
is	O
built	O
with	O
target	O
-	O
independent	O
features	O
,	O
such	O
as	O
unigram	O
,	O
bigram	O
,	O
punctuations	O
,	O
emoticons	O
,	O
hashtags	O
,	O
the	O
numbers	O
of	O
positive	O
or	O
negative	O
words	O
in	O
General	O
Inquirer	O
sentiment	O
lexicon	O
.	O
	
In	O
SVM	B-Method
-	I-Method
dep	I-Method
,	O
target	O
-	O
dependent	O
features	O
are	O
also	O
concatenated	O
as	O
the	O
feature	B-Method
representation	I-Method
.	O
	
In	O
Recursive	B-Method
NN	I-Method
,	O
standard	O
Recursive	B-Method
neural	I-Method
network	I-Method
is	O
used	O
for	O
feature	B-Task
learning	I-Task
over	O
a	O
transfered	O
target	O
-	O
dependent	O
dependency	O
tree	O
.	O
	
AdaRNN	O
	
-	O
w	B-Method
/	I-Method
oE	I-Method
,	O
AdaRNN	B-Method
-	I-Method
w	I-Method
/	I-Method
E	I-Method
and	O
AdaRNN	B-Method
-	I-Method
comb	I-Method
are	O
different	O
variations	O
of	O
adaptive	B-Method
recursive	I-Method
neural	I-Method
network	I-Method
,	O
whose	O
composition	O
functions	O
are	O
adaptively	O
selected	O
according	O
to	O
the	O
inputs	O
.	O
	
In	O
Target	B-Method
-	I-Method
dep	I-Method
,	O
SVM	B-Method
classifier	I-Method
is	O
built	O
based	O
on	O
rich	O
target	O
-	O
independent	O
and	O
target	O
-	O
dependent	O
features	O
.	O
	
In	O
Target	B-Method
-	I-Method
dep	I-Method
+	I-Method
,	O
sentiment	O
lexicon	O
features	O
are	O
further	O
incorporated	O
.	O
	
The	O
neural	B-Method
models	I-Method
developed	O
in	O
this	O
paper	O
are	O
abbreviated	O
as	O
LSTM	B-Method
,	O
TD	B-Method
-	I-Method
LSTM	I-Method
and	O
TC	B-Method
-	I-Method
LSTM	I-Method
,	O
which	O
are	O
described	O
in	O
the	O
previous	O
section	O
.	O
	
We	O
use	O
100	O
-	O
dimensional	O
Glove	O
vectors	O
learned	O
from	O
Twitter	O
,	O
randomize	O
the	O
parameters	O
with	O
uniform	O
distribution	O
,	O
set	O
the	O
clipping	O
threshold	O
of	O
softmax	O
layer	O
as	O
200	O
and	O
set	O
learning	B-Metric
rate	I-Metric
as	O
0.01	O
.	O
	
Experimental	O
results	O
of	O
baseline	O
models	O
and	O
our	O
methods	O
are	O
given	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Comparing	O
between	O
SVM	B-Method
-	I-Method
indep	I-Method
and	O
SVM	B-Method
-	I-Method
dep	I-Method
,	O
we	O
can	O
find	O
that	O
incorporating	O
target	O
information	O
can	O
improve	O
the	O
classification	O
accuracy	B-Metric
of	O
a	O
basic	O
SVM	B-Method
classifier	I-Method
.	O
	
AdaRNN	B-Method
performs	O
better	O
than	O
feature	B-Method
based	I-Method
SVM	I-Method
by	O
making	O
use	O
of	O
dependency	O
parsing	O
information	O
and	O
tree	O
-	O
structured	O
semantic	O
composition	O
.	O
	
We	O
can	O
find	O
that	O
target	B-Task
-	I-Task
dep	I-Task
is	O
a	O
strong	O
performer	O
even	O
without	O
using	O
lexicon	O
features	O
.	O
	
It	O
benefits	O
from	O
rich	O
automatic	O
features	O
generated	O
from	O
word	B-Method
embeddings	I-Method
.	O
	
Among	O
LSTM	B-Method
based	O
models	O
described	O
in	O
this	O
paper	O
,	O
the	O
basic	O
LSTM	B-Method
approach	O
performs	O
worst	O
.	O
	
This	O
is	O
not	O
surprising	O
because	O
this	O
task	O
requires	O
understanding	O
target	O
-	O
dependent	O
text	O
semantics	O
,	O
while	O
the	O
basic	O
LSTM	B-Method
model	I-Method
does	O
not	O
capture	O
any	O
target	O
information	O
so	O
that	O
it	O
predicts	O
the	O
same	O
result	O
for	O
different	O
targets	O
in	O
a	O
sentence	O
.	O
	
TD	B-Method
-	I-Method
LSTM	I-Method
obtains	O
a	O
big	O
improvement	O
over	O
LSTM	B-Method
when	O
target	O
signals	O
are	O
taken	O
into	O
consideration	O
.	O
	
This	O
result	O
demonstrates	O
the	O
importance	O
of	O
target	O
information	O
for	O
target	B-Task
-	I-Task
dependent	I-Task
sentiment	I-Task
classification	I-Task
.	O
	
By	O
incorporating	O
target	B-Method
-	I-Method
connection	I-Method
mechanism	I-Method
,	O
TC	B-Method
-	I-Method
LSTM	I-Method
obtains	O
the	O
best	O
performances	O
and	O
outperforms	O
all	O
baseline	O
methods	O
in	O
term	O
of	O
classification	O
accuracy	B-Metric
.	O
	
Comparing	O
between	O
Target	O
-	O
dep	O
and	O
Target	O
-	O
dep	O
,	O
we	O
find	O
that	O
sentiment	O
lexicon	O
feature	O
could	O
further	O
improve	O
the	O
classification	O
accuracy	B-Metric
.	O
	
Our	O
final	O
model	O
TC	O
-	O
LSTM	B-Method
without	O
using	O
sentiment	O
lexicon	O
information	O
performs	O
comparably	O
with	O
Target	O
-	O
dep	O
.	O
	
We	O
believe	O
that	O
incorporation	O
lexicon	O
information	O
in	O
TC	B-Method
-	I-Method
LSTM	I-Method
could	O
get	O
further	O
improvement	O
.	O
	
We	O
leave	O
this	O
as	O
a	O
potential	O
future	O
work	O
.	O
	
subsection	O
:	O
Effects	O
of	O
Word	O
Embeddings	O
	
It	O
is	O
well	O
accepted	O
that	O
a	O
good	O
word	B-Method
embedding	I-Method
is	O
crucial	O
to	O
composing	O
a	O
powerful	O
text	B-Method
representation	I-Method
at	O
higher	O
level	O
.	O
	
We	O
therefore	O
study	O
the	O
effects	O
of	O
different	O
word	B-Method
embeddings	I-Method
on	O
LSTM	B-Method
,	O
TD	B-Method
-	I-Method
LSTM	I-Method
and	O
TC	B-Method
-	I-Method
LSTM	I-Method
in	O
this	O
part	O
.	O
	
Since	O
the	O
benchmark	O
dataset	O
from	O
comes	O
from	O
Twitter	O
,	O
we	O
compare	O
between	O
sentiment	B-Method
-	I-Method
specific	I-Method
word	I-Method
embedding	I-Method
(	O
SSWE	B-Method
)	O
and	O
Glove	B-Method
vectors	I-Method
.	O
	
All	O
these	O
word	O
vectors	O
are	O
50	O
-	O
dimensional	O
and	O
learned	O
from	O
Twitter	O
.	O
	
SSWE	B-Method
,	O
SSWE	B-Method
and	O
SSWE	B-Method
are	O
different	O
embedding	B-Method
learning	I-Method
algorithms	I-Method
introduced	O
in	O
.	O
	
SSWE	B-Method
and	O
SSWE	B-Method
learn	O
word	B-Method
embeddings	I-Method
by	O
only	O
using	O
sentiment	O
of	O
sentences	O
.	O
	
SSWE	B-Method
takes	O
into	O
account	O
of	O
sentiment	O
of	O
sentences	O
and	O
contexts	O
of	O
words	O
simultaneously	O
.	O
	
From	O
Figure	O
[	O
reference	O
]	O
,	O
we	O
can	O
find	O
that	O
SSWE	B-Method
and	O
SSWE	B-Method
perform	O
worse	O
than	O
SSWE	B-Method
,	O
which	O
is	O
consistent	O
with	O
the	O
results	O
reported	O
on	O
target	B-Task
-	I-Task
independent	I-Task
sentiment	I-Task
classification	I-Task
of	O
tweets	O
.	O
	
This	O
shows	O
the	O
importance	O
of	O
context	O
information	O
for	O
word	B-Task
embedding	I-Task
learning	I-Task
as	O
both	O
SSWE	B-Method
and	O
SSWE	B-Method
do	O
not	O
encode	O
any	O
word	O
contexts	O
.	O
	
Glove	B-Method
and	O
SSWE	B-Method
perform	O
comparably	O
,	O
which	O
indicates	O
the	O
importance	O
of	O
global	O
context	O
for	O
estimating	O
a	O
good	O
word	B-Method
representation	I-Method
.	O
	
In	O
addition	O
,	O
the	O
target	B-Method
connection	I-Method
model	I-Method
TC	I-Method
-	I-Method
LSTM	I-Method
performs	O
best	O
when	O
considering	O
a	O
specific	O
word	B-Method
embedding	I-Method
.	O
	
We	O
compare	O
between	O
Glove	O
vectors	O
with	O
different	O
dimensions	O
(	O
50	O
/	O
100	O
/	O
200	O
)	O
.	O
	
Classification	O
accuracy	B-Metric
and	O
time	B-Metric
cost	I-Metric
are	O
given	O
in	O
Figure	O
[	O
reference	O
]	O
and	O
Table	O
[	O
reference	O
]	O
,	O
respectively	O
.	O
	
We	O
can	O
find	O
that	O
100	O
-	O
dimensional	O
word	O
vectors	O
perform	O
better	O
than	O
50	O
-	O
dimensional	O
word	O
vectors	O
,	O
while	O
200	O
-	O
dimensional	O
word	O
vectors	O
do	O
not	O
show	O
significant	O
improvements	O
.	O
	
Furthermore	O
,	O
TD	B-Method
-	I-Method
LSTM	I-Method
and	O
LSTM	B-Method
have	O
similar	O
time	B-Metric
cost	I-Metric
,	O
while	O
TD	B-Method
-	I-Method
LSTM	I-Method
gets	O
higher	O
classification	O
accuracy	B-Metric
as	O
target	O
information	O
is	O
incorporated	O
.	O
	
TC	B-Method
-	I-Method
LSTM	I-Method
performs	O
slightly	O
better	O
than	O
TD	B-Method
-	I-Method
LSTM	I-Method
while	O
at	O
the	O
cost	O
of	O
longer	O
training	B-Metric
time	I-Metric
because	O
the	O
parameter	O
number	O
of	O
TC	B-Method
-	I-Method
LSTM	I-Method
is	O
larger	O
.	O
	
subsection	O
:	O
Case	O
Study	O
	
In	O
this	O
section	O
,	O
we	O
explore	O
to	O
what	O
extent	O
the	O
target	O
-	O
dependent	O
LSTM	B-Method
models	O
including	O
TD	B-Method
-	I-Method
LSTM	I-Method
and	O
TC	B-Method
-	I-Method
LSTM	I-Method
improve	O
the	O
performance	O
of	O
a	O
basic	O
LSTM	B-Method
model	I-Method
.	O
	
In	O
Table	O
[	O
reference	O
]	O
,	O
we	O
list	O
some	O
examples	O
whose	O
polarity	O
labels	O
are	O
incorrectly	O
inferred	O
by	O
LSTM	B-Method
but	O
correctly	O
predicted	O
by	O
both	O
TD	B-Method
-	I-Method
LSTM	I-Method
and	O
TC	B-Method
-	I-Method
LSTM	I-Method
.	O
	
We	O
observe	O
that	O
LSTM	B-Method
model	I-Method
prefers	O
to	O
assigning	O
the	O
polarity	O
of	O
the	O
entire	O
sentence	O
while	O
ignoring	O
the	O
target	O
to	O
be	O
evaluated	O
.	O
	
TD	B-Method
-	I-Method
LSTM	I-Method
and	O
TC	B-Method
-	I-Method
LSTM	I-Method
could	O
take	O
into	O
account	O
of	O
target	O
information	O
to	O
some	O
extend	O
.	O
	
For	O
example	O
,	O
in	O
the	O
2nd	O
example	O
the	O
opinion	O
holder	O
expresses	O
a	O
negative	O
opinion	O
about	O
his	O
work	O
,	O
but	O
holds	O
a	O
neutral	O
sentiment	O
towards	O
the	O
target	O
“	O
lindsay	O
lohan	O
”	O
.	O
	
In	O
the	O
last	O
example	O
,	O
the	O
whole	O
sentence	O
expresses	O
a	O
neutral	O
sentiment	O
while	O
it	O
holds	O
a	O
positive	O
opinion	O
towards	O
“	O
google	O
”	O
.	O
	
We	O
analyse	O
the	O
error	O
cases	O
that	O
both	O
TD	B-Method
-	I-Method
LSTM	I-Method
and	O
TC	B-Method
-	I-Method
LSTM	I-Method
can	O
not	O
well	O
handle	O
,	O
and	O
find	O
that	O
85.4	O
%	O
of	O
the	O
misclassified	O
examples	O
relate	O
to	O
neutral	O
category	O
.	O
	
The	O
positive	O
instances	O
are	O
rarely	O
misclassified	O
as	O
negative	O
,	O
and	O
vice	O
versa	O
.	O
	
A	O
example	O
of	O
errors	O
is	O
:	O
“	O
freaky	O
friday	O
on	O
television	O
reminding	O
me	O
to	O
think	O
wtf	O
happened	O
to	O
lindsay	O
lohan	O
,	O
she	O
was	O
such	O
a	O
terrific	O
actress	O
,	O
+	O
my	O
huge	O
crush	O
on	O
haley	O
hudson	O
.	O
	
”	O
,	O
which	O
is	O
incorrectly	O
predicted	O
as	O
positive	O
towards	O
target	O
	
“	O
indsay	O
lohan	O
”	O
in	O
both	O
TD	B-Method
-	I-Method
LSTM	I-Method
and	O
TC	B-Method
-	I-Method
LSTM	I-Method
.	O
	
subsection	O
:	O
Discussion	O
	
In	O
order	O
to	O
capture	O
the	O
semantic	O
relatedness	O
between	O
target	O
and	O
context	O
words	O
,	O
we	O
extend	O
TD	B-Method
-	I-Method
LSTM	I-Method
by	O
adding	O
a	O
target	B-Method
connection	I-Method
component	I-Method
.	O
	
One	O
could	O
also	O
try	O
other	O
extensions	O
to	O
capture	O
the	O
connection	O
between	O
target	O
and	O
context	O
words	O
.	O
	
For	O
example	O
,	O
we	O
also	O
tried	O
an	O
attention	B-Method
-	I-Method
based	I-Method
LSTM	I-Method
model	I-Method
,	O
which	O
is	O
inspired	O
by	O
the	O
recent	O
success	O
of	O
attention	B-Method
-	I-Method
based	I-Method
neural	I-Method
network	I-Method
in	O
machine	B-Task
translation	I-Task
and	O
document	B-Task
encoding	I-Task
.	O
	
We	O
implement	O
the	O
soft	B-Method
-	I-Method
attention	I-Method
mechanism	I-Method
to	O
enhance	O
TD	B-Method
-	I-Method
LSTM	I-Method
.	O
	
We	O
incorporate	O
two	O
attention	B-Method
layers	I-Method
for	O
preceding	B-Method
LSTM	I-Method
and	O
following	B-Method
LSTM	I-Method
,	O
respectively	O
.	O
	
The	O
output	O
vector	O
for	O
each	O
attention	B-Method
layer	I-Method
is	O
the	O
weighted	O
average	O
among	O
hidden	O
vectors	O
of	O
LSTM	B-Method
,	O
where	O
the	O
weight	O
of	O
each	O
hidden	O
vector	O
is	O
calculated	O
with	O
a	O
feedforward	B-Method
neural	I-Method
network	I-Method
.	O
	
The	O
outputs	O
of	O
preceding	B-Method
and	I-Method
following	I-Method
attention	I-Method
models	I-Method
are	O
concatenated	O
and	O
fed	O
to	O
for	O
sentiment	B-Task
classification	I-Task
.	O
	
However	O
,	O
we	O
can	O
not	O
obtain	O
better	O
result	O
with	O
such	O
an	O
attention	B-Method
model	I-Method
.	O
	
The	O
accuracy	B-Metric
of	O
this	O
attention	B-Method
model	I-Method
is	O
slightly	O
lower	O
than	O
the	O
standard	O
LSTM	B-Method
model	I-Method
(	O
around	O
65	O
%	O
)	O
,	O
which	O
means	O
that	O
the	O
attention	B-Method
component	I-Method
has	O
a	O
negative	O
impact	O
on	O
the	O
model	O
.	O
	
A	O
potential	O
reason	O
might	O
be	O
that	O
the	O
attention	B-Method
based	I-Method
LSTM	I-Method
has	O
larger	O
number	O
of	O
parameters	O
,	O
which	O
can	O
not	O
be	O
easily	O
optimized	O
with	O
the	O
small	O
number	O
of	O
corpus	O
.	O
	
section	O
:	O
Related	O
Work	O
	
We	O
briefly	O
review	O
existing	O
studies	O
on	O
target	B-Task
-	I-Task
dependent	I-Task
sentiment	I-Task
classification	I-Task
and	O
neural	B-Method
network	I-Method
approaches	I-Method
for	O
sentiment	B-Task
classification	I-Task
in	O
this	O
section	O
.	O
	
subsection	O
:	O
Target	B-Task
-	I-Task
Dependent	I-Task
Sentiment	I-Task
Classification	I-Task
	
Target	B-Task
-	I-Task
dependent	I-Task
sentiment	I-Task
classification	I-Task
is	O
typically	O
regarded	O
as	O
a	O
kind	O
of	O
text	B-Task
classification	I-Task
problem	I-Task
in	O
literature	O
.	O
	
Therefore	O
,	O
standard	O
text	B-Method
classification	I-Method
approach	I-Method
such	O
as	O
feature	B-Method
-	I-Method
based	I-Method
Supported	I-Method
Vector	I-Method
Machine	I-Method
can	O
be	O
naturally	O
employed	O
to	O
build	O
a	O
sentiment	B-Method
classifier	I-Method
.	O
	
Despite	O
the	O
effectiveness	O
of	O
feature	B-Method
engineering	I-Method
,	O
it	O
is	O
labor	O
intensive	O
and	O
unable	O
to	O
discover	O
the	O
discriminative	O
or	O
explanatory	O
factors	O
of	O
data	O
.	O
	
To	O
handle	O
this	O
problem	O
,	O
some	O
recent	O
studies	O
use	O
neural	B-Method
network	I-Method
methods	I-Method
and	O
encode	O
each	O
sentence	O
in	O
continuous	O
and	O
low	O
-	O
dimensional	O
vector	O
space	O
without	O
feature	B-Method
engineering	I-Method
.	O
	
Dong	O
et	O
al	O
.	O
	
Dong2014a	O
transfer	O
a	O
dependency	O
tree	O
of	O
a	O
sentence	O
into	O
a	O
target	O
-	O
specific	O
recursive	O
structure	O
,	O
and	O
get	O
higher	O
level	B-Method
representation	I-Method
based	O
on	O
that	O
structure	O
.	O
	
Vo	O
and	O
Zhang	O
Vo2015	O
use	O
rich	O
features	O
including	O
sentiment	B-Method
-	I-Method
specific	I-Method
word	I-Method
embedding	I-Method
and	O
sentiment	B-Method
lexicons	I-Method
.	O
	
Different	O
from	O
previous	O
studies	O
,	O
the	O
LSTM	B-Method
models	O
developed	O
in	O
this	O
work	O
are	O
purely	O
data	O
-	O
driven	O
,	O
and	O
do	O
not	O
rely	O
on	O
dependency	O
parsing	O
results	O
or	O
external	O
sentiment	O
lexicons	O
.	O
	
subsection	O
:	O
Neural	B-Method
Network	I-Method
for	O
Sentiment	B-Task
Classification	I-Task
	
Neural	B-Method
network	I-Method
approaches	I-Method
have	O
shown	O
promising	O
results	O
on	O
many	O
sentence	B-Task
/	I-Task
document	I-Task
-	I-Task
level	I-Task
sentiment	I-Task
classification	I-Task
.	O
	
The	O
power	O
of	O
neural	B-Method
model	I-Method
lies	O
in	O
its	O
ability	O
in	O
learning	O
continuous	B-Task
text	I-Task
representation	I-Task
from	O
data	O
without	O
any	O
feature	B-Method
engineering	I-Method
.	O
	
For	O
sentence	B-Task
/	I-Task
document	I-Task
level	I-Task
sentiment	I-Task
classification	I-Task
,	O
previous	O
studies	O
mostly	O
have	O
two	O
steps	O
.	O
	
They	O
first	O
learn	O
continuous	B-Method
word	I-Method
vector	I-Method
embeddings	I-Method
from	O
data	O
.	O
	
Afterwards	O
,	O
semantic	B-Method
compositional	I-Method
approaches	I-Method
are	O
used	O
to	O
compute	O
the	O
vector	O
of	O
a	O
sentence	O
/	O
document	O
from	O
the	O
vectors	O
of	O
its	O
constituents	O
based	O
on	O
the	O
principle	B-Method
of	I-Method
compositionality	I-Method
.	O
	
Representative	O
compositional	B-Method
approaches	I-Method
to	O
learn	O
sentence	B-Task
representation	I-Task
include	O
recursive	B-Method
neural	I-Method
networks	I-Method
,	O
convolutional	B-Method
neural	I-Method
network	I-Method
,	O
long	B-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
and	O
tree	B-Method
-	I-Method
structured	I-Method
LSTM	I-Method
.	O
	
There	O
also	O
exists	O
some	O
studies	O
focusing	O
on	O
learning	O
continuous	B-Task
representation	I-Task
of	I-Task
documents	I-Task
.	O
	
section	O
:	O
Conclusion	O
	
We	O
develop	O
target	B-Method
-	I-Method
specific	I-Method
long	I-Method
short	I-Method
term	I-Method
memory	I-Method
models	I-Method
for	O
target	B-Task
-	I-Task
dependent	I-Task
sentiment	I-Task
classification	I-Task
.	O
	
The	O
approach	O
captures	O
the	O
connection	O
between	O
target	O
word	O
and	O
its	O
contexts	O
when	O
generating	O
the	O
representation	O
of	O
a	O
sentence	O
.	O
	
We	O
train	O
the	O
model	O
in	O
an	O
end	O
-	O
to	O
-	O
end	O
way	O
on	O
a	O
benchmark	O
dataset	O
,	O
and	O
show	O
that	O
incorporating	O
target	O
information	O
could	O
boost	O
the	O
performance	O
of	O
a	O
long	B-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
model	O
.	O
	
The	O
target	O
-	O
dependent	O
LSTM	B-Method
model	O
obtains	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
classification	O
accuracy	B-Metric
.	O
	
section	O
:	O
Acknowledgements	O
	
We	O
greatly	O
thank	O
Yaming	O
Sun	O
for	O
tremendously	O
helpful	O
discussions	O
.	O
	
This	O
work	O
was	O
supported	O
by	O
the	O
National	O
High	O
Technology	O
Development	O
863	O
Program	O
of	O
China	O
	
(	O
No	O
.	O
2015AA015407	O
)	O
,	O
National	O
Natural	O
Science	O
Foundation	O
of	O
China	O
(	O
No	O
.	O
61632011	O
and	O
No.61273321	O
)	O
.	O
	
According	O
to	O
the	O
meaning	O
given	O
to	O
this	O
role	O
by	O
Harbin	O
Institute	O
of	O
Technology	O
,	O
the	O
contact	O
author	O
of	O
this	O
paper	O
is	O
Bing	O
Qin	O
.	O
	
bibliography	O
:	O
References	O
	
Published	O
as	O
a	O
conference	O
paper	O
at	O
ICLR	O
	
2017	O
TEMPORAL	B-Task
ENSEMBLING	I-Task
FOR	O
SEMI	B-Task
-	I-Task
SUPERVISED	I-Task
LEARNING	I-Task
	
section	O
:	O
ABSTRACT	O
	
In	O
this	O
paper	O
,	O
we	O
present	O
a	O
simple	O
and	O
efficient	O
method	O
for	O
training	O
deep	B-Method
neural	I-Method
networks	I-Method
in	O
a	O
semi	B-Task
-	I-Task
supervised	I-Task
setting	I-Task
where	O
only	O
a	O
small	O
portion	O
of	O
training	O
data	O
is	O
labeled	O
.	O
	
We	O
introduce	O
self	B-Method
-	I-Method
ensembling	I-Method
,	O
where	O
we	O
form	O
a	O
consensus	B-Method
prediction	I-Method
of	O
the	O
unknown	O
labels	O
using	O
the	O
outputs	O
of	O
the	O
network	O
-	O
in	O
-	O
training	O
on	O
different	O
epochs	O
,	O
and	O
most	O
importantly	O
,	O
under	O
different	O
regularization	O
and	O
input	O
augmentation	O
conditions	O
.	O
	
This	O
ensemble	B-Method
prediction	I-Method
can	O
be	O
expected	O
to	O
be	O
a	O
better	O
predictor	O
for	O
the	O
unknown	O
labels	O
than	O
the	O
output	O
of	O
the	O
network	O
at	O
the	O
most	O
recent	O
training	O
epoch	O
,	O
and	O
can	O
thus	O
be	O
used	O
as	O
a	O
target	O
for	O
training	O
.	O
	
Using	O
our	O
method	O
,	O
we	O
set	O
new	O
records	O
for	O
two	O
standard	O
semi	B-Task
-	I-Task
supervised	I-Task
learning	I-Task
benchmarks	I-Task
,	O
reducing	O
the	O
(	O
non	B-Metric
-	I-Metric
augmented	I-Metric
)	I-Metric
classification	I-Metric
error	I-Metric
rate	I-Metric
from	O
18.44	O
%	O
to	O
7.05	O
%	O
in	O
SVHN	B-Material
with	O
500	O
labels	O
and	O
from	O
18.63	O
%	O
to	O
16.55	O
%	O
in	O
CIFAR	B-Material
-	I-Material
10	I-Material
with	O
4000	O
labels	O
,	O
and	O
further	O
to	O
5.12	O
%	O
and	O
12.16	O
%	O
by	O
enabling	O
the	O
standard	O
augmentations	B-Method
.	O
	
We	O
additionally	O
obtain	O
a	O
clear	O
improvement	O
in	O
CIFAR	O
-	O
100	O
classification	B-Metric
accuracy	I-Metric
by	O
using	O
random	O
images	O
from	O
the	O
Tiny	O
Images	O
dataset	O
as	O
unlabeled	O
extra	O
inputs	O
during	O
training	O
.	O
	
Finally	O
,	O
we	O
demonstrate	O
good	O
tolerance	O
to	O
incorrect	O
labels	O
.	O
	
section	O
:	O
INTRODUCTION	O
	
It	O
has	O
long	O
been	O
known	O
that	O
an	O
ensemble	B-Method
of	I-Method
multiple	I-Method
neural	I-Method
networks	I-Method
generally	O
yields	O
better	O
predictions	O
than	O
a	O
single	O
network	O
in	O
the	O
ensemble	O
.	O
	
This	O
effect	O
has	O
also	O
been	O
indirectly	O
exploited	O
when	O
training	O
a	O
single	O
network	O
through	O
dropout	B-Method
[	O
reference	O
]	O
,	O
dropconnect	B-Method
[	O
reference	O
]	O
,	O
or	O
stochastic	B-Method
depth	I-Method
[	O
reference	O
]	O
regularization	B-Method
methods	I-Method
,	O
and	O
in	O
swapout	B-Method
networks	I-Method
[	O
reference	O
]	O
,	O
where	O
training	O
always	O
focuses	O
on	O
a	O
particular	O
subset	O
of	O
the	O
network	O
,	O
and	O
thus	O
the	O
complete	O
network	O
can	O
be	O
seen	O
as	O
an	O
implicit	O
ensemble	O
of	O
such	O
trained	O
sub	B-Method
-	I-Method
networks	I-Method
.	O
	
We	O
extend	O
this	O
idea	O
by	O
forming	O
ensemble	B-Method
predictions	I-Method
during	O
training	B-Task
,	O
using	O
the	O
outputs	O
of	O
a	O
single	O
network	O
on	O
different	O
training	O
epochs	O
and	O
under	O
different	O
regularization	O
and	O
input	O
augmentation	O
conditions	O
.	O
	
Our	O
training	O
still	O
operates	O
on	O
a	O
single	O
network	O
,	O
but	O
the	O
predictions	O
made	O
on	O
different	O
epochs	O
correspond	O
to	O
an	O
ensemble	B-Method
prediction	I-Method
of	O
a	O
large	O
number	O
of	O
individual	O
sub	B-Method
-	I-Method
networks	I-Method
because	O
of	O
dropout	B-Method
regularization	I-Method
.	O
	
This	O
ensemble	B-Method
prediction	I-Method
can	O
be	O
exploited	O
for	O
semi	B-Task
-	I-Task
supervised	I-Task
learning	I-Task
where	O
only	O
a	O
small	O
portion	O
of	O
training	O
data	O
is	O
labeled	O
.	O
	
If	O
we	O
compare	O
the	O
ensemble	B-Method
prediction	I-Method
to	O
the	O
current	O
output	O
of	O
the	O
network	O
being	O
trained	O
,	O
the	O
ensemble	B-Task
prediction	I-Task
is	O
likely	O
to	O
be	O
closer	O
to	O
the	O
correct	O
,	O
unknown	O
labels	O
of	O
the	O
unlabeled	O
inputs	O
.	O
	
Therefore	O
the	O
labels	O
inferred	O
this	O
way	O
can	O
be	O
used	O
as	O
training	O
targets	O
for	O
the	O
unlabeled	O
inputs	O
.	O
	
Our	O
method	O
relies	O
heavily	O
on	O
dropout	B-Method
regularization	I-Method
and	O
versatile	B-Method
input	I-Method
augmentation	I-Method
.	O
	
Indeed	O
,	O
without	O
neither	O
,	O
there	O
would	O
be	O
much	O
less	O
reason	O
to	O
place	O
confidence	O
in	O
whatever	O
labels	O
are	O
inferred	O
for	O
the	O
unlabeled	O
training	O
data	O
.	O
	
We	O
describe	O
two	O
ways	O
to	O
implement	O
self	B-Method
-	I-Method
ensembling	I-Method
,	O
Π	B-Method
-	I-Method
model	I-Method
and	O
temporal	B-Method
ensembling	I-Method
.	O
	
Both	O
approaches	O
surpass	O
prior	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
in	O
semi	B-Task
-	I-Task
supervised	I-Task
learning	I-Task
by	O
a	O
considerable	O
margin	O
.	O
	
We	O
furthermore	O
observe	O
that	O
self	B-Method
-	I-Method
ensembling	I-Method
improves	O
the	O
classification	B-Metric
accuracy	I-Metric
in	O
fully	O
labeled	O
cases	O
as	O
well	O
,	O
and	O
provides	O
tolerance	O
against	O
incorrect	O
labels	O
.	O
	
The	O
recently	O
introduced	O
transform	B-Metric
/	I-Metric
stability	I-Metric
loss	I-Metric
of	O
[	O
reference	O
]	O
is	O
based	O
on	O
the	O
same	O
principle	O
as	O
our	O
work	O
,	O
and	O
the	O
Π	B-Method
-	I-Method
model	I-Method
can	O
be	O
seen	O
as	O
a	O
special	O
case	O
of	O
it	O
.	O
	
The	O
Π	B-Method
-	I-Method
model	I-Method
can	O
also	O
be	O
seen	O
as	O
a	O
simplification	O
of	O
the	O
Γ	B-Method
-	I-Method
model	I-Method
of	O
the	O
ladder	B-Method
network	I-Method
by	O
[	O
reference	O
]	O
,	O
a	O
previously	O
presented	O
network	B-Method
architecture	I-Method
for	O
semi	B-Task
-	I-Task
supervised	I-Task
learning	I-Task
.	O
	
Our	O
temporal	B-Method
ensembling	I-Method
method	I-Method
has	O
connections	O
to	O
the	O
bootstrapping	B-Method
method	I-Method
of	O
[	O
reference	O
]	O
targeted	O
for	O
training	O
with	O
noisy	O
labels	O
.	O
	
1	O
|B|	O
i∈	O
(	O
B∩L	O
)	O
log	O
z	O
	
i	O
	
[	O
y	O
i	O
]	O
supervised	B-Method
loss	I-Method
component	I-Method
+	O
w	B-Method
(	I-Method
t	I-Method
)	I-Method
	
1	O
C|B|	O
i∈B	O
||z	O
i	O
−z	O
	
i	O
||	O
2	O
unsupervised	B-Method
loss	I-Method
component	I-Method
update	I-Method
θ	I-Method
using	O
,	O
e.g.	O
,	O
ADAM	B-Method
update	I-Method
network	I-Method
parameters	I-Method
end	O
for	O
end	O
for	O
return	O
θ	O
	
section	O
:	O
SELF	B-Method
-	I-Method
ENSEMBLING	I-Method
DURING	O
TRAINING	B-Task
	
We	O
present	O
two	O
implementations	O
of	O
self	B-Method
-	I-Method
ensembling	I-Method
during	O
training	B-Task
.	O
	
The	O
first	O
one	O
,	O
Π	B-Method
-	I-Method
model	I-Method
,	O
encourages	O
consistent	O
network	O
output	O
between	O
two	O
realizations	O
of	O
the	O
same	O
input	O
stimulus	O
,	O
under	O
two	O
different	O
dropout	O
conditions	O
.	O
	
The	O
second	O
method	O
,	O
temporal	B-Method
ensembling	I-Method
,	O
simplifies	O
and	O
extends	O
this	O
by	O
taking	O
into	O
account	O
the	O
network	O
predictions	O
over	O
multiple	O
previous	O
training	O
epochs	O
.	O
	
We	O
shall	O
describe	O
our	O
methods	O
in	O
the	O
context	O
of	O
traditional	O
image	B-Method
classification	I-Method
networks	I-Method
.	O
	
Let	O
the	O
training	O
data	O
consist	O
of	O
total	O
of	O
N	O
inputs	O
,	O
out	O
of	O
which	O
M	O
are	O
labeled	O
.	O
	
The	O
input	O
stimuli	O
,	O
available	O
for	O
all	O
training	O
data	O
,	O
are	O
denoted	O
x	O
i	O
,	O
where	O
i	O
∈	O
{	O
1	O
.	O
.	O
.	O
	
N	O
}	O
.	O
	
Let	O
set	O
L	O
contain	O
the	O
indices	O
of	O
the	O
labeled	O
inputs	O
,	O
|L|	O
=	O
	
M	O
.	O
	
For	O
every	O
i	O
∈	O
L	O
,	O
we	O
have	O
a	O
known	O
correct	O
label	O
	
y	O
	
i	O
∈	O
{	O
1	O
.	O
.	O
.	O
	
C	O
}	O
,	O
where	O
C	O
is	O
the	O
number	O
of	O
different	O
classes	O
.	O
	
section	O
:	O
Π	B-Method
-	I-Method
MODEL	I-Method
	
The	O
structure	O
of	O
Π	B-Method
-	I-Method
model	I-Method
is	O
shown	O
in	O
Figure	O
1	O
(	O
top	O
)	O
,	O
and	O
the	O
pseudocode	O
in	O
Algorithm	O
1	O
.	O
	
During	O
training	O
,	O
we	O
evaluate	O
the	O
network	O
for	O
each	O
training	O
input	O
x	O
	
i	O
twice	O
,	O
resulting	O
in	O
prediction	O
vectors	O
	
z	O
	
i	O
andz	O
i	O
.	O
	
Our	O
loss	B-Method
function	I-Method
consists	O
of	O
two	O
components	O
.	O
	
The	O
first	O
component	O
is	O
the	O
standard	O
crossentropy	B-Method
loss	I-Method
,	O
evaluated	O
for	O
labeled	O
inputs	O
only	O
.	O
	
The	O
second	O
component	O
,	O
evaluated	O
for	O
all	O
inputs	O
,	O
penalizes	O
different	O
predictions	O
for	O
the	O
same	O
training	O
input	O
x	O
i	O
by	O
taking	O
the	O
mean	O
square	O
difference	O
between	O
the	O
prediction	O
vectors	O
	
z	O
	
i	O
andz	O
i	O
.	O
	
1	O
	
To	O
combine	O
the	O
supervised	O
and	O
unsupervised	O
loss	O
terms	O
,	O
we	O
scale	O
the	O
latter	O
by	O
time	B-Method
-	I-Method
dependent	I-Method
weighting	I-Method
function	I-Method
w	I-Method
(	I-Method
t	I-Method
)	I-Method
.	O
	
By	O
comparing	O
the	O
entire	O
output	O
vectors	O
z	O
	
i	O
andz	O
i	O
	
,	O
we	O
effectively	O
ask	O
the	O
"	O
dark	O
knowledge	O
"	O
[	O
reference	O
]	O
between	O
the	O
two	O
evaluations	O
to	O
be	O
close	O
,	O
which	O
is	O
a	O
much	O
stronger	O
requirement	O
compared	O
to	O
asking	O
that	O
only	O
the	O
final	O
classification	B-Task
remains	O
the	O
same	O
,	O
which	O
is	O
what	O
happens	O
in	O
traditional	O
training	O
.	O
	
It	O
is	O
important	O
to	O
notice	O
that	O
,	O
because	O
of	O
dropout	B-Method
regularization	I-Method
,	O
the	O
network	O
output	O
during	O
training	B-Method
is	O
a	O
stochastic	O
variable	O
.	O
	
Thus	O
two	O
evaluations	O
of	O
the	O
same	O
input	O
x	O
i	O
under	O
same	O
network	O
weights	O
θ	O
yield	O
different	O
results	O
.	O
	
In	O
addition	O
,	O
Gaussian	O
noise	O
and	O
augmentations	O
such	O
as	O
random	O
translation	O
are	O
evaluated	O
twice	O
,	O
resulting	O
in	O
additional	O
variation	O
.	O
	
The	O
combination	O
of	O
these	O
effects	O
explains	O
the	O
difference	O
between	O
the	O
prediction	O
vectors	O
z	O
i	O
andz	O
i	O
.	O
	
This	O
difference	O
can	O
be	O
seen	O
as	O
an	O
error	O
in	O
classification	B-Task
,	O
given	O
that	O
the	O
original	O
input	O
x	O
i	O
was	O
the	O
same	O
,	O
and	O
thus	O
minimizing	O
it	O
is	O
a	O
reasonable	O
goal	O
.	O
	
In	O
our	O
implementation	O
,	O
the	O
unsupervised	B-Method
loss	I-Method
weighting	I-Method
function	I-Method
w	I-Method
(	I-Method
t	I-Method
)	I-Method
ramps	O
up	O
,	O
starting	O
from	O
zero	O
,	O
along	O
a	O
Gaussian	O
curve	O
during	O
the	O
first	O
80	O
training	O
epochs	O
.	O
	
See	O
Appendix	O
A	O
for	O
further	O
details	O
about	O
this	O
and	O
other	O
training	O
parameters	O
.	O
	
In	O
the	O
beginning	O
the	O
total	O
loss	B-Metric
and	O
the	O
learning	O
gradients	O
are	O
thus	O
dominated	O
by	O
the	O
supervised	B-Method
loss	I-Method
component	I-Method
,	O
i.e.	O
,	O
the	O
labeled	O
data	O
only	O
.	O
	
We	O
have	O
found	O
it	O
to	O
be	O
very	O
important	O
that	O
the	O
ramp	O
-	O
up	O
of	O
the	O
unsupervised	B-Method
loss	I-Method
component	I-Method
is	O
slow	O
enough	O
-	O
otherwise	O
,	O
the	O
network	O
gets	O
easily	O
stuck	O
in	O
a	O
degenerate	O
solution	O
where	O
no	O
meaningful	O
classification	O
of	O
the	O
data	O
is	O
obtained	O
.	O
	
Our	O
approach	O
is	O
somewhat	O
similar	O
to	O
the	O
Γ	B-Method
-	I-Method
model	I-Method
of	O
the	O
ladder	O
network	O
by	O
[	O
reference	O
]	O
,	O
but	O
conceptually	O
simpler	O
.	O
	
In	O
the	O
Π	B-Method
-	I-Method
model	I-Method
,	O
the	O
comparison	O
is	O
done	O
directly	O
on	O
network	O
outputs	O
,	O
i.e.	O
,	O
after	O
softmax	O
activation	O
,	O
and	O
there	O
is	O
no	O
auxiliary	O
mapping	O
between	O
the	O
two	O
branches	O
such	O
as	O
the	O
learned	O
denoising	O
functions	O
in	O
the	O
ladder	B-Method
network	I-Method
architecture	I-Method
.	O
	
Furthermore	O
,	O
instead	O
of	O
having	O
one	O
"	O
clean	O
"	O
and	O
one	O
"	O
corrupted	O
"	O
branch	O
as	O
in	O
Γ	B-Method
-	I-Method
model	I-Method
,	O
we	O
apply	O
equal	B-Method
augmentation	I-Method
and	O
noise	O
to	O
the	O
inputs	O
for	O
both	O
branches	O
.	O
	
As	O
shown	O
in	O
Section	O
3	O
,	O
the	O
Π	B-Method
-	I-Method
model	I-Method
combined	O
with	O
a	O
good	O
convolutional	B-Method
network	I-Method
architecture	I-Method
provides	O
a	O
significant	O
improvement	O
over	O
prior	O
art	O
in	O
classification	B-Metric
accuracy	I-Metric
.	O
	
section	O
:	O
TEMPORAL	B-Method
ENSEMBLING	I-Method
	
Analyzing	O
how	O
the	O
Π	B-Method
-	I-Method
model	I-Method
works	O
,	O
we	O
could	O
equally	O
well	O
split	O
the	O
evaluation	O
of	O
the	O
two	O
branches	O
in	O
two	O
separate	O
phases	O
:	O
first	O
classifying	O
the	O
training	O
set	O
once	O
without	O
updating	O
the	O
weights	O
θ	O
,	O
and	O
then	O
training	O
the	O
network	O
on	O
the	O
same	O
inputs	O
under	O
different	O
augmentations	O
and	O
dropout	O
,	O
using	O
the	O
just	O
obtained	O
predictions	O
as	O
targets	O
for	O
the	O
unsupervised	B-Method
loss	I-Method
component	I-Method
.	O
	
As	O
the	O
training	O
targets	O
obtained	O
this	O
way	O
are	O
based	O
on	O
a	O
single	O
evaluation	O
of	O
the	O
network	O
,	O
they	O
can	O
be	O
expected	O
to	O
be	O
noisy	O
.	O
	
Temporal	B-Method
ensembling	I-Method
alleviates	O
this	O
by	O
aggregating	O
the	O
predictions	O
of	O
multiple	O
previous	O
network	B-Method
evaluations	I-Method
into	O
an	O
ensemble	B-Method
prediction	I-Method
.	O
	
It	O
also	O
lets	O
us	O
evaluate	O
the	O
network	O
only	O
once	O
during	O
training	B-Task
,	O
gaining	O
an	O
approximate	O
2x	O
speedup	O
over	O
the	O
Π	B-Method
-	I-Method
model	I-Method
.	O
	
The	O
structure	O
of	O
our	O
temporal	B-Method
ensembling	I-Method
method	I-Method
is	O
shown	O
in	O
Figure	O
1	O
(	O
bottom	O
)	O
,	O
and	O
the	O
pseudocode	O
in	O
Algorithm	O
2	O
.	O
	
The	O
main	O
difference	O
to	O
the	O
Π	B-Method
-	I-Method
model	I-Method
is	O
that	O
the	O
network	B-Method
and	I-Method
augmentations	I-Method
are	O
evaluated	O
only	O
once	O
per	O
input	O
per	O
epoch	O
,	O
and	O
the	O
target	O
vectorsz	O
for	O
the	O
unsupervised	B-Method
loss	I-Method
component	I-Method
are	O
based	O
on	O
prior	O
network	O
evaluations	O
instead	O
of	O
a	O
second	O
evaluation	O
of	O
the	O
network	O
.	O
	
After	O
every	O
training	O
epoch	O
,	O
the	O
network	O
outputs	O
	
z	O
i	O
are	O
accumulated	O
into	O
ensemble	O
outputs	O
Z	O
i	O
by	O
updating	O
Z	O
	
i	O
←	O
	
αZ	O
	
i	O
+	O
	
(	O
1	O
−	O
α	O
)	O
z	O
	
i	O
,	O
where	O
α	O
is	O
a	O
momentum	O
term	O
that	O
controls	O
how	O
far	O
the	O
ensemble	O
reaches	O
into	O
training	O
history	O
.	O
	
Because	O
of	O
dropout	B-Method
regularization	I-Method
and	O
stochastic	B-Method
augmentation	I-Method
,	O
Z	O
thus	O
contains	O
a	O
weighted	O
average	O
of	O
the	O
outputs	O
of	O
an	O
ensemble	O
of	O
networks	O
f	O
from	O
previous	O
training	O
epochs	O
,	O
with	O
recent	O
epochs	O
having	O
larger	O
weight	O
than	O
distant	O
epochs	O
.	O
	
For	O
generating	O
the	O
training	O
targetsz	O
,	O
we	O
need	O
to	O
correct	O
for	O
the	O
startup	O
bias	O
in	O
Z	O
by	O
dividing	O
by	O
factor	O
(	O
1	O
−	O
α	O
t	O
)	O
.	O
	
A	O
similar	O
bias	B-Method
correction	I-Method
has	O
been	O
used	O
in	O
,	O
e.g.	O
,	O
[	O
reference	O
]	O
and	O
mean	B-Method
-	I-Method
only	I-Method
batch	I-Method
normalization	I-Method
	
[	O
reference	O
]	O
.	O
	
On	O
the	O
first	O
training	O
epoch	O
,	O
Z	O
andz	O
are	O
zero	O
as	O
no	O
data	O
from	O
previous	O
epochs	O
is	O
available	O
.	O
	
For	O
this	O
reason	O
,	O
we	O
specify	O
the	O
unsupervised	O
weight	O
ramp	O
-	O
up	O
function	O
w	B-Method
(	I-Method
t	I-Method
)	I-Method
to	O
also	O
be	O
zero	O
on	O
the	O
first	O
training	O
epoch	O
.	O
	
Algorithm	O
2	O
Temporal	B-Method
ensembling	I-Method
pseudocode	I-Method
.	O
	
Note	O
that	O
the	O
updates	O
of	O
Z	O
andz	O
could	O
equally	O
well	O
be	O
done	O
inside	O
the	O
minibatch	O
loop	O
;	O
in	O
this	O
pseudocode	O
they	O
occur	O
between	O
epochs	O
for	O
clarity	O
.	O
	
Require	O
:	O
x	O
i	O
=	O
training	O
stimuli	O
	
Require	O
:	O
	
L	O
=	O
set	O
of	O
training	O
input	O
indices	O
with	O
known	O
labels	O
Require	O
:	O
	
y	O
i	O
	
=	O
labels	O
for	O
labeled	O
inputs	O
	
i	O
	
∈	O
L	O
Require	O
:	O
α	O
=	O
ensembling	O
momentum	O
,	O
0	O
≤	O
α	O
	
<	O
1	O
Require	O
:	O
w	B-Method
(	I-Method
t	I-Method
)	I-Method
=	O
	
unsupervised	B-Method
weight	I-Method
ramp	I-Method
-	I-Method
up	I-Method
function	I-Method
Require	O
:	O
f	O
θ	O
(	O
x	O
)	O
=	O
stochastic	B-Method
neural	I-Method
network	I-Method
with	O
trainable	B-Method
parameters	I-Method
θ	O
	
Require	O
:	O
	
g	O
(	O
x	O
)	O
	
=	O
stochastic	B-Method
input	I-Method
augmentation	I-Method
function	I-Method
	
unsupervised	B-Method
loss	I-Method
component	I-Method
update	I-Method
θ	I-Method
using	O
,	O
e.g.	O
,	O
ADAM	B-Method
update	I-Method
network	I-Method
parameters	I-Method
end	O
for	O
	
construct	O
target	O
vectors	O
by	O
bias	B-Method
correction	I-Method
end	O
for	O
return	O
θ	O
	
The	O
benefits	O
of	O
temporal	B-Method
ensembling	I-Method
compared	O
to	O
Π	B-Method
-	I-Method
model	I-Method
are	O
twofold	O
.	O
	
First	O
,	O
the	O
training	B-Task
is	O
faster	O
because	O
the	O
network	O
is	O
evaluated	O
only	O
once	O
per	O
input	O
on	O
each	O
epoch	O
.	O
	
Second	O
,	O
the	O
training	O
targets	O
z	O
can	O
be	O
expected	O
to	O
be	O
less	O
noisy	O
than	O
with	O
Π	B-Method
-	I-Method
model	I-Method
.	O
	
As	O
shown	O
in	O
Section	O
3	O
,	O
we	O
indeed	O
obtain	O
somewhat	O
better	O
results	O
with	O
temporal	B-Method
ensembling	I-Method
than	O
with	O
Π	B-Method
-	I-Method
model	I-Method
in	O
the	O
same	O
number	O
of	O
training	O
epochs	O
.	O
	
The	O
downside	O
compared	O
to	O
Π	B-Method
-	I-Method
model	I-Method
is	O
the	O
need	O
to	O
store	O
auxiliary	O
data	O
across	O
epochs	O
,	O
and	O
the	O
new	O
hyperparameter	O
α	O
.	O
	
While	O
the	O
matrix	O
Z	O
can	O
be	O
fairly	O
large	O
when	O
the	O
dataset	O
contains	O
a	O
large	O
number	O
of	O
items	O
and	O
categories	O
,	O
its	O
elements	O
are	O
accessed	O
relatively	O
infrequently	O
.	O
	
Thus	O
it	O
can	O
be	O
stored	O
,	O
e.g.	O
,	O
in	O
a	O
memory	O
mapped	O
file	O
.	O
	
An	O
intriguing	O
additional	O
possibility	O
of	O
temporal	B-Task
ensembling	I-Task
is	O
collecting	O
other	O
statistics	O
from	O
the	O
network	B-Method
predictions	I-Method
	
z	O
i	O
besides	O
the	O
mean	O
.	O
	
For	O
example	O
,	O
by	O
tracking	O
the	O
second	O
raw	O
moment	O
of	O
the	O
network	O
outputs	O
,	O
we	O
can	O
estimate	O
the	O
variance	O
of	O
each	O
output	O
component	O
z	O
i	O
,	O
j	O
.	O
	
This	O
makes	O
it	O
possible	O
to	O
reason	O
about	O
the	O
uncertainty	O
of	O
network	O
outputs	O
in	O
a	O
principled	O
way	O
	
[	O
reference	O
]	O
.	O
Based	O
on	O
this	O
information	O
,	O
we	O
could	O
,	O
e.g.	O
,	O
place	O
more	O
weight	O
on	O
more	O
certain	O
predictions	O
vs.	O
uncertain	O
ones	O
in	O
the	O
unsupervised	O
loss	O
term	O
.	O
	
However	O
,	O
we	O
leave	O
the	O
exploration	O
of	O
these	O
avenues	O
as	O
future	O
work	O
.	O
	
section	O
:	O
RESULTS	O
	
Our	O
network	B-Method
structure	I-Method
is	O
given	O
in	O
Table	O
5	O
,	O
and	O
the	O
test	O
setup	O
and	O
all	O
training	O
parameters	O
are	O
detailed	O
in	O
Appendix	O
A.	O
	
We	O
test	O
the	O
Π	B-Method
-	I-Method
model	I-Method
and	O
temporal	B-Method
ensembling	I-Method
in	O
two	O
image	B-Task
classification	I-Task
tasks	I-Task
,	O
CIFAR	B-Material
-	I-Material
10	I-Material
and	O
SVHN	B-Material
,	O
and	O
report	O
the	O
mean	O
and	O
standard	O
deviation	O
of	O
10	O
runs	O
using	O
different	O
random	O
seeds	O
.	O
	
Although	O
it	O
is	O
rarely	O
stated	O
explicitly	O
,	O
we	O
believe	O
that	O
our	O
comparison	O
methods	O
do	O
not	O
use	O
input	O
augmentation	O
,	O
i.e.	O
,	O
are	O
limited	O
to	O
dropout	B-Method
and	O
other	O
forms	O
of	O
permutation	O
-	O
invariant	O
noise	O
.	O
	
Therefore	O
we	O
report	O
the	O
error	B-Metric
rates	I-Metric
without	O
augmentation	B-Task
,	O
unless	O
explicitly	O
stated	O
otherwise	O
.	O
	
Given	O
that	O
the	O
ability	O
of	O
an	O
algorithm	O
to	O
extract	O
benefit	O
from	O
augmentation	B-Task
is	O
also	O
an	O
important	O
property	O
,	O
we	O
report	O
the	O
classification	B-Metric
accuracy	I-Metric
using	O
a	O
standard	O
set	O
of	O
augmentations	B-Method
as	O
well	O
.	O
	
In	O
purely	O
supervised	B-Task
training	I-Task
the	O
de	O
facto	O
standard	O
way	O
of	O
augmenting	O
the	O
CIFAR	B-Material
-	I-Material
10	I-Material
dataset	I-Material
includes	O
horizontal	O
flips	O
and	O
random	O
translations	O
,	O
while	O
SVHN	B-Material
is	O
limited	O
to	O
random	O
translations	O
.	O
	
By	O
using	O
these	O
same	O
augmentations	O
we	O
can	O
compare	O
against	O
the	O
best	O
fully	O
supervised	O
results	O
as	O
well	O
.	O
	
After	O
all	O
,	O
the	O
fully	O
supervised	O
results	O
should	O
indicate	O
the	O
upper	O
bound	O
of	O
obtainable	O
accuracy	B-Metric
.	O
	
[	O
reference	O
]	O
20.40	O
±	O
0.47	O
	
CatGAN	B-Method
[	O
reference	O
]	O
	
19.58	O
±	O
0.58	O
GAN	O
of	O
18.63	O
±	O
2.32	O
Π	B-Method
-	I-Method
model	I-Method
16.55	O
±	O
0.29	O
6.90	O
±	O
0.07	O
Π	B-Method
-	I-Method
model	I-Method
with	O
augmentation	O
12.36	O
±	O
0.31	O
5.56	O
±	O
	
0.10	O
Temporal	B-Method
ensembling	I-Method
with	O
augmentation	B-Method
12.16	O
±	O
0.24	O
5.60	O
±	O
0.10	O
Table	O
2	O
:	O
SVHN	B-Material
results	O
for	O
500	O
and	O
1000	O
labels	O
,	O
averages	O
of	O
10	O
runs	O
(	O
4	O
runs	O
for	O
all	O
labels	O
)	O
.	O
	
Error	B-Metric
rate	I-Metric
(	O
%	O
)	O
with	O
#	O
labels	O
36.02	O
±	O
0.10	O
	
Virtual	B-Method
Adversarial	I-Method
[	O
reference	O
]	O
24.63	O
ADGM	B-Method
[	O
reference	O
]	O
22.86	O
SDGM	B-Method
[	O
reference	O
]	O
16.61	O
±	O
0.24	O
GAN	B-Method
of	O
18.44	O
±	O
4.8	O
8	O
.	O
	
section	O
:	O
CIFAR	B-Material
-	I-Material
10	I-Material
	
CIFAR	B-Material
-	I-Material
10	I-Material
is	O
a	O
dataset	O
consisting	O
of	O
32	O
×	O
32	O
pixel	O
RGB	O
images	O
from	O
ten	O
classes	O
.	O
	
Table	O
1	O
shows	O
a	O
2.1	O
percentage	O
point	O
reduction	O
in	O
classification	B-Metric
error	I-Metric
rate	I-Metric
with	O
4000	O
labels	O
(	O
400	O
per	O
class	O
)	O
compared	O
to	O
earlier	O
methods	O
for	O
the	O
non	O
-	O
augmented	O
Π	B-Method
-	I-Method
model	I-Method
.	O
	
Enabling	O
the	O
standard	O
set	O
of	O
augmentations	B-Method
further	O
reduces	O
the	O
error	B-Metric
rate	I-Metric
by	O
4.2	O
percentage	O
points	O
to	O
12.36	O
%	O
.	O
	
Temporal	B-Method
ensembling	I-Method
is	O
slightly	O
better	O
still	O
at	O
12.16	O
%	O
,	O
while	O
being	O
twice	O
as	O
fast	O
to	O
train	O
.	O
	
This	O
small	O
improvement	O
conceals	O
the	O
subtle	O
fact	O
that	O
random	O
horizontal	O
flips	O
need	O
to	O
be	O
done	O
independently	O
for	O
each	O
epoch	O
in	O
temporal	B-Task
ensembling	I-Task
,	O
while	O
Π	B-Method
-	I-Method
model	I-Method
can	O
randomize	O
once	O
per	O
a	O
pair	O
of	O
evaluations	O
,	O
which	O
according	O
to	O
our	O
measurements	O
is	O
∼0.5	O
percentage	O
points	O
better	O
than	O
independent	O
flips	O
.	O
	
A	O
principled	O
comparison	O
with	O
[	O
reference	O
]	O
is	O
difficult	O
due	O
to	O
several	O
reasons	O
.	O
	
They	O
provide	O
results	O
only	O
for	O
a	O
fairly	O
extreme	O
set	O
of	O
augmentations	O
(	O
translations	O
,	O
flipping	O
,	O
rotations	O
,	O
stretching	O
,	O
and	O
shearing	O
)	O
on	O
top	O
of	O
fractional	B-Method
max	I-Method
pooling	I-Method
[	O
reference	O
]	O
,	O
which	O
introduces	O
random	O
,	O
local	O
stretching	O
inside	O
the	O
network	O
,	O
and	O
is	O
known	O
to	O
improve	O
classification	B-Task
results	O
substantially	O
.	O
	
They	O
quote	O
an	O
error	B-Metric
rate	I-Metric
of	O
only	O
13.60	O
%	O
for	O
supervised	B-Task
-	I-Task
only	I-Task
training	I-Task
with	O
4000	O
labels	O
,	O
while	O
our	O
corresponding	O
baseline	O
is	O
34.85	O
%	O
.	O
	
This	O
gap	O
indicates	O
a	O
huge	O
benefit	O
from	O
versatile	B-Method
augmentations	I-Method
and	O
fractional	B-Method
max	I-Method
pooling	I-Method
-	O
in	O
fact	O
,	O
their	O
baseline	O
result	O
is	O
already	O
better	O
than	O
any	O
previous	O
semisupervised	B-Method
results	O
.	O
	
By	O
enabling	O
semi	B-Method
-	I-Method
supervised	I-Method
learning	I-Method
they	O
achieve	O
a	O
17	O
%	O
drop	O
in	O
classification	B-Metric
error	I-Metric
rate	I-Metric
(	O
from	O
13.60	O
%	O
to	O
11.29	O
%	O
)	O
,	O
while	O
we	O
see	O
a	O
much	O
larger	O
relative	O
drop	O
of	O
65	O
%	O
(	O
from	O
34.85	O
%	O
to	O
12.16	O
%	O
)	O
.	O
	
section	O
:	O
SVHN	B-Material
	
The	O
street	B-Material
view	I-Material
house	I-Material
numbers	I-Material
(	O
SVHN	B-Material
)	I-Material
dataset	I-Material
consists	O
of	O
32	O
×	O
32	O
pixel	O
RGB	O
images	O
of	O
real	O
-	O
world	O
house	O
numbers	O
,	O
and	O
the	O
task	O
is	O
to	O
classify	O
the	O
centermost	O
digit	O
.	O
	
In	O
SVHN	B-Material
we	O
chose	O
to	O
use	O
only	O
the	O
.	O
	
Even	O
with	O
this	O
choice	O
our	O
error	B-Metric
rate	I-Metric
with	O
all	O
labels	O
is	O
only	O
3.05	O
%	O
without	O
augmentation	B-Method
.	O
	
Table	O
2	O
compares	O
our	O
method	O
to	O
the	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
.	O
	
With	O
the	O
most	O
commonly	O
used	O
1000	O
labels	O
we	O
observe	O
an	O
improvement	O
of	O
2.7	O
percentage	O
points	O
,	O
from	O
8.11	O
%	O
to	O
5.43	O
%	O
without	O
augmentation	B-Method
,	O
and	O
further	O
to	O
4.42	O
%	O
with	O
standard	O
augmentations	B-Method
.	O
	
We	O
also	O
investigated	O
the	O
behavior	O
with	O
500	O
labels	O
,	O
where	O
we	O
obtained	O
an	O
error	B-Metric
rate	I-Metric
less	O
than	O
half	O
of	O
without	O
augmentations	B-Method
,	O
with	O
a	O
significantly	O
lower	O
standard	O
deviation	O
as	O
well	O
.	O
	
When	O
augmentations	O
were	O
enabled	O
,	O
temporal	B-Method
ensembling	I-Method
further	O
reduced	O
the	O
error	B-Metric
rate	I-Metric
to	O
5.12	O
%	O
.	O
	
In	O
this	O
test	O
the	O
difference	O
between	O
Π	B-Method
-	I-Method
model	I-Method
and	O
temporal	B-Method
ensembling	I-Method
was	O
quite	O
significant	O
at	O
1.5	O
percentage	O
points	O
.	O
	
In	O
[	O
reference	O
]	O
provide	O
results	O
without	O
augmentation	B-Task
,	O
with	O
the	O
caveat	O
that	O
they	O
use	O
fractional	B-Method
max	I-Method
pooling	I-Method
,	O
which	O
is	O
a	O
very	O
augmentation	O
-	O
like	O
technique	O
due	O
to	O
the	O
random	O
,	O
local	O
stretching	O
it	O
introduces	O
inside	O
the	O
network	O
.	O
	
It	O
leads	O
to	O
a	O
superb	B-Metric
error	I-Metric
rate	I-Metric
of	O
2.28	O
%	O
in	O
supervisedonly	B-Task
training	I-Task
,	O
while	O
our	O
corresponding	O
baseline	O
is	O
3.05	O
%	O
(	O
or	O
2.88	O
%	O
with	O
translations	O
)	O
.	O
	
Given	O
that	O
in	O
a	O
separate	O
experiment	O
our	O
network	O
matched	O
the	O
best	O
published	O
result	O
for	O
non	O
-	O
augmented	O
SVHN	B-Material
when	O
extra	O
data	O
is	O
used	O
(	O
1.69	O
%	O
from	O
[	O
reference	O
]	O
)	O
,	O
this	O
gap	O
is	O
quite	O
surprising	O
,	O
and	O
leads	O
us	O
to	O
conclude	O
that	O
fractional	B-Method
max	I-Method
pooling	I-Method
leads	O
to	O
a	O
powerful	O
augmentation	O
of	O
the	O
dataset	O
,	O
well	O
beyond	O
what	O
simple	O
translations	O
can	O
achieve	O
.	O
	
Our	O
temporal	B-Method
ensembling	I-Method
technique	I-Method
obtains	O
better	O
error	B-Metric
rates	I-Metric
for	O
both	O
500	O
and	O
1000	O
labels	O
(	O
5.12	O
%	O
and	O
4.42	O
%	O
,	O
respectively	O
)	O
compared	O
to	O
the	O
6.03	O
%	O
reported	O
by	O
Sajjadi	O
et	O
al	O
.	O
for	O
732	O
labels	O
.	O
	
section	O
:	O
CIFAR	O
-	O
100	O
AND	O
TINY	O
IMAGES	O
	
The	O
CIFAR	O
-	O
100	O
dataset	O
consists	O
of	O
32	O
×	O
32	O
pixel	O
RGB	O
images	O
from	O
a	O
hundred	O
classes	O
.	O
	
We	O
are	O
not	O
aware	O
of	O
previous	O
semi	B-Task
-	I-Task
supervised	I-Task
results	O
in	O
this	O
dataset	O
,	O
and	O
chose	O
10000	O
labels	O
for	O
our	O
experiments	O
.	O
	
Table	O
3	O
shows	O
error	B-Metric
rates	I-Metric
of	O
43.43	O
%	O
and	O
38.65	O
%	O
without	O
and	O
with	O
augmentation	B-Method
,	O
respectively	O
.	O
	
These	O
correspond	O
to	O
7.8	O
and	O
5.9	O
percentage	O
point	O
improvements	O
compared	O
to	O
supervised	B-Method
learning	I-Method
with	O
labeled	O
inputs	O
only	O
.	O
	
We	O
ran	O
two	O
additional	O
tests	O
using	O
unlabeled	O
extra	O
data	O
from	O
Tiny	O
Images	O
dataset	O
[	O
reference	O
]	O
:	O
one	O
with	O
randomly	O
selected	O
500k	O
extra	O
images	O
,	O
most	O
not	O
corresponding	O
to	O
any	O
of	O
the	O
CIFAR	O
-	O
100	O
categories	O
,	O
and	O
another	O
with	O
a	O
restricted	O
set	O
of	O
237k	O
images	O
from	O
the	O
categories	O
that	O
correspond	O
to	O
those	O
found	O
in	O
the	O
CIFAR	O
-	O
100	O
dataset	O
(	O
see	O
appendix	O
A	O
for	O
details	O
)	O
.	O
	
The	O
results	O
are	O
shown	O
in	O
Table	O
4	O
.	O
	
The	O
addition	O
of	O
randomly	O
selected	O
,	O
unlabeled	O
extra	O
images	O
improved	O
the	O
error	B-Metric
rate	I-Metric
by	O
2.7	O
percentage	O
points	O
(	O
from	O
26.30	O
%	O
to	O
23.63	O
%	O
)	O
,	O
indicating	O
a	O
desirable	O
ability	O
to	O
learn	O
from	O
random	O
natural	O
images	O
.	O
	
Temporal	B-Method
ensembling	I-Method
benefited	O
much	O
more	O
from	O
the	O
extra	O
data	O
than	O
the	O
Π	B-Method
-	I-Method
model	I-Method
.	O
	
Interestingly	O
,	O
restricting	O
the	O
extra	O
data	O
to	O
categories	O
that	O
are	O
present	O
in	O
CIFAR	O
-	O
100	O
did	O
not	O
improve	O
With	O
standard	O
supervised	B-Method
training	I-Method
(	O
left	O
)	O
the	O
classification	B-Metric
accuracy	I-Metric
suffers	O
when	O
even	O
a	O
small	O
portion	O
of	O
the	O
labels	O
give	O
disinformation	O
,	O
and	O
the	O
situation	O
worsens	O
quickly	O
as	O
the	O
portion	O
of	O
randomized	O
labels	O
increases	O
to	O
50	O
%	O
or	O
more	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
temporal	O
ensembling	O
(	O
right	O
)	O
shows	O
almost	O
perfect	O
resistance	O
to	O
disinformation	O
when	O
half	O
of	O
the	O
labels	O
are	O
random	O
,	O
and	O
retains	O
over	O
ninety	O
percent	O
classification	B-Metric
accuracy	I-Metric
even	O
when	O
80	O
%	O
of	O
the	O
labels	O
are	O
random	O
.	O
	
the	O
classification	B-Metric
accuracy	I-Metric
further	O
.	O
	
This	O
indicates	O
that	O
in	O
order	O
to	O
train	O
a	O
better	O
classifier	B-Method
by	O
adding	O
extra	O
data	O
as	O
unlabeled	O
inputs	O
,	O
it	O
is	O
enough	O
to	O
have	O
the	O
extra	O
data	O
roughly	O
in	O
the	O
same	O
space	O
as	O
the	O
actual	O
inputs	O
-	O
in	O
our	O
case	O
,	O
natural	O
images	O
.	O
	
We	O
hypothesize	O
that	O
it	O
may	O
even	O
be	O
possible	O
to	O
use	O
properly	O
crafted	O
synthetic	O
data	O
as	O
unlabeled	O
inputs	O
to	O
obtain	O
improved	O
classifiers	B-Method
.	O
	
In	O
order	O
to	O
keep	O
the	O
training	B-Metric
times	I-Metric
tolerable	O
,	O
we	O
limited	O
the	O
number	O
of	O
unlabeled	O
inputs	O
to	O
50k	O
per	O
epoch	O
in	O
these	O
tests	O
,	O
i.e.	O
,	O
on	O
every	O
epoch	O
we	O
trained	O
using	O
all	O
50k	O
labeled	O
inputs	O
from	O
CIFAR	O
-	O
100	O
and	O
50k	O
additional	O
unlabeled	O
inputs	O
from	O
Tiny	O
Images	O
.	O
	
The	O
50k	O
unlabeled	O
inputs	O
were	O
chosen	O
randomly	O
on	O
each	O
epoch	O
from	O
the	O
500k	O
or	O
237k	O
extra	O
inputs	O
.	O
	
In	O
temporal	B-Task
ensembling	I-Task
,	O
after	O
each	O
epoch	O
we	O
updated	O
only	O
the	O
rows	O
of	O
Z	O
that	O
corresponded	O
to	O
inputs	O
used	O
on	O
that	O
epoch	O
.	O
	
section	O
:	O
SUPERVISED	B-Task
LEARNING	I-Task
	
When	O
all	O
labels	O
are	O
used	O
for	O
traditional	O
supervised	B-Task
training	I-Task
,	O
our	O
network	O
approximately	O
matches	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
error	B-Metric
rate	I-Metric
for	O
a	O
single	O
model	O
in	O
CIFAR	B-Material
-	I-Material
10	I-Material
with	O
augmentation	B-Method
[	O
reference	O
][	O
reference	O
]	O
at	O
6.05	O
%	O
,	O
and	O
without	O
augmentation	B-Method
[	O
reference	O
]	O
at	O
7.33	O
%	O
.	O
	
The	O
same	O
is	O
probably	O
true	O
for	O
SVHN	B-Material
as	O
well	O
,	O
but	O
there	O
the	O
best	O
published	O
results	O
rely	O
on	O
extra	O
data	O
that	O
we	O
chose	O
not	O
to	O
use	O
.	O
	
Given	O
this	O
premise	O
,	O
it	O
is	O
perhaps	O
somewhat	O
surprising	O
that	O
our	O
methods	O
reduce	O
the	O
error	B-Metric
rate	I-Metric
also	O
when	O
all	O
labels	O
are	O
used	O
(	O
Tables	O
1	O
and	O
2	O
)	O
.	O
	
We	O
believe	O
that	O
this	O
is	O
an	O
indication	O
that	O
the	O
consistency	O
requirement	O
adds	O
a	O
degree	O
of	O
resistance	O
to	O
ambiguous	O
labels	O
that	O
are	O
fairly	O
common	O
in	O
many	O
classification	B-Task
tasks	I-Task
,	O
and	O
that	O
it	O
encourages	O
features	O
to	O
be	O
more	O
invariant	O
to	O
stochastic	B-Method
sampling	I-Method
.	O
	
section	O
:	O
TOLERANCE	O
TO	O
INCORRECT	O
LABELS	O
	
In	O
a	O
further	O
test	O
we	O
studied	O
the	O
hypothesis	O
that	O
our	O
methods	O
add	O
tolerance	O
to	O
incorrect	O
labels	O
by	O
assigning	O
a	O
random	O
label	O
to	O
a	O
certain	O
percentage	O
of	O
the	O
training	O
set	O
before	O
starting	O
to	O
train	O
.	O
	
Figure	O
2	O
shows	O
the	O
classification	B-Metric
error	I-Metric
graphs	I-Metric
for	O
standard	O
supervised	B-Task
training	I-Task
and	O
temporal	B-Task
ensembling	I-Task
.	O
	
Clearly	O
our	O
methods	O
provide	O
considerable	O
resistance	O
to	O
wrong	O
labels	O
,	O
and	O
we	O
believe	O
this	O
is	O
because	O
the	O
unsupervised	B-Method
loss	I-Method
term	I-Method
encourages	O
the	O
mapping	O
function	O
implemented	O
by	O
the	O
network	O
to	O
be	O
flat	O
in	O
the	O
vicinity	O
of	O
all	O
input	O
data	O
points	O
,	O
whereas	O
the	O
supervised	B-Method
loss	I-Method
term	I-Method
enforces	O
the	O
mapping	O
function	O
to	O
have	O
a	O
specific	O
value	O
in	O
the	O
vicinity	O
of	O
the	O
labeled	O
input	O
data	O
points	O
.	O
	
This	O
means	O
that	O
even	O
the	O
wrongly	O
labeled	O
inputs	O
play	O
a	O
role	O
in	O
shaping	O
the	O
mapping	O
function	O
-	O
the	O
unsupervised	B-Method
loss	I-Method
term	I-Method
smooths	O
the	O
mapping	O
function	O
and	O
thus	O
also	O
the	O
decision	O
boundaries	O
,	O
effectively	O
fusing	O
the	O
inputs	O
into	O
coherent	O
clusters	O
,	O
whereas	O
the	O
excess	O
of	O
correct	O
labels	O
in	O
each	O
class	O
is	O
sufficient	O
for	O
locking	O
the	O
clusters	O
to	O
the	O
right	O
output	O
vectors	O
through	O
the	O
supervised	B-Method
loss	I-Method
term	I-Method
.	O
	
The	O
difference	O
to	O
classical	O
regularizers	B-Method
is	O
that	O
we	O
induce	O
smoothness	O
only	O
on	O
the	O
manifold	O
of	O
likely	O
inputs	O
instead	O
of	O
over	O
the	O
entire	O
input	O
domain	O
.	O
	
For	O
further	O
analysis	O
about	O
the	O
importance	O
of	O
the	O
gradient	O
of	O
the	O
mapping	O
function	O
,	O
see	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
RELATED	O
WORK	O
	
There	O
is	O
a	O
large	O
body	O
of	O
previous	O
work	O
on	O
semi	B-Task
-	I-Task
supervised	I-Task
learning	I-Task
	
[	O
reference	O
]	O
.	O
In	O
here	O
we	O
will	O
concentrate	O
on	O
the	O
ones	O
that	O
are	O
most	O
directly	O
connected	O
to	O
our	O
work	O
.	O
	
Γ	B-Method
-	I-Method
model	I-Method
is	O
a	O
subset	O
of	O
a	O
ladder	B-Method
network	I-Method
[	O
reference	O
]	O
that	O
introduces	O
lateral	O
connections	O
into	O
an	O
encoder	B-Method
-	I-Method
decoder	I-Method
type	I-Method
network	I-Method
architecture	I-Method
,	O
targeted	O
at	O
semi	B-Task
-	I-Task
supervised	I-Task
learning	I-Task
.	O
	
In	O
Γ	B-Method
-	I-Method
model	I-Method
,	O
all	O
but	O
the	O
highest	O
lateral	O
connections	O
in	O
the	O
ladder	B-Method
network	I-Method
are	O
removed	O
,	O
and	O
after	O
pruning	O
the	O
unnecessary	O
stages	O
,	O
the	O
remaining	O
network	O
consists	O
of	O
two	O
parallel	O
,	O
identical	O
branches	O
.	O
	
One	O
of	O
the	O
branches	O
takes	O
the	O
original	O
training	O
inputs	O
,	O
whereas	O
the	O
other	O
branch	O
is	O
given	O
the	O
same	O
input	O
corrupted	O
with	O
noise	O
.	O
	
The	O
unsupervised	B-Metric
loss	I-Metric
term	I-Metric
is	O
computed	O
as	O
the	O
squared	O
difference	O
between	O
the	O
(	O
pre	O
-	O
activation	O
)	O
output	O
of	O
the	O
clean	O
branch	O
and	O
a	O
denoised	O
(	O
pre	O
-	O
activation	O
)	O
output	O
of	O
the	O
corrupted	O
branch	O
.	O
	
The	O
denoised	B-Method
estimate	I-Method
is	O
computed	O
from	O
the	O
output	O
of	O
the	O
corrupted	O
branch	O
using	O
a	O
parametric	B-Method
nonlinearity	I-Method
that	O
has	O
10	O
auxiliary	O
trainable	O
parameters	O
per	O
unit	O
.	O
	
Our	O
Π	B-Method
-	I-Method
model	I-Method
differs	O
from	O
the	O
Γ	B-Method
-	I-Method
model	I-Method
in	O
removing	O
the	O
parametric	O
nonlinearity	O
and	O
denoising	B-Method
,	O
having	O
two	O
corrupted	O
paths	O
,	O
and	O
comparing	O
the	O
outputs	O
of	O
the	O
network	O
instead	O
of	O
pre	O
-	O
activation	O
data	O
of	O
the	O
final	O
layer	O
.	O
	
[	O
reference	O
]	O
recently	O
introduced	O
a	O
new	O
loss	B-Method
function	I-Method
for	O
semi	B-Task
-	I-Task
supervised	I-Task
learning	I-Task
,	O
so	O
called	O
transform	B-Metric
/	I-Metric
stability	I-Metric
loss	I-Metric
,	O
which	O
is	O
founded	O
on	O
the	O
same	O
principle	O
as	O
our	O
work	O
.	O
	
During	O
training	B-Task
,	O
they	O
run	O
augmentation	B-Method
and	O
network	B-Task
evaluation	I-Task
n	O
times	O
for	O
each	O
minibatch	O
,	O
and	O
then	O
compute	O
an	O
unsupervised	B-Metric
loss	I-Metric
term	I-Metric
as	O
the	O
sum	O
of	O
all	O
pairwise	O
squared	O
distances	O
between	O
the	O
obtained	O
n	O
network	O
outputs	O
.	O
	
As	O
such	O
,	O
their	O
technique	O
follows	O
the	O
general	O
pseudo	B-Method
-	I-Method
ensemble	I-Method
agreement	I-Method
(	O
PEA	B-Method
)	O
regularization	O
framework	O
of	O
[	O
reference	O
]	O
.	O
	
In	O
addition	O
,	O
they	O
employ	O
a	O
mutual	O
exclusivity	O
loss	O
term	O
[	O
reference	O
]	O
)	O
that	O
we	O
do	O
not	O
use	O
.	O
	
Our	O
Π	B-Method
-	I-Method
model	I-Method
can	O
be	O
seen	O
as	O
a	O
special	O
case	O
of	O
the	O
transform	O
/	O
stability	O
loss	O
obtained	O
by	O
setting	O
n	O
=	O
2	O
.	O
	
The	O
computational	B-Metric
cost	I-Metric
of	O
training	B-Task
with	O
transform	B-Metric
/	I-Metric
stability	I-Metric
loss	I-Metric
increases	O
linearly	O
as	O
a	O
function	O
of	O
n	O
,	O
whereas	O
the	O
efficiency	O
of	O
our	O
temporal	B-Method
ensembling	I-Method
technique	I-Method
remains	O
constant	O
regardless	O
of	O
how	O
large	O
effective	O
ensemble	O
we	O
obtain	O
via	O
the	O
averaging	O
of	O
previous	O
epochs	O
'	O
predictions	O
.	O
	
In	O
bootstrap	B-Task
aggregating	I-Task
,	O
or	O
bagging	B-Task
,	O
multiple	B-Method
networks	I-Method
are	O
trained	O
independently	O
based	O
on	O
subsets	O
of	O
training	O
data	O
	
[	O
reference	O
]	O
.	O
	
This	O
results	O
in	O
an	O
ensemble	O
that	O
is	O
more	O
stable	O
and	O
accurate	O
than	O
the	O
individual	O
networks	O
.	O
	
Our	O
approach	O
can	O
be	O
seen	O
as	O
pulling	O
the	O
predictions	O
from	O
an	O
implicit	B-Method
ensemble	I-Method
that	O
is	O
based	O
on	O
a	O
single	O
network	O
,	O
and	O
the	O
variability	O
is	O
a	O
result	O
of	O
evaluating	O
it	O
under	O
different	O
dropout	O
and	O
augmentation	O
conditions	O
instead	O
of	O
training	O
on	O
different	O
subsets	O
of	O
data	O
.	O
	
In	O
work	O
parallel	O
to	O
ours	O
,	O
[	O
reference	O
]	O
store	O
multiple	O
snapshots	O
of	O
the	O
network	O
during	O
training	O
,	O
hopefully	O
corresponding	O
to	O
different	O
local	O
minima	O
,	O
and	O
use	O
them	O
as	O
an	O
explicit	O
ensemble	O
.	O
	
The	O
general	O
technique	O
of	O
inferring	B-Task
new	I-Task
labels	I-Task
from	O
partially	O
labeled	O
data	O
is	O
often	O
referred	O
to	O
as	O
bootstrapping	B-Method
or	O
self	B-Task
-	I-Task
training	I-Task
,	O
and	O
it	O
was	O
first	O
proposed	O
by	O
[	O
reference	O
]	O
in	O
the	O
context	O
of	O
linguistic	B-Task
analysis	I-Task
.	O
	
[	O
reference	O
]	O
analyze	O
Yarowsky	B-Method
's	I-Method
algorithm	I-Method
and	O
propose	O
a	O
novel	O
graph	B-Method
-	I-Method
based	I-Method
label	I-Method
propagation	I-Method
approach	I-Method
.	O
	
Similarly	O
,	O
label	B-Method
propagation	I-Method
methods	I-Method
[	O
reference	O
]	O
infer	O
labels	O
for	O
unlabeled	O
training	O
data	O
by	O
comparing	O
the	O
associated	O
inputs	O
to	O
labeled	O
training	O
inputs	O
using	O
a	O
suitable	O
distance	B-Metric
metric	I-Metric
.	O
	
Our	O
approach	O
differs	O
from	O
this	O
in	O
two	O
important	O
ways	O
.	O
	
Firstly	O
,	O
we	O
never	O
compare	O
training	O
inputs	O
against	O
each	O
other	O
,	O
but	O
instead	O
only	O
rely	O
on	O
the	O
unknown	O
labels	O
remaining	O
constant	O
,	O
and	O
secondly	O
,	O
we	O
let	O
the	O
network	O
produce	O
the	O
likely	O
classifications	O
for	O
the	O
unlabeled	O
inputs	O
instead	O
of	O
providing	O
them	O
through	O
an	O
outside	B-Method
process	I-Method
.	O
	
In	O
addition	O
to	O
partially	O
labeled	O
data	O
,	O
considerable	O
amount	O
of	O
effort	O
has	O
been	O
put	O
into	O
dealing	O
with	O
densely	O
but	O
inaccurately	O
labeled	O
data	O
.	O
	
This	O
can	O
be	O
seen	O
as	O
a	O
semi	B-Task
-	I-Task
supervised	I-Task
learning	I-Task
task	I-Task
where	O
part	O
of	O
the	O
training	B-Task
process	I-Task
is	O
to	O
identify	O
the	O
labels	O
that	O
are	O
not	O
to	O
be	O
trusted	O
.	O
	
For	O
recent	O
work	O
in	O
this	O
area	O
,	O
see	O
,	O
e.g.	O
,	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
.	O
	
In	O
this	O
context	O
of	O
noisy	O
labels	O
,	O
[	O
reference	O
]	O
presented	O
a	O
simple	O
bootstrapping	B-Method
method	I-Method
that	O
trains	O
a	O
classifier	B-Method
with	O
the	O
target	O
composed	O
of	O
a	O
convex	O
combination	O
of	O
the	O
previous	O
epoch	O
output	O
and	O
the	O
known	O
but	O
potentially	O
noisy	O
labels	O
.	O
	
Our	O
temporal	B-Method
ensembling	I-Method
differs	O
from	O
this	O
by	O
taking	O
into	O
account	O
the	O
evaluations	O
over	O
multiple	O
epochs	O
.	O
	
Generative	B-Method
Adversarial	I-Method
Networks	I-Method
(	I-Method
GAN	I-Method
)	I-Method
have	O
been	O
recently	O
used	O
for	O
semi	B-Task
-	I-Task
supervised	I-Task
learning	I-Task
with	O
promising	O
results	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
It	O
Additive	O
Gaussian	O
noise	O
σ	O
=	O
0.15	O
conv1a	O
128	O
filters	O
,	O
3	O
×	O
3	O
,	O
pad	O
=	O
'	O
same	O
'	O
,	O
LReLU	O
(	O
α	O
=	O
0.1	O
)	O
	
conv1b	O
128	O
filters	O
,	O
3	O
×	O
3	O
,	O
pad	O
=	O
	
'	O
same	O
'	O
,	O
LReLU	O
(	O
α	O
=	O
0.1	O
)	O
conv1c	O
128	O
filters	O
,	O
3	O
×	O
3	O
,	O
pad	O
	
=	O
'	O
same	O
'	O
,	O
LReLU	O
(	O
α	O
=	O
0.1	O
)	O
	
pool1	O
	
Maxpool	O
2	O
×	O
2	O
pixels	O
drop1	O
Dropout	O
,	O
p	O
=	O
0.5	O
conv2a	O
256	O
filters	O
,	O
3	O
×	O
3	O
,	O
pad	O
=	O
'	O
same	O
'	O
,	O
	
LReLU	B-Method
	
(	O
α	O
=	O
0.1	O
)	O
conv2b	O
256	O
filters	O
,	O
3	O
×	O
3	O
,	O
pad	O
=	O
	
'	O
same	O
'	O
,	O
LReLU	O
(	O
α	O
=	O
0.1	O
)	O
	
conv2c	O
256	O
filters	O
,	O
3	O
×	O
3	O
,	O
pad	O
=	O
'	O
same	O
'	O
,	O
	
LReLU	B-Method
(	O
α	O
=	O
0.1	O
)	O
	
pool2	O
	
Maxpool	O
2	O
×	O
2	O
pixels	O
drop2	O
Dropout	O
,	O
p	O
=	O
0.5	O
conv3a	O
512	O
filters	O
,	O
3	O
×	O
3	O
,	O
pad	O
=	O
'	O
valid	O
'	O
,	O
	
LReLU	B-Method
(	O
α	O
=	O
0.1	O
)	O
	
conv3b	O
256	O
filters	O
,	O
1	O
×	O
1	O
,	O
LReLU	O
(	O
α	O
=	O
0.1	O
)	O
	
conv3c	O
128	O
filters	O
,	O
1	O
×	O
1	O
,	O
LReLU	O
(	O
α	O
=	O
0.1	O
)	O
	
pool3	O
	
Global	O
average	O
pool	O
(	O
6	O
×	O
6	O
→	O
1×1	O
pixels	O
)	O
dense	O
Fully	O
connected	O
128	O
→	O
10	O
output	O
Softmax	B-Method
could	O
be	O
an	O
interesting	O
avenue	O
for	O
future	O
work	O
to	O
incorporate	O
a	O
generative	B-Method
component	I-Method
to	O
our	O
solution	O
.	O
	
We	O
also	O
envision	O
that	O
our	O
methods	O
could	O
be	O
applied	O
to	O
regression	B-Task
-	I-Task
type	I-Task
learning	I-Task
tasks	I-Task
.	O
	
[	O
reference	O
]	O
.	O
All	O
data	O
layers	O
were	O
initialized	O
following	O
[	O
reference	O
]	O
,	O
and	O
we	O
applied	O
weight	B-Method
normalization	I-Method
and	O
mean	B-Method
-	I-Method
only	I-Method
batch	I-Method
normalization	I-Method
[	O
reference	O
]	O
with	O
momentum	O
0.999	O
to	O
all	O
of	O
them	O
.	O
	
We	O
used	O
leaky	B-Method
ReLU	I-Method
[	O
reference	O
]	O
with	O
α	O
=	O
0.1	O
as	O
the	O
non	O
-	O
linearity	O
,	O
and	O
chose	O
to	O
use	O
max	B-Method
pooling	I-Method
instead	O
of	O
strided	B-Method
convolutions	I-Method
because	O
it	O
gave	O
consistently	O
better	O
results	O
in	O
our	O
experiments	O
.	O
	
All	O
networks	O
were	O
trained	O
using	O
Adam	B-Method
(	O
Kingma	O
&	O
Ba	O
,	O
2014	O
)	O
with	O
a	O
maximum	B-Metric
learning	I-Metric
rate	I-Metric
of	O
λ	O
max	O
=	O
0.003	O
,	O
except	O
for	O
temporal	B-Task
ensembling	I-Task
in	O
the	O
SVHN	B-Material
case	O
where	O
a	O
maximum	B-Metric
learning	I-Metric
rate	I-Metric
of	O
λ	O
max	O
=	O
0.001	O
worked	O
better	O
.	O
	
Adam	O
momentum	O
parameters	O
were	O
set	O
to	O
β	O
1	O
=	O
0.9	O
and	O
β	O
2	O
=	O
0.999	O
as	O
suggested	O
in	O
the	O
paper	O
.	O
	
The	O
maximum	O
value	O
for	O
the	O
unsupervised	B-Method
loss	I-Method
component	I-Method
was	O
set	O
to	O
w	O
max	O
·	O
M	O
/	O
N	O
,	O
where	O
M	O
is	O
the	O
number	O
of	O
labeled	O
inputs	O
and	O
N	O
is	O
the	O
total	O
number	O
of	O
training	O
inputs	O
.	O
	
For	O
Π	B-Method
-	I-Method
model	I-Method
runs	O
,	O
we	O
used	O
w	O
max	O
=	O
100	O
in	O
all	O
runs	O
except	O
for	O
CIFAR	O
-	O
100	O
with	O
Tiny	O
Images	O
where	O
we	O
set	O
w	O
max	O
=	O
300	O
.	O
	
For	O
temporal	B-Task
ensembling	I-Task
we	O
used	O
w	O
max	O
=	O
30	O
in	O
most	O
runs	O
.	O
	
For	O
the	O
corrupted	B-Task
label	I-Task
test	I-Task
in	O
Section	O
3.5	O
we	O
used	O
w	O
max	O
=	O
300	O
for	O
0	O
%	O
and	O
20	O
%	O
corruption	B-Metric
,	O
and	O
w	O
max	O
=	O
3000	O
for	O
corruption	B-Metric
of	O
50	O
%	O
and	O
higher	O
.	O
	
For	O
basic	O
CIFAR	O
-	O
100	O
runs	O
we	O
used	O
w	O
max	O
=	O
100	O
,	O
and	O
for	O
CIFAR	O
-	O
100	O
with	O
Tiny	O
Images	O
we	O
used	O
w	O
max	O
=	O
1000	O
.	O
	
The	O
accumulation	O
decay	O
constant	O
of	O
temporal	O
ensembling	O
was	O
set	O
to	O
α	O
=	O
0.6	O
in	O
all	O
runs	O
.	O
	
In	O
all	O
runs	O
we	O
ramped	O
up	O
both	O
the	O
learning	B-Metric
rate	I-Metric
λ	I-Metric
and	O
unsupervised	B-Method
loss	I-Method
component	I-Method
weight	I-Method
w	I-Method
during	O
the	O
first	O
80	O
epochs	O
using	O
a	O
Gaussian	O
ramp	O
-	O
up	O
curve	O
exp	O
[	O
−5	O
(	O
1	O
−	O
T	O
)	O
2	O
]	O
,	O
where	O
T	O
advances	O
linearly	O
from	O
zero	O
to	O
one	O
during	O
the	O
ramp	O
-	O
up	O
period	O
.	O
	
In	O
addition	O
to	O
ramp	O
-	O
up	O
,	O
we	O
annealed	O
the	O
learning	O
rate	O
λ	O
to	O
zero	O
and	O
Adam	O
β	O
1	O
to	O
0.5	O
during	O
the	O
last	O
50	O
epochs	O
,	O
but	O
otherwise	O
we	O
did	O
not	O
decay	O
them	O
during	O
training	O
.	O
	
The	O
ramp	B-Method
-	I-Method
down	I-Method
curve	I-Method
was	O
similar	O
to	O
the	O
ramp	O
-	O
up	O
curve	O
but	O
time	O
-	O
reversed	O
and	O
with	O
a	O
scaling	O
constant	O
of	O
12.5	O
instead	O
of	O
5	O
.	O
	
All	O
networks	O
were	O
trained	O
for	O
300	O
epochs	O
with	O
minibatch	O
size	O
of	O
100	O
.	O
	
section	O
:	O
CIFAR	B-Material
-	I-Material
10	I-Material
	
Following	O
previous	O
work	O
in	O
fully	B-Task
supervised	I-Task
learning	I-Task
,	O
we	O
pre	O
-	O
processed	O
the	O
images	O
using	O
ZCA	B-Method
and	O
augmented	O
the	O
dataset	O
using	O
horizontal	O
flips	O
and	O
random	O
translations	O
.	O
	
The	O
translations	O
were	O
drawn	O
from	O
[	O
−2	O
,	O
2	O
]	O
pixels	O
,	O
and	O
were	O
independently	O
applied	O
to	O
both	O
branches	O
in	O
the	O
Π	B-Method
-	I-Method
model	I-Method
.	O
	
section	O
:	O
SVHN	B-Material
	
We	O
pre	O
-	O
processed	O
the	O
input	O
images	O
by	O
biasing	O
and	O
scaling	O
each	O
input	O
image	O
to	O
zero	O
mean	O
and	O
unit	O
variance	O
.	O
	
We	O
used	O
only	O
the	O
73257	O
items	O
in	O
the	O
official	O
training	O
set	O
,	O
i.e.	O
,	O
did	O
not	O
use	O
the	O
provided	O
531131	O
extra	O
items	O
.	O
	
The	O
training	O
setups	O
were	O
otherwise	O
similar	O
to	O
CIFAR	B-Material
-	I-Material
10	I-Material
except	O
that	O
horizontal	O
flips	O
were	O
not	O
used	O
.	O
	
section	O
:	O
Implementation	O
	
Our	O
implementation	O
is	O
written	O
in	O
Python	B-Method
using	O
Theano	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
,	O
and	O
is	O
available	O
at	O
https:	O
//	O
github.com	O
/	O
smlaine2	O
/	O
tempens	O
.	O
	
Model	B-Method
convergence	I-Method
	
As	O
discussed	O
in	O
Section	O
2.1	O
,	O
a	O
slow	O
ramp	O
-	O
up	O
of	O
the	O
unsupervised	B-Metric
cost	I-Metric
is	O
very	O
important	O
for	O
getting	O
the	O
models	O
to	O
converge	O
.	O
	
Furthermore	O
,	O
in	O
our	O
very	O
preliminary	O
tests	O
with	O
250	O
labels	O
in	O
SVHN	B-Material
we	O
noticed	O
that	O
optimization	B-Task
tended	O
to	O
explode	O
during	O
the	O
ramp	O
-	O
up	O
period	O
,	O
and	O
we	O
eventually	O
found	O
that	O
using	O
a	O
lower	O
value	O
for	O
Adam	O
β	O
2	O
parameter	O
(	O
e.g.	O
,	O
0.99	O
instead	O
of	O
0.999	O
)	O
seems	O
to	O
help	O
in	O
this	O
regard	O
.	O
	
We	O
do	O
not	O
attempt	O
to	O
guarantee	O
that	O
the	O
occurrence	O
of	O
labeled	O
inputs	O
during	O
training	O
would	O
be	O
somehow	O
stratified	O
;	O
with	O
bad	O
luck	O
there	O
might	O
be	O
several	O
consecutive	O
minibatches	O
without	O
any	O
labeled	O
inputs	O
when	O
the	O
label	O
density	O
is	O
very	O
low	O
.	O
	
Some	O
previous	O
work	O
has	O
identified	O
this	O
as	O
a	O
weakness	O
,	O
and	O
have	O
solved	O
the	O
issue	O
by	O
shuffling	O
the	O
input	O
sequences	O
in	O
such	O
a	O
way	O
that	O
stratification	B-Task
is	O
guaranteed	O
,	O
e.g.	O
[	O
reference	O
]	O
(	O
confirmed	O
from	O
the	O
authors	O
)	O
.	O
	
This	O
kind	O
of	O
stratification	O
might	O
further	O
improve	O
the	O
convergence	B-Metric
of	O
our	O
methods	O
as	O
well	O
.	O
	
Tiny	O
Images	O
,	O
extra	O
data	O
from	O
restricted	O
categories	O
	
The	O
restricted	O
extra	O
data	O
in	O
Section	O
3.3	O
was	O
extracted	O
from	O
Tiny	O
Images	O
by	O
picking	O
all	O
images	O
with	O
labels	O
corresponding	O
to	O
the	O
100	O
categories	O
used	O
in	O
CIFAR	O
-	O
100	O
.	O
	
As	O
the	O
Tiny	O
Images	O
dataset	O
does	O
not	O
contain	O
CIFAR	O
-	O
100	O
categories	O
aquarium	O
fish	O
and	O
maple	O
tree	O
,	O
we	O
used	O
images	O
with	O
labels	O
fish	O
and	O
maple	O
instead	O
.	O
	
The	O
result	O
was	O
a	O
total	O
of	O
237	O
203	O
images	O
that	O
were	O
used	O
as	O
unlabeled	O
extra	O
data	O
.	O
	
Table	O
6	O
shows	O
the	O
composition	O
of	O
this	O
extra	O
data	O
set	O
.	O
	
It	O
is	O
worth	O
noting	O
that	O
the	O
CIFAR	O
-	O
100	O
dataset	O
itself	O
is	O
a	O
subset	O
of	O
Tiny	O
Images	O
,	O
and	O
we	O
did	O
not	O
explicitly	O
prevent	O
overlap	O
between	O
this	O
extra	O
set	O
and	O
CIFAR	O
-	O
100	O
.	O
	
This	O
led	O
to	O
approximately	O
a	O
third	O
of	O
the	O
CIFAR	O
-	O
100	O
training	O
and	O
test	O
images	O
being	O
present	O
as	O
unlabeled	O
inputs	O
in	O
the	O
extra	O
set	O
.	O
	
The	O
other	O
test	O
with	O
500k	O
extra	O
entries	O
picked	O
randomly	O
out	O
of	O
all	O
79	O
million	O
images	O
had	O
a	O
negligible	O
overlap	O
with	O
CIFAR	O
-	O
100	O
.	O
	
section	O
:	O
	
section	O
:	O
ACKNOWLEDGEMENTS	O
	
We	O
thank	O
the	O
anonymous	O
reviewers	O
,	O
Tero	O
Karras	O
,	O
Pekka	O
Jänis	O
,	O
Tim	O
Salimans	O
,	O
Ian	O
Goodfellow	O
,	O
as	O
well	O
as	O
Harri	O
Valpola	O
and	O
his	O
colleagues	O
at	O
Curious	O
AI	O
for	O
valuable	O
suggestions	O
that	O
helped	O
to	O
improve	O
this	O
article	O
.	O
	
section	O
:	O
	
section	O
:	O
	
:	O
The	O
Tiny	O
Images	O
[	O
reference	O
]	O
labels	O
and	O
image	O
counts	O
used	O
in	O
the	O
CIFAR	O
-	O
100	O
plus	O
restricted	O
extra	O
data	O
tests	O
(	O
rightmost	O
column	O
of	O
Table	O
4	O
)	O
.	O
	
Note	O
that	O
the	O
extra	O
input	O
images	O
were	O
supplied	O
as	O
unlabeled	O
data	O
for	O
our	O
networks	O
,	O
and	O
the	O
labels	O
were	O
used	O
only	O
for	O
narrowing	O
down	O
the	O
full	O
set	O
of	O
79	O
million	O
images	O
.	O
	
section	O
:	O
	
Improving	O
Neural	B-Method
Machine	I-Method
Translation	I-Method
Models	I-Method
with	O
Monolingual	B-Method
Data	I-Method
	
section	O
:	O
Abstract	O
	
Neural	B-Task
Machine	I-Task
Translation	I-Task
(	O
NMT	B-Task
)	I-Task
has	O
obtained	O
state	O
-	O
of	O
-	O
the	O
art	O
performance	O
for	O
several	O
language	O
pairs	O
,	O
while	O
only	O
using	O
parallel	O
data	O
for	O
training	O
.	O
	
Targetside	O
monolingual	B-Method
data	I-Method
plays	O
an	O
important	O
role	O
in	O
boosting	B-Task
fluency	I-Task
for	O
phrasebased	B-Task
statistical	I-Task
machine	I-Task
translation	I-Task
,	O
and	O
we	O
investigate	O
the	O
use	O
of	O
monolingual	B-Method
data	I-Method
for	O
NMT	B-Task
.	O
	
In	O
contrast	O
to	O
previous	O
work	O
,	O
which	O
combines	O
NMT	B-Method
models	I-Method
with	O
separately	O
trained	O
language	B-Method
models	I-Method
,	O
we	O
note	O
that	O
encoder	B-Method
-	I-Method
decoder	I-Method
NMT	I-Method
architectures	I-Method
already	O
have	O
the	O
capacity	O
to	O
learn	O
the	O
same	O
information	O
as	O
a	O
language	B-Method
model	I-Method
,	O
and	O
we	O
explore	O
strategies	O
to	O
train	O
with	O
monolingual	B-Method
data	O
without	O
changing	O
the	O
neural	B-Method
network	I-Method
architecture	I-Method
.	O
	
By	O
pairing	O
monolingual	B-Method
training	I-Method
data	I-Method
with	O
an	O
automatic	O
backtranslation	O
,	O
we	O
can	O
treat	O
it	O
as	O
additional	O
parallel	O
training	O
data	O
,	O
and	O
we	O
obtain	O
substantial	O
improvements	O
on	O
the	O
WMT	B-Task
15	I-Task
task	I-Task
English↔German	I-Task
	
(	O
+	O
2.8	O
-	O
3.7	O
BLEU	B-Metric
)	O
,	O
and	O
for	O
the	O
low	B-Task
-	I-Task
resourced	I-Task
IWSLT	I-Task
14	I-Task
task	I-Task
Turkish→English	I-Task
(	O
+	O
2.1	O
-	O
3.4	O
BLEU	B-Metric
)	O
,	O
obtaining	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
.	O
	
We	O
also	O
show	O
that	O
fine	O
-	O
tuning	O
on	O
in	O
-	O
domain	O
monolingual	B-Method
and	O
parallel	O
data	O
gives	O
substantial	O
improvements	O
for	O
the	O
IWSLT	B-Task
15	I-Task
task	I-Task
English→German	I-Task
.	O
	
section	O
:	O
Introduction	O
	
Neural	B-Task
Machine	I-Task
Translation	I-Task
(	O
NMT	B-Task
)	I-Task
has	O
obtained	O
state	O
-	O
of	O
-	O
the	O
art	O
performance	O
for	O
several	O
language	O
pairs	O
,	O
while	O
only	O
using	O
parallel	O
data	O
for	O
training	O
.	O
	
Target	O
-	O
side	O
monolingual	B-Method
data	I-Method
plays	O
an	O
important	O
role	O
in	O
boosting	B-Task
fluency	I-Task
for	O
phrase	B-Task
-	I-Task
based	I-Task
statisti	I-Task
-	I-Task
	
The	O
research	O
presented	O
in	O
this	O
publication	O
was	O
conducted	O
in	O
cooperation	O
with	O
Samsung	O
Electronics	O
Polska	O
sp	O
.	O
	
z	O
o.o	O
.	O
	
-	O
Samsung	O
R	O
&	O
D	O
Institute	O
Poland	O
.	O
	
cal	O
machine	B-Task
translation	I-Task
,	O
and	O
we	O
investigate	O
the	O
use	O
of	O
monolingual	B-Method
data	I-Method
for	O
NMT	B-Task
.	O
	
Language	B-Method
models	I-Method
trained	O
on	O
monolingual	B-Method
data	I-Method
have	O
played	O
a	O
central	O
role	O
in	O
statistical	B-Task
machine	I-Task
translation	I-Task
since	O
the	O
first	O
IBM	B-Method
models	I-Method
[	O
reference	O
]	O
)	O
.	O
	
There	O
are	O
two	O
major	O
reasons	O
for	O
their	O
importance	O
.	O
	
Firstly	O
,	O
word	B-Method
-	I-Method
based	I-Method
and	I-Method
phrase	I-Method
-	I-Method
based	I-Method
translation	I-Method
models	I-Method
make	O
strong	O
independence	O
assumptions	O
,	O
with	O
the	O
probability	O
of	O
translation	O
units	O
estimated	O
independently	O
from	O
context	O
,	O
and	O
language	B-Method
models	I-Method
,	O
by	O
making	O
different	O
independence	O
assumptions	O
,	O
can	O
model	O
how	O
well	O
these	O
translation	O
units	O
fit	O
together	O
.	O
	
Secondly	O
,	O
the	O
amount	O
of	O
available	O
monolingual	B-Method
data	I-Method
in	O
the	O
target	O
language	O
typically	O
far	O
exceeds	O
the	O
amount	O
of	O
parallel	O
data	O
,	O
and	O
models	O
typically	O
improve	O
when	O
trained	O
on	O
more	O
data	O
,	O
or	O
data	O
more	O
similar	O
to	O
the	O
translation	B-Task
task	I-Task
.	O
	
In	O
(	O
attentional	B-Method
)	I-Method
encoder	I-Method
-	I-Method
decoder	I-Method
architectures	I-Method
for	O
neural	B-Task
machine	I-Task
translation	I-Task
[	O
reference	O
][	O
reference	O
]	O
,	O
the	O
decoder	B-Method
is	O
essentially	O
an	O
RNN	B-Method
language	I-Method
model	I-Method
that	O
is	O
also	O
conditioned	O
on	O
source	O
context	O
,	O
so	O
the	O
first	O
rationale	O
,	O
adding	O
a	O
language	B-Method
model	I-Method
to	O
compensate	O
for	O
the	O
independence	O
assumptions	O
of	O
the	O
translation	B-Method
model	I-Method
,	O
does	O
not	O
apply	O
.	O
	
However	O
,	O
the	O
data	O
argument	O
is	O
still	O
valid	O
in	O
NMT	B-Task
,	O
and	O
we	O
expect	O
monolingual	B-Method
data	I-Method
to	O
be	O
especially	O
helpful	O
if	O
parallel	O
data	O
is	O
sparse	O
,	O
or	O
a	O
poor	O
fit	O
for	O
the	O
translation	B-Task
task	I-Task
,	O
for	O
instance	O
because	O
of	O
a	O
domain	O
mismatch	O
.	O
	
In	O
contrast	O
to	O
previous	O
work	O
,	O
which	O
integrates	O
a	O
separately	O
trained	O
RNN	B-Method
language	I-Method
model	I-Method
into	O
the	O
NMT	B-Method
model	I-Method
[	O
reference	O
]	O
,	O
we	O
explore	O
strategies	O
to	O
include	O
monolingual	B-Method
training	I-Method
data	I-Method
in	O
the	O
training	O
process	O
without	O
changing	O
the	O
neural	B-Method
network	I-Method
architecture	I-Method
.	O
	
This	O
makes	O
our	O
approach	O
applicable	O
to	O
different	O
NMT	B-Method
architectures	I-Method
.	O
	
The	O
main	O
contributions	O
of	O
this	O
paper	O
are	O
as	O
follows	O
:	O
	
•	O
	
we	O
show	O
that	O
we	O
can	O
improve	O
the	O
machine	B-Metric
translation	I-Metric
quality	I-Metric
of	O
NMT	B-Method
systems	I-Method
by	O
mixing	O
monolingual	B-Method
target	I-Method
sentences	I-Method
into	O
the	O
training	O
set	O
.	O
	
•	O
	
we	O
investigate	O
two	O
different	O
methods	O
to	O
fill	O
the	O
source	O
side	O
of	O
monolingual	B-Method
training	I-Method
instances	O
:	O
using	O
a	O
dummy	O
source	O
sentence	O
,	O
and	O
using	O
a	O
source	O
sentence	O
obtained	O
via	O
backtranslation	B-Method
,	O
which	O
we	O
call	O
synthetic	O
.	O
	
We	O
find	O
that	O
the	O
latter	O
is	O
more	O
effective	O
.	O
	
•	O
we	O
successfully	O
adapt	O
NMT	B-Method
models	I-Method
to	O
a	O
new	O
domain	O
by	O
fine	O
-	O
tuning	O
with	O
either	O
monolingual	B-Method
or	O
parallel	O
in	O
-	O
domain	O
data	O
.	O
	
section	O
:	O
Neural	B-Task
Machine	I-Task
Translation	I-Task
	
We	O
follow	O
the	O
neural	B-Method
machine	I-Method
translation	I-Method
architecture	I-Method
by	O
[	O
reference	O
]	O
,	O
which	O
we	O
will	O
briefly	O
summarize	O
here	O
.	O
	
However	O
,	O
we	O
note	O
that	O
our	O
approach	O
is	O
not	O
specific	O
to	O
this	O
architecture	O
.	O
	
The	O
neural	B-Method
machine	I-Method
translation	I-Method
system	I-Method
is	O
implemented	O
as	O
an	O
encoder	B-Method
-	I-Method
decoder	I-Method
network	I-Method
with	O
recurrent	B-Method
neural	I-Method
networks	I-Method
.	O
	
The	O
encoder	B-Method
is	O
a	O
bidirectional	B-Method
neural	I-Method
network	I-Method
with	O
gated	B-Method
recurrent	I-Method
units	I-Method
[	O
reference	O
]	O
that	O
reads	O
an	O
input	O
sequence	O
x	O
=	O
(	O
x	O
1	O
,	O
...	O
,	O
x	O
m	O
)	O
and	O
calculates	O
a	O
forward	O
sequence	O
of	O
hidden	O
states	O
(	O
−	O
→	O
h	O
1	O
,	O
...	O
,	O
−	O
→	O
h	O
m	O
)	O
,	O
and	O
a	O
backward	O
sequence	O
	
The	O
hidden	O
states	O
−	O
→	O
h	O
j	O
and	O
←	O
	
−	O
h	O
j	O
are	O
concatenated	O
to	O
obtain	O
the	O
annotation	O
vector	O
	
h	O
j	O
.	O
	
The	O
decoder	B-Method
is	O
a	O
recurrent	B-Method
neural	I-Method
network	I-Method
that	O
predicts	O
a	O
target	O
sequence	O
y	O
=	O
	
(	O
y	O
1	O
,	O
...	O
,	O
y	O
n	O
)	O
.	O
	
Each	O
word	O
y	O
i	O
is	O
predicted	O
based	O
on	O
a	O
recurrent	O
hidden	O
state	O
s	O
	
i	O
,	O
the	O
previously	O
predicted	O
word	O
y	O
i−1	O
,	O
and	O
a	O
context	O
vector	O
c	O
i	O
.	O
	
c	O
	
i	O
is	O
computed	O
as	O
a	O
weighted	O
sum	O
of	O
the	O
annotations	O
	
h	O
j	O
.	O
	
The	O
weight	O
of	O
each	O
annotation	O
h	O
j	O
is	O
computed	O
through	O
an	O
alignment	B-Method
model	I-Method
α	I-Method
ij	I-Method
,	O
which	O
models	O
the	O
probability	O
that	O
y	O
i	O
is	O
aligned	O
to	O
x	O
j	O
.	O
	
The	O
alignment	B-Method
model	I-Method
is	O
a	O
singlelayer	B-Method
feedforward	I-Method
neural	I-Method
network	I-Method
that	O
is	O
learned	O
jointly	O
with	O
the	O
rest	O
of	O
the	O
network	O
through	O
backpropagation	B-Method
.	O
	
A	O
detailed	O
description	O
can	O
be	O
found	O
in	O
[	O
reference	O
]	O
.	O
Training	O
is	O
performed	O
on	O
a	O
parallel	O
corpus	O
with	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
.	O
	
For	O
translation	B-Task
,	O
a	O
beam	B-Method
search	I-Method
with	O
small	O
beam	O
size	O
is	O
employed	O
.	O
	
section	O
:	O
NMT	B-Task
Training	I-Task
with	O
Monolingual	B-Method
Training	I-Method
Data	I-Method
	
In	O
machine	B-Task
translation	I-Task
,	O
more	O
monolingual	B-Method
data	I-Method
(	O
or	O
monolingual	B-Method
data	I-Method
more	O
similar	O
to	O
the	O
test	O
set	O
)	O
serves	O
to	O
improve	O
the	O
estimate	O
of	O
the	O
prior	O
probability	O
p	O
(	O
T	O
)	O
of	O
the	O
target	O
sentence	O
T	O
,	O
before	O
taking	O
the	O
source	O
sentence	O
S	O
into	O
account	O
.	O
	
In	O
contrast	O
to	O
[	O
reference	O
]	O
,	O
who	O
train	O
separate	O
language	B-Method
models	I-Method
on	O
monolingual	B-Method
training	I-Method
data	I-Method
and	O
incorporate	O
them	O
into	O
the	O
neural	B-Method
network	I-Method
through	O
shallow	B-Method
or	I-Method
deep	I-Method
fusion	I-Method
,	O
we	O
propose	O
techniques	O
to	O
train	O
the	O
main	O
NMT	B-Method
model	I-Method
with	O
monolingual	B-Method
data	I-Method
,	O
exploiting	O
the	O
fact	O
that	O
encoder	B-Method
-	I-Method
decoder	I-Method
neural	I-Method
networks	I-Method
already	O
condition	O
the	O
probability	O
distribution	O
of	O
the	O
next	O
target	O
word	O
on	O
the	O
previous	O
target	O
words	O
.	O
	
We	O
describe	O
two	O
strategies	O
to	O
do	O
this	O
:	O
providing	O
monolingual	B-Method
training	I-Method
examples	I-Method
with	O
an	O
empty	O
(	O
or	O
dummy	O
)	O
source	O
sentence	O
,	O
or	O
providing	O
monolingual	B-Method
training	I-Method
data	I-Method
with	O
a	O
synthetic	O
source	O
sentence	O
that	O
is	O
obtained	O
from	O
automatically	O
translating	O
the	O
target	O
sentence	O
into	O
the	O
source	O
language	O
,	O
which	O
we	O
will	O
refer	O
to	O
as	O
back	B-Task
-	I-Task
translation	I-Task
.	O
	
section	O
:	O
Dummy	O
Source	O
Sentences	O
	
The	O
first	O
technique	O
we	O
employ	O
is	O
to	O
treat	O
monolingual	B-Method
training	I-Method
examples	I-Method
as	O
parallel	O
examples	O
with	O
empty	O
source	O
side	O
,	O
essentially	O
adding	O
training	O
examples	O
whose	O
context	O
vector	O
c	O
	
i	O
is	O
uninformative	O
,	O
and	O
for	O
which	O
the	O
network	O
has	O
to	O
fully	O
rely	O
on	O
the	O
previous	O
target	O
words	O
for	O
its	O
prediction	B-Task
.	O
	
This	O
could	O
be	O
conceived	O
as	O
a	O
form	O
of	O
dropout	B-Method
[	O
reference	O
]	O
,	O
with	O
the	O
difference	O
that	O
the	O
training	O
instances	O
that	O
have	O
the	O
context	O
vector	O
dropped	O
out	O
constitute	O
novel	O
training	O
data	O
.	O
	
We	O
can	O
also	O
conceive	O
of	O
this	O
setup	O
as	O
multi	B-Task
-	I-Task
task	I-Task
learning	I-Task
,	O
with	O
the	O
two	O
tasks	O
being	O
translation	B-Task
when	O
the	O
source	O
is	O
known	O
,	O
and	O
language	B-Method
modelling	I-Method
when	O
it	O
is	O
unknown	O
.	O
	
During	O
training	B-Task
,	O
we	O
use	O
both	O
parallel	O
and	O
monolingual	B-Method
training	I-Method
examples	I-Method
in	O
the	O
ratio	O
1	O
-	O
to	O
-	O
1	O
,	O
and	O
randomly	O
shuffle	O
them	O
.	O
	
We	O
define	O
an	O
epoch	O
as	O
one	O
iteration	O
through	O
the	O
parallel	O
data	O
set	O
,	O
and	O
resample	O
from	O
the	O
monolingual	B-Method
data	I-Method
set	O
for	O
every	O
epoch	O
.	O
	
We	O
pair	O
monolingual	B-Method
sentences	I-Method
with	O
a	O
single	O
-	O
word	O
dummy	O
source	O
side	O
<	O
null	O
>	O
to	O
allow	O
processing	O
of	O
both	O
parallel	O
and	O
monolingual	B-Method
training	I-Method
examples	I-Method
with	O
the	O
same	O
network	B-Method
graph	I-Method
.	O
	
1	O
	
For	O
monolingual	B-Method
minibatches	O
2	O
,	O
we	O
freeze	O
the	O
network	O
parameters	O
of	O
the	O
encoder	B-Method
and	O
the	O
attention	B-Method
model	I-Method
.	O
	
One	O
problem	O
with	O
this	O
integration	O
of	O
monolin	O
-	O
gual	O
data	O
is	O
that	O
we	O
can	O
not	O
arbitrarily	O
increase	O
the	O
ratio	O
of	O
monolingual	B-Method
training	I-Method
instances	I-Method
,	O
or	O
finetune	O
a	O
model	O
with	O
only	O
monolingual	B-Method
training	I-Method
data	I-Method
,	O
because	O
different	O
output	O
layer	O
parameters	O
are	O
optimal	O
for	O
the	O
two	O
tasks	O
,	O
and	O
the	O
network	O
'	O
unlearns	O
'	O
its	O
conditioning	O
on	O
the	O
source	O
context	O
if	O
the	O
ratio	O
of	O
monolingual	B-Method
training	I-Method
instances	I-Method
is	O
too	O
high	O
.	O
	
section	O
:	O
Synthetic	O
Source	O
Sentences	O
	
To	O
ensure	O
that	O
the	O
output	B-Method
layer	I-Method
remains	O
sensitive	O
to	O
the	O
source	O
context	O
,	O
and	O
that	O
good	O
parameters	O
are	O
not	O
unlearned	O
from	O
monolingual	B-Method
data	I-Method
,	O
we	O
propose	O
to	O
pair	O
monolingual	B-Method
training	I-Method
instances	O
with	O
a	O
synthetic	O
source	O
sentence	O
from	O
which	O
a	O
context	O
vector	O
can	O
be	O
approximated	O
.	O
	
We	O
obtain	O
these	O
through	O
back	B-Task
-	I-Task
translation	I-Task
,	O
i.e.	O
an	O
automatic	B-Task
translation	I-Task
of	O
the	O
monolingual	B-Method
target	I-Method
text	I-Method
into	O
the	O
source	O
language	O
.	O
	
During	O
training	B-Task
,	O
we	O
mix	O
synthetic	O
parallel	O
text	O
into	O
the	O
original	O
(	O
human	O
-	O
translated	O
)	O
parallel	O
text	O
and	O
do	O
not	O
distinguish	O
between	O
the	O
two	O
:	O
no	O
network	O
parameters	O
are	O
frozen	O
.	O
	
Importantly	O
,	O
only	O
the	O
source	O
side	O
of	O
these	O
additional	O
training	O
examples	O
is	O
synthetic	O
,	O
and	O
the	O
target	O
side	O
comes	O
from	O
the	O
monolingual	B-Method
corpus	O
.	O
	
section	O
:	O
Evaluation	O
	
We	O
evaluate	O
NMT	B-Method
training	I-Method
on	O
parallel	O
text	O
,	O
and	O
with	O
additional	O
monolingual	B-Method
data	I-Method
,	O
on	O
English↔German	O
and	O
Turkish→English	O
,	O
using	O
training	O
and	O
test	O
data	O
from	O
WMT	O
15	O
for	O
English↔German	O
,	O
IWSLT	O
15	O
for	O
English→German	O
,	O
and	O
IWSLT	O
14	O
for	O
Turkish→English	O
.	O
	
section	O
:	O
Data	O
and	O
Methods	O
	
We	O
use	O
Groundhog	O
3	O
as	O
the	O
implementation	O
of	O
the	O
NMT	B-Method
system	I-Method
for	O
all	O
experiments	O
[	O
reference	O
][	O
reference	O
]	O
.	O
	
We	O
generally	O
follow	O
the	O
settings	O
and	O
training	O
procedure	O
described	O
by	O
[	O
reference	O
]	O
.	O
	
For	O
English↔German	O
,	O
we	O
report	O
case	B-Metric
-	I-Metric
sensitive	I-Metric
BLEU	I-Metric
on	O
detokenized	O
text	O
with	O
mteval	O
-	O
v13a.pl	O
for	O
comparison	O
to	O
official	O
WMT	O
and	O
IWSLT	O
results	O
.	O
	
For	O
Turkish→English	O
,	O
we	O
report	O
case	B-Metric
-	I-Metric
sensitive	I-Metric
BLEU	I-Metric
on	O
tokenized	O
text	O
with	O
multi	O
-	O
bleu.perl	O
for	O
comparison	O
to	O
results	O
by	O
[	O
reference	O
]	O
.	O
[	O
reference	O
]	O
determine	O
the	O
network	O
vocabulary	O
based	O
on	O
the	O
parallel	O
training	O
data	O
,	O
and	O
replace	O
out	O
-	O
of	O
-	O
vocabulary	O
words	O
with	O
a	O
special	O
UNK	O
symbol	O
.	O
	
They	O
remove	O
monolingual	B-Method
sentences	I-Method
with	O
more	O
than	O
10	O
%	O
UNK	O
symbols	O
.	O
	
In	O
contrast	O
,	O
we	O
represent	O
unseen	O
words	O
as	O
sequences	O
of	O
subword	O
units	O
[	O
reference	O
]	O
,	O
and	O
can	O
represent	O
any	O
additional	O
training	O
data	O
with	O
the	O
existing	O
network	O
vocabulary	O
that	O
was	O
learned	O
on	O
the	O
parallel	O
data	O
.	O
	
In	O
all	O
experiments	O
,	O
the	O
network	O
vocabulary	O
remains	O
fixed	O
.	O
	
section	O
:	O
English↔German	O
	
We	O
use	O
all	O
parallel	O
training	O
data	O
provided	O
by	O
WMT	O
2015	O
[	O
reference	O
]	O
4	O
.	O
	
We	O
use	O
the	O
News	O
Crawl	O
corpora	O
as	O
additional	O
training	O
data	O
for	O
the	O
experiments	O
with	O
monolingual	B-Method
data	I-Method
.	O
	
The	O
amount	O
of	O
training	O
data	O
is	O
shown	O
in	O
Table	O
1	O
.	O
	
Baseline	B-Method
models	I-Method
are	O
trained	O
for	O
a	O
week	O
.	O
	
Ensembles	B-Method
are	O
sampled	O
from	O
the	O
last	O
4	O
saved	O
models	O
of	O
training	O
(	O
saved	O
at	O
12h	O
-	O
intervals	O
)	O
.	O
	
Each	O
model	O
is	O
fine	O
-	O
tuned	O
with	O
fixed	O
embeddings	O
for	O
12	O
hours	O
.	O
	
For	O
the	O
experiments	O
with	O
synthetic	O
parallel	O
data	O
,	O
we	O
back	O
-	O
translate	O
a	O
random	O
sample	O
of	O
3	O
600	O
000	O
sentences	O
from	O
the	O
German	O
monolingual	B-Method
data	I-Method
set	I-Method
into	O
English	O
.	O
	
The	O
German→English	B-Method
system	I-Method
used	O
for	O
this	O
is	O
the	O
baseline	O
system	O
(	O
parallel	O
)	O
.	O
	
Translation	B-Task
took	O
about	O
a	O
week	O
on	O
an	O
NVIDIA	O
Titan	O
Black	O
GPU	O
.	O
	
For	O
experiments	O
in	O
German→English	O
,	O
we	O
back	O
-	O
translate	O
4	O
200	O
000	O
monolingual	B-Method
English	O
sentences	O
into	O
German	O
,	O
using	O
the	O
English→German	B-Method
system	I-Method
+	I-Method
synthetic	I-Method
.	O
	
Note	O
that	O
we	O
always	O
use	O
single	O
models	O
for	O
backtranslation	B-Task
,	O
not	O
ensembles	O
.	O
	
We	O
leave	O
it	O
to	O
future	O
work	O
to	O
explore	O
how	O
sensitive	O
NMT	B-Method
training	I-Method
with	O
synthetic	O
data	O
is	O
to	O
the	O
quality	O
of	O
the	O
backtranslation	O
.	O
	
We	O
tokenize	O
and	O
truecase	O
the	O
training	O
data	O
,	O
and	O
represent	O
rare	O
words	O
via	O
BPE	B-Method
	
[	O
reference	O
]	O
.	O
	
Specifically	O
,	O
we	O
follow	O
[	O
reference	O
]	O
in	O
performing	O
BPE	B-Method
on	O
the	O
joint	O
vocabulary	O
with	O
89	O
500	O
merge	B-Method
operations	I-Method
.	O
	
dataset	O
sentences	O
	
WIT	O
160	O
000	O
SETimes	O
160	O
000	O
	
Gigaword	O
mono	O
177	O
000	O
000	O
	
Gigaword	O
synth	O
3	O
200	O
000	O
Table	O
2	O
:	O
Turkish→English	O
training	O
data	O
.	O
	
The	O
network	O
vocabulary	O
size	O
is	O
90	O
000	O
.	O
	
We	O
also	O
perform	O
experiments	O
on	O
the	O
IWSLT	O
15	O
test	O
sets	O
to	O
investigate	O
a	O
cross	B-Task
-	I-Task
domain	I-Task
setting	I-Task
.	O
	
[	O
reference	O
]	O
	
The	O
test	O
sets	O
consist	O
of	O
TED	O
talk	O
transcripts	O
.	O
	
As	O
indomain	O
training	O
data	O
,	O
IWSLT	O
provides	O
the	O
WIT	O
3	O
parallel	O
corpus	O
[	O
reference	O
]	O
,	O
which	O
also	O
consists	O
of	O
TED	O
talks	O
.	O
	
section	O
:	O
Turkish→English	O
	
We	O
use	O
data	O
provided	O
for	O
the	O
IWSLT	B-Task
14	I-Task
machine	I-Task
translation	I-Task
track	I-Task
[	O
reference	O
]	O
,	O
namely	O
the	O
WIT	O
3	O
parallel	O
corpus	O
[	O
reference	O
]	O
,	O
which	O
consists	O
of	O
TED	O
talks	O
,	O
and	O
the	O
SETimes	O
corpus	O
(	O
Tyers	O
and	O
Alperen	O
,	O
2010	O
)	O
.	O
	
[	O
reference	O
]	O
	
After	O
removal	O
of	O
sentence	O
pairs	O
which	O
contain	O
empty	O
lines	O
or	O
lines	O
with	O
a	O
length	O
ratio	O
above	O
9	O
,	O
we	O
retain	O
320	O
000	O
sentence	O
pairs	O
of	O
training	O
data	O
.	O
	
For	O
the	O
experiments	O
with	O
monolingual	B-Method
training	I-Method
data	I-Method
,	O
we	O
use	O
the	O
English	O
LDC	O
Gigaword	O
corpus	O
(	O
Fifth	O
Edition	O
)	O
.	O
	
The	O
amount	O
of	O
training	O
data	O
is	O
shown	O
in	O
Table	O
2	O
.	O
	
With	O
only	O
320	O
000	O
sentences	O
of	O
parallel	O
data	O
available	O
for	O
training	O
,	O
this	O
is	O
a	O
much	O
lower	O
-	O
resourced	O
translation	B-Task
setting	I-Task
than	O
English↔German	O
.	O
	
[	O
reference	O
]	O
segment	O
the	O
Turkish	O
text	O
with	O
the	O
morphology	B-Method
tool	I-Method
Zemberek	I-Method
,	O
followed	O
by	O
a	O
disambiguation	B-Task
of	O
the	O
morphological	B-Method
analysis	I-Method
[	O
reference	O
]	O
,	O
and	O
removal	O
of	O
non	O
-	O
surface	O
tokens	O
produced	O
by	O
the	O
analysis	O
.	O
	
We	O
use	O
the	O
same	O
preprocessing	O
7	O
.	O
	
For	O
both	O
Turkish	O
and	O
English	O
,	O
we	O
represent	O
rare	O
words	O
(	O
or	O
morphemes	O
in	O
the	O
case	O
of	O
Turkish	O
)	O
as	O
character	O
bigram	O
sequences	O
[	O
reference	O
]	O
.	O
	
The	O
20	O
000	O
most	O
frequent	O
words	O
(	O
morphemes	O
)	O
are	O
left	O
unsegmented	O
.	O
	
The	O
networks	O
have	O
a	O
vocabulary	O
size	O
of	O
23	O
000	O
symbols	O
.	O
	
To	O
obtain	O
a	O
synthetic	O
parallel	O
training	O
set	O
,	O
we	O
back	O
-	O
translate	O
a	O
random	O
sample	O
of	O
3	O
200	O
000	O
sentences	O
from	O
Gigaword	O
.	O
	
We	O
use	O
an	O
English→Turkish	B-Method
NMT	I-Method
system	I-Method
trained	O
with	O
the	O
same	O
settings	O
as	O
the	O
Turkish→English	B-Method
baseline	I-Method
system	I-Method
.	O
	
We	O
found	O
overfitting	O
to	O
be	O
a	O
bigger	O
problem	O
than	O
with	O
the	O
larger	O
English↔German	O
data	O
set	O
,	O
and	O
follow	O
[	O
reference	O
]	O
in	O
using	O
Gaussian	O
noise	O
(	O
stddev	O
0.01	O
)	O
[	O
reference	O
]	O
,	O
and	O
dropout	B-Method
on	O
the	O
output	O
layer	O
(	O
p=0.5	O
)	O
	
[	O
reference	O
]	O
.	O
	
We	O
also	O
use	O
early	O
stopping	O
,	O
based	O
on	O
BLEU	B-Metric
measured	O
every	O
three	O
hours	O
on	O
tst2010	B-Method
,	O
which	O
we	O
treat	O
as	O
development	O
set	O
.	O
	
For	O
Turkish→English	O
,	O
we	O
use	O
gradient	B-Method
clipping	I-Method
with	O
threshold	O
5	O
,	O
following	O
[	O
reference	O
]	O
,	O
in	O
contrast	O
to	O
the	O
threshold	O
1	O
that	O
we	O
use	O
for	O
English↔German	O
,	O
following	O
[	O
reference	O
]	O
.	O
Table	O
3	O
shows	O
English→German	O
results	O
with	O
WMT	O
training	O
and	O
test	O
data	O
.	O
	
We	O
find	O
that	O
mixing	O
parallel	O
training	O
data	O
with	O
monolingual	B-Method
data	I-Method
with	O
a	O
dummy	O
source	O
side	O
in	O
a	O
ratio	O
of	O
1	O
-	O
1	O
improves	O
quality	B-Metric
by	O
0.4	O
-	O
0.5	O
BLEU	B-Metric
for	O
the	O
single	O
system	O
,	O
1	O
BLEU	B-Metric
for	O
the	O
ensemble	O
.	O
	
We	O
train	O
the	O
system	O
for	O
twice	O
as	O
long	O
as	O
the	O
baseline	O
to	O
provide	O
the	O
training	B-Method
algorithm	I-Method
with	O
a	O
similar	O
amount	O
of	O
parallel	O
training	O
instances	O
.	O
	
To	O
ensure	O
that	O
the	O
quality	O
improvement	O
is	O
due	O
to	O
the	O
monolingual	B-Method
training	I-Method
instances	I-Method
,	O
and	O
not	O
just	O
increased	O
training	B-Metric
time	I-Metric
,	O
we	O
also	O
continued	O
training	O
our	O
baseline	O
system	O
for	O
another	O
week	O
,	O
but	O
saw	O
no	O
improvements	O
in	O
BLEU	B-Metric
.	O
	
section	O
:	O
Results	O
	
section	O
:	O
English→German	O
WMT	O
15	O
	
Including	O
synthetic	O
data	O
during	O
training	O
is	O
very	O
effective	O
,	O
and	O
yields	O
an	O
improvement	O
over	O
our	O
baseline	O
by	O
2.8	O
-	O
3.4	O
BLEU	B-Metric
.	O
	
Our	O
best	O
ensemble	O
system	O
also	O
outperforms	O
a	O
syntaxbased	B-Method
baseline	I-Method
[	O
reference	O
]	O
)	O
by	O
1.2	O
-	O
2.1	O
BLEU	B-Metric
.	O
	
We	O
also	O
substantially	O
outperform	O
NMT	B-Method
results	O
reported	O
by	O
[	O
reference	O
]	O
and	O
,	O
who	O
previously	O
reported	O
SOTA	O
result	O
.	O
	
[	O
reference	O
]	O
	
We	O
note	O
that	O
the	O
difference	O
is	O
particularly	O
large	O
for	O
single	O
systems	O
,	O
since	O
our	O
ensemble	O
is	O
not	O
as	O
diverse	O
as	O
that	O
of	O
,	O
who	O
used	O
8	O
independently	O
trained	O
ensemble	B-Method
components	I-Method
,	O
whereas	O
we	O
sampled	O
4	O
ensemble	B-Method
components	I-Method
from	O
the	O
same	O
training	O
run	O
.	O
	
test	O
sets	O
,	O
which	O
are	O
news	O
texts	O
.	O
	
We	O
investigate	O
if	O
monolingual	B-Method
training	I-Method
data	I-Method
is	O
especially	O
valuable	O
if	O
it	O
can	O
be	O
used	O
to	O
adapt	O
a	O
model	O
to	O
a	O
new	O
genre	O
or	O
domain	O
,	O
specifically	O
adapting	O
a	O
system	O
trained	O
on	O
WMT	O
data	O
to	O
translating	O
TED	O
talks	O
.	O
	
Systems	O
1	O
and	O
2	O
correspond	O
to	O
systems	O
in	O
Table	O
3	O
,	O
trained	O
only	O
on	O
WMT	O
data	O
.	O
	
System	O
2	O
,	O
trained	O
on	O
parallel	O
and	O
synthetic	O
WMT	O
data	O
,	O
obtains	O
a	O
BLEU	B-Metric
score	I-Metric
of	O
25.5	O
on	O
tst2015	O
.	O
	
We	O
observe	O
that	O
even	O
a	O
small	O
amount	O
of	O
fine	O
-	O
tuning	O
9	O
,	O
i.e.	O
continued	O
training	O
of	O
an	O
existing	O
model	O
,	O
on	O
WIT	O
data	O
can	O
adapt	O
a	O
system	O
trained	O
on	O
WMT	O
data	O
to	O
the	O
TED	O
domain	O
.	O
	
By	O
back	O
-	O
translating	O
the	O
monolingual	B-Method
WIT	O
corpus	O
(	O
using	O
a	O
German→English	B-Method
system	I-Method
trained	O
on	O
WMT	O
data	O
,	O
i.e.	O
without	O
in	O
-	O
domain	O
knowledge	O
)	O
,	O
we	O
obtain	O
the	O
synthetic	O
data	O
set	O
WIT	O
synth	O
.	O
	
A	O
single	O
epoch	O
of	O
fine	B-Method
-	I-Method
tuning	I-Method
on	O
WIT	B-Task
synth	I-Task
(	O
system	O
4	O
)	O
results	O
in	O
a	O
BLEU	B-Metric
score	I-Metric
of	O
26.7	O
on	O
tst2015	O
,	O
or	O
an	O
improvement	O
of	O
1.2	O
BLEU	B-Metric
.	O
	
We	O
observed	O
no	O
improvement	O
from	O
fine	B-Method
-	I-Method
tuning	I-Method
on	O
WIT	O
mono	O
,	O
the	O
monolingual	B-Method
TED	O
corpus	O
with	O
dummy	O
input	O
(	O
system	O
3	O
)	O
.	O
	
section	O
:	O
English→German	O
IWSLT	O
15	O
	
These	O
adaptation	O
experiments	O
with	O
monolingual	B-Method
data	I-Method
are	O
slightly	O
artificial	O
in	O
that	O
parallel	O
training	O
data	O
is	O
available	O
.	O
	
System	O
5	O
,	O
which	O
is	O
finetuned	O
with	O
the	O
original	O
WIT	O
training	O
data	O
,	O
obtains	O
a	O
BLEU	B-Metric
of	O
28.4	O
on	O
tst2015	O
,	O
which	O
is	O
an	O
improve	O
-	O
[	O
reference	O
]	O
	
We	O
leave	O
the	O
word	O
embeddings	O
fixed	O
for	O
fine	B-Task
-	I-Task
tuning	I-Task
.	O
	
BLEU	B-Metric
name	O
2014	O
2015	O
PBSMT	B-Method
28.8	O
29.3	O
NMT	B-Method
[	O
reference	O
]	O
23.6	O
-+	O
shallow	O
fusion	B-Method
23.7	O
-+	O
deep	O
fusion	B-Method
24.0	O
-	O
parallel	O
25.9	O
26.7	O
+	O
synthetic	O
29.5	O
30.4	O
+	O
synthetic	O
(	O
ensemble	O
of	O
4	O
)	O
30.8	O
31.6	O
Table	O
5	O
:	O
German→English	B-Metric
translation	I-Metric
performance	I-Metric
(	O
BLEU	B-Metric
)	O
on	O
WMT	O
training	O
/	O
test	O
sets	O
(	O
newstest2014	O
;	O
newstest2015	O
)	O
.	O
	
ment	O
of	O
2.9	O
BLEU	B-Metric
.	O
	
While	O
it	O
is	O
unsurprising	O
that	O
in	O
-	O
domain	O
parallel	O
data	O
is	O
most	O
valuable	O
,	O
we	O
find	O
it	O
encouraging	O
that	O
NMT	B-Method
domain	I-Method
adaptation	I-Method
with	O
monolingual	B-Method
data	I-Method
is	O
also	O
possible	O
,	O
and	O
effective	O
,	O
since	O
there	O
are	O
settings	O
where	O
only	O
monolingual	B-Method
in	I-Method
-	I-Method
domain	I-Method
data	I-Method
is	O
available	O
.	O
	
The	O
best	O
results	O
published	O
on	O
this	O
dataset	O
are	O
by	O
,	O
obtained	O
with	O
an	O
ensemble	O
of	O
8	O
independently	O
trained	B-Method
models	I-Method
.	O
	
In	O
a	O
comparison	O
of	O
single	O
-	O
model	O
results	O
,	O
we	O
outperform	O
their	O
model	O
on	O
tst2013	O
by	O
1	O
BLEU	B-Metric
.	O
	
section	O
:	O
German→English	O
WMT	O
15	O
	
Results	O
for	O
German→English	O
on	O
the	O
WMT	O
15	O
data	O
sets	O
are	O
shown	O
in	O
Table	O
5	O
.	O
	
Like	O
for	O
the	O
reverse	B-Task
translation	I-Task
direction	I-Task
,	O
we	O
see	O
substantial	O
improvements	O
(	O
3.6	O
-	O
3.7	O
BLEU	B-Metric
)	O
from	O
adding	O
monolingual	B-Method
training	I-Method
data	I-Method
with	O
synthetic	O
source	O
sentences	O
,	O
which	O
is	O
substantially	O
bigger	O
than	O
the	O
improvement	O
observed	O
with	O
deep	B-Method
fusion	I-Method
[	O
reference	O
]	O
;	O
our	O
ensemble	O
outperforms	O
the	O
previous	O
state	O
of	O
the	O
art	O
on	O
newstest2015	O
by	O
2.3	O
BLEU	B-Metric
.	O
	
Table	O
6	O
shows	O
results	O
for	O
Turkish→English	O
.	O
	
On	O
average	O
,	O
we	O
see	O
an	O
improvement	O
of	O
0.6	O
BLEU	B-Metric
on	O
the	O
test	O
sets	O
from	O
adding	O
monolingual	B-Method
data	I-Method
with	O
a	O
dummy	O
source	O
side	O
in	O
a	O
1	O
-	O
1	O
ratio	O
10	O
,	O
although	O
we	O
note	O
a	O
high	O
variance	O
between	O
different	O
test	O
sets	O
.	O
	
section	O
:	O
Turkish→English	O
IWSLT	O
14	O
	
With	O
synthetic	O
training	O
data	O
(	O
Gigaword	O
synth	O
)	O
,	O
we	O
outperform	O
the	O
baseline	O
by	O
2.7	O
BLEU	B-Metric
on	O
average	O
,	O
and	O
also	O
outperform	O
results	O
obtained	O
via	O
shallow	B-Method
or	I-Method
deep	I-Method
fusion	I-Method
by	O
[	O
reference	O
]	O
by	O
0.5	O
BLEU	B-Metric
on	O
average	O
.	O
	
To	O
compare	O
to	O
what	O
extent	O
synthetic	O
data	O
has	O
a	O
regularization	O
effect	O
,	O
even	O
without	O
novel	O
training	O
data	O
,	O
we	O
also	O
back	O
-	O
translate	O
the	O
target	O
side	O
of	O
the	O
parallel	O
training	O
text	O
to	O
obtain	O
the	O
training	O
corpus	O
parallel	O
synth	O
.	O
	
Mixing	O
the	O
original	O
parallel	O
corpus	O
with	O
parallel	O
synth	O
(	O
ratio	O
1	O
-	O
1	O
)	O
gives	O
some	O
improvement	O
over	O
the	O
baseline	O
(	O
1.7	O
BLEU	B-Metric
on	O
average	O
)	O
,	O
but	O
the	O
novel	O
monolingual	B-Method
training	I-Method
data	I-Method
(	O
Gigaword	O
mono	O
)	O
gives	O
higher	O
improvements	O
,	O
despite	O
being	O
out	O
-	O
of	O
-	O
domain	O
in	O
relation	O
to	O
the	O
test	O
sets	O
.	O
	
We	O
speculate	O
that	O
novel	O
in	O
-	O
domain	O
monolingual	B-Method
data	I-Method
would	O
lead	O
to	O
even	O
higher	O
improvements	O
.	O
	
section	O
:	O
Back	B-Metric
-	I-Metric
translation	I-Metric
Quality	I-Metric
for	O
Synthetic	O
Data	O
	
One	O
question	O
that	O
our	O
previous	O
experiments	O
leave	O
open	O
is	O
how	O
the	O
quality	O
of	O
the	O
automatic	B-Method
backtranslation	I-Method
affects	O
training	B-Task
with	O
synthetic	O
data	O
.	O
	
To	O
investigate	O
this	O
question	O
,	O
we	O
back	O
-	O
translate	O
the	O
same	O
German	O
monolingual	B-Method
corpus	I-Method
with	O
three	O
different	O
German→English	B-Method
systems	I-Method
:	O
	
•	O
with	O
our	O
baseline	O
system	O
and	O
greedy	B-Method
decoding	I-Method
	
•	O
with	O
our	O
baseline	O
system	O
and	O
beam	B-Method
search	I-Method
(	O
beam	O
size	O
12	O
)	O
.	O
	
This	O
is	O
the	O
same	O
system	O
used	O
for	O
the	O
experiments	O
in	O
Table	O
3	O
.	O
	
[	O
reference	O
]	O
	
We	O
also	O
experimented	O
with	O
higher	O
ratios	O
of	O
monolingual	B-Method
data	I-Method
,	O
but	O
this	O
led	O
to	O
decreased	O
BLEU	B-Metric
scores	I-Metric
.	O
	
Table	O
7	O
:	O
English→German	B-Metric
translation	I-Metric
performance	I-Metric
(	O
BLEU	B-Metric
)	O
on	O
WMT	O
training	O
/	O
test	O
sets	O
(	O
newstest2014	O
;	O
newstest2015	O
)	O
.	O
	
Systems	O
differ	O
in	O
how	O
the	O
synthetic	O
training	O
data	O
is	O
obtained	O
.	O
	
Ensembles	O
of	O
4	O
models	O
(	O
unless	O
specified	O
otherwise	O
)	O
.	O
	
•	O
with	O
the	O
German→English	B-Method
system	I-Method
that	O
was	O
itself	O
trained	O
with	O
synthetic	O
data	O
(	O
beam	O
size	O
12	O
)	O
.	O
	
BLEU	B-Metric
scores	I-Metric
of	O
the	O
German→English	B-Method
systems	I-Method
,	O
and	O
of	O
the	O
resulting	O
English→German	B-Method
systems	I-Method
that	O
are	O
trained	O
on	O
the	O
different	O
backtranslations	O
,	O
are	O
shown	O
in	O
Table	O
7	O
.	O
	
The	O
quality	O
of	O
the	O
German→English	B-Task
back	I-Task
-	I-Task
translation	I-Task
differs	O
substantially	O
,	O
with	O
a	O
difference	O
of	O
6	O
BLEU	B-Metric
on	O
newstest2015	O
.	O
	
Regarding	O
the	O
English→German	B-Method
systems	I-Method
trained	O
on	O
the	O
different	O
synthetic	O
corpora	O
,	O
we	O
find	O
that	O
the	O
6	O
BLEU	B-Metric
difference	I-Metric
in	O
back	B-Metric
-	I-Metric
translation	I-Metric
quality	I-Metric
leads	O
to	O
a	O
0.6	O
-	O
0.7	O
BLEU	B-Metric
difference	I-Metric
in	O
translation	B-Metric
quality	I-Metric
.	O
	
This	O
is	O
balanced	O
by	O
the	O
fact	O
that	O
we	O
can	O
increase	O
the	O
speed	O
of	O
back	B-Task
-	I-Task
translation	I-Task
by	O
trading	O
off	O
some	O
quality	B-Metric
,	O
for	O
instance	O
by	O
reducing	O
beam	O
size	O
,	O
and	O
we	O
leave	O
it	O
to	O
future	O
research	O
to	O
explore	O
how	O
much	O
the	O
amount	O
of	O
synthetic	O
data	O
affects	O
translation	B-Metric
quality	I-Metric
.	O
	
We	O
also	O
show	O
results	O
for	O
an	O
ensemble	O
of	O
3	O
models	O
(	O
the	O
best	O
single	O
model	O
of	O
each	O
training	O
run	O
)	O
,	O
and	O
12	O
models	O
(	O
all	O
4	O
models	O
of	O
each	O
training	O
run	O
)	O
.	O
	
Thanks	O
to	O
the	O
increased	O
diversity	O
of	O
the	O
ensemble	B-Method
components	I-Method
,	O
these	O
ensembles	O
outperform	O
the	O
ensembles	O
of	O
4	O
models	O
that	O
were	O
all	O
sampled	O
from	O
the	O
same	O
training	O
run	O
,	O
and	O
we	O
obtain	O
another	O
improvement	O
of	O
0.8	O
-	O
1.0	B-Metric
BLEU	I-Metric
.	O
	
section	O
:	O
Contrast	O
to	O
Phrase	B-Method
-	I-Method
based	I-Method
SMT	I-Method
	
The	O
back	B-Task
-	I-Task
translation	I-Task
of	O
monolingual	B-Method
target	I-Method
data	I-Method
into	O
the	O
source	O
language	O
to	O
produce	O
synthetic	O
parallel	O
text	O
has	O
been	O
previously	O
explored	O
for	O
phrase	B-Task
-	I-Task
based	I-Task
SMT	I-Task
	
[	O
reference	O
][	O
reference	O
]	O
.	O
	
While	O
our	O
approach	O
is	O
technically	O
similar	O
,	O
synthetic	O
parallel	O
data	O
fulfills	O
novel	O
name	O
training	O
BLEU	O
data	O
instances	O
tst2011	O
tst2012	O
tst2013	O
tst2014	O
baseline	O
[	O
reference	O
]	O
	
18.4	O
18.8	O
19.9	O
18.7	O
deep	B-Method
fusion	I-Method
[	O
reference	O
]	O
	
20	O
Table	O
8	O
:	O
Phrase	B-Task
-	I-Task
based	I-Task
SMT	I-Task
results	O
(	O
English→German	O
)	O
on	O
WMT	O
test	O
sets	O
(	O
average	O
of	O
newstest201{4	O
,	O
5	O
}	O
)	O
,	O
and	O
IWSLT	O
test	O
sets	O
(	O
average	O
of	O
tst201{3	O
,	O
4	O
,	O
5	O
}	O
)	O
,	O
and	O
average	B-Metric
BLEU	I-Metric
gain	I-Metric
from	O
adding	O
synthetic	O
data	O
for	O
both	O
PBSMT	B-Method
and	O
NMT	B-Task
.	O
	
roles	O
in	O
NMT	B-Task
.	O
	
To	O
explore	O
the	O
relative	O
effectiveness	O
of	O
backtranslated	O
data	O
for	O
phrase	B-Task
-	I-Task
based	I-Task
SMT	I-Task
and	O
NMT	B-Task
,	O
we	O
train	O
two	O
phrase	B-Method
-	I-Method
based	I-Method
SMT	I-Method
systems	I-Method
with	O
Moses	B-Method
[	O
reference	O
]	O
,	O
using	O
only	O
WMT	B-Method
parallel	I-Method
,	O
or	O
both	O
WMT	B-Method
parallel	I-Method
and	O
WMT	B-Method
synth_de	I-Method
for	O
training	O
the	O
translation	B-Method
and	I-Method
reordering	I-Method
model	I-Method
.	O
	
Both	O
systems	O
contain	O
the	O
same	O
language	B-Method
model	I-Method
,	O
a	O
5	B-Method
-	I-Method
gram	I-Method
Kneser	I-Method
-	I-Method
Ney	I-Method
model	I-Method
trained	O
on	O
all	O
available	O
WMT	O
data	O
.	O
	
We	O
use	O
the	O
baseline	O
features	O
described	O
by	O
.	O
	
Results	O
are	O
shown	O
in	O
Table	O
8	O
.	O
	
In	O
phrasebased	B-Task
SMT	I-Task
,	O
we	O
find	O
that	O
the	O
use	O
of	O
back	O
-	O
translated	O
training	O
data	O
has	O
a	O
moderate	O
positive	O
effect	O
on	O
the	O
WMT	B-Metric
test	I-Metric
sets	I-Metric
(	O
+	O
0.7	O
BLEU	B-Metric
)	O
,	O
but	O
not	O
on	O
the	O
IWSLT	O
test	O
sets	O
.	O
	
This	O
is	O
in	O
line	O
with	O
the	O
expectation	O
that	O
the	O
main	O
effect	O
of	O
back	O
-	O
translated	O
data	O
for	O
phrase	B-Task
-	I-Task
based	I-Task
SMT	I-Task
is	O
domain	B-Task
adaptation	I-Task
[	O
reference	O
]	O
.	O
	
Both	O
the	O
WMT	O
test	O
sets	O
and	O
the	O
News	O
Crawl	O
corpora	O
which	O
we	O
used	O
as	O
monolingual	B-Method
data	I-Method
come	O
from	O
the	O
same	O
source	O
,	O
a	O
web	O
crawl	O
of	O
newspaper	O
articles	O
.	O
	
11	O
	
In	O
contrast	O
,	O
News	B-Task
Crawl	I-Task
is	O
out	O
-	O
of	O
-	O
domain	O
for	O
the	O
IWSLT	O
test	O
sets	O
.	O
	
[	O
reference	O
]	O
	
The	O
WMT	O
test	O
sets	O
are	O
held	O
-	O
out	O
from	O
News	O
Crawl	O
.	O
	
In	O
contrast	O
to	O
phrase	B-Method
-	I-Method
based	I-Method
SMT	I-Method
,	O
which	O
can	O
make	O
use	O
of	O
monolingual	B-Method
data	I-Method
via	O
the	O
language	B-Method
model	I-Method
,	O
NMT	B-Task
has	O
so	O
far	O
not	O
been	O
able	O
to	O
use	O
monolingual	B-Method
data	I-Method
to	O
great	O
effect	O
,	O
and	O
without	O
requiring	O
architectural	O
changes	O
.	O
	
We	O
find	O
that	O
the	O
effect	O
of	O
synthetic	O
parallel	O
data	O
is	O
not	O
limited	O
to	O
domain	B-Task
adaptation	I-Task
,	O
and	O
that	O
even	O
out	O
-	O
of	O
-	O
domain	O
synthetic	O
data	O
improves	O
NMT	B-Metric
quality	I-Metric
,	O
as	O
in	O
our	O
evaluation	O
on	O
IWSLT	O
.	O
	
The	O
fact	O
that	O
the	O
synthetic	O
data	O
is	O
more	O
effective	O
on	O
the	O
WMT	O
test	O
sets	O
(	O
+	O
2.9	O
BLEU	B-Metric
)	O
than	O
on	O
the	O
IWSLT	O
test	O
sets	O
(	O
+	O
1.2	O
BLEU	B-Metric
)	O
supports	O
the	O
hypothesis	O
that	O
domain	B-Method
adaptation	I-Method
contributes	O
to	O
the	O
effectiveness	O
of	O
adding	O
synthetic	O
data	O
to	O
NMT	B-Task
training	I-Task
.	O
	
It	O
is	O
an	O
important	O
finding	O
that	O
back	O
-	O
translated	O
data	O
,	O
which	O
is	O
mainly	O
effective	O
for	O
domain	B-Task
adaptation	I-Task
in	O
phrase	B-Task
-	I-Task
based	I-Task
SMT	I-Task
,	O
is	O
more	O
generally	O
useful	O
in	O
NMT	B-Task
,	O
and	O
has	O
positive	O
effects	O
that	O
go	O
beyond	O
domain	B-Method
adaptation	I-Method
.	O
	
In	O
the	O
next	O
section	O
,	O
we	O
will	O
investigate	O
further	O
reasons	O
for	O
its	O
effectiveness	O
.	O
	
section	O
:	O
Analysis	O
	
We	O
previously	O
indicated	O
that	O
overfitting	O
is	O
a	O
concern	O
with	O
our	O
baseline	O
system	O
,	O
especially	O
on	O
small	O
data	O
sets	O
of	O
several	O
hundred	O
thousand	O
training	O
sentences	O
,	O
despite	O
the	O
regularization	B-Method
employed	O
.	O
	
This	O
overfitting	O
is	O
illustrated	O
in	O
Figure	O
1	O
,	O
which	O
plots	O
training	B-Metric
and	I-Metric
development	I-Metric
set	I-Metric
cross	I-Metric
-	I-Metric
entropy	I-Metric
by	O
training	B-Metric
time	I-Metric
for	O
Turkish→English	B-Method
models	I-Method
.	O
	
For	O
comparability	O
,	O
we	O
measure	O
training	B-Metric
set	I-Metric
crossentropy	I-Metric
for	O
all	O
models	O
on	O
the	O
same	O
random	O
sample	O
of	O
the	O
parallel	O
training	O
set	O
.	O
	
We	O
can	O
see	O
that	O
the	O
model	O
trained	O
on	O
only	O
parallel	O
training	O
data	O
quickly	O
overfits	O
,	O
while	O
all	O
three	O
monolingual	B-Method
data	I-Method
sets	I-Method
(	O
parallel	O
synth	O
,	O
Gigaword	O
mono	O
,	O
or	O
Gigaword	O
synth	O
)	O
delay	O
overfitting	O
,	O
and	O
give	O
better	O
perplexity	B-Metric
on	O
the	O
development	O
set	O
.	O
	
The	O
best	O
development	O
set	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
is	O
reached	O
by	O
Gigaword	B-Method
synth	I-Method
.	O
	
Figure	O
2	O
shows	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
for	O
English→German	O
,	O
comparing	O
the	O
system	O
trained	O
on	O
only	O
parallel	O
data	O
and	O
the	O
system	O
that	O
includes	O
synthetic	O
training	O
data	O
.	O
	
Since	O
more	O
training	O
data	O
is	O
available	O
for	O
English→German	O
,	O
there	O
is	O
no	O
indication	O
that	O
overfitting	O
happens	O
during	O
the	O
first	O
40	O
million	O
training	O
instances	O
(	O
or	O
7	O
days	O
of	O
training	O
)	O
;	O
while	O
both	O
systems	O
obtain	O
comparable	O
training	B-Metric
set	I-Metric
cross	I-Metric
-	I-Metric
entropies	I-Metric
,	O
the	O
system	O
with	O
synthetic	O
data	O
reaches	O
a	O
lower	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
on	O
the	O
development	O
set	O
.	O
	
One	O
explanation	O
for	O
this	O
is	O
the	O
domain	O
effect	O
discussed	O
in	O
the	O
previous	O
section	O
.	O
	
A	O
central	O
theoretical	O
expectation	O
is	O
that	O
monolingual	B-Method
target	I-Method
-	I-Method
side	I-Method
data	I-Method
improves	O
the	O
model	O
's	O
flu	O
-	O
	
We	O
compare	O
the	O
number	O
of	O
words	O
in	O
the	O
system	O
output	O
for	O
the	O
newstest2015	O
test	O
set	O
which	O
are	O
produced	O
via	O
subword	O
units	O
,	O
and	O
that	O
do	O
not	O
occur	O
in	O
the	O
parallel	O
training	O
corpus	O
.	O
	
We	O
also	O
count	O
how	O
many	O
of	O
them	O
are	O
attested	O
in	O
the	O
full	O
monolingual	B-Method
corpus	I-Method
or	O
the	O
reference	O
translation	O
,	O
which	O
we	O
all	O
consider	O
'	O
natural	O
'	O
.	O
	
Additionally	O
,	O
the	O
main	O
authors	O
,	O
a	O
native	O
speaker	O
of	O
German	O
,	O
annotated	O
a	O
random	O
subset	O
(	O
n	O
=	O
100	O
)	O
of	O
unattested	O
words	O
of	O
each	O
system	O
according	O
to	O
their	O
naturalness	O
13	O
,	O
distinguishing	O
between	O
natural	O
German	O
words	O
(	O
or	O
names	O
)	O
such	O
as	O
Literatur|klassen	O
'	O
literature	O
classes	O
'	O
,	O
and	O
nonsensical	O
ones	O
such	O
as	O
*	O
As|best|atten	O
(	O
a	O
missspelling	O
of	O
Astbestmatten	O
'	O
asbestos	O
mats	O
'	O
)	O
.	O
	
In	O
the	O
results	O
(	O
Table	O
9	O
)	O
,	O
we	O
see	O
that	O
the	O
systems	O
trained	O
with	O
additional	O
monolingual	B-Method
or	O
synthetic	O
data	O
have	O
a	O
higher	O
proportion	O
of	O
novel	O
words	O
attested	O
in	O
the	O
non	O
-	O
parallel	O
data	O
,	O
and	O
a	O
higher	O
proportion	O
that	O
is	O
deemed	O
natural	O
by	O
our	O
annotator	O
.	O
	
This	O
supports	O
our	O
expectation	O
that	O
additional	O
monolingual	B-Method
data	I-Method
improves	O
the	O
(	O
word	B-Metric
-	I-Metric
level	I-Metric
)	I-Metric
fluency	I-Metric
of	O
the	O
NMT	B-Method
system	I-Method
.	O
	
section	O
:	O
Related	O
Work	O
	
To	O
our	O
knowledge	O
,	O
the	O
integration	O
of	O
monolingual	B-Method
data	I-Method
for	O
pure	O
neural	B-Task
machine	I-Task
translation	I-Task
architectures	I-Task
was	O
first	O
investigated	O
by	O
[	O
reference	O
]	O
,	O
who	O
train	O
monolingual	B-Method
language	O
models	O
independently	O
,	O
and	O
then	O
integrate	O
them	O
during	O
decoding	B-Task
through	O
rescoring	O
of	O
the	O
beam	O
(	O
shallow	B-Method
fusion	I-Method
)	O
,	O
or	O
by	O
adding	O
the	O
recurrent	O
hidden	O
state	O
of	O
the	O
language	B-Method
model	I-Method
to	O
the	O
decoder	O
state	O
of	O
the	O
encoder	B-Method
-	I-Method
decoder	I-Method
network	I-Method
,	O
with	O
an	O
additional	O
controller	B-Method
mechanism	I-Method
that	O
controls	O
the	O
magnitude	O
of	O
the	O
LM	O
signal	O
(	O
deep	B-Method
fusion	I-Method
)	O
.	O
	
In	O
deep	B-Task
fusion	I-Task
,	O
the	O
controller	O
parameters	O
and	O
output	O
parameters	O
are	O
tuned	O
on	O
further	O
parallel	O
training	O
data	O
,	O
but	O
the	O
language	O
model	O
parameters	O
are	O
fixed	O
during	O
the	O
finetuning	B-Method
stage	I-Method
.	O
	
[	O
reference	O
]	O
also	O
report	O
on	O
experiments	O
with	O
reranking	B-Task
of	I-Task
NMT	I-Task
output	I-Task
with	O
a	O
5	B-Method
-	I-Method
gram	I-Method
language	I-Method
model	I-Method
,	O
but	O
improvements	O
are	O
small	O
(	O
between	O
0.1	O
-	O
0.5	O
BLEU	B-Metric
)	O
.	O
	
The	O
production	B-Task
of	I-Task
synthetic	I-Task
parallel	I-Task
texts	I-Task
bears	O
resemblance	O
to	O
data	B-Method
augmentation	I-Method
techniques	I-Method
used	O
in	O
computer	B-Task
vision	I-Task
,	O
where	O
datasets	O
are	O
often	O
augmented	O
with	O
rotated	O
,	O
scaled	O
,	O
or	O
otherwise	O
distorted	O
variants	O
of	O
the	O
(	O
limited	O
)	O
training	O
set	O
[	O
reference	O
]	O
.	O
	
Another	O
similar	O
avenue	O
of	O
research	O
is	O
selftraining	O
	
[	O
reference	O
][	O
reference	O
]	O
.	O
	
The	O
main	O
difference	O
is	O
that	O
self	B-Task
-	I-Task
training	I-Task
typically	O
refers	O
to	O
scenario	O
where	O
the	O
training	O
set	O
is	O
enhanced	O
with	O
training	O
instances	O
with	O
artificially	O
produced	O
output	O
labels	O
,	O
whereas	O
we	O
start	O
with	O
human	O
-	O
produced	O
output	O
(	O
i.e.	O
the	O
translation	O
)	O
,	O
and	O
artificially	O
produce	O
an	O
input	O
.	O
	
We	O
expect	O
that	O
this	O
is	O
more	O
robust	O
towards	O
noise	O
in	O
the	O
automatic	B-Task
translation	I-Task
.	O
	
Improving	O
NMT	B-Task
with	O
monolingual	B-Method
source	I-Method
data	I-Method
,	O
following	O
similar	O
work	O
on	O
phrasebased	B-Task
SMT	I-Task
[	O
reference	O
]	O
,	O
remains	O
possible	O
future	O
work	O
.	O
	
Domain	B-Method
adaptation	I-Method
of	I-Method
neural	I-Method
networks	I-Method
via	O
continued	B-Method
training	I-Method
has	O
been	O
shown	O
to	O
be	O
effective	O
for	O
neural	B-Task
language	I-Task
models	I-Task
by	O
[	O
reference	O
]	O
,	O
and	O
in	O
work	O
parallel	O
to	O
ours	O
,	O
for	O
neural	B-Task
translation	I-Task
models	I-Task
.	O
	
We	O
are	O
the	O
first	O
to	O
show	O
that	O
we	O
can	O
effectively	O
adapt	O
neural	B-Method
translation	I-Method
models	I-Method
with	O
monolingual	B-Method
data	I-Method
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
two	O
simple	O
methods	O
to	O
use	O
monolingual	B-Method
training	I-Method
data	I-Method
during	O
training	O
of	O
NMT	B-Task
systems	I-Task
,	O
with	O
no	O
changes	O
to	O
the	O
network	B-Method
architecture	I-Method
.	O
	
Providing	O
training	O
examples	O
with	O
dummy	O
source	O
context	O
was	O
successful	O
to	O
some	O
extent	O
,	O
but	O
we	O
achieve	O
substantial	O
gains	O
in	O
all	O
tasks	O
,	O
and	O
new	O
SOTA	O
results	O
,	O
via	O
back	B-Task
-	I-Task
translation	I-Task
of	O
monolingual	B-Method
target	I-Method
data	I-Method
into	O
the	O
source	O
language	O
,	O
and	O
treating	O
this	O
synthetic	O
data	O
as	O
additional	O
training	O
data	O
.	O
	
We	O
also	O
show	O
that	O
small	O
amounts	O
of	O
indomain	O
monolingual	B-Method
data	I-Method
,	O
back	O
-	O
translated	O
into	O
the	O
source	O
language	O
,	O
can	O
be	O
effectively	O
used	O
for	O
domain	B-Task
adaptation	I-Task
.	O
	
In	O
our	O
analysis	O
,	O
we	O
identified	O
domain	O
adaptation	O
effects	O
,	O
a	O
reduction	O
of	O
overfitting	B-Metric
,	O
and	O
improved	O
fluency	B-Metric
as	O
reasons	O
for	O
the	O
effectiveness	O
of	O
using	O
monolingual	B-Method
data	I-Method
for	O
training	B-Task
.	O
	
While	O
our	O
experiments	O
did	O
make	O
use	O
of	O
monolingual	B-Method
training	I-Method
data	I-Method
,	O
we	O
only	O
used	O
a	O
small	O
random	O
sample	O
of	O
the	O
available	O
data	O
,	O
especially	O
for	O
the	O
experiments	O
with	O
synthetic	O
parallel	O
data	O
.	O
	
It	O
is	O
conceivable	O
that	O
larger	O
synthetic	O
data	O
sets	O
,	O
or	O
data	O
sets	O
obtained	O
via	O
data	B-Method
selection	I-Method
,	O
will	O
provide	O
bigger	O
performance	O
benefits	O
.	O
	
Because	O
we	O
do	O
not	O
change	O
the	O
neural	B-Method
network	I-Method
architecture	I-Method
to	O
integrate	O
monolingual	B-Method
training	I-Method
data	I-Method
,	O
our	O
approach	O
can	O
be	O
easily	O
applied	O
to	O
other	O
NMT	B-Method
systems	I-Method
.	O
	
We	O
expect	O
that	O
the	O
effectiveness	O
of	O
our	O
approach	O
not	O
only	O
varies	O
with	O
the	O
quality	O
of	O
the	O
MT	B-Method
system	I-Method
used	O
for	O
back	B-Task
-	I-Task
translation	I-Task
,	O
but	O
also	O
depends	O
on	O
the	O
amount	O
(	O
and	O
similarity	O
to	O
the	O
test	O
set	O
)	O
of	O
available	O
parallel	O
and	O
monolingual	B-Method
data	I-Method
,	O
and	O
the	O
extent	O
of	O
overfitting	O
of	O
the	O
baseline	B-Method
model	I-Method
.	O
	
Future	O
work	O
will	O
explore	O
the	O
effectiveness	O
of	O
our	O
approach	O
in	O
more	O
settings	O
.	O
	
section	O
:	O
	
section	O
:	O
Acknowledgments	O
	
The	O
research	O
presented	O
in	O
this	O
publication	O
was	O
conducted	O
in	O
cooperation	O
with	O
Samsung	O
Electronics	O
Polska	O
sp	O
.	O
	
z	O
o.o	O
.	O
	
-	O
Samsung	O
R	O
&	O
D	O
Institute	O
Poland	O
.	O
	
This	O
project	O
received	O
funding	O
from	O
the	O
European	O
Union	O
's	O
Horizon	O
2020	O
research	O
and	O
innovation	O
programme	O
under	O
grant	O
agreement	O
645452	O
(	O
QT21	O
)	O
.	O
	
section	O
:	O
	
We	O
present	O
a	O
semi	B-Method
-	I-Method
supervised	I-Method
learning	I-Method
framework	I-Method
based	O
on	O
graph	B-Method
embeddings	I-Method
.	O
	
Given	O
a	O
graph	O
between	O
instances	O
,	O
we	O
train	O
an	O
embedding	B-Method
for	O
each	O
instance	O
to	O
jointly	O
predict	O
the	O
class	O
label	O
and	O
the	O
neighborhood	O
context	O
in	O
the	O
graph	O
.	O
	
We	O
develop	O
both	O
transductive	B-Method
and	O
inductive	O
variants	O
of	O
our	O
method	O
.	O
	
In	O
the	O
transductive	B-Method
variant	O
of	O
our	O
method	O
,	O
the	O
class	O
labels	O
are	O
determined	O
by	O
both	O
the	O
learned	O
embeddings	O
and	O
input	O
feature	O
vectors	O
,	O
while	O
in	O
the	O
inductive	B-Method
variant	I-Method
,	O
the	O
embeddings	O
are	O
defined	O
as	O
a	O
parametric	O
function	O
of	O
the	O
feature	O
vectors	O
,	O
so	O
predictions	O
can	O
be	O
made	O
on	O
instances	O
not	O
seen	O
during	O
training	O
.	O
	
On	O
a	O
large	O
and	O
diverse	O
set	O
of	O
benchmark	O
tasks	O
,	O
including	O
text	B-Task
classification	I-Task
,	O
distantly	B-Task
supervised	I-Task
entity	I-Task
extraction	I-Task
,	O
and	O
entity	B-Task
classification	I-Task
,	O
we	O
show	O
improved	O
performance	O
over	O
many	O
of	O
the	O
existing	O
models	O
.	O
	
RevisitingSemi	O
-	O
SupervisedLearningwithGraphEmbeddings	O
	
section	O
:	O
Introduction	O
	
Semi	B-Method
-	I-Method
supervised	I-Method
learning	I-Method
aims	O
to	O
leverage	O
unlabeled	O
data	O
to	O
improve	O
performance	O
.	O
	
A	O
large	O
number	O
of	O
semi	B-Method
-	I-Method
supervised	I-Method
learning	I-Method
algorithms	I-Method
jointly	O
optimize	O
two	O
training	B-Method
objective	I-Method
functions	I-Method
:	O
the	O
supervised	O
loss	O
over	O
labeled	O
data	O
and	O
the	O
unsupervised	O
loss	O
over	O
both	O
labeled	O
and	O
unlabeled	O
data	O
.	O
	
Graph	B-Method
-	I-Method
based	I-Method
semi	I-Method
-	I-Method
supervised	I-Method
learning	I-Method
defines	O
the	O
loss	O
function	O
as	O
a	O
weighted	B-Method
sum	I-Method
of	O
the	O
supervised	O
loss	O
over	O
labeled	O
instances	O
and	O
a	O
graph	B-Method
Laplacian	I-Method
regularization	I-Method
term	I-Method
.	O
	
The	O
graph	B-Method
Laplacian	I-Method
regularization	I-Method
is	O
based	O
on	O
the	O
assumption	O
that	O
nearby	O
nodes	O
in	O
a	O
graph	O
are	O
likely	O
to	O
have	O
the	O
same	O
labels	O
.	O
	
Graph	B-Method
Laplacian	I-Method
regularization	I-Method
is	O
effective	O
because	O
it	O
constrains	O
the	O
labels	O
to	O
be	O
consistent	O
with	O
the	O
graph	O
structure	O
.	O
	
Recently	O
developed	O
unsupervised	B-Method
representation	I-Method
learning	I-Method
methods	I-Method
learn	O
embeddings	B-Method
that	O
predict	O
a	O
distributional	O
context	O
,	O
e.g.	O
a	O
word	O
embedding	O
might	O
predict	O
nearby	O
context	O
words	O
,	O
or	O
a	O
node	B-Method
embedding	I-Method
might	O
predict	O
nearby	O
nodes	O
in	O
a	O
graph	O
.	O
	
Embeddings	B-Method
trained	O
with	O
distributional	O
context	O
can	O
be	O
used	O
to	O
boost	O
the	O
performance	O
of	O
related	B-Task
tasks	I-Task
.	O
	
For	O
example	O
,	O
word	B-Method
embeddings	I-Method
trained	O
from	O
a	O
language	B-Method
model	I-Method
can	O
be	O
applied	O
to	O
part	B-Task
-	I-Task
of	I-Task
-	I-Task
speech	I-Task
tagging	I-Task
,	O
chunking	B-Task
and	O
named	B-Task
entity	I-Task
recognition	I-Task
.	O
	
In	O
this	O
paper	O
we	O
consider	O
not	O
word	B-Method
embeddings	I-Method
but	O
graph	B-Method
embeddings	I-Method
.	O
	
Existing	O
results	O
show	O
that	O
graph	B-Method
embeddings	I-Method
are	O
effective	O
at	O
classifying	O
the	O
nodes	O
in	O
a	O
graph	O
,	O
such	O
as	O
user	B-Task
behavior	I-Task
prediction	I-Task
in	O
a	O
social	B-Task
network	I-Task
.	O
	
However	O
,	O
the	O
graph	O
embeddings	O
are	O
usually	O
learned	O
separately	O
from	O
the	O
supervised	B-Task
task	I-Task
,	O
and	O
hence	O
do	O
not	O
leverage	O
the	O
label	O
information	O
in	O
a	O
specific	O
task	O
.	O
	
Hence	O
graph	B-Method
embeddings	I-Method
are	O
in	O
some	O
sense	O
complementary	O
to	O
graph	B-Method
Laplacian	I-Method
regularization	I-Method
that	O
does	O
not	O
produce	O
useful	O
features	O
itself	O
and	O
might	O
not	O
be	O
able	O
to	O
fully	O
leverage	O
the	O
distributional	O
information	O
encoded	O
in	O
the	O
graph	O
structure	O
.	O
	
The	O
main	O
highlight	O
of	O
our	O
work	O
is	O
to	O
incorporate	O
embedding	B-Method
techniques	I-Method
into	O
the	O
graph	B-Task
-	I-Task
based	I-Task
semi	I-Task
-	I-Task
supervised	I-Task
learning	I-Task
setting	I-Task
.	O
	
We	O
propose	O
a	O
novel	O
graph	B-Method
-	I-Method
based	I-Method
semi	I-Method
-	I-Method
supervised	I-Method
learning	I-Method
framework	I-Method
,	O
Planetoid	B-Method
(	O
Predicting	O
Labels	O
And	O
Neighbors	O
with	O
Embeddings	O
	
Transductively	O
	
Or	O
Inductively	O
from	O
Data	O
)	O
.	O
	
The	O
embedding	O
of	O
an	O
instance	O
is	O
jointly	O
trained	O
to	O
predict	O
the	O
class	O
label	O
of	O
the	O
instance	O
and	O
the	O
context	O
in	O
the	O
graph	O
.	O
	
We	O
then	O
concatenate	O
the	O
embeddings	O
and	O
the	O
hidden	O
layers	O
of	O
the	O
original	O
classifier	B-Method
and	O
feed	O
them	O
to	O
a	O
softmax	B-Method
layer	I-Method
when	O
making	O
the	O
prediction	B-Task
.	O
	
Since	O
the	O
embeddings	O
are	O
learned	O
based	O
on	O
the	O
graph	O
structure	O
,	O
the	O
above	O
method	O
is	O
transductive	B-Method
,	O
which	O
means	O
we	O
can	O
only	O
predict	O
instances	O
that	O
are	O
already	O
observed	O
in	O
the	O
graph	O
at	O
training	O
time	O
.	O
	
In	O
many	O
cases	O
,	O
however	O
,	O
it	O
may	O
be	O
desirable	O
to	O
have	O
an	O
inductive	B-Method
approach	I-Method
,	O
where	O
predictions	O
can	O
be	O
made	O
on	O
instances	O
unobserved	O
in	O
the	O
graph	O
seen	O
at	O
training	O
time	O
.	O
	
To	O
address	O
this	O
issue	O
,	O
we	O
further	O
develop	O
an	O
inductive	B-Method
variant	I-Method
of	O
our	O
framework	O
,	O
where	O
we	O
define	O
the	O
embeddings	O
as	O
a	O
parameterized	O
function	O
of	O
input	O
feature	O
vectors	O
;	O
i.e.	O
,	O
the	O
embeddings	O
can	O
be	O
viewed	O
as	O
hidden	O
layers	O
of	O
a	O
neural	B-Method
network	I-Method
.	O
	
To	O
demonstrate	O
the	O
effectiveness	O
of	O
our	O
proposed	O
approach	O
,	O
we	O
conducted	O
experiments	O
on	O
five	O
datasets	O
for	O
three	O
tasks	O
,	O
including	O
text	B-Task
classification	I-Task
,	O
distantly	B-Task
supervised	I-Task
entity	I-Task
extraction	I-Task
,	O
and	O
entity	B-Task
classification	I-Task
.	O
	
Our	O
inductive	B-Method
method	I-Method
outperforms	O
the	O
second	O
best	O
inductive	B-Method
method	I-Method
by	O
up	O
to	O
points	O
and	O
on	O
average	O
points	O
in	O
terms	O
of	O
accuracy	B-Metric
.	O
	
The	O
best	O
of	O
our	O
inductive	O
and	O
transductive	B-Method
methods	O
outperforms	O
the	O
best	O
of	O
all	O
the	O
other	O
compared	O
methods	O
by	O
up	O
to	O
and	O
on	O
average	O
.	O
	
section	O
:	O
Related	O
Work	O
	
subsection	O
:	O
Semi	B-Task
-	I-Task
Supervised	I-Task
Learning	I-Task
	
Let	O
and	O
be	O
the	O
number	O
of	O
labeled	O
and	O
unlabeled	O
instances	O
.	O
	
Let	O
and	O
denote	O
the	O
feature	O
vectors	O
of	O
labeled	O
and	O
unlabeled	O
instances	O
respectively	O
.	O
	
The	O
labels	O
are	O
also	O
given	O
.	O
	
Based	O
on	O
both	O
labeled	O
and	O
unlabeled	O
instances	O
,	O
the	O
problem	O
of	O
semi	B-Task
-	I-Task
supervised	I-Task
learning	I-Task
is	O
defined	O
as	O
learning	O
a	O
classifier	B-Method
.	O
	
There	O
are	O
two	O
learning	B-Method
paradigms	I-Method
,	O
transductive	B-Method
learning	O
and	O
inductive	B-Method
learning	I-Method
.	O
	
Transductive	B-Method
learning	I-Method
only	O
aims	O
to	O
apply	O
the	O
classifier	B-Method
on	O
the	O
unlabeled	O
instances	O
observed	O
at	O
training	O
time	O
,	O
and	O
the	O
classifier	B-Method
does	O
not	O
generalize	O
to	O
unobserved	O
instances	O
.	O
	
For	O
instance	O
,	O
transductive	B-Method
support	O
vector	O
machine	O
(	O
TSVM	B-Method
)	O
maximizes	O
the	O
“	O
unlabeled	O
data	O
margin	O
”	O
based	O
on	O
the	O
low	B-Method
-	I-Method
density	I-Method
separation	I-Method
assumption	I-Method
that	O
a	O
good	O
decision	O
hyperplane	O
lies	O
on	O
a	O
sparse	O
area	O
of	O
the	O
feature	O
space	O
.	O
	
Inductive	B-Method
learning	I-Method
,	O
on	O
the	O
other	O
hand	O
,	O
aims	O
to	O
learn	O
a	O
parameterized	B-Method
classifier	I-Method
that	O
is	O
generalizable	O
to	O
unobserved	O
instances	O
.	O
	
subsection	O
:	O
Graph	B-Method
-	I-Method
Based	I-Method
Semi	I-Method
-	I-Method
Supervised	I-Method
Learning	I-Method
	
In	O
addition	O
to	O
labeled	O
and	O
unlabeled	O
instances	O
,	O
a	O
graph	O
,	O
denoted	O
as	O
a	O
matrix	O
,	O
is	O
also	O
given	O
to	O
graph	B-Method
-	I-Method
based	I-Method
semi	I-Method
-	I-Method
supervised	I-Method
learning	I-Method
methods	I-Method
.	O
	
Each	O
entry	O
indicates	O
the	O
similarity	O
between	O
instance	O
and	O
,	O
which	O
can	O
be	O
either	O
labeled	O
or	O
unlabeled	O
.	O
	
The	O
graph	O
can	O
either	O
be	O
derived	O
from	O
distances	O
between	O
instances	O
,	O
or	O
be	O
explicitly	O
derived	O
from	O
external	O
data	O
,	O
such	O
as	O
a	O
knowledge	O
graph	O
or	O
a	O
citation	B-Method
network	I-Method
between	O
documents	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
mainly	O
focus	O
on	O
the	O
setting	O
that	O
a	O
graph	O
is	O
explicitly	O
given	O
and	O
represents	O
additional	O
information	O
not	O
present	O
in	O
the	O
feature	O
vectors	O
(	O
e.g.	O
,	O
the	O
graph	O
edges	O
correspond	O
to	O
hyperlinks	O
between	O
documents	O
,	O
rather	O
than	O
distances	O
between	O
the	O
bag	B-Method
-	I-Method
of	I-Method
-	I-Method
words	I-Method
representation	I-Method
of	O
a	O
document	O
)	O
.	O
	
Graph	B-Method
-	I-Method
based	I-Method
semi	I-Method
-	I-Method
supervised	I-Method
learning	I-Method
is	O
based	O
on	O
the	O
assumption	O
that	O
nearby	O
nodes	O
tend	O
to	O
have	O
the	O
same	O
labels	O
.	O
	
Generally	O
,	O
the	O
loss	B-Method
function	I-Method
of	O
graph	B-Method
-	I-Method
based	I-Method
semi	I-Method
-	I-Method
supervised	I-Method
learning	I-Method
in	O
the	O
binary	B-Task
case	I-Task
can	O
be	O
written	O
as	O
In	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
	
,	O
the	O
first	O
term	O
is	O
the	O
standard	O
supervised	O
loss	O
function	O
,	O
where	O
can	O
be	O
log	O
loss	O
,	O
squared	B-Method
loss	I-Method
or	O
hinge	B-Method
loss	I-Method
.	O
	
The	O
second	O
term	O
is	O
the	O
graph	B-Method
Laplacian	I-Method
regularization	I-Method
,	O
which	O
incurs	O
a	O
large	O
penalty	O
when	O
similar	O
nodes	O
with	O
a	O
large	O
are	O
predicted	O
to	O
have	O
different	O
labels	O
.	O
	
The	O
graph	O
Laplacian	O
matrix	O
is	O
defined	O
as	O
,	O
where	O
is	O
a	O
diagonal	O
matrix	O
with	O
each	O
entry	O
defined	O
as	O
.	O
	
is	O
a	O
constant	O
weighting	O
factor	O
.	O
	
(	O
Note	O
that	O
we	O
omit	O
the	O
parameter	O
regularization	O
terms	O
for	O
simplicity	O
.	O
)	O
	
Various	O
graph	B-Method
-	I-Method
based	I-Method
semi	I-Method
-	I-Method
supervised	I-Method
learning	I-Method
algorithms	I-Method
define	O
the	O
loss	O
functions	O
as	O
variants	O
of	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
	
Label	B-Task
propagation	I-Task
forces	O
to	O
agree	O
with	O
labeled	O
instances	O
;	O
is	O
a	O
label	O
lookup	O
table	O
for	O
unlabeled	O
instances	O
in	O
the	O
graph	O
,	O
and	O
can	O
be	O
obtained	O
with	O
a	O
closed	B-Method
-	I-Method
form	I-Method
solution	I-Method
.	O
	
Learning	B-Method
with	O
local	O
and	O
global	O
consistency	O
defines	O
as	O
squared	O
loss	O
and	O
as	O
a	O
label	O
lookup	O
table	O
;	O
it	O
does	O
not	O
force	O
to	O
agree	O
with	O
labeled	O
instances	O
.	O
	
Modified	B-Method
Adsorption	I-Method
(	O
MAD	B-Method
)	O
is	O
a	O
variant	O
of	O
label	B-Method
propagation	I-Method
that	O
allows	O
prediction	B-Task
on	O
labeled	O
instances	O
to	O
vary	O
and	O
incorporates	O
node	O
uncertainty	O
.	O
	
Manifold	B-Task
regularization	I-Task
parameterizes	O
in	O
the	O
Reproducing	B-Method
Kernel	I-Method
Hilbert	I-Method
Space	I-Method
(	O
RKHS	B-Method
)	O
with	O
being	O
squared	O
loss	O
or	O
hinge	O
loss	O
.	O
	
Since	O
is	O
a	O
parameterized	B-Method
classifier	I-Method
,	O
manifold	B-Method
regularization	I-Method
is	O
inductive	O
and	O
can	O
naturally	O
handle	O
unobserved	O
instances	O
.	O
	
Semi	B-Task
-	I-Task
supervised	I-Task
embedding	I-Task
extends	O
the	O
regularization	O
term	O
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
to	O
be	O
,	O
where	O
represents	O
embeddings	O
of	O
instances	O
,	O
which	O
can	O
be	O
the	O
output	O
labels	O
,	O
hidden	O
layers	O
or	O
auxiliary	O
embeddings	O
in	O
a	O
neural	B-Method
network	I-Method
.	O
	
By	O
extending	O
the	O
regularization	O
from	O
to	O
,	O
this	O
method	O
imposes	O
stronger	O
constraints	O
on	O
a	O
neural	B-Method
network	I-Method
.	O
	
Iterative	B-Method
classification	I-Method
algorithm	I-Method
(	O
ICA	B-Method
)	O
uses	O
a	O
local	B-Method
classifier	I-Method
that	O
takes	O
the	O
labels	O
of	O
neighbor	O
nodes	O
as	O
input	O
,	O
and	O
employs	O
an	O
iterative	B-Method
process	I-Method
between	O
estimating	O
the	O
local	B-Method
classifier	I-Method
and	O
assigning	O
new	O
labels	O
.	O
	
subsection	O
:	O
Learning	B-Task
Embeddings	I-Task
	
Extensive	O
research	O
was	O
done	O
on	O
learning	B-Task
graph	I-Task
embeddings	I-Task
.	O
	
A	O
probabilistic	B-Method
generative	I-Method
model	I-Method
was	O
proposed	O
to	O
learn	O
node	O
embeddings	O
that	O
generate	O
the	O
edges	O
in	O
a	O
graph	O
.	O
	
A	O
clustering	B-Method
method	I-Method
was	O
proposed	O
to	O
learn	O
latent	O
social	O
states	O
in	O
a	O
social	O
network	O
to	O
predict	O
social	O
ties	O
.	O
	
More	O
recently	O
,	O
a	O
number	O
of	O
embedding	B-Method
learning	I-Method
methods	I-Method
are	O
based	O
on	O
the	O
Skipgram	B-Method
model	I-Method
,	O
which	O
is	O
a	O
variant	O
of	O
the	O
softmax	B-Method
model	I-Method
.	O
	
Given	O
an	O
instance	O
and	O
its	O
context	O
,	O
the	O
objective	O
of	O
Skipgram	B-Task
is	O
usually	O
formulated	O
as	O
minimizing	O
the	O
log	B-Task
loss	I-Task
of	I-Task
predicting	I-Task
the	I-Task
context	I-Task
using	O
the	O
embedding	O
of	O
an	O
instance	O
as	O
input	O
features	O
.	O
	
Formally	O
,	O
let	O
be	O
a	O
set	O
of	O
pairs	O
of	O
instance	O
and	O
context	O
,	O
the	O
loss	O
function	O
can	O
be	O
written	O
as	O
where	O
is	O
the	O
set	O
of	O
all	O
possible	O
context	O
,	O
’s	O
are	O
parameters	O
of	O
the	O
Skipgram	B-Method
model	I-Method
,	O
and	O
is	O
the	O
embedding	B-Method
of	I-Method
instance	I-Method
.	O
	
Skipgram	B-Method
was	O
first	O
introduced	O
to	O
learn	O
representations	B-Task
of	I-Task
words	I-Task
,	O
known	O
as	O
word2vec	O
.	O
	
In	O
word2vec	O
,	O
for	O
each	O
training	O
pair	O
,	O
the	O
instance	O
is	O
the	O
current	O
word	O
whose	O
embedding	O
is	O
under	O
estimation	O
;	O
the	O
context	O
is	O
each	O
of	O
the	O
surrounding	O
words	O
of	O
within	O
a	O
fixed	O
window	O
size	O
in	O
a	O
sentence	O
;	O
the	O
context	O
space	O
is	O
the	O
vocabulary	O
of	O
the	O
corpus	O
.	O
	
Skipgram	B-Method
was	O
later	O
extended	O
to	O
learn	O
graph	B-Task
embeddings	I-Task
.	O
	
Deepwalk	B-Method
uses	O
the	O
embedding	O
of	O
a	O
node	O
to	O
predict	O
the	O
context	O
in	O
the	O
graph	O
,	O
where	O
the	O
context	O
is	O
generated	O
by	O
random	B-Method
walk	I-Method
.	O
	
More	O
specifically	O
,	O
for	O
each	O
training	O
pair	O
,	O
the	O
instance	O
is	O
the	O
current	O
node	O
whose	O
embedding	O
is	O
under	O
estimation	O
;	O
the	O
context	O
is	O
each	O
of	O
the	O
neighbor	O
nodes	O
within	O
a	O
fixed	O
window	O
size	O
in	O
a	O
generated	O
random	O
walk	O
sequence	O
;	O
the	O
context	O
space	O
is	O
all	O
the	O
nodes	O
in	O
the	O
graph	O
.	O
	
LINE	O
extends	O
the	O
model	O
to	O
have	O
multiple	O
context	O
spaces	O
for	O
modeling	O
both	O
first	B-Task
and	I-Task
second	I-Task
order	I-Task
proximity	I-Task
.	O
	
Although	O
Skipgram	B-Method
-	I-Method
like	I-Method
models	I-Method
for	O
graphs	B-Method
have	O
received	O
much	O
recent	O
attention	O
,	O
many	O
other	O
models	O
exist	O
.	O
	
TransE	B-Method
learns	O
the	O
embeddings	O
of	O
entities	O
in	O
a	O
knowledge	O
graph	O
jointly	O
with	O
their	O
relations	O
.	O
	
Autoencoders	B-Method
were	O
used	O
to	O
learn	O
graph	B-Method
embeddings	I-Method
for	O
clustering	B-Task
on	I-Task
graphs	I-Task
.	O
	
subsection	O
:	O
Comparison	O
	
We	O
compare	O
our	O
approach	O
in	O
this	O
paper	O
with	O
other	O
methods	O
in	O
semi	B-Task
-	I-Task
supervised	I-Task
learning	I-Task
and	O
embedding	B-Task
learning	I-Task
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Unlike	O
our	O
approach	O
,	O
conventional	O
graph	B-Method
Laplacian	I-Method
based	I-Method
methods	I-Method
impose	O
regularization	O
on	O
the	O
labels	O
but	O
do	O
not	O
learn	O
embeddings	O
.	O
	
Semi	B-Method
-	I-Method
supervised	I-Method
embedding	I-Method
method	I-Method
learns	O
embeddings	B-Method
in	O
a	O
neural	B-Method
network	I-Method
,	O
but	O
our	O
approach	O
is	O
different	O
from	O
this	O
method	O
in	O
that	O
instead	O
of	O
imposing	O
regularization	O
,	O
we	O
use	O
the	O
embeddings	O
to	O
predict	O
the	O
context	O
in	O
the	O
graph	O
.	O
	
Graph	B-Method
embedding	I-Method
methods	I-Method
encode	O
the	O
graph	O
structure	O
into	O
embeddings	O
;	O
however	O
,	O
different	O
from	O
our	O
approach	O
,	O
these	O
methods	O
are	O
purely	O
unsupervised	O
and	O
do	O
not	O
leverage	O
label	O
information	O
for	O
a	O
specific	O
task	O
.	O
	
Moreover	O
,	O
these	O
methods	O
are	O
transductive	B-Method
and	O
can	O
not	O
be	O
directly	O
generalized	O
to	O
instances	O
unseen	O
at	O
training	O
time	O
.	O
	
section	O
:	O
Semi	B-Task
-	I-Task
Supervised	I-Task
Learning	I-Task
with	O
Graph	B-Task
Embeddings	I-Task
	
Following	O
the	O
notations	O
in	O
the	O
previous	O
section	O
,	O
the	O
input	O
to	O
our	O
method	O
includes	O
labeled	O
instances	O
,	O
,	O
unlabeled	O
instances	O
and	O
a	O
graph	O
denoted	O
as	O
a	O
matrix	O
.	O
	
Each	O
instance	O
has	O
an	O
embedding	O
denoted	O
as	O
.	O
	
We	O
formulate	O
our	O
framework	O
based	O
on	O
feed	B-Method
-	I-Method
forward	I-Method
neural	I-Method
networks	I-Method
.	O
	
Given	O
the	O
input	O
feature	O
vector	O
,	O
the	O
-	O
th	O
hidden	O
layer	O
of	O
the	O
network	O
is	O
denoted	O
as	O
,	O
which	O
is	O
a	O
nonlinear	O
function	O
of	O
the	O
previous	O
hidden	O
layer	O
defined	O
as	O
:	O
where	O
and	O
are	O
parameters	O
of	O
the	O
-	O
th	O
layer	O
,	O
and	O
.	O
	
We	O
adopt	O
rectified	B-Method
linear	I-Method
unit	I-Method
as	O
the	O
nonlinear	O
function	O
in	O
this	O
work	O
.	O
	
The	O
loss	B-Method
function	I-Method
of	O
our	O
framework	O
can	O
be	O
expressed	O
as	O
where	O
is	O
a	O
supervised	B-Task
loss	I-Task
of	I-Task
predicting	I-Task
the	I-Task
labels	I-Task
,	O
and	O
is	O
an	O
unsupervised	B-Task
loss	I-Task
of	I-Task
predicting	I-Task
the	I-Task
graph	I-Task
context	I-Task
.	O
	
In	O
the	O
following	O
sections	O
,	O
we	O
first	O
formulate	O
by	O
introducing	O
how	O
to	O
sample	O
context	O
from	O
the	O
graph	O
,	O
and	O
then	O
formulate	O
to	O
form	O
our	O
semi	B-Method
-	I-Method
supervised	I-Method
learning	I-Method
framework	I-Method
.	O
	
subsection	O
:	O
Sampling	O
Context	O
	
We	O
formulate	O
the	O
unsupervised	B-Task
loss	I-Task
as	O
a	O
variant	O
of	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
	
Given	O
a	O
graph	O
,	O
the	O
basic	O
idea	O
of	O
our	O
approach	O
is	O
to	O
sample	O
pairs	O
of	O
instance	O
and	O
context	O
,	O
and	O
then	O
formulate	O
the	O
loss	O
using	O
the	O
log	O
loss	O
as	O
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
	
We	O
first	O
present	O
the	O
formulation	O
of	O
by	O
introducing	O
negative	B-Task
sampling	I-Task
,	O
and	O
then	O
discuss	O
how	O
to	O
sample	O
pairs	O
of	O
instance	O
and	O
context	O
.	O
	
It	O
is	O
usually	O
intractable	O
to	O
directly	O
optimize	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
due	O
to	O
normalization	O
over	O
the	O
whole	O
context	O
space	O
.	O
	
Negative	B-Task
sampling	I-Task
was	O
introduced	O
to	O
address	O
this	O
issue	O
,	O
which	O
samples	O
negative	O
examples	O
to	O
approximate	O
the	O
normalization	O
term	O
.	O
	
In	O
our	O
case	O
,	O
we	O
are	O
sampling	O
from	O
a	O
distribution	O
,	O
where	O
and	O
denote	O
instance	O
and	O
context	O
respectively	O
,	O
means	O
is	O
a	O
positive	O
pair	O
and	O
means	O
negative	O
.	O
	
Given	O
,	O
we	O
minimize	O
the	O
cross	B-Metric
entropy	I-Metric
loss	I-Metric
of	O
classifying	O
the	O
pair	O
to	O
a	O
binary	O
label	O
:	O
where	O
is	O
the	O
sigmoid	O
function	O
defined	O
as	O
,	O
and	O
is	O
an	O
indicator	O
function	O
that	O
outputs	O
when	O
the	O
argument	O
is	O
true	O
,	O
otherwise	O
.	O
	
Therefore	O
,	O
the	O
unsupervised	B-Task
loss	I-Task
with	O
negative	B-Task
sampling	I-Task
can	O
be	O
written	O
as	O
The	O
distribution	O
is	O
conditioned	O
on	O
labels	O
and	O
the	O
graph	O
.	O
	
However	O
,	O
since	O
they	O
are	O
the	O
input	O
to	O
our	O
algorithm	O
and	O
kept	O
fixed	O
,	O
we	O
drop	O
the	O
conditioning	O
in	O
our	O
notation	O
.	O
	
We	O
now	O
define	O
the	O
distribution	O
directly	O
using	O
a	O
sampling	B-Method
process	I-Method
,	O
which	O
is	O
illustrated	O
in	O
Algorithm	O
[	O
reference	O
]	O
.	O
	
There	O
are	O
two	O
types	O
of	O
context	O
that	O
are	O
sampled	O
in	O
this	O
algorithm	O
.	O
	
The	O
first	O
type	O
of	O
context	O
is	O
based	O
on	O
the	O
graph	O
,	O
which	O
encodes	O
the	O
structure	O
(	O
distributional	O
)	O
information	O
,	O
and	O
the	O
second	O
type	O
of	O
context	O
is	O
based	O
on	O
the	O
labels	O
,	O
which	O
we	O
use	O
to	O
inject	O
label	O
information	O
into	O
the	O
embeddings	O
.	O
	
We	O
use	O
a	O
parameter	O
to	O
control	O
the	O
ratio	O
of	O
positive	O
and	O
negative	O
samples	O
,	O
and	O
use	O
to	O
control	O
the	O
ratio	O
of	O
two	O
types	O
of	O
context	O
.	O
	
With	O
probability	O
,	O
we	O
sample	O
the	O
context	O
based	O
on	O
the	O
graph	O
.	O
	
We	O
first	O
uniformly	O
sample	O
a	O
random	O
walk	O
sequence	O
.	O
	
More	O
specifically	O
,	O
we	O
uniformly	O
sample	O
the	O
first	O
instance	O
from	O
the	O
set	O
.	O
	
Given	O
the	O
previous	O
instance	O
,	O
the	O
next	O
instance	O
is	O
sampled	O
with	O
probability	O
.	O
	
With	O
probability	O
,	O
we	O
sample	O
a	O
positive	O
pair	O
from	O
the	O
set	O
,	O
where	O
is	O
another	O
parameter	O
determining	O
the	O
window	O
size	O
.	O
	
With	O
probability	O
,	O
we	O
uniformly	O
corrupt	O
the	O
context	O
to	O
sample	O
a	O
negative	O
pair	O
.	O
	
With	O
probability	O
,	O
we	O
sample	O
the	O
context	O
based	O
on	O
the	O
class	O
labels	O
.	O
	
Positive	O
pairs	O
have	O
the	O
same	O
labels	O
and	O
negative	O
pairs	O
have	O
different	O
labels	O
.	O
	
Only	O
labeled	O
instances	O
are	O
sampled	O
.	O
	
Our	O
random	B-Method
walk	I-Method
based	I-Method
sampling	I-Method
method	I-Method
is	O
built	O
upon	O
Deepwalk	B-Method
.	O
	
In	O
contrast	O
to	O
their	O
method	O
,	O
our	O
method	O
handles	O
real	O
-	O
valued	O
,	O
incorporates	O
negative	B-Method
sampling	I-Method
,	O
and	O
explicitly	O
samples	O
from	O
labels	O
with	O
probability	O
to	O
inject	O
supervised	O
information	O
.	O
	
An	O
example	O
of	O
sampling	O
when	O
is	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
[	O
tb	O
]	O
	
Sampling	O
Context	O
Distribution	O
⁢p	O
(	O
i	O
,	O
c	O
,	O
γ	O
)	O
	
Input	O
:	O
graph	O
,	O
labels	O
,	O
parameters	O
Initialize	O
	
triplet	O
if	O
then	O
else	O
Uniformly	O
sample	O
a	O
random	B-Method
walk	I-Method
of	O
length	O
	
Uniformly	O
sample	O
with	O
,	O
if	O
then	O
uniformly	O
sample	O
from	O
Uniformly	O
sample	O
with	O
Uniformly	O
sample	O
with	O
return	O
	
subsection	O
:	O
Transductive	B-Method
Formulation	I-Method
	
In	O
this	O
section	O
,	O
we	O
present	O
a	O
method	O
that	O
infers	O
the	O
labels	O
of	O
unlabeled	O
instances	O
without	O
generalizing	O
to	O
unobserved	O
instances	O
.	O
	
Transductive	B-Method
learning	I-Method
usually	O
performs	O
better	O
than	O
inductive	B-Method
learning	I-Method
because	O
transductive	B-Method
learning	O
can	O
leverage	O
the	O
unlabeled	O
test	O
data	O
when	O
training	O
the	O
model	O
.	O
	
We	O
apply	O
layers	O
on	O
the	O
input	O
feature	O
vector	O
to	O
obtain	O
,	O
and	O
layers	O
on	O
the	O
embedding	B-Method
to	O
obtain	O
,	O
as	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
The	O
two	O
hidden	O
layers	O
are	O
concatenated	O
,	O
and	O
fed	O
to	O
a	O
softmax	B-Method
layer	I-Method
to	O
predict	O
the	O
class	O
label	O
of	O
the	O
instance	O
.	O
	
More	O
specifically	O
,	O
the	O
probability	O
of	O
predicting	O
the	O
label	O
is	O
written	O
as	O
:	O
where	O
denotes	O
concatenation	O
of	O
two	O
row	O
vectors	O
,	O
the	O
super	O
script	O
denotes	O
the	O
transpose	O
of	O
vector	O
,	O
and	O
represents	O
the	O
model	O
parameter	O
.	O
	
Combined	O
with	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
	
,	O
the	O
loss	B-Method
function	I-Method
of	O
transductive	B-Method
learning	O
is	O
defined	O
as	O
:	O
where	O
the	O
first	O
term	O
is	O
defined	O
by	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
,	O
and	O
is	O
a	O
constant	O
weighting	O
factor	O
.	O
	
The	O
first	O
term	O
is	O
the	O
loss	B-Method
function	I-Method
of	O
class	B-Task
label	I-Task
prediction	I-Task
and	O
the	O
second	O
term	O
is	O
the	O
loss	O
function	O
of	O
context	B-Task
prediction	I-Task
.	O
	
This	O
formulation	O
is	O
transductive	B-Method
because	O
the	O
prediction	B-Task
of	I-Task
label	I-Task
depends	O
on	O
the	O
embedding	O
,	O
which	O
can	O
only	O
be	O
learned	O
for	O
instances	O
observed	O
in	O
the	O
graph	O
during	O
training	O
time	O
.	O
	
subsection	O
:	O
Inductive	B-Method
Formulation	I-Method
	
While	O
we	O
consider	O
transductive	B-Method
learning	O
in	O
the	O
above	O
formulation	O
,	O
in	O
many	O
cases	O
,	O
it	O
is	O
desirable	O
to	O
learn	O
a	O
classifier	B-Method
that	O
can	O
generalize	O
to	O
unobserved	O
instances	O
,	O
especially	O
for	O
large	B-Task
-	I-Task
scale	I-Task
tasks	I-Task
.	O
	
For	O
example	O
,	O
machine	B-Task
reading	I-Task
systems	I-Task
very	O
frequently	O
encounter	O
novel	O
entities	O
on	O
the	O
Web	O
and	O
it	O
is	O
not	O
practical	O
to	O
train	O
a	O
semi	B-Method
-	I-Method
supervised	I-Method
learning	I-Method
system	I-Method
on	O
the	O
entire	O
Web	O
.	O
	
However	O
,	O
since	O
learning	B-Task
graph	I-Task
embeddings	I-Task
is	O
transductive	B-Method
in	O
nature	O
,	O
it	O
is	O
not	O
straightforward	O
to	O
do	O
it	O
in	O
an	O
inductive	B-Task
setting	I-Task
.	O
	
Perozzi	O
et	O
al	O
.	O
	
perozzi2014deepwalk	O
addressed	O
this	O
issue	O
by	O
retraining	O
the	O
embeddings	O
incrementally	O
,	O
which	O
is	O
time	O
consuming	O
and	O
does	O
not	O
scale	O
(	O
and	O
not	O
inductive	O
essentially	O
)	O
.	O
	
To	O
make	O
the	O
method	O
inductive	O
,	O
the	O
prediction	B-Task
of	I-Task
label	I-Task
should	O
only	O
depend	O
on	O
the	O
input	O
feature	O
vector	O
.	O
	
Therefore	O
,	O
we	O
define	O
the	O
embedding	O
as	O
a	O
parameterized	O
function	O
of	O
feature	O
,	O
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Similar	O
to	O
the	O
transductive	B-Method
formulation	O
,	O
we	O
apply	O
layers	B-Method
on	O
the	O
input	O
feature	O
vector	O
to	O
obtain	O
.	O
	
However	O
,	O
rather	O
than	O
using	O
a	O
“	O
free	B-Method
”	I-Method
embedding	I-Method
,	O
we	O
apply	O
layers	O
on	O
the	O
input	O
feature	O
vector	O
and	O
define	O
it	O
as	O
the	O
embedding	O
.	O
	
Then	O
another	O
layers	O
are	O
applied	O
on	O
the	O
embedding	B-Task
,	O
denoted	O
as	O
where	O
.	O
	
The	O
embedding	B-Task
in	O
this	O
formulation	O
can	O
be	O
viewed	O
as	O
a	O
hidden	B-Method
layer	I-Method
that	O
is	O
a	O
parameterized	O
function	O
of	O
the	O
feature	O
.	O
	
With	O
the	O
above	O
formulation	O
,	O
the	O
label	O
only	O
depends	O
on	O
the	O
feature	O
.	O
	
More	O
specifically	O
,	O
Replacing	O
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
with	O
	
,	O
the	O
loss	B-Method
function	I-Method
of	O
inductive	B-Method
learning	I-Method
is	O
where	O
the	O
first	O
term	O
is	O
defined	O
by	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
	
subsection	O
:	O
Training	O
	
We	O
adopt	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
(	O
SGD	B-Method
)	I-Method
to	O
train	O
our	O
model	O
in	O
the	O
mini	B-Task
-	I-Task
batch	I-Task
mode	I-Task
.	O
	
We	O
first	O
sample	O
a	O
batch	O
of	O
labeled	O
instances	O
and	O
take	O
a	O
gradient	B-Method
step	I-Method
to	O
optimize	O
the	O
loss	B-Task
function	I-Task
of	I-Task
class	I-Task
label	I-Task
prediction	I-Task
.	O
	
We	O
then	O
sample	O
a	O
batch	O
of	O
context	O
and	O
take	O
another	O
gradient	B-Method
step	I-Method
to	O
optimize	O
the	O
loss	B-Task
function	I-Task
of	I-Task
context	I-Task
prediction	I-Task
.	O
	
We	O
repeat	O
the	O
above	O
procedures	O
for	O
and	O
iterations	O
respectively	O
to	O
approximate	O
the	O
weighting	O
factor	O
.	O
	
Algorithm	O
[	O
reference	O
]	O
illustrates	O
the	O
SGD	B-Method
-	I-Method
based	I-Method
training	I-Method
algorithm	I-Method
for	O
the	O
transductive	B-Method
formulation	O
.	O
	
Similarly	O
,	O
we	O
can	O
replace	O
with	O
in	O
to	O
obtain	O
the	O
training	B-Method
algorithm	I-Method
for	O
the	O
inductive	B-Method
formulation	I-Method
.	O
	
Let	O
denote	O
all	O
model	O
parameters	O
.	O
	
We	O
update	O
both	O
embeddings	O
and	O
parameters	O
in	O
transductive	B-Method
learning	O
,	O
and	O
update	O
only	O
parameters	O
in	O
inductive	B-Task
learning	I-Task
.	O
	
Before	O
the	O
joint	B-Method
training	I-Method
procedure	I-Method
,	O
we	O
apply	O
a	O
number	O
of	O
training	B-Method
iterations	I-Method
that	O
optimize	O
the	O
unsupervised	O
loss	O
alone	O
and	O
use	O
the	O
learned	O
embeddings	O
as	O
initialization	O
for	O
joint	B-Task
training	I-Task
.	O
	
[	O
tb	O
]	O
Model	B-Method
Training	I-Method
(	O
Transductive	B-Task
)	O
Input	O
:	O
,	O
,	O
,	O
,	O
batch	O
iterations	O
and	O
sizes	O
to	O
Sample	O
a	O
batch	O
of	O
labeled	O
instances	O
of	O
size	O
	
Take	O
a	O
gradient	B-Method
step	I-Method
for	O
to	O
Sample	O
a	O
batch	O
of	O
context	O
from	O
of	O
size	O
	
Take	O
a	O
gradient	O
step	O
for	O
stopping	O
	
section	O
:	O
Experiments	O
	
In	O
our	O
experiments	O
,	O
Planetoid	B-Method
-	I-Method
T	I-Method
and	O
Planetoid	B-Method
-	I-Method
I	I-Method
denote	O
the	O
transductive	B-Method
and	O
inductive	B-Method
formulation	I-Method
of	O
our	O
approach	O
.	O
	
We	O
compare	O
our	O
approach	O
with	O
label	B-Method
propagation	I-Method
(	O
LP	B-Method
)	O
,	O
semi	B-Method
-	I-Method
supervised	I-Method
embedding	I-Method
(	I-Method
SemiEmb	I-Method
)	I-Method
,	O
manifold	B-Method
regularization	I-Method
(	O
ManiReg	B-Method
)	O
,	O
TSVM	B-Method
,	O
and	O
graph	B-Method
embeddings	I-Method
(	O
GraphEmb	B-Method
)	O
.	O
	
Another	O
baseline	O
method	O
,	O
denoted	O
as	O
Feat	B-Method
,	O
is	O
a	O
linear	B-Method
softmax	I-Method
model	I-Method
that	O
takes	O
only	O
the	O
feature	O
vectors	O
as	O
input	O
.	O
	
We	O
also	O
derive	O
a	O
variant	O
Planetoid	B-Method
-	I-Method
G	I-Method
that	O
learns	O
embeddings	O
to	O
jointly	O
predict	O
class	O
labels	O
and	O
graph	O
context	O
without	O
use	O
of	O
feature	O
vectors	O
.	O
	
The	O
architecture	O
of	O
Planetoid	B-Method
-	I-Method
G	I-Method
is	O
similar	O
to	O
Figure	O
[	O
reference	O
]	O
except	O
that	O
the	O
input	O
feature	O
and	O
the	O
corresponding	O
hidden	O
layers	O
are	O
removed	O
.	O
	
Among	O
the	O
above	O
methods	O
,	O
LP	B-Method
,	O
GraphEmb	B-Method
and	O
Planetoid	B-Method
-	I-Method
G	I-Method
do	O
not	O
use	O
the	O
features	O
,	O
while	O
TSVM	B-Method
and	O
Feat	B-Method
do	O
not	O
use	O
the	O
graph	O
.	O
	
We	O
include	O
these	O
methods	O
into	O
our	O
experimental	O
settings	O
to	O
better	O
evaluate	O
our	O
approach	O
.	O
	
Our	O
preliminary	O
experiments	O
on	O
the	O
text	B-Task
classification	I-Task
datasets	O
show	O
that	O
the	O
performance	O
of	O
our	O
model	O
is	O
not	O
very	O
sensitive	O
to	O
specific	O
choices	O
of	O
the	O
network	B-Method
architecture	I-Method
.	O
	
We	O
adapt	O
the	O
implementation	O
of	O
GraphEmb	B-Method
to	O
our	O
Skipgram	B-Method
implementation	I-Method
.	O
	
We	O
use	O
the	O
Junto	B-Method
library	I-Method
for	O
label	B-Task
propagation	I-Task
,	O
and	O
SVMLight	B-Method
for	O
TSVM	B-Method
.	O
	
We	O
also	O
use	O
our	O
own	O
implementation	O
of	O
ManiReg	B-Method
and	O
SemiEmb	B-Method
by	O
modifying	O
the	O
symbolic	O
objective	O
function	O
in	O
Planetoid	B-Method
.	O
	
In	O
all	O
of	O
our	O
experiments	O
,	O
we	O
set	O
the	O
model	O
hyper	O
-	O
parameters	O
to	O
,	O
,	O
,	O
and	O
for	O
Planetoid	B-Method
.	O
	
We	O
use	O
the	O
same	O
,	O
and	O
for	O
GraphEmb	B-Method
,	O
and	O
the	O
same	O
and	O
for	O
ManiReg	B-Method
and	O
SemiEmb	B-Method
.	O
	
We	O
tune	O
,	O
,	O
,	O
the	O
learning	B-Metric
rate	I-Metric
and	O
hyper	O
-	O
parameters	O
in	O
other	O
models	O
based	O
on	O
an	O
additional	O
data	O
split	O
with	O
a	O
different	O
random	O
seed	O
.	O
	
The	O
statistics	O
for	O
five	O
of	O
our	O
benchmark	O
datasets	O
are	O
reported	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
For	O
each	O
dataset	O
,	O
we	O
split	O
all	O
instances	O
into	O
three	O
parts	O
,	O
labeled	O
data	O
,	O
unlabeled	O
data	O
,	O
and	O
test	O
data	O
.	O
	
Inductive	B-Method
methods	I-Method
are	O
trained	O
on	O
the	O
labeled	O
and	O
unlabeled	O
data	O
,	O
and	O
tested	O
on	O
the	O
test	O
data	O
.	O
	
Transductive	B-Method
methods	I-Method
,	O
on	O
the	O
other	O
hand	O
,	O
are	O
trained	O
on	O
the	O
labeled	O
,	O
unlabeled	O
data	O
,	O
and	O
test	O
data	O
without	O
labels	O
.	O
	
subsection	O
:	O
Text	B-Task
Classification	I-Task
	
We	O
first	O
considered	O
three	O
text	B-Task
classification	I-Task
datasets	O
,	O
Citeseer	B-Material
,	O
Cora	B-Material
and	O
Pubmed	B-Material
.	O
	
Each	O
dataset	O
contains	O
bag	B-Method
-	I-Method
of	I-Method
-	I-Method
words	I-Method
representation	I-Method
of	I-Method
documents	I-Method
and	O
citation	O
links	O
between	O
the	O
documents	O
.	O
	
We	O
treat	O
the	O
bag	O
-	O
of	O
-	O
words	O
as	O
feature	O
vectors	O
.	O
	
We	O
construct	O
the	O
graph	O
based	O
on	O
the	O
citation	O
links	O
;	O
if	O
document	O
cites	O
,	O
then	O
we	O
set	O
.	O
	
The	O
goal	O
is	O
to	O
classify	O
each	O
document	O
into	O
one	O
class	O
.	O
	
We	O
randomly	O
sample	O
instances	O
for	O
each	O
class	O
as	O
labeled	O
data	O
,	O
instances	O
as	O
test	O
data	O
,	O
and	O
the	O
rest	O
are	O
used	O
as	O
unlabeled	O
data	O
.	O
	
The	O
same	O
data	O
splits	O
are	O
used	O
for	O
different	O
methods	O
,	O
and	O
we	O
compute	O
the	O
average	O
accuracy	B-Metric
for	O
comparison	O
.	O
	
The	O
experimental	O
results	O
are	O
reported	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Among	O
the	O
inductive	B-Method
methods	I-Method
,	O
Planetoid	B-Method
-	I-Method
I	I-Method
achieves	O
the	O
best	O
performance	O
on	O
all	O
the	O
three	O
datasets	O
with	O
the	O
improvement	O
of	O
up	O
to	O
on	O
Pubmed	B-Material
,	O
which	O
indicates	O
that	O
our	O
embedding	B-Method
techniques	I-Method
are	O
more	O
effective	O
than	O
graph	B-Method
Laplacian	I-Method
regularization	I-Method
.	O
	
Among	O
the	O
transductive	B-Method
methods	O
,	O
Planetoid	B-Method
-	I-Method
T	I-Method
achieves	O
the	O
best	O
performance	O
on	O
Cora	B-Material
and	O
Pubmed	B-Material
,	O
while	O
TSVM	B-Method
performs	O
the	O
best	O
on	O
Citeseer	B-Material
.	O
	
However	O
,	O
TSVM	B-Method
does	O
not	O
perform	O
well	O
on	O
Cora	B-Material
and	O
Pubmed	B-Material
.	O
	
Planetoid	B-Method
-	I-Method
I	I-Method
slightly	O
outperforms	O
Planetoid	B-Method
-	I-Method
T	I-Method
on	O
Citeseer	B-Material
and	O
Pubmed	B-Material
,	O
while	O
Planetoid	B-Method
-	I-Method
T	I-Method
gets	O
up	O
to	O
improvement	O
over	O
Planetoid	B-Method
-	I-Method
I	I-Method
on	O
Cora	B-Material
.	O
	
We	O
conjecture	O
that	O
in	O
Planetoid	B-Method
-	I-Method
I	I-Method
,	O
the	O
feature	O
vectors	O
impose	O
constraints	O
on	O
the	O
learned	O
embeddings	O
,	O
since	O
they	O
are	O
represented	O
by	O
a	O
parameterized	O
function	O
of	O
the	O
input	O
feature	O
vectors	O
.	O
	
If	O
such	O
constraints	O
are	O
appropriate	O
,	O
as	O
is	O
the	O
case	O
on	O
Citeseer	B-Material
and	O
Pubmed	B-Material
,	O
it	O
improves	O
the	O
non	B-Task
-	I-Task
convex	I-Task
optimization	I-Task
of	I-Task
embedding	I-Task
learning	I-Task
and	O
leads	O
to	O
better	O
performance	O
.	O
	
However	O
,	O
if	O
such	O
constraints	O
rule	O
out	O
the	O
optimal	O
embeddings	O
,	O
the	O
inductive	B-Method
model	I-Method
will	O
suffer	O
.	O
	
Planetoid	B-Method
-	I-Method
G	I-Method
consistently	O
outperforms	O
GraphEmb	B-Method
on	O
all	O
three	O
datasets	O
,	O
which	O
indicates	O
that	O
joint	B-Method
training	I-Method
with	O
label	O
information	O
can	O
improve	O
the	O
performance	O
over	O
training	O
the	O
supervised	O
and	O
unsupervised	O
objectives	O
separately	O
.	O
	
Figure	O
[	O
reference	O
]	O
displays	O
the	O
-	O
D	O
embedding	O
spaces	O
on	O
the	O
Cora	B-Material
dataset	I-Material
using	O
t	B-Method
-	I-Method
SNE	I-Method
.	O
	
Note	O
that	O
different	O
classes	O
are	O
better	O
separated	O
in	O
the	O
embedding	O
space	O
of	O
Planetoid	B-Method
-	I-Method
T	I-Method
than	O
that	O
of	O
GraphEmb	B-Method
and	O
SemiEmb	B-Method
,	O
which	O
is	O
consistent	O
with	O
our	O
empirical	O
findings	O
.	O
	
We	O
also	O
observe	O
similar	O
results	O
for	O
the	O
other	O
two	O
datasets	O
.	O
	
subsection	O
:	O
Distantly	B-Task
-	I-Task
Supervised	I-Task
Entity	I-Task
Extraction	I-Task
	
We	O
next	O
considered	O
the	O
DIEL	B-Task
(	I-Task
Distant	I-Task
Information	I-Task
Extraction	I-Task
using	O
coordinate	O
-	O
term	O
Lists	O
)	O
dataset	O
.	O
	
The	O
DIEL	O
dataset	O
contains	O
pre	O
-	O
extracted	O
features	O
for	O
each	O
entity	O
mention	O
in	O
text	O
,	O
and	O
a	O
graph	O
that	O
connects	O
entity	O
mentions	O
to	O
coordinate	O
lists	O
.	O
	
The	O
goal	O
is	O
to	O
extract	O
medical	O
entities	O
from	O
text	O
given	O
feature	O
vectors	O
and	O
the	O
graph	O
.	O
	
We	O
follow	O
the	O
exact	O
experimental	O
setup	O
as	O
in	O
the	O
original	O
DIEL	O
paper	O
,	O
including	O
data	O
splits	O
of	O
different	O
runs	O
,	O
preprocessing	O
of	O
entity	O
mentions	O
and	O
coordinate	O
lists	O
,	O
and	O
evaluation	O
.	O
	
We	O
treat	O
the	O
top	O
-	O
entities	O
given	O
by	O
a	O
model	O
as	O
positive	O
instances	O
,	O
and	O
compute	O
recall@	B-Metric
for	O
evaluation	B-Task
(	O
is	O
set	O
to	O
following	O
the	O
DIEL	O
paper	O
)	O
.	O
	
We	O
report	O
the	O
average	O
result	O
of	O
10	O
runs	O
in	O
Table	O
[	O
reference	O
]	O
,	O
where	O
Feat	O
refers	O
to	O
a	O
result	O
obtained	O
by	O
SVM	B-Method
(	O
referred	O
to	O
as	O
DS	B-Method
-	I-Method
Baseline	I-Method
in	O
the	O
DIEL	O
paper	O
)	O
.	O
	
The	O
result	O
of	O
LP	O
was	O
also	O
taken	O
from	O
.	O
	
DIEL	B-Method
in	O
Table	O
[	O
reference	O
]	O
refers	O
to	O
the	O
method	O
proposed	O
by	O
the	O
original	O
paper	O
,	O
which	O
is	O
an	O
improved	O
version	O
of	O
label	B-Method
propagation	I-Method
that	O
trains	O
classifiers	B-Method
on	O
feature	O
vectors	O
based	O
on	O
the	O
output	O
of	O
label	B-Method
propagation	I-Method
.	O
	
We	O
did	O
not	O
include	O
TSVM	B-Method
into	O
the	O
comparison	O
since	O
it	O
does	O
not	O
scale	O
.	O
	
Since	O
we	O
use	O
Freebase	O
as	O
ground	O
truth	O
and	O
some	O
entities	O
are	O
not	O
present	O
in	O
text	O
,	O
the	O
upper	O
bound	O
of	O
recall	B-Metric
as	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
is	O
.	O
	
Both	O
Planetoid	B-Method
-	I-Method
I	I-Method
and	O
Planetoid	B-Method
-	I-Method
T	I-Method
significantly	O
outperform	O
all	O
other	O
methods	O
.	O
	
Each	O
of	O
Planetoid	B-Method
-	I-Method
I	I-Method
and	O
Planetoid	B-Method
-	I-Method
T	I-Method
achieves	O
the	O
best	O
performance	O
in	O
5	O
out	O
of	O
10	O
runs	O
,	O
and	O
they	O
give	O
a	O
similar	O
recall	B-Metric
on	O
average	O
,	O
which	O
indicates	O
that	O
there	O
is	O
no	O
significant	O
difference	O
between	O
these	O
two	O
methods	O
on	O
this	O
dataset	O
.	O
	
Planetoid	B-Method
-	I-Method
G	I-Method
clearly	O
outperforms	O
GraphEmb	B-Method
,	O
which	O
again	O
shows	O
the	O
benefit	O
of	O
joint	B-Method
training	I-Method
.	O
	
subsection	O
:	O
Entity	B-Task
Classification	I-Task
	
We	O
sorted	O
out	O
an	O
entity	B-Task
classification	I-Task
dataset	O
from	O
the	O
knowledge	B-Material
base	I-Material
of	O
Never	B-Material
Ending	I-Material
Language	I-Material
Learning	I-Material
(	O
NELL	B-Material
)	O
and	O
a	O
hierarchical	O
entity	B-Task
classification	I-Task
dataset	O
that	O
links	O
NELL	B-Material
entities	I-Material
to	O
text	O
in	O
ClueWeb09	O
.	O
	
We	O
extracted	O
the	O
entities	O
and	O
the	O
relations	O
between	O
entities	O
from	O
the	O
NELL	O
knowledge	B-Material
base	I-Material
,	O
and	O
then	O
obtained	O
text	O
description	O
by	O
linking	O
the	O
entities	O
to	O
ClueWeb09	O
.	O
	
We	O
use	O
text	B-Method
bag	I-Method
-	I-Method
of	I-Method
-	I-Method
words	I-Method
representation	I-Method
as	O
feature	O
vectors	O
of	O
the	O
entities	O
.	O
	
We	O
next	O
describe	O
how	O
to	O
construct	O
the	O
graph	O
based	O
on	O
the	O
knowledge	B-Material
base	I-Material
.	O
	
We	O
first	O
remove	O
relations	O
that	O
are	O
not	O
populated	O
in	O
NELL	B-Material
,	O
including	O
“	O
generalizations	O
”	O
,	O
“	O
haswikipediaurl	O
”	O
,	O
and	O
“	O
atdate	O
”	O
.	O
	
In	O
the	O
knowledge	B-Material
base	I-Material
,	O
each	O
relation	O
is	O
denoted	O
as	O
a	O
triplet	O
,	O
where	O
,	O
,	O
denote	O
head	O
entity	O
,	O
relation	O
,	O
and	O
tail	O
entity	O
respectively	O
.	O
	
We	O
treat	O
each	O
entity	O
as	O
a	O
node	O
in	O
the	O
graph	O
,	O
and	O
each	O
relation	O
is	O
split	O
as	O
two	O
nodes	O
and	O
in	O
the	O
graph	O
.	O
	
For	O
each	O
,	O
we	O
add	O
two	O
edges	O
in	O
the	O
graph	O
,	O
and	O
.	O
	
We	O
removed	O
all	O
classes	O
with	O
less	O
than	O
entities	O
.	O
	
The	O
goal	O
is	O
to	O
classify	O
the	O
entities	O
in	O
the	O
knowledge	B-Material
base	I-Material
into	O
one	O
of	O
the	O
classes	O
given	O
the	O
feature	O
vectors	O
and	O
the	O
graph	O
.	O
	
Let	O
be	O
the	O
labeling	B-Metric
rate	I-Metric
.	O
	
We	O
set	O
to	O
,	O
,	O
and	O
.	O
	
instances	O
are	O
labeled	O
for	O
a	O
class	O
with	O
entities	O
,	O
so	O
each	O
class	O
has	O
at	O
least	O
one	O
entity	O
in	O
the	O
labeled	O
data	O
.	O
	
We	O
report	O
the	O
results	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
We	O
did	O
not	O
include	O
TSVM	B-Method
since	O
it	O
does	O
not	O
scale	O
to	O
such	O
a	O
large	O
number	O
of	O
classes	O
with	O
the	O
one	B-Method
-	I-Method
vs	I-Method
-	I-Method
rest	I-Method
scheme	I-Method
.	O
	
Adding	O
feature	O
vectors	O
does	O
not	O
improve	O
the	O
performance	O
of	O
Planetoid	B-Method
-	I-Method
T	I-Method
,	O
so	O
we	O
set	O
the	O
feature	O
vectors	O
for	O
Planetoid	B-Method
-	I-Method
T	I-Method
to	O
be	O
all	O
empty	O
,	O
and	O
therefore	O
Planetoid	B-Method
-	I-Method
T	I-Method
is	O
equivalent	O
to	O
Planetoid	B-Method
-	I-Method
G	I-Method
in	O
this	O
case	O
.	O
	
Planetoid	B-Method
-	I-Method
I	I-Method
significantly	O
outperforms	O
the	O
best	O
of	O
the	O
other	O
compared	O
inductive	B-Method
methods	I-Method
	
—	O
i.e	O
.	O
,	O
SemiEmb	O
—	O
by	O
,	O
,	O
and	O
respectively	O
with	O
three	O
labeling	B-Metric
rates	I-Metric
.	O
	
As	O
the	O
labeling	B-Metric
rate	I-Metric
decreases	O
,	O
the	O
improvement	O
of	O
Planetoid	B-Method
-	I-Method
I	I-Method
over	O
SemiEmb	B-Method
becomes	O
more	O
significant	O
.	O
	
Graph	O
structure	O
is	O
more	O
informative	O
than	O
features	O
in	O
this	O
dataset	O
,	O
so	O
inductive	B-Method
methods	I-Method
perform	O
worse	O
than	O
transductive	B-Method
methods	O
.	O
	
Planetoid	B-Method
-	I-Method
G	I-Method
outperforms	O
GraphEmb	B-Method
by	O
,	O
and	O
.	O
	
section	O
:	O
Conclusion	O
	
Our	O
contribution	O
is	O
three	O
-	O
fold	O
:	O
a	O
)	O
incontrast	O
to	O
previous	O
semi	B-Method
-	I-Method
supervised	I-Method
learning	I-Method
approaches	I-Method
that	O
largely	O
depend	O
on	O
graph	B-Method
Laplacian	I-Method
regularization	I-Method
,	O
we	O
propose	O
a	O
novel	O
approach	O
by	O
joint	B-Task
training	I-Task
of	I-Task
classification	I-Task
and	I-Task
graph	I-Task
context	I-Task
prediction	I-Task
;	O
b	O
)	O
since	O
it	O
is	O
difficult	O
to	O
generalize	O
graph	O
embeddings	O
to	O
novel	O
instances	O
,	O
we	O
design	O
a	O
novel	O
inductive	B-Method
approach	I-Method
that	O
conditions	O
embeddings	O
on	O
input	O
features	O
;	O
c	O
)	O
we	O
empirically	O
show	O
substantial	O
improvement	O
over	O
existing	O
methods	O
(	O
up	O
to	O
and	O
on	O
average	O
)	O
,	O
and	O
even	O
more	O
significant	O
improvement	O
in	O
the	O
inductive	B-Task
setting	I-Task
(	O
up	O
to	O
and	O
on	O
average	O
)	O
.	O
	
Our	O
experimental	O
results	O
on	O
five	O
benchmark	O
datasets	O
also	O
show	O
that	O
a	O
)	O
joint	B-Method
training	I-Method
gives	O
improvement	O
over	O
unsupervised	B-Method
learning	I-Method
;	O
b	O
)	O
predicting	B-Task
graph	I-Task
context	I-Task
is	O
more	O
effective	O
than	O
graph	B-Method
Laplacian	I-Method
regularization	I-Method
;	O
c	O
)	O
the	O
performance	O
of	O
the	O
inductive	B-Method
variant	I-Method
depends	O
on	O
the	O
informativeness	O
of	O
feature	O
vectors	O
.	O
	
One	O
direction	O
of	O
future	O
work	O
would	O
be	O
to	O
apply	O
our	O
framework	O
to	O
more	O
complex	O
networks	O
,	O
including	O
recurrent	B-Method
networks	I-Method
.	O
	
It	O
would	O
also	O
be	O
interesting	O
to	O
experiment	O
with	O
datasets	O
where	O
a	O
graph	O
is	O
computed	O
based	O
on	O
distances	O
between	O
feature	O
vectors	O
.	O
	
section	O
:	O
Acknowledgements	O
	
This	O
work	O
was	O
funded	O
by	O
the	O
NSF	O
under	O
grants	O
CCF	O
-	O
1414030	O
and	O
IIS	O
-	O
1250956	O
,	O
and	O
by	O
Google	O
.	O
	
bibliography	O
:	O
References	O
	
Learning	O
Deep	B-Method
Parsimonious	I-Method
Representations	I-Method
	
In	O
this	O
paper	O
we	O
aim	O
at	O
facilitating	O
generalization	B-Task
for	O
deep	B-Method
networks	I-Method
while	O
supporting	O
interpretability	O
of	O
the	O
learned	B-Method
representations	I-Method
.	O
	
Towards	O
this	O
goal	O
,	O
we	O
propose	O
a	O
clustering	B-Method
based	O
regularization	O
that	O
encourages	O
parsimonious	B-Method
representations	I-Method
.	O
	
Our	O
k	B-Method
-	I-Method
means	I-Method
style	I-Method
objective	I-Method
is	O
easy	O
to	O
optimize	O
and	O
flexible	O
,	O
supporting	O
various	O
forms	O
of	O
clustering	B-Method
,	O
such	O
as	O
sample	B-Method
clustering	I-Method
,	O
spatial	B-Method
clustering	I-Method
,	O
as	O
well	O
as	O
co	B-Method
-	I-Method
clustering	I-Method
.	O
	
We	O
demonstrate	O
the	O
effectiveness	O
of	O
our	O
approach	O
on	O
the	O
tasks	O
of	O
unsupervised	B-Task
learning	I-Task
,	O
classification	B-Task
,	O
fine	B-Task
grained	I-Task
categorization	I-Task
,	O
and	O
zero	B-Task
-	I-Task
shot	I-Task
learning	I-Task
.	O
	
1	O
Introduction	O
	
In	O
recent	O
years	O
,	O
deep	B-Method
neural	I-Method
networks	I-Method
have	O
been	O
shown	O
to	O
perform	O
extremely	O
well	O
on	O
a	O
variety	O
of	O
tasks	O
including	O
classification	B-Task
[	O
21	O
]	O
,	O
semantic	B-Task
segmentation	I-Task
[	O
13	O
]	O
,	O
machine	B-Task
translation	I-Task
[	O
27	O
]	O
and	O
speech	B-Task
recognition	I-Task
[	O
16	O
]	O
.	O
	
This	O
has	O
led	O
to	O
their	O
adoption	O
across	O
many	O
areas	O
such	O
as	O
computer	B-Task
vision	I-Task
,	O
natural	B-Task
language	I-Task
processing	I-Task
and	O
robotics	B-Task
[	O
16	O
,	O
21	O
,	O
22	O
,	O
27	O
]	O
.	O
Three	O
major	O
advances	O
are	O
responsible	O
for	O
the	O
recent	O
success	O
of	O
neural	B-Method
networks	I-Method
:	O
the	O
increase	O
in	O
available	O
computational	O
resources	O
,	O
access	O
to	O
large	O
scale	O
data	O
sets	O
,	O
and	O
several	O
algorithmic	O
improvements	O
.	O
	
Many	O
of	O
these	O
algorithmic	O
advances	O
are	O
related	O
to	O
regularization	B-Task
,	O
which	O
is	O
key	O
to	O
prevent	O
overfitting	O
and	O
improve	O
generalization	B-Task
of	O
the	O
learned	B-Method
classifier	I-Method
,	O
as	O
the	O
current	O
trend	O
is	O
to	O
increase	O
the	O
capacity	O
of	O
neural	B-Method
nets	I-Method
.	O
	
For	O
example	O
,	O
batch	B-Method
normalization	I-Method
[	O
18	O
]	O
is	O
used	O
to	O
normalize	O
intermediate	O
representations	O
which	O
can	O
be	O
interpreted	O
as	O
imposing	O
constraints	O
.	O
	
In	O
contrast	O
,	O
dropout	B-Method
[	O
26	O
]	O
removes	O
a	O
fraction	O
of	O
the	O
learned	O
representations	O
at	O
random	O
to	O
prevent	O
co	B-Task
-	I-Task
adaptation	I-Task
.	O
	
Learning	B-Task
of	I-Task
de	I-Task
-	I-Task
correlated	I-Task
activations	I-Task
[	O
6	O
]	O
shares	O
a	O
similar	O
idea	O
since	O
it	O
explicitly	O
discourages	O
correlation	O
between	O
the	O
units	O
.	O
	
In	O
this	O
paper	O
we	O
propose	O
a	O
new	O
type	O
of	O
regularization	B-Method
that	O
encourages	O
the	O
network	B-Method
representations	I-Method
to	O
form	O
clusters	O
.	O
	
As	O
a	O
consequence	O
,	O
the	O
learned	O
feature	O
space	O
is	O
compactly	O
representable	O
,	O
facilitating	O
generalization	B-Task
.	O
	
Furthermore	O
,	O
clustering	B-Method
supports	O
interpretability	O
of	O
the	O
learned	B-Method
representations	I-Method
.	O
	
We	O
formulate	O
our	O
regularization	O
with	O
a	O
k	B-Method
-	I-Method
means	I-Method
style	I-Method
objective	I-Method
which	O
is	O
easy	O
to	O
optimize	O
,	O
and	O
investigate	O
different	O
types	O
of	O
clusterings	B-Method
,	O
including	O
sample	B-Method
clustering	I-Method
,	O
spatial	B-Method
clustering	I-Method
,	O
and	O
co	B-Method
-	I-Method
clustering	I-Method
.	O
	
We	O
demonstrate	O
the	O
generalization	B-Task
performance	O
of	O
our	O
proposed	O
method	O
in	O
several	O
settings	O
:	O
autoencoders	B-Method
trained	O
on	O
the	O
MNIST	O
dataset	O
[	O
23	O
]	O
,	O
classification	B-Task
on	O
CIFAR10	O
and	O
CIFAR100	O
[	O
20	O
]	O
,	O
as	O
well	O
as	O
fine	O
-	O
grained	O
classification	B-Task
and	O
zero	B-Method
-	I-Method
shot	I-Method
learning	I-Method
on	O
the	O
CUB	B-Material
-	I-Material
200	I-Material
-	I-Material
2011	I-Material
dataset	I-Material
	
[	O
34	O
]	O
.	O
	
We	O
show	O
that	O
our	O
approach	O
leads	O
to	O
significant	O
wins	O
in	O
all	O
these	O
scenarios	O
.	O
	
In	O
addition	O
,	O
we	O
are	O
able	O
to	O
demonstrate	O
on	O
the	O
CUB	B-Material
-	I-Material
200	I-Material
-	I-Material
2011	I-Material
dataset	I-Material
that	O
the	O
network	B-Method
representation	I-Method
captures	O
meaningful	B-Method
part	I-Method
representations	I-Method
even	O
though	O
it	O
is	O
not	O
explicitly	O
trained	O
to	O
do	O
so	O
.	O
	
2	O
Related	O
Work	O
Standard	O
neural	B-Method
network	I-Method
regularization	I-Method
involves	O
penalties	O
on	O
the	O
weights	O
based	O
on	O
the	O
norm	O
of	O
the	O
parameters	O
[	O
29	O
,	O
30	O
]	O
.	O
	
Also	O
popular	O
are	O
regularization	B-Method
methods	I-Method
applied	O
to	O
intermediate	B-Method
representations	I-Method
,	O
29th	O
Conference	O
on	O
Neural	B-Task
Information	I-Task
Processing	I-Task
Systems	I-Task
(	O
NIPS	B-Task
2016	I-Task
)	O
,	O
Barcelona	O
,	O
Spain	O
.	O
such	O
as	O
Dropout	B-Method
[	O
26	O
]	O
,	O
Drop	B-Method
-	I-Method
Connect	I-Method
[	O
32	O
]	O
,	O
Maxout	B-Method
[	O
10	O
]	O
and	O
DeCov	B-Method
[	O
6	O
]	O
.	O
	
These	O
approaches	O
share	O
the	O
aim	O
of	O
preventing	O
the	O
activations	O
in	O
the	O
network	O
to	O
be	O
correlated	O
.	O
	
Our	O
work	O
can	O
be	O
seen	O
as	O
a	O
different	O
form	O
of	O
regularization	B-Task
,	O
where	O
we	O
encourage	O
parsimonious	B-Method
representations	I-Method
.	O
	
A	O
variety	O
of	O
approaches	O
have	O
applied	O
clustering	B-Method
to	O
the	O
parameters	O
of	O
the	O
neural	B-Method
network	I-Method
with	O
the	O
aim	O
of	O
compressing	O
the	O
network	O
.	O
	
Compression	B-Metric
rates	I-Metric
of	O
more	O
than	O
an	O
order	O
of	O
magnitude	O
were	O
demonstrated	O
in	O
[	O
11	O
]	O
without	O
sacrificing	O
accuracy	B-Metric
.	O
	
In	O
the	O
same	O
spirit	O
hash	O
functions	O
were	O
exploited	O
in	O
[	O
5	O
]	O
.	O
Early	O
approaches	O
to	O
compression	B-Task
include	O
biased	B-Method
weight	I-Method
decay	I-Method
[	O
12	O
]	O
and	O
[	O
14	O
,	O
24	O
]	O
,	O
which	O
prunes	O
the	O
network	O
based	O
on	O
the	O
Hessian	O
of	O
the	O
loss	O
function	O
.	O
	
Recently	O
,	O
various	O
combinations	O
of	O
clustering	B-Method
with	O
representation	B-Method
learning	I-Method
have	O
been	O
proposed	O
.	O
	
We	O
categorize	O
them	O
broadly	O
into	O
two	O
areas	O
:	O
(	O
i	O
)	O
work	O
that	O
applies	O
clustering	B-Method
after	O
having	O
learned	O
a	O
representation	O
,	O
and	O
(	O
ii	O
)	O
approaches	O
that	O
jointly	O
optimize	O
the	O
learning	O
and	O
clustering	B-Method
objectives	O
.	O
	
[	O
4	O
]	O
combines	O
deep	B-Method
belief	I-Method
networks	I-Method
(	O
DBN	B-Method
)	O
with	O
non	O
-	O
parametric	O
maximum	O
-	O
margin	O
clustering	B-Method
in	O
a	O
posthoc	O
manner	O
:	O
	
A	O
DBN	B-Method
is	O
trained	O
layer	O
-	O
wise	O
to	O
obtain	O
an	O
intermediate	B-Method
representation	I-Method
of	O
the	O
data	O
;	O
non	O
-	O
parametric	O
maximum	O
-	O
margin	O
clustering	B-Method
is	O
then	O
applied	O
to	O
the	O
data	B-Method
representation	I-Method
.	O
	
Another	O
line	O
of	O
work	O
utilizes	O
an	O
embedding	B-Method
of	I-Method
the	I-Method
deep	I-Method
network	I-Method
,	O
which	O
can	O
be	O
based	O
on	O
annotated	O
data	O
[	O
15	O
]	O
,	O
or	O
from	O
a	O
learned	O
unsupervised	B-Method
method	I-Method
such	O
as	O
a	O
stacked	B-Method
auto	I-Method
-	I-Method
encoder	I-Method
[	O
28	O
]	O
.	O
	
In	O
these	O
approaches	O
,	O
the	O
network	O
is	O
trained	O
to	O
approximate	O
the	O
embedding	O
,	O
and	O
subsequently	O
either	O
k	B-Method
-	I-Method
means	I-Method
or	O
spectral	B-Method
clustering	I-Method
is	O
performed	O
to	O
partition	O
the	O
space	O
.	O
	
An	O
alternative	O
is	O
to	O
use	O
non	B-Method
-	I-Method
negative	I-Method
matrix	I-Method
factorization	I-Method
,	O
which	O
represents	O
a	O
given	O
data	O
matrix	O
as	O
the	O
product	O
of	O
components	O
	
[	O
31	O
]	O
.	O
This	O
deep	B-Method
non	I-Method
-	I-Method
negative	I-Method
matrix	I-Method
factorization	I-Method
is	O
trained	O
using	O
the	O
reconstruction	O
loss	O
rather	O
than	O
a	O
clustering	B-Method
objective	I-Method
.	O
	
Nonetheless	O
,	O
it	O
was	O
shown	O
that	O
factors	O
lower	O
in	O
the	O
hierarchy	O
have	O
superior	O
clustering	B-Method
performance	O
on	O
lowlevel	O
concepts	O
	
while	O
factors	O
later	O
in	O
the	O
hierarchy	O
cluster	O
high	O
-	O
level	O
concepts	O
.	O
	
The	O
aforementioned	O
approaches	O
differ	O
from	O
our	O
proposed	O
technique	O
,	O
since	O
we	O
aim	O
at	O
jointly	O
learning	O
a	O
representation	B-Task
that	O
is	O
parsimonious	O
via	O
a	O
clustering	B-Method
regularization	I-Method
.	O
	
Also	O
related	O
are	O
approaches	O
that	O
utilize	O
sparse	B-Method
coding	I-Method
.	O
	
Wang	O
et	O
al	O
.	O
	
[	O
33	O
]	O
unrolls	O
the	O
iterations	O
forming	O
the	O
sparse	B-Method
codes	I-Method
and	O
optimizes	O
end	O
-	O
to	O
-	O
end	O
the	O
involved	O
parameters	O
using	O
a	O
clustering	B-Method
objective	I-Method
as	O
loss	O
function	O
[	O
33	O
]	O
.	O
	
The	O
proposed	O
framework	O
is	O
further	O
augmented	O
by	O
clustering	B-Method
objectives	I-Method
applied	O
to	O
intermediate	B-Method
representations	I-Method
,	O
which	O
act	O
as	O
feature	B-Method
regularization	I-Method
within	O
the	O
unrolled	B-Method
optimization	I-Method
.	O
	
They	O
found	O
that	O
features	O
lower	O
in	O
the	O
unrolled	O
hierarchy	O
cluster	O
low	O
-	O
level	O
concepts	O
,	O
while	O
features	O
later	O
in	O
the	O
hierarchy	O
capture	O
high	O
-	O
level	O
concepts	O
.	O
	
Our	O
method	O
differs	O
in	O
that	O
we	O
use	O
convolutional	B-Method
neural	I-Method
networks	I-Method
rather	O
than	O
unrolling	O
a	O
sparse	B-Method
coding	I-Method
optimization	I-Method
.	O
	
In	O
the	O
context	O
of	O
unsupervised	O
clustering	B-Method
[	O
35	O
]	O
exploited	O
agglomerative	B-Method
clustering	I-Method
as	O
a	O
regularizer	B-Method
;	O
this	O
approach	O
was	O
formulated	O
as	O
a	O
recurrent	B-Method
network	I-Method
.	O
	
In	O
contrast	O
we	O
employ	O
a	O
k	B-Method
-	I-Method
means	I-Method
like	I-Method
clustering	I-Method
objective	I-Method
which	O
simplifies	O
the	O
optimization	B-Task
significantly	O
and	O
does	O
not	O
require	O
a	O
recurrent	B-Method
procedure	I-Method
.	O
	
Furthermore	O
,	O
we	O
investigate	O
both	O
unsupervised	B-Method
and	I-Method
supervised	I-Method
learning	I-Method
.	O
	
3	O
Learning	O
Deep	B-Method
Parsimonious	I-Method
Representations	I-Method
	
In	O
this	O
section	O
,	O
we	O
introduce	O
our	O
new	O
clustering	B-Method
based	O
regularization	O
which	O
not	O
only	O
encourages	O
the	O
neural	B-Method
network	I-Method
to	O
learn	O
more	O
compact	O
representations	O
,	O
but	O
also	O
enables	O
interpretability	O
of	O
the	O
neural	B-Method
network	I-Method
.	O
	
We	O
first	O
show	O
that	O
by	O
exploiting	O
different	O
unfoldings	O
of	O
the	O
representation	B-Method
tensor	I-Method
,	O
we	O
obtain	O
multiple	O
types	O
of	O
clusterings	B-Method
,	O
each	O
possessing	O
different	O
properties	O
.	O
	
We	O
then	O
devise	O
an	O
efficient	O
online	B-Method
update	I-Method
to	O
jointly	O
learn	O
the	O
clustering	B-Method
with	O
the	O
parameters	O
of	O
the	O
neural	B-Method
network	I-Method
.	O
	
3.1	O
Clustering	B-Method
of	I-Method
Representations	I-Method
	
We	O
first	O
introduce	O
some	O
notation	O
.	O
	
We	O
refer	O
to	O
[	O
K	O
]	O
as	O
the	O
set	O
of	O
K	O
positive	O
integers	O
,	O
i.e.	O
,	O
[	O
K	O
]	O
=	O
{	O
1	O
,	O
2	O
,	O
...	O
,	O
	
K}.	O
	
We	O
use	O
S\A	O
to	O
denote	O
the	O
set	O
S	O
with	O
elements	O
from	O
the	O
set	O
	
A	O
removed	O
.	O
	
A	O
tensor	B-Method
is	O
a	O
multilinear	B-Method
map	I-Method
over	O
a	O
set	O
of	O
vector	O
spaces	O
.	O
	
In	O
tensor	B-Task
terminology	I-Task
,	O
n	O
-	O
mode	O
vectors	O
of	O
a	O
D	O
-	O
order	O
tensor	O
Y	O
∈	O
RI1×I2×···×ID	O
are	O
In	O
-	O
dimensional	O
vectors	O
obtained	O
from	O
Y	O
by	O
varying	O
the	O
index	O
in	O
Indimension	O
,	O
while	O
keeping	O
all	O
other	O
indices	O
fixed	O
.	O
	
An	O
n	B-Method
-	I-Method
mode	I-Method
matrix	I-Method
unfolding	I-Method
of	O
a	O
tensor	B-Method
is	O
a	O
matrix	O
which	O
has	O
all	O
n	O
-	O
mode	O
vectors	O
as	O
its	O
columns	O
[	O
7	O
]	O
.	O
Formally	O
we	O
use	O
the	O
operator	O
T	O
{	O
In}×{Ij	O
|j∈	O
[	O
D	O
]	O
\n	O
}	O
to	O
denote	O
the	O
n	B-Method
-	I-Method
mode	I-Method
matrix	I-Method
unfolding	I-Method
,	O
which	O
returns	O
a	O
matrix	O
of	O
size	O
	
In	O
×	O
∏	O
j∈	O
[	O
D	O
]	O
\n	O
Ij	O
.	O
	
Similarly	O
,	O
we	O
definee	O
T	O
{	O
Ii	O
,	O
Ij}×{Ik|k∈	O
[	O
D	O
]	O
\{i	O
,	O
j	O
}	O
}	O
to	O
be	O
an	O
(	O
i	O
,	O
j	O
)-	O
mode	O
matrix	O
unfolding	O
operator	O
.	O
	
In	O
this	O
case	O
a	O
column	O
vector	O
is	O
a	O
concatenation	O
of	O
one	O
i	O
-	O
mode	O
vector	O
and	O
one	O
j	O
-	O
mode	O
vector	O
.	O
	
We	O
denote	O
the	O
m	O
-	O
th	O
row	O
vector	O
of	O
a	O
matrix	O
X	O
as	O
Xm	O
.	O
	
In	O
this	O
paper	O
we	O
assume	O
the	O
representation	O
of	O
one	O
layer	O
within	O
a	O
neural	B-Method
network	I-Method
to	O
be	O
a	O
4	B-Method
-	I-Method
D	I-Method
tensor	I-Method
Y	I-Method
∈	O
RN×C×H×W	O
,	O
where	O
N	O
,	O
C	O
,	O
H	O
and	O
W	O
are	O
the	O
number	O
of	O
samples	O
within	O
a	O
mini	O
-	O
batch	O
,	O
the	O
number	O
of	O
hidden	O
units	O
,	O
the	O
height	O
and	O
width	O
of	O
the	O
representation	O
respectively	O
.	O
	
Note	O
that	O
C	O
,	O
H	O
and	O
W	O
can	O
vary	O
between	O
layers	O
,	O
and	O
in	O
the	O
case	O
of	O
a	O
fully	O
connected	O
layer	O
,	O
the	O
dimensions	O
along	O
height	O
and	O
width	O
become	O
a	O
singleton	O
and	O
the	O
tensor	O
degenerates	O
to	O
a	O
matrix	O
.	O
	
Let	O
L	O
be	O
the	O
loss	O
function	O
of	O
a	O
neural	B-Method
network	I-Method
.	O
	
In	O
addition	O
,	O
we	O
refer	O
to	O
the	O
clustering	B-Method
regularization	I-Method
of	O
a	O
single	B-Method
layer	I-Method
viaR.	O
	
The	O
final	O
objective	O
is	O
L	O
+	O
λR	O
,	O
where	O
λ	O
adjusts	O
the	O
importance	O
of	O
the	O
clustering	B-Method
regularization	O
.	O
	
Note	O
that	O
we	O
can	O
add	O
a	O
regularization	O
term	O
for	O
any	O
subset	O
of	O
layers	O
,	O
but	O
we	O
focus	O
on	O
a	O
single	O
layer	O
for	O
notational	O
simplicity	O
.	O
	
In	O
what	O
follows	O
,	O
we	O
show	O
three	O
different	O
types	O
of	O
clustering	B-Method
,	O
each	O
possessing	O
different	O
properties	O
.	O
	
In	O
our	O
framework	O
any	O
variant	O
can	O
be	O
applied	O
to	O
any	O
layer	O
.	O
	
(	O
A	O
	
)	O
Sample	B-Method
Clustering	I-Method
	
:	O
We	O
first	O
investigate	O
clustering	B-Method
along	O
the	O
sample	O
dimension	O
.	O
	
Since	O
the	O
cluster	O
assignments	O
of	O
different	O
layers	O
are	O
not	O
linked	O
,	O
each	O
layer	O
is	O
free	O
to	O
cluster	O
examples	O
in	O
a	O
different	O
way	O
.	O
	
For	O
example	O
,	O
in	O
a	O
ConvNet	B-Method
,	O
bottom	B-Method
layer	I-Method
representations	I-Method
may	O
focus	O
on	O
low	O
-	O
level	O
visual	O
cues	O
,	O
such	O
as	O
color	O
and	O
edges	O
,	O
while	O
top	O
layer	O
features	O
may	O
focus	O
on	O
high	O
-	O
level	O
attributes	O
which	O
have	O
a	O
more	O
semantic	O
meaning	O
.	O
	
We	O
refer	O
the	O
reader	O
to	O
Fig	O
.	O
	
1	O
(	O
a	O
)	O
for	O
an	O
illustration	O
.	O
	
In	O
particular	O
,	O
given	O
the	O
representation	O
tensor	O
Y	O
,	O
we	O
first	O
unfold	O
it	O
into	O
a	O
matrix	O
T	O
{	O
N}×{H	O
,	O
W	O
,	O
C}	O
(	O
Y	O
)	O
∈	O
RN×HWC	O
.	O
	
We	O
then	O
encourage	O
the	O
samples	O
to	O
cluster	O
as	O
follows	O
:	O
Rsample	O
(	O
Y	O
,	O
µ	O
)	O
	
=	O
1	O
	
2NCHW	O
N∑	O
n=1	O
	
∥∥∥T	O
{	O
N}×{H	O
,	O
W	O
,	O
	
C}	O
(	O
Y	O
)	O
n	O
−	O
µzn∥∥∥2	O
,	O
	
(	O
1	O
)	O
where	O
µ	O
is	O
a	O
matrix	O
of	O
size	O
K	O
×	O
HWC	O
encoding	O
all	O
cluster	O
centers	O
,	O
with	O
K	O
the	O
total	O
number	O
of	O
clusters	O
.	O
	
zn	O
∈	O
[	O
K	O
]	O
is	O
a	O
discrete	O
latent	O
variable	O
corresponding	O
to	O
the	O
n	O
-	O
th	O
sample	O
.	O
	
It	O
indicates	O
which	O
cluster	O
this	O
sample	O
belongs	O
to	O
.	O
	
Note	O
that	O
for	O
a	O
fully	O
connected	O
layer	O
,	O
the	O
formulation	O
is	O
the	O
same	O
except	O
that	O
T	O
{	O
N}×{H	O
,	O
W	O
,	O
C}	O
(	O
Y	O
)	O
n	O
and	O
µzn	O
are	O
C	O
-	O
sized	O
vectors	O
since	O
H	O
=	O
W	O
=	O
1	O
in	O
this	O
case	O
.	O
	
(	O
B	O
)	O
Spatial	B-Method
Clustering	I-Method
:	O
The	O
representation	O
of	O
one	O
sample	O
can	O
be	O
regarded	O
as	O
a	O
C	O
-	O
channel	O
“	O
image	O
.	O
	
”	O
	
Each	O
spatial	O
location	O
within	O
that	O
“	O
image	O
”	O
can	O
be	O
thought	O
of	O
as	O
a	O
“	O
pixel	O
,	O
”	O
and	O
is	O
a	O
vector	O
of	O
size	O
C	O
(	O
shown	O
as	O
a	O
colored	O
bar	O
in	O
Fig	O
.	O
1	O
)	O
.	O
	
For	O
a	O
ConvNet	B-Method
,	O
every	O
“	O
pixel	O
”	O
has	O
a	O
corresponding	O
receptive	O
field	O
covering	O
a	O
local	O
region	O
in	O
the	O
input	O
image	O
.	O
	
Therefore	O
,	O
by	O
clustering	B-Method
“	O
pixels	O
”	O
of	O
all	O
images	O
during	O
learning	B-Task
,	O
we	O
expect	O
to	O
model	O
local	O
parts	O
shared	O
by	O
multiple	O
objects	O
or	O
scenes	O
.	O
	
To	O
achieve	O
this	O
,	O
we	O
adopt	O
the	O
unfolding	B-Method
operator	I-Method
T	O
{	O
N	O
,	O
H	O
,	O
W}×{C}	O
(	O
Y	O
)	O
and	O
use	O
Rspatial	B-Method
(	I-Method
Y	I-Method
,	O
µ	O
)	O
=	O
1	O
	
2NCHW	O
NHW∑	O
	
i=1	O
	
‖T	O
{	O
N	O
,	O
H	O
,	O
	
W}×{C}	O
(	O
Y	O
)	O
i	O
−	O
µzi‖2	O
.	O
	
(	O
2	O
)	O
Note	O
that	O
although	O
we	O
use	O
the	O
analogy	O
of	O
a	O
“	O
pixel	O
,	O
”	O
when	O
using	O
text	O
data	O
a	O
“	O
pixel	O
”	O
may	O
corresponds	O
to	O
words	O
.	O
	
For	O
spatial	B-Method
clustering	I-Method
the	O
dimension	O
of	O
the	O
matrix	O
µ	O
is	O
K	O
×	O
C.	O
(	O
C	O
)	O
	
Channel	B-Method
Co	I-Method
-	I-Method
Clustering	I-Method
:	O
This	O
regularizer	B-Method
groups	O
the	O
channels	O
of	O
different	O
samples	O
directly	O
,	O
thus	O
co	O
-	O
clustering	B-Method
samples	O
and	O
filters	O
.	O
	
We	O
expect	O
this	O
type	O
of	O
regularization	B-Method
to	O
model	O
re	O
-	O
occurring	O
Algorithm	O
1	O
:	O
	
Learning	B-Task
Parsimonious	I-Task
Representations	I-Task
1	O
	
:	O
Initialization	O
:	O
Maximum	O
training	O
iteration	O
R	O
,	O
batch	O
size	O
B	O
,	O
smooth	O
weight	O
α	O
,	O
set	O
of	O
clustering	B-Method
layers	O
S	O
and	O
set	O
of	O
cluster	O
centers	O
{	O
µ0k|k	O
∈	O
[	O
K	O
]	O
}	O
,	O
update	O
period	O
M	O
2	O
:	O
	
For	O
iteration	O
t	O
=	O
1	O
,	O
2	O
,	O
...	O
	
,	O
R	O
:	O
3	O
:	O
	
For	O
layer	O
l	O
=	O
1	O
,	O
2	O
,	O
...	O
,	O
L	O
:	O
4	O
:	O
Compute	O
the	O
output	O
representation	O
of	O
layer	O
l	O
as	O
x.	O
5	O
:	O
If	O
l	O
∈	O
S	O
:	O
6	O
:	O
Assigning	O
cluster	O
zn	O
=	O
argmin	O
k	O
‖Xn	O
−	O
µt−1k	O
‖2	O
,	O
∀n	O
∈	O
[	O
B	O
]	O
.	O
7	O
:	O
Compute	O
cluster	O
center	O
	
µ̂k	O
=	O
	
1|Nk|	O
∑	O
n∈Nk	O
Xn	O
,	O
where	O
Nk	O
=	O
	
[	O
B	O
]	O
⋂	O
{	O
n|zn	O
	
=	O
k}.	O
8	O
:	O
Smooth	O
cluster	O
center	O
µtk	O
=	O
	
αµ̂k	O
	
+	O
(	O
1−	O
α	O
)	O
µ	O
t−1	O
k	O
9	O
:	O
	
End	O
10	O
	
:	O
End	O
11	O
:	O
	
Compute	O
the	O
gradients	O
with	O
cluster	O
centers	O
µtk	O
fixed	O
.	O
	
12	O
	
:	O
Update	O
weights	O
.	O
	
13	O
:	O
Update	O
drifted	O
cluster	O
centers	O
using	O
Kmeans	B-Method
++	I-Method
every	O
M	O
iterations	O
.	O
	
14	O
	
:	O
End	O
patterns	O
shared	O
not	O
only	O
among	O
different	O
samples	O
but	O
also	O
within	O
each	O
sample	O
.	O
	
Relying	O
on	O
the	O
unfolding	B-Method
operator	I-Method
T	O
{	O
N	O
,	O
C}×{H	O
,	O
W}	O
(	O
Y	O
)	O
,	O
we	O
formulate	O
this	O
type	O
of	O
clustering	B-Method
objective	I-Method
as	O
Rchannel	B-Method
(	I-Method
Y	I-Method
,	O
µ	O
)	O
	
=	O
1	O
2NCHW	O
NC∑	O
i=1	O
‖T	O
{	O
N	O
,	O
C}×{H	O
,	O
	
W}	O
(	O
Y	O
)	O
i	O
−	O
µzi‖2	O
.	O
	
(	O
3	O
)	O
Note	O
that	O
the	O
dimension	O
of	O
the	O
matrix	O
µ	O
is	O
K	O
×HW	O
in	O
this	O
case	O
.	O
	
3.2	O
Efficient	O
Online	B-Task
Update	I-Task
	
We	O
now	O
derive	O
an	O
efficient	O
online	B-Method
update	I-Method
to	O
jointly	O
learn	O
the	O
weights	O
while	O
clustering	B-Method
the	O
representations	B-Method
of	I-Method
the	I-Method
neural	I-Method
network	I-Method
.	O
	
In	O
particular	O
,	O
we	O
illustrate	O
the	O
sample	O
clustering	B-Method
case	O
while	O
noting	O
that	O
the	O
other	O
types	O
can	O
be	O
derived	O
easily	O
by	O
applying	O
the	O
corresponding	O
unfolding	B-Method
operator	I-Method
.	O
	
For	O
ease	O
of	O
notation	O
,	O
we	O
denote	O
the	O
unfolded	O
matrix	O
T	O
{	O
N}×{H	O
,	O
W	O
,	O
C}	O
(	O
Y	O
)	O
as	O
X.	O
	
The	O
gradient	O
of	O
the	O
clustering	B-Method
regularization	O
layer	O
w.r.t	O
.	O
	
its	O
input	O
representation	O
X	O
can	O
be	O
expressed	O
as	O
,	O
∂R	O
	
∂Xn	O
=	O
1	O
NCHW	O
Xn	O
	
−	O
µzn	O
	
−	O
1Qzn	O
∑	O
	
zp	O
	
=	O
zn	O
,	O
∀p∈	O
[	O
N	O
]	O
	
(	O
Xn	O
−	O
µzp	O
)	O
	
,	O
(	O
4	O
)	O
where	O
Qzn	O
is	O
the	O
number	O
of	O
samples	O
which	O
belong	O
to	O
the	O
zn	O
-	O
th	O
cluster	O
.	O
	
This	O
gradient	O
is	O
then	O
backpropagated	O
through	O
the	O
network	O
to	O
obtain	O
the	O
gradient	O
w.r.t	O
.	O
	
the	O
parameters	O
of	O
the	O
network	O
.	O
	
The	O
time	B-Metric
and	I-Metric
space	I-Metric
complexity	I-Metric
of	O
the	O
gradient	B-Method
computation	I-Method
of	O
one	O
regularization	B-Method
layer	I-Method
are	O
max	O
(	O
O	O
(	O
KCHW	O
)	O
,	O
O	O
(	O
NCHW	O
)	O
)	O
and	O
O	O
(	O
NCHW	O
)	O
respectively	O
.	O
	
Note	O
that	O
we	O
can	O
cache	O
the	O
centered	O
data	O
	
Xn	O
−	O
µzn	O
in	O
the	O
forward	O
pass	O
to	O
speed	O
up	O
the	O
gradient	B-Task
computation	I-Task
.	O
	
The	O
overall	O
learning	B-Method
algorithm	I-Method
of	O
our	O
framework	O
is	O
summarized	O
in	O
Alg	O
.	O
	
1	O
.	O
	
In	O
the	O
forward	O
pass	O
,	O
we	O
first	O
compute	O
the	O
representation	O
of	O
the	O
n	O
-	O
th	O
sample	O
as	O
Xn	O
for	O
each	O
layer	O
.	O
	
We	O
then	O
infer	O
the	O
latent	O
cluster	O
label	O
zn	O
for	O
each	O
sample	O
based	O
on	O
the	O
distance	O
to	O
the	O
cluster	O
centers	O
µt−1k	O
from	O
the	O
last	O
time	O
step	O
t−	O
1	O
,	O
and	O
assign	O
the	O
sample	O
to	O
the	O
cluster	O
center	O
which	O
has	O
the	O
smallest	O
distance	O
.	O
	
Once	O
all	O
the	O
cluster	O
assignments	O
are	O
computed	O
,	O
we	O
estimate	O
the	O
cluster	O
centers	O
µ̂k	O
based	O
on	O
the	O
new	O
labels	O
of	O
the	O
current	O
batch	O
.	O
	
We	O
then	O
combine	O
the	O
estimate	O
based	O
on	O
the	O
current	O
batch	O
with	O
the	O
former	O
cluster	O
center	O
.	O
	
This	O
is	O
done	O
via	O
an	O
online	B-Method
update	I-Method
.	O
	
We	O
found	O
an	O
online	B-Method
update	I-Method
together	O
with	O
the	O
random	B-Method
restart	I-Method
strategy	I-Method
to	O
work	O
well	O
in	O
practice	O
,	O
as	O
the	O
learning	O
of	O
the	O
neural	B-Method
network	I-Method
proceeds	O
one	O
mini	O
-	O
batch	O
at	O
a	O
time	O
,	O
and	O
as	O
it	O
is	O
too	O
expensive	O
to	O
recompute	O
the	O
cluster	O
assignment	O
for	O
all	O
data	O
samples	O
in	O
every	O
iteration	O
.	O
	
Since	O
we	O
trust	O
our	O
current	O
cluster	O
center	O
estimate	O
more	O
than	O
older	O
ones	O
,	O
we	O
smooth	O
the	O
estimation	O
by	O
using	O
an	O
exponential	B-Method
moving	I-Method
average	I-Method
.	O
	
The	O
cluster	B-Method
center	I-Method
estimate	I-Method
at	O
iteration	O
t	O
is	O
obtained	O
via	O
µtk	O
=	O
	
αµ̂k	O
	
+	O
(	O
1−	O
α	O
)	O
µ	O
t−1	O
k	O
,	O
where	O
α	O
is	O
a	O
smoothing	O
weight	O
.	O
	
However	O
,	O
as	O
the	O
representation	O
learned	O
by	O
the	O
neural	B-Method
network	I-Method
may	O
go	O
through	O
drastic	O
changes	O
,	O
especially	O
in	O
the	O
beginning	O
of	O
training	O
,	O
some	O
of	O
the	O
cluster	O
centers	O
may	O
quickly	O
be	O
less	O
favored	O
and	O
the	O
number	O
of	O
incoming	O
samples	O
assigned	O
to	O
it	O
will	O
be	O
largely	O
reduced	O
.	O
	
To	O
overcome	O
this	O
issue	O
,	O
we	O
exploit	O
the	O
Kmeans	B-Method
++	I-Method
[	O
3	O
]	O
procedure	O
to	O
re	O
-	O
sample	O
the	O
cluster	O
center	O
from	O
the	O
current	O
mini	O
-	O
batch	O
.	O
	
Specifically	O
,	O
denoting	O
the	O
the	O
distance	O
between	O
sample	O
Xn	O
and	O
its	O
nearest	O
cluster	O
center	O
as	O
dn	O
,	O
the	O
probability	O
of	O
taking	O
Xn	O
as	O
the	O
new	O
cluster	O
center	O
is	O
d2n	O
/	O
	
∑	O
	
i	O
	
d	O
	
2	O
i	O
.	O
	
After	O
sampling	O
,	O
we	O
replace	O
the	O
old	O
cluster	O
center	O
with	O
the	O
new	O
one	O
and	O
continue	O
the	O
learning	B-Method
process	I-Method
.	O
	
In	O
practice	O
,	O
at	O
the	O
end	O
of	O
every	O
epoch	O
,	O
we	O
apply	O
the	O
kmeans	B-Method
++	I-Method
update	I-Method
to	O
cluster	O
centers	O
for	O
which	O
the	O
number	O
of	O
assigned	O
samples	O
is	O
small	O
.	O
	
See	O
Alg	O
.	O
	
1	O
for	O
an	O
outline	O
of	O
the	O
steps	O
.	O
	
The	O
overall	O
procedure	O
stabilizes	O
the	O
optimization	B-Task
and	O
also	O
increases	O
the	O
diversity	O
of	O
the	O
cluster	O
centers	O
.	O
	
In	O
the	O
backward	O
pass	O
,	O
we	O
fix	O
the	O
latest	O
estimation	O
of	O
the	O
cluster	O
centers	O
µtk	O
and	O
compute	O
the	O
gradient	O
of	O
loss	O
function	O
and	O
the	O
gradient	O
of	O
the	O
clustering	B-Method
objective	I-Method
based	O
on	O
Eq	O
.	O
	
(	O
4	O
)	O
.	O
	
Then	O
we	O
back	O
-	O
propagate	O
all	O
the	O
gradients	O
and	O
update	O
the	O
weights	O
.	O
	
4	O
Experiments	O
	
In	O
this	O
section	O
,	O
we	O
conduct	O
experiments	O
on	O
unsupervised	B-Task
,	I-Task
supervised	I-Task
and	I-Task
zero	I-Task
-	I-Task
shot	I-Task
learning	I-Task
on	O
several	O
datasets	O
.	O
	
Our	O
implementation	O
based	O
on	O
TensorFlow	B-Method
[	O
9	O
]	O
is	O
publicly	O
available.1	O
	
For	O
initializing	O
the	O
cluster	O
centers	O
before	O
training	O
,	O
we	O
randomly	O
choose	O
them	O
from	O
the	O
representations	O
obtained	O
with	O
the	O
initial	B-Method
network	I-Method
.	O
	
4.1	O
Autoencoder	B-Method
on	I-Method
MNIST	I-Method
	
We	O
first	O
test	O
our	O
method	O
on	O
the	O
unsupervised	B-Task
learning	I-Task
task	I-Task
of	O
training	O
an	O
autoencoder	B-Method
.	O
	
Our	O
architecture	O
is	O
identical	O
to	O
[	O
17	O
]	O
.	O
For	O
ease	O
of	O
training	O
we	O
did	O
not	O
tie	O
the	O
weights	O
between	O
the	O
encoder	B-Method
and	O
the	O
decoder	O
.	O
	
We	O
use	O
the	O
squared	B-Metric
`	I-Metric
2	I-Metric
reconstruction	I-Metric
error	I-Metric
as	O
the	O
loss	O
function	O
and	O
SGD	B-Method
with	O
momentum	B-Method
.	O
	
The	O
standard	O
training	O
-	O
test	O
-	O
split	O
is	O
used	O
.	O
	
We	O
compute	O
the	O
mean	B-Metric
reconstruction	I-Metric
error	I-Metric
over	O
all	O
test	O
images	O
and	O
repeat	O
the	O
experiments	O
4	O
times	O
with	O
different	O
random	O
initializations	O
.	O
	
We	O
compare	O
the	O
baseline	O
model	O
,	O
i.e.	O
,	O
a	O
plain	O
autoencoder	B-Method
,	O
with	O
one	O
that	O
employs	O
our	O
sample	O
-	O
clustering	B-Method
regularization	O
on	O
all	O
layers	O
except	O
the	O
top	O
fully	O
connected	O
layer	O
.	O
	
Sample	O
clustering	B-Method
was	O
chosen	O
since	O
this	O
autoencoder	B-Method
only	O
contains	O
fully	O
connected	O
layers	O
.	O
	
The	O
number	O
of	O
clusters	O
and	O
the	O
regularization	O
weight	O
λ	O
of	O
all	O
layers	O
are	O
set	O
to	O
100	O
and	O
1.0e−2	O
respectively	O
.	O
	
For	O
both	O
models	O
the	O
same	O
learning	B-Metric
rate	I-Metric
and	O
momentum	O
are	O
used	O
.	O
	
Our	O
exact	O
parameter	O
choices	O
are	O
detailed	O
in	O
the	O
Appendix	O
.	O
	
As	O
shown	O
in	O
Table	O
1	O
,	O
our	O
regularization	B-Method
facilitates	O
generalization	B-Task
as	O
it	O
suffers	O
less	O
from	O
overfitting	O
.	O
	
Specifically	O
,	O
applying	O
our	O
regularization	B-Method
results	O
in	O
lower	O
test	B-Metric
set	I-Metric
error	I-Metric
despite	O
slightly	O
higher	O
training	B-Metric
error	I-Metric
.	O
	
More	O
importantly	O
,	O
the	O
standard	O
deviation	O
of	O
the	O
error	B-Metric
is	O
one	O
order	O
of	O
magnitude	O
smaller	O
for	O
both	O
training	O
and	O
testing	O
when	O
applying	O
our	O
regularization	B-Method
.	O
	
This	O
indicates	O
that	O
our	O
sample	O
-	O
clustering	B-Method
regularization	O
stabilizes	O
the	O
model	O
.	O
	
1https:	O
//	O
github.com	O
/	O
lrjconan	O
	
/	O
deep_parsimonious	B-Method
4.2	I-Method
CIFAR10	I-Method
and	O
CIFAR100	O
	
In	O
this	O
section	O
,	O
we	O
explore	O
the	O
CIFAR10	O
and	O
CIFAR100	O
datasets	O
[	O
20	O
]	O
.	O
CIFAR10	O
consists	O
of	O
60	O
,	O
000	O
32×	O
32	O
images	O
assigned	O
to	O
10	O
categories	O
,	O
while	O
CIFAR100	O
differentiates	O
between	O
100	O
classes	O
.	O
	
We	O
use	O
the	O
standard	O
split	O
on	O
both	O
datasets	O
.	O
	
The	O
quick	B-Method
CIFAR10	I-Method
architecture	I-Method
of	O
Caffe	B-Method
[	O
19	O
]	O
is	O
used	O
for	O
benchmarking	O
both	O
datasets	O
.	O
	
It	O
consists	O
of	O
3	O
convolutional	B-Method
layers	I-Method
and	O
1	O
fully	B-Method
connected	I-Method
layer	I-Method
followed	O
by	O
a	O
softmax	B-Method
layer	I-Method
.	O
	
The	O
detailed	O
parameters	O
are	O
publicly	O
available	O
on	O
the	O
Caffe	O
[	O
19	O
]	O
website	O
.	O
	
We	O
report	O
mean	O
accuracy	B-Metric
averaged	O
over	O
4	O
trials	O
.	O
	
For	O
fully	O
connected	O
layers	O
we	O
use	O
the	O
sample	O
-	O
clustering	B-Method
objective	O
.	O
	
For	O
convolutional	B-Method
layers	I-Method
,	O
we	O
provide	O
the	O
results	O
of	O
all	O
three	O
clustering	B-Method
objectives	I-Method
,	O
which	O
we	O
refer	O
to	O
as	O
‘	O
sample	O
-	O
clustering	B-Method
,	O
’	O
‘	O
spatial	B-Method
-	I-Method
clustering	I-Method
,	O
’	O
and	O
‘	O
channel	B-Method
-	I-Method
co	I-Method
-	I-Method
clustering	I-Method
’	O
respectively	O
.	O
	
We	O
set	O
all	O
hyper	O
-	O
parameters	O
based	O
on	O
cross	B-Metric
-	I-Metric
validation	I-Metric
.	O
	
Specifically	O
,	O
the	O
number	O
of	O
cluster	O
centers	O
are	O
set	O
to	O
100	O
for	O
all	O
layers	O
for	O
both	O
CIFAR10	O
and	O
CIFAR100	O
.	O
	
λ	O
is	O
set	O
to	O
1.0e−3	O
and	O
1.0e−2	O
for	O
the	O
first	O
two	O
convolutional	O
and	O
the	O
remaining	O
layers	O
respectively	O
in	O
CIFAR10	O
;	O
for	O
CIFAR100	O
,	O
λ	O
is	O
set	O
to	O
10	O
and	O
1	O
for	O
the	O
first	O
convolutional	B-Method
layer	I-Method
and	O
the	O
remaining	O
layers	O
respectively	O
.	O
	
The	O
smoothness	O
parameter	O
α	O
is	O
set	O
to	O
0.9	O
and	O
0.95	O
for	O
CIFAR10	O
and	O
CIFAR100	O
respectively	O
.	O
	
Generalization	B-Task
:	O
	
In	O
Table	O
2	O
we	O
compare	O
our	O
framework	O
to	O
some	O
recent	O
regularizers	B-Method
,	O
like	O
DeCov	B-Method
[	O
6	O
]	O
,	O
Dropout	B-Method
[	O
26	O
]	O
and	O
the	O
baseline	O
results	O
obtained	O
using	O
Caffe	B-Method
.	O
	
We	O
again	O
observe	O
that	O
all	O
of	O
our	O
methods	O
achieve	O
better	O
generalization	B-Metric
performance	I-Metric
.	O
	
Visualization	B-Task
:	O
To	O
demonstrate	O
the	O
interpretability	O
of	O
our	O
learned	B-Method
network	I-Method
,	O
we	O
visualize	O
sampleclustering	O
and	O
spatial	O
-	O
clustering	B-Method
in	O
Fig	O
.	O
2	O
,	O
showing	O
the	O
top	O
-	O
10	O
ranked	O
images	O
and	O
parts	O
per	O
cluster	O
.	O
	
In	O
the	O
case	O
of	O
sample	O
-	O
clustering	B-Method
,	O
for	O
each	O
cluster	O
we	O
rank	O
all	O
its	O
assigned	O
images	O
based	O
on	O
the	O
distance	O
to	O
the	O
cluster	O
center	O
.	O
	
We	O
chose	O
to	O
show	O
2	O
clusters	O
from	O
the	O
4th	O
fully	B-Method
connected	I-Method
layer	I-Method
.	O
	
In	O
the	O
case	O
of	O
spatial	B-Method
-	I-Method
clustering	I-Method
,	O
we	O
rank	O
all	O
“	O
pixels	O
”	O
belonging	O
to	O
one	O
cluster	O
based	O
on	O
the	O
distance	O
to	O
the	O
cluster	O
center	O
.	O
	
Note	O
that	O
we	O
have	O
one	O
part	O
(	O
i.e.	O
,	O
one	O
receptive	O
field	O
region	O
in	O
the	O
input	O
image	O
)	O
for	O
each	O
“	O
pixel	O
.	O
	
”	O
	
We	O
chose	O
to	O
show	O
2	O
clusters	O
from	O
the	O
2nd	B-Method
convolutional	I-Method
layer	I-Method
.	O
	
The	O
receptive	O
field	O
of	O
the	O
2nd	B-Method
convolutional	I-Method
layer	I-Method
is	O
of	O
size	O
18	O
×	O
18	O
in	O
the	O
original	O
32	O
×	O
32	O
sized	O
image	O
.	O
	
We	O
observe	O
that	O
clusterings	B-Method
of	O
the	O
fully	B-Method
connected	I-Method
layer	I-Method
representations	I-Method
encode	O
high	O
-	O
level	O
semantic	O
meaning	O
.	O
	
In	O
contrast	O
,	O
clusterings	B-Method
of	O
the	O
convolutional	B-Method
layer	I-Method
representations	I-Method
encode	O
attributes	O
like	O
shape	O
.	O
	
Note	O
that	O
some	O
parts	O
are	O
uninformative	O
which	O
may	O
be	O
due	O
to	O
the	O
fact	O
that	O
images	O
in	O
CIFAR10	O
are	O
very	O
small	O
.	O
	
Additional	O
clusters	O
and	O
visualizations	O
on	O
CIFAR100	B-Task
are	O
shown	O
in	O
the	O
Appendix	O
.	O
	
Quantitative	B-Task
Evaluation	I-Task
of	O
Parsimonious	B-Method
Representation	I-Method
	
:	O
We	O
quantitatively	O
evaluate	O
our	O
learned	O
parsimonious	B-Method
representation	I-Method
on	O
CIFAR100	O
.	O
	
Since	O
only	O
the	O
image	O
category	O
is	O
provided	O
as	O
ground	O
truth	O
,	O
we	O
investigate	O
sample	B-Method
clustering	I-Method
using	O
the	O
4th	B-Method
fully	I-Method
connected	I-Method
layer	I-Method
where	O
representations	O
capture	O
semantic	O
meaning	O
.	O
	
In	O
particular	O
,	O
we	O
apply	O
K	B-Method
-	I-Method
means	I-Method
clustering	I-Method
to	O
the	O
learned	O
representation	O
extracted	O
from	O
the	O
model	O
with	O
and	O
without	O
sample	B-Method
clustering	I-Method
respectively	O
.	O
	
For	O
both	O
cases	O
,	O
we	O
set	O
the	O
number	O
of	O
clusters	O
to	O
be	O
100	O
and	O
control	O
the	O
random	O
seed	O
to	O
be	O
the	O
same	O
.	O
	
The	O
most	O
frequent	O
class	O
label	O
within	O
one	O
cluster	O
is	O
assigned	O
to	O
all	O
of	O
its	O
members	O
.	O
	
Then	O
we	O
compute	O
the	O
normalized	B-Metric
mutual	I-Metric
information	I-Metric
(	O
NMI	B-Method
)	O
[	O
25	O
]	O
to	O
measure	O
the	O
clustering	B-Method
accuracy	I-Metric
.	O
	
The	O
average	O
results	O
over	O
10	O
runs	O
are	O
shown	O
in	O
Table	O
3	O
.	O
	
Our	O
representations	O
achieve	O
significantly	O
better	O
clustering	B-Method
quality	O
compared	O
to	O
the	O
baseline	O
which	O
suggests	O
that	O
they	O
are	O
distributed	O
in	O
a	O
more	O
compact	O
way	O
in	O
the	O
feature	O
space	O
.	O
	
4.3	O
CUB	O
-	O
200	O
-	O
2011	O
	
Next	O
we	O
test	O
our	O
framework	O
on	O
the	O
Caltech	O
-	O
UCSD	O
birds	O
dataset	O
	
[	O
34	O
]	O
which	O
contains	O
11	O
,	O
788	O
images	O
of	O
200	O
different	O
categories	O
.	O
	
We	O
follow	O
the	O
dataset	O
split	O
provided	O
by	O
[	O
34	O
]	O
and	O
the	O
common	O
practice	O
of	O
cropping	O
the	O
image	O
using	O
the	O
ground	O
-	O
truth	O
bounding	O
box	O
annotation	O
of	O
the	O
birds	O
[	O
8	O
,	O
36	O
]	O
.	O
	
We	O
use	O
Alex	B-Method
-	I-Method
Net	I-Method
[	O
21	O
]	O
pretrained	O
on	O
ImageNet	O
as	O
the	O
base	O
model	O
and	O
adapt	O
the	O
last	O
layer	O
to	O
fit	O
classification	B-Task
of	O
200	O
categories	O
.	O
	
We	O
resize	O
the	O
image	O
to	O
227×	O
227	O
to	O
fit	O
the	O
input	O
size	O
.	O
	
We	O
add	O
clusterings	B-Method
to	O
all	O
layers	O
except	O
the	O
softmax	B-Method
-	I-Method
layer	I-Method
.	O
	
Based	O
on	O
cross	B-Metric
-	I-Metric
validation	I-Metric
,	O
the	O
number	O
of	O
clusters	O
are	O
set	O
to	O
200	O
for	O
all	O
layers	O
.	O
	
For	O
convolutional	B-Method
layers	I-Method
,	O
we	O
set	O
λ	O
to	O
1.0e−5	O
for	O
the	O
first	O
(	O
bottom	O
)	O
2	O
and	O
use	O
1.0e−4	O
for	O
the	O
remaining	O
ones	O
.	O
	
For	O
fully	O
connected	O
layers	O
,	O
we	O
set	O
λ	O
to	O
1.0e−3	O
and	O
α	O
is	O
equal	O
to	O
0.5	O
.	O
	
We	O
apply	O
Kmeans	B-Method
++	I-Method
to	O
replace	O
cluster	O
centers	O
with	O
less	O
than	O
10	O
assigned	O
samples	O
at	O
the	O
end	O
of	O
every	O
epoch	O
.	O
	
Generalization	B-Task
:	O
We	O
investigate	O
the	O
impact	O
of	O
our	O
parsimonious	B-Method
representation	I-Method
on	O
generalization	B-Task
performance	O
.	O
	
We	O
compare	O
with	O
the	O
DeCAF	B-Method
result	O
reported	O
in	O
[	O
8	O
]	O
,	O
which	O
used	O
the	O
same	O
network	O
to	O
extract	O
a	O
representation	O
and	O
applied	O
logistic	B-Method
regression	I-Method
on	O
top	O
for	O
fine	B-Task
-	I-Task
tuning	I-Task
.	O
	
We	O
also	O
fine	O
-	O
tune	O
Alex	B-Method
-	I-Method
Net	I-Method
which	O
uses	O
weight	B-Method
-	I-Method
decay	I-Method
and	O
Dropout	B-Method
,	O
and	O
report	O
the	O
best	O
result	O
we	O
achieved	O
in	O
Table	O
4	O
.	O
	
We	O
observe	O
that	O
for	O
the	O
Alex	B-Method
-	I-Method
Net	I-Method
architecture	I-Method
our	O
clustering	B-Method
improves	O
the	O
generalization	B-Task
compare	O
to	O
direct	B-Task
fine	I-Task
-	I-Task
tuning	I-Task
and	O
the	O
DeCAF	O
result	O
.	O
	
Note	O
that	O
Alex	B-Method
-	I-Method
Net	I-Method
pretrained	O
on	O
ImageNet	B-Method
easily	O
overfits	O
on	O
this	O
dataset	O
as	O
all	O
training	B-Metric
accuracies	I-Metric
reach	O
100	O
percent	O
.	O
	
Visualization	B-Task
:	O
To	O
visualize	O
the	O
sample	O
-	O
clustering	B-Method
and	O
spatial	O
-	O
clustering	B-Method
we	O
follow	O
the	O
setting	O
employed	O
when	O
evaluating	O
on	O
the	O
CIFAR	O
dataset	O
.	O
	
For	O
the	O
selected	O
cluster	O
center	O
we	O
show	O
the	O
10	O
closest	O
images	O
in	O
Fig	O
.	O
	
3	O
.	O
	
For	O
sample	B-Method
clustering	I-Method
,	O
2	O
clusters	O
from	O
the	O
3rd	B-Method
convolutional	I-Method
layer	I-Method
and	O
the	O
7th	O
fully	B-Method
connected	I-Method
layer	I-Method
are	O
chosen	O
for	O
visualization	B-Task
.	O
	
For	O
spatial	B-Method
clustering	I-Method
,	O
2	O
clusters	O
from	O
the	O
2nd	O
and	O
3rd	B-Method
convolutional	I-Method
layers	I-Method
are	O
chosen	O
for	O
visualization	B-Task
.	O
	
More	O
clusters	O
are	O
shown	O
in	O
the	O
Appendix	O
.	O
	
The	O
receptive	O
fields	O
of	O
pixels	O
from	O
the	O
2nd	O
and	O
3rd	B-Method
convolutional	I-Method
layers	I-Method
are	O
of	O
sizes	O
59	O
	
×	O
59	O
and	O
123	O
	
×	O
123	O
in	O
the	O
resized	O
227	O
×	O
227	O
image	O
.	O
	
We	O
observe	O
that	O
cluster	O
centers	O
of	O
sample	B-Method
clustering	I-Method
applied	O
to	O
layers	O
lower	O
in	O
the	O
network	O
capture	O
pose	O
and	O
shape	O
information	O
,	O
while	O
cluster	O
centers	O
from	O
top	O
layers	O
model	O
the	O
fine	O
-	O
grained	O
categories	O
of	O
birds	O
.	O
	
For	O
spatial	B-Method
clustering	I-Method
,	O
cluster	O
centers	O
from	O
different	O
layers	O
capture	O
parts	O
of	O
birds	O
in	O
different	O
scales	O
,	O
like	O
the	O
beak	O
,	O
chest	O
,	O
etc	O
.	O
	
4.4	O
Zero	B-Method
-	I-Method
Shot	I-Method
Learning	I-Method
	
We	O
also	O
investigate	O
a	O
zero	B-Task
-	I-Task
shot	I-Task
setting	I-Task
on	O
the	O
CUB	B-Material
dataset	I-Material
to	O
see	O
whether	O
our	O
parsimonious	B-Method
representation	I-Method
is	O
applicable	O
to	O
unseen	O
categories	O
.	O
	
We	O
follow	O
the	O
setting	O
in	O
[	O
1	O
,	O
2	O
]	O
and	O
use	O
the	O
same	O
split	O
where	O
100	O
,	O
50	O
and	O
50	O
classes	O
are	O
used	O
as	O
training	O
,	O
validation	O
and	O
testing	O
(	O
unseen	O
classes	O
)	O
.	O
	
We	O
use	O
a	O
pre	O
-	O
trained	O
Alex	B-Method
-	I-Method
Net	I-Method
as	O
the	O
baseline	O
model	O
and	O
extract	O
4096	B-Method
-	I-Method
dimension	I-Method
representations	I-Method
from	O
the	O
7th	O
fully	B-Method
connected	I-Method
(	I-Method
fc	I-Method
)	I-Method
layer	I-Method
.	O
	
We	O
compare	O
sample	O
-	O
clustering	B-Method
against	O
other	O
recent	O
methods	O
which	O
also	O
report	O
results	O
of	O
using	O
7th	O
fc	O
feature	O
of	O
Alex	B-Method
-	I-Method
Net	I-Method
.	O
	
Given	O
these	O
features	O
,	O
we	O
learn	O
the	O
output	O
embedding	O
W	O
via	O
the	O
same	O
unregularized	B-Method
structured	I-Method
SVM	I-Method
as	O
in	O
[	O
1	O
,	O
2	O
]	O
:	O
min	O
W	O
1	O
	
N	O
N∑	O
	
n=1	O
	
max	O
y∈Y	O
{	O
0	O
,	O
∆	O
(	O
yn	O
,	O
y	O
)	O
	
+	O
	
x	O
>	O
nW	O
[	O
φ	O
(	O
y	O
)	O
−	O
φ	O
(	O
yn	O
)	O
]	O
)	O
}	O
,	O
(	O
5	O
)	O
where	O
xn	O
and	O
yn	O
are	O
the	O
feature	O
and	O
class	O
label	O
of	O
the	O
n	O
-	O
th	O
sample	O
and	O
∆	O
is	O
the	O
0	O
-	O
1	O
loss	O
function	O
..	O
φ	O
is	O
the	O
class	O
-	O
attribute	O
matrix	O
provided	O
by	O
the	O
CUB	B-Material
dataset	I-Material
,	O
where	O
each	O
entry	O
is	O
a	O
real	O
-	O
valued	O
score	O
indicating	O
how	O
likely	O
a	O
human	O
thinks	O
one	O
attribute	O
is	O
present	O
in	O
a	O
given	O
class	O
.	O
	
We	O
tune	O
the	O
hyperparameters	O
on	O
the	O
validation	O
set	O
and	O
report	O
results	O
in	O
terms	O
of	O
top	O
-	O
1	O
accuracy	B-Metric
averaged	O
over	O
the	O
unseen	O
classes	O
.	O
	
As	O
shown	O
in	O
Table	O
5	O
our	O
approach	O
significantly	O
outperforms	O
other	O
approaches	O
.	O
	
5	O
Conclusions	O
	
We	O
have	O
proposed	O
a	O
novel	O
clustering	B-Method
based	O
regularization	O
which	O
encourages	O
parsimonious	O
representations	O
,	O
while	O
being	O
easy	O
to	O
optimize	O
.	O
	
We	O
have	O
demonstrated	O
the	O
effectiveness	O
of	O
our	O
approach	O
on	O
a	O
variety	O
of	O
tasks	O
including	O
unsupervised	B-Task
learning	I-Task
,	O
classification	B-Task
,	O
fine	B-Task
grained	I-Task
categorization	I-Task
,	O
and	O
zero	B-Task
-	I-Task
shot	I-Task
learning	I-Task
.	O
	
In	O
the	O
future	O
we	O
plan	O
to	O
apply	O
our	O
approach	O
to	O
even	O
larger	O
networks	O
,	O
e.g.	O
,	O
residual	O
nets	O
,	O
and	O
develop	O
a	O
probabilistic	B-Method
formulation	I-Method
which	O
provides	O
a	O
soft	B-Method
clustering	I-Method
.	O
	
Acknowledgments	O
	
This	O
work	O
was	O
partially	O
supported	O
by	O
ONR	O
-	O
N00014	O
-	O
14	O
-	O
1	O
-	O
0232	O
,	O
NVIDIA	O
and	O
the	O
Intelligence	O
Advanced	O
Research	O
Projects	O
Activity	O
(	O
IARPA	O
)	O
via	O
Department	O
of	O
Interior	O
/	O
Interior	O
Business	O
Center	O
(	O
DoI	O
/	O
IBC	O
)	O
contract	O
number	O
D16PC00003	O
.	O
	
The	O
U.S.	O
Government	O
is	O
authorized	O
to	O
reproduce	O
and	O
distribute	O
reprints	O
for	O
Governmental	O
purposes	O
notwithstanding	O
any	O
copyright	O
annotation	O
thereon	O
.	O
	
Disclaimer	O
:	O
	
The	O
views	O
and	O
conclusions	O
contained	O
herein	O
are	O
those	O
of	O
the	O
authors	O
and	O
should	O
not	O
be	O
interpreted	O
as	O
necessarily	O
representing	O
the	O
official	O
policies	O
or	O
endorsements	O
,	O
either	O
expressed	O
or	O
implied	O
,	O
of	O
IARPA	O
,	O
DoI	O
/	O
IBC	O
,	O
or	O
the	O
U.S.	O
Government	O
.	O
	
document	O
:	O
Mode	B-Method
Seeking	I-Method
Generative	I-Method
Adversarial	I-Method
Networks	I-Method
for	O
Diverse	B-Task
Image	I-Task
Synthesis	I-Task
	
Most	O
conditional	B-Task
generation	I-Task
tasks	I-Task
expect	O
diverse	O
outputs	O
given	O
a	O
single	O
conditional	O
context	O
.	O
	
However	O
,	O
conditional	B-Method
generative	I-Method
adversarial	I-Method
networks	I-Method
(	O
cGANs	B-Method
)	I-Method
often	O
focus	O
on	O
the	O
prior	O
conditional	O
information	O
and	O
ignore	O
the	O
input	O
noise	O
vectors	O
,	O
which	O
contribute	O
to	O
the	O
output	O
variations	O
.	O
	
Recent	O
attempts	O
to	O
resolve	O
the	O
mode	B-Task
collapse	I-Task
issue	I-Task
for	O
cGANs	B-Method
are	O
usually	O
task	O
-	O
specific	O
and	O
computationally	O
expensive	O
.	O
	
In	O
this	O
work	O
,	O
we	O
propose	O
a	O
simple	O
yet	O
effective	O
regularization	B-Method
term	I-Method
to	O
address	O
the	O
mode	B-Task
collapse	I-Task
issue	I-Task
for	O
cGANs	B-Task
.	O
	
The	O
proposed	O
method	O
explicitly	O
maximizes	O
the	O
ratio	O
of	O
the	O
distance	O
between	O
generated	O
images	O
with	O
respect	O
to	O
the	O
corresponding	O
latent	O
codes	O
,	O
thus	O
encouraging	O
the	O
generators	O
to	O
explore	O
more	O
minor	O
modes	O
during	O
training	O
.	O
	
This	O
mode	B-Method
seeking	I-Method
regularization	I-Method
term	I-Method
is	O
readily	O
applicable	O
to	O
various	O
conditional	B-Task
generation	I-Task
tasks	I-Task
without	O
imposing	O
training	O
overhead	O
or	O
modifying	O
the	O
original	O
network	O
structures	O
.	O
	
We	O
validate	O
the	O
proposed	O
algorithm	O
on	O
three	O
conditional	B-Task
image	I-Task
synthesis	I-Task
tasks	I-Task
including	O
categorical	B-Task
generation	I-Task
,	O
image	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
translation	I-Task
,	O
and	O
text	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
synthesis	I-Task
with	O
different	O
baseline	B-Method
models	I-Method
.	O
	
Both	O
qualitative	O
and	O
quantitative	O
results	O
demonstrate	O
the	O
effectiveness	O
of	O
the	O
proposed	O
regularization	B-Method
method	I-Method
for	O
improving	O
diversity	B-Metric
without	O
loss	B-Metric
of	I-Metric
quality	I-Metric
.	O
	
section	O
:	O
Introduction	O
	
Generative	B-Method
adversarial	I-Method
networks	I-Method
(	O
GANs	B-Method
)	O
have	O
been	O
shown	O
to	O
capture	O
complex	O
and	O
high	O
-	O
dimensional	O
image	O
data	O
with	O
numerous	O
applications	O
effectively	O
.	O
	
Built	O
upon	O
GANs	B-Method
,	O
conditional	B-Method
GANs	I-Method
(	O
cGANs	B-Method
)	O
take	O
external	O
information	O
as	O
additional	O
inputs	O
.	O
	
For	O
image	B-Task
synthesis	I-Task
,	O
cGANs	B-Method
can	O
be	O
applied	O
to	O
various	O
tasks	O
with	O
different	O
conditional	O
contexts	O
.	O
	
With	O
class	O
labels	O
,	O
cGANs	B-Method
can	O
be	O
applied	O
to	O
categorical	B-Task
image	I-Task
generation	I-Task
.	O
	
With	O
text	O
sentences	O
,	O
cGANs	B-Method
can	O
be	O
applied	O
to	O
text	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
synthesis	I-Task
.	O
	
With	O
images	O
,	O
cGANs	B-Method
have	O
been	O
used	O
in	O
tasks	O
including	O
image	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
translation	I-Task
,	O
semantic	B-Task
manipulation	I-Task
and	O
style	B-Task
transfer	I-Task
.	O
	
For	O
most	O
conditional	B-Task
generation	I-Task
tasks	I-Task
,	O
the	O
mappings	O
are	O
in	O
nature	O
multimodal	O
,	O
i.e.	O
,	O
a	O
single	O
input	O
context	O
corresponds	O
to	O
multiple	O
plausible	O
outputs	O
.	O
	
A	O
straightforward	O
approach	O
to	O
handle	O
multimodality	O
is	O
to	O
take	O
random	O
noise	O
vectors	O
along	O
with	O
the	O
conditional	O
contexts	O
as	O
inputs	O
,	O
where	O
the	O
contexts	O
determine	O
the	O
main	O
content	O
and	O
noise	O
vectors	O
are	O
responsible	O
for	O
variations	O
.	O
	
For	O
instance	O
,	O
in	O
the	O
dog	B-Task
-	I-Task
to	I-Task
-	I-Task
cat	I-Task
image	I-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
translation	I-Task
task	I-Task
,	O
the	O
input	O
dog	O
images	O
decide	O
contents	O
like	O
orientations	O
of	O
heads	O
and	O
positions	O
of	O
facial	O
landmarks	O
,	O
while	O
the	O
noise	O
vectors	O
help	O
the	O
generation	O
of	O
different	O
species	O
.	O
	
However	O
,	O
cGANs	B-Method
usually	O
suffer	O
from	O
the	O
mode	B-Task
collapse	I-Task
problem	I-Task
,	O
where	O
generators	B-Method
only	O
produce	O
samples	O
from	O
a	O
single	O
or	O
few	O
modes	O
of	O
the	O
distribution	O
and	O
ignore	O
other	O
modes	O
.	O
	
The	O
noise	O
vectors	O
are	O
ignored	O
or	O
of	O
minor	O
impacts	O
,	O
since	O
cGANs	B-Method
pay	O
more	O
attention	O
to	O
learn	O
from	O
the	O
high	O
-	O
dimensional	O
and	O
structured	O
conditional	O
contexts	O
.	O
	
There	O
are	O
two	O
main	O
approaches	O
to	O
address	O
the	O
mode	B-Task
collapse	I-Task
problem	I-Task
in	O
GANs	B-Task
.	O
	
A	O
number	O
of	O
methods	O
focus	O
on	O
discriminators	B-Method
by	O
introducing	O
different	O
divergence	B-Metric
metrics	I-Metric
and	O
optimization	B-Method
process	I-Method
.	O
	
The	O
other	O
methods	O
use	O
auxiliary	B-Method
networks	I-Method
such	O
as	O
multiple	B-Method
generators	I-Method
and	O
additional	O
encoders	B-Method
.	O
	
However	O
,	O
mode	B-Task
collapse	I-Task
is	O
relatively	O
less	O
studied	O
in	O
cGANs	B-Method
.	O
	
Some	O
recent	O
efforts	O
have	O
been	O
made	O
in	O
the	O
image	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
translation	I-Task
task	I-Task
to	O
improve	O
diversity	O
.	O
	
Similar	O
to	O
the	O
second	O
category	O
with	O
the	O
unconditional	B-Task
setting	I-Task
,	O
these	O
approaches	O
introduce	O
additional	O
encoders	B-Method
and	O
loss	O
functions	O
to	O
encourage	O
the	O
one	O
-	O
to	O
-	O
one	O
relationship	O
between	O
the	O
output	O
and	O
the	O
latent	O
code	O
.	O
	
These	O
methods	O
either	O
entail	O
heavy	O
computational	B-Metric
overheads	I-Metric
on	O
training	B-Task
or	O
require	O
auxiliary	B-Method
networks	I-Method
that	O
are	O
often	O
task	O
-	O
specific	O
that	O
can	O
not	O
be	O
easily	O
extended	O
to	O
other	O
frameworks	O
.	O
	
In	O
this	O
work	O
,	O
we	O
propose	O
a	O
mode	B-Method
seeking	I-Method
regularization	I-Method
method	I-Method
that	O
can	O
be	O
applied	O
to	O
cGANs	B-Method
for	O
various	O
tasks	O
to	O
alleviate	O
the	O
mode	B-Task
collapse	I-Task
problem	I-Task
.	O
	
Given	O
two	O
latent	O
vectors	O
and	O
the	O
corresponding	O
output	O
images	O
,	O
we	O
propose	O
to	O
maximize	O
the	O
ratio	O
of	O
the	O
distance	O
between	O
images	O
with	O
respect	O
to	O
the	O
distance	O
between	O
latent	O
vectors	O
.	O
	
In	O
other	O
words	O
,	O
this	O
regularization	B-Method
term	I-Method
encourages	O
generators	O
to	O
generate	O
dissimilar	O
images	O
during	O
training	O
.	O
	
As	O
a	O
result	O
,	O
generators	O
can	O
explore	O
the	O
target	O
distribution	O
,	O
and	O
enhance	O
the	O
chances	O
of	O
generating	O
samples	O
from	O
different	O
modes	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
we	O
can	O
train	O
the	O
discriminators	B-Method
with	O
dissimilar	O
generated	O
samples	O
to	O
provide	O
gradients	O
from	O
minor	O
modes	O
that	O
are	O
likely	O
to	O
be	O
ignored	O
otherwise	O
.	O
	
This	O
mode	B-Method
seeking	I-Method
regularization	I-Method
method	I-Method
incurs	O
marginal	O
computational	B-Metric
overheads	I-Metric
and	O
can	O
be	O
easily	O
embedded	O
in	O
different	O
cGAN	B-Method
frameworks	I-Method
to	O
improve	O
the	O
diversity	O
of	O
synthesized	O
images	O
.	O
	
We	O
validate	O
the	O
proposed	O
regularization	B-Method
algorithm	I-Method
through	O
an	O
extensive	O
evaluation	O
of	O
three	O
conditional	B-Task
image	I-Task
synthesis	I-Task
tasks	I-Task
with	O
different	O
baseline	B-Method
models	I-Method
.	O
	
First	O
,	O
for	O
categorical	B-Task
image	I-Task
generation	I-Task
,	O
we	O
apply	O
the	O
proposed	O
method	O
on	O
DCGAN	B-Method
using	O
the	O
CIFAR	B-Material
-	I-Material
10	I-Material
dataset	I-Material
.	O
	
Second	O
,	O
for	O
image	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
translation	I-Task
,	O
we	O
embed	O
the	O
proposed	O
regularization	B-Method
scheme	I-Method
in	O
Pix2Pix	B-Method
and	I-Method
DRIT	I-Method
using	O
the	O
facades	O
,	O
maps	O
,	O
Yosemite	O
,	O
and	O
cat	O
dog	O
datasets	O
.	O
	
Third	O
,	O
for	O
text	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
synthesis	I-Task
,	O
we	O
incorporate	O
StackGAN	B-Method
++	I-Method
with	O
the	O
proposed	O
regularization	B-Method
term	I-Method
using	O
the	O
CUB	O
-	O
200	O
-	O
2011	O
dataset	O
.	O
	
We	O
evaluate	O
the	O
diversity	O
of	O
synthesized	O
images	O
using	O
perceptual	B-Metric
distance	I-Metric
metrics	I-Metric
.	O
	
However	O
,	O
the	O
diversity	B-Metric
metric	I-Metric
alone	O
can	O
not	O
guarantee	O
the	O
similarity	O
between	O
the	O
distribution	O
of	O
generated	O
images	O
and	O
the	O
distribution	O
of	O
real	O
data	O
.	O
	
Therefore	O
,	O
we	O
adopt	O
two	O
recently	O
proposed	O
bin	B-Method
-	I-Method
based	I-Method
metrics	I-Method
,	O
the	O
Number	O
of	O
Statistically	O
-	O
Different	O
Bins	O
(	O
NDB	B-Method
)	I-Method
metric	I-Method
which	O
determines	O
the	O
relative	O
proportions	O
of	O
samples	O
fallen	O
into	O
clusters	O
predetermined	O
by	O
real	O
data	O
,	O
and	O
the	O
Jensen	B-Metric
-	I-Metric
Shannon	I-Metric
Divergence	I-Metric
(	O
JSD	B-Metric
)	O
distance	O
which	O
measures	O
the	O
similarity	O
between	O
bin	O
distributions	O
.	O
	
Furthermore	O
,	O
to	O
verify	O
that	O
we	O
do	O
not	O
achieve	O
diversity	O
at	O
the	O
expense	O
of	O
realism	B-Metric
,	O
we	O
evaluate	O
our	O
method	O
with	O
the	O
Fréchet	B-Metric
Inception	I-Metric
Distance	I-Metric
(	O
FID	B-Metric
)	O
as	O
the	O
metric	B-Metric
for	O
quality	B-Metric
.	O
	
Experimental	O
results	O
demonstrate	O
that	O
the	O
proposed	O
regularization	B-Method
method	I-Method
can	O
facilitate	O
existing	O
models	O
from	O
various	O
applications	O
achieving	O
better	O
diversity	O
without	O
loss	O
of	O
image	B-Metric
quality	I-Metric
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
the	O
effectiveness	O
of	O
the	O
proposed	O
regularization	B-Method
method	I-Method
for	O
existing	O
models	O
.	O
	
The	O
main	O
contributions	O
of	O
this	O
work	O
are	O
:	O
We	O
propose	O
a	O
simple	O
yet	O
effective	O
mode	B-Method
seeking	I-Method
regularization	I-Method
method	I-Method
to	O
address	O
the	O
mode	B-Task
collapse	I-Task
problem	I-Task
in	O
cGANs	B-Task
.	O
	
This	O
regularization	B-Method
scheme	I-Method
can	O
be	O
readily	O
extended	O
into	O
existing	O
frameworks	O
with	O
marginal	O
training	O
overheads	O
and	O
modifications	O
.	O
	
We	O
demonstrate	O
the	O
generalizability	O
of	O
the	O
proposed	O
regularization	B-Method
method	I-Method
on	O
three	O
different	O
conditional	B-Task
generation	I-Task
tasks	I-Task
:	O
categorical	B-Task
generation	I-Task
,	O
image	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
translation	I-Task
,	O
and	O
text	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
synthesis	I-Task
.	O
	
Extensive	O
experiments	O
show	O
that	O
the	O
proposed	O
method	O
can	O
facilitate	O
existing	O
models	O
from	O
different	O
tasks	O
achieving	O
better	O
diversity	B-Metric
without	O
sacrificing	O
visual	B-Metric
quality	I-Metric
of	O
the	O
generated	O
images	O
.	O
	
Our	O
code	O
and	O
pre	O
-	O
trained	O
models	O
are	O
available	O
at	O
.	O
	
section	O
:	O
Related	O
Work	O
	
paragraph	O
:	O
Conditional	B-Method
generative	I-Method
adversarial	I-Method
networks	I-Method
.	O
	
Generative	B-Method
adversarial	I-Method
networks	I-Method
have	O
been	O
widely	O
used	O
for	O
image	B-Task
synthesis	I-Task
.	O
	
With	O
adversarial	B-Method
training	I-Method
,	O
generators	B-Method
are	O
encouraged	O
to	O
capture	O
the	O
distribution	O
of	O
real	O
images	O
.	O
	
On	O
the	O
basis	O
of	O
GANs	B-Method
,	O
conditional	B-Method
GANs	I-Method
synthesize	O
images	O
based	O
on	O
various	O
contexts	O
.	O
	
For	O
instances	O
,	O
cGANs	B-Method
can	O
generate	O
high	O
-	O
resolution	O
images	O
conditioned	O
on	O
low	O
-	O
resolution	O
images	O
,	O
translate	O
images	O
between	O
different	O
visual	O
domains	O
,	O
generate	O
images	O
with	O
desired	O
style	O
,	O
and	O
synthesize	O
images	O
according	O
to	O
sentences	O
.	O
	
Although	O
cGANs	B-Method
have	O
achieved	O
success	O
in	O
various	O
applications	O
,	O
existing	O
approaches	O
suffer	O
from	O
the	O
mode	B-Task
collapse	I-Task
problem	I-Task
.	O
	
Since	O
the	O
conditional	O
contexts	O
provide	O
strong	O
structural	O
prior	O
information	O
for	O
the	O
output	O
images	O
and	O
have	O
higher	O
dimensions	O
than	O
the	O
input	O
noise	O
vectors	O
,	O
generators	O
tend	O
to	O
ignore	O
the	O
input	O
noise	O
vectors	O
,	O
which	O
are	O
responsible	O
for	O
the	O
variation	O
of	O
generated	O
images	O
.	O
	
As	O
a	O
result	O
,	O
the	O
generators	O
are	O
prone	O
to	O
produce	O
images	O
with	O
similar	O
appearances	O
.	O
	
In	O
this	O
work	O
,	O
we	O
aim	O
to	O
address	O
the	O
mode	B-Task
collapse	I-Task
problem	I-Task
for	O
cGANs	B-Task
.	O
	
paragraph	O
:	O
Reducing	B-Task
mode	I-Task
collapse	I-Task
.	O
	
Some	O
methods	O
focus	O
on	O
the	O
discriminator	B-Method
with	O
different	O
optimization	B-Method
process	I-Method
and	O
divergence	B-Metric
metrics	I-Metric
to	O
stabilize	O
the	O
training	B-Task
process	I-Task
.	O
	
The	O
minibatch	B-Method
discrimination	I-Method
scheme	I-Method
allows	O
the	O
discriminator	O
to	O
discriminate	O
between	O
whole	O
mini	O
-	O
batches	O
of	O
samples	O
instead	O
of	O
between	O
individual	O
samples	O
.	O
	
In	O
,	O
Durugkar	O
et	O
al	O
.	O
use	O
multiple	O
discriminators	B-Method
to	O
address	O
this	O
issue	O
.	O
	
The	O
other	O
methods	O
use	O
auxiliary	B-Method
networks	I-Method
to	O
alleviate	O
the	O
mode	B-Task
collapse	I-Task
issue	I-Task
.	O
	
ModeGAN	B-Method
and	O
VEEGAN	O
enforce	O
the	O
bijection	O
mapping	O
between	O
the	O
input	O
noise	O
vectors	O
and	O
generated	O
images	O
with	O
additional	O
encoder	B-Method
networks	I-Method
.	O
	
Multiple	B-Method
generators	I-Method
and	O
weight	B-Method
-	I-Method
sharing	I-Method
generators	I-Method
are	O
developed	O
to	O
capture	O
more	O
modes	O
of	O
the	O
distribution	O
.	O
	
However	O
,	O
these	O
approaches	O
either	O
entail	O
heavy	O
computational	O
overheads	O
or	O
require	O
modifications	O
of	O
the	O
network	O
structure	O
,	O
and	O
may	O
not	O
be	O
easily	O
applicable	O
to	O
cGANs	B-Method
.	O
	
In	O
the	O
field	O
of	O
cGANs	B-Task
,	O
some	O
efforts	O
have	O
been	O
recently	O
made	O
to	O
address	O
the	O
mode	B-Task
collapse	I-Task
issue	I-Task
on	O
the	O
image	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
translation	I-Task
task	I-Task
.	O
	
Similar	O
to	O
ModeGAN	B-Method
and	O
VEEGAN	B-Method
,	O
additional	O
encoders	B-Method
are	O
introduced	O
to	O
provide	O
a	O
bijection	O
constraint	O
between	O
the	O
generated	O
images	O
and	O
input	O
noise	O
vectors	O
.	O
	
However	O
,	O
these	O
approaches	O
require	O
other	O
task	O
-	O
specific	O
networks	O
and	O
objective	O
functions	O
.	O
	
The	O
additional	O
components	O
make	O
the	O
methods	O
less	O
generalizable	O
and	O
incur	O
extra	O
computational	B-Metric
loads	I-Metric
on	O
training	B-Task
.	O
	
In	O
contrast	O
,	O
we	O
propose	O
a	O
simple	O
regularization	B-Method
term	I-Method
that	O
imposes	O
no	O
training	O
overheads	O
and	O
requires	O
no	O
modifications	O
of	O
the	O
network	O
structure	O
.	O
	
Therefore	O
,	O
the	O
proposed	O
method	O
can	O
be	O
readily	O
applied	O
to	O
various	O
conditional	B-Task
generation	I-Task
tasks	I-Task
.	O
	
section	O
:	O
Diverse	B-Task
Conditional	I-Task
Image	I-Task
Synthesis	I-Task
	
subsection	O
:	O
Preliminaries	O
	
The	O
training	O
process	O
of	O
GANs	B-Method
can	O
be	O
formulated	O
as	O
a	O
mini	B-Task
-	I-Task
max	I-Task
problem	I-Task
:	O
a	O
discriminator	B-Method
learns	O
to	O
be	O
a	O
classifier	B-Method
by	O
assigning	O
higher	O
discriminative	O
values	O
to	O
the	O
real	O
data	O
samples	O
and	O
lower	O
ones	O
to	O
the	O
generated	O
ones	O
.	O
	
Meanwhile	O
,	O
a	O
generator	B-Method
aims	O
to	O
fool	O
by	O
synthesizing	O
realistic	O
examples	O
.	O
	
Through	O
adversarial	B-Method
training	I-Method
,	O
the	O
gradients	O
from	O
will	O
guide	O
toward	O
generating	O
samples	O
with	O
the	O
distribution	O
similar	O
to	O
the	O
real	O
data	O
one	O
.	O
	
The	O
mode	B-Task
collapse	I-Task
problem	I-Task
with	O
GANs	B-Method
is	O
well	O
known	O
in	O
the	O
literature	O
.	O
	
Several	O
methods	O
attribute	O
the	O
missing	O
mode	O
to	O
the	O
lack	O
of	O
penalty	O
when	O
this	O
issue	O
occurs	O
.	O
	
Since	O
all	O
modes	O
usually	O
have	O
similar	O
discriminative	O
values	O
,	O
larger	O
modes	O
are	O
likely	O
to	O
be	O
favored	O
through	O
the	O
training	B-Method
process	I-Method
based	O
on	O
gradient	B-Method
descent	I-Method
.	O
	
On	O
the	O
other	O
hand	O
,	O
it	O
is	O
difficult	O
to	O
generate	O
samples	O
from	O
minor	O
modes	O
.	O
	
The	O
mode	B-Task
missing	I-Task
problem	I-Task
becomes	O
worse	O
in	O
cGANs	B-Method
.	O
	
Generally	O
,	O
conditional	O
contexts	O
are	O
high	O
-	O
dimensional	O
and	O
structured	O
(	O
e.g.	O
,	O
images	O
and	O
sentences	O
)	O
as	O
opposed	O
to	O
the	O
noise	O
vectors	O
.	O
	
As	O
such	O
,	O
the	O
generators	O
are	O
likely	O
to	O
focus	O
on	O
the	O
contexts	O
and	O
ignore	O
the	O
noise	O
vectors	O
,	O
which	O
account	O
for	O
diversity	O
.	O
	
subsection	O
:	O
Mode	B-Method
Seeking	I-Method
GANs	I-Method
	
In	O
this	O
work	O
,	O
we	O
propose	O
to	O
alleviate	O
the	O
missing	B-Task
mode	I-Task
problem	I-Task
from	O
the	O
generator	B-Method
perspective	I-Method
.	O
	
Figure	O
[	O
reference	O
]	O
illustrates	O
the	O
main	O
ideas	O
of	O
our	O
approach	O
.	O
	
Let	O
a	O
latent	O
vector	O
from	O
the	O
latent	O
code	O
space	O
be	O
mapped	O
to	O
the	O
image	O
space	O
.	O
	
When	O
mode	B-Task
collapse	I-Task
occurs	O
,	O
the	O
mapped	O
images	O
are	O
collapsed	O
into	O
a	O
few	O
modes	O
.	O
	
Furthermore	O
,	O
when	O
two	O
latent	O
codes	O
and	O
are	O
closer	O
,	O
the	O
mapped	O
images	O
and	O
are	O
more	O
likely	O
to	O
be	O
collapsed	O
into	O
the	O
same	O
mode	O
.	O
	
To	O
address	O
this	O
issue	O
,	O
we	O
propose	O
a	O
mode	B-Method
seeking	I-Method
regularization	I-Method
term	I-Method
to	O
directly	O
maximize	O
the	O
ratio	O
of	O
the	O
distance	O
between	O
and	O
with	O
respect	O
to	O
the	O
distance	O
between	O
and	O
,	O
where	O
denotes	O
the	O
distance	B-Metric
metric	I-Metric
.	O
	
The	O
regularization	B-Method
term	I-Method
offers	O
a	O
virtuous	O
circle	O
for	O
training	O
cGANs	B-Method
.	O
	
It	O
encourages	O
the	O
generator	O
to	O
explore	O
the	O
image	O
space	O
and	O
enhances	O
the	O
chances	O
for	O
generating	O
samples	O
of	O
minor	O
modes	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
the	O
discriminator	B-Method
is	O
forced	O
to	O
pay	O
attention	O
to	O
generated	O
samples	O
from	O
minor	O
modes	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
a	O
mode	O
collapse	O
situation	O
where	O
two	O
close	O
samples	O
,	O
and	O
,	O
are	O
mapped	O
onto	O
the	O
same	O
mode	O
.	O
	
However	O
,	O
with	O
the	O
proposed	O
regularization	B-Method
term	I-Method
,	O
is	O
mapped	O
to	O
,	O
which	O
belongs	O
to	O
an	O
unexplored	O
mode	O
.	O
	
With	O
the	O
adversarial	B-Method
mechanism	I-Method
,	O
the	O
generator	B-Method
will	O
thus	O
have	O
better	O
chances	O
to	O
generate	O
samples	O
of	O
in	O
the	O
following	O
training	O
steps	O
.	O
	
As	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
the	O
proposed	O
regularization	B-Method
term	I-Method
can	O
be	O
easily	O
integrated	O
with	O
existing	O
cGANs	B-Method
by	O
appending	O
it	O
to	O
the	O
original	O
objective	O
function	O
.	O
	
where	O
denotes	O
the	O
original	O
objective	O
function	O
and	O
the	O
weights	O
to	O
control	O
the	O
importance	O
of	O
the	O
regularization	O
.	O
	
Here	O
,	O
can	O
be	O
as	O
a	O
simple	O
loss	B-Method
function	I-Method
.	O
	
For	O
example	O
,	O
in	O
categorical	B-Task
generation	I-Task
task	O
,	O
where	O
denote	O
class	O
labels	O
,	O
real	O
images	O
,	O
and	O
noise	O
vectors	O
,	O
respectively	O
.	O
	
In	O
image	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
translation	I-Task
task	I-Task
,	O
where	O
denotes	O
input	O
images	O
and	O
is	O
the	O
typical	O
GAN	B-Metric
loss	I-Metric
.	O
	
can	O
be	O
arbitrary	O
complex	O
objective	O
function	O
from	O
any	O
task	O
,	O
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
	
(	O
b	O
)	O
.	O
	
We	O
name	O
the	O
proposed	O
method	O
as	O
Mode	B-Method
Seeking	I-Method
GANs	I-Method
(	O
MSGANs	B-Method
)	O
.	O
	
[	O
Proposed	O
regularization	B-Method
]	O
	
[	O
Applying	O
proposed	O
regularization	B-Method
on	O
StackGAN	B-Method
++	I-Method
]	O
	
section	O
:	O
Experiments	O
	
We	O
evaluate	O
the	O
proposed	O
regularization	B-Method
method	I-Method
through	O
extensive	O
quantitative	B-Metric
and	I-Metric
qualitative	I-Metric
evaluation	I-Metric
.	O
	
We	O
apply	O
MSGANs	B-Method
to	O
the	O
baseline	O
models	O
from	O
three	O
representative	O
conditional	B-Task
image	I-Task
synthesis	I-Task
tasks	I-Task
:	O
categorical	B-Task
generation	I-Task
,	O
image	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
translation	I-Task
,	O
and	O
text	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
synthesis	I-Task
.	O
	
Note	O
that	O
we	O
augment	O
the	O
original	O
objective	O
functions	O
with	O
the	O
proposed	O
regularization	O
term	O
while	O
maintaining	O
original	O
network	O
architectures	O
and	O
hyper	O
-	O
parameters	O
.	O
	
We	O
employ	O
norm	B-Method
distance	I-Method
as	O
our	O
distance	B-Metric
metrics	I-Metric
for	O
both	O
and	O
and	O
set	O
the	O
hyper	O
-	O
parameter	O
in	O
all	O
experiments	O
.	O
	
More	O
implementation	O
and	O
evaluation	O
details	O
,	O
please	O
refer	O
to	O
the	O
appendixes	O
.	O
	
subsection	O
:	O
Evaluation	B-Metric
Metrics	I-Metric
	
We	O
conduct	O
evaluations	O
using	O
the	O
following	O
metrics	O
.	O
	
FID	B-Metric
.	O
	
To	O
evaluate	O
the	O
quality	O
of	O
the	O
generated	O
images	O
,	O
we	O
use	O
FID	B-Metric
to	O
measure	O
the	O
distance	B-Metric
between	O
the	O
generated	O
distribution	O
and	O
the	O
real	O
one	O
through	O
features	O
extracted	O
by	O
Inception	B-Method
Network	I-Method
.	O
	
Lower	O
FID	B-Metric
values	O
indicate	O
better	O
quality	O
of	O
the	O
generated	O
images	O
.	O
	
LPIPS	B-Method
.	O
	
To	O
evaluate	O
diversity	O
,	O
we	O
employ	O
LPIPS	B-Method
following	I-Method
.	O
	
LIPIS	B-Method
measures	O
the	O
average	O
feature	O
distances	O
between	O
generated	O
samples	O
.	O
	
Higher	O
LPIPS	B-Metric
score	I-Metric
indicates	O
better	O
diversity	O
among	O
the	O
generated	O
images	O
.	O
	
NDB	B-Method
and	O
JSD	B-Metric
.	O
	
To	O
measure	O
the	O
similarity	O
between	O
the	O
distribution	O
between	O
real	O
images	O
and	O
generated	O
one	O
,	O
we	O
adopt	O
two	O
bin	B-Method
-	I-Method
based	I-Method
metrics	I-Method
,	O
NDB	B-Method
and	O
JSD	B-Metric
,	O
proposed	O
in	O
.	O
	
These	O
metrics	O
evaluate	O
the	O
extent	O
of	O
mode	B-Method
missing	I-Method
of	I-Method
generative	I-Method
models	I-Method
.	O
	
Following	O
,	O
the	O
training	O
samples	O
are	O
first	O
clustered	O
using	O
K	B-Method
-	I-Method
means	I-Method
into	O
different	O
bins	O
which	O
can	O
be	O
viewed	O
as	O
modes	O
of	O
the	O
real	O
data	O
distribution	O
.	O
	
Then	O
each	O
generated	O
sample	O
is	O
assigned	O
to	O
the	O
bin	O
of	O
its	O
nearest	O
neighbor	O
.	O
	
We	O
calculate	O
the	O
bin	O
-	O
proportions	O
of	O
the	O
training	O
samples	O
and	O
the	O
synthesized	O
samples	O
to	O
evaluate	O
the	O
difference	O
between	O
the	O
generated	O
distribution	O
and	O
the	O
real	O
data	O
distribution	O
.	O
	
NDB	B-Metric
score	I-Metric
and	O
JSD	B-Metric
of	O
the	O
bin	O
-	O
proportion	O
are	O
then	O
computed	O
to	O
measure	O
the	O
mode	O
collapse	O
.	O
	
Lower	O
NDB	B-Metric
score	I-Metric
and	O
JSD	B-Metric
mean	O
the	O
generated	O
data	B-Method
distribution	I-Method
approaches	O
the	O
real	O
data	O
distribution	O
better	O
by	O
fitting	O
more	O
modes	O
.	O
	
Please	O
refer	O
to	O
for	O
more	O
details	O
.	O
	
subsection	O
:	O
Conditioned	O
on	O
Class	O
Label	O
	
We	O
first	O
validate	O
the	O
proposed	O
method	O
on	O
categorical	B-Task
generation	I-Task
.	O
	
In	O
categorical	B-Task
generation	I-Task
,	O
networks	O
take	O
class	O
labels	O
as	O
conditional	O
contexts	O
to	O
synthesize	O
images	O
of	O
different	O
categories	O
.	O
	
We	O
apply	O
the	O
regularization	B-Method
term	I-Method
to	O
the	O
baseline	B-Method
framework	I-Method
DCGAN	I-Method
.	O
	
We	O
conduct	O
experiments	O
on	O
the	O
CIFAR	B-Material
-	I-Material
10	I-Material
dataset	I-Material
which	O
includes	O
images	O
of	O
ten	O
categories	O
.	O
	
Since	O
images	O
in	O
the	O
CIFAR	B-Material
-	I-Material
10	I-Material
dataset	I-Material
are	O
of	O
size	O
and	O
upsampling	O
degrades	O
the	O
image	B-Metric
quality	I-Metric
,	O
we	O
do	O
not	O
compute	O
LPIPS	B-Method
in	O
this	O
task	O
.	O
	
Table	O
[	O
reference	O
]	O
and	O
Table	O
[	O
reference	O
]	O
present	O
the	O
results	O
of	O
NDB	O
,	O
JS	B-Method
,	O
and	O
FID	B-Metric
.	O
	
MSGAN	B-Method
mitigates	O
the	O
mode	B-Task
collapse	I-Task
issue	I-Task
in	O
most	O
classes	O
while	O
maintaining	O
image	B-Metric
quality	I-Metric
.	O
	
subsection	O
:	O
Conditioned	O
on	O
Image	O
	
Image	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
translation	I-Task
aims	O
to	O
learn	O
the	O
mapping	B-Task
between	I-Task
two	I-Task
visual	I-Task
domains	I-Task
.	O
	
Conditioned	O
on	O
images	O
from	O
the	O
source	O
domain	O
,	O
models	O
attempt	O
to	O
synthesize	O
corresponding	O
images	O
in	O
the	O
target	O
domain	O
.	O
	
Despite	O
the	O
multimodal	O
nature	O
of	O
the	O
image	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
translation	I-Task
task	I-Task
,	O
early	O
work	O
abandons	O
noise	O
vectors	O
and	O
performs	O
one	B-Task
-	I-Task
to	I-Task
-	I-Task
one	I-Task
mapping	I-Task
since	O
the	O
latent	O
codes	O
are	O
easily	O
ignored	O
during	O
training	O
as	O
shown	O
in	O
.	O
	
To	O
achieve	O
multimodality	O
,	O
several	O
recent	O
attempts	O
introduce	O
additional	O
encoder	B-Method
networks	I-Method
and	O
objective	B-Method
functions	I-Method
to	O
impose	O
a	O
bijection	O
constraint	O
between	O
the	O
latent	O
code	O
space	O
and	O
the	O
image	O
space	O
.	O
	
To	O
demonstrate	O
the	O
generalizability	O
,	O
we	O
apply	O
the	O
proposed	O
method	O
to	O
a	O
unimodal	B-Method
model	I-Method
Pix2Pix	I-Method
using	O
paired	O
training	O
data	O
and	O
a	O
multimodal	B-Method
model	I-Method
DRIT	I-Method
using	O
unpaired	O
images	O
.	O
	
subsubsection	B-Method
:	O
Conditioned	O
on	O
Paired	O
Images	O
	
We	O
take	O
Pix2Pix	B-Method
as	O
the	O
baseline	O
model	O
.	O
	
We	O
also	O
compare	O
MSGAN	B-Method
to	O
BicycleGAN	B-Method
which	O
generates	O
diverse	O
images	O
with	O
paired	O
training	O
images	O
.	O
	
For	O
fair	O
comparisons	O
,	O
architectures	O
of	O
the	O
generator	B-Method
and	O
the	O
discriminator	B-Method
in	O
all	O
methods	O
follow	O
the	O
ones	O
in	O
BicycleGAN	O
.	O
	
We	O
conduct	O
experiments	O
on	O
the	O
facades	O
and	O
maps	O
datasets	O
.	O
	
MSGAN	B-Method
obtains	O
consistent	O
improvements	O
on	O
all	O
metrics	B-Metric
over	O
Pix2Pix	B-Method
.	O
	
Moreover	O
,	O
MSGAN	B-Method
demonstrates	O
comparable	O
diversity	B-Metric
to	O
BicycleGAN	B-Method
,	O
which	O
applies	O
an	O
additional	O
encoder	B-Method
network	I-Method
.	O
	
Figure	O
.	O
	
[	O
reference	O
]	O
and	O
Table	O
.	O
	
[	O
reference	O
]	O
demonstrate	O
the	O
qualitative	O
and	O
quantitative	O
results	O
,	O
respectively	O
.	O
	
subsubsection	B-Method
:	O
Conditioned	O
on	O
Unpaired	O
Images	O
	
We	O
choose	O
DRIT	B-Method
,	O
one	O
of	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
frameworks	O
to	O
generate	O
diverse	O
images	O
with	O
unpaired	O
training	O
data	O
,	O
as	O
the	O
baseline	O
framework	O
.	O
	
Though	O
DRIT	B-Method
synthesizes	O
diverse	O
images	O
in	O
most	O
cases	O
,	O
mode	B-Task
collapse	I-Task
occurs	O
in	O
some	O
challenging	O
shape	B-Task
-	I-Task
variation	I-Task
cases	I-Task
(	O
e.g.	O
,	O
translation	O
between	O
cats	O
and	O
dogs	O
)	O
.	O
	
To	O
demonstrate	O
the	O
robustness	O
of	O
the	O
proposed	O
method	O
,	O
we	O
evaluate	O
on	O
the	O
shape	O
-	O
preserving	O
Yosemite	O
(	O
summer	O
winter	O
)	O
dataset	O
and	O
the	O
cat	O
dog	O
dataset	O
that	O
requires	O
shape	O
variations	O
.	O
	
As	O
the	O
quantitative	O
results	O
exhibited	O
in	O
Table	O
.	O
	
[	O
reference	O
]	O
,	O
MSGAN	B-Method
performs	O
favorably	O
against	O
DRIT	B-Method
in	O
all	O
metrics	O
on	O
both	O
datasets	O
.	O
	
Especially	O
in	O
the	O
challenging	O
cat	O
dog	O
dataset	O
,	O
MSGAN	B-Method
obtains	O
substantial	O
diversity	O
gains	O
.	O
	
From	O
the	O
statistical	O
point	O
of	O
view	O
,	O
we	O
visualize	O
the	O
bin	O
proportions	O
of	O
the	O
dog	O
-	O
to	O
-	O
cat	O
translation	O
in	O
Figure	O
.	O
	
[	O
reference	O
]	O
.	O
	
The	O
graph	O
shows	O
the	O
severe	O
mode	O
collapse	O
issue	O
of	O
DRIT	B-Method
and	O
the	O
substantial	O
improvement	O
with	O
the	O
proposed	O
regularization	B-Method
term	I-Method
.	O
	
Qualitatively	O
,	O
Figure	O
.	O
	
[	O
reference	O
]	O
shows	O
that	O
MSGAN	B-Method
discovers	O
more	O
modes	O
without	O
the	O
loss	B-Metric
of	I-Metric
visual	I-Metric
quality	I-Metric
.	O
	
subsection	O
:	O
Conditioned	O
on	O
Text	O
	
Text	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
synthesis	I-Task
targets	O
at	O
generating	O
images	O
conditioned	O
on	O
text	O
descriptions	O
.	O
	
We	O
integrate	O
the	O
proposed	O
regularization	B-Method
term	I-Method
on	O
StackGAN	B-Method
++	I-Method
using	O
the	O
CUB	O
-	O
200	O
-	O
2011	O
dataset	O
.	O
	
To	O
improve	O
diversity	O
,	O
StackGAN	B-Method
++	I-Method
introduces	O
a	O
Conditioning	B-Method
Augmentation	I-Method
(	I-Method
CA	I-Method
)	I-Method
module	I-Method
that	O
re	O
-	O
parameterizes	O
text	O
descriptions	O
into	O
text	O
codes	O
of	O
the	O
Gaussian	B-Method
distribution	I-Method
.	O
	
Instead	O
of	O
applying	O
the	O
regularization	O
term	O
on	O
the	O
semantically	O
meaningful	O
text	O
codes	O
,	O
we	O
focus	O
on	O
exploiting	O
the	O
latent	O
codes	O
randomly	O
sampled	O
from	O
the	O
prior	O
distribution	O
.	O
	
However	O
,	O
for	O
a	O
fair	O
comparison	O
,	O
we	O
evaluation	O
MSGAN	B-Method
against	O
StackGAN	B-Method
++	I-Method
in	O
two	O
settings	O
:	O
1	O
)	O
Perform	O
generation	B-Task
without	O
fixing	O
text	O
codes	O
for	O
text	O
descriptions	O
.	O
	
In	O
this	O
case	O
,	O
text	O
codes	O
also	O
provide	O
variations	O
for	O
output	O
images	O
.	O
	
2	O
)	O
Perform	O
generation	B-Task
with	O
fixed	O
text	O
codes	O
.	O
	
In	O
this	O
setting	O
,	O
the	O
effects	O
of	O
text	O
codes	O
are	O
excluded	O
.	O
	
Table	O
.	O
	
[	O
reference	O
]	O
presents	O
quantitative	O
comparisons	O
between	O
MSGAN	B-Method
and	O
StackGAN	B-Method
++	I-Method
.	O
	
MSGAN	B-Method
improves	O
the	O
diversity	O
of	O
StackGAN	B-Method
++	I-Method
and	O
maintains	O
visual	B-Metric
quality	I-Metric
.	O
	
To	O
better	O
illustrate	O
the	O
role	O
that	O
latent	O
codes	O
play	O
for	O
the	O
diversity	O
,	O
we	O
show	O
qualitative	O
comparisons	O
with	O
the	O
text	O
codes	O
fixed	O
.	O
	
In	O
this	O
setting	O
,	O
we	O
do	O
not	O
consider	O
the	O
diversity	O
resulting	O
from	O
CA	O
.	O
	
Figure	O
.	O
	
[	O
reference	O
]	O
illustrates	O
that	O
latent	B-Method
codes	I-Method
of	O
StackGAN	B-Method
++	I-Method
have	O
minor	O
effects	O
on	O
the	O
variations	O
of	O
the	O
image	O
.	O
	
On	O
the	O
contrary	O
,	O
latent	O
codes	O
of	O
MSGAN	B-Method
contribute	O
to	O
various	O
appearances	O
and	O
poses	O
of	O
birds	O
.	O
	
subsection	O
:	O
Interpolation	B-Task
of	I-Task
Latent	I-Task
Space	I-Task
in	O
MSGANs	B-Task
	
We	O
perform	O
linear	B-Method
interpolation	I-Method
between	O
two	O
given	O
latent	O
codes	O
and	O
generate	O
corresponding	O
images	O
to	O
have	O
a	O
better	O
understanding	O
of	O
how	O
well	O
MSGANs	B-Method
exploit	O
the	O
latent	O
space	O
.	O
	
Figure	O
.	O
	
[	O
reference	O
]	O
shows	O
the	O
interpolation	O
results	O
on	O
the	O
dog	B-Task
-	I-Task
to	I-Task
-	I-Task
cat	I-Task
translation	I-Task
and	O
the	O
text	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
synthesis	I-Task
task	I-Task
.	O
	
In	O
the	O
dog	B-Task
-	I-Task
to	I-Task
-	I-Task
cat	I-Task
translation	I-Task
,	O
we	O
can	O
see	O
the	O
coat	O
colors	O
and	O
patterns	O
varies	O
smoothly	O
along	O
with	O
the	O
latent	O
vectors	O
.	O
	
In	O
the	O
text	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
synthesis	I-Task
,	O
both	O
orientations	O
of	O
birds	O
and	O
the	O
appearances	O
of	O
footholds	O
change	O
gradually	O
with	O
the	O
variations	O
of	O
the	O
latent	O
codes	O
.	O
	
section	O
:	O
Conclusions	O
	
In	O
this	O
work	O
,	O
we	O
present	O
a	O
simple	O
but	O
effective	O
mode	B-Method
seeking	I-Method
regularization	I-Method
term	I-Method
on	O
the	O
generator	B-Method
to	O
address	O
the	O
model	B-Task
collapse	I-Task
in	I-Task
cGANs	I-Task
.	O
	
By	O
maximizing	O
the	O
distance	O
between	O
generated	O
images	O
with	O
respect	O
to	O
that	O
between	O
the	O
corresponding	O
latent	O
codes	O
,	O
the	O
regularization	B-Method
term	I-Method
forces	O
the	O
generators	O
to	O
explore	O
more	O
minor	O
modes	O
.	O
	
The	O
proposed	O
regularization	B-Method
method	I-Method
can	O
be	O
readily	O
integrated	O
with	O
existing	O
cGANs	B-Method
framework	I-Method
without	O
imposing	O
training	O
overheads	O
and	O
modifications	O
of	O
network	O
structures	O
.	O
	
We	O
demonstrate	O
the	O
generalizability	O
of	O
the	O
proposed	O
method	O
on	O
three	O
different	O
conditional	B-Task
generation	I-Task
tasks	I-Task
including	O
categorical	B-Task
generation	I-Task
,	O
image	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
translation	I-Task
,	O
and	O
text	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
synthesis	I-Task
.	O
	
Both	O
qualitative	O
and	O
quantitative	O
results	O
show	O
that	O
the	O
proposed	O
regularization	B-Method
term	I-Method
facilitates	O
the	O
baseline	O
frameworks	O
improving	O
the	O
diversity	B-Metric
without	O
sacrificing	O
visual	B-Metric
quality	I-Metric
of	O
the	O
generated	O
images	O
.	O
	
bibliography	O
:	O
References	O
	
section	O
:	O
Implementation	O
Details	O
	
Table	O
[	O
reference	O
]	O
summarizes	O
the	O
datasets	O
and	O
baseline	O
models	O
used	O
on	O
various	O
tasks	O
.	O
	
For	O
all	O
of	O
the	O
baseline	O
methods	O
,	O
we	O
incorporate	O
the	O
original	O
objective	O
functions	O
with	O
the	O
proposed	O
regularization	O
term	O
.	O
	
Note	O
that	O
we	O
remain	O
the	O
original	O
network	B-Method
architecture	I-Method
design	I-Method
and	O
use	O
the	O
default	O
setting	O
of	O
hyper	O
-	O
parameters	O
for	O
the	O
training	O
.	O
	
DCGAN	B-Method
.	O
	
Since	O
the	O
images	O
in	O
the	O
CIFAR	B-Material
-	I-Material
10	I-Material
dataset	I-Material
are	O
of	O
size	O
,	O
we	O
modify	O
the	O
structure	O
of	O
the	O
generator	B-Method
and	I-Method
discriminator	I-Method
in	O
DCGAN	B-Method
,	O
as	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
We	O
use	O
the	O
batch	O
size	O
of	O
,	O
learning	B-Metric
rate	I-Metric
of	O
and	O
Adam	B-Method
optimizer	I-Method
with	O
and	O
to	O
train	O
both	O
the	O
baseline	B-Method
and	I-Method
MSGAN	I-Method
network	I-Method
.	O
	
Pix2Pix	B-Method
.	O
	
We	O
adopt	O
the	O
generator	B-Method
and	I-Method
discriminator	I-Method
in	O
BicycleGAN	B-Method
to	O
build	O
the	O
Pix2Pix	B-Method
model	I-Method
.	O
	
Same	O
as	O
BicycleGAN	B-Method
,	O
we	O
use	O
a	O
U	B-Method
-	I-Method
Net	I-Method
network	I-Method
for	O
the	O
generator	B-Method
,	O
and	O
inject	O
the	O
latent	O
codes	O
into	O
every	O
layer	O
of	O
the	O
generator	O
.	O
	
The	O
architecture	O
of	O
the	O
discriminator	B-Method
is	O
a	O
two	B-Method
-	I-Method
scale	I-Method
PatchGAN	I-Method
network	I-Method
.	O
	
For	O
the	O
training	B-Task
,	O
both	O
Pix2Pix	B-Method
and	I-Method
MSGAN	I-Method
framework	I-Method
use	O
the	O
same	O
hyper	O
-	O
parameters	O
as	O
the	O
officially	O
released	O
version	O
.	O
	
DRIT	B-Method
.	O
	
DRIT	B-Method
involves	O
two	O
stages	O
of	O
image	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
translations	I-Task
in	O
the	O
training	B-Task
process	I-Task
.	O
	
We	O
only	O
apply	O
the	O
mode	B-Method
seeking	I-Method
regularization	I-Method
term	I-Method
to	O
generators	O
in	O
the	O
first	O
stage	O
,	O
which	O
is	O
modified	O
on	O
the	O
officially	O
released	O
code	O
.	O
	
StackGAN	B-Method
++	I-Method
.	O
	
StackGAN	B-Method
++	I-Method
is	O
a	O
tree	B-Method
-	I-Method
like	I-Method
structure	I-Method
with	O
multiple	O
generators	O
and	O
discriminators	B-Method
.	O
	
We	O
use	O
the	O
output	O
images	O
from	O
the	O
last	O
generator	O
and	O
input	O
latent	O
codes	O
to	O
calculate	O
the	O
mode	B-Method
seeking	I-Method
regularization	I-Method
term	I-Method
.	O
	
The	O
implementation	O
is	O
based	O
on	O
the	O
officially	O
released	O
code	O
.	O
	
section	O
:	O
Evaluation	O
Details	O
	
We	O
employ	O
the	O
official	O
implementation	O
of	O
FID	B-Metric
,	O
NDB	O
and	O
JSD	B-Metric
,	O
and	O
LPIPS	B-Method
.	O
	
For	O
NDB	B-Task
and	O
JSD	B-Metric
,	O
we	O
use	O
the	O
K	B-Method
-	I-Method
means	I-Method
method	I-Method
on	O
training	O
samples	O
to	O
obtain	O
the	O
clusters	O
.	O
	
Then	O
the	O
generated	O
samples	O
are	O
assigned	O
to	O
the	O
nearest	O
cluster	O
to	O
compute	O
the	O
bin	O
proportions	O
.	O
	
As	O
suggested	O
by	O
the	O
author	O
of	O
,	O
there	O
are	O
at	O
least	O
training	O
samples	O
for	O
each	O
cluster	O
.	O
	
Therefore	O
,	O
we	O
cluster	O
the	O
number	O
of	O
bins	O
in	O
all	O
tasks	O
,	O
where	O
denotes	O
the	O
number	O
of	O
training	O
samples	O
for	O
computing	O
the	O
clusters	O
.	O
	
We	O
have	O
verified	O
that	O
the	O
performance	O
is	O
consistent	O
within	O
a	O
large	O
range	O
of	O
.	O
	
For	O
evaluation	O
,	O
we	O
randomly	O
generate	O
images	O
for	O
a	O
given	O
conditional	O
context	O
on	O
various	O
tasks	O
.	O
	
We	O
conduct	O
five	O
independent	O
trials	O
and	O
report	O
the	O
mean	O
and	O
standard	O
derivation	O
based	O
on	O
the	O
result	O
of	O
each	O
trial	O
.	O
	
More	O
evaluation	O
details	O
of	O
one	O
trial	O
are	O
presented	O
as	O
follows	O
.	O
	
Conditioned	O
on	O
Class	O
Label	O
.	O
	
We	O
randomly	O
generate	O
images	O
for	O
each	O
class	O
label	O
.	O
	
We	O
use	O
all	O
the	O
training	O
samples	O
and	O
the	O
generated	O
samples	O
to	O
compute	O
FID	B-Metric
.	O
	
For	O
NDB	B-Task
and	O
JSD	B-Metric
,	O
we	O
employ	O
the	O
training	O
samples	O
in	O
each	O
class	O
to	O
calculate	O
clusters	O
.	O
	
Conditioned	O
on	O
Image	O
.	O
	
We	O
randomly	O
generate	O
images	O
for	O
each	O
input	O
image	O
in	O
the	O
test	O
set	O
.	O
	
For	O
LPIPS	B-Method
,	O
we	O
randomly	O
select	O
pairs	O
of	O
the	O
images	O
of	O
each	O
context	O
in	O
the	O
test	O
set	O
to	O
compute	O
LPIPS	B-Method
and	O
average	O
all	O
the	O
values	O
for	O
this	O
trial	O
.	O
	
Then	O
,	O
we	O
randomly	O
choose	O
input	O
images	O
and	O
their	O
corresponding	O
generated	O
images	O
to	O
form	O
generated	O
samples	O
.	O
	
We	O
use	O
the	O
generated	O
samples	O
and	O
all	O
samples	O
in	O
training	O
set	O
to	O
compute	O
FID	B-Metric
.	O
	
For	O
NDB	B-Task
and	O
JSD	B-Metric
,	O
we	O
employ	O
all	O
the	O
training	O
samples	O
for	O
clustering	B-Task
and	O
choose	O
bins	O
for	O
facades	O
,	O
and	O
bins	O
for	O
other	O
datasets	O
.	O
	
Conditioned	O
on	O
Text	O
.	O
	
We	O
randomly	O
select	O
sentences	O
and	O
generate	O
images	O
for	O
each	O
sentence	O
,	O
which	O
forms	O
generated	O
samples	O
.	O
	
Then	O
,	O
we	O
randomly	O
select	O
samples	O
for	O
computing	O
FID	B-Metric
,	O
and	O
clustering	O
them	O
into	O
bins	O
for	O
NDB	B-Task
and	O
JSD	B-Metric
.	O
	
For	O
LPIPS	B-Method
,	O
we	O
randomly	O
choose	O
pairs	O
for	O
each	O
sentence	O
and	O
average	O
the	O
values	O
of	O
all	O
the	O
pairs	O
for	O
this	O
trial	O
.	O
	
section	O
:	O
Ablation	B-Task
Study	I-Task
on	O
the	O
Regularization	B-Method
Term	I-Method
	
subsection	O
:	O
The	O
Weighting	O
Parameter	O
	
To	O
analyze	O
the	O
influence	O
of	O
the	O
regularization	O
term	O
,	O
we	O
conduct	O
an	O
ablation	B-Task
study	I-Task
by	O
varying	O
the	O
weighting	O
parameter	O
on	O
image	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
translation	I-Task
task	I-Task
using	O
the	O
facades	O
dataset	O
.	O
	
Figure	O
[	O
reference	O
]	O
presents	O
the	O
qualitative	O
and	O
quantitative	O
results	O
.	O
	
It	O
can	O
be	O
observed	O
that	O
increasing	O
improves	O
both	O
the	O
quality	B-Metric
and	O
diversity	O
of	O
the	O
generated	O
images	O
.	O
	
Nevertheless	O
,	O
as	O
the	O
weighting	O
parameter	O
becomes	O
larger	O
than	O
a	O
threshold	O
value	O
(	O
)	O
,	O
the	O
training	B-Method
becomes	O
unstable	O
,	O
which	O
yields	O
low	O
quality	O
,	O
and	O
even	O
low	O
diversity	O
synthesized	O
images	O
.	O
	
As	O
a	O
result	O
,	O
we	O
empirically	O
set	O
the	O
weighting	O
parameter	O
for	O
all	O
experiments	O
.	O
	
subsection	O
:	O
The	O
Design	O
Choice	O
of	O
the	O
Distance	B-Metric
Metric	I-Metric
	
We	O
have	O
explored	O
other	O
design	O
choice	O
of	O
the	O
distance	B-Metric
metric	I-Metric
.	O
	
We	O
conduct	O
experiments	O
using	O
discriminator	O
feature	O
distance	O
in	O
our	O
regularization	O
term	O
in	O
a	O
way	O
similar	O
to	O
feature	B-Task
matching	I-Task
loss	I-Task
,	O
where	O
denotes	O
the	O
layer	O
of	O
the	O
discriminator	O
.	O
	
We	O
apply	O
it	O
to	O
Pix2Pix	O
on	O
the	O
facades	O
dataset	O
.	O
	
Table	O
.	O
	
[	O
reference	O
]	O
shows	O
that	O
MSGAN	B-Method
using	O
feature	B-Method
distance	I-Method
also	O
obtains	O
improvement	O
over	O
Pix2Pix	B-Method
.	O
	
However	O
,	O
MSGAN	B-Method
using	I-Method
distance	I-Method
has	O
higher	O
diversity	O
.	O
	
Therefore	O
,	O
we	O
employ	O
MSGAN	B-Method
using	O
distance	B-Method
for	O
all	O
experiments	O
.	O
	
section	O
:	O
Computational	B-Metric
Overheads	I-Metric
	
We	O
compare	O
MSGAN	B-Method
with	O
Pix2Pix	B-Method
,	O
BicycleGAN	B-Method
in	O
terms	O
of	O
training	B-Metric
time	I-Metric
,	O
memory	B-Metric
consumption	I-Metric
,	O
and	O
model	B-Method
parameters	I-Method
on	O
an	O
NVIDIA	O
TITAN	O
X	O
GPU	O
.	O
	
Table	O
.	O
	
[	O
reference	O
]	O
shows	O
that	O
our	O
method	O
incurs	O
marginal	B-Metric
overheads	I-Metric
.	O
	
However	O
,	O
BicycleGAN	B-Method
requires	O
longer	O
time	O
per	O
iteration	O
and	O
larger	O
memory	O
with	O
an	O
additional	O
encoder	B-Method
and	O
another	O
discriminator	B-Method
network	I-Method
.	O
	
section	O
:	O
Additional	O
Results	O
	
We	O
present	O
more	O
results	O
of	O
categorical	B-Task
generation	I-Task
,	O
image	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
translation	I-Task
,	O
and	O
text	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
synthesis	I-Task
in	O
Figure	O
[	O
reference	O
]	O
,	O
Figure	O
[	O
reference	O
]	O
,	O
Figure	O
[	O
reference	O
]	O
,	O
Figure	O
[	O
reference	O
]	O
,	O
Figure	O
[	O
reference	O
]	O
,	O
and	O
Figure	O
[	O
reference	O
]	O
,	O
respectively	O
.	O
	
document	O
:	O
HD	O
-	O
CNN	B-Method
:	O
Hierarchical	B-Method
Deep	I-Method
Convolutional	I-Method
Neural	I-Method
Network	I-Method
for	O
Large	B-Task
Scale	I-Task
Visual	I-Task
Recognition	I-Task
	
In	O
image	B-Task
classification	I-Task
,	O
visual	B-Task
separability	I-Task
between	O
different	O
object	O
categories	O
is	O
highly	O
uneven	O
,	O
and	O
some	O
categories	O
are	O
more	O
difficult	O
to	O
distinguish	O
than	O
others	O
.	O
	
Such	O
difficult	O
categories	O
demand	O
more	O
dedicated	O
classifiers	B-Method
.	O
	
However	O
,	O
existing	O
deep	B-Method
convolutional	I-Method
neural	I-Method
networks	I-Method
(	O
CNN	B-Method
)	I-Method
are	O
trained	O
as	O
flat	B-Method
N	I-Method
-	I-Method
way	I-Method
classifiers	I-Method
,	O
and	O
few	O
efforts	O
have	O
been	O
made	O
to	O
leverage	O
the	O
hierarchical	O
structure	O
of	O
categories	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
introduce	O
hierarchical	B-Method
deep	I-Method
CNNs	I-Method
(	O
HD	B-Method
-	I-Method
CNNs	I-Method
)	O
by	O
embedding	O
deep	O
CNNs	B-Method
into	O
a	O
category	O
hierarchy	O
.	O
	
An	O
HD	O
-	O
CNN	B-Method
separates	O
easy	O
classes	O
using	O
a	O
coarse	B-Task
category	O
classifier	O
while	O
distinguishing	O
difficult	O
classes	O
using	O
fine	B-Method
category	I-Method
classifiers	I-Method
.	O
	
During	O
HD	O
-	O
CNN	B-Method
training	O
,	O
component	B-Method
-	I-Method
wise	I-Method
pretraining	I-Method
is	O
followed	O
by	O
global	B-Method
finetuning	I-Method
with	O
a	O
multinomial	B-Method
logistic	I-Method
loss	I-Method
regularized	O
by	O
a	O
coarse	B-Task
category	O
consistency	O
term	O
.	O
	
In	O
addition	O
,	O
conditional	B-Method
executions	I-Method
of	I-Method
fine	I-Method
category	I-Method
classifiers	I-Method
and	O
layer	B-Method
parameter	I-Method
compression	I-Method
make	O
HD	B-Method
-	I-Method
CNNs	I-Method
scalable	O
for	O
large	B-Task
-	I-Task
scale	I-Task
visual	I-Task
recognition	I-Task
.	O
	
We	O
achieve	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
both	O
CIFAR100	B-Material
and	O
large	O
-	O
scale	O
ImageNet	O
1000	O
-	O
class	O
benchmark	O
datasets	O
.	O
	
In	O
our	O
experiments	O
,	O
we	O
build	O
up	O
three	O
different	O
HD	B-Method
-	I-Method
CNNs	I-Method
and	O
they	O
lower	O
the	O
top	B-Metric
-	I-Metric
1	I-Metric
error	I-Metric
of	O
the	O
standard	O
CNNs	B-Method
by	O
,	O
and	O
,	O
respectively	O
.	O
	
.22	O
.72	O
	
section	O
:	O
Introduction	O
	
Deep	O
CNNs	B-Method
are	O
well	O
suited	O
for	O
large	B-Task
-	I-Task
scale	I-Task
learning	I-Task
based	I-Task
visual	I-Task
recognition	I-Task
tasks	I-Task
because	O
of	O
its	O
highly	O
scalable	O
training	B-Method
algorithm	I-Method
,	O
which	O
only	O
needs	O
to	O
cache	O
a	O
small	O
chunk	O
(	O
mini	O
-	O
batch	O
)	O
of	O
the	O
potentially	O
huge	O
volume	O
of	O
training	O
data	O
during	O
sequential	O
scans	O
(	O
epochs	O
)	O
.	O
	
They	O
have	O
achieved	O
increasingly	O
better	O
performance	O
in	O
recent	O
years	O
.	O
	
As	O
datasets	O
become	O
bigger	O
and	O
the	O
number	O
of	O
object	O
categories	O
becomes	O
larger	O
,	O
one	O
of	O
the	O
complications	O
that	O
come	O
along	O
is	O
that	O
visual	O
separability	O
between	O
different	O
object	O
categories	O
is	O
highly	O
uneven	O
.	O
	
Some	O
categories	O
are	O
much	O
harder	O
to	O
distinguish	O
than	O
others	O
.	O
	
Take	O
the	O
categories	O
in	O
CIFAR100	B-Material
as	O
an	O
example	O
.	O
	
It	O
is	O
easy	O
to	O
tell	O
an	O
Apple	O
from	O
a	O
Bus	O
,	O
but	O
harder	O
to	O
tell	O
an	O
Apple	O
from	O
an	O
Orange	O
.	O
	
In	O
fact	O
,	O
both	O
Apples	O
and	O
Oranges	O
belong	O
to	O
the	O
same	O
coarse	B-Task
category	O
fruit	O
and	O
vegetables	O
while	O
Buses	O
belong	O
to	O
another	O
coarse	B-Task
category	O
vehicles	O
1	O
,	O
as	O
defined	O
within	O
CIFAR100	B-Material
.	O
	
Nonetheless	O
,	O
most	O
deep	O
CNN	B-Method
models	O
nowadays	O
are	O
flat	O
N	B-Method
-	I-Method
way	I-Method
classifiers	I-Method
,	O
which	O
share	O
a	O
set	O
of	O
fully	O
connected	O
layers	O
.	O
	
This	O
makes	O
us	O
wonder	O
whether	O
such	O
a	O
flat	O
structure	O
is	O
adequate	O
for	O
distinguishing	O
all	O
the	O
difficult	O
categories	O
.	O
	
A	O
very	O
natural	O
and	O
intuitive	O
alternative	O
organizes	O
classifiers	B-Method
in	O
a	O
hierarchical	O
manner	O
according	O
to	O
the	O
divide	B-Method
-	I-Method
and	I-Method
-	I-Method
conquer	I-Method
strategy	I-Method
.	O
	
Although	O
hierarchical	B-Method
classification	I-Method
has	O
been	O
proven	O
effective	O
for	O
conventional	O
linear	B-Method
classifiers	I-Method
,	O
few	O
attempts	O
have	O
been	O
made	O
to	O
exploit	O
category	O
hierarchies	O
in	O
deep	O
CNN	B-Method
models	O
.	O
	
Since	O
deep	O
CNN	B-Method
models	O
are	O
large	O
models	O
themselves	O
,	O
organizing	O
them	O
hierarchically	O
imposes	O
the	O
following	O
challenges	O
.	O
	
First	O
,	O
instead	O
of	O
a	O
handcrafted	O
category	O
hierarchy	O
,	O
how	O
can	O
we	O
learn	O
such	O
a	O
category	O
hierarchy	O
from	O
the	O
training	O
data	O
itself	O
so	O
that	O
cascaded	B-Method
inferences	I-Method
in	O
a	O
hierarchical	B-Method
classifier	I-Method
will	O
not	O
degrade	O
the	O
overall	O
accuracy	B-Metric
while	O
dedicated	O
fine	B-Method
category	I-Method
classifiers	I-Method
exist	O
for	O
hard	O
-	O
to	O
-	O
distinguish	O
categories	O
?	O
	
Second	O
,	O
a	O
hierarchical	O
CNN	B-Method
classifier	O
consists	O
of	O
multiple	O
CNN	B-Method
models	O
at	O
different	O
levels	O
.	O
	
How	O
can	O
we	O
leverage	O
the	O
commonalities	O
among	O
these	O
models	O
and	O
effectively	O
train	O
them	O
all	O
?	O
	
Third	O
,	O
it	O
would	O
also	O
be	O
slower	O
and	O
more	O
memory	O
-	O
consuming	O
to	O
run	O
a	O
hierarchical	O
CNN	B-Method
classifier	O
on	O
a	O
novel	O
testing	O
image	O
.	O
	
How	O
can	O
we	O
alleviate	O
such	O
limitations	O
?	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
generic	B-Method
and	I-Method
principled	I-Method
hierarchical	I-Method
architecture	I-Method
,	O
Hierarchical	B-Method
Deep	I-Method
Convolutional	I-Method
Neural	I-Method
Network	I-Method
(	O
HD	O
-	O
CNN	B-Method
)	O
,	O
that	O
decomposes	O
an	O
image	B-Task
classification	I-Task
task	O
into	O
two	O
steps	O
.	O
	
An	O
HD	O
-	O
CNN	B-Method
first	O
uses	O
a	O
coarse	B-Task
category	O
CNN	B-Method
classifier	O
to	O
separate	O
easy	O
classes	O
from	O
one	O
another	O
.	O
	
More	O
challenging	O
classes	O
are	O
routed	O
downstream	O
to	O
fine	B-Method
category	I-Method
classifiers	I-Method
that	O
focus	O
on	O
confusing	O
classes	O
.	O
	
We	O
adopt	O
a	O
module	B-Method
design	I-Method
principle	I-Method
and	O
every	O
HD	O
-	O
CNN	B-Method
is	O
built	O
upon	O
a	O
building	O
block	O
CNN	B-Method
.	O
	
The	O
building	O
block	O
can	O
be	O
chosen	O
to	O
be	O
any	O
of	O
the	O
currently	O
top	O
ranked	O
single	O
CNNs	B-Method
.	O
	
Thus	O
HD	B-Method
-	I-Method
CNNs	I-Method
can	O
always	O
benefit	O
from	O
the	O
progress	O
of	O
single	O
CNN	B-Method
design	O
.	O
	
An	O
HD	O
-	O
CNN	B-Method
follows	O
the	O
coarse	B-Task
-	O
to	O
-	O
fine	O
classification	O
paradigm	O
and	O
probabilistically	O
integrates	O
predictions	O
from	O
the	O
fine	B-Method
category	I-Method
classifiers	I-Method
.	O
	
Compared	O
with	O
the	O
building	O
block	O
CNN	B-Method
,	O
the	O
corresponding	O
HD	O
-	O
CNN	B-Method
can	O
achieve	O
lower	O
error	B-Metric
at	O
the	O
cost	O
of	O
a	O
manageable	O
increase	O
in	O
memory	B-Metric
footprint	I-Metric
and	O
classification	B-Metric
time	I-Metric
.	O
	
In	O
summary	O
,	O
this	O
paper	O
has	O
the	O
following	O
contributions	O
.	O
	
First	O
,	O
we	O
introduce	O
a	O
novel	O
hierarchical	B-Method
architecture	I-Method
,	O
called	O
HD	O
-	O
CNN	B-Method
,	O
for	O
image	B-Task
classification	I-Task
.	O
	
Second	O
,	O
we	O
develop	O
a	O
scheme	O
for	O
learning	O
the	O
two	O
-	O
level	O
organization	O
of	O
coarse	B-Task
and	O
fine	O
categories	O
,	O
and	O
demonstrate	O
various	O
components	O
of	O
an	O
HD	O
-	O
CNN	B-Method
can	O
be	O
independently	O
pretrained	O
.	O
	
The	O
complete	O
HD	O
-	O
CNN	B-Method
is	O
further	O
fine	O
-	O
tuned	O
using	O
a	O
multinomial	B-Method
logistic	I-Method
loss	I-Method
regularized	O
by	O
a	O
coarse	B-Task
category	O
consistency	O
term	O
.	O
	
Third	O
,	O
we	O
make	O
the	O
HD	O
-	O
CNN	B-Method
scalable	O
by	O
compressing	O
the	O
layer	O
parameters	O
and	O
conditionally	O
executing	O
the	O
fine	B-Method
category	I-Method
classifiers	I-Method
.	O
	
We	O
have	O
performed	O
evaluations	O
on	O
the	O
medium	O
-	O
scale	O
CIFAR100	B-Material
dataset	O
and	O
the	O
large	O
-	O
scale	O
ImageNet	O
1000	O
-	O
class	O
dataset	O
,	O
and	O
our	O
method	O
has	O
achieved	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
both	O
of	O
them	O
.	O
	
section	O
:	O
Related	O
Work	O
	
Our	O
work	O
is	O
inspired	O
by	O
progresses	O
in	O
CNN	B-Method
design	O
and	O
efforts	O
on	O
integrating	O
a	O
category	O
hierarchy	O
with	O
linear	B-Method
classifiers	I-Method
.	O
	
The	O
main	O
novelty	O
of	O
our	O
method	O
is	O
a	O
new	O
scalable	O
HD	O
-	O
CNN	B-Method
architecture	O
that	O
integrates	O
a	O
category	O
hierarchy	O
with	O
deep	O
CNNs	B-Method
.	O
	
subsection	O
:	O
Convolutional	B-Method
Neural	I-Method
Networks	I-Method
	
CNN	B-Method
-	O
based	O
models	O
hold	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
in	O
various	O
computer	B-Task
vision	I-Task
tasks	I-Task
,	O
including	O
image	B-Task
classifcation	I-Task
,	O
object	B-Task
detection	I-Task
,	O
and	O
image	B-Task
parsing	I-Task
.	O
	
Recently	O
,	O
there	O
has	O
been	O
considerable	O
interest	O
in	O
enhancing	O
CNN	B-Method
components	O
,	O
including	O
pooling	B-Method
layers	I-Method
,	O
activation	B-Method
units	I-Method
,	O
and	O
nonlinear	B-Method
layers	I-Method
.	O
	
These	O
enhancements	O
either	O
improve	O
CNN	B-Method
training	O
,	O
or	O
expand	O
the	O
network	B-Method
learning	I-Method
capacity	I-Method
.	O
	
This	O
work	O
boosts	O
CNN	B-Method
performance	O
from	O
an	O
orthogonal	O
angle	O
and	O
does	O
not	O
redesign	O
a	O
specific	O
part	O
within	O
any	O
existing	O
CNN	B-Method
model	O
.	O
	
Instead	O
,	O
we	O
design	O
a	O
novel	O
generic	B-Method
hierarchical	I-Method
architecture	I-Method
that	O
uses	O
an	O
existing	O
CNN	B-Method
model	O
as	O
a	O
building	B-Method
block	I-Method
.	O
	
We	O
embed	O
multiple	O
building	O
blocks	O
into	O
a	O
larger	O
hierarchical	O
deep	O
CNN	B-Method
.	O
	
subsection	O
:	O
Category	O
Hierarchy	O
for	O
Visual	B-Task
Recognition	I-Task
	
In	O
visual	B-Task
recognition	I-Task
,	O
there	O
is	O
a	O
vast	O
literature	O
exploiting	O
category	O
hierarchical	O
structures	O
.	O
	
For	O
classification	B-Task
with	O
a	O
large	O
number	O
of	O
classes	O
using	O
linear	B-Method
classifiers	I-Method
,	O
a	O
common	O
strategy	O
is	O
to	O
build	O
a	O
hierarchy	O
or	O
taxonomy	B-Method
of	I-Method
classifiers	I-Method
so	O
that	O
the	O
number	O
of	O
classifiers	B-Method
evaluated	O
given	O
a	O
testing	O
image	O
scales	O
sub	O
-	O
linearly	O
in	O
the	O
number	O
of	O
classes	O
.	O
	
The	O
hierarchy	O
can	O
be	O
either	O
predefined	O
or	O
learnt	O
by	O
top	B-Method
-	I-Method
down	I-Method
and	I-Method
bottom	I-Method
-	I-Method
up	I-Method
approaches	I-Method
.	O
	
In	O
,	O
the	O
predefined	O
category	O
hierarchy	O
of	O
ImageNet	O
dataset	O
is	O
utilized	O
to	O
achieve	O
the	O
trade	O
-	O
offs	O
between	O
classification	B-Metric
accuracy	I-Metric
and	O
specificity	B-Metric
.	O
	
In	O
,	O
a	O
hierarchical	O
label	O
tree	O
is	O
constructed	O
to	O
probabilistically	O
combine	O
predictions	O
from	O
leaf	O
nodes	O
.	O
	
Such	O
hierarchical	B-Method
classifier	I-Method
achieves	O
significant	O
speedup	O
at	O
the	O
cost	O
of	O
certain	O
accuracy	B-Metric
loss	I-Metric
.	O
	
One	O
of	O
the	O
earliest	O
attempts	O
to	O
introduce	O
a	O
category	B-Method
hierarchy	I-Method
in	O
CNN	B-Method
-	O
based	O
methods	O
is	O
reported	O
in	O
but	O
their	O
main	O
goal	O
is	O
transferring	O
knowledge	O
between	O
classes	O
to	O
improve	O
the	O
results	O
for	O
classes	O
with	O
insufficient	O
training	O
examples	O
.	O
	
In	O
,	O
various	O
label	O
relations	O
are	O
encoded	O
in	O
a	O
hierarchy	O
.	O
	
Improved	O
accuracy	B-Metric
is	O
achieved	O
only	O
when	O
a	O
subset	O
of	O
training	O
images	O
are	O
relabeled	O
with	O
internal	O
nodes	O
in	O
the	O
hierarchical	O
class	O
tree	O
.	O
	
They	O
are	O
not	O
able	O
to	O
improve	O
the	O
accuracy	B-Metric
in	O
the	O
original	O
setting	O
where	O
all	O
training	O
images	O
are	O
labeled	O
with	O
leaf	O
nodes	O
.	O
	
In	O
,	O
a	O
hierarchy	O
of	O
CNNs	B-Method
is	O
introduced	O
but	O
they	O
experimented	O
with	O
only	O
two	O
coarse	B-Task
categories	O
mainly	O
due	O
to	O
scalability	O
constraints	O
.	O
	
HD	O
-	O
CNN	B-Method
exploits	O
the	O
category	O
hierarchy	O
in	O
a	O
novel	O
way	O
that	O
we	O
embed	O
deep	O
CNNs	B-Method
into	O
the	O
hierarchy	O
in	O
a	O
scalable	O
manner	O
and	O
achieves	O
superior	O
classification	B-Metric
results	O
over	O
the	O
standard	O
CNN	B-Method
.	O
	
section	O
:	O
Overview	O
of	O
HD	O
-	O
CNN	B-Method
	
subsection	O
:	O
Notations	O
	
The	O
following	O
notations	O
are	O
used	O
below	O
.	O
	
A	O
dataset	O
consists	O
of	O
images	O
.	O
and	O
denote	O
the	O
image	O
data	O
and	O
label	O
,	O
respectively	O
.	O
	
There	O
are	O
fine	O
categories	O
of	O
images	O
in	O
the	O
dataset	O
.	O
	
We	O
will	O
learn	O
a	O
category	O
hierarchy	O
with	O
coarse	B-Task
categories	O
.	O
	
subsection	O
:	O
HD	O
-	O
CNN	B-Method
Architecture	O
	
HD	O
-	O
CNN	B-Method
is	O
designed	O
to	O
mimic	O
the	O
structure	O
of	O
category	O
hierarchy	O
where	O
fine	O
categories	O
are	O
divided	O
into	O
coarse	B-Task
categories	O
as	O
in	O
Fig	O
[	O
reference	O
]	O
	
(	O
a	O
)	O
.	O
	
It	O
performs	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
classification	I-Task
as	O
illustrated	O
in	O
Fig	O
[	O
reference	O
]	O
	
(	O
b	O
)	O
.	O
	
It	O
mainly	O
comprises	O
four	O
parts	O
,	O
namely	O
shared	B-Method
layers	I-Method
,	O
a	O
single	O
coarse	B-Task
category	O
component	O
,	O
multiple	O
fine	B-Method
category	I-Method
components	I-Method
and	O
a	O
single	O
probabilistic	B-Method
averaging	I-Method
layer	I-Method
.	O
	
On	O
the	O
left	O
side	O
of	O
Fig	O
[	O
reference	O
]	O
(	O
b	O
)	O
are	O
the	O
shared	O
layers	O
.	O
	
They	O
receive	O
raw	O
image	O
pixel	O
as	O
input	O
and	O
extract	O
low	O
-	O
level	O
features	O
.	O
	
The	O
configuration	O
of	O
shared	O
layers	O
are	O
set	O
to	O
be	O
the	O
same	O
as	O
the	O
preceding	O
layers	O
in	O
the	O
building	O
block	O
net	O
.	O
	
On	O
the	O
top	O
of	O
Fig	O
[	O
reference	O
]	O
(	O
b	O
)	O
are	O
independent	O
layers	O
of	O
coarse	B-Task
category	O
component	O
which	O
reuses	O
the	O
configuration	O
of	O
rear	O
layers	O
from	O
the	O
building	O
block	O
CNN	B-Method
and	O
produces	O
a	O
fine	B-Task
prediction	I-Task
for	O
an	O
image	O
.	O
	
To	O
produce	O
a	O
prediction	O
over	O
coarse	B-Task
categories	O
,	O
we	O
append	O
a	O
fine	O
-	O
to	O
-	O
coarse	B-Task
aggregation	O
layer	O
which	O
aggregates	O
fine	O
predictions	O
into	O
coarse	B-Task
ones	O
when	O
a	O
mapping	O
from	O
fine	O
categories	O
to	O
coarse	B-Task
ones	O
is	O
given	O
.	O
	
The	O
coarse	B-Task
category	O
probabilities	O
serve	O
two	O
purposes	O
.	O
	
First	O
,	O
they	O
are	O
used	O
as	O
weights	O
for	O
combining	O
the	O
predictions	O
made	O
by	O
fine	B-Method
category	I-Method
components	I-Method
.	O
	
Second	O
,	O
when	O
thresholded	O
,	O
they	O
enable	O
conditional	B-Method
executions	I-Method
of	I-Method
fine	I-Method
category	I-Method
components	I-Method
whose	O
corresponding	O
coarse	B-Task
probabilities	O
are	O
sufficiently	O
large	O
.	O
	
In	O
the	O
bottom	O
-	O
right	O
of	O
Fig	O
[	O
reference	O
]	O
(	O
b	O
)	O
are	O
independent	O
layers	O
of	O
a	O
set	O
of	O
fine	B-Method
category	I-Method
classifiers	I-Method
,	O
each	O
of	O
which	O
makes	O
fine	B-Task
category	I-Task
predictions	I-Task
.	O
	
As	O
each	O
fine	B-Method
component	I-Method
only	O
excels	O
in	O
classifying	O
a	O
small	O
set	O
of	O
categories	O
,	O
they	O
produce	O
a	O
fine	O
prediction	O
over	O
a	O
partial	O
set	O
of	O
categories	O
.	O
	
The	O
probabilities	O
of	O
other	O
fine	O
categories	O
absent	O
in	O
the	O
partial	O
set	O
are	O
implicitly	O
set	O
to	O
zero	O
.	O
	
The	O
layer	O
configurations	O
are	O
mostly	O
copied	O
from	O
the	O
building	O
block	O
CNN	B-Method
except	O
that	O
in	O
the	O
final	O
classification	B-Method
layer	I-Method
the	O
number	O
of	O
filters	O
is	O
set	O
to	O
be	O
the	O
size	O
of	O
partial	O
set	O
instead	O
of	O
the	O
full	O
categories	O
.	O
	
Both	O
coarse	B-Task
category	O
component	O
and	O
fine	B-Method
category	I-Method
components	I-Method
share	O
common	O
layers	O
.	O
	
The	O
reason	O
is	O
three	O
-	O
fold	O
.	O
	
First	O
,	O
it	O
is	O
shown	O
in	O
that	O
preceding	O
layers	O
in	O
deep	B-Method
networks	I-Method
response	O
to	O
class	O
-	O
agnostic	O
low	O
-	O
level	O
features	O
such	O
as	O
corners	O
and	O
edges	O
,	O
while	O
rear	B-Method
layers	I-Method
extract	O
more	O
class	O
-	O
specific	O
features	O
such	O
as	O
dog	O
face	O
and	O
bird	O
’s	O
legs	O
.	O
	
Since	O
low	O
-	O
level	O
features	O
are	O
useful	O
for	O
both	O
coarse	B-Task
and	O
fine	B-Task
classification	I-Task
tasks	I-Task
,	O
we	O
allow	O
the	O
preceding	O
layers	O
to	O
be	O
shared	O
by	O
both	O
coarse	B-Task
and	O
fine	O
components	O
.	O
	
Second	O
,	O
it	O
reduces	O
both	O
the	O
total	O
floating	B-Metric
point	I-Metric
operations	I-Metric
and	O
the	O
memory	B-Metric
footprint	I-Metric
of	O
network	B-Task
execution	I-Task
.	O
	
Both	O
are	O
of	O
practical	O
significance	O
to	O
deploy	O
HD	O
-	O
CNN	B-Method
in	O
real	B-Task
applications	I-Task
.	O
	
Last	O
but	O
not	O
the	O
least	O
,	O
it	O
can	O
decrease	O
the	O
number	O
of	O
HD	O
-	O
CNN	B-Method
parameters	O
which	O
is	O
critical	O
to	O
the	O
success	O
of	O
HD	O
-	O
CNN	B-Method
training	O
.	O
	
On	O
the	O
right	O
side	O
of	O
Fig	O
[	O
reference	O
]	O
(	O
b	O
)	O
is	O
the	O
probabilistic	B-Method
averaging	I-Method
layer	I-Method
which	O
receives	O
fine	O
category	O
predictions	O
as	O
well	O
as	O
coarse	B-Task
category	O
prediction	O
and	O
produces	O
a	O
weighted	B-Method
average	I-Method
as	O
the	O
final	O
prediction	O
.	O
	
where	O
is	O
the	O
probability	O
of	O
coarse	B-Task
category	O
for	O
the	O
image	O
predicted	O
by	O
the	O
coarse	B-Task
category	O
component	O
.	O
	
is	O
the	O
fine	B-Task
category	I-Task
prediction	I-Task
made	O
by	O
the	O
fine	B-Method
category	I-Method
component	I-Method
.	O
	
We	O
stress	O
that	O
both	O
coarse	B-Task
and	O
fine	O
category	O
components	O
reuse	O
the	O
layer	O
configurations	O
from	O
the	O
building	O
block	O
CNN	B-Method
.	O
	
This	O
flexible	O
modular	O
design	O
allows	O
us	O
to	O
choose	O
the	O
best	O
module	O
CNN	B-Method
as	O
the	O
building	O
block	O
,	O
depending	O
on	O
the	O
task	O
at	O
hand	O
.	O
	
section	O
:	O
Learning	O
a	O
Category	B-Task
Hierarchy	I-Task
	
Our	O
goal	O
of	O
building	O
a	O
category	B-Task
hierarchy	I-Task
is	O
grouping	O
confusing	O
fine	O
categories	O
into	O
the	O
same	O
coarse	B-Task
category	O
for	O
which	O
a	O
dedicated	O
fine	B-Method
category	I-Method
classifier	I-Method
will	O
be	O
trained	O
.	O
	
We	O
employ	O
a	O
top	B-Method
-	I-Method
down	I-Method
approach	I-Method
to	O
learn	O
the	O
hierarchy	O
from	O
the	O
training	O
data	O
.	O
	
We	O
randomly	O
sample	O
a	O
held	O
-	O
out	O
set	O
of	O
images	O
with	O
balanced	O
class	O
distribution	O
from	O
the	O
training	O
set	O
.	O
	
The	O
rest	O
of	O
the	O
training	O
set	O
is	O
used	O
to	O
train	O
a	O
building	B-Method
block	I-Method
net	I-Method
.	O
	
We	O
obtain	O
a	O
confusion	B-Metric
matrix	I-Metric
by	O
evaluating	O
the	O
net	O
on	O
the	O
held	O
-	O
out	O
set	O
.	O
	
A	O
distance	O
matrix	O
is	O
derived	O
as	O
and	O
its	O
diagonal	O
entries	O
are	O
set	O
to	O
be	O
zero	O
.	O
	
is	O
further	O
transformed	O
by	O
to	O
be	O
symmetric	O
.	O
	
The	O
entry	O
measures	O
how	O
easy	O
it	O
is	O
to	O
discriminate	O
categories	O
and	O
.	O
	
Spectral	B-Method
clustering	I-Method
is	O
performed	O
on	O
to	O
cluster	O
fine	O
categories	O
into	O
coarse	B-Task
categories	O
.	O
	
The	O
result	O
is	O
a	O
two	O
-	O
level	O
category	B-Method
hierarchy	I-Method
representing	O
a	O
many	O
-	O
to	O
-	O
one	O
mapping	O
from	O
fine	O
to	O
coarse	B-Task
categories	O
.	O
	
Here	O
,	O
the	O
coarse	B-Task
categories	O
are	O
disjoint	O
.	O
	
Overlapping	O
Coarse	O
Categories	O
With	O
disjoint	O
coarse	B-Task
categories	O
,	O
the	O
overall	O
classification	B-Task
depends	O
heavily	O
on	O
the	O
coarse	B-Task
category	O
classifier	O
.	O
	
If	O
an	O
image	O
is	O
routed	O
to	O
an	O
incorrect	O
fine	B-Method
category	I-Method
classifier	I-Method
,	O
then	O
the	O
mistake	O
can	O
not	O
be	O
corrected	O
as	O
the	O
probability	O
of	O
ground	O
truth	O
label	O
is	O
implicitly	O
set	O
to	O
zero	O
there	O
.	O
	
Removing	O
the	O
separability	O
constraint	O
between	O
coarse	B-Task
categories	O
can	O
make	O
the	O
HD	O
-	O
CNN	B-Method
less	O
dependent	O
on	O
the	O
coarse	B-Task
category	O
classifier	O
.	O
	
Therefore	O
,	O
we	O
add	O
more	O
fine	O
categories	O
to	O
the	O
coarse	B-Task
categories	O
.	O
	
For	O
a	O
certain	O
fine	B-Method
classifier	I-Method
,	O
we	O
prefer	O
to	O
add	O
those	O
fine	O
categories	O
that	O
are	O
likely	O
to	O
be	O
misclassfied	O
into	O
the	O
coarse	B-Task
category	O
.	O
	
Therefore	O
,	O
we	O
estimate	O
the	O
likelihood	O
that	O
an	O
image	O
in	O
fine	O
category	O
is	O
misclassified	O
into	O
a	O
coarse	B-Task
category	O
on	O
the	O
held	O
-	O
out	O
set	O
.	O
	
is	O
the	O
coarse	B-Task
category	O
probability	O
which	O
is	O
obtained	O
by	O
aggregating	O
fine	O
category	O
probabilities	O
according	O
to	O
the	O
mapping	O
:	O
.	O
	
We	O
threshold	O
the	O
likelihood	O
using	O
a	O
parametric	O
variable	O
and	O
add	O
to	O
the	O
partial	O
set	O
all	O
fine	O
categories	O
such	O
that	O
.	O
	
Note	O
that	O
each	O
branching	B-Method
component	I-Method
gives	O
a	O
full	O
set	O
prediction	O
when	O
and	O
a	O
disjoint	O
set	O
prediction	O
when	O
.	O
	
With	O
overlapping	O
coarse	B-Task
categories	O
,	O
the	O
category	B-Method
hierarchy	I-Method
mapping	I-Method
is	O
extended	O
to	O
be	O
a	O
many	O
-	O
to	O
-	O
many	O
mapping	O
and	O
the	O
coarse	B-Task
category	O
predictions	O
are	O
updated	O
accordingly	O
.	O
	
Note	O
the	O
sum	O
of	O
exceeds	O
and	O
hence	O
we	O
perform	O
normalization	B-Method
.	O
	
The	O
use	O
of	O
overlapping	O
coarse	B-Task
categories	O
was	O
also	O
shown	O
to	O
be	O
useful	O
for	O
hierarchical	B-Method
linear	I-Method
classifiers	I-Method
.	O
	
section	O
:	O
HD	O
-	O
CNN	B-Method
Training	O
	
As	O
we	O
embed	O
fine	B-Method
category	I-Method
components	I-Method
into	O
HD	O
-	O
CNN	B-Method
,	O
the	O
number	O
of	O
parameters	O
in	O
rear	O
layers	O
grows	O
linearly	O
in	O
the	O
number	O
of	O
coarse	B-Task
categories	O
.	O
	
Given	O
the	O
same	O
amount	O
of	O
training	O
data	O
,	O
this	O
increases	O
the	O
training	B-Metric
complexity	I-Metric
and	O
the	O
risk	O
of	O
over	B-Task
-	I-Task
fitting	I-Task
.	O
	
On	O
the	O
other	O
hand	O
,	O
the	O
training	O
images	O
within	O
the	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
	
mini	B-Method
-	I-Method
batch	I-Method
are	O
probabilistically	O
routed	O
to	O
different	O
fine	B-Method
category	I-Method
components	I-Method
.	O
	
It	O
requires	O
larger	O
mini	O
-	O
batch	O
to	O
ensure	O
parameter	O
gradients	O
in	O
the	O
fine	O
category	O
components	O
are	O
estimated	O
by	O
a	O
sufficiently	O
large	O
number	O
of	O
training	O
samples	O
.	O
	
Large	O
training	B-Method
mini	I-Method
-	I-Method
batch	I-Method
both	O
increases	O
the	O
training	B-Metric
memory	I-Metric
footprint	I-Metric
and	O
slows	O
down	O
the	O
training	B-Method
process	I-Method
.	O
	
Therefore	O
,	O
we	O
decompose	O
the	O
HD	O
-	O
CNN	B-Method
training	O
into	O
multiple	O
steps	O
instead	O
of	O
training	O
the	O
complete	O
HD	O
-	O
CNN	B-Method
from	O
scratch	O
as	O
outlined	O
in	O
Algorithm	O
[	O
reference	O
]	O
.	O
	
subsection	O
:	O
Pretraining	O
HD	O
-	O
CNN	B-Method
	
We	O
sequentially	O
pretrain	O
the	O
coarse	B-Task
category	O
component	O
and	O
fine	B-Method
category	I-Method
components	I-Method
.	O
	
subsubsection	B-Method
:	O
Initializing	O
the	O
Coarse	B-Method
Category	I-Method
Component	I-Method
	
We	O
first	O
pretrain	O
a	O
building	O
block	O
CNN	B-Method
using	O
the	O
training	O
set	O
.	O
	
As	O
both	O
the	O
preceding	O
and	O
rear	O
layers	O
in	O
coarse	B-Task
category	O
component	O
resemble	O
the	O
layers	O
in	O
the	O
building	O
block	O
CNN	B-Method
,	O
we	O
copy	O
the	O
weights	O
of	O
into	O
coarse	B-Task
category	O
component	O
for	O
initialization	B-Task
purpose	I-Task
.	O
	
subsubsection	B-Method
:	O
Pretraining	O
the	O
Rear	B-Method
Layers	I-Method
of	I-Method
Fine	I-Method
Category	I-Method
Components	I-Method
	
Fine	B-Method
category	I-Method
components	I-Method
can	O
be	O
independently	O
pretrained	O
in	O
parallel	O
.	O
	
Each	O
should	O
specialize	O
in	O
classifying	O
fine	O
categories	O
within	O
the	O
coarse	B-Task
category	O
.	O
	
Therefore	O
,	O
the	O
pretraining	O
of	O
each	O
only	O
uses	O
images	O
from	O
the	O
coarse	B-Task
category	O
.	O
	
The	O
shared	O
preceding	O
layers	O
are	O
already	O
initialized	O
and	O
kept	O
fixed	O
in	O
this	O
stage	O
.	O
	
For	O
each	O
,	O
we	O
initialize	O
all	O
the	O
rear	O
layers	O
except	O
the	O
last	O
convolutional	O
layer	O
by	O
copying	O
the	O
learned	O
parameters	O
from	O
the	O
pretrained	B-Method
model	I-Method
.	O
	
[	O
!	O
t	O
]	O
HD	O
-	O
CNN	B-Method
training	O
algorithm	O
[	O
1	O
]	O
HD	O
-	O
CNN	B-Method
Training	O
Step	O
1	O
:	O
Pretrain	O
HD	O
-	O
CNN	B-Method
Step	O
1.1	O
:	O
	
Initialize	O
coarse	B-Task
category	O
component	O
Step	O
1.2	O
:	O
Pretrain	O
fine	B-Method
category	I-Method
components	I-Method
Step	O
2	O
:	O
	
Fine	O
-	O
tune	O
the	O
complete	O
HD	O
-	O
CNN	B-Method
	
subsection	O
:	O
Fine	O
-	O
tuning	O
HD	O
-	O
CNN	B-Method
	
After	O
both	O
coarse	B-Task
category	O
component	O
and	O
fine	B-Method
category	I-Method
components	I-Method
are	O
properly	O
pretrained	O
,	O
we	O
fine	O
-	O
tune	O
the	O
complete	O
HD	O
-	O
CNN	B-Method
.	O
	
Once	O
the	O
category	O
hierarchy	O
as	O
well	O
as	O
the	O
associated	O
mapping	O
is	O
learnt	O
,	O
each	O
fine	B-Method
category	I-Method
component	I-Method
focuses	O
on	O
classifying	O
a	O
fixed	O
subset	O
of	O
fine	O
categories	O
.	O
	
During	O
fine	B-Task
-	I-Task
tuning	I-Task
,	O
the	O
semantics	O
of	O
coarse	B-Task
categories	O
predicted	O
by	O
the	O
coarse	B-Task
category	O
component	O
should	O
be	O
kept	O
consistent	O
with	O
those	O
associated	O
with	O
fine	B-Method
category	I-Method
components	I-Method
.	O
	
Thus	O
we	O
add	O
a	O
coarse	B-Task
category	O
consistency	O
term	O
to	O
regularize	O
the	O
conventional	O
multinomial	B-Method
logistic	I-Method
loss	I-Method
.	O
	
Coarse	B-Metric
category	I-Metric
consistency	I-Metric
	
The	O
learnt	O
fine	O
-	O
to	O
-	O
coarse	B-Task
category	O
mapping	O
provides	O
a	O
way	O
to	O
specify	O
the	O
target	O
coarse	B-Task
category	O
distribution	O
.	O
	
Specifically	O
,	O
is	O
set	O
to	O
be	O
the	O
fraction	O
of	O
all	O
the	O
training	O
images	O
within	O
the	O
coarse	B-Task
category	O
under	O
the	O
assumption	O
the	O
distribution	O
over	O
coarse	B-Task
categories	O
across	O
the	O
training	O
dataset	O
is	O
close	O
to	O
that	O
within	O
a	O
training	O
mini	O
-	O
batch	O
.	O
	
The	O
final	O
loss	B-Metric
function	I-Metric
we	O
use	O
for	O
fine	O
-	O
tuning	O
the	O
HD	O
-	O
CNN	B-Method
is	O
shown	O
below	O
.	O
	
where	O
is	O
the	O
size	O
of	O
training	O
mini	O
-	O
batch	O
.	O
	
is	O
a	O
regularization	O
constant	O
and	O
is	O
set	O
to	O
.	O
	
section	O
:	O
HD	O
-	O
CNN	B-Method
Testing	O
	
As	O
we	O
add	O
fine	B-Method
category	I-Method
components	I-Method
into	O
the	O
HD	O
-	O
CNN	B-Method
,	O
the	O
number	O
of	O
parameters	O
,	O
memory	B-Metric
footprint	I-Metric
and	O
execution	B-Metric
time	I-Metric
in	O
rear	O
layers	O
,	O
all	O
scale	O
linearly	O
in	O
the	O
number	O
of	O
coarse	B-Task
categories	O
.	O
	
To	O
ensure	O
HD	O
-	O
CNN	B-Method
is	O
scalable	O
for	O
large	B-Task
-	I-Task
scale	I-Task
visual	I-Task
recognition	I-Task
,	O
we	O
develop	O
conditional	B-Method
execution	I-Method
and	I-Method
layer	I-Method
parameter	I-Method
compression	I-Method
techniques	I-Method
.	O
	
Conditional	B-Task
Execution	I-Task
.	O
	
At	O
test	O
time	O
,	O
for	O
a	O
given	O
image	O
,	O
it	O
is	O
not	O
necessary	O
to	O
evaluate	O
all	O
fine	B-Method
category	I-Method
classifiers	I-Method
as	O
most	O
of	O
them	O
have	O
insignificant	O
weights	O
as	O
in	O
Eqn	O
[	O
reference	O
]	O
.	O
	
Their	O
contributions	O
to	O
the	O
final	O
prediction	B-Task
are	O
negligible	O
.	O
	
Conditional	O
executions	O
of	O
the	O
top	O
weighted	B-Method
fine	I-Method
components	I-Method
can	O
accelerate	O
the	O
HD	B-Task
-	I-Task
CNN	I-Task
classification	I-Task
.	O
	
Therefore	O
,	O
we	O
threshold	O
using	O
a	O
parametric	O
variable	O
and	O
reset	O
to	O
zero	O
when	O
.	O
	
Those	O
fine	B-Method
category	I-Method
classifiers	I-Method
with	O
are	O
not	O
evaluated	O
.	O
	
Parameter	B-Method
Compression	I-Method
.	O
	
In	O
HD	O
-	O
CNN	B-Method
,	O
the	O
number	O
of	O
parameters	O
in	O
rear	O
layers	O
of	O
fine	B-Method
category	I-Method
classifiers	I-Method
grows	O
linearly	O
in	O
the	O
number	O
of	O
coarse	B-Task
categories	O
.	O
	
Thus	O
we	O
compress	O
the	O
layer	O
parameters	O
at	O
test	O
time	O
to	O
reduce	O
memory	O
footprint	O
.	O
	
Specifically	O
,	O
we	O
choose	O
the	O
Product	B-Method
Quantization	I-Method
approach	I-Method
to	O
compress	O
the	O
parameter	O
matrix	O
by	O
first	O
partitioning	O
it	O
horizontally	O
into	O
segments	O
of	O
width	O
.	O
.	O
	
Then	O
-	B-Method
means	I-Method
clustering	I-Method
is	O
used	O
to	O
cluster	O
the	O
rows	O
in	O
.	O
	
By	O
only	O
storing	O
the	O
nearest	O
cluster	O
indices	O
in	O
a	O
8	O
-	O
bit	O
integer	O
matrix	O
and	O
cluster	O
centers	O
in	O
a	O
single	O
-	O
precision	O
floating	O
number	O
matrix	O
,	O
we	O
can	O
achieve	O
a	O
compression	B-Metric
factor	I-Metric
.	O
	
The	O
hyperparameters	O
for	O
parameter	B-Task
compression	I-Task
are	O
.	O
	
section	O
:	O
Experiments	O
	
subsection	O
:	O
Overview	O
	
We	O
evaluate	O
HD	O
-	O
CNN	B-Method
on	O
the	O
benchmark	O
datasets	O
CIFAR100	B-Material
and	O
ImageNet	O
.	O
	
HD	O
-	O
CNN	B-Method
is	O
implemented	O
on	O
the	O
widely	O
deployed	O
Caffe	B-Method
software	I-Method
.	O
	
The	O
network	O
is	O
trained	O
by	O
back	B-Method
propagation	I-Method
.	O
	
We	O
run	O
all	O
the	O
testing	O
experiments	O
on	O
a	O
single	O
NVIDIA	O
Tesla	O
K40c	O
card	O
.	O
	
subsection	O
:	O
CIFAR100	B-Material
Dataset	O
	
The	O
CIFAR100	B-Material
dataset	O
consists	O
of	O
100	O
classes	O
of	O
natural	O
images	O
.	O
	
There	O
are	O
50	O
K	O
training	O
images	O
and	O
10	O
K	O
testing	O
images	O
.	O
	
We	O
follow	O
to	O
preprocess	O
the	O
datasets	O
(	O
e.g.	O
global	O
contrast	O
normalization	O
and	O
ZCA	B-Method
whitening	I-Method
)	O
.	O
	
Randomly	O
cropped	O
and	O
flipped	O
image	O
patches	O
of	O
size	O
are	O
used	O
for	O
training	O
.	O
	
We	O
adopt	O
a	O
NIN	B-Method
network	I-Method
with	O
three	O
stacked	B-Method
layers	I-Method
.	O
	
We	O
denote	O
it	O
as	O
CIFAR100	B-Material
-	O
NIN	O
which	O
will	O
be	O
the	O
HD	O
-	O
CNN	B-Method
building	O
block	O
.	O
	
Fine	B-Method
category	I-Method
components	I-Method
share	O
preceding	O
layers	O
from	O
conv1	B-Method
to	O
pool1	O
which	O
accounts	O
for	O
of	O
the	O
total	O
parameters	O
and	O
of	O
the	O
total	O
floating	O
point	O
operations	O
.	O
	
The	O
remaining	O
layers	O
are	O
used	O
as	O
independent	O
layers	O
.	O
	
For	O
building	O
the	O
category	B-Task
hierarchy	I-Task
,	O
we	O
randomly	O
choose	O
10	O
K	O
images	O
from	O
the	O
training	O
set	O
as	O
held	O
-	O
out	O
set	O
.	O
	
Fine	O
categories	O
within	O
the	O
same	O
coarse	B-Task
categories	O
are	O
visually	O
more	O
similar	O
.	O
	
We	O
pretrain	O
the	O
rear	B-Method
layers	I-Method
of	I-Method
fine	I-Method
category	I-Method
components	I-Method
.	O
	
The	O
initial	O
learning	B-Metric
rate	I-Metric
is	O
and	O
it	O
is	O
decreased	O
by	O
a	O
factor	O
of	O
10	O
every	O
6	O
K	O
iterations	O
.	O
	
Fine	B-Task
-	I-Task
tuning	I-Task
is	O
performed	O
for	O
20	O
K	O
iterations	O
with	O
large	O
mini	O
-	O
batches	O
of	O
size	O
256	O
.	O
	
The	O
initial	O
learning	B-Metric
rate	I-Metric
is	O
and	O
is	O
reduced	O
by	O
a	O
factor	O
of	O
10	O
once	O
after	O
10	O
K	O
iterations	O
.	O
	
For	O
evaluation	O
,	O
we	O
use	O
10	B-Task
-	I-Task
view	I-Task
testing	I-Task
.	O
	
We	O
extract	O
five	O
patches	O
(	O
the	O
4	O
corner	O
patches	O
and	O
the	O
center	O
patch	O
)	O
as	O
well	O
as	O
their	O
horizontal	O
reflections	O
and	O
average	O
their	O
predictions	O
.	O
	
The	O
CIFAR100	B-Material
-	O
NIN	O
net	O
obtains	O
testing	B-Metric
error	I-Metric
.	O
	
Our	O
HD	O
-	O
CNN	B-Method
achieves	O
testing	B-Metric
error	I-Metric
of	O
which	O
improves	O
the	O
building	B-Method
block	I-Method
net	I-Method
by	O
.	O
	
Category	O
hierarchy	O
.	O
	
During	O
the	O
construction	O
of	O
the	O
category	O
hierarchy	O
,	O
the	O
number	O
of	O
coarse	B-Task
categories	O
can	O
be	O
adjusted	O
by	O
the	O
clustering	B-Method
algorithm	I-Method
.	O
	
We	O
can	O
also	O
make	O
the	O
coarse	B-Task
categories	O
either	O
disjoint	O
or	O
overlapping	O
by	O
varying	O
the	O
hyperparameter	O
.	O
	
Thus	O
we	O
investigate	O
their	O
impacts	O
on	O
the	O
classification	B-Metric
error	I-Metric
.	O
	
We	O
experiment	O
with	O
5	O
,	O
9	O
,	O
14	O
and	O
19	O
coarse	B-Task
categories	O
and	O
vary	O
the	O
value	O
of	O
.	O
	
The	O
best	O
results	O
are	O
obtained	O
with	O
9	O
overlapping	O
coarse	B-Task
categories	O
and	O
as	O
shown	O
in	O
Fig	O
[	O
reference	O
]	O
left	O
.	O
	
A	O
histogram	O
of	O
fine	O
category	O
occurrences	O
in	O
9	O
overlapping	O
coarse	B-Task
categories	O
is	O
shown	O
in	O
Fig	O
[	O
reference	O
]	O
right	O
.	O
	
The	O
optimal	O
value	O
of	O
coarse	B-Task
category	O
number	O
and	O
hyperparameter	O
are	O
dataset	O
dependent	O
,	O
mainly	O
affected	O
by	O
the	O
inherent	O
hierarchy	O
within	O
the	O
categories	O
.	O
	
.30	O
	
.18	O
	
Shared	O
layers	O
.	O
	
The	O
use	O
of	O
shared	O
layers	O
makes	O
both	O
computational	B-Metric
complexity	I-Metric
and	O
memory	B-Metric
footprint	I-Metric
of	O
HD	O
-	O
CNN	B-Method
sublinear	O
in	O
the	O
number	O
of	O
fine	B-Method
category	I-Method
classifiers	I-Method
when	O
compared	O
to	O
the	O
building	B-Method
block	I-Method
net	I-Method
.	O
	
Our	O
HD	O
-	O
CNN	B-Method
with	O
9	O
fine	B-Method
category	I-Method
classifiers	I-Method
based	O
on	O
CIFAR100	B-Material
-	O
NIN	O
consumes	O
	
less	O
than	O
three	O
times	O
as	O
much	O
memory	O
as	O
the	O
building	B-Method
block	I-Method
net	I-Method
without	O
parameter	B-Method
compression	I-Method
.	O
	
We	O
also	O
want	O
to	O
investigate	O
the	O
impact	O
of	O
the	O
use	O
of	O
shared	O
layers	O
on	O
the	O
classification	B-Metric
error	I-Metric
,	O
memory	B-Metric
footprint	I-Metric
and	O
the	O
net	B-Metric
execution	I-Metric
time	I-Metric
(	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
We	O
build	O
another	O
HD	O
-	O
CNN	B-Method
where	O
coarse	B-Task
category	O
component	O
and	O
all	O
fine	B-Method
category	I-Method
components	I-Method
use	O
independent	O
preceding	B-Method
layers	I-Method
initialized	O
from	O
a	O
pretrained	B-Method
building	I-Method
block	I-Method
net	I-Method
.	O
	
Under	O
the	O
single	B-Task
-	I-Task
view	I-Task
testing	I-Task
where	O
only	O
a	O
central	O
cropping	O
is	O
used	O
,	O
we	O
observe	O
a	O
minor	O
error	O
increase	O
from	O
to	O
.	O
	
But	O
using	O
shared	O
layers	O
dramatically	O
reduces	O
the	O
memory	B-Metric
footprint	I-Metric
from	O
MB	O
to	O
MB	O
and	O
testing	B-Metric
time	I-Metric
from	O
seconds	O
to	O
seconds	O
.	O
	
Conditional	O
executions	O
.	O
	
By	O
varying	O
the	O
hyperparameter	O
,	O
we	O
can	O
effectively	O
affect	O
the	O
number	O
of	O
fine	O
category	O
components	O
that	O
will	O
be	O
executed	O
.	O
	
There	O
is	O
a	O
trade	O
-	O
off	O
between	O
execution	B-Metric
time	I-Metric
and	O
classification	B-Metric
error	I-Metric
.	O
	
A	O
larger	O
value	O
of	O
leads	O
to	O
higher	O
accuracy	B-Metric
at	O
the	O
cost	O
of	O
executing	O
more	O
components	O
for	O
fine	B-Task
categorization	I-Task
.	O
	
By	O
enabling	O
conditional	O
executions	O
with	O
hyperparameter	B-Method
,	O
we	O
obtain	O
a	O
substantial	O
X	B-Metric
speed	I-Metric
up	I-Metric
with	O
merely	O
a	O
minor	O
increase	O
in	O
error	B-Metric
from	O
to	O
(	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
The	O
testing	B-Metric
time	I-Metric
of	O
HD	O
-	O
CNN	B-Method
is	O
about	O
times	O
as	O
much	O
as	O
that	O
of	O
the	O
building	B-Method
block	I-Method
net	I-Method
.	O
	
Parameter	B-Method
compression	I-Method
.	O
	
As	O
fine	O
category	O
CNNs	B-Method
have	O
independent	O
layers	O
from	O
conv2	O
to	O
cccp6	B-Method
,	O
we	O
compress	O
them	O
and	O
reduce	O
the	O
memory	O
footprint	O
from	O
MB	O
to	O
MB	O
with	O
a	O
minor	O
increase	O
in	O
error	B-Metric
from	O
to	O
.	O
	
Comparison	O
with	O
a	O
strong	O
baseline	O
.	O
	
As	O
our	O
HD	O
-	O
CNN	B-Method
memory	O
footprint	O
is	O
about	O
two	O
times	O
as	O
much	O
as	O
the	O
building	B-Method
block	I-Method
model	I-Method
(	O
Table	O
[	O
reference	O
]	O
)	O
,	O
it	O
is	O
necessary	O
to	O
compare	O
a	O
stronger	O
baseline	O
of	O
similar	O
complexity	B-Metric
with	O
HD	O
-	O
CNN	B-Method
.	O
	
We	O
adapt	O
CIFAR100	B-Material
-	O
NIN	O
and	O
double	O
the	O
number	O
of	O
filters	O
in	O
all	O
convolutional	B-Method
layers	I-Method
which	O
accordingly	O
increases	O
the	O
memory	B-Metric
footprint	I-Metric
by	O
three	O
times	O
.	O
	
We	O
denote	O
it	O
as	O
CIFAR100	B-Method
-	I-Method
NIN	I-Method
-	I-Method
double	I-Method
and	O
obtain	O
error	B-Metric
which	O
is	O
lower	O
than	O
that	O
of	O
the	O
building	B-Method
block	I-Method
net	I-Method
but	O
is	O
higher	O
than	O
that	O
of	O
HD	O
-	O
CNN	B-Method
.	O
	
Comparison	O
with	O
model	B-Method
averaging	I-Method
.	O
	
HD	O
-	O
CNN	B-Method
is	O
fundamentally	O
different	O
from	O
model	B-Method
averaging	I-Method
.	O
	
In	O
model	B-Method
averaging	I-Method
,	O
all	O
models	O
are	O
capable	O
of	O
classifying	O
the	O
full	O
set	O
of	O
the	O
categories	O
and	O
each	O
one	O
is	O
trained	O
independently	O
.	O
	
The	O
main	O
sources	O
of	O
their	O
prediction	O
differences	O
are	O
different	O
initializations	O
.	O
	
In	O
HD	O
-	O
CNN	B-Method
,	O
each	O
fine	B-Method
category	I-Method
classifier	I-Method
only	O
excels	O
at	O
classifying	O
a	O
partial	O
set	O
of	O
categories	O
.	O
	
To	O
compare	O
HD	O
-	O
CNN	B-Method
with	O
model	B-Method
averaging	I-Method
,	O
we	O
independently	O
train	O
two	O
CIFAR100	B-Material
-	O
NIN	O
networks	O
and	O
take	O
their	O
averaged	O
prediction	O
as	O
the	O
final	O
prediction	O
.	O
	
We	O
obtain	O
an	O
error	B-Metric
of	O
,	O
which	O
is	O
about	O
higher	O
than	O
that	O
of	O
HD	O
-	O
CNN	B-Method
(	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
Note	O
that	O
HD	O
-	O
CNN	B-Method
is	O
orthogonal	O
to	O
the	O
model	B-Method
averaging	I-Method
and	O
an	O
ensemble	O
of	O
HD	O
-	O
CNN	B-Method
networks	O
can	O
further	O
improve	O
the	O
performance	O
.	O
	
Coarse	B-Metric
category	I-Metric
consistency	I-Metric
.	O
	
To	O
verify	O
the	O
effectiveness	O
of	O
coarse	B-Task
category	O
consistency	O
term	O
in	O
our	O
loss	B-Method
function	I-Method
(	O
[	O
reference	O
]	O
)	O
,	O
we	O
fine	O
-	O
tune	O
a	O
HD	O
-	O
CNN	B-Method
using	O
the	O
traditional	O
multinomial	B-Method
logistic	I-Method
loss	I-Method
function	I-Method
.	O
	
The	O
testing	B-Metric
error	I-Metric
is	O
,	O
which	O
is	O
higher	O
than	O
that	O
of	O
a	O
HD	O
-	O
CNN	B-Method
fine	O
-	O
tuned	O
with	O
coarse	B-Task
category	O
consistency	O
(	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
Comparison	O
with	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
.	O
	
Our	O
HD	O
-	O
CNN	B-Method
improves	O
on	O
the	O
current	O
two	O
best	O
methods	O
and	O
by	O
and	O
respectively	O
and	O
sets	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
CIFAR100	B-Material
(	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
subsection	O
:	O
ImageNet	O
1000	O
-	O
class	O
Dataset	O
	
The	O
ILSVRC	O
-	O
2012	O
ImageNet	O
dataset	O
consists	O
of	O
about	O
million	O
training	O
images	O
,	O
validation	O
images	O
.	O
	
To	O
demonstrate	O
the	O
generality	O
of	O
HD	O
-	O
CNN	B-Method
,	O
we	O
experiment	O
with	O
two	O
different	O
building	B-Method
block	I-Method
nets	I-Method
.	O
	
In	O
both	O
cases	O
,	O
HD	B-Method
-	I-Method
CNNs	I-Method
achieve	O
significantly	O
lower	O
testing	B-Metric
errors	I-Metric
than	O
the	O
building	B-Method
block	I-Method
nets	I-Method
.	O
	
subsubsection	O
:	O
Network	B-Method
-	I-Method
In	I-Method
-	I-Method
Network	I-Method
Building	I-Method
Block	I-Method
Net	I-Method
	
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
	
(	O
d	O
)	O
(	O
e	O
)	O
(	O
f	O
)	O
(	O
g	O
)	O
We	O
choose	O
a	O
public	B-Method
4	I-Method
-	I-Method
layer	I-Method
NIN	I-Method
net	I-Method
as	O
our	O
first	O
building	O
block	O
as	O
it	O
has	O
greatly	O
reduced	O
number	O
of	O
parameters	O
compared	O
to	O
AlexNet	B-Method
but	O
similar	O
error	B-Metric
rates	I-Metric
.	O
	
It	O
is	O
denoted	O
as	O
ImageNet	B-Method
-	I-Method
NIN	I-Method
.	O
	
In	O
HD	O
-	O
CNN	B-Method
,	O
various	O
components	O
share	O
preceding	B-Method
layers	I-Method
from	O
conv1	O
to	O
pool3	O
which	O
account	O
for	O
of	O
the	O
total	O
parameters	O
and	O
of	O
the	O
total	O
floating	O
point	O
operations	O
.	O
	
We	O
follow	O
the	O
training	O
and	O
testing	O
protocols	O
as	O
in	O
.	O
	
Original	O
images	O
are	O
resized	O
to	O
.	O
	
Randomly	O
cropped	O
and	O
horizontally	O
reflected	O
patches	O
are	O
used	O
for	O
training	O
.	O
	
At	O
test	O
time	O
,	O
the	O
net	O
makes	O
a	O
10	B-Method
-	I-Method
view	I-Method
averaged	I-Method
prediction	I-Method
.	O
	
We	O
train	O
ImageNet	B-Method
-	I-Method
NIN	I-Method
for	O
45	O
epochs	O
.	O
	
The	O
top	B-Metric
-	I-Metric
1	I-Metric
and	O
top	B-Metric
-	I-Metric
5	I-Metric
errors	I-Metric
are	O
and	O
.	O
	
To	O
build	O
the	O
category	O
hierarchy	O
,	O
we	O
take	O
100	O
K	O
training	O
images	O
as	O
the	O
held	O
-	O
out	O
set	O
and	O
find	O
89	O
overlapping	O
coarse	B-Task
categories	O
.	O
	
Each	O
fine	O
category	O
CNN	B-Method
is	O
fine	O
-	O
tuned	O
for	O
40	O
K	O
iterations	O
while	O
the	O
initial	O
learning	B-Metric
rate	I-Metric
is	O
decreased	O
by	O
a	O
factor	O
of	O
every	O
15	O
K	O
iterations	O
.	O
	
Fine	B-Task
-	I-Task
tuning	I-Task
the	O
complete	O
HD	O
-	O
CNN	B-Method
is	O
not	O
performed	O
as	O
the	O
required	O
mini	O
-	O
batch	O
size	O
is	O
significantly	O
higher	O
than	O
that	O
for	O
the	O
building	B-Method
block	I-Method
net	I-Method
.	O
	
Nevertheless	O
,	O
we	O
still	O
achieve	O
top	B-Metric
-	I-Metric
1	I-Metric
and	O
top	B-Metric
-	I-Metric
5	I-Metric
errors	I-Metric
of	O
and	O
and	O
improve	O
the	O
building	O
block	O
net	O
by	O
and	O
,	O
respectively	O
(	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
The	O
class	B-Metric
-	I-Metric
wise	I-Metric
top	I-Metric
-	I-Metric
5	I-Metric
error	I-Metric
improvement	I-Metric
over	O
the	O
building	B-Method
block	I-Method
net	I-Method
is	O
shown	O
in	O
Fig	O
[	O
reference	O
]	O
left	O
.	O
	
Case	O
studies	O
We	O
want	O
to	O
investigate	O
how	O
HD	O
-	O
CNN	B-Method
corrects	O
the	O
mistakes	O
made	O
by	O
the	O
building	B-Method
block	I-Method
net	I-Method
.	O
	
In	O
Fig	O
[	O
reference	O
]	O
,	O
we	O
collect	O
four	O
testing	O
cases	O
.	O
	
In	O
the	O
first	O
case	O
,	O
the	O
building	B-Method
block	I-Method
net	I-Method
fails	O
to	O
predict	O
the	O
label	O
of	O
the	O
tiny	O
hermit	O
crab	O
in	O
the	O
top	O
5	O
guesses	O
.	O
	
In	O
HD	O
-	O
CNN	B-Method
,	O
two	O
coarse	B-Task
categories	O
and	O
receive	O
most	O
of	O
the	O
coarse	B-Task
probability	O
mass	O
.	O
	
The	O
fine	B-Method
category	I-Method
component	I-Method
specializes	O
in	O
classifying	B-Task
crab	I-Task
breeds	I-Task
and	O
strongly	O
suggests	O
the	O
ground	O
truth	O
label	O
.	O
	
By	O
combining	O
the	O
predictions	O
from	O
the	O
top	O
fine	B-Method
category	I-Method
classifiers	I-Method
,	O
the	O
HD	O
-	O
CNN	B-Method
predicts	O
hermit	O
crab	O
as	O
the	O
most	O
probable	O
label	O
.	O
	
In	O
the	O
second	O
case	O
,	O
the	O
ImageNet	B-Method
-	I-Method
NIN	I-Method
confuses	O
the	O
ground	O
truth	O
hand	O
blower	O
with	O
other	O
objects	O
of	O
close	O
shapes	O
and	O
appearances	O
,	O
such	O
as	O
plunger	O
and	O
barbell	O
.	O
	
For	O
HD	O
-	O
CNN	B-Method
,	O
the	O
coarse	B-Task
category	O
component	O
is	O
also	O
not	O
confident	O
about	O
which	O
coarse	B-Task
category	O
the	O
object	O
belongs	O
to	O
and	O
thus	O
assigns	O
even	O
probability	O
mass	O
to	O
the	O
top	O
coarse	B-Task
categories	O
.	O
	
For	O
the	O
top	O
3	O
fine	B-Method
category	I-Method
classifiers	I-Method
,	O
strongly	O
predicts	O
ground	O
truth	O
label	O
while	O
the	O
other	O
two	O
and	O
rank	O
the	O
ground	O
truth	O
label	O
at	O
the	O
2nd	O
and	O
4th	O
place	O
respectively	O
.	O
	
Overall	O
,	O
the	O
HD	O
-	O
CNN	B-Method
ranks	O
the	O
ground	O
truth	O
label	O
at	O
the	O
1st	O
place	O
.	O
	
This	O
demonstrates	O
HD	O
-	O
CNN	B-Method
needs	O
to	O
rely	O
on	O
multiple	O
fine	B-Method
category	I-Method
classifiers	I-Method
to	O
make	O
correct	O
predictions	O
for	O
difficult	O
cases	O
.	O
	
Overlapping	O
coarse	B-Task
categories	O
.To	O
investigate	O
the	O
impact	O
of	O
overlapping	O
coarse	B-Task
categories	O
on	O
the	O
classification	B-Task
,	O
we	O
train	O
another	O
HD	O
-	O
CNN	B-Method
with	O
89	O
fine	B-Method
category	I-Method
classifiers	I-Method
using	O
disjoint	O
coarse	B-Task
categories	O
.	O
	
It	O
achieves	O
top	B-Metric
-	I-Metric
1	I-Metric
and	O
top	B-Metric
-	I-Metric
5	I-Metric
errors	I-Metric
of	O
and	O
respectively	O
,	O
which	O
is	O
higher	O
than	O
those	O
of	O
the	O
HD	O
-	O
CNN	B-Method
using	O
overlapping	O
coarse	B-Task
category	O
hierarchy	O
by	O
and	O
(	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
Conditional	O
executions	O
.	O
	
By	O
varying	O
the	O
hyperparameter	O
,	O
we	O
can	O
control	O
the	O
number	O
of	O
fine	O
category	O
components	O
that	O
will	O
be	O
executed	O
.	O
	
There	O
is	O
a	O
trade	O
-	O
off	O
between	O
execution	B-Metric
time	I-Metric
and	O
classification	B-Metric
error	I-Metric
as	O
shown	O
in	O
Fig	O
[	O
reference	O
]	O
right	O
.	O
	
A	O
larger	O
value	O
of	O
leads	O
to	O
lower	O
error	B-Metric
at	O
the	O
cost	O
of	O
more	O
executed	O
fine	B-Method
category	I-Method
components	I-Method
.	O
	
By	O
enabling	O
conditional	O
executions	O
with	O
hyperparameter	B-Method
,	O
we	O
obtain	O
a	O
substantial	O
X	B-Metric
speed	I-Metric
up	I-Metric
with	O
merely	O
a	O
minor	O
increase	O
of	O
single	O
-	O
view	B-Metric
testing	I-Metric
top	I-Metric
-	I-Metric
5	I-Metric
error	I-Metric
from	O
to	O
(	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
With	O
such	O
speedup	O
,	O
the	O
HD	O
-	O
CNN	B-Method
testing	O
time	O
is	O
less	O
than	O
times	O
as	O
much	O
as	O
that	O
of	O
the	O
building	B-Method
block	I-Method
net	I-Method
.	O
	
Parameter	B-Method
compression	I-Method
.	O
	
We	O
compress	O
independent	B-Method
layers	I-Method
conv4	I-Method
and	O
cccp7	B-Method
as	O
they	O
account	O
for	O
of	O
the	O
parameters	O
in	O
ImageNet	B-Method
-	I-Method
NIN	I-Method
.	O
	
Their	O
parameter	O
matrices	O
are	O
of	O
size	O
and	O
and	O
we	O
use	O
compression	O
hyperparameters	O
and	O
.	O
	
The	O
compression	B-Metric
factors	I-Metric
are	O
and	O
.	O
	
The	O
compression	B-Method
decreases	O
the	O
memory	B-Metric
footprint	I-Metric
from	O
MB	O
to	O
MB	O
and	O
merely	O
increases	O
the	O
top	B-Metric
-	I-Metric
5	I-Metric
error	I-Metric
from	O
to	O
under	O
single	O
-	O
view	O
testing	O
(	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
.23	O
	
.27	O
Comparison	O
with	O
model	B-Method
averaging	I-Method
.	O
	
As	O
the	O
HD	O
-	O
CNN	B-Method
memory	O
footprint	O
is	O
about	O
three	O
times	O
as	O
much	O
as	O
the	O
building	B-Method
block	I-Method
net	I-Method
,	O
we	O
independently	O
train	O
three	O
ImageNet	B-Method
-	I-Method
NIN	I-Method
nets	O
and	O
average	O
their	O
predictions	O
.	O
	
We	O
obtain	O
top	B-Metric
-	I-Metric
5	I-Metric
error	I-Metric
which	O
is	O
lower	O
than	O
the	O
building	B-Method
block	I-Method
but	O
is	O
higher	O
than	O
that	O
of	O
HD	O
-	O
CNN	B-Method
(	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
subsubsection	O
:	O
VGG	B-Method
-	I-Method
16	I-Method
-	I-Method
layer	I-Method
Building	I-Method
Block	I-Method
Net	I-Method
	
The	O
second	O
building	B-Method
block	I-Method
net	I-Method
we	O
use	O
is	O
a	O
16	O
-	O
layer	O
CNN	B-Method
from	O
.	O
	
We	O
denote	O
it	O
as	O
ImageNet	B-Method
-	I-Method
VGG	I-Method
-	I-Method
16	I-Method
-	I-Method
layer	I-Method
.	O
	
The	O
layers	O
from	O
conv1_1	O
to	O
pool4	O
are	O
shared	O
and	O
they	O
account	O
for	O
of	O
the	O
total	O
parameters	O
and	O
of	O
the	O
total	O
floating	O
number	O
operations	O
.	O
	
The	O
remaining	O
layers	O
are	O
used	O
as	O
independent	O
layers	O
in	O
coarse	B-Task
and	O
fine	O
category	O
classifiers	O
.	O
	
We	O
follow	O
the	O
training	O
and	O
testing	O
protocols	O
as	O
in	O
.	O
	
For	O
training	O
,	O
we	O
first	O
sample	O
a	O
size	O
from	O
the	O
range	O
and	O
resize	O
the	O
image	O
so	O
that	O
the	O
length	O
of	O
short	O
edge	O
is	O
.	O
	
Then	O
a	O
randomly	O
cropped	O
and	O
flipped	O
patch	O
of	O
size	O
is	O
used	O
for	O
training	O
.	O
	
For	O
testing	O
,	O
dense	B-Task
evaluation	I-Task
is	O
performed	O
on	O
three	O
scales	O
and	O
the	O
averaged	B-Method
prediction	I-Method
is	O
used	O
as	O
the	O
final	O
prediction	O
.	O
	
Please	O
refer	O
to	O
for	O
more	O
training	O
and	O
testing	O
details	O
.	O
	
On	O
ImageNet	O
validation	O
set	O
,	O
ImageNet	B-Method
-	I-Method
VGG	I-Method
-	I-Method
16	I-Method
-	I-Method
layer	I-Method
achieves	O
top	B-Metric
-	I-Metric
1	I-Metric
and	O
top	B-Metric
-	I-Metric
5	I-Metric
errors	I-Metric
and	O
respectively	O
.	O
	
We	O
build	O
a	O
category	O
hierarchy	O
with	O
84	O
overlapping	O
coarse	B-Task
categories	O
.	O
	
We	O
implement	O
multi	B-Method
-	I-Method
GPU	I-Method
training	I-Method
on	O
Caffe	B-Method
by	O
exploiting	O
data	O
parallelism	O
and	O
train	O
the	O
fine	B-Method
category	I-Method
classifiers	I-Method
on	O
two	O
NVIDIA	B-Method
Tesla	I-Method
K40c	I-Method
cards	I-Method
.	O
	
The	O
initial	O
learning	B-Metric
rate	I-Metric
is	O
and	O
it	O
is	O
decreased	O
by	O
a	O
factor	O
of	O
10	O
every	O
4	O
K	O
iterations	O
.	O
	
HD	O
-	O
CNN	B-Method
fine	O
-	O
tuning	O
is	O
not	O
performed	O
.	O
	
Due	O
to	O
large	O
memory	O
footprint	O
of	O
the	O
building	B-Method
block	I-Method
net	I-Method
(	O
Table	O
[	O
reference	O
]	O
)	O
,	O
the	O
HD	O
-	O
CNN	B-Method
with	O
84	O
fine	B-Method
category	I-Method
classifiers	I-Method
can	O
not	O
fit	O
into	O
the	O
memory	O
directly	O
.	O
	
Therefore	O
,	O
we	O
compress	O
the	O
parameters	O
in	O
layers	B-Method
fc6	I-Method
and	O
fc7	B-Method
as	O
they	O
account	O
for	O
over	O
of	O
the	O
parameters	O
.	O
	
Parameter	O
matrices	O
in	O
fc6	B-Method
and	O
fc7	B-Method
are	O
of	O
size	O
and	O
.	O
	
Their	O
compression	B-Method
hyperparameters	I-Method
are	O
and	O
.	O
	
The	O
compression	B-Metric
factors	I-Metric
are	O
and	O
respectively	O
.	O
	
The	O
HD	O
-	O
CNN	B-Method
obtains	O
top	B-Metric
-	I-Metric
1	I-Metric
and	O
top	B-Metric
-	I-Metric
5	I-Metric
errors	I-Metric
and	O
on	O
ImageNet	O
validation	O
set	O
and	O
improves	O
over	O
ImageNet	B-Method
-	I-Method
VGG	I-Method
-	I-Method
16	I-Method
-	I-Method
layer	I-Method
by	O
and	O
respectively	O
.	O
	
Comparison	O
with	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
.	O
	
Currently	O
,	O
the	O
two	O
best	O
nets	O
on	O
ImageNet	O
dataset	O
are	O
GoogLeNet	O
(	O
Table	O
[	O
reference	O
]	O
)	O
and	O
VGG	B-Method
19	I-Method
-	I-Method
layer	I-Method
network	I-Method
.	O
	
Using	O
multi	B-Task
-	I-Task
scale	I-Task
multi	I-Task
-	I-Task
crop	I-Task
testing	I-Task
,	O
a	O
single	O
GoogLeNet	B-Method
net	I-Method
achieves	O
top	B-Metric
-	I-Metric
5	I-Metric
error	I-Metric
.	O
	
With	O
multi	O
-	O
scale	B-Task
dense	I-Task
evaluation	I-Task
,	O
a	O
single	O
VGG	B-Method
19	I-Method
-	I-Method
layer	I-Method
net	I-Method
obtains	O
top	B-Metric
-	I-Metric
1	I-Metric
and	O
top	B-Metric
-	I-Metric
5	I-Metric
errors	I-Metric
and	O
and	O
improves	O
top	B-Metric
-	I-Metric
5	I-Metric
error	I-Metric
of	O
GoogLeNet	B-Method
by	O
.	O
	
Our	O
HD	O
-	O
CNN	B-Method
decreases	O
top	B-Metric
-	I-Metric
1	I-Metric
and	O
top	B-Metric
-	I-Metric
5	I-Metric
errors	I-Metric
of	O
VGG	B-Method
19	I-Method
-	I-Method
layer	I-Method
net	I-Method
by	O
and	O
respectively	O
.	O
	
Furthermore	O
,	O
HD	O
-	O
CNN	B-Method
slightly	O
outperforms	O
the	O
results	O
of	O
averaging	O
the	O
predictions	O
from	O
VGG	B-Method
-	I-Method
16	I-Method
-	I-Method
layer	I-Method
and	I-Method
VGG	I-Method
-	I-Method
19	I-Method
-	I-Method
layer	I-Method
nets	I-Method
.	O
	
section	O
:	O
Conclusions	O
and	O
Future	O
Work	O
	
We	O
demonstrated	O
that	O
HD	O
-	O
CNN	B-Method
is	O
a	O
flexible	O
deep	O
CNN	B-Method
architecture	O
to	O
improve	O
over	O
existing	O
deep	O
CNN	B-Method
models	O
.	O
	
We	O
showed	O
this	O
empirically	O
on	O
both	O
CIFAR	B-Material
-	I-Material
100	I-Material
and	O
Image	O
-	O
Net	O
datasets	O
using	O
three	O
different	O
building	B-Method
block	I-Method
nets	I-Method
.	O
	
As	O
part	O
of	O
future	O
work	O
,	O
we	O
plan	O
to	O
extend	O
HD	O
-	O
CNN	B-Method
architectures	O
to	O
those	O
with	O
more	O
than	O
2	O
hierarchical	O
levels	O
and	O
also	O
verify	O
our	O
empirical	O
results	O
in	O
a	O
theoretical	O
framework	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
An	O
Empirical	O
Evaluation	O
of	O
Deep	B-Task
Learning	I-Task
on	O
Highway	B-Task
Driving	I-Task
	
Numerous	O
groups	O
have	O
applied	O
a	O
variety	O
of	O
deep	B-Method
learning	I-Method
techniques	I-Method
to	O
computer	B-Task
vision	I-Task
problems	I-Task
in	O
highway	B-Task
perception	I-Task
scenarios	I-Task
.	O
	
In	O
this	O
paper	O
,	O
we	O
presented	O
a	O
number	O
of	O
empirical	O
evaluations	O
of	O
recent	O
deep	B-Method
learning	I-Method
advances	I-Method
.	O
	
Computer	B-Task
vision	I-Task
,	O
combined	O
with	O
deep	B-Method
learning	I-Method
,	O
has	O
the	O
potential	O
to	O
bring	O
about	O
a	O
relatively	O
inexpensive	O
,	O
robust	O
solution	O
to	O
autonomous	B-Task
driving	I-Task
.	O
	
To	O
prepare	O
deep	B-Method
learning	I-Method
for	O
industry	B-Task
uptake	I-Task
and	O
practical	B-Task
applications	I-Task
,	O
neural	B-Method
networks	I-Method
will	O
require	O
large	O
data	O
sets	O
that	O
represent	O
all	O
possible	O
driving	O
environments	O
and	O
scenarios	O
.	O
	
We	O
collect	O
a	O
large	O
data	O
set	O
of	O
highway	O
data	O
and	O
apply	O
deep	B-Method
learning	I-Method
and	I-Method
computer	I-Method
vision	I-Method
algorithms	I-Method
to	O
problems	O
such	O
as	O
car	B-Task
and	O
lane	B-Task
detection	I-Task
.	O
	
We	O
show	O
how	O
existing	O
convolutional	B-Method
neural	I-Method
networks	I-Method
(	O
CNNs	B-Method
)	O
can	O
be	O
used	O
to	O
perform	O
lane	B-Task
and	O
vehicle	B-Task
detection	I-Task
while	O
running	O
at	O
frame	B-Metric
rates	I-Metric
required	O
for	O
a	O
real	B-Task
-	I-Task
time	I-Task
system	I-Task
.	O
	
Our	O
results	O
lend	O
credence	O
to	O
the	O
hypothesis	O
that	O
deep	B-Method
learning	I-Method
holds	O
promise	O
for	O
autonomous	B-Task
driving	I-Task
.	O
	
section	O
:	O
Introduction	O
	
Since	O
the	O
DARPA	B-Task
Grand	I-Task
Challenges	I-Task
for	O
autonomous	B-Task
vehicles	I-Task
,	O
there	O
has	O
been	O
an	O
explosion	O
in	O
applications	O
and	O
research	O
for	O
self	O
-	O
driving	O
cars	B-Task
.	O
	
Among	O
the	O
different	O
environments	O
for	O
self	O
-	O
driving	O
cars	B-Task
,	O
highway	B-Task
and	I-Task
urban	I-Task
roads	I-Task
are	O
on	O
opposite	O
ends	O
of	O
the	O
spectrum	O
.	O
	
In	O
general	O
,	O
highways	O
tend	O
to	O
be	O
more	O
predictable	O
and	O
orderly	O
,	O
with	O
road	O
surfaces	O
typically	O
well	O
-	O
maintained	O
and	O
lanes	O
well	O
-	O
marked	O
.	O
	
In	O
contrast	O
,	O
residential	O
or	O
urban	O
driving	O
environments	O
feature	O
a	O
much	O
higher	O
degree	O
of	O
unpredictability	O
with	O
many	O
generic	O
objects	O
,	O
inconsistent	O
lane	B-Task
-	O
markings	O
,	O
and	O
elaborate	O
traffic	O
flow	O
patterns	O
.	O
	
The	O
relative	O
regularity	O
and	O
structure	O
of	O
highways	O
has	O
facilitated	O
some	O
of	O
the	O
first	O
practical	O
applications	O
of	O
autonomous	B-Task
driving	I-Task
technology	I-Task
.	O
	
Many	O
automakers	O
have	O
begun	O
pursuing	O
highway	B-Task
auto	I-Task
-	I-Task
pilot	I-Task
solutions	I-Task
designed	O
to	O
mitigate	O
driver	O
stress	O
and	O
fatigue	O
and	O
to	O
provide	O
additional	O
safety	O
features	O
;	O
for	O
example	O
,	O
certain	O
advanced	B-Method
-	I-Method
driver	I-Method
assistance	I-Method
systems	I-Method
(	O
ADAS	B-Method
)	O
can	O
both	O
keep	O
cars	B-Task
within	O
their	O
lane	B-Task
and	O
perform	O
front	B-Task
-	I-Task
view	I-Task
car	I-Task
detection	I-Task
.	O
	
Currently	O
,	O
the	O
human	O
drivers	O
retain	O
liability	O
and	O
,	O
as	O
such	O
,	O
must	O
keep	O
their	O
hands	O
on	O
the	O
steering	O
wheel	O
and	O
prepare	O
to	O
control	O
the	O
vehicle	O
in	O
the	O
event	O
of	O
any	O
unexpected	O
obstacle	O
or	O
catastrophic	O
incident	O
.	O
	
Financial	O
considerations	O
contribute	O
to	O
a	O
substantial	O
performance	O
gap	O
between	O
commercially	O
available	O
auto	B-Method
-	I-Method
pilot	I-Method
systems	I-Method
and	O
fully	O
self	O
-	O
driving	O
cars	B-Task
developed	O
by	O
Google	O
and	O
others	O
.	O
	
Namely	O
,	O
today	O
’s	O
self	O
-	O
driving	O
cars	B-Task
are	O
equipped	O
with	O
expensive	O
but	O
critical	O
sensors	O
,	O
such	O
as	O
LIDAR	B-Method
,	O
radar	B-Method
and	O
high	O
-	O
precision	B-Method
GPS	I-Method
coupled	O
with	O
highly	O
detailed	O
maps	O
.	O
	
In	O
today	O
’s	O
production	B-Task
-	I-Task
grade	I-Task
autonomous	I-Task
vehicles	I-Task
,	O
critical	B-Task
sensors	I-Task
include	O
radar	O
,	O
sonar	O
,	O
and	O
cameras	O
.	O
	
Long	B-Task
-	I-Task
range	I-Task
vehicle	I-Task
detection	I-Task
typically	O
requires	O
radar	B-Task
,	O
while	O
nearby	B-Task
car	I-Task
detection	I-Task
can	O
be	O
solved	O
with	O
sonar	B-Method
.	O
	
Computer	B-Task
vision	I-Task
can	O
play	O
an	O
important	O
a	O
role	O
in	O
lane	B-Task
detection	I-Task
as	O
well	O
as	O
redundant	O
object	B-Task
detection	I-Task
at	O
moderate	O
distances	O
.	O
	
Radar	B-Method
works	O
reasonably	O
well	O
for	O
detecting	B-Task
vehicles	I-Task
,	O
but	O
has	O
difficulty	O
distinguishing	O
between	O
different	O
metal	O
objects	O
and	O
thus	O
can	O
register	O
false	O
positives	O
on	O
objects	O
such	O
as	O
tin	O
cans	O
.	O
	
Also	O
,	O
radar	B-Method
provides	O
little	O
orientation	O
information	O
and	O
has	O
a	O
higher	O
variance	O
on	O
the	O
lateral	O
position	O
of	O
objects	O
,	O
making	O
the	O
localization	B-Task
difficult	O
on	O
sharp	O
bends	O
.	O
	
The	O
utility	O
of	O
sonar	B-Method
is	O
both	O
compromised	O
at	O
high	O
speeds	O
and	O
,	O
even	O
at	O
slow	O
speeds	O
,	O
is	O
limited	O
to	O
a	O
working	O
distance	O
of	O
about	O
meters	O
.	O
	
Compared	O
to	O
sonar	B-Method
and	O
radar	B-Method
,	O
cameras	B-Method
generate	O
a	O
richer	O
set	O
of	O
features	O
at	O
a	O
fraction	O
of	O
the	O
cost	O
.	O
	
By	O
advancing	O
computer	B-Task
vision	I-Task
,	O
cameras	O
could	O
serve	O
as	O
a	O
reliable	O
redundant	B-Method
sensor	I-Method
for	O
autonomous	B-Task
driving	I-Task
.	O
	
Despite	O
its	O
potential	O
,	O
computer	B-Task
vision	I-Task
has	O
yet	O
to	O
assume	O
a	O
significant	O
role	O
in	O
today	O
’s	O
self	O
-	O
driving	O
cars	B-Task
.	O
	
Classic	O
computer	B-Method
vision	I-Method
techniques	I-Method
simply	O
have	O
not	O
provided	O
the	O
robustness	B-Metric
required	O
for	O
production	B-Task
grade	I-Task
automotives	I-Task
;	O
these	O
techniques	O
require	O
intensive	O
hand	B-Task
engineering	I-Task
,	O
road	B-Task
modeling	I-Task
,	O
and	O
special	B-Task
case	I-Task
handling	I-Task
.	O
	
Considering	O
the	O
seemingly	O
infinite	O
number	O
of	O
specific	O
driving	O
situations	O
,	O
environments	O
,	O
and	O
unexpected	O
obstacles	O
,	O
the	O
task	O
of	O
scaling	O
classic	O
computer	B-Method
vision	I-Method
to	O
robust	O
,	O
human	O
-	O
level	O
performance	O
would	O
prove	O
monumental	O
and	O
is	O
likely	O
to	O
be	O
unrealistic	O
.	O
	
Deep	B-Method
learning	I-Method
,	O
or	O
neural	B-Method
networks	I-Method
,	O
represents	O
an	O
alternative	O
approach	O
to	O
computer	B-Task
vision	I-Task
.	O
	
It	O
shows	O
considerable	O
promise	O
as	O
a	O
solution	O
to	O
the	O
shortcomings	O
of	O
classic	O
computer	B-Task
vision	I-Task
.	O
	
Recent	O
progress	O
in	O
the	O
field	O
has	O
advanced	O
the	O
feasibility	O
of	O
deep	B-Task
learning	I-Task
applications	I-Task
to	O
solve	O
complex	O
,	O
real	B-Task
-	I-Task
world	I-Task
problems	I-Task
;	O
industry	O
has	O
responded	O
by	O
increasing	O
uptake	O
of	O
such	O
technology	O
.	O
	
Deep	B-Method
learning	I-Method
is	O
data	B-Task
centric	I-Task
,	O
requiring	O
heavy	O
computation	O
but	O
minimal	O
hand	O
-	O
engineering	O
.	O
	
In	O
the	O
last	O
few	O
years	O
,	O
an	O
increase	O
in	O
available	O
storage	O
and	O
compute	O
capabilities	O
have	O
enabled	O
deep	B-Method
learning	I-Method
to	O
achieve	O
success	O
in	O
supervised	B-Task
perception	I-Task
tasks	I-Task
,	O
such	O
as	O
image	B-Task
detection	I-Task
.	O
	
A	O
neural	B-Method
network	I-Method
,	O
after	O
training	O
for	O
days	O
or	O
even	O
weeks	O
on	O
a	O
large	O
data	O
set	O
,	O
can	O
be	O
capable	O
of	O
inference	B-Task
in	O
real	B-Task
-	I-Task
time	I-Task
with	O
a	O
model	O
size	O
that	O
is	O
no	O
larger	O
than	O
a	O
few	O
hundred	O
MB	O
.	O
	
State	O
-	O
of	O
-	O
the	O
-	O
art	O
neural	B-Method
networks	I-Method
for	O
computer	B-Task
vision	I-Task
require	O
very	O
large	O
training	O
sets	O
coupled	O
with	O
extensive	O
networks	O
capable	O
of	O
modeling	O
such	O
immense	O
volumes	O
of	O
data	O
.	O
	
For	O
example	O
,	O
the	O
ILSRVC	O
data	O
-	O
set	O
,	O
where	O
neural	B-Method
networks	I-Method
achieve	O
top	O
results	O
,	O
contains	O
million	O
images	O
in	O
over	O
categories	O
.	O
	
By	O
using	O
expensive	O
existing	O
sensors	O
which	O
are	O
currently	O
used	O
for	O
self	B-Task
-	I-Task
driving	I-Task
applications	I-Task
,	O
such	O
as	O
LIDAR	O
and	O
mm	B-Method
-	I-Method
accurate	I-Method
GPS	I-Method
,	O
and	O
calibrating	O
them	O
with	O
cameras	O
,	O
we	O
can	O
create	O
a	O
video	O
data	O
set	O
containing	O
labeled	O
lane	B-Task
-	O
markings	O
and	O
annotated	O
vehicles	O
with	O
location	O
and	O
relative	O
speed	O
.	O
	
By	O
building	O
a	O
labeled	O
data	O
set	O
in	O
all	O
types	O
of	O
driving	O
situations	O
(	O
rain	O
,	O
snow	O
,	O
night	O
,	O
day	O
,	O
etc	O
.	O
)	O
,	O
we	O
can	O
evaluate	O
neural	B-Method
networks	I-Method
on	O
this	O
data	O
to	O
determine	O
if	O
it	O
is	O
robust	O
in	O
every	O
driving	O
environment	O
and	O
situation	O
for	O
which	O
we	O
have	O
training	O
data	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
detail	O
empirical	O
evaluation	O
on	O
the	O
data	O
set	O
we	O
collect	O
.	O
	
In	O
addition	O
,	O
we	O
explain	O
the	O
neural	B-Method
network	I-Method
that	O
we	O
applied	O
for	O
detecting	B-Task
lanes	I-Task
and	O
cars	B-Task
,	O
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
Related	O
Work	O
	
Recently	O
,	O
computer	B-Task
vision	I-Task
has	O
been	O
expected	O
to	O
player	O
a	O
larger	O
role	O
within	O
autonomous	B-Task
driving	I-Task
.	O
	
However	O
,	O
due	O
to	O
its	O
history	O
of	O
relatively	O
low	O
precision	B-Metric
,	O
it	O
is	O
typically	O
used	O
in	O
conjunction	O
with	O
either	O
other	O
sensors	O
or	O
other	O
road	B-Method
models	I-Method
.	O
	
Cho	O
et	O
al	O
.	O
uses	O
multiple	O
sensors	O
,	O
such	O
as	O
LIDAR	O
,	O
radar	B-Method
,	O
and	O
computer	B-Task
vision	I-Task
for	O
object	B-Task
detection	I-Task
.	O
	
They	O
then	O
fuse	O
these	O
sensors	O
together	O
in	O
a	O
Kalman	B-Method
filter	I-Method
using	O
motion	B-Method
models	I-Method
on	O
the	O
objects	O
.	O
	
Held	O
et	O
al	O
.	O
,	O
uses	O
only	O
a	O
deformable	B-Method
parts	I-Method
based	I-Method
model	I-Method
on	O
images	O
to	O
get	O
the	O
detections	O
,	O
then	O
uses	O
road	B-Method
models	I-Method
to	O
filter	O
out	O
false	O
positives	O
.	O
	
Carafii	O
et	O
al	O
.	O
uses	O
a	O
WaldBoost	O
detector	B-Method
along	O
with	O
a	O
tracker	B-Method
to	O
generate	O
pixel	B-Task
space	I-Task
detections	I-Task
in	O
real	O
time	O
.	O
	
Jazayeri	O
et	O
al	O
.	O
relies	O
on	O
temporal	O
information	O
of	O
features	O
for	O
detection	B-Task
,	O
and	O
then	O
filters	O
out	O
false	O
positives	O
with	O
a	O
front	B-Method
-	I-Method
view	I-Method
motion	I-Method
model	I-Method
.	O
	
In	O
contrast	O
to	O
these	O
object	B-Method
detectors	I-Method
,	O
we	O
do	O
not	O
use	O
any	O
road	B-Method
or	I-Method
motion	I-Method
-	I-Method
based	I-Method
models	I-Method
;	O
instead	O
we	O
rely	O
only	O
on	O
the	O
robustness	O
of	O
a	O
neural	B-Method
network	I-Method
to	O
make	O
reasonable	O
predictions	O
.	O
	
In	O
addition	O
,	O
we	O
currently	O
do	O
not	O
rely	O
on	O
any	O
temporal	O
features	O
,	O
and	O
the	O
detector	B-Method
operates	O
independently	O
on	O
single	O
frames	O
from	O
a	O
monocular	O
camera	O
.	O
	
To	O
make	O
up	O
for	O
the	O
lack	O
of	O
other	O
sensors	O
,	O
which	O
estimate	O
object	O
depth	O
,	O
we	O
train	O
the	O
neural	B-Method
network	I-Method
to	O
predict	O
depth	O
based	O
on	O
labels	O
extracted	O
from	O
radar	O
returns	O
.	O
	
Although	O
the	O
model	O
only	O
predicts	O
a	O
single	O
depth	O
value	O
for	O
each	O
object	O
,	O
Eigen	O
et	O
al	O
.	O
	
have	O
shown	O
how	O
a	O
neural	B-Method
network	I-Method
can	O
predict	O
entire	B-Task
depth	I-Task
maps	I-Task
from	O
single	O
images	O
.	O
	
The	O
network	O
we	O
train	O
likely	O
learns	O
some	O
model	O
of	O
the	O
road	B-Task
for	O
object	B-Task
detection	I-Task
and	O
depth	O
predictions	O
,	O
but	O
it	O
is	O
never	O
explicitly	O
engineered	O
and	O
instead	O
learns	O
from	O
the	O
annotations	O
alone	O
.	O
	
Before	O
the	O
wide	O
spread	O
adoption	O
of	O
Convolutional	B-Method
Neural	I-Method
Networks	I-Method
(	O
CNNs	B-Method
)	O
within	O
computer	B-Task
vision	I-Task
,	O
deformable	B-Method
parts	I-Method
based	I-Method
models	I-Method
were	O
the	O
most	O
successful	O
methods	O
for	O
detection	B-Task
.	O
	
After	O
the	O
popular	O
CNN	B-Method
model	O
AlexNet	O
was	O
proposed	O
,	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
detection	B-Task
shifted	O
towards	O
CNNs	B-Method
for	O
feature	B-Task
extraction	I-Task
.	O
	
Girshick	O
et	O
al	O
.	O
developed	O
R	B-Method
-	I-Method
CNN	I-Method
,	O
a	O
two	O
part	B-Method
system	I-Method
which	O
used	O
Selective	O
Search	O
to	O
propose	O
regions	O
and	O
AlexNet	B-Method
to	O
classify	O
them	O
.	O
	
R	B-Method
-	I-Method
CNN	I-Method
achieved	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
on	O
Pascal	B-Task
by	O
a	O
large	O
margin	O
;	O
however	O
,	O
due	O
to	O
its	O
nearly	O
classification	B-Metric
queries	I-Metric
and	O
inefficient	O
re	O
-	O
use	O
of	O
convolutions	B-Method
,	O
it	O
remains	O
impractical	O
for	O
real	B-Task
-	I-Task
time	I-Task
implementations	I-Task
.	O
	
Szegedy	O
et	O
al	O
.	O
presented	O
a	O
more	O
scalable	O
alternative	O
to	O
R	B-Method
-	I-Method
CNN	I-Method
,	O
that	O
relies	O
on	O
the	O
CNN	B-Method
to	O
propose	O
higher	O
quality	O
regions	O
compared	O
to	O
Selective	B-Method
Search	I-Method
.	O
	
This	O
reduces	O
the	O
number	O
of	O
region	O
proposals	O
down	O
to	O
as	O
low	O
as	O
while	O
keeping	O
the	O
mAP	B-Method
competitive	O
with	O
Selective	B-Method
Search	I-Method
.	O
	
An	O
even	O
faster	O
approach	O
to	O
image	B-Task
detection	I-Task
called	O
Overfeat	B-Method
was	O
presented	O
by	O
Sermanet	O
et	O
al	O
.	O
.	O
	
By	O
using	O
a	O
regular	O
pattern	O
of	O
“	O
region	O
proposals	O
”	O
,	O
Overfeat	B-Method
can	O
efficiently	O
reuse	O
convolution	B-Method
computations	I-Method
from	O
each	O
layer	O
,	O
requiring	O
only	O
a	O
single	O
forward	B-Method
pass	I-Method
for	O
inference	B-Task
.	O
	
For	O
our	O
empirical	O
evaluation	O
,	O
we	O
use	O
a	O
straight	O
-	O
forward	O
application	O
of	O
Overfeat	B-Method
,	O
due	O
to	O
its	O
efficiencies	O
,	O
and	O
combine	O
this	O
with	O
labels	O
similar	O
to	O
the	O
ones	O
proposed	O
by	O
Szegedy	O
et	O
al	O
.	O
.	O
	
We	O
describe	O
the	O
model	O
and	O
similarities	O
in	O
the	O
next	O
section	O
.	O
	
section	O
:	O
Real	B-Task
Time	I-Task
Vehicle	I-Task
Detection	I-Task
	
Convolutional	B-Method
Neural	I-Method
Networks	I-Method
(	O
CNNs	B-Method
)	O
have	O
had	O
the	O
largest	O
success	O
in	O
image	B-Task
recognition	I-Task
in	O
the	O
past	O
3	O
years	O
.	O
	
From	O
these	O
image	B-Method
recognition	I-Method
systems	I-Method
,	O
a	O
number	O
of	O
detection	B-Method
networks	I-Method
were	O
adapted	O
,	O
leading	O
to	O
further	O
advances	O
in	O
image	B-Task
detection	I-Task
.	O
	
While	O
the	O
improvements	O
have	O
been	O
staggering	O
,	O
not	O
much	O
consideration	O
had	O
been	O
given	O
to	O
the	O
real	B-Task
-	I-Task
time	I-Task
detection	I-Task
performance	O
required	O
for	O
some	O
applications	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
present	O
a	O
detection	B-Method
system	I-Method
capable	O
of	O
operating	O
at	O
greater	O
than	O
Hz	O
using	O
nothing	O
but	O
a	O
laptop	B-Method
GPU	I-Method
.	O
	
Due	O
to	O
the	O
requirements	O
of	O
highway	B-Task
driving	I-Task
,	O
we	O
need	O
to	O
ensure	O
that	O
the	O
system	O
used	O
can	O
detect	O
cars	B-Task
more	O
than	O
m	O
away	O
and	O
can	O
operate	O
at	O
speeds	O
greater	O
than	O
Hz	O
;	O
this	O
distance	O
requires	O
higher	O
image	O
resolutions	O
than	O
is	O
typically	O
used	O
,	O
and	O
in	O
our	O
case	O
is	O
.	O
	
We	O
use	O
the	O
Overfeat	B-Method
CNN	I-Method
detector	I-Method
,	O
which	O
is	O
very	O
scalable	O
,	O
and	O
simulates	O
a	O
sliding	O
window	O
detector	B-Method
in	O
a	O
single	O
forward	O
pass	O
in	O
the	O
network	O
by	O
efficiently	O
reusing	O
convolutional	O
results	O
on	O
each	O
layer	O
.	O
	
Other	O
detection	B-Method
systems	I-Method
,	O
such	O
as	O
R	B-Method
-	I-Method
CNN	I-Method
,	O
rely	O
on	O
selecting	O
as	O
many	O
as	O
candidate	O
windows	O
,	O
where	O
each	O
is	O
evaluated	O
independently	O
and	O
does	O
not	O
reuse	O
convolutional	O
results	O
.	O
	
In	O
our	O
implementation	O
,	O
we	O
make	O
a	O
few	O
minor	O
modifications	O
to	O
Overfeat	B-Method
’s	O
labels	O
in	O
order	O
to	O
handle	O
occlusions	O
of	O
cars	B-Task
,	O
predictions	B-Task
of	I-Task
lanes	I-Task
,	O
and	O
accelerate	O
performance	O
during	O
inference	B-Task
.	O
	
We	O
will	O
first	O
provide	O
a	O
brief	O
overview	O
of	O
the	O
original	O
implementation	O
and	O
will	O
then	O
address	O
the	O
modifications	O
.	O
	
Overfeat	B-Method
converts	O
	
an	O
image	O
recognition	O
CNN	B-Method
into	O
a	O
“	O
sliding	O
window	O
”	O
detector	B-Method
by	O
providing	O
a	O
larger	O
resolution	O
image	O
and	O
transforming	O
the	O
fully	B-Method
connected	I-Method
layers	I-Method
into	O
convolutional	B-Method
layers	I-Method
.	O
	
Then	O
,	O
after	O
converting	O
the	O
fully	B-Method
connected	I-Method
layer	I-Method
,	O
which	O
would	O
have	O
produced	O
a	O
single	O
final	O
feature	O
vector	O
,	O
to	O
a	O
convolutional	B-Method
layer	I-Method
,	O
a	O
grid	O
of	O
final	O
feature	O
vectors	O
is	O
produced	O
.	O
	
Each	O
of	O
the	O
resulting	O
feature	O
vectors	O
represents	O
a	O
slightly	O
different	O
context	O
view	O
location	O
within	O
the	O
original	O
pixel	O
space	O
.	O
	
To	O
determine	O
the	O
stride	O
of	O
this	O
window	O
in	O
pixel	O
space	O
,	O
it	O
is	O
possible	O
to	O
simply	O
multiply	O
the	O
strides	O
on	O
each	O
convolutional	B-Method
or	I-Method
pool	I-Method
layer	I-Method
together	O
.	O
	
The	O
network	O
we	O
used	O
has	O
a	O
stride	O
size	O
of	O
pixels	O
.	O
	
Each	O
final	O
feature	O
vector	O
in	O
this	O
grid	O
can	O
predict	O
the	O
presence	O
of	O
an	O
object	O
;	O
once	O
an	O
object	O
is	O
detected	O
,	O
those	O
same	O
features	O
are	O
then	O
used	O
to	O
predict	O
a	O
single	O
bounding	O
box	O
through	O
regression	B-Method
.	O
	
The	O
classifier	B-Method
will	O
predict	O
“	O
no	O
-	O
object	O
”	O
if	O
it	O
can	O
not	O
discern	O
any	O
part	O
of	O
an	O
object	O
within	O
its	O
entire	O
input	O
view	O
.	O
	
This	O
causes	O
large	O
ambiguities	O
for	O
the	O
classifier	B-Method
,	O
which	O
can	O
only	O
predict	O
a	O
single	O
object	O
,	O
as	O
two	O
different	O
objects	O
could	O
can	O
easily	O
appear	O
in	O
the	O
context	O
view	O
of	O
the	O
final	O
feature	O
vector	O
,	O
which	O
is	O
typically	O
larger	O
than	O
of	O
the	O
input	O
image	O
resolution	O
.	O
	
The	O
network	O
we	O
used	O
has	O
a	O
context	O
view	O
of	O
pixels	O
in	O
size	O
.	O
	
To	O
ensure	O
that	O
all	O
objects	O
in	O
the	O
image	O
are	O
classified	O
at	O
least	O
once	O
,	O
many	O
different	O
context	O
views	O
are	O
taken	O
of	O
the	O
image	O
by	O
using	O
skip	B-Method
gram	I-Method
kernels	I-Method
to	O
reduce	O
the	O
stride	O
of	O
the	O
context	O
views	O
and	O
by	O
using	O
up	O
to	O
four	O
different	O
scales	O
of	O
the	O
input	O
image	O
.	O
	
The	O
classifier	B-Method
is	O
then	O
trained	O
to	O
activate	O
when	O
an	O
object	O
appears	O
anywhere	O
within	O
its	O
entire	O
context	O
view	O
.	O
	
In	O
the	O
original	O
Overfeat	B-Method
paper	O
,	O
this	O
results	O
in	O
different	O
context	O
views	O
(	O
or	O
final	O
feature	O
vectors	O
)	O
,	O
where	O
each	O
one	O
is	O
likely	O
to	O
become	O
active	O
(	O
create	O
a	O
bounding	O
box	O
)	O
.	O
	
This	O
creates	O
two	O
problems	O
for	O
our	O
empirical	O
evaluation	O
.	O
	
Due	O
to	O
the	O
L2	O
loss	O
between	O
the	O
predicted	O
bounding	O
box	O
and	O
actual	O
bounding	O
proposed	O
by	O
Sermanet	O
et	O
al	O
.	O
,	O
the	O
ambiguity	O
of	O
having	O
two	O
valid	O
bounding	O
box	O
locations	O
to	O
predict	O
when	O
two	O
objects	O
appear	O
,	O
is	O
incorrectly	O
handled	O
by	O
the	O
network	O
by	O
predicting	O
a	O
box	O
in	O
the	O
center	O
of	O
the	O
two	O
objects	O
to	O
minimize	O
its	O
expected	O
loss	O
.	O
	
These	O
boxes	O
tend	O
to	O
cause	O
a	O
problem	O
for	O
the	O
bounding	B-Method
box	I-Method
merging	I-Method
algorithm	I-Method
,	O
which	O
incorrectly	O
decides	O
that	O
there	O
must	O
be	O
a	O
third	O
object	O
between	O
the	O
two	O
ground	O
truth	O
objects	O
.	O
	
This	O
could	O
cause	O
problems	O
for	O
an	O
ADAS	B-Method
system	I-Method
which	O
falsely	O
believes	O
there	O
is	O
a	O
car	B-Task
where	O
there	O
is	O
not	O
,	O
and	O
emergency	O
breaking	O
is	O
falsely	O
applied	O
.	O
	
In	O
addition	O
,	O
the	O
merging	B-Method
algorithm	I-Method
,	O
used	O
only	O
during	O
inference	B-Task
,	O
operates	O
in	O
where	O
is	O
the	O
number	O
of	O
bounding	O
boxes	O
proposed	O
.	O
	
Because	O
the	O
bounding	B-Method
box	I-Method
merging	I-Method
is	O
not	O
as	O
easily	O
parallelizable	O
as	O
the	O
CNN	B-Method
,	O
this	O
merging	B-Task
may	O
become	O
the	O
bottleneck	O
of	O
a	O
real	B-Task
-	I-Task
time	I-Task
system	I-Task
in	O
the	O
case	O
of	O
an	O
inefficient	O
implementation	O
or	O
too	O
many	O
predicted	O
bounding	O
boxes	O
.	O
	
In	O
our	O
evaluations	O
,	O
we	O
use	O
a	O
mask	B-Method
detector	I-Method
as	O
described	O
in	O
Szegedy	O
et	O
al	O
.	O
to	O
improve	O
some	O
of	O
the	O
issues	O
with	O
Overfeat	B-Method
as	O
described	O
above	O
.	O
	
Szegedy	O
et	O
al	O
.	O
proposes	O
a	O
CNN	B-Method
that	O
takes	O
an	O
image	O
as	O
input	O
and	O
outputs	O
an	O
object	O
mask	O
through	O
regression	B-Method
,	O
highlighting	O
the	O
object	O
location	O
.	O
	
The	O
idea	O
of	O
a	O
mask	B-Method
detector	I-Method
is	O
shown	O
in	O
Fig	O
[	O
reference	O
]	O
.	O
	
To	O
distinguish	O
multiple	O
nearby	O
objects	O
,	O
different	O
part	B-Method
-	I-Method
detectors	I-Method
output	O
object	O
masks	O
,	O
from	O
which	O
bounding	O
boxes	O
are	O
then	O
extracted	O
.	O
	
The	O
detector	B-Method
they	O
propose	O
must	O
take	O
many	O
crops	O
of	O
the	O
image	O
,	O
and	O
run	O
multiple	O
CNNs	B-Method
for	O
each	O
part	O
on	O
every	O
crop	O
.	O
	
Their	O
resulting	O
implementation	O
takes	O
roughly	O
-	O
seconds	O
per	O
frame	O
per	O
class	O
using	O
a	O
12	B-Method
-	I-Method
core	I-Method
machine	I-Method
,	O
which	O
would	O
be	O
too	O
slow	O
for	O
our	O
application	O
.	O
	
We	O
combine	O
these	O
ideas	O
by	O
using	O
the	O
efficient	O
“	O
sliding	O
window	O
”	O
detector	B-Method
of	O
Overfeat	B-Method
to	O
produce	O
an	O
object	O
mask	O
and	O
perform	O
bounding	B-Method
box	I-Method
regression	I-Method
.	O
	
This	O
is	O
shown	O
in	O
Fig	O
[	O
reference	O
]	O
.	O
	
In	O
this	O
implementation	O
,	O
we	O
use	O
a	O
single	O
image	O
resolution	O
of	O
with	O
no	O
skip	B-Method
gram	I-Method
kernels	I-Method
.	O
	
To	O
help	O
the	O
ambiguity	B-Task
problem	I-Task
,	O
and	O
reduce	O
the	O
number	O
of	O
bounding	O
boxes	O
predicted	O
,	O
we	O
alter	O
the	O
detector	B-Method
on	O
the	O
top	O
layer	O
to	O
only	O
activate	O
within	O
a	O
pixel	O
region	O
at	O
the	O
center	O
of	O
its	O
context	O
view	O
,	O
as	O
shown	O
in	O
the	O
first	O
box	O
in	O
Fig	O
[	O
reference	O
]	O
.	O
	
Because	O
it	O
’s	O
highly	O
unlikely	O
that	O
any	O
two	O
different	O
object	O
’s	O
bounding	O
boxes	O
appear	O
in	O
a	O
pixel	O
region	O
,	O
compared	O
to	O
the	O
entire	O
context	O
view	O
with	O
Overfeat	B-Method
,	O
the	O
bounding	B-Method
box	I-Method
regressor	I-Method
will	O
no	O
longer	O
have	O
to	O
arbitrarily	O
choose	O
between	O
two	O
valid	O
objects	O
in	O
its	O
context	O
view	O
.	O
	
In	O
addition	O
,	O
because	O
the	O
requirement	O
for	O
the	O
detector	B-Method
to	O
fire	O
is	O
stricter	O
,	O
this	O
produces	O
many	O
fewer	O
bounding	O
boxes	O
which	O
greatly	O
reduces	O
our	O
run	B-Metric
-	I-Metric
time	I-Metric
performance	O
during	O
inference	B-Task
.	O
	
Although	O
these	O
changes	O
helped	O
,	O
ambiguity	O
was	O
still	O
a	O
common	O
problem	O
on	O
the	O
border	O
of	O
bounding	O
boxes	O
in	O
the	O
cases	O
of	O
occlusion	O
.	O
	
This	O
ambiguity	O
results	O
in	O
a	O
false	O
bounding	O
box	O
being	O
predicted	O
between	O
the	O
two	O
ground	O
truth	O
bounding	O
boxes	O
.	O
	
To	O
fix	O
this	O
problem	O
,	O
the	O
bounding	O
boxes	O
were	O
first	O
shrunk	O
by	O
before	O
creating	O
the	O
detection	O
mask	O
label	O
.	O
	
This	O
added	O
the	O
additional	O
requirement	O
that	O
the	O
center	O
-	O
pixel	O
region	O
of	O
the	O
detector	B-Method
window	O
had	O
to	O
be	O
within	O
the	O
center	O
region	O
of	O
the	O
object	O
before	O
activating	O
.	O
	
The	O
bounding	B-Method
box	I-Method
regressor	I-Method
however	O
,	O
still	O
predicts	O
the	O
original	O
bounding	O
box	O
before	O
shrinking	O
.	O
	
This	O
also	O
further	O
reduces	O
the	O
number	O
of	O
active	O
bounding	O
boxes	O
as	O
input	O
to	O
our	O
merging	B-Method
algorithm	I-Method
.	O
	
We	O
also	O
found	O
that	O
switching	O
from	O
L2	O
to	O
L1	O
loss	O
on	O
the	O
bounding	B-Method
box	I-Method
regressions	I-Method
results	O
in	O
better	O
performance	O
.	O
	
To	O
merge	O
the	O
bounding	O
boxes	O
together	O
,	O
we	O
used	O
OpenCV	B-Method
’s	O
efficient	O
implementation	O
of	O
groupRectangles	B-Method
,	O
which	O
clusters	O
the	O
bounding	O
boxes	O
based	O
on	O
a	O
similarity	B-Metric
metric	I-Metric
in	O
.	O
	
The	O
lower	O
layers	O
of	O
our	O
CNN	B-Method
we	O
use	O
for	O
feature	B-Task
extraction	I-Task
is	O
similar	O
to	O
the	O
one	O
proposed	O
by	O
Krizhevsky	O
et	O
al	O
.	O
.	O
	
Our	O
modifications	O
to	O
the	O
network	O
occurs	O
on	O
the	O
dense	B-Method
layers	I-Method
which	O
are	O
converted	O
to	O
convolution	B-Method
,	O
as	O
described	O
in	O
Sermanet	O
et	O
al	O
.	O
.	O
	
When	O
using	O
our	O
larger	O
image	O
sizes	O
of	O
this	O
changes	O
the	O
previous	O
final	O
feature	O
response	O
maps	O
of	O
size	O
to	O
.	O
	
As	O
stated	O
earlier	O
,	O
each	O
of	O
these	O
feature	B-Method
vectors	I-Method
sees	O
a	O
context	O
region	O
of	O
pixels	O
,	O
and	O
the	O
stride	O
between	O
them	O
is	O
pixels	O
;	O
however	O
,	O
we	O
want	O
each	O
making	O
predictions	O
at	O
a	O
resolution	O
of	O
pixels	O
,	O
which	O
would	O
leave	O
gaps	O
in	O
our	O
input	O
image	O
.	O
	
To	O
fix	O
this	O
,	O
we	O
use	O
each	O
feature	O
as	O
input	O
to	O
softmax	B-Method
classifiers	I-Method
,	O
which	O
are	O
arranged	O
in	O
an	O
grid	O
each	O
predicting	O
if	O
an	O
object	O
is	O
within	O
a	O
different	O
pixel	O
region	O
.	O
	
This	O
allows	O
for	O
the	O
feature	O
vector	O
to	O
cover	O
the	O
full	O
stride	O
size	O
of	O
pixels	O
;	O
the	O
end	O
result	O
is	O
a	O
grid	B-Method
mask	I-Method
detector	I-Method
of	O
size	O
where	O
each	O
element	O
is	O
pixels	O
which	O
covers	O
the	O
entire	O
input	O
image	O
of	O
size	O
.	O
	
subsection	O
:	O
Lane	B-Task
Detection	I-Task
	
The	O
CNN	B-Method
used	O
for	O
vehicle	B-Task
detection	I-Task
can	O
be	O
easily	O
extended	O
for	O
lane	B-Task
boundary	O
detection	O
by	O
adding	O
an	O
additional	O
class	O
.	O
	
Whereas	O
the	O
regression	O
for	O
the	O
vehicle	B-Task
class	I-Task
predicts	O
a	O
five	O
dimensional	O
value	O
(	O
four	O
for	O
the	O
bounding	O
box	O
and	O
one	O
for	O
depth	O
)	O
,	O
the	O
lane	B-Task
regression	O
predicts	O
six	O
dimensions	O
.	O
	
Similar	O
to	O
the	O
vehicle	B-Method
detector	I-Method
,	O
the	O
first	O
four	O
dimensions	O
indicate	O
the	O
two	O
end	O
points	O
of	O
a	O
local	O
line	O
segment	O
of	O
the	O
lane	B-Task
boundary	O
.	O
	
The	O
remaining	O
two	O
dimensions	O
indicate	O
the	O
depth	O
of	O
the	O
endpoints	O
with	O
respect	O
to	O
the	O
camera	O
.	O
	
Fig	O
[	O
reference	O
]	O
visualizes	O
the	O
lane	B-Task
boundary	O
ground	O
truth	O
label	O
overlaid	O
on	O
an	O
example	O
image	O
.	O
	
The	O
green	O
tiles	O
indicate	O
locations	O
where	O
the	O
detector	B-Method
is	O
trained	O
to	O
fire	O
,	O
and	O
the	O
line	O
segments	O
represented	O
by	O
the	O
regression	O
labels	O
are	O
explicitly	O
drawn	O
.	O
	
The	O
line	O
segments	O
have	O
their	O
ends	O
connected	O
to	O
form	O
continuous	O
splines	O
.	O
	
The	O
depth	O
of	O
the	O
line	O
segments	O
are	O
color	O
-	O
coded	O
such	O
that	O
the	O
closest	O
segments	O
are	O
red	O
and	O
the	O
furthest	O
ones	O
are	O
blue	O
.	O
	
Due	O
to	O
our	O
data	B-Method
collection	I-Method
methods	I-Method
for	O
lane	B-Task
labels	O
,	O
we	O
are	O
able	O
to	O
obtain	O
ground	O
truth	O
in	O
spite	O
of	O
objects	O
that	O
occlude	O
them	O
.	O
	
This	O
forces	O
the	O
neural	B-Method
network	I-Method
to	O
learn	O
more	O
than	O
a	O
simple	O
paint	B-Method
detector	I-Method
,	O
and	O
must	O
use	O
context	O
to	O
predict	O
lanes	O
where	O
there	O
are	O
occlusions	O
.	O
	
Similar	O
to	O
the	O
vehicle	B-Method
detector	I-Method
,	O
we	O
use	O
L1	B-Method
loss	I-Method
to	O
train	O
the	O
regressor	B-Method
.	O
	
We	O
use	O
mini	B-Method
-	I-Method
batch	I-Method
stochastic	I-Method
gradient	I-Method
descent	I-Method
for	O
optimization	B-Task
.	O
	
The	O
learning	B-Metric
rate	I-Metric
is	O
controlled	O
by	O
a	O
variant	O
of	O
the	O
momentum	B-Method
scheduler	I-Method
.	O
	
To	O
obtain	O
semantic	O
lane	B-Task
information	O
,	O
we	O
use	O
DBSCAN	B-Method
to	O
cluster	O
the	O
line	O
segments	O
into	O
lanes	O
.	O
	
Fig	O
[	O
reference	O
]	O
shows	O
our	O
lane	B-Task
predictions	O
after	O
DBSCAN	B-Method
clustering	O
.	O
	
Different	O
lanes	O
are	O
represented	O
by	O
different	O
colors	O
.	O
	
Since	O
our	O
regressor	O
outputs	O
depths	O
as	O
well	O
,	O
we	O
can	O
predict	O
the	O
lane	B-Task
shapes	O
in	O
3D	O
using	O
inverse	B-Task
camera	I-Task
perspective	I-Task
mapping	I-Task
.	O
	
section	O
:	O
Experimental	O
Setup	O
	
subsection	O
:	O
Data	O
Collection	O
	
Our	O
Research	O
Vehicle	O
is	O
a	O
2014	O
Infiniti	B-Method
Q50	I-Method
.	O
	
The	O
car	B-Task
currently	O
uses	O
the	O
following	O
sensors	O
:	O
	
6x	O
Point	B-Method
Grey	I-Method
Flea3	I-Method
cameras	I-Method
,	O
1x	O
Velodyne	B-Method
HDL32E	I-Method
lidar	I-Method
,	O
and	O
1x	O
Novatel	B-Method
SPAN	I-Method
-	I-Method
SE	I-Method
Receiver	I-Method
.	O
	
We	O
also	O
have	O
access	O
to	O
the	O
Q50	O
built	O
-	O
in	O
Continental	B-Task
mid	I-Task
-	I-Task
range	I-Task
radar	I-Task
system	I-Task
.	O
	
The	O
sensors	O
are	O
connected	O
to	O
a	O
Linux	B-Method
PC	I-Method
with	O
a	O
Core	O
i7	O
-	O
4770k	O
processor	O
.	O
	
Once	O
the	O
raw	O
videos	O
are	O
collected	O
,	O
we	O
annotate	O
the	O
3D	O
locations	O
for	O
vehicles	O
and	O
lanes	O
as	O
well	O
as	O
the	O
relative	O
speed	O
of	O
all	O
the	O
vehicles	O
.	O
	
To	O
get	O
vehicle	B-Task
annotations	I-Task
,	O
we	O
follow	O
the	O
conventional	O
approach	O
of	O
using	O
Amazon	O
Mechanical	O
Turk	O
to	O
get	O
accurate	O
bounding	O
box	O
locations	O
within	O
pixel	O
space	O
.	O
	
Then	O
,	O
we	O
match	O
bounding	O
boxes	O
and	O
radar	O
returns	O
to	O
obtain	O
the	O
distance	O
and	O
relative	O
speed	O
of	O
the	O
vehicles	O
.	O
	
Unlike	O
vehicles	O
that	O
can	O
be	O
annotated	O
with	O
bounding	O
boxes	O
,	O
highway	O
lane	B-Task
borders	O
often	O
need	O
to	O
be	O
annotated	O
as	O
curves	O
of	O
various	O
shapes	O
.	O
	
This	O
makes	O
frame	B-Method
-	I-Method
level	I-Method
labelling	I-Method
not	O
only	O
tedious	O
and	O
inefficient	O
,	O
but	O
also	O
prone	O
to	O
human	O
errors	O
.	O
	
Fortunately	O
,	O
lane	B-Task
markings	O
can	O
be	O
considered	O
as	O
âstaticâ	O
objects	O
that	O
do	O
not	O
change	O
their	O
geolocations	O
very	O
often	O
.	O
	
We	O
follow	O
the	O
process	O
descried	O
in	O
to	O
create	O
LIDAR	B-Task
maps	I-Task
of	I-Task
the	I-Task
environment	I-Task
using	O
the	O
Velodyne	B-Method
and	I-Method
GNSS	I-Method
systems	I-Method
.	O
	
Using	O
these	O
maps	O
,	O
labeling	B-Task
is	O
straight	O
forward	O
.	O
	
First	O
,	O
we	O
filter	O
the	O
3D	O
point	O
clouds	O
based	O
on	O
lidar	O
return	O
intensity	O
and	O
position	O
to	O
obtain	O
the	O
left	O
and	O
right	O
boundaries	O
of	O
the	O
ego	O
-	O
lane	B-Task
.	O
	
Then	O
,	O
we	O
replicate	O
the	O
left	O
and	O
right	O
ego	O
-	O
lane	B-Task
boundaries	O
to	O
obtain	O
initial	O
guesses	O
for	O
all	O
the	O
lane	B-Task
boundaries	O
.	O
	
A	O
human	O
annotator	O
inspects	O
the	O
generated	O
lane	B-Task
boundaries	O
and	O
makes	O
appropriate	O
corrections	O
using	O
our	O
3D	B-Method
labelling	I-Method
tool	I-Method
.	O
	
For	O
completeness	O
,	O
we	O
describe	O
each	O
of	O
these	O
steps	O
in	O
details	O
.	O
	
subsubsection	O
:	O
Ego	O
-	O
lane	B-Task
boundary	O
generation	O
	
Since	O
we	O
do	O
not	O
change	O
lanes	O
during	O
data	O
collection	O
drives	O
,	O
the	O
GPS	O
trajectory	O
of	O
our	O
research	O
vehicle	O
already	O
gives	O
a	O
decent	O
estimate	O
of	O
the	O
shape	O
of	O
the	O
road	O
.	O
	
We	O
can	O
then	O
easily	O
locate	O
the	O
ego	O
-	O
lane	B-Task
boundaries	O
using	O
a	O
few	O
heuristic	B-Method
filters	I-Method
.	O
	
Noting	O
that	O
lane	B-Task
boundaries	O
on	O
highways	O
are	O
usually	O
marked	O
with	O
retro	O
-	O
reflective	O
materials	O
,	O
we	O
first	O
filter	O
out	O
low	O
-	O
reflectivity	O
surfaces	O
such	O
as	O
asphalt	O
in	O
our	O
3D	B-Task
point	I-Task
cloud	I-Task
maps	I-Task
and	O
only	O
consider	O
points	O
with	O
high	O
enough	O
laser	O
return	O
intensities	O
.	O
	
We	O
then	O
filter	O
out	O
other	O
reflective	O
surfaces	O
such	O
as	O
cars	B-Task
and	O
traffic	O
signs	O
by	O
only	O
considering	O
points	O
whose	O
heights	O
are	O
close	O
enough	O
the	O
ground	O
plane	O
.	O
	
Lastly	O
,	O
assuming	O
our	O
car	B-Task
drives	O
close	O
to	O
the	O
center	O
of	O
the	O
lane	B-Task
,	O
we	O
filter	O
out	O
ground	O
paint	O
other	O
than	O
the	O
ego	O
-	O
lane	B-Task
boundaries	O
,	O
such	O
as	O
other	O
lane	B-Task
boundaries	O
,	O
car	B-Task
-	O
pool	O
or	O
directional	O
signs	O
,	O
by	O
only	O
considering	O
markings	O
whose	O
absolute	O
lateral	O
distances	O
from	O
the	O
car	B-Task
are	O
smaller	O
than	O
2.2	O
meters	O
and	O
greater	O
than	O
1.4	O
meters	O
.	O
	
We	O
can	O
also	O
distinguish	O
the	O
left	O
boundary	O
from	O
the	O
right	O
one	O
using	O
the	O
sign	O
of	O
the	O
lateral	O
distance	O
.	O
	
After	O
obtaining	O
the	O
points	O
in	O
the	O
left	O
and	O
right	O
boundaries	O
,	O
we	O
fit	O
a	O
piecewise	B-Method
linear	I-Method
curve	I-Method
similar	O
to	O
the	O
GPS	O
trajectory	O
to	O
each	O
boundary	O
.	O
	
subsubsection	O
:	O
Semi	O
-	O
automatic	O
generation	O
of	O
multiple	O
lane	B-Task
boundaries	O
	
We	O
observe	O
that	O
the	O
width	O
of	O
lanes	O
during	O
a	O
single	O
data	O
collection	O
run	O
stays	O
constant	O
most	O
of	O
the	O
time	O
,	O
with	O
occasional	O
exceptions	O
such	O
as	O
merges	O
and	O
splits	O
.	O
	
Therefore	O
,	O
if	O
we	O
predefine	O
the	O
number	O
of	O
lanes	O
to	O
the	O
left	O
and	O
right	O
of	O
the	O
car	B-Task
for	O
a	O
single	O
run	O
,	O
we	O
can	O
make	O
a	O
good	O
initial	O
guess	O
of	O
all	O
the	O
lane	B-Task
boundaries	O
by	O
shifting	O
the	O
auto	O
-	O
generated	O
ego	O
-	O
lane	B-Task
boundaries	O
laterally	O
by	O
multiples	O
of	O
the	O
lane	B-Task
width	O
.	O
	
We	O
will	O
then	O
rely	O
on	O
human	O
annotators	O
to	O
fix	O
the	O
exception	O
cases	O
.	O
	
subsection	O
:	O
Data	O
Set	O
	
At	O
the	O
time	O
of	O
this	O
writing	O
our	O
annotated	O
data	O
-	O
set	O
consists	O
of	O
days	O
of	O
driving	O
in	O
the	O
San	O
Francisco	O
Bay	O
Area	O
during	O
the	O
months	O
of	O
April	O
-	O
June	O
for	O
a	O
few	O
hours	O
each	O
day	O
.	O
	
The	O
vehicle	O
annotated	O
data	O
is	O
sampled	O
at	O
and	O
contains	O
nearly	O
thousand	O
frames	O
with	O
thousand	O
bounding	O
boxes	O
.	O
	
The	O
lane	B-Task
annotated	O
data	O
is	O
sampled	O
at	O
and	O
contains	O
over	O
thousand	O
frames	O
.	O
	
During	O
training	O
,	O
translation	O
and	O
7	O
different	O
perspective	O
distortions	O
are	O
applied	O
to	O
the	O
raw	O
data	O
sets	O
.	O
	
Fig	O
[	O
reference	O
]	O
shows	O
an	O
example	O
image	O
after	O
perspective	O
distortions	O
are	O
applied	O
.	O
	
Note	O
that	O
we	O
apply	O
the	O
same	O
perspective	O
distortion	O
to	O
the	O
ground	O
truth	O
labels	O
so	O
that	O
they	O
match	O
correctly	O
with	O
the	O
distorted	O
image	O
.	O
	
subsection	O
:	O
Results	O
	
The	O
detection	B-Method
network	I-Method
used	O
is	O
capable	O
of	O
running	O
at	O
Hz	O
using	O
a	O
desktop	O
PC	O
equipped	O
with	O
a	O
GTX	B-Method
780	I-Method
Ti	I-Method
.	O
	
When	O
using	O
a	O
mobile	O
GPU	O
,	O
such	O
as	O
the	O
Tegra	B-Method
K1	I-Method
,	O
we	O
were	O
capable	O
of	O
running	O
the	O
network	O
at	O
Hz	O
,	O
and	O
would	O
expect	O
the	O
system	O
to	O
run	O
at	O
Hz	O
using	O
the	O
Nvidia	B-Method
PX1	I-Method
chipset	I-Method
.	O
	
Our	O
lane	B-Task
detection	I-Task
test	O
set	O
consists	O
of	O
22	O
video	O
clips	O
collected	O
using	O
both	O
left	O
and	O
right	O
cameras	O
during	O
11	O
different	O
data	O
collection	O
runs	O
,	O
which	O
correspond	O
to	O
about	O
50	O
minutes	O
of	O
driving	O
.	O
	
We	O
evaluate	O
detection	B-Task
results	O
for	O
four	O
lane	B-Task
boundaries	O
,	O
namely	O
,	O
the	O
left	O
and	O
right	O
boundaries	O
of	O
the	O
ego	O
lane	B-Task
,	O
plus	O
the	O
outer	O
boundaries	O
of	O
the	O
two	O
adjacent	O
lanes	O
.	O
	
For	O
each	O
of	O
these	O
lane	B-Task
boundaries	O
,	O
we	O
further	O
break	O
down	O
the	O
evaluation	O
by	O
longitudinal	O
distances	O
,	O
which	O
range	O
from	O
15	O
to	O
80	O
meters	O
ahead	O
of	O
the	O
car	B-Task
,	O
spaced	O
by	O
5	O
meters	O
.	O
	
Thus	O
,	O
there	O
are	O
at	O
maximum	O
positions	O
at	O
which	O
we	O
evaluate	O
the	O
detection	B-Task
results	O
.	O
	
We	O
pair	O
up	O
the	O
prediction	O
and	O
ground	O
truth	O
points	O
at	O
each	O
of	O
these	O
locations	O
using	O
greedy	B-Method
nearest	I-Method
neighbor	I-Method
matching	I-Method
.	O
	
True	O
positives	O
,	O
false	O
positives	O
and	O
false	B-Metric
negatives	I-Metric
are	O
accumulated	O
at	O
every	O
evaluation	O
location	O
in	O
a	O
standard	O
way	O
:	O
A	O
true	O
positive	O
is	O
counted	O
when	O
the	O
matched	O
prediction	O
and	O
ground	O
truth	O
differ	O
by	O
less	O
than	O
0.5	O
meter	O
.	O
	
If	O
the	O
matched	O
prediction	O
and	O
ground	O
truth	O
differ	O
by	O
more	O
than	O
0.5	O
meter	O
,	O
both	O
false	O
positive	O
and	O
false	B-Metric
negative	I-Metric
counts	I-Metric
are	O
incremented	O
.	O
	
Fig	O
[	O
reference	O
]	O
shows	O
a	O
visualization	O
of	O
this	O
evaluation	O
method	O
on	O
one	O
image	O
.	O
	
The	O
blue	O
dots	O
are	O
true	O
positives	O
.	O
	
The	O
red	O
dots	O
are	O
false	O
positives	O
,	O
and	O
the	O
yellow	O
ones	O
are	O
false	O
negatives	O
.	O
	
Fig	O
[	O
reference	O
]	O
shows	O
the	O
aggregated	B-Metric
precision	I-Metric
,	O
recall	B-Metric
and	O
F1	B-Metric
score	I-Metric
on	O
all	O
test	O
videos	O
.	O
	
For	O
the	O
ego	O
-	O
lane	B-Task
boundaries	O
,	O
we	O
obtain	O
F1	B-Metric
score	I-Metric
up	O
to	O
50	O
meters	O
.	O
	
Recall	B-Metric
starts	O
to	O
drop	O
fast	O
beyond	O
65	O
meters	O
,	O
mainly	O
because	O
the	O
resolution	O
of	O
the	O
image	O
can	O
not	O
capture	O
the	O
width	O
of	O
the	O
lane	B-Task
markings	O
at	O
that	O
distance	O
.	O
	
For	O
the	O
adjacent	O
lanes	O
,	O
recall	B-Metric
is	O
low	O
for	O
the	O
nearest	O
point	O
because	O
it	O
is	O
outside	O
the	O
field	O
of	O
view	O
of	O
the	O
camera	O
.	O
	
[	O
b	O
]	O
1.6	O
in	O
[	O
b	O
]	O
1.6	O
in	O
[	O
b	O
]	O
1.6	O
in	O
[	O
b	O
]	O
1.6	O
in	O
The	O
vehicle	B-Task
detection	I-Task
test	O
set	O
consists	O
of	O
13	O
video	O
clips	O
collected	O
from	O
a	O
single	O
day	O
,	O
which	O
corresponds	O
to	O
1	O
hour	O
and	O
30	O
mins	O
of	O
driving	O
.	O
	
The	O
accuracy	B-Metric
of	O
the	O
vehicle	B-Task
bounding	I-Task
box	I-Task
predictions	I-Task
were	O
measured	O
using	O
Intersection	B-Metric
Over	I-Metric
Union	I-Metric
(	O
IOU	B-Metric
)	O
against	O
the	O
ground	O
truth	O
boxes	O
from	O
Amazon	O
Mechanical	O
Turk	O
(	O
AMT	O
)	O
.	O
	
A	O
bounding	B-Method
box	I-Method
prediction	I-Method
matched	O
with	O
ground	O
truth	O
if	O
IOU	B-Metric
.	O
	
The	O
performance	O
of	O
our	O
car	B-Task
detection	O
as	O
a	O
function	O
of	O
depth	O
can	O
be	O
seen	O
in	O
Fig	O
[	O
reference	O
]	O
.	O
	
Nearby	O
false	O
positives	O
can	O
cause	O
the	O
largest	O
problems	O
for	O
ADAS	B-Task
systems	I-Task
which	O
could	O
cause	O
the	O
system	O
to	O
needlessly	O
apply	O
the	O
brakes	O
.	O
	
In	O
our	O
system	O
,	O
we	O
found	O
overpasses	O
and	O
shading	O
effects	O
to	O
cause	O
the	O
largest	O
problems	O
.	O
	
Two	O
examples	O
of	O
these	O
situations	O
are	O
shown	O
in	O
Fig	O
[	O
reference	O
]	O
.	O
	
[	O
b	O
]	O
1.7	O
in	O
[	O
b	O
]	O
1.7	O
in	O
As	O
a	O
baseline	O
to	O
our	O
car	B-Method
detector	I-Method
,	O
we	O
compared	O
the	O
detection	B-Task
results	O
to	O
the	O
Continental	B-Method
mid	I-Method
-	I-Method
range	I-Method
radar	I-Method
within	O
our	O
data	O
collection	O
vehicle	O
.	O
	
While	O
matching	O
radar	O
returns	O
to	O
ground	O
truth	O
bounding	O
boxes	O
,	O
we	O
found	O
that	O
although	O
radar	B-Method
had	O
nearly	O
precision	B-Metric
,	O
false	O
positives	O
were	O
being	O
introduced	O
through	O
errors	O
in	O
radar	B-Method
/	I-Method
camera	I-Method
calibration	I-Method
.	O
	
Therefore	O
,	O
to	O
ensure	O
a	O
fair	O
comparison	O
we	O
matched	O
every	O
radar	O
return	O
to	O
a	O
ground	O
truth	O
bounding	O
box	O
even	O
if	O
IOU	B-Metric
,	O
giving	O
our	O
radar	B-Metric
returns	I-Metric
precision	I-Metric
.	O
	
This	O
comparison	O
is	O
shown	O
in	O
Fig	O
[	O
reference	O
]	O
,	O
the	O
F1	B-Metric
score	I-Metric
for	O
radar	B-Task
is	O
simply	O
the	O
recall	B-Metric
.	O
	
In	O
addition	O
to	O
the	O
bounding	O
box	O
locations	O
,	O
we	O
measured	O
the	O
accuracy	B-Metric
of	O
the	O
predicted	O
depth	O
by	O
using	O
radar	O
returns	O
as	O
ground	O
truth	O
.	O
	
The	O
standard	O
error	O
in	O
the	O
depth	O
predictions	O
as	O
a	O
function	O
of	O
depth	O
can	O
be	O
seen	O
in	O
Fig	O
[	O
reference	O
]	O
.	O
	
For	O
a	O
qualitative	O
review	O
of	O
the	O
detection	B-Method
system	I-Method
,	O
we	O
have	O
uploaded	O
a	O
hour	O
video	O
of	O
the	O
vehicle	B-Method
detector	I-Method
ran	O
on	O
our	O
test	O
set	O
.	O
	
This	O
may	O
be	O
found	O
at	O
youtu.be	O
/	O
GJ0cZBkHoHc	O
.	O
	
A	O
short	O
video	O
of	O
our	O
lane	B-Method
detector	I-Method
may	O
also	O
be	O
found	O
online	O
at	O
	
youtu.be	O
/	O
_	O
_	O
f5pqqp6aM.	O
	
In	O
these	O
videos	O
,	O
we	O
evaluate	O
the	O
detector	B-Method
on	O
every	O
frame	O
independently	O
and	O
display	O
the	O
raw	O
detections	O
,	O
without	O
the	O
use	O
of	O
any	O
Kalman	B-Method
filters	I-Method
or	O
road	B-Method
models	I-Method
.	O
	
The	O
red	O
locations	O
in	O
the	O
video	O
correspond	O
to	O
the	O
mask	B-Method
detectors	I-Method
that	O
are	O
activated	O
.	O
	
This	O
network	O
was	O
only	O
trained	O
on	O
the	O
rear	O
view	O
of	O
cars	B-Task
traveling	O
in	O
the	O
same	O
direction	O
,	O
which	O
is	O
why	O
cars	B-Task
across	O
the	O
highway	O
barrier	O
are	O
commonly	O
missed	O
.	O
	
We	O
have	O
open	O
sourced	O
the	O
code	O
for	O
the	O
vehicle	O
and	O
lane	B-Task
detector	I-Method
online	O
at	O
github.com	O
/	O
brodyh	O
/	O
caffe	O
.	O
	
Our	O
repository	O
was	O
forked	O
from	O
the	O
original	O
Caffe	O
code	O
base	O
from	O
the	O
BVLC	O
group	O
.	O
	
section	O
:	O
Conclusion	O
	
By	O
using	O
Camera	B-Method
,	O
Lidar	B-Method
,	O
Radar	B-Method
,	O
and	O
GPS	B-Method
we	O
built	O
a	O
highway	O
data	O
set	O
consisting	O
of	O
thousand	O
image	O
frames	O
with	O
vehicle	O
bounding	O
boxes	O
and	O
over	O
thousand	O
image	O
frames	O
with	O
lane	B-Task
annotations	O
.	O
	
We	O
then	O
trained	O
on	O
this	O
data	O
using	O
a	O
CNN	B-Method
architecture	O
capable	O
of	O
detecting	O
all	O
lanes	O
and	O
cars	B-Task
in	O
a	O
single	O
forward	O
pass	O
.	O
	
Using	O
a	O
single	O
GTX	O
780	O
	
Ti	O
our	O
system	O
runs	O
at	O
Hz	O
,	O
which	O
is	O
more	O
than	O
adequate	O
for	O
real	O
-	O
time	O
use	O
.	O
	
Our	O
results	O
show	O
existing	O
CNN	B-Method
algorithms	O
are	O
capable	O
of	O
good	O
performance	O
in	O
highway	B-Task
lane	I-Task
and	O
vehicle	B-Task
detection	I-Task
.	O
	
Future	O
work	O
will	O
focus	O
on	O
acquiring	O
frame	O
level	O
annotations	O
that	O
will	O
allow	O
us	O
to	O
develop	O
new	O
neural	B-Method
networks	I-Method
capable	O
of	O
using	O
temporal	O
information	O
across	O
frames	O
.	O
	
section	O
:	O
Acknowledgment	O
	
This	O
research	O
was	O
funded	O
in	O
part	O
by	O
Nissan	O
who	O
generously	O
donated	O
the	O
car	B-Task
used	O
for	O
data	O
collection	O
.	O
	
We	O
thank	O
our	O
colleagues	O
Yuta	O
Yoshihata	O
from	O
Nissan	O
who	O
provided	O
technical	O
support	O
and	O
expertise	O
on	O
vehicles	O
that	O
assisted	O
the	O
research	O
.	O
	
In	O
addition	O
,	O
the	O
authors	O
would	O
like	O
to	O
thank	O
the	O
author	O
of	O
Overfeat	B-Method
,	O
Pierre	O
Sermanet	O
,	O
for	O
their	O
helpful	O
suggestions	O
on	O
image	B-Task
detection	I-Task
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Inferencing	B-Task
Based	O
on	O
Unsupervised	B-Method
Learning	I-Method
of	I-Method
Disentangled	I-Method
Representations	I-Method
	
Combining	O
Generative	B-Method
Adversarial	I-Method
Networks	I-Method
(	O
GANs	B-Method
)	O
with	O
encoders	B-Method
that	O
learn	O
to	O
encode	O
data	O
points	O
has	O
shown	O
promising	O
results	O
in	O
learning	O
data	B-Task
representations	I-Task
in	O
an	O
unsupervised	O
way	O
.	O
	
We	O
propose	O
a	O
framework	O
that	O
combines	O
an	O
encoder	B-Method
and	O
a	O
generator	B-Method
to	O
learn	O
disentangled	B-Method
representations	I-Method
which	O
encode	O
meaningful	O
information	O
about	O
the	O
data	O
distribution	O
without	O
the	O
need	O
for	O
any	O
labels	O
.	O
	
While	O
current	O
approaches	O
focus	O
mostly	O
on	O
the	O
generative	B-Method
aspects	I-Method
of	O
GANs	B-Method
,	O
our	O
framework	O
can	O
be	O
used	O
to	O
perform	O
inference	B-Task
on	O
both	O
real	O
and	O
generated	O
data	O
points	O
.	O
	
Experiments	O
on	O
several	O
data	O
sets	O
show	O
that	O
the	O
encoder	B-Method
learns	O
interpretable	O
,	O
disentangled	B-Method
representations	I-Method
which	O
encode	O
descriptive	O
properties	O
and	O
can	O
be	O
used	O
to	O
sample	O
images	O
that	O
exhibit	O
specific	O
characteristics	O
.	O
0	O
	
AcceptedasaconferencepaperattheEuropeanSymposiumonArtificialNeural	O
Networks	O
,	O
ComputationalIntelligenceandMachineLearning	O
(	O
ESANN	O
)	O
2018	O
	
section	O
:	O
Introduction	O
	
Learning	O
meaningful	B-Task
representations	I-Task
of	I-Task
data	I-Task
is	O
an	O
important	O
step	O
for	O
models	O
to	O
understand	O
the	O
world	O
.	O
	
Recently	O
,	O
the	O
Generative	B-Method
Adversarial	I-Method
Network	I-Method
(	O
GAN	B-Method
)	O
has	O
been	O
proposed	O
as	O
a	O
method	O
that	O
can	O
learn	O
characteristics	O
of	O
data	O
distributions	O
without	O
the	O
need	O
for	O
labels	O
.	O
	
GANs	B-Method
traditionally	O
consist	O
of	O
a	O
generator	B-Method
,	O
which	O
generates	O
data	O
from	O
randomly	O
sampled	O
vectors	O
,	O
and	O
a	O
discriminator	B-Method
,	O
which	O
tries	O
to	O
distinguish	O
generated	O
data	O
from	O
real	O
data	O
.	O
	
During	O
training	O
,	O
the	O
generator	B-Method
learns	O
to	O
generate	O
realistic	O
data	O
samples	O
,	O
while	O
the	O
discriminator	B-Method
becomes	O
better	O
at	O
distinguishing	O
between	O
the	O
generated	O
and	O
the	O
real	O
data	O
.	O
	
As	O
a	O
result	O
,	O
both	O
the	O
generator	B-Method
and	O
the	O
discriminator	B-Method
learn	O
characteristics	O
about	O
the	O
underlying	O
data	O
distribution	O
without	O
the	O
need	O
for	O
any	O
labels	O
.	O
	
One	O
desirable	O
characteristic	O
of	O
learned	B-Method
representations	I-Method
is	O
disentanglement	O
,	O
which	O
means	O
that	O
different	O
parts	O
of	O
the	O
representation	O
encode	O
different	O
factors	O
of	O
the	O
data	O
-	O
generating	O
distribution	O
.	O
	
This	O
makes	O
representations	O
more	O
interpretable	O
,	O
easier	O
to	O
modify	O
,	O
and	O
is	O
a	O
useful	O
property	O
for	O
many	O
tasks	O
such	O
as	O
classification	B-Task
,	O
clustering	B-Task
,	O
or	O
image	B-Task
captioning	I-Task
.	O
	
To	O
achieve	O
this	O
,	O
Chen	O
et	O
al	O
.	O
introduced	O
a	O
GAN	B-Method
variant	O
in	O
which	O
the	O
generator	O
’s	O
input	O
is	O
split	O
into	O
two	O
parts	O
and	O
.	O
	
Here	O
,	O
encodes	O
unstructured	O
noise	O
while	O
encodes	O
meaningful	O
,	O
data	O
-	O
generating	O
factors	O
.	O
	
Through	O
enforcing	O
high	O
mutual	O
information	O
between	O
and	O
and	O
the	O
generated	O
images	O
the	O
generator	O
is	O
trained	O
using	O
the	O
inputs	O
as	O
meaningful	O
encodings	O
for	O
certain	O
image	O
characteristics	O
.	O
	
For	O
example	O
,	O
a	O
ten	O
-	O
dimensional	O
categorical	O
code	O
for	O
could	O
represent	O
the	O
ten	O
different	O
digit	O
classes	O
in	O
the	O
MNIST	B-Material
data	I-Material
set	I-Material
.	O
	
Since	O
no	O
labels	O
are	O
provided	O
the	O
generator	O
has	O
to	O
learn	O
by	O
itself	O
which	O
image	O
characteristics	O
can	O
be	O
represented	O
through	O
.	O
	
One	O
drawback	O
of	O
this	O
model	O
is	O
that	O
the	O
only	O
way	O
to	O
perform	O
inference	B-Task
,	O
i.e.	O
map	O
real	O
data	O
samples	O
into	O
a	O
(	O
disentangled	O
)	O
representation	O
,	O
is	O
to	O
use	O
the	O
discriminator	B-Method
.	O
	
However	O
,	O
there	O
is	O
no	O
guarantee	O
that	O
the	O
discriminator	B-Method
learns	O
good	O
representations	O
of	O
the	O
data	O
in	O
general	O
,	O
as	O
it	O
is	O
trained	O
to	O
discriminate	O
between	O
real	O
and	O
generated	O
data	O
and	O
may	O
therefore	O
focus	O
only	O
on	O
features	O
that	O
are	O
helpful	O
for	O
discriminating	O
these	O
two	O
,	O
but	O
are	O
not	O
necessarily	O
descriptive	O
of	O
the	O
data	O
distribution	O
in	O
general	O
.	O
	
Zhang	O
et	O
al	O
.	O
tried	O
to	O
enforce	O
disentangled	O
representations	O
in	O
order	O
to	O
improve	O
the	O
controllability	O
of	O
the	O
generator	O
.	O
	
The	O
latent	B-Method
representation	I-Method
is	O
split	O
up	O
into	O
two	O
parts	O
encoding	O
meaningful	O
information	O
and	O
unknown	O
factors	O
of	O
variation	O
.	O
	
Two	O
additional	O
inference	B-Method
networks	I-Method
are	O
introduced	O
to	O
enforce	O
the	O
disentanglement	O
between	O
the	O
two	O
parts	O
of	O
the	O
latent	B-Method
representation	I-Method
.	O
	
While	O
this	O
setup	O
yields	O
a	O
better	O
controllability	O
over	O
the	O
generative	B-Method
process	I-Method
it	O
depends	O
on	O
labeled	O
samples	O
for	O
its	O
training	O
objective	O
and	O
can	O
not	O
discover	O
unknown	O
data	O
-	O
generating	O
factors	O
,	O
but	O
only	O
encodes	O
known	O
factors	O
of	O
variation	O
(	O
obtained	O
through	O
labels	O
)	O
in	O
its	O
disentangled	B-Method
representation	I-Method
.	O
	
Donahue	O
et	O
al	O
.	O
and	O
Dumoulin	O
et	O
al	O
.	O
introduced	O
an	O
extension	O
which	O
includes	O
an	O
encoder	B-Method
that	O
learns	O
the	O
encodings	O
of	O
real	O
data	O
samples	O
.	O
	
The	O
discriminator	B-Method
gets	O
as	O
input	O
both	O
the	O
data	O
sample	O
(	O
either	O
real	O
or	O
generated	O
)	O
and	O
the	O
according	O
representation	O
(	O
either	O
or	O
)	O
and	O
has	O
to	O
classify	O
them	O
as	O
either	O
coming	O
from	O
the	O
generator	B-Method
or	O
the	O
encoder	B-Method
.	O
	
The	O
generator	B-Method
and	O
the	O
encoder	B-Method
try	O
to	O
fool	O
the	O
discriminator	B-Method
into	O
misclassifying	O
the	O
samples	O
.	O
	
As	O
a	O
result	O
,	O
the	O
encoder	B-Method
learns	O
to	O
approximate	O
the	O
inverse	O
of	O
the	O
generator	B-Method
and	O
can	O
be	O
used	O
to	O
map	O
real	O
data	O
samples	O
into	O
representations	O
for	O
other	O
applications	O
.	O
	
However	O
,	O
in	O
these	O
approaches	O
the	O
representations	O
follow	O
a	O
simple	O
prior	O
,	O
e.g.	O
a	O
Gaussian	O
or	O
uniform	O
distribution	O
,	O
and	O
do	O
not	O
exhibit	O
any	O
disentangled	O
properties	O
.	O
	
Our	O
model	O
,	O
the	O
Bidirectional	B-Method
-	I-Method
InfoGAN	I-Method
,	O
integrates	O
some	O
of	O
these	O
approaches	O
by	O
extending	O
traditional	O
GANs	B-Method
with	O
an	O
encoder	B-Method
that	O
learns	O
disentangled	B-Method
representations	I-Method
in	O
an	O
unsupervised	B-Task
setting	I-Task
.	O
	
After	O
training	O
,	O
the	O
encoder	B-Method
can	O
map	O
data	O
points	O
to	O
meaningful	O
,	O
disentangled	B-Method
representations	I-Method
which	O
can	O
potentially	O
be	O
used	O
for	O
different	O
tasks	O
such	O
as	O
classification	B-Task
,	O
clustering	B-Task
,	O
or	O
image	B-Task
captioning	I-Task
.	O
	
Compared	O
to	O
the	O
InfoGAN	B-Method
we	O
introduce	O
an	O
encoder	B-Method
to	O
mitigate	O
the	O
problems	O
of	O
using	O
a	O
discriminator	B-Method
for	O
both	O
the	O
adversarial	B-Task
loss	I-Task
and	O
the	O
inference	B-Task
task	I-Task
.	O
	
Unlike	O
the	O
Structured	O
GAN	B-Method
our	O
training	B-Method
procedure	I-Method
is	O
completely	O
unsupervised	O
,	O
can	O
detect	O
unknown	O
data	O
-	O
generating	O
factors	O
,	O
and	O
only	O
introduces	O
one	O
additional	O
inference	B-Method
network	I-Method
(	O
the	O
encoder	B-Method
)	O
.	O
	
In	O
contrast	O
to	O
the	O
Bidirectional	B-Method
GAN	I-Method
we	O
replace	O
the	O
simple	O
prior	O
on	O
the	O
latent	B-Method
representation	I-Method
with	O
a	O
distribution	O
that	O
is	O
amenable	O
to	O
disentangled	B-Method
representations	I-Method
and	O
introduce	O
an	O
additional	O
loss	O
for	O
the	O
encoder	B-Method
and	O
the	O
generator	B-Method
to	O
achieve	O
disentangled	B-Method
representations	I-Method
.	O
	
On	O
the	O
MNIST	B-Material
,	O
CelebA	O
,	O
and	O
SVHN	O
data	O
sets	O
we	O
show	O
that	O
the	O
encoder	B-Method
does	O
learn	O
interpretable	B-Method
representations	I-Method
which	O
encode	O
meaningful	O
properties	O
of	O
the	O
data	O
distribution	O
.	O
	
Using	O
these	O
we	O
can	O
sample	O
images	O
that	O
exhibit	O
certain	O
characteristics	O
,	O
e.g.	O
digit	O
identity	O
and	O
specific	O
stroke	O
widths	O
for	O
the	O
MNIST	B-Material
data	I-Material
set	I-Material
,	O
or	O
different	O
hair	O
colors	O
and	O
clothing	O
accessories	O
in	O
the	O
CelebA	O
data	O
set	O
.	O
	
every	O
picture	O
/	O
.style	O
=	O
line	O
width=0.2	O
mm	O
	
[	O
scale=0.39	O
]	O
[	O
]	O
at	O
(	O
2.5	O
,	O
9.5	O
)	O
features	O
;	O
fill	O
=	O
white	O
,	O
rounded	O
corners=0.2	O
cm	O
]	O
(	O
0.6	O
,	O
1.5	O
)	O
rectangle	O
(	O
4.6	O
,	O
2.8	O
)	O
node	O
[	O
pos=.5	O
]	O
;	O
[	O
fill	O
=	O
white	O
,	O
rounded	O
corners=0.2	O
cm	O
]	O
	
(	O
0.6	O
,-	O
0.2	O
)	O
rectangle	O
(	O
4.6	O
,	O
1.1	O
)	O
	
node	O
[	O
pos=.5	O
]	O
	
;	O
[	O
fill	O
=	O
gray	O
,	O
opacity=0.3	O
,	O
rounded	O
corners=0.2	O
cm	O
]	O
(	O
0.6	O
,	O
6.65	O
)	O
rectangle	O
(	O
4.6	O
,	O
7.95	O
)	O
node	O
[	O
pos=.5	O
,	O
opacity=1	O
]	O
;	O
[	O
-	O
¿	O
]	O
	
(	O
4.6	O
,	O
7.3	O
)	O
–	O
	
(	O
7	O
,	O
7.3	O
)	O
;	O
[	O
-	O
¿	O
]	O
	
(	O
9	O
,	O
7.3	O
)	O
	
–	O
	
(	O
10.8	O
,	O
7.3	O
)	O
;	O
(	O
18.5	O
,	O
5.75	O
)	O
ellipse	O
(	O
2.7	O
and	O
1	O
)	O
node	O
[	O
]	O
;	O
[	O
]	O
at	O
(	O
13	O
,	O
9.5	O
)	O
data	O
;	O
fill	O
=	O
gray	O
,	O
opacity=0.3	O
,	O
rounded	O
corners=0.2	O
cm	O
]	O
	
(	O
10.9	O
,	O
1.5	O
)	O
rectangle	O
(	O
14.9	O
,	O
2.8	O
)	O
node	O
[	O
pos=.5	O
,	O
opacity=1	O
]	O
;	O
[	O
-	O
¿	O
]	O
	
(	O
10.9	O
,	O
2.15	O
)	O
	
–	O
	
(	O
10.5	O
,	O
2.15	O
)	O
–	O
	
(	O
10.5	O
,	O
1.7	O
)	O
	
–	O
	
(	O
9	O
,	O
1.7	O
)	O
;	O
[	O
fill	O
=	O
white	O
,	O
rounded	O
corners=0.2	O
cm	O
]	O
	
(	O
10.9	O
,-	O
0.2	O
)	O
rectangle	O
(	O
14.9	O
,	O
1.1	O
)	O
	
node	O
[	O
pos=.5	O
]	O
;	O
[	O
-	O
¿	O
	
]	O
(	O
10.9	O
,	O
0.45	O
)	O
–	O
	
(	O
10.5	O
,	O
0.45	O
)	O
–	O
(	O
10.5	O
,	O
0.9	O
)	O
	
–	O
(	O
9	O
,	O
0.9	O
)	O
;	O
[	O
fill	O
=	O
white	O
,	O
rounded	O
corners=0.2	O
cm	O
]	O
	
(	O
10.9	O
,	O
6.65	O
)	O
rectangle	O
(	O
14.9	O
,	O
7.95	O
)	O
node	O
[	O
pos=.5	O
]	O
;	O
	
[	O
-	O
¿	O
]	O
	
(	O
2.5	O
,	O
6.6	O
)	O
	
–	O
	
(	O
2.5	O
,	O
5.8	O
)	O
	
–	O
(	O
15.8	O
,	O
5.8	O
)	O
;	O
[	O
]	O
(	O
13	O
,	O
6.6	O
	
)	O
–	O
(	O
13	O
,	O
5.8	O
)	O
;	O
[	O
]	O
(	O
13	O
,	O
2.8	O
)	O
–	O
(	O
13	O
,	O
3.4	O
)	O
;	O
[	O
-	O
¿	O
]	O
	
(	O
2.5	O
,	O
2.8	O
)	O
–	O
	
(	O
2.5	O
,	O
3.4	O
)	O
–	O
(	O
15.8	O
,	O
3.4	O
)	O
node	O
[	O
pos=.4	O
,	O
above	O
,	O
inner	O
sep=0.5pt	O
]	O
if	O
image	O
node	O
[	O
pos=.4	O
,	O
below	O
,	O
inner	O
sep=0.5pt	O
]	O
is	O
real	O
;	O
	
[	O
]	O
	
(	O
13	O
,-	O
1	O
)	O
–	O
	
(	O
13	O
,-	O
0.2	O
)	O
;	O
[	O
-	O
¿	O
]	O
(	O
2.5	O
,-	O
0.2	O
)	O
–	O
(	O
2.5	O
,-	O
1	O
)	O
–	O
	
(	O
15.8	O
,-	O
1	O
)	O
node	O
[	O
pos=.4	O
,	O
above	O
,	O
inner	O
sep=0.5pt	O
]	O
if	O
image	O
node	O
[	O
pos=.4	O
,	O
below	O
,	O
inner	O
sep=0.5pt	O
]	O
is	O
generated	O
;	O
	
(	O
18.5	O
,	O
3.35	O
)	O
ellipse	O
(	O
2.7	O
and	O
1	O
)	O
node	O
[	O
]	O
;	O
	
(	O
19.8	O
,-	O
1	O
)	O
ellipse	O
(	O
4	O
and	O
1	O
)	O
node	O
[	O
]	O
;	O
	
[	O
fill	O
=	O
	
yellow!30	O
]	O
	
(	O
27.5	O
,-	O
1	O
)	O
ellipse	O
(	O
1.9	O
and	O
0.9	O
)	O
node	O
[	O
]	O
node	O
[	O
above	O
,	O
inner	O
sep=11pt	O
]	O
mutual	O
information	O
;	O
[	O
-	O
¿	O
]	O
	
(	O
23.8	O
,-	O
1	O
)	O
	
–	O
	
(	O
25.6	O
,-	O
1	O
)	O
;	O
[	O
fill	O
=	O
red!10	O
]	O
	
(	O
7	O
,	O
8.3	O
)	O
	
–	O
	
(	O
8	O
,	O
8.3	O
)	O
	
–	O
	
(	O
9	O
,	O
7.3	O
)	O
–	O
(	O
8	O
,	O
6.3	O
)	O
	
–	O
	
(	O
7	O
,	O
6.3	O
)	O
	
–	O
	
(	O
7	O
,	O
8.3	O
)	O
;	O
[	O
]	O
at	O
(	O
7.75	O
,	O
7.3	O
)	O
;	O
[	O
fill	O
=	O
red!10	O
]	O
	
(	O
8	O
,	O
2.3	O
)	O
	
–	O
	
(	O
9	O
,	O
2.3	O
)	O
	
–	O
	
(	O
9	O
,	O
0.3	O
)	O
	
–	O
	
(	O
8	O
,	O
0.3	O
	
)	O
–	O
(	O
7	O
,	O
1.3	O
)	O
	
–	O
	
(	O
8	O
,	O
2.3	O
)	O
;	O
[	O
]	O
at	O
(	O
8.25	O
,	O
1.3	O
)	O
;	O
[	O
-	O
¿	O
]	O
(	O
7	O
,	O
1.3	O
)	O
–	O
	
(	O
6	O
,	O
1.3	O
)	O
	
–	O
	
(	O
6	O
,	O
2.1	O
)	O
	
–	O
(	O
4.7	O
,	O
2.1	O
)	O
;	O
[	O
-	O
¿	O
]	O
(	O
6	O
,	O
1.3	O
)	O
–	O
	
(	O
6	O
,	O
0.5	O
)	O
–	O
(	O
4.7	O
,	O
0.5	O
)	O
	
;	O
[	O
fill	O
=	O
red!10	O
]	O
	
(	O
23.5	O
,	O
5.6	O
)	O
	
–	O
	
(	O
22.5	O
,	O
5.6	O
)	O
	
–	O
	
(	O
22.5	O
,	O
3.6	O
)	O
	
–	O
	
(	O
23.5	O
,	O
3.6	O
)	O
–	O
	
(	O
24.5	O
,	O
4.6	O
)	O
–	O
(	O
23.5	O
,	O
5.6	O
)	O
;	O
[	O
]	O
at	O
(	O
23.25	O
,	O
4.6	O
)	O
;	O
[	O
-	O
¿	O
]	O
	
(	O
21.2	O
,	O
5.75	O
)	O
–	O
(	O
21.5	O
,	O
5.75	O
	
)	O
–	O
	
(	O
21.5	O
,	O
5.2	O
)	O
–	O
	
(	O
22.5	O
,	O
5.2	O
)	O
;	O
[	O
-	O
¿	O
]	O
	
(	O
21.2	O
,	O
3.45	O
)	O
–	O
	
(	O
21.5	O
,	O
3.45	O
)	O
	
–	O
	
(	O
21.5	O
,	O
4.2	O
)	O
–	O
(	O
22.5	O
,	O
4.2	O
)	O
	
;	O
[	O
fill	O
=	O
	
yellow!30	O
]	O
	
(	O
28	O
,	O
4.6	O
)	O
ellipse	O
(	O
2.5	O
and	O
0.9	O
)	O
node	O
[	O
]	O
node	O
[	O
above	O
,	O
inner	O
sep=11pt	O
]	O
	
adversarial	B-Metric
cost	I-Metric
;	O
[	O
-	O
¿	O
]	O
	
(	O
24.5	O
,	O
4.6	O
)	O
–	O
(	O
25.5	O
,	O
4.6	O
)	O
;	O
	
section	O
:	O
Methodology	O
	
Our	O
model	O
,	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
consists	O
of	O
a	O
generator	B-Method
,	O
a	O
discriminator	B-Method
,	O
and	O
an	O
encoder	B-Method
,	O
which	O
are	O
implemented	O
as	O
neural	B-Method
networks	I-Method
.	O
	
The	O
input	O
vector	O
that	O
is	O
given	O
to	O
the	O
generator	B-Method
is	O
made	O
up	O
of	O
two	O
parts	O
.	O
	
Here	O
,	O
is	O
sampled	O
from	O
a	O
uniform	O
distribution	O
,	O
,	O
and	O
is	O
used	O
to	O
represent	O
unstructured	O
noise	O
in	O
the	O
images	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
is	O
the	O
part	O
of	O
the	O
representation	O
that	O
encodes	O
meaningful	O
information	O
in	O
a	O
disentangled	O
manner	O
and	O
is	O
made	O
up	O
of	O
both	O
categorical	O
values	O
and	O
continuous	O
values	O
.	O
	
takes	O
as	O
input	O
and	O
transforms	O
it	O
into	O
an	O
image	O
,	O
i.e.	O
.	O
is	O
a	O
convolutional	B-Method
network	I-Method
that	O
gets	O
as	O
input	O
either	O
real	O
or	O
fake	O
images	O
and	O
encodes	O
them	O
into	O
a	O
latent	B-Method
representation	I-Method
.	O
	
gets	O
as	O
input	O
an	O
image	O
and	O
the	O
corresponding	O
representation	O
concatenated	O
along	O
the	O
channel	O
axis	O
.	O
	
It	O
then	O
tries	O
to	O
classify	O
the	O
pair	O
as	O
coming	O
either	O
from	O
the	O
generator	B-Method
or	O
the	O
encoder	B-Method
,	O
i.e.	O
,	O
while	O
both	O
and	O
try	O
to	O
fool	O
the	O
discriminator	O
into	O
misclassifying	O
its	O
input	O
.	O
	
As	O
a	O
result	O
the	O
original	O
GAN	B-Method
minimax	O
game	O
is	O
extended	O
and	O
becomes	O
:	O
where	O
is	O
the	O
adversarial	O
cost	O
as	O
depicted	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
[	O
b	O
]	O
0.8	O
[	O
b	O
]	O
0.8	O
	
In	O
order	O
to	O
force	O
the	O
generator	O
to	O
use	O
the	O
information	O
provided	O
in	O
we	O
maximize	O
the	O
mutual	O
information	O
between	O
and	O
.	O
	
Maximizing	O
the	O
mutual	O
information	O
directly	O
is	O
hard	O
,	O
as	O
it	O
requires	O
the	O
posterior	O
and	O
we	O
therefore	O
follow	O
the	O
approach	O
by	O
Chen	O
et	O
al	O
.	O
and	O
define	O
an	O
auxiliary	B-Method
distribution	I-Method
to	O
approximate	O
.	O
	
We	O
then	O
maximize	O
the	O
lower	O
bound	O
,	O
where	O
is	O
the	O
mutual	O
information	O
depicted	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
For	O
simplicity	O
reasons	O
we	O
fix	O
the	O
distribution	O
over	O
and	O
,	O
therefore	O
,	O
the	O
entropy	O
term	O
is	O
treated	O
as	O
a	O
constant	O
.	O
	
In	O
our	O
case	O
is	O
the	O
encoder	B-Method
network	I-Method
which	O
gets	O
images	O
generated	O
by	O
as	O
input	O
and	O
is	O
trained	O
to	O
approximate	O
the	O
unknown	O
posterior	O
.	O
	
For	O
categorical	O
we	O
use	O
the	O
softmax	O
nonlinearity	O
to	O
represent	O
while	O
we	O
treat	O
the	O
posterior	O
of	O
continuous	O
as	O
a	O
factored	B-Method
Gaussian	I-Method
.	O
	
Given	O
this	O
structure	O
,	O
the	O
minimax	B-Method
game	I-Method
for	O
the	O
Bidirectional	B-Method
-	I-Method
InfoGAN	I-Method
(	O
BInfoGAN	B-Method
)	O
is	O
then	O
where	O
determines	O
the	O
strength	O
of	O
the	O
impact	O
of	O
the	O
mutual	B-Metric
information	I-Metric
criterion	I-Metric
and	O
is	O
set	O
to	O
in	O
all	O
our	O
experiments	O
.	O
	
section	O
:	O
Experiments	O
	
We	O
perform	O
experiments	O
on	O
the	O
MNIST	B-Material
,	O
the	O
CelebA	O
,	O
and	O
the	O
SVHN	O
data	O
set	O
.	O
	
While	O
the	O
final	O
performance	O
of	O
the	O
model	O
is	O
likely	O
influenced	O
by	O
choosing	O
the	O
“	O
optimal	O
”	O
characteristics	O
for	O
this	O
is	O
usually	O
not	O
possible	O
,	O
since	O
we	O
do	O
not	O
know	O
all	O
data	O
-	O
generating	O
factors	O
beforehand	O
.	O
	
When	O
choosing	O
the	O
characteristics	O
and	O
dimensionality	O
of	O
the	O
disentangled	O
vector	O
we	O
therefore	O
mostly	O
stick	O
with	O
the	O
values	O
previously	O
chosen	O
by	O
Chen	O
et	O
al	O
.	O
.	O
	
For	O
further	O
information	O
on	O
the	O
network	B-Method
architectures	I-Method
and	O
more	O
examples	O
of	O
the	O
learned	O
characteristics	O
on	O
the	O
different	O
data	O
sets	O
see	O
our	O
Git	O
:	O
.	O
	
[	O
b	O
]	O
0.8	O
[	O
b	O
]	O
0.8	O
On	O
the	O
MNIST	B-Material
data	I-Material
set	I-Material
we	O
model	O
the	O
latent	O
code	O
with	O
one	O
categorical	O
variable	O
and	O
two	O
continuous	O
variables	O
.	O
	
During	O
the	O
optimization	B-Task
process	I-Task
and	O
without	O
the	O
use	O
of	O
any	O
labels	O
the	O
encoder	B-Method
learns	O
to	O
use	O
to	O
encode	O
different	O
digit	O
classes	O
,	O
while	O
and	O
encode	O
stroke	O
width	O
and	O
digit	O
rotation	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
images	O
randomly	O
sampled	O
from	O
the	O
test	O
set	O
according	O
to	O
the	O
ten	O
different	O
categorical	O
values	O
.	O
	
We	O
can	O
see	O
that	O
the	O
encoder	O
has	O
learned	O
to	O
reliably	O
assign	O
a	O
different	O
categorical	O
value	O
for	O
different	O
digits	O
.	O
	
Indeed	O
,	O
by	O
manually	O
matching	O
the	O
different	O
categories	O
in	O
to	O
a	O
digit	O
type	O
,	O
we	O
achieve	O
a	O
test	O
set	O
accuracy	B-Metric
of	O
96.61	O
%	O
(	O
,	O
averaged	O
over	O
10	O
independent	O
runs	O
)	O
without	O
ever	O
using	O
labels	O
during	O
the	O
training	O
,	O
compared	O
to	O
Chen	O
et	O
al	O
.	O
	
(	O
unsupervised	O
)	O
with	O
an	O
accuracy	B-Metric
of	O
95	O
%	O
,	O
and	O
Zhang	O
et	O
al	O
.	O
	
(	O
semi	B-Task
-	I-Task
supervised	I-Task
,	O
20	O
labels	O
)	O
with	O
an	O
accuracy	B-Metric
of	O
96	O
%	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
images	O
sampled	O
from	O
the	O
test	O
set	O
for	O
different	O
values	O
of	O
	
and	O
.	O
	
We	O
see	O
that	O
we	O
can	O
use	O
the	O
encodings	O
from	O
to	O
now	O
sample	O
for	O
digits	O
with	O
certain	O
characteristics	O
such	O
as	O
stroke	O
width	O
and	O
rotation	O
,	O
even	O
though	O
this	O
information	O
was	O
not	O
explicitly	O
provided	O
during	O
training	O
.	O
	
On	O
the	O
CelebA	O
data	O
set	O
the	O
latent	O
code	O
is	O
modeled	O
with	O
four	O
categorical	O
codes	O
and	O
four	O
continuous	O
variables	O
.	O
	
Again	O
,	O
the	O
encoder	B-Method
learns	O
to	O
associate	O
certain	O
image	O
characteristics	O
with	O
specific	O
codes	O
in	O
.	O
	
This	O
includes	O
characteristics	O
such	O
as	O
the	O
presence	O
of	O
glasses	O
,	O
hair	O
color	O
,	O
and	O
background	O
color	O
and	O
is	O
visualized	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
On	O
the	O
SVHN	O
data	O
set	O
we	O
use	O
the	O
same	O
network	B-Method
architecture	I-Method
and	O
latent	B-Method
code	I-Method
representations	I-Method
as	O
for	O
the	O
CelebA	O
data	O
set	O
.	O
	
Again	O
,	O
the	O
encoder	B-Method
learns	O
interpretable	O
,	O
disentangled	O
representations	O
encoding	O
characteristics	O
such	O
as	O
image	O
background	O
,	O
contrast	O
and	O
digit	O
type	O
.	O
	
See	O
Fig	O
.	O
	
[	O
reference	O
]	O
for	O
examples	O
sampled	O
from	O
the	O
SVHN	O
test	O
set	O
.	O
	
These	O
results	O
indicate	O
that	O
the	O
Bidirectional	B-Method
-	I-Method
InfoGAN	I-Method
is	O
indeed	O
capable	O
of	O
mapping	O
data	O
points	O
into	O
disentangled	B-Method
representations	I-Method
that	O
encode	O
meaningful	O
characteristics	O
in	O
a	O
completely	O
unsupervised	B-Method
manner	I-Method
.	O
	
section	O
:	O
Conclusion	O
	
We	O
showed	O
that	O
an	O
encoder	B-Method
coupled	O
with	O
a	O
generator	B-Method
in	O
a	O
Generative	B-Method
Adversarial	I-Method
Network	I-Method
can	O
learn	O
disentangled	B-Method
representations	I-Method
of	O
the	O
data	O
without	O
the	O
need	O
for	O
any	O
explicit	O
labels	O
.	O
	
Using	O
the	O
encoder	B-Method
network	I-Method
we	O
maximize	O
the	O
mutual	O
information	O
between	O
certain	O
parts	O
of	O
the	O
generator	O
	
’s	O
input	O
and	O
the	O
images	O
that	O
are	O
generated	O
from	O
it	O
.	O
	
Through	O
this	O
the	O
generator	O
learns	O
to	O
associate	O
certain	O
image	O
characteristics	O
with	O
specific	O
parts	O
of	O
its	O
input	O
.	O
	
Additionally	O
,	O
the	O
adversarial	O
cost	O
from	O
the	O
discriminator	B-Method
forces	O
both	O
the	O
generator	B-Method
to	O
generate	O
realistic	O
looking	O
images	O
and	O
the	O
encoder	B-Method
to	O
approximate	O
the	O
inverse	O
of	O
the	O
generator	O
,	O
leading	O
to	O
disentangled	B-Method
representations	I-Method
that	O
can	O
be	O
used	O
for	O
inference	B-Task
.	O
	
The	O
learned	O
characteristics	O
are	O
often	O
meaningful	O
and	O
humanly	O
interpretable	O
,	O
and	O
can	O
potentially	O
help	O
with	O
other	O
tasks	O
such	O
as	O
classification	B-Task
and	O
clustering	O
.	O
	
Additionally	O
,	O
our	O
method	O
can	O
be	O
used	O
as	O
a	O
pre	B-Task
-	I-Task
training	I-Task
step	I-Task
on	O
unlabeled	O
data	O
sets	O
,	O
where	O
it	O
can	O
lead	O
to	O
better	O
representations	O
for	O
the	O
final	O
task	O
.	O
	
However	O
,	O
currently	O
we	O
have	O
no	O
influence	O
over	O
which	O
characteristics	O
are	O
learned	O
in	O
the	O
unsupervised	B-Task
setting	I-Task
which	O
means	O
that	O
the	O
model	O
can	O
also	O
learn	O
characteristics	O
or	O
features	O
that	O
are	O
meaningless	O
or	O
not	O
interpretable	O
by	O
humans	O
.	O
	
In	O
the	O
future	O
,	O
this	O
can	O
be	O
mitigated	O
by	O
combining	O
our	O
approach	O
with	O
semi	B-Method
-	I-Method
supervised	I-Method
approaches	I-Method
,	O
in	O
which	O
we	O
can	O
supply	O
a	O
limited	O
amount	O
of	O
labels	O
for	O
the	O
characteristics	O
we	O
are	O
interested	O
in	O
to	O
exert	O
more	O
control	O
over	O
which	O
data	O
-	O
generating	O
factors	O
are	O
learned	O
while	O
still	O
being	O
able	O
to	O
discover	O
“	O
new	O
”	O
generating	O
factors	O
which	O
do	O
not	O
have	O
to	O
be	O
known	O
or	O
specified	O
beforehand	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Taking	O
a	O
Deeper	O
Look	O
at	O
Pedestrians	O
	
In	O
this	O
paper	O
we	O
study	O
the	O
use	O
of	O
convolutional	B-Method
neural	I-Method
networks	I-Method
(	O
convnets	B-Method
)	O
for	O
the	O
task	O
of	O
pedestrian	B-Task
detection	I-Task
.	O
	
Despite	O
their	O
recent	O
diverse	O
successes	O
,	O
convnets	B-Method
historically	O
underperform	O
compared	O
to	O
other	O
pedestrian	B-Method
detectors	I-Method
.	O
	
We	O
deliberately	O
omit	O
explicitly	O
modelling	O
the	O
problem	O
into	O
the	O
network	O
(	O
e.g.	O
parts	O
or	O
occlusion	B-Method
modelling	I-Method
)	O
and	O
show	O
that	O
we	O
can	O
reach	O
competitive	O
performance	O
without	O
bells	O
and	O
whistles	O
.	O
	
In	O
a	O
wide	O
range	O
of	O
experiments	O
we	O
analyse	O
small	O
and	O
big	O
convnets	O
,	O
their	O
architectural	O
choices	O
,	O
parameters	O
,	O
and	O
the	O
influence	O
of	O
different	O
training	O
data	O
,	O
including	O
pre	B-Method
-	I-Method
training	I-Method
on	O
surrogate	B-Task
tasks	I-Task
.	O
	
We	O
present	O
the	O
best	O
convnet	B-Method
detectors	I-Method
on	O
the	O
Caltech	B-Material
and	O
KITTI	O
dataset	O
.	O
	
On	O
Caltech	B-Material
our	O
convnets	B-Method
reach	O
top	O
performance	O
both	O
for	O
the	O
Caltech1x	B-Material
and	O
Caltech10x	B-Material
training	O
setup	O
.	O
	
Using	O
additional	O
data	O
at	O
training	O
time	O
our	O
strongest	O
convnet	B-Method
model	I-Method
is	O
competitive	O
even	O
to	O
detectors	B-Method
that	O
use	O
additional	O
data	O
(	O
optical	O
flow	O
)	O
at	O
test	O
time	O
.	O
=	O
-	O
1	O
	
section	O
:	O
Introduction	O
	
In	O
recent	O
years	O
the	O
field	O
of	O
computer	B-Task
vision	I-Task
has	O
seen	O
an	O
explosion	O
of	O
success	O
stories	O
involving	O
convolutional	B-Method
neural	I-Method
networks	I-Method
(	O
convnets	B-Method
)	O
.	O
	
Such	O
architectures	O
currently	O
provide	O
top	O
results	O
for	O
general	B-Task
object	I-Task
classification	I-Task
,	O
general	B-Task
object	I-Task
detection	I-Task
,	O
feature	B-Task
matching	I-Task
,	O
stereo	B-Task
matching	I-Task
,	O
scene	B-Task
recognition	I-Task
,	O
pose	B-Task
estimation	I-Task
,	O
action	B-Task
recognition	I-Task
and	O
many	O
other	O
tasks	O
.	O
	
Pedestrian	B-Task
detection	I-Task
is	O
a	O
canonical	O
case	O
of	O
object	B-Task
detection	I-Task
with	O
relevant	O
applications	O
in	O
car	B-Task
safety	I-Task
,	O
surveillance	B-Task
,	O
and	O
robotics	B-Task
.	O
	
A	O
diverse	O
set	O
of	O
ideas	O
has	O
been	O
explored	O
for	O
this	O
problem	O
and	O
established	O
benchmark	O
datasets	O
are	O
available	O
.	O
	
We	O
would	O
like	O
to	O
know	O
if	O
the	O
success	O
of	O
convnets	B-Method
is	O
transferable	O
to	O
the	O
pedestrian	B-Task
detection	I-Task
task	O
.	O
	
Previous	O
work	O
on	O
neural	B-Method
networks	I-Method
for	O
pedestrian	B-Task
detection	I-Task
has	O
relied	O
on	O
special	B-Method
-	I-Method
purpose	I-Method
designs	I-Method
,	O
e.g.	O
hand	O
-	O
crafted	O
features	O
,	O
part	B-Method
and	I-Method
occlusion	I-Method
modelling	I-Method
.	O
	
Although	O
these	O
proposed	O
methods	O
perform	O
ably	O
,	O
current	O
top	B-Method
methods	I-Method
are	O
all	O
based	O
on	O
decision	O
trees	O
learned	O
via	O
Adaboost	B-Method
.	O
	
In	O
this	O
work	O
we	O
revisit	O
the	O
question	O
,	O
and	O
show	O
that	O
both	O
small	O
and	O
large	O
vanilla	B-Method
convnets	I-Method
can	O
reach	O
top	O
performance	O
on	O
the	O
challenging	O
Caltech	B-Material
pedestrians	O
dataset	O
.	O
	
We	O
provide	O
extensive	O
experiments	O
regarding	O
the	O
details	O
of	O
training	B-Task
,	O
network	O
parameters	O
,	O
and	O
different	O
proposal	B-Method
methods	I-Method
.	O
	
subsection	O
:	O
Related	O
work	O
	
Despite	O
the	O
popularity	O
of	O
the	O
task	O
of	O
pedestrian	B-Task
detection	I-Task
,	O
only	O
few	O
works	O
have	O
applied	O
deep	B-Method
neural	I-Method
networks	I-Method
to	O
this	O
task	O
:	O
we	O
are	O
aware	O
of	O
only	O
six	O
.	O
	
The	O
first	O
paper	O
using	O
convnets	B-Method
for	O
pedestrian	B-Task
detection	I-Task
focuses	O
on	O
how	O
to	O
handle	O
the	O
limited	O
training	O
data	O
(	O
they	O
use	O
the	O
INRIA	O
dataset	O
,	O
which	O
provides	O
614	O
positives	O
and	O
1218	O
negative	O
images	O
for	O
training	O
)	O
.	O
	
First	O
,	O
each	O
layer	O
is	O
initialized	O
using	O
a	O
form	O
of	O
convolutional	B-Method
sparse	I-Method
coding	I-Method
,	O
and	O
the	O
entire	O
network	O
is	O
subsequently	O
fine	O
-	O
tuned	O
for	O
the	O
detection	B-Task
task	I-Task
.	O
	
They	O
propose	O
an	O
architecture	O
that	O
uses	O
features	O
from	O
the	O
last	O
and	O
second	O
last	B-Method
layer	I-Method
for	O
detection	B-Task
.	O
	
This	O
method	O
is	O
named	O
ConvNet	B-Method
.	O
	
A	O
different	O
line	O
of	O
work	O
extends	O
a	O
deformable	B-Method
parts	I-Method
model	I-Method
(	O
DPM	B-Method
)	O
with	O
a	O
stack	B-Method
of	I-Method
Restricted	I-Method
Boltzmann	I-Method
Machines	I-Method
(	O
RBMs	B-Method
)	O
trained	O
to	O
reason	O
about	O
parts	O
and	O
occlusion	O
(	O
DBN	B-Method
-	I-Method
Isol	I-Method
)	O
.	O
	
This	O
model	O
was	O
extended	O
to	O
account	O
for	O
person	B-Task
-	I-Task
to	I-Task
-	I-Task
person	I-Task
relations	I-Task
(	O
DBN	B-Method
-	I-Method
Mut	I-Method
)	O
and	O
finally	O
to	O
jointly	O
optimize	O
all	O
these	O
aspects	O
:	O
JointDeep	B-Method
jointly	O
optimizes	O
features	O
,	O
parts	O
deformations	O
,	O
occlusions	O
,	O
and	O
person	O
-	O
to	O
-	O
person	O
relations	O
.	O
	
The	O
MultiSDP	B-Method
network	I-Method
feeds	O
each	O
layer	O
with	O
contextual	O
features	O
computed	O
at	O
different	O
scales	O
around	O
the	O
candidate	O
pedestrian	B-Task
detection	I-Task
.	O
	
Finally	O
SDN	B-Method
,	O
the	O
current	O
best	O
performing	O
convnet	B-Method
for	O
pedestrian	B-Task
detection	I-Task
,	O
uses	O
additional	O
‘	O
‘	O
switchable	O
layers	O
’	O
’	O
(	O
RBM	B-Method
variants	I-Method
)	O
to	O
automatically	O
learn	O
both	O
low	O
-	O
level	O
features	O
and	O
high	O
-	O
level	O
parts	O
(	O
e.g.	O
	
‘	O
	
‘	O
head	O
’	O
’	O
,	O
	
‘	O
‘	O
legs	O
’	O
’	O
,	O
etc	O
.	O
)	O
.	O
	
Note	O
that	O
none	O
of	O
the	O
existing	O
papers	O
rely	O
on	O
a	O
‘	O
‘	O
straightforward	O
’	O
’	O
convolutional	B-Method
network	I-Method
similar	O
to	O
the	O
original	O
LeNet	O
(	O
layers	O
of	O
convolutions	B-Method
,	O
non	O
-	O
linearities	O
,	O
pooling	B-Method
,	O
inner	B-Method
products	I-Method
,	O
and	O
a	O
softmax	O
on	O
top	O
)	O
.	O
	
We	O
will	O
revisit	O
this	O
decision	O
in	O
this	O
paper	O
.	O
	
paragraph	O
:	O
Object	B-Task
detection	I-Task
	
Other	O
than	O
pedestrian	B-Task
detection	I-Task
,	O
related	O
convnets	B-Method
have	O
been	O
used	O
for	O
detection	O
of	O
ImageNet	O
and	O
Pascal	O
VOC	O
categories	O
.	O
	
The	O
most	O
successful	O
general	B-Method
object	I-Method
detectors	I-Method
are	O
based	O
on	O
variants	O
of	O
the	O
R	B-Method
-	I-Method
CNN	I-Method
framework	I-Method
.	O
	
Given	O
an	O
input	O
image	O
,	O
a	O
reduced	O
set	O
of	O
detection	O
proposals	O
is	O
created	O
,	O
and	O
these	O
are	O
then	O
evaluated	O
via	O
a	O
convnet	B-Method
.	O
	
This	O
is	O
essentially	O
a	O
two	O
-	O
stage	B-Method
cascade	I-Method
sliding	I-Method
window	I-Method
method	I-Method
.	O
	
See	O
for	O
a	O
review	O
of	O
recent	O
proposal	O
methods	O
.	O
	
paragraph	O
:	O
Detection	B-Task
proposals	O
	
The	O
most	O
popular	O
proposal	O
method	O
for	O
generic	B-Task
objects	I-Task
is	O
SelectiveSearch	B-Method
.	O
	
The	O
recent	O
review	O
also	O
points	O
out	O
EdgeBoxes	O
as	O
a	O
fast	O
and	O
effective	O
method	O
.	O
	
For	O
pedestrian	B-Task
detection	I-Task
DBN	O
-	O
Isol	O
and	O
DBN	B-Method
-	I-Method
Mut	I-Method
use	O
DPM	B-Method
for	O
proposals	O
.	O
	
JointDeep	B-Method
,	O
MultiSDP	B-Method
,	O
and	O
SDN	B-Method
use	O
a	O
HOG	B-Method
+	O
CSS	B-Method
+	O
linear	O
SVM	O
detector	O
(	O
similar	O
to	O
)	O
for	O
proposals	O
.	O
	
Only	O
ConvNet	B-Method
applies	O
a	O
convnet	B-Method
in	O
a	O
sliding	O
fashion	O
.	O
	
paragraph	O
:	O
Decision	B-Task
forests	I-Task
	
Most	O
methods	O
proposed	O
for	O
pedestrian	B-Task
detection	I-Task
do	O
not	O
use	O
convnets	B-Method
for	O
detection	B-Task
.	O
	
Leaving	O
aside	O
methods	O
that	O
use	O
optical	B-Method
flow	I-Method
,	O
the	O
current	O
top	O
performing	O
methods	O
(	O
on	O
Caltech	B-Material
and	O
KITTI	O
datasets	O
)	O
are	O
SquaresChnFtrs	B-Method
,	O
InformedHaar	B-Method
,	O
SpatialPooling	B-Method
,	O
LDCF	B-Method
,	O
and	O
Regionlets	B-Method
.	O
	
All	O
of	O
them	O
are	O
boosted	B-Method
decision	I-Method
forests	I-Method
,	O
and	O
can	O
be	O
considered	O
variants	O
of	O
the	O
integral	B-Method
channels	I-Method
features	I-Method
architecture	I-Method
.	O
	
Regionlets	B-Method
and	O
SpatialPooling	B-Method
use	O
an	O
large	O
set	O
of	O
features	O
,	O
including	O
HOG	B-Method
,	O
LBP	O
and	O
CSS	B-Method
,	O
while	O
SquaresChnFtrs	B-Method
,	O
InformedHaar	B-Method
,	O
and	O
LDCF	B-Method
build	O
over	O
HOG	B-Method
+	O
LUV	O
.	O
	
On	O
the	O
Caltech	B-Material
benchmark	O
,	O
the	O
best	O
convnet	B-Method
(	O
SDN	B-Method
)	O
is	O
outperformed	O
by	O
all	O
aforementioned	O
methods	O
.	O
	
paragraph	O
:	O
Input	O
to	O
convnets	O
	
It	O
is	O
important	O
to	O
highlight	O
that	O
ConvNet	B-Method
learns	O
to	O
predict	O
from	O
YUV	B-Method
input	O
pixels	O
,	O
whereas	O
all	O
other	O
methods	O
use	O
additional	O
hand	O
-	O
crafted	O
features	O
.	O
	
DBN	B-Method
-	I-Method
Isol	I-Method
and	O
DBN	B-Method
-	I-Method
Mut	I-Method
use	O
HOG	B-Method
features	O
as	O
input	O
.	O
	
MultiSDP	B-Method
uses	O
HOG	B-Method
+	O
CSS	B-Method
features	O
as	O
input	O
.	O
	
JointDeep	B-Method
and	O
SDN	B-Method
uses	O
YUV	B-Method
+	O
Gradients	B-Method
as	O
input	O
(	O
and	O
HOG	B-Method
+	O
CSS	B-Method
for	O
the	O
detection	B-Task
proposals	I-Task
)	O
.	O
	
We	O
will	O
show	O
in	O
our	O
experiments	O
that	O
good	O
performance	O
can	O
be	O
reached	O
using	O
RGB	B-Method
alone	O
,	O
but	O
we	O
also	O
show	O
that	O
more	O
sophisticated	O
inputs	O
systematically	O
improve	O
detection	B-Metric
quality	I-Metric
.	O
	
Our	O
data	O
indicates	O
that	O
the	O
antagonism	O
‘	O
‘	O
hand	O
-	O
crafted	O
features	O
versus	O
convnets	B-Method
’	O
’	O
is	O
an	O
illusion	O
.	O
	
subsection	O
:	O
Contributions	O
	
In	O
this	O
paper	O
we	O
propose	O
to	O
revisit	O
pedestrian	B-Task
detection	I-Task
with	O
convolutional	B-Method
neural	I-Method
networks	I-Method
by	O
carefully	O
exploring	O
the	O
design	O
space	O
(	O
number	O
of	O
layers	O
,	O
filter	O
sizes	O
,	O
etc	O
.	O
)	O
,	O
and	O
the	O
critical	O
implementation	O
choices	O
(	O
training	O
data	O
preprocessing	O
,	O
effect	O
of	O
detections	O
proposal	O
,	O
etc	O
.	O
)	O
.	O
	
We	O
show	O
that	O
both	O
small	O
(	O
parameters	O
)	O
and	O
large	O
(	O
parameters	O
)	O
networks	O
can	O
reach	O
good	O
performance	O
when	O
trained	O
from	O
scratch	O
(	O
even	O
when	O
using	O
the	O
same	O
data	O
as	O
previous	O
methods	O
)	O
.	O
	
We	O
also	O
show	O
the	O
benefits	O
of	O
using	O
extended	O
and	O
external	O
data	O
,	O
which	O
leads	O
to	O
the	O
strongest	O
single	O
-	O
frame	B-Method
detector	I-Method
on	O
Caltech	B-Material
.	O
	
We	O
report	O
the	O
best	O
known	O
performance	O
for	O
a	O
convnet	B-Method
on	O
the	O
challenging	O
Caltech	B-Material
dataset	O
(	O
improving	O
by	O
more	O
than	O
percent	O
points	O
)	O
,	O
and	O
the	O
first	O
convnet	O
results	O
on	O
the	O
KITTI	O
dataset	O
.	O
	
section	O
:	O
Training	O
data	O
	
It	O
is	O
well	O
known	O
that	O
for	O
convnets	B-Method
the	O
volume	O
of	O
training	O
data	O
is	O
quite	O
important	O
to	O
reach	O
good	O
performance	O
.	O
	
Below	O
are	O
the	O
datasets	O
we	O
consider	O
along	O
the	O
paper	O
.	O
	
paragraph	O
:	O
Caltech	B-Material
	
The	O
Caltech	B-Material
dataset	O
and	O
its	O
associated	O
benchmark	O
is	O
one	O
of	O
the	O
most	O
popular	O
pedestrian	B-Task
detection	I-Task
datasets	O
.	O
	
It	O
consists	O
of	O
videos	O
captured	O
from	O
a	O
car	O
traversing	O
U.S.	O
streets	O
under	O
good	O
weather	O
conditions	O
.	O
	
The	O
standard	O
training	O
set	O
in	O
the	O
‘	O
‘	O
Reasonable	O
’	O
’	O
setting	O
consists	O
of	O
frames	O
with	O
annotated	O
pedestrians	O
,	O
and	O
the	O
test	O
set	O
covers	O
frames	O
with	O
pedestrians	O
.	O
	
paragraph	O
:	O
Caltech	B-Material
validation	O
set	O
	
In	O
our	O
experiments	O
we	O
also	O
use	O
Caltech	B-Material
training	O
data	O
for	O
validation	B-Task
.	O
	
For	O
those	O
experiments	O
we	O
use	O
one	O
of	O
the	O
suggested	O
validation	O
splits	O
:	O
the	O
first	O
five	O
training	O
videos	O
are	O
used	O
for	O
validation	B-Task
training	I-Task
and	O
the	O
sixth	O
training	O
video	O
for	O
validation	B-Task
testing	I-Task
.	O
	
paragraph	O
:	O
Caltech10x	B-Material
	
Because	O
the	O
Caltech	B-Material
dataset	O
videos	O
are	O
fully	O
annotated	O
,	O
the	O
amount	O
of	O
training	O
data	O
can	O
be	O
increased	O
by	O
resampling	O
the	O
videos	O
.	O
	
Inspired	O
by	O
,	O
we	O
increase	O
the	O
training	O
data	O
tenfold	O
by	O
sampling	O
one	O
out	O
of	O
three	O
frames	O
(	O
instead	O
of	O
one	O
out	O
of	O
thirty	O
frames	O
in	O
the	O
standard	O
setup	O
)	O
.	O
	
This	O
yields	O
annotated	O
pedestrians	O
for	O
training	O
,	O
extracted	O
from	O
frames	O
.	O
	
paragraph	O
:	O
KITTI	O
	
The	O
KITTI	O
dataset	O
consists	O
of	O
videos	O
captured	O
from	O
a	O
car	O
traversing	O
German	O
streets	O
,	O
also	O
under	O
good	O
weather	O
conditions	O
.	O
	
Although	O
similar	O
in	O
appearance	O
to	O
Caltech	B-Material
,	O
it	O
has	O
been	O
shown	O
to	O
have	O
different	O
statistics	O
(	O
see	O
)	O
.	O
	
Its	O
training	O
set	O
contains	O
pedestrians	O
(	O
taller	O
than	O
pixels	O
)	O
over	O
frames	O
,	O
and	O
its	O
test	O
set	O
frames	O
.	O
	
paragraph	O
:	O
ImageNet	O
,	O
Places	O
	
In	O
section	O
[	O
reference	O
]	O
we	O
will	O
consider	O
using	O
large	B-Method
convnets	I-Method
that	O
can	O
exploit	O
pre	B-Method
-	I-Method
training	I-Method
for	O
surrogate	B-Task
tasks	I-Task
.	O
	
We	O
consider	O
two	O
such	O
tasks	O
(	O
and	O
their	O
associated	O
datasets	O
)	O
,	O
the	O
ImageNet	B-Task
2012	I-Task
classification	I-Task
of	I-Task
a	I-Task
thousand	I-Task
object	I-Task
categories	I-Task
and	O
the	O
classification	B-Task
of	I-Task
scene	I-Task
categories	I-Task
.	O
	
The	O
datasets	O
provide	O
and	O
annotated	O
images	O
for	O
training	O
,	O
respectively	O
.	O
	
section	O
:	O
From	O
decision	B-Task
forests	I-Task
to	O
neural	B-Method
networks	I-Method
	
Before	O
diving	O
into	O
the	O
experiments	O
,	O
it	O
is	O
worth	O
noting	O
that	O
the	O
proposal	B-Method
method	I-Method
we	O
are	O
using	O
can	O
be	O
converted	O
into	O
a	O
convnet	B-Method
so	O
that	O
the	O
overall	O
system	O
can	O
be	O
seen	O
as	O
a	O
cascade	B-Method
of	I-Method
two	I-Method
neural	I-Method
networks	I-Method
.	O
	
SquaresChnFtrs	B-Method
is	O
a	O
decision	B-Method
forest	I-Method
,	O
where	O
each	O
tree	O
node	O
pools	O
and	O
thresholds	O
information	O
from	O
one	O
out	O
of	O
several	O
feature	O
channels	O
.	O
	
As	O
mentioned	O
in	O
section	O
[	O
reference	O
]	O
it	O
is	O
common	O
practice	O
to	O
learn	O
pedestrian	B-Task
detection	I-Task
convnets	O
on	O
handcrafted	O
features	O
,	O
thus	O
the	O
feature	O
channels	O
need	O
not	O
be	O
part	O
of	O
the	O
conversion	O
.	O
	
In	O
this	O
case	O
,	O
a	O
decision	O
node	O
can	O
be	O
realised	O
using	O
(	O
i	O
)	O
a	O
fully	B-Method
connected	I-Method
layer	I-Method
with	O
constant	O
non	O
-	O
zero	O
weights	O
corresponding	O
to	O
the	O
original	O
pooling	O
region	O
and	O
zero	O
weights	O
elsewhere	O
,	O
(	O
ii	O
)	O
a	O
bias	B-Method
term	I-Method
that	O
applies	O
the	O
threshold	O
,	O
(	O
iii	O
)	O
and	O
a	O
sigmoid	B-Method
non	I-Method
-	I-Method
linearity	I-Method
that	O
yields	O
a	O
decision	O
.	O
	
A	O
two	B-Method
-	I-Method
layer	I-Method
network	I-Method
is	O
sufficient	O
to	O
model	O
a	O
level	O
-	O
2	O
decision	O
tree	O
given	O
the	O
three	O
simulated	O
node	O
outputs	O
.	O
	
Finally	O
,	O
the	O
weighted	O
sum	O
over	O
the	O
tree	O
decisions	O
can	O
be	O
modelled	O
with	O
yet	O
another	O
fully	B-Method
-	I-Method
connected	I-Method
layer	I-Method
.	O
	
The	O
mapping	O
from	O
SquaresChnFtrs	B-Method
to	O
a	O
deep	B-Method
neural	I-Method
network	I-Method
is	O
exact	O
:	O
evaluating	O
the	O
same	O
inputs	O
it	O
will	O
return	O
the	O
exact	O
same	O
outputs	O
.	O
	
What	O
is	O
special	O
about	O
the	O
resulting	O
network	O
is	O
that	O
it	O
has	O
not	O
been	O
trained	O
by	O
back	B-Method
-	I-Method
propagation	I-Method
,	O
but	O
by	O
Adaboost	B-Method
.	O
	
This	O
network	O
already	O
performs	O
better	O
than	O
the	O
best	O
known	O
convnet	B-Method
on	O
Caltech	B-Material
,	O
SDN	B-Method
.	O
	
Unfortunately	O
,	O
experiments	O
to	O
soften	O
the	O
non	O
-	O
linearities	O
and	O
use	O
back	B-Method
-	I-Method
propagation	I-Method
to	O
fine	O
-	O
tune	O
the	O
model	O
parameters	O
did	O
not	O
show	O
significant	O
improvements	O
.	O
	
section	O
:	O
Vanilla	B-Method
convolutional	I-Method
networks	I-Method
	
In	O
our	O
experience	O
many	O
convnet	B-Method
architectures	I-Method
and	O
training	O
hyper	O
-	O
parameters	O
do	O
not	O
enable	O
effective	O
learning	B-Method
for	O
diverse	B-Task
and	I-Task
challenging	I-Task
tasks	I-Task
.	O
	
It	O
is	O
thus	O
considered	O
best	O
practice	O
to	O
start	O
exploration	O
from	O
architectures	O
and	O
parameters	O
that	O
are	O
known	O
to	O
work	O
well	O
and	O
progressively	O
adapt	O
it	O
to	O
the	O
task	O
at	O
hand	O
.	O
	
This	O
is	O
the	O
strategy	O
of	O
the	O
following	O
sections	O
.	O
	
In	O
this	O
section	O
we	O
first	O
consider	O
CifarNet	B-Method
,	O
a	O
small	B-Method
network	I-Method
designed	O
to	O
solve	O
the	O
CIFAR	B-Task
-	I-Task
10	I-Task
classification	I-Task
problem	I-Task
(	O
objects	B-Task
categories	I-Task
,	O
colour	O
images	O
of	O
)	O
.	O
	
In	O
section	O
[	O
reference	O
]	O
we	O
consider	O
AlexNet	B-Method
,	O
a	O
network	O
that	O
has	O
times	O
more	O
parameters	O
than	O
CifarNet	B-Method
and	O
designed	O
to	O
solve	O
the	O
ILSVRC2012	B-Task
classification	I-Task
problem	I-Task
(	O
objects	B-Task
categories	I-Task
,	O
colour	O
images	O
of	O
VGA	O
resolution	O
)	O
.	O
	
Both	O
of	O
these	O
networks	O
were	O
introduced	O
in	O
and	O
are	O
re	O
-	O
implemented	O
in	O
the	O
open	O
source	O
Caffe	O
project	O
.	O
	
Although	O
pedestrian	B-Task
detection	I-Task
is	O
quite	O
a	O
different	O
task	O
than	O
CIFAR	O
-	O
10	O
,	O
we	O
decide	O
to	O
start	O
our	O
exploration	O
from	O
the	O
CifarNet	B-Method
,	O
which	O
provides	O
fair	O
performance	O
on	O
CIFAR	O
-	O
10	O
.	O
	
Its	O
architecture	O
is	O
depicted	O
in	O
figure	O
[	O
reference	O
]	O
,	O
unless	O
otherwise	O
specified	O
we	O
use	O
raw	O
RGB	O
input	O
.	O
	
We	O
first	O
discuss	O
how	O
to	O
use	O
the	O
CifarNet	B-Method
network	O
(	O
section	O
[	O
reference	O
]	O
)	O
.	O
	
This	O
naive	O
approach	O
already	O
improves	O
over	O
the	O
best	O
known	O
convnets	B-Method
(	O
section	O
[	O
reference	O
]	O
)	O
.	O
	
Sections	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
explore	O
the	O
design	O
space	O
around	O
CifarNet	B-Method
and	O
further	O
push	O
the	O
detection	B-Metric
quality	I-Metric
.	O
	
All	O
models	O
in	O
this	O
section	O
are	O
trained	O
using	O
Caltech	B-Material
data	O
only	O
(	O
see	O
section	O
[	O
reference	O
]	O
)	O
.	O
	
subsection	O
:	O
How	O
to	O
use	O
CifarNet	B-Method
?	O
	
Given	O
an	O
initial	O
network	O
specification	O
,	O
there	O
are	O
still	O
several	O
design	O
choices	O
that	O
affect	O
the	O
final	O
detection	B-Metric
quality	I-Metric
.	O
	
We	O
discuss	O
some	O
of	O
them	O
in	O
the	O
following	O
paragraphs	O
.	O
	
paragraph	O
:	O
Detection	B-Task
proposals	O
	
Unless	O
otherwise	O
specified	O
we	O
use	O
the	O
SquaresChnFtrs	B-Method
detector	I-Method
to	O
generate	O
proposals	O
because	O
,	O
at	O
the	O
time	O
of	O
writing	O
,	O
it	O
is	O
the	O
best	O
performing	O
pedestrian	B-Method
detector	I-Method
(	O
on	O
Caltech	B-Material
)	O
with	O
source	O
code	O
available	O
.	O
	
In	O
figure	O
[	O
reference	O
]	O
we	O
compare	O
SquaresChnFtrs	B-Method
against	O
EdgeBoxes	B-Method
,	O
a	O
state	O
of	O
the	O
art	O
class	B-Method
-	I-Method
agnostic	I-Method
proposal	I-Method
method	I-Method
.	O
	
Using	O
class	O
-	O
specific	O
proposals	O
allows	O
to	O
reduce	O
the	O
number	O
of	O
proposals	O
by	O
three	O
orders	O
of	O
magnitude	O
.	O
	
paragraph	O
:	O
Thresholds	O
for	O
positive	O
and	O
negative	O
samples	O
	
Given	O
both	O
training	O
proposals	O
and	O
ground	O
truth	O
(	O
GT	O
)	O
annotations	O
,	O
we	O
now	O
consider	O
which	O
training	O
label	O
to	O
assign	O
to	O
each	O
proposal	O
.	O
	
A	O
proposal	O
is	O
considered	O
to	O
be	O
a	O
positive	O
example	O
if	O
it	O
exceeds	O
a	O
certain	O
Intersection	B-Metric
-	I-Metric
over	I-Metric
-	I-Metric
Union	I-Metric
(	I-Metric
IoU	I-Metric
)	I-Metric
threshold	I-Metric
for	O
at	O
least	O
one	O
GT	O
annotation	O
.	O
	
It	O
is	O
considered	O
negative	O
if	O
it	O
does	O
not	O
exceed	O
a	O
second	O
IoU	O
threshold	O
for	O
any	O
GT	O
annotation	O
,	O
and	O
is	O
ignored	O
otherwise	O
.	O
	
We	O
find	O
that	O
using	O
GT	O
annotations	O
as	O
positives	O
is	O
beneficial	O
(	O
i.e.	O
not	O
applying	O
significant	O
jitter	O
)	O
.	O
	
paragraph	O
:	O
Model	O
window	O
size	O
	
A	O
typical	O
choice	O
for	O
pedestrian	B-Task
detectors	I-Task
is	O
a	O
model	O
window	O
of	O
in	O
which	O
the	O
pedestrian	O
occupies	O
an	O
area	O
of	O
.	O
	
It	O
is	O
unclear	O
that	O
this	O
is	O
the	O
ideal	O
input	O
size	O
for	O
convnets	B-Method
.	O
	
Despite	O
CifarNet	B-Method
being	O
designed	O
to	O
operate	O
over	O
,	O
table	O
[	O
reference	O
]	O
shows	O
that	O
a	O
model	O
size	O
of	O
indeed	O
works	O
best	O
.	O
	
We	O
experimented	O
with	O
other	O
variants	O
(	O
stretching	O
versus	O
cropping	O
,	O
larger	O
context	O
border	O
)	O
with	O
no	O
clear	O
improvement	O
.	O
	
paragraph	O
:	O
Training	O
batch	O
	
In	O
a	O
detection	B-Task
setup	I-Task
,	O
training	O
samples	O
are	O
typically	O
highly	O
imbalanced	O
towards	O
the	O
background	O
class	O
.	O
	
Although	O
in	O
our	O
validation	O
setup	O
the	O
imbalance	O
is	O
limited	O
(	O
see	O
table	O
[	O
reference	O
]	O
)	O
,	O
we	O
found	O
it	O
beneficial	O
throughout	O
our	O
experiments	O
to	O
enforce	O
a	O
strict	O
ratio	O
of	O
positive	O
to	O
negative	O
examples	O
per	O
batch	O
of	O
the	O
stochastic	B-Method
gradient	I-Method
	
descend	B-Task
optimisation	I-Task
.	O
	
The	O
final	O
performance	O
is	O
not	O
sensitive	O
to	O
this	O
parameter	O
as	O
long	O
as	O
some	O
ratio	O
(	O
vs.	O
None	O
)	O
is	O
maintained	O
.	O
	
We	O
use	O
a	O
ratio	O
of	O
.	O
	
In	O
the	O
supplementary	O
material	O
we	O
detail	O
all	O
other	O
training	O
parameters	O
.	O
	
subsection	O
:	O
How	O
far	O
can	O
we	O
get	O
with	O
the	O
CifarNet	B-Method
?	O
	
Given	O
the	O
parameter	O
selection	O
on	O
the	O
validation	O
set	O
from	O
previous	O
sections	O
,	O
how	O
does	O
CifarNet	B-Method
compare	O
to	O
previously	O
reported	O
convnet	B-Method
results	O
on	O
the	O
Caltech	B-Material
test	O
set	O
?	O
	
In	O
table	O
[	O
reference	O
]	O
and	O
figure	O
[	O
reference	O
]	O
,	O
we	O
see	O
that	O
our	O
naive	B-Method
network	I-Method
right	O
away	O
improves	O
over	O
the	O
best	O
known	O
convnet	B-Method
(	O
versus	O
SDN	B-Method
)	O
.	O
	
To	O
decouple	O
the	O
contribution	O
of	O
our	O
strong	B-Method
SquaresChnFtrs	I-Method
proposals	I-Method
to	O
the	O
CifarNet	B-Method
performance	O
,	O
we	O
also	O
train	O
a	O
CifarNet	B-Method
using	O
the	O
proposal	O
from	O
JointDeep	B-Method
.	O
	
When	O
using	O
the	O
same	O
detection	O
proposals	O
at	O
training	O
and	O
test	O
time	O
,	O
the	O
vanilla	O
CifarNet	B-Method
already	O
improves	O
over	O
both	O
custom	O
-	O
designed	O
JointDeep	B-Method
and	O
SDN	B-Method
.	O
	
Our	O
CifarNet	B-Method
results	O
are	O
surprisingly	O
close	O
to	O
the	O
best	O
known	O
pedestrian	B-Method
detector	I-Method
trained	O
on	O
Caltech1x	B-Material
(	O
versus	O
SpatialPooling	B-Method
)	O
.	O
	
subsection	O
:	O
Exploring	O
different	O
architectures	O
	
Encouraged	O
by	O
our	O
initial	O
results	O
,	O
we	O
proceed	O
to	O
explore	O
different	O
parameters	O
for	O
the	O
CifarNet	B-Method
architecture	O
.	O
	
subsubsection	O
:	O
Number	O
and	O
size	O
of	O
convolutional	B-Method
filters	I-Method
	
Using	O
the	O
Caltech	B-Material
validation	O
set	O
we	O
perform	O
a	O
swipe	O
of	O
convolutional	O
filter	O
sizes	O
(	O
,	O
,	O
or	O
pixels	O
)	O
and	O
number	O
of	O
filters	O
at	O
each	O
layer	O
(	O
,	O
,	O
or	O
filters	O
)	O
.	O
	
We	O
include	O
the	O
full	O
table	O
in	O
the	O
supplementary	O
material	O
.	O
	
We	O
observe	O
that	O
using	O
large	O
filter	O
sizes	O
hurts	O
quality	B-Metric
,	O
while	O
the	O
varying	O
the	O
number	O
of	O
filters	O
shows	O
less	O
impact	O
.	O
	
Although	O
some	O
fluctuation	O
in	O
miss	B-Metric
-	I-Metric
rate	I-Metric
is	O
observed	O
,	O
overall	O
there	O
is	O
no	O
clear	O
trend	O
indicating	O
that	O
a	O
configuration	O
is	O
clearly	O
better	O
than	O
another	O
.	O
	
Thus	O
,	O
for	O
sake	O
of	O
simplicity	O
,	O
we	O
keep	O
using	O
CifarNet	B-Method
(	O
-	O
-	O
filters	O
of	O
pixel	O
)	O
in	O
the	O
subsequent	O
experiments	O
.	O
	
subsubsection	O
:	O
Number	O
and	O
type	O
of	O
layers	O
	
In	O
table	O
[	O
reference	O
]	O
we	O
evaluate	O
the	O
effect	O
of	O
changing	O
the	O
number	O
and	O
type	O
of	O
layers	O
,	O
while	O
keeping	O
other	O
CifarNet	B-Method
parameters	O
fix	O
.	O
	
Besides	O
convolutional	B-Method
layers	I-Method
(	O
CONV	B-Method
)	O
and	O
fully	B-Method
-	I-Method
connected	I-Method
layers	I-Method
(	O
FC	B-Method
)	O
,	O
we	O
also	O
consider	O
locally	B-Method
-	I-Method
connected	I-Method
layers	I-Method
(	O
LC	B-Method
)	O
,	O
and	O
concatenating	O
features	O
across	O
layers	O
(	O
CONCAT23	O
)	O
(	O
used	O
in	O
ConvNet	B-Method
)	O
.	O
	
None	O
of	O
the	O
considered	O
architecture	O
changes	O
improves	O
over	O
the	O
original	O
three	O
convolutional	B-Method
layers	I-Method
of	O
CifarNet	B-Method
.	O
	
subsection	O
:	O
Input	O
channels	O
	
As	O
discussed	O
in	O
section	O
[	O
reference	O
]	O
,	O
the	O
majority	O
of	O
previous	O
convnets	B-Method
for	O
pedestrian	B-Task
detection	I-Task
use	O
gradient	O
and	O
colour	O
features	O
as	O
input	O
,	O
instead	O
of	O
raw	O
RGB	O
.	O
	
In	O
table	O
[	O
reference	O
]	O
we	O
evaluate	O
the	O
effect	O
of	O
different	O
input	O
features	O
over	O
CifarNet	B-Method
.	O
	
It	O
seems	O
that	O
HOG	B-Method
+	O
L	O
channel	O
provide	O
a	O
small	O
advantage	O
over	O
RGB	O
.	O
	
For	O
purposes	O
of	O
direct	O
comparison	O
with	O
the	O
large	B-Method
networks	I-Method
,	O
in	O
the	O
next	O
sections	O
we	O
keep	O
using	O
raw	O
RGB	O
as	O
input	O
for	O
our	O
CifarNet	B-Method
experiments	O
.	O
	
We	O
report	O
the	O
CifarNet	B-Method
test	O
set	O
results	O
in	O
section	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
Large	B-Method
convolutional	I-Method
network	I-Method
	
One	O
appealing	O
characteristic	O
of	O
convnets	B-Method
is	O
their	O
ability	O
to	O
scale	O
in	O
size	O
of	O
training	O
data	O
volume	O
.	O
	
In	O
this	O
section	O
we	O
explore	O
larger	O
networks	O
trained	O
with	O
more	O
data	O
.	O
	
We	O
base	O
our	O
experiments	O
on	O
the	O
R	B-Method
-	I-Method
CNN	I-Method
[	I-Method
]	I-Method
approach	I-Method
,	O
which	O
is	O
currently	O
one	O
of	O
the	O
best	O
performer	O
on	O
the	O
Pascal	B-Task
VOC	I-Task
detection	I-Task
task	I-Task
.	O
	
We	O
are	O
thus	O
curious	O
to	O
evaluate	O
its	O
performance	O
for	O
pedestrian	B-Task
detection	I-Task
.	O
	
subsection	O
:	O
Surrogate	B-Method
tasks	I-Method
for	O
improved	O
detections	B-Task
	
The	O
R	B-Method
-	I-Method
CNN	I-Method
approach	I-Method
(	O
‘	O
‘	O
Regions	O
with	O
CNN	O
features	O
’	O
’	O
)	O
wraps	O
the	O
large	B-Method
network	I-Method
previously	O
trained	O
for	O
the	O
ImageNet	B-Task
classification	I-Task
task	I-Task
,	O
which	O
we	O
refer	O
to	O
as	O
AlexNet	B-Method
(	O
see	O
figure	O
[	O
reference	O
]	O
)	O
.	O
	
We	O
also	O
use	O
‘	O
‘	O
AlexNet	B-Method
’	O
’	O
as	O
shorthand	O
for	O
‘	O
	
‘	O
R	B-Method
-	I-Method
CNN	I-Method
with	O
AlexNet	B-Method
’	O
’	O
with	O
the	O
distinction	O
made	O
clear	O
by	O
the	O
context	O
.	O
	
During	O
R	O
-	O
CNN	O
training	O
AlexNet	B-Method
is	O
fine	O
-	O
tuned	O
for	O
the	O
(	B-Task
pedestrian	I-Task
)	I-Task
detection	I-Task
task	I-Task
,	O
and	O
in	O
a	O
second	O
step	O
,	O
the	O
softmax	O
output	O
is	O
replaced	O
by	O
a	O
linear	B-Method
SVM	I-Method
.	O
	
Unless	O
otherwise	O
specified	O
,	O
we	O
use	O
the	O
default	O
parameters	O
of	O
the	O
open	B-Method
source	I-Method
,	I-Method
Caffe	I-Method
based	I-Method
,	I-Method
R	I-Method
-	I-Method
CNN	I-Method
implementation	I-Method
.	O
	
Like	O
in	O
the	O
previous	O
sections	O
,	O
we	O
use	O
SquaresChnFtrs	B-Method
for	O
detection	B-Task
proposals	I-Task
.	O
	
paragraph	O
:	O
Pre	B-Task
-	I-Task
training	I-Task
	
If	O
we	O
only	O
train	O
the	O
top	B-Method
layer	I-Method
SVM	I-Method
,	O
without	O
fine	O
-	O
tuning	O
the	O
lower	O
layers	O
of	O
AlexNet	B-Method
,	O
we	O
obtain	O
on	O
the	O
Caltech	B-Material
test	O
set	O
.	O
	
This	O
is	O
already	O
surprisingly	O
close	O
to	O
the	O
best	O
known	O
convnet	B-Method
for	O
the	O
task	O
(	O
SDN	B-Method
)	O
.	O
	
When	O
fine	O
-	O
tuning	O
all	O
layers	O
on	O
Caltech	B-Material
,	O
the	O
test	O
set	O
performance	O
increases	O
dramatically	O
,	O
reaching	O
.	O
	
This	O
confirms	O
the	O
effectiveness	O
of	O
the	O
general	O
R	B-Method
-	I-Method
CNN	I-Method
recipe	I-Method
for	O
detection	B-Task
(	O
train	O
AlexNet	B-Method
on	O
ImageNet	O
,	O
fine	O
-	O
tune	O
for	O
the	O
task	O
of	O
interest	O
)	O
.	O
	
In	O
table	O
[	O
reference	O
]	O
we	O
investigate	O
the	O
influence	O
of	O
the	O
pre	B-Task
-	I-Task
training	I-Task
task	I-Task
by	O
considering	O
AlexNets	B-Method
that	O
have	O
been	O
trained	O
for	O
scene	B-Task
recognition	I-Task
(	O
‘	O
‘	O
Places	O
’	O
’	O
,	O
see	O
section	O
[	O
reference	O
]	O
)	O
and	O
on	O
both	O
Places	O
and	O
ImageNet	O
(	O
‘	O
‘	O
Hybrid	O
’	O
’	O
)	O
.	O
	
‘	O
	
‘	O
Places	O
’	O
’	O
provides	O
results	O
close	O
to	O
ImageNet	O
,	O
suggesting	O
that	O
the	O
exact	O
pre	B-Task
-	I-Task
training	I-Task
task	I-Task
is	O
not	O
critical	O
and	O
that	O
there	O
is	O
nothing	O
special	O
about	O
ImageNet	O
.	O
	
paragraph	O
:	O
Caltech10x	B-Material
	
Due	O
to	O
the	O
large	O
number	O
of	O
parameters	O
of	O
AlexNet	B-Method
,	O
we	O
consider	O
providing	O
additional	O
training	O
data	O
using	O
Caltech10x	B-Material
for	O
fine	O
-	O
tuning	O
the	O
network	O
(	O
see	O
section	O
[	O
reference	O
]	O
)	O
.	O
	
Despite	O
the	O
strong	O
correlation	O
across	O
training	O
samples	O
,	O
we	O
do	O
observe	O
further	O
improvement	O
(	O
see	O
table	O
[	O
reference	O
]	O
)	O
.	O
	
Interestingly	O
,	O
the	O
bulk	O
of	O
the	O
improvement	O
is	O
due	O
to	O
more	O
pedestrians	O
(	O
Positives10x	O
,	O
uses	O
positives	O
from	O
Caltech10x	B-Material
and	O
negatives	O
from	O
Caltech1x	B-Material
)	O
.	O
	
Our	O
top	O
result	O
,	O
,	O
makes	O
our	O
AlexNet	B-Method
setup	O
the	O
best	O
reported	O
single	B-Method
-	I-Method
frame	I-Method
detector	I-Method
on	O
Caltech	B-Material
(	O
i.e.	O
no	O
optical	O
flow	O
)	O
.	O
	
subsection	O
:	O
Caltech	B-Material
-	O
only	O
training	O
	
To	O
compare	O
with	O
CifarNet	B-Method
,	O
and	O
to	O
verify	O
whether	O
pre	B-Task
-	I-Task
training	I-Task
is	O
necessary	O
at	O
all	O
,	O
we	O
train	O
AlexNet	B-Method
	
‘	O
	
‘	O
from	O
scratch	O
’	O
’	O
using	O
solely	O
the	O
Caltech	B-Material
training	O
data	O
.	O
	
We	O
collect	O
results	O
in	O
table	O
[	O
reference	O
]	O
.	O
	
Training	O
AlexNet	B-Method
solely	O
on	O
Caltech	B-Material
,	O
yields	O
,	O
which	O
improves	O
over	O
the	O
proposals	O
(	O
SquaresChnFtrs	B-Method
)	O
and	O
the	O
previous	O
best	O
known	O
convnet	B-Method
on	O
Caltech	B-Material
(	O
SDN	B-Method
)	O
.	O
	
Using	O
Caltech10x	B-Material
further	O
improves	O
the	O
performance	O
,	O
down	O
to	O
.	O
	
Although	O
these	O
numbers	O
are	O
inferior	O
than	O
the	O
ones	O
obtained	O
with	O
ImageNet	B-Method
pre	I-Method
-	I-Method
training	I-Method
(	O
,	O
see	O
table	O
[	O
reference	O
]	O
)	O
,	O
we	O
can	O
get	O
surprisingly	O
competitive	O
results	O
using	O
only	O
pedestrian	B-Material
data	I-Material
despite	O
the	O
free	O
parameters	O
of	O
the	O
AlexNet	B-Method
model	O
.	O
	
AlexNet	B-Method
with	O
Caltech10x	B-Material
is	O
second	O
best	O
known	O
single	B-Method
-	I-Method
frame	I-Method
pedestrian	I-Method
detector	I-Method
on	O
Caltech	B-Material
(	O
best	O
known	O
is	O
LDCF	B-Method
,	O
which	O
also	O
uses	O
Caltech10x	B-Material
)	O
.	O
	
subsection	O
:	O
Additional	O
experiments	O
	
paragraph	O
:	O
How	O
many	O
layers	O
?	O
	
So	O
far	O
all	O
experiments	O
use	O
the	O
default	O
parameters	O
of	O
R	B-Method
-	I-Method
CNN	I-Method
.	O
	
Previous	O
works	O
have	O
reported	O
that	O
,	O
depending	O
on	O
the	O
task	O
,	O
using	O
features	O
from	O
lower	O
AlexNet	B-Method
layers	O
can	O
provide	O
better	O
results	O
.	O
	
Table	O
[	O
reference	O
]	O
reports	O
Caltech	B-Material
validation	O
results	O
when	O
training	O
the	O
SVM	B-Method
output	I-Method
layer	I-Method
on	O
top	O
of	O
layers	O
four	O
to	O
seven	O
(	O
see	O
figure	O
[	O
reference	O
]	O
)	O
.	O
	
We	O
report	O
results	O
when	O
using	O
the	O
default	O
parameters	O
and	O
parameters	O
that	O
have	O
been	O
optimised	O
by	O
grid	B-Method
search	I-Method
(	O
detailed	O
grid	B-Method
search	I-Method
included	O
in	O
supplementary	O
material	O
)	O
.	O
	
We	O
observe	O
a	O
negligible	O
difference	O
between	O
default	O
and	O
optimized	O
parameter	O
(	O
at	O
most	O
percent	O
points	O
)	O
.	O
	
Results	O
for	O
default	O
parameters	O
exhibit	O
a	O
slight	O
trend	O
of	O
better	O
performance	O
for	O
higher	O
levels	O
.	O
	
These	O
validation	O
set	O
results	O
indicate	O
that	O
,	O
for	O
pedestrian	B-Task
detection	I-Task
,	O
the	O
R	B-Method
-	I-Method
CNN	I-Method
default	I-Method
parameters	I-Method
are	O
a	O
good	O
choice	O
overall	O
.	O
	
paragraph	O
:	O
Effect	O
of	O
proposal	O
method	O
	
When	O
comparing	O
the	O
performance	O
of	O
AlexNet	B-Method
fine	O
-	O
tuned	O
on	O
Caltech1x	B-Material
to	O
the	O
proposal	B-Method
method	I-Method
,	O
we	O
see	O
an	O
improvement	O
of	O
(	O
percent	O
points	O
)	O
in	O
miss	B-Metric
-	I-Metric
rate	I-Metric
.	O
	
In	O
table	O
[	O
reference	O
]	O
we	O
study	O
the	O
impact	O
of	O
using	O
weaker	O
or	O
stronger	O
proposals	O
.	O
	
Both	O
ACF	B-Method
and	O
SquaresChnFtrs	B-Method
provide	O
source	O
code	O
,	O
allowing	O
us	O
to	O
generate	O
training	O
proposals	O
.	O
	
Katamari	B-Method
and	O
SpatialPooling	B-Method
+	I-Method
	
[	O
]	O
are	O
current	O
top	O
performers	O
on	O
the	O
Caltech	B-Material
dataset	O
,	O
both	O
using	O
optical	O
flow	O
,	O
i.e.	O
additional	O
information	O
at	O
test	O
time	O
.	O
	
There	O
is	O
a	O
gap	O
between	O
the	O
detectors	B-Method
ACF	I-Method
,	O
SquaresChnFtrs	B-Method
,	O
and	O
Katamari	B-Method
/	I-Method
SpatialPooling	I-Method
,	O
allowing	O
us	O
to	O
cover	O
different	O
operating	O
points	O
.	O
	
The	O
results	O
of	O
table	O
[	O
reference	O
]	O
indicate	O
that	O
,	O
despite	O
the	O
gap	O
,	O
there	O
is	O
no	O
noticeable	O
difference	O
between	O
AlexNet	B-Method
models	O
trained	O
with	O
ACF	B-Method
or	O
SquaresChnFtrs	B-Method
.	O
	
It	O
is	O
seems	O
that	O
as	O
long	O
as	O
the	O
proposals	O
are	O
not	O
random	O
(	O
see	O
top	O
row	O
of	O
table	O
[	O
reference	O
]	O
)	O
,	O
the	O
obtained	O
quality	B-Metric
is	O
rather	O
stable	O
.	O
	
The	O
results	O
also	O
indicate	O
that	O
the	O
quality	B-Metric
improvement	I-Metric
from	O
AlexNet	B-Method
saturates	O
around	O
.	O
	
Using	O
stronger	O
proposals	O
does	O
not	O
lead	O
to	O
further	O
improvement	O
.	O
	
This	O
means	O
that	O
the	O
discriminative	O
power	O
of	O
our	O
trained	O
AlexNet	B-Method
is	O
on	O
par	O
with	O
the	O
best	O
known	O
models	O
on	O
the	O
Caltech	B-Material
dataset	O
,	O
but	O
does	O
not	O
overtake	O
them	O
.	O
	
paragraph	O
:	O
KITTI	O
test	O
set	O
	
In	O
figure	O
[	O
reference	O
]	O
we	O
show	O
performance	O
of	O
the	O
AlexNet	B-Method
in	O
context	O
of	O
the	O
KITTI	O
pedestrian	B-Task
detection	I-Task
benchmark	O
.	O
	
The	O
network	O
is	O
pre	O
-	O
trained	O
on	O
ImageNet	O
and	O
fine	O
-	O
tuned	O
using	O
KITTI	O
training	O
data	O
.	O
	
SquaresChnFtrs	B-Method
reaches	O
(	O
average	B-Metric
precision	I-Metric
)	O
,	O
which	O
the	O
AlexNet	B-Method
can	O
improve	O
to	O
.	O
	
These	O
are	O
the	O
first	O
published	O
results	O
for	O
convnets	B-Task
on	O
the	O
KITTI	O
pedestrian	B-Task
detection	I-Task
dataset	O
.	O
	
subsection	O
:	O
Error	B-Method
analysis	I-Method
	
Results	O
from	O
the	O
previous	O
section	O
are	O
encouraging	O
,	O
but	O
not	O
as	O
good	O
as	O
could	O
be	O
expected	O
from	O
looking	O
at	O
improvements	O
on	O
Pascal	O
VOC	O
.	O
	
So	O
what	O
bounds	O
performance	O
?	O
	
The	O
proposal	O
method	O
?	O
	
The	O
localization	B-Metric
quality	I-Metric
of	O
the	O
convnet	B-Method
?	O
	
Looking	O
at	O
the	O
highest	O
scoring	O
false	O
positives	O
paints	O
a	O
picture	O
of	O
localization	B-Metric
errors	I-Metric
of	O
the	O
proposal	B-Method
method	I-Method
,	O
the	O
R	B-Method
-	I-Method
CNN	I-Method
,	O
and	O
even	O
the	O
ground	O
truth	O
.	O
	
To	O
quantify	O
this	O
effect	O
we	O
rerun	O
the	O
Caltech	B-Material
evaluation	O
but	O
remove	O
all	O
false	O
positives	O
that	O
touch	O
an	O
annotation	O
.	O
	
This	O
experiment	O
provides	O
an	O
upper	O
bound	O
on	O
performance	O
when	O
solving	O
localisation	B-Task
issues	I-Task
in	O
detectors	B-Task
and	O
doing	O
perfect	B-Task
non	I-Task
-	I-Task
maximum	I-Task
suppression	I-Task
.	O
	
We	O
see	O
a	O
surprisingly	O
consistent	O
improvement	O
for	O
all	O
methods	O
of	O
about	O
MR	B-Metric
.	O
	
This	O
means	O
that	O
the	O
intuition	O
we	O
gathered	O
from	O
looking	O
at	O
false	O
positives	O
is	O
wrong	O
and	O
actually	O
almost	O
all	O
of	O
the	O
mistakes	O
that	O
worsen	O
the	O
MR	B-Metric
are	O
actually	O
background	O
windows	O
that	O
are	O
mistaken	O
for	O
pedestrians	O
.	O
	
What	O
is	O
striking	O
about	O
this	O
result	O
is	O
that	O
this	O
is	O
not	O
just	O
the	O
case	O
for	O
our	O
R	B-Method
-	I-Method
CNN	I-Method
experiments	I-Method
on	O
detection	B-Task
proposals	I-Task
but	O
also	O
for	O
methods	O
that	O
are	O
trained	O
as	O
a	O
sliding	B-Method
window	I-Method
detector	I-Method
.	O
	
section	O
:	O
Small	O
or	O
big	O
convnet	O
?	O
	
Since	O
we	O
have	O
analysed	O
the	O
CifarNet	B-Method
and	O
AlexNet	B-Method
separately	O
,	O
we	O
compare	O
their	O
performance	O
in	O
this	O
section	O
side	O
by	O
side	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
performance	O
on	O
the	O
Caltech	B-Material
test	O
set	O
for	O
models	O
that	O
have	O
been	O
trained	O
only	O
on	O
Caltech1x	B-Material
and	O
Caltech10x	B-Material
.	O
	
With	O
less	O
training	O
data	O
the	O
CifarNet	B-Method
reaches	O
MR	B-Method
,	O
performing	O
2	O
percent	O
points	O
better	O
than	O
the	O
AlexNet	B-Method
.	O
	
On	O
Caltech10x	B-Material
,	O
we	O
find	O
the	O
CifarNet	B-Method
performance	O
improved	O
to	O
,	O
while	O
the	O
AlexNet	B-Method
improves	O
to	O
MR	B-Metric
.	O
	
The	O
trend	O
confirms	O
the	O
intuition	O
that	O
models	O
with	O
lower	O
capacity	O
saturate	O
earlier	O
when	O
increasing	O
the	O
amount	O
of	O
training	O
data	O
than	O
models	O
with	O
higher	O
capacity	O
.	O
	
We	O
can	O
also	O
conclude	O
that	O
the	O
AlexNet	B-Method
would	O
profit	O
from	O
better	O
regularisation	B-Method
when	O
training	O
on	O
Caltech1x	B-Material
.	O
	
paragraph	O
:	O
Timing	O
	
The	O
runtime	O
during	O
detection	B-Task
is	O
about	O
3ms	O
per	O
proposal	O
window	O
.	O
	
This	O
is	O
too	O
slow	O
for	O
sliding	B-Task
window	I-Task
detection	I-Task
,	O
but	O
given	O
a	O
fast	O
proposal	B-Method
method	I-Method
that	O
has	O
high	O
recall	B-Metric
with	O
less	O
than	O
windows	O
per	O
image	O
,	O
scoring	B-Task
takes	O
about	O
300ms	O
per	O
image	O
.	O
	
In	O
our	O
experience	O
SquaresChnFtrs	O
runs	O
in	O
2s	O
per	O
image	O
,	O
so	O
proposing	O
detections	O
takes	O
most	O
of	O
the	O
detection	B-Metric
time	I-Metric
.	O
	
section	O
:	O
Takeaways	O
	
Previous	O
work	O
suggests	O
that	O
convnets	B-Method
for	O
pedestrian	B-Task
detection	I-Task
underperform	O
,	O
despite	O
having	O
involved	O
architectures	O
(	O
see	O
for	O
a	O
survey	O
of	O
pedestrian	B-Task
detection	I-Task
)	O
.	O
	
In	O
this	O
paper	O
we	O
showed	O
that	O
neither	O
has	O
to	O
be	O
the	O
case	O
.	O
	
We	O
present	O
a	O
wide	O
range	O
of	O
experiments	O
with	O
two	O
off	O
-	O
the	O
-	O
shelf	B-Method
models	I-Method
that	O
reach	O
competitive	O
performance	O
:	O
the	O
small	O
CifarNet	B-Method
and	O
the	O
big	O
AlexNet	B-Method
.	O
	
We	O
present	O
two	O
networks	O
that	O
are	O
trained	O
on	O
Caltech	B-Material
only	O
,	O
which	O
outperform	O
all	O
previously	O
published	O
convnets	B-Method
on	O
Caltech	B-Material
.	O
	
The	O
CifarNet	B-Method
shows	O
better	O
performance	O
than	O
related	O
work	O
,	O
even	O
when	O
using	O
the	O
same	O
training	O
data	O
as	O
the	O
respective	O
methods	O
(	O
section	O
[	O
reference	O
]	O
)	O
.	O
	
Despite	O
its	O
size	O
,	O
the	O
AlexNet	B-Method
also	O
improves	O
over	O
all	O
convnets	B-Method
even	O
when	O
it	O
is	O
trained	O
on	O
Caltech	B-Material
only	O
(	O
section	O
[	O
reference	O
]	O
)	O
.	O
	
We	O
push	O
the	O
state	O
of	O
the	O
art	O
for	O
pedestrian	B-Task
detectors	I-Task
that	O
have	O
been	O
trained	O
on	O
Caltech1x	B-Material
and	O
Caltech10x	B-Material
.	O
	
The	O
CifarNet	B-Method
is	O
the	O
best	O
single	B-Method
-	I-Method
frame	I-Method
pedestrian	I-Method
detector	I-Method
that	O
has	O
been	O
trained	O
on	O
Caltech1x	B-Material
(	O
section	O
[	O
reference	O
]	O
)	O
,	O
while	O
AlexNet	B-Method
is	O
the	O
best	O
single	B-Method
-	I-Method
frame	I-Method
pedestrian	I-Method
detector	I-Method
trained	O
on	O
Caltech10x	B-Material
	
(	O
section	O
[	O
reference	O
]	O
)	O
.	O
	
In	O
figure	O
[	O
reference	O
]	O
,	O
we	O
include	O
include	O
all	O
published	O
methods	O
on	O
Caltech	B-Material
into	O
the	O
comparison	O
,	O
which	O
also	O
adds	O
methods	O
that	O
use	O
additional	O
information	O
at	O
test	O
time	O
.	O
	
The	O
AlexNet	B-Method
that	O
has	O
been	O
pre	O
-	O
trained	O
on	O
ImageNet	B-Method
reaches	O
competitive	O
results	O
to	O
the	O
best	O
published	O
methods	O
,	O
but	O
without	O
using	O
additional	O
information	O
at	O
test	O
time	O
(	O
section	O
[	O
reference	O
]	O
)	O
.	O
	
We	O
report	O
first	O
results	O
for	O
convnets	B-Task
on	O
the	O
KITTI	O
pedestrian	B-Task
detection	I-Task
benchmark	O
.	O
	
The	O
AlexNet	B-Method
improves	O
over	O
the	O
proposal	B-Method
method	I-Method
alone	O
,	O
delivering	O
encouraging	O
results	O
to	O
further	O
push	O
KITTI	B-Task
performance	O
with	O
convnets	B-Method
.	O
	
section	O
:	O
Conclusion	O
	
We	O
have	O
presented	O
extensive	O
and	O
systematic	O
experimental	O
evidence	O
on	O
the	O
effectiveness	O
of	O
convnets	B-Method
for	O
pedestrian	B-Task
detection	I-Task
.	O
	
Compared	O
to	O
previous	O
convnets	B-Method
applied	O
to	O
pedestrian	B-Task
detection	I-Task
our	O
approach	O
avoids	O
custom	O
designs	O
.	O
	
When	O
using	O
the	O
exact	O
same	O
proposals	O
and	O
training	O
data	O
as	O
previous	O
approaches	O
our	O
‘	O
‘	O
vanilla	B-Method
’	I-Method
’	I-Method
networks	I-Method
outperform	O
previous	O
results	O
.	O
	
We	O
have	O
shown	O
that	O
with	O
pre	B-Method
-	I-Method
training	I-Method
on	O
surrogate	B-Task
tasks	I-Task
,	O
convnets	B-Method
can	O
reach	O
top	O
performance	O
on	O
this	O
task	O
.	O
	
Interestingly	O
we	O
have	O
shown	O
that	O
even	O
without	O
pre	B-Method
-	I-Method
training	I-Method
competitive	O
results	O
can	O
be	O
achieved	O
,	O
and	O
this	O
result	O
is	O
quite	O
insensitive	O
to	O
the	O
model	O
size	O
(	O
from	O
to	O
parameters	O
)	O
.	O
	
Our	O
experiments	O
also	O
detail	O
which	O
parameters	O
are	O
most	O
critical	O
to	O
achieve	O
top	O
performance	O
.	O
	
We	O
report	O
the	O
best	O
known	O
results	O
for	O
convnets	B-Task
on	O
both	O
the	O
challenging	O
Caltech	B-Material
and	O
KITTI	O
datasets	O
.	O
	
Our	O
experience	O
with	O
convnets	B-Method
indicate	O
that	O
they	O
show	O
good	O
promise	O
on	O
pedestrian	B-Task
detection	I-Task
,	O
and	O
that	O
reported	O
best	O
practices	O
do	O
transfer	O
to	O
said	O
task	O
.	O
	
That	O
being	O
said	O
,	O
on	O
this	O
more	O
mature	O
field	O
we	O
do	O
not	O
observe	O
the	O
large	O
improvement	O
seen	O
on	O
datasets	O
such	O
as	O
Pascal	O
VOC	O
and	O
ImageNet	O
.	O
	
paragraph	O
:	O
Acknowledgements	O
	
We	O
thank	O
Shanshan	O
Zhang	O
for	O
the	O
help	O
provided	O
setting	O
up	O
some	O
of	O
the	O
experiments	O
.	O
	
bibliography	O
:	O
References	O
	
appendix	O
:	O
CifarNet	B-Method
training	O
,	O
the	O
devil	O
is	O
in	O
the	O
details	O
	
Training	B-Method
neural	I-Method
networks	I-Method
is	O
sensitive	O
to	O
a	O
large	O
number	O
of	O
parameters	O
,	O
including	O
the	O
learning	B-Metric
rate	I-Metric
,	O
how	O
the	O
network	O
weights	O
are	O
initialised	O
,	O
the	O
type	O
of	O
regularisation	B-Method
applied	O
to	O
the	O
weights	O
,	O
and	O
the	O
training	O
batch	O
size	O
.	O
	
It	O
is	O
difficult	O
to	O
isolate	O
the	O
effects	O
of	O
the	O
individual	O
parameters	O
,	O
and	O
the	O
best	O
parameters	O
will	O
largely	O
depend	O
on	O
the	O
specific	O
setup	O
.	O
	
We	O
report	O
here	O
the	O
parameters	O
we	O
used	O
.	O
	
We	O
train	O
CifarNet	B-Method
via	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
(	I-Method
SGD	I-Method
)	I-Method
with	O
a	O
learning	B-Metric
rate	I-Metric
of	O
,	O
a	O
momentum	O
of	O
,	O
and	O
a	O
batch	O
size	O
of	O
.	O
	
After	O
epochs	O
,	O
we	O
reduce	O
the	O
learning	B-Metric
rate	I-Metric
by	O
a	O
factor	O
of	O
and	O
train	O
for	O
an	O
additional	O
epochs	O
.	O
	
Reducing	O
the	O
learning	B-Metric
rate	I-Metric
even	O
further	O
did	O
not	O
improve	O
the	O
classification	B-Metric
accuracy	I-Metric
.	O
	
The	O
other	O
learning	B-Method
rate	I-Method
policies	I-Method
we	O
explored	O
yielded	O
inferior	O
performance	O
(	O
e.g.	O
gradually	O
reducing	O
the	O
learning	B-Metric
rate	I-Metric
each	O
training	O
iteration	O
)	O
.	O
	
Careful	O
tuning	O
of	O
the	O
learning	B-Metric
rate	I-Metric
while	O
adjusting	O
the	O
batch	O
size	O
was	O
critical	O
.	O
	
Other	O
than	O
the	O
softmax	O
classification	O
loss	O
,	O
the	O
training	B-Metric
loss	I-Metric
includes	O
a	O
regularisation	O
of	O
the	O
network	O
weights	O
.	O
	
In	O
the	O
objective	O
function	O
,	O
this	O
regularization	B-Method
term	I-Method
has	O
a	O
weight	O
of	O
for	O
all	O
layers	O
but	O
the	O
last	O
one	O
(	O
softmax	O
weights	O
)	O
,	O
which	O
receives	O
weight	O
.	O
	
This	O
parameter	O
is	O
referred	O
in	O
Caffe	O
as	O
‘	O
‘	O
weight	O
decay	O
’	O
’	O
.	O
	
The	O
network	O
weights	O
are	O
initialised	O
by	O
drawing	O
values	O
from	O
a	O
Gaussian	B-Method
distribution	I-Method
with	O
standard	O
deviation	O
,	O
with	O
the	O
exception	O
of	O
the	O
first	O
layer	O
,	O
for	O
which	O
we	O
set	O
.	O
	
appendix	O
:	O
Grid	B-Task
search	I-Task
around	O
CifarNet	B-Method
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
detection	B-Metric
quality	I-Metric
of	O
different	O
variants	O
of	O
CifarNet	B-Method
obtained	O
by	O
changing	O
the	O
number	O
and	O
size	O
of	O
the	O
convolutional	O
filters	O
of	O
each	O
layer	O
.	O
	
See	O
related	O
section	O
4.3.1	O
of	O
the	O
main	O
paper	O
.	O
	
Since	O
different	O
training	O
rounds	O
have	O
different	O
random	O
initial	O
weights	O
,	O
we	O
train	O
four	O
networks	O
for	O
each	O
parameter	O
set	O
and	O
average	O
the	O
results	O
.	O
	
We	O
report	O
both	O
mean	O
and	O
standard	O
deviation	O
of	O
the	O
miss	B-Metric
rate	I-Metric
on	O
our	O
validation	O
set	O
.	O
	
We	O
observe	O
that	O
using	O
either	O
too	O
small	O
or	O
too	O
large	O
filter	O
sizes	O
throughout	O
the	O
network	O
hurts	O
quality	B-Metric
.	O
	
The	O
network	O
width	O
also	O
seems	O
to	O
matter	O
,	O
a	O
network	O
too	O
narrow	O
or	O
too	O
wide	O
can	O
negatively	O
impact	O
classification	B-Metric
accuracy	I-Metric
.	O
	
All	O
and	O
all	O
the	O
	
‘	O
	
‘	O
middle	O
-	O
section	O
’	O
’	O
of	O
the	O
table	O
shows	O
only	O
small	O
fluctuations	O
in	O
miss	B-Metric
-	I-Metric
rate	I-Metric
(	O
specially	O
when	O
considering	O
the	O
variance	O
)	O
.	O
	
In	O
addition	O
to	O
filter	O
size	O
and	O
layer	O
width	O
,	O
we	O
also	O
experimented	O
with	O
different	O
types	O
of	O
pooling	B-Method
layers	I-Method
(	O
max	B-Method
-	I-Method
pooling	I-Method
versus	O
mean	B-Method
-	I-Method
pooling	I-Method
)	O
,	O
see	O
figure	O
2	O
of	O
main	O
paper	O
.	O
	
Other	O
than	O
on	O
the	O
first	O
layer	O
,	O
replacing	O
mean	B-Method
-	I-Method
pooling	I-Method
with	O
max	B-Method
-	I-Method
pooling	I-Method
hurts	O
performance	O
.	O
	
The	O
results	O
of	O
table	O
indicate	O
that	O
there	O
is	O
no	O
set	O
of	O
parameters	O
close	O
to	O
CifarNet	B-Method
with	O
a	O
clear	O
advantage	O
over	O
the	O
default	O
CifarNet	B-Method
parameters	O
.	O
	
When	O
going	O
too	O
far	O
from	O
CifarNet	B-Method
parameters	O
,	O
classification	B-Metric
accuracy	I-Metric
plunges	O
.	O
	
appendix	O
:	O
Grid	B-Task
search	I-Task
for	O
AlexNet	B-Method
	
Table	O
[	O
reference	O
]	O
presents	O
the	O
swipe	O
of	O
parameters	O
used	O
to	O
construct	O
the	O
‘	O
	
‘	O
Best	O
parameters	O
’	O
’	O
entries	O
in	O
table	O
8	O
of	O
the	O
main	O
paper	O
.	O
	
We	O
vary	O
the	O
criterion	O
to	O
select	O
negative	O
samples	O
and	O
the	O
SVM	O
regularization	O
parameters	O
.	O
	
Defaults	O
are	O
parameters	O
are	O
,	O
and	O
.	O
	
Overall	O
we	O
notice	O
that	O
neither	O
parameter	O
is	O
very	O
sensitive	O
(	O
percent	O
points	O
fluctuations	O
)	O
.	O
	
When	O
C	O
is	O
far	O
from	O
optimal	O
large	O
degradation	O
is	O
observed	O
(	O
per	O
cent	O
points	O
)	O
.	O
	
As	O
seen	O
in	O
table	O
8	O
of	O
the	O
main	O
paper	O
the	O
gap	O
between	O
default	O
and	O
tuned	O
parameters	O
is	O
rather	O
small	O
(	O
percent	O
points	O
)	O
.	O
	
[	O
layer	O
fc7	O
]	O
	
[	O
layer	O
fc6	O
]	O
	
[	O
layer	O
pool5	O
]	O
	
[	O
layer	O
conv4	O
]	O
	
appendix	O
:	O
Datasets	O
statistics	O
	
In	O
figure	O
[	O
reference	O
]	O
we	O
plot	O
the	O
height	O
distribution	O
for	O
pedestrians	O
in	O
Caltech	B-Material
and	O
KITTI	O
training	O
sets	O
.	O
	
Although	O
the	O
datasets	O
are	O
visually	O
similar	O
,	O
the	O
height	O
distributions	O
are	O
somewhat	O
dissimilar	O
(	O
for	O
reference	O
ImageNet	O
and	O
Pascal	O
distributions	O
are	O
more	O
look	O
alike	O
among	O
each	O
other	O
)	O
.	O
	
It	O
was	O
shown	O
in	O
that	O
models	O
trained	O
in	O
each	O
dataset	O
,	O
do	O
not	O
transfer	O
well	O
across	O
each	O
other	O
(	O
compared	O
to	O
models	O
trained	O
on	O
the	O
smaller	O
INRIA	O
dataset	O
)	O
.	O
	
[	O
Caltech	B-Material
Reasonable	O
training	O
set	O
]	O
[	O
KITTI	O
training	O
set	O
]	O
	
appendix	O
:	O
Proposals	O
statistics	O
	
In	O
figures	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
we	O
show	O
statistics	O
of	O
different	O
detectors	O
on	O
the	O
Caltech	B-Material
test	O
set	O
,	O
including	O
the	O
ones	O
we	O
use	O
as	O
proposals	O
in	O
our	O
experiments	O
.	O
	
These	O
figures	O
complement	O
table	O
9	O
of	O
the	O
main	O
paper	O
.	O
	
Our	O
initial	O
experiments	O
indicated	O
that	O
it	O
is	O
important	O
to	O
keep	O
a	O
low	O
number	O
of	O
average	O
proposals	O
per	O
image	O
in	O
order	O
to	O
reduce	O
the	O
false	B-Metric
positives	I-Metric
rate	I-Metric
(	O
post	B-Task
re	I-Task
-	I-Task
scoring	I-Task
)	O
.	O
	
This	O
is	O
in	O
contrast	O
to	O
common	O
practice	O
when	O
using	O
class	B-Method
-	I-Method
agnostic	I-Method
proposal	I-Method
methods	I-Method
,	O
where	O
using	O
more	O
windows	O
is	O
considered	O
better	O
because	O
they	O
provide	O
higher	O
recall	B-Metric
.	O
	
We	O
filter	O
proposals	O
via	O
a	O
threshold	O
on	O
the	O
detection	B-Metric
score	I-Metric
.	O
	
As	O
can	O
be	O
seen	O
in	O
figure	O
[	O
reference	O
]	O
a	O
recall	B-Metric
higher	O
than	O
can	O
be	O
achieved	O
with	O
only	O
proposals	O
per	O
image	O
on	O
average	O
(	O
for	O
Intersection	B-Metric
-	I-Metric
over	I-Metric
-	I-Metric
Union	I-Metric
threshold	I-Metric
above	O
,	O
the	O
evaluation	B-Metric
criterion	I-Metric
)	O
.	O
	
The	O
average	O
number	O
of	O
proposals	O
per	O
image	O
is	O
quite	O
low	O
because	O
most	O
frames	O
of	O
the	O
Caltech	B-Material
test	O
set	O
do	O
not	O
contain	O
any	O
pedestrian	O
.	O
	
In	O
figure	O
[	O
reference	O
]	O
we	O
show	O
the	O
number	O
of	O
false	O
positives	O
at	O
different	O
overlap	O
levels	O
with	O
the	O
ground	O
truth	O
annotations	O
.	O
	
The	O
bump	O
around	O
IoU	O
,	O
most	O
visible	O
for	O
SpatialPooling	B-Method
and	O
LDCF	B-Method
,	O
is	O
an	O
artefact	O
of	O
the	O
non	B-Method
-	I-Method
maximum	I-Method
suppression	I-Method
method	I-Method
used	O
by	O
each	O
method	O
.	O
	
Both	O
these	O
method	O
obtain	O
high	O
quality	O
detection	B-Task
,	O
thus	O
they	O
must	O
assign	O
(	O
very	O
)	O
low	O
-	O
scores	O
to	O
these	O
false	O
positives	O
windows	O
.	O
	
To	O
further	O
improve	O
quality	O
the	O
re	B-Method
-	I-Method
scoring	I-Method
method	I-Method
must	O
do	O
the	O
same	O
.	O
	
When	O
using	O
a	O
method	O
for	O
proposals	B-Task
one	O
desires	O
to	O
have	O
high	O
recall	B-Metric
with	O
high	O
overlap	O
with	O
the	O
ground	O
truth	O
(	O
figure	O
[	O
reference	O
]	O
)	O
,	O
as	O
well	O
has	O
having	O
false	O
positives	O
with	O
low	O
overlap	O
with	O
the	O
ground	O
truth	O
(	O
figure	O
[	O
reference	O
]	O
)	O
.	O
	
False	O
positive	O
proposals	O
overlapping	O
true	O
pedestrians	O
will	O
have	O
pieces	O
of	O
persons	O
,	O
which	O
might	O
confuse	O
the	O
re	B-Method
-	I-Method
scoring	I-Method
classifier	I-Method
.	O
	
Classifying	B-Task
fully	I-Task
centred	I-Task
persons	I-Task
versus	O
random	O
background	O
is	O
assumed	O
to	O
be	O
easier	O
task	O
.	O
	
In	O
table	O
9	O
of	O
the	O
main	O
paper	O
we	O
see	O
that	O
AlexNet	B-Method
reaches	O
top	O
detection	B-Metric
quality	I-Metric
by	O
improving	O
over	O
LDCF	B-Method
,	O
SquaresChnFtrs	B-Method
,	O
and	O
Katamari	B-Method
.	O
	
Many	O
machine	B-Method
learning	I-Method
algorithms	I-Method
require	O
the	O
input	O
to	O
be	O
represented	O
as	O
a	O
fixed	O
-	O
length	O
feature	O
vector	O
.	O
	
When	O
it	O
comes	O
to	O
texts	O
,	O
one	O
of	O
the	O
most	O
common	O
fixed	O
-	O
length	O
features	O
is	O
bag	O
-	O
of	O
-	O
words	O
.	O
	
Despite	O
their	O
popularity	O
,	O
bag	B-Method
-	I-Method
of	I-Method
-	I-Method
words	I-Method
features	I-Method
have	O
two	O
major	O
weaknesses	O
:	O
they	O
lose	O
the	O
ordering	O
of	O
the	O
words	O
and	O
they	O
also	O
ignore	O
semantics	O
of	O
the	O
words	O
.	O
	
For	O
example	O
,	O
“	O
powerful	O
,	O
”	O
“	O
strong	O
”	O
and	O
“	O
Paris	O
”	O
are	O
equally	O
distant	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
Paragraph	B-Method
Vector	I-Method
,	O
an	O
unsupervised	B-Method
algorithm	I-Method
that	O
learns	O
fixed	B-Method
-	I-Method
length	I-Method
feature	I-Method
representations	I-Method
from	O
variable	O
-	O
length	O
pieces	O
of	O
texts	O
,	O
such	O
as	O
sentences	O
,	O
paragraphs	O
,	O
and	O
documents	O
.	O
	
Our	O
algorithm	O
represents	O
each	O
document	O
by	O
a	O
dense	O
vector	O
which	O
is	O
trained	O
to	O
predict	O
words	O
in	O
the	O
document	O
.	O
	
Its	O
construction	O
gives	O
our	O
algorithm	O
the	O
potential	O
to	O
overcome	O
the	O
weaknesses	O
of	O
bag	B-Method
-	I-Method
of	I-Method
-	I-Method
words	I-Method
models	I-Method
.	O
	
Empirical	O
results	O
show	O
that	O
Paragraph	B-Method
Vectors	I-Method
outperform	O
bag	B-Method
-	I-Method
of	I-Method
-	I-Method
words	I-Method
models	I-Method
as	O
well	O
as	O
other	O
techniques	O
for	O
text	B-Task
representations	I-Task
.	O
	
Finally	O
,	O
we	O
achieve	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
several	O
text	B-Task
classification	I-Task
and	I-Task
sentiment	I-Task
analysis	I-Task
tasks	I-Task
.	O
	
DistributedRepresentationsofSentencesandDocuments	O
	
section	O
:	O
Introduction	O
	
Text	B-Task
classification	I-Task
and	O
clustering	B-Task
play	O
an	O
important	O
role	O
in	O
many	O
applications	O
,	O
e.g	O
,	O
document	B-Task
retrieval	I-Task
,	O
web	B-Task
search	I-Task
,	O
spam	B-Task
filtering	I-Task
.	O
	
At	O
the	O
heart	O
of	O
these	O
applications	O
is	O
machine	B-Method
learning	I-Method
algorithms	I-Method
such	O
as	O
logistic	B-Method
regression	I-Method
or	O
K	B-Method
-	I-Method
means	I-Method
.	O
	
These	O
algorithms	O
typically	O
require	O
the	O
text	O
input	O
to	O
be	O
represented	O
as	O
a	O
fixed	O
-	O
length	O
vector	O
.	O
	
Perhaps	O
the	O
most	O
common	O
fixed	B-Method
-	I-Method
length	I-Method
vector	I-Method
representation	I-Method
for	O
texts	O
is	O
the	O
bag	O
-	O
of	O
-	O
words	O
or	O
bag	B-Method
-	I-Method
of	I-Method
-	I-Method
n	I-Method
-	I-Method
grams	I-Method
due	O
to	O
its	O
simplicity	O
,	O
efficiency	O
and	O
often	O
surprising	O
accuracy	B-Metric
.	O
	
However	O
,	O
the	O
bag	B-Method
-	I-Method
of	I-Method
-	I-Method
words	I-Method
(	I-Method
BOW	I-Method
)	I-Method
has	O
many	O
disadvantages	O
.	O
	
The	O
word	O
order	O
is	O
lost	O
,	O
and	O
thus	O
different	O
sentences	O
can	O
have	O
exactly	O
the	O
same	O
representation	O
,	O
as	O
long	O
as	O
the	O
same	O
words	O
are	O
used	O
.	O
	
Even	O
though	O
bag	B-Method
-	I-Method
of	I-Method
-	I-Method
n	I-Method
-	I-Method
grams	I-Method
considers	O
the	O
word	O
order	O
in	O
short	O
context	O
,	O
it	O
suffers	O
from	O
data	O
sparsity	O
and	O
high	O
dimensionality	O
.	O
	
Bag	O
-	O
of	O
-	O
words	O
and	O
bag	B-Method
-	I-Method
of	I-Method
-	I-Method
n	I-Method
-	I-Method
grams	I-Method
have	O
very	O
little	O
sense	O
about	O
the	O
semantics	O
of	O
the	O
words	O
or	O
more	O
formally	O
the	O
distances	O
between	O
the	O
words	O
.	O
	
This	O
means	O
that	O
words	O
“	O
powerful	O
,	O
”	O
“	O
strong	O
”	O
and	O
“	O
Paris	O
”	O
are	O
equally	O
distant	O
despite	O
the	O
fact	O
that	O
semantically	O
,	O
“	O
powerful	O
”	O
should	O
be	O
closer	O
to	O
“	O
strong	O
”	O
than	O
“	O
Paris	O
.	O
	
”	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
Paragraph	B-Method
Vector	I-Method
,	O
an	O
unsupervised	B-Method
framework	I-Method
that	O
learns	O
continuous	B-Method
distributed	I-Method
vector	I-Method
representations	I-Method
for	O
pieces	O
of	O
texts	O
.	O
	
The	O
texts	O
can	O
be	O
of	O
variable	O
-	O
length	O
,	O
ranging	O
from	O
sentences	O
to	O
documents	O
.	O
	
The	O
name	O
Paragraph	B-Method
Vector	I-Method
is	O
to	O
emphasize	O
the	O
fact	O
that	O
the	O
method	O
can	O
be	O
applied	O
to	O
variable	O
-	O
length	O
pieces	O
of	O
texts	O
,	O
anything	O
from	O
a	O
phrase	O
or	O
sentence	O
to	O
a	O
large	O
document	O
.	O
	
In	O
our	O
model	O
,	O
the	O
vector	B-Method
representation	I-Method
is	O
trained	O
to	O
be	O
useful	O
for	O
predicting	B-Task
words	I-Task
in	O
a	O
paragraph	O
.	O
	
More	O
precisely	O
,	O
we	O
concatenate	O
the	O
paragraph	O
vector	O
with	O
several	O
word	O
vectors	O
from	O
a	O
paragraph	O
and	O
predict	O
the	O
following	O
word	O
in	O
the	O
given	O
context	O
.	O
	
Both	O
word	O
vectors	O
and	O
paragraph	O
vectors	O
are	O
trained	O
by	O
the	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
and	O
backpropagation	B-Method
.	O
	
While	O
paragraph	O
vectors	O
are	O
unique	O
among	O
paragraphs	O
,	O
the	O
word	O
vectors	O
are	O
shared	O
.	O
	
At	O
prediction	O
time	O
,	O
the	O
paragraph	O
vectors	O
are	O
inferred	O
by	O
fixing	O
the	O
word	O
vectors	O
and	O
training	O
the	O
new	O
paragraph	O
vector	O
until	O
convergence	O
.	O
	
Our	O
technique	O
is	O
inspired	O
by	O
the	O
recent	O
work	O
in	O
learning	B-Task
vector	I-Task
representations	I-Task
of	I-Task
words	I-Task
using	O
neural	B-Method
networks	I-Method
.	O
	
In	O
their	O
formulation	O
,	O
each	O
word	O
is	O
represented	O
by	O
a	O
vector	O
which	O
is	O
concatenated	O
or	O
averaged	O
with	O
other	O
word	O
vectors	O
in	O
a	O
context	O
,	O
and	O
the	O
resulting	O
vector	O
is	O
used	O
to	O
predict	O
other	O
words	O
in	O
the	O
context	O
.	O
	
For	O
example	O
,	O
the	O
neural	B-Method
network	I-Method
language	I-Method
model	I-Method
proposed	O
in	O
uses	O
the	O
concatenation	O
of	O
several	O
previous	O
word	O
vectors	O
to	O
form	O
the	O
input	O
of	O
a	O
neural	B-Method
network	I-Method
,	O
and	O
tries	O
to	O
predict	O
the	O
next	O
word	O
.	O
	
The	O
outcome	O
is	O
that	O
after	O
the	O
model	O
is	O
trained	O
,	O
the	O
word	O
vectors	O
are	O
mapped	O
into	O
a	O
vector	O
space	O
such	O
that	O
semantically	O
similar	O
words	O
have	O
similar	O
vector	O
representations	O
(	O
e.g.	O
,	O
“	O
strong	O
”	O
is	O
close	O
to	O
“	O
powerful	O
”	O
)	O
.	O
	
Following	O
these	O
successful	O
techniques	O
,	O
researchers	O
have	O
tried	O
to	O
extend	O
the	O
models	O
to	O
go	O
beyond	O
word	O
level	O
to	O
achieve	O
phrase	O
-	O
level	O
or	O
sentence	B-Method
-	I-Method
level	I-Method
representations	I-Method
.	O
	
For	O
instance	O
,	O
a	O
simple	O
approach	O
is	O
using	O
a	O
weighted	B-Method
average	I-Method
of	O
all	O
the	O
words	O
in	O
the	O
document	O
.	O
	
A	O
more	O
sophisticated	O
approach	O
is	O
combining	O
the	O
word	O
vectors	O
in	O
an	O
order	O
given	O
by	O
a	O
parse	O
tree	O
of	O
a	O
sentence	O
,	O
using	O
matrix	B-Method
-	I-Method
vector	I-Method
operations	I-Method
.	O
	
Both	O
approaches	O
have	O
weaknesses	O
.	O
	
The	O
first	O
approach	O
,	O
weighted	B-Method
averaging	I-Method
of	I-Method
word	I-Method
vectors	I-Method
,	O
loses	O
the	O
word	O
order	O
in	O
the	O
same	O
way	O
as	O
the	O
standard	O
bag	B-Method
-	I-Method
of	I-Method
-	I-Method
words	I-Method
models	I-Method
do	O
.	O
	
The	O
second	O
approach	O
,	O
using	O
a	O
parse	O
tree	O
to	O
combine	O
word	O
vectors	O
,	O
has	O
been	O
shown	O
to	O
work	O
for	O
only	O
sentences	O
because	O
it	O
relies	O
on	O
parsing	B-Task
.	O
	
Paragraph	B-Method
Vector	I-Method
is	O
capable	O
of	O
constructing	O
representations	O
of	O
input	O
sequences	O
of	O
variable	O
length	O
.	O
	
Unlike	O
some	O
of	O
the	O
previous	O
approaches	O
,	O
it	O
is	O
general	O
and	O
applicable	O
to	O
texts	O
of	O
any	O
length	O
:	O
sentences	O
,	O
paragraphs	O
,	O
and	O
documents	O
.	O
	
It	O
does	O
not	O
require	O
task	O
-	O
specific	O
tuning	O
of	O
the	O
word	B-Method
weighting	I-Method
function	I-Method
nor	O
does	O
it	O
rely	O
on	O
the	O
parse	O
trees	O
.	O
	
Further	O
in	O
the	O
paper	O
,	O
we	O
will	O
present	O
experiments	O
on	O
several	O
benchmark	O
datasets	O
that	O
demonstrate	O
the	O
advantages	O
of	O
Paragraph	B-Method
Vector	I-Method
.	O
	
For	O
example	O
,	O
on	O
sentiment	B-Task
analysis	I-Task
task	I-Task
,	O
we	O
achieve	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
,	O
better	O
than	O
complex	O
methods	O
,	O
yielding	O
a	O
relative	O
improvement	O
of	O
more	O
than	O
16	O
%	O
in	O
terms	O
of	O
error	B-Metric
rate	I-Metric
.	O
	
On	O
a	O
text	B-Task
classification	I-Task
task	I-Task
,	O
our	O
method	O
convincingly	O
beats	O
bag	B-Method
-	I-Method
of	I-Method
-	I-Method
words	I-Method
models	I-Method
,	O
giving	O
a	O
relative	O
improvement	O
of	O
about	O
30	O
%	O
.	O
	
section	O
:	O
Algorithms	O
	
We	O
start	O
by	O
discussing	O
previous	O
methods	O
for	O
learning	B-Task
word	I-Task
vectors	I-Task
.	O
	
These	O
methods	O
are	O
the	O
inspiration	O
for	O
our	O
Paragraph	B-Method
Vector	I-Method
methods	O
.	O
	
subsection	O
:	O
Learning	B-Task
Vector	I-Task
Representation	I-Task
of	I-Task
Words	I-Task
	
This	O
section	O
introduces	O
the	O
concept	O
of	O
distributed	B-Method
vector	I-Method
representation	I-Method
of	I-Method
words	I-Method
.	O
	
A	O
well	O
known	O
framework	O
for	O
learning	O
the	O
word	O
vectors	O
is	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
The	O
task	O
is	O
to	O
predict	O
a	O
word	O
given	O
the	O
other	O
words	O
in	O
a	O
context	O
.	O
	
In	O
this	O
framework	O
,	O
every	O
word	O
is	O
mapped	O
to	O
a	O
unique	O
vector	O
,	O
represented	O
by	O
a	O
column	O
in	O
a	O
matrix	O
.	O
	
The	O
column	O
is	O
indexed	O
by	O
position	O
of	O
the	O
word	O
in	O
the	O
vocabulary	O
.	O
	
The	O
concatenation	O
or	O
sum	O
of	O
the	O
vectors	O
is	O
then	O
used	O
as	O
features	O
for	O
prediction	B-Task
of	O
the	O
next	O
word	O
in	O
a	O
sentence	O
.	O
	
More	O
formally	O
,	O
given	O
a	O
sequence	O
of	O
training	O
words	O
,	O
the	O
objective	O
of	O
the	O
word	B-Method
vector	I-Method
model	I-Method
is	O
to	O
maximize	O
the	O
average	B-Metric
log	I-Metric
probability	I-Metric
	
The	O
prediction	B-Task
task	I-Task
is	O
typically	O
done	O
via	O
a	O
multiclass	B-Method
classifier	I-Method
,	O
such	O
as	O
softmax	B-Method
.	O
	
There	O
,	O
we	O
have	O
Each	O
of	O
is	O
un	O
-	O
normalized	O
log	O
-	O
probability	O
for	O
each	O
output	O
word	O
,	O
computed	O
as	O
where	O
are	O
the	O
softmax	O
parameters	O
.	O
is	O
constructed	O
by	O
a	O
concatenation	B-Method
or	I-Method
average	I-Method
of	I-Method
word	I-Method
vectors	I-Method
extracted	O
from	O
.	O
	
In	O
practice	O
,	O
hierarchical	B-Method
softmax	I-Method
is	O
preferred	O
to	O
softmax	B-Method
for	O
fast	B-Task
training	I-Task
.	O
	
In	O
our	O
work	O
,	O
the	O
structure	O
of	O
the	O
hierarical	B-Method
softmax	I-Method
is	O
a	O
binary	B-Method
Huffman	I-Method
tree	I-Method
,	O
where	O
short	O
codes	O
are	O
assigned	O
to	O
frequent	O
words	O
.	O
	
This	O
is	O
a	O
good	O
speedup	O
trick	O
because	O
common	O
words	O
are	O
accessed	O
quickly	O
.	O
	
This	O
use	O
of	O
binary	B-Method
Huffman	I-Method
code	I-Method
for	O
the	O
hierarchy	O
is	O
the	O
same	O
with	O
.	O
	
The	O
neural	B-Method
network	I-Method
based	I-Method
word	I-Method
vectors	I-Method
are	O
usually	O
trained	O
using	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
where	O
the	O
gradient	O
is	O
obtained	O
via	O
backpropagation	B-Method
.	O
	
This	O
type	O
of	O
models	O
is	O
commonly	O
known	O
as	O
neural	B-Method
language	I-Method
models	I-Method
.	O
	
A	O
particular	O
implementation	O
of	O
neural	B-Method
network	I-Method
based	I-Method
algorithm	I-Method
for	O
training	O
the	O
word	O
vectors	O
is	O
available	O
at	O
code.google.com	O
/	O
p	O
/	O
word2vec	O
/	O
.	O
	
After	O
the	O
training	O
converges	O
,	O
words	O
with	O
similar	O
meaning	O
are	O
mapped	O
to	O
a	O
similar	O
position	O
in	O
the	O
vector	O
space	O
.	O
	
For	O
example	O
,	O
“	O
powerful	O
”	O
and	O
“	O
strong	O
”	O
are	O
close	O
to	O
each	O
other	O
,	O
whereas	O
“	O
powerful	O
”	O
and	O
“	O
Paris	O
”	O
are	O
more	O
distant	O
.	O
	
The	O
difference	O
between	O
word	O
vectors	O
also	O
carry	O
meaning	O
.	O
	
For	O
example	O
,	O
the	O
word	O
vectors	O
can	O
be	O
used	O
to	O
answer	O
analogy	B-Task
questions	I-Task
using	O
simple	O
vector	B-Method
algebra	I-Method
:	O
“	O
	
King	O
”	O
	
-	O
	
“	O
man	O
”	O
+	O
“	O
woman	O
”	O
=	O
	
“	O
	
Queen	O
”	O
.	O
	
It	O
is	O
also	O
possible	O
to	O
learn	O
a	O
linear	O
matrix	O
to	O
translate	O
words	O
and	O
phrases	O
between	O
languages	O
.	O
	
These	O
properties	O
make	O
word	B-Method
vectors	I-Method
attractive	O
for	O
many	O
natural	B-Task
language	I-Task
processing	I-Task
tasks	I-Task
such	O
as	O
language	B-Task
modeling	I-Task
,	O
natural	B-Task
language	I-Task
understanding	I-Task
,	O
statistical	B-Task
machine	I-Task
translation	I-Task
,	O
image	B-Task
understanding	I-Task
and	O
relational	B-Task
extraction	I-Task
.	O
	
subsection	O
:	O
Paragraph	B-Method
Vector	I-Method
:	O
A	O
distributed	B-Method
memory	I-Method
model	I-Method
	
Our	O
approach	O
for	O
learning	B-Task
paragraph	I-Task
vectors	I-Task
is	O
inspired	O
by	O
the	O
methods	O
for	O
learning	O
the	O
word	O
vectors	O
.	O
	
The	O
inspiration	O
is	O
that	O
the	O
word	O
vectors	O
are	O
asked	O
to	O
contribute	O
to	O
a	O
prediction	B-Task
task	I-Task
about	O
the	O
next	O
word	O
in	O
the	O
sentence	O
.	O
	
So	O
despite	O
the	O
fact	O
that	O
the	O
word	O
vectors	O
are	O
initialized	O
randomly	O
,	O
they	O
can	O
eventually	O
capture	O
semantics	O
as	O
an	O
indirect	O
result	O
of	O
the	O
prediction	B-Task
task	I-Task
.	O
	
We	O
will	O
use	O
this	O
idea	O
in	O
our	O
paragraph	O
vectors	O
in	O
a	O
similar	O
manner	O
.	O
	
The	O
paragraph	O
vectors	O
are	O
also	O
asked	O
to	O
contribute	O
to	O
the	O
prediction	B-Task
task	I-Task
of	O
the	O
next	O
word	O
given	O
many	O
contexts	O
sampled	O
from	O
the	O
paragraph	O
.	O
	
In	O
our	O
Paragraph	B-Method
Vector	I-Method
framework	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
,	O
every	O
paragraph	O
is	O
mapped	O
to	O
a	O
unique	O
vector	O
,	O
represented	O
by	O
a	O
column	O
in	O
matrix	O
and	O
every	O
word	O
is	O
also	O
mapped	O
to	O
a	O
unique	O
vector	O
,	O
represented	O
by	O
a	O
column	O
in	O
matrix	O
.	O
	
The	O
paragraph	O
vector	O
and	O
word	O
vectors	O
are	O
averaged	O
or	O
concatenated	O
to	O
predict	O
the	O
next	O
word	O
in	O
a	O
context	O
.	O
	
In	O
the	O
experiments	O
,	O
we	O
use	O
concatenation	B-Method
as	O
the	O
method	O
to	O
combine	O
the	O
vectors	O
.	O
	
More	O
formally	O
,	O
the	O
only	O
change	O
in	O
this	O
model	O
compared	O
to	O
the	O
word	B-Method
vector	I-Method
framework	I-Method
is	O
in	O
equation	O
[	O
reference	O
]	O
,	O
where	O
is	O
constructed	O
from	O
and	O
.	O
	
The	O
paragraph	O
token	O
can	O
be	O
thought	O
of	O
as	O
another	O
word	O
.	O
	
It	O
acts	O
as	O
a	O
memory	O
that	O
remembers	O
what	O
is	O
missing	O
from	O
the	O
current	O
context	O
–	O
or	O
the	O
topic	O
of	O
the	O
paragraph	O
.	O
	
For	O
this	O
reason	O
,	O
we	O
often	O
call	O
this	O
model	O
the	O
Distributed	B-Method
Memory	I-Method
Model	I-Method
of	I-Method
Paragraph	I-Method
Vectors	I-Method
(	O
PV	B-Method
-	I-Method
DM	I-Method
)	O
.	O
	
The	O
contexts	O
are	O
fixed	O
-	O
length	O
and	O
sampled	O
from	O
a	O
sliding	O
window	O
over	O
the	O
paragraph	O
.	O
	
The	O
paragraph	O
vector	O
is	O
shared	O
across	O
all	O
contexts	O
generated	O
from	O
the	O
same	O
paragraph	O
but	O
not	O
across	O
paragraphs	O
.	O
	
The	O
word	O
vector	O
matrix	O
,	O
however	O
,	O
is	O
shared	O
across	O
paragraphs	O
.	O
	
I.e.	O
,	O
the	O
vector	O
for	O
“	O
powerful	O
”	O
is	O
the	O
same	O
for	O
all	O
paragraphs	O
.	O
	
The	O
paragraph	O
vectors	O
and	O
word	O
vectors	O
are	O
trained	O
using	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
and	O
the	O
gradient	O
is	O
obtained	O
via	O
backpropagation	B-Method
.	O
	
At	O
every	O
step	O
of	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
,	O
one	O
can	O
sample	O
a	O
fixed	O
-	O
length	O
context	O
from	O
a	O
random	O
paragraph	O
,	O
compute	O
the	O
error	O
gradient	O
from	O
the	O
network	O
in	O
Figure	O
[	O
reference	O
]	O
and	O
use	O
the	O
gradient	O
to	O
update	O
the	O
parameters	O
in	O
our	O
model	O
.	O
	
At	O
prediction	O
time	O
,	O
one	O
needs	O
to	O
perform	O
an	O
inference	B-Method
step	I-Method
to	O
compute	O
the	O
paragraph	O
vector	O
for	O
a	O
new	O
paragraph	O
.	O
	
This	O
is	O
also	O
obtained	O
by	O
gradient	B-Method
descent	I-Method
.	O
	
In	O
this	O
step	O
,	O
the	O
parameters	O
for	O
the	O
rest	O
of	O
the	O
model	O
,	O
the	O
word	O
vectors	O
and	O
the	O
softmax	O
weights	O
,	O
are	O
fixed	O
.	O
	
Suppose	O
that	O
there	O
are	O
paragraphs	O
in	O
the	O
corpus	O
,	O
words	O
in	O
the	O
vocabulary	O
,	O
and	O
we	O
want	O
to	O
learn	O
paragraph	O
vectors	O
such	O
that	O
each	O
paragraph	O
is	O
mapped	O
to	O
dimensions	O
and	O
each	O
word	O
is	O
mapped	O
to	O
dimensions	O
,	O
then	O
the	O
model	O
has	O
the	O
total	O
of	O
parameters	O
(	O
excluding	O
the	O
softmax	O
parameters	O
)	O
.	O
	
Even	O
though	O
the	O
number	O
of	O
parameters	O
can	O
be	O
large	O
when	O
is	O
large	O
,	O
the	O
updates	O
during	O
training	B-Task
are	O
typically	O
sparse	O
and	O
thus	O
efficient	O
.	O
	
After	O
being	O
trained	O
,	O
the	O
paragraph	O
vectors	O
can	O
be	O
used	O
as	O
features	O
for	O
the	O
paragraph	O
(	O
e.g.	O
,	O
in	O
lieu	O
of	O
or	O
in	O
addition	O
to	O
bag	O
-	O
of	O
-	O
words	O
)	O
.	O
	
We	O
can	O
feed	O
these	O
features	O
directly	O
to	O
conventional	O
machine	B-Method
learning	I-Method
techniques	I-Method
such	O
as	O
logistic	B-Method
regression	I-Method
,	O
support	B-Method
vector	I-Method
machines	I-Method
or	O
K	B-Method
-	I-Method
means	I-Method
.	O
	
In	O
summary	O
,	O
the	O
algorithm	O
itself	O
has	O
two	O
key	O
stages	O
:	O
1	O
)	O
training	B-Task
to	O
get	O
word	O
vectors	O
,	O
softmax	O
weights	O
and	O
paragraph	O
vectors	O
on	O
already	O
seen	O
paragraphs	O
;	O
and	O
2	O
)	O
	
“	O
	
the	O
inference	B-Method
stage	I-Method
”	O
to	O
get	O
paragraph	O
vectors	O
for	O
new	O
paragraphs	O
(	O
never	O
seen	O
before	O
)	O
by	O
adding	O
more	O
columns	O
in	O
and	O
gradient	O
descending	O
on	O
while	O
holding	O
fixed	O
.	O
	
We	O
use	O
to	O
make	O
a	O
prediction	O
about	O
some	O
particular	O
labels	O
using	O
a	O
standard	O
classifier	B-Method
,	O
e.g.	O
,	O
logistic	B-Method
regression	I-Method
.	O
	
paragraph	O
:	O
Advantages	O
of	O
paragraph	O
vectors	O
:	O
	
An	O
important	O
advantage	O
of	O
paragraph	B-Method
vectors	I-Method
is	O
that	O
they	O
are	O
learned	O
from	O
unlabeled	O
data	O
and	O
thus	O
can	O
work	O
well	O
for	O
tasks	O
that	O
do	O
not	O
have	O
enough	O
labeled	O
data	O
.	O
	
Paragraph	B-Method
vectors	I-Method
also	O
address	O
some	O
of	O
the	O
key	O
weaknesses	O
of	O
bag	B-Method
-	I-Method
of	I-Method
-	I-Method
words	I-Method
models	I-Method
.	O
	
First	O
,	O
they	O
inherit	O
an	O
important	O
property	O
of	O
the	O
word	O
vectors	O
:	O
the	O
semantics	O
of	O
the	O
words	O
.	O
	
In	O
this	O
space	O
,	O
“	O
powerful	O
”	O
is	O
closer	O
to	O
“	O
strong	O
”	O
than	O
to	O
“	O
Paris	O
.	O
	
”	O
	
The	O
second	O
advantage	O
of	O
the	O
paragraph	B-Method
vectors	I-Method
is	O
that	O
they	O
take	O
into	O
consideration	O
the	O
word	O
order	O
,	O
at	O
least	O
in	O
a	O
small	O
context	O
,	O
in	O
the	O
same	O
way	O
that	O
an	O
n	B-Method
-	I-Method
gram	I-Method
model	I-Method
with	O
a	O
large	O
n	O
would	O
do	O
.	O
	
This	O
is	O
important	O
,	O
because	O
the	O
n	B-Method
-	I-Method
gram	I-Method
model	I-Method
preserves	O
a	O
lot	O
of	O
information	O
of	O
the	O
paragraph	O
,	O
including	O
the	O
word	O
order	O
.	O
	
That	O
said	O
,	O
our	O
model	O
is	O
perhaps	O
better	O
than	O
a	O
bag	B-Method
-	I-Method
of	I-Method
-	I-Method
n	I-Method
-	I-Method
grams	I-Method
model	I-Method
because	O
a	O
bag	B-Method
of	I-Method
n	I-Method
-	I-Method
grams	I-Method
model	I-Method
would	O
create	O
a	O
very	O
high	O
-	O
dimensional	B-Method
representation	I-Method
that	O
tends	O
to	O
generalize	O
poorly	O
.	O
	
subsection	O
:	O
Paragraph	B-Method
Vector	I-Method
without	O
word	B-Method
ordering	I-Method
:	O
Distributed	B-Method
bag	I-Method
of	I-Method
words	I-Method
	
The	O
above	O
method	O
considers	O
the	O
concatenation	O
of	O
the	O
paragraph	O
vector	O
with	O
the	O
word	O
vectors	O
to	O
predict	O
the	O
next	O
word	O
in	O
a	O
text	O
window	O
.	O
	
Another	O
way	O
is	O
to	O
ignore	O
the	O
context	O
words	O
in	O
the	O
input	O
,	O
but	O
force	O
the	O
model	O
to	O
predict	O
words	O
randomly	O
sampled	O
from	O
the	O
paragraph	O
in	O
the	O
output	O
.	O
	
In	O
reality	O
,	O
what	O
this	O
means	O
is	O
that	O
at	O
each	O
iteration	O
of	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
,	O
we	O
sample	O
a	O
text	O
window	O
,	O
then	O
sample	O
a	O
random	O
word	O
from	O
the	O
text	O
window	O
and	O
form	O
a	O
classification	B-Task
task	I-Task
given	O
the	O
Paragraph	B-Method
Vector	I-Method
.	O
	
This	O
technique	O
is	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
We	O
name	O
this	O
version	O
the	O
Distributed	B-Method
Bag	I-Method
of	I-Method
Words	I-Method
version	I-Method
of	I-Method
Paragraph	I-Method
Vector	I-Method
(	O
PV	B-Method
-	I-Method
DBOW	I-Method
)	O
,	O
as	O
opposed	O
to	O
Distributed	O
Memory	O
version	O
of	O
Paragraph	B-Method
Vector	I-Method
(	O
PV	B-Method
-	I-Method
DM	I-Method
)	O
in	O
previous	O
section	O
.	O
	
In	O
addition	O
to	O
being	O
conceptually	O
simple	O
,	O
this	O
model	O
requires	O
to	O
store	O
less	O
data	O
.	O
	
We	O
only	O
need	O
to	O
store	O
the	O
softmax	O
weights	O
as	O
opposed	O
to	O
both	O
softmax	O
weights	O
and	O
word	O
vectors	O
in	O
the	O
previous	O
model	O
.	O
	
This	O
model	O
is	O
also	O
similar	O
to	O
the	O
Skip	B-Method
-	I-Method
gram	I-Method
model	I-Method
in	O
word	O
vectors	O
.	O
	
In	O
our	O
experiments	O
,	O
each	O
paragraph	O
vector	O
is	O
a	O
combination	O
of	O
two	O
vectors	O
:	O
one	O
learned	O
by	O
the	O
standard	O
paragraph	B-Method
vector	I-Method
with	O
distributed	B-Method
memory	I-Method
(	O
PV	B-Method
-	I-Method
DM	I-Method
)	O
and	O
one	O
learned	O
by	O
the	O
paragraph	B-Method
vector	I-Method
with	O
distributed	B-Method
bag	I-Method
of	I-Method
words	I-Method
(	O
PV	B-Method
-	I-Method
DBOW	I-Method
)	O
.	O
	
PV	B-Method
-	I-Method
DM	I-Method
alone	O
usually	O
works	O
well	O
for	O
most	O
tasks	O
(	O
with	O
state	O
-	O
of	O
-	O
art	O
performances	O
)	O
,	O
but	O
its	O
combination	O
with	O
PV	B-Method
-	I-Method
DBOW	I-Method
is	O
usually	O
more	O
consistent	O
across	O
many	O
tasks	O
that	O
we	O
try	O
and	O
therefore	O
strongly	O
recommended	O
.	O
	
section	O
:	O
Experiments	O
	
We	O
perform	O
experiments	O
to	O
better	O
understand	O
the	O
behavior	O
of	O
the	O
paragraph	O
vectors	O
.	O
	
To	O
achieve	O
this	O
,	O
we	O
benchmark	O
Paragraph	B-Method
Vector	I-Method
on	O
two	O
text	B-Task
understanding	I-Task
problems	I-Task
that	O
require	O
fixed	B-Method
-	I-Method
length	I-Method
vector	I-Method
representations	I-Method
of	I-Method
paragraphs	I-Method
:	O
sentiment	B-Task
analysis	I-Task
and	O
information	B-Task
retrieval	I-Task
.	O
	
For	O
sentiment	B-Task
analysis	I-Task
,	O
we	O
use	O
two	O
datasets	O
:	O
Stanford	O
sentiment	O
treebank	O
dataset	O
and	O
IMDB	O
dataset	O
.	O
	
Documents	O
in	O
these	O
datasets	O
differ	O
significantly	O
in	O
lengths	O
:	O
	
every	O
example	O
in	O
Socher	O
	
et	O
al	O
.	O
	
’s	O
dataset	O
is	O
a	O
single	O
sentence	O
while	O
every	O
example	O
in	O
Maas	O
et	O
al	O
.	O
	
’s	O
dataset	O
consists	O
of	O
several	O
sentences	O
.	O
	
We	O
also	O
test	O
our	O
method	O
on	O
an	O
information	B-Task
retrieval	I-Task
task	I-Task
,	O
where	O
the	O
goal	O
is	O
to	O
decide	O
if	O
a	O
document	O
should	O
be	O
retrieved	O
given	O
a	O
query	O
.	O
	
subsection	O
:	O
Sentiment	B-Task
Analysis	I-Task
with	O
the	O
Stanford	O
Sentiment	O
Treebank	O
Dataset	O
	
paragraph	O
:	O
Dataset	O
:	O
	
This	O
dataset	O
was	O
first	O
proposed	O
by	O
and	O
subsequently	O
extended	O
by	O
as	O
a	O
benchmark	O
for	O
sentiment	B-Task
analysis	I-Task
.	O
	
It	O
has	O
11855	O
sentences	O
taken	O
from	O
the	O
movie	O
review	O
site	O
Rotten	O
Tomatoes	O
.	O
	
The	O
dataset	O
consists	O
of	O
three	O
sets	O
:	O
8544	O
sentences	O
for	O
training	O
,	O
2210	O
sentences	O
for	O
test	O
and	O
1101	O
sentences	O
for	O
validation	B-Task
(	O
or	O
development	B-Task
)	O
.	O
	
Every	O
sentence	O
in	O
the	O
dataset	O
has	O
a	O
label	O
which	O
goes	O
from	O
very	O
negative	O
to	O
very	O
positive	O
in	O
the	O
scale	O
from	O
0.0	O
to	O
1.0	O
.	O
	
The	O
labels	O
are	O
generated	O
by	O
human	O
annotators	O
using	O
Amazon	O
Mechanical	O
Turk	O
.	O
	
The	O
dataset	O
comes	O
with	O
detailed	O
labels	O
for	O
sentences	O
,	O
and	O
subphrases	O
in	O
the	O
same	O
scale	O
.	O
	
To	O
achieve	O
this	O
,	O
Socher	O
et	O
al	O
.	O
used	O
the	O
Stanford	B-Method
Parser	I-Method
to	O
parse	O
each	O
sentence	O
to	O
subphrases	O
.	O
	
The	O
subphrases	O
were	O
then	O
labeled	O
by	O
human	O
annotators	O
in	O
the	O
same	O
way	O
as	O
the	O
sentences	O
were	O
labeled	O
.	O
	
In	O
total	O
,	O
there	O
are	O
239	O
,	O
232	O
labeled	O
phrases	O
in	O
the	O
dataset	O
.	O
	
The	O
dataset	O
can	O
be	O
downloaded	O
at	O
:	O
http:	O
//	O
nlp	O
.	O
	
Stanford.edu	O
/	O
	
sentiment	O
/	O
	
paragraph	O
:	O
Tasks	O
and	O
Baselines	O
:	O
	
In	O
,	O
the	O
authors	O
propose	O
two	O
ways	O
of	O
benchmarking	B-Task
.	O
	
First	O
,	O
one	O
could	O
consider	O
a	O
5	B-Task
-	I-Task
way	I-Task
fine	I-Task
-	I-Task
grained	I-Task
classification	I-Task
task	I-Task
where	O
the	O
labels	O
are	O
{	O
Very	O
Negative	O
,	O
Negative	O
,	O
Neutral	O
,	O
Positive	O
,	O
Very	O
Positive	O
}	O
or	O
a	O
2	B-Task
-	I-Task
way	I-Task
coarse	I-Task
-	I-Task
grained	I-Task
classification	I-Task
task	I-Task
where	O
the	O
labels	O
are	O
{	O
Negative	O
,	O
	
Positive}.	O
The	O
other	O
axis	O
of	O
variation	O
is	O
in	O
terms	O
of	O
whether	O
we	O
should	O
label	O
the	O
entire	O
sentence	O
or	O
all	O
phrases	O
in	O
the	O
sentence	O
.	O
	
In	O
this	O
work	O
we	O
only	O
consider	O
labeling	O
the	O
full	O
sentences	O
.	O
	
Socher	O
et	O
al	O
.	O
apply	O
several	O
methods	O
to	O
this	O
dataset	O
and	O
find	O
that	O
their	O
Recursive	B-Method
Neural	I-Method
Tensor	I-Method
Network	I-Method
works	O
much	O
better	O
than	O
bag	B-Method
-	I-Method
of	I-Method
-	I-Method
words	I-Method
model	I-Method
.	O
	
It	O
can	O
be	O
argued	O
that	O
this	O
is	O
because	O
movie	O
reviews	O
are	O
often	O
short	O
and	O
compositionality	O
plays	O
an	O
important	O
role	O
in	O
deciding	O
whether	O
the	O
review	O
is	O
positive	O
or	O
negative	O
,	O
as	O
well	O
as	O
similarity	O
between	O
words	O
does	O
given	O
the	O
rather	O
tiny	O
size	O
of	O
the	O
training	O
set	O
.	O
	
paragraph	O
:	O
Experimental	O
protocols	O
:	O
	
We	O
follow	O
the	O
experimental	O
protocols	O
as	O
described	O
in	O
.	O
	
To	O
make	O
use	O
of	O
the	O
available	O
labeled	O
data	O
,	O
in	O
our	O
model	O
,	O
each	O
subphrase	O
is	O
treated	O
as	O
an	O
independent	O
sentence	O
and	O
we	O
learn	O
the	O
representations	O
for	O
all	O
the	O
subphrases	O
in	O
the	O
training	O
set	O
.	O
	
After	O
learning	O
the	O
vector	B-Method
representations	I-Method
for	O
training	O
sentences	O
and	O
their	O
subphrases	O
,	O
we	O
feed	O
them	O
to	O
a	O
logistic	B-Method
regression	I-Method
to	O
learn	O
a	O
predictor	O
of	O
the	O
movie	B-Task
rating	I-Task
.	O
	
At	O
test	O
time	O
,	O
we	O
freeze	O
the	O
vector	B-Method
representation	I-Method
for	O
each	O
word	O
,	O
and	O
learn	O
the	O
representations	O
for	O
the	O
sentences	O
using	O
gradient	B-Method
descent	I-Method
.	O
	
Once	O
the	O
vector	B-Method
representations	I-Method
for	O
the	O
test	O
sentences	O
are	O
learned	O
,	O
we	O
feed	O
them	O
through	O
the	O
logistic	B-Method
regression	I-Method
to	O
predict	O
the	O
movie	B-Task
rating	I-Task
.	O
	
In	O
our	O
experiments	O
,	O
we	O
cross	O
validate	O
the	O
window	O
size	O
using	O
the	O
validation	O
set	O
,	O
and	O
the	O
optimal	O
window	O
size	O
is	O
8	O
.	O
	
The	O
vector	O
presented	O
to	O
the	O
classifier	B-Method
is	O
a	O
concatenation	O
of	O
two	O
vectors	O
,	O
one	O
from	O
PV	B-Method
-	I-Method
DBOW	I-Method
and	O
one	O
from	O
PV	B-Method
-	I-Method
DM	I-Method
.	O
	
In	O
PV	B-Method
-	I-Method
DBOW	I-Method
,	O
the	O
learned	O
vector	B-Method
representations	I-Method
have	O
400	O
dimensions	O
.	O
	
In	O
PV	B-Method
-	I-Method
DM	I-Method
,	O
the	O
learned	O
vector	B-Method
representations	I-Method
have	O
400	O
dimensions	O
for	O
both	O
words	O
and	O
paragraphs	O
.	O
	
To	O
predict	O
the	O
8	O
-	O
th	O
word	O
,	O
we	O
concatenate	O
the	O
paragraph	O
vectors	O
and	O
7	O
word	O
vectors	O
.	O
	
Special	O
characters	O
such	O
as	O
,	O
.	O
!	O
?	O
are	O
treated	O
as	O
a	O
normal	O
word	O
.	O
	
If	O
the	O
paragraph	O
has	O
less	O
than	O
9	O
words	O
,	O
we	O
pre	O
-	O
pad	O
with	O
a	O
special	O
NULL	O
word	O
symbol	O
.	O
	
paragraph	O
:	O
Results	O
:	O
	
We	O
report	O
the	O
error	B-Metric
rates	I-Metric
of	O
different	O
methods	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
The	O
first	O
highlight	O
for	O
this	O
Table	O
is	O
that	O
bag	O
-	O
of	O
-	O
words	O
or	O
bag	B-Method
-	I-Method
of	I-Method
-	I-Method
n	I-Method
-	I-Method
grams	I-Method
models	I-Method
(	O
NB	B-Method
,	O
SVM	B-Method
,	O
BiNB	B-Method
)	O
perform	O
poorly	O
.	O
	
Simply	O
averaging	O
the	O
word	O
vectors	O
(	O
in	O
a	O
bag	B-Method
-	I-Method
of	I-Method
-	I-Method
words	I-Method
fashion	I-Method
)	O
does	O
not	O
improve	O
the	O
results	O
.	O
	
This	O
is	O
because	O
bag	B-Method
-	I-Method
of	I-Method
-	I-Method
words	I-Method
models	I-Method
do	O
not	O
consider	O
how	O
each	O
sentence	O
is	O
composed	O
(	O
e.g.	O
,	O
word	O
ordering	O
)	O
and	O
therefore	O
fail	O
to	O
recognize	O
many	O
sophisticated	O
linguistic	O
phenomena	O
,	O
for	O
instance	O
sarcasm	O
.	O
	
The	O
results	O
also	O
show	O
that	O
more	O
advanced	O
methods	O
(	O
such	O
as	O
Recursive	B-Method
Neural	I-Method
Network	I-Method
)	O
,	O
which	O
require	O
parsing	B-Method
and	O
take	O
into	O
account	O
the	O
compositionality	O
,	O
perform	O
much	O
better	O
.	O
	
Our	O
method	O
performs	O
better	O
than	O
all	O
these	O
baselines	O
,	O
e.g.	O
,	O
recursive	B-Method
networks	I-Method
,	O
despite	O
the	O
fact	O
that	O
it	O
does	O
not	O
require	O
parsing	B-Task
.	O
	
On	O
the	O
coarse	B-Task
-	I-Task
grained	I-Task
classification	I-Task
task	I-Task
,	O
our	O
method	O
has	O
an	O
absolute	O
improvement	O
of	O
2.4	O
%	O
in	O
terms	O
of	O
error	B-Metric
rates	I-Metric
.	O
	
This	O
translates	O
to	O
16	O
%	O
relative	O
improvement	O
.	O
	
subsection	O
:	O
Beyond	O
One	O
Sentence	O
:	O
Sentiment	B-Task
Analysis	I-Task
with	O
IMDB	O
dataset	O
	
Some	O
of	O
the	O
previous	O
techniques	O
only	O
work	O
on	O
sentences	O
,	O
but	O
not	O
paragraphs	O
/	O
documents	O
with	O
several	O
sentences	O
.	O
	
For	O
instance	O
,	O
Recursive	B-Method
Neural	I-Method
Tensor	I-Method
Network	I-Method
is	O
based	O
on	O
the	O
parsing	B-Method
over	O
each	O
sentence	O
and	O
it	O
is	O
unclear	O
how	O
to	O
combine	O
the	O
representations	O
over	O
many	O
sentences	O
.	O
	
Such	O
techniques	O
therefore	O
are	O
restricted	O
to	O
work	O
on	O
sentences	O
but	O
not	O
paragraphs	O
or	O
documents	O
.	O
	
Our	O
method	O
does	O
not	O
require	O
parsing	B-Task
,	O
thus	O
it	O
can	O
produce	O
a	O
representation	O
for	O
a	O
long	O
document	O
consisting	O
of	O
many	O
sentences	O
.	O
	
This	O
advantage	O
makes	O
our	O
method	O
more	O
general	O
than	O
some	O
of	O
the	O
other	O
approaches	O
.	O
	
The	O
following	O
experiment	O
on	O
IMDB	O
dataset	O
demonstrates	O
this	O
advantage	O
.	O
	
paragraph	O
:	O
Dataset	O
:	O
	
The	O
IMDB	O
dataset	O
was	O
first	O
proposed	O
by	O
Maas	O
et	O
al	O
.	O
as	O
a	O
benchmark	O
for	O
sentiment	B-Task
analysis	I-Task
.	O
	
The	O
dataset	O
consists	O
of	O
100	O
,	O
000	O
movie	O
reviews	O
taken	O
from	O
IMDB	O
.	O
	
One	O
key	O
aspect	O
of	O
this	O
dataset	O
is	O
that	O
each	O
movie	O
review	O
has	O
several	O
sentences	O
.	O
	
The	O
100	O
,	O
000	O
movie	O
reviews	O
are	O
divided	O
into	O
three	O
datasets	O
:	O
25	O
,	O
000	O
labeled	O
training	O
instances	O
,	O
25	O
,	O
000	O
labeled	O
test	O
instances	O
and	O
50	O
,	O
000	O
unlabeled	O
training	O
instances	O
.	O
	
There	O
are	O
two	O
types	O
of	O
labels	O
:	O
Positive	O
and	O
Negative	O
.	O
	
These	O
labels	O
are	O
balanced	O
in	O
both	O
the	O
training	O
and	O
the	O
test	O
set	O
.	O
	
The	O
dataset	O
can	O
be	O
downloaded	O
at	O
http:	O
//	O
ai	O
.	O
	
Stanford.edu	O
/	O
amaas	O
/	O
data	O
/	O
sentiment	O
/	O
index.html	O
	
paragraph	O
:	O
Experimental	O
protocols	O
:	O
	
We	O
learn	O
the	O
word	O
vectors	O
and	O
paragraph	O
vectors	O
using	O
75	O
,	O
000	O
training	O
documents	O
(	O
25	O
,	O
000	O
labeled	O
and	O
50	O
,	O
000	O
unlabeled	O
instances	O
)	O
.	O
	
The	O
paragraph	O
vectors	O
for	O
the	O
25	O
,	O
000	O
labeled	O
instances	O
are	O
then	O
fed	O
through	O
a	O
neural	B-Method
network	I-Method
with	O
one	O
hidden	B-Method
layer	I-Method
with	O
50	O
units	O
and	O
a	O
logistic	B-Method
classifier	I-Method
to	O
learn	O
to	O
predict	O
the	O
sentiment	O
.	O
	
At	O
test	O
time	O
,	O
given	O
a	O
test	O
sentence	O
,	O
we	O
again	O
freeze	O
the	O
rest	O
of	O
the	O
network	O
and	O
learn	O
the	O
paragraph	O
vectors	O
for	O
the	O
test	O
reviews	O
by	O
gradient	B-Method
descent	I-Method
.	O
	
Once	O
the	O
vectors	O
are	O
learned	O
,	O
we	O
feed	O
them	O
through	O
the	O
neural	B-Method
network	I-Method
to	O
predict	O
the	O
sentiment	O
of	O
the	O
reviews	O
.	O
	
The	O
hyperparameters	B-Method
of	O
our	O
paragraph	B-Method
vector	I-Method
model	I-Method
are	O
selected	O
in	O
the	O
same	O
manner	O
as	O
in	O
the	O
previous	O
task	O
.	O
	
In	O
particular	O
,	O
we	O
cross	O
validate	O
the	O
window	O
size	O
,	O
and	O
the	O
optimal	O
window	O
size	O
is	O
10	O
words	O
.	O
	
The	O
vector	O
presented	O
to	O
the	O
classifier	B-Method
is	O
a	O
concatenation	O
of	O
two	O
vectors	O
,	O
one	O
from	O
PV	B-Method
-	I-Method
DBOW	I-Method
and	O
one	O
from	O
PV	B-Method
-	I-Method
DM	I-Method
.	O
	
In	O
PV	B-Method
-	I-Method
DBOW	I-Method
,	O
the	O
learned	O
vector	B-Method
representations	I-Method
have	O
400	O
dimensions	O
.	O
	
In	O
PV	B-Method
-	I-Method
DM	I-Method
,	O
the	O
learned	O
vector	B-Method
representations	I-Method
have	O
400	O
dimensions	O
for	O
both	O
words	O
and	O
documents	O
.	O
	
To	O
predict	O
the	O
10	O
-	O
th	O
word	O
,	O
we	O
concatenate	O
the	O
paragraph	O
vectors	O
and	O
word	O
vectors	O
.	O
	
Special	O
characters	O
such	O
as	O
,	O
.	O
!	O
?	O
are	O
treated	O
as	O
a	O
normal	O
word	O
.	O
	
If	O
the	O
document	O
has	O
less	O
than	O
9	O
words	O
,	O
we	O
pre	O
-	O
pad	O
with	O
a	O
special	O
NULL	O
word	O
symbol	O
.	O
	
paragraph	O
:	O
Results	O
:	O
	
The	O
results	O
of	O
Paragraph	B-Method
Vector	I-Method
and	O
other	O
baselines	O
are	O
reported	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
As	O
can	O
be	O
seen	O
from	O
the	O
Table	O
,	O
for	O
long	O
documents	O
,	O
bag	B-Method
-	I-Method
of	I-Method
-	I-Method
words	I-Method
models	I-Method
perform	O
quite	O
well	O
and	O
it	O
is	O
difficult	O
to	O
improve	O
upon	O
them	O
using	O
word	O
vectors	O
.	O
	
The	O
most	O
significant	O
improvement	O
happened	O
in	O
2012	O
in	O
the	O
work	O
of	O
where	O
they	O
combine	O
a	O
Restricted	B-Method
Boltzmann	I-Method
Machines	I-Method
model	I-Method
with	O
bag	B-Method
-	I-Method
of	I-Method
-	I-Method
words	I-Method
.	O
	
The	O
combination	O
of	O
two	O
models	O
yields	O
an	O
improvement	O
approximately	O
1.5	O
%	O
in	O
terms	O
of	O
error	B-Metric
rates	I-Metric
.	O
	
Another	O
significant	O
improvement	O
comes	O
from	O
the	O
work	O
of	O
.	O
	
Among	O
many	O
variations	O
they	O
tried	O
,	O
NBSVM	B-Method
on	O
bigram	O
features	O
works	O
the	O
best	O
and	O
yields	O
a	O
considerable	O
improvement	O
of	O
2	O
%	O
in	O
terms	O
of	O
the	O
error	B-Metric
rate	I-Metric
.	O
	
The	O
method	O
described	O
in	O
this	O
paper	O
is	O
the	O
only	O
approach	O
that	O
goes	O
significantly	O
beyond	O
the	O
barrier	O
of	O
10	O
%	O
error	B-Metric
rate	I-Metric
.	O
	
It	O
achieves	O
7.42	O
%	O
which	O
is	O
another	O
1.3	O
%	O
absolute	O
improvement	O
(	O
or	O
15	O
%	O
relative	O
improvement	O
)	O
over	O
the	O
best	O
previous	O
result	O
of	O
.	O
	
subsection	O
:	O
Information	B-Task
Retrieval	I-Task
with	O
Paragraph	O
Vectors	O
	
We	O
turn	O
our	O
attention	O
to	O
an	O
information	B-Task
retrieval	I-Task
task	I-Task
which	O
requires	O
fixed	B-Method
-	I-Method
length	I-Method
representations	I-Method
of	I-Method
paragraphs	I-Method
.	O
	
Here	O
,	O
we	O
have	O
a	O
dataset	O
of	O
paragraphs	O
in	O
the	O
first	O
10	O
results	O
returned	O
by	O
a	O
search	B-Method
engine	I-Method
given	O
each	O
of	O
1	O
,	O
000	O
,	O
000	O
most	O
popular	O
queries	O
.	O
	
Each	O
of	O
these	O
paragraphs	O
is	O
also	O
known	O
as	O
a	O
“	O
snippet	O
”	O
which	O
summarizes	O
the	O
content	O
of	O
a	O
web	O
page	O
and	O
how	O
a	O
web	O
page	O
matches	O
the	O
query	O
.	O
	
From	O
such	O
collection	O
,	O
we	O
derive	O
a	O
new	O
dataset	O
to	O
test	O
vector	B-Method
representations	I-Method
of	I-Method
paragraphs	I-Method
.	O
	
For	O
each	O
query	O
,	O
we	O
create	O
a	O
triplet	O
of	O
paragraphs	O
:	O
the	O
two	O
paragraphs	O
are	O
results	O
of	O
the	O
same	O
query	O
,	O
whereas	O
the	O
third	O
paragraph	O
is	O
a	O
randomly	O
sampled	O
paragraph	O
from	O
the	O
rest	O
of	O
the	O
collection	O
(	O
returned	O
as	O
the	O
result	O
of	O
a	O
different	O
query	O
)	O
.	O
	
Our	O
goal	O
is	O
to	O
identify	O
which	O
of	O
the	O
three	O
paragraphs	O
are	O
results	O
of	O
the	O
same	O
query	O
.	O
	
To	O
achieve	O
this	O
,	O
we	O
will	O
use	O
paragraph	O
vectors	O
and	O
compute	O
the	O
distances	O
the	O
paragraphs	O
.	O
	
A	O
better	O
representation	O
is	O
one	O
that	O
achieves	O
a	O
small	O
distance	O
for	O
pairs	O
of	O
paragraphs	O
of	O
the	O
same	O
query	O
and	O
a	O
larg	O
distance	O
for	O
pairs	O
of	O
paragraphs	O
of	O
different	O
queries	O
.	O
	
Here	O
is	O
a	O
sample	O
of	O
three	O
paragraphs	O
,	O
where	O
the	O
first	O
paragraph	O
should	O
be	O
closer	O
to	O
the	O
second	O
paragraph	O
than	O
the	O
third	O
paragraph	O
:	O
Paragraph	O
1	O
:	O
calls	O
from	O
(	O
000	O
)	O
000	O
-	O
0000	O
.	O
	
3913	O
calls	O
reported	O
from	O
this	O
number	O
.	O
	
according	O
to	O
4	O
reports	O
the	O
identity	O
of	O
this	O
caller	O
is	O
american	O
airlines	O
.	O
	
Paragraph	O
2	O
:	O
do	O
you	O
want	O
to	O
find	O
out	O
who	O
called	O
you	O
from	O
+	O
1	O
000	O
-	O
000	O
-	O
0000	O
,	O
+	O
1	O
0000000000	O
or	O
(	O
000	O
)	O
000	O
-	O
0000	O
?	O
	
see	O
reports	O
and	O
share	O
information	O
you	O
have	O
about	O
this	O
caller	O
Paragraph	O
3	O
:	O
	
allina	O
health	O
clinic	O
patients	O
for	O
your	O
convenience	O
	
,	O
you	O
can	O
pay	O
your	O
allina	O
health	O
clinic	O
bill	O
online	O
.	O
	
pay	O
your	O
clinic	O
bill	O
now	O
,	O
question	O
and	O
answers	O
	
…	O
	
The	O
triplets	O
are	O
split	O
into	O
three	O
sets	O
:	O
80	O
%	O
for	O
training	O
,	O
10	O
%	O
for	O
validation	B-Metric
,	O
and	O
10	O
%	O
for	O
testing	O
.	O
	
Any	O
method	O
that	O
requires	O
learning	B-Task
will	O
be	O
trained	O
on	O
the	O
training	O
set	O
,	O
while	O
its	O
hyperparameters	O
will	O
be	O
selected	O
on	O
the	O
validation	O
set	O
.	O
	
We	O
benchmark	O
four	O
methods	O
to	O
compute	O
features	O
for	O
paragraphs	O
:	O
bag	B-Task
-	I-Task
of	I-Task
-	I-Task
words	I-Task
,	O
bag	B-Method
-	I-Method
of	I-Method
-	I-Method
bigrams	I-Method
,	O
averaging	O
word	O
vectors	O
and	O
Paragraph	B-Method
Vector	I-Method
.	O
	
To	O
improve	O
bag	B-Task
-	I-Task
of	I-Task
-	I-Task
bigrams	I-Task
,	O
we	O
also	O
learn	O
a	O
weighting	O
matrix	O
such	O
that	O
the	O
distance	O
between	O
the	O
first	O
two	O
paragraphs	O
is	O
minimized	O
whereas	O
the	O
distance	O
between	O
the	O
first	O
and	O
the	O
third	O
paragraph	O
is	O
maximized	O
(	O
the	O
weighting	O
factor	O
between	O
the	O
two	O
losses	O
is	O
a	O
hyperparameter	O
)	O
.	O
	
We	O
record	O
the	O
number	O
of	O
times	O
when	O
each	O
method	O
produces	O
smaller	O
distance	O
for	O
the	O
first	O
two	O
paragraphs	O
than	O
the	O
first	O
and	O
the	O
third	O
paragraph	O
.	O
	
An	O
error	O
is	O
made	O
if	O
a	O
method	O
does	O
not	O
produce	O
that	O
desirable	O
distance	B-Metric
metric	I-Metric
on	O
a	O
triplet	O
of	O
paragraphs	O
.	O
	
The	O
results	O
of	O
Paragraph	B-Method
Vector	I-Method
and	O
other	O
baselines	O
are	O
reported	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
In	O
this	O
task	O
,	O
we	O
find	O
that	O
TF	B-Method
-	I-Method
IDF	I-Method
weighting	I-Method
performs	O
better	O
than	O
raw	O
counts	O
,	O
and	O
therefore	O
we	O
only	O
report	O
the	O
results	O
of	O
methods	O
with	O
TF	B-Method
-	I-Method
IDF	I-Method
weighting	I-Method
.	O
	
The	O
results	O
show	O
that	O
Paragraph	B-Method
Vector	I-Method
works	O
well	O
and	O
gives	O
a	O
32	O
%	O
relative	O
improvement	O
in	O
terms	O
of	O
error	B-Metric
rate	I-Metric
.	O
	
The	O
fact	O
that	O
the	O
paragraph	B-Method
vector	I-Method
method	I-Method
significantly	O
outperforms	O
bag	O
of	O
words	O
and	O
bigrams	B-Method
suggests	O
that	O
our	O
proposed	O
method	O
is	O
useful	O
for	O
capturing	O
the	O
semantics	O
of	O
the	O
input	O
text	O
.	O
	
subsection	O
:	O
Some	O
further	O
observations	O
	
We	O
perform	O
further	O
experiments	O
to	O
understand	O
various	O
aspects	O
of	O
the	O
models	O
.	O
	
Here	O
’s	O
some	O
observations	O
PV	B-Method
-	I-Method
DM	I-Method
is	O
consistently	O
better	O
than	O
PV	B-Method
-	I-Method
DBOW	I-Method
.	O
	
PV	B-Method
-	I-Method
DM	I-Method
alone	O
can	O
achieve	O
results	O
close	O
to	O
many	O
results	O
in	O
this	O
paper	O
(	O
see	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
For	O
example	O
,	O
in	O
IMDB	B-Task
,	O
PV	B-Method
-	I-Method
DM	I-Method
only	O
achieves	O
7.63	O
%	O
.	O
	
The	O
combination	O
of	O
PV	B-Method
-	I-Method
DM	I-Method
and	O
PV	B-Method
	
-	B-Method
DBOW	I-Method
often	O
work	O
consistently	O
better	O
(	O
7.42	O
%	O
in	O
IMDB	B-Metric
)	O
and	O
therefore	O
recommended	O
.	O
	
Using	O
concatenation	B-Method
in	O
PV	B-Method
-	I-Method
DM	I-Method
is	O
often	O
better	O
than	O
sum	B-Method
.	O
	
In	O
IMDB	B-Task
,	O
PV	B-Method
-	I-Method
DM	I-Method
with	O
sum	B-Method
can	O
only	O
achieve	O
8.06	O
%	O
.	O
	
Perhaps	O
,	O
this	O
is	O
because	O
the	O
model	O
loses	O
the	O
ordering	O
information	O
.	O
	
It	O
’s	O
better	O
to	O
cross	O
validate	O
the	O
window	O
size	O
.	O
	
A	O
good	O
guess	O
of	O
window	O
size	O
in	O
many	O
applications	O
is	O
between	O
5	O
and	O
12	O
.	O
	
In	O
IMDB	B-Task
,	O
varying	O
the	O
window	O
sizes	O
between	O
5	O
and	O
12	O
causes	O
the	O
error	B-Metric
rate	I-Metric
to	O
fluctuate	O
0.7	O
%	O
.	O
	
Paragraph	B-Method
Vector	I-Method
can	O
be	O
expensive	O
,	O
but	O
it	O
can	O
be	O
done	O
in	O
parallel	O
at	O
test	O
time	O
.	O
	
On	O
average	O
,	O
our	O
implementation	O
takes	O
30	O
minutes	O
to	O
compute	O
the	O
paragraph	O
vectors	O
of	O
the	O
IMDB	O
test	O
set	O
,	O
using	O
a	O
16	O
core	O
machine	O
(	O
25	O
,	O
000	O
documents	O
,	O
each	O
document	O
on	O
average	O
has	O
230	O
words	O
)	O
.	O
	
section	O
:	O
Related	O
Work	O
	
Distributed	B-Method
representations	I-Method
for	O
words	O
were	O
first	O
proposed	O
in	O
and	O
have	O
become	O
a	O
successful	O
paradigm	O
,	O
especially	O
for	O
statistical	B-Task
language	I-Task
modeling	I-Task
.	O
	
Word	B-Method
vectors	I-Method
have	O
been	O
used	O
in	O
NLP	B-Task
applications	I-Task
such	O
as	O
word	B-Task
representation	I-Task
,	O
named	B-Task
entity	I-Task
recognition	I-Task
,	O
word	B-Task
sense	I-Task
disambiguation	I-Task
,	O
parsing	B-Task
,	O
tagging	B-Task
and	O
machine	B-Task
translation	I-Task
.	O
	
Representing	B-Task
phrases	I-Task
is	O
a	O
recent	O
trend	O
and	O
received	O
much	O
attention	O
.	O
	
In	O
this	O
direction	O
,	O
autoencoder	B-Method
-	I-Method
style	I-Method
models	I-Method
have	O
also	O
been	O
used	O
to	O
model	O
paragraphs	O
.	O
	
Distributed	B-Method
representations	I-Method
of	O
phrases	O
and	O
sentences	O
are	O
also	O
the	O
focus	O
of	O
Socher	O
et	O
al	O
.	O
.	O
	
Their	O
methods	O
typically	O
require	O
parsing	B-Task
and	O
is	O
shown	O
to	O
work	O
for	O
sentence	B-Task
-	I-Task
level	I-Task
representations	I-Task
.	O
	
And	O
it	O
is	O
not	O
obvious	O
how	O
to	O
extend	O
their	O
methods	O
beyond	O
single	O
sentences	O
.	O
	
Their	O
methods	O
are	O
also	O
supervised	O
and	O
thus	O
require	O
more	O
labeled	O
data	O
to	O
work	O
well	O
.	O
	
Paragraph	B-Method
Vector	I-Method
,	O
in	O
contrast	O
,	O
is	O
mostly	O
unsupervised	B-Method
and	O
thus	O
can	O
work	O
well	O
with	O
less	O
labeled	O
data	O
.	O
	
Our	O
approach	O
of	O
computing	O
the	O
paragraph	O
vectors	O
via	O
gradient	B-Method
descent	I-Method
bears	O
resemblance	O
to	O
a	O
successful	O
paradigm	O
in	O
computer	B-Task
vision	I-Task
known	O
as	O
Fisher	B-Method
kernels	I-Method
.	O
	
The	O
basic	O
construction	O
of	O
Fisher	B-Method
kernels	I-Method
is	O
the	O
gradient	B-Method
vector	I-Method
over	O
an	O
unsupervised	B-Method
generative	I-Method
model	I-Method
.	O
	
section	O
:	O
Discussion	O
	
We	O
described	O
Paragraph	B-Method
Vector	I-Method
,	O
an	O
unsupervised	B-Method
learning	I-Method
algorithm	I-Method
that	O
learns	O
vector	B-Method
representations	I-Method
for	O
variable	O
-	O
length	O
pieces	O
of	O
texts	O
such	O
as	O
sentences	O
and	O
documents	O
.	O
	
The	O
vector	B-Method
representations	I-Method
are	O
learned	O
to	O
predict	O
the	O
surrounding	O
words	O
in	O
contexts	O
sampled	O
from	O
the	O
paragraph	O
.	O
	
Our	O
experiments	O
on	O
several	O
text	B-Task
classification	I-Task
tasks	I-Task
such	O
as	O
Stanford	O
Treebank	O
and	O
IMDB	O
sentiment	O
analysis	O
datasets	O
show	O
that	O
the	O
method	O
is	O
competitive	O
with	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
.	O
	
The	O
good	O
performance	O
demonstrates	O
the	O
merits	O
of	O
Paragraph	B-Method
Vector	I-Method
in	O
capturing	O
the	O
semantics	B-Task
of	I-Task
paragraphs	I-Task
.	O
	
In	O
fact	O
,	O
paragraph	O
vectors	O
have	O
the	O
potential	O
to	O
overcome	O
many	O
weaknesses	O
of	O
bag	B-Method
-	I-Method
of	I-Method
-	I-Method
words	I-Method
models	I-Method
.	O
	
Although	O
the	O
focus	O
of	O
this	O
work	O
is	O
to	O
represent	O
texts	O
,	O
our	O
method	O
can	O
be	O
applied	O
to	O
learn	O
representations	O
for	O
sequential	O
data	O
.	O
	
In	O
non	B-Task
-	I-Task
text	I-Task
domains	I-Task
where	O
parsing	B-Task
is	O
not	O
available	O
,	O
we	O
expect	O
Paragraph	B-Method
Vector	I-Method
to	O
be	O
a	O
strong	O
alternative	O
to	O
bag	B-Method
-	I-Method
of	I-Method
-	I-Method
words	I-Method
and	O
bag	B-Method
-	I-Method
of	I-Method
-	I-Method
n	I-Method
-	I-Method
grams	I-Method
models	I-Method
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Recurrent	B-Method
Neural	I-Method
Network	I-Method
Grammars	I-Method
	
We	O
introduce	O
recurrent	B-Method
neural	I-Method
network	I-Method
grammars	I-Method
,	O
probabilistic	B-Method
models	I-Method
of	I-Method
sentences	I-Method
with	O
explicit	O
phrase	O
structure	O
.	O
	
We	O
explain	O
efficient	O
inference	B-Method
procedures	I-Method
that	O
allow	O
application	O
to	O
both	O
parsing	B-Task
and	O
language	B-Task
modeling	I-Task
.	O
	
Experiments	O
show	O
that	O
they	O
provide	O
better	O
parsing	B-Task
in	O
English	O
than	O
any	O
single	O
previously	O
published	O
supervised	B-Method
generative	I-Method
model	I-Method
and	O
better	O
language	B-Method
modeling	I-Method
than	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
sequential	B-Method
RNNs	I-Method
in	O
English	O
and	O
Chinese	O
.	O
	
Due	O
to	O
an	O
implentation	O
bug	O
in	O
the	O
RNNG	B-Method
’s	I-Method
recursive	I-Method
composition	I-Method
function	I-Method
,	O
the	O
results	O
reported	O
in	O
Dyer	O
et	O
al	O
.	O
	
(	O
2016	O
)	O
did	O
not	O
correspond	O
to	O
the	O
model	O
as	O
it	O
was	O
presented	O
.	O
	
This	O
corrigendum	O
describes	O
the	O
buggy	O
implementation	O
and	O
reports	O
results	O
with	O
a	O
corrected	O
implementation	O
.	O
	
After	O
correction	O
,	O
on	O
the	O
PTB	B-Material
§	O
23	O
and	O
CTB	O
5.1	O
test	O
sets	O
,	O
respectively	O
,	O
the	O
generative	B-Method
model	I-Method
achieves	O
language	B-Method
modeling	I-Method
perplexities	I-Method
of	O
105.2	O
and	O
148.5	O
,	O
and	O
phrase	O
-	O
structure	O
parsing	B-Task
F1	I-Metric
of	O
93.3	O
and	O
86.9	O
,	O
a	O
new	O
state	O
of	O
the	O
art	O
in	O
phrase	O
-	O
structure	O
parsing	B-Task
for	O
both	O
languages	O
.	O
	
*	O
	
subsubsection	O
:	O
	
This	O
is	O
modified	O
version	O
of	O
a	O
paper	O
originally	O
published	O
at	O
NAACL	O
2016	O
that	O
contains	O
a	O
corrigendum	O
at	O
the	O
end	O
,	O
with	O
improved	O
results	O
after	O
fixing	O
an	O
implementation	O
bug	O
in	O
the	O
RNNG	B-Method
composition	I-Method
function	I-Method
.	O
	
section	O
:	O
Introduction	O
	
Sequential	B-Method
recurrent	I-Method
neural	I-Method
networks	I-Method
(	O
RNNs	B-Method
)	O
are	O
remarkably	O
effective	O
models	O
of	O
natural	O
language	O
.	O
	
In	O
the	O
last	O
few	O
years	O
,	O
language	B-Method
model	I-Method
results	O
that	O
substantially	O
improve	O
over	O
long	O
-	O
established	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
baselines	O
have	O
been	O
obtained	O
using	O
RNNs	B-Method
as	O
well	O
as	O
in	O
various	O
conditional	B-Task
language	I-Task
modeling	I-Task
tasks	I-Task
such	O
as	O
machine	B-Task
translation	I-Task
,	O
image	B-Task
caption	I-Task
generation	I-Task
,	O
and	O
dialogue	B-Task
generation	I-Task
.	O
	
Despite	O
these	O
impressive	O
results	O
,	O
sequential	B-Method
models	I-Method
are	O
a	O
priori	O
inappropriate	O
models	O
of	O
natural	B-Task
language	I-Task
,	O
since	O
relationships	O
among	O
words	O
are	O
largely	O
organized	O
in	O
terms	O
of	O
latent	O
nested	O
structures	O
rather	O
than	O
sequential	O
surface	O
order	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
introduce	O
recurrent	B-Method
neural	I-Method
network	I-Method
grammars	I-Method
(	O
RNNGs	B-Method
;	O
§	O
[	O
reference	O
]	O
)	O
,	O
a	O
new	O
generative	B-Method
probabilistic	I-Method
model	I-Method
of	I-Method
sentences	I-Method
that	O
explicitly	O
models	O
nested	O
,	O
hierarchical	O
relationships	O
among	O
words	O
and	O
phrases	O
.	O
	
RNNGs	B-Method
operate	O
via	O
a	O
recursive	B-Method
syntactic	I-Method
process	I-Method
reminiscent	O
of	O
probabilistic	B-Method
context	I-Method
-	I-Method
free	I-Method
grammar	I-Method
generation	I-Method
,	O
but	O
decisions	O
are	O
parameterized	O
using	O
RNNs	B-Method
that	O
condition	O
on	O
the	O
entire	O
syntactic	O
derivation	O
history	O
,	O
greatly	O
relaxing	O
context	O
-	O
free	O
independence	O
assumptions	O
.	O
	
The	O
foundation	O
of	O
this	O
work	O
is	O
a	O
top	B-Method
-	I-Method
down	I-Method
variant	I-Method
of	O
transition	O
-	O
based	O
parsing	B-Task
(	O
§	O
[	O
reference	O
]	O
)	O
.	O
	
We	O
give	O
two	O
variants	O
of	O
the	O
algorithm	O
,	O
one	O
for	O
parsing	B-Task
(	O
given	O
an	O
observed	O
sentence	O
,	O
transform	O
it	O
into	O
a	O
tree	O
)	O
,	O
and	O
one	O
for	O
generation	B-Task
.	O
	
While	O
several	O
transition	B-Method
-	I-Method
based	I-Method
neural	I-Method
models	I-Method
of	O
syntactic	B-Task
generation	I-Task
exist	O
,	O
these	O
have	O
relied	O
on	O
structure	B-Method
building	I-Method
operations	I-Method
based	O
on	O
parsing	B-Task
actions	O
in	O
shift	B-Method
-	I-Method
reduce	I-Method
and	I-Method
left	I-Method
-	I-Method
corner	I-Method
parsers	I-Method
which	O
operate	O
in	O
a	O
largely	O
bottom	O
-	O
up	O
fashion	O
.	O
	
While	O
this	O
construction	O
is	O
appealing	O
because	O
inference	B-Task
is	O
relatively	O
straightforward	O
,	O
it	O
limits	O
the	O
use	O
of	O
top	O
-	O
down	O
grammar	O
information	O
,	O
which	O
is	O
helpful	O
for	O
generation	B-Task
.	O
	
RNNGs	B-Method
maintain	O
the	O
algorithmic	O
convenience	O
of	O
transition	O
-	O
based	O
parsing	B-Task
but	O
incorporate	O
top	O
-	O
down	O
(	O
i.e.	O
,	O
root	O
-	O
to	O
-	O
terminal	O
)	O
syntactic	O
information	O
(	O
§	O
[	O
reference	O
]	O
)	O
.	O
	
The	O
top	O
-	O
down	O
transition	O
set	O
that	O
RNNGs	B-Method
are	O
based	O
on	O
lends	O
itself	O
to	O
discriminative	B-Method
modeling	I-Method
as	O
well	O
,	O
where	O
sequences	O
of	O
transitions	O
are	O
modeled	O
conditional	O
on	O
the	O
full	O
input	O
sentence	O
along	O
with	O
the	O
incrementally	O
constructed	O
syntactic	O
structures	O
.	O
	
Similar	O
to	O
previously	O
published	O
discriminative	B-Method
bottom	I-Method
-	I-Method
up	I-Method
transition	I-Method
-	I-Method
based	I-Method
parsers	I-Method
,	O
greedy	B-Method
prediction	I-Method
with	O
our	O
model	O
yields	O
a	O
linear	B-Method
-	I-Method
time	I-Method
deterministic	I-Method
parser	I-Method
(	O
provided	O
an	O
upper	O
bound	O
on	O
the	O
number	O
of	O
actions	O
taken	O
between	O
processing	O
subsequent	O
terminal	O
symbols	O
is	O
imposed	O
)	O
;	O
however	O
,	O
our	O
algorithm	O
generates	O
arbitrary	O
tree	O
structures	O
directly	O
,	O
without	O
the	O
binarization	B-Method
required	O
by	O
shift	B-Method
-	I-Method
reduce	I-Method
parsers	I-Method
.	O
	
The	O
discriminative	B-Method
model	I-Method
also	O
lets	O
us	O
use	O
ancestor	B-Method
sampling	I-Method
to	O
obtain	O
samples	O
of	O
parse	O
trees	O
for	O
sentences	O
,	O
and	O
this	O
is	O
used	O
to	O
solve	O
a	O
second	O
practical	O
challenge	O
with	O
RNNGs	B-Method
:	O
approximating	O
the	O
marginal	O
likelihood	O
and	O
MAP	O
tree	O
of	O
a	O
sentence	O
under	O
the	O
generative	B-Method
model	I-Method
.	O
	
We	O
present	O
a	O
simple	O
importance	B-Method
sampling	I-Method
algorithm	I-Method
which	O
uses	O
samples	O
from	O
the	O
discriminative	B-Method
parser	I-Method
to	O
solve	O
inference	B-Task
problems	I-Task
in	O
the	O
generative	B-Method
model	I-Method
(	O
§	O
[	O
reference	O
]	O
)	O
.	O
	
Experiments	O
show	O
that	O
RNNGs	B-Method
are	O
effective	O
for	O
both	O
language	B-Task
modeling	I-Task
and	O
parsing	B-Task
(	O
§	O
[	O
reference	O
]	O
)	O
.	O
	
Our	O
generative	B-Method
model	I-Method
obtains	O
(	O
i	O
)	O
the	O
best	O
-	O
known	O
parsing	B-Task
results	O
using	O
a	O
single	O
supervised	B-Method
generative	I-Method
model	I-Method
and	O
(	O
ii	O
)	O
better	O
perplexities	B-Method
in	O
language	B-Method
modeling	I-Method
than	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
sequential	B-Method
LSTM	I-Method
language	I-Method
models	I-Method
.	O
	
Surprisingly	O
—	O
	
although	O
in	O
line	O
with	O
previous	O
parsing	B-Task
results	O
showing	O
the	O
effectiveness	O
of	O
generative	B-Method
models	I-Method
—parsing	O
with	O
the	O
generative	B-Method
model	I-Method
obtains	O
significantly	O
better	O
results	O
than	O
parsing	B-Task
with	O
the	O
discriminative	B-Method
model	I-Method
.	O
	
section	O
:	O
RNN	B-Method
Grammars	I-Method
	
Formally	O
,	O
an	O
RNNG	B-Method
is	O
a	O
triple	O
consisting	O
of	O
a	O
finite	O
set	O
of	O
nonterminal	O
symbols	O
(	O
)	O
,	O
a	O
finite	O
set	O
of	O
terminal	O
symbols	O
(	O
)	O
such	O
that	O
,	O
and	O
a	O
collection	O
of	O
neural	B-Method
network	I-Method
parameters	I-Method
.	O
	
It	O
does	O
not	O
explicitly	O
define	O
rules	O
since	O
these	O
are	O
implicitly	O
characterized	O
by	O
.	O
	
The	O
algorithm	O
that	O
the	O
grammar	B-Method
uses	O
to	O
generate	O
trees	O
and	O
strings	O
in	O
the	O
language	O
is	O
characterized	O
in	O
terms	O
of	O
a	O
transition	B-Method
-	I-Method
based	I-Method
algorithm	I-Method
,	O
which	O
is	O
outlined	O
in	O
the	O
next	O
section	O
.	O
	
In	O
the	O
section	O
after	O
that	O
,	O
the	O
semantics	O
of	O
the	O
parameters	O
that	O
are	O
used	O
to	O
turn	O
this	O
into	O
a	O
stochastic	B-Method
algorithm	I-Method
that	O
generates	O
pairs	O
of	O
trees	O
and	O
strings	O
are	O
discussed	O
.	O
	
section	O
:	O
Top	B-Task
-	I-Task
down	I-Task
Parsing	I-Task
and	O
Generation	B-Task
	
RNNGs	B-Method
are	O
based	O
on	O
a	O
top	B-Method
-	I-Method
down	I-Method
generation	I-Method
algorithm	I-Method
that	O
relies	O
on	O
a	O
stack	O
data	O
structure	O
of	O
partially	O
completed	O
syntactic	O
constituents	O
.	O
	
To	O
emphasize	O
the	O
similarity	O
of	O
our	O
algorithm	O
to	O
more	O
familiar	O
bottom	B-Method
-	I-Method
up	I-Method
shift	I-Method
-	I-Method
reduce	I-Method
recognition	I-Method
algorithms	I-Method
,	O
we	O
first	O
present	O
the	O
parsing	B-Task
(	O
rather	O
than	O
generation	O
)	O
version	O
of	O
our	O
algorithm	O
(	O
§	O
[	O
reference	O
]	O
)	O
and	O
then	O
present	O
modifications	O
to	O
turn	O
it	O
into	O
a	O
generator	B-Method
(	O
§	O
[	O
reference	O
]	O
)	O
.	O
	
subsection	O
:	O
Parser	O
Transitions	O
	
The	O
parsing	B-Task
algorithm	O
transforms	O
a	O
sequence	O
of	O
words	O
into	O
a	O
parse	O
tree	O
using	O
two	O
data	O
structures	O
(	O
a	O
stack	O
and	O
an	O
input	O
buffer	O
)	O
.	O
	
As	O
with	O
the	O
bottom	B-Method
-	I-Method
up	I-Method
algorithm	I-Method
of	O
,	O
our	O
algorithm	O
begins	O
with	O
the	O
stack	O
(	O
)	O
empty	O
and	O
the	O
complete	O
sequence	O
of	O
words	O
in	O
the	O
input	O
buffer	O
(	O
)	O
.	O
	
The	O
buffer	O
contains	O
unprocessed	O
terminal	O
symbols	O
,	O
and	O
the	O
stack	O
contains	O
terminal	O
symbols	O
,	O
“	O
open	O
”	O
nonterminal	O
symbols	O
,	O
and	O
completed	O
constituents	O
.	O
	
At	O
each	O
timestep	O
,	O
one	O
of	O
the	O
following	O
three	O
classes	O
of	O
operations	O
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
is	O
selected	O
by	O
a	O
classifier	B-Method
,	O
based	O
on	O
the	O
current	O
contents	O
on	O
the	O
stack	O
and	O
buffer	O
:	O
introduces	O
an	O
“	O
open	O
nonterminal	O
”	O
X	O
onto	O
the	O
top	O
of	O
the	O
stack	O
.	O
	
Open	O
nonterminals	O
are	O
written	O
as	O
a	O
nonterminal	O
symbol	O
preceded	O
by	O
an	O
open	O
parenthesis	O
,	O
e.g.	O
,	O
“	O
(	O
VP	O
”	O
,	O
and	O
they	O
represent	O
a	O
nonterminal	O
whose	O
child	O
nodes	O
have	O
not	O
yet	O
been	O
fully	O
constructed	O
.	O
	
Open	O
nonterminals	O
are	O
“	O
closed	O
”	O
to	O
form	O
complete	O
constituents	O
by	O
subsequent	O
reduce	B-Method
operations	I-Method
.	O
	
shift	B-Method
removes	O
the	O
terminal	O
symbol	O
from	O
the	O
front	O
of	O
the	O
input	O
buffer	O
,	O
and	O
pushes	O
it	O
onto	O
the	O
top	O
of	O
the	O
stack	O
.	O
	
reduce	O
repeatedly	O
pops	O
completed	O
subtrees	O
or	O
terminal	O
symbols	O
from	O
the	O
stack	O
until	O
an	O
open	O
nonterminal	O
is	O
encountered	O
,	O
and	O
then	O
this	O
open	O
NT	O
is	O
popped	O
and	O
used	O
as	O
the	O
label	O
of	O
a	O
new	O
constituent	O
that	O
has	O
the	O
popped	O
subtrees	O
as	O
its	O
children	O
.	O
	
This	O
new	O
completed	O
constituent	O
is	O
pushed	O
onto	O
the	O
stack	O
as	O
a	O
single	O
composite	O
item	O
.	O
	
A	O
single	O
reduce	B-Method
operation	I-Method
can	O
thus	O
create	O
constituents	O
with	O
an	O
unbounded	O
number	O
of	O
children	O
.	O
	
The	O
parsing	B-Task
algorithm	O
terminates	O
when	O
there	O
is	O
a	O
single	O
completed	O
constituent	O
on	O
the	O
stack	O
and	O
the	O
buffer	O
is	O
empty	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
an	O
example	O
parse	O
using	O
our	O
transition	O
set	O
.	O
	
Note	O
that	O
in	O
this	O
paper	O
we	O
do	O
not	O
model	O
preterminal	O
symbols	O
(	O
i.e.	O
,	O
part	O
-	O
of	O
-	O
speech	O
tags	O
)	O
and	O
our	O
examples	O
therefore	O
do	O
not	O
include	O
them	O
.	O
	
Our	O
transition	O
set	O
is	O
closely	O
related	O
to	O
the	O
operations	O
used	O
in	O
Earley	B-Method
’s	I-Method
algorithm	I-Method
which	O
likewise	O
introduces	O
nonterminals	O
symbols	O
with	O
its	O
predict	O
operation	O
and	O
later	O
complete	O
	
s	O
them	O
after	O
consuming	O
terminal	O
symbols	O
one	O
at	O
a	O
time	O
using	O
scan	O
.	O
	
It	O
is	O
likewise	O
closely	O
related	O
to	O
the	O
“	O
linearized	O
”	O
parse	O
trees	O
proposed	O
by	O
and	O
to	O
the	O
top	O
-	O
down	O
,	O
left	O
-	O
to	O
-	O
right	O
decompositions	O
of	O
trees	O
used	O
in	O
previous	O
generative	O
parsing	B-Task
and	O
language	B-Task
modeling	I-Task
work	O
.	O
	
A	O
further	O
connection	O
is	O
to	O
parsing	B-Task
which	O
uses	O
an	O
unbounded	O
lookahead	O
(	O
compactly	O
represented	O
by	O
a	O
DFA	B-Method
)	O
to	O
distinguish	O
between	O
parse	O
alternatives	O
in	O
a	O
top	B-Method
-	I-Method
down	I-Method
parser	I-Method
;	O
however	O
,	O
our	O
parser	B-Method
uses	O
an	O
RNN	B-Method
encoding	I-Method
of	O
the	O
lookahead	B-Method
rather	O
than	O
a	O
DFA	B-Method
.	O
	
Input	O
:	O
	
The	O
hungry	O
cat	O
meows	O
.	O
	
paragraph	O
:	O
Constraints	O
on	O
parser	O
transitions	O
.	O
	
To	O
guarantee	O
that	O
only	O
well	O
-	O
formed	O
phrase	O
-	O
structure	O
trees	O
are	O
produced	O
by	O
the	O
parser	B-Method
,	O
we	O
impose	O
the	O
following	O
constraints	O
on	O
the	O
transitions	O
that	O
can	O
be	O
applied	O
at	O
each	O
step	O
which	O
are	O
a	O
function	O
of	O
the	O
parser	O
state	O
where	O
is	O
the	O
number	O
of	O
open	O
nonterminals	O
on	O
the	O
stack	O
:	O
The	O
operation	O
can	O
only	O
be	O
applied	O
if	O
is	O
not	O
empty	O
and	O
.	O
	
The	O
shift	B-Method
operation	I-Method
can	O
only	O
be	O
applied	O
if	O
is	O
not	O
empty	O
and	O
.	O
	
The	O
reduce	B-Method
operation	I-Method
can	O
only	O
be	O
applied	O
if	O
the	O
top	O
of	O
the	O
stack	O
is	O
not	O
an	O
open	O
nonterminal	O
symbol	O
.	O
	
The	O
reduce	B-Method
operation	I-Method
can	O
only	O
be	O
applied	O
if	O
or	O
if	O
the	O
buffer	O
is	O
empty	O
.	O
	
To	O
designate	O
the	O
set	O
of	O
valid	O
parser	O
transitions	O
,	O
we	O
write	O
.	O
	
subsection	O
:	O
Generator	B-Method
Transitions	I-Method
	
The	O
parsing	B-Task
algorithm	O
that	O
maps	O
from	O
sequences	O
of	O
words	O
to	O
parse	O
trees	O
can	O
be	O
adapted	O
with	O
minor	O
changes	O
to	O
produce	O
an	O
algorithm	O
that	O
stochastically	O
generates	O
trees	O
and	O
terminal	O
symbols	O
.	O
	
Two	O
changes	O
are	O
required	O
:	O
(	O
i	O
)	O
there	O
is	O
no	O
input	O
buffer	O
of	O
unprocessed	O
words	O
,	O
rather	O
there	O
is	O
an	O
output	O
buffer	O
(	O
)	O
,	O
and	O
(	O
ii	O
)	O
instead	O
of	O
a	O
shift	B-Method
operation	I-Method
there	O
are	O
operations	O
which	O
generate	O
terminal	O
symbol	O
and	O
add	O
it	O
to	O
the	O
top	O
of	O
the	O
stack	O
and	O
the	O
output	O
buffer	O
.	O
	
At	O
each	O
timestep	O
an	O
action	O
is	O
stochastically	O
selected	O
according	O
to	O
a	O
conditional	O
distribution	O
that	O
depends	O
on	O
the	O
current	O
contents	O
of	O
and	O
.	O
	
The	O
algorithm	O
terminates	O
when	O
a	O
single	O
completed	O
constituent	O
remains	O
on	O
the	O
stack	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
an	O
example	O
generation	O
sequence	O
.	O
	
paragraph	O
:	O
Constraints	O
on	O
generator	O
transitions	O
.	O
	
The	O
generation	B-Method
algorithm	I-Method
also	O
requires	O
slightly	O
modified	O
constraints	O
.	O
	
These	O
are	O
:	O
The	O
operation	O
can	O
only	O
be	O
applied	O
if	O
.	O
	
The	O
reduce	B-Method
operation	I-Method
can	O
only	O
be	O
applied	O
if	O
the	O
top	O
of	O
the	O
stack	O
is	O
not	O
an	O
open	O
nonterminal	O
symbol	O
and	O
.	O
	
To	O
designate	O
the	O
set	O
of	O
valid	O
generator	O
transitions	O
,	O
we	O
write	O
.	O
	
This	O
transition	O
set	O
generates	O
trees	O
using	O
nearly	O
the	O
same	O
structure	O
building	O
actions	O
and	O
stack	O
configurations	O
as	O
the	O
“	O
top	B-Method
-	I-Method
down	I-Method
PDA	I-Method
”	I-Method
construction	I-Method
proposed	O
by	O
,	O
albeit	O
without	O
the	O
restriction	O
that	O
the	O
trees	O
be	O
in	O
Chomsky	O
normal	O
form	O
.	O
	
subsection	O
:	O
Transition	O
Sequences	O
from	O
Trees	O
	
Any	O
parse	O
tree	O
can	O
be	O
converted	O
to	O
a	O
sequence	O
of	O
transitions	O
via	O
a	O
depth	B-Method
-	I-Method
first	I-Method
,	O
left	O
-	O
to	O
-	O
right	O
traversal	O
of	O
a	O
parse	O
tree	O
.	O
	
Since	O
there	O
is	O
a	O
unique	O
depth	O
-	O
first	O
,	O
left	O
-	O
ro	O
-	O
right	O
traversal	O
of	O
a	O
tree	O
,	O
there	O
is	O
exactly	O
one	O
transition	O
sequence	O
of	O
each	O
tree	O
.	O
	
For	O
a	O
tree	O
and	O
a	O
sequence	O
of	O
symbols	O
,	O
we	O
write	O
to	O
indicate	O
the	O
corresponding	O
sequence	O
of	O
generation	O
transitions	O
,	O
and	O
to	O
indicate	O
the	O
parser	O
transitions	O
.	O
	
subsection	O
:	O
Runtime	B-Task
Analysis	I-Task
	
A	O
detailed	O
analysis	O
of	O
the	O
algorithmic	O
properties	O
of	O
our	O
top	B-Method
-	I-Method
down	I-Method
parser	I-Method
is	O
beyond	O
the	O
scope	O
of	O
this	O
paper	O
;	O
however	O
,	O
we	O
briefly	O
state	O
several	O
facts	O
.	O
	
Assuming	O
the	O
availability	O
of	O
constant	O
time	O
push	O
and	O
pop	O
operations	O
,	O
the	O
runtime	B-Metric
is	O
linear	O
in	O
the	O
number	O
of	O
the	O
nodes	O
in	O
the	O
parse	O
tree	O
that	O
is	O
generated	O
by	O
the	O
parser	B-Method
/	I-Method
generator	I-Method
(	O
intuitively	O
,	O
this	O
is	O
true	O
since	O
although	O
an	O
individual	O
reduce	B-Method
operation	I-Method
may	O
require	O
applying	O
a	O
number	O
of	O
pops	O
that	O
is	O
linear	O
in	O
the	O
number	O
of	O
input	O
symbols	O
,	O
the	O
total	O
number	O
of	O
pop	O
operations	O
across	O
an	O
entire	O
parse	B-Task
/	I-Task
generation	I-Task
run	O
will	O
also	O
be	O
linear	O
)	O
.	O
	
Since	O
there	O
is	O
no	O
way	O
to	O
bound	O
the	O
number	O
of	O
output	O
nodes	O
in	O
a	O
parse	O
tree	O
as	O
a	O
function	O
of	O
the	O
number	O
of	O
input	O
words	O
,	O
stating	O
the	O
runtime	B-Metric
complexity	I-Metric
of	O
the	O
parsing	B-Task
algorithm	O
as	O
a	O
function	O
of	O
the	O
input	O
size	O
requires	O
further	O
assumptions	O
.	O
	
Assuming	O
our	O
fixed	O
constraint	O
on	O
maximum	O
depth	O
,	O
it	O
is	O
linear	O
.	O
	
subsection	O
:	O
Comparison	O
to	O
Other	O
Models	O
	
Our	O
generation	B-Method
algorithm	I-Method
algorithm	I-Method
differs	O
from	O
previous	O
stack	O
-	O
based	O
parsing	B-Task
/	O
generation	O
algorithms	O
in	O
two	O
ways	O
.	O
	
First	O
,	O
it	O
constructs	O
rooted	O
tree	O
structures	O
top	O
down	O
(	O
rather	O
than	O
bottom	O
up	O
)	O
,	O
and	O
second	O
,	O
the	O
transition	B-Method
operators	I-Method
are	O
capable	O
of	O
directly	O
generating	O
arbitrary	O
tree	O
structures	O
rather	O
than	O
,	O
e.g.	O
,	O
assuming	O
binarized	O
trees	O
,	O
as	O
is	O
the	O
case	O
in	O
much	O
prior	O
work	O
that	O
has	O
used	O
transition	B-Method
-	I-Method
based	I-Method
algorithms	I-Method
to	O
produce	O
phrase	O
-	O
structure	O
trees	O
.	O
	
section	O
:	O
Generative	B-Method
Model	I-Method
	
RNNGs	B-Method
use	O
the	O
generator	O
transition	O
set	O
	
just	O
presented	O
to	O
define	O
a	O
joint	O
distribution	O
on	O
syntax	O
trees	O
(	O
)	O
and	O
words	O
(	O
)	O
.	O
	
This	O
distribution	O
is	O
defined	O
as	O
a	O
sequence	B-Method
model	I-Method
over	O
generator	B-Method
transitions	I-Method
that	O
is	O
parameterized	O
using	O
a	O
continuous	B-Method
space	I-Method
embedding	I-Method
of	O
the	O
algorithm	O
state	O
at	O
each	O
time	O
step	O
(	O
)	O
;	O
i.e.	O
,	O
and	O
where	O
action	O
-	O
specific	O
embeddings	O
and	O
bias	O
vector	O
are	O
parameters	O
in	O
.	O
	
The	O
representation	O
of	O
the	O
algorithm	O
state	O
at	O
time	O
,	O
,	O
is	O
computed	O
by	O
combining	O
the	O
representation	O
of	O
the	O
generator	B-Method
’s	O
three	O
data	B-Method
structures	I-Method
:	O
the	O
output	O
buffer	O
(	O
)	O
,	O
represented	O
by	O
an	O
embedding	B-Method
,	O
the	O
stack	O
(	O
)	O
,	O
represented	O
by	O
an	O
embedding	B-Method
,	O
and	O
the	O
history	O
of	O
actions	O
(	O
)	O
taken	O
by	O
the	O
generator	B-Method
,	O
represented	O
by	O
an	O
embedding	B-Method
,	O
where	O
and	O
are	O
parameters	O
.	O
	
Refer	O
to	O
Figure	O
[	O
reference	O
]	O
for	O
an	O
illustration	O
of	O
the	O
architecture	O
.	O
	
The	O
output	O
buffer	O
,	O
stack	O
,	O
and	O
history	O
are	O
sequences	O
that	O
grow	O
unboundedly	O
,	O
and	O
to	O
obtain	O
representations	O
of	O
them	O
	
we	O
use	O
recurrent	B-Method
neural	I-Method
networks	I-Method
to	O
“	O
encode	O
”	O
their	O
contents	O
.	O
	
Since	O
the	O
output	O
buffer	O
and	O
history	O
of	O
actions	O
are	O
only	O
appended	O
to	O
and	O
only	O
contain	O
symbols	O
from	O
a	O
finite	O
alphabet	O
,	O
it	O
is	O
straightforward	O
to	O
apply	O
a	O
standard	O
RNN	B-Method
encoding	I-Method
architecture	I-Method
.	O
	
The	O
stack	O
(	O
)	O
is	O
more	O
complicated	O
for	O
two	O
reasons	O
.	O
	
First	O
,	O
the	O
elements	O
of	O
the	O
stack	O
are	O
more	O
complicated	O
objects	O
than	O
symbols	O
from	O
a	O
discrete	O
alphabet	O
:	O
open	O
nonterminals	O
,	O
terminals	O
,	O
and	O
full	O
trees	O
,	O
are	O
all	O
present	O
on	O
the	O
stack	O
.	O
	
Second	O
,	O
it	O
is	O
manipulated	O
using	O
both	O
push	O
and	O
pop	O
operations	O
.	O
	
To	O
efficiently	O
obtain	O
representations	O
of	O
under	O
push	O
and	O
pop	O
operations	O
,	O
we	O
use	O
stack	B-Method
LSTMs	I-Method
.	O
	
To	O
represent	O
complex	O
parse	O
trees	O
,	O
we	O
define	O
a	O
new	O
syntactic	B-Method
composition	I-Method
function	I-Method
that	O
recursively	O
defines	O
representations	O
of	O
trees	O
.	O
	
subsection	O
:	O
Syntactic	B-Method
Composition	I-Method
Function	I-Method
	
When	O
a	O
reduce	B-Method
operation	I-Method
is	O
executed	O
,	O
the	O
parser	B-Method
pops	O
a	O
sequence	O
of	O
completed	O
subtrees	O
and	O
/	O
or	O
tokens	O
(	O
together	O
with	O
their	O
vector	O
embeddings	O
)	O
from	O
the	O
stack	O
and	O
makes	O
them	O
children	O
of	O
the	O
most	O
recent	O
open	O
nonterminal	O
on	O
the	O
stack	O
,	O
“	O
completing	O
”	O
the	O
constituent	O
.	O
	
To	O
compute	O
an	O
embedding	O
of	O
this	O
new	O
subtree	O
,	O
we	O
use	O
a	O
composition	B-Method
function	I-Method
based	O
on	O
bidirectional	B-Method
LSTMs	I-Method
,	O
which	O
is	O
illustrated	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
The	O
first	O
vector	O
read	O
by	O
the	O
LSTM	B-Method
in	O
both	O
the	O
forward	O
and	O
reverse	O
directions	O
is	O
an	O
embedding	O
of	O
the	O
label	O
on	O
the	O
constituent	O
being	O
constructed	O
(	O
in	O
the	O
figure	O
,	O
NP	O
)	O
.	O
	
This	O
is	O
followed	O
by	O
the	O
embeddings	O
of	O
the	O
child	O
subtrees	O
(	O
or	O
tokens	O
)	O
in	O
forward	O
or	O
reverse	O
order	O
.	O
	
Intuitively	O
,	O
this	O
order	O
serves	O
to	O
“	O
notify	O
”	O
each	O
LSTM	B-Method
what	O
sort	O
of	O
head	O
it	O
should	O
be	O
looking	O
for	O
as	O
it	O
processes	O
the	O
child	O
node	O
embeddings	O
.	O
	
The	O
final	O
state	O
of	O
the	O
forward	B-Method
and	I-Method
reverse	I-Method
LSTMs	I-Method
are	O
concatenated	O
,	O
passed	O
through	O
an	O
affine	B-Method
transformation	I-Method
and	O
a	O
nonlinearity	O
to	O
become	O
the	O
subtree	B-Method
embedding	I-Method
.	O
	
Because	O
each	O
of	O
the	O
child	O
node	O
embeddings	O
(	O
,	O
,	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
is	O
computed	O
similarly	O
(	O
if	O
it	O
corresponds	O
to	O
an	O
internal	O
node	O
)	O
,	O
this	O
composition	B-Method
function	I-Method
is	O
a	O
kind	O
of	O
recursive	B-Method
neural	I-Method
network	I-Method
.	O
	
subsection	O
:	O
Word	B-Task
Generation	I-Task
	
To	O
reduce	O
the	O
size	O
of	O
,	O
word	B-Task
generation	I-Task
is	O
broken	O
into	O
two	O
parts	O
.	O
	
First	O
,	O
the	O
decision	O
to	O
generate	O
is	O
made	O
(	O
by	O
predicting	O
gen	O
as	O
an	O
action	O
)	O
,	O
and	O
then	O
choosing	O
the	O
word	O
,	O
conditional	O
on	O
the	O
current	O
parser	O
state	O
.	O
	
To	O
further	O
reduce	O
the	O
computational	B-Metric
complexity	I-Metric
of	O
modeling	O
the	O
generation	B-Task
of	I-Task
a	I-Task
word	I-Task
,	O
we	O
use	O
a	O
class	B-Method
-	I-Method
factored	I-Method
softmax	I-Method
.	O
	
By	O
using	O
classes	O
for	O
a	O
vocabulary	O
of	O
size	O
,	O
this	O
prediction	B-Method
step	I-Method
runs	O
in	O
time	O
rather	O
than	O
the	O
of	O
the	O
full	B-Method
-	I-Method
vocabulary	I-Method
softmax	I-Method
.	O
	
To	O
obtain	O
clusters	O
,	O
we	O
use	O
the	O
greedy	B-Method
agglomerative	I-Method
clustering	I-Method
algorithm	I-Method
of	O
.	O
	
subsection	O
:	O
Training	O
	
The	O
parameters	O
in	O
the	O
model	O
are	O
learned	O
to	O
maximize	O
the	O
likelihood	O
of	O
a	O
corpus	O
of	O
trees	O
.	O
	
subsection	O
:	O
Discriminative	B-Method
Parsing	I-Method
Model	I-Method
	
A	O
discriminative	O
parsing	B-Task
model	O
can	O
be	O
obtained	O
by	O
replacing	O
the	O
embedding	O
of	O
at	O
each	O
time	O
step	O
with	O
an	O
embedding	O
of	O
the	O
input	O
buffer	O
.	O
	
To	O
train	O
this	O
model	O
,	O
the	O
conditional	O
likelihood	O
of	O
each	O
sequence	O
of	O
actions	O
given	O
the	O
input	O
string	O
is	O
maximized	O
.	O
	
section	O
:	O
Inference	B-Task
via	O
Importance	B-Method
Sampling	I-Method
	
Our	O
generative	B-Method
model	I-Method
defines	O
a	O
joint	O
distribution	O
on	O
trees	O
(	O
)	O
and	O
sequences	O
of	O
words	O
(	O
)	O
.	O
	
To	O
evaluate	O
this	O
as	O
a	O
language	B-Method
model	I-Method
,	O
it	O
is	O
necessary	O
to	O
compute	O
the	O
marginal	O
probability	O
.	O
	
And	O
,	O
to	O
evaluate	O
the	O
model	O
as	O
a	O
parser	B-Method
,	O
we	O
need	O
to	O
be	O
able	O
to	O
find	O
the	O
MAP	O
parse	O
tree	O
,	O
i.e.	O
,	O
the	O
tree	O
that	O
maximizes	O
.	O
	
However	O
,	O
because	O
of	O
the	O
unbounded	O
dependencies	O
across	O
the	O
sequence	O
of	O
parsing	B-Task
actions	O
in	O
our	O
model	O
,	O
exactly	O
solving	O
either	O
of	O
these	O
inference	B-Task
problems	I-Task
is	O
intractable	O
.	O
	
To	O
obtain	O
estimates	O
of	O
these	O
,	O
we	O
use	O
a	O
variant	O
of	O
importance	B-Method
sampling	I-Method
.	O
	
Our	O
importance	B-Method
sampling	I-Method
algorithm	I-Method
uses	O
a	O
conditional	B-Method
proposal	I-Method
distribution	I-Method
with	O
the	O
following	O
properties	O
:	O
(	O
i	O
)	O
;	O
(	O
ii	O
)	O
samples	O
can	O
be	O
obtained	O
efficiently	O
;	O
and	O
(	O
iii	O
)	O
the	O
conditional	O
probabilities	O
of	O
these	O
samples	O
are	O
known	O
.	O
	
While	O
many	O
such	O
distributions	O
are	O
available	O
,	O
the	O
discriminatively	B-Method
trained	I-Method
variant	I-Method
of	O
our	O
parser	B-Method
(	O
§	O
[	O
reference	O
]	O
)	O
fulfills	O
these	O
requirements	O
:	O
sequences	O
of	O
actions	O
can	O
be	O
sampled	O
using	O
a	O
simple	O
ancestral	B-Method
sampling	I-Method
approach	I-Method
,	O
and	O
,	O
since	O
parse	O
trees	O
and	O
action	O
sequences	O
exist	O
in	O
a	O
one	O
-	O
to	O
-	O
one	O
relationship	O
,	O
the	O
product	O
of	O
the	O
action	O
probabilities	O
is	O
the	O
conditional	O
probability	O
of	O
the	O
parse	O
tree	O
under	O
.	O
	
We	O
therefore	O
use	O
our	O
discriminative	B-Method
parser	I-Method
as	O
our	O
proposal	B-Method
distribution	I-Method
.	O
	
Importance	B-Method
sampling	I-Method
uses	O
importance	O
weights	O
,	O
which	O
we	O
define	O
as	O
,	O
to	O
compute	O
this	O
estimate	O
.	O
	
Under	O
this	O
definition	O
,	O
we	O
can	O
derive	O
the	O
estimator	O
as	O
follows	O
:	O
We	O
now	O
replace	O
this	O
expectation	O
with	O
its	O
Monte	B-Method
Carlo	I-Method
estimate	I-Method
as	O
follows	O
,	O
using	O
samples	O
from	O
:	O
To	O
obtain	O
an	O
estimate	O
of	O
the	O
MAP	O
tree	O
,	O
we	O
choose	O
the	O
sampled	O
tree	O
with	O
the	O
highest	O
probability	O
under	O
the	O
joint	B-Method
model	I-Method
.	O
	
section	O
:	O
Experiments	O
	
We	O
present	O
results	O
of	O
our	O
two	O
models	O
both	O
on	O
parsing	B-Task
(	O
discriminative	B-Method
and	I-Method
generative	I-Method
)	O
and	O
as	O
a	O
language	B-Method
model	I-Method
(	O
generative	B-Method
only	I-Method
)	O
in	O
English	O
and	O
Chinese	O
.	O
	
paragraph	O
:	O
Data	O
.	O
	
For	O
English	O
,	O
§	O
2–21	O
of	O
the	O
Penn	B-Material
Treebank	I-Material
are	O
used	O
as	O
training	O
corpus	O
for	O
both	O
,	O
with	O
§	O
24	O
held	O
out	O
as	O
validation	O
,	O
and	O
§	O
23	O
used	O
for	O
evaluation	O
.	O
	
Singleton	O
words	O
in	O
the	O
training	O
corpus	O
with	O
unknown	O
word	O
classes	O
using	O
the	O
the	O
Berkeley	B-Method
parser	I-Method
’s	I-Method
mapping	I-Method
rules	I-Method
.	O
	
Orthographic	O
case	O
distinctions	O
are	O
preserved	O
,	O
and	O
numbers	O
(	O
beyond	O
singletons	O
)	O
are	O
not	O
normalized	O
.	O
	
For	O
Chinese	O
,	O
we	O
use	O
the	O
Penn	O
Chinese	O
Treebank	O
Version	O
5.1	O
(	O
CTB	O
)	O
.	O
	
For	O
the	O
Chinese	O
experiments	O
,	O
we	O
use	O
a	O
single	O
unknown	O
word	O
class	O
.	O
	
Corpus	O
statistics	O
are	O
given	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
paragraph	O
:	O
Model	O
and	O
training	O
parameters	O
.	O
	
For	O
the	O
discriminative	B-Method
model	I-Method
,	O
we	O
used	O
hidden	O
dimensions	O
of	O
128	O
and	O
2	B-Method
-	I-Method
layer	I-Method
LSTMs	I-Method
(	O
larger	O
numbers	O
of	O
dimensions	O
reduced	O
validation	O
set	O
performance	O
)	O
.	O
	
For	O
the	O
generative	B-Method
model	I-Method
,	O
we	O
used	O
256	O
dimensions	O
and	O
2	B-Method
-	I-Method
layer	I-Method
LSTMs	I-Method
.	O
	
For	O
both	O
models	O
,	O
we	O
tuned	O
the	O
dropout	B-Metric
rate	I-Metric
to	O
maximize	O
validation	B-Metric
set	I-Metric
likelihood	I-Metric
,	O
obtaining	O
optimal	O
rates	O
of	O
0.2	O
(	O
discriminative	O
)	O
and	O
0.3	O
(	O
generative	O
)	O
.	O
	
For	O
the	O
sequential	B-Method
LSTM	I-Method
baseline	I-Method
for	O
the	O
language	B-Method
model	I-Method
,	O
we	O
also	O
found	O
an	O
optimal	O
dropout	B-Metric
rate	I-Metric
of	I-Metric
0.3	I-Metric
.	O
	
For	O
training	B-Task
we	O
used	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
with	O
a	O
learning	B-Metric
rate	I-Metric
of	I-Metric
0.1	I-Metric
.	O
	
All	O
parameters	O
were	O
initialized	O
according	O
to	O
recommendations	O
given	O
by	O
.	O
	
paragraph	O
:	O
English	O
parsing	B-Task
results	O
.	O
	
Table	O
[	O
reference	O
]	O
(	O
last	O
two	O
rows	O
)	O
gives	O
the	O
performance	O
of	O
our	O
parser	B-Method
on	O
Section	O
23	O
,	O
as	O
well	O
as	O
the	O
performance	O
of	O
several	O
representative	O
models	O
.	O
	
For	O
the	O
discriminative	B-Method
model	I-Method
,	O
we	O
used	O
a	O
greedy	B-Method
decoding	I-Method
rule	I-Method
as	O
opposed	O
to	O
beam	B-Method
search	I-Method
in	O
some	O
shift	B-Method
-	I-Method
reduce	I-Method
baselines	I-Method
.	O
	
For	O
the	O
generative	B-Method
model	I-Method
,	O
we	O
obtained	O
100	O
independent	O
samples	O
from	O
a	O
flattened	O
distribution	O
of	O
the	O
discriminative	B-Method
parser	I-Method
(	O
by	O
exponentiating	O
each	O
probability	O
by	O
and	O
renormalizing	O
)	O
and	O
reranked	O
them	O
according	O
to	O
the	O
generative	B-Method
model	I-Method
.	O
	
paragraph	O
:	O
Chinese	O
parsing	B-Task
results	O
.	O
	
Chinese	O
parsing	B-Task
results	O
were	O
obtained	O
with	O
the	O
same	O
methodology	O
as	O
in	O
English	O
and	O
show	O
the	O
same	O
pattern	O
(	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
paragraph	O
:	O
Language	B-Method
model	I-Method
results	O
.	O
	
We	O
report	O
held	O
-	O
out	O
per	O
-	O
word	B-Metric
perplexities	I-Metric
of	O
three	O
language	B-Method
models	I-Method
,	O
both	O
sequential	B-Task
and	I-Task
syntactic	I-Task
.	O
	
Log	O
probabilities	O
are	O
normalized	O
by	O
the	O
number	O
of	O
words	O
(	O
excluding	O
the	O
stop	O
symbol	O
)	O
,	O
inverted	O
,	O
and	O
exponentiated	O
to	O
yield	O
the	O
perplexity	O
.	O
	
Results	O
are	O
summarized	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
Discussion	O
	
It	O
is	O
clear	O
from	O
our	O
experiments	O
that	O
the	O
proposed	O
generative	B-Method
model	I-Method
is	O
quite	O
effective	O
both	O
as	O
a	O
parser	B-Method
and	O
as	O
a	O
language	B-Method
model	I-Method
.	O
	
This	O
is	O
the	O
result	O
of	O
(	O
i	O
)	O
relaxing	O
conventional	O
independence	O
assumptions	O
(	O
e.g.	O
,	O
context	O
-	O
freeness	O
)	O
and	O
(	O
ii	O
)	O
inferring	O
continuous	B-Method
representations	I-Method
of	I-Method
symbols	I-Method
alongside	O
non	B-Method
-	I-Method
linear	I-Method
models	I-Method
of	O
their	O
syntactic	O
relationships	O
.	O
	
The	O
most	O
significant	O
question	O
that	O
remains	O
is	O
why	O
the	O
discriminative	B-Method
model	I-Method
—	O
which	O
has	O
more	O
information	O
available	O
to	O
it	O
than	O
the	O
generative	B-Method
model	I-Method
—	O
performs	O
worse	O
than	O
the	O
generative	B-Method
model	I-Method
.	O
	
This	O
pattern	O
has	O
been	O
observed	O
before	O
in	O
neural	O
parsing	B-Task
by	O
,	O
who	O
hypothesized	O
that	O
larger	O
,	O
unstructured	O
conditioning	O
contexts	O
are	O
harder	O
to	O
learn	O
from	O
,	O
and	O
provide	O
opportunities	O
to	O
overfit	O
.	O
	
Our	O
discriminative	B-Method
model	I-Method
conditions	O
on	O
the	O
entire	O
history	O
,	O
stack	O
,	O
and	O
buffer	O
,	O
while	O
our	O
generative	B-Method
model	I-Method
only	O
accesses	O
the	O
history	O
and	O
stack	O
.	O
	
The	O
fully	B-Method
discriminative	I-Method
model	I-Method
of	O
was	O
able	O
to	O
obtain	O
results	O
similar	O
to	O
those	O
of	O
our	O
generative	B-Method
model	I-Method
(	O
albeit	O
using	O
much	O
larger	O
training	O
sets	O
obtained	O
through	O
semisupervision	B-Method
)	O
but	O
similar	O
results	O
to	O
those	O
of	O
our	O
discriminative	B-Method
parser	I-Method
using	O
the	O
same	O
data	O
.	O
	
In	O
light	O
of	O
their	O
results	O
,	O
we	O
believe	O
Henderson	O
’s	O
hypothesis	O
is	O
correct	O
,	O
and	O
that	O
generative	B-Method
models	I-Method
should	O
be	O
considered	O
as	O
a	O
more	O
statistically	O
efficient	O
method	O
for	O
learning	O
neural	B-Method
networks	I-Method
from	O
small	O
data	O
.	O
	
section	O
:	O
Related	O
Work	O
	
Our	O
language	B-Method
model	I-Method
combines	O
work	O
from	O
two	O
modeling	O
traditions	O
:	O
(	O
i	O
)	O
recurrent	B-Method
neural	I-Method
network	I-Method
language	I-Method
models	I-Method
and	O
(	O
ii	O
)	O
syntactic	B-Method
language	I-Method
modeling	I-Method
.	O
	
Recurrent	B-Method
neural	I-Method
network	I-Method
language	I-Method
models	I-Method
use	O
RNNs	B-Method
to	O
compute	O
representations	O
of	O
an	O
unbounded	O
history	O
of	O
words	O
in	O
a	O
left	O
-	O
to	O
-	O
right	B-Method
language	I-Method
model	I-Method
.	O
	
Syntactic	B-Method
language	I-Method
models	I-Method
jointly	O
generate	O
a	O
syntactic	O
structure	O
and	O
a	O
sequence	O
of	O
words	O
.	O
	
There	O
is	O
an	O
extensive	O
literature	O
here	O
,	O
but	O
one	O
strand	O
of	O
work	O
has	O
emphasized	O
a	O
bottom	B-Task
-	I-Task
up	I-Task
generation	I-Task
of	I-Task
the	I-Task
tree	I-Task
,	O
using	O
variants	O
of	O
shift	B-Method
-	I-Method
reduce	I-Method
parser	I-Method
actions	I-Method
to	O
define	O
the	O
probability	O
space	O
.	O
	
The	O
neural	B-Method
-	I-Method
network	I-Method
–	I-Method
based	I-Method
model	I-Method
of	O
is	O
particularly	O
similar	O
to	O
ours	O
in	O
using	O
an	O
unbounded	O
history	O
in	O
a	O
neural	B-Method
network	I-Method
architecture	I-Method
to	O
parameterize	O
generative	O
parsing	B-Task
based	O
on	O
a	O
left	B-Method
-	I-Method
corner	I-Method
model	I-Method
.	O
	
Dependency	B-Method
-	I-Method
only	I-Method
language	I-Method
models	I-Method
have	O
also	O
been	O
explored	O
.	O
	
Modeling	B-Task
generation	I-Task
top	I-Task
-	I-Task
down	I-Task
as	O
a	O
rooted	B-Method
branching	I-Method
process	I-Method
that	O
recursively	O
rewrites	O
nonterminals	O
has	O
been	O
explored	O
by	O
and	O
.	O
	
Of	O
particular	O
note	O
is	O
the	O
work	O
of	O
,	O
which	O
uses	O
random	B-Method
forests	I-Method
and	O
hand	O
-	O
engineered	O
features	O
over	O
the	O
entire	O
syntactic	O
derivation	O
history	O
to	O
make	O
decisions	O
over	O
the	O
next	O
action	O
to	O
take	O
.	O
	
The	O
neural	B-Method
networks	I-Method
we	O
use	O
to	O
model	O
sentences	O
are	O
structured	O
according	O
to	O
the	O
syntax	O
of	O
the	O
sentence	O
being	O
generated	O
.	O
	
Syntactically	B-Method
structured	I-Method
neural	I-Method
architectures	I-Method
have	O
been	O
explored	O
in	O
a	O
number	O
of	O
applications	O
,	O
including	O
discriminative	O
parsing	B-Task
,	O
sentiment	B-Task
analysis	I-Task
,	O
and	O
sentence	B-Task
representation	I-Task
.	O
	
However	O
,	O
these	O
models	O
have	O
been	O
,	O
without	O
exception	O
,	O
discriminative	O
;	O
this	O
is	O
the	O
first	O
work	O
to	O
use	O
syntactically	B-Method
structured	I-Method
neural	I-Method
models	I-Method
to	O
generate	O
language	O
.	O
	
Earlier	O
work	O
has	O
demonstrated	O
that	O
sequential	B-Method
RNNs	I-Method
have	O
the	O
capacity	O
to	O
recognize	O
context	O
-	O
free	O
(	O
and	O
beyond	O
)	O
languages	O
.	O
	
In	O
contrast	O
,	O
our	O
work	O
may	O
be	O
understood	O
as	O
a	O
way	O
of	O
incorporating	O
a	O
context	O
-	O
free	O
inductive	O
bias	O
into	O
the	O
model	O
structure	O
.	O
	
section	O
:	O
Outlook	O
	
RNNGs	B-Method
can	O
be	O
combined	O
with	O
a	O
particle	B-Method
filter	I-Method
inference	I-Method
scheme	I-Method
(	O
rather	O
than	O
the	O
importance	B-Method
sampling	I-Method
method	I-Method
based	O
on	O
a	O
discriminative	B-Method
parser	I-Method
,	O
§	O
[	O
reference	O
]	O
)	O
to	O
produce	O
a	O
left	B-Method
-	I-Method
to	I-Method
-	I-Method
right	I-Method
marginalization	I-Method
algorithm	I-Method
that	O
runs	O
in	O
expected	O
linear	O
time	O
.	O
	
Thus	O
,	O
they	O
could	O
be	O
used	O
in	O
applications	O
that	O
require	O
language	B-Method
models	I-Method
.	O
	
A	O
second	O
possibility	O
is	O
to	O
replace	O
the	O
sequential	B-Method
generation	I-Method
architectures	I-Method
found	O
in	O
many	O
neural	B-Method
network	I-Method
transduction	I-Method
problems	I-Method
that	O
produce	O
sentences	O
conditioned	O
on	O
some	O
input	O
.	O
	
Previous	O
work	O
in	O
machine	B-Task
translation	I-Task
has	O
showed	O
that	O
conditional	B-Method
syntactic	I-Method
models	I-Method
can	O
function	O
quite	O
well	O
without	O
the	O
computationally	O
expensive	O
marginalization	B-Method
process	I-Method
at	O
decoding	O
time	O
.	O
	
A	O
third	O
consideration	O
regarding	O
how	O
RNNGs	B-Method
,	O
human	B-Task
sentence	I-Task
processing	I-Task
takes	O
place	O
in	O
a	O
left	O
-	O
to	O
-	O
right	O
,	O
incremental	O
order	O
.	O
	
While	O
an	O
RNNG	B-Method
is	O
not	O
a	O
processing	B-Method
model	I-Method
(	O
it	O
is	O
a	O
grammar	B-Method
)	O
,	O
the	O
fact	O
that	O
it	O
is	O
left	O
-	O
to	O
-	O
right	O
opens	O
up	O
several	O
possibilities	O
for	O
developing	O
new	O
sentence	B-Method
processing	I-Method
models	I-Method
based	O
on	O
an	O
explicit	B-Method
grammars	I-Method
,	O
similar	O
to	O
the	O
processing	B-Method
model	I-Method
of	O
.	O
	
Finally	O
,	O
although	O
we	O
considered	O
only	O
the	O
supervised	B-Task
learning	I-Task
scenario	I-Task
,	O
RNNGs	B-Method
are	O
joint	B-Method
models	I-Method
that	O
could	O
be	O
trained	O
without	O
trees	O
,	O
for	O
example	O
,	O
using	O
expectation	B-Method
maximization	I-Method
.	O
	
section	O
:	O
Conclusion	O
	
We	O
introduced	O
recurrent	B-Method
neural	I-Method
network	I-Method
grammars	I-Method
,	O
a	O
probabilistic	B-Method
model	I-Method
of	I-Method
phrase	I-Method
-	I-Method
structure	I-Method
trees	I-Method
that	O
can	O
be	O
trained	O
generatively	O
and	O
used	O
as	O
a	O
language	B-Method
model	I-Method
or	O
a	O
parser	B-Method
,	O
and	O
a	O
corresponding	O
discriminative	B-Method
model	I-Method
that	O
can	O
be	O
used	O
as	O
a	O
parser	B-Method
.	O
	
Apart	O
from	O
out	B-Method
-	I-Method
of	I-Method
-	I-Method
vocabulary	I-Method
preprocessing	I-Method
,	O
the	O
approach	O
requires	O
no	O
feature	B-Method
design	I-Method
or	O
transformations	B-Method
to	O
treebank	B-Material
data	I-Material
.	O
	
The	O
generative	B-Method
model	I-Method
outperforms	O
every	O
previously	O
published	O
parser	B-Method
built	O
on	O
a	O
single	O
supervised	B-Method
generative	I-Method
model	I-Method
in	O
English	O
,	O
and	O
a	O
bit	O
behind	O
the	O
best	O
-	O
reported	O
generative	B-Method
model	I-Method
in	O
Chinese	O
.	O
	
As	O
language	B-Method
models	I-Method
,	O
RNNGs	B-Method
outperform	O
the	O
best	O
single	B-Method
-	I-Method
sentence	I-Method
language	I-Method
models	I-Method
.	O
	
section	O
:	O
Acknowledgments	O
	
We	O
thank	O
Brendan	O
O’Connor	O
,	O
Swabha	O
Swayamdipta	O
,	O
and	O
Brian	O
Roark	O
for	O
feedback	O
on	O
drafts	O
of	O
this	O
paper	O
,	O
and	O
Jan	O
Buys	O
,	O
Phil	O
Blunsom	O
,	O
and	O
Yue	O
Zhang	O
for	O
help	O
with	O
data	B-Task
preparation	I-Task
.	O
	
This	O
work	O
was	O
sponsored	O
in	O
part	O
by	O
the	O
Defense	O
Advanced	O
Research	O
Projects	O
Agency	O
(	O
DARPA	O
)	O
Information	O
Innovation	O
Office	O
(	O
I2O	O
)	O
under	O
the	O
Low	O
Resource	O
Languages	O
for	O
Emergent	O
Incidents	O
(	O
LORELEI	O
)	O
program	O
issued	O
by	O
DARPA	O
/	O
I2O	O
under	O
	
Contract	O
No	O
.	O
	
HR0011	O
-	O
15	O
-	O
C	O
-	O
0114	O
	
;	O
it	O
was	O
also	O
supported	O
in	O
part	O
by	O
Contract	O
No	O
.	O
	
W911NF	O
-	O
15	O
-	O
1	O
-	O
0543	O
	
with	O
the	O
DARPA	O
and	O
the	O
Army	O
Research	O
Office	O
(	O
ARO	O
)	O
.	O
	
Approved	O
for	O
public	O
release	O
,	O
distribution	O
unlimited	O
.	O
	
The	O
views	O
expressed	O
are	O
those	O
of	O
the	O
authors	O
and	O
do	O
not	O
reflect	O
the	O
official	O
policy	O
or	O
position	O
of	O
the	O
Department	O
of	O
Defense	O
or	O
the	O
U.S.	O
Government	O
.	O
	
Miguel	O
Ballesteros	O
was	O
supported	O
by	O
the	O
European	O
Commission	O
under	O
the	O
contract	O
numbers	O
FP7	O
-	O
ICT	O
-	O
610411	O
(	O
project	O
MULTISENSOR	O
)	O
and	O
H2020	O
-	O
RIA	O
-	O
645012	O
(	O
project	O
KRISTINA	O
)	O
.	O
	
bibliography	O
:	O
References	O
	
Chris	O
Dyer⁢	O
♠	O
♣	O
Adhiguna	O
Kuncoro	O
♠	O
Miguel	O
Ballesteros	O
♢	O
Noah	O
A.	O
Smith	O
♡	O
School	O
of	O
Computer	O
Science	O
,	O
Carnegie	O
Mellon	O
University	O
,	O
Pittsburgh	O
,	O
PA	O
,	O
USA	O
NLP	O
Group	O
,	O
Pompeu	O
Fabra	O
University	O
,	O
Barcelona	O
,	O
Spain	O
Google	O
DeepMind	O
,	O
London	O
,	O
UK	O
Computer	O
Science	O
&	O
Engineering	O
,	O
University	O
of	O
Washington	O
,	O
Seattle	O
,	O
WA	O
,	O
USA	O
{	O
cdyer	O
,	O
akuncoro}@cs.cmu.edumiguel.ballesteros@upf.edu	O
,	O
nasmith@cs.washington.edu	O
	
section	O
:	O
RNNG	B-Method
Composition	I-Method
Function	I-Method
and	O
Implementation	O
Error	O
	
The	O
composition	B-Method
function	I-Method
reduces	O
a	O
completed	O
constituent	O
into	O
a	O
single	O
vector	B-Method
representation	I-Method
using	O
a	O
bidirectional	B-Method
LSTM	I-Method
(	O
Figure	O
[	O
reference	O
]	O
)	O
over	O
embeddings	O
of	O
the	O
constituent	O
’s	O
children	O
as	O
well	O
as	O
an	O
embedding	O
of	O
the	O
resulting	O
nonterminal	O
symbol	O
type	O
.	O
	
The	O
implementation	O
error	O
(	O
Figure	O
[	O
reference	O
]	O
)	O
composed	O
the	O
constituent	O
(	O
NP	O
the	O
hungry	O
cat	O
)	O
by	O
reading	O
the	O
sequence	O
	
“	O
NP	O
the	O
hungry	O
NP	O
”	O
,	O
that	O
is	O
,	O
it	O
discarded	O
the	O
rightmost	O
child	O
of	O
every	O
constituent	O
and	O
replaced	O
it	O
with	O
a	O
second	O
copy	O
of	O
the	O
constituent	O
’s	O
nonterminal	O
symbol	O
.	O
	
This	O
error	O
occurs	O
for	O
every	O
constituent	O
and	O
means	O
crucial	O
information	O
is	O
not	O
properly	O
propagated	O
upwards	O
in	O
the	O
tree	O
.	O
	
section	O
:	O
Results	O
after	O
Correction	O
	
The	O
implementation	B-Metric
error	I-Metric
affected	O
both	O
the	O
generative	O
and	O
discriminative	O
RNNGs	B-Method
.	O
	
We	O
summarize	O
corrected	O
English	O
phrase	O
-	O
structure	O
PTB	B-Material
§	O
23	O
parsing	B-Task
result	O
in	O
Table	O
[	O
reference	O
]	O
,	O
Chinese	O
(	O
CTB	O
5.1	O
§	O
271–300	O
)	O
in	O
Table	O
[	O
reference	O
]	O
(	O
achieving	O
the	O
the	O
best	O
reported	O
result	O
on	O
both	O
datasets	O
)	O
,	O
and	O
English	B-Task
and	I-Task
Chinese	I-Task
language	I-Task
modeling	I-Task
perplexities	I-Task
in	O
Table	O
[	O
reference	O
]	O
.	O
	
The	O
considerable	O
improvement	O
in	O
parsing	B-Task
accuracy	O
indicates	O
that	O
properly	O
composing	O
the	O
constituent	O
and	O
propagating	O
information	O
upwards	O
is	O
crucial	O
.	O
	
Despite	O
slightly	O
higher	O
language	B-Metric
modeling	I-Metric
perplexity	I-Metric
on	O
PTB	B-Material
§	O
23	O
,	O
the	O
fixed	B-Method
RNNG	I-Method
still	O
outperforms	O
a	O
highly	O
optimized	O
sequential	B-Method
LSTM	I-Method
baseline	I-Method
.	O
	
document	O
:	O
Snips	B-Method
Voice	I-Method
Platform	I-Method
:	O
an	O
embedded	B-Method
Spoken	I-Method
Language	I-Method
Understanding	I-Method
system	I-Method
for	O
private	B-Task
-	I-Task
by	I-Task
-	I-Task
design	I-Task
voice	I-Task
interfaces	I-Task
	
This	O
paper	O
presents	O
the	O
machine	B-Method
learning	I-Method
architecture	I-Method
of	O
the	O
Snips	B-Method
Voice	I-Method
Platform	I-Method
,	O
a	O
software	B-Method
solution	I-Method
to	O
perform	O
Spoken	B-Task
Language	I-Task
Understanding	I-Task
on	O
microprocessors	O
typical	O
of	O
IoT	B-Task
devices	I-Task
.	O
	
The	O
embedded	B-Method
inference	I-Method
is	O
fast	O
and	O
accurate	O
while	O
enforcing	O
privacy	O
by	O
design	O
,	O
as	O
no	O
personal	O
user	O
data	O
is	O
ever	O
collected	O
.	O
	
Focusing	O
on	O
Automatic	B-Task
Speech	I-Task
Recognition	I-Task
and	O
Natural	B-Method
Language	I-Method
Understanding	I-Method
,	O
we	O
detail	O
our	O
approach	O
to	O
training	O
high	O
-	O
performance	O
Machine	B-Method
Learning	I-Method
models	I-Method
that	O
are	O
small	O
enough	O
to	O
run	O
in	O
real	O
-	O
time	O
on	O
small	O
devices	O
.	O
	
Additionally	O
,	O
we	O
describe	O
a	O
data	B-Method
generation	I-Method
procedure	I-Method
that	O
provides	O
sufficient	O
,	O
high	O
-	O
quality	O
training	O
data	O
without	O
compromising	O
user	O
privacy	O
.	O
	
section	O
:	O
Introduction	O
	
Over	O
the	O
last	O
years	O
,	O
thanks	O
in	O
part	O
to	O
steady	O
improvements	O
brought	O
by	O
deep	B-Method
learning	I-Method
approaches	I-Method
to	O
speech	B-Task
recognition	I-Task
,	O
voice	B-Task
interfaces	I-Task
have	O
greatly	O
evolved	O
from	O
spotting	O
limited	O
and	O
predetermined	O
keywords	O
to	O
understanding	O
arbitrary	O
formulations	O
of	O
a	O
given	O
intention	O
.	O
	
They	O
also	O
became	O
much	O
more	O
reliable	O
,	O
with	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
speech	B-Task
recognition	I-Task
engines	O
reaching	O
human	O
level	O
in	O
English	O
.	O
	
This	O
achievement	O
unlocked	O
many	O
practical	O
applications	O
of	O
voice	B-Task
assistants	I-Task
which	O
are	O
now	O
used	O
in	O
many	O
fields	O
from	O
customer	B-Task
support	I-Task
,	O
to	O
autonomous	B-Task
cars	I-Task
,	O
or	O
smart	B-Task
homes	I-Task
.	O
	
In	O
particular	O
,	O
smart	B-Task
speaker	I-Task
adoption	I-Task
by	O
the	O
public	O
is	O
on	O
the	O
rise	O
,	O
with	O
a	O
recent	O
study	O
showing	O
that	O
nearly	O
20	O
%	O
of	O
U.S.	O
adults	O
reported	O
having	O
a	O
smart	O
speaker	O
at	O
home	O
.	O
	
These	O
recent	O
developments	O
however	O
raise	O
questions	O
about	O
user	O
privacy	O
–	O
especially	O
since	O
unique	B-Task
speaker	I-Task
identification	I-Task
is	O
an	O
active	O
field	O
of	O
research	O
using	O
voice	O
as	O
a	O
sensitive	O
biometric	O
feature	O
.	O
	
The	O
CNIL	B-Method
(	O
French	O
Data	O
Protection	O
Authority	O
)	O
advises	O
owners	O
of	O
connected	O
speakers	O
to	O
switch	O
off	O
the	O
microphone	O
when	O
possible	O
and	O
to	O
warn	O
guests	O
of	O
the	O
presence	O
of	O
such	O
a	O
device	O
in	O
their	O
home	O
.	O
	
The	O
General	O
Data	B-Method
Protection	I-Method
Regulation	I-Method
which	O
harmonizes	O
data	O
privacy	O
laws	O
across	O
the	O
European	O
Union	O
indeed	O
requires	O
companies	O
to	O
ask	O
for	O
explicit	O
consent	O
before	O
collecting	O
user	O
data	O
.	O
	
Some	O
of	O
the	O
most	O
popular	O
commercial	O
solutions	O
for	O
voice	B-Task
assistants	I-Task
include	O
Microsoft	O
’s	O
Cortana	O
,	O
Google	O
’s	O
DialogFlow	O
,	O
IBM	O
’s	O
Watson	O
,	O
or	O
Amazon	B-Method
Alexa	I-Method
.	O
	
In	O
this	O
paper	O
,	O
we	O
introduce	O
a	O
competing	O
solution	O
,	O
the	O
Snips	B-Method
Voice	I-Method
Platform	I-Method
which	O
,	O
unlike	O
the	O
previous	O
ones	O
,	O
is	O
completely	O
cloud	O
independent	O
and	O
runs	O
offline	O
on	O
typical	O
IoT	B-Method
microprocessors	I-Method
,	O
thus	O
guaranteeing	O
privacy	O
by	O
design	O
,	O
with	O
no	O
user	O
data	O
ever	O
collected	O
nor	O
stored	O
.	O
	
The	O
Natural	B-Method
Language	I-Method
Understanding	I-Method
component	O
of	O
the	O
platform	O
is	O
already	O
open	O
source	O
,	O
while	O
the	O
other	O
components	O
will	O
be	O
opensourced	O
in	O
the	O
future	O
.	O
	
The	O
aim	O
of	O
this	O
paper	O
is	O
to	O
contribute	O
to	O
the	O
collective	O
effort	O
towards	O
ever	O
more	O
private	O
and	O
efficient	O
cloud	O
-	O
independent	O
voice	O
interfaces	O
.	O
	
To	O
this	O
end	O
,	O
we	O
devote	O
this	O
introduction	O
to	O
a	O
brief	O
description	O
of	O
the	O
Snips	B-Method
Ecosystem	O
and	O
of	O
some	O
of	O
the	O
design	B-Method
principles	I-Method
behind	O
the	O
Snips	B-Method
Voice	I-Method
Platform	I-Method
.	O
	
subsection	O
:	O
The	O
Snips	B-Method
Ecosystem	O
	
The	O
Snips	B-Method
ecosystem	O
comprises	O
a	O
web	B-Method
console	I-Method
to	O
build	O
voice	B-Task
assistants	I-Task
and	O
train	O
the	O
corresponding	O
Spoken	O
Language	O
Understanding	O
(	O
SLU	B-Method
)	O
engine	O
,	O
made	O
of	O
an	O
Automatic	B-Task
Speech	I-Task
Recognition	I-Task
(	O
ASR	B-Method
)	O
engine	O
and	O
a	O
Natural	B-Method
Language	I-Method
Understanding	I-Method
(	O
NLU	B-Method
)	O
engine	O
.	O
	
The	O
console	B-Method
can	O
be	O
used	O
as	O
a	O
self	B-Task
-	I-Task
service	I-Task
development	I-Task
environment	I-Task
by	O
businesses	O
or	O
individuals	O
,	O
or	O
through	O
professional	O
services	O
.	O
	
The	O
Snips	B-Method
Voice	I-Method
Platform	I-Method
is	O
free	O
for	O
non	O
-	O
commercial	O
use	O
.	O
	
Since	O
its	O
launch	O
in	O
Summer	O
2017	O
,	O
over	O
23	O
,	O
000	O
Snips	B-Method
voice	O
assistants	O
have	O
been	O
created	O
by	O
over	O
13	O
,	O
000	O
developers	O
.	O
	
The	O
languages	O
currently	O
supported	O
by	O
the	O
Snips	B-Method
platform	O
are	O
English	O
,	O
French	O
and	O
German	O
,	O
with	O
additional	O
NLU	B-Method
support	O
for	O
Spanish	O
and	O
Korean	O
.	O
	
More	O
languages	O
are	O
added	O
regularly	O
.	O
	
An	O
assistant	B-Method
is	O
composed	O
of	O
a	O
set	O
of	O
skills	O
–	O
e.g.	O
SmartLights	B-Method
,	O
SmartThermostat	O
,	O
or	O
SmartOven	O
skills	O
for	O
a	O
SmartHome	B-Task
assistant	I-Task
–	O
that	O
may	O
be	O
either	O
selected	O
from	O
preexisting	O
ones	O
in	O
a	O
skill	O
store	O
or	O
created	O
from	O
scratch	O
on	O
the	O
web	O
console	O
.	O
	
A	O
given	O
skill	O
may	O
contain	O
several	O
intents	O
,	O
or	O
user	O
intention	O
–	O
	
e.g.	O
SwitchLightOn	O
and	O
SwitchLightOff	O
for	O
a	O
SmartLights	B-Method
skill	O
.	O
	
Finally	O
,	O
a	O
given	O
intent	O
is	O
bound	O
to	O
a	O
list	O
of	O
entities	O
that	O
must	O
be	O
extracted	O
from	O
the	O
user	O
’s	O
query	O
–	O
	
e.g.	O
room	O
for	O
the	O
SwitchLightOn	O
intent	O
.	O
	
We	O
call	O
slot	O
the	O
particular	O
value	O
of	O
an	O
entity	O
in	O
a	O
query	O
	
–	O
	
e.g.	O
kitchen	O
for	O
the	O
entity	O
room	O
.	O
	
When	O
a	O
user	O
speaks	O
to	O
the	O
assistant	O
,	O
the	O
SLU	B-Method
engine	O
trained	O
on	O
the	O
different	O
skills	O
will	O
handle	O
the	O
request	O
by	O
successively	O
converting	O
speech	O
into	O
text	O
,	O
classifying	O
the	O
user	O
’s	O
intent	O
,	O
and	O
extracting	O
the	O
relevant	O
slots	O
.	O
	
Once	O
the	O
user	O
’s	O
request	O
has	O
been	O
processed	O
and	O
based	O
on	O
the	O
information	O
that	O
has	O
been	O
extracted	O
from	O
the	O
query	O
and	O
fed	O
to	O
the	O
device	O
,	O
a	O
dialog	B-Method
management	I-Method
component	I-Method
is	O
responsible	O
for	O
providing	O
a	O
feedback	O
to	O
the	O
user	O
,	O
or	O
performing	O
an	O
action	O
.	O
	
It	O
may	O
take	O
multiple	O
forms	O
,	O
such	O
as	O
an	O
audio	O
response	O
via	O
speech	B-Method
synthesis	I-Method
or	O
a	O
direct	O
action	O
on	O
a	O
connected	O
device	O
–	O
e.g.	O
actually	O
turning	O
on	O
the	O
lights	O
for	O
a	O
SmartLights	B-Method
skill	O
.	O
	
Figure	O
[	O
reference	O
]	O
illustrates	O
the	O
typical	O
interaction	O
flow	O
.	O
	
subsection	O
:	O
A	O
private	O
-	O
by	O
-	O
design	B-Method
embedded	I-Method
platform	I-Method
	
The	O
Privacy	B-Method
by	I-Method
Design	I-Method
principle	I-Method
sets	O
privacy	O
as	O
the	O
default	O
standard	O
in	O
the	O
design	B-Task
and	I-Task
engineering	I-Task
of	I-Task
a	I-Task
system	I-Task
.	O
	
In	O
the	O
context	O
of	O
voice	B-Task
assistants	I-Task
,	O
that	O
can	O
be	O
deployed	O
anywhere	O
including	O
users	O
’	O
homes	O
,	O
this	O
principle	O
calls	O
for	O
a	O
strong	O
interpretation	O
to	O
protect	O
users	O
against	O
any	O
future	O
misuse	O
of	O
their	O
private	O
data	O
.	O
	
In	O
the	O
following	O
,	O
we	O
call	O
private	B-Method
-	I-Method
by	I-Method
-	I-Method
design	I-Method
a	O
system	O
that	O
does	O
not	O
transfer	O
user	O
data	O
to	O
any	O
remote	O
location	O
,	O
such	O
as	O
cloud	O
servers	O
.	O
	
Within	O
the	O
Snips	B-Method
ecosystem	O
,	O
the	O
SLU	B-Method
components	O
are	O
trained	O
on	O
servers	O
,	O
but	O
the	O
inference	B-Task
happens	O
directly	O
on	O
the	O
device	O
once	O
the	O
assistant	O
has	O
been	O
deployed	O
-	O
no	O
data	O
from	O
the	O
user	O
is	O
ever	O
collected	O
nor	O
stored	O
.	O
	
This	O
design	O
choice	O
adds	O
engineering	B-Metric
complexity	I-Metric
as	O
most	O
IoT	O
devices	O
run	O
on	O
specific	O
hardware	O
with	O
limited	O
memory	O
and	O
computing	O
power	O
.	O
	
Cross	B-Task
-	I-Task
platform	I-Task
support	I-Task
is	O
also	O
a	O
requirement	O
in	O
the	O
IoT	B-Task
industry	I-Task
,	O
since	O
IoT	O
devices	O
are	O
powered	O
by	O
many	O
different	O
hardware	O
boards	O
,	O
with	O
sustained	O
innovation	O
in	O
that	O
field	O
.	O
	
For	O
these	O
reasons	O
,	O
the	O
Snips	B-Method
Voice	I-Method
Platform	I-Method
has	O
been	O
built	O
with	O
portability	O
and	O
footprint	O
in	O
mind	O
.	O
	
Its	O
embedded	B-Method
inference	I-Method
runs	O
on	O
common	O
IoT	O
hardware	O
as	O
light	O
as	O
the	O
Raspberry	O
Pi	O
3	O
(	O
CPU	O
with	O
1.4	O
GHz	O
and	O
1	O
GB	O
of	O
RAM	O
)	O
,	O
a	O
popular	O
choice	O
among	O
developers	O
and	O
therefore	O
our	O
reference	O
hardware	O
setting	O
throughout	O
this	O
paper	O
.	O
	
Other	O
Linux	O
boards	O
are	O
also	O
supported	O
,	O
such	O
as	O
IMX.7D	B-Method
,	O
i	O
.	O
	
MX8	O
M	O
,	O
DragonBoard	O
410c	O
,	O
and	O
Jetson	B-Method
TX2	I-Method
.	O
	
The	O
Snips	B-Method
SDK	O
for	O
Android	O
works	O
with	O
devices	O
with	O
Android	O
5	O
and	O
ARM	O
CPU	O
,	O
while	O
the	O
iOS	B-Method
SDK	I-Method
targets	O
iOS	O
11	O
and	O
newer	O
.	O
	
For	O
efficiency	O
and	O
portability	O
reasons	O
,	O
the	O
algorithms	O
have	O
been	O
re	O
-	O
implemented	O
whenever	O
needed	O
in	O
Rust	B-Method
–	O
a	O
modern	O
programming	B-Method
language	I-Method
offering	O
high	O
performance	O
,	O
low	B-Metric
memory	I-Metric
overhead	I-Metric
,	O
and	O
cross	B-Method
-	I-Method
compilation	I-Method
.	O
	
SLU	B-Method
engines	O
are	O
usually	O
broken	O
down	O
into	O
two	O
parts	O
:	O
Automatic	B-Task
Speech	I-Task
Recognition	I-Task
(	O
ASR	B-Method
)	O
and	O
Natural	B-Method
Language	I-Method
Understanding	I-Method
(	O
NLU	B-Method
)	O
.	O
	
The	O
ASR	B-Method
engine	O
translates	O
a	O
spoken	O
utterance	O
into	O
text	O
through	O
an	O
acoustic	B-Method
model	I-Method
,	O
mapping	O
raw	O
audio	O
to	O
a	O
phonetic	B-Method
representation	I-Method
,	O
and	O
a	O
Language	B-Method
Model	I-Method
(	O
LM	B-Method
)	O
,	O
mapping	O
this	O
phonetic	B-Method
representation	I-Method
to	O
text	O
.	O
	
The	O
NLU	B-Method
then	O
extracts	O
intent	O
and	O
slots	O
from	O
the	O
decoded	O
query	O
.	O
	
As	O
discussed	O
in	O
section	O
[	O
reference	O
]	O
,	O
LM	B-Method
and	O
NLU	B-Method
have	O
to	O
be	O
mutually	O
consistent	O
in	O
order	O
to	O
optimize	O
the	O
accuracy	B-Metric
of	O
the	O
SLU	B-Method
engine	O
.	O
	
It	O
is	O
therefore	O
useful	O
to	O
introduce	O
a	O
language	B-Method
modeling	I-Method
component	I-Method
composed	O
of	O
the	O
LM	B-Method
and	O
NLU	B-Method
.	O
	
Figure	O
[	O
reference	O
]	O
describes	O
the	O
building	O
blocks	O
of	O
the	O
SLU	B-Method
pipeline	O
.	O
	
As	O
stated	O
above	O
,	O
ASR	B-Method
engines	O
relying	O
on	O
large	B-Method
deep	I-Method
learning	I-Method
models	I-Method
have	O
improved	O
drastically	O
over	O
the	O
past	O
few	O
years	O
.	O
	
Yet	O
,	O
they	O
still	O
have	O
a	O
major	O
drawback	O
today	O
.	O
	
For	O
example	O
,	O
the	O
model	O
achieving	O
human	B-Task
parity	I-Task
in	I-Task
is	O
a	O
combination	O
of	O
several	O
neural	B-Method
networks	I-Method
,	O
each	O
containing	O
several	O
hundreds	O
of	O
millions	O
of	O
parameters	O
,	O
and	O
large	B-Method
-	I-Method
vocabulary	I-Method
language	I-Method
models	I-Method
made	O
of	O
several	O
millions	O
of	O
n	O
-	O
grams	O
.	O
	
The	O
size	O
of	O
these	O
models	O
,	O
along	O
with	O
the	O
computational	O
resources	O
necessary	O
to	O
run	O
them	O
in	O
real	O
-	O
time	O
,	O
make	O
them	O
unfit	O
for	O
deployment	O
on	O
small	O
devices	O
,	O
so	O
that	O
solutions	O
implementing	O
them	O
are	O
bound	O
to	O
rely	O
on	O
the	O
cloud	B-Method
for	O
speech	B-Task
recognition	I-Task
.	O
	
Enforcing	B-Task
privacy	I-Task
by	O
design	O
therefore	O
implies	O
developing	O
new	O
tools	O
to	O
build	O
reliable	O
SLU	B-Method
engines	O
that	O
are	O
constrained	O
in	O
size	O
and	O
computational	O
requirements	O
,	O
which	O
we	O
detail	O
in	O
this	O
paper	O
.	O
	
In	O
section	O
[	O
reference	O
]	O
,	O
we	O
describe	O
strategies	O
to	O
obtain	O
small	O
(	O
10	O
MB	O
)	O
and	O
robust	O
acoustic	B-Method
models	I-Method
trained	O
on	O
general	O
speech	O
corpora	O
of	O
a	O
few	O
hundred	O
to	O
a	O
few	O
thousand	O
hours	O
.	O
	
Section	O
[	O
reference	O
]	O
is	O
devoted	O
to	O
a	O
description	O
of	O
the	O
language	B-Method
modeling	I-Method
approach	I-Method
of	O
the	O
Snips	B-Method
SLU	I-Method
engine	O
.	O
	
Notably	O
,	O
we	O
show	O
how	O
to	O
ensure	O
consistency	O
between	O
the	O
language	B-Method
model	I-Method
of	O
the	O
ASR	B-Method
engine	O
and	O
the	O
NLU	B-Method
engine	O
while	O
specializing	O
them	O
to	O
a	O
particular	O
use	O
case	O
.	O
	
The	O
resulting	O
SLU	B-Method
engine	O
is	O
lightweight	O
and	O
fast	O
to	O
execute	O
,	O
making	O
it	O
fit	O
for	O
deployment	O
on	O
small	B-Task
devices	I-Task
and	O
the	O
NLU	B-Method
component	O
is	O
open	O
source	O
.	O
	
In	O
section	O
[	O
reference	O
]	O
,	O
we	O
illustrate	O
the	O
high	O
generalization	B-Metric
accuracy	I-Metric
of	O
the	O
SLU	B-Method
engine	O
in	O
the	O
context	O
of	O
real	B-Task
-	I-Task
word	I-Task
voice	I-Task
assistants	I-Task
.	O
	
Finally	O
,	O
we	O
discuss	O
in	O
section	O
[	O
reference	O
]	O
a	O
data	B-Method
generation	I-Method
procedure	I-Method
to	O
automatically	O
create	O
training	O
sets	O
replacing	O
user	O
data	O
.	O
	
section	O
:	O
Acoustic	B-Method
model	I-Method
	
The	O
acoustic	B-Method
model	I-Method
is	O
the	O
first	O
step	O
of	O
the	O
SLU	B-Method
pipeline	O
,	O
and	O
is	O
therefore	O
crucial	O
to	O
its	O
functioning	O
.	O
	
If	O
the	O
decoding	O
contains	O
errors	O
,	O
it	O
might	O
compromise	O
the	O
subsequent	O
steps	O
and	O
trigger	O
a	O
different	O
action	O
than	O
that	O
intended	O
by	O
the	O
user	O
.	O
	
The	O
acoustic	B-Method
model	I-Method
is	O
responsible	O
for	O
converting	O
raw	O
audio	O
data	O
to	O
what	O
can	O
approximately	O
be	O
interpreted	O
as	O
phone	O
probabilities	O
,	O
i.e.	O
context	B-Method
-	I-Method
dependent	I-Method
clustered	I-Method
Hidden	I-Method
Markov	I-Method
Model	I-Method
(	O
HMM	B-Method
)	I-Method
state	I-Method
probabilities	I-Method
.	O
	
These	O
probabilities	O
are	O
then	O
fed	O
to	O
a	O
language	B-Method
model	I-Method
,	O
which	O
decodes	O
a	O
sequence	O
of	O
words	O
corresponding	O
to	O
the	O
user	O
utterance	O
.	O
	
The	O
acoustic	B-Method
and	I-Method
language	I-Method
models	I-Method
are	O
thus	O
closely	O
related	O
in	O
the	O
Automatic	B-Task
Speech	I-Task
Recognition	I-Task
(	O
ASR	B-Method
)	O
engine	O
,	O
but	O
are	O
often	O
designed	O
and	O
trained	O
separately	O
.	O
	
The	O
construction	O
of	O
the	O
language	B-Method
model	I-Method
used	O
in	O
the	O
SLU	B-Method
engine	O
is	O
detailed	O
in	O
section	O
[	O
reference	O
]	O
.	O
	
In	O
this	O
section	O
,	O
we	O
present	O
the	O
acoustic	B-Method
model	I-Method
.	O
	
First	O
,	O
we	O
give	O
details	O
about	O
how	O
the	O
training	O
data	O
is	O
collected	O
,	O
processed	O
,	O
cleaned	O
,	O
and	O
augmented	O
.	O
	
Then	O
,	O
we	O
present	O
the	O
acoustic	B-Method
model	I-Method
itself	O
(	O
a	O
hybrid	B-Method
of	I-Method
Neural	I-Method
Networks	I-Method
and	O
Hidden	B-Method
Markov	I-Method
Models	I-Method
,	O
or	O
NN	B-Method
/	I-Method
HMM	I-Method
)	O
and	O
how	O
it	O
is	O
trained	O
.	O
	
Finally	O
,	O
we	O
present	O
the	O
performance	O
of	O
the	O
acoustic	B-Method
model	I-Method
in	O
a	O
large	B-Task
-	I-Task
vocabulary	I-Task
setup	I-Task
,	O
in	O
terms	O
of	O
word	B-Metric
error	I-Metric
rate	I-Metric
(	O
WER	B-Metric
)	O
,	O
speed	B-Metric
,	O
and	O
memory	B-Metric
usage	I-Metric
.	O
	
subsection	O
:	O
Data	O
	
paragraph	O
:	O
Training	O
data	O
.	O
	
To	O
train	O
the	O
acoustic	B-Method
model	I-Method
,	O
we	O
need	O
several	O
hundreds	O
to	O
thousands	O
of	O
hours	O
of	O
audio	O
data	O
with	O
corresponding	O
transcripts	O
.	O
	
The	O
data	O
is	O
collected	O
from	O
public	O
or	O
commercial	O
sources	O
.	O
	
A	O
realignment	O
of	O
transcripts	O
to	O
the	O
audio	O
is	O
performed	O
to	O
match	O
transcripts	O
to	O
timestamps	O
.	O
	
This	O
additionally	O
helps	O
in	O
removing	O
transcription	B-Task
errors	I-Task
that	O
might	O
be	O
present	O
in	O
the	O
data	O
.	O
	
The	O
result	O
is	O
a	O
set	O
of	O
audio	O
extracts	O
and	O
matching	O
transcripts	O
,	O
with	O
lengths	O
suitable	O
for	O
acoustic	B-Task
training	I-Task
(	O
up	O
to	O
a	O
few	O
dozen	O
seconds	O
)	O
.	O
	
This	O
data	O
is	O
split	O
in	O
a	O
training	O
,	O
testing	O
,	O
and	O
development	O
sets	O
.	O
	
paragraph	O
:	O
Data	B-Task
augmentation	I-Task
.	O
	
One	O
of	O
the	O
main	O
issues	O
regarding	O
the	O
training	O
of	O
the	O
acoustic	B-Method
model	I-Method
is	O
the	O
lack	O
of	O
data	O
corresponding	O
to	O
real	O
usage	O
scenari	O
.	O
	
Most	O
of	O
the	O
available	O
training	O
data	O
is	O
clear	O
close	O
-	O
field	O
speech	O
,	O
but	O
voice	O
assistants	O
will	O
often	O
be	O
used	O
in	O
noisy	O
conditions	O
(	O
music	O
,	O
television	O
,	O
environment	O
noise	O
)	O
,	O
from	O
a	O
distance	O
of	O
several	O
meters	O
in	O
far	O
-	O
field	O
conditions	O
,	O
and	O
in	O
rooms	O
or	O
cars	O
with	O
reverberation	O
.	O
	
From	O
a	O
machine	B-Method
learning	I-Method
perspective	I-Method
,	O
data	O
corresponding	O
to	O
real	O
usage	O
of	O
the	O
system	O
–	O
-	O
or	O
in	O
-	O
domain	O
data	O
–	O
is	O
extremely	O
valuable	O
.	O
	
Since	O
spoken	O
utterances	O
from	O
the	O
user	O
are	O
not	O
collected	O
by	O
our	O
platform	O
for	O
privacy	O
reasons	O
,	O
noisy	O
and	O
reverberant	O
conditions	O
are	O
simulated	O
by	O
augmenting	O
the	O
data	O
.	O
	
Thousands	O
of	O
virtual	O
rooms	O
of	O
different	O
sizes	O
are	O
thus	O
generated	O
with	O
random	O
microphone	O
and	O
speaker	O
locations	O
,	O
and	O
the	O
rerecording	O
of	O
the	O
original	O
data	O
in	O
those	O
conditions	O
is	O
simulated	O
using	O
a	O
method	O
close	O
to	O
that	O
presented	O
in	O
.	O
	
subsection	O
:	O
Model	B-Method
training	I-Method
	
Acoustic	B-Method
models	I-Method
are	O
hybrid	B-Method
NN	I-Method
/	I-Method
HMM	I-Method
models	I-Method
.	O
	
More	O
specifically	O
,	O
they	O
are	O
a	O
custom	O
version	O
of	O
the	O
s5	B-Method
training	I-Method
recipe	I-Method
of	O
the	O
Kaldi	B-Method
toolkit	I-Method
.	O
	
40	O
MFCC	O
features	O
are	O
extracted	O
from	O
the	O
audio	O
signal	O
with	O
windows	O
of	O
size	O
25ms	O
every	O
10ms	O
.	O
	
Models	O
with	O
a	O
variable	O
number	O
of	O
layers	O
and	O
neurons	O
can	O
be	O
trained	O
,	O
which	O
will	O
impact	O
their	O
accuracy	B-Metric
and	O
computational	B-Metric
cost	I-Metric
.	O
	
We	O
can	O
thus	O
train	O
different	O
model	B-Method
architectures	I-Method
depending	O
on	O
the	O
target	O
hardware	O
and	O
the	O
desired	O
application	B-Metric
accuracy	I-Metric
.	O
	
In	O
the	O
following	O
evaluation	O
(	O
section	O
[	O
reference	O
]	O
)	O
,	O
we	O
present	O
performance	O
results	O
of	O
a	O
model	O
targeted	O
for	O
the	O
Raspberry	B-Task
Pi	I-Task
3	O
.	O
	
First	O
,	O
a	O
speaker	O
-	O
adaptive	O
Gaussian	B-Method
Mixture	I-Method
Model	I-Method
Hidden	I-Method
Markov	I-Method
Model	I-Method
(	O
GMM	B-Method
-	I-Method
HMM	I-Method
)	O
is	O
trained	O
on	O
the	O
speech	B-Material
corpus	I-Material
to	O
obtain	O
a	O
context	B-Method
-	I-Method
dependent	I-Method
bootstrapping	I-Method
model	I-Method
with	O
which	O
we	O
align	O
the	O
full	O
dataset	O
and	O
extract	O
lattices	O
to	O
prepare	O
the	O
neural	B-Method
network	I-Method
training	I-Method
.	O
	
We	O
train	O
a	O
deep	B-Method
neural	I-Method
network	I-Method
,	O
consisting	O
of	O
time	B-Method
-	I-Method
delay	I-Method
layers	I-Method
similar	O
to	O
those	O
presented	O
in	O
,	O
and	O
long	B-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
layers	I-Method
similar	O
to	O
those	O
of	O
.	O
	
The	O
architecture	O
,	O
close	O
to	O
that	O
of	O
,	O
is	O
summarized	O
in	O
Figure	O
[	O
reference	O
]	O
and	O
Table	O
[	O
reference	O
]	O
.	O
	
The	O
Raspberry	B-Method
Pi	I-Method
3	I-Method
model	I-Method
uses	O
7	O
layers	O
,	O
and	O
is	O
trained	O
with	O
the	O
lattice	B-Metric
-	I-Metric
free	I-Metric
Maximum	I-Metric
Mutual	I-Metric
Information	I-Metric
(	O
MMI	B-Metric
)	I-Metric
criterion	I-Metric
,	O
using	O
natural	B-Method
gradient	I-Method
descent	I-Method
,	O
with	O
a	O
learning	B-Metric
rate	I-Metric
of	O
0.0005	O
and	O
the	O
backstitching	B-Method
trick	I-Method
.	O
	
We	O
follow	O
the	O
approach	O
described	O
in	O
to	O
create	O
fast	B-Method
acoustic	I-Method
models	I-Method
,	O
namely	O
an	O
HMM	B-Method
topology	I-Method
with	O
one	O
state	O
for	O
each	O
of	O
the	O
1	O
,	O
700	O
context	O
-	O
dependent	O
senones	O
,	O
operating	O
at	O
a	O
third	O
of	O
the	O
original	O
frame	B-Metric
rate	I-Metric
.	O
	
subsection	O
:	O
Acoustic	B-Method
model	I-Method
evaluation	I-Method
	
In	O
this	O
section	O
,	O
we	O
present	O
an	O
evaluation	O
of	O
our	O
acoustic	B-Method
model	I-Method
for	O
English	O
.	O
	
Our	O
goal	O
is	O
the	O
design	O
of	O
an	O
end	O
-	O
to	O
-	O
end	O
SLU	B-Method
pipeline	O
which	O
runs	O
in	O
real	O
-	O
time	O
on	O
small	O
embedded	O
devices	O
,	O
but	O
has	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
accuracy	B-Metric
.	O
	
This	O
requires	O
tradeoffs	O
between	O
speed	O
and	O
the	O
generality	O
of	O
SLU	B-Method
task	O
.	O
	
More	O
precisely	O
,	O
we	O
use	O
domain	B-Method
-	I-Method
adapted	I-Method
language	I-Method
models	I-Method
described	O
in	O
section	O
[	O
reference	O
]	O
,	O
to	O
compensate	O
for	O
the	O
decrease	O
of	O
accuracy	B-Metric
of	O
smaller	O
acoustic	B-Method
models	I-Method
.	O
	
However	O
in	O
order	O
to	O
assess	O
the	O
quality	O
of	O
the	O
acoustic	B-Method
model	I-Method
in	O
a	O
more	O
general	O
setting	O
,	O
the	O
evaluation	O
of	O
this	O
section	O
is	O
carried	O
out	O
in	O
a	O
large	B-Task
vocabulary	I-Task
setup	I-Task
,	O
on	O
the	O
LibriSpeech	B-Material
evaluation	I-Material
dataset	I-Material
,	O
chosen	O
because	O
it	O
is	O
freely	O
available	O
and	O
widely	O
used	O
in	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
comparisons	O
.	O
	
The	O
language	B-Method
model	I-Method
for	O
the	O
large	B-Task
-	I-Task
vocabulary	I-Task
evaluation	I-Task
is	O
also	O
freely	O
available	O
online	O
.	O
	
It	O
is	O
a	O
pruned	O
trigram	O
LM	B-Method
with	O
a	O
vocabulary	O
of	O
200k	O
words	O
,	O
trained	O
on	O
the	O
content	O
of	O
public	O
domain	O
books	O
.	O
	
Two	O
sets	O
of	O
experiments	O
are	O
reported	O
.	O
	
In	O
the	O
first	O
set	O
,	O
the	O
models	O
are	O
trained	O
only	O
on	O
the	O
LibriSpeech	B-Material
training	I-Material
set	I-Material
(	O
or	O
on	O
a	O
subset	O
of	O
it	O
)	O
.	O
	
It	O
allows	O
us	O
to	O
validate	O
our	O
training	O
approach	O
and	O
keep	O
track	O
of	O
how	O
the	O
models	O
we	O
develop	O
compare	O
to	O
the	O
state	O
of	O
the	O
art	O
when	O
trained	O
on	O
public	O
data	O
.	O
	
Then	O
,	O
the	O
performance	O
of	O
the	O
model	O
in	O
terms	O
of	O
speed	B-Metric
and	I-Metric
memory	I-Metric
usage	I-Metric
is	O
studied	O
,	O
which	O
allows	O
us	O
to	O
select	O
a	O
good	O
tradeoff	O
for	O
the	O
targeted	O
Raspberry	B-Task
Pi	I-Task
3	I-Task
setting	I-Task
.	O
	
subsubsection	O
:	O
Model	B-Method
architecture	I-Method
trained	O
and	O
evaluated	O
on	O
LibriSpeech	B-Material
	
To	O
evaluate	O
the	O
impact	O
of	O
the	O
dataset	O
and	O
model	O
sizes	O
on	O
the	O
model	B-Metric
accuracy	I-Metric
,	O
neural	B-Method
networks	I-Method
of	O
different	O
sizes	O
are	O
trained	O
on	O
different	O
subsets	O
of	O
the	O
LibriSpeech	B-Material
dataset	I-Material
,	O
with	O
and	O
without	O
data	B-Method
augmentation	I-Method
.	O
	
The	O
results	O
obtained	O
with	O
nnet	B-Method
-	I-Method
512	I-Method
are	O
reported	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
The	O
Num	O
.	O
hours	O
column	O
corresponds	O
to	O
the	O
number	O
of	O
training	O
hours	O
(	O
460h	O
in	O
the	O
train	O
-	O
clean	O
split	O
of	O
the	O
LibriSpeech	B-Material
dataset	I-Material
and	O
500h	O
in	O
the	O
train	O
-	O
other	O
split	O
)	O
.	O
	
The	O
data	B-Task
augmentation	I-Task
was	O
only	O
applied	O
to	O
the	O
clean	B-Material
data	I-Material
.	O
	
For	O
example	O
460x2	O
means	O
460h	O
of	O
clean	B-Material
data	I-Material
+	O
460h	O
of	O
augmented	B-Material
data	I-Material
.	O
	
We	O
observe	O
that	O
adding	O
data	O
does	O
not	O
have	O
much	O
impact	O
on	O
LibriSpeech	B-Material
’s	I-Material
clean	I-Material
test	I-Material
sets	I-Material
(	O
dev	B-Material
-	I-Material
clean	I-Material
and	O
test	B-Material
-	I-Material
clean	I-Material
)	O
.	O
	
The	O
WER	B-Metric
however	O
decreases	O
when	O
adding	O
data	O
on	O
the	O
datasets	O
marked	O
as	O
other	O
(	O
dev	O
-	O
other	O
,	O
test	O
-	O
other	O
)	O
.	O
	
In	O
general	O
(	O
not	O
shown	O
in	O
those	O
tests	O
)	O
,	O
adding	O
more	O
data	O
and	O
using	O
data	B-Method
augmentation	I-Method
increases	O
significantly	O
the	O
performance	O
on	O
noisy	O
and	O
reverberant	O
conditions	O
.	O
	
In	O
the	O
next	O
experiment	O
,	O
the	O
neural	B-Method
networks	I-Method
are	O
trained	O
with	O
the	O
same	O
architecture	O
but	O
different	O
layer	O
sizes	O
on	O
the	O
460x6	O
+	O
500	O
hours	O
dataset	O
.	O
	
Results	O
are	O
reported	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
This	O
shows	O
that	O
larger	O
models	O
are	O
capable	O
of	O
fitting	O
the	O
data	O
and	O
generalizing	O
better	O
,	O
as	O
expected	O
.	O
	
This	O
allows	O
us	O
to	O
choose	O
the	O
best	O
tradeoff	O
between	O
precision	B-Metric
and	O
computational	B-Metric
cost	I-Metric
depending	O
on	O
each	O
target	O
hardware	O
and	O
assistant	O
needs	O
.	O
	
subsubsection	O
:	O
Online	B-Task
recognition	I-Task
performance	O
	
While	O
it	O
is	O
possible	O
to	O
get	O
closer	O
to	O
the	O
state	O
of	O
the	O
art	O
using	O
larger	O
neural	B-Method
network	I-Method
architectures	I-Method
,	O
their	O
associated	O
memory	B-Metric
and	I-Metric
computational	I-Metric
costs	I-Metric
would	O
prohibit	O
their	O
deployment	O
on	O
small	O
devices	O
.	O
	
In	O
section	O
[	O
reference	O
]	O
,	O
we	O
show	O
how	O
carefully	O
adapting	O
the	O
LM	B-Method
allows	O
to	O
reach	O
high	O
end	O
-	O
to	O
-	O
end	B-Metric
accuracies	I-Metric
using	O
the	O
acoustic	B-Method
models	I-Method
described	O
here	O
.	O
	
We	O
now	O
report	O
experiments	O
on	O
the	O
processing	B-Metric
speed	I-Metric
of	O
these	O
models	O
on	O
our	O
target	O
	
Raspberry	B-Method
Pi	I-Method
3	O
hardware	O
setting	O
.	O
	
We	O
trained	O
models	O
with	O
various	O
sizes	O
enjoying	O
a	O
faster	O
-	O
than	O
-	O
real	B-Metric
-	I-Metric
time	I-Metric
processing	I-Metric
factor	I-Metric
,	O
to	O
account	O
for	O
additional	O
processing	B-Metric
time	I-Metric
(	O
necessitated	O
e.g.	O
by	O
the	O
LM	B-Method
decoding	O
or	O
the	O
NLU	B-Method
engine	O
)	O
,	O
and	O
chose	O
a	O
model	O
with	O
a	O
good	O
compromise	O
of	O
accuracy	B-Metric
to	O
real	B-Metric
-	I-Metric
time	I-Metric
factor	I-Metric
and	O
model	B-Metric
size	I-Metric
(	O
on	O
disk	O
and	O
in	O
RAM	O
)	O
.	O
	
As	O
a	O
reference	O
,	O
in	O
terms	O
of	O
model	B-Metric
size	I-Metric
(	O
as	O
reported	O
in	O
Table	O
[	O
reference	O
]	O
)	O
nnet	B-Method
-	I-Method
256	I-Method
is	O
nearly	O
six	O
times	O
smaller	O
than	O
nnet	B-Method
-	I-Method
768	I-Method
,	O
with	O
2.6	O
M	O
parameters	O
vs	O
15.4	O
M	O
,	O
representing	O
10	O
MB	O
vs	O
59	O
MB	O
on	O
disk	O
.	O
	
The	O
gain	O
is	O
similar	O
in	O
RAM	O
.	O
	
In	O
terms	O
of	O
speed	B-Metric
,	O
the	O
nnet	B-Method
-	I-Method
256	I-Method
is	O
6	O
to	O
10	O
times	O
faster	O
than	O
the	O
nnet	B-Method
-	I-Method
768	I-Method
.	O
	
These	O
tradeoffs	O
and	O
comparison	O
with	O
other	O
trained	O
models	O
led	O
us	O
to	O
select	O
the	O
nnet	B-Method
-	I-Method
256	I-Method
.	O
	
It	O
has	O
a	O
reasonable	O
speed	B-Metric
and	I-Metric
memory	I-Metric
footprint	I-Metric
,	O
and	O
the	O
loss	O
in	O
accuracy	B-Metric
is	O
compensated	O
by	O
the	O
adapted	B-Method
LM	I-Method
and	O
robust	B-Method
NLU	I-Method
.	O
	
This	O
network	B-Method
architecture	I-Method
and	O
size	O
will	O
be	O
the	O
one	O
used	O
in	O
the	O
subsequent	O
experiments	O
.	O
	
The	O
different	O
architecture	O
variations	O
presented	O
in	O
this	O
section	O
were	O
chosen	O
for	O
the	O
sake	O
of	O
comparison	O
and	O
demonstration	O
.	O
	
This	O
experimental	O
comparison	O
,	O
along	O
with	O
optional	B-Method
layer	I-Method
factorization	I-Method
(	O
similar	O
to	O
)	O
or	O
weight	B-Method
quantization	I-Method
are	O
carried	O
out	O
for	O
each	O
target	O
hardware	O
setting	O
,	O
but	O
this	O
analysis	O
is	O
out	O
of	O
the	O
scope	O
of	O
this	O
paper	O
.	O
	
section	O
:	O
Language	B-Method
Modeling	I-Method
	
We	O
now	O
turn	O
to	O
the	O
description	O
of	O
the	O
language	B-Method
modeling	I-Method
component	I-Method
of	O
the	O
Snips	B-Method
platform	O
,	O
which	O
is	O
responsible	O
for	O
the	O
extraction	B-Task
of	I-Task
the	I-Task
intent	I-Task
and	I-Task
slots	I-Task
from	O
the	O
output	O
of	O
the	O
acoustic	B-Method
model	I-Method
.	O
	
This	O
component	O
is	O
made	O
up	O
of	O
two	O
closely	O
-	O
interacting	O
parts	O
.	O
	
The	O
first	O
is	O
the	O
language	B-Method
model	I-Method
(	O
LM	B-Method
)	O
,	O
that	O
turns	O
the	O
predictions	O
of	O
the	O
acoustic	B-Method
model	I-Method
into	O
likely	O
sentences	O
,	O
taking	O
into	O
account	O
the	O
probability	O
of	O
co	O
-	O
occurrence	O
of	O
words	O
.	O
	
The	O
second	O
is	O
the	O
Natural	B-Method
Language	I-Method
Understanding	I-Method
(	O
NLU	B-Method
)	O
model	O
,	O
that	O
extracts	O
intent	O
and	O
slots	O
from	O
the	O
prediction	O
of	O
the	O
Automatic	B-Task
Speech	I-Task
Recognition	I-Task
(	O
ASR	B-Method
)	O
engine	O
.	O
	
In	O
typical	O
commercial	O
large	O
vocabulary	O
speech	B-Task
recognition	I-Task
systems	O
,	O
the	O
LM	B-Method
component	O
is	O
usually	O
the	O
largest	O
in	O
size	O
,	O
and	O
can	O
take	O
up	O
to	O
terabytes	O
of	O
storage	O
.	O
	
Indeed	O
,	O
to	O
account	O
for	O
the	O
high	O
variability	O
of	O
general	O
spoken	O
language	O
,	O
large	B-Method
vocabulary	I-Method
language	I-Method
models	I-Method
need	O
to	O
be	O
trained	O
on	O
very	O
large	O
text	O
corpora	O
.	O
	
The	O
size	O
of	O
these	O
models	O
also	O
has	O
an	O
impact	O
on	O
decoding	B-Task
performance	O
:	O
the	O
search	O
space	O
of	O
the	O
ASR	B-Method
is	O
expanded	O
,	O
making	O
speech	B-Task
recognition	I-Task
harder	O
and	O
more	O
computationally	O
demanding	O
.	O
	
Additionally	O
,	O
the	O
performance	O
of	O
an	O
ASR	B-Method
engine	O
on	O
a	O
given	O
domain	O
will	O
strongly	O
depend	O
on	O
the	O
perplexity	O
of	O
its	O
LM	B-Method
on	O
queries	O
from	O
this	O
domain	O
,	O
making	O
the	O
choice	O
of	O
the	O
training	O
text	O
corpus	O
critical	O
.	O
	
This	O
question	O
is	O
sometimes	O
addressed	O
through	O
massive	O
use	O
of	O
users	O
’	O
private	O
data	O
.	O
	
One	O
option	O
to	O
overcome	O
these	O
challenges	O
is	O
to	O
specialize	O
the	O
language	B-Method
model	I-Method
of	O
the	O
assistant	O
to	O
a	O
certain	O
domain	O
,	O
e.g.	O
by	O
restricting	O
its	O
vocabulary	O
as	O
well	O
as	O
the	O
variety	O
of	O
the	O
queries	O
it	O
should	O
model	O
.	O
	
While	O
this	O
approach	O
appears	O
to	O
restrict	O
the	O
range	O
of	O
queries	O
that	O
can	O
be	O
made	O
to	O
an	O
assistant	O
,	O
we	O
argue	O
that	O
it	O
does	O
not	O
impair	O
the	O
usability	O
of	O
the	O
resulting	O
assistant	O
.	O
	
In	O
fact	O
,	O
while	O
the	O
performance	O
of	O
an	O
ASR	B-Method
engine	O
alone	O
can	O
be	O
measured	O
using	O
e.g.	O
the	O
word	B-Metric
error	I-Metric
rate	I-Metric
as	O
in	O
the	O
previous	O
section	O
,	O
we	O
assess	O
the	O
performance	O
of	O
the	O
SLU	B-Method
system	O
through	O
its	O
end	O
-	O
to	O
-	O
end	O
,	O
speech	B-Metric
-	I-Metric
to	I-Metric
-	I-Metric
meaning	I-Metric
accuracy	I-Metric
,	O
i.e.	O
its	O
ability	O
to	O
correctly	O
predict	O
the	O
intent	O
and	O
slots	O
of	O
a	O
spoken	O
utterance	O
.	O
	
As	O
a	O
consequence	O
,	O
it	O
is	O
sufficient	O
for	O
the	O
LM	B-Method
to	O
correctly	O
model	O
the	O
sentences	O
that	O
are	O
in	O
the	O
domain	O
that	O
the	O
NLU	B-Method
supports	O
.	O
	
The	O
size	O
of	O
the	O
model	O
is	O
thus	O
greatly	O
reduced	O
,	O
and	O
the	O
decoding	B-Metric
speed	I-Metric
increases	O
.	O
	
The	O
resulting	O
ASR	B-Method
is	O
particularly	O
robust	O
within	O
the	O
use	O
case	O
,	O
with	O
an	O
accuracy	B-Metric
unreachable	O
under	O
our	O
hardware	O
constraints	O
for	O
an	O
all	O
-	O
purpose	O
,	O
general	O
ASR	B-Method
model	O
.	O
	
In	O
the	O
following	O
,	O
we	O
detail	O
the	O
implementation	O
of	O
this	O
design	O
principle	O
,	O
allowing	O
the	O
Snips	B-Method
SLU	I-Method
component	O
to	O
run	O
efficiently	O
on	O
small	O
devices	O
with	O
high	O
accuracy	B-Metric
,	O
and	O
illustrate	O
its	O
performance	O
on	O
two	O
real	O
-	O
world	O
assistants	O
.	O
	
subsection	O
:	O
Data	O
	
In	O
application	O
of	O
the	O
principles	O
outlined	O
above	O
,	O
we	O
use	O
the	O
same	O
data	O
to	O
train	O
both	O
LM	B-Method
and	O
NLU	B-Method
.	O
	
The	O
next	O
section	O
is	O
devoted	O
to	O
a	O
description	O
of	O
this	O
dataset	O
.	O
	
The	O
generation	O
of	O
this	O
dataset	O
is	O
discussed	O
in	O
section	O
[	O
reference	O
]	O
.	O
	
subsubsection	O
:	O
Training	O
dataset	O
	
The	O
dataset	O
used	O
to	O
train	O
both	O
the	O
LM	B-Method
and	O
NLU	B-Method
contains	O
written	O
queries	O
exemplifying	O
intents	O
that	O
depend	O
on	O
entities	O
.	O
	
Entities	O
are	O
bound	O
to	O
an	O
intent	O
and	O
used	O
to	O
describe	O
all	O
the	O
possible	O
values	O
for	O
a	O
given	O
attribute	O
.	O
	
For	O
example	O
,	O
in	O
the	O
case	O
of	O
a	O
SmartLights	B-Method
assistant	O
handling	O
connected	O
lights	O
,	O
these	O
entities	O
are	O
room	O
,	O
brightness	O
and	O
color	O
.	O
	
They	O
are	O
required	O
by	O
the	O
assistant	O
logic	O
to	O
execute	O
the	O
right	O
action	O
.	O
	
Another	O
example	O
dealing	O
with	O
weather	B-Task
-	I-Task
related	I-Task
queries	I-Task
is	O
described	O
in	O
section	O
[	O
reference	O
]	O
.	O
	
An	O
intent	O
often	O
has	O
several	O
entities	O
that	O
it	O
can	O
share	O
with	O
other	O
intents	O
.	O
	
For	O
instance	O
,	O
the	O
room	O
entity	O
is	O
used	O
by	O
several	O
intents	O
(	O
SwitchLightOn	O
and	O
SwitchLightOff	O
)	O
,	O
since	O
the	O
user	O
might	O
want	O
to	O
specify	O
the	O
room	O
for	O
both	O
switching	O
on	O
and	O
switching	O
off	O
the	O
lights	O
.	O
	
Entities	O
can	O
be	O
of	O
two	O
types	O
,	O
either	O
custom	O
or	O
built	O
-	O
in	O
.	O
	
Custom	O
entities	O
are	O
user	O
-	O
defined	O
entities	O
that	O
can	O
be	O
exhaustively	O
specified	O
by	O
a	O
list	O
of	O
values	O
(	O
e.g.	O
room	O
:	O
kitchen	O
,	O
bedroom	O
,	O
etc	O
.	O
and	O
color	O
:	O
blue	O
,	O
red	O
,	O
etc	O
.	O
)	O
.	O
	
Built	O
-	O
in	O
entities	O
are	O
common	O
entities	O
that	O
can	O
not	O
be	O
easily	O
listed	O
exhaustively	O
by	O
a	O
user	O
,	O
and	O
are	O
therefore	O
provided	O
by	O
the	O
platform	O
(	O
numbers	O
,	O
ordinals	O
,	O
amounts	O
with	O
unit	O
,	O
date	O
and	O
times	O
,	O
durations	O
,	O
etc	O
.	O
)	O
.	O
	
In	O
our	O
SmartLights	B-Method
example	O
,	O
the	O
entity	O
brightness	O
can	O
be	O
any	O
number	O
between	O
0	O
and	O
100	O
,	O
so	O
that	O
the	O
built	O
-	O
in	O
entity	O
type	O
snips	O
/	O
number	O
can	O
be	O
used	O
.	O
	
A	O
query	O
is	O
the	O
written	O
expression	O
of	O
an	O
intent	O
.	O
	
For	O
instance	O
,	O
the	O
query	O
‘	O
	
‘	O
set	O
the	O
kitchen	O
lights	O
intensity	O
to	O
65	O
’’	O
is	O
associated	O
with	O
the	O
intent	O
SetLightBrightness	O
.	O
	
Slot	B-Task
labeling	I-Task
is	O
done	O
by	O
specifying	O
chunks	O
of	O
the	O
query	O
that	O
should	O
be	O
bound	O
to	O
a	O
given	O
entity	O
.	O
	
Using	O
the	O
same	O
examples	O
,	O
the	O
slots	O
associated	O
with	O
the	O
room	O
and	O
brightness	O
entities	O
in	O
the	O
query	O
can	O
be	O
specified	O
as	O
follows	O
:	O
	
‘	O
	
‘	O
set	O
the	O
(	O
kitchen	O
)[	O
room	O
]	O
lights	O
intensity	O
to	O
(	O
65	O
)[	O
brightness	O
]	O
	
’’	O
.	O
	
The	O
number	O
of	O
queries	O
per	O
intent	O
ranges	O
from	O
a	O
few	O
ones	O
to	O
several	O
thousands	O
depending	O
on	O
the	O
variability	O
needed	O
to	O
cover	O
most	O
common	O
wordings	O
.	O
	
subsubsection	O
:	O
Normalization	B-Method
	
One	O
key	O
challenge	O
related	O
to	O
end	O
-	O
to	O
-	O
end	O
SLU	B-Method
is	O
data	B-Task
consistency	I-Task
between	O
training	B-Task
and	O
inference	B-Task
.	O
	
The	O
dataset	O
described	O
above	O
is	O
collected	O
via	O
the	O
console	O
where	O
no	O
specific	O
writing	B-Method
system	I-Method
,	O
nor	O
cleaning	O
rules	O
regarding	O
non	O
-	O
alphanumeric	O
characters	O
are	O
enforced	O
.	O
	
Before	O
training	O
the	O
LM	B-Method
,	O
this	O
dataset	O
therefore	O
needs	O
to	O
be	O
verbalized	O
:	O
entity	O
values	O
and	O
user	O
queries	O
are	O
tokenized	O
,	O
normalized	O
to	O
a	O
canonical	O
form	O
,	O
and	O
verbalized	O
to	O
match	O
entries	O
from	O
a	O
lexicon	O
.	O
	
For	O
instance	O
,	O
numbers	O
and	O
dates	O
are	O
spelled	O
out	O
,	O
so	O
that	O
their	O
pronunciation	O
can	O
be	O
generated	O
from	O
their	O
written	O
form	O
.	O
	
Importantly	O
,	O
we	O
apply	O
the	O
same	O
preprocessing	O
before	O
training	O
the	O
NLU	B-Method
.	O
	
This	O
step	O
ensures	O
consistency	O
when	O
it	O
comes	O
to	O
inference	B-Task
.	O
	
More	O
precisely	O
,	O
it	O
guarantees	O
that	O
the	O
words	O
output	O
by	O
the	O
ASR	B-Method
match	O
those	O
seen	O
by	O
the	O
NLU	B-Method
during	O
training	O
.	O
	
The	O
normalization	B-Method
pipeline	I-Method
is	O
used	O
to	O
handle	O
languages	O
specificities	O
,	O
through	O
the	O
use	O
of	O
a	O
class	B-Method
-	I-Method
based	I-Method
tokenizer	I-Method
that	O
allows	O
support	O
for	O
case	B-Task
-	I-Task
by	I-Task
-	I-Task
case	I-Task
verbalization	I-Task
for	O
each	O
token	O
class	O
.	O
	
For	O
instance	O
,	O
numeric	O
values	O
are	O
transliterated	O
to	O
words	O
,	O
punctuation	O
tokens	O
skipped	O
,	O
while	O
quantities	O
with	O
units	O
such	O
as	O
amounts	O
of	O
money	O
require	O
a	O
more	O
advanced	O
verbalization	O
(	O
in	O
English	O
,	O
	
‘	O
‘	O
$	O
25	O
’’	O
should	O
be	O
verbalized	O
as	O
‘	O
‘	O
twenty	O
five	O
dollars	O
’	O
’	O
)	O
.	O
	
The	O
tokenizer	B-Method
is	O
implemented	O
as	O
a	O
character	B-Method
-	I-Method
level	I-Method
finite	I-Method
state	I-Method
transducer	I-Method
,	O
and	O
is	O
designed	O
to	O
be	O
easily	O
extensible	O
to	O
accommodate	O
new	O
token	O
types	O
as	O
more	O
languages	O
are	O
supported	O
.	O
	
subsection	O
:	O
Language	B-Method
model	I-Method
	
The	O
mapping	O
from	O
the	O
output	O
of	O
the	O
acoustic	B-Method
model	I-Method
to	O
likely	O
word	O
sequences	O
is	O
done	O
via	O
a	O
Viterbi	B-Method
search	I-Method
in	O
a	O
weighted	B-Method
Finite	I-Method
State	I-Method
Transducer	I-Method
(	O
wFST	B-Method
)	O
,	O
called	O
ASR	B-Method
decoding	O
graph	O
in	O
the	O
following	O
.	O
	
Formally	O
,	O
the	O
decoding	O
graph	O
may	O
be	O
written	O
as	O
the	O
composition	O
of	O
four	O
wFSTs	B-Method
,	O
where	O
denotes	O
transducer	B-Method
composition	I-Method
(	O
see	O
section	O
[	O
reference	O
]	O
)	O
,	O
represents	O
Hidden	B-Method
Markov	I-Method
Models	I-Method
(	O
HMMs	B-Method
)	O
modeling	O
context	O
-	O
dependent	O
phones	O
,	O
represents	O
the	O
context	O
-	O
dependency	O
,	O
is	O
the	O
lexicon	O
and	O
is	O
the	O
LM	B-Method
,	O
typically	O
a	O
bigram	B-Method
or	O
a	O
trigram	B-Method
model	I-Method
represented	O
as	O
a	O
wFST	B-Method
.	O
	
Determinization	B-Method
and	I-Method
minimization	I-Method
operations	I-Method
are	O
also	O
applied	O
at	O
each	O
step	O
in	O
order	O
to	O
compute	O
equivalent	O
optimized	O
transducers	O
with	O
less	O
states	O
,	O
allowing	O
the	O
composition	O
and	O
the	O
inference	B-Task
to	O
run	O
faster	O
.	O
	
More	O
detailed	O
definitions	O
of	O
the	O
previous	O
classical	B-Method
transducers	I-Method
are	O
beyond	O
the	O
scope	O
of	O
this	O
paper	O
,	O
and	O
we	O
refer	O
the	O
interested	O
reader	O
to	O
and	O
references	O
therein	O
.	O
	
In	O
the	O
following	O
,	O
we	O
focus	O
on	O
the	O
construction	O
of	O
the	O
G	B-Method
transducer	I-Method
,	O
encoding	O
the	O
LM	B-Method
,	O
from	O
the	O
domain	O
-	O
specific	O
dataset	O
presented	O
above	O
.	O
	
subsubsection	O
:	O
Language	B-Method
Model	I-Method
Adaptation	I-Method
	
As	O
explained	O
earlier	O
,	O
the	O
ASR	B-Method
engine	O
is	O
required	O
to	O
understand	O
arbitrary	O
formulations	O
of	O
a	O
finite	O
set	O
of	O
intents	O
described	O
in	O
the	O
dataset	O
.	O
	
In	O
particular	O
,	O
it	O
should	O
be	O
able	O
to	O
generalize	O
to	O
unseen	O
queries	O
within	O
the	O
same	O
domain	O
,	O
and	O
allow	O
entity	O
values	O
to	O
be	O
interchangeable	O
.	O
	
The	O
generalization	B-Metric
properties	I-Metric
of	O
the	O
ASR	B-Method
engine	O
are	O
preserved	O
by	O
using	O
a	O
statistical	O
n	O
-	O
gram	O
LM	B-Method
allowing	O
to	O
mix	O
parts	O
of	O
the	O
training	O
queries	O
to	O
create	O
new	O
ones	O
,	O
and	O
by	O
using	O
class	B-Method
-	I-Method
based	I-Method
language	I-Method
modeling	I-Method
where	O
the	O
value	O
of	O
each	O
entity	O
may	O
be	O
replaced	O
by	O
any	O
other	O
.	O
	
We	O
now	O
detail	O
the	O
resulting	O
LM	B-Method
construction	O
strategy	O
.	O
	
The	O
first	O
step	O
in	O
building	O
the	O
LM	B-Method
is	O
the	O
creation	O
of	O
patterns	O
abstracting	O
the	O
type	O
of	O
queries	O
the	O
user	O
may	O
make	O
to	O
the	O
assistant	O
.	O
	
Starting	O
from	O
the	O
dataset	O
described	O
above	O
,	O
we	O
replace	O
all	O
occurrences	O
of	O
each	O
entity	O
by	O
a	O
symbol	O
for	O
the	O
entity	O
.	O
	
For	O
example	O
,	O
the	O
query	O
	
‘	O
	
‘	O
	
Play	O
some	O
music	O
by	O
(	O
The	O
Rolling	O
Stones	O
)[	O
artist	O
]	O
’’	O
	
is	O
abstracted	O
to	O
‘	O
	
‘	O
	
Play	O
some	O
music	O
by	O
ARTIST	O
’’	O
.	O
	
An	O
n	B-Method
-	I-Method
gram	I-Method
model	I-Method
is	O
then	O
trained	O
on	O
the	O
resulting	O
set	O
of	O
patterns	O
,	O
which	O
is	O
then	O
converted	O
to	O
a	O
wFST	O
called	O
.	O
	
Next	O
,	O
for	O
each	O
entity	O
where	O
and	O
is	O
the	O
number	O
of	O
entities	O
,	O
an	O
acceptor	O
is	O
defined	O
to	O
encode	O
the	O
values	O
the	O
entity	O
can	O
take	O
.	O
	
The	O
construction	O
of	O
depends	O
on	O
the	O
type	O
of	O
the	O
entity	O
.	O
	
For	O
custom	O
entities	O
,	O
whose	O
values	O
are	O
listed	O
exhaustively	O
in	O
the	O
dataset	O
,	O
can	O
be	O
defined	O
either	O
as	O
a	O
union	O
of	O
acceptors	O
of	O
the	O
different	O
values	O
of	O
the	O
entity	O
,	O
or	O
as	O
an	O
n	B-Method
-	I-Method
gram	I-Method
model	I-Method
trained	O
specifically	O
on	O
the	O
values	O
of	O
the	O
entity	O
.	O
	
For	O
built	O
-	O
in	O
entities	O
such	O
as	O
numbers	O
or	O
dates	O
and	O
times	O
,	O
is	O
a	O
wFST	B-Method
representation	I-Method
of	O
a	O
generative	B-Method
grammar	I-Method
describing	O
the	O
construction	O
of	O
any	O
instance	O
of	O
the	O
entity	O
.	O
	
The	O
LM	B-Method
transducer	O
is	O
then	O
defined	O
as	O
where	O
Replace	B-Method
denotes	O
wFST	B-Method
replacement	I-Method
.	O
	
For	O
instance	O
,	O
in	O
the	O
example	O
above	O
,	O
the	O
arcs	O
of	O
carrying	O
the	O
‘	O
	
‘	O
ARTIST	O
’’	O
symbol	O
are	O
expanded	O
into	O
the	O
wFST	B-Method
representing	O
the	O
‘	O
‘	O
artist	O
’’	O
entity	O
.	O
	
This	O
process	O
is	O
represented	O
on	O
a	O
simple	O
LM	B-Method
on	O
Figure	O
[	O
reference	O
]	O
.	O
	
The	O
resulting	O
allows	O
the	O
ASR	B-Method
to	O
generalize	O
to	O
unseen	O
queries	O
and	O
to	O
swap	O
entity	O
values	O
.	O
	
Continuing	O
with	O
the	O
simple	O
example	O
introduced	O
above	O
,	O
the	O
query	O
	
‘	O
	
‘	O
	
Play	O
me	O
some	O
music	O
by	O
The	O
Beatles	O
	
’’	O
has	O
the	O
same	O
weight	O
as	O
‘	O
	
‘	O
	
Play	O
me	O
some	O
music	O
by	O
The	O
Rolling	O
Stones	O
’’	O
in	O
the	O
LM	B-Method
,	O
while	O
the	O
sentence	O
‘	O
	
‘	O
	
Play	O
music	O
by	O
The	O
Rolling	O
Stones	O
’’	O
also	O
has	O
a	O
finite	O
weight	O
thanks	O
to	O
the	O
n	B-Method
-	I-Method
gram	I-Method
back	I-Method
-	I-Method
off	I-Method
mechanism	I-Method
.	O
	
The	O
lexicon	B-Method
transducer	I-Method
encodes	O
the	O
pronunciations	O
of	O
all	O
the	O
words	O
in	O
both	O
and	O
.	O
	
The	O
pronunciations	O
are	O
obtained	O
from	O
large	O
base	O
dictionaries	O
,	O
with	O
a	O
fall	O
-	O
back	O
to	O
a	O
statistical	O
grapheme	B-Method
-	I-Method
to	I-Method
-	I-Method
phoneme	I-Method
(	O
G2P	B-Method
)	O
system	O
to	O
generate	O
the	O
missing	O
pronunciations	O
.	O
	
subsubsection	O
:	O
Dynamic	B-Method
Language	I-Method
Model	I-Method
	
The	O
standard	O
way	O
to	O
compute	O
the	O
decoding	O
graph	O
is	O
to	O
perform	O
compositions	O
from	O
right	O
to	O
left	O
with	O
the	O
following	O
formula	O
where	O
each	O
composition	O
is	O
followed	O
by	O
a	O
determinization	O
and	O
a	O
minimization	B-Method
.	O
	
The	O
order	O
in	O
which	O
the	O
compositions	O
are	O
done	O
is	O
important	O
,	O
as	O
the	O
composition	O
is	O
known	O
to	O
be	O
intractable	O
when	O
is	O
not	O
deterministic	O
,	O
as	O
is	O
the	O
case	O
when	O
G	O
is	O
a	O
wFST	B-Method
representing	O
an	O
n	B-Method
-	I-Method
gram	I-Method
model	I-Method
.	O
	
We	O
will	O
refer	O
to	O
the	O
result	O
of	O
equation	O
[	O
reference	O
]	O
as	O
a	O
static	B-Method
model	I-Method
in	O
the	O
following	O
.	O
	
In	O
the	O
context	O
of	O
embedded	B-Task
inference	I-Task
,	O
a	O
major	O
drawback	O
of	O
this	O
standard	O
method	O
is	O
the	O
necessity	O
to	O
compute	O
and	O
load	O
the	O
static	O
HCLG	O
decoding	O
graph	O
in	O
memory	O
in	O
order	O
to	O
perform	O
speech	B-Task
recognition	I-Task
.	O
	
The	O
size	O
of	O
this	O
decoding	B-Method
graph	I-Method
can	O
claim	O
a	O
large	O
chunk	O
of	O
the	O
GB	O
of	O
RAM	O
available	O
on	O
a	O
Raspberry	O
Pi	O
3	O
,	O
or	O
even	O
be	O
too	O
big	O
for	O
smaller	O
devices	O
.	O
	
Additionally	O
,	O
since	O
LMs	B-Method
are	O
trained	O
synchronously	O
in	O
the	O
Snips	B-Method
web	O
console	O
after	O
the	O
user	O
has	O
created	O
their	O
dataset	O
(	O
see	O
section	O
[	O
reference	O
]	O
)	O
,	O
it	O
is	O
important	O
for	O
the	O
decoding	O
graph	O
to	O
be	O
generated	O
as	O
fast	O
as	O
possible	O
.	O
	
For	O
these	O
reasons	O
,	O
a	O
dynamic	B-Method
language	I-Method
model	I-Method
,	O
composing	O
the	O
various	O
transducers	O
upon	O
request	O
instead	O
of	O
ahead	O
of	O
time	O
,	O
is	O
employed	O
.	O
	
This	O
is	O
achieved	O
by	O
replacing	O
the	O
compositions	B-Method
of	I-Method
equation	I-Method
(	O
[	O
reference	O
]	O
)	O
by	O
delayed	O
(	O
or	O
lazy	O
)	O
ones	O
.	O
	
Consequently	O
,	O
the	O
states	O
and	O
transitions	O
of	O
the	O
complete	O
HCLG	B-Method
decoding	I-Method
graph	I-Method
are	O
not	O
computed	O
at	O
the	O
time	O
of	O
creation	O
,	O
but	O
rather	O
at	O
runtime	O
during	O
the	O
inference	B-Task
,	O
notably	O
speeding	O
up	O
the	O
building	O
of	O
the	O
decoding	B-Method
graph	I-Method
.	O
	
Additionally	O
,	O
employing	O
lazy	B-Method
composition	I-Method
allows	O
to	O
break	O
the	O
decoding	O
graph	O
into	O
two	O
pieces	O
(	O
HCL	O
on	O
one	O
hand	O
,	O
and	O
G	O
on	O
the	O
other	O
)	O
.	O
	
The	O
sum	O
of	O
the	O
sizes	O
of	O
these	O
pieces	O
is	O
typically	O
several	O
times	O
smaller	O
than	O
the	O
equivalent	O
,	O
statically	O
-	O
composed	O
HCLG	B-Method
.	O
	
In	O
order	O
to	O
preserve	O
the	O
decoding	B-Metric
speed	I-Metric
of	O
the	O
ASR	B-Method
engine	O
using	O
a	O
dynamic	B-Method
language	I-Method
model	I-Method
,	O
a	O
better	O
composition	B-Method
algorithm	I-Method
using	O
lazy	O
look	O
-	O
ahead	O
operations	O
must	O
be	O
used	O
.	O
	
Indeed	O
,	O
a	O
naive	O
lazy	B-Method
composition	I-Method
typically	O
creates	O
many	O
non	O
co	O
-	O
accessible	O
states	O
in	O
the	O
resulting	O
wFST	B-Method
,	O
wasting	O
both	O
time	O
and	O
memory	O
.	O
	
In	O
the	O
case	O
of	O
a	O
static	O
decoding	O
graph	O
,	O
these	O
states	O
are	O
removed	O
through	O
a	O
final	O
optimization	B-Method
step	I-Method
of	O
the	O
HCLG	B-Method
that	O
can	O
not	O
be	O
applied	O
in	O
the	O
dynamic	B-Task
case	I-Task
because	O
the	O
full	O
HCLG	B-Method
is	O
never	O
built	O
.	O
	
This	O
issue	O
can	O
be	O
addressed	O
through	O
the	O
use	O
of	O
composition	B-Method
filters	I-Method
.	O
	
In	O
particular	O
,	O
the	O
use	O
of	O
look	B-Method
-	I-Method
ahead	I-Method
filters	I-Method
followed	O
by	O
label	B-Method
-	I-Method
reachability	I-Method
filters	I-Method
with	O
weights	O
and	O
labels	O
pushing	O
allows	O
to	O
discard	O
inaccessible	O
and	O
costly	O
decoding	O
hypotheses	O
early	O
in	O
the	O
decoding	B-Task
.	O
	
The	O
lexicon	O
can	O
therefore	O
be	O
composed	O
with	O
the	O
language	B-Method
model	I-Method
while	O
simultaneously	O
optimizing	O
the	O
resulting	O
transducer	B-Method
.	O
	
Finally	O
,	O
the	O
Replace	B-Method
operation	I-Method
of	O
equation	O
(	O
[	O
reference	O
]	O
)	O
is	O
also	O
delayed	O
.	O
	
This	O
allows	O
to	O
further	O
break	O
the	O
decoding	O
graph	O
into	O
smaller	O
distinct	O
pieces	O
:	O
the	O
transducer	B-Method
mapping	I-Method
the	O
output	O
of	O
the	O
acoustic	B-Method
model	I-Method
to	O
words	O
,	O
the	O
query	B-Method
language	I-Method
model	I-Method
,	O
and	O
the	O
entities	B-Method
languages	I-Method
models	I-Method
.	O
	
Formally	O
,	O
at	O
runtime	O
,	O
the	O
dynamic	O
decoding	O
graph	O
is	O
created	O
using	O
the	O
following	O
formula	O
where	O
the	O
HCL	B-Method
transducer	I-Method
is	O
computed	O
beforehand	O
using	O
regular	B-Method
transducer	I-Method
compositions	I-Method
(	O
i.e.	O
)	O
and	O
denotes	O
the	O
delayed	B-Method
transducer	I-Method
composition	I-Method
with	O
composition	B-Method
filters	I-Method
.	O
	
These	O
improvements	O
yield	O
real	B-Task
time	I-Task
decoding	I-Task
on	O
a	O
Raspberry	O
Pi	O
3	O
with	O
a	O
small	O
overhead	O
compared	O
to	O
a	O
static	B-Method
model	I-Method
,	O
and	O
preserve	O
decoding	B-Metric
accuracy	I-Metric
while	O
reducing	O
drastically	O
the	O
size	O
of	O
the	O
model	O
on	O
disk	O
.	O
	
Additionally	O
,	O
this	O
greatly	O
reduces	O
the	O
training	B-Metric
time	I-Metric
of	O
the	O
LM	B-Method
.	O
	
Finally	O
,	O
breaking	O
down	O
the	O
LM	B-Method
into	O
smaller	O
,	O
separate	O
parts	O
makes	O
it	O
possible	O
to	O
efficiently	O
update	O
it	O
.	O
	
It	O
particular	O
,	O
performing	O
on	B-Task
-	I-Task
device	I-Task
injection	I-Task
of	I-Task
new	I-Task
values	I-Task
in	O
the	O
LM	B-Method
becomes	O
straightforward	O
,	O
enabling	O
users	O
to	O
locally	O
customize	O
their	O
SLU	B-Method
engine	O
without	O
going	O
through	O
the	O
Snips	B-Method
web	O
console	O
.	O
	
This	O
feature	O
is	O
described	O
in	O
the	O
following	O
.	O
	
subsubsection	O
:	O
On	B-Task
-	I-Task
device	I-Task
personalization	I-Task
	
Using	O
contextual	O
information	O
in	O
ASR	B-Method
is	O
a	O
promising	O
approach	O
to	O
improving	O
the	O
recognition	B-Task
results	O
by	O
biasing	O
the	O
language	B-Method
model	I-Method
towards	O
a	O
user	O
-	O
specific	O
vocabulary	O
.	O
	
A	O
straightforward	O
way	O
of	O
customizing	O
the	O
LM	B-Method
previously	O
described	O
is	O
to	O
update	O
the	O
list	O
of	O
values	O
each	O
entity	O
can	O
take	O
.	O
	
For	O
instance	O
,	O
if	O
we	O
consider	O
an	O
assistant	O
dedicated	O
to	O
making	O
phone	O
calls	O
(	O
‘	O
‘	O
call	O
(	O
Jane	O
Doe	O
)[	O
contact	O
]	O
’	O
’	O
)	O
,	O
the	O
user	O
’s	O
list	O
of	O
contacts	O
could	O
be	O
added	O
to	O
the	O
values	O
of	O
the	O
entity	O
	
‘	O
	
‘	O
contact	O
’’	O
in	O
an	O
embedded	O
way	O
,	O
without	O
this	O
sensitive	O
data	O
ever	O
leaving	O
the	O
device	O
.	O
	
This	O
operation	O
is	O
called	O
entity	B-Task
injection	I-Task
in	O
the	O
following	O
.	O
	
In	O
order	O
to	O
perform	O
entity	B-Task
injection	I-Task
,	O
two	O
modifications	O
of	O
the	O
decoding	O
graph	O
are	O
necessary	O
.	O
	
First	O
,	O
the	O
new	O
words	O
and	O
their	O
pronunciations	O
are	O
added	O
to	O
the	O
transducer	B-Method
.	O
	
Second	O
,	O
the	O
new	O
values	O
are	O
added	O
to	O
the	O
corresponding	O
entity	O
wFST	O
.	O
	
The	O
pronunciations	O
of	O
the	O
words	O
already	O
supported	O
by	O
the	O
ASR	B-Method
are	O
cached	O
to	O
avoid	O
recomputing	O
them	O
on	O
-	O
device	O
.	O
	
Pronunciations	O
for	O
words	O
absent	O
from	O
the	O
transducer	B-Method
are	O
computed	O
via	O
an	O
embedded	B-Method
G2P.	I-Method
	
The	O
updated	O
transducer	O
can	O
then	O
be	O
fully	O
recompiled	O
and	O
optimized	O
.	O
	
The	O
procedure	O
for	O
adding	O
a	O
new	O
value	O
to	O
varies	O
depending	O
on	O
whether	O
a	O
union	B-Method
of	I-Method
word	I-Method
acceptors	I-Method
or	O
an	O
n	B-Method
-	I-Method
gram	I-Method
model	I-Method
is	O
used	O
.	O
	
In	O
the	O
former	O
case	O
,	O
an	O
acceptor	O
of	O
the	O
new	O
value	O
is	O
created	O
and	O
its	O
union	O
with	O
is	O
computed	O
.	O
	
In	O
the	O
latter	O
case	O
,	O
we	O
update	O
the	O
n	O
-	O
gram	O
counts	O
with	O
the	O
new	O
values	O
and	O
recompute	O
using	O
an	O
embedded	B-Method
n	I-Method
-	I-Method
gram	I-Method
engine	I-Method
.	O
	
The	O
time	O
required	O
for	O
the	O
complete	O
entity	B-Task
injection	I-Task
procedure	I-Task
just	O
described	O
ranges	O
from	O
a	O
few	O
seconds	O
for	O
small	O
assistants	O
,	O
to	O
a	O
few	O
dozen	O
seconds	O
for	O
larger	O
assistants	O
supporting	O
a	O
vocabulary	O
comprising	O
tens	O
of	O
thousands	O
of	O
words	O
.	O
	
Breaking	O
down	O
the	O
decoding	O
graph	O
into	O
smaller	O
,	O
computationally	O
manageable	O
pieces	O
,	O
therefore	O
allows	O
to	O
modify	O
the	O
model	O
directly	O
on	O
device	O
in	O
order	O
to	O
provide	O
a	O
personalized	O
user	O
experience	O
and	O
increase	O
the	O
overall	O
accuracy	B-Metric
of	O
the	O
SLU	B-Method
component	O
.	O
	
subsubsection	O
:	O
Confidence	B-Method
scoring	I-Method
	
An	O
important	O
challenge	O
of	O
specialized	O
SLU	B-Method
systems	O
trained	O
on	O
small	O
amounts	O
of	O
domain	O
-	O
specific	O
text	O
data	O
is	O
the	O
ability	O
to	O
detect	O
out	B-Method
-	I-Method
of	I-Method
-	I-Method
vocabulary	I-Method
(	O
OOV	B-Method
)	O
words	O
.	O
	
Indeed	O
,	O
while	O
a	O
sufficient	O
amount	O
of	O
specific	O
training	O
data	O
may	O
guarantee	O
sampling	O
the	O
important	O
words	O
which	O
allow	O
to	O
discriminate	O
between	O
different	O
intents	O
,	O
it	O
will	O
in	O
general	O
prove	O
unable	O
to	O
correctly	O
sample	O
filler	O
words	O
from	O
general	O
spoken	O
language	O
.	O
	
As	O
a	O
consequence	O
,	O
a	O
specialized	O
ASR	B-Method
such	O
as	O
the	O
one	O
described	O
in	O
the	O
previous	O
sections	O
will	O
tend	O
to	O
approximate	O
unknown	O
words	O
using	O
phonetically	O
related	O
ones	O
from	O
its	O
vocabulary	O
,	O
potentially	O
harming	O
the	O
subsequent	O
NLU	B-Method
.	O
	
One	O
way	O
of	O
addressing	O
this	O
issue	O
is	O
to	O
extract	O
a	O
word	B-Metric
-	I-Metric
level	I-Metric
confidence	I-Metric
score	I-Metric
from	O
the	O
ASR	B-Method
,	O
assigning	O
a	O
probability	O
for	O
the	O
word	O
to	O
be	O
correctly	O
decoded	O
.	O
	
Confidence	B-Task
scoring	I-Task
is	O
a	O
notoriously	O
hard	O
problem	O
in	O
speech	B-Task
recognition	I-Task
.	O
	
Our	O
approach	O
is	O
based	O
on	O
the	O
so	O
-	O
called	O
	
‘	O
‘	O
confusion	B-Method
network	I-Method
’	O
’	O
representation	O
of	O
the	O
hypotheses	O
of	O
the	O
ASR	B-Method
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
A	O
confusion	B-Method
network	I-Method
is	O
a	O
graph	B-Method
encoding	I-Method
,	O
for	O
each	O
speech	O
segment	O
in	O
an	O
utterance	O
,	O
the	O
competing	O
decoding	O
hypotheses	O
along	O
with	O
their	O
posterior	O
probability	O
,	O
thus	O
providing	O
a	O
richer	O
output	O
than	O
the	O
-	O
best	O
decoding	O
hypothesis	O
.	O
	
In	O
particular	O
,	O
confusion	B-Method
networks	I-Method
in	O
conjunction	O
with	O
NLU	B-Method
systems	O
typically	O
improve	O
end	O
-	O
to	O
-	O
end	O
performance	O
in	O
speech	B-Task
-	I-Task
to	I-Task
-	I-Task
meaning	I-Task
tasks	I-Task
.	O
	
In	O
the	O
following	O
,	O
we	O
restrict	O
our	O
use	O
of	O
confusion	B-Method
networks	I-Method
to	O
a	O
greedy	B-Method
decoder	I-Method
that	O
outputs	O
,	O
for	O
each	O
speech	O
segment	O
,	O
the	O
most	O
probable	O
decoded	O
word	O
along	O
with	O
its	O
probability	O
.	O
	
In	O
this	O
context	O
,	O
our	O
strategy	O
for	O
identifying	O
OOVs	B-Task
is	O
to	O
set	O
a	O
threshold	O
on	O
this	O
word	O
-	O
level	O
probability	O
.	O
	
Below	O
this	O
threshold	O
,	O
the	O
word	O
is	O
declared	O
misunderstood	O
.	O
	
In	O
practice	O
,	O
a	O
post	B-Method
-	I-Method
processing	I-Method
step	I-Method
is	O
used	O
to	O
remove	O
these	O
words	O
from	O
the	O
decoded	O
sentence	O
,	O
replacing	O
them	O
with	O
a	O
special	O
OOV	B-Method
symbol	O
.	O
	
This	O
allows	O
the	O
SLU	B-Method
pipeline	O
to	O
proceed	O
with	O
the	O
words	O
the	O
ASR	B-Method
has	O
understood	O
with	O
sufficient	O
probability	O
,	O
leaving	O
out	O
the	O
filler	O
words	O
which	O
are	O
unimportant	O
to	O
extract	O
the	O
intent	O
and	O
the	O
slots	O
from	O
the	O
query	O
,	O
thus	O
preserving	O
the	O
generalization	O
properties	O
of	O
the	O
SLU	B-Method
in	O
the	O
presence	O
of	O
unknown	O
filler	O
words	O
(	O
see	O
section	O
[	O
reference	O
]	O
for	O
a	O
quantitative	O
evaluation	O
)	O
.	O
	
Finally	O
,	O
we	O
may	O
define	O
a	O
sentence	B-Metric
-	I-Metric
level	I-Metric
confidence	I-Metric
by	O
simply	O
taking	O
the	O
geometric	B-Metric
mean	I-Metric
of	I-Metric
the	I-Metric
word	I-Metric
-	I-Metric
level	I-Metric
confidence	I-Metric
scores	I-Metric
.	O
	
subsection	O
:	O
Natural	B-Method
Language	I-Method
Understanding	I-Method
	
The	O
Natural	B-Method
Language	I-Method
Understanding	I-Method
component	O
of	O
the	O
Snips	B-Method
Voice	I-Method
Platform	I-Method
extracts	O
structured	O
data	O
from	O
queries	O
written	O
in	O
natural	O
language	O
.	O
	
Snips	B-Method
NLU	I-Method
–	O
a	O
Python	B-Method
library	I-Method
–	O
can	O
be	O
used	O
for	O
training	B-Task
and	I-Task
inference	I-Task
,	O
with	O
a	O
Rust	B-Method
implementation	I-Method
focusing	O
solely	O
on	O
inference	B-Task
.	O
	
Both	O
have	O
been	O
recently	O
open	O
-	O
sourced	O
.	O
	
Three	O
tasks	O
are	O
successively	O
performed	O
.	O
	
Intent	B-Task
Classification	I-Task
consists	O
in	O
extracting	O
the	O
intent	O
expressed	O
in	O
the	O
query	O
(	O
e.g.	O
SetTemperature	O
or	O
SwitchLightOn	O
)	O
.	O
	
Once	O
the	O
intent	O
is	O
known	O
,	O
Slot	B-Task
Filling	I-Task
aims	O
to	O
extract	O
the	O
slots	O
,	O
i.e.	O
the	O
values	O
of	O
the	O
entities	O
present	O
in	O
the	O
query	O
.	O
	
Finally	O
,	O
Entity	B-Task
Resolution	I-Task
focuses	O
on	O
built	O
-	O
in	O
entities	O
,	O
such	O
as	O
date	O
and	O
times	O
,	O
durations	O
,	O
temperatures	O
,	O
for	O
which	O
Snips	B-Method
provides	O
an	O
extra	O
resolution	O
step	O
.	O
	
It	O
basically	O
transforms	O
entity	O
values	O
such	O
as	O
"	O
tomorrow	O
evening	O
"	O
into	O
formatted	O
values	O
such	O
as	O
"	O
2018	O
-	O
04	O
-	O
19	O
19:00:00	O
+	O
00:00	O
"	O
.	O
	
Snippet	B-Method
[	O
reference	O
]	O
illustrates	O
a	O
typical	O
output	O
of	O
the	O
NLU	B-Method
component	O
.	O
	
subsubsection	O
:	O
Models	O
	
The	O
Snips	B-Method
NLU	I-Method
pipeline	O
(	O
Figure	O
[	O
reference	O
]	O
)	O
contains	O
a	O
main	O
component	O
,	O
the	O
NLU	B-Method
Engine	O
,	O
which	O
itself	O
is	O
composed	O
of	O
several	O
components	O
.	O
	
A	O
first	O
component	O
is	O
the	O
Intent	B-Method
Parser	I-Method
,	O
which	O
performs	O
both	O
intent	B-Task
classification	I-Task
and	O
slot	B-Task
filling	I-Task
.	O
	
It	O
does	O
not	O
resolve	O
entity	O
values	O
.	O
	
The	O
NLU	B-Method
Engine	O
calls	O
two	O
intent	B-Method
parsers	I-Method
successively	O
:	O
a	O
deterministic	B-Method
intent	I-Method
parser	I-Method
a	O
probabilistic	B-Method
intent	I-Method
parser	I-Method
	
The	O
second	O
one	O
is	O
called	O
only	O
when	O
nothing	O
is	O
extracted	O
by	O
the	O
first	O
one	O
.	O
	
paragraph	O
:	O
Deterministic	B-Method
Intent	I-Method
Parser	I-Method
.	O
	
The	O
goal	O
of	O
the	O
deterministic	B-Method
intent	I-Method
parser	I-Method
is	O
to	O
provide	O
robustness	B-Metric
and	O
a	O
predictable	O
experience	O
for	O
the	O
user	O
as	O
it	O
is	O
guaranteed	O
to	O
achieve	O
a	O
F1	O
-	O
score	O
on	O
the	O
training	O
examples	O
.	O
	
Its	O
implementation	O
relies	O
on	O
regular	O
expressions	O
.	O
	
The	O
queries	O
contained	O
in	O
the	O
training	O
data	O
are	O
used	O
to	O
build	O
patterns	O
covering	O
all	O
combinations	O
of	O
entity	O
values	O
.	O
	
Let	O
us	O
consider	O
,	O
for	O
instance	O
,	O
the	O
training	O
sample	O
:	O
set	O
the	O
[	O
kitchen	O
](	O
room	O
)	O
lights	O
to	O
[	O
blue	O
](	O
color	O
)	O
Let	O
us	O
assume	O
that	O
the	O
set	O
of	O
possible	O
values	O
for	O
the	O
room	O
entity	O
are	O
kitchen	O
,	O
hall	O
,	O
bedroom	O
and	O
those	O
for	O
the	O
color	O
entity	O
are	O
blue	O
,	O
yellow	O
,	O
red	O
.	O
	
A	O
representation	O
of	O
the	O
generated	O
pattern	O
for	O
this	O
sample	O
is	O
:	O
set	O
the	O
(	O
?	O
	
P	O
<	O
room	O
	
>	O
kitchen|hall|bedroom	O
)	O
	
lights	O
to	O
(	O
?	O
	
P	O
<	O
color	O
>	O
blue|yellow|red	O
)	O
	
paragraph	O
:	O
Probabilistic	B-Method
Intent	I-Method
Parser	I-Method
.	O
	
The	O
probabilistic	B-Method
intent	I-Method
parser	I-Method
aims	O
at	O
extending	O
parsing	B-Task
beyond	O
training	O
examples	O
and	O
recognizing	O
variations	O
which	O
do	O
not	O
appear	O
in	O
the	O
training	O
data	O
.	O
	
It	O
provides	O
the	O
generalization	O
power	O
that	O
the	O
deterministic	B-Method
parser	I-Method
lacks	O
.	O
	
This	O
parser	B-Method
runs	O
in	O
two	O
cascaded	O
steps	O
:	O
intent	B-Task
classification	I-Task
and	O
slot	B-Task
filling	I-Task
.	O
	
The	O
intent	B-Task
classification	I-Task
is	O
implemented	O
with	O
a	O
logistic	B-Method
regression	I-Method
trained	O
on	O
the	O
queries	O
from	O
every	O
intent	O
.	O
	
The	O
slot	B-Method
-	I-Method
filling	I-Method
step	I-Method
consists	O
in	O
several	O
linear	B-Method
-	I-Method
chain	I-Method
Conditional	I-Method
Random	I-Method
Fields	I-Method
(	O
CRFs	B-Method
)	O
,	O
each	O
of	O
them	O
being	O
trained	O
for	O
a	O
specific	O
intent	O
.	O
	
Once	O
the	O
intent	O
is	O
extracted	O
by	O
the	O
intent	B-Method
classifier	I-Method
,	O
the	O
corresponding	O
slot	O
filler	O
is	O
used	O
to	O
extract	O
slots	O
from	O
the	O
query	O
.	O
	
The	O
choice	O
of	O
CRFs	O
for	O
the	O
slot	B-Task
-	I-Task
filling	I-Task
step	I-Task
results	O
from	O
careful	O
considerations	O
and	O
experiments	O
.	O
	
They	O
are	O
indeed	O
a	O
standard	O
approach	O
for	O
this	O
task	O
,	O
and	O
are	O
known	O
to	O
have	O
low	O
generalization	B-Metric
error	I-Metric
.	O
	
Recently	O
,	O
more	O
computationally	O
demanding	O
approaches	O
based	O
on	O
deep	B-Method
learning	I-Method
models	I-Method
have	O
been	O
proposed	O
.	O
	
Our	O
experiments	O
however	O
showed	O
that	O
these	O
approaches	O
do	O
not	O
yield	O
any	O
significant	O
gain	O
in	O
accuracy	B-Metric
in	O
the	O
typical	O
training	O
size	O
regime	O
of	O
custom	B-Task
voice	I-Task
assistants	I-Task
(	O
a	O
few	O
hundred	O
queries	O
)	O
.	O
	
The	O
lightest	O
option	O
was	O
therefore	O
favored	O
.	O
	
On	O
top	O
of	O
the	O
classical	O
features	O
used	O
in	O
slot	B-Task
-	I-Task
filling	I-Task
tasks	I-Task
such	O
as	O
n	O
-	O
grams	O
,	O
case	O
,	O
shape	O
,	O
etc	O
.	O
,	O
additional	O
features	O
are	O
crafted	O
.	O
	
In	O
this	O
kind	O
of	O
task	O
,	O
it	O
appears	O
that	O
leveraging	O
external	O
knowledge	O
is	O
crucial	O
.	O
	
Hence	O
,	O
we	O
apply	O
a	O
built	O
-	O
in	O
entity	B-Method
extractor	I-Method
(	O
see	O
next	O
paragraph	O
about	O
Entity	B-Task
Resolution	I-Task
)	O
to	O
build	O
features	O
that	O
indicate	O
whether	O
or	O
not	O
a	O
token	O
in	O
the	O
sentence	O
is	O
part	O
of	O
a	O
built	O
-	O
in	O
entity	O
.	O
	
The	O
value	O
of	O
the	O
feature	O
is	O
the	O
corresponding	O
entity	O
,	O
if	O
one	O
is	O
found	O
,	O
augmented	O
with	O
a	O
BILOU	B-Method
coding	I-Method
scheme	I-Method
,	O
indicating	O
the	O
position	O
of	O
the	O
token	O
in	O
the	O
matching	O
entity	O
value	O
.	O
	
We	O
find	O
empirically	O
that	O
the	O
presence	O
of	O
such	O
features	O
improves	O
the	O
overall	O
accuracy	B-Metric
,	O
thanks	O
to	O
the	O
robustness	B-Metric
of	O
the	O
built	B-Method
-	I-Method
in	I-Method
entities	I-Method
extractor	I-Method
.	O
	
The	O
problem	O
of	O
data	B-Task
sparsity	I-Task
is	O
addressed	O
by	O
integrating	O
features	O
based	O
on	O
word	B-Method
clusters	I-Method
.	O
	
More	O
specifically	O
,	O
we	O
use	O
Brown	O
clusters	O
released	O
by	O
the	O
authors	O
of	O
,	O
as	O
well	O
as	O
word	O
clusters	O
built	O
from	O
word2vec	B-Method
embeddings	I-Method
using	O
k	B-Method
-	I-Method
means	I-Method
clustering	I-Method
.	O
	
We	O
find	O
that	O
the	O
use	O
of	O
these	O
features	O
helps	O
in	O
reducing	O
generalization	B-Metric
error	I-Metric
,	O
by	O
bringing	O
the	O
effective	O
size	O
of	O
the	O
vocabulary	O
from	O
typically	O
50	O
K	O
words	O
down	O
to	O
a	O
few	O
hundred	O
word	O
clusters	O
.	O
	
Finally	O
,	O
gazetteer	O
features	O
are	O
built	O
,	O
based	O
on	O
entity	O
values	O
provided	O
in	O
the	O
training	O
data	O
.	O
	
One	O
gazetteer	O
is	O
created	O
per	O
entity	O
type	O
,	O
and	O
used	O
to	O
match	O
tokens	O
via	O
a	O
BILOU	B-Method
coding	I-Method
scheme	I-Method
.	O
	
Table	O
[	O
reference	O
]	O
displays	O
some	O
examples	O
of	O
features	O
used	O
in	O
Snips	B-Method
NLU	I-Method
.	O
	
Overfitting	O
is	O
avoided	O
by	O
dropping	O
a	O
fraction	O
of	O
the	O
features	O
during	O
training	O
.	O
	
More	O
precisely	O
,	O
each	O
feature	O
is	O
assigned	O
a	O
dropout	O
probability	O
.	O
	
For	O
each	O
training	O
example	O
,	O
we	O
compute	O
the	O
features	O
and	O
then	O
erase	O
feature	O
with	O
probability	O
.	O
	
Without	O
this	O
mechanism	O
,	O
we	O
typically	O
observed	O
that	O
the	O
CRF	B-Method
learns	O
to	O
tag	O
every	O
value	O
matching	O
the	O
entity	O
gazetteer	O
while	O
discarding	O
all	O
those	O
absent	O
from	O
it	O
.	O
	
paragraph	O
:	O
Entity	B-Task
resolution	I-Task
.	O
	
The	O
last	O
step	O
of	O
the	O
NLU	B-Method
pipeline	O
consists	O
in	O
resolving	O
slot	O
values	O
(	O
e.g.	O
from	O
raw	O
strings	O
to	O
ISO	O
formatted	O
values	O
for	O
date	O
and	O
time	O
entities	O
)	O
.	O
	
Entity	O
values	O
that	O
can	O
be	O
resolved	O
(	O
e.g.	O
dates	O
,	O
temperatures	O
,	O
numbers	O
)	O
correspond	O
to	O
the	O
built	O
-	O
in	O
entities	O
introduced	O
in	O
section	O
[	O
reference	O
]	O
,	O
and	O
are	O
supported	O
natively	O
without	O
requiring	O
training	O
examples	O
.	O
	
The	O
resolution	B-Task
is	O
done	O
with	O
Rustling	B-Method
,	O
an	O
in	O
-	O
house	O
re	B-Method
-	I-Method
implementation	I-Method
of	I-Method
Facebook	I-Method
’s	I-Method
Duckling	I-Method
library	I-Method
in	O
Rust	B-Method
,	O
which	O
we	O
also	O
open	O
sourced	O
,	O
with	O
modifications	O
to	O
make	O
its	O
runtime	O
more	O
stable	O
with	O
regards	O
to	O
the	O
length	O
of	O
the	O
sentences	O
parsed	O
.	O
	
subsubsection	O
:	O
Evaluation	O
	
Snips	B-Method
NLU	I-Method
is	O
evaluated	O
and	O
compared	O
to	O
various	O
NLU	B-Method
services	O
on	O
two	O
datasets	O
:	O
a	O
previously	O
published	O
comparison	O
,	O
and	O
an	O
in	O
-	O
house	O
open	O
dataset	O
.	O
	
The	O
latter	O
has	O
been	O
made	O
freely	O
accessible	O
on	O
GitHub	O
to	O
promote	O
transparency	O
and	O
reproducibility	O
.	O
	
paragraph	O
:	O
Evaluation	O
on	O
Braun	O
et	O
al	O
.	O
,	O
2017	O
.	O
	
In	O
January	O
2018	O
,	O
we	O
evaluated	O
Snips	B-Method
NLU	I-Method
on	O
a	O
previously	O
published	O
comparison	O
between	O
various	O
NLU	B-Method
services	O
:	O
a	O
few	O
of	O
the	O
main	O
cloud	B-Method
-	I-Method
based	I-Method
solutions	I-Method
(	O
Microsoft	B-Method
’s	I-Method
Luis	I-Method
,	O
IBM	B-Method
Watson	I-Method
,	O
API.AI	B-Method
now	O
Google	B-Method
’s	I-Method
Dialogflow	I-Method
)	O
,	O
and	O
the	O
open	O
-	O
source	O
platform	O
Rasa	O
NLU	B-Method
.	O
	
For	O
the	O
raw	O
results	O
and	O
methodology	O
,	O
see	O
.	O
	
The	O
main	O
metric	O
used	O
in	O
this	O
benchmark	O
is	O
the	O
average	B-Metric
F1	I-Metric
-	I-Metric
score	I-Metric
of	O
intent	B-Task
classification	I-Task
and	O
slot	B-Task
filling	I-Task
.	O
	
The	O
data	O
consists	O
in	O
three	O
corpora	O
.	O
	
Two	O
of	O
the	O
corpora	O
were	O
extracted	O
from	O
StackExchange	B-Method
,	O
one	O
from	O
a	O
Telegram	O
chatbot	O
.	O
	
The	O
exact	O
same	O
splits	O
as	O
in	O
the	O
original	O
paper	O
were	O
used	O
for	O
the	O
Ubuntu	O
and	O
Web	O
Applications	O
corpora	O
.	O
	
At	O
the	O
date	O
we	O
ran	O
the	O
evaluation	O
,	O
the	O
train	B-Metric
and	I-Metric
test	I-Metric
splits	I-Metric
were	O
not	O
explicit	O
for	O
the	O
Chatbot	O
dataset	O
(	O
although	O
they	O
were	O
added	O
later	O
on	O
)	O
.	O
	
In	O
that	O
case	O
,	O
we	O
ran	O
a	O
5	B-Method
-	I-Method
fold	I-Method
cross	I-Method
-	I-Method
validation	I-Method
.	O
	
The	O
results	O
are	O
presented	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Figure	O
[	O
reference	O
]	O
presents	O
the	O
average	O
results	O
on	O
the	O
three	O
corpora	O
,	O
corresponding	O
to	O
the	O
overall	O
section	O
of	O
Table	O
[	O
reference	O
]	O
.	O
	
For	O
Rasa	B-Method
,	O
we	O
considered	O
all	O
three	O
possible	O
backends	O
(	O
Spacy	B-Method
,	O
SKLearn	B-Method
+	O
MITIE	B-Method
,	O
MITIE	B-Method
)	O
,	O
see	O
the	O
abovementioned	O
GitHub	O
repository	O
for	O
more	O
details	O
.	O
	
However	O
,	O
only	O
Spacy	B-Method
was	O
run	O
on	O
all	O
3	O
datasets	O
,	O
for	O
train	O
time	O
reasons	O
.	O
	
For	O
fairness	O
,	O
the	O
latest	O
version	O
of	O
Rasa	O
NLU	B-Method
is	O
also	O
displayed	O
.	O
	
Results	O
show	O
that	O
Snips	B-Method
NLU	I-Method
ranks	O
second	O
highest	O
overall	O
.	O
	
paragraph	O
:	O
Evaluation	O
on	O
an	O
in	O
-	O
house	O
open	O
dataset	O
.	O
	
In	O
June	O
2017	O
,	O
Snips	B-Method
NLU	I-Method
was	O
evaluated	O
on	O
an	O
in	O
-	O
house	O
dataset	O
of	O
over	O
16	O
K	O
crowdsourced	O
queries	O
(	O
freely	O
available	O
)	O
distributed	O
among	O
7	O
user	O
intents	O
of	O
various	O
complexity	O
:	O
	
SearchCreativeWork	O
	
(	O
e.g.	O
Find	O
me	O
the	O
I	O
,	O
Robot	O
television	O
show	O
)	O
,	O
GetWeather	O
(	O
e.g.	O
Is	O
it	O
windy	O
in	O
Boston	O
,	O
MA	O
right	O
now	O
?	O
)	O
,	O
BookRestaurant	O
(	O
e.g.	O
I	O
want	O
to	O
book	O
a	O
highly	O
rated	O
restaurant	O
in	O
Paris	O
tomorrow	O
night	O
)	O
,	O
PlayMusic	O
(	O
e.g.	O
Play	O
the	O
last	O
track	O
from	O
Beyoncé	O
off	O
Spotify	O
)	O
,	O
AddToPlaylist	O
(	O
e.g.	O
Add	O
Diamonds	O
to	O
my	O
roadtrip	O
playlist	O
)	O
RateBook	O
(	O
e.g.	O
Give	O
6	O
stars	O
to	O
Of	O
Mice	O
and	O
Men	O
)	O
SearchScreeningEvent	O
(	O
e.g.	O
Check	O
the	O
showtimes	O
for	O
Wonder	O
Woman	O
in	O
Paris	O
)	O
	
The	O
full	O
ontology	O
is	O
available	O
on	O
Table	O
[	O
reference	O
]	O
in	O
Appendix	O
.	O
	
In	O
this	O
experiment	O
,	O
the	O
comparison	O
is	O
done	O
separately	O
on	O
each	O
intent	O
to	O
focus	O
on	O
slot	B-Task
filling	I-Task
(	O
rather	O
than	O
intent	B-Task
classification	I-Task
)	O
.	O
	
The	O
main	O
metric	O
used	O
in	O
this	O
benchmark	O
is	O
the	O
average	B-Metric
F1	I-Metric
-	I-Metric
score	I-Metric
of	O
slot	B-Method
filling	I-Method
on	O
all	O
slots	O
.	O
	
Three	O
training	O
sets	O
of	O
70	O
and	O
2000	O
queries	O
have	O
been	O
drawn	O
from	O
the	O
total	O
pool	O
of	O
queries	O
to	O
gain	O
in	O
statistical	O
relevance	O
.	O
	
Validation	O
sets	O
consist	O
in	O
100	O
queries	O
per	O
intent	O
.	O
	
Five	O
different	O
cloud	B-Method
-	I-Method
based	I-Method
providers	I-Method
are	O
compared	O
to	O
Snips	B-Method
NLU	I-Method
(	O
Microsoft	B-Method
’s	I-Method
Luis	I-Method
,	O
API.AI	B-Method
now	O
Google	B-Method
’s	I-Method
Dialogflow	I-Method
,	O
Facebook	B-Method
’s	I-Method
Wit.ai	I-Method
,	O
and	O
Amazon	B-Method
Alexa	I-Method
)	O
.	O
	
For	O
more	O
details	O
about	O
the	O
specific	O
methodology	O
for	O
each	O
provider	O
and	O
access	O
to	O
the	O
full	O
dataset	O
,	O
see	O
.	O
	
Each	O
solution	O
is	O
trained	O
and	O
evaluated	O
on	O
the	O
exact	O
same	O
datasets	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
precision	B-Metric
,	O
recall	B-Metric
and	O
F1	B-Metric
-	I-Metric
score	I-Metric
averaged	O
on	O
all	O
slots	O
and	O
on	O
all	O
intents	O
.	O
	
Results	O
specific	O
to	O
each	O
intent	O
are	O
available	O
in	O
Tables	O
[	O
reference	O
]	O
&	O
[	O
reference	O
]	O
in	O
Appendix	O
.	O
	
Snips	B-Method
NLU	I-Method
is	O
as	O
accurate	O
or	O
better	O
than	O
competing	O
cloud	B-Method
-	I-Method
based	I-Method
solutions	I-Method
in	O
slot	B-Task
filling	I-Task
,	O
regardless	O
of	O
the	O
training	O
set	O
size	O
.	O
	
subsubsection	O
:	O
Embedded	O
performance	O
	
Using	O
Rust	B-Method
for	O
the	O
NLU	B-Method
inference	O
pipeline	O
allows	O
to	O
keep	O
the	O
memory	B-Metric
footprint	I-Metric
and	O
the	O
inference	B-Metric
runtime	I-Metric
very	O
low	O
.	O
	
Memory	B-Metric
usage	I-Metric
has	O
been	O
optimized	O
,	O
with	O
model	O
sizes	O
ranging	O
from	O
a	O
few	O
hundred	O
kilobytes	O
of	O
RAM	O
for	O
common	O
cases	O
to	O
a	O
few	O
megabytes	O
for	O
the	O
most	O
complex	O
assistants	O
.	O
	
They	O
are	O
therefore	O
fit	O
for	O
deployment	O
on	O
a	O
Raspberry	B-Task
Pi	I-Task
or	O
a	O
mobile	B-Task
app	I-Task
,	O
and	O
more	O
powerful	O
servers	O
can	O
handle	O
hundreds	O
of	O
parallel	O
instances	O
.	O
	
Using	O
the	O
embedded	O
Snips	B-Method
Voice	O
platform	O
significantly	O
reduces	O
the	O
inference	B-Metric
runtime	I-Metric
compared	O
to	O
a	O
roundtrip	B-Method
to	O
a	O
cloud	O
service	O
,	O
as	O
displayed	O
on	O
Table	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
End	O
-	O
to	O
-	O
end	O
Evaluation	O
	
In	O
this	O
section	O
,	O
we	O
evaluate	O
the	O
performance	O
of	O
the	O
Snips	B-Method
Spoken	I-Method
Language	I-Method
Understanding	I-Method
(	O
SLU	B-Method
)	O
pipeline	O
in	O
an	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
,	I-Task
speech	I-Task
-	I-Task
to	I-Task
-	I-Task
meaning	I-Task
setting	I-Task
.	O
	
To	O
this	O
end	O
,	O
we	O
consider	O
two	O
real	O
-	O
world	O
assistants	O
of	O
different	O
sizes	O
,	O
namely	O
SmartLights	B-Method
and	O
Weather	B-Method
.	O
	
The	O
SmartLights	B-Method
assistant	O
specializes	O
in	O
interacting	O
with	O
light	O
devices	O
supporting	O
different	O
colors	O
and	O
levels	O
of	O
brightness	O
,	O
and	O
positioned	O
in	O
various	O
rooms	O
.	O
	
The	O
Weather	B-Method
assistant	O
is	O
targeted	O
at	O
weather	B-Task
queries	I-Task
in	O
general	O
,	O
and	O
supports	O
various	O
types	O
of	O
formulations	O
and	O
places	O
.	O
	
Tables	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
sum	O
up	O
the	O
constitution	O
and	O
size	O
of	O
the	O
datasets	O
corresponding	O
to	O
these	O
two	O
assistants	O
,	O
while	O
tables	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
	
describe	O
their	O
entities	O
.	O
	
Note	O
in	O
particular	O
the	O
use	O
of	O
the	O
built	O
-	O
in	O
‘	O
‘	O
snips	O
/	O
number	O
’’	O
(	O
respectively	O
‘	O
‘	O
snips	O
/	O
datetime	O
’’	O
)	O
entity	O
to	O
define	O
the	O
brightness	O
(	O
resp	O
.	O
	
datetime	O
)	O
slot	O
,	O
which	O
allows	O
the	O
assistant	O
to	O
generalize	O
to	O
values	O
absent	O
from	O
the	O
dataset	O
.	O
	
We	O
are	O
interested	O
in	O
computing	O
end	O
-	O
to	O
-	O
end	O
metrics	O
quantifying	O
the	O
ability	O
of	O
the	O
assistants	B-Method
to	O
extract	O
intent	O
and	O
slots	O
from	O
spoken	O
utterances	O
.	O
	
We	O
create	O
a	O
test	O
set	O
by	O
crowdsourcing	B-Method
a	O
spoken	O
corpus	O
corresponding	O
to	O
the	O
queries	O
of	O
each	O
dataset	O
.	O
	
For	O
each	O
sentence	O
of	O
the	O
speech	B-Material
corpus	I-Material
,	O
we	O
apply	O
the	O
ASR	B-Method
engine	O
followed	O
by	O
the	O
NLU	B-Method
engine	O
,	O
and	O
compare	O
the	O
predicted	O
output	O
to	O
the	O
ground	O
true	O
intent	O
and	O
slots	O
in	O
the	O
dataset	O
.	O
	
In	O
the	O
following	O
,	O
we	O
present	O
our	O
results	O
in	O
terms	O
of	O
the	O
classical	B-Metric
precision	I-Metric
,	O
recall	B-Metric
,	O
and	O
F1	B-Metric
scores	I-Metric
.	O
	
subsection	O
:	O
Language	B-Metric
Model	I-Metric
Generalization	I-Metric
Error	I-Metric
	
To	O
be	O
able	O
to	O
understand	O
arbitrary	O
formulations	O
of	O
an	O
intent	O
,	O
the	O
SLU	B-Method
engine	O
must	O
be	O
able	O
to	O
generalize	O
to	O
unseen	O
queries	O
in	O
the	O
same	O
domain	O
.	O
	
To	O
test	O
the	O
generalization	B-Metric
ability	I-Metric
of	O
the	O
Snips	B-Method
SLU	I-Method
components	O
,	O
we	O
use	O
5	B-Method
-	I-Method
fold	I-Method
cross	I-Method
-	I-Method
validation	I-Method
,	O
and	O
successively	O
train	O
the	O
LM	B-Method
and	O
NLU	B-Method
on	O
four	O
fifth	O
of	O
the	O
dataset	O
,	O
testing	O
on	O
the	O
last	O
,	O
unseen	O
,	O
fifth	O
of	O
the	O
data	O
.	O
	
The	O
training	O
procedure	O
is	O
identical	O
to	O
the	O
one	O
detailed	O
in	O
section	O
[	O
reference	O
]	O
.	O
	
We	O
note	O
that	O
all	O
the	O
values	O
of	O
the	O
entities	O
are	O
always	O
included	O
in	O
the	O
training	O
set	O
.	O
	
Tables	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
sum	O
up	O
the	O
results	O
of	O
this	O
experiment	O
,	O
highlighting	O
in	O
particular	O
the	O
modest	O
effect	O
of	O
the	O
introduction	O
of	O
the	O
ASR	B-Method
engine	O
compared	O
to	O
the	O
accuracy	B-Metric
of	O
the	O
NLU	B-Method
evaluated	O
directly	O
on	O
the	O
ground	O
true	O
query	O
.	O
	
Because	O
unseen	O
test	O
queries	O
may	O
contain	O
out	O
of	O
vocabulary	O
words	O
absent	O
from	O
the	O
training	O
splits	O
,	O
the	O
ability	O
of	O
the	O
SLU	B-Method
to	O
generalize	O
in	O
this	O
setting	O
relies	O
heavily	O
on	O
the	O
identification	O
of	O
unknown	O
words	O
through	O
the	O
strategy	O
detailed	O
in	O
section	O
[	O
reference	O
]	O
.	O
	
As	O
noted	O
earlier	O
and	O
confirmed	O
by	O
these	O
results	O
,	O
this	O
confidence	B-Method
scoring	I-Method
strategy	I-Method
also	O
allows	O
to	O
favor	O
precision	B-Metric
over	O
recall	B-Metric
by	O
rejecting	O
uncertain	O
words	O
that	O
may	O
be	O
misinterpreted	O
by	O
the	O
NLU	B-Method
.	O
	
Figure	O
[	O
reference	O
]	O
illustrates	O
the	O
correlation	O
between	O
the	O
sentence	B-Metric
-	I-Metric
level	I-Metric
confidence	I-Metric
score	I-Metric
defined	O
in	O
section	O
[	O
reference	O
]	O
and	O
the	O
word	B-Metric
error	I-Metric
rate	I-Metric
.	O
	
While	O
noisy	O
,	O
the	O
confidence	O
allows	O
to	O
detect	O
misunderstood	O
queries	O
,	O
and	O
can	O
be	O
mixed	O
with	O
the	O
intent	O
classification	O
probability	O
output	O
by	O
the	O
NLU	B-Method
to	O
reject	O
dubious	O
queries	O
,	O
thus	O
promoting	O
precision	B-Metric
over	O
recall	B-Metric
.	O
	
subsection	O
:	O
Embedded	B-Metric
Performance	I-Metric
	
The	O
embedded	O
SLU	B-Method
components	O
corresponding	O
to	O
the	O
assistants	O
described	O
in	O
the	O
previous	O
section	O
are	O
trained	O
in	O
under	O
thirty	O
seconds	O
through	O
the	O
Snips	B-Method
web	O
console	O
(	O
see	O
section	O
[	O
reference	O
]	O
)	O
.	O
	
The	O
resulting	O
language	B-Method
models	I-Method
have	O
a	O
size	O
of	O
the	O
order	O
of	O
the	O
megabyte	O
for	O
the	O
SmartLights	B-Method
assistant	O
(	O
MB	O
in	O
total	O
,	O
with	O
the	O
acoustic	B-Method
model	I-Method
)	O
,	O
and	O
MB	O
for	O
the	O
Weather	B-Method
assistant	O
(	O
MB	O
in	O
total	O
)	O
.	O
	
The	O
SLU	B-Method
components	O
run	O
faster	O
than	O
real	O
time	O
on	O
a	O
single	O
core	O
on	O
a	O
Raspberry	O
Pi	O
3	O
,	O
as	O
well	O
as	O
on	O
the	O
smaller	O
NXP	O
imx7D.	O
	
section	O
:	O
Training	B-Method
models	I-Method
without	O
user	O
data	O
	
The	O
private	O
-	O
by	O
-	O
design	B-Method
approach	I-Method
described	O
in	O
the	O
previous	O
sections	O
requires	O
to	O
train	O
high	O
-	O
performance	O
machine	B-Method
learning	I-Method
models	I-Method
without	O
access	O
to	O
users	O
queries	O
.	O
	
This	O
problem	O
is	O
especially	O
critical	O
for	O
the	O
specialized	O
language	B-Method
modeling	I-Method
components	I-Method
	
–	O
Language	B-Method
Model	I-Method
and	O
Natural	B-Method
Language	I-Method
Understanding	I-Method
engine	O
–	O
as	O
both	O
need	O
to	O
be	O
trained	O
on	O
an	O
assistant	O
-	O
specific	O
dataset	O
.	O
	
A	O
solution	O
is	O
to	O
develop	O
a	O
data	B-Method
generation	I-Method
pipeline	I-Method
.	O
	
Once	O
the	O
scope	O
of	O
an	O
assistant	O
has	O
been	O
defined	O
,	O
a	O
mix	O
of	O
crowdsourcing	B-Method
and	O
semi	B-Method
-	I-Method
supervised	I-Method
machine	I-Method
learning	I-Method
is	O
used	O
to	O
generate	O
thousands	O
of	O
high	O
-	O
quality	O
training	O
examples	O
,	O
mimicking	O
user	O
data	O
collection	O
without	O
compromising	O
on	O
privacy	O
.	O
	
The	O
aim	O
of	O
this	O
section	O
is	O
to	O
describe	O
the	O
data	B-Method
generation	I-Method
pipeline	I-Method
,	O
and	O
to	O
demonstrate	O
its	O
impact	O
on	O
the	O
performance	O
of	O
the	O
NLU	B-Method
.	O
	
subsection	O
:	O
Data	B-Method
generation	I-Method
pipeline	I-Method
	
A	O
first	O
simple	O
approach	O
to	O
data	B-Task
generation	I-Task
is	O
grammar	B-Method
-	I-Method
based	I-Method
generation	I-Method
,	O
which	O
consists	O
in	O
breaking	O
down	O
a	O
written	O
query	O
into	O
consecutive	O
semantic	O
blocks	O
and	O
requires	O
enumerating	O
every	O
possible	O
pattern	O
in	O
the	O
chosen	O
language	O
.	O
	
While	O
this	O
method	O
guarantees	O
an	O
exact	O
slot	O
and	O
intent	O
supervision	O
,	O
queries	O
generated	O
in	O
this	O
way	O
are	O
highly	O
correlated	O
:	O
their	O
diversity	O
is	O
limited	O
to	O
the	O
expressive	O
power	O
of	O
the	O
used	O
grammar	O
and	O
the	O
imagination	O
of	O
the	O
person	O
having	O
created	O
it	O
.	O
	
Moreover	O
,	O
the	O
pattern	B-Method
definition	I-Method
and	O
enumeration	B-Task
can	O
be	O
very	O
time	O
consuming	O
and	O
requires	O
an	O
extensive	O
knowledge	O
of	O
the	O
given	O
language	O
.	O
	
This	O
approach	O
is	O
therefore	O
unfit	O
for	O
generating	B-Task
queries	I-Task
in	I-Task
natural	I-Task
language	I-Task
.	O
	
On	O
the	O
other	O
hand	O
,	O
crowdsourcing	B-Method
–	O
widely	O
used	O
in	O
Natural	B-Task
Language	I-Task
Processing	I-Task
research	I-Task
–	O
ensures	O
diversity	O
in	O
formulation	B-Task
by	O
sampling	O
queries	O
from	O
a	O
large	O
number	O
of	O
demographically	O
diverse	O
contributors	O
.	O
	
However	O
,	O
the	O
accuracy	B-Metric
of	O
intent	O
and	O
slot	B-Task
supervision	I-Task
decreases	O
as	O
soon	O
as	O
humans	O
are	O
in	O
the	O
loop	O
.	O
	
Any	O
mislabeling	O
of	O
a	O
query	O
	
’s	O
intent	O
or	O
slots	O
has	O
a	O
strong	O
impact	O
on	O
the	O
end	O
-	O
to	O
-	O
end	O
performance	O
of	O
the	O
SLU	B-Method
.	O
	
To	O
guarantee	O
a	O
fast	O
and	O
accurate	O
generation	O
of	O
training	O
data	O
for	O
the	O
language	B-Method
modeling	I-Method
components	I-Method
,	O
we	O
complement	O
crowdsourcing	B-Method
with	O
machine	B-Method
-	I-Method
learning	I-Method
-	I-Method
based	I-Method
disambiguation	I-Method
techniques	I-Method
.	O
	
We	O
new	O
detail	O
the	O
implementation	O
of	O
the	O
data	B-Method
generation	I-Method
pipeline	I-Method
.	O
	
subsubsection	O
:	O
Crowdsourcing	O
	
Crowdsourcing	B-Task
tasks	I-Task
were	O
originally	O
submitted	O
to	O
Amazon	O
Mechanical	O
Turk	O
,	O
a	O
widely	O
used	O
platform	O
in	O
non	B-Task
-	I-Task
expert	I-Task
annotations	I-Task
for	O
natural	B-Task
language	I-Task
tasks	I-Task
.	O
	
While	O
a	O
sufficient	O
number	O
of	O
English	O
-	O
speaking	O
contributors	O
can	O
be	O
reached	O
easily	O
,	O
other	O
languages	O
such	O
as	O
French	O
,	O
German	O
or	O
Japanese	O
suffer	O
from	O
a	O
comparatively	O
smaller	O
available	O
crowd	O
.	O
	
Local	O
crowdsourcing	B-Method
platforms	O
therefore	O
had	O
to	O
be	O
integrated	O
.	O
	
A	O
text	B-Task
query	I-Task
generation	I-Task
task	I-Task
consists	O
in	O
generating	O
an	O
example	O
of	O
user	B-Task
query	I-Task
matching	O
a	O
provided	O
set	O
of	O
intent	O
and	O
slots	O
–	O
	
e.g.	O
the	O
following	O
set	O
	
:	O
Intent	O
:	O
The	O
user	O
wants	O
to	O
switch	O
the	O
lights	O
on	O
;	O
slot	O
:	O
(	O
bedroom	O
)[	O
room	O
]	O
could	O
result	O
in	O
the	O
generated	O
query	O
	
‘	O
	
‘	O
	
I	O
want	O
lights	O
in	O
the	O
bedroom	O
right	O
now	O
!	O
	
’’	O
.	O
	
Fixing	O
entity	O
values	O
reduces	O
the	O
task	O
to	O
a	O
sentence	B-Task
generation	I-Task
and	O
removes	O
the	O
need	O
for	O
a	O
slot	B-Method
labeling	I-Method
step	I-Method
,	O
limiting	O
the	O
sources	O
of	O
error	O
.	O
	
Diversity	O
is	O
enforced	O
by	O
both	O
submitting	O
this	O
task	O
to	O
the	O
widest	O
possible	O
crowd	O
while	O
limiting	O
the	O
number	O
of	O
available	O
tasks	O
per	O
contributor	O
and	O
by	O
selecting	O
large	O
sets	O
of	O
slot	O
values	O
.	O
	
Each	O
generated	O
query	O
goes	O
through	O
a	O
validation	B-Method
process	I-Method
taking	O
the	O
form	O
of	O
a	O
second	O
crowdsourcing	B-Method
task	O
,	O
where	O
at	O
least	O
two	O
out	O
of	O
three	O
new	O
contributors	O
must	O
confirm	O
its	O
formulation	O
,	O
spelling	O
,	O
and	O
intent	O
.	O
	
Majority	B-Method
voting	I-Method
is	O
indeed	O
a	O
simple	O
and	O
straightforward	O
approach	O
for	O
quality	B-Task
assessment	I-Task
in	O
crowdsourcing	B-Method
.	O
	
A	O
custom	O
dashboard	B-Method
hosted	O
on	O
our	O
servers	O
has	O
been	O
developed	O
to	O
optimize	O
the	O
contributor	O
’s	O
workflow	O
,	O
with	O
clear	O
descriptions	O
of	O
the	O
task	O
.	O
	
The	O
dashboard	O
also	O
prevents	O
a	O
contributor	O
from	O
submitting	O
a	O
query	O
that	O
does	O
not	O
contain	O
the	O
imposed	O
entity	O
values	O
,	O
with	O
a	O
fuzzy	B-Method
matching	I-Method
rule	I-Method
allowing	O
for	O
inflections	O
in	O
all	O
supported	O
languages	O
(	O
conjugation	O
,	O
plural	O
,	O
gender	O
,	O
compounds	O
,	O
etc	O
.	O
)	O
.	O
	
subsubsection	O
:	O
Disambiguation	B-Task
	
While	O
the	O
previous	O
validation	O
step	O
allows	O
to	O
filter	O
out	O
most	O
spelling	O
and	O
formulation	O
mistakes	O
,	O
it	O
does	O
not	O
always	O
guarantee	O
the	O
correctness	O
of	O
the	O
intent	O
or	O
the	O
absence	O
of	O
spurious	O
entities	O
.	O
	
Indeed	O
,	O
in	O
a	O
first	O
type	O
of	O
errors	O
,	O
the	O
intent	O
of	O
the	O
query	O
may	O
not	O
match	O
the	O
provided	O
one	O
–	O
	
e.g.	O
Switch	O
off	O
the	O
lights	O
when	O
the	O
intent	O
SwitchLightOn	O
was	O
required	O
.	O
	
In	O
a	O
second	O
type	O
of	O
errors	O
,	O
spurious	O
entities	O
may	O
be	O
added	O
by	O
the	O
contributor	O
,	O
so	O
that	O
they	O
are	O
not	O
labeled	O
as	O
such	O
–	O
	
e.g.	O
	
‘	O
	
‘	O
	
I	O
want	O
lights	O
in	O
the	O
guest	O
[	O
bedroom	O
](	O
room	O
)	O
at	O
60	O
right	O
now	O
!	O
	
’’	O
when	O
only	O
[	O
bedroom	O
](	O
room	O
)	O
was	O
mentioned	O
in	O
the	O
task	O
specifications	O
.	O
	
An	O
unlabeled	O
entity	O
has	O
a	O
particularly	O
strong	O
impact	O
on	O
the	O
CRF	O
features	O
in	O
the	O
NLU	B-Method
component	O
,	O
and	O
limits	O
the	O
ability	O
of	O
the	O
LM	B-Method
to	O
generalize	O
.	O
	
These	O
errors	O
in	O
the	O
training	O
queries	O
must	O
be	O
fixed	O
to	O
achieve	O
a	O
high	O
accuracy	B-Metric
of	O
the	O
SLU	B-Method
.	O
	
To	O
do	O
so	O
,	O
we	O
perform	O
a	O
3	B-Method
-	I-Method
fold	I-Method
cross	I-Method
validation	I-Method
of	O
the	O
NLU	B-Method
engine	O
on	O
this	O
dataset	O
.	O
	
This	O
yields	O
predicted	O
intents	O
and	O
slots	O
for	O
each	O
sentence	O
in	O
the	O
dataset	O
.	O
	
By	O
repeating	O
this	O
procedure	O
several	O
times	O
,	O
we	O
obtain	O
several	O
predictions	O
for	O
each	O
sentence	O
.	O
	
We	O
then	O
apply	O
majority	B-Method
voting	I-Method
on	O
these	O
predictions	O
to	O
detect	O
missing	O
slots	O
and	O
wrong	O
intents	O
.	O
	
Slots	O
may	O
therefore	O
be	O
extended	O
	
–	O
e.g.	O
(	O
bedroom	O
)[	O
room	O
]	O
	
(	O
guest	O
bedroom	O
)[	O
room	O
]	O
in	O
the	O
previous	O
example	O
	
–	O
or	O
added	O
–	O
	
(	O
60	O
)[	O
intensity	O
]	O
–	O
and	O
ill	O
-	O
formed	O
queries	O
(	O
with	O
regard	O
to	O
spelling	O
or	O
intent	O
)	O
are	O
filtered	O
-	O
out	O
.	O
	
subsection	O
:	O
Evaluation	O
	
We	O
illustrate	O
the	O
impact	O
of	O
data	B-Task
generation	I-Task
on	O
the	O
SLU	B-Method
performance	O
on	O
the	O
specific	O
case	O
of	O
the	O
slot	B-Task
-	I-Task
filling	I-Task
task	I-Task
in	O
the	O
NLU	B-Method
component	O
.	O
	
The	O
same	O
in	O
-	O
house	O
open	O
dataset	O
of	O
over	O
16	O
K	O
crowdsourced	O
query	O
presented	O
in	O
Section	O
[	O
reference	O
]	O
is	O
used	O
.	O
	
Unsurprisingly	O
,	O
slot	B-Method
-	I-Method
filling	I-Method
performance	O
drastically	O
increases	O
with	O
the	O
number	O
of	O
training	O
samples	O
.	O
	
The	O
F1	B-Metric
-	I-Metric
scores	I-Metric
averaged	O
over	O
all	O
slots	O
are	O
computed	O
,	O
depending	O
on	O
the	O
number	O
of	O
training	O
queries	O
per	O
intent	O
.	O
	
An	O
NLU	B-Method
engine	O
has	O
been	O
trained	O
on	O
each	O
individual	O
intent	O
.	O
	
Training	O
queries	O
are	O
freely	O
available	O
on	O
GitHub	O
.	O
	
The	O
data	O
has	O
been	O
generated	O
with	O
our	O
data	B-Method
generation	I-Method
pipeline	I-Method
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
the	O
influence	O
of	O
the	O
number	O
of	O
training	O
samples	O
on	O
the	O
performance	O
of	O
the	O
slot	B-Task
-	I-Task
filling	I-Task
task	I-Task
of	O
the	O
NLU	B-Method
component	O
.	O
	
Compared	O
to	O
10	O
training	O
queries	O
,	O
the	O
gain	O
in	O
performance	O
with	O
500	O
queries	O
is	O
of	O
32	O
%	O
absolute	O
on	O
average	O
,	O
ranging	O
from	O
22	O
%	O
for	O
the	O
RateBook	B-Metric
intent	I-Metric
(	O
from	O
0.76	O
to	O
0.98	O
)	O
to	O
44	O
%	O
for	O
the	O
GetWeather	O
intent	O
(	O
from	O
0.44	O
to	O
0.88	O
)	O
.	O
	
This	O
gain	O
indeed	O
strongly	O
depends	O
on	O
the	O
intent	O
’s	O
complexity	O
,	O
which	O
is	O
mainly	O
defined	O
by	O
its	O
entities	O
(	O
number	O
of	O
entities	O
,	O
built	O
-	O
in	O
or	O
custom	O
,	O
number	O
of	O
entity	O
values	O
,	O
etc	O
.	O
)	O
.	O
	
While	O
a	O
few	O
tens	O
of	O
training	O
queries	O
might	O
suffice	O
for	O
some	O
simple	O
use	O
cases	O
(	O
such	O
as	O
RateBook	O
)	O
,	O
more	O
complicated	O
intents	O
with	O
larger	O
sets	O
of	O
entity	O
values	O
(	O
PlayMusic	O
for	O
instance	O
)	O
require	O
larger	O
training	O
datasets	O
.	O
	
While	O
it	O
is	O
easy	O
to	O
manually	O
generate	O
up	O
to	O
50	O
queries	O
,	O
being	O
able	O
to	O
come	O
up	O
with	O
hundreds	O
or	O
thousands	O
of	O
diverse	O
formulations	O
of	O
the	O
same	O
intent	O
is	O
nearly	O
impossible	O
.	O
	
For	O
private	B-Task
-	I-Task
by	I-Task
-	I-Task
design	I-Task
assistants	I-Task
that	O
do	O
not	O
gather	O
user	O
queries	O
,	O
the	O
ability	O
to	O
generate	O
enough	O
queries	O
is	O
key	O
to	O
training	O
efficient	O
machine	B-Method
learning	I-Method
models	I-Method
.	O
	
Moreover	O
,	O
being	O
able	O
to	O
generate	O
training	O
data	O
allows	O
us	O
to	O
validate	O
the	O
performance	O
of	O
our	O
models	O
before	O
deploying	O
them	O
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
paper	O
,	O
we	O
have	O
described	O
the	O
design	O
of	O
the	O
Snips	B-Method
Voice	I-Method
Platform	I-Method
,	O
a	O
Spoken	B-Method
Language	I-Method
Understanding	I-Method
solution	I-Method
that	O
can	O
be	O
embedded	O
in	O
small	O
devices	O
and	O
runs	O
entirely	O
offline	O
.	O
	
In	O
compliance	O
with	O
the	O
privacy	O
-	O
by	O
-	O
design	O
principle	O
,	O
assistants	O
created	O
through	O
the	O
Snips	B-Method
Voice	I-Method
Platform	I-Method
never	O
send	O
user	O
queries	O
to	O
the	O
cloud	O
and	O
offer	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
.	O
	
Focusing	O
on	O
the	O
Automatic	B-Task
Speech	I-Task
Recognition	I-Task
and	O
Natural	B-Method
Language	I-Method
Understanding	I-Method
engines	O
,	O
we	O
have	O
described	O
the	O
challenges	O
of	O
embedding	O
high	O
-	O
performance	O
machine	B-Method
learning	I-Method
models	I-Method
on	O
small	B-Task
IoT	I-Task
devices	I-Task
.	O
	
On	O
the	O
acoustic	B-Task
modeling	I-Task
side	O
,	O
we	O
have	O
shown	O
how	O
small	B-Method
-	I-Method
sized	I-Method
neural	I-Method
networks	I-Method
can	O
be	O
trained	O
that	O
enjoy	O
near	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
accuracy	B-Metric
while	O
running	O
in	O
real	O
-	O
time	O
on	O
small	O
devices	O
.	O
	
On	O
the	O
language	B-Task
modeling	I-Task
side	O
,	O
we	O
have	O
described	O
how	O
to	O
train	O
the	O
language	B-Method
model	I-Method
of	O
the	O
ASR	B-Method
and	O
the	O
NLU	B-Method
in	O
a	O
consistent	O
way	O
,	O
efficiently	O
specializing	O
them	O
to	O
a	O
particular	O
use	O
case	O
.	O
	
We	O
have	O
also	O
demonstrated	O
the	O
accuracy	B-Metric
of	O
the	O
resulting	O
SLU	B-Method
engine	O
on	O
real	O
-	O
world	O
assistants	O
.	O
	
Finally	O
,	O
we	O
have	O
shown	O
how	O
sufficient	O
,	O
high	O
-	O
quality	O
training	O
data	O
can	O
be	O
obtained	O
without	O
compromising	O
user	O
privacy	O
through	O
a	O
combination	O
of	O
crowdsourcing	B-Method
and	O
machine	B-Method
learning	I-Method
.	O
	
We	O
hope	O
that	O
the	O
present	O
paper	O
can	O
contribute	O
to	O
a	O
larger	O
effort	O
towards	O
ever	O
more	O
private	O
and	O
ubiquitous	B-Task
artificial	I-Task
intelligence	I-Task
.	O
	
Future	O
research	O
directions	O
will	O
include	O
private	B-Task
analytics	I-Task
,	O
allowing	O
to	O
receive	O
privacy	O
-	O
preserving	O
feedback	O
from	O
assistant	O
usage	O
,	O
and	O
federated	B-Method
learning	I-Method
,	O
as	O
a	O
complement	O
to	O
data	B-Task
generation	I-Task
.	O
	
section	O
:	O
Acknowledgments	O
	
All	O
of	O
the	O
work	O
presented	O
here	O
has	O
been	O
done	O
closely	O
together	O
with	O
the	O
engineering	O
teams	O
at	O
Snips	B-Method
.	O
	
We	O
are	O
grateful	O
to	O
the	O
crowd	O
of	O
contributors	O
who	O
regularly	O
work	O
with	O
us	O
on	O
the	O
data	B-Task
generation	I-Task
pipeline	I-Task
.	O
	
We	O
are	O
indebted	O
to	O
the	O
community	O
of	O
users	O
of	O
the	O
Snips	B-Method
Voice	I-Method
Platform	I-Method
for	O
valuable	O
feedback	O
and	O
contributions	O
.	O
	
section	O
:	O
Appendix	O
:	O
NLU	B-Method
benchmark	O
on	O
an	O
in	O
-	O
house	O
dataset	O
	
bibliography	O
:	O
References	O
	
CornerNet	B-Method
:	O
Detecting	B-Task
Objects	I-Task
as	O
Paired	O
Keypoints	O
	
section	O
:	O
	
Abstract	O
We	O
propose	O
CornerNet	B-Method
,	O
a	O
new	O
approach	O
to	O
object	B-Task
detection	I-Task
where	O
we	O
detect	O
an	O
object	O
bounding	O
box	O
as	O
a	O
pair	O
of	O
keypoints	O
,	O
the	O
top	O
-	O
left	O
corner	O
and	O
the	O
bottom	O
-	O
right	O
corner	O
,	O
using	O
a	O
single	O
convolution	B-Method
neural	I-Method
network	I-Method
.	O
	
By	O
detecting	O
objects	O
as	O
paired	O
keypoints	O
,	O
we	O
eliminate	O
the	O
need	O
for	O
designing	O
a	O
set	O
of	O
anchor	O
boxes	O
commonly	O
used	O
in	O
prior	O
single	B-Method
-	I-Method
stage	I-Method
detectors	I-Method
.	O
	
In	O
addition	O
to	O
our	O
novel	O
formulation	O
,	O
we	O
introduce	O
corner	B-Method
pooling	I-Method
,	O
a	O
new	O
type	O
of	O
pooling	B-Method
layer	I-Method
that	O
helps	O
the	O
network	O
better	O
localize	O
corners	O
.	O
	
Experiments	O
show	O
that	O
CornerNet	B-Method
achieves	O
a	O
42.2	O
%	O
AP	B-Metric
on	O
MS	B-Material
COCO	I-Material
,	O
outperforming	O
all	O
existing	O
one	B-Method
-	I-Method
stage	I-Method
detectors	I-Method
.	O
	
section	O
:	O
Introduction	O
	
Object	B-Method
detectors	I-Method
based	O
on	O
convolutional	B-Method
neural	I-Method
networks	I-Method
(	O
ConvNets	B-Method
)	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
have	O
achieved	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
various	O
challenging	O
benchmarks	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
A	O
common	O
component	O
of	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
approaches	O
is	O
anchor	O
boxes	O
[	O
reference	O
][	O
reference	O
]	O
,	O
which	O
are	O
boxes	O
of	O
various	O
sizes	O
and	O
aspect	O
ratios	O
that	O
serve	O
as	O
detection	O
candidates	O
.	O
	
Anchor	O
boxes	O
are	O
extensively	O
used	O
in	O
one	B-Method
-	I-Method
stage	I-Method
detectors	I-Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
,	O
which	O
can	O
achieve	O
results	O
highly	O
competitive	O
with	O
two	O
-	O
stage	B-Method
detectors	I-Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
while	O
being	O
more	O
efficient	O
.	O
	
One	O
-	O
stage	O
detectors	O
place	O
anchor	O
boxes	O
densely	O
over	O
an	O
image	O
and	O
generate	O
final	O
box	O
predictions	O
by	O
scoring	O
anchor	O
boxes	O
and	O
refining	O
their	O
coordinates	O
through	O
regression	B-Method
.	O
	
But	O
the	O
use	O
of	O
anchor	O
boxes	O
has	O
two	O
drawbacks	O
.	O
	
First	O
,	O
we	O
typically	O
need	O
a	O
very	O
large	O
set	O
of	O
anchor	O
boxes	O
,	O
e.g.	O
more	O
than	O
40k	O
in	O
DSSD	B-Method
and	O
more	O
than	O
100k	O
in	O
RetinaNet	O
.	O
	
This	O
is	O
because	O
the	O
detector	O
is	O
trained	O
to	O
classify	O
whether	O
each	O
anchor	O
box	O
sufficiently	O
overlaps	O
with	O
a	O
ground	O
truth	O
box	O
,	O
and	O
a	O
large	O
number	O
of	O
anchor	O
boxes	O
is	O
needed	O
to	O
ensure	O
sufficient	O
overlap	O
with	O
most	O
ground	O
truth	O
boxes	O
.	O
	
As	O
a	O
result	O
,	O
only	O
a	O
tiny	O
fraction	O
of	O
anchor	O
boxes	O
will	O
overlap	O
with	O
ground	O
truth	O
;	O
this	O
creates	O
a	O
huge	O
imbalance	O
between	O
positive	O
and	O
negative	O
anchor	O
boxes	O
and	O
slows	O
down	O
training	B-Task
.	O
	
Second	O
,	O
the	O
use	O
of	O
anchor	O
boxes	O
introduces	O
many	O
hyperparameters	O
and	O
design	O
choices	O
.	O
	
These	O
include	O
how	O
many	O
boxes	O
,	O
what	O
sizes	O
,	O
and	O
what	O
aspect	O
ratios	O
.	O
	
Such	O
choices	O
have	O
largely	O
been	O
made	O
via	O
ad	B-Method
-	I-Method
hoc	I-Method
heuristics	I-Method
,	O
and	O
can	O
become	O
even	O
more	O
complicated	O
when	O
combined	O
with	O
multiscale	B-Method
architectures	I-Method
where	O
a	O
single	O
network	O
makes	O
separate	O
predictions	O
at	O
multiple	O
resolutions	O
,	O
with	O
each	O
scale	O
using	O
different	O
features	O
and	O
its	O
own	O
set	O
of	O
anchor	O
boxes	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
	
In	O
this	O
paper	O
we	O
introduce	O
CornerNet	B-Method
,	O
a	O
new	O
onestage	B-Method
approach	I-Method
to	O
object	B-Task
detection	I-Task
that	O
does	O
away	O
with	O
anchor	O
boxes	O
.	O
	
We	O
detect	O
an	O
object	O
as	O
a	O
pair	O
of	O
keypointsthe	O
top	O
-	O
left	O
corner	O
and	O
bottom	O
-	O
right	O
corner	O
of	O
the	O
bounding	O
box	O
.	O
	
We	O
use	O
a	O
single	O
convolutional	B-Method
network	I-Method
to	O
predict	O
a	O
heatmap	O
for	O
the	O
top	O
-	O
left	O
corners	O
of	O
all	O
instances	O
of	O
the	O
same	O
object	O
category	O
,	O
a	O
heatmap	O
for	O
all	O
bottomright	O
corners	O
,	O
and	O
an	O
embedding	O
vector	O
for	O
each	O
detected	O
corner	O
.	O
	
The	O
embeddings	O
serve	O
to	O
group	O
a	O
pair	O
of	O
corners	O
that	O
belong	O
to	O
the	O
same	O
object	O
-	O
the	O
network	O
is	O
trained	O
to	O
predict	O
similar	O
embeddings	O
for	O
them	O
.	O
	
Our	O
ap	O
-	O
	
section	O
:	O
ConvNet	B-Method
Embeddings	I-Method
Heatmaps	I-Method
	
Top	O
-	O
Left	O
Corners	O
	
Bottom	O
-	O
Right	O
Corners	O
	
Fig	O
.	O
	
1	O
	
We	O
detect	O
an	O
object	O
as	O
a	O
pair	O
of	O
bounding	O
box	O
corners	O
grouped	O
together	O
.	O
	
A	O
convolutional	B-Method
network	I-Method
outputs	O
a	O
heatmap	O
for	O
all	O
top	O
-	O
left	O
corners	O
,	O
a	O
heatmap	O
for	O
all	O
bottom	O
-	O
right	O
corners	O
,	O
and	O
an	O
embedding	O
vector	O
for	O
each	O
detected	O
corner	O
.	O
	
The	O
network	O
is	O
trained	O
to	O
predict	O
similar	O
embeddings	O
for	O
corners	O
that	O
belong	O
to	O
the	O
same	O
object	O
.	O
	
proach	O
greatly	O
simplifies	O
the	O
output	O
of	O
the	O
network	O
and	O
eliminates	O
the	O
need	O
for	O
designing	O
anchor	O
boxes	O
.	O
	
Our	O
approach	O
is	O
inspired	O
by	O
the	O
associative	B-Method
embedding	I-Method
method	I-Method
proposed	O
by	O
,	O
who	O
detect	O
and	O
group	B-Task
keypoints	I-Task
in	O
the	O
context	O
of	O
multiperson	B-Task
human	I-Task
-	I-Task
pose	I-Task
estimation	I-Task
.	O
	
Fig	O
.	O
	
1	O
illustrates	O
the	O
overall	O
pipeline	O
of	O
our	O
approach	O
.	O
	
Another	O
novel	O
component	O
of	O
CornerNet	B-Method
is	O
corner	B-Method
pooling	I-Method
,	O
a	O
new	O
type	O
of	O
pooling	B-Method
layer	I-Method
that	O
helps	O
a	O
convolutional	B-Method
network	I-Method
better	O
localize	O
corners	O
of	O
bounding	O
boxes	O
.	O
	
A	O
corner	O
of	O
a	O
bounding	O
box	O
is	O
often	O
outside	O
the	O
object	O
-	O
consider	O
the	O
case	O
of	O
a	O
circle	O
as	O
well	O
as	O
the	O
examples	O
in	O
Fig	O
.	O
2	O
.	O
	
In	O
such	O
cases	O
a	O
corner	O
can	O
not	O
be	O
localized	O
based	O
on	O
local	O
evidence	O
.	O
	
Instead	O
,	O
to	O
determine	O
whether	O
there	O
is	O
a	O
top	O
-	O
left	O
corner	O
at	O
a	O
pixel	O
location	O
,	O
we	O
need	O
to	O
look	O
horizontally	O
towards	O
the	O
right	O
for	O
the	O
topmost	O
boundary	O
of	O
the	O
object	O
,	O
and	O
look	O
vertically	O
towards	O
the	O
bottom	O
for	O
the	O
leftmost	O
boundary	O
.	O
	
This	O
motivates	O
our	O
corner	B-Method
pooling	I-Method
layer	O
:	O
it	O
takes	O
in	O
two	O
feature	O
maps	O
;	O
at	O
each	O
pixel	O
location	O
it	O
max	O
-	O
pools	O
all	O
feature	O
vectors	O
to	O
the	O
right	O
from	O
the	O
first	O
feature	O
map	O
,	O
maxpools	O
all	O
feature	O
vectors	O
directly	O
below	O
from	O
the	O
second	O
feature	O
map	O
,	O
and	O
then	O
adds	O
the	O
two	O
pooled	O
results	O
together	O
.	O
	
An	O
example	O
is	O
shown	O
in	O
Fig	O
.	O
3	O
.	O
	
We	O
hypothesize	O
two	O
reasons	O
why	O
detecting	B-Task
corners	I-Task
would	O
work	O
better	O
than	O
bounding	O
box	O
centers	O
or	O
proposals	O
.	O
	
First	O
,	O
the	O
center	O
of	O
a	O
box	O
can	O
be	O
harder	O
to	O
localize	O
because	O
it	O
depends	O
on	O
all	O
4	O
sides	O
of	O
the	O
object	O
,	O
whereas	O
locating	O
a	O
corner	O
depends	O
on	O
2	O
sides	O
and	O
is	O
thus	O
easier	O
,	O
and	O
even	O
more	O
so	O
with	O
corner	B-Method
pooling	I-Method
,	O
which	O
encodes	O
some	O
explicit	O
prior	O
knowledge	O
about	O
the	O
definition	O
of	O
corners	O
.	O
	
Second	O
,	O
corners	O
provide	O
a	O
more	O
efficient	O
way	O
of	O
densely	O
discretizing	O
the	O
space	O
of	O
boxes	O
:	O
we	O
just	O
need	O
O	O
(	O
wh	O
)	O
	
corners	O
to	O
represent	O
O	O
(	O
w	O
2	O
h	O
2	O
)	O
possible	O
anchor	O
boxes	O
.	O
	
We	O
demonstrate	O
the	O
effectiveness	O
of	O
CornerNet	B-Method
on	O
MS	B-Material
COCO	I-Material
	
[	O
reference	O
]	O
.	O
CornerNet	B-Method
achieves	O
a	O
42.2	O
%	O
AP	B-Metric
,	O
outperforming	O
all	O
existing	O
one	B-Method
-	I-Method
stage	I-Method
detectors	I-Method
.	O
	
In	O
addition	O
,	O
through	O
ablation	O
studies	O
we	O
show	O
that	O
corner	B-Method
pooling	I-Method
is	O
critical	O
to	O
the	O
superior	O
performance	O
of	O
CornerNet	B-Method
.	O
	
Code	O
is	O
available	O
at	O
https:	O
//	O
github.com	O
/	O
princeton	O
-	O
vl	O
/	O
CornerNet	B-Method
.	O
	
section	O
:	O
Related	O
Works	O
	
section	O
:	O
Two	O
-	O
stage	O
object	B-Method
detectors	I-Method
	
Two	O
-	O
stage	O
approach	O
was	O
first	O
introduced	O
and	O
popularized	O
by	O
R	B-Method
-	I-Method
CNN	I-Method
	
[	O
reference	O
]	O
.	O
Two	O
-	O
stage	B-Method
detectors	I-Method
generate	O
a	O
sparse	O
set	O
of	O
regions	O
of	O
interest	O
(	O
RoIs	O
)	O
and	O
classify	O
each	O
of	O
them	O
by	O
a	O
network	O
.	O
	
R	B-Method
-	I-Method
CNN	I-Method
generates	O
RoIs	B-Method
using	O
a	O
low	B-Method
level	I-Method
vision	I-Method
algorithm	I-Method
	
[	O
reference	O
][	O
reference	O
]	O
.	O
	
Each	O
region	O
is	O
then	O
extracted	O
from	O
the	O
image	O
and	O
processed	O
by	O
a	O
ConvNet	B-Method
independently	O
,	O
which	O
creates	O
lots	O
of	O
redundant	O
computations	O
.	O
	
Later	O
,	O
SPP	B-Method
[	O
reference	O
]	O
and	O
Fast	B-Method
-	I-Method
RCNN	I-Method
[	O
reference	O
]	O
improve	O
R	B-Method
-	I-Method
CNN	I-Method
by	O
designing	O
a	O
special	O
pooling	B-Method
layer	I-Method
that	O
pools	O
each	O
region	O
from	O
feature	O
maps	O
instead	O
.	O
	
However	O
,	O
both	O
still	O
rely	O
on	O
separate	O
proposal	B-Method
algorithms	I-Method
and	O
can	O
not	O
be	O
trained	O
end	O
-	O
to	O
-	O
end	O
.	O
	
Faster	B-Method
-	I-Method
RCNN	I-Method
[	O
reference	O
]	O
does	O
away	O
low	B-Method
level	I-Method
proposal	I-Method
algorithms	I-Method
by	O
introducing	O
a	O
region	B-Method
proposal	I-Method
network	I-Method
(	O
RPN	B-Method
)	O
,	O
which	O
generates	O
proposals	O
from	O
a	O
set	O
of	O
pre	O
-	O
determined	O
candidate	O
boxes	O
,	O
usually	O
known	O
as	O
anchor	O
boxes	O
.	O
	
This	O
not	O
only	O
makes	O
the	O
detectors	O
more	O
efficient	O
but	O
also	O
allows	O
the	O
detectors	O
to	O
be	O
trained	O
end	O
-	O
toend	O
.	O
	
R	B-Method
-	I-Method
FCN	I-Method
[	O
reference	O
]	O
further	O
improves	O
the	O
efficiency	O
of	O
Faster	B-Method
-	I-Method
RCNN	I-Method
by	O
replacing	O
the	O
fully	B-Method
connected	I-Method
sub	I-Method
-	I-Method
detection	I-Method
network	I-Method
with	O
a	O
fully	B-Method
convolutional	I-Method
subdetection	I-Method
network	I-Method
.	O
	
Other	O
works	O
focus	O
on	O
incorporating	O
sub	O
-	O
category	O
information	O
[	O
reference	O
]	O
,	O
generating	O
object	O
proposals	O
at	O
multiple	O
scales	O
with	O
more	O
contextual	O
information	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
,	O
selecting	O
better	O
features	O
[	O
reference	O
]	O
,	O
improving	O
speed	B-Metric
,	O
cascade	B-Method
procedure	I-Method
[	O
reference	O
]	O
and	O
better	O
training	O
procedure	O
.	O
	
section	O
:	O
One	O
-	O
stage	B-Method
object	I-Method
detectors	I-Method
	
On	O
the	O
other	O
hand	O
,	O
YOLO	O
and	O
SSD	B-Method
[	O
reference	O
]	O
have	O
popularized	O
the	O
one	B-Method
-	I-Method
stage	I-Method
approach	I-Method
,	O
which	O
removes	O
the	O
RoI	B-Method
pooling	I-Method
step	I-Method
and	O
detects	O
objects	O
in	O
a	O
single	O
network	O
.	O
	
One	B-Method
-	I-Method
stage	I-Method
detectors	I-Method
are	O
usually	O
more	O
computationally	O
efficient	O
than	O
twostage	B-Method
detectors	I-Method
while	O
maintaining	O
competitive	O
performance	O
on	O
different	O
challenging	O
benchmarks	O
.	O
	
SSD	B-Method
places	O
anchor	O
boxes	O
densely	O
over	O
feature	O
maps	O
from	O
multiple	O
scales	O
,	O
directly	O
classifies	O
and	O
refines	O
each	O
anchor	O
box	O
.	O
	
YOLO	O
predicts	O
bounding	O
box	O
coordinates	O
directly	O
from	O
an	O
image	O
,	O
and	O
is	O
later	O
improved	O
in	O
YOLO9000	O
by	O
switching	O
to	O
anchor	O
boxes	O
.	O
	
DSSD	B-Method
and	O
RON	B-Method
[	O
reference	O
]	O
adopt	O
networks	O
similar	O
to	O
the	O
hourglass	B-Method
network	I-Method
[	O
reference	O
]	O
,	O
enabling	O
them	O
to	O
combine	O
low	O
-	O
level	O
and	O
high	O
-	O
level	O
features	O
via	O
skip	O
connections	O
to	O
predict	O
bounding	O
boxes	O
more	O
accurately	O
.	O
	
However	O
,	O
these	O
one	B-Method
-	I-Method
stage	I-Method
detectors	I-Method
are	O
still	O
outperformed	O
by	O
the	O
two	O
-	O
stage	B-Method
detectors	I-Method
until	O
the	O
introduction	O
of	O
RetinaNet	O
.	O
	
In	O
,	O
the	O
authors	O
suggest	O
that	O
the	O
dense	O
anchor	O
boxes	O
create	O
a	O
huge	O
imbalance	O
between	O
positive	O
and	O
negative	O
anchor	O
boxes	O
during	O
training	O
.	O
	
This	O
imbalance	O
causes	O
the	O
training	O
to	O
be	O
inefficient	O
and	O
hence	O
the	O
performance	O
to	O
be	O
suboptimal	O
.	O
	
They	O
propose	O
a	O
new	O
loss	O
,	O
Focal	B-Method
Loss	I-Method
,	O
to	O
dynamically	O
adjust	O
the	O
weights	O
of	O
each	O
anchor	O
box	O
and	O
show	O
that	O
their	O
onestage	B-Method
detector	I-Method
can	O
outperform	O
the	O
two	O
-	O
stage	B-Method
detectors	I-Method
.	O
	
RefineDet	O
proposes	O
to	O
filter	O
the	O
an	O
-	O
chor	O
boxes	O
to	O
reduce	O
the	O
number	O
of	O
negative	O
boxes	O
,	O
and	O
to	O
coarsely	O
adjust	O
the	O
anchor	O
boxes	O
.	O
	
DeNet	O
[	O
reference	O
]	O
)	O
is	O
a	O
two	O
-	O
stage	B-Method
detector	I-Method
which	O
generates	O
RoIs	O
without	O
using	O
anchor	O
boxes	O
.	O
	
It	O
first	O
determines	O
how	O
likely	O
each	O
location	O
belongs	O
to	O
either	O
the	O
top	O
-	O
left	O
,	O
top	O
-	O
right	O
,	O
bottomleft	O
or	O
bottom	O
-	O
right	O
corner	O
of	O
a	O
bounding	O
box	O
.	O
	
It	O
then	O
generates	O
RoIs	O
by	O
enumerating	O
all	O
possible	O
corner	O
combinations	O
,	O
and	O
follows	O
the	O
standard	O
two	O
-	O
stage	O
approach	O
to	O
classify	O
each	O
RoI.	O
Our	O
approach	O
is	O
very	O
different	O
from	O
DeNet	O
.	O
	
First	O
,	O
DeNet	B-Method
does	O
not	O
identify	O
if	O
two	O
corners	O
are	O
from	O
the	O
same	O
objects	O
and	O
relies	O
on	O
a	O
sub	B-Method
-	I-Method
detection	I-Method
network	I-Method
to	O
reject	O
poor	O
RoIs	O
.	O
	
In	O
contrast	O
,	O
our	O
approach	O
is	O
a	O
one	O
-	O
stage	B-Method
approach	I-Method
which	O
detects	O
and	O
groups	O
the	O
corners	O
using	O
a	O
single	O
ConvNet	B-Method
.	O
	
Second	O
,	O
DeNet	O
selects	O
features	O
at	O
manually	O
determined	O
locations	O
relative	O
to	O
a	O
region	O
for	O
classification	B-Task
,	O
while	O
our	O
approach	O
does	O
not	O
require	O
any	O
feature	B-Method
selection	I-Method
step	I-Method
.	O
	
Third	O
,	O
we	O
introduce	O
corner	B-Method
pooling	I-Method
,	O
a	O
novel	O
type	O
of	O
layer	O
to	O
enhance	O
corner	B-Task
detection	I-Task
.	O
	
Point	B-Method
Linking	I-Method
Network	I-Method
(	O
PLN	B-Method
)	O
is	O
an	O
one	B-Method
-	I-Method
stage	I-Method
detector	I-Method
without	O
anchor	B-Method
boxes	I-Method
.	O
	
It	O
first	O
predicts	O
the	O
locations	O
of	O
the	O
four	O
corners	O
and	O
the	O
center	O
of	O
a	O
bounding	O
box	O
.	O
	
Then	O
,	O
at	O
each	O
corner	O
location	O
,	O
it	O
predicts	O
how	O
likely	O
each	O
pixel	O
location	O
in	O
the	O
image	O
is	O
the	O
center	O
.	O
	
Similarly	O
,	O
at	O
the	O
center	O
location	O
,	O
it	O
predicts	O
how	O
likely	O
each	O
pixel	O
location	O
belongs	O
to	O
either	O
the	O
top	O
-	O
left	O
,	O
top	O
-	O
right	O
,	O
bottom	O
-	O
left	O
or	O
bottom	O
-	O
right	O
corner	O
.	O
	
It	O
combines	O
the	O
predictions	O
from	O
each	O
corner	O
and	O
center	O
pair	O
to	O
generate	O
a	O
bounding	O
box	O
.	O
	
Finally	O
,	O
it	O
merges	O
the	O
four	O
bounding	O
boxes	O
to	O
give	O
a	O
bounding	O
box	O
.	O
	
CornerNet	B-Method
is	O
very	O
different	O
from	O
PLN	B-Method
.	O
	
First	O
,	O
CornerNet	B-Method
groups	O
the	O
corners	O
by	O
predicting	O
embedding	O
vectors	O
,	O
while	O
PLN	B-Method
groups	O
the	O
corner	O
and	O
center	O
by	O
predicting	O
pixel	O
locations	O
.	O
	
Second	O
,	O
CornerNet	B-Method
uses	O
corner	B-Method
pooling	I-Method
to	O
better	O
localize	O
the	O
corners	O
.	O
	
Our	O
approach	O
is	O
inspired	O
by	O
on	O
Associative	B-Task
Embedding	I-Task
in	O
the	O
context	O
of	O
multi	B-Task
-	I-Task
person	I-Task
pose	I-Task
estimation	I-Task
.	O
	
Newell	O
et	O
al	O
.	O
propose	O
an	O
approach	O
that	O
detects	O
and	O
groups	O
human	O
joints	O
in	O
a	O
single	O
network	O
.	O
	
In	O
their	O
approach	O
each	O
detected	O
human	O
joint	O
has	O
an	O
embedding	O
vector	O
.	O
	
The	O
joints	O
are	O
grouped	O
based	O
on	O
the	O
distances	O
between	O
their	O
embeddings	O
.	O
	
To	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
we	O
are	O
the	O
first	O
to	O
formulate	O
the	O
task	O
of	O
object	B-Task
detection	I-Task
as	O
a	O
task	O
of	O
detecting	B-Task
and	I-Task
grouping	I-Task
corners	I-Task
with	O
embeddings	B-Task
.	O
	
Another	O
novelty	O
of	O
ours	O
is	O
the	O
corner	B-Method
pooling	I-Method
layers	O
that	O
help	O
better	O
localize	O
the	O
corners	O
.	O
	
We	O
also	O
significantly	O
modify	O
the	O
hourglass	B-Method
architecture	I-Method
and	O
add	O
our	O
novel	O
variant	O
of	O
focal	B-Method
loss	I-Method
to	O
help	O
better	O
train	O
the	O
network	O
.	O
	
section	O
:	O
CornerNet	B-Method
	
section	O
:	O
Overview	O
	
In	O
CornerNet	B-Method
,	O
we	O
detect	O
an	O
object	O
as	O
a	O
pair	O
of	O
keypointsthe	O
top	O
-	O
left	O
corner	O
and	O
bottom	O
-	O
right	O
corner	O
of	O
the	O
bounding	O
box	O
.	O
	
A	O
convolutional	B-Method
network	I-Method
predicts	O
two	O
sets	O
of	O
heatmaps	O
to	O
represent	O
the	O
locations	O
of	O
corners	O
of	O
different	O
object	O
categories	O
,	O
one	O
set	O
for	O
the	O
top	O
-	O
left	O
corners	O
and	O
the	O
other	O
for	O
the	O
bottom	O
-	O
right	O
corners	O
.	O
	
The	O
network	O
also	O
predicts	O
an	O
embedding	O
vector	O
for	O
each	O
detected	O
corner	O
such	O
that	O
the	O
distance	O
between	O
the	O
embeddings	O
of	O
two	O
corners	O
from	O
the	O
same	O
object	O
is	O
small	O
.	O
	
To	O
produce	O
tighter	O
bounding	O
boxes	O
,	O
the	O
network	O
also	O
predicts	O
offsets	O
to	O
slightly	O
adjust	O
the	O
locations	O
of	O
the	O
corners	O
.	O
	
With	O
the	O
predicted	O
heatmaps	O
,	O
embeddings	O
and	O
offsets	O
,	O
we	O
apply	O
a	O
simple	O
post	B-Method
-	I-Method
processing	I-Method
algorithm	I-Method
to	O
obtain	O
the	O
final	O
bounding	O
boxes	O
.	O
	
Fig	O
.	O
	
4	O
provides	O
an	O
overview	O
of	O
CornerNet	B-Method
.	O
	
We	O
use	O
the	O
hourglass	B-Method
network	I-Method
[	O
reference	O
]	O
as	O
the	O
backbone	B-Method
network	I-Method
of	O
CornerNet	B-Method
.	O
	
The	O
hourglass	B-Method
network	I-Method
is	O
followed	O
by	O
two	O
prediction	B-Method
modules	I-Method
.	O
	
One	O
module	O
is	O
for	O
the	O
top	O
-	O
left	O
corners	O
,	O
while	O
the	O
other	O
one	O
is	O
for	O
the	O
bottomright	O
corners	O
.	O
	
Each	O
module	O
has	O
its	O
own	O
corner	B-Method
pooling	I-Method
module	O
to	O
pool	O
features	O
from	O
the	O
hourglass	B-Method
network	I-Method
before	O
predicting	O
the	O
heatmaps	O
,	O
embeddings	O
and	O
offsets	O
.	O
	
Unlike	O
many	O
other	O
object	B-Method
detectors	I-Method
,	O
we	O
do	O
not	O
use	O
features	O
from	O
different	O
scales	O
to	O
detect	O
objects	O
of	O
different	O
sizes	O
.	O
	
We	O
only	O
apply	O
both	O
modules	O
to	O
the	O
output	O
of	O
the	O
hourglass	B-Method
network	I-Method
.	O
	
section	O
:	O
Detecting	B-Task
Corners	I-Task
	
We	O
predict	O
two	O
sets	O
of	O
heatmaps	B-Method
,	O
one	O
for	O
top	O
-	O
left	O
corners	O
and	O
one	O
for	O
bottom	O
-	O
right	O
corners	O
.	O
	
Each	O
set	O
of	O
heatmaps	O
has	O
C	O
channels	O
,	O
where	O
C	O
is	O
the	O
number	O
of	O
categories	O
,	O
and	O
is	O
of	O
size	O
H	O
×	O
W	O
.	O
	
There	O
is	O
no	O
background	O
channel	O
.	O
	
Each	O
channel	O
is	O
a	O
binary	O
mask	O
indicating	O
the	O
locations	O
of	O
the	O
corners	O
for	O
a	O
class	O
.	O
	
For	O
each	O
corner	O
,	O
there	O
is	O
one	O
ground	O
-	O
truth	O
positive	O
location	O
,	O
and	O
all	O
other	O
locations	O
are	O
negative	O
.	O
	
During	O
training	B-Task
,	O
instead	O
of	O
equally	O
penalizing	O
negative	O
locations	O
,	O
we	O
reduce	O
the	O
penalty	O
given	O
to	O
negative	O
locations	O
within	O
a	O
radius	O
of	O
the	O
positive	O
location	O
.	O
	
This	O
is	O
because	O
a	O
pair	O
of	O
false	O
corner	O
detections	O
,	O
if	O
they	O
are	O
close	O
to	O
their	O
respective	O
ground	O
truth	O
locations	O
,	O
can	O
still	O
produce	O
a	O
box	O
that	O
sufficiently	O
overlaps	O
the	O
ground	O
-	O
truth	O
box	O
(	O
Fig	O
.	O
5	O
)	O
.	O
	
We	O
determine	O
the	O
radius	O
by	O
the	O
size	O
of	O
an	O
object	O
by	O
ensuring	O
that	O
a	O
pair	O
of	O
points	O
within	O
the	O
radius	O
would	O
generate	O
a	O
bounding	O
box	O
with	O
at	O
least	O
t	O
IoU	O
with	O
the	O
ground	O
-	O
truth	O
annotation	O
(	O
we	O
set	O
t	O
to	O
0.3	O
in	O
all	O
experiments	O
)	O
.	O
	
Given	O
the	O
radius	O
,	O
the	O
amount	O
of	O
penalty	O
reduction	O
is	O
given	O
by	O
an	O
unnormalized	B-Method
2D	I-Method
Gaussian	I-Method
,	O
Fig	O
.	O
4	O
Overview	O
of	O
CornerNet	B-Method
.	O
	
The	O
backbone	B-Method
network	I-Method
is	O
followed	O
by	O
two	O
prediction	B-Method
modules	I-Method
,	O
one	O
for	O
the	O
top	O
-	O
left	O
corners	O
and	O
the	O
other	O
for	O
the	O
bottom	O
-	O
right	O
corners	O
.	O
	
Using	O
the	O
predictions	O
from	O
both	O
modules	O
,	O
we	O
locate	O
and	O
group	O
the	O
corners	O
.	O
	
e	O
−	O
x	O
2	O
+	O
y	O
2	O
2σ	O
2	O
,	O
whose	O
center	O
is	O
at	O
the	O
positive	O
location	O
and	O
whose	O
σ	O
is	O
1	O
/	O
3	O
of	O
the	O
radius	O
.	O
	
Let	O
p	O
cij	O
be	O
the	O
score	O
at	O
location	O
(	O
i	O
,	O
j	O
)	O
for	O
class	O
c	O
in	O
the	O
predicted	O
heatmaps	O
,	O
and	O
let	O
y	B-Method
cij	I-Method
be	O
the	O
"	O
groundtruth	O
"	O
heatmap	O
augmented	O
with	O
the	O
unnormalized	B-Method
Gaussians	I-Method
.	O
	
We	O
design	O
a	O
variant	O
of	O
focal	B-Method
loss	I-Method
:	O
	
where	O
N	O
is	O
the	O
number	O
of	O
objects	O
in	O
an	O
image	O
,	O
and	O
α	O
and	O
β	O
are	O
the	O
hyper	O
-	O
parameters	O
which	O
control	O
the	O
contribution	O
of	O
each	O
point	O
(	O
we	O
set	O
α	O
to	O
2	O
and	O
β	O
to	O
4	O
in	O
all	O
experiments	O
)	O
.	O
	
With	O
the	O
Gaussian	O
bumps	O
encoded	O
in	O
y	B-Method
cij	I-Method
,	O
the	O
(	O
1	O
−	O
y	O
cij	O
)	O
term	O
reduces	O
the	O
penalty	O
around	O
the	O
ground	O
truth	O
locations	O
.	O
	
Many	O
networks	O
[	O
reference	O
]	O
)	O
involve	O
downsampling	B-Method
layers	I-Method
to	O
gather	O
global	O
information	O
and	O
to	O
reduce	O
memory	O
usage	O
.	O
	
When	O
they	O
are	O
applied	O
to	O
an	O
image	B-Task
fully	I-Task
convolutionally	I-Task
,	O
the	O
size	O
of	O
the	O
output	O
is	O
usually	O
smaller	O
than	O
the	O
image	O
.	O
	
Hence	O
,	O
a	O
location	O
(	O
x	O
,	O
y	O
)	O
in	O
the	O
image	O
is	O
mapped	O
to	O
the	O
location	O
x	O
n	O
,	O
y	O
n	O
in	O
the	O
heatmaps	O
,	O
where	O
n	O
is	O
the	O
downsampling	O
factor	O
.	O
	
When	O
we	O
remap	O
the	O
locations	O
from	O
the	O
heatmaps	O
to	O
the	O
input	O
image	O
,	O
some	O
precision	O
may	O
be	O
lost	O
,	O
which	O
can	O
greatly	O
affect	O
the	O
IoU	O
of	O
small	O
bounding	O
boxes	O
with	O
their	O
ground	O
truths	O
.	O
	
To	O
address	O
this	O
issue	O
we	O
predict	O
location	O
offsets	O
to	O
slightly	O
adjust	O
the	O
corner	O
locations	O
before	O
remapping	O
them	O
to	O
the	O
input	O
resolution	O
.	O
	
where	O
o	O
k	O
is	O
the	O
offset	O
,	O
x	O
k	O
and	O
y	O
	
k	O
are	O
the	O
x	O
and	O
y	O
coordinate	O
for	O
corner	O
	
k.	O
	
In	O
particular	O
,	O
we	O
predict	O
one	O
set	O
of	O
offsets	O
shared	O
by	O
the	O
top	O
-	O
left	O
corners	O
of	O
all	O
categories	O
,	O
and	O
another	O
set	O
shared	O
by	O
the	O
bottom	O
-	O
right	O
corners	O
.	O
	
For	O
training	B-Task
,	O
we	O
apply	O
the	O
smooth	O
L1	O
Loss	O
[	O
reference	O
]	O
at	O
ground	O
-	O
truth	O
corner	O
locations	O
:	O
	
section	O
:	O
Grouping	O
Corners	O
	
Multiple	O
objects	O
may	O
appear	O
in	O
an	O
image	O
,	O
and	O
thus	O
multiple	O
top	O
-	O
left	O
and	O
bottom	O
-	O
right	O
corners	O
may	O
be	O
detected	O
.	O
	
We	O
need	O
to	O
determine	O
if	O
a	O
pair	O
of	O
the	O
top	O
-	O
left	O
corner	O
and	O
bottom	O
-	O
right	O
corner	O
is	O
from	O
the	O
same	O
bounding	O
box	O
.	O
	
Our	O
approach	O
is	O
inspired	O
by	O
the	O
Associative	B-Method
Embedding	I-Method
method	I-Method
proposed	O
by	O
for	O
the	O
task	O
of	O
multi	B-Task
-	I-Task
person	I-Task
pose	I-Task
estimation	I-Task
.	O
	
Newell	O
et	O
al	O
.	O
	
detect	O
all	O
human	O
joints	O
and	O
generate	O
an	O
embedding	B-Method
for	O
each	O
detected	O
joint	O
.	O
	
They	O
group	O
the	O
joints	O
based	O
on	O
the	O
distances	O
between	O
the	O
embeddings	O
.	O
	
The	O
idea	O
of	O
associative	B-Method
embedding	I-Method
is	O
also	O
applicable	O
to	O
our	O
task	O
.	O
	
The	O
network	O
predicts	O
an	O
embedding	O
vector	O
for	O
each	O
detected	O
corner	O
such	O
that	O
if	O
a	O
top	O
-	O
left	O
corner	O
and	O
a	O
bottom	O
-	O
right	O
corner	O
belong	O
to	O
the	O
same	O
bounding	O
box	O
,	O
the	O
distance	O
between	O
their	O
embeddings	O
should	O
be	O
small	O
.	O
	
We	O
can	O
then	O
group	O
the	O
corners	O
based	O
on	O
the	O
distances	O
between	O
the	O
embeddings	O
of	O
the	O
top	O
-	O
left	O
and	O
bottom	O
-	O
right	O
corners	O
.	O
	
The	O
actual	O
values	O
of	O
the	O
embeddings	O
are	O
unimportant	O
.	O
	
Only	O
the	O
distances	O
between	O
the	O
embeddings	O
are	O
used	O
to	O
group	O
the	O
corners	O
.	O
	
We	O
follow	O
and	O
use	O
embeddings	O
of	O
1	O
dimension	O
.	O
	
Let	O
e	O
t	O
k	O
be	O
the	O
embedding	O
for	O
the	O
top	O
-	O
left	O
corner	O
of	O
object	O
k	O
and	O
e	O
b	O
k	O
for	O
the	O
bottom	O
-	O
right	O
corner	O
.	O
	
As	O
in	O
,	O
we	O
use	O
the	O
"	O
pull	O
"	O
loss	O
to	O
train	O
the	O
network	O
to	O
group	O
the	O
corners	O
and	O
the	O
"	O
push	O
"	O
loss	O
to	O
separate	O
the	O
corners	O
:	O
	
where	O
e	O
k	O
is	O
the	O
average	O
of	O
e	O
t	O
k	O
and	O
e	O
	
b	O
k	O
	
and	O
we	O
set	O
∆	O
to	O
be	O
1	O
in	O
all	O
our	O
experiments	O
.	O
	
Similar	O
to	O
the	O
offset	O
loss	O
,	O
we	O
only	O
apply	O
the	O
losses	O
at	O
the	O
ground	O
-	O
truth	O
corner	O
location	O
.	O
	
section	O
:	O
Corner	B-Method
Pooling	I-Method
	
As	O
shown	O
in	O
Fig	O
.	O
2	O
,	O
there	O
is	O
often	O
no	O
local	O
visual	O
evidence	O
for	O
the	O
presence	O
of	O
corners	O
.	O
	
To	O
determine	O
if	O
a	O
pixel	O
is	O
a	O
top	O
-	O
left	O
corner	O
,	O
we	O
need	O
to	O
look	O
horizontally	O
towards	O
the	O
right	O
for	O
the	O
topmost	O
boundary	O
of	O
an	O
object	O
and	O
vertically	O
towards	O
the	O
bottom	O
for	O
the	O
leftmost	O
boundary	O
.	O
	
We	O
thus	O
propose	O
corner	B-Method
pooling	I-Method
to	O
better	O
localize	O
the	O
corners	O
by	O
encoding	O
explicit	O
prior	O
knowledge	O
.	O
	
Suppose	O
we	O
want	O
to	O
determine	O
if	O
a	O
pixel	O
at	O
location	O
(	O
i	O
,	O
j	O
)	O
is	O
a	O
top	O
-	O
left	O
corner	O
.	O
	
Let	O
f	O
t	O
and	O
f	O
l	O
be	O
the	O
feature	O
maps	O
that	O
are	O
the	O
inputs	O
to	O
the	O
top	O
-	O
left	O
corner	B-Method
pooling	I-Method
layer	O
,	O
and	O
let	O
f	O
tij	O
and	O
f	O
lij	O
be	O
the	O
vectors	O
at	O
location	O
(	O
i	O
,	O
j	O
)	O
in	O
f	O
t	O
and	O
f	O
l	O
respectively	O
.	O
	
With	O
H	O
×	O
W	O
feature	O
maps	O
,	O
the	O
corner	B-Method
pooling	I-Method
layer	O
first	O
max	O
-	O
pools	O
all	O
feature	O
vectors	O
between	O
(	O
i	O
,	O
j	O
)	O
and	O
(	O
i	O
,	O
H	O
)	O
in	O
f	O
t	O
to	O
a	O
feature	O
vector	O
t	O
ij	O
,	O
and	O
max	O
-	O
pools	O
all	O
feature	O
vectors	O
between	O
(	O
i	O
,	O
j	O
)	O
and	O
(	O
W	O
,	O
j	O
)	O
in	O
f	O
l	O
to	O
a	O
feature	O
vector	O
l	O
ij	O
.	O
	
Finally	O
,	O
it	O
adds	O
t	O
ij	O
and	O
l	O
ij	O
together	O
.	O
	
This	O
computation	O
can	O
be	O
expressed	O
by	O
the	O
following	O
equations	O
:	O
	
where	O
we	O
apply	O
an	O
elementwise	B-Method
max	I-Method
operation	I-Method
.	O
	
Both	O
t	O
ij	O
and	O
l	O
ij	O
can	O
be	O
computed	O
efficiently	O
by	O
dynamic	B-Method
programming	I-Method
as	O
shown	O
Fig	O
.	O
8	O
.	O
	
We	O
define	O
bottom	O
-	O
right	O
corner	B-Method
pooling	I-Method
layer	O
in	O
a	O
similar	O
way	O
.	O
	
It	O
max	O
-	O
pools	O
all	O
feature	O
vectors	O
between	O
(	O
0	O
,	O
j	O
)	O
and	O
	
(	O
i	O
,	O
j	O
)	O
,	O
and	O
all	O
feature	O
vectors	O
between	O
(	O
i	O
,	O
0	O
)	O
and	O
(	O
i	O
,	O
j	O
)	O
before	O
adding	O
the	O
pooled	O
results	O
.	O
	
The	O
corner	B-Method
pooling	I-Method
layers	O
are	O
used	O
in	O
the	O
prediction	B-Method
modules	I-Method
to	O
predict	O
heatmaps	O
,	O
embeddings	O
and	O
offsets	O
.	O
	
The	O
architecture	O
of	O
the	O
prediction	B-Method
module	I-Method
is	O
shown	O
in	O
Fig	O
.	O
7	O
.	O
	
The	O
first	O
part	O
of	O
the	O
module	O
is	O
a	O
modified	O
version	O
of	O
the	O
residual	B-Method
block	I-Method
.	O
	
In	O
this	O
modified	O
residual	O
block	O
,	O
we	O
replace	O
the	O
first	O
3	B-Method
×	I-Method
3	I-Method
convolution	I-Method
module	I-Method
with	O
a	O
corner	B-Method
pooling	I-Method
module	O
,	O
which	O
first	O
processes	O
the	O
features	O
from	O
the	O
backbone	B-Method
network	I-Method
by	O
two	O
3	O
×	B-Method
3	I-Method
convolution	I-Method
modules	I-Method
1	O
with	O
128	O
channels	O
and	O
then	O
applies	O
a	O
corner	B-Method
pooling	I-Method
layer	O
.	O
	
Following	O
the	O
design	O
of	O
a	O
residual	O
block	O
,	O
we	O
then	O
feed	O
the	O
pooled	O
features	O
into	O
a	O
3	B-Method
×	I-Method
3	I-Method
Conv	I-Method
-	I-Method
BN	I-Method
layer	I-Method
with	O
256	O
channels	O
and	O
add	O
back	O
the	O
projection	O
shortcut	O
.	O
	
The	O
modified	O
residual	O
block	O
is	O
followed	O
by	O
a	O
3×3	B-Method
convolution	I-Method
module	I-Method
with	O
256	O
channels	O
,	O
and	O
3	O
Conv	B-Method
-	I-Method
ReLU	I-Method
-	I-Method
Conv	I-Method
layers	I-Method
to	O
produce	O
the	O
heatmaps	O
,	O
embeddings	O
and	O
offsets	O
.	O
	
section	O
:	O
Hourglass	B-Method
Network	I-Method
	
CornerNet	B-Method
uses	O
the	O
hourglass	B-Method
network	I-Method
[	O
reference	O
]	O
as	O
its	O
backbone	B-Method
network	I-Method
.	O
	
The	O
hourglass	B-Method
network	I-Method
was	O
first	O
introduced	O
for	O
the	O
human	B-Task
pose	I-Task
estimation	I-Task
task	I-Task
.	O
	
It	O
is	O
a	O
fully	B-Method
convolutional	I-Method
neural	I-Method
network	I-Method
that	O
consists	O
of	O
one	O
or	O
more	O
hourglass	B-Method
modules	I-Method
.	O
	
An	O
hourglass	B-Method
module	I-Method
first	O
downsamples	O
the	O
input	O
features	O
by	O
a	O
series	O
of	O
convolution	B-Method
and	I-Method
max	I-Method
pooling	I-Method
layers	I-Method
.	O
	
It	O
then	O
upsamples	O
the	O
features	O
back	O
to	O
the	O
original	O
resolution	O
by	O
a	O
series	O
of	O
upsampling	B-Method
and	I-Method
convolution	I-Method
layers	I-Method
.	O
	
Since	O
details	O
are	O
lost	O
in	O
the	O
max	B-Method
pooling	I-Method
layers	I-Method
,	O
skip	B-Method
layers	I-Method
are	O
added	O
to	O
bring	O
back	O
the	O
details	O
to	O
the	O
upsampled	O
features	O
.	O
	
The	O
hourglass	B-Method
module	I-Method
captures	O
both	O
global	O
and	O
local	O
features	O
in	O
a	O
single	O
unified	O
structure	O
.	O
	
When	O
multiple	O
hourglass	B-Method
modules	I-Method
are	O
stacked	O
in	O
the	O
network	O
,	O
the	O
hourglass	B-Method
modules	I-Method
can	O
reprocess	O
the	O
features	O
to	O
capture	O
higher	O
-	O
level	O
of	O
information	O
.	O
	
These	O
properties	O
make	O
the	O
hourglass	B-Method
network	I-Method
an	O
ideal	O
choice	O
for	O
object	B-Task
detection	I-Task
as	O
well	O
.	O
	
In	O
fact	O
,	O
many	O
current	O
detectors	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
)	O
already	O
adopted	O
networks	O
similar	O
to	O
the	O
hourglass	B-Method
network	I-Method
.	O
	
Our	O
hourglass	B-Method
network	I-Method
consists	O
of	O
two	O
hourglasses	B-Method
,	O
and	O
we	O
make	O
some	O
modifications	O
to	O
the	O
architecture	O
of	O
the	O
hourglass	B-Method
module	I-Method
.	O
	
Instead	O
of	O
using	O
max	B-Method
pool	I-Method
-	I-Method
	
9	O
10	O
	
Fig	O
.	O
	
6	O
	
The	O
top	O
-	O
left	O
corner	B-Method
pooling	I-Method
layer	O
can	O
be	O
implemented	O
very	O
efficiently	O
.	O
	
We	O
scan	O
from	O
right	O
to	O
left	O
for	O
the	O
horizontal	B-Task
max	I-Task
-	I-Task
pooling	I-Task
and	O
from	O
bottom	O
to	O
top	O
for	O
the	O
vertical	B-Method
max	I-Method
-	I-Method
pooling	I-Method
.	O
	
We	O
then	O
add	O
two	O
max	B-Method
-	I-Method
pooled	I-Method
feature	I-Method
maps	I-Method
.	O
	
Fig	O
.	O
	
7	O
	
The	O
prediction	B-Method
module	I-Method
starts	O
with	O
a	O
modified	O
residual	O
block	O
,	O
in	O
which	O
we	O
replace	O
the	O
first	O
convolution	B-Method
module	I-Method
with	O
our	O
corner	B-Method
pooling	I-Method
module	O
.	O
	
The	O
modified	O
residual	O
block	O
is	O
then	O
followed	O
by	O
a	O
convolution	B-Method
module	I-Method
.	O
	
We	O
have	O
multiple	O
branches	O
for	O
predicting	O
the	O
heatmaps	O
,	O
embeddings	O
and	O
offsets	O
.	O
	
ing	O
,	O
we	O
simply	O
use	O
stride	O
2	O
to	O
reduce	O
feature	O
resolution	O
.	O
	
We	O
reduce	O
feature	O
resolutions	O
5	O
times	O
and	O
increase	O
the	O
number	O
of	O
feature	O
channels	O
along	O
the	O
way	O
	
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
When	O
we	O
upsample	O
the	O
features	O
,	O
we	O
apply	O
2	O
residual	B-Method
modules	I-Method
followed	O
by	O
a	O
nearest	B-Method
neighbor	I-Method
upsampling	I-Method
.	O
	
Every	O
skip	O
connection	O
also	O
consists	O
of	O
2	O
residual	B-Method
modules	I-Method
.	O
	
There	O
are	O
4	O
residual	B-Method
modules	I-Method
with	O
512	O
channels	O
in	O
the	O
middle	O
of	O
an	O
hourglass	B-Method
module	I-Method
.	O
	
Before	O
the	O
hourglass	B-Method
modules	I-Method
,	O
we	O
reduce	O
the	O
image	O
resolution	O
by	O
4	O
times	O
using	O
a	O
7	O
×	B-Method
7	I-Method
convolution	I-Method
module	I-Method
with	O
stride	O
2	O
and	O
128	O
channels	O
followed	O
by	O
a	O
residual	O
block	O
with	O
stride	O
2	O
and	O
256	O
channels	O
.	O
	
Following	O
[	O
reference	O
]	O
,	O
we	O
also	O
add	O
intermediate	O
supervision	O
in	O
training	B-Task
.	O
	
However	O
,	O
we	O
do	O
not	O
add	O
back	O
the	O
intermediate	O
predictions	O
to	O
the	O
network	O
as	O
we	O
find	O
that	O
this	O
hurts	O
the	O
performance	O
of	O
the	O
network	O
.	O
	
We	O
apply	O
a	O
1	O
×	B-Method
1	I-Method
Conv	I-Method
-	I-Method
BN	I-Method
module	I-Method
to	O
both	O
the	O
input	O
and	O
output	O
of	O
the	O
first	O
hourglass	B-Method
module	I-Method
.	O
	
We	O
then	O
merge	O
them	O
by	O
element	B-Method
-	I-Method
wise	I-Method
addition	I-Method
followed	O
by	O
a	O
ReLU	B-Method
and	O
a	O
residual	O
block	O
with	O
256	O
channels	O
,	O
which	O
is	O
then	O
used	O
as	O
the	O
input	O
to	O
the	O
second	O
hourglass	B-Method
module	I-Method
.	O
	
The	O
depth	O
of	O
the	O
hourglass	B-Method
network	I-Method
is	O
104	O
.	O
	
Unlike	O
many	O
other	O
stateof	O
-	O
the	O
-	O
art	O
detectors	B-Method
,	O
we	O
only	O
use	O
the	O
features	O
from	O
the	O
last	O
layer	O
of	O
the	O
whole	O
network	O
to	O
make	O
predictions	O
.	O
	
section	O
:	O
Experiments	O
	
section	O
:	O
Training	O
Details	O
	
We	O
implement	O
CornerNet	B-Method
in	O
PyTorch	O
	
[	O
reference	O
]	O
.	O
	
The	O
network	O
is	O
randomly	O
initialized	O
under	O
the	O
default	O
setting	O
of	O
PyTorch	B-Method
with	O
no	O
pretraining	B-Method
on	O
any	O
external	O
dataset	O
.	O
	
As	O
we	O
apply	O
focal	O
loss	O
,	O
we	O
follow	O
to	O
set	O
the	O
biases	O
in	O
the	O
convolution	B-Method
layers	I-Method
that	O
predict	O
the	O
corner	O
heatmaps	O
.	O
	
During	O
training	O
,	O
we	O
set	O
the	O
input	O
resolution	O
of	O
the	O
network	O
to	O
511	O
×	O
511	O
,	O
which	O
leads	O
to	O
an	O
output	O
resolution	O
of	O
128	O
×	O
128	O
.	O
	
To	O
reduce	O
overfitting	O
,	O
we	O
adopt	O
standard	O
data	B-Method
augmentation	I-Method
techniques	I-Method
including	O
random	B-Method
horizontal	I-Method
flipping	I-Method
,	O
random	B-Method
scaling	I-Method
,	O
random	O
cropping	O
and	O
random	O
color	O
jittering	O
,	O
which	O
includes	O
adjusting	O
the	O
brightness	O
,	O
saturation	O
and	O
contrast	O
of	O
an	O
image	O
.	O
	
Finally	O
,	O
we	O
apply	O
PCA	B-Method
[	O
reference	O
]	O
to	O
the	O
input	O
image	O
.	O
	
We	O
use	O
Adam	B-Method
[	O
reference	O
]	O
to	O
optimize	O
the	O
full	B-Metric
training	I-Metric
loss	I-Metric
:	O
	
where	O
α	O
,	O
β	O
and	O
γ	O
are	O
the	O
weights	O
for	O
the	O
pull	O
,	O
push	O
and	O
offset	O
loss	O
respectively	O
.	O
	
We	O
set	O
both	O
α	O
and	O
β	O
to	O
0.1	O
and	O
γ	O
to	O
1	O
.	O
	
We	O
find	O
that	O
1	O
or	O
larger	O
values	O
of	O
α	O
and	O
β	O
lead	O
to	O
poor	O
performance	O
.	O
	
We	O
use	O
a	O
batch	O
size	O
of	O
49	O
and	O
train	O
the	O
network	O
on	O
10	O
Titan	O
X	O
(	O
PASCAL	O
)	O
GPUs	O
(	O
4	O
images	O
on	O
the	O
master	O
GPU	O
,	O
5	O
images	O
per	O
GPU	O
for	O
the	O
rest	O
of	O
the	O
GPUs	O
)	O
.	O
	
To	O
conserve	O
GPU	O
resources	O
,	O
in	O
our	O
ablation	O
experiments	O
,	O
we	O
train	O
the	O
networks	O
for	O
250k	O
iterations	O
with	O
a	O
learning	B-Metric
rate	I-Metric
of	O
2.5	O
×	O
10	O
−4	O
.	O
	
When	O
we	O
compare	O
our	O
results	O
with	O
other	O
detectors	B-Method
,	O
we	O
train	O
the	O
networks	O
for	O
an	O
extra	O
250k	O
iterations	O
and	O
reduce	O
the	O
learning	B-Metric
rate	I-Metric
to	O
2.5	O
×	O
10	O
−5	O
for	O
the	O
last	O
50k	O
iterations	O
.	O
	
section	O
:	O
Testing	O
Details	O
	
During	O
testing	O
,	O
we	O
use	O
a	O
simple	O
post	B-Method
-	I-Method
processing	I-Method
algorithm	I-Method
to	O
generate	O
bounding	O
boxes	O
from	O
the	O
heatmaps	O
,	O
embeddings	O
and	O
offsets	O
.	O
	
We	O
first	O
apply	O
non	B-Method
-	I-Method
maximal	I-Method
suppression	I-Method
(	O
NMS	B-Method
)	O
by	O
using	O
a	O
3×3	B-Method
max	I-Method
pooling	I-Method
layer	I-Method
on	O
the	O
corner	O
heatmaps	O
.	O
	
Then	O
we	O
pick	O
the	O
top	O
100	O
top	O
-	O
left	O
and	O
top	O
100	O
bottom	O
-	O
right	O
corners	O
from	O
the	O
heatmaps	O
.	O
	
The	O
corner	O
locations	O
are	O
adjusted	O
by	O
the	O
corresponding	O
offsets	O
.	O
	
We	O
calculate	O
the	O
L1	O
distances	O
between	O
the	O
embeddings	O
of	O
the	O
top	O
-	O
left	O
and	O
bottom	O
-	O
right	O
corners	O
.	O
	
Pairs	O
that	O
have	O
distances	O
greater	O
than	O
0.5	O
or	O
contain	O
corners	O
from	O
different	O
categories	O
are	O
rejected	O
.	O
	
The	O
average	O
scores	O
of	O
the	O
top	O
-	O
left	O
and	O
bottom	O
-	O
right	O
corners	O
are	O
used	O
as	O
the	O
detection	B-Metric
scores	I-Metric
.	O
	
Instead	O
of	O
resizing	O
an	O
image	O
to	O
a	O
fixed	O
size	O
,	O
we	O
maintain	O
the	O
original	O
resolution	O
of	O
the	O
image	O
and	O
pad	O
it	O
with	O
zeros	O
before	O
feeding	O
it	O
to	O
CornerNet	B-Method
.	O
	
Both	O
the	O
original	O
and	O
flipped	O
images	O
are	O
used	O
for	O
testing	O
.	O
	
We	O
combine	O
the	O
detections	O
from	O
the	O
original	O
and	O
flipped	O
images	O
,	O
and	O
apply	O
soft	B-Method
-	I-Method
nms	I-Method
[	O
reference	O
]	O
to	O
suppress	O
redundant	O
detections	O
.	O
	
Only	O
the	O
top	O
100	O
detections	O
are	O
reported	O
.	O
	
The	O
average	O
inference	B-Metric
time	I-Metric
is	O
244ms	O
per	O
image	O
on	O
a	O
Titan	O
X	O
(	O
PASCAL	O
)	O
GPU	O
.	O
	
section	O
:	O
MS	B-Material
COCO	I-Material
	
We	O
evaluate	O
CornerNet	B-Method
on	O
the	O
very	O
challenging	O
MS	B-Material
COCO	I-Material
dataset	O
[	O
reference	O
]	O
.	O
MS	B-Material
COCO	I-Material
contains	O
80k	O
images	O
for	O
training	O
,	O
40k	O
for	O
validation	B-Task
and	O
20k	O
for	O
testing	O
.	O
	
All	O
images	O
in	O
the	O
training	O
set	O
and	O
35k	O
images	O
in	O
the	O
validation	O
set	O
are	O
used	O
for	O
training	O
.	O
	
The	O
remaining	O
5k	O
images	O
in	O
validation	O
set	O
are	O
used	O
for	O
hyper	B-Task
-	I-Task
parameter	I-Task
searching	I-Task
and	O
ablation	B-Task
study	I-Task
.	O
	
All	O
results	O
on	O
the	O
test	O
set	O
are	O
submitted	O
to	O
an	O
external	O
server	O
for	O
evaluation	O
.	O
	
To	O
provide	O
fair	O
comparisons	O
with	O
other	O
detectors	O
,	O
we	O
report	O
our	O
main	O
results	O
on	O
the	O
test	O
-	O
dev	O
set	O
.	O
	
MS	B-Material
COCO	I-Material
uses	O
average	B-Metric
precisions	I-Metric
(	O
APs	B-Metric
)	O
at	O
different	O
IoUs	O
and	O
APs	B-Metric
for	O
different	O
object	O
sizes	O
as	O
the	O
main	O
evaluation	B-Metric
metrics	I-Metric
.	O
	
section	O
:	O
Ablation	B-Task
Study	I-Task
	
section	O
:	O
Corner	B-Method
Pooling	I-Method
	
Corner	B-Method
pooling	I-Method
is	O
a	O
key	O
component	O
of	O
CornerNet	B-Method
.	O
	
To	O
understand	O
its	O
contribution	O
to	O
performance	O
,	O
we	O
train	O
another	O
network	O
without	O
corner	B-Method
pooling	I-Method
but	O
with	O
the	O
same	O
number	O
of	O
parameters	O
.	O
	
Tab	O
.	O
	
1	O
shows	O
that	O
adding	O
corner	B-Method
pooling	I-Method
gives	O
significant	O
improvement	O
:	O
2.0	O
%	O
on	O
AP	B-Metric
,	O
2.1	O
%	O
on	O
AP	B-Metric
50	O
and	O
2.1	O
%	O
on	O
AP	B-Metric
75	O
.	O
	
We	O
also	O
see	O
that	O
corner	B-Method
pooling	I-Method
is	O
especially	O
helpful	O
for	O
medium	O
and	O
large	O
objects	O
,	O
improving	O
their	O
APs	B-Metric
by	O
2.4	O
%	O
and	O
3.6	O
%	O
respectively	O
.	O
	
This	O
is	O
expected	O
because	O
the	O
topmost	O
,	O
bottommost	O
,	O
leftmost	O
,	O
rightmost	O
boundaries	O
of	O
medium	O
and	O
large	O
objects	O
are	O
likely	O
to	O
be	O
further	O
away	O
from	O
the	O
corner	O
locations	O
.	O
	
Fig	O
.	O
	
8	O
shows	O
four	O
qualitative	O
examples	O
with	O
and	O
without	O
corner	B-Method
pooling	I-Method
.	O
	
section	O
:	O
Stability	O
of	O
Corner	B-Method
Pooling	I-Method
over	O
Larger	O
Area	O
	
Corner	B-Method
pooling	I-Method
pools	O
over	O
different	O
sizes	O
of	O
area	O
in	O
different	O
quadrants	O
of	O
an	O
image	O
.	O
	
For	O
example	O
,	O
the	O
top	O
-	O
left	O
corner	B-Method
pooling	I-Method
pools	O
over	O
larger	O
areas	O
both	O
horizontally	O
and	O
vertically	O
in	O
the	O
upper	O
-	O
left	O
quadrant	O
of	O
an	O
image	O
,	O
compared	O
to	O
the	O
lower	O
-	O
right	O
quadrant	O
.	O
	
Therefore	O
,	O
the	O
location	O
of	O
a	O
corner	O
may	O
affect	O
the	O
stability	O
of	O
the	O
corner	B-Method
pooling	I-Method
.	O
	
We	O
evaluate	O
the	O
performance	O
of	O
our	O
network	O
on	O
detecting	O
both	O
the	O
top	O
-	O
left	O
and	O
bottom	O
-	O
right	O
corners	O
in	O
different	O
quadrants	O
of	O
an	O
image	O
.	O
	
Detecting	B-Task
corners	I-Task
can	O
be	O
seen	O
as	O
a	O
binary	B-Task
classification	I-Task
task	I-Task
i.e.	O
the	O
groundtruth	O
location	O
of	O
a	O
corner	O
is	O
positive	O
,	O
and	O
any	O
location	O
outside	O
of	O
a	O
small	O
radius	O
of	O
the	O
corner	O
is	O
negative	O
.	O
	
We	O
measure	O
the	O
performance	O
using	O
mAPs	B-Metric
over	O
all	O
categories	O
on	O
the	O
MS	B-Material
COCO	I-Material
validation	O
set	O
.	O
	
Tab	O
.	O
	
3	O
shows	O
that	O
without	O
corner	B-Method
pooling	I-Method
,	O
the	O
topleft	O
corner	O
mAPs	B-Metric
of	O
upper	O
-	O
left	O
and	O
lower	O
-	O
right	O
quadrant	O
are	O
66.1	O
%	O
and	O
60.8	O
%	O
respectively	O
.	O
	
Top	O
-	O
left	O
corner	B-Method
pooling	I-Method
improves	O
the	O
mAPs	B-Metric
by	O
3.1	O
%	O
(	O
to	O
69.2	O
%	O
)	O
and	O
2.7	O
%	O
(	O
to	O
63.5	O
%	O
)	O
respectively	O
.	O
	
Similarly	O
,	O
bottomright	O
corner	B-Method
pooling	I-Method
improves	O
the	O
bottom	O
-	O
right	O
corner	O
mAPs	B-Metric
of	O
upper	O
-	O
left	O
quadrant	O
by	O
2.8	O
%	O
(	O
from	O
53.4	O
%	O
to	O
56.2	O
%	O
)	O
,	O
and	O
lower	O
-	O
right	O
quadrant	O
by	O
2.6	O
%	O
(	O
from	O
65.0	O
%	O
to	O
67.6	O
%	O
)	O
.	O
	
Corner	B-Method
pooling	I-Method
gives	O
similar	O
improvement	O
to	O
corners	O
at	O
different	O
quadrants	O
,	O
show	O
that	O
corner	B-Method
pooling	I-Method
is	O
effective	O
and	O
stable	O
over	O
both	O
small	O
and	O
large	O
areas	O
.	O
	
section	O
:	O
Reducing	O
Penalty	O
to	O
Negative	O
Locations	O
	
We	O
reduce	O
the	O
penalty	O
given	O
to	O
negative	O
locations	O
around	O
a	O
positive	O
location	O
,	O
within	O
a	O
radius	O
determined	O
by	O
the	O
size	O
of	O
the	O
object	O
(	O
Sec	O
.	O
3.2	O
)	O
.	O
	
To	O
understand	O
how	O
this	O
helps	O
train	O
CornerNet	B-Method
,	O
we	O
train	O
one	O
network	O
with	O
no	O
penalty	B-Method
reduction	I-Method
and	O
another	O
network	O
with	O
a	O
fixed	O
radius	O
of	O
2.5	O
.	O
	
We	O
compare	O
them	O
with	O
CornerNet	B-Method
on	O
the	O
validation	O
set	O
.	O
	
Tab	O
.	O
2	O
shows	O
that	O
a	O
fixed	O
radius	O
improves	O
AP	B-Metric
over	O
the	O
baseline	O
by	O
2.7	O
%	O
,	O
AP	B-Metric
m	I-Metric
by	O
1.5	O
%	O
and	O
AP	B-Metric
	
l	O
by	O
5.3	O
%	O
.	O
	
Object	O
-	O
dependent	O
radius	O
further	O
improves	O
the	O
AP	B-Metric
by	O
2.8	O
%	O
,	O
AP	B-Metric
m	I-Metric
by	O
2.0	O
%	O
and	O
AP	B-Metric
l	I-Metric
by	O
5.8	O
%	O
.	O
	
In	O
addition	O
,	O
we	O
see	O
that	O
the	O
penalty	B-Task
reduction	I-Task
especially	O
benefits	O
medium	O
and	O
large	O
objects	O
.	O
	
section	O
:	O
Hourglass	B-Method
Network	I-Method
	
CornerNet	B-Method
uses	O
the	O
hourglass	B-Method
network	I-Method
[	O
reference	O
]	O
as	O
its	O
backbone	B-Method
network	I-Method
.	O
	
Since	O
the	O
hourglass	B-Method
network	I-Method
is	O
not	O
commonly	O
used	O
in	O
other	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
detectors	O
,	O
we	O
perform	O
an	O
experiment	O
to	O
study	O
the	O
contribution	O
of	O
the	O
hourglass	B-Method
network	I-Method
in	O
CornerNet	B-Method
.	O
	
We	O
train	O
a	O
CornerNet	B-Method
in	O
which	O
we	O
replace	O
the	O
hourglass	B-Method
network	I-Method
with	O
FPN	B-Method
(	O
w	O
/	O
ResNet	B-Method
-	I-Method
101	I-Method
)	O
,	O
which	O
is	O
more	O
commonly	O
used	O
in	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
object	B-Method
detectors	I-Method
.	O
	
We	O
only	O
use	O
the	O
final	O
output	O
of	O
FPN	B-Method
for	O
predictions	B-Task
.	O
	
Meanwhile	O
,	O
we	O
train	O
an	O
anchor	B-Method
box	I-Method
based	I-Method
detector	I-Method
which	O
uses	O
the	O
hourglass	B-Method
network	I-Method
as	O
its	O
backbone	O
.	O
	
Each	O
hourglass	B-Method
module	I-Method
predicts	O
anchor	O
boxes	O
at	O
multiple	O
resolutions	O
by	O
using	O
features	O
at	O
multiple	O
scales	O
during	O
upsampling	B-Method
stage	I-Method
.	O
	
We	O
follow	O
the	O
anchor	B-Method
box	I-Method
design	I-Method
in	O
RetinaNet	B-Method
and	O
add	O
intermediate	O
supervisions	O
during	O
training	O
.	O
	
In	O
both	O
experiments	O
,	O
we	O
initialize	O
the	O
networks	O
from	O
scratch	O
and	O
follow	O
the	O
same	O
training	O
procedure	O
as	O
we	O
train	O
CornerNet	B-Method
(	O
Sec	O
.	O
4.1	O
)	O
.	O
	
Tab	O
.	O
	
4	O
shows	O
that	O
CornerNet	B-Method
with	O
hourglass	O
network	O
outperforms	O
CornerNet	B-Method
with	O
FPN	B-Method
by	O
8.2	O
%	O
AP	B-Metric
,	O
and	O
the	O
anchor	B-Method
box	I-Method
based	I-Method
detector	I-Method
with	O
hourglass	B-Method
network	I-Method
by	O
5.5	O
%	O
AP	B-Metric
.	O
	
The	O
results	O
suggest	O
that	O
the	O
choice	O
of	O
the	O
backbone	B-Method
network	I-Method
is	O
important	O
and	O
the	O
hourglass	B-Method
network	I-Method
is	O
crucial	O
to	O
the	O
performance	O
of	O
CornerNet	B-Method
.	O
	
section	O
:	O
Quality	O
of	O
the	O
Bounding	O
Boxes	O
	
A	O
good	O
detector	O
should	O
predict	O
high	O
quality	O
bounding	O
boxes	O
that	O
cover	O
objects	O
tightly	O
.	O
	
To	O
understand	O
the	O
quality	O
of	O
the	O
bounding	O
boxes	O
predicted	O
by	O
CornerNet	B-Method
,	O
we	O
evaluate	O
the	O
performance	O
of	O
CornerNet	B-Method
at	O
multiple	O
IoU	O
thresholds	O
,	O
and	O
compare	O
the	O
results	O
with	O
other	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
detectors	B-Method
,	O
including	O
RetinaNet	B-Method
,	O
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
[	O
reference	O
]	O
and	O
IoU	B-Method
-	I-Method
Net	I-Method
[	O
	
reference	O
]	O
.	O
Tab	O
.	O
5	O
shows	O
that	O
CornerNet	B-Method
achieves	O
a	O
much	O
higher	O
AP	B-Metric
at	O
0.9	O
IoU	B-Metric
than	O
other	O
detectors	O
,	O
outperforming	O
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
+	O
	
IoU	B-Metric
-	I-Metric
Net	I-Metric
by	O
3.9	O
%	O
,	O
	
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
by	O
7.6	O
%	O
and	O
RetinaNet	B-Method
2	I-Method
by	O
7.3	O
%	O
.	O
	
This	O
suggests	O
that	O
Cor	B-Method
-	I-Method
2	I-Method
We	O
use	O
the	O
best	O
model	O
publicly	O
available	O
on	O
https:	O
//	O
github.com	O
/	O
facebookresearch	O
/	O
Detectron	O
/	O
blob	O
/	O
master	O
/	O
MODEL_ZOO.md	O
nerNet	O
is	O
able	O
to	O
generate	O
bounding	O
boxes	O
of	O
higher	O
quality	O
compared	O
to	O
other	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
detectors	O
.	O
	
section	O
:	O
Error	B-Task
Analysis	I-Task
	
CornerNet	B-Method
simultaneously	O
outputs	O
heatmaps	O
,	O
offsets	O
,	O
and	O
embeddings	O
,	O
all	O
of	O
which	O
affect	O
detection	B-Task
performance	O
.	O
	
An	O
object	O
will	O
be	O
missed	O
if	O
either	O
corner	O
is	O
missed	O
;	O
precise	O
offsets	O
are	O
needed	O
to	O
generate	O
tight	O
bounding	O
boxes	O
;	O
incorrect	O
embeddings	O
will	O
result	O
in	O
many	O
false	O
bounding	O
boxes	O
.	O
	
To	O
understand	O
how	O
each	O
part	O
contributes	O
to	O
the	O
final	O
error	O
,	O
we	O
perform	O
an	O
error	B-Method
analysis	I-Method
by	O
replacing	O
the	O
predicted	O
heatmaps	O
and	O
offsets	O
with	O
the	O
ground	O
-	O
truth	O
values	O
and	O
evaluting	O
performance	O
on	O
the	O
validation	O
set	O
.	O
	
Tab	O
.	O
6	O
shows	O
that	O
using	O
the	O
ground	O
-	O
truth	O
corner	O
heatmaps	O
alone	O
improves	O
the	O
AP	B-Metric
from	O
38.4	O
%	O
to	O
73.1	O
%	O
.	O
	
section	O
:	O
AP	B-Metric
	
s	O
,	O
AP	B-Metric
m	O
and	O
AP	B-Metric
l	O
also	O
increase	O
by	O
42.3	O
%	O
,	O
40.7	O
%	O
and	O
30.0	O
%	O
respectively	O
.	O
	
If	O
we	O
replace	O
the	O
predicted	O
offsets	O
with	O
the	O
ground	O
-	O
truth	O
offsets	O
,	O
the	O
AP	B-Metric
further	O
increases	O
by	O
13.0	O
%	O
to	O
86.1	O
%	O
.	O
	
This	O
suggests	O
that	O
although	O
there	O
is	O
still	O
ample	O
room	O
for	O
improvement	O
in	O
both	O
detecting	B-Task
and	I-Task
grouping	I-Task
corners	I-Task
,	O
the	O
main	O
bottleneck	O
is	O
detecting	B-Task
corners	I-Task
.	O
	
Fig	O
.	O
	
9	O
shows	O
some	O
qualitative	O
examples	O
where	O
the	O
corner	O
locations	O
or	O
embeddings	O
are	O
incorrect	O
.	O
	
section	O
:	O
Comparisons	O
with	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
detectors	O
	
We	O
compare	O
CornerNet	B-Method
with	O
other	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
detectors	O
on	O
MS	B-Material
COCO	I-Material
test	O
-	O
dev	O
	
(	O
Tab	O
.	O
7	O
)	O
.	O
	
With	O
multiscale	B-Task
evaluation	I-Task
,	O
CornerNet	B-Method
achieves	O
an	O
AP	B-Metric
of	O
42.2	O
%	O
,	O
the	O
state	O
of	O
the	O
art	O
among	O
existing	O
one	B-Method
-	I-Method
stage	I-Method
methods	I-Method
and	O
competitive	O
with	O
two	O
-	O
stage	B-Method
methods	I-Method
.	O
	
section	O
:	O
Conclusion	O
	
We	O
have	O
presented	O
CornerNet	B-Method
,	O
a	O
new	O
approach	O
to	O
object	B-Task
detection	I-Task
that	O
detects	O
bounding	O
boxes	O
as	O
pairs	O
of	O
corners	O
.	O
	
We	O
evaluate	O
CornerNet	B-Method
on	O
MS	B-Material
COCO	I-Material
and	O
demonstrate	O
competitive	O
results	O
.	O
	
section	O
:	O
	
section	O
:	O
	
Acknowledgements	O
This	O
work	O
is	O
partially	O
supported	O
by	O
a	O
grant	O
from	O
Toyota	O
Research	O
Institute	O
and	O
a	O
DARPA	O
grant	O
FA8750	O
-	O
18	O
-	O
2	O
-	O
0019	O
.	O
	
This	O
article	O
solely	O
reflects	O
the	O
opinions	O
and	O
conclusions	O
of	O
its	O
authors	O
.	O
	
section	O
:	O
	
document	O
:	O
Deep	B-Task
Exploration	I-Task
via	O
Bootstrapped	B-Method
DQN	I-Method
	
Efficient	B-Task
exploration	I-Task
remains	O
a	O
major	O
challenge	O
for	O
reinforcement	B-Task
learning	I-Task
(	O
RL	B-Task
)	O
.	O
	
Common	O
dithering	B-Method
strategies	I-Method
for	O
exploration	B-Task
,	O
such	O
as	O
-	B-Method
greedy	I-Method
,	O
do	O
not	O
carry	O
out	O
temporally	O
-	O
extended	O
(	O
or	O
deep	O
)	O
exploration	O
;	O
this	O
can	O
lead	O
to	O
exponentially	O
larger	O
data	O
requirements	O
.	O
	
However	O
,	O
most	O
algorithms	O
for	O
statistically	O
efficient	O
RL	B-Task
are	O
not	O
computationally	O
tractable	O
in	O
complex	O
environments	O
.	O
	
Randomized	B-Method
value	I-Method
functions	I-Method
offer	O
a	O
promising	O
approach	O
to	O
efficient	O
exploration	B-Task
with	O
generalization	B-Task
,	O
but	O
existing	O
algorithms	O
are	O
not	O
compatible	O
with	O
nonlinearly	O
parameterized	O
value	O
functions	O
.	O
	
As	O
a	O
first	O
step	O
towards	O
addressing	O
such	O
contexts	O
we	O
develop	O
bootstrapped	B-Method
DQN	I-Method
.	O
	
We	O
demonstrate	O
that	O
bootstrapped	B-Method
DQN	I-Method
can	O
combine	O
deep	B-Method
exploration	I-Method
with	O
deep	B-Method
neural	I-Method
networks	I-Method
for	O
exponentially	O
faster	O
learning	B-Task
than	O
any	O
dithering	B-Method
strategy	I-Method
.	O
	
In	O
the	O
Arcade	B-Method
Learning	I-Method
Environment	I-Method
bootstrapped	I-Method
DQN	I-Method
substantially	O
improves	O
learning	B-Metric
speed	I-Metric
and	O
cumulative	O
performance	O
across	O
most	O
games	O
.	O
	
section	O
:	O
Introduction	O
	
We	O
study	O
the	O
reinforcement	B-Task
learning	I-Task
(	O
RL	B-Task
)	O
problem	O
where	O
an	O
agent	O
interacts	O
with	O
an	O
unknown	O
environment	O
.	O
	
The	O
agent	O
takes	O
a	O
sequence	O
of	O
actions	O
in	O
order	O
to	O
maximize	O
cumulative	O
rewards	O
.	O
	
Unlike	O
standard	O
planning	B-Task
problems	I-Task
,	O
an	O
RL	B-Task
agent	O
does	O
not	O
begin	O
with	O
perfect	O
knowledge	O
of	O
the	O
environment	O
,	O
but	O
learns	O
through	O
experience	O
.	O
	
This	O
leads	O
to	O
a	O
fundamental	O
trade	O
-	O
off	O
of	O
exploration	B-Task
versus	O
exploitation	B-Task
;	O
the	O
agent	O
may	O
improve	O
its	O
future	O
rewards	O
by	O
exploring	O
poorly	O
understood	O
states	O
and	O
actions	O
,	O
but	O
this	O
may	O
require	O
sacrificing	O
immediate	O
rewards	O
.	O
	
To	O
learn	O
efficiently	O
an	O
agent	O
should	O
explore	O
only	O
when	O
there	O
are	O
valuable	O
learning	O
opportunities	O
.	O
	
Further	O
,	O
since	O
any	O
action	O
may	O
have	O
long	O
term	O
consequences	O
,	O
the	O
agent	O
should	O
reason	O
about	O
the	O
informational	O
value	O
of	O
possible	O
observation	O
sequences	O
.	O
	
Without	O
this	O
sort	O
of	O
temporally	B-Method
extended	I-Method
(	I-Method
deep	I-Method
)	I-Method
exploration	I-Method
,	O
learning	B-Metric
times	I-Metric
can	O
worsen	O
by	O
an	O
exponential	O
factor	O
.	O
	
The	O
theoretical	O
RL	B-Task
literature	O
offers	O
a	O
variety	O
of	O
provably	O
-	O
efficient	O
approaches	O
to	O
deep	B-Task
exploration	I-Task
.	O
	
However	O
,	O
most	O
of	O
these	O
are	O
designed	O
for	O
Markov	B-Task
decision	I-Task
processes	I-Task
(	O
MDPs	B-Method
)	O
with	O
small	O
finite	O
state	O
spaces	O
,	O
while	O
others	O
require	O
solving	O
computationally	B-Task
intractable	I-Task
planning	I-Task
tasks	I-Task
.	O
	
These	O
algorithms	O
are	O
not	O
practical	O
in	O
complex	O
environments	O
where	O
an	O
agent	O
must	O
generalize	O
to	O
operate	O
effectively	O
.	O
	
For	O
this	O
reason	O
,	O
large	O
-	O
scale	O
applications	O
of	O
RL	B-Task
have	O
relied	O
upon	O
statistically	B-Method
inefficient	I-Method
strategies	I-Method
for	O
exploration	B-Task
or	O
even	O
no	O
exploration	O
at	O
all	O
.	O
	
We	O
review	O
related	O
literature	O
in	O
more	O
detail	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Common	O
dithering	B-Method
strategies	I-Method
,	O
such	O
as	O
-	B-Method
greedy	I-Method
,	O
approximate	O
the	O
value	O
of	O
an	O
action	O
by	O
a	O
single	O
number	O
.	O
	
Most	O
of	O
the	O
time	O
they	O
pick	O
the	O
action	O
with	O
the	O
highest	O
estimate	O
,	O
but	O
sometimes	O
they	O
choose	O
another	O
action	O
at	O
random	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
consider	O
an	O
alternative	O
approach	O
to	O
efficient	B-Task
exploration	I-Task
inspired	O
by	O
Thompson	B-Method
sampling	I-Method
.	O
	
These	O
algorithms	O
have	O
some	O
notion	O
of	O
uncertainty	O
and	O
instead	O
maintain	O
a	O
distribution	O
over	O
possible	O
values	O
.	O
	
They	O
explore	O
by	O
randomly	O
select	O
a	O
policy	O
according	O
to	O
the	O
probability	O
it	O
is	O
the	O
optimal	O
policy	O
.	O
	
Recent	O
work	O
has	O
shown	O
that	O
randomized	B-Method
value	I-Method
functions	I-Method
can	O
implement	O
something	O
similar	O
to	O
Thompson	B-Method
sampling	I-Method
without	O
the	O
need	O
for	O
an	O
intractable	O
exact	O
posterior	O
update	O
.	O
	
However	O
,	O
this	O
work	O
is	O
restricted	O
to	O
linearly	O
-	O
parameterized	O
value	O
functions	O
.	O
	
We	O
present	O
a	O
natural	O
extension	O
of	O
this	O
approach	O
that	O
enables	O
use	O
of	O
complex	O
non	B-Method
-	I-Method
linear	I-Method
generalization	I-Method
methods	I-Method
such	O
as	O
deep	B-Method
neural	I-Method
networks	I-Method
.	O
	
We	O
show	O
that	O
the	O
bootstrap	B-Method
with	O
random	B-Method
initialization	I-Method
can	O
produce	O
reasonable	O
uncertainty	B-Metric
estimates	I-Metric
for	O
neural	B-Method
networks	I-Method
at	O
low	O
computational	B-Metric
cost	I-Metric
.	O
	
Bootstrapped	B-Method
DQN	I-Method
leverages	O
these	O
uncertainty	B-Method
estimates	I-Method
for	O
efficient	O
(	B-Task
and	I-Task
deep	I-Task
)	I-Task
exploration	I-Task
.	O
	
We	O
demonstrate	O
that	O
these	O
benefits	O
can	O
extend	O
to	O
large	B-Task
scale	I-Task
problems	I-Task
that	O
are	O
not	O
designed	O
to	O
highlight	O
deep	B-Task
exploration	I-Task
.	O
	
Bootstrapped	B-Method
DQN	I-Method
substantially	O
reduces	O
learning	B-Metric
times	I-Metric
and	O
improves	O
performance	O
across	O
most	O
games	O
.	O
	
This	O
algorithm	O
is	O
computationally	O
efficient	O
and	O
parallelizable	O
;	O
on	O
a	O
single	O
machine	O
our	O
implementation	O
runs	O
roughly	O
%	O
slower	O
than	O
DQN	B-Method
.	O
	
section	O
:	O
Uncertainty	O
for	O
neural	B-Method
networks	I-Method
	
Deep	B-Method
neural	I-Method
networks	I-Method
(	O
DNN	B-Method
)	I-Method
represent	O
the	O
state	O
of	O
the	O
art	O
in	O
many	O
supervised	O
and	O
reinforcement	B-Task
learning	I-Task
domains	O
.	O
	
We	O
want	O
an	O
exploration	B-Method
strategy	I-Method
that	O
is	O
statistically	O
computationally	O
efficient	O
together	O
with	O
a	O
DNN	B-Method
representation	I-Method
of	I-Method
the	I-Method
value	I-Method
function	I-Method
.	O
	
To	O
explore	O
efficiently	O
,	O
the	O
first	O
step	O
to	O
quantify	O
uncertainty	O
in	O
value	B-Task
estimates	I-Task
so	O
that	O
the	O
agent	O
can	O
judge	O
potential	O
benefits	O
of	O
exploratory	O
actions	O
.	O
	
The	O
neural	B-Method
network	I-Method
literature	I-Method
presents	O
a	O
sizable	O
body	O
of	O
work	O
on	O
uncertainty	B-Task
quantification	I-Task
founded	O
on	O
parametric	B-Method
Bayesian	I-Method
inference	I-Method
.	O
	
We	O
actually	O
found	O
the	O
simple	O
non	O
-	O
parametric	O
bootstrap	B-Method
with	O
random	B-Method
initialization	I-Method
more	O
effective	O
in	O
our	O
experiments	O
,	O
but	O
the	O
main	O
ideas	O
of	O
this	O
paper	O
would	O
apply	O
with	O
any	O
other	O
approach	O
to	O
uncertainty	B-Task
in	O
DNNs	B-Task
.	O
	
The	O
bootstrap	B-Method
princple	O
is	O
to	O
approximate	O
a	O
population	O
distribution	O
by	O
a	O
sample	B-Method
distribution	I-Method
.	O
	
In	O
its	O
most	O
common	O
form	O
,	O
the	O
bootstrap	B-Method
takes	O
as	O
input	O
a	O
data	O
set	O
and	O
an	O
estimator	B-Method
.	O
	
To	O
generate	O
a	O
sample	O
from	O
the	O
bootstrapped	B-Method
distribution	I-Method
,	O
a	O
data	O
set	O
of	O
cardinality	O
equal	O
to	O
that	O
of	O
is	O
sampled	O
uniformly	O
with	O
replacement	O
from	O
.	O
	
The	O
bootstrap	B-Method
sample	O
estimate	O
is	O
then	O
taken	O
to	O
be	O
.	O
	
The	O
bootstrap	B-Method
is	O
widely	O
hailed	O
as	O
a	O
great	O
advance	O
of	O
20th	O
century	O
applied	O
statistics	O
and	O
even	O
comes	O
with	O
theoretical	O
guarantees	O
.	O
	
In	O
Figure	O
[	O
reference	O
]	O
we	O
present	O
an	O
efficient	O
and	O
scalable	O
method	O
for	O
generating	O
bootstrap	B-Method
samples	O
from	O
a	O
large	B-Method
and	I-Method
deep	I-Method
neural	I-Method
network	I-Method
.	O
	
The	O
network	O
consists	O
of	O
a	O
shared	B-Method
architecture	I-Method
with	O
bootstrapped	O
	
‘	O
	
‘	O
heads	O
’	O
’	O
branching	O
off	O
independently	O
.	O
	
Each	O
head	O
is	O
trained	O
only	O
on	O
its	O
bootstrapped	O
sub	O
-	O
sample	O
of	O
the	O
data	O
and	O
represents	O
a	O
single	O
bootstrap	B-Method
sample	O
.	O
	
The	O
shared	B-Method
network	I-Method
learns	O
a	O
joint	B-Method
feature	I-Method
representation	I-Method
across	O
all	O
the	O
data	O
,	O
which	O
can	O
provide	O
significant	O
computational	O
advantages	O
at	O
the	O
cost	O
of	O
lower	O
diversity	O
between	O
heads	O
.	O
	
This	O
type	O
of	O
bootstrap	B-Method
can	O
be	O
trained	O
efficiently	O
in	O
a	O
single	O
forward	B-Method
/	I-Method
backward	I-Method
pass	I-Method
;	O
it	O
can	O
be	O
thought	O
of	O
as	O
a	O
data	B-Method
-	I-Method
dependent	I-Method
dropout	I-Method
,	O
where	O
the	O
dropout	O
mask	O
for	O
each	O
head	O
is	O
fixed	O
for	O
each	O
data	O
point	O
.	O
	
[	O
b	O
]	O
0.31	O
[	O
b	O
]	O
0.31	O
[	O
b	O
]	O
0.31	O
Figure	O
[	O
reference	O
]	O
presents	O
an	O
example	O
of	O
uncertainty	B-Method
estimates	I-Method
from	O
bootstrapped	B-Method
neural	I-Method
networks	I-Method
on	O
a	O
regression	B-Task
task	I-Task
with	O
noisy	O
data	O
.	O
	
We	O
trained	O
a	O
fully	B-Method
-	I-Method
connected	I-Method
2	I-Method
-	I-Method
layer	I-Method
neural	I-Method
networks	I-Method
with	O
50	O
rectified	B-Method
linear	I-Method
units	I-Method
(	O
ReLU	B-Method
)	O
in	O
each	O
layer	O
on	O
50	O
bootstrapped	O
samples	O
from	O
the	O
data	O
.	O
	
As	O
is	O
standard	O
,	O
we	O
initialize	O
these	O
networks	O
with	O
random	O
parameter	O
values	O
,	O
this	O
induces	O
an	O
important	O
initial	O
diversity	O
in	O
the	O
models	O
.	O
	
We	O
were	O
unable	O
to	O
generate	O
effective	O
uncertainty	B-Task
estimates	I-Task
for	O
this	O
problem	O
using	O
the	O
dropout	B-Method
approach	I-Method
in	O
prior	O
literature	O
.	O
	
Further	O
details	O
are	O
provided	O
in	O
Appendix	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
Bootstrapped	B-Method
DQN	I-Method
	
For	O
a	O
policy	O
we	O
define	O
the	O
value	O
of	O
an	O
action	O
in	O
state	O
,	O
where	O
is	O
a	O
discount	O
factor	O
that	O
balances	O
immediate	O
versus	O
future	O
rewards	O
.	O
	
This	O
expectation	O
indicates	O
that	O
the	O
initial	O
state	O
is	O
,	O
the	O
initial	O
action	O
is	O
,	O
and	O
thereafter	O
actions	O
are	O
selected	O
by	O
the	O
policy	O
.	O
	
The	O
optimal	O
value	O
is	O
.	O
	
To	O
scale	O
to	O
large	O
problems	O
,	O
we	O
learn	O
a	O
parameterized	B-Method
estimate	I-Method
of	I-Method
the	I-Method
Q	I-Method
-	I-Method
value	I-Method
function	I-Method
rather	O
than	O
a	O
tabular	B-Method
encoding	I-Method
.	O
	
We	O
use	O
a	O
neural	B-Method
network	I-Method
to	O
estimate	O
this	O
value	O
.	O
	
The	O
Q	B-Method
-	I-Method
learning	I-Method
update	I-Method
from	O
state	O
,	O
action	O
,	O
reward	O
and	O
new	O
state	O
is	O
given	O
by	O
where	O
is	O
the	O
scalar	B-Metric
learning	I-Metric
rate	I-Metric
and	O
is	O
the	O
target	O
value	O
.	O
are	O
target	O
network	O
parameters	O
fixed	O
.	O
	
Several	O
important	O
modifications	O
to	O
the	O
Q	B-Method
-	I-Method
learning	I-Method
update	I-Method
improve	O
stability	B-Task
for	O
DQN	B-Method
.	O
	
First	O
the	O
algorithm	O
learns	O
from	O
sampled	O
transitions	O
from	O
an	O
experience	O
buffer	O
,	O
rather	O
than	O
learning	O
fully	O
online	O
.	O
	
Second	O
the	O
algorithm	O
uses	O
a	O
target	B-Method
network	I-Method
with	O
parameters	O
that	O
are	O
copied	O
from	O
the	O
learning	B-Method
network	I-Method
only	O
every	O
time	O
steps	O
and	O
then	O
kept	O
fixed	O
in	O
between	O
updates	O
.	O
	
Double	O
DQN	B-Method
modifies	O
the	O
target	O
and	O
helps	O
further	O
:	O
Bootstrapped	B-Method
DQN	I-Method
modifies	O
DQN	B-Method
to	O
approximate	O
a	O
distribution	O
over	O
Q	O
-	O
values	O
via	O
the	O
bootstrap	B-Method
.	O
	
At	O
the	O
start	O
of	O
each	O
episode	O
,	O
bootstrapped	B-Method
DQN	I-Method
samples	O
a	O
single	O
Q	B-Method
-	I-Method
value	I-Method
function	I-Method
from	O
its	O
approximate	O
posterior	O
.	O
	
The	O
agent	O
then	O
follows	O
the	O
policy	O
which	O
is	O
optimal	O
for	O
that	O
sample	O
for	O
the	O
duration	O
of	O
the	O
episode	O
.	O
	
This	O
is	O
a	O
natural	O
adaptation	O
of	O
the	O
Thompson	B-Method
sampling	I-Method
heuristic	I-Method
to	O
RL	B-Task
that	O
allows	O
for	O
temporally	B-Task
extended	I-Task
(	I-Task
or	I-Task
deep	I-Task
)	I-Task
exploration	I-Task
.	O
	
We	O
implement	O
this	O
algorithm	O
efficiently	O
by	O
building	O
up	O
bootstrapped	B-Method
estimates	I-Method
of	O
the	O
Q	B-Method
-	I-Method
value	I-Method
function	I-Method
in	O
parallel	O
as	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Importantly	O
,	O
each	O
one	O
of	O
these	O
value	B-Method
function	I-Method
function	I-Method
heads	I-Method
is	O
trained	O
against	O
its	O
own	O
target	O
network	O
.	O
	
This	O
means	O
that	O
each	O
provide	O
a	O
temporally	O
extended	O
(	O
and	O
consistent	O
)	O
estimate	O
of	O
the	O
value	O
uncertainty	O
via	O
TD	B-Method
estimates	I-Method
.	O
	
In	O
order	O
to	O
keep	O
track	O
of	O
which	O
data	O
belongs	O
to	O
which	O
bootstrap	B-Method
head	O
we	O
store	O
flags	O
indicating	O
which	O
heads	O
are	O
privy	O
to	O
which	O
data	O
.	O
	
We	O
approximate	O
a	O
bootstrap	B-Method
sample	I-Method
by	O
selecting	O
uniformly	O
at	O
random	O
and	O
following	O
for	O
the	O
duration	O
of	O
that	O
episode	O
.	O
	
We	O
present	O
a	O
detailed	O
algorithm	O
for	O
our	O
implementation	O
of	O
bootstrapped	B-Method
DQN	I-Method
in	O
Appendix	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
Related	O
work	O
	
The	O
observation	O
that	O
temporally	B-Task
extended	I-Task
exploration	I-Task
is	O
necessary	O
for	O
efficient	O
reinforcement	B-Task
learning	I-Task
is	O
not	O
new	O
.	O
	
For	O
any	O
prior	O
distribution	O
over	O
MDPs	B-Method
,	O
the	O
optimal	O
exploration	B-Method
strategy	I-Method
is	O
available	O
through	O
dynamic	B-Method
programming	I-Method
in	O
the	O
Bayesian	O
belief	O
state	O
space	O
.	O
	
However	O
,	O
the	O
exact	O
solution	O
is	O
intractable	O
even	O
for	O
very	O
simple	O
systems	O
.	O
	
Many	O
successful	O
RL	B-Task
applications	O
focus	O
on	O
generalization	B-Task
and	I-Task
planning	I-Task
but	O
address	O
exploration	B-Task
only	O
via	O
inefficient	O
exploration	O
or	O
even	O
none	O
at	O
all	O
.	O
	
However	O
,	O
such	O
exploration	B-Method
strategies	I-Method
can	O
be	O
highly	O
inefficient	O
.	O
	
Many	O
exploration	B-Method
strategies	I-Method
are	O
guided	O
by	O
the	O
principle	O
of	O
‘	O
	
‘	O
optimism	O
in	O
the	O
face	O
of	O
uncertainty	O
’	O
’	O
(	O
OFU	O
)	O
.	O
	
These	O
algorithms	O
add	O
an	O
exploration	O
bonus	O
to	O
values	O
of	O
state	O
-	O
action	O
pairs	O
that	O
may	O
lead	O
to	O
useful	O
learning	O
and	O
select	O
actions	O
to	O
maximize	O
these	O
adjusted	O
values	O
.	O
	
This	O
approach	O
was	O
first	O
proposed	O
for	O
finite	B-Task
-	I-Task
armed	I-Task
bandits	I-Task
,	O
but	O
the	O
principle	O
has	O
been	O
extended	O
successfully	O
across	O
bandits	B-Method
with	O
generalization	O
and	O
tabular	O
RL	B-Task
.	O
	
Except	O
for	O
particular	O
deterministic	O
contexts	O
,	O
OFU	B-Method
methods	I-Method
that	O
lead	O
to	O
efficient	O
RL	B-Task
in	O
complex	O
domains	O
have	O
been	O
computationally	O
intractable	O
.	O
	
The	O
work	O
of	O
aims	O
to	O
add	O
an	O
effective	O
bonus	O
through	O
a	O
variation	O
of	O
DQN	B-Method
.	O
	
The	O
resulting	O
algorithm	O
relies	O
on	O
a	O
large	O
number	O
of	O
hand	O
-	O
tuned	O
parameters	O
and	O
is	O
only	O
suitable	O
for	O
application	O
to	O
deterministic	B-Task
problems	I-Task
.	O
	
We	O
compare	O
our	O
results	O
on	O
Atari	B-Material
to	O
theirs	O
in	O
Appendix	O
[	O
reference	O
]	O
and	O
find	O
that	O
bootstrapped	B-Method
DQN	I-Method
offers	O
a	O
significant	O
improvement	O
over	O
previous	O
methods	O
.	O
	
Perhaps	O
the	O
oldest	O
heuristic	O
for	O
balancing	B-Task
exploration	I-Task
with	I-Task
exploitation	I-Task
is	O
given	O
by	O
Thompson	B-Method
sampling	I-Method
.	O
	
This	O
bandit	B-Method
algorithm	I-Method
takes	O
a	O
single	O
sample	O
from	O
the	O
posterior	O
at	O
every	O
time	O
step	O
and	O
chooses	O
the	O
action	O
which	O
is	O
optimal	O
for	O
that	O
time	O
step	O
.	O
	
To	O
apply	O
the	O
Thompson	B-Method
sampling	I-Method
principle	I-Method
to	O
RL	B-Task
,	O
an	O
agent	O
should	O
sample	O
a	O
value	O
function	O
from	O
its	O
posterior	O
.	O
	
Naive	O
applications	O
of	O
Thompson	B-Method
sampling	I-Method
to	O
RL	B-Task
which	O
resample	O
every	O
timestep	O
can	O
be	O
extremely	O
inefficient	O
.	O
	
The	O
agent	O
must	O
also	O
commit	O
to	O
this	O
sample	O
for	O
several	O
time	O
steps	O
in	O
order	O
to	O
achieve	O
deep	B-Task
exploration	I-Task
.	O
	
The	O
algorithm	O
PSRL	B-Method
does	O
exactly	O
this	O
,	O
with	O
state	O
of	O
the	O
art	O
guarantees	O
.	O
	
However	O
,	O
this	O
algorithm	O
still	O
requires	O
solving	O
a	O
single	O
known	O
MDP	B-Method
,	O
which	O
will	O
usually	O
be	O
intractable	O
for	O
large	O
systems	O
.	O
	
Our	O
new	O
algorithm	O
,	O
bootstrapped	B-Method
DQN	I-Method
,	O
approximates	O
this	O
approach	O
to	O
exploration	B-Task
via	O
randomized	O
value	O
functions	O
sampled	O
from	O
an	O
approximate	O
posterior	O
.	O
	
Recently	O
,	O
authors	O
have	O
proposed	O
the	O
RLSVI	B-Method
algorithm	I-Method
which	O
accomplishes	O
this	O
for	O
linearly	O
parameterized	O
value	O
functions	O
.	O
	
Surprisingly	O
,	O
RLSVI	B-Method
recovers	O
state	O
of	O
the	O
art	O
guarantees	B-Metric
in	O
the	O
setting	O
with	O
tabular	O
basis	O
functions	O
,	O
but	O
its	O
performance	O
is	O
crucially	O
dependent	O
upon	O
a	O
suitable	O
linear	B-Method
representation	I-Method
of	I-Method
the	I-Method
value	I-Method
function	I-Method
.	O
	
We	O
extend	O
these	O
ideas	O
to	O
produce	O
an	O
algorithm	O
that	O
can	O
simultaneously	O
perform	O
generalization	B-Task
and	I-Task
exploration	I-Task
with	O
a	O
flexible	O
nonlinear	B-Method
value	I-Method
function	I-Method
representation	I-Method
.	O
	
Our	O
method	O
is	O
simple	O
,	O
general	O
and	O
compatible	O
with	O
almost	O
all	O
advances	O
in	O
deep	O
RL	B-Task
at	O
low	B-Metric
computational	I-Metric
cost	I-Metric
and	O
with	O
few	O
tuning	O
parameters	O
.	O
	
section	O
:	O
Deep	B-Task
Exploration	I-Task
	
Uncertainty	B-Task
estimates	I-Task
allow	O
an	O
agent	O
to	O
direct	O
its	O
exploration	O
at	O
potentially	O
informative	O
states	O
and	O
actions	O
.	O
	
In	O
bandits	B-Method
,	O
this	O
choice	O
of	O
directed	B-Method
exploration	I-Method
rather	O
than	O
dithering	B-Method
generally	O
categorizes	O
efficient	B-Method
algorithms	I-Method
.	O
	
The	O
story	O
in	O
RL	B-Task
is	O
not	O
as	O
simple	O
,	O
directed	B-Task
exploration	I-Task
is	O
not	O
enough	O
to	O
guarantee	O
efficiency	O
;	O
the	O
exploration	B-Task
must	O
also	O
be	O
deep	O
.	O
	
Deep	B-Task
exploration	I-Task
means	O
exploration	B-Task
which	O
is	O
directed	O
over	O
multiple	O
time	O
steps	O
;	O
it	O
can	O
also	O
be	O
called	O
‘	O
‘	O
planning	O
to	O
learn	O
’	O
’	O
or	O
‘	O
‘	O
far	O
-	O
sighted	O
’	O
’	O
exploration	B-Task
.	O
	
Unlike	O
bandit	B-Task
problems	I-Task
,	O
which	O
balance	O
actions	O
which	O
are	O
immediately	O
rewarding	O
or	O
immediately	O
informative	O
,	O
RL	B-Task
settings	O
require	O
planning	O
over	O
several	O
time	O
steps	O
.	O
	
For	O
exploitation	B-Task
,	O
this	O
means	O
that	O
an	O
efficient	O
agent	O
must	O
consider	O
the	O
future	O
rewards	O
over	O
several	O
time	O
steps	O
and	O
not	O
simply	O
the	O
myopic	O
rewards	O
.	O
	
In	O
exactly	O
the	O
same	O
way	O
,	O
efficient	O
exploration	B-Task
may	O
require	O
taking	O
actions	O
which	O
are	O
neither	O
immediately	O
rewarding	O
,	O
nor	O
immediately	O
informative	O
.	O
	
To	O
illustrate	O
this	O
distinction	O
,	O
consider	O
a	O
simple	O
deterministic	B-Method
chain	I-Method
with	O
three	O
step	O
horizon	O
starting	O
from	O
state	O
.	O
	
This	O
MDP	B-Method
is	O
known	O
to	O
the	O
agent	O
a	O
priori	O
,	O
with	O
deterministic	O
actions	O
	
‘	O
‘	O
left	O
’	O
’	O
and	O
‘	O
‘	O
right	O
’	O
’	O
.	O
	
All	O
states	O
have	O
zero	O
reward	O
,	O
except	O
for	O
the	O
leftmost	O
state	O
which	O
has	O
known	O
reward	O
and	O
the	O
rightmost	O
state	O
which	O
is	O
unknown	O
.	O
	
In	O
order	O
to	O
reach	O
either	O
a	O
rewarding	O
state	O
or	O
an	O
informative	O
state	O
within	O
three	O
steps	O
from	O
the	O
agent	O
must	O
plan	O
a	O
consistent	B-Method
strategy	I-Method
over	O
several	O
time	O
steps	O
.	O
	
Figure	O
[	O
reference	O
]	O
depicts	O
the	O
planning	B-Task
and	I-Task
look	I-Task
ahead	I-Task
trees	I-Task
for	O
several	O
algorithmic	B-Method
approaches	I-Method
in	O
this	O
example	O
MDP	B-Method
.	O
	
The	O
action	O
	
‘	O
	
‘	O
left	O
’	O
’	O
is	O
gray	O
,	O
the	O
action	O
	
‘	O
‘	O
	
right	O
’	O
’	O
is	O
black	O
.	O
	
Rewarding	O
states	O
are	O
depicted	O
as	O
red	O
,	O
informative	O
states	O
as	O
blue	O
.	O
	
Dashed	O
lines	O
indicate	O
that	O
the	O
agent	O
can	O
plan	O
ahead	O
for	O
either	O
rewards	O
or	O
information	O
.	O
	
Unlike	O
bandit	B-Method
algorithms	I-Method
,	O
an	O
RL	B-Task
agent	O
can	O
plan	O
to	O
exploit	O
future	O
rewards	O
.	O
	
Only	O
an	O
RL	B-Task
agent	O
with	O
deep	B-Method
exploration	I-Method
can	O
plan	O
to	O
learn	O
.	O
	
[	O
	
b	O
]	O
0.99	O
[	O
b	O
]	O
0.23	O
	
[	O
b	O
]	O
0.23	O
	
[	O
b	O
]	O
0.23	O
	
[	O
b	O
]	O
0.23	O
	
subsection	O
:	O
Testing	O
for	O
deep	B-Task
exploration	I-Task
	
We	O
now	O
present	O
a	O
series	O
of	O
didactic	O
computational	O
experiments	O
designed	O
to	O
highlight	O
the	O
need	O
for	O
deep	B-Task
exploration	I-Task
.	O
	
These	O
environments	O
can	O
be	O
described	O
by	O
chains	O
of	O
length	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Each	O
episode	O
of	O
interaction	O
lasts	O
steps	O
after	O
which	O
point	O
the	O
agent	O
resets	O
to	O
the	O
initial	O
state	O
.	O
	
These	O
are	O
toy	B-Task
problems	I-Task
intended	O
to	O
be	O
expository	O
rather	O
than	O
entirely	O
realistic	O
.	O
	
Balancing	O
a	O
well	O
known	O
and	O
mildly	O
successful	O
strategy	O
versus	O
an	O
unknown	O
,	O
but	O
potentially	O
more	O
rewarding	O
,	O
approach	O
can	O
emerge	O
in	O
many	O
practical	O
applications	O
.	O
	
These	O
environments	O
may	O
be	O
described	O
by	O
a	O
finite	B-Method
tabular	I-Method
MDP	I-Method
.	O
	
However	O
,	O
we	O
consider	O
algorithms	O
which	O
interact	O
with	O
the	O
MDP	B-Method
only	O
through	O
raw	O
pixel	O
features	O
.	O
	
We	O
consider	O
two	O
feature	O
mappings	O
and	O
in	O
.	O
	
We	O
present	O
results	O
for	O
,	O
which	O
worked	O
better	O
for	O
all	O
DQN	B-Method
variants	O
due	O
to	O
better	O
generalization	B-Task
,	O
but	O
the	O
difference	O
was	O
relatively	O
small	O
-	O
see	O
Appendix	O
[	O
reference	O
]	O
.	O
	
Thompson	O
DQN	B-Method
is	O
the	O
same	O
as	O
bootstrapped	B-Method
DQN	I-Method
,	O
but	O
resamples	O
every	O
timestep	O
.	O
	
Ensemble	O
DQN	B-Method
uses	O
the	O
same	O
architecture	O
as	O
bootstrapped	B-Method
DQN	I-Method
,	O
but	O
with	O
an	O
ensemble	B-Method
policy	I-Method
.	O
	
We	O
say	O
that	O
the	O
algorithm	O
has	O
successfully	O
learned	O
the	O
optimal	B-Method
policy	I-Method
when	O
it	O
has	O
successfully	O
completed	O
one	O
hundred	O
episodes	O
with	O
optimal	O
reward	O
of	O
.	O
	
For	O
each	O
chain	O
length	O
,	O
we	O
ran	O
each	O
learning	B-Method
algorithm	I-Method
for	O
2000	O
episodes	O
across	O
three	O
seeds	O
.	O
	
We	O
plot	O
the	O
median	B-Metric
time	I-Metric
to	O
learn	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
together	O
with	O
a	O
conservative	O
lower	O
bound	O
of	O
on	O
the	O
expected	O
time	O
to	O
learn	O
for	O
any	O
shallow	B-Method
exploration	I-Method
strategy	I-Method
.	O
	
Only	O
bootstrapped	B-Method
DQN	I-Method
demonstrates	O
a	O
graceful	O
scaling	O
to	O
long	O
chains	O
which	O
require	O
deep	O
exploration	O
.	O
	
subsection	O
:	O
How	O
does	O
bootstrapped	B-Method
DQN	I-Method
drive	O
deep	B-Task
exploration	I-Task
?	O
	
Bootstrapped	B-Method
DQN	I-Method
explores	O
in	O
a	O
manner	O
similar	O
to	O
the	O
provably	O
-	O
efficient	O
algorithm	B-Method
PSRL	I-Method
	
but	O
it	O
uses	O
a	O
bootstrapped	B-Method
neural	I-Method
network	I-Method
to	O
approximate	O
a	O
posterior	O
sample	O
for	O
the	O
value	O
.	O
	
Unlike	O
PSRL	B-Method
,	O
bootstrapped	B-Method
DQN	I-Method
directly	O
samples	O
a	O
value	B-Method
function	I-Method
and	O
so	O
does	O
not	O
require	O
further	O
planning	O
steps	O
.	O
	
This	O
algorithm	O
is	O
similar	O
to	O
RLSVI	B-Method
,	O
which	O
is	O
also	O
provably	O
-	O
efficient	O
,	O
but	O
with	O
a	O
neural	B-Method
network	I-Method
instead	O
of	O
linear	B-Method
value	I-Method
function	I-Method
and	O
bootstrap	B-Method
instead	O
of	O
Gaussian	B-Method
sampling	I-Method
.	O
	
The	O
analysis	O
for	O
the	O
linear	B-Task
setting	I-Task
suggests	O
that	O
this	O
nonlinear	B-Method
approach	I-Method
will	O
work	O
well	O
so	O
long	O
as	O
the	O
distribution	O
remains	O
stochastically	O
optimistic	O
,	O
or	O
at	O
least	O
as	O
spread	O
out	O
as	O
the	O
‘	O
‘	O
	
correct	O
’	O
’	O
posterior	O
.	O
	
Bootstrapped	B-Method
DQN	I-Method
relies	O
upon	O
random	B-Method
initialization	I-Method
of	O
the	O
network	O
weights	O
as	O
a	O
prior	O
to	O
induce	O
diversity	O
.	O
	
Surprisingly	O
,	O
we	O
found	O
this	O
initial	O
diversity	O
was	O
enough	O
to	O
maintain	O
diverse	O
generalization	O
to	O
new	O
and	O
unseen	O
states	O
for	O
large	B-Method
and	I-Method
deep	I-Method
neural	I-Method
networks	I-Method
.	O
	
This	O
is	O
effective	O
for	O
our	O
experimental	O
setting	O
,	O
but	O
will	O
not	O
work	O
in	O
all	O
situations	O
.	O
	
In	O
general	O
it	O
may	O
be	O
necessary	O
to	O
maintain	O
some	O
more	O
rigorous	O
notion	O
of	O
‘	O
	
‘	O
prior	O
’	O
’	O
,	O
potentially	O
through	O
the	O
use	O
of	O
artificial	O
prior	O
data	O
to	O
maintain	O
diversity	O
.	O
	
One	O
potential	O
explanation	O
for	O
the	O
efficacy	O
of	O
simple	O
random	B-Method
initialization	I-Method
is	O
that	O
unlike	O
supervised	B-Method
learning	I-Method
or	O
bandits	B-Method
,	O
where	O
all	O
networks	O
fit	O
the	O
same	O
data	O
,	O
each	O
of	O
our	O
heads	O
has	O
a	O
unique	O
target	O
network	O
.	O
	
This	O
,	O
together	O
with	O
stochastic	B-Method
minibatch	I-Method
and	O
flexible	B-Method
nonlinear	I-Method
representations	I-Method
,	O
means	O
that	O
even	O
small	O
differences	O
at	O
initialization	O
may	O
become	O
bigger	O
as	O
they	O
refit	O
to	O
unique	O
TD	O
errors	O
.	O
	
Bootstrapped	B-Method
DQN	I-Method
does	O
not	O
require	O
that	O
any	O
single	O
network	O
is	O
initialized	O
to	O
the	O
correct	O
policy	O
of	O
‘	O
	
‘	O
right	O
’	O
’	O
at	O
every	O
step	O
,	O
which	O
would	O
be	O
exponentially	O
unlikely	O
for	O
large	O
chains	O
.	O
	
For	O
the	O
algorithm	O
to	O
be	O
successful	O
in	O
this	O
example	O
we	O
only	O
require	O
that	O
the	O
networks	O
generalize	O
in	O
a	O
diverse	O
way	O
to	O
the	O
actions	O
they	O
have	O
never	O
chosen	O
in	O
the	O
states	O
they	O
have	O
not	O
visited	O
very	O
often	O
.	O
	
Imagine	O
that	O
,	O
in	O
the	O
example	O
above	O
,	O
the	O
network	O
has	O
made	O
it	O
as	O
far	O
as	O
state	O
,	O
but	O
never	O
observed	O
the	O
action	O
right	O
.	O
	
As	O
long	O
as	O
one	O
head	O
imagines	O
then	O
TD	B-Method
bootstrapping	I-Method
can	O
propagate	O
this	O
signal	O
back	O
to	O
through	O
the	O
target	O
network	O
to	O
drive	O
deep	B-Task
exploration	I-Task
.	O
	
The	O
expected	O
time	O
for	O
these	O
estimates	O
at	O
to	O
propagate	O
to	O
at	O
least	O
one	O
head	O
grows	O
gracefully	O
in	O
,	O
even	O
for	O
relatively	O
small	O
,	O
as	O
our	O
experiments	O
show	O
.	O
	
We	O
expand	O
upon	O
this	O
intuition	O
with	O
a	O
video	O
designed	O
to	O
highlight	O
how	O
bootstrapped	B-Method
DQN	I-Method
demonstrates	O
deep	B-Task
exploration	I-Task
.	O
	
We	O
present	O
further	O
evaluation	O
on	O
a	O
difficult	O
stochastic	B-Task
MDP	I-Task
in	O
Appendix	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
Arcade	B-Method
Learning	I-Method
Environment	I-Method
	
We	O
now	O
evaluate	O
our	O
algorithm	O
across	O
49	O
Atari	B-Material
games	I-Material
on	O
the	O
Arcade	B-Task
Learning	I-Task
Environment	I-Task
.	O
	
Importantly	O
,	O
and	O
unlike	O
the	O
experiments	O
in	O
Section	O
[	O
reference	O
]	O
,	O
these	O
domains	O
are	O
not	O
specifically	O
designed	O
to	O
showcase	O
our	O
algorithm	O
.	O
	
In	O
fact	O
,	O
many	O
Atari	B-Material
games	I-Material
are	O
structured	O
so	O
that	O
small	O
rewards	O
always	O
indicate	O
part	O
of	O
an	O
optimal	B-Method
policy	I-Method
.	O
	
This	O
may	O
be	O
crucial	O
for	O
the	O
strong	O
performance	O
observed	O
by	O
dithering	B-Method
strategies	I-Method
.	O
	
We	O
find	O
that	O
exploration	O
via	O
bootstrapped	B-Method
DQN	I-Method
produces	O
significant	O
gains	O
versus	O
-	O
greedy	O
in	O
this	O
setting	O
.	O
	
Bootstrapped	B-Method
DQN	I-Method
reaches	O
peak	O
performance	O
roughly	O
similar	O
to	O
DQN	B-Method
.	O
	
However	O
,	O
our	O
improved	O
exploration	O
mean	O
we	O
reach	O
human	O
performance	O
on	O
average	O
30	O
%	O
faster	O
across	O
all	O
games	O
.	O
	
This	O
translates	O
to	O
significantly	O
improved	O
cumulative	O
rewards	O
through	O
learning	B-Task
.	O
	
We	O
follow	O
the	O
setup	O
of	O
for	O
our	O
network	B-Method
architecture	I-Method
and	O
benchmark	O
our	O
performance	O
against	O
their	O
algorithm	O
.	O
	
Our	O
network	B-Method
structure	I-Method
is	O
identical	O
to	O
the	O
convolutional	B-Method
structure	I-Method
of	O
DQN	B-Method
except	O
we	O
split	O
10	O
separate	O
bootstrap	B-Method
heads	O
after	O
the	O
convolutional	B-Method
layer	I-Method
as	O
per	O
Figure	O
[	O
reference	O
]	O
.	O
	
Recently	O
,	O
several	O
authors	O
have	O
provided	O
architectural	O
and	O
algorithmic	O
improvements	O
to	O
DDQN	B-Method
.	O
	
We	O
do	O
not	O
compare	O
our	O
results	O
to	O
these	O
since	O
their	O
advances	O
are	O
orthogonal	O
to	O
our	O
concern	O
and	O
could	O
easily	O
be	O
incorporated	O
to	O
our	O
bootstrapped	B-Method
DQN	I-Method
design	O
.	O
	
Full	O
details	O
of	O
our	O
experimental	O
set	O
up	O
are	O
available	O
in	O
Appendix	O
[	O
reference	O
]	O
.	O
	
subsection	O
:	O
Implementing	O
bootstrapped	B-Method
DQN	I-Method
at	O
scale	O
	
We	O
now	O
examine	O
how	O
to	O
generate	O
online	O
bootstrap	B-Method
samples	O
for	O
DQN	B-Method
in	O
a	O
computationally	O
efficient	O
manner	O
.	O
	
We	O
focus	O
on	O
three	O
key	O
questions	O
:	O
how	O
many	O
heads	O
do	O
we	O
need	O
,	O
how	O
should	O
we	O
pass	O
gradients	O
to	O
the	O
shared	O
network	O
and	O
how	O
should	O
we	O
bootstrap	B-Method
data	O
online	O
?	O
	
We	O
make	O
significant	O
compromises	O
in	O
order	O
to	O
maintain	O
computational	B-Metric
cost	I-Metric
comparable	O
to	O
DQN	B-Method
.	O
	
Figure	O
[	O
reference	O
]	O
presents	O
the	O
cumulative	O
reward	O
of	O
bootstrapped	B-Method
DQN	I-Method
on	O
the	O
game	B-Task
Breakout	I-Task
,	O
for	O
different	O
number	O
of	O
heads	O
.	O
	
More	O
heads	O
leads	O
to	O
faster	O
learning	B-Task
,	O
but	O
even	O
a	O
small	O
number	O
of	O
heads	O
captures	O
most	O
of	O
the	O
benefits	O
of	O
bootstrapped	B-Method
DQN	I-Method
.	O
	
We	O
choose	O
.	O
	
[	O
b	O
]	O
0.4	O
[	O
b	O
]	O
0.4	O
	
The	O
shared	B-Method
network	I-Method
architecture	I-Method
allows	O
us	O
to	O
train	O
this	O
combined	B-Method
network	I-Method
via	O
backpropagation	B-Method
.	O
	
Feeding	O
network	B-Method
heads	I-Method
to	O
the	O
shared	B-Method
convolutional	I-Method
network	I-Method
effectively	O
increases	O
the	O
learning	B-Metric
rate	I-Metric
for	O
this	O
portion	O
of	O
the	O
network	O
.	O
	
In	O
some	O
games	O
,	O
this	O
leads	O
to	O
premature	B-Task
and	I-Task
sub	I-Task
-	I-Task
optimal	I-Task
convergence	I-Task
.	O
	
We	O
found	O
the	O
best	O
final	O
scores	O
by	O
normalizing	O
the	O
gradients	O
by	O
,	O
but	O
this	O
also	O
leads	O
to	O
slower	O
early	B-Task
learning	I-Task
.	O
	
See	O
Appendix	O
[	O
reference	O
]	O
for	O
more	O
details	O
.	O
	
4mu	O
plus	O
2mu	O
minus	O
4mu=0mu	O
3	O
	
mu=0mu	O
5mu	O
plus	O
5mu=0mu	O
	
To	O
implement	O
an	O
online	O
bootstrap	B-Method
we	O
use	O
an	O
independent	O
Bernoulli	O
mask	O
for	O
each	O
head	O
in	O
each	O
episode	O
.	O
	
These	O
flags	O
are	O
stored	O
in	O
the	O
memory	O
replay	O
buffer	O
and	O
identify	O
which	O
heads	O
are	O
trained	O
on	O
which	O
data	O
.	O
	
However	O
,	O
when	O
trained	O
using	O
a	O
shared	B-Method
minibatch	I-Method
the	O
algorithm	O
will	O
also	O
require	O
an	O
effective	O
more	O
iterations	O
;	O
this	O
is	O
undesirable	O
computationally	O
.	O
	
Surprisingly	O
,	O
we	O
found	O
the	O
algorithm	O
performed	O
similarly	O
irrespective	O
of	O
and	O
all	O
outperformed	O
DQN	B-Method
,	O
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
This	O
is	O
strange	O
and	O
we	O
discuss	O
this	O
phenomenon	O
in	O
Appendix	O
[	O
reference	O
]	O
.	O
	
However	O
,	O
in	O
light	O
of	O
this	O
empirical	O
observation	O
for	O
Atari	B-Material
,	O
we	O
chose	O
to	O
save	O
on	O
minibatch	O
passes	O
.	O
	
As	O
a	O
result	O
bootstrapped	B-Method
DQN	I-Method
runs	O
at	O
similar	O
computational	B-Metric
speed	I-Metric
to	O
vanilla	O
DQN	B-Method
on	O
identical	O
hardware	O
.	O
	
subsection	O
:	O
Efficient	O
exploration	B-Task
in	O
Atari	B-Material
	
We	O
find	O
that	O
Bootstrapped	B-Method
DQN	I-Method
drives	O
efficient	O
exploration	B-Task
in	O
several	O
Atari	B-Material
games	I-Material
.	O
	
For	O
the	O
same	O
amount	O
of	O
game	O
experience	O
,	O
bootstrapped	B-Method
DQN	I-Method
generally	O
outperforms	O
DQN	B-Method
with	O
-	O
greedy	O
exploration	O
.	O
	
Figure	O
[	O
reference	O
]	O
demonstrates	O
this	O
effect	O
for	O
a	O
diverse	O
selection	O
of	O
games	O
.	O
	
On	O
games	O
where	O
DQN	B-Method
performs	O
well	O
,	O
bootstrapped	B-Method
DQN	I-Method
typically	O
performs	O
better	O
.	O
	
Bootstrapped	B-Method
DQN	I-Method
does	O
not	O
reach	O
human	O
performance	O
on	O
Amidar	B-Method
(	O
DQN	B-Method
does	O
)	O
but	O
does	O
on	O
Beam	B-Task
Rider	I-Task
and	O
Battle	B-Task
Zone	I-Task
	
(	O
DQN	B-Method
does	O
not	O
)	O
.	O
	
To	O
summarize	O
this	O
improvement	O
in	O
learning	B-Metric
time	I-Metric
we	O
consider	O
the	O
number	O
of	O
frames	O
required	O
to	O
reach	O
human	O
performance	O
.	O
	
If	O
bootstrapped	B-Method
DQN	I-Method
reaches	O
human	O
performance	O
in	O
frames	O
of	O
DQN	B-Method
we	O
say	O
it	O
has	O
improved	O
by	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
that	O
Bootstrapped	B-Method
DQN	I-Method
typically	O
reaches	O
human	O
performance	O
significantly	O
faster	O
.	O
	
On	O
most	O
games	O
where	O
DQN	B-Method
does	O
not	O
reach	O
human	O
performance	O
,	O
bootstrapped	B-Method
DQN	I-Method
does	O
not	O
solve	O
the	O
problem	O
by	O
itself	O
.	O
	
On	O
some	O
challenging	O
Atari	B-Material
games	I-Material
where	O
deep	B-Task
exploration	I-Task
is	O
conjectured	O
to	O
be	O
important	O
our	O
results	O
are	O
not	O
entirely	O
successful	O
,	O
but	O
still	O
promising	O
.	O
	
In	O
Frostbite	B-Method
,	O
bootstrapped	B-Method
DQN	I-Method
reaches	O
the	O
second	O
level	O
much	O
faster	O
than	O
DQN	B-Method
but	O
network	O
instabilities	O
cause	O
the	O
performance	O
to	O
crash	O
.	O
	
In	O
Montezuma	B-Task
’s	I-Task
Revenge	I-Task
,	O
bootstrapped	B-Method
DQN	I-Method
reaches	O
the	O
first	O
key	O
after	O
20	O
m	O
frames	O
(	O
DQN	B-Method
never	O
observes	O
a	O
reward	O
even	O
after	O
200	O
m	O
frames	O
)	O
but	O
does	O
not	O
properly	O
learn	O
from	O
this	O
experience	O
.	O
	
Our	O
results	O
suggest	O
that	O
improved	O
exploration	B-Task
may	O
help	O
to	O
solve	O
these	O
remaining	O
games	O
,	O
but	O
also	O
highlight	O
the	O
importance	O
of	O
other	O
problems	O
like	O
network	O
instability	O
,	O
reward	O
clipping	O
and	O
temporally	O
extended	O
rewards	O
.	O
	
subsection	O
:	O
Overall	O
performance	O
	
Bootstrapped	B-Method
DQN	I-Method
is	O
able	O
to	O
learn	O
much	O
faster	O
than	O
DQN	B-Method
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
that	O
bootstrapped	O
	
DQN	B-Method
also	O
improves	O
upon	O
the	O
final	O
score	B-Metric
across	O
most	O
games	O
.	O
	
However	O
,	O
the	O
real	O
benefits	O
to	O
efficient	O
exploration	B-Task
mean	O
that	O
bootstrapped	B-Method
DQN	I-Method
outperforms	O
DQN	B-Method
by	O
orders	O
of	O
magnitude	O
in	O
terms	O
of	O
the	O
cumulative	B-Metric
rewards	I-Metric
through	O
learning	B-Task
(	O
Figure	O
[	O
reference	O
]	O
.	O
	
In	O
both	O
figures	O
we	O
normalize	O
performance	O
relative	O
to	O
a	O
fully	B-Method
random	I-Method
policy	I-Method
.	O
	
The	O
most	O
similar	O
work	O
to	O
ours	O
presents	O
several	O
other	O
approaches	O
to	O
improved	O
exploration	B-Task
in	O
Atari	B-Material
they	O
optimize	O
for	O
AUC	B-Metric
-	I-Metric
20	I-Metric
,	O
a	O
normalized	O
version	O
of	O
the	O
cumulative	O
returns	O
after	O
20	O
m	O
frames	O
.	O
	
According	O
to	O
their	O
metric	O
,	O
averaged	O
across	O
the	O
14	O
games	O
they	O
consider	O
,	O
we	O
improve	O
upon	O
both	O
base	O
DQN	B-Method
(	O
0.29	O
)	O
and	O
their	O
best	O
method	O
(	O
0.37	O
)	O
to	O
obtain	O
0.62	O
via	O
bootstrapped	B-Method
DQN	I-Method
.	O
	
We	O
present	O
these	O
results	O
together	O
with	O
results	O
tables	O
across	O
all	O
49	O
games	O
in	O
Appendix	O
[	O
reference	O
]	O
.	O
	
subsection	O
:	O
Visualizing	O
bootstrapped	B-Method
DQN	I-Method
	
We	O
now	O
present	O
some	O
more	O
insight	O
to	O
how	O
bootstrapped	B-Method
DQN	I-Method
drives	O
deep	B-Task
exploration	I-Task
in	O
Atari	B-Material
.	O
	
In	O
each	O
game	O
,	O
although	O
each	O
head	O
learns	O
a	O
high	O
scoring	O
policy	O
,	O
the	O
policies	O
they	O
find	O
are	O
quite	O
distinct	O
.	O
	
In	O
the	O
video	O
we	O
show	O
the	O
evolution	O
of	O
these	O
policies	O
simultaneously	O
for	O
several	O
games	O
.	O
	
Although	O
each	O
head	O
performs	O
well	O
,	O
they	O
each	O
follow	O
a	O
unique	O
policy	O
.	O
	
By	O
contrast	O
,	O
-	B-Method
greedy	I-Method
strategies	I-Method
are	O
almost	O
indistinguishable	O
for	O
small	O
values	O
of	O
and	O
totally	O
ineffectual	O
for	O
larger	O
values	O
.	O
	
We	O
believe	O
that	O
this	O
deep	B-Method
exploration	I-Method
is	O
key	O
to	O
improved	O
learning	B-Task
,	O
since	O
diverse	O
experiences	O
allow	O
for	O
better	O
generalization	B-Task
.	O
	
Disregarding	O
exploration	B-Method
,	O
bootstrapped	B-Method
DQN	I-Method
may	O
be	O
beneficial	O
as	O
a	O
purely	O
exploitative	B-Method
policy	I-Method
.	O
	
We	O
can	O
combine	O
all	O
the	O
heads	O
into	O
a	O
single	O
ensemble	B-Method
policy	I-Method
,	O
for	O
example	O
by	O
choosing	O
the	O
action	O
with	O
the	O
most	O
votes	O
across	O
heads	O
.	O
	
This	O
approach	O
might	O
have	O
several	O
benefits	O
.	O
	
First	O
,	O
we	O
find	O
that	O
the	O
ensemble	B-Method
policy	I-Method
can	O
often	O
outperform	O
any	O
individual	B-Method
policy	I-Method
.	O
	
Second	O
,	O
the	O
distribution	O
of	O
votes	O
across	O
heads	O
to	O
give	O
a	O
measure	O
of	O
the	O
uncertainty	O
in	O
the	O
optimal	B-Task
policy	I-Task
.	O
	
Unlike	O
vanilla	O
DQN	B-Method
,	O
bootstrapped	B-Method
DQN	I-Method
can	O
know	O
what	O
it	O
does	O
n’t	O
know	O
.	O
	
In	O
an	O
application	O
where	O
executing	O
a	O
poorly	O
-	O
understood	O
action	O
is	O
dangerous	O
this	O
could	O
be	O
crucial	O
.	O
	
In	O
the	O
video	O
we	O
visualize	O
this	O
ensemble	B-Method
policy	I-Method
across	O
several	O
games	O
.	O
	
We	O
find	O
that	O
the	O
uncertainty	O
in	O
this	O
policy	O
is	O
surprisingly	O
interpretable	O
:	O
all	O
heads	O
agree	O
at	O
clearly	O
crucial	O
decision	O
points	O
,	O
but	O
remain	O
diverse	O
at	O
other	O
less	O
important	O
steps	O
.	O
	
section	O
:	O
Closing	O
remarks	O
	
In	O
this	O
paper	O
we	O
present	O
bootstrapped	B-Method
DQN	I-Method
as	O
an	O
algorithm	O
for	O
efficient	O
reinforcement	B-Task
learning	I-Task
in	O
complex	B-Task
environments	I-Task
.	O
	
We	O
demonstrate	O
that	O
the	O
bootstrap	B-Method
can	O
produce	O
useful	O
uncertainty	B-Task
estimates	I-Task
for	O
deep	B-Method
neural	I-Method
networks	I-Method
.	O
	
Bootstrapped	B-Method
DQN	I-Method
is	O
computationally	O
tractable	O
and	O
also	O
naturally	O
scalable	O
to	O
massive	B-Task
parallel	I-Task
systems	I-Task
.	O
	
We	O
believe	O
that	O
,	O
beyond	O
our	O
specific	O
implementation	O
,	O
randomized	B-Method
value	I-Method
functions	I-Method
represent	O
a	O
promising	O
alternative	O
to	O
dithering	O
for	O
exploration	B-Task
.	O
	
Bootstrapped	B-Method
DQN	I-Method
practically	O
combines	O
efficient	O
generalization	B-Method
with	O
exploration	B-Task
for	O
complex	O
nonlinear	O
value	O
functions	O
.	O
	
bibliography	O
:	O
References	O
	
APPENDICES	O
	
appendix	O
:	O
Uncertainty	O
for	O
neural	B-Method
networks	I-Method
	
In	O
this	O
appendix	O
we	O
discuss	O
some	O
of	O
the	O
experimental	O
setup	O
to	O
qualitatively	O
evaluate	O
uncertainty	B-Method
methods	I-Method
for	O
deep	B-Method
neural	I-Method
networks	I-Method
.	O
	
To	O
do	O
this	O
,	O
we	O
generated	O
twenty	O
noisy	O
regression	O
pairs	O
with	O
:	O
where	O
are	O
drawn	O
uniformly	O
from	O
	
and	O
.	O
	
We	O
set	O
and	O
.	O
	
None	O
of	O
these	O
numerical	O
choices	O
were	O
important	O
except	O
to	O
represent	O
a	O
highly	O
nonlinear	O
function	O
with	O
lots	O
of	O
noise	O
and	O
several	O
clear	O
regions	O
where	O
we	O
should	O
be	O
uncertain	O
.	O
	
We	O
present	O
the	O
regression	O
data	O
together	O
with	O
an	O
indication	O
of	O
the	O
generating	B-Method
distribution	I-Method
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Interestingly	O
,	O
we	O
did	O
not	O
find	O
that	O
using	O
dropout	B-Method
produced	O
satisfying	O
confidence	O
intervals	O
for	O
this	O
task	O
.	O
	
We	O
present	O
one	O
example	O
of	O
this	O
dropout	B-Method
posterior	I-Method
estimate	I-Method
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
[	O
b	O
]	O
0.45	O
	
[	O
b	O
]	O
0.45	O
	
These	O
results	O
are	O
unsatisfactory	O
for	O
several	O
reasons	O
.	O
	
First	O
,	O
the	O
network	O
extrapolates	O
the	O
mean	O
posterior	O
far	O
outside	O
the	O
range	O
of	O
any	O
actual	O
data	O
for	O
.	O
	
We	O
believe	O
this	O
is	O
because	O
dropout	B-Method
only	O
perturbs	O
locally	O
from	O
a	O
single	O
neural	B-Method
network	I-Method
fit	I-Method
,	O
unlike	O
bootstrap	B-Method
.	O
	
Second	O
,	O
the	O
posterior	O
samples	O
from	O
the	O
dropout	B-Method
approximation	I-Method
are	O
very	O
spiky	O
and	O
do	O
not	O
look	O
like	O
any	O
sensible	O
posterior	O
sample	O
.	O
	
Third	O
,	O
the	O
network	O
collapses	O
to	O
almost	O
zero	O
uncertainty	O
in	O
regions	O
with	O
data	O
.	O
	
We	O
spent	O
some	O
time	O
altering	O
our	O
dropout	B-Method
scheme	I-Method
to	O
fix	O
this	O
effect	O
,	O
which	O
might	O
be	O
undesirable	O
for	O
stochastic	O
domains	O
and	O
we	O
believed	O
might	O
be	O
an	O
artefact	O
of	O
our	O
implementation	O
.	O
	
However	O
,	O
after	O
further	O
thought	O
we	O
believe	O
this	O
to	O
be	O
an	O
effect	O
which	O
you	O
would	O
expect	O
for	O
dropout	B-Method
posterior	I-Method
approximations	I-Method
.	O
	
In	O
Figure	O
[	O
reference	O
]	O
we	O
present	O
a	O
didactic	O
example	O
taken	O
from	O
the	O
author	O
’s	O
website	O
.	O
	
On	O
the	O
right	O
hand	O
side	O
of	O
the	O
plot	O
we	O
generate	O
noisy	O
data	O
with	O
wildly	O
different	O
values	O
.	O
	
Training	O
a	O
neural	B-Method
network	I-Method
using	O
MSE	B-Metric
criterion	I-Metric
means	O
that	O
the	O
network	O
will	O
surely	O
converge	O
to	O
the	O
mean	O
of	O
the	O
noisy	O
data	O
.	O
	
Any	O
dropout	O
samples	O
remain	O
highly	O
concentrated	O
around	O
this	O
mean	O
.	O
	
By	O
contrast	O
,	O
bootstrapped	B-Method
neural	I-Method
networks	I-Method
may	O
include	O
different	O
subsets	O
of	O
this	O
noisy	O
data	O
and	O
so	O
may	O
produce	O
a	O
more	O
intuitive	O
uncertainty	B-Metric
estimates	I-Metric
for	O
our	O
settings	O
.	O
	
Note	O
this	O
is	O
n’t	O
necessarily	O
a	O
failure	O
of	O
dropout	B-Method
to	O
approximate	O
a	O
Gaussian	B-Method
process	I-Method
posterior	I-Method
,	O
but	O
this	O
artefact	O
could	O
be	O
shared	O
by	O
any	O
homoskedastic	O
posterior	O
.	O
	
The	O
authors	O
of	O
propose	O
a	O
heteroskedastic	B-Method
variant	I-Method
which	O
can	O
help	O
,	O
but	O
does	O
not	O
address	O
the	O
fundamental	O
issue	O
that	O
for	O
large	B-Method
networks	I-Method
trained	O
to	O
convergence	O
all	O
dropout	O
samples	O
may	O
converge	O
to	O
every	O
single	O
datapoint	O
…	O
even	O
the	O
outliers	O
.	O
	
In	O
this	O
paper	O
we	O
focus	O
on	O
the	O
bootstrap	B-Method
approach	I-Method
to	O
uncertainty	B-Task
for	O
neural	B-Task
networks	I-Task
.	O
	
We	O
like	O
its	O
simplicity	O
,	O
connections	O
to	O
established	O
statistical	B-Method
methodology	I-Method
and	O
empirical	O
good	O
performance	O
.	O
	
However	O
,	O
the	O
key	O
insights	O
of	O
this	O
paper	O
is	O
the	O
use	O
of	O
deep	B-Method
exploration	I-Method
via	O
randomized	B-Method
value	I-Method
functions	I-Method
.	O
	
This	O
is	O
compatible	O
with	O
any	O
approximate	B-Method
posterior	I-Method
estimator	I-Method
for	O
deep	B-Method
neural	I-Method
networks	I-Method
.	O
	
We	O
believe	O
that	O
this	O
area	O
of	O
uncertainty	B-Task
estimates	I-Task
for	O
neural	B-Method
networks	I-Method
remains	O
an	O
important	O
area	O
of	O
research	O
in	O
its	O
own	O
right	O
.	O
	
Bootstrapped	B-Method
uncertainty	I-Method
estimates	I-Method
for	O
the	O
Q	B-Method
-	I-Method
value	I-Method
functions	I-Method
have	O
another	O
crucial	O
advantage	O
over	O
dropout	B-Method
which	O
does	O
not	O
appear	O
in	O
the	O
supervised	B-Task
problem	I-Task
.	O
	
Unlike	O
random	B-Method
dropout	I-Method
masks	I-Method
trained	O
against	O
random	B-Method
target	I-Method
networks	I-Method
,	O
our	O
implementation	O
of	O
bootstrap	B-Method
DQN	I-Method
trains	O
against	O
its	O
own	O
temporally	B-Method
consistent	I-Method
target	I-Method
network	I-Method
.	O
	
This	O
means	O
that	O
our	O
bootstrap	B-Method
estimates	I-Method
(	O
in	O
the	O
sense	O
of	O
)	O
,	O
are	O
able	O
to	O
‘	O
	
‘	O
bootstrap	B-Method
’	O
’	O
(	O
in	O
the	O
TD	O
sense	O
of	O
)	O
on	O
their	O
own	O
estimates	O
of	O
the	O
long	O
run	O
value	O
.	O
	
This	O
is	O
important	O
to	O
quantify	O
the	O
long	O
run	O
uncertainty	O
over	O
Q	O
and	O
drive	O
deep	B-Task
exploration	I-Task
.	O
	
appendix	O
:	O
Bootstrapped	B-Method
DQN	I-Method
implementation	O
	
Algorithm	O
[	O
reference	O
]	O
gives	O
a	O
full	O
description	O
of	O
Bootstrapped	B-Method
DQN	I-Method
.	O
	
It	O
captures	O
two	O
modes	O
of	O
operation	O
where	O
either	O
neural	B-Method
networks	I-Method
are	O
used	O
to	O
estimate	O
the	O
-	O
value	O
functions	O
,	O
or	O
where	O
one	O
neural	B-Method
network	I-Method
with	O
heads	B-Method
is	O
used	O
to	O
estimate	O
-	O
value	O
functions	O
.	O
	
In	O
both	O
cases	O
,	O
as	O
this	O
is	O
largely	O
a	O
parameterisation	B-Task
issue	I-Task
,	O
we	O
denote	O
the	O
value	B-Method
function	I-Method
networks	I-Method
as	O
,	O
where	O
is	O
output	O
of	O
the	O
th	O
network	O
or	O
the	O
th	O
head	O
.	O
	
A	O
core	O
idea	O
to	O
the	O
full	O
bootstrapped	B-Method
DQN	I-Method
algorithm	O
is	O
the	O
bootstrap	B-Method
mask	I-Method
.	O
	
The	O
mask	O
decides	O
,	O
for	O
each	O
value	O
function	O
,	O
whether	O
or	O
not	O
it	O
should	O
train	O
upon	O
the	O
experience	O
generated	O
at	O
step	O
.	O
	
In	O
its	O
simplest	O
form	O
is	O
a	O
binary	O
vector	O
of	O
length	O
,	O
masking	O
out	O
or	O
including	O
each	O
value	O
function	O
for	O
training	O
on	O
that	O
time	O
step	O
of	O
experience	O
(	O
i.e.	O
,	O
should	O
it	O
receive	O
gradients	O
from	O
the	O
corresponding	O
tuple	O
)	O
.	O
	
The	O
masking	B-Method
distribution	I-Method
is	O
responsible	O
for	O
generating	O
each	O
.	O
	
For	O
example	O
,	O
when	O
yields	O
whose	O
components	O
are	O
independently	O
drawn	O
from	O
a	O
bernoulli	O
distribution	O
with	O
parameter	O
then	O
this	O
corresponds	O
to	O
the	O
double	O
-	O
or	O
-	O
nothing	O
bootstrap	B-Method
.	O
	
On	O
the	O
other	O
hand	O
,	O
if	O
yields	O
a	O
mask	O
with	O
all	O
ones	O
,	O
then	O
the	O
algorithm	O
reduces	O
to	O
an	O
ensemble	B-Method
method	I-Method
.	O
	
Poisson	B-Method
masks	I-Method
provides	O
the	O
most	O
natural	O
parallel	O
with	O
the	O
standard	O
non	B-Method
-	I-Method
parameteric	I-Method
boostrap	I-Method
since	O
as	O
.	O
	
Exponential	O
masks	O
closely	O
resemble	O
the	O
standard	O
Bayesian	B-Method
nonparametric	I-Method
posterior	I-Method
of	I-Method
a	I-Method
Dirichlet	I-Method
process	I-Method
.	O
	
Bootstrapped	B-Method
DQN	I-Method
	
[	O
1	O
]	O
Input	O
:	O
Value	B-Method
function	I-Method
networks	I-Method
with	O
outputs	O
.	O
	
Masking	O
distribution	O
.	O
	
Let	O
be	O
a	O
replay	B-Method
buffer	I-Method
storing	O
experience	O
for	O
training	O
.	O
	
each	O
episode	O
Obtain	O
initial	O
state	O
from	O
environment	O
	
Pick	O
a	O
value	O
function	O
to	O
act	O
using	O
step	O
until	O
end	O
of	O
episode	O
Pick	O
an	O
action	O
according	O
to	O
Receive	O
state	O
and	O
reward	O
from	O
environment	O
,	O
having	O
taking	O
action	O
Sample	O
bootstrap	B-Method
mask	O
Add	O
to	O
replay	O
buffer	O
	
Periodically	O
,	O
the	O
replay	O
buffer	O
is	O
played	O
back	O
to	O
update	O
the	O
parameters	O
of	O
the	O
value	B-Method
function	I-Method
network	I-Method
.	O
	
The	O
gradients	O
of	O
the	O
th	O
value	O
function	O
for	O
the	O
th	O
tuple	O
in	O
the	O
replay	O
buffer	O
,	O
is	O
:	O
where	O
is	O
given	O
by	O
(	O
[	O
reference	O
]	O
)	O
.	O
	
Note	O
that	O
the	O
mask	O
modulates	O
the	O
gradient	O
,	O
giving	O
rise	O
to	O
the	O
bootstrap	B-Method
behaviour	O
.	O
	
appendix	O
:	O
Experiments	O
for	O
deep	B-Task
exploration	I-Task
	
subsection	O
:	O
Bootstrap	B-Method
methodology	I-Method
	
A	O
naive	O
implementation	O
of	O
bootstrapped	B-Method
DQN	I-Method
builds	O
up	O
complete	B-Method
networks	I-Method
with	O
distinct	O
memory	O
buffers	O
.	O
	
This	O
method	O
is	O
parallelizable	O
up	O
to	O
many	O
machines	O
,	O
however	O
we	O
wanted	O
to	O
produce	O
an	O
algorithm	O
that	O
was	O
efficient	O
even	O
on	O
a	O
single	O
machine	O
.	O
	
To	O
do	O
this	O
,	O
we	O
implemented	O
the	O
bootstrap	B-Method
heads	I-Method
in	O
a	O
single	O
larger	O
network	O
,	O
like	O
Figure	O
[	O
reference	O
]	O
but	O
without	O
any	O
shared	O
network	O
.	O
	
We	O
implement	O
bootstrap	B-Method
by	O
masking	O
each	O
episode	O
of	O
data	O
according	O
to	O
.	O
	
In	O
Figure	O
[	O
reference	O
]	O
we	O
demonstrate	O
that	O
bootstrapped	B-Method
DQN	I-Method
can	O
implement	O
deep	B-Task
exploration	I-Task
even	O
with	O
relatively	O
small	O
values	O
of	O
.	O
	
However	O
,	O
the	O
results	O
are	O
more	O
robust	O
and	O
scalable	O
with	O
larger	O
.	O
	
We	O
run	O
our	O
experiments	O
on	O
the	O
example	O
from	O
Figure	O
[	O
reference	O
]	O
.	O
	
Surprisingly	O
,	O
this	O
method	O
is	O
even	O
effective	O
with	O
and	O
complete	O
data	O
sharing	O
between	O
heads	O
.	O
	
This	O
degenerate	O
full	O
sharing	O
of	O
information	O
turns	O
out	O
to	O
be	O
remarkably	O
efficient	O
for	O
training	O
large	B-Task
and	I-Task
deep	I-Task
neural	I-Task
networks	I-Task
.	O
	
We	O
discuss	O
this	O
phenomenon	O
more	O
in	O
Appendix	O
[	O
reference	O
]	O
.	O
	
Generating	O
good	O
estimates	O
for	O
uncertainty	O
is	O
not	O
enough	O
for	O
efficient	O
exploration	B-Task
.	O
	
In	O
Figure	O
[	O
reference	O
]	O
we	O
see	O
that	O
other	O
methods	O
trained	O
with	O
the	O
same	O
network	B-Method
architecture	I-Method
are	O
totally	O
ineffective	O
at	O
implementing	O
deep	B-Task
exploration	I-Task
.	O
	
The	O
-	B-Method
greedy	I-Method
policy	I-Method
follows	O
just	O
one	O
-	O
value	O
estimate	O
.	O
	
We	O
allow	O
this	O
policy	O
to	O
be	O
evaluated	O
without	O
dithering	O
.	O
	
The	O
ensemble	B-Method
policy	I-Method
is	O
trained	O
exactly	O
as	O
per	O
bootstrapped	B-Method
DQN	I-Method
except	O
at	O
each	O
stage	O
the	O
algorithm	O
follows	O
the	O
policy	O
which	O
is	O
majority	O
vote	O
of	O
the	O
bootstrap	B-Method
heads	O
.	O
	
Thompson	B-Method
sampling	I-Method
is	O
the	O
same	O
as	O
bootstrapped	B-Method
DQN	I-Method
except	O
a	O
new	O
head	O
is	O
sampled	O
every	O
timestep	O
,	O
rather	O
than	O
every	O
episode	O
.	O
	
We	O
can	O
see	O
that	O
only	O
bootstrapped	B-Method
DQN	I-Method
demonstrates	O
efficient	O
and	O
deep	B-Task
exploration	I-Task
in	O
this	O
domain	O
.	O
	
subsection	O
:	O
A	O
difficult	O
stochastic	B-Method
MDP	I-Method
	
Figure	O
[	O
reference	O
]	O
shows	O
that	O
bootstrapped	B-Method
DQN	I-Method
can	O
implement	O
effective	O
(	O
and	O
deep	B-Task
)	I-Task
exploration	I-Task
where	O
similar	O
deep	O
RL	B-Task
architectures	O
fail	O
.	O
	
However	O
,	O
since	O
the	O
underlying	O
system	O
is	O
a	O
small	O
and	O
finite	B-Method
MDP	I-Method
there	O
may	O
be	O
several	O
other	O
simpler	O
strategies	O
which	O
would	O
also	O
solve	O
this	O
problem	O
.	O
	
We	O
will	O
now	O
consider	O
a	O
difficult	O
variant	O
of	O
this	O
chain	B-Method
system	I-Method
with	O
significant	O
stochastic	O
noise	O
in	O
transitions	O
as	O
depicted	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Action	O
	
‘	O
	
‘	O
left	O
’	O
’	O
deterministically	O
moves	O
the	O
agent	O
left	O
,	O
but	O
action	O
	
‘	O
‘	O
right	O
’	O
’	O
is	O
only	O
successful	O
50	O
%	O
of	O
the	O
time	O
and	O
otherwise	O
also	O
moves	O
left	O
.	O
	
The	O
agent	O
interacts	O
with	O
the	O
MDP	B-Method
in	O
episodes	O
of	O
length	O
and	O
begins	O
each	O
episode	O
at	O
.	O
	
Once	O
again	O
the	O
optimal	O
policy	O
is	O
to	O
head	O
right	O
.	O
	
Bootstrapped	B-Method
DQN	I-Method
is	O
unique	O
amongst	O
scalable	O
approaches	O
to	O
efficient	O
exploration	B-Task
with	O
deep	O
RL	B-Task
in	O
stochastic	B-Task
domains	I-Task
.	O
	
For	O
benchmark	O
performance	O
we	O
implement	O
three	O
algorithms	O
which	O
,	O
unlike	O
bootstrapped	B-Method
DQN	I-Method
,	O
will	O
receive	O
the	O
true	O
tabular	B-Method
representation	I-Method
for	O
the	O
MDP	B-Method
.	O
	
These	O
algorithms	O
are	O
based	O
on	O
three	O
state	O
of	O
the	O
art	O
approaches	O
to	O
exploration	B-Task
via	O
dithering	B-Method
(	O
-	O
greedy	O
)	O
,	O
optimism	B-Method
and	O
posterior	B-Method
sampling	I-Method
.	O
	
We	O
discuss	O
the	O
choice	O
of	O
these	O
benchmarks	O
in	O
Appendix	O
[	O
reference	O
]	O
.	O
	
[	O
b	O
]	O
0.45	O
	
[	O
b	O
]	O
0.45	O
	
In	O
Figure	O
[	O
reference	O
]	O
we	O
present	O
the	O
empirical	B-Metric
regret	I-Metric
of	O
each	O
algorithm	O
averaged	O
over	O
10	O
seeds	O
over	O
the	O
first	O
two	O
thousand	O
episodes	O
.	O
	
The	O
empirical	B-Metric
regret	I-Metric
is	O
the	O
cumulative	O
difference	O
between	O
the	O
expected	O
rewards	O
of	O
the	O
optimal	B-Method
policy	I-Method
and	O
the	O
realized	O
rewards	O
of	O
each	O
algorithm	O
.	O
	
We	O
find	O
that	O
bootstrapped	B-Method
DQN	I-Method
achieves	O
similar	O
performance	O
to	O
state	O
of	O
the	O
art	O
efficient	O
exploration	B-Method
schemes	I-Method
such	O
as	O
PSRL	B-Method
even	O
without	O
prior	O
knowledge	O
of	O
the	O
tabular	O
MDP	O
structure	O
and	O
in	O
noisy	O
environments	O
.	O
	
Most	O
telling	O
is	O
how	O
much	O
better	O
bootstrapped	B-Method
DQN	I-Method
does	O
than	O
the	O
state	O
of	O
the	O
art	O
optimistic	B-Method
algorithm	I-Method
UCRL2	I-Method
.	O
	
Although	O
Figure	O
[	O
reference	O
]	O
seems	O
to	O
suggest	O
UCRL2	B-Method
incurs	O
linear	O
regret	O
,	O
actually	O
it	O
follows	O
its	O
bounds	O
where	O
is	O
the	O
number	O
of	O
states	O
and	O
is	O
the	O
number	O
of	O
actions	O
.	O
	
For	O
the	O
example	O
in	O
Figure	O
[	O
reference	O
]	O
we	O
attempted	O
to	O
display	O
our	O
performance	O
compared	O
to	O
several	O
benchmark	O
tabula	B-Method
rasa	I-Method
approaches	I-Method
to	O
exploration	B-Task
.	O
	
There	O
are	O
many	O
other	O
algorithms	O
we	O
could	O
have	O
considered	O
,	O
but	O
for	O
a	O
short	O
paper	O
we	O
chose	O
to	O
focus	O
against	O
the	O
most	O
common	O
approach	O
(	O
-	O
greedy	O
)	O
the	O
pre	B-Method
-	I-Method
eminent	I-Method
optimistic	I-Method
approach	I-Method
(	O
UCRL2	B-Method
)	O
and	O
posterior	B-Method
sampling	I-Method
(	O
PSRL	B-Method
)	O
.	O
	
Other	O
common	O
heuristic	B-Method
approaches	I-Method
,	O
such	O
as	O
optimistic	B-Method
initialization	I-Method
for	O
Q	B-Method
-	I-Method
learning	I-Method
can	O
be	O
tuned	O
to	O
work	O
well	O
on	O
this	O
domain	O
,	O
however	O
the	O
precise	O
parameters	O
are	O
sensitive	O
to	O
the	O
underlying	O
MDP	B-Method
.	O
	
To	O
make	O
a	O
general	O
-	O
purpose	O
version	O
of	O
this	O
heuristic	O
essentially	O
leads	O
to	O
optimistic	B-Method
algorithms	I-Method
.	O
	
Since	O
UCRL2	B-Method
is	O
originally	O
designed	O
for	O
infinite	B-Task
-	I-Task
horizon	I-Task
MDPs	I-Task
,	O
we	O
use	O
the	O
natural	O
adaptation	O
of	O
this	O
algorithm	O
,	O
which	O
has	O
state	O
of	O
the	O
art	O
guarantees	O
in	O
finite	B-Task
horizon	I-Task
MDPs	I-Task
as	O
well	O
.	O
	
Figure	O
[	O
reference	O
]	O
displays	O
the	O
empirical	B-Metric
regret	I-Metric
of	O
these	O
algorithms	O
together	O
with	O
	
bootstrapped	B-Method
DQN	I-Method
on	O
the	O
example	O
from	O
Figure	O
[	O
reference	O
]	O
.	O
	
It	O
is	O
somewhat	O
disconcerting	O
that	O
UCRL2	B-Method
appears	O
to	O
incur	O
linear	O
regret	O
,	O
but	O
it	O
is	O
proven	O
to	O
satisfy	O
near	O
-	O
optimal	O
regret	O
bounds	O
.	O
	
Actually	O
,	O
as	O
we	O
show	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
the	O
algorithm	O
produces	O
regret	B-Metric
which	O
scales	O
very	O
similarly	O
to	O
its	O
established	O
bounds	O
.	O
	
Similarly	O
,	O
even	O
for	O
this	O
tiny	O
problem	O
size	O
,	O
the	O
recent	O
analysis	O
that	O
proves	O
a	O
near	B-Metric
optimal	I-Metric
sample	I-Metric
complexity	I-Metric
in	O
fixed	B-Task
horizon	I-Task
problems	I-Task
only	O
guarantees	O
that	O
we	O
will	O
have	O
fewer	O
than	O
suboptimal	O
episodes	O
.	O
	
While	O
these	O
bounds	O
may	O
be	O
acceptable	O
in	O
worst	B-Task
case	I-Task
scaling	I-Task
,	O
they	O
are	O
not	O
of	O
much	O
practical	O
use	O
.	O
	
subsection	O
:	O
One	O
-	O
hot	O
features	O
	
In	O
Figure	O
[	O
reference	O
]	O
we	O
include	O
the	O
mean	O
performance	O
of	O
bootstrapped	B-Method
DQN	I-Method
with	O
one	B-Method
-	I-Method
hot	I-Method
feature	I-Method
encodings	I-Method
.	O
	
We	O
found	O
that	O
,	O
using	O
these	O
features	O
,	O
bootstrapped	B-Method
DQN	I-Method
learned	O
the	O
optimal	B-Method
policy	I-Method
for	O
most	O
seeds	O
,	O
but	O
was	O
somewhat	O
less	O
robust	O
than	O
the	O
thermometer	B-Method
encoding	I-Method
.	O
	
Two	O
out	O
of	O
ten	O
seeds	O
failed	O
to	O
learn	O
the	O
optimal	B-Method
policy	I-Method
within	O
2000	O
episodes	O
,	O
this	O
is	O
presented	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
appendix	O
:	O
Experiments	O
for	O
Atari	B-Material
	
subsection	O
:	O
Experimental	O
setup	O
	
We	O
use	O
the	O
same	O
49	O
Atari	B-Material
games	I-Material
as	O
for	O
our	O
experiments	O
.	O
	
Each	O
step	O
of	O
the	O
agent	O
corresponds	O
to	O
four	O
steps	O
of	O
the	O
emulator	B-Method
,	O
where	O
the	O
same	O
action	O
is	O
repeated	O
,	O
the	O
reward	O
values	O
of	O
the	O
agents	O
are	O
clipped	O
between	O
-	O
1	O
and	O
1	O
for	O
stability	O
.	O
	
We	O
evaluate	O
our	O
agents	O
and	O
report	O
performance	O
based	O
upon	O
the	O
raw	B-Metric
scores	I-Metric
.	O
	
The	O
convolutional	B-Method
part	I-Method
of	O
the	O
network	O
used	O
is	O
identical	O
to	O
the	O
one	O
used	O
in	O
.	O
	
The	O
input	O
to	O
the	O
network	O
is	O
4x84x84	O
tensor	O
with	O
a	O
rescaled	O
,	O
grayscale	O
version	O
of	O
the	O
last	O
four	O
observations	O
.	O
	
The	O
first	O
convolutional	B-Method
(	I-Method
conv	I-Method
)	I-Method
layer	I-Method
has	O
32	O
filters	O
of	O
size	O
8	O
with	O
a	O
stride	O
of	O
4	O
.	O
	
The	O
second	O
conv	B-Method
layer	I-Method
has	O
64	O
filters	O
of	O
size	O
4	O
with	O
stride	O
2	O
.	O
	
The	O
last	O
conv	B-Method
layer	I-Method
has	O
64	O
filters	O
of	O
size	O
3	O
.	O
	
We	O
split	O
the	O
network	O
beyond	O
the	O
final	O
layer	O
into	O
distinct	O
heads	O
,	O
each	O
one	O
is	O
fully	O
connected	O
and	O
identical	O
to	O
the	O
single	O
head	O
of	O
DQN	B-Method
.	O
	
This	O
consists	O
of	O
a	O
fully	B-Method
connected	I-Method
layer	I-Method
to	O
512	O
units	O
followed	O
by	O
another	O
fully	B-Method
connected	I-Method
layer	I-Method
to	O
the	O
Q	O
-	O
Values	O
for	O
each	O
action	O
.	O
	
The	O
fully	B-Method
connected	I-Method
layers	I-Method
all	O
use	O
Rectified	B-Method
Linear	I-Method
Units	I-Method
(	O
ReLU	B-Method
)	O
as	O
a	O
non	O
-	O
linearity	O
.	O
	
We	O
normalize	O
gradients	O
that	O
flow	O
from	O
each	O
head	O
.	O
	
We	O
trained	O
the	O
networks	O
with	O
RMSProp	B-Method
with	O
a	O
momentum	O
of	O
0.95	O
and	O
a	O
learning	B-Metric
rate	I-Metric
of	O
0.00025	O
as	O
in	O
.	O
	
The	O
discount	O
was	O
set	O
to	O
,	O
the	O
number	O
of	O
steps	O
between	O
target	O
updates	O
was	O
set	O
to	O
steps	O
.	O
	
We	O
trained	O
the	O
agents	O
for	O
a	O
total	O
of	O
50	O
m	O
steps	O
per	O
game	O
,	O
which	O
corresponds	O
to	O
200	O
m	O
frames	O
.	O
	
The	O
agents	O
were	O
every	O
1	O
m	O
frames	O
,	O
for	O
evaluation	O
in	O
bootstrapped	B-Method
DQN	I-Method
we	O
use	O
an	O
ensemble	B-Method
voting	I-Method
policy	I-Method
.	O
	
The	O
experience	O
replay	O
contains	O
the	O
1	O
m	O
most	O
recent	O
transitions	O
.	O
	
We	O
update	O
the	O
network	O
every	O
steps	O
by	O
randomly	O
sampling	O
a	O
minibatch	O
of	O
transitions	O
from	O
the	O
replay	O
buffer	O
to	O
use	O
the	O
exact	O
same	O
minibatch	O
schedule	O
as	O
DQN	B-Method
.	O
	
For	O
training	B-Task
we	O
used	O
an	O
-	B-Method
greedy	I-Method
policy	I-Method
with	O
being	O
annealed	O
linearly	O
from	O
to	O
over	O
the	O
first	O
1	O
m	O
timesteps	O
.	O
	
subsection	O
:	O
Gradient	B-Method
normalization	I-Method
in	O
bootstrap	B-Method
heads	I-Method
	
Most	O
literature	O
in	O
deep	O
RL	B-Task
for	O
Atari	B-Material
focuses	O
on	O
learning	O
the	O
best	O
single	O
evaluation	B-Task
policy	I-Task
,	O
with	O
particular	O
attention	O
to	O
whether	O
this	O
above	O
or	O
below	O
human	O
performance	O
.	O
	
This	O
is	O
unusual	O
for	O
the	O
RL	B-Task
literature	O
,	O
which	O
typically	O
focuses	O
upon	O
cumulative	O
or	O
final	O
performance	O
.	O
	
Bootstrapped	B-Method
DQN	I-Method
makes	O
significant	O
improvements	O
to	O
the	O
cumulative	B-Metric
rewards	I-Metric
of	O
DQN	B-Method
on	O
Atari	B-Material
,	O
as	O
we	O
display	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
while	O
the	O
peak	O
performance	O
is	O
much	O
more	O
We	O
found	O
that	O
using	O
bootstrapped	B-Method
DQN	I-Method
without	O
gradient	B-Method
normalization	I-Method
on	O
each	O
head	O
typically	O
learned	O
even	O
faster	O
than	O
our	O
implementation	O
with	O
rescaling	B-Method
,	O
but	O
it	O
was	O
somewhat	O
prone	O
to	O
premature	O
and	O
suboptimal	O
convergence	B-Metric
.	O
	
We	O
present	O
an	O
example	O
of	O
this	O
phenomenon	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
We	O
found	O
that	O
,	O
in	O
order	O
to	O
better	O
the	O
benchmark	O
	
‘	O
	
‘	O
best	O
’	O
’	O
policies	O
reported	O
by	O
DQN	B-Method
	
,	O
it	O
was	O
very	O
helpful	O
for	O
us	O
to	O
use	O
the	O
gradient	B-Method
normalization	I-Method
.	O
	
However	O
,	O
it	O
is	O
not	O
entirely	O
clear	O
whether	O
this	O
represents	O
an	O
improvement	O
for	O
all	O
settings	O
.	O
	
In	O
Figures	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
	
we	O
present	O
the	O
cumulative	O
rewards	O
of	O
the	O
same	O
algorithms	O
on	O
Beam	B-Task
Rider	I-Task
.	O
	
[	O
b	O
]	O
0.45	O
	
[	O
b	O
]	O
0.45	O
	
Where	O
an	O
RL	B-Task
system	O
is	O
deployed	O
to	O
learn	O
with	O
real	O
interactions	O
,	O
cumulative	O
rewards	O
present	O
a	O
better	O
measure	O
for	O
performance	O
.	O
	
In	O
these	O
settings	O
the	O
benefits	O
of	O
gradient	B-Method
normalization	I-Method
are	O
less	O
clear	O
.	O
	
However	O
,	O
even	O
with	O
normalization	O
bootstrapped	B-Method
DQN	I-Method
significantly	O
outperforms	O
DQN	B-Method
in	O
terms	O
of	O
cumulative	B-Metric
rewards	I-Metric
.	O
	
This	O
is	O
reflected	O
most	O
clearly	O
in	O
Figure	O
[	O
reference	O
]	O
and	O
Table	O
[	O
reference	O
]	O
.	O
	
subsection	O
:	O
Sharing	O
data	O
in	O
bootstrap	B-Method
heads	O
	
In	O
this	O
setting	O
all	O
network	O
heads	O
share	O
all	O
the	O
data	O
,	O
so	O
they	O
are	O
not	O
actually	O
a	O
traditional	O
bootstrap	B-Method
at	O
all	O
.	O
	
This	O
is	O
different	O
from	O
the	O
regression	B-Task
task	I-Task
in	O
Section	O
[	O
reference	O
]	O
,	O
where	O
bootstrapped	O
data	O
was	O
essential	O
to	O
obtain	O
meaningful	O
uncertainty	B-Task
estimates	I-Task
.	O
	
We	O
have	O
several	O
theories	O
for	O
why	O
the	O
networks	O
maintain	O
significant	O
diversity	O
even	O
without	O
data	B-Method
bootstrapping	I-Method
in	O
this	O
setting	O
.	O
	
We	O
build	O
upon	O
the	O
intuition	O
of	O
Section	O
[	O
reference	O
]	O
.	O
	
First	O
,	O
they	O
all	O
train	O
on	O
different	O
target	B-Method
networks	I-Method
.	O
	
This	O
means	O
that	O
even	O
when	O
facing	O
the	O
same	O
datapoint	O
this	O
can	O
still	O
lead	O
to	O
drastically	O
different	O
Q	O
-	O
value	O
updates	O
.	O
	
Second	O
,	O
Atari	B-Material
is	O
a	O
deterministic	O
environment	O
,	O
any	O
transition	O
observation	O
is	O
the	O
unique	O
correct	O
datapoint	O
for	O
this	O
setting	O
.	O
	
Third	O
,	O
the	O
networks	O
are	O
deep	O
and	O
initialized	O
from	O
different	O
random	O
values	O
so	O
they	O
will	O
likely	O
find	O
quite	O
diverse	O
generalization	O
even	O
when	O
they	O
agree	O
on	O
given	O
data	O
.	O
	
Finally	O
,	O
since	O
all	O
variants	O
of	O
DQN	B-Method
take	O
many	O
many	O
frames	O
to	O
update	O
their	O
policy	O
,	O
it	O
is	O
likely	O
that	O
even	O
using	O
they	O
would	O
still	O
populate	O
their	O
replay	O
memory	O
with	O
identical	O
datapoints	O
.	O
	
This	O
means	O
using	O
to	O
save	O
on	O
minibatch	O
passes	O
seems	O
like	O
a	O
reasonable	O
compromise	O
and	O
it	O
does	O
n’t	O
seem	O
to	O
negatively	O
affect	O
performance	O
too	O
much	O
in	O
this	O
setting	O
.	O
	
More	O
research	O
is	O
needed	O
to	O
examine	O
exactly	O
where	O
/	O
when	O
this	O
data	B-Task
sharing	I-Task
is	O
important	O
.	O
	
subsection	O
:	O
Results	O
tables	O
	
In	O
Table	O
[	O
reference	O
]	O
the	O
average	O
score	B-Metric
achieved	O
by	O
the	O
agents	O
during	O
the	O
most	O
successful	O
evaluation	O
period	O
,	O
compared	O
to	O
human	O
performance	O
and	O
a	O
uniformly	B-Method
random	I-Method
policy	I-Method
.	O
	
DQN	B-Method
is	O
our	O
implementation	O
of	O
DQN	B-Method
with	O
the	O
hyperparameters	O
specified	O
above	O
,	O
using	O
the	O
double	B-Method
Q	I-Method
-	I-Method
Learning	I-Method
update	I-Method
.	O
.	O
	
We	O
find	O
that	O
peak	O
final	O
performance	O
is	O
similar	O
under	O
bootstrapped	B-Method
DQN	I-Method
to	O
previous	O
benchmarks	O
.	O
	
To	O
compare	O
the	O
benefits	O
of	O
exploration	B-Task
via	O
bootstrapped	B-Method
DQN	I-Method
we	O
benchmark	O
our	O
performance	O
against	O
the	O
most	O
similar	O
prior	O
work	O
on	O
incentivizing	B-Task
exploration	I-Task
in	O
Atari	B-Material
.	O
	
To	O
do	O
this	O
,	O
we	O
compute	O
the	O
AUC	B-Metric
-	I-Metric
100	I-Metric
measure	I-Metric
specified	O
in	O
this	O
work	O
.	O
	
We	O
present	O
these	O
results	O
in	O
Table	O
[	O
reference	O
]	O
compare	O
to	O
their	O
best	O
performing	O
strategy	O
as	O
well	O
as	O
their	O
implementation	O
of	O
DQN	B-Method
.	O
	
Importantly	O
,	O
bootstrapped	B-Method
DQN	I-Method
outperforms	O
this	O
prior	O
work	O
significantly	O
.	O
	
We	O
now	O
compare	O
our	O
method	O
against	O
the	O
results	O
in	O
.	O
	
In	O
this	O
paper	O
they	O
introduce	O
a	O
new	O
measure	O
of	O
performance	B-Metric
called	O
AUC	B-Method
-	I-Method
100	I-Method
,	O
which	O
is	O
something	O
similar	O
to	O
normalized	O
cumulative	O
rewards	O
up	O
to	O
20	O
million	O
frames	O
.	O
	
Table	O
[	O
reference	O
]	O
displays	O
the	O
results	O
for	O
our	O
reference	O
DQN	B-Method
and	O
bootstrapped	B-Method
DQN	I-Method
as	O
Boot	B-Method
-	I-Method
DQN	I-Method
.	O
	
We	O
reproduce	O
their	O
reference	O
results	O
for	O
DQN	B-Method
as	O
DQN	B-Method
*	I-Method
and	O
their	O
best	O
performing	O
algorithm	O
,	O
Dynamic	B-Method
AE	I-Method
.	O
	
We	O
also	O
present	O
bootstrapped	B-Method
DQN	I-Method
without	O
head	O
rescaling	O
as	O
Boot	B-Method
-	I-Method
DQN	I-Method
+	I-Method
.	O
	
We	O
see	O
that	O
,	O
on	O
average	O
,	O
both	O
bootstrapped	B-Method
DQN	I-Method
implementations	O
outperform	O
Dynamic	B-Method
AE	I-Method
,	O
the	O
best	O
algorithm	O
from	O
previous	O
work	O
.	O
	
The	O
only	O
game	O
in	O
which	O
Dynamic	B-Method
AE	I-Method
produces	O
best	O
results	O
is	O
Bowling	B-Task
,	O
but	O
this	O
difference	O
in	O
Bowling	B-Task
is	O
dominated	O
by	O
the	O
implementation	O
of	O
DQN	B-Method
*	I-Method
vs	O
DQN	B-Method
.	O
	
Bootstrapped	B-Method
DQN	I-Method
still	O
gives	O
over	O
100	O
%	O
improvement	O
over	O
its	O
relevant	O
DQN	B-Method
baseline	O
.	O
	
Overall	O
it	O
is	O
clear	O
that	O
Boot	B-Method
-	I-Method
DQN	I-Method
+	I-Method
(	O
bootstrapped	B-Method
DQN	I-Method
without	O
rescaling	O
)	O
	
performs	O
best	O
in	O
terms	O
of	O
AUC	B-Metric
-	I-Metric
100	I-Metric
metric	I-Metric
.	O
	
Averaged	O
across	O
the	O
14	O
games	O
it	O
is	O
over	O
50	O
%	O
better	O
than	O
the	O
next	O
best	O
competitor	O
,	O
which	O
is	O
bootstrapped	B-Method
DQN	I-Method
with	O
gradient	B-Method
normalization	I-Method
.	O
	
However	O
,	O
in	O
terms	O
of	O
peak	O
performance	O
over	O
200	O
m	O
frames	O
Boot	B-Method
-	O
DQN	B-Method
generally	O
reached	O
higher	O
scores	O
.	O
	
Boot	B-Method
-	O
DQN	B-Method
+	I-Method
sometimes	O
plateaud	O
early	O
as	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
This	O
highlights	O
an	O
important	O
distinction	O
between	O
evaluation	B-Task
based	O
on	O
best	O
learned	O
policy	O
versus	O
cumulative	O
rewards	O
,	O
as	O
we	O
discuss	O
in	O
Appendix	O
[	O
reference	O
]	O
.	O
	
Bootstrapped	B-Method
DQN	I-Method
displays	O
the	O
biggest	O
improvements	O
over	O
DQN	B-Method
when	O
doing	O
well	O
during	O
learning	B-Task
is	O
important	O
.	O
	
document	O
:	O
Semi	B-Task
-	I-Task
Supervised	I-Task
Classification	I-Task
with	O
Graph	B-Method
Convolutional	I-Method
Networks	I-Method
	
We	O
present	O
a	O
scalable	O
approach	O
for	O
semi	B-Task
-	I-Task
supervised	I-Task
learning	I-Task
on	O
graph	O
-	O
structured	O
data	O
that	O
is	O
based	O
on	O
an	O
efficient	O
variant	O
of	O
convolutional	B-Method
neural	I-Method
networks	I-Method
which	O
operate	O
directly	O
on	O
graphs	B-Method
.	O
	
We	O
motivate	O
the	O
choice	O
of	O
our	O
convolutional	B-Method
architecture	I-Method
via	O
a	O
localized	O
first	B-Method
-	I-Method
order	I-Method
approximation	I-Method
of	I-Method
spectral	I-Method
graph	I-Method
convolutions	I-Method
.	O
	
Our	O
model	O
scales	O
linearly	O
in	O
the	O
number	O
of	O
graph	O
edges	O
and	O
learns	O
hidden	B-Method
layer	I-Method
representations	I-Method
that	O
encode	O
both	O
local	O
graph	O
structure	O
and	O
features	O
of	O
nodes	O
.	O
	
In	O
a	O
number	O
of	O
experiments	O
on	O
citation	B-Task
networks	I-Task
and	O
on	O
a	O
knowledge	O
graph	O
dataset	O
we	O
demonstrate	O
that	O
our	O
approach	O
outperforms	O
related	O
methods	O
by	O
a	O
significant	O
margin	O
.	O
	
section	O
:	O
Introduction	O
	
We	O
consider	O
the	O
problem	O
of	O
classifying	B-Task
nodes	I-Task
(	O
such	O
as	O
documents	O
)	O
in	O
a	O
graph	O
(	O
such	O
as	O
a	O
citation	B-Task
network	I-Task
)	O
,	O
where	O
labels	O
are	O
only	O
available	O
for	O
a	O
small	O
subset	O
of	O
nodes	O
.	O
	
This	O
problem	O
can	O
be	O
framed	O
as	O
graph	B-Method
-	I-Method
based	I-Method
semi	I-Method
-	I-Method
supervised	I-Method
learning	I-Method
,	O
where	O
label	O
information	O
is	O
smoothed	O
over	O
the	O
graph	O
via	O
some	O
form	O
of	O
explicit	B-Method
graph	I-Method
-	I-Method
based	I-Method
regularization	I-Method
zhu2003semi	O
,	O
zhou2004learning	O
,	O
belkin2006manifold	O
,	O
weston2012deep	O
,	O
e.g.	O
by	O
using	O
a	O
graph	O
Laplacian	O
regularization	O
term	O
in	O
the	O
loss	O
function	O
:	O
Here	O
,	O
denotes	O
the	O
supervised	O
loss	O
w.r.t	O
.	O
	
the	O
labeled	O
part	O
of	O
the	O
graph	O
,	O
can	O
be	O
a	O
neural	B-Method
network	I-Method
-	I-Method
like	I-Method
differentiable	I-Method
function	I-Method
,	O
is	O
a	O
weighing	O
factor	O
and	O
is	O
a	O
matrix	O
of	O
node	O
feature	O
vectors	O
.	O
	
denotes	O
the	O
unnormalized	O
graph	O
Laplacian	O
of	O
an	O
undirected	O
graph	O
with	O
nodes	O
,	O
edges	O
,	O
an	O
adjacency	O
matrix	O
(	O
binary	O
or	O
weighted	O
)	O
and	O
a	O
degree	O
matrix	O
.	O
	
The	O
formulation	O
of	O
Eq	O
.	O
	
[	O
reference	O
]	O
relies	O
on	O
the	O
assumption	O
that	O
connected	O
nodes	O
in	O
the	O
graph	O
are	O
likely	O
to	O
share	O
the	O
same	O
label	O
.	O
	
This	O
assumption	O
,	O
however	O
,	O
might	O
restrict	O
modeling	O
capacity	O
,	O
as	O
graph	O
edges	O
need	O
not	O
necessarily	O
encode	O
node	O
similarity	O
,	O
but	O
could	O
contain	O
additional	O
information	O
.	O
	
In	O
this	O
work	O
,	O
we	O
encode	O
the	O
graph	O
structure	O
directly	O
using	O
a	O
neural	B-Method
network	I-Method
model	I-Method
and	O
train	O
on	O
a	O
supervised	O
target	O
for	O
all	O
nodes	O
with	O
labels	O
,	O
thereby	O
avoiding	O
explicit	O
graph	B-Method
-	I-Method
based	I-Method
regularization	I-Method
in	O
the	O
loss	O
function	O
.	O
	
Conditioning	O
on	O
the	O
adjacency	O
matrix	O
of	O
the	O
graph	O
will	O
allow	O
the	O
model	O
to	O
distribute	O
gradient	O
information	O
from	O
the	O
supervised	O
loss	O
and	O
will	O
enable	O
it	O
to	O
learn	O
representations	O
of	O
nodes	O
both	O
with	O
and	O
without	O
labels	O
.	O
	
Our	O
contributions	O
are	O
two	O
-	O
fold	O
.	O
	
Firstly	O
,	O
we	O
introduce	O
a	O
simple	O
and	O
well	O
-	O
behaved	O
layer	B-Method
-	I-Method
wise	I-Method
propagation	I-Method
rule	I-Method
for	O
neural	B-Method
network	I-Method
models	I-Method
which	O
operate	O
directly	O
on	O
graphs	B-Method
and	O
show	O
how	O
it	O
can	O
be	O
motivated	O
from	O
a	O
first	B-Method
-	I-Method
order	I-Method
approximation	I-Method
of	I-Method
spectral	I-Method
graph	I-Method
convolutions	I-Method
hammond2011wavelets	O
.	O
	
Secondly	O
,	O
we	O
demonstrate	O
how	O
this	O
form	O
of	O
a	O
graph	B-Method
-	I-Method
based	I-Method
neural	I-Method
network	I-Method
model	I-Method
can	O
be	O
used	O
for	O
fast	B-Task
and	I-Task
scalable	I-Task
semi	I-Task
-	I-Task
supervised	I-Task
classification	I-Task
of	I-Task
nodes	I-Task
in	I-Task
a	I-Task
graph	I-Task
.	O
	
Experiments	O
on	O
a	O
number	O
of	O
datasets	O
demonstrate	O
that	O
our	O
model	O
compares	O
favorably	O
both	O
in	O
classification	B-Metric
accuracy	I-Metric
and	O
efficiency	B-Metric
(	O
measured	O
in	O
wall	B-Metric
-	I-Metric
clock	I-Metric
time	I-Metric
)	O
against	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
for	O
semi	B-Task
-	I-Task
supervised	I-Task
learning	I-Task
.	O
	
section	O
:	O
Fast	B-Task
Approximate	I-Task
Convolutions	I-Task
on	I-Task
Graphs	I-Task
	
In	O
this	O
section	O
,	O
we	O
provide	O
theoretical	O
motivation	O
for	O
a	O
specific	O
graph	B-Method
-	I-Method
based	I-Method
neural	I-Method
network	I-Method
model	I-Method
that	O
we	O
will	O
use	O
in	O
the	O
rest	O
of	O
this	O
paper	O
.	O
	
We	O
consider	O
a	O
multi	O
-	O
layer	O
Graph	B-Method
Convolutional	I-Method
Network	I-Method
(	O
GCN	B-Method
)	O
with	O
the	O
following	O
layer	B-Method
-	I-Method
wise	I-Method
propagation	I-Method
rule	I-Method
:	O
Here	O
,	O
is	O
the	O
adjacency	O
matrix	O
of	O
the	O
undirected	O
graph	O
with	O
added	O
self	O
-	O
connections	O
.	O
	
is	O
the	O
identity	O
matrix	O
,	O
and	O
is	O
a	O
layer	B-Method
-	I-Method
specific	I-Method
trainable	I-Method
weight	I-Method
matrix	I-Method
.	O
	
denotes	O
an	O
activation	O
function	O
,	O
such	O
as	O
the	O
.	O
	
is	O
the	O
matrix	O
of	O
activations	O
in	O
the	O
layer	O
;	O
.	O
	
In	O
the	O
following	O
,	O
we	O
show	O
that	O
the	O
form	O
of	O
this	O
propagation	B-Method
rule	I-Method
can	O
be	O
motivated	O
via	O
a	O
first	B-Method
-	I-Method
order	I-Method
approximation	I-Method
of	I-Method
localized	I-Method
spectral	I-Method
filters	I-Method
on	O
graphs	B-Method
hammond2011wavelets	O
,	O
defferrard2016convolutional	O
.	O
	
subsection	O
:	O
Spectral	O
Graph	O
Convolutions	O
	
We	O
consider	O
spectral	O
convolutions	O
on	O
graphs	B-Method
defined	O
as	O
the	O
multiplication	O
of	O
a	O
signal	O
(	O
a	O
scalar	O
for	O
every	O
node	O
)	O
with	O
a	O
filter	B-Method
parameterized	O
by	O
in	O
the	O
Fourier	O
domain	O
,	O
i.e.	O
:	O
where	O
is	O
the	O
matrix	O
of	O
eigenvectors	O
of	O
the	O
normalized	O
graph	O
Laplacian	O
,	O
with	O
a	O
diagonal	O
matrix	O
of	O
its	O
eigenvalues	O
and	O
being	O
the	O
graph	B-Method
Fourier	I-Method
transform	I-Method
of	O
.	O
	
We	O
can	O
understand	O
as	O
a	O
function	O
of	O
the	O
eigenvalues	O
of	O
,	O
i.e.	O
.	O
	
Evaluating	B-Task
Eq	I-Task
.	O
	
[	O
reference	O
]	O
is	O
computationally	O
expensive	O
,	O
as	O
multiplication	O
with	O
the	O
eigenvector	O
matrix	O
is	O
.	O
	
Furthermore	O
,	O
computing	O
the	O
eigendecomposition	O
of	O
in	O
the	O
first	O
place	O
might	O
be	O
prohibitively	O
expensive	O
for	O
large	O
graphs	B-Method
.	O
	
To	O
circumvent	O
this	O
problem	O
,	O
it	O
was	O
suggested	O
in	O
that	O
can	O
be	O
well	O
-	O
approximated	O
by	O
a	O
truncated	B-Method
expansion	I-Method
in	O
terms	O
of	O
Chebyshev	B-Method
polynomials	I-Method
up	O
to	O
order	O
:	O
with	O
a	O
rescaled	O
.	O
	
denotes	O
the	O
largest	O
eigenvalue	O
of	O
.	O
	
is	O
now	O
a	O
vector	O
of	O
Chebyshev	O
coefficients	O
.	O
	
The	O
Chebyshev	B-Method
polynomials	I-Method
are	O
recursively	O
defined	O
as	O
,	O
with	O
and	O
.	O
	
The	O
reader	O
is	O
referred	O
to	O
for	O
an	O
in	O
-	O
depth	O
discussion	O
of	O
this	O
approximation	O
.	O
	
Going	O
back	O
to	O
our	O
definition	O
of	O
a	O
convolution	B-Method
of	I-Method
a	I-Method
signal	I-Method
with	O
a	O
filter	B-Method
,	O
we	O
now	O
have	O
:	O
with	O
;	O
as	O
can	O
easily	O
be	O
verified	O
by	O
noticing	O
that	O
.	O
	
Note	O
that	O
this	O
expression	O
is	O
now	O
-	O
localized	O
since	O
it	O
is	O
a	O
-	O
order	O
polynomial	O
in	O
the	O
Laplacian	O
,	O
i.e.	O
it	O
depends	O
only	O
on	O
nodes	O
that	O
are	O
at	O
maximum	O
steps	O
away	O
from	O
the	O
central	O
node	O
(	O
-	O
order	O
neighborhood	O
)	O
.	O
	
The	O
complexity	B-Metric
of	O
evaluating	O
Eq	B-Task
.	O
	
[	O
reference	O
]	O
is	O
,	O
i.e.	O
linear	O
in	O
the	O
number	O
of	O
edges	O
.	O
	
use	O
this	O
-	B-Method
localized	I-Method
convolution	I-Method
to	O
define	O
a	O
convolutional	O
neural	O
network	O
on	O
graphs	B-Method
.	O
	
subsection	O
:	O
Layer	B-Method
-	I-Method
Wise	I-Method
Linear	I-Method
Model	I-Method
	
A	O
neural	B-Method
network	I-Method
model	I-Method
based	O
on	O
graph	B-Method
convolutions	I-Method
can	O
therefore	O
be	O
built	O
by	O
stacking	O
multiple	B-Method
convolutional	I-Method
layers	I-Method
of	O
the	O
form	O
of	O
Eq	O
.	O
	
[	O
reference	O
]	O
,	O
each	O
layer	O
followed	O
by	O
a	O
point	B-Method
-	I-Method
wise	I-Method
non	I-Method
-	I-Method
linearity	I-Method
.	O
	
Now	O
,	O
imagine	O
we	O
limited	O
the	O
layer	B-Method
-	I-Method
wise	I-Method
convolution	I-Method
operation	I-Method
to	O
(	O
see	O
Eq	O
.	O
	
[	O
reference	O
]	O
)	O
,	O
i.e.	O
a	O
function	O
that	O
is	O
linear	O
w.r.t	O
.	O
and	O
therefore	O
a	O
linear	O
function	O
on	O
the	O
graph	O
Laplacian	O
spectrum	O
.	O
	
In	O
this	O
way	O
,	O
we	O
can	O
still	O
recover	O
a	O
rich	O
class	O
of	O
convolutional	B-Method
filter	I-Method
functions	I-Method
by	O
stacking	O
multiple	O
such	O
layers	O
,	O
but	O
we	O
are	O
not	O
limited	O
to	O
the	O
explicit	O
parameterization	O
given	O
by	O
,	O
e.g.	O
,	O
the	O
Chebyshev	O
polynomials	O
.	O
	
We	O
intuitively	O
expect	O
that	O
such	O
a	O
model	O
can	O
alleviate	O
the	O
problem	O
of	O
overfitting	O
on	O
local	O
neighborhood	O
structures	O
for	O
graphs	B-Method
with	O
very	O
wide	O
node	O
degree	O
distributions	O
,	O
such	O
as	O
social	O
networks	O
,	O
citation	O
networks	O
,	O
knowledge	O
graphs	B-Method
and	O
many	O
other	O
real	O
-	O
world	O
graph	O
datasets	O
.	O
	
Additionally	O
,	O
for	O
a	O
fixed	O
computational	O
budget	O
,	O
this	O
layer	B-Method
-	I-Method
wise	I-Method
linear	I-Method
formulation	I-Method
allows	O
us	O
to	O
build	O
deeper	B-Method
models	I-Method
,	O
a	O
practice	O
that	O
is	O
known	O
to	O
improve	O
modeling	O
capacity	O
on	O
a	O
number	O
of	O
domains	O
he2015deep	O
.	O
	
In	O
this	O
linear	B-Method
formulation	I-Method
of	O
a	O
GCN	B-Method
we	O
further	O
approximate	O
,	O
as	O
we	O
can	O
expect	O
that	O
neural	B-Method
network	I-Method
parameters	I-Method
will	O
adapt	O
to	O
this	O
change	O
in	O
scale	O
during	O
training	O
.	O
	
Under	O
these	O
approximations	O
Eq	O
.	O
[	O
reference	O
]	O
simplifies	O
to	O
:	O
with	O
two	O
free	O
parameters	O
and	O
.	O
	
The	O
filter	O
parameters	O
can	O
be	O
shared	O
over	O
the	O
whole	O
graph	O
.	O
	
Successive	O
application	O
of	O
filters	B-Method
of	O
this	O
form	O
then	O
effectively	O
convolve	O
the	O
-	O
order	O
neighborhood	O
of	O
a	O
node	O
,	O
where	O
is	O
the	O
number	O
of	O
successive	B-Method
filtering	I-Method
operations	I-Method
or	O
convolutional	B-Method
layers	I-Method
in	O
the	O
neural	B-Method
network	I-Method
model	I-Method
.	O
	
In	O
practice	O
,	O
it	O
can	O
be	O
beneficial	O
to	O
constrain	O
the	O
number	O
of	O
parameters	O
further	O
to	O
address	O
overfitting	O
and	O
to	O
minimize	O
the	O
number	O
of	O
operations	O
(	O
such	O
as	O
matrix	B-Method
multiplications	I-Method
)	O
per	O
layer	O
.	O
	
This	O
leaves	O
us	O
with	O
the	O
following	O
expression	O
:	O
with	O
a	O
single	O
parameter	O
.	O
	
Note	O
that	O
now	O
has	O
eigenvalues	O
in	O
the	O
range	O
.	O
	
Repeated	O
application	O
of	O
this	O
operator	O
can	O
therefore	O
lead	O
to	O
numerical	O
instabilities	O
and	O
exploding	O
/	O
vanishing	O
gradients	O
when	O
used	O
in	O
a	O
deep	B-Method
neural	I-Method
network	I-Method
model	I-Method
.	O
	
To	O
alleviate	O
this	O
problem	O
,	O
we	O
introduce	O
the	O
following	O
renormalization	B-Method
trick	I-Method
:	O
,	O
with	O
and	O
.	O
	
We	O
can	O
generalize	O
this	O
definition	O
to	O
a	O
signal	O
with	O
input	O
channels	O
(	O
i.e.	O
a	O
-	O
dimensional	O
feature	O
vector	O
for	O
every	O
node	O
)	O
and	O
filters	O
or	O
feature	O
maps	O
as	O
follows	O
:	O
where	O
is	O
now	O
a	O
matrix	O
of	O
filter	O
parameters	O
and	O
is	O
the	O
convolved	O
signal	O
matrix	O
.	O
	
This	O
filtering	B-Method
operation	I-Method
has	O
complexity	B-Metric
,	O
as	O
can	O
be	O
efficiently	O
implemented	O
as	O
a	O
product	O
of	O
a	O
sparse	B-Method
matrix	I-Method
with	O
a	O
dense	O
matrix	O
.	O
	
section	O
:	O
Semi	B-Task
-	I-Task
Supervised	I-Task
Node	I-Task
Classification	I-Task
	
Having	O
introduced	O
a	O
simple	O
,	O
yet	O
flexible	O
model	O
for	O
efficient	O
information	O
propagation	O
on	O
graphs	B-Method
,	O
we	O
can	O
return	O
to	O
the	O
problem	O
of	O
semi	B-Task
-	I-Task
supervised	I-Task
node	I-Task
classification	I-Task
.	O
	
As	O
outlined	O
in	O
the	O
introduction	O
,	O
we	O
can	O
relax	O
certain	O
assumptions	O
typically	O
made	O
in	O
graph	B-Task
-	I-Task
based	I-Task
semi	I-Task
-	I-Task
supervised	I-Task
learning	I-Task
by	O
conditioning	O
our	O
model	O
both	O
on	O
the	O
data	O
and	O
on	O
the	O
adjacency	O
matrix	O
of	O
the	O
underlying	O
graph	O
structure	O
.	O
	
We	O
expect	O
this	O
setting	O
to	O
be	O
especially	O
powerful	O
in	O
scenarios	O
where	O
the	O
adjacency	O
matrix	O
contains	O
information	O
not	O
present	O
in	O
the	O
data	O
,	O
such	O
as	O
citation	O
links	O
between	O
documents	O
in	O
a	O
citation	O
network	O
or	O
relations	O
in	O
a	O
knowledge	O
graph	O
.	O
	
The	O
overall	O
model	O
,	O
a	O
multi	O
-	O
layer	O
GCN	B-Method
for	O
semi	B-Task
-	I-Task
supervised	I-Task
learning	I-Task
,	O
is	O
schematically	O
depicted	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
[	O
b	O
]	O
0.67	O
	
[	O
b	O
]	O
0.33	O
	
subsection	O
:	O
Example	O
	
In	O
the	O
following	O
,	O
we	O
consider	O
a	O
two	O
-	O
layer	O
GCN	B-Method
for	O
semi	B-Task
-	I-Task
supervised	I-Task
node	I-Task
classification	I-Task
on	O
a	O
graph	O
with	O
a	O
symmetric	O
adjacency	O
matrix	O
(	O
binary	O
or	O
weighted	O
)	O
.	O
	
We	O
first	O
calculate	O
in	O
a	O
pre	B-Task
-	I-Task
processing	I-Task
step	I-Task
.	O
	
Our	O
forward	B-Method
model	I-Method
then	O
takes	O
the	O
simple	O
form	O
:	O
Here	O
,	O
is	O
an	O
input	O
-	O
to	O
-	O
hidden	O
weight	O
matrix	O
for	O
a	O
hidden	B-Method
layer	I-Method
with	O
feature	O
maps	O
.	O
	
is	O
a	O
hidden	O
-	O
to	O
-	O
output	O
weight	O
matrix	O
.	O
	
The	O
softmax	O
activation	O
function	O
,	O
defined	O
as	O
with	O
,	O
is	O
applied	O
row	O
-	O
wise	O
.	O
	
For	O
semi	B-Task
-	I-Task
supervised	I-Task
multi	I-Task
-	I-Task
class	I-Task
classification	I-Task
,	O
we	O
then	O
evaluate	O
the	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
error	I-Metric
over	O
all	O
labeled	O
examples	O
:	O
where	O
is	O
the	O
set	O
of	O
node	O
indices	O
that	O
have	O
labels	O
.	O
	
The	O
neural	B-Method
network	I-Method
weights	I-Method
and	O
are	O
trained	O
using	O
gradient	B-Method
descent	I-Method
.	O
	
In	O
this	O
work	O
,	O
we	O
perform	O
batch	B-Method
gradient	I-Method
descent	I-Method
using	O
the	O
full	O
dataset	O
for	O
every	O
training	O
iteration	O
,	O
which	O
is	O
a	O
viable	O
option	O
as	O
long	O
as	O
datasets	O
fit	O
in	O
memory	O
.	O
	
Using	O
a	O
sparse	B-Method
representation	I-Method
for	O
,	O
memory	B-Metric
requirement	I-Metric
is	O
,	O
i.e.	O
linear	O
in	O
the	O
number	O
of	O
edges	O
.	O
	
Stochasticity	O
in	O
the	O
training	B-Method
process	I-Method
is	O
introduced	O
via	O
dropout	B-Method
srivastava2014dropout	O
.	O
	
We	O
leave	O
memory	O
-	O
efficient	O
extensions	O
with	O
mini	B-Method
-	I-Method
batch	I-Method
stochastic	I-Method
gradient	I-Method
descent	I-Method
for	O
future	O
work	O
.	O
	
subsection	O
:	O
Implementation	O
	
In	O
practice	O
,	O
we	O
make	O
use	O
of	O
TensorFlow	B-Method
tensorflow2015	O
-	O
whitepaper	O
for	O
an	O
efficient	O
GPU	B-Method
-	I-Method
based	I-Method
implementation	I-Method
of	I-Method
Eq	I-Method
.	O
	
[	O
reference	O
]	O
using	O
sparse	B-Method
-	I-Method
dense	I-Method
matrix	I-Method
multiplications	I-Method
.	O
	
The	O
computational	B-Metric
complexity	I-Metric
of	O
evaluating	B-Task
Eq	I-Task
.	O
	
[	O
reference	O
]	O
is	O
then	O
,	O
i.e.	O
linear	O
in	O
the	O
number	O
of	O
graph	O
edges	O
.	O
	
section	O
:	O
Related	O
Work	O
	
Our	O
model	O
draws	O
inspiration	O
both	O
from	O
the	O
field	O
of	O
graph	B-Task
-	I-Task
based	I-Task
semi	I-Task
-	I-Task
supervised	I-Task
learning	I-Task
and	O
from	O
recent	O
work	O
on	O
neural	B-Method
networks	I-Method
that	O
operate	O
on	O
graphs	B-Method
.	O
	
In	O
what	O
follows	O
,	O
we	O
provide	O
a	O
brief	O
overview	O
on	O
related	O
work	O
in	O
both	O
fields	O
.	O
	
subsection	O
:	O
Graph	B-Method
-	I-Method
Based	I-Method
Semi	I-Method
-	I-Method
Supervised	I-Method
Learning	I-Method
	
A	O
large	O
number	O
of	O
approaches	O
for	O
semi	B-Task
-	I-Task
supervised	I-Task
learning	I-Task
using	O
graph	B-Task
representations	I-Task
have	O
been	O
proposed	O
in	O
recent	O
years	O
,	O
most	O
of	O
which	O
fall	O
into	O
two	O
broad	O
categories	O
:	O
methods	O
that	O
use	O
some	O
form	O
of	O
explicit	B-Method
graph	I-Method
Laplacian	I-Method
regularization	I-Method
and	O
graph	B-Method
embedding	I-Method
-	I-Method
based	I-Method
approaches	I-Method
.	O
	
Prominent	O
examples	O
for	O
graph	B-Task
Laplacian	I-Task
regularization	I-Task
include	O
label	B-Task
propagation	I-Task
zhu2003semi	O
,	O
manifold	B-Method
regularization	I-Method
belkin2006manifold	O
and	O
deep	B-Method
semi	I-Method
-	I-Method
supervised	I-Method
embedding	I-Method
weston2012deep	O
.	O
	
Recently	O
,	O
attention	O
has	O
shifted	O
to	O
models	O
that	O
learn	O
graph	B-Method
embeddings	I-Method
with	O
methods	O
inspired	O
by	O
the	O
skip	B-Method
-	I-Method
gram	I-Method
model	I-Method
mikolov2013distributed	O
.	O
	
DeepWalk	B-Method
perozzi2014deepwalk	O
learns	O
embeddings	B-Method
via	O
the	O
prediction	O
of	O
the	O
local	O
neighborhood	O
of	O
nodes	O
,	O
sampled	O
from	O
random	O
walks	O
on	O
the	O
graph	O
.	O
	
LINE	B-Method
tang2015line	O
and	O
node2vec	B-Method
grovernode2vec	O
extend	O
DeepWalk	B-Method
with	O
more	O
sophisticated	O
random	B-Method
walk	I-Method
or	I-Method
breadth	I-Method
-	I-Method
first	I-Method
search	I-Method
schemes	I-Method
.	O
	
For	O
all	O
these	O
methods	O
,	O
however	O
,	O
a	O
multi	B-Method
-	I-Method
step	I-Method
pipeline	I-Method
including	O
random	B-Method
walk	I-Method
generation	I-Method
and	O
semi	B-Method
-	I-Method
supervised	I-Method
training	I-Method
is	O
required	O
where	O
each	O
step	O
has	O
to	O
be	O
optimized	O
separately	O
.	O
	
Planetoid	B-Method
yang2016revisiting	O
alleviates	O
this	O
by	O
injecting	O
label	O
information	O
in	O
the	O
process	O
of	O
learning	B-Task
embeddings	I-Task
.	O
	
subsection	O
:	O
Neural	B-Method
Networks	I-Method
on	O
Graphs	O
	
Neural	B-Method
networks	I-Method
that	O
operate	O
on	O
graphs	B-Method
have	O
previously	O
been	O
introduced	O
in	O
as	O
a	O
form	O
of	O
recurrent	B-Method
neural	I-Method
network	I-Method
.	O
	
Their	O
framework	O
requires	O
the	O
repeated	O
application	O
of	O
contraction	B-Method
maps	I-Method
as	O
propagation	B-Method
functions	I-Method
until	O
node	B-Method
representations	I-Method
reach	O
a	O
stable	O
fixed	O
point	O
.	O
	
This	O
restriction	O
was	O
later	O
alleviated	O
in	O
by	O
introducing	O
modern	O
practices	O
for	O
recurrent	B-Method
neural	I-Method
network	I-Method
training	I-Method
to	O
the	O
original	O
graph	B-Method
neural	I-Method
network	I-Method
framework	I-Method
.	O
	
introduced	O
a	O
convolution	B-Method
-	I-Method
like	I-Method
propagation	I-Method
rule	I-Method
on	O
graphs	B-Method
and	O
methods	O
for	O
graph	B-Task
-	I-Task
level	I-Task
classification	I-Task
.	O
	
Their	O
approach	O
requires	O
to	O
learn	O
node	O
degree	O
-	O
specific	O
weight	O
matrices	O
which	O
does	O
not	O
scale	O
to	O
large	O
graphs	B-Method
with	O
wide	O
node	O
degree	O
distributions	O
.	O
	
Our	O
model	O
instead	O
uses	O
a	O
single	O
weight	B-Method
matrix	I-Method
per	I-Method
layer	I-Method
and	O
deals	O
with	O
varying	O
node	O
degrees	O
through	O
an	O
appropriate	O
normalization	B-Method
of	I-Method
the	I-Method
adjacency	I-Method
matrix	I-Method
(	O
see	O
Section	O
[	O
reference	O
]	O
)	O
.	O
	
A	O
related	O
approach	O
to	O
node	B-Task
classification	I-Task
with	O
a	O
graph	B-Method
-	I-Method
based	I-Method
neural	I-Method
network	I-Method
was	O
recently	O
introduced	O
in	O
.	O
	
They	O
report	O
complexity	B-Metric
,	O
limiting	O
the	O
range	O
of	O
possible	O
applications	O
.	O
	
In	O
a	O
different	O
yet	O
related	O
model	O
,	O
convert	O
graphs	B-Method
locally	O
into	O
sequences	O
that	O
are	O
fed	O
into	O
a	O
conventional	O
1D	B-Method
convolutional	I-Method
neural	I-Method
network	I-Method
,	O
which	O
requires	O
the	O
definition	O
of	O
a	O
node	O
ordering	O
in	O
a	O
pre	O
-	O
processing	O
step	O
.	O
	
Our	O
method	O
is	O
based	O
on	O
spectral	B-Method
graph	I-Method
convolutional	I-Method
neural	I-Method
networks	I-Method
,	O
introduced	O
in	O
and	O
later	O
extended	O
by	O
with	O
fast	B-Method
localized	I-Method
convolutions	I-Method
.	O
	
In	O
contrast	O
to	O
these	O
works	O
,	O
we	O
consider	O
here	O
the	O
task	O
of	O
transductive	B-Task
node	I-Task
classification	I-Task
within	O
networks	O
of	O
significantly	O
larger	O
scale	O
.	O
	
We	O
show	O
that	O
in	O
this	O
setting	O
,	O
a	O
number	O
of	O
simplifications	O
(	O
see	O
Section	O
[	O
reference	O
]	O
)	O
can	O
be	O
introduced	O
to	O
the	O
original	O
frameworks	O
of	O
and	O
that	O
improve	O
scalability	B-Metric
and	O
classification	B-Task
performance	O
in	O
large	B-Task
-	I-Task
scale	I-Task
networks	I-Task
.	O
	
section	O
:	O
Experiments	O
	
We	O
test	O
our	O
model	O
in	O
a	O
number	O
of	O
experiments	O
:	O
semi	B-Task
-	I-Task
supervised	I-Task
document	I-Task
classification	I-Task
in	O
citation	B-Task
networks	I-Task
,	O
semi	B-Task
-	I-Task
supervised	I-Task
entity	I-Task
classification	I-Task
in	O
a	O
bipartite	O
graph	O
extracted	O
from	O
a	O
knowledge	O
graph	O
,	O
an	O
evaluation	O
of	O
various	O
graph	B-Method
propagation	I-Method
models	I-Method
and	O
a	O
run	B-Method
-	I-Method
time	I-Method
analysis	I-Method
on	O
random	O
graphs	B-Method
.	O
	
subsection	O
:	O
Datasets	O
	
We	O
closely	O
follow	O
the	O
experimental	O
setup	O
in	O
.	O
	
Dataset	O
statistics	O
are	O
summarized	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
In	O
the	O
citation	O
network	O
datasets	O
—	O
Citeseer	B-Material
,	O
Cora	B-Material
and	O
Pubmed	B-Material
sen2008collective	O
—	O
nodes	O
are	O
documents	O
and	O
edges	O
are	O
citation	O
links	O
.	O
	
Label	B-Metric
rate	I-Metric
denotes	O
the	O
number	O
of	O
labeled	O
nodes	O
that	O
are	O
used	O
for	O
training	O
divided	O
by	O
the	O
total	O
number	O
of	O
nodes	O
in	O
each	O
dataset	O
.	O
	
NELL	B-Material
carlson2010toward	O
,	O
yang2016revisiting	O
is	O
a	O
bipartite	O
graph	O
dataset	O
extracted	O
from	O
a	O
knowledge	O
graph	O
with	O
55	O
,	O
864	O
relation	O
nodes	O
and	O
9	O
,	O
891	O
entity	O
nodes	O
.	O
	
paragraph	O
:	O
Citation	B-Method
networks	I-Method
	
We	O
consider	O
three	O
citation	O
network	O
datasets	O
:	O
Citeseer	B-Material
,	O
Cora	B-Material
and	O
Pubmed	B-Material
sen2008collective	O
.	O
	
The	O
datasets	O
contain	O
sparse	O
bag	O
-	O
of	O
-	O
words	O
feature	O
vectors	O
for	O
each	O
document	O
and	O
a	O
list	O
of	O
citation	O
links	O
between	O
documents	O
.	O
	
We	O
treat	O
the	O
citation	O
links	O
as	O
(	O
undirected	O
)	O
edges	O
and	O
construct	O
a	O
binary	O
,	O
symmetric	O
adjacency	O
matrix	O
.	O
	
Each	O
document	O
has	O
a	O
class	O
label	O
.	O
	
For	O
training	B-Task
,	O
we	O
only	O
use	O
20	O
labels	O
per	O
class	O
,	O
but	O
all	O
feature	O
vectors	O
.	O
	
paragraph	O
:	O
NELL	B-Material
	
NELL	B-Material
is	O
a	O
dataset	O
extracted	O
from	O
the	O
knowledge	O
graph	O
introduced	O
in	O
carlson2010toward	O
.	O
	
A	O
knowledge	O
graph	O
is	O
a	O
set	O
of	O
entities	O
connected	O
with	O
directed	O
,	O
labeled	O
edges	O
(	O
relations	O
)	O
.	O
	
We	O
follow	O
the	O
pre	B-Method
-	I-Method
processing	I-Method
scheme	I-Method
as	O
described	O
in	O
.	O
	
We	O
assign	O
separate	O
relation	O
nodes	O
and	O
for	O
each	O
entity	O
pair	O
as	O
and	O
.	O
	
Entity	O
nodes	O
are	O
described	O
by	O
sparse	O
feature	O
vectors	O
.	O
	
We	O
extend	O
the	O
number	O
of	O
features	O
in	O
NELL	B-Material
by	O
assigning	O
a	O
unique	O
one	B-Method
-	I-Method
hot	I-Method
representation	I-Method
for	O
every	O
relation	O
node	O
,	O
effectively	O
resulting	O
in	O
a	O
61	O
,	O
278	O
-	O
dim	O
sparse	O
feature	O
vector	O
per	O
node	O
.	O
	
The	O
semi	B-Task
-	I-Task
supervised	I-Task
task	I-Task
here	O
considers	O
the	O
extreme	O
case	O
of	O
only	O
a	O
single	O
labeled	O
example	O
per	O
class	O
in	O
the	O
training	O
set	O
.	O
	
We	O
construct	O
a	O
binary	O
,	O
symmetric	O
adjacency	O
matrix	O
from	O
this	O
graph	O
by	O
setting	O
entries	O
,	O
if	O
one	O
or	O
more	O
edges	O
are	O
present	O
between	O
nodes	O
and	O
.	O
	
paragraph	O
:	O
Random	O
graphs	B-Method
	
We	O
simulate	O
random	O
graph	O
datasets	O
of	O
various	O
sizes	O
for	O
experiments	O
where	O
we	O
measure	O
training	B-Metric
time	I-Metric
per	O
epoch	O
.	O
	
For	O
a	O
dataset	O
with	O
nodes	O
we	O
create	O
a	O
random	O
graph	O
assigning	O
edges	O
uniformly	O
at	O
random	O
.	O
	
We	O
take	O
the	O
identity	O
matrix	O
as	O
input	O
feature	O
matrix	O
,	O
thereby	O
implicitly	O
taking	O
a	O
featureless	B-Method
approach	I-Method
where	O
the	O
model	O
is	O
only	O
informed	O
about	O
the	O
identity	O
of	O
each	O
node	O
,	O
specified	O
by	O
a	O
unique	O
one	O
-	O
hot	O
vector	O
.	O
	
We	O
add	O
dummy	O
labels	O
for	O
every	O
node	O
.	O
	
subsection	O
:	O
Experimental	O
Set	O
-	O
Up	O
	
Unless	O
otherwise	O
noted	O
,	O
we	O
train	O
a	O
two	O
-	O
layer	O
GCN	B-Method
as	O
described	O
in	O
Section	O
[	O
reference	O
]	O
and	O
evaluate	O
prediction	B-Metric
accuracy	I-Metric
on	O
a	O
test	O
set	O
of	O
1	O
,	O
000	O
labeled	O
examples	O
.	O
	
We	O
provide	O
additional	O
experiments	O
using	O
deeper	B-Method
models	I-Method
with	O
up	O
to	O
10	O
layers	O
in	O
Appendix	O
[	O
reference	O
]	O
.	O
	
We	O
choose	O
the	O
same	O
dataset	O
splits	O
as	O
in	O
with	O
an	O
additional	O
validation	O
set	O
of	O
500	O
labeled	O
examples	O
for	O
hyperparameter	B-Method
optimization	I-Method
(	O
dropout	B-Method
rate	O
for	O
all	O
layers	O
,	O
L2	O
regularization	O
factor	O
for	O
the	O
first	O
GCN	B-Method
layer	O
and	O
number	O
of	O
hidden	O
units	O
)	O
.	O
	
We	O
do	O
not	O
use	O
the	O
validation	O
set	O
labels	O
for	O
training	O
.	O
	
For	O
the	O
citation	O
network	O
datasets	O
,	O
we	O
optimize	O
hyperparameters	B-Method
on	O
Cora	B-Material
only	O
and	O
use	O
the	O
same	O
set	O
of	O
parameters	O
for	O
Citeseer	B-Material
and	O
Pubmed	B-Material
.	O
	
We	O
train	O
all	O
models	O
for	O
a	O
maximum	O
of	O
200	O
epochs	O
(	O
training	O
iterations	O
)	O
using	O
Adam	B-Method
kingma2014adam	I-Method
with	O
a	O
learning	B-Metric
rate	I-Metric
of	O
and	O
early	O
stopping	O
with	O
a	O
window	O
size	O
of	O
,	O
i.e.	O
we	O
stop	O
training	O
if	O
the	O
validation	B-Metric
loss	I-Metric
does	O
not	O
decrease	O
for	O
10	O
consecutive	O
epochs	O
.	O
	
We	O
initialize	O
weights	O
using	O
the	O
initialization	O
described	O
in	O
and	O
accordingly	O
(	O
row	O
-)	O
normalize	O
input	O
feature	O
vectors	O
.	O
	
On	O
the	O
random	O
graph	O
datasets	O
,	O
we	O
use	O
a	O
hidden	O
layer	O
size	O
of	O
32	O
units	O
and	O
omit	O
regularization	B-Method
(	O
i.e.	O
neither	O
dropout	B-Method
nor	O
L2	B-Method
regularization	I-Method
)	O
.	O
	
subsection	O
:	O
Baselines	O
	
We	O
compare	O
against	O
the	O
same	O
baseline	O
methods	O
as	O
in	O
,	O
i.e.	O
label	B-Task
propagation	I-Task
(	O
LP	B-Method
)	O
zhu2003semi	O
,	O
semi	B-Task
-	I-Task
supervised	I-Task
embedding	I-Task
(	O
SemiEmb	B-Method
)	O
	
weston2012deep	O
,	O
manifold	B-Method
regularization	I-Method
(	O
	
ManiReg	O
)	O
belkin2006manifold	O
and	O
skip	B-Method
-	I-Method
gram	I-Method
based	I-Method
graph	I-Method
embeddings	I-Method
	
(	O
DeepWalk	B-Method
)	O
perozzi2014deepwalk	O
.	O
	
We	O
omit	O
TSVM	B-Method
joachims1999transductive	O
,	O
as	O
it	O
does	O
not	O
scale	O
to	O
the	O
large	O
number	O
of	O
classes	O
in	O
one	O
of	O
our	O
datasets	O
.	O
	
We	O
further	O
compare	O
against	O
the	O
iterative	B-Method
classification	I-Method
algorithm	I-Method
(	O
ICA	B-Task
)	O
proposed	O
in	O
in	O
conjunction	O
with	O
two	O
logistic	B-Method
regression	I-Method
classifiers	I-Method
,	O
one	O
for	O
local	O
node	O
features	O
alone	O
and	O
one	O
for	O
relational	B-Task
classification	I-Task
using	O
local	O
features	O
and	O
an	O
aggregation	B-Method
operator	I-Method
as	O
described	O
in	O
.	O
	
We	O
first	O
train	O
the	O
local	B-Method
classifier	I-Method
using	O
all	O
labeled	O
training	O
set	O
nodes	O
and	O
use	O
it	O
to	O
bootstrap	O
class	O
labels	O
of	O
unlabeled	O
nodes	O
for	O
relational	B-Method
classifier	I-Method
training	I-Method
.	O
	
We	O
run	O
iterative	B-Method
classification	I-Method
(	O
relational	B-Method
classifier	I-Method
)	O
with	O
a	O
random	O
node	O
ordering	O
for	O
10	O
iterations	O
on	O
all	O
unlabeled	O
nodes	O
(	O
bootstrapped	O
using	O
the	O
local	B-Method
classifier	I-Method
)	O
.	O
	
L2	O
regularization	O
parameter	O
and	O
aggregation	O
operator	O
(	O
count	O
vs.	O
prop	O
,	O
see	O
)	O
are	O
chosen	O
based	O
on	O
validation	O
set	O
performance	O
for	O
each	O
dataset	O
separately	O
.	O
	
Lastly	O
,	O
we	O
compare	O
against	O
Planetoid	B-Method
yang2016revisiting	O
,	O
where	O
we	O
always	O
choose	O
their	O
best	O
-	O
performing	O
model	O
variant	O
(	O
transductive	B-Method
vs.	I-Method
inductive	I-Method
)	O
as	O
a	O
baseline	O
.	O
	
section	O
:	O
Results	O
	
subsection	O
:	O
Semi	B-Task
-	I-Task
Supervised	I-Task
Node	I-Task
Classification	I-Task
	
Results	O
are	O
summarized	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Reported	O
numbers	O
denote	O
classification	B-Metric
accuracy	I-Metric
in	O
percent	O
.	O
	
For	O
ICA	B-Task
,	O
we	O
report	O
the	O
mean	O
accuracy	B-Metric
of	O
100	O
runs	O
with	O
random	O
node	O
orderings	O
.	O
	
Results	O
for	O
all	O
other	O
baseline	O
methods	O
are	O
taken	O
from	O
the	O
Planetoid	B-Method
paper	I-Method
yang2016revisiting	O
.	O
	
Planetoid	B-Method
*	O
denotes	O
the	O
best	O
model	O
for	O
the	O
respective	O
dataset	O
out	O
of	O
the	O
variants	O
presented	O
in	O
their	O
paper	O
.	O
	
We	O
further	O
report	O
wall	B-Metric
-	I-Metric
clock	I-Metric
training	I-Metric
time	I-Metric
in	O
seconds	O
until	O
convergence	O
(	O
in	O
brackets	O
)	O
for	O
our	O
method	O
(	O
incl	O
.	O
evaluation	B-Metric
of	I-Metric
validation	I-Metric
error	I-Metric
)	O
and	O
for	O
Planetoid	B-Method
.	O
	
For	O
the	O
latter	O
,	O
we	O
used	O
an	O
implementation	O
provided	O
by	O
the	O
authors	O
and	O
trained	O
on	O
the	O
same	O
hardware	O
(	O
with	O
GPU	O
)	O
as	O
our	O
GCN	B-Method
model	I-Method
.	O
	
We	O
trained	O
and	O
tested	O
our	O
model	O
on	O
the	O
same	O
dataset	O
splits	O
as	O
in	O
and	O
report	O
mean	O
accuracy	B-Metric
of	O
100	O
runs	O
with	O
random	B-Method
weight	I-Method
initializations	I-Method
.	O
	
We	O
used	O
the	O
following	O
sets	O
of	O
hyperparameters	O
for	O
Citeseer	B-Material
,	O
Cora	B-Material
and	O
Pubmed	B-Material
:	O
0.5	O
(	O
dropout	B-Method
rate	O
)	O
,	O
(	O
L2	B-Method
regularization	I-Method
)	O
and	O
(	O
number	O
of	O
hidden	O
units	O
)	O
;	O
and	O
for	O
NELL	B-Material
:	O
0.1	O
(	O
dropout	B-Method
rate	O
)	O
,	O
(	O
L2	B-Method
regularization	I-Method
)	O
and	O
(	O
number	O
of	O
hidden	O
units	O
)	O
.	O
	
In	O
addition	O
,	O
we	O
report	O
performance	O
of	O
our	O
model	O
on	O
10	O
randomly	O
drawn	O
dataset	O
splits	O
of	O
the	O
same	O
size	O
as	O
in	O
,	O
denoted	O
by	O
GCN	B-Method
(	O
rand	O
.	O
	
splits	O
)	O
.	O
	
Here	O
,	O
we	O
report	O
mean	O
and	O
standard	O
error	B-Metric
of	O
prediction	B-Metric
accuracy	I-Metric
on	O
the	O
test	O
set	O
split	O
in	O
percent	O
.	O
	
subsection	O
:	O
Evaluation	O
of	O
Propagation	B-Method
Model	I-Method
	
We	O
compare	O
different	O
variants	O
of	O
our	O
proposed	O
per	B-Method
-	I-Method
layer	I-Method
propagation	I-Method
model	I-Method
on	O
the	O
citation	O
network	O
datasets	O
.	O
	
We	O
follow	O
the	O
experimental	O
set	O
-	O
up	O
described	O
in	O
the	O
previous	O
section	O
.	O
	
Results	O
are	O
summarized	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
The	O
propagation	B-Method
model	I-Method
of	O
our	O
original	O
GCN	B-Method
model	I-Method
is	O
denoted	O
by	O
renormalization	B-Method
trick	I-Method
(	O
in	O
bold	O
)	O
.	O
	
In	O
all	O
other	O
cases	O
,	O
the	O
propagation	B-Method
model	I-Method
of	O
both	O
neural	B-Method
network	I-Method
layers	I-Method
is	O
replaced	O
with	O
the	O
model	O
specified	O
under	O
propagation	B-Method
model	I-Method
.	O
	
Reported	O
numbers	O
denote	O
mean	O
classification	B-Metric
accuracy	I-Metric
for	O
100	O
repeated	O
runs	O
with	O
random	B-Method
weight	I-Method
matrix	I-Method
initializations	I-Method
.	O
	
In	O
case	O
of	O
multiple	O
variables	O
per	O
layer	O
,	O
we	O
impose	O
L2	B-Method
regularization	I-Method
on	O
all	O
weight	O
matrices	O
of	O
the	O
first	O
layer	O
.	O
	
subsection	O
:	O
Training	B-Metric
Time	I-Metric
per	O
Epoch	O
	
Here	O
,	O
we	O
report	O
results	O
for	O
the	O
mean	B-Metric
training	I-Metric
time	I-Metric
per	I-Metric
epoch	I-Metric
(	O
forward	B-Metric
pass	I-Metric
,	O
cross	B-Method
-	I-Method
entropy	I-Method
calculation	I-Method
,	O
backward	B-Method
pass	I-Method
)	O
for	O
100	O
epochs	O
on	O
simulated	O
random	O
graphs	B-Method
,	O
measured	O
in	O
seconds	O
wall	O
-	O
clock	O
time	O
.	O
	
See	O
Section	O
[	O
reference	O
]	O
for	O
a	O
detailed	O
description	O
of	O
the	O
random	O
graph	O
dataset	O
used	O
in	O
these	O
experiments	O
.	O
	
We	O
compare	O
results	O
on	O
a	O
GPU	B-Method
and	O
on	O
a	O
CPU	B-Method
-	I-Method
only	I-Method
implementation	I-Method
in	O
TensorFlow	B-Method
tensorflow2015	O
-	O
whitepaper	O
.	O
	
Figure	O
[	O
reference	O
]	O
summarizes	O
the	O
results	O
.	O
	
section	O
:	O
Discussion	O
	
subsection	O
:	O
Semi	B-Method
-	I-Method
Supervised	I-Method
Model	I-Method
	
In	O
the	O
experiments	O
demonstrated	O
here	O
,	O
our	O
method	O
for	O
semi	B-Task
-	I-Task
supervised	I-Task
node	I-Task
classification	I-Task
outperforms	O
recent	O
related	O
methods	O
by	O
a	O
significant	O
margin	O
.	O
	
Methods	O
based	O
on	O
graph	B-Method
-	I-Method
Laplacian	I-Method
regularization	I-Method
zhu2003semi	O
,	O
belkin2006manifold	O
,	O
weston2012deep	O
are	O
most	O
likely	O
limited	O
due	O
to	O
their	O
assumption	O
that	O
edges	O
encode	O
mere	O
similarity	O
of	O
nodes	O
.	O
	
Skip	B-Method
-	I-Method
gram	I-Method
based	I-Method
methods	I-Method
on	O
the	O
other	O
hand	O
are	O
limited	O
by	O
the	O
fact	O
that	O
they	O
are	O
based	O
on	O
a	O
multi	B-Method
-	I-Method
step	I-Method
pipeline	I-Method
which	O
is	O
difficult	O
to	O
optimize	O
.	O
	
Our	O
proposed	O
model	O
can	O
overcome	O
both	O
limitations	O
,	O
while	O
still	O
comparing	O
favorably	O
in	O
terms	O
of	O
efficiency	B-Metric
(	O
measured	O
in	O
wall	B-Metric
-	I-Metric
clock	I-Metric
time	I-Metric
)	O
to	O
related	O
methods	O
.	O
	
Propagation	O
of	O
feature	O
information	O
from	O
neighboring	O
nodes	O
in	O
every	O
layer	O
improves	O
classification	B-Task
performance	O
in	O
comparison	O
to	O
methods	O
like	O
ICA	B-Task
lu2003link	O
,	O
where	O
only	O
label	O
information	O
is	O
aggregated	O
.	O
	
We	O
have	O
further	O
demonstrated	O
that	O
the	O
proposed	O
renormalized	B-Method
propagation	I-Method
model	I-Method
(	O
Eq	O
.	O
	
[	O
reference	O
]	O
)	O
offers	O
both	O
improved	O
efficiency	O
(	O
fewer	O
parameters	O
and	O
operations	O
,	O
such	O
as	O
multiplication	O
or	O
addition	O
)	O
and	O
better	O
predictive	B-Task
performance	O
on	O
a	O
number	O
of	O
datasets	O
compared	O
to	O
a	O
naïve	B-Method
-	I-Method
order	I-Method
model	I-Method
(	O
Eq	O
.	O
	
[	O
reference	O
]	O
)	O
or	O
higher	B-Method
-	I-Method
order	I-Method
graph	I-Method
convolutional	I-Method
models	I-Method
using	O
Chebyshev	B-Method
polynomials	I-Method
(	O
Eq	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
subsection	O
:	O
Limitations	O
and	O
Future	O
Work	O
	
Here	O
,	O
we	O
describe	O
several	O
limitations	O
of	O
our	O
current	O
model	O
and	O
outline	O
how	O
these	O
might	O
be	O
overcome	O
in	O
future	O
work	O
.	O
	
paragraph	O
:	O
Memory	O
requirement	O
	
In	O
the	O
current	O
setup	O
with	O
full	O
-	O
batch	O
gradient	B-Method
descent	I-Method
,	O
memory	O
requirement	O
grows	O
linearly	O
in	O
the	O
size	O
of	O
the	O
dataset	O
.	O
	
We	O
have	O
shown	O
that	O
for	O
large	O
graphs	B-Method
that	O
do	O
not	O
fit	O
in	O
GPU	O
memory	O
,	O
training	O
on	O
CPU	B-Method
can	O
still	O
be	O
a	O
viable	O
option	O
.	O
	
Mini	B-Method
-	I-Method
batch	I-Method
stochastic	I-Method
gradient	I-Method
descent	I-Method
can	O
alleviate	O
this	O
issue	O
.	O
	
The	O
procedure	O
of	O
generating	B-Task
mini	I-Task
-	I-Task
batches	I-Task
,	O
however	O
,	O
should	O
take	O
into	O
account	O
the	O
number	O
of	O
layers	O
in	O
the	O
GCN	B-Method
model	I-Method
,	O
as	O
the	O
-	O
order	O
neighborhood	O
for	O
a	O
GCN	B-Method
with	O
layers	O
has	O
to	O
be	O
stored	O
in	O
memory	O
for	O
an	O
exact	O
procedure	O
.	O
	
For	O
very	O
large	O
and	O
densely	O
connected	O
graph	O
datasets	O
,	O
further	O
approximations	O
might	O
be	O
necessary	O
.	O
	
paragraph	O
:	O
Directed	O
edges	O
and	O
edge	O
features	O
	
Our	O
framework	O
currently	O
does	O
not	O
naturally	O
support	O
edge	O
features	O
and	O
is	O
limited	O
to	O
undirected	O
graphs	B-Method
(	O
weighted	O
or	O
unweighted	O
)	O
.	O
	
Results	O
on	O
NELL	B-Material
however	O
show	O
that	O
it	O
is	O
possible	O
to	O
handle	O
both	O
directed	O
edges	O
and	O
edge	O
features	O
by	O
representing	O
the	O
original	O
directed	O
graph	O
as	O
an	O
undirected	B-Method
bipartite	I-Method
graph	I-Method
with	O
additional	O
nodes	O
that	O
represent	O
edges	O
in	O
the	O
original	O
graph	O
(	O
see	O
Section	O
[	O
reference	O
]	O
for	O
details	O
)	O
.	O
	
paragraph	O
:	O
Limiting	O
assumptions	O
	
Through	O
the	O
approximations	O
introduced	O
in	O
Section	O
[	O
reference	O
]	O
,	O
we	O
implicitly	O
assume	O
locality	O
(	O
dependence	O
on	O
the	O
-	O
order	O
neighborhood	O
for	O
a	O
GCN	B-Method
with	O
layers	O
)	O
and	O
equal	O
importance	O
of	O
self	O
-	O
connections	O
vs.	O
edges	O
to	O
neighboring	O
nodes	O
.	O
	
For	O
some	O
datasets	O
,	O
however	O
,	O
it	O
might	O
be	O
beneficial	O
to	O
introduce	O
a	O
trade	O
-	O
off	O
parameter	O
in	O
the	O
definition	O
of	O
:	O
This	O
parameter	O
now	O
plays	O
a	O
similar	O
role	O
as	O
the	O
trade	O
-	O
off	O
parameter	O
between	O
supervised	O
and	O
unsupervised	O
loss	O
in	O
the	O
typical	O
semi	B-Task
-	I-Task
supervised	I-Task
setting	I-Task
(	O
see	O
Eq	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
Here	O
,	O
however	O
,	O
it	O
can	O
be	O
learned	O
via	O
gradient	B-Method
descent	I-Method
.	O
	
section	O
:	O
Conclusion	O
	
We	O
have	O
introduced	O
a	O
novel	O
approach	O
for	O
semi	B-Task
-	I-Task
supervised	I-Task
classification	I-Task
on	O
graph	O
-	O
structured	O
data	O
.	O
	
Our	O
GCN	B-Method
model	I-Method
uses	O
an	O
efficient	O
layer	B-Method
-	I-Method
wise	I-Method
propagation	I-Method
rule	I-Method
that	O
is	O
based	O
on	O
a	O
first	O
-	O
order	O
approximation	O
of	O
spectral	O
convolutions	O
on	O
graphs	B-Method
.	O
	
Experiments	O
on	O
a	O
number	O
of	O
network	O
datasets	O
suggest	O
that	O
the	O
proposed	O
GCN	B-Method
model	I-Method
is	O
capable	O
of	O
encoding	O
both	O
graph	O
structure	O
and	O
node	O
features	O
in	O
a	O
way	O
useful	O
for	O
semi	B-Task
-	I-Task
supervised	I-Task
classification	I-Task
.	O
	
In	O
this	O
setting	O
,	O
our	O
model	O
outperforms	O
several	O
recently	O
proposed	O
methods	O
by	O
a	O
significant	O
margin	O
,	O
while	O
being	O
computationally	O
efficient	O
.	O
	
subsubsection	O
:	O
Acknowledgments	O
	
We	O
would	O
like	O
to	O
thank	O
Christos	O
Louizos	O
,	O
Taco	O
Cohen	O
,	O
Joan	O
Bruna	O
,	O
Zhilin	O
Yang	O
,	O
Dave	O
Herman	O
,	O
Pramod	O
Sinha	O
and	O
Abdul	O
-	O
Saboor	O
Sheikh	O
for	O
helpful	O
discussions	O
.	O
	
This	O
research	O
was	O
funded	O
by	O
SAP	O
.	O
	
bibliography	O
:	O
References	O
	
appendix	O
:	O
Relation	O
to	O
Weisfeiler	B-Method
-	I-Method
Lehman	I-Method
Algorithm	I-Method
	
A	O
neural	B-Method
network	I-Method
model	I-Method
for	O
graph	O
-	O
structured	O
data	O
should	O
ideally	O
be	O
able	O
to	O
learn	O
representations	O
of	O
nodes	O
in	O
a	O
graph	O
,	O
taking	O
both	O
the	O
graph	O
structure	O
and	O
feature	O
description	O
of	O
nodes	O
into	O
account	O
.	O
	
A	O
well	O
-	O
studied	O
framework	O
for	O
the	O
unique	B-Task
assignment	I-Task
of	I-Task
node	I-Task
labels	I-Task
given	O
a	O
graph	O
and	O
	
(	O
optionally	O
)	O
discrete	O
initial	O
node	O
labels	O
is	O
provided	O
by	O
the	O
1	B-Method
-	I-Method
dim	I-Method
Weisfeiler	I-Method
-	I-Method
Lehman	I-Method
(	I-Method
WL	I-Method
-	I-Method
1	I-Method
)	I-Method
algorithm	I-Method
weisfeiler1968reduction	O
:	O
[	O
H	O
]	O
	
Initial	B-Method
node	I-Method
coloring	I-Method
Final	O
node	O
coloring	O
t	O
0	O
stable	O
node	O
coloring	O
is	O
reached	O
WL	B-Method
-	I-Method
1	I-Method
algorithm	I-Method
Here	O
,	O
denotes	O
the	O
coloring	O
(	O
label	O
assignment	O
)	O
of	O
node	O
(	O
at	O
iteration	O
)	O
and	O
is	O
its	O
set	O
of	O
neighboring	O
node	O
indices	O
(	O
irrespective	O
of	O
whether	O
the	O
graph	O
includes	O
self	O
-	O
connections	O
for	O
every	O
node	O
or	O
not	O
)	O
.	O
	
is	O
a	O
hash	B-Method
function	I-Method
.	O
	
For	O
an	O
in	O
-	O
depth	O
mathematical	O
discussion	O
of	O
the	O
WL	B-Method
-	I-Method
1	I-Method
algorithm	I-Method
see	O
,	O
e.g.	O
,	O
.	O
	
We	O
can	O
replace	O
the	O
hash	B-Method
function	I-Method
in	O
Algorithm	O
[	O
reference	O
]	O
with	O
a	O
neural	B-Method
network	I-Method
layer	I-Method
-	I-Method
like	I-Method
differentiable	I-Method
function	I-Method
with	O
trainable	O
parameters	O
as	O
follows	O
:	O
where	O
is	O
an	O
appropriately	O
chosen	O
normalization	O
constant	O
for	O
the	O
edge	O
.	O
	
Further	O
,	O
we	O
can	O
take	O
now	O
to	O
be	O
a	O
vector	O
of	O
activations	O
of	O
node	O
in	O
the	O
neural	B-Method
network	I-Method
layer	I-Method
.	O
	
is	O
a	O
layer	O
-	O
specific	O
weight	O
matrix	O
and	O
denotes	O
a	O
differentiable	O
,	O
non	O
-	O
linear	O
activation	O
function	O
.	O
	
By	O
choosing	O
,	O
where	O
denotes	O
the	O
degree	O
of	O
node	O
,	O
we	O
recover	O
the	O
propagation	O
rule	O
of	O
our	O
Graph	B-Method
Convolutional	I-Method
Network	I-Method
(	O
GCN	B-Method
)	O
model	O
in	O
vector	O
form	O
(	O
see	O
Eq	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
This	O
—	O
loosely	O
speaking	O
—	O
allows	O
us	O
to	O
interpret	O
our	O
GCN	B-Method
model	I-Method
as	O
a	O
differentiable	B-Method
and	I-Method
parameterized	I-Method
generalization	I-Method
of	O
the	O
1	B-Method
-	I-Method
dim	I-Method
Weisfeiler	I-Method
-	I-Method
Lehman	I-Method
algorithm	I-Method
on	O
graphs	B-Method
.	O
	
subsection	O
:	O
Node	O
Embeddings	O
with	O
Random	O
Weights	O
	
From	O
the	O
analogy	O
with	O
the	O
Weisfeiler	B-Method
-	I-Method
Lehman	I-Method
algorithm	I-Method
,	O
we	O
can	O
understand	O
that	O
even	O
an	O
untrained	B-Method
GCN	I-Method
model	I-Method
with	O
random	O
weights	O
can	O
serve	O
as	O
a	O
powerful	O
feature	B-Method
extractor	I-Method
for	O
nodes	O
in	O
a	O
graph	O
.	O
	
As	O
an	O
example	O
,	O
consider	O
the	O
following	O
3	B-Method
-	I-Method
layer	I-Method
GCN	I-Method
model	I-Method
:	O
with	O
weight	O
matrices	O
initialized	O
at	O
random	O
using	O
the	O
initialization	O
described	O
in	O
.	O
,	O
and	O
are	O
defined	O
as	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
We	O
apply	O
this	O
model	O
on	O
Zachary	O
’s	O
karate	O
club	O
network	O
zachary1977information	O
.	O
	
This	O
graph	O
contains	O
34	O
nodes	O
,	O
connected	O
by	O
154	O
(	O
undirected	O
and	O
unweighted	O
)	O
edges	O
.	O
	
Every	O
node	O
is	O
labeled	O
by	O
one	O
of	O
four	O
classes	O
,	O
obtained	O
via	O
modularity	B-Method
-	I-Method
based	I-Method
clustering	I-Method
brandes2008modularity	O
.	O
	
See	O
Figure	O
[	O
reference	O
]	O
for	O
an	O
illustration	O
.	O
	
[	O
b	O
]	O
0.5	O
[	O
b	O
]	O
0.5	O
	
We	O
take	O
a	O
featureless	B-Method
approach	I-Method
by	O
setting	O
,	O
where	O
is	O
the	O
by	O
identity	O
matrix	O
.	O
	
is	O
the	O
number	O
of	O
nodes	O
in	O
the	O
graph	O
.	O
	
Note	O
that	O
nodes	O
are	O
randomly	O
ordered	O
(	O
i.e.	O
ordering	O
contains	O
no	O
information	O
)	O
.	O
	
Furthermore	O
,	O
we	O
choose	O
a	O
hidden	O
layer	O
dimensionality	O
of	O
and	O
a	O
two	O
-	O
dimensional	O
output	O
(	O
so	O
that	O
the	O
output	O
can	O
immediately	O
be	O
visualized	O
in	O
a	O
2	O
-	O
dim	O
plot	O
)	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
a	O
representative	O
example	O
of	O
node	O
embeddings	O
(	O
outputs	O
)	O
obtained	O
from	O
an	O
untrained	B-Method
GCN	I-Method
model	I-Method
applied	O
to	O
the	O
karate	B-Method
club	I-Method
network	I-Method
.	O
	
These	O
results	O
are	O
comparable	O
to	O
embeddings	O
obtained	O
from	O
DeepWalk	B-Method
perozzi2014deepwalk	O
,	O
which	O
uses	O
a	O
more	O
expensive	O
unsupervised	B-Method
training	I-Method
procedure	I-Method
.	O
	
subsection	O
:	O
Semi	B-Task
-	I-Task
Supervised	I-Task
Node	I-Task
Embeddings	I-Task
	
On	O
this	O
simple	O
example	O
of	O
a	O
GCN	B-Method
applied	O
to	O
the	O
karate	B-Method
club	I-Method
network	I-Method
it	O
is	O
interesting	O
to	O
observe	O
how	O
embeddings	O
react	O
during	O
training	O
on	O
a	O
semi	B-Task
-	I-Task
supervised	I-Task
classification	I-Task
task	I-Task
.	O
	
Such	O
a	O
visualization	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
provides	O
insights	O
into	O
how	O
the	O
GCN	B-Method
model	I-Method
can	O
make	O
use	O
of	O
the	O
graph	O
structure	O
(	O
and	O
of	O
features	O
extracted	O
from	O
the	O
graph	O
structure	O
at	O
later	O
layers	O
)	O
to	O
learn	O
embeddings	B-Task
that	O
are	O
useful	O
for	O
a	O
classification	B-Task
task	I-Task
.	O
	
We	O
consider	O
the	O
following	O
semi	B-Task
-	I-Task
supervised	I-Task
learning	I-Task
setup	I-Task
:	O
we	O
add	O
a	O
softmax	B-Method
layer	I-Method
on	O
top	O
of	O
our	O
model	O
	
(	O
Eq	O
.	O
	
[	O
reference	O
]	O
)	O
and	O
train	O
using	O
only	O
a	O
single	O
labeled	O
example	O
per	O
class	O
(	O
i.e.	O
a	O
total	O
number	O
of	O
4	O
labeled	O
nodes	O
)	O
.	O
	
We	O
train	O
for	O
300	O
training	O
iterations	O
using	O
Adam	B-Method
kingma2014adam	I-Method
with	O
a	O
learning	B-Metric
rate	I-Metric
of	O
on	O
a	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
loss	I-Metric
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
the	O
evolution	O
of	O
node	O
embeddings	O
over	O
a	O
number	O
of	O
training	O
iterations	O
.	O
	
The	O
model	O
succeeds	O
in	O
linearly	O
separating	O
the	O
communities	O
based	O
on	O
minimal	O
supervision	O
and	O
the	O
graph	O
structure	O
alone	O
.	O
	
A	O
video	O
of	O
the	O
full	O
training	O
process	O
can	O
be	O
found	O
on	O
our	O
website	O
.	O
	
[	O
b	O
]	O
0.5	O
[	O
b	O
]	O
0.5	O
[	O
b	O
]	O
0.5	O
[	O
b	O
]	O
0.5	O
[	O
b	O
]	O
0.5	O
[	O
b	O
]	O
0.5	O
	
appendix	O
:	O
Experiments	O
on	O
Model	B-Task
Depth	I-Task
	
In	O
these	O
experiments	O
,	O
we	O
investigate	O
the	O
influence	O
of	O
model	O
depth	O
(	O
number	O
of	O
layers	O
)	O
on	O
classification	B-Task
performance	O
.	O
	
We	O
report	O
results	O
on	O
a	O
5	B-Metric
-	I-Metric
fold	I-Metric
cross	I-Metric
-	I-Metric
validation	I-Metric
experiment	I-Metric
on	O
the	O
Cora	B-Material
,	O
Citeseer	B-Material
and	O
Pubmed	B-Material
datasets	I-Material
sen2008collective	O
using	O
all	O
labels	O
.	O
	
In	O
addition	O
to	O
the	O
standard	O
GCN	B-Method
model	I-Method
(	O
Eq	O
.	O
	
[	O
reference	O
]	O
)	O
	
,	O
we	O
report	O
results	O
on	O
a	O
model	O
variant	O
where	O
we	O
use	O
residual	O
connections	O
he2015deep	O
between	O
hidden	O
layers	O
to	O
facilitate	O
training	O
of	O
deeper	B-Method
models	I-Method
by	O
enabling	O
the	O
model	O
to	O
carry	O
over	O
information	O
from	O
the	O
previous	O
layer	O
’s	O
input	O
:	O
On	O
each	O
cross	B-Metric
-	I-Metric
validation	I-Metric
split	I-Metric
,	O
we	O
train	O
for	O
400	O
epochs	O
(	O
without	O
early	O
stopping	O
)	O
using	O
the	O
Adam	B-Method
optimizer	I-Method
kingma2014adam	O
with	O
a	O
learning	B-Metric
rate	I-Metric
of	O
.	O
	
Other	O
hyperparameters	O
are	O
chosen	O
as	O
follows	O
:	O
0.5	O
(	O
dropout	B-Method
rate	O
,	O
first	O
and	O
last	O
layer	O
)	O
,	O
(	O
L2	B-Method
regularization	I-Method
,	O
first	O
layer	O
)	O
,	O
16	O
(	O
number	O
of	O
units	O
for	O
each	O
hidden	O
layer	O
)	O
and	O
0.01	O
(	O
learning	B-Metric
rate	I-Metric
)	O
.	O
	
Results	O
are	O
summarized	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
[	O
b	O
]	O
0.33	O
[	O
b	O
]	O
0.33	O
	
[	O
b	O
]	O
0.33	O
	
For	O
the	O
datasets	O
considered	O
here	O
,	O
best	O
results	O
are	O
obtained	O
with	O
a	O
2	B-Method
-	I-Method
or	I-Method
3	I-Method
-	I-Method
layer	I-Method
model	I-Method
.	O
	
We	O
observe	O
that	O
for	O
models	O
deeper	O
than	O
7	O
layers	O
,	O
training	O
without	O
the	O
use	O
of	O
residual	O
connections	O
can	O
become	O
difficult	O
,	O
as	O
the	O
effective	O
context	O
size	O
for	O
each	O
node	O
increases	O
by	O
the	O
size	O
of	O
its	O
-	O
order	O
neighborhood	O
(	O
for	O
a	O
model	O
with	O
layers	O
)	O
with	O
each	O
additional	O
layer	O
.	O
	
Furthermore	O
,	O
overfitting	O
can	O
become	O
an	O
issue	O
as	O
the	O
number	O
of	O
parameters	O
increases	O
with	O
model	O
depth	O
.	O
	
document	O
:	O
Batch	B-Task
Normalization	I-Task
:	O
Accelerating	O
Deep	B-Method
Network	I-Method
Training	I-Method
by	O
Reducing	O
Internal	O
Covariate	O
Shift	O
	
Training	O
Deep	B-Method
Neural	I-Method
Networks	I-Method
is	O
complicated	O
by	O
the	O
fact	O
that	O
the	O
distribution	O
of	O
each	O
layer	O
’s	O
inputs	O
changes	O
during	O
training	O
,	O
as	O
the	O
parameters	O
of	O
the	O
previous	O
layers	O
change	O
.	O
	
This	O
slows	O
down	O
the	O
training	B-Task
by	O
requiring	O
lower	O
learning	B-Metric
rates	I-Metric
and	O
careful	O
parameter	B-Method
initialization	I-Method
,	O
and	O
makes	O
it	O
notoriously	O
hard	O
to	O
train	O
models	O
with	O
saturating	O
nonlinearities	O
.	O
	
We	O
refer	O
to	O
this	O
phenomenon	O
as	O
internal	O
covariate	O
shift	O
,	O
and	O
address	O
the	O
problem	O
by	O
normalizing	O
layer	O
inputs	O
.	O
	
Our	O
method	O
draws	O
its	O
strength	O
from	O
making	O
normalization	B-Method
a	O
part	O
of	O
the	O
model	B-Method
architecture	I-Method
and	O
performing	O
the	O
normalization	B-Method
for	O
each	O
training	O
mini	O
-	O
batch	O
.	O
	
Batch	B-Method
Normalization	I-Method
allows	O
us	O
to	O
use	O
much	O
higher	O
learning	B-Metric
rates	I-Metric
and	O
be	O
less	O
careful	O
about	O
initialization	B-Task
.	O
	
It	O
also	O
acts	O
as	O
a	O
regularizer	B-Method
,	O
in	O
some	O
cases	O
eliminating	O
the	O
need	O
for	O
Dropout	O
.	O
	
Applied	O
to	O
a	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
image	B-Method
classification	I-Method
model	I-Method
,	O
Batch	B-Method
Normalization	I-Method
achieves	O
the	O
same	O
accuracy	B-Metric
with	O
14	O
times	O
fewer	O
training	O
steps	O
,	O
and	O
beats	O
the	O
original	O
model	O
by	O
a	O
significant	O
margin	O
.	O
	
Using	O
an	O
ensemble	B-Method
of	I-Method
batch	I-Method
-	I-Method
normalized	I-Method
networks	I-Method
,	O
we	O
improve	O
upon	O
the	O
best	O
published	O
result	O
on	O
ImageNet	B-Task
classification	I-Task
:	O
reaching	O
4.9	O
%	O
	
top	B-Metric
-	I-Metric
5	I-Metric
validation	I-Metric
error	I-Metric
(	O
and	O
4.8	O
%	O
test	B-Metric
error	I-Metric
)	O
,	O
exceeding	O
the	O
accuracy	B-Metric
of	O
human	B-Metric
raters	I-Metric
.	O
	
section	O
:	O
Introduction	O
	
Deep	B-Method
learning	I-Method
has	O
dramatically	O
advanced	O
the	O
state	O
of	O
the	O
art	O
in	O
vision	B-Task
,	O
speech	B-Task
,	O
and	O
many	O
other	O
areas	O
.	O
	
Stochastic	B-Method
gradient	I-Method
descent	I-Method
(	O
SGD	B-Method
)	O
has	O
proved	O
to	O
be	O
an	O
effective	O
way	O
of	O
training	O
deep	B-Method
networks	I-Method
,	O
and	O
SGD	B-Method
variants	O
such	O
as	O
momentum	B-Method
and	O
Adagrad	B-Method
have	O
been	O
used	O
to	O
achieve	O
state	O
of	O
the	O
art	O
performance	O
.	O
	
SGD	B-Method
optimizes	O
the	O
parameters	O
of	O
the	O
network	O
,	O
so	O
as	O
to	O
minimize	O
the	O
loss	O
where	O
is	O
the	O
training	O
data	O
set	O
.	O
	
With	O
SGD	B-Method
,	O
the	O
training	O
proceeds	O
in	O
steps	O
,	O
and	O
at	O
each	O
step	O
we	O
consider	O
a	O
mini	O
-	O
batch	O
of	O
size	O
.	O
	
The	O
mini	O
-	O
batch	O
is	O
used	O
to	O
approximate	O
the	O
gradient	O
of	O
the	O
loss	O
function	O
with	O
respect	O
to	O
the	O
parameters	O
,	O
by	O
computing	O
Using	O
mini	O
-	O
batches	O
of	O
examples	O
,	O
as	O
opposed	O
to	O
one	O
example	O
at	O
a	O
time	O
,	O
is	O
helpful	O
in	O
several	O
ways	O
.	O
	
First	O
,	O
the	O
gradient	O
of	O
the	O
loss	O
over	O
a	O
mini	O
-	O
batch	O
is	O
an	O
estimate	O
of	O
the	O
gradient	O
over	O
the	O
training	O
set	O
,	O
whose	O
quality	O
improves	O
as	O
the	O
batch	O
size	O
increases	O
.	O
	
Second	O
,	O
computation	O
over	O
a	O
batch	O
can	O
be	O
much	O
more	O
efficient	O
than	O
computations	O
for	O
individual	O
examples	O
,	O
due	O
to	O
the	O
parallelism	O
afforded	O
by	O
the	O
modern	O
computing	B-Method
platforms	I-Method
.	O
	
While	O
stochastic	B-Method
gradient	I-Method
is	O
simple	O
and	O
effective	O
,	O
it	O
requires	O
careful	O
tuning	O
of	O
the	O
model	O
hyper	O
-	O
parameters	O
,	O
specifically	O
the	O
learning	B-Metric
rate	I-Metric
used	O
in	O
optimization	B-Task
,	O
as	O
well	O
as	O
the	O
initial	O
values	O
for	O
the	O
model	O
parameters	O
.	O
	
The	O
training	B-Task
is	O
complicated	O
by	O
the	O
fact	O
that	O
the	O
inputs	O
to	O
each	O
layer	O
are	O
affected	O
by	O
the	O
parameters	O
of	O
all	O
preceding	O
layers	O
–	O
	
so	O
that	O
small	O
changes	O
to	O
the	O
network	O
parameters	O
amplify	O
as	O
the	O
network	O
becomes	O
deeper	O
.	O
	
The	O
change	O
in	O
the	O
distributions	O
of	O
layers	O
’	O
inputs	O
presents	O
a	O
problem	O
because	O
the	O
layers	O
need	O
to	O
continuously	O
adapt	O
to	O
the	O
new	O
distribution	O
.	O
	
When	O
the	O
input	O
distribution	O
to	O
a	O
learning	B-Method
system	I-Method
changes	O
,	O
it	O
is	O
said	O
to	O
experience	O
covariate	O
shift	O
.	O
	
This	O
is	O
typically	O
handled	O
via	O
domain	B-Method
adaptation	I-Method
.	O
	
However	O
,	O
the	O
notion	O
of	O
covariate	O
shift	O
can	O
be	O
extended	O
beyond	O
the	O
learning	B-Method
system	I-Method
as	O
a	O
whole	O
,	O
to	O
apply	O
to	O
its	O
parts	O
,	O
such	O
as	O
a	O
sub	B-Method
-	I-Method
network	I-Method
or	O
a	O
layer	O
.	O
	
Consider	O
a	O
network	O
computing	O
where	O
and	O
are	O
arbitrary	O
transformations	O
,	O
and	O
the	O
parameters	O
are	O
to	O
be	O
learned	O
so	O
as	O
to	O
minimize	O
the	O
loss	O
.	O
	
Learning	B-Task
can	O
be	O
viewed	O
as	O
if	O
the	O
inputs	O
are	O
fed	O
into	O
the	O
sub	B-Method
-	I-Method
network	I-Method
	
For	O
example	O
,	O
a	O
gradient	B-Method
descent	I-Method
step	I-Method
(	O
for	O
batch	O
size	O
and	O
learning	B-Metric
rate	I-Metric
)	O
is	O
exactly	O
equivalent	O
to	O
that	O
for	O
a	O
stand	B-Method
-	I-Method
alone	I-Method
network	I-Method
with	O
input	O
.	O
	
Therefore	O
,	O
the	O
input	O
distribution	O
properties	O
that	O
make	O
training	O
more	O
efficient	O
–	O
such	O
as	O
having	O
the	O
same	O
distribution	O
between	O
the	O
training	O
and	O
test	O
data	O
–	O
apply	O
to	O
training	O
the	O
sub	B-Method
-	I-Method
network	I-Method
as	O
well	O
.	O
	
As	O
such	O
it	O
is	O
advantageous	O
for	O
the	O
distribution	O
of	O
to	O
remain	O
fixed	O
over	O
time	O
.	O
	
Then	O
,	O
does	O
not	O
have	O
to	O
readjust	O
to	O
compensate	O
for	O
the	O
change	O
in	O
the	O
distribution	O
of	O
.	O
	
Fixed	O
distribution	O
of	O
inputs	O
to	O
a	O
sub	O
-	O
network	O
would	O
have	O
positive	O
consequences	O
for	O
the	O
layers	O
outside	O
the	O
sub	O
-	O
network	O
,	O
as	O
well	O
.	O
	
Consider	O
a	O
layer	O
with	O
a	O
sigmoid	O
activation	O
function	O
where	O
is	O
the	O
layer	O
input	O
,	O
the	O
weight	O
matrix	O
and	O
bias	O
vector	O
are	O
the	O
layer	O
parameters	O
to	O
be	O
learned	O
,	O
and	O
.	O
	
As	O
increases	O
,	O
tends	O
to	O
zero	O
.	O
	
This	O
means	O
that	O
for	O
all	O
dimensions	O
of	O
except	O
those	O
with	O
small	O
absolute	O
values	O
,	O
the	O
gradient	O
flowing	O
down	O
to	O
will	O
vanish	O
and	O
the	O
model	O
will	O
train	O
slowly	O
.	O
	
However	O
,	O
since	O
is	O
affected	O
by	O
and	O
the	O
parameters	O
of	O
all	O
the	O
layers	O
below	O
,	O
changes	O
to	O
those	O
parameters	O
during	O
training	O
will	O
likely	O
move	O
many	O
dimensions	O
of	O
into	O
the	O
saturated	O
regime	O
of	O
the	O
nonlinearity	O
and	O
slow	O
down	O
the	O
convergence	B-Task
.	O
	
This	O
effect	O
is	O
amplified	O
as	O
the	O
network	O
depth	O
increases	O
.	O
	
In	O
practice	O
,	O
the	O
saturation	B-Task
problem	I-Task
and	O
the	O
resulting	O
vanishing	O
gradients	O
are	O
usually	O
addressed	O
by	O
using	O
Rectified	B-Method
Linear	I-Method
Units	I-Method
,	O
careful	O
initialization	O
,	O
and	O
small	O
learning	B-Metric
rates	I-Metric
.	O
	
If	O
,	O
however	O
,	O
we	O
could	O
ensure	O
that	O
the	O
distribution	O
of	O
nonlinearity	O
inputs	O
remains	O
more	O
stable	O
as	O
the	O
network	O
trains	O
,	O
then	O
the	O
optimizer	B-Method
would	O
be	O
less	O
likely	O
to	O
get	O
stuck	O
in	O
the	O
saturated	O
regime	O
,	O
and	O
the	O
training	O
would	O
accelerate	O
.	O
	
We	O
refer	O
to	O
the	O
change	O
in	O
the	O
distributions	O
of	O
internal	O
nodes	O
of	O
a	O
deep	B-Method
network	I-Method
,	O
in	O
the	O
course	O
of	O
training	O
,	O
as	O
Internal	O
Covariate	O
Shift	O
.	O
	
Eliminating	O
it	O
offers	O
a	O
promise	O
of	O
faster	O
training	B-Task
.	O
	
We	O
propose	O
a	O
new	O
mechanism	O
,	O
which	O
we	O
call	O
Batch	B-Method
Normalization	I-Method
,	O
that	O
takes	O
a	O
step	O
towards	O
reducing	O
internal	B-Task
covariate	I-Task
shift	I-Task
,	O
and	O
in	O
doing	O
so	O
dramatically	O
accelerates	O
the	O
training	O
of	O
deep	B-Method
neural	I-Method
nets	I-Method
.	O
	
It	O
accomplishes	O
this	O
via	O
a	O
normalization	B-Method
step	I-Method
that	O
fixes	O
the	O
means	O
and	O
variances	O
of	O
layer	O
inputs	O
.	O
	
Batch	B-Method
Normalization	I-Method
also	O
has	O
a	O
beneficial	O
effect	O
on	O
the	O
gradient	O
flow	O
through	O
the	O
network	O
,	O
by	O
reducing	O
the	O
dependence	O
of	O
gradients	O
on	O
the	O
scale	O
of	O
the	O
parameters	O
or	O
of	O
their	O
initial	O
values	O
.	O
	
This	O
allows	O
us	O
to	O
use	O
much	O
higher	O
learning	B-Metric
rates	I-Metric
without	O
the	O
risk	O
of	O
divergence	O
.	O
	
Furthermore	O
,	O
batch	B-Method
normalization	I-Method
regularizes	O
the	O
model	O
and	O
reduces	O
the	O
need	O
for	O
Dropout	O
.	O
	
Finally	O
,	O
Batch	B-Method
Normalization	I-Method
makes	O
it	O
possible	O
to	O
use	O
saturating	O
nonlinearities	O
by	O
preventing	O
the	O
network	O
from	O
getting	O
stuck	O
in	O
the	O
saturated	O
modes	O
.	O
	
In	O
Sec	O
.	O
	
[	O
reference	O
]	O
,	O
we	O
apply	O
Batch	B-Method
Normalization	I-Method
to	O
the	O
best	O
-	O
performing	O
ImageNet	B-Task
classification	I-Task
network	O
,	O
and	O
show	O
that	O
we	O
can	O
match	O
its	O
performance	O
using	O
only	O
7	O
%	O
of	O
the	O
training	O
steps	O
,	O
and	O
can	O
further	O
exceed	O
its	O
accuracy	B-Metric
by	O
a	O
substantial	O
margin	O
.	O
	
Using	O
an	O
ensemble	O
of	O
such	O
networks	O
trained	O
with	O
Batch	B-Method
Normalization	I-Method
,	O
we	O
achieve	O
the	O
top	B-Metric
-	I-Metric
5	I-Metric
error	I-Metric
rate	I-Metric
that	O
improves	O
upon	O
the	O
best	O
known	O
results	O
on	O
ImageNet	B-Task
classification	I-Task
.	O
	
section	O
:	O
Towards	O
Reducing	O
Internal	B-Task
Covariate	I-Task
Shift	I-Task
	
We	O
define	O
Internal	O
Covariate	O
Shift	O
as	O
the	O
change	O
in	O
the	O
distribution	O
of	O
network	O
activations	O
due	O
to	O
the	O
change	O
in	O
network	O
parameters	O
during	O
training	O
.	O
	
To	O
improve	O
the	O
training	B-Task
,	O
we	O
seek	O
to	O
reduce	O
the	O
internal	O
covariate	O
shift	O
.	O
	
By	O
fixing	O
the	O
distribution	O
of	O
the	O
layer	O
inputs	O
as	O
the	O
training	O
progresses	O
,	O
we	O
expect	O
to	O
improve	O
the	O
training	B-Metric
speed	I-Metric
.	O
	
It	O
has	O
been	O
long	O
known	O
that	O
the	O
network	B-Method
training	I-Method
converges	O
faster	O
if	O
its	O
inputs	O
are	O
whitened	O
–	O
i.e.	O
,	O
linearly	O
transformed	O
to	O
have	O
zero	O
means	O
and	O
unit	O
variances	O
,	O
and	O
decorrelated	O
.	O
	
As	O
each	O
layer	O
observes	O
the	O
inputs	O
produced	O
by	O
the	O
layers	O
below	O
,	O
it	O
would	O
be	O
advantageous	O
to	O
achieve	O
the	O
same	O
whitening	O
of	O
the	O
inputs	O
of	O
each	O
layer	O
.	O
	
By	O
whitening	O
the	O
inputs	O
to	O
each	O
layer	O
,	O
we	O
would	O
take	O
a	O
step	O
towards	O
achieving	O
the	O
fixed	O
distributions	O
of	O
inputs	O
that	O
would	O
remove	O
the	O
ill	O
effects	O
of	O
the	O
internal	O
covariate	O
shift	O
.	O
	
We	O
could	O
consider	O
whitening	O
activations	O
at	O
every	O
training	O
step	O
or	O
at	O
some	O
interval	O
,	O
either	O
by	O
modifying	O
the	O
network	O
directly	O
or	O
by	O
changing	O
the	O
parameters	O
of	O
the	O
optimization	B-Method
algorithm	I-Method
to	O
depend	O
on	O
the	O
network	O
activation	O
values	O
.	O
	
However	O
,	O
if	O
these	O
modifications	O
are	O
interspersed	O
with	O
the	O
optimization	B-Method
steps	I-Method
,	O
then	O
the	O
gradient	B-Method
descent	I-Method
step	I-Method
may	O
attempt	O
to	O
update	O
the	O
parameters	O
in	O
a	O
way	O
that	O
requires	O
the	O
normalization	O
to	O
be	O
updated	O
,	O
which	O
reduces	O
the	O
effect	O
of	O
the	O
gradient	O
step	O
.	O
	
For	O
example	O
,	O
consider	O
a	O
layer	O
with	O
the	O
input	O
that	O
adds	O
the	O
learned	O
bias	O
,	O
and	O
normalizes	O
the	O
result	O
by	O
subtracting	O
the	O
mean	O
of	O
the	O
activation	O
computed	O
over	O
the	O
training	O
data	O
:	O
where	O
,	O
is	O
the	O
set	O
of	O
values	O
of	O
over	O
the	O
training	O
set	O
,	O
and	O
.	O
	
If	O
a	O
gradient	B-Method
descent	I-Method
step	I-Method
ignores	O
the	O
dependence	O
of	O
on	O
,	O
then	O
it	O
will	O
update	O
,	O
where	O
.	O
	
Then	O
.	O
	
Thus	O
,	O
the	O
combination	O
of	O
the	O
update	O
to	O
and	O
subsequent	O
change	O
in	O
normalization	B-Task
led	O
to	O
no	O
change	O
in	O
the	O
output	O
of	O
the	O
layer	O
nor	O
,	O
consequently	O
,	O
the	O
loss	O
.	O
	
As	O
the	O
training	O
continues	O
,	O
will	O
grow	O
indefinitely	O
while	O
the	O
loss	O
remains	O
fixed	O
.	O
	
This	O
problem	O
can	O
get	O
worse	O
if	O
the	O
normalization	B-Method
not	O
only	O
centers	O
but	O
also	O
scales	O
the	O
activations	O
.	O
	
We	O
have	O
observed	O
this	O
empirically	O
in	O
initial	O
experiments	O
,	O
where	O
the	O
model	O
blows	O
up	O
when	O
the	O
normalization	O
parameters	O
are	O
computed	O
outside	O
the	O
gradient	B-Method
descent	I-Method
step	I-Method
.	O
	
The	O
issue	O
with	O
the	O
above	O
approach	O
is	O
that	O
the	O
gradient	B-Method
descent	I-Method
optimization	I-Method
does	O
not	O
take	O
into	O
account	O
the	O
fact	O
that	O
the	O
normalization	O
takes	O
place	O
.	O
	
To	O
address	O
this	O
issue	O
,	O
we	O
would	O
like	O
to	O
ensure	O
that	O
,	O
for	O
any	O
parameter	O
values	O
,	O
the	O
network	O
always	O
produces	O
activations	O
with	O
the	O
desired	O
distribution	O
.	O
	
Doing	O
so	O
would	O
allow	O
the	O
gradient	O
of	O
the	O
loss	O
with	O
respect	O
to	O
the	O
model	O
parameters	O
to	O
account	O
for	O
the	O
normalization	O
,	O
and	O
for	O
its	O
dependence	O
on	O
the	O
model	O
parameters	O
.	O
	
Let	O
again	O
be	O
a	O
layer	O
input	O
,	O
treated	O
as	O
a	O
vector	O
,	O
and	O
be	O
the	O
set	O
of	O
these	O
inputs	O
over	O
the	O
training	O
data	O
set	O
.	O
	
The	O
normalization	B-Task
can	O
then	O
be	O
written	O
as	O
a	O
transformation	O
which	O
depends	O
not	O
only	O
on	O
the	O
given	O
training	O
example	O
but	O
on	O
all	O
examples	O
	
–	O
each	O
of	O
which	O
depends	O
on	O
if	O
is	O
generated	O
by	O
another	O
layer	O
.	O
	
For	O
backpropagation	B-Task
,	O
we	O
would	O
need	O
to	O
compute	O
the	O
Jacobians	O
ignoring	O
the	O
latter	O
term	O
would	O
lead	O
to	O
the	O
explosion	O
described	O
above	O
.	O
	
Within	O
this	O
framework	O
,	O
whitening	O
the	O
layer	O
inputs	O
is	O
expensive	O
,	O
as	O
it	O
requires	O
computing	O
the	O
covariance	O
matrix	O
and	O
its	O
inverse	O
square	O
root	O
,	O
to	O
produce	O
the	O
whitened	O
activations	O
,	O
as	O
well	O
as	O
the	O
derivatives	O
of	O
these	O
transforms	O
for	O
backpropagation	B-Method
.	O
	
This	O
motivates	O
us	O
to	O
seek	O
an	O
alternative	O
that	O
performs	O
input	B-Task
normalization	I-Task
in	O
a	O
way	O
that	O
is	O
differentiable	O
and	O
does	O
not	O
require	O
the	O
analysis	O
of	O
the	O
entire	O
training	O
set	O
after	O
every	O
parameter	O
update	O
.	O
	
Some	O
of	O
the	O
previous	O
approaches	O
(	O
e.g.	O
)	O
use	O
statistics	O
computed	O
over	O
a	O
single	O
training	O
example	O
,	O
or	O
,	O
in	O
the	O
case	O
of	O
image	B-Task
networks	I-Task
,	O
over	O
different	O
feature	O
maps	O
at	O
a	O
given	O
location	O
.	O
	
However	O
,	O
this	O
changes	O
the	O
representation	O
ability	O
of	O
a	O
network	O
by	O
discarding	O
the	O
absolute	O
scale	O
of	O
activations	O
.	O
	
We	O
want	O
to	O
a	O
preserve	O
the	O
information	O
in	O
the	O
network	O
,	O
by	O
normalizing	O
the	O
activations	O
in	O
a	O
training	O
example	O
relative	O
to	O
the	O
statistics	O
of	O
the	O
entire	O
training	O
data	O
.	O
	
section	O
:	O
Normalization	B-Task
via	O
Mini	B-Method
-	I-Method
Batch	I-Method
Statistics	I-Method
	
Since	O
the	O
full	O
whitening	O
of	O
each	O
layer	O
’s	O
inputs	O
is	O
costly	O
and	O
not	O
everywhere	O
differentiable	O
,	O
we	O
make	O
two	O
necessary	O
simplifications	O
.	O
	
The	O
first	O
is	O
that	O
instead	O
of	O
whitening	O
the	O
features	O
in	O
layer	O
inputs	O
and	O
outputs	O
jointly	O
,	O
we	O
will	O
normalize	O
each	O
scalar	O
feature	O
independently	O
,	O
by	O
making	O
it	O
have	O
the	O
mean	O
of	O
zero	O
and	O
the	O
variance	O
of	O
1	O
.	O
	
For	O
a	O
layer	O
with	O
-	O
dimensional	O
input	O
,	O
we	O
will	O
normalize	O
each	O
dimension	O
where	O
the	O
expectation	O
and	O
variance	O
are	O
computed	O
over	O
the	O
training	O
data	O
set	O
.	O
	
As	O
shown	O
in	O
,	O
such	O
normalization	B-Method
speeds	O
up	O
convergence	B-Task
,	O
even	O
when	O
the	O
features	O
are	O
not	O
decorrelated	O
.	O
	
Note	O
that	O
simply	O
normalizing	O
each	O
input	O
of	O
a	O
layer	O
may	O
change	O
what	O
the	O
layer	O
can	O
represent	O
.	O
	
For	O
instance	O
,	O
normalizing	O
the	O
inputs	O
of	O
a	O
sigmoid	B-Method
would	O
constrain	O
them	O
to	O
the	O
linear	O
regime	O
of	O
the	O
nonlinearity	O
.	O
	
To	O
address	O
this	O
,	O
we	O
make	O
sure	O
that	O
the	O
transformation	O
inserted	O
in	O
the	O
network	O
can	O
represent	O
the	O
identity	B-Method
transform	I-Method
.	O
	
To	O
accomplish	O
this	O
,	O
we	O
introduce	O
,	O
for	O
each	O
activation	O
,	O
a	O
pair	O
of	O
parameters	O
,	O
which	O
scale	O
and	O
shift	O
the	O
normalized	O
value	O
:	O
These	O
parameters	O
are	O
learned	O
along	O
with	O
the	O
original	O
model	O
parameters	O
,	O
and	O
restore	O
the	O
representation	O
power	O
of	O
the	O
network	O
.	O
	
Indeed	O
,	O
by	O
setting	O
and	O
,	O
we	O
could	O
recover	O
the	O
original	O
activations	O
,	O
if	O
that	O
were	O
the	O
optimal	O
thing	O
to	O
do	O
.	O
	
In	O
the	O
batch	B-Task
setting	I-Task
where	O
each	O
training	O
step	O
is	O
based	O
on	O
the	O
entire	O
training	O
set	O
,	O
we	O
would	O
use	O
the	O
whole	O
set	O
to	O
normalize	O
activations	O
.	O
	
However	O
,	O
this	O
is	O
impractical	O
when	O
using	O
stochastic	B-Method
optimization	I-Method
.	O
	
Therefore	O
,	O
we	O
make	O
the	O
second	O
simplification	O
:	O
since	O
we	O
use	O
mini	O
-	O
batches	O
in	O
stochastic	B-Method
gradient	I-Method
training	I-Method
,	O
each	O
mini	O
-	O
batch	O
produces	O
estimates	O
of	O
the	O
mean	O
and	O
variance	O
of	O
each	O
activation	O
.	O
	
This	O
way	O
,	O
the	O
statistics	O
used	O
for	O
normalization	B-Task
can	O
fully	O
participate	O
in	O
the	O
gradient	B-Method
backpropagation	I-Method
.	O
	
Note	O
that	O
the	O
use	O
of	O
mini	O
-	O
batches	O
is	O
enabled	O
by	O
computation	O
of	O
per	O
-	O
dimension	O
variances	O
rather	O
than	O
joint	O
covariances	O
;	O
in	O
the	O
joint	O
case	O
,	O
regularization	B-Task
would	O
be	O
required	O
since	O
the	O
mini	O
-	O
batch	O
size	O
is	O
likely	O
to	O
be	O
smaller	O
than	O
the	O
number	O
of	O
activations	O
being	O
whitened	O
,	O
resulting	O
in	O
singular	O
covariance	O
matrices	O
.	O
	
Consider	O
a	O
mini	O
-	O
batch	O
of	O
size	O
.	O
	
Since	O
the	O
normalization	B-Method
is	O
applied	O
to	O
each	O
activation	O
independently	O
,	O
let	O
us	O
focus	O
on	O
a	O
particular	O
activation	O
and	O
omit	O
for	O
clarity	O
.	O
	
We	O
have	O
values	O
of	O
this	O
activation	O
in	O
the	O
mini	O
-	O
batch	O
,	O
	
Let	O
the	O
normalized	O
values	O
be	O
,	O
and	O
their	O
linear	B-Method
transformations	I-Method
be	O
.	O
	
We	O
refer	O
to	O
the	O
transform	O
as	O
the	O
Batch	B-Method
Normalizing	I-Method
Transform	I-Method
.	O
	
We	O
present	O
the	O
BN	B-Method
Transform	O
in	O
Algorithm	O
[	O
reference	O
]	O
.	O
	
In	O
the	O
algorithm	O
,	O
is	O
a	O
constant	O
added	O
to	O
the	O
mini	O
-	O
batch	O
variance	O
for	O
numerical	B-Metric
stability	I-Metric
.	O
	
Batch	B-Method
Normalizing	I-Method
Transform	I-Method
,	O
applied	O
to	O
activation	O
x	O
over	O
a	O
mini	O
-	O
batch	O
.	O
	
The	O
BN	B-Method
transform	O
can	O
be	O
added	O
to	O
a	O
network	O
to	O
manipulate	O
any	O
activation	O
.	O
	
In	O
the	O
notation	O
,	O
we	O
indicate	O
that	O
the	O
parameters	O
and	O
are	O
to	O
be	O
learned	O
,	O
but	O
it	O
should	O
be	O
noted	O
that	O
the	O
BN	B-Method
transform	O
does	O
not	O
independently	O
process	O
the	O
activation	O
in	O
each	O
training	O
example	O
.	O
	
Rather	O
,	O
depends	O
both	O
on	O
the	O
training	O
example	O
and	O
the	O
other	O
examples	O
in	O
the	O
mini	O
-	O
batch	O
.	O
	
The	O
scaled	O
and	O
shifted	O
values	O
are	O
passed	O
to	O
other	O
network	B-Method
layers	I-Method
.	O
	
The	O
normalized	O
activations	O
are	O
internal	O
to	O
our	O
transformation	O
,	O
but	O
their	O
presence	O
is	O
crucial	O
.	O
	
The	O
distributions	O
of	O
values	O
of	O
any	O
has	O
the	O
expected	O
value	O
of	O
and	O
the	O
variance	O
of	O
,	O
as	O
long	O
as	O
the	O
elements	O
of	O
each	O
mini	O
-	O
batch	O
are	O
sampled	O
from	O
the	O
same	O
distribution	O
,	O
and	O
if	O
we	O
neglect	O
.	O
	
This	O
can	O
be	O
seen	O
by	O
observing	O
that	O
and	O
,	O
and	O
taking	O
expectations	O
.	O
	
Each	O
normalized	O
activation	O
can	O
be	O
viewed	O
as	O
an	O
input	O
to	O
a	O
sub	B-Method
-	I-Method
network	I-Method
composed	O
of	O
the	O
linear	B-Method
transform	I-Method
,	O
followed	O
by	O
the	O
other	O
processing	O
done	O
by	O
the	O
original	O
network	O
.	O
	
These	O
sub	O
-	O
network	O
inputs	O
all	O
have	O
fixed	O
means	O
and	O
variances	O
,	O
and	O
although	O
the	O
joint	O
distribution	O
of	O
these	O
normalized	O
can	O
change	O
over	O
the	O
course	O
of	O
training	O
,	O
we	O
expect	O
that	O
the	O
introduction	O
of	O
normalized	O
inputs	O
accelerates	O
the	O
training	O
of	O
the	O
sub	B-Method
-	I-Method
network	I-Method
and	O
,	O
consequently	O
,	O
the	O
network	O
as	O
a	O
whole	O
.	O
	
During	O
training	B-Task
we	O
need	O
to	O
backpropagate	O
the	O
gradient	O
of	O
loss	O
through	O
this	O
transformation	O
,	O
as	O
well	O
as	O
compute	O
the	O
gradients	O
with	O
respect	O
to	O
the	O
parameters	O
of	O
the	O
BN	B-Method
transform	O
.	O
	
We	O
use	O
chain	O
rule	O
,	O
as	O
follows	O
(	O
before	O
simplification	O
)	O
:	O
Thus	O
,	O
BN	B-Method
transform	O
is	O
a	O
differentiable	B-Method
transformation	I-Method
that	O
introduces	O
normalized	O
activations	O
into	O
the	O
network	O
.	O
	
This	O
ensures	O
that	O
as	O
the	O
model	O
is	O
training	O
,	O
layers	O
can	O
continue	O
learning	O
on	O
input	O
distributions	O
that	O
exhibit	O
less	O
internal	O
covariate	O
shift	O
,	O
thus	O
accelerating	O
the	O
training	O
.	O
	
Furthermore	O
,	O
the	O
learned	O
affine	B-Method
transform	I-Method
applied	O
to	O
these	O
normalized	O
activations	O
allows	O
the	O
BN	B-Method
transform	O
to	O
represent	O
the	O
identity	O
transformation	O
and	O
preserves	O
the	O
network	O
capacity	O
.	O
	
subsection	O
:	O
Training	O
and	O
Inference	B-Task
with	O
Batch	B-Method
-	I-Method
Normalized	I-Method
Networks	I-Method
	
To	O
Batch	O
-	O
Normalize	O
a	O
network	O
,	O
we	O
specify	O
a	O
subset	O
of	O
activations	O
and	O
insert	O
the	O
BN	B-Method
transform	O
for	O
each	O
of	O
them	O
,	O
according	O
to	O
Alg	O
.	O
	
[	O
reference	O
]	O
.	O
	
Any	O
layer	O
that	O
previously	O
received	O
as	O
the	O
input	O
,	O
now	O
receives	O
.	O
	
A	O
model	O
employing	O
Batch	B-Task
Normalization	I-Task
can	O
be	O
trained	O
using	O
batch	B-Method
gradient	I-Method
descent	I-Method
,	O
or	O
Stochastic	B-Method
Gradient	I-Method
Descent	I-Method
with	O
a	O
mini	O
-	O
batch	O
size	O
,	O
or	O
with	O
any	O
of	O
its	O
variants	O
such	O
as	O
Adagrad	B-Method
.	O
	
The	O
normalization	O
of	O
activations	O
that	O
depends	O
on	O
the	O
mini	O
-	O
batch	O
allows	O
efficient	O
training	B-Task
,	O
but	O
is	O
neither	O
necessary	O
nor	O
desirable	O
during	O
inference	B-Task
;	O
we	O
want	O
the	O
output	O
to	O
depend	O
only	O
on	O
the	O
input	O
,	O
deterministically	O
.	O
	
For	O
this	O
,	O
once	O
the	O
network	O
has	O
been	O
trained	O
,	O
we	O
use	O
the	O
normalization	B-Method
using	O
the	O
population	O
,	O
rather	O
than	O
mini	O
-	O
batch	O
,	O
statistics	O
.	O
	
Neglecting	O
,	O
these	O
normalized	O
activations	O
have	O
the	O
same	O
mean	O
0	O
and	O
variance	O
1	O
as	O
during	O
training	O
.	O
	
We	O
use	O
the	O
unbiased	B-Method
variance	I-Method
estimate	I-Method
,	O
where	O
the	O
expectation	O
is	O
over	O
training	O
mini	O
-	O
batches	O
of	O
size	O
and	O
are	O
their	O
sample	O
variances	O
.	O
	
Using	O
moving	B-Method
averages	I-Method
instead	O
,	O
we	O
can	O
track	O
the	O
accuracy	B-Metric
of	O
a	O
model	O
as	O
it	O
trains	O
.	O
	
Since	O
the	O
means	O
and	O
variances	O
are	O
fixed	O
during	O
inference	B-Task
,	O
the	O
normalization	B-Method
is	O
simply	O
a	O
linear	B-Method
transform	I-Method
applied	O
to	O
each	O
activation	O
.	O
	
It	O
may	O
further	O
be	O
composed	O
with	O
the	O
scaling	O
by	O
and	O
shift	O
by	O
,	O
to	O
yield	O
a	O
single	O
linear	B-Method
transform	I-Method
that	O
replaces	O
.	O
	
Algorithm	O
[	O
reference	O
]	O
summarizes	O
the	O
procedure	O
for	O
training	O
batch	B-Method
-	I-Method
normalized	I-Method
networks	I-Method
.	O
	
Training	O
a	O
Batch	B-Method
-	I-Method
Normalized	I-Method
Network	I-Method
	
[	O
1	O
]	O
Batch	B-Method
-	I-Method
normalized	I-Method
network	I-Method
for	O
inference	B-Task
,	O
Training	O
BN	B-Method
network	O
Add	O
transformation	B-Task
to	O
(	O
Alg	O
.	O
	
[	O
reference	O
]	O
)	O
	
Modify	O
each	O
layer	O
in	O
with	O
input	O
to	O
take	O
instead	O
Train	O
to	O
optimize	O
the	O
parameters	O
For	O
clarity	O
,	O
,	O
etc	O
.	O
	
Process	O
multiple	O
training	O
mini	O
-	O
batches	O
,	O
each	O
of	O
size	O
,	O
and	O
average	O
over	O
them	O
:	O
In	O
,	O
replace	O
the	O
transform	O
with	O
	
subsection	O
:	O
Batch	B-Method
-	I-Method
Normalized	I-Method
Convolutional	I-Method
Networks	I-Method
	
Batch	B-Method
Normalization	I-Method
can	O
be	O
applied	O
to	O
any	O
set	O
of	O
activations	O
in	O
the	O
network	O
.	O
	
Here	O
,	O
we	O
focus	O
on	O
transforms	O
that	O
consist	O
of	O
an	O
affine	O
transformation	O
followed	O
by	O
an	O
element	O
-	O
wise	O
nonlinearity	O
:	O
where	O
and	O
are	O
learned	O
parameters	O
of	O
the	O
model	O
,	O
and	O
is	O
the	O
nonlinearity	O
such	O
as	O
sigmoid	B-Method
or	O
ReLU	B-Method
.	O
	
This	O
formulation	O
covers	O
both	O
fully	B-Method
-	I-Method
connected	I-Method
and	I-Method
convolutional	I-Method
layers	I-Method
.	O
	
We	O
add	O
the	O
BN	B-Method
transform	O
immediately	O
before	O
the	O
nonlinearity	O
,	O
by	O
normalizing	O
.	O
	
We	O
could	O
have	O
also	O
normalized	O
the	O
layer	O
inputs	O
,	O
but	O
since	O
is	O
likely	O
the	O
output	O
of	O
another	O
nonlinearity	O
,	O
the	O
shape	O
of	O
its	O
distribution	O
is	O
likely	O
to	O
change	O
during	O
training	O
,	O
and	O
constraining	O
its	O
first	O
and	O
second	O
moments	O
would	O
not	O
eliminate	O
the	O
covariate	O
shift	O
.	O
	
In	O
contrast	O
,	O
is	O
more	O
likely	O
to	O
have	O
a	O
symmetric	O
,	O
non	O
-	O
sparse	O
distribution	O
,	O
that	O
is	O
“	O
more	O
Gaussian	O
”	O
;	O
normalizing	O
it	O
is	O
likely	O
to	O
produce	O
activations	O
with	O
a	O
stable	O
distribution	O
.	O
	
Note	O
that	O
,	O
since	O
we	O
normalize	O
,	O
the	O
bias	O
can	O
be	O
ignored	O
since	O
its	O
effect	O
will	O
be	O
canceled	O
by	O
the	O
subsequent	O
mean	B-Method
subtraction	I-Method
(	O
the	O
role	O
of	O
the	O
bias	O
is	O
subsumed	O
by	O
in	O
Alg	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
Thus	O
,	O
is	O
replaced	O
with	O
where	O
the	O
BN	B-Method
transform	O
is	O
applied	O
independently	O
to	O
each	O
dimension	O
of	O
,	O
with	O
a	O
separate	O
pair	O
of	O
learned	O
parameters	O
,	O
per	O
dimension	O
.	O
	
For	O
convolutional	O
layers	O
,	O
we	O
additionally	O
want	O
the	O
normalization	O
to	O
obey	O
the	O
convolutional	O
property	O
–	O
	
so	O
that	O
different	O
elements	O
of	O
the	O
same	O
feature	O
map	O
,	O
at	O
different	O
locations	O
,	O
are	O
normalized	O
in	O
the	O
same	O
way	O
.	O
	
To	O
achieve	O
this	O
,	O
we	O
jointly	O
normalize	O
all	O
the	O
activations	O
in	O
a	O
mini	O
-	O
batch	O
,	O
over	O
all	O
locations	O
.	O
	
In	O
Alg	O
.	O
	
[	O
reference	O
]	O
,	O
we	O
let	O
be	O
the	O
set	O
of	O
all	O
values	O
in	O
a	O
feature	O
map	O
across	O
both	O
the	O
elements	O
of	O
a	O
mini	O
-	O
batch	O
and	O
spatial	O
locations	O
–	O
	
so	O
for	O
a	O
mini	O
-	O
batch	O
of	O
size	O
and	O
feature	O
maps	O
of	O
size	O
,	O
we	O
use	O
the	O
effective	O
mini	O
-	O
batch	O
of	O
size	O
.	O
	
We	O
learn	O
a	O
pair	O
of	O
parameters	O
and	O
per	O
feature	O
map	O
,	O
rather	O
than	O
per	O
activation	O
.	O
	
Alg	O
.	O
	
[	O
reference	O
]	O
is	O
modified	O
similarly	O
,	O
so	O
that	O
during	O
inference	B-Task
the	O
BN	B-Method
transform	O
applies	O
the	O
same	O
linear	B-Method
transformation	I-Method
to	O
each	O
activation	O
in	O
a	O
given	O
feature	O
map	O
.	O
	
subsection	O
:	O
Batch	B-Method
Normalization	I-Method
enables	O
higher	O
learning	B-Metric
rates	I-Metric
	
In	O
traditional	O
deep	B-Method
networks	I-Method
,	O
too	O
-	O
high	O
learning	B-Metric
rate	I-Metric
may	O
result	O
in	O
the	O
gradients	O
that	O
explode	O
or	O
vanish	O
,	O
as	O
well	O
as	O
getting	O
stuck	O
in	O
poor	O
local	O
minima	O
.	O
	
Batch	B-Method
Normalization	I-Method
helps	O
address	O
these	O
issues	O
.	O
	
By	O
normalizing	O
activations	O
throughout	O
the	O
network	O
,	O
it	O
prevents	O
small	O
changes	O
to	O
the	O
parameters	O
from	O
amplifying	O
into	O
larger	O
and	O
suboptimal	O
changes	O
in	O
activations	O
in	O
gradients	O
;	O
for	O
instance	O
,	O
it	O
prevents	O
the	O
training	O
from	O
getting	O
stuck	O
in	O
the	O
saturated	O
regimes	O
of	O
nonlinearities	O
.	O
	
Batch	B-Method
Normalization	I-Method
also	O
makes	O
training	B-Task
more	O
resilient	O
to	O
the	O
parameter	O
scale	O
.	O
	
Normally	O
,	O
large	O
learning	B-Metric
rates	I-Metric
may	O
increase	O
the	O
scale	O
of	O
layer	O
parameters	O
,	O
which	O
then	O
amplify	O
the	O
gradient	O
during	O
backpropagation	O
and	O
lead	O
to	O
the	O
model	B-Task
explosion	I-Task
.	O
	
However	O
,	O
with	O
Batch	B-Method
Normalization	I-Method
,	O
backpropagation	B-Method
through	O
a	O
layer	O
is	O
unaffected	O
by	O
the	O
scale	O
of	O
its	O
parameters	O
.	O
	
Indeed	O
,	O
for	O
a	O
scalar	O
,	O
and	O
we	O
can	O
show	O
that	O
The	O
scale	O
does	O
not	O
affect	O
the	O
layer	O
Jacobian	O
nor	O
,	O
consequently	O
,	O
the	O
gradient	B-Method
propagation	I-Method
.	O
	
Moreover	O
,	O
larger	O
weights	O
lead	O
to	O
smaller	O
gradients	O
,	O
and	O
Batch	B-Method
Normalization	I-Method
will	O
stabilize	O
the	O
parameter	O
growth	O
.	O
	
We	O
further	O
conjecture	O
that	O
Batch	B-Method
Normalization	I-Method
may	O
lead	O
the	O
layer	O
Jacobians	O
to	O
have	O
singular	O
values	O
close	O
to	O
1	O
,	O
which	O
is	O
known	O
to	O
be	O
beneficial	O
for	O
training	B-Task
.	O
	
Consider	O
two	O
consecutive	O
layers	O
with	O
normalized	O
inputs	O
,	O
and	O
the	O
transformation	O
between	O
these	O
normalized	O
vectors	O
:	O
.	O
	
If	O
we	O
assume	O
that	O
and	O
are	O
Gaussian	O
and	O
uncorrelated	O
,	O
and	O
that	O
is	O
a	O
linear	B-Method
transformation	I-Method
for	O
the	O
given	O
model	O
parameters	O
,	O
then	O
both	O
and	O
have	O
unit	O
covariances	O
,	O
and	O
.	O
	
Thus	O
,	O
,	O
and	O
so	O
all	O
singular	O
values	O
of	O
are	O
equal	O
to	O
1	O
,	O
which	O
preserves	O
the	O
gradient	O
magnitudes	O
during	O
backpropagation	O
.	O
	
In	O
reality	O
,	O
the	O
transformation	O
is	O
not	O
linear	O
,	O
and	O
the	O
normalized	O
values	O
are	O
not	O
guaranteed	O
to	O
be	O
Gaussian	O
nor	O
independent	O
,	O
but	O
we	O
nevertheless	O
expect	O
Batch	B-Method
Normalization	I-Method
to	O
help	O
make	O
gradient	B-Method
propagation	I-Method
better	O
behaved	O
.	O
	
The	O
precise	O
effect	O
of	O
Batch	B-Method
Normalization	I-Method
on	O
gradient	B-Task
propagation	I-Task
remains	O
an	O
area	O
of	O
further	O
study	O
.	O
	
subsection	O
:	O
Batch	B-Method
Normalization	I-Method
regularizes	O
the	O
model	O
	
When	O
training	O
with	O
Batch	B-Method
Normalization	I-Method
,	O
a	O
training	O
example	O
is	O
seen	O
in	O
conjunction	O
with	O
other	O
examples	O
in	O
the	O
mini	O
-	O
batch	O
,	O
and	O
the	O
training	B-Method
network	I-Method
no	O
longer	O
producing	O
deterministic	O
values	O
for	O
a	O
given	O
training	O
example	O
.	O
	
In	O
our	O
experiments	O
,	O
we	O
found	O
this	O
effect	O
to	O
be	O
advantageous	O
to	O
the	O
generalization	O
of	O
the	O
network	O
.	O
	
Whereas	O
Dropout	B-Method
is	O
typically	O
used	O
to	O
reduce	O
overfitting	B-Task
,	O
in	O
a	O
batch	B-Method
-	I-Method
normalized	I-Method
network	I-Method
we	O
found	O
that	O
it	O
can	O
be	O
either	O
removed	O
or	O
reduced	O
in	O
strength	O
.	O
	
section	O
:	O
Experiments	O
	
subsection	O
:	O
Activations	O
over	O
time	O
	
To	O
verify	O
the	O
effects	O
of	O
internal	O
covariate	O
shift	O
on	O
training	B-Task
,	O
and	O
the	O
ability	O
of	O
Batch	B-Method
Normalization	I-Method
to	O
combat	O
it	O
,	O
we	O
considered	O
the	O
problem	O
of	O
predicting	B-Task
the	I-Task
digit	I-Task
class	I-Task
on	O
the	O
MNIST	O
dataset	O
.	O
	
We	O
used	O
a	O
very	O
simple	O
network	O
,	O
with	O
a	O
28x28	O
binary	O
image	O
as	O
input	O
,	O
and	O
3	O
fully	B-Method
-	I-Method
connected	I-Method
hidden	I-Method
layers	I-Method
with	O
100	O
activations	O
each	O
.	O
	
Each	O
hidden	B-Method
layer	I-Method
computes	O
with	O
sigmoid	O
nonlinearity	O
,	O
and	O
the	O
weights	O
initialized	O
to	O
small	O
random	O
Gaussian	O
values	O
.	O
	
The	O
last	O
hidden	O
layer	O
is	O
followed	O
by	O
a	O
fully	B-Method
-	I-Method
connected	I-Method
layer	I-Method
with	O
10	O
activations	O
(	O
one	O
per	O
class	O
)	O
and	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
loss	I-Metric
.	O
	
We	O
trained	O
the	O
network	O
for	O
50000	O
steps	O
,	O
with	O
60	O
examples	O
per	O
mini	O
-	O
batch	O
.	O
	
We	O
added	O
Batch	O
Normalization	O
to	O
each	O
hidden	O
layer	O
of	O
the	O
network	O
,	O
as	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
.	O
	
We	O
were	O
interested	O
in	O
the	O
comparison	O
between	O
the	O
baseline	B-Method
and	I-Method
batch	I-Method
-	I-Method
normalized	I-Method
networks	I-Method
,	O
rather	O
than	O
achieving	O
the	O
state	O
of	O
the	O
art	O
performance	O
on	O
MNIST	B-Task
(	O
which	O
the	O
described	O
architecture	O
does	O
not	O
)	O
.	O
	
Figure	O
[	O
reference	O
]	O
(	O
a	O
)	O
shows	O
the	O
fraction	O
of	O
correct	O
predictions	O
by	O
the	O
two	O
networks	O
on	O
held	O
-	O
out	O
test	O
data	O
,	O
as	O
training	O
progresses	O
.	O
	
The	O
batch	B-Method
-	I-Method
normalized	I-Method
network	I-Method
enjoys	O
the	O
higher	O
test	B-Metric
accuracy	I-Metric
.	O
	
To	O
investigate	O
why	O
,	O
we	O
studied	O
inputs	O
to	O
the	O
sigmoid	O
,	O
in	O
the	O
original	O
network	B-Method
N	I-Method
and	O
batch	B-Method
-	I-Method
normalized	I-Method
network	I-Method
	
(	O
Alg	O
.	O
	
[	O
reference	O
]	O
)	O
over	O
the	O
course	O
of	O
training	O
.	O
	
In	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
b	O
,	O
c	O
)	O
we	O
show	O
,	O
for	O
one	O
typical	O
activation	O
from	O
the	O
last	O
hidden	O
layer	O
of	O
each	O
network	O
,	O
how	O
its	O
distribution	O
evolves	O
.	O
	
The	O
distributions	O
in	O
the	O
original	O
network	O
change	O
significantly	O
over	O
time	O
,	O
both	O
in	O
their	O
mean	O
and	O
the	O
variance	O
,	O
which	O
complicates	O
the	O
training	O
of	O
the	O
subsequent	O
layers	O
.	O
	
In	O
contrast	O
,	O
the	O
distributions	O
in	O
the	O
batch	B-Method
-	I-Method
normalized	I-Method
network	I-Method
are	O
much	O
more	O
stable	O
as	O
training	O
progresses	O
,	O
which	O
aids	O
the	O
training	O
.	O
	
subsection	O
:	O
ImageNet	B-Task
classification	I-Task
	
We	O
applied	O
Batch	B-Method
Normalization	I-Method
to	O
a	O
new	O
variant	O
of	O
the	O
Inception	B-Method
network	I-Method
,	O
trained	O
on	O
the	O
ImageNet	B-Task
classification	I-Task
task	O
.	O
	
The	O
network	O
has	O
a	O
large	O
number	O
of	O
convolutional	B-Method
and	I-Method
pooling	I-Method
layers	I-Method
,	O
with	O
a	O
softmax	B-Method
layer	I-Method
to	O
predict	O
the	O
image	O
class	O
,	O
out	O
of	O
1000	O
possibilities	O
.	O
	
Convolutional	B-Method
layers	I-Method
use	O
ReLU	B-Method
as	O
the	O
nonlinearity	O
.	O
	
The	O
main	O
difference	O
to	O
the	O
network	O
described	O
in	O
is	O
that	O
the	O
convolutional	B-Method
layers	I-Method
are	O
replaced	O
by	O
two	O
consecutive	O
layers	O
of	O
convolutions	B-Method
with	O
up	O
to	O
filters	O
.	O
	
The	O
network	O
contains	O
parameters	O
,	O
and	O
,	O
other	O
than	O
the	O
top	O
softmax	B-Method
layer	I-Method
,	O
has	O
no	O
fully	B-Method
-	I-Method
connected	I-Method
layers	I-Method
.	O
	
More	O
details	O
are	O
given	O
in	O
the	O
Appendix	O
.	O
	
We	O
refer	O
to	O
this	O
model	O
as	O
Inception	B-Method
in	O
the	O
rest	O
of	O
the	O
text	O
.	O
	
The	O
model	O
was	O
trained	O
using	O
a	O
version	O
of	O
Stochastic	B-Method
Gradient	I-Method
Descent	I-Method
with	O
momentum	B-Method
,	O
using	O
the	O
mini	O
-	O
batch	O
size	O
of	O
32	O
.	O
	
The	O
training	O
was	O
performed	O
using	O
a	O
large	O
-	O
scale	B-Method
,	I-Method
distributed	I-Method
architecture	I-Method
(	O
similar	O
to	O
)	O
.	O
	
All	O
networks	O
are	O
evaluated	O
as	O
training	O
progresses	O
by	O
computing	O
the	O
validation	B-Metric
accuracy	I-Metric
,	O
i.e.	O
the	O
probability	O
of	O
predicting	O
the	O
correct	O
label	O
out	O
of	O
1000	O
possibilities	O
,	O
on	O
a	O
held	O
-	O
out	O
set	O
,	O
using	O
a	O
single	O
crop	O
per	O
image	O
.	O
	
In	O
our	O
experiments	O
,	O
we	O
evaluated	O
several	O
modifications	O
of	O
Inception	B-Method
with	O
Batch	B-Method
Normalization	I-Method
.	O
	
In	O
all	O
cases	O
,	O
Batch	B-Method
Normalization	I-Method
was	O
applied	O
to	O
the	O
input	O
of	O
each	O
nonlinearity	O
,	O
in	O
a	O
convolutional	O
way	O
,	O
as	O
described	O
in	O
section	O
[	O
reference	O
]	O
,	O
while	O
keeping	O
the	O
rest	O
of	O
the	O
architecture	O
constant	O
.	O
	
subsubsection	O
:	O
Accelerating	O
BN	B-Method
Networks	O
	
Simply	O
adding	O
Batch	B-Method
Normalization	I-Method
to	O
a	O
network	O
does	O
not	O
take	O
full	O
advantage	O
of	O
our	O
method	O
.	O
	
To	O
do	O
so	O
,	O
we	O
further	O
changed	O
the	O
network	O
and	O
its	O
training	O
parameters	O
,	O
as	O
follows	O
:	O
Increase	O
learning	B-Metric
rate	I-Metric
.	O
	
In	O
a	O
batch	B-Method
-	I-Method
normalized	I-Method
model	I-Method
,	O
we	O
have	O
been	O
able	O
to	O
achieve	O
a	O
training	O
speedup	O
from	O
higher	O
learning	B-Metric
rates	I-Metric
,	O
with	O
no	O
ill	O
side	O
effects	O
(	O
Sec	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
Remove	O
Dropout	O
.	O
	
As	O
described	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
	
,	O
Batch	B-Method
Normalization	I-Method
fulfills	O
some	O
of	O
the	O
same	O
goals	O
as	O
Dropout	B-Task
.	O
	
Removing	O
Dropout	B-Method
from	O
Modified	O
BN	B-Method
-	O
Inception	B-Method
speeds	O
up	O
training	B-Task
,	O
without	O
increasing	O
overfitting	O
.	O
	
Reduce	O
the	O
L2	B-Method
weight	I-Method
regularization	I-Method
.	O
	
While	O
in	O
Inception	B-Method
an	O
loss	O
on	O
the	O
model	O
parameters	O
controls	O
overfitting	O
,	O
in	O
Modified	O
BN	B-Method
-	O
Inception	B-Method
the	O
weight	O
of	O
this	O
loss	O
is	O
reduced	O
by	O
a	O
factor	O
of	O
5	O
.	O
	
We	O
find	O
that	O
this	O
improves	O
the	O
accuracy	B-Metric
on	O
the	O
held	O
-	O
out	O
validation	O
data	O
.	O
	
Accelerate	O
the	O
learning	B-Metric
rate	I-Metric
decay	I-Metric
.	O
	
In	O
training	O
Inception	B-Method
,	O
learning	B-Metric
rate	I-Metric
was	O
decayed	O
exponentially	O
.	O
	
Because	O
our	O
network	O
trains	O
faster	O
than	O
Inception	B-Method
,	O
we	O
lower	O
the	O
learning	B-Metric
rate	I-Metric
6	O
times	O
faster	O
.	O
	
Remove	O
Local	B-Method
Response	I-Method
Normalization	I-Method
	
While	O
Inception	B-Method
and	O
other	O
networks	O
benefit	O
from	O
it	O
,	O
we	O
found	O
that	O
with	O
Batch	B-Method
Normalization	I-Method
it	O
is	O
not	O
necessary	O
.	O
	
Shuffle	O
training	O
examples	O
more	O
thoroughly	O
.	O
	
We	O
enabled	O
within	O
-	O
shard	O
shuffling	O
of	O
the	O
training	O
data	O
,	O
which	O
prevents	O
the	O
same	O
examples	O
from	O
always	O
appearing	O
in	O
a	O
mini	O
-	O
batch	O
together	O
.	O
	
This	O
led	O
to	O
about	O
1	O
%	O
improvements	O
in	O
the	O
validation	B-Metric
accuracy	I-Metric
,	O
which	O
is	O
consistent	O
with	O
the	O
view	O
of	O
Batch	B-Method
Normalization	I-Method
as	O
a	O
regularizer	B-Method
(	O
Sec	O
.	O
	
[	O
reference	O
]	O
)	O
:	O
	
the	O
randomization	O
inherent	O
in	O
our	O
method	O
should	O
be	O
most	O
beneficial	O
when	O
it	O
affects	O
an	O
example	O
differently	O
each	O
time	O
it	O
is	O
seen	O
.	O
	
Reduce	O
the	O
photometric	O
distortions	O
.	O
	
Because	O
batch	B-Method
-	I-Method
normalized	I-Method
networks	I-Method
train	O
faster	O
and	O
observe	O
each	O
training	O
example	O
fewer	O
times	O
,	O
we	O
let	O
the	O
trainer	O
focus	O
on	O
more	O
“	O
real	O
”	O
images	O
by	O
distorting	O
them	O
less	O
.	O
	
subsubsection	O
:	O
Single	B-Method
-	I-Method
Network	I-Method
Classification	I-Method
	
We	O
evaluated	O
the	O
following	O
networks	O
,	O
all	O
trained	O
on	O
the	O
LSVRC2012	O
training	O
data	O
,	O
and	O
tested	O
on	O
the	O
validation	O
data	O
:	O
Inception	B-Method
:	O
the	O
network	O
described	O
at	O
the	O
beginning	O
of	O
Section	O
[	O
reference	O
]	O
,	O
trained	O
with	O
the	O
initial	O
learning	B-Metric
rate	I-Metric
of	O
0.0015	O
.	O
	
BN	B-Method
-	O
Baseline	O
:	O
	
Same	O
as	O
Inception	B-Method
with	O
Batch	B-Method
Normalization	I-Method
before	O
each	O
nonlinearity	O
.	O
	
BN	B-Method
-	O
x5	O
:	O
	
Inception	B-Method
with	O
Batch	B-Method
Normalization	I-Method
and	O
the	O
modifications	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
.	O
	
The	O
initial	O
learning	B-Metric
rate	I-Metric
was	O
increased	O
by	O
a	O
factor	O
of	O
5	O
,	O
to	O
0.0075	O
.	O
	
The	O
same	O
learning	O
rate	O
increase	O
with	O
original	O
Inception	B-Method
caused	O
the	O
model	O
parameters	O
to	O
reach	O
machine	O
infinity	O
.	O
	
BN	B-Method
-	O
x30	O
:	O
	
Like	O
BN	B-Method
-	O
x5	O
,	O
but	O
with	O
the	O
initial	O
learning	B-Metric
rate	I-Metric
0.045	O
(	O
30	O
times	O
that	O
of	O
Inception	B-Method
)	O
.	O
	
BN	B-Method
-	O
x5	O
-	O
Sigmoid	O
	
:	O
	
Like	O
BN	B-Method
-	O
x5	O
,	O
but	O
with	O
sigmoid	O
nonlinearity	O
instead	O
of	O
ReLU	B-Method
.	O
	
We	O
also	O
attempted	O
to	O
train	O
the	O
original	O
Inception	B-Method
with	O
sigmoid	B-Method
,	O
but	O
the	O
model	O
remained	O
at	O
the	O
accuracy	B-Metric
equivalent	O
to	O
chance	O
.	O
	
In	O
Figure	O
[	O
reference	O
]	O
,	O
we	O
show	O
the	O
validation	B-Metric
accuracy	I-Metric
of	O
the	O
networks	O
,	O
as	O
a	O
function	O
of	O
the	O
number	O
of	O
training	O
steps	O
.	O
	
Inception	B-Method
reached	O
the	O
accuracy	B-Metric
of	O
72.2	O
%	O
after	O
training	O
steps	O
.	O
	
The	O
Figure	O
[	O
reference	O
]	O
shows	O
,	O
for	O
each	O
network	O
,	O
the	O
number	O
of	O
training	O
steps	O
required	O
to	O
reach	O
the	O
same	O
72.2	O
%	O
accuracy	B-Metric
,	O
as	O
well	O
as	O
the	O
maximum	B-Metric
validation	I-Metric
accuracy	I-Metric
reached	O
by	O
the	O
network	O
and	O
the	O
number	O
of	O
steps	O
to	O
reach	O
it	O
.	O
	
By	O
only	O
using	O
Batch	B-Method
Normalization	I-Method
(	O
BN	B-Method
-	O
Baseline	O
)	O
,	O
we	O
match	O
the	O
accuracy	B-Metric
of	O
Inception	B-Method
in	O
less	O
than	O
half	O
the	O
number	O
of	O
training	O
steps	O
.	O
	
By	O
applying	O
the	O
modifications	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
,	O
we	O
significantly	O
increase	O
the	O
training	B-Metric
speed	I-Metric
of	O
the	O
network	O
.	O
	
BN	B-Method
-	O
x5	O
needs	O
14	O
times	O
fewer	O
steps	O
than	O
Inception	B-Method
to	O
reach	O
the	O
72.2	O
%	O
accuracy	B-Metric
.	O
	
Interestingly	O
,	O
increasing	O
the	O
learning	B-Metric
rate	I-Metric
further	O
(	O
BN	B-Method
-	O
x30	O
)	O
causes	O
the	O
model	O
to	O
train	O
somewhat	O
slower	O
initially	O
,	O
but	O
allows	O
it	O
to	O
reach	O
a	O
higher	O
final	O
accuracy	B-Metric
.	O
	
It	O
reaches	O
74.8	O
%	O
after	O
steps	O
,	O
i.e.	O
5	O
times	O
fewer	O
steps	O
than	O
required	O
by	O
Inception	B-Method
to	O
reach	O
72.2	O
%	O
.	O
	
We	O
also	O
verified	O
that	O
the	O
reduction	O
in	O
internal	O
covariate	O
shift	O
allows	O
deep	B-Method
networks	I-Method
with	O
Batch	B-Method
Normalization	I-Method
to	O
be	O
trained	O
when	O
sigmoid	O
is	O
used	O
as	O
the	O
nonlinearity	O
,	O
despite	O
the	O
well	O
-	O
known	O
difficulty	O
of	O
training	O
such	O
networks	O
.	O
	
Indeed	O
,	O
BN	B-Method
-	O
x5	O
-	O
Sigmoid	O
achieves	O
the	O
accuracy	B-Metric
of	O
69.8	O
%	O
.	O
	
Without	O
Batch	B-Method
Normalization	I-Method
,	O
Inception	B-Method
with	O
sigmoid	B-Method
never	O
achieves	O
better	O
than	O
accuracy	B-Metric
.	O
	
subsubsection	O
:	O
Ensemble	B-Method
Classification	I-Method
	
The	O
current	O
reported	O
best	O
results	O
on	O
the	O
ImageNet	B-Task
Large	I-Task
Scale	I-Task
Visual	I-Task
Recognition	I-Task
Competition	I-Task
are	O
reached	O
by	O
the	O
Deep	B-Method
Image	I-Method
ensemble	I-Method
of	I-Method
traditional	I-Method
models	I-Method
and	O
the	O
ensemble	B-Method
model	I-Method
of	O
.	O
	
The	O
latter	O
reports	O
the	O
top	B-Metric
-	I-Metric
5	I-Metric
error	I-Metric
of	O
4.94	O
%	O
,	O
as	O
evaluated	O
by	O
the	O
ILSVRC	B-Method
server	I-Method
.	O
	
Here	O
we	O
report	O
a	O
top	B-Metric
-	I-Metric
5	I-Metric
validation	I-Metric
error	I-Metric
of	O
4.9	O
%	O
,	O
and	O
test	B-Metric
error	I-Metric
of	O
4.82	O
%	O
(	O
according	O
to	O
the	O
ILSVRC	B-Method
server	I-Method
)	O
.	O
	
This	O
improves	O
upon	O
the	O
previous	O
best	O
result	O
,	O
and	O
exceeds	O
the	O
estimated	O
accuracy	B-Metric
of	O
human	B-Metric
raters	I-Metric
according	O
to	O
.	O
	
For	O
our	O
ensemble	O
,	O
we	O
used	O
6	O
networks	O
.	O
	
Each	O
was	O
based	O
on	O
BN	B-Method
-	O
x30	O
,	O
modified	O
via	O
some	O
of	O
the	O
following	O
:	O
increased	O
initial	O
weights	O
in	O
the	O
convolutional	O
layers	O
;	O
using	O
Dropout	B-Method
(	O
with	O
the	O
Dropout	O
probability	O
of	O
5	O
%	O
or	O
10	O
%	O
,	O
vs.	O
40	O
%	O
for	O
the	O
original	O
Inception	B-Method
)	O
;	O
and	O
using	O
non	B-Method
-	I-Method
convolutional	I-Method
,	I-Method
per	I-Method
-	I-Method
activation	I-Method
Batch	I-Method
Normalization	I-Method
with	O
last	O
hidden	O
layers	O
of	O
the	O
model	O
.	O
	
Each	O
network	O
achieved	O
its	O
maximum	O
accuracy	B-Metric
after	O
about	O
training	O
steps	O
.	O
	
The	O
ensemble	B-Task
prediction	I-Task
was	O
based	O
on	O
the	O
arithmetic	O
average	O
of	O
class	O
probabilities	O
predicted	O
by	O
the	O
constituent	B-Method
networks	I-Method
.	O
	
The	O
details	O
of	O
ensemble	B-Method
and	I-Method
multicrop	I-Method
inference	I-Method
are	O
similar	O
to	O
.	O
	
We	O
demonstrate	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
that	O
batch	B-Method
normalization	I-Method
allows	O
us	O
to	O
set	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
by	O
a	O
healthy	O
margin	O
on	O
the	O
ImageNet	B-Material
classification	I-Material
challenge	I-Material
benchmarks	I-Material
.	O
	
section	O
:	O
Conclusion	O
	
We	O
have	O
presented	O
a	O
novel	O
mechanism	O
for	O
dramatically	O
accelerating	O
the	O
training	B-Task
of	I-Task
deep	I-Task
networks	I-Task
.	O
	
It	O
is	O
based	O
on	O
the	O
premise	O
that	O
covariate	O
shift	O
,	O
which	O
is	O
known	O
to	O
complicate	O
the	O
training	B-Task
of	I-Task
machine	I-Task
learning	I-Task
systems	I-Task
,	O
also	O
applies	O
to	O
sub	O
-	O
networks	O
and	O
layers	O
,	O
and	O
removing	O
it	O
from	O
internal	O
activations	O
of	O
the	O
network	O
may	O
aid	O
in	O
training	B-Task
.	O
	
Our	O
proposed	O
method	O
draws	O
its	O
power	O
from	O
normalizing	O
activations	O
,	O
and	O
from	O
incorporating	O
this	O
normalization	B-Method
in	O
the	O
network	B-Method
architecture	I-Method
itself	O
.	O
	
This	O
ensures	O
that	O
the	O
normalization	B-Task
is	O
appropriately	O
handled	O
by	O
any	O
optimization	B-Method
method	I-Method
that	O
is	O
being	O
used	O
to	O
train	O
the	O
network	O
.	O
	
To	O
enable	O
stochastic	B-Method
optimization	I-Method
methods	I-Method
commonly	O
used	O
in	O
deep	B-Task
network	I-Task
training	I-Task
,	O
we	O
perform	O
the	O
normalization	B-Method
for	O
each	O
mini	O
-	O
batch	O
,	O
and	O
backpropagate	O
the	O
gradients	O
through	O
the	O
normalization	O
parameters	O
.	O
	
Batch	B-Method
Normalization	I-Method
adds	O
only	O
two	O
extra	O
parameters	O
per	O
activation	O
,	O
and	O
in	O
doing	O
so	O
preserves	O
the	O
representation	O
ability	O
of	O
the	O
network	O
.	O
	
We	O
presented	O
an	O
algorithm	O
for	O
constructing	O
,	O
training	B-Task
,	O
and	O
performing	O
inference	B-Task
with	O
batch	B-Method
-	I-Method
normalized	I-Method
networks	I-Method
.	O
	
The	O
resulting	O
networks	O
can	O
be	O
trained	O
with	O
saturating	O
nonlinearities	O
,	O
are	O
more	O
tolerant	O
to	O
increased	O
training	B-Metric
rates	I-Metric
,	O
and	O
often	O
do	O
not	O
require	O
Dropout	B-Method
for	O
regularization	B-Task
.	O
	
Merely	O
adding	O
Batch	B-Method
Normalization	I-Method
to	O
a	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
image	B-Method
classification	I-Method
model	I-Method
yields	O
a	O
substantial	O
speedup	O
in	O
training	B-Task
.	O
	
By	O
further	O
increasing	O
the	O
learning	B-Metric
rates	I-Metric
,	O
removing	O
Dropout	B-Method
,	O
and	O
applying	O
other	O
modifications	O
afforded	O
by	O
Batch	B-Method
Normalization	I-Method
,	O
we	O
reach	O
the	O
previous	O
state	O
of	O
the	O
art	O
with	O
only	O
a	O
small	O
fraction	O
of	O
training	O
steps	O
–	O
and	O
then	O
beat	O
the	O
state	O
of	O
the	O
art	O
in	O
single	B-Task
-	I-Task
network	I-Task
image	I-Task
classification	I-Task
.	O
	
Furthermore	O
,	O
by	O
combining	O
multiple	O
models	O
trained	O
with	O
Batch	B-Method
Normalization	I-Method
,	O
we	O
perform	O
better	O
than	O
the	O
best	O
known	O
system	O
on	O
ImageNet	B-Material
,	O
by	O
a	O
significant	O
margin	O
.	O
	
Interestingly	O
,	O
our	O
method	O
bears	O
similarity	O
to	O
the	O
standardization	B-Method
layer	I-Method
of	O
,	O
though	O
the	O
two	O
methods	O
stem	O
from	O
very	O
different	O
goals	O
,	O
and	O
perform	O
different	O
tasks	O
.	O
	
The	O
goal	O
of	O
Batch	B-Task
Normalization	I-Task
is	O
to	O
achieve	O
a	O
stable	O
distribution	O
of	O
activation	O
values	O
throughout	O
training	O
,	O
and	O
in	O
our	O
experiments	O
we	O
apply	O
it	O
before	O
the	O
nonlinearity	O
since	O
that	O
is	O
where	O
matching	O
the	O
first	O
and	O
second	O
moments	O
is	O
more	O
likely	O
to	O
result	O
in	O
a	O
stable	O
distribution	O
.	O
	
On	O
the	O
contrary	O
,	O
apply	O
the	O
standardization	B-Method
layer	I-Method
to	O
the	O
output	O
of	O
the	O
nonlinearity	O
,	O
which	O
results	O
in	O
sparser	O
activations	O
.	O
	
In	O
our	O
large	B-Task
-	I-Task
scale	I-Task
image	I-Task
classification	I-Task
experiments	O
,	O
we	O
have	O
not	O
observed	O
the	O
nonlinearity	O
inputs	O
to	O
be	O
sparse	O
,	O
neither	O
with	O
nor	O
without	O
Batch	B-Method
Normalization	I-Method
.	O
	
Other	O
notable	O
differentiating	O
characteristics	O
of	O
Batch	B-Method
Normalization	I-Method
include	O
the	O
learned	O
scale	O
and	O
shift	O
that	O
allow	O
the	O
BN	B-Method
transform	O
to	O
represent	O
identity	O
(	O
the	O
standardization	B-Method
layer	I-Method
did	O
not	O
require	O
this	O
since	O
it	O
was	O
followed	O
by	O
the	O
learned	O
linear	B-Method
transform	I-Method
that	O
,	O
conceptually	O
,	O
absorbs	O
the	O
necessary	O
scale	O
and	O
shift	O
)	O
,	O
handling	O
of	O
convolutional	B-Method
layers	I-Method
,	O
deterministic	B-Method
inference	I-Method
that	O
does	O
not	O
depend	O
on	O
the	O
mini	O
-	O
batch	O
,	O
and	O
batch	B-Method
-	I-Method
normalizing	I-Method
each	I-Method
convolutional	I-Method
layer	I-Method
in	O
the	O
network	O
.	O
	
In	O
this	O
work	O
,	O
we	O
have	O
not	O
explored	O
the	O
full	O
range	O
of	O
possibilities	O
that	O
Batch	B-Method
Normalization	I-Method
potentially	O
enables	O
.	O
	
Our	O
future	O
work	O
includes	O
applications	O
of	O
our	O
method	O
to	O
Recurrent	B-Task
Neural	I-Task
Networks	I-Task
,	O
where	O
the	O
internal	O
covariate	O
shift	O
and	O
the	O
vanishing	O
or	O
exploding	O
gradients	O
may	O
be	O
especially	O
severe	O
,	O
and	O
which	O
would	O
allow	O
us	O
to	O
more	O
thoroughly	O
test	O
the	O
hypothesis	O
that	O
normalization	B-Method
improves	O
gradient	B-Task
propagation	I-Task
(	O
Sec	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
We	O
plan	O
to	O
investigate	O
whether	O
Batch	B-Method
Normalization	I-Method
can	O
help	O
with	O
domain	B-Task
adaptation	I-Task
,	O
in	O
its	O
traditional	O
sense	O
–	O
i.e.	O
whether	O
the	O
normalization	B-Method
performed	O
by	O
the	O
network	O
would	O
allow	O
it	O
to	O
more	O
easily	O
generalize	O
to	O
new	O
data	O
distributions	O
,	O
perhaps	O
with	O
just	O
a	O
recomputation	O
of	O
the	O
population	O
means	O
and	O
variances	O
(	O
Alg	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
Finally	O
,	O
we	O
believe	O
that	O
further	O
theoretical	O
analysis	O
of	O
the	O
algorithm	O
would	O
allow	O
still	O
more	O
improvements	O
and	O
applications	O
.	O
	
bibliography	O
:	O
References	O
	
section	O
:	O
Appendix	O
	
subsection	O
:	O
Variant	O
of	O
the	O
Inception	B-Method
Model	O
Used	O
	
Figure	O
[	O
reference	O
]	O
documents	O
the	O
changes	O
that	O
were	O
performed	O
compared	O
to	O
the	O
architecture	O
with	O
respect	O
to	O
the	O
GoogleNet	O
archictecture	O
.	O
	
For	O
the	O
interpretation	O
of	O
this	O
table	O
,	O
please	O
consult	O
.	O
	
The	O
notable	O
architecture	O
changes	O
compared	O
to	O
the	O
GoogLeNet	B-Method
model	I-Method
include	O
:	O
The	O
5	O
5	O
convolutional	B-Method
layers	I-Method
are	O
replaced	O
by	O
two	O
consecutive	O
3	B-Method
3	I-Method
convolutional	I-Method
layers	I-Method
.	O
	
This	O
increases	O
the	O
maximum	O
depth	O
of	O
the	O
network	O
by	O
9	O
weight	O
layers	O
.	O
	
Also	O
it	O
increases	O
the	O
number	O
of	O
parameters	O
by	O
25	O
%	O
and	O
the	O
computational	B-Metric
cost	I-Metric
is	O
increased	O
by	O
about	O
30	O
%	O
.	O
	
The	O
number	O
28	O
28	O
inception	B-Method
modules	O
is	O
increased	O
from	O
2	O
to	O
3	O
.	O
	
Inside	O
the	O
modules	O
,	O
sometimes	O
average	O
,	O
sometimes	O
maximum	B-Method
-	I-Method
pooling	I-Method
is	O
employed	O
.	O
	
This	O
is	O
indicated	O
in	O
the	O
entries	O
corresponding	O
to	O
the	O
pooling	O
layers	O
of	O
the	O
table	O
.	O
	
There	O
are	O
no	O
across	O
the	O
board	O
pooling	O
layers	O
between	O
any	O
two	O
Inception	B-Method
modules	O
,	O
but	O
stride	B-Method
-	I-Method
2	I-Method
convolution	I-Method
/	I-Method
pooling	I-Method
layers	I-Method
are	O
employed	O
before	O
the	O
filter	B-Method
concatenation	I-Method
in	O
the	O
modules	O
3c	O
,	O
4e	O
.	O
	
Our	O
model	O
employed	O
separable	B-Method
convolution	I-Method
with	O
depth	B-Method
multiplier	I-Method
on	O
the	O
first	O
convolutional	B-Method
layer	I-Method
.	O
	
This	O
reduces	O
the	O
computational	B-Metric
cost	I-Metric
while	O
increasing	O
the	O
memory	B-Metric
consumption	I-Metric
at	O
training	B-Metric
time	I-Metric
.	O
	
document	O
:	O
Unifying	O
Count	B-Method
-	I-Method
Based	I-Method
Exploration	I-Method
and	O
Intrinsic	B-Method
Motivation	I-Method
	
We	O
consider	O
an	O
agent	O
’s	O
uncertainty	O
about	O
its	O
environment	O
and	O
the	O
problem	O
of	O
generalizing	O
this	O
uncertainty	O
across	O
states	O
.	O
	
Specifically	O
,	O
we	O
focus	O
on	O
the	O
problem	O
of	O
exploration	B-Task
in	I-Task
non	I-Task
-	I-Task
tabular	I-Task
reinforcement	I-Task
learning	I-Task
.	O
	
Drawing	O
inspiration	O
from	O
the	O
intrinsic	O
motivation	O
literature	O
,	O
we	O
use	O
density	B-Method
models	I-Method
to	O
measure	O
uncertainty	O
,	O
and	O
propose	O
a	O
novel	O
algorithm	O
for	O
deriving	O
a	O
pseudo	O
-	O
count	O
from	O
an	O
arbitrary	O
density	B-Method
model	I-Method
.	O
	
This	O
technique	O
enables	O
us	O
to	O
generalize	O
count	B-Method
-	I-Method
based	I-Method
exploration	I-Method
algorithms	I-Method
to	O
the	O
non	B-Task
-	I-Task
tabular	I-Task
case	I-Task
.	O
	
We	O
apply	O
our	O
ideas	O
to	O
Atari	B-Task
2600	I-Task
games	I-Task
,	O
providing	O
sensible	O
pseudo	O
-	O
counts	O
from	O
raw	O
pixels	O
.	O
	
We	O
transform	O
these	O
pseudo	O
-	O
counts	O
into	O
exploration	O
bonuses	O
and	O
obtain	O
significantly	O
improved	O
exploration	B-Task
in	O
a	O
number	O
of	O
hard	B-Task
games	I-Task
,	O
including	O
the	O
infamously	O
difficult	O
Montezuma	B-Material
’s	I-Material
Revenge	I-Material
.	O
	
section	O
:	O
Introduction	O
	
Exploration	B-Method
algorithms	I-Method
for	O
Markov	B-Task
Decision	I-Task
Processes	I-Task
(	O
MDPs	B-Method
)	O
are	O
typically	O
concerned	O
with	O
reducing	O
the	O
agent	O
’s	O
uncertainty	O
over	O
the	O
environment	O
	
’s	O
reward	O
and	O
transition	O
functions	O
.	O
	
In	O
a	O
tabular	O
setting	O
,	O
this	O
uncertainty	O
can	O
be	O
quantified	O
using	O
confidence	O
intervals	O
derived	O
from	O
Chernoff	O
bounds	O
,	O
or	O
inferred	O
from	O
a	O
posterior	O
over	O
the	O
environment	O
parameters	O
.	O
	
In	O
fact	O
,	O
both	O
confidence	O
intervals	O
and	O
posterior	O
shrink	O
as	O
the	O
inverse	O
square	O
root	O
of	O
the	O
state	O
-	O
action	O
visit	O
count	O
,	O
making	O
this	O
quantity	O
fundamental	O
to	O
most	O
theoretical	O
results	O
on	O
exploration	B-Task
.	O
	
Count	B-Method
-	I-Method
based	I-Method
exploration	I-Method
methods	I-Method
directly	O
use	O
visit	O
counts	O
to	O
guide	O
an	O
agent	O
’s	O
behaviour	O
towards	O
reducing	B-Task
uncertainty	I-Task
.	O
	
For	O
example	O
,	O
Model	B-Method
-	I-Method
based	I-Method
Interval	I-Method
Estimation	I-Method
with	O
Exploration	B-Method
Bonuses	I-Method
[	O
MBIE	B-Method
-	O
EB;	O
][]	O
strehl08analysis	O
solves	O
the	O
augmented	B-Method
Bellman	I-Method
equation	I-Method
involving	O
the	O
empirical	O
reward	O
,	O
the	O
empirical	O
transition	O
function	O
,	O
and	O
an	O
exploration	O
bonus	O
proportional	O
to	O
.	O
	
This	O
bonus	O
accounts	O
for	O
uncertainties	O
in	O
both	O
transition	O
and	O
reward	O
functions	O
and	O
enables	O
a	O
finite	O
-	O
time	O
bound	O
on	O
the	O
agent	O
	
’s	O
suboptimality	O
.	O
	
In	O
spite	O
of	O
their	O
pleasant	O
theoretical	O
guarantees	O
,	O
count	B-Method
-	I-Method
based	I-Method
methods	I-Method
have	O
not	O
played	O
a	O
role	O
in	O
the	O
contemporary	O
successes	O
of	O
reinforcement	B-Task
learning	I-Task
[	O
e.g.	O
][]	O
mnih15human	O
.	O
	
Instead	O
,	O
most	O
practical	O
methods	O
still	O
rely	O
on	O
simple	O
rules	B-Method
such	O
as	O
-	O
greedy	O
.	O
	
The	O
issue	O
is	O
that	O
visit	O
counts	O
are	O
not	O
directly	O
useful	O
in	O
large	O
domains	O
,	O
where	O
states	O
are	O
rarely	O
visited	O
more	O
than	O
once	O
.	O
	
Answering	O
a	O
different	O
scientific	O
question	O
,	O
intrinsic	O
motivation	O
aims	O
to	O
provide	O
qualitative	O
guidance	O
for	O
exploration	B-Task
schmidhuber91possibility	O
,	O
oudeyer07intrinsic	O
,	O
	
barto13intrinsic	B-Method
.	O
	
This	O
guidance	O
can	O
be	O
summarized	O
as	O
“	O
explore	O
what	O
surprises	O
you	O
”	O
.	O
	
A	O
typical	O
approach	O
guides	O
the	O
agent	O
based	O
on	O
change	B-Metric
in	I-Metric
prediction	I-Metric
error	I-Metric
,	O
or	O
learning	O
progress	O
.	O
	
If	O
is	O
the	O
error	O
made	O
by	O
the	O
agent	O
at	O
time	O
over	O
some	O
event	O
A	O
,	O
and	O
the	O
same	O
error	O
after	O
observing	O
a	O
new	O
piece	O
of	O
information	O
,	O
then	O
learning	O
progress	O
is	O
Intrinsic	O
motivation	B-Method
methods	I-Method
are	O
attractive	O
as	O
they	O
remain	O
applicable	O
in	O
the	O
absence	O
of	O
the	O
Markov	O
property	O
or	O
the	O
lack	O
of	O
a	O
tabular	B-Method
representation	I-Method
,	O
both	O
of	O
which	O
are	O
required	O
by	O
count	B-Method
-	I-Method
based	I-Method
algorithms	I-Method
.	O
	
Yet	O
the	O
theoretical	O
foundations	O
of	O
intrinsic	B-Task
motivation	I-Task
remain	O
largely	O
absent	O
from	O
the	O
literature	O
,	O
which	O
may	O
explain	O
its	O
slow	O
rate	O
of	O
adoption	O
as	O
a	O
standard	O
approach	O
to	O
exploration	B-Task
.	O
	
In	O
this	O
paper	O
we	O
provide	O
formal	O
evidence	O
that	O
intrinsic	B-Task
motivation	I-Task
and	O
count	B-Method
-	I-Method
based	I-Method
exploration	I-Method
are	O
but	O
two	O
sides	O
of	O
the	O
same	O
coin	O
.	O
	
Specifically	O
,	O
we	O
consider	O
a	O
frequently	O
used	O
measure	O
of	O
learning	B-Metric
progress	I-Metric
,	O
information	B-Metric
gain	I-Metric
cover91elements	I-Metric
.	O
	
Defined	O
as	O
the	O
Kullback	O
-	O
Leibler	O
divergence	O
of	O
a	O
prior	O
distribution	O
from	O
its	O
posterior	O
,	O
information	B-Metric
gain	I-Metric
can	O
be	O
related	O
to	O
the	O
confidence	O
intervals	O
used	O
in	O
count	B-Method
-	I-Method
based	I-Method
exploration	I-Method
.	O
	
Our	O
contribution	O
is	O
to	O
propose	O
a	O
new	O
quantity	O
,	O
the	O
pseudo	B-Method
-	I-Method
count	I-Method
,	O
which	O
connects	O
information	B-Method
-	I-Method
gain	I-Method
-	I-Method
as	I-Method
-	I-Method
learning	I-Method
-	I-Method
progress	I-Method
and	O
count	B-Method
-	I-Method
based	I-Method
exploration	I-Method
.	O
	
We	O
derive	O
our	O
pseudo	O
-	O
count	O
from	O
a	O
density	B-Method
model	I-Method
over	O
the	O
state	O
space	O
.	O
	
This	O
is	O
in	O
departure	O
from	O
more	O
traditional	O
approaches	O
to	O
intrinsic	B-Task
motivation	I-Task
that	O
consider	O
learning	O
progress	O
with	O
respect	O
to	O
a	O
transition	B-Method
model	I-Method
.	O
	
We	O
expose	O
the	O
relationship	O
between	O
pseudo	O
-	O
counts	O
,	O
a	O
variant	O
of	O
schmidhuber91possibility	B-Method
’s	I-Method
compression	I-Method
progress	I-Method
we	O
call	O
prediction	B-Metric
gain	I-Metric
,	O
and	O
information	B-Metric
gain	I-Metric
.	O
	
Combined	O
to	O
kolter09near	O
’s	O
negative	O
result	O
on	O
the	O
frequentist	O
suboptimality	O
of	O
Bayesian	O
bonuses	O
,	O
our	O
result	O
highlights	O
the	O
theoretical	O
advantages	O
of	O
pseudo	O
-	O
counts	O
compared	O
to	O
many	O
existing	O
intrinsic	B-Method
motivation	I-Method
methods	I-Method
.	O
	
The	O
pseudo	O
-	O
counts	O
we	O
introduce	O
here	O
are	O
best	O
thought	O
of	O
as	O
“	O
function	B-Method
approximation	I-Method
for	O
exploration	B-Task
”	O
.	O
	
We	O
bring	O
them	O
to	O
bear	O
on	O
Atari	B-Task
2600	I-Task
games	I-Task
from	O
the	O
Arcade	B-Method
Learning	I-Method
Environment	I-Method
bellemare13arcade	O
,	O
focusing	O
on	O
games	O
where	O
myopic	B-Task
exploration	I-Task
fails	O
.	O
	
We	O
extract	O
our	O
pseudo	O
-	O
counts	O
from	O
a	O
simple	O
density	B-Method
model	I-Method
and	O
use	O
them	O
within	O
a	O
variant	O
of	O
MBIE	B-Method
-	I-Method
EB	I-Method
.	O
	
We	O
apply	O
them	O
to	O
an	O
experience	B-Task
replay	I-Task
setting	I-Task
and	O
to	O
an	O
actor	B-Method
-	I-Method
critic	I-Method
setting	I-Method
,	O
and	O
find	O
improved	O
performance	O
in	O
both	O
cases	O
.	O
	
Our	O
approach	O
produces	O
dramatic	O
progress	O
on	O
the	O
reputedly	O
most	O
difficult	O
Atari	O
2600	O
game	O
,	O
Montezuma	B-Material
’s	I-Material
Revenge	I-Material
:	O
within	O
a	O
fraction	O
of	O
the	O
training	O
time	O
,	O
our	O
agent	O
explores	O
a	O
significant	O
portion	O
of	O
the	O
first	O
level	O
and	O
obtains	O
significantly	O
higher	O
scores	O
than	O
previously	O
published	O
agents	O
.	O
	
section	O
:	O
Notation	O
	
We	O
consider	O
a	O
countable	O
state	O
space	O
.	O
	
We	O
denote	O
a	O
sequence	O
of	O
length	O
from	O
by	O
,	O
the	O
set	O
of	O
finite	O
sequences	O
from	O
by	O
,	O
write	O
to	O
mean	O
the	O
concatenation	O
of	O
and	O
a	O
state	O
,	O
and	O
denote	O
the	O
empty	O
sequence	O
by	O
.	O
	
A	O
model	O
over	O
is	O
a	O
mapping	O
from	O
to	O
probability	O
distributions	O
over	O
.	O
	
That	O
is	O
,	O
for	O
each	O
the	O
model	O
provides	O
a	O
probability	O
distribution	O
Note	O
that	O
we	O
do	O
not	O
require	O
to	O
be	O
strictly	O
positive	O
for	O
all	O
and	O
.	O
	
When	O
it	O
is	O
,	O
however	O
,	O
we	O
may	O
understand	O
to	O
be	O
the	O
usual	O
conditional	O
probability	O
of	O
given	O
.	O
	
We	O
will	O
take	O
particular	O
interest	O
in	O
the	O
empirical	O
distribution	O
derived	O
from	O
the	O
sequence	O
.	O
	
If	O
is	O
the	O
number	O
of	O
occurrences	O
of	O
a	O
state	O
in	O
the	O
sequence	O
,	O
then	O
We	O
call	O
the	O
the	O
empirical	O
count	O
function	O
,	O
or	O
simply	O
empirical	B-Method
count	I-Method
.	O
	
The	O
above	O
notation	O
extends	O
to	O
state	O
-	O
action	O
spaces	O
,	O
and	O
we	O
write	O
to	O
explicitly	O
refer	O
to	O
the	O
number	O
of	O
occurrences	O
of	O
a	O
state	O
-	O
action	O
pair	O
when	O
the	O
argument	O
requires	O
it	O
.	O
	
When	O
is	O
generated	O
by	O
an	O
ergodic	B-Method
Markov	I-Method
chain	I-Method
,	O
for	O
example	O
if	O
we	O
follow	O
a	O
fixed	B-Method
policy	I-Method
in	O
a	O
finite	B-Task
-	I-Task
state	I-Task
MDP	I-Task
,	O
then	O
the	O
limit	O
point	O
of	O
is	O
the	O
chain	B-Method
’s	I-Method
stationary	I-Method
distribution	I-Method
.	O
	
In	O
our	O
setting	O
,	O
a	O
density	B-Method
model	I-Method
is	O
any	O
model	O
that	O
assumes	O
states	O
are	O
independently	O
(	O
but	O
not	O
necessarily	O
identically	O
)	O
distributed	O
;	O
a	O
density	B-Method
model	I-Method
is	O
thus	O
a	O
particular	O
kind	O
of	O
generative	B-Method
model	I-Method
.	O
	
We	O
emphasize	O
that	O
a	O
density	B-Method
model	I-Method
differs	O
from	O
a	O
forward	B-Method
model	I-Method
,	O
which	O
takes	O
into	O
account	O
the	O
temporal	O
relationship	O
between	O
successive	O
states	O
.	O
	
Note	O
that	O
is	O
itself	O
a	O
density	B-Method
model	I-Method
.	O
	
section	O
:	O
From	O
Densities	O
to	O
Counts	O
	
In	O
the	O
introduction	O
we	O
argued	O
that	O
the	O
visit	O
count	O
(	O
and	O
consequently	O
,	O
)	O
is	O
not	O
directly	O
useful	O
in	O
practical	O
settings	O
,	O
since	O
states	O
are	O
rarely	O
revisited	O
.	O
	
Specifically	O
,	O
is	O
almost	O
always	O
zero	O
and	O
can	O
not	O
help	O
answer	O
the	O
question	O
“	O
	
How	O
novel	O
is	O
this	O
state	O
?	O
”	O
	
Nor	O
is	O
the	O
problem	O
solved	O
by	O
a	O
Bayesian	B-Method
approach	I-Method
:	O
even	O
variable	B-Method
-	I-Method
alphabet	I-Method
models	I-Method
[	O
e.g.	O
][]	O
hutter13sparse	O
must	O
assign	O
a	O
small	O
,	O
diminishing	O
probability	O
to	O
yet	O
-	O
unseen	O
states	O
.	O
	
To	O
estimate	O
the	O
uncertainty	O
of	O
an	O
agent	O
’s	O
knowledge	O
,	O
we	O
must	O
instead	O
look	O
for	O
a	O
quantity	O
which	O
generalizes	O
across	O
states	O
.	O
	
Guided	O
by	O
ideas	O
from	O
the	O
intrinsic	O
motivation	O
literature	O
,	O
we	O
now	O
derive	O
such	O
a	O
quantity	O
.	O
	
We	O
call	O
it	O
a	O
pseudo	O
-	O
count	O
as	O
it	O
extends	O
the	O
familiar	O
notion	O
from	O
Bayesian	B-Task
estimation	I-Task
.	O
	
subsection	O
:	O
Pseudo	O
-	O
Counts	O
and	O
the	O
Recoding	B-Method
Probability	I-Method
	
We	O
are	O
given	O
a	O
density	B-Method
model	I-Method
over	O
.	O
	
This	O
density	B-Method
model	I-Method
may	O
be	O
approximate	O
,	O
biased	O
,	O
or	O
even	O
inconsistent	O
.	O
	
We	O
begin	O
by	O
introducing	O
the	O
recoding	O
probability	O
of	O
a	O
state	O
:	O
This	O
is	O
the	O
probability	O
assigned	O
to	O
by	O
our	O
density	B-Method
model	I-Method
after	O
observing	O
a	O
new	O
occurrence	O
of	O
.	O
	
The	O
term	O
“	O
recoding	B-Task
”	O
is	O
inspired	O
from	O
the	O
statistical	B-Task
compression	I-Task
literature	I-Task
,	O
where	O
coding	B-Metric
costs	I-Metric
are	O
inversely	O
related	O
to	O
probabilities	O
cover91elements	O
.	O
	
When	O
admits	O
a	O
conditional	O
probability	O
distribution	O
,	O
We	O
now	O
postulate	O
two	O
unknowns	O
:	O
a	O
pseudo	B-Method
-	I-Method
count	I-Method
function	I-Method
,	O
and	O
a	O
pseudo	B-Method
-	I-Method
count	I-Method
total	I-Method
.	O
	
We	O
relate	O
these	O
two	O
unknowns	O
through	O
two	O
constraints	O
:	O
In	O
words	O
:	O
we	O
require	O
that	O
,	O
after	O
observing	O
one	O
instance	O
of	O
,	O
the	O
density	B-Method
model	I-Method
	
’s	O
increase	O
in	O
prediction	O
of	O
that	O
same	O
should	O
correspond	O
to	O
a	O
unit	O
increase	O
in	O
pseudo	O
-	O
count	O
.	O
	
The	O
pseudo	O
-	O
count	O
itself	O
is	O
derived	O
from	O
solving	O
the	O
linear	B-Method
system	I-Method
(	O
[	O
reference	O
]	O
)	O
:	O
	
Note	O
that	O
the	O
equations	O
(	O
[	O
reference	O
]	O
)	O
yield	O
(	O
with	O
)	O
when	O
,	O
and	O
are	O
inconsistent	O
when	O
.	O
	
These	O
cases	O
may	O
arise	O
from	O
poorly	O
behaved	O
density	B-Method
models	I-Method
,	O
but	O
are	O
easily	O
accounted	O
for	O
.	O
	
From	O
here	O
onwards	O
we	O
will	O
assume	O
a	O
consistent	O
system	O
of	O
equations	O
.	O
	
theorem	O
:	O
(	O
Learning	B-Method
-	I-Method
positive	I-Method
density	I-Method
model	I-Method
)	O
.	O
	
A	O
density	B-Method
model	I-Method
ρ	I-Method
is	O
learning	O
-	O
positive	O
if	O
for	O
all	O
∈x:1nXn	O
and	O
all	O
∈xX	O
,	O
≥⁢ρ′n	O
(	O
x	O
)	O
⁢ρn	O
(	O
x	O
)	O
.	O
	
By	O
inspecting	O
(	O
[	O
reference	O
]	O
)	O
,	O
we	O
see	O
that	O
if	O
and	O
only	O
if	O
is	O
learning	O
-	O
positive	O
;	O
if	O
and	O
only	O
if	O
;	O
and	O
if	O
and	O
only	O
if	O
.	O
	
In	O
many	O
cases	O
of	O
interest	O
,	O
the	O
pseudo	O
-	O
count	O
matches	O
our	O
intuition	O
.	O
	
If	O
then	O
.	O
	
Similarly	O
,	O
if	O
is	O
a	O
Dirichlet	B-Method
estimator	I-Method
then	O
recovers	O
the	O
usual	O
notion	O
of	O
pseudo	O
-	O
count	O
.	O
	
More	O
importantly	O
,	O
if	O
the	O
model	O
generalizes	O
across	O
states	O
then	O
so	O
do	O
pseudo	O
-	O
counts	O
.	O
	
subsection	O
:	O
Estimating	O
the	O
Frequency	B-Task
of	I-Task
a	I-Task
Salient	I-Task
Event	I-Task
in	O
Freeway	B-Material
	
As	O
an	O
illustrative	O
example	O
,	O
we	O
employ	O
our	O
method	O
to	O
estimate	O
the	O
number	O
of	O
occurrences	O
of	O
an	O
infrequent	O
event	O
in	O
the	O
Atari	B-Material
2600	I-Material
video	I-Material
game	I-Material
Freeway	I-Material
(	O
Figure	O
[	O
reference	O
]	O
,	O
screenshot	O
)	O
.	O
	
We	O
use	O
the	O
Arcade	B-Method
Learning	I-Method
Environment	I-Method
bellemare13arcade	O
.	O
	
We	O
will	O
demonstrate	O
the	O
following	O
:	O
Pseudo	O
-	O
counts	O
are	O
roughly	O
zero	O
for	O
novel	O
events	O
,	O
they	O
exhibit	O
credible	O
magnitudes	O
,	O
they	O
respect	O
the	O
ordering	O
of	O
state	O
frequency	O
,	O
they	O
grow	O
linearly	O
(	O
on	O
average	O
)	O
with	O
real	O
counts	O
,	O
they	O
are	O
robust	O
in	O
the	O
presence	O
of	O
nonstationary	O
data	O
.	O
	
These	O
properties	O
suggest	O
that	O
pseudo	O
-	O
counts	O
provide	O
an	O
appropriate	O
generalized	O
notion	O
of	O
visit	B-Task
counts	I-Task
in	O
non	B-Task
-	I-Task
tabular	I-Task
settings	I-Task
.	O
	
In	O
Freeway	B-Material
,	O
the	O
agent	O
must	O
navigate	O
a	O
chicken	O
across	O
a	O
busy	O
road	O
.	O
	
As	O
our	O
example	O
,	O
we	O
consider	O
estimating	O
the	O
number	O
of	O
times	O
the	O
chicken	O
has	O
reached	O
the	O
very	O
top	O
of	O
the	O
screen	O
.	O
	
As	O
is	O
the	O
case	O
for	O
many	O
Atari	B-Task
2600	I-Task
games	I-Task
,	O
this	O
naturally	O
salient	O
event	O
is	O
associated	O
with	O
an	O
increase	O
in	O
score	B-Metric
,	O
which	O
ALE	B-Method
translates	O
into	O
a	O
positive	O
reward	O
.	O
	
We	O
may	O
reasonably	O
imagine	O
that	O
knowing	O
how	O
certain	O
we	O
are	O
about	O
this	O
part	O
of	O
the	O
environment	O
is	O
useful	O
.	O
	
After	O
crossing	O
,	O
the	O
chicken	O
is	O
teleported	O
back	O
to	O
the	O
bottom	O
of	O
the	O
screen	O
.	O
	
To	O
highlight	O
the	O
robustness	O
of	O
our	O
pseudo	B-Method
-	I-Method
count	I-Method
,	O
we	O
consider	O
a	O
nonstationary	B-Method
policy	I-Method
which	O
waits	O
for	O
250	O
,	O
000	O
frames	O
,	O
then	O
applies	O
the	O
up	O
action	O
for	O
250	O
,	O
000	O
frames	O
,	O
then	O
waits	O
,	O
then	O
goes	O
up	O
again	O
.	O
	
The	O
salient	O
event	O
only	O
occurs	O
during	O
up	O
periods	O
.	O
	
It	O
also	O
occurs	O
with	O
the	O
cars	O
in	O
different	O
positions	O
,	O
thus	O
requiring	O
generalization	O
.	O
	
As	O
a	O
point	O
of	O
reference	O
,	O
we	O
record	O
the	O
pseudo	O
-	O
counts	O
for	O
both	O
the	O
salient	O
event	O
and	O
visits	O
to	O
the	O
chicken	O
’s	O
start	O
position	O
.	O
	
We	O
use	O
a	O
simplified	O
,	O
pixel	B-Method
-	I-Method
level	I-Method
version	I-Method
of	O
the	O
CTS	B-Method
model	I-Method
for	O
Atari	B-Material
2600	I-Material
frames	I-Material
proposed	O
by	O
bellemare14skip	O
,	O
ignoring	O
temporal	O
dependencies	O
.	O
	
While	O
the	O
CTS	B-Method
model	I-Method
is	O
rather	O
impoverished	O
in	O
comparison	O
to	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
density	B-Method
models	I-Method
for	O
images	O
[	O
e.g.	O
][]	O
vandenoord16pixel	O
,	O
its	O
count	O
-	O
based	O
nature	O
results	O
in	O
extremely	O
fast	O
learning	B-Task
,	O
making	O
it	O
an	O
appealing	O
candidate	O
for	O
exploration	B-Task
.	O
	
Further	O
details	O
on	O
the	O
model	O
may	O
be	O
found	O
in	O
the	O
appendix	O
.	O
	
Examining	O
the	O
pseudo	O
-	O
counts	O
depicted	O
in	O
Figure	O
[	O
reference	O
]	O
confirms	O
that	O
they	O
exhibit	O
the	O
desirable	O
properties	O
listed	O
above	O
.	O
	
In	O
particular	O
,	O
the	O
pseudo	B-Metric
-	I-Metric
count	I-Metric
is	O
almost	O
zero	O
on	O
the	O
first	O
occurrence	O
of	O
the	O
salient	O
event	O
;	O
it	O
increases	O
slightly	O
during	O
the	O
3rd	O
period	O
,	O
since	O
the	O
salient	O
and	O
reference	O
events	O
share	O
some	O
common	O
structure	O
;	O
throughout	O
,	O
it	O
remains	O
smaller	O
than	O
the	O
reference	O
pseudo	O
-	O
count	O
.	O
	
The	O
linearity	O
on	O
average	O
and	O
robustness	B-Metric
to	O
nonstationarity	O
are	O
immediate	O
from	O
the	O
graph	O
.	O
	
Note	O
,	O
however	O
,	O
that	O
the	O
pseudo	O
-	O
counts	O
are	O
a	O
fraction	O
of	O
the	O
real	O
visit	O
counts	O
(	O
inasmuch	O
as	O
we	O
can	O
define	O
“	O
real	O
”	O
)	O
	
:	O
by	O
the	O
end	O
of	O
the	O
trial	O
,	O
the	O
start	O
position	O
has	O
been	O
visited	O
about	O
140	O
,	O
000	O
times	O
,	O
and	O
the	O
topmost	O
part	O
of	O
the	O
screen	O
,	O
1285	O
times	O
.	O
	
Furthermore	O
,	O
the	O
ratio	O
of	O
recorded	O
pseudo	O
-	O
counts	O
differs	O
from	O
the	O
ratio	O
of	O
real	O
counts	O
.	O
	
Both	O
effects	O
are	O
quantifiable	O
,	O
as	O
we	O
shall	O
show	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
The	O
Connection	O
to	O
Intrinsic	B-Task
Motivation	I-Task
	
Having	O
argued	O
that	O
pseudo	O
-	O
counts	O
appropriately	O
generalize	O
visit	O
counts	O
,	O
we	O
will	O
now	O
show	O
that	O
they	O
are	O
closely	O
related	O
to	O
information	B-Metric
gain	I-Metric
,	O
which	O
is	O
commonly	O
used	O
to	O
quantify	O
novelty	O
or	O
curiosity	O
and	O
consequently	O
as	O
an	O
intrinsic	O
reward	O
.	O
	
Information	B-Task
gain	I-Task
is	O
defined	O
in	O
relation	O
to	O
a	O
mixture	B-Method
model	I-Method
over	O
a	O
class	O
of	O
density	B-Method
models	I-Method
.	O
	
This	O
model	O
predicts	O
according	O
to	O
a	O
weighted	O
combination	O
from	O
:	O
with	O
the	O
posterior	O
weight	O
of	O
.	O
	
This	O
posterior	O
is	O
defined	O
recursively	O
,	O
starting	O
from	O
a	O
prior	O
distribution	O
over	O
:	O
Information	B-Metric
gain	I-Metric
is	O
then	O
the	O
Kullback	O
-	O
Leibler	O
divergence	O
from	O
prior	O
to	O
posterior	O
that	O
results	O
from	O
observing	O
:	O
Computing	O
the	O
information	B-Metric
gain	I-Metric
of	O
a	O
complex	B-Method
density	I-Method
model	I-Method
is	O
often	O
impractical	O
,	O
if	O
not	O
downright	O
intractable	O
.	O
	
However	O
,	O
a	O
quantity	O
which	O
we	O
call	O
the	O
prediction	B-Metric
gain	I-Metric
provides	O
us	O
with	O
a	O
good	O
approximation	O
of	O
the	O
information	B-Metric
gain	I-Metric
.	O
	
We	O
define	O
the	O
prediction	B-Metric
gain	I-Metric
of	O
a	O
density	B-Method
model	I-Method
(	O
and	O
in	O
particular	O
,	O
)	O
as	O
the	O
difference	O
between	O
the	O
recoding	O
log	O
-	O
probability	O
and	O
log	B-Metric
-	I-Metric
probability	I-Metric
of	O
:	O
Prediction	B-Metric
gain	I-Metric
is	O
nonnegative	O
if	O
and	O
only	O
if	O
is	O
learning	O
-	O
positive	O
.	O
	
It	O
is	O
related	O
to	O
the	O
pseudo	O
-	O
count	O
:	O
with	O
equality	O
when	O
.	O
	
As	O
the	O
following	O
theorem	O
shows	O
,	O
prediction	O
gain	O
allows	O
us	O
to	O
relate	O
pseudo	O
-	O
count	O
and	O
information	O
gain	O
.	O
	
theorem	O
:	O
.	O
	
Consider	O
a	O
sequence	O
∈x:1nXn	O
.	O
	
Let	O
ξ	O
be	O
a	O
mixture	B-Method
model	I-Method
over	O
a	O
class	O
of	O
learning	B-Method
-	I-Method
positive	I-Method
models	I-Method
M.	I-Method
Let	O
	
^Nn	O
be	O
the	O
pseudo	O
-	O
count	O
derived	O
from	O
ξ	B-Method
(	O
Equation	O
)	O
.	O
	
For	O
this	O
model	O
,	O
Theorem	O
1	O
suggests	O
that	O
using	O
an	O
exploration	O
bonus	O
proportional	O
to	O
,	O
similar	O
to	O
the	O
MBIE	B-Method
-	I-Method
EB	I-Method
bonus	I-Method
,	O
leads	O
to	O
a	O
behaviour	O
at	O
least	O
as	O
exploratory	O
as	O
one	O
derived	O
from	O
an	O
information	B-Method
gain	I-Method
bonus	I-Method
.	O
	
Since	O
pseudo	O
-	O
counts	O
correspond	O
to	O
empirical	O
counts	O
in	O
the	O
tabular	O
setting	O
,	O
this	O
approach	O
also	O
preserves	O
known	O
theoretical	O
guarantees	O
.	O
	
In	O
fact	O
,	O
we	O
are	O
confident	O
pseudo	O
-	O
counts	O
may	O
be	O
used	O
to	O
prove	O
similar	O
results	O
in	O
non	B-Task
-	I-Task
tabular	I-Task
settings	I-Task
.	O
	
On	O
the	O
other	O
hand	O
,	O
it	O
may	O
be	O
difficult	O
to	O
provide	O
theoretical	O
guarantees	O
about	O
existing	O
bonus	B-Method
-	I-Method
based	I-Method
intrinsic	I-Method
motivation	I-Method
approaches	I-Method
.	O
	
kolter09near	O
showed	O
that	O
no	O
algorithm	O
based	O
on	O
a	O
bonus	O
upper	O
bounded	O
by	O
for	O
any	O
can	O
guarantee	O
PAC	B-Task
-	I-Task
MDP	I-Task
optimality	I-Task
.	O
	
Again	O
considering	O
the	O
tabular	O
setting	O
and	O
combining	O
their	O
result	O
to	O
Theorem	O
[	O
reference	O
]	O
,	O
we	O
conclude	O
that	O
bonuses	O
proportional	O
to	O
immediate	O
information	O
(	O
or	O
prediction	O
)	O
gain	O
are	O
insufficient	O
for	O
theoretically	B-Task
near	I-Task
-	I-Task
optimal	I-Task
exploration	I-Task
:	O
to	O
paraphrase	O
kolter09near	O
,	O
these	O
methods	O
produce	O
explore	O
too	O
little	O
in	O
comparison	O
to	O
pseudo	O
-	O
count	O
bonuses	O
.	O
	
By	O
inspecting	O
(	O
[	O
reference	O
]	O
)	O
we	O
come	O
to	O
a	O
similar	O
negative	O
conclusion	O
for	O
bonuses	O
proportional	O
to	O
the	O
L1	O
or	O
L2	O
distance	O
between	O
and	O
.	O
	
Unlike	O
many	O
intrinsic	B-Method
motivation	I-Method
algorithms	I-Method
,	O
pseudo	B-Method
-	I-Method
counts	I-Method
also	O
do	O
not	O
rely	O
on	O
learning	O
a	O
forward	B-Method
(	I-Method
transition	I-Method
and	I-Method
/	I-Method
or	I-Method
reward	I-Method
)	I-Method
model	I-Method
.	O
	
This	O
point	O
is	O
especially	O
important	O
because	O
a	O
number	O
of	O
powerful	O
density	B-Method
models	I-Method
for	O
images	O
exist	O
vandenoord16pixel	O
,	O
and	O
because	O
optimality	O
guarantees	O
can	O
not	O
in	O
general	O
exist	O
for	O
intrinsic	B-Method
motivation	I-Method
algorithms	I-Method
based	O
on	O
forward	B-Method
models	I-Method
.	O
	
section	O
:	O
Asymptotic	B-Task
Analysis	I-Task
	
In	O
this	O
section	O
we	O
analyze	O
the	O
limiting	O
behaviour	O
of	O
the	O
ratio	O
.	O
	
We	O
use	O
this	O
analysis	O
to	O
assert	O
the	O
consistency	O
of	O
pseudo	O
-	O
counts	O
derived	O
from	O
tabular	B-Method
density	I-Method
models	I-Method
,	O
i.e.	O
models	O
which	O
maintain	O
per	O
-	O
state	O
visit	O
counts	O
.	O
	
In	O
the	O
appendix	O
we	O
use	O
the	O
same	O
result	O
to	O
bound	O
the	O
approximation	B-Metric
error	I-Metric
of	I-Metric
pseudo	I-Metric
-	I-Metric
counts	I-Metric
derived	O
from	O
directed	B-Method
graphical	I-Method
models	I-Method
,	O
of	O
which	O
our	O
CTS	B-Method
model	I-Method
is	O
a	O
special	O
case	O
.	O
	
Consider	O
a	O
fixed	O
,	O
infinite	O
sequence	O
from	O
.	O
	
We	O
define	O
the	O
limit	O
of	O
a	O
sequence	O
of	O
functions	O
with	O
respect	O
to	O
the	O
length	O
of	O
the	O
subsequence	O
.	O
	
We	O
additionally	O
assume	O
that	O
the	O
empirical	O
distribution	O
converges	O
pointwise	O
to	O
a	O
distribution	O
,	O
and	O
write	O
for	O
the	O
recoding	O
probability	O
of	O
under	O
.	O
	
We	O
begin	O
with	O
two	O
assumptions	O
on	O
our	O
density	B-Method
model	I-Method
.	O
	
theorem	O
:	O
.	O
	
The	O
limits	O
exist	O
for	O
all	O
x	O
;	O
furthermore	O
,	O
>	O
⁢˙r	O
(	O
x	O
)	O
0	O
.	O
	
Assumption	O
(	O
a	O
)	O
states	O
that	O
should	O
eventually	O
assign	O
a	O
probability	O
to	O
proportional	O
to	O
the	O
limiting	O
empirical	O
distribution	O
.	O
	
In	O
particular	O
there	O
must	O
be	O
a	O
state	O
for	O
which	O
,	O
unless	O
.	O
	
Assumption	O
(	O
b	O
)	O
,	O
on	O
the	O
other	O
hand	O
,	O
imposes	O
a	O
restriction	O
on	O
the	O
learning	B-Metric
rate	I-Metric
of	O
relative	O
to	O
’	O
	
s.	O
	
As	O
both	O
and	O
exist	O
,	O
Assumption	O
[	O
reference	O
]	O
also	O
implies	O
that	O
and	O
have	O
a	O
common	O
limit	O
.	O
	
theorem	O
:	O
.	O
	
Under	O
Assumption	O
,	O
the	O
limit	O
of	O
the	O
ratio	O
of	O
pseudo	O
-	O
counts	O
⁢^Nn	O
(	O
x	O
)	O
to	O
empirical	O
counts	O
⁢Nn	O
(	O
x	O
)	O
exists	O
for	O
all	O
	
x.	O
	
This	O
limit	O
is	O
The	O
model	O
’s	O
relative	O
rate	O
of	O
change	O
,	O
whose	O
convergence	O
to	O
we	O
require	O
,	O
plays	O
an	O
essential	O
role	O
in	O
the	O
ratio	O
of	O
pseudo	O
-	O
to	O
empirical	O
counts	O
.	O
	
To	O
see	O
this	O
,	O
consider	O
a	O
sequence	O
generated	O
i.i.d	O
.	O
from	O
a	O
distribution	O
over	O
a	O
finite	O
state	O
space	O
,	O
and	O
a	O
density	B-Method
model	I-Method
defined	O
from	O
a	O
sequence	O
of	O
nonincreasing	O
step	O
-	O
sizes	O
:	O
with	O
initial	O
condition	O
.	O
	
For	O
,	O
this	O
density	B-Method
model	I-Method
is	O
the	O
empirical	B-Method
distribution	I-Method
.	O
	
For	O
,	O
we	O
may	O
appeal	O
to	O
well	O
-	O
known	O
results	O
from	O
stochastic	B-Method
approximation	I-Method
[	O
e.g.	O
][]	O
bertsekas96neurodynamic	O
and	O
find	O
that	O
almost	O
surely	O
Since	O
,	O
we	O
may	O
think	O
of	O
Assumption	O
1	O
(	O
b	O
)	O
as	O
also	O
requiring	O
to	O
converge	O
at	O
a	O
rate	O
of	O
for	O
a	O
comparison	O
with	O
the	O
empirical	O
count	O
to	O
be	O
meaningful	O
.	O
	
Note	O
,	O
however	O
,	O
that	O
a	O
density	B-Method
model	I-Method
that	O
does	O
not	O
satisfy	O
Assumption	O
1	O
(	O
b	O
)	O
may	O
still	O
yield	O
useful	O
(	O
but	O
incommensurable	O
)	O
pseudo	O
-	O
counts	O
.	O
	
theorem	O
:	O
.	O
	
Let	O
>	O
⁢ϕ	O
(	O
x	O
)	O
0	O
with	O
<	O
∑∈xX⁢ϕ	O
(	O
x	O
)	O
∞	O
and	O
consider	O
the	O
count	B-Method
-	I-Method
based	I-Method
estimator	I-Method
	
If	O
^Nn	B-Method
is	O
the	O
pseudo	O
-	O
count	O
corresponding	O
to	O
ρn	O
then	O
→⁢	O
/	O
⁢^Nn	O
(	O
x	O
)	O
Nn	O
(	O
x	O
)	O
1	O
for	O
all	O
x	O
with	O
>	O
⁢μ	O
(	O
x	O
)	O
0	O
.	O
	
section	O
:	O
Empirical	O
Evaluation	O
	
In	O
this	O
section	O
we	O
demonstrate	O
the	O
use	O
of	O
pseudo	O
-	O
counts	O
to	O
guide	O
exploration	B-Task
.	O
	
We	O
return	O
to	O
the	O
Arcade	B-Method
Learning	I-Method
Environment	I-Method
,	O
now	O
using	O
the	O
CTS	B-Method
model	I-Method
to	O
generate	O
an	O
exploration	O
bonus	O
.	O
	
subsection	O
:	O
Exploration	B-Task
in	O
Hard	B-Task
Atari	I-Task
2600	I-Task
Games	I-Task
	
From	O
60	O
games	O
available	O
through	O
the	O
Arcade	B-Method
Learning	I-Method
Environment	I-Method
we	O
selected	O
five	O
“	O
hard	O
”	O
games	O
,	O
in	O
the	O
sense	O
that	O
an	O
-	B-Method
greedy	I-Method
policy	I-Method
is	O
inefficient	O
at	O
exploring	O
them	O
.	O
	
We	O
used	O
a	O
bonus	O
of	O
the	O
form	O
where	O
was	O
selected	O
from	O
a	O
coarse	O
parameter	O
sweep	O
.	O
	
We	O
also	O
compared	O
our	O
method	O
to	O
the	O
optimistic	B-Method
initialization	I-Method
trick	I-Method
proposed	O
by	O
machado14domainindependent	B-Method
.	O
	
We	O
trained	O
our	O
agents	O
’	O
Q	B-Method
-	I-Method
functions	I-Method
with	O
Double	B-Method
DQN	I-Method
vanhasselt16deep	I-Method
,	O
with	O
one	O
important	O
modification	O
:	O
we	O
mixed	O
the	O
Double	B-Method
Q	I-Method
-	I-Method
Learning	I-Method
target	I-Method
with	O
the	O
Monte	B-Method
Carlo	I-Method
return	I-Method
.	O
	
This	O
modification	O
led	O
to	O
improved	O
results	O
both	O
with	O
and	O
without	O
exploration	O
bonuses	O
(	O
details	O
in	O
the	O
appendix	O
)	O
.	O
	
Figure	O
[	O
reference	O
]	O
depicts	O
the	O
result	O
of	O
our	O
experiment	O
,	O
averaged	O
across	O
5	O
trials	O
.	O
	
Although	O
optimistic	B-Method
initialization	I-Method
helps	O
in	O
Freeway	B-Material
,	O
it	O
otherwise	O
yields	O
performance	O
similar	O
to	O
DQN	B-Method
.	O
	
By	O
contrast	O
,	O
the	O
count	B-Method
-	I-Method
based	I-Method
exploration	I-Method
bonus	I-Method
enables	O
us	O
to	O
make	O
quick	O
progress	O
on	O
a	O
number	O
of	O
games	O
,	O
most	O
dramatically	O
in	O
Montezuma	B-Material
’s	I-Material
Revenge	I-Material
and	O
Venture	B-Material
.	O
	
Montezuma	B-Material
’s	I-Material
Revenge	I-Material
is	O
perhaps	O
the	O
hardest	O
Atari	B-Material
2600	I-Material
game	I-Material
available	O
through	O
the	O
ALE	B-Method
.	O
	
The	O
game	O
is	O
infamous	O
for	O
its	O
hostile	O
,	O
unforgiving	O
environment	O
:	O
the	O
agent	O
must	O
navigate	O
a	O
number	O
of	O
different	O
rooms	O
,	O
each	O
filled	O
with	O
traps	O
.	O
	
Due	O
to	O
its	O
sparse	O
reward	O
function	O
,	O
most	O
published	O
agents	O
achieve	O
an	O
average	O
score	B-Metric
close	O
to	O
zero	O
and	O
completely	O
fail	O
to	O
explore	O
most	O
of	O
the	O
24	O
rooms	O
that	O
constitute	O
the	O
first	O
level	O
(	O
Figure	O
[	O
reference	O
]	O
,	O
top	O
)	O
.	O
	
By	O
contrast	O
,	O
within	O
50	O
million	O
frames	O
our	O
agent	O
learns	O
a	O
policy	O
which	O
consistently	O
navigates	O
through	O
15	O
rooms	O
(	O
Figure	O
[	O
reference	O
]	O
,	O
bottom	O
)	O
.	O
	
Our	O
agent	O
also	O
achieves	O
a	O
score	B-Metric
higher	O
than	O
anything	O
previously	O
reported	O
,	O
with	O
one	O
run	O
consistently	O
achieving	O
6600	O
points	O
by	O
100	O
million	O
frames	O
(	O
half	O
the	O
training	O
samples	O
used	O
by	O
mnih15human	O
)	O
.	O
	
We	O
believe	O
the	O
success	O
of	O
our	O
method	O
in	O
this	O
game	O
is	O
a	O
strong	O
indicator	O
of	O
the	O
usefulness	O
of	O
pseudo	O
-	O
counts	O
for	O
exploration	B-Task
.	O
	
subsection	O
:	O
Exploration	O
for	O
Actor	B-Method
-	I-Method
Critic	I-Method
Methods	I-Method
	
We	O
next	O
used	O
our	O
exploration	B-Method
bonuses	I-Method
in	O
conjunction	O
with	O
the	O
A3C	B-Method
(	O
Asynchronous	B-Method
Advantage	I-Method
Actor	I-Method
-	I-Method
Critic	I-Method
)	O
algorithm	O
of	O
mnih16asynchronous	O
.	O
	
One	O
appeal	O
of	O
actor	B-Method
-	I-Method
critic	I-Method
methods	I-Method
is	O
their	O
explicit	O
separation	O
of	O
policy	O
and	O
Q	O
-	O
function	O
parameters	O
,	O
which	O
leads	O
to	O
a	O
richer	O
behaviour	O
space	O
.	O
	
This	O
very	O
separation	O
,	O
however	O
,	O
often	O
leads	O
to	O
deficient	O
exploration	B-Task
:	O
to	O
produce	O
any	O
sensible	O
results	O
,	O
the	O
A3C	B-Method
policy	O
must	O
be	O
regularized	O
with	O
an	O
entropy	O
cost	O
.	O
	
We	O
trained	O
A3C	B-Method
on	O
60	O
Atari	B-Task
2600	I-Task
games	I-Task
,	O
with	O
and	O
without	O
the	O
exploration	O
bonus	O
(	O
[	O
reference	O
]	O
)	O
.	O
	
We	O
refer	O
to	O
our	O
augmented	B-Method
algorithm	I-Method
as	O
A3C	B-Method
+	O
.	O
	
Full	O
details	O
and	O
additional	O
results	O
may	O
be	O
found	O
in	O
the	O
appendix	O
.	O
	
We	O
found	O
that	O
A3C	B-Method
fails	O
to	O
learn	O
in	O
15	O
games	O
,	O
in	O
the	O
sense	O
that	O
the	O
agent	O
does	O
not	O
achieve	O
a	O
score	B-Metric
50	O
%	O
better	O
than	O
random	B-Method
.	O
	
In	O
comparison	O
,	O
there	O
are	O
only	O
10	O
games	O
for	O
which	O
A3C	B-Method
+	O
fails	O
to	O
improve	O
on	O
the	O
random	B-Method
agent	I-Method
;	O
of	O
these	O
,	O
8	O
are	O
games	O
where	O
DQN	B-Method
fails	O
in	O
the	O
same	O
sense	O
.	O
	
We	O
normalized	O
the	O
two	O
algorithms	O
’	O
scores	O
so	O
that	O
0	O
and	O
1	O
are	O
respectively	O
the	O
minimum	O
and	O
maximum	O
of	O
the	O
random	O
agent	O
’s	O
and	O
A3C	B-Method
’s	O
end	O
-	O
of	O
-	O
training	O
score	B-Metric
on	O
a	O
particular	O
game	O
.	O
	
Figure	O
[	O
reference	O
]	O
depicts	O
the	O
in	O
-	O
training	O
median	O
score	B-Metric
for	O
A3C	B-Method
	
and	O
A3C	B-Method
+	O
,	O
along	O
with	O
1st	O
and	O
3rd	O
quartile	O
intervals	O
.	O
	
Not	O
only	O
does	O
A3C	B-Method
+	O
achieve	O
slightly	O
superior	O
median	B-Metric
performance	I-Metric
,	O
but	O
it	O
also	O
significantly	O
outperforms	O
A3C	B-Method
on	O
at	O
least	O
a	O
quarter	O
of	O
the	O
games	O
.	O
	
This	O
is	O
particularly	O
important	O
given	O
the	O
large	O
proportion	O
of	O
Atari	B-Task
2600	I-Task
games	I-Task
for	O
which	O
an	O
-	B-Method
greedy	I-Method
policy	I-Method
is	O
sufficient	O
for	O
exploration	B-Task
.	O
	
section	O
:	O
Related	O
Work	O
	
Information	O
-	O
theoretic	O
quantities	O
have	O
been	O
repeatedly	O
used	O
to	O
describe	O
intrinsically	B-Task
motivated	I-Task
behaviour	I-Task
.	O
	
Closely	O
related	O
to	O
prediction	B-Metric
gain	I-Metric
is	O
schmidhuber91possibility	O
’s	O
notion	O
of	O
compression	O
progress	O
,	O
which	O
equates	O
novelty	O
with	O
an	O
agent	O
’s	O
improvement	O
in	O
its	O
ability	O
to	O
compress	O
its	O
past	O
.	O
	
More	O
recently	O
,	O
lopes12exploration	O
showed	O
the	O
relationship	O
between	O
time	O
-	O
averaged	O
prediction	O
gain	O
and	O
visit	O
counts	O
in	O
a	O
tabular	O
setting	O
;	O
their	O
result	O
is	O
a	O
special	O
case	O
of	O
Theorem	O
[	O
reference	O
]	O
.	O
	
orseau13universal	O
demonstrated	O
that	O
maximizing	O
the	O
sum	O
of	O
future	O
information	O
gains	O
does	O
lead	O
to	O
optimal	O
behaviour	O
,	O
even	O
though	O
maximizing	O
immediate	O
information	O
gain	O
does	O
not	O
(	O
Section	O
[	O
reference	O
]	O
)	O
.	O
	
Finally	O
,	O
there	O
may	O
be	O
a	O
connection	O
between	O
sequential	B-Method
normalized	I-Method
maximum	I-Method
likelihood	I-Method
estimators	I-Method
and	O
our	O
pseudo	B-Method
-	I-Method
count	I-Method
derivation	I-Method
[	O
see	O
e.g.	O
][]	O
ollivier15laplace	O
.	O
	
Intrinsic	O
motivation	O
has	O
also	O
been	O
studied	O
in	O
reinforcement	B-Task
learning	I-Task
proper	I-Task
,	O
in	O
particular	O
in	O
the	O
context	O
of	O
discovering	B-Task
skills	I-Task
singh04intrinsically	I-Task
,	O
barto13intrinsic	O
.	O
	
Recently	O
,	O
stadie15incentivizing	B-Method
used	O
a	O
squared	B-Method
prediction	I-Method
error	I-Method
bonus	I-Method
for	O
exploring	B-Task
in	O
Atari	B-Task
2600	I-Task
games	I-Task
.	O
	
Closest	O
to	O
our	O
work	O
is	O
houthooft16curiosity	B-Method
’s	I-Method
variational	I-Method
approach	I-Method
to	O
intrinsic	B-Task
motivation	I-Task
,	O
which	O
is	O
equivalent	O
to	O
a	O
second	B-Method
order	I-Method
Taylor	I-Method
approximation	I-Method
to	O
prediction	O
gain	O
.	O
	
mohamed15variational	O
	
also	O
considered	O
a	O
variational	B-Method
approach	I-Method
to	O
the	O
different	O
problem	O
of	O
maximizing	O
an	O
agent	O
’s	O
ability	O
to	O
influence	O
its	O
environment	O
.	O
	
Aside	O
for	O
orseau13universal	O
’s	O
above	O
-	O
cited	O
work	O
,	O
it	O
is	O
only	O
recently	O
that	O
theoretical	O
guarantees	O
for	O
exploration	B-Task
have	O
emerged	O
for	O
non	B-Task
-	I-Task
tabular	I-Task
,	I-Task
stateful	I-Task
settings	I-Task
.	O
	
We	O
note	O
pazis16efficient	O
	
’s	O
PAC	B-Method
-	I-Method
MDP	I-Method
result	I-Method
for	O
metric	B-Task
spaces	I-Task
and	O
leike16thompson	O
’s	O
asymptotic	B-Task
analysis	I-Task
of	O
Thompson	B-Task
sampling	I-Task
in	O
general	O
environments	O
.	O
	
section	O
:	O
Future	O
Directions	O
	
The	O
last	O
few	O
years	O
have	O
seen	O
tremendous	O
advances	O
in	O
learning	B-Task
representations	I-Task
for	O
reinforcement	B-Task
learning	I-Task
.	O
	
Surprisingly	O
,	O
these	O
advances	O
have	O
yet	O
to	O
carry	O
over	O
to	O
the	O
problem	O
of	O
exploration	B-Task
.	O
	
In	O
this	O
paper	O
,	O
we	O
reconciled	O
counts	O
,	O
the	O
fundamental	O
unit	O
of	O
uncertainty	O
,	O
with	O
prediction	B-Method
-	I-Method
based	I-Method
heuristics	I-Method
and	O
intrinsic	O
motivation	O
.	O
	
Combining	O
our	O
work	O
with	O
more	O
ideas	O
from	O
deep	B-Method
learning	I-Method
and	O
better	O
density	B-Method
models	I-Method
seems	O
a	O
plausible	O
avenue	O
for	O
quick	O
progress	O
in	O
practical	O
,	O
efficient	O
exploration	B-Task
.	O
	
We	O
now	O
conclude	O
by	O
outlining	O
a	O
few	O
research	O
directions	O
we	O
believe	O
are	O
promising	O
.	O
	
Induced	B-Metric
metric	I-Metric
.	O
	
We	O
did	O
not	O
address	O
the	O
question	O
of	O
where	O
the	O
generalization	B-Task
comes	O
from	O
.	O
	
Clearly	O
,	O
the	O
choice	O
of	O
density	B-Method
model	I-Method
induces	O
a	O
particular	O
metric	O
over	O
the	O
state	O
space	O
.	O
	
A	O
better	O
understanding	O
of	O
this	O
metric	O
should	O
allow	O
us	O
to	O
tailor	O
the	O
density	B-Method
model	I-Method
to	O
the	O
problem	O
of	O
exploration	B-Task
.	O
	
Compatible	O
value	O
function	O
.	O
	
There	O
may	O
be	O
a	O
mismatch	O
in	O
the	O
learning	B-Metric
rates	I-Metric
of	O
the	O
density	B-Method
model	I-Method
and	O
the	O
value	B-Method
function	I-Method
:	O
DQN	B-Method
learns	O
much	O
more	O
slowly	O
than	O
our	O
CTS	B-Method
model	I-Method
.	O
	
As	O
such	O
,	O
it	O
should	O
be	O
beneficial	O
to	O
design	O
value	B-Method
functions	I-Method
compatible	O
with	O
density	B-Method
models	I-Method
(	O
or	O
vice	O
-	O
versa	O
)	O
.	O
	
The	O
continuous	B-Task
case	I-Task
.	O
	
Although	O
we	O
focused	O
here	O
on	O
countable	O
state	O
spaces	O
,	O
we	O
can	O
as	O
easily	O
define	O
a	O
pseudo	O
-	O
count	O
in	O
terms	O
of	O
probability	B-Method
density	I-Method
functions	I-Method
.	O
	
At	O
present	O
it	O
is	O
unclear	O
whether	O
this	O
provides	O
us	O
with	O
the	O
right	O
notion	O
of	O
counts	O
for	O
continuous	O
spaces	O
.	O
	
subsubsection	O
:	O
Acknowledgments	O
	
The	O
authors	O
would	O
like	O
to	O
thank	O
Laurent	O
Orseau	O
,	O
Alex	O
Graves	O
,	O
Joel	O
Veness	O
,	O
Charles	O
Blundell	O
,	O
Shakir	O
Mohamed	O
,	O
Ivo	O
Danihelka	O
,	O
Ian	O
Osband	O
,	O
Matt	O
Hoffman	O
,	O
Greg	O
Wayne	O
,	O
Will	O
Dabney	O
,	O
and	O
Aäron	O
van	O
	
den	O
Oord	O
for	O
their	O
excellent	O
feedback	O
early	O
and	O
late	O
in	O
the	O
writing	O
,	O
and	O
Pierre	O
-	O
Yves	O
Oudeyer	O
and	O
Yann	O
Ollivier	O
for	O
pointing	O
out	O
additional	O
connections	O
to	O
the	O
literature	O
.	O
	
bibliography	O
:	O
References	O
	
appendix	O
:	O
The	O
Connection	O
to	O
Intrinsic	O
Motivation	O
	
The	O
following	O
provides	O
an	O
identity	O
connecting	O
information	O
gain	O
and	O
prediction	O
gain	O
.	O
	
theorem	O
:	O
.	O
	
Consider	O
a	O
mixture	B-Method
model	I-Method
ξ	I-Method
over	O
M	O
with	O
prediction	B-Method
gain	I-Method
PGn	I-Method
and	O
information	B-Method
gain	I-Method
IGn	I-Method
,	O
a	O
fixed	O
∈xX	O
,	O
and	O
let	O
:	O
=	O
⁢w′n	O
(	O
x	O
)	O
⁢wn	O
(	O
ρ	O
,	O
x	O
)	O
be	O
the	O
posterior	O
of	O
ξ	O
over	O
M	O
after	O
observing	O
x.	O
Let	O
:	O
=	O
	
⁢w′′n	O
(	O
x	O
)	O
⁢w′n	O
(	O
ρ	O
,	O
x	O
)	O
be	O
the	O
same	O
posterior	O
after	O
observing	O
x	O
a	O
second	O
time	O
,	O
and	O
let	O
⁢PGρn	O
(	O
x	O
)	O
denote	O
the	O
prediction	O
gain	O
of	O
∈ρM.	O
	
Then	O
In	O
particular	O
,	O
if	O
M	B-Method
is	O
a	O
class	O
of	O
non	B-Method
-	I-Method
adaptive	I-Method
models	I-Method
in	O
the	O
sense	O
that	O
=	O
⁢ρn	O
(	O
x	O
)	O
⁢ρ	O
(	O
x	O
)	O
for	O
all	O
x:1n	O
,	O
then	O
A	O
model	O
which	O
is	O
non	O
-	O
adaptive	O
is	O
also	O
learning	O
-	O
positive	O
in	O
the	O
sense	O
of	O
Definition	O
[	O
reference	O
]	O
.	O
	
Many	O
common	O
mixture	B-Method
models	I-Method
,	O
for	O
example	O
Dirichlet	B-Method
-	I-Method
multinomial	I-Method
estimators	I-Method
,	O
are	O
mixtures	B-Method
over	I-Method
non	I-Method
-	I-Method
adaptive	I-Method
models	I-Method
.	O
	
proof	O
:	O
Proof	O
.	O
	
We	O
rewrite	O
the	O
posterior	B-Method
update	I-Method
rule	I-Method
(	O
[	O
reference	O
]	O
)	O
to	O
show	O
that	O
for	O
any	O
and	O
any	O
,	O
Write	O
.	O
	
Now	O
The	O
second	O
statement	O
follows	O
immediately	O
.	O
	
theorem	O
:	O
.	O
	
The	O
functions	O
:	O
=	O
⁢f	O
(	O
x	O
)-	O
ex1x	O
and	O
:	O
=	O
	
⁢g	O
(	O
x	O
)-	O
ex1x2	O
are	O
nonnegative	O
on	O
∈x	O
[	O
0	O
,	O
∞	O
)	O
.	O
	
proof	O
:	O
Proof	O
.	O
	
The	O
statement	O
regarding	O
follows	O
directly	O
from	O
the	O
Taylor	B-Method
expansion	I-Method
for	O
.	O
	
Now	O
,	O
the	O
first	O
derivative	O
of	O
is	O
.	O
	
It	O
is	O
clearly	O
positive	O
for	O
.	O
	
For	O
,	O
Since	O
,	O
the	O
second	O
result	O
follows	O
.	O
	
∎	O
	
proof	O
:	O
Proof	O
(	O
Theorem	O
[	O
reference	O
]	O
)	O
.	O
	
The	O
inequality	O
follows	O
directly	O
from	O
Lemma	O
[	O
reference	O
]	O
,	O
the	O
nonnegativity	O
of	O
the	O
Kullback	O
-	O
Leibler	O
divergence	O
,	O
and	O
the	O
fact	O
that	O
all	O
models	O
in	O
are	O
learning	O
-	O
positive	O
.	O
	
For	O
the	O
inequality	O
,	O
we	O
write	O
where	O
(	O
a	O
)	O
follows	O
by	O
definition	O
of	O
prediction	O
gain	O
,	O
(	O
b	O
)	O
from	O
,	O
and	O
(	O
c	O
)	O
from	O
Lemma	O
[	O
reference	O
]	O
.	O
	
Using	O
the	O
second	O
part	O
of	O
Lemma	O
[	O
reference	O
]	O
in	O
(	O
c	O
)	O
yields	O
the	O
inequality	O
.	O
	
∎	O
	
appendix	O
:	O
Asymptotic	B-Method
Analysis	I-Method
	
We	O
begin	O
with	O
a	O
simple	O
lemma	O
which	O
will	O
prove	O
useful	O
throughout	O
.	O
	
theorem	O
:	O
.	O
	
The	O
rate	O
of	O
change	O
of	O
the	O
empirical	O
distribution	O
,	O
-	O
⁢μ′n	O
(	O
x	O
)	O
⁢μn	O
(	O
x	O
)	O
,	O
is	O
such	O
that	O
	
proof	O
:	O
Proof	O
.	O
	
We	O
expand	O
the	O
definition	O
of	O
and	O
:	O
	
∎	O
Using	O
this	O
lemma	O
,	O
we	O
derive	O
an	O
asymptotic	O
relationship	O
between	O
and	O
.	O
	
proof	O
:	O
Proof	O
(	O
Theorem	O
[	O
reference	O
]	O
)	O
.	O
	
We	O
expand	O
the	O
definition	O
of	O
and	O
:	O
with	O
the	O
last	O
line	O
following	O
from	O
Lemma	O
[	O
reference	O
]	O
.	O
	
Under	O
Assumption	O
[	O
reference	O
]	O
,	O
all	O
terms	O
of	O
the	O
right	O
-	O
hand	O
side	O
converge	O
as	O
.	O
	
Taking	O
the	O
limit	O
on	O
both	O
sides	O
,	O
where	O
(	O
a	O
)	O
is	O
justified	O
by	O
the	O
existence	O
of	O
the	O
relevant	O
limits	O
and	O
,	O
and	O
(	O
b	O
)	O
follows	O
from	O
writing	O
as	O
,	O
where	O
all	O
limits	O
involved	O
exist	O
.	O
	
∎	O
	
subsection	O
:	O
Directed	B-Method
Graphical	I-Method
Models	I-Method
	
We	O
say	O
that	O
is	O
a	O
factored	O
state	O
space	O
if	O
it	O
is	O
the	O
Cartesian	O
product	O
of	O
subspaces	O
,	O
i.e.	O
.	O
	
This	O
factored	B-Method
structure	I-Method
allows	O
us	O
to	O
construct	O
approximate	B-Method
density	I-Method
models	I-Method
over	O
,	O
for	O
example	O
by	O
modelling	O
the	O
joint	O
density	O
as	O
a	O
product	B-Method
of	I-Method
marginals	I-Method
.	O
	
We	O
write	O
the	O
factor	O
of	O
a	O
state	O
as	O
,	O
and	O
write	O
the	O
sequence	O
of	O
the	O
factor	O
across	O
as	O
.	O
	
We	O
will	O
show	O
that	O
directed	B-Method
graphical	I-Method
models	I-Method
	
wainwright08graphical	O
satisfy	O
Assumption	O
[	O
reference	O
]	O
.	O
	
A	O
directed	B-Method
graphical	I-Method
model	I-Method
describes	O
a	O
probability	B-Method
distribution	I-Method
over	O
a	O
factored	O
state	O
space	O
.	O
	
To	O
the	O
factor	O
is	O
associated	O
a	O
parent	O
set	O
.	O
	
Let	O
denote	O
the	O
value	O
of	O
the	O
factors	O
in	O
the	O
parent	O
set	O
.	O
	
The	O
factor	B-Method
model	I-Method
is	O
,	O
with	O
the	O
understanding	O
that	O
is	O
allowed	O
to	O
make	O
a	O
different	O
prediction	O
for	O
each	O
value	O
of	O
.	O
	
The	O
state	O
is	O
assigned	O
the	O
joint	O
probability	O
Common	O
choices	O
for	O
include	O
the	O
conditional	B-Method
empirical	I-Method
distribution	I-Method
and	O
the	O
Dirichlet	B-Method
estimator	I-Method
.	O
	
theorem	O
:	O
.	O
	
Suppose	O
that	O
each	O
factor	B-Method
model	I-Method
ρin	I-Method
converges	O
to	O
the	O
conditional	O
probability	O
distribution	O
μ	O
(	O
xi|x⁢π	O
(	O
i	O
)	O
)	O
and	O
that	O
for	O
each	O
xi	O
with	O
μ	O
(	O
xi|x⁢π	O
(	O
i	O
)	O
)	O
,	O
Then	O
for	O
all	O
x	O
with	O
>	O
⁢μ	O
(	O
x	O
)	O
0	O
,	O
the	O
density	B-Method
model	I-Method
ρgm	I-Method
satisfies	O
Assumption	O
with	O
The	O
CTS	B-Method
density	I-Method
model	I-Method
used	O
in	O
our	O
experiments	O
is	O
in	O
fact	O
a	O
particular	O
kind	O
of	O
induced	B-Method
graphical	I-Method
model	I-Method
.	O
	
The	O
result	O
above	O
thus	O
describes	O
how	O
the	O
pseudo	O
-	O
counts	O
computed	O
in	O
Section	O
[	O
reference	O
]	O
are	O
asymptotically	O
related	O
to	O
the	O
empirical	O
counts	O
.	O
	
proof	O
:	O
Proof	O
.	O
	
By	O
hypothesis	O
,	O
.	O
	
Combining	O
this	O
with	O
,	O
Similarly	O
,	O
where	O
in	O
(	O
a	O
)	O
we	O
used	O
the	O
identity	O
derived	O
in	O
the	O
proof	O
of	O
Theorem	O
[	O
reference	O
]	O
.	O
	
Now	O
Let	O
	
and	O
.	O
	
The	O
difference	O
of	O
products	O
above	O
is	O
and	O
By	O
the	O
hypothesis	O
on	O
the	O
rate	O
of	O
change	O
of	O
and	O
the	O
identity	O
,	O
we	O
have	O
	
Since	O
the	O
limits	O
of	O
and	O
are	O
both	O
,	O
we	O
deduce	O
that	O
	
Now	O
,	O
if	O
then	O
also	O
for	O
each	O
factor	O
.	O
	
Hence	O
.	O
	
∎	O
	
subsection	O
:	O
Tabular	B-Method
Density	I-Method
Models	I-Method
(	O
Corollary	O
[	O
reference	O
]	O
)	O
	
We	O
shall	O
prove	O
the	O
following	O
,	O
which	O
includes	O
Corollary	O
[	O
reference	O
]	O
as	O
a	O
special	O
case	O
.	O
	
theorem	O
:	O
.	O
	
Consider	O
:	O
ϕ→×XX*R	O
+	O
.	O
	
Suppose	O
that	O
for	O
all	O
(	O
:	O
xn∈nN	O
)	O
and	O
every	O
∈xX	O
,	O
and	O
.	O
	
Let	O
⁢ρn	O
(	O
x	O
)	O
be	O
the	O
count	B-Method
-	I-Method
based	I-Method
estimator	I-Method
	
If	O
^Nn	B-Method
is	O
the	O
pseudo	O
-	O
count	O
corresponding	O
to	O
ρn	O
then	O
→⁢	O
/	O
⁢^Nn	O
(	O
x	O
)	O
Nn	O
(	O
x	O
)	O
1	O
for	O
all	O
x	O
with	O
>	O
⁢μ	O
(	O
x	O
)	O
0	O
.	O
	
Condition	O
2	O
is	O
satisfied	O
if	O
with	O
monotonically	O
increasing	O
in	O
(	O
but	O
not	O
too	O
quickly	O
!	O
)	O
and	O
converging	O
to	O
some	O
distribution	O
for	O
all	O
sequences	O
.	O
	
This	O
is	O
the	O
case	O
for	O
most	O
tabular	B-Method
density	I-Method
models	I-Method
.	O
	
proof	O
:	O
Proof	O
.	O
	
We	O
will	O
show	O
that	O
the	O
condition	O
on	O
the	O
rate	O
of	O
change	O
required	O
by	O
Proposition	O
[	O
reference	O
]	O
is	O
satisfied	O
under	O
the	O
stated	O
conditions	O
.	O
	
Let	O
,	O
,	O
and	O
.	O
	
By	O
hypothesis	O
,	O
Note	O
that	O
we	O
do	O
not	O
require	O
.	O
	
Now	O
Using	O
Lemma	O
[	O
reference	O
]	O
we	O
deduce	O
that	O
Since	O
and	O
similarly	O
for	O
,	O
then	O
pointwise	O
implies	O
that	O
also	O
.	O
	
For	O
any	O
,	O
where	O
a	O
)	O
follows	O
from	O
and	O
b	O
)	O
is	O
justified	O
by	O
and	O
the	O
hypothesis	O
that	O
.	O
	
Therefore	O
.	O
	
Hence	O
Since	O
,	O
we	O
further	O
deduce	O
from	O
Theorem	O
[	O
reference	O
]	O
that	O
The	O
condition	O
,	O
which	O
was	O
also	O
needed	O
in	O
Proposition	O
[	O
reference	O
]	O
,	O
is	O
necessary	O
for	O
the	O
ratio	O
to	O
converge	O
to	O
1	O
:	O
for	O
example	O
,	O
if	O
grows	O
as	O
but	O
grows	O
as	O
(	O
with	O
finite	O
)	O
then	O
will	O
grow	O
as	O
the	O
larger	O
.	O
	
appendix	O
:	O
Experimental	O
Methods	O
	
subsection	O
:	O
CTS	B-Method
Density	I-Method
Model	I-Method
	
Our	O
state	O
space	O
is	O
the	O
set	O
of	O
all	O
preprocessed	B-Material
Atari	I-Material
2600	I-Material
frames	I-Material
.	O
	
Each	O
raw	O
frame	O
is	O
composed	O
of	O
7	O
-	O
bit	O
NTSC	O
pixels	O
bellemare13arcade	O
.	O
	
We	O
preprocess	O
these	O
frames	O
by	O
first	O
converting	O
them	O
to	O
grayscale	O
(	O
luminance	O
)	O
,	O
then	O
downsampling	O
to	O
by	O
averaging	O
over	O
pixel	O
values	O
(	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
Aside	O
from	O
this	O
preprocessing	O
,	O
our	O
model	O
is	O
very	O
similar	O
to	O
the	O
model	O
used	O
by	O
bellemare14skip	O
and	O
veness15compress	O
.	O
	
The	O
CTS	B-Method
density	I-Method
model	I-Method
treats	O
as	O
a	O
factored	O
state	O
,	O
where	O
each	O
pixel	O
corresponds	O
to	O
a	O
factor	O
.	O
	
The	O
parents	O
of	O
this	O
factor	O
are	O
its	O
upper	O
-	O
left	O
neighbours	O
,	O
i.e.	O
pixels	O
,	O
,	O
and	O
(	O
in	O
this	O
order	O
)	O
.	O
	
The	O
probability	O
of	O
is	O
then	O
the	O
product	O
of	O
the	O
probability	O
assigned	O
to	O
its	O
factors	O
.	O
	
Each	O
factor	O
is	O
modelled	O
using	O
a	O
location	B-Method
-	I-Method
dependent	I-Method
CTS	I-Method
model	I-Method
,	O
which	O
predicts	O
the	O
pixel	O
’s	O
colour	O
value	O
conditional	O
on	O
some	O
,	O
all	O
,	O
or	O
possibly	O
none	O
,	O
of	O
the	O
pixel	O
’s	O
parents	O
(	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
subsection	O
:	O
A	O
Taxonomy	O
of	O
Exploration	B-Task
	
We	O
provide	O
in	O
Table	O
[	O
reference	O
]	O
a	O
rough	O
taxonomy	O
of	O
the	O
Atari	B-Task
2600	I-Task
games	I-Task
available	O
through	O
the	O
ALE	B-Method
in	O
terms	O
of	O
the	O
difficulty	O
of	O
exploration	B-Task
.	O
	
We	O
first	O
divided	O
the	O
games	O
into	O
two	O
groups	O
:	O
those	O
for	O
which	O
local	O
exploration	O
(	O
e.g.	O
-	O
greedy	O
)	O
is	O
sufficient	O
to	O
achieve	O
a	O
high	O
scoring	O
policy	O
(	O
easy	O
)	O
,	O
and	O
those	O
for	O
which	O
it	O
is	O
not	O
(	O
hard	O
)	O
.	O
	
For	O
example	O
,	O
Space	O
Invaders	O
versus	O
Pitfall	O
!	O
.	O
	
We	O
further	O
divided	O
the	O
easy	O
group	O
based	O
on	O
whether	O
an	O
-	B-Method
greedy	I-Method
scheme	I-Method
finds	O
a	O
score	B-Metric
exploit	O
,	O
that	O
is	O
maximizes	O
the	O
score	B-Metric
without	O
achieving	O
the	O
game	O
’s	O
stated	O
objective	O
.	O
	
For	O
example	O
,	O
Kung	O
-	O
Fu	O
Master	O
versus	O
Boxing	O
.	O
	
While	O
this	O
distinction	O
is	O
not	O
directly	O
used	O
here	O
,	O
score	B-Metric
exploits	O
lead	O
to	O
behaviours	O
which	O
are	O
optimal	O
from	O
an	O
ALE	B-Method
perspective	O
but	O
uninteresting	O
to	O
humans	O
.	O
	
We	O
divide	O
the	O
games	O
in	O
the	O
hard	O
category	O
into	O
dense	B-Method
reward	I-Method
games	I-Method
(	O
Ms.	B-Method
Pac	I-Method
-	I-Method
Man	I-Method
)	O
and	O
sparse	B-Method
reward	I-Method
games	I-Method
(	O
Montezuma	B-Material
’s	I-Material
Revenge	I-Material
)	O
.	O
	
subsection	O
:	O
Exploration	B-Task
in	O
Montezuma	B-Material
’s	I-Material
Revenge	I-Material
	
Montezuma	B-Material
’s	I-Material
Revenge	I-Material
is	O
divided	O
into	O
three	O
levels	O
,	O
each	O
composed	O
of	O
24	O
rooms	O
arranged	O
in	O
a	O
pyramidal	O
shape	O
(	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
As	O
discussed	O
above	O
,	O
each	O
room	O
poses	O
a	O
number	O
of	O
challenges	O
:	O
to	O
escape	O
the	O
very	O
first	O
room	O
,	O
the	O
agent	O
must	O
climb	O
ladders	O
,	O
dodge	O
a	O
creature	O
,	O
pick	O
up	O
a	O
key	O
,	O
then	O
backtrack	O
to	O
open	O
one	O
of	O
two	O
doors	O
.	O
	
The	O
number	O
of	O
rooms	O
reached	O
by	O
an	O
agent	O
is	O
therefore	O
a	O
good	O
measure	O
of	O
its	O
ability	O
.	O
	
By	O
accessing	O
the	O
game	O
RAM	O
,	O
we	O
recorded	O
the	O
location	O
of	O
the	O
agent	O
at	O
each	O
step	O
during	O
the	O
course	O
of	O
training	O
.	O
	
We	O
computed	O
the	O
visit	O
count	O
to	O
each	O
room	O
,	O
averaged	O
over	O
epochs	O
each	O
lasting	O
one	O
million	O
frames	O
.	O
	
From	O
this	O
information	O
we	O
constructed	O
a	O
map	O
of	O
the	O
agent	O
’s	O
“	O
known	O
world	O
”	O
,	O
that	O
is	O
,	O
all	O
rooms	O
visited	O
at	O
least	O
once	O
.	O
	
The	O
agent	O
’s	O
current	O
room	O
number	O
ranges	O
from	O
0	O
to	O
23	O
(	O
Figure	O
[	O
reference	O
]	O
)	O
and	O
is	O
stored	O
at	O
RAM	O
location	O
0x83	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
the	O
set	O
of	O
rooms	O
explored	O
by	O
our	O
DQN	B-Method
agents	I-Method
at	O
different	O
points	O
during	O
training	O
.	O
	
Figure	O
[	O
reference	O
]	O
paints	O
a	O
clear	O
picture	O
:	O
after	O
50	O
million	O
frames	O
,	O
the	O
agent	O
using	O
exploration	O
bonuses	O
has	O
seen	O
a	O
total	O
of	O
15	O
rooms	O
,	O
while	O
the	O
no	O
-	O
bonus	O
agent	O
has	O
seen	O
two	O
.	O
	
At	O
that	O
point	O
in	O
time	O
,	O
our	O
agent	O
achieves	O
an	O
average	O
score	B-Metric
of	O
2461	O
;	O
by	O
100	O
million	O
frames	O
,	O
this	O
figure	O
stands	O
at	O
3439	O
,	O
higher	O
than	O
anything	O
previously	O
reported	O
.	O
	
We	O
believe	O
the	O
success	O
of	O
our	O
method	O
in	O
this	O
game	O
is	O
a	O
strong	O
indicator	O
of	O
the	O
usefulness	O
of	O
pseudo	O
-	O
counts	O
for	O
exploration	B-Task
.	O
	
We	O
remark	O
that	O
without	O
mixing	O
in	O
the	O
Monte	O
-	O
Carlo	O
return	O
,	O
our	O
bonus	B-Method
-	I-Method
based	I-Method
agent	I-Method
still	O
explores	O
significantly	O
more	O
than	O
the	O
no	B-Method
-	I-Method
bonus	I-Method
agent	I-Method
.	O
	
However	O
,	O
the	O
deep	B-Method
network	I-Method
seems	O
unable	O
to	O
maintain	O
a	O
sufficiently	O
good	O
approximation	O
to	O
the	O
value	O
function	O
,	O
and	O
performance	O
quickly	O
deteriorates	O
.	O
	
Comparable	O
results	O
using	O
the	O
A3C	B-Method
method	O
provide	O
another	O
example	O
of	O
the	O
practical	O
importance	O
of	O
eligibility	B-Method
traces	I-Method
and	O
return	B-Method
-	I-Method
based	I-Method
methods	I-Method
in	O
reinforcement	B-Task
learning	I-Task
.	O
	
subsection	O
:	O
Improving	O
Exploration	B-Task
for	O
Actor	B-Method
-	I-Method
Critic	I-Method
Methods	I-Method
	
Our	O
implementation	O
of	O
A3C	B-Method
was	O
along	O
the	O
lines	O
mentioned	O
in	O
and	O
uses	O
16	O
threads	O
.	O
	
Each	O
thread	O
corresponds	O
to	O
an	O
actor	B-Method
learner	I-Method
and	O
maintains	O
a	O
copy	O
of	O
the	O
density	B-Method
model	I-Method
.	O
	
All	O
the	O
threads	O
are	O
synchronized	O
with	O
the	O
master	O
thread	O
at	O
regular	O
intervals	O
of	O
250	O
,	O
000	O
steps	O
.	O
	
We	O
followed	O
the	O
same	O
training	O
procedure	O
as	O
that	O
reported	O
in	O
the	O
A3C	B-Method
paper	O
with	O
the	O
following	O
additional	O
steps	O
:	O
We	O
update	O
our	O
density	B-Method
model	I-Method
with	O
the	O
states	O
generated	O
by	O
following	O
the	O
policy	O
.	O
	
During	O
the	O
policy	B-Method
gradient	I-Method
step	I-Method
,	O
we	O
compute	O
the	O
intrinsic	O
rewards	O
by	O
querying	O
the	O
density	B-Method
model	I-Method
and	O
add	O
it	O
to	O
the	O
extrinsic	O
rewards	O
before	O
clipping	O
them	O
in	O
the	O
range	O
as	O
was	O
done	O
in	O
the	O
A3C	B-Method
paper	O
.	O
	
This	O
resulted	O
in	O
minimal	O
overhead	O
in	O
computation	B-Metric
costs	I-Metric
and	O
the	O
memory	B-Metric
footprint	I-Metric
was	O
manageable	O
(	O
32	O
GB	O
)	O
for	O
most	O
of	O
the	O
Atari	B-Material
games	I-Material
.	O
	
Our	O
training	B-Metric
times	I-Metric
were	O
almost	O
the	O
same	O
as	O
the	O
ones	O
reported	O
in	O
the	O
A3C	B-Method
paper	O
.	O
	
We	O
picked	O
after	O
performing	O
a	O
short	O
parameter	O
sweep	O
over	O
the	O
training	O
games	O
.	O
	
The	O
choice	O
of	O
training	O
games	O
is	O
the	O
same	O
as	O
mentioned	O
in	O
the	O
A3C	B-Method
paper	O
.	O
	
The	O
games	O
on	O
which	O
DQN	B-Method
achieves	O
a	O
score	B-Metric
of	O
150	O
%	O
or	O
less	O
of	O
the	O
random	O
score	B-Metric
are	O
:	O
Asteroids	O
,	O
Double	O
Dunk	O
,	O
Gravitar	B-Material
,	O
Ice	O
Hockey	O
,	O
Montezuma	B-Material
’s	I-Material
Revenge	I-Material
,	O
Pitfall	O
!	O
,	O
Skiing	O
,	O
Surround	O
,	O
Tennis	O
,	O
Time	O
Pilot	O
.	O
	
The	O
games	O
on	O
which	O
A3C	B-Method
achieves	O
a	O
score	B-Metric
of	O
150	O
%	O
or	O
less	O
of	O
the	O
random	O
score	B-Metric
are	O
:	O
Battle	O
Zone	O
,	O
Bowling	O
,	O
Enduro	O
,	O
Freeway	B-Material
,	O
Gravitar	B-Material
,	O
Kangaroo	O
,	O
Pitfall	O
!	O
,	O
Robotank	O
,	O
Skiing	O
,	O
Solaris	O
,	O
Surround	O
,	O
Tennis	O
,	O
Time	O
Pilot	O
,	O
Venture	B-Material
.	O
	
The	O
games	O
on	O
which	O
A3C	B-Method
+	O
achieves	O
a	O
score	B-Metric
of	O
150	O
%	O
or	O
less	O
of	O
the	O
random	O
score	B-Metric
are	O
:	O
Double	O
Dunk	O
,	O
Gravitar	B-Material
,	O
Ice	O
Hockey	O
,	O
Pitfall	O
!	O
,	O
Skiing	O
,	O
Solaris	O
,	O
Surround	O
,	O
Tennis	O
,	O
Time	O
Pilot	O
,	O
Venture	B-Material
.	O
	
Our	O
experiments	O
involved	O
the	O
stochastic	B-Method
version	I-Method
of	O
the	O
Arcade	B-Method
Learning	I-Method
Environment	I-Method
(	O
ALE	B-Method
)	O
without	O
a	O
terminal	O
signal	O
for	O
life	O
loss	O
,	O
which	O
is	O
now	O
the	O
default	O
ALE	B-Method
setting	O
.	O
	
Briefly	O
,	O
the	O
stochasticity	O
is	O
achieved	O
by	O
accepting	O
the	O
agentâ	O
action	O
at	O
each	O
frame	O
with	O
probability	O
and	O
using	O
the	O
agentâs	O
previous	O
action	O
during	O
rejection	O
.	O
	
We	O
used	O
the	O
ALE	B-Method
’s	O
default	O
value	O
of	O
as	O
has	O
been	O
previously	O
used	O
in	O
.	O
	
For	O
comparison	O
,	O
Table	O
[	O
reference	O
]	O
also	O
reports	O
the	O
deterministic	O
+	O
life	O
loss	O
setting	O
also	O
used	O
in	O
the	O
literature	O
.	O
	
Anecdotally	O
,	O
we	O
found	O
that	O
using	O
the	O
life	O
loss	O
signal	O
,	O
while	O
helpful	O
in	O
achieving	O
high	O
scores	O
in	O
some	O
games	O
,	O
is	O
detrimental	O
in	O
Montezuma	B-Material
’s	I-Material
Revenge	I-Material
.	O
	
Recall	O
that	O
the	O
life	O
loss	O
signal	O
was	O
used	O
by	O
mnih15human	O
to	O
treat	O
each	O
of	O
the	O
agent	O
’	O
	
lives	O
as	O
a	O
separate	O
episode	O
.	O
	
For	O
comparison	O
,	O
after	O
200	O
million	O
frames	O
A3C	B-Method
+	O
achieves	O
the	O
following	O
average	B-Metric
scores	I-Metric
:	O
1	O
)	O
Stochastic	B-Metric
+	I-Metric
Life	I-Metric
Loss	I-Metric
:	O
142.50	O
;	O
2	O
)	O
Deterministic	B-Metric
+	I-Metric
Life	I-Metric
Loss	I-Metric
:	O
273.70	O
3	O
)	O
Stochastic	B-Method
without	I-Method
Life	I-Method
Loss	I-Method
:	O
1127.05	O
4	O
)	O
	
Deterministic	O
without	O
Life	O
Loss	O
:	O
273.70	O
.	O
	
The	O
maximum	O
score	B-Metric
achieved	O
by	O
3	O
)	O
is	O
3600	O
,	O
in	O
comparison	O
to	O
the	O
maximum	O
of	O
500	O
achieved	O
by	O
1	O
)	O
and	O
3	O
)	O
.	O
	
This	O
large	O
discrepancy	O
is	O
not	O
unsurprising	O
when	O
one	O
considers	O
that	O
losing	O
a	O
life	O
in	O
Montezuma	B-Material
’s	I-Material
Revenge	I-Material
,	O
and	O
in	O
fact	O
in	O
most	O
games	O
,	O
is	O
very	O
different	O
from	O
restarting	O
a	O
new	O
episode	O
.	O
	
subsection	O
:	O
Comparing	O
Exploration	B-Task
Bonuses	I-Task
	
In	O
this	O
section	O
we	O
compare	O
the	O
effect	O
of	O
using	O
different	O
exploration	O
bonuses	O
derived	O
from	O
our	O
density	B-Method
model	I-Method
.	O
	
We	O
consider	O
the	O
following	O
variants	O
:	O
no	O
exploration	O
bonus	O
,	O
,	O
as	O
per	O
MBIE	B-Method
-	O
EB	O
strehl08analysis	O
;	O
,	O
as	O
per	O
BEB	O
kolter09near	O
;	O
and	O
,	O
related	O
to	O
compression	B-Method
progress	O
schmidhuber08driven	O
.	O
	
The	O
exact	O
form	O
of	O
these	O
bonuses	O
is	O
analogous	O
to	O
(	O
[	O
reference	O
]	O
)	O
.	O
	
We	O
compare	O
these	O
variants	O
after	O
10	O
,	O
50	O
,	O
100	O
,	O
and	O
200	O
million	O
frames	O
of	O
training	O
,	O
again	O
in	O
the	O
A3C	B-Method
setup	O
.	O
	
To	O
compare	O
scores	O
across	O
60	O
games	O
,	O
we	O
use	O
inter	O
-	O
algorithm	O
score	B-Metric
distributions	O
bellemare13arcade	O
.	O
	
Inter	B-Metric
-	I-Metric
algorithm	I-Metric
scores	I-Metric
are	O
normalized	O
so	O
that	O
0	O
corresponds	O
to	O
the	O
worst	O
score	B-Metric
on	O
a	O
game	O
,	O
and	O
1	O
,	O
to	O
the	O
best	O
.	O
	
If	O
is	O
a	O
game	O
and	O
the	O
inter	O
-	O
algorithm	O
score	B-Metric
on	O
for	O
algorithm	O
,	O
then	O
the	O
score	B-Metric
distribution	O
function	O
is	O
The	O
score	B-Metric
distribution	O
effectively	O
depicts	O
a	O
kind	O
of	O
cumulative	B-Method
distribution	I-Method
,	O
with	O
a	O
higher	O
overall	O
curve	O
implying	O
better	O
scores	O
across	O
the	O
gamut	O
of	O
Atari	B-Task
2600	I-Task
games	I-Task
.	O
	
A	O
higher	O
curve	O
at	O
implies	O
top	O
performance	O
on	O
more	O
games	O
;	O
a	O
higher	O
curve	O
at	O
indicates	O
the	O
algorithm	O
does	O
not	O
perform	O
poorly	O
on	O
many	O
games	O
.	O
	
The	O
scale	O
parameter	O
was	O
optimized	O
to	O
for	O
each	O
variant	O
separately	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
that	O
,	O
while	O
prediction	B-Metric
gain	I-Metric
initially	O
achieves	O
strong	O
performance	O
,	O
by	O
50	O
million	O
frames	O
all	O
three	O
algorithms	O
perform	O
equally	O
well	O
.	O
	
By	O
200	O
million	O
frames	O
,	O
the	O
exploration	B-Method
bonus	I-Method
outperforms	O
both	O
prediction	B-Metric
gain	I-Metric
and	O
no	O
bonus	O
.	O
	
The	O
prediction	B-Metric
gain	I-Metric
achieves	O
a	O
decent	O
,	O
but	O
not	O
top	O
-	O
performing	O
score	B-Metric
on	O
all	O
games	O
.	O
	
This	O
matches	O
our	O
earlier	O
argument	O
that	O
using	O
prediction	O
gain	O
results	O
in	O
too	O
little	O
exploration	O
.	O
	
We	O
hypothesize	O
that	O
the	O
poor	O
performance	O
of	O
the	O
bonus	O
stems	O
from	O
too	O
abrupt	O
a	O
decay	O
from	O
a	O
large	O
to	O
small	O
intrinsic	O
reward	O
,	O
although	O
more	O
experiments	O
are	O
needed	O
.	O
	
As	O
a	O
whole	O
,	O
these	O
results	O
show	O
how	O
using	O
PG	B-Method
offers	O
an	O
advantage	O
over	O
the	O
baseline	O
A3C	B-Method
algorithm	O
,	O
which	O
is	O
furthered	O
by	O
using	O
our	O
count	B-Method
-	I-Method
based	I-Method
exploration	I-Method
bonus	I-Method
.	O
	
document	O
:	O
Transfer	B-Task
Learning	I-Task
for	O
Sequence	B-Task
Tagging	I-Task
with	O
Hierarchical	B-Method
Recurrent	I-Method
Networks	I-Method
	
Recent	O
papers	O
have	O
shown	O
that	O
neural	B-Method
networks	I-Method
obtain	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
several	O
different	O
sequence	B-Task
tagging	I-Task
tasks	I-Task
.	O
	
One	O
appealing	O
property	O
of	O
such	O
systems	O
is	O
their	O
generality	O
,	O
as	O
excellent	O
performance	O
can	O
be	O
achieved	O
with	O
a	O
unified	B-Method
architecture	I-Method
and	O
without	O
task	B-Method
-	I-Method
specific	I-Method
feature	I-Method
engineering	I-Method
.	O
	
However	O
,	O
it	O
is	O
unclear	O
if	O
such	O
systems	O
can	O
be	O
used	O
for	O
tasks	O
without	O
large	O
amounts	O
of	O
training	O
data	O
.	O
	
In	O
this	O
paper	O
we	O
explore	O
the	O
problem	O
of	O
transfer	B-Method
learning	I-Method
for	O
neural	B-Task
sequence	I-Task
taggers	I-Task
,	O
where	O
a	O
source	O
task	O
with	O
plentiful	O
annotations	O
(	O
e.g.	O
,	O
POS	B-Task
tagging	I-Task
on	O
Penn	B-Material
Treebank	I-Material
)	O
	
is	O
used	O
to	O
improve	O
performance	O
on	O
a	O
target	O
task	O
with	O
fewer	O
available	O
annotations	O
(	O
e.g.	O
,	O
POS	B-Task
tagging	I-Task
for	O
microblogs	O
)	O
.	O
	
We	O
examine	O
the	O
effects	O
of	O
transfer	B-Method
learning	I-Method
for	O
deep	B-Method
hierarchical	I-Method
recurrent	I-Method
networks	I-Method
across	O
domains	O
,	O
applications	O
,	O
and	O
languages	O
,	O
and	O
show	O
that	O
significant	O
improvement	O
can	O
often	O
be	O
obtained	O
.	O
	
These	O
improvements	O
lead	O
to	O
improvements	O
over	O
the	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
on	O
several	O
well	O
-	O
studied	O
tasks	O
.	O
	
section	O
:	O
Introduction	O
	
Sequence	B-Task
tagging	I-Task
is	O
an	O
important	O
problem	O
in	O
natural	B-Task
language	I-Task
processing	I-Task
,	O
which	O
has	O
wide	O
applications	O
including	O
part	B-Task
-	I-Task
of	I-Task
-	I-Task
speech	I-Task
(	O
POS	B-Task
)	O
tagging	O
,	O
text	B-Task
chunking	I-Task
,	O
and	O
named	B-Task
entity	I-Task
recognition	I-Task
(	O
NER	B-Task
)	O
.	O
	
Given	O
a	O
sequence	O
of	O
words	O
,	O
sequence	B-Method
tagging	I-Method
aims	O
to	O
predict	O
a	O
linguistic	O
tag	O
for	O
each	O
word	O
such	O
as	O
the	O
POS	B-Task
tag	O
.	O
	
An	O
important	O
challenge	O
for	O
sequence	B-Task
tagging	I-Task
is	O
how	O
to	O
transfer	O
knowledge	O
from	O
one	O
task	O
to	O
another	O
,	O
which	O
is	O
often	O
referred	O
to	O
as	O
transfer	B-Method
learning	I-Method
pan2010survey	O
.	O
	
Transfer	B-Method
learning	I-Method
can	O
be	O
used	O
in	O
several	O
settings	O
,	O
notably	O
for	O
low	O
-	O
resource	O
languages	O
zirikly2cross	O
,	O
wang2013cross	O
and	O
low	O
-	O
resource	O
domains	O
such	O
as	O
biomedical	O
corpora	O
kim2003genia	O
and	O
Twitter	B-Material
corpora	O
ritter2011named	O
)	O
.	O
	
In	O
these	O
cases	O
,	O
transfer	B-Method
learning	I-Method
can	O
improve	O
performance	O
by	O
taking	O
advantage	O
of	O
more	O
plentiful	O
labels	O
from	O
related	O
tasks	O
.	O
	
Even	O
on	O
datasets	O
with	O
relatively	O
abundant	O
labels	O
,	O
multi	B-Task
-	I-Task
task	I-Task
transfer	I-Task
can	O
sometimes	O
achieve	O
improvement	O
over	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
collobert2011natural	O
.	O
	
Recently	O
,	O
a	O
number	O
of	O
approaches	O
based	O
on	O
deep	O
neural	B-Method
networks	I-Method
have	O
addressed	O
the	O
problem	O
of	O
sequence	B-Task
tagging	I-Task
in	O
an	O
end	O
-	O
to	O
-	O
end	O
manner	O
collobert2011natural	O
,	O
lample2016neural	O
,	O
ling2015finding	O
,	O
ma2016end	O
.	O
	
These	O
neural	B-Method
networks	I-Method
consist	O
of	O
multiple	O
layers	O
of	O
neurons	O
organized	O
in	O
a	O
hierarchy	O
and	O
can	O
transform	O
the	O
input	O
tokens	O
to	O
the	O
output	O
labels	O
without	O
explicit	O
hand	O
-	O
engineered	O
feature	B-Task
extraction	I-Task
.	O
	
The	O
aforementioned	O
neural	B-Method
networks	I-Method
require	O
minimal	O
assumptions	O
about	O
the	O
task	O
at	O
hand	O
and	O
thus	O
demonstrate	O
significant	O
generality	O
	
—	O
	
one	O
single	O
model	O
can	O
be	O
applied	O
to	O
multiple	O
applications	O
in	O
multiple	O
languages	O
without	O
changing	O
the	O
architecture	O
.	O
	
A	O
natural	O
question	O
is	O
whether	O
the	O
representation	O
learned	O
from	O
one	O
task	O
can	O
be	O
useful	O
for	O
another	O
task	O
.	O
	
In	O
other	O
words	O
,	O
is	O
there	O
a	O
way	O
we	O
can	O
exploit	O
the	O
generality	O
of	O
neural	B-Method
networks	I-Method
to	O
improve	O
task	O
performance	O
by	O
sharing	O
model	B-Method
parameters	I-Method
and	O
feature	B-Method
representations	I-Method
with	O
another	O
task	O
?	O
	
To	O
address	O
the	O
above	O
question	O
,	O
we	O
study	O
the	O
transfer	B-Method
learning	I-Method
setting	O
,	O
which	O
aims	O
to	O
improve	O
the	O
performance	O
on	O
a	O
target	O
task	O
by	O
joint	B-Method
training	I-Method
with	O
a	O
source	O
task	O
.	O
	
We	O
present	O
a	O
transfer	B-Method
learning	I-Method
approach	O
based	O
on	O
a	O
deep	B-Method
hierarchical	I-Method
recurrent	I-Method
neural	I-Method
network	I-Method
,	O
which	O
shares	O
the	O
hidden	B-Method
feature	I-Method
representation	I-Method
and	O
part	O
of	O
the	O
model	O
parameters	O
between	O
the	O
source	O
task	O
and	O
the	O
target	O
task	O
.	O
	
Our	O
approach	O
combines	O
the	O
objectives	O
of	O
the	O
two	O
tasks	O
and	O
uses	O
gradient	B-Method
-	I-Method
based	I-Method
methods	I-Method
for	O
efficient	O
training	B-Task
.	O
	
We	O
study	O
cross	O
-	O
domain	O
,	O
cross	O
-	O
application	O
,	O
and	O
cross	B-Task
-	I-Task
lingual	I-Task
transfer	O
,	O
and	O
present	O
a	O
parameter	B-Method
-	I-Method
sharing	I-Method
architecture	I-Method
for	O
each	O
case	O
.	O
	
Experimental	O
results	O
show	O
that	O
our	O
approach	O
can	O
significantly	O
improve	O
the	O
performance	O
of	O
the	O
target	O
task	O
when	O
the	O
the	O
target	O
task	O
has	O
few	O
labels	O
and	O
is	O
more	O
related	O
to	O
the	O
source	O
task	O
.	O
	
Furthermore	O
,	O
we	O
show	O
that	O
transfer	B-Method
learning	I-Method
can	O
improve	O
performance	O
over	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
even	O
if	O
the	O
amount	O
of	O
labels	O
is	O
relatively	O
abundant	O
.	O
	
We	O
have	O
novel	O
contributions	O
in	O
two	O
folds	O
.	O
	
First	O
,	O
our	O
work	O
is	O
,	O
to	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
the	O
first	O
that	O
focuses	O
on	O
studying	O
the	O
transferability	O
of	O
different	O
layers	O
of	O
representations	O
for	O
hierarchical	B-Task
RNNs	I-Task
.	O
	
Second	O
,	O
different	O
from	O
previous	O
transfer	B-Method
learning	I-Method
methods	O
that	O
usually	O
focus	O
on	O
one	O
specific	O
transfer	O
setting	O
,	O
our	O
framework	O
exploits	O
different	O
levels	O
of	O
representation	B-Method
sharing	I-Method
and	O
provides	O
a	O
unified	O
framework	O
to	O
handle	O
cross	B-Task
-	I-Task
application	I-Task
,	O
cross	B-Task
-	I-Task
lingual	I-Task
,	O
and	O
cross	B-Task
-	I-Task
domain	I-Task
transfer	I-Task
.	O
	
section	O
:	O
Related	O
Work	O
	
There	O
are	O
two	O
common	O
paradigms	O
for	O
transfer	B-Method
learning	I-Method
for	O
natural	B-Task
language	I-Task
processing	I-Task
(	O
NLP	B-Task
)	O
tasks	O
,	O
resource	B-Task
-	I-Task
based	I-Task
transfer	I-Task
and	O
model	B-Method
-	I-Method
based	I-Method
transfer	I-Method
.	O
	
Resource	B-Method
-	I-Method
based	I-Method
transfer	I-Method
utilizes	O
additional	O
linguistic	O
annotations	O
as	O
weak	O
supervision	O
for	O
transfer	B-Method
learning	I-Method
,	O
such	O
as	O
cross	B-Task
-	I-Task
lingual	I-Task
dictionaries	O
zirikly2cross	O
,	O
corpora	O
wang2013cross	O
,	O
and	O
word	O
alignments	O
yarowsky2001inducing	O
.	O
	
Resource	B-Method
-	I-Method
based	I-Method
methods	I-Method
demonstrate	O
considerable	O
success	O
in	O
cross	B-Task
-	I-Task
lingual	I-Task
transfer	O
,	O
but	O
are	O
quite	O
sensitive	O
to	O
the	O
scale	O
and	O
quality	O
of	O
the	O
additional	O
resources	O
.	O
	
Resource	B-Method
-	I-Method
based	I-Method
transfer	I-Method
is	O
mostly	O
limited	O
to	O
cross	B-Task
-	I-Task
lingual	I-Task
transfer	O
in	O
previous	O
works	O
,	O
and	O
there	O
is	O
not	O
extensive	O
research	O
on	O
extending	O
resource	B-Method
-	I-Method
based	I-Method
methods	I-Method
to	O
cross	B-Task
-	I-Task
domain	I-Task
and	I-Task
cross	I-Task
-	I-Task
application	I-Task
settings	I-Task
.	O
	
Model	B-Method
-	I-Method
based	I-Method
transfer	I-Method
,	O
on	O
the	O
other	O
hand	O
,	O
does	O
not	O
require	O
additional	O
resources	O
.	O
	
Model	B-Method
-	I-Method
based	I-Method
transfer	I-Method
exploits	O
the	O
similarity	O
and	O
relatedness	O
between	O
the	O
source	O
task	O
and	O
the	O
target	O
task	O
by	O
adaptively	O
modifying	O
the	O
model	B-Method
architectures	I-Method
,	O
training	B-Method
algorithms	I-Method
,	O
or	O
feature	B-Method
representation	I-Method
.	O
	
For	O
example	O
,	O
proposed	O
a	O
transfer	B-Method
learning	I-Method
framework	O
that	O
shares	O
structural	O
parameters	O
across	O
multiple	O
tasks	O
,	O
and	O
improve	O
the	O
performance	O
on	O
various	O
tasks	O
including	O
NER	B-Task
;	O
presented	O
a	O
task	B-Method
-	I-Method
independent	I-Method
convolutional	I-Method
neural	I-Method
network	I-Method
and	O
employed	O
joint	B-Method
training	I-Method
to	O
transfer	O
knowledge	O
from	O
NER	B-Task
and	O
POS	B-Task
tagging	I-Task
to	O
chunking	B-Task
;	O
studied	O
transfer	B-Method
learning	I-Method
between	O
named	B-Task
entity	I-Task
recognition	I-Task
and	O
word	B-Task
segmentation	I-Task
in	O
Chinese	O
based	O
on	O
recurrent	O
neural	B-Method
networks	I-Method
.	O
	
Cross	B-Task
-	I-Task
domain	I-Task
transfer	I-Task
,	O
or	O
domain	B-Method
adaptation	I-Method
,	O
is	O
also	O
a	O
well	O
-	O
studied	O
branch	O
of	O
model	B-Method
-	I-Method
based	I-Method
transfer	I-Method
in	O
NLP	B-Task
.	O
	
Techniques	O
in	O
cross	B-Task
-	I-Task
domain	I-Task
transfer	I-Task
include	O
the	O
design	O
of	O
robust	B-Method
feature	I-Method
representations	I-Method
schnabel2014flors	O
,	O
co	B-Method
-	I-Method
training	I-Method
chen2011co	O
,	O
hierarchical	B-Method
Bayesian	I-Method
prior	I-Method
finkel2009hierarchical	O
,	O
and	O
canonical	B-Method
component	I-Method
analysis	I-Method
kim2015new	O
.	O
	
While	O
our	O
approach	O
falls	O
into	O
the	O
paradigm	O
of	O
model	B-Method
-	I-Method
based	I-Method
transfer	I-Method
,	O
in	O
contrast	O
to	O
the	O
above	O
methods	O
,	O
our	O
method	O
focuses	O
on	O
exploiting	O
the	O
generality	O
of	O
deep	O
recurrent	O
neural	B-Method
networks	I-Method
and	O
is	O
applicable	O
to	O
transfer	O
between	O
domains	O
,	O
applications	O
,	O
and	O
languages	O
.	O
	
Our	O
work	O
builds	O
on	O
previous	O
work	O
on	O
sequence	B-Task
tagging	I-Task
based	O
on	O
deep	O
neural	B-Method
networks	I-Method
.	O
	
develop	O
end	O
-	O
to	O
-	O
end	O
neural	B-Method
networks	I-Method
for	O
sequence	B-Task
tagging	I-Task
without	O
hand	O
-	O
engineered	O
features	O
.	O
	
Later	O
architectures	O
based	O
on	O
different	O
combinations	O
of	O
convolutional	B-Method
networks	I-Method
and	O
recurrent	B-Method
networks	I-Method
have	O
achieved	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
many	O
tasks	O
collobert2011natural	O
,	O
huang2015bidirectional	O
,	O
chiu2015named	O
,	O
lample2016neural	O
,	O
ma2016end	O
.	O
	
These	O
models	O
demonstrate	O
significant	O
generality	O
since	O
they	O
can	O
be	O
applied	O
to	O
multiple	O
applications	O
in	O
multiple	O
languages	O
with	O
a	O
unified	B-Method
network	I-Method
architecture	I-Method
and	O
without	O
task	B-Method
-	I-Method
specific	I-Method
feature	I-Method
extraction	I-Method
.	O
	
section	O
:	O
Approach	O
	
In	O
this	O
section	O
,	O
we	O
introduce	O
our	O
transfer	B-Method
learning	I-Method
approach	O
.	O
	
We	O
first	O
introduce	O
an	O
abstract	O
framework	O
for	O
neural	B-Task
sequence	I-Task
tagging	I-Task
,	O
summarizing	O
previous	O
work	O
,	O
and	O
then	O
discuss	O
three	O
different	O
transfer	B-Method
learning	I-Method
architectures	O
.	O
	
subsection	O
:	O
Base	O
Model	O
	
Though	O
many	O
different	O
variants	O
of	O
neural	B-Method
networks	I-Method
have	O
been	O
proposed	O
for	O
the	O
problem	O
of	O
sequence	B-Task
tagging	I-Task
,	O
we	O
find	O
that	O
most	O
of	O
the	O
models	O
can	O
be	O
described	O
with	O
the	O
hierarchical	B-Method
framework	I-Method
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
A	O
character	B-Method
-	I-Method
level	I-Method
layer	I-Method
takes	O
a	O
sequence	O
of	O
characters	O
(	O
represented	O
as	O
embeddings	O
)	O
as	O
input	O
,	O
and	O
outputs	O
a	O
representation	O
that	O
encodes	O
the	O
morphological	O
information	O
at	O
the	O
character	O
level	O
.	O
	
A	O
word	B-Method
-	I-Method
level	I-Method
layer	I-Method
subsequently	O
combines	O
the	O
character	B-Method
-	I-Method
level	I-Method
feature	I-Method
representation	I-Method
and	O
a	O
word	B-Method
embedding	I-Method
,	O
and	O
further	O
incorporates	O
the	O
contextual	O
information	O
to	O
output	O
a	O
new	O
feature	B-Method
representation	I-Method
.	O
	
After	O
two	O
levels	O
of	O
feature	B-Task
extraction	I-Task
(	O
encoding	B-Task
)	O
,	O
the	O
feature	B-Method
representation	I-Method
output	O
by	O
the	O
word	B-Method
-	I-Method
level	I-Method
layer	I-Method
is	O
fed	O
to	O
a	O
conditional	B-Method
random	I-Method
field	I-Method
(	O
CRF	B-Method
)	O
layer	O
that	O
outputs	O
the	O
label	O
sequence	O
.	O
	
Both	O
of	O
the	O
word	B-Method
-	I-Method
level	I-Method
layer	I-Method
and	O
the	O
character	B-Method
-	I-Method
level	I-Method
layer	I-Method
can	O
be	O
implemented	O
as	O
convolutional	O
neural	B-Method
networks	I-Method
(	O
CNNs	B-Method
)	O
or	O
recurrent	O
neural	B-Method
networks	I-Method
	
(	O
RNNs	B-Method
)	O
collobert2011natural	O
,	O
chiu2015named	O
,	O
lample2016neural	O
,	O
ma2016end	O
.	O
	
We	O
discuss	O
the	O
details	O
of	O
the	O
model	O
we	O
use	O
in	O
this	O
work	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
subsection	O
:	O
Transfer	B-Method
Learning	I-Method
Architectures	I-Method
	
We	O
develop	O
three	O
architectures	O
for	O
transfer	B-Method
learning	I-Method
,	O
T	B-Method
-	I-Method
A	I-Method
,	O
T	B-Method
-	I-Method
B	I-Method
,	O
and	O
T	B-Method
-	I-Method
C	I-Method
,	O
are	O
illustrated	O
in	O
Figures	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
and	O
[	O
reference	O
]	O
respectively	O
.	O
	
The	O
three	O
architectures	O
are	O
all	O
extensions	O
of	O
the	O
base	B-Method
model	I-Method
discussed	O
in	O
the	O
previous	O
section	O
with	O
different	O
parameter	B-Method
sharing	I-Method
schemes	I-Method
.	O
	
We	O
now	O
discuss	O
the	O
use	O
cases	O
for	O
the	O
different	O
architectures	O
.	O
	
subsubsection	O
:	O
Cross	B-Method
-	I-Method
Domain	I-Method
Transfer	I-Method
	
Since	O
different	O
domains	O
are	O
“	O
sub	O
-	O
languages	O
”	O
that	O
have	O
domain	O
-	O
specific	O
regularities	O
,	O
sequence	B-Method
taggers	I-Method
trained	O
on	O
one	O
domain	O
might	O
not	O
have	O
optimal	O
performance	O
on	O
another	O
domain	O
.	O
	
The	O
goal	O
of	O
cross	B-Task
-	I-Task
domain	I-Task
transfer	I-Task
is	O
to	O
learn	O
a	O
sequence	B-Method
tagger	I-Method
that	O
transfers	O
knowledge	O
from	O
a	O
source	O
domain	O
to	O
a	O
target	O
domain	O
.	O
	
We	O
assume	O
that	O
few	O
labels	O
are	O
available	O
in	O
the	O
target	O
domain	O
.	O
	
There	O
are	O
two	O
cases	O
of	O
cross	B-Task
-	I-Task
domain	I-Task
transfer	I-Task
.	O
	
The	O
two	O
domains	O
can	O
have	O
label	O
sets	O
that	O
can	O
be	O
mapped	O
to	O
each	O
other	O
,	O
or	O
disparate	O
label	O
sets	O
.	O
	
For	O
example	O
,	O
POS	B-Task
tags	I-Task
in	O
the	O
Genia	B-Material
biomedical	O
corpus	O
can	O
be	O
mapped	O
to	O
	
Penn	B-Task
Treebank	I-Task
tags	I-Task
barrett2014token	O
,	O
while	O
some	O
POS	B-Task
tags	I-Task
in	O
Twitter	B-Material
(	O
e.g.	O
,	O
“	O
URL	O
”	O
)	O
can	O
not	O
be	O
mapped	O
to	O
Penn	B-Task
Treebank	I-Task
tags	I-Task
ritter2011named	O
.	O
	
If	O
the	O
two	O
domains	O
have	O
mappable	O
label	O
sets	O
,	O
we	O
share	O
all	O
the	O
model	O
parameters	O
and	O
feature	B-Method
representation	I-Method
in	O
the	O
neural	B-Method
networks	I-Method
,	O
including	O
the	O
word	B-Method
and	I-Method
character	I-Method
embedding	I-Method
,	O
the	O
word	B-Method
-	I-Method
level	I-Method
layer	I-Method
,	O
the	O
character	B-Method
-	I-Method
level	I-Method
layer	I-Method
,	O
and	O
the	O
CRF	B-Method
layer	O
.	O
	
We	O
perform	O
a	O
label	B-Method
mapping	I-Method
step	I-Method
on	O
top	O
of	O
the	O
CRF	B-Method
layer	O
.	O
	
This	O
becomes	O
the	O
model	O
T	B-Method
-	I-Method
A	I-Method
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
If	O
the	O
two	O
domains	O
have	O
disparate	O
label	O
sets	O
,	O
we	O
untie	O
the	O
parameter	O
sharing	O
in	O
the	O
CRF	B-Method
layer	O
	
—	O
	
i.e	O
.	O
	
,	O
each	O
task	O
learns	O
a	O
separate	O
CRF	B-Method
layer	O
.	O
	
This	O
parameter	B-Method
sharing	I-Method
scheme	I-Method
reduces	O
to	O
model	O
T	B-Method
-	I-Method
B	I-Method
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
subsubsection	O
:	O
Cross	B-Method
-	I-Method
Application	I-Method
Transfer	I-Method
	
Sequence	B-Task
tagging	I-Task
has	O
a	O
couple	O
of	O
applications	O
including	O
POS	B-Task
tagging	I-Task
,	O
chunking	B-Task
,	O
and	O
named	B-Task
entity	I-Task
recognition	I-Task
.	O
	
Similar	O
to	O
the	O
motivation	O
in	O
collobert2011natural	O
,	O
it	O
is	O
usually	O
desirable	O
to	O
exploit	O
the	O
underlying	O
similarities	O
and	O
regularities	O
of	O
different	O
applications	O
,	O
and	O
improve	O
the	O
performance	O
of	O
one	O
application	O
via	O
joint	B-Method
training	I-Method
with	O
another	O
.	O
	
Moreover	O
,	O
transfer	O
between	O
multiple	O
applications	O
can	O
be	O
helpful	O
when	O
the	O
labels	O
are	O
limited	O
.	O
	
In	O
the	O
cross	B-Task
-	I-Task
application	I-Task
setting	I-Task
,	O
we	O
assume	O
that	O
multiple	O
applications	O
are	O
in	O
the	O
same	O
language	O
.	O
	
Since	O
different	O
applications	O
share	O
the	O
same	O
alphabet	O
,	O
the	O
case	O
is	O
similar	O
to	O
cross	B-Task
-	I-Task
domain	I-Task
transfer	I-Task
with	O
disparate	O
label	O
sets	O
.	O
	
We	O
adopt	O
the	O
architecture	O
of	O
model	O
T	B-Method
-	I-Method
B	I-Method
for	O
cross	O
-	O
application	O
transfer	B-Method
learning	I-Method
where	O
only	O
the	O
CRF	B-Method
layers	O
are	O
disjoint	O
for	O
different	O
applications	O
.	O
	
subsubsection	O
:	O
Cross	B-Method
-	I-Method
Lingual	I-Method
Transfer	I-Method
	
Though	O
cross	B-Task
-	I-Task
lingual	I-Task
transfer	O
is	O
usually	O
accomplished	O
with	O
additional	O
multi	O
-	O
lingual	O
resources	O
,	O
these	O
methods	O
are	O
sensitive	O
to	O
the	O
size	O
and	O
quality	O
of	O
the	O
additional	O
resources	O
yarowsky2001inducing	O
,	O
wang2013cross	O
.	O
	
In	O
this	O
work	O
,	O
instead	O
,	O
we	O
explore	O
a	O
complementary	O
method	O
that	O
exploits	O
the	O
cross	B-Task
-	I-Task
lingual	I-Task
regularities	O
purely	O
on	O
the	O
model	O
level	O
.	O
	
Our	O
approach	O
focuses	O
on	O
transfer	B-Method
learning	I-Method
between	O
languages	O
with	O
similar	O
alphabets	O
,	O
such	O
as	O
English	O
and	O
Spanish	B-Task
,	O
since	O
it	O
is	O
very	O
difficult	O
for	O
transfer	B-Method
learning	I-Method
between	O
languages	O
with	O
disparate	O
alphabets	O
(	O
e.g.	O
,	O
English	O
and	O
Chinese	O
)	O
to	O
work	O
without	O
additional	O
resources	O
zirikly2cross	O
.	O
	
Model	O
-	O
level	O
transfer	B-Method
learning	I-Method
is	O
achieved	O
through	O
exploiting	O
the	O
morphologies	O
shared	O
by	O
the	O
two	O
languages	O
.	O
	
For	O
example	O
,	O
“	O
Canada	O
”	O
in	O
English	O
and	O
“	O
Canadá	O
”	O
in	O
Spanish	B-Task
refer	O
to	O
the	O
same	O
named	O
entity	O
,	O
and	O
the	O
morphological	O
similarities	O
can	O
be	O
leveraged	O
for	O
NER	B-Task
and	O
also	O
POS	B-Task
tagging	I-Task
with	O
nouns	O
.	O
	
Thus	O
we	O
share	O
the	O
character	O
embeddings	O
and	O
the	O
character	O
-	O
level	O
layer	O
between	O
different	O
languages	O
for	O
transfer	B-Method
learning	I-Method
,	O
which	O
is	O
illustrated	O
as	O
the	O
model	O
T	B-Method
-	I-Method
C	I-Method
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
subsection	O
:	O
Training	O
	
In	O
the	O
above	O
sections	O
,	O
we	O
introduced	O
three	O
neural	B-Method
architectures	I-Method
with	O
different	O
parameter	B-Method
sharing	I-Method
schemes	I-Method
,	O
designed	O
for	O
different	O
transfer	B-Method
learning	I-Method
settings	O
.	O
	
Now	O
we	O
describe	O
how	O
we	O
train	O
the	O
neural	B-Method
networks	I-Method
jointly	O
for	O
two	O
tasks	O
.	O
	
Suppose	O
we	O
are	O
transferring	O
from	O
a	O
source	O
task	O
to	O
a	O
target	O
task	O
,	O
with	O
the	O
training	O
instances	O
being	O
and	O
.	O
	
Let	O
and	O
denote	O
the	O
set	O
of	O
model	O
parameters	O
for	O
the	O
source	O
and	O
target	O
tasks	O
respectively	O
.	O
	
The	O
model	O
parameters	O
are	O
divided	O
into	O
two	O
sets	O
,	O
task	O
specific	O
parameters	O
and	O
shared	O
parameters	O
,	O
i.e.	O
,	O
where	O
shared	O
parameters	O
are	O
jointly	O
optimized	O
by	O
the	O
two	O
tasks	O
,	O
while	O
task	O
specific	O
parameters	O
and	O
are	O
trained	O
for	O
each	O
task	O
separately	O
.	O
	
The	O
training	O
procedure	O
is	O
as	O
follows	O
.	O
	
At	O
each	O
iteration	O
,	O
we	O
sample	O
a	O
task	O
(	O
i.e.	O
,	O
either	O
or	O
)	O
from	O
based	O
on	O
a	O
binomial	O
distribution	O
(	O
the	O
binomial	O
probability	O
is	O
set	O
as	O
a	O
hyperparameter	O
)	O
.	O
	
Given	O
the	O
sampled	O
task	O
,	O
we	O
sample	O
a	O
batch	O
of	O
training	O
instances	O
from	O
the	O
given	O
task	O
,	O
and	O
then	O
perform	O
a	O
gradient	B-Method
update	I-Method
according	O
to	O
the	O
loss	O
function	O
of	O
the	O
given	O
task	O
.	O
	
We	O
update	O
both	O
the	O
shared	O
parameters	O
and	O
the	O
task	O
specific	O
parameters	O
.	O
	
We	O
repeat	O
the	O
above	O
iterations	O
until	O
stopping	O
.	O
	
We	O
adopt	O
AdaGrad	B-Method
duchi2011adaptive	I-Method
to	O
dynamically	O
compute	O
the	O
learning	O
rates	O
for	O
each	O
iteration	O
.	O
	
Since	O
the	O
source	O
and	O
target	O
tasks	O
might	O
have	O
different	O
convergence	B-Metric
rates	I-Metric
,	O
we	O
do	O
early	O
stopping	O
on	O
the	O
target	O
task	O
performance	O
.	O
	
subsection	O
:	O
Model	O
Implementation	O
	
In	O
this	O
section	O
,	O
we	O
describe	O
our	O
implementation	O
of	O
the	O
base	B-Method
model	I-Method
.	O
	
Both	O
the	O
character	O
-	O
level	O
and	O
word	O
-	O
level	O
neural	B-Method
networks	I-Method
are	O
implemented	O
as	O
RNNs	B-Method
.	O
	
More	O
specifically	O
,	O
we	O
employ	O
gated	B-Method
recurrent	I-Method
units	I-Method
(	O
GRUs	B-Method
)	O
cho2014properties	O
.	O
	
Let	O
be	O
a	O
sequence	O
of	O
inputs	O
that	O
can	O
be	O
embeddings	O
or	O
hidden	O
states	O
of	O
other	O
layers	O
.	O
	
Let	O
be	O
the	O
GRU	O
hidden	O
state	O
at	O
time	O
step	O
.	O
	
Formally	O
,	O
a	O
GRU	B-Method
unit	I-Method
at	O
time	O
step	O
can	O
be	O
expressed	O
as	O
where	O
’s	O
are	O
model	O
parameters	O
of	O
each	O
unit	O
,	O
is	O
a	O
candidate	O
hidden	O
state	O
that	O
is	O
used	O
to	O
compute	O
,	O
is	O
an	O
element	B-Method
-	I-Method
wise	I-Method
sigmoid	I-Method
logistic	I-Method
function	I-Method
defined	O
as	O
,	O
and	O
denotes	O
element	O
-	O
wise	O
multiplication	O
of	O
two	O
vectors	O
.	O
	
Intuitively	O
,	O
the	O
update	O
gate	O
controls	O
how	O
much	O
the	O
unit	O
updates	O
its	O
hidden	O
state	O
,	O
and	O
the	O
reset	O
gate	O
determines	O
how	O
much	O
information	O
from	O
the	O
previous	O
hidden	O
state	O
needs	O
to	O
be	O
reset	O
.	O
	
The	O
input	O
to	O
the	O
character	O
-	O
level	O
GRUs	B-Method
is	O
character	O
embeddings	O
,	O
while	O
the	O
input	O
to	O
the	O
word	O
-	O
level	O
GRUs	B-Method
is	O
the	O
concatenation	O
of	O
character	O
-	O
level	O
GRU	O
hidden	O
states	O
and	O
word	B-Method
embeddings	I-Method
.	O
	
Both	O
GRUs	B-Method
are	O
bi	O
-	O
directional	O
and	O
have	O
two	O
layers	O
.	O
	
Given	O
an	O
input	O
sequence	O
of	O
words	O
,	O
the	O
word	O
-	O
level	O
GRUs	B-Method
and	O
the	O
character	O
-	O
level	O
GRUs	B-Method
together	O
learn	O
a	O
feature	B-Method
representation	I-Method
for	O
the	O
-	O
th	O
word	O
in	O
the	O
sequence	O
,	O
which	O
forms	O
a	O
sequence	O
.	O
	
Let	O
denote	O
the	O
tag	O
sequence	O
.	O
	
Given	O
the	O
feature	B-Method
representation	I-Method
and	O
the	O
tag	O
sequence	O
for	O
each	O
training	O
instance	O
,	O
the	O
CRF	B-Method
layer	O
defines	O
the	O
objective	B-Metric
function	I-Metric
to	O
maximize	O
based	O
on	O
a	O
max	B-Method
-	I-Method
margin	I-Method
principle	I-Method
gimpel2010softmax	O
as	O
:	O
where	O
is	O
a	O
function	O
that	O
assigns	O
a	O
score	O
for	O
each	O
pair	O
of	O
and	O
,	O
and	O
denotes	O
the	O
space	O
of	O
tag	O
sequences	O
for	O
.	O
	
The	O
cost	O
function	O
is	O
added	O
based	O
on	O
the	O
max	B-Method
-	I-Method
margin	I-Method
principle	I-Method
gimpel2010softmax	O
that	O
high	O
-	O
cost	O
tags	O
should	O
be	O
penalized	O
more	O
heavily	O
.	O
	
Our	O
base	O
model	O
is	O
similar	O
to	O
,	O
but	O
in	O
contrast	O
to	O
their	O
model	O
,	O
we	O
employ	O
GRUs	B-Method
for	O
the	O
character	O
-	O
level	O
and	O
word	O
-	O
level	O
networks	O
instead	O
of	O
Long	B-Method
Short	I-Method
-	I-Method
Term	I-Method
Memory	I-Method
(	O
LSTM	B-Method
)	O
units	O
,	O
and	O
define	O
the	O
objective	O
function	O
based	O
on	O
the	O
max	B-Method
-	I-Method
margin	I-Method
principle	I-Method
.	O
	
We	O
note	O
that	O
our	O
transfer	B-Method
learning	I-Method
framework	O
does	O
not	O
make	O
assumptions	O
about	O
specific	O
model	B-Method
implementation	I-Method
,	O
and	O
could	O
be	O
applied	O
to	O
other	O
neural	B-Method
architectures	I-Method
collobert2011natural	O
,	O
chiu2015named	O
,	O
lample2016neural	O
,	O
ma2016end	O
as	O
well	O
.	O
	
section	O
:	O
Experiments	O
	
subsection	O
:	O
Datasets	O
	
We	O
use	O
the	O
following	O
benchmark	O
datasets	O
in	O
our	O
experiments	O
:	O
Penn	B-Material
Treebank	I-Material
(	O
PTB	B-Material
)	O
	
POS	B-Task
tagging	I-Task
,	O
CoNLL	O
2000	O
chunking	O
,	O
CoNLL	B-Material
2003	I-Material
English	I-Material
NER	I-Material
,	O
	
CoNLL	B-Material
2002	I-Material
Dutch	I-Material
NER	I-Material
,	O
	
CoNLL	B-Material
2002	I-Material
Spanish	I-Material
NER	I-Material
,	O
the	O
Genia	B-Material
biomedical	I-Material
corpus	I-Material
kim2003genia	O
,	O
and	O
a	O
Twitter	B-Material
corpus	I-Material
ritter2011named	O
.	O
	
The	O
statistics	O
of	O
the	O
datasets	O
are	O
described	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
We	O
construct	O
the	O
POS	B-Task
tagging	I-Task
dataset	O
with	O
the	O
instructions	O
described	O
in	O
.	O
	
Note	O
that	O
as	O
a	O
standard	O
practice	O
,	O
the	O
POS	B-Task
tags	O
are	O
extracted	O
from	O
the	O
parsed	O
trees	O
.	O
	
For	O
the	O
CoNLL	O
2003	O
English	O
NER	B-Task
dataset	O
,	O
we	O
follow	O
previous	O
works	O
collobert2011natural	O
to	O
append	O
one	O
-	O
hot	O
gazetteer	O
features	O
to	O
the	O
input	O
of	O
the	O
CRF	B-Method
layer	O
for	O
fair	O
comparison	O
.	O
	
Since	O
there	O
is	O
no	O
standard	O
training	O
/	O
dev	O
/	O
test	O
data	O
split	O
for	O
the	O
Genia	B-Material
and	O
Twitter	B-Material
corpora	O
,	O
we	O
randomly	O
sample	O
10	O
%	O
for	O
test	O
,	O
10	O
%	O
for	O
development	B-Task
,	O
and	O
80	O
%	O
for	O
training	O
.	O
	
We	O
follow	O
previous	O
work	O
barrett2014token	O
to	O
map	O
Genia	B-Material
POS	I-Task
tags	I-Task
to	O
PTB	B-Material
POS	I-Task
tags	I-Task
.	O
	
subsection	O
:	O
Transfer	B-Task
Learning	I-Task
Performance	O
	
We	O
evaluate	O
our	O
transfer	B-Method
learning	I-Method
approach	O
on	O
the	O
above	O
datasets	O
.	O
	
We	O
fix	O
the	O
hyperparameters	O
for	O
all	O
the	O
results	O
reported	O
in	O
this	O
section	O
:	O
we	O
set	O
the	O
character	O
embedding	O
dimension	O
at	O
,	O
the	O
word	O
embedding	O
dimension	O
at	O
for	O
English	O
and	O
for	O
Spanish	B-Task
,	O
the	O
dimension	O
of	O
hidden	O
states	O
of	O
the	O
character	O
-	O
level	O
GRUs	B-Method
at	O
,	O
the	O
dimension	O
of	O
hidden	O
states	O
of	O
the	O
word	O
-	O
level	O
GRUs	B-Method
at	O
,	O
and	O
the	O
initial	O
learning	B-Metric
rate	I-Metric
at	O
.	O
	
Except	O
for	O
the	O
Twitter	B-Material
datasets	O
,	O
these	O
datasets	O
are	O
fairly	O
large	O
.	O
	
To	O
simulate	O
a	O
low	B-Task
-	I-Task
resource	I-Task
setting	I-Task
,	O
we	O
also	O
use	O
random	O
subsets	O
of	O
the	O
data	O
.	O
	
We	O
vary	O
the	O
labeling	B-Metric
rate	I-Metric
of	O
the	O
target	O
task	O
at	O
,	O
,	O
and	O
.	O
	
Given	O
a	O
labeling	B-Metric
rate	I-Metric
,	O
we	O
randomly	O
sample	O
a	O
ratio	O
of	O
the	O
sentences	O
from	O
the	O
training	O
set	O
and	O
discard	O
the	O
rest	O
of	O
the	O
training	O
data	O
	
—	O
e.g	O
.	O
,	O
a	O
labeling	B-Metric
rate	I-Metric
of	O
results	O
in	O
around	O
900	O
training	O
tokens	O
on	O
PTB	B-Task
POS	I-Task
tagging	I-Task
(	O
Cf	O
.	O
	
Table	O
[	O
reference	O
]	O
)	O
.	O
	
The	O
results	O
on	O
transfer	B-Method
learning	I-Method
are	O
plotted	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
where	O
we	O
compare	O
the	O
results	O
with	O
and	O
without	O
transfer	B-Method
learning	I-Method
under	O
various	O
labeling	B-Metric
rates	I-Metric
.	O
	
The	O
numbers	O
in	O
the	O
y	O
-	O
axes	O
are	O
accuracies	B-Metric
for	O
POS	B-Task
tagging	I-Task
,	O
and	O
chunk	B-Metric
-	I-Metric
level	I-Metric
F1	I-Metric
scores	I-Metric
for	O
chunking	B-Task
and	O
NER	B-Task
.	O
	
The	O
numbers	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
We	O
can	O
see	O
that	O
our	O
transfer	B-Method
learning	I-Method
approach	O
consistently	O
improved	O
over	O
the	O
non	O
-	O
transfer	O
results	O
.	O
	
We	O
also	O
observe	O
that	O
the	O
improvement	O
by	O
transfer	B-Method
learning	I-Method
is	O
more	O
substantial	O
when	O
the	O
labeling	B-Metric
rate	I-Metric
is	O
lower	O
.	O
	
For	O
cross	B-Task
-	I-Task
domain	I-Task
transfer	I-Task
,	O
we	O
obtained	O
substantial	O
improvement	O
on	O
the	O
Genia	B-Material
and	O
Twitter	B-Material
corpora	O
by	O
transferring	O
the	O
knowledge	O
from	O
PTB	B-Task
POS	I-Task
tagging	I-Task
and	O
CoNLL	B-Task
2003	I-Task
NER	I-Task
.	O
	
For	O
example	O
,	O
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
we	O
can	O
obtain	O
an	O
tagging	B-Metric
accuracy	I-Metric
of	O
with	O
zero	O
labels	O
and	O
with	O
only	O
labels	O
when	O
transferring	O
from	O
PTB	B-Material
to	O
Genia	B-Material
.	O
	
As	O
shown	O
in	O
Figures	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
,	O
our	O
transfer	B-Method
learning	I-Method
approach	O
can	O
improve	O
the	O
performance	O
on	O
Twitter	B-Task
POS	I-Task
tagging	I-Task
and	O
NER	B-Task
for	O
all	O
labeling	B-Metric
rates	I-Metric
,	O
and	O
the	O
improvements	O
with	O
labels	O
are	O
more	O
than	O
for	O
both	O
datasets	O
.	O
	
Cross	B-Method
-	I-Method
application	I-Method
transfer	I-Method
also	O
leads	O
to	O
substantial	O
improvement	O
under	O
low	O
-	O
resource	O
conditions	O
.	O
	
For	O
example	O
,	O
as	O
shown	O
in	O
Figures	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
,	O
the	O
improvements	O
with	O
labels	O
are	O
and	O
on	O
CoNLL	O
2000	O
chunking	O
and	O
CoNLL	O
	
2003	O
NER	B-Task
respectively	O
when	O
transferring	O
from	O
PTB	B-Task
POS	I-Task
tagging	I-Task
.	O
	
Figures	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
show	O
that	O
cross	B-Task
-	I-Task
lingual	I-Task
transfer	O
can	O
improve	O
the	O
performance	O
when	O
few	O
labels	O
are	O
available	O
.	O
	
Figure	O
[	O
reference	O
]	O
further	O
shows	O
that	O
the	O
improvements	O
by	O
different	O
architectures	O
are	O
in	O
the	O
following	O
order	O
:	O
	
T	B-Method
-	I-Method
A	I-Method
T	I-Method
-	I-Method
B	I-Method
T	O
-	O
C.	O
	
This	O
phenomenon	O
can	O
be	O
explained	O
by	O
the	O
fact	O
that	O
T	B-Method
-	I-Method
A	I-Method
shares	O
the	O
most	O
model	O
parameters	O
while	O
T	B-Method
-	I-Method
C	I-Method
shares	O
the	O
least	O
.	O
	
Transfer	B-Method
settings	I-Method
like	O
cross	B-Task
-	I-Task
lingual	I-Task
transfer	O
can	O
only	O
use	O
T	B-Method
-	I-Method
C	I-Method
because	O
the	O
underlying	O
similarities	O
between	O
the	O
source	O
task	O
and	O
the	O
target	O
task	O
are	O
less	O
prominent	O
(	O
i.e.	O
,	O
less	O
transferable	O
)	O
,	O
and	O
in	O
those	O
cases	O
the	O
improvement	O
by	O
transfer	B-Method
learning	I-Method
is	O
less	O
substantial	O
.	O
	
Another	O
interesting	O
comparison	O
is	O
among	O
Figures	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
and	O
[	O
reference	O
]	O
.	O
	
Figure	O
[	O
reference	O
]	O
is	O
	
cross	B-Task
-	I-Task
domain	I-Task
transfer	I-Task
,	O
Figure	O
[	O
reference	O
]	O
is	O
transfer	O
across	O
domains	O
and	O
applications	O
at	O
the	O
same	O
time	O
,	O
and	O
Figure	O
[	O
reference	O
]	O
combines	O
all	O
the	O
three	O
transfer	O
settings	O
(	O
i.e.	O
,	O
from	O
Spanish	B-Task
NER	I-Task
in	O
the	O
general	O
domain	O
to	O
English	B-Task
POS	I-Task
tagging	I-Task
in	O
the	O
biomedical	O
domain	O
)	O
.	O
	
The	O
results	O
show	O
that	O
the	O
improvement	O
by	O
transfer	B-Method
learning	I-Method
diminishes	O
when	O
the	O
transfer	O
becomes	O
“	O
indirect	O
”	O
(	O
i.e.	O
,	O
the	O
source	O
task	O
and	O
the	O
target	O
task	O
are	O
more	O
loosely	O
related	O
)	O
.	O
	
We	O
also	O
study	O
using	O
different	O
transfer	B-Method
learning	I-Method
models	O
for	O
the	O
same	O
task	O
.	O
	
We	O
study	O
the	O
effects	O
of	O
using	O
T	B-Method
-	I-Method
A	I-Method
,	O
T	B-Method
-	I-Method
B	I-Method
,	O
and	O
T	B-Method
-	I-Method
C	I-Method
when	O
transferring	O
from	O
PTB	B-Material
to	O
Genia	B-Material
,	O
and	O
the	O
results	O
are	O
included	O
in	O
the	O
lower	O
part	O
of	O
Table	O
[	O
reference	O
]	O
.	O
	
We	O
observe	O
that	O
the	O
performance	O
gain	O
decreases	O
when	O
less	O
parameters	O
are	O
shared	O
(	O
i.e.	O
,	O
T	B-Method
-	I-Method
A	I-Method
T	I-Method
-	I-Method
B	I-Method
T	I-Method
-	I-Method
C	I-Method
)	O
.	O
	
subsection	O
:	O
Comparison	O
with	O
State	O
-	O
of	O
-	O
the	O
-	O
Art	O
Results	O
	
In	O
the	O
above	O
section	O
,	O
we	O
examine	O
the	O
effects	O
of	O
different	O
transfer	B-Method
learning	I-Method
architectures	O
.	O
	
Now	O
we	O
compare	O
our	O
approach	O
with	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
systems	O
on	O
these	O
datasets	O
.	O
	
We	O
use	O
publicly	O
available	O
pretrained	O
word	O
embeddings	O
as	O
initialization	O
.	O
	
On	O
the	O
English	B-Material
datasets	I-Material
,	O
following	O
previous	O
works	O
that	O
are	O
based	O
on	O
neural	B-Method
networks	I-Method
collobert2011natural	O
,	O
huang2015bidirectional	O
,	O
chiu2015named	O
,	O
ma2016end	O
,	O
we	O
experiment	O
with	O
both	O
the	O
50	B-Method
-	I-Method
dimensional	I-Method
SENNA	I-Method
embeddings	I-Method
collobert2011natural	O
and	O
the	O
100	B-Method
-	I-Method
dimensional	I-Method
GloVe	I-Method
embeddings	I-Method
pennington2014glove	O
and	O
use	O
the	O
development	O
set	O
to	O
choose	O
the	O
embeddings	O
for	O
different	O
tasks	O
and	O
settings	O
.	O
	
For	O
Spanish	B-Task
and	O
Dutch	O
,	O
we	O
use	O
the	O
64	B-Method
-	I-Method
dimensional	I-Method
Polyglot	I-Method
embeddings	O
al2013polyglot	O
.	O
	
We	O
set	O
the	O
hidden	O
state	O
dimensions	O
to	O
be	O
300	O
for	O
the	O
word	B-Method
-	I-Method
level	I-Method
GRU	I-Method
.	O
	
The	O
initial	O
learning	B-Metric
rate	I-Metric
for	O
AdaGrad	B-Method
is	O
fixed	O
at	O
0.01	O
.	O
	
We	O
use	O
the	O
development	O
set	O
to	O
tune	O
the	O
other	O
hyperparameters	O
of	O
our	O
model	O
.	O
	
Our	O
results	O
are	O
reported	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Since	O
there	O
are	O
no	O
standard	O
data	O
splits	O
on	O
the	O
Genia	B-Material
and	O
Twitter	B-Material
corpora	O
,	O
we	O
do	O
not	O
include	O
these	O
datasets	O
into	O
our	O
comparison	O
.	O
	
The	O
results	O
for	O
CoNLL	O
2000	O
chunking	O
,	O
CoNLL	B-Task
2003	I-Task
NER	I-Task
,	O
and	O
PTB	B-Task
POS	I-Task
tagging	I-Task
are	O
obtained	O
by	O
transfer	B-Method
learning	I-Method
between	O
the	O
three	O
tasks	O
,	O
i.e.	O
,	O
transferring	O
from	O
two	O
tasks	O
to	O
the	O
other	O
.	O
	
The	O
results	O
for	O
Spanish	B-Task
and	O
Dutch	B-Task
NER	I-Task
are	O
obtained	O
with	O
transfer	B-Method
learning	I-Method
between	O
the	O
NER	B-Task
datasets	O
in	O
three	O
languages	O
(	O
English	B-Material
,	O
Spanish	B-Task
,	O
and	O
Dutch	O
)	O
.	O
	
From	O
Table	O
[	O
reference	O
]	O
,	O
we	O
can	O
draw	O
two	O
conclusions	O
.	O
	
First	O
,	O
our	O
transfer	B-Method
learning	I-Method
approach	O
achieves	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
all	O
the	O
considered	O
benchmark	O
datasets	O
except	O
PTB	B-Task
POS	I-Task
tagging	I-Task
,	O
which	O
indicates	O
that	O
transfer	B-Method
learning	I-Method
can	O
still	O
improve	O
the	O
performance	O
even	O
on	O
datasets	O
with	O
relatively	O
abundant	O
labels	O
.	O
	
Second	O
,	O
our	O
base	O
model	O
(	O
w	B-Method
/	I-Method
o	I-Method
transfer	I-Method
)	O
performs	O
competitively	O
compared	O
to	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
systems	O
,	O
which	O
means	O
that	O
the	O
improvements	O
shown	O
in	O
Section	O
[	O
reference	O
]	O
are	O
obtained	O
over	O
a	O
strong	O
baseline	O
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
paper	O
we	O
develop	O
a	O
transfer	B-Method
learning	I-Method
approach	O
for	O
sequence	B-Task
tagging	I-Task
,	O
which	O
exploits	O
the	O
generality	O
demonstrated	O
by	O
deep	O
neural	B-Method
networks	I-Method
in	O
previous	O
work	O
.	O
	
We	O
design	O
three	O
neural	B-Method
network	I-Method
architectures	I-Method
for	O
the	O
settings	O
of	O
cross	B-Task
-	I-Task
domain	I-Task
,	I-Task
cross	I-Task
-	I-Task
application	I-Task
,	O
and	O
cross	B-Task
-	I-Task
lingual	I-Task
transfer	O
.	O
	
Our	O
transfer	B-Method
learning	I-Method
approach	O
achieves	O
significant	O
improvement	O
on	O
various	O
datasets	O
under	O
low	O
-	O
resource	O
conditions	O
,	O
as	O
well	O
as	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
some	O
of	O
the	O
benchmarks	O
.	O
	
With	O
thorough	O
experiments	O
,	O
we	O
observe	O
that	O
the	O
following	O
factors	O
are	O
crucial	O
for	O
the	O
performance	O
of	O
our	O
transfer	B-Method
learning	I-Method
approach	O
:	O
a	O
)	O
label	O
abundance	O
for	O
the	O
target	O
task	O
,	O
b	O
)	O
relatedness	O
between	O
the	O
source	O
and	O
target	O
tasks	O
,	O
and	O
c	O
)	O
the	O
number	O
of	O
parameters	O
that	O
can	O
be	O
shared	O
.	O
	
In	O
the	O
future	O
,	O
it	O
will	O
be	O
interesting	O
to	O
combine	O
model	B-Method
-	I-Method
based	I-Method
transfer	I-Method
(	O
as	O
in	O
this	O
work	O
)	O
with	O
resource	B-Method
-	I-Method
based	I-Method
transfer	I-Method
for	O
cross	B-Task
-	I-Task
lingual	I-Task
transfer	I-Method
learning	I-Method
.	O
	
subsubsection	O
:	O
Acknowledgments	O
	
This	O
work	O
was	O
funded	O
by	O
NVIDIA	O
,	O
the	O
Office	O
of	O
Naval	O
Research	O
grant	O
N000141512791	O
,	O
the	O
ADeLAIDE	O
grant	O
FA8750	O
-	O
16C	O
-	O
0130	O
-	O
001	O
,	O
the	O
NSF	O
grant	O
IIS1250956	O
,	O
and	O
Google	O
Research	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
FaceNet	B-Method
:	O
A	O
Unified	B-Method
Embedding	I-Method
for	O
Face	B-Task
Recognition	I-Task
and	I-Task
Clustering	I-Task
	
Despite	O
significant	O
recent	O
advances	O
in	O
the	O
field	O
of	O
face	O
recognition	B-Task
,	O
implementing	O
face	B-Task
verification	I-Task
and	O
recognition	B-Task
efficiently	O
at	O
scale	O
presents	O
serious	O
challenges	O
to	O
current	O
approaches	O
.	O
	
In	O
this	O
paper	O
we	O
present	O
a	O
system	O
,	O
called	O
FaceNet	B-Method
,	O
that	O
directly	O
learns	O
a	O
mapping	O
from	O
face	O
images	O
to	O
a	O
compact	O
Euclidean	O
space	O
where	O
distances	O
directly	O
correspond	O
to	O
a	O
measure	O
of	O
face	B-Metric
similarity	I-Metric
.	O
	
Once	O
this	O
space	O
has	O
been	O
produced	O
,	O
tasks	O
such	O
as	O
face	O
recognition	B-Task
,	O
verification	B-Task
and	O
clustering	B-Task
can	O
be	O
easily	O
implemented	O
using	O
standard	O
techniques	O
with	O
FaceNet	B-Method
embeddings	O
as	O
feature	O
vectors	O
.	O
	
Our	O
method	O
uses	O
a	O
deep	O
convolutional	B-Method
network	O
trained	O
to	O
directly	O
optimize	O
the	O
embedding	O
itself	O
,	O
rather	O
than	O
an	O
intermediate	B-Method
bottleneck	I-Method
layer	I-Method
as	O
in	O
previous	O
deep	B-Method
learning	I-Method
approaches	I-Method
.	O
	
To	O
train	O
,	O
we	O
use	O
triplets	O
of	O
roughly	O
aligned	O
matching	O
/	O
non	O
-	O
matching	O
face	O
patches	O
generated	O
using	O
a	O
novel	O
online	B-Method
triplet	I-Method
mining	I-Method
method	I-Method
.	O
	
The	O
benefit	O
of	O
our	O
approach	O
is	O
much	O
greater	O
representational	B-Metric
efficiency	I-Metric
:	O
we	O
achieve	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
face	O
recognition	B-Task
performance	O
using	O
only	O
128	O
-	O
bytes	O
per	O
face	O
.	O
	
On	O
the	O
widely	O
used	O
Labeled	B-Material
Faces	I-Material
in	I-Material
the	I-Material
Wild	I-Material
(	O
LFW	B-Material
)	O
dataset	O
,	O
our	O
system	O
achieves	O
a	O
new	O
record	B-Metric
accuracy	I-Metric
of	O
99.63	O
%	O
.	O
	
On	O
YouTube	B-Material
Faces	I-Material
DB	I-Material
it	O
achieves	O
95.12	O
%	O
.	O
	
Our	O
system	O
cuts	O
the	O
error	B-Metric
rate	I-Metric
in	O
comparison	O
to	O
the	O
best	O
published	O
result	O
by	O
30	O
%	O
on	O
both	O
datasets	O
.	O
	
We	O
also	O
introduce	O
the	O
concept	O
of	O
harmonic	B-Method
embeddings	I-Method
,	O
and	O
a	O
harmonic	O
triplet	O
loss	O
,	O
which	O
describe	O
different	O
versions	O
of	O
face	O
embeddings	O
(	O
produced	O
by	O
different	O
networks	O
)	O
that	O
are	O
compatible	O
to	O
each	O
other	O
and	O
allow	O
for	O
direct	O
comparison	O
between	O
each	O
other	O
.	O
	
section	O
:	O
Introduction	O
	
In	O
this	O
paper	O
we	O
present	O
a	O
unified	O
system	O
for	O
face	B-Task
verification	I-Task
(	O
is	O
this	O
the	O
same	O
person	O
)	O
,	O
recognition	B-Task
(	O
who	O
is	O
this	O
person	O
)	O
and	O
clustering	B-Task
(	O
find	O
common	O
people	O
among	O
these	O
faces	O
)	O
.	O
	
Our	O
method	O
is	O
based	O
on	O
learning	O
a	O
Euclidean	B-Method
embedding	I-Method
per	I-Method
image	I-Method
using	O
a	O
deep	O
convolutional	B-Method
network	O
.	O
	
The	O
network	O
is	O
trained	O
such	O
that	O
the	O
squared	O
L2	O
distances	O
in	O
the	O
embedding	O
space	O
directly	O
correspond	O
to	O
face	O
similarity	O
:	O
faces	O
of	O
the	O
same	O
person	O
have	O
small	O
distances	O
and	O
faces	O
of	O
distinct	O
people	O
have	O
large	O
distances	O
.	O
	
Once	O
this	O
embedding	O
has	O
been	O
produced	O
,	O
then	O
the	O
aforementioned	O
tasks	O
become	O
straight	O
-	O
forward	O
:	O
face	B-Task
verification	I-Task
simply	O
involves	O
thresholding	O
the	O
distance	O
between	O
the	O
two	O
embeddings	O
;	O
recognition	B-Task
becomes	O
a	O
k	B-Task
-	I-Task
NN	I-Task
classification	I-Task
problem	I-Task
;	O
and	O
clustering	B-Method
can	O
be	O
achieved	O
using	O
off	B-Method
-	I-Method
the	I-Method
-	I-Method
shelf	I-Method
techniques	I-Method
such	O
as	O
k	B-Method
-	I-Method
means	I-Method
or	O
agglomerative	B-Method
clustering	I-Method
.	O
	
Previous	O
face	O
recognition	B-Task
approaches	O
based	O
on	O
deep	B-Method
networks	I-Method
use	O
a	O
classification	B-Method
layer	I-Method
trained	O
over	O
a	O
set	O
of	O
known	O
face	O
identities	O
and	O
then	O
take	O
an	O
intermediate	B-Method
bottleneck	I-Method
layer	I-Method
as	O
a	O
representation	O
used	O
to	O
generalize	O
recognition	B-Task
beyond	O
the	O
set	O
of	O
identities	O
used	O
in	O
training	O
.	O
	
The	O
downsides	O
of	O
this	O
approach	O
are	O
its	O
indirectness	O
and	O
its	O
inefficiency	O
:	O
one	O
has	O
to	O
hope	O
that	O
the	O
bottleneck	B-Method
representation	I-Method
generalizes	O
well	O
to	O
new	O
faces	O
;	O
and	O
by	O
using	O
a	O
bottleneck	B-Method
layer	I-Method
the	O
representation	O
size	O
per	O
face	O
is	O
usually	O
very	O
large	O
(	O
1000s	O
of	O
dimensions	O
)	O
.	O
	
Some	O
recent	O
work	O
has	O
reduced	O
this	O
dimensionality	O
using	O
PCA	B-Method
,	O
but	O
this	O
is	O
a	O
linear	B-Method
transformation	I-Method
that	O
can	O
be	O
easily	O
learnt	O
in	O
one	O
layer	O
of	O
the	O
network	O
.	O
	
In	O
contrast	O
to	O
these	O
approaches	O
,	O
FaceNet	B-Method
directly	O
trains	O
its	O
output	O
to	O
be	O
a	O
compact	O
128	B-Method
-	I-Method
D	I-Method
embedding	I-Method
using	O
a	O
triplet	B-Method
-	I-Method
based	I-Method
loss	I-Method
function	I-Method
based	O
on	O
LMNN	B-Method
.	O
	
Our	O
triplets	O
consist	O
of	O
two	O
matching	O
face	O
thumbnails	O
and	O
a	O
non	O
-	O
matching	O
face	O
thumbnail	O
and	O
the	O
loss	O
aims	O
to	O
separate	O
the	O
positive	O
pair	O
from	O
the	O
negative	O
by	O
a	O
distance	O
margin	O
.	O
	
The	O
thumbnails	O
are	O
tight	O
crops	O
of	O
the	O
face	O
area	O
,	O
no	O
2D	O
or	O
3D	O
alignment	O
,	O
other	O
than	O
scale	O
and	O
translation	O
is	O
performed	O
.	O
	
Choosing	O
which	O
triplets	O
to	O
use	O
turns	O
out	O
to	O
be	O
very	O
important	O
for	O
achieving	O
good	O
performance	O
and	O
,	O
inspired	O
by	O
curriculum	B-Method
learning	I-Method
,	O
we	O
present	O
a	O
novel	O
online	B-Method
negative	I-Method
exemplar	I-Method
mining	I-Method
strategy	I-Method
which	O
ensures	O
consistently	O
increasing	O
difficulty	O
of	O
triplets	O
as	O
the	O
network	O
trains	O
.	O
	
To	O
improve	O
clustering	B-Metric
accuracy	I-Metric
,	O
we	O
also	O
explore	O
hard	B-Method
-	I-Method
positive	I-Method
mining	I-Method
techniques	I-Method
which	O
encourage	O
spherical	O
clusters	O
for	O
the	O
embeddings	O
of	O
a	O
single	O
person	O
.	O
	
As	O
an	O
illustration	O
of	O
the	O
incredible	O
variability	O
that	O
our	O
method	O
can	O
handle	O
see	O
Figure	O
[	O
reference	O
]	O
.	O
	
Shown	O
are	O
image	O
pairs	O
from	O
PIE	O
that	O
previously	O
were	O
considered	O
to	O
be	O
very	O
difficult	O
for	O
face	B-Task
verification	I-Task
systems	O
.	O
	
An	O
overview	O
of	O
the	O
rest	O
of	O
the	O
paper	O
is	O
as	O
follows	O
:	O
	
in	O
section	O
[	O
reference	O
]	O
we	O
review	O
the	O
literature	O
in	O
this	O
area	O
;	O
section	O
[	O
reference	O
]	O
defines	O
the	O
triplet	O
loss	O
and	O
section	O
[	O
reference	O
]	O
describes	O
our	O
novel	O
triplet	B-Method
selection	I-Method
and	O
training	B-Method
procedure	I-Method
;	O
in	O
section	O
[	O
reference	O
]	O
we	O
describe	O
the	O
model	O
architecture	O
used	O
.	O
	
Finally	O
in	O
section	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
we	O
present	O
some	O
quantitative	O
results	O
of	O
our	O
embeddings	O
and	O
also	O
qualitatively	O
explore	O
some	O
clustering	B-Task
results	O
.	O
	
section	O
:	O
Related	O
Work	O
	
Similarly	O
to	O
other	O
recent	O
works	O
which	O
employ	O
deep	B-Method
networks	I-Method
,	O
our	O
approach	O
is	O
a	O
purely	O
data	B-Method
driven	I-Method
method	I-Method
which	O
learns	O
its	O
representation	O
directly	O
from	O
the	O
pixels	O
of	O
the	O
face	O
.	O
	
Rather	O
than	O
using	O
engineered	O
features	O
,	O
we	O
use	O
a	O
large	O
dataset	O
of	O
labelled	O
faces	O
to	O
attain	O
the	O
appropriate	O
invariances	O
to	O
pose	O
,	O
illumination	O
,	O
and	O
other	O
variational	O
conditions	O
.	O
	
In	O
this	O
paper	O
we	O
explore	O
two	O
different	O
deep	B-Method
network	I-Method
architectures	I-Method
that	O
have	O
been	O
recently	O
used	O
to	O
great	O
success	O
in	O
the	O
computer	B-Task
vision	I-Task
community	I-Task
.	O
	
Both	O
are	O
deep	O
convolutional	B-Method
networks	O
.	O
	
The	O
first	O
architecture	O
is	O
based	O
on	O
the	O
Zeiler	B-Method
&	I-Method
Fergus	I-Method
model	I-Method
which	O
consists	O
of	O
multiple	O
interleaved	B-Method
layers	I-Method
of	I-Method
convolutions	I-Method
,	O
non	O
-	O
linear	O
activations	O
,	O
local	B-Method
response	I-Method
normalizations	I-Method
,	O
and	O
max	O
pooling	B-Method
layers	I-Method
.	O
	
We	O
additionally	O
add	O
several	O
convolution	B-Method
layers	I-Method
inspired	O
by	O
the	O
work	O
of	O
.	O
	
The	O
second	O
architecture	O
is	O
based	O
on	O
the	O
Inception	B-Method
model	I-Method
of	O
Szegedy	B-Method
which	O
was	O
recently	O
used	O
as	O
the	O
winning	O
approach	O
for	O
ImageNet	B-Task
2014	I-Task
.	O
	
These	O
networks	O
use	O
mixed	B-Method
layers	I-Method
that	O
run	O
several	O
different	O
convolutional	B-Method
and	O
pooling	B-Method
layers	I-Method
in	O
parallel	O
and	O
concatenate	O
their	O
responses	O
.	O
	
We	O
have	O
found	O
that	O
these	O
models	O
can	O
reduce	O
the	O
number	O
of	O
parameters	O
by	O
up	O
to	O
20	O
times	O
and	O
have	O
the	O
potential	O
to	O
reduce	O
the	O
number	O
of	O
FLOPS	O
required	O
for	O
comparable	O
performance	O
.	O
	
There	O
is	O
a	O
vast	O
corpus	O
of	O
face	B-Task
verification	I-Task
and	O
recognition	B-Task
works	O
.	O
	
Reviewing	O
it	O
is	O
out	O
of	O
the	O
scope	O
of	O
this	O
paper	O
so	O
we	O
will	O
only	O
briefly	O
discuss	O
the	O
most	O
relevant	O
recent	O
work	O
.	O
	
The	O
works	O
of	O
all	O
employ	O
a	O
complex	O
system	O
of	O
multiple	O
stages	O
,	O
that	O
combines	O
the	O
output	O
of	O
a	O
deep	O
convolutional	B-Method
network	O
with	O
PCA	B-Method
for	O
dimensionality	B-Task
reduction	I-Task
and	O
an	O
SVM	B-Method
for	O
classification	B-Task
.	O
	
Zhenyao	O
employ	O
a	O
deep	B-Method
network	I-Method
to	O
‘	O
‘	O
warp	O
’	O
’	O
faces	O
into	O
a	O
canonical	O
frontal	O
view	O
and	O
then	O
learn	O
CNN	B-Method
that	O
classifies	O
each	O
face	O
as	O
belonging	O
to	O
a	O
known	O
identity	O
.	O
	
For	O
face	B-Task
verification	I-Task
,	O
PCA	B-Method
on	O
the	O
network	O
output	O
in	O
conjunction	O
with	O
an	O
ensemble	B-Method
of	I-Method
SVMs	I-Method
is	O
used	O
.	O
	
Taigman	B-Method
propose	O
a	O
multi	B-Method
-	I-Method
stage	I-Method
approach	I-Method
that	O
aligns	O
faces	O
to	O
a	O
general	O
3D	B-Method
shape	I-Method
model	I-Method
.	O
	
A	O
multi	B-Method
-	I-Method
class	I-Method
network	I-Method
is	O
trained	O
to	O
perform	O
the	O
face	O
recognition	B-Task
task	O
on	O
over	O
four	O
thousand	O
identities	O
.	O
	
The	O
authors	O
also	O
experimented	O
with	O
a	O
so	O
called	O
Siamese	B-Method
network	I-Method
where	O
they	O
directly	O
optimize	O
the	O
-	O
distance	O
between	O
two	O
face	O
features	O
.	O
	
Their	O
best	O
performance	O
on	O
LFW	B-Material
(	O
)	O
stems	O
from	O
an	O
ensemble	B-Method
of	I-Method
three	I-Method
networks	I-Method
using	O
different	O
alignments	O
and	O
color	O
channels	O
.	O
	
The	O
predicted	O
distances	O
(	O
non	B-Method
-	I-Method
linear	I-Method
SVM	I-Method
predictions	I-Method
based	O
on	O
the	O
kernel	O
)	O
of	O
those	O
networks	O
are	O
combined	O
using	O
a	O
non	B-Method
-	I-Method
linear	I-Method
SVM	I-Method
.	O
	
Sun	O
propose	O
a	O
compact	O
and	O
therefore	O
relatively	O
cheap	O
to	O
compute	B-Method
network	I-Method
.	O
	
They	O
use	O
an	O
ensemble	O
of	O
25	O
of	O
these	O
network	O
,	O
each	O
operating	O
on	O
a	O
different	O
face	O
patch	O
.	O
	
For	O
their	O
final	O
performance	O
on	O
LFW	B-Material
(	O
)	O
the	O
authors	O
combine	O
50	O
responses	O
(	O
regular	O
and	O
flipped	O
)	O
.	O
	
Both	O
PCA	B-Method
and	O
a	O
Joint	B-Method
Bayesian	I-Method
model	I-Method
that	O
effectively	O
correspond	O
to	O
a	O
linear	B-Method
transform	I-Method
in	O
the	O
embedding	O
space	O
are	O
employed	O
.	O
	
Their	O
method	O
does	O
not	O
require	O
explicit	O
2D	O
/	O
3D	O
alignment	O
.	O
	
The	O
networks	O
are	O
trained	O
by	O
using	O
a	O
combination	O
of	O
classification	B-Metric
and	I-Metric
verification	I-Metric
loss	I-Metric
.	O
	
The	O
verification	B-Task
loss	I-Task
is	O
similar	O
to	O
the	O
triplet	O
loss	O
we	O
employ	O
,	O
in	O
that	O
it	O
minimizes	O
the	O
-	O
distance	O
between	O
faces	O
of	O
the	O
same	O
identity	O
and	O
enforces	O
a	O
margin	O
between	O
the	O
distance	O
of	O
faces	O
of	O
different	O
identities	O
.	O
	
The	O
main	O
difference	O
is	O
that	O
only	O
pairs	O
of	O
images	O
are	O
compared	O
,	O
whereas	O
the	O
triplet	O
loss	O
encourages	O
a	O
relative	O
distance	O
constraint	O
.	O
	
A	O
similar	O
loss	O
to	O
the	O
one	O
used	O
here	O
was	O
explored	O
in	O
Wang	O
for	O
ranking	B-Task
images	I-Task
by	O
semantic	O
and	O
visual	O
similarity	O
.	O
	
section	O
:	O
Method	O
	
FaceNet	B-Method
uses	O
a	O
deep	O
convolutional	B-Method
network	O
.	O
	
We	O
discuss	O
two	O
different	O
core	O
architectures	O
:	O
The	O
Zeiler	B-Method
&	I-Method
Fergus	I-Method
style	I-Method
networks	I-Method
and	O
the	O
recent	O
Inception	B-Method
type	I-Method
networks	I-Method
.	O
	
The	O
details	O
of	O
these	O
networks	O
are	O
described	O
in	O
section	O
[	O
reference	O
]	O
.	O
	
Given	O
the	O
model	O
details	O
,	O
and	O
treating	O
it	O
as	O
a	O
black	O
box	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
,	O
the	O
most	O
important	O
part	O
of	O
our	O
approach	O
lies	O
in	O
the	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
learning	I-Task
of	O
the	O
whole	O
system	O
.	O
	
To	O
this	O
end	O
we	O
employ	O
the	O
triplet	O
loss	O
that	O
directly	O
reflects	O
what	O
we	O
want	O
to	O
achieve	O
in	O
face	B-Task
verification	I-Task
,	O
recognition	B-Task
and	O
clustering	B-Task
.	O
	
Namely	O
,	O
we	O
strive	O
for	O
an	O
embedding	B-Task
,	O
from	O
an	O
image	O
into	O
a	O
feature	O
space	O
,	O
such	O
that	O
the	O
squared	O
distance	O
between	O
all	O
faces	O
,	O
independent	O
of	O
imaging	O
conditions	O
,	O
of	O
the	O
same	O
identity	O
is	O
small	O
,	O
whereas	O
the	O
squared	O
distance	O
between	O
a	O
pair	O
of	O
face	O
images	O
from	O
different	O
identities	O
is	O
large	O
.	O
	
Although	O
we	O
did	O
not	O
directly	O
compare	O
to	O
other	O
losses	O
,	O
the	O
one	O
using	O
pairs	O
of	O
positives	O
and	O
negatives	O
,	O
as	O
used	O
in	O
Eq	O
.	O
	
(	O
2	O
)	O
,	O
we	O
believe	O
that	O
the	O
triplet	B-Method
loss	I-Method
is	O
more	O
suitable	O
for	O
face	B-Task
verification	I-Task
.	O
	
The	O
motivation	O
is	O
that	O
the	O
loss	O
from	O
encourages	O
all	O
faces	O
of	O
one	O
identity	O
to	O
be	O
projected	O
onto	O
a	O
single	O
point	O
in	O
the	O
embedding	O
space	O
.	O
	
The	O
triplet	O
loss	O
,	O
however	O
,	O
tries	O
to	O
enforce	O
a	O
margin	O
between	O
each	O
pair	O
of	O
faces	O
from	O
one	O
person	O
to	O
all	O
other	O
faces	O
.	O
	
This	O
allows	O
the	O
faces	O
for	O
one	O
identity	O
to	O
live	O
on	O
a	O
manifold	O
,	O
while	O
still	O
enforcing	O
the	O
distance	O
and	O
thus	O
discriminability	O
to	O
other	O
identities	O
.	O
	
The	O
following	O
section	O
describes	O
this	O
triplet	O
loss	O
and	O
how	O
it	O
can	O
be	O
learned	O
efficiently	O
at	O
scale	O
.	O
	
subsection	O
:	O
Triplet	B-Method
Loss	I-Method
	
The	O
embedding	B-Task
is	O
represented	O
by	O
.	O
	
It	O
embeds	O
an	O
image	O
into	O
a	O
-	O
dimensional	O
Euclidean	O
space	O
.	O
	
Additionally	O
,	O
we	O
constrain	O
this	O
embedding	O
to	O
live	O
on	O
the	O
-	O
dimensional	O
hypersphere	O
,	O
.	O
	
This	O
loss	O
is	O
motivated	O
in	O
in	O
the	O
context	O
of	O
nearest	B-Task
-	I-Task
neighbor	I-Task
classification	I-Task
.	O
	
Here	O
we	O
want	O
to	O
ensure	O
that	O
an	O
image	O
(	O
anchor	O
)	O
of	O
a	O
specific	O
person	O
is	O
closer	O
to	O
all	O
other	O
images	O
(	O
positive	O
)	O
of	O
the	O
same	O
person	O
than	O
it	O
is	O
to	O
any	O
image	O
(	O
negative	O
)	O
of	O
any	O
other	O
person	O
.	O
	
This	O
is	O
visualized	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Thus	O
we	O
want	O
,	O
where	O
is	O
a	O
margin	O
that	O
is	O
enforced	O
between	O
positive	O
and	O
negative	O
pairs	O
.	O
	
is	O
the	O
set	O
of	O
all	O
possible	O
triplets	O
in	O
the	O
training	O
set	O
and	O
has	O
cardinality	O
.	O
	
The	O
loss	O
that	O
is	O
being	O
minimized	O
is	O
then	O
Generating	O
all	O
possible	O
triplets	O
would	O
result	O
in	O
many	O
triplets	O
that	O
are	O
easily	O
satisfied	O
(	O
fulfill	O
the	O
constraint	O
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
)	O
.	O
	
These	O
triplets	O
would	O
not	O
contribute	O
to	O
the	O
training	B-Task
and	O
result	O
in	O
slower	O
convergence	B-Metric
,	O
as	O
they	O
would	O
still	O
be	O
passed	O
through	O
the	O
network	O
.	O
	
It	O
is	O
crucial	O
to	O
select	O
hard	O
triplets	O
,	O
that	O
are	O
active	O
and	O
can	O
therefore	O
contribute	O
to	O
improving	O
the	O
model	O
.	O
	
The	O
following	O
section	O
talks	O
about	O
the	O
different	O
approaches	O
we	O
use	O
for	O
the	O
triplet	B-Task
selection	I-Task
.	O
	
subsection	O
:	O
Triplet	B-Method
Selection	I-Method
	
In	O
order	O
to	O
ensure	O
fast	O
convergence	O
it	O
is	O
crucial	O
to	O
select	O
triplets	O
that	O
violate	O
the	O
triplet	O
constraint	O
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
	
This	O
means	O
that	O
,	O
given	O
,	O
we	O
want	O
to	O
select	O
an	O
(	O
hard	O
positive	O
)	O
such	O
that	O
and	O
similarly	O
(	O
hard	O
negative	O
)	O
such	O
that	O
.	O
	
It	O
is	O
infeasible	O
to	O
compute	O
the	O
and	O
across	O
the	O
whole	O
training	O
set	O
.	O
	
Additionally	O
,	O
it	O
might	O
lead	O
to	O
poor	O
training	B-Task
,	O
as	O
mislabelled	O
and	O
poorly	O
imaged	O
faces	O
would	O
dominate	O
the	O
hard	O
positives	O
and	O
negatives	O
.	O
	
There	O
are	O
two	O
obvious	O
choices	O
that	O
avoid	O
this	O
issue	O
:	O
	
Generate	O
triplets	O
offline	O
every	O
n	O
steps	O
,	O
using	O
the	O
most	O
recent	O
network	O
checkpoint	O
and	O
computing	O
the	O
and	O
on	O
a	O
subset	O
of	O
the	O
data	O
.	O
	
Generate	O
triplets	O
online	O
.	O
	
This	O
can	O
be	O
done	O
by	O
selecting	O
the	O
hard	O
positive	O
/	O
negative	O
exemplars	O
from	O
within	O
a	O
mini	O
-	O
batch	O
.	O
	
Here	O
,	O
we	O
focus	O
on	O
the	O
online	B-Task
generation	I-Task
and	O
use	O
large	O
mini	O
-	O
batches	O
in	O
the	O
order	O
of	O
a	O
few	O
thousand	O
exemplars	O
and	O
only	O
compute	O
the	O
and	O
within	O
a	O
mini	O
-	O
batch	O
.	O
	
To	O
have	O
a	O
meaningful	O
representation	O
of	O
the	O
anchor	O
-	O
positive	O
distances	O
,	O
it	O
needs	O
to	O
be	O
ensured	O
that	O
a	O
minimal	O
number	O
of	O
exemplars	O
of	O
any	O
one	O
identity	O
is	O
present	O
in	O
each	O
mini	O
-	O
batch	O
.	O
	
In	O
our	O
experiments	O
we	O
sample	O
the	O
training	O
data	O
such	O
that	O
around	O
40	O
faces	O
are	O
selected	O
per	O
identity	O
per	O
mini	O
-	O
batch	O
.	O
	
Additionally	O
,	O
randomly	O
sampled	O
negative	O
faces	O
are	O
added	O
to	O
each	O
mini	O
-	O
batch	O
.	O
	
Instead	O
of	O
picking	O
the	O
hardest	O
positive	O
,	O
we	O
use	O
all	O
anchor	O
-	O
positive	O
pairs	O
in	O
a	O
mini	O
-	O
batch	O
while	O
still	O
selecting	O
the	O
hard	O
negatives	O
.	O
	
We	O
do	O
n’t	O
have	O
a	O
side	O
-	O
by	O
-	O
side	O
comparison	O
of	O
hard	O
anchor	O
-	O
positive	O
pairs	O
versus	O
all	O
anchor	O
-	O
positive	O
pairs	O
within	O
a	O
mini	O
-	O
batch	O
,	O
but	O
we	O
found	O
in	O
practice	O
that	O
the	O
all	O
anchor	B-Method
-	I-Method
positive	I-Method
method	I-Method
was	O
more	O
stable	O
and	O
converged	O
slightly	O
faster	O
at	O
the	O
beginning	O
of	O
training	O
.	O
	
We	O
also	O
explored	O
the	O
offline	B-Task
generation	I-Task
of	I-Task
triplets	I-Task
in	O
conjunction	O
with	O
the	O
online	B-Method
generation	I-Method
and	O
it	O
may	O
allow	O
the	O
use	O
of	O
smaller	O
batch	O
sizes	O
,	O
but	O
the	O
experiments	O
were	O
inconclusive	O
.	O
	
Selecting	O
the	O
hardest	O
negatives	O
can	O
in	O
practice	O
lead	O
to	O
bad	O
local	O
minima	O
early	O
on	O
in	O
training	B-Task
,	O
specifically	O
it	O
can	O
result	O
in	O
a	O
collapsed	B-Method
model	I-Method
(	O
)	O
.	O
	
In	O
order	O
to	O
mitigate	O
this	O
,	O
it	O
helps	O
to	O
select	O
such	O
that	O
We	O
call	O
these	O
negative	O
exemplars	O
semi	O
-	O
hard	O
,	O
as	O
they	O
are	O
further	O
away	O
from	O
the	O
anchor	O
than	O
the	O
positive	O
exemplar	O
,	O
but	O
still	O
hard	O
because	O
the	O
squared	O
distance	O
is	O
close	O
to	O
the	O
anchor	O
-	O
positive	O
distance	O
.	O
	
Those	O
negatives	O
lie	O
inside	O
the	O
margin	O
.	O
	
As	O
mentioned	O
before	O
,	O
correct	O
triplet	B-Task
selection	I-Task
is	O
crucial	O
for	O
fast	B-Task
convergence	I-Task
.	O
	
On	O
the	O
one	O
hand	O
we	O
would	O
like	O
to	O
use	O
small	O
mini	O
-	O
batches	O
as	O
these	O
tend	O
to	O
improve	O
convergence	B-Metric
during	O
Stochastic	B-Method
Gradient	I-Method
Descent	I-Method
(	O
SGD	B-Method
)	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
implementation	O
details	O
make	O
batches	O
of	O
tens	O
to	O
hundreds	O
of	O
exemplars	O
more	O
efficient	O
.	O
	
The	O
main	O
constraint	O
with	O
regards	O
to	O
the	O
batch	O
size	O
,	O
however	O
,	O
is	O
the	O
way	O
we	O
select	O
hard	O
relevant	O
triplets	O
from	O
within	O
the	O
mini	O
-	O
batches	O
.	O
	
In	O
most	O
experiments	O
we	O
use	O
a	O
batch	O
size	O
of	O
around	O
1	O
,	O
800	O
exemplars	O
.	O
	
subsection	O
:	O
Deep	B-Method
Convolutional	I-Method
Networks	I-Method
	
In	O
all	O
our	O
experiments	O
we	O
train	O
the	O
CNN	B-Method
using	O
Stochastic	B-Method
Gradient	I-Method
Descent	I-Method
(	O
SGD	B-Method
)	O
with	O
standard	O
backprop	B-Method
and	O
AdaGrad	B-Method
.	O
	
In	O
most	O
experiments	O
we	O
start	O
with	O
a	O
learning	B-Metric
rate	I-Metric
of	O
which	O
we	O
lower	O
to	O
finalize	O
the	O
model	O
.	O
	
The	O
models	O
are	O
initialized	O
from	O
random	O
,	O
similar	O
to	O
,	O
and	O
trained	O
on	O
a	O
CPU	O
cluster	O
for	O
1	O
,	O
000	O
to	O
2	O
,	O
000	O
hours	O
.	O
	
The	O
decrease	O
in	O
the	O
loss	B-Metric
(	O
and	O
increase	O
in	O
accuracy	B-Metric
)	O
slows	O
down	O
drastically	O
after	O
500h	O
of	O
training	B-Task
,	O
but	O
additional	O
training	B-Method
can	O
still	O
significantly	O
improve	O
performance	O
.	O
	
The	O
margin	O
is	O
set	O
to	O
.	O
	
We	O
used	O
two	O
types	O
of	O
architectures	O
and	O
explore	O
their	O
trade	O
-	O
offs	O
in	O
more	O
detail	O
in	O
the	O
experimental	O
section	O
.	O
	
Their	O
practical	O
differences	O
lie	O
in	O
the	O
difference	O
of	O
parameters	O
and	O
FLOPS	O
.	O
	
The	O
best	O
model	O
may	O
be	O
different	O
depending	O
on	O
the	O
application	O
.	O
	
a	O
model	O
running	O
in	O
a	O
datacenter	O
can	O
have	O
many	O
parameters	O
and	O
require	O
a	O
large	O
number	O
of	O
FLOPS	O
,	O
whereas	O
a	O
model	O
running	O
on	O
a	O
mobile	O
phone	O
needs	O
to	O
have	O
few	O
parameters	O
,	O
so	O
that	O
it	O
can	O
fit	O
into	O
memory	O
.	O
	
All	O
our	O
models	O
use	O
rectified	B-Method
linear	I-Method
units	I-Method
as	O
the	O
non	B-Method
-	I-Method
linear	I-Method
activation	I-Method
function	I-Method
.	O
	
The	O
first	O
category	O
,	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
,	O
adds	O
convolutional	B-Method
layers	O
,	O
as	O
suggested	O
in	O
,	O
between	O
the	O
standard	O
convolutional	B-Method
layers	O
of	O
the	O
Zeiler	B-Method
&	I-Method
Fergus	I-Method
architecture	I-Method
and	O
results	O
in	O
a	O
model	O
22	O
layers	O
deep	O
.	O
	
It	O
has	O
a	O
total	O
of	O
140	O
million	O
parameters	O
and	O
requires	O
around	O
1.6	O
billion	O
FLOPS	O
per	O
image	O
.	O
	
The	O
second	O
category	O
we	O
use	O
is	O
based	O
on	O
GoogLeNet	B-Method
style	I-Method
Inception	I-Method
models	I-Method
.	O
	
These	O
models	O
have	O
fewer	O
parameters	O
(	O
around	O
6.6M	O
-	O
7.5	O
M	O
)	O
and	O
up	O
to	O
fewer	O
FLOPS	O
(	O
between	O
500M	O
-	O
1.6B	O
)	O
.	O
	
Some	O
of	O
these	O
models	O
are	O
dramatically	O
reduced	O
in	O
size	O
(	O
both	O
depth	O
and	O
number	O
of	O
filters	O
)	O
,	O
so	O
that	O
they	O
can	O
be	O
run	O
on	O
a	O
mobile	O
phone	O
.	O
	
One	O
,	O
NNS1	B-Method
,	O
has	O
26	O
M	O
parameters	O
and	O
only	O
requires	O
220	O
M	O
FLOPS	O
per	O
image	O
.	O
	
The	O
other	O
,	O
NNS2	B-Method
,	O
has	O
4.3	O
M	O
parameters	O
and	O
20	O
M	O
FLOPS	O
.	O
	
Table	O
[	O
reference	O
]	O
describes	O
NN2	B-Method
our	O
largest	O
network	O
in	O
detail	O
.	O
	
NN3	B-Method
is	O
identical	O
in	O
architecture	O
but	O
has	O
a	O
reduced	O
input	O
size	O
of	O
160x160	O
.	O
	
NN4	B-Method
has	O
an	O
input	O
size	O
of	O
only	O
96x96	O
,	O
thereby	O
drastically	O
reducing	O
the	O
CPU	B-Metric
requirements	I-Metric
(	O
285	O
M	O
FLOPS	O
vs	O
1.6B	O
for	O
NN2	B-Method
)	O
.	O
	
In	O
addition	O
to	O
the	O
reduced	O
input	O
size	O
it	O
does	O
not	O
use	O
5x5	O
convolutions	B-Method
in	O
the	O
higher	O
layers	O
as	O
the	O
receptive	O
field	O
is	O
already	O
too	O
small	O
by	O
then	O
.	O
	
Generally	O
we	O
found	O
that	O
the	O
5x5	O
convolutions	O
can	O
be	O
removed	O
throughout	O
with	O
only	O
a	O
minor	O
drop	O
in	O
accuracy	B-Metric
.	O
	
Figure	O
[	O
reference	O
]	O
compares	O
all	O
our	O
models	O
.	O
	
section	O
:	O
Datasets	O
and	O
Evaluation	O
	
We	O
evaluate	O
our	O
method	O
on	O
four	O
datasets	O
and	O
with	O
the	O
exception	O
of	O
Labelled	B-Material
Faces	I-Material
in	I-Material
the	I-Material
Wild	I-Material
and	O
YouTube	B-Material
Faces	I-Material
we	O
evaluate	O
our	O
method	O
on	O
the	O
face	B-Task
verification	I-Task
task	O
.	O
	
given	O
a	O
pair	O
of	O
two	O
face	O
images	O
a	O
squared	O
distance	O
threshold	O
is	O
used	O
to	O
determine	O
the	O
classification	O
of	O
same	O
and	O
different	O
.	O
	
All	O
faces	O
pairs	O
of	O
the	O
same	O
identity	O
are	O
denoted	O
with	O
,	O
whereas	O
all	O
pairs	O
of	O
different	O
identities	O
are	O
denoted	O
with	O
.	O
	
We	O
define	O
the	O
set	O
of	O
all	O
true	O
accepts	O
as	O
These	O
are	O
the	O
face	O
pairs	O
that	O
were	O
correctly	O
classified	O
as	O
same	O
at	O
threshold	O
.	O
	
Similarly	O
is	O
the	O
set	O
of	O
all	O
pairs	O
that	O
was	O
incorrectly	O
classified	O
as	O
same	O
(	O
false	O
accept	O
)	O
.	O
	
The	O
validation	B-Metric
rate	I-Metric
and	O
the	O
false	B-Metric
accept	I-Metric
rate	I-Metric
for	O
a	O
given	O
face	O
distance	O
are	O
then	O
defined	O
as	O
	
subsection	O
:	O
Hold	O
-	O
out	O
Test	O
Set	O
	
We	O
keep	O
a	O
hold	O
out	O
set	O
of	O
around	O
one	O
million	O
images	O
,	O
that	O
has	O
the	O
same	O
distribution	O
as	O
our	O
training	O
set	O
,	O
but	O
disjoint	O
identities	O
.	O
	
For	O
evaluation	O
we	O
split	O
it	O
into	O
five	O
disjoint	O
sets	O
of	O
images	O
each	O
.	O
	
The	O
and	B-Metric
rate	I-Metric
are	O
then	O
computed	O
on	O
image	O
pairs	O
.	O
	
Standard	B-Metric
error	I-Metric
is	O
reported	O
across	O
the	O
five	O
splits	O
.	O
	
subsection	O
:	O
Personal	O
Photos	O
	
This	O
is	O
a	O
test	O
set	O
with	O
similar	O
distribution	O
to	O
our	O
training	O
set	O
,	O
but	O
has	O
been	O
manually	O
verified	O
to	O
have	O
very	O
clean	O
labels	O
.	O
	
It	O
consists	O
of	O
three	O
personal	O
photo	O
collections	O
with	O
a	O
total	O
of	O
around	O
images	O
.	O
	
We	O
compute	O
the	O
and	B-Metric
rate	I-Metric
across	O
all	O
12k	O
squared	O
pairs	O
of	O
images	O
.	O
	
subsection	O
:	O
Academic	O
Datasets	O
	
Labeled	B-Material
Faces	I-Material
in	I-Material
the	I-Material
Wild	I-Material
(	O
LFW	B-Material
)	O
is	O
the	O
de	O
-	O
facto	O
academic	O
test	O
set	O
for	O
face	B-Task
verification	I-Task
.	O
	
We	O
follow	O
the	O
standard	O
protocol	O
for	O
unrestricted	O
,	O
labeled	O
outside	O
data	O
and	O
report	O
the	O
mean	B-Metric
classification	I-Metric
accuracy	I-Metric
as	O
well	O
as	O
the	O
standard	B-Metric
error	I-Metric
of	O
the	O
mean	O
.	O
	
Youtube	B-Material
Faces	I-Material
DB	I-Material
is	O
a	O
new	O
dataset	O
that	O
has	O
gained	O
popularity	O
in	O
the	O
face	O
recognition	B-Task
community	O
.	O
	
The	O
setup	O
is	O
similar	O
to	O
LFW	B-Material
,	O
but	O
instead	O
of	O
verifying	O
pairs	O
of	O
images	O
,	O
pairs	O
of	O
videos	O
are	O
used	O
.	O
	
section	O
:	O
Experiments	O
	
If	O
not	O
mentioned	O
otherwise	O
we	O
use	O
between	O
100M	O
-	O
200	O
M	O
training	O
face	O
thumbnails	O
consisting	O
of	O
about	O
8	O
M	O
different	O
identities	O
.	O
	
A	O
face	B-Method
detector	I-Method
is	O
run	O
on	O
each	O
image	O
and	O
a	O
tight	O
bounding	O
box	O
around	O
each	O
face	O
is	O
generated	O
.	O
	
These	O
face	O
thumbnails	O
are	O
resized	O
to	O
the	O
input	O
size	O
of	O
the	O
respective	O
network	O
.	O
	
Input	O
sizes	O
range	O
from	O
96x96	O
pixels	O
to	O
224x224	O
pixels	O
in	O
our	O
experiments	O
.	O
	
subsection	O
:	O
Computation	B-Metric
Accuracy	I-Metric
Trade	I-Metric
-	O
off	O
	
Before	O
diving	O
into	O
the	O
details	O
of	O
more	O
specific	O
experiments	O
we	O
will	O
discuss	O
the	O
trade	O
-	O
off	O
of	O
accuracy	B-Metric
versus	O
number	O
of	O
FLOPS	O
that	O
a	O
particular	O
model	O
requires	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
the	O
FLOPS	O
on	O
the	O
x	O
-	O
axis	O
and	O
the	O
accuracy	B-Metric
at	O
0.001	O
false	B-Metric
accept	I-Metric
rate	I-Metric
(	O
)	O
on	O
our	O
user	O
labelled	O
test	O
-	O
data	O
set	O
from	O
section	O
[	O
reference	O
]	O
.	O
	
It	O
is	O
interesting	O
to	O
see	O
the	O
strong	O
correlation	O
between	O
the	O
computation	O
a	O
model	O
requires	O
and	O
the	O
accuracy	B-Metric
it	O
achieves	O
.	O
	
The	O
figure	O
highlights	O
the	O
five	O
models	O
(	O
NN1	B-Method
,	O
NN2	B-Method
,	O
NN3	B-Method
,	O
NNS1	B-Method
,	O
NNS2	B-Method
)	O
that	O
we	O
discuss	O
in	O
more	O
detail	O
in	O
our	O
experiments	O
.	O
	
We	O
also	O
looked	O
into	O
the	O
accuracy	B-Metric
trade	O
-	O
off	O
with	O
regards	O
to	O
the	O
number	O
of	O
model	O
parameters	O
.	O
	
However	O
,	O
the	O
picture	O
is	O
not	O
as	O
clear	O
in	O
that	O
case	O
.	O
	
For	O
example	O
,	O
the	O
Inception	B-Method
based	I-Method
model	I-Method
NN2	I-Method
achieves	O
a	O
comparable	O
performance	O
to	O
NN1	B-Method
,	O
but	O
only	O
has	O
a	O
20th	O
of	O
the	O
parameters	O
.	O
	
The	O
number	O
of	O
FLOPS	O
is	O
comparable	O
,	O
though	O
.	O
	
Obviously	O
at	O
some	O
point	O
the	O
performance	O
is	O
expected	O
to	O
decrease	O
,	O
if	O
the	O
number	O
of	O
parameters	O
is	O
reduced	O
further	O
.	O
	
Other	O
model	B-Method
architectures	I-Method
may	O
allow	O
further	O
reductions	O
without	O
loss	O
of	O
accuracy	B-Metric
,	O
just	O
like	O
Inception	O
did	O
in	O
this	O
case	O
.	O
	
subsection	O
:	O
Effect	O
of	O
CNN	B-Method
Model	I-Method
	
We	O
now	O
discuss	O
the	O
performance	O
of	O
our	O
four	O
selected	O
models	O
in	O
more	O
detail	O
.	O
	
On	O
the	O
one	O
hand	O
we	O
have	O
our	O
traditional	O
Zeiler	B-Method
&	I-Method
Fergus	I-Method
based	I-Method
architecture	I-Method
with	O
convolutions	B-Method
(	O
see	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
On	O
the	O
other	O
hand	O
we	O
have	O
Inception	B-Method
based	I-Method
models	I-Method
that	O
dramatically	O
reduce	O
the	O
model	B-Metric
size	I-Metric
.	O
	
Overall	O
,	O
in	O
the	O
final	O
performance	O
the	O
top	O
models	O
of	O
both	O
architectures	O
perform	O
comparably	O
.	O
	
However	O
,	O
some	O
of	O
our	O
Inception	B-Method
based	I-Method
models	I-Method
,	O
such	O
as	O
NN3	B-Method
,	O
still	O
achieve	O
good	O
performance	O
while	O
significantly	O
reducing	O
both	O
the	O
FLOPS	B-Metric
and	O
the	O
model	B-Metric
size	I-Metric
.	O
	
The	O
detailed	O
evaluation	O
on	O
our	O
personal	O
photos	O
test	O
set	O
is	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
While	O
the	O
largest	O
model	O
achieves	O
a	O
dramatic	O
improvement	O
in	O
accuracy	B-Metric
compared	O
to	O
the	O
tiny	O
NNS2	B-Method
,	O
the	O
latter	O
can	O
be	O
run	O
30ms	O
/	O
image	O
on	O
a	O
mobile	O
phone	O
and	O
is	O
still	O
accurate	O
enough	O
to	O
be	O
used	O
in	O
face	B-Task
clustering	I-Task
.	O
	
The	O
sharp	O
drop	O
in	O
the	O
ROC	B-Metric
for	O
indicates	O
noisy	O
labels	O
in	O
the	O
test	O
data	O
groundtruth	O
.	O
	
At	O
extremely	O
low	O
false	B-Metric
accept	I-Metric
rates	I-Metric
a	O
single	O
mislabeled	O
image	O
can	O
have	O
a	O
significant	O
impact	O
on	O
the	O
curve	O
.	O
	
subsection	O
:	O
Sensitivity	B-Metric
to	O
Image	B-Metric
Quality	I-Metric
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
robustness	O
of	O
our	O
model	O
across	O
a	O
wide	O
range	O
of	O
image	O
sizes	O
.	O
	
The	O
network	O
is	O
surprisingly	O
robust	O
with	O
respect	O
to	O
JPEG	B-Task
compression	I-Task
and	O
performs	O
very	O
well	O
down	O
to	O
a	O
JPEG	B-Metric
quality	I-Metric
of	O
20	O
.	O
	
The	O
performance	O
drop	O
is	O
very	O
small	O
for	O
face	O
thumbnails	O
down	O
to	O
a	O
size	O
of	O
120x120	O
pixels	O
and	O
even	O
at	O
80x80	O
pixels	O
it	O
shows	O
acceptable	O
performance	O
.	O
	
This	O
is	O
notable	O
,	O
because	O
the	O
network	O
was	O
trained	O
on	O
220x220	O
input	O
images	O
.	O
	
Training	O
with	O
lower	O
resolution	O
faces	O
could	O
improve	O
this	O
range	O
further	O
.	O
	
subsection	O
:	O
Embedding	B-Task
Dimensionality	I-Task
	
We	O
explored	O
various	O
embedding	O
dimensionalities	O
and	O
selected	O
128	O
for	O
all	O
experiments	O
other	O
than	O
the	O
comparison	O
reported	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
One	O
would	O
expect	O
the	O
larger	O
embeddings	O
to	O
perform	O
at	O
least	O
as	O
good	O
as	O
the	O
smaller	O
ones	O
,	O
however	O
,	O
it	O
is	O
possible	O
that	O
they	O
require	O
more	O
training	O
to	O
achieve	O
the	O
same	O
accuracy	B-Metric
.	O
	
That	O
said	O
,	O
the	O
differences	O
in	O
the	O
performance	O
reported	O
in	O
Table	O
[	O
reference	O
]	O
are	O
statistically	O
insignificant	O
.	O
	
It	O
should	O
be	O
noted	O
,	O
that	O
during	O
training	O
a	O
128	O
dimensional	O
float	O
vector	O
is	O
used	O
,	O
but	O
it	O
can	O
be	O
quantized	O
to	O
128	O
-	O
bytes	O
without	O
loss	O
of	O
accuracy	B-Metric
.	O
	
Thus	O
each	O
face	O
is	O
compactly	O
represented	O
by	O
a	O
128	B-Method
dimensional	I-Method
byte	I-Method
vector	I-Method
,	O
which	O
is	O
ideal	O
for	O
large	O
scale	O
clustering	O
and	O
recognition	B-Task
.	O
	
Smaller	O
embeddings	O
are	O
possible	O
at	O
a	O
minor	O
loss	O
of	O
accuracy	B-Metric
and	O
could	O
be	O
employed	O
on	O
mobile	O
devices	O
.	O
	
subsection	O
:	O
Amount	O
of	O
Training	O
Data	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
impact	O
of	O
large	O
amounts	O
of	O
training	O
data	O
.	O
	
Due	O
to	O
time	O
constraints	O
this	O
evaluation	O
was	O
run	O
on	O
a	O
smaller	O
model	O
;	O
the	O
effect	O
may	O
be	O
even	O
larger	O
on	O
larger	O
models	O
.	O
	
It	O
is	O
clear	O
that	O
using	O
tens	O
of	O
millions	O
of	O
exemplars	O
results	O
in	O
a	O
clear	O
boost	O
of	O
accuracy	B-Metric
on	O
our	O
personal	O
photo	O
test	O
set	O
from	O
section	O
[	O
reference	O
]	O
.	O
	
Compared	O
to	O
only	O
millions	O
of	O
images	O
the	O
relative	O
reduction	O
in	O
error	B-Metric
is	O
60	O
%	O
.	O
	
Using	O
another	O
order	O
of	O
magnitude	O
more	O
images	O
(	O
hundreds	O
of	O
millions	O
)	O
still	O
gives	O
a	O
small	O
boost	O
,	O
but	O
the	O
improvement	O
tapers	O
off	O
.	O
	
subsection	O
:	O
Performance	O
on	O
LFW	B-Material
	
False	O
accept	O
False	O
reject	O
	
We	O
evaluate	O
our	O
model	O
on	O
LFW	B-Material
using	O
the	O
standard	O
protocol	O
for	O
unrestricted	O
,	O
labeled	O
outside	O
data	O
.	O
	
Nine	O
training	O
splits	O
are	O
used	O
to	O
select	O
the	O
-	O
distance	O
threshold	O
.	O
	
Classification	B-Task
(	O
same	O
or	O
different	O
)	O
is	O
then	O
performed	O
on	O
the	O
tenth	O
test	O
split	O
.	O
	
The	O
selected	O
optimal	O
threshold	O
is	O
for	O
all	O
test	O
splits	O
except	O
split	O
eighth	O
(	O
)	O
.	O
	
Our	O
model	O
is	O
evaluated	O
in	O
two	O
modes	O
:	O
Fixed	O
center	O
crop	O
of	O
the	O
LFW	B-Material
provided	O
thumbnail	O
.	O
	
A	O
proprietary	B-Method
face	I-Method
detector	I-Method
(	O
similar	O
to	O
Picasa	B-Method
)	O
is	O
run	O
on	O
the	O
provided	O
LFW	B-Material
thumbnails	I-Material
.	O
	
If	O
it	O
fails	O
to	O
align	O
the	O
face	O
(	O
this	O
happens	O
for	O
two	O
images	O
)	O
,	O
the	O
LFW	B-Material
alignment	I-Material
is	O
used	O
.	O
	
Figure	O
[	O
reference	O
]	O
gives	O
an	O
overview	O
of	O
all	O
failure	O
cases	O
.	O
	
It	O
shows	O
false	O
accepts	O
on	O
the	O
top	O
as	O
well	O
as	O
false	O
rejects	O
at	O
the	O
bottom	O
.	O
	
We	O
achieve	O
a	O
classification	B-Metric
accuracy	I-Metric
of	O
98.87%±0.15	O
when	O
using	O
the	O
fixed	O
center	O
crop	O
described	O
in	O
(	O
1	O
)	O
and	O
the	O
record	O
breaking	O
99.63%±	O
0.09	O
standard	O
error	O
of	O
the	O
mean	O
when	O
using	O
the	O
extra	O
face	O
alignment	O
(	O
2	O
)	O
.	O
	
This	O
reduces	O
the	O
error	B-Metric
reported	O
for	O
DeepFace	B-Task
in	I-Task
by	O
more	O
than	O
a	O
factor	O
of	O
7	O
and	O
the	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
reported	O
for	O
DeepId2	B-Metric
+	I-Metric
in	I-Metric
by	O
30	O
%	O
.	O
	
This	O
is	O
the	O
performance	O
of	O
model	B-Method
NN1	I-Method
,	O
but	O
even	O
the	O
much	O
smaller	O
NN3	B-Method
achieves	O
performance	O
that	O
is	O
not	O
statistically	O
significantly	O
different	O
.	O
	
subsection	O
:	O
Performance	O
on	O
Youtube	B-Material
Faces	I-Material
DB	I-Material
	
We	O
use	O
the	O
average	O
similarity	O
of	O
all	O
pairs	O
of	O
the	O
first	O
one	O
hundred	O
frames	O
that	O
our	O
face	B-Method
detector	I-Method
detects	O
in	O
each	O
video	O
.	O
	
This	O
gives	O
us	O
a	O
classification	B-Metric
accuracy	I-Metric
of	O
95.12%±0.39	O
.	O
	
Using	O
the	O
first	O
one	O
thousand	O
frames	O
results	O
in	O
95.18	O
%	O
.	O
	
Compared	O
to	O
91.4	O
%	O
who	O
also	O
evaluate	O
one	O
hundred	O
frames	O
per	O
video	O
we	O
reduce	O
the	O
error	B-Metric
rate	I-Metric
by	O
almost	O
half	O
.	O
	
DeepId2	B-Method
+	I-Method
achieved	O
93.2	O
%	O
and	O
our	O
method	O
reduces	O
this	O
error	O
by	O
30	O
%	O
,	O
comparable	O
to	O
our	O
improvement	O
on	O
LFW	B-Material
.	O
	
subsection	O
:	O
Face	B-Task
Clustering	I-Task
	
Our	O
compact	B-Method
embedding	I-Method
lends	O
itself	O
to	O
be	O
used	O
in	O
order	O
to	O
cluster	O
a	O
users	O
personal	O
photos	O
into	O
groups	O
of	O
people	O
with	O
the	O
same	O
identity	O
.	O
	
The	O
constraints	O
in	O
assignment	B-Task
imposed	O
by	O
clustering	O
faces	O
,	O
compared	O
to	O
the	O
pure	B-Task
verification	I-Task
task	I-Task
,	O
lead	O
to	O
truly	O
amazing	O
results	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
one	O
cluster	O
in	O
a	O
users	O
personal	O
photo	O
collection	O
,	O
generated	O
using	O
agglomerative	B-Method
clustering	I-Method
.	O
	
It	O
is	O
a	O
clear	O
showcase	O
of	O
the	O
incredible	O
invariance	O
to	O
occlusion	O
,	O
lighting	O
,	O
pose	O
and	O
even	O
age	O
.	O
	
section	O
:	O
Summary	O
	
We	O
provide	O
a	O
method	O
to	O
directly	O
learn	O
an	O
embedding	B-Task
into	O
an	O
Euclidean	O
space	O
for	O
face	B-Task
verification	I-Task
.	O
	
This	O
sets	O
it	O
apart	O
from	O
other	O
methods	O
who	O
use	O
the	O
CNN	B-Method
bottleneck	I-Method
layer	I-Method
,	O
or	O
require	O
additional	O
post	B-Method
-	I-Method
processing	I-Method
such	O
as	O
concatenation	B-Method
of	I-Method
multiple	I-Method
models	I-Method
and	O
PCA	B-Method
,	O
as	O
well	O
as	O
SVM	B-Method
classification	I-Method
.	O
	
Our	O
end	O
-	O
to	O
-	O
end	B-Task
training	I-Task
both	O
simplifies	O
the	O
setup	O
and	O
shows	O
that	O
directly	O
optimizing	O
a	O
loss	B-Task
relevant	O
to	O
the	O
task	O
at	O
hand	O
	
improves	O
performance	O
.	O
	
Another	O
strength	O
of	O
our	O
model	O
is	O
that	O
it	O
only	O
requires	O
minimal	O
alignment	O
(	O
tight	O
crop	O
around	O
the	O
face	O
area	O
)	O
.	O
	
,	O
for	O
example	O
,	O
performs	O
a	O
complex	O
3D	B-Task
alignment	I-Task
.	O
	
We	O
also	O
experimented	O
with	O
a	O
similarity	B-Method
transform	I-Method
alignment	I-Method
and	O
notice	O
that	O
this	O
can	O
actually	O
improve	O
performance	O
slightly	O
.	O
	
It	O
is	O
not	O
clear	O
if	O
it	O
is	O
worth	O
the	O
extra	O
complexity	O
.	O
	
Future	O
work	O
will	O
focus	O
on	O
better	O
understanding	O
of	O
the	O
error	O
cases	O
,	O
further	O
improving	O
the	O
model	O
,	O
and	O
also	O
reducing	O
model	B-Metric
size	I-Metric
and	O
reducing	O
CPU	B-Metric
requirements	I-Metric
.	O
	
We	O
will	O
also	O
look	O
into	O
ways	O
of	O
improving	O
the	O
currently	O
extremely	O
long	O
training	B-Metric
times	I-Metric
,	O
variations	O
of	O
our	O
curriculum	B-Method
learning	I-Method
with	O
smaller	O
batch	O
sizes	O
and	O
offline	O
as	O
well	O
as	O
online	B-Task
positive	I-Task
and	I-Task
negative	I-Task
mining	I-Task
.	O
	
section	O
:	O
Appendix	O
:	O
Harmonic	B-Method
Embedding	I-Method
	
In	O
this	O
section	O
we	O
introduce	O
the	O
concept	O
of	O
harmonic	B-Task
embeddings	I-Task
.	O
	
By	O
this	O
we	O
denote	O
a	O
set	O
of	O
embeddings	O
that	O
are	O
generated	O
by	O
different	O
models	O
v1	O
and	O
v2	O
but	O
are	O
compatible	O
in	O
the	O
sense	O
that	O
they	O
can	O
be	O
compared	O
to	O
each	O
other	O
.	O
	
This	O
compatibility	O
greatly	O
simplifies	O
upgrade	O
paths	O
.	O
	
in	O
an	O
scenario	O
where	O
embedding	B-Task
v1	I-Task
was	O
computed	O
across	O
a	O
large	O
set	O
of	O
images	O
and	O
a	O
new	O
embedding	B-Method
model	I-Method
v2	O
is	O
being	O
rolled	O
out	O
,	O
this	O
compatibility	O
ensures	O
a	O
smooth	O
transition	O
without	O
the	O
need	O
to	O
worry	O
about	O
version	O
incompatibilities	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
results	O
on	O
our	O
3	O
G	O
dataset	O
.	O
	
It	O
can	O
be	O
seen	O
that	O
the	O
improved	O
model	B-Method
NN2	I-Method
significantly	O
outperforms	O
NN1	B-Method
,	O
while	O
the	O
comparison	O
of	O
NN2	B-Method
embeddings	I-Method
to	O
NN1	B-Method
embeddings	I-Method
performs	O
at	O
an	O
intermediate	O
level	O
.	O
	
subsection	O
:	O
Harmonic	O
Triplet	O
Loss	O
	
In	O
order	O
to	O
learn	O
the	O
harmonic	B-Method
embedding	I-Method
we	O
mix	O
embeddings	O
of	O
v1	O
together	O
with	O
the	O
embeddings	O
v2	O
,	O
that	O
are	O
being	O
learned	O
.	O
	
This	O
is	O
done	O
inside	O
the	O
triplet	O
loss	O
and	O
results	O
in	O
additionally	O
generated	O
triplets	O
that	O
encourage	O
the	O
compatibility	O
between	O
the	O
different	O
embedding	O
versions	O
.	O
	
Figure	O
[	O
reference	O
]	O
visualizes	O
the	O
different	O
combinations	O
of	O
triplets	O
that	O
contribute	O
to	O
the	O
triplet	O
loss	O
.	O
	
We	O
initialized	O
the	O
v2	B-Method
embedding	I-Method
from	O
an	O
independently	O
trained	O
NN2	B-Method
and	O
retrained	O
the	O
last	O
layer	O
(	O
embedding	B-Method
layer	I-Method
)	O
from	O
random	B-Method
initialization	I-Method
with	O
the	O
compatibility	O
encouraging	O
triplet	O
loss	O
.	O
	
First	O
only	O
the	O
last	O
layer	O
is	O
retrained	O
,	O
then	O
we	O
continue	O
training	O
the	O
whole	O
v2	B-Method
network	I-Method
with	O
the	O
harmonic	O
loss	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
a	O
possible	O
interpretation	O
of	O
how	O
this	O
compatibility	O
may	O
work	O
in	O
practice	O
.	O
	
The	O
vast	O
majority	O
of	O
v2	O
embeddings	O
may	O
be	O
embedded	O
near	O
the	O
corresponding	O
v1	O
embedding	O
,	O
however	O
,	O
incorrectly	O
placed	O
v1	O
embeddings	O
can	O
be	O
perturbed	O
slightly	O
such	O
that	O
their	O
new	O
location	O
in	O
embedding	O
space	O
improves	O
verification	B-Metric
accuracy	I-Metric
.	O
	
subsection	O
:	O
Summary	O
	
These	O
are	O
very	O
interesting	O
findings	O
and	O
it	O
is	O
somewhat	O
surprising	O
that	O
it	O
works	O
so	O
well	O
.	O
	
Future	O
work	O
can	O
explore	O
how	O
far	O
this	O
idea	O
can	O
be	O
extended	O
.	O
	
Presumably	O
there	O
is	O
a	O
limit	O
as	O
to	O
how	O
much	O
the	O
v2	B-Method
embedding	I-Method
can	O
improve	O
over	O
v1	O
,	O
while	O
still	O
being	O
compatible	O
.	O
	
Additionally	O
it	O
would	O
be	O
interesting	O
to	O
train	O
small	O
networks	O
that	O
can	O
run	O
on	O
a	O
mobile	O
phone	O
and	O
are	O
compatible	O
to	O
a	O
larger	O
server	B-Method
side	I-Method
model	I-Method
.	O
	
section	O
:	O
Acknowledgments	O
	
We	O
would	O
like	O
to	O
thank	O
Johannes	O
Steffens	O
for	O
his	O
discussions	O
and	O
great	O
insights	O
on	O
face	O
recognition	B-Task
and	O
Christian	O
Szegedy	O
for	O
providing	O
new	O
network	B-Method
architectures	I-Method
like	O
and	O
discussing	O
network	B-Method
design	I-Method
choices	I-Method
.	O
	
Also	O
we	O
are	O
indebted	O
to	O
the	O
DistBelief	O
team	O
for	O
their	O
support	O
especially	O
to	O
Rajat	O
Monga	O
for	O
help	O
in	O
setting	O
up	O
efficient	O
training	B-Method
schemes	I-Method
.	O
	
Also	O
our	O
work	O
would	O
not	O
have	O
been	O
possible	O
without	O
the	O
support	O
of	O
Chuck	O
Rosenberg	O
,	O
Hartwig	O
Adam	O
,	O
and	O
Simon	O
Han	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
node2vec	B-Method
:	O
Scalable	B-Method
Feature	I-Method
Learning	I-Method
for	O
Networks	B-Task
	
Prediction	B-Task
tasks	I-Task
over	O
nodes	O
and	O
edges	O
in	O
networks	O
require	O
careful	O
effort	O
in	O
engineering	O
features	O
used	O
by	O
learning	B-Method
algorithms	I-Method
.	O
	
Recent	O
research	O
in	O
the	O
broader	O
field	O
of	O
representation	B-Task
learning	I-Task
has	O
led	O
to	O
significant	O
progress	O
in	O
automating	B-Task
prediction	I-Task
by	O
learning	O
the	O
features	O
themselves	O
.	O
	
However	O
,	O
present	O
feature	B-Method
learning	I-Method
approaches	I-Method
are	O
not	O
expressive	O
enough	O
to	O
capture	O
the	O
diversity	O
of	O
connectivity	O
patterns	O
observed	O
in	O
networks	O
.	O
	
Here	O
we	O
propose	O
node2vec	B-Method
,	O
an	O
algorithmic	B-Method
framework	I-Method
for	O
learning	O
continuous	B-Task
feature	I-Task
representations	I-Task
for	O
nodes	B-Task
in	I-Task
networks	I-Task
.	O
	
In	O
node2vec	B-Method
,	O
we	O
learn	O
a	O
mapping	O
of	O
nodes	O
to	O
a	O
low	O
-	O
dimensional	O
space	O
of	O
features	O
that	O
maximizes	O
the	O
likelihood	O
of	O
preserving	O
network	O
neighborhoods	O
of	O
nodes	O
.	O
	
We	O
define	O
a	O
flexible	O
notion	O
of	O
a	O
node	O
’s	O
network	O
neighborhood	O
and	O
design	O
a	O
biased	B-Method
random	I-Method
walk	I-Method
procedure	I-Method
,	O
which	O
efficiently	O
explores	O
diverse	O
neighborhoods	O
.	O
	
Our	O
algorithm	O
generalizes	O
prior	O
work	O
which	O
is	O
based	O
on	O
rigid	O
notions	O
of	O
network	O
neighborhoods	O
,	O
and	O
we	O
argue	O
that	O
the	O
added	O
flexibility	O
in	O
exploring	O
neighborhoods	O
is	O
the	O
key	O
to	O
learning	O
richer	B-Task
representations	I-Task
.	O
	
We	O
demonstrate	O
the	O
efficacy	O
of	O
node2vec	B-Method
over	O
existing	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
techniques	O
on	O
multi	B-Task
-	I-Task
label	I-Task
classification	I-Task
and	O
link	B-Task
prediction	I-Task
in	O
several	O
real	O
-	O
world	O
networks	O
from	O
diverse	O
domains	O
.	O
	
Taken	O
together	O
,	O
our	O
work	O
represents	O
a	O
new	O
way	O
for	O
efficiently	O
learning	B-Task
state	I-Task
-	I-Task
of	I-Task
-	I-Task
the	I-Task
-	I-Task
art	I-Task
task	I-Task
-	I-Task
independent	I-Task
representations	I-Task
in	O
complex	B-Task
networks	I-Task
.	O
	
2	O
2016	O
acmlicensed	O
KDD	O
’	O
16	O
,	O
August	O
13	O
-	O
17	O
,	O
2016	O
,	O
San	O
Francisco	O
,	O
CA	O
,	O
USA	O
978	O
-	O
1	O
-	O
4503	O
-	O
4232	O
-	O
2	O
/	O
16	O
/	O
08	O
$	O
15.00	O
	
http:	O
//	O
dx.doi.org	O
/	O
10.1145	O
/	O
2939672.2939754	O
Categories	O
and	O
Subject	O
Descriptors	O
:	O
	
H.2.8	O
	
[	O
Database	O
Management	O
]	O
:	O
	
Database	O
applications—	O
Data	O
mining	O
;	O
I.2.6	O
[	O
Artificial	O
Intelligence	O
]	O
:	O
	
Learning	B-Task
General	O
Terms	O
:	O
Algorithms	O
;	O
Experimentation	O
.	O
	
Keywords	O
:	O
Information	B-Task
networks	I-Task
,	O
Feature	B-Task
learning	I-Task
,	O
	
Node	B-Task
embeddings	I-Task
,	O
Graph	B-Method
representations	I-Method
.	O
	
section	O
:	O
Introduction	O
	
Many	O
important	O
tasks	O
in	O
network	B-Task
analysis	I-Task
involve	O
predictions	O
over	O
nodes	O
and	O
edges	O
.	O
	
In	O
a	O
typical	O
node	B-Task
classification	I-Task
task	I-Task
,	O
we	O
are	O
interested	O
in	O
predicting	O
the	O
most	O
probable	O
labels	O
of	O
nodes	O
in	O
a	O
network	O
.	O
	
For	O
example	O
,	O
in	O
a	O
social	B-Task
network	I-Task
,	O
we	O
might	O
be	O
interested	O
in	O
predicting	B-Task
interests	I-Task
of	I-Task
users	I-Task
,	O
or	O
in	O
a	O
protein	B-Task
-	I-Task
protein	I-Task
interaction	I-Task
network	I-Task
we	O
might	O
be	O
interested	O
in	O
predicting	O
functional	O
labels	O
of	O
proteins	O
.	O
	
Similarly	O
,	O
in	O
link	B-Task
prediction	I-Task
,	O
we	O
wish	O
to	O
predict	O
whether	O
a	O
pair	O
of	O
nodes	O
in	O
a	O
network	O
should	O
have	O
an	O
edge	O
connecting	O
them	O
.	O
	
Link	B-Task
prediction	I-Task
is	O
useful	O
in	O
a	O
wide	O
variety	O
of	O
domains	O
;	O
for	O
instance	O
,	O
in	O
genomics	B-Task
,	O
it	O
helps	O
us	O
discover	O
novel	O
interactions	O
between	O
genes	O
,	O
and	O
in	O
social	B-Task
networks	I-Task
,	O
it	O
can	O
identify	O
real	O
-	O
world	O
friends	O
.	O
	
Any	O
supervised	B-Method
machine	I-Method
learning	I-Method
algorithm	I-Method
requires	O
a	O
set	O
of	O
informative	O
,	O
discriminating	O
,	O
and	O
independent	O
features	O
.	O
	
In	O
prediction	B-Task
problems	I-Task
on	O
networks	B-Task
this	O
means	O
that	O
one	O
has	O
to	O
construct	O
a	O
feature	B-Method
vector	I-Method
representation	I-Method
for	O
the	O
nodes	O
and	O
edges	O
.	O
	
A	O
typical	O
solution	O
involves	O
hand	O
-	O
engineering	O
domain	O
-	O
specific	O
features	O
based	O
on	O
expert	O
knowledge	O
.	O
	
Even	O
if	O
one	O
discounts	O
the	O
tedious	O
effort	O
required	O
for	O
feature	B-Task
engineering	I-Task
,	O
such	O
features	O
are	O
usually	O
designed	O
for	O
specific	O
tasks	O
and	O
do	O
not	O
generalize	O
across	O
different	O
prediction	B-Task
tasks	I-Task
.	O
	
An	O
alternative	O
approach	O
is	O
to	O
learn	O
feature	B-Method
representations	I-Method
by	O
solving	O
an	O
optimization	B-Task
problem	I-Task
.	O
	
The	O
challenge	O
in	O
feature	B-Task
learning	I-Task
is	O
defining	O
an	O
objective	O
function	O
,	O
which	O
involves	O
a	O
trade	O
-	O
off	O
in	O
balancing	B-Metric
computational	I-Metric
efficiency	I-Metric
and	O
predictive	O
accuracy	B-Metric
.	O
	
On	O
one	O
side	O
of	O
the	O
spectrum	O
,	O
one	O
could	O
directly	O
aim	O
to	O
find	O
a	O
feature	B-Method
representation	I-Method
that	O
optimizes	O
performance	O
of	O
a	O
downstream	B-Task
prediction	I-Task
task	I-Task
.	O
	
While	O
this	O
supervised	B-Method
procedure	I-Method
results	O
in	O
good	O
accuracy	B-Metric
,	O
it	O
comes	O
at	O
the	O
cost	O
of	O
high	O
training	B-Metric
time	I-Metric
complexity	I-Metric
due	O
to	O
a	O
blowup	O
in	O
the	O
number	O
of	O
parameters	O
that	O
need	O
to	O
be	O
estimated	O
.	O
	
At	O
the	O
other	O
extreme	O
,	O
the	O
objective	B-Metric
function	I-Metric
can	O
be	O
defined	O
to	O
be	O
independent	O
of	O
the	O
downstream	B-Task
prediction	I-Task
task	I-Task
and	O
the	O
representations	O
can	O
be	O
learned	O
in	O
a	O
purely	O
unsupervised	B-Method
way	I-Method
.	O
	
This	O
makes	O
the	O
optimization	B-Task
computationally	O
efficient	O
and	O
with	O
a	O
carefully	O
designed	O
objective	O
,	O
it	O
results	O
in	O
task	O
-	O
independent	O
features	O
that	O
closely	O
match	O
task	O
-	O
specific	O
approaches	O
in	O
predictive	O
accuracy	B-Metric
.	O
	
However	O
,	O
current	O
techniques	O
fail	O
to	O
satisfactorily	O
define	O
and	O
optimize	O
a	O
reasonable	O
objective	B-Metric
required	O
for	O
scalable	B-Task
unsupervised	I-Task
feature	I-Task
learning	I-Task
in	I-Task
networks	I-Task
.	O
	
Classic	O
approaches	O
based	O
on	O
linear	B-Method
and	I-Method
non	I-Method
-	I-Method
linear	I-Method
dimensionality	I-Method
reduction	I-Method
techniques	I-Method
such	O
as	O
Principal	B-Method
Component	I-Method
Analysis	I-Method
,	O
Multi	B-Method
-	I-Method
Dimensional	I-Method
Scaling	I-Method
and	O
their	O
extensions	O
optimize	O
an	O
objective	O
that	O
transforms	O
a	O
representative	O
data	O
matrix	O
of	O
the	O
network	O
such	O
that	O
it	O
maximizes	O
the	O
variance	O
of	O
the	O
data	B-Method
representation	I-Method
.	O
	
Consequently	O
,	O
these	O
approaches	O
invariably	O
involve	O
eigendecomposition	B-Method
of	O
the	O
appropriate	O
data	B-Method
matrix	I-Method
which	O
is	O
expensive	O
for	O
large	B-Task
real	I-Task
-	I-Task
world	I-Task
networks	I-Task
.	O
	
Moreover	O
,	O
the	O
resulting	O
latent	B-Method
representations	I-Method
give	O
poor	O
performance	O
on	O
various	O
prediction	B-Task
tasks	I-Task
over	O
networks	B-Task
.	O
	
Alternatively	O
,	O
we	O
can	O
design	O
an	O
objective	O
that	O
seeks	O
to	O
preserve	O
local	O
neighborhoods	O
of	O
nodes	O
.	O
	
The	O
objective	O
can	O
be	O
efficiently	O
optimized	O
using	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
(	O
SGD	B-Method
)	I-Method
akin	O
to	O
backpropogation	B-Method
on	O
just	O
single	O
hidden	B-Method
-	I-Method
layer	I-Method
feedforward	I-Method
neural	I-Method
networks	I-Method
.	O
	
Recent	O
attempts	O
in	O
this	O
direction	O
propose	O
efficient	O
algorithms	O
but	O
rely	O
on	O
a	O
rigid	O
notion	O
of	O
a	O
network	O
neighborhood	O
,	O
which	O
results	O
in	O
these	O
approaches	O
being	O
largely	O
insensitive	O
to	O
connectivity	O
patterns	O
unique	O
to	O
networks	O
.	O
	
Specifically	O
,	O
nodes	O
in	O
networks	O
could	O
be	O
organized	O
based	O
on	O
communities	O
they	O
belong	O
to	O
(	O
i.e.	O
,	O
homophily	O
)	O
;	O
in	O
other	O
cases	O
,	O
the	O
organization	O
could	O
be	O
based	O
on	O
the	O
structural	O
roles	O
of	O
nodes	O
in	O
the	O
network	O
(	O
i.e.	O
,	O
structural	O
equivalence	O
)	O
.	O
	
For	O
instance	O
,	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
we	O
observe	O
nodes	O
and	O
belonging	O
to	O
the	O
same	O
tightly	O
knit	O
community	O
of	O
nodes	O
,	O
while	O
the	O
nodes	O
and	O
in	O
the	O
two	O
distinct	O
communities	O
share	O
the	O
same	O
structural	O
role	O
of	O
a	O
hub	O
node	O
.	O
	
Real	B-Task
-	I-Task
world	I-Task
networks	I-Task
commonly	O
exhibit	O
a	O
mixture	O
of	O
such	O
equivalences	O
.	O
	
Thus	O
,	O
it	O
is	O
essential	O
to	O
allow	O
for	O
a	O
flexible	O
algorithm	O
that	O
can	O
learn	O
node	B-Method
representations	I-Method
obeying	O
both	O
principles	O
:	O
ability	O
to	O
learn	O
representations	O
that	O
embed	O
nodes	O
from	O
the	O
same	O
network	O
community	O
closely	O
together	O
,	O
as	O
well	O
as	O
to	O
learn	O
representations	O
where	O
nodes	O
that	O
share	O
similar	O
roles	O
have	O
similar	O
embeddings	O
.	O
	
This	O
would	O
allow	O
feature	B-Method
learning	I-Method
algorithms	I-Method
to	O
generalize	O
across	O
a	O
wide	O
variety	O
of	O
domains	O
and	O
prediction	B-Task
tasks	I-Task
.	O
	
Present	O
work	O
.	O
	
We	O
propose	O
node2vec	B-Method
,	O
a	O
semi	B-Method
-	I-Method
supervised	I-Method
algorithm	I-Method
for	O
scalable	B-Task
feature	I-Task
learning	I-Task
in	I-Task
networks	I-Task
.	O
	
We	O
optimize	O
a	O
custom	O
graph	B-Method
-	I-Method
based	I-Method
objective	I-Method
function	I-Method
using	O
SGD	B-Method
motivated	O
by	O
prior	O
work	O
on	O
natural	B-Task
language	I-Task
processing	I-Task
.	O
	
Intuitively	O
,	O
our	O
approach	O
returns	O
feature	B-Method
representations	I-Method
that	O
maximize	O
the	O
likelihood	O
of	O
preserving	O
network	O
neighborhoods	O
of	O
nodes	O
in	O
a	O
-	O
dimensional	O
feature	O
space	O
.	O
	
We	O
use	O
a	O
2	B-Method
order	I-Method
random	I-Method
walk	I-Method
approach	I-Method
to	O
generate	O
(	O
sample	O
)	O
network	O
neighborhoods	O
for	O
nodes	O
.	O
	
Our	O
key	O
contribution	O
is	O
in	O
defining	O
a	O
flexible	O
notion	O
of	O
a	O
node	O
’s	O
network	O
neighborhood	O
.	O
	
By	O
choosing	O
an	O
appropriate	O
notion	O
of	O
a	O
neighborhood	O
,	O
node2vec	B-Method
can	O
learn	O
representations	O
that	O
organize	O
nodes	O
based	O
on	O
their	O
network	O
roles	O
and	O
/	O
or	O
communities	O
they	O
belong	O
to	O
.	O
	
We	O
achieve	O
this	O
by	O
developing	O
a	O
family	O
of	O
biased	B-Method
random	I-Method
walks	I-Method
,	O
which	O
efficiently	O
explore	O
diverse	O
neighborhoods	O
of	O
a	O
given	O
node	O
.	O
	
The	O
resulting	O
algorithm	O
is	O
flexible	O
,	O
giving	O
us	O
control	O
over	O
the	O
search	O
space	O
through	O
tunable	O
parameters	O
,	O
in	O
contrast	O
to	O
rigid	B-Method
search	I-Method
procedures	I-Method
in	O
prior	O
work	O
.	O
	
Consequently	O
,	O
our	O
method	O
generalizes	O
prior	O
work	O
and	O
can	O
model	O
the	O
full	O
spectrum	O
of	O
equivalences	O
observed	O
in	O
networks	O
.	O
	
The	O
parameters	O
governing	O
our	O
search	B-Method
strategy	I-Method
have	O
an	O
intuitive	O
interpretation	O
and	O
bias	O
the	O
walk	O
towards	O
different	O
network	B-Method
exploration	I-Method
strategies	I-Method
.	O
	
These	O
parameters	O
can	O
also	O
be	O
learned	O
directly	O
using	O
a	O
tiny	O
fraction	O
of	O
labeled	O
data	O
in	O
a	O
semi	B-Method
-	I-Method
supervised	I-Method
fashion	I-Method
.	O
	
We	O
also	O
show	O
how	O
feature	B-Method
representations	I-Method
of	O
individual	O
nodes	O
can	O
be	O
extended	O
to	O
pairs	O
of	O
nodes	O
(	O
i.e.	O
,	O
edges	O
)	O
.	O
	
In	O
order	O
to	O
generate	O
feature	O
representations	O
of	O
edges	O
,	O
we	O
compose	O
the	O
learned	O
feature	B-Method
representations	I-Method
of	O
the	O
individual	O
nodes	O
using	O
simple	O
binary	B-Method
operators	I-Method
.	O
	
This	O
compositionality	O
lends	O
node2vec	B-Method
to	O
prediction	B-Task
tasks	I-Task
involving	O
nodes	O
as	O
well	O
as	O
edges	O
.	O
	
Our	O
experiments	O
focus	O
on	O
two	O
common	O
prediction	B-Task
tasks	I-Task
in	O
networks	B-Task
:	O
a	O
multi	B-Task
-	I-Task
label	I-Task
classification	I-Task
task	I-Task
,	O
where	O
every	O
node	O
is	O
assigned	O
one	O
or	O
more	O
class	O
labels	O
and	O
a	O
link	B-Task
prediction	I-Task
task	I-Task
,	O
where	O
we	O
predict	O
the	O
existence	O
of	O
an	O
edge	O
given	O
a	O
pair	O
of	O
nodes	O
.	O
	
We	O
contrast	O
the	O
performance	O
of	O
node2vec	B-Method
with	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
feature	B-Method
learning	I-Method
algorithms	I-Method
.	O
	
We	O
experiment	O
with	O
several	O
real	O
-	O
world	O
networks	O
from	O
diverse	O
domains	O
,	O
such	O
as	O
social	O
networks	O
,	O
information	O
networks	O
,	O
as	O
well	O
as	O
networks	O
from	O
systems	O
biology	O
.	O
	
Experiments	O
demonstrate	O
that	O
node2vec	B-Method
outperforms	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
by	O
up	O
to	O
26.7	O
%	O
on	O
multi	B-Task
-	I-Task
label	I-Task
classification	I-Task
and	O
up	O
to	O
12.6	O
%	O
on	O
link	B-Task
prediction	I-Task
.	O
	
The	O
algorithm	O
shows	O
competitive	O
performance	O
with	O
even	O
10	O
%	O
labeled	O
data	O
and	O
is	O
also	O
robust	O
to	O
perturbations	O
in	O
the	O
form	O
of	O
noisy	O
or	O
missing	O
edges	O
.	O
	
Computationally	O
,	O
the	O
major	O
phases	O
of	O
node2vec	B-Method
are	O
trivially	O
parallelizable	O
,	O
and	O
it	O
can	O
scale	O
to	O
large	O
networks	O
with	O
millions	O
of	O
nodes	O
in	O
a	O
few	O
hours	O
.	O
	
Overall	O
our	O
paper	O
makes	O
the	O
following	O
contributions	O
:	O
We	O
propose	O
node2vec	B-Method
,	O
an	O
efficient	O
scalable	B-Method
algorithm	I-Method
for	O
feature	B-Task
learning	I-Task
in	I-Task
networks	I-Task
that	O
efficiently	O
optimizes	O
a	O
novel	O
network	B-Task
-	I-Task
aware	I-Task
,	I-Task
neighborhood	I-Task
preserving	I-Task
objective	I-Task
using	O
SGD	B-Method
.	O
	
We	O
show	O
how	O
node2vec	B-Method
is	O
in	O
accordance	O
with	O
established	O
principles	O
in	O
network	B-Task
science	I-Task
,	O
providing	O
flexibility	O
in	O
discovering	O
representations	O
conforming	O
to	O
different	O
equivalences	O
.	O
	
We	O
extend	O
node2vec	B-Method
and	O
other	O
feature	B-Method
learning	I-Method
methods	I-Method
based	O
on	O
neighborhood	O
preserving	O
objectives	O
,	O
from	O
nodes	O
to	O
pairs	O
of	O
nodes	O
for	O
edge	B-Task
-	I-Task
based	I-Task
prediction	I-Task
tasks	I-Task
.	O
	
We	O
empirically	O
evaluate	O
node2vec	B-Method
for	O
multi	B-Task
-	I-Task
label	I-Task
classification	I-Task
and	O
link	O
prediction	O
on	O
several	O
real	O
-	O
world	O
datasets	O
.	O
	
The	O
rest	O
of	O
the	O
paper	O
is	O
structured	O
as	O
follows	O
.	O
	
In	O
Section	O
[	O
reference	O
]	O
,	O
we	O
briefly	O
survey	O
related	O
work	O
in	O
feature	B-Task
learning	I-Task
for	O
networks	B-Task
.	O
	
We	O
present	O
the	O
technical	O
details	O
for	O
feature	B-Task
learning	I-Task
using	O
node2vec	B-Method
in	O
Section	O
[	O
reference	O
]	O
.	O
	
In	O
Section	O
[	O
reference	O
]	O
,	O
we	O
empirically	O
evaluate	O
node2vec	B-Method
on	O
prediction	B-Task
tasks	I-Task
over	O
nodes	O
and	O
edges	O
on	O
various	O
real	O
-	O
world	O
networks	O
and	O
assess	O
the	O
parameter	B-Metric
sensitivity	I-Metric
,	O
perturbation	B-Method
analysis	I-Method
,	O
and	O
scalability	O
aspects	O
of	O
our	O
algorithm	O
.	O
	
We	O
conclude	O
with	O
a	O
discussion	O
of	O
the	O
node2vec	B-Method
framework	O
and	O
highlight	O
some	O
promising	O
directions	O
for	O
future	O
work	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Datasets	O
and	O
a	O
reference	O
implementation	O
of	O
node2vec	B-Method
are	O
available	O
on	O
the	O
project	O
page	O
:	O
.	O
	
section	O
:	O
Related	O
work	O
	
Feature	B-Method
engineering	I-Method
has	O
been	O
extensively	O
studied	O
by	O
the	O
machine	B-Task
learning	I-Task
community	I-Task
under	O
various	O
headings	O
.	O
	
In	O
networks	B-Task
,	O
the	O
conventional	O
paradigm	O
for	O
generating	B-Task
features	I-Task
for	O
nodes	O
is	O
based	O
on	O
feature	B-Method
extraction	I-Method
techniques	I-Method
which	O
typically	O
involve	O
some	O
seed	O
hand	O
-	O
crafted	O
features	O
based	O
on	O
network	O
properties	O
.	O
	
In	O
contrast	O
,	O
our	O
goal	O
is	O
to	O
automate	O
the	O
whole	O
process	O
by	O
casting	O
feature	B-Task
extraction	I-Task
as	O
a	O
representation	B-Task
learning	I-Task
problem	I-Task
in	O
which	O
case	O
we	O
do	O
not	O
require	O
any	O
hand	O
-	O
engineered	O
features	O
.	O
	
Unsupervised	B-Method
feature	I-Method
learning	I-Method
approaches	I-Method
typically	O
exploit	O
the	O
spectral	O
properties	O
of	O
various	O
matrix	B-Method
representations	I-Method
of	I-Method
graphs	I-Method
,	O
especially	O
the	O
Laplacian	O
and	O
the	O
adjacency	O
matrices	O
.	O
	
Under	O
this	O
linear	B-Method
algebra	I-Method
perspective	I-Method
,	O
these	O
methods	O
can	O
be	O
viewed	O
as	O
dimensionality	B-Method
reduction	I-Method
techniques	I-Method
.	O
	
Several	O
linear	B-Method
(	O
e.g.	O
,	O
PCA	B-Method
)	O
and	O
non	B-Method
-	I-Method
linear	I-Method
(	O
e.g.	O
,	O
IsoMap	B-Method
)	I-Method
dimensionality	I-Method
reduction	I-Method
techniques	I-Method
have	O
been	O
proposed	O
.	O
	
These	O
methods	O
suffer	O
from	O
both	O
computational	B-Metric
and	I-Metric
statistical	I-Metric
performance	I-Metric
drawbacks	O
.	O
	
In	O
terms	O
of	O
computational	B-Metric
efficiency	I-Metric
,	O
eigendecomposition	B-Method
of	I-Method
a	I-Method
data	I-Method
matrix	I-Method
is	O
expensive	O
unless	O
the	O
solution	B-Metric
quality	I-Metric
is	O
significantly	O
compromised	O
with	O
approximations	O
,	O
and	O
hence	O
,	O
these	O
methods	O
are	O
hard	O
to	O
scale	O
to	O
large	O
networks	O
.	O
	
Secondly	O
,	O
these	O
methods	O
optimize	O
for	O
objectives	O
that	O
are	O
not	O
robust	O
to	O
the	O
diverse	O
patterns	O
observed	O
in	O
networks	O
(	O
such	O
as	O
homophily	O
and	O
structural	O
equivalence	O
)	O
and	O
make	O
assumptions	O
about	O
the	O
relationship	O
between	O
the	O
underlying	O
network	O
structure	O
and	O
the	O
prediction	B-Task
task	I-Task
.	O
	
For	O
instance	O
,	O
spectral	B-Method
clustering	I-Method
makes	O
a	O
strong	O
homophily	O
assumption	O
that	O
graph	O
cuts	O
will	O
be	O
useful	O
for	O
classification	B-Task
.	O
	
Such	O
assumptions	O
are	O
reasonable	O
in	O
many	O
scenarios	O
,	O
but	O
unsatisfactory	O
in	O
effectively	O
generalizing	O
across	O
diverse	O
networks	O
.	O
	
Recent	O
advancements	O
in	O
representational	B-Method
learning	I-Method
for	O
natural	B-Task
language	I-Task
processing	I-Task
opened	O
new	O
ways	O
for	O
feature	B-Task
learning	I-Task
of	I-Task
discrete	I-Task
objects	I-Task
such	O
as	O
words	O
.	O
	
In	O
particular	O
,	O
the	O
Skip	B-Method
-	I-Method
gram	I-Method
model	I-Method
aims	O
to	O
learn	O
continuous	O
feature	O
representations	O
for	O
words	O
by	O
optimizing	O
a	O
neighborhood	O
preserving	O
likelihood	O
objective	O
.	O
	
The	O
algorithm	O
proceeds	O
as	O
follows	O
	
:	O
It	O
scans	O
over	O
the	O
words	O
of	O
a	O
document	O
,	O
and	O
for	O
every	O
word	O
it	O
aims	O
to	O
embed	O
it	O
such	O
that	O
the	O
word	O
’s	O
features	O
can	O
predict	O
nearby	O
words	O
(	O
i.e.	O
,	O
words	O
inside	O
some	O
context	O
window	O
)	O
.	O
	
The	O
word	B-Method
feature	I-Method
representations	I-Method
are	O
learned	O
by	O
optmizing	O
the	O
likelihood	O
objective	O
using	O
SGD	B-Method
with	O
negative	B-Method
sampling	I-Method
.	O
	
The	O
Skip	B-Method
-	I-Method
gram	I-Method
objective	I-Method
is	O
based	O
on	O
the	O
distributional	B-Method
hypothesis	I-Method
which	O
states	O
that	O
words	O
in	O
similar	O
contexts	O
tend	O
to	O
have	O
similar	O
meanings	O
.	O
	
That	O
is	O
,	O
similar	O
words	O
tend	O
to	O
appear	O
in	O
similar	O
word	O
neighborhoods	O
.	O
	
Inspired	O
by	O
the	O
Skip	B-Method
-	I-Method
gram	I-Method
model	I-Method
,	O
recent	O
research	O
established	O
an	O
analogy	O
for	O
networks	B-Task
by	O
representing	O
a	O
network	O
as	O
a	O
“	O
document	O
”	O
.	O
	
The	O
same	O
way	O
as	O
a	O
document	O
is	O
an	O
ordered	O
sequence	O
of	O
words	O
,	O
one	O
could	O
sample	O
sequences	O
of	O
nodes	O
from	O
the	O
underlying	O
network	O
and	O
turn	O
a	O
network	O
into	O
a	O
ordered	O
sequence	O
of	O
nodes	O
.	O
	
However	O
,	O
there	O
are	O
many	O
possible	O
sampling	B-Method
strategies	I-Method
for	O
nodes	O
,	O
resulting	O
in	O
different	O
learned	O
feature	B-Method
representations	I-Method
.	O
	
In	O
fact	O
,	O
as	O
we	O
shall	O
show	O
,	O
there	O
is	O
no	O
clear	O
winning	B-Method
sampling	I-Method
strategy	I-Method
that	O
works	O
across	O
all	O
networks	O
and	O
all	O
prediction	B-Task
tasks	I-Task
.	O
	
This	O
is	O
a	O
major	O
shortcoming	O
of	O
prior	O
work	O
which	O
fail	O
to	O
offer	O
any	O
flexibility	O
in	O
sampling	B-Task
of	I-Task
nodes	I-Task
from	O
a	O
network	O
.	O
	
Our	O
algorithm	O
node2vec	B-Method
overcomes	O
this	O
limitation	O
by	O
designing	O
a	O
flexible	O
objective	O
that	O
is	O
not	O
tied	O
to	O
a	O
particular	O
sampling	B-Method
strategy	I-Method
and	O
provides	O
parameters	O
to	O
tune	O
the	O
explored	O
search	O
space	O
(	O
see	O
Section	O
[	O
reference	O
]	O
)	O
.	O
	
Finally	O
,	O
for	O
both	O
node	B-Task
and	I-Task
edge	I-Task
based	I-Task
prediction	I-Task
tasks	I-Task
,	O
there	O
is	O
a	O
body	O
of	O
recent	O
work	O
for	O
supervised	B-Task
feature	I-Task
learning	I-Task
based	O
on	O
existing	O
and	O
novel	O
graph	B-Method
-	I-Method
specific	I-Method
deep	I-Method
network	I-Method
architectures	I-Method
.	O
	
These	O
architectures	O
directly	O
minimize	O
the	O
loss	O
function	O
for	O
a	O
downstream	B-Task
prediction	I-Task
task	I-Task
using	O
several	O
layers	O
of	O
non	B-Method
-	I-Method
linear	I-Method
transformations	I-Method
which	O
results	O
in	O
high	O
accuracy	B-Metric
,	O
but	O
at	O
the	O
cost	O
of	O
scalability	B-Metric
due	O
to	O
high	O
training	B-Metric
time	I-Metric
requirements	I-Metric
.	O
	
section	O
:	O
Feature	B-Method
learning	I-Method
framework	I-Method
	
We	O
formulate	O
feature	B-Task
learning	I-Task
in	I-Task
networks	I-Task
as	O
a	O
maximum	B-Task
likelihood	I-Task
optimization	I-Task
problem	I-Task
.	O
	
Let	O
be	O
a	O
given	O
network	O
.	O
	
Our	O
analysis	O
is	O
general	O
and	O
applies	O
to	O
any	O
(	B-Task
un	I-Task
)	I-Task
directed	I-Task
,	I-Task
(	I-Task
un	I-Task
)	I-Task
weighted	I-Task
network	I-Task
.	O
	
Let	O
be	O
the	O
mapping	O
function	O
from	O
nodes	O
to	O
feature	B-Method
representaions	I-Method
we	O
aim	O
to	O
learn	O
for	O
a	O
downstream	B-Task
prediction	I-Task
task	I-Task
.	O
	
Here	O
is	O
a	O
parameter	O
specifying	O
the	O
number	O
of	O
dimensions	O
of	O
our	O
feature	B-Method
representation	I-Method
.	O
	
Equivalently	O
,	O
is	O
a	O
matrix	O
of	O
size	O
parameters	O
.	O
	
For	O
every	O
source	O
node	O
,	O
we	O
define	O
as	O
a	O
network	O
neighborhood	O
of	O
node	O
generated	O
through	O
a	O
neighborhood	B-Method
sampling	I-Method
strategy	I-Method
.	O
	
We	O
proceed	O
by	O
extending	O
the	O
Skip	B-Method
-	I-Method
gram	I-Method
architecture	I-Method
to	O
networks	O
.	O
	
We	O
seek	O
to	O
optimize	O
the	O
following	O
objective	B-Metric
function	I-Metric
,	O
which	O
maximizes	O
the	O
log	O
-	O
probability	O
of	O
observing	O
a	O
network	O
neighborhood	O
for	O
a	O
node	O
conditioned	O
on	O
its	O
feature	B-Method
representation	I-Method
,	O
given	O
by	O
:	O
	
In	O
order	O
to	O
make	O
the	O
optimization	B-Task
problem	I-Task
tractable	O
,	O
we	O
make	O
two	O
standard	O
assumptions	O
:	O
Conditional	O
independence	O
.	O
	
We	O
factorize	O
the	O
likelihood	O
by	O
assuming	O
that	O
the	O
likelihood	O
of	O
observing	O
a	O
neighborhood	O
node	O
is	O
independent	O
of	O
observing	O
any	O
other	O
neighborhood	O
node	O
given	O
the	O
feature	B-Method
representation	I-Method
of	O
the	O
source	O
:	O
	
Symmetry	O
in	O
feature	O
space	O
.	O
	
A	O
source	O
node	O
and	O
neighborhood	O
node	O
have	O
a	O
symmetric	O
effect	O
over	O
each	O
other	O
in	O
feature	O
space	O
.	O
	
Accordingly	O
,	O
we	O
model	O
the	O
conditional	O
likelihood	O
of	O
every	O
source	O
-	O
neighborhood	O
node	O
pair	O
as	O
a	O
softmax	O
unit	O
parametrized	O
by	O
a	O
dot	O
product	O
of	O
their	O
features	O
:	O
	
With	O
the	O
above	O
assumptions	O
,	O
the	O
objective	O
in	O
Eq	O
.	O
	
[	O
reference	O
]	O
simplifies	O
to	O
:	O
The	O
per	O
-	O
node	O
partition	O
function	O
,	O
,	O
is	O
expensive	O
to	O
compute	O
for	O
large	B-Task
networks	I-Task
and	O
we	O
approximate	O
it	O
using	O
negative	B-Method
sampling	I-Method
.	O
	
We	O
optimize	O
Eq	O
.	O
	
[	O
reference	O
]	O
using	O
stochastic	B-Method
gradient	I-Method
ascent	I-Method
over	O
the	O
model	O
parameters	O
defining	O
the	O
features	O
.	O
	
Feature	B-Method
learning	I-Method
methods	I-Method
based	O
on	O
the	O
Skip	B-Method
-	I-Method
gram	I-Method
architecture	I-Method
have	O
been	O
originally	O
developed	O
in	O
the	O
context	O
of	O
natural	O
language	O
.	O
	
Given	O
the	O
linear	O
nature	O
of	O
text	O
,	O
the	O
notion	O
of	O
a	O
neighborhood	O
can	O
be	O
naturally	O
defined	O
using	O
a	O
sliding	O
window	O
over	O
consecutive	O
words	O
.	O
	
Networks	B-Method
,	O
however	O
,	O
are	O
not	O
linear	O
,	O
and	O
thus	O
a	O
richer	O
notion	O
of	O
a	O
neighborhood	O
is	O
needed	O
.	O
	
To	O
resolve	O
this	O
issue	O
,	O
we	O
propose	O
a	O
randomized	B-Method
procedure	I-Method
that	O
samples	O
many	O
different	O
neighborhoods	O
of	O
a	O
given	O
source	O
node	O
.	O
	
The	O
neighborhoods	O
are	O
not	O
restricted	O
to	O
just	O
immediate	O
neighbors	O
but	O
can	O
have	O
vastly	O
different	O
structures	O
depending	O
on	O
the	O
sampling	B-Method
strategy	I-Method
.	O
	
subsection	O
:	O
Classic	B-Method
search	I-Method
strategies	I-Method
	
We	O
view	O
the	O
problem	O
of	O
sampling	B-Task
neighborhoods	I-Task
of	I-Task
a	I-Task
source	I-Task
node	I-Task
as	O
a	O
form	O
of	O
local	B-Method
search	I-Method
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
a	O
graph	O
,	O
	
where	O
given	O
a	O
source	O
node	O
we	O
aim	O
to	O
generate	O
(	O
sample	O
)	O
its	O
neighborhood	O
.	O
	
Importantly	O
,	O
to	O
be	O
able	O
to	O
fairly	O
compare	O
different	O
sampling	B-Method
strategies	I-Method
,	O
we	O
shall	O
constrain	O
the	O
size	O
of	O
the	O
neighborhood	O
set	O
to	O
nodes	O
and	O
then	O
sample	O
multiple	O
sets	O
for	O
a	O
single	O
node	O
.	O
	
Generally	O
,	O
there	O
are	O
two	O
extreme	O
sampling	B-Method
strategies	I-Method
for	O
generating	O
neighborhood	O
set	O
(	O
s	O
)	O
of	O
nodes	O
:	O
	
Breadth	B-Method
-	I-Method
first	I-Method
Sampling	I-Method
(	O
BFS	B-Method
)	O
	
The	O
neighborhood	O
is	O
restricted	O
to	O
nodes	O
which	O
are	O
immediate	O
neighbors	O
of	O
the	O
source	O
.	O
	
For	O
example	O
,	O
in	O
Figure	O
[	O
reference	O
]	O
for	O
a	O
neighborhood	O
of	O
size	O
,	O
BFS	O
samples	O
nodes	O
,	O
,	O
.	O
	
Depth	B-Method
-	I-Method
first	I-Method
Sampling	I-Method
(	O
DFS	B-Method
)	O
	
The	O
neighborhood	O
consists	O
of	O
nodes	O
sequentially	O
sampled	O
at	O
increasing	O
distances	O
from	O
the	O
source	O
node	O
.	O
	
In	O
Figure	O
[	O
reference	O
]	O
,	O
DFS	O
samples	O
,	O
,	O
.	O
	
The	O
breadth	B-Method
-	I-Method
first	I-Method
and	I-Method
depth	I-Method
-	I-Method
first	I-Method
sampling	I-Method
represent	O
extreme	O
scenarios	O
in	O
terms	O
of	O
the	O
search	O
space	O
they	O
explore	O
leading	O
to	O
interesting	O
implications	O
on	O
the	O
learned	O
representations	O
.	O
	
In	O
particular	O
,	O
prediction	B-Task
tasks	I-Task
on	O
nodes	B-Task
in	I-Task
networks	I-Task
often	O
shuttle	O
between	O
two	O
kinds	O
of	O
similarities	O
:	O
homophily	O
and	O
structural	O
equivalence	O
.	O
	
Under	O
the	O
homophily	O
hypothesis	O
nodes	O
that	O
are	O
highly	O
interconnected	O
and	O
belong	O
to	O
similar	O
network	O
clusters	O
or	O
communities	O
should	O
be	O
embedded	O
closely	O
together	O
(	O
e.g.	O
,	O
nodes	O
and	O
in	O
Figure	O
[	O
reference	O
]	O
belong	O
to	O
the	O
same	O
network	O
community	O
)	O
.	O
	
In	O
contrast	O
,	O
under	O
the	O
structural	O
equivalence	O
hypothesis	O
nodes	O
that	O
have	O
similar	O
structural	O
roles	O
in	O
networks	O
should	O
be	O
embedded	O
closely	O
together	O
(	O
e.g.	O
,	O
nodes	O
and	O
in	O
Figure	O
[	O
reference	O
]	O
act	O
as	O
hubs	O
of	O
their	O
corresponding	O
communities	O
)	O
.	O
	
Importantly	O
,	O
unlike	O
homophily	O
,	O
structural	O
equivalence	O
does	O
not	O
emphasize	O
connectivity	O
;	O
nodes	O
could	O
be	O
far	O
apart	O
in	O
the	O
network	O
and	O
still	O
have	O
the	O
same	O
structural	O
role	O
.	O
	
In	O
real	O
-	O
world	O
,	O
these	O
equivalence	O
notions	O
are	O
not	O
exclusive	O
;	O
networks	O
commonly	O
exhibit	O
both	O
behaviors	O
where	O
some	O
nodes	O
exhibit	O
homophily	O
while	O
others	O
reflect	O
structural	O
equivalence	O
.	O
	
We	O
observe	O
that	O
BFS	B-Method
and	I-Method
DFS	I-Method
strategies	I-Method
play	O
a	O
key	O
role	O
in	O
producing	O
representations	O
that	O
reflect	O
either	O
of	O
the	O
above	O
equivalences	O
.	O
	
In	O
particular	O
,	O
the	O
neighborhoods	O
sampled	O
by	O
BFS	B-Method
lead	O
to	O
embeddings	O
that	O
correspond	O
closely	O
to	O
structural	O
equivalence	O
.	O
	
Intuitively	O
,	O
we	O
note	O
that	O
in	O
order	O
to	O
ascertain	O
structural	O
equivalence	O
,	O
it	O
is	O
often	O
sufficient	O
to	O
characterize	O
the	O
local	O
neighborhoods	O
accurately	O
.	O
	
For	O
example	O
,	O
structural	O
equivalence	O
based	O
on	O
network	O
roles	O
such	O
as	O
bridges	O
and	O
hubs	O
can	O
be	O
inferred	O
just	O
by	O
observing	O
the	O
immediate	O
neighborhoods	O
of	O
each	O
node	O
.	O
	
By	O
restricting	O
search	O
to	O
nearby	O
nodes	O
,	O
BFS	B-Method
achieves	O
this	O
characterization	O
and	O
obtains	O
a	O
microscopic	O
view	O
of	O
the	O
neighborhood	O
of	O
every	O
node	O
.	O
	
Additionally	O
,	O
in	O
BFS	O
,	O
nodes	O
in	O
the	O
sampled	O
neighborhoods	O
tend	O
to	O
repeat	O
many	O
times	O
.	O
	
This	O
is	O
also	O
important	O
as	O
it	O
reduces	O
the	O
variance	O
in	O
characterizing	O
the	O
distribution	O
of	O
1	O
-	O
hop	O
nodes	O
with	O
respect	O
the	O
source	O
node	O
.	O
	
However	O
,	O
a	O
very	O
small	O
portion	O
of	O
the	O
graph	O
is	O
explored	O
for	O
any	O
given	O
.	O
	
The	O
opposite	O
is	O
true	O
for	O
DFS	B-Method
which	O
can	O
explore	O
larger	O
parts	O
of	O
the	O
network	O
as	O
it	O
can	O
move	O
further	O
away	O
from	O
the	O
source	O
node	O
(	O
with	O
sample	O
size	O
being	O
fixed	O
)	O
.	O
	
In	O
DFS	B-Method
,	O
the	O
sampled	O
nodes	O
more	O
accurately	O
reflect	O
a	O
macro	O
-	O
view	O
of	O
the	O
neighborhood	O
which	O
is	O
essential	O
in	O
inferring	B-Task
communities	I-Task
based	O
on	O
homophily	O
.	O
	
However	O
,	O
the	O
issue	O
with	O
DFS	B-Method
is	O
that	O
it	O
is	O
important	O
to	O
not	O
only	O
infer	O
which	O
node	O
-	O
to	O
-	O
node	O
dependencies	O
exist	O
in	O
a	O
network	O
,	O
but	O
also	O
to	O
characterize	O
the	O
exact	O
nature	O
of	O
these	O
dependencies	O
.	O
	
This	O
is	O
hard	O
given	O
we	O
have	O
a	O
constrain	O
on	O
the	O
sample	O
size	O
and	O
a	O
large	O
neighborhood	O
to	O
explore	O
,	O
resulting	O
in	O
high	O
variance	O
.	O
	
Secondly	O
,	O
moving	O
to	O
much	O
greater	O
depths	O
leads	O
to	O
complex	O
dependencies	O
since	O
a	O
sampled	O
node	O
may	O
be	O
far	O
from	O
the	O
source	O
and	O
potentially	O
less	O
representative	O
.	O
	
subsection	O
:	O
node2vec	B-Method
	
Building	O
on	O
the	O
above	O
observations	O
,	O
we	O
design	O
a	O
flexible	O
neighborhood	B-Method
sampling	I-Method
strategy	I-Method
which	O
allows	O
us	O
to	O
smoothly	O
interpolate	O
between	O
BFS	B-Method
and	O
DFS	B-Method
.	O
	
We	O
achieve	O
this	O
by	O
developing	O
a	O
flexible	O
biased	B-Method
random	I-Method
walk	I-Method
procedure	I-Method
that	O
can	O
explore	O
neighborhoods	O
in	O
a	O
BFS	O
as	O
well	O
as	O
DFS	B-Method
fashion	I-Method
.	O
	
subsubsection	O
:	O
Random	B-Method
Walks	I-Method
	
Formally	O
,	O
given	O
a	O
source	O
node	O
,	O
we	O
simulate	O
a	O
random	B-Method
walk	I-Method
of	I-Method
fixed	I-Method
length	I-Method
.	O
	
Let	O
denote	O
the	O
th	O
node	O
in	O
the	O
walk	O
,	O
starting	O
with	O
.	O
	
Nodes	O
are	O
generated	O
by	O
the	O
following	O
distribution	O
:	O
where	O
is	O
the	O
unnormalized	O
transition	O
probability	O
between	O
nodes	O
and	O
,	O
and	O
is	O
the	O
normalizing	O
constant	O
.	O
	
subsubsection	O
:	O
Search	O
bias	O
	
The	O
simplest	O
way	O
to	O
bias	O
our	O
random	O
walks	O
would	O
be	O
to	O
sample	O
the	O
next	O
node	O
based	O
on	O
the	O
static	O
edge	O
weights	O
i.e.	O
,	O
.	O
	
(	O
In	O
case	O
of	O
unweighted	B-Task
graphs	I-Task
.	O
)	O
	
However	O
,	O
this	O
does	O
not	O
allow	O
us	O
to	O
account	O
for	O
the	O
network	O
structure	O
and	O
guide	O
our	O
search	B-Method
procedure	I-Method
to	O
explore	O
different	O
types	O
of	O
network	O
neighborhoods	O
.	O
	
Additionally	O
,	O
unlike	O
BFS	B-Method
and	I-Method
DFS	I-Method
which	O
are	O
extreme	O
sampling	B-Method
paradigms	I-Method
suited	O
for	O
structural	B-Task
equivalence	I-Task
and	O
homophily	B-Task
respectively	I-Task
,	O
our	O
random	B-Method
walks	I-Method
should	O
accommodate	O
for	O
the	O
fact	O
that	O
these	O
notions	O
of	O
equivalence	O
are	O
not	O
competing	O
or	O
exclusive	O
,	O
and	O
real	O
-	O
world	O
networks	O
commonly	O
exhibit	O
a	O
mixture	O
of	O
both	O
.	O
	
We	O
define	O
a	O
2	B-Method
order	I-Method
random	I-Method
walk	I-Method
with	O
two	O
parameters	O
and	O
which	O
guide	O
the	O
walk	O
:	O
Consider	O
a	O
random	B-Method
walk	I-Method
that	O
just	O
traversed	O
edge	O
and	O
now	O
resides	O
at	O
node	O
(	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
The	O
walk	O
now	O
needs	O
to	O
decide	O
on	O
the	O
next	O
step	O
so	O
it	O
evaluates	O
the	O
transition	O
probabilities	O
on	O
edges	O
leading	O
from	O
.	O
	
We	O
set	O
the	O
unnormalized	O
transition	O
probability	O
to	O
,	O
where	O
and	O
denotes	O
the	O
shortest	O
path	O
distance	O
between	O
nodes	O
and	O
.	O
	
Note	O
that	O
must	O
be	O
one	O
of	O
,	O
and	O
hence	O
,	O
the	O
two	O
parameters	O
are	O
necessary	O
and	O
sufficient	O
to	O
guide	O
the	O
walk	O
.	O
	
Intuitively	O
,	O
parameters	O
and	O
control	O
how	O
fast	O
the	O
walk	O
explores	O
and	O
leaves	O
the	O
neighborhood	O
of	O
starting	O
node	O
.	O
	
In	O
particular	O
,	O
the	O
parameters	O
allow	O
our	O
search	B-Method
procedure	I-Method
to	O
(	O
approximately	O
)	O
interpolate	O
between	O
BFS	B-Method
and	O
DFS	B-Method
and	O
thereby	O
reflect	O
an	O
affinity	O
for	O
different	O
notions	O
of	O
node	O
equivalences	O
.	O
	
Return	O
parameter	O
,	O
	
p.	O
Parameter	O
controls	O
the	O
likelihood	O
of	O
immediately	O
revisiting	O
a	O
node	O
in	O
the	O
walk	O
.	O
	
Setting	O
it	O
to	O
a	O
high	O
value	O
(	O
)	O
ensures	O
that	O
we	O
are	O
less	O
likely	O
to	O
sample	O
an	O
already	O
-	O
visited	O
node	O
in	O
the	O
following	O
two	O
steps	O
(	O
unless	O
the	O
next	O
node	O
in	O
the	O
walk	O
had	O
no	O
other	O
neighbor	O
)	O
.	O
	
This	O
strategy	O
encourages	O
moderate	O
exploration	O
and	O
avoids	O
-	O
hop	O
redundancy	O
in	O
sampling	B-Task
.	O
	
On	O
the	O
other	O
hand	O
,	O
if	O
is	O
low	O
(	O
)	O
,	O
it	O
would	O
lead	O
the	O
walk	O
to	O
backtrack	O
a	O
step	O
(	O
Figure	O
[	O
reference	O
]	O
)	O
and	O
this	O
would	O
keep	O
the	O
walk	O
“	O
local	O
”	O
close	O
to	O
the	O
starting	O
node	O
.	O
	
In	O
-	O
out	O
parameter	O
,	O
	
q.	O
Parameter	O
allows	O
the	O
search	O
to	O
differentiate	O
between	O
“	O
inward	O
”	O
and	O
“	O
outward	O
”	O
nodes	O
.	O
	
Going	O
back	O
to	O
Figure	O
[	O
reference	O
]	O
,	O
if	O
,	O
the	O
random	O
walk	O
is	O
biased	O
towards	O
nodes	O
close	O
to	O
node	O
.	O
	
Such	O
walks	O
obtain	O
a	O
local	O
view	O
of	O
the	O
underlying	O
graph	O
with	O
respect	O
to	O
the	O
start	O
node	O
in	O
the	O
walk	O
and	O
approximate	O
BFS	O
behavior	O
in	O
the	O
sense	O
that	O
our	O
samples	O
comprise	O
of	O
nodes	O
within	O
a	O
small	O
locality	O
.	O
	
In	O
contrast	O
,	O
if	O
,	O
the	O
walk	O
is	O
more	O
inclined	O
to	O
visit	O
nodes	O
which	O
are	O
further	O
away	O
from	O
the	O
node	O
.	O
	
Such	O
behavior	O
is	O
reflective	O
of	O
DFS	B-Method
which	O
encourages	O
outward	B-Task
exploration	I-Task
.	O
	
However	O
,	O
an	O
essential	O
difference	O
here	O
is	O
that	O
we	O
achieve	O
DFS	B-Method
-	I-Method
like	I-Method
exploration	I-Method
within	O
the	O
random	B-Method
walk	I-Method
framework	I-Method
.	O
	
Hence	O
,	O
the	O
sampled	O
nodes	O
are	O
not	O
at	O
strictly	O
increasing	O
distances	O
from	O
a	O
given	O
source	O
node	O
,	O
but	O
in	O
turn	O
,	O
we	O
benefit	O
from	O
tractable	O
preprocessing	B-Metric
and	O
superior	O
sampling	B-Metric
efficiency	I-Metric
of	O
random	B-Method
walks	I-Method
.	O
	
Note	O
that	O
by	O
setting	O
to	O
be	O
a	O
function	O
of	O
the	O
preceeding	O
node	O
in	O
the	O
walk	O
,	O
the	O
random	B-Method
walks	I-Method
are	O
2	B-Method
order	I-Method
Markovian	I-Method
.	O
	
Benefits	O
of	O
random	B-Method
walks	I-Method
.	O
	
There	O
are	O
several	O
benefits	O
of	O
random	B-Method
walks	I-Method
over	O
pure	B-Method
BFS	I-Method
/	I-Method
DFS	I-Method
approaches	I-Method
.	O
	
Random	B-Method
walks	I-Method
are	O
computationally	O
efficient	O
in	O
terms	O
of	O
both	O
space	B-Metric
and	I-Metric
time	I-Metric
requirements	I-Metric
.	O
	
The	O
space	B-Metric
complexity	I-Metric
to	O
store	O
the	O
immediate	O
neighbors	O
of	O
every	O
node	O
in	O
the	O
graph	O
is	O
.	O
	
For	O
2	B-Task
order	I-Task
random	I-Task
walks	I-Task
,	O
it	O
is	O
helpful	O
to	O
store	O
the	O
interconnections	O
between	O
the	O
neighbors	O
of	O
every	O
node	O
,	O
which	O
incurs	O
a	O
space	B-Metric
complexity	I-Metric
of	O
where	O
is	O
the	O
average	O
degree	O
of	O
the	O
graph	O
and	O
is	O
usually	O
small	O
for	O
real	B-Task
-	I-Task
world	I-Task
networks	I-Task
.	O
	
The	O
other	O
key	O
advantage	O
of	O
random	B-Method
walks	I-Method
over	O
classic	O
search	B-Method
-	I-Method
based	I-Method
sampling	I-Method
strategies	I-Method
is	O
its	O
time	B-Metric
complexity	I-Metric
.	O
	
In	O
particular	O
,	O
by	O
imposing	O
graph	O
connectivity	O
in	O
the	O
sample	B-Method
generation	I-Method
process	I-Method
,	O
random	B-Method
walks	I-Method
provide	O
a	O
convenient	O
mechanism	O
to	O
increase	O
the	O
effective	B-Metric
sampling	I-Metric
rate	I-Metric
by	O
reusing	O
samples	O
across	O
different	O
source	O
nodes	O
.	O
	
By	O
simulating	O
a	O
random	O
walk	O
of	O
length	O
we	O
can	O
generate	O
samples	O
for	O
nodes	O
at	O
once	O
due	O
to	O
the	O
Markovian	O
nature	O
of	O
the	O
random	O
walk	O
.	O
	
Hence	O
,	O
our	O
effective	B-Metric
complexity	I-Metric
is	O
per	O
sample	O
.	O
	
For	O
example	O
,	O
in	O
Figure	O
[	O
reference	O
]	O
we	O
sample	O
a	O
random	O
walk	O
of	O
length	O
,	O
which	O
results	O
in	O
,	O
and	O
.	O
	
Note	O
that	O
sample	O
reuse	O
can	O
introduce	O
some	O
bias	O
in	O
the	O
overall	O
procedure	O
.	O
	
However	O
,	O
we	O
observe	O
that	O
it	O
greatly	O
improves	O
the	O
efficiency	O
.	O
	
subsubsection	O
:	O
The	O
node2vec	B-Method
algorithm	O
	
[	O
h	O
]	O
LearnFeatures	O
(	O
Graph	O
,	O
Dimensions	O
,	O
Walks	O
per	O
node	O
,	O
Walk	O
length	O
,	O
Context	O
size	O
,	O
Return	O
,	O
In	O
-	O
out	O
)	O
PreprocessModifiedWeights	O
(	O
)	O
	
Initialize	O
to	O
Empty	O
to	O
nodes	O
node2vecWalk	O
(	O
)	O
	
Append	O
to	O
StochasticGradientDescent	B-Method
(	I-Method
,	O
,	O
)	O
return	O
node2vecWalk	O
	
(	O
Graph	O
,	O
Start	O
node	O
,	O
Length	O
)	O
	
Inititalize	O
to	O
to	O
GetNeighbors	O
(	O
,	O
)	O
AliasSample	O
(	O
)	O
	
Append	O
to	O
return	O
The	O
node2vec	B-Method
algorithm	O
.	O
	
The	O
pseudocode	O
for	O
node2vec	B-Method
,	O
is	O
given	O
in	O
Algorithm	O
[	O
reference	O
]	O
.	O
	
In	O
any	O
random	B-Method
walk	I-Method
,	O
there	O
is	O
an	O
implicit	O
bias	O
due	O
to	O
the	O
choice	O
of	O
the	O
start	O
node	O
.	O
	
Since	O
we	O
learn	O
representations	O
for	O
all	O
nodes	O
,	O
we	O
offset	O
this	O
bias	O
by	O
simulating	O
random	O
walks	O
of	O
fixed	O
length	O
starting	O
from	O
every	O
node	O
.	O
	
At	O
every	O
step	O
of	O
the	O
walk	O
,	O
sampling	B-Task
is	O
done	O
based	O
on	O
the	O
transition	O
probabilities	O
.	O
	
The	O
transition	O
probabilities	O
for	O
the	O
2	B-Method
order	I-Method
Markov	I-Method
chain	I-Method
can	O
be	O
precomputed	O
and	O
hence	O
,	O
sampling	B-Task
of	I-Task
nodes	I-Task
while	O
simulating	O
the	O
random	O
walk	O
can	O
be	O
done	O
efficiently	O
in	O
time	O
using	O
alias	B-Method
sampling	I-Method
.	O
	
The	O
three	O
phases	O
of	O
node2vec	B-Method
,	O
i.e.	O
,	O
preprocessing	B-Task
to	O
compute	O
transition	O
probabilities	O
,	O
random	B-Method
walk	I-Method
simulations	I-Method
and	O
optimization	B-Task
using	O
SGD	B-Method
,	O
are	O
executed	O
sequentially	O
.	O
	
Each	O
phase	O
is	O
parallelizable	O
and	O
executed	O
asynchronously	O
,	O
contributing	O
to	O
the	O
overall	O
scalability	O
of	O
node2vec	B-Method
.	O
	
node2vec	B-Method
is	O
available	O
at	O
:	O
.	O
	
subsection	O
:	O
Learning	O
edge	O
features	O
	
The	O
node2vec	B-Method
algorithm	O
provides	O
a	O
semi	B-Method
-	I-Method
supervised	I-Method
method	I-Method
to	O
learn	O
rich	O
feature	O
representations	O
for	O
nodes	O
in	O
a	O
network	O
.	O
	
However	O
,	O
we	O
are	O
often	O
interested	O
in	O
prediction	B-Task
tasks	I-Task
involving	O
pairs	O
of	O
nodes	O
instead	O
of	O
individual	O
nodes	O
.	O
	
For	O
instance	O
,	O
in	O
link	B-Task
prediction	I-Task
,	O
we	O
predict	O
whether	O
a	O
link	O
exists	O
between	O
two	O
nodes	O
in	O
a	O
network	O
.	O
	
Since	O
our	O
random	B-Method
walks	I-Method
are	O
naturally	O
based	O
on	O
the	O
connectivity	O
structure	O
between	O
nodes	O
in	O
the	O
underlying	O
network	O
,	O
we	O
extend	O
them	O
to	O
pairs	O
of	O
nodes	O
using	O
a	O
bootstrapping	B-Method
approach	I-Method
over	O
the	O
feature	B-Method
representations	I-Method
of	O
the	O
individual	O
nodes	O
.	O
	
Given	O
two	O
nodes	O
and	O
,	O
we	O
define	O
a	O
binary	O
operator	O
over	O
the	O
corresponding	O
feature	O
vectors	O
and	O
in	O
order	O
to	O
generate	O
a	O
representation	O
such	O
that	O
where	O
is	O
the	O
representation	O
size	O
for	O
the	O
pair	O
.	O
	
We	O
want	O
our	O
operators	O
to	O
be	O
generally	O
defined	O
for	O
any	O
pair	O
of	O
nodes	O
,	O
even	O
if	O
an	O
edge	O
does	O
not	O
exist	O
between	O
the	O
pair	O
since	O
doing	O
so	O
makes	O
the	O
representations	O
useful	O
for	O
link	B-Task
prediction	I-Task
where	O
our	O
test	O
set	O
contains	O
both	O
true	O
and	O
false	O
edges	O
(	O
i.e.	O
,	O
do	O
not	O
exist	O
)	O
.	O
	
We	O
consider	O
several	O
choices	O
for	O
the	O
operator	O
such	O
that	O
which	O
are	O
summarized	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
Experiments	O
	
The	O
objective	O
in	O
Eq	O
.	O
	
[	O
reference	O
]	O
is	O
independent	O
of	O
any	O
downstream	B-Task
task	I-Task
and	O
the	O
flexibility	O
in	O
exploration	B-Task
offered	O
by	O
node2vec	B-Method
lends	O
the	O
learned	O
feature	B-Method
representations	I-Method
to	O
a	O
wide	O
variety	O
of	O
network	B-Task
analysis	I-Task
settings	I-Task
discussed	O
below	O
.	O
	
subsection	O
:	O
Case	O
Study	O
:	O
Les	O
Misérables	O
network	O
	
In	O
Section	O
[	O
reference	O
]	O
we	O
observed	O
that	O
BFS	B-Method
and	I-Method
DFS	I-Method
strategies	I-Method
represent	O
extreme	O
ends	O
on	O
the	O
spectrum	O
of	O
embedding	O
nodes	O
based	O
on	O
the	O
principles	O
of	O
homophily	O
(	O
i.e.	O
,	O
network	O
communities	O
)	O
and	O
structural	O
equivalence	O
(	O
i.e.	O
,	O
structural	O
roles	O
of	O
nodes	O
)	O
.	O
	
We	O
now	O
aim	O
to	O
empirically	O
demonstrate	O
this	O
fact	O
and	O
show	O
that	O
node2vec	B-Method
in	O
fact	O
can	O
discover	O
embeddings	O
that	O
obey	O
both	O
principles	O
.	O
	
We	O
use	O
a	O
network	O
where	O
nodes	O
correspond	O
to	O
characters	O
in	O
the	O
novel	O
Les	O
Misérables	O
and	O
edges	O
connect	O
coappearing	O
characters	O
.	O
	
The	O
network	O
has	O
77	O
nodes	O
and	O
254	O
edges	O
.	O
	
We	O
set	O
and	O
run	O
node2vec	B-Method
to	O
learn	O
feature	B-Method
representation	I-Method
for	O
every	O
node	O
in	O
the	O
network	O
.	O
	
The	O
feature	B-Method
representations	I-Method
are	O
clustered	O
using	O
-	O
means	O
.	O
	
We	O
then	O
visualize	O
the	O
original	O
network	O
in	O
two	O
dimensions	O
with	O
nodes	O
now	O
assigned	O
colors	O
based	O
on	O
their	O
clusters	O
.	O
	
Figure	O
[	O
reference	O
]	O
	
(	O
top	O
)	O
shows	O
the	O
example	O
when	O
we	O
set	O
.	O
	
Notice	O
how	O
regions	O
of	O
the	O
network	O
(	O
i.e.	O
,	O
network	O
communities	O
)	O
are	O
colored	O
using	O
the	O
same	O
color	O
.	O
	
In	O
this	O
setting	O
node2vec	B-Method
discovers	O
clusters	O
/	O
communities	O
of	O
characters	O
that	O
frequently	O
interact	O
with	O
each	O
other	O
in	O
the	O
major	O
sub	O
-	O
plots	O
of	O
the	O
novel	O
.	O
	
Since	O
the	O
edges	O
between	O
characters	O
are	O
based	O
on	O
coappearances	O
,	O
we	O
can	O
conclude	O
this	O
characterization	O
closely	O
relates	O
with	O
homophily	O
.	O
	
In	O
order	O
to	O
discover	O
which	O
nodes	O
have	O
the	O
same	O
structural	O
roles	O
we	O
use	O
the	O
same	O
network	O
but	O
set	O
,	O
use	O
node2vec	B-Method
to	O
get	O
node	O
features	O
and	O
then	O
cluster	O
the	O
nodes	O
based	O
on	O
the	O
obtained	O
features	O
.	O
	
Here	O
node2vec	B-Method
obtains	O
a	O
complementary	O
assignment	O
of	O
node	O
to	O
clusters	O
such	O
that	O
the	O
colors	O
correspond	O
to	O
structural	O
equivalence	O
as	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
	
(	O
bottom	O
)	O
.	O
	
For	O
instance	O
,	O
node2vec	B-Method
embeds	O
blue	O
-	O
colored	O
nodes	O
close	O
together	O
.	O
	
These	O
nodes	O
represent	O
characters	O
that	O
act	O
as	O
bridges	O
between	O
different	O
sub	O
-	O
plots	O
of	O
the	O
novel	O
.	O
	
Similarly	O
,	O
the	O
yellow	O
nodes	O
mostly	O
represent	O
characters	O
that	O
are	O
at	O
the	O
periphery	O
and	O
have	O
limited	O
interactions	O
.	O
	
One	O
could	O
assign	O
alternate	O
semantic	O
interpretations	O
to	O
these	O
clusters	O
of	O
nodes	O
,	O
but	O
the	O
key	O
takeaway	O
is	O
that	O
node2vec	B-Method
is	O
not	O
tied	O
to	O
a	O
particular	O
notion	O
of	O
equivalence	O
.	O
	
As	O
we	O
show	O
through	O
our	O
experiments	O
,	O
these	O
equivalence	O
notions	O
are	O
commonly	O
exhibited	O
in	O
most	O
real	B-Task
-	I-Task
world	I-Task
networks	I-Task
and	O
have	O
a	O
significant	O
impact	O
on	O
the	O
performance	O
of	O
the	O
learned	O
representations	O
for	O
prediction	B-Task
tasks	I-Task
.	O
	
subsection	O
:	O
Experimental	O
setup	O
	
Our	O
experiments	O
evaluate	O
the	O
feature	B-Method
representations	I-Method
obtained	O
through	O
node2vec	B-Method
on	O
standard	O
supervised	B-Task
learning	I-Task
tasks	I-Task
:	O
multi	B-Task
-	I-Task
label	I-Task
classification	I-Task
for	O
nodes	B-Task
and	O
link	B-Task
prediction	I-Task
for	O
edges	O
.	O
	
For	O
both	O
tasks	O
,	O
we	O
evaluate	O
the	O
performance	O
of	O
node2vec	B-Method
against	O
the	O
following	O
feature	B-Method
learning	I-Method
algorithms	I-Method
:	O
	
Spectral	B-Method
clustering	I-Method
	
:	O
This	O
is	O
a	O
matrix	B-Method
factorization	I-Method
approach	I-Method
in	O
which	O
we	O
take	O
the	O
top	O
eigenvectors	O
of	O
the	O
normalized	O
Laplacian	O
matrix	O
of	O
graph	O
as	O
the	O
feature	B-Method
vector	I-Method
representations	I-Method
for	O
nodes	O
.	O
	
DeepWalk	B-Method
:	O
	
This	O
approach	O
learns	O
-	B-Method
dimensional	I-Method
feature	I-Method
representations	I-Method
by	O
simulating	O
uniform	B-Method
random	I-Method
walks	I-Method
.	O
	
The	O
sampling	B-Method
strategy	I-Method
in	O
DeepWalk	B-Method
can	O
be	O
seen	O
as	O
a	O
special	O
case	O
of	O
node2vec	B-Method
with	O
and	O
.	O
	
LINE	B-Method
:	O
	
This	O
approach	O
learns	O
-	B-Method
dimensional	I-Method
feature	I-Method
representations	I-Method
in	O
two	O
separate	O
phases	O
.	O
	
In	O
the	O
first	O
phase	O
,	O
it	O
learns	O
dimensions	O
by	O
BFS	B-Method
-	I-Method
style	I-Method
simulations	I-Method
over	O
immediate	O
neighbors	O
of	O
nodes	O
.	O
	
In	O
the	O
second	O
phase	O
,	O
it	O
learns	O
the	O
next	O
dimensions	O
by	O
sampling	O
nodes	O
strictly	O
at	O
a	O
2	O
-	O
hop	O
distance	O
from	O
the	O
source	O
nodes	O
.	O
	
We	O
exclude	O
other	O
matrix	B-Method
factorization	I-Method
approaches	I-Method
which	O
have	O
already	O
been	O
shown	O
to	O
be	O
inferior	O
to	O
DeepWalk	B-Method
.	O
	
We	O
also	O
exclude	O
a	O
recent	O
approach	O
,	O
GraRep	B-Method
,	O
that	O
generalizes	O
LINE	B-Method
to	O
incorporate	O
information	O
from	O
network	O
neighborhoods	O
beyond	O
2	O
-	O
hops	O
,	O
but	O
is	O
unable	O
to	O
efficiently	O
scale	O
to	O
large	O
networks	O
.	O
	
In	O
contrast	O
to	O
the	O
setup	O
used	O
in	O
prior	O
work	O
for	O
evaluating	O
sampling	B-Method
-	I-Method
based	I-Method
feature	I-Method
learning	I-Method
algorithms	I-Method
,	O
we	O
generate	O
an	O
equal	O
number	O
of	O
samples	O
for	O
each	O
method	O
and	O
then	O
evaluate	O
the	O
quality	O
of	O
the	O
obtained	O
features	O
on	O
the	O
prediction	B-Task
task	I-Task
.	O
	
In	O
doing	O
so	O
,	O
we	O
discount	O
for	O
performance	O
gain	O
observed	O
purely	O
because	O
of	O
the	O
implementation	B-Method
language	I-Method
(	O
C	B-Method
/	I-Method
C	I-Method
++/	I-Method
Python	I-Method
)	O
since	O
it	O
is	O
secondary	O
to	O
the	O
algorithm	O
.	O
	
Thus	O
,	O
in	O
the	O
sampling	B-Task
phase	I-Task
,	O
the	O
parameters	O
for	O
DeepWalk	B-Method
,	O
LINE	B-Method
and	O
node2vec	B-Method
are	O
set	O
such	O
that	O
they	O
generate	O
equal	O
number	O
of	O
samples	O
at	O
runtime	O
.	O
	
As	O
an	O
example	O
,	O
if	O
is	O
the	O
overall	O
sampling	O
budget	O
,	O
then	O
the	O
node2vec	B-Method
parameters	O
satisfy	O
.	O
	
In	O
the	O
optimization	B-Task
phase	I-Task
,	O
all	O
these	O
benchmarks	O
optimize	O
using	O
SGD	B-Method
with	O
two	O
key	O
differences	O
that	O
we	O
correct	O
for	O
.	O
	
First	O
,	O
DeepWalk	B-Method
uses	O
hierarchical	B-Method
sampling	I-Method
to	O
approximate	O
the	O
softmax	O
probabilities	O
with	O
an	O
objective	O
similar	O
to	O
the	O
one	O
use	O
by	O
node2vec	B-Method
.	O
	
However	O
,	O
hierarchical	B-Method
softmax	I-Method
is	O
inefficient	O
when	O
compared	O
with	O
negative	B-Method
sampling	I-Method
.	O
	
Hence	O
,	O
keeping	O
everything	O
else	O
the	O
same	O
,	O
we	O
switch	O
to	O
negative	B-Task
sampling	I-Task
in	O
DeepWalk	B-Method
which	O
is	O
also	O
the	O
de	O
facto	O
approximation	O
in	O
node2vec	B-Method
and	O
LINE	B-Method
.	O
	
Second	O
,	O
both	O
node2vec	B-Method
and	O
DeepWalk	B-Method
have	O
a	O
parameter	O
for	O
the	O
number	O
of	O
context	O
neighborhood	O
nodes	O
to	O
optimize	O
for	O
and	O
the	O
greater	O
the	O
number	O
,	O
the	O
more	O
rounds	O
of	O
optimization	B-Task
are	O
required	O
.	O
	
This	O
parameter	O
is	O
set	O
to	O
unity	O
for	O
LINE	B-Method
,	O
but	O
since	O
LINE	B-Method
completes	O
a	O
single	O
epoch	O
quicker	O
than	O
other	O
approaches	O
,	O
we	O
let	O
it	O
run	O
for	O
epochs	O
.	O
	
The	O
parameter	O
settings	O
used	O
for	O
node2vec	B-Method
are	O
in	O
line	O
with	O
typical	O
values	O
used	O
for	O
DeepWalk	B-Method
and	O
LINE	B-Method
.	O
	
Specifically	O
,	O
we	O
set	O
,	O
,	O
,	O
,	O
and	O
the	O
optimization	B-Task
is	O
run	O
for	O
a	O
single	O
epoch	O
.	O
	
We	O
repeat	O
our	O
experiments	O
for	O
random	O
seed	O
initializations	O
,	O
and	O
our	O
results	O
are	O
statistically	O
significant	O
with	O
a	O
p	O
-	O
value	O
of	O
less	O
than	O
0.01	O
.	O
	
The	O
best	O
in	O
-	O
out	O
and	O
return	O
hyperparameters	O
were	O
learned	O
using	O
10	B-Method
-	I-Method
fold	I-Method
cross	I-Method
-	I-Method
validation	I-Method
on	O
10	O
%	O
labeled	O
data	O
with	O
a	O
grid	O
search	O
over	O
.	O
	
subsection	O
:	O
Multi	B-Task
-	I-Task
label	I-Task
classification	I-Task
	
In	O
the	O
multi	B-Task
-	I-Task
label	I-Task
classification	I-Task
setting	I-Task
,	O
every	O
node	O
is	O
assigned	O
one	O
or	O
more	O
labels	O
from	O
a	O
finite	O
set	O
.	O
	
During	O
the	O
training	O
phase	O
,	O
we	O
observe	O
a	O
certain	O
fraction	O
of	O
nodes	O
and	O
all	O
their	O
labels	O
.	O
	
The	O
task	O
is	O
to	O
predict	O
the	O
labels	O
for	O
the	O
remaining	O
nodes	O
.	O
	
This	O
is	O
a	O
challenging	O
task	O
especially	O
if	O
is	O
large	O
.	O
	
We	O
utilize	O
the	O
following	O
datasets	O
:	O
	
BlogCatalog	B-Material
:	O
	
This	O
is	O
a	O
network	O
of	O
social	O
relationships	O
of	O
the	O
bloggers	O
listed	O
on	O
the	O
BlogCatalog	B-Material
website	O
.	O
	
The	O
labels	O
represent	O
blogger	O
interests	O
inferred	O
through	O
the	O
meta	O
-	O
data	O
provided	O
by	O
the	O
bloggers	O
.	O
	
The	O
network	O
has	O
10	O
,	O
312	O
nodes	O
,	O
333	O
,	O
983	O
edges	O
,	O
and	O
39	O
different	O
labels	O
.	O
	
Protein	B-Task
-	I-Task
Protein	I-Task
Interactions	I-Task
(	O
PPI	B-Task
)	O
:	O
	
We	O
use	O
a	O
subgraph	O
of	O
the	O
PPI	B-Method
network	I-Method
for	O
Homo	B-Material
Sapiens	I-Material
.	O
	
The	O
subgraph	O
corresponds	O
to	O
the	O
graph	O
induced	O
by	O
nodes	O
for	O
which	O
we	O
could	O
obtain	O
labels	O
from	O
the	O
hallmark	O
gene	O
sets	O
and	O
represent	O
biological	O
states	O
.	O
	
The	O
network	O
has	O
3	O
,	O
890	O
nodes	O
,	O
76	O
,	O
584	O
edges	O
,	O
and	O
50	O
different	O
labels	O
.	O
	
Wikipedia	B-Material
:	O
	
This	O
is	O
a	O
cooccurrence	B-Method
network	I-Method
of	O
words	O
appearing	O
in	O
the	O
first	O
million	O
bytes	O
of	O
the	O
Wikipedia	B-Material
dump	O
.	O
	
The	O
labels	O
represent	O
the	O
Part	O
-	O
of	O
-	O
Speech	O
(	O
POS	O
)	O
tags	O
inferred	O
using	O
the	O
Stanford	B-Method
POS	I-Method
-	I-Method
Tagger	I-Method
.	O
	
The	O
network	O
has	O
4	O
,	O
777	O
nodes	O
,	O
184	O
,	O
812	O
edges	O
,	O
and	O
40	O
different	O
labels	O
.	O
	
All	O
these	O
networks	O
exhibit	O
a	O
fair	O
mix	O
of	O
homophilic	O
and	O
structural	O
equivalences	O
.	O
	
For	O
example	O
,	O
we	O
expect	O
the	O
social	O
network	O
of	O
bloggers	O
to	O
exhibit	O
strong	O
homophily	O
-	O
based	O
relationships	O
;	O
however	O
,	O
there	O
might	O
also	O
be	O
some	O
“	O
familiar	O
strangers	O
”	O
,	O
i.e.	O
,	O
bloggers	O
that	O
do	O
not	O
interact	O
but	O
share	O
interests	O
and	O
hence	O
are	O
structurally	O
equivalent	O
nodes	O
.	O
	
The	O
biological	O
states	O
of	O
proteins	O
in	O
a	O
protein	B-Task
-	I-Task
protein	I-Task
interaction	I-Task
network	I-Task
also	O
exhibit	O
both	O
types	O
of	O
equivalences	O
.	O
	
For	O
example	O
,	O
they	O
exhibit	O
structural	O
equivalence	O
when	O
proteins	O
perform	O
functions	O
complementary	O
to	O
those	O
of	O
neighboring	O
proteins	O
,	O
and	O
at	O
other	O
times	O
,	O
they	O
organize	O
based	O
on	O
homophily	B-Method
in	O
assisting	O
neighboring	O
proteins	O
in	O
performing	O
similar	O
functions	O
.	O
	
The	O
word	B-Method
cooccurence	I-Method
network	I-Method
is	O
fairly	O
dense	O
,	O
since	O
edges	O
exist	O
between	O
words	O
cooccuring	O
in	O
a	O
2	O
-	O
length	O
window	O
in	O
the	O
Wikipedia	B-Material
corpus	I-Material
.	O
	
Hence	O
,	O
words	O
having	O
the	O
same	O
POS	O
tags	O
are	O
not	O
hard	O
to	O
find	O
,	O
lending	O
a	O
high	O
degree	O
of	O
homophily	O
.	O
	
At	O
the	O
same	O
time	O
,	O
we	O
expect	O
some	O
structural	O
equivalence	O
in	O
the	O
POS	O
tags	O
due	O
to	O
syntactic	O
grammar	O
patterns	O
such	O
as	O
nouns	O
following	O
determiners	O
,	O
punctuations	O
succeeding	O
nouns	O
etc	O
.	O
	
Experimental	O
results	O
.	O
	
The	O
node	B-Method
feature	I-Method
representations	I-Method
are	O
input	O
to	O
a	O
one	B-Method
-	I-Method
vs	I-Method
-	I-Method
rest	I-Method
logistic	I-Method
regression	I-Method
classifier	I-Method
with	O
L2	B-Method
regularization	I-Method
.	O
	
The	O
train	O
and	O
test	O
data	O
is	O
split	O
equally	O
over	O
10	O
random	O
instances	O
.	O
	
We	O
use	O
the	O
Macro	B-Metric
-	I-Metric
F	I-Metric
scores	O
for	O
comparing	O
performance	O
in	O
Table	O
[	O
reference	O
]	O
and	O
the	O
relative	O
performance	O
gain	O
is	O
over	O
the	O
closest	O
benchmark	O
.	O
	
The	O
trends	O
are	O
similar	O
for	O
Micro	B-Metric
-	I-Metric
F	I-Metric
and	O
accuracy	B-Metric
and	O
are	O
not	O
shown	O
.	O
	
From	O
the	O
results	O
,	O
it	O
is	O
evident	O
we	O
can	O
see	O
how	O
the	O
added	O
flexibility	O
in	O
exploring	O
neighborhoods	O
allows	O
node2vec	B-Method
to	O
outperform	O
the	O
other	O
benchmark	O
algorithms	O
.	O
	
In	O
BlogCatalog	B-Material
,	O
we	O
can	O
discover	O
the	O
right	O
mix	O
of	O
homophily	O
and	O
structural	O
equivalence	O
by	O
setting	O
parameters	O
and	O
to	O
low	O
values	O
,	O
giving	O
us	O
22.3	O
%	O
gain	O
over	O
DeepWalk	B-Method
and	O
229.2	O
%	O
gain	O
over	O
LINE	B-Method
in	O
Macro	B-Metric
-	I-Metric
F	I-Metric
scores	O
.	O
	
LINE	B-Method
showed	O
worse	O
performance	O
than	O
expected	O
,	O
which	O
can	O
be	O
explained	O
by	O
its	O
inability	O
to	O
reuse	O
samples	O
,	O
a	O
feat	O
that	O
can	O
be	O
easily	O
done	O
using	O
the	O
random	B-Method
walk	I-Method
methods	I-Method
.	O
	
Even	O
in	O
our	O
other	O
two	O
networks	O
,	O
where	O
we	O
have	O
a	O
mix	O
of	O
equivalences	O
present	O
,	O
the	O
semi	B-Method
-	I-Method
supervised	I-Method
nature	I-Method
of	O
node2vec	B-Method
can	O
help	O
us	O
infer	O
the	O
appropriate	O
degree	O
of	O
exploration	O
necessary	O
for	O
feature	B-Task
learning	I-Task
.	O
	
In	O
the	O
case	O
of	O
PPI	B-Task
network	I-Task
,	O
the	O
best	O
exploration	B-Method
strategy	I-Method
(	O
,	O
)	O
turns	O
out	O
to	O
be	O
virtually	O
indistinguishable	O
from	O
DeepWalk	B-Method
’s	O
uniform	O
(	O
,	O
)	O
exploration	O
giving	O
us	O
only	O
a	O
slight	O
edge	O
over	O
DeepWalk	B-Method
by	O
avoiding	O
redudancy	O
in	O
already	O
visited	O
nodes	O
through	O
a	O
high	O
value	O
,	O
but	O
a	O
convincing	O
23.8	O
%	O
gain	O
over	O
LINE	B-Method
in	O
Macro	B-Metric
-	I-Metric
F	I-Metric
scores	O
.	O
	
However	O
,	O
in	O
general	O
,	O
the	O
uniform	O
random	O
walks	O
can	O
be	O
much	O
worse	O
than	O
the	O
exploration	B-Method
strategy	I-Method
learned	O
by	O
node2vec	B-Method
.	O
	
As	O
we	O
can	O
see	O
in	O
the	O
Wikipedia	B-Material
word	O
cooccurrence	O
network	O
,	O
uniform	O
walks	O
can	O
not	O
guide	O
the	O
search	B-Method
procedure	I-Method
towards	O
the	O
best	O
samples	O
and	O
hence	O
,	O
we	O
achieve	O
a	O
gain	O
of	O
21.8	O
%	O
over	O
DeepWalk	B-Method
and	O
33.2	O
%	O
over	O
LINE	B-Method
.	O
	
For	O
a	O
more	O
fine	B-Task
-	I-Task
grained	I-Task
analysis	I-Task
,	O
we	O
also	O
compare	O
performance	O
while	O
varying	O
the	O
train	O
-	O
test	O
split	O
from	O
10	O
%	O
to	O
90	O
%	O
,	O
while	O
learning	O
parameters	O
and	O
on	O
10	O
%	O
of	O
the	O
data	O
as	O
before	O
.	O
	
For	O
brevity	O
,	O
we	O
summarize	O
the	O
results	O
for	O
the	O
Micro	B-Metric
-	I-Metric
F	I-Metric
and	O
Macro	B-Metric
-	I-Metric
F	I-Metric
scores	O
graphically	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Here	O
we	O
make	O
similar	O
observations	O
.	O
	
All	O
methods	O
significantly	O
outperform	O
Spectral	B-Method
clustering	I-Method
,	O
DeepWalk	B-Method
outperforms	O
LINE	B-Method
,	O
node2vec	B-Method
consistently	O
outperforms	O
LINE	B-Method
and	O
achieves	O
large	O
improvement	O
over	O
DeepWalk	B-Method
across	O
domains	O
.	O
	
For	O
example	O
,	O
we	O
achieve	O
the	O
biggest	O
improvement	O
over	O
DeepWalk	B-Method
of	O
26.7	O
%	O
on	O
BlogCatalog	B-Material
at	O
70	O
%	O
labeled	O
data	O
.	O
	
In	O
the	O
worst	O
case	O
,	O
the	O
search	B-Method
phase	I-Method
has	O
little	O
bearing	O
on	O
learned	O
representations	O
in	O
which	O
case	O
node2vec	B-Method
is	O
equivalent	O
to	O
DeepWalk	B-Method
.	O
	
Similarly	O
,	O
the	O
improvements	O
are	O
even	O
more	O
striking	O
when	O
compared	O
to	O
LINE	B-Method
,	O
where	O
in	O
addition	O
to	O
drastic	O
gain	O
(	O
over	O
200	O
%	O
)	O
on	O
BlogCatalog	B-Material
,	O
we	O
observe	O
high	O
magnitude	O
improvements	O
upto	O
41.1	O
%	O
on	O
other	O
datasets	O
such	O
as	O
PPI	B-Method
while	O
training	O
on	O
just	O
10	O
%	O
labeled	O
data	O
.	O
	
[	O
b	O
]	O
0.70	O
	
[	O
b	O
]	O
0.28	O
	
subsection	O
:	O
Parameter	B-Metric
sensitivity	I-Metric
	
The	O
node2vec	B-Method
algorithm	O
involves	O
a	O
number	O
of	O
parameters	O
and	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
we	O
examine	O
how	O
the	O
different	O
choices	O
of	O
parameters	O
affect	O
the	O
performance	O
of	O
node2vec	B-Method
on	O
the	O
BlogCatalog	B-Material
dataset	O
using	O
a	O
50	O
-	O
50	O
split	O
between	O
labeled	O
and	O
unlabeled	O
data	O
.	O
	
Except	O
for	O
the	O
parameter	O
being	O
tested	O
,	O
all	O
other	O
parameters	O
assume	O
default	O
values	O
.	O
	
The	O
default	O
values	O
for	O
and	O
are	O
set	O
to	O
unity	O
.	O
	
We	O
measure	O
the	O
Macro	B-Metric
-	I-Metric
F	I-Metric
score	O
as	O
a	O
function	O
of	O
parameters	O
and	O
.	O
	
The	O
performance	O
of	O
node2vec	B-Method
improves	O
as	O
the	O
in	O
-	O
out	O
parameter	O
and	O
the	O
return	O
parameter	O
decrease	O
.	O
	
This	O
increase	O
in	O
performance	O
can	O
be	O
based	O
on	O
the	O
homophilic	O
and	O
structural	O
equivalences	O
we	O
expect	O
to	O
see	O
in	O
BlogCatalog	B-Material
.	O
	
While	O
a	O
low	O
encourages	O
outward	O
exploration	O
,	O
it	O
is	O
balanced	O
by	O
a	O
low	O
which	O
ensures	O
that	O
the	O
walk	O
does	O
not	O
go	O
too	O
far	O
from	O
the	O
start	O
node	O
.	O
	
We	O
also	O
examine	O
how	O
the	O
number	O
of	O
features	O
and	O
the	O
node	O
’s	O
neighborhood	O
parameters	O
(	O
number	O
of	O
walks	O
,	O
walk	O
length	O
,	O
and	O
neighborhood	O
size	O
)	O
affect	O
the	O
performance	O
.	O
	
We	O
observe	O
that	O
performance	O
tends	O
to	O
saturate	O
once	O
the	O
dimensions	O
of	O
the	O
representations	O
reaches	O
around	O
100	O
.	O
	
Similarly	O
,	O
we	O
observe	O
that	O
increasing	O
the	O
number	O
and	O
length	O
of	O
walks	O
per	O
source	O
improves	O
performance	O
,	O
which	O
is	O
not	O
surprising	O
since	O
we	O
have	O
a	O
greater	O
overall	O
sampling	O
budget	O
to	O
learn	O
representations	O
.	O
	
Both	O
these	O
parameters	O
have	O
a	O
relatively	O
high	O
impact	O
on	O
the	O
performance	O
of	O
the	O
method	O
.	O
	
Interestingly	O
,	O
the	O
context	O
size	O
,	O
also	O
improves	O
performance	O
at	O
the	O
cost	O
of	O
increased	O
optimization	B-Metric
time	I-Metric
.	O
	
However	O
,	O
the	O
performance	O
differences	O
are	O
not	O
that	O
large	O
in	O
this	O
case	O
.	O
	
subsection	O
:	O
Perturbation	B-Method
Analysis	I-Method
	
For	O
many	O
real	B-Task
-	I-Task
world	I-Task
networks	I-Task
,	O
we	O
do	O
not	O
have	O
access	O
to	O
accurate	O
information	O
about	O
the	O
network	O
structure	O
.	O
	
We	O
performed	O
a	O
perturbation	O
study	O
where	O
we	O
analyzed	O
the	O
performance	O
of	O
node2vec	B-Method
for	O
two	O
imperfect	B-Task
information	I-Task
scenarios	I-Task
related	O
to	O
the	O
edge	O
structure	O
in	O
the	O
BlogCatalog	B-Material
network	O
.	O
	
In	O
the	O
first	O
scenario	O
,	O
we	O
measure	O
performace	O
as	O
a	O
function	O
of	O
the	O
fraction	O
of	O
missing	O
edges	O
(	O
relative	O
to	O
the	O
full	O
network	O
)	O
.	O
	
The	O
missing	O
edges	O
are	O
chosen	O
randomly	O
,	O
subject	O
to	O
the	O
constraint	O
that	O
the	O
number	O
of	O
connected	O
components	O
in	O
the	O
network	O
remains	O
fixed	O
.	O
	
As	O
we	O
can	O
see	O
in	O
Figure	O
[	O
reference	O
]	O
(	O
top	O
)	O
,	O
the	O
decrease	O
in	O
Macro	B-Metric
-	I-Metric
F	I-Metric
score	O
as	O
the	O
fraction	O
of	O
missing	O
edges	O
increases	O
is	O
roughly	O
linear	O
with	O
a	O
small	O
slope	O
.	O
	
Robustness	B-Metric
to	O
missing	O
edges	O
in	O
the	O
network	O
is	O
especially	O
important	O
in	O
cases	O
where	O
the	O
graphs	O
are	O
evolving	O
over	O
time	O
(	O
e.g.	O
,	O
citation	O
networks	O
)	O
,	O
or	O
where	O
network	B-Task
construction	I-Task
is	O
expensive	O
(	O
e.g.	O
,	O
biological	O
networks	O
)	O
.	O
	
In	O
the	O
second	O
perturbation	B-Task
setting	I-Task
,	O
we	O
have	O
noisy	O
edges	O
between	O
randomly	O
selected	O
pairs	O
of	O
nodes	O
in	O
the	O
network	O
.	O
	
As	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
(	O
bottom	O
)	O
,	O
the	O
performance	O
of	O
node2vec	B-Method
declines	O
slightly	O
faster	O
initially	O
when	O
compared	O
with	O
the	O
setting	O
of	O
missing	O
edges	O
,	O
however	O
,	O
the	O
rate	O
of	O
decrease	O
in	O
Macro	B-Metric
-	I-Metric
F	I-Metric
score	O
gradually	O
slows	O
down	O
over	O
time	O
.	O
	
Again	O
,	O
the	O
robustness	B-Metric
of	O
node2vec	B-Method
to	O
false	O
edges	O
is	O
useful	O
in	O
several	O
situations	O
such	O
as	O
sensor	B-Task
networks	I-Task
where	O
the	O
measurements	O
used	O
for	O
constructing	O
the	O
network	O
are	O
noisy	O
.	O
	
subsection	O
:	O
Scalability	O
	
To	O
test	O
for	O
scalability	O
,	O
we	O
learn	O
node	B-Method
representations	I-Method
using	O
node2vec	B-Method
with	O
default	O
parameter	O
values	O
for	O
Erdos	O
-	O
Renyi	O
graphs	O
with	O
increasing	O
sizes	O
from	O
100	O
to	O
1	O
,	O
000	O
,	O
000	O
nodes	O
and	O
constant	O
average	O
degree	O
of	O
10	O
.	O
	
In	O
Figure	O
[	O
reference	O
]	O
,	O
we	O
empirically	O
observe	O
that	O
node2vec	B-Method
scales	O
linearly	O
with	O
increase	O
in	O
number	O
of	O
nodes	O
generating	O
representations	O
for	O
one	O
million	O
nodes	O
in	O
less	O
than	O
four	O
hours	O
.	O
	
The	O
sampling	B-Method
procedure	I-Method
comprises	O
of	O
preprocessing	B-Task
for	O
computing	O
transition	O
probabilities	O
for	O
our	O
walk	O
(	O
negligibly	O
small	O
)	O
and	O
simulation	B-Task
of	I-Task
random	I-Task
walks	I-Task
.	O
	
The	O
optimization	B-Task
phase	I-Task
is	O
made	O
efficient	O
using	O
negative	B-Method
sampling	I-Method
and	O
asynchronous	B-Method
SGD	I-Method
.	O
	
Many	O
ideas	O
from	O
prior	O
work	O
serve	O
as	O
useful	O
pointers	O
in	O
making	O
the	O
sampling	B-Method
procedure	I-Method
computationally	O
efficient	O
.	O
	
We	O
showed	O
how	O
random	O
walks	O
,	O
also	O
used	O
in	O
DeepWalk	B-Method
,	O
allow	O
the	O
sampled	O
nodes	O
to	O
be	O
reused	O
as	O
neighborhoods	O
for	O
different	O
source	O
nodes	O
appearing	O
in	O
the	O
walk	O
.	O
	
Alias	B-Method
sampling	I-Method
allows	O
our	O
walks	O
to	O
generalize	O
to	O
weighted	B-Task
networks	I-Task
,	O
with	O
little	O
preprocessing	O
.	O
	
Though	O
we	O
are	O
free	O
to	O
set	O
the	O
search	O
parameters	O
based	O
on	O
the	O
underlying	O
task	O
and	O
domain	O
at	O
no	O
additional	O
cost	O
,	O
learning	O
the	O
best	O
settings	O
of	O
our	O
search	O
parameters	O
adds	O
an	O
overhead	O
.	O
	
However	O
,	O
as	O
our	O
experiments	O
confirm	O
,	O
this	O
overhead	O
is	O
minimal	O
since	O
node2vec	B-Method
is	O
semi	B-Method
-	I-Method
supervised	I-Method
and	O
hence	O
,	O
can	O
learn	O
these	O
parameters	O
efficiently	O
with	O
very	O
little	O
labeled	O
data	O
.	O
	
subsection	O
:	O
Link	B-Task
prediction	I-Task
	
In	O
link	B-Task
prediction	I-Task
,	O
we	O
are	O
given	O
a	O
network	O
with	O
a	O
certain	O
fraction	O
of	O
edges	O
removed	O
,	O
and	O
we	O
would	O
like	O
to	O
predict	O
these	O
missing	O
edges	O
.	O
	
We	O
generate	O
the	O
labeled	O
dataset	O
of	O
edges	O
as	O
follows	O
:	O
To	O
obtain	O
positive	O
examples	O
,	O
we	O
remove	O
50	O
%	O
of	O
edges	O
chosen	O
randomly	O
from	O
the	O
network	O
while	O
ensuring	O
that	O
the	O
residual	O
network	O
obtained	O
after	O
the	O
edge	B-Method
removals	I-Method
is	O
connected	O
,	O
and	O
to	O
generate	O
negative	O
examples	O
,	O
we	O
randomly	O
sample	O
an	O
equal	O
number	O
of	O
node	O
pairs	O
from	O
the	O
network	O
which	O
have	O
no	O
edge	O
connecting	O
them	O
.	O
	
Since	O
none	O
of	O
feature	B-Method
learning	I-Method
algorithms	I-Method
have	O
been	O
previously	O
used	O
for	O
link	B-Task
prediction	I-Task
,	O
we	O
additionally	O
evaluate	O
node2vec	B-Method
against	O
some	O
popular	O
heuristic	B-Method
scores	I-Method
that	O
achieve	O
good	O
performance	O
in	O
link	B-Task
prediction	I-Task
.	O
	
The	O
scores	O
we	O
consider	O
are	O
defined	O
in	O
terms	O
of	O
the	O
neighborhood	O
sets	O
of	O
the	O
nodes	O
constituting	O
the	O
pair	O
(	O
see	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
We	O
test	O
our	O
benchmarks	O
on	O
the	O
following	O
datasets	O
:	O
Facebook	B-Material
:	O
	
In	O
the	O
Facebook	B-Material
network	I-Material
,	O
nodes	O
represent	O
users	O
,	O
and	O
edges	O
represent	O
a	O
friendship	O
relation	O
between	O
any	O
two	O
users	O
.	O
	
The	O
network	O
has	O
4	O
,	O
039	O
nodes	O
and	O
88	O
,	O
234	O
edges	O
.	O
	
Protein	B-Task
-	I-Task
Protein	I-Task
Interactions	I-Task
(	O
PPI	B-Task
)	O
:	O
	
In	O
the	O
PPI	O
network	O
for	O
Homo	B-Material
Sapiens	I-Material
,	O
nodes	O
represent	O
proteins	O
,	O
and	O
an	O
edge	O
indicates	O
a	O
biological	O
interaction	O
between	O
a	O
pair	O
of	O
proteins	O
.	O
	
The	O
network	O
has	O
19	O
,	O
706	O
nodes	O
and	O
390	O
,	O
633	O
edges	O
.	O
	
arXiv	O
	
ASTRO	B-Task
-	I-Task
PH	I-Task
:	O
This	O
is	O
a	O
collaboration	O
network	O
generated	O
from	O
papers	O
submitted	O
to	O
the	O
e	O
-	O
print	O
arXiv	O
where	O
nodes	O
represent	O
scientists	O
,	O
and	O
an	O
edge	O
is	O
present	O
between	O
two	O
scientists	O
if	O
they	O
have	O
collaborated	O
in	O
a	O
paper	O
.	O
	
The	O
network	O
has	O
18	O
,	O
722	O
nodes	O
and	O
198	O
,	O
110	O
edges	O
.	O
	
Experimental	O
results	O
.	O
	
We	O
summarize	O
our	O
results	O
for	O
link	B-Task
prediction	I-Task
in	O
Table	O
[	O
reference	O
]	O
.	O
	
The	O
best	O
and	O
parameter	O
settings	O
for	O
each	O
node2vec	B-Method
entry	O
are	O
omitted	O
for	O
ease	O
of	O
presentation	O
.	O
	
A	O
general	O
observation	O
we	O
can	O
draw	O
from	O
the	O
results	O
is	O
that	O
the	O
learned	O
feature	B-Method
representations	I-Method
for	O
node	O
pairs	O
significantly	O
outperform	O
the	O
heuristic	B-Metric
benchmark	I-Metric
scores	I-Metric
with	O
node2vec	B-Method
achieving	O
the	O
best	O
AUC	B-Metric
improvement	O
on	O
12.6	O
%	O
on	O
the	O
arXiv	B-Material
dataset	I-Material
over	O
the	O
best	O
performing	O
baseline	O
(	O
Adamic	B-Method
-	I-Method
Adar	I-Method
)	O
.	O
	
Amongst	O
the	O
feature	B-Method
learning	I-Method
algorithms	I-Method
,	O
node2vec	B-Method
outperforms	O
both	O
DeepWalk	B-Method
and	O
LINE	B-Method
in	O
all	O
networks	O
with	O
gain	O
up	O
to	O
3.8	O
%	O
and	O
6.5	O
%	O
respectively	O
in	O
the	O
AUC	B-Metric
scores	I-Metric
for	O
the	O
best	O
possible	O
choices	O
of	O
the	O
binary	O
operator	O
for	O
each	O
algorithm	O
.	O
	
When	O
we	O
look	O
at	O
operators	O
individually	O
(	O
Table	O
[	O
reference	O
]	O
)	O
,	O
node2vec	B-Method
outperforms	O
DeepWalk	B-Method
and	O
LINE	B-Method
barring	O
a	O
couple	O
of	O
cases	O
involving	O
the	O
Weighted	O
-	O
L1	O
and	O
Weighted	B-Method
-	I-Method
L2	I-Method
operators	I-Method
in	O
which	O
LINE	B-Method
performs	O
better	O
.	O
	
Overall	O
,	O
the	O
Hadamard	B-Method
operator	I-Method
when	O
used	O
with	O
node2vec	B-Method
is	O
highly	O
stable	O
and	O
gives	O
the	O
best	O
performance	O
on	O
average	O
across	O
all	O
networks	O
.	O
	
section	O
:	O
Discussion	O
and	O
Conclusion	O
	
In	O
this	O
paper	O
,	O
we	O
studied	O
feature	B-Task
learning	I-Task
in	I-Task
networks	I-Task
as	O
a	O
search	B-Task
-	I-Task
based	I-Task
optimization	I-Task
problem	I-Task
.	O
	
This	O
perspective	O
gives	O
us	O
multiple	O
advantages	O
.	O
	
It	O
can	O
explain	O
classic	O
search	B-Method
strategies	I-Method
on	O
the	O
basis	O
of	O
the	O
exploration	B-Metric
-	I-Metric
exploitation	I-Metric
trade	I-Metric
-	I-Metric
off	I-Metric
.	O
	
Additionally	O
,	O
it	O
provides	O
a	O
degree	O
of	O
interpretability	O
to	O
the	O
learned	O
representations	O
when	O
applied	O
for	O
a	O
prediction	B-Task
task	I-Task
.	O
	
For	O
instance	O
,	O
we	O
observed	O
that	O
BFS	B-Method
can	O
explore	O
only	O
limited	O
neighborhoods	O
.	O
	
This	O
makes	O
BFS	B-Method
suitable	O
for	O
characterizing	O
structural	B-Task
equivalences	I-Task
in	I-Task
network	I-Task
that	O
rely	O
on	O
the	O
immediate	O
local	O
structure	O
of	O
nodes	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
DFS	B-Method
can	O
freely	O
explore	O
network	O
neighborhoods	O
which	O
is	O
important	O
in	O
discovering	O
homophilous	O
communities	O
at	O
the	O
cost	O
of	O
high	O
variance	B-Metric
.	O
	
Both	O
DeepWalk	B-Method
and	O
LINE	B-Method
can	O
be	O
seen	O
as	O
rigid	B-Method
search	I-Method
strategies	I-Method
over	O
networks	O
.	O
	
DeepWalk	B-Method
proposes	O
search	B-Task
using	O
uniform	B-Method
random	I-Method
walks	I-Method
.	O
	
The	O
obvious	O
limitation	O
with	O
such	O
a	O
strategy	O
is	O
that	O
it	O
gives	O
us	O
no	O
control	O
over	O
the	O
explored	O
neighborhoods	O
.	O
	
LINE	B-Method
proposes	O
primarily	O
a	O
breadth	B-Method
-	I-Method
first	I-Method
strategy	I-Method
,	O
sampling	O
nodes	O
and	O
optimizing	O
the	O
likelihood	O
independently	O
over	O
only	O
1	O
-	O
hop	O
and	O
2	O
-	O
hop	O
neighbors	O
.	O
	
The	O
effect	O
of	O
such	O
an	O
exploration	O
is	O
easier	O
to	O
characterize	O
,	O
but	O
it	O
is	O
restrictive	O
and	O
provides	O
no	O
flexibility	O
in	O
exploring	O
nodes	O
at	O
further	O
depths	O
.	O
	
In	O
contrast	O
,	O
the	O
search	B-Method
strategy	I-Method
in	O
node2vec	B-Method
is	O
both	O
flexible	O
and	O
controllable	O
exploring	O
network	O
neighborhoods	O
through	O
parameters	O
and	O
.	O
	
While	O
these	O
search	O
parameters	O
have	O
intuitive	O
interpretations	O
,	O
we	O
obtain	O
best	O
results	O
on	O
complex	B-Task
networks	I-Task
when	O
we	O
can	O
learn	O
them	O
directly	O
from	O
data	O
.	O
	
From	O
a	O
practical	O
standpoint	O
,	O
node2vec	B-Method
is	O
scalable	O
and	O
robust	O
to	O
perturbations	O
.	O
	
We	O
showed	O
how	O
extensions	O
of	O
node	B-Method
embeddings	I-Method
to	O
link	B-Task
prediction	I-Task
outperform	O
popular	O
heuristic	B-Method
scores	I-Method
designed	O
specifically	O
for	O
this	O
task	O
.	O
	
Our	O
method	O
permits	O
additional	O
binary	O
operators	O
beyond	O
those	O
listed	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
As	O
a	O
future	O
work	O
,	O
we	O
would	O
like	O
to	O
explore	O
the	O
reasons	O
behind	O
the	O
success	O
of	O
Hadamard	O
operator	O
over	O
others	O
,	O
as	O
well	O
as	O
establish	O
interpretable	O
equivalence	O
notions	O
for	O
edges	O
based	O
on	O
the	O
search	O
parameters	O
.	O
	
Future	O
extensions	O
of	O
node2vec	B-Method
could	O
involve	O
networks	O
with	O
special	O
structure	O
such	O
as	O
heterogeneous	O
information	O
networks	O
,	O
networks	O
with	O
explicit	O
domain	O
features	O
for	O
nodes	O
and	O
edges	O
and	O
signed	O
-	O
edge	O
networks	O
.	O
	
Continuous	B-Method
feature	I-Method
representations	I-Method
are	O
the	O
backbone	O
of	O
many	O
deep	B-Method
learning	I-Method
algorithms	I-Method
,	O
and	O
it	O
would	O
be	O
interesting	O
to	O
use	O
node2vec	B-Method
representations	O
as	O
building	O
blocks	O
for	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
deep	I-Task
learning	I-Task
on	I-Task
graphs	I-Task
.	O
	
Acknowledgements	O
.	O
	
We	O
are	O
thankful	O
to	O
Austin	O
Benson	O
,	O
Will	O
Hamilton	O
,	O
Rok	O
Sosič	O
,	O
Marinka	O
Žitnik	O
as	O
well	O
as	O
the	O
anonymous	O
reviewers	O
for	O
their	O
helpful	O
comments	O
.	O
	
This	O
research	O
has	O
been	O
supported	O
in	O
part	O
by	O
NSF	O
CNS	O
-	O
1010921	O
,	O
IIS	O
-	O
1149837	O
,	O
NIH	O
BD2	O
K	O
,	O
ARO	O
MURI	O
,	O
DARPA	O
XDATA	O
,	O
DARPA	O
SIMPLEX	O
,	O
Stanford	O
Data	O
Science	O
Initiative	O
,	O
Boeing	O
,	O
Lightspeed	O
,	O
SAP	O
,	O
and	O
Volkswagen	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Subcategory	B-Method
-	I-Method
aware	I-Method
Convolutional	I-Method
Neural	I-Method
Networks	I-Method
for	O
Object	B-Task
Proposals	I-Task
and	O
Detection	B-Task
	
In	O
Convolutional	B-Method
Neural	I-Method
Network	I-Method
(	O
CNN	B-Method
)-	O
based	O
object	B-Method
detection	I-Method
methods	I-Method
,	O
region	B-Method
proposal	I-Method
becomes	O
a	O
bottleneck	O
when	O
objects	O
exhibit	O
significant	O
scale	O
variation	O
,	O
occlusion	O
or	O
truncation	O
.	O
	
In	O
addition	O
,	O
these	O
methods	O
mainly	O
focus	O
on	O
2D	O
object	B-Task
detection	I-Task
and	O
can	O
not	O
estimate	O
detailed	O
properties	O
of	O
objects	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
subcategory	B-Method
-	I-Method
aware	I-Method
CNNs	I-Method
for	O
object	B-Task
detection	I-Task
.	O
	
We	O
introduce	O
a	O
novel	O
region	B-Method
proposal	I-Method
network	I-Method
that	O
uses	O
subcategory	O
information	O
to	O
guide	O
the	O
proposal	B-Method
generating	I-Method
process	I-Method
,	O
and	O
a	O
new	O
detection	B-Method
network	I-Method
for	O
joint	B-Task
detection	I-Task
and	O
subcategory	B-Task
classification	I-Task
.	O
	
By	O
using	O
subcategories	O
related	O
to	O
object	O
pose	O
,	O
we	O
achieve	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
both	O
detection	O
and	O
pose	B-Task
estimation	I-Task
on	O
commonly	O
used	O
benchmarks	O
.	O
	
section	O
:	O
Introduction	O
	
Convolutional	B-Method
Neural	I-Method
Networks	I-Method
(	O
CNNs	B-Method
)	O
have	O
become	O
dominating	O
in	O
solving	O
different	O
recognition	B-Task
problems	I-Task
recently	O
.	O
	
CNNs	B-Method
are	O
powerful	O
due	O
to	O
their	O
capability	O
in	O
both	O
representation	B-Task
and	O
learning	B-Task
.	O
	
With	O
millions	O
of	O
weights	O
in	O
the	O
contemporary	O
CNNs	B-Method
,	O
they	O
are	O
able	O
to	O
learn	O
much	O
richer	O
representations	O
from	O
data	O
.	O
	
In	O
object	B-Task
detection	I-Task
,	O
we	O
have	O
witnessed	O
the	O
performance	O
boost	O
when	O
CNNs	B-Method
are	O
applied	O
to	O
commonly	O
used	O
benchmarks	O
such	O
as	O
PASCAL	B-Material
VOC	I-Material
and	O
ImageNet	B-Material
.	O
	
However	O
,	O
there	O
are	O
two	O
main	O
limitations	O
of	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
CNN	B-Method
-	O
based	O
object	B-Task
detection	I-Task
methods	O
.	O
	
First	O
,	O
they	O
rely	O
on	O
region	B-Method
proposal	I-Method
methods	I-Method
to	O
generate	O
object	O
candidates	O
,	O
which	O
are	O
often	O
based	O
on	O
low	O
-	O
level	O
image	O
features	O
such	O
as	O
superpixels	O
or	O
edges	O
.	O
	
Although	O
these	O
methods	O
work	O
very	O
well	O
on	O
PASCAL	B-Material
VOC	I-Material
and	O
ImageNet	B-Material
,	O
however	O
,	O
when	O
it	O
comes	O
to	O
the	O
KITTI	B-Material
dataset	O
for	O
autonomous	B-Task
driving	I-Task
where	O
objects	O
have	O
large	O
scale	O
variation	O
,	O
occlusion	O
and	O
truncation	O
,	O
these	O
region	B-Method
proposal	I-Method
methods	I-Method
perform	O
very	O
poor	O
as	O
observed	O
in	O
our	O
experiments	O
.	O
	
Recently	O
,	O
the	O
Region	B-Method
Proposal	I-Method
Network	I-Method
(	O
RPN	B-Method
)	O
in	O
is	O
able	O
to	O
improve	O
over	O
the	O
traditional	O
region	B-Method
proposal	I-Method
methods	I-Method
.	O
	
However	O
,	O
it	O
still	O
can	O
not	O
efficiently	O
handle	O
the	O
scale	O
change	O
of	O
object	O
,	O
occlusion	O
and	O
truncation	O
.	O
	
Second	O
,	O
the	O
existing	O
CNN	B-Method
-	O
based	O
object	B-Task
detection	I-Task
methods	O
mainly	O
focus	O
on	O
2D	O
object	B-Task
detection	I-Task
with	O
bounding	O
boxes	O
.	O
	
As	O
a	O
result	O
,	O
they	O
are	O
not	O
able	O
to	O
estimate	O
detailed	O
information	O
about	O
objects	O
such	O
as	O
2D	O
segmentation	O
boundary	O
,	O
3D	O
pose	O
or	O
occlusion	O
relationship	O
between	O
objects	O
,	O
while	O
these	O
information	O
is	O
critical	O
for	O
various	O
applications	O
such	O
as	O
autonomous	B-Task
driving	I-Task
,	O
robotics	B-Task
and	O
augmented	B-Task
reality	I-Task
.	O
	
In	O
this	O
work	O
,	O
we	O
explore	O
subcategory	O
information	O
,	O
which	O
is	O
widely	O
used	O
in	O
traditional	O
object	B-Task
detection	I-Task
,	O
to	O
tackle	O
the	O
aforementioned	O
two	O
limitations	O
in	O
CNN	B-Method
-	O
based	O
object	B-Task
detection	I-Task
.	O
	
For	O
region	B-Task
proposal	I-Task
generation	I-Task
,	O
we	O
introduce	O
a	O
new	O
CNN	B-Method
architecture	O
that	O
uses	O
subcategory	O
detections	O
as	O
object	O
candidates	O
.	O
	
For	O
detection	B-Task
,	O
we	O
modify	O
the	O
network	O
in	O
Fast	O
R	O
-	O
CNN	B-Method
for	O
joint	B-Task
detection	I-Task
and	O
subcategory	B-Task
classification	I-Task
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
illustrates	O
our	O
object	B-Task
detection	I-Task
framework	O
.	O
	
The	O
concept	O
of	O
subcategory	O
is	O
general	O
here	O
.	O
	
A	O
subcategory	O
can	O
be	O
objects	O
with	O
similar	O
properties	O
or	O
attributes	O
such	O
as	O
2D	O
appearance	O
,	O
3D	O
pose	O
or	O
3D	O
shape	O
.	O
	
By	O
associating	O
object	O
attributes	O
to	O
subcategories	O
,	O
we	O
are	O
able	O
to	O
estimate	O
these	O
attributes	O
(	O
e.g.	O
,	O
2D	O
segmentation	O
boundary	O
or	O
3D	O
pose	O
)	O
by	O
conducting	O
subcategory	B-Task
classification	I-Task
.	O
	
Specifically	O
,	O
motivated	O
by	O
the	O
traditional	O
detection	B-Method
methods	I-Method
that	O
train	O
a	O
template	O
or	O
a	O
detector	B-Method
for	O
each	O
subcategory	O
,	O
we	O
introduce	O
a	O
subcategory	B-Method
convolutional	I-Method
(	I-Method
conv	I-Method
)	I-Method
layer	I-Method
in	O
our	O
Region	B-Method
Proposal	I-Method
Network	I-Method
(	O
RPN	B-Method
)	O
,	O
where	O
each	O
filter	B-Method
in	O
the	O
conv	B-Method
layer	I-Method
is	O
trained	O
discriminatively	O
for	O
subcategory	B-Task
detection	I-Task
.	O
	
The	O
subcategory	B-Method
conv	I-Method
layer	I-Method
outputs	O
heat	O
maps	O
about	O
the	O
presence	O
of	O
certain	O
subcategories	O
at	O
a	O
specific	O
location	O
and	O
scale	O
.	O
	
Using	O
these	O
heat	B-Method
maps	I-Method
,	O
our	O
RPN	B-Method
is	O
able	O
to	O
output	O
confident	O
subcategory	O
detections	O
as	O
proposals	O
.	O
	
For	O
classifying	B-Task
region	I-Task
proposals	I-Task
and	O
refining	O
their	O
locations	O
,	O
we	O
introduce	O
a	O
new	O
object	B-Task
detection	I-Task
network	O
by	O
injecting	O
subcategory	O
information	O
into	O
the	O
network	O
proposed	O
in	O
Fast	O
R	O
-	O
CNN	B-Method
.	O
	
Our	O
detection	B-Method
network	I-Method
is	O
able	O
to	O
perform	O
object	B-Task
detection	I-Task
and	O
subcategory	B-Task
classification	I-Task
jointly	O
.	O
	
By	O
using	O
3D	O
Voxel	O
Patterns	O
(	O
3DVPs	B-Method
)	O
as	O
subcategories	O
,	O
our	O
method	O
is	O
able	O
to	O
jointly	O
detect	O
the	O
object	O
,	O
estimate	O
its	O
3D	O
pose	O
,	O
segment	O
its	O
boundary	O
and	O
estimate	O
its	O
occluded	O
or	O
truncated	O
regions	O
.	O
	
In	O
addition	O
,	O
in	O
both	O
our	O
RPN	B-Method
and	O
our	O
detection	O
CNN	B-Method
,	O
we	O
use	O
image	O
pyramids	O
as	O
input	O
,	O
and	O
we	O
introduce	O
a	O
new	O
feature	B-Method
extrapolating	I-Method
layer	I-Method
to	O
efficiently	O
compute	O
conv	O
features	O
in	O
multiple	O
scales	O
.	O
	
In	O
this	O
way	O
,	O
our	O
method	O
is	O
able	O
to	O
detect	O
objects	O
with	O
large	O
scale	O
variations	O
.	O
	
We	O
conduct	O
experiments	O
on	O
the	O
KITTI	B-Material
dataset	O
,	O
the	O
PASCAL3D	B-Material
+	I-Material
dataset	I-Material
and	O
the	O
PASCAL	B-Material
VOC	O
2007	O
dataset	O
.	O
	
Comparisons	O
with	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
on	O
these	O
benchmarks	O
demonstrate	O
the	O
advantages	O
of	O
our	O
subcategory	B-Method
-	I-Method
aware	I-Method
CNNs	I-Method
for	O
object	B-Task
recognition	I-Task
.	O
	
section	O
:	O
Related	O
Work	O
	
Subcategory	B-Method
in	O
Object	O
Detection	B-Task
.	O
	
Subcategory	B-Method
has	O
been	O
widely	O
utilized	O
to	O
facilitate	O
object	B-Task
detection	I-Task
,	O
and	O
different	O
methods	O
of	O
discovering	B-Task
object	I-Task
subcategories	I-Task
have	O
been	O
proposed	O
.	O
	
In	O
DPM	B-Method
,	O
subcategories	O
are	O
discovered	O
by	O
clustering	O
objects	O
according	O
to	O
the	O
aspect	O
ratio	O
of	O
their	O
bounding	O
boxes	O
.	O
	
performs	O
clustering	B-Task
according	O
to	O
the	O
viewpoint	O
of	O
the	O
object	O
to	O
discover	O
subcategories	O
.	O
	
Visual	O
subcategories	O
are	O
constructed	O
by	O
clustering	B-Method
in	O
the	O
appearance	O
space	O
of	O
object	O
.	O
	
3DVP	B-Method
performs	O
clustering	B-Task
in	O
the	O
3D	O
voxel	O
space	O
according	O
to	O
the	O
visibility	O
of	O
the	O
voxels	O
.	O
	
Unlike	O
previous	O
works	O
,	O
we	O
utilize	O
subcategory	O
to	O
improve	O
CNN	B-Method
-	O
based	O
detection	O
,	O
and	O
our	O
framework	O
is	O
general	O
to	O
employ	O
different	O
types	O
of	O
object	O
subcategories	O
.	O
	
CNN	B-Method
-	O
based	O
Object	O
Detection	B-Task
.	O
	
We	O
can	O
categorize	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
CNN	B-Method
-	O
based	O
object	B-Task
detection	I-Task
methods	O
into	O
two	O
classes	O
:	O
one	O
-	O
stage	B-Method
detection	I-Method
and	O
two	B-Task
-	I-Task
stage	I-Task
detection	I-Task
.	O
	
In	O
one	B-Task
-	I-Task
stage	I-Task
detection	I-Task
,	O
such	O
as	O
the	O
Overfeat	B-Method
framework	I-Method
,	O
a	O
CNN	B-Method
directly	O
processes	O
an	O
input	O
image	O
,	O
and	O
outputs	O
object	B-Task
detections	I-Task
.	O
	
In	O
two	B-Task
-	I-Task
stage	I-Task
detection	I-Task
,	O
such	O
as	O
R	B-Method
-	I-Method
CNNs	I-Method
,	O
region	B-Method
proposals	I-Method
are	O
first	O
generated	O
from	O
an	O
input	O
image	O
,	O
where	O
different	O
region	B-Method
proposal	I-Method
methods	I-Method
can	O
be	O
employed	O
.	O
	
Then	O
these	O
region	B-Method
proposals	I-Method
are	O
fed	O
into	O
a	O
CNN	B-Method
for	O
classification	B-Task
and	I-Task
location	I-Task
refinement	I-Task
.	O
	
It	O
is	O
debatable	O
which	O
detection	B-Method
paradigm	I-Method
is	O
better	O
.	O
	
We	O
adopt	O
the	O
two	B-Task
-	I-Task
stage	I-Task
detection	I-Task
framework	O
in	O
this	O
work	O
,	O
and	O
consider	O
the	O
region	B-Method
proposal	I-Method
process	I-Method
to	O
be	O
the	O
coarse	B-Task
detection	I-Task
step	I-Task
in	O
coarse	B-Task
-	I-Task
to	I-Task
-	I-Task
fine	I-Task
detection	I-Task
.	O
	
We	O
propose	O
a	O
novel	O
RPN	B-Method
motivated	O
by	O
and	O
demonstrate	O
its	O
advantages	O
.	O
	
section	O
:	O
Subcategory	O
-	O
aware	O
RPN	B-Method
	
Ideally	O
,	O
we	O
want	O
to	O
have	O
a	O
region	B-Method
proposal	I-Method
approach	I-Method
that	O
can	O
cover	O
objects	O
in	O
an	O
input	O
image	O
with	O
as	O
few	O
proposals	O
as	O
possible	O
.	O
	
Since	O
objects	O
in	O
images	O
appear	O
at	O
different	O
locations	O
and	O
scales	O
,	O
region	B-Method
proposal	I-Method
itself	O
is	O
a	O
challenging	O
problem	O
.	O
	
Recently	O
,	O
proposed	O
to	O
tackle	O
the	O
region	B-Task
proposal	I-Task
problem	I-Task
with	O
CNNs	B-Method
,	O
demonstrating	O
the	O
advantages	O
of	O
using	O
CNNs	B-Method
over	O
traditional	O
approaches	O
for	O
region	B-Task
proposal	I-Task
.	O
	
In	O
this	O
section	O
,	O
we	O
describe	O
our	O
subcategory	B-Method
-	I-Method
aware	I-Method
Region	I-Method
Proposal	I-Method
Network	I-Method
(	O
RPN	B-Method
)	O
.	O
	
subsection	O
:	O
Network	B-Method
Architecture	I-Method
	
We	O
introduce	O
a	O
novel	O
network	B-Method
architecture	I-Method
for	O
generating	B-Task
object	I-Task
proposals	I-Task
from	O
images	O
.	O
	
The	O
architecture	O
is	O
inspired	O
by	O
the	O
traditional	O
sliding	B-Method
-	I-Method
window	I-Method
-	I-Method
based	I-Method
object	I-Method
detectors	I-Method
,	O
such	O
as	O
the	O
Aggregated	B-Method
Channel	I-Method
Feature	I-Method
(	I-Method
ACF	I-Method
)	I-Method
detector	I-Method
and	O
the	O
Deformable	B-Method
Part	I-Method
Model	I-Method
(	O
DPM	B-Method
)	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
illustrates	O
the	O
architecture	O
of	O
our	O
region	B-Method
proposal	I-Method
network	I-Method
.	O
	
i	O
)	O
	
To	O
handle	O
different	O
scales	O
of	O
objects	O
,	O
we	O
input	O
into	O
our	O
RPN	B-Method
an	O
image	B-Method
pyramid	I-Method
.	O
	
This	O
pyramid	O
is	O
processed	O
by	O
several	O
convolutional	B-Method
(	I-Method
conv	I-Method
)	I-Method
and	I-Method
max	I-Method
pooling	I-Method
layers	I-Method
to	O
extract	O
the	O
conv	O
feature	O
maps	O
,	O
with	O
one	O
conv	B-Method
feature	I-Method
map	I-Method
for	O
each	O
scale	O
.	O
	
ii	O
)	O
	
In	O
order	O
to	O
speed	O
up	O
the	O
computation	B-Task
of	I-Task
conv	I-Task
features	I-Task
on	O
image	B-Task
pyramids	I-Task
,	O
we	O
introduce	O
the	O
feature	B-Method
extrapolating	I-Method
layer	I-Method
,	O
which	O
generates	O
feature	O
maps	O
for	O
scales	O
that	O
are	O
not	O
covered	O
by	O
the	O
image	O
pyramid	O
via	O
extrapolation	B-Method
.	O
	
iii	O
)	O
	
After	O
computing	O
the	O
extrapolated	O
conv	O
feature	O
maps	O
,	O
we	O
specifically	O
design	O
a	O
conv	B-Method
layer	I-Method
for	O
object	B-Task
subcategory	I-Task
detection	I-Task
,	O
where	O
each	O
filter	B-Method
in	O
the	O
conv	B-Method
layer	I-Method
corresponds	O
to	O
an	O
object	O
subcategory	O
.	O
	
We	O
train	O
these	O
filters	O
to	O
make	O
sure	O
they	O
fire	O
on	O
correct	O
locations	O
and	O
scales	O
of	O
objects	O
in	O
the	O
corresponding	O
subcategories	O
during	O
the	O
network	B-Method
training	I-Method
.	O
	
The	O
subcategory	B-Method
conv	I-Method
layer	I-Method
outputs	O
a	O
heat	O
map	O
for	O
each	O
scale	O
,	O
where	O
each	O
value	O
in	O
the	O
heat	O
map	O
indicates	O
the	O
confidence	O
of	O
an	O
object	O
in	O
the	O
corresponding	O
location	O
,	O
scale	O
and	O
subcategory	O
.	O
	
v	O
)	O
	
Using	O
the	O
subcategory	O
heat	O
maps	O
,	O
we	O
design	O
a	O
RoI	B-Method
generating	I-Method
layer	I-Method
that	O
generates	O
object	O
candidates	O
(	O
RoIs	O
)	O
by	O
thresholding	O
the	O
heat	B-Method
maps	I-Method
.	O
	
vi	O
)	O
	
The	O
RoIs	O
are	O
used	O
in	O
a	O
RoI	B-Method
pooling	I-Method
layer	I-Method
to	O
pool	O
conv	O
features	O
from	O
the	O
extrapolated	O
conv	B-Method
feature	I-Method
maps	I-Method
.	O
	
vii	O
)	O
	
Finally	O
,	O
our	O
RPN	B-Method
terminates	O
at	O
two	O
sibling	O
layers	O
:	O
one	O
that	O
outputs	O
softmax	O
probability	O
estimates	O
over	O
object	O
subcategories	O
,	O
and	O
the	O
other	O
layer	O
that	O
refines	O
the	O
RoI	O
location	O
with	O
a	O
bounding	B-Method
box	I-Method
regressor	I-Method
.	O
	
subsection	O
:	O
Feature	B-Method
Extrapolating	I-Method
Layer	I-Method
	
In	O
our	O
RPN	B-Method
,	O
we	O
use	O
fixed	B-Method
-	I-Method
size	I-Method
conv	I-Method
filters	I-Method
in	O
the	O
subcategory	O
conv	O
layer	O
to	O
localize	O
objects	O
(	O
e.g.	O
,	O
conv	B-Method
filters	I-Method
)	O
.	O
	
In	O
order	O
to	O
handle	O
different	O
scales	O
of	O
objects	O
,	O
we	O
resort	O
to	O
image	O
pyramids	O
.	O
	
An	O
image	B-Task
pyramid	I-Task
consists	O
of	O
images	O
with	O
different	O
resolutions	O
obtained	O
by	O
rescaling	O
the	O
original	O
image	O
according	O
to	O
different	O
sampled	O
scales	O
.	O
	
After	O
constructing	O
the	O
image	O
pyramid	O
for	O
an	O
input	O
image	O
,	O
multi	O
-	O
resolution	O
conv	O
feature	O
maps	O
can	O
be	O
computed	O
by	O
applying	O
several	O
conv	B-Method
layers	I-Method
and	O
max	B-Method
pooling	I-Method
layers	I-Method
to	O
each	O
image	O
in	O
the	O
pyramid	O
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
If	O
we	O
perform	O
convolution	B-Method
on	O
every	O
scale	O
explicitly	O
,	O
it	O
is	O
computationally	O
expensive	O
,	O
especially	O
when	O
a	O
finely	B-Task
-	I-Task
sampled	I-Task
image	I-Task
pyramid	I-Task
is	O
needed	O
as	O
in	O
the	O
region	B-Task
proposal	I-Task
process	I-Task
.	O
	
In	O
,	O
Dollár	O
et	O
al	O
.	O
demonstrate	O
that	O
multi	B-Task
-	I-Task
resolution	I-Task
image	I-Task
features	I-Task
can	O
be	O
approximated	O
by	O
extrapolation	O
from	O
nearby	O
scales	O
rather	O
than	O
being	O
computed	O
explicitly	O
.	O
	
Inspired	O
by	O
their	O
work	O
,	O
we	O
introduce	O
a	O
feature	B-Method
extrapolating	I-Method
layer	I-Method
to	O
accelerate	O
the	O
computation	B-Task
of	I-Task
conv	I-Task
features	I-Task
on	O
an	O
image	O
pyramid	O
.	O
	
Specifically	O
,	O
a	O
feature	B-Method
extrapolating	I-Method
layer	I-Method
takes	O
as	O
input	O
feature	O
maps	O
that	O
are	O
supplied	O
by	O
the	O
last	O
conv	B-Method
layer	I-Method
for	O
feature	B-Task
extraction	I-Task
,	O
where	O
equals	O
to	O
the	O
number	O
of	O
scales	O
in	O
the	O
input	O
image	O
pyramid	O
.	O
	
Each	O
feature	B-Method
map	I-Method
is	O
a	O
multi	O
-	O
dimensional	O
array	O
of	O
size	O
,	O
with	O
rows	O
,	O
columns	O
,	O
and	O
channels	O
.	O
	
The	O
width	O
and	O
height	O
of	O
the	O
feature	O
map	O
corresponds	O
to	O
the	O
largest	O
scale	O
in	O
the	O
image	O
pyramid	O
,	O
where	O
images	O
in	O
smaller	O
scales	O
are	O
padded	O
with	O
zeros	O
in	O
order	O
to	O
generate	O
feature	O
maps	O
with	O
the	O
same	O
size	O
.	O
	
The	O
feature	B-Method
extrapolating	I-Method
layer	I-Method
constructs	O
feature	O
maps	O
at	O
intermediate	O
scales	O
by	O
extrapolating	O
features	O
from	O
the	O
nearest	O
scales	O
among	O
the	O
scales	O
using	O
bilinear	B-Method
interpolation	I-Method
.	O
	
Suppose	O
we	O
add	O
intermediate	O
scales	O
between	O
every	O
th	O
scale	O
and	O
th	O
scale	O
,	O
.	O
	
The	O
output	O
of	O
the	O
feature	B-Method
extrapolating	I-Method
layer	I-Method
is	O
feature	O
maps	O
,	O
each	O
with	O
size	O
.	O
	
Since	O
extrapolating	O
a	O
multi	O
-	O
dimensional	O
array	O
is	O
much	O
faster	O
than	O
computing	O
a	O
conv	O
feature	O
map	O
explicitly	O
,	O
the	O
feature	B-Method
extrapolating	I-Method
layer	I-Method
speeds	O
up	O
the	O
feature	B-Task
computation	I-Task
with	O
less	O
memory	O
.	O
	
subsection	O
:	O
Subcategory	B-Method
Conv	I-Method
Layer	I-Method
	
After	O
computing	O
the	O
conv	O
feature	O
maps	O
,	O
we	O
design	O
a	O
subcategory	B-Method
conv	I-Method
layer	I-Method
for	O
subcategory	B-Task
detection	I-Task
.	O
	
Motivated	O
by	O
the	O
traditional	O
object	B-Method
detection	I-Method
methods	I-Method
that	O
train	O
a	O
classifier	B-Method
or	O
a	O
template	O
for	O
each	O
subcategory	O
,	O
we	O
train	O
a	O
conv	B-Method
filter	I-Method
in	O
the	O
subcategory	B-Method
conv	I-Method
layer	I-Method
to	O
detect	O
a	O
specific	O
subcategory	O
.	O
	
Suppose	O
there	O
are	O
subcategories	O
to	O
be	O
considered	O
.	O
	
Then	O
,	O
the	O
subcategory	B-Method
conv	I-Method
layer	I-Method
consists	O
of	O
conv	B-Method
filters	I-Method
with	O
one	O
additional	O
conv	B-Method
filter	I-Method
for	O
a	O
special	O
“	O
background	O
”	O
category	O
.	O
	
For	O
multi	B-Task
-	I-Task
class	I-Task
detection	I-Task
(	O
e.g.	O
,	O
car	O
,	O
pedestrian	O
,	O
cyclist	O
,	O
etc	O
.	O
)	O
,	O
the	O
subcategories	O
are	O
the	O
aggregation	O
of	O
all	O
the	O
subcategories	O
from	O
all	O
the	O
classes	O
.	O
	
These	O
conv	B-Method
filters	I-Method
operate	O
on	O
the	O
extrapolated	O
conv	O
feature	O
maps	O
and	O
output	O
heat	O
maps	O
that	O
indicate	O
the	O
confidences	O
of	O
the	O
presence	O
of	O
objects	O
in	O
the	O
input	O
image	O
.	O
	
We	O
use	O
fixed	B-Method
-	I-Method
size	I-Method
conv	I-Method
filters	I-Method
in	O
this	O
layer	O
(	O
e.g.	O
,	O
conv	B-Method
filters	I-Method
)	O
,	O
which	O
are	O
trained	O
to	O
fire	O
on	O
specific	O
scales	O
in	O
the	O
feature	O
pyramid	O
.	O
	
Sec	O
.	O
	
[	O
reference	O
]	O
explains	O
how	O
we	O
back	O
-	O
propagate	O
errors	O
from	O
the	O
loss	B-Method
layer	I-Method
to	O
train	O
these	O
subcategory	B-Method
conv	I-Method
filters	I-Method
.	O
	
subsection	O
:	O
RoI	B-Method
Generating	I-Method
Layer	I-Method
	
The	O
RoI	B-Method
generating	I-Method
layer	I-Method
takes	O
as	O
input	O
heat	O
maps	O
and	O
outputs	O
a	O
set	O
of	O
region	O
proposals	O
(	O
RoIs	O
)	O
,	O
where	O
is	O
the	O
number	O
of	O
scales	O
in	O
the	O
feature	O
pyramid	O
after	O
extrapolation	O
.	O
	
Each	O
heat	B-Method
map	I-Method
is	O
a	O
multi	O
-	O
dimensional	O
array	O
of	O
size	O
for	O
subcategories	O
(	O
i.e.	O
,	O
for	O
RoI	B-Task
generating	I-Task
,	O
we	O
ignore	O
the	O
“	O
background	O
”	O
channel	O
in	O
the	O
heat	O
map	O
)	O
.	O
	
The	O
RoI	B-Method
generating	I-Method
layer	I-Method
first	O
converts	O
each	O
heat	O
map	O
into	O
a	O
2D	O
array	O
by	O
performing	O
max	B-Method
operation	I-Method
over	O
the	O
channels	O
for	O
subcategory	O
.	O
	
Then	O
,	O
it	O
thresholds	O
the	O
2D	B-Method
heat	I-Method
map	I-Method
to	O
generate	O
RoIs	O
.	O
	
In	O
this	O
way	O
,	O
we	O
measure	O
the	O
objectness	O
of	O
a	O
region	O
by	O
aggregating	O
information	O
from	O
subcategories	O
.	O
	
Different	O
generating	B-Method
strategies	I-Method
are	O
used	O
in	O
testing	O
and	O
training	B-Task
.	O
	
In	O
testing	O
,	O
each	O
location	O
in	O
a	O
heat	O
map	O
with	O
a	O
score	O
larger	O
than	O
a	O
predefined	O
threshold	O
is	O
used	O
to	O
generate	O
RoIs	O
.	O
	
First	O
,	O
a	O
canonical	O
bounding	O
box	O
is	O
centered	O
on	O
.	O
	
The	O
width	O
and	O
height	O
of	O
the	O
box	O
are	O
the	O
same	O
as	O
those	O
of	O
the	O
conv	B-Method
filters	I-Method
(	O
e.g.	O
,	O
)	O
in	O
the	O
subcategory	B-Method
conv	I-Method
layer	I-Method
,	O
which	O
have	O
an	O
aspect	O
ratio	O
one	O
.	O
	
Second	O
,	O
a	O
number	O
of	O
boxes	O
centered	O
on	O
with	O
the	O
same	O
areas	O
as	O
the	O
canonical	O
box	O
(	O
e.g.	O
,	O
)	O
but	O
with	O
different	O
aspect	O
ratios	O
are	O
generated	O
.	O
	
Finally	O
,	O
the	O
RoI	B-Method
generating	I-Method
layer	I-Method
rescales	O
the	O
generated	O
boxes	O
according	O
to	O
the	O
scale	O
of	O
the	O
heat	O
map	O
,	O
so	O
as	O
to	O
cover	O
objects	O
in	O
different	O
scales	O
and	O
aspect	O
ratios	O
.	O
	
In	O
training	O
,	O
the	O
RoI	B-Method
generating	I-Method
layer	I-Method
outputs	O
hard	O
positive	O
RoIs	O
and	O
hard	O
negative	O
RoIs	O
for	O
training	O
the	O
subcategory	B-Method
conv	I-Method
filters	I-Method
,	O
given	O
a	O
budget	O
on	O
batch	O
size	O
in	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
.	O
	
First	O
,	O
we	O
use	O
the	O
same	O
procedure	O
as	O
described	O
in	O
testing	O
to	O
generate	O
a	O
number	O
of	O
bounding	O
boxes	O
for	O
each	O
location	O
in	O
each	O
heat	O
map	O
.	O
	
Second	O
,	O
according	O
to	O
the	O
ground	O
truth	O
bounding	O
boxes	O
of	O
objects	O
in	O
a	O
training	O
image	O
,	O
we	O
compute	O
the	O
intersection	B-Metric
over	I-Metric
union	I-Metric
(	O
IoU	B-Metric
)	O
overlap	O
between	O
the	O
generated	O
boxes	O
and	O
the	O
ground	O
truth	O
boxes	O
.	O
	
Bounding	O
boxes	O
with	O
IoU	B-Metric
overlap	O
larger	O
/	O
smaller	O
than	O
some	O
threshold	O
(	O
e.g.	O
,	O
0.5	O
)	O
are	O
considered	O
to	O
be	O
positive	O
/	O
negative	O
.	O
	
Finally	O
,	O
given	O
the	O
number	O
of	O
RoIs	O
to	O
be	O
generated	O
for	O
each	O
training	O
image	O
(	O
i.e.	O
,	O
batch	O
size	O
divided	O
by	O
the	O
number	O
of	O
images	O
in	O
a	O
batch	O
)	O
,	O
the	O
RoI	B-Method
generating	I-Method
layer	I-Method
outputs	O
hard	O
positives	O
(	O
i.e.	O
,	O
positive	O
bounding	O
boxes	O
with	O
lowest	O
scores	O
in	O
the	O
heat	O
maps	O
)	O
and	O
hard	O
negatives	O
(	O
i.e.	O
,	O
negative	O
bounding	O
boxes	O
with	O
highest	O
scores	O
in	O
the	O
heat	O
maps	O
)	O
,	O
where	O
is	O
the	O
percentage	O
of	O
positive	O
examples	O
.	O
	
subsection	O
:	O
Network	B-Method
Training	I-Method
	
After	O
generating	O
RoIs	O
,	O
we	O
apply	O
the	O
RoI	B-Method
pooling	I-Method
layer	I-Method
proposed	O
in	O
to	O
pool	O
conv	O
features	O
for	O
each	O
RoI.	O
	
Then	O
the	O
pooled	O
conv	O
features	O
are	O
used	O
for	O
two	O
tasks	O
:	O
subcategory	B-Task
classification	I-Task
and	O
bounding	B-Task
box	I-Task
regression	I-Task
.	O
	
As	O
illustrated	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
,	O
our	O
RPN	B-Method
has	O
two	O
sibling	O
output	O
layers	O
.	O
	
The	O
first	O
layer	O
outputs	O
a	O
discrete	O
probability	O
distribution	O
,	O
over	O
subcategories	O
,	O
which	O
is	O
computed	O
by	O
applying	O
a	O
softmax	B-Method
function	I-Method
over	O
the	O
outputs	O
of	O
the	O
subcategory	B-Method
conv	I-Method
layer	I-Method
.	O
	
The	O
second	O
layer	O
outputs	O
bounding	B-Method
box	I-Method
regression	I-Method
offsets	I-Method
for	O
object	O
classes	O
(	O
)	O
.	O
	
We	O
parameterize	O
as	O
in	O
,	O
which	O
specifies	O
a	O
scale	O
-	O
invariant	O
translation	O
and	O
log	O
-	O
space	O
width	O
/	O
height	O
shift	O
relative	O
to	O
a	O
RoI.	O
We	O
employ	O
a	O
multi	O
-	O
task	O
loss	O
as	O
in	O
to	O
train	O
our	O
RPN	B-Method
for	O
subcategory	B-Task
classification	I-Task
and	O
bounding	B-Task
box	I-Task
regression	I-Task
:	O
where	O
and	O
are	O
the	O
truth	O
subcategory	O
label	O
and	O
the	O
true	O
class	O
label	O
respectively	O
,	O
is	O
the	O
standard	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
loss	I-Metric
,	O
is	O
the	O
true	O
bounding	B-Metric
box	I-Metric
regression	I-Metric
targets	I-Metric
for	O
class	O
,	O
and	O
is	O
the	O
prediction	O
for	O
class	O
.	O
	
We	O
use	O
the	O
smoothed	O
loss	O
defined	O
in	O
for	O
the	O
bounding	B-Method
box	I-Method
regression	I-Method
loss	I-Method
.	O
	
The	O
indicator	O
function	O
indicates	O
that	O
bounding	B-Method
box	I-Method
regression	I-Method
is	O
ignored	O
if	O
the	O
RoI	O
is	O
background	O
(	O
i.e.	O
,	O
)	O
.	O
is	O
a	O
predefined	O
weight	O
to	O
balance	O
the	O
two	O
losses	O
.	O
	
In	O
training	B-Task
,	O
derivatives	O
from	O
the	O
loss	O
function	O
are	O
back	O
-	O
propagated	O
(	O
see	O
red	O
arrows	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
The	O
two	O
subcategory	B-Method
conv	I-Method
layers	I-Method
in	O
our	O
RPN	B-Method
share	O
their	O
weights	O
.	O
	
These	O
weights	O
/	O
conv	B-Method
filters	I-Method
are	O
updated	O
according	O
to	O
the	O
derivatives	O
from	O
the	O
softmax	O
loss	O
function	O
for	O
subcategory	B-Task
classification	I-Task
,	O
so	O
we	O
are	O
able	O
to	O
train	O
these	O
filters	O
for	O
subcategory	B-Task
detection	I-Task
.	O
	
There	O
is	O
no	O
derivative	O
flow	O
in	O
computing	O
heat	B-Task
maps	I-Task
using	O
the	O
subcategory	B-Method
conv	I-Method
layer	I-Method
and	O
in	O
the	O
RoI	B-Method
generating	I-Method
layer	I-Method
.	O
	
Finally	O
,	O
our	O
RPN	B-Method
generates	O
confident	O
subcategory	O
detections	O
as	O
region	O
proposals	O
.	O
	
section	O
:	O
Subcategory	B-Method
-	I-Method
aware	I-Method
Detection	I-Method
Network	I-Method
	
After	O
the	O
region	B-Method
proposal	I-Method
process	I-Method
,	O
CNNs	B-Method
are	O
utilized	O
to	O
classify	O
these	O
proposals	O
and	O
refine	O
their	O
locations	O
.	O
	
Since	O
region	B-Method
proposal	I-Method
significantly	O
reduces	O
the	O
search	O
space	O
,	O
more	O
powerful	O
CNNs	B-Method
can	O
be	O
used	O
in	O
the	O
detection	B-Task
step	I-Task
,	O
which	O
usually	O
contain	O
several	O
fully	B-Method
connected	I-Method
layers	O
with	O
high	O
dimensions	O
.	O
	
In	O
this	O
section	O
,	O
we	O
introduce	O
our	O
subcategory	B-Method
-	I-Method
aware	I-Method
object	I-Method
detection	I-Method
network	I-Method
for	O
joint	B-Task
detection	I-Task
and	O
subcategory	B-Task
classification	I-Task
.	O
	
subsection	O
:	O
Network	B-Method
Architecture	I-Method
	
Fig	O
.	O
	
[	O
reference	O
]	O
illustrates	O
the	O
architecture	O
of	O
our	O
detection	B-Method
network	I-Method
.	O
	
The	O
network	O
is	O
constructed	O
based	O
on	O
the	O
Fast	O
R	O
-	O
CNN	B-Method
detection	O
network	O
with	O
a	O
number	O
of	O
improvements	O
.	O
	
i	O
)	O
	
We	O
use	O
image	B-Method
pyramids	I-Method
to	O
handle	O
the	O
scale	O
variation	O
of	O
objects	O
.	O
	
After	O
the	O
last	O
conv	B-Method
layer	I-Method
for	O
feature	B-Task
extraction	I-Task
,	O
we	O
add	O
the	O
feature	B-Method
extrapolating	I-Method
layer	I-Method
to	O
increase	O
the	O
number	O
of	O
scales	O
in	O
the	O
conv	O
feature	O
pyramid	O
.	O
	
ii	O
)	O
	
Given	O
the	O
region	O
proposals	O
generated	O
from	O
our	O
RPN	B-Method
,	O
we	O
employ	O
a	O
RoI	B-Method
pooling	I-Method
layer	I-Method
to	O
pool	O
conv	O
features	O
for	O
each	O
RoI.	O
	
Each	O
RoI	O
is	O
mapped	O
to	O
a	O
scale	O
in	O
the	O
conv	O
feature	O
pyramid	O
such	O
that	O
smaller	O
RoIs	O
pool	O
features	O
from	O
larger	O
scales	O
.	O
	
iii	O
)	O
	
The	O
pooled	O
conv	O
features	O
are	O
fed	O
into	O
three	O
fully	B-Method
connected	I-Method
(	O
FC	B-Method
)	O
layers	O
,	O
where	O
the	O
last	O
FC	B-Method
layer	O
is	O
designed	O
for	O
subcategory	B-Task
classification	I-Task
.	O
	
For	O
subcategories	O
,	O
the	O
“	O
subcategory	O
FC	B-Method
”	O
layer	O
outputs	O
a	O
dimensional	O
vector	O
with	O
one	O
additional	O
dimension	O
for	O
the	O
background	O
class	O
.	O
	
We	O
consider	O
the	O
output	O
,	O
named	O
RoI	O
feature	O
vector	O
,	O
to	O
be	O
an	O
embedding	O
in	O
the	O
subcategory	O
space	O
.	O
	
iv	O
)	O
	
Finally	O
,	O
the	O
network	O
terminates	O
at	O
three	O
output	O
layers	O
.	O
	
The	O
first	O
output	O
layer	O
applies	O
a	O
softmax	O
function	O
directly	O
on	O
the	O
output	O
of	O
the	O
“	O
subcategory	O
FC	B-Method
”	O
layer	O
for	O
subcategory	B-Task
classification	I-Task
.	O
	
The	O
other	O
two	O
output	O
layers	O
operate	O
on	O
the	O
RoI	O
feature	O
vector	O
and	O
apply	O
FC	B-Method
layers	O
for	O
object	B-Task
class	I-Task
classification	I-Task
and	O
bounding	B-Task
box	I-Task
regression	I-Task
.	O
	
subsection	O
:	O
Network	B-Method
Training	I-Method
	
We	O
train	O
our	O
object	B-Task
detection	I-Task
network	O
with	O
a	O
multi	B-Task
-	I-Task
task	I-Task
loss	I-Task
for	O
joint	B-Task
object	I-Task
class	I-Task
classification	I-Task
,	O
subcategory	B-Task
classification	I-Task
and	O
bounding	B-Task
box	I-Task
regression	I-Task
:	O
where	O
is	O
a	O
probability	O
distribution	O
over	O
subcategories	O
,	O
is	O
a	O
probability	O
distribution	O
over	O
object	O
classes	O
,	O
and	O
are	O
the	O
truth	O
subcategory	O
label	O
and	O
the	O
true	O
class	O
label	O
respectively	O
,	O
and	O
are	O
the	O
predicted	O
vector	O
and	O
the	O
true	O
vector	O
for	O
bounding	B-Method
box	I-Method
regression	I-Method
respectively	O
,	O
and	O
and	O
are	O
predefined	O
weights	O
to	O
balance	O
the	O
losses	O
of	O
different	O
tasks	O
.	O
	
and	O
are	O
the	O
standard	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
loss	I-Metric
,	O
and	O
is	O
the	O
smoothed	O
loss	O
as	O
in	O
our	O
RPN	B-Method
.	O
	
In	O
back	B-Method
-	I-Method
propagation	I-Method
training	I-Method
,	O
derivatives	O
for	O
the	O
multi	B-Task
-	I-Task
task	I-Task
loss	I-Task
are	O
back	O
-	O
propagated	O
to	O
the	O
previous	O
layers	O
.	O
	
Red	O
arrows	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
indicate	O
the	O
route	O
of	O
the	O
derivative	O
flow	O
.	O
	
section	O
:	O
Experiments	O
	
subsection	O
:	O
Experimental	O
Settings	O
	
Datasets	O
.	O
	
We	O
evaluate	O
our	O
object	B-Task
detection	I-Task
framework	O
on	O
the	O
KITTI	B-Material
detection	I-Material
benchmark	I-Material
,	O
the	O
PASCAL3D	B-Material
+	I-Material
dataset	I-Material
and	O
the	O
PASCAL	B-Material
VOC	O
2007	O
dataset	O
.	O
	
i	O
)	O
	
The	O
KITTI	B-Material
dataset	O
consists	O
of	O
video	O
frames	O
from	O
autonomous	O
driving	O
scenes	O
,	O
with	O
7	O
,	O
481	O
images	O
for	O
training	O
and	O
7	O
,	O
518	O
images	O
for	O
testing	O
.	O
	
Car	O
,	O
pedestrian	O
and	O
cyclist	O
are	O
evaluated	O
for	O
object	B-Task
detection	I-Task
.	O
	
Since	O
the	O
ground	O
truth	O
annotations	O
of	O
the	O
KITTI	B-Material
test	O
set	O
are	O
not	O
released	O
,	O
we	O
split	O
the	O
KITTI	B-Material
training	O
images	O
into	O
a	O
train	O
set	O
and	O
a	O
validation	O
set	O
for	O
analyses	O
as	O
in	O
.	O
	
ii	O
)	O
	
The	O
PASCAL3D	B-Material
+	I-Material
dataset	I-Material
augments	O
12	O
rigid	O
categories	O
in	O
the	O
PASCAL	B-Material
VOC	O
2012	O
with	O
3D	O
annotations	O
.	O
	
Each	O
object	O
in	O
the	O
12	O
categories	O
is	O
registered	O
with	O
a	O
3D	B-Method
CAD	I-Method
model	I-Method
.	O
	
The	O
train	O
set	O
of	O
PASCAL	B-Material
VOC	O
2012	O
is	O
used	O
for	O
training	O
(	O
5	O
,	O
717	O
images	O
)	O
,	O
while	O
the	O
val	O
set	O
is	O
used	O
for	O
testing	O
(	O
5	O
,	O
823	O
images	O
)	O
.	O
	
iii	O
)	O
	
The	O
PASCAL	B-Material
VOC	O
2007	O
dataset	O
contains	O
5	O
,	O
011	O
training	O
images	O
and	O
4	O
,	O
952	O
testing	O
images	O
on	O
20	O
categories	O
.	O
	
Evaluation	O
Metrics	O
.	O
	
On	O
KITTI	B-Material
,	O
we	O
evaluate	O
our	O
detection	B-Method
framework	I-Method
at	O
three	O
levels	O
of	O
difficulty	O
as	O
suggested	O
by	O
,	O
i.e.	O
,	O
easy	O
,	O
moderate	O
and	O
hard	O
,	O
where	O
the	O
difficulty	O
is	O
measured	O
by	O
the	O
minimal	O
scale	O
of	O
object	O
to	O
be	O
considered	O
and	O
the	O
occlusion	O
and	O
truncation	O
of	O
the	O
object	O
.	O
	
Average	B-Metric
Precision	I-Metric
(	O
AP	B-Metric
)	O
is	O
used	O
to	O
measure	O
the	O
detection	B-Metric
performance	I-Metric
,	O
where	O
70	O
%	O
,	O
50	O
%	O
,	O
and	O
50	O
%	O
overlap	B-Metric
thresholds	I-Metric
are	O
adopted	O
by	O
the	O
KITTI	B-Material
benchmark	O
for	O
car	O
,	O
pedestrian	O
and	O
cyclist	O
respectively	O
.	O
	
To	O
evaluate	O
joint	B-Task
detection	I-Task
and	O
orientation	O
estimation	O
on	O
KITTI	B-Material
,	O
introduces	O
Average	B-Metric
Orientation	I-Metric
Similarity	I-Metric
(	O
AOS	B-Metric
)	I-Metric
,	O
which	O
evaluates	O
the	O
orientation	B-Metric
similarity	I-Metric
between	O
detections	O
and	O
ground	O
truths	O
at	O
different	O
detection	B-Metric
	
recalls	B-Metric
.	O
	
introduces	O
Average	B-Metric
Segmentation	I-Metric
Accuracy	I-Metric
(	O
ASA	B-Metric
)	O
for	O
joint	B-Task
detection	I-Task
and	O
segmentation	O
,	O
and	O
Average	B-Metric
Location	I-Metric
Precision	I-Metric
(	O
ALP	B-Metric
)	O
for	O
joint	B-Task
detection	I-Task
and	O
3D	B-Task
location	I-Task
similar	O
to	O
AOS	B-Method
.	O
	
We	O
also	O
use	O
these	O
metrics	O
here	O
.	O
	
On	O
PASCAL3D	B-Material
+	I-Material
and	O
PASCAL	B-Material
VOC	I-Material
2007	I-Material
,	O
the	O
standard	O
AP	B-Metric
with	O
50	O
%	B-Metric
overlap	I-Metric
ratio	I-Metric
is	O
adopted	O
to	O
evaluate	O
object	B-Task
detection	I-Task
.	O
	
For	O
joint	B-Task
detection	I-Task
and	O
pose	B-Task
estimation	I-Task
,	O
we	O
use	O
the	O
Average	B-Metric
Viewpoint	I-Metric
Precision	I-Metric
(	O
AVP	B-Metric
)	O
suggested	O
by	O
,	O
where	O
a	O
detection	B-Task
is	O
considered	O
to	O
be	O
a	O
true	O
positive	O
if	O
its	O
location	O
and	O
viewpoint	O
are	O
both	O
correct	O
.	O
	
Subcategories	O
.	O
	
We	O
experiment	O
with	O
both	O
2D	O
subcategories	O
and	O
3D	O
subcategories	O
.	O
	
For	O
2D	B-Task
subcategories	I-Task
,	O
we	O
cluster	O
objects	O
using	O
2D	O
image	O
features	O
(	O
i.e.	O
,	O
aggregated	O
channel	O
features	O
from	O
)	O
.	O
	
Only	O
bounding	O
box	O
annotations	O
are	O
needed	O
for	O
2D	O
subcategories	O
.	O
	
When	O
additional	O
annotations	O
are	O
available	O
,	O
we	O
can	O
obtain	O
3D	O
subcategories	O
.	O
	
We	O
adopt	O
the	O
3D	B-Method
Voxel	I-Method
Pattern	I-Method
(	O
3DVP	B-Method
)	O
representation	O
for	O
rigid	O
objects	O
(	O
i.e.	O
,	O
car	O
in	O
KITTI	B-Material
and	O
the	O
12	O
categories	O
in	O
PASCAL3D	B-Material
+	I-Material
)	O
,	O
which	O
jointly	O
models	O
object	O
pose	O
,	O
occlusion	O
and	O
truncation	O
in	O
the	O
clustering	B-Method
process	I-Method
.	O
	
Each	O
3DVP	B-Method
is	O
considered	O
to	O
be	O
a	O
subcategory	O
.	O
	
For	O
pedestrian	B-Task
and	I-Task
cyclist	I-Task
in	O
KITTI	B-Material
,	O
we	O
perform	O
clustering	B-Method
according	O
to	O
the	O
object	O
orientation	O
,	O
and	O
each	O
cluster	O
is	O
considered	O
to	O
be	O
a	O
subcategory	O
.	O
	
In	O
this	O
way	O
,	O
by	O
subcategory	B-Task
classification	I-Task
,	O
we	O
can	O
transfer	O
the	O
meta	O
data	O
carried	O
by	O
3DVPs	O
(	O
3D	O
pose	O
,	O
segmentation	O
boundary	O
and	O
occluded	O
regions	O
)	O
to	O
the	O
detected	O
object	O
.	O
	
For	O
validation	B-Task
on	O
KITTI	B-Material
(	O
3	O
,	O
682	O
images	O
for	O
training	O
,	O
3	O
,	O
799	O
images	O
for	O
testing	O
)	O
,	O
we	O
use	O
173	O
subcategories	O
(	O
125	O
3DVPs	O
for	O
car	O
,	O
24	O
poses	O
for	O
pedestrian	O
and	O
cyclist	O
each	O
)	O
,	O
while	O
for	O
testing	O
on	O
KITTI	B-Material
(	O
7	O
,	O
481	O
images	O
for	O
training	O
,	O
7	O
,	O
518	O
images	O
for	O
testing	O
)	O
,	O
we	O
use	O
275	O
subcategories	O
(	O
227	O
3DVPs	O
for	O
car	O
,	O
24	O
poses	O
for	O
pedestrian	O
and	O
cyclist	O
each	O
)	O
.	O
	
3DVPs	B-Method
are	O
discovered	O
with	O
affinity	B-Method
propagation	I-Method
clustering	I-Method
,	O
which	O
automatically	O
discovers	O
the	O
number	O
of	O
clusters	O
from	O
the	O
data	O
.	O
	
For	O
PASCAL3D	B-Material
+	I-Material
,	O
337	O
3DVPs	O
are	O
discovered	O
among	O
the	O
12	O
categories	O
.	O
	
For	O
PASCAL	B-Material
VOC	I-Material
2007	I-Material
,	O
we	O
use	O
240	O
2D	O
subcategories	O
,	O
with	O
12	O
for	O
each	O
class	O
.	O
	
Correspondingly	O
,	O
the	O
output	O
number	O
of	O
the	O
subcategory	B-Method
conv	I-Method
layer	I-Method
in	O
our	O
RPN	B-Method
and	O
that	O
of	O
the	O
subcategory	O
FC	B-Method
layer	O
in	O
our	O
detection	B-Method
network	I-Method
equal	O
to	O
the	O
number	O
of	O
subcategory	O
plus	O
one	O
.	O
	
Region	B-Method
Proposal	I-Method
Network	I-Method
Hyper	I-Method
-	I-Method
parameters	I-Method
.	O
	
In	O
our	O
RPN	B-Method
,	O
we	O
use	O
5	O
scales	O
for	O
KITTI	B-Material
in	O
the	O
input	O
image	O
pyramid	O
and	O
4	O
scales	O
for	O
PASCAL	B-Material
(	O
both	O
PASCAL3D	B-Material
+	I-Material
and	O
PASCAL	B-Material
VOC	I-Material
2007	I-Material
)	O
,	O
where	O
each	O
number	O
indicates	O
the	O
rescaling	O
factor	O
with	O
respect	O
to	O
the	O
original	O
image	O
size	O
.	O
	
Objects	O
in	O
PASCAL	B-Material
have	O
smaller	O
scale	O
variation	O
compared	O
to	O
objects	O
in	O
KITTI	B-Material
.	O
	
Adding	O
larger	O
scales	O
for	O
PASCAL	B-Material
only	O
results	O
in	O
marginal	O
improvement	O
but	O
significantly	O
increases	O
the	O
computation	O
.	O
	
The	O
feature	B-Method
extrapolating	I-Method
layer	I-Method
extrapolates	O
4	O
scales	O
with	O
equal	O
intervals	O
between	O
every	O
two	O
input	O
scales	O
,	O
so	O
the	O
final	O
conv	B-Method
feature	I-Method
pyramid	I-Method
has	O
21	O
scales	O
for	O
KITTI	B-Material
and	O
16	O
scales	O
for	O
PASCAL	B-Material
.	O
	
In	O
the	O
RoI	B-Method
generating	I-Method
layer	I-Method
,	O
each	O
location	O
in	O
a	O
heat	O
map	O
generates	O
7	O
boxes	O
with	O
7	O
different	O
aspect	O
ratios	O
for	O
KITTI	B-Material
and	O
5	O
aspect	O
ratios	O
for	O
PASCAL	B-Material
,	O
where	O
each	O
number	O
indicates	O
the	O
ratio	O
between	O
the	O
height	O
and	O
the	O
width	O
of	O
the	O
bounding	O
box	O
.	O
	
In	O
training	O
the	O
RPN	B-Method
,	O
each	O
SGD	B-Method
mini	I-Method
-	I-Method
batch	I-Method
is	O
constructed	O
from	O
a	O
single	O
image	O
,	O
chosen	O
uniformly	O
at	O
random	O
.	O
	
A	O
mini	O
-	O
batch	O
has	O
size	O
128	O
,	O
with	O
64	O
positive	O
RoIs	O
and	O
64	O
negative	O
RoIs	O
,	O
where	O
the	O
IoU	B-Metric
threshold	O
is	O
70	O
%	O
for	O
both	O
KITTI	B-Material
and	O
PASCAL	B-Material
.	O
	
Detection	B-Task
Network	O
Hyper	O
-	O
parameters	O
.	O
	
In	O
our	O
detection	B-Method
network	I-Method
,	O
we	O
use	O
4	O
scales	O
in	O
the	O
input	O
image	O
pyramid	O
for	O
KITTI	B-Material
and	O
2	O
scales	O
for	O
PASCAL	B-Material
,	O
both	O
with	O
4	O
scales	O
extrapolated	O
between	O
every	O
two	O
scales	O
.	O
	
Each	O
SGD	B-Method
mini	I-Method
-	I-Method
batch	I-Method
is	O
constructed	O
from	O
2	O
images	O
.	O
	
A	O
mini	O
-	O
batch	O
has	O
size	O
128	O
,	O
with	O
64	O
RoIs	O
from	O
each	O
image	O
.	O
	
25	O
%	O
of	O
the	O
RoIs	O
are	O
positive	O
,	O
where	O
the	O
IoU	B-Metric
threshold	O
is	O
70	O
%	O
for	O
car	O
in	O
KITTI	B-Material
,	O
and	O
50	O
%	O
for	O
the	O
other	O
categories	O
.	O
	
The	O
same	O
SGD	O
hyper	O
-	O
parameters	O
are	O
used	O
as	O
in	O
for	O
region	B-Task
proposal	I-Task
and	I-Task
detection	I-Task
.	O
	
Fine	B-Method
-	I-Method
tuning	I-Method
Pre	I-Method
-	I-Method
trained	I-Method
Networks	I-Method
.	O
	
Our	O
framework	O
is	O
implemented	O
in	O
Caffe	B-Method
.	O
	
We	O
initialize	O
the	O
conv	B-Method
layers	I-Method
for	O
feature	B-Task
extraction	I-Task
in	O
both	O
networks	O
and	O
the	O
two	O
FC	B-Method
layers	O
before	O
subcategory	O
FC	B-Method
layer	O
in	O
the	O
detection	B-Method
network	I-Method
with	O
pre	O
-	O
trained	B-Method
networks	I-Method
on	O
ImageNet	B-Material
.	O
	
On	O
KITTI	B-Material
,	O
we	O
experiment	O
with	O
the	O
AlexNet	B-Method
,	O
the	O
VGG16	B-Method
network	I-Method
and	O
the	O
GoogleNet	B-Method
.	O
	
On	O
PASCAL	B-Material
,	O
we	O
fine	O
-	O
tune	O
the	O
VGG16	B-Method
network	I-Method
.	O
	
subsection	O
:	O
Analysis	O
on	O
KITTI	B-Material
Validation	O
Set	O
	
Region	B-Method
Proposal	I-Method
Evalutaion	I-Method
on	O
Recall	B-Metric
.	O
	
We	O
evaluate	O
the	O
detection	B-Metric
recall	I-Metric
of	O
our	O
RPN	B-Method
and	O
compare	O
it	O
with	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
in	O
Table	O
[	O
reference	O
]	O
on	O
the	O
KITTI	B-Material
validation	O
set	O
.	O
	
For	O
each	O
image	O
,	O
we	O
use	O
2k	O
proposals	O
for	O
all	O
the	O
methods	O
.	O
	
First	O
,	O
two	O
popular	O
methods	O
that	O
work	O
well	O
on	O
PASCAL	B-Material
VOC	I-Material
,	O
Selective	B-Task
Search	I-Task
and	O
Edge	O
Boxes	O
,	O
do	O
not	O
perform	O
well	O
on	O
KITTI	B-Material
,	O
mainly	O
because	O
objects	O
in	O
KITTI	B-Material
exhibit	O
more	O
significant	O
scale	O
variation	O
,	O
occlusion	O
and	O
truncation	O
.	O
	
It	O
is	O
challenging	O
for	O
a	O
bottom	B-Method
-	I-Method
up	I-Method
proposal	I-Method
method	I-Method
to	O
achieve	O
high	O
recall	B-Metric
under	O
a	O
small	O
budget	O
(	O
i.e	O
,	O
2k	O
boxes	O
per	O
image	O
)	O
.	O
	
Second	O
,	O
the	O
RPN	B-Method
in	O
Faster	O
R	O
-	O
CNN	B-Method
performs	O
much	O
better	O
than	O
Selective	O
Search	O
and	O
Edge	O
Boxes	O
,	O
which	O
demonstrates	O
the	O
ability	O
of	O
discriminatively	B-Method
trained	I-Method
CNNs	I-Method
for	O
region	B-Task
proposal	I-Task
.	O
	
But	O
we	O
have	O
to	O
increase	O
its	O
parameter	O
setting	O
from	O
3	O
scales	O
and	O
3	O
aspect	O
ratios	O
in	O
to	O
10	O
scales	O
and	O
7	O
aspect	O
ratios	O
in	O
order	O
to	O
make	O
it	O
work	O
on	O
KITTI	B-Material
.	O
	
Finally	O
,	O
our	O
RPN	B-Method
performs	O
on	O
par	O
with	O
Faster	O
R	O
-	O
CNN	B-Method
on	O
car	B-Task
,	O
and	O
outperforms	O
it	O
on	O
pedestrian	B-Task
and	O
cyclist	B-Task
using	O
the	O
same	O
number	O
of	O
proposals	O
per	O
image	O
.	O
	
Our	O
new	O
architecture	O
can	O
better	O
handle	O
scale	O
variation	O
using	O
image	O
pyramid	O
.	O
	
It	O
also	O
benefits	O
from	O
data	B-Task
mining	I-Task
hard	O
training	O
examples	O
in	O
our	O
RoI	B-Method
generating	I-Method
layer	I-Method
.	O
	
Region	B-Method
Proposal	I-Method
Evalutaion	I-Method
on	O
Detection	B-Task
and	O
Oritentaion	O
Estimation	O
.	O
	
Detection	B-Task
recall	O
measures	O
the	O
coverage	O
of	O
region	O
proposals	O
,	O
which	O
can	O
not	O
demonstrate	O
the	O
quality	O
of	O
the	O
region	O
proposals	O
for	O
detection	B-Task
.	O
	
In	O
this	O
experiment	O
,	O
we	O
directly	O
measure	O
the	O
detection	B-Task
and	I-Task
orientation	I-Task
estimation	I-Task
performance	O
using	O
different	O
region	B-Method
proposals	I-Method
.	O
	
Table	O
[	O
reference	O
]	O
presents	O
the	O
detection	B-Task
and	I-Task
orientation	I-Task
estimation	I-Task
results	O
using	O
RPN	B-Method
in	O
Faster	O
R	O
-	O
CNN	B-Method
and	O
the	O
RPN	B-Method
we	O
propose	O
,	O
while	O
keeping	O
the	O
detection	B-Method
network	I-Method
the	O
same	O
as	O
described	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
.	O
	
We	O
compare	O
our	O
RPN	B-Method
with	O
two	O
variations	O
of	O
the	O
RPN	B-Method
in	O
Faster	O
R	O
-	O
CNN	B-Method
.	O
	
For	O
the	O
first	O
model	O
,	O
the	O
RPN	B-Method
and	O
the	O
detection	B-Method
network	I-Method
are	O
trained	O
independently	O
to	O
each	O
other	O
(	O
“	O
unshared	O
”	O
)	O
.	O
	
For	O
the	O
second	O
model	O
,	O
the	O
RPN	B-Method
and	O
the	O
detection	B-Method
network	I-Method
share	O
their	O
conv	B-Method
layers	I-Method
for	O
feature	B-Task
extraction	I-Task
in	O
order	O
to	O
save	O
computation	O
on	O
convolution	B-Task
(	O
“	O
shared	O
”	O
)	O
.	O
	
The	O
sharing	O
is	O
achieved	O
by	O
the	O
four	O
-	O
step	O
alternating	B-Method
optimization	I-Method
training	I-Method
algorithm	I-Method
described	O
in	O
.	O
	
By	O
comparing	O
the	O
two	O
models	O
in	O
Table	O
[	O
reference	O
]	O
,	O
we	O
find	O
that	O
sharing	O
conv	O
layers	O
hurts	O
the	O
performance	O
on	O
car	B-Task
and	O
pedestrian	B-Task
,	O
but	O
improves	O
the	O
performance	O
on	O
cyclist	B-Task
.	O
	
Car	O
and	O
pedestrian	O
have	O
much	O
more	O
training	O
examples	O
available	O
than	O
cyclist	O
.	O
	
With	O
enough	O
training	O
data	O
,	O
the	O
RPN	B-Method
and	O
the	O
detection	B-Method
network	I-Method
trained	O
independently	O
can	O
develop	O
conv	O
features	O
suitable	O
for	O
its	O
own	O
task	O
.	O
	
In	O
this	O
case	O
,	O
shared	O
conv	O
features	O
degrade	O
the	O
performance	O
.	O
	
However	O
,	O
when	O
the	O
training	O
data	O
is	O
insufficient	O
,	O
sharing	O
conv	O
features	O
can	O
help	O
.	O
	
In	O
Table	O
[	O
reference	O
]	O
,	O
by	O
using	O
region	B-Method
proposals	I-Method
from	O
our	O
RPN	B-Method
,	O
we	O
achieve	O
better	O
performance	O
on	O
detection	B-Task
and	O
orientation	B-Task
estimation	I-Task
across	O
all	O
the	O
three	O
categories	O
.	O
	
The	O
experimental	O
results	O
demonstrate	O
the	O
advantages	O
of	O
our	O
RPN	B-Method
.	O
	
We	O
also	O
tried	O
to	O
share	O
the	O
conv	O
layers	O
in	O
our	O
RPN	B-Method
and	O
our	O
detection	B-Method
network	I-Method
.	O
	
However	O
,	O
since	O
the	O
architecture	O
of	O
our	O
RPN	B-Method
after	O
the	O
conv	B-Method
layers	I-Method
for	O
feature	B-Task
extraction	I-Task
is	O
quite	O
different	O
from	O
that	O
of	O
the	O
detection	B-Method
network	I-Method
,	O
we	O
found	O
that	O
the	O
training	O
can	O
not	O
converge	O
,	O
which	O
verifies	O
our	O
observation	O
that	O
the	O
RPN	B-Method
and	O
the	O
detection	B-Method
network	I-Method
have	O
developed	O
their	O
own	O
conv	O
features	O
that	O
are	O
suitable	O
for	O
its	O
own	O
task	O
.	O
	
Detection	B-Task
Network	O
Evalutaion	O
.	O
	
In	O
Table	O
[	O
reference	O
]	O
,	O
we	O
first	O
show	O
that	O
our	O
RPN	B-Method
achieves	O
significantly	O
better	O
performance	O
than	O
the	O
RPN	B-Method
in	O
when	O
the	O
two	O
RPNs	B-Method
are	O
used	O
with	O
Fast	O
R	O
-	O
CNN	B-Method
on	O
the	O
KITTI	B-Material
validation	O
set	O
respectively	O
.	O
	
Then	O
,	O
we	O
use	O
region	O
proposals	O
from	O
our	O
RPN	B-Method
and	O
compare	O
different	O
variations	O
of	O
the	O
network	B-Method
architecture	I-Method
for	O
detection	B-Task
.	O
	
i	O
)	O
	
“	O
	
Ours	O
w	O
/	O
o	O
Pose	O
”	O
indicates	O
using	O
2D	O
subcategories	O
from	O
clustering	B-Method
on	O
2D	O
appearances	O
of	O
objects	O
without	O
using	O
additional	O
pose	O
information	O
.	O
	
As	O
we	O
can	O
see	O
,	O
our	O
method	O
still	O
outperforms	O
Fatser	O
R	O
-	O
CNN	B-Method
in	O
this	O
case	O
.	O
	
ii	O
)	O
	
By	O
using	O
pose	O
information	O
to	O
obtain	O
subcategories	O
,	O
our	O
detection	B-Method
network	I-Method
is	O
also	O
able	O
to	O
estimate	O
the	O
orientation	O
of	O
the	O
object	O
.	O
	
“	O
	
Ours	O
w	O
/	O
o	O
Extra	O
”	O
refers	O
to	O
a	O
network	O
without	O
feature	B-Method
extrapolating	I-Method
.	O
	
By	O
augmenting	O
the	O
network	O
with	O
the	O
feature	B-Method
extrapolating	I-Method
layer	I-Method
,	O
our	O
full	B-Method
model	I-Method
	
(	O
“	O
	
Ours	O
Full	O
”	O
in	O
Table	O
[	O
reference	O
]	O
)	O
	
further	O
boosts	O
the	O
performance	O
,	O
except	O
for	O
a	O
minor	O
drop	O
on	O
orientation	B-Task
estimation	I-Task
of	I-Task
pedestrian	I-Task
.	O
	
Evaluation	O
on	O
2D	B-Task
Segmentation	I-Task
and	O
3D	B-Task
Localization	I-Task
.	O
	
3DVPs	B-Method
enable	O
us	O
to	O
transfer	O
the	O
meta	O
data	O
to	O
the	O
detect	O
objects	O
,	O
so	O
our	O
method	O
is	O
able	O
to	O
segment	O
the	O
boundary	O
of	O
object	O
.	O
	
In	O
addition	O
,	O
after	O
detecting	O
the	O
objects	O
and	O
estimating	O
their	O
3D	O
poses	O
,	O
we	O
can	O
back	O
-	O
project	O
them	O
into	O
3D	O
using	O
the	O
camera	O
parameters	O
provided	O
in	O
KITTI	B-Material
,	O
so	O
as	O
to	O
evaluate	O
the	O
3D	B-Task
localization	I-Task
performance	O
.	O
	
In	O
table	O
[	O
reference	O
]	O
,	O
we	O
compare	O
our	O
method	O
on	O
2D	B-Task
segmentation	I-Task
and	O
3D	B-Task
localization	I-Task
of	I-Task
car	I-Task
with	O
DPM	B-Method
and	O
3DVP	B-Method
on	O
the	O
KITTI	B-Material
validation	O
set	O
.	O
	
We	O
have	O
significantly	O
improve	O
the	O
segmentation	B-Metric
accuracy	I-Metric
and	O
3D	B-Metric
location	I-Metric
accuracy	I-Metric
when	O
the	O
2	O
-	O
meter	O
threshold	O
is	O
used	O
(	O
i.e.	O
,	O
a	O
detection	O
within	O
2	O
meters	O
from	O
the	O
ground	O
truth	O
location	O
is	O
considered	O
to	O
be	O
correct	O
)	O
.	O
	
Surprisingly	O
,	O
obtains	O
better	O
3D	B-Metric
localization	I-Metric
accuracy	I-Metric
with	O
the	O
1	O
-	O
meter	O
threshold	O
,	O
which	O
indicates	O
that	O
more	O
detections	O
from	O
are	O
within	O
the	O
1	O
-	O
meter	O
distance	O
from	O
the	O
ground	O
truth	O
.	O
	
subsection	O
:	O
KITTI	B-Material
Test	O
Set	O
Evaluation	O
	
To	O
compare	O
with	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
on	O
the	O
KITTI	B-Material
detection	I-Material
benchmark	I-Material
,	O
we	O
train	O
our	O
RPN	B-Method
and	O
detection	O
network	O
with	O
all	O
the	O
KITTI	B-Material
training	O
data	O
,	O
and	O
then	O
test	O
our	O
method	O
on	O
the	O
KITTI	B-Material
test	O
set	O
by	O
submitting	O
our	O
results	O
to	O
.	O
	
Table	O
[	O
reference	O
]	O
presents	O
the	O
detection	B-Task
and	I-Task
orientation	I-Task
estimation	I-Task
results	O
on	O
the	O
three	O
categories	O
,	O
where	O
we	O
compare	O
our	O
method	O
(	O
SubCNN	B-Method
)	O
with	O
different	O
methods	O
evaluated	O
on	O
KITTI	B-Material
.	O
	
We	O
have	O
experimented	O
fine	O
-	O
tuning	O
both	O
the	O
VGG16	B-Method
network	I-Method
and	O
the	O
GoogleNet	B-Method
for	O
the	O
detection	B-Task
network	I-Task
.	O
	
Our	O
method	O
ranks	O
on	O
top	O
among	O
all	O
the	O
published	O
methods	O
.	O
	
The	O
experimental	O
results	O
demonstrate	O
the	O
ability	O
of	O
our	O
CNNs	B-Method
in	O
using	O
subcategory	O
information	O
for	O
detection	B-Task
and	I-Task
orientation	I-Task
estimation	I-Task
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
presents	O
some	O
examples	O
of	O
our	O
detection	B-Task
and	I-Task
3D	I-Task
localization	I-Task
results	O
on	O
KITTI	B-Material
.	O
	
subsection	O
:	O
Evaluation	O
on	O
PASCAL3D	B-Material
+	I-Material
and	O
PASCAL	B-Material
VOC	I-Material
	
We	O
also	O
evaluate	O
our	O
detection	B-Method
framework	I-Method
on	O
the	O
12	O
categories	O
in	O
PASCAL3D	B-Material
+	I-Material
.	O
	
Table	O
[	O
reference	O
]	O
presents	O
the	O
detection	B-Task
results	O
in	O
AP	B-Metric
and	O
the	O
joint	B-Task
detection	I-Task
and	O
pose	B-Task
estimation	I-Task
results	O
in	O
AVP	B-Metric
.	O
	
After	O
generating	O
region	O
proposals	O
from	O
our	O
RPN	B-Method
,	O
we	O
experiment	O
with	O
our	O
detection	B-Method
networks	I-Method
with	O
and	O
without	O
feature	B-Method
extrapolation	I-Method
.	O
	
First	O
,	O
in	O
terms	O
of	O
detection	B-Task
,	O
our	O
method	O
improves	O
over	O
R	O
-	O
CNN	B-Method
on	O
all	O
12	O
categories	O
.	O
	
Second	O
,	O
in	O
terms	O
of	O
join	B-Task
detection	I-Task
and	O
pose	B-Task
estimation	I-Task
,	O
our	O
method	O
significantly	O
outperforms	O
two	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
:	O
VDPM	B-Method
and	O
DPM	B-Method
-	I-Method
VOC	I-Method
+	I-Method
VP	I-Method
.	O
	
Third	O
,	O
feature	B-Task
extrapolation	I-Task
helps	O
both	O
detection	O
and	O
pose	B-Task
estimation	I-Task
on	O
PASCAL3D	B-Material
+	I-Material
.	O
	
It	O
is	O
worth	O
mentioning	O
that	O
PASCAL3D	B-Material
+	I-Material
has	O
much	O
fewer	O
training	O
examples	O
in	O
each	O
subcategory	O
compared	O
to	O
KITTI	B-Material
.	O
	
Our	O
pose	B-Task
estimation	I-Task
performance	O
is	O
limited	O
by	O
the	O
number	O
of	O
training	O
examples	O
available	O
in	O
PASCAL3D	B-Material
+	I-Material
.	O
	
We	O
also	O
note	O
that	O
the	O
two	O
recent	O
methods	O
achieve	O
very	O
appealing	O
pose	B-Task
estimation	I-Task
results	O
on	O
PASCAL3D	B-Material
+	I-Material
.	O
	
However	O
,	O
both	O
of	O
them	O
utilize	O
additional	O
training	O
images	O
(	O
ImageNet	B-Material
images	I-Material
in	O
and	O
synthetic	O
images	O
in	O
)	O
and	O
conduct	O
detection	O
and	O
pose	B-Task
estimation	I-Task
with	O
separate	O
CNNs	B-Method
,	O
where	O
a	O
CNN	B-Method
is	O
specifically	O
designed	O
for	O
pose	B-Task
estimation	I-Task
.	O
	
Our	O
method	O
is	O
capable	O
of	O
simultaneous	O
object	B-Task
detection	I-Task
and	O
viewpoint	O
estimation	O
even	O
in	O
the	O
presence	O
of	O
limited	O
training	O
examples	O
per	O
viewpoint	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
some	O
detection	B-Task
results	O
from	O
our	O
method	O
.	O
	
We	O
again	O
transfer	O
segmentation	O
masks	O
of	O
3DVPs	O
to	O
the	O
detected	O
objects	O
according	O
to	O
the	O
subcategory	B-Task
classification	I-Task
results	O
.	O
	
Please	O
see	O
supplementary	O
material	O
for	O
more	O
examples	O
.	O
	
To	O
demonstrate	O
that	O
our	O
method	O
also	O
works	O
on	O
datasets	O
with	O
bounding	O
box	O
annotations	O
only	O
,	O
we	O
have	O
conducted	O
experiments	O
on	O
the	O
PASCAL	B-Material
VOC	O
2007	O
dataset	O
,	O
where	O
subcategories	O
are	O
obtained	O
by	O
clustering	B-Method
on	O
image	O
features	O
.	O
	
In	O
table	O
[	O
reference	O
]	O
,	O
we	O
compare	O
with	O
Fast	O
R	O
-	O
CNN	B-Method
and	O
Faster	O
R	O
-	O
CNN	B-Method
.	O
	
We	O
have	O
achieved	O
comparable	O
performance	O
to	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
arts	O
.	O
	
Region	B-Method
proposal	I-Method
on	O
PASCAL	B-Material
VOC	I-Material
is	O
relatively	O
easy	O
compared	O
to	O
KITTI	B-Material
.	O
	
So	O
we	O
do	O
not	O
see	O
much	O
improvement	O
with	O
our	O
RPN	B-Method
on	O
PASCAL	B-Material
VOC	I-Material
2007	I-Material
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
work	O
,	O
we	O
explore	O
how	O
subcategory	O
information	O
can	O
be	O
exploited	O
in	O
CNN	B-Method
-	O
based	O
object	B-Task
detection	I-Task
.	O
	
We	O
have	O
proposed	O
a	O
novel	O
region	B-Method
proposal	I-Method
network	I-Method
,	O
and	O
a	O
novel	O
object	B-Task
detection	I-Task
network	O
,	O
where	O
we	O
explicitly	O
employ	O
subcategory	O
information	O
to	O
improve	O
region	B-Task
proposal	I-Task
generation	I-Task
,	O
	
object	B-Task
detection	I-Task
and	O
object	O
pose	B-Task
estimation	I-Task
.	O
	
Our	O
subcategory	B-Method
-	I-Method
aware	I-Method
CNNs	I-Method
can	O
also	O
handle	O
the	O
scale	O
variation	O
of	O
objects	O
using	O
image	O
pyramids	O
in	O
an	O
efficient	O
way	O
.	O
	
We	O
have	O
conducted	O
extensive	O
experiments	O
on	O
the	O
KITTI	B-Material
detection	I-Material
benchmark	I-Material
,	O
the	O
PASCAL3D	B-Material
+	I-Material
dataset	I-Material
and	O
PASCAL	B-Material
VOC	O
2007	O
dataset	O
.	O
	
Our	O
method	O
achieves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
these	O
benchmarks	O
.	O
	
Acknowledgments	O
.	O
	
We	O
acknowledge	O
the	O
support	O
of	O
Nissan	O
grant	O
1188371	O
-	O
1	O
-	O
UDARQ	O
and	O
MURI	O
grant	O
1186514	O
-	O
1	O
-	O
TBCJE	O
.	O
	
bibliography	O
:	O
References	O
	
Geometric	B-Task
Matrix	I-Task
Completion	I-Task
with	O
Recurrent	B-Method
Multi	I-Method
-	I-Method
Graph	I-Method
Neural	I-Method
Networks	I-Method
	
section	O
:	O
Abstract	O
	
Matrix	B-Method
completion	I-Method
models	I-Method
are	O
among	O
the	O
most	O
common	O
formulations	O
of	O
recommender	B-Task
systems	I-Task
.	O
	
Recent	O
works	O
have	O
showed	O
a	O
boost	O
of	O
performance	O
of	O
these	O
techniques	O
when	O
introducing	O
the	O
pairwise	O
relationships	O
between	O
users	O
/	O
items	O
in	O
the	O
form	O
of	O
graphs	O
,	O
and	O
imposing	O
smoothness	O
priors	O
on	O
these	O
graphs	O
.	O
	
However	O
,	O
such	O
techniques	O
do	O
not	O
fully	O
exploit	O
the	O
local	O
stationarity	O
structures	O
of	O
user	O
/	O
item	O
graphs	O
,	O
and	O
the	O
number	O
of	O
parameters	O
to	O
learn	O
is	O
linear	O
w.r.t	O
.	O
	
the	O
number	O
of	O
users	O
and	O
items	O
.	O
	
We	O
propose	O
a	O
novel	O
approach	O
to	O
overcome	O
these	O
limitations	O
by	O
using	O
geometric	B-Method
deep	I-Method
learning	I-Method
on	I-Method
graphs	I-Method
.	O
	
Our	O
matrix	B-Method
completion	I-Method
architecture	I-Method
combines	O
graph	B-Method
convolutional	I-Method
neural	I-Method
networks	I-Method
and	O
recurrent	B-Method
neural	I-Method
networks	I-Method
to	O
learn	O
meaningful	O
statistical	O
graph	O
-	O
structured	O
patterns	O
and	O
the	O
non	B-Method
-	I-Method
linear	I-Method
diffusion	I-Method
process	I-Method
that	O
generates	O
the	O
known	O
ratings	O
.	O
	
This	O
neural	B-Method
network	I-Method
system	I-Method
requires	O
a	O
constant	O
number	O
of	O
parameters	O
independent	O
of	O
the	O
matrix	O
size	O
.	O
	
We	O
apply	O
our	O
method	O
on	O
both	O
synthetic	O
and	O
real	O
datasets	O
,	O
showing	O
that	O
it	O
outperforms	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
techniques	O
.	O
	
section	O
:	O
Introduction	O
	
Recommender	B-Method
systems	I-Method
have	O
become	O
a	O
central	O
part	O
of	O
modern	O
intelligent	B-Task
systems	I-Task
.	O
	
Recommending	O
movies	O
on	O
Netflix	O
,	O
friends	O
on	O
Facebook	O
,	O
furniture	O
on	O
Amazon	O
,	O
jobs	O
on	O
LinkedIn	O
are	O
a	O
few	O
examples	O
of	O
the	O
main	O
purpose	O
of	O
these	O
systems	O
.	O
	
Two	O
major	O
approach	O
to	O
recommender	B-Method
systems	I-Method
are	O
collaborative	O
[	O
reference	O
]	O
and	O
content	O
[	O
reference	O
]	O
use	O
of	O
similarities	O
between	O
products	O
and	O
customers	O
to	O
recommend	O
new	O
products	O
.	O
	
Hybrid	B-Method
systems	I-Method
combine	O
collaborative	B-Method
and	I-Method
content	I-Method
techniques	I-Method
.	O
	
Matrix	B-Task
completion	I-Task
.	O
	
Mathematically	O
,	O
a	O
recommendation	B-Method
method	I-Method
can	O
be	O
posed	O
as	O
a	O
matrix	B-Task
completion	I-Task
problem	I-Task
[	O
reference	O
]	O
,	O
where	O
columns	O
and	O
rows	O
represent	O
users	O
and	O
items	O
,	O
respectively	O
,	O
and	O
matrix	O
values	O
represent	O
a	O
score	O
determining	O
whether	O
a	O
user	O
would	O
like	O
an	O
item	O
or	O
not	O
.	O
	
Given	O
a	O
small	O
subset	O
of	O
known	O
elements	O
of	O
the	O
matrix	O
,	O
the	O
goal	O
is	O
to	O
fill	O
in	O
the	O
rest	O
.	O
	
A	O
famous	O
example	O
is	O
the	O
Netflix	O
challenge	O
[	O
reference	O
]	O
)	O
offered	O
in	O
2009	O
and	O
carrying	O
a	O
1M$	O
prize	O
for	O
the	O
algorithm	O
that	O
can	O
best	O
predict	O
user	O
ratings	O
for	O
movies	O
based	O
on	O
previous	O
ratings	O
.	O
	
The	O
size	O
of	O
the	O
Netflix	B-Material
is	O
480k	O
movies	O
	
×	O
18k	O
users	O
(	O
8.5B	O
entries	O
)	O
,	O
with	O
only	O
0.011	O
%	O
known	O
entries	O
.	O
	
Recently	O
,	O
there	O
have	O
been	O
several	O
attempts	O
to	O
incorporate	O
geometric	O
structure	O
into	O
matrix	B-Task
completion	I-Task
problems	I-Task
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
,	O
e.g.	O
in	O
the	O
form	O
of	O
column	O
and	O
row	O
graphs	O
representing	O
similarity	O
of	O
users	O
and	O
items	O
,	O
respectively	O
.	O
	
Such	O
additional	O
information	O
makes	O
well	O
-	O
defined	O
e.g.	O
the	O
notion	O
of	O
smoothness	O
of	O
data	O
and	O
was	O
shown	O
beneficial	O
for	O
the	O
performance	O
of	O
recommender	B-Method
systems	I-Method
.	O
	
These	O
approaches	O
can	O
be	O
generally	O
related	O
to	O
the	O
field	O
of	O
signal	B-Task
processing	I-Task
on	I-Task
graphs	I-Task
[	O
reference	O
]	O
,	O
extending	O
classical	O
harmonic	B-Method
analysis	I-Method
methods	I-Method
to	O
non	O
-	O
Euclidean	O
domains	O
.	O
	
Geometric	B-Method
deep	I-Method
learning	I-Method
.	O
	
Of	O
key	O
interest	O
to	O
the	O
design	O
of	O
recommender	B-Task
systems	I-Task
are	O
deep	B-Method
learning	I-Method
approaches	I-Method
.	O
	
In	O
the	O
recent	O
years	O
,	O
deep	B-Method
neural	I-Method
networks	I-Method
and	O
,	O
in	O
particular	O
,	O
convolutional	B-Method
neural	I-Method
networks	I-Method
(	O
CNNs	B-Method
)	O
[	O
reference	O
]	O
have	O
been	O
applied	O
with	O
great	O
success	O
to	O
numerous	O
computer	B-Task
vision	I-Task
-	I-Task
related	I-Task
applications	I-Task
.	O
	
However	O
,	O
original	O
CNN	B-Method
models	I-Method
can	O
not	O
be	O
directly	O
applied	O
to	O
the	O
recommendation	B-Task
problem	I-Task
to	O
extract	O
meaningful	O
patterns	O
in	O
users	O
,	O
items	O
and	O
ratings	O
because	O
these	O
data	O
are	O
not	O
Euclidean	O
structured	O
,	O
i.e.	O
they	O
do	O
not	O
lie	O
on	O
regular	O
lattices	O
like	O
images	O
but	O
irregular	O
domains	O
like	O
graphs	O
or	O
manifolds	O
.	O
	
This	O
strongly	O
motivates	O
the	O
development	O
of	O
geometric	B-Method
deep	I-Method
learning	I-Method
[	O
reference	O
]	O
techniques	O
that	O
can	O
mathematically	O
deal	O
with	O
graph	O
-	O
structured	O
data	O
,	O
which	O
arises	O
in	O
numerous	O
applications	O
,	O
ranging	O
from	O
computer	B-Task
graphics	I-Task
and	I-Task
vision	I-Task
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
to	O
chemistry	O
[	O
reference	O
]	O
.	O
	
The	O
earliest	O
attempts	O
to	O
apply	O
neural	B-Method
networks	I-Method
to	O
graphs	O
are	O
due	O
to	O
[	O
reference	O
]	O
(	O
see	O
more	O
recent	O
formulation	O
[	O
reference	O
][	O
reference	O
]	O
)	O
.	O
	
[	O
reference	O
][	O
reference	O
]	O
formulated	O
CNN	B-Method
-	I-Method
like	I-Method
deep	I-Method
neural	I-Method
architectures	I-Method
on	O
graphs	O
in	O
the	O
spectral	O
domain	O
,	O
employing	O
the	O
analogy	O
between	O
the	O
classical	B-Method
Fourier	I-Method
transforms	I-Method
and	O
projections	O
onto	O
the	O
eigenbasis	O
of	O
the	O
graph	O
Laplacian	O
operator	O
[	O
reference	O
]	O
.	O
	
In	O
a	O
follow	O
-	O
up	O
work	O
,	O
proposed	O
an	O
efficient	O
filtering	B-Method
scheme	I-Method
using	O
recurrent	B-Method
Chebyshev	I-Method
polynomials	I-Method
,	O
which	O
reduces	O
the	O
complexity	B-Metric
of	O
CNNs	B-Method
on	I-Method
graphs	I-Method
to	O
the	O
same	O
complexity	B-Metric
of	O
standard	O
CNNs	B-Method
(	O
on	O
grids	O
)	O
.	O
	
This	O
model	O
was	O
later	O
extended	O
to	O
deal	O
with	O
dynamic	O
data	O
[	O
reference	O
]	O
Main	O
contribution	O
.	O
	
In	O
this	O
work	O
,	O
we	O
treat	O
matrix	B-Task
completion	I-Task
problem	I-Task
as	O
deep	B-Task
learning	I-Task
on	O
graph	O
-	O
structured	O
data	O
.	O
	
We	O
introduce	O
a	O
novel	O
neural	B-Method
network	I-Method
architecture	I-Method
that	O
is	O
able	O
to	O
extract	O
local	O
stationary	O
patterns	O
from	O
the	O
highdimensional	O
spaces	O
of	O
users	O
and	O
items	O
,	O
and	O
use	O
these	O
meaningful	O
representations	O
to	O
infer	O
the	O
non	B-Method
-	I-Method
linear	I-Method
temporal	I-Method
diffusion	I-Method
mechanism	I-Method
of	I-Method
ratings	I-Method
.	O
	
The	O
spatial	O
patterns	O
are	O
extracted	O
by	O
a	O
new	O
CNN	B-Method
architecture	I-Method
designed	O
to	O
work	O
on	O
multiple	O
graphs	O
.	O
	
The	O
temporal	B-Task
dynamics	I-Task
of	I-Task
the	I-Task
rating	I-Task
diffusion	I-Task
is	O
produced	O
by	O
a	O
Long	B-Method
-	I-Method
Short	I-Method
Term	I-Method
Memory	I-Method
(	O
LSTM	B-Method
)	O
recurrent	B-Method
neural	I-Method
network	I-Method
(	O
RNN	B-Method
)	O
	
[	O
reference	O
]	O
.	O
	
To	O
our	O
knowledge	O
,	O
our	O
work	O
is	O
the	O
first	O
application	O
of	O
graph	B-Method
-	I-Method
based	I-Method
deep	I-Method
learning	I-Method
to	O
matrix	B-Task
completion	I-Task
problem	I-Task
.	O
	
The	O
rest	O
of	O
the	O
paper	O
is	O
organized	O
as	O
follows	O
.	O
	
Section	O
2	O
reviews	O
the	O
matrix	B-Method
completion	I-Method
models	I-Method
.	O
	
Section	O
3	O
presents	O
the	O
proposed	O
approach	O
.	O
	
Section	O
4	O
presents	O
experimental	O
results	O
demonstrating	O
the	O
efficiency	O
of	O
our	O
techniques	O
on	O
synthetic	O
and	O
real	O
-	O
world	O
datasets	O
,	O
and	O
Section	O
5	O
concludes	O
the	O
paper	O
.	O
	
section	O
:	O
Background	O
	
section	O
:	O
Matrix	B-Task
Completion	I-Task
	
Matrix	B-Task
completion	I-Task
problem	I-Task
.	O
	
Recovering	O
the	O
missing	O
values	O
of	O
a	O
matrix	O
given	O
a	O
small	O
fraction	O
of	O
its	O
entries	O
is	O
an	O
ill	O
-	O
posed	B-Task
problem	I-Task
without	O
additional	O
mathematical	O
constraints	O
on	O
the	O
space	O
of	O
solutions	O
.	O
	
A	O
well	B-Task
-	I-Task
posed	I-Task
problem	I-Task
is	O
to	O
assume	O
that	O
the	O
variables	O
lie	O
in	O
a	O
smaller	O
subspace	O
,	O
i.e.	O
,	O
that	O
the	O
matrix	O
is	O
of	O
low	O
rank	O
,	O
	
where	O
X	O
denotes	O
the	O
matrix	O
to	O
recover	O
,	O
Ω	O
is	O
the	O
set	O
of	O
the	O
known	O
entries	O
and	O
y	O
ij	O
are	O
their	O
values	O
.	O
	
To	O
make	O
(	O
1	O
)	O
robust	O
against	O
noise	O
and	O
perturbation	O
,	O
the	O
equality	O
constraint	O
can	O
be	O
replaced	O
with	O
a	O
penalty	O
	
where	O
Ω	O
is	O
the	O
indicator	O
matrix	O
of	O
the	O
known	O
entries	O
	
Ω	O
and	O
•	O
denotes	O
the	O
Hadamard	B-Method
pointwise	I-Method
product	I-Method
.	O
	
Unfortunately	O
,	O
rank	B-Task
minimization	I-Task
turns	O
out	O
an	O
NP	B-Task
-	I-Task
hard	I-Task
combinatorial	I-Task
problem	I-Task
that	O
is	O
computationally	O
intractable	O
in	O
practical	O
cases	O
.	O
	
The	O
tightest	O
possible	O
convex	O
relaxation	O
of	O
the	O
previous	O
problem	O
is	O
	
where	O
·	O
is	O
the	O
nuclear	O
norm	O
of	O
a	O
matrix	O
equal	O
to	O
the	O
sum	O
of	O
its	O
singular	O
values	O
[	O
reference	O
]	O
)	O
.	O
	
[	O
reference	O
]	O
proved	O
that	O
the	O
1	B-Method
relaxation	I-Method
of	I-Method
the	I-Method
SVD	I-Method
lead	O
to	O
solutions	O
that	O
recover	O
almost	O
exactly	O
the	O
original	O
low	O
-	O
rank	O
matrix	O
.	O
	
Geometric	B-Method
matrix	I-Method
completion	I-Method
	
An	O
alternative	O
relaxation	O
of	O
the	O
rank	O
operator	O
in	O
(	O
1	O
)	O
is	O
to	O
constraint	O
the	O
space	O
of	O
solutions	O
to	O
be	O
smooth	O
w.r.t	O
.	O
	
some	O
geometric	O
structure	O
of	O
the	O
matrix	O
rows	O
and	O
columns	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
	
The	O
simplest	O
model	O
is	O
proximity	O
structure	O
represented	O
as	O
an	O
undirected	B-Method
weighted	I-Method
column	I-Method
graph	I-Method
	
G	O
c	O
=	O
	
(	O
{	O
1	O
,	O
.	O
	
.	O
.	O
	
,	O
n	O
}	O
,	O
E	O
c	O
,	O
W	O
c	O
)	O
with	O
	
In	O
our	O
notation	O
,	O
the	O
column	O
graph	O
could	O
be	O
thought	O
of	O
as	O
a	O
social	O
network	O
capturing	O
relations	O
between	O
users	O
and	O
the	O
similarity	O
of	O
their	O
tastes	O
.	O
	
The	O
row	B-Method
graph	I-Method
	
G	O
r	O
=	O
	
(	O
{	O
1	O
,	O
.	O
	
.	O
.	O
,	O
m	O
}	O
,	O
	
E	O
r	O
,	O
W	O
r	O
)	O
representing	O
the	O
similarities	O
of	O
the	O
items	O
is	O
defined	O
in	O
a	O
similar	O
manner	O
.	O
	
On	O
each	O
of	O
these	O
graphs	O
one	O
can	O
construct	O
the	O
(	O
unnormalized	O
)	O
graph	O
Laplacian	O
,	O
an	O
n	O
×	O
n	O
symmetric	O
positivesemidefinite	O
matrix	O
	
w	O
ij	O
is	O
the	O
degree	O
matrix	O
.	O
	
We	O
denote	O
the	O
Laplacian	O
associated	O
with	O
row	O
and	O
column	O
graphs	O
by	O
∆	O
r	O
and	O
∆	O
c	O
,	O
respectively	O
.	O
	
Considering	O
the	O
columns	O
(	O
respectively	O
,	O
rows	O
)	O
of	O
matrix	O
X	O
as	O
vector	O
-	O
valued	O
functions	O
on	O
the	O
column	O
graph	O
	
G	O
c	O
(	O
respectively	O
,	O
row	O
graph	O
	
G	O
r	O
)	O
	
,	O
their	O
smoothness	O
can	O
be	O
expressed	O
as	O
the	O
Dirichlet	O
norm	O
X	O
2	O
	
Gr	O
=	O
trace	O
(	O
X	O
	
∆	O
r	O
X	O
)	O
	
(	O
respecitvely	O
,	O
X	O
Gc	O
=	O
trace	O
(	O
X∆	O
c	O
X	O
)	O
)	O
.	O
	
The	O
geometric	B-Task
matrix	I-Task
completion	I-Task
problem	I-Task
thus	O
boils	O
down	O
to	O
minimizing	O
	
n	O
users	B-Method
Factorized	I-Method
models	I-Method
.	O
	
Matrix	B-Method
completion	I-Method
algorithms	I-Method
introduced	O
in	O
the	O
previous	O
section	O
are	O
well	O
-	O
posed	O
as	O
convex	B-Task
optimization	I-Task
problems	I-Task
,	O
guaranteeing	O
existence	O
,	O
uniqueness	O
and	O
robustness	O
of	O
solutions	O
.	O
	
Besides	O
,	O
fast	O
algorithms	O
have	O
been	O
developed	O
in	O
the	O
context	O
of	O
compressed	B-Task
sensing	I-Task
to	O
solve	O
the	O
non	B-Task
-	I-Task
differential	I-Task
nuclear	I-Task
norm	I-Task
problem	I-Task
.	O
	
However	O
,	O
the	O
variables	O
in	O
this	O
formulation	O
are	O
the	O
full	O
m	O
×	O
n	O
matrix	O
X	O
,	O
making	O
such	O
methods	O
hard	O
to	O
scale	O
up	O
to	O
large	O
matrices	O
such	O
as	O
the	O
notorious	O
Netflix	O
challenge	O
.	O
	
A	O
solution	O
is	O
to	O
use	O
a	O
factorized	B-Method
representation	I-Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
)	O
	
X	O
=	O
WH	O
,	O
where	O
W	O
,	O
H	O
are	O
m	O
	
×	O
r	O
	
and	O
n	O
×	O
r	O
matrices	O
,	O
respectively	O
,	O
with	O
r	O
min	O
(	O
m	O
,	O
n	O
)	O
.	O
	
The	O
use	O
of	O
factors	O
W	O
,	O
H	O
reduce	O
the	O
number	O
of	O
degrees	O
of	O
freedom	O
from	O
O	O
(	O
mn	O
)	O
to	O
O	O
(	O
m	O
+	O
n	O
)	O
;	O
this	O
representation	O
is	O
also	O
attractive	O
as	O
solving	O
the	O
matrix	B-Task
completion	I-Task
problem	I-Task
often	O
assumes	O
the	O
original	O
matrix	O
to	O
be	O
low	O
-	O
rank	O
,	O
and	O
rank	O
(	O
WH	O
)	O
	
≤	O
r	O
by	O
construction	O
.	O
	
Figure	O
1	O
shows	O
the	O
full	O
and	O
factorized	O
settings	O
of	O
the	O
matrix	B-Task
completion	I-Task
problem	I-Task
.	O
	
The	O
nuclear	B-Task
norm	I-Task
minimization	I-Task
problem	I-Task
in	O
the	O
previous	O
section	O
can	O
be	O
equivalently	O
rewritten	O
in	O
a	O
factorized	B-Method
form	I-Method
as	O
[	O
reference	O
]	O
:	O
	
and	O
the	O
factorized	B-Method
formulation	I-Method
of	O
the	O
graph	B-Task
-	I-Task
based	I-Task
minimization	I-Task
problem	I-Task
(	O
4	O
)	O
as	O
	
The	O
limitation	O
of	O
model	O
(	O
6	O
)	O
is	O
to	O
decouple	O
the	O
regularization	B-Method
process	I-Method
applied	O
simultaneously	O
on	O
the	O
rows	O
and	O
columns	O
of	O
X	O
in	O
(	O
4	O
)	O
,	O
but	O
the	O
advantage	O
is	O
linear	O
instead	O
of	O
quadratic	B-Metric
complexity	I-Metric
.	O
	
section	O
:	O
Deep	B-Task
learning	I-Task
on	I-Task
graphs	I-Task
	
The	O
key	O
idea	O
to	O
our	O
work	O
is	O
geometric	B-Method
deep	I-Method
learning	I-Method
,	O
an	O
extension	O
of	O
the	O
popular	O
CNNs	B-Method
to	O
graphs	O
.	O
	
A	O
graph	O
Laplacian	O
admits	O
a	O
spectral	B-Method
eigendecomposition	I-Method
of	O
the	O
form	O
∆	O
=	O
ΦΛΦ	O
,	O
where	O
Φ	O
=	O
(	O
φ	O
1	O
,	O
.	O
.	O
.	O
	
φ	O
n	O
)	O
denotes	O
the	O
matrix	O
of	O
orthonormal	O
eigenvectors	O
and	O
Λ	O
=	O
diag	O
(	O
λ	O
1	O
,	O
.	O
.	O
.	O
,	O
	
λ	O
n	O
)	O
	
is	O
the	O
diagonal	O
matrix	O
of	O
the	O
corresponding	O
eigenvalues	O
.	O
	
The	O
eigenvectors	O
play	O
the	O
role	O
of	O
Fourier	O
atoms	O
in	O
classical	B-Method
harmonic	I-Method
analysis	I-Method
and	O
the	O
eigenvalues	O
can	O
be	O
interpreted	O
as	O
frequencies	O
.	O
	
Given	O
a	O
function	O
x	O
=	O
(	O
x	O
1	O
,	O
.	O
.	O
.	O
,	O
x	O
n	O
)	O
on	O
the	O
vertices	O
of	O
the	O
graph	O
,	O
its	O
graph	B-Method
Fourier	I-Method
transform	I-Method
is	O
given	O
byx	O
=	O
	
Φ	O
x.	O
	
The	O
spectral	O
convolution	O
of	O
two	O
functions	O
x	O
,	O
y	O
can	O
be	O
defined	O
as	O
the	O
element	O
-	O
wise	O
product	O
of	O
the	O
respective	O
Fourier	B-Method
transforms	I-Method
,	O
	
Bruna	O
et	O
al	O
.	O
	
2013	O
used	O
the	O
spectral	B-Method
definition	I-Method
of	I-Method
convolution	I-Method
(	O
7	O
)	O
to	O
generalize	O
CNNs	B-Method
on	I-Method
graphs	I-Method
.	O
	
A	O
spectral	B-Method
convolutional	I-Method
layer	I-Method
has	O
the	O
form	O
	
where	O
q	O
,	O
q	O
denote	O
the	O
number	O
of	O
input	O
and	O
output	O
channels	O
,	O
respectively	O
,	O
Ŷ	O
ll	O
=	O
	
diag	O
(	O
ŷ	O
ll	O
,	O
1	O
,	O
.	O
.	O
	
.	O
	
,	O
ŷ	O
ll	O
,	O
n	O
)	O
is	O
a	O
diagonal	B-Method
matrix	I-Method
of	I-Method
spectral	I-Method
multipliers	I-Method
representing	O
a	O
learnable	B-Method
filter	I-Method
in	O
the	O
spectral	O
domain	O
,	O
and	O
ξ	O
is	O
a	O
nonlinearity	O
(	O
e.g.	O
ReLU	B-Method
)	O
applied	O
on	O
the	O
vertex	O
-	O
wise	O
function	O
values	O
.	O
	
Unlike	O
classical	O
convolutions	B-Method
carried	O
out	O
efficiently	O
in	O
the	O
spectral	B-Method
domain	I-Method
using	O
FFT	B-Method
,	O
the	O
computations	O
of	O
the	O
forward	B-Method
and	I-Method
inverse	I-Method
graph	I-Method
	
Fourier	B-Method
transform	I-Method
incur	O
expensive	O
O	O
(	O
n	O
2	O
)	O
multiplication	O
by	O
the	O
matrices	O
Φ	O
,	O
Φ	O
,	O
as	O
there	O
are	O
no	O
FFTlike	B-Method
algorithms	I-Method
on	O
general	O
graphs	O
.	O
	
Furthermore	O
,	O
there	O
is	O
no	O
guarantee	O
that	O
the	O
filters	O
represented	O
in	O
the	O
spectral	O
domain	O
are	O
localized	O
in	O
the	O
spatial	O
domain	O
,	O
which	O
is	O
an	O
important	O
property	O
of	O
classical	B-Method
CNNs	I-Method
.	O
	
To	O
address	O
these	O
issues	O
,	O
[	O
reference	O
]	O
proposed	O
using	O
an	O
explicit	B-Method
expansion	I-Method
in	O
the	O
Chebyshev	B-Method
polynomial	I-Method
basis	I-Method
to	O
represent	O
the	O
spectral	B-Method
filters	I-Method
	
row	B-Method
+	I-Method
column	I-Method
filtering	I-Method
Figure	O
2	O
.	O
	
Recurrent	B-Method
GCNN	I-Method
(	O
RGCNN	B-Method
)	O
architecture	O
using	O
the	O
full	B-Method
matrix	I-Method
completion	I-Method
model	I-Method
and	O
operating	O
simultaneously	O
on	O
the	O
rows	O
and	O
columns	O
of	O
the	O
matrix	O
X.	O
	
The	O
output	O
of	O
the	O
Multi	B-Method
-	I-Method
Graph	I-Method
CNN	I-Method
(	O
MGCNN	B-Method
)	O
module	O
is	O
a	O
q	O
-	O
dimensional	O
feature	O
vector	O
for	O
each	O
element	O
of	O
the	O
input	O
matrix	O
.	O
	
The	O
number	O
of	O
parameters	O
to	O
learn	O
is	O
O	O
(	O
1	O
)	O
and	O
the	O
learning	B-Metric
complexity	I-Metric
is	O
O	O
(	O
mn	O
)	O
.	O
	
n	O
	
∆	O
	
−	O
I	O
is	O
the	O
rescaled	O
Laplacian	O
	
such	O
that	O
its	O
eigenvaluesΛ	O
=	O
	
2λ	O
	
θ	O
is	O
the	O
p	O
-	O
dimensional	O
vector	O
of	O
polynomial	O
coefficients	O
parametrizing	O
the	O
filter	B-Method
,	O
and	O
T	O
j	O
(	O
λ	O
)	O
=	O
	
2λT	O
j−1	O
(	O
λ	O
)	O
−T	O
j−2	O
(	O
λ	O
)	O
denotes	O
the	O
Chebyshev	O
polynomial	O
of	O
degree	O
j	O
defined	O
in	O
a	O
recursive	O
manner	O
with	O
T	O
1	O
(	O
λ	O
)	O
=	O
	
λ	O
and	O
T	O
0	O
	
(	O
λ	O
)	O
	
=	O
1	O
.	O
1	O
	
This	O
approach	O
benefits	O
from	O
several	O
advantages	O
.	O
	
First	O
,	O
it	O
does	O
not	O
require	O
an	O
explicit	O
computation	O
of	O
the	O
Laplacian	O
eigenvectors	O
,	O
and	O
due	O
to	O
the	O
recursive	B-Method
definition	I-Method
of	I-Method
the	I-Method
Chebyshev	I-Method
polynomials	I-Method
,	O
the	O
computation	O
of	O
the	O
filter	B-Method
incurs	O
applying	O
the	O
Laplacian	B-Method
p	I-Method
times	I-Method
.	O
	
Multiplication	B-Method
by	O
Laplacian	O
has	O
the	O
cost	O
of	O
O	O
(	O
|E|	O
)	O
,	O
and	O
assuming	O
the	O
graph	O
has	O
|E|	O
=	O
O	O
(	O
n	O
)	O
edges	O
(	O
which	O
is	O
the	O
case	O
for	O
k	B-Task
-	I-Task
nearest	I-Task
neighbors	I-Task
graphs	I-Task
and	O
most	O
real	B-Task
-	I-Task
world	I-Task
networks	I-Task
)	O
,	O
the	O
overall	O
complexity	B-Metric
is	O
O	O
(	O
n	O
)	O
rather	O
than	O
O	O
(	O
n	O
2	O
)	O
operations	O
,	O
which	O
is	O
the	O
same	O
complexity	O
than	O
standard	O
CNNs	B-Method
.	O
	
Moreover	O
,	O
since	O
the	O
Laplacian	O
is	O
a	O
local	O
operator	O
affecting	O
only	O
1	O
-	O
hop	O
neighbors	O
of	O
a	O
vertex	O
and	O
accordingly	O
its	O
(	O
p	O
−	O
1	O
)	O
st	O
power	O
affects	O
the	O
p	O
-	O
hop	O
neighborhood	O
,	O
the	O
resulting	O
filters	B-Method
are	O
spatially	O
localized	O
.	O
	
section	O
:	O
Our	O
approach	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
formulating	O
matrix	B-Method
completion	I-Method
as	O
a	O
learnable	B-Method
diffusion	I-Method
process	I-Method
applied	O
to	O
the	O
score	O
values	O
.	O
	
The	O
deep	B-Method
learning	I-Method
architecture	I-Method
considered	O
for	O
this	O
purpose	O
consists	O
of	O
a	O
spatial	B-Method
part	I-Method
extracting	O
spatial	O
features	O
from	O
the	O
matrix	O
(	O
we	O
consider	O
two	O
different	O
approaches	O
working	O
on	O
the	O
full	B-Method
and	I-Method
factorized	I-Method
matrix	I-Method
models	I-Method
)	O
,	O
and	O
a	O
temporal	B-Method
part	I-Method
using	O
a	O
recurrent	O
LSTM	B-Method
network	O
.	O
	
The	O
two	O
architectures	O
are	O
1	O
Tj	O
(	O
λ	O
)	O
=	O
	
cos	O
(	O
j	O
cos	O
−1	O
(	O
λ	O
)	O
)	O
is	O
an	O
oscillating	O
function	O
on	O
[	O
−1	O
,	O
1	O
]	O
with	O
j	O
roots	O
,	O
j	O
+	O
1	O
equally	O
spaced	O
extrema	O
,	O
and	O
a	O
frequency	O
linearly	O
dependent	O
on	O
j.	O
Chebyshev	B-Method
polynomials	I-Method
form	O
an	O
orthogonal	B-Method
basis	I-Method
for	O
the	O
space	O
of	O
smooth	O
functions	O
on	O
[	O
−1	O
,	O
1	O
]	O
and	O
are	O
thus	O
convenient	O
to	O
compactly	O
represent	O
spectral	B-Method
filters	I-Method
.	O
	
summarized	O
in	O
Figures	O
2	O
and	O
3	O
and	O
described	O
in	O
details	O
in	O
the	O
following	O
.	O
	
section	O
:	O
Multi	B-Method
-	I-Method
Graph	I-Method
CNNs	I-Method
	
Multi	B-Method
-	I-Method
graph	I-Method
convolution	I-Method
.	O
	
Our	O
first	O
goal	O
is	O
to	O
extend	O
the	O
notion	O
of	O
the	O
aforementioned	O
graph	B-Method
Fourier	I-Method
transform	I-Method
to	O
matrices	O
whose	O
rows	O
and	O
columns	O
are	O
defined	O
on	O
row	B-Method
-	I-Method
and	O
column	O
-	O
graphs	O
.	O
	
We	O
recall	O
that	O
a	O
classical	O
two	B-Method
-	I-Method
dimensional	I-Method
Fourier	I-Method
transform	I-Method
of	I-Method
an	I-Method
image	I-Method
(	I-Method
matrix	I-Method
)	O
can	O
be	O
thought	O
of	O
as	O
applying	O
a	O
one	B-Method
-	I-Method
dimensional	I-Method
Fourier	I-Method
transform	I-Method
to	O
its	O
rows	O
and	O
columns	O
.	O
	
In	O
our	O
setting	O
,	O
the	O
analogy	O
of	O
the	O
twodimensional	B-Method
Fourier	I-Method
transform	I-Method
has	O
the	O
form	O
	
where	O
Φ	O
c	O
,	O
Φ	O
r	O
and	O
Λ	O
c	O
,	O
Λ	O
r	O
denote	O
the	O
n	O
×	O
n	O
	
and	O
m	O
×	O
m	O
eigenvector	O
-	O
and	O
eigenvalue	O
matrices	O
of	O
the	O
column	O
-	O
and	O
row	B-Method
-	I-Method
graph	O
	
Laplacians	O
∆	O
c	O
,	O
	
∆	O
r	O
,	O
respectively	O
.	O
	
The	O
multigraph	B-Method
version	I-Method
of	O
the	O
spectral	B-Method
convolution	I-Method
(	O
7	O
)	O
is	O
given	O
by	O
	
Representing	O
the	O
filters	O
as	O
their	O
spectral	B-Method
multipliersŶ	I-Method
would	O
yield	O
O	O
(	O
mn	O
)	O
	
parameters	O
,	O
prohibitive	O
in	O
any	O
practical	O
application	O
.	O
	
To	O
overcome	O
this	O
limitation	O
,	O
we	O
resort	O
to	O
the	O
representation	O
of	O
the	O
filters	O
in	O
Chebychev	O
polynomial	O
bases	O
of	O
degree	O
p	O
,	O
	
where	O
Θ	O
=	O
	
(	O
θ	O
jj	O
)	O
is	O
the	O
(	O
p	O
+	O
1	O
)	O
×	O
(	O
p	O
+	O
1	O
)	O
matrix	O
of	O
coefficients	O
,	O
i.e.	O
,	O
O	O
(	O
1	O
)	O
parameters	O
.	O
	
The	O
application	O
of	O
such	O
filters	O
to	O
the	O
matrix	O
	
X	O
A	O
	
Multi	B-Method
-	I-Method
Graph	I-Method
CNN	I-Method
(	O
MGCNN	B-Method
)	O
	
using	O
this	O
parametrization	O
of	O
filters	O
(	O
13	O
)	O
in	O
the	O
convolutional	B-Method
layer	I-Method
is	O
applied	O
to	O
the	O
m×n	O
matrix	O
X	O
(	O
single	O
input	O
channel	O
)	O
,	O
producing	O
q	O
outputs	O
(	O
i.e.	O
,	O
a	O
tensor	O
of	O
size	O
m	O
×	O
n	O
×	O
q	O
)	O
.	O
	
Separable	B-Method
convolution	I-Method
.	O
	
A	O
simplification	O
of	O
the	O
multigraph	B-Task
convolution	I-Task
is	O
obtained	O
considering	O
the	O
factorized	O
form	O
of	O
the	O
matrix	O
X	O
=	O
WH	O
and	O
applying	O
onedimensional	B-Method
convolution	I-Method
on	O
the	O
respective	O
graph	O
to	O
each	O
factor	O
,	O
w	O
	
with	O
2	O
(	O
p	O
+	O
1	O
)	O
qq	O
parameters	O
in	O
total	O
.	O
	
section	O
:	O
Matrix	B-Task
diffusion	I-Task
with	O
RNN	B-Method
	
The	O
next	O
step	O
of	O
our	O
approach	O
is	O
to	O
feed	O
the	O
features	O
extracted	O
from	O
the	O
matrix	O
by	O
the	O
MGCNN	B-Method
(	O
or	O
alternatively	O
,	O
the	O
row	B-Method
-	I-Method
and	O
column	O
-	O
GCNNs	B-Method
)	O
to	O
a	O
Recurrent	B-Method
Neural	I-Method
Network	I-Method
(	O
RNN	B-Method
)	O
implementing	O
the	O
score	B-Method
diffusion	I-Method
process	I-Method
.	O
	
We	O
use	O
the	O
classical	O
Long	B-Method
-	I-Method
Short	I-Method
Term	I-Method
Memory	I-Method
(	O
LSTM	B-Method
)	O
RNN	B-Method
architecture	O
[	O
reference	O
]	O
,	O
which	O
has	O
demonstrated	O
to	O
be	O
highly	O
efficient	O
to	O
learn	O
the	O
dynamical	O
property	O
of	O
data	O
sequences	O
as	O
LSTM	B-Method
is	O
able	O
to	O
keep	O
long	O
-	O
term	O
internal	O
states	O
(	O
in	O
particular	O
,	O
avoiding	O
the	O
vanishing	B-Task
gradient	I-Task
issue	I-Task
)	O
.	O
	
The	O
input	O
of	O
the	O
LSTM	B-Method
gate	O
is	O
given	O
by	O
the	O
static	O
features	O
extracted	O
from	O
the	O
MGCNN	B-Method
,	O
which	O
can	O
be	O
seen	O
as	O
a	O
projection	B-Method
or	I-Method
dimensionality	I-Method
reduction	I-Method
of	O
the	O
original	O
matrix	O
in	O
the	O
space	O
of	O
the	O
most	O
meaningful	O
and	O
representative	O
information	O
(	O
the	O
disentanglement	O
effect	O
)	O
.	O
	
This	O
representation	O
coupled	O
with	O
LSTM	B-Method
appears	O
particularly	O
well	O
-	O
suited	O
to	O
keep	O
a	O
long	O
term	O
internal	O
state	O
,	O
which	O
allows	O
to	O
predict	O
accurate	O
small	O
changes	O
dX	O
of	O
the	O
matrix	O
X	O
(	O
or	O
dW	O
,	O
dH	O
of	O
the	O
factors	O
W	O
,	O
H	O
)	O
that	O
can	O
propagate	O
through	O
the	O
full	O
temporal	O
steps	O
.	O
	
Figures	O
2	O
and	O
3	O
provides	O
an	O
illustration	O
of	O
the	O
proposed	O
matrix	B-Method
completion	I-Method
model	I-Method
.	O
	
We	O
also	O
give	O
a	O
precise	O
description	O
of	O
the	O
two	O
settings	O
of	O
our	O
model	O
in	O
Algorithms	O
1	O
and	O
2	O
.	O
	
We	O
refer	O
to	O
the	O
whole	O
architecture	O
combining	O
the	O
MGCNN	B-Method
and	O
RNN	B-Method
in	O
the	O
full	B-Task
matrix	I-Task
completion	I-Task
setting	I-Task
as	O
Recurrent	B-Method
Graph	I-Method
CNN	I-Method
(	O
RGCNN	B-Method
)	O
.	O
	
The	O
factorized	B-Method
version	I-Method
with	O
two	O
GCNNs	B-Method
and	O
RNN	B-Method
is	O
referred	O
to	O
as	O
separable	B-Method
Recurrent	I-Method
Graph	I-Method
CNN	I-Method
(	O
sRGCNN	B-Method
)	O
.	O
	
The	O
complexity	B-Metric
of	O
Algorithm	O
1	O
scales	O
quadratically	O
as	O
O	O
(	O
mn	O
)	O
	
due	O
to	O
the	O
use	O
of	O
MGCNN	B-Method
.	O
	
For	O
large	O
matrices	O
,	O
we	O
can	O
opt	O
for	O
Algorithm	O
2	O
that	O
processes	O
the	O
rows	O
and	O
columns	O
separately	O
with	O
standard	O
GCNNs	B-Method
and	O
scales	O
linearly	O
as	O
O	O
(	O
m	O
+	O
n	O
)	O
.	O
	
section	O
:	O
Algorithm	O
1	O
Full	B-Method
matrix	I-Method
completion	I-Method
model	I-Method
using	O
RGCNN	B-Method
	
input	O
m	O
×	O
n	O
matrix	O
X	O
(	O
0	O
)	O
containing	O
initial	O
values	O
1	O
:	O
for	O
t	O
	
=	O
0	O
:	O
T	O
do	O
2	O
:	O
	
Apply	O
the	O
Multi	B-Method
-	I-Method
Graph	I-Method
CNN	I-Method
(	O
13	O
)	O
on	O
X	O
(	O
t	O
)	O
producing	O
an	O
m×n×q	O
outputX	O
(	O
t	O
)	O
containing	O
a	O
q	O
-	O
dimensional	O
feature	O
vector	O
for	O
each	O
matrix	O
element	O
.	O
	
section	O
:	O
3	O
:	O
	
for	O
all	O
elements	O
(	O
i	O
,	O
j	O
)	O
	
do	O
	
section	O
:	O
4	O
:	O
	
Apply	O
RNN	B-Method
to	O
feature	B-Task
vectorx	I-Task
	
ijq	O
)	O
producing	O
the	O
predicted	O
incremental	O
value	O
dx	O
(	O
t	O
)	O
ij	O
5	O
:	O
	
7	O
:	O
end	O
for	O
Algorithm	O
2	O
Factorized	B-Method
matrix	I-Method
completion	I-Method
model	I-Method
using	O
sRGCNN	B-Method
input	O
m×r	O
factor	O
H	O
(	O
0	O
)	O
and	O
n×r	O
factor	O
W	O
(	O
0	O
)	O
representing	O
the	O
matrix	O
	
X	O
Apply	O
the	O
Graph	B-Method
CNN	I-Method
on	O
H	O
(	O
t	O
)	O
producing	O
an	O
n	O
×	O
q	O
	
outputH	O
(	O
t	O
)	O
.	O
	
3	O
:	O
	
Apply	O
RNN	B-Method
to	O
feature	B-Task
vectorh	I-Task
	
jq	O
)	O
producing	O
the	O
predicted	O
incremental	O
value	O
dh	O
Update	O
	
Apply	O
the	O
Graph	B-Method
CNN	I-Method
on	O
W	O
(	O
t	O
)	O
producing	O
an	O
m	O
×	O
q	O
outputW	O
(	O
t	O
)	O
.	O
	
8	O
:	O
	
Apply	O
RNN	B-Method
to	O
feature	B-Task
vectorw	I-Task
	
iq	O
)	O
producing	O
the	O
predicted	O
incremental	O
value	O
dw	O
	
12	O
:	O
end	O
for	O
	
section	O
:	O
Training	O
	
Training	O
of	O
the	O
networks	O
is	O
performed	O
by	O
minimizing	O
the	O
loss	B-Metric
	
Here	O
,	O
T	O
denotes	O
the	O
number	O
of	O
diffusion	O
iterations	O
(	O
applications	O
of	O
the	O
RNN	B-Method
)	O
,	O
and	O
we	O
use	O
the	O
notation	O
X	O
(	O
T	O
)	O
Θ	O
,	O
σ	O
to	O
emphasize	O
that	O
the	O
matrix	O
depends	O
on	O
the	O
parameters	O
of	O
the	O
MGCNN	B-Method
(	O
Chebyshev	O
polynomial	O
coefficients	O
Θ	O
)	O
and	O
those	O
of	O
the	O
LSTM	B-Method
(	O
denoted	O
by	O
σ	B-Method
)	O
.	O
	
In	O
the	O
factorized	B-Task
setting	I-Task
,	O
we	O
use	O
the	O
loss	O
	
where	O
θ	O
c	O
,	O
θ	O
r	O
are	O
the	O
parameters	O
of	O
the	O
two	O
GCNNs	B-Method
.	O
	
section	O
:	O
Results	O
	
Experimental	O
settings	O
.	O
	
We	O
closely	O
followed	O
the	O
experimental	O
setup	O
of	O
[	O
reference	O
]	O
,	O
using	O
five	O
standard	O
datasets	O
:	O
Synthetic	O
dataset	O
from	O
[	O
reference	O
]	O
,	O
MovieLens	B-Material
[	O
reference	O
]	O
,	O
Flixster	B-Material
[	O
reference	O
]	O
,	O
Douban	B-Material
[	O
reference	O
]	O
,	O
and	O
YahooMusic	B-Material
[	O
reference	O
]	O
.	O
Classical	O
Matrix	B-Method
Completion	I-Method
(	O
MC	B-Method
)	O
	
[	O
reference	O
]	O
,	O
Inductive	B-Method
Matrix	I-Method
Completion	I-Method
(	O
IMC	B-Method
)	O
	
[	O
reference	O
][	O
reference	O
]	O
,	O
Geometric	B-Method
Matrix	I-Method
Completion	I-Method
(	O
GMC	B-Method
)	I-Method
[	O
reference	O
]	O
,	O
and	O
Graph	B-Method
Regularized	I-Method
Alternating	I-Method
Least	I-Method
Squares	I-Method
(	O
GRALS	B-Method
)	O
	
[	O
reference	O
]	O
were	O
used	O
as	O
baseline	O
methods	O
.	O
	
In	O
all	O
the	O
experiments	O
,	O
we	O
used	O
the	O
following	O
settings	O
for	O
our	O
RGCNNs	B-Method
:	O
Chebyshev	B-Method
polynomials	I-Method
of	O
order	O
p	O
=	O
5	O
,	O
outputting	O
k	O
=	O
32	O
-	O
dimensional	O
features	O
,	O
LSTM	B-Method
cells	O
with	O
32	O
features	O
and	O
T	O
=	O
10	O
diffusion	O
steps	O
.	O
	
All	O
the	O
models	O
were	O
implemented	O
in	O
Google	B-Method
TensorFlow	I-Method
and	O
trained	O
using	O
the	O
Adam	B-Method
stochastic	I-Method
optimization	I-Method
algorithm	I-Method
[	O
reference	O
]	O
with	O
learning	B-Metric
rate	I-Metric
10	O
−3	O
.	O
	
In	O
factorized	B-Method
models	I-Method
,	O
rank	O
r	O
=	O
15	O
and	O
10	O
was	O
used	O
for	O
the	O
synthetic	O
and	O
real	O
datasets	O
,	O
respectively	O
.	O
	
For	O
all	O
methods	O
,	O
hyperparameters	O
were	O
chosen	O
by	O
cross	B-Method
-	I-Method
validation	I-Method
.	O
	
section	O
:	O
Synthetic	O
data	O
	
We	O
start	O
our	O
experimental	O
evaluation	O
showing	O
the	O
performance	O
of	O
our	O
approach	O
on	O
a	O
small	O
synthetic	O
dataset	O
,	O
in	O
which	O
the	O
user	O
and	O
item	O
graphs	O
have	O
strong	O
communities	O
structure	O
.	O
	
Though	O
rather	O
simple	O
,	O
such	O
a	O
dataset	O
allows	O
to	O
study	O
the	O
behavior	O
of	O
different	O
algorithms	O
in	O
controlled	O
settings	O
.	O
	
The	O
performance	O
of	O
different	O
matrix	B-Method
completion	I-Method
methods	I-Method
is	O
reported	O
in	O
Table	O
1	O
,	O
along	O
with	O
their	O
theoretical	B-Metric
complexity	I-Metric
.	O
	
Our	O
RGCNN	B-Method
model	I-Method
achieves	O
the	O
best	O
accuracy	B-Metric
,	O
followed	O
by	O
the	O
separable	B-Method
RGCNN	I-Method
.	O
	
Different	O
diffusion	O
time	O
steps	O
of	O
these	O
two	O
models	O
are	O
visualized	O
in	O
Figure	O
4	O
.	O
	
Figure	O
5	O
shows	O
the	O
convergence	B-Metric
rates	I-Metric
of	O
different	O
methods	O
.	O
	
Figures	O
6	O
and	O
7	O
depict	O
the	O
spectral	B-Method
filters	I-Method
learnt	O
by	O
the	O
MGCNN	B-Method
and	O
row	B-Method
-	I-Method
and	O
column	B-Method
-	I-Method
GCNNs	I-Method
.	O
	
We	O
repeated	O
the	O
same	O
experiment	O
considering	O
only	O
the	O
column	O
(	O
users	O
)	O
graph	O
to	O
be	O
given	O
.	O
	
In	O
this	O
setting	O
,	O
the	O
RGCNN	B-Method
can	O
not	O
be	O
applied	O
,	O
while	O
the	O
sRGCNN	B-Method
has	O
only	O
one	O
GCNN	O
applied	O
on	O
the	O
factor	O
H	O
,	O
and	O
the	O
other	O
factor	O
W	O
is	O
free	O
.	O
	
Figure	O
4	O
.	O
	
Evolution	O
of	O
the	O
matrix	O
X	O
(	O
t	O
)	O
with	O
our	O
architecture	O
using	O
full	O
matrix	O
completion	O
model	O
RGCNN	B-Method
(	O
top	O
)	O
and	O
factorized	B-Method
matrix	I-Method
completion	I-Method
model	I-Method
sRGCNN	I-Method
(	O
bottom	O
)	O
.	O
	
Numbers	O
indicate	O
the	O
RMS	B-Metric
error	I-Metric
.	O
	
Figure	O
5	O
.	O
	
Convergence	B-Metric
rates	I-Metric
of	O
the	O
tested	O
algorithms	O
over	O
the	O
Synthetic	B-Material
Netflix	I-Material
dataset	I-Material
.	O
	
section	O
:	O
Real	O
data	O
	
Following	O
[	O
reference	O
]	O
,	O
we	O
evaluated	O
the	O
proposed	O
approach	O
on	O
the	O
MovieLens	B-Material
,	O
Flixster	B-Material
,	O
Douban	B-Material
and	O
YahooMusic	B-Material
datasets	I-Material
.	O
	
For	O
the	O
MovieLens	B-Material
dataset	O
we	O
constructed	O
the	O
user	O
and	O
item	O
(	O
movie	O
)	O
graphs	O
as	O
unweighted	O
10	O
-	O
nearest	O
neighbor	O
graphs	O
in	O
the	O
space	O
of	O
user	O
and	O
movie	O
features	O
,	O
respectively	O
.	O
	
For	O
Flixster	B-Material
,	O
the	O
user	O
and	O
item	O
graphs	O
were	O
constructed	O
from	O
the	O
scores	O
of	O
the	O
original	O
matrix	O
.	O
	
On	O
this	O
dataset	O
,	O
we	O
also	O
performed	O
an	O
experiment	O
using	O
only	O
the	O
users	O
graph	O
.	O
	
For	O
the	O
Douban	B-Material
dataset	O
,	O
we	O
used	O
only	O
the	O
user	O
graph	O
(	O
the	O
provided	O
social	O
network	O
of	O
the	O
user	O
)	O
.	O
	
For	O
the	O
YahooMusic	B-Material
dataset	O
,	O
we	O
used	O
only	O
the	O
item	O
graph	O
,	O
constructed	O
with	O
unweighted	O
10	O
-	O
nearest	O
neighbors	O
in	O
the	O
space	O
of	O
item	O
features	O
(	O
artists	O
,	O
albums	O
,	O
and	O
genres	O
)	O
.	O
	
For	O
the	O
latter	O
three	O
datasets	O
,	O
we	O
used	O
a	O
sub	O
-	O
matrix	O
of	O
3000	O
×	O
3000	O
entries	O
for	O
evaluating	O
the	O
performance	O
.	O
	
Tables	O
3	O
and	O
4	O
summarize	O
the	O
performance	O
of	O
different	O
methods	O
.	O
	
RGCNN	B-Method
outperforms	O
the	O
competitors	O
in	O
all	O
the	O
experiments	O
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
paper	O
,	O
we	O
presented	O
a	O
new	O
deep	B-Method
learning	I-Method
approach	I-Method
for	O
matrix	B-Task
completion	I-Task
based	O
on	O
a	O
specially	O
designed	O
multigraph	B-Method
convolutional	I-Method
neural	I-Method
network	I-Method
architecture	I-Method
.	O
	
Among	O
the	O
key	O
advantages	O
of	O
our	O
approach	O
compared	O
to	O
traditional	O
methods	O
is	O
its	O
low	O
computational	B-Metric
complexity	I-Metric
and	O
constant	O
number	O
of	O
degrees	O
of	O
freedom	O
independent	O
of	O
the	O
matrix	O
size	O
.	O
	
We	O
showed	O
that	O
the	O
use	O
of	O
deep	B-Method
learning	I-Method
for	O
matrix	B-Task
completion	I-Task
allows	O
to	O
beat	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
recommender	B-Method
system	I-Method
methods	I-Method
.	O
	
To	O
our	O
knowledge	O
,	O
our	O
work	O
is	O
the	O
first	O
application	O
of	O
deep	B-Task
learning	I-Task
on	I-Task
graphs	I-Task
to	O
this	O
class	O
of	O
problems	O
.	O
	
We	O
believe	O
that	O
it	O
shows	O
the	O
potential	O
of	O
the	O
nascent	O
field	O
of	O
geometric	B-Task
deep	I-Task
learning	I-Task
on	O
non	B-Task
-	I-Task
Euclidean	I-Task
domains	I-Task
,	O
and	O
will	O
encourage	O
future	O
works	O
in	O
this	O
direction	O
.	O
	
section	O
:	O
	
section	O
:	O
Acknowledgments	O
	
section	O
:	O
	
Numerous	O
important	O
problems	O
can	O
be	O
framed	O
as	O
learning	B-Task
from	O
graph	B-Material
data	I-Material
.	O
	
We	O
propose	O
a	O
framework	O
for	O
learning	O
convolutional	B-Method
neural	I-Method
networks	I-Method
for	O
arbitrary	B-Material
graphs	I-Material
.	O
	
These	O
graphs	O
may	O
be	O
undirected	O
,	O
directed	O
,	O
and	O
with	O
both	O
discrete	O
and	O
continuous	O
node	O
and	O
edge	O
attributes	O
.	O
	
Analogous	O
to	O
image	B-Method
-	I-Method
based	I-Method
convolutional	I-Method
networks	I-Method
that	O
operate	O
on	O
locally	O
connected	O
regions	O
of	O
the	O
input	O
,	O
we	O
present	O
a	O
general	O
approach	O
to	O
extracting	B-Task
locally	I-Task
connected	I-Task
regions	I-Task
from	O
graphs	O
.	O
	
Using	O
established	O
benchmark	B-Material
data	I-Material
sets	I-Material
,	O
we	O
demonstrate	O
that	O
the	O
learned	O
feature	B-Method
representations	I-Method
are	O
competitive	O
with	O
state	O
of	O
the	O
art	O
graph	B-Method
kernels	I-Method
and	O
that	O
their	O
computation	O
is	O
highly	O
efficient	O
.	O
	
LearningConvolutionalNeuralNetworksforGraphs	B-Task
	
section	O
:	O
Introduction	O
	
With	O
this	O
paper	O
we	O
aim	O
to	O
bring	O
convolutional	B-Method
neural	I-Method
networks	I-Method
to	O
bear	O
on	O
a	O
large	O
class	O
of	O
graph	B-Task
-	I-Task
based	I-Task
learning	I-Task
problems	I-Task
.	O
	
We	O
consider	O
the	O
following	O
two	O
problems	O
.	O
	
Given	O
a	O
collection	O
of	O
graphs	B-Material
,	O
learn	O
a	O
function	O
that	O
can	O
be	O
used	O
for	O
classification	B-Task
and	I-Task
regression	I-Task
problems	I-Task
on	O
unseen	B-Material
graphs	I-Material
.	O
	
The	O
nodes	O
of	O
any	O
two	O
graphs	O
are	O
not	O
necessarily	O
in	O
correspondence	O
.	O
	
For	O
instance	O
,	O
each	O
graph	O
of	O
the	O
collection	O
could	O
model	O
a	O
chemical	O
compound	O
and	O
the	O
output	O
could	O
be	O
a	O
function	O
mapping	O
unseen	O
compounds	O
to	O
their	O
level	O
of	O
activity	O
against	O
cancer	O
cells	O
.	O
	
Given	O
a	O
large	O
graph	O
,	O
learn	O
graph	B-Method
representations	I-Method
that	O
can	O
be	O
used	O
to	O
infer	O
unseen	O
graph	O
properties	O
such	O
as	O
node	O
types	O
and	O
missing	O
edges	O
.	O
	
We	O
propose	O
a	O
framework	O
for	O
learning	B-Task
representations	I-Task
for	O
classes	B-Task
of	I-Task
directed	I-Task
and	I-Task
undirected	I-Task
graphs	I-Task
.	O
	
The	O
graphs	O
may	O
have	O
nodes	O
and	O
edges	O
with	O
multiple	O
discrete	O
and	O
continuous	O
attributes	O
and	O
may	O
have	O
multiple	O
types	O
of	O
edges	O
.	O
	
Similar	O
to	O
convolutional	B-Method
neural	I-Method
network	I-Method
for	O
images	B-Material
,	O
we	O
construct	O
locally	O
connected	O
neighborhoods	O
from	O
the	O
input	O
graphs	O
.	O
	
These	O
neighborhoods	O
are	O
generated	O
efficiently	O
and	O
serve	O
as	O
the	O
receptive	O
fields	O
of	O
a	O
convolutional	B-Method
architecture	I-Method
,	O
allowing	O
the	O
framework	O
to	O
learn	O
effective	O
graph	B-Method
representations	I-Method
.	O
	
The	O
proposed	O
approach	O
builds	O
on	O
concepts	O
from	O
convolutional	B-Method
neural	I-Method
networks	I-Method
(	O
CNNs	B-Method
)	O
for	O
images	B-Material
and	O
extends	O
them	O
to	O
arbitrary	O
graphs	O
.	O
	
Figure	O
[	O
reference	O
]	O
illustrates	O
the	O
locally	O
connected	O
receptive	O
fields	O
of	O
a	O
CNN	B-Method
for	O
images	B-Material
.	O
	
An	O
image	B-Material
can	O
be	O
represented	O
as	O
a	O
square	B-Method
grid	I-Method
graph	I-Method
whose	O
nodes	O
represent	O
pixels	O
.	O
	
Now	O
,	O
a	O
CNN	B-Method
can	O
be	O
seen	O
as	O
traversing	O
a	O
node	O
sequence	O
(	O
nodes	O
-	O
in	O
Figure	O
[	O
reference	O
]	O
(	O
a	O
)	O
)	O
and	O
generating	O
fixed	O
-	O
size	O
neighborhood	O
graphs	O
(	O
the	O
x	O
grids	O
in	O
Figure	O
[	O
reference	O
]	O
(	O
b	O
)	O
)	O
for	O
each	O
of	O
the	O
nodes	O
.	O
	
The	O
neighborhood	O
graphs	O
serve	O
as	O
the	O
receptive	O
fields	O
to	O
read	O
feature	O
values	O
from	O
the	O
pixel	O
nodes	O
.	O
	
Due	O
to	O
the	O
implicit	O
spatial	O
order	O
of	O
the	O
pixels	O
,	O
the	O
sequence	O
of	O
nodes	O
for	O
which	O
neighborhood	O
graphs	O
are	O
created	O
,	O
from	O
left	O
to	O
right	O
and	O
top	O
to	O
bottom	O
,	O
is	O
uniquely	O
determined	O
.	O
	
The	O
same	O
holds	O
for	O
NLP	B-Task
problems	I-Task
where	O
each	O
sentence	O
(	O
and	O
its	O
parse	O
-	O
tree	O
)	O
determines	O
a	O
sequence	O
of	O
words	O
.	O
	
However	O
,	O
for	O
numerous	O
graph	B-Task
collections	I-Task
a	O
problem	O
-	O
specific	O
ordering	O
(	O
spatial	O
,	O
temporal	O
,	O
or	O
otherwise	O
)	O
is	O
missing	O
and	O
the	O
nodes	O
of	O
the	O
graphs	O
are	O
not	O
in	O
correspondence	O
.	O
	
In	O
these	O
instances	O
,	O
one	O
has	O
to	O
solve	O
two	O
problems	O
:	O
(	O
i	O
)	O
	
Determining	O
the	O
node	O
sequences	O
for	O
which	O
neighborhood	O
graphs	O
are	O
created	O
and	O
(	O
ii	O
)	O
computing	O
a	O
normalization	B-Method
of	I-Method
neighborhood	I-Method
graphs	I-Method
,	O
that	O
is	O
,	O
a	O
unique	O
mapping	O
from	O
a	O
graph	B-Method
representation	I-Method
into	O
a	O
vector	B-Method
space	I-Method
representation	I-Method
.	O
	
The	O
proposed	O
approach	O
,	O
termed	O
Patchy	B-Method
-	I-Method
san	I-Method
,	O
addresses	O
these	O
two	O
problems	O
for	O
arbitrary	B-Task
graphs	I-Task
.	O
	
For	O
each	O
input	O
graph	O
,	O
it	O
first	O
determines	O
nodes	O
(	O
and	O
their	O
order	O
)	O
for	O
which	O
neighborhood	O
graphs	O
are	O
created	O
.	O
	
For	O
each	O
of	O
these	O
nodes	O
,	O
a	O
neighborhood	O
consisting	O
of	O
exactly	O
nodes	O
is	O
extracted	O
and	O
normalized	O
,	O
that	O
is	O
,	O
it	O
is	O
uniquely	O
mapped	O
to	O
a	O
space	O
with	O
a	O
fixed	O
linear	O
order	O
.	O
	
The	O
normalized	O
neighborhood	O
serves	O
as	O
the	O
receptive	O
field	O
for	O
a	O
node	O
under	O
consideration	O
.	O
	
Finally	O
,	O
feature	B-Method
learning	I-Method
components	I-Method
such	O
as	O
convolutional	B-Method
and	I-Method
dense	I-Method
layers	I-Method
are	O
combined	O
with	O
the	O
normalized	O
neighborhood	O
graphs	O
as	O
the	O
CNN	B-Method
’s	I-Method
receptive	I-Method
fields	I-Method
.	O
	
Figure	O
[	O
reference	O
]	O
illustrates	O
the	O
Patchy	B-Method
-	I-Method
san	I-Method
architecture	I-Method
which	O
has	O
several	O
advantages	O
over	O
existing	O
approaches	O
:	O
First	O
,	O
it	O
is	O
highly	O
efficient	O
,	O
naively	O
parallelizable	O
,	O
and	O
applicable	O
to	O
large	B-Task
graphs	I-Task
.	O
	
Second	O
,	O
for	O
a	O
number	O
of	O
applications	O
,	O
ranging	O
from	O
computational	B-Task
biology	I-Task
to	O
social	B-Task
network	I-Task
analysis	I-Task
,	O
it	O
is	O
important	O
to	O
visualize	O
learned	O
network	O
motifs	O
.	O
	
Patchy	B-Method
-	I-Method
san	I-Method
supports	O
feature	B-Task
visualizations	I-Task
providing	O
insights	O
into	O
the	O
structural	O
properties	O
of	O
graphs	O
.	O
	
Third	O
,	O
instead	O
of	O
crafting	O
yet	O
another	O
graph	B-Method
kernel	I-Method
,	O
Patchy	B-Method
-	I-Method
san	I-Method
learns	O
application	O
dependent	O
features	O
without	O
the	O
need	O
to	O
feature	B-Method
engineering	I-Method
.	O
	
Our	O
theoretical	O
contributions	O
are	O
the	O
definition	O
of	O
the	O
normalization	B-Task
problem	I-Task
on	I-Task
graphs	I-Task
and	O
its	O
complexity	B-Metric
;	O
a	O
method	O
for	O
comparing	O
graph	B-Method
labeling	I-Method
approaches	I-Method
for	O
a	O
collection	O
of	O
graphs	O
;	O
and	O
a	O
result	O
that	O
shows	O
that	O
Patchy	B-Method
-	I-Method
san	I-Method
generalizes	O
CNNs	B-Method
on	O
images	B-Material
.	O
	
Using	O
standard	O
benchmark	B-Material
data	I-Material
sets	I-Material
,	O
we	O
demonstrate	O
that	O
the	O
learned	O
CNNs	B-Method
for	O
graphs	B-Task
are	O
both	O
efficient	O
and	O
effective	O
compared	O
to	O
state	O
of	O
the	O
art	O
graph	B-Method
kernels	I-Method
.	O
	
section	O
:	O
Related	O
Work	O
	
Graph	B-Method
kernels	I-Method
allow	O
kernel	B-Method
-	I-Method
based	I-Method
learning	I-Method
approaches	I-Method
such	O
as	O
SVMs	B-Method
to	O
work	O
directly	O
on	O
graphs	O
.	O
	
Kernels	B-Method
on	O
graphs	O
were	O
originally	O
defined	O
as	O
similarity	O
functions	O
on	O
the	O
nodes	O
of	O
a	O
single	O
graph	O
.	O
	
Two	O
representative	O
classes	O
of	O
kernels	O
are	O
the	O
skew	B-Method
spectrum	I-Method
kernel	I-Method
and	O
kernels	B-Method
based	O
on	O
graphlets	B-Method
.	O
	
The	O
latter	O
is	O
related	O
to	O
our	O
work	O
,	O
as	O
it	O
builds	O
kernels	B-Method
based	O
on	O
fixed	O
-	O
sized	O
subgraphs	O
.	O
	
These	O
subgraphs	O
,	O
which	O
are	O
often	O
called	O
motifs	O
or	O
graphlets	O
,	O
reflect	O
functional	O
network	O
properties	O
.	O
	
However	O
,	O
due	O
to	O
the	O
combinatorial	B-Metric
complexity	I-Metric
of	O
subgraph	B-Task
enumeration	I-Task
,	O
graphlet	B-Method
kernels	I-Method
are	O
restricted	O
to	O
subgraphs	O
with	O
few	O
nodes	O
.	O
	
An	O
effective	O
class	O
of	O
graph	B-Method
kernels	I-Method
are	O
the	O
Weisfeiler	B-Method
-	I-Method
Lehman	I-Method
(	I-Method
WL	I-Method
)	I-Method
kernels	I-Method
.	O
	
WL	B-Method
kernels	I-Method
,	O
however	O
,	O
only	O
support	O
discrete	O
features	O
and	O
use	O
memory	O
linear	O
in	O
the	O
number	O
of	O
training	O
examples	O
at	O
test	O
time	O
.	O
	
Patchy	B-Method
-	I-Method
san	I-Method
uses	O
WL	B-Method
as	O
one	O
possible	O
labeling	B-Method
procedure	I-Method
to	O
compute	O
receptive	O
fields	O
.	O
	
Deep	B-Method
graph	I-Method
kernels	I-Method
and	O
graph	B-Method
invariant	I-Method
kernels	I-Method
compare	O
graphs	B-Method
based	O
on	O
the	O
existence	O
or	O
count	O
of	O
small	O
substructures	O
such	O
as	O
shortest	O
paths	O
,	O
graphlets	O
,	O
subtrees	O
,	O
and	O
other	O
graph	O
invariants	O
.	O
	
In	O
contrast	O
,	O
Patchy	B-Method
-	I-Method
san	I-Method
learns	O
substructures	B-Method
from	O
graph	B-Material
data	I-Material
and	O
is	O
not	O
limited	O
to	O
a	O
predefined	O
set	O
of	O
motifs	O
.	O
	
Moreover	O
,	O
while	O
all	O
graph	B-Method
kernels	I-Method
have	O
a	O
training	B-Metric
complexity	I-Metric
at	O
least	O
quadratic	O
in	O
the	O
number	O
of	O
graphs	O
,	O
which	O
is	O
prohibitive	O
for	O
large	B-Task
-	I-Task
scale	I-Task
problems	I-Task
,	O
Patchy	B-Method
-	I-Method
san	I-Method
scales	O
linearly	O
with	O
the	O
number	O
of	O
graphs	O
.	O
	
Graph	B-Method
neural	I-Method
networks	I-Method
(	O
GNNs	B-Method
)	O
are	O
a	O
recurrent	B-Method
neural	I-Method
network	I-Method
architecture	I-Method
defined	O
on	O
graphs	B-Material
.	O
	
GNNs	B-Method
apply	O
recurrent	B-Method
neural	I-Method
networks	I-Method
for	O
walks	O
on	O
the	O
graph	O
structure	O
,	O
propagating	O
node	B-Method
representations	I-Method
until	O
a	O
fixed	O
point	O
is	O
reached	O
.	O
	
The	O
resulting	O
node	B-Method
representations	I-Method
are	O
then	O
used	O
as	O
features	O
in	O
classification	B-Task
and	I-Task
regression	I-Task
problems	I-Task
.	O
	
GNNs	B-Method
support	O
only	O
discrete	O
labels	O
and	O
perform	O
as	O
many	O
backpropagation	B-Method
operations	I-Method
as	O
there	O
are	O
edges	O
and	O
nodes	O
in	O
the	O
graph	O
per	O
learning	O
iteration	O
.	O
	
Gated	B-Method
Graph	I-Method
Sequence	I-Method
Neural	I-Method
Networks	I-Method
modify	O
GNNs	B-Method
to	O
use	O
gated	B-Method
recurrent	I-Method
units	I-Method
and	O
to	O
output	O
sequences	O
.	O
	
Recent	O
work	O
extended	O
CNNs	B-Method
to	O
topologies	O
that	O
differ	O
from	O
the	O
low	O
-	O
dimensional	O
grid	O
structure	O
.	O
	
All	O
of	O
these	O
methods	O
,	O
however	O
,	O
assume	O
one	O
global	O
graph	O
structure	O
,	O
that	O
is	O
,	O
a	O
correspondence	O
of	O
the	O
vertices	O
across	O
input	O
examples	O
.	O
	
perform	O
convolutional	B-Method
type	I-Method
operations	I-Method
on	O
graphs	O
,	O
developing	O
a	O
differentiable	B-Method
variant	I-Method
of	O
one	O
specific	O
graph	O
feature	O
.	O
	
section	O
:	O
Background	O
	
We	O
provide	O
a	O
brief	O
introduction	O
to	O
the	O
required	O
background	O
in	O
convolutional	B-Method
networks	I-Method
and	O
graph	B-Method
theory	I-Method
.	O
	
subsection	O
:	O
Convolutional	B-Method
Neural	I-Method
Networks	I-Method
	
CNNs	B-Method
were	O
inspired	O
by	O
earlier	O
work	O
that	O
showed	O
that	O
the	O
visual	O
cortex	O
in	O
animals	O
contains	O
complex	O
arrangements	O
of	O
cells	O
,	O
responsible	O
for	O
detecting	O
light	O
in	O
small	O
local	O
regions	O
of	O
the	O
visual	O
field	O
.	O
	
CNNs	B-Method
were	O
developed	O
in	O
the	O
s	O
and	O
have	O
been	O
applied	O
to	O
image	B-Task
,	I-Task
speech	I-Task
,	I-Task
text	I-Task
,	I-Task
and	I-Task
drug	I-Task
discovery	I-Task
problems	I-Task
.	O
	
A	O
predecessor	O
to	O
CNNs	B-Method
was	O
the	O
Neocognitron	B-Method
.	O
	
A	O
typical	O
CNN	B-Method
is	O
composed	O
of	O
convolutional	B-Method
and	I-Method
dense	I-Method
layers	I-Method
.	O
	
The	O
purpose	O
of	O
the	O
first	O
convolutional	B-Method
layer	I-Method
is	O
the	O
extraction	O
of	O
common	O
patterns	O
found	O
within	O
local	O
regions	O
of	O
the	O
input	O
images	O
.	O
	
CNNs	B-Method
convolve	O
learned	O
filters	O
over	O
the	O
input	O
image	O
,	O
computing	O
the	O
inner	O
product	O
at	O
every	O
image	O
location	O
in	O
the	O
image	O
and	O
outputting	O
the	O
result	O
as	O
tensors	O
whose	O
depth	O
is	O
the	O
number	O
of	O
filters	O
.	O
	
subsection	O
:	O
Graphs	O
	
A	O
graph	O
is	O
a	O
pair	O
with	O
the	O
set	O
of	O
vertices	O
and	O
the	O
set	O
of	O
edges	O
.	O
	
Let	O
be	O
the	O
number	O
of	O
vertices	O
and	O
the	O
number	O
of	O
edges	O
.	O
	
Each	O
graph	O
can	O
be	O
represented	O
by	O
an	O
adjacency	O
matrix	O
of	O
size	O
,	O
where	O
if	O
there	O
is	O
an	O
edge	O
from	O
vertex	O
to	O
vertex	O
,	O
and	O
otherwise	O
.	O
	
In	O
this	O
case	O
,	O
we	O
say	O
that	O
vertex	O
has	O
position	O
in	O
.	O
	
Moreover	O
,	O
if	O
we	O
say	O
and	O
are	O
adjacent	O
.	O
	
Node	O
and	O
edge	O
attributes	O
are	O
features	O
that	O
attain	O
one	O
value	O
for	O
each	O
node	O
and	O
edge	O
of	O
a	O
graph	O
.	O
	
We	O
use	O
the	O
term	O
attribute	O
value	O
instead	O
of	O
label	O
to	O
avoid	O
confusion	O
with	O
the	O
graph	B-Method
-	I-Method
theoretical	I-Method
concept	I-Method
of	O
a	O
labeling	B-Method
.	O
	
A	O
walk	O
is	O
a	O
sequence	O
of	O
nodes	O
in	O
a	O
graph	O
,	O
in	O
which	O
consecutive	O
nodes	O
are	O
connected	O
by	O
an	O
edge	O
.	O
	
A	O
path	O
is	O
a	O
walk	O
with	O
distinct	O
nodes	O
.	O
	
We	O
write	O
to	O
denote	O
the	O
distance	O
between	O
and	O
,	O
that	O
is	O
,	O
the	O
length	O
of	O
the	O
shortest	O
path	O
between	O
and	O
.	O
is	O
the	O
-	O
neighborhood	O
of	O
a	O
node	O
,	O
that	O
is	O
,	O
all	O
nodes	O
that	O
are	O
adjacent	O
to	O
.	O
	
Labeling	B-Task
and	O
Node	B-Task
Partitions	I-Task
.	O
	
Patchy	B-Method
-	I-Method
san	I-Method
utilizes	O
graph	B-Method
labelings	I-Method
to	O
impose	O
an	O
order	O
on	O
nodes	O
.	O
	
A	O
graph	B-Method
labeling	I-Method
is	O
a	O
function	O
from	O
the	O
set	O
of	O
vertices	O
to	O
an	O
ordered	O
set	O
such	O
as	O
the	O
real	O
numbers	O
and	O
integers	O
.	O
	
A	O
graph	B-Method
labeling	I-Method
procedure	I-Method
computes	O
a	O
graph	B-Method
labeling	I-Method
for	O
an	O
input	O
graph	O
.	O
	
When	O
it	O
is	O
clear	O
from	O
the	O
context	O
,	O
we	O
use	O
labeling	B-Task
to	O
refer	O
to	O
both	O
,	O
the	O
graph	B-Method
labeling	I-Method
and	O
the	O
procedure	O
to	O
compute	O
it	O
.	O
	
A	O
ranking	B-Task
(	O
or	O
coloring	B-Task
)	O
is	O
a	O
function	O
.	O
	
Every	O
labeling	O
induces	O
a	O
ranking	O
with	O
if	O
and	O
only	O
if	O
.	O
	
If	O
the	O
labeling	B-Method
of	I-Method
graph	I-Method
is	O
injective	O
,	O
it	O
determines	O
a	O
total	O
order	O
of	O
’s	O
vertices	O
and	O
a	O
unique	O
adjacency	O
matrix	O
of	O
where	O
vertex	O
has	O
position	O
in	O
.	O
	
Moreover	O
,	O
every	O
graph	O
labeling	O
induces	O
a	O
partition	O
on	O
with	O
if	O
and	O
only	O
if	O
.	O
	
Examples	O
of	O
graph	B-Method
labeling	I-Method
procedures	I-Method
are	O
node	O
degree	O
and	O
other	O
measures	B-Metric
of	I-Metric
centrality	I-Metric
commonly	O
used	O
in	O
the	O
analysis	B-Task
of	I-Task
networks	I-Task
.	O
	
For	O
instance	O
,	O
the	O
betweeness	O
centrality	O
of	O
a	O
vertex	O
computes	O
the	O
fractions	O
of	O
shortest	O
paths	O
that	O
pass	O
through	O
.	O
	
The	O
Weisfeiler	B-Method
-	I-Method
Lehman	I-Method
algorithm	I-Method
is	O
a	O
procedure	O
for	O
partitioning	B-Task
the	I-Task
vertices	I-Task
of	I-Task
a	I-Task
graph	I-Task
.	O
	
It	O
is	O
also	O
known	O
as	O
color	B-Task
refinement	I-Task
and	O
naive	B-Task
vertex	I-Task
classification	I-Task
.	O
	
Color	B-Task
refinement	I-Task
has	O
attracted	O
considerable	O
interest	O
in	O
the	O
ML	B-Task
community	I-Task
since	O
it	O
can	O
be	O
applied	O
to	O
speed	O
-	O
up	O
inference	B-Task
in	O
graphical	B-Task
models	I-Task
and	O
as	O
a	O
method	O
to	O
compute	O
graph	O
kernels	O
.	O
	
Patchy	B-Method
-	I-Method
san	I-Method
applies	O
these	O
labeling	B-Method
procedures	I-Method
,	O
among	O
others	O
(	O
degree	O
,	O
page	O
-	O
rank	O
,	O
eigenvector	O
centrality	O
,	O
etc	O
.	O
)	O
,	O
to	O
impose	O
an	O
order	O
on	O
the	O
nodes	O
of	O
graphs	O
,	O
replacing	O
application	O
-	O
dependent	O
orders	O
(	O
temporal	O
,	O
spatial	O
,	O
etc	O
.	O
)	O
where	O
missing	O
.	O
	
Isomorphism	B-Method
and	O
Canonicalization	B-Method
.	O
	
The	O
computational	B-Task
problem	I-Task
of	O
deciding	O
whether	O
two	O
graphs	O
are	O
isomorphic	O
surfaces	O
in	O
several	O
application	O
domains	O
.	O
	
The	O
graph	B-Task
isomorphism	I-Task
(	I-Task
GI	I-Task
)	I-Task
problem	I-Task
is	O
in	O
NP	O
but	O
not	O
known	O
to	O
be	O
in	O
P	O
or	O
NP	O
-	O
hard	O
.	O
	
Under	O
several	O
mild	O
restrictions	O
,	O
GI	B-Method
is	O
known	O
to	O
be	O
in	O
P.	O
	
For	O
instance	O
,	O
GI	O
is	O
in	O
P	O
for	O
graphs	O
of	O
bounded	O
degree	O
.	O
	
A	O
canonicalization	B-Method
of	I-Method
a	I-Method
graph	I-Method
is	O
a	O
graph	O
with	O
a	O
fixed	O
vertex	O
order	O
which	O
is	O
isomorphic	O
to	O
and	O
which	O
represents	O
its	O
entire	O
isomorphism	O
class	O
.	O
	
In	O
practice	O
,	O
the	O
graph	B-Method
canonicalization	I-Method
tool	I-Method
Nauty	I-Method
has	O
shown	O
remarkable	O
performance	O
.	O
	
section	O
:	O
Learning	B-Task
CNNs	I-Task
for	O
Arbitrary	B-Task
Graphs	I-Task
	
When	O
CNNs	B-Method
are	O
applied	O
to	O
images	O
,	O
a	O
receptive	O
field	O
(	O
a	O
square	O
grid	O
)	O
is	O
moved	O
over	O
each	O
image	O
with	O
a	O
particular	O
step	O
size	O
.	O
	
The	O
receptive	O
field	O
reads	O
the	O
pixels	O
’	O
feature	O
values	O
,	O
for	O
each	O
channel	O
once	O
,	O
and	O
a	O
patch	O
of	O
values	O
is	O
created	O
for	O
each	O
channel	O
.	O
	
Since	O
the	O
pixels	O
of	O
an	O
image	O
have	O
an	O
implicit	O
arrangement	O
–	O
a	O
spatial	O
order	O
	
–	O
the	O
receptive	O
fields	O
are	O
always	O
moved	O
from	O
left	O
to	O
right	O
and	O
top	O
to	O
bottom	O
.	O
	
Moreover	O
,	O
the	O
spatial	O
order	O
uniquely	O
determines	O
the	O
nodes	O
of	O
each	O
receptive	O
field	O
and	O
the	O
way	O
these	O
nodes	O
are	O
mapped	O
to	O
a	O
vector	B-Method
space	I-Method
representation	I-Method
(	O
see	O
Figure	O
[	O
reference	O
]	O
(	O
b	O
)	O
)	O
.	O
	
Consequently	O
,	O
the	O
values	O
read	O
from	O
two	O
pixels	O
using	O
two	O
different	O
locations	O
of	O
the	O
receptive	O
field	O
are	O
assigned	O
to	O
the	O
same	O
relative	O
position	O
if	O
and	O
only	O
if	O
the	O
pixels	O
’	O
structural	O
roles	O
(	O
their	O
spatial	O
position	O
within	O
the	O
receptive	O
field	O
)	O
are	O
identical	O
.	O
	
To	O
show	O
the	O
connection	O
between	O
CNNs	B-Method
and	O
Patchy	B-Task
-	I-Task
san	I-Task
,	O
we	O
frame	O
CNNs	B-Method
on	O
images	B-Material
as	O
identifying	O
a	O
sequence	O
of	O
nodes	O
in	O
the	O
square	B-Method
grid	I-Method
graph	I-Method
representing	O
the	O
image	O
and	O
building	O
a	O
normalized	B-Method
neighborhood	I-Method
graph	I-Method
	
–	O
	
a	O
receptive	O
field	O
–	O
	
for	O
each	O
node	O
in	O
the	O
identified	O
sequence	O
.	O
	
For	O
graph	B-Task
collections	I-Task
where	O
an	O
application	O
-	O
dependent	O
node	O
order	O
is	O
missing	O
and	O
where	O
the	O
nodes	O
of	O
any	O
two	O
graphs	O
are	O
not	O
yet	O
aligned	O
,	O
we	O
need	O
to	O
determine	O
for	O
each	O
graph	O
(	O
i	O
)	O
the	O
sequences	O
of	O
nodes	O
for	O
which	O
we	O
create	O
neighborhoods	O
,	O
and	O
(	O
ii	O
)	O
a	O
unique	O
mapping	O
from	O
the	O
graph	B-Method
representation	I-Method
to	O
a	O
vector	B-Method
representation	I-Method
such	O
that	O
nodes	O
with	O
similar	O
structural	O
roles	O
in	O
the	O
neighborhood	O
graphs	O
are	O
positioned	O
similarly	O
in	O
the	O
vector	B-Method
representation	I-Method
.	O
	
We	O
address	O
these	O
problems	O
by	O
leveraging	O
graph	B-Method
labeling	I-Method
procedures	I-Method
that	O
assigns	O
nodes	O
from	O
two	O
different	O
graphs	O
to	O
a	O
similar	O
relative	O
position	O
in	O
their	O
respective	O
adjacency	O
matrices	O
if	O
their	O
structural	O
roles	O
within	O
the	O
graphs	O
are	O
similar	O
.	O
	
Given	O
a	O
collection	O
of	O
graphs	B-Material
,	O
Patchy	B-Method
-	I-Method
san	I-Method
(	I-Method
Select	I-Method
-	I-Method
Assemble	I-Method
-	I-Method
Normalize	I-Method
)	O
applies	O
the	O
following	O
steps	O
to	O
each	O
graph	O
:	O
(	O
1	O
)	O
Select	O
a	O
fixed	O
-	O
length	O
sequence	O
of	O
nodes	O
from	O
the	O
graph	O
;	O
(	O
2	O
)	O
assemble	O
a	O
fixed	O
-	O
size	O
neighborhood	O
for	O
each	O
node	O
in	O
the	O
selected	O
sequence	O
;	O
(	O
3	O
)	O
normalize	O
the	O
extracted	O
neighborhood	O
graph	O
;	O
and	O
(	O
4	O
)	O
learn	O
neighborhood	B-Method
representations	I-Method
with	O
convolutional	B-Method
neural	I-Method
networks	I-Method
from	O
the	O
resulting	O
sequence	O
of	O
patches	O
.	O
	
In	O
the	O
following	O
,	O
we	O
describe	O
methods	O
that	O
address	O
the	O
above	O
-	O
mentioned	O
challenges	O
.	O
	
[	O
t	O
!	O
]	O
	
SelNodeSeq	B-Method
:	O
Select	O
Node	O
Sequence	O
{	O
algorithmic}	O
[	O
1	O
]	O
graph	B-Method
labeling	I-Method
procedure	I-Method
ℓ	O
	
,	O
graph	O
=	O
G	O
(	O
V	O
,	O
E	O
)	O
,	O
stride	O
s	O
,	O
width	O
w	O
,	O
receptive	O
field	O
size	O
k	O
	
=	O
top	O
w	O
elements	O
of	O
V	O
according	O
to	O
ℓ	O
f	O
to	O
each	O
input	O
channel	O
=	O
	
j	O
+	O
j1	O
	
subsection	O
:	O
Node	B-Method
Sequence	I-Method
Selection	I-Method
	
Node	B-Method
sequence	I-Method
selection	I-Method
is	O
the	O
process	O
of	O
identifying	O
,	O
for	O
each	O
input	O
graph	O
,	O
a	O
sequence	O
of	O
nodes	O
for	O
which	O
receptive	O
fields	O
are	O
created	O
.	O
	
Algorithm	O
[	O
reference	O
]	O
lists	O
one	O
such	O
procedure	O
.	O
	
First	O
,	O
the	O
vertices	O
of	O
the	O
input	O
graph	O
are	O
sorted	O
with	O
respect	O
to	O
a	O
given	O
graph	O
labeling	O
.	O
	
Second	O
,	O
the	O
resulting	O
node	O
sequence	O
is	O
traversed	O
using	O
a	O
given	O
stride	O
and	O
for	O
each	O
visited	O
node	O
,	O
Algorithm	O
[	O
reference	O
]	O
is	O
executed	O
to	O
construct	O
a	O
receptive	O
field	O
,	O
until	O
exactly	O
receptive	O
fields	O
have	O
been	O
created	O
.	O
	
The	O
stride	O
determines	O
the	O
distance	O
,	O
relative	O
to	O
the	O
selected	O
node	O
sequence	O
,	O
between	O
two	O
consecutive	O
nodes	O
for	O
which	O
a	O
receptive	O
field	O
is	O
created	O
.	O
	
If	O
the	O
number	O
of	O
nodes	O
is	O
smaller	O
than	O
,	O
the	O
algorithm	O
creates	O
all	O
-	O
zero	O
receptive	O
fields	O
for	O
padding	B-Task
purposes	I-Task
.	O
	
Several	O
alternative	O
methods	O
for	O
vertex	B-Task
sequence	I-Task
selection	I-Task
are	O
possible	O
.	O
	
For	O
instance	O
,	O
a	O
depth	B-Method
-	I-Method
first	I-Method
traversal	I-Method
of	O
the	O
input	O
graph	O
guided	O
by	O
the	O
values	O
of	O
the	O
graph	B-Method
labeling	I-Method
.	O
	
We	O
leave	O
these	O
ideas	O
to	O
future	O
work	O
.	O
	
[	O
t	O
!	O
]	O
	
NeighAssemb	O
:	O
Neighborhood	O
Assembly	O
{	O
algorithmic}	O
[	O
1	O
]	O
vertex	O
v	O
,	O
receptive	O
field	O
size	O
k	O
set	O
of	O
neighborhood	O
nodes	O
N	O
for	O
v	O
and	O
>	O
|L|0	O
the	O
set	O
of	O
vertices	O
N	O
	
subsection	O
:	O
Neighborhood	B-Method
Assembly	I-Method
	
For	O
each	O
of	O
the	O
nodes	O
identified	O
in	O
the	O
previous	O
step	O
,	O
a	O
receptive	O
field	O
has	O
to	O
be	O
constructed	O
.	O
	
Algorithm	O
[	O
reference	O
]	O
first	O
calls	O
Algorithm	O
[	O
reference	O
]	O
to	O
assembles	O
a	O
local	O
neighborhood	O
for	O
the	O
input	O
node	O
.	O
	
The	O
nodes	O
of	O
the	O
neighborhood	O
are	O
the	O
candidates	O
for	O
the	O
receptive	O
field	O
.	O
	
Algorithm	O
[	O
reference	O
]	O
lists	O
the	O
neighborhood	O
assembly	O
steps	O
.	O
	
Given	O
as	O
inputs	O
a	O
node	O
and	O
the	O
size	O
of	O
the	O
receptive	O
field	O
,	O
the	O
procedure	O
performs	O
a	O
breadth	B-Method
-	I-Method
first	I-Method
search	I-Method
,	O
exploring	O
vertices	O
with	O
an	O
increasing	O
distance	O
from	O
,	O
and	O
adds	O
these	O
vertices	O
to	O
a	O
set	O
.	O
	
If	O
the	O
number	O
of	O
collected	O
nodes	O
is	O
smaller	O
than	O
,	O
the	O
-	O
neighborhood	O
of	O
the	O
vertices	O
most	O
recently	O
added	O
to	O
are	O
collected	O
,	O
and	O
so	O
on	O
,	O
until	O
at	O
least	O
vertices	O
are	O
in	O
,	O
or	O
until	O
there	O
are	O
no	O
more	O
neighbors	O
to	O
add	O
.	O
	
Note	O
that	O
at	O
this	O
time	O
,	O
the	O
size	O
of	O
is	O
possibly	O
different	O
to	O
.	O
	
subsection	O
:	O
Graph	B-Method
Normalization	I-Method
	
The	O
receptive	O
field	O
for	O
a	O
node	O
is	O
constructed	O
by	O
normalizing	O
the	O
neighborhood	O
assembled	O
in	O
the	O
previous	O
step	O
.	O
	
Illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
the	O
normalization	O
imposes	O
an	O
order	O
on	O
the	O
nodes	O
of	O
the	O
neighborhood	O
graph	O
so	O
as	O
to	O
map	O
from	O
the	O
unordered	O
graph	O
space	O
to	O
a	O
vector	O
space	O
with	O
a	O
linear	O
order	O
.	O
	
The	O
basic	O
idea	O
is	O
to	O
leverage	O
graph	B-Method
labeling	I-Method
procedures	I-Method
that	O
assigns	O
nodes	O
of	O
two	O
different	O
graphs	O
to	O
a	O
similar	O
relative	O
position	O
in	O
the	O
respective	O
adjacency	O
matrices	O
if	O
and	O
only	O
if	O
their	O
structural	O
roles	O
within	O
the	O
graphs	O
are	O
similar	O
.	O
	
To	O
formalize	O
this	O
intuition	O
,	O
we	O
define	O
the	O
optimal	B-Task
graph	I-Task
normalization	I-Task
problem	I-Task
which	O
aims	O
to	O
find	O
a	O
labeling	B-Task
that	O
is	O
optimal	O
relative	O
to	O
a	O
given	O
collection	O
of	O
graphs	O
.	O
	
theorem	O
:	O
(	O
Optimal	B-Method
graph	I-Method
normalization	I-Method
)	O
.	O
	
Let	O
G	O
be	O
a	O
collection	O
of	O
unlabeled	B-Material
graphs	I-Material
with	O
k	O
nodes	O
,	O
let	O
ℓ	O
be	O
an	O
injective	B-Method
graph	I-Method
labeling	I-Method
procedure	I-Method
,	O
let	O
dG	B-Method
be	O
a	O
distance	B-Method
measure	I-Method
on	O
graphs	O
with	O
k	O
nodes	O
,	O
and	O
let	O
dA	O
be	O
a	O
distance	B-Metric
measure	I-Metric
on	O
×kk	B-Method
matrices	I-Method
.	O
	
Find	O
^ℓ	O
such	O
that	O
The	O
problem	O
amounts	O
to	O
finding	O
a	O
graph	B-Method
labeling	I-Method
procedure	I-Method
,	O
such	O
that	O
,	O
for	O
any	O
two	O
graphs	O
drawn	O
uniformly	O
at	O
random	O
from	O
,	O
the	O
expected	O
difference	O
between	O
the	O
distance	O
of	O
the	O
graphs	O
in	O
vector	O
space	O
(	O
with	O
respect	O
to	O
the	O
adjacency	O
matrices	O
based	O
on	O
)	O
and	O
the	O
distance	O
of	O
the	O
graphs	O
in	O
graph	O
space	O
is	O
minimized	O
.	O
	
The	O
optimal	B-Task
graph	I-Task
normalization	I-Task
problem	I-Task
is	O
a	O
generalization	O
of	O
the	O
classical	O
graph	B-Task
canonicalization	I-Task
problem	I-Task
.	O
	
A	O
canonical	B-Method
labeling	I-Method
algorithm	I-Method
,	O
however	O
,	O
is	O
optimal	O
only	O
for	O
isomorphic	O
graphs	O
and	O
might	O
perform	O
poorly	O
for	O
graphs	O
that	O
are	O
similar	O
but	O
not	O
isomorphic	O
.	O
	
In	O
contrast	O
,	O
the	O
smaller	O
the	O
expectation	O
of	O
the	O
optimal	B-Task
normalization	I-Task
problem	I-Task
,	O
the	O
better	O
the	O
labeling	O
aligns	O
nodes	O
with	O
similar	O
structural	O
roles	O
.	O
	
Note	O
that	O
the	O
similarity	O
is	O
determined	O
by	O
.	O
	
[	O
t	O
!	O
]	O
	
ReceptiveField	B-Method
:	O
Create	O
Receptive	O
Field	O
{	O
algorithmic}	O
[	O
1	O
]	O
vertex	O
v	O
,	O
graph	O
labeling	O
ℓ	O
,	O
receptive	O
field	O
size	O
k	O
Gnorm	O
	
We	O
have	O
the	O
following	O
result	O
concerning	O
the	O
complexity	B-Metric
of	O
the	O
optimal	B-Task
normalization	I-Task
problem	I-Task
.	O
	
theorem	O
:	O
.	O
	
Optimal	B-Task
graph	I-Task
normalization	I-Task
is	O
NP	O
-	O
hard	O
.	O
	
proof	O
:	O
Proof	O
.	O
	
By	O
reduction	O
from	O
subgraph	B-Method
isomorphism	I-Method
.	O
	
∎	O
Patchy	B-Method
-	I-Method
san	I-Method
does	O
not	O
solve	O
the	O
above	O
optimization	B-Task
problem	I-Task
.	O
	
Instead	O
,	O
it	O
may	O
compare	O
different	O
graph	B-Method
labeling	I-Method
methods	I-Method
and	O
choose	O
the	O
one	O
that	O
performs	O
best	O
relative	O
to	O
a	O
given	O
collection	O
of	O
graphs	O
.	O
	
[	O
t	O
!	O
]	O
	
NormalizeGraph	B-Method
:	O
	
Graph	B-Method
Normalization	I-Method
{	O
algorithmic}	O
[	O
1	O
]	O
subset	O
of	O
vertices	O
	
U	O
from	O
original	O
graph	O
G	O
,	O
vertex	O
v	O
,	O
graph	O
labeling	O
ℓ	O
,	O
receptive	O
field	O
size	O
k	O
receptive	O
field	O
for	O
v	O
ranking	O
r	O
of	O
U	O
using	O
ℓ	O
,	O
subject	O
to	O
:	O
∈∀u	O
,	O
wU⁢d	O
(	O
u	O
,	O
v	O
)	O
<⁢d	O
(	O
w	O
,	O
v	O
)	O
⇒⁢r	O
(	O
u	O
)	O
<⁢r	O
(	O
w	O
)	O
top	O
k	O
vertices	O
in	O
U	O
according	O
to	O
r	O
ranking	O
r	O
of	O
N	O
using	O
ℓ	O
,	O
subject	O
to	O
:	O
∈∀u	O
,	O
wN⁢d	O
(	O
u	O
,	O
v	O
)	O
<⁢d	O
(	O
w	O
,	O
v	O
)	O
⇒⁢r	O
(	O
u	O
)	O
<⁢r	O
(	O
w	O
)	O
	
and	O
-	O
k|U|	O
dummy	O
nodes	O
the	O
subgraph	O
⁢G	O
[	O
N	O
]	O
for	O
the	O
vertices	O
N	O
⁢G	O
[	O
N	O
]	O
,	O
respecting	O
the	O
prior	O
coloring	O
r	O
⁢G	O
[	O
N	O
]	O
	
theorem	O
:	O
.	O
	
Let	O
G	O
be	O
a	O
collection	O
of	O
graphs	O
and	O
let	O
(	O
G1	O
,	O
G1′	O
)	O
,	O
…	O
,	O
(	O
GN	O
,	O
GN′	O
)	O
be	O
a	O
sequence	O
of	O
pairs	O
of	O
graphs	O
sampled	O
independently	O
and	O
uniformly	O
at	O
random	O
from	O
G.	O
Let	O
:	O
=	O
^θℓ∑=i1N	O
/	O
⁢dA	O
(	O
⁢Aℓ	O
(	O
Gi	O
),	O
⁢Aℓ	O
(	O
Gi′	O
))	O
N	O
and	O
:	O
=	O
θℓ⁢EG	O
[	O
|	O
-	O
⁢dA	O
(	O
⁢Aℓ	O
(	O
G	O
),	O
⁢Aℓ	O
(	O
G′	O
))	O
⁢dG	O
(	O
G	O
,	O
G′	O
)	O
|	O
]	O
.	O
	
If	O
≥dAdG	O
,	O
then	O
<	O
⁢EG	O
[	O
^θℓ1	O
]	O
⁢EG	O
[	O
^θℓ2	O
]	O
if	O
and	O
only	O
if	O
<	O
θℓ1θℓ2	O
.	O
	
Theorem	O
[	O
reference	O
]	O
enables	O
us	O
to	O
compare	O
different	O
labeling	B-Method
procedures	I-Method
in	O
an	O
unsupervised	O
manner	O
via	O
a	O
comparison	O
of	O
the	O
corresponding	O
estimators	O
.	O
	
Under	O
the	O
assumption	O
,	O
the	O
smaller	O
the	O
estimate	O
the	O
smaller	O
the	O
absolute	O
difference	O
.	O
	
Therefore	O
,	O
we	O
can	O
simply	O
choose	O
the	O
labeling	O
for	O
which	O
is	O
minimal	O
.	O
	
The	O
assumption	O
holds	O
,	O
for	O
instance	O
,	O
for	O
the	O
edit	O
distance	O
on	O
graphs	O
and	O
the	O
Hamming	O
distance	O
on	O
adjacency	O
matrices	O
.	O
	
Finally	O
,	O
note	O
that	O
all	O
of	O
the	O
above	O
results	O
can	O
be	O
extended	O
to	O
directed	B-Task
graphs	I-Task
.	O
	
The	O
graph	B-Task
normalization	I-Task
problem	I-Task
and	O
the	O
application	O
of	O
appropriate	O
graph	B-Method
labeling	I-Method
procedures	I-Method
for	O
the	O
normalization	B-Task
of	I-Task
local	I-Task
graph	I-Task
structures	I-Task
is	O
at	O
the	O
core	O
of	O
the	O
proposed	O
approach	O
.	O
	
Within	O
the	O
Patchy	B-Method
-	I-Method
san	I-Method
framework	I-Method
,	O
we	O
normalize	O
the	O
neighborhood	O
graphs	O
of	O
a	O
vertex	O
.	O
	
The	O
labeling	O
of	O
the	O
vertices	O
is	O
therefore	O
constrained	O
by	O
the	O
graph	O
distance	O
to	O
:	O
for	O
any	O
two	O
vertices	O
,	O
if	O
is	O
closer	O
to	O
than	O
,	O
then	O
is	O
always	O
ranked	O
higher	O
than	O
.	O
	
This	O
definition	O
ensures	O
that	O
has	O
always	O
rank	O
,	O
and	O
that	O
the	O
closer	O
a	O
vertex	O
is	O
to	O
in	O
,	O
the	O
higher	O
it	O
is	O
ranked	O
in	O
the	O
vector	B-Method
space	I-Method
representation	I-Method
.	O
	
Since	O
most	O
labeling	B-Method
methods	I-Method
are	O
not	O
injective	O
,	O
it	O
is	O
necessary	O
to	O
break	O
ties	O
between	O
same	O
-	O
label	O
nodes	O
.	O
	
To	O
do	O
so	O
,	O
we	O
use	O
Nauty	O
.	O
	
Nauty	O
accepts	O
prior	O
node	O
partitions	O
as	O
input	O
and	O
breaks	O
remaining	O
ties	O
by	O
choosing	O
the	O
lexicographically	O
maximal	O
adjacency	O
matrix	O
.	O
	
It	O
is	O
known	O
that	O
graph	B-Task
isomorphism	I-Task
is	O
in	O
PTIME	O
for	O
graphs	O
of	O
bounded	O
degree	O
.	O
	
Due	O
to	O
the	O
constant	O
size	O
of	O
the	O
neighborhood	O
graphs	O
,	O
the	O
algorithm	O
runs	O
in	O
time	O
polynomial	O
in	O
the	O
size	O
of	O
the	O
original	O
graph	O
and	O
,	O
on	O
average	O
,	O
in	O
time	O
linear	O
in	O
.	O
	
Our	O
experiments	O
verify	O
that	O
computing	O
a	O
canonical	B-Method
labeling	I-Method
of	I-Method
the	I-Method
graph	I-Method
neigborhoods	I-Method
adds	O
a	O
negligible	O
overhead	O
.	O
	
Algorithm	O
[	O
reference	O
]	O
lists	O
the	O
normalization	B-Method
procedure	I-Method
.	O
	
If	O
the	O
size	O
of	O
the	O
input	O
set	O
is	O
larger	O
than	O
,	O
it	O
first	O
applies	O
the	O
ranking	B-Method
based	O
on	O
to	O
select	O
the	O
top	O
nodes	O
and	O
recomputes	O
a	O
ranking	O
on	O
the	O
smaller	O
set	O
of	O
nodes	O
.	O
	
If	O
the	O
size	O
of	O
is	O
smaller	O
than	O
,	O
it	O
adds	O
disconnected	O
dummy	O
nodes	O
.	O
	
Finally	O
,	O
it	O
induces	O
the	O
subgraph	O
on	O
the	O
vertices	O
and	O
canonicalizes	O
the	O
graph	O
taking	O
the	O
ranking	O
as	O
prior	O
coloring	O
.	O
	
We	O
can	O
relate	O
Patchy	B-Method
-	I-Method
san	I-Method
to	O
CNNs	B-Method
for	O
images	B-Material
as	O
follows	O
.	O
	
theorem	O
:	O
.	O
	
Given	O
a	O
sequence	O
of	O
pixels	O
taken	O
from	O
an	O
image	O
.	O
	
Applying	O
Patchy	B-Method
-	I-Method
san	I-Method
with	O
receptive	O
field	O
size	O
(	O
-	O
⁢2m1	O
)	O
2	O
,	O
stride	O
s	O
,	O
no	O
zero	O
padding	O
,	O
and	O
1	B-Method
-	I-Method
WL	I-Method
normalization	I-Method
to	O
the	O
sequence	O
is	O
identical	O
(	O
up	O
to	O
a	O
fixed	O
permutation	O
of	O
the	O
receptive	O
field	O
)	O
to	O
the	O
first	B-Method
layer	I-Method
of	O
a	O
CNN	B-Method
with	O
receptive	O
field	O
size	O
-	O
⁢2m1	O
,	O
stride	O
s	O
,	O
and	O
no	O
zero	O
padding	O
.	O
	
proof	O
:	O
Proof	O
.	O
	
It	O
is	O
possible	O
to	O
show	O
that	O
if	O
an	O
input	O
graph	O
is	O
a	O
square	O
grid	O
,	O
then	O
the	O
-	O
WL	O
normalized	O
receptive	O
field	O
constructed	O
for	O
a	O
vertex	O
is	O
always	O
a	O
square	B-Method
grid	I-Method
graph	I-Method
with	O
a	O
unique	O
vertex	O
order	O
.	O
	
∎	O
	
subsection	O
:	O
Convolutional	B-Method
Architecture	I-Method
	
Patchy	B-Method
-	I-Method
san	I-Method
is	O
able	O
to	O
process	O
both	O
vertex	O
and	O
edge	O
attributes	O
(	O
discrete	O
and	O
continuous	O
)	O
.	O
	
Let	O
be	O
the	O
number	O
of	O
vertex	O
attributes	O
and	O
let	O
be	O
the	O
number	O
of	O
edge	O
attributes	O
.	O
	
For	O
each	O
input	O
graph	O
,	O
it	O
applies	O
normalized	O
receptive	O
fields	O
for	O
vertices	O
and	O
edges	O
which	O
results	O
in	O
one	O
and	O
one	O
tensor	O
.	O
	
These	O
can	O
be	O
reshaped	O
to	O
a	O
and	O
a	O
tensors	O
.	O
	
Note	O
that	O
and	O
are	O
the	O
number	O
of	O
input	O
channels	O
.	O
	
We	O
can	O
now	O
apply	O
a	O
-	B-Method
dimensional	I-Method
convolutional	I-Method
layer	I-Method
with	O
stride	O
and	O
receptive	O
field	O
size	O
to	O
the	O
first	O
and	O
to	O
the	O
second	O
tensor	O
.	O
	
The	O
rest	O
of	O
the	O
architecture	O
can	O
be	O
chosen	O
arbitrarily	O
.	O
	
We	O
may	O
use	O
merge	O
layers	O
to	O
combine	O
convolutional	O
layers	O
representing	O
nodes	O
and	O
edges	O
,	O
respectively	O
.	O
	
section	O
:	O
Complexity	B-Metric
and	O
Implementation	O
	
Patchy	B-Method
-	I-Method
san	I-Method
’s	I-Method
algorithm	I-Method
for	O
creating	B-Task
receptive	I-Task
fields	I-Task
is	O
highly	O
efficient	O
and	O
naively	O
parallelizable	O
because	O
the	O
fields	O
are	O
generated	O
independently	O
.	O
	
We	O
can	O
show	O
the	O
following	O
asymptotic	O
worst	O
-	O
case	O
result	O
.	O
	
theorem	O
:	O
.	O
	
Let	O
N	O
be	O
the	O
number	O
of	O
graphs	O
,	O
let	O
k	O
be	O
the	O
receptive	O
field	O
size	O
,	O
w	O
the	O
width	O
,	O
and	O
⁢O	O
(	O
⁢f	O
(	O
n	O
,	O
m	O
)	O
)	O
	
the	O
complexity	O
of	O
computing	O
a	O
given	O
labeling	O
ℓ	O
for	O
a	O
graph	O
with	O
n	O
vertices	O
and	O
m	O
edges	O
.	O
	
Patchy	B-Method
-	I-Method
san	I-Method
has	O
a	O
worst	B-Metric
-	I-Metric
case	I-Metric
complexity	I-Metric
of	O
⁢O	O
(	O
⁢Nw	O
(+	O
⁢f	O
(	O
n	O
,	O
m	O
)	O
⁢nlog	O
(	O
n	O
)	O
exp	O
(	O
k	O
)	O
)	O
)	O
for	O
computing	O
the	O
receptive	O
fields	O
for	O
N	O
graphs	O
.	O
	
proof	O
:	O
Proof	O
.	O
	
Node	B-Task
sequence	I-Task
selection	I-Task
requires	O
the	O
labeling	O
of	O
each	O
input	O
graph	O
and	O
the	O
retrieval	O
of	O
the	O
highest	O
ranked	O
nodes	O
.	O
	
For	O
the	O
creation	B-Task
of	I-Task
normalized	I-Task
graph	I-Task
patches	I-Task
,	O
most	O
computational	O
effort	O
is	O
spent	O
applying	O
the	O
labeling	B-Method
procedure	I-Method
to	O
a	O
neighborhood	O
whose	O
size	O
may	O
be	O
larger	O
than	O
.	O
	
Let	O
be	O
the	O
maximum	O
degree	O
of	O
the	O
input	O
graph	O
,	O
and	O
the	O
neighborhood	O
returned	O
by	O
Algorithm	O
[	O
reference	O
]	O
.	O
	
We	O
have	O
.	O
	
The	O
term	O
comes	O
from	O
the	O
worst	B-Metric
-	I-Metric
case	I-Metric
complexity	I-Metric
of	O
the	O
graph	B-Method
canonicalization	I-Method
algorithm	I-Method
Nauty	I-Method
on	O
a	O
node	O
graph	O
.	O
	
∎	O
For	O
instance	O
,	O
for	O
the	O
Weisfeiler	B-Method
-	I-Method
Lehman	I-Method
algorithm	I-Method
,	O
which	O
has	O
a	O
complexity	B-Metric
of	O
,	O
and	O
constants	O
and	O
,	O
the	O
complexity	B-Metric
of	O
Patchy	B-Method
-	I-Method
san	I-Method
is	O
linear	O
in	O
and	O
quasi	O
-	O
linear	O
in	O
and	O
.	O
	
section	O
:	O
Experiments	O
	
We	O
conduct	O
three	O
types	O
of	O
experiments	O
:	O
a	O
runtime	B-Task
analysis	I-Task
,	O
a	O
qualitative	O
analysis	O
of	O
the	O
learned	O
features	O
,	O
and	O
a	O
comparison	O
to	O
graph	B-Method
kernels	I-Method
on	O
benchmark	B-Material
data	I-Material
sets	I-Material
.	O
	
[	O
subfigure	O
]	O
labelformat	O
=	O
empty	O
	
subsection	O
:	O
Runtime	B-Task
Analysis	I-Task
	
We	O
assess	O
the	O
efficiency	O
of	O
Patchy	B-Method
-	I-Method
san	I-Method
by	O
applying	O
it	O
to	O
real	B-Material
-	I-Material
world	I-Material
graphs	I-Material
.	O
	
The	O
objective	O
is	O
to	O
compare	O
the	O
rates	O
at	O
which	O
receptive	O
fields	O
are	O
generated	O
to	O
the	O
rate	O
at	O
which	O
state	O
of	O
the	O
art	O
CNNs	B-Method
perform	O
learning	B-Method
.	O
	
All	O
input	O
graphs	O
are	O
part	O
of	O
the	O
collection	O
of	O
the	O
Python	B-Method
module	I-Method
graph	I-Method
-	I-Method
toolhttps:	I-Method
//	I-Method
graph	I-Method
-	I-Method
tool.skewed.de	I-Method
/	I-Method
.	O
	
For	O
a	O
given	O
graph	O
,	O
we	O
used	O
Patchy	B-Method
-	I-Method
san	I-Method
to	O
compute	O
a	O
receptive	O
field	O
for	O
all	O
nodes	O
using	O
the	O
-	B-Method
dimensional	I-Method
Weisfeiler	I-Method
-	I-Method
Lehman	I-Method
(	I-Method
1	I-Method
-	I-Method
WL	I-Method
)	I-Method
algorithm	I-Method
for	O
the	O
normalization	B-Task
.	O
	
torus	B-Method
is	O
a	O
periodic	B-Material
lattice	I-Material
with	O
nodes	O
;	O
random	B-Material
is	O
a	O
random	B-Method
undirected	I-Method
graph	I-Method
with	O
nodes	O
and	O
a	O
degree	O
distribution	O
and	O
;	O
power	B-Material
is	O
a	O
network	O
representing	O
the	O
topology	O
of	O
a	O
power	B-Material
grid	I-Material
in	O
the	O
US	O
;	O
polbooks	B-Material
is	O
a	O
co	O
-	O
purchasing	B-Material
network	I-Material
of	I-Material
books	I-Material
about	O
US	B-Material
politics	I-Material
published	O
during	O
the	O
presidential	B-Material
election	I-Material
;	O
preferential	B-Method
is	O
a	O
preferential	B-Method
attachment	I-Method
network	I-Method
model	I-Method
where	O
newly	O
added	O
vertices	O
have	O
degree	O
;	O
	
astro	B-Method
-	I-Method
ph	I-Method
is	O
a	O
coauthorship	B-Method
network	I-Method
between	O
authors	O
of	O
preprints	O
posted	O
on	O
the	O
astrophysics	B-Material
arxiv	I-Material
;	O
email	O
-	O
enron	B-Material
is	O
a	O
communication	B-Method
network	I-Method
generated	O
from	O
about	O
half	O
a	O
million	O
sent	O
emails	O
.	O
	
All	O
experiments	O
were	O
run	O
on	O
commodity	O
hardware	O
with	O
64	O
G	O
RAM	O
and	O
a	O
single	O
2.8	O
GHz	O
CPU	O
.	O
	
Figure	O
[	O
reference	O
]	O
depicts	O
the	O
receptive	O
fields	O
per	O
second	O
rates	O
for	O
each	O
input	O
graph	O
.	O
	
For	O
receptive	O
field	O
size	O
and	O
Patchy	B-Method
-	I-Method
san	I-Method
creates	O
fields	O
at	O
a	O
rate	O
of	O
more	O
than	O
except	O
for	O
email	B-Method
-	O
enron	O
with	O
a	O
rate	O
of	O
and	O
,	O
respectively	O
.	O
	
For	O
,	O
the	O
largest	O
tested	O
size	O
,	O
fields	O
are	O
created	O
at	O
a	O
rate	O
of	O
at	O
least	O
.	O
	
A	O
CNN	B-Method
with	I-Method
convolutional	I-Method
and	I-Method
dense	I-Method
layers	I-Method
learns	O
at	O
a	O
rate	O
of	O
about	O
-	O
training	O
examples	O
per	O
second	O
on	O
the	O
same	O
machine	O
.	O
	
Hence	O
,	O
the	O
speed	O
at	O
which	O
receptive	O
fields	O
are	O
generated	O
is	O
sufficient	O
to	O
saturate	O
a	O
downstream	B-Method
CNN	I-Method
.	O
	
subsection	O
:	O
Feature	B-Method
Visualization	I-Method
	
The	O
visualization	B-Task
experiments	O
’	O
aim	O
is	O
to	O
qualitatively	O
investigate	O
whether	O
popular	B-Method
models	I-Method
such	O
as	O
the	O
restricted	B-Method
Boltzman	I-Method
machine	I-Method
(	I-Method
RBM	I-Method
)	I-Method
can	O
be	O
combined	O
with	O
Patchy	B-Method
-	I-Method
san	I-Method
for	O
unsupervised	B-Task
feature	I-Task
learning	I-Task
.	O
	
For	O
every	O
input	O
graph	O
,	O
we	O
have	O
generated	O
receptive	O
fields	O
for	O
all	O
nodes	O
and	O
used	O
these	O
as	O
input	O
to	O
an	O
RBM	B-Method
.	O
	
The	O
RBM	B-Method
had	O
hidden	O
nodes	O
and	O
was	O
trained	O
for	O
epochs	O
with	O
contrastive	O
divergence	O
and	O
a	O
learning	B-Metric
rate	I-Metric
of	O
.	O
	
We	O
visualize	O
the	O
features	O
learned	O
by	O
a	O
single	B-Method
-	I-Method
layer	I-Method
RBM	I-Method
for	O
-	O
dimensional	O
Weisfeiler	O
-	O
Lehman	O
(	O
1	O
-	O
WL	O
)	O
normalized	O
receptive	O
fields	O
of	O
size	O
.	O
	
Note	O
that	O
the	O
features	O
learned	O
by	O
the	O
RBM	B-Method
correspond	O
to	O
reoccurring	O
receptive	O
field	O
patterns	O
.	O
	
Figure	O
[	O
reference	O
]	O
depicts	O
some	O
of	O
the	O
features	O
and	O
samples	O
drawn	O
from	O
it	O
for	O
four	O
different	O
graphs	O
.	O
	
subsection	O
:	O
Graph	B-Task
Classification	I-Task
	
Graph	B-Task
classification	I-Task
is	O
the	O
problem	O
of	O
assigning	B-Task
graphs	I-Task
to	O
one	O
of	O
several	O
categories	O
.	O
	
Data	O
Sets	O
.	O
	
We	O
use	O
standard	O
benchmark	B-Material
data	I-Material
sets	I-Material
to	O
compare	O
run	B-Metric
-	I-Metric
time	I-Metric
and	O
classification	B-Metric
accuracy	I-Metric
with	O
state	O
of	O
	
the	O
art	B-Method
graph	I-Method
kernels	I-Method
:	O
	
MUTAG	B-Method
,	O
PCT	B-Material
,	O
NCI1	B-Material
,	O
NCI109	B-Material
,	O
PROTEIN	B-Material
,	O
and	O
D	B-Method
&	I-Method
D.	I-Method
MUTAG	I-Method
is	O
a	O
data	O
set	O
of	O
nitro	O
compounds	O
where	O
classes	O
indicate	O
whether	O
the	O
compound	O
has	O
a	O
mutagenic	O
effect	O
on	O
a	O
bacterium	O
.	O
	
PTC	B-Method
consists	O
of	O
chemical	O
compounds	O
where	O
classes	O
indicate	O
carcinogenicity	O
for	O
male	O
and	O
female	O
rats	O
.	O
	
NCI1	B-Method
and	O
NCI109	B-Method
are	O
chemical	O
compounds	O
screened	O
for	O
activity	O
against	O
non	B-Task
-	I-Task
small	I-Task
cell	I-Task
lung	I-Task
cancer	I-Task
and	I-Task
ovarian	I-Task
cancer	I-Task
cell	I-Task
lines	I-Task
.	O
	
PROTEINS	B-Material
is	O
a	O
graph	O
collection	O
where	O
nodes	O
are	O
secondary	O
structure	O
elements	O
and	O
edges	O
indicate	O
neighborhood	O
in	O
the	O
amino	O
-	O
acid	O
sequence	O
or	O
in	O
3D	O
space	O
.	O
	
Graphs	B-Method
are	O
classified	O
as	O
enzyme	O
or	O
non	O
-	O
enzyme	O
.	O
	
D	B-Method
&	I-Method
D	I-Method
is	O
a	O
data	O
set	O
of	O
protein	B-Material
structures	I-Material
classified	O
into	O
enzymes	O
and	O
non	O
-	O
enzymes	O
.	O
	
Experimental	O
Set	O
-	O
up	O
.	O
	
We	O
compared	O
Patchy	B-Method
-	I-Method
san	I-Method
with	O
the	O
shortest	B-Method
-	I-Method
path	I-Method
kernel	I-Method
(	I-Method
SP	I-Method
)	I-Method
,	O
the	O
random	B-Method
walk	I-Method
kernel	I-Method
(	O
RW	B-Method
)	O
,	O
the	O
graphlet	B-Method
count	I-Method
kernel	I-Method
(	O
GK	B-Method
)	O
,	O
and	O
the	O
Weisfeiler	B-Method
-	I-Method
Lehman	I-Method
subtree	I-Method
kernel	I-Method
(	O
WL	B-Method
)	O
.	O
	
Similar	O
to	O
previous	O
work	O
,	O
we	O
set	O
the	O
height	O
parameter	O
of	O
WL	O
to	O
,	O
the	O
size	O
of	O
the	O
graphlets	O
for	O
GK	O
to	O
,	O
and	O
chose	O
the	O
decay	O
factor	O
for	O
RW	O
from	O
.	O
	
We	O
performed	O
-	B-Method
fold	I-Method
cross	I-Method
-	I-Method
validation	I-Method
with	O
LIB	B-Method
-	I-Method
SVM	I-Method
,	O
using	O
folds	O
for	O
training	O
and	O
for	O
testing	O
,	O
and	O
repeated	O
the	O
experiments	O
times	O
.	O
	
We	O
report	O
average	B-Metric
prediction	I-Metric
accuracies	I-Metric
and	O
standard	O
deviations	O
.	O
	
For	O
Patchy	B-Task
-	I-Task
san	I-Task
(	O
referred	O
to	O
as	O
PSCN	B-Method
)	O
,	O
we	O
used	O
-	B-Method
dimensional	I-Method
WL	I-Method
normalization	I-Method
,	O
a	O
width	O
equal	O
to	O
the	O
average	O
number	O
of	O
nodes	O
(	O
see	O
Table	O
[	O
reference	O
]	O
)	O
,	O
and	O
receptive	O
field	O
sizes	O
of	O
and	O
.	O
	
For	O
the	O
experiments	O
we	O
only	O
used	O
node	O
attributes	O
.	O
	
In	O
addition	O
,	O
we	O
ran	O
experiments	O
for	O
where	O
we	O
combined	O
receptive	O
fields	O
for	O
nodes	O
and	O
edges	O
using	O
a	O
merge	B-Method
layer	I-Method
(	O
)	O
.	O
	
To	O
make	O
a	O
fair	O
comparison	O
,	O
we	O
used	O
a	O
single	O
network	B-Method
architecture	I-Method
with	O
two	O
convolutional	B-Method
layers	I-Method
,	O
one	O
dense	B-Method
hidden	I-Method
layer	I-Method
,	O
and	O
a	O
softmax	B-Method
layer	I-Method
for	O
all	O
experiments	O
.	O
	
The	O
first	O
convolutional	B-Method
layer	I-Method
had	O
output	O
channels	O
(	O
feature	O
maps	O
)	O
.	O
	
The	O
second	O
conv	B-Method
layer	I-Method
has	O
output	O
channels	O
,	O
a	O
stride	O
of	O
,	O
and	O
a	O
field	O
size	O
of	O
.	O
	
The	O
convolutional	B-Method
layers	I-Method
have	O
rectified	B-Method
linear	I-Method
units	I-Method
.	O
	
The	O
dense	B-Method
layer	I-Method
has	O
rectified	B-Method
linear	I-Method
units	I-Method
with	O
a	O
dropout	B-Metric
rate	I-Metric
of	O
.	O
	
Dropout	B-Method
and	O
the	O
relatively	O
small	O
number	O
of	O
neurons	O
are	O
needed	O
to	O
avoid	O
overfitting	O
on	O
the	O
smaller	O
data	O
sets	O
.	O
	
The	O
only	O
hyperparameter	O
we	O
optimized	O
is	O
the	O
number	O
of	O
epochs	O
and	O
the	O
batch	O
size	O
for	O
the	O
mini	B-Method
-	I-Method
batch	I-Method
gradient	I-Method
decent	I-Method
algorithm	I-Method
rmsprop	I-Method
.	O
	
All	O
of	O
the	O
above	O
was	O
implemented	O
with	O
the	O
Theano	B-Method
wrapper	I-Method
Keras	I-Method
.	O
	
We	O
also	O
applied	O
a	O
logistic	B-Method
regression	I-Method
(	O
PSLR	B-Method
)	I-Method
classifier	I-Method
on	O
the	O
patches	O
for	O
.	O
	
Moreover	O
,	O
we	O
ran	O
experiments	O
with	O
the	O
same	O
set	O
-	O
up	O
on	O
larger	O
social	B-Material
graph	I-Material
data	I-Material
sets	I-Material
(	O
up	O
to	O
graphs	O
each	O
,	O
with	O
an	O
average	O
of	O
nodes	O
)	O
,	O
and	O
compared	O
Patchy	B-Method
-	I-Method
san	I-Method
with	O
previously	O
reported	O
results	O
for	O
the	O
graphlet	B-Method
count	I-Method
(	O
GK	B-Method
)	O
and	O
the	O
deep	B-Method
graphlet	I-Method
count	I-Method
kernel	I-Method
(	O
DGK	B-Method
)	O
.	O
	
We	O
used	O
the	O
normalized	O
node	O
degree	O
as	O
attribute	O
for	O
Patchy	B-Task
-	I-Task
san	I-Task
,	O
highlighting	O
one	O
of	O
its	O
advantages	O
:	O
it	O
can	O
easily	O
incorporate	O
continuous	O
features	O
.	O
	
Results	O
.	O
	
Table	O
[	O
reference	O
]	O
lists	O
the	O
results	O
of	O
the	O
experiments	O
.	O
	
We	O
omit	O
the	O
results	O
for	O
NCI109	B-Method
as	O
they	O
are	O
almost	O
identical	O
to	O
NCI1	O
.	O
	
Despite	O
using	O
a	O
one	B-Method
-	I-Method
fits	I-Method
-	I-Method
all	I-Method
CNN	I-Method
architecture	I-Method
,	O
the	O
CNNs	B-Metric
accuracy	I-Metric
is	O
highly	O
competitive	O
with	O
existing	O
graph	B-Method
kernels	I-Method
.	O
	
In	O
most	O
cases	O
,	O
a	O
receptive	O
field	O
size	O
of	O
results	O
in	O
the	O
best	O
classification	B-Metric
accuracy	I-Metric
.	O
	
The	O
relatively	O
high	O
variance	O
can	O
be	O
explained	O
with	O
the	O
small	O
size	O
of	O
the	O
benchmark	O
data	O
sets	O
and	O
the	O
fact	O
that	O
the	O
CNNs	B-Method
hyperparameters	I-Method
(	O
with	O
the	O
exception	O
of	O
epochs	O
and	O
batch	O
size	O
)	O
were	O
not	O
tuned	O
to	O
individual	O
data	O
sets	O
.	O
	
Similar	O
to	O
the	O
experience	O
on	O
image	B-Material
and	I-Material
text	I-Material
data	I-Material
,	O
we	O
expect	O
Patchy	B-Method
-	I-Method
san	I-Method
to	O
perform	O
even	O
better	O
for	O
large	O
data	O
sets	O
.	O
	
Moreover	O
,	O
Patchy	B-Method
-	I-Method
san	I-Method
is	O
between	O
and	O
times	O
more	O
efficient	O
than	O
the	O
most	O
efficient	O
graph	B-Method
kernel	I-Method
(	O
WL	B-Method
)	O
.	O
	
We	O
expect	O
the	O
performance	O
advantage	O
to	O
be	O
much	O
more	O
pronounced	O
for	O
data	O
sets	O
with	O
a	O
large	O
number	O
of	O
graphs	O
.	O
	
Results	O
for	O
betweeness	B-Task
centrality	I-Task
normalization	I-Task
are	O
similar	O
with	O
the	O
exception	O
of	O
the	O
runtime	B-Metric
which	O
increases	O
by	O
about	O
%	O
.	O
	
Logistic	B-Method
regression	I-Method
applied	O
to	O
Patchy	B-Method
-	I-Method
san	I-Method
’s	I-Method
receptive	I-Method
fields	I-Method
performs	O
worse	O
,	O
indicating	O
that	O
Patchy	B-Method
-	I-Method
san	I-Method
works	O
especially	O
well	O
in	O
conjunction	O
with	O
CNNs	B-Method
which	O
learn	O
non	O
-	O
linear	O
feature	O
combinations	O
and	O
which	O
share	O
weights	O
across	O
receptive	O
fields	O
.	O
	
Patchy	B-Method
-	I-Method
san	I-Method
is	O
also	O
highly	O
competitive	O
on	O
the	O
social	B-Material
graph	I-Material
data	I-Material
.	O
	
It	O
significantly	O
outperforms	O
the	O
other	O
two	O
kernels	O
on	O
four	O
of	O
the	O
six	O
data	O
sets	O
and	O
achieves	O
ties	O
on	O
the	O
rest	O
.	O
	
Table	O
[	O
reference	O
]	O
lists	O
the	O
results	O
of	O
the	O
experiments	O
.	O
	
section	O
:	O
Conclusion	O
and	O
Future	O
Work	O
	
We	O
proposed	O
a	O
framework	O
for	O
learning	B-Task
graph	I-Task
representations	I-Task
that	O
are	O
especially	O
beneficial	O
in	O
conjunction	O
with	O
CNNs	B-Method
.	O
	
It	O
combines	O
two	O
complementary	O
procedures	O
:	O
(	O
a	O
)	O
selecting	O
a	O
sequence	O
of	O
nodes	O
that	O
covers	O
large	O
parts	O
of	O
the	O
graph	O
and	O
(	O
b	O
)	O
generating	O
local	B-Method
normalized	I-Method
neighborhood	I-Method
representations	I-Method
for	O
each	O
of	O
the	O
nodes	O
in	O
the	O
sequence	O
.	O
	
Experiments	O
show	O
that	O
the	O
approach	O
is	O
competitive	O
with	O
state	O
of	O
the	O
art	O
graph	B-Method
kernels	I-Method
.	O
	
Directions	O
for	O
future	O
work	O
include	O
the	O
use	O
of	O
alternative	O
neural	B-Method
network	I-Method
architectures	I-Method
such	O
as	O
RNNs	B-Method
;	O
combining	O
different	O
receptive	O
field	O
sizes	O
;	O
pretraining	B-Method
with	O
RBMs	B-Method
and	O
autoencoders	B-Method
;	O
and	O
statistical	B-Method
relational	I-Method
models	I-Method
based	O
on	O
the	O
ideas	O
of	O
the	O
approach	O
.	O
	
section	O
:	O
Acknowledgments	O
	
Many	O
thanks	O
to	O
the	O
anonymous	O
ICML	O
reviewers	O
who	O
provided	O
tremendously	O
helpful	O
comments	O
.	O
	
The	O
research	O
leading	O
to	O
these	O
results	O
has	O
received	O
funding	O
from	O
the	O
European	O
Union	O
’s	O
Horizon	O
2020	O
innovation	O
action	O
program	O
under	O
grant	O
agreement	O
	
No	O
653449	O
-	O
TYPES	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Semantic	B-Task
Instance	I-Task
Segmentation	I-Task
with	O
a	O
Discriminative	B-Method
Loss	I-Method
Function	I-Method
	
Semantic	B-Task
instance	I-Task
segmentation	I-Task
remains	O
a	O
challenging	O
task	O
.	O
	
In	O
this	O
work	O
we	O
propose	O
to	O
tackle	O
the	O
problem	O
with	O
a	O
discriminative	O
loss	B-Method
function	I-Method
,	O
operating	O
at	O
the	O
pixel	O
level	O
,	O
that	O
encourages	O
a	O
convolutional	B-Method
network	I-Method
to	O
produce	O
a	O
representation	O
of	O
the	O
image	O
that	O
can	O
easily	O
be	O
clustered	O
into	O
instances	O
with	O
a	O
simple	O
post	B-Method
-	I-Method
processing	I-Method
step	I-Method
.	O
	
The	O
loss	B-Method
function	I-Method
encourages	O
the	O
network	O
to	O
map	O
each	O
pixel	O
to	O
a	O
point	O
in	O
feature	O
space	O
so	O
that	O
pixels	O
belonging	O
to	O
the	O
same	O
instance	O
lie	O
close	O
together	O
while	O
different	O
instances	O
are	O
separated	O
by	O
a	O
wide	O
margin	O
.	O
	
Our	O
approach	O
of	O
combining	O
an	O
off	B-Method
-	I-Method
the	I-Method
-	I-Method
shelf	I-Method
network	I-Method
with	O
a	O
principled	B-Method
loss	I-Method
function	I-Method
inspired	O
by	O
a	O
metric	B-Method
learning	I-Method
objective	I-Method
is	O
conceptually	O
simple	O
and	O
distinct	O
from	O
recent	O
efforts	O
in	O
instance	B-Task
segmentation	I-Task
.	O
	
In	O
contrast	O
to	O
previous	O
works	O
,	O
our	O
method	O
does	O
not	O
rely	O
on	O
object	B-Method
proposals	I-Method
or	O
recurrent	B-Method
mechanisms	I-Method
.	O
	
A	O
key	O
contribution	O
of	O
our	O
work	O
is	O
to	O
demonstrate	O
that	O
such	O
a	O
simple	O
setup	O
without	O
bells	O
and	O
whistles	O
is	O
effective	O
and	O
can	O
perform	O
on	O
-	O
par	O
with	O
more	O
complex	O
methods	O
.	O
	
Moreover	O
,	O
we	O
show	O
that	O
it	O
does	O
not	O
suffer	O
from	O
some	O
of	O
the	O
limitations	O
of	O
the	O
popular	O
detect	B-Method
-	I-Method
and	I-Method
-	I-Method
segment	I-Method
approaches	I-Method
.	O
	
We	O
achieve	O
competitive	O
performance	O
on	O
the	O
Cityscapes	B-Material
and	O
CVPPP	B-Material
leaf	I-Material
segmentation	I-Material
benchmarks	I-Material
.	O
	
section	O
:	O
Introduction	O
	
Semantic	B-Task
instance	I-Task
segmentation	I-Task
has	O
recently	O
gained	O
in	O
popularity	O
.	O
	
As	O
an	O
extension	O
of	O
regular	B-Task
semantic	I-Task
segmentation	I-Task
,	O
the	O
task	O
is	O
to	O
generate	O
a	O
binary	O
segmentation	O
mask	O
for	O
each	O
individual	O
object	O
along	O
with	O
a	O
semantic	O
label	O
.	O
	
It	O
is	O
considered	O
a	O
fundamentally	O
harder	O
problem	O
than	O
semantic	B-Task
segmentation	I-Task
-	O
where	O
overlapping	O
objects	O
of	O
the	O
same	O
class	O
are	O
segmented	O
as	O
one	O
-	O
and	O
is	O
closely	O
related	O
to	O
the	O
tasks	O
of	O
object	B-Task
counting	I-Task
and	O
object	B-Task
detection	I-Task
.	O
	
One	O
could	O
also	O
say	O
instance	B-Task
segmentation	I-Task
is	O
a	O
generalization	B-Task
of	I-Task
object	I-Task
detection	I-Task
,	O
with	O
the	O
goal	O
of	O
producing	O
a	O
segmentation	O
mask	O
rather	O
than	O
a	O
bounding	O
box	O
for	O
each	O
object	O
.	O
	
Pinheiro	O
obtain	O
bounding	O
boxes	O
from	O
instance	B-Method
segmentations	I-Method
by	O
simply	O
drawing	O
the	O
tightest	O
bounding	O
box	O
around	O
each	O
segmentation	O
mask	O
,	O
and	O
show	O
that	O
their	O
system	O
reaches	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
an	O
object	B-Task
detection	I-Task
benchmark	O
.	O
	
The	O
relation	O
between	O
instance	B-Task
segmentation	I-Task
and	O
semantic	B-Task
segmentation	I-Task
is	O
less	O
clear	O
.	O
	
Intuitively	O
,	O
the	O
two	O
tasks	O
feel	O
very	O
closely	O
related	O
,	O
but	O
it	O
turns	O
out	O
not	O
to	O
be	O
obvious	O
how	O
to	O
apply	O
the	O
network	B-Method
architectures	I-Method
and	O
loss	B-Method
functions	I-Method
that	O
are	O
successful	O
in	O
semantic	B-Task
segmentation	I-Task
to	O
this	O
related	O
instance	B-Task
task	I-Task
.	O
	
One	O
key	O
factor	O
that	O
complicates	O
the	O
naive	O
application	O
of	O
the	O
popular	O
softmax	O
cross	O
-	O
entropy	O
loss	B-Method
function	I-Method
to	O
instance	B-Task
segmentation	I-Task
,	O
is	O
the	O
fact	O
that	O
an	O
image	O
can	O
contain	O
an	O
arbitrary	O
number	O
of	O
instances	O
and	O
that	O
the	O
labeling	O
is	O
permutation	O
-	O
invariant	O
:	O
it	O
does	O
not	O
matter	O
which	O
specific	O
label	O
an	O
instance	O
gets	O
,	O
as	O
long	O
as	O
it	O
is	O
different	O
from	O
all	O
other	O
instance	O
labels	O
.	O
	
One	O
possible	O
solution	O
is	O
to	O
set	O
an	O
upper	O
limit	O
to	O
the	O
number	O
of	O
detectable	O
instances	O
and	O
to	O
impose	O
extra	O
constraints	O
on	O
the	O
labeling	O
,	O
but	O
this	O
may	O
unnecessarily	O
limit	O
the	O
representational	O
power	O
of	O
the	O
network	O
and	O
introduce	O
unwanted	O
biases	O
,	O
leading	O
to	O
unsatisfying	O
results	O
.	O
	
Most	O
recent	O
works	O
on	O
instance	B-Task
segmentation	I-Task
with	O
deep	B-Method
networks	I-Method
go	O
a	O
different	O
route	O
.	O
	
Two	O
popular	O
approaches	O
introduce	O
a	O
multi	B-Method
-	I-Method
stage	I-Method
pipeline	I-Method
with	O
object	B-Method
proposals	I-Method
,	O
or	O
train	O
a	O
recurrent	B-Method
network	I-Method
end	O
-	O
to	O
-	O
end	O
with	O
a	O
custom	O
loss	B-Method
function	I-Method
that	O
outputs	O
instances	O
sequentially	O
.	O
	
Another	O
line	O
of	O
research	O
is	O
to	O
train	O
a	O
network	O
to	O
transform	O
the	O
image	O
into	O
a	O
representation	O
that	O
is	O
clustered	O
into	O
individual	O
instances	O
with	O
a	O
post	B-Method
-	I-Method
processing	I-Method
step	I-Method
.	O
	
Our	O
method	O
belongs	O
to	O
this	O
last	O
category	O
,	O
but	O
takes	O
a	O
more	O
principled	O
(	O
less	O
ad	O
-	O
hoc	O
)	O
approach	O
than	O
previous	O
works	O
and	O
reduces	O
the	O
post	B-Task
-	I-Task
processing	I-Task
step	I-Task
to	O
a	O
minimum	O
.	O
	
Inspired	O
by	O
the	O
success	O
of	O
siamese	B-Method
networks	I-Method
and	O
the	O
triplet	B-Method
loss	I-Method
in	O
image	B-Task
classification	I-Task
,	O
we	O
introduce	O
a	O
discriminative	O
loss	B-Method
function	I-Method
to	O
replace	O
the	O
pixel	B-Method
-	I-Method
wise	I-Method
softmax	I-Method
loss	I-Method
that	O
is	O
commonly	O
used	O
in	O
semantic	B-Task
segmentation	I-Task
.	O
	
Our	O
loss	B-Method
function	I-Method
enforces	O
the	O
network	O
to	O
map	O
each	O
pixel	O
in	O
the	O
image	O
to	O
an	O
n	O
-	O
dimensional	O
vector	O
in	O
feature	O
space	O
,	O
such	O
that	O
feature	O
vectors	O
of	O
pixels	O
that	O
belong	O
to	O
the	O
same	O
instance	O
lie	O
close	O
together	O
while	O
feature	O
vectors	O
of	O
pixels	O
that	O
belong	O
to	O
different	O
instances	O
lie	O
far	O
apart	O
.	O
	
The	O
output	O
of	O
the	O
network	O
can	O
easily	O
be	O
clustered	O
with	O
a	O
fast	O
and	O
simple	O
post	B-Method
-	I-Method
processing	I-Method
operation	I-Method
.	O
	
With	O
this	O
mechanism	O
,	O
we	O
optimize	O
an	O
objective	O
that	O
avoids	O
the	O
aforementioned	O
problems	O
related	O
to	O
variable	O
number	O
of	O
instances	O
and	O
permutation	O
-	O
invariance	O
.	O
	
Our	O
work	O
mainly	O
focuses	O
on	O
the	O
loss	B-Method
function	I-Method
,	O
as	O
we	O
aim	O
to	O
be	O
able	O
to	O
re	O
-	O
use	O
network	B-Method
architectures	I-Method
that	O
were	O
designed	O
for	O
semantic	B-Task
segmentation	I-Task
:	O
we	O
plug	O
in	O
an	O
off	O
-	O
the	O
-	O
shelf	B-Method
architecture	I-Method
and	O
retrain	O
the	O
system	O
with	O
our	O
discriminative	O
loss	B-Method
function	I-Method
.	O
	
In	O
our	O
framework	O
,	O
the	O
tasks	O
of	O
semantic	B-Task
and	I-Task
instance	I-Task
segmentation	I-Task
can	O
be	O
treated	O
in	O
a	O
consistent	O
and	O
similar	O
manner	O
and	O
do	O
not	O
require	O
changes	O
on	O
the	O
architecture	O
side	O
.	O
	
The	O
rest	O
of	O
this	O
paper	O
is	O
structured	O
as	O
follows	O
.	O
	
First	O
we	O
give	O
an	O
extensive	O
overview	O
of	O
the	O
related	O
work	O
in	O
section	O
[	O
reference	O
]	O
.	O
	
In	O
section	O
[	O
reference	O
]	O
we	O
discuss	O
our	O
proposed	O
method	O
in	O
detail	O
.	O
	
In	O
section	O
[	O
reference	O
]	O
we	O
set	O
up	O
experiments	O
on	O
two	O
instance	B-Task
segmentation	I-Task
benchmarks	I-Task
and	O
show	O
that	O
we	O
get	O
a	O
performance	O
that	O
is	O
competitive	O
with	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
.	O
	
section	O
:	O
Related	O
Work	O
	
In	O
the	O
last	O
few	O
years	O
,	O
deep	B-Method
networks	I-Method
have	O
achieved	O
impressive	O
results	O
in	O
semantic	B-Task
and	I-Task
instance	I-Task
segmentation	I-Task
.	O
	
All	O
top	O
-	O
performing	O
methods	O
across	O
different	O
benchmarks	O
use	O
a	O
deep	B-Method
network	I-Method
in	O
their	O
pipeline	O
.	O
	
Here	O
we	O
discuss	O
these	O
prior	O
works	O
and	O
situate	O
our	O
model	O
between	O
them	O
.	O
	
Proposal	B-Method
-	I-Method
based	I-Method
Many	I-Method
instance	I-Method
segmentation	I-Method
approaches	I-Method
build	O
a	O
multi	B-Method
-	I-Method
stage	I-Method
pipeline	I-Method
with	O
a	O
separate	O
object	B-Method
proposal	I-Method
and	O
classification	B-Method
step	I-Method
.	O
	
Hariharan	O
and	O
Chen	O
use	O
MCG	B-Method
to	O
generate	O
category	B-Task
-	I-Task
independent	I-Task
region	I-Task
proposals	I-Task
,	O
followed	O
by	O
a	O
classification	B-Method
step	I-Method
.	O
	
Pinheiro	O
use	O
the	O
same	O
general	O
approach	O
,	O
but	O
their	O
work	O
focuses	O
on	O
generating	B-Task
segmentation	I-Task
proposals	I-Task
with	O
a	O
deep	B-Method
network	I-Method
.	O
	
Dai	O
won	O
the	O
2015	O
MS	B-Task
-	I-Task
COCO	I-Task
instance	I-Task
segmentation	I-Task
challenge	I-Task
with	O
a	O
cascade	B-Method
of	I-Method
networks	I-Method
(	O
MNC	B-Method
)	O
to	O
merge	O
bounding	O
boxes	O
,	O
segmentation	O
masks	O
and	O
category	O
information	O
.	O
	
Many	O
works	O
were	O
inspired	O
by	O
this	O
approach	O
and	O
also	O
combine	O
an	O
object	B-Method
detector	I-Method
with	O
a	O
semantic	B-Method
segmentation	I-Method
network	I-Method
to	O
produce	O
instances	O
.	O
	
In	O
contrast	O
to	O
these	O
works	O
,	O
our	O
method	O
does	O
not	O
rely	O
on	O
object	O
proposals	O
or	O
bounding	B-Method
boxes	I-Method
but	O
treats	O
the	O
image	O
holistically	O
,	O
which	O
we	O
show	O
to	O
be	O
beneficial	O
for	O
handling	O
certain	O
tasks	O
with	O
complex	O
occlusions	O
as	O
discussed	O
in	O
section	O
[	O
reference	O
]	O
.	O
	
Recurrent	B-Method
methods	I-Method
	
Other	O
recent	O
works	O
employ	O
recurrent	B-Method
networks	I-Method
to	O
generate	O
the	O
individual	O
instances	O
sequentially	O
.	O
	
Stewart	O
train	O
a	O
network	O
for	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
object	I-Task
detection	I-Task
using	O
an	O
LSTM	B-Method
.	O
	
Their	O
loss	B-Method
function	I-Method
is	O
permutation	O
-	O
invariant	O
as	O
it	O
incorporates	O
the	O
Hungarian	B-Method
algorithm	I-Method
to	O
match	O
candidate	O
hypotheses	O
to	O
ground	O
-	O
truth	O
instances	O
.	O
	
Inspired	O
by	O
their	O
work	O
,	O
Romera	O
propose	O
an	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
recurrent	I-Method
network	I-Method
with	O
convolutional	B-Method
LSTMs	I-Method
that	O
sequentially	O
outputs	O
binary	O
segmentation	O
maps	O
for	O
each	O
instance	O
.	O
	
Ren	O
improve	O
upon	O
by	O
adding	O
a	O
box	B-Method
network	I-Method
to	O
confine	O
segmentations	O
within	O
a	O
local	O
window	O
and	O
skip	O
connections	O
instead	O
of	O
graphical	B-Method
models	I-Method
to	O
restore	O
the	O
resolution	O
at	O
the	O
output	O
.	O
	
Their	O
final	O
framework	O
consists	O
of	O
four	O
major	O
components	O
:	O
an	O
external	B-Method
memory	I-Method
and	I-Method
networks	I-Method
for	O
box	B-Task
proposal	I-Task
,	O
segmentation	B-Task
and	O
scoring	B-Task
.	O
	
We	O
argue	O
that	O
our	O
proposed	O
method	O
is	O
conceptually	O
simpler	O
and	O
easier	O
to	O
implement	O
than	O
these	O
methods	O
.	O
	
Our	O
method	O
does	O
not	O
involve	O
recurrent	B-Method
mechanisms	I-Method
and	O
can	O
work	O
with	O
any	O
off	B-Method
-	I-Method
the	I-Method
-	I-Method
shelf	I-Method
segmentation	I-Method
architecture	I-Method
.	O
	
Moreover	O
,	O
our	O
loss	B-Method
function	I-Method
is	O
permutation	O
-	O
invariant	O
by	O
design	O
,	O
without	O
the	O
need	O
to	O
resort	O
to	O
a	O
Hungarian	B-Method
algorithm	I-Method
.	O
	
Clustering	B-Method
Another	O
approach	O
is	O
to	O
transform	O
the	O
image	O
into	O
a	O
representation	O
that	O
is	O
subsequently	O
clustered	O
into	O
discrete	O
instances	O
.	O
	
Silberman	B-Method
produce	O
a	O
segmentation	B-Method
tree	I-Method
and	O
use	O
a	O
coverage	O
loss	O
to	O
cut	O
it	O
into	O
non	O
-	O
overlapping	O
regions	O
.	O
	
Zhang	O
impose	O
an	O
ordering	O
on	O
the	O
individual	O
instances	O
based	O
on	O
their	O
depth	O
,	O
and	O
use	O
a	O
MRF	B-Method
to	O
merge	O
overlapping	O
predicted	O
patches	O
into	O
a	O
coherent	B-Method
segmentation	I-Method
.	O
	
Two	O
earlier	O
works	O
also	O
use	O
depth	O
information	O
to	O
segment	O
instances	O
.	O
	
Uhrig	B-Method
train	O
a	O
network	O
to	O
predict	O
each	O
pixel	O
’s	O
direction	O
towards	O
its	O
instance	O
center	O
,	O
along	O
with	O
monocular	O
depth	O
and	O
semantic	O
labels	O
.	O
	
They	O
use	O
template	B-Method
matching	I-Method
and	O
proposal	B-Method
fusion	I-Method
techniques	I-Method
to	O
extract	O
the	O
individual	O
instances	O
from	O
this	O
representation	O
.	O
	
Liang	O
predict	O
pixel	O
-	O
wise	O
feature	O
vectors	O
representing	O
the	O
ground	O
truth	O
bounding	O
box	O
of	O
the	O
instance	O
it	O
belongs	O
to	O
.	O
	
With	O
the	O
help	O
of	O
a	O
sub	B-Method
-	I-Method
network	I-Method
that	O
predicts	O
an	O
object	O
count	O
,	O
they	O
cluster	O
the	O
output	O
of	O
the	O
network	O
into	O
individual	O
instances	O
.	O
	
Our	O
work	O
is	O
similar	O
to	O
these	O
works	O
in	O
that	O
we	O
have	O
a	O
separate	O
clustering	B-Method
step	I-Method
,	O
but	O
our	O
loss	O
does	O
not	O
constrain	O
the	O
output	O
of	O
the	O
network	O
to	O
a	O
specific	O
representation	O
like	O
instance	O
center	O
coordinates	O
or	O
depth	O
ordering	O
;	O
it	O
is	O
less	O
ad	O
-	O
hoc	O
in	O
that	O
sense	O
.	O
	
Other	O
Bai	O
use	O
deep	B-Method
networks	I-Method
to	O
directly	O
learn	O
the	O
energy	O
of	O
the	O
watershed	O
transform	O
.	O
	
A	O
drawback	O
of	O
this	O
bottom	B-Method
-	I-Method
up	I-Method
approach	I-Method
is	O
that	O
they	O
can	O
not	O
handle	O
occlusions	O
where	O
instances	O
are	O
separated	O
into	O
multiple	O
pieces	O
.	O
	
Kirillov	O
use	O
a	O
CRF	B-Method
,	O
but	O
with	O
a	O
novel	O
MultiCut	B-Method
formulation	I-Method
to	O
combine	O
semantic	B-Method
segmentations	I-Method
with	O
edge	O
maps	O
to	O
extract	O
instances	O
as	O
connected	O
regions	O
.	O
	
A	O
shortcoming	O
of	O
this	O
method	O
is	O
that	O
,	O
although	O
they	O
reason	O
globally	O
about	O
instances	O
,	O
they	O
also	O
can	O
not	O
handle	O
occlusions	O
.	O
	
Arnab	B-Method
combine	O
an	O
object	B-Method
detector	I-Method
with	O
a	O
semantic	B-Method
segmentation	I-Method
module	I-Method
using	O
a	O
CRF	B-Method
model	I-Method
.	O
	
By	O
considering	O
the	O
image	O
holistically	O
it	O
can	O
handle	O
occlusions	O
and	O
produce	O
more	O
precise	O
segmentations	B-Task
.	O
	
Loss	O
function	O
	
Our	O
loss	B-Method
function	I-Method
is	O
inspired	O
by	O
earlier	O
works	O
on	O
distance	B-Task
metric	I-Task
learning	I-Task
,	O
discriminative	O
loss	B-Method
functions	I-Method
and	O
siamese	B-Method
networks	I-Method
.	O
	
Most	O
similar	O
to	O
our	O
loss	B-Method
function	I-Method
,	O
Weinberger	O
propose	O
to	O
learn	O
a	O
distance	B-Method
metric	I-Method
for	O
large	B-Task
margin	I-Task
nearest	I-Task
neighbor	I-Task
classification	I-Task
.	O
	
Kostinger	O
further	O
explore	O
a	O
similar	O
LDA	B-Method
based	I-Method
objective	I-Method
.	O
	
More	O
recently	O
Schroff	O
,	O
building	O
on	O
Sun	O
,	O
introduced	O
the	O
triplet	B-Method
loss	I-Method
for	O
face	B-Task
recognition	I-Task
.	O
	
The	O
triplet	O
loss	O
enforces	O
a	O
margin	O
between	O
each	O
pair	O
of	O
faces	O
from	O
one	O
person	O
,	O
to	O
all	O
other	O
faces	O
.	O
	
Xie	O
propose	O
a	O
clustering	B-Method
objective	I-Method
for	O
unsupervised	B-Task
learning	I-Task
.	O
	
Whereas	O
these	O
works	O
employ	O
a	O
discriminative	O
loss	B-Method
function	I-Method
to	O
optimize	O
distances	O
between	O
images	O
in	O
a	O
dataset	O
,	O
our	O
method	O
operates	O
at	O
the	O
pixel	O
level	O
,	O
optimizing	O
distances	O
between	O
individual	O
pixels	O
in	O
an	O
image	O
.	O
	
To	O
our	O
knowledge	O
,	O
we	O
are	O
the	O
first	O
to	O
successfully	O
use	O
a	O
discriminative	B-Method
loss	I-Method
based	O
on	O
distance	B-Method
metric	I-Method
learning	I-Method
principles	I-Method
for	O
the	O
task	O
of	O
instance	B-Task
segmentation	I-Task
with	O
deep	B-Method
networks	I-Method
.	O
	
section	O
:	O
Method	O
	
subsection	O
:	O
Discriminative	O
loss	B-Method
function	I-Method
	
Consider	O
a	O
differentiable	B-Method
function	I-Method
that	O
maps	O
each	O
pixel	O
in	O
an	O
input	O
image	O
to	O
a	O
point	O
in	O
n	O
-	O
dimensional	O
feature	O
space	O
,	O
referred	O
to	O
as	O
the	O
pixel	B-Method
embedding	I-Method
.	O
	
The	O
intuition	O
behind	O
our	O
loss	B-Method
function	I-Method
is	O
that	O
embeddings	O
with	O
the	O
same	O
label	O
(	O
same	O
instance	O
)	O
should	O
end	O
up	O
close	O
together	O
,	O
while	O
embeddings	O
with	O
a	O
different	O
label	O
(	O
different	O
instance	O
)	O
should	O
end	O
up	O
far	O
apart	O
.	O
	
Weinberger	O
propose	O
a	O
loss	B-Method
function	I-Method
with	O
two	O
competing	O
terms	O
to	O
achieve	O
this	O
objective	O
:	O
a	O
term	O
to	O
penalize	O
large	O
distances	O
between	O
embeddings	O
with	O
the	O
same	O
label	O
,	O
and	O
a	O
term	O
to	O
penalize	O
small	O
distances	O
between	O
embeddings	O
with	O
a	O
different	O
label	O
.	O
	
In	O
our	O
loss	B-Method
function	I-Method
we	O
keep	O
the	O
first	O
term	O
,	O
but	O
replace	O
the	O
second	O
term	O
with	O
a	O
more	O
tractable	O
one	O
:	O
instead	O
of	O
directly	O
penalizing	O
small	O
distances	O
between	O
every	O
pair	O
of	O
differently	O
-	O
labeled	O
embeddings	O
,	O
we	O
only	O
penalize	O
small	O
distances	O
between	O
the	O
mean	O
embeddings	O
of	O
different	O
labels	O
.	O
	
If	O
the	O
number	O
of	O
different	O
labels	O
is	O
smaller	O
than	O
the	O
number	O
of	O
inputs	O
,	O
this	O
is	O
computationally	O
much	O
cheaper	O
than	O
calculating	O
the	O
distances	O
between	O
every	O
pair	O
of	O
embeddings	O
.	O
	
This	O
is	O
a	O
valid	O
assumption	O
for	O
instance	B-Task
segmentation	I-Task
,	O
where	O
there	O
are	O
orders	O
of	O
magnitude	O
fewer	O
instances	O
than	O
pixels	O
in	O
an	O
image	O
.	O
	
We	O
now	O
formulate	O
our	O
discriminative	O
loss	O
in	O
terms	O
of	O
push	O
(	O
i.e.	O
repelling	O
)	O
and	O
pull	O
forces	O
between	O
and	O
within	O
clusters	O
.	O
	
A	O
cluster	O
is	O
defined	O
as	O
a	O
group	O
of	O
pixel	O
embeddings	O
sharing	O
the	O
same	O
label	O
,	O
e.g.	O
pixels	O
belonging	O
to	O
the	O
same	O
instance	O
.	O
	
Our	O
loss	O
consists	O
of	O
three	O
terms	O
:	O
variance	B-Metric
term	O
:	O
an	O
intra	O
-	O
cluster	O
pull	O
-	O
force	O
that	O
draws	O
embeddings	O
towards	O
the	O
mean	O
embedding	O
,	O
i.e.	O
the	O
cluster	O
center	O
.	O
	
distance	B-Method
term	I-Method
:	O
an	O
inter	O
-	O
cluster	O
push	O
-	O
force	O
that	O
pushes	O
clusters	O
away	O
from	O
each	O
other	O
,	O
increasing	O
the	O
distance	O
between	O
the	O
cluster	O
centers	O
.	O
	
regularization	B-Method
term	I-Method
:	O
a	O
small	O
pull	O
-	O
force	O
that	O
draws	O
all	O
clusters	O
towards	O
the	O
origin	O
,	O
to	O
keep	O
the	O
activations	O
bounded	O
.	O
	
The	O
variance	B-Metric
and	O
distance	O
terms	O
are	O
hinged	O
:	O
their	O
forces	O
are	O
only	O
active	O
up	O
to	O
a	O
certain	O
distance	O
.	O
	
Embeddings	O
within	O
a	O
distance	O
of	O
from	O
their	O
cluster	O
centers	O
are	O
no	O
longer	O
attracted	O
to	O
it	O
,	O
which	O
means	O
that	O
they	O
can	O
exist	O
on	O
a	O
local	O
manifold	O
in	O
feature	O
space	O
rather	O
than	O
having	O
to	O
converge	O
to	O
a	O
single	O
point	O
.	O
	
Analogously	O
,	O
cluster	O
centers	O
further	O
apart	O
than	O
are	O
no	O
longer	O
repulsed	O
and	O
can	O
move	O
freely	O
in	O
feature	O
space	O
.	O
	
Hinging	O
the	O
forces	O
relaxes	O
the	O
constraints	O
on	O
the	O
network	O
,	O
giving	O
it	O
more	O
representational	O
power	O
to	O
achieve	O
its	O
goal	O
.	O
	
The	O
interacting	O
forces	O
in	O
feature	O
space	O
are	O
illustrated	O
in	O
figure	O
[	O
reference	O
]	O
.	O
	
The	O
loss	B-Method
function	I-Method
can	O
also	O
be	O
written	O
down	O
exactly	O
.	O
	
We	O
use	O
the	O
following	O
definitions	O
:	O
is	O
the	O
number	O
of	O
clusters	O
in	O
the	O
ground	O
truth	O
,	O
is	O
the	O
number	O
of	O
elements	O
in	O
cluster	O
,	O
is	O
an	O
embedding	O
,	O
is	O
the	O
mean	O
embedding	O
of	O
cluster	O
(	O
the	O
cluster	O
center	O
)	O
,	O
is	O
the	O
L1	O
or	O
L2	O
distance	O
,	O
and	O
denotes	O
the	O
hinge	O
.	O
	
and	O
are	O
respectively	O
the	O
margins	O
for	O
the	O
variance	B-Metric
and	O
distance	B-Metric
loss	I-Metric
.	O
	
The	O
loss	O
can	O
then	O
be	O
written	O
as	O
follows	O
:	O
	
In	O
our	O
experiments	O
we	O
set	O
and	O
.	O
	
The	O
loss	O
is	O
minimized	O
by	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
.	O
	
Comparison	O
with	O
softmax	B-Method
loss	I-Method
	
We	O
discuss	O
the	O
relation	O
of	O
our	O
loss	B-Method
function	I-Method
with	O
the	O
popular	O
pixel	B-Method
-	I-Method
wise	I-Method
multi	I-Method
-	I-Method
class	I-Method
cross	I-Method
-	I-Method
entropy	I-Method
loss	I-Method
,	O
often	O
referred	O
to	O
as	O
the	O
softmax	O
loss	O
.	O
	
In	O
the	O
case	O
of	O
a	O
softmax	B-Task
loss	I-Task
with	O
classes	O
,	O
each	O
pixel	B-Method
embedding	I-Method
is	O
driven	O
to	O
a	O
one	O
-	O
hot	O
vector	O
,	O
i.e.	O
the	O
unit	O
vector	O
on	O
one	O
of	O
the	O
axes	O
of	O
an	O
-	O
dimensional	O
feature	O
space	O
.	O
	
Because	O
the	O
softmax	B-Method
function	I-Method
has	O
the	O
normalizing	O
property	O
that	O
its	O
outputs	O
are	O
positive	O
and	O
sum	O
to	O
one	O
,	O
the	O
embeddings	O
are	O
restricted	O
to	O
lie	O
on	O
the	O
unit	O
simplex	O
.	O
	
When	O
the	O
loss	O
reaches	O
zero	O
,	O
all	O
embeddings	O
lie	O
on	O
one	O
of	O
the	O
unit	O
vectors	O
.	O
	
By	O
design	O
,	O
the	O
dimensions	O
of	O
the	O
output	O
feature	O
space	O
(	O
which	O
correspond	O
to	O
the	O
number	O
of	O
feature	O
maps	O
in	O
the	O
last	O
layer	O
of	O
the	O
network	O
)	O
must	O
be	O
equal	O
to	O
the	O
number	O
of	O
classes	O
.	O
	
To	O
add	O
a	O
class	O
after	O
training	O
,	O
the	O
architecture	O
needs	O
to	O
be	O
updated	O
too	O
.	O
	
In	O
comparison	O
,	O
our	O
loss	B-Method
function	I-Method
does	O
not	O
drive	O
the	O
embeddings	O
to	O
a	O
specific	O
point	O
in	O
feature	O
space	O
.	O
	
The	O
network	O
could	O
for	O
example	O
place	O
similar	O
clusters	O
(	O
e.g.	O
two	O
small	O
objects	O
)	O
closer	O
together	O
than	O
dissimilar	O
ones	O
(	O
e.g.	O
a	O
small	O
and	O
a	O
large	O
object	O
)	O
.	O
	
When	O
the	O
loss	O
reaches	O
zero	O
,	O
the	O
system	O
of	O
push	O
and	O
pull	O
forces	O
has	O
minimal	O
energy	O
and	O
the	O
clusters	O
have	O
organized	O
themselves	O
in	O
n	O
-	O
dimensional	O
space	O
.	O
	
Most	O
importantly	O
,	O
the	O
dimensionality	O
of	O
the	O
feature	O
space	O
is	O
independent	O
of	O
the	O
number	O
of	O
instances	O
that	O
needs	O
to	O
be	O
segmented	O
.	O
	
Figure	O
[	O
reference	O
]	O
depicts	O
the	O
convergence	O
of	O
our	O
loss	B-Method
function	I-Method
when	O
overfitting	O
on	O
a	O
single	O
image	O
with	O
instances	O
,	O
in	O
a	O
2	O
-	O
dimensional	O
feature	O
space	O
.	O
	
subsection	O
:	O
Post	B-Task
-	I-Task
processing	I-Task
	
When	O
the	O
variance	B-Metric
and	O
distance	O
terms	O
of	O
the	O
loss	O
are	O
zero	O
,	O
the	O
following	O
is	O
true	O
:	O
all	O
embeddings	O
are	O
within	O
a	O
distance	O
of	O
from	O
their	O
cluster	O
center	O
all	O
cluster	O
centers	O
are	O
at	O
least	O
apart	O
	
If	O
,	O
then	O
each	O
embedding	O
is	O
closer	O
to	O
its	O
own	O
cluster	O
center	O
than	O
to	O
any	O
other	O
cluster	O
center	O
.	O
	
It	O
follows	O
that	O
during	O
inference	B-Task
,	O
we	O
can	O
threshold	O
with	O
a	O
bandwidth	O
around	O
a	O
cluster	O
center	O
to	O
select	O
all	O
embeddings	O
belonging	O
to	O
that	O
cluster	O
.	O
	
Thresholding	B-Task
in	O
this	O
case	O
means	O
selecting	O
all	O
embeddings	O
that	O
lie	O
within	O
a	O
hypersphere	O
with	O
radius	O
around	O
the	O
cluster	O
center	O
:	O
For	O
the	O
tasks	O
of	O
classification	B-Task
and	I-Task
semantic	I-Task
segmentation	I-Task
,	O
with	O
a	O
fixed	O
set	O
of	O
classes	O
,	O
this	O
leads	O
to	O
a	O
simple	O
strategy	O
for	O
post	B-Task
-	I-Task
processing	I-Task
the	O
output	O
of	O
the	O
network	O
into	O
discrete	O
classes	O
:	O
after	O
training	O
,	O
calculate	O
the	O
cluster	O
centers	O
of	O
each	O
class	O
over	O
the	O
entire	O
training	O
set	O
.	O
	
During	O
inference	B-Task
,	O
threshold	O
around	O
each	O
of	O
the	O
cluster	O
centers	O
to	O
select	O
all	O
pixels	O
belonging	O
to	O
the	O
corresponding	O
semantic	O
class	O
.	O
	
This	O
requires	O
that	O
the	O
cluster	O
centers	O
of	O
a	O
specific	O
class	O
are	O
the	O
same	O
in	O
each	O
image	O
,	O
which	O
can	O
be	O
accomplished	O
by	O
coupling	O
the	O
cluster	B-Method
centers	I-Method
across	O
a	O
mini	O
-	O
batch	O
.	O
	
For	O
the	O
task	O
of	O
instance	B-Task
segmentation	I-Task
things	O
are	O
more	O
complicated	O
.	O
	
As	O
the	O
labeling	B-Task
is	O
permutation	O
invariant	O
,	O
we	O
can	O
not	O
simply	O
record	O
cluster	O
centers	O
and	O
threshold	O
around	O
them	O
during	O
inference	B-Task
.	O
	
We	O
could	O
follow	O
a	O
different	O
strategy	O
:	O
if	O
we	O
set	O
,	O
then	O
each	O
embedding	O
is	O
closer	O
to	O
all	O
embeddings	O
of	O
its	O
own	O
cluster	O
than	O
to	O
any	O
embedding	O
of	O
a	O
different	O
cluster	O
.	O
	
It	O
follows	O
that	O
we	O
can	O
threshold	O
around	O
any	O
embedding	O
to	O
select	O
all	O
embeddings	O
belonging	O
to	O
the	O
same	O
cluster	O
.	O
	
The	O
procedure	O
during	O
inference	B-Task
is	O
to	O
select	O
an	O
unlabeled	O
pixel	O
,	O
threshold	O
around	O
its	O
embedding	O
to	O
find	O
all	O
pixels	O
belonging	O
to	O
the	O
same	O
instance	O
,	O
and	O
assign	O
them	O
all	O
the	O
same	O
label	O
.	O
	
Then	O
select	O
another	O
pixel	O
that	O
does	O
not	O
yet	O
belong	O
to	O
an	O
instance	O
and	O
repeat	O
until	O
all	O
pixels	O
are	O
labeled	O
.	O
	
Increasing	B-Task
robustness	I-Task
	
In	O
a	O
real	B-Task
-	I-Task
world	I-Task
problem	I-Task
the	O
loss	O
on	O
the	O
test	O
set	O
will	O
not	O
be	O
zero	O
,	O
potentially	O
causing	O
our	O
clustering	B-Method
algorithm	I-Method
for	O
instance	B-Task
segmentation	I-Task
to	O
make	O
mistakes	O
.	O
	
If	O
a	O
cluster	O
is	O
not	O
compact	O
and	O
we	O
accidentally	O
select	O
an	O
outlier	O
to	O
threshold	O
around	O
,	O
it	O
could	O
happen	O
that	O
a	O
real	O
cluster	O
gets	O
predicted	O
as	O
two	O
sub	O
-	O
clusters	O
.	O
	
To	O
avoid	O
this	O
issue	O
,	O
we	O
make	O
the	O
clustering	B-Method
more	O
robust	O
against	O
outliers	O
by	O
applying	O
a	O
fast	O
variant	O
of	O
the	O
mean	B-Method
-	I-Method
shift	I-Method
algorithm	I-Method
.	O
	
As	O
before	O
,	O
we	O
select	O
a	O
random	O
unlabeled	O
pixel	O
and	O
threshold	O
around	O
its	O
embedding	O
.	O
	
Next	O
however	O
,	O
we	O
calculate	O
the	O
mean	O
of	O
the	O
selected	O
group	O
of	O
embeddings	O
and	O
use	O
the	O
mean	O
to	O
threshold	O
again	O
.	O
	
We	O
repeat	O
this	O
process	O
until	O
mean	O
convergence	O
.	O
	
This	O
has	O
the	O
effect	O
of	O
moving	O
to	O
a	O
high	O
-	O
density	O
area	O
in	O
feature	O
space	O
,	O
likely	O
corresponding	O
to	O
a	O
true	O
cluster	O
center	O
.	O
	
In	O
the	O
experiments	O
section	O
,	O
we	O
investigate	O
the	O
effect	O
of	O
this	O
clustering	B-Method
algorithm	I-Method
by	O
comparing	O
against	O
ground	B-Method
truth	I-Method
clustering	I-Method
,	O
where	O
the	O
thresholding	O
targets	O
are	O
calculated	O
as	O
an	O
average	B-Method
embedding	I-Method
over	O
the	O
ground	O
truth	O
instance	O
labels	O
.	O
	
subsection	O
:	O
Pros	O
and	O
cons	O
	
Our	O
proposed	O
method	O
has	O
some	O
distinctive	O
advantages	O
and	O
disadvantages	O
compared	O
to	O
other	O
methods	O
that	O
we	O
now	O
discuss	O
.	O
	
One	O
big	O
limitation	O
of	O
detect	B-Method
-	I-Method
and	I-Method
-	I-Method
segment	I-Method
approaches	I-Method
that	O
is	O
not	O
immediately	O
apparent	O
from	O
their	O
excellent	O
results	O
on	O
popular	O
benchmarks	O
,	O
is	O
that	O
they	O
rely	O
on	O
the	O
assumption	O
that	O
an	O
object	O
’s	O
segmentation	O
mask	O
can	O
be	O
unambiguously	O
extracted	O
from	O
its	O
bounding	O
box	O
.	O
	
This	O
is	O
an	O
implicit	O
prior	O
that	O
is	O
very	O
effective	O
for	O
datasets	O
like	O
MS	B-Material
COCO	I-Material
and	O
Pascal	B-Material
VOC	I-Material
,	O
which	O
contain	O
relatively	O
blobby	O
objects	O
that	O
do	O
not	O
occlude	O
each	O
other	O
in	O
complex	O
ways	O
.	O
	
However	O
,	O
the	O
assumption	O
is	O
problematic	O
for	O
tasks	O
where	O
an	O
object	O
’s	O
bounding	O
box	O
conveys	O
insufficient	O
information	O
to	O
recover	O
the	O
object	O
’s	O
segmentation	O
mask	O
.	O
	
Consider	O
the	O
synthetic	O
scattered	O
sticks	O
dataset	O
shown	O
in	O
figure	O
[	O
reference	O
]	O
as	O
an	O
example	O
to	O
illustrate	O
the	O
issue	O
.	O
	
When	O
two	O
sticks	O
overlap	O
like	O
two	O
crossed	O
swords	O
,	O
their	O
bounding	O
boxes	O
are	O
highly	O
overlapping	O
.	O
	
Given	O
only	O
a	O
detection	B-Task
in	O
the	O
form	O
of	O
a	O
bounding	O
box	O
,	O
it	O
is	O
exceedingly	O
hard	O
to	O
unambigously	O
extract	O
a	O
segmentation	O
mask	O
of	O
the	O
indicated	O
object	O
.	O
	
Methods	O
that	O
rely	O
on	O
bounding	O
boxes	O
in	O
their	O
pipeline	O
all	O
suffer	O
from	O
this	O
issue	O
.	O
	
In	O
contrast	O
,	O
our	O
method	O
can	O
handle	O
such	O
complex	O
occlusions	O
without	O
problems	O
as	O
it	O
treats	O
the	O
image	O
holistically	O
and	O
learns	O
to	O
reason	O
about	O
occlusions	O
,	O
but	O
does	O
not	O
employ	O
a	O
computationally	O
expensive	O
CRF	B-Method
like	O
.	O
	
Many	O
real	B-Task
-	I-Task
world	I-Task
industrial	I-Task
or	I-Task
medical	I-Task
applications	I-Task
(	O
conveyor	B-Task
belt	I-Task
sorting	I-Task
systems	I-Task
,	O
overlapping	B-Task
cell	I-Task
and	I-Task
chromosome	I-Task
segmentation	I-Task
,	O
etc	O
.	O
)	O
exhibit	O
this	O
kind	O
of	O
occlusions	O
.	O
	
To	O
the	O
best	O
of	O
our	O
knowledge	O
no	O
sufficiently	O
large	O
datasets	O
for	O
such	O
tasks	O
are	O
publicly	O
available	O
,	O
which	O
unfortunately	O
prevents	O
us	O
from	O
showcasing	O
this	O
particular	O
strength	O
of	O
our	O
method	O
to	O
the	O
full	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
our	O
method	O
also	O
has	O
some	O
drawbacks	O
.	O
	
Due	O
to	O
the	O
holistic	O
treatment	O
of	O
the	O
image	O
,	O
our	O
method	O
performs	O
well	O
on	O
datasets	O
with	O
a	O
lot	O
of	O
similarity	O
across	O
the	O
images	O
(	O
traffic	O
scenes	O
in	O
Cityscapes	B-Material
or	O
leaf	O
configurations	O
in	O
CVPPP	B-Material
)	O
,	O
but	O
underperforms	O
on	O
datasets	O
where	O
objects	O
can	O
appear	O
in	O
random	O
constellations	O
and	O
diverse	O
settings	O
,	O
like	O
Pascal	B-Material
VOC	I-Material
and	O
MSCOCO	B-Material
.	O
	
A	O
sliding	O
-	O
window	O
detection	B-Task
-	O
based	O
approach	O
with	O
non	B-Method
-	I-Method
max	I-Method
suppression	I-Method
is	O
more	O
suited	O
for	O
such	O
datasets	O
.	O
	
For	O
example	O
,	O
if	O
our	O
method	O
were	O
trained	O
on	O
images	O
with	O
only	O
one	O
object	O
,	O
it	O
would	O
perform	O
badly	O
on	O
an	O
image	O
that	O
unexpectedly	O
contained	O
many	O
of	O
these	O
objects	O
.	O
	
A	O
detection	B-Task
-	O
based	O
approach	O
has	O
no	O
trouble	O
with	O
this	O
.	O
	
section	O
:	O
Experiments	O
	
We	O
test	O
our	O
loss	B-Method
function	I-Method
on	O
two	O
instance	O
segmentation	O
datasets	O
:	O
The	O
CVPPP	B-Material
Leaf	I-Material
Segmentation	I-Material
dataset	I-Material
and	O
the	O
Cityscapes	B-Material
Instance	O
-	O
Level	O
Semantic	O
Labeling	O
Task	O
.	O
	
These	O
datasets	O
contain	O
a	O
median	O
number	O
of	O
more	O
than	O
15	O
instances	O
per	O
image	O
.	O
	
We	O
also	O
study	O
the	O
influence	O
of	O
the	O
different	O
components	O
of	O
our	O
method	O
and	O
point	O
out	O
where	O
there	O
is	O
room	O
for	O
improvement	O
.	O
	
subsection	O
:	O
Datasets	O
	
The	O
LSC	B-Material
competition	I-Material
of	O
the	O
CVPPP	B-Material
workshop	I-Material
is	O
a	O
small	O
but	O
challenging	O
benchmark	O
.	O
	
The	O
task	O
is	O
to	O
individually	O
segment	O
each	O
leaf	O
of	O
a	O
plant	O
.	O
	
The	O
dataset	O
was	O
developed	O
to	O
encourage	O
the	O
use	O
of	O
computer	B-Method
vision	I-Method
methods	I-Method
to	O
aid	O
in	O
the	O
study	O
of	O
plant	B-Task
phenotyping	I-Task
.	O
	
We	O
use	O
the	O
A1	B-Material
subset	I-Material
which	O
consists	O
of	O
128	O
labeled	O
images	O
and	O
33	O
test	O
images	O
.	O
	
gives	O
an	O
overview	O
of	O
results	O
on	O
this	O
dataset	O
.	O
	
We	O
compare	O
our	O
performance	O
with	O
some	O
of	O
these	O
works	O
and	O
two	O
other	O
recent	O
approaches	O
.	O
	
We	O
report	O
two	O
metrics	O
defined	O
in	O
:	O
Symmetric	B-Metric
Best	I-Metric
Dice	I-Metric
(	I-Metric
)	I-Metric
,	O
which	O
denotes	O
the	O
accuracy	B-Metric
of	O
the	O
instance	B-Method
segmentation	I-Method
and	O
Absolute	B-Metric
Difference	I-Metric
in	I-Metric
Count	I-Metric
(	O
)	O
which	O
is	O
the	O
absolute	O
value	O
of	O
the	O
mean	O
of	O
the	O
difference	O
between	O
the	O
predicted	O
number	O
of	O
leaves	O
and	O
the	O
ground	O
truth	O
over	O
all	O
images	O
.	O
	
The	O
large	O
-	O
scale	O
Cityscapes	B-Material
dataset	O
focuses	O
on	O
semantic	B-Task
understanding	I-Task
of	I-Task
urban	I-Task
street	I-Task
scenes	I-Task
.	O
	
It	O
has	O
a	O
benchmark	O
for	O
pixel	B-Task
-	I-Task
level	I-Task
and	I-Task
instance	I-Task
-	I-Task
level	I-Task
semantic	I-Task
segmentation	I-Task
.	O
	
We	O
test	O
our	O
method	O
on	O
the	O
latter	O
,	O
using	O
only	O
the	O
fine	O
-	O
grained	O
annotations	O
.	O
	
The	O
dataset	O
is	O
split	O
up	O
in	O
2975	O
training	O
images	O
,	O
500	O
validation	O
images	O
,	O
and	O
1525	O
test	O
images	O
.	O
	
We	O
tune	O
hyperparameters	O
using	O
the	O
validation	O
set	O
and	O
only	O
use	O
the	O
train	O
set	O
to	O
train	O
our	O
final	O
model	O
.	O
	
We	O
compare	O
our	O
results	O
with	O
the	O
published	O
works	O
in	O
the	O
official	O
leaderboard	O
.	O
	
We	O
report	O
accuracy	B-Metric
using	O
4	O
metrics	O
defined	O
in	O
:	O
mean	B-Metric
Average	I-Metric
Precision	I-Metric
(	O
AP	B-Metric
)	O
,	O
mean	B-Metric
Average	I-Metric
Precision	I-Metric
with	O
overlap	B-Metric
of	O
50	O
%	O
(	O
AP0.5	O
)	O
,	O
AP50	O
m	O
and	O
AP100	O
m	O
,	O
where	O
evaluation	O
is	O
restricted	O
to	O
objects	O
within	O
50	O
m	O
and	O
100	O
m	O
distance	O
,	O
respectively	O
.	O
	
subsection	O
:	O
Setup	O
	
Model	B-Method
architecture	I-Method
and	O
general	O
setup	O
Since	O
we	O
want	O
to	O
stress	O
the	O
fact	O
that	O
our	O
loss	O
can	O
be	O
used	O
with	O
an	O
off	B-Method
-	I-Method
the	I-Method
-	I-Method
shelf	I-Method
network	I-Method
	
,	O
we	O
use	O
the	O
ResNet	B-Method
-	I-Method
38	I-Method
network	I-Method
,	O
designed	O
for	O
semantic	B-Task
segmentation	I-Task
.	O
	
We	O
finetune	O
from	O
a	O
model	O
that	O
was	O
pre	O
-	O
trained	O
on	O
CityScapes	B-Task
semantic	I-Task
segmentation	I-Task
.	O
	
In	O
the	O
following	O
experiments	O
,	O
all	O
models	O
are	O
trained	O
using	O
Adam	B-Method
,	O
with	O
a	O
learning	B-Metric
rate	I-Metric
of	O
1e	O
-	O
4	O
on	O
a	O
NVidia	O
Titan	O
X	O
GPU	O
.	O
	
Leaf	B-Task
segmentation	I-Task
Since	O
this	O
dataset	O
only	O
consists	O
of	O
128	O
images	O
,	O
we	O
use	O
online	B-Task
data	I-Task
augmentation	I-Task
to	O
prevent	O
the	O
model	O
from	O
overfitting	O
and	O
to	O
increase	O
the	O
overall	O
robustness	B-Metric
.	O
	
We	O
apply	O
random	O
left	O
-	O
right	O
flip	O
,	O
random	O
rotation	O
with	O
and	O
random	B-Method
scale	I-Method
deformation	I-Method
with	O
.	O
	
All	O
images	O
are	O
rescaled	O
to	O
512x512	O
and	O
concatenated	O
with	O
an	O
x	O
-	O
and	O
y	O
-	O
coordinate	O
map	O
with	O
values	O
between	O
-	O
1	O
and	O
1	O
.	O
	
We	O
train	O
the	O
network	O
with	O
margins	O
,	O
,	O
and	O
16	O
output	O
dimensions	O
.	O
	
Foreground	O
masks	O
are	O
included	O
with	O
the	O
test	O
set	O
,	O
since	O
this	O
challenge	O
only	O
focuses	O
on	O
instance	B-Task
segmentation	I-Task
.	O
	
Cityscapes	B-Material
	
Our	O
final	O
model	O
is	O
trained	O
on	O
the	O
training	O
images	O
,	O
downsampled	O
to	O
.	O
	
Because	O
of	O
the	O
size	O
and	O
variability	O
of	O
the	O
dataset	O
,	O
there	O
is	O
no	O
need	O
for	O
extra	O
data	B-Task
augmentation	I-Task
.	O
	
We	O
train	O
the	O
network	O
with	O
margins	O
,	O
,	O
and	O
8	O
output	O
dimensions	O
.	O
	
In	O
contrast	O
to	O
the	O
CVPPP	B-Material
dataset	I-Material
,	O
Cityscapes	B-Material
is	O
a	O
multi	B-Task
-	I-Task
class	I-Task
instance	I-Task
segmentation	I-Task
challenge	I-Task
.	O
	
Therefore	O
,	O
we	O
run	O
our	O
loss	B-Method
function	I-Method
independently	O
on	O
every	O
semantic	O
class	O
,	O
so	O
that	O
instances	O
belonging	O
to	O
the	O
same	O
class	O
are	O
far	O
apart	O
in	O
feature	O
space	O
,	O
whereas	O
instances	O
from	O
different	O
classes	O
can	O
occupy	O
the	O
same	O
space	O
.	O
	
For	O
example	O
,	O
the	O
cluster	O
centers	O
of	O
a	O
pedestrian	O
and	O
a	O
car	O
that	O
appear	O
in	O
the	O
same	O
image	O
are	O
not	O
pushed	O
away	O
from	O
each	O
other	O
.	O
	
We	O
use	O
a	O
pretrained	B-Method
ResNet	I-Method
-	I-Method
38	I-Method
network	I-Method
to	O
generate	O
segmentation	O
masks	O
for	O
the	O
semantic	O
classes	O
.	O
	
subsection	O
:	O
Analysis	O
of	O
the	O
individual	O
components	O
	
The	O
final	O
result	O
of	O
the	O
semantic	B-Task
instance	I-Task
segmentation	I-Task
is	O
influenced	O
by	O
three	O
main	O
components	O
:	O
the	O
performance	O
of	O
the	O
network	B-Method
architecture	I-Method
with	O
our	O
loss	B-Method
function	I-Method
,	O
the	O
quality	O
of	O
the	O
semantic	O
labels	O
,	O
and	O
the	O
post	B-Method
-	I-Method
processing	I-Method
step	I-Method
.	O
	
To	O
disentangle	O
the	O
effects	O
of	O
the	O
semantic	B-Method
segmentation	I-Method
and	O
the	O
post	B-Task
-	I-Task
processing	I-Task
and	O
to	O
point	O
out	O
potential	O
for	O
improvement	O
,	O
we	O
run	O
two	O
extra	O
experiments	O
on	O
the	O
Cityscapes	B-Material
validation	O
set	O
:	O
	
Semantic	B-Task
segmentation	I-Task
vs	O
ground	B-Task
truth	I-Task
For	O
the	O
Cityscapes	B-Material
challenge	O
,	O
we	O
rely	O
on	O
semantic	O
segmentation	O
masks	O
to	O
make	O
a	O
distinction	O
between	O
the	O
different	O
classes	O
.	O
	
Since	O
our	O
instance	B-Method
segmentation	I-Method
will	O
discard	O
regions	O
not	O
indicated	O
in	O
the	O
semantic	O
segmentation	O
labels	O
,	O
the	O
results	O
will	O
be	O
influenced	O
by	O
the	O
quality	O
of	O
the	O
semantic	O
segmentation	O
masks	O
.	O
	
To	O
measure	O
the	O
size	O
of	O
this	O
influence	O
,	O
we	O
also	O
report	O
performance	O
with	O
the	O
ground	O
truth	O
semantic	O
segmentation	O
masks	O
.	O
	
Mean	B-Method
shift	I-Method
clustering	I-Method
vs	O
ground	B-Method
truth	I-Method
clustering	I-Method
Since	O
the	O
output	O
of	O
our	O
network	O
needs	O
to	O
be	O
clustered	O
into	O
discrete	O
instances	O
,	O
the	O
clustering	B-Method
method	I-Method
can	O
potentially	O
influence	O
the	O
accuracy	B-Metric
of	O
the	O
overall	O
instance	B-Task
segmentation	I-Task
.	O
	
In	O
this	O
experiment	O
,	O
we	O
measure	O
this	O
influence	O
by	O
clustering	B-Method
with	O
our	O
adapted	O
mean	B-Method
shift	I-Method
clustering	I-Method
algorithm	I-Method
versus	O
thresholding	B-Method
around	O
the	O
mean	O
embeddings	O
over	O
the	O
ground	O
truth	O
instance	O
masks	O
,	O
as	O
explained	O
in	O
section	O
[	O
reference	O
]	O
)	O
.	O
	
subsection	O
:	O
Results	O
and	O
discussion	O
	
Figure	O
[	O
reference	O
]	O
shows	O
some	O
results	O
of	O
our	O
method	O
on	O
the	O
validation	O
set	O
of	O
the	O
CVPPP	B-Material
dataset	I-Material
.	O
	
The	O
network	O
makes	O
very	O
few	O
mistakes	O
:	O
only	O
the	O
segmentation	O
of	O
the	O
smallest	O
leafs	O
and	O
the	O
leaf	O
stalks	O
sometimes	O
show	O
a	O
small	O
error	O
.	O
	
Table	O
[	O
reference	O
]	O
contains	O
the	O
numerical	O
results	O
.	O
	
We	O
achieve	O
competitive	O
results	O
(	O
SBD	B-Metric
score	I-Metric
of	O
84.2	O
)	O
that	O
are	O
on	O
-	O
par	O
with	O
the	O
state	O
-	O
of	O
-	O
the	O
art	O
(	O
SBD	B-Metric
score	I-Metric
of	O
84.9	O
)	O
.	O
	
We	O
outperform	O
all	O
non	B-Method
-	I-Method
deep	I-Method
learning	I-Method
methods	I-Method
and	O
also	O
the	O
recurrent	B-Method
instance	I-Method
segmentation	I-Method
of	O
,	O
with	O
a	O
method	O
that	O
is	O
arguably	O
less	O
complex	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
some	O
visual	O
results	O
on	O
the	O
Cityscapes	B-Material
validation	O
set	O
.	O
	
We	O
see	O
that	O
even	O
in	O
difficult	O
scenarios	O
,	O
with	O
street	O
scenes	O
containing	O
a	O
lot	O
of	O
cars	O
or	O
pedestrians	O
,	O
our	O
method	O
often	O
manages	O
to	O
identify	O
the	O
individual	O
objects	O
.	O
	
Failure	O
cases	O
mostly	O
involve	O
the	O
splitting	O
up	O
of	O
a	O
single	O
object	O
into	O
multiple	O
instances	O
or	O
incorrect	O
merging	O
of	O
neighboring	O
instances	O
.	O
	
This	O
happens	O
in	O
the	O
lower	O
left	O
example	O
,	O
where	O
the	O
two	O
rightmost	O
cars	O
are	O
merged	O
.	O
	
Another	O
failure	O
mode	O
is	O
incorrect	O
semantic	B-Method
segmentation	I-Method
:	O
in	O
the	O
lower	O
right	O
example	O
,	O
the	O
semantic	B-Method
segmentation	I-Method
network	I-Method
accidentally	O
mistakes	O
an	O
empty	O
bicycle	O
storage	O
for	O
actual	O
bikes	O
.	O
	
The	O
instance	B-Method
segmentation	I-Method
network	I-Method
is	O
left	O
no	O
choice	O
but	O
to	O
give	O
it	O
a	O
shot	O
,	O
and	O
tries	O
to	O
split	O
up	O
the	O
imaginary	O
bikes	O
into	O
individual	O
objects	O
.	O
	
Nevertheless	O
,	O
we	O
achieve	O
competitive	O
results	O
on	O
the	O
Cityscapes	B-Material
leaderboard	O
,	O
outperforming	O
all	O
but	O
one	O
unpublished	O
work	O
.	O
	
Note	O
that	O
we	O
perform	O
on	O
-	O
par	O
with	O
the	O
MNC	B-Method
-	O
based	O
method	O
SAIS	O
on	O
this	O
dataset	O
.	O
	
See	O
table	O
[	O
reference	O
]	O
for	O
a	O
complete	O
overview	O
.	O
	
A	O
video	O
of	O
the	O
results	O
is	O
available	O
at	O
.	O
	
As	O
discussed	O
in	O
section	O
[	O
reference	O
]	O
,	O
we	O
are	O
interested	O
to	O
know	O
the	O
influence	O
of	O
the	O
quality	O
of	O
the	O
semantic	B-Method
segmentations	I-Method
and	O
the	O
clustering	B-Method
algorithm	I-Method
on	O
the	O
overall	O
performance	O
.	O
	
The	O
results	O
of	O
these	O
experiments	O
can	O
be	O
found	O
in	O
table	O
[	O
reference	O
]	O
.	O
	
As	O
expected	O
,	O
the	O
performance	O
increases	O
when	O
we	O
switch	O
out	O
a	O
component	O
with	O
its	O
ground	O
truth	O
counterpart	O
.	O
	
The	O
effect	O
of	O
the	O
semantic	B-Task
segmentation	I-Task
is	O
the	O
largest	O
:	O
comparing	O
the	O
first	O
row	O
(	O
our	O
method	O
)	O
to	O
the	O
third	O
row	O
,	O
we	O
see	O
a	O
large	O
performance	O
increase	O
when	O
replacing	O
the	O
ResNet	O
-	O
38	O
semantic	O
segmentation	O
masks	O
with	O
the	O
ground	O
truth	O
masks	O
.	O
	
This	O
can	O
be	O
explained	O
by	O
the	O
fact	O
that	O
the	O
average	B-Metric
precision	I-Metric
metric	I-Metric
is	O
an	O
average	O
over	O
the	O
semantic	O
classes	O
.	O
	
Some	O
classes	O
like	O
tram	O
,	O
train	O
and	O
bus	O
almost	O
never	O
have	O
more	O
than	O
one	O
instance	O
per	O
image	O
,	O
causing	O
the	O
semantic	B-Task
segmentation	I-Task
to	O
have	O
a	O
big	O
influence	O
on	O
this	O
metric	O
.	O
	
It	O
is	O
clear	O
that	O
the	O
overall	O
performance	O
can	O
be	O
increased	O
by	O
having	O
better	O
semantic	B-Method
segmentations	I-Method
.	O
	
The	O
last	O
two	O
entries	O
of	O
the	O
table	O
show	O
the	O
difference	O
between	O
ground	B-Method
truth	I-Method
clustering	I-Method
and	O
mean	B-Method
shift	I-Method
clustering	I-Method
,	O
both	O
using	O
ground	O
truth	O
segmentation	O
masks	O
.	O
	
Here	O
also	O
,	O
there	O
is	O
a	O
performance	O
gap	O
.	O
	
The	O
main	O
reason	O
is	O
that	O
the	O
loss	O
on	O
the	O
validation	O
set	O
is	O
not	O
zero	O
which	O
means	O
the	O
constraints	O
imposed	O
by	O
the	O
loss	B-Method
function	I-Method
are	O
not	O
met	O
.	O
	
Clustering	B-Method
using	O
mean	B-Method
-	I-Method
shift	I-Method
will	O
therefore	O
not	O
lead	O
to	O
perfect	O
results	O
.	O
	
The	O
effect	O
is	O
more	O
pronounced	O
for	O
small	O
instances	O
,	O
as	O
also	O
noticeable	O
in	O
the	O
shown	O
examples	O
.	O
	
subsection	O
:	O
Speed	O
-	O
accuracy	B-Metric
trade	O
-	O
off	O
	
To	O
investigate	O
the	O
trade	O
-	O
off	O
between	O
speed	B-Metric
,	O
accuracy	B-Metric
and	O
memory	B-Metric
requirements	I-Metric
,	O
we	O
train	O
four	O
different	O
network	B-Method
models	I-Method
on	O
different	O
resolutions	O
and	O
evaluate	O
them	O
on	O
the	O
car	O
class	O
of	O
the	O
Cityscapes	B-Material
validation	O
set	O
.	O
	
This	O
also	O
illustrates	O
the	O
benefit	O
that	O
our	O
method	O
can	O
be	O
used	O
with	O
any	O
off	B-Method
-	I-Method
the	I-Method
-	I-Method
shelf	I-Method
network	I-Method
designed	O
for	O
semantic	B-Task
segmentation	I-Task
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
results	O
.	O
	
We	O
can	O
conclude	O
that	O
Resnet	B-Method
-	I-Method
38	I-Method
is	O
best	O
for	O
accuracy	B-Metric
,	O
but	O
requires	O
some	O
more	O
memory	O
.	O
	
If	O
speed	B-Metric
is	O
important	O
,	O
ENet	B-Method
would	O
favor	O
over	O
Segnet	B-Method
since	O
it	O
is	O
much	O
faster	O
with	O
almost	O
the	O
same	O
accuracy	B-Metric
.	O
	
It	O
also	O
shows	O
that	O
running	O
on	O
a	O
higher	O
resolution	O
than	O
768x384	O
does	O
n’t	O
increase	O
accuracy	B-Metric
much	O
for	O
the	O
tested	O
networks	O
.	O
	
Note	O
that	O
the	O
post	B-Method
-	I-Method
processing	I-Method
step	I-Method
can	O
be	O
implemented	O
efficiently	O
,	O
causing	O
only	O
a	O
negligible	O
overhead	O
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
work	O
we	O
have	O
proposed	O
a	O
discriminative	O
loss	B-Method
function	I-Method
for	O
the	O
task	O
of	O
instance	B-Task
segmentation	I-Task
.	O
	
After	O
training	O
,	O
the	O
output	O
of	O
the	O
network	O
can	O
be	O
clustered	O
into	O
discrete	O
instances	O
with	O
a	O
simple	O
post	B-Method
-	I-Method
processing	I-Method
thresholding	I-Method
operation	I-Method
that	O
is	O
tailored	O
to	O
the	O
loss	B-Method
function	I-Method
.	O
	
Furthermore	O
,	O
we	O
showed	O
that	O
our	O
method	O
can	O
handle	O
complex	O
occlusions	O
as	O
opposed	O
to	O
popular	O
detect	B-Method
-	I-Method
and	I-Method
-	I-Method
segment	I-Method
approaches	I-Method
.	O
	
Our	O
method	O
achieves	O
competitive	O
performance	O
on	O
two	O
benchmarks	O
.	O
	
In	O
this	O
paper	O
we	O
still	O
used	O
a	O
pretrained	B-Method
network	I-Method
to	O
produce	O
the	O
semantic	O
segmentation	O
masks	O
.	O
	
We	O
will	O
investigate	O
the	O
joint	B-Task
training	I-Task
of	I-Task
instance	I-Task
and	I-Task
semantic	I-Task
segmentation	I-Task
with	O
our	O
loss	B-Method
function	I-Method
in	O
future	O
work	O
.	O
	
Acknowledgement	O
:	O
This	O
work	O
was	O
supported	O
by	O
Toyota	O
,	O
and	O
was	O
carried	O
out	O
at	O
the	O
TRACE	O
Lab	O
at	O
KU	O
Leuven	O
(	O
Toyota	O
Research	O
on	O
Automated	B-Task
Cars	I-Task
in	O
Europe	O
-	O
Leuven	O
)	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
DeepMatching	B-Method
:	O
Hierarchical	B-Task
Deformable	I-Task
Dense	I-Task
Matching	I-Task
	
We	O
introduce	O
a	O
novel	O
matching	B-Method
algorithm	I-Method
,	O
called	O
DeepMatching	B-Method
,	O
to	O
compute	O
dense	B-Task
correspondences	I-Task
between	I-Task
images	I-Task
.	O
	
DeepMatching	B-Method
relies	O
on	O
a	O
hierarchical	B-Method
,	I-Method
multi	I-Method
-	I-Method
layer	I-Method
,	I-Method
correlational	I-Method
architecture	I-Method
designed	O
for	O
matching	B-Method
images	O
and	O
was	O
inspired	O
by	O
deep	B-Method
convolutional	I-Method
approaches	I-Method
.	O
	
The	O
proposed	O
matching	B-Method
algorithm	I-Method
can	O
handle	O
non	O
-	O
rigid	O
deformations	O
and	O
repetitive	O
textures	O
and	O
efficiently	O
determines	O
dense	O
correspondences	O
in	O
the	O
presence	O
of	O
significant	O
changes	O
between	O
images	O
.	O
	
We	O
evaluate	O
the	O
performance	O
of	O
DeepMatching	B-Method
,	O
in	O
comparison	O
with	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
matching	B-Method
algorithms	I-Method
,	O
on	O
the	O
Mikolajczyk	B-Material
Mikolajczyk2005	O
,	O
the	O
MPI	B-Material
-	I-Material
Sintel	I-Material
sintel	O
and	O
the	O
Kitti	B-Material
kitti	O
datasets	O
.	O
	
DeepMatching	B-Method
outperforms	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
algorithms	O
and	O
shows	O
excellent	O
results	O
in	O
particular	O
for	O
repetitive	O
textures	O
.	O
	
We	O
also	O
propose	O
a	O
method	O
for	O
estimating	B-Task
optical	I-Task
flow	I-Task
,	O
called	O
DeepFlow	B-Method
,	O
by	O
integrating	O
DeepMatching	B-Method
in	O
the	O
large	B-Method
displacement	I-Method
optical	I-Method
flow	I-Method
(	O
LDOF	B-Method
)	O
approach	O
of	O
[	O
]	O
.	O
	
Compared	O
to	O
existing	O
matching	B-Method
algorithms	I-Method
,	O
additional	O
robustness	B-Metric
to	O
large	O
displacements	O
and	O
complex	O
motion	O
is	O
obtained	O
thanks	O
to	O
our	O
matching	B-Method
approach	I-Method
.	O
	
DeepFlow	B-Method
obtains	O
competitive	O
performance	O
on	O
public	O
benchmarks	O
for	O
optical	B-Task
flow	I-Task
estimation	I-Task
.	O
	
section	O
:	O
Introduction	O
	
Computing	B-Task
correspondences	I-Task
between	O
related	O
images	O
is	O
a	O
central	O
issue	O
in	O
many	O
computer	B-Task
vision	I-Task
problems	I-Task
,	O
ranging	O
from	O
scene	B-Task
recognition	I-Task
to	O
optical	B-Task
flow	I-Task
estimation	I-Task
forsyth2011computer	O
,	O
Szeliski2010	O
.	O
	
The	O
goal	O
of	O
a	O
matching	B-Method
algorithm	I-Method
is	O
to	O
discover	O
shared	O
visual	O
content	O
between	O
two	O
images	O
,	O
and	O
to	O
establish	O
as	O
many	O
as	O
possible	O
precise	O
point	O
-	O
wise	O
correspondences	O
,	O
called	O
matches	O
.	O
	
An	O
essential	O
aspect	O
of	O
matching	B-Method
approaches	I-Method
is	O
the	O
amount	O
of	O
rigidity	O
they	O
assume	O
when	O
computing	O
the	O
correspondences	O
.	O
	
In	O
fact	O
,	O
matching	B-Method
approaches	I-Method
range	O
between	O
two	O
extreme	O
cases	O
:	O
stereo	O
matching	B-Method
,	O
where	O
matching	B-Method
hinges	O
upon	O
strong	O
geometric	O
constraints	O
,	O
and	O
matching	B-Method
‘	O
‘	O
in	O
the	O
wild	O
’	O
’	O
,	O
where	O
the	O
set	O
of	O
possible	O
transformations	O
from	O
the	O
source	O
image	O
to	O
the	O
target	O
one	O
is	O
large	O
and	O
the	O
problem	O
is	O
basically	O
almost	O
unconstrained	O
.	O
	
Effective	O
approaches	O
have	O
been	O
designed	O
for	O
matching	B-Method
rigid	O
objects	O
across	O
images	O
in	O
the	O
presence	O
of	O
large	O
viewpoint	O
changes	O
Lowe2004	O
,	O
Barnes2010	O
,	O
HaCohen2011	O
.	O
	
However	O
,	O
the	O
performance	O
of	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
matching	B-Method
algorithms	I-Method
for	O
images	B-Task
	
‘	O
	
‘	O
in	O
the	O
wild	O
’	O
’	O
,	O
such	O
as	O
consecutive	O
images	O
in	O
real	O
-	O
world	O
videos	O
featuring	O
fast	O
non	O
-	O
rigid	O
motion	O
,	O
still	O
calls	O
for	O
improvement	O
mdpof	O
,	O
Chen2013	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
aim	O
at	O
tackling	O
matching	B-Method
in	O
such	O
a	O
general	O
setting	O
.	O
	
Matching	B-Method
algorithms	I-Method
for	O
images	B-Task
	
‘	O
	
‘	O
in	O
the	O
wild	O
’	O
’	O
need	O
to	O
accommodate	O
several	O
requirements	O
,	O
that	O
turn	O
out	O
to	O
be	O
often	O
in	O
contradiction	O
.	O
	
On	O
one	O
hand	O
,	O
matching	B-Method
objects	O
necessarily	O
requires	O
rigidity	O
assumptions	O
to	O
some	O
extent	O
.	O
	
It	O
is	O
also	O
mandatory	O
that	O
these	O
objects	O
have	O
sufficiently	O
discriminative	O
textures	O
to	O
make	O
the	O
problem	O
well	O
-	O
defined	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
many	O
objects	O
or	O
regions	O
are	O
not	O
rigid	O
objects	O
,	O
like	O
humans	O
or	O
animals	O
.	O
	
Furthermore	O
,	O
large	O
portions	O
of	O
an	O
image	O
are	O
usually	O
occupied	O
by	O
weakly	O
-	O
to	O
-	O
no	O
textured	O
regions	O
,	O
often	O
with	O
repetitive	O
textures	O
,	O
like	O
sky	O
or	O
bucolic	O
background	O
.	O
	
Descriptor	O
matching	B-Method
approaches	O
,	O
such	O
as	O
SIFT	B-Method
Lowe2004	O
or	O
HOG	B-Method
Dalal2005	I-Method
,	O
Bro11a	O
matching	B-Method
,	O
compute	O
discriminative	B-Method
feature	I-Method
representations	I-Method
from	O
rectangular	O
patches	O
.	O
	
However	O
,	O
while	O
these	O
approaches	O
succeed	O
in	O
case	O
of	O
rigid	B-Task
motion	I-Task
,	O
they	O
fail	O
to	O
match	O
regions	O
with	O
weak	O
or	O
repetitive	O
textures	O
,	O
as	O
local	O
patches	O
are	O
poorly	O
discriminative	O
.	O
	
Furthermore	O
,	O
matches	O
are	O
usually	O
poor	O
and	O
imprecise	O
in	O
case	O
of	O
non	O
-	O
rigid	O
deformations	O
,	O
as	O
these	O
approaches	O
rely	O
on	O
rigid	O
patches	O
.	O
	
Discriminative	O
power	O
can	O
be	O
traded	O
against	O
increased	O
robustness	B-Metric
to	O
non	O
-	O
rigid	O
deformations	O
.	O
	
Indeed	O
,	O
propagation	B-Method
-	I-Method
based	I-Method
approaches	I-Method
,	O
such	O
as	O
Generalized	B-Method
PatchMatch	I-Method
Barnes2010	O
or	O
Non	B-Method
-	I-Method
rigid	I-Method
Dense	I-Method
Correspondences	I-Method
HaCohen2011	O
,	O
compute	O
simple	O
feature	B-Method
representations	I-Method
from	O
small	O
patches	O
and	O
propagate	O
matches	O
to	O
neighboring	O
patches	O
.	O
	
They	O
yield	O
good	O
performance	O
in	O
case	O
of	O
non	B-Task
-	I-Task
rigid	I-Task
deformations	I-Task
.	O
	
However	O
,	O
matching	B-Method
repetitive	O
textures	O
remains	O
beyond	O
the	O
reach	O
of	O
these	O
approaches	O
.	O
	
In	O
this	O
paper	O
we	O
propose	O
a	O
novel	O
approach	O
,	O
called	O
DeepMatching	B-Method
,	O
that	O
gracefully	O
combines	O
the	O
strengths	O
of	O
these	O
two	O
families	O
of	O
approaches	O
.	O
	
DeepMatching	B-Method
is	O
computed	O
using	O
a	O
multi	B-Method
-	I-Method
layer	I-Method
architecture	I-Method
,	O
which	O
breaks	O
down	O
patches	O
into	O
a	O
hierarchy	O
of	O
sub	O
-	O
patches	O
.	O
	
This	O
architecture	O
allows	O
to	O
work	O
at	O
several	O
scales	O
and	O
handle	O
repetitive	O
textures	O
.	O
	
Furthermore	O
,	O
within	O
each	O
layer	O
,	O
local	O
matches	O
are	O
computed	O
assuming	O
a	O
restricted	O
set	O
of	O
feasible	O
rigid	O
deformations	O
.	O
	
Local	O
matches	O
are	O
then	O
propagated	O
up	O
the	O
hierarchy	O
,	O
which	O
progressively	O
discard	O
spurious	O
incorrect	O
matches	O
.	O
	
We	O
called	O
our	O
approach	O
DeepMatching	B-Method
,	O
as	O
it	O
is	O
inspired	O
by	O
deep	B-Method
convolutional	I-Method
approaches	I-Method
.	O
	
In	O
summary	O
,	O
we	O
make	O
three	O
contributions	O
:	O
Dense	O
matching	B-Method
:	O
we	O
propose	O
a	O
matching	B-Method
algorithm	I-Method
,	O
DeepMatching	B-Method
,	O
that	O
allows	O
to	O
robustly	O
determine	O
dense	O
correspondences	O
between	O
two	O
images	O
.	O
	
It	O
explicitly	O
handles	O
non	B-Task
-	I-Task
rigid	I-Task
deformations	I-Task
,	O
with	O
bounds	O
on	O
the	O
deformation	O
tolerance	O
,	O
and	O
incorporates	O
a	O
multi	O
-	O
scale	O
scoring	O
of	O
the	O
matches	O
,	O
making	O
it	O
robust	O
to	O
repetitive	O
or	O
weak	O
textures	O
.	O
	
Furthermore	O
,	O
our	O
approach	O
is	O
based	O
on	O
gradient	B-Method
histograms	I-Method
,	O
and	O
thus	O
robust	O
to	O
appearance	O
changes	O
caused	O
by	O
illumination	O
and	O
color	O
variations	O
.	O
	
Fast	O
,	O
scale	O
/	O
rotation	O
-	O
invariant	O
matching	B-Method
:	O
we	O
propose	O
a	O
computationally	O
efficient	O
version	O
of	O
DeepMatching	B-Method
,	O
which	O
performs	O
almost	O
as	O
well	O
as	O
exact	O
DeepMatching	B-Method
,	O
but	O
at	O
a	O
much	O
lower	O
memory	B-Metric
cost	I-Metric
.	O
	
Furthermore	O
,	O
this	O
fast	O
version	O
of	O
DeepMatching	B-Method
can	O
be	O
extended	O
to	O
a	O
scale	B-Method
and	I-Method
rotation	I-Method
-	I-Method
invariant	I-Method
version	I-Method
,	O
making	O
it	O
an	O
excellent	O
competitor	O
to	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
descriptor	O
matching	B-Method
approaches	O
.	O
	
Large	B-Task
-	I-Task
displacement	I-Task
optical	I-Task
flow	I-Task
:	O
we	O
propose	O
an	O
optical	B-Method
flow	I-Method
approach	I-Method
which	O
uses	O
DeepMatching	B-Method
in	O
the	O
matching	B-Method
term	I-Method
of	O
the	O
large	B-Method
displacement	I-Method
variational	I-Method
energy	I-Method
minimization	I-Method
of	O
[	O
]	O
.	O
	
We	O
show	O
that	O
DeepMatching	B-Method
is	O
a	O
better	O
choice	O
compared	O
to	O
the	O
HOG	B-Method
descriptor	I-Method
used	O
by	O
[	O
]	O
and	O
other	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
matching	B-Method
algorithms	I-Method
.	O
	
The	O
approach	O
,	O
named	O
DeepFlow	B-Method
,	O
obtains	O
competitive	O
results	O
on	O
public	O
optical	O
flow	O
benchmarks	O
.	O
	
This	O
paper	O
is	O
organized	O
as	O
follows	O
.	O
	
After	O
a	O
review	O
of	O
previous	O
works	O
(	O
Section	O
[	O
reference	O
]	O
)	O
,	O
we	O
start	O
by	O
presenting	O
the	O
proposed	O
matching	B-Method
algorithm	I-Method
,	O
DeepMatching	B-Method
,	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Then	O
,	O
Section	O
[	O
reference	O
]	O
describes	O
several	O
extensions	O
of	O
DeepMatching	B-Method
.	O
	
In	O
particular	O
,	O
we	O
propose	O
an	O
optical	B-Method
flow	I-Method
approach	I-Method
,	O
DeepFlow	B-Method
,	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Finally	O
,	O
we	O
present	O
experimental	O
results	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
A	O
preliminary	O
version	O
of	O
this	O
article	O
has	O
appeared	O
in	O
.	O
	
This	O
version	O
adds	O
(	O
1	O
)	O
an	O
in	O
-	O
depth	O
presentation	O
of	O
DeepMatching	B-Method
;	O
(	O
2	O
)	O
an	O
enhanced	O
version	O
of	O
DeepMatching	B-Method
,	O
which	O
improves	O
the	O
match	B-Task
scoring	I-Task
and	O
the	O
selection	O
of	O
entry	O
points	O
for	O
backtracking	O
;	O
(	O
3	O
)	O
proofs	O
on	O
time	B-Metric
and	I-Metric
memory	I-Metric
complexity	I-Metric
of	O
DeepMatching	B-Method
as	O
well	O
as	O
its	O
deformation	B-Metric
tolerance	I-Metric
;	O
(	O
4	O
)	O
a	O
discussion	O
on	O
the	O
connection	O
between	O
Deep	B-Method
Convolutional	I-Method
Neural	I-Method
Networks	I-Method
and	O
DeepMatching	B-Method
;	O
(	O
5	O
)	O
a	O
fast	O
approximate	B-Method
version	I-Method
of	O
DeepMatching	B-Method
;	O
(	O
6	O
)	O
a	O
scale	B-Method
and	I-Method
rotation	I-Method
invariant	I-Method
version	I-Method
of	O
DeepMatching	B-Method
;	O
and	O
(	O
7	O
)	O
an	O
extensive	O
experimental	O
evaluation	O
of	O
DeepMatching	B-Method
on	O
several	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
benchmarks	O
.	O
	
The	O
code	O
for	O
DeepMatching	B-Method
as	O
well	O
as	O
DeepFlow	B-Method
are	O
available	O
at	O
and	O
.	O
	
Note	O
that	O
we	O
provide	O
a	O
GPU	B-Method
implementation	I-Method
in	O
addition	O
to	O
the	O
CPU	B-Method
one	I-Method
.	O
	
section	O
:	O
Related	O
work	O
	
In	O
this	O
section	O
we	O
review	O
related	O
work	O
on	O
‘	O
‘	O
general	O
’	O
’	O
image	O
matching	B-Method
,	O
that	O
is	O
matching	B-Method
without	O
prior	O
knowledge	O
and	O
constraints	O
,	O
and	O
on	O
matching	B-Method
in	O
the	O
context	O
of	O
optical	B-Task
flow	I-Task
estimation	I-Task
,	O
that	O
is	O
matching	B-Method
consecutive	O
images	O
in	O
videos	O
.	O
	
subsection	O
:	O
General	O
image	O
matching	B-Method
	
Image	O
matching	B-Method
based	O
on	O
local	O
features	O
has	O
been	O
extensively	O
studied	O
in	O
the	O
past	O
decade	O
.	O
	
It	O
has	O
been	O
applied	O
successfully	O
to	O
various	O
domains	O
,	O
such	O
as	O
wide	B-Task
baseline	I-Task
stereo	I-Task
matching	I-Task
Furukawa2010	O
and	O
image	B-Task
retrieval	I-Task
Philbin2010	O
.	O
	
It	O
consists	O
of	O
two	O
steps	O
,	O
i.e	O
.	O
,	O
extracting	O
local	B-Method
descriptors	I-Method
and	O
matching	B-Method
them	O
.	O
	
Image	B-Method
descriptors	I-Method
are	O
extracted	O
in	O
rigid	O
(	O
generally	O
square	O
)	O
local	O
frames	O
at	O
sparse	O
invariant	O
image	O
locations	O
Mikolajczyk2005	O
,	O
Szeliski2010	O
.	O
	
Matching	B-Task
then	O
equals	O
nearest	B-Method
neighbor	I-Method
search	I-Method
between	O
descriptors	O
,	O
followed	O
by	O
an	O
optional	O
geometric	B-Method
verification	I-Method
.	O
	
Note	O
that	O
a	O
confidence	B-Metric
value	I-Metric
can	O
be	O
obtained	O
by	O
computing	O
the	O
uniqueness	O
of	O
a	O
match	O
,	O
i.e.	O
,	O
by	O
looking	O
at	O
the	O
distance	O
of	O
its	O
nearest	O
neighbors	O
While	O
this	O
class	O
of	O
techniques	O
is	O
well	O
suited	O
for	O
well	O
-	O
textured	O
rigid	O
objects	O
,	O
it	O
fails	O
to	O
match	O
non	O
-	O
rigid	O
objects	O
and	O
weakly	O
textured	O
regions	O
.	O
	
In	O
contrast	O
,	O
the	O
proposed	O
matching	B-Method
algorithm	I-Method
,	O
called	O
DeepMatching	B-Method
,	O
is	O
inspired	O
by	O
non	B-Method
-	I-Method
rigid	I-Method
2D	I-Method
warping	I-Method
and	O
deep	B-Method
convolutional	I-Method
networks	I-Method
LeCun98	O
,	O
Uchida1998	O
,	O
Keysers2007	O
.	O
	
This	O
family	O
of	O
approaches	O
explicitly	O
models	O
non	O
-	O
rigid	O
deformations	O
.	O
	
We	O
employ	O
a	O
novel	O
family	B-Method
of	I-Method
feasible	I-Method
warpings	I-Method
that	O
does	O
not	O
enforce	O
monotonicity	O
nor	O
continuity	O
constraints	O
,	O
in	O
contrast	O
to	O
traditional	O
2D	B-Method
warping	I-Method
Uchida1998	O
,	O
Keysers2007	O
.	O
	
This	O
makes	O
the	O
problem	O
computationally	O
much	O
less	O
expensive	O
.	O
	
It	O
is	O
also	O
worthwhile	O
to	O
mention	O
the	O
similarity	O
with	O
non	B-Method
-	I-Method
rigid	I-Method
matching	I-Method
approaches	O
developed	O
for	O
a	O
broad	O
range	O
of	O
applications	O
.	O
	
proposed	O
a	O
similar	O
pipeline	O
to	O
ours	O
(	O
albeit	O
more	O
complex	O
)	O
to	O
measure	O
the	O
similarity	B-Task
of	I-Task
small	I-Task
images	I-Task
.	O
	
However	O
,	O
their	O
method	O
lacks	O
a	O
way	O
of	O
merging	O
correspondences	O
belonging	O
to	O
objects	O
with	O
contradictory	O
motions	O
,	O
	
e.g	O
.	O
,	O
on	O
different	O
focal	O
planes	O
.	O
	
For	O
the	O
purpose	O
of	O
establishing	O
dense	B-Task
correspondences	I-Task
between	I-Task
images	I-Task
,	O
estimated	O
a	O
non	B-Method
-	I-Method
rigid	I-Method
matching	I-Method
by	O
robustly	O
fitting	O
smooth	B-Method
parametric	I-Method
models	I-Method
(	O
homography	O
and	O
splines	O
)	O
to	O
local	O
descriptor	O
matches	O
.	O
	
In	O
contrast	O
,	O
our	O
approach	O
is	O
non	O
-	O
parametric	B-Method
and	I-Method
model	I-Method
-	I-Method
free	I-Method
.	O
	
Recently	O
,	O
fast	O
algorithms	O
for	O
dense	O
patch	O
matching	B-Method
have	O
taken	O
advantage	O
of	O
the	O
redundancy	O
between	O
overlapping	O
patches	O
Barnes2010	O
,	O
Korman2011	O
,	O
kpm	B-Method
,	O
daisyff	O
.	O
	
The	O
insight	O
is	O
to	O
propagate	O
good	O
matches	O
to	O
their	O
neighborhood	O
in	O
a	O
loose	O
fashion	O
,	O
yielding	O
dense	O
non	O
-	O
rigid	O
matches	O
.	O
	
In	O
practice	O
,	O
however	O
,	O
the	O
lack	O
of	O
a	O
smoothness	O
constraint	O
leads	O
to	O
highly	O
discontinuous	O
matches	O
.	O
	
Several	O
works	O
have	O
proposed	O
ways	O
to	O
fix	O
this	O
.	O
	
reinforce	O
neighboring	O
matches	O
using	O
an	O
iterative	O
multiscale	O
expansion	O
and	O
contraction	B-Method
strategy	I-Method
,	O
performed	O
in	O
a	O
coarse	O
-	O
to	O
-	O
fine	O
manner	O
.	O
	
include	O
a	O
guided	B-Method
filtering	I-Method
stage	I-Method
on	O
top	O
of	O
PatchMatch	B-Method
,	O
which	O
obtains	O
smooth	O
correspondence	O
fields	O
by	O
locally	O
approximating	O
a	O
MRF	B-Method
.	O
	
Finally	O
,	O
propose	O
a	O
hierarchical	B-Method
matching	I-Method
to	O
obtain	O
dense	B-Task
correspondences	I-Task
,	O
using	O
a	O
coarse	O
-	O
to	O
-	O
fine	O
(	O
top	B-Method
-	I-Method
down	I-Method
)	I-Method
strategy	I-Method
.	O
	
Loopy	B-Method
belief	I-Method
propagation	I-Method
is	O
used	O
to	O
perform	O
inference	B-Task
.	O
	
In	O
contrast	O
to	O
these	O
approaches	O
,	O
DeepMatching	B-Method
proceeds	O
bottom	O
-	O
up	O
	
and	O
,	O
then	O
,	O
top	O
-	O
down	O
.	O
	
Due	O
to	O
its	O
hierarchical	O
nature	O
,	O
DeepMatching	B-Method
is	O
able	O
to	O
consider	O
patches	O
at	O
several	O
scales	O
,	O
thus	O
overcoming	O
the	O
lack	O
of	O
distinctiveness	O
that	O
affects	O
small	O
patches	O
.	O
	
Yet	O
,	O
the	O
multi	B-Method
-	I-Method
layer	I-Method
construction	I-Method
allows	O
to	O
efficiently	O
perform	O
matching	B-Method
allowing	O
semi	B-Task
-	I-Task
rigid	I-Task
local	I-Task
deformations	I-Task
.	O
	
In	O
addition	O
,	O
DeepMatching	B-Method
can	O
be	O
computed	O
efficiently	O
,	O
and	O
can	O
be	O
further	O
accelerated	O
to	O
satisfy	O
low	B-Metric
-	I-Metric
memory	I-Metric
requirements	I-Metric
with	O
negligible	O
loss	O
in	O
accuracy	B-Metric
.	O
	
subsection	O
:	O
Matching	B-Task
for	O
flow	B-Task
estimation	I-Task
	
Variational	B-Method
energy	I-Method
minimization	I-Method
is	O
currently	O
the	O
most	O
popular	O
framework	O
for	O
optical	B-Task
flow	I-Task
estimation	I-Task
.	O
	
Since	O
the	O
pioneering	O
work	O
of	O
,	O
research	O
has	O
focused	O
on	O
alleviating	O
the	O
drawbacks	O
of	O
this	O
approach	O
.	O
	
A	O
series	O
of	O
improvements	O
were	O
proposed	O
over	O
the	O
years	O
Black1996	O
,	O
Werlberger2009	O
,	O
Bruhn2005	O
,	O
Papenberg2006	O
,	O
middlebury	O
,	O
Sun2014	O
,	O
Vogel2013data	O
.	O
	
The	O
variational	B-Method
approach	I-Method
of	O
combines	O
most	O
of	O
these	O
improvements	O
in	O
a	O
unified	O
framework	O
.	O
	
The	O
energy	O
decomposes	O
into	O
several	O
terms	O
,	O
resp	O
.	O
	
the	O
data	B-Method
-	I-Method
fitting	I-Method
and	O
the	O
smoothness	B-Method
terms	I-Method
.	O
	
Energy	B-Task
minimization	I-Task
is	O
performed	O
by	O
solving	O
the	O
Euler	B-Method
-	I-Method
Lagrange	I-Method
equations	I-Method
,	O
reducing	O
the	O
problem	O
to	O
solving	O
a	O
sequence	O
of	O
large	B-Task
and	I-Task
structured	I-Task
linear	I-Task
systems	I-Task
.	O
	
More	O
recently	O
,	O
the	O
addition	O
of	O
a	O
descriptor	O
matching	B-Method
term	O
in	O
the	O
energy	O
to	O
be	O
minimized	O
was	O
proposed	O
by	O
.	O
	
Following	O
this	O
idea	O
,	O
several	O
papers	O
Tola2008	O
,	O
Bro11a	O
,	O
siftflow	B-Method
,	O
siftscales	B-Method
show	O
that	O
dense	B-Method
descriptor	I-Method
matching	I-Method
improves	O
performance	O
.	O
	
Strategies	O
such	O
as	O
reciprocal	B-Method
nearest	I-Method
-	I-Method
neighbor	I-Method
verification	I-Method
allow	O
to	O
prune	O
most	O
of	O
the	O
false	O
matches	O
.	O
	
However	O
,	O
a	O
variational	B-Method
energy	I-Method
minimization	I-Method
approach	I-Method
that	O
includes	O
such	O
a	O
descriptor	O
matching	B-Method
term	O
may	O
fail	O
at	O
locations	O
where	O
matches	O
are	O
missing	O
or	O
wrong	O
.	O
	
Related	O
approaches	O
tackle	O
the	O
problem	O
of	O
dense	B-Task
scene	I-Task
correspondence	I-Task
.	O
	
SIFT	B-Method
-	O
flow	O
one	O
of	O
the	O
most	O
famous	O
method	O
in	O
this	O
context	O
,	O
also	O
formulates	O
the	O
matching	B-Method
problem	O
in	O
a	O
variational	B-Method
framework	I-Method
.	O
	
[	O
]	O
improve	O
over	O
SIFT	B-Method
-	O
flow	O
by	O
using	O
multi	O
-	O
scale	O
patches	O
.	O
	
However	O
,	O
this	O
decreases	O
performance	O
in	O
cases	O
where	O
scale	O
invariance	O
is	O
not	O
required	O
.	O
	
integrate	O
matching	B-Method
of	O
SIFT	B-Method
Lowe2004	O
and	O
PatchMatch	B-Method
Barnes2010	O
to	O
refine	O
the	O
flow	B-Task
initialization	I-Task
at	O
each	O
level	O
.	O
	
Excellent	O
results	O
are	O
obtained	O
for	O
optical	B-Task
flow	I-Task
estimation	I-Task
,	O
yet	O
at	O
the	O
cost	O
of	O
expensive	O
fusion	B-Method
steps	I-Method
.	O
	
extends	O
sparse	O
matches	O
with	O
locally	O
affine	O
constraints	O
to	O
dense	O
matches	O
and	O
,	O
then	O
,	O
uses	O
a	O
total	B-Method
variation	I-Method
algorithm	I-Method
to	O
refine	O
the	O
flow	B-Task
estimation	I-Task
.	O
	
We	O
present	O
here	O
a	O
computationally	O
efficient	O
and	O
competitive	O
approach	O
for	O
large	B-Method
displacement	I-Method
optical	I-Method
flow	I-Method
by	O
integrating	O
the	O
proposed	O
DeepMatching	B-Method
algorithm	I-Method
into	O
the	O
approach	O
of	O
.	O
	
section	O
:	O
DeepMatching	B-Method
	
This	O
section	O
introduces	O
our	O
matching	B-Method
algorithm	O
DeepMatching	B-Method
.	O
	
DeepMatching	B-Method
is	O
a	O
matching	B-Method
algorithm	I-Method
based	O
on	O
correlations	O
at	O
the	O
patch	O
-	O
level	O
,	O
that	O
proceeds	O
in	O
a	O
multi	B-Method
-	I-Method
layer	I-Method
fashion	I-Method
.	O
	
The	O
multi	B-Method
-	I-Method
layer	I-Method
architecture	I-Method
relies	O
on	O
a	O
quadtree	B-Method
-	I-Method
like	I-Method
patch	I-Method
subdivision	I-Method
scheme	I-Method
,	O
with	O
an	O
extra	O
degree	O
of	O
freedom	O
to	O
locally	O
re	O
-	O
optimize	O
the	O
positions	O
of	O
each	O
quadrant	O
.	O
	
In	O
order	O
to	O
enhance	O
the	O
contrast	O
of	O
the	O
spatial	O
correlation	O
maps	O
output	O
by	O
the	O
local	O
correlations	O
,	O
a	O
nonlinear	B-Method
transformation	I-Method
is	O
applied	O
after	O
each	O
layer	O
.	O
	
We	O
first	O
give	O
an	O
overview	O
of	O
DeepMatching	B-Method
in	O
Section	O
[	O
reference	O
]	O
and	O
show	O
that	O
it	O
can	O
be	O
decomposed	O
in	O
a	O
bottom	O
-	O
up	O
pass	O
followed	O
by	O
a	O
top	O
-	O
down	O
pass	O
.	O
	
We	O
,	O
then	O
,	O
present	O
the	O
bottom	O
-	O
up	O
pass	O
in	O
Section	O
[	O
reference	O
]	O
and	O
the	O
top	O
-	O
down	O
one	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Finally	O
,	O
we	O
analyze	O
DeepMatching	B-Method
in	O
Section	O
[	O
reference	O
]	O
.	O
	
subsection	O
:	O
Overview	O
of	O
the	O
approach	O
	
A	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
approach	O
for	O
matching	B-Method
regions	O
between	O
two	O
images	O
is	O
based	O
on	O
the	O
SIFT	B-Method
descriptor	I-Method
Lowe2004	O
.	O
	
SIFT	B-Method
is	O
a	O
histogram	O
of	O
gradients	O
with	O
spatial	O
and	O
8	O
orientation	O
bins	O
,	O
yielding	O
a	O
robust	B-Method
descriptor	I-Method
that	O
effectively	O
encodes	O
a	O
square	O
image	O
region	O
.	O
	
Note	O
that	O
its	O
cell	O
grid	O
can	O
also	O
be	O
viewed	O
as	O
4	O
so	O
-	O
called	O
‘	O
	
‘	O
quadrants	O
’	O
’	O
of	O
cells	O
,	O
see	O
Figure	O
[	O
reference	O
]	O
.	O
	
We	O
can	O
,	O
then	O
,	O
rewrite	O
with	O
.	O
	
Let	O
and	O
be	O
the	O
SIFT	B-Method
descriptors	O
of	O
the	O
corresponding	O
regions	O
in	O
the	O
source	O
and	O
target	O
image	O
.	O
	
In	O
order	O
to	O
remove	O
the	O
effect	O
of	O
non	O
-	O
rigid	O
motion	O
,	O
we	O
propose	O
to	O
optimize	O
the	O
positions	O
of	O
the	O
quadrants	O
of	O
the	O
target	O
descriptor	O
(	O
rather	O
than	O
keeping	O
them	O
fixed	O
)	O
,	O
in	O
order	O
to	O
maximize	O
where	O
is	O
the	O
descriptor	O
of	O
a	O
single	O
quadrant	O
extracted	O
at	O
position	O
and	O
a	O
similarity	O
function	O
.	O
	
Now	O
,	O
is	O
able	O
to	O
handle	O
situations	O
such	O
as	O
the	O
one	O
presented	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
where	O
a	O
region	O
contains	O
multiple	O
objects	O
moving	O
in	O
different	O
directions	O
.	O
	
Furthermore	O
,	O
if	O
the	O
four	O
quadrants	O
can	O
move	O
independently	O
(	O
of	O
course	O
,	O
within	O
some	O
extent	O
)	O
,	O
it	O
can	O
be	O
calculated	O
more	O
efficiently	O
as	O
:	O
When	O
applied	O
recursively	O
to	O
each	O
quadrant	O
by	O
subdivided	O
it	O
into	O
4	O
sub	O
-	O
quadrants	O
until	O
a	O
minimum	O
patch	O
size	O
is	O
reached	O
(	O
atomic	O
patches	O
)	O
,	O
this	O
strategy	O
allows	O
for	O
accurate	O
non	B-Method
-	I-Method
rigid	I-Method
matching	I-Method
.	O
	
Such	O
a	O
recursive	B-Method
decomposition	I-Method
can	O
be	O
represented	O
as	O
a	O
quad	O
-	O
tree	O
,	O
see	O
Figure	O
[	O
reference	O
]	O
.	O
	
Given	O
an	O
initial	O
pair	O
of	O
two	O
matching	B-Method
regions	O
,	O
retrieving	O
atomic	B-Task
patch	I-Task
correspondences	I-Task
is	O
then	O
done	O
in	O
a	O
top	O
-	O
down	O
fashion	O
(	O
i.e	O
.	O
by	O
recursively	O
applying	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
to	O
the	O
quadrant	O
’s	O
positions	O
)	O
.	O
	
Nevertheless	O
,	O
in	O
order	O
to	O
first	O
determine	O
the	O
set	O
of	O
matching	B-Method
regions	O
between	O
the	O
two	O
images	O
,	O
we	O
need	O
to	O
compute	O
beforehand	O
the	O
matching	B-Method
scores	O
(	O
i.e	O
.	O
similarity	O
)	O
of	O
all	O
large	O
-	O
enough	O
patches	O
in	O
the	O
two	O
images	O
(	O
as	O
in	O
Figure	O
[	O
reference	O
]	O
)	O
,	O
and	O
keep	O
the	O
pairs	O
with	O
maximum	O
similarity	O
.	O
	
As	O
indicated	O
by	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
,	O
the	O
score	O
is	O
formed	O
by	O
averaging	O
the	O
max	O
-	O
pooled	O
scores	O
of	O
the	O
quadrants	O
.	O
	
Hence	O
,	O
the	O
process	O
of	O
computing	O
the	O
matching	B-Method
scores	O
is	O
bottom	O
-	O
up	O
.	O
	
In	O
the	O
following	O
,	O
we	O
call	O
correlation	O
map	O
the	O
matching	B-Method
scores	O
of	O
a	O
single	O
patch	O
from	O
the	O
first	O
image	O
at	O
every	O
position	O
in	O
the	O
second	O
image	O
.	O
	
Selecting	O
matching	B-Method
patches	O
then	O
corresponds	O
to	O
finding	O
local	O
maxima	O
in	O
the	O
correlation	O
maps	O
.	O
	
To	O
sum	O
-	O
up	O
,	O
the	O
algorithm	O
can	O
be	O
decomposed	O
in	O
two	O
steps	O
:	O
(	O
i	O
)	O
first	O
,	O
correlation	O
maps	O
are	O
computed	O
using	O
a	O
bottom	B-Method
-	I-Method
up	I-Method
algorithm	I-Method
,	O
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Correlation	O
maps	O
of	O
small	O
patches	O
are	O
first	O
computed	O
and	O
then	O
aggregated	O
to	O
form	O
correlation	O
maps	O
of	O
larger	O
patches	O
;	O
(	O
ii	O
)	O
next	O
,	O
a	O
top	B-Method
-	I-Method
down	I-Method
method	I-Method
estimates	O
the	O
motion	B-Task
of	I-Task
atomic	I-Task
patches	I-Task
starting	O
from	O
matches	O
of	O
large	O
patches	O
.	O
	
In	O
the	O
remainder	O
of	O
this	O
section	O
,	O
we	O
detail	O
the	O
two	O
steps	O
described	O
above	O
(	O
Section	O
[	O
reference	O
]	O
and	O
Section	O
[	O
reference	O
]	O
)	O
,	O
before	O
analyzing	O
the	O
properties	O
of	O
DeepMatching	B-Method
in	O
Section	O
[	O
reference	O
]	O
.	O
	
subsection	O
:	O
Bottom	O
-	O
up	O
correlation	B-Method
pyramid	I-Method
computation	I-Method
	
Let	O
and	O
be	O
two	O
images	O
of	O
resolution	O
and	O
.	O
	
paragraph	O
:	O
Bottom	O
level	O
.	O
	
We	O
use	O
patches	O
of	O
size	O
pixels	O
as	O
atomic	O
patches	O
.	O
	
We	O
split	O
into	O
non	O
-	O
overlapping	O
atomic	O
patches	O
,	O
and	O
compute	O
the	O
correlation	O
map	O
with	O
image	O
for	O
each	O
of	O
them	O
,	O
see	O
Figure	O
[	O
reference	O
]	O
.	O
	
The	O
score	O
between	O
two	O
atomic	O
patches	O
and	O
is	O
defined	O
as	O
the	O
average	B-Metric
pixel	I-Metric
-	I-Metric
wise	I-Metric
similarity	I-Metric
:	O
where	O
each	O
pixel	O
is	O
represented	O
as	O
a	O
histogram	O
of	O
oriented	O
gradients	O
pooled	O
over	O
a	O
local	O
neighborhood	O
.	O
	
We	O
detail	O
below	O
how	O
the	O
pixel	B-Method
descriptor	I-Method
is	O
computed	O
.	O
	
paragraph	O
:	O
Pixel	B-Method
descriptor	I-Method
:	O
	
We	O
rely	O
on	O
a	O
robust	B-Method
pixel	I-Method
representation	I-Method
that	O
is	O
similar	O
in	O
spirit	O
to	O
SIFT	B-Method
and	O
DAISY	B-Method
	
Given	O
an	O
input	O
image	O
	
I	O
,	O
we	O
first	O
apply	O
a	O
Gaussian	B-Method
smoothing	I-Method
of	I-Method
radius	I-Method
ν1	I-Method
in	O
order	O
to	O
denoise	O
I	O
from	O
potential	O
artifacts	O
caused	O
for	O
example	O
by	O
JPEG	B-Task
compression	I-Task
.	O
	
We	O
then	O
extract	O
the	O
gradient	O
(	O
⁢δx	O
,	O
⁢δy	O
)	O
at	O
each	O
pixel	O
and	O
compute	O
its	O
non	O
-	O
negative	O
projection	O
onto	O
8	O
orientations	O
{	O
(	O
cos⁢iπ4	O
,	O
sin⁢iπ4	O
)	O
}=i⁢1	O
…	O
8	O
.	O
	
At	O
this	O
point	O
,	O
we	O
obtain	O
8	O
oriented	B-Method
gradient	I-Method
maps	I-Method
.	O
	
We	O
smooth	O
each	O
map	O
with	O
a	O
Gaussian	B-Method
filter	I-Method
of	I-Method
radius	I-Method
ν2	I-Method
.	O
	
Next	O
we	O
cap	O
strong	O
gradients	O
using	O
a	O
sigmoid	O
↦x	O
-/	O
2	O
(+	O
1exp	O
(-	O
⁢ςx	O
))	O
1	O
,	O
to	O
help	O
canceling	O
out	O
effects	O
of	O
varying	O
illumination	O
.	O
	
We	O
smooth	O
gradients	O
one	O
more	O
time	O
for	O
each	O
orientation	O
with	O
a	O
Gaussian	B-Method
filter	I-Method
of	I-Method
radius	I-Method
ν3	I-Method
.	O
	
Finally	O
,	O
the	O
descriptor	O
for	O
each	O
pixel	O
is	O
obtained	O
by	O
the	O
ℓ2	O
-	O
normalized	O
concatenation	O
of	O
8	O
oriented	O
gradients	O
and	O
a	O
ninth	O
small	O
constant	O
value	O
μ	O
.	O
	
Appending	O
μ	B-Method
amounts	O
to	O
adding	O
a	O
regularizer	B-Method
that	O
will	O
reduce	O
the	O
importance	O
of	O
small	O
gradients	O
(	O
i.e.	O
noise	O
)	O
and	O
ensures	O
that	O
two	O
pixels	O
lying	O
in	O
areas	O
without	O
gradient	O
information	O
will	O
still	O
correlate	O
positively	O
.	O
	
Pixel	O
descriptors	O
Ri	O
,	O
j	O
are	O
compared	O
using	O
dot	B-Method
-	I-Method
product	I-Method
and	O
the	O
similarity	B-Method
function	I-Method
takes	O
value	O
in	O
the	O
interval	O
[	O
0	O
,	O
1	O
]	O
.	O
	
In	O
Section	O
,	O
we	O
evaluate	O
the	O
impact	O
of	O
the	O
parameters	O
of	O
this	O
pixel	B-Method
descriptor	I-Method
.	O
	
paragraph	O
:	O
Bottom	O
-	O
level	O
correlation	B-Metric
map	I-Metric
:	O
	
We	O
can	O
express	O
the	O
correlation	O
map	O
computation	O
obtained	O
from	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
more	O
conveniently	O
in	O
a	O
convolutional	B-Method
framework	I-Method
.	O
	
Let	O
be	O
a	O
patch	O
of	O
size	O
from	O
the	O
first	O
image	O
centered	O
at	O
(	O
is	O
a	O
power	O
of	O
2	O
)	O
.	O
	
Let	O
be	O
a	O
grid	O
with	O
step	O
pixels	O
.	O
	
is	O
the	O
set	O
of	O
the	O
centers	O
of	O
the	O
atomic	O
patches	O
.	O
	
For	O
each	O
,	O
we	O
convolve	O
the	O
flipped	O
patch	O
over	O
to	O
get	O
the	O
correlation	O
map	O
,	O
where	O
.F	O
denotes	O
an	O
horizontal	O
and	O
vertical	O
	
flipThis	O
amounts	O
to	O
the	O
cross	O
-	O
correlation	O
of	O
the	O
patch	O
and	O
I′.	O
.	O
	
For	O
any	O
pixel	O
of	O
,	O
is	O
a	O
measure	B-Metric
of	I-Metric
similarity	I-Metric
between	O
and	O
.	O
	
Examples	O
of	O
such	O
correlation	O
maps	O
are	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
and	O
Figure	O
[	O
reference	O
]	O
.	O
	
Without	O
surprise	O
we	O
can	O
observe	O
that	O
atomic	O
patches	O
are	O
not	O
discriminative	O
.	O
	
Recursive	B-Method
aggregation	I-Method
of	I-Method
patches	I-Method
in	O
subsequent	O
stages	O
will	O
be	O
the	O
key	O
to	O
create	O
discriminative	O
responses	O
.	O
	
paragraph	O
:	O
Iteration	O
.	O
	
We	O
then	O
compute	O
the	O
correlation	O
maps	O
of	O
larger	O
patches	O
by	O
aggregating	O
those	O
of	O
smaller	O
patches	O
.	O
	
As	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
a	O
patch	O
is	O
the	O
concatenation	O
of	O
patches	O
of	O
size	O
:	O
They	O
correspond	O
respectively	O
to	O
the	O
bottom	O
-	O
left	O
,	O
top	O
-	O
left	O
,	O
bottom	O
-	O
right	O
and	O
top	O
-	O
right	O
quadrants	O
.	O
	
The	O
correlation	O
map	O
of	O
can	O
thus	O
be	O
computed	O
using	O
its	O
children	O
’s	O
correlation	O
maps	O
.	O
	
For	O
the	O
sake	O
of	O
clarity	O
,	O
we	O
define	O
the	O
short	O
-	O
hand	O
notation	O
=	O
	
sN	B-Method
,	O
i⁢N4oi	O
describing	O
the	O
positional	O
shift	O
of	O
a	O
children	O
patch	O
∈i	O
[	O
0	O
,	O
3	O
]	O
relatively	O
to	O
its	O
parent	O
patch	O
(	O
see	O
Figure	O
)	O
.	O
	
Using	O
the	O
above	O
notations	O
,	O
we	O
rewrite	O
Eq	O
.	O
	
(	O
)	O
by	O
replacing	O
=	O
⁢def⁢sim	O
(	O
R	O
,	O
R′	O
)	O
⁢CN	O
,	O
p	O
(	O
p′	O
)	O
	
(	O
i.e.	O
assuming	O
here	O
that	O
patch	O
=	O
RIN	O
,	O
	
p	O
and	O
that	O
R′	O
is	O
centered	O
at	O
∈p′I′	O
)	O
.	O
	
Similarly	O
,	O
we	O
replace	O
the	O
similarity	O
between	O
children	O
patches	O
⁢sim	O
(	O
Ri	O
,	O
⁢Ri′	O
(	O
p′i	O
)	O
)	O
by	O
⁢CN2	O
,+	O
psN	O
,	O
i	O
(	O
pi′	O
)	O
.	O
	
For	O
each	O
child	O
,	O
we	O
retain	O
the	O
maximum	O
similarity	O
over	O
a	O
small	O
neighborhood	O
Θi	O
of	O
width	O
and	O
height	O
N8	O
centered	O
at	O
+	O
p′sN	O
,	O
i	O
.	O
	
We	O
then	O
obtain	O
:	O
We	O
now	O
explain	O
how	O
we	O
can	O
break	O
down	O
Eq	O
.	O
	
(	O
)	O
into	O
a	O
succession	O
of	O
simple	O
operations	O
.	O
	
First	O
,	O
let	O
us	O
assume	O
that	O
=	O
N×42ℓ	O
,	O
where	O
≥ℓ1	O
is	O
the	O
current	O
iteration	O
.	O
	
During	O
iteration	O
ℓ	O
,	O
we	O
want	O
to	O
compute	O
the	O
correlation	O
maps	O
CN	O
,	O
p	O
of	O
every	O
patch	O
IN	O
,	O
p	O
from	O
the	O
first	O
image	O
for	O
which	O
correlation	O
maps	O
of	O
its	O
children	O
have	O
been	O
computed	O
in	O
the	O
previous	O
iteration	O
.	O
	
Formally	O
,	O
the	O
position	O
GN	O
of	O
such	O
patches	O
is	O
defined	O
according	O
to	O
the	O
position	O
of	O
children	O
patches	O
GN2	O
according	O
to	O
Eq	O
.	O
	
(	O
)	O
:	O
We	O
observe	O
that	O
the	O
larger	O
a	O
patch	O
is	O
(	O
i.e	O
.	O
after	O
several	O
iterations	O
)	O
,	O
the	O
smaller	O
the	O
spatial	O
variation	O
of	O
its	O
correlation	B-Metric
map	I-Metric
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
This	O
is	O
due	O
to	O
the	O
statistics	O
of	O
natural	O
images	O
,	O
in	O
which	O
low	O
frequencies	O
significantly	O
dominate	O
over	O
high	O
frequencies	O
.	O
	
As	O
a	O
consequence	O
,	O
we	O
choose	O
to	O
subsample	O
each	O
map	O
CN	O
,	O
	
p	O
by	O
a	O
factor	O
2	O
.	O
	
We	O
express	O
this	O
with	O
an	O
operator	O
:	O
	
The	O
subsampling	B-Method
reduces	O
by	O
the	O
area	O
of	O
the	O
correlation	O
maps	O
and	O
,	O
as	O
a	O
direct	O
consequence	O
,	O
the	O
computational	B-Metric
requirements	I-Metric
.	O
	
Instead	O
of	O
computing	O
the	O
subsampling	O
on	O
top	O
of	O
Eq	O
.	O
	
(	O
)	O
,	O
it	O
is	O
actually	O
more	O
efficient	O
to	O
propagate	O
it	O
towards	O
the	O
children	O
maps	O
and	O
perform	O
it	O
jointly	O
with	O
max	B-Method
-	I-Method
pooling	I-Method
.	O
	
It	O
also	O
makes	O
the	O
max	B-Method
-	I-Method
pooling	I-Method
domain	I-Method
become	O
independent	O
from	O
in	O
the	O
subsampled	O
maps	O
,	O
as	O
it	O
exactly	O
cancels	O
out	O
the	O
effect	O
of	O
doubling	O
at	O
each	O
iteration	O
.	O
	
We	O
call	O
the	O
max	B-Method
-	I-Method
pooling	I-Method
operator	I-Method
with	O
the	O
iteration	O
-	O
independent	O
domain	O
:	O
For	O
the	O
same	O
reason	O
,	O
the	O
shift	O
applied	O
to	O
the	O
correlation	O
maps	O
in	O
’s	O
definition	O
becomes	O
simply	O
after	O
subsampling	O
.	O
	
Let	O
be	O
the	O
shift	O
(	O
or	O
translation	O
)	O
operator	O
on	O
the	O
correlation	O
map	O
:	O
Finally	O
,	O
we	O
incorporate	O
an	O
additional	O
non	B-Method
-	I-Method
linear	I-Method
mapping	I-Method
at	O
each	O
iteration	O
on	O
top	O
of	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
by	O
applying	O
a	O
power	B-Method
transform	I-Method
MalikPerona90	O
,	O
LeCun98	O
:	O
	
This	O
step	O
,	O
commonly	O
referred	O
to	O
as	O
rectification	O
,	O
is	O
added	O
in	O
order	O
to	O
better	O
propagate	O
high	O
correlations	O
after	O
each	O
level	O
,	O
or	O
,	O
in	O
other	O
words	O
,	O
to	O
counterbalance	O
the	O
fact	O
that	O
max	B-Method
-	I-Method
pooling	I-Method
tends	O
to	O
retain	O
only	O
high	O
scores	O
.	O
	
Indeed	O
,	O
its	O
effect	O
is	O
to	O
decrease	O
the	O
correlation	B-Metric
values	I-Metric
(	O
which	O
are	O
in	O
[	O
0	O
,	O
1	O
]	O
)	O
as	O
we	O
use	O
>	O
λ1	O
.	O
	
Such	O
post	B-Method
-	I-Method
processing	I-Method
is	O
commonly	O
used	O
in	O
deep	B-Method
convolutional	I-Method
networks	I-Method
lecun	O
-	O
98b	O
,	O
Bengio09	O
.	O
	
In	O
practice	O
,	O
good	O
performance	O
is	O
obtained	O
with	O
,	O
see	O
Section	O
[	O
reference	O
]	O
.	O
	
The	O
final	O
expression	O
of	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
is	O
:	O
Figure	O
[	O
reference	O
]	O
illustrates	O
the	O
computation	O
of	O
correlation	O
maps	O
for	O
different	O
patch	O
sizes	O
and	O
Algorithm	O
[	O
reference	O
]	O
summarizes	O
our	O
approach	O
.	O
	
The	O
resulting	O
set	O
of	O
correlation	O
maps	O
across	O
iterations	O
is	O
referred	O
to	O
as	O
multi	O
-	O
level	O
correlation	O
pyramid	O
.	O
	
paragraph	O
:	O
Boundary	O
effects	O
:	O
	
In	O
practice	O
,	O
a	O
patch	O
IN	O
,	O
p	O
can	O
overlap	O
with	O
the	O
image	O
boundary	O
,	O
as	O
long	O
as	O
its	O
center	O
p	O
remains	O
inside	O
the	O
image	O
(	O
from	O
Eq	O
.	O
	
(	O
)	O
)	O
.	O
	
For	O
instance	O
,	O
a	O
patch	O
IN	O
,	O
p0	O
with	O
center	O
at	O
p0=	O
(	O
0	O
,	O
0	O
)	O
∈GN	O
has	O
only	O
a	O
single	O
valid	O
child	O
(	O
the	O
one	O
for	O
which	O
=	O
i3	O
as	O
∈	O
+	O
p0sN	O
,	O
3I	O
)	O
.	O
	
In	O
such	O
degenerate	O
cases	O
,	O
the	O
average	O
sum	O
in	O
Eq	O
.	O
	
(	O
)	O
is	O
carried	O
out	O
on	O
valid	O
children	O
only	O
.	O
	
For	O
IN	O
,	O
p0	O
,	O
it	O
thus	O
only	O
comprises	O
one	O
term	O
weighted	O
by	O
1	O
instead	O
of	O
14	O
.	O
	
Note	O
that	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
implicitly	O
defines	O
the	O
set	O
of	O
possible	O
displacements	O
of	O
the	O
approach	O
,	O
see	O
Figures	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
.	O
	
Given	O
the	O
position	O
of	O
a	O
parent	O
patch	O
,	O
each	O
child	O
patch	O
can	O
move	O
only	O
within	O
a	O
small	O
extent	O
,	O
equal	O
to	O
the	O
quarter	O
of	O
its	O
own	O
size	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
the	O
correlation	O
maps	O
for	O
patches	O
of	O
size	O
,	O
and	O
.	O
	
Clearly	O
,	O
correlation	O
maps	O
for	O
larger	O
patch	O
are	O
more	O
and	O
more	O
discriminative	O
,	O
while	O
still	O
allowing	O
non	B-Method
-	I-Method
rigid	I-Method
matching	I-Method
.	O
	
Input	O
:	O
	
Images	O
,	O
For	O
do	B-Task
(	I-Task
convolution	I-Task
,	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
)	O
	
(	O
rectification	O
,	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
)	O
	
While	O
do	O
For	O
do	O
(	O
max	B-Method
-	I-Method
pooling	I-Method
and	O
subsampling	B-Method
)	O
	
For	O
do	O
(	O
shift	O
and	O
average	O
)	O
(	O
rectification	O
,	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
)	O
	
Return	O
the	O
multi	O
-	O
level	O
correlation	O
	
pyramid	B-Method
Computing	I-Method
the	O
multi	O
-	O
level	O
correlation	O
pyramid	O
.	O
	
subsection	O
:	O
Top	B-Task
-	I-Task
down	I-Task
correspondence	I-Task
extraction	I-Task
	
A	O
score	O
in	O
the	O
multi	O
-	O
level	O
correlation	O
pyramid	O
represents	O
the	O
deformation	O
-	O
tolerant	O
similarity	O
of	O
two	O
patches	O
and	O
.	O
	
Since	O
this	O
score	O
is	O
built	O
from	O
the	O
similarity	O
of	O
4	O
matching	B-Method
sub	O
-	O
patches	O
at	O
the	O
lower	O
pyramid	O
level	O
,	O
we	O
can	O
thus	O
recursively	O
backtrack	O
a	O
set	O
of	O
correspondences	O
to	O
the	O
bottom	O
level	O
(	O
corresponding	O
to	O
matches	O
of	O
atomic	O
patches	O
)	O
.	O
	
In	O
this	O
section	O
,	O
we	O
first	O
describe	O
this	O
backtracking	B-Method
.	O
	
We	O
,	O
then	O
,	O
present	O
the	O
procedure	O
for	O
merging	O
atomic	O
correspondences	O
backtracked	O
from	O
different	O
entry	O
points	O
in	O
the	O
multi	O
-	O
level	O
pyramid	O
,	O
which	O
constitute	O
the	O
final	O
output	O
of	O
DeepMatching	B-Method
.	O
	
Compared	O
to	O
our	O
initial	O
version	O
of	O
DeepMatching	B-Method
DeepFlow	O
,	O
we	O
have	O
updated	O
match	B-Method
scoring	I-Method
and	O
entry	B-Method
point	I-Method
selection	I-Method
to	O
optimize	O
the	O
execution	B-Metric
time	I-Metric
and	O
the	O
matching	B-Method
accuracy	O
.	O
	
A	O
quantitative	O
comparison	O
is	O
provided	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
paragraph	O
:	O
Backtracking	B-Task
atomic	I-Task
correspondences	I-Task
.	O
	
Given	O
an	O
entry	O
point	O
in	O
the	O
pyramid	O
(	O
i.e	O
.	O
a	O
match	O
between	O
two	O
patches	O
and	O
)	O
,	O
we	O
retrieve	O
atomic	O
correspondences	O
by	O
successively	O
undoing	O
the	O
steps	O
used	O
to	O
aggregate	O
correlation	O
maps	O
during	O
the	O
pyramid	B-Method
construction	I-Method
,	O
see	O
Figure	O
[	O
reference	O
]	O
.	O
	
The	O
entry	O
patch	O
is	O
itself	O
composed	O
of	O
four	O
moving	O
quadrants	O
,	O
.	O
	
Due	O
to	O
the	O
subsampling	O
,	O
the	O
quadrant	O
matches	O
with	O
where	O
For	O
the	O
sake	O
of	O
clarity	O
,	O
we	O
define	O
the	O
short	O
-	O
hand	O
notations	O
and	O
.	O
	
Let	O
be	O
the	O
function	O
that	O
assigns	O
to	O
a	O
tuple	O
,	O
representing	O
a	O
correspondence	O
between	O
pixel	O
and	O
for	O
patch	O
of	O
size	O
with	O
a	O
score	O
,	O
	
the	O
set	O
of	O
the	O
correspondences	O
of	O
children	O
patches	O
:	O
	
Given	O
a	O
set	O
of	O
such	O
tuples	O
,	O
let	O
be	O
the	O
union	O
of	O
the	O
sets	O
for	O
all	O
.	O
	
Note	O
that	O
if	O
all	O
candidate	O
correspondences	O
corresponds	O
to	O
atomic	O
patches	O
,	O
then	O
.	O
	
Thus	O
,	O
the	O
algorithm	O
for	O
backtracking	B-Task
correspondences	I-Task
is	O
the	O
following	O
.	O
	
Consider	O
an	O
entry	O
match	O
.	O
	
We	O
repeatedly	O
apply	O
on	O
.	O
	
After	O
calls	O
,	O
we	O
get	O
one	O
correspondence	O
for	O
each	O
of	O
the	O
atomic	O
patches	O
.	O
	
Furthermore	O
,	O
their	O
score	O
is	O
equal	O
to	O
the	O
sum	O
of	O
all	O
patch	O
similarities	O
along	O
their	O
backtracking	O
path	O
.	O
	
paragraph	O
:	O
Merging	B-Task
correspondences	I-Task
.	O
	
We	O
have	O
shown	O
how	O
to	O
retrieve	O
atomic	O
correspondences	O
from	O
a	O
match	O
between	O
two	O
deformable	O
(	O
potentially	O
large	O
)	O
patches	O
.	O
	
Despite	O
this	O
flexibility	O
,	O
a	O
single	O
match	O
is	O
unlikely	O
to	O
explain	O
the	O
complex	O
set	O
of	O
motions	O
that	O
can	O
occur	O
,	O
for	O
example	O
,	O
between	O
two	O
adjacent	O
frames	O
in	O
a	O
video	O
,	O
	
i.e	O
.	O
	
,	O
two	O
objects	O
moving	O
independently	O
with	O
significantly	O
different	O
motions	O
exceeds	O
the	O
deformation	O
range	O
of	O
DeepMatching	B-Method
.	O
	
We	O
quantitatively	O
specify	O
this	O
range	O
in	O
the	O
next	O
subsection	O
.	O
	
We	O
thus	O
merge	O
atomic	O
correspondences	O
gathered	O
from	O
different	O
entry	O
points	O
(	O
matches	O
)	O
in	O
the	O
pyramid	O
.	O
	
In	O
the	O
initial	O
version	O
of	O
DeepMatching	B-Method
DeepFlow	O
,	O
entry	O
points	O
were	O
local	O
maxima	O
over	O
all	O
correlation	O
maps	O
.	O
	
This	O
is	O
now	O
replaced	O
by	O
a	O
faster	O
procedure	O
,	O
that	O
starts	O
with	O
all	O
possible	O
matches	O
in	O
the	O
top	O
pyramid	O
level	O
(	O
i.e	O
.	O
)	O
.	O
	
Using	O
this	O
level	O
only	O
results	O
in	O
significantly	O
less	O
entry	O
points	O
than	O
starting	O
from	O
all	O
maxima	O
in	O
the	O
entire	O
pyramid	O
.	O
	
We	O
did	O
not	O
observe	O
any	O
impact	O
on	O
the	O
matching	B-Method
performance	O
,	O
see	O
Section	O
[	O
reference	O
]	O
.	O
	
Because	O
contains	O
a	O
lot	O
of	O
overlapping	O
patches	O
,	O
most	O
of	O
the	O
computation	O
during	O
repeated	O
calls	O
to	O
can	O
be	O
factorized	O
.	O
	
In	O
other	O
words	O
,	O
as	O
soon	O
as	O
two	O
tuples	O
in	O
are	O
equal	O
in	O
terms	O
of	O
,	O
and	O
,	O
the	O
one	O
with	O
the	O
lowest	O
score	O
is	O
simply	O
eliminated	O
.	O
	
We	O
thus	O
obtain	O
a	O
set	O
of	O
atomic	O
correspondences	O
:	O
that	O
we	O
filter	O
with	O
reciprocal	B-Task
match	I-Task
verification	I-Task
.	O
	
The	O
final	O
set	O
of	O
correspondences	O
is	O
obtained	O
as	O
:	O
where	O
(	O
resp	O
.	O
)	O
returns	O
the	O
best	O
match	O
in	O
a	O
small	O
vicinity	O
of	O
pixels	O
around	O
in	O
(	O
resp	O
.	O
around	O
in	O
)	O
from	O
.	O
	
subsection	O
:	O
Discussion	O
and	O
Analysis	O
of	O
DeepMatching	B-Method
	
paragraph	O
:	O
Multi	O
-	O
size	O
patches	O
and	O
repetitive	O
textures	O
.	O
	
During	O
the	O
bottom	O
-	O
up	O
pass	O
of	O
the	O
algorithm	O
,	O
we	O
iteratively	O
aggregate	O
correlation	O
maps	O
of	O
smaller	O
patches	O
to	O
form	O
the	O
correlation	O
maps	O
of	O
larger	O
patches	O
.	O
	
Doing	O
so	O
,	O
we	O
effectively	O
consider	O
patches	O
of	O
different	O
sizes	O
(	O
)	O
,	O
in	O
contrast	O
to	O
most	O
existing	O
matching	B-Method
methods	I-Method
.	O
	
This	O
is	O
a	O
key	O
feature	O
of	O
our	O
approach	O
when	O
dealing	O
with	O
repetitive	O
textures	O
.	O
	
As	O
one	O
moves	O
up	O
to	O
upper	O
levels	O
,	O
the	O
matching	B-Method
problem	O
gets	O
less	O
ambiguous	O
.	O
	
Hence	O
,	O
our	O
method	O
can	O
correctly	O
match	O
repetitive	O
patterns	O
,	O
see	O
for	O
instance	O
Figure	O
[	O
reference	O
]	O
.	O
	
paragraph	O
:	O
Quasi	O
-	O
dense	O
correspondences	O
.	O
	
Our	O
method	O
retrieves	O
dense	O
correspondences	O
for	O
every	O
single	O
match	O
between	O
large	O
regions	O
(	O
i.e	O
.	O
entry	O
point	O
for	O
the	O
backtracking	O
in	O
the	O
top	O
-	O
level	O
correlation	O
maps	O
)	O
	
,	O
even	O
in	O
weakly	O
textured	O
areas	O
;	O
this	O
is	O
in	O
contrast	O
to	O
correspondences	O
obtained	O
when	O
matching	B-Method
descriptors	I-Method
(	O
e.g	O
.	O
SIFT	B-Method
)	O
.	O
	
A	O
quantitative	O
assessment	O
,	O
which	O
compares	O
the	O
coverage	O
of	O
matches	O
obtained	O
with	O
several	O
matching	B-Method
schemes	I-Method
,	O
is	O
given	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
paragraph	O
:	O
Non	O
-	O
rigid	O
deformations	O
.	O
	
Our	O
matching	B-Method
algorithm	I-Method
is	O
able	O
to	O
cope	O
with	O
various	O
sources	O
of	O
image	O
deformations	O
:	O
object	O
-	O
induced	O
or	O
camera	O
-	O
induced	O
.	O
	
The	O
set	O
of	O
feasible	O
deformations	O
,	O
explicitly	O
defined	O
by	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
,	O
theoretically	O
allows	O
to	O
deal	O
with	O
a	O
scaling	O
factor	O
in	O
the	O
range	O
and	O
rotations	O
approximately	O
in	O
the	O
range	O
.	O
	
Note	O
also	O
that	O
DeepMatching	B-Method
is	O
translation	O
-	O
invariant	O
by	O
construction	O
,	O
thanks	O
to	O
the	O
convolutional	B-Method
nature	I-Method
of	O
the	O
processing	O
.	O
	
Given	O
a	O
patch	O
of	O
size	O
located	O
at	O
level	O
,	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
allows	O
each	O
of	O
its	O
children	O
patches	O
to	O
move	O
by	O
at	O
most	O
pixels	O
from	O
their	O
ideal	O
location	O
in	O
.	O
	
By	O
recursively	O
summing	O
the	O
displacements	O
at	O
each	O
level	O
,	O
the	O
maximal	O
displacements	O
for	O
an	O
atomic	O
patch	O
is	O
.	O
	
An	O
example	O
is	O
given	O
in	O
Figure	O
[	O
reference	O
]	O
with	O
and	O
.	O
	
Relatively	O
to	O
,	O
we	O
thus	O
have	O
and	O
.	O
	
For	O
a	O
rotation	O
,	O
the	O
rationale	O
is	O
similar	O
,	O
see	O
Figure	O
[	O
reference	O
]	O
.	O
	
Note	O
that	O
the	O
displacement	O
tolerance	O
in	O
Θi	O
from	O
Eq	O
.	O
	
(	O
)	O
could	O
be	O
extended	O
to	O
/	O
×xN8	O
pixels	O
with	O
∈x{2	O
,	O
3	O
,	O
…	O
}	O
(	O
instead	O
of	O
=	O
x1	O
)	O
.	O
	
Then	O
the	O
above	O
formula	O
for	O
computing	O
the	O
lower	B-Metric
bound	I-Metric
on	O
the	O
scale	O
factor	O
of	O
DeepMatching	B-Method
generalizes	O
to	O
=	O
	
⁢LB	O
(	O
x	O
)	O
lim→N∞	O
/(-	O
N⁢2xdN	O
)	O
N.	O
	
Hence	O
,	O
for	O
≥x2	O
we	O
obtain	O
<	O
	
⁢LB	O
(	O
x	O
)	O
0	O
	
instead	O
of	O
=	O
⁢LB	O
(	O
1	O
)	O
12	O
.	O
	
This	O
implies	O
that	O
the	O
deformation	O
range	O
is	O
extended	O
to	O
a	O
point	O
where	O
any	O
patch	O
can	O
be	O
matched	O
to	O
a	O
single	O
pixel	O
,	O
i.e.	O
,	O
this	O
results	O
in	O
unrealistic	O
deformations	O
.	O
	
For	O
this	O
reason	O
,	O
we	O
choose	O
to	O
not	O
expand	O
the	O
deformation	O
range	O
of	O
DeepMatching	B-Method
.	O
	
paragraph	O
:	O
Built	B-Method
-	I-Method
in	I-Method
smoothing	I-Method
.	O
	
Furthermore	O
,	O
correspondences	O
generated	O
through	O
backtracking	O
of	O
a	O
single	O
entry	O
point	O
in	O
the	O
correlation	B-Method
maps	I-Method
are	O
naturally	O
smooth	O
.	O
	
Indeed	O
,	O
feasible	O
deformations	O
can	O
not	O
be	O
too	O
	
‘	O
	
‘	O
far	O
’	O
’	O
from	O
the	O
identity	O
deformation	O
.	O
	
To	O
verify	O
this	O
assumption	O
,	O
we	O
conduct	O
the	O
following	O
experiment	O
.	O
	
We	O
artificially	O
generate	O
two	O
types	O
of	O
correspondences	O
between	O
two	O
images	O
of	O
size	O
×128128	O
.	O
	
The	O
first	O
one	O
is	O
completely	O
random	O
,	O
i.e.	O
for	O
each	O
atomic	O
patch	O
in	O
the	O
first	O
image	O
we	O
assign	O
randomly	O
a	O
match	O
in	O
the	O
second	O
image	O
.	O
	
The	O
second	O
one	O
respects	O
the	O
backtracking	O
constraints	O
.	O
	
Starting	O
from	O
a	O
single	O
entry	O
point	O
in	O
the	O
top	O
level	O
we	O
simulate	O
the	O
backtracking	B-Method
procedure	I-Method
from	O
Section	O
by	O
replacing	O
in	O
Eq	O
.	O
	
(	O
)	O
the	O
max	B-Method
operation	I-Method
by	O
a	O
random	B-Method
sampling	I-Method
over	O
{	O
-	O
1	O
,	O
0	O
,	O
1}2	O
.	O
	
By	O
generating	O
10	O
,	O
000	O
sets	O
of	O
possible	O
atomic	O
correspondences	O
,	O
we	O
simulate	O
a	O
set	O
which	O
respects	O
the	O
deformations	O
allowed	O
by	O
DeepMatching	B-Method
.	O
	
Figure	O
[	O
reference	O
]	O
compares	O
the	O
smoothness	O
of	O
these	O
two	O
types	O
of	O
artificial	O
correspondences	O
.	O
	
Smoothness	B-Metric
is	O
measured	O
by	O
interpreting	O
the	O
correspondences	O
as	O
flow	O
and	O
measuring	O
the	O
gradient	O
flow	O
norm	O
,	O
see	O
Eq	O
.	O
	
(	O
)	O
.	O
	
Clearly	O
,	O
the	O
two	O
types	O
of	O
warpings	O
are	O
different	O
by	O
orders	O
of	O
magnitude	O
.	O
	
Furthermore	O
,	O
the	O
one	O
which	O
respects	O
the	O
built	O
-	O
in	O
constraints	O
of	O
DeepMatching	B-Method
is	O
close	O
to	O
the	O
identity	B-Method
warping	I-Method
.	O
	
paragraph	O
:	O
Relation	O
to	O
Deep	B-Method
Convolutional	I-Method
Neural	I-Method
Networks	I-Method
(	O
CNNs	B-Method
)	O
.	O
	
DeepMatching	B-Method
relies	O
on	O
a	O
hierarchical	B-Method
,	I-Method
multi	I-Method
-	I-Method
layer	I-Method
,	I-Method
correlational	I-Method
architecture	I-Method
designed	O
for	O
matching	B-Method
images	O
and	O
was	O
inspired	O
by	O
deep	B-Method
convolutional	I-Method
approaches	I-Method
	
In	O
the	O
following	O
we	O
describe	O
the	O
major	O
similarities	O
and	O
differences	O
.	O
	
Deep	B-Method
networks	I-Method
learn	O
from	O
data	O
the	O
weights	O
of	O
the	O
convolutions	B-Method
.	O
	
In	O
contrast	O
,	O
DeepMatching	B-Method
does	O
not	O
learn	O
any	O
feature	B-Method
representations	I-Method
and	O
instead	O
directly	O
computes	O
correlations	O
at	O
the	O
patch	O
level	O
.	O
	
It	O
uses	O
patches	O
from	O
the	O
first	O
image	O
as	O
convolution	B-Method
filters	I-Method
for	O
the	O
second	O
one	O
.	O
	
However	O
,	O
the	O
bottom	B-Method
-	I-Method
up	I-Method
pipeline	I-Method
of	O
DeepMatching	B-Method
is	O
similar	O
to	O
CNNs	B-Method
.	O
	
It	O
alternates	O
aggregating	O
channels	O
from	O
the	O
previous	O
layer	O
with	O
channel	B-Method
-	I-Method
wise	I-Method
max	I-Method
-	I-Method
pooling	I-Method
and	O
subsampling	B-Method
.	O
	
As	O
in	O
CNNs	B-Method
,	O
max	B-Method
-	I-Method
pooling	I-Method
in	O
DeepMatching	B-Method
allows	O
for	O
invariance	B-Task
w.r.t	O
.	O
small	O
deformations	O
.	O
	
Likewise	O
,	O
the	O
algorithm	O
propagates	O
pairwise	O
patch	O
similarity	O
scores	O
through	O
the	O
hierarchy	O
using	O
non	O
-	O
linear	B-Method
rectifying	I-Method
stages	I-Method
in	O
-	O
between	O
layers	O
.	O
	
Finally	O
,	O
DeepMatching	B-Method
includes	O
a	O
top	B-Method
-	I-Method
down	I-Method
pass	I-Method
which	O
is	O
not	O
present	O
in	O
CNNs	B-Method
.	O
	
paragraph	O
:	O
Time	B-Metric
and	I-Metric
space	I-Metric
complexity	I-Metric
.	O
	
DeepMatching	B-Method
has	O
a	O
complexity	O
in	O
memory	B-Metric
and	O
time	O
,	O
where	O
and	O
are	O
the	O
number	O
of	O
pixels	O
per	O
image	O
.	O
	
Computing	O
the	O
initial	O
correlations	O
is	O
a	O
operation	O
.	O
	
Then	O
,	O
at	O
each	O
level	O
of	O
the	O
pyramid	O
,	O
the	O
process	O
is	O
repeated	O
while	O
the	O
complexity	B-Metric
is	O
divided	O
by	O
a	O
factor	O
due	O
to	O
the	O
subsampling	O
step	O
in	O
the	O
target	O
image	O
(	O
since	O
the	O
cardinality	O
of	O
remains	O
approximately	O
constant	O
)	O
.	O
	
Thus	O
,	O
the	O
total	O
complexity	B-Metric
of	O
the	O
correlation	B-Method
maps	I-Method
computation	I-Method
is	O
,	O
at	O
worst	O
,	O
.	O
	
During	O
the	O
top	O
-	O
down	O
pass	O
,	O
most	O
backtracking	O
paths	O
can	O
be	O
pruned	O
as	O
soon	O
as	O
they	O
cross	O
a	O
concurrent	O
path	O
with	O
a	O
higher	O
score	O
(	O
see	O
Section	O
[	O
reference	O
]	O
)	O
.	O
	
Thus	O
,	O
all	O
correlations	O
will	O
be	O
examined	O
at	O
most	O
once	O
,	O
and	O
there	O
are	O
values	O
in	O
total	O
.	O
	
However	O
,	O
this	O
analysis	O
is	O
worst	O
-	O
case	O
.	O
	
In	O
practice	O
,	O
only	O
correlations	O
lying	O
on	O
maximal	O
paths	O
are	O
actually	O
examined	O
.	O
	
section	O
:	O
Extensions	O
of	O
DeepMatching	B-Method
	
subsection	O
:	O
Approximate	O
DeepMatching	B-Method
	
As	O
a	O
consequence	O
of	O
its	O
space	B-Metric
complexity	I-Metric
,	O
DeepMatching	B-Method
requires	O
an	O
amount	O
of	O
RAM	O
that	O
is	O
orders	O
of	O
magnitude	O
above	O
other	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
matching	B-Method
methods	I-Method
.	O
	
This	O
could	O
correspond	O
to	O
several	O
gigabytes	O
for	O
images	O
of	O
moderate	O
size	O
(	O
800	O
600	O
pixels	O
)	O
;	O
see	O
Section	O
[	O
reference	O
]	O
.	O
	
This	O
section	O
introduces	O
an	O
approximation	O
of	O
DeepMatching	B-Method
that	O
allows	O
to	O
trade	O
matching	B-Method
quality	O
for	O
reduced	B-Metric
time	I-Metric
and	I-Metric
memory	I-Metric
usage	I-Metric
.	O
	
As	O
shown	O
in	O
Section	O
[	O
reference	O
]	O
,	O
near	O
-	O
optimal	O
results	O
can	O
be	O
obtained	O
at	O
a	O
fraction	O
of	O
the	O
original	O
cost	O
.	O
	
Our	O
approximation	O
proposes	O
to	O
compress	O
the	O
representation	B-Method
of	I-Method
atomic	I-Method
patches	I-Method
.	O
	
Atomic	O
patches	O
carry	O
little	O
information	O
,	O
and	O
thus	O
are	O
highly	O
redundant	O
.	O
	
For	O
instance	O
,	O
in	O
uniform	O
regions	O
,	O
all	O
patches	O
are	O
nearly	O
identical	O
(	O
i.e	O
.	O
,	O
gradient	O
-	O
wise	O
)	O
.	O
	
To	O
exploit	O
this	O
property	O
,	O
we	O
index	O
atomic	O
patches	O
with	O
a	O
small	O
set	O
of	O
patch	O
prototypes	O
.	O
	
We	O
substitute	O
each	O
patch	O
with	O
its	O
closest	O
neighbor	O
in	O
a	O
fixed	O
dictionary	O
of	O
prototypes	O
.	O
	
Hence	O
,	O
we	O
need	O
to	O
perform	O
and	O
store	O
only	O
convolutions	O
at	O
the	O
first	O
level	O
,	O
instead	O
of	O
(	O
with	O
)	O
.	O
	
This	O
significantly	O
reduces	O
both	O
memory	B-Metric
and	I-Metric
time	I-Metric
complexity	I-Metric
.	O
	
Note	O
that	O
higher	O
pyramid	O
levels	O
also	O
benefit	O
from	O
this	O
optimization	O
.	O
	
Indeed	O
,	O
two	O
parent	O
patches	O
at	O
the	O
second	O
level	O
have	O
the	O
exact	O
same	O
correlation	O
map	O
in	O
case	O
their	O
children	O
are	O
assigned	O
the	O
same	O
prototypes	O
.	O
	
The	O
same	O
reasoning	O
also	O
holds	O
for	O
all	O
subsequent	O
levels	O
,	O
but	O
the	O
gains	O
rapidly	O
diminish	O
due	O
to	O
statistical	O
unlikeliness	O
of	O
the	O
required	O
condition	O
.	O
	
This	O
is	O
not	O
really	O
an	O
issue	O
,	O
since	O
the	O
memory	B-Metric
and	I-Metric
computational	I-Metric
cost	I-Metric
mostly	O
rests	O
on	O
the	O
initial	O
levels	O
;	O
see	O
Section	O
[	O
reference	O
]	O
.	O
	
In	O
practice	O
,	O
we	O
build	O
the	O
prototype	B-Method
dictionary	I-Method
using	O
k	B-Method
-	I-Method
means	I-Method
,	O
as	O
it	O
is	O
designed	O
to	O
minimize	O
the	O
approximation	O
error	O
between	O
input	O
descriptors	O
and	O
resulting	O
centroids	O
(	O
i.e	O
.	O
prototypes	O
)	O
.	O
	
Given	O
a	O
pair	O
of	O
images	O
to	O
match	O
,	O
we	O
perform	O
on	O
-	O
line	B-Method
clustering	I-Method
of	O
all	O
descriptors	B-Method
of	I-Method
atomic	I-Method
patches	I-Method
in	O
the	O
first	O
image	O
.	O
	
Since	O
the	O
original	O
descriptors	O
lie	O
on	O
an	O
hypersphere	O
(	O
each	O
pixel	B-Method
descriptor	I-Method
has	O
norm	O
1	O
)	O
,	O
we	O
modify	O
the	O
k	B-Method
-	I-Method
means	I-Method
approach	I-Method
so	O
as	O
to	O
project	O
the	O
estimated	O
centroids	O
on	O
the	O
hypersphere	O
at	O
each	O
iteration	O
.	O
	
We	O
find	O
experimentally	O
that	O
this	O
is	O
important	O
to	O
obtain	O
good	O
results	O
.	O
	
subsection	O
:	O
Scale	O
and	O
rotation	O
invariant	O
DeepMatching	B-Method
	
For	O
a	O
variety	O
of	O
tasks	O
,	O
objects	O
to	O
be	O
matched	O
can	O
appear	O
under	O
image	O
rotations	O
or	O
at	O
different	O
scales	O
Lowe2004	O
,	O
Mikolajczyk2005	O
,	O
Szeliski2010	O
,	O
HaCohen2011	O
.	O
	
As	O
discussed	O
above	O
,	O
DeepMatching	B-Method
(	O
DM	B-Method
)	O
is	O
only	O
robust	O
to	O
moderate	O
scale	O
changes	O
and	O
rotations	O
.	O
	
We	O
now	O
present	O
a	O
scale	B-Method
and	I-Method
rotation	I-Method
invariant	I-Method
version	I-Method
.	O
	
The	O
approach	O
is	O
straightforward	O
:	O
we	O
apply	O
DM	B-Method
to	O
several	O
rotated	O
and	O
scaled	O
versions	O
of	O
the	O
second	O
image	O
.	O
	
According	O
to	O
the	O
invariance	O
range	O
of	O
DM	B-Method
,	O
we	O
use	O
steps	O
of	O
for	O
image	B-Task
rotation	I-Task
and	O
power	O
of	O
for	O
scale	O
changes	O
.	O
	
While	O
iterating	O
over	O
all	O
combinations	O
of	O
scale	O
changes	O
and	O
rotations	O
,	O
we	O
maintain	O
a	O
list	O
of	O
all	O
atomic	O
correspondences	O
obtained	O
so	O
far	O
,	O
i.e	O
.	O
	
corresponding	O
positions	O
and	O
scores	O
.	O
	
As	O
before	O
,	O
the	O
final	O
output	O
correspondences	O
consists	O
of	O
the	O
reciprocal	O
matches	O
in	O
.	O
	
Storing	O
all	O
matches	O
and	O
finally	O
choosing	O
the	O
best	O
ones	O
based	O
on	O
reciprocal	B-Task
verification	I-Task
permits	O
to	O
capture	O
distinct	O
motions	O
possibly	O
occurring	O
together	O
in	O
the	O
same	O
scene	O
(	O
e.g	O
.	O
one	O
object	O
could	O
have	O
undergone	O
a	O
rotation	O
,	O
while	O
the	O
rest	O
of	O
the	O
scene	O
did	O
not	O
move	O
)	O
.	O
	
The	O
steps	O
of	O
the	O
approach	O
are	O
described	O
in	O
Algorithm	O
[	O
reference	O
]	O
.	O
	
Since	O
we	O
iterate	O
sequentially	O
over	O
a	O
fixed	O
list	O
of	O
rotations	O
and	O
scale	O
changes	O
,	O
the	O
space	B-Metric
and	I-Metric
time	I-Metric
complexity	I-Metric
of	O
the	O
algorithm	O
remains	O
unchanged	O
(	O
i.e	O
.	O
)	O
.	O
	
In	O
practice	O
,	O
the	O
run	B-Metric
-	I-Metric
time	I-Metric
compared	O
to	O
DM	B-Method
is	O
multiplied	O
by	O
a	O
constant	O
approximately	O
equal	O
to	O
25	O
,	O
see	O
Section	O
[	O
reference	O
]	O
.	O
	
Note	O
that	O
the	O
algorithm	O
permits	O
a	O
straightforward	O
parallelization	O
.	O
	
Input	O
:	O
,	O
are	O
the	O
images	O
to	O
be	O
matched	O
Initialize	O
an	O
empty	O
set	O
of	O
correspondences	O
	
For	O
do	O
#	O
either	O
downsize	O
image	O
1	O
#	O
or	O
downsize	O
image	O
2	O
For	O
∈θ{0	O
,	O
⁢π4	O
…	O
,	O
⁢7π4	O
}	O
	
do	O
#	O
get	O
raw	O
atomic	O
correspondences	O
	
(	O
Eq	O
.	O
(	O
)	O
)	O
	
#	O
Geometric	B-Method
rectification	I-Method
to	O
the	O
input	O
image	O
space	O
:	O
	
#	O
Concatenate	O
results	O
:	O
	
#	O
keep	O
reciprocal	O
matches	O
(	O
Eq	O
.	O
(	O
)	O
)	O
	
Return	O
Scale	O
and	O
rotation	O
invariant	O
version	O
of	O
DeepMatching	B-Method
(	O
DM	B-Method
)	O
.	O
	
Iσ	O
denotes	O
the	O
image	O
I	O
downsized	O
by	O
a	O
factor	O
σ	O
,	O
and	O
Rθ	O
denotes	O
rotation	O
by	O
an	O
angle	O
θ	O
.	O
	
subsection	O
:	O
DeepFlow	B-Method
	
We	O
now	O
present	O
our	O
approach	O
for	O
optical	B-Task
flow	I-Task
estimation	I-Task
,	O
DeepFlow	B-Task
.	O
	
We	O
adopt	O
the	O
method	O
introduced	O
by	O
[	O
]	O
,	O
where	O
a	O
matching	B-Method
term	I-Method
penalizes	O
the	O
differences	O
between	O
optical	O
flow	O
and	O
input	O
matches	O
,	O
and	O
replace	O
their	O
matching	B-Method
approach	I-Method
by	O
DeepMatching	B-Method
.	O
	
In	O
addition	O
,	O
we	O
make	O
a	O
few	O
minor	O
modifications	O
introduced	O
recently	O
in	O
the	O
state	O
of	O
the	O
art	O
:	O
(	O
i	O
)	O
we	O
add	O
a	O
normalization	B-Method
in	O
the	O
data	O
term	O
to	O
downweight	O
the	O
impact	O
of	O
locations	O
with	O
high	O
spatial	O
image	O
derivatives	O
(	O
ii	O
)	O
we	O
use	O
a	O
different	O
weight	O
at	O
each	O
level	O
to	O
downweight	O
the	O
matching	B-Method
term	I-Method
at	O
finer	O
scales	O
and	O
(	O
iii	O
)	O
the	O
smoothness	O
term	O
is	O
locally	O
weighted	O
	
Let	O
be	O
two	O
consecutive	O
images	O
defined	O
on	O
with	O
channels	O
.	O
	
The	O
goal	O
is	O
to	O
estimate	O
the	O
flow	O
.	O
	
We	O
assume	O
that	O
the	O
images	O
are	O
already	O
smoothed	O
using	O
a	O
Gaussian	B-Method
filter	I-Method
of	I-Method
standard	I-Method
deviation	I-Method
.	O
	
The	O
energy	O
we	O
optimize	O
is	O
a	O
weighted	B-Method
sum	I-Method
of	O
a	O
data	O
term	O
,	O
a	O
smoothness	O
term	O
and	O
a	O
matching	B-Method
term	I-Method
:	O
For	O
the	O
three	O
terms	O
,	O
we	O
use	O
a	O
robust	B-Method
penalizer	I-Method
with	O
which	O
has	O
shown	O
excellent	O
results	O
Sun2014	O
.	O
	
paragraph	O
:	O
Data	O
term	O
.	O
	
The	O
data	B-Method
term	I-Method
is	O
a	O
separate	O
penalization	O
of	O
the	O
color	O
and	O
gradient	O
constancy	O
assumptions	O
with	O
a	O
normalization	O
factor	O
as	O
proposed	O
by	O
.	O
	
We	O
start	O
from	O
the	O
optical	O
flow	O
constraint	O
assuming	O
brightness	O
constancy	O
:	O
the	O
spatio	O
-	O
temporal	O
gradient	O
.	O
	
A	O
basic	O
way	O
to	O
build	O
a	O
data	O
term	O
is	O
to	O
penalize	O
it	O
,	O
i.e	O
.	O
with	O
the	O
tensor	O
defined	O
by	O
.	O
	
As	O
highlighted	O
by	O
,	O
such	O
a	O
data	B-Method
term	I-Method
adds	O
a	O
higher	O
weight	O
in	O
locations	O
corresponding	O
to	O
high	O
spatial	O
image	O
derivatives	O
.	O
	
We	O
normalize	O
it	O
by	O
the	O
norm	O
of	O
the	O
spatial	O
derivatives	O
plus	O
a	O
small	O
factor	O
to	O
avoid	O
division	O
by	O
zero	O
,	O
and	O
to	O
reduce	O
a	O
bit	O
the	O
influence	O
in	O
tiny	O
gradient	O
locations	O
Zimmer2011	O
.	O
	
Let	O
be	O
the	O
normalized	O
tensor	O
with	O
.	O
	
We	O
set	O
in	O
the	O
following	O
.	O
	
To	O
deal	O
with	O
color	O
images	O
,	O
we	O
consider	O
the	O
tensor	O
defined	O
for	O
a	O
channel	O
denoted	O
by	O
upper	O
indices	O
and	O
we	O
penalize	O
the	O
sum	O
over	O
channels	O
:	O
.	O
	
We	O
consider	O
images	O
in	O
the	O
RGB	O
color	O
space	O
.	O
	
We	O
separately	O
penalize	O
the	O
gradient	O
constancy	O
assumption	O
Bruhn2005	O
.	O
	
Let	O
and	O
be	O
the	O
derivatives	O
of	O
the	O
images	O
with	O
respect	O
to	O
the	O
and	O
axis	O
respectively	O
.	O
	
Let	O
be	O
the	O
tensor	O
for	O
the	O
channel	O
including	O
the	O
normalization	O
The	O
data	O
term	O
is	O
the	O
sum	O
of	O
two	O
terms	O
,	O
balanced	O
by	O
two	O
weights	O
and	O
:	O
	
paragraph	O
:	O
Smoothness	O
term	O
.	O
	
The	O
smoothness	O
term	O
is	O
a	O
robust	B-Method
penalization	I-Method
of	O
the	O
gradient	B-Method
flow	I-Method
norm	I-Method
:	O
The	O
smoothness	O
weight	O
α	O
is	O
locally	O
set	O
according	O
to	O
image	O
derivatives	O
with	O
=	O
⁢α	O
(	O
x	O
)	O
exp	O
(-	O
⁢κ∇2I	O
(	O
x	O
)	O
)	O
where	O
κ	O
is	O
experimentally	O
set	O
to	O
=	O
κ5	O
.	O
	
paragraph	O
:	O
Matching	O
term	O
.	O
	
The	O
matching	B-Method
term	I-Method
encourages	O
the	O
flow	B-Task
estimation	I-Task
to	O
be	O
similar	O
to	O
a	O
precomputed	B-Method
vector	I-Method
field	I-Method
.	O
	
To	O
this	O
end	O
,	O
we	O
penalize	O
the	O
difference	O
between	O
and	O
using	O
the	O
robust	B-Method
penalizer	I-Method
.	O
	
Since	O
the	O
matching	B-Method
is	O
not	O
totally	O
dense	O
,	O
we	O
add	O
a	O
binary	O
term	O
which	O
is	O
equal	O
to	O
if	O
and	O
only	O
if	O
a	O
match	O
is	O
available	O
at	O
.	O
	
We	O
also	O
multiply	O
each	O
matching	B-Method
penalization	O
by	O
a	O
weight	O
,	O
which	O
is	O
low	O
in	O
uniform	O
regions	O
where	O
matching	B-Method
is	O
ambiguous	O
and	O
when	O
matched	O
patches	O
are	O
dissimilar	O
.	O
	
To	O
that	O
aim	O
,	O
we	O
rely	O
on	O
,	O
the	O
minimum	O
eigenvalue	O
of	O
the	O
autocorrelation	O
matrix	O
multiplied	O
by	O
.	O
	
We	O
also	O
compute	O
the	O
visual	O
similarity	O
between	O
matches	O
as	O
.	O
	
We	O
then	O
compute	O
the	O
score	O
as	O
a	O
Gaussian	B-Method
kernel	I-Method
on	O
weighted	O
by	O
with	O
a	O
parameter	O
,	O
experimentally	O
set	O
to	O
.	O
	
More	O
precisely	O
,	O
we	O
define	O
at	O
each	O
point	O
with	O
a	O
match	O
as	O
:	O
The	O
matching	B-Method
term	O
is	O
then	O
.	O
	
paragraph	O
:	O
Minimization	B-Task
.	O
	
This	O
energy	O
objective	O
is	O
non	O
-	O
convex	O
and	O
non	O
-	O
linear	O
.	O
	
To	O
solve	O
it	O
,	O
we	O
use	O
a	O
numerical	B-Method
optimization	I-Method
algorithm	I-Method
similar	O
as	O
.	O
	
An	O
incremental	B-Method
coarse	I-Method
-	I-Method
to	I-Method
-	I-Method
fine	I-Method
warping	I-Method
strategy	I-Method
is	O
used	O
with	O
a	O
downsampling	O
factor	O
.	O
	
The	O
remaining	O
equations	O
are	O
still	O
non	O
-	O
linear	O
due	O
to	O
the	O
robust	B-Method
penalizers	I-Method
.	O
	
We	O
apply	O
5	O
inner	B-Method
fixed	I-Method
point	I-Method
iterations	I-Method
where	O
the	O
non	O
-	O
linear	O
weights	O
and	O
the	O
flow	O
increments	O
are	O
iteratively	O
updated	O
while	O
fixing	O
the	O
other	O
.	O
	
To	O
approximate	O
the	O
solution	O
of	O
the	O
linear	B-Task
system	I-Task
,	O
we	O
use	O
25	O
iterations	O
of	O
the	O
Successive	B-Method
Over	I-Method
Relaxation	I-Method
(	I-Method
SOR	I-Method
)	I-Method
method	I-Method
Young	O
:	O
sor	B-Method
.	O
	
To	O
downweight	O
the	O
matching	B-Method
term	O
on	O
fine	O
scales	O
,	O
we	O
use	O
a	O
different	O
weight	O
at	O
each	O
level	O
as	O
proposed	O
by	O
.	O
	
We	O
set	O
where	O
k	O
is	O
the	O
current	O
level	O
of	O
computation	O
,	O
kmax	O
the	O
coarsest	O
level	O
and	O
b	O
a	O
parameter	O
which	O
is	O
optimized	O
together	O
with	O
the	O
other	O
parameters	O
,	O
see	O
Section	O
.	O
	
section	O
:	O
Experiments	O
	
This	O
section	O
presents	O
an	O
experimental	O
evaluation	O
of	O
DeepMatching	B-Method
and	O
DeepFlow	B-Method
.	O
	
The	O
datasets	O
and	O
metrics	O
used	O
to	O
evaluate	O
DeepMatching	B-Method
and	O
DeepFlow	B-Method
are	O
introduced	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Experimental	O
results	O
are	O
given	O
in	O
Sections	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
respectively	O
.	O
	
subsection	O
:	O
Datasets	O
and	O
metrics	O
	
In	O
this	O
section	O
we	O
briefly	O
introduce	O
the	O
matching	B-Method
and	O
flow	O
datasets	O
used	O
in	O
our	O
experiments	O
.	O
	
Since	O
consecutive	O
frames	O
of	O
a	O
video	O
are	O
well	O
-	O
suited	O
to	O
evaluate	O
a	O
matching	B-Method
approach	I-Method
,	O
we	O
use	O
several	O
optical	O
flow	O
datasets	O
for	O
evaluating	O
both	O
the	O
quality	O
of	O
matching	B-Method
and	O
flow	B-Task
,	O
but	O
we	O
rely	O
on	O
different	O
metrics	O
.	O
	
paragraph	O
:	O
The	O
Mikolajczyk	B-Material
dataset	O
	
was	O
originally	O
proposed	O
by	O
to	O
evaluate	O
and	O
compare	O
the	O
performance	O
of	O
keypoint	B-Method
detectors	I-Method
and	O
descriptors	B-Method
.	O
	
It	O
is	O
one	O
of	O
the	O
standard	O
benchmarks	O
for	O
evaluating	O
matching	B-Method
approaches	I-Method
.	O
	
The	O
dataset	O
consists	O
of	O
8	O
sequences	O
of	O
6	O
images	O
each	O
viewing	O
a	O
scene	O
under	O
different	O
conditions	O
,	O
such	O
as	O
illumination	O
changes	O
or	O
viewpoint	O
changes	O
.	O
	
The	O
images	O
of	O
a	O
sequence	O
are	O
related	O
by	O
homographies	O
.	O
	
During	O
the	O
evaluation	O
,	O
we	O
comply	O
to	O
the	O
standard	O
procedure	O
in	O
which	O
the	O
first	O
image	O
of	O
each	O
scene	O
is	O
matched	O
to	O
the	O
5	O
remaining	O
ones	O
.	O
	
Since	O
our	O
goal	O
is	O
to	O
study	O
robustness	B-Metric
of	O
DeepMatching	B-Method
to	O
geometric	O
distortions	O
,	O
we	O
follow	O
and	O
restrict	O
our	O
evaluation	O
to	O
the	O
4	O
most	O
difficult	O
sequences	O
with	O
viewpoint	O
changes	O
:	O
bark	O
,	O
boat	O
,	O
graf	O
and	O
wall	O
.	O
	
paragraph	O
:	O
The	O
MPI	B-Material
-	I-Material
Sintel	I-Material
dataset	O
sintel	O
	
is	O
a	O
challenging	O
evaluation	B-Metric
benchmark	I-Metric
for	O
optical	B-Task
flow	I-Task
estimation	I-Task
,	O
constructed	O
from	O
realistic	O
computer	O
-	O
animated	O
films	O
.	O
	
The	O
dataset	O
contains	O
sequences	O
with	O
large	O
motions	O
and	O
specular	O
reflections	O
.	O
	
In	O
the	O
training	O
set	O
,	O
more	O
than	O
of	O
the	O
pixels	O
have	O
a	O
motion	O
over	O
pixels	O
,	O
approximately	O
over	O
pixels	O
.	O
	
We	O
use	O
the	O
‘	O
‘	O
final	O
’	O
’	O
version	O
,	O
featuring	O
rendering	O
effects	O
such	O
as	O
motion	O
blur	O
,	O
defocus	O
blur	O
and	O
atmospheric	O
effects	O
.	O
	
Note	O
that	O
ground	O
-	O
truth	O
optical	O
flows	O
for	O
the	O
test	O
set	O
are	O
not	O
publicly	O
available	O
.	O
	
paragraph	O
:	O
The	O
Middlebury	B-Material
dataset	O
middlebury	O
	
has	O
been	O
extensively	O
used	O
for	O
evaluating	O
optical	B-Method
flow	I-Method
methods	I-Method
.	O
	
The	O
dataset	O
contains	O
complex	O
motions	O
,	O
but	O
most	O
of	O
the	O
motions	O
are	O
small	O
.	O
	
Less	O
than	O
of	O
the	O
pixels	O
have	O
a	O
motion	O
over	O
pixels	O
,	O
and	O
no	O
motion	O
exceeds	O
pixels	O
(	O
training	O
set	O
)	O
.	O
	
Ground	O
-	O
truth	O
optical	O
flows	O
for	O
the	O
test	O
set	O
are	O
not	O
publicly	O
available	O
.	O
	
paragraph	O
:	O
The	O
Kitti	B-Material
dataset	O
	
contains	O
real	O
-	O
world	O
sequences	O
taken	O
from	O
a	O
driving	B-Method
platform	I-Method
.	O
	
The	O
dataset	O
includes	O
non	O
-	O
Lambertian	O
surfaces	O
,	O
different	O
lighting	O
conditions	O
,	O
a	O
large	O
variety	O
of	O
materials	O
and	O
large	O
displacements	O
.	O
	
More	O
than	O
16	O
%	O
of	O
the	O
pixels	O
have	O
motion	O
over	O
20	O
pixels	O
.	O
	
Again	O
,	O
ground	O
-	O
truth	O
optical	O
flows	O
for	O
the	O
test	O
set	O
are	O
not	O
publicly	O
available	O
.	O
	
paragraph	O
:	O
Performance	B-Metric
metric	I-Metric
for	O
matching	B-Method
.	O
	
Choosing	O
a	O
performance	B-Metric
measure	I-Metric
for	O
matching	B-Method
approaches	I-Method
is	O
delicate	O
.	O
	
Matching	B-Method
approaches	I-Method
typically	O
do	O
not	O
return	O
dense	O
correspondences	O
,	O
but	O
output	O
varying	O
numbers	O
of	O
matches	O
.	O
	
Furthermore	O
,	O
correspondences	O
might	O
be	O
concentrated	O
in	O
different	O
areas	O
of	O
the	O
image	O
.	O
	
Most	O
matching	B-Method
approaches	I-Method
,	O
including	O
DeepMatching	B-Method
,	O
are	O
based	O
on	O
establishing	O
correspondences	O
between	O
patches	O
.	O
	
Given	O
a	O
pair	O
of	O
matching	B-Method
patches	O
,	O
it	O
is	O
possible	O
to	O
obtain	O
a	O
list	O
of	O
pixel	O
correspondences	O
for	O
all	O
pixels	O
within	O
the	O
patches	O
.	O
	
We	O
introduce	O
a	O
measure	O
based	O
on	O
the	O
number	O
of	O
correctly	O
matched	O
pixels	O
compared	O
to	O
the	O
overall	O
number	O
of	O
pixels	O
.	O
	
We	O
define	O
‘	O
	
‘	O
	
accuracy@	B-Metric
’’	O
as	O
the	O
proportion	O
of	O
‘	O
	
‘	O
correct	O
’	O
’	O
pixels	O
from	O
the	O
first	O
image	O
with	O
respect	O
to	O
the	O
total	O
number	O
of	O
pixels	O
.	O
	
A	O
pixel	O
is	O
considered	O
correct	O
if	O
its	O
pixel	O
match	O
in	O
the	O
second	O
image	O
is	O
closer	O
than	O
pixels	O
to	O
ground	O
-	O
truth	O
.	O
	
In	O
practice	O
,	O
we	O
use	O
a	O
threshold	O
of	O
pixels	O
,	O
as	O
this	O
represents	O
a	O
sufficiently	O
precise	O
estimation	O
(	O
about	O
1	O
%	O
of	O
image	O
diagonal	O
for	O
all	O
datasets	O
)	O
,	O
while	O
allowing	O
some	O
tolerance	O
in	O
blurred	O
areas	O
that	O
are	O
difficult	O
to	O
match	O
exactly	O
.	O
	
If	O
a	O
pixel	O
belongs	O
to	O
several	O
matches	O
,	O
we	O
choose	O
the	O
one	O
with	O
the	O
highest	O
score	O
to	O
predict	O
its	O
correspondence	O
.	O
	
Pixels	O
which	O
do	O
not	O
belong	O
to	O
any	O
patch	O
have	O
an	O
infinite	O
error	O
.	O
	
paragraph	O
:	O
Performance	B-Metric
metric	I-Metric
for	O
optical	B-Task
flow	I-Task
.	O
	
To	O
evaluate	O
optical	B-Task
flow	I-Task
,	O
we	O
follow	O
the	O
standard	O
protocol	O
and	O
measure	O
the	O
average	B-Metric
endpoint	I-Metric
error	I-Metric
over	O
all	O
pixels	O
,	O
denoted	O
as	O
‘	O
‘	O
EPE	B-Metric
’	O
’	O
.	O
	
The	O
‘	O
‘	O
s10	O
-	O
40	O
’	O
’	O
variant	O
measures	O
the	O
EPE	B-Method
only	O
for	O
pixels	O
with	O
a	O
ground	O
-	O
truth	O
displacement	O
between	O
10	O
and	O
40	O
pixels	O
,	O
and	O
likewise	O
for	O
‘	O
‘	O
s0	O
-	O
10	O
’	O
’	O
and	O
‘	O
‘	O
s40	O
+	O
’	O
’	O
.	O
	
In	O
all	O
cases	O
,	O
scores	O
are	O
averaged	O
over	O
all	O
image	O
pairs	O
to	O
yield	O
the	O
final	O
result	O
for	O
a	O
given	O
dataset	O
.	O
	
subsection	O
:	O
Matching	B-Task
Experiments	O
	
In	O
this	O
section	O
,	O
we	O
evaluate	O
DeepMatching	B-Method
(	O
DM	B-Method
)	O
.	O
	
We	O
present	O
results	O
for	O
all	O
datasets	O
presented	O
above	O
but	O
Middlebury	B-Material
,	O
which	O
does	O
not	O
feature	O
long	O
-	O
range	O
motions	O
,	O
the	O
main	O
difficulty	O
in	O
image	O
matching	B-Method
.	O
	
When	O
evaluating	O
on	O
the	O
Mikolajczyk	B-Material
dataset	O
,	O
we	O
employ	O
the	O
scale	O
and	O
rotation	O
invariant	O
version	O
of	O
DM	B-Method
presented	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
For	O
all	O
the	O
matching	B-Method
experiments	O
reported	O
in	O
this	O
section	O
,	O
we	O
use	O
the	O
Mikolajczyk	B-Material
dataset	O
and	O
the	O
training	O
sets	O
of	O
MPI	B-Material
-	I-Material
Sintel	I-Material
and	O
Kitti	B-Material
.	O
	
subsubsection	O
:	O
Impact	O
of	O
the	O
parameters	O
	
We	O
optimize	O
the	O
different	O
parameters	O
of	O
DM	B-Method
jointly	O
on	O
all	O
datasets	O
.	O
	
To	O
prevent	O
overfitting	O
,	O
we	O
use	O
the	O
same	O
parameters	O
across	O
all	O
datasets	O
.	O
	
paragraph	O
:	O
Pixel	O
descriptor	O
parameters	O
:	O
	
We	O
first	O
optimize	O
the	O
parameters	O
of	O
the	O
pixel	B-Method
representation	I-Method
(	O
Section	O
)	O
:	O
ν1	O
,	O
ν2	O
,	O
ν3	O
(	O
different	O
smoothing	O
stages	O
)	O
,	O
ς	O
(	O
sigmoid	O
slope	O
)	O
and	O
μ	O
(	O
regularization	O
constant	O
)	O
.	O
	
After	O
performing	O
a	O
grid	B-Task
search	I-Task
,	O
we	O
find	O
that	O
good	O
results	O
are	O
obtained	O
at	O
ν1=ν2=ν3=1	O
,	O
=	O
ς0.2	O
and	O
=	O
μ0.3	O
across	O
all	O
datasets	O
.	O
	
Figure	O
shows	O
the	O
accuracy@10	B-Metric
in	O
the	O
neighborhood	O
of	O
these	O
values	O
for	O
all	O
parameters	O
.	O
	
Image	B-Task
pre	I-Task
-	I-Task
smoothing	I-Task
seems	O
to	O
be	O
crucial	O
for	O
JPEG	B-Material
images	I-Material
(	O
Mikolajczyk	B-Material
dataset	O
)	O
,	O
as	O
it	O
smooths	O
out	O
compression	O
artifacts	O
,	O
whereas	O
it	O
slightly	O
degrades	O
performance	O
for	O
uncompressed	B-Material
PNG	I-Material
images	I-Material
(	O
MPI	B-Material
-	I-Material
Sintel	I-Material
and	O
Kitti	B-Material
)	O
.	O
	
As	O
expected	O
,	O
similar	O
findings	O
are	O
observed	O
for	O
the	O
regularization	O
constant	O
μ	O
since	O
it	O
acts	O
as	O
a	O
regularizer	B-Method
that	O
reduces	O
the	O
impact	O
of	O
small	O
gradients	O
(	O
i.e.	O
noise	O
)	O
.	O
	
In	O
the	O
following	O
,	O
we	O
thus	O
use	O
low	O
values	O
of	O
ν1	O
and	O
μ	O
when	O
dealing	O
with	O
PNG	B-Material
images	I-Material
(	O
we	O
set	O
=	O
ν10	O
and	O
=	O
	
μ0.1	O
,	O
other	O
parameters	O
are	O
unchanged	O
)	O
.	O
	
paragraph	O
:	O
Non	B-Task
-	I-Task
linear	I-Task
rectification	I-Task
:	O
	
We	O
also	O
evaluate	O
the	O
impact	O
of	O
the	O
parameter	O
of	O
the	O
non	O
-	O
linear	O
rectification	O
obtained	O
by	O
applying	O
power	B-Method
normalization	I-Method
,	O
see	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
	
Figure	O
[	O
reference	O
]	O
displays	O
the	O
accuracy@10	B-Metric
for	O
various	O
values	O
of	O
.	O
	
We	O
can	O
observe	O
that	O
the	O
optimal	O
performance	O
is	O
achieved	O
at	O
for	O
all	O
datasets	O
.	O
	
We	O
use	O
this	O
value	O
in	O
the	O
remainder	O
of	O
our	O
experiments	O
.	O
	
subsubsection	O
:	O
Evaluation	O
of	O
the	O
backtracking	B-Method
and	I-Method
scoring	I-Method
schemes	I-Method
	
We	O
now	O
evaluate	O
two	O
improvements	O
of	O
DM	B-Method
with	O
respect	O
to	O
the	O
previous	O
version	O
published	O
in	O
[	O
]	O
,	O
referred	O
to	O
as	O
DM	B-Method
*	O
:	O
Backtracking	O
	
(	O
BT	O
)	O
entry	O
points	O
:	O
in	O
DM	B-Method
*	O
we	O
select	O
as	O
entry	O
points	O
local	O
maxima	O
in	O
the	O
correlation	O
maps	O
from	O
all	O
pyramid	O
levels	O
.	O
	
The	O
new	O
alternative	O
is	O
to	O
start	O
from	O
all	O
possible	O
points	O
in	O
the	O
top	O
pyramid	O
level	O
.	O
	
Scoring	B-Method
scheme	I-Method
:	O
In	O
DM	B-Method
*	O
we	O
scored	O
atomic	O
correspondences	O
based	O
on	O
the	O
correlation	O
values	O
of	O
start	O
and	O
end	O
point	O
of	O
the	O
backtracking	O
path	O
.	O
	
The	O
new	O
scoring	B-Method
scheme	I-Method
is	O
the	O
sum	O
of	O
correlation	O
values	O
along	O
the	O
full	O
backtracking	O
path	O
.	O
	
We	O
report	O
results	O
for	O
the	O
different	O
variants	O
in	O
Table	O
on	O
each	O
dataset	O
.	O
	
The	O
first	O
two	O
rows	O
for	O
each	O
dataset	O
correspond	O
to	O
the	O
exact	O
settings	O
used	O
for	O
DM	B-Method
	
*	O
(	O
i.e.	O
with	O
an	O
image	O
resolution	O
of	O
1	O
/	O
4	O
and	O
1	O
/	O
2	O
)	O
.	O
	
We	O
observe	O
a	O
steady	O
increase	O
in	O
performance	O
on	O
all	O
datasets	O
when	O
we	O
add	O
the	O
new	O
scoring	B-Method
and	I-Method
backtracking	I-Method
approach	I-Method
.	O
	
We	O
can	O
observe	O
that	O
starting	O
from	O
all	O
possible	O
entry	O
points	O
in	O
the	O
top	O
pyramid	O
level	O
(	O
i.e.	O
considering	O
all	O
possible	O
translations	O
)	O
yields	O
slightly	O
better	O
results	O
than	O
starting	O
from	O
local	O
maxima	O
.	O
	
This	O
demonstrates	O
that	O
some	O
ground	O
-	O
truth	O
matches	O
are	O
not	O
covered	O
by	O
any	O
local	O
maximum	O
.	O
	
By	O
enumerating	O
all	O
possible	O
patch	O
translations	O
from	O
the	O
top	O
-	O
level	O
,	O
we	O
instead	O
ensure	O
to	O
fully	O
explore	O
the	O
space	O
of	O
all	O
possible	O
matches	O
.	O
	
Furthermore	O
,	O
it	O
is	O
interesting	O
to	O
note	O
that	O
memory	B-Metric
usage	I-Metric
and	O
run	B-Metric
-	I-Metric
time	I-Metric
significantly	O
decreases	O
when	O
using	O
the	O
new	O
options	O
.	O
	
This	O
is	O
because	O
(	O
1	O
)	O
searching	O
and	O
storing	O
local	O
maxima	O
(	O
which	O
are	O
exponentially	O
more	O
numerous	O
in	O
lower	O
pyramid	O
levels	O
)	O
is	O
not	O
necessary	O
anymore	O
,	O
and	O
(	O
2	O
)	O
the	O
new	O
scoring	B-Method
scheme	I-Method
allows	O
for	O
further	O
optimization	B-Task
,	O
i.e.	O
early	B-Task
pruning	I-Task
of	I-Task
backtracking	I-Task
paths	I-Task
(	O
Section	O
)	O
.	O
	
subsubsection	O
:	O
Approximate	O
DeepMatching	B-Method
	
We	O
now	O
evaluate	O
the	O
performance	O
of	O
approximate	O
DeepMatching	B-Method
(	O
Section	O
[	O
reference	O
]	O
)	O
and	O
report	O
its	O
run	B-Metric
-	I-Metric
time	I-Metric
and	I-Metric
memory	I-Metric
usage	I-Metric
.	O
	
We	O
evaluate	O
and	O
compare	O
two	O
different	O
ways	O
of	O
reducing	O
the	O
computational	B-Metric
load	I-Metric
.	O
	
The	O
first	O
one	O
simply	O
consists	O
in	O
downsizing	O
the	O
input	O
images	O
,	O
and	O
upscaling	O
the	O
resulting	O
matches	O
accordingly	O
.	O
	
The	O
second	O
option	O
is	O
the	O
compression	B-Method
scheme	I-Method
proposed	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
We	O
evaluate	O
both	O
schemes	O
jointly	O
by	O
varying	O
the	O
input	O
image	O
size	O
(	O
expressed	O
as	O
a	O
fraction	O
of	O
the	O
original	O
resolution	O
)	O
and	O
the	O
size	O
of	O
the	O
prototype	O
dictionary	O
(	O
i.e	O
.	O
parameter	O
of	O
k	B-Method
-	I-Method
means	I-Method
in	O
Section	O
[	O
reference	O
]	O
)	O
.	O
	
corresponds	O
to	O
the	O
original	O
dataset	O
image	O
size	O
(	O
no	O
downsizing	O
)	O
.	O
	
We	O
display	O
the	O
results	O
in	O
terms	O
of	O
matching	B-Method
accuracy	O
(	O
accuracy@10	B-Metric
)	O
against	O
memory	B-Metric
consumption	I-Metric
in	O
Figure	O
[	O
reference	O
]	O
and	O
as	O
a	O
function	O
of	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
that	O
DeepMatching	B-Method
can	O
be	O
computed	O
in	O
an	O
approximate	O
manner	O
for	O
any	O
given	O
memory	O
budget	O
.	O
	
Unsurprisingly	O
,	O
too	O
low	O
settings	O
(	O
e.g	O
.	O
,	O
)	O
result	O
in	O
a	O
strong	O
loss	O
of	O
performance	O
.	O
	
It	O
should	O
be	O
noted	O
that	O
that	O
we	O
were	O
unable	O
to	O
compute	O
DeepMatching	B-Method
at	O
full	O
resolution	O
(	O
for	O
,	O
as	O
the	O
memory	O
consumption	O
explodes	O
.	O
	
As	O
a	O
consequence	O
,	O
all	O
subsequent	O
experiments	O
in	O
the	O
paper	O
are	O
done	O
at	O
.	O
	
In	O
Figure	O
[	O
reference	O
]	O
,	O
we	O
observe	O
that	O
good	O
trades	O
-	O
off	O
are	O
achieved	O
for	O
dictionary	B-Metric
sizes	I-Metric
comprised	O
in	O
.	O
	
For	O
instance	O
,	O
on	O
MPI	B-Material
-	I-Material
Sintel	I-Material
,	O
at	O
,	O
94	O
%	O
of	O
the	O
performance	O
of	O
the	O
uncompressed	O
case	O
(	O
)	O
is	O
reached	O
for	O
half	O
the	O
computation	B-Metric
time	I-Metric
and	O
one	O
third	O
of	O
the	O
memory	O
usage	O
.	O
	
Detailed	O
timings	O
of	O
the	O
different	O
stages	O
of	O
DeepMatching	B-Method
are	O
given	O
in	O
Table	O
.	O
	
As	O
expected	O
,	O
only	O
the	O
bottom	B-Method
-	I-Method
up	I-Method
pass	I-Method
is	O
affected	O
by	O
the	O
approximation	B-Method
,	O
with	O
a	O
run	B-Metric
-	I-Metric
time	I-Metric
of	O
the	O
different	O
operations	O
involved	O
(	O
patch	O
correlations	O
,	O
max	B-Method
-	I-Method
pooling	I-Method
,	O
subsampling	B-Method
,	O
aggregation	B-Method
and	O
non	B-Method
-	I-Method
linear	I-Method
rectification	I-Method
)	O
roughly	O
proportional	O
to	O
D	O
(	O
or	O
to	O
|G4|	O
,	O
the	O
actual	O
number	O
of	O
atomic	O
patches	O
,	O
if	O
=	O
D∞	O
)	O
.	O
	
The	O
overhead	O
of	O
clustering	O
the	O
dictionary	O
prototypes	O
with	O
k	B-Method
-	I-Method
means	I-Method
appears	O
negligible	O
,	O
with	O
the	O
exception	O
of	O
the	O
largest	O
dictionary	O
size	O
(	O
)	O
for	O
which	O
it	O
induces	O
a	O
slightly	O
longer	O
run	B-Metric
-	I-Metric
time	I-Metric
than	O
in	O
the	O
uncompressed	O
case	O
.	O
	
Overall	O
,	O
the	O
proposed	O
method	O
for	O
approximating	O
DeepMatching	B-Method
is	O
highly	O
effective	O
.	O
	
paragraph	O
:	O
GPU	B-Method
Implementation	I-Method
.	O
	
We	O
have	O
implemented	O
DM	B-Method
on	O
GPU	B-Method
in	O
the	O
Caffe	B-Method
framework	I-Method
caffe	I-Method
.	O
	
Using	O
existing	O
Caffe	B-Method
layers	I-Method
like	O
ConvolutionLayer	B-Method
and	O
PoolingLayer	B-Method
,	O
the	O
implementation	O
is	O
straightforward	O
for	O
most	O
layers	O
.	O
	
We	O
had	O
to	O
specifically	O
code	O
a	O
few	O
layers	O
which	O
are	O
not	O
available	O
in	O
Caffe	O
	
(	O
e.g	O
.	O
	
the	O
backtracking	O
pass	O
)	O
.	O
	
For	O
the	O
aggregation	B-Method
layer	I-Method
which	O
consists	O
in	O
selecting	O
and	O
averaging	O
4	O
children	O
channels	O
out	O
of	O
many	O
channels	O
,	O
we	O
relied	O
on	O
the	O
sparse	B-Method
matrix	I-Method
multiplication	I-Method
in	O
the	O
cuSPARSE	B-Method
toolbox	I-Method
.	O
	
Detailed	O
timings	O
are	O
given	O
in	O
Table	O
[	O
reference	O
]	O
on	O
a	O
GeForce	B-Material
Titan	I-Material
X.	I-Material
	
Our	O
code	O
runs	O
in	O
about	O
0.2s	O
for	O
a	O
pair	O
of	O
MPI	B-Material
-	I-Material
Sintel	I-Material
image	O
.	O
	
As	O
expected	O
,	O
the	O
computation	B-Metric
bottleneck	I-Metric
essentially	O
lies	O
in	O
the	O
computation	O
of	O
bottom	O
-	O
level	O
patch	O
correlations	O
and	O
the	O
backtracking	O
pass	O
.	O
	
Note	O
that	O
computing	O
patch	B-Method
descriptors	I-Method
takes	O
significantly	O
more	O
time	O
,	O
in	O
proportion	O
,	O
than	O
on	O
CPU	O
:	O
it	O
takes	O
about	O
0.024s	O
	
=	O
11	O
%	O
of	O
total	O
time	O
(	O
not	O
shown	O
in	O
table	O
)	O
.	O
	
This	O
is	O
because	O
it	O
involves	O
a	O
succession	O
of	O
many	O
small	O
layers	O
(	O
image	B-Method
smoothing	I-Method
,	O
gradient	B-Method
extraction	I-Method
and	O
projection	O
,	O
etc	O
.	O
)	O
,	O
which	O
causes	O
overhead	O
and	O
is	O
rather	O
inefficient	O
.	O
	
subsubsection	O
:	O
Comparison	O
to	O
the	O
state	O
of	O
the	O
art	O
	
We	O
compare	O
DM	B-Method
with	O
several	O
baselines	O
and	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
matching	B-Method
algorithms	I-Method
,	O
namely	O
:	O
SIFT	B-Method
keypoints	O
extracted	O
with	O
DoG	B-Method
detector	I-Method
Lowe2004	O
and	O
matched	O
with	O
FLANN	B-Method
flann	I-Method
,	O
referred	O
to	O
as	O
SIFT	B-Method
-	I-Method
NN	I-Method
,	O
dense	B-Method
HOG	I-Method
matching	I-Method
,	O
followed	O
by	O
nearest	O
-	O
neighbor	O
matching	B-Method
with	O
reciprocal	B-Method
verification	I-Method
as	O
done	O
in	O
LDOF	B-Method
Bro11a	O
,	O
referred	O
to	O
as	O
HOG	B-Method
-	I-Method
NN	I-Method
,	O
Generalized	B-Method
PatchMatch	I-Method
(	O
GPM	B-Method
)	O
Barnes2010	O
,	O
with	O
default	O
parameters	O
,	O
32x32	O
patches	O
and	O
20	O
iterations	O
(	O
best	O
settings	O
in	O
our	O
experiments	O
)	O
,	O
Kd	B-Method
-	I-Method
tree	I-Method
PatchMatch	I-Method
(	O
KPM	B-Method
)	O
kpm	B-Method
,	O
an	O
improved	O
version	O
of	O
PatchMatch	B-Method
based	O
on	O
better	O
patch	B-Method
descriptors	I-Method
and	O
kd	B-Method
-	I-Method
trees	I-Method
optimized	O
for	O
correspondence	B-Task
propagation	I-Task
,	O
Non	O
-	O
Rigid	O
Dense	O
Correspondences	O
(	O
NRDC	O
)	O
	
HaCohen2011	O
,	O
an	O
improved	O
version	O
of	O
GPM	B-Method
based	O
on	O
a	O
multiscale	B-Method
iterative	I-Method
expansion	I-Method
/	O
contraction	B-Method
strategy	I-Method
,	O
SIFT	B-Method
-	O
flow	O
a	O
dense	O
matching	B-Method
algorithm	O
based	O
on	O
an	O
energy	B-Method
minimization	I-Method
where	O
pixels	O
are	O
represented	O
as	O
SIFT	B-Method
features	O
and	O
a	O
smoothness	O
term	O
is	O
incorporated	O
to	O
explicitly	O
preserve	O
spatial	O
discontinuities	O
Scale	O
-	O
less	O
SIFT	B-Method
(	O
SLS	B-Method
)	O
an	O
improvement	O
of	O
SIFT	B-Method
-	O
flow	O
to	O
handle	O
scale	O
changes	O
(	O
multiple	O
sized	O
SIFTs	O
are	O
extracted	O
and	O
combined	O
to	O
form	O
a	O
scale	B-Method
-	I-Method
invariant	I-Method
pixel	I-Method
representation	I-Method
)	O
	
DaisyFilterFlow	B-Method
(	O
DaisyFF	B-Method
)	O
a	O
dense	B-Method
matching	I-Method
approach	I-Method
that	O
combines	O
filter	B-Method
-	I-Method
based	I-Method
efficient	I-Method
flow	I-Method
inference	I-Method
and	O
the	O
Patch	B-Method
-	I-Method
Match	I-Method
fast	I-Method
search	I-Method
algorithm	I-Method
to	O
match	O
pixels	O
described	O
using	O
the	O
DAISY	B-Method
representation	I-Method
Deformable	I-Method
Pyramid	I-Method
Matching	I-Method
(	O
DSP	B-Method
)	O
a	O
dense	B-Method
matching	I-Method
approach	I-Method
based	O
on	O
a	O
coarse	O
-	O
to	O
-	O
fine	O
(	O
top	O
-	O
down	O
)	O
strategy	O
where	O
inference	B-Task
is	O
performed	O
with	O
(	O
inexact	O
)	O
	
loopy	O
belief	O
propagation	O
SIFT	B-Method
-	O
NN	O
,	O
HOG	B-Method
-	I-Method
NN	I-Method
and	O
DM	B-Method
output	O
sparse	O
matches	O
,	O
whereas	O
the	O
other	O
methods	O
output	O
fully	O
dense	O
correspondence	O
fields	O
.	O
	
SIFT	B-Method
keypoints	O
,	O
GPM	B-Method
,	O
NRDC	B-Method
and	O
DaisyFF	B-Method
are	O
scale	B-Method
and	I-Method
rotation	I-Method
invariant	I-Method
,	O
whereas	O
HOG	B-Method
-	I-Method
NN	I-Method
,	O
KPM	B-Method
,	O
SIFT	B-Method
-	O
flow	O
,	O
SLS	B-Method
and	O
DSP	B-Method
are	O
not	O
.	O
	
We	O
,	O
therefore	O
,	O
do	O
not	O
report	O
results	O
for	O
these	O
latter	O
methods	O
on	O
the	O
Mikolajczyk	B-Material
dataset	O
which	O
includes	O
image	O
rotations	O
and	O
scale	O
changes	O
.	O
	
Statistics	O
about	O
each	O
method	O
(	O
average	O
number	O
of	O
matches	O
per	O
image	O
and	O
their	O
coverage	O
)	O
are	O
reported	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Coverage	B-Task
is	O
computed	O
as	O
the	O
proportion	O
of	O
points	O
on	O
a	O
regular	O
grid	O
with	O
10	O
pixel	O
spacing	O
for	O
which	O
there	O
exists	O
a	O
correspondence	O
(	O
in	O
the	O
raw	O
output	O
of	O
the	O
considered	O
method	O
)	O
within	O
a	O
10	O
pixel	O
neighborhood	O
.	O
	
Thus	O
,	O
it	O
measures	O
how	O
well	O
matches	O
	
‘	O
	
‘	O
cover	O
’	O
’	O
the	O
image	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
that	O
DeepMatching	B-Method
outputs	O
2	O
to	O
7	O
times	O
more	O
matches	O
than	O
SIFT	B-Method
-	I-Method
NN	I-Method
and	O
a	O
comparable	O
number	O
to	O
HOG	B-Method
-	I-Method
NN	I-Method
.	O
	
Yet	O
,	O
the	O
coverage	O
for	O
DM	B-Task
matches	I-Task
is	O
much	O
higher	O
than	O
for	O
HOG	B-Method
-	I-Method
NN	I-Method
and	O
SIFT	B-Method
-	I-Method
NN	I-Method
.	O
	
This	O
shows	O
that	O
DM	B-Task
matches	I-Task
are	O
well	O
distributed	O
over	O
the	O
entire	O
image	O
,	O
which	O
is	O
not	O
the	O
case	O
for	O
HOG	B-Method
-	I-Method
NN	I-Method
and	O
SIFT	B-Method
-	I-Method
NN	I-Method
,	O
as	O
they	O
have	O
difficulties	O
estimating	O
matches	O
in	O
regions	O
with	O
weak	O
or	O
repetitive	O
textures	O
.	O
	
Quantitative	O
results	O
are	O
listed	O
in	O
Table	O
[	O
reference	O
]	O
,	O
and	O
qualitative	O
results	O
in	O
Figures	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
.	O
	
Overall	O
,	O
DM	B-Method
significantly	O
outperforms	O
all	O
other	O
methods	O
,	O
even	O
when	O
reduced	O
settings	O
are	O
used	O
(	O
e.g	O
.	O
for	O
image	O
resolution	O
and	O
prototypes	O
)	O
.	O
	
As	O
expected	O
,	O
SIFT	B-Method
-	I-Method
NN	I-Method
performs	O
rather	O
well	O
in	O
presence	O
of	O
global	B-Task
image	I-Task
transformation	I-Task
(	O
Mikolajczyk	B-Material
dataset	O
)	O
,	O
but	O
yields	O
the	O
worst	O
result	O
for	O
the	O
case	O
of	O
more	O
complex	O
motions	O
(	O
flow	O
datasets	O
)	O
.	O
	
Figures	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
illustrate	O
the	O
reason	O
:	O
SIFT	B-Method
’s	O
large	O
patches	O
are	O
way	O
too	O
coarse	O
to	O
follow	O
motion	O
boundaries	O
precisely	O
.	O
	
The	O
same	O
issue	O
also	O
holds	O
for	O
HOG	B-Method
-	I-Method
NN	I-Method
.	O
	
Methods	O
predicting	B-Task
dense	I-Task
correspondence	I-Task
fields	I-Task
return	O
a	O
more	O
precise	O
estimate	O
,	O
yet	O
most	O
of	O
them	O
(	O
KPM	B-Method
,	O
GPM	B-Method
,	O
SIFT	B-Method
-	O
flow	O
,	O
DSP	B-Method
)	O
are	O
not	O
robust	O
to	O
repetitive	O
textures	O
in	O
the	O
Kitti	B-Material
dataset	O
(	O
Figure	O
)	O
as	O
they	O
rely	O
on	O
weakly	O
discriminative	O
small	O
patches	O
.	O
	
Despite	O
this	O
limitation	O
,	O
SIFT	B-Method
-	O
flow	O
and	O
DSP	B-Method
are	O
still	O
able	O
to	O
perform	O
well	O
on	O
MPI	B-Material
-	I-Material
Sintel	I-Material
as	O
this	O
dataset	O
contains	O
little	O
scale	O
changes	O
.	O
	
Other	O
dense	B-Method
methods	I-Method
,	O
NRDC	B-Method
,	O
SLS	B-Method
and	O
DaisyFF	B-Method
,	O
can	O
handle	O
patches	O
of	O
different	O
sizes	O
and	O
thus	O
perform	O
better	O
on	O
Kitti	B-Material
.	O
	
But	O
in	O
turn	O
this	O
is	O
at	O
the	O
cost	O
of	O
reduced	O
performance	O
on	O
the	O
MPI	B-Material
-	I-Material
Sintel	I-Material
or	O
Mikolajczyk	B-Material
datasets	O
(	O
qualitative	O
results	O
are	O
in	O
Figure	O
)	O
.	O
	
In	O
conclusion	O
,	O
DM	B-Method
outperforms	O
all	O
other	O
methods	O
on	O
the	O
3	O
datasets	O
,	O
including	O
DSP	B-Method
which	O
also	O
relies	O
on	O
a	O
hierarchical	B-Method
matching	I-Method
.	O
	
In	O
terms	O
of	O
computing	O
resources	O
,	O
DeepMatching	B-Method
with	O
full	O
settings	O
(	O
,	O
)	O
is	O
one	O
of	O
the	O
most	O
costly	O
method	O
(	O
only	O
SLS	B-Method
and	O
DaisyFF	B-Method
require	O
the	O
same	O
order	O
of	O
memory	O
and	O
longer	O
run	B-Metric
-	I-Metric
time	I-Metric
)	O
.	O
	
The	O
scale	O
and	O
rotation	O
invariant	O
version	O
of	O
DM	B-Method
,	O
used	O
for	O
the	O
Mikolajczyk	B-Material
dataset	O
,	O
is	O
slow	O
compared	O
to	O
most	O
other	O
approaches	O
,	O
due	O
to	O
its	O
sequential	B-Method
processing	I-Method
(	O
i.e	O
.	O
treating	O
each	O
combination	O
of	O
rotation	O
and	O
scaling	O
sequentially	O
)	O
,	O
yet	O
yields	O
near	O
perfect	O
results	O
.	O
	
However	O
,	O
running	O
DM	B-Method
with	O
reduced	O
settings	O
is	O
very	O
competitive	O
to	O
the	O
other	O
approaches	O
.	O
	
On	O
MPI	B-Material
-	I-Material
Sintel	I-Material
and	O
Kitti	B-Material
,	O
for	O
instance	O
,	O
DM	B-Method
with	O
a	O
quarter	O
resolution	O
has	O
a	O
run	B-Metric
-	I-Metric
time	I-Metric
comparable	O
to	O
the	O
fastest	O
method	O
,	O
SIFT	B-Method
-	I-Method
NN	I-Method
,	O
with	O
a	O
reasonable	O
memory	B-Metric
usage	I-Metric
,	O
while	O
still	O
outperforming	O
nearly	O
all	O
methods	O
in	O
terms	O
of	O
the	O
accuracy@10	B-Metric
measure	I-Metric
.	O
	
Ground	O
-	O
truth	O
SIFT	B-Method
-	O
NN	O
GPM	B-Method
NRDC	O
DaisyFF	O
	
DeepMatching	B-Method
GT	O
SIFT	B-Method
-	O
NN	O
HOG	B-Method
-	I-Method
NN	I-Method
KPM	I-Method
GPM	I-Method
SIFT	I-Method
-	O
flow	O
SLS	O
DaisyFF	O
DSP	O
DM	B-Method
GT	O
	
SIFT	B-Method
-	O
NN	O
HOG	B-Method
-	I-Method
NN	I-Method
	
KPM	B-Method
GPM	I-Method
SIFT	I-Method
-	O
flow	O
SLS	O
DaisyFF	O
DSP	O
DM	B-Method
	
subsection	O
:	O
Optical	B-Task
Flow	I-Task
Experiments	I-Task
	
We	O
now	O
present	O
experimental	O
results	O
for	O
the	O
optical	B-Task
flow	I-Task
estimation	I-Task
.	O
	
Optical	B-Task
flow	I-Task
is	O
predicted	O
using	O
the	O
variational	B-Method
framework	I-Method
presented	O
in	O
Section	O
[	O
reference	O
]	O
that	O
takes	O
as	O
input	O
a	O
set	O
of	O
matches	O
.	O
	
In	O
the	O
following	O
,	O
we	O
evaluate	O
the	O
impact	O
of	O
DeepMatching	B-Method
against	O
other	O
matching	B-Method
methods	I-Method
,	O
and	O
compare	O
to	O
the	O
state	O
of	O
the	O
art	O
.	O
	
subsubsection	O
:	O
Optimization	O
of	O
the	O
parameters	O
	
We	O
optimize	O
the	O
parameters	O
of	O
DeepFlow	B-Method
on	O
a	O
subset	O
of	O
the	O
MPI	B-Material
-	I-Material
Sintel	I-Material
training	O
set	O
(	O
20	O
%	O
)	O
,	O
called	O
‘	O
‘	O
small	O
’	O
’	O
set	O
,	O
and	O
report	O
results	O
on	O
the	O
remaining	O
image	O
pairs	O
(	O
80	O
%	O
,	O
called	O
‘	O
	
‘	O
validation	O
set	O
’	O
’	O
)	O
and	O
on	O
the	O
training	O
sets	O
of	O
Kitti	B-Material
and	O
Middlebury	B-Material
.	O
	
Ground	O
-	O
truth	O
optical	O
flows	O
for	O
the	O
three	O
test	O
sets	O
are	O
not	O
publicly	O
available	O
,	O
in	O
order	O
to	O
prevent	O
parameter	B-Method
tuning	I-Method
on	O
the	O
test	O
set	O
.	O
	
We	O
first	O
optimize	O
the	O
different	O
flow	O
parameters	O
(	O
,	O
,	O
,	O
and	O
)	O
by	O
employing	O
a	O
gradient	B-Method
descent	I-Method
strategy	I-Method
with	O
multiple	O
initializations	O
followed	O
by	O
a	O
local	B-Method
grid	I-Method
search	I-Method
.	O
	
For	O
the	O
data	O
term	O
,	O
we	O
find	O
an	O
optimum	O
at	O
,	O
which	O
is	O
equivalent	O
to	O
removing	O
the	O
color	O
constancy	O
assumption	O
.	O
	
This	O
can	O
be	O
explained	O
by	O
the	O
fact	O
that	O
the	O
‘	O
‘	O
final	O
’	O
’	O
version	O
contains	O
atmospheric	O
effects	O
,	O
reflections	O
,	O
blurs	O
,	O
etc	O
.	O
	
The	O
remaining	O
parameters	O
are	O
optimal	O
at	O
,	O
,	O
,	O
.	O
	
These	O
parameters	O
are	O
used	O
in	O
the	O
remaining	O
of	O
the	O
experiments	O
for	O
DeepFlow	B-Method
,	O
i.e.	O
using	O
matches	O
obtained	O
with	O
DeepMatching	B-Method
,	O
except	O
when	O
reporting	O
results	O
on	O
Kitti	B-Material
and	O
Middlebury	B-Material
test	O
sets	O
in	O
Section	O
.	O
	
In	O
this	O
case	O
the	O
parameters	O
are	O
optimized	O
on	O
their	O
respective	O
training	O
set	O
.	O
	
subsubsection	O
:	O
Impact	O
of	O
the	O
matches	O
on	O
the	O
flow	O
	
We	O
examine	O
the	O
impact	O
of	O
different	O
matching	B-Method
methods	I-Method
on	O
the	O
flow	O
,	O
i.e	O
.	O
,	O
different	O
matches	O
are	O
used	O
in	O
DeepFlow	B-Method
,	O
see	O
Section	O
[	O
reference	O
]	O
.	O
	
For	O
all	O
matching	B-Method
approaches	I-Method
evaluated	O
in	O
the	O
previous	O
section	O
,	O
we	O
use	O
their	O
output	O
as	O
matching	B-Method
term	O
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
	
Because	O
these	O
approaches	O
may	O
output	O
matches	O
with	O
statistics	O
different	O
from	O
DM	B-Method
,	O
we	O
separately	O
optimize	O
the	O
flow	O
parameters	O
for	O
each	O
matching	B-Method
approach	I-Method
on	O
the	O
small	O
training	O
set	O
of	O
MPI	B-Material
-	I-Material
Sintel	I-Material
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
endpoint	B-Metric
error	I-Metric
,	O
averaged	O
over	O
all	O
pixels	O
.	O
	
Clearly	O
,	O
a	O
sufficiently	O
dense	O
and	O
accurate	O
matching	B-Method
like	O
DM	B-Method
allows	O
to	O
considerably	O
improve	O
the	O
flow	B-Task
estimation	I-Task
on	O
datasets	O
with	O
large	O
displacements	O
(	O
MPI	B-Material
-	I-Material
Sintel	I-Material
,	O
Kitti	B-Material
)	O
.	O
	
In	O
contrast	O
,	O
none	O
of	O
the	O
methods	O
presented	O
have	O
a	O
tangible	O
effect	O
on	O
the	O
Middlebury	B-Material
dataset	O
,	O
where	O
the	O
displacements	O
are	O
small	O
.	O
	
The	O
relatively	O
small	O
gains	O
achieved	O
by	O
SIFT	B-Method
-	I-Method
NN	I-Method
and	O
HOG	B-Method
-	I-Method
NN	I-Method
on	O
MPI	B-Material
-	I-Material
Sintel	I-Material
and	O
Kitti	B-Material
are	O
due	O
to	O
the	O
fact	O
that	O
a	O
lot	O
of	O
regions	O
with	O
large	O
displacements	O
are	O
not	O
covered	O
by	O
any	O
matches	O
,	O
such	O
as	O
the	O
sky	O
or	O
the	O
blurred	O
character	O
in	O
the	O
first	O
and	O
second	O
column	O
of	O
Figure	O
[	O
reference	O
]	O
.	O
	
Hence	O
,	O
SIFT	B-Method
-	I-Method
NN	I-Method
and	O
HOG	B-Method
-	I-Method
NN	I-Method
have	O
only	O
a	O
limited	O
impact	O
on	O
the	O
variational	B-Method
approach	I-Method
.	O
	
On	O
the	O
other	O
hand	O
,	O
the	O
gains	O
are	O
also	O
small	O
(	O
or	O
even	O
negative	O
)	O
for	O
the	O
dense	B-Method
methods	I-Method
despite	O
the	O
fact	O
that	O
they	O
output	O
significantly	O
more	O
correspondences	O
.	O
	
We	O
observe	O
for	O
these	O
methods	O
that	O
the	O
weight	O
of	O
the	O
matching	B-Method
term	O
tends	O
to	O
be	O
small	O
after	O
optimizing	O
the	O
parameters	O
,	O
thus	O
indicating	O
that	O
the	O
matches	O
are	O
found	O
unreliable	O
and	O
noisy	O
during	O
training	O
.	O
	
The	O
cause	O
is	O
clearly	O
visible	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
where	O
large	O
portions	O
containing	O
repetitive	O
textures	O
(	O
e.g	O
.	O
road	O
,	O
trees	O
)	O
are	O
incorrectly	O
matched	O
.	O
	
The	O
poor	O
quality	O
of	O
these	O
matches	O
even	O
leads	O
to	O
a	O
significant	O
drop	O
in	O
performance	O
on	O
the	O
Kitti	B-Material
dataset	O
.	O
	
In	O
contrast	O
,	O
DeepMatching	B-Method
generates	O
accurate	O
matches	O
well	O
covering	O
the	O
image	O
that	O
enable	O
to	O
boost	O
the	O
optical	B-Metric
flow	I-Metric
accuracy	I-Metric
in	O
case	O
of	O
large	O
displacements	O
.	O
	
Namely	O
,	O
we	O
observe	O
a	O
relative	O
improvement	O
of	O
30	O
%	O
on	O
MPI	B-Material
-	I-Material
Sintel	I-Material
and	O
of	O
50	O
%	O
on	O
Kitti	B-Material
.	O
	
It	O
is	O
interesting	O
to	O
observe	O
that	O
DM	B-Method
is	O
able	O
to	O
effectively	O
prune	O
false	O
matches	O
arising	O
in	O
occluded	O
areas	O
(	O
black	O
areas	O
in	O
Figures	O
and	O
)	O
.	O
	
This	O
is	O
due	O
to	O
the	O
reciprocal	B-Method
verification	I-Method
filtering	I-Method
incorporated	O
in	O
DM	B-Method
(	O
Eq	O
.	O
(	O
)	O
)	O
.	O
	
When	O
using	O
the	O
approximation	B-Method
with	O
1024	O
prototypes	O
,	O
however	O
,	O
a	O
significant	O
drop	O
is	O
observed	O
on	O
the	O
Kitti	B-Material
dataset	O
,	O
while	O
the	O
performance	O
remains	O
good	O
on	O
MPI	B-Material
-	I-Material
Sintel	I-Material
.	O
	
This	O
indicates	O
that	O
approximating	O
DeepMatching	B-Method
can	O
result	O
in	O
a	O
significant	O
loss	O
of	O
robustness	B-Metric
when	O
matching	B-Method
repetitive	O
textures	O
,	O
that	O
are	O
more	O
frequent	O
in	O
Kitti	B-Material
than	O
in	O
MPI	B-Material
-	I-Material
Sintel	I-Material
.	O
	
subsubsection	O
:	O
Comparison	O
to	O
the	O
state	O
of	O
the	O
art	O
	
In	O
this	O
section	O
,	O
we	O
compare	O
DeepFlow	B-Method
to	O
the	O
state	O
of	O
the	O
art	O
on	O
the	O
test	O
sets	O
of	O
MPI	B-Material
-	I-Material
Sintel	I-Material
,	O
Kitti	B-Material
and	O
Middlebury	B-Material
datasets	O
.	O
	
For	O
theses	O
datasets	O
,	O
the	O
results	O
are	O
submitted	O
to	O
a	O
dedicated	O
server	O
which	O
performs	O
the	O
evaluation	O
.	O
	
Prior	O
to	O
submitting	O
our	O
results	O
for	O
Kitti	B-Material
and	O
Middlebury	B-Material
test	O
sets	O
,	O
we	O
have	O
optimized	O
the	O
parameters	O
on	O
the	O
respective	O
training	O
set	O
.	O
	
paragraph	O
:	O
Results	O
on	O
MPI	B-Material
-	I-Material
Sintel	I-Material
.	O
	
Images	O
Ground	O
-	O
Truth	O
DeepMatching	B-Method
DeepFlow	O
MDP	O
-	O
Flow2	O
LDOF	B-Method
Table	O
[	O
reference	O
]	O
compares	O
our	O
method	O
to	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
algorithms	O
on	O
the	O
MPI	B-Material
-	I-Material
Sintel	I-Material
test	O
set	O
.	O
	
A	O
comparison	O
with	O
the	O
preliminary	O
version	O
of	O
DeepFlow	B-Method
DeepFlow	I-Method
,	O
referred	O
to	O
as	O
DeepFlow	B-Method
*	I-Method
,	O
is	O
also	O
provided	O
.	O
	
In	O
this	O
early	O
version	O
,	O
we	O
used	O
a	O
constant	O
smoothness	O
weight	O
instead	O
of	O
a	O
local	O
one	O
here	O
(	O
see	O
Section	O
[	O
reference	O
]	O
)	O
and	O
used	O
DM	B-Method
*	O
as	O
input	O
matches	O
.	O
	
We	O
can	O
see	O
that	O
DeepFlow	B-Method
is	O
among	O
the	O
best	O
performing	O
methods	O
on	O
MPI	B-Material
-	I-Material
Sintel	I-Material
,	O
particularly	O
for	O
large	O
displacements	O
.	O
	
This	O
is	O
due	O
to	O
the	O
use	O
of	O
a	O
reliable	O
matching	B-Method
term	O
in	O
the	O
variational	B-Method
approach	I-Method
,	O
and	O
this	O
property	O
is	O
shared	O
by	O
all	O
top	O
performing	O
approaches	O
,	O
e.g	O
.	O
epicflow	B-Method
,	O
Leordeanu2013	O
.	O
	
Furthermore	O
,	O
it	O
is	O
interesting	O
to	O
note	O
that	O
among	O
the	O
top	O
performers	O
on	O
MPI	B-Material
-	I-Material
Sintel	I-Material
,	O
3	O
methods	O
out	O
of	O
6	O
actually	O
employ	O
DeepMatching	B-Method
.	O
	
In	O
particular	O
,	O
the	O
top	O
-	O
3	O
method	O
EpicFlow	B-Method
epicflow	I-Method
relies	O
on	O
the	O
output	O
of	O
DeepMatching	B-Method
to	O
produce	O
a	O
piece	O
-	O
wise	O
affine	O
flow	O
,	O
and	O
SparseFlowFused	B-Method
sparseflowfused	I-Method
combines	O
matches	O
obtained	O
with	O
DeepMatching	B-Method
and	O
another	O
algorithm	O
.	O
	
We	O
refer	O
to	O
the	O
webpage	O
of	O
the	O
MPI	B-Material
-	I-Material
Sintel	I-Material
dataset	O
for	O
complete	O
results	O
including	O
the	O
‘	O
‘	O
clean	O
’	O
’	O
version	O
.	O
	
paragraph	O
:	O
Timings	O
.	O
	
As	O
mentioned	O
before	O
,	O
DeepMatching	B-Method
at	O
half	O
the	O
resolution	O
takes	O
15	O
seconds	O
to	O
compute	O
on	O
CPU	O
and	O
0.2	O
second	O
on	O
GPU	O
.	O
	
The	O
variational	B-Method
part	I-Method
requires	O
10	O
additional	O
seconds	O
on	O
CPU	O
.	O
	
Note	O
that	O
by	O
implementing	O
it	O
on	O
GPU	B-Method
,	O
we	O
could	O
obtain	O
a	O
significant	O
speed	O
-	O
up	O
as	O
well	O
.	O
	
DeepFlow	B-Method
consequently	O
takes	O
25	O
seconds	O
in	O
total	O
on	O
a	O
single	O
CPU	O
core	O
@	O
3.6	O
GHz	O
or	O
10.2s	O
with	O
GPU	O
+	O
CPU	O
.	O
	
This	O
is	O
in	O
the	O
same	O
order	O
of	O
magnitude	O
as	O
the	O
fastest	O
among	O
the	O
best	O
competitors	O
,	O
EpicFlow	B-Method
epicflow	I-Method
.	O
	
paragraph	O
:	O
Results	O
on	O
Kitti	B-Material
.	O
	
Table	O
[	O
reference	O
]	O
summarizes	O
the	O
main	O
results	O
on	O
the	O
Kitti	B-Material
benchmark	O
(	O
see	O
official	O
website	O
for	O
complete	O
results	O
)	O
,	O
when	O
optimizing	O
the	O
parameters	O
on	O
the	O
Kitti	B-Material
training	O
set	O
.	O
	
EPE	B-Method
-	I-Method
Noc	I-Method
is	O
the	O
EPE	B-Method
computed	O
only	O
in	O
non	O
-	O
occluded	O
areas	O
.	O
	
‘	O
	
‘	O
	
Out	O
3	O
’	O
’	O
corresponds	O
to	O
the	O
proportion	O
of	O
incorrect	O
pixel	O
correspondences	O
for	O
an	O
error	O
threshold	O
of	O
3	O
pixels	O
,	O
i.e	O
.	O
	
it	O
corresponds	O
to	O
,	O
and	O
likewise	O
for	O
‘	O
‘	O
	
Out	O
-	O
Noc	O
3	O
’	O
’	O
for	O
non	O
-	O
occluded	O
areas	O
.	O
	
In	O
terms	O
of	O
EPE	B-Task
-	I-Task
noc	I-Task
,	O
DeepFlow	B-Method
is	O
on	O
par	O
with	O
the	O
best	O
approaches	O
,	O
but	O
performs	O
somewhat	O
worse	O
in	O
the	O
occluded	O
areas	O
.	O
	
This	O
is	O
due	O
to	O
a	O
specificity	O
of	O
the	O
Kitti	B-Material
dataset	O
,	O
in	O
which	O
motion	O
is	O
mostly	O
homographic	O
(	O
especially	O
on	O
the	O
image	O
borders	O
,	O
where	O
most	O
surfaces	O
like	O
roads	O
and	O
walls	O
are	O
planar	O
)	O
.	O
	
In	O
such	O
cases	O
,	O
flow	O
is	O
better	O
predicted	O
using	O
an	O
affine	O
motion	O
prior	O
,	O
which	O
locally	O
well	O
approximates	O
homographies	O
(	O
a	O
constant	O
motion	O
prior	O
is	O
used	O
in	O
DeepFlow	B-Method
)	O
.	O
	
As	O
a	O
matter	O
of	O
facts	O
,	O
all	O
top	O
performing	O
methods	O
in	O
terms	O
of	O
total	O
EPE	B-Metric
output	O
piece	O
-	O
wise	O
affine	O
optical	O
flow	O
,	O
either	O
due	O
to	O
affine	B-Method
regularizers	I-Method
(	O
BTF	B-Method
-	I-Method
ILLUM	I-Method
demetz2014learning	O
,	O
NLTGB	B-Method
-	I-Method
SC	I-Method
ranftl2014non	O
,	O
TGV2ADCSIFT	B-Method
Braux	O
-	O
Zin_2013_ICCV	O
)	O
or	O
due	O
to	O
local	B-Method
affine	I-Method
estimators	I-Method
(	O
EpicFlow	B-Method
epicflow	I-Method
)	O
.	O
	
Note	O
that	O
the	O
learned	O
parameters	O
on	O
Kitti	B-Material
and	O
MPI	B-Material
-	I-Material
Sintel	I-Material
are	O
close	O
.	O
	
In	O
particular	O
,	O
running	O
the	O
experiments	O
with	O
the	O
same	O
parameters	O
as	O
MPI	B-Material
-	I-Material
Sintel	I-Material
decreases	O
EPE	O
-	O
Noc	O
by	O
only	O
pixels	O
on	O
the	O
training	O
set	O
.	O
	
This	O
shows	O
that	O
our	O
method	O
does	O
not	O
suffer	O
from	O
overfitting	O
.	O
	
paragraph	O
:	O
Results	O
on	O
Middlebury	B-Material
.	O
	
We	O
optimize	O
the	O
parameters	O
on	O
the	O
Middlebury	B-Material
training	O
set	O
by	O
minimizing	O
the	O
average	B-Metric
angular	I-Metric
error	I-Metric
with	O
the	O
same	O
strategy	O
as	O
for	O
MPI	B-Material
-	I-Material
Sintel	I-Material
.	O
	
We	O
find	O
weights	O
quasi	O
-	O
zero	O
for	O
the	O
matching	B-Method
term	O
due	O
to	O
the	O
absence	O
of	O
large	O
displacements	O
.	O
	
DeepFlow	B-Method
obtained	O
an	O
average	B-Metric
endpoint	I-Metric
error	I-Metric
of	O
on	O
the	O
test	O
which	O
is	O
competitive	O
with	O
the	O
state	O
of	O
the	O
art	O
.	O
	
section	O
:	O
Conclusion	O
	
We	O
have	O
introduced	O
a	O
dense	O
matching	B-Method
algorithm	O
,	O
termed	O
DeepMatching	B-Method
.	O
	
The	O
proposed	O
algorithm	O
gracefully	O
handles	O
complex	O
non	O
-	O
rigid	O
object	O
deformations	O
and	O
repetitive	O
textured	O
regions	O
.	O
	
DeepMatching	B-Method
yields	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
for	O
image	O
matching	B-Method
,	O
on	O
the	O
Mikolajczyk	B-Material
Mikolajczyk2005	O
,	O
the	O
MPI	B-Material
-	I-Material
Sintel	I-Material
sintel	O
and	O
the	O
Kitti	B-Material
kitti	O
datasets	O
.	O
	
Integrated	O
in	O
a	O
variational	B-Method
energy	I-Method
minimization	I-Method
approach	I-Method
Bro11a	O
,	O
the	O
resulting	O
approach	O
for	O
optical	B-Task
flow	I-Task
estimation	I-Task
,	O
termed	O
DeepFlow	B-Method
,	O
shows	O
competitive	O
performance	O
on	O
optical	B-Task
flow	I-Task
benchmarks	I-Task
.	O
	
Future	O
work	O
includes	O
incorporating	O
a	O
weighting	O
of	O
the	O
patches	O
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
instead	O
of	O
weighting	O
all	O
patches	O
equally	O
to	O
take	O
into	O
account	O
that	O
different	O
parts	O
of	O
a	O
large	O
patch	O
may	O
belong	O
to	O
different	O
objects	O
.	O
	
This	O
could	O
improve	O
the	O
performance	O
of	O
DeepMatching	B-Method
for	O
thin	B-Task
objects	I-Task
,	O
such	O
as	O
human	O
limbs	O
.	O
	
bibliography	O
:	O
References	O
	
ImageNet	B-Task
Classification	I-Task
with	O
Deep	B-Method
Convolutional	I-Method
Neural	I-Method
Networks	I-Method
	
We	O
trained	O
a	O
large	O
,	O
deep	B-Method
convolutional	I-Method
neural	I-Method
network	I-Method
to	O
classify	O
the	O
1.2	O
million	O
high	O
-	O
resolution	O
images	O
in	O
the	O
ImageNet	B-Material
LSVRC	I-Material
-	I-Material
2010	I-Material
contest	I-Material
into	O
the	O
1000	O
different	O
classes	O
.	O
	
On	O
the	O
test	O
data	O
,	O
we	O
achieved	O
top	B-Metric
-	I-Metric
1	I-Metric
and	O
top	B-Metric
-	I-Metric
5	I-Metric
error	I-Metric
rates	I-Metric
of	O
37.5	O
%	O
and	O
17.0	O
%	O
,	O
respectively	O
,	O
which	O
is	O
considerably	O
better	O
than	O
the	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
.	O
	
The	O
neural	B-Method
network	I-Method
,	O
which	O
has	O
60	O
million	O
parameters	O
and	O
650	O
,	O
000	O
neurons	O
,	O
consists	O
of	O
five	O
convolutional	B-Method
layers	I-Method
,	O
some	O
of	O
which	O
are	O
followed	O
by	O
max	B-Method
-	I-Method
pooling	I-Method
layers	I-Method
,	O
and	O
three	O
fully	B-Method
connected	I-Method
layers	I-Method
with	O
a	O
final	O
1000	B-Method
-	I-Method
way	I-Method
softmax	I-Method
.	O
	
To	O
make	O
training	B-Task
faster	O
,	O
we	O
used	O
non	B-Method
-	I-Method
saturating	I-Method
neurons	I-Method
and	O
a	O
very	O
efficient	O
GPU	B-Method
implementation	I-Method
of	O
the	O
convolution	B-Method
operation	I-Method
.	O
	
To	O
reduce	O
overfitting	O
in	O
the	O
fully	O
connected	O
layers	O
we	O
employed	O
a	O
recently	O
developed	O
regularization	B-Method
method	I-Method
called	O
"	O
dropout	B-Method
"	O
that	O
proved	O
to	O
be	O
very	O
effective	O
.	O
	
We	O
also	O
entered	O
a	O
variant	O
of	O
this	O
model	O
in	O
the	O
ILSVRC	B-Material
-	O
2012	O
competition	O
and	O
achieved	O
a	O
winning	O
top	B-Metric
-	I-Metric
5	I-Metric
test	I-Metric
error	I-Metric
rate	I-Metric
of	O
15.3	O
%	O
,	O
compared	O
to	O
26.2	O
%	O
achieved	O
by	O
the	O
second	O
-	O
best	O
entry	O
.	O
	
We	O
trained	O
a	O
large	O
,	O
deep	B-Method
convolutional	I-Method
neural	I-Method
network	I-Method
to	O
classify	O
the	O
1.2	O
million	O
high	O
-	O
resolution	O
images	O
in	O
the	O
ImageNet	B-Material
LSVRC	I-Material
-	I-Material
2010	I-Material
contest	I-Material
into	O
the	O
1000	O
different	O
classes	O
.	O
	
On	O
the	O
test	O
data	O
,	O
we	O
achieved	O
top	B-Metric
-	I-Metric
1	I-Metric
and	O
top	B-Metric
-	I-Metric
5	I-Metric
error	I-Metric
rates	I-Metric
of	O
37.5	O
%	O
and	O
17.0	O
%	O
which	O
is	O
considerably	O
better	O
than	O
the	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
.	O
	
The	O
neural	B-Method
network	I-Method
,	O
which	O
has	O
60	O
million	O
parameters	O
and	O
650	O
,	O
000	O
neurons	O
,	O
consists	O
of	O
five	O
convolutional	B-Method
layers	I-Method
,	O
some	O
of	O
which	O
are	O
followed	O
by	O
max	B-Method
-	I-Method
pooling	I-Method
layers	I-Method
,	O
and	O
three	O
fully	B-Method
-	I-Method
connected	I-Method
layers	I-Method
with	O
a	O
final	O
1000	B-Method
-	I-Method
way	I-Method
softmax	I-Method
.	O
	
To	O
make	O
training	B-Task
faster	O
,	O
we	O
used	O
non	B-Method
-	I-Method
saturating	I-Method
neurons	I-Method
and	O
a	O
very	O
efficient	O
GPU	B-Method
implementation	I-Method
of	O
the	O
convolution	B-Method
operation	I-Method
.	O
	
To	O
reduce	O
overfitting	O
in	O
the	O
fully	O
-	O
connected	O
layers	O
we	O
employed	O
a	O
recently	O
-	O
developed	O
regularization	B-Method
method	I-Method
called	O
“	O
dropout	B-Method
”	O
that	O
proved	O
to	O
be	O
very	O
effective	O
.	O
	
We	O
also	O
entered	O
a	O
variant	O
of	O
this	O
model	O
in	O
the	O
ILSVRC	B-Material
-	O
2012	O
competition	O
and	O
achieved	O
a	O
winning	O
top	B-Metric
-	I-Metric
5	I-Metric
test	I-Metric
error	I-Metric
rate	I-Metric
of	O
15.3	O
%	O
,	O
compared	O
to	O
26.2	O
%	O
achieved	O
by	O
the	O
second	O
-	O
best	O
entry	O
.	O
	
1	O
Introduction	O
Current	O
approaches	O
to	O
object	B-Task
recognition	I-Task
make	O
essential	O
use	O
of	O
machine	B-Method
learning	I-Method
methods	I-Method
.	O
	
To	O
improve	O
their	O
performance	O
,	O
we	O
can	O
collect	O
larger	O
datasets	O
,	O
learn	O
more	O
powerful	O
models	O
,	O
and	O
use	O
better	O
techniques	O
for	O
preventing	O
overfitting	B-Task
.	O
	
Until	O
recently	O
,	O
datasets	O
of	O
labeled	O
images	O
were	O
relatively	O
small	O
—	O
on	O
the	O
order	O
of	O
tens	O
of	O
thousands	O
of	O
images	O
(	O
e.g.	O
,	O
NORB	B-Material
[	O
16	O
]	O
,	O
Caltech	B-Material
-	I-Material
101	I-Material
/	O
256	O
	
[	O
8	O
,	O
9	O
]	O
,	O
and	O
CIFAR	B-Material
-	I-Material
10	I-Material
/	O
100	O
[	O
12	O
]	O
)	O
.	O
	
Simple	O
recognition	B-Task
tasks	I-Task
can	O
be	O
solved	O
quite	O
well	O
with	O
datasets	O
of	O
this	O
size	O
,	O
especially	O
if	O
they	O
are	O
augmented	O
with	O
label	O
-	O
preserving	O
transformations	O
.	O
	
For	O
example	O
,	O
the	O
currentbest	O
error	B-Metric
rate	I-Metric
on	O
the	O
MNIST	B-Task
digit	I-Task
-	I-Task
recognition	I-Task
task	I-Task
(	O
<	O
0.3	O
%	O
)	O
approaches	O
human	O
performance	O
	
[	O
4	O
]	O
.	O
	
But	O
objects	O
in	O
realistic	O
settings	O
exhibit	O
considerable	O
variability	O
,	O
so	O
to	O
learn	O
to	O
recognize	O
them	O
it	O
is	O
necessary	O
to	O
use	O
much	O
larger	O
training	O
sets	O
.	O
	
And	O
indeed	O
,	O
the	O
shortcomings	O
of	O
small	O
image	O
datasets	O
have	O
been	O
widely	O
recognized	O
(	O
e.g.	O
,	O
Pinto	O
et	O
al	O
.	O
	
[	O
21	O
]	O
)	O
,	O
but	O
it	O
has	O
only	O
recently	O
become	O
possible	O
to	O
collect	O
labeled	O
datasets	O
with	O
millions	O
of	O
images	O
.	O
	
The	O
new	O
larger	O
datasets	O
include	O
LabelMe	B-Material
[	O
23	O
]	O
,	O
which	O
consists	O
of	O
hundreds	O
of	O
thousands	O
of	O
fully	O
-	O
segmented	O
images	O
,	O
and	O
ImageNet	B-Material
[	O
6	O
]	O
,	O
which	O
consists	O
of	O
over	O
15	O
million	O
labeled	O
high	O
-	O
resolution	O
images	O
in	O
over	O
22	O
,	O
000	O
categories	O
.	O
	
To	O
learn	O
about	O
thousands	O
of	O
objects	O
from	O
millions	O
of	O
images	O
,	O
we	O
need	O
a	O
model	O
with	O
a	O
large	O
learning	B-Metric
capacity	I-Metric
.	O
	
However	O
,	O
the	O
immense	O
complexity	O
of	O
the	O
object	B-Task
recognition	I-Task
task	I-Task
means	O
that	O
this	O
problem	O
can	O
not	O
be	O
specified	O
even	O
by	O
a	O
dataset	O
as	O
large	O
as	O
ImageNet	B-Material
,	O
so	O
our	O
model	O
should	O
also	O
have	O
lots	O
of	O
prior	O
knowledge	O
to	O
compensate	O
for	O
all	O
the	O
data	O
we	O
do	O
	
n’t	O
have	O
.	O
	
Convolutional	B-Method
neural	I-Method
networks	I-Method
(	O
CNNs	B-Method
)	O
constitute	O
one	O
such	O
class	O
of	O
models	O
[	O
16	O
,	O
11	O
,	O
13	O
,	O
18	O
,	O
15	O
,	O
22	O
,	O
	
26	O
]	O
.	O
	
Their	O
capacity	O
can	O
be	O
controlled	O
by	O
varying	O
their	O
depth	O
and	O
breadth	O
,	O
and	O
they	O
also	O
make	O
strong	O
and	O
mostly	O
correct	O
assumptions	O
about	O
the	O
nature	O
of	O
images	O
(	O
namely	O
,	O
stationarity	O
of	O
statistics	O
and	O
locality	O
of	O
pixel	O
dependencies	O
)	O
.	O
	
Thus	O
,	O
compared	O
to	O
standard	O
feedforward	B-Method
neural	I-Method
networks	I-Method
with	O
similarly	B-Method
-	I-Method
sized	I-Method
layers	I-Method
,	O
CNNs	B-Method
have	O
much	O
fewer	O
connections	O
and	O
parameters	O
and	O
so	O
they	O
are	O
easier	O
to	O
train	O
,	O
while	O
their	O
theoretically	O
-	O
best	O
performance	O
is	O
likely	O
to	O
be	O
only	O
slightly	O
worse	O
.	O
	
Despite	O
the	O
attractive	O
qualities	O
of	O
CNNs	B-Method
,	O
and	O
despite	O
the	O
relative	O
efficiency	O
of	O
their	O
local	B-Method
architecture	I-Method
,	O
they	O
have	O
still	O
been	O
prohibitively	O
expensive	O
to	O
apply	O
in	O
large	O
scale	O
to	O
high	B-Task
-	I-Task
resolution	I-Task
images	I-Task
.	O
	
Luckily	O
,	O
current	O
GPUs	B-Method
,	O
paired	O
with	O
a	O
highly	B-Method
-	I-Method
optimized	I-Method
implementation	I-Method
of	I-Method
2D	I-Method
convolution	I-Method
,	O
are	O
powerful	O
enough	O
to	O
facilitate	O
the	O
training	O
of	O
interestingly	O
-	O
large	O
CNNs	B-Method
,	O
and	O
recent	O
datasets	O
such	O
as	O
ImageNet	B-Material
contain	O
enough	O
labeled	O
examples	O
to	O
train	O
such	O
models	O
without	O
severe	O
overfitting	O
.	O
	
The	O
specific	O
contributions	O
of	O
this	O
paper	O
are	O
as	O
follows	O
:	O
we	O
trained	O
one	O
of	O
the	O
largest	O
convolutional	B-Method
neural	I-Method
networks	I-Method
to	O
date	O
on	O
the	O
subsets	O
of	O
ImageNet	B-Material
used	O
in	O
the	O
ILSVRC	B-Material
-	I-Material
2010	I-Material
and	O
ILSVRC	B-Material
-	O
2012	O
competitions	O
[	O
2	O
]	O
and	O
achieved	O
by	O
far	O
the	O
best	O
results	O
ever	O
reported	O
on	O
these	O
datasets	O
.	O
	
We	O
wrote	O
a	O
highly	O
-	O
optimized	O
GPU	B-Method
implementation	I-Method
of	I-Method
2D	I-Method
convolution	I-Method
and	O
all	O
the	O
other	O
operations	O
inherent	O
in	O
training	O
convolutional	B-Method
neural	I-Method
networks	I-Method
,	O
which	O
we	O
make	O
available	O
publicly1	O
.	O
	
Our	O
network	O
contains	O
a	O
number	O
of	O
new	O
and	O
unusual	O
features	O
which	O
improve	O
its	O
performance	O
and	O
reduce	O
its	O
training	B-Metric
time	I-Metric
,	O
which	O
are	O
detailed	O
in	O
Section	O
3	O
.	O
	
The	O
size	O
of	O
our	O
network	O
made	O
overfitting	O
a	O
significant	O
problem	O
,	O
even	O
with	O
1.2	O
million	O
labeled	O
training	O
examples	O
,	O
so	O
we	O
used	O
several	O
effective	O
techniques	O
for	O
preventing	O
overfitting	B-Task
,	O
which	O
are	O
described	O
in	O
Section	O
4	O
.	O
	
Our	O
final	O
network	O
contains	O
five	O
convolutional	O
and	O
three	O
fully	B-Method
-	I-Method
connected	I-Method
layers	I-Method
,	O
and	O
this	O
depth	O
seems	O
to	O
be	O
important	O
:	O
we	O
found	O
that	O
removing	O
any	O
convolutional	B-Method
layer	I-Method
(	O
each	O
of	O
which	O
contains	O
no	O
more	O
than	O
1	O
%	O
of	O
the	O
model	O
	
’s	O
parameters	O
)	O
resulted	O
in	O
inferior	O
performance	O
.	O
	
In	O
the	O
end	O
,	O
the	O
network	O
’s	O
size	O
is	O
limited	O
mainly	O
by	O
the	O
amount	O
of	O
memory	O
available	O
on	O
current	O
GPUs	B-Method
and	O
by	O
the	O
amount	O
of	O
training	B-Metric
time	I-Metric
that	O
we	O
are	O
willing	O
to	O
tolerate	O
.	O
	
Our	O
network	O
takes	O
between	O
five	O
and	O
six	O
days	O
to	O
train	O
on	O
two	O
GTX	O
580	O
3	O
GB	O
GPUs	B-Method
.	O
	
All	O
of	O
our	O
experiments	O
suggest	O
that	O
our	O
results	O
can	O
be	O
improved	O
simply	O
by	O
waiting	O
for	O
faster	O
GPUs	B-Method
and	O
bigger	O
datasets	O
to	O
become	O
available	O
.	O
	
2	O
	
The	O
Dataset	B-Material
ImageNet	I-Material
is	O
a	O
dataset	O
of	O
over	O
15	O
million	O
labeled	O
high	O
-	O
resolution	O
images	O
belonging	O
to	O
roughly	O
22	O
,	O
000	O
categories	O
.	O
	
The	O
images	O
were	O
collected	O
from	O
the	O
web	O
and	O
labeled	O
by	O
human	B-Method
labelers	I-Method
using	O
Amazon	B-Method
’s	I-Method
Mechanical	I-Method
Turk	I-Method
crowd	I-Method
-	I-Method
sourcing	I-Method
tool	I-Method
.	O
	
Starting	O
in	O
2010	O
,	O
as	O
part	O
of	O
the	O
Pascal	B-Task
Visual	I-Task
Object	I-Task
Challenge	I-Task
,	O
an	O
annual	O
competition	O
called	O
the	O
ImageNet	B-Task
Large	I-Task
-	I-Task
Scale	I-Task
Visual	I-Task
Recognition	I-Task
Challenge	I-Task
(	O
ILSVRC	B-Material
)	O
has	O
been	O
held	O
.	O
	
ILSVRC	B-Material
uses	O
a	O
subset	O
of	O
ImageNet	B-Material
with	O
roughly	O
1000	O
images	O
in	O
each	O
of	O
1000	O
categories	O
.	O
	
In	O
all	O
,	O
there	O
are	O
roughly	O
1.2	O
million	O
training	O
images	O
,	O
50	O
,	O
000	O
validation	O
images	O
,	O
and	O
150	O
,	O
000	O
testing	O
images	O
.	O
	
ILSVRC	B-Material
-	I-Material
2010	I-Material
is	O
the	O
only	O
version	O
of	O
ILSVRC	B-Material
for	O
which	O
the	O
test	O
set	O
labels	O
are	O
available	O
,	O
so	O
this	O
is	O
the	O
version	O
on	O
which	O
we	O
performed	O
most	O
of	O
our	O
experiments	O
.	O
	
Since	O
we	O
also	O
entered	O
our	O
model	O
in	O
the	O
ILSVRC	B-Material
-	O
2012	O
competition	O
,	O
in	O
Section	O
6	O
we	O
report	O
our	O
results	O
on	O
this	O
version	O
of	O
the	O
dataset	O
as	O
well	O
,	O
for	O
which	O
test	O
set	O
labels	O
are	O
unavailable	O
.	O
	
On	O
ImageNet	B-Material
,	O
it	O
is	O
customary	O
to	O
report	O
two	O
error	B-Metric
rates	I-Metric
:	O
top	B-Metric
-	I-Metric
1	I-Metric
and	O
top	B-Metric
-	I-Metric
5	I-Metric
,	O
where	O
the	O
top	B-Metric
-	I-Metric
5	I-Metric
error	I-Metric
rate	I-Metric
is	O
the	O
fraction	O
of	O
test	O
images	O
for	O
which	O
the	O
correct	O
label	O
is	O
not	O
among	O
the	O
five	O
labels	O
considered	O
most	O
probable	O
by	O
the	O
model	O
.	O
	
ImageNet	B-Material
consists	O
of	O
variable	O
-	O
resolution	O
images	O
,	O
while	O
our	O
system	O
requires	O
a	O
constant	O
input	O
dimensionality	O
.	O
	
Therefore	O
,	O
we	O
down	O
-	O
sampled	O
the	O
images	O
to	O
a	O
fixed	O
resolution	O
of	O
256	O
⇥	O
256	O
.	O
	
Given	O
a	O
rectangular	O
image	O
,	O
we	O
first	O
rescaled	O
the	O
image	O
such	O
that	O
the	O
shorter	O
side	O
was	O
of	O
length	O
256	O
,	O
and	O
then	O
cropped	O
out	O
the	O
central	O
256	O
⇥	O
256	O
patch	O
from	O
the	O
resulting	O
image	O
.	O
	
We	O
did	O
not	O
pre	O
-	O
process	O
the	O
images	O
in	O
any	O
other	O
way	O
,	O
except	O
for	O
subtracting	O
the	O
mean	O
activity	O
over	O
the	O
training	O
set	O
from	O
each	O
pixel	O
.	O
	
So	O
we	O
trained	O
our	O
network	O
on	O
the	O
(	O
centered	O
)	O
raw	O
RGB	O
values	O
of	O
the	O
pixels	O
.	O
	
3	O
	
The	O
Architecture	O
	
The	O
architecture	O
of	O
our	O
network	O
is	O
summarized	O
in	O
Figure	O
2	O
.	O
	
It	O
contains	O
eight	O
learned	O
layers	O
	
—	O
five	O
convolutional	B-Method
and	O
three	O
fully	B-Method
-	I-Method
connected	I-Method
.	O
	
Below	O
,	O
we	O
describe	O
some	O
of	O
the	O
novel	O
or	O
unusual	O
features	O
of	O
our	O
network	B-Method
’s	I-Method
architecture	I-Method
.	O
	
Sections	O
3.1	O
-	O
3.4	O
are	O
sorted	O
according	O
to	O
our	O
estimation	O
of	O
their	O
importance	O
,	O
with	O
the	O
most	O
important	O
first	O
.	O
	
1http:	O
//	O
code.google.com	O
/	O
p	O
/	O
cuda	O
-	O
convnet	O
/	O
3.1	O
ReLU	O
Nonlinearity	O
	
The	O
standard	O
way	O
to	O
model	O
a	O
neuron	O
’s	O
output	O
f	O
as	O
a	O
function	O
of	O
its	O
input	O
x	O
is	O
with	O
f	O
(	O
x	O
)	O
	
=	O
tanh	O
(	O
x	O
)	O
or	O
f	O
(	O
x	O
)	O
	
=	O
	
(	O
1	O
+	O
e	O
x	O
)	O
1	O
.	O
	
In	O
terms	O
of	O
training	B-Metric
time	I-Metric
with	O
gradient	B-Method
descent	I-Method
,	O
these	O
saturating	B-Method
nonlinearities	I-Method
are	O
much	O
slower	O
than	O
the	O
non	O
-	O
saturating	O
nonlinearity	O
f	O
(	O
x	O
)	O
=	O
	
max	O
(	O
0	O
,	O
x	O
)	O
.	O
	
Following	O
Nair	O
and	O
Hinton	O
[	O
20	O
]	O
,	O
we	O
refer	O
to	O
neurons	O
with	O
this	O
nonlinearity	O
as	O
Rectified	B-Method
Linear	I-Method
Units	I-Method
(	O
ReLUs	B-Method
)	O
.	O
	
Deep	B-Method
convolutional	I-Method
neural	I-Method
networks	I-Method
with	O
ReLUs	B-Method
train	O
several	O
times	O
faster	O
than	O
their	O
equivalents	O
with	O
tanh	B-Method
units	I-Method
.	O
	
This	O
is	O
demonstrated	O
in	O
Figure	O
1	O
,	O
which	O
shows	O
the	O
number	O
of	O
iterations	O
required	O
to	O
reach	O
25	O
%	O
training	B-Metric
error	I-Metric
on	O
the	O
CIFAR	B-Material
-	I-Material
10	I-Material
dataset	I-Material
for	O
a	O
particular	O
four	B-Method
-	I-Method
layer	I-Method
convolutional	I-Method
network	I-Method
.	O
	
This	O
plot	O
shows	O
that	O
we	O
would	O
not	O
have	O
been	O
able	O
to	O
experiment	O
with	O
such	O
large	O
neural	B-Method
networks	I-Method
for	O
this	O
work	O
if	O
we	O
had	O
used	O
traditional	O
saturating	B-Method
neuron	I-Method
models	I-Method
.	O
	
We	O
are	O
not	O
the	O
first	O
to	O
consider	O
alternatives	O
to	O
traditional	O
neuron	B-Method
models	I-Method
in	O
CNNs	B-Method
.	O
	
For	O
example	O
,	O
Jarrett	O
et	O
al	O
.	O
	
[	O
11	O
]	O
claim	O
that	O
the	O
nonlinearity	O
f	O
(	O
x	O
)	O
=	O
|tanh	O
(	O
x	O
)	O
|	O
works	O
particularly	O
well	O
with	O
their	O
type	O
of	O
contrast	B-Method
normalization	I-Method
followed	O
by	O
local	B-Method
average	I-Method
pooling	I-Method
on	O
the	O
Caltech	B-Material
-	I-Material
101	I-Material
dataset	O
.	O
	
However	O
,	O
on	O
this	O
dataset	O
the	O
primary	O
concern	O
is	O
preventing	O
overfitting	B-Task
,	O
so	O
the	O
effect	O
they	O
are	O
observing	O
is	O
different	O
from	O
the	O
accelerated	O
ability	O
to	O
fit	O
the	O
training	O
set	O
which	O
we	O
report	O
when	O
using	O
ReLUs	B-Method
.	O
	
Faster	B-Method
learning	I-Method
has	O
a	O
great	O
influence	O
on	O
the	O
performance	O
of	O
large	B-Method
models	I-Method
trained	O
on	O
large	O
datasets	O
.	O
	
3.2	O
Training	B-Task
on	O
Multiple	O
GPUs	B-Method
	
A	O
single	O
GTX	O
580	O
	
GPU	B-Method
has	O
only	O
3	O
GB	O
of	O
memory	O
,	O
which	O
limits	O
the	O
maximum	O
size	O
of	O
the	O
networks	O
that	O
can	O
be	O
trained	O
on	O
it	O
.	O
	
It	O
turns	O
out	O
that	O
1.2	O
million	O
training	O
examples	O
are	O
enough	O
to	O
train	O
networks	O
which	O
are	O
too	O
big	O
to	O
fit	O
on	O
one	O
GPU	O
.	O
	
Therefore	O
we	O
spread	O
the	O
net	O
across	O
two	O
GPUs	B-Method
.	O
	
Current	O
GPUs	B-Method
are	O
particularly	O
well	O
-	O
suited	O
to	O
cross	B-Task
-	I-Task
GPU	I-Task
parallelization	I-Task
,	O
as	O
they	O
are	O
able	O
to	O
read	O
from	O
and	O
write	O
to	O
one	O
another	O
’s	O
memory	O
directly	O
,	O
without	O
going	O
through	O
host	O
machine	O
memory	O
.	O
	
The	O
parallelization	B-Method
scheme	I-Method
that	O
we	O
employ	O
essentially	O
puts	O
half	O
of	O
the	O
kernels	O
(	O
or	O
neurons	O
)	O
on	O
each	O
GPU	O
,	O
with	O
one	O
additional	O
trick	O
:	O
the	O
GPUs	B-Method
communicate	O
only	O
in	O
certain	O
layers	O
.	O
	
This	O
means	O
that	O
,	O
for	O
example	O
,	O
the	O
kernels	O
of	O
layer	O
3	O
take	O
input	O
from	O
all	O
kernel	B-Method
maps	I-Method
in	O
layer	O
2	O
.	O
	
However	O
,	O
kernels	O
in	O
layer	O
4	O
take	O
input	O
only	O
from	O
those	O
kernel	B-Method
maps	I-Method
in	O
layer	O
3	O
which	O
reside	O
on	O
the	O
same	O
GPU	O
.	O
	
Choosing	O
the	O
pattern	O
of	O
connectivity	O
is	O
a	O
problem	O
for	O
cross	B-Task
-	I-Task
validation	I-Task
,	O
but	O
this	O
allows	O
us	O
to	O
precisely	O
tune	O
the	O
amount	O
of	O
communication	O
until	O
it	O
is	O
an	O
acceptable	O
fraction	O
of	O
the	O
amount	O
of	O
computation	O
.	O
	
The	O
resultant	O
architecture	O
is	O
somewhat	O
similar	O
to	O
that	O
of	O
the	O
“	O
columnar	O
”	O
CNN	B-Method
employed	O
by	O
Cireşan	O
et	O
al	O
.	O
	
[	O
5	O
]	O
,	O
except	O
that	O
our	O
columns	O
are	O
not	O
independent	O
(	O
see	O
Figure	O
2	O
)	O
.	O
	
This	O
scheme	O
reduces	O
our	O
top	B-Metric
-	I-Metric
1	I-Metric
and	O
top	B-Metric
-	I-Metric
5	I-Metric
	
error	B-Metric
rates	I-Metric
by	O
1.7	O
%	O
and	O
1.2	O
%	O
,	O
respectively	O
,	O
as	O
compared	O
with	O
a	O
net	O
with	O
half	O
as	O
many	O
kernels	O
in	O
each	O
convolutional	B-Method
layer	I-Method
trained	O
on	O
one	O
GPU	O
.	O
	
The	O
two	O
-	O
GPU	B-Method
net	I-Method
takes	O
slightly	O
less	O
time	O
to	O
train	O
than	O
the	O
one	B-Method
-	I-Method
GPU	I-Method
net2	I-Method
.	O
	
2The	O
	
one	B-Method
-	I-Method
GPU	I-Method
net	I-Method
actually	O
has	O
the	O
same	O
number	O
of	O
kernels	O
as	O
the	O
two	O
-	O
GPU	B-Method
net	I-Method
in	O
the	O
final	O
convolutional	B-Method
layer	I-Method
.	O
	
This	O
is	O
because	O
most	O
of	O
the	O
net	O
’s	O
parameters	O
are	O
in	O
the	O
first	O
fully	B-Method
-	I-Method
connected	I-Method
layer	I-Method
,	O
which	O
takes	O
the	O
last	O
convolutional	B-Method
layer	I-Method
as	O
input	O
.	O
	
So	O
to	O
make	O
the	O
two	O
nets	O
have	O
approximately	O
the	O
same	O
number	O
of	O
parameters	O
,	O
we	O
did	O
not	O
halve	O
the	O
size	O
of	O
the	O
final	O
convolutional	B-Method
layer	I-Method
(	O
nor	O
the	O
fully	B-Method
-	I-Method
conneced	I-Method
layers	I-Method
which	O
follow	O
)	O
.	O
	
Therefore	O
this	O
comparison	O
is	O
biased	O
in	O
favor	O
of	O
the	O
one	O
-	O
GPU	B-Method
net	I-Method
,	O
since	O
it	O
is	O
bigger	O
than	O
“	O
half	O
the	O
size	O
”	O
of	O
the	O
two	O
-	O
GPU	B-Method
net	I-Method
.	O
	
3.3	O
Local	B-Method
Response	I-Method
Normalization	I-Method
ReLUs	I-Method
have	O
the	O
desirable	O
property	O
that	O
they	O
do	O
not	O
require	O
input	O
normalization	O
to	O
prevent	O
them	O
from	O
saturating	O
.	O
	
If	O
at	O
least	O
some	O
training	O
examples	O
produce	O
a	O
positive	O
input	O
to	O
a	O
ReLU	O
,	O
learning	O
will	O
happen	O
in	O
that	O
neuron	O
.	O
	
However	O
,	O
we	O
still	O
find	O
that	O
the	O
following	O
local	B-Method
normalization	I-Method
scheme	I-Method
aids	O
generalization	B-Task
.	O
	
Denoting	O
by	O
aix	O
,	O
y	O
the	O
activity	O
of	O
a	O
neuron	O
computed	O
by	O
applying	O
kernel	B-Method
i	I-Method
at	O
position	O
(	O
x	O
,	O
y	O
)	O
and	O
then	O
applying	O
the	O
ReLU	B-Method
nonlinearity	I-Method
,	O
the	O
response	O
-	O
normalized	O
activity	O
bix	O
,	O
y	O
is	O
given	O
by	O
the	O
expression	O
bix	O
,	O
y	O
=	O
a	O
	
i	O
x	O
,	O
y	O
/	O
0	O
	
@k	O
	
+	O
	
↵	O
min	O
(	O
N	O
1	O
,	O
i	O
+	O
n	O
/	O
2	O
)	O
X	O
	
j	O
	
=	O
max	O
(	O
0	O
,	O
i	O
	
n	O
/	O
2	O
)	O
(	O
ajx	O
,	O
y	O
	
)	O
2	O
1	O
	
A	O
where	O
the	O
sum	O
runs	O
over	O
n	O
“	O
adjacent	O
”	O
kernel	O
maps	O
at	O
the	O
same	O
spatial	O
position	O
,	O
and	O
N	O
is	O
the	O
total	O
number	O
of	O
kernels	O
in	O
the	O
layer	O
.	O
	
The	O
ordering	O
of	O
the	O
kernel	B-Method
maps	I-Method
is	O
of	O
course	O
arbitrary	O
and	O
determined	O
before	O
training	O
begins	O
.	O
	
This	O
sort	O
of	O
response	B-Method
normalization	I-Method
implements	O
a	O
form	O
of	O
lateral	O
inhibition	O
inspired	O
by	O
the	O
type	O
found	O
in	O
real	O
neurons	O
,	O
creating	O
competition	O
for	O
big	O
activities	O
amongst	O
neuron	O
outputs	O
computed	O
using	O
different	O
kernels	O
.	O
	
The	O
constants	O
k	O
,	O
n	O
,	O
↵	O
,	O
and	O
are	O
hyper	O
-	O
parameters	O
whose	O
values	O
are	O
determined	O
using	O
a	O
validation	O
set	O
;	O
we	O
used	O
k	O
=	O
2	O
,	O
n	O
=	O
5	O
,	O
↵	O
=	O
10	O
4	O
,	O
and	O
=	O
0.75	O
.	O
	
We	O
applied	O
this	O
normalization	O
after	O
applying	O
the	O
ReLU	B-Method
nonlinearity	I-Method
in	O
certain	O
layers	O
(	O
see	O
Section	O
3.5	O
)	O
.	O
	
This	O
scheme	O
bears	O
some	O
resemblance	O
to	O
the	O
local	B-Method
contrast	I-Method
normalization	I-Method
scheme	I-Method
of	O
Jarrett	O
et	O
al	O
.	O
	
[	O
11	O
]	O
,	O
but	O
ours	O
would	O
be	O
more	O
correctly	O
termed	O
“	O
brightness	B-Method
normalization	I-Method
”	O
,	O
since	O
we	O
do	O
not	O
subtract	O
the	O
mean	O
activity	O
.	O
	
Response	B-Method
normalization	I-Method
reduces	O
our	O
top	B-Metric
-	I-Metric
1	I-Metric
and	O
top	B-Metric
-	I-Metric
5	I-Metric
	
error	B-Metric
rates	I-Metric
by	O
1.4	O
%	O
and	O
1.2	O
%	O
,	O
respectively	O
.	O
	
We	O
also	O
verified	O
the	O
effectiveness	O
of	O
this	O
scheme	O
on	O
the	O
CIFAR	B-Material
-	I-Material
10	I-Material
dataset	I-Material
:	O
a	O
four	O
-	O
layer	O
CNN	B-Method
achieved	O
a	O
13	O
%	O
test	B-Metric
error	I-Metric
rate	I-Metric
without	O
normalization	B-Metric
and	O
11	O
%	O
with	O
normalization3	B-Task
.	O
	
3.4	O
Overlapping	B-Method
Pooling	I-Method
	
Pooling	B-Method
layers	I-Method
in	O
CNNs	B-Method
summarize	O
the	O
outputs	O
of	O
neighboring	O
groups	O
of	O
neurons	O
in	O
the	O
same	O
kernel	O
map	O
.	O
	
Traditionally	O
,	O
the	O
neighborhoods	O
summarized	O
by	O
adjacent	O
pooling	O
units	O
do	O
not	O
overlap	O
(	O
e.g.	O
,	O
[	O
17	O
,	O
11	O
,	O
4	O
]	O
)	O
.	O
	
To	O
be	O
more	O
precise	O
,	O
a	O
pooling	B-Method
layer	I-Method
can	O
be	O
thought	O
of	O
as	O
consisting	O
of	O
a	O
grid	O
of	O
pooling	B-Method
units	I-Method
spaced	O
s	O
pixels	O
apart	O
,	O
each	O
summarizing	O
a	O
neighborhood	O
of	O
size	O
z	O
⇥	O
z	O
centered	O
at	O
the	O
location	O
of	O
the	O
pooling	O
unit	O
.	O
	
If	O
we	O
set	O
s	O
=	O
z	O
	
,	O
we	O
obtain	O
traditional	O
local	B-Method
pooling	I-Method
as	O
commonly	O
employed	O
in	O
CNNs	B-Method
.	O
	
If	O
we	O
set	O
s	O
<	O
z	O
,	O
we	O
obtain	O
overlapping	O
pooling	O
.	O
	
This	O
is	O
what	O
we	O
use	O
throughout	O
our	O
network	O
,	O
with	O
s	O
=	O
2	O
and	O
z	O
=	O
3	O
.	O
	
This	O
scheme	O
reduces	O
the	O
top	B-Metric
-	I-Metric
1	I-Metric
and	O
top	B-Metric
-	I-Metric
5	I-Metric
error	I-Metric
rates	I-Metric
by	O
0.4	O
%	O
and	O
0.3	O
%	O
,	O
respectively	O
,	O
as	O
compared	O
with	O
the	O
non	B-Method
-	I-Method
overlapping	I-Method
scheme	I-Method
s	O
=	O
2	O
,	O
z	O
=	O
2	O
,	O
which	O
produces	O
output	O
of	O
equivalent	O
dimensions	O
.	O
	
We	O
generally	O
observe	O
during	O
training	O
that	O
models	O
with	O
overlapping	O
pooling	O
find	O
it	O
slightly	O
more	O
difficult	O
to	O
overfit	O
.	O
	
3.5	O
Overall	O
Architecture	O
	
Now	O
we	O
are	O
ready	O
to	O
describe	O
the	O
overall	O
architecture	O
of	O
our	O
CNN	B-Method
.	O
	
As	O
depicted	O
in	O
Figure	O
2	O
,	O
the	O
net	O
contains	O
eight	O
layers	O
with	O
weights	O
;	O
the	O
first	O
five	O
are	O
convolutional	B-Method
and	O
the	O
remaining	O
three	O
are	O
fullyconnected	O
.	O
	
The	O
output	O
of	O
the	O
last	O
fully	B-Method
-	I-Method
connected	I-Method
layer	I-Method
is	O
fed	O
to	O
a	O
1000	B-Method
-	I-Method
way	I-Method
softmax	I-Method
which	O
produces	O
a	O
distribution	O
over	O
the	O
1000	O
class	O
labels	O
.	O
	
Our	O
network	O
maximizes	O
the	O
multinomial	B-Task
logistic	I-Task
regression	I-Task
objective	I-Task
,	O
which	O
is	O
equivalent	O
to	O
maximizing	O
the	O
average	O
across	O
training	O
cases	O
of	O
the	O
log	O
-	O
probability	O
of	O
the	O
correct	O
label	O
under	O
the	O
prediction	O
distribution	O
.	O
	
The	O
kernels	O
of	O
the	O
second	O
,	O
fourth	O
,	O
and	O
fifth	O
convolutional	B-Method
layers	I-Method
are	O
connected	O
only	O
to	O
those	O
kernel	O
maps	O
in	O
the	O
previous	O
layer	O
which	O
reside	O
on	O
the	O
same	O
GPU	O
(	O
see	O
Figure	O
2	O
)	O
.	O
	
The	O
kernels	O
of	O
the	O
third	O
convolutional	B-Method
layer	I-Method
are	O
connected	O
to	O
all	O
kernel	B-Method
maps	I-Method
in	O
the	O
second	O
layer	O
.	O
	
The	O
neurons	O
in	O
the	O
fullyconnected	O
layers	O
are	O
connected	O
to	O
all	O
neurons	O
in	O
the	O
previous	O
layer	O
.	O
	
Response	B-Method
-	I-Method
normalization	I-Method
layers	I-Method
follow	O
the	O
first	O
and	O
second	O
convolutional	B-Method
layers	I-Method
.	O
	
Max	B-Method
-	I-Method
pooling	I-Method
layers	I-Method
,	O
of	O
the	O
kind	O
described	O
in	O
Section	O
3.4	O
,	O
follow	O
both	O
response	B-Method
-	I-Method
normalization	I-Method
layers	I-Method
as	O
well	O
as	O
the	O
fifth	B-Method
convolutional	I-Method
layer	I-Method
.	O
	
The	O
ReLU	O
non	O
-	O
linearity	O
is	O
applied	O
to	O
the	O
output	O
of	O
every	O
convolutional	B-Method
and	I-Method
fully	I-Method
-	I-Method
connected	I-Method
layer	I-Method
.	O
	
The	O
first	O
convolutional	B-Method
layer	I-Method
filters	O
the	O
224	O
⇥	O
224	O
⇥	O
3	O
input	O
image	O
with	O
96	O
kernels	O
of	O
size	O
11	O
⇥	O
11	O
⇥	O
3	O
with	O
a	O
stride	O
of	O
4	O
pixels	O
(	O
this	O
is	O
the	O
distance	O
between	O
the	O
receptive	O
field	O
centers	O
of	O
neighboring	O
	
3We	O
can	O
not	O
describe	O
this	O
network	O
in	O
detail	O
due	O
to	O
space	O
constraints	O
,	O
but	O
it	O
is	O
specified	O
precisely	O
by	O
the	O
code	O
and	O
parameter	O
files	O
provided	O
here	O
:	O
http:	O
//	O
code.google.com	O
/	O
p	O
/	O
cuda	O
-	O
convnet	O
/	O
.	O
neurons	O
in	O
a	O
kernel	B-Method
map	I-Method
)	O
.	O
	
The	O
second	O
convolutional	B-Method
layer	I-Method
takes	O
as	O
input	O
the	O
(	O
response	O
-	O
normalized	O
and	O
pooled	O
)	O
output	O
of	O
the	O
first	O
convolutional	B-Method
layer	I-Method
and	O
filters	O
it	O
with	O
256	O
kernels	O
of	O
size	O
5	O
⇥	O
5	O
⇥	O
48	O
.	O
	
The	O
third	O
,	O
fourth	O
,	O
and	O
fifth	O
convolutional	B-Method
layers	I-Method
are	O
connected	O
to	O
one	O
another	O
without	O
any	O
intervening	B-Method
pooling	I-Method
or	I-Method
normalization	I-Method
layers	I-Method
.	O
	
The	O
third	O
convolutional	B-Method
layer	I-Method
has	O
384	O
kernels	O
of	O
size	O
3	O
⇥	O
3	O
⇥	O
256	O
connected	O
to	O
the	O
(	O
normalized	O
,	O
pooled	O
)	O
outputs	O
of	O
the	O
second	O
convolutional	B-Method
layer	I-Method
.	O
	
The	O
fourth	O
convolutional	B-Method
layer	I-Method
has	O
384	O
kernels	O
of	O
size	O
3	O
⇥	O
3	O
⇥	O
192	O
,	O
and	O
the	O
fifth	O
convolutional	B-Method
layer	I-Method
has	O
256	O
kernels	O
of	O
size	O
3	O
⇥	O
3	O
⇥	O
192	O
.	O
	
The	O
fully	B-Method
-	I-Method
connected	I-Method
layers	I-Method
have	O
4096	O
neurons	O
each	O
.	O
	
4	O
Reducing	O
Overfitting	B-Task
	
Our	O
neural	B-Method
network	I-Method
architecture	I-Method
has	O
60	O
million	O
parameters	O
.	O
	
Although	O
the	O
1000	O
classes	O
of	O
ILSVRC	B-Material
make	O
each	O
training	O
example	O
impose	O
10	O
bits	O
of	O
constraint	O
on	O
the	O
mapping	O
from	O
image	O
to	O
label	O
,	O
this	O
turns	O
out	O
to	O
be	O
insufficient	O
to	O
learn	O
so	O
many	O
parameters	O
without	O
considerable	O
overfitting	O
.	O
	
Below	O
,	O
we	O
describe	O
the	O
two	O
primary	O
ways	O
in	O
which	O
we	O
combat	O
overfitting	O
.	O
	
4.1	O
Data	B-Task
Augmentation	I-Task
	
The	O
easiest	O
and	O
most	O
common	O
method	O
to	O
reduce	O
overfitting	B-Task
on	O
image	O
data	O
is	O
to	O
artificially	O
enlarge	O
the	O
dataset	O
using	O
label	O
-	O
preserving	O
transformations	O
(	O
e.g.	O
,	O
[	O
25	O
,	O
4	O
,	O
5	O
]	O
)	O
.	O
	
We	O
employ	O
two	O
distinct	O
forms	O
of	O
data	B-Task
augmentation	I-Task
,	O
both	O
of	O
which	O
allow	O
transformed	O
images	O
to	O
be	O
produced	O
from	O
the	O
original	O
images	O
with	O
very	O
little	O
computation	O
,	O
so	O
the	O
transformed	O
images	O
do	O
not	O
need	O
to	O
be	O
stored	O
on	O
disk	O
.	O
	
In	O
our	O
implementation	O
,	O
the	O
transformed	O
images	O
are	O
generated	O
in	O
Python	O
code	O
on	O
the	O
CPU	O
while	O
the	O
GPU	B-Method
is	O
training	O
on	O
the	O
previous	O
batch	O
of	O
images	O
.	O
	
So	O
these	O
data	B-Method
augmentation	I-Method
schemes	I-Method
are	O
,	O
in	O
effect	O
,	O
computationally	O
free	O
.	O
	
The	O
first	O
form	O
of	O
data	B-Task
augmentation	I-Task
consists	O
of	O
generating	B-Task
image	I-Task
translations	I-Task
and	O
horizontal	O
reflections	O
.	O
	
We	O
do	O
this	O
by	O
extracting	O
random	O
224	O
⇥	O
224	O
patches	O
(	O
and	O
their	O
horizontal	O
reflections	O
)	O
from	O
the	O
256	O
⇥	O
256	O
images	O
and	O
training	O
our	O
network	O
on	O
these	O
extracted	O
patches4	O
.	O
	
This	O
increases	O
the	O
size	O
of	O
our	O
training	O
set	O
by	O
a	O
factor	O
of	O
2048	O
,	O
though	O
the	O
resulting	O
training	O
examples	O
are	O
,	O
of	O
course	O
,	O
highly	O
interdependent	O
.	O
	
Without	O
this	O
scheme	O
,	O
our	O
network	O
suffers	O
from	O
substantial	O
overfitting	O
,	O
which	O
would	O
have	O
forced	O
us	O
to	O
use	O
much	O
smaller	O
networks	O
.	O
	
At	O
test	O
time	O
,	O
the	O
network	O
makes	O
a	O
prediction	O
by	O
extracting	O
five	O
224	O
⇥	O
224	O
patches	O
(	O
the	O
four	O
corner	O
patches	O
and	O
the	O
center	O
patch	O
)	O
as	O
well	O
as	O
their	O
horizontal	O
reflections	O
(	O
hence	O
ten	O
patches	O
in	O
all	O
)	O
,	O
and	O
averaging	O
the	O
predictions	O
made	O
by	O
the	O
network	O
’s	O
softmax	B-Method
layer	I-Method
on	O
the	O
ten	O
patches	O
.	O
	
The	O
second	O
form	O
of	O
data	B-Task
augmentation	I-Task
consists	O
of	O
altering	O
the	O
intensities	O
of	O
the	O
RGB	O
channels	O
in	O
training	O
images	O
.	O
	
Specifically	O
,	O
we	O
perform	O
PCA	B-Method
on	O
the	O
set	O
of	O
RGB	B-Material
pixel	I-Material
values	I-Material
throughout	O
the	O
ImageNet	B-Material
training	I-Material
set	I-Material
.	O
	
To	O
each	O
training	O
image	O
,	O
we	O
add	O
multiples	O
of	O
the	O
found	O
principal	O
components	O
,	O
4This	O
is	O
the	O
reason	O
why	O
the	O
input	O
images	O
in	O
Figure	O
2	O
are	O
224	O
⇥	O
224	O
	
⇥	O
	
3	O
-	O
dimensional	O
.	O
with	O
magnitudes	O
proportional	O
to	O
the	O
corresponding	O
eigenvalues	O
times	O
a	O
random	O
variable	O
drawn	O
from	O
a	O
Gaussian	O
with	O
mean	O
zero	O
and	O
standard	O
deviation	O
0.1	O
.	O
	
Therefore	O
to	O
each	O
RGB	B-Material
image	I-Material
pixel	O
Ixy	O
=	O
	
[	O
IRxy	O
,	O
I	O
G	O
xy	O
,	O
	
I	O
B	O
xy	O
]	O
	
T	O
we	O
add	O
the	O
following	O
quantity	O
:	O
[	O
p1	O
,	O
p2	O
,	O
p3	O
]	O
[	O
↵	O
1	O
1	O
,	O
	
↵	O
2	O
2	O
,	O
	
↵	O
	
3	O
3	O
]	O
	
T	O
where	O
pi	O
and	O
i	O
are	O
ith	O
eigenvector	O
and	O
eigenvalue	O
of	O
the	O
3	O
⇥	O
3	O
covariance	O
matrix	O
of	O
RGB	O
pixel	O
values	O
,	O
respectively	O
,	O
and	O
↵	O
i	O
is	O
the	O
aforementioned	O
random	O
variable	O
.	O
	
Each	O
↵	O
i	O
is	O
drawn	O
only	O
once	O
for	O
all	O
the	O
pixels	O
of	O
a	O
particular	O
training	O
image	O
until	O
that	O
image	O
is	O
used	O
for	O
training	O
again	O
,	O
at	O
which	O
point	O
it	O
is	O
re	O
-	O
drawn	O
.	O
	
This	O
scheme	O
approximately	O
captures	O
an	O
important	O
property	O
of	O
natural	O
images	O
,	O
namely	O
,	O
that	O
object	O
identity	O
is	O
invariant	O
to	O
changes	O
in	O
the	O
intensity	O
and	O
color	O
of	O
the	O
illumination	O
.	O
	
This	O
scheme	O
reduces	O
the	O
top	B-Metric
-	I-Metric
1	I-Metric
error	O
rate	O
by	O
over	O
1	O
%	O
.	O
	
4.2	O
Dropout	O
	
Combining	O
the	O
predictions	O
of	O
many	O
different	O
models	O
is	O
a	O
very	O
successful	O
way	O
to	O
reduce	O
test	O
errors	O
[	O
1	O
,	O
3	O
]	O
,	O
but	O
it	O
appears	O
to	O
be	O
too	O
expensive	O
for	O
big	B-Method
neural	I-Method
networks	I-Method
that	O
already	O
take	O
several	O
days	O
to	O
train	O
.	O
	
There	O
is	O
,	O
however	O
,	O
a	O
very	O
efficient	O
version	O
of	O
model	B-Method
combination	I-Method
that	O
only	O
costs	O
about	O
a	O
factor	O
of	O
two	O
during	O
training	O
.	O
	
The	O
recently	O
-	O
introduced	O
technique	O
,	O
called	O
“	O
dropout	B-Method
”	I-Method
[	O
10	O
]	O
,	O
consists	O
of	O
setting	O
to	O
zero	O
the	O
output	O
of	O
each	O
hidden	O
neuron	O
with	O
probability	O
0.5	O
.	O
	
The	O
neurons	O
which	O
are	O
“	O
dropped	O
out	O
”	O
in	O
this	O
way	O
do	O
not	O
contribute	O
to	O
the	O
forward	O
pass	O
and	O
do	O
not	O
participate	O
in	O
backpropagation	B-Method
.	O
	
So	O
every	O
time	O
an	O
input	O
is	O
presented	O
,	O
the	O
neural	B-Method
network	I-Method
samples	O
a	O
different	O
architecture	O
,	O
but	O
all	O
these	O
architectures	O
share	O
weights	O
.	O
	
This	O
technique	O
reduces	O
complex	O
co	O
-	O
adaptations	O
of	O
neurons	O
,	O
since	O
a	O
neuron	O
can	O
not	O
rely	O
on	O
the	O
presence	O
of	O
particular	O
other	O
neurons	O
.	O
	
It	O
is	O
,	O
therefore	O
,	O
forced	O
to	O
learn	O
more	O
robust	O
features	O
that	O
are	O
useful	O
in	O
conjunction	O
with	O
many	O
different	O
random	O
subsets	O
of	O
the	O
other	O
neurons	O
.	O
	
At	O
test	O
time	O
,	O
we	O
use	O
all	O
the	O
neurons	O
but	O
multiply	O
their	O
outputs	O
by	O
0.5	O
,	O
which	O
is	O
a	O
reasonable	O
approximation	O
to	O
taking	O
the	O
geometric	O
mean	O
of	O
the	O
predictive	O
distributions	O
produced	O
by	O
the	O
exponentially	B-Method
-	I-Method
many	I-Method
dropout	I-Method
networks	I-Method
.	O
	
We	O
use	O
dropout	B-Method
in	O
the	O
first	O
two	O
fully	O
-	O
connected	O
layers	O
of	O
Figure	O
2	O
.	O
	
Without	O
dropout	B-Method
,	O
our	O
network	O
exhibits	O
substantial	O
overfitting	O
.	O
	
Dropout	B-Method
roughly	O
doubles	O
the	O
number	O
of	O
iterations	O
required	O
to	O
converge	O
.	O
	
5	O
Details	O
of	O
learning	B-Task
	
We	O
trained	O
our	O
models	O
using	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
with	O
a	O
batch	O
size	O
of	O
128	O
examples	O
,	O
momentum	O
of	O
0.9	O
,	O
and	O
weight	O
decay	O
of	O
0.0005	O
.	O
	
We	O
found	O
that	O
this	O
small	O
amount	O
of	O
weight	O
decay	O
was	O
important	O
for	O
the	O
model	O
to	O
learn	O
.	O
	
In	O
other	O
words	O
,	O
weight	B-Method
decay	I-Method
here	O
is	O
not	O
merely	O
a	O
regularizer	B-Method
:	O
it	O
reduces	O
the	O
model	O
’s	O
training	B-Metric
error	I-Metric
.	O
	
The	O
update	B-Method
rule	I-Method
for	O
weight	O
	
w	O
was	O
	
vi	O
+	O
1	O
	
:	O
=	O
0.9	O
·	O
vi	O
0.0005	O
·	O
✏	O
·	O
wi	O
✏	O
	
·	O
⌧	O
@L	O
@w	O
wi	O
	
Di	O
	
wi	O
+	O
1	O
	
:	O
=	O
wi	O
+	O
vi	O
+	O
1	O
where	O
i	O
is	O
the	O
iteration	O
index	O
,	O
v	O
is	O
the	O
momentum	O
variable	O
,	O
	
✏	O
is	O
the	O
learning	B-Metric
rate	I-Metric
,	O
and	O
D	O
	
@L	O
	
@w	O
	
wi	O
	
E	O
Di	O
is	O
the	O
average	O
over	O
the	O
ith	O
batch	O
Di	O
of	O
the	O
derivative	O
of	O
the	O
objective	O
with	O
respect	O
to	O
w	O
,	O
evaluated	O
at	O
wi	O
.	O
	
We	O
initialized	O
the	O
weights	O
in	O
each	O
layer	O
from	O
a	O
zero	B-Method
-	I-Method
mean	I-Method
Gaussian	I-Method
distribution	I-Method
with	O
standard	O
deviation	O
0.01	O
.	O
	
We	O
initialized	O
the	O
neuron	O
biases	O
in	O
the	O
second	O
,	O
fourth	O
,	O
and	O
fifth	O
convolutional	O
layers	O
,	O
as	O
well	O
as	O
in	O
the	O
fully	O
-	O
connected	O
hidden	O
layers	O
,	O
with	O
the	O
constant	O
1	O
.	O
	
This	O
initialization	O
accelerates	O
the	O
early	O
stages	O
of	O
learning	B-Task
by	O
providing	O
the	O
ReLUs	O
with	O
positive	O
inputs	O
.	O
	
We	O
initialized	O
the	O
neuron	O
biases	O
in	O
the	O
remaining	O
layers	O
with	O
the	O
constant	O
0	O
.	O
	
We	O
used	O
an	O
equal	O
learning	O
rate	O
for	O
all	O
layers	O
,	O
which	O
we	O
adjusted	O
manually	O
throughout	O
training	O
.	O
	
The	O
heuristic	O
which	O
we	O
followed	O
was	O
to	O
divide	O
the	O
learning	B-Metric
rate	I-Metric
by	O
10	O
when	O
the	O
validation	B-Metric
error	I-Metric
rate	I-Metric
stopped	O
improving	O
with	O
the	O
current	O
learning	B-Metric
rate	I-Metric
.	O
	
The	O
learning	B-Metric
rate	I-Metric
was	O
initialized	O
at	O
0.01	O
and	O
reduced	O
three	O
times	O
prior	O
to	O
termination	O
.	O
	
We	O
trained	O
the	O
network	O
for	O
roughly	O
90	O
cycles	O
through	O
the	O
training	O
set	O
of	O
1.2	O
million	O
images	O
,	O
which	O
took	O
five	O
to	O
six	O
days	O
on	O
two	O
NVIDIA	O
GTX	O
580	O
3	O
GB	O
GPUs	B-Method
.	O
	
6	O
Results	O
	
Our	O
results	O
on	O
ILSVRC	B-Material
-	I-Material
2010	I-Material
are	O
summarized	O
in	O
Table	O
1	O
.	O
	
Our	O
network	O
achieves	O
top	B-Metric
-	I-Metric
1	I-Metric
and	O
top	O
-	O
5	O
test	O
set	O
error	O
rates	O
of	O
37.5	O
%	O
and	O
17.0%5	O
.	O
	
The	O
best	O
performance	O
achieved	O
during	O
the	O
ILSVRC2010	B-Metric
competition	I-Metric
was	O
47.1	O
%	O
and	O
28.2	O
%	O
with	O
an	O
approach	O
that	O
averages	O
the	O
predictions	O
produced	O
from	O
six	O
sparse	B-Method
-	I-Method
coding	I-Method
models	I-Method
trained	O
on	O
different	O
features	O
[	O
2	O
]	O
,	O
and	O
since	O
then	O
the	O
best	O
published	O
results	O
are	O
45.7	O
%	O
and	O
25.7	O
%	O
with	O
an	O
approach	O
that	O
averages	O
the	O
predictions	O
of	O
two	O
classifiers	B-Method
trained	O
on	O
Fisher	O
Vectors	O
(	O
FVs	B-Method
)	O
computed	O
from	O
two	O
types	O
of	O
densely	O
-	O
sampled	O
features	O
[	O
24	O
]	O
.	O
	
We	O
also	O
entered	O
our	O
model	O
in	O
the	O
ILSVRC	B-Material
-	O
2012	O
competition	O
and	O
report	O
our	O
results	O
in	O
Table	O
2	O
.	O
	
Since	O
the	O
ILSVRC	B-Material
-	O
2012	O
test	O
set	O
labels	O
are	O
not	O
publicly	O
available	O
,	O
we	O
can	O
not	O
report	O
test	B-Metric
error	I-Metric
rates	I-Metric
for	O
all	O
the	O
models	O
that	O
we	O
tried	O
.	O
	
In	O
the	O
remainder	O
of	O
this	O
paragraph	O
,	O
we	O
use	O
validation	B-Metric
and	I-Metric
test	I-Metric
error	I-Metric
rates	I-Metric
interchangeably	O
because	O
in	O
our	O
experience	O
they	O
do	O
not	O
differ	O
by	O
more	O
than	O
0.1	O
%	O
(	O
see	O
Table	O
2	O
)	O
.	O
	
The	O
CNN	B-Method
described	O
in	O
this	O
paper	O
achieves	O
a	O
top	B-Metric
-	I-Metric
5	I-Metric
error	I-Metric
rate	I-Metric
of	O
18.2	O
%	O
.	O
	
Averaging	O
the	O
predictions	O
of	O
five	O
similar	O
CNNs	B-Method
gives	O
an	O
error	B-Metric
rate	I-Metric
of	O
16.4	O
%	O
.	O
	
Training	B-Task
one	O
CNN	B-Method
,	O
with	O
an	O
extra	O
sixth	B-Method
convolutional	I-Method
layer	I-Method
over	O
the	O
last	O
pooling	B-Method
layer	I-Method
,	O
to	O
classify	O
the	O
entire	O
ImageNet	B-Material
Fall	I-Material
2011	I-Material
release	I-Material
(	O
15	O
M	O
images	O
,	O
22	O
K	O
categories	O
)	O
,	O
and	O
then	O
“	O
fine	O
-	O
tuning	O
”	O
it	O
on	O
ILSVRC	B-Material
-	I-Material
2012	I-Material
gives	O
an	O
error	B-Metric
rate	I-Metric
of	O
16.6	O
%	O
.	O
	
Averaging	O
the	O
predictions	O
of	O
two	O
CNNs	B-Method
that	O
were	O
pre	O
-	O
trained	O
on	O
the	O
entire	O
Fall	O
2011	O
release	O
with	O
the	O
aforementioned	O
five	O
CNNs	B-Method
gives	O
an	O
error	B-Metric
rate	I-Metric
of	O
15.3	O
%	O
.	O
	
The	O
second	O
-	O
best	O
contest	O
entry	O
achieved	O
an	O
error	B-Metric
rate	I-Metric
of	O
26.2	O
%	O
with	O
an	O
approach	O
that	O
averages	O
the	O
predictions	O
of	O
several	O
classifiers	B-Method
trained	O
on	O
FVs	B-Method
computed	O
from	O
different	O
types	O
of	O
densely	O
-	O
sampled	O
features	O
[	O
7	O
]	O
.	O
	
Finally	O
,	O
we	O
also	O
report	O
our	O
error	B-Metric
rates	I-Metric
on	O
the	O
Fall	O
2009	O
version	O
of	O
ImageNet	B-Material
with	O
10	O
,	O
184	O
categories	O
and	O
8.9	O
million	O
images	O
.	O
	
On	O
this	O
dataset	O
we	O
follow	O
the	O
convention	O
in	O
the	O
literature	O
of	O
using	O
half	O
of	O
the	O
images	O
for	O
training	O
and	O
half	O
for	O
testing	O
.	O
	
Since	O
there	O
is	O
no	O
established	O
test	O
set	O
,	O
our	O
split	O
necessarily	O
differs	O
from	O
the	O
splits	O
used	O
by	O
previous	O
authors	O
,	O
but	O
this	O
does	O
not	O
affect	O
the	O
results	O
appreciably	O
.	O
	
Our	O
top	B-Metric
-	I-Metric
1	I-Metric
and	O
top	B-Metric
-	I-Metric
5	I-Metric
error	I-Metric
rates	I-Metric
on	O
this	O
dataset	O
are	O
67.4	O
%	O
and	O
40.9	O
%	O
,	O
attained	O
by	O
the	O
net	O
described	O
above	O
but	O
with	O
an	O
additional	O
,	O
sixth	O
convolutional	B-Method
layer	I-Method
over	O
the	O
last	O
pooling	B-Method
layer	I-Method
.	O
	
The	O
best	O
published	O
results	O
on	O
this	O
dataset	O
are	O
78.1	O
%	O
and	O
60.9	O
%	O
[	O
19	O
]	O
.	O
6.1	O
Qualitative	O
Evaluations	O
Figure	O
3	O
shows	O
the	O
convolutional	B-Method
kernels	I-Method
learned	O
by	O
the	O
network	O
’s	O
two	O
data	B-Method
-	I-Method
connected	I-Method
layers	I-Method
.	O
	
The	O
network	O
has	O
learned	O
a	O
variety	O
of	O
frequency	O
-	O
and	O
orientation	O
-	O
selective	O
kernels	O
,	O
as	O
well	O
as	O
various	O
colored	O
blobs	O
.	O
	
Notice	O
the	O
specialization	O
exhibited	O
by	O
the	O
two	O
GPUs	B-Method
,	O
a	O
result	O
of	O
the	O
restricted	O
connectivity	O
described	O
in	O
Section	O
3.5	O
.	O
	
The	O
kernels	O
on	O
GPU	B-Method
1	I-Method
are	O
largely	O
color	O
-	O
agnostic	O
,	O
while	O
the	O
kernels	O
on	O
on	O
GPU	O
2	O
are	O
largely	O
color	O
-	O
specific	O
.	O
	
This	O
kind	O
of	O
specialization	O
occurs	O
during	O
every	O
run	O
and	O
is	O
independent	O
of	O
any	O
particular	O
random	B-Method
weight	I-Method
initialization	I-Method
(	O
modulo	O
a	O
renumbering	O
of	O
the	O
GPUs	B-Method
)	O
.	O
	
5The	O
error	B-Metric
rates	I-Metric
without	O
averaging	O
predictions	O
over	O
ten	O
patches	O
as	O
described	O
in	O
Section	O
4.1	O
are	O
39.0	O
%	O
and	O
18.3	O
%	O
.	O
	
In	O
the	O
left	O
panel	O
of	O
Figure	O
4	O
we	O
qualitatively	O
assess	O
what	O
the	O
network	O
has	O
learned	O
by	O
computing	O
its	O
top	O
-	O
5	O
predictions	O
on	O
eight	O
test	O
images	O
.	O
	
Notice	O
that	O
even	O
off	O
-	O
center	O
objects	O
,	O
such	O
as	O
the	O
mite	O
in	O
the	O
top	O
-	O
left	O
,	O
can	O
be	O
recognized	O
by	O
the	O
net	O
.	O
	
Most	O
of	O
the	O
top	O
-	O
5	O
labels	O
appear	O
reasonable	O
.	O
	
For	O
example	O
,	O
only	O
other	O
types	O
of	O
cat	O
are	O
considered	O
plausible	O
labels	O
for	O
the	O
leopard	O
.	O
	
In	O
some	O
cases	O
(	O
grille	O
,	O
cherry	O
)	O
	
there	O
is	O
genuine	O
ambiguity	O
about	O
the	O
intended	O
focus	O
of	O
the	O
photograph	O
.	O
	
Another	O
way	O
to	O
probe	O
the	O
network	O
’s	O
visual	O
knowledge	O
is	O
to	O
consider	O
the	O
feature	O
activations	O
induced	O
by	O
an	O
image	O
at	O
the	O
last	O
,	O
4096	O
-	O
dimensional	O
hidden	O
layer	O
.	O
	
If	O
two	O
images	O
produce	O
feature	O
activation	O
vectors	O
with	O
a	O
small	O
Euclidean	O
separation	O
,	O
we	O
can	O
say	O
that	O
the	O
higher	O
levels	O
of	O
the	O
neural	B-Method
network	I-Method
consider	O
them	O
to	O
be	O
similar	O
.	O
	
Figure	O
4	O
shows	O
five	O
images	O
from	O
the	O
test	O
set	O
and	O
the	O
six	O
images	O
from	O
the	O
training	O
set	O
that	O
are	O
most	O
similar	O
to	O
each	O
of	O
them	O
according	O
to	O
this	O
measure	O
.	O
	
Notice	O
that	O
at	O
the	O
pixel	O
level	O
,	O
the	O
retrieved	O
training	O
images	O
are	O
generally	O
not	O
close	O
in	O
L2	O
to	O
the	O
query	O
images	O
in	O
the	O
first	O
column	O
.	O
	
For	O
example	O
,	O
the	O
retrieved	O
dogs	O
and	O
elephants	O
appear	O
in	O
a	O
variety	O
of	O
poses	O
.	O
	
We	O
present	O
the	O
results	O
for	O
many	O
more	O
test	O
images	O
in	O
the	O
supplementary	O
material	O
.	O
	
Computing	B-Task
similarity	I-Task
by	O
using	O
Euclidean	O
distance	O
between	O
two	O
4096	O
-	O
dimensional	O
,	O
real	O
-	O
valued	O
vectors	O
is	O
inefficient	O
,	O
but	O
it	O
could	O
be	O
made	O
efficient	O
by	O
training	O
an	O
auto	B-Method
-	I-Method
encoder	I-Method
to	O
compress	O
these	O
vectors	O
to	O
short	B-Method
binary	I-Method
codes	I-Method
.	O
	
This	O
should	O
produce	O
a	O
much	O
better	O
image	B-Method
retrieval	I-Method
method	I-Method
than	O
applying	O
autoencoders	B-Method
to	O
the	O
raw	O
pixels	O
[	O
14	O
]	O
,	O
which	O
does	O
not	O
make	O
use	O
of	O
image	O
labels	O
and	O
hence	O
has	O
a	O
tendency	O
to	O
retrieve	O
images	O
with	O
similar	O
patterns	O
of	O
edges	O
,	O
whether	O
or	O
not	O
they	O
are	O
semantically	O
similar	O
.	O
	
7	O
Discussion	O
	
Our	O
results	O
show	O
that	O
a	O
large	O
,	O
deep	B-Method
convolutional	I-Method
neural	I-Method
network	I-Method
is	O
capable	O
of	O
achieving	O
recordbreaking	O
results	O
on	O
a	O
highly	O
challenging	O
dataset	O
using	O
purely	O
supervised	B-Method
learning	I-Method
.	O
	
It	O
is	O
notable	O
that	O
our	O
network	O
’s	O
performance	O
degrades	O
if	O
a	O
single	O
convolutional	B-Method
layer	I-Method
is	O
removed	O
.	O
	
For	O
example	O
,	O
removing	O
any	O
of	O
the	O
middle	O
layers	O
results	O
in	O
a	O
loss	O
of	O
about	O
2	O
%	O
for	O
the	O
top	B-Metric
-	I-Metric
1	I-Metric
performance	O
of	O
the	O
network	O
.	O
	
So	O
the	O
depth	O
really	O
is	O
important	O
for	O
achieving	O
our	O
results	O
.	O
	
To	O
simplify	O
our	O
experiments	O
,	O
we	O
did	O
not	O
use	O
any	O
unsupervised	B-Task
pre	I-Task
-	I-Task
training	I-Task
even	O
though	O
we	O
expect	O
that	O
it	O
will	O
help	O
,	O
especially	O
if	O
we	O
obtain	O
enough	O
computational	O
power	O
to	O
significantly	O
increase	O
the	O
size	O
of	O
the	O
network	O
without	O
obtaining	O
a	O
corresponding	O
increase	O
in	O
the	O
amount	O
of	O
labeled	O
data	O
.	O
	
Thus	O
far	O
,	O
our	O
results	O
have	O
improved	O
as	O
we	O
have	O
made	O
our	O
network	O
larger	O
and	O
trained	O
it	O
longer	O
	
but	O
we	O
still	O
have	O
many	O
orders	O
of	O
magnitude	O
to	O
go	O
in	O
order	O
to	O
match	O
the	O
infero	O
-	O
temporal	O
pathway	O
of	O
the	O
human	B-Method
visual	I-Method
system	I-Method
.	O
	
Ultimately	O
we	O
would	O
like	O
to	O
use	O
very	O
large	O
and	O
deep	B-Method
convolutional	I-Method
nets	I-Method
on	O
video	O
sequences	O
where	O
the	O
temporal	O
structure	O
provides	O
very	O
helpful	O
information	O
that	O
is	O
missing	O
or	O
far	O
less	O
obvious	O
in	O
static	O
images	O
.	O
	
document	O
:	O
Attending	O
to	O
Characters	O
in	O
Neural	B-Method
Sequence	I-Method
Labeling	I-Method
Models	I-Method
	
Sequence	B-Method
labeling	I-Method
architectures	I-Method
use	O
word	O
embeddings	O
for	O
capturing	O
similarity	B-Task
,	O
but	O
suffer	O
when	O
handling	O
previously	O
unseen	O
or	O
rare	O
words	O
.	O
	
We	O
investigate	O
character	B-Method
-	I-Method
level	I-Method
extensions	I-Method
to	O
such	O
models	O
and	O
propose	O
a	O
novel	O
architecture	O
for	O
combining	O
alternative	O
word	B-Method
representations	I-Method
.	O
	
By	O
using	O
an	O
attention	B-Method
mechanism	I-Method
,	O
the	O
model	O
is	O
able	O
to	O
dynamically	O
decide	O
how	O
much	O
information	O
to	O
use	O
from	O
a	O
word	O
-	O
or	O
character	O
-	O
level	O
component	O
.	O
	
We	O
evaluated	O
different	O
architectures	O
on	O
a	O
range	O
of	O
sequence	O
labeling	O
datasets	O
,	O
and	O
character	B-Method
-	I-Method
level	I-Method
extensions	I-Method
were	O
found	O
to	O
improve	O
performance	O
on	O
every	O
benchmark	O
.	O
	
In	O
addition	O
,	O
the	O
proposed	O
attention	B-Method
-	I-Method
based	I-Method
architecture	I-Method
delivered	O
the	O
best	O
results	O
even	O
with	O
a	O
smaller	O
number	O
of	O
trainable	O
parameters	O
.	O
	
section	O
:	O
Introduction	O
	
This	O
work	O
is	O
licenced	O
under	O
a	O
Creative	O
Commons	O
Attribution	O
4.0	O
International	O
Licence	O
.	O
	
Licence	O
details	O
:	O
	
Many	O
NLP	B-Task
tasks	I-Task
,	O
including	O
named	B-Task
entity	I-Task
recognition	I-Task
(	O
NER	B-Task
)	O
,	O
part	B-Task
-	I-Task
of	I-Task
-	I-Task
speech	I-Task
(	O
POS	B-Task
)	O
tagging	O
and	O
shallow	O
parsing	B-Task
can	O
be	O
framed	O
as	O
types	O
of	O
sequence	B-Task
labeling	I-Task
.	O
	
The	O
development	O
of	O
accurate	O
and	O
efficient	O
sequence	B-Method
labeling	I-Method
models	I-Method
is	O
thereby	O
useful	O
for	O
a	O
wide	O
range	O
of	O
downstream	B-Task
applications	I-Task
.	O
	
Work	O
in	O
this	O
area	O
has	O
traditionally	O
involved	O
task	O
-	O
specific	O
feature	B-Task
engineering	I-Task
–	O
for	O
example	O
,	O
integrating	O
gazetteers	B-Task
for	O
named	B-Task
entity	I-Task
recognition	I-Task
,	O
or	O
using	O
features	O
from	O
a	O
morphological	B-Method
analyser	I-Method
in	O
POS	B-Task
-	I-Task
tagging	I-Task
.	O
	
Recent	O
developments	O
in	O
neural	B-Method
architectures	I-Method
and	O
representation	B-Method
learning	I-Method
have	O
opened	O
the	O
door	O
to	O
models	O
that	O
can	O
discover	O
useful	O
features	O
automatically	O
from	O
the	O
data	O
.	O
	
Such	O
sequence	B-Method
labeling	I-Method
systems	I-Method
are	O
applicable	O
to	O
many	O
tasks	O
,	O
using	O
only	O
the	O
surface	O
text	O
as	O
input	O
,	O
yet	O
are	O
able	O
to	O
achieve	O
competitive	O
results	O
.	O
	
Current	O
neural	B-Method
models	I-Method
generally	O
make	O
use	O
of	O
word	B-Method
embeddings	I-Method
,	O
which	O
allow	O
them	O
to	O
learn	O
similar	O
representations	O
for	O
semantically	O
or	O
functionally	O
similar	O
words	O
.	O
	
While	O
this	O
is	O
an	O
important	O
improvement	O
over	O
count	B-Method
-	I-Method
based	I-Method
models	I-Method
,	O
they	O
still	O
have	O
weaknesses	O
that	O
should	O
be	O
addressed	O
.	O
	
The	O
most	O
obvious	O
problem	O
arises	O
when	O
dealing	O
with	O
out	B-Task
-	I-Task
of	I-Task
-	I-Task
vocabulary	I-Task
(	O
OOV	B-Task
)	O
words	O
–	O
if	O
a	O
token	O
has	O
never	O
been	O
seen	O
before	O
,	O
then	O
it	O
does	O
not	O
have	O
an	O
embedding	O
and	O
the	O
model	O
needs	O
to	O
back	O
-	O
off	O
to	O
a	O
generic	O
OOV	B-Task
representation	O
.	O
	
Words	O
that	O
have	O
been	O
seen	O
very	O
infrequently	O
have	O
embeddings	O
,	O
but	O
they	O
will	O
likely	O
have	O
low	O
quality	O
due	O
to	O
lack	O
of	O
training	O
data	O
.	O
	
The	O
approach	O
can	O
also	O
be	O
sub	O
-	O
optimal	O
in	O
terms	O
of	O
parameter	O
usage	O
–	O
for	O
example	O
,	O
certain	O
suffixes	O
indicate	O
more	O
likely	O
POS	B-Task
tags	O
for	O
these	O
words	O
,	O
but	O
this	O
information	O
gets	O
encoded	O
into	O
each	O
individual	O
embedding	O
as	O
opposed	O
to	O
being	O
shared	O
between	O
the	O
whole	O
vocabulary	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
construct	O
a	O
task	B-Method
-	I-Method
independent	I-Method
neural	I-Method
network	I-Method
architecture	I-Method
for	O
sequence	B-Task
labeling	I-Task
,	O
and	O
then	O
extend	O
it	O
with	O
two	O
different	O
approaches	O
for	O
integrating	O
character	B-Task
-	I-Task
level	I-Task
information	I-Task
.	O
	
By	O
operating	O
on	O
individual	O
characters	O
,	O
the	O
model	O
is	O
able	O
to	O
infer	O
representations	O
for	O
previously	O
unseen	O
words	O
and	O
share	O
information	O
about	O
morpheme	O
-	O
level	O
regularities	O
.	O
	
We	O
propose	O
a	O
novel	O
architecture	O
for	O
combining	O
character	B-Method
-	I-Method
level	I-Method
representations	I-Method
with	O
word	B-Method
embeddings	I-Method
using	O
a	O
gating	B-Method
mechanism	I-Method
,	O
also	O
referred	O
to	O
as	O
attention	O
,	O
which	O
allows	O
the	O
model	O
to	O
dynamically	O
decide	O
which	O
source	O
of	O
information	O
to	O
use	O
for	O
each	O
word	O
.	O
	
In	O
addition	O
,	O
we	O
describe	O
a	O
new	O
objective	O
for	O
model	B-Task
training	I-Task
where	O
the	O
character	B-Method
-	I-Method
level	I-Method
representations	I-Method
are	O
optimised	O
to	O
mimic	O
the	O
current	O
state	O
of	O
word	O
embeddings	O
.	O
	
We	O
evaluate	O
the	O
neural	B-Method
models	I-Method
on	O
8	O
datasets	O
from	O
the	O
fields	O
of	O
NER	B-Task
,	O
POS	B-Task
-	I-Task
tagging	I-Task
,	O
chunking	B-Task
and	O
error	B-Task
detection	I-Task
in	O
learner	O
texts	O
.	O
	
Our	O
experiments	O
show	O
that	O
including	O
a	O
character	B-Method
-	I-Method
based	I-Method
component	I-Method
in	O
the	O
sequence	B-Method
labeling	I-Method
model	I-Method
provides	O
substantial	O
performance	O
improvements	O
on	O
all	O
the	O
benchmarks	O
.	O
	
In	O
addition	O
,	O
the	O
attention	B-Method
-	I-Method
based	I-Method
architecture	I-Method
achieves	O
the	O
best	O
results	O
on	O
all	O
evaluations	O
,	O
while	O
requiring	O
a	O
smaller	O
number	O
of	O
parameters	O
.	O
	
section	O
:	O
Bidirectional	O
LSTM	B-Method
for	O
sequence	B-Task
labeling	I-Task
	
We	O
first	O
describe	O
a	O
basic	O
word	B-Method
-	I-Method
level	I-Method
neural	I-Method
network	I-Method
for	O
sequence	B-Task
labeling	I-Task
,	O
following	O
the	O
models	O
described	O
by	O
Lample2016	O
and	O
Rei2016	O
,	O
and	O
then	O
propose	O
two	O
alternative	O
methods	O
for	O
incorporating	O
character	O
-	O
level	O
information	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
the	O
general	O
architecture	O
of	O
the	O
sequence	B-Method
labeling	I-Method
network	I-Method
.	O
	
The	O
model	O
receives	O
a	O
sequence	O
of	O
tokens	O
as	O
input	O
,	O
and	O
predicts	O
a	O
label	O
corresponding	O
to	O
each	O
of	O
the	O
input	O
tokens	O
.	O
	
The	O
tokens	O
are	O
first	O
mapped	O
to	O
a	O
distributed	O
vector	O
space	O
,	O
resulting	O
in	O
a	O
sequence	O
of	O
word	B-Method
embeddings	I-Method
.	O
	
Next	O
,	O
the	O
embeddings	O
are	O
given	O
as	O
input	O
to	O
two	O
LSTM	B-Method
components	O
moving	O
in	O
opposite	O
directions	O
through	O
the	O
text	O
,	O
creating	O
context	B-Method
-	I-Method
specific	I-Method
representations	I-Method
.	O
	
The	O
respective	O
forward	B-Method
-	I-Method
and	I-Method
backward	I-Method
-	I-Method
conditioned	I-Method
representations	I-Method
are	O
concatenated	O
for	O
each	O
word	O
position	O
,	O
resulting	O
in	O
representations	O
that	O
are	O
conditioned	O
on	O
the	O
whole	O
sequence	O
:	O
We	O
include	O
an	O
extra	O
narrow	O
hidden	O
layer	O
on	O
top	O
of	O
the	O
LSTM	B-Method
,	O
which	O
proved	O
to	O
be	O
a	O
useful	O
modification	O
based	O
on	O
development	O
experiments	O
.	O
	
An	O
additional	O
hidden	O
layer	O
allows	O
the	O
model	O
to	O
detect	O
higher	O
-	O
level	O
feature	O
combinations	O
,	O
while	O
constraining	O
it	O
to	O
be	O
small	O
forces	O
it	O
to	O
focus	O
on	O
more	O
generalisable	O
patterns	O
:	O
where	O
is	O
a	O
weight	O
matrix	O
between	O
the	O
layers	O
,	O
and	O
the	O
size	O
of	O
is	O
intentionally	O
kept	O
small	O
.	O
	
Finally	O
,	O
to	O
produce	O
label	B-Task
predictions	I-Task
,	O
we	O
use	O
either	O
a	O
softmax	B-Method
layer	I-Method
or	O
a	O
conditional	B-Method
random	I-Method
field	I-Method
(	O
CRF	B-Method
,	O
Lafferty2001	O
)	O
.	O
	
The	O
softmax	B-Method
calculates	O
a	O
normalised	O
probability	O
distribution	O
over	O
all	O
the	O
possible	O
labels	O
for	O
each	O
word	O
:	O
where	O
is	O
the	O
probability	O
of	O
the	O
label	O
of	O
the	O
-	O
th	O
word	O
(	O
)	O
being	O
,	O
is	O
the	O
set	O
of	O
all	O
possible	O
labels	O
,	O
and	O
is	O
the	O
-	O
th	O
row	O
of	O
output	O
weight	O
matrix	O
.	O
	
To	O
optimise	O
this	O
model	O
,	O
we	O
minimise	O
categorical	B-Method
crossentropy	I-Method
,	O
which	O
is	O
equivalent	O
to	O
minimising	O
the	O
negative	O
log	O
-	O
probability	O
of	O
the	O
correct	O
labels	O
:	O
	
Following	O
Huang2015	O
,	O
we	O
can	O
also	O
use	O
a	O
CRF	B-Method
as	O
the	O
output	B-Method
layer	I-Method
,	O
which	O
conditions	O
each	O
prediction	O
on	O
the	O
previously	O
predicted	O
label	O
.	O
	
In	O
this	O
architecture	O
,	O
the	O
last	O
hidden	O
layer	O
is	O
used	O
to	O
predict	O
confidence	O
scores	O
for	O
the	O
word	O
having	O
each	O
of	O
the	O
possible	O
labels	O
.	O
	
A	O
separate	O
weight	O
matrix	O
is	O
used	O
to	O
learn	O
transition	O
probabilities	O
between	O
different	O
labels	O
,	O
and	O
the	O
Viterbi	B-Method
algorithm	I-Method
is	O
used	O
to	O
find	O
an	O
optimal	O
sequence	O
of	O
weights	O
.	O
	
Given	O
that	O
is	O
a	O
sequence	O
of	O
labels	O
,	O
then	O
the	O
CRF	B-Metric
score	I-Metric
for	O
this	O
sequence	O
can	O
be	O
calculated	O
as	O
:	O
where	O
shows	O
how	O
confident	O
the	O
network	O
is	O
that	O
the	O
label	O
on	O
the	O
-	O
th	O
word	O
is	O
.	O
shows	O
the	O
likelihood	O
of	O
transitioning	O
from	O
label	O
to	O
label	O
,	O
and	O
these	O
values	O
are	O
optimised	O
during	O
training	O
.	O
	
The	O
output	O
from	O
the	O
model	O
is	O
the	O
sequence	O
of	O
labels	O
with	O
the	O
largest	O
score	O
,	O
which	O
can	O
be	O
found	O
efficiently	O
using	O
the	O
Viterbi	B-Method
algorithm	I-Method
.	O
	
In	O
order	O
to	O
optimise	O
the	O
CRF	B-Method
model	I-Method
,	O
the	O
loss	B-Method
function	I-Method
maximises	O
the	O
score	O
for	O
the	O
correct	O
label	O
sequence	O
,	O
while	O
minimising	O
the	O
scores	O
for	O
all	O
other	O
sequences	O
:	O
where	O
is	O
the	O
set	O
of	O
all	O
possible	O
label	O
sequences	O
.	O
	
section	O
:	O
Character	B-Task
-	I-Task
level	I-Task
sequence	I-Task
labeling	I-Task
	
Distributed	B-Method
embeddings	I-Method
map	O
words	O
into	O
a	O
space	O
where	O
semantically	O
similar	O
words	O
have	O
similar	O
vector	B-Method
representations	I-Method
,	O
allowing	O
the	O
models	O
to	O
generalise	O
better	O
.	O
	
However	O
,	O
they	O
still	O
treat	O
words	O
as	O
atomic	O
units	O
and	O
ignore	O
any	O
surface	O
-	O
or	O
morphological	O
similarities	O
between	O
different	O
words	O
.	O
	
By	O
constructing	O
models	O
that	O
operate	O
over	O
individual	O
characters	O
in	O
each	O
word	O
,	O
we	O
can	O
take	O
advantage	O
of	O
these	O
regularities	O
.	O
	
This	O
can	O
be	O
particularly	O
useful	O
for	O
handling	O
unseen	O
words	O
–	O
for	O
example	O
,	O
if	O
we	O
have	O
never	O
seen	O
the	O
word	O
cabinets	O
before	O
,	O
a	O
character	B-Method
-	I-Method
level	I-Method
model	I-Method
could	O
still	O
infer	O
a	O
representation	O
for	O
this	O
word	O
if	O
it	O
has	O
previously	O
seen	O
the	O
word	O
cabinet	O
and	O
other	O
words	O
with	O
the	O
suffix	O
-	O
s	O
.	O
	
In	O
contrast	O
,	O
a	O
word	B-Method
-	I-Method
level	I-Method
model	I-Method
can	O
only	O
represent	O
this	O
word	O
with	O
a	O
generic	O
out	B-Task
-	I-Task
of	I-Task
-	I-Task
vocabulary	I-Task
representation	O
,	O
which	O
is	O
shared	O
between	O
all	O
other	O
unseen	O
words	O
.	O
	
Research	O
into	O
character	B-Method
-	I-Method
level	I-Method
models	I-Method
is	O
still	O
in	O
fairly	O
early	O
stages	O
,	O
and	O
models	O
that	O
operate	O
exclusively	O
on	O
characters	O
are	O
not	O
yet	O
competitive	O
to	O
word	B-Method
-	I-Method
level	I-Method
models	I-Method
on	O
most	O
tasks	O
.	O
	
However	O
,	O
instead	O
of	O
fully	O
replacing	O
word	O
embeddings	O
,	O
we	O
are	O
interested	O
in	O
combining	O
the	O
two	O
approaches	O
,	O
thereby	O
allowing	O
the	O
model	O
to	O
take	O
advantage	O
of	O
information	O
at	O
both	O
granularity	O
levels	O
.	O
	
The	O
general	O
outline	O
of	O
our	O
approach	O
is	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Each	O
word	O
is	O
broken	O
down	O
into	O
individual	O
characters	O
,	O
these	O
are	O
then	O
mapped	O
to	O
a	O
sequence	O
of	O
character	O
embeddings	O
,	O
which	O
are	O
passed	O
through	O
a	O
bidirectional	O
LSTM	B-Method
:	O
We	O
then	O
use	O
the	O
last	O
hidden	O
vectors	O
from	O
each	O
of	O
the	O
LSTM	B-Method
components	O
,	O
concatenate	O
them	O
together	O
,	O
and	O
pass	O
the	O
result	O
through	O
a	O
separate	O
non	B-Method
-	I-Method
linear	I-Method
layer	I-Method
.	O
	
where	O
is	O
a	O
weight	O
matrix	O
mapping	O
the	O
concatenated	O
hidden	O
vectors	O
from	O
both	O
LSTMs	B-Method
into	O
a	O
joint	B-Method
word	I-Method
representation	I-Method
,	O
built	O
from	O
individual	O
characters	O
.	O
	
We	O
now	O
have	O
two	O
alternative	O
feature	B-Method
representations	I-Method
for	O
each	O
word	O
–	O
from	O
Section	O
[	O
reference	O
]	O
is	O
an	O
embedding	B-Method
learned	O
on	O
the	O
word	O
level	O
,	O
and	O
is	O
a	O
representation	O
dynamically	O
built	O
from	O
individual	O
characters	O
in	O
the	O
-	O
th	O
word	O
of	O
the	O
input	O
text	O
.	O
	
Following	O
Lample2016	O
,	O
one	O
possible	O
approach	O
is	O
to	O
concatenate	O
the	O
two	O
vectors	O
and	O
use	O
this	O
as	O
the	O
new	O
word	B-Method
-	I-Method
level	I-Method
representation	I-Method
for	O
the	O
sequence	B-Method
labeling	I-Method
model	I-Method
:	O
This	O
approach	O
,	O
also	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
assumes	O
that	O
the	O
word	O
-	O
level	O
and	O
character	O
-	O
level	O
components	O
learn	O
somewhat	O
disjoint	O
information	O
,	O
and	O
it	O
is	O
beneficial	O
to	O
give	O
them	O
separately	O
as	O
input	O
to	O
the	O
sequence	B-Task
labeler	I-Task
.	O
	
section	O
:	O
Attention	O
over	O
character	O
features	O
	
Alternatively	O
,	O
we	O
can	O
have	O
the	O
word	B-Method
embedding	I-Method
and	O
the	O
character	B-Method
-	I-Method
level	I-Method
component	I-Method
learn	O
the	O
same	O
semantic	O
features	O
for	O
each	O
word	O
.	O
	
Instead	O
of	O
concatenating	O
them	O
as	O
alternative	O
feature	O
sets	O
,	O
we	O
specifically	O
construct	O
the	O
network	O
so	O
that	O
they	O
would	O
learn	O
the	O
same	O
representations	O
,	O
and	O
then	O
allow	O
the	O
model	O
to	O
decide	O
how	O
to	O
combine	O
the	O
information	O
for	O
each	O
specific	O
word	O
.	O
	
We	O
first	O
construct	O
the	O
word	B-Method
representation	I-Method
from	O
characters	O
using	O
the	O
same	O
architecture	O
	
–	O
a	O
bidirectional	O
LSTM	B-Method
operates	O
over	O
characters	O
,	O
and	O
the	O
last	O
hidden	O
states	O
are	O
used	O
to	O
create	O
vector	O
for	O
the	O
input	O
word	O
.	O
	
Instead	O
of	O
concatenating	O
this	O
with	O
the	O
word	B-Method
embedding	I-Method
,	O
the	O
two	O
vectors	O
are	O
added	O
together	O
using	O
a	O
weighted	B-Method
sum	I-Method
,	O
where	O
the	O
weights	O
are	O
predicted	O
by	O
a	O
two	O
-	O
layer	B-Method
network	I-Method
:	O
where	O
,	O
and	O
are	O
weight	O
matrices	O
for	O
calculating	O
,	O
and	O
is	O
the	O
logistic	B-Method
function	I-Method
with	O
values	O
in	O
the	O
range	O
.	O
	
The	O
vector	O
has	O
the	O
same	O
dimensions	O
as	O
or	O
,	O
acting	O
as	O
the	O
weight	O
between	O
the	O
two	O
vectors	O
.	O
	
It	O
allows	O
the	O
model	O
to	O
dynamically	O
decide	O
how	O
much	O
information	O
to	O
use	O
from	O
the	O
character	B-Method
-	I-Method
level	I-Method
component	I-Method
or	O
from	O
the	O
word	B-Method
embedding	I-Method
.	O
	
This	O
decision	O
is	O
done	O
for	O
each	O
feature	O
separately	O
,	O
which	O
adds	O
extra	O
flexiblity	O
–	O
for	O
example	O
,	O
words	O
with	O
regular	O
suffixes	O
can	O
share	O
some	O
character	O
-	O
level	O
features	O
,	O
whereas	O
irregular	O
words	O
can	O
store	O
exceptions	O
into	O
word	O
embeddings	O
.	O
	
Furthermore	O
,	O
previously	O
unknown	O
words	O
are	O
able	O
to	O
use	O
character	O
-	O
level	O
regularities	O
whenever	O
possible	O
,	O
and	O
are	O
still	O
able	O
to	O
revert	O
to	O
using	O
the	O
generic	O
OOV	B-Task
token	O
when	O
necessary	O
.	O
	
The	O
main	O
benefits	O
of	O
character	B-Method
-	I-Method
level	I-Method
modeling	I-Method
are	O
expected	O
to	O
come	O
from	O
improved	O
handling	O
of	O
rare	O
and	O
unseen	O
words	O
,	O
whereas	O
frequent	O
words	O
are	O
likely	O
able	O
to	O
learn	O
high	O
-	O
quality	O
word	O
-	O
level	O
embeddings	O
directly	O
.	O
	
We	O
would	O
like	O
to	O
take	O
advantage	O
of	O
this	O
,	O
and	O
train	O
the	O
character	B-Method
component	I-Method
to	O
predict	O
these	O
word	O
embeddings	O
.	O
	
Our	O
attention	B-Method
-	I-Method
based	I-Method
architecture	I-Method
requires	O
the	O
learned	O
features	O
in	O
both	O
word	B-Method
representations	I-Method
to	O
align	O
,	O
and	O
we	O
can	O
add	O
in	O
an	O
extra	O
constraint	O
to	O
encourage	O
this	O
.	O
	
During	O
training	B-Task
,	O
we	O
add	O
a	O
term	O
to	O
the	O
loss	O
function	O
that	O
optimises	O
the	O
vector	O
to	O
be	O
similar	O
to	O
the	O
word	O
embedding	O
:	O
Equation	O
[	O
reference	O
]	O
maximises	O
the	O
cosine	O
similarity	O
between	O
and	O
.	O
	
Importantly	O
,	O
this	O
is	O
done	O
only	O
for	O
words	O
that	O
are	O
not	O
out	B-Task
-	I-Task
of	I-Task
-	I-Task
vocabulary	I-Task
–	O
	
we	O
want	O
the	O
character	B-Method
-	I-Method
level	I-Method
component	I-Method
to	O
learn	O
from	O
the	O
word	O
embeddings	O
,	O
but	O
this	O
should	O
exclude	O
the	O
OOV	B-Task
embedding	O
,	O
as	O
it	O
is	O
shared	O
between	O
many	O
words	O
.	O
	
We	O
use	O
to	O
set	O
this	O
cost	B-Method
component	I-Method
to	O
for	O
any	O
OOV	B-Task
tokens	O
.	O
	
While	O
the	O
character	B-Method
component	I-Method
learns	O
general	O
regularities	O
that	O
are	O
shared	O
between	O
all	O
the	O
words	O
,	O
individual	O
word	O
embeddings	O
provide	O
a	O
way	O
for	O
the	O
model	O
to	O
store	O
word	O
-	O
specific	O
information	O
and	O
any	O
exceptions	O
.	O
	
Therefore	O
,	O
while	O
we	O
want	O
the	O
character	B-Method
-	I-Method
based	I-Method
model	I-Method
to	O
shift	O
towards	O
predicting	O
high	B-Task
-	I-Task
quality	I-Task
word	I-Task
embeddings	I-Task
,	O
it	O
is	O
not	O
desireable	O
to	O
optimise	O
the	O
word	O
embeddings	O
towards	O
the	O
character	B-Method
-	I-Method
level	I-Method
representations	I-Method
.	O
	
This	O
can	O
be	O
achieved	O
by	O
making	O
sure	O
that	O
the	O
optimisation	B-Task
is	O
performed	O
only	O
in	O
one	O
direction	O
;	O
in	O
Theano	O
,	O
the	O
disconnected_grad	O
function	O
gives	O
the	O
desired	O
effect	O
.	O
	
section	O
:	O
Datasets	O
	
We	O
evaluate	O
the	O
sequence	B-Method
labeling	I-Method
models	I-Method
and	O
character	B-Method
architectures	I-Method
on	O
8	O
different	O
datasets	O
.	O
	
Table	O
[	O
reference	O
]	O
contains	O
information	O
about	O
the	O
number	O
of	O
labels	O
and	O
dataset	O
sizes	O
for	O
each	O
of	O
them	O
.	O
	
CoNLL00	B-Material
:	O
	
The	O
CoNLL	B-Material
-	I-Material
2000	I-Material
dataset	I-Material
is	O
a	O
frequently	O
used	O
benchmark	O
for	O
the	O
task	O
of	O
chunking	B-Task
.	O
	
Wall	B-Material
Street	I-Material
Journal	I-Material
Sections	I-Material
15	O
-	O
18	O
from	O
the	O
Penn	B-Material
Treebank	I-Material
are	O
used	O
for	O
training	O
,	O
and	O
Section	O
20	O
as	O
the	O
test	O
data	O
.	O
	
As	O
there	O
is	O
no	O
official	O
development	O
set	O
,	O
we	O
separated	O
some	O
of	O
the	O
training	O
set	O
for	O
this	O
purpose	O
.	O
	
CoNLL03	B-Material
:	O
	
The	O
CoNLL	B-Material
-	I-Material
2003	I-Material
corpus	I-Material
was	O
created	O
for	O
the	O
shared	B-Task
task	I-Task
on	O
language	O
-	O
independent	O
NER	B-Task
.	O
	
We	O
use	O
the	O
English	B-Material
section	I-Material
of	O
the	O
dataset	O
,	O
containing	O
news	O
stories	O
from	O
the	O
Reuters	B-Material
Corpus	I-Material
.	O
	
PTB	B-Material
-	I-Material
POS	I-Material
	
:	O
The	O
Penn	B-Material
Treebank	I-Material
POS	I-Task
-	O
tag	O
corpus	O
contains	O
texts	O
from	O
the	O
Wall	B-Material
Street	I-Material
Journal	I-Material
,	O
annotated	O
for	O
part	B-Task
-	I-Task
of	I-Task
-	I-Task
speech	I-Task
tags	O
.	O
	
The	O
PTB	B-Material
label	I-Material
set	I-Material
includes	O
36	O
main	O
tags	O
and	O
an	O
additional	O
12	O
tags	O
covering	O
items	O
such	O
as	O
punctuation	O
.	O
	
FCEPUBLIC	B-Material
:	O
	
The	O
publicly	O
released	O
subset	O
of	O
the	O
First	B-Material
Certificate	I-Material
in	I-Material
English	I-Material
(	O
FCE	B-Material
)	O
dataset	O
contains	O
short	O
essays	O
written	O
by	O
language	O
learners	O
and	O
manual	O
corrections	O
by	O
examiners	O
.	O
	
We	O
use	O
a	O
version	O
of	O
this	O
corpus	O
converted	O
into	O
a	O
binary	B-Task
error	I-Task
detection	I-Task
task	I-Task
,	O
where	O
each	O
token	O
is	O
labeled	O
as	O
being	O
correct	O
or	O
incorrect	O
in	O
the	O
given	O
context	O
.	O
	
BC2GM	B-Material
:	O
	
The	O
BioCreative	B-Material
II	I-Material
Gene	I-Material
Mention	I-Material
corpus	I-Material
consists	O
of	O
20	O
,	O
000	O
sentences	O
from	O
biomedical	O
publication	O
abstracts	O
and	O
is	O
annotated	O
for	O
mentions	O
of	O
the	O
names	O
of	O
genes	O
,	O
proteins	O
and	O
related	O
entities	O
using	O
a	O
single	O
NE	O
class	O
.	O
	
CHEMDNER	B-Method
:	O
	
The	O
BioCreative	O
IV	O
Chemical	O
and	O
Drug	O
NER	B-Task
corpus	O
consists	O
of	O
10	O
,	O
000	O
abstracts	O
annotated	O
for	O
mentions	O
of	O
chemical	O
and	O
drug	O
names	O
using	O
a	O
single	O
class	O
.	O
	
We	O
make	O
use	O
of	O
the	O
official	O
splits	O
provided	O
by	O
the	O
shared	O
task	O
organizers	O
.	O
	
JNLPBA	B-Material
:	O
	
The	O
JNLPBA	B-Material
corpus	O
consists	O
of	O
2	O
,	O
404	O
biomedical	O
abstracts	O
and	O
is	O
annotated	O
for	O
mentions	O
of	O
five	O
entity	O
types	O
:	O
cell	O
line	O
,	O
cell	O
type	O
,	O
dna	O
,	O
rna	O
,	O
and	O
protein	O
.	O
	
The	O
corpus	O
was	O
derived	O
from	O
GENIA	B-Material
corpus	I-Material
entity	I-Material
annotations	I-Material
for	O
use	O
in	O
the	O
shared	B-Task
task	I-Task
organized	O
in	O
conjuction	O
with	O
the	O
BioNLP	B-Material
2004	I-Material
workshop	I-Material
.	O
	
GENIA	O
-	O
POS	B-Task
:	O
The	O
GENIA	B-Material
corpus	I-Material
is	O
one	O
of	O
the	O
most	O
widely	O
used	O
resources	O
for	O
biomedical	B-Task
NLP	I-Task
and	O
has	O
a	O
rich	O
set	O
of	O
annotations	O
including	O
parts	O
of	O
speech	O
,	O
phrase	O
structure	O
syntax	O
,	O
entity	O
mentions	O
,	O
and	O
events	O
.	O
	
Here	O
,	O
we	O
make	O
use	O
of	O
the	O
GENIA	O
POS	B-Task
annotations	O
,	O
which	O
cover	O
2	O
,	O
000	O
PubMed	B-Material
abstracts	O
(	O
approx	O
.	O
	
20	O
,	O
000	O
sentences	O
)	O
.	O
	
We	O
use	O
the	O
same	O
210	O
-	O
document	O
test	O
set	O
as	O
Tsuruoka2005	O
,	O
and	O
additionally	O
split	O
off	O
a	O
sample	O
of	O
210	O
from	O
the	O
remaining	O
documents	O
as	O
a	O
development	O
set	O
.	O
	
section	O
:	O
Experiment	O
settings	O
	
For	O
data	B-Task
prepocessing	I-Task
,	O
all	O
digits	O
were	O
replaced	O
with	O
the	O
character	O
’	O
0	O
’	O
.	O
	
Any	O
words	O
that	O
occurred	O
only	O
once	O
in	O
the	O
training	O
data	O
were	O
replaced	O
by	O
the	O
generic	O
OOV	B-Task
token	O
for	O
word	O
embeddings	O
,	O
but	O
were	O
still	O
used	O
in	O
the	O
character	B-Method
-	I-Method
level	I-Method
components	I-Method
.	O
	
The	O
word	O
embeddings	O
were	O
initialised	O
with	O
publicly	O
available	O
pretrained	O
vectors	O
,	O
created	O
using	O
word2vec	O
,	O
and	O
then	O
fine	O
-	O
tuned	O
during	O
model	B-Method
training	I-Method
.	O
	
For	O
the	O
general	O
-	O
domain	O
datasets	O
we	O
used	O
300	O
-	O
dimensional	O
vectors	O
trained	O
on	O
Google	B-Material
News	I-Material
;	O
for	O
the	O
biomedical	O
datasets	O
we	O
used	O
200	O
-	O
dimensional	O
vectors	O
trained	O
on	O
PubMed	B-Material
and	O
PMC	B-Material
.	O
	
The	O
embeddings	O
for	O
characters	O
were	O
set	O
to	O
length	O
and	O
initialised	O
randomly	O
.	O
	
The	O
LSTM	B-Method
layer	O
size	O
was	O
set	O
to	O
in	O
each	O
direction	O
for	O
both	O
word	O
-	O
and	O
character	O
-	O
level	O
components	O
.	O
	
The	O
hidden	B-Method
layer	I-Method
has	O
size	O
,	O
and	O
the	O
combined	B-Method
representation	I-Method
has	O
the	O
same	O
length	O
as	O
the	O
word	O
embeddings	O
.	O
	
CRF	B-Method
was	O
used	O
as	O
the	O
output	O
layer	O
for	O
all	O
the	O
experiments	O
–	O
	
we	O
found	O
that	O
this	O
gave	O
most	O
benefits	O
to	O
tasks	O
with	O
larger	O
numbers	O
of	O
possible	O
labels	O
.	O
	
Parameters	O
were	O
optimised	O
using	O
AdaDelta	B-Method
with	O
default	O
learning	B-Metric
rate	I-Metric
and	O
sentences	O
were	O
grouped	O
into	O
batches	O
of	O
size	O
.	O
	
Performance	O
on	O
the	O
development	O
set	O
was	O
measured	O
at	O
every	O
epoch	O
and	O
training	O
was	O
stopped	O
if	O
performance	O
had	O
not	O
improved	O
for	O
7	O
epochs	O
;	O
the	O
best	O
-	O
performing	O
model	O
on	O
the	O
development	O
set	O
was	O
then	O
used	O
for	O
evaluation	O
on	O
the	O
test	O
set	O
.	O
	
In	O
order	O
to	O
avoid	O
any	O
outlier	O
results	O
due	O
to	O
randomness	O
in	O
the	O
model	B-Method
initialisation	I-Method
,	O
we	O
trained	O
each	O
configuration	O
with	O
10	O
different	O
random	O
seeds	O
and	O
present	O
here	O
the	O
averaged	O
results	O
.	O
	
When	O
evaluating	O
on	O
each	O
dataset	O
,	O
we	O
report	O
the	O
measures	O
established	O
in	O
previous	O
work	O
.	O
	
Token	B-Metric
-	I-Metric
level	I-Metric
accuracy	I-Metric
is	O
used	O
for	O
PTB	B-Material
-	I-Material
POS	I-Material
and	O
GENIA	O
-	O
POS	B-Task
;	O
score	O
over	O
the	O
erroneous	O
words	O
for	O
FCEPUBLIC	B-Material
;	O
the	O
official	B-Metric
evaluation	I-Metric
script	I-Metric
for	O
BC2GM	B-Material
which	O
allows	O
for	O
alternative	O
correct	O
entity	O
spans	O
;	O
and	O
microaveraged	B-Metric
mention	I-Metric
-	I-Metric
level	I-Metric
score	I-Metric
for	O
the	O
remaining	O
datasets	O
.	O
	
section	O
:	O
Results	O
	
While	O
optimising	O
the	O
hyperparameters	O
for	O
each	O
dataset	O
separately	O
would	O
likely	O
improve	O
individual	O
performance	O
,	O
we	O
conduct	O
more	O
controlled	O
experiments	O
on	O
a	O
task	B-Method
-	I-Method
independent	I-Method
model	I-Method
.	O
	
Therefore	O
,	O
we	O
use	O
the	O
same	O
hyperparameters	O
from	O
Section	O
[	O
reference	O
]	O
on	O
all	O
datasets	O
,	O
and	O
the	O
development	O
set	O
is	O
only	O
used	O
for	O
the	O
stopping	O
condition	O
.	O
	
With	O
these	O
experiments	O
,	O
we	O
wish	O
to	O
determine	O
1	O
)	O
on	O
which	O
sequence	B-Task
labeling	I-Task
tasks	I-Task
do	O
character	B-Method
-	I-Method
based	I-Method
models	I-Method
offer	O
an	O
advantange	O
,	O
and	O
2	O
)	O
which	O
character	B-Method
-	I-Method
based	I-Method
architecture	I-Method
performs	O
better	O
.	O
	
Results	O
for	O
the	O
different	O
model	O
architectures	O
on	O
all	O
8	O
datasets	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
As	O
can	O
be	O
seen	O
,	O
including	O
a	O
character	B-Method
-	I-Method
based	I-Method
component	I-Method
in	O
the	O
sequence	B-Method
labeling	I-Method
architecture	I-Method
improves	O
performance	O
on	O
every	O
benchmark	O
.	O
	
The	O
NER	B-Task
datasets	O
have	O
the	O
largest	O
absolute	O
improvement	O
–	O
	
the	O
model	O
is	O
able	O
to	O
learn	O
character	O
-	O
level	O
patterns	O
for	O
names	O
,	O
and	O
also	O
improve	O
the	O
handling	O
of	O
any	O
previously	O
unseen	O
tokens	O
.	O
	
Compared	O
to	O
concatenating	O
the	O
word	B-Method
-	I-Method
and	I-Method
character	I-Method
-	I-Method
level	I-Method
representations	I-Method
,	O
the	O
attention	B-Method
-	I-Method
based	I-Method
character	I-Method
model	I-Method
outperforms	O
the	O
former	O
on	O
all	O
evaluations	O
.	O
	
The	O
mechanism	O
for	O
dynamically	O
deciding	O
how	O
much	O
character	O
-	O
level	O
information	O
to	O
use	O
allows	O
the	O
model	O
to	O
better	O
handle	O
individual	O
word	B-Method
representations	I-Method
,	O
giving	O
it	O
an	O
advantage	O
in	O
the	O
experiments	O
.	O
	
Visualisation	O
of	O
the	O
attention	O
values	O
in	O
Figure	O
[	O
reference	O
]	O
shows	O
that	O
the	O
model	O
is	O
actively	O
using	O
character	O
-	O
based	O
features	O
,	O
and	O
the	O
attention	O
areas	O
vary	O
between	O
different	O
words	O
.	O
	
The	O
results	O
of	O
this	O
general	O
tagging	B-Method
architecture	I-Method
are	O
competitive	O
,	O
even	O
when	O
compared	O
to	O
previous	O
work	O
using	O
hand	O
-	O
crafted	O
features	O
.	O
	
The	O
network	O
achieves	O
97.27	O
%	O
on	O
PTB	B-Material
-	I-Material
POS	I-Material
compared	O
to	O
97.55	O
%	O
by	O
Huang2015	O
,	O
and	O
72.70	O
%	O
on	O
JNLPBA	B-Material
compared	O
to	O
72.55	O
%	O
by	O
Zhou2004	O
.	O
	
In	O
some	O
cases	O
,	O
we	O
are	O
also	O
able	O
to	O
beat	O
the	O
previous	O
best	O
results	O
–	O
87.99	O
%	O
on	O
BC2GM	B-Material
compared	O
to	O
87.48	O
%	O
by	O
Campos2015	O
,	O
and	O
41.88	O
%	O
on	O
FCEPUBLIC	B-Material
compared	O
to	O
41.1	O
%	O
by	O
Rei2016	O
.	O
	
Lample2016	O
report	O
a	O
considerably	O
higher	O
result	O
of	O
90.94	O
%	O
on	O
CoNLL03	B-Material
,	O
indicating	O
that	O
the	O
chosen	O
hyperparameters	B-Method
for	O
the	O
baseline	O
system	O
are	O
suboptimal	O
for	O
this	O
specific	O
task	O
.	O
	
Compared	O
to	O
the	O
experiments	O
presented	O
here	O
,	O
their	O
model	O
used	O
the	O
IOBES	B-Method
tagging	I-Method
scheme	I-Method
instead	O
of	O
the	O
original	O
IOB	B-Method
,	O
and	O
embeddings	B-Method
pretrained	I-Method
with	O
a	O
more	O
specialised	O
method	O
that	O
accounts	O
for	O
word	O
order	O
.	O
	
It	O
is	O
important	O
to	O
also	O
compare	O
the	O
parameter	O
counts	O
of	O
alternative	O
neural	B-Method
architectures	I-Method
,	O
as	O
this	O
shows	O
their	O
learning	B-Metric
capacity	I-Metric
and	O
indicates	O
their	O
time	O
requirements	O
in	O
practice	O
.	O
	
Table	O
[	O
reference	O
]	O
contains	O
the	O
parameter	O
counts	O
on	O
three	O
representative	O
datasets	O
.	O
	
While	O
keeping	O
the	O
model	O
hyperparameters	O
constant	O
,	O
the	O
character	B-Method
-	I-Method
level	I-Method
models	I-Method
require	O
additional	O
parameters	O
for	O
the	O
character	O
composition	O
and	O
character	O
embeddings	O
.	O
	
However	O
,	O
the	O
attention	B-Method
-	I-Method
based	I-Method
model	I-Method
uses	O
fewer	O
parameters	O
compared	O
to	O
the	O
concatenation	B-Method
approach	I-Method
.	O
	
When	O
the	O
two	O
representations	O
are	O
concatenated	O
,	O
the	O
overall	O
word	B-Metric
representation	I-Metric
size	I-Metric
is	O
increased	O
,	O
which	O
in	O
turn	O
increases	O
the	O
number	O
of	O
parameters	O
required	O
for	O
the	O
word	B-Method
-	I-Method
level	I-Method
bidirectional	I-Method
LSTM	I-Method
.	O
	
Therefore	O
,	O
the	O
attention	B-Method
-	I-Method
based	I-Method
character	I-Method
architecture	I-Method
achieves	O
improved	O
results	O
even	O
with	O
a	O
smaller	O
parameter	O
footprint	O
.	O
	
section	O
:	O
Related	O
work	O
	
There	O
is	O
a	O
wide	O
range	O
of	O
previous	O
work	O
on	O
constructing	O
and	O
optimising	O
neural	B-Method
architectures	I-Method
applicable	O
to	O
sequence	B-Task
labeling	I-Task
.	O
	
Collobert2011	O
described	O
one	O
of	O
the	O
first	O
task	B-Method
-	I-Method
independent	I-Method
neural	I-Method
tagging	I-Method
models	I-Method
using	O
convolutional	B-Method
neural	I-Method
networks	I-Method
.	O
	
They	O
were	O
able	O
to	O
achieve	O
good	O
results	O
on	O
POS	B-Task
tagging	O
,	O
chunking	B-Task
,	O
NER	B-Task
and	O
semantic	B-Task
role	I-Task
labeling	I-Task
,	O
without	O
relying	O
on	O
hand	O
-	O
engineered	O
features	O
.	O
	
Irsoy2014a	O
experimented	O
with	O
multi	B-Method
-	I-Method
layer	I-Method
bidirectional	I-Method
Elman	I-Method
-	I-Method
style	I-Method
recurrent	I-Method
networks	I-Method
,	O
and	O
found	O
that	O
the	O
deep	B-Method
models	I-Method
outperformed	O
conditional	B-Method
random	I-Method
fields	I-Method
on	O
the	O
task	O
of	O
opinion	B-Task
mining	I-Task
.	O
	
Huang2015	O
described	O
a	O
bidirectional	B-Method
LSTM	I-Method
model	I-Method
with	O
a	O
CRF	B-Method
layer	I-Method
,	O
which	O
included	O
hand	O
-	O
crafted	O
features	O
specialised	O
for	O
the	O
task	O
of	O
named	B-Task
entity	I-Task
recognition	I-Task
.	O
	
Rei2016	O
evaluated	O
a	O
range	O
of	O
neural	B-Method
architectures	I-Method
,	O
including	O
convolutional	B-Method
and	I-Method
recurrent	I-Method
networks	I-Method
,	O
on	O
the	O
task	O
of	O
error	B-Task
detection	I-Task
in	O
learner	B-Task
writing	I-Task
.	O
	
The	O
word	B-Method
-	I-Method
level	I-Method
sequence	I-Method
labeling	I-Method
model	I-Method
described	O
in	O
this	O
paper	O
follows	O
the	O
previous	O
work	O
,	O
combining	O
useful	O
design	O
choices	O
from	O
each	O
of	O
them	O
.	O
	
In	O
addition	O
,	O
we	O
extended	O
the	O
model	O
with	O
two	O
alternative	O
character	B-Method
-	I-Method
level	I-Method
architectures	I-Method
,	O
and	O
evaluated	O
its	O
performance	O
on	O
8	O
different	O
datasets	O
.	O
	
Character	B-Method
-	I-Method
level	I-Method
models	I-Method
have	O
the	O
potential	O
of	O
capturing	O
morpheme	O
patterns	O
,	O
thereby	O
improving	O
generalisation	B-Task
on	O
both	O
frequent	O
and	O
unseen	O
words	O
.	O
	
In	O
recent	O
years	O
,	O
there	O
has	O
been	O
an	O
increase	O
in	O
research	O
into	O
these	O
models	O
,	O
resulting	O
in	O
several	O
interesting	O
applications	O
.	O
	
Ling2015b	O
described	O
a	O
character	B-Method
-	I-Method
level	I-Method
neural	I-Method
model	I-Method
for	O
machine	B-Task
translation	I-Task
,	O
performing	O
both	O
encoding	B-Task
and	O
decoding	B-Task
on	O
individual	O
characters	O
.	O
	
Kim2016	O
implemented	O
a	O
language	B-Method
model	I-Method
where	O
encoding	B-Method
is	O
performed	O
by	O
a	O
convolutional	B-Method
network	I-Method
and	O
LSTM	B-Method
over	O
characters	O
,	O
whereas	O
predictions	O
are	O
given	O
on	O
the	O
word	O
-	O
level	O
.	O
	
Cao2016	O
proposed	O
a	O
method	O
for	O
learning	O
both	O
word	B-Task
embeddings	I-Task
and	O
morphological	B-Task
segmentation	I-Task
with	O
a	O
bidirectional	B-Method
recurrent	I-Method
network	I-Method
over	O
characters	O
.	O
	
There	O
is	O
also	O
research	O
on	O
performing	O
parsing	B-Task
and	O
text	B-Task
classification	I-Task
with	O
character	B-Method
-	I-Method
level	I-Method
neural	I-Method
models	I-Method
.	O
	
Ling2015a	O
proposed	O
a	O
neural	B-Method
architecture	I-Method
that	O
replaces	O
word	O
embeddings	O
with	O
dynamically	O
-	O
constructed	O
character	B-Method
-	I-Method
based	I-Method
representations	I-Method
.	O
	
We	O
applied	O
a	O
similar	O
method	O
for	O
operating	O
over	O
characters	O
,	O
but	O
combined	O
them	O
with	O
word	O
embeddings	O
instead	O
of	O
replacing	O
them	O
,	O
as	O
this	O
allows	O
the	O
model	O
to	O
benefit	O
from	O
both	O
approaches	O
.	O
	
Lample2016	O
described	O
a	O
model	O
where	O
the	O
character	B-Method
-	I-Method
level	I-Method
representation	I-Method
is	O
combined	O
with	O
word	B-Method
embeddings	I-Method
through	O
concatenation	B-Method
.	O
	
In	O
this	O
work	O
,	O
we	O
proposed	O
an	O
alternative	O
architecture	O
,	O
where	O
the	O
representations	O
are	O
combined	O
using	O
an	O
attention	B-Method
mechanism	I-Method
,	O
and	O
evaluated	O
both	O
approaches	O
on	O
a	O
range	O
of	O
tasks	O
and	O
datasets	O
.	O
	
Recently	O
,	O
Miyamoto2016	O
have	O
also	O
described	O
a	O
related	O
method	O
for	O
the	O
task	O
of	O
language	B-Task
modelling	I-Task
,	O
combining	O
characters	O
and	O
word	B-Method
embeddings	I-Method
using	O
gating	B-Method
.	O
	
section	O
:	O
Conclusion	O
	
Developments	O
in	O
neural	B-Method
network	I-Method
research	I-Method
allow	O
for	O
model	B-Method
architectures	I-Method
that	O
work	O
well	O
on	O
a	O
wide	O
range	O
of	O
sequence	O
labeling	O
datasets	O
without	O
requiring	O
hand	O
-	O
crafted	O
data	O
.	O
	
While	O
word	B-Method
-	I-Method
level	I-Method
representation	I-Method
learning	I-Method
is	O
a	O
powerful	O
tool	O
for	O
automatically	B-Task
discovering	I-Task
useful	I-Task
features	I-Task
,	O
these	O
models	O
still	O
come	O
with	O
certain	O
weaknesses	O
	
–	O
rare	O
words	O
have	O
low	O
-	O
quality	O
representations	O
,	O
previously	O
unseen	O
words	O
can	O
not	O
be	O
modeled	O
at	O
all	O
,	O
and	O
morpheme	O
-	O
level	O
information	O
is	O
not	O
shared	O
with	O
the	O
whole	O
vocabulary	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
investigated	O
character	B-Method
-	I-Method
level	I-Method
model	I-Method
components	I-Method
for	O
a	O
sequence	B-Method
labeling	I-Method
architecture	I-Method
,	O
which	O
allow	O
the	O
system	O
to	O
learn	O
useful	O
patterns	O
from	O
sub	O
-	O
word	O
units	O
.	O
	
In	O
addition	O
to	O
a	O
bidirectional	O
LSTM	B-Method
operating	O
over	O
words	O
,	O
a	O
separate	O
bidirectional	O
LSTM	B-Method
is	O
used	O
to	O
construct	O
word	B-Method
representations	I-Method
from	O
individual	O
characters	O
.	O
	
We	O
proposed	O
a	O
novel	O
architecture	O
for	O
combining	O
the	O
character	B-Method
-	I-Method
based	I-Method
representation	I-Method
with	O
the	O
word	B-Method
embedding	I-Method
by	O
using	O
an	O
attention	B-Method
mechanism	I-Method
,	O
allowing	O
the	O
model	O
to	O
dynamically	O
choose	O
which	O
information	O
to	O
use	O
from	O
each	O
information	O
source	O
.	O
	
In	O
addition	O
,	O
the	O
character	O
-	O
level	O
composition	O
function	O
is	O
augmented	O
with	O
a	O
novel	O
training	B-Metric
objective	I-Metric
,	O
optimising	O
it	O
to	O
predict	O
representations	O
that	O
are	O
similar	O
to	O
the	O
word	O
embeddings	O
in	O
the	O
model	O
.	O
	
The	O
evaluation	O
was	O
performed	O
on	O
8	O
different	O
sequence	O
labeling	O
datasets	O
,	O
covering	O
a	O
range	O
of	O
tasks	O
and	O
domains	O
.	O
	
We	O
found	O
that	O
incorporating	O
character	O
-	O
level	O
information	O
into	O
the	O
model	O
improved	O
performance	O
on	O
every	O
benchmark	O
,	O
indicating	O
that	O
capturing	O
features	O
regarding	O
characters	O
and	O
morphmes	O
is	O
indeed	O
useful	O
in	O
a	O
general	O
-	O
purpose	O
tagging	B-Task
system	I-Task
.	O
	
In	O
addition	O
,	O
the	O
attention	B-Method
-	I-Method
based	I-Method
model	I-Method
for	O
combining	O
character	B-Method
representations	I-Method
outperformed	O
the	O
concatenation	B-Method
method	I-Method
used	O
in	O
previous	O
work	O
in	O
all	O
evaluations	O
.	O
	
Even	O
though	O
the	O
proposed	O
method	O
requires	O
fewer	O
parameters	O
,	O
the	O
added	O
ability	O
of	O
controlling	O
how	O
much	O
character	O
-	O
level	O
information	O
is	O
used	O
for	O
each	O
word	O
has	O
led	O
to	O
improved	O
performance	O
on	O
a	O
range	O
of	O
different	O
tasks	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Fused	B-Method
Text	I-Method
Segmentation	I-Method
Networks	I-Method
for	O
Multi	B-Task
-	I-Task
oriented	I-Task
Scene	I-Task
Text	I-Task
Detection	I-Task
	
In	O
this	O
paper	O
,	O
we	O
introduce	O
a	O
novel	O
end	B-Method
-	I-Method
end	I-Method
framework	I-Method
for	O
multi	O
-	O
oriented	O
scene	B-Task
text	I-Task
detection	I-Task
from	O
an	O
instance	B-Task
-	I-Task
aware	I-Task
semantic	I-Task
segmentation	I-Task
perspective	I-Task
.	O
	
We	O
present	O
Fused	B-Method
Text	I-Method
Segmentation	I-Method
Networks	I-Method
,	O
which	O
combine	O
multi	O
-	O
level	O
features	O
during	O
the	O
feature	B-Method
extracting	I-Method
as	O
text	O
instance	O
may	O
rely	O
on	O
finer	O
feature	O
expression	O
compared	O
to	O
general	O
objects	O
.	O
	
It	O
detects	O
and	O
segments	O
the	O
text	O
instance	O
jointly	O
and	O
simultaneously	O
,	O
leveraging	O
merits	O
from	O
both	O
semantic	B-Task
segmentation	I-Task
task	I-Task
and	O
region	B-Task
proposal	I-Task
based	I-Task
object	I-Task
detection	I-Task
task	I-Task
.	O
	
Not	O
involving	O
any	O
extra	O
pipelines	O
,	O
our	O
approach	O
surpasses	O
the	O
current	O
state	O
of	O
the	O
art	O
on	O
multi	O
-	O
oriented	O
scene	B-Task
text	I-Task
detection	I-Task
benchmarks	O
:	O
	
ICDAR2015	B-Material
	
Incidental	B-Material
Scene	I-Material
Text	I-Material
and	O
MSRA	B-Material
-	I-Material
TD500	I-Material
reaching	O
Hmean	B-Method
84.1	O
%	O
and	O
82.0	O
%	O
respectively	O
.	O
	
Morever	O
,	O
we	O
report	O
a	O
baseline	O
on	O
total	O
-	O
text	O
containing	O
curved	O
text	O
which	O
suggests	O
effectiveness	O
of	O
the	O
proposed	O
approach	O
.	O
	
section	O
:	O
Introduction	O
	
Recently	O
,	O
scene	B-Task
text	I-Task
detection	I-Task
has	O
drawn	O
great	O
attention	O
from	O
computer	B-Task
vision	I-Task
and	O
machine	B-Task
learning	I-Task
community	I-Task
.	O
	
Driven	O
by	O
many	O
content	B-Task
-	I-Task
based	I-Task
image	I-Task
applications	I-Task
such	O
as	O
photo	B-Task
translation	I-Task
and	O
receipt	B-Task
content	I-Task
recognition	I-Task
,	O
it	O
has	O
become	O
a	O
promising	O
and	O
challenging	O
research	O
area	O
both	O
in	O
academia	O
and	O
industry	O
.	O
	
Detecting	B-Task
text	I-Task
in	O
natural	O
images	O
is	O
difficult	O
,	O
because	O
both	O
text	O
and	O
background	O
may	O
be	O
complex	O
in	O
the	O
wild	O
and	O
it	O
often	O
suffers	O
from	O
disturbance	O
such	O
as	O
occlusion	O
and	O
uncontrollable	O
lighting	O
conditions	O
.	O
	
Previous	O
text	B-Method
detection	I-Method
methods	I-Method
have	O
achieved	O
promising	O
results	O
on	O
several	O
benchmarks	O
.	O
	
The	O
essential	O
problem	O
in	O
text	B-Task
detection	I-Task
is	O
to	O
represent	O
text	O
region	O
using	O
discriminative	O
features	O
.	O
	
Conventionally	O
,	O
hand	O
-	O
crafted	O
features	O
are	O
designed	O
to	O
capture	O
the	O
properties	O
of	O
text	O
region	O
such	O
as	O
texture	O
and	O
shape	O
,	O
while	O
in	O
the	O
past	O
few	O
years	O
,	O
deep	B-Method
learning	I-Method
based	I-Method
approaches	I-Method
directly	O
learn	O
hierarchical	O
features	O
from	O
training	O
data	O
,	O
demonstrating	O
more	O
accurate	O
and	O
efficient	O
performance	O
in	O
various	O
benchmarks	O
such	O
as	O
ICDAR	B-Material
series	I-Material
contests	I-Material
.	O
	
Existing	O
methods	O
have	O
obtained	O
decent	O
performance	O
for	O
detecting	B-Task
horizontal	I-Task
or	I-Task
near	I-Task
-	I-Task
horizontal	I-Task
text	I-Task
.	O
	
While	O
horizontal	B-Task
text	I-Task
detection	I-Task
has	O
constraints	O
of	O
axis	O
-	O
aligned	O
bounding	O
-	O
box	O
ground	O
truth	O
,	O
the	O
multi	O
-	O
oriented	O
text	O
is	O
not	O
restrictive	O
to	O
a	O
particular	O
orientation	O
and	O
usually	O
uses	O
quadrilaterals	O
for	O
annotations	O
.	O
	
Therefore	O
,	O
it	O
reports	O
relatively	O
lower	O
accuracies	B-Metric
in	O
ICDAR	B-Task
2015	I-Task
Competition	I-Task
Challenge	I-Task
4	O
âIncidental	B-Task
scene	I-Task
text	I-Task
localizationâ	I-Task
compared	O
to	O
horizontal	O
scene	B-Task
text	I-Task
detection	I-Task
benchmarks	O
.	O
	
Recently	O
,	O
a	O
few	O
approaches	O
have	O
been	O
proposed	O
to	O
address	O
the	O
multi	B-Task
-	I-Task
oriented	I-Task
text	I-Task
detection	I-Task
.	O
	
In	O
general	O
,	O
there	O
are	O
currently	O
four	O
different	O
types	O
of	O
methods	O
.	O
	
Region	B-Method
based	I-Method
methods	I-Method
leverage	O
advanced	O
object	B-Method
detection	I-Method
techniques	I-Method
such	O
as	O
Faster	O
RCNN	B-Method
and	O
SSD	B-Method
.	O
	
Segmentation	B-Method
-	I-Method
based	I-Method
methods	I-Method
mainly	O
utilize	O
fully	B-Method
convolutional	I-Method
neural	I-Method
networks	I-Method
(	O
FCN	B-Method
)	O
for	O
generating	O
text	B-Task
score	I-Task
maps	I-Task
,	O
which	O
often	O
need	O
several	O
stages	O
and	O
components	O
to	O
achieve	O
final	O
detections	B-Task
.	O
	
Direct	B-Method
regression	I-Method
based	I-Method
method	I-Method
regresses	O
the	O
position	O
and	O
size	O
of	O
an	O
object	O
from	O
a	O
given	O
point	O
.	O
	
Finally	O
,	O
hybrid	O
method	O
combines	O
text	B-Method
scores	I-Method
map	I-Method
and	O
rotated	B-Method
/	I-Method
quadrangle	I-Method
bounding	I-Method
boxes	I-Method
generation	I-Method
to	O
collaboratively	O
obtain	O
the	O
efficient	O
and	O
accurate	O
performance	O
in	O
multi	B-Task
-	I-Task
oriented	I-Task
text	I-Task
detection	I-Task
.	O
	
Inspired	O
by	O
recent	O
advance	O
of	O
instance	B-Task
-	I-Task
aware	I-Task
semantic	I-Task
segmentation	I-Task
,	O
we	O
present	O
a	O
novel	O
perspective	O
to	O
handle	O
the	O
task	O
of	O
multi	B-Task
-	I-Task
oriented	I-Task
text	I-Task
detection	I-Task
.	O
	
In	O
this	O
work	O
,	O
we	O
leverage	O
the	O
merits	O
from	O
accurate	O
region	B-Method
proposal	I-Method
based	I-Method
methods	I-Method
,	O
and	O
flexible	B-Method
segmentation	I-Method
based	I-Method
methods	I-Method
which	O
can	O
easily	O
generate	O
arbitrary	O
-	O
shaped	O
text	O
mask	O
.	O
	
It	O
is	O
an	O
end	O
-	O
to	O
-	O
end	B-Method
trainable	I-Method
framework	I-Method
excluding	O
redundant	O
and	O
low	O
-	O
efficient	O
pipelines	O
such	O
as	O
the	O
use	O
of	O
text	B-Task
/	I-Task
nontext	I-Task
salient	I-Task
map	I-Task
and	O
text	B-Task
-	I-Task
line	I-Task
generation	I-Task
.	O
	
Based	O
on	O
region	B-Method
proposal	I-Method
network	I-Method
(	O
RPN	B-Method
)	O
,	O
our	O
approach	O
detects	O
and	O
segments	O
text	O
instance	O
simultaneously	O
,	O
followed	O
by	O
non	B-Method
-	I-Method
maximum	I-Method
suppression	I-Method
(	O
NMS	B-Method
)	O
to	O
suppress	O
overlapping	O
instances	O
.	O
	
Finally	O
,	O
a	O
minimum	O
quadrangle	O
bounding	O
box	O
to	O
fit	O
each	O
instance	O
area	O
is	O
generated	O
as	O
the	O
result	O
of	O
the	O
whole	O
detection	B-Task
process	I-Task
.	O
	
Our	O
main	O
contributions	O
are	O
summarized	O
as	O
follows	O
:	O
	
We	O
present	O
an	O
end	O
-	O
end	O
efficient	O
and	O
trainable	B-Method
solution	I-Method
for	O
multi	B-Task
-	I-Task
oriented	I-Task
text	I-Task
detection	I-Task
from	O
an	O
instance	B-Task
aware	I-Task
segmentation	I-Task
perspective	I-Task
,	O
excluding	O
any	O
redundant	B-Method
pipelines	I-Method
.	O
	
During	O
feature	B-Task
extraction	I-Task
,	O
feature	O
maps	O
are	O
composed	O
in	O
a	O
fused	O
fashion	O
to	O
adaptively	O
satisfy	O
the	O
finer	O
representation	O
of	O
text	O
instance	O
.	O
	
Mask	B-Method
-	I-Method
NMS	I-Method
is	O
introduced	O
to	O
improve	O
the	O
standard	O
NMS	B-Method
when	O
facing	O
heavily	O
inclined	O
or	O
line	O
-	O
level	O
text	O
instances	O
.	O
	
Without	O
many	O
bells	O
and	O
whistles	O
,	O
our	O
approach	O
outperforms	O
state	O
of	O
the	O
art	O
on	O
current	O
multi	B-Task
-	I-Task
oriented	I-Task
text	I-Task
detection	I-Task
benchmarks	I-Task
.	O
	
section	O
:	O
Related	O
work	O
	
Detecting	B-Task
text	I-Task
in	O
natural	O
images	O
has	O
been	O
widely	O
studied	O
in	O
past	O
few	O
years	O
,	O
motivated	O
by	O
many	O
text	B-Task
-	I-Task
related	I-Task
real	I-Task
-	I-Task
world	I-Task
applications	I-Task
such	O
as	O
photo	B-Task
OCR	I-Task
and	O
blind	B-Task
navigation	I-Task
.	O
	
One	O
of	O
the	O
mainstream	O
traditional	O
methods	O
for	O
scene	B-Task
text	I-Task
detection	I-Task
are	O
Connected	B-Method
Components	I-Method
(	O
CCs	B-Method
)	O
based	O
methods	O
,	O
which	O
consider	O
text	O
as	O
a	O
group	O
of	O
individual	O
components	O
such	O
as	O
characters	O
.	O
	
Within	O
these	O
methods	O
,	O
stroke	B-Method
width	I-Method
transform	I-Method
(	O
SWT	B-Method
)	O
and	O
maximally	O
stable	O
extremal	O
region	O
(	O
MSER	B-Method
)	O
are	O
usually	O
used	O
to	O
seek	O
character	O
candidates	O
.	O
	
Finally	O
,	O
these	O
candidates	O
are	O
combined	O
to	O
obtain	O
text	O
objects	O
.	O
	
Although	O
these	O
bottom	B-Method
up	I-Method
approaches	I-Method
may	O
be	O
accurate	O
on	O
some	O
benchmarks	O
,	O
they	O
often	O
suffer	O
from	O
too	O
many	O
pipelines	O
,	O
which	O
may	O
cause	O
inefficiency	O
.	O
	
Another	O
mainstream	O
traditional	O
methods	O
are	O
sliding	B-Method
window	I-Method
based	I-Method
.	O
	
These	O
methods	O
often	O
use	O
a	O
fixed	O
-	O
size	O
or	O
multi	O
-	O
scale	O
window	O
to	O
slide	O
through	O
the	O
image	O
searching	O
the	O
region	O
which	O
most	O
likely	O
contains	O
text	O
.	O
	
However	O
,	O
the	O
process	O
of	O
sliding	B-Method
window	I-Method
may	O
involve	O
large	O
computational	B-Metric
cost	I-Metric
which	O
results	O
in	O
inefficiency	O
.	O
	
Generally	O
,	O
traditional	O
methods	O
often	O
require	O
several	O
steps	O
to	O
obtain	O
final	O
detections	O
,	O
and	O
hand	O
-	O
designed	O
features	O
are	O
usually	O
used	O
to	O
represent	O
properties	O
of	O
text	O
.	O
	
Therefore	O
,	O
they	O
may	O
suffer	O
from	O
inefficiency	O
and	O
low	O
generalization	B-Metric
ability	I-Metric
against	O
complex	O
situations	O
such	O
as	O
non	O
-	O
uniform	O
illumination	O
.	O
	
Recent	O
progress	O
on	O
deep	B-Method
learning	I-Method
based	I-Method
approaches	I-Method
for	O
object	B-Task
detection	I-Task
and	O
semantic	B-Task
segmentation	I-Task
has	O
provided	O
new	O
techniques	O
for	O
reading	B-Task
text	I-Task
in	O
the	O
wild	O
,	O
which	O
can	O
be	O
also	O
seen	O
as	O
an	O
instance	O
of	O
general	B-Task
object	I-Task
detection	I-Task
.	O
	
Driven	O
by	O
the	O
advance	O
of	O
object	B-Method
detection	I-Method
frameworks	I-Method
such	O
as	O
Faster	B-Method
RCNN	I-Method
and	O
SSD	B-Method
,	O
these	O
methods	O
achieved	O
state	O
of	O
the	O
art	O
by	O
either	O
using	O
a	O
region	B-Method
proposal	I-Method
network	I-Method
to	O
first	O
classify	O
some	O
text	O
region	O
proposals	O
,	O
or	O
directly	O
regress	O
text	O
bounding	O
boxes	O
coordinates	O
from	O
a	O
set	O
of	O
default	O
boxes	O
.	O
	
These	O
methods	O
are	O
able	O
to	O
achieve	O
leading	O
performance	O
on	O
horizontal	O
or	O
multi	O
-	O
oriented	O
scene	B-Task
text	I-Task
detection	I-Task
benchmarks	O
.	O
	
However	O
,	O
they	O
may	O
also	O
be	O
restricted	O
to	O
rectangular	O
bounding	O
box	O
constraints	O
even	O
with	O
appropriate	O
rotation	O
.	O
	
Different	O
from	O
these	O
methods	O
,	O
FCN	B-Method
based	I-Method
approaches	I-Method
generate	O
text	B-Task
/	I-Task
non	I-Task
-	I-Task
text	I-Task
map	I-Task
which	O
classifies	O
text	O
at	O
the	O
pixel	O
level	O
.	O
	
Though	O
it	O
may	O
be	O
suited	O
well	O
for	O
arbitrary	O
shape	O
of	O
text	O
in	O
natural	O
images	O
,	O
it	O
often	O
involves	O
several	O
pipelines	B-Method
which	O
leads	O
to	O
inefficiency	O
.	O
	
Inspired	O
by	O
recent	O
advance	O
on	O
instance	B-Task
-	I-Task
aware	I-Task
semantic	I-Task
segmentation	I-Task
,	O
we	O
present	O
an	O
end	B-Method
-	I-Method
end	I-Method
trainable	I-Method
framework	I-Method
called	O
Fused	B-Method
Text	I-Method
Segmentation	I-Method
Networks	I-Method
(	O
FTSN	B-Method
)	O
to	O
handle	O
arbitrary	B-Task
-	I-Task
shape	I-Task
text	I-Task
detection	I-Task
with	O
no	O
extra	O
pipelines	O
involved	O
.	O
	
It	O
inherits	O
merits	O
from	O
both	O
object	B-Method
detection	I-Method
and	O
semantic	B-Method
segmentation	I-Method
architecture	I-Method
which	O
efficiently	O
detects	O
and	O
segments	O
an	O
text	O
instance	O
simultaneously	O
and	O
accurately	O
gives	O
predictions	O
in	O
the	O
pixel	O
level	O
.	O
	
As	O
text	O
may	O
rely	O
on	O
finer	O
feature	B-Method
representation	I-Method
,	O
a	O
fused	O
structure	O
formed	O
by	O
multi	B-Method
-	I-Method
level	I-Method
feature	I-Method
maps	I-Method
is	O
set	O
to	O
fit	O
this	O
property	O
.	O
	
section	O
:	O
Methods	O
	
The	O
proposed	O
framework	O
for	O
multi	O
-	O
oriented	O
scene	B-Task
text	I-Task
detection	I-Task
is	O
diagrammed	O
in	O
Fig.2	O
.	O
	
It	O
is	O
a	O
deep	B-Method
CNN	I-Method
model	I-Method
which	O
mainly	O
consists	O
of	O
three	O
parts	O
.	O
	
Feature	B-Method
representations	I-Method
of	O
each	O
image	O
are	O
extracted	O
through	O
resnet	B-Method
-	I-Method
101	I-Method
backbone	I-Method
,	O
then	O
multi	O
-	O
level	O
feature	O
maps	O
are	O
fused	O
as	O
FusedMapA	B-Method
which	O
is	O
fed	O
to	O
the	O
region	B-Method
proposed	I-Method
network	I-Method
(	O
RPN	B-Method
)	O
for	O
text	B-Task
region	I-Task
of	I-Task
interest	I-Task
(	O
ROI	B-Task
)	I-Task
generation	I-Task
and	O
FusedMapB	O
for	O
later	O
rois	B-Task
’	I-Task
PSROIPooling	I-Task
.	O
	
Finally	O
the	O
rois	O
are	O
sent	O
to	O
the	O
detection	B-Task
,	I-Task
segmentation	I-Task
and	I-Task
box	I-Task
regression	I-Task
branches	I-Task
to	O
output	O
text	O
instances	O
in	O
pixel	O
level	O
along	O
with	O
their	O
corresponding	O
bounding	O
boxes	O
.	O
	
The	O
post	B-Task
-	I-Task
processing	I-Task
part	I-Task
includes	O
NMS	B-Method
and	O
minimal	B-Task
quadrilateral	I-Task
generation	I-Task
.	O
	
subsection	O
:	O
Network	B-Method
Architecture	I-Method
	
The	O
convolutional	B-Method
feature	I-Method
representation	I-Method
is	O
designed	O
in	O
a	O
fusion	B-Method
fashion	I-Method
.	O
	
The	O
text	O
instance	O
is	O
not	O
like	O
the	O
general	O
object	O
such	O
as	O
people	O
and	O
cars	O
which	O
have	O
relatively	O
strong	O
semantics	O
.	O
	
On	O
the	O
contrary	O
,	O
texts	O
often	O
vary	O
tremendously	O
in	O
intra	O
-	O
class	O
geometries	O
.	O
	
Consequently	O
,	O
low	O
-	O
level	O
features	O
should	O
be	O
taken	O
into	O
consideration	O
.	O
	
Basically	O
,	O
resnet	B-Method
-	I-Method
101	I-Method
consists	O
of	O
five	O
stages	O
.	O
	
Before	O
region	B-Task
proposing	I-Task
,	O
stage3	O
and	O
upsampled	O
stage4	O
feature	O
maps	O
are	O
combined	O
to	O
form	O
FusedMapA	O
through	O
element	B-Method
-	I-Method
wise	I-Method
adding	I-Method
,	O
then	O
upsampled	O
feature	O
maps	O
from	O
stage5	O
are	O
fused	O
with	O
FusedMapA	B-Method
to	O
form	O
	
FusedMapB.	B-Method
	
It	O
is	O
noted	O
that	O
downsampling	B-Task
is	O
not	O
involved	O
during	O
stage5	O
.	O
	
Instead	O
,	O
we	O
use	O
the	O
âhole	O
algorithmâ	O
to	O
keep	O
the	O
feature	O
stride	O
and	O
maintain	O
the	O
receptive	O
field	O
.	O
	
The	O
reason	O
for	O
this	O
is	O
that	O
both	O
text	O
properties	O
and	O
the	O
segmentation	B-Task
task	I-Task
may	O
require	O
finer	O
features	O
and	O
involving	O
final	O
downsampling	O
may	O
lose	O
some	O
useful	O
information	O
.	O
	
Because	O
using	O
feature	O
stride	O
of	O
stage3	O
may	O
cause	O
millions	O
of	O
anchors	O
in	O
original	O
RPN	B-Method
which	O
makes	O
model	B-Task
training	I-Task
hard	O
,	O
so	O
we	O
add	O
a	O
with	O
stride	B-Method
2	I-Method
convolution	I-Method
to	O
reduce	O
such	O
huge	O
number	O
of	O
anchors	O
.	O
	
Followed	O
FCIS	B-Method
,	O
we	O
use	O
Joint	B-Method
Mask	I-Method
Prediction	I-Method
and	O
Classification	B-Method
to	O
simultaneously	O
classify	O
and	O
mask	O
the	O
text	O
instance	O
on	O
inside	O
/	O
outside	O
score	O
maps	O
generated	O
through	O
PSROIPooling	B-Method
on	O
conv	B-Method
-	I-Method
cls	I-Method
-	I-Method
seg	I-Method
feature	I-Method
maps	I-Method
,	O
and	O
box	B-Method
regression	I-Method
branch	I-Method
utilizes	O
feature	O
maps	O
from	O
conv	O
-	O
box	O
after	O
PSROIPooling	B-Method
(	O
”	O
”	O
means	O
one	O
class	O
is	O
for	O
text	O
and	O
the	O
other	O
for	O
background	O
)	O
.	O
	
We	O
use	O
shown	O
in	O
Fig.2	O
in	O
our	O
experiments	O
by	O
default	O
.	O
	
It	O
is	O
noted	O
that	O
after	O
PSROIPooling	B-Method
,	O
the	O
resolution	O
of	O
feature	O
maps	O
becomes	O
.	O
	
Therefore	O
,	O
we	O
use	O
global	B-Method
average	I-Method
pooling	I-Method
for	O
classification	B-Task
(	O
after	O
pixel	O
-	O
wise	O
max	O
)	O
and	O
box	O
regression	O
branches	O
,	O
and	O
pixel	O
-	O
wise	O
softmax	O
on	O
mask	O
branch	O
.	O
	
subsection	O
:	O
Ground	B-Metric
Truth	I-Metric
and	O
Loss	B-Metric
Function	I-Metric
	
The	O
whole	O
multi	B-Task
-	I-Task
task	I-Task
loss	I-Task
can	O
be	O
interpreted	O
as	O
The	O
full	O
loss	O
consists	O
of	O
two	O
sub	B-Method
stage	I-Method
losses	I-Method
:	O
RPN	B-Method
loss	I-Method
where	O
is	O
for	O
region	B-Task
proposal	I-Task
classification	I-Task
and	O
is	O
for	O
box	B-Method
regression	I-Method
,	O
and	O
text	B-Method
instance	I-Method
loss	I-Method
based	O
on	O
each	O
ROI	O
,	O
where	O
represent	O
losses	O
for	O
instance	B-Task
classification	I-Task
,	O
mask	B-Task
and	I-Task
box	I-Task
regression	I-Task
task	I-Task
respectively	O
.	O
	
is	O
the	O
hyper	O
-	O
parameter	O
to	O
control	O
the	O
balance	O
among	O
each	O
loss	O
term	O
.	O
	
They	O
are	O
set	O
as	O
in	O
our	O
experiments	O
.	O
	
Classification	B-Task
and	O
mask	B-Task
task	I-Task
both	O
use	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
as	O
loss	B-Metric
function	I-Metric
,	O
whereas	O
we	O
use	O
smooth	B-Method
-	I-Method
L1	I-Method
for	O
box	B-Task
regression	I-Task
task	I-Task
formulated	O
as	O
is	O
set	O
to	O
3	O
in	O
our	O
experiments	O
which	O
makes	O
the	O
box	B-Method
regression	I-Method
loss	I-Method
less	O
sensitive	O
to	O
outliers	O
.	O
	
Ground	O
truth	O
of	O
each	O
text	O
instance	O
is	O
presented	O
by	O
bounding	O
boxes	O
and	O
masks	O
shown	O
in	O
Fig.3	O
.	O
	
In	O
most	O
multi	B-Task
-	I-Task
oriented	I-Task
text	I-Task
detection	I-Task
dataset	I-Task
,	O
annotations	O
are	O
given	O
in	O
quadrilaterals	O
such	O
as	O
IC15	B-Material
or	O
can	O
be	O
converted	O
to	O
quadrilaterals	O
such	O
as	O
TD500	B-Material
.	O
	
For	O
each	O
instance	O
,	O
we	O
directly	O
generate	O
mask	O
from	O
quadrilateral	O
coordinates	O
and	O
use	O
the	O
minimal	O
rectangle	O
containing	O
the	O
mask	O
as	O
the	O
bounding	O
box	O
.	O
	
subsection	O
:	O
Post	B-Task
Processing	I-Task
	
Mask	B-Method
-	I-Method
NMS	I-Method
	
To	O
obtain	O
final	O
detection	B-Task
results	O
,	O
we	O
use	O
Non	B-Method
-	I-Method
Maximum	I-Method
Suppression	I-Method
mechanism	I-Method
(	O
NMS	B-Method
)	O
to	O
filter	O
overlapped	O
text	O
instances	O
and	O
preserve	O
those	O
with	O
highest	O
scores	O
.	O
	
After	O
NMS	B-Method
,	O
we	O
generate	O
a	O
minimum	O
quadrilateral	O
for	O
each	O
text	O
instance	O
covering	O
the	O
mask	O
as	O
shown	O
in	O
Fig.1	O
.	O
	
Standard	O
NMS	B-Method
computes	O
IOU	B-Method
among	O
bounding	O
boxes	O
,	O
which	O
may	O
be	O
fine	O
for	O
word	B-Task
-	I-Task
level	I-Task
and	I-Task
near	I-Task
-	I-Task
horizontal	I-Task
results	I-Task
’	I-Task
filtering	I-Task
.	O
	
However	O
,	O
it	O
may	O
filter	O
some	O
correct	O
line	O
-	O
level	O
detections	O
when	O
they	O
are	O
close	O
and	O
heavily	O
inclined	O
as	O
shown	O
in	O
Fig.4	O
or	O
when	O
words	O
stay	O
close	O
in	O
the	O
same	O
line	O
as	O
shown	O
in	O
Fig.5	O
.	O
	
Consequently	O
,	O
we	O
propose	O
a	O
modified	O
NMS	B-Method
called	O
Mask	B-Method
-	I-Method
NMS	I-Method
to	O
handle	O
such	O
situations	O
.	O
	
Mask	B-Method
-	I-Method
NMS	I-Method
mainly	O
changes	O
bounding	B-Method
box	I-Method
IOU	I-Method
computation	I-Method
to	O
so	O
-	O
called	O
mask	B-Method
-	I-Method
maximum	I-Method
-	I-Method
intersection	I-Method
(	O
MMI	B-Method
)	O
as	O
formulated	O
:	O
are	O
mask	O
areas	O
of	O
two	O
text	O
instances	O
to	O
be	O
computed	O
,	O
is	O
the	O
intersection	O
area	O
between	O
the	O
masks	O
.	O
	
Maximum	O
intersection	O
over	O
the	O
mask	O
areas	O
are	O
used	O
to	O
replace	O
original	O
IOU	O
for	O
the	O
reason	O
that	O
detections	O
may	O
easily	O
involve	O
line	O
-	O
level	O
and	O
word	O
-	O
level	O
text	O
instances	O
simultaneously	O
at	O
the	O
same	O
line	O
as	O
shown	O
in	O
Fig.5	O
.	O
	
The	O
proposed	O
Mask	B-Method
-	I-Method
NMS	I-Method
has	O
significantly	O
improved	O
performance	O
for	O
multi	O
-	O
oriented	O
scene	B-Task
text	I-Task
detection	I-Task
as	O
shown	O
in	O
section.5	O
.	O
	
section	O
:	O
Experiments	O
	
To	O
evaluate	O
the	O
proposed	O
framework	O
,	O
we	O
conduct	O
quantitative	O
experiments	O
on	O
three	O
public	O
benchmarks	O
:	O
	
ICDAR2015	B-Material
,	O
MSRA	B-Material
-	I-Material
TD500	I-Material
and	O
Total	B-Material
-	I-Material
Text	I-Material
.	O
	
subsection	O
:	O
Datasets	O
	
ICDAR	B-Material
2015	I-Material
	
Incidental	B-Material
Text	I-Material
(	O
IC15	B-Material
)	O
	
the	O
Challenge	O
4	O
of	O
ICDAR	B-Material
2015	I-Material
Robust	O
Reading	O
Competition	O
.	O
	
IC15	B-Material
contains	O
1000	O
training	O
and	O
500	O
testing	O
incidental	O
images	O
taken	O
by	O
Google	B-Material
Glasses	I-Material
without	O
paying	O
attention	O
to	O
viewpoint	O
and	O
image	B-Metric
quality	I-Metric
.	O
	
Therefore	O
,	O
large	O
variations	O
in	O
text	O
scale	O
,	O
orientation	O
and	O
resolution	O
lead	O
to	O
difficulty	O
for	O
text	B-Task
detection	I-Task
.	O
	
Annotations	O
of	O
the	O
dataset	O
are	O
given	O
in	O
word	O
-	O
level	O
quadrilaterals	O
.	O
	
MSRA	B-Material
-	I-Material
TD500	I-Material
(	O
TD500	B-Material
)	O
is	O
early	O
presented	O
in	O
.	O
	
The	O
dataset	O
is	O
multi	O
-	O
oriented	O
and	O
multi	O
-	O
lingual	O
including	O
both	O
Chinese	B-Material
and	I-Material
English	I-Material
textï¼	O
which	O
consists	O
of	O
300	O
training	O
and	O
200	O
testing	O
images	O
.	O
	
Different	O
from	O
IC15	B-Material
,	O
annotations	O
of	O
TD500	B-Material
are	O
at	O
line	O
level	O
which	O
are	O
rotated	O
rectangles	O
.	O
	
Total	B-Material
-	I-Material
Text	I-Material
is	O
presented	O
in	O
ICDAR2017	B-Material
.	O
	
It	O
consists	O
of	O
1555	O
images	O
with	O
more	O
than	O
3	O
different	O
text	O
orientations	O
:	O
Horizontal	O
,	O
Multi	O
-	O
Oriented	O
,	O
and	O
Curved	O
.	O
	
SynthText	B-Material
in	O
the	O
Wild	O
(	O
SynthText	B-Material
)	O
	
The	O
dataset	O
contains	O
800	O
,	O
000	O
synthetic	O
images	O
,	O
text	O
with	O
random	O
color	O
,	O
fonts	O
,	O
scale	O
and	O
orientation	O
are	O
rendered	O
on	O
natural	O
images	O
carefully	O
to	O
have	O
a	O
realistic	O
look	O
.	O
	
Annotations	O
are	O
given	O
in	O
character	O
,	O
word	O
and	O
line	O
level	O
.	O
	
subsection	O
:	O
Implementation	O
Details	O
	
Training	O
We	O
pretrain	O
the	O
proposed	O
FTSN	B-Method
on	O
a	O
subset	O
of	O
SynthText	B-Material
containing	O
160	O
,	O
000	O
images	O
,	O
then	O
finetune	O
on	O
IC15	B-Material
,	O
TD500	B-Material
and	O
Total	B-Material
-	I-Material
Text	I-Material
.	O
	
For	O
optimization	B-Task
,	O
standard	O
SGD	B-Method
is	O
used	O
during	O
training	O
with	O
learning	B-Metric
rate	I-Metric
for	O
first	O
5	O
epochs	O
and	O
for	O
the	O
last	O
epoch	O
,	O
and	O
we	O
also	O
apply	O
online	B-Method
hard	I-Method
example	I-Method
mining	I-Method
(	O
OHEM	B-Method
)	I-Method
for	O
balancing	O
the	O
positive	O
and	O
negative	O
samples	O
.	O
	
Different	O
from	O
original	O
RPN	B-Method
anchor	I-Method
ratios	I-Method
and	O
scales	O
setting	O
for	O
object	B-Task
detection	I-Task
,	O
anchor	O
scales	O
of	O
[	O
]	O
and	O
ratios	O
of	O
[	O
1	O
/	O
3	O
,	O
1	O
/	O
2	O
,	O
1	O
,	O
2	O
,	O
3	O
,	O
5	O
,	O
7	O
]	O
are	O
set	O
because	O
text	O
often	O
has	O
a	O
large	O
aspect	O
ratio	O
and	O
a	O
small	O
scale	O
.	O
	
Data	B-Task
augmentation	I-Task
Multi	I-Task
-	I-Task
scale	I-Task
training	I-Task
,	O
rotation	O
and	O
color	O
jittering	O
are	O
applied	O
during	O
training	O
.	O
	
Scales	O
are	O
randomly	O
chosen	O
from	O
[	O
600	O
,	O
720	O
,	O
960	O
,	O
1100	O
]	O
and	O
each	O
number	O
represents	O
the	O
short	O
edge	O
of	O
input	O
images	O
.	O
	
Rotation	O
with	O
,	O
and	O
are	O
applied	O
with	O
horizontal	O
flip	O
.	O
	
Consequently	O
,	O
it	O
enlarges	O
8x	O
dataset	O
size	O
than	O
the	O
original	O
one	O
.	O
	
Random	O
brightness	O
,	O
contrast	O
and	O
saturation	O
jittering	O
are	O
applied	O
for	O
input	O
images	O
.	O
	
Testing	O
Input	O
images	O
are	O
resized	O
to	O
when	O
testing	O
.	O
	
After	O
NMS	B-Method
,	O
mask	B-Method
voting	I-Method
is	O
used	O
to	O
obtain	O
an	O
ensemble	O
text	O
instance	O
mask	O
by	O
averaging	O
all	O
reasonable	O
detections	O
.	O
	
Experiments	O
are	O
conducted	O
on	O
MXNet	B-Method
and	O
run	O
on	O
a	O
server	O
with	O
Intel	O
i7	O
6700	O
K	O
CPU	O
,	O
64	O
GB	O
RAM	O
,	O
GTX	O
1080	O
and	O
Ubuntu	O
14.04	O
OS	O
.	O
	
subsection	O
:	O
Results	O
	
Tabel.1	O
shows	O
results	O
of	O
the	O
proposed	O
FTSN	B-Method
on	O
IC15	B-Material
compared	O
with	O
previous	O
state	O
of	O
art	O
published	O
methods	O
.	O
	
SNMS	B-Method
and	O
MNMS	B-Method
represent	O
standard	O
NMS	B-Method
and	I-Method
Mask	I-Method
-	I-Method
NMS	I-Method
respectively	O
.	O
	
Our	O
FTSN	B-Method
with	O
Mask	B-Method
-	I-Method
NMS	I-Method
outperforms	O
former	O
best	O
result	O
by	O
5.3	O
%	O
in	O
Precision	B-Metric
and	O
3.1	O
%	O
in	O
Hmean	B-Method
.	O
	
It	O
is	O
evaluated	O
by	O
the	O
official	O
submission	O
server	O
.	O
	
Results	O
on	O
TD500	B-Material
are	O
shown	O
in	O
Table.2	O
along	O
with	O
other	O
state	O
of	O
art	O
methods	O
.	O
	
It	O
is	O
shown	O
that	O
our	O
methods	O
outperform	O
the	O
current	O
state	O
of	O
art	O
approaches	O
by	O
a	O
large	O
margin	B-Metric
in	O
Hmean	B-Metric
and	I-Metric
Recall	I-Metric
,	O
without	O
adding	O
extra	O
real	O
-	O
world	O
training	O
images	O
.	O
	
Our	O
method	O
also	O
shows	O
great	O
flexibility	O
on	O
the	O
total	O
-	O
text	O
dataset	O
containing	O
curved	O
text	O
.	O
	
As	O
the	O
dataset	O
is	O
new	O
to	O
the	O
community	O
,	O
experiments	O
are	O
seldom	O
conducted	O
on	O
it	O
which	O
makes	O
our	O
results	O
as	O
a	O
baseline	O
shown	O
in	O
Table3	O
.	O
	
The	O
evaluation	B-Metric
metric	I-Metric
uses	O
IoU	O
of	O
0.5	O
between	O
each	O
instance	O
masks	O
.	O
	
Outperforming	O
the	O
current	O
state	O
of	O
the	O
art	O
,	O
our	O
approach	O
runs	O
about	O
4	O
FPS	B-Metric
on	O
images	O
and	O
2.5	O
FPS	B-Metric
when	O
using	O
Mask	B-Method
-	I-Method
NMS	I-Method
,	O
which	O
presents	O
efficiency	O
and	O
accuracy	B-Metric
.	O
	
It	O
is	O
noted	O
that	O
the	O
proposed	O
Mask	B-Method
-	I-Method
NMS	I-Method
significantly	O
improved	O
Hmean	B-Method
by	O
0.7	O
and	O
0.3	O
percent	O
on	O
IC15	B-Material
and	O
TD500	B-Material
,	O
which	O
mainly	O
target	O
the	O
situations	O
in	O
Fig.4	O
and	O
Fig.5	O
.	O
	
Fig.6	O
shows	O
example	O
results	O
of	O
FTSN	B-Method
.	O
	
From	O
left	O
to	O
right	O
,	O
it	O
illustrates	O
results	O
on	O
IC15	B-Material
,	O
TD500	B-Material
and	O
Total	B-Material
-	I-Material
Text	I-Material
dataset	I-Material
.	O
	
The	O
decent	O
performance	O
for	O
word	B-Task
-	I-Task
level	I-Task
,	I-Task
line	I-Task
-	I-Task
level	I-Task
and	I-Task
curved	I-Task
text	I-Task
detection	I-Task
with	O
large	O
variation	O
in	O
resolution	B-Metric
,	O
view	O
point	O
,	O
scale	O
and	O
linguistics	O
suggests	O
excellent	O
generalization	B-Metric
ability	I-Metric
.	O
	
section	O
:	O
Conclusion	O
	
We	O
present	O
FTSN	B-Method
,	O
an	O
end	O
-	O
end	O
efficient	O
and	O
accurate	O
multi	O
-	O
oriented	O
scene	B-Task
text	I-Task
detection	I-Task
framework	O
.	O
	
It	O
has	O
outperformed	O
previous	O
state	O
of	O
the	O
art	O
approaches	O
on	O
word	O
-	O
level	O
line	O
-	O
level	O
annotated	O
benchmarks	O
and	O
report	O
a	O
baseline	O
on	O
total	O
-	O
text	O
demonstrating	O
decent	O
generalization	B-Metric
ability	I-Metric
and	O
flexibility	O
.	O
	
section	O
:	O
Acknowlegements	O
	
The	O
research	O
is	O
supported	O
by	O
The	O
National	O
Key	O
Research	O
and	O
Development	O
Program	O
of	O
China	O
under	O
grant	O
2017YFB1002401	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Segmental	B-Method
Recurrent	I-Method
Neural	I-Method
Networks	I-Method
for	O
End	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
Speech	I-Task
Recognition	I-Task
	
We	O
study	O
the	O
segmental	B-Method
recurrent	I-Method
neural	I-Method
network	I-Method
for	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
acoustic	I-Task
modelling	I-Task
.	O
	
This	O
model	O
connects	O
the	O
segmental	O
conditional	B-Method
random	I-Method
field	I-Method
(	O
CRF	B-Method
)	O
with	O
a	O
recurrent	B-Method
neural	I-Method
network	I-Method
(	O
RNN	B-Method
)	I-Method
used	O
for	O
feature	B-Task
extraction	I-Task
.	O
	
Compared	O
to	O
most	O
previous	O
CRF	B-Method
-	O
based	O
acoustic	O
models	O
,	O
it	O
does	O
not	O
rely	O
on	O
an	O
external	B-Method
system	I-Method
to	O
provide	O
features	O
or	O
segmentation	O
boundaries	O
.	O
	
Instead	O
,	O
this	O
model	O
marginalises	O
out	O
all	O
the	O
possible	O
segmentations	O
,	O
and	O
features	O
are	O
extracted	O
from	O
the	O
RNN	B-Method
trained	O
together	O
with	O
the	O
segmental	O
CRF	B-Method
.	O
	
Essentially	O
,	O
this	O
model	O
is	O
self	O
-	O
contained	O
and	O
can	O
be	O
trained	O
end	O
-	O
to	O
-	O
end	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
discuss	O
practical	B-Task
training	I-Task
and	I-Task
decoding	I-Task
issues	I-Task
as	O
well	O
as	O
the	O
method	O
to	O
speed	O
up	O
the	O
training	B-Task
in	O
the	O
context	O
of	O
speech	B-Task
recognition	I-Task
.	O
	
We	O
performed	O
experiments	O
on	O
the	O
TIMIT	B-Material
dataset	I-Material
.	O
	
We	O
achieved	O
17.3	O
%	O
phone	B-Metric
error	I-Metric
rate	I-Metric
(	O
PER	B-Metric
)	O
from	O
the	O
first	B-Method
-	I-Method
pass	I-Method
decoding	I-Method
—	O
the	O
best	O
reported	O
result	O
using	O
CRFs	B-Method
,	O
despite	O
the	O
fact	O
that	O
we	O
only	O
used	O
a	O
zeroth	O
-	O
order	O
CRF	B-Method
and	O
without	O
using	O
any	O
language	B-Method
model	I-Method
.	O
	
CentreforSpeechTechnologyResearch	O
,	O
TheUniversityofEdinburgh	O
,	O
Edinburgh	O
,	O
UK	O
SchoolofComputerScience	O
,	O
CarnegieMellonUniversity	O
,	O
Pittsburgh	O
,	O
USA	O
ComputerScience	O
&	O
Engineering	O
,	O
TheUniversityofWashington	O
,	O
Seattle	O
,	O
	
USA	O
{	O
liang.lu	O
,	O
s.renals}@ed.ac.uk	O
,	O
{lingpenk	O
,	O
cdyer}@cs.cmu.edu	O
,	O
nasmith@cs.washington.edu	O
Index	O
Terms	O
:	O
end	O
-	O
to	O
-	O
end	O
speech	B-Task
recognition	I-Task
,	O
segmental	O
CRF	B-Method
,	O
recurrent	B-Method
neural	I-Method
networks	I-Method
.	O
	
section	O
:	O
Introduction	O
	
Speech	B-Task
recognition	I-Task
is	O
a	O
typical	O
sequence	B-Task
to	I-Task
sequence	I-Task
transduction	I-Task
problem	I-Task
,	O
i.e.	O
,	O
given	O
a	O
sequence	O
of	O
acoustic	O
observations	O
,	O
the	O
speech	B-Task
recognition	I-Task
engine	O
decodes	O
the	O
corresponding	O
sequence	O
of	O
words	O
or	O
phonemes	O
.	O
	
A	O
key	O
component	O
in	O
a	O
speech	B-Task
recognition	I-Task
system	O
is	O
the	O
acoustic	B-Method
model	I-Method
,	O
which	O
computes	O
the	O
conditional	O
probability	O
of	O
the	O
output	O
sequence	O
given	O
the	O
input	O
sequence	O
.	O
	
However	O
,	O
directly	O
computing	O
this	O
conditional	O
probability	O
is	O
challenging	O
due	O
to	O
many	O
factors	O
including	O
the	O
variable	O
lengths	O
of	O
the	O
input	O
and	O
output	O
sequences	O
.	O
	
The	O
hidden	B-Method
Markov	I-Method
model	I-Method
(	O
HMM	B-Method
)	O
converts	O
this	O
sequence	B-Task
-	I-Task
level	I-Task
classification	I-Task
task	I-Task
into	O
a	O
frame	B-Task
-	I-Task
level	I-Task
classification	I-Task
problem	I-Task
,	O
where	O
each	O
acoustic	O
frame	O
is	O
classified	O
into	O
one	O
of	O
the	O
hidden	O
states	O
,	O
and	O
each	O
output	O
sequence	O
corresponds	O
to	O
a	O
sequence	O
of	O
hidden	O
states	O
.	O
	
To	O
make	O
it	O
computationally	O
tractable	O
,	O
HMMs	B-Method
usually	O
rely	O
on	O
the	O
conditional	O
independence	O
assumption	O
and	O
the	O
first	B-Method
-	I-Method
order	I-Method
Markov	I-Method
rule	I-Method
—	O
the	O
well	O
-	O
known	O
weaknesses	O
of	O
HMMs	B-Method
.	O
	
Furthermore	O
,	O
the	O
HMM	B-Method
-	I-Method
based	I-Method
pipeline	I-Method
is	O
composed	O
of	O
a	O
few	O
relatively	O
independent	O
modules	O
,	O
which	O
makes	O
the	O
joint	B-Task
optimisation	I-Task
nontrivial	O
.	O
	
There	O
has	O
been	O
a	O
consistent	O
research	O
effort	O
to	O
seek	O
architectures	O
to	O
replace	O
HMMs	B-Method
and	O
overcome	O
their	O
limitation	O
for	O
acoustic	B-Task
modelling	I-Task
,	O
e.g.	O
,	O
;	O
however	O
these	O
approaches	O
have	O
not	O
yet	O
improved	O
speech	B-Task
recognition	I-Task
accuracy	O
over	O
HMMs	B-Method
.	O
	
In	O
the	O
past	O
few	O
years	O
,	O
several	O
neural	B-Method
network	I-Method
based	I-Method
approaches	I-Method
have	O
been	O
proposed	O
and	O
demonstrated	O
promising	O
results	O
.	O
	
In	O
particular	O
,	O
the	O
connectionist	O
temporal	O
classification	O
(	O
CTC	B-Method
)	O
approach	O
defines	O
the	O
loss	O
function	O
directly	O
to	O
maximise	O
the	O
conditional	O
probability	O
of	O
the	O
output	O
sequence	O
given	O
the	O
input	O
sequence	O
,	O
and	O
it	O
usually	O
uses	O
a	O
recurrent	B-Method
neural	I-Method
network	I-Method
to	O
extract	O
features	O
.	O
	
However	O
,	O
CTC	B-Method
simplifies	O
the	O
sequence	O
-	O
level	O
error	O
function	O
by	O
a	O
product	O
of	O
the	O
frame	O
-	O
level	O
error	O
functions	O
(	O
i.e.	O
,	O
independence	O
assumption	O
)	O
,	O
which	O
means	O
it	O
essentially	O
still	O
does	O
frame	B-Method
-	I-Method
level	I-Method
classification	I-Method
.	O
	
It	O
also	O
requires	O
the	O
lengths	O
of	O
the	O
input	O
and	O
output	O
sequence	O
to	O
be	O
the	O
same	O
,	O
which	O
is	O
inappropriate	O
for	O
speech	B-Task
recognition	I-Task
.	O
	
CTC	B-Method
deals	O
with	O
this	O
problem	O
by	O
replicating	O
the	O
output	O
labels	O
so	O
that	O
a	O
consecutive	O
frames	O
may	O
correspond	O
to	O
the	O
same	O
output	O
label	O
or	O
a	O
blank	O
token	O
.	O
	
Attention	O
-	O
based	O
RNNs	B-Method
have	O
been	O
demonstrated	O
to	O
be	O
a	O
powerful	O
alternative	O
sequence	B-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
transducer	I-Method
,	O
e.g.	O
,	O
in	O
machine	B-Task
translation	I-Task
,	O
and	O
speech	B-Task
recognition	I-Task
.	O
	
A	O
key	O
difference	O
of	O
this	O
model	O
from	O
HMMs	B-Method
and	O
CTCs	B-Method
is	O
that	O
the	O
attention	B-Method
-	I-Method
based	I-Method
approach	I-Method
does	O
not	O
apply	O
the	O
conditional	O
independence	O
assumption	O
to	O
the	O
input	O
sequence	O
.	O
	
Instead	O
,	O
it	O
maps	O
the	O
variable	O
-	O
length	O
input	O
sequence	O
into	O
a	O
fixed	O
-	O
size	O
vector	B-Method
representation	I-Method
at	O
each	O
decoding	O
step	O
by	O
an	O
attention	B-Method
-	I-Method
based	I-Method
scheme	I-Method
(	O
see	O
for	O
further	O
explanation	O
)	O
.	O
	
It	O
then	O
generates	O
the	O
output	O
sequence	O
using	O
an	O
RNN	B-Method
conditioned	O
on	O
the	O
vector	B-Method
representation	I-Method
from	O
the	O
source	O
sequence	O
.	O
	
The	O
attentive	B-Method
scheme	I-Method
suits	O
the	O
machine	B-Task
translation	I-Task
task	I-Task
well	O
,	O
because	O
there	O
may	O
be	O
no	O
clear	O
alignment	O
between	O
the	O
source	O
and	O
target	O
sequence	O
for	O
many	O
language	O
pairs	O
.	O
	
However	O
,	O
this	O
approach	O
does	O
not	O
naturally	O
apply	O
to	O
the	O
speech	B-Task
recognition	I-Task
task	O
,	O
as	O
each	O
output	O
token	O
only	O
corresponds	O
to	O
a	O
small	O
size	O
window	O
of	O
acoustic	O
spectrum	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
study	O
segmental	O
RNNs	B-Method
for	O
acoustic	B-Task
modelling	I-Task
.	O
	
This	O
model	O
is	O
similar	O
to	O
CTC	B-Method
and	O
attention	B-Method
-	I-Method
based	I-Method
RNN	I-Method
in	O
the	O
sense	O
that	O
an	O
RNN	B-Method
encoder	O
is	O
also	O
used	O
for	O
feature	B-Task
extraction	I-Task
,	O
but	O
it	O
differs	O
in	O
the	O
sense	O
that	O
the	O
sequence	O
-	O
level	O
conditional	O
probability	O
is	O
defined	O
using	O
an	O
segmental	O
(	O
semi	O
-	O
Markov	O
)	O
CRF	B-Method
,	O
which	O
is	O
an	O
extension	O
on	O
the	O
standard	O
CRF	B-Method
.	O
	
There	O
have	O
been	O
numerous	O
works	O
on	O
CRFs	B-Method
and	O
their	O
variants	O
for	O
speech	B-Task
recognition	I-Task
,	O
e.g	O
,	O
(	O
see	O
for	O
an	O
overview	O
)	O
.	O
	
In	O
particular	O
,	O
feed	B-Method
-	I-Method
forward	I-Method
neural	I-Method
networks	I-Method
have	O
been	O
used	O
with	O
segmental	O
CRFs	B-Method
for	O
speech	B-Task
recognition	I-Task
.	O
	
However	O
,	O
segmental	O
RNNs	B-Method
are	O
different	O
in	O
that	O
they	O
are	O
end	O
-	O
to	O
-	O
end	O
models	O
	
—	O
they	O
do	O
not	O
depend	O
on	O
external	B-Method
systems	I-Method
to	O
provide	O
segmentation	O
boundaries	O
and	O
features	O
,	O
instead	O
,	O
they	O
are	O
trained	O
by	O
marginalising	O
out	O
all	O
possible	O
segmentations	O
,	O
while	O
the	O
features	O
are	O
derived	O
from	O
the	O
encoder	O
RNNs	B-Method
,	O
which	O
are	O
trained	O
jointly	O
with	O
the	O
segmental	O
CRFs	B-Method
.	O
	
Our	O
experiments	O
were	O
performed	O
on	O
the	O
TIMIT	B-Material
dataset	I-Material
,	O
and	O
we	O
achieved	O
17.3	O
%	O
PER	B-Metric
from	O
first	B-Method
-	I-Method
pass	I-Method
decoding	I-Method
with	O
zeroth	O
-	O
order	O
CRF	B-Method
and	O
without	O
using	O
any	O
language	B-Method
model	I-Method
—	O
the	O
best	O
reported	O
result	O
using	O
CRFs	B-Method
.	O
	
section	O
:	O
Segmental	B-Method
Recurrent	I-Method
Neural	I-Method
Networks	I-Method
	
subsection	O
:	O
Segmental	B-Method
Conditional	I-Method
Random	I-Method
Fields	I-Method
	
Given	O
a	O
sequence	O
of	O
acoustic	O
frames	O
and	O
its	O
corresponding	O
sequence	O
of	O
output	O
labels	O
,	O
where	O
,	O
segmental	O
(	O
or	O
semi	O
-	O
Markov	O
)	O
conditional	B-Method
random	I-Method
field	I-Method
defines	O
the	O
sequence	O
-	O
level	O
conditional	O
probability	O
with	O
the	O
auxiliary	O
segment	O
labels	O
as	O
where	O
is	O
a	O
tuple	O
of	O
the	O
beginning	O
(	O
)	O
and	O
the	O
end	O
(	O
)	O
time	O
tag	O
for	O
the	O
segment	O
of	O
,	O
and	O
while	O
;	O
and	O
denotes	O
the	O
vocabulary	O
set	O
;	O
is	O
the	O
normaliser	O
that	O
that	O
sums	O
over	O
all	O
the	O
possible	O
pairs	O
,	O
i.e.	O
,	O
Here	O
,	O
we	O
only	O
consider	O
the	O
zeroth	O
-	O
order	O
CRF	B-Method
,	O
while	O
the	O
extension	O
to	O
higher	O
order	B-Method
models	I-Method
is	O
straightforward	O
.	O
	
Similar	O
to	O
other	O
CRF	B-Method
-	O
based	O
models	O
,	O
the	O
function	O
is	O
defined	O
as	O
where	O
denotes	O
the	O
feature	O
function	O
,	O
and	O
is	O
the	O
weight	O
vector	O
.	O
	
Previous	O
works	O
on	O
CRF	B-Method
-	O
based	O
acoustic	O
models	O
mainly	O
use	O
heuristically	O
handcrafted	O
feature	O
function	O
.	O
	
They	O
also	O
usually	O
rely	O
on	O
an	O
external	O
system	O
to	O
provide	O
the	O
segment	O
labels	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
define	O
using	O
neural	B-Method
networks	I-Method
,	O
and	O
the	O
segmentation	B-Method
is	O
marginalised	O
out	O
during	O
training	O
,	O
which	O
makes	O
our	O
model	O
self	O
-	O
contained	O
.	O
	
subsection	O
:	O
Feature	B-Method
Representations	I-Method
	
We	O
use	O
neural	B-Method
networks	I-Method
to	O
define	O
the	O
feature	O
function	O
,	O
which	O
maps	O
the	O
acoustic	O
segment	O
and	O
its	O
corresponding	O
label	O
into	O
a	O
joint	O
feature	O
space	O
.	O
	
More	O
specifically	O
,	O
is	O
firstly	O
represented	O
as	O
a	O
one	O
-	O
hot	O
vector	O
,	O
and	O
it	O
is	O
then	O
mapped	O
into	O
a	O
continuous	O
space	O
by	O
a	O
linear	B-Method
embedding	I-Method
matrix	I-Method
as	O
Given	O
the	O
segment	O
label	O
,	O
we	O
use	O
an	O
RNN	B-Method
to	O
map	O
the	O
acoustic	O
segment	O
to	O
a	O
fixed	O
-	O
dimensional	B-Method
vector	I-Method
representation	I-Method
,	O
i.e.	O
,	O
where	O
denotes	O
the	O
initial	O
hidden	O
state	O
,	O
denotes	O
the	O
duration	O
of	O
the	O
segment	O
and	O
is	O
a	O
non	O
-	O
linear	O
function	O
.	O
	
We	O
take	O
the	O
final	O
hidden	O
state	O
as	O
the	O
segment	O
embedding	O
vector	O
,	O
then	O
can	O
be	O
represented	O
as	O
where	O
corresponds	O
to	O
one	O
layer	O
or	O
multiple	O
layers	O
of	O
linear	B-Method
or	I-Method
non	I-Method
-	I-Method
linear	I-Method
transformation	I-Method
.	O
	
In	O
fact	O
,	O
it	O
is	O
flexible	O
to	O
include	O
other	O
relevant	O
features	O
as	O
additional	O
inputs	O
to	O
the	O
function	O
,	O
e.g.	O
,	O
the	O
duration	O
feature	O
which	O
can	O
be	O
obtained	O
by	O
converting	O
into	O
another	O
embedding	O
vector	O
.	O
	
In	O
practice	O
,	O
multiple	O
RNN	B-Method
layers	O
can	O
be	O
used	O
transform	O
the	O
acoustic	O
signal	O
before	O
extracting	O
the	O
segment	O
embedding	O
vector	O
as	O
Figure	O
[	O
reference	O
]	O
.	O
	
subsection	O
:	O
Conditional	B-Method
Maximum	I-Method
Likelihood	I-Method
Training	I-Method
	
For	O
speech	B-Task
recognition	I-Task
,	O
the	O
segmentation	O
labels	O
are	O
usually	O
unknown	O
,	O
training	O
the	O
model	O
by	O
maximising	O
the	O
conditional	O
probability	O
as	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
is	O
therefore	O
not	O
practical	O
.	O
	
The	O
problem	O
can	O
be	O
addressed	O
by	O
defining	O
the	O
loss	O
function	O
as	O
the	O
negative	O
marginal	O
log	O
-	O
likelihood	O
as	O
where	O
denotes	O
the	O
set	O
of	O
model	O
parameters	O
,	O
and	O
denotes	O
the	O
summation	O
over	O
all	O
the	O
possible	O
segmentations	O
when	O
only	O
is	O
observed	O
.	O
	
To	O
simplify	O
notations	O
,	O
the	O
objective	B-Metric
function	I-Metric
is	O
define	O
with	O
only	O
one	O
training	O
utterance	O
.	O
	
However	O
,	O
the	O
number	O
of	O
possible	O
segmentations	O
is	O
exponential	O
with	O
the	O
length	O
of	O
,	O
which	O
makes	O
the	O
naive	O
computation	O
of	O
both	O
and	O
impractical	O
.	O
	
Fortunately	O
,	O
this	O
can	O
be	O
addressed	O
by	O
using	O
the	O
following	O
dynamic	B-Method
programming	I-Method
algorithm	I-Method
as	O
proposed	O
in	O
:	O
	
In	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
	
,	O
the	O
first	O
summation	O
is	O
over	O
all	O
the	O
possible	O
segmentation	O
up	O
to	O
timestep	O
,	O
and	O
the	O
second	O
summation	O
is	O
over	O
all	O
the	O
possible	O
labels	O
from	O
the	O
vocabulary	O
.	O
	
The	O
computation	B-Metric
cost	I-Metric
of	O
this	O
algorithm	O
is	O
,	O
where	O
is	O
the	O
size	O
of	O
the	O
vocabulary	O
.	O
	
The	O
cost	O
can	O
be	O
further	O
reduced	O
by	O
introducing	O
an	O
upper	O
bound	O
of	O
the	O
segment	O
length	O
,	O
in	O
which	O
case	O
Eq	O
.	O
(	O
[	O
reference	O
]	O
)	O
can	O
be	O
rewritten	O
as	O
where	O
denotes	O
the	O
maximum	O
value	O
of	O
the	O
segment	O
length	O
.	O
	
The	O
cost	O
is	O
then	O
reduced	O
to	O
,	O
and	O
for	O
long	O
sequences	O
like	O
speech	O
signals	O
where	O
,	O
the	O
computational	B-Metric
savings	I-Metric
are	O
substantial	O
.	O
	
The	O
term	O
can	O
be	O
computed	O
similarly	O
.	O
	
In	O
this	O
case	O
,	O
since	O
the	O
label	O
is	O
now	O
observed	O
,	O
the	O
summation	O
over	O
all	O
the	O
possible	O
labels	O
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
is	O
not	O
necessary	O
,	O
i.e.	O
,	O
Again	O
,	O
we	O
can	O
limit	O
the	O
length	O
of	O
the	O
possible	O
segments	O
as	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
	
Given	O
and	O
,	O
the	O
loss	O
function	O
can	O
be	O
minimised	O
using	O
the	O
stochastic	B-Method
gradient	I-Method
decent	I-Method
(	O
SGD	B-Method
)	O
algorithm	O
similar	O
to	O
training	O
other	O
neural	B-Method
network	I-Method
models	I-Method
.	O
	
Other	O
losses	O
,	O
for	O
example	O
,	O
hinge	O
,	O
can	O
be	O
considered	O
in	O
future	O
work	O
.	O
	
subsection	O
:	O
Viterbi	B-Method
Decoding	I-Method
	
During	O
decoding	B-Task
,	O
we	O
need	O
to	O
search	O
the	O
target	O
label	O
sequence	O
that	O
yields	O
the	O
highest	O
posterior	O
probability	O
given	O
by	O
marginalising	O
out	O
all	O
the	O
possible	O
segmentations	O
:	O
This	O
involves	O
minor	O
modification	O
of	O
the	O
recursive	B-Method
algorithm	I-Method
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
	
that	O
instead	O
of	O
summing	O
over	O
all	O
the	O
possible	O
labels	O
,	O
the	O
Viterbi	O
path	O
up	O
to	O
the	O
timestep	O
is	O
However	O
,	O
marginalising	O
out	O
all	O
the	O
possible	O
segmentations	O
is	O
still	O
expensive	O
.	O
	
The	O
computational	B-Metric
cost	I-Metric
can	O
be	O
further	O
reduced	O
by	O
greedy	O
searching	O
the	O
most	O
likely	O
segmentation	O
,	O
i.e.	O
,	O
which	O
corresponds	O
to	O
the	O
decoding	B-Task
objective	I-Task
as	O
This	O
joint	B-Method
maximization	I-Method
algorithm	I-Method
may	O
yield	O
high	O
search	B-Metric
error	I-Metric
,	O
because	O
it	O
only	O
considers	O
one	O
segmentation	O
.	O
	
In	O
the	O
future	O
,	O
we	O
shall	O
investigate	O
the	O
beam	B-Method
search	I-Method
algorithm	I-Method
which	O
may	O
yield	O
a	O
lower	O
search	B-Metric
error	I-Metric
.	O
	
subsection	O
:	O
Further	O
Speedup	O
	
It	O
is	O
computationally	O
expensive	O
for	O
RNNs	B-Method
to	O
model	O
long	O
sequences	O
,	O
and	O
the	O
number	O
of	O
possible	O
segmentations	O
is	O
exponential	O
with	O
the	O
length	O
of	O
the	O
input	O
sequence	O
as	O
mentioned	O
before	O
.	O
	
The	O
computational	B-Metric
cost	I-Metric
can	O
be	O
significantly	O
reduced	O
by	O
using	O
the	O
hierarchical	O
subsampling	O
RNN	B-Method
to	O
shorten	O
the	O
input	O
sequences	O
,	O
where	O
the	O
subsampling	B-Method
layer	I-Method
takes	O
a	O
window	O
of	O
hidden	O
states	O
from	O
the	O
lower	O
layer	O
as	O
input	O
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
In	O
this	O
work	O
,	O
we	O
consider	O
three	O
variants	O
:	O
a	O
)	O
concatenate	B-Method
–	O
	
the	O
hidden	O
states	O
in	O
the	O
subsampling	O
window	O
are	O
concatenated	O
before	O
been	O
fed	O
into	O
the	O
next	O
layer	O
;	O
b	O
)	O
add	O
–	O
	
the	O
hidden	O
states	O
are	O
added	O
into	O
one	O
vector	O
for	O
the	O
next	O
layer	O
;	O
c	O
)	O
skip	O
–	O
only	O
the	O
last	O
hidden	O
state	O
in	O
the	O
window	O
is	O
kept	O
and	O
all	O
the	O
others	O
are	O
skipped	O
.	O
	
The	O
last	O
two	O
schemes	O
are	O
computationally	O
cheaper	O
as	O
they	O
do	O
not	O
introduce	O
extra	O
model	O
parameters	O
.	O
	
section	O
:	O
Experiments	O
	
subsection	O
:	O
System	O
Setup	O
	
We	O
used	O
the	O
TIMIT	B-Material
dataset	I-Material
to	O
evaluate	O
the	O
segmental	O
RNN	B-Method
acoustic	O
models	O
.	O
	
This	O
dataset	O
was	O
preferred	O
for	O
the	O
rapid	O
evaluation	O
of	O
different	O
system	B-Task
settings	I-Task
,	O
and	O
for	O
the	O
comparison	O
to	O
other	O
CRF	B-Method
and	O
end	O
-	O
to	O
-	O
end	O
systems	O
.	O
	
We	O
followed	O
the	O
standard	O
protocol	O
of	O
the	O
TIMIT	B-Material
dataset	I-Material
,	O
and	O
our	O
experiments	O
were	O
based	O
on	O
the	O
Kaldi	B-Method
recipe	I-Method
.	O
	
We	O
used	O
the	O
core	O
test	O
set	O
as	O
our	O
evaluation	O
set	O
,	O
which	O
has	O
192	O
utterances	O
.	O
	
We	O
used	O
24	O
dimensional	O
log	O
fiterbanks	B-Method
(	O
FBANKs	B-Method
)	O
with	O
delta	O
and	O
double	O
-	O
delta	O
coefficients	O
,	O
yielding	O
72	O
dimensional	O
feature	O
vectors	O
.	O
	
Our	O
models	O
were	O
trained	O
with	O
48	O
phonemes	O
,	O
and	O
their	O
predictions	O
were	O
converted	O
to	O
39	O
phonemes	O
before	O
scoring	O
.	O
	
The	O
dimension	O
of	O
was	O
fixed	O
to	O
be	O
32	O
.	O
	
For	O
all	O
our	O
experiments	O
,	O
we	O
used	O
the	O
long	B-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
(	O
LSTM	B-Method
)	O
networks	O
as	O
the	O
implementation	O
of	O
RNNs	B-Method
,	O
and	O
the	O
networks	O
were	O
always	O
bi	O
-	O
directional	O
.	O
	
We	O
set	O
the	O
initial	O
SGD	B-Method
learning	O
rate	O
to	O
be	O
0.1	O
,	O
and	O
we	O
exponentially	O
decay	O
the	O
learning	B-Metric
rate	I-Metric
by	O
a	O
factor	O
of	O
2	O
when	O
the	O
validation	B-Metric
error	I-Metric
stopped	O
decreasing	O
.	O
	
Our	O
models	O
were	O
trained	O
with	O
dropout	B-Method
regularisation	I-Method
,	O
using	O
an	O
specific	O
implementation	O
for	O
recurrent	B-Method
networks	I-Method
.	O
	
The	O
dropout	B-Metric
rate	I-Metric
was	O
0.2	O
unless	O
specified	O
otherwise	O
.	O
	
Our	O
models	O
were	O
randomly	O
initialised	O
with	O
the	O
same	O
random	O
seed	O
.	O
	
subsection	O
:	O
Results	O
of	O
Hierarchical	B-Method
Subsampling	I-Method
	
We	O
first	O
demonstrate	O
the	O
results	O
of	O
the	O
hierarchical	B-Method
subsampling	I-Method
recurrent	I-Method
network	I-Method
,	O
which	O
is	O
the	O
key	O
to	O
speed	O
up	O
our	O
experiments	O
.	O
	
We	O
set	O
the	O
size	O
of	O
the	O
subsampling	O
window	O
to	O
be	O
2	O
,	O
therefore	O
each	O
subsampling	B-Method
layer	I-Method
reduced	O
the	O
time	O
resolution	O
by	O
a	O
factor	O
of	O
2	O
.	O
	
We	O
set	O
the	O
maximum	O
segment	O
length	O
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
to	O
be	O
300	O
milliseconds	O
,	O
which	O
corresponded	O
to	O
30	O
frames	O
of	O
FBANKs	B-Method
(	O
sampled	O
at	O
the	O
rate	O
of	O
10	O
milliseconds	O
)	O
.	O
	
With	O
two	O
layers	O
of	O
subsampling	B-Method
recurrent	I-Method
networks	I-Method
,	O
the	O
time	B-Metric
resolution	I-Metric
was	O
reduced	O
by	O
a	O
factor	O
of	O
4	O
,	O
and	O
the	O
value	O
of	O
was	O
reduced	O
to	O
be	O
8	O
,	O
yielding	O
around	O
10	O
times	O
speedup	O
as	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Table	O
[	O
reference	O
]	O
compares	O
the	O
three	O
implementations	O
of	O
the	O
recurrent	B-Method
subsampling	I-Method
network	I-Method
detailed	O
in	O
section	O
[	O
reference	O
]	O
.	O
	
We	O
observed	O
that	O
concatenating	O
all	O
the	O
hidden	O
states	O
in	O
the	O
subsampling	O
window	O
did	O
not	O
yield	O
lower	O
phone	B-Metric
error	I-Metric
rate	I-Metric
(	O
PER	B-Metric
)	O
than	O
using	O
the	O
simple	O
skipping	B-Method
approach	I-Method
,	O
which	O
may	O
be	O
due	O
to	O
the	O
fact	O
that	O
the	O
TIMIT	B-Material
dataset	I-Material
is	O
small	O
and	O
it	O
prefers	O
a	O
smaller	O
model	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
adding	O
the	O
hidden	O
states	O
in	O
the	O
subsampling	O
window	O
together	O
worked	O
even	O
worse	O
,	O
possibly	O
due	O
to	O
that	O
the	O
sequential	O
information	O
in	O
the	O
subsampling	O
window	O
was	O
flattened	O
.	O
	
In	O
the	O
following	O
experiments	O
,	O
we	O
sticked	O
to	O
the	O
skipping	B-Method
method	I-Method
,	O
and	O
using	O
two	O
subsampling	B-Method
layers	I-Method
.	O
	
subsection	O
:	O
Hyperparameters	O
and	O
Different	O
Features	O
	
We	O
then	O
evaluated	O
the	O
model	O
by	O
tuning	O
the	O
hyperparameters	O
,	O
and	O
the	O
results	O
are	O
given	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
We	O
tuned	O
the	O
number	O
of	O
LSTM	B-Method
layers	O
,	O
and	O
the	O
dimension	O
of	O
LSTM	B-Method
cells	O
,	O
as	O
well	O
as	O
the	O
dimensions	O
of	O
and	O
the	O
segment	O
vector	O
.	O
	
In	O
general	O
,	O
larger	O
models	O
with	O
dropout	B-Method
regularisation	I-Method
yielded	O
higher	O
recognition	B-Metric
accuracy	I-Metric
.	O
	
Our	O
best	O
result	O
was	O
obtained	O
using	O
6	O
layers	O
of	O
250	B-Method
-	I-Method
dimensional	I-Method
LSTMs	I-Method
.	O
	
However	O
,	O
without	O
the	O
dropout	B-Method
regularisation	I-Method
,	O
the	O
model	O
can	O
be	O
easily	O
overfit	O
due	O
to	O
the	O
small	O
size	O
of	O
training	O
set	O
.	O
	
In	O
the	O
future	O
,	O
we	O
shall	O
evaluate	O
this	O
model	O
with	O
a	O
large	O
dataset	O
.	O
	
We	O
then	O
evaluated	O
another	O
two	O
types	O
of	O
features	O
using	O
the	O
same	O
system	O
configuration	O
that	O
achieved	O
the	O
best	O
result	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
We	O
increased	O
the	O
number	O
of	O
FBANKs	B-Method
from	O
24	O
to	O
40	O
,	O
which	O
yielded	O
slightly	O
lower	O
PER	B-Metric
.	O
	
We	O
also	O
evaluated	O
the	O
standard	O
Kaldi	B-Method
features	I-Method
—	O
39	O
dimensional	B-Method
MFCCs	I-Method
spliced	O
by	O
a	O
context	O
window	O
of	O
7	O
,	O
followed	O
by	O
LDA	B-Method
and	I-Method
MLLT	I-Method
transform	I-Method
and	O
with	O
feature	B-Method
-	I-Method
space	I-Method
speaker	I-Method
-	I-Method
dependent	I-Method
MLLR	I-Method
,	O
which	O
were	O
the	O
same	O
features	O
used	O
in	O
the	O
HMM	B-Method
-	I-Method
DNN	I-Method
baseline	I-Method
in	O
Table	O
[	O
reference	O
]	O
.	O
	
The	O
well	O
-	O
engineered	O
features	O
improved	O
the	O
accuracy	B-Metric
of	O
our	O
system	O
by	O
more	O
than	O
1	O
%	O
absolute	O
.	O
	
subsection	O
:	O
Comparison	O
to	O
Related	O
Works	O
	
In	O
Table	O
[	O
reference	O
]	O
,	O
we	O
compare	O
our	O
result	O
to	O
other	O
reported	O
results	O
using	O
segmental	O
CRFs	B-Method
as	O
well	O
as	O
recent	O
end	O
-	O
to	O
-	O
end	B-Method
systems	I-Method
.	O
	
Previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
result	O
using	O
segmental	O
CRFs	B-Method
on	O
the	O
TIMIT	B-Material
dataset	I-Material
is	O
reported	O
in	O
,	O
where	O
the	O
first	O
-	O
pass	B-Method
decoding	I-Method
was	O
used	O
to	O
prune	O
the	O
search	O
space	O
,	O
and	O
the	O
second	O
-	O
pass	O
was	O
used	O
to	O
re	O
-	O
score	O
the	O
hypothesis	O
using	O
various	O
features	O
including	O
neural	B-Method
network	I-Method
features	I-Method
.	O
	
Besides	O
,	O
the	O
ground	B-Metric
-	I-Metric
truth	I-Metric
segmentation	I-Metric
was	O
used	O
in	O
.	O
	
We	O
achieved	O
considerably	O
lower	O
PER	B-Metric
with	O
first	B-Method
-	I-Method
pass	I-Method
decoding	I-Method
,	O
despite	O
the	O
fact	O
that	O
our	O
CRF	B-Method
was	O
zeroth	O
-	O
order	O
,	O
and	O
we	O
did	O
not	O
use	O
any	O
language	B-Method
model	I-Method
.	O
	
Furthermore	O
,	O
our	O
results	O
are	O
also	O
comparable	O
to	O
that	O
from	O
the	O
CTC	B-Method
and	O
attention	O
-	O
based	O
RNN	B-Method
end	O
-	O
to	O
-	O
end	O
systems	O
.	O
	
The	O
accuracy	B-Metric
of	O
segmental	O
RNNs	B-Method
may	O
be	O
further	O
improved	O
by	O
using	O
higher	O
-	O
order	O
CRFs	B-Method
or	O
incorporating	O
a	O
language	B-Method
model	I-Method
into	O
the	O
decode	B-Method
step	I-Method
,	O
and	O
using	O
beam	B-Method
search	I-Method
to	O
reduce	O
the	O
search	B-Metric
error	I-Metric
.	O
	
section	O
:	O
Conclusions	O
	
In	O
this	O
paper	O
,	O
we	O
present	O
the	O
segmental	O
RNN	B-Method
—	O
a	O
novel	O
acoustic	B-Method
model	I-Method
that	O
combines	O
the	O
segmental	O
CRF	B-Method
with	O
an	O
encoder	O
RNN	B-Method
for	O
end	O
-	O
to	O
-	O
end	O
speech	B-Task
recognition	I-Task
.	O
	
We	O
discuss	O
the	O
practical	O
training	B-Method
and	I-Method
decoding	I-Method
algorithms	I-Method
of	O
this	O
model	O
for	O
speech	B-Task
recognition	I-Task
,	O
and	O
the	O
subsampling	B-Method
network	I-Method
to	O
reduce	O
the	O
computational	B-Metric
cost	I-Metric
.	O
	
Our	O
experiments	O
were	O
performed	O
on	O
the	O
TIMIT	B-Material
dataset	I-Material
,	O
and	O
we	O
achieved	O
strong	O
recognition	B-Metric
accuracy	I-Metric
using	O
zeroth	O
-	O
order	O
CRF	B-Method
,	O
and	O
without	O
using	O
any	O
language	B-Method
model	I-Method
.	O
	
In	O
the	O
future	O
,	O
we	O
shall	O
investigate	O
discriminative	B-Metric
training	I-Metric
criteria	I-Metric
,	O
and	O
incorporating	O
a	O
language	B-Method
model	I-Method
into	O
the	O
decoding	B-Task
step	I-Task
.	O
	
Future	O
works	O
also	O
include	O
implementing	O
a	O
weighted	B-Method
finite	I-Method
sate	I-Method
transducer	I-Method
(	I-Method
WFST	I-Method
)	I-Method
based	I-Method
decoder	I-Method
and	O
scaling	O
this	O
model	O
to	O
large	O
vocabulary	O
datasets	O
.	O
	
bibliography	O
:	O
References	O
	
This	O
paper	O
introduces	O
the	O
Deep	B-Method
Recurrent	I-Method
Attentive	I-Method
Writer	I-Method
(	O
DRAW	B-Method
)	O
	
neural	B-Method
network	I-Method
architecture	I-Method
for	O
image	B-Task
generation	I-Task
.	O
	
DRAW	B-Method
networks	O
combine	O
a	O
novel	O
spatial	B-Method
attention	I-Method
mechanism	I-Method
that	O
mimics	O
the	O
foveation	O
of	O
the	O
human	O
eye	O
,	O
with	O
a	O
sequential	B-Method
variational	I-Method
auto	I-Method
-	I-Method
encoding	I-Method
framework	I-Method
that	O
allows	O
for	O
the	O
iterative	B-Task
construction	I-Task
of	I-Task
complex	I-Task
images	I-Task
.	O
	
The	O
system	O
substantially	O
improves	O
on	O
the	O
state	O
of	O
the	O
art	O
for	O
generative	B-Method
models	I-Method
on	O
MNIST	B-Material
,	O
and	O
,	O
when	O
trained	O
on	O
the	O
Street	B-Material
View	I-Material
House	I-Material
Numbers	I-Material
dataset	O
,	O
it	O
generates	O
images	O
that	O
can	O
not	O
be	O
distinguished	O
from	O
real	O
data	O
with	O
the	O
naked	O
eye	O
.	O
	
DRAW	B-Method
:	O
	
ARecurrentNeuralNetworkForImageGeneration	O
	
section	O
:	O
Introduction	O
	
A	O
person	O
asked	O
to	O
draw	O
,	O
paint	O
or	O
otherwise	O
recreate	O
a	O
visual	O
scene	O
will	O
naturally	O
do	O
so	O
in	O
a	O
sequential	O
,	O
iterative	O
fashion	O
,	O
reassessing	O
their	O
handiwork	O
after	O
each	O
modification	O
.	O
	
Rough	O
outlines	O
are	O
gradually	O
replaced	O
by	O
precise	O
forms	O
,	O
lines	O
are	O
sharpened	O
,	O
darkened	O
or	O
erased	O
,	O
shapes	O
are	O
altered	O
,	O
and	O
the	O
final	O
picture	O
emerges	O
.	O
	
Most	O
approaches	O
to	O
automatic	O
image	B-Task
generation	I-Task
,	O
however	O
,	O
aim	O
to	O
generate	O
entire	O
scenes	O
at	O
once	O
.	O
	
In	O
the	O
context	O
of	O
generative	B-Method
neural	I-Method
networks	I-Method
,	O
this	O
typically	O
means	O
that	O
all	O
the	O
pixels	O
are	O
conditioned	O
on	O
a	O
single	O
latent	O
distribution	O
.	O
	
As	O
well	O
as	O
precluding	O
the	O
possibility	O
of	O
iterative	B-Task
self	I-Task
-	I-Task
correction	I-Task
,	O
the	O
“	O
one	B-Method
shot	I-Method
”	I-Method
approach	I-Method
is	O
fundamentally	O
difficult	O
to	O
scale	O
to	O
large	O
images	O
.	O
	
The	O
Deep	B-Method
Recurrent	I-Method
Attentive	I-Method
Writer	I-Method
(	O
DRAW	B-Method
)	O
architecture	O
represents	O
a	O
shift	O
towards	O
a	O
more	O
natural	O
form	O
of	O
image	B-Task
construction	I-Task
,	O
in	O
which	O
parts	O
of	O
a	O
scene	O
are	O
created	O
independently	O
from	O
others	O
,	O
and	O
approximate	O
sketches	O
are	O
successively	O
refined	O
.	O
	
The	O
core	O
of	O
the	O
DRAW	B-Method
architecture	O
is	O
a	O
pair	O
of	O
recurrent	B-Method
neural	I-Method
networks	I-Method
:	O
an	O
encoder	B-Method
network	I-Method
that	O
compresses	O
the	O
real	O
images	O
presented	O
during	O
training	O
,	O
and	O
a	O
decoder	B-Method
that	O
reconstitutes	O
images	O
after	O
receiving	O
codes	O
.	O
	
The	O
combined	O
system	O
is	O
trained	O
end	O
-	O
to	O
-	O
end	O
with	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
,	O
where	O
the	O
loss	O
function	O
is	O
a	O
variational	O
upper	O
bound	O
on	O
the	O
log	O
-	O
likelihood	O
of	O
the	O
data	O
.	O
	
It	O
therefore	O
belongs	O
to	O
the	O
family	O
of	O
variational	B-Method
auto	I-Method
-	I-Method
encoders	I-Method
,	O
a	O
recently	O
emerged	O
hybrid	B-Method
of	I-Method
deep	I-Method
learning	I-Method
and	O
variational	B-Method
inference	I-Method
that	O
has	O
led	O
to	O
significant	O
advances	O
in	O
generative	B-Task
modelling	I-Task
.	O
	
Where	O
DRAW	B-Method
differs	O
from	O
its	O
siblings	O
is	O
that	O
,	O
rather	O
than	O
generating	O
images	O
in	O
a	O
single	O
pass	O
,	O
it	O
iteratively	O
constructs	O
scenes	O
through	O
an	O
accumulation	O
of	O
modifications	O
emitted	O
by	O
the	O
decoder	B-Method
,	O
each	O
of	O
which	O
is	O
observed	O
by	O
the	O
encoder	B-Method
.	O
	
An	O
obvious	O
correlate	O
of	O
generating	O
images	O
step	O
by	O
step	O
is	O
the	O
ability	O
to	O
selectively	O
attend	O
to	O
parts	O
of	O
the	O
scene	O
while	O
ignoring	O
others	O
.	O
	
A	O
wealth	O
of	O
results	O
in	O
the	O
past	O
few	O
years	O
suggest	O
that	O
visual	O
structure	O
can	O
be	O
better	O
captured	O
by	O
a	O
sequence	O
of	O
partial	O
glimpses	O
,	O
or	O
foveations	O
,	O
than	O
by	O
a	O
single	O
sweep	O
through	O
the	O
entire	O
image	O
.	O
	
The	O
main	O
challenge	O
faced	O
by	O
sequential	B-Method
attention	I-Method
models	I-Method
is	O
learning	O
where	O
to	O
look	O
,	O
which	O
can	O
be	O
addressed	O
with	O
reinforcement	B-Method
learning	I-Method
techniques	I-Method
such	O
as	O
policy	B-Method
gradients	I-Method
.	O
	
The	O
attention	B-Method
model	I-Method
in	O
DRAW	B-Method
,	O
however	O
,	O
is	O
fully	O
differentiable	O
,	O
making	O
it	O
possible	O
to	O
train	O
with	O
standard	O
backpropagation	B-Method
.	O
	
In	O
this	O
sense	O
it	O
resembles	O
the	O
selective	O
read	O
and	O
write	O
operations	O
developed	O
for	O
the	O
Neural	B-Method
Turing	I-Method
Machine	I-Method
.	O
	
The	O
following	O
section	O
defines	O
the	O
DRAW	B-Method
architecture	O
,	O
along	O
with	O
the	O
loss	B-Method
function	I-Method
used	O
for	O
training	B-Task
and	O
the	O
procedure	O
for	O
image	B-Task
generation	I-Task
.	O
	
Section	O
[	O
reference	O
]	O
presents	O
the	O
selective	B-Method
attention	I-Method
model	I-Method
and	O
shows	O
how	O
it	O
is	O
applied	O
to	O
reading	B-Task
and	I-Task
modifying	I-Task
images	I-Task
.	O
	
Section	O
[	O
reference	O
]	O
provides	O
experimental	O
results	O
on	O
the	O
MNIST	B-Material
,	O
Street	B-Material
View	I-Material
House	I-Material
Numbers	I-Material
and	O
CIFAR	B-Material
-	I-Material
10	I-Material
datasets	I-Material
,	O
with	O
examples	O
of	O
generated	O
images	O
;	O
and	O
concluding	O
remarks	O
are	O
given	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Lastly	O
,	O
we	O
would	O
like	O
to	O
direct	O
the	O
reader	O
to	O
the	O
video	O
accompanying	O
this	O
paper	O
(	O
)	O
which	O
contains	O
examples	O
of	O
DRAW	B-Method
networks	O
reading	O
and	O
generating	O
images	O
.	O
	
section	O
:	O
The	O
DRAW	B-Method
Network	O
	
The	O
basic	O
structure	O
of	O
a	O
DRAW	B-Method
network	O
is	O
similar	O
to	O
that	O
of	O
other	O
variational	B-Method
auto	I-Method
-	I-Method
encoders	I-Method
:	O
an	O
encoder	B-Method
network	I-Method
determines	O
a	O
distribution	B-Method
over	I-Method
latent	I-Method
codes	I-Method
that	O
capture	O
salient	O
information	O
about	O
the	O
input	O
data	O
;	O
a	O
decoder	B-Method
network	I-Method
receives	O
samples	O
from	O
the	O
code	B-Method
distribuion	I-Method
and	O
uses	O
them	O
to	O
condition	O
its	O
own	O
distribution	O
over	O
images	O
.	O
	
However	O
there	O
are	O
three	O
key	O
differences	O
.	O
	
Firstly	O
,	O
both	O
the	O
encoder	B-Method
and	I-Method
decoder	I-Method
are	O
recurrent	B-Method
networks	I-Method
in	O
DRAW	B-Method
,	O
so	O
that	O
a	O
sequence	O
of	O
code	O
samples	O
is	O
exchanged	O
between	O
them	O
;	O
moreover	O
the	O
encoder	O
is	O
privy	O
to	O
the	O
decoder	O
	
’s	O
previous	O
outputs	O
,	O
allowing	O
it	O
to	O
tailor	O
the	O
codes	O
it	O
sends	O
according	O
to	O
the	O
decoder	O
’s	O
behaviour	O
so	O
far	O
.	O
	
Secondly	O
,	O
the	O
decoder	O
’s	O
outputs	O
are	O
successively	O
added	O
to	O
the	O
distribution	O
that	O
will	O
ultimately	O
generate	O
the	O
data	O
,	O
as	O
opposed	O
to	O
emitting	O
this	O
distribution	O
in	O
a	O
single	O
step	O
.	O
	
And	O
thirdly	O
,	O
a	O
dynamically	B-Method
updated	I-Method
attention	I-Method
mechanism	I-Method
is	O
used	O
to	O
restrict	O
both	O
the	O
input	O
region	O
observed	O
by	O
the	O
encoder	O
,	O
and	O
	
the	O
output	O
region	O
modified	O
by	O
the	O
decoder	B-Method
.	O
	
In	O
simple	O
terms	O
,	O
the	O
network	O
decides	O
at	O
each	O
time	O
-	O
step	O
“	O
where	O
to	O
read	O
”	O
and	O
“	O
where	O
to	O
write	O
”	O
as	O
well	O
as	O
“	O
what	O
to	O
write	O
”	O
.	O
	
The	O
architecture	O
is	O
sketched	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
alongside	O
a	O
feedforward	B-Method
variational	I-Method
auto	I-Method
-	I-Method
encoder	I-Method
.	O
	
subsection	O
:	O
Network	B-Method
Architecture	I-Method
	
Let	O
be	O
the	O
function	O
enacted	O
by	O
the	O
encoder	B-Method
network	I-Method
at	O
a	O
single	O
time	O
-	O
step	O
.	O
	
The	O
output	O
of	O
at	O
time	O
is	O
the	O
encoder	O
hidden	O
vector	O
.	O
	
Similarly	O
the	O
output	O
of	O
the	O
decoder	B-Method
at	O
is	O
the	O
hidden	O
vector	O
.	O
	
In	O
general	O
the	O
encoder	B-Method
and	I-Method
decoder	I-Method
may	O
be	O
implemented	O
by	O
any	O
recurrent	B-Method
neural	I-Method
network	I-Method
.	O
	
In	O
our	O
experiments	O
we	O
use	O
the	O
Long	B-Method
Short	I-Method
-	I-Method
Term	I-Method
Memory	I-Method
architecture	I-Method
(	O
LSTM	B-Method
;	I-Method
)	O
for	O
both	O
,	O
in	O
the	O
extended	O
form	O
with	O
forget	O
gates	O
.	O
	
We	O
favour	O
LSTM	B-Method
due	O
to	O
its	O
proven	O
track	O
record	O
for	O
handling	O
long	B-Task
-	I-Task
range	I-Task
dependencies	I-Task
in	O
real	O
sequential	O
data	O
.	O
	
Throughout	O
the	O
paper	O
,	O
we	O
use	O
the	O
notation	O
to	O
denote	O
a	O
linear	O
weight	O
matrix	O
with	O
bias	O
from	O
the	O
vector	O
to	O
the	O
vector	O
.	O
	
At	O
each	O
time	O
-	O
step	O
,	O
the	O
encoder	B-Method
receives	O
input	O
from	O
both	O
the	O
image	O
and	O
from	O
the	O
previous	O
decoder	O
hidden	O
vector	O
.	O
	
The	O
precise	O
form	O
of	O
the	O
encoder	O
input	O
depends	O
on	O
a	O
operation	O
,	O
which	O
will	O
be	O
defined	O
in	O
the	O
next	O
section	O
.	O
	
The	O
output	O
of	O
the	O
encoder	B-Method
is	O
used	O
to	O
parameterise	O
a	O
distribution	O
over	O
the	O
latent	O
vector	O
.	O
	
In	O
our	O
experiments	O
the	O
latent	O
distribution	O
is	O
a	O
diagonal	B-Method
Gaussian	I-Method
:	O
Bernoulli	B-Method
distributions	I-Method
are	O
more	O
common	O
than	O
Gaussians	B-Method
for	O
latent	O
variables	O
in	O
auto	B-Method
-	I-Method
encoders	I-Method
;	O
however	O
a	O
great	O
advantage	O
of	O
Gaussian	B-Method
latents	I-Method
is	O
that	O
the	O
gradient	O
of	O
a	O
function	O
of	O
the	O
samples	O
with	O
respect	O
to	O
the	O
distribution	O
parameters	O
can	O
be	O
easily	O
obtained	O
using	O
the	O
so	O
-	O
called	O
reparameterization	B-Method
trick	I-Method
.	O
	
This	O
makes	O
it	O
straightforward	O
to	O
back	O
-	O
propagate	O
unbiased	O
,	O
low	O
variance	O
stochastic	O
gradients	O
of	O
the	O
loss	O
function	O
through	O
the	O
latent	O
distribution	O
.	O
	
At	O
each	O
time	O
-	O
step	O
a	O
sample	O
drawn	O
from	O
the	O
latent	O
distribution	O
is	O
passed	O
as	O
input	O
to	O
the	O
decoder	B-Method
.	O
	
The	O
output	O
of	O
the	O
decoder	O
is	O
added	O
(	O
via	O
a	O
operation	O
,	O
defined	O
in	O
the	O
sequel	O
)	O
to	O
a	O
cumulative	O
canvas	O
matrix	O
,	O
which	O
is	O
ultimately	O
used	O
to	O
reconstruct	O
the	O
image	O
.	O
	
The	O
total	O
number	O
of	O
time	O
-	O
steps	O
consumed	O
by	O
the	O
network	O
before	O
performing	O
the	O
reconstruction	B-Task
is	O
a	O
free	O
parameter	O
that	O
must	O
be	O
specified	O
in	O
advance	O
.	O
	
For	O
each	O
image	O
presented	O
to	O
the	O
network	O
,	O
are	O
initialised	O
to	O
learned	O
biases	O
,	O
and	O
the	O
DRAW	B-Method
network	O
iteratively	O
computes	O
the	O
following	O
equations	O
for	O
:	O
where	O
is	O
the	O
error	O
image	O
,	O
is	O
the	O
concatenation	O
of	O
vectors	O
and	O
into	O
a	O
single	O
vector	O
,	O
and	O
denotes	O
the	O
logistic	B-Method
sigmoid	I-Method
function	I-Method
:	O
.	O
	
Note	O
that	O
,	O
and	O
hence	O
,	O
depends	O
on	O
both	O
and	O
the	O
history	O
of	O
previous	O
latent	O
samples	O
.	O
	
We	O
will	O
sometimes	O
make	O
this	O
dependency	O
explicit	O
by	O
writing	O
,	O
as	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
can	O
also	O
be	O
passed	O
as	O
input	O
to	O
the	O
operation	O
;	O
however	O
we	O
did	O
not	O
find	O
that	O
this	O
helped	O
performance	O
and	O
therefore	O
omitted	O
it	O
.	O
	
subsection	O
:	O
Loss	B-Method
Function	I-Method
	
The	O
final	O
canvas	O
matrix	O
is	O
used	O
to	O
parameterise	O
a	O
model	O
of	O
the	O
input	O
data	O
.	O
	
If	O
the	O
input	O
is	O
binary	O
,	O
the	O
natural	O
choice	O
for	O
is	O
a	O
Bernoulli	B-Method
distribution	I-Method
with	O
means	O
given	O
by	O
.	O
	
The	O
reconstruction	B-Metric
loss	I-Metric
is	O
defined	O
as	O
the	O
negative	O
log	O
probability	O
of	O
under	O
:	O
	
The	O
latent	O
loss	O
for	O
a	O
sequence	O
of	O
latent	O
distributions	O
is	O
defined	O
as	O
the	O
summed	O
Kullback	O
-	O
Leibler	O
divergence	O
of	O
some	O
latent	O
prior	O
from	O
:	O
Note	O
that	O
this	O
loss	O
depends	O
upon	O
the	O
latent	O
samples	O
drawn	O
from	O
,	O
which	O
depend	O
in	O
turn	O
on	O
the	O
input	O
.	O
	
If	O
the	O
latent	B-Method
distribution	I-Method
is	O
a	O
diagonal	B-Method
Gaussian	I-Method
with	O
,	O
as	O
defined	O
in	O
Eqs	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
,	O
a	O
simple	O
choice	O
for	O
is	O
a	O
standard	B-Method
Gaussian	I-Method
with	O
mean	O
zero	O
and	O
standard	O
deviation	O
one	O
,	O
in	O
which	O
case	O
Eq	O
.	O
	
[	O
reference	O
]	O
becomes	O
The	O
total	O
loss	O
for	O
the	O
network	O
is	O
the	O
expectation	O
of	O
the	O
sum	O
of	O
the	O
reconstruction	O
and	O
latent	O
losses	O
:	O
which	O
we	O
optimise	O
using	O
a	O
single	O
sample	O
of	O
for	O
each	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
step	I-Method
.	O
	
can	O
be	O
interpreted	O
as	O
the	O
number	O
of	O
nats	O
required	O
to	O
transmit	O
the	O
latent	O
sample	O
sequence	O
to	O
the	O
decoder	O
from	O
the	O
prior	O
,	O
and	O
	
(	O
if	O
is	O
discrete	O
)	O
is	O
the	O
number	O
of	O
nats	O
required	O
for	O
the	O
decoder	B-Method
to	O
reconstruct	O
given	O
.	O
	
The	O
total	B-Metric
loss	I-Metric
is	O
therefore	O
equivalent	O
to	O
the	O
expected	O
compression	O
of	O
the	O
data	O
by	O
the	O
decoder	O
and	O
prior	O
.	O
	
subsection	O
:	O
Stochastic	B-Task
Data	I-Task
Generation	I-Task
	
An	O
image	O
can	O
be	O
generated	O
by	O
a	O
DRAW	B-Method
network	O
by	O
iteratively	O
picking	O
latent	O
samples	O
from	O
the	O
prior	O
,	O
then	O
running	O
the	O
decoder	B-Method
to	O
update	O
the	O
canvas	O
matrix	O
.	O
	
After	O
repetitions	O
of	O
this	O
process	O
the	O
generated	O
image	O
is	O
a	O
sample	O
from	O
:	O
Note	O
that	O
the	O
encoder	B-Method
is	O
not	O
involved	O
in	O
image	B-Task
generation	I-Task
.	O
	
section	O
:	O
Read	B-Task
and	I-Task
Write	I-Task
Operations	I-Task
	
The	O
DRAW	B-Method
network	O
described	O
in	O
the	O
previous	O
section	O
is	O
not	O
complete	O
until	O
the	O
and	O
operations	O
in	O
Eqs	O
.	O
	
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
have	O
been	O
defined	O
.	O
	
This	O
section	O
describes	O
two	O
ways	O
to	O
do	O
so	O
,	O
one	O
with	O
selective	O
attention	O
and	O
one	O
without	O
.	O
	
subsection	O
:	O
Reading	O
and	O
Writing	O
Without	O
Attention	O
	
In	O
the	O
simplest	O
instantiation	O
of	O
DRAW	B-Method
the	O
entire	O
input	O
image	O
is	O
passed	O
to	O
the	O
encoder	O
at	O
every	O
time	O
-	O
step	O
,	O
and	O
the	O
decoder	O
modifies	O
the	O
entire	O
canvas	O
matrix	O
at	O
every	O
time	O
-	O
step	O
.	O
	
In	O
this	O
case	O
the	O
and	O
operations	O
reduce	O
to	O
However	O
this	O
approach	O
does	O
not	O
allow	O
the	O
encoder	B-Method
to	O
focus	O
on	O
only	O
part	O
of	O
the	O
input	O
when	O
creating	O
the	O
latent	O
distribution	O
;	O
nor	O
does	O
it	O
allow	O
the	O
decoder	B-Method
to	O
modify	O
only	O
a	O
part	O
of	O
the	O
canvas	O
vector	O
.	O
	
In	O
other	O
words	O
it	O
does	O
not	O
provide	O
the	O
network	O
with	O
an	O
explicit	O
selective	B-Method
attention	I-Method
mechanism	I-Method
,	O
which	O
we	O
believe	O
to	O
be	O
crucial	O
to	O
large	O
scale	O
image	B-Task
generation	I-Task
.	O
	
We	O
refer	O
to	O
the	O
above	O
configuration	O
as	O
“	O
DRAW	B-Method
without	O
attention	O
”	O
.	O
	
subsection	O
:	O
Selective	B-Method
Attention	I-Method
Model	I-Method
	
To	O
endow	O
the	O
network	O
with	O
selective	O
attention	O
without	O
sacrificing	O
the	O
benefits	O
of	O
gradient	B-Method
descent	I-Method
training	I-Method
,	O
we	O
take	O
inspiration	O
from	O
the	O
differentiable	B-Method
attention	I-Method
mechanisms	I-Method
recently	O
used	O
in	O
handwriting	B-Task
synthesis	I-Task
and	O
Neural	B-Task
Turing	I-Task
Machines	I-Task
.	O
	
Unlike	O
the	O
aforementioned	O
works	O
,	O
we	O
consider	O
an	O
explicitly	O
two	O
-	O
dimensional	B-Method
form	I-Method
of	I-Method
attention	I-Method
,	O
where	O
an	O
array	B-Method
of	I-Method
2D	I-Method
Gaussian	I-Method
filters	I-Method
is	O
applied	O
to	O
the	O
image	O
,	O
yielding	O
an	O
image	O
‘	O
patch	O
’	O
of	O
smoothly	O
varying	O
location	O
and	O
zoom	O
.	O
	
This	O
configuration	O
,	O
which	O
we	O
refer	O
to	O
simply	O
as	O
“	O
DRAW	B-Method
”	O
,	O
somewhat	O
resembles	O
the	O
affine	O
transformations	O
used	O
in	O
computer	B-Method
graphics	I-Method
-	I-Method
based	I-Method
autoencoders	I-Method
.	O
	
As	O
illustrated	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
the	O
grid	B-Method
of	I-Method
Gaussian	I-Method
filters	I-Method
is	O
positioned	O
on	O
the	O
image	O
by	O
specifying	O
the	O
co	O
-	O
ordinates	O
of	O
the	O
grid	O
centre	O
and	O
the	O
stride	O
distance	O
between	O
adjacent	O
filters	O
.	O
	
The	O
stride	O
controls	O
the	O
‘	O
zoom	O
’	O
of	O
the	O
patch	O
;	O
that	O
is	O
,	O
the	O
larger	O
the	O
stride	O
,	O
the	O
larger	O
an	O
area	O
of	O
the	O
original	O
image	O
will	O
be	O
visible	O
in	O
the	O
attention	O
patch	O
,	O
but	O
the	O
lower	O
the	O
effective	O
resolution	O
of	O
the	O
patch	O
will	O
be	O
.	O
	
The	O
grid	O
centre	O
and	O
stride	O
(	O
both	O
of	O
which	O
are	O
real	O
-	O
valued	O
)	O
determine	O
the	O
mean	O
location	O
of	O
the	O
filter	O
at	O
row	O
,	O
column	O
in	O
the	O
patch	O
as	O
follows	O
:	O
Two	O
more	O
parameters	O
are	O
required	O
to	O
fully	O
specify	O
the	O
attention	B-Method
model	I-Method
:	O
the	O
isotropic	O
variance	O
of	O
the	O
Gaussian	B-Method
filters	I-Method
,	O
and	O
a	O
scalar	O
intensity	O
that	O
multiplies	O
the	O
filter	O
response	O
.	O
	
Given	O
an	O
input	O
image	O
,	O
all	O
five	O
attention	O
parameters	O
are	O
dynamically	O
determined	O
at	O
each	O
time	O
step	O
via	O
a	O
linear	B-Method
transformation	I-Method
of	O
the	O
decoder	O
output	O
:	O
where	O
the	O
variance	O
,	O
stride	O
and	O
intensity	O
are	O
emitted	O
in	O
the	O
log	O
-	O
scale	O
to	O
ensure	O
positivity	O
.	O
	
The	O
scaling	O
of	O
,	O
and	O
is	O
chosen	O
to	O
ensure	O
that	O
the	O
initial	O
patch	O
(	O
with	O
a	O
randomly	B-Method
initialised	I-Method
network	I-Method
)	O
roughly	O
covers	O
the	O
whole	O
input	O
image	O
.	O
	
Given	O
the	O
attention	O
parameters	O
emitted	O
by	O
the	O
decoder	B-Method
,	O
the	O
horizontal	B-Method
and	I-Method
vertical	I-Method
filterbank	I-Method
matrices	I-Method
and	O
(	O
dimensions	O
and	O
respectively	O
)	O
are	O
defined	O
as	O
follows	O
:	O
where	O
is	O
a	O
point	O
in	O
the	O
attention	O
patch	O
,	O
is	O
a	O
point	O
in	O
the	O
input	O
image	O
,	O
and	O
are	O
normalisation	O
constants	O
that	O
ensure	O
that	O
and	O
.	O
	
subsection	O
:	O
Reading	B-Task
and	I-Task
Writing	I-Task
With	O
Attention	O
	
Given	O
,	O
and	O
intensity	O
determined	O
by	O
,	O
along	O
with	O
an	O
input	O
image	O
and	O
error	O
image	O
,	O
the	O
read	B-Method
operation	I-Method
returns	O
the	O
concatenation	O
of	O
two	O
patches	O
from	O
the	O
image	O
and	O
error	O
image	O
	
:	O
Note	O
that	O
the	O
same	O
filterbanks	B-Method
are	O
used	O
for	O
both	O
the	O
image	O
and	O
error	O
image	O
.	O
	
For	O
the	O
write	B-Task
operation	I-Task
,	O
a	O
distinct	O
set	O
of	O
attention	O
parameters	O
,	O
and	O
are	O
extracted	O
from	O
,	O
the	O
order	O
of	O
transposition	O
is	O
reversed	O
,	O
and	O
the	O
intensity	O
is	O
inverted	O
:	O
where	O
is	O
the	O
writing	O
patch	O
emitted	O
by	O
.	O
	
For	O
colour	O
images	O
each	O
point	O
in	O
the	O
input	O
and	O
error	O
image	O
(	O
and	O
hence	O
in	O
the	O
reading	O
and	O
writing	O
patches	O
)	O
is	O
an	O
RGB	O
triple	O
.	O
	
In	O
this	O
case	O
the	O
same	O
reading	O
and	O
writing	O
filters	O
are	O
used	O
for	O
all	O
three	O
channels	O
.	O
	
section	O
:	O
Experimental	O
Results	O
	
We	O
assess	O
the	O
ability	O
of	O
DRAW	B-Method
to	O
generate	O
realistic	B-Task
-	I-Task
looking	I-Task
images	I-Task
by	O
training	O
on	O
three	O
datasets	O
of	O
progressively	O
increasing	O
visual	O
complexity	O
:	O
MNIST	B-Material
,	O
Street	B-Material
View	I-Material
House	I-Material
Numbers	I-Material
(	O
SVHN	B-Material
)	O
and	O
CIFAR	B-Material
-	I-Material
10	I-Material
.	O
	
The	O
images	O
generated	O
by	O
the	O
network	O
are	O
always	O
novel	O
(	O
not	O
simply	O
copies	O
of	O
training	O
examples	O
)	O
,	O
and	O
are	O
virtually	O
indistinguishable	O
from	O
real	O
data	O
for	O
MNIST	B-Material
and	O
SVHN	B-Material
;	O
the	O
generated	O
CIFAR	B-Material
images	I-Material
are	O
somewhat	O
blurry	O
,	O
but	O
still	O
contain	O
recognisable	O
structure	O
from	O
natural	O
scenes	O
.	O
	
The	O
binarized	B-Material
MNIST	I-Material
results	O
substantially	O
improve	O
on	O
the	O
state	O
of	O
the	O
art	O
.	O
	
As	O
a	O
preliminary	O
exercise	O
,	O
we	O
also	O
evaluate	O
the	O
2D	B-Method
attention	I-Method
module	I-Method
of	O
the	O
DRAW	B-Method
network	O
on	O
cluttered	O
MNIST	B-Material
classification	O
.	O
	
For	O
all	O
experiments	O
,	O
the	O
model	O
of	O
the	O
input	O
data	O
was	O
a	O
Bernoulli	B-Method
distribution	I-Method
with	O
means	O
given	O
by	O
.	O
	
For	O
the	O
MNIST	B-Material
experiments	O
,	O
the	O
reconstruction	B-Metric
loss	I-Metric
from	O
Eq	O
[	O
reference	O
]	O
was	O
the	O
usual	O
binary	B-Metric
cross	I-Metric
-	I-Metric
entropy	I-Metric
term	I-Metric
.	O
	
For	O
the	O
SVHN	B-Material
and	O
CIFAR	B-Material
-	I-Material
10	I-Material
experiments	I-Material
,	O
the	O
red	O
,	O
green	O
and	O
blue	O
pixel	O
intensities	O
were	O
represented	O
as	O
numbers	O
between	O
0	O
and	O
1	O
,	O
which	O
were	O
then	O
interpreted	O
as	O
independent	O
colour	O
emission	O
probabilities	O
.	O
	
The	O
reconstruction	O
loss	O
was	O
therefore	O
the	O
cross	O
-	O
entropy	O
between	O
the	O
pixel	O
intensities	O
and	O
the	O
model	O
probabilities	O
.	O
	
Although	O
this	O
approach	O
worked	O
well	O
in	O
practice	O
,	O
it	O
means	O
that	O
the	O
training	B-Metric
loss	I-Metric
did	O
not	O
correspond	O
to	O
the	O
true	O
compression	B-Metric
cost	I-Metric
of	O
RGB	B-Material
images	I-Material
.	O
	
Network	O
hyper	O
-	O
parameters	O
for	O
all	O
the	O
experiments	O
are	O
presented	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
The	O
Adam	B-Method
optimisation	I-Method
algorithm	I-Method
was	O
used	O
throughout	O
.	O
	
Examples	O
of	O
generation	O
sequences	O
for	O
MNIST	B-Material
and	O
SVHN	B-Material
are	O
provided	O
in	O
the	O
accompanying	O
video	O
(	O
)	O
.	O
	
subsection	O
:	O
Cluttered	O
MNIST	B-Material
Classification	O
	
To	O
test	O
the	O
classification	B-Task
efficacy	O
of	O
the	O
DRAW	B-Method
attention	O
mechanism	O
(	O
as	O
opposed	O
to	O
its	O
ability	O
to	O
aid	O
in	O
image	B-Task
generation	I-Task
)	O
,	O
we	O
evaluate	O
its	O
performance	O
on	O
the	O
cluttered	O
translated	O
MNIST	B-Material
task	O
.	O
	
Each	O
image	O
in	O
cluttered	O
MNIST	B-Material
contains	O
many	O
digit	O
-	O
like	O
fragments	O
of	O
visual	O
clutter	O
that	O
the	O
network	O
must	O
distinguish	O
from	O
the	O
true	O
digit	O
to	O
be	O
classified	O
.	O
	
As	O
illustrated	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
having	O
an	O
iterative	B-Method
attention	I-Method
model	I-Method
allows	O
the	O
network	O
to	O
progressively	O
zoom	O
in	O
on	O
the	O
relevant	O
region	O
of	O
the	O
image	O
,	O
and	O
ignore	O
the	O
clutter	O
outside	O
it	O
.	O
	
Our	O
model	O
consists	O
of	O
an	O
LSTM	B-Method
recurrent	I-Method
network	I-Method
that	O
receives	O
a	O
‘	O
glimpse	O
’	O
from	O
the	O
input	O
image	O
at	O
each	O
time	O
-	O
step	O
,	O
using	O
the	O
selective	O
read	O
operation	O
defined	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
After	O
a	O
fixed	O
number	O
of	O
glimpses	O
the	O
network	O
uses	O
a	O
softmax	B-Method
layer	I-Method
to	O
classify	O
the	O
MNIST	B-Material
digit	O
.	O
	
The	O
network	O
is	O
similar	O
to	O
the	O
recently	O
introduced	O
Recurrent	B-Method
Attention	I-Method
Model	I-Method
(	O
RAM	B-Method
)	I-Method
,	O
except	O
that	O
our	O
attention	B-Method
method	I-Method
is	O
differentiable	O
;	O
we	O
therefore	O
refer	O
to	O
it	O
as	O
“	O
Differentiable	B-Method
RAM	I-Method
”	O
.	O
	
The	O
results	O
in	O
Table	O
[	O
reference	O
]	O
demonstrate	O
a	O
significant	O
improvement	O
in	O
test	B-Metric
error	I-Metric
over	O
the	O
original	O
RAM	B-Method
network	I-Method
.	O
	
Moreover	O
our	O
model	O
had	O
only	O
a	O
single	O
attention	O
patch	O
at	O
each	O
time	O
-	O
step	O
,	O
whereas	O
RAM	O
used	O
four	O
,	O
at	O
different	O
zooms	O
.	O
	
subsection	O
:	O
MNIST	B-Material
Generation	O
	
We	O
trained	O
the	O
full	O
DRAW	B-Method
network	O
as	O
a	O
generative	B-Method
model	I-Method
on	O
the	O
binarized	O
MNIST	B-Material
dataset	O
.	O
	
This	O
dataset	O
has	O
been	O
widely	O
studied	O
in	O
the	O
literature	O
,	O
allowing	O
us	O
to	O
compare	O
the	O
numerical	O
performance	O
(	O
measured	O
in	O
average	B-Metric
nats	I-Metric
per	O
image	O
on	O
the	O
test	O
set	O
)	O
of	O
DRAW	B-Method
with	O
existing	O
methods	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
that	O
DRAW	B-Method
without	O
selective	O
attention	O
performs	O
comparably	O
to	O
other	O
recent	O
generative	B-Method
models	I-Method
such	O
as	O
DARN	B-Method
,	O
NADE	B-Method
and	O
DBMs	B-Method
,	O
and	O
that	O
DRAW	B-Method
with	O
attention	B-Method
considerably	O
improves	O
on	O
the	O
state	O
of	O
the	O
art	O
.	O
	
Once	O
the	O
DRAW	B-Method
network	O
was	O
trained	O
,	O
we	O
generated	O
MNIST	B-Material
digits	O
following	O
the	O
method	O
in	O
Section	O
[	O
reference	O
]	O
,	O
examples	O
of	O
which	O
are	O
presented	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
illustrates	O
the	O
image	B-Task
generation	I-Task
sequence	O
for	O
a	O
DRAW	B-Method
network	O
without	O
selective	O
attention	O
(	O
see	O
Section	O
[	O
reference	O
]	O
)	O
.	O
	
It	O
is	O
interesting	O
to	O
compare	O
this	O
with	O
the	O
generation	O
sequence	O
for	O
DRAW	B-Method
with	O
attention	O
,	O
as	O
depicted	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Whereas	O
without	O
attention	O
it	O
progressively	O
sharpens	O
a	O
blurred	O
image	O
in	O
a	O
global	O
way	O
,	O
with	O
attention	O
it	O
constructs	O
the	O
digit	O
by	O
tracing	O
the	O
lines	O
—	O
much	O
like	O
a	O
person	O
with	O
a	O
pen	O
.	O
	
subsection	O
:	O
MNIST	B-Material
Generation	O
with	O
Two	O
Digits	O
	
The	O
main	O
motivation	O
for	O
using	O
an	O
attention	B-Method
-	I-Method
based	I-Method
generative	I-Method
model	I-Method
is	O
that	O
large	O
images	O
can	O
be	O
built	O
up	O
iteratively	O
,	O
by	O
adding	O
to	O
a	O
small	O
part	O
of	O
the	O
image	O
at	O
a	O
time	O
.	O
	
To	O
test	O
this	O
capability	O
in	O
a	O
controlled	O
fashion	O
,	O
we	O
trained	O
DRAW	B-Method
to	O
generate	O
images	O
with	O
two	O
MNIST	B-Material
images	O
chosen	O
at	O
random	O
and	O
placed	O
at	O
random	O
locations	O
in	O
a	O
black	O
background	O
.	O
	
In	O
cases	O
where	O
the	O
two	O
digits	O
overlap	O
,	O
the	O
pixel	O
intensities	O
were	O
added	O
together	O
at	O
each	O
point	O
and	O
clipped	O
to	O
be	O
no	O
greater	O
than	O
one	O
.	O
	
Examples	O
of	O
generated	O
data	O
are	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
The	O
network	O
typically	O
generates	O
one	O
digit	O
and	O
then	O
the	O
other	O
,	O
suggesting	O
an	O
ability	O
to	O
recreate	O
composite	O
scenes	O
from	O
simple	O
pieces	O
.	O
	
subsection	O
:	O
Street	B-Task
View	I-Task
House	I-Task
Number	I-Task
Generation	I-Task
	
MNIST	B-Material
digits	O
are	O
very	O
simplistic	O
in	O
terms	O
of	O
visual	O
structure	O
,	O
and	O
we	O
were	O
keen	O
to	O
see	O
how	O
well	O
DRAW	B-Method
performed	O
on	O
natural	O
images	O
.	O
	
Our	O
first	O
natural	O
image	B-Task
generation	I-Task
experiment	O
used	O
the	O
multi	O
-	O
digit	O
Street	B-Material
View	I-Material
House	I-Material
Numbers	I-Material
dataset	O
.	O
	
We	O
used	O
the	O
same	O
preprocessing	O
as	O
,	O
yielding	O
a	O
house	O
number	O
image	O
for	O
each	O
training	O
example	O
.	O
	
The	O
network	O
was	O
then	O
trained	O
using	O
patches	O
extracted	O
at	O
random	O
locations	O
from	O
the	O
preprocessed	O
images	O
.	O
	
The	O
SVHN	B-Material
training	O
set	O
contains	O
231	O
,	O
053	O
images	O
,	O
and	O
the	O
validation	O
set	O
contains	O
4	O
,	O
701	O
images	O
.	O
	
The	O
house	O
number	O
images	O
generated	O
by	O
the	O
network	O
are	O
highly	O
realistic	O
,	O
as	O
shown	O
in	O
Figs	O
.	O
	
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
reveals	O
that	O
,	O
despite	O
the	O
long	O
training	O
time	O
,	O
the	O
DRAW	B-Method
network	O
underfit	O
the	O
SVHN	B-Material
training	O
data	O
.	O
	
s	O
	
subsection	O
:	O
Generating	B-Task
CIFAR	I-Task
Images	I-Task
	
The	O
most	O
challenging	O
dataset	O
we	O
applied	O
DRAW	B-Method
to	O
was	O
the	O
CIFAR	B-Material
-	I-Material
10	I-Material
collection	O
of	O
natural	O
images	O
.	O
	
CIFAR	B-Material
-	I-Material
10	I-Material
is	O
very	O
diverse	O
,	O
and	O
with	O
only	O
50	O
,	O
000	O
training	O
examples	O
it	O
is	O
very	O
difficult	O
to	O
generate	O
realistic	O
-	O
looking	O
objects	O
without	O
overfitting	O
(	O
in	O
other	O
words	O
,	O
without	O
copying	O
from	O
the	O
training	O
set	O
)	O
.	O
	
Nonetheless	O
the	O
images	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
demonstrate	O
that	O
DRAW	B-Method
is	O
able	O
to	O
capture	O
much	O
of	O
the	O
shape	O
,	O
colour	O
and	O
composition	O
of	O
real	O
photographs	O
.	O
	
section	O
:	O
Conclusion	O
	
This	O
paper	O
introduced	O
the	O
Deep	B-Method
Recurrent	I-Method
Attentive	I-Method
Writer	I-Method
(	O
DRAW	B-Method
)	O
neural	O
network	O
architecture	O
,	O
and	O
demonstrated	O
its	O
ability	O
to	O
generate	O
highly	O
realistic	O
natural	O
images	O
such	O
as	O
photographs	O
of	O
house	O
numbers	O
,	O
as	O
well	O
as	O
improving	O
on	O
the	O
best	O
known	O
results	O
for	O
binarized	O
MNIST	B-Material
generation	O
.	O
	
We	O
also	O
established	O
that	O
the	O
two	O
-	O
dimensional	B-Method
differentiable	I-Method
attention	I-Method
mechanism	I-Method
embedded	O
in	O
DRAW	B-Method
is	O
beneficial	O
not	O
only	O
to	O
image	B-Task
generation	I-Task
,	O
but	O
also	O
to	O
image	B-Task
classification	I-Task
.	O
	
section	O
:	O
Acknowledgments	O
	
Of	O
the	O
many	O
who	O
assisted	O
in	O
creating	O
this	O
paper	O
,	O
we	O
are	O
especially	O
thankful	O
to	O
Koray	O
Kavukcuoglu	O
,	O
Volodymyr	O
Mnih	O
,	O
Jimmy	O
Ba	O
,	O
Yaroslav	O
Bulatov	O
,	O
Greg	O
Wayne	O
,	O
Andrei	O
Rusu	O
and	O
Shakir	O
Mohamed	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
U	B-Method
-	I-Method
Net	I-Method
:	O
Machine	B-Task
Reading	I-Task
Comprehension	I-Task
with	O
Unanswerable	O
Questions	O
	
Machine	B-Task
reading	I-Task
comprehension	I-Task
with	O
unanswerable	O
questions	O
is	O
a	O
new	O
challenging	O
task	O
for	O
natural	B-Task
language	I-Task
processing	I-Task
.	O
	
A	O
key	O
subtask	O
is	O
to	O
reliably	O
predict	O
whether	O
the	O
question	B-Method
is	O
unanswerable	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
unified	B-Method
model	I-Method
,	O
called	O
U	B-Method
-	I-Method
Net	I-Method
,	O
with	O
three	O
important	O
components	O
:	O
answer	O
pointer	O
,	O
no	O
-	O
answer	O
pointer	O
,	O
and	O
answer	B-Method
verifier	I-Method
.	O
	
We	O
introduce	O
a	O
universal	O
node	O
and	O
thus	O
process	O
the	O
question	B-Method
and	O
its	O
context	O
passage	O
as	O
a	O
single	O
contiguous	O
sequence	O
of	O
tokens	O
.	O
	
The	O
universal	O
node	O
encodes	O
the	O
fused	O
information	O
from	O
both	O
the	O
question	B-Method
and	O
passage	O
,	O
and	O
plays	O
an	O
important	O
role	O
to	O
predict	O
whether	O
the	O
question	B-Method
is	O
answerable	O
and	O
also	O
greatly	O
improves	O
the	O
conciseness	B-Metric
of	O
the	O
U	B-Method
-	I-Method
Net	I-Method
.	O
	
Different	O
from	O
the	O
state	O
-	O
of	O
-	O
art	O
pipeline	B-Method
models	I-Method
,	O
U	B-Method
-	I-Method
Net	I-Method
can	O
be	O
learned	O
in	O
an	O
end	O
-	O
to	O
-	O
end	O
fashion	O
.	O
	
The	O
experimental	O
results	O
on	O
the	O
SQuAD	B-Material
2.0	I-Material
dataset	I-Material
show	O
that	O
U	B-Method
-	I-Method
Net	I-Method
can	O
effectively	O
predict	O
the	O
unanswerability	O
of	O
questions	O
and	O
achieves	O
an	O
F1	B-Metric
score	I-Metric
of	O
71.7	O
on	O
SQuAD	B-Material
2.0	I-Material
.	O
	
section	O
:	O
Introduction	O
	
Machine	B-Task
reading	I-Task
comprehension	I-Task
(	O
MRC	B-Task
)	O
is	O
a	O
challenging	O
task	O
in	O
natural	B-Task
language	I-Task
processing	I-Task
,	O
which	O
requires	O
that	O
machine	O
can	O
read	O
,	O
understand	O
,	O
and	O
answer	O
questions	O
about	O
a	O
text	O
.	O
	
Benefiting	O
from	O
the	O
rapid	O
development	O
of	O
deep	B-Method
learning	I-Method
techniques	I-Method
and	O
large	O
-	O
scale	O
benchmarks	O
,	O
the	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
neural	I-Method
methods	I-Method
have	O
achieved	O
promising	O
results	O
on	O
MRC	B-Task
task	I-Task
.	O
	
The	O
best	O
systems	O
have	O
even	O
surpassed	O
human	O
performance	O
on	O
the	O
Stanford	B-Material
Question	I-Material
Answering	I-Material
Dataset	I-Material
(	O
SQuAD	B-Material
)	I-Material
,	O
one	O
of	O
the	O
most	O
widely	O
used	O
MRC	B-Material
benchmarks	I-Material
.	O
	
However	O
,	O
one	O
of	O
the	O
limitations	O
of	O
the	O
SQuAD	B-Material
task	O
is	O
that	O
each	O
question	B-Method
has	O
a	O
correct	O
answer	O
in	O
the	O
context	O
passage	O
,	O
therefore	O
most	O
models	O
just	O
need	O
to	O
select	O
the	O
most	O
relevant	O
text	O
span	O
as	O
the	O
answer	O
,	O
without	O
necessarily	O
checking	O
whether	O
it	O
is	O
indeed	O
the	O
answer	O
to	O
the	O
question	B-Method
.	O
	
To	O
remedy	O
the	O
deficiency	O
of	O
SQuAD	B-Material
,	O
squad2.0	B-Material
squad2.0	I-Material
developed	O
SQuAD	B-Material
2.0	I-Material
that	O
combines	O
SQuAD	B-Material
with	O
new	O
unanswerable	O
questions	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
two	O
examples	O
of	O
unanswerable	O
questions	O
.	O
	
The	O
new	O
dataset	O
requires	O
the	O
MRC	B-Method
systems	I-Method
to	O
know	O
what	O
they	O
do	O
n’t	O
know	O
.	O
	
Paragraph	O
:	O
	
“	O
	
…	O
Other	O
legislation	O
followed	O
,	O
including	O
the	O
Migratory	O
Bird	O
Conservation	O
Act	O
of	O
1929	O
,	O
a	O
1937	O
treaty	O
prohibiting	O
the	O
hunting	O
of	O
right	O
and	O
gray	O
whales	O
,	O
and	O
the	O
Bald	O
Eagle	O
Protection	O
Act	O
of	O
1940	O
.	O
	
These	O
later	O
laws	O
had	O
a	O
low	O
cost	O
to	O
societyâthe	O
species	O
were	O
relatively	O
rareâand	O
little	O
opposition	O
was	O
raised.â	O
To	O
do	O
well	O
on	O
MRC	B-Task
with	O
unanswerable	O
questions	O
,	O
the	O
model	O
needs	O
to	O
comprehend	O
the	O
question	B-Method
,	O
reason	O
among	O
the	O
passage	O
,	O
judge	O
the	O
unanswerability	O
and	O
then	O
identify	O
the	O
answer	O
span	O
.	O
	
Since	O
extensive	O
work	O
has	O
been	O
done	O
on	O
how	O
to	O
correctly	O
predict	O
the	O
answer	O
span	O
when	O
the	O
question	B-Method
is	O
answerable	O
(	O
e.g.	O
,	O
SQuAD	B-Material
1.1	O
)	O
,	O
the	O
main	O
challenge	O
of	O
this	O
task	O
lies	O
in	O
how	O
to	O
reliably	O
determine	O
whether	O
a	O
question	B-Method
is	O
not	O
answerable	O
from	O
the	O
passage	O
.	O
	
There	O
are	O
two	O
kinds	O
of	O
approaches	O
to	O
model	O
the	O
answerability	O
of	O
a	O
question	B-Method
.	O
	
One	O
approach	O
is	O
to	O
directly	O
extend	O
previous	O
MRC	B-Method
models	I-Method
by	O
introducing	O
a	O
no	O
-	O
answer	O
score	O
to	O
the	O
score	O
vector	O
of	O
the	O
answer	O
span	O
.	O
	
But	O
this	O
kind	O
of	O
approaches	O
is	O
relatively	O
simple	O
and	O
can	O
not	O
effectively	O
model	O
the	O
answerability	O
of	O
a	O
question	B-Method
.	O
	
Another	O
approach	O
introduces	O
an	O
answer	B-Method
verifier	I-Method
to	O
determine	O
whether	O
the	O
question	B-Method
is	O
unanswerable	O
.	O
	
However	O
,	O
this	O
kind	O
of	O
approaches	O
usually	O
has	O
a	O
pipeline	B-Method
structure	I-Method
.	O
	
The	O
answer	O
pointer	O
and	O
answer	B-Method
verifier	I-Method
have	O
their	O
respective	O
models	O
,	O
which	O
are	O
trained	O
separately	O
.	O
	
Intuitively	O
,	O
it	O
is	O
unnecessary	O
since	O
the	O
underlying	O
comprehension	O
and	O
reasoning	O
of	O
language	O
for	O
these	O
components	O
is	O
the	O
same	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
decompose	O
the	O
problem	O
of	O
MRC	B-Task
with	I-Task
unanswerable	I-Task
questions	I-Task
into	O
three	O
sub	B-Task
-	I-Task
tasks	I-Task
:	O
answer	O
pointer	O
,	O
no	O
-	O
answer	O
pointer	O
,	O
and	O
answer	B-Method
verifier	I-Method
.	O
	
Since	O
these	O
three	O
sub	O
-	O
tasks	O
are	O
highly	O
related	O
,	O
we	O
regard	O
the	O
MRC	B-Task
with	O
unanswerable	O
questions	O
as	O
a	O
multi	B-Task
-	I-Task
task	I-Task
learning	I-Task
problem	I-Task
by	O
sharing	O
some	O
meta	O
-	O
knowledge	O
.	O
	
We	O
propose	O
the	O
U	B-Method
-	I-Method
Net	I-Method
to	O
incorporate	O
these	O
three	O
sub	O
-	O
tasks	O
into	O
a	O
unified	O
model	O
:	O
1	O
)	O
an	O
answer	B-Method
pointer	I-Method
to	O
predict	O
a	O
candidate	O
answer	O
span	O
for	O
a	O
question	B-Method
;	O
2	O
)	O
a	O
no	O
-	O
answer	O
pointer	O
to	O
avoid	O
selecting	O
any	O
text	O
span	O
when	O
a	O
question	B-Method
has	O
no	O
answer	O
;	O
and	O
3	O
)	O
an	O
answer	B-Method
verifier	I-Method
to	O
determine	O
the	O
probability	O
of	O
the	O
“	O
unanswerability	O
”	O
of	O
a	O
question	B-Method
with	O
candidate	O
answer	O
information	O
.	O
	
Additionally	O
,	O
we	O
also	O
introduce	O
a	O
universal	O
node	O
and	O
process	O
the	O
question	B-Method
and	O
its	O
context	O
passage	O
as	O
a	O
single	O
contiguous	O
sequence	O
of	O
tokens	O
,	O
which	O
greatly	O
improves	O
the	O
conciseness	O
of	O
U	B-Method
-	I-Method
Net	I-Method
.	O
	
The	O
universal	O
node	O
acts	O
on	O
both	O
question	B-Method
and	O
passage	O
to	O
learn	O
whether	O
the	O
question	B-Method
is	O
answerable	O
.	O
	
Different	O
from	O
the	O
previous	O
pipeline	B-Method
models	I-Method
,	O
U	B-Method
-	I-Method
Net	I-Method
can	O
be	O
learned	O
in	O
an	O
end	O
-	O
to	O
-	O
end	O
fashion	O
.	O
	
Our	O
experimental	O
results	O
on	O
the	O
SQuAD	B-Material
2.0	I-Material
dataset	I-Material
show	O
that	O
U	B-Method
-	I-Method
Net	I-Method
effectively	O
predicts	O
the	O
unanswerability	B-Task
of	I-Task
questions	I-Task
and	O
achieves	O
an	O
F1	B-Metric
score	I-Metric
of	O
72.6	O
.	O
	
The	O
contributions	O
of	O
this	O
paper	O
can	O
be	O
summarized	O
as	O
follows	O
.	O
	
We	O
decompose	O
the	O
problem	O
of	O
MRC	B-Task
with	O
unanswerable	O
questions	O
into	O
three	O
sub	O
-	O
tasks	O
and	O
combine	O
them	O
into	O
a	O
unified	O
model	O
,	O
which	O
uses	O
the	O
shared	B-Method
encoding	I-Method
and	I-Method
interaction	I-Method
layers	I-Method
.	O
	
Thus	O
,	O
the	O
three	O
-	O
tasks	O
can	O
be	O
trained	O
simultaneously	O
in	O
an	O
end	O
-	O
to	O
-	O
end	O
fashion	O
.	O
	
We	O
introduce	O
a	O
universal	O
node	O
to	O
encode	O
the	O
common	O
information	O
of	O
the	O
question	B-Method
and	O
passage	O
.	O
	
Thus	O
,	O
we	O
can	O
use	O
a	O
unified	B-Method
representation	I-Method
to	O
model	O
the	O
question	B-Method
and	O
passage	O
,	O
which	O
makes	O
our	O
model	O
more	O
condensed	O
.	O
	
U	B-Method
-	I-Method
Net	I-Method
is	O
very	O
easy	O
to	O
implement	O
yet	O
effective	O
.	O
	
section	O
:	O
Proposed	O
Model	O
	
Formally	O
,	O
we	O
can	O
represent	O
the	O
MRC	B-Task
problem	I-Task
as	O
:	O
given	O
a	O
set	O
of	O
tuples	O
,	O
where	O
is	O
the	O
question	B-Method
with	O
words	O
,	O
is	O
the	O
context	O
passage	O
with	O
words	O
,	O
and	O
is	O
the	O
answer	O
with	O
and	O
indicating	O
the	O
start	O
and	O
end	O
points	O
,	O
the	O
task	O
is	O
to	O
estimate	O
the	O
conditional	O
probability	O
.	O
	
The	O
architecture	O
of	O
our	O
proposed	O
U	B-Method
-	I-Method
Net	I-Method
is	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
U	B-Method
-	I-Method
Net	I-Method
consists	O
of	O
four	O
major	O
blocks	O
:	O
Unified	B-Method
Encoding	I-Method
,	O
Multi	B-Task
-	I-Task
Level	I-Task
Attention	I-Task
,	O
Final	B-Task
Fusion	I-Task
,	O
and	O
Prediction	B-Task
.	O
	
As	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
we	O
first	O
combine	O
the	O
embedded	B-Method
representation	I-Method
of	O
the	O
question	B-Method
and	O
passage	O
with	O
a	O
universal	O
node	O
and	O
pass	O
them	O
through	O
a	O
BiLSTM	B-Method
to	O
encode	O
the	O
whole	O
text	O
.	O
	
We	O
then	O
use	O
the	O
encoded	B-Method
representation	I-Method
to	O
do	O
the	O
information	B-Task
interaction	I-Task
.	O
	
Then	O
we	O
use	O
the	O
encoded	B-Method
and	I-Method
interacted	I-Method
representation	I-Method
to	O
fuse	O
the	O
full	B-Method
representation	I-Method
and	O
feed	O
them	O
into	O
the	O
final	O
prediction	B-Method
layers	I-Method
to	O
do	O
the	O
multi	B-Task
-	I-Task
task	I-Task
training	I-Task
.	O
	
We	O
will	O
describe	O
our	O
model	O
in	O
details	O
in	O
the	O
following	O
.	O
	
subsection	O
:	O
(	O
A	O
)	O
Unified	B-Method
Encoding	I-Method
	
paragraph	O
:	O
Embedding	B-Task
	
Following	O
the	O
successful	O
models	O
on	O
SQuAD	B-Material
1.1	I-Material
,	O
we	O
first	O
embed	O
both	O
the	O
question	B-Method
and	O
the	O
passage	O
with	O
the	O
following	O
features	O
.	O
	
Glove	B-Method
embedding	I-Method
and	O
Elmo	B-Method
embedding	I-Method
are	O
used	O
as	O
basic	B-Method
embeddings	I-Method
.	O
	
Besides	O
,	O
we	O
use	O
POS	O
embedding	O
,	O
NER	B-Method
embedding	I-Method
,	O
and	O
a	O
feature	B-Method
embedding	I-Method
that	O
includes	O
the	O
exact	O
match	O
,	O
lower	O
-	O
case	O
match	O
,	O
lemma	O
match	O
,	O
and	O
a	O
TF	B-Method
-	I-Method
IDF	I-Method
feature	I-Method
.	O
	
Now	O
we	O
get	O
the	O
question	B-Method
representation	I-Method
and	O
the	O
passage	B-Method
representation	I-Method
,	O
where	O
each	O
word	O
is	O
represented	O
as	O
a	O
-	B-Method
dim	I-Method
embedding	I-Method
by	O
combining	O
the	O
features	B-Method
/	I-Method
embedding	I-Method
described	O
above	O
.	O
	
paragraph	O
:	O
Universal	B-Method
Node	I-Method
	
We	O
create	O
a	O
universal	O
node	O
,	O
which	O
is	O
a	O
key	O
factor	O
in	O
our	O
model	O
and	O
has	O
several	O
roles	O
in	O
predicting	O
the	O
unanswerability	B-Task
of	I-Task
question	I-Task
.	O
	
We	O
expect	O
this	O
node	O
to	O
learn	O
universal	O
information	O
from	O
both	O
passage	O
and	O
question	B-Method
.	O
	
This	O
universal	O
node	O
is	O
added	O
and	O
connects	O
the	O
passage	O
and	O
question	B-Method
at	O
the	O
phase	O
of	O
embedding	B-Task
,	O
and	O
then	O
goes	O
along	O
with	O
the	O
whole	O
representation	O
,	O
so	O
it	O
is	O
a	O
key	O
factor	O
in	O
information	B-Task
representation	I-Task
.	O
	
Since	O
the	O
universal	O
node	O
is	O
in	O
between	O
and	O
later	O
shared	O
between	O
passage	O
and	O
question	B-Method
,	O
it	O
has	O
an	O
abstract	O
semantic	O
meaning	O
rather	O
than	O
just	O
a	O
word	B-Method
embedding	I-Method
.	O
	
Also	O
,	O
the	O
universal	O
node	O
is	O
later	O
shared	O
in	O
the	O
attention	B-Method
interaction	I-Method
mechanism	I-Method
and	O
used	O
in	O
both	O
the	O
answer	B-Task
boundary	I-Task
detection	I-Task
and	I-Task
classification	I-Task
tasks	I-Task
,	O
so	O
this	O
node	O
carries	O
massive	O
information	O
and	O
has	O
several	O
important	O
roles	O
in	O
our	O
whole	O
model	B-Method
construction	I-Method
.	O
	
The	O
universal	O
node	O
is	O
first	O
represented	O
by	O
a	O
-	O
dim	O
randomly	O
-	O
initialized	O
vector	O
.	O
	
We	O
concatenated	O
question	B-Method
representation	I-Method
,	O
universal	B-Method
node	I-Method
representation	I-Method
,	O
passage	B-Method
representation	I-Method
together	O
as	O
:	O
is	O
a	O
joint	O
representation	O
of	O
question	B-Method
and	O
passage	O
.	O
	
paragraph	O
:	O
Word	B-Method
-	I-Method
level	I-Method
Fusion	I-Method
	
Then	O
we	O
first	O
use	O
two	O
-	O
layer	O
bidirectional	B-Method
LSTM	I-Method
(	O
BiLSTM	B-Method
)	O
to	O
fuse	O
the	O
joint	O
representation	O
of	O
question	B-Method
,	O
universal	O
node	O
,	O
and	O
passage	O
.	O
	
where	O
is	O
the	O
hidden	O
states	O
of	O
the	O
first	O
BiLSTM	B-Method
,	O
representing	O
the	O
low	O
-	O
level	O
semantic	O
information	O
,	O
and	O
is	O
the	O
hidden	O
states	O
of	O
the	O
second	O
BiLSTM	B-Method
,	O
representing	O
the	O
high	O
-	O
level	O
semantic	O
information	O
.	O
	
Finally	O
,	O
we	O
concatenate	O
and	O
together	O
and	O
pass	O
them	O
through	O
the	O
third	O
BiLSTM	B-Method
and	O
obtain	O
a	O
full	B-Method
representation	I-Method
.	O
	
Thus	O
,	O
represents	O
the	O
deep	O
fusion	O
information	O
of	O
the	O
question	B-Method
and	O
passage	O
on	O
word	O
-	O
level	O
.	O
	
When	O
a	O
BiLSTM	B-Method
is	O
applied	O
to	O
encode	O
representations	O
,	O
it	O
learns	O
the	O
semantic	O
information	O
bi	O
-	O
directionally	O
.	O
	
Since	O
the	O
universal	O
node	O
is	O
between	O
the	O
question	B-Method
and	O
passage	O
,	O
its	O
hidden	O
states	O
can	O
learn	O
both	O
question	B-Method
and	O
passage	O
information	O
.	O
	
When	O
the	O
passage	O
-	O
question	B-Method
pair	O
was	O
encoded	O
as	O
a	O
unified	B-Method
representation	I-Method
and	O
information	O
flows	O
via	O
the	O
BiLSTM	B-Method
,	O
the	O
universal	O
node	O
has	O
an	O
important	O
role	O
in	O
information	B-Task
representation	I-Task
.	O
	
subsection	O
:	O
(	O
B	O
)	O
Multi	B-Task
-	I-Task
Level	I-Task
Attention	I-Task
	
To	O
fully	O
fuse	O
the	O
semantic	O
representation	O
of	O
the	O
question	B-Method
and	O
passage	O
,	O
we	O
use	O
the	O
attention	B-Method
mechanism	I-Method
to	O
capture	O
their	O
interactions	O
on	O
different	O
levels	O
.	O
	
We	O
expected	O
that	O
we	O
could	O
simply	O
use	O
self	B-Method
-	I-Method
attention	I-Method
on	O
the	O
encoded	B-Method
representation	I-Method
for	O
interaction	O
between	O
question	B-Method
and	O
passage	O
,	O
which	O
contains	O
both	O
bi	O
-	O
attention	O
and	O
self	O
-	O
attention	O
of	O
the	O
question	B-Method
and	O
passage	O
.	O
	
But	O
we	O
found	O
that	O
it	O
performed	O
slightly	O
worse	O
than	O
the	O
traditional	O
bi	B-Method
-	I-Method
directional	I-Method
attention	I-Method
with	O
the	O
universal	O
node	O
included	O
.	O
	
Therefore	O
,	O
we	O
use	O
a	O
bi	O
-	O
directional	O
attention	O
between	O
the	O
question	B-Method
and	O
passage	O
.	O
	
We	O
first	O
divide	O
into	O
two	O
representations	O
:	O
attached	O
passage	O
and	O
attached	O
question	B-Method
,	O
and	O
let	O
the	O
universal	B-Method
node	I-Method
representation	I-Method
attached	O
to	O
both	O
the	O
passage	O
and	O
question	B-Method
,	O
i.e.	O
,	O
Note	O
is	O
shared	O
by	O
and	O
.	O
	
Here	O
the	O
universal	O
node	O
works	O
as	O
a	O
special	O
information	O
carrier	O
,	O
and	O
both	O
passage	O
and	O
question	B-Method
can	O
focus	O
attention	O
information	O
on	O
this	O
node	O
so	O
that	O
the	O
connection	O
between	O
them	O
is	O
closer	O
than	O
a	O
traditional	O
bi	B-Method
-	I-Method
attention	I-Method
interaction	I-Method
.	O
	
Since	O
both	O
and	O
are	O
concatenated	O
by	O
three	O
-	O
level	B-Method
representations	I-Method
,	O
we	O
followed	O
previous	O
work	O
FusionNet	B-Method
to	O
construct	O
their	O
iterations	O
on	O
three	O
levels	O
.	O
	
Take	O
the	O
first	O
level	O
as	O
an	O
example	O
.	O
	
We	O
first	O
compute	O
the	O
affine	O
matrix	O
of	O
and	O
by	O
where	O
;	O
and	O
are	O
learnable	O
parameters	O
.	O
	
Next	O
,	O
a	O
bi	B-Method
-	I-Method
directional	I-Method
attention	I-Method
is	O
used	O
to	O
compute	O
the	O
interacted	B-Method
representation	I-Method
and	O
.	O
where	O
is	O
column	O
-	O
wise	O
normalized	O
function	O
.	O
	
We	O
use	O
the	O
same	O
attention	B-Method
layer	I-Method
to	O
model	O
the	O
interactions	O
for	O
all	O
the	O
three	O
levels	O
,	O
and	O
get	O
the	O
final	O
fused	B-Method
representation	I-Method
for	O
the	O
question	B-Method
and	O
passage	O
respectively	O
.	O
	
Note	O
that	O
while	O
dealing	O
with	O
the	O
attention	O
output	O
of	O
the	O
universal	O
node	O
,	O
we	O
added	O
two	O
outputs	O
from	O
passage	O
-	O
to	O
-	O
question	B-Method
attention	O
and	O
question	B-Method
-	O
to	O
-	O
passage	O
attention	O
.	O
	
So	O
after	O
the	O
interaction	O
,	O
the	O
fused	B-Method
representation	I-Method
still	O
have	O
the	O
same	O
length	O
as	O
the	O
encoded	B-Method
representation	I-Method
,	O
and	O
.	O
	
subsection	O
:	O
(	O
C	O
)	O
Final	O
Fusion	O
	
After	O
the	O
three	O
-	O
level	O
attentive	O
interaction	O
,	O
we	O
generate	O
the	O
final	O
fused	O
information	O
for	O
the	O
question	B-Method
and	O
passage	O
.	O
	
We	O
concatenate	O
all	O
the	O
history	O
information	O
:	O
we	O
first	O
concatenate	O
the	O
encoded	B-Method
representation	I-Method
and	O
the	O
representation	O
after	O
attention	O
(	O
again	O
,	O
we	O
use	O
,	O
and	O
to	O
represent	O
3	O
different	O
levels	O
of	O
representation	O
for	O
the	O
two	O
previous	O
steps	O
respectively	O
)	O
.	O
	
Following	O
the	O
success	O
of	O
DenseNet	B-Method
,	O
we	O
concatenate	O
the	O
input	O
and	O
output	O
of	O
each	O
layer	O
as	O
the	O
input	O
of	O
the	O
next	O
layer	O
.	O
	
First	O
,	O
we	O
pass	O
the	O
concatenated	B-Method
representation	I-Method
through	O
a	O
BiLSTM	B-Method
to	O
get	O
.	O
	
where	O
the	O
representation	O
is	O
a	O
fusion	O
of	O
information	O
from	O
different	O
levels	O
.	O
	
Then	O
we	O
concatenate	O
the	O
original	O
embedded	B-Method
representation	I-Method
and	O
for	O
better	O
representation	O
of	O
the	O
fused	O
information	O
of	O
passage	O
,	O
universal	O
node	O
,	O
and	O
question	B-Method
.	O
	
Finally	O
,	O
we	O
use	O
a	O
self	B-Method
-	I-Method
attention	I-Method
layer	I-Method
to	O
get	O
the	O
attention	O
information	O
within	O
the	O
fused	O
information	O
.	O
	
The	O
self	B-Method
-	I-Method
attention	I-Method
layer	I-Method
is	O
constructed	O
the	O
same	O
way	O
as	O
:	O
where	O
is	O
the	O
representation	O
after	O
self	O
-	O
attention	O
of	O
the	O
fused	O
information	O
.	O
	
Next	O
we	O
concatenated	O
representation	O
and	O
and	O
pass	O
them	O
through	O
another	O
BiLSTM	B-Method
layer	O
:	O
Now	O
is	O
the	O
final	O
fused	B-Method
representation	I-Method
of	O
all	O
the	O
information	O
.	O
	
At	O
this	O
point	O
,	O
we	O
divide	O
into	O
two	O
parts	O
:	O
,	O
,	O
representing	O
the	O
fused	O
information	O
of	O
the	O
question	B-Method
and	O
passage	O
respectively	O
.	O
	
Note	O
for	O
the	O
final	O
representation	O
,	O
we	O
attach	O
the	O
universal	O
node	O
only	O
in	O
the	O
passage	B-Method
representation	I-Method
.	O
	
This	O
is	O
because	O
we	O
need	O
the	O
universal	O
node	O
as	O
a	O
focus	O
for	O
the	O
pointer	O
when	O
the	O
question	B-Method
is	O
unanswerable	O
.	O
	
These	O
will	O
be	O
fed	O
into	O
the	O
next	O
decoder	B-Method
prediction	I-Method
layer	I-Method
.	O
	
subsection	O
:	O
(	O
D	O
)	O
Prediction	B-Task
	
The	O
prediction	B-Method
layer	I-Method
receives	O
fused	O
information	O
of	O
passage	O
and	O
question	B-Method
,	O
and	O
tackles	O
three	O
prediction	B-Task
tasks	I-Task
:	O
(	O
1	O
)	O
answer	O
pointer	O
,	O
(	O
2	O
)	O
no	O
-	O
answer	O
pointer	O
and	O
	
(	O
3	O
)	O
answer	B-Method
verifier	I-Method
.	O
	
First	O
,	O
we	O
use	O
a	O
function	O
shown	O
below	O
to	O
summarize	O
the	O
question	B-Method
information	O
into	O
a	O
fixed	B-Method
-	I-Method
dim	I-Method
representation	I-Method
.	O
	
where	O
is	O
a	O
learnable	O
weight	O
matrix	O
and	O
represents	O
the	O
word	O
in	O
the	O
question	B-Method
representation	I-Method
.	O
	
Then	O
we	O
feed	O
into	O
the	O
answer	O
pointer	O
to	O
find	O
boundaries	O
of	O
answers	O
,	O
and	O
the	O
classification	B-Method
layer	I-Method
to	O
distinguish	O
whether	O
the	O
question	B-Method
is	O
answerable	O
.	O
	
paragraph	O
:	O
(	O
i	O
)	O
Answer	O
Pointer	O
	
We	O
use	O
this	O
answer	O
pointer	O
to	O
detect	O
the	O
answer	O
boundaries	O
from	O
the	O
passage	O
when	O
the	O
question	B-Method
is	O
answerable	O
(	O
i.e.	O
,	O
the	O
answer	O
is	O
a	O
span	O
in	O
the	O
passage	O
)	O
.	O
	
This	O
layer	O
is	O
a	O
classic	O
pointer	B-Method
net	I-Method
structure	I-Method
.	O
	
We	O
use	O
two	O
trainable	B-Method
matrices	I-Method
and	O
to	O
estimate	O
the	O
probability	O
of	O
the	O
answer	O
start	O
and	O
end	O
boundaries	O
of	O
the	O
word	O
in	O
the	O
passage	O
,	O
and	O
.	O
	
Note	O
here	O
when	O
the	O
question	B-Method
is	O
answerable	O
,	O
we	O
do	O
not	O
consider	O
the	O
universal	O
node	O
in	O
answer	B-Task
boundary	I-Task
detection	I-Task
,	O
so	O
we	O
have	O
(	O
is	O
the	O
universal	O
node	O
in	O
the	O
passage	B-Method
representation	I-Method
)	O
.	O
	
The	O
loss	B-Method
function	I-Method
for	O
the	O
answerable	O
question	B-Method
pairs	O
is	O
:	O
where	O
and	O
are	O
the	O
ground	O
-	O
truth	O
of	O
the	O
start	O
and	O
end	O
boundary	O
of	O
the	O
answer	O
.	O
	
paragraph	O
:	O
(	O
ii	O
)	O
No	O
-	O
Answer	O
Pointer	O
	
Then	O
we	O
use	O
the	O
same	O
pointer	O
for	O
questions	O
that	O
are	O
not	O
answerable	O
.	O
	
Here	O
the	O
loss	O
is	O
:	O
and	O
correspond	O
to	O
the	O
position	O
of	O
the	O
universal	O
node	O
,	O
which	O
is	O
at	O
the	O
front	O
of	O
the	O
passage	B-Method
representation	I-Method
.	O
	
For	O
this	O
scenario	O
,	O
the	O
loss	O
is	O
calculated	O
for	O
the	O
universal	O
node	O
.	O
	
Additionally	O
,	O
since	O
there	O
exits	O
a	O
plausible	O
answer	O
for	O
each	O
unanswerable	O
question	B-Method
in	O
SQuAD	B-Material
2.0	I-Material
,	O
we	O
introduce	O
an	O
auxiliary	O
plausible	O
answer	O
pointer	O
to	O
predict	O
the	O
boundaries	O
of	O
the	O
plausible	O
answers	O
.	O
	
The	O
plausible	O
answer	O
pointer	O
has	O
the	O
same	O
structure	O
as	O
the	O
answer	O
pointer	O
,	O
but	O
with	O
different	O
parameters	O
.	O
	
Thus	O
,	O
the	O
total	B-Metric
loss	I-Metric
function	I-Metric
is	O
:	O
where	O
and	O
are	O
the	O
output	O
of	O
the	O
plausible	O
answer	O
pointer	O
;	O
and	O
are	O
the	O
start	O
and	O
end	O
boundary	O
of	O
the	O
unanswerable	O
answer	O
.	O
	
The	O
no	O
-	O
answer	O
pointer	O
and	O
plausible	O
answer	O
pointer	O
are	O
removed	O
at	O
test	O
phase	O
.	O
	
paragraph	O
:	O
(	O
iii	O
)	O
Answer	O
Verifier	O
	
We	O
use	O
the	O
answer	B-Method
verifier	I-Method
to	O
distinguish	O
whether	O
the	O
question	B-Method
is	O
answerable	O
.	O
	
Answer	B-Method
verifier	I-Method
applies	O
a	O
weighted	B-Method
summary	I-Method
layer	I-Method
to	O
summarize	O
the	O
passage	O
information	O
into	O
a	O
fixed	B-Method
-	I-Method
dim	I-Method
representation	I-Method
(	O
as	O
shown	O
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
)	O
.	O
	
And	O
we	O
use	O
the	O
weight	O
matrix	O
obtained	O
from	O
the	O
answer	O
pointer	O
to	O
get	O
two	O
representations	O
of	O
the	O
passage	O
.	O
	
Then	O
we	O
use	O
the	O
universal	O
node	O
and	O
concatenate	O
it	O
with	O
the	O
summary	O
of	O
question	B-Method
and	O
passage	O
to	O
make	O
a	O
fixed	O
vector	O
This	O
fixed	O
includes	O
the	O
representation	O
representing	O
the	O
question	B-Method
information	O
,	O
and	O
and	O
representing	O
the	O
passage	O
information	O
.	O
	
Since	O
these	O
representations	O
are	O
highly	O
summarized	O
specially	O
for	O
classification	B-Task
,	O
we	O
believe	O
that	O
this	O
passage	O
-	O
question	B-Method
pair	O
contains	O
information	O
to	O
distinguish	O
whether	O
this	O
question	B-Method
is	O
answerable	O
.	O
	
In	O
addition	O
,	O
we	O
include	O
the	O
universal	O
node	O
as	O
a	O
supplement	O
.	O
	
Since	O
the	O
universal	O
node	O
is	O
pointed	O
at	O
when	O
the	O
question	B-Method
is	O
unanswerable	O
and	O
this	O
node	O
itself	O
already	O
contains	O
information	O
collected	O
from	O
both	O
the	O
passage	O
and	O
question	B-Method
during	O
encoding	O
and	O
information	B-Task
interaction	I-Task
,	O
we	O
believe	O
that	O
this	O
node	O
is	O
important	O
in	O
distinguishing	O
whether	O
the	O
question	B-Method
is	O
answerable	O
.	O
	
Finally	O
,	O
we	O
pass	O
this	O
fixed	O
vector	O
through	O
a	O
linear	B-Method
layer	I-Method
to	O
obtain	O
the	O
prediction	O
whether	O
the	O
question	B-Method
is	O
answerable	O
.	O
	
where	O
is	O
a	O
sigmoid	O
function	O
,	O
is	O
a	O
learnable	O
weight	O
matrix	O
.	O
	
Here	O
we	O
use	O
the	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
loss	I-Metric
in	O
training	B-Task
.	O
	
where	O
indicates	O
whether	O
the	O
question	B-Method
has	O
an	O
answer	O
in	O
the	O
passage	O
.	O
	
Compared	O
with	O
other	O
relatively	O
complex	O
structures	O
developped	O
for	O
this	O
MRC	B-Task
task	I-Task
,	O
our	O
U	B-Method
-	I-Method
Net	I-Method
model	O
passes	O
the	O
original	O
question	B-Method
and	O
passage	O
pair	O
through	O
embedding	O
and	O
encoding	O
,	O
which	O
then	O
interacts	O
with	O
each	O
other	O
,	O
yielding	O
fused	O
information	O
merged	O
from	O
all	O
the	O
levels	O
.	O
	
The	O
entire	O
architecture	O
is	O
very	O
easy	O
to	O
construct	O
.	O
	
After	O
we	O
have	O
the	O
fused	B-Method
representation	I-Method
of	O
the	O
question	B-Method
and	O
passage	O
,	O
we	O
pass	O
them	O
through	O
the	O
pointer	B-Method
layer	I-Method
and	O
a	O
fused	B-Method
information	I-Method
classification	I-Method
layer	I-Method
in	O
a	O
multi	B-Task
-	I-Task
task	I-Task
setup	I-Task
.	O
	
section	O
:	O
Training	O
	
We	O
jointly	O
train	O
the	O
three	O
tasks	O
by	O
combining	O
the	O
three	O
loss	B-Method
functions	I-Method
.	O
	
The	O
final	O
loss	B-Metric
function	I-Metric
is	O
:	O
where	O
indicates	O
whether	O
the	O
question	B-Method
has	O
an	O
answer	O
in	O
the	O
passage	O
,	O
,	O
and	O
are	O
the	O
three	O
loss	O
functions	O
of	O
the	O
answer	O
pointer	O
,	O
no	O
-	O
answer	O
pointer	O
,	O
and	O
answer	B-Method
verifier	I-Method
.	O
	
Although	O
the	O
three	O
tasks	O
could	O
have	O
different	O
weights	O
in	O
the	O
final	O
loss	B-Metric
function	I-Metric
and	O
be	O
further	O
fine	O
-	O
tuned	O
after	O
joint	B-Task
training	I-Task
,	O
here	O
we	O
just	O
consider	O
them	O
in	O
the	O
same	O
weight	O
and	O
do	O
not	O
fine	O
-	O
tune	O
them	O
individually	O
.	O
	
At	O
the	O
test	O
phase	O
,	O
we	O
first	O
use	O
the	O
answer	O
pointer	O
to	O
find	O
a	O
potential	O
answer	O
to	O
the	O
question	B-Method
,	O
while	O
the	O
verifier	O
layer	O
judges	O
whether	O
the	O
question	B-Method
is	O
answerable	O
.	O
	
If	O
the	O
classifier	B-Method
predicts	O
the	O
question	B-Method
is	O
unanswerable	O
,	O
we	O
consider	O
the	O
answer	O
extracted	O
by	O
the	O
answer	O
pointer	O
as	O
plausible	O
.	O
	
In	O
this	O
way	O
,	O
we	O
get	O
the	O
system	O
result	O
.	O
	
section	O
:	O
Experiment	O
	
subsection	O
:	O
Datasets	O
	
Recently	O
,	O
machine	B-Task
reading	I-Task
comprehension	I-Task
and	O
question	B-Method
answering	O
have	O
progressed	O
rapidly	O
,	O
owing	O
to	O
the	O
computation	B-Metric
ability	I-Metric
and	O
publicly	O
available	O
high	O
-	O
quality	O
datasets	O
such	O
as	O
SQuAD	B-Material
.	O
	
Now	O
new	O
research	O
efforts	O
have	O
been	O
devoted	O
to	O
the	O
newly	O
released	O
answer	B-Task
extraction	I-Task
test	I-Task
with	O
unanswerable	O
questions	O
,	O
SQuAD	B-Material
2.0	I-Material
.	O
	
It	O
is	O
constructed	O
by	O
combining	O
question	B-Method
-	O
answer	O
pairs	O
selected	O
from	O
SQuAD	B-Material
1.0	O
and	O
newly	O
crafted	O
unanswerable	O
questions	O
.	O
	
These	O
unanswerable	O
questions	O
are	O
created	O
by	O
workers	O
that	O
were	O
asked	O
to	O
pose	O
questions	O
that	O
can	O
not	O
be	O
answered	O
based	O
on	O
the	O
paragraph	O
alone	O
but	O
are	O
similar	O
to	O
the	O
answerable	O
questions	O
.	O
	
It	O
is	O
very	O
difficult	O
to	O
distinguish	O
these	O
questions	O
from	O
the	O
answerable	O
ones	O
.	O
	
We	O
evaluate	O
our	O
model	O
using	O
this	O
data	O
set	O
.	O
	
It	O
contains	O
over	O
100	O
,	O
000	O
+	O
questions	O
on	O
500	O
+	O
wikipedia	O
articles	O
.	O
	
subsection	O
:	O
Implementation	O
Details	O
	
We	O
use	O
Spacy	B-Method
to	O
process	O
each	O
question	B-Method
and	O
passage	O
to	O
obtain	O
tokens	O
,	O
POS	O
tags	O
,	O
NER	O
tags	O
and	O
lemmas	O
tags	O
of	O
each	O
text	O
.	O
	
We	O
use	O
12	O
dimensions	O
to	O
embed	O
POS	O
tags	O
,	O
8	O
for	O
NER	O
tags	O
.	O
	
We	O
use	O
3	O
binary	O
features	O
:	O
exact	O
match	O
,	O
lower	O
-	O
case	O
match	O
and	O
lemma	O
match	O
between	O
the	O
question	B-Method
and	O
passage	O
.	O
	
We	O
use	O
100	B-Method
-	I-Method
dim	I-Method
Glove	I-Method
pretrained	I-Method
word	I-Method
embeddings	I-Method
and	O
1024	B-Method
-	I-Method
dim	I-Method
Elmo	I-Method
embeddings	I-Method
.	O
	
All	O
the	O
LSTM	B-Method
blocks	I-Method
are	O
bi	O
-	O
directional	O
with	O
one	O
single	O
layer	O
.	O
	
We	O
set	O
the	O
hidden	O
layer	O
dimension	O
as	O
125	O
,	O
attention	O
layer	O
dimension	O
as	O
250	O
.	O
	
We	O
added	O
a	O
dropout	O
layer	O
over	O
all	O
the	O
modeling	B-Method
layers	I-Method
,	O
including	O
the	O
embedding	B-Method
layer	I-Method
,	O
at	O
a	O
dropout	B-Metric
rate	I-Metric
of	O
0.3	O
.	O
	
We	O
use	O
Adam	B-Method
optimizer	I-Method
with	O
a	O
learning	B-Metric
rate	I-Metric
of	I-Metric
0.002	I-Metric
.	O
	
During	O
training	O
,	O
we	O
omit	O
passage	O
with	O
over	O
400	O
words	O
and	O
question	B-Method
with	O
more	O
than	O
50	O
words	O
.	O
	
For	O
testing	O
,	O
when	O
the	O
passage	O
has	O
over	O
600	O
words	O
and	O
the	O
question	B-Method
is	O
over	O
100	O
words	O
,	O
we	O
simply	O
label	O
these	O
questions	O
as	O
unanswerable	O
.	O
	
subsection	O
:	O
Main	O
Results	O
	
Our	O
model	O
achieves	O
an	O
F1	B-Metric
score	I-Metric
of	O
74.0	O
and	O
an	O
EM	B-Metric
score	I-Metric
of	O
70.3	O
on	O
the	O
development	O
set	O
,	O
and	O
an	O
F1	B-Metric
score	I-Metric
of	O
72.6	O
and	O
an	O
EM	B-Metric
score	I-Metric
of	O
69.2	O
on	O
Test	O
set	O
,	O
as	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Our	O
model	O
outperforms	O
most	O
of	O
the	O
previous	O
approaches	O
.	O
	
Comparing	O
to	O
the	O
best	O
-	O
performing	O
systems	O
,	O
our	O
model	O
has	O
a	O
simple	O
architecture	O
and	O
is	O
an	O
end	O
-	O
to	O
-	O
end	B-Method
model	I-Method
.	O
	
In	O
fact	O
,	O
among	O
all	O
the	O
end	O
-	O
to	O
-	O
end	B-Method
models	I-Method
,	O
we	O
achieve	O
the	O
best	O
F1	B-Metric
scores	I-Metric
.	O
	
We	O
believe	O
that	O
the	O
performance	O
of	O
the	O
U	B-Method
-	I-Method
Net	I-Method
can	O
be	O
boosted	O
with	O
an	O
additional	O
post	B-Method
-	I-Method
processing	I-Method
step	I-Method
to	O
verify	O
answers	O
using	O
approaches	O
such	O
as	O
.	O
	
subsection	O
:	O
Ablation	B-Task
Study	I-Task
	
We	O
also	O
do	O
an	O
ablation	B-Task
study	I-Task
on	O
the	O
SQuAD	B-Material
2.0	O
development	O
set	O
to	O
further	O
test	O
the	O
effectiveness	O
of	O
different	O
components	O
in	O
our	O
model	O
.	O
	
In	O
Table	O
[	O
reference	O
]	O
,	O
we	O
show	O
four	O
different	O
configurations	O
.	O
	
First	O
,	O
we	O
remove	O
the	O
universal	O
node	O
.	O
	
We	O
let	O
the	O
negative	O
examples	O
focus	O
on	O
the	O
plausible	O
answer	O
spans	O
instead	O
of	O
focusing	O
on	O
the	O
universal	O
node	O
.	O
	
This	O
results	O
in	O
a	O
loss	O
of	O
2.6	O
%	O
F1	B-Metric
score	I-Metric
on	O
the	O
development	O
set	O
,	O
showing	O
that	O
the	O
universal	B-Method
node	I-Method
indeed	O
learns	O
information	O
about	O
whether	O
the	O
question	B-Method
is	O
answerable	O
.	O
	
We	O
also	O
tried	O
to	O
make	O
the	O
universal	O
node	O
only	O
attached	O
to	O
the	O
passage	B-Method
representation	I-Method
when	O
passing	O
the	O
attention	B-Method
layer	I-Method
.	O
	
Our	O
results	O
showed	O
that	O
when	O
node	O
is	O
shared	O
,	O
as	O
it	O
is	O
called	O
‘	O
universal	O
’	O
,	O
it	O
learns	O
information	O
interaction	O
between	O
the	O
question	B-Method
and	O
passage	O
,	O
and	O
when	O
it	O
is	O
not	O
shared	O
,	O
the	O
performance	O
slightly	O
degraded	O
.	O
	
As	O
for	O
the	O
approaches	O
to	O
encode	O
the	O
representations	O
,	O
we	O
pass	O
both	O
the	O
question	B-Method
and	O
passage	O
through	O
a	O
shared	O
BiLSTM	B-Method
.	O
	
To	O
test	O
the	O
effectiveness	O
of	O
this	O
,	O
we	O
ran	O
the	O
experiment	O
using	O
separate	O
BiLSTMs	B-Method
on	O
embedded	O
question	B-Method
and	O
passage	O
representations	O
.	O
	
Results	O
show	O
that	O
the	O
performance	O
dropped	O
slightly	O
,	O
suggesting	O
sharing	O
BiLSTM	B-Method
is	O
an	O
effective	O
method	O
to	O
improve	O
the	O
quality	B-Metric
of	O
the	O
encoder	O
.	O
	
After	O
removing	O
the	O
plausible	O
answer	O
pointer	O
,	O
the	O
performance	O
also	O
dropped	O
,	O
indicating	O
the	O
plausible	O
answers	O
are	O
useful	O
to	O
improve	O
the	O
model	O
even	O
though	O
they	O
are	O
incorrect	O
.	O
	
After	O
removing	O
the	O
answer	O
verifier	O
,	O
the	O
performance	O
dropped	O
greatly	O
,	O
indicating	O
it	O
is	O
vital	O
for	O
our	O
model	O
.	O
	
Lastly	O
,	O
we	O
run	O
a	O
test	O
using	O
a	O
more	O
concise	O
configuration	O
.	O
	
In	O
the	O
second	O
block	O
(	O
multi	O
-	O
level	O
attention	O
)	O
of	O
the	O
U	B-Method
-	I-Method
Net	I-Method
,	O
we	O
do	O
not	O
split	O
the	O
output	O
of	O
the	O
encoded	O
presentation	O
and	O
let	O
it	O
pass	O
through	O
a	O
self	B-Method
-	I-Method
attention	I-Method
layer	I-Method
.	O
	
The	O
bidirectional	O
attention	O
is	O
removed	O
.	O
	
In	O
this	O
way	O
,	O
our	O
model	O
uses	O
only	O
one	O
unified	B-Method
representation	I-Method
of	O
the	O
question	B-Method
and	O
passage	O
at	O
all	O
time	O
.	O
	
We	O
simply	O
pass	O
this	O
representation	O
layer	O
by	O
layer	O
to	O
get	O
the	O
final	O
result	O
.	O
	
Compared	O
to	O
the	O
bi	B-Method
-	I-Method
attention	I-Method
model	I-Method
,	O
the	O
F1	B-Metric
-	I-Metric
score	I-Metric
decreases	O
0.5	O
%	O
.	O
	
subsection	O
:	O
Multi	B-Task
-	I-Task
task	I-Task
Study	I-Task
	
We	O
also	O
run	O
an	O
experiment	O
to	O
test	O
the	O
performance	O
of	O
our	O
multi	B-Method
-	I-Method
task	I-Method
model	I-Method
.	O
	
We	O
select	O
different	O
losses	O
that	O
participate	O
in	O
the	O
training	O
procedure	O
to	O
observe	O
the	O
performance	O
affected	O
by	O
answer	B-Task
boundary	I-Task
detect	I-Task
or	O
classification	B-Task
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
performance	O
.	O
	
Here	O
we	O
use	O
and	O
to	O
represent	O
the	O
EM	B-Metric
and	O
F1	B-Metric
score	I-Metric
when	O
the	O
classification	B-Task
is	O
not	O
part	O
of	O
the	O
task	O
,	O
which	O
makes	O
it	O
very	O
much	O
like	O
the	O
task	O
in	O
SQuAD	B-Material
1.1	I-Material
.	O
	
To	O
test	O
our	O
classifier	B-Method
performance	O
,	O
we	O
do	O
not	O
use	O
backward	B-Method
propagation	I-Method
over	O
the	O
loss	B-Task
of	I-Task
answer	I-Task
boundary	I-Task
detection	I-Task
and	O
simply	O
run	O
a	O
classification	B-Task
task	I-Task
.	O
	
Results	O
(	O
the	O
first	O
two	O
rows	O
in	O
Table	O
[	O
reference	O
]	O
)	O
show	O
that	O
there	O
is	O
a	O
large	O
gain	O
when	O
using	O
the	O
multi	B-Method
-	I-Method
task	I-Method
model	I-Method
.	O
	
The	O
answer	B-Task
boundary	I-Task
detection	I-Task
task	I-Task
helps	O
the	O
encoder	O
learn	O
information	O
between	O
the	O
passage	O
and	O
question	B-Method
and	O
also	O
feed	O
information	O
into	O
the	O
universal	O
node	O
,	O
therefore	O
we	O
can	O
use	O
a	O
summarized	B-Method
representation	I-Method
of	O
the	O
passage	O
and	O
question	B-Method
as	O
well	O
as	O
the	O
universal	O
node	O
to	O
distinguish	O
whether	O
the	O
question	B-Method
is	O
answerable	O
,	O
i.e.	O
,	O
help	O
improve	O
classification	B-Task
.	O
	
For	O
the	O
answer	B-Task
boundary	I-Task
detection	I-Task
task	I-Task
,	O
we	O
find	O
that	O
the	O
multi	B-Task
-	I-Task
task	I-Task
setup	I-Task
(	O
i.e.	O
,	O
the	O
classification	B-Method
layer	I-Method
participates	O
in	O
the	O
training	O
process	O
)	O
does	O
not	O
help	O
its	O
performance	O
.	O
	
Since	O
the	O
classifier	B-Method
and	O
pointer	B-Method
layer	I-Method
shared	O
the	O
encoding	B-Method
process	I-Method
,	O
we	O
originally	O
expected	O
that	O
classification	O
information	O
can	O
help	O
detect	O
answer	O
boundaries	O
.	O
	
But	O
this	O
is	O
not	O
the	O
case	O
.	O
	
We	O
think	O
this	O
is	O
also	O
reasonable	O
since	O
distinguishing	O
whether	O
the	O
question	B-Method
is	O
answerable	O
is	O
mainly	O
focusing	O
on	O
the	O
interactions	O
between	O
the	O
passage	O
-	O
question	B-Method
pair	O
,	O
so	O
once	O
the	O
question	B-Method
is	O
predicted	O
as	O
answerable	O
or	O
not	O
,	O
it	O
has	O
nothing	O
to	O
do	O
with	O
the	O
answer	O
boundaries	O
.	O
	
This	O
is	O
consistent	O
with	O
how	O
human	O
-	O
beings	O
do	O
this	O
classification	B-Task
task	I-Task
.	O
	
We	O
also	O
run	O
the	O
test	O
over	O
SQuAD	B-Material
1.1	O
development	O
test	O
to	O
evaluate	O
the	O
performance	O
.	O
	
Due	O
to	O
a	O
condensed	O
structure	O
,	O
our	O
model	O
achieves	O
an	O
score	O
of	O
less	O
than	O
86	O
%	O
,	O
which	O
is	O
not	O
a	O
very	O
competitive	O
score	O
on	O
SQuAD	B-Material
1.1	I-Material
test	I-Material
.	O
	
But	O
as	O
shown	O
above	O
,	O
our	O
model	O
achieves	O
a	O
good	O
score	O
in	O
SQuAD	B-Material
2.0	I-Material
test	I-Material
,	O
which	O
shows	O
this	O
model	O
has	O
the	O
potential	O
to	O
achieve	O
higher	O
performance	O
by	O
making	O
progress	O
on	O
both	O
the	O
answer	B-Task
detection	I-Task
and	I-Task
classification	I-Task
tasks	I-Task
.	O
	
Overall	O
,	O
we	O
can	O
conclude	O
that	O
our	O
multi	B-Method
-	I-Method
task	I-Method
model	I-Method
works	O
well	O
since	O
the	O
performance	O
of	O
unanswerability	B-Task
classification	I-Task
improves	O
significantly	O
when	O
the	O
answer	O
pointer	O
and	O
answer	B-Task
verifier	I-Task
work	O
simultaneously	O
.	O
	
subsection	O
:	O
Study	O
on	O
the	O
Different	O
Thresholds	O
of	O
Unanswerability	B-Task
Classification	I-Task
	
The	O
output	O
of	O
the	O
answer	B-Method
verifier	I-Method
is	O
the	O
probability	O
of	O
a	O
question	B-Method
being	O
unanswerable	O
.	O
	
The	O
smaller	O
the	O
output	O
,	O
the	O
lower	O
the	O
probability	O
of	O
unanswerability	O
is	O
.	O
	
In	O
SQuAD	B-Material
2.0	I-Material
,	O
the	O
proportions	O
of	O
unanswerable	O
questions	O
are	O
different	O
in	O
the	O
training	O
and	O
test	O
sets	O
.	O
	
The	O
default	O
threshold	O
is	O
optimized	O
on	O
the	O
training	O
set	O
,	O
but	O
not	O
suitable	O
for	O
the	O
test	O
set	O
.	O
	
Therefore	O
,	O
it	O
is	O
reasonable	O
to	O
set	O
a	O
proper	O
threshold	O
to	O
manually	O
adapt	O
to	O
the	O
test	O
set	O
.	O
	
As	O
mentioned	O
in	O
SQuAD	B-Material
2.0	I-Material
paper	O
,	O
different	O
thresholds	O
for	O
answerability	B-Task
prediction	I-Task
result	O
in	O
fluctuated	O
scores	O
between	O
answerable	O
and	O
unanswerable	O
questions	O
.	O
	
Here	O
we	O
show	O
the	O
variation	O
of	O
the	O
F1	B-Metric
score	I-Metric
with	O
different	O
thresholds	O
in	O
Figure	O
.	O
	
The	O
threshold	O
between	O
is	O
used	O
to	O
decide	O
whether	O
a	O
question	B-Method
can	O
be	O
answered	O
.	O
	
When	O
the	O
threshold	O
is	O
set	O
to	O
,	O
all	O
questions	O
are	O
considered	O
as	O
answerable	O
.	O
	
As	O
we	O
can	O
see	O
,	O
when	O
the	O
threshold	O
is	O
set	O
to	O
0.5	O
,	O
F1	B-Metric
score	I-Metric
of	O
answerable	O
questions	O
is	O
similar	O
to	O
that	O
of	O
unanswerable	O
questions	O
.	O
	
When	O
we	O
increase	O
the	O
threshold	O
(	O
i.e.	O
,	O
more	O
likely	O
to	O
predict	O
the	O
question	B-Method
as	O
unanswerable	O
)	O
,	O
performance	O
for	O
answerable	B-Task
questions	I-Task
degrades	O
,	O
and	O
improves	O
for	O
unanswerable	O
questions	O
.	O
	
This	O
is	O
as	O
expected	O
.	O
	
We	O
can	O
see	O
that	O
the	O
overall	O
score	O
is	O
slightly	O
better	O
,	O
which	O
is	O
consistent	O
with	O
the	O
idea	O
from	O
SQuAD	B-Material
2.0	I-Material
.	O
	
In	O
addition	O
,	O
we	O
find	O
that	O
for	O
larger	O
thresholds	O
,	O
the	O
variance	O
between	O
and	O
is	O
narrowed	O
since	O
and	O
scores	O
for	O
unanswerable	O
questions	O
are	O
the	O
same	O
.	O
	
Finally	O
,	O
we	O
set	O
the	O
threshold	O
to	O
be	O
for	O
the	O
submission	B-Method
system	I-Method
to	O
SQuAD	B-Material
evaluation	O
.	O
	
section	O
:	O
Related	O
Work	O
	
subsection	O
:	O
End	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
Models	I-Method
for	O
MRC	B-Task
	
Currently	O
,	O
end	O
-	O
to	O
-	O
end	O
neural	B-Method
network	I-Method
models	I-Method
have	O
achieved	O
great	O
successes	O
for	O
machine	B-Task
reading	I-Task
comprehension	I-Task
.	O
	
Most	O
of	O
these	O
models	O
consist	O
of	O
three	O
components	O
:	O
encoder	B-Method
,	O
interaction	O
,	O
and	O
pointer	O
.	O
	
The	O
BiLSTM	B-Method
is	O
widely	O
used	O
for	O
encoding	O
the	O
embedded	B-Task
representation	I-Task
.	O
	
For	O
the	O
interaction	O
,	O
bidirectional	B-Method
attention	I-Method
mechanism	I-Method
is	O
very	O
effective	O
to	O
fuse	O
information	O
of	O
the	O
question	B-Method
and	O
passage	O
.	O
	
Finally	O
,	O
a	O
pointer	B-Method
network	I-Method
is	O
used	O
to	O
predict	O
the	O
span	O
boundaries	O
of	O
the	O
answer	O
.	O
	
Specifically	O
,	O
in	O
SQuAD	B-Material
test	O
,	O
there	O
are	O
approaches	O
to	O
combine	O
match	B-Method
-	I-Method
LSTM	I-Method
and	I-Method
pointer	I-Method
networks	I-Method
to	O
produce	O
boundaries	O
of	O
the	O
answer	O
and	O
employ	O
variant	O
bidirectional	B-Method
attention	I-Method
mechanism	I-Method
to	O
match	O
the	O
question	B-Method
and	O
passage	O
mutually	O
.	O
	
In	O
our	O
model	O
,	O
we	O
learn	O
from	O
previous	O
work	O
and	O
develop	O
a	O
condensed	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
model	I-Method
for	O
the	O
SQuAD	B-Material
2.0	I-Material
task	I-Material
.	O
	
Different	O
from	O
the	O
previous	O
models	O
,	O
we	O
use	O
a	O
unified	B-Method
representation	I-Method
to	O
encode	O
the	O
question	B-Method
and	O
passage	O
simultaneously	O
,	O
and	O
introduce	O
a	O
universal	O
node	O
to	O
encode	O
the	O
fused	O
information	O
of	O
the	O
question	B-Method
and	O
passage	O
,	O
which	O
also	O
plays	O
an	O
important	O
role	O
to	O
predict	O
the	O
unanswerability	B-Task
of	I-Task
a	I-Task
question	I-Task
.	O
	
subsection	O
:	O
MRC	B-Method
with	O
Unanswerable	O
Questions	O
	
MRC	B-Task
with	O
unanswerable	O
questions	O
is	O
a	O
more	O
challenging	O
task	O
.	O
	
Previous	O
work	O
levy2017zero	O
,	O
clark2017simple	O
levy2017zero	O
	
,	O
clark2017simple	O
has	O
attempted	O
to	O
normalize	O
a	O
no	O
-	O
answer	O
score	O
depending	O
on	O
the	O
probability	O
of	O
all	O
answer	O
spans	O
and	O
still	O
detect	O
boundaries	O
at	O
the	O
same	O
time	O
.	O
	
But	O
the	O
scores	O
of	O
the	O
answer	B-Method
span	I-Method
predictions	I-Method
are	O
not	O
very	O
discriminative	O
in	O
distinguishing	O
whether	O
the	O
question	B-Method
is	O
answerable	O
.	O
	
Therefore	O
,	O
this	O
kind	O
of	O
approaches	O
,	O
though	O
relatively	O
simple	O
,	O
can	O
not	O
effectively	O
deal	O
with	O
the	O
answerability	O
of	O
a	O
question	B-Method
.	O
	
hu2018read	B-Method
,	O
tan2018know	O
hu2018read	O
,	O
tan2018know	O
introduced	O
an	O
answer	B-Method
verifier	I-Method
idea	I-Method
to	O
construct	O
a	O
classification	B-Method
layer	I-Method
.	O
	
However	O
,	O
this	O
kind	O
of	O
approaches	O
usually	O
has	O
a	O
pipeline	B-Method
structure	I-Method
.	O
	
The	O
answer	O
pointer	O
and	O
answer	B-Method
verifier	I-Method
have	O
their	O
respective	O
models	O
that	O
are	O
trained	O
separately	O
.	O
	
paragraph	O
:	O
Multi	B-Method
-	I-Method
task	I-Method
models	I-Method
	
Different	O
from	O
existing	O
work	O
,	O
we	O
regard	O
the	O
MRC	B-Task
with	O
unanswerable	O
questions	O
as	O
a	O
multi	B-Task
-	I-Task
task	I-Task
learning	I-Task
problem	I-Task
by	O
sharing	O
some	O
meta	O
-	O
knowledge	O
.	O
	
Intuitively	O
,	O
answer	B-Task
prediction	I-Task
and	O
answer	B-Task
verification	I-Task
are	O
related	O
tasks	O
since	O
the	O
underlying	O
comprehension	O
and	O
reasoning	O
of	O
language	O
for	O
these	O
components	O
is	O
the	O
same	O
.	O
	
Therefore	O
,	O
we	O
construct	O
a	O
multi	B-Method
-	I-Method
task	I-Method
model	I-Method
to	O
solve	O
three	O
sub	B-Task
-	I-Task
tasks	I-Task
:	O
answer	O
pointer	O
,	O
no	O
-	O
answer	O
pointer	O
,	O
and	O
answer	B-Task
verifier	I-Task
.	O
	
section	O
:	O
Conclusion	O
and	O
Future	O
Work	O
	
In	O
this	O
paper	O
,	O
we	O
regard	O
the	O
MRC	B-Task
with	O
unanswerable	O
questions	O
as	O
multi	B-Task
-	I-Task
task	I-Task
learning	I-Task
problems	I-Task
and	O
propose	O
the	O
U	B-Method
-	I-Method
Net	I-Method
,	O
a	O
simple	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
model	I-Method
for	O
MRC	B-Task
challenges	I-Task
.	O
	
U	B-Method
-	I-Method
Net	I-Method
has	O
good	O
performance	O
on	O
SQuAD	B-Material
2.0	I-Material
.	O
	
We	O
first	O
add	O
a	O
universal	O
node	O
to	O
learn	O
a	O
fused	B-Method
representation	I-Method
from	O
both	O
the	O
question	B-Method
and	O
passage	O
,	O
then	O
use	O
a	O
concatenated	B-Method
representation	I-Method
to	O
pass	O
through	O
encoding	B-Method
layers	I-Method
.	O
	
We	O
only	O
treat	O
question	B-Method
and	O
passage	O
differently	O
during	O
attention	O
interactions	O
.	O
	
In	O
the	O
rest	O
blocks	O
of	O
U	B-Method
-	I-Method
Net	I-Method
,	O
we	O
still	O
use	O
the	O
unified	B-Method
representation	I-Method
containing	O
both	O
the	O
question	B-Method
and	O
passage	B-Method
representation	I-Method
.	O
	
Finally	O
,	O
we	O
train	O
the	O
U	B-Method
-	I-Method
Net	I-Method
as	O
a	O
multi	B-Method
-	I-Method
task	I-Method
framework	I-Method
to	O
determine	O
the	O
final	O
answer	O
boundaries	O
as	O
well	O
as	O
whether	O
the	O
question	B-Method
is	O
answerable	O
.	O
	
Our	O
model	O
has	O
very	O
simple	O
structure	O
yet	O
achieves	O
good	O
results	O
on	O
SQuAD	B-Material
2.0	I-Material
test	I-Material
.	O
	
Our	O
future	O
work	O
is	O
to	O
reconstruct	O
the	O
structure	O
of	O
U	B-Method
-	I-Method
Net	I-Method
by	O
replacing	O
the	O
current	O
multi	B-Method
-	I-Method
level	I-Method
attention	I-Method
block	I-Method
with	O
a	O
simpler	O
self	B-Method
-	I-Method
attention	I-Method
mechanism	I-Method
,	O
which	O
we	O
believe	O
can	O
capture	O
the	O
question	B-Method
and	O
passage	O
information	O
,	O
and	O
intuitively	O
is	O
also	O
coherent	O
with	O
the	O
rest	O
of	O
our	O
U	B-Method
-	I-Method
Net	I-Method
model	O
.	O
	
In	O
addition	O
,	O
we	O
will	O
improve	O
the	O
answer	B-Task
boundary	I-Task
detection	I-Task
performance	O
based	O
on	O
some	O
of	O
the	O
previous	O
successful	O
models	O
.	O
	
Since	O
our	O
model	O
actually	O
does	O
not	O
achieve	O
very	O
competitive	O
performance	O
in	O
the	O
boundary	B-Task
detection	I-Task
task	I-Task
yet	O
still	O
has	O
a	O
good	O
overall	O
performance	O
on	O
SQuAD	B-Material
2.0	I-Material
test	I-Material
,	O
we	O
are	O
optimistic	O
that	O
our	O
U	B-Method
-	I-Method
Net	I-Method
model	O
is	O
potentially	O
capable	O
of	O
achieving	O
better	O
performance	O
.	O
	
Furthermore	O
,	O
our	O
model	O
has	O
a	O
simple	O
structure	O
and	O
is	O
easy	O
to	O
implement	O
,	O
therefore	O
we	O
believe	O
that	O
our	O
model	O
can	O
be	O
easily	O
modified	O
for	O
various	O
datasets	O
.	O
	
section	O
:	O
Acknowledgement	O
	
We	O
would	O
like	O
to	O
thank	O
Robin	O
Jia	O
,	O
Pranav	O
Rajpurkar	O
for	O
their	O
help	O
with	O
SQuAD	B-Material
2.0	I-Material
submissions	I-Material
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Grammar	B-Method
as	O
a	O
Foreign	O
Language	O
	
Syntactic	B-Task
constituency	I-Task
parsing	I-Task
is	O
a	O
fundamental	O
problem	O
in	O
natural	B-Task
language	I-Task
processing	I-Task
and	O
has	O
been	O
the	O
subject	O
of	O
intensive	O
research	O
and	O
engineering	O
for	O
decades	O
.	O
	
As	O
a	O
result	O
,	O
the	O
most	O
accurate	O
parsers	B-Method
are	O
domain	O
specific	O
,	O
complex	O
,	O
and	O
inefficient	O
.	O
	
In	O
this	O
paper	O
we	O
show	O
that	O
the	O
domain	B-Method
agnostic	I-Method
attention	I-Method
-	I-Method
enhanced	I-Method
sequence	I-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
model	I-Method
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
the	O
most	O
widely	O
used	O
syntactic	O
constituency	O
parsing	O
dataset	O
,	O
when	O
trained	O
on	O
a	O
large	O
synthetic	O
corpus	O
that	O
was	O
annotated	O
using	O
existing	O
parsers	B-Method
.	O
	
It	O
also	O
matches	O
the	O
performance	O
of	O
standard	O
parsers	B-Method
when	O
trained	O
only	O
on	O
a	O
small	O
human	O
-	O
annotated	O
dataset	O
,	O
which	O
shows	O
that	O
this	O
model	O
is	O
highly	O
data	O
-	O
efficient	O
,	O
in	O
contrast	O
to	O
sequence	B-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
models	I-Method
without	O
the	O
attention	B-Method
mechanism	I-Method
.	O
	
Our	O
parser	B-Method
is	O
also	O
fast	O
,	O
processing	O
over	O
a	O
hundred	O
sentences	O
per	O
second	O
with	O
an	O
unoptimized	B-Method
CPU	I-Method
implementation	I-Method
.	O
	
section	O
:	O
Introduction	O
	
Syntactic	B-Task
constituency	I-Task
parsing	I-Task
is	O
a	O
fundamental	O
problem	O
in	O
linguistics	B-Task
and	I-Task
natural	I-Task
language	I-Task
processing	I-Task
that	O
has	O
a	O
wide	O
range	O
of	O
applications	O
.	O
	
This	O
problem	O
has	O
been	O
the	O
subject	O
of	O
intense	O
research	O
for	O
decades	O
,	O
and	O
as	O
a	O
result	O
,	O
there	O
exist	O
highly	O
accurate	O
domain	B-Method
-	I-Method
specific	I-Method
parsers	I-Method
.	O
	
The	O
computational	B-Metric
requirements	I-Metric
of	O
traditional	O
parsers	B-Method
are	O
cubic	O
in	O
sentence	O
length	O
,	O
and	O
while	O
linear	B-Method
-	I-Method
time	I-Method
shift	I-Method
-	I-Method
reduce	I-Method
constituency	I-Method
parsers	I-Method
improved	O
in	O
accuracy	B-Metric
in	O
recent	O
years	O
,	O
they	O
never	O
matched	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
.	O
	
Furthermore	O
,	O
standard	O
parsers	B-Method
have	O
been	O
designed	O
with	O
parsing	B-Task
in	O
mind	O
;	O
the	O
concept	O
of	O
a	O
parse	O
tree	O
is	O
deeply	O
ingrained	O
into	O
these	O
systems	O
,	O
which	O
makes	O
these	O
methods	O
inapplicable	O
to	O
other	O
problems	O
.	O
	
Recently	O
,	O
Sutskever	O
et	O
al	O
.	O
introduced	O
a	O
neural	B-Method
network	I-Method
model	I-Method
for	O
solving	O
the	O
general	B-Task
sequence	I-Task
-	I-Task
to	I-Task
-	I-Task
sequence	I-Task
problem	I-Task
,	O
and	O
Bahdanau	O
et	O
al	O
.	O
proposed	O
a	O
related	O
model	O
with	O
an	O
attention	B-Method
mechanism	I-Method
that	O
makes	O
it	O
capable	O
of	O
handling	O
long	O
sequences	O
well	O
.	O
	
Both	O
models	O
achieve	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
large	B-Task
scale	I-Task
machine	I-Task
translation	I-Task
tasks	I-Task
(	O
e.g.	O
,	O
)	O
.	O
	
Syntactic	B-Task
constituency	I-Task
parsing	I-Task
can	O
be	O
formulated	O
as	O
a	O
sequence	B-Task
-	I-Task
to	I-Task
-	I-Task
sequence	I-Task
problem	I-Task
if	O
we	O
linearize	O
the	O
parse	O
tree	O
(	O
cf	O
.	O
	
Figure	O
[	O
reference	O
]	O
)	O
	
,	O
so	O
we	O
can	O
apply	O
these	O
models	O
to	O
parsing	B-Task
as	O
well	O
.	O
	
Our	O
early	O
experiments	O
focused	O
on	O
the	O
sequence	B-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
model	I-Method
of	O
Sutskever	O
et	O
al	O
.	O
.	O
	
We	O
found	O
this	O
model	O
to	O
work	O
poorly	O
when	O
we	O
trained	O
it	O
on	O
standard	O
human	O
-	O
annotated	O
parsing	O
datasets	O
(	O
1	O
M	O
tokens	O
)	O
,	O
so	O
we	O
constructed	O
an	O
artificial	O
dataset	O
by	O
labelling	O
a	O
large	O
corpus	O
with	O
the	O
BerkeleyParser	B-Method
.	O
	
To	O
our	O
surprise	O
,	O
the	O
sequence	B-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
model	I-Method
matched	O
the	O
BerkeleyParser	B-Method
that	O
produced	O
the	O
annotation	O
,	O
having	O
achieved	O
an	O
F1	B-Metric
score	I-Metric
of	O
90.5	O
on	O
the	O
test	O
set	O
(	O
section	O
23	O
of	O
the	O
WSJ	B-Material
)	O
.	O
	
We	O
suspected	O
that	O
the	O
attention	B-Method
model	I-Method
of	O
Bahdanau	O
et	O
al	O
.	O
might	O
be	O
more	O
data	O
efficient	O
and	O
we	O
found	O
that	O
it	O
is	O
indeed	O
the	O
case	O
.	O
	
We	O
trained	O
a	O
sequence	B-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
model	I-Method
with	O
attention	B-Method
on	O
the	O
small	O
human	O
-	O
annotated	O
parsing	O
dataset	O
and	O
were	O
able	O
to	O
achieve	O
an	O
F1	B-Metric
score	I-Metric
of	O
88.3	O
on	O
section	O
23	O
of	O
the	O
WSJ	B-Material
without	O
the	O
use	O
of	O
an	O
ensemble	B-Method
and	O
90.5	O
with	O
an	O
ensemble	B-Method
,	O
which	O
matches	O
the	O
performance	O
of	O
the	O
BerkeleyParser	B-Method
(	O
90.4	O
)	O
when	O
trained	O
on	O
the	O
same	O
data	O
.	O
	
Finally	O
,	O
we	O
constructed	O
a	O
second	O
artificial	O
dataset	O
consisting	O
of	O
only	O
high	O
-	O
confidence	O
parse	O
trees	O
,	O
as	O
measured	O
by	O
the	O
agreement	O
of	O
two	O
parsers	B-Method
.	O
	
We	O
trained	O
a	O
sequence	B-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
model	I-Method
with	O
attention	B-Method
on	O
this	O
data	O
and	O
achieved	O
an	O
F1	B-Metric
score	I-Metric
of	O
92.5	O
on	O
section	O
23	O
of	O
the	O
WSJ	B-Material
–	O
a	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
.	O
	
This	O
result	O
did	O
not	O
require	O
an	O
ensemble	O
,	O
and	O
as	O
a	O
result	O
,	O
the	O
parser	B-Method
is	O
also	O
very	O
fast	O
.	O
	
An	O
ensemble	O
further	O
improves	O
the	O
score	O
to	O
92.8	O
.	O
	
section	O
:	O
LSTM	B-Method
+	O
A	O
Parsing	O
Model	O
	
[	O
xscale=0.64	O
,	O
yscale=0.75	O
]	O
(	O
A	O
)	O
at	O
(	O
0	O
,	O
-	O
1.7	O
)	O
.	O
	
;	O
(	O
B	O
)	O
at	O
(	O
2	O
,	O
-	O
1.7	O
)	O
Go	O
;	O
[	O
thick	O
,-	O
¿	O
]	O
	
(	O
A	O
)	O
–	O
	
(	O
0	O
,	O
-	O
1.05	O
)	O
;	O
[	O
thick	O
,-	O
¿	O
]	O
(	O
B	O
)	O
–	O
	
(	O
2	O
,	O
-	O
1.05	O
)	O
;	O
(	O
-	O
0.8	O
,	O
-	O
1.0	O
)	O
rectangle	O
(	O
2.8	O
,	O
0.0	O
)	O
;	O
(	O
lstm	B-Method
)	O
at	O
(	O
1	O
,	O
-	O
0.5	O
)	O
LSTM	B-Method
;	O
[	O
thick	O
,-	O
¿	O
]	O
(	O
0	O
,	O
0.05	O
)	O
–	O
(	O
0	O
,	O
0.45	O
)	O
;	O
[	O
thick	O
,-	O
¿	O
]	O
(	O
2	O
,	O
0.05	O
)	O
	
–	O
(	O
2	O
,	O
0.45	O
)	O
;	O
(	O
-	O
0.8	O
,	O
0.5	O
)	O
rectangle	O
(	O
2.8	O
,	O
1.5	O
)	O
;	O
(	O
lstm	B-Method
)	O
at	O
(	O
1	O
,	O
1	O
)	O
LSTM	B-Method
;	O
[	O
thick	O
,-	O
¿	O
]	O
(	O
0	O
,	O
1.55	O
)	O
–	O
(	O
0	O
,	O
1.95	O
)	O
;	O
[	O
thick	O
,-	O
¿	O
]	O
(	O
2	O
,	O
1.55	O
)	O
–	O
(	O
2	O
,	O
1.95	O
)	O
;	O
(	O
-	O
0.8	O
,	O
2	O
)	O
rectangle	O
(	O
2.8	O
,	O
3	O
)	O
;	O
(	O
lstm	B-Method
)	O
at	O
(	O
1	O
,	O
2.5	O
)	O
LSTM	B-Method
;	O
	
[	O
thick	O
,-	O
¿	O
]	O
(	O
2.85	O
,	O
-	O
0.5	O
)	O
–	O
(	O
4.15	O
,	O
-	O
0.5	O
)	O
;	O
[	O
thick	O
,-	O
¿	O
]	O
(	O
2.85	O
,	O
1	O
)	O
–	O
	
(	O
4.15	O
,	O
1	O
)	O
;	O
[	O
thick	O
,-	O
¿	O
]	O
(	O
2.85	O
,	O
2.5	O
)	O
	
–	O
	
(	O
4.15	O
,	O
2.5	O
)	O
;	O
[	O
xshift=1	O
cm	O
]	O
(	O
end	O
)	O
at	O
(	O
4	O
,	O
-	O
1.7	O
)	O
end	O
;	O
(	O
S	O
)	O
at	O
(	O
6	O
,	O
-	O
1.7	O
)	O
	
(	O
S	O
;	O
(	O
VP	O
)	O
at	O
(	O
8	O
,	O
-	O
1.7	O
)	O
	
(	O
VP	O
;	O
(	O
VB	O
)	O
at	O
(	O
10	O
,	O
-	O
1.7	O
)	O
XX	O
;	O
(	O
cVP	O
)	O
at	O
(	O
12	O
,	O
-	O
1.7	O
)	O
)	O
;	O
(	O
dot	O
)	O
at	O
(	O
14	O
,	O
-	O
1.7	O
)	O
.	O
	
;	O
(	O
cS	O
)	O
at	O
(	O
16	O
,	O
-	O
1.7	O
)	O
)	O
	
;	O
[	O
thick	O
,-	O
¿	O
]	O
(	O
end	O
)	O
–	O
(	O
4	O
,	O
-	O
1.05	O
)	O
;	O
[	O
thick	O
,-	O
¿	O
]	O
	
(	O
S	O
)	O
–	O
	
(	O
6	O
,	O
-	O
1.05	O
)	O
;	O
[	O
thick	O
,-	O
¿	O
]	O
	
(	O
VP	O
)	O
–	O
	
(	O
8	O
,	O
-	O
1.05	O
)	O
;	O
[	O
thick	O
,-	O
¿	O
]	O
(	O
VB	O
)	O
–	O
	
(	O
10	O
,	O
-	O
1.05	O
)	O
;	O
[	O
thick	O
,-	O
¿	O
]	O
(	O
cVP	B-Method
)	O
	
–	O
	
(	O
12	O
,	O
-	O
1.05	O
)	O
;	O
[	O
thick	O
,-	O
¿	O
]	O
(	O
dot	O
)	O
	
–	O
	
(	O
14	O
,	O
-	O
1.05	O
)	O
;	O
[	O
thick	O
,-	O
¿	O
]	O
	
(	O
cS	O
)	O
	
–	O
	
(	O
16	O
,	O
-	O
1.05	O
)	O
;	O
(	O
3.2	O
,	O
-	O
1.0	O
)	O
rectangle	O
(	O
16.8	O
,	O
0.0	O
)	O
;	O
(	O
lstm	B-Method
)	O
at	O
(	O
10	O
,	O
-	O
0.5	O
)	O
LSTM	B-Method
;	O
[	O
thick	O
,-	O
¿	O
]	O
(	O
4	O
,	O
0.05	O
)	O
	
–	O
(	O
4	O
,	O
0.45	O
)	O
;	O
[	O
thick	O
,-	O
¿	O
]	O
(	O
6	O
,	O
0.05	O
)	O
	
–	O
(	O
6	O
,	O
0.45	O
)	O
;	O
[	O
thick	O
,-	O
¿	O
]	O
(	O
8	O
,	O
0.05	O
)	O
	
–	O
(	O
8	O
,	O
0.45	O
)	O
;	O
[	O
thick	O
,-	O
¿	O
]	O
(	O
10	O
,	O
0.05	O
)	O
	
–	O
(	O
10	O
,	O
0.45	O
)	O
;	O
	
[	O
thick	O
,-	O
¿	O
]	O
(	O
12	O
,	O
0.05	O
)	O
	
–	O
(	O
12	O
,	O
0.45	O
)	O
;	O
[	O
thick	O
,-	O
¿	O
]	O
(	O
14	O
,	O
0.05	O
)	O
	
–	O
(	O
14	O
,	O
0.45	O
)	O
;	O
[	O
thick	O
,-	O
¿	O
]	O
(	O
16	O
,	O
0.05	O
)	O
	
–	O
(	O
16	O
,	O
0.45	O
)	O
;	O
(	O
3.2	O
,	O
0.5	O
)	O
rectangle	O
(	O
16.8	O
,	O
1.5	O
)	O
;	O
(	O
lstm	B-Method
)	O
at	O
(	O
10	O
,	O
1	O
)	O
LSTM	B-Method
;	O
[	O
thick	O
,-	O
¿	O
]	O
(	O
4	O
,	O
1.55	O
)	O
–	O
(	O
4	O
,	O
1.95	O
)	O
;	O
[	O
thick	O
,-	O
¿	O
]	O
(	O
6	O
,	O
1.55	O
)	O
	
–	O
	
(	O
6	O
,	O
1.95	O
)	O
;	O
[	O
thick	O
,-	O
¿	O
]	O
(	O
8	O
,	O
1.55	O
)	O
–	O
	
(	O
8	O
,	O
1.95	O
)	O
;	O
[	O
thick	O
,-	O
¿	O
]	O
(	O
10	O
,	O
1.55	O
	
)	O
–	O
(	O
10	O
,	O
1.95	O
)	O
;	O
[	O
thick	O
,-	O
¿	O
]	O
(	O
12	O
	
,	O
1.55	O
)	O
–	O
	
(	O
12	O
,	O
1.95	O
)	O
;	O
[	O
thick	O
,-	O
¿	O
]	O
(	O
14	O
,	O
1.55	O
)	O
–	O
	
(	O
14	O
,	O
1.95	O
)	O
;	O
[	O
thick	O
,-	O
¿	O
]	O
(	O
16	O
,	O
1.55	O
)	O
–	O
	
(	O
16	O
,	O
1.95	O
)	O
;	O
(	O
3.2	O
,	O
2	O
)	O
rectangle	O
(	O
16.8	O
,	O
3	O
)	O
;	O
(	O
lstm	B-Method
)	O
at	O
(	O
10	O
,	O
2.5	O
)	O
LSTM	B-Method
;	O
(	O
S	O
)	O
at	O
(	O
4	O
,	O
3.7	O
)	O
(	O
S	O
;	O
(	O
VP	O
)	O
at	O
(	O
6	O
,	O
3.7	O
)	O
(	O
VP	O
;	O
(	O
VB	O
)	O
at	O
(	O
8	O
,	O
3.7	O
)	O
XX	O
;	O
(	O
cVP	O
)	O
at	O
(	O
10	O
,	O
3.7	O
)	O
)	O
;	O
(	O
dot	O
)	O
at	O
(	O
12	O
,	O
3.7	O
)	O
.	O
;	O
(	O
cS	O
)	O
at	O
(	O
14	O
,	O
3.7	O
)	O
)	O
;	O
(	O
end	O
)	O
at	O
(	O
16	O
,	O
3.7	O
)	O
end	O
;	O
[	O
thick	O
,-	O
¿	O
]	O
(	O
4	O
,	O
3.05	O
)	O
–	O
	
(	O
S	O
)	O
;	O
0	O
,	O
3.05	O
)	O
;	O
[	O
thick	O
,-	O
¿	O
]	O
(	O
6	O
,	O
3.05	O
)	O
–	O
(	O
VP	O
)	O
;	O
0	O
,	O
3.05	O
)	O
;	O
[	O
thick	O
,-	O
¿	O
]	O
(	O
8	O
,	O
3.05	O
)	O
	
–	O
	
(	O
VB	O
)	O
;	O
0	O
,	O
3.05	O
)	O
;	O
[	O
thick	O
,-	O
¿	O
]	O
(	O
10	O
,	O
3.05	O
)	O
–	O
(	O
cVP	O
)	O
;	O
0	O
,	O
3.05	O
)	O
;	O
[	O
thick	O
,-	O
¿	O
]	O
(	O
12	O
,	O
3.05	O
)	O
	
–	O
(	O
dot	O
)	O
;	O
0	O
,	O
3.05	O
)	O
;	O
[	O
thick	O
,-	O
¿	O
]	O
(	O
14	O
,	O
3.05	O
)	O
–	O
	
(	O
cS	O
)	O
;	O
0	O
,	O
3.05	O
)	O
;	O
[	O
thick	O
,-	O
¿	O
]	O
(	O
16	O
,	O
3.05	O
)	O
	
–	O
(	O
end	O
)	O
;	O
0	O
,	O
3.05	O
)	O
	
;	O
Let	O
us	O
first	O
recall	O
the	O
sequence	O
-	O
to	O
-	O
sequence	O
LSTM	B-Method
model	O
.	O
	
The	O
Long	B-Method
Short	I-Method
-	I-Method
Term	I-Method
Memory	I-Method
model	I-Method
of	O
is	O
defined	O
as	O
follows	O
.	O
	
Let	O
,	O
,	O
and	O
be	O
the	O
input	O
,	O
control	O
state	O
,	O
and	O
memory	O
state	O
at	O
timestep	O
.	O
	
Given	O
a	O
sequence	O
of	O
inputs	O
,	O
the	O
LSTM	B-Method
computes	O
the	O
-	O
sequence	O
and	O
the	O
-	O
sequence	O
as	O
follows	O
.	O
	
The	O
operator	O
denotes	O
element	O
-	O
wise	O
multiplication	O
,	O
the	O
matrices	O
and	O
the	O
vector	O
are	O
the	O
parameters	O
of	O
the	O
model	O
,	O
and	O
all	O
the	O
nonlinearities	O
are	O
computed	O
element	O
-	O
wise	O
.	O
	
In	O
a	O
deep	O
LSTM	B-Method
,	O
each	O
subsequent	O
layer	O
uses	O
the	O
-	O
sequence	O
of	O
the	O
previous	O
layer	O
for	O
its	O
input	O
sequence	O
.	O
	
The	O
deep	O
LSTM	B-Method
defines	O
a	O
distribution	O
over	O
output	O
sequences	O
given	O
an	O
input	O
sequence	O
:	O
The	O
above	O
equation	O
assumes	O
a	O
deep	O
LSTM	B-Method
whose	O
input	O
sequence	O
is	O
,	O
so	O
denotes	O
-	O
th	O
element	O
of	O
the	O
-	O
sequence	O
of	O
topmost	O
LSTM	B-Method
.	O
	
The	O
matrix	O
consists	O
of	O
the	O
vector	B-Method
representations	I-Method
of	O
each	O
output	O
symbol	O
and	O
the	O
symbol	O
is	O
a	O
Kronecker	O
delta	O
with	O
a	O
dimension	O
for	O
each	O
output	O
symbol	O
,	O
so	O
is	O
precisely	O
the	O
’	O
th	O
element	O
of	O
the	O
distribution	O
defined	O
by	O
the	O
softmax	B-Method
.	O
	
Every	O
output	O
sequence	O
terminates	O
with	O
a	O
special	O
end	O
-	O
of	O
-	O
sequence	O
token	O
which	O
is	O
necessary	O
in	O
order	O
to	O
define	O
a	O
distribution	O
over	O
sequences	O
of	O
variable	O
lengths	O
.	O
	
We	O
use	O
two	O
different	O
sets	O
of	O
LSTM	B-Method
parameters	O
,	O
one	O
for	O
the	O
input	O
sequence	O
and	O
one	O
for	O
the	O
output	O
sequence	O
,	O
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Stochastic	B-Method
gradient	I-Method
descent	I-Method
is	O
used	O
to	O
maximize	O
the	O
training	B-Metric
objective	I-Metric
which	O
is	O
the	O
average	O
over	O
the	O
training	O
set	O
of	O
the	O
log	O
probability	O
of	O
the	O
correct	O
output	O
sequence	O
given	O
the	O
input	O
sequence	O
.	O
	
subsection	O
:	O
Attention	B-Method
Mechanism	I-Method
	
An	O
important	O
extension	O
of	O
the	O
sequence	B-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
model	I-Method
is	O
by	O
adding	O
an	O
attention	B-Method
mechanism	I-Method
.	O
	
We	O
adapted	O
the	O
attention	B-Method
model	I-Method
from	O
which	O
,	O
to	O
produce	O
each	O
output	O
symbol	O
,	O
uses	O
an	O
attention	B-Method
mechanism	I-Method
over	O
the	O
encoder	O
LSTM	B-Method
states	O
.	O
	
Similar	O
to	O
our	O
sequence	B-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
model	I-Method
described	O
in	O
the	O
previous	O
section	O
,	O
we	O
use	O
two	O
separate	O
LSTMs	B-Method
(	O
one	O
to	O
encode	O
the	O
sequence	O
of	O
input	O
words	O
,	O
and	O
another	O
one	O
to	O
produce	O
or	O
decode	O
the	O
output	O
symbols	O
)	O
.	O
	
Recall	O
that	O
the	O
encoder	O
hidden	O
states	O
are	O
denoted	O
and	O
we	O
denote	O
the	O
hidden	O
states	O
of	O
the	O
decoder	O
by	O
.	O
	
To	O
compute	O
the	O
attention	O
vector	O
at	O
each	O
output	O
time	O
over	O
the	O
input	O
words	O
we	O
define	O
:	O
The	O
vector	O
and	O
matrices	O
are	O
learnable	O
parameters	O
of	O
the	O
model	O
.	O
	
The	O
vector	O
has	O
length	O
and	O
its	O
-	O
th	O
item	O
contains	O
a	O
score	O
of	O
how	O
much	O
attention	O
should	O
be	O
put	O
on	O
the	O
-	O
th	O
hidden	O
encoder	O
state	O
.	O
	
These	O
scores	O
are	O
normalized	O
by	O
softmax	O
to	O
create	O
the	O
attention	O
mask	O
over	O
encoder	O
hidden	O
states	O
.	O
	
In	O
all	O
our	O
experiments	O
,	O
we	O
use	O
the	O
same	O
hidden	O
dimensionality	O
(	O
256	O
)	O
at	O
the	O
encoder	B-Method
and	O
the	O
decoder	O
,	O
so	O
is	O
a	O
vector	O
and	O
and	O
are	O
square	O
matrices	O
.	O
	
Lastly	O
,	O
we	O
concatenate	O
with	O
,	O
which	O
becomes	O
the	O
new	O
hidden	O
state	O
from	O
which	O
we	O
make	O
predictions	O
,	O
and	O
which	O
is	O
fed	O
to	O
the	O
next	O
time	O
step	O
in	O
our	O
recurrent	B-Method
model	I-Method
.	O
	
In	O
Section	O
[	O
reference	O
]	O
we	O
provide	O
an	O
analysis	O
of	O
what	O
the	O
attention	B-Method
mechanism	I-Method
learned	O
,	O
and	O
we	O
visualize	O
the	O
normalized	O
attention	O
vector	O
for	O
all	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
subsection	O
:	O
Linearizing	B-Task
Parsing	I-Task
Trees	I-Task
	
To	O
apply	O
the	O
model	O
described	O
above	O
to	O
parsing	B-Task
,	O
we	O
need	O
to	O
design	O
an	O
invertible	O
way	O
of	O
converting	O
the	O
parse	O
tree	O
into	O
a	O
sequence	O
(	O
linearization	O
)	O
.	O
	
We	O
do	O
this	O
in	O
a	O
very	O
simple	O
way	O
following	O
a	O
depth	B-Method
-	I-Method
first	I-Method
traversal	I-Method
order	I-Method
,	O
as	O
depicted	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
[	O
growth	O
parent	O
anchor	O
=	O
north	O
,	O
level	O
distance=2em	O
,	O
xscale=1.5	O
,	O
yscale=1.3	O
]	O
	
(	O
tokens	O
)	O
at	O
(	O
-	O
2	O
,	O
0	O
)	O
	
John	O
has	O
a	O
dog	O
.	O
;	O
(	O
arrow	O
)	O
at	O
(	O
-	O
0.7	O
,	O
0	O
)	O
;	O
(	O
S	O
)	O
at	O
(	O
2	O
,	O
0.5	O
)	O
S	O
child	O
node	O
NP	O
child	O
node	O
NNP	O
child	O
node	O
VP	O
child	O
node	O
VBZ	O
child	O
node	O
NP	O
child	O
node	O
DT	O
child	O
node	O
NN	O
child	O
node	O
.	O
;	O
(	O
tokens	O
)	O
at	O
(	O
-	O
2	O
,	O
-	O
1.7	O
)	O
	
John	O
has	O
a	O
dog	O
.	O
;	O
(	O
arrow	O
)	O
at	O
(	O
-	O
0.7	O
,	O
-	O
1.7	O
)	O
;	O
[	O
anchor	O
=	O
west	O
]	O
	
(	O
result	O
)	O
at	O
(	O
0	O
,	O
-	O
1.7	O
)	O
	
(	O
S	O
(	O
NP	O
NNP	O
)	O
(	O
VP	O
VBZ	O
(	O
NP	O
DT	O
NN	O
)	O
)	O
.	O
)	O
	
;	O
We	O
use	O
the	O
above	O
model	O
for	O
parsing	B-Task
in	O
the	O
following	O
way	O
.	O
	
First	O
,	O
the	O
network	O
consumes	O
the	O
sentence	O
in	O
a	O
left	O
-	O
to	O
-	O
right	O
sweep	O
,	O
creating	O
vectors	O
in	O
memory	O
.	O
	
Then	O
,	O
it	O
outputs	O
the	O
linearized	O
parse	O
tree	O
using	O
information	O
in	O
these	O
vectors	O
.	O
	
As	O
described	O
below	O
,	O
we	O
use	O
3	O
LSTM	B-Method
layers	O
,	O
reverse	O
the	O
input	O
sentence	O
and	O
normalize	O
part	O
-	O
of	O
-	O
speech	O
tags	O
.	O
	
An	O
example	O
run	O
of	O
our	O
LSTM	B-Method
+	O
A	O
model	O
on	O
the	O
sentence	O
“	O
	
Go	O
.	O
	
”	O
is	O
depicted	O
in	O
Figure	O
[	O
reference	O
]	O
(	O
top	O
gray	O
edges	O
illustrate	O
attention	O
)	O
.	O
	
subsection	O
:	O
Parameters	O
and	O
Initialization	O
	
paragraph	O
:	O
Sizes	O
.	O
	
In	O
our	O
experiments	O
we	O
used	O
a	O
model	O
with	O
3	O
LSTM	B-Method
layers	O
and	O
256	O
units	O
in	O
each	O
layer	O
,	O
which	O
we	O
call	O
LSTM	B-Method
+	O
A.	O
	
Our	O
input	O
vocabulary	O
size	O
was	O
90	O
K	O
	
and	O
we	O
output	O
128	O
symbols	O
.	O
	
paragraph	O
:	O
Dropout	O
.	O
	
Training	O
on	O
a	O
small	O
dataset	O
we	O
additionally	O
used	O
2	O
dropout	B-Method
layers	I-Method
,	O
one	O
between	O
LSTM	B-Method
and	O
LSTM	B-Method
,	O
and	O
one	O
between	O
LSTM	B-Method
and	O
LSTM	B-Method
.	O
	
We	O
call	O
this	O
model	O
LSTM	B-Method
+	O
A	O
+	O
D.	O
	
paragraph	O
:	O
POS	B-Method
-	I-Method
tag	I-Method
normalization	I-Method
.	O
	
Since	O
part	O
-	O
of	O
-	O
speech	O
(	O
POS	O
)	O
tags	O
are	O
not	O
evaluated	O
in	O
the	O
syntactic	O
parsing	O
F1	B-Metric
score	I-Metric
,	O
we	O
replaced	O
all	O
of	O
them	O
by	O
“	O
XX	O
”	O
in	O
the	O
training	O
data	O
.	O
	
This	O
improved	O
our	O
F1	B-Metric
score	I-Metric
by	O
about	O
1	O
point	O
,	O
which	O
is	O
surprising	O
:	O
For	O
standard	O
parsers	B-Method
,	O
including	O
POS	O
tags	O
in	O
training	O
data	O
helps	O
significantly	O
.	O
	
All	O
experiments	O
reported	O
below	O
are	O
performed	O
with	O
normalized	O
POS	O
tags	O
.	O
	
paragraph	O
:	O
Input	O
reversing	O
.	O
	
We	O
also	O
found	O
it	O
useful	O
to	O
reverse	O
the	O
input	O
sentences	O
but	O
not	O
their	O
parse	O
trees	O
,	O
similarly	O
to	O
.	O
	
Not	O
reversing	O
the	O
input	O
had	O
a	O
small	O
negative	O
impact	O
on	O
the	O
F1	B-Metric
score	I-Metric
on	O
our	O
development	O
set	O
(	O
about	O
absolute	O
)	O
.	O
	
All	O
experiments	O
reported	O
below	O
are	O
performed	O
with	O
input	O
reversing	O
.	O
	
paragraph	O
:	O
Pre	O
-	O
training	O
word	O
vectors	O
.	O
	
The	O
embedding	B-Method
layer	I-Method
for	O
our	O
90	O
K	O
vocabulary	O
can	O
be	O
initialized	O
randomly	O
or	O
using	O
pre	O
-	O
trained	O
word	B-Method
-	I-Method
vector	I-Method
embeddings	I-Method
.	O
	
We	O
pre	O
-	O
trained	O
skip	B-Method
-	I-Method
gram	I-Method
embeddings	I-Method
of	O
size	O
512	O
using	O
word2vec	B-Method
on	O
a	O
10B	O
-	O
word	O
corpus	O
.	O
	
These	O
embeddings	O
were	O
used	O
to	O
initialize	O
our	O
network	O
but	O
not	O
fixed	O
,	O
they	O
were	O
later	O
modified	O
during	O
training	O
.	O
	
We	O
discuss	O
the	O
impact	O
of	O
pre	B-Task
-	I-Task
training	I-Task
in	O
the	O
experimental	O
section	O
.	O
	
We	O
do	O
not	O
apply	O
any	O
other	O
special	O
preprocessing	O
to	O
the	O
data	O
.	O
	
In	O
particular	O
,	O
we	O
do	O
not	O
binarize	O
the	O
parse	O
trees	O
or	O
handle	O
unaries	O
in	O
any	O
specific	O
way	O
.	O
	
We	O
also	O
treat	O
unknown	O
words	O
in	O
a	O
naive	O
way	O
:	O
we	O
map	O
all	O
words	O
beyond	O
our	O
90	O
K	O
vocabulary	O
to	O
a	O
single	O
UNK	O
token	O
.	O
	
This	O
potentially	O
underestimates	O
our	O
final	O
results	O
,	O
but	O
keeps	O
our	O
framework	O
task	O
-	O
independent	O
.	O
	
section	O
:	O
Experiments	O
	
subsection	O
:	O
Training	O
Data	O
	
We	O
trained	O
the	O
model	O
described	O
above	O
on	O
2	O
different	O
datasets	O
.	O
	
For	O
one	O
,	O
we	O
trained	O
on	O
the	O
standard	O
WSJ	B-Material
training	O
dataset	O
.	O
	
This	O
is	O
a	O
very	O
small	O
training	O
set	O
by	O
neural	B-Method
network	I-Method
standards	I-Method
,	O
as	O
it	O
contains	O
only	O
40	O
K	O
sentences	O
(	O
compared	O
to	O
60	O
K	O
examples	O
even	O
in	O
MNIST	B-Material
)	O
.	O
	
Still	O
,	O
even	O
training	O
on	O
this	O
set	O
,	O
we	O
managed	O
to	O
get	O
results	O
that	O
match	O
those	O
obtained	O
by	O
domain	B-Method
-	I-Method
specific	I-Method
parsers	I-Method
.	O
	
To	O
exceed	O
the	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
,	O
we	O
created	O
another	O
,	O
larger	O
training	O
set	O
of	O
11	O
M	O
parsed	O
sentences	O
(	O
250	O
M	O
tokens	O
)	O
.	O
	
First	O
,	O
we	O
collected	O
all	O
publicly	O
available	O
treebanks	O
.	O
	
We	O
used	O
the	O
OntoNotes	B-Material
corpus	I-Material
version	O
5	O
,	O
the	O
English	B-Material
Web	I-Material
Treebank	I-Material
and	O
the	O
updated	O
and	O
corrected	B-Material
Question	I-Material
Treebank	I-Material
.	O
	
Note	O
that	O
the	O
popular	O
Wall	B-Material
Street	I-Material
Journal	I-Material
section	I-Material
of	O
the	O
Penn	B-Material
Treebank	I-Material
is	O
part	O
of	O
the	O
OntoNotes	B-Material
corpus	I-Material
.	O
	
In	O
total	O
,	O
these	O
corpora	O
give	O
us	O
90	O
K	O
training	O
sentences	O
(	O
we	O
held	O
out	O
certain	O
sections	O
for	O
evaluation	O
,	O
as	O
described	O
below	O
)	O
.	O
	
In	O
addition	O
to	O
this	O
gold	O
standard	O
data	O
,	O
we	O
use	O
a	O
corpus	O
parsed	O
with	O
existing	O
parsers	B-Method
using	O
the	O
“	O
tri	B-Method
-	I-Method
training	I-Method
”	I-Method
approach	I-Method
of	O
.	O
	
In	O
this	O
approach	O
,	O
two	O
parsers	B-Method
,	O
our	O
reimplementation	O
of	O
BerkeleyParser	B-Method
and	O
a	O
reimplementation	O
of	O
ZPar	B-Method
,	O
are	O
used	O
to	O
process	O
unlabeled	O
sentences	O
sampled	O
from	O
news	O
appearing	O
on	O
the	O
web	O
.	O
	
We	O
select	O
only	O
sentences	O
for	O
which	O
both	O
parsers	B-Method
produced	O
the	O
same	O
parse	O
tree	O
and	O
re	O
-	O
sample	O
to	O
match	O
the	O
distribution	O
of	O
sentence	O
lengths	O
of	O
the	O
WSJ	B-Material
training	O
corpus	O
.	O
	
Re	B-Task
-	I-Task
sampling	I-Task
is	O
useful	O
because	O
parsers	B-Method
agree	O
much	O
more	O
often	O
on	O
short	O
sentences	O
.	O
	
We	O
call	O
the	O
set	O
of	O
11	O
million	O
sentences	O
selected	O
in	O
this	O
way	O
,	O
together	O
with	O
the	O
90	O
K	O
golden	O
sentences	O
described	O
above	O
,	O
the	O
high	O
-	O
confidence	O
corpus	O
.	O
	
In	O
earlier	O
experiments	O
,	O
we	O
only	O
used	O
one	O
parser	B-Method
,	O
our	O
reimplementation	O
of	O
BerkeleyParser	B-Method
,	O
to	O
create	O
a	O
corpus	O
of	O
parsed	O
sentences	O
.	O
	
In	O
that	O
case	O
we	O
just	O
parsed	O
7	O
million	O
senteces	O
from	O
news	O
appearing	O
on	O
the	O
web	O
and	O
combined	O
these	O
parsed	O
sentences	O
with	O
the	O
90	O
K	O
golden	O
corpus	O
described	O
above	O
.	O
	
We	O
call	O
this	O
the	O
BerkeleyParser	B-Method
corpus	O
.	O
	
subsection	O
:	O
Evaluation	O
	
We	O
use	O
the	O
standard	O
EVALB	B-Method
tool	I-Method
for	O
evaluation	O
and	O
report	O
F1	B-Metric
scores	I-Metric
on	O
our	O
developments	O
set	O
(	O
section	O
22	O
of	O
the	O
Penn	B-Material
Treebank	I-Material
)	O
and	O
the	O
final	O
test	O
set	O
(	O
section	O
23	O
)	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
First	O
,	O
let	O
us	O
remark	O
that	O
our	O
training	O
setup	O
differs	O
from	O
those	O
reported	O
in	O
previous	O
works	O
.	O
	
To	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
no	O
standard	O
parsers	B-Method
have	O
ever	O
been	O
trained	O
on	O
datasets	O
numbering	O
in	O
the	O
hundreds	O
of	O
millions	O
of	O
tokens	O
,	O
and	O
it	O
would	O
be	O
hard	O
to	O
do	O
due	O
to	O
efficiency	B-Task
problems	I-Task
.	O
	
We	O
therefore	O
cite	O
the	O
semi	B-Task
-	I-Task
supervised	I-Task
results	I-Task
,	O
which	O
are	O
analogous	O
in	O
spirit	O
but	O
use	O
less	O
data	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
performance	O
of	O
our	O
models	O
on	O
the	O
top	O
and	O
results	O
from	O
other	O
papers	O
at	O
the	O
bottom	O
.	O
	
We	O
compare	O
to	O
variants	O
of	O
the	O
BerkeleyParser	B-Method
that	O
use	O
self	B-Method
-	I-Method
training	I-Method
on	O
unlabeled	O
data	O
,	O
or	O
built	O
an	O
ensemble	B-Method
of	I-Method
multiple	I-Method
parsers	I-Method
,	O
or	O
combine	O
both	O
techniques	O
.	O
	
We	O
also	O
include	O
the	O
best	O
linear	B-Method
-	I-Method
time	I-Method
parser	I-Method
in	O
the	O
literature	O
,	O
the	O
transition	B-Method
-	I-Method
based	I-Method
parser	I-Method
of	O
.	O
	
It	O
can	O
be	O
seen	O
that	O
,	O
when	O
training	O
on	O
WSJ	B-Material
only	O
,	O
a	O
baseline	O
LSTM	B-Method
does	O
not	O
achieve	O
any	O
reasonable	O
score	O
,	O
even	O
with	O
dropout	B-Method
and	O
early	B-Method
stopping	I-Method
.	O
	
But	O
a	O
single	O
attention	B-Method
model	I-Method
gets	O
to	O
and	O
an	O
ensemble	O
of	O
5	O
LSTM	B-Method
+	O
A	O
+	O
D	O
models	O
achieves	O
matching	O
a	O
single	O
-	O
model	O
BerkeleyParser	B-Method
on	O
WSJ	B-Material
23	O
.	O
	
When	O
trained	O
on	O
the	O
large	O
high	O
-	O
confidence	O
corpus	O
,	O
a	O
single	O
LSTM	B-Method
+	O
A	O
model	O
achieves	O
and	O
so	O
outperforms	O
not	O
only	O
the	O
best	O
single	O
model	O
,	O
but	O
also	O
the	O
best	O
ensemble	O
result	O
reported	O
previously	O
.	O
	
An	O
ensemble	O
of	O
5	O
LSTM	B-Method
+	O
A	O
models	O
further	O
improves	O
this	O
score	O
to	O
.	O
	
paragraph	O
:	O
Generating	B-Task
well	I-Task
-	I-Task
formed	I-Task
trees	I-Task
.	O
	
The	O
LSTM	B-Method
+	O
A	O
model	O
trained	O
on	O
WSJ	B-Material
dataset	O
only	O
produced	O
malformed	O
trees	O
for	O
25	O
of	O
the	O
1700	O
sentences	O
in	O
our	O
development	O
set	O
(	O
%	O
of	O
all	O
cases	O
)	O
,	O
and	O
the	O
model	O
trained	O
on	O
full	O
high	O
-	O
confidence	O
dataset	O
did	O
this	O
for	O
14	O
sentences	O
(	O
%	O
)	O
.	O
	
In	O
these	O
few	O
cases	O
where	O
LSTM	B-Method
+	O
A	O
outputs	O
a	O
malformed	O
tree	O
,	O
we	O
simply	O
add	O
brackets	O
to	O
either	O
the	O
beginning	O
or	O
the	O
end	O
of	O
the	O
tree	O
in	O
order	O
to	O
make	O
it	O
balanced	O
.	O
	
It	O
is	O
worth	O
noting	O
that	O
all	O
14	O
cases	O
where	O
LSTM	B-Method
+	O
A	O
produced	O
unbalanced	O
trees	O
were	O
sentences	O
or	O
sentence	O
fragments	O
that	O
did	O
not	O
end	O
with	O
proper	O
punctuation	O
.	O
	
There	O
were	O
very	O
few	O
such	O
sentences	O
in	O
the	O
training	O
data	O
,	O
so	O
it	O
is	O
not	O
a	O
surprise	O
that	O
our	O
model	O
can	O
not	O
deal	O
with	O
them	O
very	O
well	O
.	O
	
paragraph	O
:	O
Score	O
by	O
sentence	O
length	O
.	O
	
An	O
important	O
concern	O
with	O
the	O
sequence	O
-	O
to	O
-	O
sequence	O
LSTM	B-Method
was	O
that	O
it	O
may	O
not	O
be	O
able	O
to	O
handle	O
long	O
sentences	O
well	O
.	O
	
We	O
determine	O
the	O
extent	O
of	O
this	O
problem	O
by	O
partitioning	O
the	O
development	O
set	O
by	O
length	O
,	O
and	O
evaluating	O
BerkeleyParser	B-Method
,	O
a	O
baseline	O
LSTM	B-Method
model	O
without	O
attention	O
,	O
and	O
LSTM	B-Method
+	O
A	O
on	O
sentences	O
of	O
each	O
length	O
.	O
	
The	O
results	O
,	O
presented	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
are	O
surprising	O
.	O
	
The	O
difference	O
between	O
the	O
F1	B-Metric
score	I-Metric
on	O
sentences	O
of	O
length	O
upto	O
30	O
and	O
that	O
upto	O
70	O
is	O
for	O
the	O
BerkeleyParser	B-Method
,	O
for	O
the	O
baseline	O
LSTM	B-Method
,	O
and	O
for	O
LSTM	B-Method
+	O
A.	O
	
So	O
already	O
the	O
baseline	O
LSTM	B-Method
has	O
similar	O
performance	O
to	O
the	O
BerkeleyParser	B-Method
,	O
it	O
degrades	O
with	O
length	B-Metric
only	O
slightly	O
.	O
	
Surprisingly	O
,	O
LSTM	B-Method
+	O
A	O
shows	O
less	O
degradation	O
with	O
length	B-Metric
than	O
BerkeleyParser	B-Method
–	O
a	O
full	B-Method
chart	I-Method
parser	I-Method
that	O
uses	O
a	O
lot	O
more	O
memory	O
.	O
	
[	O
xscale=0.18	O
,	O
yscale=0.5	O
]	O
[	O
xstep=10	O
cm	O
,	O
ystep=1	O
cm	O
,	O
color	O
=	O
lightgray	O
,	O
thin	O
]	O
	
(	O
10	O
,	O
90	O
)	O
grid	O
(	O
71	O
,	O
96	O
)	O
;	O
in	O
10	O
,	O
20	O
,	O
…	O
,	O
70	O
(	O
x	O
)	O
at	O
(	O
,	O
89.8	O
)	O
;	O
in	O
90	O
,	O
…	O
,	O
96	O
(	O
x	O
)	O
at	O
(	O
8	O
,	O
)	O
;	O
(	O
bottom	O
)	O
at	O
(	O
40	O
,	O
89.3	O
)	O
Sentence	O
length	O
;	O
[	O
rotate=90	O
]	O
(	O
left	O
)	O
at	O
(	O
5	O
,	O
92.5	O
)	O
F1	B-Metric
score	I-Metric
;	O
[	O
color	O
=	O
blue	O
,	O
fill	O
=	O
blue	O
]	O
(	O
72	O
,	O
93.85	O
)	O
rectangle	O
(	O
73	O
,	O
94.15	O
)	O
;	O
[	O
anchor	O
=	O
west	O
]	O
	
(	O
l	O
)	O
at	O
(	O
73	O
,	O
94	O
)	O
BerkeleyParser	B-Method
;	O
[	O
color	O
=	O
red	O
,	O
fill	O
=	O
red	O
]	O
(	O
72	O
,	O
93.35	O
)	O
rectangle	O
(	O
73	O
,	O
93.65	O
)	O
;	O
[	O
anchor	O
=	O
west	O
]	O
	
(	O
l	O
)	O
at	O
(	O
73	O
,	O
93.5	O
)	O
baseline	O
LSTM	B-Method
;	O
[	O
color	O
=	O
orange	O
,	O
fill	O
=	O
orange	O
]	O
(	O
72	O
,	O
92.85	O
)	O
rectangle	O
(	O
73	O
,	O
93.15	O
)	O
;	O
[	O
anchor	O
=	O
west	O
]	O
	
(	O
l	O
)	O
at	O
(	O
73	O
,	O
93	O
)	O
LSTM	B-Method
+	O
A	O
;	O
[	O
thick	O
,	O
color	O
=	O
blue	O
]	O
plot	O
coordinates	O
(	O
10	O
,	O
92.7	O
)	O
(	O
11	O
,	O
92.94	O
)	O
(	O
12	O
,	O
92.95	O
)	O
(	O
13	O
,	O
93.49	O
)	O
(	O
14	O
,	O
93.69	O
)	O
(	O
15	O
,	O
93.73	O
)	O
(	O
16	O
,	O
93.75	O
)	O
(	O
17	O
,	O
93.83	O
)	O
(	O
18	O
,	O
93.69	O
)	O
(	O
19	O
,	O
93.57	O
)	O
(	O
20	O
,	O
93.33	O
)	O
(	O
21	O
,	O
93.17	O
)	O
(	O
22	O
,	O
93.12	O
)	O
(	O
23	O
,	O
93.34	O
)	O
(	O
24	O
,	O
93.2	O
)	O
(	O
25	O
,	O
93.05	O
)	O
(	O
26	O
,	O
92.78	O
)	O
(	O
27	O
,	O
92.74	O
)	O
(	O
28	O
,	O
92.64	O
)	O
(	O
29	O
,	O
92.54	O
)	O
(	O
30	O
,	O
92.37	O
)	O
(	O
31	O
,	O
92.34	O
)	O
(	O
32	O
,	O
92.3	O
)	O
(	O
33	O
,	O
92.29	O
)	O
(	O
34	O
,	O
92.15	O
)	O
(	O
35	O
,	O
92.04	O
)	O
(	O
36	O
,	O
91.99	O
)	O
(	O
37	O
,	O
91.97	O
)	O
(	O
38	O
,	O
91.91	O
)	O
(	O
39	O
,	O
91.89	O
)	O
(	O
40	O
,	O
91.8	O
)	O
(	O
41	O
,	O
91.72	O
)	O
(	O
42	O
,	O
91.69	O
)	O
(	O
43	O
,	O
91.67	O
)	O
(	O
44	O
,	O
91.55	O
)	O
(	O
45	O
,	O
91.55	O
)	O
(	O
46	O
,	O
91.47	O
)	O
(	O
47	O
,	O
91.48	O
)	O
(	O
48	O
,	O
91.45	O
)	O
(	O
49	O
,	O
91.47	O
)	O
(	O
50	O
,	O
91.43	O
)	O
(	O
51	O
,	O
91.37	O
)	O
(	O
52	O
,	O
91.34	O
)	O
(	O
53	O
,	O
91.3	O
)	O
(	O
54	O
,	O
91.3	O
)	O
(	O
55	O
,	O
91.3	O
)	O
(	O
56	O
,	O
91.26	O
)	O
(	O
57	O
,	O
91.14	O
)	O
(	O
58	O
,	O
91.15	O
)	O
(	O
59	O
,	O
91.15	O
)	O
(	O
60	O
,	O
91.15	O
)	O
(	O
61	O
,	O
91.14	O
)	O
(	O
62	O
,	O
91.14	O
)	O
(	O
63	O
,	O
91.14	O
)	O
(	O
64	O
,	O
91.09	O
)	O
(	O
65	O
,	O
91.1	O
)	O
(	O
66	O
,	O
91.1	O
)	O
(	O
67	O
,	O
91.1	O
)	O
(	O
68	O
,	O
91.1	O
)	O
(	O
69	O
,	O
91.1	O
)	O
(	O
70	O
,	O
91.1	O
)	O
(	O
71	O
,	O
91.1	O
)	O
;	O
[	O
thick	O
,	O
color	O
=	O
red	O
]	O
plot	O
coordinates	O
(	O
10	O
,	O
92.36	O
)	O
(	O
11	O
,	O
93.05	O
)	O
(	O
12	O
,	O
93.33	O
)	O
(	O
13	O
,	O
93.47	O
)	O
(	O
14	O
,	O
93.88	O
)	O
(	O
15	O
,	O
94.12	O
)	O
(	O
16	O
,	O
93.77	O
)	O
(	O
17	O
,	O
93.83	O
)	O
(	O
18	O
,	O
93.76	O
)	O
(	O
19	O
,	O
93.84	O
)	O
(	O
20	O
,	O
93.67	O
)	O
(	O
21	O
,	O
93.53	O
)	O
(	O
22	O
,	O
93.63	O
)	O
(	O
23	O
,	O
93.76	O
)	O
(	O
24	O
,	O
93.38	O
)	O
(	O
25	O
,	O
93.3	O
)	O
(	O
26	O
,	O
93.21	O
)	O
(	O
27	O
,	O
92.98	O
)	O
(	O
28	O
,	O
92.81	O
)	O
(	O
29	O
,	O
92.72	O
)	O
(	O
30	O
,	O
92.69	O
)	O
(	O
31	O
,	O
92.54	O
)	O
(	O
32	O
,	O
92.57	O
)	O
(	O
33	O
,	O
92.61	O
)	O
(	O
34	O
,	O
92.57	O
)	O
(	O
35	O
,	O
92.44	O
)	O
(	O
36	O
,	O
92.31	O
)	O
(	O
37	O
,	O
92.33	O
)	O
(	O
38	O
,	O
92.3	O
)	O
(	O
39	O
,	O
92.18	O
)	O
(	O
40	O
,	O
92.09	O
)	O
(	O
41	O
,	O
92.04	O
)	O
(	O
42	O
,	O
92.01	O
)	O
(	O
43	O
,	O
91.99	O
)	O
(	O
44	O
,	O
91.92	O
)	O
(	O
45	O
,	O
91.9	O
)	O
(	O
46	O
,	O
91.75	O
)	O
(	O
47	O
,	O
91.74	O
)	O
(	O
48	O
,	O
91.71	O
)	O
(	O
49	O
,	O
91.7	O
)	O
(	O
50	O
,	O
91.67	O
)	O
(	O
51	O
,	O
91.57	O
)	O
(	O
52	O
,	O
91.53	O
)	O
(	O
53	O
,	O
91.52	O
)	O
(	O
54	O
,	O
91.52	O
)	O
(	O
55	O
,	O
91.52	O
)	O
(	O
56	O
,	O
91.46	O
)	O
(	O
57	O
,	O
91.23	O
)	O
(	O
58	O
,	O
91.14	O
)	O
(	O
59	O
,	O
91.11	O
)	O
(	O
60	O
,	O
91.11	O
)	O
(	O
61	O
,	O
91.06	O
)	O
(	O
62	O
,	O
91.06	O
)	O
(	O
63	O
,	O
90.99	O
)	O
(	O
64	O
,	O
90.99	O
)	O
(	O
65	O
,	O
90.99	O
)	O
(	O
66	O
,	O
90.99	O
)	O
(	O
67	O
,	O
90.99	O
)	O
(	O
68	O
,	O
90.99	O
)	O
(	O
69	O
,	O
90.99	O
)	O
(	O
70	O
,	O
90.99	O
)	O
(	O
71	O
,	O
90.99	O
)	O
;	O
[	O
thick	O
,	O
color	O
=	O
orange	O
]	O
plot	O
coordinates	O
(	O
10	O
,	O
95.41	O
)	O
(	O
11	O
,	O
95.07	O
)	O
(	O
12	O
,	O
95.57	O
)	O
(	O
13	O
,	O
95.16	O
)	O
(	O
14	O
,	O
95.39	O
)	O
(	O
15	O
,	O
95.24	O
)	O
(	O
16	O
,	O
95.44	O
)	O
(	O
17	O
,	O
95.5	O
)	O
(	O
18	O
,	O
95.5	O
)	O
(	O
19	O
,	O
95.39	O
)	O
(	O
20	O
,	O
95.42	O
)	O
(	O
21	O
,	O
95.1	O
)	O
(	O
22	O
,	O
94.85	O
)	O
(	O
23	O
,	O
94.76	O
)	O
(	O
24	O
,	O
94.83	O
)	O
(	O
25	O
,	O
94.58	O
)	O
(	O
26	O
,	O
94.54	O
)	O
(	O
27	O
,	O
94.37	O
)	O
(	O
28	O
,	O
94.18	O
)	O
(	O
29	O
,	O
94.06	O
)	O
(	O
30	O
,	O
94.03	O
)	O
(	O
31	O
,	O
94.03	O
)	O
(	O
32	O
,	O
93.91	O
)	O
(	O
33	O
,	O
93.9	O
)	O
(	O
34	O
,	O
93.99	O
)	O
(	O
35	O
,	O
93.94	O
)	O
(	O
36	O
,	O
93.85	O
)	O
(	O
37	O
,	O
93.86	O
)	O
(	O
38	O
,	O
93.9	O
)	O
(	O
39	O
,	O
93.87	O
)	O
(	O
40	O
,	O
93.87	O
)	O
(	O
41	O
,	O
93.84	O
)	O
(	O
42	O
,	O
93.77	O
)	O
(	O
43	O
,	O
93.77	O
)	O
(	O
44	O
,	O
93.77	O
)	O
(	O
45	O
,	O
93.75	O
)	O
(	O
46	O
,	O
93.72	O
)	O
(	O
47	O
,	O
93.62	O
)	O
(	O
48	O
,	O
93.61	O
)	O
(	O
49	O
,	O
93.59	O
)	O
(	O
50	O
,	O
93.6	O
)	O
(	O
51	O
,	O
93.6	O
)	O
(	O
52	O
,	O
93.54	O
)	O
(	O
53	O
,	O
93.49	O
)	O
(	O
54	O
,	O
93.49	O
)	O
(	O
55	O
,	O
93.49	O
)	O
(	O
56	O
,	O
93.5	O
)	O
(	O
57	O
,	O
93.43	O
)	O
(	O
58	O
,	O
93.42	O
)	O
(	O
59	O
,	O
93.42	O
)	O
(	O
60	O
,	O
93.43	O
)	O
(	O
61	O
,	O
93.43	O
)	O
(	O
62	O
,	O
93.42	O
)	O
(	O
63	O
,	O
93.42	O
)	O
(	O
64	O
,	O
93.42	O
)	O
(	O
65	O
,	O
93.36	O
)	O
(	O
66	O
,	O
93.37	O
)	O
(	O
67	O
,	O
93.37	O
)	O
(	O
68	O
,	O
93.37	O
)	O
(	O
69	O
,	O
93.37	O
)	O
(	O
70	O
,	O
93.37	O
)	O
(	O
71	O
,	O
93.37	O
)	O
;	O
	
paragraph	O
:	O
Beam	O
size	O
influence	O
.	O
	
Our	O
decoder	O
uses	O
a	O
beam	O
of	O
a	O
fixed	O
size	O
to	O
calculate	O
the	O
output	O
sequence	O
of	O
labels	O
.	O
	
We	O
experimented	O
with	O
different	O
settings	O
for	O
the	O
beam	O
size	O
.	O
	
It	O
turns	O
out	O
that	O
it	O
is	O
almost	O
irrelevant	O
.	O
	
We	O
report	O
report	O
results	O
that	O
use	O
beam	O
size	O
10	O
,	O
but	O
using	O
beam	O
size	O
2	O
only	O
lowers	O
the	O
F1	B-Metric
score	I-Metric
of	O
LSTM	B-Method
+	O
A	O
on	O
the	O
development	O
set	O
by	O
,	O
and	O
using	O
beam	O
size	O
1	O
lowers	O
it	O
by	O
(	O
to	O
)	O
.	O
	
Beam	O
sizes	O
above	O
10	O
do	O
not	O
give	O
any	O
additional	O
improvements	O
.	O
	
paragraph	O
:	O
Dropout	O
influence	O
.	O
	
We	O
only	O
used	O
dropout	B-Method
when	O
training	O
on	O
the	O
small	O
WSJ	B-Material
dataset	O
and	O
its	O
influence	O
was	O
significant	O
.	O
	
A	O
single	O
LSTM	B-Method
+	O
A	O
model	O
only	O
achieved	O
an	O
F1	B-Metric
score	I-Metric
of	O
on	O
our	O
development	O
set	O
,	O
that	O
is	O
over	O
points	O
lower	O
than	O
the	O
of	O
a	O
LSTM	B-Method
+	O
A	O
+	O
D	O
model	O
.	O
	
paragraph	O
:	O
Pre	O
-	O
training	O
influence	O
.	O
	
As	O
described	O
in	O
the	O
previous	O
section	O
,	O
we	O
initialized	O
the	O
word	B-Method
-	I-Method
vector	I-Method
embedding	I-Method
with	O
pre	O
-	O
trained	O
word	O
vectors	O
obtained	O
from	O
word2vec	B-Material
.	O
	
To	O
test	O
the	O
influence	O
of	O
this	O
initialization	O
,	O
we	O
trained	O
a	O
LSTM	B-Method
+	O
A	O
model	O
on	O
the	O
high	O
-	O
confidence	O
corpus	O
,	O
and	O
a	O
LSTM	B-Method
+	O
A	O
+	O
D	O
model	O
on	O
the	O
WSJ	B-Material
corpus	O
,	O
starting	O
with	O
randomly	O
initialized	O
word	B-Method
-	I-Method
vector	I-Method
embeddings	I-Method
.	O
	
The	O
F1	B-Metric
score	I-Metric
on	O
our	O
development	O
set	O
was	O
lower	O
for	O
the	O
LSTM	B-Method
+	O
A	O
model	O
(	O
vs	O
)	O
and	O
lower	O
for	O
the	O
LSTM	B-Method
+	O
A	O
+	O
D	O
model	O
(	O
vs	O
)	O
.	O
	
So	O
the	O
effect	O
of	O
pre	O
-	O
training	O
is	O
consistent	O
but	O
small	O
.	O
	
paragraph	O
:	O
Performance	O
on	O
other	O
datasets	O
.	O
	
The	O
WSJ	B-Material
evaluation	O
set	O
has	O
been	O
in	O
use	O
for	O
20	O
years	O
and	O
is	O
commonly	O
used	O
to	O
compare	O
syntactic	B-Method
parsers	I-Method
.	O
	
But	O
it	O
is	O
not	O
representative	O
for	O
text	O
encountered	O
on	O
the	O
web	O
.	O
	
Even	O
though	O
our	O
model	O
was	O
trained	O
on	O
a	O
news	O
corpus	O
,	O
we	O
wanted	O
to	O
check	O
how	O
well	O
it	O
generalizes	O
to	O
other	O
forms	O
of	O
text	O
.	O
	
To	O
this	O
end	O
,	O
we	O
evaluated	O
it	O
on	O
two	O
additional	O
datasets	O
:	O
1000	O
held	O
-	O
out	O
sentences	O
from	O
the	O
Question	B-Material
Treebank	I-Material
;	O
the	O
first	O
half	O
of	O
each	O
domain	O
from	O
the	O
English	B-Material
Web	I-Material
Treebank	I-Material
(	O
8310	O
sentences	O
)	O
.	O
	
LSTM	B-Method
+	O
A	O
trained	O
on	O
the	O
high	O
-	O
confidence	O
corpus	O
(	O
which	O
only	O
includes	O
text	O
from	O
news	O
)	O
achieved	O
an	O
F1	B-Metric
score	I-Metric
of	O
on	O
QTB	B-Material
and	O
on	O
WEB	B-Material
.	O
	
Our	O
score	O
on	O
WEB	B-Material
is	O
higher	O
both	O
than	O
the	O
best	O
score	O
reported	O
in	O
(	O
)	O
and	O
the	O
best	O
score	O
we	O
achieved	O
with	O
an	O
in	O
-	O
house	O
reimplementation	O
of	O
BerkeleyParser	B-Method
trained	O
on	O
human	O
-	O
annotated	O
data	O
(	O
)	O
.	O
	
We	O
managed	O
to	O
achieve	O
a	O
slightly	O
higher	O
score	O
(	O
)	O
with	O
the	O
in	O
-	O
house	O
BerkeleyParser	B-Method
trained	O
on	O
a	O
large	O
corpus	O
.	O
	
On	O
QTB	B-Material
,	O
the	O
score	O
of	O
LSTM	B-Method
+	O
A	O
is	O
also	O
lower	O
than	O
the	O
best	O
score	O
of	O
our	O
in	O
-	O
house	O
BerkeleyParser	B-Method
(	O
)	O
.	O
	
Still	O
,	O
taking	O
into	O
account	O
that	O
there	O
were	O
only	O
few	O
questions	O
in	O
the	O
training	O
data	O
,	O
these	O
scores	O
show	O
that	O
LSTM	B-Method
+	O
A	O
managed	O
to	O
generalize	O
well	O
beyond	O
the	O
news	O
language	O
it	O
was	O
trained	O
on	O
.	O
	
paragraph	O
:	O
Parsing	B-Metric
speed	I-Metric
.	O
	
Our	O
LSTM	B-Method
+	O
A	O
model	O
,	O
running	O
on	O
a	O
multi	B-Method
-	I-Method
core	I-Method
CPU	I-Method
using	O
batches	O
of	O
128	O
sentences	O
on	O
a	O
generic	O
unoptimized	B-Method
decoder	I-Method
,	O
can	O
parse	O
over	O
120	O
sentences	O
from	O
WSJ	B-Material
per	O
second	O
for	O
sentences	O
of	O
all	O
lengths	O
(	O
using	O
beam	O
-	O
size	O
1	O
)	O
.	O
	
This	O
is	O
better	O
than	O
the	O
speed	O
reported	O
for	O
this	O
batch	O
size	O
in	O
Figure	O
4	O
of	O
at	O
100	O
sentences	O
per	O
second	O
,	O
even	O
though	O
they	O
run	O
on	O
a	O
GPU	B-Method
and	O
only	O
on	O
sentences	O
of	O
under	O
40	O
words	O
.	O
	
Note	O
that	O
they	O
achieve	O
F1	B-Metric
score	I-Metric
on	O
this	O
subset	O
of	O
sentences	O
of	O
section	O
22	O
,	O
while	O
our	O
model	O
at	O
beam	O
-	O
size	O
1	O
achieves	O
a	O
score	O
of	O
on	O
this	O
subset	O
.	O
	
section	O
:	O
Analysis	O
	
As	O
shown	O
in	O
this	O
paper	O
,	O
the	O
attention	B-Method
mechanism	I-Method
was	O
a	O
key	O
component	O
especially	O
when	O
learning	O
from	O
a	O
relatively	O
small	O
dataset	O
.	O
	
We	O
found	O
that	O
the	O
model	O
did	O
not	O
overfit	O
and	O
learned	O
the	O
parsing	O
function	O
from	O
scratch	O
much	O
faster	O
,	O
which	O
resulted	O
in	O
a	O
model	O
which	O
generalized	O
much	O
better	O
than	O
the	O
plain	O
LSTM	B-Method
without	O
attention	O
.	O
	
One	O
of	O
the	O
most	O
interesting	O
aspects	O
of	O
attention	O
is	O
that	O
it	O
allows	O
us	O
to	O
visualize	O
to	O
interpret	O
what	O
the	O
model	O
has	O
learned	O
from	O
the	O
data	O
.	O
	
For	O
example	O
,	O
in	O
it	O
is	O
shown	O
that	O
for	O
translation	B-Task
,	O
attention	B-Task
learns	O
an	O
alignment	O
function	O
,	O
which	O
certainly	O
should	O
help	O
translating	B-Task
from	O
English	B-Material
to	O
French	B-Material
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
an	O
example	O
of	O
the	O
attention	B-Method
model	I-Method
trained	O
only	O
on	O
the	O
WSJ	B-Material
dataset	O
.	O
	
From	O
the	O
attention	O
matrix	O
,	O
where	O
each	O
column	O
is	O
the	O
attention	O
vector	O
over	O
the	O
inputs	O
,	O
it	O
is	O
clear	O
that	O
the	O
model	O
focuses	O
quite	O
sharply	O
on	O
one	O
word	O
as	O
it	O
produces	O
the	O
parse	O
tree	O
.	O
	
It	O
is	O
also	O
clear	O
that	O
the	O
focus	O
moves	O
from	O
the	O
first	O
word	O
to	O
the	O
last	O
monotonically	O
,	O
and	O
steps	O
to	O
the	O
right	O
deterministically	O
when	O
a	O
word	O
is	O
consumed	O
.	O
	
On	O
the	O
bottom	O
of	O
Figure	O
[	O
reference	O
]	O
we	O
see	O
where	O
the	O
model	O
attends	O
(	O
black	O
arrow	O
)	O
,	O
and	O
the	O
current	O
output	O
being	O
decoded	O
in	O
the	O
tree	O
(	O
black	O
circle	O
)	O
.	O
	
This	O
stack	B-Method
procedure	I-Method
is	O
learned	O
from	O
data	O
(	O
as	O
all	O
the	O
parameters	O
are	O
randomly	O
initialized	O
)	O
,	O
but	O
is	O
not	O
quite	O
a	O
simple	O
stack	B-Method
decoding	I-Method
.	O
	
Indeed	O
,	O
at	O
the	O
input	O
side	O
,	O
if	O
the	O
model	O
focuses	O
on	O
position	O
,	O
that	O
state	O
has	O
information	O
for	O
all	O
words	O
after	O
(	O
since	O
we	O
also	O
reverse	O
the	O
inputs	O
)	O
.	O
	
It	O
is	O
worth	O
noting	O
that	O
,	O
in	O
some	O
examples	O
(	O
not	O
shown	O
here	O
)	O
,	O
the	O
model	O
does	O
skip	O
words	O
.	O
	
[	O
width=1.1	O
]	O
attention_figure	O
	
section	O
:	O
Related	O
Work	O
	
The	O
task	O
of	O
syntactic	B-Task
constituency	I-Task
parsing	I-Task
has	O
received	O
a	O
tremendous	O
amount	O
of	O
attention	O
in	O
the	O
last	O
20	O
years	O
.	O
	
Traditional	O
approaches	O
to	O
constituency	B-Task
parsing	I-Task
rely	O
on	O
probabilistic	B-Method
context	I-Method
-	I-Method
free	I-Method
grammars	I-Method
(	O
CFGs	B-Method
)	O
.	O
	
The	O
focus	O
in	O
these	O
approaches	O
is	O
on	O
devising	O
appropriate	O
smoothing	B-Method
techniques	I-Method
for	O
highly	O
lexicalized	O
and	O
thus	O
rare	O
events	O
or	O
carefully	O
crafting	O
the	O
model	O
structure	O
.	O
	
partially	O
alleviate	O
the	O
heavy	O
reliance	O
on	O
manual	B-Task
modeling	I-Task
of	I-Task
linguistic	I-Task
structure	I-Task
by	O
using	O
latent	O
variables	O
to	O
learn	O
a	O
more	O
articulated	B-Method
model	I-Method
.	O
	
However	O
,	O
their	O
model	O
still	O
depends	O
on	O
a	O
CFG	B-Method
backbone	I-Method
and	O
is	O
thereby	O
potentially	O
restricted	O
in	O
its	O
capacity	O
.	O
	
Early	O
neural	B-Method
network	I-Method
approaches	I-Method
to	O
parsing	B-Task
,	O
for	O
example	O
by	O
also	O
relied	O
on	O
strong	O
linguistic	O
insights	O
.	O
	
introduced	O
Incremental	B-Method
Sigmoid	I-Method
Belief	I-Method
Networks	I-Method
for	O
syntactic	B-Task
parsing	I-Task
.	O
	
By	O
constructing	O
the	O
model	B-Method
structure	I-Method
incrementally	O
,	O
they	O
are	O
able	O
to	O
avoid	O
making	O
strong	O
independence	O
assumptions	O
but	O
inference	B-Task
becomes	O
intractable	O
.	O
	
To	O
avoid	O
complex	O
inference	B-Method
methods	I-Method
,	O
propose	O
a	O
recurrent	B-Method
neural	I-Method
network	I-Method
where	O
parse	O
trees	O
are	O
decomposed	O
into	O
a	O
stack	O
of	O
independent	O
levels	O
.	O
	
Unfortunately	O
,	O
this	O
decomposition	O
breaks	O
for	O
long	O
sentences	O
and	O
their	O
accuracy	B-Metric
on	O
longer	O
sentences	O
falls	O
quite	O
significantly	O
behind	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
.	O
	
used	O
a	O
tree	B-Method
-	I-Method
structured	I-Method
neural	I-Method
network	I-Method
to	O
score	O
candidate	O
parse	O
trees	O
.	O
	
Their	O
model	O
however	O
relies	O
again	O
on	O
the	O
CFG	O
assumption	O
and	O
furthermore	O
can	O
only	O
be	O
used	O
to	O
score	O
candidate	O
trees	O
rather	O
than	O
for	O
full	B-Task
inference	I-Task
.	O
	
Our	O
LSTM	B-Method
model	O
significantly	O
differs	O
from	O
all	O
these	O
models	O
,	O
as	O
it	O
makes	O
no	O
assumptions	O
about	O
the	O
task	O
.	O
	
As	O
a	O
sequence	B-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
prediction	I-Method
model	I-Method
it	O
is	O
somewhat	O
related	O
to	O
the	O
incremental	B-Method
parsing	I-Method
models	I-Method
,	O
pioneered	O
by	O
and	O
extended	O
by	O
.	O
	
Such	O
linear	B-Method
time	I-Method
parsers	I-Method
however	O
typically	O
need	O
some	O
task	O
-	O
specific	O
constraints	O
and	O
might	O
build	O
up	O
the	O
parse	O
in	O
multiple	O
passes	O
.	O
	
Relatedly	O
,	O
present	O
excellent	O
parsing	B-Task
results	O
with	O
a	O
single	O
left	O
-	O
to	O
-	O
right	O
pass	O
,	O
but	O
require	O
a	O
stack	O
to	O
explicitly	O
delay	O
making	O
decisions	O
and	O
a	O
parsing	O
-	O
specific	O
transition	B-Method
strategy	I-Method
in	O
order	O
to	O
achieve	O
good	O
parsing	B-Metric
accuracies	I-Metric
.	O
	
The	O
LSTM	B-Method
in	O
contrast	O
uses	O
its	O
short	B-Method
term	I-Method
memory	I-Method
to	O
model	O
the	O
complex	O
underlying	O
structure	O
that	O
connects	O
the	O
input	O
-	O
output	O
pairs	O
.	O
	
Recently	O
,	O
researchers	O
have	O
developed	O
a	O
number	O
of	O
neural	B-Method
network	I-Method
models	I-Method
that	O
can	O
be	O
applied	O
to	O
general	B-Task
sequence	I-Task
-	I-Task
to	I-Task
-	I-Task
sequence	I-Task
problems	I-Task
.	O
	
was	O
the	O
first	O
to	O
propose	O
a	O
differentiable	B-Method
attention	I-Method
mechanism	I-Method
for	O
the	O
general	O
problem	O
of	O
handwritten	B-Task
text	I-Task
synthesis	I-Task
,	O
although	O
his	O
approach	O
assumed	O
a	O
monotonic	O
alignment	O
between	O
the	O
input	O
and	O
output	O
sequences	O
.	O
	
Later	O
,	O
introduced	O
a	O
more	O
general	O
attention	B-Method
model	I-Method
that	O
does	O
not	O
assume	O
a	O
monotonic	O
alignment	O
,	O
and	O
applied	O
it	O
to	O
machine	B-Task
translation	I-Task
,	O
and	O
applied	O
the	O
same	O
model	O
to	O
speech	B-Task
recognition	I-Task
.	O
	
used	O
a	O
convolutional	B-Method
neural	I-Method
network	I-Method
to	O
encode	O
a	O
variable	O
-	O
sized	O
input	O
sentence	O
into	O
a	O
vector	O
of	O
a	O
fixed	O
dimension	O
and	O
used	O
a	O
RNN	B-Method
to	O
produce	O
the	O
output	O
sentence	O
.	O
	
Essentially	O
the	O
same	O
model	O
has	O
been	O
used	O
by	O
to	O
successfully	O
learn	O
to	O
generate	O
image	B-Task
captions	I-Task
.	O
	
Finally	O
,	O
already	O
in	O
1990	O
experimented	O
with	O
applying	O
recurrent	B-Method
neural	I-Method
networks	I-Method
to	O
the	O
problem	O
of	O
syntactic	B-Task
parsing	I-Task
.	O
	
section	O
:	O
Conclusions	O
	
In	O
this	O
work	O
,	O
we	O
have	O
shown	O
that	O
generic	O
sequence	B-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
approaches	I-Method
can	O
achieve	O
excellent	O
results	O
on	O
syntactic	B-Task
constituency	I-Task
parsing	I-Task
with	O
relatively	O
little	O
effort	O
or	O
tuning	O
.	O
	
In	O
addition	O
,	O
while	O
we	O
found	O
the	O
model	O
of	O
Sutskever	O
et	O
al	O
.	O
to	O
not	O
be	O
particularly	O
data	O
efficient	O
,	O
the	O
attention	B-Method
model	I-Method
of	O
Bahdanau	O
et	O
al	O
.	O
was	O
found	O
to	O
be	O
highly	O
data	O
efficient	O
,	O
as	O
it	O
has	O
matched	O
the	O
performance	O
of	O
the	O
BerkeleyParser	B-Method
when	O
trained	O
on	O
a	O
small	O
human	O
-	O
annotated	O
parsing	O
dataset	O
.	O
	
Finally	O
,	O
we	O
showed	O
that	O
synthetic	O
datasets	O
with	O
imperfect	O
labels	O
can	O
be	O
highly	O
useful	O
,	O
as	O
our	O
models	O
have	O
substantially	O
outperformed	O
the	O
models	O
that	O
have	O
been	O
used	O
to	O
create	O
their	O
training	O
data	O
.	O
	
We	O
suspect	O
it	O
is	O
the	O
case	O
due	O
to	O
the	O
different	O
natures	O
of	O
the	O
teacher	B-Method
model	I-Method
and	O
the	O
student	B-Method
model	I-Method
:	O
the	O
student	B-Method
model	I-Method
has	O
likely	O
viewed	O
the	O
teacher	O
’s	O
errors	O
as	O
noise	O
which	O
it	O
has	O
been	O
able	O
to	O
ignore	O
.	O
	
This	O
approach	O
was	O
so	O
successful	O
that	O
we	O
obtained	O
a	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
result	O
in	O
syntactic	B-Task
constituency	I-Task
parsing	I-Task
with	O
a	O
single	O
attention	B-Method
model	I-Method
,	O
which	O
also	O
means	O
that	O
the	O
model	O
is	O
exceedingly	O
fast	O
.	O
	
This	O
work	O
shows	O
that	O
domain	B-Method
independent	I-Method
models	I-Method
with	O
excellent	O
learning	B-Method
algorithms	I-Method
can	O
match	O
and	O
even	O
outperform	O
domain	B-Method
specific	I-Method
models	I-Method
.	O
	
Acknowledgement	O
.	O
	
We	O
would	O
like	O
to	O
thank	O
Amin	O
Ahmad	O
,	O
Dan	O
Bikel	O
and	O
Jonni	O
Kanerva	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Occlusion	B-Method
-	I-Method
aware	I-Method
R	I-Method
-	I-Method
CNN	I-Method
:	O
Detecting	B-Task
Pedestrians	I-Task
in	O
a	O
Crowd	O
	
Pedestrian	B-Task
detection	I-Task
in	O
crowded	B-Task
scenes	I-Task
is	O
a	O
challenging	O
problem	O
since	O
the	O
pedestrians	O
often	O
gather	O
together	O
and	O
occlude	O
each	O
other	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
new	O
occlusion	B-Method
-	I-Method
aware	I-Method
R	I-Method
-	I-Method
CNN	I-Method
(	O
OR	B-Method
-	I-Method
CNN	I-Method
)	O
to	O
improve	O
the	O
detection	B-Metric
accuracy	I-Metric
in	O
the	O
crowd	O
.	O
	
Specifically	O
,	O
we	O
design	O
a	O
new	O
aggregation	O
loss	O
to	O
enforce	O
proposals	O
to	O
be	O
close	O
and	O
locate	O
compactly	O
to	O
the	O
corresponding	O
objects	O
.	O
	
Meanwhile	O
,	O
we	O
use	O
a	O
new	O
part	B-Method
occlusion	I-Method
-	I-Method
aware	I-Method
region	I-Method
of	I-Method
interest	I-Method
(	O
PORoI	B-Method
)	O
pooling	O
unit	O
to	O
replace	O
the	O
RoI	B-Method
pooling	I-Method
layer	I-Method
in	O
order	O
to	O
integrate	O
the	O
prior	O
structure	O
information	O
of	O
human	O
body	O
with	O
visibility	O
prediction	O
into	O
the	O
network	O
to	O
handle	O
occlusion	O
.	O
	
Our	O
detector	O
is	O
trained	O
in	O
an	O
end	O
-	O
to	O
-	O
end	O
fashion	O
,	O
which	O
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
three	O
pedestrian	O
detection	O
datasets	O
,	O
i.e.	O
,	O
CityPersons	B-Material
,	O
ETH	B-Material
,	O
and	O
INRIA	B-Material
,	O
and	O
performs	O
on	O
-	O
pair	O
with	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
arts	O
on	O
Caltech	B-Material
.	O
	
section	O
:	O
Introduction	O
	
Pedestrian	B-Task
detection	I-Task
is	O
an	O
important	O
research	O
topic	O
in	O
computer	B-Task
vision	I-Task
field	I-Task
with	O
various	O
applications	O
,	O
such	O
as	O
autonomous	B-Task
driving	I-Task
,	O
video	B-Task
surveillance	I-Task
,	O
and	O
robotics	B-Task
,	O
which	O
aims	O
to	O
predict	O
a	O
series	O
of	O
bounding	O
boxes	O
enclosing	O
pedestrian	O
instances	O
in	O
an	O
image	O
.	O
	
Recent	O
advances	O
in	O
object	B-Task
detection	I-Task
are	O
driven	O
by	O
the	O
success	O
of	O
deep	B-Method
convolutional	I-Method
neural	I-Method
networks	I-Method
(	O
CNNs	B-Method
)	O
,	O
which	O
uses	O
the	O
bounding	B-Method
box	I-Method
regression	I-Method
techniques	I-Method
to	O
accurately	O
localize	O
the	O
objects	O
based	O
on	O
the	O
deep	O
features	O
.	O
	
Actually	O
,	O
in	O
real	B-Task
life	I-Task
complex	I-Task
scenarios	I-Task
,	O
occlusion	B-Task
is	O
one	O
of	O
the	O
most	O
significant	O
challenges	O
in	O
detecting	B-Task
pedestrian	I-Task
,	O
especially	O
in	O
the	O
crowded	O
scenes	O
.	O
	
For	O
example	O
,	O
as	O
pointed	O
out	O
in	O
,	O
annotated	O
pedestrians	O
are	O
occluded	O
by	O
other	O
pedestrians	O
in	O
the	O
CityPersons	B-Material
dataset	I-Material
.	O
	
Previous	O
methods	O
only	O
require	O
each	O
predicted	O
bounding	O
box	O
to	O
be	O
close	O
to	O
its	O
designated	O
ground	O
truth	O
,	O
without	O
considering	O
the	O
relations	O
among	O
them	O
.	O
	
Thus	O
,	O
they	O
make	O
the	O
detectors	B-Method
sensitive	O
to	O
the	O
threshold	O
of	O
non	B-Task
-	I-Task
maximum	I-Task
suppression	I-Task
(	O
NMS	B-Task
)	O
in	O
the	O
crowded	O
scenes	O
,	O
wherein	O
filling	O
with	O
occlusions	O
.	O
	
To	O
that	O
end	O
,	O
Wang	O
et	O
al	O
.	O
	
[	O
]	O
design	O
a	O
repulsion	B-Method
loss	I-Method
,	O
which	O
not	O
only	O
pushes	O
each	O
proposal	O
to	O
approach	O
its	O
designated	O
target	O
,	O
but	O
also	O
to	O
keep	O
it	O
away	O
from	O
the	O
other	O
ground	O
truth	O
objects	O
and	O
their	O
corresponding	O
designated	O
proposals	O
.	O
	
However	O
,	O
it	O
is	O
difficult	O
to	O
control	O
the	O
balance	O
between	O
the	O
repulsion	O
and	O
attraction	O
terms	O
in	O
the	O
loss	O
function	O
to	O
handle	O
the	O
overlapping	O
pedestrians	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
new	O
occlusion	B-Method
-	I-Method
aware	I-Method
R	I-Method
-	I-Method
CNN	I-Method
(	O
OR	B-Method
-	I-Method
CNN	I-Method
)	O
based	O
on	O
the	O
Faster	O
R	O
-	O
CNN	B-Method
detection	O
framework	O
to	O
mitigate	O
the	O
impact	O
of	O
occlusion	B-Task
challenge	I-Task
.	O
	
Specifically	O
,	O
to	O
reduce	O
the	O
false	O
detections	O
of	O
the	O
adjacent	O
overlapping	O
pedestrians	O
,	O
we	O
expect	O
the	O
proposals	O
to	O
be	O
close	O
and	O
locate	O
compactly	O
to	O
the	O
corresponding	O
objects	O
.	O
	
Thus	O
,	O
inspired	O
by	O
the	O
herd	O
behavior	O
in	O
psychology	O
,	O
we	O
design	O
a	O
new	O
loss	B-Method
function	I-Method
,	O
called	O
aggregation	B-Method
loss	I-Method
(	O
AggLoss	B-Method
)	O
,	O
not	O
only	O
to	O
enforce	O
proposals	O
to	O
be	O
close	O
to	O
the	O
corresponding	O
objects	O
,	O
but	O
also	O
to	O
minimize	O
the	O
internal	O
region	O
distances	O
of	O
proposals	O
associated	O
with	O
the	O
same	O
objects	O
.	O
	
Meanwhile	O
,	O
to	O
effectively	O
handle	O
partial	O
occlusion	O
,	O
we	O
propose	O
a	O
new	O
part	B-Method
occlusion	I-Method
-	I-Method
aware	I-Method
region	I-Method
of	I-Method
interest	I-Method
(	O
PORoI	B-Method
)	O
pooling	O
unit	O
to	O
replace	O
the	O
original	O
RoI	B-Method
pooling	I-Method
layer	I-Method
in	O
the	O
second	O
stage	O
Fast	O
R	O
-	O
CNN	B-Method
module	O
of	O
the	O
detector	B-Method
,	O
which	O
integrates	O
the	O
prior	O
structure	O
information	O
of	O
human	O
body	O
with	O
visibility	O
prediction	O
into	O
the	O
network	O
.	O
	
That	O
is	O
,	O
we	O
first	O
partition	O
the	O
pedestrian	O
region	O
into	O
five	O
parts	O
,	O
and	O
pool	O
the	O
features	O
under	O
each	O
part	O
’s	O
projection	O
as	O
well	O
as	O
the	O
whole	O
proposal	O
’s	O
projection	O
onto	O
the	O
feature	O
map	O
into	O
fixed	O
-	O
length	O
feature	O
vectors	O
by	O
adaptively	O
-	O
sized	O
pooling	O
bins	O
.	O
	
After	O
that	O
,	O
we	O
use	O
the	O
learned	O
sub	B-Method
-	I-Method
network	I-Method
to	O
predict	O
the	O
visibility	O
score	O
of	O
each	O
part	O
to	O
combine	O
the	O
extracted	O
features	O
for	O
pedestrian	B-Task
detection	I-Task
.	O
	
Several	O
experiments	O
are	O
carried	O
out	O
on	O
four	O
pedestrian	O
detection	O
datasets	O
,	O
i.e.	O
,	O
CityPersons	B-Material
,	O
Caltech	B-Material
,	O
ETH	B-Material
and	O
INRIA	B-Material
,	O
to	O
demonstrate	O
the	O
superiority	O
of	O
the	O
proposed	O
method	O
,	O
especially	O
for	O
the	O
crowded	O
scenes	O
.	O
	
Notably	O
,	O
the	O
proposed	O
OR	B-Method
-	I-Method
CNN	I-Method
method	I-Method
achieves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
with	O
MR	B-Method
on	O
the	O
CityPersons	B-Material
dataset	I-Material
,	O
MR	B-Method
on	O
the	O
ETH	B-Material
dataset	I-Material
,	O
and	O
MR	B-Method
on	O
the	O
INRIA	B-Material
dataset	I-Material
.	O
	
The	O
main	O
contributions	O
of	O
this	O
work	O
are	O
summarized	O
as	O
follows	O
.	O
	
We	O
propose	O
a	O
new	O
occlusion	B-Method
-	I-Method
aware	I-Method
R	I-Method
-	I-Method
CNN	I-Method
method	O
,	O
which	O
uses	O
a	O
new	O
designed	O
AggLoss	B-Method
to	O
enforce	O
proposals	O
to	O
be	O
close	O
to	O
the	O
corresponding	O
objects	O
,	O
as	O
well	O
as	O
minimize	O
the	O
internal	O
region	O
distances	O
of	O
proposals	O
associated	O
with	O
the	O
same	O
objects	O
.	O
	
We	O
design	O
a	O
new	O
PORoI	B-Method
pooling	O
unit	O
to	O
replace	O
the	O
RoI	B-Method
pooling	I-Method
layer	I-Method
in	O
the	O
second	O
Fast	O
R	O
-	O
CNN	B-Method
module	O
to	O
integrate	O
the	O
prior	O
structure	O
information	O
of	O
human	O
body	O
with	O
visibility	O
prediction	O
into	O
the	O
network	O
.	O
	
Several	O
experiments	O
are	O
carried	O
out	O
on	O
four	O
challenging	O
pedestrian	O
detection	O
datasets	O
,	O
i.e.	O
,	O
CityPersons	B-Material
,	O
Caltech	B-Material
,	O
ETH	B-Material
,	O
and	O
INRIA	B-Material
,	O
to	O
demonstrate	O
the	O
superiority	O
of	O
the	O
proposed	O
method	O
.	O
	
section	O
:	O
Related	O
Work	O
	
Generic	B-Task
Object	I-Task
Detection	I-Task
.	O
	
Early	O
generic	B-Method
object	I-Method
detectors	I-Method
rely	O
on	O
the	O
sliding	B-Method
window	I-Method
paradigm	I-Method
based	O
on	O
the	O
hand	O
-	O
crafted	O
features	O
and	O
classifiers	B-Method
to	O
find	O
the	O
objects	O
of	O
interest	O
.	O
	
In	O
recent	O
years	O
,	O
with	O
the	O
advent	O
of	O
deep	B-Method
convolutional	I-Method
neural	I-Method
network	I-Method
(	O
CNN	B-Method
)	O
,	O
a	O
new	O
generation	O
of	O
more	O
effective	O
object	B-Method
detection	I-Method
methods	I-Method
based	O
on	O
CNN	B-Method
significantly	O
improve	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performances	O
,	O
which	O
can	O
be	O
roughly	O
divided	O
into	O
two	O
categories	O
,	O
i.e.	O
,	O
the	O
one	B-Method
-	I-Method
stage	I-Method
approach	I-Method
and	O
the	O
two	O
-	O
stage	B-Method
approach	I-Method
.	O
	
The	O
one	O
-	O
stage	O
approach	O
directly	O
predicts	O
object	O
class	O
label	O
and	O
regresses	O
object	O
bounding	O
box	O
based	O
on	O
the	O
pre	O
-	O
tiled	O
anchor	O
boxes	O
using	O
deep	O
CNNs	B-Method
.	O
	
The	O
main	O
advantage	O
of	O
the	O
one	O
-	O
stage	B-Method
approach	I-Method
is	O
its	O
high	O
computational	B-Metric
efficiency	I-Metric
.	O
	
In	O
contrast	O
to	O
the	O
one	O
-	O
stage	B-Method
approach	I-Method
,	O
the	O
two	O
-	O
stage	O
approach	O
always	O
achieves	O
top	O
accuracy	B-Metric
on	O
several	O
benchmarks	O
,	O
which	O
first	O
generates	O
a	O
pool	O
of	O
object	O
proposals	O
by	O
a	O
separated	B-Method
proposal	I-Method
generator	I-Method
(	O
e.g.	O
,	O
Selective	B-Method
Search	I-Method
,	O
EdgeBoxes	B-Method
,	O
and	O
RPN	B-Method
)	O
,	O
and	O
then	O
predicts	O
the	O
class	O
label	O
and	O
accurate	O
location	O
and	O
size	O
of	O
each	O
proposal	O
.	O
	
Pedestrian	B-Task
Detection	I-Task
.	O
	
Even	O
as	O
one	O
of	O
the	O
long	O
-	O
standing	O
problems	O
in	O
computer	B-Task
vision	I-Task
field	I-Task
with	O
an	O
extensive	O
literature	O
,	O
pedestrian	B-Task
detection	I-Task
still	O
receives	O
considerable	O
interests	O
with	O
a	O
wide	O
range	O
of	O
applications	O
.	O
	
A	O
common	O
paradigm	O
to	O
address	O
this	O
problem	O
is	O
to	O
train	O
a	O
pedestrian	B-Method
detector	I-Method
that	O
exhaustively	O
operates	O
on	O
the	O
sub	O
-	O
images	O
across	O
all	O
locations	O
and	O
scales	O
.	O
	
Dalal	O
and	O
Triggs	O
design	O
the	O
histograms	B-Method
of	I-Method
oriented	I-Method
gradient	I-Method
(	I-Method
HOG	I-Method
)	I-Method
descriptors	I-Method
and	O
support	B-Method
vector	I-Method
machine	I-Method
(	O
SVM	B-Method
	
)	O
classifier	B-Method
for	O
human	B-Task
detection	I-Task
.	O
	
Dollár	O
et	O
al	O
.	O
	
[	O
]	O
demonstrate	O
that	O
using	O
features	O
from	O
multiple	O
channels	O
can	O
significantly	O
improve	O
the	O
performance	O
.	O
	
Zhang	O
et	O
al	O
.	O
	
[	O
]	O
provide	O
a	O
systematic	O
analysis	O
for	O
the	O
filtered	O
channel	O
features	O
,	O
and	O
find	O
that	O
with	O
the	O
proper	O
filter	B-Method
bank	I-Method
,	O
filtered	O
channel	O
features	O
can	O
reach	O
top	O
detection	B-Metric
quality	I-Metric
.	O
	
Paisitkriangkrai	O
et	O
al	O
.	O
	
[	O
]	O
design	O
a	O
new	O
features	O
built	O
on	O
the	O
basis	O
of	O
low	O
-	O
level	O
visual	O
features	O
and	O
spatial	B-Method
pooling	I-Method
,	O
and	O
directly	O
optimize	O
the	O
partial	B-Metric
area	I-Metric
under	O
the	O
ROC	B-Metric
curve	I-Metric
for	O
better	O
performance	O
.	O
	
Recently	O
,	O
pedestrian	B-Task
detection	I-Task
is	O
dominated	O
by	O
the	O
CNN	B-Method
-	O
based	O
methods	O
(	O
e.g.	O
,	O
)	O
.	O
	
Sermanet	O
et	O
al	O
.	O
	
[	O
]	O
present	O
an	O
unsupervised	B-Method
method	I-Method
using	O
the	O
convolutional	B-Method
sparse	I-Method
coding	I-Method
to	O
pre	O
-	O
train	O
CNN	B-Method
for	O
pedestrian	B-Task
detection	I-Task
.	O
	
In	O
,	O
a	O
complexity	B-Method
-	I-Method
aware	I-Method
cascaded	I-Method
detector	I-Method
is	O
proposed	O
for	O
an	O
optimal	O
trade	O
-	O
off	O
between	O
accuracy	B-Metric
and	O
speed	B-Metric
.	O
	
Angelova	O
et	O
al	O
.	O
	
[	O
]	O
combine	O
the	O
ideas	O
of	O
fast	B-Method
cascade	I-Method
and	O
a	O
deep	B-Method
network	I-Method
to	O
detect	O
pedestrian	B-Task
.	O
	
Yang	O
et	O
al	O
.	O
	
[	O
]	O
use	O
scale	B-Method
-	I-Method
dependent	I-Method
pooling	I-Method
and	O
layer	B-Method
-	I-Method
wise	I-Method
cascaded	I-Method
rejection	I-Method
classifiers	I-Method
to	O
detect	O
objects	O
efficiently	O
.	O
	
Zhang	O
et	O
al	O
.	O
	
[	O
]	O
present	O
an	O
effective	O
pipeline	O
for	O
pedestrian	B-Task
detection	I-Task
via	O
using	O
RPN	B-Method
followed	O
by	O
boosted	B-Method
forests	I-Method
.	O
	
To	O
jointly	O
learn	O
pedestrian	B-Task
detection	I-Task
with	O
the	O
given	O
extra	O
features	O
,	O
a	O
novel	O
network	B-Method
architecture	I-Method
is	O
presented	O
in	O
.	O
	
Li	O
et	O
al	O
.	O
	
[	O
]	O
use	O
multiple	O
built	B-Method
-	I-Method
in	I-Method
sub	I-Method
-	I-Method
networks	I-Method
to	O
adaptively	O
detect	O
pedestrians	O
across	O
scales	O
.	O
	
Brazil	O
et	O
al	O
.	O
	
[	O
]	O
exploit	O
weakly	O
annotated	O
boxes	O
via	O
a	O
segmentation	B-Method
infusion	I-Method
network	I-Method
to	O
achieve	O
considerable	O
performance	O
gains	O
.	O
	
However	O
,	O
occlusion	O
still	O
remains	O
one	O
of	O
the	O
most	O
significant	O
challenges	O
in	O
pedestrian	B-Task
detection	I-Task
,	O
which	O
increases	O
the	O
difficulty	O
in	O
pedestrian	B-Task
localization	I-Task
.	O
	
Several	O
methods	O
use	O
part	B-Method
-	I-Method
based	I-Method
model	I-Method
to	O
describe	O
the	O
pedestrian	B-Task
in	I-Task
occlusion	I-Task
handling	I-Task
,	O
which	O
learn	O
a	O
series	O
of	O
part	B-Method
detectors	I-Method
and	O
design	O
some	O
mechanisms	O
to	O
fuse	O
the	O
part	B-Method
detection	I-Method
results	O
to	O
localize	O
partially	O
occluded	O
pedestrians	O
.	O
	
Besides	O
the	O
part	B-Method
-	I-Method
based	I-Method
model	I-Method
,	O
Leibe	O
et	O
al	O
.	O
	
[	O
]	O
propose	O
an	O
implicit	B-Method
shape	I-Method
model	I-Method
to	O
generate	O
a	O
set	O
of	O
pedestrian	O
hypotheses	O
that	O
are	O
further	O
refined	O
to	O
obtain	O
the	O
visible	O
regions	O
.	O
	
Wang	O
et	O
al	O
.	O
	
[	O
]	O
divide	O
the	O
template	O
of	O
pedestrian	O
into	O
a	O
set	O
of	O
blocks	O
and	O
conduct	O
occlusion	B-Method
reasoning	I-Method
by	O
estimating	O
the	O
visibility	O
status	O
of	O
each	O
block	O
.	O
	
Ouyang	O
et	O
al	O
.	O
	
[	O
]	O
exploit	O
multi	B-Method
-	I-Method
pedestrian	I-Method
detectors	I-Method
to	O
aid	O
single	O
-	O
pedestrian	B-Method
detectors	I-Method
to	O
handle	O
partial	O
occlusions	O
,	O
especially	O
when	O
the	O
pedestrians	O
gather	O
together	O
and	O
occlude	O
each	O
other	O
in	O
real	O
-	O
world	O
scenarios	O
.	O
	
In	O
,	O
a	O
set	O
of	O
occlusion	O
patterns	O
of	O
pedestrians	O
are	O
discovered	O
to	O
learn	O
a	O
mixture	B-Method
of	I-Method
occlusion	I-Method
-	I-Method
specific	I-Method
detectors	I-Method
.	O
	
Zhou	O
et	O
al	O
.	O
	
[	O
]	O
propose	O
to	O
jointly	O
learn	O
part	B-Method
detectors	I-Method
so	O
as	O
to	O
exploit	O
part	O
correlations	O
and	O
reduce	O
the	O
computational	B-Metric
cost	I-Metric
.	O
	
Wang	O
et	O
al	O
.	O
	
[	O
]	O
introduce	O
a	O
novel	O
bounding	B-Method
box	I-Method
regression	I-Method
loss	I-Method
to	O
detect	O
pedestrians	B-Task
in	O
the	O
crowd	O
scenes	O
.	O
	
Although	O
numerous	O
pedestrian	B-Method
detection	I-Method
methods	I-Method
are	O
presented	O
in	O
literature	O
,	O
how	O
to	O
robustly	O
detect	O
each	O
individual	O
pedestrian	O
in	O
crowded	O
scenarios	O
is	O
still	O
one	O
of	O
the	O
most	O
critical	O
issues	O
for	O
pedestrian	B-Task
detectors	I-Task
.	O
	
section	O
:	O
Occlusion	B-Method
-	I-Method
aware	I-Method
R	I-Method
-	I-Method
CNN	I-Method
	
Our	O
occlusion	B-Method
-	I-Method
aware	I-Method
R	I-Method
-	I-Method
CNN	I-Method
detector	O
follows	O
the	O
adaptive	O
Faster	O
R	O
-	O
CNN	B-Method
detection	O
framework	O
for	O
pedestrian	B-Task
detection	I-Task
,	O
with	O
the	O
new	O
designed	O
aggregation	B-Metric
loss	I-Metric
(	O
Section	O
[	O
reference	O
]	O
)	O
,	O
and	O
the	O
PORoI	B-Method
pooling	O
unit	O
(	O
Section	O
[	O
reference	O
]	O
)	O
.	O
	
Specifically	O
,	O
Faster	O
R	O
-	O
CNN	B-Method
consists	O
of	O
two	O
modules	O
,	O
i.e.	O
,	O
the	O
first	O
region	B-Method
proposal	I-Method
network	I-Method
(	O
RPN	B-Method
)	O
module	O
and	O
the	O
second	O
Fast	O
R	O
-	O
CNN	B-Method
module	O
.	O
	
The	O
RPN	B-Method
module	O
is	O
designed	O
to	O
generate	O
high	O
-	O
quality	O
region	O
proposals	O
,	O
and	O
the	O
Fast	O
R	O
-	O
CNN	B-Method
module	O
is	O
used	O
to	O
classify	O
and	O
regress	O
the	O
accurate	O
locations	O
and	O
sizes	O
of	O
objects	O
,	O
based	O
on	O
the	O
generated	O
proposals	O
.	O
	
To	O
effectively	O
generate	O
accurate	B-Task
region	I-Task
proposals	I-Task
in	O
the	O
first	O
RPN	B-Method
module	O
,	O
we	O
design	O
the	O
AggLoss	B-Method
term	I-Method
to	O
enforce	O
the	O
proposals	O
locate	O
closely	O
and	O
compactly	O
to	O
the	O
ground	O
-	O
truth	O
object	O
,	O
which	O
is	O
defined	O
as	O
where	O
is	O
the	O
index	O
of	O
anchor	O
in	O
a	O
mini	O
-	O
batch	O
,	O
and	O
are	O
the	O
predicted	O
confidence	O
of	O
the	O
-	O
th	O
anchor	O
being	O
a	O
pedestrian	O
and	O
the	O
predicted	O
coordinates	O
of	O
the	O
pedestrian	O
,	O
and	O
are	O
the	O
associated	O
ground	O
truth	O
class	O
label	O
and	O
coordinates	O
of	O
the	O
-	O
th	O
anchor	O
,	O
is	O
the	O
hyperparameters	O
used	O
to	O
balance	O
the	O
two	O
loss	O
terms	O
,	O
is	O
the	O
classification	B-Metric
loss	I-Metric
,	O
and	O
is	O
the	O
AggLoss	B-Method
(	O
see	O
Section	O
[	O
reference	O
]	O
)	O
.	O
	
We	O
use	O
the	O
log	O
loss	O
to	O
calculate	O
the	O
classification	O
loss	O
over	O
two	O
classes	O
(	O
pedestrian	O
vs.	O
background	O
)	O
,	O
i.e.	O
,	O
where	O
is	O
the	O
total	O
number	O
of	O
anchors	O
in	O
classification	B-Task
.	O
	
subsection	O
:	O
Aggregation	B-Task
Loss	I-Task
	
To	O
reduce	O
the	O
false	O
detections	O
of	O
the	O
adjacent	O
overlapping	O
pedestrians	O
,	O
we	O
enforce	O
proposals	O
to	O
be	O
close	O
and	O
locate	O
compactly	O
to	O
the	O
corresponding	O
ground	O
truth	O
objects	O
.	O
	
To	O
that	O
end	O
,	O
we	O
design	O
a	O
new	O
aggregation	B-Method
loss	I-Method
(	O
AggLoss	B-Method
)	I-Method
for	O
both	O
the	O
region	B-Method
proposal	I-Method
network	I-Method
(	O
RPN	B-Method
)	O
and	O
Fast	O
R	O
-	O
CNN	B-Method
modules	O
in	O
the	O
Faster	O
R	O
-	O
CNN	B-Method
algorithm	O
,	O
which	O
is	O
a	O
multi	B-Task
-	I-Task
task	I-Task
loss	I-Task
pushing	O
proposals	O
to	O
be	O
close	O
to	O
the	O
corresponding	O
ground	O
truth	O
object	O
,	O
while	O
minimizing	O
the	O
internal	O
region	O
distances	O
of	O
proposals	O
associated	O
with	O
the	O
same	O
objects	O
,	O
i.e.	O
,	O
where	O
is	O
the	O
regression	O
loss	O
which	O
requires	O
each	O
proposal	O
to	O
approach	O
the	O
designated	O
ground	O
truth	O
,	O
and	O
is	O
the	O
compactness	O
loss	O
which	O
enforces	O
proposals	O
locate	O
compactly	O
to	O
the	O
designated	O
ground	O
truth	O
object	O
,	O
and	O
is	O
the	O
hyper	O
-	O
parameters	O
used	O
to	O
balance	O
the	O
two	O
loss	O
terms	O
.	O
	
Similar	O
to	O
Fast	O
R	O
-	O
CNN	B-Method
,	O
we	O
use	O
the	O
smooth	O
L1	O
loss	O
as	O
the	O
regression	O
loss	O
to	O
measure	O
the	O
accuracy	B-Metric
of	O
predicted	O
bounding	O
boxes	O
,	O
i.e.	O
,	O
where	O
is	O
the	O
total	O
number	O
of	O
anchors	O
in	O
regression	B-Task
,	O
and	O
is	O
the	O
smooth	O
L1	O
loss	O
of	O
the	O
predicted	O
bounding	O
box	O
.	O
	
The	O
compactness	O
term	O
is	O
designed	O
to	O
consider	O
the	O
attractiveness	O
among	O
proposals	O
associated	O
with	O
the	O
same	O
ground	O
truth	O
object	O
.	O
	
In	O
this	O
way	O
,	O
we	O
can	O
make	O
the	O
proposals	O
to	O
locate	O
compactly	O
around	O
the	O
ground	O
truth	O
to	O
reduce	O
the	O
false	O
detections	O
of	O
adjacent	O
overlapping	O
objects	O
.	O
	
Specifically	O
,	O
we	O
set	O
to	O
be	O
the	O
ground	O
truth	O
set	O
associated	O
with	O
more	O
than	O
one	O
anchor	O
,	O
and	O
to	O
be	O
the	O
index	O
sets	O
of	O
the	O
associated	O
anchors	O
corresponding	O
to	O
the	O
ground	O
truth	O
objects	O
,	O
i.e.	O
,	O
the	O
anchors	O
indexed	O
by	O
are	O
associated	O
to	O
the	O
ground	O
truth	O
,	O
where	O
is	O
the	O
total	O
number	O
of	O
ground	O
-	O
truth	O
object	O
associated	O
with	O
more	O
than	O
one	O
anchor	O
.	O
	
Thus	O
,	O
we	O
have	O
,	O
for	O
,	O
	
and	O
.	O
	
We	O
use	O
the	O
smooth	O
L1	O
loss	O
to	O
measure	O
the	O
difference	O
between	O
the	O
average	O
predictions	O
of	O
the	O
anchors	O
indexed	O
by	O
each	O
set	O
in	O
and	O
the	O
corresponding	O
ground	O
truth	O
object	O
,	O
describing	O
the	O
compactness	O
of	O
predicted	O
bounding	O
boxes	O
with	O
respect	O
to	O
the	O
ground	O
truth	O
object	O
,	O
i.e.	O
,	O
where	O
is	O
the	O
total	O
number	O
of	O
ground	O
truth	O
object	O
associated	O
with	O
more	O
than	O
one	O
anchor	O
(	O
i.e.	O
,	O
)	O
,	O
and	O
is	O
the	O
number	O
of	O
anchors	O
associated	O
with	O
the	O
-	O
th	O
ground	O
truth	O
object	O
.	O
	
subsection	O
:	O
Part	B-Method
Occlusion	I-Method
-	I-Method
aware	I-Method
RoI	I-Method
Pooling	I-Method
Unit	I-Method
	
In	O
real	B-Task
life	I-Task
complex	I-Task
scenarios	I-Task
,	O
occlusion	O
is	O
ubiquitous	O
challenging	O
the	O
accuracy	B-Metric
of	O
detectors	B-Task
,	O
especially	O
in	O
crowded	O
scenes	O
.	O
	
As	O
indicated	O
in	O
,	O
the	O
part	B-Method
-	I-Method
based	I-Method
model	I-Method
is	O
effective	O
in	O
handling	O
occluded	B-Task
pedestrians	I-Task
.	O
	
In	O
contrast	O
to	O
the	O
aforementioned	O
methods	O
,	O
we	O
design	O
a	O
new	O
part	B-Method
occlusion	I-Method
-	I-Method
aware	I-Method
RoI	I-Method
pooling	I-Method
unit	I-Method
to	O
integrate	O
the	O
prior	O
structure	O
information	O
of	O
human	O
body	O
with	O
visibility	B-Method
prediction	I-Method
into	O
the	O
Fast	O
R	O
-	O
CNN	B-Method
module	O
of	O
the	O
detector	B-Method
,	O
which	O
assembles	O
a	O
micro	B-Method
neural	I-Method
network	I-Method
to	O
estimate	O
the	O
part	O
occlusion	O
status	O
.	O
	
As	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
(	O
a	O
)	O
,	O
we	O
first	O
divide	O
the	O
pedestrian	O
region	O
into	O
five	O
parts	O
with	O
the	O
empirical	O
ratio	O
in	O
.	O
	
For	O
each	O
part	O
,	O
we	O
use	O
the	O
RoI	B-Method
pooling	I-Method
layer	I-Method
to	O
pool	O
the	O
features	O
into	O
a	O
small	O
feature	O
map	O
with	O
a	O
fixed	O
spatial	O
extent	O
of	O
(	O
e.g.	O
,	O
)	O
.	O
	
We	O
introduce	O
an	O
occlusion	B-Method
process	I-Method
unit	I-Method
,	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
(	O
b	O
)	O
,	O
to	O
predict	O
the	O
visibility	O
score	O
of	O
the	O
corresponding	O
part	O
based	O
on	O
the	O
pooled	O
features	O
.	O
	
Specifically	O
,	O
the	O
occlusion	B-Method
process	I-Method
unit	I-Method
is	O
constructed	O
by	O
three	O
convolutional	B-Method
layers	I-Method
followed	O
by	O
a	O
softmax	B-Method
layer	I-Method
with	O
the	O
log	O
loss	O
in	O
training	O
.	O
	
Symbolically	O
,	O
indicates	O
the	O
-	O
th	O
part	O
of	O
the	O
-	O
th	O
proposal	O
,	O
represents	O
its	O
predicted	B-Metric
visibility	I-Metric
score	I-Metric
,	O
and	O
is	O
the	O
corresponding	O
ground	B-Metric
truth	I-Metric
visibility	I-Metric
score	I-Metric
.	O
	
If	O
half	O
of	O
the	O
part	O
is	O
visible	O
,	O
,	O
otherwise	O
.	O
	
Mathematically	O
,	O
if	O
the	O
intersection	O
between	O
and	O
the	O
visible	O
region	O
of	O
ground	O
truth	O
object	O
divided	O
by	O
the	O
area	O
of	O
is	O
larger	O
than	O
the	O
threshold	O
,	O
,	O
otherwise	O
.	O
	
That	O
is	O
where	O
is	O
the	O
area	O
computing	O
function	O
,	O
is	O
the	O
region	O
of	O
,	O
is	O
the	O
visible	O
region	O
of	O
the	O
ground	O
truth	O
object	O
,	O
and	O
is	O
the	O
intersection	O
operation	O
between	O
two	O
regions	O
.	O
	
Then	O
,	O
the	O
loss	O
function	O
of	O
the	O
occlusion	B-Method
process	I-Method
unit	I-Method
is	O
calculated	O
as	O
.	O
	
After	O
that	O
,	O
we	O
apply	O
the	O
element	B-Method
-	I-Method
wise	I-Method
multiplication	I-Method
operator	I-Method
to	O
multiply	O
the	O
pooled	O
features	O
of	O
each	O
part	O
and	O
the	O
corresponding	O
predicted	O
visibility	O
score	O
to	O
generate	O
the	O
final	O
features	O
with	O
the	O
dimensions	O
.	O
	
The	O
element	B-Method
-	I-Method
wise	I-Method
summation	I-Method
operation	I-Method
is	O
further	O
used	O
to	O
combine	O
the	O
extracted	O
features	O
of	O
the	O
five	O
parts	O
and	O
the	O
whole	O
proposal	O
for	O
classification	B-Task
and	I-Task
regression	I-Task
in	O
the	O
Fast	O
R	O
-	O
CNN	B-Method
module	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
To	O
further	O
improve	O
the	O
regression	B-Metric
accuracy	I-Metric
,	O
we	O
also	O
use	O
AggLoss	B-Method
in	O
the	O
Fast	O
R	O
-	O
CNN	B-Method
module	O
,	O
which	O
is	O
defined	O
as	O
:	O
where	O
and	O
are	O
used	O
to	O
balance	O
the	O
three	O
loss	O
terms	O
,	O
and	O
are	O
the	O
classification	B-Metric
and	I-Metric
aggregation	I-Metric
losses	I-Metric
,	O
defined	O
the	O
same	O
as	O
that	O
in	O
the	O
RPN	B-Method
module	O
,	O
and	O
is	O
the	O
occlusion	O
process	O
loss	O
.	O
	
section	O
:	O
Experiments	O
	
Several	O
experiments	O
are	O
conducted	O
on	O
four	O
datasets	O
:	O
CityPersons	B-Material
,	O
Caltech	B-Material
-	O
USA	O
,	O
ETH	B-Material
,	O
and	O
INRIA	B-Material
,	O
to	O
demonstrate	O
the	O
performance	O
of	O
the	O
proposed	O
OR	B-Method
-	I-Method
CNN	I-Method
method	I-Method
.	O
	
subsection	O
:	O
Experimental	O
Setup	O
	
Our	O
OR	B-Method
-	I-Method
CNN	I-Method
detector	O
follows	O
the	O
adaptive	O
Faster	O
R	O
-	O
CNN	B-Method
framework	O
and	O
uses	O
VGG	B-Method
-	I-Method
16	I-Method
as	O
the	O
backbone	B-Method
network	I-Method
,	O
pre	O
-	O
trained	O
on	O
the	O
ILSVRC	B-Material
CLS	I-Material
-	I-Material
LOC	I-Material
dataset	I-Material
.	O
	
To	O
improve	O
the	O
detection	B-Metric
accuracy	I-Metric
of	O
pedestrians	B-Task
with	I-Task
small	I-Task
scale	I-Task
,	O
we	O
use	O
the	O
method	O
presented	O
in	O
to	O
dense	O
the	O
anchor	O
boxes	O
with	O
the	O
height	O
less	O
than	O
pixels	O
two	O
times	O
,	O
and	O
use	O
the	O
matching	B-Method
strategy	I-Method
in	O
to	O
associate	O
the	O
anchors	O
and	O
the	O
ground	O
truth	O
objects	O
.	O
	
All	O
the	O
parameters	O
in	O
the	O
newly	O
added	O
convolutional	O
layers	O
are	O
randomly	O
initialized	O
by	O
the	O
“	O
xavier	B-Method
”	I-Method
method	I-Method
.	O
	
We	O
optimize	O
the	O
OR	B-Method
-	I-Method
CNN	I-Method
detector	O
using	O
the	O
Stochastic	B-Method
Gradient	I-Method
Descent	I-Method
(	O
SGD	B-Method
)	O
algorithm	O
with	O
momentum	B-Method
and	I-Method
weight	I-Method
decay	I-Method
,	O
which	O
is	O
trained	O
on	O
Titan	O
X	O
GPUs	O
with	O
the	O
mini	O
-	O
batch	O
involving	O
image	O
per	O
GPU	O
.	O
	
For	O
the	O
Citypersons	B-Material
dataset	I-Material
,	O
we	O
set	O
the	O
learning	B-Metric
rate	I-Metric
to	O
for	O
the	O
first	O
iterations	O
,	O
and	O
decay	O
it	O
to	O
for	O
another	O
iterations	O
.	O
	
For	O
the	O
Caltech	B-Material
-	O
USA	O
dataset	O
,	O
we	O
train	O
the	O
network	O
for	O
iterations	O
with	O
the	O
initial	O
learning	B-Metric
rate	I-Metric
and	O
decrease	O
it	O
by	O
a	O
factor	O
of	O
after	O
the	O
first	O
iterations	O
.	O
	
All	O
the	O
hyperparameters	O
,	O
and	O
are	O
empirically	O
set	O
to	O
.	O
	
subsection	O
:	O
CityPersons	B-Material
Dataset	O
	
The	O
CityPersons	B-Material
dataset	I-Material
is	O
built	O
upon	O
the	O
semantic	B-Material
segmentation	I-Material
dataset	I-Material
Cityscapes	I-Material
to	O
provide	O
a	O
new	O
dataset	O
of	O
interest	O
for	O
pedestrian	B-Task
detection	I-Task
.	O
	
It	O
is	O
recorded	O
across	O
different	O
cities	O
in	O
Germany	O
with	O
different	O
seasons	O
and	O
various	O
weather	O
conditions	O
.	O
	
The	O
dataset	O
includes	O
images	O
(	O
for	O
training	O
,	O
for	O
validation	B-Task
,	O
and	O
for	O
testing	O
)	O
with	O
manually	O
annotated	O
persons	O
plus	O
ignore	O
region	O
annotations	O
.	O
	
Both	O
the	O
bounding	O
boxes	O
and	O
visible	O
parts	O
of	O
pedestrians	O
are	O
provided	O
and	O
there	O
are	O
approximately	O
pedestrians	O
in	O
average	O
per	O
image	O
.	O
	
Following	O
the	O
evaluation	O
protocol	O
in	O
CityPersons	B-Material
,	O
we	O
train	O
our	O
OR	B-Method
-	I-Method
CNN	I-Method
detector	O
on	O
the	O
training	O
set	O
,	O
and	O
evaluate	O
it	O
on	O
both	O
the	O
validation	O
and	O
the	O
testing	O
sets	O
.	O
	
The	O
log	O
miss	B-Metric
rate	I-Metric
averaged	O
over	O
the	O
false	B-Metric
positive	I-Metric
per	I-Metric
image	I-Metric
(	O
FPPI	B-Metric
)	O
range	O
of	O
(	O
)	O
is	O
used	O
to	O
measure	O
the	O
detection	B-Task
performance	O
(	O
lower	O
score	O
indicates	O
better	O
performance	O
)	O
.	O
	
We	O
use	O
the	O
adaptive	O
Faster	O
R	O
-	O
CNN	B-Method
method	O
trained	O
by	O
ourselves	O
as	O
the	O
baseline	B-Method
detector	O
,	O
which	O
achieves	O
on	O
the	O
validation	O
set	O
with	O
scale	O
,	O
sightly	O
better	O
than	O
the	O
reported	O
result	O
(	O
)	O
in	O
.	O
	
subsubsection	B-Method
:	O
Ablation	O
Study	O
on	O
AggLoss	B-Task
	
To	O
demonstrate	O
the	O
effectiveness	O
of	O
AggLoss	B-Method
,	O
we	O
construct	O
a	O
detector	B-Method
,	O
denoted	O
as	O
OR	B-Method
-	I-Method
CNN	I-Method
-	O
A	O
,	O
that	O
use	O
AggLoss	B-Method
instead	O
of	O
the	O
original	O
regression	O
loss	O
in	O
the	O
baseline	B-Method
detector	O
,	O
and	O
evaluate	O
it	O
on	O
the	O
validation	O
set	O
of	O
CityPersons	B-Material
in	O
Table	O
[	O
reference	O
]	O
.	O
	
For	O
a	O
fair	O
comparison	O
,	O
we	O
use	O
the	O
same	O
setting	O
of	O
parameters	O
of	O
OR	B-Method
-	I-Method
CNN	I-Method
-	O
A	O
and	O
our	O
OR	B-Method
-	I-Method
CNN	I-Method
detector	O
in	O
both	O
training	O
and	O
testing	O
.	O
	
All	O
of	O
the	O
experiments	O
are	O
conducted	O
on	O
the	O
reasonable	O
train	O
/	O
validation	O
sets	O
for	O
training	O
and	O
testing	O
.	O
	
Comparing	O
the	O
detection	B-Task
results	O
between	O
the	O
baseline	B-Method
and	O
OR	B-Method
-	I-Method
CNN	I-Method
-	O
A	O
in	O
Table	O
[	O
reference	O
]	O
,	O
we	O
find	O
that	O
using	O
the	O
newly	O
proposed	O
AggLoss	B-Method
can	O
reduce	O
the	O
by	O
(	O
i.e.	O
,	O
vs.	O
)	O
with	O
scale	O
.	O
	
It	O
is	O
worth	O
noting	O
that	O
the	O
OR	B-Method
-	I-Method
CNN	I-Method
	
-	O
A	O
detector	B-Method
achieves	O
with	O
scale	B-Metric
,	O
surpassing	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
method	O
using	O
Repulsion	B-Method
Loss	I-Method
(	O
)	O
,	O
which	O
demonstrates	O
that	O
AggLoss	B-Method
is	O
more	O
effective	O
than	O
Repulsion	B-Method
Loss	I-Method
for	O
detecting	O
the	O
pedestrians	O
in	O
a	O
crowd	O
.	O
	
In	O
addition	O
,	O
we	O
also	O
show	O
some	O
visual	O
comparison	O
results	O
of	O
the	O
predicted	O
bounding	O
boxes	O
before	O
NMS	B-Method
of	O
the	O
baseline	B-Method
and	O
OR	B-Method
-	I-Method
CNN	I-Method
	
-	O
A	O
detectors	O
in	O
Figure	O
[	O
reference	O
]	O
	
(	O
a	O
)	O
.	O
	
As	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
(	O
a	O
)	O
,	O
the	O
predictions	O
of	O
OR	B-Method
-	I-Method
CNN	I-Method
-	O
	
A	O
locate	O
more	O
compactly	O
than	O
that	O
of	O
the	O
baseline	B-Method
detector	O
,	O
and	O
there	O
are	O
fewer	O
predictions	O
of	O
OR	B-Method
-	I-Method
CNN	I-Method
	
-	O
A	O
lying	O
in	O
between	O
two	O
adjacent	O
ground	O
-	O
truth	O
objects	O
than	O
the	O
baseline	B-Method
detector	O
.	O
	
This	O
phenomenon	O
demonstrates	O
that	O
AggLoss	B-Method
can	O
push	O
the	O
predictions	O
lying	O
compactly	O
to	O
the	O
ground	O
-	O
truth	O
objects	O
,	O
making	O
the	O
detector	O
less	O
sensitive	O
to	O
the	O
NMS	O
threshold	O
with	O
better	O
performance	O
in	O
the	O
crowd	O
scene	O
.	O
	
To	O
further	O
validate	O
this	O
point	O
,	O
we	O
also	O
present	O
the	O
results	O
with	O
AggLoss	O
across	O
various	O
NMS	O
threshold	O
at	O
in	O
Figure	O
[	O
reference	O
]	O
	
(	O
b	O
)	O
.	O
	
A	O
high	O
NMS	O
threshold	O
may	O
lead	O
to	O
more	O
false	O
positives	O
,	O
while	O
a	O
low	O
NMS	O
threshold	O
may	O
lead	O
to	O
more	O
false	O
negatives	O
.	O
	
As	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
(	O
b	O
)	O
,	O
we	O
find	O
that	O
the	O
curve	O
of	O
OR	B-Method
-	I-Method
CNN	I-Method
-	O
A	O
is	O
smoother	O
than	O
that	O
of	O
baseline	B-Method
(	O
i.e.	O
,	O
the	O
variances	O
of	O
the	O
miss	B-Metric
rates	I-Metric
are	O
vs.	O
)	O
,	O
which	O
indicates	O
that	O
the	O
former	O
is	O
less	O
sensitive	O
to	O
the	O
NMS	O
threshold	O
.	O
	
It	O
is	O
worth	O
noting	O
that	O
across	O
various	O
NMS	O
thresholds	O
at	O
,	O
the	O
OR	B-Method
-	I-Method
CNN	I-Method
	
-	O
A	O
method	O
always	O
produces	O
lower	O
miss	B-Metric
rate	I-Metric
,	O
which	O
is	O
due	O
to	O
the	O
NMS	B-Method
operation	I-Method
filtering	O
out	O
more	O
false	O
positives	O
in	O
the	O
predictions	O
of	O
OR	B-Method
-	I-Method
CNN	I-Method
-	O
A	O
than	O
that	O
of	O
baseline	B-Method
,	O
implying	O
that	O
the	O
predicted	O
bounding	O
boxes	O
of	O
OR	B-Method
-	I-Method
CNN	I-Method
-	O
	
A	O
locate	O
compactly	O
than	O
baseline	B-Method
.	O
	
subsubsection	O
:	O
Ablation	B-Task
Study	I-Task
on	O
PORoI	B-Method
Pooling	O
	
To	O
validate	O
the	O
effectiveness	O
of	O
the	O
PORoI	B-Method
pooling	O
unit	O
,	O
we	O
construct	O
a	O
detector	B-Method
,	O
denoted	O
as	O
OR	B-Method
-	I-Method
CNN	I-Method
-	O
P	O
,	O
that	O
use	O
the	O
PORoI	B-Method
pooling	O
unit	O
instead	O
of	O
the	O
RoI	B-Method
pooling	I-Method
layer	I-Method
in	O
baseline	B-Method
,	O
and	O
evaluate	O
it	O
on	O
the	O
validation	O
set	O
of	O
CityPersons	B-Material
in	O
Table	O
[	O
reference	O
]	O
.	O
	
For	O
a	O
fair	O
comparison	O
,	O
we	O
use	O
the	O
same	O
parameter	O
settings	O
of	O
OR	B-Method
-	I-Method
CNN	I-Method
-	O
P	O
and	O
our	O
OR	B-Method
-	I-Method
CNN	I-Method
detector	O
in	O
both	O
training	O
and	O
testing	O
.	O
	
All	O
of	O
the	O
ablation	O
experiments	O
involved	O
CityPersons	B-Material
are	O
conducted	O
on	O
the	O
reasonable	O
train	O
/	O
validation	O
sets	O
for	O
training	O
and	O
testing	O
.	O
	
As	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
,	O
comparing	O
to	O
baseline	B-Method
,	O
OR	B-Method
-	I-Method
CNN	I-Method
-	O
P	O
reduces	O
with	O
scale	O
(	O
i.e.	O
,	O
vs.	O
)	O
,	O
which	O
demonstrates	O
the	O
effectiveness	O
of	O
the	O
PORoI	B-Method
pooling	O
unit	O
in	O
pedestrian	B-Task
detection	I-Task
.	O
	
Meanwhile	O
,	O
we	O
also	O
present	O
some	O
qualitative	O
results	O
of	O
the	O
predictions	O
with	O
the	O
visibility	O
scores	O
of	O
the	O
corresponding	O
parts	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Notably	O
,	O
we	O
find	O
that	O
the	O
visibility	O
scores	O
predicted	O
by	O
the	O
PORoI	B-Method
pooling	O
unit	O
are	O
in	O
accordance	O
with	O
the	O
human	B-Method
visual	I-Method
system	I-Method
.	O
	
As	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
(	O
a	O
)	O
and	O
(	O
b	O
)	O
,	O
if	O
the	O
pedestrian	O
is	O
not	O
occluded	O
,	O
the	O
visibility	B-Metric
score	I-Metric
of	O
each	O
part	O
of	O
the	O
pedestrian	O
approaches	O
.	O
	
However	O
,	O
if	O
some	O
parts	O
of	O
the	O
pedestrians	O
are	O
occluded	O
by	O
the	O
background	O
obstacles	O
or	O
other	O
pedestrians	O
,	O
the	O
scores	O
of	O
the	O
corresponding	O
parts	O
decrease	O
,	O
such	O
as	O
the	O
occluded	O
thigh	O
and	O
calf	O
in	O
Figure	O
[	O
reference	O
]	O
(	O
c	O
)-(	O
f	O
)	O
.	O
	
Besides	O
,	O
if	O
two	O
pedestrians	O
gather	O
together	O
and	O
occlude	O
each	O
other	O
,	O
our	O
PORoI	B-Method
pooling	O
unit	O
successfully	O
detects	O
the	O
occluded	O
human	O
parts	O
that	O
can	O
help	O
lower	O
the	O
contributions	O
of	O
the	O
occluded	O
parts	O
in	O
pedestrian	B-Task
detection	I-Task
,	O
see	O
Figure	O
[	O
reference	O
]	O
	
(	O
g	O
)	O
and	O
(	O
h	O
)	O
.	O
	
Notably	O
,	O
the	O
detection	B-Metric
accuracy	I-Metric
of	O
the	O
OR	B-Method
-	I-Method
CNN	I-Method
detector	O
can	O
not	O
be	O
improved	O
if	O
we	O
fix	O
the	O
visibility	O
score	O
of	O
each	O
part	O
to	O
instead	O
of	O
using	O
the	O
predictions	O
of	O
the	O
occlusion	B-Method
process	I-Method
unit	I-Method
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
Thus	O
,	O
the	O
occlusion	B-Method
process	I-Method
unit	I-Method
is	O
the	O
key	O
component	O
to	O
detection	B-Metric
accuracy	I-Metric
,	O
since	O
it	O
enables	O
our	O
PORoI	B-Method
pooling	O
unit	O
to	O
detect	O
the	O
occluded	O
parts	O
of	O
pedestrians	O
,	O
which	O
is	O
useful	O
to	O
help	O
extract	O
effective	O
features	O
for	O
detection	B-Task
.	O
	
subsubsection	O
:	O
Evaluation	O
Results	O
	
We	O
compare	O
the	O
proposed	O
OR	B-Method
-	I-Method
CNN	I-Method
method	I-Method
with	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
detectors	O
on	O
both	O
the	O
validation	O
and	O
testing	O
sets	O
of	O
CityPersons	B-Material
in	O
Table	O
[	O
reference	O
]	O
and	O
Table	O
[	O
reference	O
]	O
,	O
respectively	O
.	O
	
Our	O
OR	B-Method
-	I-Method
CNN	I-Method
achieves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
the	O
validation	O
set	O
of	O
CityPersons	B-Material
by	O
reducing	O
(	O
i.e.	O
,	O
vs.	O
of	O
)	O
with	O
scale	O
and	O
(	O
i.e.	O
,	O
vs.	O
of	O
)	O
with	O
scale	O
,	O
surpassing	O
all	O
published	O
approaches	O
,	O
which	O
demonstrates	O
the	O
superiority	O
of	O
the	O
proposed	O
method	O
in	O
pedestrian	B-Task
detection	I-Task
.	O
	
To	O
demonstrate	O
the	O
effectiveness	O
of	O
OR	B-Method
-	I-Method
CNN	I-Method
under	O
various	O
occlusion	O
levels	O
,	O
we	O
follow	O
the	O
strategy	O
in	O
to	O
divide	O
the	O
Reasonable	O
subset	O
in	O
the	O
validation	O
set	O
(	O
occlusion	O
)	O
into	O
the	O
Reasonable	O
-	O
Partial	O
subset	O
(	O
occlusion	O
)	O
,	O
denoted	O
as	O
Partial	O
subset	O
,	O
and	O
the	O
Reasonable	O
-	O
Bare	O
subset	O
(	O
occlusion	O
)	O
,	O
denoted	O
as	O
Bare	O
subset	O
.	O
	
Meanwhile	O
,	O
we	O
denote	O
the	O
annotated	O
pedestrians	O
with	O
the	O
occlusion	O
ratio	O
larger	O
than	O
(	O
that	O
are	O
not	O
included	O
in	O
the	O
Reasonable	O
set	O
)	O
as	O
Heavy	O
subset	O
.	O
	
We	O
report	O
the	O
results	O
of	O
the	O
proposed	O
OR	B-Method
-	I-Method
CNN	I-Method
method	I-Method
and	O
other	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
on	O
these	O
three	O
subsets	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
As	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
,	O
OR	B-Method
-	I-Method
CNN	I-Method
outperforms	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
consistently	O
across	O
all	O
three	O
subsets	O
,	O
i.e.	O
,	O
reduces	O
on	O
the	O
Bare	O
subset	O
,	O
on	O
the	O
Partial	B-Material
subset	I-Material
,	O
and	O
on	O
the	O
Heavy	O
subset	O
.	O
	
Notably	O
,	O
when	O
the	O
occlusion	O
becomes	O
severely	O
(	O
i.e.	O
,	O
from	O
Bare	O
subset	O
to	O
Heavy	O
subset	O
)	O
,	O
the	O
performance	O
improvement	O
of	O
our	O
OR	B-Method
-	I-Method
CNN	I-Method
is	O
more	O
obvious	O
compared	O
to	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
,	O
which	O
demonstrates	O
that	O
the	O
AggLoss	O
and	O
PORoI	B-Method
pooling	O
unit	O
are	O
extremely	O
effective	O
to	O
address	O
the	O
occlusion	B-Task
challenge	I-Task
.	O
	
In	O
addition	O
,	O
we	O
also	O
evaluate	O
the	O
proposed	O
OR	B-Method
-	I-Method
CNN	I-Method
method	I-Method
on	O
the	O
testing	O
set	O
of	O
CityPersons	B-Material
.	O
	
Following	O
its	O
evaluation	O
protocol	O
,	O
we	O
submit	O
the	O
detection	B-Task
results	O
of	O
OR	B-Method
-	I-Method
CNN	I-Method
to	O
the	O
authors	O
for	O
evaluation	O
and	O
report	O
the	O
results	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
The	O
proposed	O
OR	B-Method
-	I-Method
CNN	I-Method
method	I-Method
achieves	O
the	O
top	O
accuracy	B-Metric
with	O
only	O
scale	O
.	O
	
Although	O
the	O
second	O
best	O
detector	B-Metric
Repulsion	I-Metric
Loss	I-Metric
uses	O
much	O
bigger	O
input	O
images	O
(	O
i.e.	O
,	O
scale	O
of	O
vs.	O
scale	O
of	O
OR	B-Method
-	I-Method
CNN	I-Method
)	O
and	O
stronger	O
backbone	B-Method
network	I-Method
(	O
i.e.	O
,	O
ResNet	B-Method
-	I-Method
50	I-Method
of	O
vs.	O
VGG	B-Method
-	I-Method
16	I-Method
of	O
OR	B-Method
-	I-Method
CNN	I-Method
)	O
,	O
it	O
still	O
produces	O
higher	O
on	O
the	O
Reasonable	O
subset	O
and	O
higher	O
on	O
the	O
Reasonable	O
-	O
Small	O
subset	O
.	O
	
We	O
believe	O
the	O
performance	O
of	O
OR	B-Method
-	I-Method
CNN	I-Method
can	O
be	O
further	O
improved	O
by	O
using	O
bigger	O
input	O
images	O
and	O
stronger	O
backbone	B-Method
network	I-Method
.	O
	
subsection	O
:	O
Caltech	B-Material
-	O
USA	O
Dataset	O
	
The	O
Caltech	B-Material
-	O
USA	O
dataset	O
is	O
one	O
of	O
the	O
most	O
popular	O
and	O
challenging	O
datasets	O
for	O
pedestrian	B-Task
detection	I-Task
,	O
which	O
comes	O
from	O
approximately	O
hours	O
	
Hz	O
VGA	B-Material
video	I-Material
recorded	O
by	O
a	O
car	O
traversing	O
the	O
streets	O
in	O
the	O
greater	O
Los	O
Angeles	O
metropolitan	O
area	O
.	O
	
We	O
use	O
the	O
new	O
high	O
quality	O
annotations	O
provided	O
by	O
to	O
evaluate	O
the	O
proposed	O
OR	B-Method
-	I-Method
CNN	I-Method
method	I-Method
.	O
	
The	O
training	O
and	O
testing	O
sets	O
contains	O
and	O
frames	O
,	O
respectively	O
.	O
	
Following	O
,	O
the	O
log	O
-	O
average	O
miss	B-Metric
rate	I-Metric
over	O
points	O
ranging	O
from	O
to	O
FPPI	B-Method
is	O
used	O
to	O
evaluate	O
the	O
performance	O
of	O
the	O
detectors	O
.	O
	
We	O
directly	O
fine	O
-	O
tune	O
the	O
detection	B-Method
models	I-Method
pre	O
-	O
trained	O
on	O
CityPersons	B-Material
of	O
the	O
proposed	O
OR	B-Method
-	I-Method
CNN	I-Method
method	I-Method
on	O
the	O
training	O
set	O
in	O
Caltech	B-Material
-	O
USA	O
.	O
	
Similar	O
to	O
,	O
we	O
evaluate	O
the	O
OR	B-Method
-	I-Method
CNN	I-Method
method	I-Method
on	O
the	O
Reasonable	O
subset	O
of	O
the	O
Caltech	B-Material
-	O
USA	O
dataset	O
,	O
and	O
compare	O
it	O
to	O
other	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
(	O
e.g.	O
,	O
)	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Notably	O
,	O
the	O
Reasonable	O
subset	O
(	O
occlusion	O
)	O
only	O
includes	O
the	O
pedestrians	O
with	O
at	O
least	O
pixels	O
tall	O
,	O
which	O
is	O
widely	O
used	O
to	O
evaluate	O
the	O
pedestrian	B-Method
detectors	I-Method
.	O
	
As	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
the	O
OR	B-Method
-	I-Method
CNN	I-Method
method	I-Method
performs	O
competitively	O
with	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
method	O
by	O
producing	O
.	O
	
subsection	O
:	O
ETH	B-Material
Dataset	I-Material
	
To	O
verify	O
the	O
generalization	B-Metric
capacity	I-Metric
of	O
the	O
proposed	O
OR	B-Method
-	I-Method
CNN	I-Method
detector	O
,	O
we	O
directly	O
use	O
the	O
model	O
trained	O
on	O
the	O
CityPersons	B-Material
dataset	I-Material
to	O
detect	O
the	O
pedestrians	O
in	O
the	O
ETH	B-Material
dataset	I-Material
without	O
fine	O
-	O
tuning	O
.	O
	
That	O
is	O
,	O
all	O
frames	O
in	O
three	O
video	O
clips	O
of	O
the	O
ETH	B-Material
dataset	I-Material
are	O
used	O
to	O
evaluate	O
the	O
performance	O
of	O
the	O
OR	B-Method
-	I-Method
CNN	I-Method
detector	O
.	O
	
We	O
use	O
to	O
evaluate	O
the	O
performance	O
of	O
the	O
detectors	O
,	O
and	O
compare	O
the	O
proposed	O
OR	B-Method
-	I-Method
CNN	I-Method
method	I-Method
with	O
other	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
(	O
i.e.	O
,	O
)	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Our	O
OR	B-Method
-	I-Method
CNN	I-Method
detector	O
achieves	O
the	O
top	O
accuracy	B-Metric
by	O
reducing	O
comparing	O
to	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
(	O
i.e.	O
,	O
of	O
OR	B-Method
-	I-Method
CNN	I-Method
vs.	O
RFN	B-Method
-	I-Method
BF	I-Method
)	O
.	O
	
The	O
results	O
on	O
the	O
ETH	B-Material
dataset	I-Material
not	O
only	O
demonstrates	O
the	O
superiority	O
of	O
the	O
proposed	O
OR	B-Method
-	I-Method
CNN	I-Method
method	I-Method
in	O
pedestrian	B-Task
detection	I-Task
,	O
but	O
also	O
verifies	O
its	O
generalization	B-Metric
capacity	I-Metric
to	O
other	O
scenarios	O
.	O
	
subsection	O
:	O
INRIA	B-Material
Dataset	I-Material
	
The	O
INRIA	B-Material
dataset	I-Material
contains	O
images	O
of	O
high	O
resolution	O
pedestrians	O
collected	O
mostly	O
from	O
holiday	O
photos	O
,	O
which	O
consists	O
of	O
images	O
,	O
including	O
images	O
for	O
training	O
and	O
images	O
.	O
	
Specifically	O
,	O
there	O
are	O
positive	O
images	O
and	O
negative	O
images	O
in	O
the	O
training	O
set	O
.	O
	
We	O
use	O
the	O
positive	O
images	O
in	O
the	O
training	O
set	O
to	O
fine	O
-	O
tune	O
our	O
model	O
pre	O
-	O
trained	O
on	O
CityPersons	B-Material
for	O
iterations	O
,	O
and	O
test	O
it	O
on	O
the	O
testing	O
images	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
that	O
our	O
OR	B-Method
-	I-Method
CNN	I-Method
method	I-Method
achieves	O
an	O
of	O
,	O
better	O
than	O
the	O
other	O
available	O
competitors	O
(	O
i.e.	O
,	O
)	O
,	O
which	O
demonstrates	O
the	O
effectiveness	O
of	O
the	O
proposed	O
method	O
in	O
pedestrian	B-Task
detection	I-Task
.	O
	
section	O
:	O
Conclusions	O
	
In	O
this	O
paper	O
,	O
we	O
present	O
a	O
new	O
occlusion	B-Method
-	I-Method
aware	I-Method
R	I-Method
-	I-Method
CNN	I-Method
method	O
to	O
improve	O
the	O
pedestrian	B-Task
detection	I-Task
accuracy	I-Task
in	O
crowded	B-Task
scenes	I-Task
.	O
	
Specifically	O
,	O
we	O
design	O
a	O
new	O
aggregation	B-Method
loss	I-Method
to	O
reduce	O
the	O
false	O
detections	O
of	O
the	O
adjacent	O
overlapping	O
pedestrians	O
,	O
by	O
simultaneously	O
enforcing	O
the	O
proposals	O
to	O
be	O
close	O
to	O
the	O
associated	O
objects	O
,	O
and	O
locate	O
compactly	O
.	O
	
Meanwhile	O
,	O
to	O
effectively	O
handle	O
partial	O
occlusion	O
,	O
we	O
propose	O
a	O
new	O
part	B-Method
occlusion	I-Method
-	I-Method
aware	I-Method
RoI	I-Method
pooling	I-Method
unit	I-Method
to	O
replace	O
the	O
RoI	B-Method
pooling	I-Method
layer	I-Method
in	O
the	O
Fast	O
R	O
-	O
CNN	B-Method
module	O
of	O
the	O
detector	B-Method
,	O
which	O
integrates	O
the	O
prior	O
structure	O
information	O
of	O
human	O
body	O
with	O
visibility	O
prediction	O
into	O
the	O
network	O
to	O
handle	O
occlusion	O
.	O
	
Our	O
method	O
is	O
trained	O
in	O
an	O
end	O
-	O
to	O
-	O
end	O
fashion	O
and	O
achieves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
accuracy	B-Metric
on	O
three	O
pedestrian	B-Task
detection	I-Task
datasets	I-Task
,	O
i.e.	O
,	O
CityPersons	B-Material
,	O
ETH	B-Material
,	O
and	O
INRIA	B-Material
,	O
and	O
performs	O
on	O
-	O
pair	O
with	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
arts	O
on	O
Caltech	B-Material
.	O
	
In	O
the	O
future	O
,	O
we	O
plan	O
to	O
improve	O
the	O
method	O
in	O
two	O
aspects	O
.	O
	
First	O
,	O
we	O
would	O
like	O
to	O
redesign	O
the	O
PORoI	B-Method
pooling	O
unit	O
to	O
jointly	O
estimate	O
the	O
location	O
,	O
size	O
,	O
and	O
occlusion	O
status	O
of	O
the	O
object	O
parts	O
in	O
the	O
network	O
,	O
instead	O
of	O
using	O
the	O
empirical	O
ratio	O
.	O
	
And	O
then	O
,	O
we	O
plan	O
to	O
extend	O
the	O
proposed	O
method	O
to	O
detect	O
other	O
kinds	O
of	O
objects	O
,	O
e.g.	O
,	O
car	O
,	O
bicycle	O
,	O
tricycle	O
,	O
etc	O
.	O
	
section	O
:	O
Acknowledgments	O
	
This	O
work	O
was	O
supported	O
by	O
the	O
National	O
Key	O
Research	O
and	O
Development	O
Plan	O
(	O
Grant	O
No.2016YFC0801002	O
)	O
,	O
the	O
Chinese	O
National	O
Natural	O
Science	O
Foundation	O
Projects	O
,	O
,	O
,	O
,	O
the	O
Science	O
and	O
Technology	O
Development	O
Fund	O
of	O
Macau	O
	
(	O
No	O
.	O
0025	O
/	O
2018	O
/	O
A1	O
,	O
151	O
/	O
2017	O
/	O
A	O
,	O
152	O
/	O
2017	O
/	O
A	O
)	O
,	O
JDGrapevine	O
Plan	O
and	O
AuthenMetric	O
R	O
&	O
D	O
Funds	O
.	O
	
We	O
also	O
thank	O
NVIDIA	O
for	O
GPU	O
donations	O
through	O
their	O
academic	O
program	O
.	O
	
bibliography	O
:	O
References	O
	
FINDING	O
REMO	B-Method
(	O
RELATED	B-Method
MEMORY	I-Method
OBJECT	I-Method
)	O
:	O
	
A	O
SIMPLE	O
NEURAL	B-Method
ARCHITECTURE	I-Method
FOR	O
TEXT	B-Task
BASED	I-Task
REASONING	I-Task
	
section	O
:	O
ABSTRACT	O
	
To	O
solve	O
the	O
text	B-Task
-	I-Task
based	I-Task
question	I-Task
and	I-Task
answering	I-Task
task	I-Task
that	O
requires	O
relational	B-Task
reasoning	I-Task
,	O
it	O
is	O
necessary	O
to	O
memorize	O
a	O
large	O
amount	O
of	O
information	O
and	O
find	O
out	O
the	O
question	O
relevant	O
information	O
from	O
the	O
memory	O
.	O
	
Most	O
approaches	O
were	O
based	O
on	O
external	O
memory	O
and	O
four	O
components	O
proposed	O
by	O
Memory	B-Method
Network	I-Method
.	O
	
The	O
distinctive	O
component	O
among	O
them	O
was	O
the	O
way	O
of	O
finding	O
the	O
necessary	O
information	O
and	O
it	O
contributes	O
to	O
the	O
performance	O
.	O
	
Recently	O
,	O
a	O
simple	O
but	O
powerful	O
neural	B-Method
network	I-Method
module	I-Method
for	O
reasoning	B-Task
called	O
Relation	B-Method
Network	I-Method
(	O
RN	B-Method
)	O
has	O
been	O
introduced	O
.	O
	
We	O
analyzed	O
RN	B-Method
from	O
the	O
view	O
of	O
Memory	B-Method
Network	I-Method
,	O
and	O
realized	O
that	O
its	O
MLP	B-Method
component	O
is	O
able	O
to	O
reveal	O
the	O
complicate	O
relation	O
between	O
question	O
and	O
object	O
pair	O
.	O
	
Motivated	O
from	O
it	O
,	O
we	O
introduce	O
Relation	B-Method
Memory	I-Method
Network	I-Method
(	O
RMN	B-Method
)	O
which	O
uses	O
MLP	B-Method
to	O
find	O
out	O
relevant	O
information	O
on	O
Memory	B-Method
Network	I-Method
architecture	I-Method
.	O
	
It	O
shows	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
in	O
jointly	O
trained	O
bAbI	B-Task
-	I-Task
10k	I-Task
story	I-Task
-	I-Task
based	I-Task
question	I-Task
answering	I-Task
tasks	I-Task
and	O
bAbI	B-Task
dialog	I-Task
-	I-Task
based	I-Task
question	I-Task
answering	I-Task
tasks	I-Task
.	O
	
section	O
:	O
INTRODUCTION	O
	
Neural	B-Method
network	I-Method
has	O
made	O
an	O
enormous	O
progress	O
on	O
the	O
two	O
major	O
challenges	O
in	O
artificial	B-Task
intelligence	I-Task
:	O
seeing	B-Task
and	I-Task
reading	I-Task
.	O
	
In	O
both	O
areas	O
,	O
embedding	B-Method
methods	I-Method
have	O
served	O
as	O
the	O
main	O
vehicle	O
to	O
process	O
and	O
analyze	O
text	O
and	O
image	O
data	O
for	O
solving	O
classification	B-Task
problems	I-Task
.	O
	
As	O
for	O
the	O
task	O
of	O
logical	B-Task
reasoning	I-Task
,	O
however	O
,	O
more	O
complex	O
and	O
careful	O
handling	O
of	O
features	O
is	O
called	O
for	O
.	O
	
A	O
reasoning	B-Task
task	I-Task
requires	O
the	O
machine	O
to	O
answer	O
a	O
simple	O
question	O
upon	O
the	O
delivery	O
of	O
a	O
series	O
of	O
sequential	O
information	O
.	O
	
For	O
example	O
,	O
imagine	O
that	O
the	O
machine	O
is	O
given	O
the	O
following	O
three	O
sentences	O
:	O
	
"	O
Mary	O
got	O
the	O
milk	O
there	O
.	O
	
"	O
,	O
"	O
John	O
moved	O
to	O
the	O
bedroom	O
.	O
"	O
,	O
and	O
"	O
Mary	O
traveled	O
to	O
the	O
hallway	O
.	O
	
"	O
	
Once	O
prompted	O
with	O
the	O
question	O
,	O
"	O
Where	O
is	O
the	O
milk	O
?	O
"	O
,	O
the	O
machine	O
then	O
needs	O
to	O
sequentially	O
focus	O
on	O
the	O
two	O
supporting	O
sentences	O
,	O
"	O
Mary	O
got	O
the	O
milk	O
there	O
.	O
	
"	O
	
and	O
"	O
Mary	O
traveled	O
to	O
the	O
hallway	O
.	O
	
"	O
	
in	O
order	O
to	O
successfully	O
determine	O
that	O
the	O
milk	O
is	O
located	O
in	O
the	O
hallway	O
.	O
	
Inspired	O
by	O
this	O
reasoning	B-Method
mechanism	I-Method
,	O
J.	O
has	O
introduced	O
the	O
memory	B-Method
network	I-Method
(	O
MemNN	B-Method
)	I-Method
,	O
which	O
consists	O
of	O
an	O
external	O
memory	O
and	O
four	O
components	O
:	O
input	O
feature	O
map	O
(	O
I	O
)	O
,	O
generalization	O
(	O
G	O
)	O
,	O
output	O
feature	O
map	O
(	O
O	O
)	O
,	O
and	O
response	O
(	O
R	O
)	O
.	O
	
The	O
external	O
memory	O
enables	O
the	O
model	O
to	O
deal	O
with	O
a	O
knowledge	O
base	O
without	O
loss	O
of	O
information	O
.	O
	
Input	O
feature	B-Method
map	I-Method
embeds	O
the	O
incoming	O
sentences	O
.	O
	
Generalization	B-Method
updates	O
old	O
memories	O
given	O
the	O
new	O
input	O
and	O
output	O
feature	O
map	O
finds	O
relevant	O
information	O
from	O
the	O
memory	O
.	O
	
Finally	O
,	O
response	O
produces	O
the	O
final	O
output	O
.	O
	
Based	O
on	O
the	O
memory	B-Method
network	I-Method
architecture	I-Method
,	O
neural	B-Method
network	I-Method
based	I-Method
models	I-Method
like	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
memory	I-Method
network	I-Method
(	O
MemN2N	B-Method
)	O
[	O
reference	O
]	O
,	O
gated	B-Method
end	I-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
memory	I-Method
network	I-Method
(	O
GMemN2N	B-Method
)	O
[	O
reference	O
]	O
,	O
dynamic	B-Method
memory	I-Method
network	I-Method
(	O
DMN	B-Method
)	O
	
[	O
reference	O
]	O
,	O
and	O
dynamic	B-Method
memory	I-Method
network	I-Method
+	I-Method
(	I-Method
DMN	I-Method
+	I-Method
)	O
	
[	O
reference	O
]	O
are	O
proposed	O
.	O
	
Since	O
strong	O
reasoning	O
ability	O
depends	O
on	O
whether	O
the	O
model	O
is	O
able	O
to	O
sequentially	O
catching	O
the	O
right	O
supporting	O
sentences	O
that	O
lead	O
to	O
the	O
answer	O
,	O
the	O
most	O
important	O
thing	O
that	O
discriminates	O
those	O
models	O
is	O
the	O
way	O
of	O
constructing	O
the	O
output	O
feature	O
map	O
.	O
	
As	O
the	O
output	O
feature	O
map	O
becomes	O
more	O
complex	O
,	O
it	O
is	O
able	O
to	O
learn	O
patterns	O
for	O
more	O
complicate	O
relations	O
.	O
	
For	O
example	O
,	O
MemN2N	B-Method
,	O
which	O
has	O
the	O
lowest	O
performance	O
among	O
the	O
four	O
models	O
,	O
measures	O
the	O
relatedness	O
between	O
question	O
and	O
sentence	O
by	O
the	O
inner	B-Method
product	I-Method
,	O
while	O
the	O
best	O
performing	O
DMN	B-Method
+	I-Method
uses	O
inner	B-Method
product	I-Method
and	O
absolute	O
difference	O
with	O
two	O
embedding	B-Method
matrices	I-Method
.	O
	
Recently	O
,	O
a	O
new	O
architecture	O
called	O
Relation	B-Method
Network	I-Method
(	O
RN	B-Method
)	O
	
[	O
reference	O
]	O
has	O
been	O
proposed	O
as	O
a	O
general	O
solution	O
to	O
relational	B-Task
reasoning	I-Task
.	O
	
The	O
design	O
philosophy	O
behind	O
it	O
is	O
to	O
directly	O
capture	O
the	O
supporting	O
relation	O
between	O
the	O
sentences	O
through	O
the	O
multi	B-Method
-	I-Method
layer	I-Method
perceptron	I-Method
(	O
MLP	B-Method
)	O
.	O
	
Despite	O
its	O
simplicity	O
,	O
RN	B-Method
achieves	O
better	O
performance	O
than	O
previous	O
models	O
without	O
any	O
catastrophic	O
failure	O
.	O
	
The	O
interesting	O
thing	O
we	O
found	O
is	O
that	O
RN	B-Method
can	O
also	O
be	O
interpreted	O
in	O
terms	O
of	O
MemNN	B-Method
.	O
	
It	O
is	O
composed	O
of	O
O	O
and	O
R	O
where	O
each	O
corresponds	O
to	O
MLP	B-Method
which	O
focuses	O
on	O
the	O
related	O
pair	O
and	O
another	O
MLP	B-Method
which	O
infers	O
the	O
answer	O
.	O
	
RN	B-Method
does	O
not	O
need	O
to	O
have	O
G	O
because	O
it	O
directly	O
finds	O
all	O
the	O
supporting	O
sentences	O
at	O
once	O
.	O
	
In	O
this	O
point	O
of	O
view	O
,	O
the	O
significant	O
component	O
would	O
be	O
MLP	B-Method
-	O
based	O
output	O
feature	O
map	O
.	O
	
As	O
MLP	B-Method
is	O
enough	O
to	O
recognize	O
highly	O
non	O
-	O
linear	O
pattern	O
,	O
RN	B-Method
could	O
find	O
the	O
proper	O
relation	O
better	O
than	O
previous	O
models	O
to	O
answer	O
the	O
given	O
question	O
.	O
	
However	O
,	O
as	O
RN	B-Method
considers	O
a	O
pair	O
at	O
a	O
time	O
unlike	O
MemNN	B-Method
,	O
the	O
number	O
of	O
relations	O
that	O
RN	B-Method
learns	O
is	O
n	O
2	O
when	O
the	O
number	O
of	O
input	O
sentence	O
is	O
n.	O
	
When	O
n	O
is	O
small	O
,	O
the	O
cost	O
of	O
learning	B-Task
relation	I-Task
is	O
reduced	O
by	O
n	O
times	O
compared	O
to	O
MemNN	B-Method
based	I-Method
models	I-Method
,	O
which	O
enables	O
more	O
data	O
-	O
efficient	O
learning	B-Task
	
[	O
reference	O
]	O
.	O
However	O
,	O
when	O
n	O
increases	O
,	O
the	O
performance	O
becomes	O
worse	O
than	O
the	O
previous	O
models	O
.	O
	
In	O
this	O
case	O
,	O
the	O
pair	B-Method
-	I-Method
wise	I-Method
operation	I-Method
increases	O
the	O
number	O
of	O
non	O
-	O
related	O
sentence	O
pairs	O
more	O
than	O
the	O
related	O
sentence	O
pair	O
,	O
thereby	O
confuses	O
RN	B-Method
's	O
learning	O
.	O
	
[	O
reference	O
]	O
has	O
suggested	O
attention	B-Method
mechanisms	I-Method
as	O
a	O
solution	O
to	O
filter	O
out	O
unimportant	O
relations	O
;	O
however	O
,	O
since	O
it	O
interrupts	O
the	O
reasoning	O
operation	O
,	O
it	O
may	O
not	O
be	O
the	O
most	O
optimal	O
solution	O
to	O
the	O
problem	O
.	O
	
Our	O
proposed	O
model	O
,	O
"	O
Relation	B-Method
Memory	I-Method
Network	I-Method
"	O
(	O
RMN	B-Method
)	O
,	O
is	O
able	O
to	O
find	O
complex	O
relation	O
even	O
when	O
a	O
lot	O
of	O
information	O
is	O
given	O
.	O
	
It	O
uses	O
MLP	B-Method
to	O
find	O
out	O
relevant	O
information	O
with	O
a	O
new	O
generalization	B-Method
which	O
simply	O
erase	O
the	O
information	O
already	O
used	O
.	O
	
In	O
other	O
words	O
,	O
RMN	B-Method
inherits	O
RN	B-Method
's	O
MLP	B-Method
-	O
based	O
output	O
feature	O
map	O
on	O
Memory	B-Method
Network	I-Method
architecture	I-Method
.	O
	
Experiments	O
show	O
its	O
state	O
-	O
ofthe	O
-	O
art	O
result	O
on	O
the	O
text	B-Task
-	I-Task
based	I-Task
question	I-Task
answering	I-Task
tasks	I-Task
.	O
	
Relation	B-Method
Memory	I-Method
Network	I-Method
(	O
RMN	B-Method
)	O
is	O
composed	O
of	O
four	O
components	O
-	O
embedding	O
,	O
attention	O
,	O
updating	B-Task
,	O
and	O
reasoning	B-Task
.	O
	
It	O
takes	O
as	O
the	O
inputs	O
a	O
set	O
of	O
sentences	O
x	O
1	O
,	O
x	O
2	O
,	O
...	O
,	O
	
x	O
n	O
and	O
its	O
related	O
question	O
u	O
,	O
and	O
outputs	O
an	O
answer	O
a.	O
	
Each	O
of	O
the	O
x	O
i	O
,	O
u	O
,	O
and	O
a	O
is	O
made	O
up	O
of	O
one	O
-	O
hot	B-Method
representation	I-Method
of	O
words	O
,	O
for	O
example	O
,	O
	
section	O
:	O
RELATION	B-Method
MEMORY	I-Method
NETWORK	I-Method
	
..	O
,	O
	
n	O
i	O
)	O
,	O
V	O
=	O
vocabulary	O
size	O
,	O
n	O
	
i	O
=	O
number	O
of	O
words	O
in	O
sentence	O
i	O
)	O
.	O
	
section	O
:	O
EMBEDDING	B-Method
COMPONENT	I-Method
	
We	O
first	O
embed	O
words	O
in	O
each	O
x	O
i	O
=	O
{	O
x	O
i1	O
,	O
x	O
i2	O
,	O
x	O
i3	O
,	O
...	O
,	O
x	O
ini	O
}	O
and	O
u	O
to	O
a	O
continuous	O
space	O
multiplying	O
an	O
embedding	B-Method
matrix	I-Method
	
A	O
∈	O
R	O
d×V	O
.	O
	
Then	O
,	O
the	O
embedded	O
sentence	O
is	O
stored	O
and	O
represented	O
as	O
a	O
memory	O
object	O
	
m	O
	
i	O
while	O
question	O
is	O
represented	O
as	O
q.	O
Any	O
of	O
the	O
following	O
methods	O
are	O
available	O
for	O
embedding	B-Method
component	I-Method
:	O
simple	B-Method
sum	I-Method
(	O
equation	O
1	O
)	O
,	O
position	B-Method
encoding	I-Method
(	O
J.	O
(	O
equation	O
2	O
)	O
,	O
concatenation	B-Method
(	O
equation	O
3	O
)	O
,	O
LSTM	B-Method
,	O
and	O
GRU	B-Method
.	O
	
In	O
case	O
of	O
LSTM	B-Method
or	O
GRU	B-Method
,	O
m	O
i	O
is	O
the	O
final	O
hidden	O
state	O
of	O
it	O
.	O
	
As	O
the	O
following	O
attention	B-Method
component	I-Method
takes	O
the	O
concatenation	O
of	O
m	O
i	O
and	O
q	O
,	O
it	O
is	O
not	O
necessarily	O
the	O
case	O
that	O
sentence	O
and	O
question	O
have	O
the	O
same	O
dimensional	O
embedding	O
vectors	O
unlike	O
previous	O
memory	B-Method
-	I-Method
augmented	I-Method
neural	I-Method
networks	I-Method
.	O
	
section	O
:	O
ATTENTION	B-Method
COMPONENT	I-Method
	
Attention	B-Method
component	I-Method
can	O
be	O
applied	O
more	O
than	O
once	O
depending	O
on	O
the	O
problem	O
;	O
Figure	O
1	O
illustrates	O
2	O
hop	B-Method
version	I-Method
of	O
RMN	B-Method
.	O
	
We	O
refer	O
to	O
the	O
i	O
th	O
embedded	O
sentence	O
on	O
the	O
t	O
th	O
hop	O
as	O
m	O
	
section	O
:	O
UPDATING	B-Method
COMPONENT	I-Method
	
To	O
forget	O
the	O
information	O
already	O
used	O
,	O
we	O
use	O
intuitive	B-Method
updating	I-Method
component	I-Method
to	O
renew	O
the	O
memory	O
.	O
	
It	O
is	O
replaced	O
by	O
the	O
amount	O
of	O
unconsumed	O
from	O
the	O
old	O
one	O
:	O
	
Contrary	O
to	O
other	O
components	O
,	O
updating	B-Task
is	O
not	O
a	O
mandatory	O
component	O
.	O
	
When	O
it	O
is	O
considered	O
to	O
have	O
1	O
hop	O
,	O
there	O
is	O
no	O
need	O
to	O
use	O
this	O
.	O
	
section	O
:	O
REASONING	B-Method
COMPONENT	I-Method
	
Similar	O
to	O
attention	B-Method
component	I-Method
,	O
reasoning	B-Method
component	I-Method
is	O
also	O
made	O
up	O
of	O
MLP	B-Method
,	O
represented	O
as	O
f	B-Method
φ	I-Method
.	O
	
It	O
receives	O
both	O
q	O
and	O
the	O
final	O
result	O
of	O
attention	O
component	O
	
r	O
f	O
and	O
then	O
takes	O
a	O
softmax	B-Method
to	O
produce	O
the	O
model	O
answerâ	O
:	O
	
To	O
answer	O
the	O
question	O
from	O
a	O
given	O
set	O
of	O
facts	O
,	O
the	O
model	O
needs	O
to	O
memorize	O
these	O
facts	O
from	O
the	O
past	O
.	O
	
Long	B-Method
short	I-Method
term	I-Method
memory	I-Method
(	O
LSTM	B-Method
)	O
	
[	O
reference	O
]	O
,	O
one	O
of	O
the	O
variants	O
of	O
recurrent	B-Method
neural	I-Method
network	I-Method
(	I-Method
RNN	I-Method
)	I-Method
,	O
is	O
inept	O
at	O
remembering	O
past	O
stories	O
because	O
of	O
their	O
small	O
internal	O
memory	O
[	O
reference	O
]	O
.	O
	
To	O
cope	O
with	O
this	O
problem	O
,	O
J.	O
has	O
proposed	O
a	O
new	O
class	O
of	O
memory	B-Method
-	I-Method
augmented	I-Method
model	I-Method
called	O
Memory	B-Method
Network	I-Method
(	O
MemNN	B-Method
)	O
.	O
	
MemNN	B-Method
comprises	O
an	O
external	O
memory	O
m	O
and	O
four	O
components	O
:	O
input	O
feature	O
map	O
(	O
I	O
)	O
,	O
	
generalization	B-Method
(	O
G	O
)	O
,	O
output	O
feature	O
map	O
(	O
O	O
)	O
,	O
and	O
response	O
(	O
R	O
)	O
.	O
	
I	O
encodes	O
the	O
sentences	O
which	O
are	O
stored	O
in	O
	
memory	O
m.	O
G	O
updates	O
the	O
memory	O
,	O
whereas	O
O	O
reads	O
output	O
feature	O
o	O
from	O
the	O
memory	O
.	O
	
Finally	O
,	O
R	O
infers	O
an	O
answer	O
from	O
o.	O
	
MemN2N	B-Method
,	O
GMemN2N	B-Method
,	O
DMN	B-Method
,	O
and	O
DMN	B-Method
+	I-Method
all	O
follow	O
the	O
same	O
structure	O
of	O
MemNN	B-Method
from	O
a	O
broad	O
perspective	O
,	O
however	O
,	O
output	O
feature	O
map	O
is	O
composed	O
in	O
slightly	O
different	O
way	O
.	O
	
The	O
relation	O
between	O
question	O
and	O
supporting	O
sentences	O
is	O
realized	O
from	O
its	O
cooperation	O
.	O
	
MemN2N	B-Method
first	O
calculates	O
the	O
relatedness	O
of	O
sentences	O
in	O
the	O
question	O
and	O
memory	O
by	O
taking	O
the	O
inner	O
product	O
,	O
and	O
the	O
sentence	O
with	O
the	O
highest	O
relatedness	O
is	O
selected	O
as	O
the	O
first	O
supporting	O
sentence	O
for	O
the	O
given	O
question	O
.	O
	
The	O
first	O
supporting	O
sentence	O
is	O
then	O
added	O
with	O
the	O
question	O
and	O
repeat	O
the	O
same	O
operation	O
with	O
the	O
updated	O
memory	O
to	O
find	O
the	O
second	O
supporting	O
sentence	O
.	O
	
GMemN2N	B-Method
selects	O
the	O
supporting	O
sentence	O
in	O
the	O
same	O
way	O
as	O
MemN2N	B-Method
,	O
but	O
uses	O
the	O
gate	O
to	O
selectively	O
add	O
the	O
the	O
question	O
to	O
control	O
the	O
influence	O
of	O
the	O
question	O
information	O
in	O
finding	O
the	O
supporting	O
sentence	O
in	O
the	O
next	O
step	O
.	O
	
DMN	B-Method
and	I-Method
DMN	I-Method
+	I-Method
use	O
output	B-Method
feature	I-Method
map	I-Method
based	O
on	O
various	O
relatedness	O
such	O
as	O
absolute	O
difference	O
,	O
as	O
well	O
as	O
inner	O
product	O
,	O
to	O
understand	O
the	O
relation	O
between	O
sentence	O
and	O
question	O
at	O
various	O
points	O
.	O
	
The	O
more	O
difficult	O
the	O
task	O
,	O
the	O
more	O
complex	O
the	O
output	O
feature	O
map	O
and	O
the	O
generalization	B-Method
component	I-Method
to	O
get	O
the	O
correct	O
answer	O
.	O
	
For	O
a	O
dataset	O
experimenting	O
the	O
text	B-Task
-	I-Task
based	I-Task
reasoning	I-Task
ability	I-Task
of	O
the	O
model	O
,	O
the	O
overall	O
accuracy	B-Metric
could	O
be	O
increased	O
in	O
order	O
of	O
MemN2N	B-Method
,	O
GMemN2N	B-Method
,	O
DMN	B-Method
,	O
and	O
DMN	B-Method
+	I-Method
,	O
where	O
the	O
complexity	B-Metric
of	O
the	O
component	O
increases	O
.	O
	
section	O
:	O
RELATION	B-Method
NETWORK	I-Method
	
Relation	B-Method
Network	I-Method
(	O
RN	B-Method
)	O
has	O
emerged	O
as	O
a	O
new	O
and	O
simpler	O
framework	O
for	O
solving	O
the	O
general	B-Task
reasoning	I-Task
problem	I-Task
.	O
	
RN	B-Method
takes	O
in	O
a	O
pair	O
of	O
objects	O
as	O
its	O
input	O
and	O
simply	O
learns	O
from	O
the	O
compositions	O
of	O
two	O
MLPs	B-Method
represented	O
as	O
g	O
θ	O
and	O
f	O
φ	O
.	O
	
The	O
role	O
of	O
each	O
MLP	B-Method
is	O
not	O
clearly	O
defined	O
in	O
the	O
original	O
paper	O
,	O
but	O
from	O
the	O
view	O
of	O
MemNN	B-Method
,	O
it	O
can	O
be	O
understood	O
that	O
g	O
θ	O
corresponds	O
to	O
O	O
and	O
f	O
φ	O
corresponds	O
to	O
R.	O
Table	O
1	O
summarizes	O
the	O
interpretation	O
of	O
RN	B-Method
compared	O
to	O
MemN2N	B-Method
and	O
our	O
model	O
,	O
RMN	B-Method
.	O
	
To	O
verify	O
the	O
role	O
of	O
g	O
θ	O
,	O
we	O
compare	O
the	O
output	O
when	O
pairs	O
are	O
made	O
with	O
supporting	O
sentences	O
and	O
when	O
made	O
with	O
unrelated	O
sentences	O
.	O
	
Figure	O
2	O
shows	O
the	O
visualization	O
result	O
of	O
each	O
output	O
.	O
	
When	O
we	O
focus	O
on	O
whether	O
the	O
value	O
is	O
activated	O
or	O
not	O
,	O
we	O
can	O
see	O
that	O
g	O
θ	O
distinguishes	O
supporting	O
sentence	O
pair	O
from	O
non	O
-	O
supporting	O
sentence	O
pair	O
as	O
output	O
feature	O
map	O
examines	O
how	O
relevant	O
the	O
sentence	O
is	O
to	O
the	O
question	O
.	O
	
Therefore	O
,	O
we	O
can	O
comprehend	O
the	O
output	O
of	O
g	O
θ	O
reveals	O
the	O
relation	O
between	O
the	O
object	O
pair	O
and	O
the	O
question	O
and	O
f	O
φ	O
aggregates	O
all	O
these	O
outputs	O
to	O
infer	O
the	O
answer	O
.	O
	
bAbI	B-Material
story	I-Material
-	I-Material
based	I-Material
QA	I-Material
dataset	I-Material
bAbI	I-Material
story	I-Material
-	I-Material
based	I-Material
QA	I-Material
dataset	I-Material
is	O
composed	O
of	O
20	O
different	O
types	O
of	O
tasks	O
for	O
testing	O
natural	B-Task
language	I-Task
reasoning	I-Task
ability	I-Task
.	O
	
Each	O
task	O
requires	O
different	O
methods	O
to	O
infer	O
the	O
answer	O
.	O
	
The	O
dataset	O
includes	O
a	O
set	O
of	O
statements	O
comprised	O
of	O
multiple	O
sentences	O
,	O
a	O
question	O
and	O
answer	O
.	O
	
A	O
statement	O
can	O
be	O
as	O
short	O
as	O
two	O
sentences	O
and	O
as	O
long	O
as	O
320	O
sentences	O
.	O
	
To	O
answer	O
the	O
question	O
,	O
it	O
is	O
necessary	O
to	O
find	O
relevant	O
one	O
or	O
more	O
sentences	O
to	O
a	O
given	O
question	O
and	O
derive	O
answer	O
from	O
them	O
.	O
	
Answer	O
is	O
typically	O
a	O
single	O
word	O
but	O
in	O
a	O
few	O
tasks	O
,	O
answers	O
are	O
a	O
set	O
of	O
words	O
.	O
	
Each	O
task	O
is	O
regarded	O
as	O
success	O
when	O
the	O
accuracy	B-Metric
is	O
greater	O
than	O
95	O
%	O
.	O
	
There	O
are	O
two	O
versions	O
of	O
this	O
dataset	O
,	O
one	O
that	O
has	O
1k	O
training	O
examples	O
and	O
the	O
other	O
with	O
10k	O
examples	O
.	O
	
Most	O
of	O
the	O
previous	O
models	O
test	O
their	O
accuracy	B-Metric
on	O
10k	O
dataset	O
with	O
trained	O
jointly	O
.	O
	
bAbI	B-Material
dialog	I-Material
dataset	I-Material
bAbI	I-Material
dialog	I-Material
dataset	I-Material
[	O
reference	O
]	O
)	O
is	O
a	O
set	O
of	O
5	O
tasks	O
within	O
the	O
goal	O
-	O
oriented	O
context	O
of	O
restaurant	B-Task
reservation	I-Task
.	O
	
It	O
is	O
designed	O
to	O
test	O
if	O
model	O
can	O
learn	O
various	O
abilities	O
such	O
as	O
performing	O
dialog	B-Task
management	I-Task
,	O
querying	O
knowledge	O
bases	O
(	O
KBs	O
)	O
,	O
and	O
interpreting	O
the	O
output	O
of	O
such	O
queries	O
.	O
	
The	O
KB	O
can	O
be	O
queried	O
using	O
API	O
calls	O
and	O
4	O
fields	O
(	O
a	O
type	O
of	O
cuisine	O
,	O
a	O
location	O
,	O
a	O
price	O
range	O
,	O
and	O
a	O
party	O
size	O
)	O
.	O
	
They	O
should	O
be	O
filled	O
to	O
issue	O
an	O
API	O
call	O
.	O
	
Task	O
1	O
tests	O
the	O
capacity	O
of	O
interpreting	O
a	O
request	O
and	O
asking	O
the	O
right	O
questions	O
to	O
issue	O
an	O
API	O
call	O
.	O
	
Task	O
2	O
checks	O
the	O
ability	O
to	O
modify	O
an	O
API	O
call	O
.	O
	
Task	O
3	O
and	O
4	O
test	O
the	O
capacity	O
of	O
using	O
outputs	O
from	O
an	O
API	B-Method
call	I-Method
to	O
propose	O
options	O
in	O
the	O
order	O
of	O
rating	O
and	O
to	O
provide	O
extra	O
-	O
information	O
of	O
what	O
user	O
asks	O
for	O
.	O
	
Task	O
5	O
combines	O
everything	O
.	O
	
The	O
maximum	O
length	O
of	O
the	O
dialog	O
for	O
each	O
task	O
is	O
different	O
:	O
14	O
for	O
task	O
1	O
,	O
20	O
for	O
task	O
2	O
,	O
78	O
for	O
task	O
3	O
,	O
13	O
for	O
task	O
4	O
,	O
and	O
96	O
for	O
task	O
5	O
.	O
	
As	O
restaurant	O
name	O
,	O
locations	O
,	O
and	O
cuisine	O
types	O
always	O
face	O
new	O
entities	O
,	O
there	O
are	O
normal	B-Task
and	O
OOV	O
test	O
sets	O
to	O
assess	O
model	O
's	O
generalization	B-Metric
ability	I-Metric
.	O
	
Training	O
sets	O
consist	O
fo	O
1k	O
examples	O
,	O
which	O
is	O
not	O
a	O
large	O
amount	O
of	O
creating	O
realistic	O
learning	O
conditions	O
.	O
	
section	O
:	O
TRAINING	O
DETAILS	O
	
bAbI	B-Material
story	I-Material
-	I-Material
based	I-Material
QA	I-Material
dataset	I-Material
	
We	O
trained	O
2	O
hop	O
RMN	B-Method
jointly	O
on	O
all	O
tasks	O
using	O
10k	O
dataset	O
for	O
model	O
to	O
infer	O
the	O
solution	O
suited	O
to	O
each	O
type	O
of	O
tasks	O
.	O
	
We	O
limited	O
the	O
input	O
to	O
the	O
last	O
70	O
stories	O
for	O
all	O
tasks	O
except	O
task	O
3	O
for	O
which	O
we	O
limited	O
input	O
to	O
the	O
last	O
130	O
stories	O
,	O
similar	O
to	O
[	O
reference	O
]	O
which	O
is	O
the	O
hardest	O
condition	O
among	O
previous	O
models	O
.	O
	
Then	O
,	O
we	O
labeled	O
each	O
sentence	O
with	O
its	O
relative	O
position	O
.	O
	
Embedding	B-Method
component	I-Method
is	O
similar	O
to	O
[	O
reference	O
]	O
,	O
where	O
story	O
and	O
question	O
are	O
embedded	O
through	O
different	O
LSTMs	B-Method
;	O
32	O
unit	B-Method
word	I-Method
-	I-Method
lookup	I-Method
embeddings	I-Method
;	O
32	O
unit	O
LSTM	B-Method
for	O
story	B-Task
and	I-Task
question	I-Task
.	O
	
For	O
attention	B-Task
component	I-Task
,	O
as	O
we	O
use	O
2	O
hop	O
RMN	B-Method
,	O
there	O
are	O
g	O
1	O
θ	O
and	O
g	O
2	O
θ	O
;	O
both	O
are	O
three	O
-	O
layer	O
MLP	B-Method
consisting	O
of	O
256	O
,	O
128	O
,	O
1	O
unit	O
with	O
ReLU	O
activation	O
function	O
[	O
reference	O
]	O
.	O
f	O
φ	O
is	O
composed	O
of	O
512	O
,	O
512	O
,	O
and	O
159	O
units	O
(	O
the	O
number	O
of	O
words	O
appearing	O
in	O
bAbI	B-Material
dataset	I-Material
is	O
159	O
)	O
of	O
three	O
-	O
layer	O
MLP	B-Method
with	O
ReLU	B-Method
non	I-Method
-	I-Method
linearities	I-Method
where	O
the	O
final	O
layer	O
was	O
a	O
linear	O
that	O
produced	O
logits	O
for	O
a	O
softmax	O
over	O
the	O
answer	O
vocabulary	O
.	O
	
For	O
regularization	B-Task
,	O
we	O
use	O
batch	B-Method
normalization	I-Method
[	O
reference	O
]	O
for	O
all	O
MLPs	B-Method
.	O
	
The	O
softmax	O
output	O
was	O
optimized	O
with	O
a	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
loss	I-Metric
function	I-Metric
using	O
the	O
Adam	B-Method
optimizer	I-Method
[	O
reference	O
]	O
)	O
with	O
a	O
learning	B-Metric
rate	I-Metric
of	O
2e	O
−4	O
.	O
	
bAbI	B-Material
dialog	I-Material
dataset	I-Material
We	O
trained	O
on	O
full	O
dialog	O
scripts	O
with	O
every	O
model	O
response	O
as	O
answer	O
,	O
all	O
previous	O
dialog	O
history	O
as	O
sentences	O
to	O
be	O
memorized	O
,	O
and	O
the	O
last	O
user	O
utterance	O
as	O
question	O
.	O
	
Model	O
selects	O
the	O
most	O
probable	O
response	O
from	O
4	O
,	O
212	O
candidates	O
which	O
are	O
ranked	O
from	O
a	O
set	O
of	O
all	O
bot	O
utterances	O
appearing	O
in	O
training	O
,	O
validation	O
and	O
test	O
sets	O
(	O
plain	O
and	O
OOV	O
)	O
for	O
all	O
tasks	O
combined	O
.	O
	
We	O
also	O
report	O
results	O
when	O
we	O
use	O
match	O
type	O
features	O
for	O
dialog	B-Task
.	O
	
Match	O
type	O
feature	O
is	O
an	O
additional	O
label	O
on	O
the	O
candidates	O
indicating	O
if	O
word	O
is	O
found	O
on	O
the	O
dialog	O
history	O
.	O
	
For	O
example	O
,	O
if	O
the	O
concentrate	O
on	O
the	O
same	O
sentences	O
which	O
are	O
all	O
critical	O
to	O
answer	O
the	O
question	O
,	O
and	O
sometimes	O
g	O
1	O
θ	O
finds	O
a	O
fact	O
related	O
to	O
the	O
given	O
question	O
and	O
with	O
this	O
information	O
g	O
2	O
θ	O
chooses	O
the	O
key	O
fact	O
to	O
answer	O
.	O
	
While	O
trained	O
jointly	O
,	O
RMN	B-Method
learns	O
these	O
different	O
solutions	O
for	O
each	O
task	O
.	O
	
For	O
the	O
task	O
3	O
,	O
the	O
only	O
failed	O
task	O
,	O
attention	B-Method
component	I-Method
still	O
functions	O
well	O
	
;	O
it	O
focuses	O
sequentially	O
on	O
the	O
supporting	O
sentences	O
.	O
	
However	O
,	O
the	O
reasoning	B-Method
component	I-Method
,	O
f	O
φ	O
,	O
had	O
difficulty	O
catching	O
the	O
word	O
'	O
before	O
'	O
.	O
	
We	O
could	O
easily	O
figure	O
out	O
'	O
before	O
'	O
implies	O
'	O
just	O
before	O
'	O
the	O
certain	O
situation	O
,	O
whereas	O
RMN	B-Method
confused	O
its	O
meaning	O
.	O
	
As	O
shown	O
in	O
table	O
3c	O
,	O
our	O
model	O
found	O
all	O
previous	O
locations	O
before	O
the	O
garden	O
.	O
	
Still	O
,	O
it	O
is	O
remarkable	O
that	O
the	O
simple	O
MLP	B-Method
carried	O
out	O
all	O
of	O
these	O
various	O
roles	O
.	O
	
section	O
:	O
BABI	B-Task
DIALOG	I-Task
	
The	O
results	O
in	O
the	O
Table	O
4	O
show	O
that	O
the	O
RMN	B-Method
has	O
the	O
best	O
results	O
in	O
any	O
conditions	O
.	O
	
Without	O
any	O
match	O
type	O
,	O
RN	B-Method
and	O
RMN	B-Method
outperform	O
previous	O
memory	B-Method
-	I-Method
augmented	I-Method
models	I-Method
on	O
both	O
normal	B-Task
and	O
OOV	B-Task
tasks	I-Task
.	O
	
This	O
is	O
mainly	O
attributed	O
to	O
the	O
impressive	O
result	O
on	O
task	O
4	O
which	O
can	O
be	O
interpreted	O
as	O
an	O
effect	O
of	O
MLP	B-Method
based	O
output	O
feature	O
map	O
.	O
	
To	O
solve	O
task	O
4	O
,	O
it	O
is	O
critical	O
to	O
understand	O
the	O
relation	O
between	O
'	O
phone	O
number	O
'	O
of	O
user	O
input	O
and	O
'	O
r	O
phone	O
'	O
of	O
previous	O
dialog	O
as	O
shown	O
in	O
Table	O
8c	O
.	O
	
We	O
assumed	O
that	O
inner	O
product	O
was	O
not	O
sufficient	O
to	O
capture	O
their	O
implicit	O
similarity	O
and	O
performed	O
an	O
supporting	O
experiment	O
.	O
	
We	O
converted	O
RMN	B-Method
's	I-Method
attention	I-Method
component	I-Method
to	O
inner	B-Method
product	I-Method
based	I-Method
attention	I-Method
,	O
and	O
the	O
results	O
revealed	O
the	O
error	B-Metric
rate	I-Metric
increased	O
to	O
11.3	O
%	O
.	O
	
For	O
the	O
task	O
3	O
and	O
task	O
5	O
where	O
the	O
maximum	O
length	O
is	O
especially	O
longer	O
than	O
the	O
others	O
,	O
RN	B-Method
performs	O
worse	O
than	O
MemN2N	B-Method
,	O
GMemN2N	B-Method
and	O
RMN	B-Method
.	O
	
The	O
number	O
of	O
unnecessary	O
object	O
pairs	O
created	O
by	O
the	O
RN	B-Method
not	O
only	O
increases	O
the	O
processing	B-Metric
time	I-Metric
but	O
also	O
decreases	O
the	O
accuracy	B-Metric
.	O
	
With	O
the	O
match	O
type	O
feature	O
,	O
all	O
models	O
other	O
than	O
RMN	B-Method
have	O
significantly	O
improved	O
their	O
performance	O
except	O
for	O
task	O
3	O
compared	O
to	O
the	O
plain	O
condition	O
.	O
	
RMN	B-Method
was	O
helped	O
by	O
the	O
match	O
type	O
only	O
on	O
the	O
OOV	B-Task
tasks	I-Task
and	O
this	O
implies	O
RMN	B-Method
is	O
able	O
to	O
find	O
relation	O
in	O
the	O
With	O
Match	O
condition	O
for	O
the	O
normal	B-Task
tasks	O
.	O
	
When	O
we	O
look	O
at	O
the	O
OOV	B-Task
tasks	I-Task
more	O
precisely	O
,	O
RMN	B-Method
failed	O
to	O
perform	O
well	O
on	O
the	O
OOV	B-Task
task	I-Task
1	O
and	O
2	O
even	O
though	O
g	O
1	O
θ	O
properly	O
focused	O
on	O
the	O
related	O
object	O
as	O
shown	O
in	O
Table	O
8a	O
.	O
	
We	O
state	O
that	O
this	O
originated	O
from	O
the	O
fact	O
that	O
the	O
number	O
of	O
keywords	O
in	O
task	O
1	O
and	O
2	O
is	O
bigger	O
than	O
that	O
in	O
task	O
4	O
.	O
	
In	O
task	O
1	O
and	O
2	O
,	O
all	O
four	O
keywords	O
(	O
cuisine	O
,	O
location	O
,	O
number	O
and	O
price	O
)	O
must	O
be	O
correctly	O
aligned	O
from	O
the	O
supporting	O
sentence	O
in	O
order	O
to	O
make	O
the	O
correct	O
API	O
call	O
which	O
is	O
harder	O
than	O
task	O
4	O
.	O
	
Consider	O
the	O
example	O
in	O
Table	O
8a	O
and	O
Table	O
8c	O
.	O
	
Supporting	O
sentence	O
of	O
task	O
4	O
have	O
one	O
keyword	O
out	O
of	O
three	O
words	O
,	O
whereas	O
supporting	O
sentences	O
of	O
task	O
1	O
and	O
2	O
consist	O
of	O
four	O
keywords	O
(	O
cuisine	O
,	O
location	O
,	O
number	O
and	O
price	O
)	O
out	O
of	O
sixteen	O
words	O
.	O
	
Different	O
from	O
other	O
tasks	O
,	O
RMN	B-Method
yields	O
the	O
same	O
error	B-Metric
rate	I-Metric
25.1	O
%	O
with	O
MemN2N	B-Method
and	O
GMemN2N	B-Method
on	O
the	O
task	O
3	O
.	O
	
The	O
main	O
goal	O
of	O
task	O
3	O
is	O
to	O
recommend	O
restaurant	O
from	O
knowledge	B-Material
base	I-Material
in	O
the	O
order	O
of	O
rating	O
.	O
	
All	O
failed	O
cases	O
are	O
displaying	O
restaurant	O
where	O
the	O
user	O
input	O
is	O
<	O
silence	O
>	O
which	O
is	O
somewhat	O
an	O
ambiguous	O
trigger	O
to	O
find	O
the	O
input	O
relevant	O
previous	O
utterance	O
.	O
	
As	O
shown	O
in	O
Table	O
8b	O
,	O
there	O
are	O
two	O
different	O
types	O
of	O
response	O
to	O
the	O
same	O
user	O
input	O
.	O
	
One	O
is	O
to	O
check	O
whether	O
all	O
the	O
required	O
fields	O
are	O
given	O
from	O
the	O
previous	O
utterances	O
and	O
then	O
ask	O
user	O
for	O
the	O
missing	O
fields	O
or	O
send	O
a	O
"	O
Ok	O
let	O
me	O
look	O
into	O
some	O
options	O
for	O
you	O
.	O
"	O
message	O
.	O
	
The	O
other	O
type	O
is	O
to	O
recommend	O
restaurant	O
starting	O
from	O
the	O
highest	O
rating	O
.	O
	
All	O
models	O
show	O
lack	O
of	O
ability	O
to	O
discriminate	O
these	O
two	O
types	O
of	O
silences	O
so	O
that	O
concluded	O
to	O
the	O
same	O
results	O
.	O
	
To	O
verify	O
our	O
statement	O
,	O
we	O
performed	O
an	O
additional	O
experiment	O
on	O
task	O
3	O
and	O
checked	O
the	O
performance	O
gain	O
(	O
extra	O
result	O
is	O
given	O
in	O
Table	O
10	O
of	O
Appendix	O
B	O
)	O
.	O
	
section	O
:	O
MODEL	B-Method
ANALYSIS	I-Method
	
Effectiveness	O
of	O
the	O
MLP	B-Method
-	O
based	O
output	O
feature	O
map	O
The	O
most	O
important	O
feature	O
that	O
distinguishes	O
MemNN	B-Method
based	I-Method
models	I-Method
is	O
the	O
output	O
feature	O
map	O
.	O
	
Table	O
5	O
summarizes	O
the	O
experimental	O
results	O
for	O
the	O
bAbI	B-Material
story	I-Material
-	I-Material
based	I-Material
QA	I-Material
dataset	I-Material
when	O
replacing	O
the	O
RMN	B-Method
's	O
MLP	B-Method
-	O
based	O
output	O
feature	O
map	O
with	O
the	O
idea	O
of	O
the	O
previous	O
models	O
.	O
	
inner	B-Method
product	I-Method
was	O
used	O
in	O
MemN2N	B-Method
,	O
inner	B-Method
product	I-Method
with	O
gate	B-Method
was	O
used	O
in	O
GMemN2N	B-Method
,	O
and	O
inner	O
product	O
and	O
absolute	O
difference	O
with	O
two	O
embedding	O
matrices	O
was	O
used	O
in	O
DMN	B-Method
and	O
DMN	B-Method
+	I-Method
.	O
	
From	O
the	O
Table	O
5	O
,	O
the	O
more	O
complex	O
the	O
output	O
feature	O
map	O
,	O
the	O
better	O
the	O
overall	O
performance	O
.	O
	
In	O
this	O
point	O
of	O
view	O
,	O
MLP	B-Method
is	O
the	O
effective	O
output	O
feature	O
map	O
.	O
	
Performance	O
of	O
RN	B-Method
and	O
RMN	B-Method
according	O
to	O
memory	B-Metric
size	I-Metric
Additional	O
experiments	O
were	O
conducted	O
with	O
the	O
bAbI	B-Material
story	I-Material
-	I-Material
based	I-Material
QA	I-Material
dataset	I-Material
to	O
see	O
how	O
memory	O
size	O
affects	O
both	O
performance	O
and	O
training	B-Metric
time	I-Metric
of	O
RN	B-Method
and	O
RMN	B-Method
.	O
	
Test	B-Metric
errors	I-Metric
with	O
training	B-Metric
time	I-Metric
written	O
in	O
parentheses	O
are	O
summarized	O
in	O
Table	O
6	O
.	O
	
When	O
memory	O
size	O
is	O
small	O
,	O
we	O
could	O
observe	O
the	O
data	O
-	O
effeciency	O
of	O
RN	B-Method
.	O
	
It	O
shows	O
similar	O
performance	O
to	O
RMN	B-Method
in	O
less	O
time	O
.	O
	
However	O
,	O
when	O
the	O
memory	O
size	O
increases	O
,	O
performance	O
is	O
significantly	O
reduced	O
compared	O
to	O
RMN	B-Method
,	O
even	O
though	O
it	O
has	O
been	O
learned	O
for	O
a	O
longer	O
time	O
.	O
	
It	O
is	O
even	O
lower	O
than	O
itself	O
when	O
the	O
memory	O
size	O
is	O
20	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
RMN	B-Method
maintains	O
high	O
performance	O
even	O
when	O
the	O
memory	O
size	O
increases	O
.	O
	
Effectiveness	O
of	O
the	O
number	O
of	O
hops	B-Material
bAbI	I-Material
story	I-Material
based	I-Material
QA	I-Material
dataset	I-Material
differs	O
in	O
the	O
number	O
of	O
supporting	O
sentences	O
by	O
each	O
task	O
that	O
need	O
to	O
be	O
referenced	O
to	O
solve	O
problems	O
.	O
	
For	O
example	O
,	O
task	O
1	O
,	O
2	O
,	O
and	O
3	O
require	O
single	O
,	O
two	O
,	O
and	O
three	O
supporting	O
facts	O
,	O
respectively	O
.	O
	
The	O
result	O
of	O
the	O
mean	B-Metric
error	I-Metric
rate	I-Metric
for	O
each	O
task	O
according	O
to	O
the	O
number	O
of	O
hops	O
is	O
in	O
Table	O
7	O
.	O
	
Overall	O
,	O
the	O
number	O
of	O
hops	O
is	O
correlated	O
with	O
the	O
number	O
of	O
supporting	O
sentences	O
.	O
	
In	O
this	O
respect	O
,	O
when	O
the	O
number	O
of	O
relations	O
increases	O
,	O
RMN	B-Method
could	O
reason	O
across	O
increasing	O
the	O
number	O
of	O
hops	O
to	O
3	O
,	O
4	O
or	O
more	O
.	O
	
section	O
:	O
CONCLUSION	O
	
Our	O
work	O
,	O
RMN	B-Method
,	O
is	O
a	O
simple	O
and	O
powerful	O
architecture	O
that	O
effectively	O
handles	O
text	B-Task
-	I-Task
based	I-Task
question	I-Task
answering	I-Task
tasks	I-Task
when	O
large	O
size	O
of	O
memory	O
and	O
high	O
reasoning	B-Metric
ability	I-Metric
is	O
required	O
.	O
	
Multiple	O
access	O
to	O
the	O
external	O
memory	O
to	O
find	O
out	O
necessary	O
information	O
through	O
a	O
multi	B-Method
-	I-Method
hop	I-Method
approach	I-Method
is	O
similar	O
to	O
most	O
existing	O
approaches	O
.	O
	
However	O
,	O
by	O
using	O
a	O
MLP	B-Method
that	O
can	O
effectively	O
deal	O
with	O
complex	O
relatedness	O
when	O
searching	O
for	O
the	O
right	O
supporting	O
sentences	O
among	O
a	O
lot	O
of	O
sentences	O
,	O
RMN	B-Method
raised	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
the	O
story	B-Task
-	I-Task
based	I-Task
QA	I-Task
and	O
goal	B-Task
-	I-Task
oriented	I-Task
dialog	I-Task
dataset	I-Task
.	O
	
When	O
comparing	O
RN	B-Method
which	O
also	O
used	O
MLP	B-Method
to	O
understand	O
relations	O
,	O
RMN	B-Method
was	O
more	O
effective	O
in	O
the	O
case	O
of	O
large	O
memory	O
.	O
	
Future	O
work	O
will	O
apply	O
RMN	B-Method
to	O
image	B-Task
based	I-Task
reasoning	I-Task
task	I-Task
(	O
e.g.	O
,	O
CLEVR	B-Task
,	O
DAQUAR	B-Task
,	O
VQA	B-Task
etc	O
.	O
)	O
.	O
	
To	O
extract	O
features	O
from	O
the	O
image	O
,	O
VGG	B-Method
net	I-Method
[	O
reference	O
]	O
)	O
is	O
used	O
in	O
convention	O
and	O
outputs	O
196	O
objects	O
of	O
512	O
dimensional	O
vectors	O
which	O
also	O
require	O
large	O
sized	O
memory	O
.	O
	
An	O
important	O
direction	O
will	O
be	O
to	O
find	O
an	O
appropriate	O
way	O
to	O
focus	O
sequentially	O
on	O
related	O
object	O
which	O
was	O
rather	O
easy	O
in	O
text	B-Task
-	I-Task
based	I-Task
reasoning	I-Task
.	O
	
5	O
Number	O
in	O
parentheses	O
indicates	O
the	O
number	O
of	O
supporting	O
sentences	O
to	O
solve	O
the	O
task	O
	
A	O
MODEL	O
DETAILS	O
	
We	O
modify	O
the	O
user	O
input	O
from	O
<	O
silence	O
>	O
to	O
<	O
silence><silence	O
>	O
when	O
looking	O
for	O
restaurant	B-Task
recommendations	I-Task
.	O
	
This	O
makes	O
model	O
to	O
distinguish	O
two	O
different	O
situations	O
whether	O
to	O
ask	O
for	O
additional	O
fields	O
or	O
to	O
recommend	O
restaurant	O
.	O
	
section	O
:	O
	
document	O
:	O
Deep	B-Task
Identity	I-Task
-	I-Task
Aware	I-Task
Transfer	I-Task
of	I-Task
Facial	I-Task
Attributes	I-Task
	
This	O
paper	O
presents	O
a	O
Deep	B-Method
convolutional	I-Method
network	I-Method
model	I-Method
for	O
Identity	B-Task
-	I-Task
Aware	I-Task
Transfer	I-Task
(	O
DIAT	B-Task
)	O
of	O
facial	O
attributes	O
.	O
	
Given	O
the	O
source	O
input	O
image	O
and	O
the	O
reference	O
attribute	O
,	O
DIAT	B-Task
aims	O
to	O
generate	O
a	O
facial	O
image	O
that	O
owns	O
the	O
reference	O
attribute	O
as	O
well	O
as	O
keeps	O
the	O
same	O
or	O
similar	O
identity	O
to	O
the	O
input	O
image	O
.	O
	
In	O
general	O
,	O
our	O
model	O
consists	O
of	O
a	O
mask	B-Method
network	I-Method
and	O
an	O
attribute	B-Method
transform	I-Method
network	I-Method
which	O
work	O
in	O
synergy	O
to	O
generate	O
photo	O
-	O
realistic	O
facial	O
image	O
with	O
the	O
reference	O
attribute	O
.	O
	
Considering	O
that	O
the	O
reference	O
attribute	O
may	O
be	O
only	O
related	O
to	O
some	O
parts	O
of	O
the	O
image	O
,	O
the	O
mask	B-Method
network	I-Method
is	O
introduced	O
to	O
avoid	O
the	O
incorrect	O
editing	O
on	O
attribute	O
irrelevant	O
region	O
.	O
	
Then	O
the	O
estimated	O
mask	O
is	O
adopted	O
to	O
combine	O
the	O
input	O
and	O
transformed	O
image	O
for	O
producing	O
the	O
transfer	O
result	O
.	O
	
For	O
joint	B-Task
training	I-Task
of	I-Task
transform	I-Task
network	I-Task
and	O
mask	B-Method
network	I-Method
,	O
we	O
incorporate	O
the	O
adversarial	B-Method
attribute	I-Method
loss	I-Method
,	O
identity	B-Method
aware	I-Method
adaptive	I-Method
perceptual	I-Method
loss	I-Method
and	O
VGG	B-Method
-	I-Method
FACE	I-Method
based	I-Method
identity	I-Method
loss	I-Method
.	O
	
Furthermore	O
,	O
a	O
denoising	B-Method
network	I-Method
is	O
presented	O
to	O
serve	O
for	O
perceptual	B-Task
regularization	I-Task
to	O
suppress	O
the	O
artifacts	O
in	O
transfer	O
result	O
,	O
while	O
an	O
attribute	B-Method
ratio	I-Method
regularization	I-Method
is	O
introduced	O
to	O
constrain	O
the	O
size	O
of	O
attribute	O
relevant	O
region	O
.	O
	
Our	O
DIAT	B-Task
can	O
provide	O
a	O
unified	O
solution	O
for	O
several	O
representative	O
facial	B-Task
attribute	I-Task
transfer	I-Task
tasks	I-Task
,	O
e	O
.	O
g	O
.	O
,	O
expression	B-Task
transfer	I-Task
,	O
accessory	B-Task
removal	I-Task
,	O
age	B-Task
progression	I-Task
and	O
gender	B-Task
transfer	I-Task
,	O
and	O
can	O
be	O
extended	O
for	O
other	O
face	B-Task
enhancement	I-Task
tasks	I-Task
such	O
as	O
face	B-Task
hallucination	I-Task
.	O
	
The	O
experimental	O
results	O
validate	O
the	O
effectiveness	O
of	O
the	O
proposed	O
method	O
.	O
	
Even	O
for	O
the	O
identity	O
-	O
related	O
attribute	O
(	O
e	O
.	O
g	O
.	O
,	O
gender	O
)	O
,	O
our	O
DIAT	B-Task
can	O
obtain	O
visually	O
impressive	O
results	O
by	O
changing	O
the	O
attribute	O
while	O
retaining	O
most	O
identity	O
-	O
aware	O
features	O
.	O
	
Facial	B-Task
attribute	I-Task
transfer	I-Task
,	O
generative	B-Method
adversarial	I-Method
nets	I-Method
,	O
convolutional	B-Method
networks	I-Method
,	O
perceptual	B-Task
loss	I-Task
.	O
	
section	O
:	O
Introduction	O
	
Face	O
attributes	O
,	O
e	O
.	O
	
g	O
.	O
,	O
gender	O
and	O
expression	O
,	O
can	O
not	O
only	O
provide	O
a	O
natural	O
description	O
of	O
facial	O
images	O
,	O
but	O
also	O
offer	O
a	O
unified	O
viewpoint	O
for	O
understanding	O
many	O
facial	B-Task
animation	I-Task
and	I-Task
manipulation	I-Task
tasks	I-Task
.	O
	
For	O
example	O
,	O
the	O
goal	O
of	O
facial	B-Task
avatar	I-Task
and	I-Task
reenactment	I-Task
is	O
to	O
transfer	O
the	O
facial	O
expression	O
attributes	O
of	O
a	O
source	O
actor	O
to	O
a	O
target	O
actor	O
.	O
	
In	O
most	O
applications	O
such	O
as	O
expression	B-Task
transfer	I-Task
,	O
accessory	B-Task
removal	I-Task
and	O
age	B-Task
progression	I-Task
,	O
the	O
animation	B-Method
only	O
modifies	O
the	O
related	O
attribute	O
without	O
changing	O
the	O
identity	O
.	O
	
But	O
for	O
some	O
other	O
tasks	O
,	O
the	O
change	O
of	O
some	O
attributes	O
,	O
e	O
.	O
	
g	O
.	O
,	O
gender	O
and	O
ethnicity	O
,	O
will	O
inevitably	O
alter	O
the	O
identity	O
of	O
the	O
source	O
image	O
.	O
	
In	O
recent	O
years	O
,	O
a	O
variety	O
of	O
methods	O
have	O
been	O
developed	O
for	O
specific	O
facial	B-Task
attribute	I-Task
transfer	I-Task
tasks	I-Task
,	O
and	O
have	O
achieved	O
impressive	O
results	O
.	O
	
For	O
expression	B-Task
transfer	I-Task
,	O
approaches	O
have	O
been	O
suggested	O
to	O
create	O
3D	B-Task
or	I-Task
image	I-Task
-	I-Task
based	I-Task
avatars	I-Task
from	O
hand	O
-	O
held	O
video	O
,	O
while	O
face	B-Method
trackers	I-Method
and	O
expression	B-Method
modeling	I-Method
have	O
been	O
investigated	O
for	O
offline	B-Task
and	I-Task
online	I-Task
facial	I-Task
reenactment	I-Task
.	O
	
For	O
age	B-Task
progression	I-Task
,	O
explicit	B-Method
and	I-Method
implicit	I-Method
synthesis	I-Method
methods	I-Method
have	O
been	O
proposed	O
for	O
different	O
image	B-Method
models	I-Method
.	O
	
Hair	B-Method
style	I-Method
generation	I-Method
and	O
replacement	B-Task
have	O
also	O
been	O
studied	O
in	O
literatures	O
.	O
	
Convolutional	B-Method
neural	I-Method
network	I-Method
(	O
CNN	B-Method
)-	O
based	O
models	O
have	O
also	O
been	O
investigated	O
for	O
human	B-Task
face	I-Task
generation	I-Task
with	I-Task
attributes	I-Task
.	O
	
Kulkarni	O
et	O
al	O
.	O
propose	O
deep	B-Method
convolution	I-Method
inverse	I-Method
graphic	I-Method
network	I-Method
(	O
DG	B-Method
-	I-Method
IGN	I-Method
)	O
.	O
	
This	O
method	O
requires	O
a	O
large	O
number	O
of	O
faces	O
of	O
a	O
single	O
person	O
for	O
training	O
,	O
and	O
can	O
only	O
generate	O
faces	O
with	O
different	O
pose	O
and	O
light	O
.	O
	
Gauthier	B-Method
developes	O
a	O
conditional	B-Method
generative	I-Method
adversarial	I-Method
network	I-Method
(	O
cGAN	B-Method
)	O
to	O
generate	O
facial	O
image	O
from	O
a	O
noise	O
distribution	O
and	O
conditional	O
attributes	O
.	O
	
Yan	O
et	O
al	O
.	O
suggest	O
an	O
attribute	B-Method
-	I-Method
conditioned	I-Method
deep	I-Method
variational	I-Method
auto	I-Method
-	I-Method
encoder	I-Method
which	O
extracts	O
the	O
latent	O
variables	O
from	O
a	O
reference	O
image	O
and	O
combines	O
them	O
with	O
attributes	O
to	O
produce	O
the	O
generated	O
image	O
with	O
a	O
generative	B-Method
model	I-Method
.	O
	
Oord	O
et	O
al	O
.	O
propose	O
a	O
conditional	B-Method
image	I-Method
generation	I-Method
model	I-Method
based	O
on	O
PixelCNN	B-Method
decoder	I-Method
for	O
image	B-Task
generation	I-Task
conditioned	O
on	O
an	O
arbitrary	O
feature	O
vector	O
.	O
	
However	O
,	O
the	O
identity	O
of	O
the	O
generated	O
face	O
is	O
not	O
emphasized	O
in	O
,	O
making	O
them	O
not	O
directly	O
applicable	O
to	O
attribute	B-Task
transfer	I-Task
.	O
	
Motivated	O
by	O
the	O
strong	O
capability	O
of	O
CNN	B-Method
in	O
modeling	O
complex	B-Task
transformation	I-Task
and	O
capturing	O
perceptual	O
similarity	O
,	O
several	O
approaches	O
have	O
also	O
been	O
suggested	O
for	O
facial	B-Task
attribute	I-Task
transfer	I-Task
.	O
	
Li	O
et	O
al	O
.	O
suggest	O
a	O
CNN	B-Method
-	I-Method
based	I-Method
attribute	I-Method
transfer	I-Method
model	I-Method
from	O
the	O
optimization	B-Task
perspective	I-Task
,	O
but	O
both	O
run	B-Metric
time	I-Metric
and	O
transfer	B-Metric
quality	I-Metric
is	O
far	O
from	O
satisfying	O
.	O
	
Considering	O
that	O
it	O
is	O
impracticable	O
to	O
collect	O
labeled	O
data	O
for	O
supervised	B-Task
learning	I-Task
,	O
the	O
generative	B-Method
adversarial	I-Method
net	I-Method
(	O
GAN	B-Method
)	O
framework	O
usually	O
is	O
adopted	O
for	O
handling	O
this	O
task	O
.	O
	
However	O
,	O
visible	O
artifacts	O
and	O
over	O
-	O
smoothing	O
usually	O
are	O
inevitable	O
in	O
the	O
transfer	O
result	O
for	O
these	O
methods	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
present	O
a	O
novel	O
Deep	O
CNN	B-Method
model	O
for	O
Identity	B-Task
-	I-Task
Aware	I-Task
Transfer	I-Task
(	O
DIAT	B-Task
)	O
of	O
facial	O
attributes	O
which	O
can	O
provide	O
a	O
unified	O
solution	O
to	O
several	O
facial	B-Task
animation	I-Task
and	I-Task
manipulation	I-Task
tasks	I-Task
,	O
e	O
.	O
g	O
.	O
,	O
expression	B-Task
transfer	I-Task
,	O
accessory	B-Task
removal	I-Task
,	O
age	B-Task
progression	I-Task
,	O
and	O
gender	B-Task
transfer	I-Task
.	O
	
For	O
each	O
reference	O
attribute	O
label	O
,	O
we	O
train	O
a	O
CNN	B-Method
model	O
for	O
the	O
transfer	O
of	O
the	O
input	O
image	O
to	O
the	O
desired	O
attribute	O
.	O
	
Note	O
that	O
the	O
reference	O
attribute	O
may	O
be	O
only	O
related	O
to	O
some	O
parts	O
of	O
the	O
image	O
.	O
	
To	O
avoid	O
the	O
the	O
incorrect	O
editing	O
on	O
attribute	O
irrelevant	O
region	O
,	O
our	O
model	O
consists	O
of	O
a	O
mask	B-Method
network	I-Method
and	O
an	O
attribute	B-Method
transform	I-Method
network	I-Method
.	O
	
The	O
attribute	B-Method
transform	I-Method
network	I-Method
is	O
presented	O
to	O
edit	O
the	O
input	O
image	O
for	O
generating	O
the	O
desired	O
attribute	O
.	O
	
While	O
the	O
mask	B-Method
network	I-Method
is	O
adopted	O
to	O
estimate	O
a	O
mask	O
of	O
the	O
attribute	O
relevant	O
region	O
for	O
guiding	O
the	O
combination	O
of	O
the	O
input	O
image	O
and	O
transformed	O
image	O
.	O
	
Then	O
attribute	B-Method
transform	I-Method
network	I-Method
and	O
mask	B-Method
network	I-Method
work	O
collaboratively	O
to	O
generate	O
final	O
photo	B-Task
-	I-Task
realistic	I-Task
transfer	I-Task
result	O
.	O
	
For	O
attribute	B-Task
transfer	I-Task
,	O
the	O
ground	B-Task
truth	I-Task
transfer	I-Task
results	O
generally	O
are	O
very	O
difficult	O
or	O
even	O
impossible	O
to	O
obtain	O
.	O
	
Therefore	O
,	O
we	O
follow	O
the	O
GAN	B-Method
framework	O
to	O
train	O
the	O
model	O
.	O
	
As	O
for	O
training	O
data	O
,	O
we	O
only	O
consider	O
the	O
binary	O
attribute	O
labels	O
presented	O
in	O
the	O
large	B-Material
-	I-Material
scale	I-Material
CelebFaces	I-Material
Attributes	I-Material
(	O
CelebA	B-Material
)	O
dataset	O
.	O
	
To	O
capture	O
the	O
convolutional	O
feature	O
distribution	O
of	O
each	O
attribute	O
,	O
we	O
construct	O
an	O
attribute	O
guided	O
set	O
using	O
all	O
the	O
images	O
with	O
the	O
desired	O
attribute	O
in	O
CelebA.	B-Material
	
Then	O
,	O
the	O
input	O
set	O
is	O
defined	O
as	O
a	O
set	O
of	O
input	O
images	O
without	O
the	O
reference	O
attribute	O
.	O
	
Due	O
to	O
the	O
infeasibility	O
of	O
ground	O
truth	O
transfer	O
results	O
,	O
two	O
alternative	O
losses	O
,	O
i	O
.	O
	
e	O
.	O
,	O
adversarial	B-Method
attribute	I-Method
loss	I-Method
and	O
identity	O
-	O
aware	O
perceptual	O
loss	O
,	O
are	O
incorporated	O
for	O
unsupervised	B-Task
training	I-Task
of	O
our	O
DIAT	B-Task
model	O
.	O
	
Furthermore	O
,	O
two	O
regularizers	O
,	O
i	O
.	O
	
e	O
.	O
,	O
perceptual	O
regularization	O
and	O
attribute	B-Method
ratio	I-Method
regularization	I-Method
,	O
are	O
also	O
introduced	O
in	O
the	O
learning	O
of	O
DIAT	B-Task
.	O
	
In	O
terms	O
of	O
attribute	B-Task
transfer	I-Task
,	O
the	O
generated	O
image	O
should	O
have	O
the	O
desired	O
attribute	O
label	O
.	O
	
Following	O
the	O
GAN	B-Method
framework	O
,	O
we	O
define	O
the	O
adversarial	B-Method
attribute	I-Method
loss	I-Method
on	O
the	O
attribute	B-Method
discriminator	I-Method
to	O
require	O
the	O
generated	O
image	O
to	O
have	O
the	O
desired	O
attribute	O
.	O
	
As	O
for	O
identity	B-Task
-	I-Task
aware	I-Task
transfer	I-Task
,	O
our	O
DIAT	B-Task
requires	O
that	O
the	O
generated	O
image	O
should	O
keep	O
the	O
same	O
or	O
similar	O
identity	O
to	O
the	O
input	O
image	O
.	O
	
To	O
this	O
end	O
,	O
the	O
identity	B-Task
-	I-Task
aware	I-Task
perceptual	I-Task
loss	I-Task
is	O
introduced	O
on	O
the	O
convolutional	B-Method
feature	I-Method
map	I-Method
of	O
a	O
CNN	B-Method
model	O
to	O
model	O
the	O
content	O
similarity	O
between	O
the	O
reference	O
face	O
and	O
the	O
generated	O
face	O
.	O
	
Instead	O
of	O
adopting	O
any	O
pre	B-Method
-	I-Method
trained	I-Method
CNNs	I-Method
,	O
we	O
suggest	O
to	O
define	O
the	O
perceptual	O
loss	O
on	O
the	O
attribute	B-Method
discriminator	I-Method
,	O
which	O
can	O
be	O
adaptively	O
trained	O
along	O
with	O
the	O
learning	B-Method
procedure	I-Method
,	O
and	O
is	O
named	O
as	O
adaptive	B-Method
perceptual	I-Method
loss	I-Method
.	O
	
Compared	O
with	O
conventional	O
perceptual	B-Method
loss	I-Method
,	O
ours	O
is	O
more	O
effective	O
in	O
computation	B-Task
,	O
tailored	O
to	O
our	O
specific	O
attribute	B-Task
transfer	I-Task
task	I-Task
,	O
and	O
can	O
serve	O
as	O
a	O
kind	O
of	O
hidden	B-Method
-	I-Method
layer	I-Method
supervision	I-Method
or	O
regularization	B-Method
to	O
ease	O
the	O
training	O
of	O
the	O
DIAT	B-Task
model	O
.	O
	
To	O
further	O
encourage	O
the	O
identity	O
keeping	O
property	O
,	O
we	O
add	O
an	O
identity	O
loss	O
by	O
minimizing	O
the	O
distance	O
between	O
feature	B-Method
representations	I-Method
of	O
the	O
generated	O
face	O
and	O
the	O
reference	O
.	O
	
Pre	O
-	O
trained	O
VGG	B-Method
-	I-Method
Face	I-Method
is	O
used	O
to	O
extract	O
the	O
identity	O
related	O
features	O
for	O
face	B-Task
verification	I-Task
.	O
	
The	O
model	O
objective	O
of	O
DIAT	B-Task
also	O
consider	O
two	O
regularizers	B-Method
,	O
i	O
.	O
	
e	O
.	O
,	O
perceptual	B-Method
regularization	I-Method
and	O
attribute	B-Method
ratio	I-Method
regularization	I-Method
.	O
	
To	O
suppress	O
the	O
artifacts	O
,	O
we	O
propose	O
a	O
denoising	B-Method
network	I-Method
to	O
serve	O
for	O
a	O
perceptual	B-Method
regularization	I-Method
on	O
the	O
generated	O
image	O
.	O
	
To	O
guide	O
the	O
learning	O
of	O
mask	B-Method
network	I-Method
,	O
an	O
attribute	B-Method
ratio	I-Method
regularization	I-Method
is	O
introduced	O
to	O
constrain	O
the	O
size	O
of	O
attribute	O
relevant	O
region	O
.	O
	
Finally	O
,	O
our	O
DIAT	B-Task
model	O
can	O
be	O
learned	O
from	O
training	O
data	O
by	O
incorporating	O
adversarial	B-Method
attribute	I-Method
loss	I-Method
,	O
adaptive	B-Method
perceptual	I-Method
loss	I-Method
with	O
perceptual	B-Method
regularization	I-Method
and	O
attribute	B-Method
ratio	I-Method
regularization	I-Method
.	O
	
Extensive	O
experiments	O
are	O
conducted	O
on	O
CelebA	B-Material
and	O
real	B-Material
images	I-Material
from	O
the	O
website	B-Material
iStock	I-Material
.	O
	
As	O
illustrated	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
,	O
our	O
DIAT	B-Task
performs	O
favorably	O
in	O
attribute	B-Task
transfer	I-Task
with	O
minor	O
or	O
no	O
modification	O
on	O
the	O
identity	O
of	O
the	O
input	O
faces	O
.	O
	
Even	O
for	O
some	O
identity	O
-	O
related	O
attributes	O
(	O
e	O
.	O
g	O
.	O
,	O
gender	O
)	O
,	O
our	O
DIAT	B-Task
can	O
obtain	O
visually	O
impressive	O
transfer	B-Task
result	O
while	O
retaining	O
most	O
identity	O
-	O
relevant	O
features	O
.	O
	
Computational	B-Metric
efficiency	I-Metric
is	O
also	O
a	O
prominent	O
merit	O
of	O
our	O
method	O
.	O
	
In	O
the	O
testing	O
stage	O
,	O
our	O
DIAT	B-Task
can	O
process	O
more	O
than	O
one	O
hundred	O
of	O
images	O
within	O
one	O
second	O
.	O
	
Furthermore	O
,	O
our	O
model	O
can	O
be	O
extended	O
to	O
face	B-Task
hallucination	I-Task
,	O
and	O
is	O
effective	O
in	O
generating	O
photo	B-Task
-	I-Task
realistic	I-Task
high	I-Task
resolution	I-Task
images	I-Task
.	O
	
A	O
preliminary	O
report	O
of	O
this	O
work	O
is	O
given	O
in	O
2016	O
.	O
	
To	O
sum	O
up	O
,	O
our	O
contribution	O
is	O
three	O
-	O
fold	O
:	O
A	O
novel	O
DIAT	B-Task
model	O
is	O
developed	O
for	O
facial	B-Task
attribute	I-Task
transfer	I-Task
.	O
	
For	O
better	O
preserving	O
of	O
attribute	O
irrelevant	O
feature	O
,	O
our	O
model	O
comprises	O
a	O
mask	B-Method
network	I-Method
and	O
an	O
attribute	B-Method
transform	I-Method
network	I-Method
,	O
which	O
collaborate	O
to	O
generate	O
the	O
transfer	O
result	O
and	O
can	O
be	O
jointly	O
learned	O
from	O
training	O
data	O
.	O
	
Adversarial	O
attribute	O
loss	O
,	O
adaptive	B-Method
perceptual	I-Method
loss	I-Method
,	O
identity	B-Method
loss	I-Method
,	O
perceptual	B-Method
regularization	I-Method
,	O
and	O
attribute	B-Method
ratio	I-Method
regularization	I-Method
are	O
incorporated	O
for	O
training	O
our	O
DIAT	B-Task
model	O
.	O
	
The	O
adversarial	B-Method
attribute	I-Method
loss	I-Method
is	O
adopted	O
to	O
make	O
the	O
transfer	O
result	O
exhibit	O
the	O
desired	O
attribute	O
,	O
and	O
the	O
adaptive	B-Method
perceptual	I-Method
loss	I-Method
is	O
defined	O
on	O
the	O
discriminator	B-Method
for	O
identity	B-Task
-	I-Task
aware	I-Task
transfer	I-Task
while	O
improving	O
training	B-Metric
efficiency	I-Metric
.	O
	
Moreover	O
,	O
perceptual	B-Method
regularization	I-Method
and	O
attribute	B-Method
ratio	I-Method
regularization	I-Method
are	O
further	O
introduced	O
for	O
suppressing	O
the	O
artifacts	O
and	O
constraining	O
the	O
mask	B-Method
network	I-Method
.	O
	
Experimental	O
results	O
validate	O
the	O
effectiveness	O
and	O
efficiency	O
of	O
our	O
method	O
for	O
identity	B-Task
-	I-Task
aware	I-Task
attribute	I-Task
transfer	I-Task
.	O
	
Our	O
DIAT	B-Task
can	O
be	O
used	O
for	O
the	O
transfer	B-Task
of	O
either	O
local	O
(	O
e	O
.	O
g	O
.	O
,	O
mouth	O
)	O
,	O
global	O
(	O
e	O
.	O
g	O
.	O
,	O
age	B-Task
progression	I-Task
)	O
or	O
identity	O
-	O
related	O
(	O
e	O
.	O
g	O
.	O
,	O
gender	O
)	O
attributes	O
,	O
and	O
can	O
be	O
extended	O
to	O
face	B-Task
hallucination	I-Task
.	O
	
The	O
remainder	O
of	O
the	O
paper	O
is	O
organized	O
as	O
follows	O
.	O
	
Section	O
[	O
reference	O
]	O
gives	O
a	O
brief	O
survey	O
on	O
relevant	O
work	O
.	O
	
Section	O
[	O
reference	O
]	O
describes	O
the	O
model	O
and	O
learning	O
of	O
our	O
DIAT	B-Task
method	O
.	O
	
Section	O
[	O
reference	O
]	O
reports	O
the	O
experimental	O
results	O
on	O
facial	B-Task
attribute	I-Task
transfer	I-Task
and	O
face	B-Task
hallucination	I-Task
.	O
	
Finally	O
,	O
Section	O
[	O
reference	O
]	O
ends	O
this	O
work	O
with	O
several	O
concluding	O
remarks	O
.	O
	
section	O
:	O
Related	O
work	O
	
Deep	B-Method
convolutional	I-Method
neural	I-Method
networks	I-Method
(	O
CNNs	B-Method
)	O
not	O
only	O
have	O
achieved	O
unprecedented	O
success	O
in	O
versatile	O
high	B-Task
level	I-Task
vision	I-Task
problems	I-Task
,	O
but	O
also	O
exhibited	O
their	O
remarkable	O
power	O
in	O
understanding	O
,	O
generating	B-Task
,	I-Task
and	I-Task
recovering	I-Task
images	I-Task
.	O
	
In	O
this	O
section	O
,	O
we	O
focus	O
on	O
the	O
task	O
of	O
facial	B-Task
attribute	I-Task
transfer	I-Task
,	O
and	O
briefly	O
survey	O
the	O
CNN	B-Method
models	O
for	O
image	B-Task
generation	I-Task
and	O
face	B-Task
generation	I-Task
.	O
	
subsection	O
:	O
CNN	B-Method
for	O
image	B-Task
generation	I-Task
	
Generative	B-Method
image	I-Method
modeling	I-Method
is	O
a	O
critical	O
issue	O
for	O
image	B-Task
generation	I-Task
and	O
many	O
low	B-Task
level	I-Task
vision	I-Task
problems	I-Task
.	O
	
Conventional	O
sparse	B-Method
,	I-Method
low	I-Method
rank	I-Method
,	I-Method
FRAME	I-Method
and	I-Method
non	I-Method
-	I-Method
local	I-Method
similarity	I-Method
based	I-Method
models	I-Method
usually	O
are	O
limited	O
in	O
capturing	O
highly	O
complex	O
and	O
long	O
-	O
range	O
dependence	O
between	O
pixels	O
.	O
	
For	O
better	O
image	B-Task
modeling	I-Task
,	O
a	O
number	O
of	O
CNN	B-Method
-	O
based	O
methods	O
have	O
been	O
proposed	O
,	O
including	O
convolutional	B-Method
auto	I-Method
-	I-Method
encoder	I-Method
,	O
PixelCNN	B-Method
and	O
PixelRNN	B-Method
,	O
and	O
they	O
have	O
been	O
applied	O
to	O
image	B-Task
completion	I-Task
and	I-Task
generation	I-Task
.	O
	
Several	O
CNN	B-Method
architectures	O
have	O
been	O
developed	O
for	O
image	B-Task
generation	I-Task
.	O
	
Fully	B-Method
convolutional	I-Method
networks	I-Method
can	O
be	O
trained	O
in	O
the	O
supervised	B-Method
learning	I-Method
manner	I-Method
to	O
generate	O
an	O
image	O
from	O
an	O
input	O
image	O
.	O
	
The	O
generative	O
CNN	B-Method
model	O
stacks	O
four	O
convolution	B-Method
layers	I-Method
upon	O
five	O
fully	B-Method
connected	I-Method
layers	I-Method
to	O
generate	O
images	O
from	O
object	O
description	O
.	O
	
Kulkarni	O
et	O
al	O
.	O
suggest	O
the	O
Deep	B-Method
Convolution	I-Method
Inverse	I-Method
Graphics	I-Method
Network	I-Method
(	O
DC	B-Method
-	I-Method
IGN	I-Method
)	O
,	O
which	O
follows	O
the	O
variational	B-Method
autoencoder	I-Method
architecture	I-Method
to	O
transform	O
the	O
input	O
image	O
into	O
different	O
pose	O
and	O
lighting	O
condition	O
.	O
	
However	O
,	O
both	O
generative	O
CNN	B-Method
and	O
DC	B-Method
-	I-Method
IGN	I-Method
	
require	O
many	O
labeled	O
images	O
in	O
training	O
.	O
	
To	O
visualize	O
and	O
understand	O
CNN	B-Method
features	O
,	O
several	O
methods	O
have	O
been	O
proposed	O
to	O
reconstruct	O
images	O
by	O
inverting	O
deep	B-Method
representation	I-Method
or	O
maximizing	O
class	B-Metric
score	I-Metric
.	O
	
Subsequently	O
,	O
Gatys	O
et	O
al	O
.	O
suggest	O
to	O
combine	O
content	O
and	O
style	O
losses	O
defined	O
on	O
deep	B-Method
representation	I-Method
on	O
the	O
off	O
-	O
the	O
-	O
shelf	O
CNNs	B-Method
for	O
artistic	B-Task
style	I-Task
transfer	I-Task
.	O
	
To	O
improve	O
the	O
efficiency	O
,	O
alternative	O
approaches	O
have	O
been	O
proposed	O
by	O
substituting	O
the	O
iterative	B-Method
optimization	I-Method
procedure	I-Method
with	O
pre	O
-	O
trained	O
feed	O
-	O
forward	O
CNN	B-Method
.	O
	
And	O
perceptual	O
loss	O
has	O
also	O
been	O
adopted	O
for	O
style	B-Task
transfer	I-Task
and	O
other	O
generation	B-Task
tasks	I-Task
.	O
	
Motivated	O
by	O
these	O
works	O
,	O
both	O
identity	B-Method
-	I-Method
aware	I-Method
adaptive	I-Method
perceptual	I-Method
loss	I-Method
and	O
perceptual	B-Method
regularization	I-Method
are	O
exploited	O
in	O
our	O
DIAT	B-Task
model	O
to	O
meet	O
the	O
requirement	O
of	O
facial	B-Task
attribute	I-Task
transfer	I-Task
.	O
	
Another	O
representative	O
approach	O
is	O
generative	B-Method
adversarial	I-Method
network	I-Method
(	O
GAN	B-Method
)	O
,	O
where	O
a	O
discriminator	B-Method
and	O
a	O
generator	B-Method
are	O
alternatingly	O
trained	O
as	O
an	O
adversarial	B-Method
game	I-Method
.	O
	
The	O
generator	B-Method
aims	O
to	O
generate	O
images	O
to	O
match	O
the	O
data	O
distribution	O
,	O
while	O
the	O
discriminator	B-Method
attempts	O
to	O
distinguish	O
between	O
the	O
generated	O
images	O
and	O
the	O
training	O
data	O
.	O
	
Laplacian	O
Pyramid	O
of	O
GANs	B-Method
is	O
further	O
suggested	O
to	O
generate	O
high	O
quality	O
image	O
in	O
a	O
coarse	O
-	O
to	O
-	O
fine	O
manner	O
.	O
	
Radford	O
et	O
al	O
.	O
extend	O
GAN	B-Method
with	O
the	O
fully	B-Method
deep	I-Method
convolutional	I-Method
networks	I-Method
(	O
i	O
.	O
	
e	O
.	O
,	O
DCGAN	O
)	O
	
for	O
image	B-Task
generation	I-Task
.	O
	
To	O
learn	O
disentangled	B-Method
representations	I-Method
,	O
information	O
-	O
theoretic	O
extension	O
of	O
GAN	B-Method
is	O
proposed	O
by	O
maximizing	O
the	O
mutual	O
information	O
between	O
a	O
subset	O
of	O
noise	O
variables	O
and	O
the	O
generated	O
results	O
.	O
	
In	O
,	O
WGAN	B-Method
and	O
WGAN	B-Method
-	I-Method
GP	I-Method
minimize	O
the	O
Wasserstein	O
-	O
1	O
distance	O
between	O
the	O
generated	O
distribution	O
and	O
the	O
real	O
distribution	O
to	O
improve	O
the	O
stability	O
of	O
learning	O
generator	B-Method
.	O
	
In	O
this	O
work	O
,	O
we	O
adopt	O
the	O
WGAN	B-Method
framework	I-Method
to	O
learn	O
our	O
DIAT	B-Task
model	O
,	O
and	O
further	O
suggest	O
adaptive	B-Method
perceptual	I-Method
loss	I-Method
for	O
identity	B-Task
-	I-Task
aware	I-Task
transfer	I-Task
and	O
perceptual	B-Task
regularization	I-Task
to	O
suppress	O
visual	O
artifacts	O
.	O
	
subsection	O
:	O
CNN	B-Method
for	O
face	B-Task
generation	I-Task
	
Facial	B-Task
attribute	I-Task
transfer	I-Task
has	O
received	O
considerable	O
recent	O
attention	O
.	O
	
Larsen	O
et	O
al	O
.	O
present	O
to	O
combine	O
variational	B-Method
autoencode	I-Method
with	I-Method
GAN	I-Method
(	O
VAE	B-Method
/	O
GAN	B-Method
)	O
for	O
image	B-Task
generation	I-Task
.	O
	
By	O
modeling	O
the	O
attribute	O
vector	O
as	O
the	O
difference	O
between	O
the	O
mean	B-Method
latent	I-Method
representations	I-Method
of	O
the	O
images	O
with	O
and	O
without	O
the	O
reference	O
attribute	O
,	O
VAE	B-Method
/	O
GAN	B-Method
can	O
provide	O
a	O
flexible	O
solution	O
to	O
arbitrary	B-Task
facial	I-Task
attribute	I-Task
transfer	I-Task
,	O
but	O
is	O
limited	O
in	O
transfer	B-Task
performance	O
.	O
	
Li	O
et	O
al	O
.	O
suggest	O
an	O
attribute	B-Method
driven	I-Method
and	I-Method
identity	I-Method
-	I-Method
preserving	I-Method
face	I-Method
generation	I-Method
model	I-Method
by	O
solving	O
an	O
optimization	B-Task
problems	I-Task
with	O
perceptual	O
loss	O
,	O
which	O
is	O
computationally	O
expensive	O
and	O
can	O
not	O
obtain	O
high	O
quality	O
results	O
.	O
	
Perarnau	O
et	O
al	O
.	O
adopt	O
an	O
encoder	B-Method
-	I-Method
decoder	I-Method
architecture	I-Method
,	O
where	O
attribute	B-Task
transfer	I-Task
can	O
be	O
conducted	O
by	O
editing	O
the	O
latent	B-Method
representation	I-Method
.	O
	
Shen	O
et	O
al	O
.	O
learn	O
the	O
residual	O
image	O
in	O
the	O
GAN	B-Method
framework	O
,	O
and	O
adopt	O
dual	B-Method
learning	I-Method
to	O
learn	O
two	O
reverse	B-Method
attribute	I-Method
transfer	I-Method
models	I-Method
simultaneously	O
.	O
	
Zhou	O
et	O
al	O
.	O
propose	O
a	O
model	O
to	O
learn	O
object	B-Task
transfiguration	I-Task
from	O
two	O
sets	O
of	O
unpaired	O
images	O
that	O
have	O
the	O
opposite	O
attribute	O
.	O
	
However	O
,	O
most	O
existing	O
methods	O
can	O
not	O
achieve	O
high	O
quality	O
transfer	B-Metric
results	I-Metric
,	O
and	O
visible	O
artifacts	O
and	O
over	O
-	O
smoothing	O
usually	O
are	O
inevitable	O
.	O
	
In	O
comparison	O
,	O
our	O
DIAT	B-Task
model	O
can	O
achieve	O
much	O
better	O
transfer	O
results	O
than	O
the	O
competing	O
methods	O
.	O
	
Besides	O
,	O
CNNs	B-Method
have	O
also	O
been	O
developed	O
for	O
other	O
face	B-Task
generation	I-Task
tasks	I-Task
.	O
	
For	O
painting	B-Task
style	I-Task
transfer	I-Task
of	I-Task
head	I-Task
portrait	I-Task
,	O
Selim	O
et	O
al	O
.	O
modify	O
the	O
perceptual	O
loss	O
to	O
balance	O
the	O
contribution	O
of	O
the	O
input	O
photograph	O
and	O
the	O
aligned	O
exemplar	O
painting	O
.	O
	
Gucluturk	O
et	O
al	O
.	O
train	O
a	O
feed	O
-	O
forward	O
CNN	B-Method
with	O
perceptual	B-Method
loss	I-Method
for	O
sketch	B-Task
inversion	I-Task
.	O
	
Yeh	O
et	O
al	O
.	O
apply	O
DCGAN	B-Method
to	O
semantic	B-Task
face	I-Task
inpainting	I-Task
in	O
an	O
optimization	B-Method
manner	I-Method
.	O
	
section	O
:	O
Deep	B-Method
CNNs	I-Method
for	O
Identity	B-Task
-	I-Task
aware	I-Task
Attribute	I-Task
Transfer	I-Task
	
In	O
this	O
section	O
,	O
we	O
present	O
our	O
DIAT	B-Task
model	O
for	O
identity	B-Task
-	I-Task
aware	I-Task
transfer	I-Task
of	I-Task
facial	I-Task
attribute	I-Task
.	O
	
As	O
illustrated	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
our	O
model	O
involves	O
a	O
mask	B-Method
network	I-Method
and	O
an	O
attribute	B-Method
transform	I-Method
network	I-Method
which	O
collaborate	O
to	O
produce	O
the	O
transfer	O
result	O
.	O
	
To	O
train	O
our	O
model	O
,	O
we	O
incorporate	O
the	O
adversarial	B-Method
attribute	I-Method
loss	I-Method
,	O
adaptive	B-Method
perceptual	I-Method
loss	I-Method
,	O
perceptual	B-Method
regularization	I-Method
and	O
attribute	B-Method
ratio	I-Method
regularization	I-Method
.	O
	
subsection	O
:	O
Network	B-Method
architecture	I-Method
	
Most	O
facial	O
attributes	O
,	O
e	O
.	O
g	O
.	O
,	O
expression	O
and	O
accessory	O
,	O
are	O
local	O
-	O
based	O
and	O
only	O
related	O
to	O
part	O
of	O
facial	O
image	O
.	O
	
Even	O
for	O
global	O
attributes	O
such	O
as	O
age	O
and	O
gender	O
,	O
some	O
parts	O
,	O
e	O
.	O
	
g	O
.	O
	
,	O
the	O
background	O
,	O
should	O
also	O
keep	O
the	O
same	O
with	O
the	O
source	O
image	O
.	O
	
For	O
the	O
sake	O
of	O
preserving	O
attribute	O
irrelevant	O
feature	O
,	O
it	O
is	O
natural	O
to	O
only	O
perform	O
attribute	B-Task
transfer	I-Task
in	O
image	O
region	O
related	O
to	O
specific	O
attribute	O
.	O
	
However	O
,	O
it	O
is	O
not	O
a	O
trivial	O
issue	O
to	O
find	O
the	O
attribute	O
relevant	O
region	O
.	O
	
One	O
possible	O
solution	O
is	O
to	O
manually	O
specify	O
the	O
relevant	O
region	O
for	O
each	O
attribute	O
given	O
a	O
new	O
transfer	B-Task
task	I-Task
,	O
but	O
it	O
undoubtedly	O
restricts	O
the	O
universality	O
and	O
adaptivity	O
of	O
the	O
solution	O
.	O
	
In	O
this	O
work	O
,	O
we	O
aim	O
to	O
provide	O
a	O
unified	O
solution	O
to	O
attribute	B-Task
transfer	I-Task
,	O
which	O
indicates	O
that	O
we	O
only	O
require	O
to	O
prepare	O
training	O
data	O
and	O
retrain	O
the	O
model	O
when	O
a	O
new	O
transfer	B-Task
task	I-Task
comes	O
.	O
	
To	O
this	O
end	O
,	O
our	O
whole	O
attribute	B-Method
transfer	I-Method
network	I-Method
is	O
comprised	O
of	O
two	O
sub	O
-	O
networks	O
,	O
i	O
.	O
	
e	O
.	O
,	O
	
mask	B-Method
network	I-Method
and	O
attribute	B-Method
transform	I-Method
network	I-Method
.	O
	
Both	O
mask	B-Method
network	I-Method
and	O
attribute	B-Method
transform	I-Method
network	I-Method
take	O
the	O
source	O
image	O
as	O
input	O
.	O
	
The	O
mask	B-Method
network	I-Method
is	O
utilized	O
to	O
predict	O
a	O
mask	O
to	O
indicate	O
the	O
attribute	O
relevant	O
region	O
,	O
while	O
the	O
attribute	B-Method
transform	I-Method
network	I-Method
is	O
used	O
to	O
produce	O
the	O
transformed	O
image	O
.	O
	
Given	O
and	O
,	O
the	O
final	O
transfer	O
result	O
can	O
be	O
obtained	O
by	O
,	O
where	O
denotes	O
the	O
element	O
-	O
wise	O
product	O
operator	O
.	O
	
We	O
also	O
note	O
that	O
both	O
attribute	B-Method
transform	I-Method
network	I-Method
and	O
mask	B-Method
network	I-Method
can	O
be	O
learned	O
from	O
training	O
data	O
in	O
an	O
end	O
-	O
to	O
-	O
end	O
manner	O
.	O
	
In	O
the	O
following	O
,	O
we	O
describe	O
the	O
architecture	O
of	O
attribute	B-Method
transform	I-Method
network	I-Method
and	O
mask	B-Method
network	I-Method
,	O
respectively	O
.	O
	
Attribute	B-Method
transform	I-Method
network	I-Method
.	O
	
We	O
adopt	O
the	O
Unet	B-Method
for	O
attribute	B-Task
transform	I-Task
due	O
to	O
its	O
good	O
tradeoff	O
between	O
efficiency	B-Metric
and	O
reconstruction	B-Metric
ability	I-Metric
.	O
	
In	O
general	O
,	O
the	O
Unet	B-Method
architecture	I-Method
involves	O
an	O
encoder	B-Method
subnetwork	I-Method
and	O
a	O
decoder	B-Method
subnetwork	I-Method
,	O
then	O
skip	B-Method
connection	I-Method
and	O
pooling	B-Method
operation	I-Method
are	O
further	O
introduced	O
to	O
exploit	O
multi	O
-	O
scale	O
information	O
.	O
	
As	O
for	O
attribute	B-Task
transform	I-Task
,	O
we	O
design	O
a	O
10	B-Method
-	I-Method
layer	I-Method
Unet	I-Method
,	O
which	O
includes	O
5	O
convolution	B-Method
layers	I-Method
for	O
encoding	B-Task
and	O
another	O
5	O
convolution	B-Method
layers	I-Method
for	O
decoding	B-Task
.	O
	
In	O
the	O
encoder	B-Method
,	O
we	O
use	O
convolution	B-Method
with	I-Method
stride	I-Method
2	I-Method
for	O
downsampling	B-Task
.	O
	
In	O
the	O
decoder	B-Method
,	O
a	O
depth	O
to	O
width	O
(	O
DTOW	O
)	O
layer	O
is	O
deployed	O
for	O
upsampling	B-Method
,	O
and	O
the	O
element	B-Method
-	I-Method
wise	I-Method
summation	I-Method
operation	I-Method
is	O
adopted	O
to	O
fuse	O
the	O
feature	O
maps	O
from	O
the	O
encoder	B-Method
and	I-Method
decoder	I-Method
subnetworks	I-Method
.	O
	
The	O
detailed	O
parameters	O
of	O
the	O
attribute	B-Method
transform	I-Method
network	I-Method
are	O
summarized	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Mask	B-Method
network	I-Method
.	O
	
As	O
for	O
mask	B-Method
network	I-Method
,	O
we	O
first	O
adopt	O
a	O
5	B-Method
-	I-Method
layer	I-Method
fully	I-Method
convolutional	I-Method
network	I-Method
to	O
generate	O
a	O
binary	O
mask	O
for	O
indicating	O
the	O
attribute	O
relevant	O
region	O
.	O
	
A	O
batch	B-Method
normalization	I-Method
layer	I-Method
is	O
added	O
after	O
each	O
convolution	B-Method
layer	I-Method
.	O
	
Then	O
,	O
upsampling	B-Method
is	O
deployed	O
by	O
simply	O
replicating	O
each	O
element	O
in	O
the	O
binary	O
mask	O
times	O
.	O
	
In	O
order	O
to	O
make	O
the	O
generated	O
image	O
smooth	O
,	O
we	O
further	O
utilize	O
a	O
Gaussian	B-Method
filter	I-Method
with	O
the	O
standard	O
deviation	O
of	O
to	O
produce	O
the	O
final	O
mask	O
.	O
	
To	O
sum	O
up	O
,	O
the	O
details	O
of	O
the	O
mask	B-Method
network	I-Method
are	O
given	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
In	O
our	O
mask	B-Method
network	I-Method
,	O
ReLU	B-Method
is	O
adopted	O
for	O
nonlinearity	O
for	O
the	O
first	O
4	O
convolution	O
layers	O
.	O
	
As	O
for	O
the	O
fifth	O
convolution	B-Method
layer	I-Method
,	O
we	O
adopt	O
the	O
sigmoid	B-Method
nonlinearity	I-Method
,	O
and	O
the	O
binarization	B-Method
operation	I-Method
is	O
then	O
used	O
to	O
obtain	O
the	O
binary	O
mask	O
,	O
where	O
denotes	O
an	O
element	O
of	O
the	O
feature	O
map	O
.	O
	
However	O
,	O
the	O
gradient	O
of	O
the	O
binarizer	O
is	O
zero	O
almost	O
everywhere	O
except	O
that	O
it	O
is	O
infinite	O
when	O
,	O
making	O
any	O
layer	O
before	O
the	O
binarizer	O
never	O
be	O
updated	O
during	O
training	O
.	O
	
As	O
a	O
remedy	O
,	O
we	O
follow	O
the	O
straight	O
-	O
through	O
estimator	O
on	O
gradient	O
,	O
and	O
introduce	O
a	O
piecewise	B-Method
linear	I-Method
proxy	I-Method
function	I-Method
to	O
approximate	O
,	O
During	O
training	B-Task
,	O
is	O
still	O
used	O
in	O
forward	B-Task
-	I-Task
propagation	I-Task
calculation	I-Task
,	O
while	O
is	O
used	O
in	O
back	B-Task
-	I-Task
propagation	I-Task
,	O
with	O
its	O
gradient	O
computed	O
by	O
,	O
	
subsection	O
:	O
Model	O
objective	O
	
By	O
enforcing	O
proper	O
constraints	O
on	O
transfer	O
result	O
,	O
both	O
the	O
attribute	B-Method
transform	I-Method
network	I-Method
and	O
mask	B-Method
network	I-Method
can	O
be	O
learned	O
from	O
training	O
data	O
.	O
	
However	O
,	O
the	O
ground	O
truth	O
of	O
attribute	B-Task
transfer	I-Task
usually	O
is	O
unavailable	O
and	O
not	O
unique	O
.	O
	
For	O
example	O
,	O
it	O
is	O
generally	O
impossible	O
to	O
obtain	O
the	O
ground	O
truth	O
of	O
gender	B-Task
transfer	I-Task
in	O
reality	O
.	O
	
Instead	O
,	O
the	O
training	O
data	O
used	O
in	O
this	O
work	O
includes	O
a	O
guided	O
set	O
of	O
images	O
with	O
the	O
desired	O
reference	O
attribute	O
and	O
a	O
source	O
set	O
of	O
input	O
images	O
not	O
with	O
the	O
reference	O
attribute	O
.	O
	
And	O
we	O
do	O
not	O
require	O
the	O
images	O
from	O
guided	O
set	O
to	O
have	O
the	O
same	O
identity	O
with	O
theose	O
from	O
source	O
set	O
.	O
	
For	O
the	O
sake	O
of	O
identity	B-Task
-	I-Task
aware	I-Task
attribute	I-Task
transfer	I-Task
,	O
we	O
define	O
two	O
alternative	O
losses	O
:	O
(	O
i	O
)	O
adversarial	B-Method
attribute	I-Method
loss	I-Method
to	O
make	O
the	O
transfer	O
result	O
exhibit	O
the	O
desired	O
attribute	O
,	O
and	O
(	O
ii	O
)	O
adaptive	B-Method
perceptual	I-Method
loss	I-Method
and	O
identity	O
loss	O
to	O
make	O
the	O
generated	O
image	O
keep	O
the	O
same	O
or	O
similar	O
identity	O
to	O
input	O
image	O
.	O
	
To	O
suppress	O
the	O
visual	O
artifacts	O
of	O
the	O
transfer	O
result	O
,	O
we	O
further	O
include	O
(	O
iii	O
)	O
a	O
perceptual	B-Method
regularization	I-Method
defined	O
on	O
a	O
denoising	B-Method
network	I-Method
.	O
	
Finally	O
,	O
(	O
iv	O
)	O
an	O
attribute	B-Method
ratio	I-Method
regularization	I-Method
is	O
deployed	O
on	O
to	O
guide	O
the	O
learning	B-Method
of	I-Method
mask	I-Method
network	I-Method
.	O
	
In	O
the	O
following	O
,	O
we	O
provide	O
more	O
details	O
on	O
these	O
losses	O
and	O
regularization	O
terms	O
.	O
	
Adversarial	B-Task
attribute	I-Task
loss	I-Task
.	O
	
Adversarial	B-Method
strategy	I-Method
is	O
a	O
common	O
stratey	O
that	O
is	O
widely	O
used	O
in	O
security	B-Task
problems	I-Task
.	O
	
For	O
computer	B-Task
vision	I-Task
,	O
an	O
adversarial	B-Method
learning	I-Method
framework	I-Method
called	O
generative	B-Method
adversarial	I-Method
networks	I-Method
(	O
GANs	B-Method
)	O
also	O
shows	O
powerful	O
ability	O
on	O
generating	O
images	O
that	O
fulfil	O
the	O
distribution	O
of	O
a	O
set	O
of	O
images	O
without	O
any	O
ground	O
truth	O
targets	O
.	O
	
Considering	O
the	O
infeasibility	O
of	O
obtaining	O
the	O
ground	O
truth	O
transfer	O
result	O
,	O
we	O
define	O
the	O
adversarial	B-Method
attribute	I-Method
loss	I-Method
based	O
on	O
the	O
guided	O
set	O
and	O
the	O
source	O
set	O
.	O
	
If	O
the	O
guided	O
set	O
is	O
of	O
large	O
scale	O
,	O
it	O
can	O
provide	O
a	O
natural	O
representation	O
of	O
the	O
attribute	B-Task
distribution	I-Task
.	O
	
Therefore	O
,	O
the	O
goal	O
of	O
adversarial	B-Method
attribute	I-Method
loss	I-Method
is	O
to	O
make	O
that	O
the	O
distribution	O
of	O
generated	O
images	O
matches	O
the	O
real	O
attribute	O
distribution	O
.	O
	
To	O
this	O
end	O
,	O
we	O
adopt	O
the	O
generative	B-Method
adversarial	I-Method
network	I-Method
framework	I-Method
,	O
where	O
the	O
generator	B-Method
is	O
the	O
attribute	B-Method
transfer	I-Method
network	I-Method
,	O
and	O
the	O
discriminator	B-Method
is	O
used	O
to	O
define	O
the	O
adversarial	B-Method
attribute	I-Method
loss	I-Method
.	O
	
The	O
details	O
of	O
the	O
discriminator	B-Method
are	O
provided	O
in	O
Table	O
[	O
reference	O
]	O
,	O
which	O
contains	O
6	O
convolution	O
layers	O
followed	O
by	O
another	O
two	O
fully	B-Method
-	I-Method
connected	I-Method
layers	I-Method
.	O
	
Denote	O
by	O
an	O
input	O
image	O
from	O
,	O
and	O
an	O
image	O
from	O
.	O
	
Let	O
be	O
the	O
distribution	O
of	O
the	O
input	O
images	O
,	O
be	O
the	O
distribution	O
of	O
the	O
images	O
with	O
the	O
reference	O
attribute	O
.	O
	
The	O
discriminator	B-Method
is	O
defined	O
as	O
to	O
output	O
the	O
probability	O
that	O
the	O
image	O
comes	O
from	O
the	O
set	O
.	O
	
To	O
train	O
the	O
generator	B-Method
and	O
the	O
discriminator	B-Method
,	O
we	O
take	O
use	O
of	O
the	O
following	O
adversarial	B-Method
attribute	I-Method
loss	I-Method
,	O
	
In	O
order	O
to	O
improve	O
the	O
training	B-Metric
stability	I-Metric
,	O
the	O
improved	O
Wasserstein	O
GAN	B-Method
is	O
adopted	O
by	O
defining	O
the	O
loss	O
as	O
,	O
	
For	O
simplicity	O
,	O
we	O
respectively	O
define	O
the	O
adversarial	O
attribute	O
losses	O
for	O
the	O
generator	B-Method
and	O
discriminator	B-Method
as	O
follows	O
,	O
Adaptive	O
perceptual	O
loss	O
.	O
	
The	O
adaptive	B-Method
perceptual	I-Method
loss	I-Method
is	O
introduced	O
to	O
guarantee	O
that	O
the	O
transfer	O
result	O
keeps	O
the	O
same	O
or	O
similar	O
identity	O
with	O
the	O
input	O
image	O
.	O
	
Due	O
to	O
identity	O
is	O
a	O
high	O
level	O
semantic	O
concept	O
,	O
it	O
is	O
not	O
proper	O
to	O
define	O
identity	B-Task
-	I-Task
aware	I-Task
loss	I-Task
by	O
forcing	O
two	O
images	O
to	O
be	O
exactly	O
the	O
same	O
in	O
pixel	O
domain	O
.	O
	
Instead	O
,	O
we	O
define	O
the	O
squared	B-Metric
-	I-Metric
error	I-Metric
loss	I-Metric
on	O
the	O
feature	B-Method
representations	I-Method
of	O
the	O
discriminator	B-Method
,	O
resulting	O
in	O
our	O
adaptive	B-Method
perceptual	I-Method
loss	I-Method
.	O
	
Denote	O
by	O
the	O
discriminator	B-Method
,	O
and	O
the	O
feature	O
map	O
of	O
the	O
-	B-Method
th	I-Method
convolution	I-Method
layer	I-Method
.	O
,	O
and	O
represent	O
the	O
channel	O
number	O
,	O
height	O
,	O
and	O
width	O
of	O
the	O
feature	O
map	O
,	O
respectively	O
.	O
	
We	O
then	O
define	O
the	O
perceptual	O
loss	O
between	O
and	O
on	O
the	O
-	O
th	O
convolution	O
layer	O
as	O
,	O
And	O
the	O
identity	B-Method
-	I-Method
aware	I-Method
adaptive	I-Method
perceptual	I-Method
loss	I-Method
is	O
further	O
defined	O
as	O
,	O
We	O
note	O
that	O
the	O
discriminator	B-Method
is	O
learned	O
from	O
training	O
data	O
.	O
	
Thus	O
,	O
the	O
network	O
parameters	O
of	O
will	O
be	O
changed	O
along	O
with	O
the	O
updating	O
of	O
discriminator	B-Method
,	O
and	O
thus	O
we	O
name	O
as	O
adaptive	B-Method
perceptual	I-Method
loss	I-Method
.	O
	
In	O
contrast	O
,	O
conventional	O
perceptual	O
loss	O
is	O
defined	O
on	O
the	O
off	B-Method
-	I-Method
the	I-Method
-	I-Method
shelf	I-Method
CNNs	I-Method
(	O
e	O
.	O
g	O
.	O
,	O
VGG	B-Material
-	I-Material
Face	I-Material
)	O
.	O
	
Compared	O
with	O
conventional	O
perceptual	B-Method
loss	I-Method
,	O
our	O
adaptive	B-Method
perceptual	I-Method
loss	I-Method
generally	O
is	O
more	O
effective	O
in	O
improving	O
the	O
training	B-Metric
efficiency	I-Metric
and	O
attribute	B-Metric
transfer	I-Metric
performance	I-Metric
:	O
The	O
training	B-Metric
efficiency	I-Metric
of	O
adaptive	B-Method
perceptual	I-Method
loss	I-Method
can	O
be	O
further	O
explained	O
from	O
two	O
aspects	O
.	O
	
(	O
i	O
)	O
	
For	O
conventional	O
perceptual	B-Task
loss	I-Task
,	O
the	O
forward	B-Task
and	I-Task
backward	I-Task
calculations	I-Task
are	O
required	O
for	O
both	O
the	O
off	O
-	O
the	O
-	O
shelf	O
CNN	B-Method
and	O
the	O
discriminator	B-Method
during	O
training	B-Task
.	O
	
Due	O
to	O
that	O
the	O
adaptive	B-Method
perceptual	I-Method
loss	I-Method
is	O
defined	O
on	O
the	O
discriminator	B-Method
,	O
it	O
is	O
sufficient	O
to	O
only	O
conduct	O
forward	O
and	O
backward	O
calculation	O
on	O
the	O
discriminator	B-Method
,	O
making	O
our	O
DIAT	B-Task
more	O
efficient	O
in	O
training	B-Task
.	O
	
(	O
ii	O
)	O
	
For	O
conventional	O
GAN	B-Method
,	O
the	O
generator	B-Method
usually	O
is	O
difficult	O
to	O
be	O
trained	O
.	O
	
As	O
for	O
our	O
DIAT	B-Task
,	O
it	O
can	O
be	O
trained	O
by	O
both	O
the	O
adversarial	B-Method
attribute	I-Method
loss	I-Method
and	O
adaptive	B-Method
perceptual	I-Method
loss	I-Method
,	O
greatly	O
accelerating	O
the	O
training	B-Metric
speed	I-Metric
.	O
	
Actually	O
,	O
the	O
adaptive	B-Method
perceptual	I-Method
loss	I-Method
is	O
defined	O
on	O
the	O
third	O
and	O
fourth	O
convolution	O
layers	O
of	O
the	O
discriminator	B-Method
,	O
which	O
can	O
serve	O
as	O
some	O
kind	O
of	O
hidden	O
-	O
layer	O
supervision	O
and	O
benefit	O
the	O
convergence	B-Task
of	I-Task
network	I-Task
training	I-Task
.	O
	
For	O
conventional	O
perceptual	B-Task
loss	I-Task
,	O
the	O
off	B-Method
-	I-Method
the	I-Method
-	I-Method
shelf	I-Method
CNNs	I-Method
generally	O
are	O
pre	O
-	O
trained	O
using	O
other	O
training	O
data	O
and	O
are	O
not	O
tailored	O
to	O
attribute	B-Task
transfer	I-Task
.	O
	
One	O
plausible	O
choice	O
is	O
the	O
VGG	B-Method
-	I-Method
Face	I-Method
,	O
which	O
,	O
however	O
,	O
is	O
trained	O
for	O
face	B-Task
recognition	I-Task
and	O
may	O
not	O
be	O
suitable	O
for	O
identity	B-Task
-	I-Task
aware	I-Task
attribute	I-Task
transfer	I-Task
.	O
	
In	O
comparison	O
,	O
our	O
adaptive	B-Method
perceptual	I-Method
loss	I-Method
is	O
defined	O
on	O
the	O
discriminator	B-Method
which	O
is	O
trained	O
for	O
modeling	B-Task
.	O
	
Such	O
loss	O
can	O
thus	O
provide	O
natural	O
balance	O
between	O
identity	O
similarity	O
and	O
attribute	B-Task
transfer	I-Task
and	O
benefit	O
transfer	B-Task
performance	O
.	O
	
For	O
example	O
,	O
in	O
terms	O
of	O
gender	B-Task
transfer	I-Task
,	O
the	O
introduction	O
of	O
adaptive	B-Method
perceptual	I-Method
loss	I-Method
will	O
allow	O
the	O
adaptive	B-Method
adjustment	I-Method
on	O
the	O
length	O
of	O
hair	O
.	O
	
Identity	B-Task
Loss	I-Task
.	O
	
The	O
proposed	O
adaptive	B-Method
perceptual	I-Method
loss	I-Method
does	O
help	O
keep	O
the	O
content	O
similarity	O
between	O
the	O
generated	O
face	O
and	O
the	O
reference	O
.	O
	
However	O
,	O
it	O
can	O
not	O
guarantee	O
the	O
identity	O
by	O
itself	O
.	O
	
To	O
further	O
enhance	O
the	O
identity	O
keeping	O
property	O
,	O
we	O
add	O
constrains	O
on	O
the	O
feature	B-Method
representation	I-Method
extracted	O
for	O
face	B-Task
recognition	I-Task
or	I-Task
verification	I-Task
.	O
	
In	O
face	B-Task
verification	I-Task
task	I-Task
,	O
two	O
faces	O
are	O
from	O
the	O
same	O
person	O
when	O
the	O
distance	O
between	O
two	O
features	O
are	O
smaller	O
than	O
ceratain	O
threshold	O
.	O
	
Here	O
,	O
we	O
adopt	O
VGG	B-Method
-	I-Method
Face	I-Method
and	O
model	O
the	O
distance	O
between	O
the	O
features	O
of	O
the	O
generated	O
face	O
and	O
the	O
reference	O
as	O
the	O
identity	O
loss	O
,	O
Perceptual	B-Task
regularization	I-Task
.	O
	
Despite	O
the	O
use	O
of	O
adversarial	B-Method
attribute	I-Method
loss	I-Method
and	O
adaptive	B-Method
perceptual	I-Method
loss	I-Method
,	O
visual	O
artifacts	O
are	O
still	O
inevitable	O
in	O
the	O
transfer	O
result	O
.	O
	
Image	B-Task
regularization	I-Task
is	O
thus	O
required	O
to	O
encourage	O
the	O
spatial	O
smoothness	O
while	O
preserving	O
small	O
scale	O
details	O
of	O
the	O
generated	O
face	O
.	O
	
One	O
choice	O
is	O
the	O
Total	B-Method
Variation	I-Method
(	O
TV	B-Method
)	O
regularizer	O
which	O
has	O
been	O
adopted	O
in	O
CNN	B-Method
feature	O
visualization	O
and	O
artistic	B-Task
style	I-Task
transfer	I-Task
.	O
	
However	O
,	O
the	O
TV	B-Method
regularizer	O
is	O
limited	O
in	O
recovering	B-Task
small	I-Task
-	I-Task
scale	I-Task
texture	I-Task
details	I-Task
and	O
suppressing	O
complex	O
artifacts	O
.	O
	
Moreover	O
,	O
it	O
is	O
a	O
generic	O
model	O
that	O
does	O
not	O
consider	O
the	O
characteristics	O
of	O
facial	O
images	O
.	O
	
In	O
this	O
work	O
,	O
we	O
take	O
the	O
facial	O
characteristics	O
into	O
account	O
and	O
train	O
a	O
denoising	B-Method
network	I-Method
for	O
perceptual	B-Task
regularization	I-Task
.	O
	
To	O
train	O
the	O
denoising	B-Method
network	I-Method
,	O
we	O
generate	O
the	O
noisy	O
image	O
by	O
adding	O
Gaussian	O
noise	O
with	O
the	O
standard	O
deviation	O
of	O
to	O
the	O
clean	O
facial	O
image	O
from	O
CelebA.	B-Material
Inspired	O
by	O
residual	B-Method
learning	I-Method
,	O
we	O
train	O
the	O
denoising	B-Method
network	I-Method
through	O
learning	O
the	O
residual	O
between	O
the	O
noise	O
image	O
and	O
the	O
clean	O
image	O
.	O
	
Taking	O
the	O
noise	O
image	O
as	O
input	O
,	O
the	O
denoising	B-Method
network	I-Method
utilizes	O
a	O
fully	B-Method
convolutional	I-Method
network	I-Method
of	I-Method
6	I-Method
layers	I-Method
to	O
predict	O
the	O
residual	O
.	O
	
The	O
denoising	B-Task
result	O
can	O
then	O
be	O
obtained	O
by	O
.	O
	
The	O
architecture	O
of	O
is	O
listed	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Denote	O
by	O
a	O
training	O
set	O
,	O
where	O
denotes	O
the	O
-	O
th	O
noisy	O
image	O
and	O
the	O
corresponding	O
clean	O
image	O
.	O
	
The	O
objective	O
for	O
learning	B-Task
is	O
given	O
as	O
,	O
	
Given	O
the	O
denoising	B-Method
network	I-Method
and	O
the	O
transfer	O
result	O
,	O
we	O
define	O
the	O
perceptual	O
regularization	O
as	O
,	O
where	O
denotes	O
the	O
Frobenius	O
norm	O
.	O
	
Note	O
that	O
predicts	O
the	O
residual	O
between	O
the	O
latent	O
clean	O
image	O
and	O
.	O
	
Minimizing	B-Method
makes	O
be	O
close	O
to	O
the	O
clean	O
image	O
,	O
and	O
can	O
be	O
used	O
to	O
suppress	O
the	O
noise	O
and	O
artifacts	O
in	O
.	O
	
Furthermore	O
,	O
the	O
threshold	O
is	O
introduced	O
for	O
better	O
preserving	O
of	O
small	O
scale	O
details	O
,	O
and	O
we	O
empirically	O
set	O
be	O
a	O
value	O
in	O
the	O
range	O
of	O
.	O
	
Note	O
that	O
the	O
regularizer	O
in	O
Eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
is	O
defined	O
on	O
the	O
denoising	B-Method
network	I-Method
,	O
and	O
thus	O
is	O
named	O
as	O
perceptual	B-Method
regularization	I-Method
.	O
	
Attribute	B-Method
ratio	I-Method
regularization	I-Method
.	O
	
The	O
size	O
of	O
attribute	O
relevant	O
region	O
varies	O
for	O
different	O
attributes	O
.	O
	
For	O
example	O
,	O
the	O
region	O
related	O
to	O
mouth	O
open	O
/	O
close	O
mainly	O
includes	O
the	O
mouth	O
and	O
should	O
be	O
small	O
.	O
	
For	O
glasses	B-Task
removal	I-Task
,	O
the	O
attribute	O
relevant	O
region	O
includes	O
the	O
two	O
eyes	O
and	O
is	O
relatively	O
large	O
.	O
	
As	O
for	O
gender	B-Task
transfer	I-Task
,	O
all	O
the	O
face	O
region	O
and	O
the	O
hair	O
should	O
be	O
attribute	O
relevant	O
.	O
	
Therefore	O
,	O
we	O
introduce	O
an	O
attribute	B-Method
ratio	I-Method
regularization	I-Method
term	I-Method
to	O
constrain	O
the	O
size	O
of	O
attribute	O
relevant	O
region	O
.	O
	
Specifically	O
,	O
such	O
regularization	B-Method
is	O
defined	O
on	O
the	O
binary	O
mask	O
in	O
Eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
	
Denote	O
by	O
the	O
image	O
size	O
,	O
and	O
the	O
expected	O
ratio	O
of	O
the	O
region	O
for	O
a	O
specific	O
attribute	O
.	O
	
The	O
attribute	O
ratio	O
regularization	O
is	O
then	O
defined	O
as	O
,	O
In	O
our	O
experiments	O
,	O
we	O
set	O
smaller	O
value	O
for	O
local	O
attribute	O
and	O
larger	O
value	O
for	O
global	O
attribute	O
.	O
	
Objective	B-Metric
function	I-Metric
.	O
	
We	O
define	O
the	O
objective	B-Metric
function	I-Metric
for	O
learning	O
the	O
transfer	B-Method
model	I-Method
and	O
the	O
discriminator	B-Method
by	O
combining	O
the	O
adversarial	B-Method
attribute	I-Method
loss	I-Method
,	O
adaptive	B-Method
perceptual	I-Method
loss	I-Method
,	O
perceptual	B-Method
regularization	I-Method
,	O
and	O
attribute	B-Method
ratio	I-Method
regularization	I-Method
.	O
	
The	O
transfer	B-Method
model	I-Method
is	O
learned	O
by	O
minimizing	O
the	O
following	O
objective	B-Metric
,	O
where	O
.	O
,	O
,	O
and	O
are	O
the	O
tradeoff	O
parameters	O
for	O
the	O
adaptive	B-Method
perceptual	I-Method
loss	I-Method
,	O
attribute	B-Method
ratio	I-Method
regularization	I-Method
,	O
and	O
perceptual	O
regularization	O
,	O
respectively	O
.	O
	
However	O
,	O
it	O
is	O
difficult	O
to	O
set	O
the	O
tradeoff	O
parameter	O
.	O
	
Instead	O
,	O
we	O
empirically	O
find	O
that	O
the	O
transfer	B-Method
model	I-Method
can	O
be	O
stably	O
learned	O
by	O
alternatingly	B-Method
minimizing	I-Method
and	O
during	O
training	O
.	O
	
Finally	O
,	O
the	O
discriminator	B-Method
is	O
learned	O
by	O
minimizing	O
the	O
following	O
objective	B-Metric
,	O
	
subsection	O
:	O
Learning	B-Method
algorithm	I-Method
	
Generally	O
,	O
both	O
the	O
generator	B-Method
and	O
the	O
discriminator	B-Method
are	O
difficult	O
to	O
converge	O
in	O
GAN	B-Method
.	O
	
Therefore	O
,	O
we	O
adopt	O
a	O
two	O
-	O
stage	B-Method
strategy	I-Method
for	O
learning	O
the	O
transfer	B-Method
model	I-Method
and	O
the	O
discriminator	B-Method
:	O
(	O
i	O
)	O
	
we	O
first	O
combine	O
the	O
source	O
set	O
and	O
the	O
guided	O
set	O
to	O
pre	O
-	O
train	O
for	O
initialization	B-Task
,	O
and	O
(	O
ii	O
)	O
alternate	O
between	O
updating	O
and	O
.	O
	
The	O
procedure	O
for	O
training	O
the	O
transfer	B-Method
model	I-Method
is	O
summarized	O
in	O
Algorithm	O
[	O
reference	O
]	O
.	O
	
Initialization	B-Task
.	O
	
For	O
the	O
initialization	O
of	O
the	O
,	O
we	O
only	O
consider	O
the	O
attribute	B-Method
transform	I-Method
network	I-Method
,	O
and	O
leave	O
the	O
mask	B-Method
network	I-Method
be	O
learned	O
in	O
the	O
second	O
stage	O
.	O
	
Note	O
that	O
the	O
transform	B-Method
network	I-Method
has	O
the	O
architecture	O
of	O
auto	B-Method
-	I-Method
encoder	I-Method
.	O
	
Thus	O
,	O
it	O
can	O
be	O
pre	O
-	O
trained	O
by	O
minimizing	O
the	O
following	O
reconstruction	B-Metric
objective	I-Metric
on	O
and	O
,	O
	
As	O
for	O
the	O
initialization	O
of	O
the	O
discriminator	B-Method
,	O
we	O
use	O
the	O
images	O
in	O
as	O
negative	O
samples	O
and	O
the	O
images	O
in	O
as	O
positive	O
samples	O
.	O
	
Then	O
the	O
discriminator	B-Method
can	O
be	O
pre	O
-	O
trained	O
by	O
minimizing	O
the	O
following	O
objective	O
,	O
where	O
is	O
for	O
positive	O
image	O
and	O
for	O
negative	O
image	O
.	O
	
By	O
this	O
way	O
,	O
the	O
initialization	O
can	O
provide	O
a	O
good	O
start	O
point	O
and	O
benefit	O
the	O
convergence	B-Metric
and	I-Metric
stability	I-Metric
of	O
DIAT	B-Task
training	O
.	O
	
Network	B-Method
training	I-Method
.	O
	
After	O
the	O
initialization	O
of	O
and	O
,	O
network	B-Method
training	I-Method
is	O
further	O
performed	O
by	O
updating	O
the	O
whole	O
(	O
including	O
both	O
and	O
)	O
and	O
alternatingly	O
.	O
	
Moreover	O
,	O
is	O
updated	O
by	O
first	O
iterations	O
for	O
minimizing	B-Task
and	O
then	O
iterations	O
for	O
minimizing	B-Task
.	O
	
We	O
apply	O
the	O
RMSProp	B-Method
solver	I-Method
to	O
train	O
the	O
transfer	B-Method
network	I-Method
and	O
the	O
discriminator	B-Method
with	O
a	O
learning	B-Metric
rate	I-Metric
of	O
.	O
	
[	O
!	O
tbp	O
]	O
	
Learning	O
the	O
attribute	B-Method
transfer	I-Method
network	I-Method
[	O
1	O
]	O
Source	O
set	O
,	O
guided	O
set	O
,	O
,	O
,	O
.	O
	
mini	O
-	O
batch	O
size	O
is	O
.	O
	
The	O
attribute	B-Method
transfer	I-Method
network	I-Method
Pre	O
-	O
train	O
the	O
transform	B-Method
model	I-Method
by	O
minimizing	O
the	O
objective	B-Metric
in	O
Eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
	
Pre	O
-	O
train	O
the	O
discriminator	B-Method
by	O
minimizing	O
the	O
objective	B-Metric
in	O
Eqn	B-Metric
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
	
not	O
converged	O
Select	O
a	O
mini	O
-	O
bath	O
from	O
to	O
generate	O
the	O
transfer	O
results	O
,	O
which	O
is	O
further	O
combined	O
with	O
another	O
mini	O
-	O
batch	O
from	O
to	O
form	O
the	O
set	O
for	O
training	O
the	O
discriminator	B-Method
.	O
	
Here	O
we	O
set	O
.	O
	
Use	O
the	O
RMSProp	B-Method
solver	I-Method
to	O
update	O
the	O
discriminator	B-Method
with	O
Eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
using	O
the	O
mini	B-Method
-	I-Method
batch	I-Method
.	O
	
Clip	O
the	O
parameters	O
of	O
the	O
discriminator	B-Method
.	O
	
Use	O
the	O
RMSProp	B-Method
solver	I-Method
to	O
update	O
by	O
minimizing	O
in	O
Eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
	
Use	O
the	O
RMSProp	B-Method
solver	I-Method
to	O
update	O
by	O
minimizing	O
in	O
Eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
	
Return	O
the	O
transfer	B-Method
network	I-Method
	
subsection	O
:	O
Extension	O
to	O
face	B-Task
hallucination	I-Task
	
Besides	O
facial	B-Task
attribute	I-Task
transfer	I-Task
,	O
our	O
DIAT	B-Task
can	O
also	O
be	O
extended	O
to	O
other	O
face	B-Task
editing	I-Task
tasks	I-Task
.	O
	
Here	O
we	O
use	O
the	O
face	B-Task
hallucination	I-Task
as	O
an	O
example	O
.	O
	
Face	B-Task
hallucination	I-Task
is	O
undoubtedly	O
a	O
global	B-Task
transfer	I-Task
task	I-Task
,	O
and	O
thus	O
we	O
remove	O
the	O
mask	B-Method
network	I-Method
as	O
well	O
as	O
the	O
attribute	B-Method
ratio	I-Method
regularization	I-Method
,	O
making	O
.	O
	
Moreover	O
,	O
the	O
input	O
image	O
in	O
face	B-Task
hallucination	I-Task
is	O
of	O
low	O
resolution	O
(	O
LR	B-Method
)	O
while	O
the	O
output	O
image	O
is	O
of	O
high	O
resolution	O
(	O
HR	O
)	O
.	O
	
To	O
be	O
consistent	O
with	O
attribute	B-Task
transfer	I-Task
,	O
we	O
super	O
-	O
resolve	O
LR	B-Method
image	O
to	O
the	O
size	O
of	O
HR	O
image	O
with	O
the	O
bicubic	B-Method
interpolator	I-Method
,	O
which	O
is	O
taken	O
as	O
input	O
to	O
.	O
	
Furthermore	O
,	O
the	O
ground	O
truth	O
HR	O
images	O
can	O
be	O
available	O
to	O
guide	O
the	O
network	B-Method
training	I-Method
for	O
face	B-Task
hallucination	I-Task
.	O
	
Denote	O
by	O
the	O
super	O
-	O
resolved	O
image	O
by	O
bicubic	B-Method
interpolator	I-Method
,	O
and	O
the	O
ground	O
truth	O
HR	O
image	O
.	O
	
Then	O
,	O
the	O
pixel	B-Metric
-	I-Metric
wise	I-Metric
reconstruction	I-Metric
loss	I-Metric
is	O
defined	O
as	O
,	O
We	O
further	O
modify	O
the	O
definition	O
of	O
by	O
removing	O
the	O
attribute	B-Method
ratio	I-Method
regularization	I-Method
and	O
adding	O
reconstruction	O
loss	O
,	O
where	O
is	O
the	O
tradeoff	O
parameter	O
for	O
pixel	B-Metric
-	I-Metric
wise	I-Metric
reconstruction	I-Metric
loss	I-Metric
,	O
and	O
we	O
set	O
in	O
our	O
experiment	O
.	O
	
Given	O
the	O
training	O
data	O
,	O
the	O
models	O
can	O
then	O
be	O
learned	O
by	O
updating	O
and	O
alternatingly	O
.	O
	
section	O
:	O
Experimental	O
Results	O
	
In	O
this	O
section	O
,	O
we	O
first	O
describe	O
the	O
experimental	O
settings	O
,	O
including	O
the	O
training	B-Material
and	I-Material
testing	I-Material
data	I-Material
,	O
competing	O
methods	O
,	O
model	O
and	O
learning	B-Method
parameters	I-Method
.	O
	
Experiments	O
are	O
then	O
performed	O
for	O
local	B-Task
and	I-Task
global	I-Task
attribute	I-Task
transfer	I-Task
.	O
	
Quantitative	B-Metric
metrics	I-Metric
and	O
the	O
results	O
on	O
real	B-Material
images	I-Material
are	O
also	O
reported	O
.	O
	
Moreover	O
,	O
we	O
analyze	O
the	O
effect	O
of	O
adaptive	B-Method
perceptual	I-Method
loss	I-Method
and	O
perceptual	B-Method
regularization	I-Method
.	O
	
Finally	O
,	O
the	O
results	O
are	O
reported	O
to	O
further	O
assess	O
the	O
performance	O
of	O
our	O
DIAT	B-Task
for	O
face	B-Task
hallucination	I-Task
.	O
	
The	O
source	O
code	O
will	O
be	O
given	O
after	O
the	O
publication	O
of	O
this	O
work	O
.	O
	
subsection	O
:	O
Experimental	O
settings	O
	
Our	O
DIAT	B-Task
models	O
are	O
trained	O
using	O
a	O
subset	O
of	O
the	O
aligned	O
CelebA	B-Material
dataset	O
by	O
removing	O
the	O
images	O
with	O
poor	O
quality	O
.	O
	
The	O
size	O
of	O
the	O
aligned	O
images	O
is	O
.	O
	
Due	O
to	O
the	O
limitation	O
of	O
the	O
GPU	O
memory	O
,	O
we	O
sample	O
the	O
central	O
part	O
of	O
each	O
image	O
and	O
resize	O
it	O
to	O
.	O
	
For	O
each	O
attribute	B-Task
transfer	I-Task
task	I-Task
,	O
we	O
use	O
all	O
the	O
images	O
with	O
the	O
reference	O
attribute	O
from	O
training	O
set	O
to	O
form	O
the	O
guided	O
set	O
,	O
and	O
randomly	O
select	O
10	O
,	O
000	O
training	O
images	O
not	O
with	O
the	O
reference	O
attribute	O
as	O
the	O
source	O
set	O
.	O
	
After	O
training	O
,	O
2	O
,	O
000	O
images	O
apart	O
from	O
the	O
images	O
for	O
training	O
are	O
adopted	O
to	O
assess	O
the	O
attribute	B-Metric
transfer	I-Metric
performance	I-Metric
.	O
	
And	O
we	O
also	O
test	O
the	O
models	O
on	O
other	O
real	B-Material
images	I-Material
from	O
the	O
website	B-Material
iStock	I-Material
.	O
	
Only	O
a	O
few	O
methods	O
have	O
been	O
proposed	O
for	O
facial	B-Task
attribute	I-Task
transfer	I-Task
.	O
	
In	O
our	O
experiments	O
,	O
we	O
compare	O
our	O
DIAT	B-Task
with	O
the	O
convolutional	B-Method
attribute	I-Method
-	I-Method
driven	I-Method
and	I-Method
identity	I-Method
-	I-Method
preserving	I-Method
model	I-Method
(	O
CNIA	B-Method
)	O
,	O
IcGAN	B-Method
and	O
VAE	B-Method
/	O
GAN	B-Method
due	O
to	O
that	O
their	O
codes	O
are	O
available	O
.	O
	
As	O
for	O
IcGAN	B-Method
and	O
VAE	B-Method
/	O
GAN	B-Method
,	O
the	O
original	O
image	O
size	O
is	O
not	O
the	O
same	O
with	O
our	O
DIAT	B-Task
,	O
so	O
we	O
resize	O
the	O
result	O
to	O
the	O
same	O
size	O
with	O
DIAT	B-Task
for	O
comparison	O
.	O
	
For	O
the	O
task	O
of	O
glasses	B-Task
removal	I-Task
,	O
we	O
can	O
first	O
manually	O
detect	O
the	O
region	O
of	O
glasses	O
,	O
and	O
then	O
use	O
some	O
face	B-Method
inpainting	I-Method
methods	I-Method
(	O
e	O
.	O
g	O
.	O
,	O
semantic	B-Task
inpainting	I-Task
)	O
to	O
recover	O
the	O
missing	O
pixels	O
.	O
	
Thus	O
we	O
also	O
compare	O
our	O
DIAT	B-Task
with	O
semantic	B-Task
inpainting	I-Task
for	O
glasses	B-Task
removal	I-Task
.	O
	
All	O
the	O
experiments	O
are	O
conducted	O
on	O
a	O
computer	O
with	O
the	O
GTX	B-Method
TitanX	I-Method
GPU	I-Method
of	O
12	O
GB	O
memory	O
.	O
	
We	O
set	O
the	O
parameters	O
and	O
for	O
DIAT	B-Task
.	O
	
For	O
the	O
threshold	O
in	O
the	O
perceptual	B-Task
regularization	I-Task
,	O
we	O
set	O
it	O
to	O
be	O
a	O
value	O
in	O
the	O
range	O
of	O
.	O
	
As	O
for	O
in	O
the	O
attribute	B-Task
ration	I-Task
regularization	I-Task
,	O
we	O
set	O
it	O
to	O
be	O
(	O
i	O
)	O
for	O
small	O
local	O
attributes	O
(	O
e	O
.	O
g	O
.	O
,	O
mouth	O
)	O
,	O
(	O
ii	O
)	O
for	O
large	O
local	O
attributes	O
(	O
e	O
.	O
g	O
.	O
,	O
eyes	O
)	O
,	O
and	O
(	O
iii	O
)	O
for	O
global	O
attributes	O
(	O
e	O
.	O
g	O
.	O
,	O
gender	O
and	O
age	O
)	O
.	O
	
subsection	O
:	O
Local	B-Method
attribute	I-Method
transfer	I-Method
	
We	O
assess	O
the	O
local	B-Method
attribute	I-Method
transfer	I-Method
models	I-Method
on	O
three	O
tasks	O
,	O
i	O
.	O
	
e	O
.	O
,	O
mouth	O
open	O
,	O
mouth	O
close	O
,	O
and	O
eyeglasses	B-Task
removal	I-Task
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
illustrates	O
the	O
transfer	O
results	O
by	O
our	O
DIAT	B-Task
.	O
	
It	O
can	O
be	O
seen	O
that	O
our	O
DIAT	B-Task
performs	O
favorably	O
for	O
transferring	O
the	O
input	O
images	O
to	O
the	O
desired	O
attribute	O
with	O
satisfying	O
visual	B-Metric
quality	I-Metric
.	O
	
Benefited	O
from	O
the	O
mask	B-Method
network	I-Method
,	O
the	O
results	O
by	O
DIAT	B-Task
can	O
preserve	O
more	O
identity	O
-	O
aware	O
and	O
attribute	O
irrelevant	O
details	O
.	O
	
Moreover	O
,	O
when	O
the	O
training	O
data	O
are	O
sufficient	O
,	O
it	O
is	O
feasible	O
to	O
separately	O
train	O
two	O
DIAT	B-Task
models	O
for	O
reverse	B-Task
tasks	I-Task
,	O
e	O
.	O
	
g	O
.	O
,	O
one	O
for	O
mouth	O
open	O
and	O
another	O
for	O
mouth	O
close	O
.	O
	
We	O
further	O
compare	O
our	O
DIAT	B-Task
with	O
three	O
competing	O
methods	O
,	O
i	O
.	O
	
e	O
.	O
,	O
CNIA	B-Method
,	O
IcGAN	B-Method
and	O
VAE	B-Method
/	O
GAN	B-Method
.	O
	
As	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
the	O
results	O
by	O
our	O
DIAT	B-Task
are	O
visually	O
more	O
pleasing	O
than	O
those	O
by	O
CNIA	B-Method
for	O
all	O
the	O
three	O
local	B-Task
attribute	I-Task
transfer	I-Task
tasks	I-Task
.	O
	
In	O
terms	O
of	O
run	B-Metric
time	I-Metric
,	O
CNIA	B-Method
takes	O
about	O
seconds	O
(	O
)	O
to	O
deal	O
with	O
an	O
image	O
,	O
while	O
our	O
DIAT	B-Task
only	O
needs	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
further	O
provides	O
the	O
results	O
by	O
IcGAN	B-Method
,	O
VAE	B-Method
/	O
GAN	B-Method
,	O
and	O
our	O
DIAT	B-Task
.	O
	
In	O
comparison	O
with	O
the	O
competing	O
methods	O
,	O
our	O
DIAT	B-Task
can	O
well	O
address	O
the	O
attribute	B-Task
transfer	I-Task
tasks	I-Task
while	O
recovering	O
more	O
visual	O
details	O
in	O
both	O
attribute	O
relevant	O
and	O
attribute	O
irrelevant	O
regions	O
.	O
	
Finally	O
,	O
for	O
glasses	B-Task
removal	I-Task
,	O
we	O
compare	O
our	O
DIAT	B-Task
with	O
semantic	B-Task
inpainting	I-Task
,	O
and	O
the	O
results	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
clearly	O
demonstrate	O
the	O
superiority	O
of	O
DIAT	B-Task
.	O
	
subsection	O
:	O
Global	B-Method
attribute	I-Method
transfer	I-Method
	
We	O
consider	O
two	O
global	B-Task
attribute	I-Task
transfer	I-Task
tasks	I-Task
,	O
i	O
.	O
	
e	O
.	O
,	O
gender	B-Task
transfer	I-Task
and	O
age	B-Task
transfer	I-Task
.	O
	
For	O
gender	B-Task
transfer	I-Task
,	O
we	O
only	O
evaluate	O
the	O
model	O
for	O
male	B-Task
-	I-Task
to	I-Task
-	I-Task
female	I-Task
.	O
	
For	O
age	B-Task
transfer	I-Task
,	O
we	O
only	O
test	O
the	O
model	O
for	O
older	O
-	O
to	O
-	O
younger	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
the	O
transfer	O
results	O
,	O
and	O
our	O
DIAT	B-Task
is	O
also	O
effective	O
for	O
global	B-Task
attribute	I-Task
transfer	I-Task
.	O
	
Even	O
gender	B-Task
transfer	I-Task
certainly	O
causes	O
the	O
change	O
of	O
the	O
identity	O
,	O
as	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
a	O
)	O
,	O
our	O
DIAT	B-Task
can	O
still	O
retain	O
most	O
identity	O
-	O
aware	O
features	O
,	O
making	O
the	O
transfer	O
result	O
similar	O
to	O
the	O
input	O
image	O
in	O
appearance	O
.	O
	
Figs	O
.	O
	
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
show	O
the	O
results	O
by	O
our	O
DIAT	B-Task
,	O
CNAI	B-Method
,	O
IcGAN	B-Method
and	O
VAE	B-Method
/	O
GAN	B-Method
.	O
	
Compared	O
with	O
the	O
competing	O
methods	O
,	O
the	O
results	O
by	O
our	O
DIAT	B-Task
well	O
exhibit	O
the	O
desired	O
attribute	O
,	O
and	O
are	O
of	O
high	O
visual	B-Metric
quality	I-Metric
with	O
photo	O
-	O
realistic	O
details	O
.	O
	
Finally	O
,	O
we	O
also	O
note	O
that	O
for	O
gender	B-Task
transfer	I-Task
our	O
DIAT	B-Task
is	O
able	O
of	O
adjusting	O
the	O
hair	O
length	O
due	O
to	O
the	O
introduction	O
of	O
adaptive	B-Method
perceptual	I-Method
loss	I-Method
.	O
	
subsection	O
:	O
Quantitative	B-Metric
evaluation	I-Metric
	
Given	O
each	O
attribute	B-Task
transfer	I-Task
task	I-Task
,	O
we	O
randomly	O
select	O
images	O
without	O
the	O
reference	O
attribute	O
from	O
the	O
testing	O
partition	O
of	O
CelebA	B-Material
to	O
form	O
our	O
testing	O
set	O
.	O
	
Then	O
,	O
three	O
groups	O
of	O
experiments	O
are	O
conducted	O
to	O
evaluate	O
the	O
transfer	B-Metric
performance	I-Metric
quantitatively	O
:	O
Attribute	B-Task
classification	I-Task
.	O
	
For	O
attribute	B-Task
transfer	I-Task
,	O
it	O
is	O
natural	O
to	O
require	O
the	O
transfer	O
result	O
to	O
exhibit	O
the	O
desired	O
attribute	O
.	O
	
Thus	O
,	O
we	O
first	O
train	O
a	O
CNN	B-Method
-	O
based	O
attribute	O
classifier	O
(	O
including	O
two	O
convolution	B-Method
layers	I-Method
,	O
three	O
residual	O
blocks	O
and	O
two	O
fully	B-Method
-	I-Method
connected	I-Method
layers	I-Method
)	O
using	O
the	O
training	O
set	O
of	O
CelebA.	B-Material
Given	O
an	O
attribute	B-Task
transfer	I-Task
task	I-Task
,	O
we	O
test	O
the	O
classification	B-Metric
accuracy	I-Metric
of	O
the	O
desired	O
attribute	O
for	O
the	O
transfer	O
results	O
of	O
2	O
,	O
000	O
testing	O
images	O
.	O
	
Tabel	O
[	O
reference	O
]	O
lists	O
the	O
classification	B-Metric
accuracy	I-Metric
for	O
five	O
attribute	B-Task
transfer	I-Task
tasks	I-Task
,	O
i	O
.	O
	
e	O
.	O
,	O
mouth	O
open	O
,	O
mouth	O
close	O
,	O
glasses	O
removal	O
,	O
gender	B-Task
transfer	I-Task
,	O
and	O
age	B-Task
transfer	I-Task
.	O
	
It	O
can	O
be	O
observed	O
that	O
our	O
DIAT	B-Task
achieves	O
satisfying	O
accuracy	B-Metric
(	O
i	O
.	O
	
e	O
.	O
,	O
)	O
for	O
all	O
the	O
tasks	O
,	O
indicating	O
that	O
the	O
results	O
by	O
our	O
DIAT	B-Task
generally	O
are	O
with	O
the	O
desired	O
attribute	O
.	O
	
Identity	B-Task
verification	I-Task
.	O
	
As	O
for	O
local	B-Task
attribute	I-Task
transfer	I-Task
,	O
we	O
also	O
require	O
the	O
transfer	O
result	O
to	O
preserve	O
the	O
identity	O
of	O
input	O
image	O
.	O
	
Here	O
we	O
use	O
the	O
open	B-Method
source	I-Method
face	I-Method
recognition	I-Method
platform	I-Method
Openface	I-Method
for	O
matching	O
the	O
input	O
image	O
with	O
the	O
transfer	O
result	O
.	O
	
By	O
setting	O
the	O
threshold	O
be	O
0.99	O
,	O
Table	O
[	O
reference	O
]	O
lists	O
the	O
identity	B-Metric
verification	I-Metric
accuracy	I-Metric
for	O
mouth	O
open	O
,	O
mouth	O
close	O
,	O
and	O
glasses	B-Task
removal	I-Task
.	O
	
The	O
results	O
demonstrate	O
that	O
our	O
DIAT	B-Task
can	O
well	O
preserve	O
the	O
identity	O
-	O
aware	O
feature	O
for	O
local	B-Task
attribute	I-Task
transfer	I-Task
.	O
	
Image	B-Metric
quality	I-Metric
.	O
	
Image	B-Metric
quality	I-Metric
is	O
another	O
crucial	O
metric	O
to	O
assess	O
attribute	B-Task
transfer	I-Task
.	O
	
However	O
,	O
the	O
ground	O
truth	O
of	O
transfer	O
result	O
is	O
unavailable	O
,	O
making	O
it	O
difficult	O
to	O
perform	O
quantitative	B-Task
evaluation	I-Task
.	O
	
Here	O
we	O
use	O
a	O
pair	O
of	O
reverse	B-Task
attribute	I-Task
transfer	I-Task
tasks	I-Task
(	O
i	O
.	O
	
e	O
.	O
,	O
mouth	O
close	O
and	O
mouth	O
open	O
)	O
as	O
an	O
example	O
,	O
and	O
adopt	O
an	O
indirect	B-Method
scheme	I-Method
to	O
compute	O
average	B-Metric
PSNR	I-Metric
on	O
the	O
2000	O
testing	O
images	O
.	O
	
Specifically	O
,	O
we	O
first	O
perform	O
mouth	O
open	O
to	O
the	O
images	O
with	O
mouth	O
close	O
,	O
and	O
then	O
perform	O
reverse	O
mouth	O
close	O
to	O
the	O
transfer	O
results	O
.	O
	
Finally	O
,	O
the	O
input	O
images	O
are	O
taken	O
as	O
ground	O
truth	O
and	O
the	O
images	O
after	O
two	O
steps	O
of	O
transfer	B-Task
can	O
be	O
viewed	O
as	O
the	O
generated	O
images	O
.	O
	
By	O
this	O
way	O
,	O
we	O
obtain	O
the	O
average	B-Metric
PSNR	I-Metric
of	O
33.27dB	O
,	O
indicating	O
the	O
effectiveness	O
of	O
our	O
DIAT	B-Task
for	O
local	B-Task
attribute	I-Task
transfer	I-Task
.	O
	
subsection	O
:	O
Results	O
on	O
other	O
real	O
facial	O
images	O
	
To	O
assess	O
the	O
generalization	B-Metric
ability	I-Metric
,	O
we	O
use	O
the	O
DIAT	B-Task
models	O
learned	O
on	O
CelebA	B-Material
to	O
other	O
real	O
facial	O
images	O
from	O
the	O
website	B-Material
iStock	I-Material
.	O
	
Each	O
test	O
image	O
is	O
first	O
aligned	O
with	O
the	O
5	O
facial	O
landmarks	O
,	O
and	O
then	O
input	O
to	O
the	O
DIAT	B-Task
models	O
.	O
	
Taking	O
mouth	B-Task
open	I-Task
and	O
gender	O
transfer	O
as	O
examples	O
,	O
Fig	O
.	O
	
[	O
reference	O
]	O
gives	O
the	O
transfer	O
results	O
on	O
15	O
images	O
for	O
each	O
task	O
,	O
clearly	O
demonstrating	O
the	O
generalization	O
ability	O
of	O
our	O
models	O
to	O
other	O
real	O
facial	O
images	O
.	O
	
subsection	O
:	O
Evaluation	O
on	O
adaptive	B-Method
perceptual	I-Method
loss	I-Method
and	O
perceptual	B-Task
regularization	I-Task
	
We	O
also	O
implement	O
a	O
variant	O
of	O
DIAT	B-Task
(	O
i	O
.	O
	
e	O
.	O
,	O
DIAT	B-Task
-	O
1	O
)	O
	
by	O
replacing	O
the	O
adaptive	B-Method
perceptual	I-Method
loss	I-Method
with	O
the	O
conventional	O
perceptual	O
loss	O
defined	O
on	O
VGG	B-Material
-	I-Material
Face	I-Material
.	O
	
Taking	O
gender	B-Task
transfer	I-Task
as	O
an	O
example	O
,	O
Fig	O
.	O
	
[	O
reference	O
]	O
compares	O
DIAT	B-Task
with	O
DIAT	B-Task
-	O
1	O
.	O
	
It	O
can	O
be	O
observed	O
that	O
DIAT	B-Task
converges	O
very	O
fast	O
and	O
can	O
generate	O
satisfying	O
results	O
after	O
4	O
epochs	O
of	O
training	O
.	O
	
In	O
comparison	O
,	O
DIAT	B-Task
-	O
1	O
requires	O
much	O
more	O
epochs	O
in	O
training	O
,	O
and	O
the	O
gender	O
just	O
begins	O
to	O
be	O
modified	O
after	O
18	O
epochs	O
.	O
	
Moreover	O
,	O
the	O
adoption	O
of	O
adaptive	B-Method
perceptual	I-Method
loss	I-Method
also	O
benefits	O
the	O
transfer	B-Task
performance	O
,	O
and	O
adaptive	B-Method
adjustment	I-Method
on	O
the	O
hair	O
length	O
can	O
be	O
observed	O
on	O
the	O
transfer	O
results	O
by	O
DIAT	B-Task
.	O
	
Furthermore	O
,	O
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
the	O
transfer	O
results	O
by	O
DIAT	B-Task
with	O
the	O
perceptual	B-Method
regularization	I-Method
and	O
the	O
TV	B-Method
regularization	O
.	O
	
It	O
can	O
be	O
clearly	O
seen	O
that	O
the	O
perceptual	B-Method
regularization	I-Method
is	O
more	O
effective	O
on	O
suppressing	O
noise	O
and	O
artifacts	O
while	O
preserving	O
sharp	O
edges	O
and	O
fine	O
details	O
.	O
	
subsection	O
:	O
Results	O
of	O
the	O
learnt	O
mask	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
gives	O
the	O
masks	O
generated	O
by	O
the	O
mask	B-Method
network	I-Method
for	O
different	O
task	O
.	O
	
For	O
the	O
local	B-Task
attribute	I-Task
transformation	I-Task
tasks	I-Task
such	O
as	O
glasses	B-Task
removal	I-Task
and	O
closing	B-Task
mouth	I-Task
,	O
the	O
generated	O
masks	O
accurately	O
cover	O
the	O
local	O
facial	O
part	O
which	O
is	O
related	O
to	O
the	O
attribute	O
.	O
	
For	O
global	B-Task
transformation	I-Task
like	O
gender	B-Task
transformation	I-Task
,	O
the	O
mask	O
covers	O
most	O
of	O
the	O
face	O
and	O
keep	O
the	O
background	O
out	O
.	O
	
subsection	O
:	O
Experiments	O
on	O
face	B-Task
hallucination	I-Task
	
Finally	O
,	O
we	O
evaluate	O
the	O
performance	O
of	O
DIAT	B-Task
for	O
face	B-Task
hallucination	I-Task
.	O
	
Table	O
[	O
reference	O
]	O
lists	O
the	O
average	B-Metric
PSNR	I-Metric
and	O
SSIM	B-Metric
values	I-Metric
on	O
the	O
2	O
,	O
000	O
testing	O
images	O
by	O
DIAT	B-Task
,	O
bicubic	B-Method
interpolator	I-Method
,	O
and	O
Unet	B-Method
,	O
while	O
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
the	O
super	O
-	O
resolved	O
images	O
.	O
	
Even	O
our	O
DIAT	B-Task
achieves	O
lower	O
PSNR	B-Metric
/	O
SSIM	B-Metric
than	O
the	O
baseline	O
Unet	B-Method
,	O
it	O
is	O
much	O
better	O
in	O
terms	O
of	O
visual	B-Metric
quality	I-Metric
,	O
and	O
can	O
generate	O
hallucinated	O
image	O
with	O
rich	O
textures	O
and	O
sharp	O
edges	O
.	O
	
section	O
:	O
Conclusion	O
	
A	O
deep	B-Method
identity	I-Method
-	I-Method
aware	I-Method
transfer	I-Method
(	O
i	O
.	O
	
e	O
.	O
,	O
	
DIAT	B-Task
)	O
model	O
is	O
presented	O
for	O
facial	B-Task
attribute	I-Task
transfer	I-Task
.	O
	
Considering	O
that	O
some	O
attributes	O
may	O
be	O
only	O
related	O
with	O
parts	O
of	O
facial	O
image	O
,	O
the	O
whole	O
transfer	B-Method
model	I-Method
consists	O
of	O
two	O
subnetworks	O
,	O
i	O
.	O
	
e	O
.	O
,	O
	
mask	B-Method
network	I-Method
and	O
attribute	B-Method
transform	I-Method
network	I-Method
,	O
which	O
work	O
collaboratively	O
to	O
produce	O
the	O
transfer	O
result	O
.	O
	
In	O
order	O
to	O
train	O
the	O
model	O
,	O
we	O
further	O
incorporate	O
adversarial	B-Method
attribute	I-Method
loss	I-Method
,	O
adaptive	B-Method
perceptual	I-Method
loss	I-Method
with	O
perceptual	B-Method
regularization	I-Method
and	O
attribute	B-Method
ratio	I-Method
regularization	I-Method
.	O
	
Experiments	O
show	O
that	O
our	O
model	O
can	O
obtain	O
satisfying	O
results	O
for	O
both	O
local	B-Task
and	I-Task
global	I-Task
attribute	I-Task
transfer	I-Task
.	O
	
Even	O
for	O
some	O
identity	O
-	O
related	O
attributes	O
(	O
e.g.	O
,	O
gender	B-Task
transfer	I-Task
)	O
,	O
our	O
DIAT	B-Task
can	O
obtain	O
visually	O
impressive	O
results	O
with	O
minor	O
modification	O
on	O
identity	O
-	O
related	O
features	O
.	O
	
Our	O
DIAT	B-Task
can	O
also	O
be	O
extended	O
to	O
face	B-Task
hallucination	I-Task
and	O
performs	O
favorably	O
in	O
recovering	B-Task
facial	I-Task
details	I-Task
.	O
	
In	O
future	O
work	O
,	O
we	O
will	O
further	O
improve	O
the	O
visual	B-Metric
quality	I-Metric
and	O
diversity	O
of	O
the	O
transfer	O
results	O
,	O
and	O
extend	O
our	O
model	O
to	O
arbitrary	B-Task
attribute	I-Task
transfer	I-Task
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
	
Dynamic	B-Task
Evaluation	I-Task
of	O
Neural	B-Method
Sequence	I-Method
Models	I-Method
	
We	O
present	O
methodology	O
for	O
using	O
dynamic	B-Metric
evaluation	I-Metric
to	O
improve	O
neural	B-Method
sequence	I-Method
models	I-Method
.	O
	
Models	O
are	O
adapted	O
to	O
recent	O
history	O
via	O
a	O
gradient	B-Method
descent	I-Method
based	I-Method
mechanism	I-Method
,	O
causing	O
them	O
to	O
assign	O
higher	O
probabilities	O
to	O
re	O
-	O
occurring	O
sequential	O
patterns	O
.	O
	
Dynamic	B-Task
evaluation	I-Task
outperforms	O
existing	O
adaptation	B-Method
approaches	I-Method
in	O
our	O
comparisons	O
.	O
	
Dynamic	B-Task
evaluation	I-Task
improves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
word	B-Metric
-	I-Metric
level	I-Metric
perplexities	I-Metric
on	O
the	O
Penn	B-Material
Treebank	I-Material
and	O
WikiText	B-Material
-	I-Material
2	I-Material
datasets	I-Material
to	O
51.1	O
and	O
44.3	O
respectively	O
,	O
and	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
character	B-Metric
-	I-Metric
level	I-Metric
cross	I-Metric
-	I-Metric
entropies	I-Metric
on	O
the	O
text8	B-Material
and	O
Hutter	B-Material
Prize	I-Material
datasets	O
to	O
1.19	O
bits	O
/	O
char	O
and	O
1.08	O
bits	O
/	O
char	O
respectively	O
.	O
	
section	O
:	O
Introduction	O
	
Sequence	B-Task
generation	I-Task
and	O
prediction	B-Task
tasks	I-Task
span	O
many	O
modes	O
of	O
data	O
,	O
ranging	O
from	O
audio	B-Task
and	O
language	B-Task
modelling	I-Task
,	O
to	O
more	O
general	O
timeseries	B-Task
prediction	I-Task
tasks	I-Task
.	O
	
Applications	O
of	O
such	O
models	O
include	O
speech	B-Task
recognition	I-Task
,	O
machine	B-Task
translation	I-Task
,	O
dialogue	B-Task
generation	I-Task
,	O
speech	B-Task
synthesis	I-Task
,	O
forecasting	B-Task
,	O
and	O
music	B-Task
generation	I-Task
,	O
among	O
others	O
.	O
	
Neural	B-Method
networks	I-Method
can	O
be	O
applied	O
to	O
these	O
tasks	O
by	O
predicting	O
sequence	O
elements	O
one	O
-	O
by	O
-	O
one	O
,	O
conditioning	O
on	O
the	O
history	O
of	O
sequence	O
elements	O
,	O
forming	O
an	O
autoregressive	B-Method
model	I-Method
.	O
	
Convolutional	B-Method
neural	I-Method
networks	I-Method
(	O
CNNs	B-Method
)	O
and	O
recurrent	B-Method
neural	I-Method
networks	I-Method
(	O
RNNs	B-Method
)	O
,	O
including	O
long	B-Method
-	I-Method
short	I-Method
term	I-Method
memory	I-Method
(	O
LSTM	B-Method
)	O
networks	O
in	O
particular	O
,	O
have	O
achieved	O
many	O
successes	O
at	O
these	O
tasks	O
.	O
	
However	O
,	O
in	O
their	O
basic	O
form	O
,	O
these	O
models	O
have	O
a	O
limited	O
ability	O
to	O
adapt	O
to	O
recently	O
observed	O
parts	O
of	O
a	O
sequence	O
.	O
	
Many	O
sequences	O
contain	O
repetition	O
;	O
a	O
pattern	O
that	O
occurs	O
once	O
is	O
more	O
likely	O
to	O
occur	O
again	O
.	O
	
For	O
instance	O
,	O
a	O
word	O
that	O
occurs	O
once	O
in	O
a	O
document	O
is	O
much	O
more	O
likely	O
to	O
occur	O
again	O
.	O
	
A	O
sequence	O
of	O
handwriting	O
will	O
generally	O
stay	O
in	O
the	O
same	O
handwriting	O
style	O
.	O
	
A	O
sequence	O
of	O
speech	O
will	O
generally	O
stay	O
in	O
the	O
same	O
voice	O
.	O
	
Although	O
RNNs	B-Method
have	O
a	O
hidden	O
state	O
that	O
can	O
summarize	O
the	O
recent	O
past	O
,	O
they	O
are	O
often	O
unable	O
to	O
exploit	O
new	O
patterns	O
that	O
occur	O
repeatedly	O
in	O
a	O
test	O
sequence	O
.	O
	
This	O
paper	O
concerns	O
dynamic	B-Metric
evaluation	I-Metric
,	O
which	O
we	O
investigate	O
as	O
a	O
candidate	O
solution	O
to	O
this	O
problem	O
.	O
	
Our	O
approach	O
adapts	O
models	O
to	O
recent	O
sequences	O
using	O
gradient	B-Method
descent	I-Method
based	I-Method
mechanisms	I-Method
.	O
	
We	O
show	O
several	O
ways	O
to	O
improve	O
on	O
past	O
dynamic	B-Metric
evaluation	I-Metric
approaches	O
in	O
Section	O
[	O
reference	O
]	O
,	O
and	O
use	O
our	O
improved	O
methodology	O
to	O
achieve	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
in	O
Section	O
[	O
reference	O
]	O
and	O
Section	O
[	O
reference	O
]	O
.	O
	
In	O
Section	O
[	O
reference	O
]	O
we	O
design	O
a	O
method	O
to	O
dramatically	O
to	O
reduce	O
the	O
number	O
of	O
adaptation	O
parameters	O
in	O
dynamic	B-Metric
evaluation	I-Metric
,	O
making	O
it	O
practical	O
in	O
a	O
wider	O
range	O
of	O
situations	O
.	O
	
In	O
Section	O
[	O
reference	O
]	O
we	O
analyse	O
dynamic	B-Metric
evaluation	I-Metric
	
’s	O
performance	O
over	O
varying	O
time	O
-	O
scales	O
and	O
distribution	O
shifts	O
,	O
and	O
demonstrate	O
that	O
dynamically	B-Method
evaluated	I-Method
models	I-Method
can	O
generate	O
conditional	O
samples	O
that	O
repeat	O
many	O
patterns	O
from	O
the	O
conditioning	O
data	O
.	O
	
section	O
:	O
Motivation	O
	
Generative	B-Method
models	I-Method
can	O
assign	O
probabilities	O
to	O
sequences	O
by	O
modelling	O
each	O
term	O
in	O
the	O
factorization	O
given	O
by	O
the	O
product	B-Method
rule	I-Method
.	O
	
The	O
probability	O
of	O
a	O
sequence	O
factorizes	O
as	O
Methods	O
that	O
apply	O
this	O
factorization	O
either	O
use	O
a	O
fixed	O
context	O
when	O
predicting	B-Task
,	O
for	O
instance	O
as	O
in	O
N	B-Task
-	I-Task
grams	I-Task
or	O
CNNs	B-Method
,	O
or	O
use	O
a	O
recurrent	O
hidden	O
state	O
to	O
summarize	O
the	O
context	O
,	O
as	O
in	O
an	O
RNN	B-Method
.	O
	
However	O
,	O
for	O
longer	O
sequences	O
,	O
the	O
history	O
often	O
contains	O
re	O
-	O
occurring	O
patterns	O
that	O
are	O
difficult	O
to	O
capture	O
using	O
models	O
with	O
fixed	B-Method
parameters	I-Method
(	O
static	B-Metric
models	O
)	O
.	O
	
In	O
many	O
domains	O
,	O
in	O
a	O
dataset	O
of	O
sequences	O
,	O
each	O
sequence	O
is	O
generated	O
from	O
a	O
slightly	O
different	O
distribution	O
.	O
	
At	O
any	O
point	O
in	O
time	O
,	O
the	O
history	O
of	O
a	O
sequence	O
contains	O
useful	O
information	O
about	O
the	O
generating	B-Method
distribution	I-Method
for	O
that	O
specific	O
sequence	O
.	O
	
Therefore	O
adapting	O
the	O
model	O
parameters	O
learned	O
during	O
training	O
is	O
justified	O
.	O
	
We	O
aim	O
to	O
infer	O
a	O
set	O
of	O
model	O
parameters	O
from	O
that	O
will	O
better	O
approximate	O
within	O
sequence	O
.	O
	
Many	O
sequence	B-Task
modelling	I-Task
tasks	I-Task
are	O
characterised	O
by	O
sequences	O
generated	O
from	O
slightly	O
different	O
distributions	O
as	O
in	O
the	O
scenario	O
described	O
above	O
.	O
	
The	O
generating	B-Method
distribution	I-Method
may	O
also	O
change	O
continuously	O
across	O
a	O
single	O
sequence	O
;	O
for	O
instance	O
,	O
a	O
text	O
excerpt	O
may	O
change	O
topic	O
.	O
	
Furthermore	O
,	O
many	O
machine	B-Method
learning	I-Method
benchmarks	I-Method
do	O
not	O
distinguish	O
between	O
sequence	O
boundaries	O
,	O
and	O
concatenate	O
all	O
sequences	O
into	O
one	O
continuous	O
sequence	O
.	O
	
Thus	O
,	O
many	O
sequence	B-Task
modelling	I-Task
tasks	I-Task
could	O
be	O
seen	O
as	O
having	O
a	O
local	O
distribution	O
as	O
well	O
as	O
a	O
global	O
distribution	O
.	O
	
During	O
training	O
time	O
,	O
the	O
goal	O
is	O
to	O
find	O
the	O
best	O
fixed	B-Method
model	I-Method
possible	O
for	O
.	O
	
However	O
,	O
during	O
evaluation	O
time	O
,	O
a	O
model	O
that	O
can	O
infer	O
the	O
current	O
from	O
the	O
recent	O
history	O
has	O
an	O
advantage	O
.	O
	
section	O
:	O
Dynamic	B-Task
evaluation	I-Task
	
Dynamic	B-Method
evaluation	I-Method
methods	I-Method
continuously	O
adapt	O
the	O
model	O
parameters	O
,	O
learned	O
at	O
training	O
time	O
,	O
to	O
parts	O
of	O
a	O
sequence	O
during	O
evaluation	O
.	O
	
The	O
goal	O
is	O
to	O
learn	O
adapted	O
parameters	O
that	O
provide	O
a	O
better	O
model	O
of	O
the	O
local	O
sequence	O
distribution	O
,	O
.	O
	
When	O
dynamic	B-Metric
evaluation	I-Metric
is	O
applied	O
in	O
the	O
present	O
work	O
,	O
a	O
long	O
test	O
sequence	O
is	O
divided	O
up	O
into	O
shorter	O
sequences	O
of	O
length	O
.	O
	
We	O
define	O
to	O
be	O
a	O
sequence	O
of	O
shorter	O
sequence	O
segments	O
	
The	O
initial	O
adapted	O
parameters	O
are	O
set	O
to	O
,	O
and	O
used	O
to	O
compute	O
the	O
probability	O
of	O
the	O
first	O
segment	O
,	O
.	O
	
This	O
probability	O
gives	O
a	O
cross	O
entropy	O
loss	O
,	O
with	O
gradient	O
,	O
which	O
is	O
computed	O
using	O
truncated	B-Method
back	I-Method
-	I-Method
propagation	I-Method
through	O
time	O
.	O
	
The	O
gradient	O
is	O
used	O
to	O
update	O
the	O
model	O
,	O
resulting	O
in	O
adapted	O
parameters	O
,	O
before	O
evaluating	O
.	O
	
The	O
same	O
procedure	O
is	O
then	O
repeated	O
for	O
,	O
and	O
for	O
each	O
in	O
the	O
sequence	O
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Gradients	O
for	O
each	O
loss	O
are	O
only	O
backpropagated	O
to	O
the	O
beginning	O
of	O
,	O
so	O
computation	O
is	O
linear	O
in	O
the	O
sequence	O
length	O
.	O
	
Each	O
update	O
applies	O
one	O
maximum	B-Method
likelihood	I-Method
training	I-Method
step	I-Method
to	O
approximate	O
the	O
current	O
local	O
distribution	O
.	O
	
The	O
computational	B-Metric
cost	I-Metric
of	O
dynamic	B-Metric
evaluation	I-Metric
is	O
one	O
forward	B-Method
pass	I-Method
and	O
one	O
gradient	B-Method
computation	I-Method
through	O
the	O
data	O
,	O
with	O
some	O
slight	O
overhead	O
to	O
apply	O
the	O
update	B-Method
rule	I-Method
for	O
every	O
sequence	O
segment	O
.	O
	
As	O
in	O
all	O
autoregressive	B-Method
models	I-Method
,	O
dynamic	B-Metric
evaluation	I-Metric
only	O
conditions	O
on	O
sequence	O
elements	O
that	O
it	O
has	O
already	O
predicted	O
,	O
and	O
so	O
evaluates	O
a	O
valid	O
log	O
-	O
probability	O
for	O
each	O
sequence	O
.	O
	
Dynamic	B-Task
evaluation	I-Task
can	O
also	O
be	O
used	O
while	O
generating	B-Task
sequences	I-Task
.	O
	
In	O
this	O
case	O
,	O
the	O
model	O
generates	O
each	O
sequence	O
segment	O
using	O
fixed	O
weights	O
,	O
and	O
performs	O
a	O
gradient	B-Method
descent	I-Method
based	I-Method
update	I-Method
step	I-Method
on	O
.	O
	
Applying	O
dynamic	B-Metric
evaluation	I-Metric
for	O
sequence	B-Task
generation	I-Task
could	O
result	O
in	O
generated	O
sequences	O
with	O
more	O
consistent	O
regularities	O
,	O
meaning	O
that	O
patterns	O
that	O
occur	O
in	O
the	O
generated	O
sequence	O
are	O
more	O
likely	O
to	O
occur	O
again	O
.	O
	
section	O
:	O
Background	O
	
subsection	O
:	O
Related	O
approaches	O
	
Adaptive	B-Task
language	I-Task
modelling	I-Task
was	O
first	O
considered	O
for	O
n	B-Task
-	I-Task
grams	I-Task
,	O
adapting	O
to	O
recent	O
history	O
via	O
caching	O
,	O
and	O
other	O
methods	O
.	O
	
More	O
recently	O
,	O
the	O
neural	B-Method
cache	I-Method
approach	I-Method
and	O
the	O
closely	O
related	O
pointer	O
sentinel	O
-	O
LSTM	B-Method
have	O
been	O
used	O
to	O
for	O
adaptive	O
neural	O
language	B-Task
modelling	I-Task
.	O
	
Neural	B-Method
caching	I-Method
has	O
recently	O
been	O
used	O
to	O
improve	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
at	O
word	O
-	O
level	O
language	B-Task
modelling	I-Task
.	O
	
The	O
neural	B-Method
cache	I-Method
model	I-Method
learns	O
a	O
type	O
of	O
non	B-Method
-	I-Method
parametric	I-Method
output	I-Method
layer	I-Method
on	O
the	O
fly	O
at	O
test	B-Metric
time	I-Metric
,	O
which	O
allows	O
the	O
network	O
to	O
adapt	O
to	O
recent	O
observations	O
.	O
	
Each	O
past	O
hidden	O
state	O
is	O
paired	O
with	O
the	O
next	O
input	O
,	O
and	O
is	O
stored	O
as	O
a	O
tuple	O
.	O
	
When	O
a	O
new	O
hidden	O
state	O
is	O
observed	O
,	O
the	O
output	O
probabilities	O
are	O
adjusted	O
to	O
give	O
a	O
higher	O
weight	O
to	O
output	O
words	O
that	O
coincided	O
with	O
past	O
hidden	O
states	O
with	O
a	O
large	O
inner	O
product	O
.	O
	
where	O
is	O
a	O
one	B-Method
hot	I-Method
encoding	I-Method
of	O
,	O
and	O
is	O
a	O
scaling	O
parameter	O
.	O
	
The	O
cache	O
probabilities	O
are	O
interpolated	O
with	O
the	O
base	O
network	O
probabilities	O
to	O
adapt	O
the	O
base	O
network	O
at	O
test	B-Metric
time	I-Metric
.	O
	
The	O
neural	B-Method
cache	I-Method
closely	O
relates	O
to	O
dynamic	B-Metric
evaluation	I-Metric
,	O
as	O
both	O
methods	O
can	O
be	O
added	O
on	O
top	O
of	O
a	O
base	O
model	O
for	O
adaptation	B-Task
at	O
test	B-Metric
time	I-Metric
.	O
	
The	O
main	O
difference	O
is	O
the	O
mechanism	O
used	O
to	O
fit	O
to	O
recent	O
history	O
:	O
the	O
neural	B-Method
cache	I-Method
approach	I-Method
uses	O
a	O
non	B-Method
-	I-Method
parametric	I-Method
,	I-Method
nearest	I-Method
neighbours	I-Method
-	I-Method
like	I-Method
method	I-Method
,	O
whereas	O
dynamic	B-Metric
evaluation	I-Metric
uses	O
a	O
gradient	B-Method
descent	I-Method
based	I-Method
method	I-Method
to	O
change	O
model	O
parameters	O
dynamically	O
.	O
	
Both	O
methods	O
rely	O
on	O
an	O
autoregressive	B-Method
factorisation	I-Method
,	O
as	O
they	O
depend	O
on	O
observing	O
sequence	O
elements	O
after	O
they	O
are	O
predicted	O
in	O
order	O
to	O
perform	O
adaptation	B-Task
.	O
	
Dynamic	B-Method
evaluation	I-Method
and	O
neural	B-Method
caching	I-Method
methods	I-Method
are	O
therefore	O
both	O
applicable	O
to	O
sequence	B-Task
prediction	I-Task
and	I-Task
generation	I-Task
tasks	I-Task
,	O
but	O
not	O
directly	O
to	O
more	O
general	O
supervised	B-Task
learning	I-Task
tasks	I-Task
.	O
	
One	O
drawback	O
of	O
the	O
neural	B-Method
cache	I-Method
method	I-Method
is	O
that	O
it	O
can	O
not	O
adjust	O
the	O
recurrent	O
hidden	O
state	O
dynamics	O
.	O
	
As	O
a	O
result	O
,	O
the	O
neural	B-Method
cache	I-Method
’s	O
ability	O
to	O
capture	O
information	O
that	O
occurs	O
jointly	O
between	O
successive	O
sequence	O
elements	O
is	O
limited	O
.	O
	
This	O
capability	O
is	O
critical	O
for	O
adapting	O
to	O
sequences	O
where	O
each	O
element	O
has	O
very	O
little	O
independent	O
meaning	O
,	O
e.g.	O
character	B-Task
level	I-Task
language	I-Task
modelling	I-Task
.	O
	
subsection	O
:	O
Dynamic	B-Task
evaluation	I-Task
in	O
neural	B-Task
networks	I-Task
	
Dynamic	B-Task
evaluation	I-Task
of	O
neural	B-Method
language	I-Method
models	I-Method
was	O
proposed	O
by	O
.	O
	
Their	O
approach	O
simply	O
used	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
(	O
SGD	B-Method
)	O
updates	O
at	O
every	O
time	O
step	O
,	O
computing	O
the	O
gradient	O
with	O
fully	O
truncated	O
backpropagation	O
through	O
time	O
,	O
which	O
is	O
equivalent	O
to	O
setting	O
in	O
equation	O
(	O
[	O
reference	O
]	O
)	O
.	O
	
Dynamic	B-Task
evaluation	I-Task
has	O
since	O
been	O
applied	O
to	O
character	B-Task
and	O
word	O
-	O
level	O
language	O
models	O
.	O
	
Previous	O
work	O
using	O
dynamic	B-Metric
evaluation	I-Metric
considered	O
it	O
as	O
an	O
aside	O
,	O
and	O
did	O
not	O
explore	O
it	O
in	O
depth	O
.	O
	
section	O
:	O
Update	B-Method
Rule	I-Method
methodology	I-Method
for	O
Dynamic	B-Task
evaluation	I-Task
	
We	O
propose	O
several	O
changes	O
to	O
’s	O
dynamic	B-Method
evaluation	I-Method
method	I-Method
with	O
SGD	B-Method
and	O
fully	B-Method
truncated	I-Method
backpropagation	I-Method
,	O
which	O
we	O
refer	O
to	O
as	O
traditional	O
dynamic	B-Metric
evaluation	I-Metric
.	O
	
The	O
first	O
modification	O
reduces	O
the	O
update	O
frequency	O
,	O
so	O
that	O
gradients	O
are	O
backpropagated	O
over	O
more	O
timesteps	O
.	O
	
This	O
change	O
provides	O
more	O
accurate	O
gradient	O
information	O
,	O
and	O
also	O
improves	O
the	O
computational	B-Metric
efficiency	I-Metric
of	O
dynamic	B-Metric
evaluation	I-Metric
,	O
since	O
the	O
update	B-Method
rule	I-Method
is	O
applied	O
much	O
less	O
often	O
.	O
	
We	O
use	O
sequence	O
segments	O
of	O
length	O
5	O
for	O
word	B-Task
-	I-Task
level	I-Task
tasks	I-Task
and	O
20	O
for	O
character	B-Task
-	O
level	O
tasks	O
.	O
	
Next	O
,	O
we	O
add	O
a	O
global	O
decay	O
prior	O
to	O
bias	O
the	O
model	O
towards	O
the	O
parameters	O
learned	O
during	O
training	O
.	O
	
Our	O
motivation	O
for	O
dynamic	B-Metric
evaluation	I-Metric
assumes	O
that	O
the	O
local	B-Method
generating	I-Method
distribution	I-Method
is	O
constantly	O
changing	O
,	O
so	O
it	O
is	O
potentially	O
desirable	O
to	O
weight	O
recent	O
sequence	O
history	O
higher	O
in	O
adaptation	B-Task
.	O
	
Adding	O
a	O
global	O
decay	O
prior	O
accomplishes	O
this	O
by	O
causing	O
previous	O
adaptation	O
updates	O
to	O
decay	O
exponentially	O
over	O
time	O
.	O
	
For	O
SGD	B-Method
with	O
a	O
global	O
prior	O
,	O
learning	B-Metric
rate	I-Metric
and	O
decay	B-Metric
rate	I-Metric
;	O
we	O
form	O
the	O
update	B-Method
rule	I-Method
We	O
then	O
consider	O
using	O
an	O
RMSprop	B-Method
derived	I-Method
update	I-Method
rule	I-Method
for	O
the	O
learning	B-Method
rule	I-Method
in	O
place	O
of	O
SGD	B-Method
.	O
	
RMSprop	B-Method
uses	O
a	O
moving	B-Method
average	I-Method
of	I-Method
recent	I-Method
squared	I-Method
gradients	I-Method
to	O
scale	O
learning	O
rates	O
for	O
each	O
weight	O
.	O
	
In	O
dynamic	B-Metric
evaluation	I-Metric
,	O
near	O
the	O
start	O
of	O
a	O
test	O
sequence	O
,	O
RMSprop	B-Method
has	O
had	O
very	O
few	O
gradients	O
to	O
average	O
,	O
and	O
therefore	O
may	O
not	O
be	O
able	O
to	O
leverage	O
its	O
updates	O
as	O
effectively	O
.	O
	
For	O
this	O
reason	O
,	O
we	O
collect	O
mean	O
squared	O
gradients	O
,	O
,	O
on	O
the	O
training	O
data	O
rather	O
than	O
on	O
recent	O
test	O
data	O
(	O
which	O
is	O
what	O
RMSprop	O
would	O
do	O
)	O
.	O
is	O
given	O
by	O
where	O
is	O
the	O
number	O
of	O
training	O
batches	O
and	O
is	O
the	O
gradient	O
on	O
the	O
th	O
training	O
batch	O
.	O
	
The	O
mini	O
-	O
batch	O
size	O
for	O
this	O
computation	O
becomes	O
a	O
hyper	O
-	O
parameter	O
,	O
as	O
larger	O
mini	O
-	O
batches	O
will	O
result	O
in	O
smaller	O
mean	O
squared	O
gradients	O
.	O
	
The	O
update	B-Method
rule	I-Method
,	O
which	O
we	O
call	O
RMS	B-Method
with	O
a	O
global	O
prior	O
in	O
our	O
experiments	O
,	O
is	O
then	O
where	O
is	O
a	O
stabilization	O
parameter	O
.	O
	
For	O
the	O
decay	O
step	O
of	O
our	O
update	B-Method
rule	I-Method
,	O
we	O
also	O
consider	O
scaling	O
the	O
decay	B-Metric
rate	I-Metric
for	O
each	O
parameter	O
proportionally	O
to	O
.	O
	
Parameters	O
with	O
a	O
high	O
RMS	O
gradient	O
affect	O
the	O
dynamics	O
of	O
the	O
network	O
more	O
,	O
so	O
it	O
makes	O
sense	O
to	O
decay	O
them	O
faster	O
.	O
	
is	O
divided	O
by	O
its	O
mean	O
,	O
resulting	O
in	O
a	O
normalized	O
version	O
of	O
with	O
a	O
mean	O
of	O
1	O
	
:	O
We	O
clip	O
the	O
values	O
of	O
to	O
be	O
no	O
greater	O
than	O
to	O
be	O
sure	O
that	O
the	O
decay	B-Metric
rate	I-Metric
does	O
not	O
exceed	O
for	O
any	O
parameter	O
.	O
	
Combining	O
the	O
learning	B-Method
component	I-Method
and	O
the	O
regularization	B-Method
component	I-Method
results	O
in	O
the	O
final	O
update	B-Method
equation	I-Method
,	O
which	O
we	O
refer	O
to	O
as	O
RMS	B-Method
with	O
an	O
RMS	B-Method
global	I-Method
prior	I-Method
	
section	O
:	O
Sparse	O
dynamic	B-Metric
evaluation	I-Metric
	
Mini	B-Method
-	I-Method
batching	I-Method
over	O
sequences	O
is	O
desirable	O
for	O
some	O
test	B-Task
-	I-Task
time	I-Task
sequence	I-Task
modelling	I-Task
applications	I-Task
because	O
it	O
allows	O
faster	B-Task
processing	I-Task
of	I-Task
multiple	I-Task
sequences	I-Task
in	O
parallel	O
.	O
	
Dynamic	B-Task
evaluation	I-Task
has	O
a	O
high	O
memory	B-Metric
cost	I-Metric
for	O
mini	B-Task
-	I-Task
batching	I-Task
because	O
it	O
is	O
necessary	O
to	O
store	O
a	O
different	O
set	O
of	O
parameters	O
for	O
each	O
sequence	O
in	O
the	O
mini	O
-	O
batch	O
.	O
	
Therefore	O
,	O
we	O
consider	O
a	O
sparse	O
dynamic	B-Metric
evaluation	I-Metric
variant	O
that	O
updates	O
a	O
smaller	O
number	O
of	O
parameters	O
.	O
	
We	O
introduce	O
a	O
new	O
adaptation	B-Method
matrix	I-Method
which	O
is	O
initialized	O
to	O
zeros	O
.	O
	
multiplies	O
hidden	O
state	O
vector	O
of	O
an	O
RNN	B-Method
at	O
every	O
time	O
-	O
step	O
to	O
get	O
a	O
new	O
hidden	O
state	O
,	O
via	O
then	O
replaces	O
and	O
is	O
propagated	O
throughout	O
the	O
network	O
via	O
both	O
recurrent	B-Method
and	I-Method
feed	I-Method
-	I-Method
forward	I-Method
connections	I-Method
.	O
	
Applying	O
dynamic	B-Metric
evaluation	I-Metric
to	O
avoids	O
the	O
need	O
to	O
apply	O
dynamic	B-Metric
evaluation	I-Metric
to	O
the	O
original	O
parameters	O
of	O
the	O
network	O
,	O
reduces	O
the	O
number	O
of	O
adaptation	O
parameters	O
,	O
and	O
makes	O
mini	B-Method
-	I-Method
batching	I-Method
less	O
memory	O
intensive	O
.	O
	
We	O
reduce	O
the	O
number	O
of	O
adaptation	O
parameters	O
further	O
by	O
only	O
using	O
to	O
transform	O
an	O
arbitrary	O
subset	O
of	O
hidden	O
units	O
.	O
	
This	O
results	O
in	O
being	O
an	O
matrix	O
with	O
adaptation	O
parameters	O
.	O
	
If	O
is	O
chosen	O
to	O
be	O
much	O
less	O
than	O
the	O
number	O
of	O
hidden	O
units	O
,	O
this	O
reduces	O
the	O
number	O
of	O
adaptation	O
parameters	O
dramatically	O
.	O
	
In	O
Section	O
[	O
reference	O
]	O
	
we	O
experiment	O
with	O
sparse	O
dynamic	B-Metric
evaluation	I-Metric
for	O
character	B-Task
-	O
level	O
language	O
models	O
.	O
	
section	O
:	O
Experiments	O
	
We	O
applied	O
dynamic	B-Metric
evaluation	I-Metric
to	O
word	O
-	O
level	O
and	O
character	B-Task
-	O
level	O
language	B-Task
modelling	I-Task
.	O
	
In	O
all	O
tasks	O
,	O
we	O
evaluate	O
dynamic	B-Metric
evaluation	I-Metric
on	O
top	O
of	O
a	O
base	O
model	O
.	O
	
After	O
training	O
the	O
base	O
model	O
,	O
we	O
tune	O
hyper	O
-	O
parameters	O
for	O
dynamic	B-Metric
evaluation	I-Metric
on	O
the	O
validation	O
set	O
,	O
and	O
evaluate	O
both	O
the	O
static	B-Metric
and	O
dynamic	O
versions	O
of	O
the	O
model	O
on	O
the	O
test	O
set	O
.	O
	
We	O
also	O
consider	O
follow	O
up	O
experiments	O
that	O
analyse	O
the	O
sequence	O
lengths	O
for	O
which	O
dynamic	B-Metric
evaluation	I-Metric
is	O
useful	O
.	O
	
Code	O
for	O
our	O
dynamic	B-Metric
evaluation	I-Metric
methodology	O
is	O
available	O
.	O
	
subsection	O
:	O
Word	B-Task
-	I-Task
level	I-Task
language	I-Task
modelling	I-Task
	
We	O
train	O
base	B-Method
models	I-Method
on	O
the	O
Penn	B-Material
Treebank	I-Material
and	O
WikiText	B-Material
-	I-Material
2	I-Material
datasets	I-Material
,	O
and	O
compare	O
the	O
performance	O
of	O
static	B-Metric
and	O
dynamic	B-Metric
evaluation	I-Metric
.	O
	
These	O
experiments	O
compare	O
dynamic	B-Metric
evaluation	I-Metric
against	O
past	O
approaches	O
such	O
as	O
the	O
neural	B-Method
cache	I-Method
and	O
measure	O
dynamic	B-Metric
evaluation	I-Metric
’s	O
general	O
performance	O
across	O
different	O
models	O
and	O
datasets	O
.	O
	
PTB	B-Material
is	O
derived	O
from	O
articles	O
of	O
the	O
Wall	B-Material
Street	I-Material
Journal	I-Material
.	O
	
It	O
contains	O
929k	O
training	O
tokens	O
and	O
a	O
vocab	O
size	O
limited	O
to	O
10k	O
words	O
.	O
	
It	O
is	O
one	O
of	O
the	O
most	O
commonly	O
used	O
benchmarks	O
in	O
language	B-Task
modelling	I-Task
.	O
	
We	O
consider	O
two	O
baseline	O
models	O
on	O
PTB	B-Material
,	O
a	O
standard	O
LSTM	B-Method
implementation	O
with	O
recurrent	B-Method
dropout	I-Method
,	O
and	O
the	O
recent	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
AWD	B-Method
-	I-Method
LSTM	I-Method
.	O
	
Our	O
standard	O
LSTM	B-Method
was	O
taken	O
from	O
the	O
Chainer	B-Method
tutorial	I-Method
on	O
language	B-Task
modelling	I-Task
,	O
and	O
used	O
two	O
LSTM	B-Method
layers	O
with	O
650	O
units	O
each	O
,	O
trained	O
with	O
SGD	B-Method
and	O
regularized	B-Method
with	O
recurrent	B-Method
dropout	I-Method
.	O
	
On	O
our	O
standard	O
LSTM	B-Method
,	O
we	O
experiment	O
with	O
traditional	O
dynamic	B-Metric
evaluation	I-Metric
as	O
applied	O
by	O
,	O
as	O
well	O
as	O
each	O
modification	O
we	O
make	O
building	O
up	O
to	O
our	O
final	O
update	O
rule	O
as	O
described	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
As	O
our	O
final	O
update	B-Method
rule	I-Method
(	O
RMS	O
+	O
RMS	O
global	O
prior	O
)	O
worked	O
best	O
,	O
we	O
use	O
this	O
for	O
all	O
other	O
experiments	O
and	O
use	O
‘	O
‘	O
dynamic	O
eval	O
’	O
’	O
by	O
default	O
to	O
refer	O
to	O
this	O
update	B-Method
rule	I-Method
in	O
tables	O
.	O
	
We	O
applied	O
dynamic	B-Metric
evaluation	I-Metric
on	O
a	O
more	O
powerful	O
model	O
,	O
the	O
ASGD	B-Method
weight	I-Method
-	I-Method
dropped	I-Method
LSTM	I-Method
.	O
	
The	O
AWD	B-Method
-	I-Method
LSTM	I-Method
is	O
a	O
vanilla	O
LSTM	B-Method
that	O
combines	O
the	O
use	O
of	O
drop	B-Method
-	I-Method
connect	I-Method
on	O
recurrent	O
weights	O
for	O
regularization	B-Task
,	O
and	O
a	O
variant	O
of	O
averaged	B-Method
stochastic	I-Method
gradient	I-Method
descent	I-Method
for	O
optimisation	B-Task
.	O
	
Our	O
model	O
,	O
which	O
used	O
3	O
layers	O
and	O
tied	O
input	O
and	O
output	O
embeddings	O
,	O
was	O
intended	O
to	O
be	O
a	O
direct	O
replication	O
of	O
AWD	B-Method
-	I-Method
LSTM	I-Method
,	O
using	O
code	O
from	O
their	O
implementation	O
.	O
	
Results	O
are	O
given	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Dynamic	B-Task
evaluation	I-Task
gives	O
significant	O
overall	O
improvements	O
to	O
both	O
models	O
on	O
this	O
dataset	O
.	O
	
Dynamic	B-Task
evaluation	I-Task
also	O
achieves	O
better	O
final	O
results	O
than	O
the	O
neural	B-Method
cache	I-Method
on	O
both	O
a	O
standard	O
LSTM	B-Method
and	O
the	O
AWD	O
-	O
LSTM	B-Method
reimplementation	O
,	O
and	O
improves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
on	O
PTB	B-Material
.	O
	
WikiText	B-Material
-	I-Material
2	I-Material
is	O
roughly	O
twice	O
the	O
size	O
of	O
PTB	B-Material
,	O
with	O
2	O
million	O
training	O
tokens	O
and	O
a	O
vocab	O
size	O
of	O
33k	O
.	O
	
It	O
features	O
articles	O
in	O
a	O
non	O
-	O
shuffled	O
order	O
,	O
with	O
dependencies	O
across	O
articles	O
that	O
adaptive	B-Method
methods	I-Method
should	O
be	O
able	O
to	O
exploit	O
.	O
	
For	O
this	O
dataset	O
,	O
we	O
use	O
the	O
same	O
baseline	O
LSTM	B-Method
implementation	O
and	O
AWD	O
-	O
LSTM	B-Method
re	O
-	O
implementation	O
as	O
on	O
PTB	B-Material
.	O
	
Results	O
are	O
given	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Dynamic	B-Task
evaluation	I-Task
improves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
perplexity	B-Metric
on	O
WikiText	B-Material
-	I-Material
2	I-Material
,	O
and	O
provides	O
a	O
significantly	O
greater	O
improvement	O
than	O
neural	B-Method
caching	I-Method
to	O
both	O
base	O
models	O
.	O
	
This	O
suggests	O
that	O
dynamic	B-Metric
evaluation	I-Metric
is	O
effective	O
at	O
exploiting	O
regularities	O
that	O
co	O
-	O
occur	O
across	O
non	O
-	O
shuffled	O
documents	O
.	O
	
subsection	O
:	O
Character	B-Task
-	I-Task
level	I-Task
language	I-Task
modelling	I-Task
	
We	O
consider	O
dynamic	B-Metric
evaluation	I-Metric
on	O
the	O
text8	B-Material
,	O
and	O
Hutter	B-Material
Prize	I-Material
datasets	I-Material
.	O
	
The	O
Hutter	B-Material
Prize	O
dataset	O
is	O
comprised	O
of	O
Wikipedia	B-Material
text	I-Material
,	O
and	O
includes	O
XML	B-Material
and	O
characters	O
from	O
non	B-Material
-	I-Material
Latin	I-Material
languages	I-Material
.	O
	
It	O
is	O
100	O
million	O
UTF	O
-	O
8	O
bytes	O
long	O
and	O
contains	O
205	O
unique	O
bytes	O
.	O
	
Similarly	O
to	O
other	O
reported	O
results	O
,	O
we	O
use	O
a	O
90	O
-	O
5	O
-	O
5	O
split	O
for	O
training	B-Task
,	O
validation	B-Task
,	O
and	O
testing	B-Task
.	O
	
The	O
text8	B-Material
dataset	O
is	O
also	O
derived	O
from	O
Wikipedia	B-Material
text	I-Material
,	O
but	O
has	O
all	O
XML	O
removed	O
,	O
and	O
is	O
lower	O
cased	O
to	O
only	O
have	O
26	O
characters	O
of	O
English	B-Material
text	I-Material
plus	O
spaces	O
.	O
	
As	O
with	O
Hutter	B-Material
Prize	O
,	O
we	O
use	O
the	O
standard	O
90	O
-	O
5	O
-	O
5	O
split	O
for	O
training	O
,	O
validation	B-Task
,	O
and	O
testing	O
for	O
text8	B-Material
.	O
	
We	O
used	O
a	O
multiplicative	B-Method
LSTM	I-Method
(	O
mLSTM	B-Method
)	O
as	O
our	O
base	O
model	O
for	O
both	O
datasets	O
.	O
	
The	O
mLSTMs	B-Method
for	O
both	O
tasks	O
used	O
2800	O
hidden	O
units	O
,	O
an	O
embedding	B-Method
layer	I-Method
of	O
400	O
units	O
,	O
weight	B-Method
normalization	I-Method
,	O
variational	B-Method
dropout	I-Method
,	O
and	O
ADAM	B-Method
for	O
training	B-Task
.	O
	
We	O
also	O
consider	O
sparse	O
dynamic	B-Metric
evaluation	I-Metric
,	O
as	O
described	O
in	O
Section	O
[	O
reference	O
]	O
,	O
on	O
the	O
Hutter	B-Material
Prize	O
dataset	O
.	O
	
For	O
sparse	O
dynamic	B-Metric
evaluation	I-Metric
,	O
we	O
adapted	O
a	O
subset	O
of	O
hidden	O
units	O
,	O
resulting	O
in	O
a	O
adaptation	O
matrix	O
and	O
250k	O
adaptation	O
parameters	O
.	O
	
All	O
of	O
our	O
dynamic	B-Metric
evaluation	I-Metric
results	O
in	O
this	O
section	O
use	O
the	O
final	O
update	O
rule	O
given	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Results	O
for	O
Hutter	B-Material
Prize	I-Material
are	O
given	O
in	O
Table	O
[	O
reference	O
]	O
,	O
and	O
results	O
for	O
text8	B-Material
are	O
given	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Dynamic	B-Task
evaluation	I-Task
achieves	O
large	O
improvements	O
to	O
our	O
base	O
models	O
and	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
both	O
datasets	O
.	O
	
Sparse	O
dynamic	B-Metric
evaluation	I-Metric
also	O
achieves	O
significant	O
improvements	O
on	O
Hutter	B-Material
Prize	I-Material
using	O
only	O
0.5	O
%	O
of	O
the	O
adaptation	O
parameters	O
of	O
regular	O
dynamic	B-Metric
evaluation	I-Metric
.	O
	
subsection	O
:	O
Time	O
-	O
scales	O
of	O
dynamic	B-Metric
evaluation	I-Metric
	
We	O
measure	O
time	O
-	O
scales	O
at	O
which	O
dynamic	B-Metric
evaluation	I-Metric
gains	O
an	O
advantage	O
over	O
static	B-Metric
evaluation	O
.	O
	
Starting	O
from	O
the	O
model	O
trained	O
on	O
Hutter	B-Material
Prize	I-Material
,	O
we	O
plot	O
the	O
performance	O
of	O
static	B-Metric
and	O
dynamic	B-Metric
evaluation	I-Metric
against	O
the	O
number	O
of	O
characters	O
processed	O
on	O
sequences	O
from	O
the	O
Hutter	B-Material
Prize	O
test	O
set	O
,	O
and	O
sequences	O
in	O
Spanish	B-Material
from	O
the	O
European	B-Material
Parliament	I-Material
dataset	I-Material
.	O
	
The	O
Hutter	B-Material
Prize	O
data	O
experiments	O
show	O
the	O
timescales	O
at	O
which	O
dynamic	B-Metric
evaluation	I-Metric
gained	O
the	O
advantage	O
observed	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
We	O
divided	O
the	O
Hutter	B-Material
Prize	O
test	O
set	O
into	O
500	O
sequences	O
of	O
length	O
10000	O
,	O
and	O
applied	O
static	B-Metric
and	O
dynamic	B-Metric
evaluation	I-Metric
to	O
these	O
sequences	O
using	O
the	O
same	O
model	O
and	O
methodology	O
used	O
to	O
obtain	O
results	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Losses	O
were	O
averaged	O
across	O
these	O
500	O
sequences	O
to	O
obtain	O
average	O
losses	O
at	O
each	O
time	O
step	O
.	O
	
Plots	O
of	O
the	O
average	B-Metric
cross	I-Metric
-	I-Metric
entropy	I-Metric
errors	I-Metric
against	O
the	O
number	O
of	O
Hutter	B-Material
characters	O
sequenced	O
are	O
given	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
The	O
Spanish	O
experiments	O
measure	O
how	O
dynamic	B-Metric
evaluation	I-Metric
handles	O
large	O
distribution	O
shifts	O
between	O
training	O
and	O
test	B-Metric
time	I-Metric
,	O
as	O
Hutter	B-Material
Prize	I-Material
contains	O
very	O
little	O
Spanish	B-Material
.	O
	
We	O
used	O
the	O
first	O
5	O
million	O
characters	O
of	O
the	O
Spanish	B-Material
European	I-Material
Parliament	I-Material
data	I-Material
in	O
place	O
of	O
the	O
Hutter	B-Material
Prize	O
test	O
set	O
.	O
	
The	O
Spanish	O
experiments	O
used	O
the	O
same	O
base	O
model	O
and	O
dynamic	B-Metric
evaluation	I-Metric
settings	O
as	O
Hutter	B-Material
Prize	I-Material
.	O
	
Plots	O
of	O
the	O
average	B-Metric
cross	I-Metric
-	I-Metric
entropy	I-Metric
errors	I-Metric
against	O
the	O
number	O
of	O
Spanish	O
characters	O
sequenced	O
are	O
given	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
.4	O
	
.4	O
	
On	O
both	O
datasets	O
,	O
dynamic	B-Metric
evaluation	I-Metric
gave	O
a	O
very	O
noticeable	O
advantage	O
after	O
a	O
few	O
hundred	O
characters	O
.	O
	
For	O
Spanish	O
this	O
advantage	O
continued	O
to	O
grow	O
as	O
more	O
of	O
the	O
sequence	O
was	O
processed	O
,	O
whereas	O
for	O
Hutter	B-Material
,	O
this	O
advantage	O
was	O
maximized	O
after	O
viewing	O
around	O
2	O
-	O
3k	O
characters	O
.	O
	
The	O
advantage	O
of	O
dynamic	B-Metric
evaluation	I-Metric
was	O
also	O
much	O
greater	O
on	O
Spanish	B-Material
sequences	I-Material
than	O
Hutter	B-Material
sequences	O
.	O
	
We	O
also	O
drew	O
300	O
character	B-Task
conditional	O
samples	O
from	O
the	O
static	B-Metric
and	O
dynamic	O
versions	O
of	O
our	O
model	O
after	O
viewing	O
10k	O
characters	O
of	O
Spanish	B-Material
.	O
	
For	O
the	O
dynamic	B-Method
model	I-Method
,	O
we	O
continued	O
to	O
apply	O
dynamic	B-Metric
evaluation	I-Metric
during	O
sampling	B-Task
as	O
well	O
,	O
by	O
the	O
process	O
described	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
The	O
conditional	O
samples	O
are	O
given	O
in	O
the	O
appendix	O
.	O
	
The	O
static	B-Metric
samples	O
quickly	O
switched	O
to	O
English	B-Material
that	O
resembled	O
Hutter	B-Material
Prize	O
data	O
.	O
	
The	O
dynamic	B-Method
model	I-Method
generated	O
data	O
with	O
some	O
Spanish	B-Material
words	I-Material
and	O
a	O
number	O
of	O
made	O
up	O
words	O
with	O
characteristics	O
of	O
Spanish	O
words	O
for	O
the	O
entirety	O
of	O
the	O
sample	O
.	O
	
This	O
is	O
an	O
example	O
of	O
the	O
kinds	O
of	O
features	O
that	O
dynamic	B-Metric
evaluation	I-Metric
was	O
able	O
to	O
learn	O
to	O
model	O
on	O
the	O
fly	O
.	O
	
section	O
:	O
Conclusion	O
	
This	O
work	O
explores	O
and	O
develops	O
methodology	O
for	O
applying	O
dynamic	B-Metric
evaluation	I-Metric
to	O
sequence	B-Task
modelling	I-Task
tasks	I-Task
.	O
	
Experiments	O
show	O
that	O
the	O
proposed	O
dynamic	B-Metric
evaluation	I-Metric
methodology	O
gives	O
large	O
test	B-Metric
time	I-Metric
improvements	O
across	O
character	B-Task
and	O
word	O
level	O
language	B-Task
modelling	I-Task
.	O
	
Our	O
improvements	O
to	O
language	B-Task
modelling	I-Task
have	O
applications	O
to	O
speech	B-Task
recognition	I-Task
and	O
machine	B-Task
translation	I-Task
over	O
longer	O
contexts	O
,	O
including	O
broadcast	B-Task
speech	I-Task
recognition	I-Task
and	O
paragraph	B-Task
level	I-Task
machine	I-Task
translation	I-Task
.	O
	
Overall	O
,	O
dynamic	B-Metric
evaluation	I-Metric
is	O
shown	O
to	O
be	O
an	O
effective	O
method	O
for	O
exploiting	O
pattern	B-Task
re	I-Task
-	I-Task
occurrence	I-Task
in	I-Task
sequences	I-Task
.	O
	
plus	O
0.3ex	O
	
bibliography	O
:	O
References	O
	
appendix	O
:	O
Appendix	O
	
subsection	O
:	O
Dynamic	O
samples	O
conditioned	O
on	O
Spanish	B-Material
	
300	O
character	B-Task
samples	O
generated	O
from	O
the	O
dynamic	B-Method
version	I-Method
of	O
the	O
model	O
trained	O
on	O
Hutter	B-Material
Prize	I-Material
,	O
conditioned	O
on	O
10k	O
of	O
Spanish	B-Material
characters	I-Material
.	O
	
The	O
final	O
sentence	O
fragment	O
of	O
the	O
10k	O
conditioning	O
characters	O
is	O
given	O
to	O
the	O
reader	O
,	O
with	O
the	O
generated	O
text	O
given	O
in	O
bold	O
:	O
	
Tiene	O
importancia	O
este	O
compromiso	O
	
en	O
la	O
medida	O
en	O
que	O
	
la	O
Comisión	O
	
es	O
un	O
organismo	O
que	O
tiene	O
el	O
montembre	O
tas	O
procedíns	O
la	O
conscriptione	O
se	O
ha	O
Tesalo	O
	
del	O
Pómienda	O
que	O
	
et	O
hanemos	O
que	O
	
Pe	O
la	O
Siemina	O
.	O
	
De	O
la	O
Pedrera	O
Orden	O
	
es	O
Señora	O
Presidente	O
civil	O
,	O
Orden	O
de	O
siemin	O
presente	O
relevante	O
frónmida	O
que	O
esculdad	O
pludiore	O
e	O
formidad	O
President	O
de	O
la	O
Presidenta	O
Antidorne	O
Adamirmidad	O
	
i	O
ciemano	O
de	O
el	O
200	O
’	O
.	O
	
Fo	O
	
subsection	O
:	O
Static	B-Material
samples	I-Material
conditioned	O
on	O
Spanish	B-Material
	
300	O
character	B-Task
samples	O
generated	O
from	O
the	O
static	B-Metric
version	O
of	O
the	O
model	O
trained	O
on	O
Hutter	B-Material
Prize	I-Material
,	O
conditioned	O
on	O
10k	O
of	O
Spanish	B-Material
characters	I-Material
.	O
	
The	O
final	O
sentence	O
fragment	O
of	O
the	O
10k	O
conditioning	O
characters	O
is	O
given	O
to	O
the	O
reader	O
,	O
with	O
the	O
generated	O
text	O
given	O
in	O
bold	O
:	O
	
Tiene	O
importancia	O
este	O
compromiso	O
	
en	O
la	O
medida	O
en	O
que	O
	
la	O
Comisión	O
	
es	O
un	O
organismo	O
que	O
tiene	O
	
el	O
monde	O
,	O
&	O
lt;br	O
&	O
gt;There	O
	
is	O
a	O
secret	O
act	O
in	O
the	O
world	O
except	O
Cape	O
Town	O
,	O
seen	O
in	O
now	O
flat	O
comalo	O
and	O
ball	O
market	O
and	O
has	O
seen	O
the	O
closure	O
of	O
the	O
eagle	O
as	O
imprints	O
in	O
a	O
dallas	O
within	O
the	O
country.	O
&	O
quot	O
;	O
Is	O
a	O
topic	O
for	O
an	O
increasingly	O
small	O
contract	O
saying	O
Allan	O
Roth	O
acquired	O
the	O
government	O
in	O
[	O
[	O
1916	O
]]	O
.	O
=	O
=	O
=	O
	
document	O
:	O
Squeezed	B-Method
Very	I-Method
Deep	I-Method
Convolutional	I-Method
Neural	I-Method
Networks	I-Method
for	O
Text	B-Task
Classification	I-Task
	
Most	O
of	O
the	O
research	O
in	O
convolutional	B-Method
neural	I-Method
networks	I-Method
has	O
focused	O
on	O
increasing	O
network	O
depth	O
to	O
improve	O
accuracy	B-Metric
,	O
resulting	O
in	O
a	O
massive	O
number	O
of	O
parameters	O
which	O
restricts	O
the	O
trained	O
network	O
to	O
platforms	O
with	O
memory	O
and	O
processing	O
constraints	O
.	O
	
We	O
propose	O
to	O
modify	O
the	O
structure	O
of	O
the	O
Very	B-Method
Deep	I-Method
Convolutional	I-Method
Neural	I-Method
Networks	I-Method
(	O
VDCNN	B-Method
)	O
model	O
to	O
fit	O
mobile	O
platforms	O
constraints	O
and	O
keep	O
performance	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
evaluate	O
the	O
impact	O
of	O
Temporal	B-Method
Depthwise	I-Method
Separable	I-Method
Convolutions	I-Method
and	O
Global	B-Method
Average	I-Method
Pooling	I-Method
in	O
the	O
network	O
parameters	O
,	O
storage	B-Metric
size	I-Metric
,	O
and	O
latency	B-Metric
.	O
	
The	O
squeezed	B-Method
model	I-Method
(	O
SVDCNN	B-Method
)	O
is	O
between	O
10x	O
and	O
20x	O
smaller	O
,	O
depending	O
on	O
the	O
network	O
depth	O
,	O
maintaining	O
a	O
maximum	O
size	O
of	O
6	O
MB	O
.	O
	
Regarding	O
accuracy	B-Metric
,	O
the	O
network	O
experiences	O
a	O
loss	O
between	O
0.4	O
%	O
and	O
1.3	O
%	O
and	O
obtains	O
lower	O
latencies	B-Metric
compared	O
to	O
the	O
baseline	O
model	O
.	O
	
section	O
:	O
Introduction	O
	
The	O
general	O
trend	O
in	O
deep	B-Method
learning	I-Method
approaches	I-Method
has	O
been	O
developing	O
models	O
with	O
increasing	O
layers	O
.	O
	
Deeper	B-Method
neural	I-Method
networks	I-Method
have	O
achieved	O
high	O
-	O
quality	O
results	O
in	O
different	O
tasks	O
such	O
as	O
image	B-Task
classification	I-Task
,	O
detection	B-Task
,	O
and	O
segmentation	B-Task
.	O
	
Deep	B-Method
models	I-Method
can	O
also	O
learn	O
hierarchical	B-Method
feature	I-Method
representations	I-Method
from	O
images	O
.	O
	
In	O
the	O
Natural	B-Task
Language	I-Task
Processing	I-Task
(	O
NLP	B-Task
)	O
field	O
,	O
the	O
belief	O
that	O
compositional	B-Method
models	I-Method
can	O
also	O
be	O
used	O
to	O
text	B-Task
-	I-Task
related	I-Task
tasks	I-Task
is	O
more	O
recent	O
.	O
	
The	O
increasing	O
availability	O
of	O
text	O
data	O
motivates	O
research	O
for	O
models	O
able	O
to	O
improve	O
accuracy	B-Metric
in	O
different	O
language	B-Task
tasks	I-Task
.	O
	
Following	O
the	O
image	O
classification	O
Convolutional	B-Method
Neural	I-Method
Network	I-Method
(	O
CNN	B-Method
)	O
tendency	O
,	O
the	O
research	O
in	O
text	B-Task
classification	I-Task
has	O
placed	O
effort	O
into	O
developing	O
deeper	B-Method
networks	I-Method
.	O
	
The	O
first	O
CNN	B-Method
based	O
approach	O
for	O
text	O
was	O
a	O
shallow	B-Method
network	I-Method
with	O
one	O
layer	O
.	O
	
Following	O
this	O
work	O
,	O
deeper	O
architectures	O
were	O
proposed	O
.	O
	
Conneau	O
et	O
al	O
.	O
were	O
the	O
first	O
to	O
propose	O
Very	B-Method
Deep	I-Method
Convolutional	I-Method
Neural	I-Method
Networks	I-Method
(	O
VDCNN	B-Method
)	I-Method
applied	O
to	O
text	B-Task
classification	I-Task
.	O
	
VDCNN	B-Method
accuracy	O
increases	O
with	O
depth	O
.	O
	
The	O
approach	O
with	O
29	O
layers	O
is	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
accuracy	B-Metric
of	O
CNNs	B-Method
for	O
text	B-Task
classification	I-Task
.	O
	
However	O
,	O
regardless	O
of	O
making	O
networks	O
deeper	O
to	O
improve	O
accuracy	B-Metric
,	O
little	O
effort	O
has	O
been	O
made	O
to	O
build	O
text	B-Method
classification	I-Method
models	I-Method
to	O
constrained	O
resources	O
.	O
	
It	O
is	O
a	O
very	O
different	O
scenario	O
compared	O
to	O
image	B-Method
approaches	I-Method
,	O
where	O
size	B-Method
and	I-Method
speed	I-Method
constrained	I-Method
models	I-Method
have	O
been	O
proposed	O
.	O
	
In	O
real	B-Task
-	I-Task
world	I-Task
applications	I-Task
,	O
size	O
and	O
speed	B-Metric
are	O
constraints	O
to	O
an	O
efficient	O
mobile	B-Task
and	I-Task
embedded	I-Task
deployment	I-Task
of	I-Task
deep	I-Task
models	I-Task
.	O
	
Several	O
relevant	O
real	B-Task
-	I-Task
world	I-Task
applications	I-Task
depend	O
on	O
text	B-Task
classification	I-Task
tasks	I-Task
such	O
as	O
sentiment	B-Task
analysis	I-Task
,	O
recommendation	B-Task
and	O
opinion	B-Task
mining	I-Task
.	O
	
The	O
appeal	O
for	O
these	O
applications	O
combined	O
with	O
the	O
boost	O
in	O
mobile	B-Task
devices	I-Task
usage	I-Task
motivates	O
the	O
need	O
for	O
research	O
in	O
restrained	B-Method
text	I-Method
classification	I-Method
models	I-Method
.	O
	
Concerning	O
mobile	B-Task
development	I-Task
,	O
there	O
are	O
numerous	O
benefits	O
to	O
developing	O
smaller	B-Method
models	I-Method
.	O
	
Some	O
of	O
the	O
most	O
relevant	O
are	O
requiring	O
fewer	O
data	B-Task
transferring	I-Task
while	O
updating	O
the	O
client	B-Method
model	I-Method
and	O
increasing	O
usability	O
by	O
diminishing	O
the	O
inference	B-Metric
time	I-Metric
.	O
	
Such	O
advantages	O
would	O
boost	O
the	O
usage	O
of	O
deep	B-Method
neural	I-Method
models	I-Method
in	O
text	B-Task
-	I-Task
based	I-Task
applications	I-Task
for	O
embedded	B-Task
platforms	I-Task
.	O
	
In	O
this	O
paper	O
,	O
we	O
investigate	O
modifications	O
on	O
the	O
network	O
proposed	O
by	O
Conneau	O
et	O
al	O
.	O
	
with	O
the	O
aim	O
of	O
reducing	O
its	O
number	O
of	O
parameters	O
,	O
storage	B-Metric
size	I-Metric
and	O
latency	B-Metric
with	O
minimal	O
performance	O
degradation	O
.	O
	
To	O
achieve	O
these	O
improvements	O
we	O
used	O
Temporal	B-Method
Depthwise	I-Method
Separable	I-Method
Convolution	I-Method
and	O
Global	B-Method
Average	I-Method
Pooling	I-Method
techniques	I-Method
.	O
	
Therefore	O
,	O
our	O
main	O
contribution	O
is	O
to	O
propose	O
the	O
Squeezed	B-Method
Very	I-Method
Deep	I-Method
Convolutional	I-Method
Neural	I-Method
Networks	I-Method
(	O
SVDCNN	B-Method
)	O
,	O
a	O
text	B-Method
classification	I-Method
model	I-Method
which	O
requires	O
significantly	O
fewer	O
parameters	O
compared	O
to	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
CNNs	B-Method
.	O
	
Section	O
II	O
provides	O
an	O
overview	O
of	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
in	O
CNNs	B-Method
for	O
text	B-Task
classification	I-Task
.	O
	
Section	O
III	O
presents	O
the	O
VDCNN	B-Method
model	I-Method
.	O
	
Section	O
IV	O
explains	O
the	O
proposed	O
model	O
SVDCNN	B-Method
and	O
the	O
subsequent	O
impact	O
in	O
the	O
total	O
number	O
of	O
parameters	O
of	O
the	O
network	O
.	O
	
Section	O
V	O
details	O
how	O
we	O
perform	O
experiments	O
.	O
	
Section	O
VI	O
analyses	O
the	O
results	O
and	O
lastly	O
,	O
Section	O
VII	O
,	O
presents	O
conclusions	O
and	O
direction	O
for	O
future	O
works	O
.	O
	
section	O
:	O
Related	O
Work	O
	
CNNs	B-Method
were	O
originally	O
designed	O
for	O
Computer	B-Task
Vision	I-Task
with	O
the	O
aim	O
of	O
considering	O
feature	B-Task
extraction	I-Task
and	O
classification	B-Task
as	O
one	O
task	O
.	O
	
Although	O
CNNs	B-Method
are	O
very	O
successful	O
in	O
image	B-Task
classification	I-Task
tasks	I-Task
,	O
its	O
use	O
in	O
text	B-Task
classification	I-Task
is	O
relatively	O
new	O
and	O
has	O
some	O
peculiarities	O
.	O
	
Contrasting	O
with	O
traditional	O
image	B-Method
bi	I-Method
-	I-Method
dimensional	I-Method
representations	I-Method
,	O
texts	O
are	O
one	O
-	O
dimensionally	O
represented	O
.	O
	
Due	O
to	O
this	O
property	O
,	O
the	O
convolutions	B-Method
are	O
designed	O
as	O
temporal	B-Method
convolutions	I-Method
.	O
	
Furthermore	O
,	O
it	O
is	O
necessary	O
to	O
generate	O
a	O
numerical	B-Method
representation	I-Method
from	O
the	O
text	O
so	O
the	O
network	O
can	O
be	O
trained	O
using	O
this	O
representation	O
.	O
	
This	O
representation	O
,	O
namely	O
embeddings	O
,	O
is	O
usually	O
obtained	O
through	O
the	O
application	O
of	O
a	O
lookup	O
table	O
,	O
generated	O
from	O
a	O
given	O
dictionary	O
.	O
	
An	O
early	O
approach	O
for	O
text	B-Task
classification	I-Task
tasks	I-Task
consisted	O
of	O
a	O
shallow	B-Method
neural	I-Method
network	I-Method
working	O
on	O
the	O
word	O
level	O
and	O
using	O
only	O
one	O
convolutional	B-Method
layer	I-Method
.	O
	
The	O
author	O
reported	O
results	O
in	O
smaller	O
datasets	O
.	O
	
Later	O
,	O
Zhang	O
et	O
al	O
.	O
proposed	O
the	O
first	O
CNN	B-Method
performing	O
on	O
a	O
character	O
level	O
(	O
Char	B-Method
-	I-Method
CNN	I-Method
)	O
,	O
which	O
allowed	O
them	O
to	O
train	O
up	O
to	O
6	O
convolutional	B-Method
layers	I-Method
,	O
followed	O
by	O
three	O
fully	B-Method
connected	I-Method
classification	O
layers	O
.	O
	
Char	B-Method
-	I-Method
CNN	I-Method
uses	O
convolutional	B-Method
kernels	I-Method
of	O
size	O
3	O
and	O
7	O
,	O
as	O
well	O
as	O
simple	O
max	B-Method
-	I-Method
pooling	I-Method
layers	I-Method
.	O
	
Conneau	O
et	O
al	O
.	O
	
(	O
2016	O
)	O
proposed	O
the	O
Very	O
Deep	O
CNN	B-Method
(	O
VDCNN	B-Method
)	O
also	O
on	O
a	O
character	O
level	O
,	O
presenting	O
improvements	O
compared	O
to	O
Char	B-Method
-	I-Method
CNN	I-Method
.	O
	
Conneau	O
et	O
al	O
.	O
	
(	O
2016	O
)	O
have	O
shown	O
that	O
text	B-Metric
classification	I-Metric
accuracy	I-Metric
increases	O
when	O
the	O
proposed	O
model	O
becomes	O
deeper	O
.	O
	
VDCNN	B-Method
uses	O
only	O
small	O
kernel	B-Method
convolutions	I-Method
and	O
pooling	B-Method
operations	I-Method
.	O
	
The	O
proposed	O
architecture	O
relies	O
on	O
the	O
VGG	B-Method
and	I-Method
ResNet	I-Method
philosophy	I-Method
:	O
The	O
number	O
of	O
feature	O
maps	O
and	O
the	O
temporal	O
resolution	O
is	O
modeled	O
so	O
that	O
their	O
product	O
is	O
constant	O
.	O
	
This	O
approach	O
makes	O
it	O
easier	O
to	O
control	O
the	O
memory	O
footprint	O
of	O
the	O
network	O
.	O
	
Both	O
Zhang	O
and	O
Conneau	O
et	O
al	O
.	O
	
CNNs	B-Method
utilized	O
standard	O
convolutional	B-Method
blocks	I-Method
and	O
fully	B-Method
connected	I-Method
layers	O
to	O
combine	O
convolution	O
information	O
.	O
	
This	O
architecture	O
choice	O
increases	O
the	O
number	O
of	O
parameters	O
and	O
storage	B-Metric
size	I-Metric
of	O
the	O
models	O
.	O
	
However	O
,	O
size	O
and	O
speed	O
was	O
not	O
the	O
focus	O
of	O
those	O
works	O
.	O
	
The	O
idea	O
of	O
developing	O
smaller	O
and	O
more	O
efficient	O
CNNs	B-Method
without	O
losing	O
representative	B-Metric
accuracy	I-Metric
is	O
a	O
less	O
explored	O
research	O
direction	O
in	O
NLP	B-Task
,	O
but	O
it	O
has	O
already	O
been	O
a	O
trend	O
for	O
computer	B-Task
vision	I-Task
applications	I-Task
.	O
	
Most	O
approaches	O
consist	O
in	O
compressing	O
pre	B-Method
-	I-Method
trained	I-Method
networks	I-Method
or	O
training	O
small	B-Method
networks	I-Method
directly	O
.	O
	
A	O
recent	O
tendency	O
in	O
deep	B-Method
models	I-Method
is	O
replacing	O
standard	O
convolutional	B-Method
blocks	I-Method
with	O
Depthwise	B-Method
Separable	I-Method
Convolutions	I-Method
(	O
DSCs	B-Method
)	O
.	O
	
The	O
purpose	O
is	O
to	O
reduce	O
the	O
number	O
of	O
parameters	O
and	O
consequently	O
the	O
model	O
size	O
.	O
	
DSCs	B-Method
were	O
initially	O
introduced	O
in	O
and	O
since	O
then	O
have	O
been	O
successfully	O
applied	O
to	O
image	B-Task
classification	I-Task
and	O
machine	B-Task
translation	I-Task
to	O
reduce	O
the	O
computation	B-Task
in	O
convolutional	O
blocks	O
.	O
	
Another	O
approach	O
is	O
the	O
use	O
of	O
a	O
Global	B-Method
Average	I-Method
Pooling	I-Method
(	I-Method
GAP	I-Method
)	I-Method
layer	I-Method
at	O
the	O
output	O
of	O
the	O
network	O
to	O
replace	O
fully	B-Method
connected	I-Method
layers	O
.	O
	
This	O
approach	O
has	O
become	O
a	O
standard	O
architectural	O
decision	O
for	O
newer	O
CNNs	B-Method
.	O
	
section	O
:	O
VDCNN	B-Method
Model	I-Method
for	O
Text	B-Task
Classification	I-Task
	
The	O
VDCNN	B-Method
is	O
a	O
modular	B-Method
architecture	I-Method
for	O
text	B-Task
classification	I-Task
tasks	I-Task
developed	O
to	O
offer	O
different	O
depth	O
levels	O
(	O
9	O
,	O
17	O
,	O
29	O
and	O
49	O
)	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
presents	O
the	O
architecture	O
for	O
depth	B-Task
9	I-Task
.	O
	
The	O
network	O
begins	O
with	O
a	O
lookup	O
table	O
,	O
which	O
generates	O
the	O
embeddings	O
for	O
the	O
input	O
text	O
and	O
stores	O
them	O
in	O
a	O
2D	O
tensor	O
of	O
size	O
.	O
	
The	O
number	O
of	O
input	O
characters	O
is	O
fixed	O
to	O
1	O
,	O
024	O
while	O
the	O
embedding	O
dimension	O
is	O
16	O
.	O
	
The	O
embedding	B-Metric
dimension	I-Metric
can	O
be	O
seen	O
as	O
the	O
number	O
of	O
RGB	O
channels	O
of	O
an	O
image	O
.	O
	
The	O
following	O
layer	O
(	O
3	O
,	O
Temp	O
Convolution	O
,	O
64	O
)	O
applies	O
64	O
temporal	B-Method
convolutions	I-Method
of	O
kernel	O
size	O
3	O
,	O
so	O
the	O
output	O
tensor	O
has	O
size	O
.	O
	
Its	O
primary	O
function	O
is	O
to	O
fit	O
the	O
lookup	O
table	O
output	O
with	O
the	O
modular	B-Method
network	I-Method
segment	I-Method
input	I-Method
composed	O
by	O
convolutional	B-Method
blocks	I-Method
.	O
	
Each	O
aforenamed	O
block	O
is	O
a	O
sequence	O
of	O
two	O
temporal	B-Method
convolutional	I-Method
layers	I-Method
,	O
each	O
one	O
accompanied	O
by	O
a	O
temporal	B-Method
batch	I-Method
normalization	I-Method
layer	I-Method
and	O
a	O
ReLU	B-Method
activation	I-Method
.	O
	
Besides	O
,	O
the	O
different	O
network	O
depths	O
are	O
obtained	O
varying	O
the	O
number	O
of	O
convolutional	O
blocks	O
.	O
	
As	O
a	O
convention	O
,	O
the	O
depth	O
of	O
a	O
network	O
is	O
given	O
as	O
its	O
total	O
number	O
of	O
convolutions	O
.	O
	
For	O
instance	O
,	O
the	O
architecture	O
of	O
depth	O
17	O
has	O
two	O
convolutional	O
blocks	O
of	O
each	O
level	O
of	O
feature	O
maps	O
,	O
which	O
results	O
in	O
4	O
convolutional	O
layers	O
for	O
each	O
level	O
(	O
see	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
Considering	O
the	O
first	O
convolutional	B-Method
layer	I-Method
of	O
the	O
network	O
,	O
we	O
obtain	O
the	O
depth	O
.	O
	
The	O
different	O
depth	B-Method
architectures	I-Method
provided	O
by	O
VDCNN	B-Method
model	I-Method
are	O
summarized	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
The	O
following	O
rule	O
is	O
employed	O
to	O
minimize	O
the	O
network	O
’s	O
memory	O
footprint	O
:	O
Before	O
each	O
convolutional	B-Method
block	I-Method
doubling	O
the	O
number	O
of	O
feature	O
maps	O
,	O
a	O
pooling	B-Method
layer	I-Method
halves	O
the	O
temporal	O
dimension	O
.	O
	
This	O
strategy	O
is	O
inspired	O
by	O
the	O
VGG	B-Method
and	I-Method
ResNets	I-Method
philosophy	I-Method
and	O
results	O
in	O
three	O
levels	O
of	O
feature	O
maps	O
:	O
128	O
,	O
256	O
and	O
512	O
(	O
see	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
Additionally	O
,	O
the	O
VDCNN	B-Method
network	I-Method
also	O
contains	O
shortcut	O
connections	O
for	O
each	O
convolutional	B-Method
blocks	I-Method
implemented	O
through	O
the	O
usage	O
of	O
convolutions	B-Method
.	O
	
Lastly	O
,	O
for	O
the	O
classification	B-Task
task	I-Task
,	O
the	O
most	O
valuable	O
features	O
are	O
extracted	O
using	O
-	B-Method
max	I-Method
pooling	I-Method
,	O
generating	O
a	O
one	O
-	O
dimensional	O
vector	O
which	O
supplies	O
three	O
fully	B-Method
connected	I-Method
layers	O
with	O
ReLU	O
hidden	O
units	O
and	O
softmax	O
outputs	O
.	O
	
The	O
number	O
of	O
hidden	O
units	O
is	O
2	O
,	O
048	O
,	O
and	O
they	O
do	O
not	O
use	O
dropout	B-Method
but	O
rather	O
batch	B-Method
normalization	I-Method
after	O
convolutional	B-Method
layers	I-Method
perform	O
the	O
network	B-Method
regularization	I-Method
.	O
	
section	O
:	O
SVDCNN	B-Method
Model	I-Method
for	O
Text	B-Task
Classification	I-Task
	
The	O
primary	O
objective	O
is	O
reducing	O
the	O
number	O
of	O
parameters	O
so	O
that	O
the	O
resulting	O
network	O
has	O
a	O
significative	O
lower	O
storage	B-Metric
size	I-Metric
.	O
	
We	O
first	O
propose	O
to	O
modify	O
the	O
convolutional	B-Method
blocks	I-Method
of	I-Method
VDCNN	I-Method
model	I-Method
by	O
the	O
usage	O
of	O
Temporal	B-Method
Depthwise	I-Method
Separable	I-Method
Convolutions	I-Method
(	O
TDSCs	B-Method
)	O
.	O
	
Next	O
,	O
we	O
reduce	O
the	O
number	O
of	O
fully	B-Method
connected	I-Method
layers	O
using	O
the	O
Global	B-Method
Average	I-Method
Pooling	I-Method
(	I-Method
GAP	I-Method
)	I-Method
technique	I-Method
.	O
	
The	O
resulting	O
proposed	O
architecture	O
is	O
called	O
Squeezed	B-Method
Very	I-Method
Deep	I-Method
Convolutional	I-Method
Neural	I-Method
Networks	I-Method
(	O
SVDCNN	B-Method
)	O
.	O
	
paragraph	O
:	O
Temporal	B-Method
Depthwise	I-Method
Separable	I-Method
Convolutions	I-Method
(	O
TDSCs	B-Method
)	O
	
The	O
use	O
of	O
TDSCs	B-Method
over	O
standard	O
convolutions	B-Method
allowed	O
reducing	O
the	O
number	O
of	O
parameters	O
without	O
relevant	O
accuracy	B-Metric
loss	I-Metric
.	O
	
TDSCs	B-Method
work	O
decompounding	O
the	O
standard	O
convolution	B-Method
into	O
two	O
parts	O
:	O
Depthwise	O
and	O
Pointwise	O
.	O
	
The	O
first	O
one	O
is	O
responsible	O
for	O
applying	O
a	O
convolutional	B-Method
filter	I-Method
to	O
each	O
channel	O
of	O
the	O
input	O
at	O
a	O
time	O
.	O
	
For	O
an	O
image	O
input	O
,	O
one	O
possibility	O
of	O
channels	O
are	O
the	O
RGB	O
components	O
,	O
whereas	O
in	O
a	O
text	O
input	O
the	O
dimensions	O
of	O
the	O
embedding	O
can	O
be	O
used	O
instead	O
.	O
	
For	O
both	O
cases	O
mentioned	O
above	O
,	O
the	O
result	O
is	O
one	O
feature	O
map	O
by	O
channel	O
.	O
	
The	O
second	O
convolution	O
unifies	O
the	O
generated	O
feature	O
maps	O
successively	O
applying	O
1x1	O
convolutions	B-Method
so	O
that	O
the	O
target	O
amount	O
of	O
feature	O
maps	O
can	O
be	O
achieved	O
.	O
	
[	O
]	O
[	O
]	O
TDSCs	B-Method
are	O
DSCs	B-Method
which	O
work	O
with	O
one	B-Method
-	I-Method
dimensional	I-Method
convolutions	I-Method
.	O
	
Although	O
DSCs	B-Method
hold	O
verified	O
results	O
in	O
image	B-Task
classification	I-Task
networks	I-Task
,	O
the	O
usage	O
of	O
its	O
temporal	B-Method
version	I-Method
for	O
text	B-Task
related	I-Task
tasks	I-Task
is	O
less	O
explored	O
.	O
	
Fig	O
.	O
	
2a	O
presents	O
the	O
architecture	O
of	O
a	O
temporal	B-Method
standard	I-Method
convolution	I-Method
while	O
Fig	O
.	O
	
2b	O
presents	O
the	O
TDSC	B-Method
.	O
	
For	O
a	O
more	O
formal	O
definition	O
,	O
let	O
be	O
the	O
number	O
of	O
parameters	O
of	O
a	O
temporal	B-Method
standard	I-Method
convolution	I-Method
,	O
where	O
In	O
and	O
Out	O
are	O
the	O
numbers	O
of	O
Input	O
and	O
Output	O
channels	O
respectively	O
,	O
and	O
is	O
the	O
kernel	O
size	O
:	O
Alternatively	O
,	O
a	O
TDSC	B-Method
achieves	O
fewer	O
parameters	O
(	O
)	O
:	O
	
In	O
the	O
VDCNN	B-Method
model	I-Method
,	O
one	O
convolutional	B-Method
block	I-Method
is	O
composed	O
of	O
two	O
temporal	B-Method
standard	I-Method
convolutional	I-Method
layers	I-Method
.	O
	
The	O
first	O
one	O
doubles	O
the	O
number	O
of	O
feature	O
maps	O
while	O
the	O
second	O
keeps	O
the	O
same	O
value	O
received	O
as	O
input	O
.	O
	
Besides	O
,	O
each	O
convolutional	B-Method
layer	I-Method
is	O
followed	O
by	O
a	O
Batch	B-Method
Normalization	I-Method
and	O
a	O
ReLU	B-Method
layers	I-Method
.	O
	
In	O
our	O
model	O
,	O
we	O
proposed	O
changing	O
the	O
temporal	B-Method
standard	I-Method
convolutions	I-Method
by	O
TDSCs	B-Method
.	O
	
[	O
]	O
	
[	O
]	O
Fig	O
.	O
3	O
presents	O
the	O
standard	O
convolutional	B-Method
block	I-Method
on	O
the	O
left	O
and	O
the	O
proposed	O
convolutional	B-Method
block	I-Method
using	O
TDSC	B-Method
on	O
the	O
right	O
.	O
	
The	O
pattern	O
used	O
in	O
the	O
figure	O
for	O
the	O
convolutional	B-Method
layers	I-Method
is	O
the	O
following	O
:	O
”	O
Kernel	O
Size	O
,	O
Conv	O
type	O
,	O
Output	O
Feature	O
Maps	O
”	O
;	O
as	O
a	O
brief	O
example	O
consider	O
”	O
3x1	O
,	O
Temporal	O
Conv	O
,	O
256	O
”	O
,	O
which	O
means	O
a	O
Temporal	B-Method
Convolution	I-Method
with	O
kernel	O
size	O
3	O
and	O
256	O
feature	O
maps	O
as	O
output	O
.	O
	
From	O
Equation	O
1	O
,	O
we	O
have	O
the	O
number	O
of	O
parameters	O
of	O
the	O
original	O
convolutional	O
block	O
(	O
)	O
as	O
follows	O
:	O
	
Moreover	O
,	O
from	O
equation	O
2	O
,	O
the	O
number	O
of	O
parameters	O
of	O
the	O
proposed	O
convolutional	B-Method
block	I-Method
(	O
)	O
that	O
uses	O
TDSC	B-Method
being	O
:	O
For	O
illustration	O
,	O
following	O
the	O
same	O
characteristics	O
of	O
Fig	O
.	O
3	O
,	O
consider	O
that	O
the	O
number	O
of	O
input	O
channels	O
	
In	O
is	O
equal	O
to	O
128	O
and	O
the	O
number	O
of	O
output	O
channels	O
Out	O
is	O
equal	O
to	O
256	O
.	O
	
Our	O
proposed	O
approach	O
accumulates	O
a	O
total	O
of	O
99	O
,	O
456	O
parameters	O
.	O
	
In	O
contrast	O
,	O
there	O
are	O
294	O
,	O
912	O
parameters	O
in	O
the	O
original	O
convolutional	O
block	O
.	O
	
The	O
use	O
of	O
TDSC	B-Method
yields	O
a	O
reduction	O
of	O
66.28	O
%	O
in	O
the	O
network	B-Metric
size	I-Metric
.	O
	
Lastly	O
,	O
since	O
each	O
standard	O
temporal	B-Method
convolution	I-Method
turns	O
into	O
two	O
(	O
Depthwise	O
and	O
Pointwise	O
)	O
,	O
the	O
number	O
of	O
convolutions	B-Method
per	O
convolutional	B-Method
block	I-Method
has	O
doubled	O
.	O
	
Nevertheless	O
,	O
these	O
two	O
convolutions	O
work	O
as	O
one	O
because	O
it	O
is	O
not	O
possible	O
to	O
use	O
them	O
separately	O
keeping	O
the	O
same	O
propose	O
.	O
	
In	O
this	O
way	O
,	O
we	O
count	O
them	O
as	O
one	O
layer	O
in	O
the	O
network	O
depth	O
.	O
	
This	O
decision	O
holds	O
the	O
provided	O
depth	O
architectures	O
the	O
same	O
as	O
the	O
VDCNN	B-Method
model	I-Method
summarized	O
in	O
Table	O
[	O
reference	O
]	O
,	O
contributing	O
to	O
a	O
proper	O
comparison	O
between	O
the	O
models	O
.	O
	
paragraph	O
:	O
Global	B-Method
Average	I-Method
Pooling	I-Method
(	O
GAP	B-Method
)	O
	
The	O
VDCNN	B-Method
model	I-Method
uses	O
a	O
-	B-Method
max	I-Method
pooling	I-Method
layer	I-Method
followed	O
by	O
three	O
fully	B-Method
connected	I-Method
(	O
FC	B-Method
)	O
layers	O
to	O
perform	O
the	O
classification	B-Task
task	I-Task
(	O
Fig	O
.	O
4a	O
)	O
.	O
	
Although	O
this	O
approach	O
is	O
the	O
traditional	O
architecture	O
choice	O
for	O
text	B-Task
classification	I-Task
CNNs	I-Task
,	O
it	O
introduces	O
a	O
significant	O
number	O
of	O
parameter	O
in	O
the	O
network	O
.	O
	
The	O
resulting	O
number	O
of	O
the	O
FC	B-Method
layers	O
parameters	O
(	O
)	O
aforementioned	O
is	O
presented	O
below	O
,	O
for	O
a	O
problem	O
with	O
four	O
target	O
classes	O
:	O
[	O
]	O
[	O
]	O
Instead	O
of	O
maintaining	O
these	O
fully	B-Method
connected	I-Method
layers	O
,	O
we	O
directly	O
aggregate	O
the	O
output	O
of	O
the	O
last	O
convolutional	O
block	O
through	O
the	O
usage	O
of	O
an	O
average	B-Method
pooling	I-Method
layer	I-Method
.	O
	
This	O
method	O
,	O
known	O
as	O
Global	B-Method
Average	I-Method
Pooling	I-Method
,	O
contributes	O
substantially	O
to	O
the	O
parameters	B-Task
reduction	I-Task
without	O
degrading	O
the	O
network	B-Metric
accuracy	I-Metric
significantly	O
.	O
	
The	O
number	O
of	O
resulting	O
feature	O
maps	O
given	O
by	O
the	O
average	B-Method
pooling	I-Method
layer	I-Method
was	O
the	O
same	O
as	O
the	O
original	O
-	B-Method
max	I-Method
pooling	I-Method
layer	I-Method
.	O
	
Fig	O
.	O
	
4b	O
presents	O
this	O
proposed	O
modification	O
.	O
	
The	O
number	O
of	O
parameters	O
obtained	O
by	O
the	O
usage	O
of	O
GAP	B-Method
(	I-Method
)	O
is	O
revealed	O
as	O
follows	O
:	O
	
Our	O
proposed	O
approach	O
accumulates	O
a	O
total	O
of	O
16	O
,	O
384	O
parameters	O
.	O
	
In	O
contrast	O
,	O
there	O
are	O
12	O
,	O
591	O
,	O
104	O
parameters	O
in	O
the	O
original	O
classification	B-Method
method	I-Method
.	O
	
The	O
use	O
of	O
GAP	B-Method
yields	O
a	O
reduction	O
of	O
99.86	O
%	O
.	O
	
section	O
:	O
Experiments	O
	
The	O
experiment	O
goal	O
is	O
to	O
investigate	O
the	O
impact	O
of	O
modifying	O
the	O
convolutional	O
block	O
of	O
VDCNN	B-Method
to	O
TDSCs	B-Method
and	O
using	O
GAP	B-Method
instead	O
of	O
the	O
original	O
fully	B-Method
connected	I-Method
layers	O
.	O
	
We	O
evaluate	O
Char	B-Method
-	I-Method
CNN	I-Method
,	O
VDCNN	B-Method
,	O
and	O
SVDCNN	B-Method
according	O
to	O
the	O
number	O
of	O
parameters	O
,	O
storage	B-Metric
size	I-Metric
,	O
inference	B-Metric
time	I-Metric
and	O
accuracy	B-Metric
.	O
	
The	O
source	O
code	O
of	O
the	O
proposed	O
model	O
is	O
available	O
in	O
the	O
GitHub	O
repository	O
SVDCNN	B-Method
	
The	O
original	O
VDCNN	B-Method
paper	O
reported	O
the	O
number	O
of	O
parameters	O
of	O
the	O
convolutional	B-Method
layers	I-Method
,	O
in	O
which	O
we	O
reproduce	O
in	O
this	O
article	O
.	O
	
For	O
SVDCNN	B-Method
and	O
Char	B-Method
-	I-Method
CNN	I-Method
,	O
we	O
calculated	O
the	O
abovementioned	O
number	O
from	O
the	O
network	B-Method
architecture	I-Method
implemented	O
in	O
PyTorch	B-Method
.	O
	
As	O
for	O
the	O
FC	B-Method
layer	O
’s	O
parameters	O
,	O
the	O
number	O
is	O
obtained	O
as	O
the	O
summation	O
of	O
the	O
product	O
of	O
the	O
input	O
and	O
output	O
size	O
of	O
each	O
FC	B-Method
layer	O
for	O
each	O
CNN	B-Method
.	O
	
Considering	O
the	O
network	O
parameters	O
and	O
assuming	O
that	O
one	O
float	O
number	O
on	O
Cuda	O
environment	O
takes	O
4	O
bytes	O
,	O
we	O
can	O
calculate	O
the	O
network	O
storage	O
in	O
megabytes	O
,	O
for	O
all	O
the	O
models	O
,	O
as	O
follows	O
:	O
	
Regarding	O
the	O
inference	B-Metric
time	I-Metric
,	O
its	O
average	B-Metric
and	O
standard	B-Metric
deviation	I-Metric
were	O
calculated	O
as	O
the	O
time	O
to	O
predict	O
one	O
instance	O
of	O
the	O
AG	B-Material
’s	I-Material
News	I-Material
dataset	O
throughout	O
1	O
,	O
000	O
repetitions	O
.	O
	
The	O
SVDCNN	B-Method
experimental	O
settings	O
are	O
similar	O
to	O
the	O
original	O
VDCNN	B-Method
paper	O
,	O
using	O
the	O
same	O
dictionary	O
and	O
the	O
same	O
embedding	O
size	O
of	O
16	O
.	O
	
The	O
training	O
is	O
also	O
performed	O
with	O
SGD	B-Method
,	O
utilizing	O
size	O
batch	O
of	O
64	O
,	O
with	O
a	O
maximum	O
of	O
100	O
epochs	O
.	O
	
We	O
use	O
an	O
initial	O
learning	B-Metric
rate	I-Metric
of	O
0.01	O
,	O
a	O
momentum	O
of	O
0.9	O
and	O
a	O
weight	O
decay	O
of	O
0.001	O
.	O
	
All	O
the	O
experiments	O
were	O
performed	O
on	O
an	O
NVIDIA	B-Material
GTX	I-Material
1060	O
	
GPU	B-Method
+	O
Intel	O
Core	O
i7	O
4770s	O
CPU	O
.	O
	
The	O
model	O
’s	O
performance	O
is	O
evaluated	O
on	O
three	O
large	O
-	O
scale	O
public	O
datasets	O
also	O
used	O
by	O
Zhang	O
et	O
al	O
.	O
	
in	O
the	O
introduction	O
of	O
Char	O
-	O
CNN	B-Method
and	O
VDCNN	B-Method
models	O
.	O
	
Table	O
[	O
reference	O
]	O
presents	O
the	O
details	O
of	O
the	O
utilized	O
datasets	O
:	O
	
AG	B-Material
’s	I-Material
News	I-Material
,	O
Yelp	B-Material
Polarity	I-Material
and	O
Yelp	B-Material
Full	I-Material
.	O
	
section	O
:	O
Results	O
	
Table	O
[	O
reference	O
]	O
presents	O
the	O
number	O
of	O
parameters	O
,	O
storage	B-Metric
size	I-Metric
,	O
and	O
accuracy	B-Metric
for	O
the	O
SVDCNN	B-Method
,	O
VDCNN	B-Method
,	O
and	O
Char	B-Method
-	I-Method
CNN	I-Method
in	O
all	O
datasets	O
.	O
	
The	O
use	O
of	O
TDSCs	B-Method
promoted	O
a	O
significant	O
reduction	O
in	O
convolutional	B-Metric
parameters	I-Metric
compared	O
to	O
VDCNN	B-Method
.	O
	
For	O
the	O
most	O
in	B-Task
-	I-Task
depth	I-Task
network	I-Task
evaluated	O
,	O
which	O
contains	O
29	O
convolutional	O
layers	O
(	O
depth	O
29	O
)	O
,	O
the	O
number	O
of	O
parameters	O
of	O
these	O
convolutional	B-Method
layers	I-Method
had	O
a	O
reduction	O
of	O
66.08	O
%	O
,	O
from	O
4.6	O
to	O
1.56	O
million	O
parameters	O
.	O
	
This	O
quantity	O
is	O
slightly	O
larger	O
than	O
the	O
one	O
obtained	O
from	O
the	O
Char	B-Method
-	I-Method
CNN	I-Method
,	O
1.40	O
million	O
parameters	O
,	O
but	O
this	O
network	O
has	O
only	O
six	O
convolutional	B-Method
layers	I-Method
(	O
depth	O
6	O
)	O
.	O
	
The	O
network	B-Task
reduction	I-Task
obtained	O
by	O
the	O
GAP	B-Method
is	O
even	O
more	O
representative	O
since	O
both	O
compared	O
models	O
use	O
three	O
FC	B-Method
layers	O
for	O
their	O
classification	B-Task
tasks	I-Task
.	O
	
Considering	O
a	O
dataset	O
with	O
four	O
target	O
classes	O
,	O
and	O
comparing	O
SVDCNN	B-Method
with	O
VDCNN	B-Method
,	O
the	O
number	O
of	O
parameters	O
of	O
the	O
FC	B-Method
layers	O
has	O
passed	O
from	O
12.59	O
to	O
0.02	O
million	O
parameters	O
,	O
representing	O
a	O
reduction	O
of	O
99.84	O
%	O
.	O
	
Following	O
with	O
the	O
same	O
comparison	O
,	O
but	O
to	O
Char	B-Method
-	I-Method
CNN	I-Method
,	O
the	O
proposed	O
model	O
is	O
99.82	O
%	O
smaller	O
,	O
0.02	O
against	O
11.36	O
million	O
of	O
FC	B-Method
parameters	O
.	O
	
The	O
reduction	O
of	O
the	O
total	O
parameters	O
impacts	O
directly	O
on	O
the	O
storage	B-Task
size	I-Task
of	I-Task
the	I-Task
networks	I-Task
.	O
	
While	O
our	O
most	O
in	B-Method
-	I-Method
depth	I-Method
model	I-Method
(	O
29	O
)	O
occupies	O
only	O
6	O
MB	O
,	O
VDCNN	B-Method
with	O
the	O
same	O
depth	O
occupies	O
64.16	O
MB	O
of	O
storage	O
.	O
	
Likewise	O
,	O
Char	B-Method
-	I-Method
CNN	I-Method
(	O
which	O
has	O
depth	O
6	O
)	O
occupies	O
43.25	O
MB	O
.	O
	
This	O
reduction	O
is	O
a	O
significant	O
result	O
because	O
many	O
embedded	B-Method
platforms	I-Method
have	O
several	O
memory	O
constraints	O
.	O
	
For	O
example	O
,	O
FPGAs	O
often	O
have	O
less	O
than	O
10	O
MB	O
of	O
on	O
-	O
chip	O
memory	O
and	O
no	O
off	O
-	O
chip	O
memory	O
or	O
storage	O
.	O
	
Regarding	O
accuracy	B-Metric
results	O
,	O
usually	O
,	O
a	O
model	O
with	O
such	O
parameter	B-Method
reduction	I-Method
should	O
present	O
some	O
loss	O
of	O
accuracy	B-Metric
in	O
comparison	O
to	O
the	O
original	O
model	O
.	O
	
Nevertheless	O
,	O
the	O
performance	O
difference	O
between	O
VDCNN	B-Method
and	O
SVDCNN	B-Method
models	O
varies	O
between	O
0.4	O
and	O
1.3	O
%	O
,	O
which	O
is	O
pretty	O
modest	O
considering	O
the	O
parameters	O
and	O
storage	B-Task
size	I-Task
reduction	I-Task
aforementioned	O
.	O
	
In	O
Table	O
[	O
reference	O
]	O
,	O
it	O
is	O
possible	O
to	O
see	O
the	O
accuracy	B-Metric
scores	I-Metric
obtained	O
by	O
the	O
compared	O
models	O
.	O
	
Another	O
two	O
fundamental	O
results	O
obtained	O
are	O
a	O
)	O
	
The	O
base	O
property	O
of	O
VDCNN	B-Method
model	I-Method
is	O
preserved	O
on	O
its	O
squeezed	B-Method
model	I-Method
:	O
the	O
performance	O
still	O
increasing	O
up	O
with	O
the	O
depth	O
and	O
b	O
)	O
	
The	O
performance	O
evaluated	O
for	O
the	O
most	O
extensive	O
dataset	O
,	O
i.e.	O
,	O
Yelp	B-Material
Review	I-Material
(	O
62.30	O
%	O
)	O
,	O
still	O
overcomes	O
the	O
accuracy	B-Metric
of	O
the	O
Char	O
-	O
CNN	B-Method
model	O
(	O
62.05	O
%	O
)	O
.	O
	
Deep	B-Method
learning	I-Method
processing	I-Method
architecture	I-Method
has	O
the	O
property	O
of	O
being	O
high	O
parallelizable	O
;	O
it	O
is	O
expected	O
smaller	O
latencies	O
when	O
performing	O
inferences	O
in	O
hardware	O
with	O
high	O
parallelization	O
power	O
.	O
	
Despite	O
this	O
property	O
,	O
the	O
model	O
ability	O
to	O
use	O
all	O
hardware	O
parallel	O
potential	O
available	O
also	O
depends	O
on	O
the	O
network	B-Method
architecture	I-Method
.	O
	
The	O
more	O
parameters	O
per	O
layers	O
,	O
the	O
more	O
parallelizable	O
a	O
model	O
tends	O
to	O
be	O
,	O
while	O
the	O
increase	O
of	O
the	O
depth	O
gets	O
the	O
opposite	O
result	O
.	O
	
Another	O
natural	O
comprehension	O
fact	O
is	O
if	O
a	O
model	O
has	O
few	O
parameters	O
,	O
there	O
exists	O
less	O
content	O
to	O
be	O
processed	O
,	O
and	O
then	O
we	O
have	O
a	O
faster	O
inference	B-Metric
time	I-Metric
.	O
	
Concerning	O
mobile	O
devices	O
,	O
the	O
presence	O
of	O
dedicated	B-Method
hardware	I-Method
for	O
deep	B-Task
learning	I-Task
is	O
not	O
entirely	O
feasible	O
.	O
	
This	O
hardware	O
usually	O
requires	O
more	O
energy	O
and	O
dissipates	O
more	O
heat	O
,	O
two	O
undesirable	O
features	O
for	O
a	O
mobile	B-Task
platform	I-Task
.	O
	
Therefore	O
,	O
obtaining	O
fewer	O
inference	B-Metric
times	I-Metric
,	O
even	O
out	O
of	O
environments	O
with	O
high	O
parallelization	O
capabilities	O
,	O
is	O
a	O
pretty	O
desirable	O
characteristic	O
for	O
a	O
model	O
designed	O
to	O
work	O
on	O
mobile	B-Task
platforms	I-Task
.	O
	
The	O
latency	B-Metric
ratio	I-Metric
between	O
CPU	O
and	O
GPU	B-Metric
inference	I-Metric
times	I-Metric
indicates	O
how	O
undependable	O
of	O
dedicated	O
hardware	O
a	O
model	O
is	O
,	O
with	O
higher	O
values	O
meaning	O
more	O
independence	O
.	O
	
The	O
inference	B-Metric
times	I-Metric
obtained	O
for	O
the	O
three	O
models	O
compared	O
are	O
available	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
As	O
explained	O
in	O
Section	O
IV	O
a	O
)	O
,	O
each	O
convolutional	B-Method
layer	I-Method
of	O
the	O
convolutional	B-Method
blocks	I-Method
was	O
substituted	O
by	O
two	O
convolutions	B-Method
.	O
	
This	O
change	O
could	O
impact	O
the	O
inference	B-Metric
time	I-Metric
negatively	O
,	O
but	O
the	O
significant	O
parameter	B-Method
reduction	I-Method
allows	O
the	O
SVDCNN	B-Method
to	O
obtain	O
better	O
results	O
than	O
the	O
VDCNN	B-Method
model	I-Method
.	O
	
The	O
CPU	B-Metric
inference	I-Metric
time	I-Metric
obtained	O
by	O
the	O
proposed	O
model	O
was	O
smaller	O
than	O
the	O
base	O
model	O
for	O
the	O
depth	O
9	O
(	O
25.88ms	O
against	O
29	O
,	O
13ms	O
)	O
and	O
depth	O
17	O
(	O
47.80ms	O
against	O
48.05ms	O
)	O
,	O
while	O
the	O
Ratio	O
was	O
higher	O
for	O
all	O
depths	O
(	O
0.20	O
against	O
0.15	O
in	O
average	O
)	O
.	O
	
These	O
results	O
,	O
as	O
explained	O
above	O
,	O
are	O
pretty	O
significant	O
for	O
mobile	B-Task
platforms	I-Task
.	O
	
Looking	O
to	O
Char	B-Method
-	I-Method
CNN	I-Method
,	O
this	O
model	O
got	O
notably	O
inferior	O
results	O
compared	O
to	O
the	O
proposed	O
method	O
,	O
with	O
313.53ms	O
of	O
CPU	B-Metric
inference	I-Metric
time	I-Metric
and	O
Ratio	B-Metric
of	I-Metric
0.03	I-Metric
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
paper	O
,	O
we	O
presented	O
a	O
squeezed	B-Method
version	I-Method
of	O
the	O
VDCNN	B-Method
model	I-Method
considering	O
the	O
number	O
of	O
parameters	O
and	O
size	O
.	O
	
The	O
new	O
model	O
proprieties	O
became	O
it	O
feasible	O
for	O
mobile	B-Task
platforms	I-Task
.	O
	
To	O
achieve	O
this	O
goal	O
,	O
we	O
analyzed	O
the	O
impact	O
of	O
including	O
Temporal	B-Method
Depthwise	I-Method
Separable	I-Method
Convolutions	I-Method
and	O
a	O
Global	B-Method
Average	I-Method
Pooling	I-Method
layer	I-Method
in	O
a	O
very	O
deep	B-Method
convolutional	I-Method
neural	I-Method
network	I-Method
for	O
text	B-Task
classification	I-Task
.	O
	
The	O
SVDCNN	B-Method
model	O
reduces	O
about	O
92.45	O
%	O
the	O
number	O
of	O
parameters	O
and	O
storage	B-Metric
size	I-Metric
while	O
presents	O
an	O
inference	B-Metric
time	I-Metric
ratio	I-Metric
(	O
CPU	B-Metric
/	I-Metric
GPU	I-Metric
)	O
,	O
31.94	O
%	O
higher	O
.	O
	
For	O
future	O
works	O
,	O
we	O
plan	O
to	O
evaluate	O
other	O
techniques	O
able	O
to	O
reduce	O
storage	O
size	O
,	O
such	O
as	O
model	B-Method
compression	I-Method
.	O
	
Moreover	O
,	O
the	O
model	B-Metric
accuracy	I-Metric
over	O
even	O
more	O
massive	O
datasets	O
will	O
be	O
evaluated	O
as	O
well	O
as	O
the	O
efficiency	O
of	O
its	O
depth	O
49	O
configuration	O
.	O
	
section	O
:	O
Acknowledgment	O
	
We	O
would	O
like	O
to	O
thank	O
FACEPE	O
and	O
CNPq	O
(	O
Brazilian	O
research	O
agencies	O
)	O
for	O
financial	O
support	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Wider	O
or	O
Deeper	O
:	O
Revisiting	O
the	O
ResNet	B-Method
Model	I-Method
for	O
Visual	B-Task
Recognition	I-Task
	
The	O
trend	O
towards	O
increasingly	O
deep	B-Method
neural	I-Method
networks	I-Method
has	O
been	O
driven	O
by	O
a	O
general	O
observation	O
that	O
increasing	O
depth	O
increases	O
the	O
performance	O
of	O
a	O
network	O
.	O
	
Recently	O
,	O
however	O
,	O
evidence	O
has	O
been	O
amassing	O
that	O
simply	O
increasing	O
depth	O
may	O
not	O
be	O
the	O
best	O
way	O
to	O
increase	O
performance	O
,	O
particularly	O
given	O
other	O
limitations	O
.	O
	
Investigations	O
into	O
deep	B-Method
residual	I-Method
networks	I-Method
have	O
also	O
suggested	O
that	O
they	O
may	O
not	O
in	O
fact	O
be	O
operating	O
as	O
a	O
single	O
deep	B-Method
network	I-Method
,	O
but	O
rather	O
as	O
an	O
ensemble	O
of	O
many	O
relatively	O
shallow	B-Method
networks	I-Method
.	O
	
We	O
examine	O
these	O
issues	O
,	O
and	O
in	O
doing	O
so	O
arrive	O
at	O
a	O
new	O
interpretation	O
of	O
the	O
unravelled	O
view	O
of	O
deep	B-Method
residual	I-Method
networks	I-Method
which	O
explains	O
some	O
of	O
the	O
behaviours	O
that	O
have	O
been	O
observed	O
experimentally	O
.	O
	
As	O
a	O
result	O
,	O
we	O
are	O
able	O
to	O
derive	O
a	O
new	O
,	O
shallower	B-Method
,	I-Method
architecture	I-Method
of	I-Method
residual	I-Method
networks	I-Method
which	O
significantly	O
outperforms	O
much	O
deeper	B-Method
models	I-Method
such	O
as	O
ResNet	B-Method
-	I-Method
200	I-Method
on	O
the	O
ImageNet	B-Task
classification	O
dataset	O
.	O
	
We	O
also	O
show	O
that	O
this	O
performance	O
is	O
transferable	O
to	O
other	O
problem	O
domains	O
by	O
developing	O
a	O
semantic	B-Method
segmentation	I-Method
approach	I-Method
which	O
outperforms	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
by	O
a	O
remarkable	O
margin	O
on	O
datasets	O
including	O
PASCAL	B-Material
VOC	I-Material
,	O
PASCAL	B-Material
Context	I-Material
,	O
and	O
Cityscapes	B-Material
.	O
	
The	O
architecture	O
that	O
we	O
propose	O
thus	O
outperforms	O
its	O
comparators	B-Method
,	O
including	O
very	O
deep	B-Method
ResNets	I-Method
,	O
and	O
yet	O
is	O
more	O
efficient	O
in	O
memory	B-Metric
use	I-Metric
and	O
sometimes	O
also	O
in	O
training	B-Metric
time	I-Metric
.	O
	
The	O
code	O
and	O
models	O
are	O
available	O
at	O
.	O
	
section	O
:	O
Introduction	O
	
The	O
convolutional	B-Method
networks	I-Method
used	O
by	O
the	O
computer	B-Task
vision	I-Task
community	I-Task
have	O
been	O
growing	O
deeper	O
and	O
deeper	O
each	O
year	O
since	O
Krizhevsky	O
et	O
al	O
.	O
proposed	O
AlexNet	B-Method
in	O
2012	O
.	O
	
The	O
deepest	B-Method
network	I-Method
in	O
the	O
literature	O
is	O
a	O
residual	B-Method
network	I-Method
(	O
ResNet	B-Method
)	O
with	O
1	O
,	O
202	O
trainable	B-Method
layers	I-Method
,	O
which	O
was	O
trained	O
using	O
the	O
tiny	O
images	O
in	O
the	O
CIFAR	B-Material
-	I-Material
10	I-Material
dataset	O
.	O
	
The	O
image	O
size	O
here	O
is	O
important	O
,	O
because	O
it	O
means	O
that	O
the	O
size	O
of	O
corresponding	O
feature	O
maps	O
is	O
relatively	O
small	O
,	O
which	O
is	O
critical	O
in	O
training	O
extremely	O
deep	B-Method
models	I-Method
.	O
	
Most	O
networks	O
operating	O
on	O
more	O
practically	O
interesting	O
image	O
sizes	O
tend	O
to	O
have	O
the	O
order	O
of	O
one	O
,	O
to	O
two	O
,	O
hundred	O
layers	O
,	O
the	O
200	B-Method
-	I-Method
layer	I-Method
ResNet	I-Method
and	O
96	B-Method
-	I-Method
layer	I-Method
Inception	I-Method
-	I-Method
ResNet	I-Method
.	O
	
The	O
progression	O
to	O
deeper	O
networks	O
continues	O
,	O
however	O
,	O
with	O
Zhao	O
et	O
al	O
.	O
having	O
trained	O
a	O
269	B-Method
-	I-Method
layer	I-Method
network	I-Method
for	O
semantic	B-Task
image	I-Task
segmentation	I-Task
.	O
	
These	O
networks	O
were	O
trained	O
using	O
the	O
ImageNet	B-Task
classification	O
dataset	O
,	O
where	O
the	O
images	O
are	O
of	O
much	O
higher	O
resolution	O
.	O
	
Each	O
additional	O
layer	O
requires	O
not	O
only	O
additional	O
memory	O
,	O
but	O
also	O
additional	O
training	O
.	O
	
The	O
marginal	O
gains	O
achieved	O
by	O
each	O
additional	O
layer	O
diminish	O
with	O
depth	O
,	O
however	O
,	O
to	O
the	O
point	O
where	O
Zhao	O
et	O
al	O
.	O
achieved	O
only	O
an	O
improvement	O
of	O
1.1	O
%	O
(	O
from	O
42.2	O
%	O
to	O
43.3	O
%	O
by	O
mean	O
intersection	B-Metric
-	I-Metric
over	I-Metric
-	I-Metric
union	I-Metric
scores	I-Metric
)	O
after	O
almost	O
doubling	O
the	O
number	O
of	O
layers	O
(	O
from	O
152	O
to	O
269	O
)	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
Zagoruyko	O
and	O
Komodakis	O
showed	O
that	O
it	O
is	O
possible	O
to	O
train	O
much	O
shallower	O
but	O
wider	O
networks	O
on	O
CIFAR	B-Material
-	I-Material
10	I-Material
,	O
which	O
outperform	O
a	O
ResNet	B-Method
with	O
its	O
more	O
than	O
one	O
thousand	O
layers	O
.	O
	
The	O
question	O
thus	O
naturally	O
arises	O
as	O
to	O
whether	O
deep	O
,	O
or	O
wide	O
,	O
is	O
the	O
right	O
strategy	O
.	O
	
In	O
order	O
to	O
examine	O
the	O
issue	O
we	O
first	O
need	O
to	O
understand	O
the	O
mechanism	O
behind	O
ResNets	B-Method
.	O
	
Veit	O
et	O
al	O
.	O
have	O
claimed	O
that	O
they	O
actually	O
behave	O
as	O
exponential	B-Method
ensembles	I-Method
of	I-Method
relatively	I-Method
shallow	I-Method
networks	I-Method
.	O
	
However	O
,	O
there	O
is	O
a	O
gap	O
between	O
their	O
proposed	O
unravelled	O
view	O
of	O
a	O
ResNet	B-Method
,	O
and	O
a	O
real	O
exponential	B-Method
ensemble	I-Method
of	I-Method
sub	I-Method
-	I-Method
networks	I-Method
,	O
as	O
illustrated	O
in	O
the	O
top	O
row	O
of	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Since	O
the	O
residual	O
units	O
are	O
non	O
-	O
linear	O
,	O
we	O
can	O
not	O
further	O
split	O
the	O
bottom	O
path	O
into	O
two	O
sub	O
-	O
networks	O
,	O
i.e.	O
,	O
and	O
.	O
	
It	O
turns	O
out	O
that	O
ResNets	B-Method
are	O
only	O
assembling	O
linearly	O
growing	O
numbers	O
of	O
sub	O
-	O
networks	O
.	O
	
Besides	O
,	O
the	O
key	O
characteristic	O
of	O
our	O
introduced	O
view	O
is	O
that	O
it	O
depends	O
on	O
the	O
effective	O
depth	O
of	O
a	O
network	O
.	O
	
This	O
amounts	O
to	O
the	O
number	O
of	O
residual	O
units	O
which	O
backward	O
gradients	O
during	O
training	O
can	O
go	O
through	O
.	O
	
When	O
,	O
the	O
two	O
-	O
unit	O
ResNet	B-Method
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
can	O
be	O
seen	O
as	O
an	O
ensemble	O
of	O
three	O
sub	B-Method
-	I-Method
networks	I-Method
,	O
i.e.	O
,	O
,	O
,	O
and	O
,	O
as	O
shown	O
in	O
the	O
bottom	O
left	O
.	O
	
When	O
,	O
nothing	O
changes	O
except	O
that	O
we	O
replace	O
the	O
third	O
sub	B-Method
-	I-Method
network	I-Method
with	O
a	O
shallower	O
one	O
,	O
as	O
shown	O
in	O
the	O
bottom	O
right	O
example	O
.	O
	
The	O
superscripts	O
in	O
and	O
denote	O
their	O
actual	O
depths	O
.	O
	
About	O
the	O
unravelled	O
view	O
,	O
the	O
effective	O
depth	O
of	O
a	O
ResNet	B-Method
,	O
and	O
the	O
actual	O
depth	O
of	O
a	O
sub	O
-	O
network	O
,	O
more	O
details	O
will	O
be	O
provided	O
in	O
the	O
sequence	O
.	O
	
It	O
is	O
also	O
worth	O
noting	O
that	O
Veit	O
et	O
al	O
.	O
empirically	O
found	O
that	O
most	O
gradients	O
in	O
a	O
110	O
-	O
layer	O
ResNet	B-Method
can	O
only	O
go	O
through	O
up	O
to	O
seventeen	O
residual	O
units	O
,	O
which	O
supports	O
our	O
above	O
hypothesis	O
that	O
the	O
effective	O
depth	O
exists	O
for	O
a	O
specific	O
network	O
.	O
	
In	O
this	O
paper	O
,	O
our	O
contributions	O
include	O
:	O
We	O
introduce	O
a	O
further	O
developed	O
intuitive	B-Method
view	I-Method
of	O
ResNets	B-Method
,	O
which	O
helps	O
us	O
understand	O
their	O
behaviours	O
,	O
and	O
find	O
possible	O
directions	O
to	O
further	O
improvements	O
.	O
	
We	O
propose	O
a	O
group	O
of	O
relatively	O
shallow	B-Method
convolutional	I-Method
networks	I-Method
based	O
on	O
our	O
new	O
understanding	O
.	O
	
Some	O
of	O
them	O
achieve	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
the	O
ImageNet	B-Task
classification	O
dataset	O
.	O
	
We	O
evaluate	O
the	O
impact	O
of	O
using	O
different	O
networks	O
on	O
the	O
performance	O
of	O
semantic	B-Task
image	I-Task
segmentation	I-Task
,	O
and	O
show	O
these	O
networks	O
,	O
as	O
pre	O
-	O
trained	O
features	O
,	O
can	O
boost	O
existing	O
algorithms	O
a	O
lot	O
.	O
	
We	O
achieve	O
the	O
best	O
results	O
on	O
PASCAL	B-Material
VOC	I-Material
,	O
PASCAL	B-Material
Context	I-Material
,	O
and	O
Cityscapes	B-Material
.	O
	
section	O
:	O
Related	O
work	O
	
Our	O
work	O
here	O
is	O
closely	O
related	O
to	O
two	O
topics	O
,	O
residual	B-Method
network	I-Method
(	O
ResNet	B-Method
)	O
based	O
image	B-Task
classification	I-Task
and	O
semantic	B-Task
image	I-Task
segmentation	I-Task
using	O
fully	B-Method
convolutional	I-Method
networks	I-Method
.	O
	
As	O
we	O
have	O
noted	O
above	O
,	O
He	O
et	O
al	O
.	O
recently	O
proposed	O
the	O
ResNets	B-Method
to	O
combat	O
the	O
vanishing	B-Task
gradient	I-Task
problem	I-Task
during	O
training	O
very	O
deep	B-Method
convolutional	I-Method
networks	I-Method
.	O
	
ResNets	B-Method
have	O
outperformed	O
previous	O
models	O
at	O
a	O
variety	O
of	O
tasks	O
,	O
such	O
as	O
object	B-Task
detection	I-Task
and	O
semantic	B-Task
image	I-Task
segmentation	I-Task
.	O
	
They	O
are	O
gradually	O
replacing	O
VGGNets	B-Method
in	O
the	O
computer	B-Task
vision	I-Task
community	I-Task
,	O
as	O
the	O
standard	O
feature	B-Method
extractors	I-Method
.	O
	
Nevertheless	O
,	O
the	O
real	O
mechanism	O
underpinning	O
the	O
effectiveness	O
of	O
ResNets	B-Method
is	O
not	O
yet	O
clear	O
.	O
	
Veit	O
et	O
al	O
.	O
claimed	O
that	O
they	O
behave	O
like	O
exponential	B-Method
ensembles	I-Method
of	I-Method
relatively	I-Method
shallow	I-Method
networks	I-Method
,	O
yet	O
the	O
‘	O
exponential	O
’	O
nature	O
of	O
the	O
ensembles	O
has	O
yet	O
to	O
be	O
theoretically	O
verified	O
.	O
	
Residual	O
units	O
are	O
usually	O
non	O
-	O
linear	O
,	O
which	O
prevents	O
a	O
ResNet	B-Method
from	O
exponentially	O
expanding	O
into	O
separated	O
sub	O
-	O
networks	O
,	O
as	O
illustrated	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
It	O
is	O
also	O
unclear	O
as	O
to	O
whether	O
a	O
residual	O
structure	O
is	O
required	O
to	O
train	O
very	O
deep	B-Method
networks	I-Method
.	O
	
For	O
example	O
,	O
Szegedy	O
et	O
al	O
.	O
showed	O
that	O
it	O
is	O
‘	O
not	O
very	O
difficult	O
’	O
to	O
train	O
competitively	B-Method
deep	I-Method
networks	I-Method
,	O
even	O
without	O
residual	O
shortcuts	O
.	O
	
Currently	O
,	O
the	O
most	O
clear	O
advantage	O
of	O
ResNets	B-Method
is	O
in	O
their	O
fast	O
convergence	B-Metric
.	O
	
Szegedy	O
et	O
al	O
.	O
	
observed	O
similar	O
empirically	O
results	O
to	O
support	O
that	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
Zagoruyko	O
and	O
Komodakis	O
found	O
that	O
a	O
wide	O
sixteen	O
-	O
layer	O
ResNet	B-Method
outperformed	O
the	O
original	O
thin	O
thousand	O
-	O
layer	O
ResNet	B-Method
on	O
datasets	O
composed	O
of	O
tiny	O
images	O
such	O
as	O
CIFAR	B-Material
-	I-Material
10	I-Material
.	O
	
The	O
analysis	O
we	O
present	O
here	O
is	O
motivated	O
by	O
their	O
empirical	O
testing	O
,	O
but	O
aims	O
at	O
a	O
more	O
theoretical	O
approach	O
,	O
and	O
the	O
observation	O
that	O
a	O
grid	B-Method
search	I-Method
of	I-Method
configuration	I-Method
space	I-Method
is	O
impractical	O
on	O
large	O
scale	O
datasets	O
such	O
as	O
the	O
ImageNet	B-Task
classification	O
dataset	O
.	O
	
Semantic	B-Task
image	I-Task
segmentation	I-Task
amounts	O
to	O
predicting	O
the	O
categories	O
for	O
each	O
pixel	O
in	O
an	O
image	O
.	O
	
Long	O
et	O
al	O
.	O
proposed	O
the	O
fully	B-Method
convolutional	I-Method
networks	I-Method
(	O
FCN	B-Method
)	O
to	O
this	O
end	O
.	O
	
FCNs	B-Method
soon	O
became	O
the	O
mainstream	O
approach	O
to	O
dense	B-Task
prediction	I-Task
based	I-Task
tasks	I-Task
,	O
especially	O
due	O
to	O
its	O
efficiency	O
.	O
	
Besides	O
,	O
empirical	O
results	O
in	O
the	O
literature	O
showed	O
that	O
stronger	O
pre	O
-	O
trained	O
features	O
can	O
yet	O
further	O
improve	O
their	O
performance	O
.	O
	
We	O
thus	O
here	O
base	O
our	O
semantic	B-Task
image	I-Task
segmentation	I-Task
approach	O
on	O
fully	B-Method
convolutional	I-Method
networks	I-Method
,	O
and	O
will	O
show	O
the	O
impact	O
of	O
different	O
pre	O
-	O
trained	O
features	O
on	O
final	O
segmentation	B-Task
results	O
.	O
	
section	O
:	O
Residual	B-Method
networks	I-Method
revisited	O
	
We	O
are	O
concerned	O
here	O
with	O
the	O
full	B-Method
pre	I-Method
-	I-Method
activation	I-Method
version	I-Method
of	I-Method
residual	I-Method
networks	I-Method
(	O
ResNet	B-Method
)	O
.	O
	
For	O
shortcut	O
connections	O
,	O
we	O
consider	O
identity	O
mappings	O
only	O
.	O
	
We	O
omit	O
the	O
raw	O
input	O
and	O
the	O
top	O
-	O
most	O
linear	B-Method
classifier	I-Method
for	O
clarity	O
.	O
	
Usually	O
,	O
there	O
may	O
be	O
a	O
stem	O
block	O
or	O
several	O
traditional	O
convolution	B-Method
layers	I-Method
directly	O
after	O
the	O
raw	O
input	O
.	O
	
We	O
omit	O
these	O
also	O
,	O
for	O
the	O
purpose	O
of	O
simplicity	O
.	O
	
For	O
the	O
residual	B-Method
Unit	I-Method
,	O
let	O
be	O
the	O
input	O
,	O
and	O
let	O
be	O
its	O
trainable	O
non	B-Method
-	I-Method
linear	I-Method
mappings	I-Method
,	O
also	O
named	O
Block	O
.	O
	
The	O
output	O
of	O
Unit	O
is	O
recursively	O
defined	O
as	O
:	O
where	O
denotes	O
the	O
trainable	O
parameters	O
,	O
and	O
is	O
often	O
two	O
or	O
three	O
stacked	B-Method
convolution	I-Method
stages	I-Method
.	O
	
In	O
the	O
full	O
pre	B-Method
-	I-Method
activation	I-Method
version	I-Method
,	O
the	O
components	O
of	O
a	O
stage	O
are	O
in	O
turn	O
a	O
batch	B-Method
normalization	I-Method
,	O
a	O
rectified	B-Method
linear	I-Method
unit	I-Method
(	O
ReLU	B-Method
)	O
non	O
-	O
linearity	O
,	O
and	O
a	O
convolution	B-Method
layer	I-Method
.	O
	
subsection	O
:	O
Residual	B-Method
networks	I-Method
unravelled	O
online	O
	
Applying	O
Eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
in	O
one	O
substitution	O
step	O
	
,	O
we	O
expand	O
the	O
forward	O
pass	O
into	O
:	O
which	O
describes	O
the	O
unravelled	O
view	O
by	O
Veit	O
et	O
al	O
.	O
,	O
as	O
shown	O
in	O
the	O
top	O
row	O
of	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Since	O
is	O
non	O
-	O
linear	O
,	O
we	O
can	O
not	O
derive	O
Eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
from	O
Eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
	
So	O
the	O
whole	O
network	O
is	O
not	O
equivalent	O
to	O
an	O
exponentially	O
growing	O
ensemble	O
of	O
sub	B-Method
-	I-Method
networks	I-Method
.	O
	
It	O
is	O
rather	O
,	O
more	O
accurately	O
,	O
described	O
as	O
a	O
linearly	B-Method
growing	I-Method
ensemble	I-Method
of	I-Method
sub	I-Method
-	I-Method
networks	I-Method
.	O
	
For	O
the	O
two	O
-	O
unit	O
ResNet	B-Method
as	O
illustrated	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
,	O
there	O
are	O
three	O
,	O
e.g.	O
,	O
,	O
,	O
and	O
,	O
sub	O
-	O
networks	O
respectively	O
corresponding	O
to	O
the	O
three	O
terms	O
in	O
Eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
,	O
i.e.	O
,	O
,	O
,	O
	
and	O
.	O
	
Veit	O
et	O
al	O
.	O
	
in	O
showed	O
that	O
the	O
paths	O
which	O
gradients	O
take	O
through	O
a	O
ResNet	B-Method
are	O
typically	O
far	O
shorter	O
than	O
the	O
total	O
depth	O
of	O
that	O
network	O
.	O
	
They	O
thus	O
introduced	O
the	O
idea	O
of	O
effective	O
depth	O
as	O
a	O
measure	O
for	O
the	O
true	O
length	O
of	O
these	O
paths	O
.	O
	
By	O
characterising	O
the	O
units	O
of	O
a	O
ResNet	B-Method
given	O
its	O
effective	O
depth	O
,	O
we	O
illuminate	O
the	O
impact	O
of	O
varying	O
paths	O
that	O
gradients	O
actually	O
take	O
,	O
as	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
We	O
here	O
illustrate	O
this	O
impact	O
in	O
terms	O
of	O
small	O
effective	O
depths	O
,	O
because	O
to	O
do	O
so	O
for	O
larger	O
ones	O
would	O
require	O
diagrams	O
of	O
enormous	O
networks	O
.	O
	
The	O
impact	O
is	O
the	O
same	O
,	O
however	O
.	O
	
Take	O
the	O
ResNet	B-Method
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
for	O
example	O
again	O
.	O
	
In	O
an	O
SGD	B-Method
iteration	I-Method
,	O
the	O
backward	O
gradients	O
are	O
:	O
where	O
denotes	O
the	O
derivative	O
of	O
to	O
its	O
input	O
.	O
	
When	O
effective	O
depth	O
,	O
both	O
terms	O
in	O
Eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
are	O
non	O
-	O
zeros	O
,	O
which	O
corresponds	O
to	O
the	O
bottom	O
-	O
left	O
case	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Namely	O
,	O
Block	O
1	O
receives	O
gradients	O
from	O
both	O
and	O
.	O
	
However	O
,	O
when	O
effective	O
depth	O
,	O
the	O
gradient	O
vanishes	O
after	O
passing	O
through	O
Block	O
2	O
.	O
	
Namely	O
,	O
.	O
	
So	O
,	O
the	O
second	O
term	O
in	O
Eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
also	O
goes	O
to	O
zeros	O
,	O
which	O
is	O
illustrated	O
by	O
the	O
bottom	O
-	O
right	O
case	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
The	O
weights	O
in	O
Block	O
1	O
indeed	O
vary	O
across	O
different	O
iterations	O
,	O
but	O
they	O
are	O
updated	O
only	O
by	O
.	O
	
To	O
,	O
Block	O
1	O
is	O
no	O
more	O
than	O
an	O
additional	O
input	O
providing	O
preprocessed	O
representations	O
,	O
because	O
Block	O
1	O
is	O
not	O
end	O
-	O
to	O
-	O
end	O
trained	O
,	O
from	O
the	O
point	O
of	O
view	O
of	O
.	O
	
In	O
this	O
case	O
,	O
we	O
name	O
to	O
have	O
an	O
actual	O
depth	O
of	O
one	O
.	O
	
We	O
say	O
that	O
the	O
ResNet	B-Method
is	O
over	O
-	O
deepened	O
,	O
and	O
that	O
it	O
can	O
not	O
be	O
trained	O
in	O
a	O
fully	O
end	O
-	O
to	O
-	O
end	O
manner	O
,	O
even	O
with	O
those	O
shortcut	O
connections	O
.	O
	
Let	O
be	O
the	O
total	O
number	O
of	O
residual	O
units	O
.	O
	
We	O
can	O
see	O
a	O
ResNet	B-Method
as	O
an	O
ensemble	O
of	O
different	O
sub	O
-	O
networks	O
,	O
i.e.	O
,	O
.	O
	
The	O
actual	O
depth	O
of	O
is	O
.	O
	
We	O
show	O
an	O
unravelled	O
three	O
-	O
unit	O
ResNet	B-Method
with	O
different	O
effective	O
depths	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
By	O
way	O
of	O
example	O
,	O
note	O
that	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
contains	O
only	O
Block	O
1	O
,	O
whereas	O
contains	O
both	O
Block	O
1	O
and	O
Block	O
2	O
.	O
	
Among	O
the	O
cases	O
illustrated	O
,	O
the	O
bottom	O
left	O
example	O
is	O
more	O
complicated	O
,	O
where	O
and	O
.	O
	
From	O
the	O
point	O
of	O
view	O
of	O
,	O
the	O
gradient	O
of	O
Block	O
1	O
is	O
,	O
where	O
the	O
first	O
term	O
is	O
non	O
-	O
zero	O
.	O
will	O
thus	O
update	O
Block	O
1	O
at	O
each	O
iteration	O
.	O
	
Considering	O
the	O
non	O
-	O
linearity	O
in	O
Block	O
3	O
,	O
it	O
is	O
non	O
-	O
trivial	O
to	O
tell	O
if	O
this	O
is	O
as	O
good	O
as	O
the	O
fully	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
training	I-Task
case	I-Task
,	O
as	O
illustrated	O
by	O
in	O
the	O
top	O
right	O
example	O
.	O
	
An	O
investigation	O
of	O
this	O
issue	O
remains	O
future	O
work	O
.	O
	
subsection	O
:	O
Residual	O
networks	O
behaviours	O
revisited	O
	
Very	O
deep	B-Method
ResNets	I-Method
.	O
	
Conventionally	O
,	O
it	O
is	O
not	O
easy	O
to	O
train	O
very	O
deep	B-Method
networks	I-Method
due	O
to	O
the	O
vanishing	B-Task
gradient	I-Task
problem	I-Task
.	O
	
To	O
understand	O
how	O
a	O
very	O
deep	O
ResNet	B-Method
is	O
trained	O
,	O
the	O
observation	O
by	O
Veit	O
et	O
al	O
.	O
is	O
important	O
,	O
i.e.	O
,	O
gradients	O
vanish	O
exponentially	O
as	O
the	O
length	O
of	O
paths	O
increases	O
.	O
	
Now	O
refer	O
to	O
the	O
top	O
-	O
right	O
example	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
This	O
is	O
somewhat	O
similar	O
to	O
the	O
case	O
of	O
a	O
shallow	O
or	O
reasonably	O
deep	O
ResNet	B-Method
,	O
when	O
.	O
	
At	O
the	O
beginning	O
,	O
the	O
shallowest	B-Method
sub	I-Method
-	I-Method
network	I-Method
,	O
i.e.	O
,	O
,	O
converges	O
fast	O
,	O
because	O
it	O
gives	O
Block	O
1	O
the	O
largest	O
gradients	O
.	O
	
From	O
the	O
point	O
of	O
view	O
of	O
,	O
Block	O
2	O
may	O
also	O
receive	O
large	O
gradients	O
due	O
to	O
the	O
path	O
with	O
a	O
length	O
of	O
one	O
.	O
	
However	O
,	O
the	O
input	O
of	O
Block	O
2	O
partly	O
depends	O
on	O
Block	O
1	O
.	O
	
It	O
would	O
not	O
be	O
easy	O
for	O
Block	O
2	O
to	O
converge	O
before	O
the	O
output	O
of	O
Block	O
1	O
stabilises	O
.	O
	
Similarly	O
,	O
Block	O
3	O
will	O
need	O
to	O
wait	O
for	O
Blocks	O
1	O
and	O
2	O
,	O
and	O
so	O
forth	O
.	O
	
In	O
this	O
way	O
,	O
a	O
ResNet	B-Method
seems	O
like	O
an	O
ensemble	B-Method
with	O
a	O
growing	O
number	O
of	O
sub	O
-	O
networks	O
.	O
	
Besides	O
,	O
each	O
newly	O
added	O
sub	O
-	O
network	O
will	O
have	O
a	O
larger	O
actual	O
depth	O
than	O
all	O
the	O
previous	O
ones	O
.	O
	
Note	O
that	O
Littwin	O
and	O
Wolf	O
,	O
in	O
a	O
concurrent	O
work	O
,	O
have	O
theoretically	O
showed	O
that	O
ResNets	B-Method
are	O
virtual	B-Method
ensembles	I-Method
whose	O
depth	O
grows	O
as	O
training	O
progresses	O
.	O
	
Their	O
result	O
to	O
some	O
extent	O
coincides	O
with	O
the	O
above	O
described	O
process	O
.	O
	
The	O
story	O
will	O
however	O
be	O
different	O
when	O
the	O
actual	O
depth	O
becomes	O
as	O
large	O
as	O
the	O
effective	O
depth	O
.	O
	
Refer	O
to	O
the	O
bottom	O
-	O
right	O
example	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
This	O
is	O
somewhat	O
similar	O
to	O
the	O
case	O
of	O
an	O
over	O
-	O
deepened	O
ResNet	B-Method
,	O
when	O
is	O
much	O
larger	O
than	O
.	O
	
Again	O
,	O
Block	O
1	O
in	O
gets	O
trained	O
and	O
stabilises	O
first	O
.	O
	
However	O
,	O
this	O
time	O
is	O
not	O
fully	O
end	O
-	O
to	O
-	O
end	O
trained	O
any	O
more	O
.	O
	
Since	O
gives	O
no	O
gradients	O
to	O
Block	O
1	O
,	O
it	O
becomes	O
a	O
one	B-Method
-	I-Method
block	I-Method
sub	I-Method
-	I-Method
network	I-Method
trained	O
on	O
top	O
of	O
some	O
preprocessed	B-Method
representations	I-Method
,	O
which	O
are	O
obtained	O
by	O
adding	O
the	O
output	O
of	O
Block	O
1	O
up	O
to	O
the	O
original	O
input	O
.	O
	
In	O
this	O
way	O
,	O
the	O
newly	O
added	O
sub	O
-	O
network	O
still	O
has	O
an	O
actual	O
depth	O
of	O
one	O
,	O
which	O
is	O
no	O
deeper	O
than	O
the	O
previous	O
one	O
,	O
i.e.	O
,	O
,	O
and	O
so	O
forth	O
for	O
.	O
	
ResNets	B-Method
thus	O
avoid	O
the	O
vanishing	B-Task
gradient	I-Task
problem	I-Task
by	O
reshaping	O
themselves	O
into	O
multiple	O
shallower	B-Method
sub	I-Method
-	I-Method
networks	I-Method
.	O
	
This	O
is	O
just	O
another	O
view	O
of	O
delivering	O
gradients	O
to	O
bottom	O
layers	O
through	O
shortcut	O
connections	O
.	O
	
Researchers	O
have	O
claimed	O
that	O
the	O
residual	O
shortcut	O
connections	O
are	O
not	O
necessary	O
even	O
in	O
very	O
deep	B-Method
networks	I-Method
.	O
	
However	O
,	O
there	O
are	O
usually	O
short	O
paths	O
in	O
their	O
proposed	O
networks	O
as	O
well	O
.	O
	
For	O
example	O
,	O
the	O
76	O
-	O
layer	O
Inception	B-Method
-	I-Method
v4	I-Method
network	O
has	O
a	O
much	O
shorter	O
twenty	O
-	O
layer	O
route	O
from	O
its	O
input	O
to	O
the	O
output	O
.	O
	
There	O
might	O
be	O
differences	O
in	O
the	O
details	O
between	O
fusion	B-Task
by	O
concatenation	B-Method
(	O
Inception	B-Method
-	I-Method
v4	I-Method
)	O
and	O
fusion	B-Method
by	O
summation	B-Method
(	O
ResNets	B-Method
)	O
.	O
	
However	O
,	O
the	O
manner	O
of	O
avoiding	O
the	O
vanishing	B-Task
gradient	I-Task
problem	I-Task
is	O
probably	O
similar	O
,	O
i.e.	O
,	O
using	O
shortcuts	B-Method
,	O
either	O
with	O
trainable	O
weights	O
or	O
not	O
.	O
	
We	O
are	O
thus	O
not	O
yet	O
in	O
a	O
position	O
to	O
be	O
able	O
to	O
claim	O
that	O
the	O
vanishing	B-Task
gradient	I-Task
problem	I-Task
has	O
been	O
solved	O
.	O
	
Wide	O
ResNets	B-Method
.	O
	
Conventionally	O
,	O
wide	B-Method
layers	I-Method
are	O
more	O
prone	O
to	O
over	O
-	O
fitting	O
,	O
and	O
sometimes	O
require	O
extra	O
regularization	O
such	O
as	O
dropout	B-Method
.	O
	
However	O
,	O
Zagoruyko	O
and	O
Komodakis	O
showed	O
the	O
possibility	O
to	O
effectively	O
train	O
times	O
wider	O
ResNets	B-Method
,	O
even	O
without	O
any	O
extra	O
regularization	O
.	O
	
To	O
understand	O
how	O
a	O
wide	O
ResNet	B-Method
is	O
trained	O
,	O
refer	O
to	O
the	O
top	O
right	O
example	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
This	O
simulates	O
the	O
case	O
of	O
a	O
rather	O
shallow	B-Method
network	I-Method
,	O
when	O
is	O
smaller	O
than	O
.	O
	
We	O
reuse	O
the	O
weights	O
of	O
Block	O
1	O
for	O
four	O
times	O
.	O
	
Among	O
these	O
,	O
Block	O
1	O
is	O
located	O
in	O
three	O
different	O
kinds	O
of	O
circumstances	O
.	O
	
In	O
the	O
bottom	O
-	O
most	O
path	O
of	O
the	O
sub	B-Method
-	I-Method
network	I-Method
,	O
it	O
is	O
supposed	O
to	O
learn	O
some	O
low	O
-	O
level	O
features	O
;	O
in	O
,	O
it	O
should	O
learn	O
both	O
low	O
-	O
level	O
and	O
mid	O
-	O
level	O
features	O
;	O
and	O
in	O
,	O
it	O
has	O
to	O
learn	O
everything	O
.	O
	
This	O
format	O
of	O
weight	B-Method
sharing	I-Method
may	O
suppress	O
over	B-Task
-	I-Task
fitting	I-Task
,	O
especially	O
for	O
those	O
units	O
far	O
from	O
the	O
top	O
-	O
most	O
linear	B-Method
classifier	I-Method
.	O
	
Hence	O
ResNets	B-Method
inherently	O
introduce	O
regularization	O
by	O
weight	B-Method
sharing	I-Method
among	O
multiple	O
very	O
different	O
sub	O
-	O
networks	O
.	O
	
Residual	O
unit	O
choices	O
.	O
	
For	O
better	O
performance	O
,	O
we	O
hope	O
that	O
a	O
ResNet	B-Method
should	O
expand	O
into	O
a	O
sufficiently	O
large	O
number	O
of	O
sub	O
-	O
networks	O
,	O
some	O
of	O
which	O
should	O
have	O
large	O
model	O
capacity	O
.	O
	
So	O
,	O
given	O
our	O
previous	O
observations	O
,	O
the	O
requirements	O
for	O
an	O
ideal	O
mapping	O
function	O
in	O
a	O
residual	O
unit	O
are	O
,	O
1	O
)	O
being	O
strong	O
enough	O
to	O
converge	O
even	O
if	O
it	O
is	O
reused	O
in	O
many	O
sub	O
-	O
networks	O
,	O
and	O
2	O
)	O
being	O
shallow	O
enough	O
to	O
enable	O
an	O
large	O
effective	O
depth	O
.	O
	
Since	O
it	O
is	O
very	O
hard	O
to	O
build	O
a	O
model	O
with	O
large	O
capacity	O
using	O
a	O
single	O
trainable	B-Method
layer	I-Method
,	O
the	O
most	O
natural	O
choice	O
would	O
be	O
a	O
residual	B-Method
unit	I-Method
with	O
two	O
wide	O
convolution	B-Method
stages	I-Method
.	O
	
This	O
coincides	O
with	O
empirical	O
results	O
reported	O
by	O
Zagoruyko	O
and	O
Komodakis	O
.	O
	
They	O
found	O
that	O
,	O
among	O
the	O
most	O
trivial	O
structure	O
choices	O
,	O
the	O
best	O
one	O
is	O
to	O
stack	O
two	O
convolution	B-Method
stages	I-Method
.	O
	
subsection	O
:	O
Wider	O
or	O
deeper	O
?	O
	
To	O
summarize	O
the	O
previous	O
subsections	O
,	O
shortcut	O
connections	O
enable	O
us	O
to	O
train	O
wider	O
and	O
deeper	B-Method
networks	I-Method
.	O
	
As	O
they	O
growing	O
to	O
some	O
point	O
,	O
we	O
will	O
face	O
the	O
dilemma	O
between	O
width	O
and	O
depth	O
.	O
	
From	O
that	O
point	O
,	O
going	O
deep	O
,	O
we	O
will	O
actually	O
get	O
a	O
wider	O
network	O
,	O
with	O
extra	O
features	O
which	O
are	O
not	O
completely	O
end	O
-	O
to	O
-	O
end	O
trained	O
;	O
going	O
wider	O
,	O
we	O
will	O
literally	O
get	O
a	O
wider	O
network	O
,	O
without	O
changing	O
its	O
end	O
-	O
to	O
-	O
end	O
characteristic	O
.	O
	
We	O
have	O
learned	O
the	O
strength	O
of	O
depth	O
from	O
the	O
previous	O
plain	B-Method
deep	I-Method
networks	I-Method
without	O
any	O
shortcuts	O
,	O
e.g.	O
,	O
the	O
AlexNet	B-Method
and	O
VGGNets	B-Method
.	O
	
However	O
,	O
it	O
is	O
not	O
clear	O
whether	O
those	O
extra	O
features	O
in	O
very	O
deep	B-Method
residual	I-Method
networks	I-Method
can	O
perform	O
as	O
well	O
as	O
conventional	O
fully	O
end	O
-	O
to	O
-	O
end	O
trained	O
features	O
.	O
	
So	O
in	O
this	O
paper	O
,	O
we	O
only	O
favour	O
a	O
deeper	B-Method
model	I-Method
,	O
when	O
it	O
can	O
be	O
completely	O
end	O
-	O
to	O
-	O
end	O
trained	O
.	O
	
In	O
practice	O
,	O
algorithms	O
are	O
often	O
limited	O
by	O
their	O
spatial	B-Metric
costs	I-Metric
.	O
	
One	O
way	O
is	O
to	O
use	O
more	O
devices	O
,	O
which	O
will	O
however	O
increase	O
communication	B-Metric
costs	I-Metric
among	O
them	O
.	O
	
With	O
similar	O
memory	O
costs	O
,	O
a	O
shallower	B-Method
but	I-Method
wider	I-Method
network	I-Method
can	O
have	O
times	O
more	O
number	O
of	O
trainable	O
parameters	O
.	O
	
Therefore	O
,	O
given	O
the	O
following	O
observations	O
in	O
the	O
literature	O
,	O
Zagoruyko	O
and	O
Komodakis	O
found	O
that	O
the	O
performance	O
of	O
a	O
ResNet	B-Method
was	O
related	O
to	O
the	O
number	O
of	O
trainable	O
parameters	O
.	O
	
Szegedy	O
et	O
al	O
.	O
came	O
to	O
a	O
similar	O
conclusion	O
,	O
according	O
to	O
the	O
comparison	O
between	O
their	O
proposed	O
Inception	B-Method
networks	I-Method
.	O
	
Veit	O
et	O
al	O
.	O
found	O
that	O
there	O
is	O
a	O
relatively	O
small	O
effective	O
depth	O
for	O
a	O
very	O
deep	O
ResNet	B-Method
,	O
e.g.	O
,	O
seventeen	O
residual	O
units	O
for	O
a	O
110	O
-	O
layer	O
ResNet	B-Method
.	O
	
most	O
of	O
the	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
on	O
the	O
ImageNet	B-Task
classification	O
dataset	O
seem	O
over	O
-	O
deepened	O
,	O
e.g.	O
,	O
the	O
200	B-Method
-	I-Method
layer	I-Method
ResNet	I-Method
and	O
96	B-Method
-	I-Method
layer	I-Method
Inception	I-Method
-	I-Method
ResNet	I-Method
.	O
	
The	O
reason	O
is	O
that	O
,	O
to	O
effectively	O
utilize	O
GPU	O
memories	O
,	O
we	O
should	O
make	O
a	O
model	B-Method
shallow	I-Method
.	O
	
According	O
to	O
our	O
previous	O
analysis	O
,	O
paths	O
longer	O
than	O
the	O
effective	O
depth	O
in	O
ResNets	B-Method
are	O
not	O
trained	O
in	O
a	O
fully	O
end	O
-	O
to	O
-	O
end	O
manner	O
.	O
	
Thus	O
,	O
we	O
can	O
remove	O
most	O
of	O
these	O
paths	O
by	O
directly	O
reducing	O
the	O
number	O
of	O
residual	O
units	O
.	O
	
For	O
example	O
,	O
in	O
our	O
best	O
performing	O
network	O
,	O
there	O
are	O
exactly	O
seventeen	O
residual	O
units	O
.	O
	
With	O
empirical	O
results	O
,	O
we	O
will	O
show	O
that	O
our	O
fully	B-Method
end	I-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
networks	I-Method
can	O
perform	O
much	O
better	O
than	O
the	O
previous	O
much	O
deeper	O
ResNets	B-Method
,	O
especially	O
as	O
feature	B-Method
extractors	I-Method
.	O
	
However	O
,	O
even	O
if	O
a	O
rather	O
shallow	B-Method
network	I-Method
(	O
eight	O
-	O
unit	O
,	O
or	O
twenty	B-Method
-	I-Method
layer	I-Method
)	O
can	O
outperform	O
ResNet	B-Method
-	I-Method
152	I-Method
on	O
the	O
ImageNet	B-Task
classification	O
dataset	O
,	O
we	O
will	O
not	O
go	O
that	O
shallow	O
,	O
because	O
an	O
appropriate	O
depth	O
is	O
vital	O
to	O
train	O
good	O
features	O
.	O
	
section	O
:	O
Approach	O
to	O
image	B-Task
classification	I-Task
	
We	O
show	O
the	O
proposed	O
networks	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
There	O
are	O
three	O
architectures	O
,	O
with	O
different	O
input	O
sizes	O
.	O
	
Dashed	O
blue	O
rectangles	O
to	O
denote	O
convolution	O
stages	O
,	O
which	O
are	O
respectively	O
composed	O
of	O
a	O
batch	B-Method
normalization	I-Method
,	O
an	O
ReLU	B-Method
non	O
-	O
linearity	O
and	O
a	O
convolution	B-Method
layer	I-Method
,	O
following	O
the	O
second	O
version	O
of	O
ResNets	B-Method
.	O
	
The	O
closely	O
stacked	O
two	O
or	O
three	O
convolution	B-Method
stages	I-Method
denote	O
different	O
kinds	O
of	O
residual	O
units	O
(	O
B1–B7	O
)	O
,	O
with	O
inner	O
shortcut	O
connections	O
.	O
	
Each	O
kind	O
corresponds	O
to	O
a	O
level	O
,	O
where	O
all	O
units	O
share	O
the	O
same	O
kernel	O
sizes	O
and	O
numbers	O
of	O
channels	O
,	O
as	O
given	O
in	O
the	O
dashed	O
black	O
rectangles	O
in	O
the	O
left	O
-	O
most	O
column	O
of	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
As	O
mentioned	O
before	O
,	O
there	O
are	O
two	O
3	O
3	O
convolution	B-Method
layers	I-Method
in	O
most	O
residual	O
units	O
(	O
B1–B5	O
)	O
.	O
	
However	O
,	O
in	O
B6	O
and	O
B7	O
,	O
we	O
use	O
bottleneck	O
structures	O
as	O
in	O
ResNets	B-Method
,	O
except	O
that	O
we	O
adjust	O
the	O
numbers	O
of	O
channels	O
to	O
avoid	O
drastic	O
changes	O
in	O
width	O
.	O
	
Each	O
of	O
our	O
networks	O
usually	O
consists	O
of	O
one	O
B6	O
,	O
one	O
B7	O
,	O
and	O
different	O
numbers	O
of	O
B1–B5	O
.	O
	
For	O
those	O
with	O
a	O
224	O
224	O
input	O
,	O
we	O
do	O
not	O
use	O
B1	O
due	O
to	O
limited	O
GPU	O
memories	O
.	O
	
Each	O
of	O
the	O
green	O
triangles	O
denotes	O
a	O
down	B-Method
-	I-Method
sampling	I-Method
operation	I-Method
with	O
a	O
rate	O
of	O
two	O
,	O
which	O
is	O
clear	O
given	O
the	O
feature	O
map	O
sizes	O
of	O
different	O
convolution	B-Method
stages	I-Method
(	O
in	O
dashed	O
blue	O
rectangles	O
)	O
.	O
	
To	O
this	O
end	O
,	O
we	O
can	O
let	O
the	O
first	O
convolution	B-Method
layer	I-Method
at	O
according	O
levels	O
have	O
a	O
stride	O
of	O
two	O
.	O
	
Or	O
,	O
we	O
can	O
use	O
an	O
extra	O
spatial	B-Method
pooling	I-Method
layer	I-Method
,	O
whose	O
kernel	O
size	O
is	O
three	O
and	O
stride	O
is	O
two	O
.	O
	
In	O
a	O
network	O
whose	O
classification	B-Task
results	O
are	O
reported	O
in	O
this	O
paper	O
,	O
we	O
always	O
use	O
pooling	B-Method
layers	I-Method
for	O
down	B-Task
-	I-Task
sampling	I-Task
.	O
	
We	O
average	O
the	O
top	O
-	O
most	O
feature	O
maps	O
into	O
4	O
,	O
096	O
-	O
dimensional	O
final	O
features	O
,	O
which	O
matches	O
the	O
cases	O
of	O
AlexNet	B-Method
and	O
VGGNets	B-Method
.	O
	
We	O
will	O
show	O
more	O
details	O
about	O
network	O
structures	O
in	O
Subsection	O
[	O
reference	O
]	O
.	O
	
Implementation	O
details	O
.	O
	
We	O
run	O
all	O
experiments	O
using	O
the	O
MXNet	B-Method
framework	I-Method
,	O
with	O
four	O
devices	O
(	O
two	O
K80	O
or	O
four	O
Maxwell	O
Titan	O
X	O
cards	O
)	O
on	O
a	O
single	O
node	O
.	O
	
We	O
follow	O
settings	O
in	O
the	O
re	O
-	O
implementation	O
of	O
ResNets	B-Method
by	O
Gross	O
and	O
Wilber	O
as	O
possible	O
.	O
	
But	O
,	O
we	O
use	O
a	O
linear	B-Method
learning	I-Method
rate	I-Method
schedule	I-Method
,	O
which	O
was	O
reported	O
as	O
a	O
better	O
choice	O
by	O
Mishkin	O
et	O
al	O
.	O
.	O
	
Take	O
Model	O
A	O
in	O
Table	O
[	O
reference	O
]	O
for	O
example	O
.	O
	
We	O
start	O
from	O
0.1	O
,	O
and	O
linearly	O
reduce	O
the	O
learning	B-Metric
rate	I-Metric
to	O
within	O
450k	O
iterations	O
.	O
	
section	O
:	O
Approach	O
to	O
semantic	B-Task
image	I-Task
segmentation	I-Task
	
Our	O
approach	O
is	O
similar	O
to	O
the	O
fully	B-Method
convolutional	I-Method
networks	I-Method
(	O
FCN	B-Method
)	O
implemented	O
in	O
the	O
first	O
version	O
of	O
DeepLab	B-Method
.	O
	
However	O
,	O
without	O
getting	O
too	O
many	O
factors	O
entangled	O
,	O
we	O
in	O
this	O
paper	O
do	O
not	O
introduce	O
any	O
multi	O
-	O
scale	O
structures	O
,	O
deep	O
supervision	O
signals	O
,	O
or	O
global	O
context	O
features	O
.	O
	
Besides	O
,	O
we	O
do	O
not	O
apply	O
any	O
multi	B-Method
-	I-Method
scale	I-Method
testing	I-Method
,	O
model	B-Method
averaging	I-Method
or	O
CRF	B-Method
based	I-Method
post	I-Method
-	I-Method
processing	I-Method
,	O
except	O
for	O
the	O
test	O
set	O
of	O
ADE20	B-Material
K	I-Material
.	O
	
Given	O
a	O
pre	O
-	O
trained	B-Method
network	I-Method
,	O
there	O
are	O
three	O
steps	O
to	O
reshape	O
it	O
into	O
a	O
network	O
suitable	O
for	O
semantic	B-Task
image	I-Task
segmentation	I-Task
,	O
as	O
stated	O
below	O
.	O
	
1	O
)	O
Resolution	B-Metric
.	O
	
To	O
generate	O
score	O
maps	O
at	O
1	O
/	O
8	O
resolution	O
,	O
we	O
remove	O
down	O
-	O
sampling	O
operations	O
and	O
increase	O
dilation	B-Metric
rates	I-Metric
accordingly	O
in	O
some	O
convolution	B-Method
layers	I-Method
.	O
	
For	O
clarity	O
,	O
first	O
suppose	O
that	O
we	O
always	O
down	O
-	O
sample	O
features	O
maps	O
using	O
a	O
convolution	B-Method
layer	I-Method
with	O
a	O
stride	O
of	O
two	O
.	O
	
Take	O
networks	O
with	O
224	O
224	O
inputs	O
for	O
example	O
.	O
	
We	O
set	O
stride	O
of	O
the	O
first	O
convolution	B-Method
layer	I-Method
in	O
B5	O
to	O
one	O
,	O
and	O
increase	O
the	O
dilation	B-Metric
rate	I-Metric
from	O
one	O
to	O
two	O
for	O
the	O
following	O
layers	O
;	O
We	O
do	O
the	O
same	O
thing	O
to	O
the	O
first	O
convolution	B-Method
layer	I-Method
in	O
B6	O
too	O
,	O
and	O
increase	O
the	O
dilation	B-Metric
rate	I-Metric
from	O
two	O
to	O
four	O
for	O
the	O
following	O
layers	O
.	O
	
In	O
the	O
case	O
of	O
down	B-Task
-	I-Task
sampling	I-Task
using	O
a	O
pooling	B-Method
layer	I-Method
,	O
everything	O
is	O
the	O
same	O
except	O
that	O
we	O
set	O
stride	O
of	O
that	O
pooling	B-Method
layer	I-Method
to	O
one	O
.	O
	
Sometimes	O
,	O
we	O
will	O
have	O
to	O
apply	O
a	O
pooling	B-Method
layer	I-Method
with	O
dilation	B-Method
.	O
	
On	O
the	O
other	O
hand	O
,	O
we	O
do	O
not	O
make	O
any	O
change	O
for	O
networks	O
with	O
56	O
56	O
inputs	O
,	O
since	O
there	O
are	O
only	O
three	O
down	B-Method
-	I-Method
sampling	I-Method
operations	I-Method
in	O
each	O
of	O
them	O
.	O
	
It	O
is	O
notable	O
that	O
all	O
down	B-Method
-	I-Method
sampling	I-Method
operations	I-Method
are	O
implemented	O
using	O
spatial	B-Method
pooling	I-Method
layers	I-Method
in	O
our	O
originally	O
pre	B-Method
-	I-Method
trained	I-Method
networks	I-Method
.	O
	
We	O
find	O
it	O
harmful	O
for	O
FCNs	B-Method
in	O
our	O
preliminary	O
experiments	O
,	O
probably	O
due	O
to	O
too	O
strong	O
spatial	O
invariance	O
.	O
	
To	O
this	O
end	O
,	O
we	O
replace	O
several	O
top	B-Method
-	I-Method
most	I-Method
down	I-Method
-	I-Method
sampling	I-Method
operations	I-Method
in	O
a	O
network	O
,	O
and	O
then	O
tune	O
it	O
for	O
some	O
additional	O
iterations	O
.	O
	
Take	O
Model	O
A	O
in	O
Table	O
[	O
reference	O
]	O
for	O
example	O
again	O
.	O
	
We	O
remove	O
the	O
top	O
-	O
most	O
three	O
pooling	O
layers	O
(	O
before	O
B4	O
,	O
B5	O
and	O
B6	O
)	O
,	O
increase	O
the	O
strides	O
of	O
according	O
convolution	B-Method
layers	I-Method
up	O
to	O
two	O
,	O
and	O
tune	O
it	O
for	O
45k	O
iterations	O
using	O
the	O
ImageNet	B-Task
dataset	O
,	O
starting	O
from	O
a	O
learning	B-Metric
rate	I-Metric
of	O
0.01	O
.	O
2	O
)	O
Classifier	B-Method
.	O
	
We	O
remove	O
the	O
top	O
-	O
most	O
linear	B-Method
classifier	I-Method
and	O
the	O
global	B-Method
pooling	I-Method
layer	I-Method
,	O
and	O
then	O
consider	O
two	O
cases	O
.	O
	
For	O
one	O
thing	O
,	O
we	O
follow	O
a	O
basic	O
large	O
field	O
-	O
of	O
-	O
view	O
setting	O
in	O
DeepLab	B-Method
-	I-Method
v2	I-Method
,	O
called	O
‘	O
1	B-Method
convolution	I-Method
’	O
.	O
	
Namely	O
,	O
we	O
just	O
add	O
back	O
a	O
single	O
linear	B-Method
layer	I-Method
as	O
the	O
new	O
classifier	B-Method
.	O
	
For	O
anther	B-Task
,	O
we	O
insert	O
an	O
additional	O
non	B-Method
-	I-Method
linear	I-Method
convolution	I-Method
stage	I-Method
(	O
without	O
batch	B-Method
normalization	I-Method
)	O
below	O
the	O
linear	B-Method
classifier	I-Method
.	O
	
This	O
case	O
is	O
called	O
‘	O
2	B-Method
convolutions	I-Method
’	O
.	O
	
Both	O
of	O
the	O
added	O
layers	O
have	O
3	O
3	O
kernels	O
,	O
with	O
a	O
dilation	B-Metric
rate	I-Metric
of	O
twelve	O
.	O
	
The	O
top	O
-	O
most	O
two	O
-	O
layer	B-Method
classifier	I-Method
thus	O
has	O
a	O
receptive	O
field	O
of	O
392	O
392	O
on	O
the	O
final	O
feature	O
maps	O
.	O
	
By	O
default	O
,	O
we	O
let	O
the	O
number	O
of	O
channels	O
in	O
the	O
hidden	O
layer	O
be	O
512	O
.	O
	
3	O
)	O
Dropout	O
.	O
	
To	O
alleviate	O
over	B-Task
-	I-Task
fitting	I-Task
,	O
we	O
also	O
apply	O
the	O
traditional	O
dropout	B-Method
to	O
very	O
wide	O
residual	O
units	O
.	O
	
The	O
dropout	B-Metric
rate	I-Metric
is	O
0.3	O
for	O
those	O
with	O
2	O
,	O
048	O
channels	O
,	O
e.g.	O
,	O
the	O
last	O
three	O
units	O
in	O
ResNets	B-Method
and	O
the	O
second	O
last	O
units	O
(	O
B6	O
)	O
in	O
our	O
networks	O
;	O
while	O
0.5	O
for	O
those	O
with	O
4	O
,	O
096	O
channels	O
,	O
e.g.	O
,	O
the	O
top	O
-	O
most	O
units	O
(	O
B7	O
)	O
in	O
our	O
networks	O
.	O
	
Implementation	O
details	O
.	O
	
We	O
fix	O
the	O
moving	O
means	O
and	O
variations	O
in	O
batch	B-Method
normalization	I-Method
layers	I-Method
during	O
fine	B-Task
-	I-Task
tuning	I-Task
.	O
	
We	O
use	O
four	O
devices	O
on	O
a	O
single	O
node	O
.	O
	
The	O
batch	O
size	O
is	O
sixteen	O
,	O
so	O
there	O
are	O
four	O
examples	O
per	O
device	O
.	O
	
We	O
first	O
tune	O
each	O
network	O
for	O
a	O
number	O
of	O
iterations	O
,	O
keeping	O
the	O
learning	B-Metric
rate	I-Metric
unchanged	O
at	O
0.0016	O
.	O
	
And	O
then	O
,	O
we	O
reduce	O
the	O
learning	B-Metric
rate	I-Metric
gradually	O
during	O
another	O
number	O
of	O
iterations	O
,	O
following	O
a	O
linear	B-Method
schedule	I-Method
.	O
	
For	O
datasets	O
with	O
available	O
testing	O
sets	O
,	O
we	O
evaluate	O
these	O
numbers	O
of	O
iterations	O
on	O
validation	O
sets	O
.	O
	
During	O
training	B-Task
,	O
we	O
first	O
resize	O
an	O
image	O
by	O
a	O
ratio	O
randomly	O
sampled	O
from	O
,	O
and	O
then	O
generate	O
a	O
sample	O
by	O
cropping	O
one	O
500	O
500	O
sub	O
-	O
window	O
at	O
a	O
randomly	O
selected	O
location	O
.	O
	
section	O
:	O
Experimental	O
results	O
	
subsection	O
:	O
Image	B-Task
classification	I-Task
results	O
	
We	O
evaluate	O
our	O
proposed	O
networks	O
on	O
the	O
ILSVRC	B-Task
2012	I-Task
classification	O
dataset	O
,	O
with	O
1.28	O
million	O
images	O
for	O
training	O
,	O
respectively	O
belonging	O
to	O
1	O
,	O
000	O
categories	O
.	O
	
We	O
report	O
top	B-Metric
-	I-Metric
1	I-Metric
and	I-Metric
top	I-Metric
-	I-Metric
5	I-Metric
error	I-Metric
rates	I-Metric
on	O
the	O
validation	O
set	O
.	O
	
We	O
compare	O
various	O
networks	O
in	O
Table	O
[	O
reference	O
]	O
,	O
where	O
we	O
obtain	O
all	O
the	O
results	O
by	O
testing	O
on	O
a	O
single	O
crop	O
.	O
	
However	O
,	O
we	O
list	O
the	O
ten	O
-	O
crop	O
result	O
for	O
VGG16	B-Method
since	O
it	O
is	O
not	O
inherently	O
a	O
fully	B-Method
convolutional	I-Method
network	I-Method
.	O
	
For	O
networks	O
trained	O
with	O
224	O
224	O
inputs	O
,	O
the	O
testing	O
crop	O
size	O
is	O
320	O
320	O
,	O
following	O
the	O
setting	O
used	O
by	O
He	O
et	O
al	O
.	O
.	O
	
For	O
those	O
with	O
112	O
112	O
and	O
56	O
56	O
inputs	O
,	O
we	O
use	O
160	O
160	O
and	O
80	O
80	O
crops	O
respectively	O
.	O
	
For	O
Inception	B-Task
networks	I-Task
,	O
the	O
testing	O
crop	B-Metric
size	I-Metric
is	O
299	O
299	O
.	O
	
The	O
names	O
of	O
our	O
proposed	O
networks	O
are	O
composed	O
of	O
training	O
crop	O
sizes	O
and	O
the	O
numbers	O
of	O
residual	O
units	O
on	O
different	O
levels	O
.	O
	
Take	O
56	O
-	O
1	O
-	O
1	O
-	O
1	O
-	O
1	O
-	O
9	O
-	O
1	O
-	O
1	O
for	O
example	O
.	O
	
Its	O
input	O
size	O
is	O
56	O
,	O
and	O
there	O
are	O
only	O
one	O
unit	O
on	O
all	O
levels	O
except	O
for	O
Level	O
5	O
(	O
B5	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
Notable	O
points	O
about	O
the	O
results	O
are	O
as	O
follows	O
.	O
	
1	O
)	O
Relatively	O
shallow	B-Method
networks	I-Method
can	O
outperform	O
very	O
deep	O
ones	O
,	O
which	O
is	O
probably	O
due	O
to	O
large	O
model	O
capacity	O
,	O
coinciding	O
with	O
the	O
results	O
reported	O
by	O
Zagoruyko	O
and	O
Komodakis	O
.	O
	
For	O
example	O
,	O
the	O
much	O
shallower	B-Method
Model	I-Method
B	I-Method
achieves	O
similar	O
error	B-Metric
rates	I-Metric
as	O
ResNet	B-Method
-	I-Method
152	I-Method
,	O
and	O
even	O
runs	O
slightly	O
faster	O
.	O
	
And	O
particularly	O
,	O
Model	O
A	O
performs	O
the	O
best	O
among	O
all	O
the	O
networks	O
.	O
	
2	O
)	O
	
We	O
can	O
trade	O
performance	O
for	O
efficiency	O
by	O
using	O
a	O
small	O
input	O
size	O
.	O
	
For	O
example	O
,	O
Model	O
D	O
performs	O
slightly	O
worse	O
than	O
ResNet	B-Method
-	I-Method
152	I-Method
,	O
but	O
is	O
almost	O
two	O
times	O
faster	O
.	O
	
This	O
may	O
be	O
useful	O
when	O
efficiency	O
is	O
strictly	O
required	O
.	O
	
Mishkin	O
et	O
al	O
.	O
also	O
reduced	O
the	O
input	O
size	O
for	O
efficiency	O
.	O
	
However	O
,	O
they	O
did	O
not	O
remove	O
down	O
-	O
sampling	O
operations	O
accordingly	O
to	O
preserve	O
the	O
size	O
of	O
final	O
feature	O
maps	O
,	O
which	O
resulted	O
in	O
much	O
degraded	O
performance	O
.	O
	
3	O
)	O
Models	O
C	O
,	O
D	O
and	O
E	O
perform	O
comparably	O
,	O
even	O
though	O
Model	O
C	O
has	O
larger	O
depth	O
and	O
more	O
parameters	O
.	O
	
This	O
comparison	O
shows	O
the	O
importance	O
of	O
designing	O
a	O
network	O
properly	O
.	O
	
In	O
these	O
models	O
,	O
we	O
put	O
too	O
many	O
layers	O
on	O
low	O
resolution	O
levels	O
(	O
7	O
7	O
,	O
B5	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
subsection	O
:	O
Semantic	B-Task
image	I-Task
segmentation	I-Task
results	O
	
We	O
evaluate	O
our	O
proposed	O
networks	O
on	O
four	O
widely	O
used	O
datasets	O
.	O
	
When	O
available	O
,	O
we	O
report	O
,	O
1	O
)	O
the	O
pixel	B-Metric
accuracy	I-Metric
,	O
which	O
is	O
the	O
percentage	O
of	O
correctly	O
labelled	O
pixels	O
on	O
a	O
whole	O
test	O
set	O
,	O
2	O
)	O
the	O
mean	B-Metric
pixel	I-Metric
accuracy	I-Metric
,	O
which	O
is	O
the	O
mean	O
of	O
class	B-Metric
-	I-Metric
wise	I-Metric
pixel	I-Metric
accuracies	I-Metric
,	O
and	O
3	O
)	O
the	O
mean	B-Metric
IoU	I-Metric
score	I-Metric
,	O
which	O
is	O
the	O
mean	O
of	O
class	B-Metric
-	I-Metric
wise	I-Metric
intersection	I-Metric
-	I-Metric
over	I-Metric
-	I-Metric
union	I-Metric
scores	I-Metric
.	O
	
PASCAL	B-Material
VOC	I-Material
2012	I-Material
.	O
	
This	O
dataset	O
consists	O
of	O
daily	O
life	O
photos	O
.	O
	
There	O
are	O
1	O
,	O
464	O
labelled	O
images	O
for	O
training	O
and	O
another	O
1	O
,	O
449	O
for	O
validation	B-Task
.	O
	
Pixels	O
either	O
belong	O
to	O
the	O
background	O
or	O
twenty	O
object	O
categories	O
,	O
including	O
bus	O
,	O
car	O
,	O
cat	O
,	O
sofa	O
,	O
monitor	O
,	O
etc	O
.	O
	
Following	O
the	O
common	O
criteria	O
in	O
the	O
literature	O
,	O
we	O
augment	O
the	O
dataset	O
with	O
extra	O
labelled	O
images	O
from	O
the	O
semantic	O
boundaries	O
dataset	O
.	O
	
So	O
in	O
total	O
,	O
there	O
are	O
10	O
,	O
582	O
images	O
for	O
training	O
.	O
	
We	O
first	O
compare	O
different	O
networks	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Notable	O
points	O
about	O
the	O
results	O
are	O
as	O
follows	O
.	O
	
1	O
)	O
	
We	O
can	O
not	O
make	O
statistically	O
significant	O
improvement	O
by	O
using	O
ResNet	B-Method
-	I-Method
152	I-Method
instead	O
of	O
ResNet	B-Method
-	I-Method
101	I-Method
.	O
	
However	O
,	O
Model	O
A	O
performs	O
better	O
than	O
ResNet	B-Method
-	I-Method
152	I-Method
by	O
3.4	O
%	O
.	O
	
Using	O
one	O
hidden	B-Method
layer	I-Method
leads	O
to	O
a	O
further	O
improvement	O
by	O
2.1	O
%	O
.	O
	
2	O
)	O
	
The	O
very	O
deep	O
ResNet	B-Method
-	I-Method
152	I-Method
uses	O
too	O
many	O
memories	O
due	O
to	O
intentionally	O
enlarged	O
depth	O
.	O
	
With	O
our	O
settings	O
,	O
it	O
even	O
can	O
not	O
be	O
tuned	O
using	O
many	O
mainstream	O
GPUs	B-Method
with	O
only	O
12	O
GB	O
memories	O
.	O
	
3	O
)	O
	
Model	O
B	O
performs	O
worse	O
than	O
ResNet	B-Method
-	I-Method
101	I-Method
,	O
even	O
if	O
it	O
performs	O
better	O
on	O
the	O
classification	B-Task
task	I-Task
as	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
This	O
shows	O
that	O
it	O
is	O
not	O
reliable	O
to	O
tell	O
a	O
good	O
feature	B-Method
extractor	I-Method
only	O
depending	O
on	O
its	O
classification	B-Task
performance	O
.	O
	
And	O
it	O
again	O
shows	O
why	O
we	O
should	O
favour	O
deeper	O
models	O
.	O
	
4	O
)	O
Model	O
A2	O
performs	O
worse	O
than	O
Model	O
A	O
on	O
this	O
dataset	O
.	O
	
We	O
initialize	O
it	O
using	O
weights	O
from	O
Model	O
A	O
,	O
and	O
tune	O
it	O
with	O
the	O
Places	B-Material
365	I-Material
data	I-Material
for	O
45k	O
iterations	O
.	O
	
This	O
is	O
reasonable	O
since	O
there	O
are	O
only	O
object	O
categories	O
in	O
this	O
dataset	O
,	O
while	O
Places	O
365	O
is	O
for	O
scene	B-Task
classification	I-Task
tasks	I-Task
.	O
	
We	O
then	O
compare	O
our	O
method	O
with	O
previous	O
ones	O
on	O
the	O
test	O
set	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Only	O
using	O
the	O
augmented	B-Material
PASCAL	I-Material
VOC	I-Material
data	I-Material
for	O
training	O
,	O
we	O
achieve	O
a	O
mean	B-Metric
IoU	I-Metric
score	I-Metric
of	O
82.5	O
%	O
,	O
which	O
is	O
better	O
than	O
the	O
previous	O
best	O
one	O
by	O
3.4	O
%	O
.	O
	
This	O
is	O
a	O
significant	O
margin	O
,	O
considering	O
that	O
the	O
gap	O
between	O
ResNet	B-Method
-	I-Method
based	I-Method
and	O
VGGNet	B-Method
-	I-Method
based	I-Method
methods	I-Method
is	O
3.8	O
%	O
.	O
	
Our	O
method	O
wins	O
for	O
seventeen	O
out	O
of	O
the	O
twenty	O
object	O
categories	O
,	O
which	O
was	O
the	O
official	O
criteria	O
used	O
in	O
the	O
PASCAL	B-Material
VOC	I-Material
challenges	I-Material
.	O
	
In	O
some	O
works	O
,	O
models	O
were	O
further	O
pre	O
-	O
trained	O
using	O
the	O
Microsoft	B-Material
COCO	I-Material
data	I-Material
,	O
which	O
consists	O
of	O
120k	O
labelled	O
images	O
.	O
	
In	O
this	O
case	O
,	O
the	O
current	O
best	O
mean	B-Metric
IoU	I-Metric
is	O
79.7	O
%	O
reported	O
by	O
Chen	O
et	O
al	O
.	O
.	O
	
They	O
also	O
used	O
multi	B-Method
-	I-Method
scale	I-Method
structure	I-Method
and	O
CRF	B-Method
-	I-Method
based	I-Method
post	I-Method
-	I-Method
processing	I-Method
in	O
their	O
submission	O
,	O
which	O
we	O
do	O
not	O
consider	O
here	O
.	O
	
Nevertheless	O
,	O
our	O
method	O
outperforms	O
theirs	O
by	O
2.8	O
%	O
,	O
which	O
further	O
shows	O
the	O
effectiveness	O
of	O
our	O
features	O
pre	O
-	O
trained	O
only	O
using	O
the	O
ImageNet	B-Task
classification	O
data	O
.	O
	
aero	O
.	O
	
bicy	O
.	O
	
bird	O
boat	O
bott	O
.	O
	
bus	O
car	O
cat	O
chai	O
.	O
	
cow	O
dini	O
.	O
	
dog	O
hors	O
.	O
	
moto	O
.	O
	
pers	O
.	O
	
pott	O
.	O
	
shee	O
.	O
	
sofa	O
trai	O
.	O
	
tvmo	O
.	O
	
mean	O
Cityscapes	B-Material
.	O
	
This	O
dataset	O
consists	O
of	O
street	O
scene	O
photos	O
taken	O
by	O
car	O
-	O
carried	O
cameras	O
.	O
	
There	O
are	O
2975	O
labelled	O
images	O
for	O
training	O
and	O
another	O
500	O
for	O
validation	B-Task
.	O
	
Besides	O
,	O
there	O
is	O
also	O
an	O
extended	O
set	O
with	O
19	O
,	O
998	O
coarsely	O
labelled	O
images	O
.	O
	
Pixels	O
belong	O
to	O
nineteen	O
semantic	O
classes	O
,	O
including	O
road	O
,	O
car	O
,	O
pedestrian	O
,	O
bicycle	O
,	O
etc	O
.	O
	
These	O
classes	O
further	O
belong	O
to	O
seven	O
categories	O
,	O
i.e.	O
,	O
flat	O
,	O
nature	O
,	O
object	O
,	O
sky	O
,	O
construction	O
,	O
human	O
,	O
and	O
vehicle	O
.	O
	
We	O
first	O
compare	O
different	O
networks	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
On	O
this	O
dataset	O
,	O
ResNet	B-Method
-	I-Method
152	I-Method
again	O
shows	O
no	O
advantage	O
against	O
ResNet	B-Method
-	I-Method
101	I-Method
.	O
	
However	O
,	O
Model	O
A1	O
outperforms	O
ResNet	B-Method
-	I-Method
101	I-Method
by	O
4.2	O
%	O
in	O
terms	O
of	O
mean	B-Metric
IoU	I-Metric
scores	O
,	O
which	O
again	O
is	O
a	O
significant	O
margin	O
.	O
	
Because	O
there	O
are	O
many	O
scene	O
classes	O
,	O
models	O
pre	O
-	O
trained	O
using	O
Places	O
365	O
are	O
supposed	O
to	O
perform	O
better	O
,	O
which	O
coincides	O
with	O
our	O
results	O
.	O
	
We	O
then	O
compare	O
our	O
method	O
with	O
previous	O
ones	O
on	O
the	O
test	O
set	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
The	O
official	B-Metric
criteria	I-Metric
on	O
this	O
dataset	O
includes	O
two	O
levels	O
,	O
i.e.	O
,	O
class	O
and	O
category	O
.	O
	
Besides	O
,	O
there	O
is	O
also	O
an	O
instance	O
-	O
weighted	O
IoU	B-Metric
score	I-Metric
for	O
each	O
of	O
the	O
two	O
,	O
which	O
assigns	O
high	O
scores	O
to	O
those	O
pixels	O
of	O
small	O
instances	O
.	O
	
Namely	O
,	O
this	O
score	O
penalizes	O
methods	O
ignoring	O
small	O
instances	O
,	O
which	O
may	O
cause	O
fatal	O
problems	O
in	O
vehicle	B-Task
-	I-Task
centric	I-Task
scenarios	I-Task
.	O
	
Our	O
method	O
achieves	O
a	O
class	O
-	O
level	O
IoU	B-Metric
score	I-Metric
of	O
78.4	O
%	O
,	O
and	O
outperforms	O
the	O
previous	O
best	O
one	O
by	O
6.6	O
%	O
.	O
	
Furthermore	O
,	O
in	O
the	O
case	O
of	O
instance	O
-	O
weighted	O
IoU	B-Metric
score	I-Metric
,	O
our	O
method	O
also	O
performs	O
better	O
than	O
the	O
previous	O
best	O
one	O
by	O
6.4	O
%	O
.	O
	
It	O
is	O
notable	O
that	O
these	O
significant	O
improvements	O
show	O
the	O
strength	O
of	O
our	O
pre	O
-	O
trained	O
features	O
,	O
considering	O
that	O
DeepLab	B-Method
-	I-Method
v2	I-Method
uses	O
ResNet	B-Method
-	I-Method
101	I-Method
,	O
and	O
LRR	B-Method
uses	O
much	O
more	O
data	O
for	O
training	O
.	O
	
ADE20	B-Method
K	O
.	O
	
This	O
dataset	O
consists	O
of	O
both	O
indoor	O
and	O
outdoor	O
images	O
with	O
large	O
variations	O
.	O
	
There	O
are	O
20	O
,	O
210	O
labelled	O
images	O
for	O
training	O
and	O
another	O
2k	O
for	O
validation	B-Task
.	O
	
Pixels	O
belong	O
to	O
150	O
semantic	O
categories	O
,	O
including	O
sky	O
,	O
house	O
,	O
bottle	O
,	O
food	O
,	O
toy	O
,	O
etc	O
.	O
	
We	O
first	O
compare	O
different	O
networks	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
On	O
this	O
dataset	O
,	O
ResNet	B-Method
-	I-Method
152	I-Method
performs	O
slightly	O
better	O
than	O
ResNet	B-Method
-	I-Method
101	I-Method
.	O
	
However	O
,	O
Model	O
A2	O
outperforms	O
ResNet	B-Method
-	I-Method
152	I-Method
by	O
4.0	O
%	O
in	O
terms	O
of	O
mean	B-Metric
IoU	I-Metric
scores	O
.	O
	
Being	O
similar	O
with	O
Cityscapes	B-Material
,	O
this	O
dataset	O
has	O
many	O
scene	O
categories	O
.	O
	
So	O
,	O
Model	O
A2	O
performs	O
slightly	O
better	O
than	O
Model	O
A.	O
	
Another	O
notable	O
point	O
is	O
that	O
,	O
Model	O
C	O
takes	O
the	O
second	O
place	O
on	O
this	O
dataset	O
,	O
even	O
if	O
it	O
performs	O
worse	O
than	O
Model	O
A	O
in	O
the	O
image	B-Task
classification	I-Task
task	O
on	O
the	O
ImageNet	B-Task
dataset	O
.	O
	
This	O
shows	O
that	O
large	O
model	O
capacity	O
may	O
become	O
more	O
critical	O
in	O
complicated	O
tasks	O
,	O
since	O
there	O
are	O
more	O
parameters	O
in	O
Model	O
C.	O
	
We	O
then	O
compare	O
our	O
method	O
with	O
others	O
on	O
the	O
test	O
set	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
The	O
official	B-Metric
criteria	I-Metric
on	O
this	O
dataset	O
is	O
the	O
average	B-Metric
of	I-Metric
pixel	I-Metric
accuracies	I-Metric
and	O
mean	B-Metric
IoU	I-Metric
scores	O
.	O
	
For	O
better	O
performance	O
,	O
we	O
apply	O
multi	B-Method
-	I-Method
scale	I-Method
testing	I-Method
,	O
model	B-Method
averaging	I-Method
and	O
post	B-Method
-	I-Method
processing	I-Method
with	O
CRFs	B-Method
.	O
	
Our	O
Model	O
A2	O
performs	O
the	O
best	O
among	O
all	O
methods	O
using	O
only	O
a	O
single	O
pre	B-Method
-	I-Method
trained	I-Method
model	I-Method
.	O
	
However	O
,	O
in	O
this	O
submission	O
,	O
we	O
only	O
managed	O
to	O
include	O
two	O
kinds	O
of	O
pre	O
-	O
trained	O
features	O
,	O
i.e.	O
,	O
Models	O
A	O
and	O
C.	O
Nevertheless	O
,	O
our	O
method	O
only	O
performs	O
slightly	O
worse	O
than	O
the	O
winner	O
by	O
a	O
margin	O
of	O
0.47	O
%	O
.	O
	
PASCAL	B-Material
Context	I-Material
.	O
	
This	O
dataset	O
consists	O
of	O
images	O
from	O
PASCAL	B-Material
VOC	I-Material
2010	I-Material
with	O
extra	O
object	O
and	O
stuff	O
labels	O
.	O
	
There	O
are	O
4	O
,	O
998	O
images	O
for	O
training	O
and	O
another	O
5	O
,	O
105	O
for	O
validation	B-Task
.	O
	
Pixels	O
either	O
belong	O
to	O
the	O
background	O
category	O
or	O
59	O
semantic	O
categories	O
,	O
including	O
bag	O
,	O
food	O
,	O
sign	O
,	O
ceiling	O
,	O
ground	O
and	O
snow	O
.	O
	
All	O
images	O
in	O
this	O
dataset	O
are	O
no	O
larger	O
than	O
500	O
500	O
.	O
	
Since	O
the	O
test	O
set	O
is	O
not	O
available	O
,	O
here	O
we	O
directly	O
apply	O
the	O
hyper	O
-	O
parameters	O
which	O
are	O
used	O
on	O
the	O
PASCAL	B-Material
VOC	I-Material
dataset	I-Material
.	O
	
Our	O
method	O
again	O
performs	O
the	O
best	O
with	O
a	O
clear	O
margin	O
by	O
all	O
the	O
three	O
kinds	O
of	O
scores	O
,	O
as	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
In	O
particular	O
,	O
we	O
improve	O
the	O
IoU	B-Metric
score	I-Metric
by	O
2.4	O
%	O
compared	O
to	O
the	O
previous	O
best	O
method	O
.	O
	
section	O
:	O
Conclusion	O
	
We	O
have	O
analysed	O
the	O
ResNet	B-Method
architecture	O
,	O
in	O
terms	O
of	O
the	O
ensemble	B-Method
classifiers	I-Method
therein	O
and	O
the	O
effective	O
depths	O
of	O
the	O
residual	O
units	O
.	O
	
On	O
the	O
basis	O
of	O
that	O
analysis	O
we	O
calculated	O
a	O
new	O
,	O
more	O
spatially	O
efficient	O
,	O
and	O
better	O
performing	O
architecture	O
which	O
actually	O
achieves	O
fully	B-Task
end	I-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
training	I-Task
for	O
large	B-Task
networks	I-Task
.	O
	
Using	O
this	O
new	O
architecture	O
we	O
designed	O
a	O
group	O
of	O
correspondingly	B-Method
shallow	I-Method
networks	I-Method
,	O
and	O
showed	O
that	O
they	O
outperform	O
the	O
previous	O
very	O
deep	B-Method
residual	I-Method
networks	I-Method
not	O
only	O
on	O
the	O
ImageNet	B-Task
classification	O
dataset	O
,	O
but	O
also	O
when	O
applied	O
to	O
semantic	B-Task
image	I-Task
segmentation	I-Task
.	O
	
These	O
results	O
show	O
that	O
the	O
proposed	O
architecture	O
delivers	O
better	O
feature	B-Task
extraction	I-Task
performance	O
than	O
the	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
.	O
	
appendix	O
:	O
Appendix	O
	
subsection	O
:	O
Network	O
structures	O
	
The	O
graph	O
structures	O
of	O
Model	O
A	O
for	O
the	O
ImageNet	B-Task
(	O
ILSVRC	B-Task
2012	I-Task
)	O
classification	O
can	O
be	O
accessed	O
at	O
:	O
Model	O
A2	O
for	O
the	O
PASCAL	B-Task
VOC	I-Task
2012	I-Task
segmentation	I-Task
can	O
be	O
accessed	O
at	O
:	O
.	O
	
subsection	O
:	O
Gradients	O
in	O
residual	B-Method
networks	I-Method
	
We	O
show	O
results	O
of	O
the	O
experiment	O
on	O
gradients	B-Method
proposed	O
by	O
Veit	O
et	O
al	O
.	O
,	O
with	O
various	O
residual	B-Method
networks	I-Method
.	O
	
Namely	O
,	O
for	O
a	O
trained	B-Method
network	I-Method
with	O
units	O
,	O
we	O
sample	O
individual	O
paths	O
of	O
a	O
certain	O
length	O
,	O
and	O
measure	O
the	O
norm	O
of	O
gradients	O
that	O
arrive	O
at	O
the	O
input	O
.	O
	
Each	O
time	O
,	O
we	O
first	O
feed	O
a	O
batch	O
forward	O
through	O
the	O
whole	O
network	O
;	O
then	O
during	O
the	O
backward	O
pass	O
,	O
we	O
randomly	O
sample	O
units	O
.	O
	
For	O
them	O
,	O
we	O
only	O
propagate	O
gradients	O
through	O
their	O
trainable	B-Method
mapping	I-Method
functions	I-Method
,	O
but	O
without	O
their	O
shortcut	O
connections	O
.	O
	
For	O
the	O
remaining	O
units	O
,	O
we	O
do	O
the	O
opposite	O
,	O
namely	O
,	O
only	O
propagating	O
gradients	O
through	O
their	O
shortcut	O
connections	O
.	O
	
We	O
record	O
the	O
norm	O
of	O
those	O
gradients	O
that	O
reach	O
the	O
input	O
for	O
varying	O
path	O
length	O
,	O
and	O
show	O
the	O
results	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Note	O
the	O
varying	O
magnitude	O
and	O
maximum	O
path	O
length	O
in	O
individual	O
figures	O
.	O
	
These	O
are	O
compared	O
to	O
the	O
middle	O
part	O
of	O
Fig	O
.	O
6	O
in	O
.	O
	
However	O
,	O
differently	O
we	O
further	O
divide	O
the	O
computed	O
norm	O
of	O
a	O
batch	O
by	O
its	O
number	O
of	O
examples	O
.	O
	
According	O
to	O
the	O
results	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
ResNet	B-Method
-	I-Method
110	I-Method
trained	O
on	O
CIFAR	B-Material
-	I-Material
10	I-Material
,	O
as	O
well	O
as	O
ResNet	B-Method
-	I-Method
101	I-Method
and	O
ResNet	B-Method
-	I-Method
152	I-Method
trained	O
on	O
ILSVRC	B-Task
2012	I-Task
,	O
generate	O
much	O
smaller	O
gradients	O
from	O
their	O
long	O
paths	O
than	O
from	O
their	O
short	O
paths	O
.	O
	
In	O
contrast	O
,	O
our	O
Model	O
A	O
trained	O
on	O
ILSVRC	B-Task
2012	I-Task
,	O
generates	O
more	O
comparable	O
gradients	O
from	O
its	O
paths	O
with	O
different	O
lengths	O
.	O
	
subsection	O
:	O
Qualitative	O
results	O
	
We	O
show	O
qualitative	O
results	O
of	O
semantic	B-Task
image	I-Task
segmentation	I-Task
on	O
PASCAL	B-Material
VOC	I-Material
,	O
Cityscapes	B-Material
,	O
ADE20	B-Material
K	I-Material
,	O
and	O
PASCAL	B-Material
Context	I-Material
,	O
respectively	O
in	O
Figs	O
.	O
	
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
,	O
and	O
show	O
some	O
failure	O
cases	O
in	O
Figs	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
.	O
	
In	O
a	O
difference	O
map	O
,	O
grey	O
and	O
black	O
respectively	O
denotes	O
correctly	O
and	O
wrongly	O
labelled	O
pixels	O
,	O
while	O
white	O
denotes	O
the	O
officially	O
ignored	O
pixels	O
during	O
evaluation	O
.	O
	
Note	O
that	O
we	O
do	O
not	O
apply	O
post	B-Method
-	I-Method
processing	I-Method
with	O
CRFs	B-Method
,	O
which	O
can	O
smooth	O
the	O
output	O
but	O
is	O
too	O
slow	O
in	O
practice	O
,	O
especially	O
for	O
large	O
images	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Shorten	O
Spatial	O
-	O
spectral	O
RNN	O
with	O
Parallel	B-Method
-	I-Method
GRU	I-Method
for	O
Hyperspectral	B-Task
Image	I-Task
Classification	I-Task
	
Convolutional	B-Method
neural	I-Method
networks	I-Method
(	O
CNNs	B-Method
)	O
attained	O
a	O
good	O
performance	O
in	O
hyperspectral	B-Task
sensing	I-Task
image	I-Task
(	O
HSI	B-Task
)	O
classification	B-Task
,	O
but	O
CNNs	B-Method
consider	O
spectra	O
as	O
orderless	O
vectors	O
.	O
	
Therefore	O
,	O
considering	O
the	O
spectra	O
as	O
sequences	O
,	O
recurrent	B-Method
neural	I-Method
networks	I-Method
(	O
RNNs	B-Method
)	O
have	O
been	O
applied	O
in	O
HSI	B-Task
classification	I-Task
,	O
for	O
RNNs	B-Method
is	O
skilled	O
at	O
dealing	O
with	O
sequential	O
data	O
.	O
	
However	O
,	O
for	O
a	O
long	B-Task
-	I-Task
sequence	I-Task
task	I-Task
,	O
RNNs	B-Method
is	O
difficult	O
for	O
training	O
and	O
not	O
as	O
effective	O
as	O
we	O
expected	O
.	O
	
Besides	O
,	O
spatial	O
contextual	O
features	O
are	O
not	O
considered	O
in	O
RNNs	B-Method
.	O
	
In	O
this	O
study	O
,	O
we	O
propose	O
a	O
Shorten	B-Method
Spatial	I-Method
-	I-Method
spectral	I-Method
RNN	I-Method
with	I-Method
Parallel	I-Method
-	I-Method
GRU	I-Method
(	O
St	B-Method
-	I-Method
SS	I-Method
-	I-Method
pGRU	I-Method
)	O
for	O
HSI	B-Task
classification	I-Task
.	O
	
A	O
shorten	B-Method
RNN	I-Method
is	O
more	O
efficient	O
and	O
easier	O
for	O
training	O
than	O
band	B-Method
-	I-Method
by	I-Method
-	I-Method
band	I-Method
RNN	I-Method
.	O
	
By	O
combining	O
converlusion	B-Method
layer	I-Method
,	O
the	O
St	B-Method
-	I-Method
SSpGRU	I-Method
model	I-Method
considers	O
not	O
only	O
spectral	O
but	O
also	O
spatial	O
feature	O
,	O
which	O
results	O
in	O
a	O
better	O
performance	O
.	O
	
An	O
architecture	O
named	O
parallel	O
-	O
GRU	B-Method
is	O
also	O
proposed	O
and	O
applied	O
in	O
St	B-Method
-	I-Method
SS	I-Method
-	I-Method
pGRU	I-Method
.	O
	
With	O
this	O
architecture	O
,	O
the	O
model	O
gets	O
a	O
better	O
performance	O
and	O
is	O
more	O
robust	O
.	O
	
deep	B-Method
learning	I-Method
,	O
gated	B-Method
recurrent	I-Method
unit	I-Method
(	O
GRU	B-Method
)	O
,	O
long	B-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
(	O
LSTM	B-Method
)	O
,	O
recurrent	B-Method
neural	I-Method
networks	I-Method
(	O
RNN	B-Method
)	O
,	O
hyperspectral	O
image	O
classification	B-Task
	
section	O
:	O
Introduction	O
	
Hyperspectral	B-Method
image	I-Method
(	O
HSI	B-Task
)	O
has	O
attracted	O
considerable	O
attention	O
in	O
the	O
remote	B-Task
sensing	I-Task
community	I-Task
and	O
been	O
widely	O
used	O
in	O
various	O
areas	O
.	O
	
With	O
the	O
rich	O
spectral	O
information	O
in	O
HSI	B-Task
,	O
different	O
land	O
cover	O
categories	O
can	O
potentially	O
be	O
differentiated	O
precisely	O
.	O
	
In	O
recent	O
years	O
,	O
deep	B-Method
learning	I-Method
has	O
been	O
widely	O
used	O
in	O
various	O
fields	O
,	O
including	O
HSI	B-Task
classification	I-Task
.	O
	
Convolutional	B-Method
neural	I-Method
networks	I-Method
(	O
CNNs	B-Method
)	O
and	O
residual	B-Method
networks	I-Method
(	O
ResNets	B-Method
)	O
have	O
obtained	O
a	O
successful	O
result	O
for	O
HSI	B-Task
classification	I-Task
.	O
	
Recurrent	B-Method
neural	I-Method
networks	I-Method
(	O
RNNs	B-Method
)	O
are	O
also	O
applied	O
in	O
HSI	B-Task
classification	I-Task
.	O
	
Because	O
of	O
the	O
ability	O
to	O
extract	O
the	O
spatial	O
contextual	O
information	O
,	O
CNNs	B-Method
and	O
ResNets	B-Method
can	O
achieve	O
a	O
high	O
accuracy	B-Metric
in	O
the	O
classification	B-Task
task	O
.	O
	
However	O
,	O
CNNs	B-Method
and	O
ResNets	B-Method
consider	O
spectra	O
as	O
orderless	O
vectors	O
in	O
-	O
dimensional	O
feature	O
space	O
where	O
represents	O
the	O
number	O
of	O
bands	O
.	O
	
However	O
,	O
spectra	O
can	O
be	O
seen	O
as	O
orderly	O
and	O
continuing	O
sequences	O
in	O
the	O
spectral	O
space	O
.	O
	
In	O
other	O
words	O
,	O
CNNs	B-Method
and	O
ResNets	B-Method
ignore	O
the	O
continuity	O
of	O
spectra	O
.	O
	
RNNs	B-Method
have	O
proved	O
effective	O
in	O
solving	O
many	O
challenging	O
problems	O
involving	O
sequential	O
data	O
,	O
such	O
as	O
Natural	B-Task
Language	I-Task
Processing	I-Task
(	O
NLP	B-Task
)	O
and	O
prediction	B-Task
of	I-Task
time	I-Task
series	I-Task
.	O
	
Considering	O
the	O
spectrum	O
as	O
a	O
sequential	O
sequence	O
,	O
the	O
application	O
of	O
RNNs	B-Method
is	O
reasonable	O
as	O
it	O
can	O
take	O
full	O
advantage	O
of	O
the	O
high	O
spectral	O
resolution	O
characteristics	O
of	O
HSI	B-Task
.	O
	
However	O
,	O
for	O
a	O
long	B-Task
-	I-Task
sequence	I-Task
task	I-Task
,	O
RNNs	B-Method
is	O
not	O
as	O
effective	O
as	O
we	O
expected	O
.	O
	
Long	O
distance	O
dependence	O
,	O
gradient	O
vanish	O
and	O
overfitting	O
are	O
prone	O
to	O
occur	O
.	O
	
Even	O
if	O
the	O
long	B-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
network	I-Method
(	O
LSTM	B-Method
)	O
is	O
used	O
to	O
solve	O
the	O
long	B-Task
-	I-Task
distance	I-Task
dependence	I-Task
problem	I-Task
,	O
RNNs	B-Method
is	O
still	O
hard	O
for	O
training	B-Task
and	O
easily	O
overfitting	O
in	O
a	O
long	B-Task
-	I-Task
sequence	I-Task
task	I-Task
.	O
	
In	O
previous	O
work	O
,	O
3D	B-Method
-	I-Method
CNN	I-Method
is	O
applied	O
in	O
HSI	B-Task
classification	I-Task
and	O
obtained	O
a	O
good	O
behavior	O
.	O
	
For	O
RNNs	B-Method
,	O
Convolutional	B-Method
-	I-Method
LSTM	I-Method
(	O
CLSTM	B-Method
)	O
also	O
achieved	O
a	O
good	O
performance	O
in	O
HSI	B-Task
classification	I-Task
.	O
	
3D	B-Method
-	I-Method
CNNs	I-Method
and	O
CLSTM	B-Method
consider	O
both	O
spatial	O
contextual	O
information	O
and	O
spectral	O
continuity	O
,	O
which	O
result	O
in	O
a	O
high	O
accuracy	B-Metric
.	O
	
Nevertheless	O
,	O
it	O
takes	O
a	O
long	O
time	O
to	O
train	O
these	O
two	O
models	O
.	O
	
In	O
,	O
LSTM	B-Method
and	O
its	O
variant	O
,	O
GRU	B-Method
,	O
are	O
applied	O
in	O
HIS	O
classification	B-Task
,	O
and	O
it	O
is	O
proved	O
that	O
GRU	B-Method
has	O
a	O
better	O
performance	O
in	O
HIS	O
classification	B-Task
.	O
	
To	O
solve	O
the	O
problem	O
that	O
RNNs	B-Method
are	O
easily	O
over	O
-	O
fitting	O
and	O
difficult	O
for	O
training	O
,	O
proposed	O
band	O
-	O
group	O
LSTM	B-Method
,	O
which	O
can	O
effectively	O
make	O
training	B-Task
easier	O
by	O
reducing	O
the	O
number	O
of	O
timestep	O
in	O
LSTM	B-Method
.	O
	
In	O
this	O
study	O
,	O
a	O
Shorten	B-Method
Spatial	I-Method
-	I-Method
spectral	I-Method
RNN	I-Method
with	I-Method
Parallel	I-Method
-	I-Method
GRU	I-Method
(	O
St	B-Method
-	I-Method
SS	I-Method
-	I-Method
pGRU	I-Method
)	O
is	O
proposed	O
.	O
	
This	O
study	O
contributes	O
to	O
the	O
literature	O
in	O
2	O
major	O
respects	O
:	O
A	O
shorten	O
RNN	B-Method
with	O
GRU	B-Method
is	O
applied	O
in	O
HIS	O
classification	B-Task
.	O
	
The	O
model	O
is	O
more	O
efficient	O
and	O
easier	O
for	O
training	B-Task
than	O
band	B-Method
-	I-Method
by	I-Method
-	I-Method
band	I-Method
RNN	I-Method
.	O
	
By	O
combining	O
converlusion	B-Method
layer	I-Method
,	O
an	O
advanced	O
model	O
Shorten	O
Spatial	B-Method
-	I-Method
spectral	I-Method
RNN	I-Method
with	O
GRU	B-Method
is	O
proposed	O
.	O
	
The	O
model	O
considers	O
not	O
only	O
spectral	O
but	O
also	O
spatial	O
feature	O
,	O
which	O
leads	O
to	O
a	O
better	O
performance	O
.	O
	
An	O
architecture	O
named	O
parallel	O
-	O
GRU	B-Method
is	O
proposed	O
and	O
the	O
model	O
with	O
this	O
architecture	O
has	O
a	O
better	O
performance	O
and	O
is	O
more	O
robust	O
.	O
	
The	O
remainder	O
of	O
this	O
paper	O
is	O
organized	O
as	O
follows	O
.	O
	
In	O
the	O
methodology	O
section	O
,	O
firstly	O
the	O
structure	O
of	O
traditional	O
RNN	B-Method
,	O
LSTM	B-Method
and	O
GRU	B-Method
are	O
introduced	O
and	O
then	O
the	O
architecture	O
of	O
the	O
proposed	O
models	O
are	O
described	O
.	O
	
In	O
the	O
experimental	O
section	O
,	O
the	O
network	O
setup	O
,	O
the	O
experimental	O
results	O
,	O
and	O
the	O
comparison	O
of	O
different	O
models	O
are	O
provided	O
.	O
	
Finally	O
,	O
the	O
conclusion	O
section	O
concludes	O
the	O
paper	O
.	O
	
section	O
:	O
Methodology	O
	
subsection	O
:	O
Recurrent	B-Method
neural	I-Method
networks	I-Method
(	O
RNN	B-Method
)	O
	
Different	O
from	O
Artificial	B-Method
neural	I-Method
network	I-Method
(	I-Method
ANN	I-Method
)	I-Method
,	O
RNN	B-Method
,	O
a	O
neural	B-Method
network	I-Method
with	O
recurrent	B-Method
unit	I-Method
,	O
has	O
a	O
better	O
performance	O
in	O
solving	O
many	O
challenging	O
problems	O
involving	O
sequential	B-Task
data	I-Task
analysis	I-Task
.	O
	
The	O
state	O
of	O
each	O
time	O
step	O
of	O
the	O
recurrent	B-Method
unit	I-Method
is	O
not	O
only	O
related	O
to	O
the	O
input	O
of	O
the	O
current	O
step	O
,	O
but	O
also	O
related	O
to	O
the	O
state	O
of	O
the	O
previous	O
step	O
.	O
	
Thus	O
,	O
the	O
state	O
of	O
the	O
preceding	O
step	O
can	O
effectively	O
influence	O
the	O
next	O
step	O
.	O
	
Given	O
a	O
sequence	O
sample	O
,	O
in	O
which	O
is	O
the	O
data	O
at	O
th	O
timestep	O
.	O
	
For	O
the	O
th	O
recurrent	B-Method
unit	I-Method
,	O
its	O
hidden	O
state	O
can	O
be	O
described	O
as	O
:	O
where	O
is	O
the	O
initial	O
state	O
of	O
the	O
recurrent	B-Method
unit	I-Method
,	O
is	O
a	O
nonlinear	O
function	O
.	O
	
Normally	O
,	O
is	O
set	O
as	O
a	O
zero	O
vector	O
.	O
	
Optionally	O
,	O
in	O
th	O
timestep	O
,	O
the	O
recurrent	B-Method
unit	I-Method
may	O
have	O
an	O
output	O
.	O
	
For	O
some	O
task	O
,	O
the	O
RNN	B-Method
model	I-Method
will	O
finally	O
have	O
an	O
output	O
vector	O
,	O
while	O
for	O
classification	B-Task
tasks	O
,	O
only	O
one	O
output	O
is	O
needed	O
.	O
	
Generally	O
,	O
The	O
last	O
output	O
is	O
adopted	O
:	O
The	O
recurrent	B-Method
unit	I-Method
in	O
a	O
traditional	O
RNN	B-Method
is	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
In	O
the	O
traditional	O
RNN	B-Method
model	I-Method
,	O
the	O
update	O
rule	O
of	O
the	O
recurrent	O
hidden	O
state	O
and	O
output	O
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
and	O
(	O
[	O
reference	O
]	O
)	O
is	O
usually	O
implemented	O
as	O
follows	O
:	O
where	O
,	O
and	O
are	O
the	O
weight	O
matrices	O
.	O
	
and	O
are	O
the	O
bias	O
vectors	O
,	O
and	O
is	O
an	O
activation	O
function	O
,	O
such	O
as	O
the	O
sigmoid	B-Method
function	I-Method
or	O
the	O
hyperbolic	B-Method
tangent	I-Method
function	I-Method
.	O
	
subsection	O
:	O
Long	B-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
(	O
LSTM	B-Method
)	O
	
The	O
traditional	O
RNN	B-Method
has	O
the	O
problem	O
of	O
long	O
-	O
distance	O
dependence	O
.	O
	
The	O
RNN	B-Method
has	O
the	O
capability	O
to	O
connect	O
different	O
timesteps	O
related	O
information	O
.	O
	
However	O
,	O
when	O
the	O
sequence	O
is	O
too	O
long	O
,	O
the	O
RNN	B-Method
becomes	O
unable	O
to	O
connect	O
related	O
information	O
as	O
the	O
distance	O
increases	O
,	O
because	O
the	O
information	O
losses	O
when	O
propagating	O
through	O
multi	B-Method
-	I-Method
time	I-Method
-	I-Method
step	I-Method
recurrent	I-Method
units	I-Method
.	O
	
By	O
using	O
long	B-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
(	O
LSTM	B-Method
)	O
,	O
the	O
problems	O
have	O
been	O
solved	O
.	O
	
As	O
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
,	O
LSTM	B-Method
contains	O
a	O
forget	O
gate	O
,	O
an	O
input	O
gate	O
and	O
an	O
output	O
gate	O
.	O
	
’	O
	
Gate	B-Method
’	I-Method
structure	I-Method
is	O
actually	O
a	O
logistic	B-Method
regression	I-Method
model	I-Method
so	O
that	O
part	O
of	O
the	O
information	O
is	O
filtered	O
selectively	O
,	O
while	O
the	O
rest	O
is	O
reserved	O
and	O
passes	O
through	O
the	O
gate	O
.	O
	
LSTM	B-Method
can	O
simulate	O
the	O
process	O
of	O
forgetting	O
and	O
memory	O
and	O
calculate	O
the	O
probability	O
of	O
forgetting	O
and	O
memory	O
,	O
so	O
information	O
flow	O
could	O
be	O
preserved	O
in	O
long	B-Task
-	I-Task
distance	I-Task
propagation	I-Task
.	O
	
The	O
structure	O
of	O
LSTM	B-Method
can	O
be	O
described	O
as	O
:	O
where	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
,	O
(	O
[	O
reference	O
]	O
)	O
and	O
(	O
[	O
reference	O
]	O
)	O
represent	O
forget	O
gate	O
,	O
input	O
gate	O
and	O
output	O
gate	O
.	O
	
,	O
,	O
,	O
,	O
,	O
,	O
and	O
are	O
the	O
weight	O
matrices	O
.	O
	
,	O
,	O
and	O
are	O
the	O
bias	O
vectors	O
.	O
	
refers	O
to	O
sigmoid	O
function	O
and	O
tanh	B-Method
refers	O
to	O
the	O
hyperbolic	O
tangent	O
function	O
:	O
	
subsection	O
:	O
Gated	B-Method
recurrent	I-Method
unit	I-Method
(	O
GRU	B-Method
)	O
	
Over	O
the	O
years	O
,	O
there	O
have	O
been	O
many	O
variants	O
of	O
LSTM	B-Method
,	O
but	O
there	O
is	O
no	O
evidence	O
to	O
show	O
that	O
there	O
is	O
not	O
a	O
superior	O
variant	O
.	O
	
Any	O
variant	O
may	O
have	O
advantages	O
in	O
a	O
particular	O
problem	O
.	O
	
GRU	B-Method
is	O
a	O
variant	O
of	O
LSTM	B-Method
.	O
	
With	O
fewer	O
parameters	O
,	O
it	O
is	O
much	O
easier	O
for	O
training	O
than	O
LSTM	B-Method
,	O
and	O
usually	O
achieves	O
the	O
same	O
performance	O
as	O
LSTM	B-Method
in	O
some	O
tasks	O
.	O
	
It	O
is	O
considered	O
that	O
using	O
GRU	B-Method
in	O
a	O
HSI	B-Task
classification	I-Task
task	O
is	O
more	O
appropriate	O
than	O
using	O
LSTM	B-Method
.	O
	
The	O
main	O
difference	O
between	O
LSTM	B-Method
and	O
GRU	B-Method
is	O
that	O
an	O
update	O
gate	O
and	O
a	O
reset	O
gate	O
are	O
adopted	O
in	O
GRU	B-Method
,	O
instead	O
of	O
using	O
a	O
forget	O
gate	O
,	O
an	O
input	O
gate	O
and	O
an	O
output	O
gate	O
.	O
	
The	O
structure	O
of	O
the	O
GRU	B-Method
is	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
which	O
can	O
be	O
defined	O
as	O
follows	O
:	O
	
where	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
and	O
(	O
[	O
reference	O
]	O
)	O
represent	O
update	O
gate	O
and	O
reset	O
gate	O
.	O
	
,	O
,	O
,	O
,	O
and	O
are	O
the	O
weight	O
matrices	O
.	O
	
,	O
and	O
are	O
the	O
bias	O
vectors	O
.	O
	
subsection	O
:	O
The	O
proposed	O
model	O
	
subsubsection	O
:	O
Shorten	B-Method
Spatial	I-Method
-	I-Method
spectral	I-Method
RNN	I-Method
with	I-Method
GRU	I-Method
(	O
St	B-Method
-	I-Method
SS	I-Method
-	I-Method
GRU	I-Method
)	O
	
A	O
Shorten	B-Method
Spatial	I-Method
-	I-Method
spectral	I-Method
RNN	I-Method
with	I-Method
GRU	I-Method
(	O
St	B-Method
-	I-Method
SS	I-Method
-	I-Method
GRU	I-Method
)	O
model	O
for	O
HSI	B-Task
classification	I-Task
is	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
For	O
each	O
pixel	O
,	O
a	O
square	O
subgraph	O
composed	O
of	O
5	O
5	O
pixels	O
centered	O
on	O
it	O
is	O
used	O
as	O
a	O
training	O
sample	O
.	O
	
The	O
first	O
part	O
of	O
St	B-Method
-	I-Method
SS	I-Method
-	I-Method
GRU	I-Method
is	O
actually	O
a	O
3D	B-Method
-	I-Method
Convolutional	I-Method
layer	I-Method
but	O
both	O
the	O
depth	O
and	O
stride	O
of	O
the	O
kernels	O
are	O
1	O
.	O
	
Three	O
different	O
convolution	B-Method
kernels	I-Method
(	O
1Ã1	O
,	O
3Ã3	O
,	O
5Ã5	O
)	O
were	O
used	O
to	O
convolve	O
different	O
bands	O
.	O
	
The	O
output	O
of	O
this	O
part	O
is	O
a	O
sequence	O
with	O
the	O
same	O
length	O
as	O
the	O
original	O
input	O
.	O
	
The	O
output	O
sequence	O
is	O
a	O
’	O
spectra	O
’	O
with	O
the	O
spatial	O
contextual	O
feature	O
.	O
	
Every	O
timestep	O
of	O
the	O
sequence	O
is	O
a	O
feature	O
vector	O
.	O
	
The	O
second	O
part	O
is	O
a	O
Shorten	B-Method
RNN	I-Method
with	I-Method
GRU	I-Method
(	O
St	B-Method
-	I-Method
GRU	I-Method
)	O
.	O
	
The	O
structure	O
of	O
St	B-Method
-	I-Method
GRU	I-Method
is	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
The	O
1D	B-Method
converlusion	I-Method
layer	I-Method
before	O
GRU	B-Method
is	O
used	O
to	O
reduce	O
the	O
number	O
of	O
timesteps	O
so	O
that	O
the	O
network	O
is	O
easier	O
for	O
training	O
.	O
	
subsubsection	O
:	O
Parallel	O
-	O
GRU	B-Method
Architecture	O
	
In	O
order	O
to	O
make	O
the	O
model	O
more	O
robust	O
,	O
a	O
Parallel	B-Method
-	I-Method
GRU	I-Method
(	O
pGRU	B-Method
)	O
architecture	O
is	O
proposed	O
.	O
	
The	O
architecture	O
of	O
Shorten	O
Parallel	O
-	O
GRU	B-Method
(	O
St	O
-	O
pGRU	B-Method
)	O
is	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
The	O
architecture	O
is	O
actually	O
a	O
combination	O
of	O
several	O
GRU	B-Method
units	O
.	O
	
The	O
output	O
of	O
the	O
architecture	O
is	O
the	O
summation	O
of	O
every	O
unit	O
.	O
	
The	O
Shorten	B-Method
Spatial	I-Method
-	I-Method
spectral	I-Method
RNN	I-Method
with	I-Method
parallel	I-Method
-	I-Method
GRU	I-Method
(	O
St	B-Method
-	I-Method
SS	I-Method
-	I-Method
pGRU	I-Method
)	O
is	O
similar	O
to	O
St	B-Method
-	I-Method
SS	I-Method
-	I-Method
GRU	I-Method
,	O
except	O
that	O
St	B-Method
-	I-Method
GRU	I-Method
is	O
replaced	O
by	O
St	B-Method
-	I-Method
SS	I-Method
-	I-Method
pGRU	I-Method
.	O
	
section	O
:	O
Experiment	O
	
subsection	O
:	O
Data	O
	
In	O
the	O
experiment	O
,	O
two	O
HSI	B-Task
datasets	O
,	O
including	O
the	O
Pavia	B-Material
University	I-Material
and	O
Indian	B-Material
Pines	I-Material
,	O
are	O
used	O
to	O
evaluate	O
the	O
performance	O
of	O
the	O
proposed	O
model	O
.	O
	
The	O
Pavia	B-Material
University	I-Material
dataset	I-Material
was	O
acquired	O
by	O
the	O
Reflective	B-Method
Optics	I-Method
System	I-Method
Imaging	I-Method
Spectrometer	I-Method
(	O
ROSIS	B-Method
)	O
sensor	O
over	O
Pavia	O
,	O
northern	O
Italy	O
in	O
2001	O
.	O
	
The	O
corrected	O
data	O
,	O
with	O
a	O
spatial	O
resolution	O
of	O
1.3	O
m	O
per	O
pixel	O
,	O
contains	O
103	O
spectral	O
bands	O
ranging	O
from	O
0.43	O
to	O
0.86	O
.	O
	
The	O
image	O
,	O
with	O
610	O
340	O
pixels	O
,	O
is	O
differentiated	O
into	O
9	O
ground	O
truth	O
classes	O
.	O
	
Table	O
[	O
reference	O
]	O
provides	O
information	O
about	O
all	O
classes	O
of	O
the	O
dataset	O
with	O
their	O
corresponding	O
training	O
and	O
test	O
sample	O
.	O
	
The	O
Indian	B-Material
Pines	I-Material
dataset	I-Material
was	O
acquired	O
by	O
the	O
TAirborne	B-Method
Visible	I-Method
/	O
Infrared	B-Method
Imaging	I-Method
Spectrometer	I-Method
(	O
AVIRIS	B-Method
)	O
sensor	O
over	O
the	O
Indian	B-Material
Pines	I-Material
test	O
site	O
in	O
north	O
-	O
western	O
Indiana	O
in	O
1992	O
.	O
	
The	O
corrected	O
data	O
with	O
a	O
moderate	O
spatial	O
resolution	O
of	O
20	O
m	O
contains	O
200	O
spectral	O
bands	O
ranging	O
from	O
0.4	O
to	O
2.5	O
.	O
	
The	O
image	O
consists	O
of	O
145	O
145	O
pixels	O
,	O
which	O
are	O
differentiated	O
into	O
16	O
ground	O
truth	O
classes	O
.	O
	
Table	O
[	O
reference	O
]	O
provides	O
information	O
about	O
all	O
classes	O
of	O
the	O
dataset	O
with	O
their	O
corresponding	O
training	O
and	O
test	O
sample	O
.	O
	
subsection	O
:	O
Result	O
	
Table	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
list	O
the	O
results	O
obtained	O
by	O
the	O
experiment	O
,	O
and	O
Fig	O
.	O
	
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
show	O
the	O
classification	B-Task
maps	O
on	O
the	O
Pavia	B-Material
University	I-Material
dataset	I-Material
and	O
the	O
Indian	B-Material
Pines	I-Material
dataset	I-Material
.	O
	
Note	O
that	O
the	O
accuracies	B-Metric
list	O
in	O
Table	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
are	O
overall	O
accuracies	B-Metric
(	O
OA	B-Metric
)	O
along	O
with	O
the	O
standard	O
deviation	O
,	O
from	O
10	O
independent	O
runs	O
on	O
each	O
dataset	O
.	O
	
The	O
experiment	O
is	O
implemented	O
with	O
an	O
Intel	O
i7	O
-	O
7700	O
K	O
4.20GHz	O
processor	O
with	O
16	O
GB	O
of	O
RAM	O
and	O
an	O
NVIDIA	B-Material
GTX1050Ti	I-Material
graphic	I-Material
card	I-Material
under	O
Python3.6	B-Method
with	O
tensorflow1.8.0	B-Method
.	O
	
First	O
of	O
all	O
,	O
for	O
all	O
the	O
datasets	O
,	O
GRU	B-Method
outperforms	O
LSTM	B-Method
.	O
	
In	O
addition	O
,	O
it	O
is	O
observed	O
that	O
LSTM	B-Method
is	O
difficult	O
to	O
converge	O
in	O
the	O
experiment	O
,	O
while	O
GRU	B-Method
is	O
not	O
.	O
	
Thus	O
,	O
it	O
is	O
reasonable	O
to	O
indicate	O
that	O
GRU	B-Method
is	O
a	O
better	O
choice	O
for	O
a	O
HSI	B-Task
classification	I-Task
task	O
.	O
	
Furthermore	O
,	O
it	O
is	O
apparent	O
that	O
St	B-Method
-	I-Method
GRU	I-Method
increases	O
the	O
accuracy	B-Metric
significantly	O
by	O
5.33	O
%	O
and	O
3.52	O
%	O
in	O
the	O
Pavia	B-Material
University	I-Material
dataset	I-Material
and	O
the	O
Indian	B-Material
Pines	I-Material
correspondingly	O
.	O
	
With	O
converlusion	B-Method
layers	I-Method
,	O
St	B-Method
-	I-Method
SS	I-Method
-	I-Method
GRU	I-Method
has	O
a	O
better	O
than	O
St	B-Method
-	I-Method
GRU	I-Method
.	O
	
The	O
accuracy	B-Metric
of	O
St	B-Method
-	I-Method
SS	I-Method
-	I-Method
GRU	I-Method
is	O
4.55	O
%	O
and	O
6.63	O
%	O
higher	O
than	O
that	O
in	O
St	B-Method
-	I-Method
GRU	I-Method
.	O
	
After	O
parallel	O
-	O
GRU	B-Method
is	O
adopted	O
,	O
the	O
model	O
gains	O
the	O
best	O
performance	O
in	O
this	O
experiment	O
.	O
	
The	O
accuracy	B-Metric
of	O
St	B-Method
-	I-Method
SS	I-Method
-	I-Method
pGRU	I-Method
is	O
1.64	O
%	O
and	O
3.19	O
%	O
higher	O
than	O
St	B-Method
-	I-Method
SS	I-Method
-	I-Method
GRU	I-Method
.	O
	
What	O
is	O
more	O
,	O
the	O
standard	O
deviation	O
of	O
St	B-Method
-	I-Method
SS	I-Method
-	I-Method
pGRU	I-Method
is	O
smaller	O
than	O
other	O
models	O
,	O
which	O
indicate	O
that	O
St	B-Method
-	I-Method
SS	I-Method
-	I-Method
pGRU	I-Method
is	O
more	O
robust	O
.	O
	
Comparing	O
the	O
processing	B-Metric
time	I-Metric
of	O
different	O
methods	O
,	O
st	O
-	O
GRU	B-Method
is	O
significantly	O
faster	O
in	O
training	B-Task
than	O
band	O
-	O
by	O
-	O
band	O
GRU	B-Method
.	O
	
St	O
-	O
SS	O
-	O
GRU	B-Method
and	O
St	B-Method
-	I-Method
SS	I-Method
-	I-Method
pGRU	I-Method
are	O
as	O
slow	O
as	O
LSTM	B-Method
and	O
GRU	B-Method
in	O
training	B-Task
,	O
but	O
they	O
have	O
higher	O
accuracies	B-Metric
than	O
LSTM	B-Method
and	O
GRU	B-Method
.	O
	
section	O
:	O
Conclusion	O
	
In	O
the	O
study	O
,	O
a	O
St	B-Method
-	I-Method
SS	I-Method
-	I-Method
pGRU	I-Method
model	I-Method
is	O
proposed	O
for	O
HSI	B-Task
classification	I-Task
.	O
	
What	O
is	O
more	O
,	O
an	O
architecture	O
named	O
parallel	O
-	O
GRU	B-Method
is	O
proposed	O
to	O
promote	O
the	O
performance	O
and	O
robustness	B-Metric
.	O
	
Then	O
an	O
experiment	O
is	O
conducted	O
to	O
compare	O
the	O
performance	O
of	O
different	O
models	O
.	O
	
From	O
the	O
experiment	O
,	O
it	O
is	O
confirmed	O
that	O
GRU	B-Method
performs	O
better	O
than	O
LSTM	B-Method
in	O
HSI	B-Task
classification	I-Task
task	O
.	O
	
Moreover	O
,	O
it	O
is	O
apparent	O
that	O
the	O
proposed	O
models	O
are	O
a	O
lot	O
more	O
accurate	O
,	O
more	O
robust	O
and	O
faster	O
than	O
the	O
traditional	O
GRU	B-Method
network	O
.	O
	
Specifically	O
,	O
St	B-Method
-	I-Method
GRU	I-Method
effectively	O
reduced	O
the	O
training	B-Metric
time	I-Metric
and	O
promoted	O
the	O
accuracy	B-Metric
.	O
	
St	B-Method
-	I-Method
SS	I-Method
-	I-Method
GRU	I-Method
needs	O
more	O
time	O
for	O
training	B-Task
but	O
gains	O
a	O
better	O
performance	O
than	O
St	B-Method
-	I-Method
GRU	I-Method
.	O
	
The	O
proposed	O
architecture	O
parallel	O
-	O
GRU	B-Method
also	O
provided	O
a	O
satisfactory	O
result	O
in	O
the	O
experiment	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Text	B-Task
Classification	I-Task
Improved	O
by	O
Integrating	O
Bidirectional	O
LSTM	B-Method
with	O
Two	B-Method
-	I-Method
dimensional	I-Method
Max	I-Method
Pooling	I-Method
	
Recurrent	B-Method
Neural	I-Method
Network	I-Method
(	O
RNN	B-Method
)	O
is	O
one	O
of	O
the	O
most	O
popular	O
architectures	O
used	O
in	O
Natural	B-Task
Language	I-Task
Processsing	I-Task
(	O
NLP	B-Task
)	O
tasks	O
because	O
its	O
recurrent	B-Method
structure	I-Method
is	O
very	O
suitable	O
to	O
process	O
variable	O
-	O
length	O
text	O
.	O
	
RNN	B-Method
can	O
utilize	O
distributed	B-Method
representations	I-Method
of	I-Method
words	I-Method
by	O
first	O
converting	O
the	O
tokens	O
comprising	O
each	O
text	O
into	O
vectors	O
,	O
which	O
form	O
a	O
matrix	O
.	O
	
And	O
this	O
matrix	O
includes	O
two	O
dimensions	O
:	O
the	O
time	O
-	O
step	O
dimension	O
and	O
the	O
feature	O
vector	O
dimension	O
.	O
	
Then	O
most	O
existing	O
models	O
usually	O
utilize	O
one	B-Method
-	I-Method
dimensional	I-Method
(	I-Method
1D	I-Method
)	I-Method
max	I-Method
pooling	I-Method
operation	I-Method
or	O
attention	B-Method
-	I-Method
based	I-Method
operation	I-Method
only	O
on	O
the	O
time	O
-	O
step	O
dimension	O
to	O
obtain	O
a	O
fixed	O
-	O
length	O
vector	O
.	O
	
However	O
,	O
the	O
features	O
on	O
the	O
feature	O
vector	O
dimension	O
are	O
not	O
mutually	O
independent	O
,	O
and	O
simply	O
applying	O
1D	B-Method
pooling	I-Method
operation	I-Method
over	O
the	O
time	O
-	O
step	O
dimension	O
independently	O
may	O
destroy	O
the	O
structure	O
of	O
the	O
feature	B-Method
representation	I-Method
.	O
	
On	O
the	O
other	O
hand	O
,	O
applying	O
two	O
-	O
dimensional	O
	
(	O
2D	O
)	O
pooling	B-Method
operation	I-Method
over	O
the	O
two	O
dimensions	O
may	O
sample	O
more	O
meaningful	O
features	O
for	O
sequence	B-Task
modeling	I-Task
tasks	I-Task
.	O
	
To	O
integrate	O
the	O
features	O
on	O
both	O
dimensions	O
of	O
the	O
matrix	O
,	O
this	O
paper	O
explores	O
applying	O
2D	B-Method
max	I-Method
pooling	I-Method
operation	I-Method
to	O
obtain	O
a	O
fixed	B-Method
-	I-Method
length	I-Method
representation	I-Method
of	O
the	O
text	O
.	O
	
This	O
paper	O
also	O
utilizes	O
2D	B-Method
convolution	I-Method
to	O
sample	O
more	O
meaningful	O
information	O
of	O
the	O
matrix	O
.	O
	
Experiments	O
are	O
conducted	O
on	O
six	O
text	B-Task
classification	I-Task
tasks	I-Task
,	O
including	O
sentiment	B-Task
analysis	I-Task
,	O
question	B-Task
classification	I-Task
,	O
subjectivity	B-Task
classification	I-Task
and	O
newsgroup	B-Task
classification	I-Task
.	O
	
Compared	O
with	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
,	O
the	O
proposed	O
models	O
achieve	O
excellent	O
performance	O
on	O
4	O
out	O
of	O
6	O
tasks	O
.	O
	
Specifically	O
,	O
one	O
of	O
the	O
proposed	O
models	O
achieves	O
highest	O
accuracy	B-Metric
on	O
Stanford	B-Material
Sentiment	I-Material
Treebank	I-Material
binary	O
classification	O
and	O
fine	B-Task
-	I-Task
grained	I-Task
classification	I-Task
tasks	I-Task
.	O
	
section	O
:	O
Introduction	O
	
This	O
work	O
is	O
licenced	O
under	O
a	O
Creative	O
Commons	O
Attribution	O
4.0	O
International	O
Licence	O
.	O
	
Licence	O
details	O
	
:	O
Text	B-Task
classification	I-Task
is	O
an	O
essential	O
component	O
in	O
many	O
NLP	B-Task
applications	O
,	O
such	O
as	O
sentiment	B-Task
analysis	I-Task
,	O
relation	B-Task
extraction	I-Task
and	O
spam	B-Task
detection	I-Task
.	O
	
Therefore	O
,	O
it	O
has	O
attracted	O
considerable	O
attention	O
from	O
many	O
researchers	O
,	O
and	O
various	O
types	O
of	O
models	O
have	O
been	O
proposed	O
.	O
	
As	O
a	O
traditional	O
method	O
,	O
the	O
bag	B-Method
-	I-Method
of	I-Method
-	I-Method
words	I-Method
(	I-Method
BoW	I-Method
)	I-Method
model	I-Method
treats	O
texts	O
as	O
unordered	O
sets	O
of	O
words	O
.	O
	
In	O
this	O
way	O
,	O
however	O
,	O
it	O
fails	O
to	O
encode	O
word	O
order	O
and	O
syntactic	O
feature	O
.	O
	
Recently	O
,	O
order	B-Method
-	I-Method
sensitive	I-Method
models	I-Method
based	O
on	O
neural	B-Method
networks	I-Method
have	O
achieved	O
tremendous	O
success	O
for	O
text	B-Task
classification	I-Task
,	O
and	O
shown	O
more	O
significant	O
progress	O
compared	O
with	O
BoW	B-Method
models	I-Method
.	O
	
The	O
challenge	O
for	O
textual	B-Task
modeling	I-Task
is	O
how	O
to	O
capture	O
features	O
for	O
different	O
text	O
units	O
,	O
such	O
as	O
phrases	O
,	O
sentences	O
and	O
documents	O
.	O
	
Benefiting	O
from	O
its	O
recurrent	B-Method
structure	I-Method
,	O
RNN	B-Method
,	O
as	O
an	O
alternative	O
type	O
of	O
neural	B-Method
networks	I-Method
,	O
is	O
very	O
suitable	O
to	O
process	O
the	O
variable	O
-	O
length	O
text	O
.	O
	
RNN	B-Method
can	O
capitalize	O
on	O
distributed	O
representations	O
of	O
words	O
by	O
first	O
converting	O
the	O
tokens	O
comprising	O
each	O
text	O
into	O
vectors	O
,	O
which	O
form	O
a	O
matrix	O
.	O
	
This	O
matrix	O
includes	O
two	O
dimensions	O
:	O
the	O
time	O
-	O
step	O
dimension	O
and	O
the	O
feature	O
vector	O
dimension	O
,	O
and	O
it	O
will	O
be	O
updated	O
in	O
the	O
process	O
of	O
learning	B-Task
feature	I-Task
representation	I-Task
.	O
	
Then	O
RNN	B-Method
utilizes	O
1D	B-Method
max	I-Method
pooling	I-Method
operation	I-Method
or	O
attention	B-Method
-	I-Method
based	I-Method
operation	I-Method
,	O
which	O
extracts	O
maximum	O
values	O
or	O
generates	O
a	O
weighted	B-Method
representation	I-Method
over	O
the	O
time	O
-	O
step	O
dimension	O
of	O
the	O
matrix	O
,	O
to	O
obtain	O
a	O
fixed	O
-	O
length	O
vector	O
.	O
	
Both	O
of	O
the	O
two	O
operators	O
ignore	O
features	O
on	O
the	O
feature	O
vector	O
dimension	O
,	O
which	O
maybe	O
important	O
for	O
sentence	B-Task
representation	I-Task
,	O
therefore	O
the	O
use	O
of	O
1D	B-Method
max	I-Method
pooling	I-Method
and	O
attention	B-Method
-	I-Method
based	I-Method
operators	I-Method
may	O
pose	O
a	O
serious	O
limitation	O
.	O
	
Convolutional	O
Neural	O
Networks	O
(	O
CNN	B-Method
)	O
utilizes	O
1D	B-Method
convolution	I-Method
to	O
perform	O
the	O
feature	B-Task
mapping	I-Task
,	O
and	O
then	O
applies	O
1D	B-Method
max	I-Method
pooling	I-Method
operation	I-Method
over	O
the	O
time	O
-	O
step	O
dimension	O
to	O
obtain	O
a	O
fixed	O
-	O
length	O
output	O
.	O
	
However	O
the	O
elements	O
in	O
the	O
matrix	O
learned	O
by	O
RNN	B-Method
are	O
not	O
independent	O
,	O
as	O
RNN	B-Method
reads	O
a	O
sentence	O
word	O
by	O
word	O
,	O
one	O
can	O
effectively	O
treat	O
the	O
matrix	O
as	O
an	O
’	O
image	O
’	O
.	O
	
Unlike	O
in	O
NLP	B-Task
,	O
CNN	B-Method
in	O
image	B-Task
processing	I-Task
tasks	I-Task
applies	O
2D	B-Method
convolution	I-Method
and	O
2D	B-Method
pooling	I-Method
operation	I-Method
to	O
get	O
a	O
representation	O
of	O
the	O
input	O
.	O
	
It	O
is	O
a	O
good	O
choice	O
to	O
utilize	O
2D	B-Method
convolution	I-Method
and	O
2D	B-Method
pooling	I-Method
to	O
sample	O
more	O
meaningful	O
features	O
on	O
both	O
the	O
time	O
-	O
step	O
dimension	O
and	O
the	O
feature	O
vector	O
dimension	O
for	O
text	B-Task
classification	I-Task
.	O
	
Above	O
all	O
,	O
this	O
paper	O
proposes	O
Bidirectional	B-Method
Long	I-Method
Short	I-Method
-	I-Method
Term	I-Method
Memory	I-Method
Networks	I-Method
with	O
Two	B-Method
-	I-Method
Dimensional	I-Method
Max	I-Method
Pooling	I-Method
(	O
BLSTM	B-Method
-	I-Method
2DPooling	I-Method
)	O
to	O
capture	O
features	O
on	O
both	O
the	O
time	O
-	O
step	O
dimension	O
and	O
the	O
feature	O
vector	O
dimension	O
.	O
	
It	O
first	O
utilizes	O
Bidirectional	B-Method
Long	I-Method
Short	I-Method
-	I-Method
Term	I-Method
Memory	I-Method
Networks	I-Method
(	O
BLSTM	B-Method
)	O
to	O
transform	O
the	O
text	O
into	O
vectors	O
.	O
	
And	O
then	O
2D	B-Method
max	I-Method
pooling	I-Method
operation	I-Method
is	O
utilized	O
to	O
obtain	O
a	O
fixed	O
-	O
length	O
vector	O
.	O
	
This	O
paper	O
also	O
applies	O
2D	B-Method
convolution	I-Method
(	O
BLSTM	B-Method
-	I-Method
2DCNN	I-Method
)	O
to	O
capture	O
more	O
meaningful	O
features	O
to	O
represent	O
the	O
input	O
text	O
.	O
	
The	O
contributions	O
of	O
this	O
paper	O
can	O
be	O
summarized	O
as	O
follows	O
:	O
This	O
paper	O
proposes	O
a	O
combined	O
framework	O
,	O
which	O
utilizes	O
BLSTM	B-Method
to	O
capture	O
long	O
-	O
term	O
sentence	O
dependencies	O
,	O
and	O
extracts	O
features	O
by	O
2D	B-Method
convolution	I-Method
and	O
2D	B-Method
max	I-Method
pooling	I-Method
operation	I-Method
for	O
sequence	B-Task
modeling	I-Task
tasks	I-Task
.	O
	
To	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
this	O
work	O
is	O
the	O
first	O
example	O
of	O
using	O
2D	B-Method
convolution	I-Method
and	O
2D	B-Method
max	I-Method
pooling	I-Method
operation	I-Method
in	O
NLP	B-Task
tasks	O
.	O
	
This	O
work	O
introduces	O
two	O
combined	O
models	O
BLSTM	B-Method
-	I-Method
2DPooling	I-Method
and	O
BLSTM	B-Method
-	I-Method
2DCNN	I-Method
,	O
and	O
verifies	O
them	O
on	O
six	O
text	B-Task
classification	I-Task
tasks	I-Task
,	O
including	O
sentiment	B-Task
analysis	I-Task
,	O
question	B-Task
classification	I-Task
,	O
subjectivity	B-Task
classification	I-Task
,	O
and	O
newsgroups	B-Task
classification	I-Task
.	O
	
Compared	O
with	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
,	O
BLSTM	B-Method
-	I-Method
2DCNN	I-Method
achieves	O
excellent	O
performance	O
on	O
out	O
of	O
tasks	O
.	O
	
Specifically	O
,	O
it	O
achieves	O
highest	O
accuracy	B-Metric
on	O
Stanford	B-Material
Sentiment	I-Material
Treebank	I-Material
binary	O
classification	O
and	O
fine	B-Task
-	I-Task
grained	I-Task
classification	I-Task
tasks	I-Task
.	O
	
To	O
better	O
understand	O
the	O
effect	O
of	O
2D	B-Method
convolution	I-Method
and	O
2D	B-Method
max	I-Method
pooling	I-Method
operation	I-Method
,	O
this	O
paper	O
conducts	O
experiments	O
on	O
Stanford	B-Material
Sentiment	I-Material
Treebank	I-Material
fine	O
-	O
grained	O
task	O
.	O
	
It	O
first	O
depicts	O
the	O
performance	O
of	O
the	O
proposed	O
models	O
on	O
different	O
length	O
of	O
sentences	O
,	O
and	O
then	O
conducts	O
a	O
sensitivity	B-Method
analysis	I-Method
of	O
2D	B-Method
filter	I-Method
and	O
max	B-Metric
pooling	I-Metric
size	I-Metric
.	O
	
The	O
remainder	O
of	O
the	O
paper	O
is	O
organized	O
as	O
follows	O
.	O
	
In	O
Section	O
2	O
,	O
the	O
related	O
work	O
about	O
text	B-Task
classification	I-Task
is	O
reviewed	O
.	O
	
Section	O
3	O
presents	O
the	O
BLSTM	B-Method
-	O
2DCNN	O
architectures	O
for	O
text	B-Task
classification	I-Task
in	O
detail	O
.	O
	
Section	O
4	O
describes	O
details	O
about	O
the	O
setup	O
of	O
the	O
experiments	O
.	O
	
Section	O
5	O
presents	O
the	O
experimental	O
results	O
.	O
	
The	O
conclusion	O
is	O
drawn	O
in	O
the	O
section	O
6	O
.	O
	
section	O
:	O
Related	O
Work	O
	
Deep	B-Method
learning	I-Method
based	I-Method
neural	I-Method
network	I-Method
models	I-Method
have	O
achieved	O
great	O
improvement	O
on	O
text	B-Task
classification	I-Task
tasks	I-Task
.	O
	
These	O
models	O
generally	O
consist	O
of	O
a	O
projection	B-Method
layer	I-Method
that	O
maps	O
words	O
of	O
text	O
to	O
vectors	O
.	O
	
And	O
then	O
combine	O
the	O
vectors	O
with	O
different	O
neural	B-Method
networks	I-Method
to	O
make	O
a	O
fixed	B-Method
-	I-Method
length	I-Method
representation	I-Method
.	O
	
According	O
to	O
the	O
structure	O
,	O
they	O
may	O
divide	O
into	O
four	O
categories	O
:	O
Recursive	B-Method
Neural	I-Method
Networks	I-Method
(	O
RecNN	B-Method
)	O
,	O
RNN	B-Method
,	O
CNN	B-Method
and	O
other	O
neural	B-Method
networks	I-Method
.	O
	
Recursive	B-Method
Neural	I-Method
Networks	I-Method
:	O
	
RecNN	B-Method
is	O
defined	O
over	O
recursive	O
tree	O
structures	O
.	O
	
In	O
the	O
type	O
of	O
recursive	B-Method
models	I-Method
,	O
information	O
from	O
the	O
leaf	O
nodes	O
of	O
a	O
tree	O
and	O
its	O
internal	O
nodes	O
are	O
combined	O
in	O
a	O
bottom	O
-	O
up	O
manner	O
.	O
	
socher2013recursive	O
introduced	O
recursive	B-Method
neural	I-Method
tensor	I-Method
network	I-Method
to	O
build	O
representations	O
of	O
phrases	O
and	O
sentences	O
by	O
combining	O
neighbour	O
constituents	O
based	O
on	O
the	O
parsing	O
tree	O
.	O
	
irsoy2014deep	O
proposed	O
deep	B-Method
recursive	I-Method
neural	I-Method
network	I-Method
,	O
which	O
is	O
constructed	O
by	O
stacking	O
multiple	O
recursive	B-Method
layers	I-Method
on	O
top	O
of	O
each	O
other	O
,	O
to	O
modeling	O
sentence	O
.	O
	
Recurrent	B-Method
Neural	I-Method
Networks	I-Method
:	O
	
RNN	B-Method
has	O
obtained	O
much	O
attention	O
because	O
of	O
their	O
superior	O
ability	O
to	O
preserve	O
sequence	O
information	O
over	O
time	O
.	O
	
tang2015target	O
developed	O
target	B-Method
dependent	I-Method
Long	I-Method
Short	I-Method
-	I-Method
Term	I-Method
Memory	I-Method
Networks	I-Method
(	O
LSTM	B-Method
)	I-Method
,	O
where	O
target	O
information	O
is	O
automatically	O
taken	O
into	O
account	O
.	O
	
tai2015improved	O
generalized	B-Method
LSTM	I-Method
to	O
Tree	B-Method
-	I-Method
LSTM	I-Method
where	O
each	O
LSTM	B-Method
unit	I-Method
gains	O
information	O
from	O
its	O
children	O
units	O
.	O
	
zhou2016attention	O
introduced	O
BLSTM	B-Method
with	O
attention	B-Method
mechanism	I-Method
to	O
automatically	O
select	O
features	O
that	O
have	O
a	O
decisive	O
effect	O
on	O
classification	B-Task
.	O
	
yang2016hierarchical	O
introduced	O
a	O
hierarchical	B-Method
network	I-Method
with	O
two	O
levels	O
of	O
attention	B-Method
mechanisms	I-Method
,	O
which	O
are	O
word	O
attention	O
and	O
sentence	O
attention	O
,	O
for	O
document	B-Task
classification	I-Task
.	O
	
This	O
paper	O
also	O
implements	O
an	O
attention	O
-	O
based	O
model	O
BLSTM	B-Method
-	O
Att	O
like	O
the	O
model	O
in	O
zhou2016attention	B-Method
.	O
	
Convolution	B-Method
Neural	I-Method
Networks	I-Method
:	O
	
CNN	B-Method
is	O
a	O
feedforward	B-Method
neural	I-Method
network	I-Method
with	O
2D	B-Method
convolution	I-Method
layers	I-Method
and	O
2D	B-Method
pooling	I-Method
layers	I-Method
,	O
originally	O
developed	O
for	O
image	B-Task
processing	I-Task
.	O
	
Then	O
CNN	B-Method
is	O
applied	O
to	O
NLP	B-Task
tasks	O
,	O
such	O
as	O
sentence	B-Task
classification	I-Task
,	O
and	O
relation	B-Task
classification	I-Task
.	O
	
The	O
difference	O
is	O
that	O
the	O
common	O
CNN	B-Method
in	O
NLP	B-Task
tasks	O
is	O
made	O
up	O
of	O
1D	B-Method
convolution	I-Method
layers	I-Method
and	O
1D	B-Method
pooling	I-Method
layers	I-Method
.	O
	
kim2014convolutional	O
defined	O
a	O
CNN	B-Method
architecture	O
with	O
two	O
channels	O
.	O
	
kalchbrenner2014convolutional	O
proposed	O
a	O
dynamic	B-Method
-	I-Method
max	I-Method
pooling	I-Method
mechanism	I-Method
for	O
sentence	B-Task
modeling	I-Task
.	O
	
conducted	O
a	O
sensitivity	B-Method
analysis	I-Method
of	O
one	O
-	O
layer	O
CNN	B-Method
to	O
explore	O
the	O
effect	O
of	O
architecture	B-Method
components	I-Method
on	O
model	O
performance	O
.	O
	
yin2016multichannel	O
introduced	O
multichannel	B-Method
embeddings	I-Method
and	O
unsupervised	B-Method
pretraining	I-Method
to	O
improve	O
classification	B-Metric
accuracy	I-Metric
.	O
	
conducted	O
a	O
sensitivity	B-Method
analysis	I-Method
of	O
one	O
-	O
layer	O
CNN	B-Method
to	O
explore	O
the	O
effect	O
of	O
architecture	B-Method
components	I-Method
on	O
model	O
performance	O
.	O
	
Usually	O
there	O
is	O
a	O
misunderstanding	O
that	O
1D	B-Method
convolutional	I-Method
filter	I-Method
in	O
NLP	B-Task
tasks	O
has	O
one	O
dimension	O
.	O
	
Actually	O
it	O
has	O
two	O
dimensions	O
,	O
where	O
,	O
.	O
	
As	O
is	O
equal	O
to	O
the	O
word	O
embeddings	O
size	O
,	O
the	O
window	O
slides	O
only	O
on	O
the	O
time	O
-	O
step	O
dimension	O
,	O
so	O
the	O
convolution	B-Method
is	O
usually	O
called	O
1D	B-Method
convolution	I-Method
.	O
	
While	O
in	O
this	O
paper	O
varies	O
from	O
2	O
to	O
,	O
to	O
avoid	O
confusion	O
with	O
common	O
CNN	B-Method
,	O
the	O
convolution	B-Method
in	O
this	O
work	O
is	O
named	O
as	O
2D	B-Method
convolution	I-Method
.	O
	
The	O
details	O
will	O
be	O
described	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Other	O
Neural	B-Method
Networks	I-Method
:	O
	
In	O
addition	O
to	O
the	O
models	O
described	O
above	O
,	O
lots	O
of	O
other	O
neural	B-Method
networks	I-Method
have	O
been	O
proposed	O
for	O
text	B-Task
classification	I-Task
.	O
	
iyyer2015deep	O
introduced	O
a	O
deep	B-Method
averaging	I-Method
network	I-Method
,	O
which	O
fed	O
an	O
unweighted	B-Method
average	I-Method
of	I-Method
word	I-Method
embeddings	I-Method
through	O
multiple	O
hidden	B-Method
layers	I-Method
before	O
classification	B-Task
.	O
	
zhou2015c	O
	
used	O
CNN	B-Method
to	O
extract	O
a	O
sequence	O
of	O
higher	O
-	O
level	O
phrase	O
representations	O
,	O
then	O
the	O
representations	O
were	O
fed	O
into	O
a	O
LSTM	B-Method
to	O
obtain	O
the	O
sentence	B-Method
representation	I-Method
.	O
	
The	O
proposed	O
model	O
BLSTM	B-Method
-	I-Method
2DCNN	I-Method
is	O
most	O
relevant	O
to	O
DSCNN	B-Method
and	O
RCNN	B-Method
.	O
	
The	O
difference	O
is	O
that	O
the	O
former	O
two	O
utilize	O
LSTM	B-Method
,	O
bidirectional	O
RNN	B-Method
respectively	O
,	O
while	O
this	O
work	O
applies	O
BLSTM	B-Method
,	O
to	O
capture	O
long	O
-	O
term	O
sentence	O
dependencies	O
.	O
	
After	O
that	O
the	O
former	O
two	O
both	O
apply	O
1D	B-Method
convolution	I-Method
and	O
1D	B-Method
max	I-Method
pooling	I-Method
operation	I-Method
,	O
while	O
this	O
paper	O
uses	O
2D	B-Method
convolution	I-Method
and	O
2D	B-Method
max	I-Method
pooling	I-Method
operation	I-Method
,	O
to	O
obtain	O
the	O
whole	O
sentence	B-Method
representation	I-Method
.	O
	
section	O
:	O
Model	O
	
As	O
shown	O
in	O
Figure	O
1	O
,	O
the	O
overall	O
model	O
consists	O
of	O
four	O
parts	O
:	O
BLSTM	B-Method
Layer	I-Method
,	O
Two	B-Method
-	I-Method
dimensional	I-Method
Convolution	I-Method
Layer	I-Method
,	O
	
Two	O
dimensional	B-Method
max	I-Method
pooling	I-Method
Layer	I-Method
,	O
and	O
Output	B-Method
Layer	I-Method
.	O
	
The	O
details	O
of	O
different	O
components	O
are	O
described	O
in	O
the	O
following	O
sections	O
.	O
	
subsection	O
:	O
BLSTM	B-Method
Layer	I-Method
	
LSTM	B-Method
was	O
firstly	O
proposed	O
by	O
hochreiter1997long	O
to	O
overcome	O
the	O
gradient	O
vanishing	O
problem	O
of	O
RNN	B-Method
.	O
	
The	O
main	O
idea	O
is	O
to	O
introduce	O
an	O
adaptive	B-Method
gating	I-Method
mechanism	I-Method
,	O
which	O
decides	O
the	O
degree	O
to	O
keep	O
the	O
previous	O
state	O
and	O
memorize	O
the	O
extracted	O
features	O
of	O
the	O
current	O
data	O
input	O
.	O
	
Given	O
a	O
sequence	O
,	O
where	O
is	O
the	O
length	O
of	O
input	O
text	O
,	O
LSTM	B-Method
processes	O
it	O
word	O
by	O
word	O
.	O
	
At	O
time	O
-	O
step	O
,	O
the	O
memory	O
and	O
the	O
hidden	O
state	O
are	O
updated	O
with	O
the	O
following	O
equations	O
:	O
where	O
is	O
the	O
input	O
at	O
the	O
current	O
time	O
-	O
step	O
,	O
,	O
and	O
is	O
the	O
input	O
gate	O
activation	O
,	O
forget	O
gate	O
activation	O
and	O
output	O
gate	O
activation	O
respectively	O
,	O
is	O
the	O
current	O
cell	O
state	O
,	O
denotes	O
the	O
logistic	B-Method
sigmoid	I-Method
function	I-Method
and	O
denotes	O
element	B-Method
-	I-Method
wise	I-Method
multiplication	I-Method
.	O
	
For	O
the	O
sequence	B-Task
modeling	I-Task
tasks	I-Task
,	O
it	O
is	O
beneficial	O
to	O
have	O
access	O
to	O
the	O
past	O
context	O
as	O
well	O
as	O
the	O
future	O
context	O
.	O
	
schuster1997bidirectional	O
proposed	O
BLSTM	B-Method
to	O
extend	O
the	O
unidirectional	O
LSTM	B-Method
by	O
introducing	O
a	O
second	O
hidden	O
layer	O
,	O
where	O
the	O
hidden	O
to	O
hidden	O
connections	O
flow	O
in	O
opposite	O
temporal	O
order	O
.	O
	
Therefore	O
,	O
the	O
model	O
is	O
able	O
to	O
exploit	O
information	O
from	O
both	O
the	O
past	O
and	O
the	O
future	O
.	O
	
In	O
this	O
paper	O
,	O
BLSTM	B-Method
is	O
utilized	O
to	O
capture	O
the	O
past	O
and	O
the	O
future	O
information	O
.	O
	
As	O
shown	O
in	O
Figure	O
1	O
,	O
the	O
network	O
contains	O
two	O
sub	O
-	O
networks	O
for	O
the	O
forward	O
and	O
backward	O
sequence	O
context	O
respectively	O
.	O
	
The	O
output	O
of	O
the	O
word	O
is	O
shown	O
in	O
the	O
following	O
equation	O
:	O
Here	O
,	O
element	O
-	O
wise	O
sum	O
is	O
used	O
to	O
combine	O
the	O
forward	O
and	O
backward	O
pass	O
outputs	O
.	O
	
subsection	O
:	O
Convolutional	B-Method
Neural	I-Method
Networks	I-Method
	
Since	O
BLSTM	B-Method
has	O
access	O
to	O
the	O
future	O
context	O
as	O
well	O
as	O
the	O
past	O
context	O
,	O
is	O
related	O
to	O
all	O
the	O
other	O
words	O
in	O
the	O
text	O
.	O
	
One	O
can	O
effectively	O
treat	O
the	O
matrix	O
,	O
which	O
consists	O
of	O
feature	O
vectors	O
,	O
as	O
an	O
’	O
image	O
’	O
,	O
so	O
2D	B-Method
convolution	I-Method
and	O
2D	B-Method
max	I-Method
pooling	I-Method
operation	I-Method
can	O
be	O
utilized	O
to	O
capture	O
more	O
meaningful	O
information	O
.	O
	
subsubsection	O
:	O
Two	B-Method
-	I-Method
dimensional	I-Method
Convolution	I-Method
Layer	I-Method
	
A	O
matrix	O
,	O
,	O
is	O
obtained	O
from	O
BLSTM	B-Method
Layer	I-Method
,	O
where	O
is	O
the	O
size	O
of	O
word	O
embeddings	O
.	O
	
Then	O
narrow	B-Method
convolution	I-Method
is	O
utilized	O
to	O
extract	O
local	O
features	O
over	O
.	O
	
A	O
convolution	B-Method
operation	I-Method
involves	O
a	O
2D	B-Method
filter	I-Method
,	O
which	O
is	O
applied	O
to	O
a	O
window	O
of	O
k	O
words	O
and	O
d	O
feature	O
vectors	O
.	O
	
For	O
example	O
,	O
a	O
feature	O
is	O
generated	O
from	O
a	O
window	O
of	O
vectors	O
by	O
where	O
ranges	O
from	O
1	O
to	O
,	O
ranges	O
from	O
1	O
to	O
,	O
represents	O
dot	O
product	O
,	O
is	O
a	O
bias	O
and	O
an	O
is	O
a	O
non	O
-	O
linear	O
function	O
such	O
as	O
the	O
hyperbolic	O
tangent	O
.	O
	
This	O
filter	O
is	O
applied	O
to	O
each	O
possible	O
window	O
of	O
the	O
matrix	O
to	O
produce	O
a	O
feature	O
map	O
:	O
with	O
.	O
	
It	O
has	O
described	O
the	O
process	O
of	O
one	O
convolution	B-Method
filter	I-Method
.	O
	
The	O
convolution	B-Method
layer	I-Method
may	O
have	O
multiple	O
filters	O
for	O
the	O
same	O
size	O
filter	O
to	O
learn	O
complementary	O
features	O
,	O
or	O
multiple	O
kinds	O
of	O
filter	O
with	O
different	O
size	O
.	O
	
subsubsection	O
:	O
Two	B-Method
-	I-Method
dimensional	I-Method
Max	I-Method
Pooling	I-Method
Layer	I-Method
	
Then	O
2D	B-Method
max	I-Method
pooling	I-Method
operation	I-Method
is	O
utilized	O
to	O
obtain	O
a	O
fixed	O
length	O
vector	O
.	O
	
For	O
a	O
2D	B-Method
max	I-Method
pooling	I-Method
,	O
it	O
is	O
applied	O
to	O
each	O
possible	O
window	O
of	O
matrix	O
O	O
to	O
extract	O
the	O
maximum	O
value	O
:	O
where	O
represents	O
the	O
2D	B-Method
max	I-Method
pooling	I-Method
function	I-Method
,	O
,	O
and	O
.	O
	
Then	O
the	O
pooling	O
results	O
are	O
combined	O
as	O
follows	O
:	O
where	O
,	O
and	O
the	O
length	O
of	O
is	O
.	O
	
subsection	O
:	O
Output	O
Layer	O
	
For	O
text	B-Task
classification	I-Task
,	O
the	O
output	O
of	O
2D	B-Method
Max	I-Method
Pooling	I-Method
Layer	I-Method
is	O
the	O
whole	O
representation	O
of	O
the	O
input	O
text	O
.	O
	
And	O
then	O
it	O
is	O
passed	O
to	O
a	O
softmax	B-Method
classifier	I-Method
layer	I-Method
to	O
predict	O
the	O
semantic	O
relation	O
label	O
from	O
a	O
discrete	O
set	O
of	O
classes	O
.	O
	
The	O
classifier	B-Method
takes	O
the	O
hidden	O
state	O
as	O
input	O
:	O
A	O
reasonable	O
training	B-Metric
objective	I-Metric
to	O
be	O
minimized	O
is	O
the	O
categorical	B-Metric
cross	I-Metric
-	I-Metric
entropy	I-Metric
loss	I-Metric
.	O
	
The	O
loss	B-Metric
is	O
calculated	O
as	O
a	O
regularized	B-Method
sum	I-Method
:	O
where	O
is	O
the	O
one	O
-	O
hot	O
represented	O
ground	O
truth	O
,	O
is	O
the	O
estimated	O
probability	O
for	O
each	O
class	O
by	O
softmax	O
,	O
is	O
the	O
number	O
of	O
target	O
classes	O
,	O
and	O
is	O
an	O
L2	O
regularization	O
hyper	O
-	O
parameter	O
.	O
	
Training	B-Task
is	O
done	O
through	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
over	O
shuffled	O
mini	O
-	O
batches	O
with	O
the	O
AdaDelta	B-Method
update	I-Method
rule	I-Method
.	O
	
Training	O
details	O
are	O
further	O
introduced	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
Experimental	O
Setup	O
	
subsection	O
:	O
Datasets	O
	
The	O
proposed	O
models	O
are	O
tested	O
on	O
six	O
datasets	O
.	O
	
Summary	O
statistics	O
of	O
the	O
datasets	O
are	O
in	O
Table	O
1	O
.	O
	
MRhttps:	O
//	O
www.cs.cornell.edu	O
/	O
people	O
/	O
pabo	O
/	O
movie	O
-	O
review	O
-	O
data	O
/	O
:	O
Sentence	O
polarity	O
dataset	O
from	O
pang2005seeing	O
.	O
	
The	O
task	O
is	O
to	O
detect	O
positive	O
/	O
negative	O
reviews	O
.	O
	
SST	O
-	O
1http:	O
//	O
nlp.stanford.edu	O
/	O
sentiment	O
/	O
:	O
Stanford	B-Material
Sentiment	I-Material
Treebank	I-Material
is	O
an	O
extension	O
of	O
MR	B-Material
from	O
socher2013recursive	O
.	O
	
The	O
aim	O
is	O
to	O
classify	O
a	O
review	O
as	O
fine	O
-	O
grained	O
labels	O
(	O
very	O
negative	O
,	O
negative	O
,	O
neutral	O
,	O
positive	O
,	O
very	O
positive	O
)	O
.	O
	
SST	B-Material
-	I-Material
2	I-Material
:	O
	
Same	O
as	O
	
SST	B-Material
-	I-Material
1	I-Material
but	O
with	O
neutral	O
reviews	O
removed	O
and	O
binary	O
labels	O
(	O
negative	O
,	O
positive	O
)	O
.	O
	
For	O
both	O
experiments	O
,	O
phrases	O
and	O
sentences	O
are	O
used	O
to	O
train	O
the	O
model	O
,	O
but	O
only	O
sentences	O
are	O
scored	O
at	O
test	O
time	O
.	O
	
Thus	O
the	O
training	O
set	O
is	O
an	O
order	O
of	O
magnitude	O
larger	O
than	O
listed	O
in	O
table	O
1	O
.	O
	
Subjhttp:	O
//	O
www.cs.cornell.edu	O
/	O
people	O
/	O
pabo	O
/	O
movie	O
-	O
review	O
-	O
data	O
/	O
:	O
	
Subjectivity	B-Material
dataset	I-Material
.	O
	
The	O
task	O
is	O
to	O
classify	O
a	O
sentence	O
as	O
being	O
subjective	O
or	O
objective	O
.	O
	
TREChttp:	O
//	O
cogcomp.cs.illinois.edu	O
/	O
Data	O
/	O
QA	O
	
/	O
QC	O
/	O
:	O
	
Question	B-Material
classification	I-Material
dataset	I-Material
.	O
	
The	O
task	O
involves	O
classifying	O
a	O
question	O
into	O
6	O
question	O
types	O
(	O
abbreviation	O
,	O
description	O
,	O
entity	O
,	O
human	O
,	O
location	O
,	O
numeric	O
value	O
)	O
.	O
	
20Newsgroupshttp:	O
//	O
web.ist.utl.pt	O
/	O
acardoso	O
/	O
datasets	O
/	O
:	O
The	O
20Ng	B-Material
dataset	I-Material
contains	O
messages	O
from	O
twenty	O
newsgroups	O
.	O
	
We	O
use	O
the	O
bydate	B-Method
version	I-Method
preprocessed	I-Method
by	O
cachopo2007improving	O
.	O
	
We	O
select	O
four	O
major	O
categories	O
(	O
comp	O
,	O
politics	O
,	O
rec	O
and	O
religion	O
)	O
followed	O
by	O
hingmire2013document	O
.	O
	
subsection	O
:	O
Word	B-Method
Embeddings	I-Method
	
The	O
word	B-Method
embeddings	I-Method
are	O
pre	O
-	O
trained	O
on	O
much	O
larger	O
unannotated	O
corpora	O
to	O
achieve	O
better	O
generalization	B-Task
given	O
limited	O
amount	O
of	O
training	O
data	O
.	O
	
In	O
particular	O
,	O
our	O
experiments	O
utilize	O
the	O
GloVe	B-Method
embeddings	I-Method
trained	O
by	O
pennington2014glove	O
on	O
6	O
billion	O
tokens	O
of	O
Wikipedia	B-Material
2014	I-Material
and	O
Gigaword	B-Material
5	I-Material
.	O
	
Words	O
not	O
present	O
in	O
the	O
set	O
of	O
pre	O
-	O
trained	O
words	O
are	O
initialized	O
by	O
randomly	O
sampling	O
from	O
uniform	O
distribution	O
in	O
.	O
	
The	O
word	O
embeddings	O
are	O
fine	O
-	O
tuned	O
during	O
training	O
to	O
improve	O
the	O
performance	O
of	O
classification	B-Task
.	O
	
subsection	O
:	O
Hyper	O
-	O
parameter	O
Settings	O
	
For	O
datasets	O
without	O
a	O
standard	O
development	O
set	O
we	O
randomly	O
select	O
of	O
the	O
training	O
data	O
as	O
the	O
development	O
set	O
.	O
	
The	O
evaluation	B-Metric
metric	I-Metric
of	O
the	O
20Ng	O
is	O
the	O
Macro	B-Metric
-	I-Metric
F1	I-Metric
measure	I-Metric
followed	O
by	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
work	O
and	O
the	O
other	O
five	O
datasets	O
use	O
accuracy	B-Metric
as	O
the	O
metric	O
.	O
	
The	O
final	O
hyper	O
-	O
parameters	O
are	O
as	O
follows	O
.	O
	
The	O
dimension	O
of	O
word	O
embeddings	O
is	O
300	O
,	O
the	O
hidden	O
units	O
of	O
LSTM	B-Method
is	O
300	O
.	O
	
We	O
use	O
100	O
convolutional	B-Method
filters	I-Method
each	O
for	O
window	O
sizes	O
of	O
(	O
3	O
,	O
3	O
)	O
,	O
2D	O
pooling	O
size	O
of	O
(	O
2	O
,	O
2	O
)	O
.	O
	
We	O
set	O
the	O
mini	O
-	O
batch	O
size	O
as	O
10	O
and	O
the	O
learning	B-Metric
rate	I-Metric
of	O
AdaDelta	B-Method
as	O
the	O
default	O
value	O
1.0	O
.	O
	
For	O
regularization	B-Task
,	O
we	O
employ	O
Dropout	B-Method
operation	I-Method
with	O
dropout	B-Metric
rate	I-Metric
of	O
0.5	O
for	O
the	O
word	O
embeddings	O
,	O
0.2	O
for	O
the	O
BLSTM	B-Method
layer	I-Method
and	O
0.4	O
for	O
the	O
penultimate	O
layer	O
,	O
we	O
also	O
use	O
l2	O
penalty	O
with	O
coefficient	O
over	O
the	O
parameters	O
.	O
	
These	O
values	O
are	O
chosen	O
via	O
a	O
grid	B-Method
search	I-Method
on	O
the	O
SST	B-Material
-	I-Material
1	I-Material
development	O
set	O
.	O
	
We	O
only	O
tune	O
these	O
hyper	O
-	O
parameters	O
,	O
and	O
more	O
finer	O
tuning	O
,	O
such	O
as	O
using	O
different	O
numbers	O
of	O
hidden	O
units	O
of	O
LSTM	B-Method
layer	O
,	O
or	O
using	O
wide	B-Method
convolution	I-Method
,	O
may	O
further	O
improve	O
the	O
performance	O
.	O
	
section	O
:	O
Results	O
	
subsection	O
:	O
Overall	O
Performance	O
	
This	O
work	O
implements	O
four	O
models	O
,	O
BLSTM	B-Method
,	O
BLSTM	B-Method
-	I-Method
Att	I-Method
,	O
BLSTM	B-Method
-	I-Method
2DPooling	I-Method
,	O
and	O
BLSTM	B-Method
-	I-Method
2DCNN	I-Method
.	O
	
Table	O
2	O
presents	O
the	O
performance	O
of	O
the	O
four	O
models	O
and	O
other	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
on	O
six	O
classification	B-Task
tasks	I-Task
.	O
	
The	O
BLSTM	B-Method
-	O
2DCNN	O
model	O
achieves	O
excellent	O
performance	O
on	O
4	O
out	O
of	O
6	O
tasks	O
.	O
	
Especially	O
,	O
it	O
achieves	O
and	O
test	O
accuracies	B-Metric
on	O
SST	B-Material
-	I-Material
1	I-Material
and	O
SST	B-Material
-	I-Material
2	I-Material
respectively	O
.	O
	
BLSTM	B-Method
-	I-Method
2DPooling	I-Method
performs	O
worse	O
than	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
.	O
	
While	O
we	O
expect	O
performance	O
gains	O
through	O
the	O
use	O
of	O
2D	B-Method
convolution	I-Method
,	O
we	O
are	O
surprised	O
at	O
the	O
magnitude	O
of	O
the	O
gains	O
.	O
	
BLSTM	B-Method
-	O
CNN	B-Method
beats	O
all	O
baselines	O
on	O
SST	B-Material
-	I-Material
1	I-Material
,	O
SST	B-Material
-	I-Material
2	I-Material
,	O
and	O
TREC	B-Material
datasets	I-Material
.	O
	
As	O
for	O
Subj	B-Material
and	O
MR	B-Material
datasets	I-Material
,	O
BLSTM	B-Method
-	I-Method
2DCNN	I-Method
gets	O
a	O
second	O
higher	O
accuracies	B-Metric
.	O
	
Some	O
of	O
the	O
previous	O
techniques	O
only	O
work	O
on	O
sentences	O
,	O
but	O
not	O
paragraphs	O
/	O
documents	O
with	O
several	O
sentences	O
.	O
	
Our	O
question	O
becomes	O
whether	O
it	O
is	O
possible	O
to	O
use	O
our	O
models	O
for	O
datasets	O
that	O
have	O
a	O
substantial	O
number	O
of	O
words	O
,	O
such	O
as	O
20Ng	O
and	O
where	O
the	O
content	O
consists	O
of	O
many	O
different	O
topics	O
.	O
	
For	O
that	O
purpose	O
,	O
this	O
paper	O
tests	O
the	O
four	O
models	O
on	O
document	B-Material
-	I-Material
level	I-Material
dataset	I-Material
20Ng	I-Material
,	O
by	O
treating	O
the	O
document	O
as	O
a	O
long	O
sentence	O
.	O
	
Compared	O
with	O
RCNN	B-Method
,	O
BLSTM	B-Method
-	I-Method
2DCNN	I-Method
achieves	O
a	O
comparable	O
result	O
.	O
	
Besides	O
,	O
this	O
paper	O
also	O
compares	O
with	O
ReNN	B-Method
,	O
RNN	B-Method
,	O
CNN	B-Method
and	O
other	O
neural	B-Method
networks	I-Method
:	O
	
Compared	O
with	O
ReNN	B-Method
,	O
the	O
proposed	O
two	O
models	O
do	O
not	O
depend	O
on	O
external	O
language	O
-	O
specific	O
features	O
such	O
as	O
dependency	O
parse	O
trees	O
.	O
	
CNN	B-Method
extracts	O
features	O
from	O
word	O
embeddings	O
of	O
the	O
input	O
text	O
,	O
while	O
BLSTM	B-Method
-	I-Method
2DPooling	I-Method
and	O
BLSTM	B-Method
-	I-Method
2DCNN	I-Method
captures	O
features	O
from	O
the	O
output	O
of	O
BLSTM	B-Method
layer	I-Method
,	O
which	O
has	O
already	O
extracted	O
features	O
from	O
the	O
original	O
input	O
text	O
.	O
	
BLSTM	B-Method
-	I-Method
2DCNN	I-Method
is	O
an	O
extension	O
of	O
BLSTM	B-Method
-	I-Method
2DPooling	I-Method
,	O
and	O
the	O
results	O
show	O
that	O
BLSTM	B-Method
-	I-Method
2DCNN	I-Method
can	O
capture	O
more	O
dependencies	O
in	O
text	O
.	O
	
AdaSent	B-Method
utilizes	O
a	O
more	O
complicated	O
model	O
to	O
form	O
a	O
hierarchy	B-Method
of	I-Method
representations	I-Method
,	O
and	O
it	O
outperforms	O
BLSTM	B-Method
-	I-Method
2DCNN	I-Method
on	O
Subj	B-Material
and	O
MR	B-Material
datasets	I-Material
.	O
	
Compared	O
with	O
DSCNN	B-Method
,	O
BLSTM	B-Method
-	I-Method
2DCNN	I-Method
outperforms	O
it	O
on	O
five	O
datasets	O
.	O
	
Compared	O
with	O
these	O
results	O
,	O
2D	B-Method
convolution	I-Method
and	O
2D	B-Method
max	I-Method
pooling	I-Method
operation	I-Method
are	O
more	O
effective	O
for	O
modeling	O
sentence	O
,	O
even	O
document	O
.	O
	
To	O
better	O
understand	O
the	O
effect	O
of	O
2D	O
operations	O
,	O
this	O
work	O
conducts	O
a	O
sensitivity	B-Method
analysis	I-Method
on	O
SST	B-Material
-	I-Material
1	I-Material
dataset	O
.	O
	
subsection	O
:	O
Effect	O
of	O
Sentence	O
Length	O
	
Figure	O
2	O
depicts	O
the	O
performance	O
of	O
the	O
four	O
models	O
on	O
different	O
length	O
of	O
sentences	O
.	O
	
In	O
the	O
figure	O
,	O
the	O
x	O
-	O
axis	O
represents	O
sentence	O
lengths	O
and	O
y	O
-	O
axis	O
is	O
accuracy	B-Metric
.	O
	
The	O
sentences	O
collected	O
in	O
test	O
set	O
are	O
no	O
longer	O
than	O
45	O
words	O
.	O
	
The	O
accuracy	B-Metric
here	O
is	O
the	O
average	O
value	O
of	O
the	O
sentences	O
with	O
length	O
in	O
the	O
window	O
.	O
	
Each	O
data	O
point	O
is	O
a	O
mean	O
score	O
over	O
5	O
runs	O
,	O
and	O
error	O
bars	O
have	O
been	O
omitted	O
for	O
clarity	O
.	O
	
It	O
is	O
found	O
that	O
both	O
BLSTM	B-Method
-	I-Method
2DPooling	I-Method
and	O
BLSTM	B-Method
-	I-Method
2DCNN	I-Method
outperform	O
the	O
other	O
two	O
models	O
.	O
	
This	O
suggests	O
that	O
both	O
2D	B-Method
convolution	I-Method
and	O
2D	B-Method
max	I-Method
pooling	I-Method
operation	I-Method
are	O
able	O
to	O
encode	O
semantically	O
-	O
useful	O
structural	O
information	O
.	O
	
At	O
the	O
same	O
time	O
,	O
it	O
shows	O
that	O
the	O
accuracies	B-Metric
decline	O
with	O
the	O
length	O
of	O
sentences	O
increasing	O
.	O
	
In	O
future	O
work	O
,	O
we	O
would	O
like	O
to	O
investigate	O
neural	B-Method
mechanisms	I-Method
to	O
preserve	O
long	O
-	O
term	O
dependencies	O
of	O
text	O
.	O
	
subsection	O
:	O
Effect	O
of	O
2D	B-Method
Convolutional	I-Method
Filter	I-Method
and	O
2D	B-Method
Max	I-Method
Pooling	I-Method
Size	I-Method
	
We	O
are	O
interested	O
in	O
what	O
is	O
the	O
best	O
2D	B-Method
filter	I-Method
and	O
max	O
pooling	O
size	O
to	O
get	O
better	O
performance	O
.	O
	
We	O
conduct	O
experiments	O
on	O
SST	B-Material
-	I-Material
1	I-Material
dataset	O
with	O
BLSTM	B-Method
-	I-Method
2DCNN	I-Method
and	O
set	O
the	O
number	O
of	O
feature	O
maps	O
to	O
100	O
.	O
	
To	O
make	O
it	O
simple	O
,	O
we	O
set	O
these	O
two	O
dimensions	O
to	O
the	O
same	O
values	O
,	O
thus	O
both	O
the	O
filter	B-Method
and	O
the	O
pooling	B-Method
are	O
square	B-Method
matrices	I-Method
.	O
	
For	O
the	O
horizontal	O
axis	O
,	O
c	O
means	O
2D	O
convolutional	O
filter	O
size	O
,	O
and	O
the	O
five	O
different	O
color	O
bar	O
charts	O
on	O
each	O
c	O
represent	O
different	O
2D	O
max	O
pooling	O
size	O
from	O
2	O
to	O
6	O
.	O
	
Figure	O
3	O
shows	O
that	O
different	O
size	O
of	O
filter	O
and	O
pooling	O
can	O
get	O
different	O
accuracies	B-Metric
.	O
	
The	O
best	O
accuracy	B-Metric
is	O
52.6	O
with	O
2D	O
filter	O
size	O
(	O
5	O
,	O
5	O
)	O
and	O
2D	O
max	O
pooling	O
size	O
(	O
5	O
,	O
5	O
)	O
	
,	O
this	O
shows	O
that	O
finer	O
tuning	O
can	O
further	O
improve	O
the	O
performance	O
reported	O
here	O
.	O
	
And	O
if	O
a	O
larger	O
filter	B-Method
is	O
used	O
,	O
the	O
convolution	B-Method
can	O
detector	O
more	O
features	O
,	O
and	O
the	O
performance	O
may	O
be	O
improved	O
,	O
too	O
.	O
	
However	O
,	O
the	O
networks	O
will	O
take	O
up	O
more	O
storage	O
space	O
,	O
and	O
consume	O
more	O
time	O
.	O
	
section	O
:	O
Conclusion	O
	
This	O
paper	O
introduces	O
two	O
combination	B-Method
models	I-Method
,	O
one	O
is	O
BLSTM	B-Method
-	I-Method
2DPooling	I-Method
,	O
the	O
other	O
is	O
BLSTM	B-Method
-	I-Method
2DCNN	I-Method
,	O
which	O
can	O
be	O
seen	O
as	O
an	O
extension	O
of	O
BLSTM	B-Method
-	I-Method
2DPooling	I-Method
.	O
	
Both	O
models	O
can	O
hold	O
not	O
only	O
the	O
time	O
-	O
step	O
dimension	O
but	O
also	O
the	O
feature	O
vector	O
dimension	O
information	O
.	O
	
The	O
experiments	O
are	O
conducted	O
on	O
six	O
text	B-Task
classificaion	I-Task
tasks	I-Task
.	O
	
The	O
experiments	O
results	O
demonstrate	O
that	O
BLSTM	B-Method
-	I-Method
2DCNN	I-Method
not	O
only	O
outperforms	O
RecNN	B-Method
,	O
RNN	B-Method
and	O
CNN	B-Method
models	O
,	O
but	O
also	O
works	O
better	O
than	O
the	O
BLSTM	B-Method
-	I-Method
2DPooling	I-Method
and	O
DSCNN	B-Method
.	O
	
Especially	O
,	O
BLSTM	B-Method
-	I-Method
2DCNN	I-Method
achieves	O
highest	O
accuracy	B-Metric
on	O
SST	B-Material
-	I-Material
1	I-Material
and	O
SST	B-Material
-	I-Material
2	I-Material
datasets	I-Material
.	O
	
To	O
better	O
understand	O
the	O
effective	O
of	O
the	O
proposed	O
two	O
models	O
,	O
this	O
work	O
also	O
conducts	O
a	O
sensitivity	B-Task
analysis	I-Task
on	O
SST	B-Material
-	I-Material
1	I-Material
dataset	O
.	O
	
It	O
is	O
found	O
that	O
large	B-Method
filter	I-Method
can	O
detector	O
more	O
features	O
,	O
and	O
this	O
may	O
lead	O
to	O
performance	O
improvement	O
.	O
	
section	O
:	O
Acknowledgements	O
	
We	O
thank	O
anonymous	O
reviewers	O
for	O
their	O
constructive	O
comments	O
.	O
	
This	O
research	O
was	O
funded	O
by	O
the	O
National	O
High	O
Technology	O
Research	O
and	O
Development	O
Program	O
of	O
China	O
(	O
No.2015AA015402	O
)	O
,	O
and	O
the	O
National	O
Natural	O
Science	O
Foundation	O
of	O
China	O
(	O
No	O
.	O
61602479	O
)	O
,	O
and	O
the	O
Strategic	O
Priority	O
Research	O
Program	O
of	O
the	O
Chinese	O
Academy	O
of	O
Sciences	O
	
(	O
Grant	O
No	O
.	O
XDB02070005	O
)	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Order	B-Task
-	I-Task
Embeddings	I-Task
of	I-Task
Images	I-Task
and	I-Task
Language	I-Task
	
Hypernymy	B-Method
,	O
textual	B-Task
entailment	I-Task
,	O
and	O
image	B-Task
captioning	I-Task
can	O
be	O
seen	O
as	O
special	O
cases	O
of	O
a	O
single	O
visual	O
-	O
semantic	O
hierarchy	O
over	O
words	O
,	O
sentences	O
,	O
and	O
images	O
.	O
	
In	O
this	O
paper	O
we	O
advocate	O
for	O
explicitly	O
modeling	O
the	O
partial	O
order	O
structure	O
of	O
this	O
hierarchy	O
.	O
	
Towards	O
this	O
goal	O
,	O
we	O
introduce	O
a	O
general	O
method	O
for	O
learning	B-Task
ordered	I-Task
representations	I-Task
,	O
and	O
show	O
how	O
it	O
can	O
be	O
applied	O
to	O
a	O
variety	O
of	O
tasks	O
involving	O
images	O
and	O
language	B-Task
.	O
	
We	O
show	O
that	O
the	O
resulting	O
representations	O
improve	O
performance	O
over	O
current	O
approaches	O
for	O
hypernym	B-Task
prediction	I-Task
and	O
image	B-Task
-	I-Task
caption	I-Task
retrieval	I-Task
.	O
	
section	O
:	O
Introduction	O
	
Computer	O
vision	B-Task
and	O
natural	B-Task
language	I-Task
processing	I-Task
are	O
becoming	O
increasingly	O
intertwined	O
.	O
	
Recent	O
work	O
in	O
vision	B-Task
has	O
moved	O
beyond	O
discriminating	O
between	O
a	O
fixed	O
set	O
of	O
object	O
classes	O
,	O
to	O
automatically	O
generating	O
open	B-Method
-	I-Method
ended	I-Method
lingual	I-Method
descriptions	I-Method
of	I-Method
images	I-Method
vinyals2015show	O
.	O
	
Recent	O
methods	O
for	O
natural	B-Task
language	I-Task
processing	I-Task
such	O
as	O
flickr30k	B-Method
learn	O
the	O
semantics	O
of	O
language	B-Task
by	O
grounding	O
it	O
in	O
the	O
visual	O
world	O
.	O
	
Looking	O
to	O
the	O
future	O
,	O
autonomous	B-Task
artificial	I-Task
agents	I-Task
will	O
need	O
to	O
jointly	O
model	O
vision	B-Task
and	O
language	B-Task
in	O
order	O
to	O
parse	O
the	O
visual	O
world	O
and	O
communicate	O
with	O
people	O
.	O
	
But	O
what	O
,	O
precisely	O
,	O
is	O
the	O
relationship	O
between	O
images	O
and	O
the	O
words	O
or	O
captions	O
we	O
use	O
to	O
describe	O
them	O
?	O
	
It	O
is	O
akin	O
to	O
the	O
hypernym	O
relation	O
between	O
words	O
,	O
and	O
textual	O
entailment	O
among	O
phrases	O
:	O
captions	O
are	O
simply	O
abstractions	O
of	O
images	O
.	O
	
In	O
fact	O
,	O
all	O
three	O
relations	O
can	O
be	O
seen	O
as	O
special	O
cases	O
of	O
a	O
partial	O
order	O
over	O
images	O
and	O
language	B-Task
,	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
which	O
we	O
refer	O
to	O
as	O
the	O
visual	O
-	O
semantic	O
hierarchy	O
.	O
	
As	O
a	O
partial	O
order	O
,	O
this	O
relation	O
is	O
transitive	O
:	O
“	O
woman	O
walking	O
her	O
dog	O
”	O
,	O
“	O
woman	O
walking	O
”	O
,	O
“	O
person	O
walking	O
”	O
,	O
“	O
person	O
”	O
,	O
and	O
“	O
entity	O
”	O
are	O
all	O
valid	O
abstractions	O
of	O
the	O
rightmost	O
image	O
.	O
	
Our	O
goal	O
in	O
this	O
work	O
is	O
to	O
learn	O
representations	O
that	O
respect	O
this	O
partial	O
order	O
structure	O
.	O
	
Most	O
recent	O
approaches	O
to	O
modeling	O
the	O
hypernym	B-Task
,	I-Task
entailment	I-Task
,	I-Task
and	I-Task
image	I-Task
-	I-Task
caption	I-Task
relations	I-Task
involve	O
learning	O
distributed	B-Method
representations	I-Method
or	O
embeddings	B-Method
.	O
	
This	O
is	O
a	O
very	O
powerful	O
and	O
general	O
approach	O
which	O
maps	O
the	O
objects	O
of	O
interest	O
—	O
words	O
,	O
phrases	O
,	O
images—	O
to	O
points	O
in	O
a	O
high	O
-	O
dimensional	O
vector	O
space	O
.	O
	
One	O
line	O
of	O
work	O
,	O
exemplified	O
by	O
chopra2005learning	O
and	O
first	O
applied	O
to	O
the	O
caption	B-Task
-	I-Task
image	I-Task
relationship	I-Task
by	O
socher2014grounded	O
,	O
requires	O
the	O
mapping	B-Task
to	O
be	O
distance	O
-	O
preserving	O
:	O
semantically	O
similar	O
objects	O
are	O
mapped	O
to	O
points	O
that	O
are	O
nearby	O
in	O
the	O
embedding	O
space	O
.	O
	
A	O
symmetric	B-Metric
distance	I-Metric
measure	I-Metric
such	O
as	O
Euclidean	B-Method
or	I-Method
cosine	I-Method
distance	I-Method
is	O
typically	O
used	O
.	O
	
Since	O
the	O
visual	O
-	O
semantic	O
hierarchy	O
is	O
an	O
anti	O
symmetric	O
relation	O
,	O
we	O
expect	O
this	O
approach	O
to	O
introduce	O
systematic	O
model	B-Metric
error	I-Metric
.	O
	
Other	O
approaches	O
do	O
not	O
have	O
such	O
explicit	O
constraints	O
,	O
learning	O
a	O
more	O
-	O
or	O
-	O
less	O
general	O
binary	O
relation	O
between	O
the	O
objects	O
of	O
interest	O
,	O
e.g.	O
bordes2011learning	O
,	O
socher2013reasoning	O
,	O
ma2015multimodal	O
.	O
	
Notably	O
,	O
no	O
existing	O
approach	O
directly	O
imposes	O
the	O
transitivity	O
and	O
antisymmetry	O
of	O
the	O
partial	O
order	O
,	O
leaving	O
the	O
model	O
to	O
induce	O
these	O
properties	O
from	O
data	O
.	O
	
In	O
contrast	O
,	O
we	O
propose	O
to	O
exploit	O
the	O
partial	O
order	O
structure	O
of	O
the	O
visual	O
-	O
semantic	O
hierarchy	O
by	O
learning	O
a	O
mapping	B-Method
which	O
is	O
not	O
distance	O
-	O
preserving	O
but	O
order	O
-	O
preserving	O
between	O
the	O
visual	O
-	O
semantic	O
hierarchy	O
and	O
a	O
partial	O
order	O
over	O
the	O
embedding	O
space	O
.	O
	
We	O
call	O
embeddings	O
learned	O
in	O
this	O
way	O
order	B-Method
-	I-Method
embeddings	I-Method
.	O
	
This	O
idea	O
can	O
be	O
integrated	O
into	O
existing	O
relational	B-Method
learning	I-Method
methods	I-Method
simply	O
by	O
replacing	O
their	O
comparison	B-Method
operation	I-Method
with	O
ours	O
.	O
	
By	O
modifying	O
existing	O
methods	O
in	O
this	O
way	O
,	O
we	O
find	O
that	O
order	B-Method
-	I-Method
embeddings	I-Method
provide	O
a	O
marked	O
improvement	O
over	O
the	O
state	O
-	O
of	O
-	O
art	O
for	O
hypernymy	B-Task
prediction	I-Task
and	O
caption	B-Task
-	I-Task
image	I-Task
retrieval	I-Task
,	O
and	O
near	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
for	O
natural	B-Task
language	I-Task
inference	I-Task
.	O
	
This	O
paper	O
is	O
structured	O
as	O
follows	O
.	O
	
We	O
begin	O
,	O
in	O
Section	O
[	O
reference	O
]	O
,	O
by	O
giving	O
a	O
unified	O
mathematical	O
treatment	O
of	O
our	O
tasks	O
,	O
and	O
describing	O
the	O
general	O
approach	O
of	O
learning	B-Task
order	I-Task
-	I-Task
embeddings	I-Task
.	O
	
In	O
the	O
next	O
three	O
sections	O
we	O
describe	O
in	O
detail	O
the	O
tasks	O
we	O
tackle	O
,	O
how	O
we	O
apply	O
the	O
order	B-Method
-	I-Method
embeddings	I-Method
idea	I-Method
to	O
each	O
of	O
them	O
,	O
and	O
the	O
results	O
we	O
obtain	O
.	O
	
The	O
tasks	O
are	O
hypernym	B-Task
prediction	I-Task
(	O
Section	O
[	O
reference	O
]	O
)	O
,	O
caption	B-Task
-	I-Task
image	I-Task
retrieval	I-Task
(	O
Section	O
[	O
reference	O
]	O
)	O
,	O
and	O
textual	B-Task
entailment	I-Task
(	O
Section	O
[	O
reference	O
]	O
)	O
.	O
	
In	O
the	O
supplementary	O
material	O
,	O
we	O
visualize	O
novel	O
vector	O
regularities	O
that	O
emerge	O
in	O
our	O
learned	O
embeddings	O
of	O
images	O
and	O
language	B-Task
.	O
	
section	O
:	O
Learning	B-Task
Order	I-Task
-	I-Task
Embeddings	I-Task
	
To	O
unify	O
our	O
treatment	O
of	O
various	O
tasks	O
,	O
we	O
introduce	O
the	O
problem	O
of	O
partial	B-Task
order	I-Task
completion	I-Task
.	O
	
In	O
partial	B-Task
order	I-Task
completion	I-Task
,	O
we	O
are	O
given	O
a	O
set	O
of	O
positive	O
examples	O
of	O
ordered	O
pairs	O
drawn	O
from	O
a	O
partially	O
ordered	O
set	O
,	O
and	O
a	O
set	O
of	O
negative	O
examples	O
which	O
we	O
know	O
to	O
be	O
unordered	O
.	O
	
Our	O
goal	O
is	O
to	O
predict	O
whether	O
an	O
unseen	O
pair	O
is	O
ordered	O
.	O
	
Note	O
that	O
hypernym	B-Task
prediction	I-Task
,	O
caption	B-Task
-	I-Task
image	I-Task
retrieval	I-Task
,	O
and	O
textual	B-Task
entailment	I-Task
are	O
all	O
special	O
cases	O
of	O
this	O
task	O
,	O
since	O
they	O
all	O
involve	O
classifying	O
pairs	O
of	O
concepts	O
in	O
the	O
(	O
partially	O
ordered	O
)	O
visual	O
-	O
semantic	O
hierarchy	O
.	O
	
We	O
tackle	O
this	O
problem	O
by	O
learning	O
a	O
mapping	O
from	O
into	O
a	O
partially	O
ordered	O
embedding	O
space	O
.	O
	
The	O
idea	O
is	O
to	O
predict	O
the	O
ordering	O
of	O
an	O
unseen	O
pair	O
in	O
based	O
on	O
its	O
ordering	O
in	O
the	O
embedding	O
space	O
.	O
	
This	O
is	O
possible	O
only	O
if	O
the	O
mapping	O
satisfies	O
the	O
following	O
crucial	O
property	O
:	O
	
theorem	O
:	O
.	O
	
A	O
function	O
:	O
f→	O
(	O
X	O
,	O
⪯X	O
)(	O
Y	O
,	O
⪯Y	O
)	O
is	O
an	O
order	B-Method
-	I-Method
embedding	I-Method
if	O
for	O
all	O
∈u	O
,	O
	
vX	O
,	O
This	O
definition	O
implies	O
that	O
each	O
combination	O
of	O
embedding	O
space	O
,	O
order	O
,	O
and	O
order	B-Method
-	I-Method
embedding	I-Method
determines	O
a	O
unique	O
completion	O
of	O
our	O
data	O
as	O
a	O
partial	O
order	O
.	O
	
In	O
the	O
following	O
,	O
we	O
first	O
consider	O
the	O
choice	O
of	O
and	O
,	O
and	O
then	O
discuss	O
how	O
to	O
find	O
an	O
appropriate	O
.	O
	
subsection	O
:	O
The	O
Reversed	O
Product	O
Order	O
on	O
	
The	O
choice	O
of	O
and	O
is	O
somewhat	O
application	O
-	O
dependent	O
.	O
	
For	O
the	O
purpose	O
of	O
modeling	O
the	O
semantic	B-Task
hierarchy	I-Task
,	O
our	O
choices	O
are	O
narrowed	O
by	O
the	O
following	O
considerations	O
.	O
	
Much	O
of	O
the	O
expressive	O
power	O
of	O
human	O
language	B-Task
comes	O
from	O
abstraction	B-Method
and	O
composition	B-Task
.	O
	
For	O
any	O
two	O
concepts	O
,	O
say	O
“	O
dog	O
”	O
and	O
“	O
cat	O
”	O
,	O
we	O
can	O
name	O
a	O
concept	O
that	O
is	O
an	O
abstraction	O
of	O
the	O
two	O
,	O
such	O
as	O
“	O
mammal	O
”	O
,	O
as	O
well	O
as	O
a	O
concept	O
that	O
composes	O
the	O
two	O
,	O
such	O
as	O
“	O
dog	O
chasing	O
cat	O
”	O
.	O
	
So	O
,	O
in	O
order	O
to	O
represent	O
the	O
visual	O
-	O
semantic	O
hierarchy	O
,	O
we	O
need	O
to	O
choose	O
an	O
order	O
that	O
is	O
rich	O
enough	O
to	O
embed	O
these	O
two	O
relations	O
.	O
	
We	O
also	O
restrict	O
ourselves	O
to	O
orders	O
with	O
a	O
top	O
element	O
,	O
which	O
is	O
above	O
every	O
other	O
element	O
in	O
the	O
order	O
.	O
	
In	O
the	O
visual	O
-	O
semantic	O
hierarchy	O
,	O
this	O
element	O
represents	O
the	O
most	O
general	O
possible	O
concept	O
;	O
practically	O
,	O
it	O
provides	O
an	O
anchor	O
for	O
the	O
embedding	B-Task
.	O
	
Finally	O
,	O
we	O
choose	O
the	O
embedding	O
space	O
to	O
be	O
continuous	O
in	O
order	O
to	O
allow	O
optimization	B-Task
with	O
gradient	B-Method
-	I-Method
based	I-Method
methods	I-Method
.	O
	
A	O
natural	O
choice	O
that	O
satisfies	O
all	O
three	O
properties	O
is	O
the	O
reversed	O
product	O
order	O
on	O
,	O
defined	O
by	O
the	O
conjunction	O
of	O
total	O
orders	O
on	O
each	O
coordinate	O
:	O
for	O
all	O
vectors	O
with	O
nonnegative	O
coordinates	O
.	O
	
Note	O
the	O
reversal	O
of	O
direction	O
:	O
smaller	O
coordinates	O
imply	O
higher	O
position	O
in	O
the	O
partial	O
order	O
.	O
	
The	O
origin	O
is	O
then	O
the	O
top	O
element	O
of	O
the	O
order	O
,	O
representing	O
the	O
most	O
general	O
concept	O
.	O
	
Instead	O
of	O
viewing	O
our	O
embeddings	O
as	O
single	O
points	O
,	O
we	O
can	O
also	O
view	O
them	O
as	O
sets	O
.	O
	
The	O
meaning	O
of	O
a	O
word	O
is	O
then	O
the	O
union	O
of	O
all	O
concepts	O
of	O
which	O
it	O
is	O
a	O
hypernym	O
,	O
and	O
the	O
meaning	O
of	O
a	O
sentence	O
is	O
the	O
union	O
of	O
all	O
sentences	O
that	O
entail	O
it	O
.	O
	
The	O
visual	O
-	O
semantic	O
hierarchy	O
can	O
then	O
be	O
seen	O
as	O
a	O
special	O
case	O
of	O
the	O
subset	O
relation	O
,	O
a	O
connection	O
also	O
used	O
by	O
flickr30k	B-Method
.	O
	
subsection	O
:	O
Penalizing	B-Task
Order	I-Task
Violations	I-Task
	
Having	O
fixed	O
the	O
embedding	O
space	O
and	O
order	O
,	O
we	O
now	O
consider	O
the	O
problem	O
of	O
finding	O
an	O
order	B-Method
-	I-Method
embedding	I-Method
into	O
this	O
space	O
.	O
	
In	O
practice	O
,	O
the	O
order	O
embedding	O
condition	O
(	O
Definition	O
[	O
reference	O
]	O
)	O
is	O
too	O
restrictive	O
to	O
impose	O
as	O
a	O
hard	O
constraint	O
.	O
	
Instead	O
,	O
we	O
aim	O
to	O
find	O
an	O
approximate	B-Method
order	I-Method
-	I-Method
embedding	I-Method
:	O
a	O
mapping	B-Method
which	O
violates	O
the	O
order	O
-	O
embedding	O
condition	O
,	O
imposed	O
as	O
a	O
soft	O
constraint	O
,	O
as	O
little	O
as	O
possible	O
.	O
	
More	O
precisely	O
,	O
we	O
define	O
a	O
penalty	O
that	O
measures	O
the	O
degree	O
to	O
which	O
a	O
pair	O
of	O
points	O
violates	O
the	O
product	O
order	O
.	O
	
In	O
particular	O
,	O
we	O
define	O
the	O
penalty	O
for	O
an	O
ordered	O
pair	O
of	O
points	O
in	O
as	O
Crucially	O
,	O
according	O
to	O
the	O
reversed	O
product	O
order	O
;	O
if	O
the	O
order	O
is	O
not	O
satisfied	O
,	O
is	O
positive	O
.	O
	
This	O
effectively	O
imposes	O
a	O
strong	O
prior	O
on	O
the	O
space	O
of	O
relations	O
,	O
encouraging	O
our	O
learned	O
relation	O
to	O
satisfy	O
the	O
partial	O
order	O
properties	O
of	O
transitivity	O
and	O
antisymmetry	O
.	O
	
This	O
penalty	O
is	O
key	O
to	O
our	O
method	O
.	O
	
Throughout	O
the	O
remainder	O
of	O
the	O
paper	O
,	O
we	O
will	O
use	O
it	O
where	O
previous	O
work	O
has	O
used	O
symmetric	O
distances	O
or	O
learned	O
comparison	O
operators	O
.	O
	
Recall	O
that	O
and	O
are	O
our	O
positive	O
and	O
negative	O
examples	O
,	O
respectively	O
.	O
	
Then	O
,	O
to	O
learn	O
an	O
approximate	B-Task
order	I-Task
-	I-Task
embedding	I-Task
,	O
we	O
could	O
use	O
a	O
max	B-Method
-	I-Method
margin	I-Method
loss	I-Method
which	O
encourages	O
positive	O
examples	O
to	O
have	O
zero	O
penalty	O
,	O
and	O
negative	O
examples	O
to	O
have	O
penalty	O
greater	O
than	O
a	O
margin	O
:	O
In	O
practice	O
we	O
are	O
often	O
not	O
given	O
negative	O
examples	O
,	O
in	O
which	O
case	O
this	O
loss	O
admits	O
the	O
trivial	O
solution	O
of	O
mapping	O
all	O
objects	O
to	O
the	O
same	O
point	O
.	O
	
The	O
best	O
way	O
of	O
dealing	O
with	O
this	O
problem	O
depends	O
on	O
the	O
application	O
,	O
so	O
we	O
will	O
describe	O
task	O
-	O
specific	O
variations	O
of	O
the	O
loss	O
in	O
the	O
next	O
several	O
sections	O
.	O
	
section	O
:	O
Hypernym	B-Task
Prediction	I-Task
	
To	O
test	O
the	O
ability	O
of	O
our	O
model	O
to	O
learn	O
partial	O
orders	O
from	O
incomplete	O
data	O
,	O
our	O
first	O
task	O
is	O
to	O
predict	O
withheld	O
hypernym	O
pairs	O
in	O
WordNet	B-Material
miller1995wordnet	O
.	O
	
A	O
hypernym	O
pair	O
is	O
a	O
pair	O
of	O
concepts	O
where	O
the	O
first	O
concept	O
is	O
a	O
specialization	O
or	O
an	O
instance	O
of	O
the	O
second	O
,	O
e.g.	O
,	O
(	O
woman	O
,	O
person	O
)	O
or	O
(	O
New	O
York	O
,	O
city	O
)	O
.	O
	
Our	O
setup	O
differs	O
significantly	O
from	O
previous	O
work	O
in	O
that	O
we	O
use	O
only	O
the	O
WordNet	B-Material
hierarchy	O
as	O
training	O
data	O
.	O
	
The	O
most	O
similar	O
evaluation	O
has	O
been	O
that	O
of	O
baroni2012entailment	O
,	O
who	O
use	O
external	O
linguistic	O
data	O
in	O
the	O
form	O
of	O
distributional	O
semantic	O
vectors	O
.	O
	
bordes2011learning	O
and	O
socher2013reasoning	O
also	O
evaluate	O
on	O
the	O
WordNet	B-Material
hierarchy	O
,	O
but	O
they	O
use	O
other	O
relations	O
in	O
WordNet	B-Material
as	O
training	O
data	O
(	O
and	O
external	O
linguistic	O
data	O
,	O
in	O
Socher	O
’s	O
case	O
)	O
.	O
	
Additionally	O
,	O
the	O
latter	O
two	O
consider	O
only	O
direct	O
hypernyms	O
,	O
rather	O
than	O
the	O
full	O
,	O
transitive	O
hypernymy	O
relation	O
.	O
	
But	O
predicting	O
the	O
transitive	O
hypernym	O
relation	O
is	O
a	O
better	O
-	O
defined	O
problem	O
because	O
individual	O
hypernym	O
edges	O
in	O
WordNet	B-Material
vary	O
dramatically	O
in	O
the	O
degree	O
of	O
abstraction	O
they	O
require	O
.	O
	
For	O
instance	O
,	O
(	O
person	O
,	O
organism	O
)	O
is	O
a	O
direct	O
hypernym	O
pair	O
,	O
but	O
it	O
takes	O
eight	O
hypernym	O
edges	O
to	O
get	O
from	O
cat	O
to	O
organism	O
.	O
	
subsection	O
:	O
Loss	B-Method
Function	I-Method
	
To	O
apply	O
order	O
-	O
embeddings	O
to	O
hypernymy	O
,	O
we	O
follow	O
the	O
setup	O
of	O
socher2013reasoning	O
in	O
learning	O
an	O
N	O
-	O
dimensional	O
vector	O
for	O
each	O
concept	O
in	O
WordNet	B-Material
,	O
but	O
we	O
replace	O
their	O
neural	B-Method
tensor	I-Method
network	I-Method
with	O
our	O
order	O
-	O
violation	O
penalty	O
defined	O
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
	
Just	O
like	O
them	O
,	O
we	O
corrupt	O
each	O
hypernym	O
pair	O
by	O
replacing	O
one	O
of	O
the	O
two	O
concepts	O
with	O
a	O
randomly	O
chosen	O
concept	O
,	O
and	O
use	O
these	O
corrupted	O
pairs	O
as	O
negative	O
examples	O
for	O
both	O
training	O
and	O
evaluation	B-Task
.	O
	
We	O
use	O
their	O
max	B-Method
-	I-Method
margin	I-Method
loss	I-Method
,	O
which	O
encourages	O
the	O
order	O
-	O
violation	O
penalty	O
to	O
be	O
zero	O
for	O
positive	O
examples	O
,	O
and	O
greater	O
than	O
a	O
margin	O
for	O
negative	O
examples	O
:	O
where	O
is	O
our	O
order	O
-	O
violation	O
penalty	O
,	O
and	O
is	O
a	O
corrupted	O
version	O
of	O
.	O
	
Since	O
we	O
learn	O
an	O
independent	O
embedding	O
for	O
each	O
concept	O
,	O
the	O
mapping	O
is	O
simply	O
a	O
lookup	O
table	O
.	O
	
subsection	O
:	O
Dataset	O
	
The	O
transitive	O
closure	O
of	O
the	O
WordNet	B-Material
hierarchy	O
gives	O
us	O
edges	O
between	O
concepts	O
in	O
WordNet	B-Material
.	O
	
Like	O
bordes2011learning	O
,	O
we	O
randomly	O
select	O
edges	O
for	O
the	O
test	O
split	O
,	O
and	O
another	O
for	O
the	O
development	O
set	O
.	O
	
Note	O
that	O
the	O
majority	O
of	O
test	O
set	O
edges	O
can	O
be	O
inferred	O
simply	O
by	O
applying	O
transitivity	B-Method
,	O
giving	O
us	O
a	O
strong	O
baseline	O
.	O
	
subsection	O
:	O
Details	O
of	O
Training	O
	
We	O
learn	O
a	O
50	O
-	O
dimensional	O
nonnegative	O
vector	O
for	O
each	O
concept	O
in	O
WordNet	B-Material
using	O
the	O
max	B-Method
-	I-Method
margin	I-Method
objective	I-Method
(	O
[	O
reference	O
]	O
)	O
with	O
margin	O
,	O
sampling	O
500	O
true	O
and	O
500	O
false	O
hypernym	O
pairs	O
in	O
each	O
batch	O
.	O
	
We	O
train	O
for	O
30	O
-	O
50	O
epochs	O
using	O
the	O
Adam	B-Method
optimizer	I-Method
adam	I-Method
with	O
learning	B-Method
rate	I-Method
and	O
early	B-Method
stopping	I-Method
on	O
the	O
validation	O
set	O
.	O
	
During	O
evaluation	O
,	O
we	O
find	O
the	O
optimal	O
classification	B-Metric
threshold	I-Metric
on	O
the	O
validation	O
set	O
,	O
then	O
apply	O
it	O
to	O
the	O
test	O
set	O
.	O
	
subsection	O
:	O
Results	O
	
Since	O
our	O
setup	O
is	O
novel	O
,	O
there	O
are	O
no	O
published	O
numbers	O
to	O
compare	O
to	O
.	O
	
We	O
therefore	O
compare	O
three	O
variants	O
of	O
our	O
model	O
to	O
two	O
baselines	O
,	O
with	O
results	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
The	O
transitive	B-Method
closure	I-Method
baseline	I-Method
involves	O
no	O
learning	B-Method
;	O
it	O
simply	O
classifies	O
hypernyms	O
pairs	O
as	O
positive	O
if	O
they	O
are	O
in	O
the	O
transitive	O
closure	O
of	O
the	O
union	O
of	O
edges	O
in	O
the	O
training	O
and	O
validation	O
sets	O
.	O
	
The	O
word2gauss	B-Method
baseline	I-Method
evaluates	O
the	O
approach	O
of	O
word2gauss	B-Method
to	O
represent	O
words	O
as	O
Gaussian	O
densities	O
rather	O
than	O
points	O
in	O
the	O
embedding	O
space	O
.	O
	
This	O
allows	O
a	O
natural	O
representation	O
of	O
hierarchies	O
using	O
the	O
KL	B-Method
divergence	I-Method
.	O
	
We	O
used	O
50	B-Method
-	I-Method
dimensional	I-Method
diagonal	I-Method
Gaussian	I-Method
embeddings	I-Method
,	O
trained	O
for	O
200	O
epochs	O
on	O
a	O
max	B-Metric
-	I-Metric
margin	I-Metric
objective	I-Metric
with	O
margin	O
,	O
chosen	O
by	O
grid	B-Method
search	I-Method
.	O
	
order	B-Method
-	I-Method
embeddings	I-Method
(	O
symmetric	O
)	O
is	O
our	O
full	B-Method
model	I-Method
,	O
but	O
using	O
symmetric	O
cosine	O
distance	O
instead	O
of	O
our	O
asymmetric	O
penalty	O
.	O
	
order	B-Method
-	I-Method
embeddings	I-Method
(	O
bilinear	B-Method
)	I-Method
replaces	O
our	O
penalty	O
with	O
the	O
bilinear	B-Method
model	I-Method
used	O
by	O
socher2013reasoning	O
.	O
	
order	B-Method
-	I-Method
embeddings	I-Method
is	O
our	O
full	O
model	O
.	O
	
Only	O
our	O
full	O
model	O
can	O
do	O
better	O
than	O
the	O
transitive	B-Method
baseline	I-Method
,	O
showing	O
the	O
value	O
of	O
exploiting	O
partial	O
order	O
structure	O
in	O
contrast	O
to	O
using	O
symmetric	O
similarity	O
or	O
learning	O
a	O
general	O
binary	O
relation	O
as	O
most	O
previous	O
work	O
and	O
our	O
bilinear	B-Method
baseline	I-Method
do	O
.	O
	
The	O
resulting	O
50	O
-	O
dimensional	O
embeddings	O
are	O
difficult	O
to	O
visualize	O
.	O
	
To	O
give	O
some	O
intuition	O
for	O
the	O
structure	O
being	O
learned	O
,	O
Figure	O
[	O
reference	O
]	O
shows	O
the	O
results	O
of	O
a	O
toy	O
2D	O
experiment	O
.	O
	
section	O
:	O
Caption	B-Task
-	O
Image	B-Task
Retrieval	I-Task
	
The	O
caption	B-Task
-	I-Task
image	I-Task
retrieval	I-Task
task	I-Task
has	O
become	O
a	O
standard	O
evaluation	O
of	O
joint	B-Method
models	I-Method
of	O
vision	B-Task
and	O
language	B-Task
hodosh2013framing	O
,	O
LinCVPR14	B-Task
.	O
	
The	O
task	O
involves	O
ranking	B-Task
a	O
large	O
dataset	O
of	O
images	O
by	O
relevance	O
for	O
a	O
query	O
caption	O
(	O
Image	B-Task
Retrieval	I-Task
)	O
,	O
and	O
ranking	B-Task
captions	I-Task
by	O
relevance	B-Task
for	O
a	O
query	O
image	O
(	O
Caption	B-Task
Retrieval	I-Task
)	O
.	O
	
Given	O
a	O
set	O
of	O
aligned	O
image	O
-	O
caption	O
pairs	O
as	O
training	O
data	O
,	O
the	O
goal	O
is	O
then	O
to	O
learn	O
a	O
caption	B-Metric
-	I-Metric
image	I-Metric
compatibility	I-Metric
score	I-Metric
to	O
be	O
used	O
at	O
test	O
time	O
.	O
	
Many	O
modern	O
approaches	O
model	O
the	O
caption	O
-	O
image	O
relationship	O
symmetrically	O
,	O
either	O
by	O
embedding	O
into	O
a	O
common	O
“	O
visual	O
-	O
semantic	O
”	O
space	O
with	O
inner	B-Method
-	I-Method
product	I-Method
similarity	I-Method
socher2014grounded	O
,	O
kiros2014	O
,	O
or	O
by	O
using	O
Canonical	B-Method
Correlations	I-Method
Analysis	I-Method
between	O
distributed	B-Method
representations	I-Method
of	I-Method
images	I-Method
and	O
captions	B-Method
klein2015fisher	O
.	O
	
While	O
karpathydeep	O
and	O
plummer2015flickr30k	O
model	O
a	O
finer	O
-	O
grained	O
alignment	O
between	O
regions	O
in	O
the	O
image	O
and	O
segments	O
of	O
the	O
caption	O
,	O
the	O
similarity	O
they	O
use	O
is	O
still	O
symmetric	O
.	O
	
An	O
alternative	O
is	O
to	O
learn	O
an	O
unconstrained	O
binary	O
relation	O
,	O
either	O
with	O
a	O
neural	O
language	B-Task
model	O
conditioned	O
on	O
the	O
image	O
vinyals2015show	O
,	O
mao2015	O
or	O
using	O
a	O
multimodal	B-Method
CNN	I-Method
ma2015multimodal	O
.	O
	
In	O
contrast	O
to	O
these	O
lines	O
of	O
work	O
,	O
we	O
propose	O
to	O
treat	O
the	O
caption	O
-	O
image	O
pairs	O
as	O
a	O
two	O
-	O
level	O
partial	O
order	O
with	O
captions	O
above	O
the	O
images	O
they	O
describe	O
,	O
and	O
let	O
with	O
our	O
order	O
-	O
violation	O
penalty	O
defined	O
in	O
Eq	O
(	O
[	O
reference	O
]	O
)	O
,	O
and	O
are	O
embedding	O
functions	O
from	O
captions	O
and	O
images	O
into	O
.	O
	
subsection	O
:	O
Loss	B-Method
Function	I-Method
	
To	O
facilitate	O
comparison	O
,	O
we	O
use	O
the	O
same	O
pairwise	B-Metric
ranking	I-Metric
loss	I-Metric
that	O
socher2014grounded	O
,	O
kiros2014	O
and	O
karpathydeep	O
have	O
used	O
on	O
this	O
task	O
—	O
simply	O
replacing	O
their	O
symmetric	B-Metric
similarity	I-Metric
measure	I-Metric
with	O
our	O
asymmetric	O
order	O
-	O
violation	O
penalty	O
.	O
	
This	O
loss	B-Method
function	I-Method
encourages	O
for	O
ground	O
truth	O
caption	O
-	O
image	O
pairs	O
to	O
be	O
greater	O
than	O
that	O
for	O
all	O
other	O
pairs	O
,	O
by	O
a	O
margin	O
:	O
where	O
is	O
a	O
ground	O
truth	O
caption	O
-	O
image	O
pair	O
,	O
goes	O
over	O
captions	O
that	O
no	O
describe	O
,	O
and	O
goes	O
over	O
image	O
not	O
described	O
by	O
.	O
	
subsection	O
:	O
Image	B-Task
and	I-Task
Caption	I-Task
Embeddings	I-Task
	
To	O
learn	O
and	O
,	O
we	O
use	O
the	O
approach	O
of	O
kiros2014	B-Method
except	O
,	O
since	O
we	O
are	O
embedding	O
into	O
,	O
we	O
constrain	O
the	O
embedding	O
vectors	O
to	O
have	O
nonnegative	O
entries	O
by	O
taking	O
their	O
absolute	O
value	O
.	O
	
Thus	O
,	O
to	O
embed	O
images	O
,	O
we	O
use	O
where	O
is	O
a	O
learned	O
matrix	O
,	O
being	O
the	O
dimensionality	O
of	O
the	O
embedding	O
space	O
.	O
	
is	O
the	O
same	O
image	O
feature	O
used	O
by	O
klein2015fisher	O
:	O
we	O
rescale	O
images	O
to	O
have	O
smallest	O
side	O
pixels	O
,	O
we	O
take	O
crops	O
from	O
the	O
corners	O
,	O
center	O
,	O
and	O
their	O
horizontal	O
reflections	O
,	O
run	O
the	O
10	O
crops	O
through	O
the	O
19	O
-	O
layer	O
VGG	B-Method
network	I-Method
of	O
vgg	B-Method
(	O
weights	O
pre	O
-	O
trained	O
on	O
ImageNet	B-Material
and	O
fixed	O
during	O
training	O
)	O
,	O
and	O
average	O
their	O
fc7	O
features	O
.	O
	
To	O
embed	O
the	O
captions	O
,	O
we	O
use	O
a	O
recurrent	B-Method
neural	I-Method
net	I-Method
encoder	I-Method
with	O
GRU	B-Method
activations	I-Method
gru	I-Method
,	O
so	O
,	O
the	O
absolute	O
value	O
of	O
hidden	O
state	O
after	O
processing	O
the	O
last	O
word	O
.	O
	
subsection	O
:	O
Dataset	O
	
We	O
evaluate	O
on	O
the	O
Microsoft	B-Material
COCO	I-Material
dataset	I-Material
coco	I-Material
,	O
which	O
has	O
over	O
120	O
,	O
000	O
images	O
,	O
each	O
with	O
at	O
least	O
five	O
human	O
-	O
annotated	O
captions	O
per	O
image	O
.	O
	
This	O
is	O
by	O
far	O
the	O
largest	O
dataset	O
commonly	O
used	O
for	O
caption	B-Task
-	I-Task
image	I-Task
retrieval	I-Task
.	O
	
We	O
use	O
the	O
data	O
splits	O
of	O
karpathydeep	O
for	O
training	O
(	O
113	O
,	O
287	O
images	O
)	O
,	O
validation	O
(	O
5000	O
images	O
)	O
,	O
and	O
test	O
(	O
5000	O
images	O
)	O
.	O
	
subsection	O
:	O
Details	O
of	O
Training	O
	
To	O
train	O
the	O
model	O
,	O
we	O
use	O
the	O
standard	O
pairwise	B-Metric
ranking	I-Metric
objective	I-Metric
from	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
	
We	O
sample	O
minibatches	O
of	O
128	O
random	O
image	O
-	O
caption	O
pairs	O
,	O
and	O
draw	O
all	O
contrastive	O
terms	O
from	O
the	O
minibatch	O
,	O
giving	O
us	O
127	O
contrastive	O
images	O
for	O
each	O
caption	O
and	O
captions	O
for	O
each	O
image	O
.	O
	
We	O
train	O
for	O
15	O
-	O
30	O
epochs	O
using	O
the	O
Adam	B-Method
optimizer	I-Method
with	O
learning	B-Method
rate	I-Method
,	O
and	O
early	B-Method
stopping	I-Method
on	O
the	O
validation	O
set	O
.	O
	
We	O
set	O
the	O
dimension	O
of	O
the	O
embedding	O
space	O
and	O
the	O
GRU	O
hidden	O
state	O
to	O
,	O
the	O
dimension	O
of	O
the	O
learned	O
word	O
embeddings	O
to	O
,	O
and	O
the	O
margin	O
to	O
.	O
	
All	O
these	O
hyperparameters	O
,	O
as	O
well	O
as	O
the	O
learning	B-Metric
rate	I-Metric
and	O
batchsize	O
,	O
were	O
selected	O
using	O
the	O
validation	O
set	O
.	O
	
For	O
consistency	O
with	O
kiros2014	O
and	O
to	O
mitigate	O
overfitting	O
,	O
we	O
constrain	O
the	O
caption	O
and	O
image	O
embeddings	O
to	O
have	O
unit	O
L2	O
norm	O
.	O
	
This	O
constraint	O
implies	O
that	O
no	O
two	O
points	O
can	O
be	O
exactly	O
ordered	O
with	O
zero	O
order	O
-	O
violation	O
penalty	O
,	O
but	O
since	O
we	O
use	O
a	O
ranking	O
loss	O
,	O
only	O
the	O
relative	O
size	O
of	O
the	O
penalties	O
matters	O
.	O
	
subsection	O
:	O
Results	O
	
L	O
—	O
CCCC	O
	
—	O
CCCC	O
	
Align	B-Task
Caption	I-Task
Retrieval	I-Task
Align	O
Image	B-Task
Retrieval	I-Task
	
Model	O
Align	O
R@1	O
Align	O
	
R@10	O
Align	O
Med	O
r	O
	
Align	B-Metric
Mean	I-Metric
rAlign	I-Metric
	
R@1	O
Align	O
R@10	O
Align	O
Med	O
	
r	O
	
Align	O
Mean	O
rAlign	O
Align	O
1k	O
Test	O
Images	O
	
Align	O
Align	O
Align	O
Align	O
Align	O
Align	O
Align	O
MNLM	B-Task
Align	I-Task
	
43.4	O
Align	O
	
85.8	O
Align	O
2	O
Align	O
	
*	O
Align	O
	
31.0	O
Align	O
79.9	O
Align	O
	
3	O
Align	O
	
*	O
m	O
-	O
RNN	B-Method
Align41.0	I-Method
	
Align	O
	
83.5	O
Align	O
	
2	O
Align	O
	
*	O
Align	O
29.0	O
	
Align	O
	
77.0	O
Align	O
	
3	O
Align	O
	
*	O
DVSA	B-Method
Align	O
	
38.4	O
Align	O
80.5	O
	
Align	O
1	O
Align	O
	
*	O
Align	O
	
27.4	O
Align	O
74.8	O
Align	O
	
3	O
Align	O
	
*	O
STV	B-Method
Align	I-Method
	
33.8	O
Align	O
82.1	O
	
Align	O
3	O
Align	O
	
*	O
Align	O
	
25.9	O
Align	O
74.6	O
	
Align	O
4	O
Align	O
*	O
FV	O
Align	O
39.4Align	O
80.9	O
	
Align	O
2	O
Align	O
	
10.4	O
Align	O
25.1	O
	
Align	O
76.6	O
	
Align	O
4	O
Align	O
11.1	O
	
m	B-Method
-	I-Method
CNN	I-Method
Align	I-Method
38.3	O
	
Align	O
81.0	O
Align	O
2	O
Align	O
	
*	O
Align	O
	
27.4	O
Align	O
	
79.5	O
Align	O
	
3	O
Align	O
	
*	O
m	O
-	O
CNN⁢ENS	O
	
Align	O
	
42.8	O
Align	O
	
84.1	O
Align	O
2	O
Align	O
	
*	O
Align	O
	
32.6	O
Align	O
	
82.8	O
Align	O
	
3	O
Align	O
	
*	O
Align	O
Align	O
Align	O
Align	O
Align	O
Align	O
Align	O
order	O
-	O
embeddings	O
(	O
reversed	O
)	O
	
Align	O
11.2	O
	
Align	O
	
44.0	O
Align	O
14.2	O
	
Align	O
86.6	O
	
Align	O
	
12.3	O
Align	O
53.5	O
Align	O
	
9.0	O
Align	B-Task
30.1order	I-Task
-	I-Task
embeddings	I-Task
(	O
	
1	B-Method
-	I-Method
crop	I-Method
)	O
	
Align	O
41.4	O
Align	O
	
84.2	O
Align	O
2.0	O
Align	O
8.7	O
Align	O
	
33.5	O
Align	O
82.2	O
	
Align	B-Task
2.6Align	I-Task
	
10.0	O
order	B-Method
-	I-Method
embeddings	I-Method
(	O
symm	B-Method
.	O
)	O
	
Align	O
45.4	O
	
Align	O
88.7	O
Align	O
	
2.0	O
Align	O
5.8	O
Align	O
36.3	O
	
Align	O
	
85.8	O
Align	O
	
2.0	O
Align	B-Task
9.0	I-Task
order	I-Task
-	I-Task
embeddings	I-Task
	
Align	O
	
46.7	O
Align	O
88.9	O
Align	O
2.0	O
Align	O
5.7	O
Align	O
	
37.9	O
Align	O
	
85.9	O
Align	O
	
2.0	O
Align	O
	
8.1	O
5k	O
Test	O
Images	O
Align	O
Align	O
Align	O
	
Align	O
Align	O
Align	O
Align	O
DVSA	B-Method
Align	O
	
11.8	O
Align	O
45.4	O
Align	O
	
12.2	O
Align	O
	
*	O
Align	O
8.9	O
Align	O
36.3	O
	
Align	O
19.5	O
	
Align	O
*	O
FV	O
Align	O
17.3	O
	
Align	O
	
50.2	O
Align	O
10.0	O
	
Align	O
46.4	O
Align	O
	
10.8	O
Align	O
40.1	O
	
Align	O
	
17.0	O
Align	O
49.3	O
	
Align	O
Align	O
Align	O
Align	O
Align	O
Align	O
Align	O
	
order	B-Method
-	I-Method
embeddings	I-Method
(	O
symm	B-Method
.	O
)	O
	
Align	O
21.5	O
	
Align	O
	
62.9	O
Align	O
6.0	O
Align	O
24.4	O
	
Align	O
	
16.8	O
Align	O
	
56.3	O
Align	O
8.0	O
	
Align	B-Task
40.4	I-Task
order	I-Task
-	I-Task
embeddings	I-Task
	
Align	O
23.3	O
Align	O
65.0	O
Align	O
5.0	O
Align	O
24.4	O
	
Align	O
	
18.0	O
Align	O
	
57.6	O
Align	B-Task
7.0	O
Align	O
35.9	O
Given	O
a	O
query	O
caption	O
or	O
image	O
	
,	O
we	O
sort	O
all	O
the	O
images	O
or	O
captions	O
of	O
the	O
test	O
set	O
in	O
order	O
of	O
increasing	O
penalty	O
.	O
	
We	O
use	O
standard	O
ranking	B-Metric
metrics	I-Metric
for	O
evaluation	B-Task
.	O
	
We	O
measure	O
Recall@K	B-Metric
,	O
the	O
percent	O
of	O
queries	O
for	O
which	O
the	O
GT	O
term	O
is	O
one	O
of	O
the	O
first	O
K	O
retrieved	O
;	O
and	O
median	B-Metric
and	I-Metric
mean	I-Metric
rank	I-Metric
,	O
which	O
are	O
statistics	O
over	O
the	O
position	O
of	O
the	O
GT	O
term	O
in	O
the	O
retrieval	O
order	O
.	O
	
Table	O
shows	O
a	O
comparison	O
between	O
all	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
and	O
some	O
older	O
methodsNote	O
that	O
the	O
numbers	O
for	O
MNLM	B-Method
come	O
not	O
from	O
the	O
published	O
paper	O
but	O
from	O
the	O
recently	O
released	O
code	O
at	O
http:	O
//	O
github.com	O
/	O
ryankiros	O
/	O
visual	O
-	O
semantic	O
-	O
embedding	O
.	O
	
along	O
with	O
our	O
own	O
;	O
see	O
for	O
a	O
more	O
complete	O
listing	O
.	O
	
The	O
best	O
results	O
overall	O
are	O
in	O
bold	O
,	O
and	O
the	O
best	O
results	O
using	O
1	B-Method
-	I-Method
crop	I-Method
VGG	O
image	O
features	O
are	O
underlined	O
.	O
	
Note	O
that	O
the	O
comparison	O
is	O
additionally	O
complicated	O
by	O
the	O
following	O
:	O
-	O
CNN	O
is	O
an	O
ensemble	O
of	O
four	O
different	O
models	O
,	O
whereas	O
the	O
other	O
entries	O
are	O
all	O
single	O
models	O
.	O
	
STV	B-Method
and	O
FV	B-Method
use	O
external	O
text	O
corpora	O
to	O
learn	O
their	O
language	B-Task
features	O
,	O
whereas	O
the	O
other	O
methods	O
learn	O
them	O
from	O
scratch	O
.	O
	
To	O
facilitate	O
the	O
comparison	O
and	O
to	O
evaluate	O
the	O
contributions	O
of	O
various	O
components	O
of	O
our	O
model	O
,	O
we	O
evaluate	O
four	O
variations	O
of	O
order	B-Method
-	I-Method
embeddings	I-Method
:	O
order	B-Method
-	I-Method
embeddings	I-Method
is	O
our	O
full	O
model	O
as	O
described	O
above	O
.	O
	
order	B-Method
-	I-Method
embeddings	I-Method
(	O
reversed	O
)	O
reverses	O
the	O
order	O
of	O
captions	O
and	O
image	O
embeddings	O
in	O
our	O
order	O
-	O
violation	O
penalty	O
—	O
placing	O
images	O
above	O
captions	O
in	O
the	O
partial	O
order	O
learned	O
by	O
our	O
model	O
.	O
	
This	O
seemingly	O
slight	O
variation	O
performs	O
atrociously	O
,	O
confirming	O
our	O
prior	O
that	O
captions	O
are	O
much	O
more	O
abstract	O
than	O
images	O
,	O
and	O
should	O
be	O
placed	O
higher	O
in	O
the	O
semantic	O
hierarchy	O
.	O
	
order	B-Method
-	I-Method
embeddings	I-Method
(	O
1	B-Method
-	I-Method
crop	I-Method
)	O
computes	O
the	O
image	O
feature	O
using	O
just	O
the	O
center	O
crop	O
,	O
instead	O
of	O
averaging	O
over	O
10	O
crops	O
.	O
	
order	B-Method
-	I-Method
embeddings	I-Method
(	O
symm	B-Method
.	O
)	O
replaces	O
our	O
asymmetric	O
penalty	O
with	O
the	O
symmetric	O
cosine	O
distance	O
,	O
and	O
allows	O
embedding	O
coordinates	O
to	O
be	O
negative	O
—	O
essentially	O
replicating	O
MNLM	B-Method
,	O
but	O
with	O
better	O
image	O
features	O
.	O
	
Here	O
we	O
find	O
that	O
a	O
different	O
margin	O
(	O
=	O
α0.2	O
)	O
works	O
best	O
.	O
	
Between	O
these	O
four	O
models	O
,	O
the	O
only	O
previous	O
work	O
whose	O
results	O
are	O
incommensurable	O
with	O
ours	O
is	O
DVSA	B-Method
,	O
since	O
it	O
uses	O
the	O
less	O
discriminative	B-Method
CNN	I-Method
of	O
but	O
20	O
region	O
features	O
instead	O
of	O
a	O
single	O
whole	O
-	O
image	O
feature	O
.	O
	
Aside	O
from	O
this	O
limitation	O
,	O
and	O
if	O
only	O
single	O
models	O
are	O
considered	O
,	O
order	B-Method
-	I-Method
embeddings	I-Method
significantly	O
outperform	O
the	O
state	O
-	O
of	O
-	O
art	O
approaches	O
for	O
image	B-Task
retrieval	I-Task
even	O
when	O
we	O
control	O
for	O
image	O
features	O
.	O
	
subsection	O
:	O
Exploration	O
	
Why	O
would	O
order	B-Method
-	I-Method
embeddings	I-Method
do	O
well	O
on	O
such	O
a	O
shallow	O
partial	O
order	O
?	O
	
Why	O
are	O
they	O
much	O
more	O
helpful	O
for	O
image	B-Task
retrieval	I-Task
than	O
for	O
caption	B-Task
retrieval	I-Task
?	O
	
Intuitively	O
,	O
symmetric	O
similarity	O
should	O
fail	O
when	O
an	O
image	O
has	O
captions	O
with	O
very	O
different	O
levels	O
of	O
detail	O
,	O
because	O
the	O
captions	O
are	O
so	O
dissimilar	O
that	O
it	O
is	O
impossible	O
to	O
map	O
both	O
their	O
embeddings	O
close	O
to	O
the	O
same	O
image	O
embedding	O
.	O
	
Order	B-Method
-	I-Method
embeddings	I-Method
do	O
n’t	O
have	O
this	O
problem	O
:	O
the	O
less	O
detailed	O
caption	O
can	O
be	O
embedded	O
very	O
far	O
away	O
from	O
the	O
image	O
while	O
remaining	O
above	O
it	O
in	O
the	O
partial	O
order	O
.	O
	
To	O
evaluate	O
this	O
intuition	O
,	O
we	O
use	O
caption	O
length	O
as	O
a	O
proxy	O
for	O
level	O
of	O
detail	O
and	O
select	O
,	O
among	O
pairs	O
of	O
co	O
-	O
referring	O
captions	O
in	O
our	O
validation	O
set	O
,	O
the	O
100	O
pairs	O
with	O
the	O
biggest	O
length	O
difference	O
.	O
	
For	O
image	B-Task
retrieval	I-Task
with	O
1000	O
target	O
images	O
,	O
the	O
mean	B-Metric
rank	I-Metric
over	O
captions	O
in	O
this	O
set	O
is	O
for	O
order	O
-	O
embeddings	O
and	O
for	O
cosine	B-Metric
similarity	I-Metric
,	O
a	O
much	O
bigger	O
difference	O
than	O
over	O
the	O
entire	O
dataset	O
.	O
	
Some	O
particularly	O
dramatic	O
examples	O
of	O
this	O
are	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Moreover	O
,	O
if	O
we	O
use	O
the	O
shorter	O
caption	O
as	O
a	O
query	O
,	O
and	O
retrieve	O
captions	O
in	O
order	O
of	O
increasing	O
error	B-Metric
,	O
the	O
mean	B-Metric
rank	I-Metric
of	O
the	O
longer	O
caption	O
is	O
for	O
order	B-Method
-	I-Method
embeddings	I-Method
and	O
for	O
cosine	B-Metric
similarity	I-Metric
,	O
showing	O
that	O
order	B-Method
-	I-Method
embeddings	I-Method
are	O
able	O
to	O
capture	O
the	O
relatedness	O
of	O
co	O
-	O
referring	O
captions	O
with	O
very	O
different	O
lengths	O
.	O
	
This	O
also	O
explains	O
why	O
order	B-Method
-	I-Method
embeddings	I-Method
provide	O
a	O
much	O
smaller	O
improvement	O
for	O
caption	B-Task
retrieval	I-Task
than	O
for	O
image	B-Task
retrieval	I-Task
:	O
all	O
the	O
caption	B-Metric
retrieval	I-Metric
metrics	I-Metric
are	O
based	O
on	O
the	O
position	O
of	O
the	O
first	O
ground	O
truth	O
caption	O
in	O
the	O
retrieval	O
order	O
,	O
so	O
the	O
embeddings	O
need	O
only	O
learn	O
to	O
retrieve	O
one	O
of	O
each	O
image	O
	
’s	O
five	O
captions	O
well	O
,	O
which	O
symmetric	B-Metric
similarity	I-Metric
is	O
well	O
suited	O
for	O
.	O
	
section	O
:	O
Textual	B-Task
Entailment	I-Task
/	O
Natural	B-Task
Language	I-Task
Inference	I-Task
	
Natural	O
language	B-Task
inference	O
can	O
be	O
seen	O
as	O
a	O
generalization	B-Method
of	I-Method
hypernymy	I-Method
from	O
words	O
to	O
sentences	O
.	O
	
For	O
example	O
,	O
from	O
“	O
woman	O
walking	O
her	O
dog	O
in	O
a	O
park	O
”	O
we	O
can	O
infer	O
both	O
“	O
woman	O
walking	O
her	O
dog	O
”	O
and	O
“	O
dog	O
in	O
a	O
park	O
”	O
,	O
but	O
not	O
”	O
old	O
woman	O
”	O
or	O
”	O
black	O
dog	O
”	O
.	O
	
Given	O
a	O
pair	O
of	O
sentences	O
,	O
our	O
task	O
is	O
to	O
predict	O
whether	O
we	O
can	O
infer	O
the	O
second	O
sentence	O
(	O
the	O
hypothesis	O
)	O
from	O
the	O
first	O
(	O
the	O
premise	O
)	O
.	O
	
subsection	O
:	O
Loss	B-Method
Function	I-Method
	
To	O
apply	O
order	B-Method
-	I-Method
embeddings	I-Method
to	O
this	O
task	O
,	O
we	O
again	O
view	O
it	O
as	O
partial	B-Task
order	I-Task
completion	I-Task
—	O
we	O
can	O
infer	O
a	O
hypothesis	O
from	O
a	O
premise	O
exactly	O
when	O
the	O
hypothesis	O
is	O
above	O
the	O
premise	O
in	O
the	O
visual	O
-	O
semantic	O
hierarchy	O
.	O
	
Unlike	O
our	O
other	O
tasks	O
,	O
for	O
which	O
we	O
had	O
to	O
generate	O
contrastive	O
negatives	O
,	O
datasets	O
for	O
natural	B-Task
language	I-Task
inference	I-Task
include	O
labeled	O
negative	O
examples	O
.	O
	
So	O
,	O
we	O
can	O
simply	O
use	O
a	O
max	B-Method
-	I-Method
margin	I-Method
loss	I-Method
:	O
where	O
are	O
positive	O
and	O
negative	O
pairs	O
of	O
premise	O
and	O
hypothesis	O
.	O
	
To	O
embed	O
sentences	O
,	O
we	O
use	O
the	O
same	O
GRU	B-Method
encoder	I-Method
as	O
in	O
the	O
caption	B-Task
-	I-Task
image	I-Task
retrieval	I-Task
task	I-Task
.	O
	
subsection	O
:	O
Dataset	O
	
To	O
evaluate	O
order	B-Task
-	I-Task
embeddings	I-Task
on	O
the	O
natural	O
language	B-Task
inference	O
task	O
,	O
we	O
use	O
the	O
recently	O
proposed	O
SNLI	B-Material
corpus	O
snli	B-Material
,	O
which	O
contains	O
570	O
,	O
000	O
pairs	O
of	O
sentences	O
,	O
each	O
labeled	O
with	O
“	O
entailment	O
”	O
if	O
the	O
inference	O
is	O
valid	O
,	O
“	O
contradiction	O
”	O
if	O
the	O
two	O
sentences	O
contradict	O
,	O
or	O
“	O
neutral	O
”	O
if	O
the	O
inference	O
is	O
invalid	O
but	O
there	O
is	O
no	O
contradiction	O
.	O
	
Our	O
method	O
only	O
allows	O
us	O
to	O
discriminate	O
between	O
entailment	O
and	O
non	O
-	O
entailment	O
,	O
so	O
we	O
merge	O
the	O
“	O
contradiction	O
”	O
and	O
“	O
neutral	O
”	O
classes	O
together	O
to	O
serve	O
as	O
our	O
negative	O
examples	O
.	O
	
subsection	O
:	O
Implementation	O
Details	O
	
Just	O
as	O
for	O
caption	B-Task
-	I-Task
image	I-Task
ranking	I-Task
,	O
we	O
set	O
the	O
dimensions	O
of	O
the	O
embedding	O
space	O
and	O
GRU	O
hidden	O
state	O
to	O
be	O
,	O
the	O
dimension	O
of	O
the	O
word	O
embeddings	O
to	O
be	O
,	O
and	O
constrain	O
the	O
embeddings	O
to	O
have	O
unit	O
L2	O
norm	O
.	O
	
We	O
train	O
for	O
10	O
epochs	O
with	O
batches	O
of	O
sentence	O
pairs	O
.	O
	
We	O
use	O
the	O
Adam	B-Method
optimizer	I-Method
with	O
learning	B-Method
rate	I-Method
and	O
early	B-Method
stopping	I-Method
on	O
the	O
validation	O
set	O
.	O
	
During	O
evaluation	O
,	O
we	O
find	O
the	O
optimal	O
classification	B-Metric
threshold	I-Metric
on	O
validation	O
,	O
then	O
use	O
the	O
threshold	O
to	O
classify	O
the	O
test	O
set	O
.	O
	
subsection	O
:	O
Results	O
	
The	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
method	O
for	O
3	B-Task
-	I-Task
class	I-Task
classification	I-Task
on	O
SNLI	B-Material
is	O
that	O
of	O
rocktaschel2015reasoning	O
.	O
	
Unfortunately	O
,	O
they	O
do	O
not	O
compute	O
2	B-Metric
-	I-Metric
class	I-Metric
accuracy	I-Metric
,	O
so	O
we	O
can	O
not	O
compare	O
to	O
them	O
directly	O
.	O
	
As	O
a	O
bridge	O
to	O
facilitate	O
comparison	O
,	O
we	O
use	O
a	O
challenging	O
baseline	O
which	O
can	O
be	O
evaluated	O
on	O
both	O
the	O
	
2	B-Task
-	I-Task
class	I-Task
and	O
3	B-Task
-	I-Task
class	I-Task
problems	I-Task
.	O
	
The	O
baseline	O
,	O
referred	O
to	O
as	O
skip	O
-	O
thoughts	O
,	O
involves	O
a	O
feedforward	B-Method
neural	I-Method
network	I-Method
on	O
top	O
of	O
skip	B-Method
-	I-Method
thought	I-Method
vectors	I-Method
kiros2015skip	O
,	O
a	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
semantic	B-Method
representation	I-Method
of	I-Method
sentences	I-Method
.	O
	
Given	O
pairs	O
of	O
sentence	O
vectors	O
and	O
,	O
the	O
input	O
to	O
the	O
network	O
is	O
the	O
concatenation	O
of	O
,	O
and	O
the	O
absolute	O
difference	O
.	O
	
We	O
tuned	O
the	O
number	O
of	O
layers	O
,	O
layer	O
dimensionality	O
and	O
dropout	B-Metric
rates	I-Metric
to	O
optimize	O
performance	O
on	O
the	O
development	O
set	O
,	O
using	O
the	O
Adam	B-Method
optimizer	I-Method
.	O
	
Batch	B-Method
normalization	I-Method
ioffe2015batch	O
and	O
PReLU	B-Method
units	I-Method
	
he2015delving	O
were	O
used	O
.	O
	
Our	O
best	O
network	O
used	O
2	O
hidden	O
layers	O
of	O
1000	O
units	O
each	O
,	O
with	O
dropout	O
rate	O
of	O
0.5	O
across	O
both	O
the	O
input	O
and	O
hidden	O
layers	O
.	O
	
We	O
did	O
not	O
backpropagate	O
through	O
the	O
skip	B-Method
-	I-Method
thought	I-Method
encoder	I-Method
.	O
	
We	O
also	O
evaluate	O
against	O
EOP	B-Method
classifier	I-Method
,	O
a	O
2	B-Task
-	I-Task
class	I-Task
baseline	O
introduced	O
by	O
snli	B-Material
,	O
and	O
against	O
a	O
version	O
of	O
our	O
model	O
where	O
our	O
order	O
-	O
violation	O
penalty	O
is	O
replaced	O
with	O
the	O
symmetric	O
cosine	O
distance	O
,	O
order	B-Method
-	I-Method
embeddings	I-Method
(	O
symmetric	B-Method
)	O
.	O
	
The	O
results	O
for	O
all	O
models	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
We	O
see	O
that	O
order	B-Method
-	I-Method
embeddings	I-Method
outperform	O
the	O
skip	B-Method
-	I-Method
thought	I-Method
baseline	I-Method
despite	O
not	O
using	O
external	O
text	O
corpora	O
.	O
	
While	O
our	O
method	O
is	O
almost	O
certainly	O
worse	O
than	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
method	O
of	O
rocktaschel2015reasoning	O
,	O
which	O
uses	O
a	O
word	B-Method
-	I-Method
by	I-Method
-	I-Method
word	I-Method
attention	I-Method
mechanism	I-Method
,	O
it	O
is	O
also	O
much	O
simpler	O
.	O
	
section	O
:	O
Conclusion	O
and	O
Future	O
Work	O
	
We	O
introduced	O
a	O
simple	O
method	O
to	O
encode	O
order	O
into	O
learned	O
distributed	B-Method
representations	I-Method
,	O
which	O
allows	O
us	O
to	O
explicitly	O
model	O
the	O
partial	O
order	O
structure	O
of	O
the	O
visual	O
-	O
semantic	O
hierarchy	O
.	O
	
Our	O
method	O
can	O
be	O
easily	O
integrated	O
into	O
existing	O
relational	B-Method
learning	I-Method
methods	I-Method
,	O
as	O
we	O
demonstrated	O
on	O
three	O
challenging	O
tasks	O
involving	O
computer	O
vision	B-Task
and	O
natural	B-Task
language	I-Task
processing	I-Task
.	O
	
On	O
two	O
of	O
these	O
tasks	O
,	O
hypernym	B-Task
prediction	I-Task
and	O
caption	B-Task
-	I-Task
image	I-Task
retrieval	I-Task
,	O
our	O
methods	O
outperform	O
all	O
previous	O
work	O
.	O
	
A	O
promising	O
direction	O
of	O
future	O
work	O
is	O
to	O
learn	O
better	O
classifiers	B-Method
on	O
ImageNet	B-Material
imagenet	I-Material
,	O
which	O
has	O
over	O
21k	O
image	O
classes	O
arranged	O
by	O
the	O
WordNet	B-Material
hierarchy	O
.	O
	
Previous	O
approaches	O
,	O
including	O
frome2013devise	O
and	O
norouzi2013zero	O
have	O
embedded	O
words	O
and	O
images	O
into	O
a	O
shared	O
semantic	O
space	O
with	O
symmetric	O
similarity	O
—	O
which	O
our	O
experiments	O
suggest	O
to	O
be	O
a	O
poor	O
fit	O
with	O
the	O
partial	O
order	O
structure	O
of	O
WordNet	B-Material
.	O
	
We	O
expect	O
significant	O
progress	O
on	O
ImageNet	B-Task
classification	I-Task
,	O
and	O
the	O
related	O
problems	O
of	O
one	B-Task
-	I-Task
shot	I-Task
and	O
zero	B-Task
-	I-Task
shot	I-Task
learning	I-Task
,	O
to	O
be	O
possible	O
using	O
order	B-Method
-	I-Method
embeddings	I-Method
.	O
	
Going	O
further	O
,	O
order	B-Method
-	I-Method
embeddings	I-Method
may	O
enable	O
learning	O
the	O
entire	O
semantic	O
hierarchy	O
in	O
a	O
single	O
model	O
which	O
jointly	O
reasons	O
about	O
hypernymy	O
,	O
entailment	O
,	O
and	O
the	O
relationship	O
between	O
perception	O
and	O
language	B-Task
,	O
unifying	O
what	O
have	O
been	O
until	O
now	O
almost	O
independent	O
lines	O
of	O
work	O
.	O
	
subsubsection	O
:	O
Acknowledgments	O
	
We	O
thank	O
Kaustav	O
Kundu	O
for	O
many	O
fruitful	O
discussions	O
throughout	O
the	O
development	O
of	O
this	O
paper	O
.	O
	
The	O
work	O
was	O
supported	O
in	O
part	O
by	O
an	O
NSERC	O
Graduate	O
Scholarship	O
.	O
	
bibliography	O
:	O
References	O
	
section	O
:	O
Supplementary	O
Material	O
	
mikolov2013linguistic	O
showed	O
that	O
word	B-Method
representations	I-Method
learned	O
using	O
word2vec	O
exhibit	O
semantic	O
regularities	O
,	O
such	O
as	O
.	O
	
kiros2014	O
showed	O
that	O
similar	O
regularities	O
hold	O
for	O
joint	O
image	O
-	O
language	B-Task
models	O
.	O
	
We	O
find	O
that	O
order	B-Method
-	I-Method
embeddings	I-Method
exhibit	O
a	O
novel	O
form	O
of	O
regularity	O
,	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
The	O
elementwise	O
and	O
operations	O
in	O
the	O
embedding	O
space	O
roughly	O
correspond	O
to	O
composition	O
and	O
abstraction	O
,	O
respectively	O
.	O
	
document	O
:	O
Sliding	B-Method
Line	I-Method
Point	I-Method
Regression	I-Method
for	O
Shape	B-Task
Robust	I-Task
Scene	I-Task
Text	I-Task
Detection	I-Task
	
Traditional	O
text	B-Method
detection	I-Method
methods	I-Method
mostly	O
focus	O
on	O
quadrangle	O
text	O
.	O
	
In	O
this	O
study	O
we	O
propose	O
a	O
novel	O
method	O
named	O
sliding	B-Method
line	I-Method
point	I-Method
regression	I-Method
(	O
SLPR	B-Method
)	O
in	O
order	O
to	O
detect	O
arbitrary	B-Task
-	I-Task
shape	I-Task
text	I-Task
in	O
natural	O
scene	O
.	O
	
SLPR	B-Method
regresses	O
multiple	O
points	O
on	O
the	O
edge	O
of	O
text	O
line	O
and	O
then	O
utilizes	O
these	O
points	O
to	O
sketch	O
the	O
outlines	O
of	O
the	O
text	O
.	O
	
The	O
proposed	O
SLPR	B-Method
can	O
be	O
adapted	O
to	O
many	O
object	B-Task
detection	I-Task
architectures	O
such	O
as	O
Faster	B-Method
R	I-Method
-	I-Method
CNN	I-Method
and	O
R	B-Method
-	I-Method
FCN	I-Method
.	O
	
Specifically	O
,	O
we	O
first	O
generate	O
the	O
smallest	O
rectangular	O
box	O
including	O
the	O
text	O
with	O
region	B-Method
proposal	I-Method
network	I-Method
(	O
RPN	B-Method
)	O
,	O
then	O
isometrically	O
regress	O
the	O
points	O
on	O
the	O
edge	O
of	O
text	O
by	O
using	O
the	O
vertically	O
and	O
horizontally	O
sliding	O
lines	O
.	O
	
To	O
make	O
full	O
use	O
of	O
information	O
and	O
reduce	O
redundancy	O
,	O
we	O
calculate	O
x	O
-	O
coordinate	O
or	O
y	O
-	O
coordinate	O
of	O
target	O
point	O
by	O
the	O
rectangular	O
box	O
position	O
,	O
and	O
just	O
regress	O
the	O
remaining	O
y	O
-	O
coordinate	O
or	O
x	O
-	O
coordinate	O
.	O
	
Accordingly	O
we	O
can	O
not	O
only	O
reduce	O
the	O
parameters	O
of	O
system	O
,	O
but	O
also	O
restrain	O
the	O
points	O
which	O
will	O
generate	O
more	O
regular	O
polygon	O
.	O
	
Our	O
approach	O
achieved	O
competitive	O
results	O
on	O
traditional	O
ICDAR2015	B-Material
Incidental	I-Material
Scene	I-Material
Text	I-Material
benchmark	I-Material
and	O
curve	B-Material
text	I-Material
detection	I-Material
dataset	I-Material
CTW1500	I-Material
.	O
	
section	O
:	O
Introduction	O
	
Text	B-Task
detection	I-Task
is	O
important	O
in	O
our	O
daily	O
life	O
as	O
it	O
can	O
be	O
applied	O
in	O
many	O
areas	O
,	O
such	O
as	O
digitization	B-Task
of	I-Task
text	I-Task
,	O
text	B-Task
translation	I-Task
,	O
etc	O
.	O
	
In	O
this	O
study	O
,	O
we	O
focus	O
on	O
scene	B-Task
text	I-Task
detection	I-Task
.	O
	
Some	O
of	O
the	O
previous	O
methods	O
have	O
obtained	O
good	O
results	O
on	O
many	O
horizontal	O
scene	O
texts	O
dataset	O
based	O
on	O
Faster	B-Method
R	I-Method
-	I-Method
CNN	I-Method
or	O
SSD	B-Method
.	O
	
Some	O
methods	O
also	O
tried	O
to	O
solve	O
arbitrary	B-Task
-	I-Task
oriented	I-Task
text	O
detection	O
problem	O
.	O
	
and	O
regressed	O
first	O
a	O
horizontal	O
rectangle	O
and	O
then	O
a	O
quadrilateral	O
.	O
	
aimed	O
to	O
generate	O
an	O
irregular	O
polygon	O
after	O
regressing	O
a	O
rectangle	O
.	O
	
The	O
methods	O
mentioned	O
above	O
mostly	O
treated	O
a	O
text	O
line	O
as	O
a	O
quadrilateral	O
which	O
can	O
be	O
completely	O
represented	O
by	O
four	O
points	O
.	O
	
However	O
,	O
besides	O
the	O
quadrilateral	O
shape	O
,	O
there	O
are	O
many	O
other	O
various	O
shapes	O
of	O
text	O
line	O
in	O
natural	O
scene	O
.	O
	
Therefore	O
,	O
recent	O
research	O
have	O
begun	O
to	O
explore	O
curve	B-Task
text	I-Task
line	I-Task
detection	I-Task
.	O
	
In	O
this	O
paper	O
we	O
explore	O
both	O
arbitrary	B-Task
-	I-Task
oriented	I-Task
and	O
curve	B-Task
text	I-Task
detection	I-Task
.	O
	
Our	O
method	O
named	O
sliding	B-Method
line	I-Method
point	I-Method
regression	I-Method
(	O
SLPR	B-Method
)	O
is	O
based	O
on	O
2	O
-	O
step	O
object	B-Task
detection	I-Task
methods	O
using	O
Faster	B-Method
R	I-Method
-	I-Method
CNN	I-Method
or	I-Method
R	I-Method
-	I-Method
FCN	I-Method
.	O
	
Firstly	O
we	O
propose	O
some	O
interesting	O
rectangular	O
regions	O
with	O
region	B-Method
proposal	I-Method
network	I-Method
(	O
RPN	B-Method
)	O
,	O
then	O
regress	O
the	O
points	O
on	O
the	O
edge	O
of	O
text	O
.	O
	
We	O
generate	O
some	O
rules	O
to	O
determine	O
which	O
points	O
should	O
be	O
regressed	O
so	O
that	O
there	O
will	O
be	O
relevance	O
between	O
points	O
.	O
	
Different	O
from	O
which	O
directly	O
regressed	O
both	O
x	O
-	O
coordinate	O
and	O
y	O
-	O
coordinate	O
of	O
fixed	O
annotated	O
points	O
and	O
employed	O
RNN	B-Method
to	O
learn	O
their	O
relevance	O
,	O
we	O
introduce	O
some	O
rules	O
to	O
vertically	O
and	O
horizontally	O
slide	O
lines	O
along	O
text	O
and	O
then	O
regress	O
the	O
intersection	O
points	O
of	O
sliding	O
lines	O
and	O
text	O
lines	O
as	O
illustrated	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
In	O
this	O
way	O
,	O
we	O
can	O
only	O
regress	O
x	O
-	O
coordinate	O
or	O
y	O
-	O
coordinate	O
of	O
these	O
points	O
,	O
then	O
calculate	O
other	O
coordinates	O
with	O
the	O
position	O
of	O
rectangle	O
,	O
yielding	O
reduction	O
of	O
unnecessary	O
computation	O
and	O
improvement	O
of	O
performance	O
.	O
	
The	O
contributions	O
of	O
this	O
paper	O
are	O
as	O
follows	O
:	O
1	O
.	O
	
We	O
explore	O
regressing	O
multiple	O
points	O
on	O
the	O
border	O
of	O
text	O
line	O
,	O
try	O
to	O
handle	O
arbitrary	B-Task
-	I-Task
oriented	I-Task
and	O
curve	B-Task
text	I-Task
detection	I-Task
based	O
on	O
Faster	O
R	B-Method
-	I-Method
CNN	I-Method
and	O
R	B-Method
-	I-Method
FCN	I-Method
.	O
	
2	O
.	O
	
We	O
introduce	O
a	O
sliding	B-Method
line	I-Method
method	I-Method
to	O
determine	O
the	O
ground	O
truth	O
points	O
for	O
the	O
regression	B-Task
,	O
and	O
we	O
make	O
full	O
use	O
of	O
the	O
relevance	O
of	O
these	O
points	O
to	O
generate	O
more	O
regular	O
polygon	O
.	O
	
section	O
:	O
Related	O
Work	O
	
In	O
recent	O
years	O
,	O
scene	B-Task
text	I-Task
detection	I-Task
and	I-Task
recognition	I-Task
has	O
drawn	O
more	O
and	O
more	O
attention	O
.	O
	
But	O
scene	B-Task
text	I-Task
detection	I-Task
remains	O
a	O
difficult	O
problem	O
due	O
to	O
its	O
complicated	O
orientation	O
and	O
background	O
.	O
	
All	O
the	O
methods	O
can	O
be	O
divided	O
into	O
three	O
categories	O
:	O
character	B-Method
based	I-Method
methods	I-Method
,	O
word	B-Method
based	I-Method
methods	I-Method
and	O
segmentation	B-Method
based	I-Method
methods	I-Method
.	O
	
Character	B-Method
based	I-Method
methods	I-Method
often	O
need	O
synthetic	O
datasets	O
because	O
labeling	O
characters	O
in	O
text	O
lines	O
requires	O
additional	O
efforts	O
.	O
	
However	O
,	O
the	O
generated	O
data	O
is	O
greatly	O
deviated	O
from	O
the	O
real	O
data	O
,	O
which	O
can	O
not	O
make	O
the	O
trained	O
model	O
to	O
achieve	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
real	O
dataset	O
such	O
as	O
the	O
popular	O
ICDAR2015	B-Material
Incidental	I-Material
Scene	I-Material
Text	I-Material
benchmark	I-Material
.	O
	
In	O
order	O
to	O
solve	O
this	O
problem	O
,	O
used	O
semi	B-Method
-	I-Method
supervised	I-Method
method	I-Method
to	O
finetune	B-Method
model	I-Method
on	O
real	O
data	O
and	O
obtained	O
good	O
results	O
.	O
	
The	O
segmentation	B-Method
based	I-Method
methods	I-Method
have	O
also	O
been	O
used	O
in	O
text	B-Task
detection	I-Task
recently	O
.	O
	
trained	O
a	O
fully	B-Method
convolutional	I-Method
network	I-Method
(	O
FCN	B-Method
)	O
to	O
predict	O
the	O
salient	O
map	O
of	O
text	O
regions	O
,	O
then	O
traced	O
the	O
text	O
line	O
by	O
combining	O
the	O
salient	O
map	O
and	O
character	B-Method
components	I-Method
.	O
	
added	O
the	O
border	O
class	O
to	O
separate	O
text	O
from	O
their	O
neighbor	O
.	O
	
and	O
generated	O
text	O
maps	O
and	O
regress	O
the	O
size	O
and	O
angle	O
of	O
the	O
corresponding	O
quadrilateral	O
,	O
or	O
coordinates	O
of	O
four	O
vertexes	O
at	O
the	O
same	O
time	O
.	O
	
Compared	O
with	O
the	O
traditional	O
segmentation	B-Method
methods	I-Method
,	O
they	O
made	O
a	O
huge	O
breakthrough	O
on	O
ICDAR2015	B-Material
Incidental	I-Material
Scene	I-Material
Text	I-Material
benchmark	I-Material
.	O
	
Many	O
methods	O
of	O
object	B-Task
detection	I-Task
can	O
be	O
applied	O
to	O
text	B-Task
detection	I-Task
,	O
e.g.	O
,	O
Faster	O
R	B-Method
-	I-Method
CNN	I-Method
,	O
SSD	B-Method
,	O
R	B-Method
-	I-Method
FCN	I-Method
and	O
YOLO	B-Method
.	O
used	O
irregular	B-Method
convolutional	I-Method
filters	I-Method
instead	O
of	O
the	O
standard	O
convolutional	B-Method
filters	I-Method
to	O
make	O
the	O
network	O
more	O
suitable	O
for	O
long	B-Task
text	I-Task
detection	I-Task
.	O
	
used	O
the	O
attention	B-Method
map	I-Method
to	O
remove	O
background	O
noise	O
.	O
	
Recently	O
more	O
and	O
more	O
researchers	O
proposed	O
2	B-Method
-	I-Method
step	I-Method
methods	I-Method
based	O
on	O
Faster	O
R	B-Method
-	I-Method
CNN	I-Method
or	I-Method
R	I-Method
-	I-Method
FCN	I-Method
.	O
	
firstly	O
generated	O
axis	O
-	O
aligned	O
bounding	O
boxes	O
and	O
then	O
regressed	O
the	O
text	O
quadrangle	O
.	O
	
They	O
used	O
multi	B-Method
-	I-Method
scale	I-Method
pool	I-Method
operations	I-Method
on	O
the	O
roipool	B-Method
layer	I-Method
.	O
tried	O
to	O
segment	O
and	O
detect	O
text	O
simultaneously	O
.	O
	
Considering	O
the	O
particularity	O
of	O
text	O
line	O
,	O
appended	O
different	O
angle	O
anchors	O
which	O
are	O
suitable	O
for	O
arbitrary	B-Task
-	I-Task
oriented	I-Task
text	O
line	O
.	O
	
More	O
recently	O
,	O
considered	O
the	O
polygon	O
case	O
and	O
labeled	O
a	O
new	O
dataset	O
of	O
curve	O
text	O
.	O
	
also	O
constructed	O
a	O
curve	O
text	O
dataset	O
named	O
CTW1500	B-Material
,	O
and	O
they	O
proposed	O
a	O
new	O
structure	O
named	O
curve	B-Method
text	I-Method
detector	I-Method
(	O
CTD	B-Method
)	O
to	O
solve	O
curve	B-Task
text	I-Task
detection	I-Task
problem	O
.	O
	
section	O
:	O
Method	O
	
Our	O
model	O
can	O
be	O
applied	O
to	O
any	O
2	O
-	O
step	O
object	B-Task
detection	I-Task
framework	O
such	O
as	O
Faster	B-Method
R	I-Method
-	I-Method
CNN	I-Method
and	O
R	B-Method
-	I-Method
FCN	I-Method
.	O
	
Our	O
system	O
simultaneously	O
regresses	O
the	O
minimum	O
rectangle	O
including	O
text	O
line	O
and	O
the	O
coordinates	O
of	O
some	O
specific	O
points	O
on	O
the	O
boundary	O
of	O
text	O
line	O
.	O
	
More	O
specifically	O
,	O
take	O
Faster	O
R	B-Method
-	I-Method
CNN	I-Method
as	O
an	O
example	O
,	O
we	O
first	O
get	O
some	O
interesting	O
regions	O
using	O
the	O
RPN	B-Method
,	O
then	O
we	O
not	O
only	O
regress	O
the	O
position	O
of	O
the	O
rectangle	O
,	O
but	O
also	O
regress	O
the	O
coordinates	O
of	O
the	O
points	O
on	O
the	O
edge	O
of	O
the	O
text	O
line	O
,	O
finally	O
we	O
can	O
get	O
arbitrary	O
shape	O
text	O
area	O
.	O
	
subsection	O
:	O
Which	O
points	O
should	O
be	O
regressed	O
?	O
	
Obviously	O
,	O
how	O
to	O
determine	O
the	O
point	O
set	O
for	O
restoring	O
the	O
polygon	O
is	O
quite	O
important	O
.	O
	
We	O
believe	O
the	O
simpler	O
the	O
rules	O
,	O
the	O
easier	O
the	O
neural	B-Method
net	I-Method
learns	O
.	O
	
We	O
do	O
not	O
regress	O
the	O
fixed	O
points	O
such	O
as	O
vertexes	O
on	O
the	O
polygon	O
because	O
there	O
are	O
a	O
large	O
variety	O
of	O
shapes	O
and	O
angles	O
in	O
natural	O
scene	O
and	O
it	O
is	O
difficult	O
to	O
define	O
the	O
order	O
of	O
fixed	O
feature	O
points	O
for	O
all	O
shapes	O
.	O
	
Although	O
for	O
quadrilateral	O
,	O
we	O
can	O
perfectly	O
restore	O
it	O
by	O
regressing	O
the	O
corresponding	O
four	O
vertices	O
,	O
the	O
determination	O
of	O
the	O
order	O
of	O
four	O
vertices	O
requires	O
a	O
complicated	O
rule	O
which	O
is	O
difficult	O
for	O
the	O
neural	B-Method
net	I-Method
to	O
learn	O
.	O
	
Alternatively	O
,	O
as	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
,	O
we	O
introduce	O
some	O
rules	O
to	O
vertically	O
and	O
horizontally	O
slide	O
the	O
lines	O
(	O
we	O
use	O
equidistant	O
sliding	O
in	O
our	O
experiment	O
)	O
on	O
text	O
line	O
and	O
then	O
regress	O
the	O
intersection	O
of	O
sliding	O
lines	O
and	O
text	O
line	O
border	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
the	O
correlation	O
exists	O
among	O
the	O
coordinates	O
of	O
different	O
intersection	O
points	O
due	O
to	O
the	O
constraints	O
of	O
the	O
sliding	O
lines	O
.	O
	
It	O
is	O
not	O
necessary	O
to	O
regress	O
both	O
x	O
-	O
coordinate	O
and	O
y	O
-	O
coordinate	O
of	O
all	O
points	O
simultaneously	O
.	O
	
If	O
it	O
is	O
horizontal	O
sliding	O
,	O
the	O
x	O
-	O
coordinate	O
of	O
the	O
point	O
on	O
the	O
text	O
boundary	O
can	O
be	O
calculated	O
by	O
the	O
coordinates	O
of	O
the	O
rectangle	O
,	O
so	O
we	O
only	O
need	O
to	O
regress	O
the	O
y	O
-	O
coordinate	O
of	O
these	O
points	O
.	O
	
Similarly	O
,	O
if	O
it	O
is	O
vertical	O
sliding	O
,	O
we	O
only	O
need	O
to	O
regress	O
the	O
x	O
-	O
coordinate	O
of	O
these	O
points	O
.	O
	
This	O
method	O
not	O
only	O
reduces	O
the	O
computational	B-Metric
complexity	I-Metric
of	O
the	O
network	O
,	O
but	O
also	O
adds	O
restraints	O
to	O
the	O
regressed	O
points	O
as	O
the	O
prior	O
knowledge	O
which	O
can	O
prevent	O
generating	O
polygons	O
with	O
weird	O
shapes	O
and	O
further	O
improve	O
the	O
accuracy	B-Metric
.	O
	
As	O
for	O
the	O
number	O
of	O
sliding	O
lines	O
,	O
we	O
observe	O
that	O
this	O
parameter	O
is	O
not	O
sensitive	O
to	O
quadrangle	O
text	O
line	O
.	O
	
But	O
in	O
order	O
to	O
restore	O
other	O
shape	O
text	O
line	O
well	O
,	O
after	O
balancing	O
the	O
performance	O
and	O
network	B-Metric
complexity	I-Metric
,	O
seven	O
sliding	O
lines	O
are	O
used	O
for	O
we	O
decided	O
to	O
for	O
vertical	O
and	O
horizontal	O
directions	O
,	O
respectively	O
.	O
	
Accordingly	O
a	O
total	O
of	O
14	O
lines	O
with	O
28	O
intersection	O
points	O
are	O
generated	O
.	O
	
subsection	O
:	O
The	O
multi	B-Task
-	I-Task
task	I-Task
learning	I-Task
	
To	O
optimize	O
the	O
neural	O
network	O
parameters	O
,	O
as	O
illustrated	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
,	O
we	O
adopt	O
the	O
multi	B-Task
-	I-Task
task	I-Task
learning	I-Task
to	O
define	O
the	O
loss	O
function	O
as	O
:	O
where	O
is	O
the	O
region	O
proposal	O
loss	O
,	O
is	O
region	B-Method
proposal	I-Method
classification	I-Method
loss	I-Method
,	O
is	O
box	B-Method
regression	I-Method
loss	I-Method
.	O
	
is	O
the	O
loss	O
for	O
the	O
second	O
step	O
after	O
RPN	B-Method
.	O
	
Similarly	O
,	O
the	O
first	O
two	O
items	O
and	O
are	O
respectively	O
classification	B-Metric
loss	I-Metric
and	O
box	B-Method
regression	I-Method
loss	I-Method
.	O
,	O
and	O
are	O
the	O
related	O
weighting	O
factors	O
,	O
which	O
are	O
all	O
set	O
to	O
1	O
in	O
this	O
study	O
.	O
	
is	O
the	O
proposed	O
new	O
loss	O
item	O
for	O
SLPR	B-Method
:	O
is	O
the	O
smooth	B-Method
L1	I-Method
loss	I-Method
for	O
the	O
box	B-Task
regression	I-Task
task	I-Task
:	O
	
In	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
,	O
represents	O
the	O
number	O
of	O
sliding	O
lines	O
in	O
one	O
direction	O
and	O
we	O
set	O
in	O
our	O
experiments	O
.	O
	
In	O
general	O
,	O
each	O
line	O
has	O
two	O
intersection	O
points	O
with	O
the	O
text	O
line	O
border	O
.	O
	
If	O
there	O
are	O
more	O
than	O
two	O
intersection	O
points	O
,	O
we	O
take	O
the	O
smallest	O
and	O
the	O
largest	O
coordinates	O
.	O
	
is	O
x	O
-	O
coordinate	O
of	O
the	O
intersection	O
point	O
of	O
vertically	O
sliding	O
lines	O
and	O
text	O
line	O
border	O
while	O
is	O
y	O
-	O
coordinate	O
of	O
the	O
intersection	O
point	O
of	O
horizontally	O
sliding	O
lines	O
and	O
text	O
line	O
border	O
.	O
	
and	O
are	O
the	O
corresponding	O
estimated	O
points	O
from	O
neural	O
net	O
outputs	O
.	O
	
For	O
horizontally	O
sliding	O
lines	O
,	O
we	O
only	O
regress	O
the	O
y	O
-	O
coordinate	O
of	O
its	O
intersection	O
point	O
.	O
	
For	O
vertically	O
sliding	O
lines	O
,	O
we	O
only	O
regress	O
the	O
x	O
-	O
coordinate	O
of	O
its	O
intersection	O
point	O
.	O
	
The	O
other	O
coordinates	O
can	O
be	O
restored	O
through	O
the	O
coordinates	O
of	O
the	O
rectangle	O
:	O
and	O
represent	O
the	O
minimum	O
x	O
-	O
coordinate	O
and	O
y	O
-	O
coordinate	O
of	O
the	O
rectangular	O
border	O
while	O
and	O
represent	O
the	O
maximum	O
x	O
-	O
coordinate	O
and	O
y	O
-	O
coordinate	O
of	O
the	O
rectangular	O
border	O
.	O
	
is	O
the	O
floor	O
function	O
.	O
	
In	O
a	O
word	O
,	O
in	O
order	O
to	O
regress	O
the	O
coordinates	O
of	O
polygon	O
,	O
32	O
parameters	O
should	O
be	O
considered	O
including	O
4	O
parameters	O
for	O
the	O
rectangle	O
and	O
28	O
parameters	O
to	O
represent	O
x	O
and	O
y	O
coordinates	O
of	O
intersection	O
points	O
on	O
text	O
line	O
border	O
.	O
	
subsection	O
:	O
Restoration	B-Task
of	I-Task
polygon	I-Task
	
Through	O
the	O
above	O
SLPR	B-Method
method	O
,	O
we	O
can	O
obtain	O
multiple	O
points	O
from	O
the	O
output	O
of	O
neural	B-Method
nets	I-Method
.	O
	
To	O
restore	O
the	O
final	O
quadrilateral	O
or	O
polygon	O
,	O
the	O
following	O
two	O
approaches	O
are	O
adopted	O
and	O
compared	O
:	O
	
subsubsection	B-Method
:	O
Only	O
Using	O
Points	O
in	O
Long	O
Side	O
(	O
PLS	O
)	O
	
The	O
text	O
line	O
always	O
extends	O
to	O
the	O
long	O
side	O
,	O
and	O
the	O
lines	O
that	O
slide	O
along	O
the	O
long	O
side	O
can	O
better	O
reflect	O
the	O
shape	O
of	O
the	O
text	O
.	O
	
In	O
fact	O
we	O
can	O
restore	O
the	O
polygon	O
by	O
only	O
scanning	O
the	O
long	O
side	O
,	O
as	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Specifically	O
,	O
we	O
firstly	O
judge	O
whether	O
the	O
text	O
line	O
is	O
horizontal	O
or	O
vertical	O
through	O
the	O
regressed	O
rectangle	O
,	O
and	O
then	O
restore	O
the	O
polygon	O
through	O
points	O
in	O
the	O
corresponding	O
direction	O
.	O
	
Taking	O
the	O
vertical	O
direction	O
as	O
an	O
example	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
	
since	O
we	O
do	O
not	O
regress	O
the	O
intersection	O
point	O
on	O
the	O
rectangular	O
border	O
,	O
we	O
firstly	O
extend	O
the	O
four	O
lines	O
near	O
the	O
border	O
to	O
find	O
four	O
intersection	O
points	O
with	O
the	O
rectangle	O
,	O
then	O
we	O
connect	O
four	O
new	O
points	O
and	O
other	O
intersection	O
points	O
to	O
generate	O
polygon	O
.	O
	
subsubsection	B-Method
:	O
Using	O
Both	O
of	O
Horizontal	O
and	O
Vertical	O
Points	O
(	O
BHVP	B-Method
)	O
	
In	O
fact	O
,	O
if	O
we	O
use	O
both	O
horizontal	O
and	O
vertical	O
points	O
to	O
restore	O
polygon	O
,	O
we	O
can	O
calculate	O
a	O
polygon	O
or	O
quadrangle	O
that	O
passes	O
through	O
these	O
points	O
roughly	O
as	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
by	O
using	O
the	O
method	O
in	O
.	O
	
In	O
this	O
way	O
we	O
can	O
obtain	O
dense	O
enough	O
points	O
in	O
both	O
horizontal	O
and	O
vertical	O
direction	O
and	O
we	O
do	O
not	O
need	O
to	O
calculate	O
the	O
intersection	O
with	O
the	O
rectangle	O
as	O
in	O
PLS	B-Method
method	I-Method
.	O
	
However	O
,	O
we	O
observe	O
BHVP	B-Method
is	O
not	O
as	O
effective	O
as	O
PLS	B-Method
for	O
the	O
polygon	B-Task
case	I-Task
.	O
	
So	O
we	O
use	O
this	O
method	O
only	O
on	O
the	O
quadrilateral	O
dataset	O
(	O
ICDAR2015	B-Material
Incidental	O
Scene	O
Text	O
)	O
.	O
	
subsection	O
:	O
Polygonal	B-Method
non	I-Method
-	I-Method
maximum	I-Method
suppression	I-Method
	
Non	B-Method
-	I-Method
maximum	I-Method
suppression	I-Method
(	O
NMS	B-Method
)	O
is	O
a	O
basic	O
method	O
commonly	O
used	O
in	O
the	O
object	B-Task
detection	I-Task
,	O
and	O
its	O
purpose	O
is	O
to	O
remove	O
duplicate	O
boxes	O
.	O
	
The	O
traditional	O
NMS	B-Method
method	O
is	O
based	O
on	O
rectangular	O
boxes	O
,	O
which	O
is	O
not	O
the	O
best	O
choice	O
for	O
other	O
shapes	O
.	O
	
In	O
recent	O
years	O
,	O
other	O
NMS	B-Method
approaches	O
were	O
investigated	O
,	O
e.g.	O
,	O
locality	O
-	O
aware	O
NMS	B-Method
,	O
inclined	O
NMS	B-Method
,	O
Mask	O
-	O
NMS	B-Method
and	O
polygonal	O
NMS	B-Method
(	O
PNMS	B-Method
)	O
.	O
	
As	O
we	O
consider	O
the	O
polygon	O
in	O
this	O
study	O
,	O
both	O
NMS	B-Method
and	O
PNMS	B-Method
are	O
compared	O
in	O
our	O
experiment	O
.	O
	
section	O
:	O
Experiments	O
	
subsection	O
:	O
Datasets	O
	
subsubsection	O
:	O
ICDAR2015	B-Material
Incidental	O
Scene	O
Text	O
.	O
	
ICDAR2015	B-Material
	
Incidental	B-Material
Scene	I-Material
Text	I-Material
dataset	I-Material
is	O
commonly	O
used	O
benchmark	O
for	O
detecting	B-Task
arbitrary	I-Task
-	I-Task
angle	I-Task
quadrangular	I-Task
text	I-Task
lines	I-Task
.	O
	
It	O
contains	O
1000	O
images	O
for	O
training	O
,	O
500	O
images	O
for	O
testing	O
.	O
	
Some	O
words	O
which	O
are	O
too	O
short	O
,	O
or	O
unclear	O
is	O
annotated	O
as	O
do	O
n’t	O
cared	O
samples	O
.	O
	
subsubsection	O
:	O
CTW1500	B-Material
	
Curve	B-Material
text	I-Material
dataset	I-Material
(	O
CTW1500	B-Material
)	O
is	O
constructed	O
by	O
Yuliang	O
et	O
al	O
.	O
.	O
	
Different	O
from	O
traditional	O
text	B-Material
datasets	I-Material
,	O
a	O
text	B-Material
line	I-Material
is	O
labelled	O
by	O
a	O
polygon	O
with	O
14	O
points	O
.	O
	
subsection	O
:	O
Implementation	O
Details	O
	
Since	O
our	O
proposed	O
SLPR	B-Method
can	O
be	O
applied	O
to	O
any	O
2	O
-	O
step	O
object	B-Task
detection	I-Task
framework	O
.	O
	
We	O
adopted	O
Faster	O
R	B-Method
-	I-Method
CNN	I-Method
in	O
ICDAR2015	B-Material
Incidental	O
Scene	O
Text	O
.	O
	
And	O
because	O
also	O
proposed	O
a	O
2	B-Method
-	I-Method
step	I-Method
framework	I-Method
based	O
on	O
R	B-Method
-	I-Method
FCN	I-Method
while	O
presenting	O
the	O
CTW1500	B-Material
dataset	O
,	O
to	O
perform	O
a	O
fair	O
comparison	O
,	O
we	O
directly	O
used	O
the	O
network	O
in	O
from	O
.	O
	
All	O
experiments	O
were	O
implemented	O
in	O
Caffe	B-Method
by	O
using	O
the	O
NVIDIA	B-Method
GTX	I-Method
1080Ti	I-Method
GPU	I-Method
.	O
	
subsubsection	O
:	O
ICDAR2015	B-Material
Incidental	O
Scene	O
Text	O
.	O
	
For	O
Faster	O
R	B-Task
-	I-Task
CNN	I-Task
structure	I-Task
,	O
we	O
used	O
an	O
additional	O
anchor	O
and	O
replaced	O
RoIPool	O
with	O
RoIAlign	O
because	O
the	O
text	O
line	O
is	O
smaller	O
than	O
other	O
objects	O
.	O
	
We	O
set	O
anchor	O
scales	O
as	O
[	O
]	O
and	O
set	O
ratios	O
as	O
[	O
0.5	O
,	O
1	O
,	O
2	O
]	O
.	O
	
The	O
base	O
network	O
is	O
VGG16	B-Method
,	O
which	O
is	O
initialized	O
by	O
the	O
pre	B-Method
-	I-Method
trained	I-Method
model	I-Method
on	O
ImageNet	B-Material
database	I-Material
.	O
	
We	O
used	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
(	O
SGD	B-Method
)	O
with	O
back	B-Method
-	I-Method
propagation	I-Method
and	O
the	O
maximum	O
iteration	O
was	O
.	O
	
Learning	B-Metric
rates	I-Metric
started	O
from	O
,	O
decays	O
to	O
one	O
-	O
tenth	O
every	O
iterations	O
.	O
	
We	O
set	O
weight	O
decay	O
as	O
,	O
and	O
momentum	O
as	O
.	O
	
We	O
used	O
1000	O
training	O
incidental	O
images	O
in	O
ICDAR2015	B-Material
Incidental	O
Scene	O
Text	O
and	O
the	O
229	O
training	O
images	O
from	O
ICDAR	B-Material
2013	I-Material
to	O
train	O
our	O
network	O
.	O
	
In	O
order	O
to	O
prevent	O
over	B-Task
-	I-Task
fitting	I-Task
we	O
employed	O
data	B-Method
augmentation	I-Method
.	O
	
Specifically	O
,	O
we	O
randomly	O
resized	O
the	O
images	O
to	O
where	O
the	O
numbers	O
represent	O
the	O
length	O
of	O
the	O
short	O
side	O
,	O
and	O
randomly	O
rotated	O
the	O
images	O
among	O
.	O
	
subsubsection	O
:	O
CTW1500	B-Material
	
We	O
used	O
the	O
curve	B-Method
text	I-Method
detector	I-Method
(	O
CTD	B-Method
)	O
network	O
which	O
is	O
based	O
R	B-Method
-	I-Method
FCN	I-Method
from	O
.	O
	
also	O
added	O
LSTM	B-Method
units	I-Method
named	O
transverse	O
and	O
longitudinal	O
offset	O
connection	O
(	O
TLOC	B-Method
)	O
to	O
learn	O
the	O
correlation	O
of	O
points	O
.	O
	
But	O
we	O
removed	O
it	O
.	O
	
As	O
we	O
only	O
used	O
PLS	O
to	O
restore	O
polygon	O
,	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
was	O
modified	O
as	O
:	O
equals	O
to	O
when	O
is	O
true	O
,	O
otherwise	O
.	O
	
and	O
are	O
the	O
height	O
and	O
width	O
of	O
the	O
rectangle	O
.	O
	
Because	O
most	O
of	O
the	O
texts	O
in	O
this	O
dataset	O
are	O
horizontal	O
text	O
line	O
,	O
to	O
solve	O
the	O
imbalance	O
between	O
horizontal	O
and	O
vertical	O
samples	O
,	O
we	O
added	O
to	O
balance	O
the	O
losses	O
between	O
them	O
.	O
	
And	O
when	O
is	O
close	O
to	O
,	O
the	O
text	O
line	O
may	O
be	O
judged	O
as	O
horizontal	O
or	O
vertical	O
,	O
so	O
we	O
set	O
as	O
.	O
	
The	O
base	O
network	O
is	O
ResNet	B-Method
-	I-Method
50	I-Method
,	O
which	O
is	O
initialized	O
by	O
the	O
pre	B-Method
-	I-Method
trained	I-Method
model	I-Method
on	O
ImageNet	B-Material
database	I-Material
.	O
	
The	O
max	O
iteration	O
was	O
.	O
	
The	O
learning	B-Metric
rate	I-Metric
in	O
this	O
experiment	O
was	O
always	O
.	O
	
We	O
set	O
weight	O
decay	O
as	O
,	O
and	O
momentum	O
as	O
.	O
	
To	O
conduct	O
a	O
fair	O
comparison	O
,	O
we	O
only	O
used	O
the	O
training	O
set	O
in	O
CTW1500	B-Material
to	O
train	O
our	O
network	O
and	O
did	O
not	O
use	O
data	B-Method
augmentation	I-Method
.	O
	
subsection	O
:	O
Results	O
	
subsubsection	O
:	O
ICDAR2015	B-Material
Incidental	O
Scene	O
Text	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
results	O
of	O
SLPR	B-Method
system	O
with	O
different	O
settings	O
.	O
	
First	O
,	O
for	O
the	O
restoration	B-Task
of	I-Task
the	I-Task
quadrangle	I-Task
for	O
the	O
text	O
region	O
,	O
BHVP	B-Method
using	O
all	O
the	O
points	O
can	O
achieve	O
better	O
results	O
than	O
PLS	B-Method
using	O
only	O
the	O
long	O
-	O
side	O
points	O
.	O
	
Second	O
,	O
even	O
we	O
aim	O
to	O
detect	O
the	O
quadrangle	O
in	O
this	O
dataset	O
,	O
PNMS	B-Method
still	O
outperforms	O
NMS	B-Method
.	O
	
Finally	O
,	O
the	O
use	O
of	O
multi	B-Method
-	I-Method
scale	I-Method
is	O
one	O
way	O
to	O
improve	O
detection	B-Task
performance	O
on	O
different	O
target	O
sizes	O
.	O
	
We	O
also	O
test	O
the	O
multi	O
-	O
scale	O
results	O
of	O
our	O
system	O
at	O
(	O
850	O
,	O
1000	O
)	O
,	O
which	O
yields	O
about	O
1	O
%	O
absolute	O
improvement	O
of	O
Hmean	B-Metric
measure	I-Metric
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
lists	O
several	O
challenging	O
examples	O
of	O
detection	B-Task
results	O
on	O
ICDAR2015	B-Material
Incidental	I-Material
Scene	I-Material
Text	I-Material
dataset	I-Material
.	O
	
Table	O
[	O
reference	O
]	O
gives	O
the	O
comparison	O
of	O
SLPR	B-Method
with	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
ICDAR2015	B-Material
Incidental	O
Scene	O
Text	O
.	O
	
We	O
can	O
observe	O
that	O
our	O
method	O
achieved	O
the	O
competitive	O
results	O
on	O
this	O
dataset	O
.	O
	
subsubsection	O
:	O
CTW1500	B-Material
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
results	O
of	O
our	O
method	O
with	O
different	O
NMS	B-Method
settings	O
.	O
	
Different	O
from	O
the	O
observation	O
in	O
ICDAR2015	B-Material
Incidental	O
Scene	O
Text	O
,	O
our	O
method	O
achieved	O
the	O
best	O
result	O
on	O
NMS0.3	B-Method
,	O
namely	O
the	O
traditional	O
NMS	B-Method
method	O
with	O
the	O
threshold	O
0.3	O
for	O
calculating	O
the	O
IoU	B-Metric
(	O
Intersection	B-Metric
-	I-Metric
over	I-Metric
-	I-Metric
Union	I-Metric
)	O
.	O
	
Table	O
[	O
reference	O
]	O
lists	O
the	O
results	O
of	O
our	O
method	O
compared	O
with	O
CTD	B-Method
and	O
CTD	B-Method
+	O
TLOC	O
.	O
	
We	O
removed	O
TLOC	O
from	O
as	O
our	O
base	O
network	O
which	O
is	O
the	O
same	O
as	O
CTD	B-Method
.	O
	
Clearly	O
,	O
the	O
Hmean	B-Metric
performance	O
of	O
our	O
SLPR	B-Method
method	O
could	O
be	O
increased	O
by	O
over	O
the	O
CTD	B-Method
method	O
,	O
demonstrating	O
the	O
effectiveness	O
of	O
our	O
simple	O
rules	O
to	O
set	O
the	O
regression	O
points	O
.	O
	
Even	O
compared	O
with	O
the	O
CTD	B-Method
+	O
TLOC	O
method	O
with	O
an	O
additional	O
LSTM	B-Method
network	I-Method
,	O
SLPR	B-Method
still	O
achieved	O
improvement	O
of	O
Hmean	B-Metric
performance	I-Metric
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
gives	O
several	O
examples	O
of	O
the	O
detection	B-Task
results	O
of	O
CTD	B-Method
,	O
CTD	B-Method
+	O
TLOC	O
and	O
our	O
SLPR	B-Method
.	O
	
We	O
can	O
observe	O
that	O
our	O
method	O
generated	O
smoother	O
regions	O
and	O
better	O
detection	B-Task
results	O
compared	O
with	O
CTD	B-Method
,	O
which	O
implied	O
that	O
the	O
proposed	O
SLPR	B-Method
can	O
better	O
handle	O
the	O
arbitrary	B-Task
-	I-Task
oriented	I-Task
case	O
due	O
to	O
the	O
novel	O
design	O
of	O
the	O
horizontally	O
and	O
vertically	O
symmetrical	O
scanning	O
using	O
sliding	O
lines	O
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
study	O
,	O
we	O
propose	O
a	O
novel	O
SLPR	B-Method
method	O
for	O
the	O
text	B-Task
detection	I-Task
in	O
arbitrary	B-Task
-	I-Task
shape	I-Task
case	I-Task
.	O
	
Compared	O
with	O
the	O
curve	B-Task
text	I-Task
detection	I-Task
method	O
CTD	B-Method
+	O
TLOC	O
,	O
SLPR	B-Method
is	O
more	O
concise	O
without	O
using	O
LSTM	B-Method
and	O
obtains	O
better	O
performance	O
.	O
	
In	O
the	O
traditional	O
quadrangle	O
dataset	O
(	O
ICDAR2015	B-Material
Incidental	O
Scene	O
Text	O
)	O
,	O
SLPR	B-Method
also	O
achieves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
.	O
	
section	O
:	O
Acknowledgment	O
	
This	O
work	O
was	O
supported	O
in	O
part	O
by	O
the	O
National	O
Key	O
R	O
&	O
D	O
Program	O
of	O
China	O
under	O
contract	O
	
No	O
.	O
2017YFB1002202	O
	
,	O
in	O
part	O
by	O
the	O
National	O
Natural	O
Science	O
Foundation	O
of	O
China	O
under	O
Grants	O
61671422	O
and	O
U1613211	O
,	O
in	O
part	O
by	O
the	O
MOE	O
-	O
Microsoft	O
Key	O
Laboratory	O
of	O
USTC	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Unsupervised	B-Task
Representation	I-Task
Learning	I-Task
with	O
Deep	B-Method
Convolutional	I-Method
Generative	I-Method
Adversarial	I-Method
Networks	I-Method
	
In	O
recent	O
years	O
,	O
supervised	B-Method
learning	I-Method
with	O
convolutional	B-Method
networks	I-Method
(	O
CNNs	B-Method
)	O
has	O
seen	O
huge	O
adoption	O
in	O
computer	B-Task
vision	I-Task
applications	I-Task
.	O
	
Comparatively	O
,	O
unsupervised	B-Method
learning	I-Method
with	O
CNNs	B-Method
has	O
received	O
less	O
attention	O
.	O
	
In	O
this	O
work	O
we	O
hope	O
to	O
help	O
bridge	O
the	O
gap	O
between	O
the	O
success	O
of	O
CNNs	B-Method
for	O
supervised	B-Task
learning	I-Task
and	O
unsupervised	B-Task
learning	I-Task
.	O
	
We	O
introduce	O
a	O
class	O
of	O
CNNs	B-Method
called	O
deep	B-Method
convolutional	I-Method
generative	I-Method
adversarial	I-Method
networks	I-Method
(	O
DCGANs	B-Method
)	O
,	O
that	O
have	O
certain	O
architectural	O
constraints	O
,	O
and	O
demonstrate	O
that	O
they	O
are	O
a	O
strong	O
candidate	O
for	O
unsupervised	B-Task
learning	I-Task
.	O
	
Training	O
on	O
various	O
image	O
datasets	O
,	O
we	O
show	O
convincing	O
evidence	O
that	O
our	O
deep	B-Method
convolutional	I-Method
adversarial	I-Method
pair	I-Method
learns	O
a	O
hierarchy	O
of	O
representations	O
from	O
object	O
parts	O
to	O
scenes	O
in	O
both	O
the	O
generator	B-Method
and	I-Method
discriminator	I-Method
.	O
	
Additionally	O
,	O
we	O
use	O
the	O
learned	O
features	O
for	O
novel	O
tasks	O
-	O
demonstrating	O
their	O
applicability	O
as	O
general	B-Method
image	I-Method
representations	I-Method
.	O
	
.	O
/	O
	
section	O
:	O
Introduction	O
	
Learning	O
reusable	B-Method
feature	I-Method
representations	I-Method
from	O
large	O
unlabeled	O
datasets	O
has	O
been	O
an	O
area	O
of	O
active	O
research	O
.	O
	
In	O
the	O
context	O
of	O
computer	B-Task
vision	I-Task
,	O
one	O
can	O
leverage	O
the	O
practically	O
unlimited	O
amount	O
of	O
unlabeled	O
images	O
and	O
videos	O
to	O
learn	O
good	O
intermediate	B-Method
representations	I-Method
,	O
which	O
can	O
then	O
be	O
used	O
on	O
a	O
variety	O
of	O
supervised	B-Task
learning	I-Task
tasks	I-Task
such	O
as	O
image	B-Task
classification	I-Task
.	O
	
We	O
propose	O
that	O
one	O
way	O
to	O
build	O
good	O
image	B-Task
representations	I-Task
is	O
by	O
training	O
Generative	B-Method
Adversarial	I-Method
Networks	I-Method
(	O
GANs	B-Method
)	O
Goodfellow2014	O
,	O
and	O
later	O
reusing	O
parts	O
of	O
the	O
generator	B-Method
and	I-Method
discriminator	I-Method
networks	I-Method
as	O
feature	B-Method
extractors	I-Method
for	O
supervised	B-Task
tasks	I-Task
.	O
	
GANs	B-Method
provide	O
an	O
attractive	O
alternative	O
to	O
maximum	B-Method
likelihood	I-Method
techniques	I-Method
.	O
	
One	O
can	O
additionally	O
argue	O
that	O
their	O
learning	B-Method
process	I-Method
and	O
the	O
lack	O
of	O
a	O
heuristic	B-Metric
cost	I-Metric
function	I-Metric
(	O
such	O
as	O
pixel	B-Method
-	I-Method
wise	I-Method
independent	I-Method
mean	I-Method
-	I-Method
square	I-Method
error	I-Method
)	O
are	O
attractive	O
to	O
representation	B-Task
learning	I-Task
.	O
	
GANs	B-Method
have	O
been	O
known	O
to	O
be	O
unstable	O
to	O
train	O
,	O
often	O
resulting	O
in	O
generators	O
that	O
produce	O
nonsensical	O
outputs	O
.	O
	
There	O
has	O
been	O
very	O
limited	O
published	O
research	O
in	O
trying	O
to	O
understand	O
and	O
visualize	O
what	O
GANs	B-Method
learn	I-Method
,	O
and	O
the	O
intermediate	B-Method
representations	I-Method
of	I-Method
multi	I-Method
-	I-Method
layer	I-Method
GANs	I-Method
.	O
	
In	O
this	O
paper	O
,	O
we	O
make	O
the	O
following	O
contributions	O
We	O
propose	O
and	O
evaluate	O
a	O
set	O
of	O
constraints	O
on	O
the	O
architectural	O
topology	O
of	O
Convolutional	B-Method
GANs	I-Method
that	O
make	O
them	O
stable	O
to	O
train	O
in	O
most	O
settings	O
.	O
	
We	O
name	O
this	O
class	O
of	O
architectures	O
Deep	B-Method
Convolutional	I-Method
GANs	I-Method
(	O
DCGAN	B-Method
)	O
	
We	O
use	O
the	O
trained	O
discriminators	O
for	O
image	B-Task
classification	I-Task
tasks	I-Task
,	O
showing	O
competitive	O
performance	O
with	O
other	O
unsupervised	B-Method
algorithms	I-Method
.	O
	
We	O
visualize	O
the	O
filters	B-Method
learnt	O
by	O
GANs	B-Method
and	O
empirically	O
show	O
that	O
specific	O
filters	O
have	O
learned	O
to	O
draw	O
specific	O
objects	O
.	O
	
We	O
show	O
that	O
the	O
generators	O
have	O
interesting	O
vector	O
arithmetic	O
properties	O
allowing	O
for	O
easy	O
manipulation	O
of	O
many	O
semantic	O
qualities	O
of	O
generated	O
samples	O
.	O
	
section	O
:	O
Related	O
Work	O
	
subsection	O
:	O
Representation	B-Task
Learning	I-Task
from	O
unlabeled	O
data	O
	
Unsupervised	B-Method
representation	I-Method
learning	I-Method
is	O
a	O
fairly	O
well	O
studied	O
problem	O
in	O
general	B-Task
computer	I-Task
vision	I-Task
research	I-Task
,	O
as	O
well	O
as	O
in	O
the	O
context	O
of	O
images	O
.	O
	
A	O
classic	O
approach	O
to	O
unsupervised	B-Task
representation	I-Task
learning	I-Task
is	O
to	O
do	O
clustering	B-Task
on	O
the	O
data	O
(	O
for	O
example	O
using	O
K	B-Method
-	I-Method
means	I-Method
)	O
,	O
and	O
leverage	O
the	O
clusters	O
for	O
improved	O
classification	B-Metric
scores	I-Metric
.	O
	
In	O
the	O
context	O
of	O
images	O
,	O
one	O
can	O
do	O
hierarchical	B-Method
clustering	I-Method
of	I-Method
image	I-Method
patches	I-Method
coates2012learning	O
to	O
learn	O
powerful	O
image	B-Method
representations	I-Method
.	O
	
Another	O
popular	O
method	O
is	O
to	O
train	O
auto	B-Method
-	I-Method
encoders	I-Method
(	O
convolutionally	B-Method
,	O
stacked	B-Method
vincent2010stacked	O
,	O
separating	O
the	O
what	O
and	O
where	O
components	O
of	O
the	O
code	O
zhao2015stacked	O
,	O
ladder	B-Method
structures	I-Method
rasmus2015semi	O
)	O
that	O
encode	O
an	O
image	O
into	O
a	O
compact	B-Method
code	I-Method
,	O
and	O
decode	O
the	O
code	O
to	O
reconstruct	O
the	O
image	O
as	O
accurately	O
as	O
possible	O
.	O
	
These	O
methods	O
have	O
also	O
been	O
shown	O
to	O
learn	O
good	O
feature	B-Method
representations	I-Method
from	O
image	O
pixels	O
.	O
	
Deep	B-Method
belief	I-Method
networks	I-Method
lee2009convolutional	O
have	O
also	O
been	O
shown	O
to	O
work	O
well	O
in	O
learning	B-Task
hierarchical	I-Task
representations	I-Task
.	O
	
subsection	O
:	O
Generating	B-Task
natural	I-Task
images	I-Task
	
Generative	B-Method
image	I-Method
models	I-Method
are	O
well	O
studied	O
and	O
fall	O
into	O
two	O
categories	O
:	O
parametric	B-Method
and	I-Method
non	I-Method
-	I-Method
parametric	I-Method
.	O
	
The	O
non	B-Method
-	I-Method
parametric	I-Method
models	I-Method
often	O
do	O
matching	B-Task
from	O
a	O
database	O
of	O
existing	O
images	O
,	O
often	O
matching	O
patches	O
of	O
images	O
,	O
and	O
have	O
been	O
used	O
in	O
texture	B-Task
synthesis	I-Task
efros1999texture	O
,	O
super	B-Task
-	I-Task
resolution	I-Task
freeman2002example	O
and	O
in	B-Task
-	I-Task
painting	I-Task
hays2007scene	O
.	O
	
Parametric	B-Method
models	I-Method
for	O
generating	B-Task
images	I-Task
has	O
been	O
explored	O
extensively	O
(	O
for	O
example	O
on	O
MNIST	B-Material
digits	O
or	O
for	O
texture	B-Task
synthesis	I-Task
portilla2000parametric	O
)	O
.	O
	
However	O
,	O
generating	O
natural	O
images	O
of	O
the	O
real	O
world	O
have	O
had	O
not	O
much	O
success	O
until	O
recently	O
.	O
	
A	O
variational	B-Method
sampling	I-Method
approach	I-Method
to	O
generating	B-Task
images	I-Task
kingma2013auto	O
has	O
had	O
some	O
success	O
,	O
but	O
the	O
samples	O
often	O
suffer	O
from	O
being	O
blurry	O
.	O
	
Another	O
approach	O
generates	O
images	O
using	O
an	O
iterative	B-Method
forward	I-Method
diffusion	I-Method
process	I-Method
sohl2015deep	O
.	O
	
Generative	B-Method
Adversarial	I-Method
Networks	I-Method
Goodfellow2014	O
generated	O
images	O
suffering	O
from	O
being	O
noisy	O
and	O
incomprehensible	O
.	O
	
A	O
laplacian	B-Method
pyramid	I-Method
extension	I-Method
to	O
this	O
approach	O
denton2015deep	O
showed	O
higher	O
quality	O
images	O
,	O
but	O
they	O
still	O
suffered	O
from	O
the	O
objects	O
looking	O
wobbly	O
because	O
of	O
noise	O
introduced	O
in	O
chaining	O
multiple	O
models	O
.	O
	
A	O
recurrent	B-Method
network	I-Method
approach	I-Method
gregor2015draw	O
and	O
a	O
deconvolution	B-Method
network	I-Method
approach	I-Method
dosovitskiy2014learning	O
have	O
also	O
recently	O
had	O
some	O
success	O
with	O
generating	O
natural	O
images	O
.	O
	
However	O
,	O
they	O
have	O
not	O
leveraged	O
the	O
generators	B-Method
for	O
supervised	B-Task
tasks	I-Task
.	O
	
subsection	O
:	O
Visualizing	O
the	O
internals	O
of	O
CNNs	B-Method
	
One	O
constant	O
criticism	O
of	O
using	O
neural	B-Method
networks	I-Method
has	O
been	O
that	O
they	O
are	O
black	B-Method
-	I-Method
box	I-Method
methods	I-Method
,	O
with	O
little	O
understanding	O
of	O
what	O
the	O
networks	O
do	O
in	O
the	O
form	O
of	O
a	O
simple	O
human	B-Method
-	I-Method
consumable	I-Method
algorithm	I-Method
.	O
	
In	O
the	O
context	O
of	O
CNNs	B-Method
,	O
Zeiler	O
et	O
.	O
	
al	O
.	O
	
zeiler2014visualizing	O
showed	O
that	O
by	O
using	O
deconvolutions	B-Method
and	O
filtering	O
the	O
maximal	O
activations	O
,	O
one	O
can	O
find	O
the	O
approximate	O
purpose	O
of	O
each	O
convolution	B-Method
filter	I-Method
in	O
the	O
network	O
.	O
	
Similarly	O
,	O
using	O
a	O
gradient	B-Method
descent	I-Method
on	O
the	O
inputs	O
lets	O
us	O
inspect	O
the	O
ideal	O
image	O
that	O
activates	O
certain	O
subsets	O
of	O
filters	O
Inceptionism2015	O
.	O
	
section	O
:	O
Approach	O
and	O
Model	O
Architecture	O
	
Historical	O
attempts	O
to	O
scale	O
up	O
GANs	B-Method
using	O
CNNs	B-Method
to	O
model	O
images	O
have	O
been	O
unsuccessful	O
.	O
	
This	O
motivated	O
the	O
authors	O
of	O
LAPGAN	B-Method
denton2015deep	O
to	O
develop	O
an	O
alternative	O
approach	O
to	O
iteratively	B-Task
upscale	I-Task
low	I-Task
resolution	I-Task
generated	I-Task
images	I-Task
which	O
can	O
be	O
modeled	O
more	O
reliably	O
.	O
	
We	O
also	O
encountered	O
difficulties	O
attempting	O
to	O
scale	O
GANs	B-Method
using	O
CNN	B-Method
architectures	I-Method
commonly	O
used	O
in	O
the	O
supervised	O
literature	O
.	O
	
However	O
,	O
after	O
extensive	O
model	B-Task
exploration	I-Task
we	O
identified	O
a	O
family	O
of	O
architectures	O
that	O
resulted	O
in	O
stable	O
training	O
across	O
a	O
range	O
of	O
datasets	O
and	O
allowed	O
for	O
training	O
higher	O
resolution	O
and	O
deeper	B-Method
generative	I-Method
models	I-Method
.	O
	
Core	O
to	O
our	O
approach	O
is	O
adopting	O
and	O
modifying	O
three	O
recently	O
demonstrated	O
changes	O
to	O
CNN	B-Method
architectures	I-Method
.	O
	
The	O
first	O
is	O
the	O
all	B-Method
convolutional	I-Method
net	I-Method
springenberg2014striving	O
which	O
replaces	O
deterministic	B-Method
spatial	I-Method
pooling	I-Method
functions	I-Method
(	O
such	O
as	O
maxpooling	B-Method
)	O
with	O
strided	B-Method
convolutions	I-Method
,	O
allowing	O
the	O
network	O
to	O
learn	O
its	O
own	O
spatial	O
downsampling	O
.	O
	
We	O
use	O
this	O
approach	O
in	O
our	O
generator	O
,	O
allowing	O
it	O
to	O
learn	O
its	O
own	O
spatial	B-Method
upsampling	I-Method
,	O
and	O
discriminator	B-Method
.	O
	
Second	O
is	O
the	O
trend	O
towards	O
eliminating	O
fully	O
connected	O
layers	O
on	O
top	O
of	O
convolutional	O
features	O
.	O
	
The	O
strongest	O
example	O
of	O
this	O
is	O
global	B-Method
average	I-Method
pooling	I-Method
which	O
has	O
been	O
utilized	O
in	O
state	O
of	O
the	O
art	O
image	B-Method
classification	I-Method
models	I-Method
Inceptionism2015	O
.	O
	
We	O
found	O
global	B-Method
average	I-Method
pooling	I-Method
increased	O
model	B-Metric
stability	I-Metric
but	O
hurt	O
convergence	B-Metric
speed	I-Metric
.	O
	
A	O
middle	O
ground	O
of	O
directly	O
connecting	O
the	O
highest	O
convolutional	O
features	O
to	O
the	O
input	O
and	O
output	O
respectively	O
of	O
the	O
generator	B-Method
and	O
discriminator	B-Method
worked	O
well	O
.	O
	
The	O
first	O
layer	O
of	O
the	O
GAN	B-Method
,	O
which	O
takes	O
a	O
uniform	O
noise	O
distribution	O
as	O
input	O
,	O
could	O
be	O
called	O
fully	O
connected	O
as	O
it	O
is	O
just	O
a	O
matrix	B-Method
multiplication	I-Method
,	O
but	O
the	O
result	O
is	O
reshaped	O
into	O
a	O
4	O
-	O
dimensional	O
tensor	O
and	O
used	O
as	O
the	O
start	O
of	O
the	O
convolution	B-Method
stack	I-Method
.	O
	
For	O
the	O
discriminator	B-Method
,	O
the	O
last	O
convolution	B-Method
layer	I-Method
is	O
flattened	O
and	O
then	O
fed	O
into	O
a	O
single	O
sigmoid	O
output	O
.	O
	
See	O
Fig	O
.	O
	
[	O
reference	O
]	O
for	O
a	O
visualization	O
of	O
an	O
example	O
model	B-Method
architecture	I-Method
.	O
	
Third	O
is	O
Batch	B-Method
Normalization	I-Method
ioffe2015batch	O
which	O
stabilizes	O
learning	B-Task
by	O
normalizing	O
the	O
input	O
to	O
each	O
unit	O
to	O
have	O
zero	O
mean	O
and	O
unit	O
variance	O
.	O
	
This	O
helps	O
deal	O
with	O
training	B-Task
problems	I-Task
that	O
arise	O
due	O
to	O
poor	O
initialization	O
and	O
helps	O
gradient	B-Method
flow	I-Method
in	O
deeper	B-Method
models	I-Method
.	O
	
This	O
proved	O
critical	O
to	O
get	O
deep	B-Method
generators	I-Method
to	O
begin	O
learning	B-Task
,	O
preventing	O
the	O
generator	O
from	O
collapsing	O
all	O
samples	O
to	O
a	O
single	O
point	O
which	O
is	O
a	O
common	O
failure	O
mode	O
observed	O
in	O
GANs	B-Method
.	O
	
Directly	O
applying	O
batchnorm	B-Method
to	O
all	O
layers	O
however	O
,	O
resulted	O
in	O
sample	O
oscillation	O
and	O
model	O
instability	O
.	O
	
This	O
was	O
avoided	O
by	O
not	O
applying	O
batchnorm	B-Method
to	O
the	O
generator	B-Method
output	I-Method
layer	I-Method
and	O
the	O
discriminator	B-Method
input	I-Method
layer	I-Method
.	O
	
The	O
ReLU	B-Method
activation	I-Method
nair2010rectified	O
is	O
used	O
in	O
the	O
generator	B-Method
with	O
the	O
exception	O
of	O
the	O
output	O
layer	O
which	O
uses	O
the	O
Tanh	O
function	O
.	O
	
We	O
observed	O
that	O
using	O
a	O
bounded	O
activation	O
allowed	O
the	O
model	O
to	O
learn	O
more	O
quickly	O
to	O
saturate	O
and	O
cover	O
the	O
color	O
space	O
of	O
the	O
training	O
distribution	O
.	O
	
Within	O
the	O
discriminator	O
we	O
found	O
the	O
leaky	B-Method
rectified	I-Method
activation	I-Method
	
maas2013rectifier	O
xu2015empirical	O
to	O
work	O
well	O
,	O
especially	O
for	O
higher	B-Task
resolution	I-Task
modeling	I-Task
.	O
	
This	O
is	O
in	O
contrast	O
to	O
the	O
original	O
GAN	B-Method
paper	O
,	O
which	O
used	O
the	O
maxout	O
activation	O
goodfellow2013maxout	O
.	O
	
Architecture	O
guidelines	O
for	O
stable	O
Deep	B-Method
Convolutional	I-Method
GANs	I-Method
Replace	O
any	O
pooling	B-Method
layers	I-Method
with	O
strided	B-Method
convolutions	I-Method
(	O
discriminator	B-Method
)	O
and	O
fractional	B-Method
-	I-Method
strided	I-Method
convolutions	I-Method
(	O
generator	B-Method
)	O
.	O
	
Use	O
batchnorm	B-Method
in	O
both	O
the	O
generator	B-Method
and	O
the	O
discriminator	B-Method
.	O
	
Remove	O
fully	O
connected	O
hidden	O
layers	O
for	O
deeper	B-Method
architectures	I-Method
.	O
	
Use	O
ReLU	B-Method
activation	I-Method
in	O
generator	B-Method
for	O
all	O
layers	O
except	O
for	O
the	O
output	O
,	O
which	O
uses	O
Tanh	B-Method
.	O
	
Use	O
LeakyReLU	O
activation	O
in	O
the	O
discriminator	B-Method
for	O
all	O
layers	O
.	O
	
section	O
:	O
Details	O
of	O
adversarial	B-Method
training	I-Method
	
We	O
trained	O
DCGANs	B-Method
on	O
three	O
datasets	O
,	O
Large	B-Task
-	I-Task
scale	I-Task
Scene	I-Task
Understanding	I-Task
	
(	O
LSUN	B-Method
)	O
yu2015construction	O
,	O
Imagenet	B-Material
-	I-Material
1k	I-Material
and	O
a	O
newly	O
assembled	B-Material
Faces	I-Material
dataset	I-Material
.	O
	
Details	O
on	O
the	O
usage	O
of	O
each	O
of	O
these	O
datasets	O
are	O
given	O
below	O
.	O
	
No	O
pre	O
-	O
processing	O
was	O
applied	O
to	O
training	O
images	O
besides	O
scaling	O
to	O
the	O
range	O
of	O
the	O
tanh	O
activation	O
function	O
[	O
-	O
1	O
,	O
1	O
]	O
.	O
All	O
models	O
were	O
trained	O
with	O
mini	B-Method
-	I-Method
batch	I-Method
stochastic	I-Method
gradient	I-Method
descent	I-Method
(	O
SGD	B-Method
)	O
with	O
a	O
mini	O
-	O
batch	O
size	O
of	O
128	O
.	O
	
All	O
weights	O
were	O
initialized	O
from	O
a	O
zero	B-Method
-	I-Method
centered	I-Method
Normal	I-Method
distribution	I-Method
with	O
standard	O
deviation	O
0.02	O
.	O
	
In	O
the	O
LeakyReLU	O
,	O
the	O
slope	O
of	O
the	O
leak	O
was	O
set	O
to	O
0.2	O
in	O
all	O
models	O
.	O
	
While	O
previous	O
GAN	B-Method
work	O
has	O
used	O
momentum	O
to	O
accelerate	O
training	B-Task
,	O
we	O
used	O
the	O
Adam	B-Method
optimizer	I-Method
kingma2014adam	O
with	O
tuned	B-Method
hyperparameters	I-Method
.	O
	
We	O
found	O
the	O
suggested	O
learning	B-Metric
rate	I-Metric
of	O
0.001	O
,	O
to	O
be	O
too	O
high	O
,	O
using	O
0.0002	O
instead	O
.	O
	
Additionally	O
,	O
we	O
found	O
leaving	O
the	O
momentum	O
term	O
at	O
the	O
suggested	O
value	O
of	O
0.9	O
resulted	O
in	O
training	O
oscillation	O
and	O
instability	O
while	O
reducing	O
it	O
to	O
0.5	O
helped	O
stabilize	O
training	B-Task
.	O
	
subsection	O
:	O
LSUN	B-Method
	
As	O
visual	B-Metric
quality	I-Metric
of	O
samples	O
from	O
generative	B-Method
image	I-Method
models	I-Method
has	O
improved	O
,	O
concerns	O
of	O
over	B-Method
-	I-Method
fitting	I-Method
and	O
memorization	B-Task
of	I-Task
training	I-Task
samples	I-Task
have	O
risen	O
.	O
	
To	O
demonstrate	O
how	O
our	O
model	O
scales	O
with	O
more	O
data	O
and	O
higher	O
resolution	B-Task
generation	I-Task
,	O
we	O
train	O
a	O
model	O
on	O
the	O
LSUN	B-Material
bedrooms	I-Material
dataset	I-Material
containing	O
a	O
little	O
over	O
3	O
million	O
training	O
examples	O
.	O
	
Recent	O
analysis	O
has	O
shown	O
that	O
there	O
is	O
a	O
direct	O
link	O
between	O
how	O
fast	O
models	O
learn	O
and	O
their	O
generalization	B-Metric
performance	I-Metric
hardt2015train	O
.	O
	
We	O
show	O
samples	O
from	O
one	O
epoch	O
of	O
training	O
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
,	O
mimicking	O
online	B-Method
learning	I-Method
,	O
in	O
addition	O
to	O
samples	O
after	O
convergence	O
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
,	O
as	O
an	O
opportunity	O
to	O
demonstrate	O
that	O
our	O
model	O
is	O
not	O
producing	O
high	O
quality	O
samples	O
via	O
simply	O
overfitting	O
/	O
memorizing	O
training	O
examples	O
.	O
	
No	O
data	B-Method
augmentation	I-Method
was	O
applied	O
to	O
the	O
images	O
.	O
	
subsubsection	O
:	O
Deduplication	O
	
To	O
further	O
decrease	O
the	O
likelihood	O
of	O
the	O
generator	O
memorizing	O
input	O
examples	O
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
	
we	O
perform	O
a	O
simple	O
image	B-Method
de	I-Method
-	I-Method
duplication	I-Method
process	I-Method
.	O
	
We	O
fit	O
a	O
3072	B-Method
-	I-Method
128	I-Method
-	I-Method
3072	I-Method
de	I-Method
-	I-Method
noising	I-Method
dropout	I-Method
regularized	I-Method
RELU	I-Method
autoencoder	I-Method
on	O
32x32	O
downsampled	O
center	O
-	O
crops	O
of	O
training	O
examples	O
.	O
	
The	O
resulting	O
code	O
layer	O
activations	O
are	O
then	O
binarized	O
via	O
thresholding	B-Method
the	O
ReLU	B-Method
activation	I-Method
which	O
has	O
been	O
shown	O
to	O
be	O
an	O
effective	O
information	B-Method
preserving	I-Method
technique	I-Method
srivastava2014understanding	O
and	O
provides	O
a	O
convenient	O
form	O
of	O
semantic	B-Method
-	I-Method
hashing	I-Method
,	O
allowing	O
for	O
linear	B-Task
time	I-Task
de	I-Task
-	I-Task
duplication	I-Task
.	O
	
Visual	B-Task
inspection	I-Task
of	I-Task
hash	I-Task
collisions	I-Task
showed	O
high	O
precision	B-Metric
with	O
an	O
estimated	O
false	B-Metric
positive	I-Metric
rate	I-Metric
of	O
less	O
than	O
1	O
in	O
100	O
.	O
	
Additionally	O
,	O
the	O
technique	O
detected	O
and	O
removed	O
approximately	O
275	O
,	O
000	O
near	O
duplicates	O
,	O
suggesting	O
a	O
high	O
recall	B-Metric
.	O
	
subsection	O
:	O
Faces	O
	
We	O
scraped	O
images	O
containing	O
human	O
faces	O
from	O
random	O
web	O
image	O
queries	O
of	O
peoples	O
names	O
.	O
	
The	O
people	O
names	O
were	O
acquired	O
from	O
dbpedia	B-Material
,	O
with	O
a	O
criterion	O
that	O
they	O
were	O
born	O
in	O
the	O
modern	O
era	O
.	O
	
This	O
dataset	O
has	O
3	O
M	O
images	O
from	O
10	O
K	O
people	O
.	O
	
We	O
run	O
an	O
OpenCV	B-Method
face	I-Method
detector	I-Method
on	O
these	O
images	O
,	O
keeping	O
the	O
detections	O
that	O
are	O
sufficiently	O
high	O
resolution	O
,	O
which	O
gives	O
us	O
approximately	O
350	O
,	O
000	O
face	O
boxes	O
.	O
	
We	O
use	O
these	O
face	O
boxes	O
for	O
training	O
.	O
	
No	O
data	B-Method
augmentation	I-Method
was	O
applied	O
to	O
the	O
images	O
.	O
	
subsection	O
:	O
Imagenet	B-Material
-	I-Material
1k	I-Material
	
We	O
use	O
Imagenet	B-Material
-	I-Material
1k	I-Material
deng2009imagenet	O
as	O
a	O
source	O
of	O
natural	O
images	O
for	O
unsupervised	B-Task
training	I-Task
.	O
	
We	O
train	O
on	O
min	B-Method
-	I-Method
resized	I-Method
center	I-Method
crops	I-Method
.	O
	
No	O
data	B-Method
augmentation	I-Method
was	O
applied	O
to	O
the	O
images	O
.	O
	
section	O
:	O
Empirical	O
Validation	O
of	O
DCGANs	B-Method
capabilities	O
	
subsection	O
:	O
Classifying	O
CIFAR	B-Material
-	I-Material
10	I-Material
using	O
GANs	B-Method
as	O
a	O
feature	B-Method
extractor	I-Method
	
One	O
common	O
technique	O
for	O
evaluating	O
the	O
quality	O
of	O
unsupervised	B-Method
representation	I-Method
learning	I-Method
algorithms	I-Method
is	O
to	O
apply	O
them	O
as	O
a	O
feature	B-Method
extractor	I-Method
on	O
supervised	O
datasets	O
and	O
evaluate	O
the	O
performance	O
of	O
linear	B-Method
models	I-Method
fitted	O
on	O
top	O
of	O
these	O
features	O
.	O
	
On	O
the	O
CIFAR	B-Material
-	I-Material
10	I-Material
dataset	O
,	O
a	O
very	O
strong	O
baseline	O
performance	O
has	O
been	O
demonstrated	O
from	O
a	O
well	O
tuned	O
single	B-Method
layer	I-Method
feature	I-Method
extraction	I-Method
pipeline	I-Method
utilizing	O
K	B-Method
-	I-Method
means	I-Method
as	O
a	O
feature	B-Method
learning	I-Method
algorithm	I-Method
.	O
	
When	O
using	O
a	O
very	O
large	O
amount	O
of	O
feature	O
maps	O
(	O
4800	O
)	O
	
this	O
technique	O
achieves	O
80.6	O
%	O
accuracy	B-Metric
.	O
	
An	O
unsupervised	B-Method
multi	I-Method
-	I-Method
layered	I-Method
extension	I-Method
of	O
the	O
base	O
algorithm	O
reaches	O
82.0	O
%	O
accuracy	B-Metric
coates2011selecting	O
.	O
	
To	O
evaluate	O
the	O
quality	O
of	O
the	O
representations	O
learned	O
by	O
DCGANs	B-Method
for	O
supervised	B-Task
tasks	I-Task
,	O
we	O
train	O
on	O
Imagenet	B-Material
-	I-Material
1k	I-Material
and	O
then	O
use	O
the	O
discriminator	O
’s	O
convolutional	O
features	O
from	O
all	O
layers	O
,	O
maxpooling	O
each	O
layers	B-Method
representation	I-Method
to	O
produce	O
a	O
spatial	O
grid	O
.	O
	
These	O
features	O
are	O
then	O
flattened	O
and	O
concatenated	O
to	O
form	O
a	O
28672	O
dimensional	O
vector	O
and	O
a	O
regularized	B-Method
linear	I-Method
L2	I-Method
-	I-Method
SVM	I-Method
classifier	I-Method
is	O
trained	O
on	O
top	O
of	O
them	O
.	O
	
This	O
achieves	O
82.8	O
%	O
accuracy	B-Metric
,	O
out	O
performing	O
all	O
K	B-Method
-	I-Method
means	I-Method
based	I-Method
approaches	I-Method
.	O
	
Notably	O
,	O
the	O
discriminator	B-Method
has	O
many	O
less	O
feature	O
maps	O
(	O
512	O
in	O
the	O
highest	O
layer	O
)	O
compared	O
to	O
K	B-Method
-	I-Method
means	I-Method
based	I-Method
techniques	I-Method
,	O
but	O
does	O
result	O
in	O
a	O
larger	O
total	O
feature	B-Metric
vector	I-Metric
size	I-Metric
due	O
to	O
the	O
many	O
layers	O
of	O
spatial	O
locations	O
.	O
	
The	O
performance	O
of	O
DCGANs	B-Method
is	O
still	O
less	O
than	O
that	O
of	O
Exemplar	B-Method
CNNs	I-Method
dosovitskiy2014discriminative	O
,	O
a	O
technique	O
which	O
trains	O
normal	B-Method
discriminative	I-Method
CNNs	I-Method
in	O
an	O
unsupervised	B-Method
fashion	I-Method
to	O
differentiate	O
between	O
specifically	O
chosen	O
,	O
aggressively	O
augmented	O
,	O
exemplar	O
samples	O
from	O
the	O
source	O
dataset	O
.	O
	
Further	O
improvements	O
could	O
be	O
made	O
by	O
finetuning	O
the	O
discriminator	B-Method
’s	I-Method
representations	I-Method
,	O
but	O
we	O
leave	O
this	O
for	O
future	O
work	O
.	O
	
Additionally	O
,	O
since	O
our	O
DCGAN	B-Method
was	O
never	O
trained	O
on	O
CIFAR	B-Material
-	I-Material
10	I-Material
this	O
experiment	O
also	O
demonstrates	O
the	O
domain	B-Metric
robustness	I-Metric
of	O
the	O
learned	O
features	O
.	O
	
subsection	O
:	O
Classifying	B-Task
SVHN	I-Task
digits	I-Task
using	O
GANs	B-Method
as	O
a	O
feature	B-Method
extractor	I-Method
	
On	O
the	O
StreetView	B-Material
House	I-Material
Numbers	I-Material
dataset	I-Material
(	O
SVHN	B-Material
)	O
	
netzer2011reading	O
,	O
we	O
use	O
the	O
features	O
of	O
the	O
discriminator	B-Method
of	O
a	O
DCGAN	B-Method
for	O
supervised	B-Task
purposes	I-Task
when	O
labeled	O
data	O
is	O
scarce	O
.	O
	
Following	O
similar	O
dataset	O
preparation	O
rules	O
as	O
in	O
the	O
CIFAR	B-Material
-	I-Material
10	I-Material
experiments	O
,	O
we	O
split	O
off	O
a	O
validation	O
set	O
of	O
10	O
,	O
000	O
examples	O
from	O
the	O
non	O
-	O
extra	O
set	O
and	O
use	O
it	O
for	O
all	O
hyperparameter	B-Method
and	I-Method
model	I-Method
selection	I-Method
.	O
	
1000	O
uniformly	O
class	O
distributed	O
training	O
examples	O
are	O
randomly	O
selected	O
and	O
used	O
to	O
train	O
a	O
regularized	B-Method
linear	I-Method
L2	I-Method
-	I-Method
SVM	I-Method
classifier	I-Method
on	O
top	O
of	O
the	O
same	O
feature	B-Method
extraction	I-Method
pipeline	I-Method
used	O
for	O
CIFAR	B-Material
-	I-Material
10	I-Material
.	O
	
This	O
achieves	O
state	O
of	O
the	O
art	O
(	O
for	O
classification	B-Task
using	O
1000	O
labels	O
)	O
at	O
22.48	O
%	O
test	B-Metric
error	I-Metric
,	O
improving	O
upon	O
another	O
modifcation	O
of	O
CNNs	B-Method
designed	O
to	O
leverage	O
unlabled	O
data	O
zhao2015stacked	O
.	O
	
Additionally	O
,	O
we	O
validate	O
that	O
the	O
CNN	B-Method
architecture	I-Method
used	O
in	O
DCGAN	B-Method
is	O
not	O
the	O
key	O
contributing	O
factor	O
of	O
the	O
model	O
	
’s	O
performance	O
by	O
training	O
a	O
purely	O
supervised	B-Method
CNN	I-Method
with	O
the	O
same	O
architecture	O
on	O
the	O
same	O
data	O
and	O
optimizing	O
this	O
model	O
via	O
random	B-Method
search	I-Method
over	O
64	O
hyperparameter	O
trials	O
bergstra2012hpopt	O
.	O
	
It	O
achieves	O
a	O
signficantly	O
higher	O
28.87	O
%	O
validation	B-Metric
error	I-Metric
.	O
	
section	O
:	O
Investigating	O
and	O
visualizing	O
the	O
internals	O
of	O
the	O
networks	O
	
We	O
investigate	O
the	O
trained	O
generators	B-Method
and	O
discriminators	B-Method
in	O
a	O
variety	O
of	O
ways	O
.	O
	
We	O
do	O
not	O
do	O
any	O
kind	O
of	O
nearest	B-Method
neighbor	I-Method
search	I-Method
on	O
the	O
training	O
set	O
.	O
	
Nearest	O
neighbors	O
in	O
pixel	O
or	O
feature	O
space	O
are	O
trivially	O
fooled	O
Theis2015d	O
by	O
small	B-Method
image	I-Method
transforms	I-Method
.	O
	
We	O
also	O
do	O
not	O
use	O
log	B-Metric
-	I-Metric
likelihood	I-Metric
metrics	I-Metric
to	O
quantitatively	O
assess	O
the	O
model	O
,	O
as	O
it	O
is	O
a	O
poor	O
Theis2015d	O
metric	O
.	O
	
subsection	O
:	O
Walking	O
in	O
the	O
latent	O
space	O
	
The	O
first	O
experiment	O
we	O
did	O
was	O
to	O
understand	O
the	O
landscape	O
of	O
the	O
latent	O
space	O
.	O
	
Walking	O
on	O
the	O
manifold	O
that	O
is	O
learnt	O
can	O
usually	O
tell	O
us	O
about	O
signs	O
of	O
memorization	O
(	O
if	O
there	O
are	O
sharp	O
transitions	O
)	O
and	O
about	O
the	O
way	O
in	O
which	O
the	O
space	O
is	O
hierarchically	O
collapsed	O
.	O
	
If	O
walking	O
in	O
this	O
latent	O
space	O
results	O
in	O
semantic	O
changes	O
to	O
the	O
image	O
generations	O
(	O
such	O
as	O
objects	O
being	O
added	O
and	O
removed	O
)	O
,	O
we	O
can	O
reason	O
that	O
the	O
model	O
has	O
learned	O
relevant	O
and	O
interesting	O
representations	O
.	O
	
The	O
results	O
are	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
subsection	O
:	O
Visualizing	O
the	O
Discriminator	O
Features	O
	
Previous	O
work	O
has	O
demonstrated	O
that	O
supervised	B-Method
training	I-Method
of	I-Method
CNNs	I-Method
on	O
large	O
image	O
datasets	O
results	O
in	O
very	O
powerful	O
learned	O
features	O
zeiler2014visualizing	O
.	O
	
Additionally	O
,	O
supervised	B-Method
CNNs	I-Method
trained	O
on	O
scene	B-Task
classification	I-Task
learn	O
object	B-Method
detectors	I-Method
Oquab14	O
.	O
	
We	O
demonstrate	O
that	O
an	O
unsupervised	O
DCGAN	B-Method
trained	O
on	O
a	O
large	O
image	O
dataset	O
can	O
also	O
learn	O
a	O
hierarchy	O
of	O
features	O
that	O
are	O
interesting	O
.	O
	
Using	O
guided	B-Method
backpropagation	I-Method
as	O
proposed	O
by	O
springenberg2014striving	O
,	O
we	O
show	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
that	O
the	O
features	O
learnt	O
by	O
the	O
discriminator	B-Method
activate	O
on	O
typical	O
parts	O
of	O
a	O
bedroom	O
,	O
like	O
beds	O
and	O
windows	O
.	O
	
For	O
comparison	O
,	O
in	O
the	O
same	O
figure	O
,	O
we	O
give	O
a	O
baseline	O
for	O
randomly	O
initialized	O
features	O
that	O
are	O
not	O
activated	O
on	O
anything	O
that	O
is	O
semantically	O
relevant	O
or	O
interesting	O
.	O
	
subsection	O
:	O
Manipulating	O
the	O
Generator	B-Method
Representation	I-Method
	
subsubsection	O
:	O
Forgetting	O
to	O
draw	O
certain	O
objects	O
	
In	O
addition	O
to	O
the	O
representations	O
learnt	O
by	O
a	O
discriminator	B-Method
,	O
there	O
is	O
the	O
question	O
of	O
what	O
representations	O
the	O
generator	B-Method
learns	O
.	O
	
The	O
quality	O
of	O
samples	O
suggest	O
that	O
the	O
generator	B-Method
learns	O
specific	O
object	B-Method
representations	I-Method
for	O
major	O
scene	O
components	O
such	O
as	O
beds	O
,	O
windows	O
,	O
lamps	O
,	O
doors	O
,	O
and	O
miscellaneous	O
furniture	O
.	O
	
In	O
order	O
to	O
explore	O
the	O
form	O
that	O
these	O
representations	O
take	O
,	O
we	O
conducted	O
an	O
experiment	O
to	O
attempt	O
to	O
remove	O
windows	O
from	O
the	O
generator	B-Method
completely	O
.	O
	
On	O
150	O
samples	O
,	O
52	O
window	O
bounding	O
boxes	O
were	O
drawn	O
manually	O
.	O
	
On	O
the	O
second	O
highest	O
convolution	O
layer	O
features	O
,	O
logistic	B-Method
regression	I-Method
was	O
fit	O
to	O
predict	O
whether	O
a	O
feature	O
activation	O
was	O
on	O
a	O
window	O
(	O
or	O
not	O
)	O
,	O
by	O
using	O
the	O
criterion	O
that	O
activations	O
inside	O
the	O
drawn	O
bounding	O
boxes	O
are	O
positives	O
and	O
random	O
samples	O
from	O
the	O
same	O
images	O
are	O
negatives	O
.	O
	
Using	O
this	O
simple	O
model	O
,	O
all	O
feature	O
maps	O
with	O
weights	O
greater	O
than	O
zero	O
(	O
200	O
in	O
total	O
)	O
were	O
dropped	O
from	O
all	O
spatial	O
locations	O
.	O
	
Then	O
,	O
random	O
new	O
samples	O
were	O
generated	O
with	O
and	O
without	O
the	O
feature	B-Method
map	I-Method
removal	I-Method
.	O
	
The	O
generated	O
images	O
with	O
and	O
without	O
the	O
window	O
dropout	O
are	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
and	O
interestingly	O
,	O
the	O
network	O
mostly	O
forgets	O
to	O
draw	O
windows	O
in	O
the	O
bedrooms	O
,	O
replacing	O
them	O
with	O
other	O
objects	O
.	O
	
subsubsection	O
:	O
Vector	B-Method
arithmetic	I-Method
on	O
face	O
samples	O
	
In	O
the	O
context	O
of	O
evaluating	O
learned	B-Task
representations	I-Task
of	I-Task
words	I-Task
mikolov2013distributed	O
demonstrated	O
that	O
simple	O
arithmetic	B-Method
operations	I-Method
revealed	O
rich	O
linear	O
structure	O
in	O
representation	O
space	O
.	O
	
One	O
canonical	O
example	O
demonstrated	O
that	O
the	O
vector	O
(	O
”King	O
”	O
)	O
-	O
vector	O
(	O
”Man	O
”	O
)	O
+	O
vector	O
(	O
”Woman	O
”	O
)	O
resulted	O
in	O
a	O
vector	O
whose	O
nearest	O
neighbor	O
was	O
the	O
vector	O
for	O
Queen	O
.	O
	
We	O
investigated	O
whether	O
similar	O
structure	O
emerges	O
in	O
the	O
representation	O
of	O
our	O
generators	O
.	O
	
We	O
performed	O
similar	O
arithmetic	O
on	O
the	O
vectors	O
of	O
sets	O
of	O
exemplar	O
samples	O
for	O
visual	O
concepts	O
.	O
	
Experiments	O
working	O
on	O
only	O
single	O
samples	O
per	O
concept	O
were	O
unstable	O
,	O
but	O
averaging	O
the	O
vector	O
for	O
three	O
examplars	O
showed	O
consistent	O
and	O
stable	O
generations	O
that	O
semantically	O
obeyed	O
the	O
arithmetic	O
.	O
	
In	O
addition	O
to	O
the	O
object	O
manipulation	O
shown	O
in	O
(	O
Fig	O
.	O
[	O
reference	O
]	O
)	O
,	O
we	O
demonstrate	O
that	O
face	O
pose	O
is	O
also	O
modeled	O
linearly	O
in	O
space	O
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
These	O
demonstrations	O
suggest	O
interesting	O
applications	O
can	O
be	O
developed	O
using	O
representations	B-Method
learned	O
by	O
our	O
models	O
.	O
	
It	O
has	O
been	O
previously	O
demonstrated	O
that	O
conditional	B-Method
generative	I-Method
models	I-Method
can	O
learn	O
to	O
convincingly	O
model	O
object	O
attributes	O
like	O
scale	O
,	O
rotation	O
,	O
and	O
position	O
dosovitskiy2014learning	O
.	O
	
This	O
is	O
to	O
our	O
knowledge	O
the	O
first	O
demonstration	O
of	O
this	O
occurring	O
in	O
purely	O
unsupervised	B-Method
models	I-Method
.	O
	
Further	O
exploring	O
and	O
developing	O
the	O
above	O
mentioned	O
vector	B-Method
arithmetic	I-Method
could	O
dramatically	O
reduce	O
the	O
amount	O
of	O
data	O
needed	O
for	O
conditional	B-Method
generative	I-Method
modeling	I-Method
of	O
complex	B-Task
image	I-Task
distributions	I-Task
.	O
	
section	O
:	O
Conclusion	O
and	O
Future	O
Work	O
	
We	O
propose	O
a	O
more	O
stable	O
set	O
of	O
architectures	O
for	O
training	O
generative	B-Method
adversarial	I-Method
networks	I-Method
and	O
we	O
give	O
evidence	O
that	O
adversarial	B-Method
networks	I-Method
learn	O
good	O
representations	O
of	O
images	O
for	O
supervised	B-Task
learning	I-Task
and	O
generative	B-Task
modeling	I-Task
.	O
	
There	O
are	O
still	O
some	O
forms	O
of	O
model	O
instability	O
remaining	O
-	O
we	O
noticed	O
as	O
models	O
are	O
trained	O
longer	O
they	O
sometimes	O
collapse	O
a	O
subset	O
of	O
filters	O
to	O
a	O
single	O
oscillating	O
mode	O
.	O
	
Further	O
work	O
is	O
needed	O
to	O
tackle	O
this	O
from	O
of	O
instability	O
.	O
	
We	O
think	O
that	O
extending	O
this	O
framework	O
to	O
other	O
domains	O
such	O
as	O
video	O
(	O
for	O
frame	B-Task
prediction	I-Task
)	O
and	O
audio	O
(	O
pre	B-Task
-	I-Task
trained	I-Task
features	I-Task
for	O
speech	B-Task
synthesis	I-Task
)	O
should	O
be	O
very	O
interesting	O
.	O
	
Further	O
investigations	O
into	O
the	O
properties	O
of	O
the	O
learnt	O
latent	O
space	O
would	O
be	O
interesting	O
as	O
well	O
.	O
	
subsubsection	O
:	O
Acknowledgments	O
	
We	O
are	O
fortunate	O
and	O
thankful	O
for	O
all	O
the	O
advice	O
and	O
guidance	O
we	O
have	O
received	O
during	O
this	O
work	O
,	O
especially	O
that	O
of	O
Ian	O
Goodfellow	O
,	O
Tobias	O
Springenberg	O
,	O
Arthur	O
Szlam	O
and	O
Durk	O
Kingma	O
.	O
	
Additionally	O
we	O
’d	O
like	O
to	O
thank	O
all	O
of	O
the	O
folks	O
at	O
indico	O
for	O
providing	O
support	O
,	O
resources	O
,	O
and	O
conversations	O
,	O
especially	O
the	O
two	O
other	O
members	O
of	O
the	O
indico	O
research	O
team	O
,	O
Dan	O
Kuster	O
and	O
Nathan	O
Lintz	O
.	O
	
Finally	O
,	O
we	O
’d	O
like	O
to	O
thank	O
Nvidia	O
for	O
donating	O
a	O
Titan	O
-	O
X	O
GPU	O
used	O
in	O
this	O
work	O
.	O
	
bibliography	O
:	O
References	O
	
section	O
:	O
Supplementary	O
Material	O
	
subsection	O
:	O
Evaluating	O
DCGANs	B-Method
capability	O
to	O
capture	O
data	B-Task
distributions	I-Task
	
We	O
propose	O
to	O
apply	O
standard	O
classification	B-Method
metrics	I-Method
to	O
a	O
conditional	B-Method
version	I-Method
of	O
our	O
model	O
,	O
evaluating	O
the	O
conditional	O
distributions	O
learned	O
.	O
	
We	O
trained	O
a	O
DCGAN	B-Method
on	O
MNIST	B-Material
(	O
splitting	O
off	O
a	O
10	O
K	O
validation	O
set	O
)	O
as	O
well	O
as	O
a	O
permutation	O
invariant	O
GAN	B-Method
baseline	O
and	O
evaluated	O
the	O
models	O
using	O
a	O
nearest	B-Method
neighbor	I-Method
classifier	I-Method
comparing	O
real	O
data	O
to	O
a	O
set	O
of	O
generated	O
conditional	O
samples	O
.	O
	
We	O
found	O
that	O
removing	O
the	O
scale	O
and	O
bias	O
parameters	O
from	O
batchnorm	B-Method
produced	O
better	O
results	O
for	O
both	O
models	O
.	O
	
We	O
speculate	O
that	O
the	O
noise	O
introduced	O
by	O
batchnorm	B-Method
helps	O
the	O
generative	B-Method
models	I-Method
to	O
better	O
explore	O
and	O
generate	O
from	O
the	O
underlying	O
data	O
distribution	O
.	O
	
The	O
results	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
which	O
compares	O
our	O
models	O
with	O
other	O
techniques	O
.	O
	
The	O
DCGAN	B-Method
model	O
achieves	O
the	O
same	O
test	B-Metric
error	I-Metric
as	O
a	O
nearest	B-Method
neighbor	I-Method
classifier	I-Method
fitted	O
on	O
the	O
training	O
dataset	O
-	O
suggesting	O
the	O
DCGAN	B-Method
model	O
has	O
done	O
a	O
superb	O
job	O
at	O
modeling	O
the	O
conditional	O
distributions	O
of	O
this	O
dataset	O
.	O
	
At	O
one	O
million	O
samples	O
per	O
class	O
,	O
the	O
DCGAN	B-Method
model	O
outperforms	O
InfiMNIST	B-Method
loosli	O
-	O
canu	O
-	O
bottou	O
-	O
2006	O
,	O
a	O
hand	B-Method
developed	I-Method
data	I-Method
augmentation	I-Method
pipeline	I-Method
which	O
uses	O
translations	O
and	O
elastic	O
deformations	O
of	O
training	O
examples	O
.	O
	
The	O
DCGAN	B-Method
is	O
competitive	O
with	O
a	O
probabilistic	B-Method
generative	I-Method
data	I-Method
augmentation	I-Method
technique	I-Method
utilizing	O
learned	O
per	B-Method
class	I-Method
transformations	I-Method
Hauberg2015	O
while	O
being	O
more	O
general	O
as	O
it	O
directly	O
models	O
the	O
data	O
instead	O
of	O
transformations	O
of	O
the	O
data	O
.	O
	
document	O
:	O
Deep	B-Method
Learning	I-Method
For	O
Smile	B-Task
Recognition	I-Task
	
Inspired	O
by	O
recent	O
successes	O
of	O
deep	B-Method
learning	I-Method
in	O
computer	B-Task
vision	I-Task
,	O
we	O
propose	O
a	O
novel	O
application	O
of	O
deep	B-Method
convolutional	I-Method
neural	I-Method
networks	I-Method
to	O
facial	B-Task
expression	I-Task
recognition	I-Task
,	O
in	O
particular	O
smile	B-Task
recognition	I-Task
.	O
	
A	O
smile	B-Metric
recognition	I-Metric
test	I-Metric
accuracy	I-Metric
of	O
99.45	O
%	O
is	O
achieved	O
for	O
the	O
Denver	B-Material
Intensity	I-Material
of	I-Material
Spontaneous	I-Material
Facial	I-Material
Action	I-Material
	
(	O
DISFA	B-Material
)	O
database	O
,	O
significantly	O
outperforming	O
existing	O
approaches	O
based	O
on	O
hand	O
-	O
crafted	O
features	O
with	O
accuracies	B-Metric
ranging	O
from	O
65.55	O
%	O
to	O
79.67	O
%	O
.	O
	
The	O
novelty	O
of	O
this	O
approach	O
includes	O
a	O
comprehensive	O
model	B-Method
selection	I-Method
of	O
the	O
architecture	O
parameters	O
,	O
allowing	O
to	O
find	O
an	O
appropriate	O
architecture	O
for	O
each	O
expression	O
such	O
as	O
smile	O
.	O
	
This	O
is	O
feasible	O
because	O
all	O
experiments	O
were	O
run	O
on	O
a	O
Tesla	O
K40c	O
GPU	O
,	O
allowing	O
a	O
speedup	O
of	O
factor	O
10	O
over	O
traditional	O
computations	O
on	O
a	O
CPU	O
.	O
	
section	O
:	O
Introduction	O
	
Neural	B-Method
networks	I-Method
are	O
celebrating	O
a	O
comeback	O
under	O
the	O
term	O
”	O
deep	B-Method
learning	I-Method
”	O
for	O
the	O
last	O
ten	O
years	O
by	O
training	O
many	O
hidden	O
layers	O
allowing	O
to	O
self	O
-	O
learn	O
complex	O
feature	O
hierarchies	O
.	O
	
This	O
makes	O
them	O
of	O
particular	O
interest	O
for	O
computer	B-Task
vision	I-Task
,	O
in	O
which	O
feature	B-Task
description	I-Task
is	O
a	O
long	O
-	O
standing	O
issue	O
.	O
	
Many	O
advances	O
have	O
been	O
reported	O
in	O
this	O
period	O
,	O
including	O
new	O
training	B-Method
methods	I-Method
and	O
a	O
paradigm	O
shift	O
of	O
training	O
from	O
CPUs	B-Method
to	O
GPUs	B-Method
.	O
	
As	O
a	O
result	O
,	O
those	O
advances	O
allow	O
to	O
train	O
more	O
reliable	O
models	O
much	O
faster	O
.	O
	
This	O
has	O
for	O
example	O
resulted	O
in	O
breakthroughs	O
in	O
signal	B-Task
processing	I-Task
.	O
	
Nonetheless	O
,	O
deep	B-Method
neural	I-Method
networks	I-Method
are	O
not	O
a	O
magic	O
bullet	O
and	O
successful	O
training	O
is	O
still	O
heavily	O
based	O
on	O
experimentation	O
.	O
	
The	O
Facial	B-Method
Action	I-Method
Coding	I-Method
System	I-Method
(	I-Method
FACS	I-Method
)	O
is	O
a	O
system	O
to	O
taxonomize	O
any	O
facial	O
expression	O
of	O
a	O
human	O
being	O
by	O
their	O
appearance	O
on	O
the	O
face	O
.	O
	
Action	O
units	O
describe	O
muscles	O
or	O
muscle	O
groups	O
in	O
the	O
face	O
,	O
are	O
set	O
or	O
unset	O
and	O
the	O
activation	O
may	O
be	O
on	O
different	O
intensity	O
levels	O
.	O
	
State	O
-	O
of	O
-	O
the	O
art	O
approaches	O
in	O
this	O
field	O
mostly	O
rely	O
on	O
hand	O
-	O
crafted	O
features	O
leaving	O
a	O
lot	O
of	O
potential	O
for	O
higher	O
accuracies	B-Metric
.	O
	
In	O
contrast	O
to	O
other	O
fields	O
such	O
as	O
face	B-Task
or	I-Task
gesture	I-Task
recognition	I-Task
,	O
only	O
very	O
few	O
works	O
on	O
deep	B-Method
learning	I-Method
applied	O
to	O
facial	B-Task
expression	I-Task
recognition	I-Task
have	O
been	O
reported	O
so	O
far	O
in	O
which	O
the	O
architecture	O
parameters	O
are	O
fixed	O
.	O
	
We	O
are	O
not	O
aware	O
of	O
publications	O
in	O
which	O
the	O
architecture	O
of	O
a	O
deep	B-Method
neural	I-Method
network	I-Method
for	O
facial	B-Task
expression	I-Task
recognition	I-Task
is	O
subject	O
to	O
extensive	O
model	B-Method
selection	I-Method
.	O
	
This	O
allows	O
to	O
learn	O
appropriate	O
architectures	O
per	O
action	O
unit	O
.	O
	
section	O
:	O
Deep	B-Method
neural	I-Method
networks	I-Method
	
Training	B-Method
neural	I-Method
networks	I-Method
is	O
difficult	O
,	O
as	O
their	O
cost	O
functions	O
have	O
many	O
local	O
minima	O
.	O
	
The	O
more	O
hidden	O
layers	O
,	O
the	O
more	O
difficult	O
the	O
training	O
of	O
a	O
neural	B-Method
network	I-Method
.	O
	
Hence	O
,	O
training	B-Task
tends	O
to	O
converge	O
to	O
a	O
local	O
minimum	O
,	O
resulting	O
in	O
poor	O
generalization	O
of	O
the	O
network	O
.	O
	
In	O
order	O
to	O
overcome	O
these	O
issues	O
,	O
a	O
variety	O
of	O
new	O
concepts	O
have	O
been	O
proposed	O
in	O
the	O
literature	O
,	O
of	O
which	O
only	O
a	O
few	O
can	O
be	O
named	O
in	O
this	O
chapter	O
.	O
	
Unsupervised	B-Method
pre	I-Method
-	I-Method
training	I-Method
methods	I-Method
,	O
such	O
as	O
autoencoders	B-Method
allow	O
to	O
initialize	O
the	O
weights	O
well	O
in	O
order	O
for	O
backpropagation	B-Method
to	O
quickly	O
optimize	O
them	O
.	O
	
The	O
Rectified	B-Method
Linear	I-Method
Unit	I-Method
(	O
ReLU	B-Method
)	O
and	O
	
dropout	B-Method
are	O
new	O
regularization	B-Method
methods	I-Method
.	O
	
The	O
new	O
training	B-Method
methods	I-Method
and	O
other	O
new	O
concepts	O
can	O
also	O
lead	O
to	O
significant	O
improvements	O
of	O
shallow	B-Method
neural	I-Method
networks	I-Method
with	O
just	O
a	O
few	O
hidden	O
layers	O
.	O
	
Convolutional	B-Method
neural	I-Method
networks	I-Method
(	O
CNNs	B-Method
)	O
were	O
initially	O
proposed	O
by	O
LeCun	B-Method
for	O
the	O
recognition	B-Task
of	I-Task
hand	I-Task
-	I-Task
written	I-Task
digits	I-Task
.	O
	
A	O
CNN	B-Method
consists	O
of	O
two	O
layers	O
:	O
a	O
convolutional	B-Method
layer	O
,	O
followed	O
by	O
a	O
subsampling	B-Method
layer	I-Method
.	O
	
Inspired	O
by	O
biological	B-Method
processes	I-Method
and	O
exploiting	O
the	O
fact	O
that	O
nearby	O
pixels	O
are	O
strongly	O
correlated	O
,	O
CNNs	B-Method
are	O
relatively	O
insensitive	O
to	O
small	O
translations	O
or	O
rotations	O
of	O
the	O
image	O
input	O
.	O
	
Training	O
deep	B-Method
neural	I-Method
networks	I-Method
is	O
slow	O
due	O
to	O
the	O
number	O
of	O
parameters	O
in	O
the	O
model	O
.	O
	
As	O
the	O
training	B-Task
can	O
be	O
described	O
in	O
a	O
vectorized	B-Method
form	I-Method
,	O
it	O
is	O
possible	O
to	O
massively	O
parallelize	O
it	O
.	O
	
Modern	O
GPUs	B-Method
have	O
thousands	O
of	O
cores	O
and	O
are	O
therefore	O
an	O
ideal	O
candidate	O
for	O
the	O
execution	O
of	O
the	O
training	B-Task
of	I-Task
neural	I-Task
networks	I-Task
.	O
	
Significant	O
speedups	O
of	O
factor	O
10	O
or	O
higher	O
have	O
been	O
reported	O
.	O
	
A	O
difficulty	O
is	O
to	O
write	O
GPU	B-Method
code	I-Method
.	O
	
In	O
the	O
last	O
few	O
years	O
,	O
more	O
abstract	O
libraries	O
have	O
been	O
released	O
.	O
	
section	O
:	O
DISFA	B-Material
database	O
	
The	O
Denver	B-Material
Intensity	I-Material
of	I-Material
Spontaneous	I-Material
Facial	I-Material
Action	I-Material
	
(	O
DISFA	B-Material
)	O
database	O
consists	O
of	O
27	O
videos	O
of	O
4844	O
frames	O
each	O
,	O
with	O
130	O
,	O
788	O
images	O
in	O
total	O
.	O
	
Action	O
unit	O
annotations	O
are	O
on	O
different	O
levels	O
of	O
intensity	O
,	O
which	O
are	O
ignored	O
in	O
the	O
following	O
experiments	O
and	O
action	O
units	O
are	O
either	O
set	O
or	O
unset	O
.	O
	
DISFA	B-Material
was	O
selected	O
from	O
a	O
wider	O
range	O
of	O
databases	O
popular	O
in	O
the	O
field	O
of	O
facial	B-Task
expression	I-Task
recognition	I-Task
because	O
of	O
the	O
high	O
number	O
of	O
smiles	O
,	O
i.e.	O
action	O
unit	O
12	O
.	O
	
In	O
detail	O
,	O
30	O
,	O
792	O
have	O
this	O
action	O
unit	O
set	O
,	O
82	O
,	O
176	O
images	O
have	O
some	O
action	O
unit	O
(	O
s	O
)	O
set	O
and	O
48	O
,	O
612	O
images	O
have	O
no	O
action	O
unit	O
(	O
s	O
)	O
set	O
at	O
all	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
contains	O
a	O
sample	O
image	O
of	O
DISFA	B-Material
.	O
	
[	O
width=0.2	O
]	O
mouth	O
[	O
width=0.2	O
]	O
face	O
	
In	O
the	O
original	O
paper	O
on	O
DISFA	B-Material
multi	O
-	O
class	O
SVMs	O
were	O
trained	O
for	O
the	O
different	O
levels	O
0	O
-	O
5	O
of	O
action	O
unit	O
intensity	O
.	O
	
Test	O
accuracies	B-Metric
for	O
the	O
individual	O
levels	O
and	O
for	O
the	O
binary	O
action	B-Task
unit	I-Task
recognition	I-Task
problem	O
are	O
reported	O
for	O
three	O
different	O
hand	B-Method
-	I-Method
crafted	I-Method
feature	I-Method
description	I-Method
techniques	I-Method
.	O
	
In	O
those	O
three	O
cases	O
,	O
accuracies	B-Metric
of	O
65.55	O
%	O
,	O
72.94	O
%	O
and	O
79.67	O
%	O
for	O
smile	B-Task
recognition	I-Task
are	O
reported	O
.	O
	
section	O
:	O
Smile	B-Task
recognition	I-Task
	
In	O
the	O
following	O
experiments	O
,	O
an	O
aligned	O
version	O
of	O
DISFA	B-Material
is	O
used	O
.	O
	
In	O
this	O
aligned	O
version	O
,	O
the	O
faces	O
have	O
been	O
cropped	O
and	O
annotated	O
with	O
facial	O
landmark	O
points	O
.	O
	
Facial	O
landmark	O
points	O
allow	O
to	O
compute	O
a	O
bounding	O
box	O
to	O
fit	O
the	O
mouth	O
in	O
all	O
images	O
.	O
	
In	O
the	O
experiments	O
,	O
two	O
inputs	O
are	O
used	O
:	O
the	O
mouth	O
and	O
face	O
,	O
downscaled	O
to	O
and	O
pixels	O
,	O
respectively	O
.	O
	
Both	O
inputs	O
are	O
used	O
to	O
assess	O
if	O
the	O
mouth	O
alone	O
is	O
as	O
expressive	O
as	O
or	O
even	O
more	O
expressive	O
than	O
the	O
entire	O
face	O
for	O
smile	B-Task
recognition	I-Task
.	O
	
subsection	O
:	O
Model	O
	
The	O
architecture	O
of	O
the	O
network	O
is	O
as	O
follows	O
:	O
The	O
input	O
images	O
are	O
fed	O
into	O
a	O
convolution	B-Method
comprising	O
a	O
convolutional	B-Method
and	O
a	O
subsampling	B-Method
layer	I-Method
.	O
	
That	O
convolution	B-Method
may	O
be	O
followed	O
by	O
more	O
convolutions	B-Method
to	O
become	O
gradually	O
more	O
invariant	O
to	O
distortions	O
in	O
the	O
input	O
.	O
	
In	O
the	O
second	O
stage	O
,	O
a	O
regular	B-Method
neural	I-Method
network	I-Method
follows	O
the	O
convolutions	B-Method
in	O
order	O
to	O
discriminate	O
the	O
features	O
learned	O
by	O
the	O
convolutions	B-Method
.	O
	
The	O
output	B-Method
layer	I-Method
consists	O
of	O
two	O
units	O
for	O
smile	O
or	O
no	O
smile	O
.	O
	
The	O
novelty	O
of	O
this	O
approach	O
is	O
that	O
the	O
exact	O
number	O
of	O
convolutions	O
,	O
number	O
of	O
hidden	O
layers	O
and	O
size	O
of	O
hidden	O
layers	O
are	O
not	O
fixed	O
but	O
subject	O
to	O
extensive	O
model	B-Task
selection	I-Task
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
.	O
	
subsection	O
:	O
Experiment	O
setting	O
	
Due	O
to	O
training	O
time	O
constraints	O
,	O
some	O
parameters	O
have	O
been	O
fixed	O
to	O
reasonable	O
and	O
empirical	O
values	O
,	O
such	O
as	O
the	O
size	O
of	O
convolutions	O
(	O
pixels	O
,	O
32	O
feature	O
maps	O
)	O
and	O
the	O
size	O
of	O
subsamplings	O
(	O
pixels	O
using	O
max	B-Method
pooling	I-Method
)	O
.	O
	
All	O
layers	O
use	O
ReLU	O
units	O
,	O
except	O
of	O
softmax	B-Method
being	O
used	O
in	O
the	O
output	O
layer	O
.	O
	
The	O
learning	B-Metric
rate	I-Metric
is	O
fixed	O
to	O
and	O
not	O
subject	O
to	O
model	B-Task
selection	I-Task
as	O
it	O
would	O
significantly	O
prolong	O
the	O
model	B-Task
selection	I-Task
.	O
	
The	O
same	O
considerations	O
apply	O
to	O
the	O
momentum	O
,	O
which	O
is	O
fixed	O
to	O
.	O
	
The	O
entire	O
database	O
has	O
been	O
randomly	O
split	O
into	O
a	O
60%	O
/	O
20%	O
/	O
20	O
%	O
training	B-Metric
/	I-Metric
validation	I-Metric
/	I-Metric
test	I-Metric
ratio	I-Metric
.	O
	
Training	B-Method
neural	I-Method
networks	I-Method
comes	O
with	O
uncertainties	O
,	O
mostly	O
due	O
to	O
the	O
random	O
initialization	O
of	O
the	O
weights	O
,	O
but	O
also	O
due	O
to	O
that	O
random	O
split	O
of	O
the	O
data	O
.	O
	
Evaluations	O
have	O
shown	O
that	O
for	O
10	O
similar	O
experiments	O
carried	O
out	O
,	O
the	O
standard	O
deviation	O
of	O
the	O
test	B-Metric
accuracy	I-Metric
is	O
0.041725	O
%	O
.	O
	
Because	O
of	O
this	O
low	O
standard	O
deviation	O
,	O
performing	O
each	O
experiment	O
exactly	O
once	O
has	O
only	O
a	O
very	O
low	O
bias	O
and	O
is	O
therefore	O
relatively	O
safe	O
to	O
do	O
for	O
reasons	O
of	O
faster	O
training	B-Task
time	I-Task
.	O
	
Throughout	O
the	O
experiments	O
,	O
the	O
classification	B-Metric
rate	I-Metric
is	O
used	O
as	O
the	O
accuracy	B-Metric
measure	I-Metric
.	O
	
The	O
model	O
is	O
implemented	O
using	O
Lasagne	B-Method
and	O
the	O
generated	O
CUDA	B-Method
code	I-Method
is	O
executed	O
on	O
a	O
Tesla	B-Method
K40c	I-Method
as	O
training	O
on	O
a	O
GPU	O
allows	O
to	O
perform	O
a	O
comprehensive	O
model	B-Task
selection	I-Task
in	O
a	O
feasible	O
amount	O
of	O
time	O
.	O
	
Stochastic	B-Method
gradient	I-Method
descent	I-Method
with	O
a	O
batch	O
size	O
of	O
500	O
is	O
used	O
.	O
	
subsection	O
:	O
Parameter	B-Task
optimization	I-Task
	
Table	O
[	O
reference	O
]	O
contains	O
the	O
four	O
parameters	O
to	O
be	O
optimized	O
:	O
the	O
number	O
of	O
convolutions	O
,	O
the	O
number	O
of	O
hidden	O
layers	O
,	O
the	O
number	O
of	O
units	O
per	O
hidden	O
layer	O
and	O
the	O
dropout	O
factor	O
.	O
	
Each	O
parameter	O
was	O
optimized	O
independently	O
due	O
to	O
training	O
time	O
constraints	O
.	O
	
This	O
may	O
not	O
lead	O
to	O
an	O
optimal	O
model	O
,	O
but	O
has	O
proven	O
to	O
work	O
empirically	O
well	O
.	O
	
Each	O
model	O
was	O
trained	O
for	O
50	O
epochs	O
in	O
the	O
model	B-Task
selection	I-Task
.	O
	
Parameters	O
and	O
possible	O
values	O
used	O
in	O
model	B-Task
selection	I-Task
.	O
	
For	O
both	O
inputs	O
,	O
Table	O
[	O
reference	O
]	O
contains	O
the	O
final	O
models	O
selected	O
.	O
	
For	O
the	O
mouth	O
input	O
,	O
there	O
is	O
a	O
preference	O
to	O
more	O
convolutions	O
and	O
more	O
hidden	O
layers	O
.	O
	
This	O
is	O
the	O
case	O
because	O
slight	O
translations	O
or	O
rotations	O
in	O
the	O
mouth	O
input	O
have	O
stronger	O
consequences	O
on	O
the	O
classification	B-Task
result	O
.	O
	
In	O
the	O
entire	O
face	O
,	O
that	O
sort	O
of	O
distortions	O
may	O
be	O
less	O
of	O
a	O
problem	O
because	O
other	O
parts	O
of	O
the	O
face	O
such	O
as	O
the	O
cheeks	O
contribute	O
to	O
smile	B-Task
recognition	I-Task
,	O
too	O
.	O
	
Selected	O
parameter	O
values	O
for	O
mouth	O
and	O
face	O
input	O
.	O
	
subsection	O
:	O
Results	O
and	O
discussion	O
	
Both	O
final	O
models	O
were	O
trained	O
for	O
1000	O
epochs	O
.	O
	
The	O
test	O
accuracies	B-Metric
of	O
both	O
models	O
started	O
to	O
converge	O
after	O
about	O
300	O
epochs	O
.	O
	
For	O
the	O
mouth	O
and	O
face	O
inputs	O
,	O
the	O
best	O
accuracies	B-Metric
were	O
achieved	O
after	O
700	O
and	O
1000	O
epochs	O
with	O
99.45	O
%	O
and	O
99.34	O
%	O
,	O
respectively	O
.	O
	
Both	O
models	O
significantly	O
outperform	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
SVM	B-Method
baselines	I-Method
reported	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
ranging	O
from	O
65.55	O
%	O
to	O
79.67	O
%	O
.	O
	
Overall	O
,	O
there	O
is	O
no	O
strong	O
preference	O
for	O
either	O
the	O
mouth	O
or	O
face	O
input	O
.	O
	
Further	O
experiments	O
with	O
a	O
reduced	O
dataset	O
containing	O
only	O
70	O
%	O
of	O
the	O
images	O
that	O
have	O
no	O
action	O
unit	O
(	O
s	O
)	O
set	O
at	O
all	O
support	O
this	O
hypothesis	O
.	O
	
Concretely	O
,	O
the	O
test	O
accuracies	B-Metric
for	O
the	O
mouth	O
and	O
face	O
input	O
reduced	O
to	O
99.24	O
%	O
and	O
99.26	O
%	O
,	O
respectively	O
.	O
	
Thus	O
,	O
the	O
difference	O
between	O
the	O
two	O
models	O
has	O
been	O
further	O
reduced	O
and	O
this	O
time	O
giving	O
a	O
very	O
low	O
preference	O
for	O
the	O
face	O
input	O
.	O
	
Nonetheless	O
,	O
this	O
difference	O
is	O
not	O
representative	O
as	O
it	O
is	O
within	O
the	O
experiment	O
error	O
standard	O
deviation	O
reported	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
.	O
	
Training	B-Metric
time	I-Metric
per	O
epoch	O
are	O
82	O
seconds	O
and	O
41	O
seconds	O
for	O
the	O
mouth	B-Method
and	I-Method
face	I-Method
input	I-Method
models	I-Method
,	O
respectively	O
.	O
	
Experiments	O
have	O
shown	O
that	O
the	O
training	B-Metric
time	I-Metric
mostly	O
depends	O
on	O
the	O
number	O
of	O
convolutions	O
.	O
	
Using	O
the	O
Tesla	B-Method
K40c	I-Method
GPU	I-Method
has	O
allowed	O
to	O
speed	O
up	O
the	O
training	B-Metric
time	I-Metric
by	O
factor	O
ten	O
over	O
the	O
use	O
of	O
a	O
CPU	O
to	O
execute	O
the	O
CPU	O
code	O
generated	O
by	O
the	O
library	O
.	O
	
This	O
clearly	O
demonstrates	O
the	O
importance	O
of	O
training	O
on	O
a	O
GPU	O
to	O
do	O
a	O
comprehensive	O
model	B-Method
selection	I-Method
in	O
a	O
feasible	O
amount	O
of	O
time	O
.	O
	
section	O
:	O
Conclusions	O
and	O
future	O
work	O
	
Deep	B-Method
learning	I-Method
is	O
an	O
umbrella	B-Method
term	I-Method
for	O
training	O
neural	B-Method
networks	I-Method
with	O
potentially	O
many	O
hidden	O
layers	O
using	O
new	O
training	B-Method
methods	I-Method
allowing	O
to	O
learn	O
complex	O
feature	O
hierarchies	O
from	O
data	O
.	O
	
Applied	O
to	O
action	B-Task
unit	I-Task
recognition	I-Task
and	O
smile	B-Task
recognition	I-Task
in	O
particular	O
,	O
a	O
deep	O
convolutional	B-Method
neural	O
network	O
model	O
with	O
an	O
overall	O
accuracy	B-Metric
of	O
99.45	O
%	O
significantly	O
outperforms	O
existing	O
approaches	O
.	O
	
The	O
underlying	O
extensive	O
model	B-Method
selection	I-Method
allows	O
to	O
find	O
for	O
each	O
action	O
unit	O
an	O
appropriate	O
architecture	O
in	O
order	O
to	O
maximize	O
test	O
accuracies	O
.	O
	
In	O
the	O
future	O
,	O
we	O
will	O
extend	O
the	O
model	O
to	O
images	O
from	O
multiple	O
databases	O
and	O
to	O
make	O
predictions	O
in	O
image	O
sequences	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Multi	B-Method
-	I-Method
column	I-Method
Deep	I-Method
Neural	I-Method
Networks	I-Method
for	O
Image	B-Task
Classification	I-Task
	
Traditional	O
methods	O
of	O
computer	B-Method
vision	I-Method
and	O
machine	B-Method
learning	I-Method
can	O
not	O
match	O
human	O
performance	O
on	O
tasks	O
such	O
as	O
the	O
recognition	B-Task
of	I-Task
handwritten	I-Task
digits	I-Task
or	O
traffic	B-Task
signs	I-Task
.	O
	
Our	O
biologically	B-Method
plausible	I-Method
deep	I-Method
artificial	I-Method
neural	I-Method
network	I-Method
architectures	I-Method
can	O
.	O
	
Small	O
(	O
often	O
minimal	O
)	O
receptive	O
fields	O
of	O
convolutional	B-Method
winner	I-Method
-	I-Method
take	I-Method
-	I-Method
all	I-Method
neurons	I-Method
yield	O
large	O
network	O
depth	O
,	O
resulting	O
in	O
roughly	O
as	O
many	O
sparsely	O
connected	O
neural	O
layers	O
as	O
found	O
in	O
mammals	O
between	O
retina	O
and	O
visual	O
cortex	O
.	O
	
Only	O
winner	O
neurons	O
are	O
trained	O
.	O
	
Several	O
deep	B-Method
neural	I-Method
columns	I-Method
become	O
experts	O
on	O
inputs	O
preprocessed	O
in	O
different	O
ways	O
;	O
their	O
predictions	O
are	O
averaged	O
.	O
	
Graphics	O
cards	O
allow	O
for	O
fast	B-Task
training	I-Task
.	O
	
On	O
the	O
very	O
competitive	O
MNIST	B-Material
handwriting	O
benchmark	O
,	O
our	O
method	O
is	O
the	O
first	O
to	O
achieve	O
near	O
-	O
human	O
performance	O
.	O
	
On	O
a	O
traffic	B-Task
sign	I-Task
recognition	I-Task
benchmark	O
it	O
outperforms	O
humans	O
by	O
a	O
factor	O
of	O
two	O
.	O
	
We	O
also	O
improve	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
on	O
a	O
plethora	O
of	O
common	O
image	B-Task
classification	I-Task
benchmarks	I-Task
.	O
	
04	O
-	O
12	O
	
section	O
:	O
Introduction	O
	
Recent	O
publications	O
suggest	O
that	O
unsupervised	B-Method
pre	I-Method
-	I-Method
training	I-Method
of	O
deep	B-Method
,	I-Method
hierarchical	I-Method
neural	I-Method
networks	I-Method
improves	O
supervised	B-Task
pattern	I-Task
classification	I-Task
.	O
	
Here	O
we	O
train	O
such	O
nets	O
by	O
simple	O
online	B-Method
back	I-Method
-	I-Method
propagation	I-Method
,	O
setting	O
new	O
,	O
greatly	O
improved	O
records	O
on	O
MNIST	B-Material
,	O
Latin	B-Material
letters	I-Material
,	O
Chinese	B-Material
characters	I-Material
,	O
traffic	B-Task
signs	I-Task
,	O
NORB	B-Material
(	O
jittered	O
,	O
cluttered	O
)	O
and	O
CIFAR10	B-Material
benchmarks	I-Material
.	O
	
We	O
focus	O
on	O
deep	B-Method
convolutional	I-Method
neural	I-Method
networks	I-Method
(	O
DNN	B-Method
)	O
,	O
introduced	O
by	O
,	O
improved	O
by	O
,	O
refined	O
and	O
simplified	O
by	O
.	O
	
Lately	O
,	O
DNN	B-Method
proved	O
their	O
mettle	O
on	O
data	O
sets	O
ranging	O
from	O
handwritten	O
digits	O
(	O
MNIST	B-Material
)	O
,	O
handwritten	O
characters	O
to	O
3D	O
toys	O
(	O
NORB	B-Material
)	O
and	O
faces	O
.	O
	
DNNs	B-Method
fully	O
unfold	O
their	O
potential	O
when	O
they	O
are	O
big	O
and	O
deep	O
.	O
	
But	O
training	O
them	O
requires	O
weeks	O
,	O
months	O
,	O
even	O
years	O
on	O
CPUs	O
.	O
	
High	O
data	B-Metric
transfer	I-Metric
latency	I-Metric
prevents	O
multi	O
-	O
threading	O
and	O
multi	O
-	O
CPU	O
code	O
from	O
saving	O
the	O
situation	O
.	O
	
In	O
recent	O
years	O
,	O
however	O
,	O
fast	O
parallel	B-Method
neural	I-Method
net	I-Method
code	I-Method
for	O
graphics	B-Method
cards	I-Method
(	O
GPUs	B-Method
)	O
has	O
overcome	O
this	O
problem	O
.	O
	
Carefully	O
designed	O
GPU	B-Method
code	I-Method
for	O
image	B-Task
classification	I-Task
can	O
be	O
up	O
to	O
two	O
orders	O
of	O
magnitude	O
faster	O
than	O
its	O
CPU	B-Method
counterpart	I-Method
.	O
	
Hence	O
,	O
to	O
train	O
huge	O
DNN	B-Method
in	O
hours	O
or	O
days	O
,	O
we	O
implement	O
them	O
on	O
GPU	B-Method
,	O
building	O
upon	O
the	O
work	O
of	O
.	O
	
The	O
training	B-Method
algorithm	I-Method
is	O
fully	O
online	O
,	O
i.e.	O
weight	O
updates	O
occur	O
after	O
each	O
error	B-Method
back	I-Method
-	I-Method
propagation	I-Method
step	I-Method
.	O
	
We	O
will	O
show	O
that	O
properly	O
trained	O
big	B-Method
and	I-Method
deep	I-Method
DNNs	I-Method
can	O
outperform	O
all	O
previous	O
methods	O
,	O
and	O
demonstrate	O
that	O
unsupervised	B-Method
initialization	I-Method
/	O
pretraining	B-Task
is	O
not	O
necessary	O
(	O
although	O
we	O
do	O
n’t	O
deny	O
that	O
it	O
might	O
help	O
sometimes	O
,	O
especially	O
for	O
small	O
datasets	O
)	O
.	O
	
We	O
also	O
show	O
how	O
combining	O
several	O
DNN	B-Method
columns	O
into	O
a	O
Multi	B-Method
-	I-Method
column	I-Method
DNN	I-Method
(	O
MCDNN	B-Method
)	O
further	O
decreases	O
the	O
error	B-Metric
rate	I-Metric
by	O
30	O
-	O
40	O
%	O
.	O
	
section	O
:	O
Architecture	O
	
The	O
initially	O
random	O
weights	O
of	O
the	O
DNN	B-Method
are	O
iteratively	O
trained	O
to	O
minimize	O
the	O
classification	B-Metric
error	I-Metric
on	O
a	O
set	O
of	O
labeled	O
training	O
images	O
;	O
generalization	B-Task
performance	O
is	O
then	O
tested	O
on	O
a	O
separate	O
set	O
of	O
test	O
images	O
.	O
	
Our	O
architecture	O
does	O
this	O
by	O
combining	O
several	O
techniques	O
in	O
a	O
novel	O
way	O
:	O
(	O
1	O
)	O
Unlike	O
the	O
shallow	B-Method
NN	I-Method
used	O
in	O
many	O
1990s	O
applications	O
,	O
ours	O
are	O
deep	O
,	O
inspired	O
by	O
the	O
Neocognitron	B-Method
,	O
with	O
many	O
(	O
6	O
-	O
10	O
)	O
layers	O
of	O
non	O
-	O
linear	O
neurons	O
stacked	O
on	O
top	O
of	O
each	O
other	O
,	O
comparable	O
to	O
the	O
number	O
of	O
layers	O
found	O
between	O
retina	O
and	O
visual	O
cortex	O
of	O
macaque	O
monkeys	O
.	O
	
(	O
2	O
)	O
	
It	O
was	O
shown	O
that	O
such	O
multi	O
-	O
layered	O
DNN	B-Method
are	O
hard	O
to	O
train	O
by	O
standard	O
gradient	B-Method
descent	I-Method
,	O
the	O
method	O
of	O
choice	O
from	O
a	O
mathematical	O
/	O
algorithmic	O
point	O
of	O
view	O
.	O
	
Today	O
’s	O
computers	O
,	O
however	O
,	O
are	O
fast	O
enough	O
for	O
this	O
,	O
more	O
than	O
60000	O
times	O
faster	O
than	O
those	O
of	O
the	O
early	O
90s	O
.	O
	
Carefully	O
designed	O
code	O
for	O
massively	B-Task
parallel	I-Task
graphics	I-Task
processing	I-Task
units	I-Task
(	O
GPUs	B-Method
normally	O
used	O
for	O
video	B-Task
games	I-Task
)	O
allows	O
for	O
gaining	O
an	O
additional	O
speedup	B-Metric
factor	I-Metric
of	O
50	O
-	O
100	O
over	O
serial	B-Method
code	I-Method
for	O
standard	O
computers	O
.	O
	
Given	O
enough	O
labeled	O
data	O
,	O
our	O
networks	O
do	O
not	O
need	O
additional	O
heuristics	O
such	O
as	O
unsupervised	B-Method
pre	I-Method
-	I-Method
training	I-Method
or	O
carefully	O
prewired	O
synapses	O
.	O
	
(	O
3	O
)	O
	
The	O
DNN	B-Method
of	O
this	O
paper	O
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
a	O
)	O
have	O
2	B-Method
-	I-Method
dimensional	I-Method
layers	I-Method
of	I-Method
winner	I-Method
-	I-Method
take	I-Method
-	I-Method
all	I-Method
neurons	I-Method
with	O
overlapping	O
receptive	O
fields	O
whose	O
weights	O
are	O
shared	O
.	O
	
Given	O
some	O
input	O
pattern	O
,	O
a	O
simple	O
max	B-Method
pooling	I-Method
technique	I-Method
determines	O
winning	O
neurons	O
by	O
partitioning	O
layers	O
into	O
quadratic	O
regions	O
of	O
local	O
inhibition	O
,	O
selecting	O
the	O
most	O
active	O
neuron	O
of	O
each	O
region	O
.	O
	
The	O
winners	O
of	O
some	O
layer	O
represent	O
a	O
smaller	O
,	O
down	O
-	O
sampled	O
layer	O
with	O
lower	O
resolution	O
,	O
feeding	O
the	O
next	O
layer	O
in	O
the	O
hierarchy	O
.	O
	
The	O
approach	O
is	O
inspired	O
by	O
Hubel	O
and	O
Wiesel	O
’s	O
seminal	O
work	O
on	O
the	O
cat	O
’s	O
primary	O
visual	O
cortex	O
,	O
which	O
identified	O
orientation	O
-	O
selective	O
simple	O
cells	O
with	O
overlapping	O
local	O
receptive	O
fields	O
and	O
complex	O
cells	O
performing	O
down	B-Method
-	I-Method
sampling	I-Method
-	I-Method
like	I-Method
operations	I-Method
.	O
	
(	O
4	O
)	O
Note	O
that	O
at	O
some	O
point	O
down	O
-	O
sampling	O
automatically	O
leads	O
to	O
the	O
first	O
1	O
-	O
dimensional	O
layer	O
.	O
	
From	O
then	O
on	O
,	O
only	O
trivial	O
1	O
-	O
dimensional	O
winner	O
-	O
take	O
-	O
all	O
regions	O
are	O
possible	O
,	O
that	O
is	O
,	O
the	O
top	O
part	O
of	O
the	O
hierarchy	O
becomes	O
a	O
standard	O
multi	B-Method
-	I-Method
layer	I-Method
perceptron	I-Method
(	O
MLP	B-Method
)	O
.	O
	
Receptive	O
fields	O
and	O
winner	O
-	O
take	O
-	O
all	O
regions	O
of	O
our	O
DNN	B-Method
often	O
are	O
(	O
near	O
-)	O
minimal	O
,	O
e.g.	O
,	O
only	O
2x2	O
or	O
3x3	O
neurons	O
.	O
	
This	O
results	O
in	O
(	O
near	O
-)	O
maximal	O
depth	O
of	O
layers	O
with	O
non	O
-	O
trivial	O
(	O
2	O
-	O
dimensional	O
)	O
winner	O
-	O
take	O
-	O
all	O
regions	O
.	O
	
In	O
fact	O
,	O
insisting	O
on	O
minimal	O
2x2	O
fields	O
automatically	O
defines	O
the	O
entire	O
deep	B-Method
architecture	I-Method
,	O
apart	O
from	O
the	O
number	O
of	O
different	O
convolutional	B-Method
kernels	I-Method
per	O
layer	O
and	O
the	O
depth	O
of	O
the	O
plain	O
MLP	B-Method
on	O
top	O
.	O
	
(	O
5	O
)	O
Only	O
winner	O
neurons	O
are	O
trained	O
,	O
that	O
is	O
,	O
other	O
neurons	O
can	O
not	O
forget	O
what	O
they	O
learnt	O
so	O
far	O
,	O
although	O
they	O
may	O
be	O
affected	O
by	O
weight	O
changes	O
in	O
more	O
peripheral	O
layers	O
.	O
	
The	O
resulting	O
decrease	O
of	O
synaptic	O
changes	O
per	O
time	O
interval	O
corresponds	O
to	O
biologically	O
plausible	O
reduction	O
of	O
energy	B-Metric
consumption	I-Metric
.	O
	
Our	O
training	B-Method
algorithm	I-Method
is	O
fully	O
online	O
,	O
i.e.	O
weight	O
updates	O
occur	O
after	O
each	O
gradient	O
computation	O
step	O
.	O
	
(	O
6	O
)	O
Inspired	O
by	O
microcolumns	O
of	O
neurons	O
in	O
the	O
cerebral	O
cortex	O
,	O
we	O
combine	O
several	O
DNN	B-Method
columns	O
to	O
form	O
a	O
Multi	B-Method
-	I-Method
column	I-Method
DNN	I-Method
(	O
MCDNN	B-Method
)	O
.	O
	
Given	O
some	O
input	O
pattern	O
,	O
the	O
predictions	O
of	O
all	O
columns	O
are	O
democratically	O
averaged	O
.	O
	
Before	O
training	O
,	O
the	O
weights	O
(	O
synapses	O
)	O
of	O
all	O
columns	O
are	O
randomly	O
initialized	O
.	O
	
Various	O
columns	O
can	O
be	O
trained	O
on	O
the	O
same	O
inputs	O
,	O
or	O
on	O
inputs	O
preprocessed	O
in	O
different	O
ways	O
.	O
	
The	O
latter	O
helps	O
to	O
reduce	O
both	O
error	B-Metric
rate	I-Metric
and	O
number	O
of	O
columns	O
required	O
to	O
reach	O
a	O
given	O
accuracy	B-Metric
.	O
	
The	O
MCDNN	B-Method
architecture	I-Method
and	O
its	O
training	O
and	O
testing	O
procedures	O
are	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
Experiments	O
	
In	O
the	O
following	O
we	O
give	O
a	O
detailed	O
description	O
of	O
all	O
the	O
experiments	O
we	O
performed	O
.	O
	
We	O
evaluate	O
our	O
architecture	O
on	O
various	O
commonly	O
used	O
object	B-Task
recognition	I-Task
benchmarks	I-Task
and	O
improve	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
on	O
all	O
of	O
them	O
.	O
	
The	O
description	O
of	O
the	O
DNN	B-Method
architecture	O
used	O
for	O
the	O
various	O
experiments	O
is	O
given	O
in	O
the	O
following	O
way	O
:	O
	
2x48x48	O
-	O
100C5	O
-	O
MP2	O
-	O
100C5	O
-	O
MP2	O
-	O
100C4	O
-	O
MP2	O
-	O
300N	O
-	O
100N	O
-	O
6N	O
represents	O
a	O
net	O
with	O
2	O
input	O
images	O
of	O
size	O
48x48	O
,	O
a	O
convolutional	B-Method
layer	I-Method
with	O
100	O
maps	O
and	O
5x5	O
filters	O
,	O
a	O
max	B-Method
-	I-Method
pooling	I-Method
layer	I-Method
over	O
non	O
overlapping	O
regions	O
of	O
size	O
	
2x2	O
,	O
a	O
convolutional	B-Method
layer	I-Method
with	O
100	O
maps	B-Method
and	O
4x4	B-Method
filters	I-Method
,	O
a	O
max	B-Method
-	I-Method
pooling	I-Method
layer	I-Method
over	O
non	O
overlapping	O
regions	O
of	O
size	O
2x2	O
,	O
a	O
fully	B-Method
connected	I-Method
layer	I-Method
with	O
300	O
hidden	O
units	O
,	O
a	O
fully	B-Method
connected	I-Method
layer	I-Method
with	O
100	O
hidden	O
units	O
and	O
a	O
fully	B-Method
connected	I-Method
output	I-Method
layer	I-Method
with	O
6	O
neurons	O
(	O
one	O
per	O
class	O
)	O
.	O
	
We	O
use	O
a	O
scaled	B-Method
hyperbolic	I-Method
tangent	I-Method
activation	I-Method
function	I-Method
for	O
convolutional	B-Method
and	I-Method
fully	I-Method
connected	I-Method
layers	I-Method
,	O
a	O
linear	B-Method
activation	I-Method
function	I-Method
for	O
max	B-Method
-	I-Method
pooling	I-Method
layers	I-Method
and	O
a	O
softmax	B-Method
activation	I-Method
function	I-Method
for	O
the	O
output	O
layer	O
.	O
	
All	O
DNN	B-Method
are	O
trained	O
using	O
on	B-Method
-	I-Method
line	I-Method
gradient	I-Method
descent	I-Method
with	O
an	O
annealed	B-Method
learning	I-Method
rate	I-Method
.	O
	
During	O
training	O
,	O
images	O
are	O
continually	O
translated	O
,	O
scaled	O
and	O
rotated	O
(	O
even	O
elastically	O
distorted	O
in	O
case	O
of	O
characters	O
)	O
,	O
whereas	O
only	O
the	O
original	O
images	O
are	O
used	O
for	O
validation	B-Task
.	O
	
Training	B-Task
ends	O
once	O
the	O
validation	B-Metric
error	I-Metric
is	O
zero	O
or	O
when	O
the	O
learning	B-Metric
rate	I-Metric
reaches	O
its	O
predetermined	O
minimum	O
.	O
	
Initial	O
weights	O
are	O
drawn	O
from	O
a	O
uniform	O
random	O
distribution	O
in	O
the	O
range	O
.	O
	
subsection	O
:	O
MNIST	B-Material
	
The	O
original	O
MNIST	B-Material
digits	O
are	O
normalized	O
such	O
that	O
the	O
width	O
or	O
height	O
of	O
the	O
bounding	O
box	O
equals	O
20	O
pixels	O
.	O
	
Aspect	O
ratios	O
for	O
various	O
digits	O
vary	O
strongly	O
and	O
we	O
therefore	O
create	O
six	O
additional	O
datasets	O
by	O
normalizing	O
digit	O
width	O
to	O
10	O
,	O
12	O
,	O
14	O
,	O
16	O
,	O
18	O
,	O
20	O
pixels	O
.	O
	
This	O
is	O
like	O
seeing	O
the	O
data	O
from	O
different	O
angles	O
.	O
	
We	O
train	O
five	O
DNN	B-Method
columns	O
per	O
normalization	B-Task
,	O
resulting	O
in	O
a	O
total	O
of	O
35	O
columns	O
for	O
the	O
entire	O
MCDNN	B-Method
.	O
	
All	O
1x29x29	O
-	O
20C4	B-Method
-	I-Method
MP2	I-Method
-	I-Method
40C5	I-Method
-	I-Method
MP3	I-Method
-	I-Method
150N	I-Method
-	I-Method
10N	I-Method
DNN	I-Method
are	O
trained	O
for	O
around	O
800	O
epochs	O
with	O
an	O
annealed	B-Metric
learning	I-Metric
rate	I-Metric
(	O
i.e.	O
initialized	O
with	O
0.001	O
multiplied	O
by	O
a	O
factor	O
of	O
0.993	O
/	O
epoch	O
until	O
it	O
reaches	O
0.00003	O
)	O
.	O
	
Training	O
a	O
DNN	B-Method
takes	O
almost	O
14	O
hours	O
and	O
after	O
500	O
training	O
epochs	O
little	O
additional	O
improvement	O
is	O
observed	O
.	O
	
During	O
training	O
the	O
digits	O
are	O
randomly	O
distorted	O
before	O
each	O
epoch	O
(	O
see	O
Fig	O
.	O
	
[	O
reference	O
]	O
a	O
for	O
representative	O
characters	O
and	O
their	O
distorted	O
versions	O
)	O
.	O
	
The	O
internal	O
state	O
of	O
a	O
single	O
DNN	B-Method
is	O
depicted	O
in	O
Figure	O
[	O
reference	O
]	O
	
c	O
,	O
where	O
a	O
particular	O
digit	O
is	O
forward	O
propagated	O
through	O
a	O
trained	O
network	O
and	O
all	O
activations	O
together	O
with	O
the	O
network	O
weights	O
are	O
plotted	O
.	O
	
Results	O
of	O
all	O
individual	O
nets	O
and	O
various	O
MCDNN	B-Method
are	O
summarized	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
MCDNN	B-Method
of	O
5	O
nets	O
trained	O
with	O
the	O
same	O
preprocessor	O
achieve	O
better	O
results	O
than	O
their	O
constituent	O
DNNs	B-Method
,	O
except	O
for	O
original	O
images	O
(	O
Tab	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
The	O
MCDNN	B-Method
has	O
a	O
very	O
low	O
0.23	O
%	O
error	B-Metric
rate	I-Metric
,	O
improving	O
state	O
of	O
the	O
art	O
by	O
at	O
least	O
34	O
%	O
(	O
Tab	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
This	O
is	O
the	O
first	O
time	O
an	O
artificial	O
method	O
comes	O
close	O
to	O
the	O
0.2	O
%	O
error	B-Metric
rate	I-Metric
of	O
humans	O
on	O
this	O
task	O
.	O
	
Many	O
of	O
the	O
wrongly	O
classified	O
digits	O
either	O
contain	O
broken	O
or	O
strange	O
strokes	O
,	O
or	O
have	O
wrong	O
labels	O
.	O
	
The	O
23	O
errors	O
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
b	O
)	O
are	O
associated	O
with	O
20	O
correct	O
second	O
guesses	O
.	O
	
We	O
also	O
trained	O
a	O
single	O
DNN	B-Method
on	O
all	O
7	O
datasets	O
simultaneously	O
which	O
yielded	O
worse	O
result	O
(	O
0.52	O
%	O
)	O
than	O
both	O
MCDNN	B-Method
and	O
their	O
individual	O
DNN	B-Method
.	O
	
This	O
shows	O
that	O
the	O
improvements	O
come	O
from	O
the	O
MCDNN	B-Method
and	O
not	O
from	O
using	O
more	O
preprocessed	O
data	O
.	O
	
How	O
are	O
the	O
MCDNN	B-Metric
errors	I-Metric
affected	O
by	O
the	O
number	O
of	O
preprocessors	O
?	O
	
We	O
train	O
5	O
DNNs	B-Method
on	O
all	O
7	O
datasets	O
.	O
	
A	O
MCDNN	B-Method
’	O
out	O
-	O
of	O
-	O
7	O
’	O
(	O
from	O
1	O
to	O
7	O
)	O
averages	O
nets	O
trained	O
on	O
datasets	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
that	O
more	O
preprocessing	O
results	O
in	O
lower	O
MCDNN	B-Metric
error	I-Metric
.	O
	
We	O
also	O
train	O
5	O
DNN	B-Method
for	O
each	O
odd	O
normalization	O
,	O
i.e.	O
W11	O
,	O
W13	O
,	O
W15	O
,	O
W17	O
and	O
W19	O
.	O
	
The	O
60	B-Method
-	I-Method
net	I-Method
MCDNN	I-Method
performs	O
(	O
0.24	O
%	O
)	O
similarly	O
to	O
the	O
35	O
-	O
net	O
MCDNN	B-Method
,	O
indicating	O
that	O
additional	O
preprocessing	B-Task
does	O
not	O
further	O
improve	O
recognition	B-Task
.	O
	
We	O
conclude	O
that	O
MCDNN	B-Method
outperform	O
DNN	B-Method
trained	O
on	O
the	O
same	O
data	O
,	O
and	O
that	O
different	O
preprocessors	O
further	O
decrease	O
the	O
error	B-Metric
rate	I-Metric
.	O
	
subsection	O
:	O
NIST	O
SD	O
19	O
	
The	O
35	B-Method
-	I-Method
columns	I-Method
MCDNN	I-Method
architecture	I-Method
and	O
preprocessing	B-Method
used	O
for	O
MNIST	B-Material
are	O
also	O
applied	O
to	O
Latin	B-Material
characters	I-Material
from	O
NIST	B-Material
SD	I-Material
19	I-Material
.	O
	
For	O
all	O
tasks	O
our	O
MCDNN	B-Method
achieves	O
recognition	B-Metric
rates	I-Metric
1.5	O
-	O
5	O
times	O
better	O
than	O
any	O
published	O
result	O
(	O
Tab	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
In	O
total	O
there	O
are	O
82000	O
characters	O
in	O
the	O
test	O
set	O
,	O
but	O
there	O
are	O
many	O
more	O
easy	O
to	O
classify	O
digits	O
(	O
58000	O
)	O
than	O
hard	O
to	O
classify	O
letters	O
(	O
24000	O
)	O
.	O
	
This	O
explains	O
the	O
lower	O
overall	O
error	B-Metric
rate	I-Metric
of	O
the	O
62	B-Task
-	I-Task
class	I-Task
problem	I-Task
compared	O
to	O
the	O
52	B-Task
-	I-Task
class	I-Task
letters	I-Task
problem	I-Task
.	O
	
From	O
all	O
errors	O
of	O
the	O
62	O
-	O
class	O
problem	O
3	O
%	O
of	O
the	O
58000	O
digits	O
are	O
misclassified	O
and	O
33	O
%	O
of	O
the	O
24000	O
letters	O
are	O
misclassified	O
.	O
	
Letters	O
are	O
in	O
general	O
more	O
difficult	O
to	O
classify	O
,	O
but	O
there	O
is	O
also	O
a	O
higher	O
amount	O
of	O
confusion	O
between	O
similar	O
lower	O
-	O
and	O
upper	O
-	O
case	O
letters	O
such	O
as	O
i	O
,	O
I	O
and	O
o	O
,	O
O	O
for	O
example	O
.	O
	
Indeed	O
,	O
error	B-Metric
rates	I-Metric
for	O
the	O
case	B-Task
insensitive	I-Task
task	I-Task
drop	O
from	O
21	O
%	O
to	O
7.37	O
%	O
.	O
	
If	O
the	O
confused	O
upper	O
-	O
and	O
lower	O
-	O
case	O
classes	O
are	O
merged	O
,	O
resulting	O
in	O
37	O
different	O
classes	O
,	O
the	O
error	B-Metric
rate	I-Metric
is	O
only	O
slightly	O
bigger	O
(	O
7.99	O
%	O
)	O
.	O
	
Upper	O
-	O
case	O
letters	O
are	O
far	O
easier	O
to	O
classify	O
(	O
1.83	O
%	O
error	B-Metric
rate	I-Metric
)	O
than	O
lowercase	O
letters	O
(	O
7.47	O
%	O
)	O
due	O
to	O
the	O
smaller	O
writer	O
dependent	O
in	O
-	O
class	O
variability	O
.	O
	
For	O
a	O
detailed	O
analysis	O
of	O
all	O
the	O
errors	O
and	O
confusions	O
between	O
different	O
classes	O
,	O
the	O
confusion	B-Metric
matrix	I-Metric
is	O
most	O
informative	O
(	O
Supplementary	O
material	O
Fig	O
.	O
S1	O
)	O
.	O
	
subsection	O
:	O
Chinese	O
characters	O
	
Compared	O
to	O
Latin	B-Task
character	I-Task
recognition	I-Task
,	O
isolated	B-Task
Chinese	I-Task
character	I-Task
recognition	I-Task
is	O
a	O
much	O
harder	O
problem	O
,	O
mainly	O
because	O
of	O
the	O
much	O
larger	O
category	O
set	O
,	O
but	O
also	O
because	O
of	O
wide	O
variability	O
of	O
writing	O
styles	O
,	O
and	O
the	O
confusion	O
between	O
similar	O
characters	O
.	O
	
We	O
use	O
a	O
dataset	O
from	O
the	O
Institute	O
of	O
Automation	O
of	O
Chinese	O
Academy	O
of	O
Sciences	O
(	O
CASIA	O
)	O
,	O
which	O
contains	O
300	O
samples	O
for	O
each	O
of	O
3755	O
characters	O
(	O
in	O
GB1	O
set	O
)	O
.	O
	
This	O
resulted	O
in	O
a	O
data	O
set	O
with	O
more	O
than	O
1	O
Million	O
characters	O
(	O
3	O
GB	O
of	O
data	O
)	O
which	O
posed	O
a	O
major	O
computational	O
challenge	O
even	O
to	O
our	O
system	O
.	O
	
Without	O
our	O
fast	O
GPU	B-Method
implementation	I-Method
the	O
nets	O
on	O
this	O
task	O
would	O
train	O
for	O
more	O
than	O
one	O
year	O
.	O
	
Only	O
the	O
forward	B-Method
propagation	I-Method
of	O
the	O
training	O
set	O
takes	O
27h	O
on	O
a	O
normal	O
CPU	B-Method
,	O
and	O
training	O
a	O
single	O
epoch	O
would	O
consequently	O
have	O
lasted	O
several	O
days	O
.	O
	
On	O
our	O
fast	O
GPU	B-Method
implementation	I-Method
on	O
the	O
other	O
hand	O
,	O
training	O
a	O
single	O
epoch	O
takes	O
3.4h	O
,	O
which	O
makes	O
it	O
feasible	O
to	O
train	O
a	O
net	O
within	O
a	O
few	O
days	O
instead	O
of	O
many	O
months	O
.	O
	
We	O
train	O
following	O
DNN	B-Method
,	O
1x48x48	O
-	O
100C3	O
-	O
MP2	O
-	O
200C2	O
-	O
MP2	O
-	O
300C2	O
-	O
MP2	O
-	O
400C2	O
-	O
MP2	O
-	O
500N	O
-	O
3755N	O
,	O
on	O
offline	O
as	O
well	O
as	O
on	O
online	O
characters	O
.	O
	
For	O
the	O
offline	B-Task
character	I-Task
recognition	I-Task
task	I-Task
,	O
we	O
resize	O
all	O
characters	O
to	O
40x40	O
pixels	O
and	O
place	O
them	O
in	O
the	O
center	O
of	O
a	O
48x48	O
image	O
.	O
	
The	O
contrast	O
of	O
each	O
image	O
is	O
normalized	O
independently	O
.	O
	
As	O
suggested	O
by	O
the	O
organizers	O
,	O
the	O
first	O
240	O
writers	O
from	O
the	O
database	B-Material
CASIA	I-Material
-	I-Material
HWDB1.1	I-Material
are	O
used	O
for	O
training	O
and	O
the	O
remaining	O
60	O
writers	O
are	O
used	O
for	O
testing	O
.	O
	
The	O
total	O
numbers	O
of	O
training	O
and	O
test	O
characters	O
are	O
938679	O
and	O
234228	O
,	O
respectively	O
.	O
	
For	O
the	O
online	O
dataset	O
,	O
we	O
draw	O
each	O
character	O
from	O
its	O
list	O
of	O
coordinates	O
,	O
resize	O
the	O
resulting	O
images	O
to	O
40x40	O
pixels	O
and	O
place	O
them	O
in	O
the	O
center	O
of	O
a	O
48x48	O
image	O
.	O
	
Additionally	O
,	O
we	O
smooth	O
-	O
out	O
the	O
resulting	O
images	O
with	O
a	O
Gaussian	B-Method
blur	I-Method
filter	I-Method
over	O
a	O
3x3	O
pixel	O
neighborhood	O
and	O
uniform	O
standard	O
deviation	O
of	O
0.75	O
.	O
	
As	O
suggested	O
by	O
the	O
organizers	O
,	O
the	O
characters	O
of	O
240	O
writers	O
from	O
database	B-Material
CASIA	I-Material
-	O
OLHWDB1.1	O
are	O
used	O
for	O
training	O
the	O
classifier	B-Method
and	O
the	O
characters	O
of	O
the	O
remaining	O
60	O
writers	O
are	O
used	O
for	O
testing	O
.	O
	
The	O
resulting	O
numbers	O
of	O
training	O
and	O
test	O
characters	O
are	O
939564	O
and	O
234800	O
,	O
respectively	O
.	O
	
All	O
methods	O
previously	O
applied	O
to	O
this	O
dataset	O
perform	O
some	O
feature	B-Method
extraction	I-Method
followed	O
by	O
a	O
dimensionality	B-Method
reduction	I-Method
,	O
whereas	O
our	O
method	O
directly	O
works	O
on	O
raw	O
pixel	O
intensities	O
and	O
learns	O
the	O
feature	B-Method
extraction	I-Method
and	O
dimensionality	B-Task
reduction	I-Task
in	O
a	O
supervised	B-Method
way	I-Method
.	O
	
On	O
the	O
offline	B-Task
task	I-Task
we	O
obtain	O
an	O
error	B-Metric
rate	I-Metric
of	O
6.5	O
%	O
compared	O
to	O
10.01	O
%	O
of	O
the	O
best	O
method	O
.	O
	
Even	O
though	O
much	O
information	O
is	O
lost	O
when	O
drawing	O
a	O
character	O
from	O
it	O
’s	O
coordinate	O
sequence	O
,	O
we	O
obtain	O
a	O
recognition	B-Metric
rate	I-Metric
of	O
5.61	O
%	O
on	O
the	O
online	B-Task
task	I-Task
compared	O
to	O
7.61	O
%	O
of	O
the	O
best	O
method	O
.	O
	
We	O
conclude	O
that	O
on	O
this	O
very	O
hard	O
classification	B-Task
problem	I-Task
,	O
with	O
many	O
classes	O
(	O
3755	O
)	O
and	O
relatively	O
few	O
samples	O
per	O
class	O
(	O
240	O
)	O
,	O
our	O
fully	O
supervised	O
DNN	B-Method
beats	O
the	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
by	O
a	O
large	O
margin	O
.	O
	
subsection	O
:	O
Traffic	B-Task
signs	I-Task
	
Recognizing	O
traffic	B-Task
signs	I-Task
is	O
essential	O
for	O
the	O
automotive	B-Task
industry	I-Task
	
’s	O
efforts	O
in	O
the	O
field	O
of	O
driver	B-Task
’s	I-Task
assistance	I-Task
,	O
and	O
for	O
many	O
other	O
traffic	B-Task
-	I-Task
related	I-Task
applications	I-Task
.	O
	
We	O
use	O
the	O
GTSRB	B-Material
traffic	I-Material
sign	I-Material
dataset	I-Material
.	O
	
The	O
original	O
color	O
images	O
contain	O
one	O
traffic	O
sign	O
each	O
,	O
with	O
a	O
border	O
of	O
10	O
%	O
around	O
the	O
sign	O
.	O
	
They	O
vary	O
in	O
size	O
from	O
to	O
pixels	O
and	O
are	O
not	O
necessarily	O
square	O
.	O
	
The	O
actual	O
traffic	O
sign	O
is	O
not	O
always	O
centered	O
within	O
the	O
image	O
;	O
its	O
bounding	O
box	O
is	O
part	O
of	O
the	O
annotations	O
.	O
	
The	O
training	O
set	O
consists	O
of	O
26640	O
images	O
;	O
the	O
test	O
set	O
of	O
12569	O
images	O
.	O
	
We	O
crop	O
all	O
images	O
and	O
process	O
only	O
within	O
the	O
bounding	O
box	O
.	O
	
Our	O
DNN	B-Method
implementation	O
requires	O
all	O
training	O
images	O
to	O
be	O
of	O
equal	O
size	O
.	O
	
After	O
visual	O
inspection	O
of	O
the	O
image	O
size	O
distribution	O
we	O
resize	O
all	O
images	O
to	O
pixels	O
.	O
	
As	O
a	O
consequence	O
,	O
scaling	O
factors	O
along	O
both	O
axes	O
are	O
different	O
for	O
traffic	B-Task
signs	I-Task
with	O
rectangular	O
bounding	O
boxes	O
.	O
	
Resizing	O
forces	O
them	O
to	O
have	O
square	O
bounding	O
boxes	O
.	O
	
Our	O
MCDNN	B-Method
is	O
the	O
only	O
artificial	O
method	O
to	O
outperform	O
humans	O
,	O
who	O
produced	O
twice	O
as	O
many	O
errors	O
.	O
	
Since	O
traffic	B-Task
signs	I-Task
greatly	O
vary	O
in	O
illumination	O
and	O
contrast	O
,	O
standard	O
image	B-Method
preprocessing	I-Method
methods	I-Method
are	O
used	O
to	O
enhance	O
/	O
normalize	O
them	O
	
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
a	O
and	O
supplementary	O
material	O
)	O
.	O
	
For	O
each	O
dataset	O
five	O
DNN	B-Method
are	O
trained	O
(	O
architecture	O
:	O
3x48x48	O
-	O
100C7	O
-	O
MP2	O
-	O
150C4	O
-	O
150MP2	O
-	O
250C4	O
-	O
250MP2	O
-	O
300N	O
-	O
43N	O
)	O
,	O
resulting	O
in	O
a	O
MCDNN	B-Method
with	O
25	O
columns	O
,	O
achieving	O
an	O
error	B-Metric
rate	I-Metric
of	O
0.54	O
%	O
on	O
the	O
test	O
set	O
.	O
	
Figure	O
[	O
reference	O
]	O
	
b	O
depicts	O
all	O
errors	O
,	O
plus	O
ground	O
truth	O
and	O
first	O
and	O
second	O
predictions	O
.	O
	
Over	O
80	O
%	O
of	O
the	O
68	O
errors	O
are	O
associated	O
with	O
correct	O
second	O
predictions	O
.	O
	
Erroneously	O
predicted	O
class	O
probabilities	O
tend	O
to	O
be	O
very	O
low	O
—	O
here	O
the	O
MCDNN	B-Method
is	O
quite	O
unsure	O
about	O
its	O
classifications	O
.	O
	
In	O
general	O
,	O
however	O
,	O
it	O
is	O
very	O
confident	O
—	O
most	O
of	O
its	O
predicted	O
class	O
probabilities	O
are	O
close	O
to	O
one	O
or	O
zero	O
.	O
	
Rejecting	O
only	O
1	O
%	O
percent	O
of	O
all	O
images	O
(	O
confidence	O
below	O
0.51	O
)	O
results	O
in	O
an	O
even	O
lower	O
error	B-Metric
rate	I-Metric
of	O
0.24	O
%	O
.	O
	
To	O
reach	O
an	O
error	B-Metric
rate	I-Metric
of	O
0.01	O
%	O
(	O
a	O
single	O
misclassification	O
)	O
,	O
only	O
6.67	O
%	O
of	O
the	O
images	O
have	O
to	O
be	O
rejected	O
(	O
confidence	O
below	O
0.94	O
)	O
.	O
	
Our	O
method	O
outperforms	O
the	O
second	O
best	O
algorithm	O
by	O
a	O
factor	O
of	O
3	O
.	O
	
It	O
takes	O
37	O
hours	O
to	O
train	O
the	O
MCDNN	B-Method
with	O
25	O
columns	O
on	O
four	O
GPUs	O
.	O
	
The	O
trained	O
MCDNN	B-Method
can	O
check	O
87	O
images	O
per	O
second	O
on	O
one	O
GPU	O
(	O
and	O
2175	O
images	O
/	O
s	O
/	O
DNN	B-Method
)	O
.	O
	
subsection	O
:	O
CIFAR	B-Material
10	I-Material
	
CIFAR10	B-Material
is	O
a	O
set	O
of	O
natural	O
color	O
images	O
of	O
32x32	O
pixels	O
.	O
	
It	O
contains	O
10	O
classes	O
,	O
each	O
with	O
5000	O
training	O
samples	O
and	O
1000	O
test	O
samples	O
.	O
	
Images	O
vary	O
greatly	O
within	O
each	O
class	O
.	O
	
They	O
are	O
not	O
necessarily	O
centered	O
,	O
may	O
contain	O
only	O
parts	O
of	O
the	O
object	O
,	O
and	O
show	O
different	O
backgrounds	O
.	O
	
Subjects	O
may	O
vary	O
in	O
size	O
by	O
an	O
order	O
of	O
magnitude	O
(	O
i.e.	O
,	O
some	O
images	O
show	O
only	O
the	O
head	O
of	O
a	O
bird	O
,	O
others	O
an	O
entire	O
bird	O
from	O
a	O
distance	O
)	O
.	O
	
Colors	O
and	O
textures	O
of	O
objects	O
/	O
animals	O
also	O
vary	O
greatly	O
.	O
	
Our	O
DNN	B-Method
input	O
layers	O
have	O
three	O
maps	O
,	O
one	O
for	O
each	O
color	O
channel	O
(	O
RGB	O
)	O
.	O
	
We	O
use	O
a	O
10	B-Method
-	I-Method
layer	I-Method
architecture	I-Method
with	O
very	O
small	O
kernels	O
:	O
3x32x32	O
-	O
300C3	O
-	O
MP2	O
-	O
	
300C2	O
-	O
MP2	O
-	O
300C3	O
-	O
MP2	O
-	O
300C2	O
-	O
MP2	O
-	O
300N	O
-	O
100N	O
-	O
10N.	O
	
Just	O
like	O
for	O
MNIST	B-Material
,	O
the	O
initial	O
learning	B-Metric
rate	I-Metric
0.001	O
decays	O
by	O
a	O
factor	O
of	O
0.993	O
after	O
every	O
epoch	O
.	O
	
Transforming	O
CIFAR	B-Material
color	I-Material
images	I-Material
to	O
gray	O
scale	O
reduces	O
input	O
layer	O
complexity	O
but	O
increases	O
error	B-Metric
rates	I-Metric
.	O
	
Hence	O
we	O
stick	O
to	O
the	O
original	O
color	O
images	O
.	O
	
As	O
for	O
MNIST	B-Material
,	O
augmenting	O
the	O
training	O
set	O
with	O
randomly	O
(	O
by	O
at	O
most	O
5	O
%	O
)	O
translated	O
images	O
greatly	O
decreases	O
the	O
error	B-Metric
from	O
28	O
%	O
to	O
20	O
%	O
(	O
the	O
NN	B-Method
-	O
inherent	O
local	O
translation	O
invariance	O
by	O
itself	O
is	O
not	O
sufficient	O
)	O
.	O
	
By	O
additional	O
scaling	O
(	O
up	O
to	O
15	O
%	O
)	O
,	O
rotation	O
(	O
up	O
to	O
)	O
,	O
and	O
up	O
to	O
15	O
%	O
translation	O
,	O
the	O
individual	O
net	B-Metric
errors	I-Metric
decrease	O
by	O
another	O
3	O
%	O
(	O
Tab	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
The	O
above	O
small	O
maximal	O
bounds	O
prevent	O
loss	O
of	O
too	O
much	O
information	O
leaked	O
beyond	O
the	O
pixels	O
rectangle	O
.	O
	
We	O
repeat	O
the	O
experiment	O
with	O
different	O
random	B-Method
initializations	I-Method
and	O
compute	O
mean	B-Metric
and	I-Metric
standard	I-Metric
deviation	I-Metric
of	I-Metric
the	I-Metric
error	I-Metric
,	O
which	O
is	O
rather	O
small	O
for	O
original	O
images	O
,	O
showing	O
that	O
our	O
DNN	B-Method
are	O
robust	O
.	O
	
Our	O
MCDNN	B-Method
obtains	O
a	O
very	O
low	O
error	B-Metric
rate	I-Metric
of	O
11.21	O
%	O
,	O
greatly	O
rising	O
the	O
bar	O
for	O
this	O
benchmark	O
.	O
	
The	O
confusion	B-Metric
matrix	I-Metric
(	O
Figure	O
[	O
reference	O
]	O
)	O
shows	O
that	O
the	O
MCDNN	B-Method
almost	O
perfectly	O
separates	O
animals	O
from	O
artifacts	O
,	O
except	O
for	O
planes	O
and	O
birds	O
,	O
which	O
seems	O
natural	O
,	O
although	O
humans	O
easily	O
distinguish	O
almost	O
all	O
the	O
incorrectly	O
classified	O
images	O
,	O
even	O
if	O
many	O
are	O
cluttered	O
or	O
contain	O
only	O
parts	O
of	O
the	O
objects	O
/	O
animals	O
(	O
see	O
false	O
positive	O
and	O
false	O
negative	O
images	O
in	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
There	O
are	O
many	O
confusions	O
between	O
different	O
animals	O
;	O
the	O
frog	O
class	O
collects	O
most	O
false	O
positives	O
from	O
other	O
animal	O
classes	O
,	O
with	O
very	O
few	O
false	O
negatives	O
.	O
	
As	O
expected	O
,	O
cats	O
are	O
hard	O
to	O
tell	O
from	O
dogs	O
,	O
collectively	O
causing	O
15.25	O
%	O
of	O
the	O
errors	O
.	O
	
The	O
MCDNN	B-Method
with	O
8	O
columns	O
(	O
four	O
trained	O
on	O
original	O
data	O
and	O
one	O
trained	O
for	O
each	O
preprocessing	O
used	O
also	O
for	O
traffic	B-Task
signs	I-Task
)	O
reaches	O
a	O
low	O
11.21	O
%	O
error	B-Metric
rate	I-Metric
,	O
far	O
better	O
than	O
any	O
other	O
algorithm	O
.	O
	
subsection	O
:	O
NORB	B-Material
	
We	O
test	O
a	O
MCDNN	B-Method
with	O
four	O
columns	O
on	O
NORB	B-Material
(	O
jittered	O
-	O
cluttered	O
)	O
,	O
a	O
collection	O
of	O
stereo	O
images	O
of	O
3D	O
models	O
(	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
The	O
objects	O
are	O
centrally	O
placed	O
on	O
randomly	O
chosen	O
backgrounds	O
,	O
and	O
there	O
is	O
also	O
cluttering	O
from	O
a	O
peripherally	O
placed	O
second	O
object	O
.	O
	
This	O
database	O
is	O
designed	O
for	O
experimenting	O
with	O
3D	B-Task
object	I-Task
recognition	I-Task
from	O
shape	O
.	O
	
It	O
contains	O
images	O
of	O
50	O
toys	O
belonging	O
to	O
5	O
generic	O
categories	O
:	O
four	O
-	O
legged	O
animals	O
,	O
human	O
figures	O
,	O
airplanes	O
,	O
trucks	O
,	O
and	O
cars	O
.	O
	
The	O
objects	O
were	O
imaged	O
by	O
two	O
cameras	O
under	O
6	O
lighting	O
conditions	O
,	O
9	O
elevations	O
(	O
30	O
to	O
70	O
degrees	O
every	O
5	O
degrees	O
)	O
,	O
and	O
18	O
azimuths	O
(	O
0	O
to	O
340	O
every	O
20	O
degrees	O
)	O
.	O
	
The	O
training	O
set	O
has	O
10	O
folds	O
of	O
29160	O
images	O
each	O
for	O
a	O
total	O
of	O
291600	O
images	O
;	O
the	O
testing	O
set	O
consists	O
of	O
two	O
folds	O
totalizing	O
58320	O
images	O
.	O
	
No	O
preprocessing	B-Method
is	O
used	O
for	O
this	O
dataset	O
.	O
	
We	O
scale	O
down	O
images	O
from	O
the	O
original	O
108x108	O
to	O
48x48	O
pixels	O
.	O
	
This	O
size	O
is	O
big	O
enough	O
to	O
preserve	O
the	O
details	O
present	O
in	O
images	O
and	O
small	O
enough	O
to	O
allow	O
fast	O
training	O
.	O
	
We	O
perform	O
two	O
rounds	O
of	O
experiments	O
,	O
using	O
only	O
the	O
first	O
two	O
folds	O
(	O
to	O
compare	O
with	O
previous	O
results	O
that	O
do	O
not	O
use	O
the	O
entire	O
training	O
data	O
)	O
and	O
using	O
all	O
training	O
data	O
.	O
	
We	O
tested	O
several	O
distortion	O
parameters	O
with	O
small	O
nets	O
and	O
found	O
that	O
maximum	O
rotation	O
of	O
,	O
maximum	O
translation	O
of	O
15	O
%	O
and	O
maximum	O
scaling	O
of	O
15	O
%	O
are	O
good	O
choices	O
,	O
hence	O
we	O
use	O
them	O
for	O
all	O
NORB	B-Material
experiments	O
.	O
	
To	O
compare	O
to	O
previous	O
results	O
,	O
we	O
first	O
train	O
only	O
on	O
the	O
first	O
2	O
-	O
folds	O
of	O
the	O
data	O
.	O
	
The	O
net	B-Method
architecture	I-Method
is	O
deep	O
,	O
but	O
has	O
few	O
maps	O
per	O
layer	O
:	O
2x48x48	O
-	O
50C5	O
-	O
MP2	O
-	O
50C5	O
-	O
MP2	O
-	O
50C4	O
-	O
MP2	O
-	O
300N	O
-	O
100N	O
-	O
6N.	O
	
The	O
learning	B-Metric
rate	I-Metric
setup	I-Metric
is	O
:	O
eta	O
start	O
0.001	O
;	O
eta	O
factor	O
0.95	O
;	O
eta	O
stop	O
0.000003	O
.	O
	
Due	O
to	O
small	O
net	B-Metric
size	I-Metric
,	O
training	B-Task
is	O
fast	O
at	O
156s	O
/	O
epoch	O
for	O
114	O
epochs	O
.	O
	
Testing	O
one	O
sample	O
requires	O
0.5ms	O
.	O
	
Even	O
when	O
we	O
use	O
less	O
data	O
to	O
train	O
,	O
the	O
MCDNN	B-Method
greatly	O
improves	O
the	O
state	O
of	O
the	O
art	O
from	O
5	O
%	O
to	O
3.57	O
%	O
(	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
Our	O
method	O
is	O
fast	O
enough	O
to	O
process	O
the	O
entire	O
training	O
set	O
though	O
.	O
	
We	O
use	O
the	O
same	O
architecture	O
but	O
double	O
the	O
number	O
of	O
maps	O
when	O
training	O
with	O
all	O
10	O
folds	O
:	O
2x48x48	O
-	O
100C5	O
-	O
MP2	O
-	O
100C5	O
-	O
MP2	O
-	O
100C4	O
-	O
MP2	O
-	O
300N	O
-	O
100N	O
-	O
6N.	O
	
The	O
learning	B-Metric
rate	I-Metric
setup	I-Metric
remains	O
the	O
same	O
.	O
	
Training	B-Metric
time	I-Metric
increases	O
to	O
34min	O
/	O
epoch	O
because	O
the	O
net	O
is	O
bigger	O
,	O
and	O
we	O
use	O
five	O
times	O
more	O
data	O
.	O
	
Testing	O
one	O
sample	O
takes	O
1.3ms	O
.	O
	
All	O
of	O
this	O
pays	O
off	O
,	O
resulting	O
in	O
a	O
very	O
low	O
2.70	O
%	O
error	B-Metric
rate	I-Metric
,	O
further	O
improving	O
the	O
state	O
of	O
the	O
art	O
.	O
	
Although	O
NORB	B-Material
has	O
only	O
six	O
classes	O
,	O
training	O
and	O
test	O
instances	O
sometimes	O
differ	O
greatly	O
,	O
making	O
classification	B-Task
hard	O
.	O
	
More	O
than	O
50	O
%	O
of	O
the	O
errors	O
are	O
due	O
to	O
confusions	O
between	O
cars	O
and	O
trucks	O
.	O
	
Considering	O
second	O
predictions	O
,	O
too	O
,	O
the	O
error	B-Metric
rate	I-Metric
drops	O
from	O
2.70	O
%	O
to	O
0.42	O
%	O
,	O
showing	O
that	O
84	O
%	O
of	O
the	O
errors	O
are	O
associated	O
with	O
a	O
correct	O
second	O
prediction	O
.	O
	
section	O
:	O
Conclusion	O
	
This	O
is	O
the	O
first	O
time	O
human	O
-	O
competitive	O
results	O
are	O
reported	O
on	O
widely	O
used	O
computer	O
vision	O
benchmarks	O
.	O
	
On	O
many	O
other	O
image	O
classification	O
datasets	O
our	O
MCDNN	B-Method
improves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
by	O
30	O
-	O
80	O
%	O
(	O
Tab	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
We	O
drastically	O
improve	O
recognition	B-Metric
rates	I-Metric
on	O
MNIST	B-Material
,	O
NIST	B-Material
SD	I-Material
19	I-Material
,	O
Chinese	B-Material
characters	I-Material
,	O
traffic	B-Task
signs	I-Task
,	O
CIFAR10	B-Material
and	O
NORB	B-Material
.	O
	
Our	O
method	O
is	O
fully	O
supervised	B-Method
and	O
does	O
not	O
use	O
any	O
additional	O
unlabeled	O
data	O
source	O
.	O
	
Single	O
DNN	B-Method
already	O
are	O
sufficient	O
to	O
obtain	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
;	O
combining	O
them	O
into	O
MCDNNs	B-Method
yields	O
further	O
dramatic	O
performance	O
boosts	O
.	O
	
section	O
:	O
Acknowledgment	O
	
This	O
work	O
was	O
partially	O
supported	O
by	O
a	O
FP7	O
-	O
ICT	O
-	O
2009	O
-	O
6	O
EU	O
Grant	O
under	O
Project	O
Code	O
270247	O
:	O
	
A	O
Neuro	B-Method
-	I-Method
dynamic	I-Method
Framework	I-Method
for	O
Cognitive	B-Task
Robotics	I-Task
:	O
Scene	B-Task
Representations	I-Task
,	O
Behavioral	B-Task
Sequences	I-Task
,	O
and	O
Learning	B-Task
.	O
	
bibliography	O
:	O
References	O
	
section	O
:	O
Supplementary	O
Material	O
	
subsection	O
:	O
Experiment	O
details	O
	
subsubsection	O
:	O
NIST	O
SD	O
19	O
	
The	O
confusion	B-Metric
matrix	I-Metric
of	O
the	O
62	B-Task
characters	I-Task
task	I-Task
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
shows	O
that	O
most	O
of	O
the	O
errors	O
are	O
due	O
to	O
confusions	O
between	O
digits	O
and	O
letters	O
and	O
between	O
lower	O
-	O
and	O
upper	O
-	O
case	O
letters	O
.	O
	
Not	O
very	O
surprisingly	O
,	O
the	O
confusion	B-Metric
matrix	I-Metric
for	O
the	O
digit	B-Task
task	I-Task
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
shows	O
that	O
confusions	O
between	O
fours	O
and	O
nines	O
are	O
the	O
most	O
common	O
error	O
source	O
.	O
	
For	O
the	O
52	B-Task
letter	I-Task
task	I-Task
(	O
case	O
sensitive	O
)	O
the	O
confusion	O
matrix	O
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
shows	O
that	O
the	O
MCDNN	B-Method
has	O
mainly	O
problems	O
with	O
upper	O
-	O
and	O
lower	O
-	O
case	O
confusions	O
of	O
the	O
same	O
letter	O
.	O
	
Other	O
hard	O
-	O
to	O
-	O
distinguish	O
classes	O
are	O
:	O
’	O
q	O
’	O
and	O
’	O
g	O
’	O
,	O
’	O
l	O
’	O
and	O
’	O
i	O
’	O
.	O
	
For	O
the	O
upper	B-Task
-	I-Task
case	I-Task
letter	I-Task
task	I-Task
the	O
confusion	O
matrix	O
(	O
Figure	O
[	O
reference	O
]	O
)	O
shows	O
that	O
the	O
MCDNN	B-Method
has	O
problems	O
with	O
letters	O
of	O
similar	O
shape	O
,	O
i.e.	O
’	O
D	O
’	O
,	O
and	O
’	O
O	O
’	O
,	O
’	O
V	O
’	O
and	O
’	O
U	O
’	O
etc	O
.	O
	
The	O
total	O
error	O
of	O
1.82	O
%	O
is	O
very	O
low	O
though	O
.	O
	
For	O
the	O
lower	B-Task
-	I-Task
case	I-Task
letter	I-Task
task	I-Task
the	O
confusion	O
matrix	O
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
shows	O
that	O
like	O
with	O
upper	O
-	O
case	O
letters	O
,	O
the	O
MCDNN	B-Method
has	O
problems	O
with	O
letters	O
of	O
similar	O
shapes	O
,	O
i.e.	O
’	O
g	O
’	O
,	O
and	O
’	O
q	O
’	O
,	O
’	O
v	O
’	O
and	O
’	O
u	O
’	O
etc	O
.	O
	
But	O
the	O
total	O
error	O
is	O
much	O
higher	O
(	O
7.47	O
%	O
)	O
than	O
for	O
the	O
upper	B-Task
-	I-Task
case	I-Task
letters	I-Task
task	I-Task
.	O
	
For	O
the	O
merged	B-Task
-	I-Task
case	I-Task
letter	I-Task
task	I-Task
(	O
37	O
classes	O
)	O
the	O
confusion	B-Metric
matrix	I-Metric
(	O
Figure	O
[	O
reference	O
]	O
)	O
shows	O
that	O
the	O
MCDNN	B-Method
has	O
mostly	O
problems	O
with	O
letters	O
of	O
similar	O
shapes	O
,	O
i.e.	O
’	O
l	O
’	O
,	O
and	O
’	O
i	O
’	O
.	O
	
All	O
upper	O
-	O
lower	O
-	O
case	O
confusions	O
of	O
identical	O
letters	O
from	O
the	O
52	O
class	O
task	O
vanish	O
,	O
the	O
error	O
shrinks	O
by	O
a	O
factor	O
of	O
almost	O
three	O
down	O
to	O
7.99	O
%	O
.	O
	
The	O
experiments	O
on	O
different	O
subsets	O
of	O
the	O
62	O
character	O
task	O
clearly	O
show	O
that	O
it	O
is	O
very	O
hard	O
to	O
distinguish	O
between	O
small	O
and	O
capital	O
letters	O
.	O
	
Also	O
,	O
digits	O
0	O
and	O
1	O
are	O
hard	O
to	O
separate	O
from	O
letters	O
O	O
and	O
I.	O
Many	O
of	O
these	O
problems	O
could	O
be	O
alleviated	O
by	O
incorporating	O
context	O
where	O
possible	O
.	O
	
subsubsection	O
:	O
Traffic	O
signs	O
	
High	O
contrast	O
variation	O
among	O
the	O
images	O
calls	O
for	O
normalization	B-Task
.	O
	
We	O
test	O
the	O
following	O
standard	O
contrast	B-Method
normalizations	I-Method
:	O
	
Image	B-Task
Adjustment	I-Task
(	O
Imadjust	B-Method
)	O
increases	O
image	O
contrast	O
by	O
mapping	O
pixel	O
intensities	O
to	O
new	O
values	O
such	O
that	O
1	O
%	O
of	O
the	O
data	O
is	O
saturated	O
at	O
low	O
and	O
high	O
intensities	O
.	O
	
Histogram	B-Method
Equalization	I-Method
(	O
Histeq	B-Method
)	O
enhances	O
contrast	O
by	O
transforming	O
pixel	O
intensities	O
such	O
that	O
the	O
output	O
image	O
histogram	O
is	O
roughly	O
uniform	O
.	O
	
Adaptive	B-Method
Histogram	I-Method
Equalization	I-Method
(	O
Adapthisteq	B-Method
)	O
operates	O
(	O
unlike	O
Histeq	B-Method
)	O
on	O
tiles	O
rather	O
than	O
the	O
entire	O
image	O
,	O
we	O
tiled	O
the	O
image	O
in	O
8	O
nonoverlapping	O
regions	O
of	O
6x6	O
pixels	O
.	O
	
Each	O
tile	O
’s	O
contrast	O
is	O
enhanced	O
such	O
that	O
its	O
histogram	O
becomes	O
roughly	O
uniform	O
.	O
	
Contrast	B-Method
Normalization	I-Method
(	O
Conorm	B-Method
)	O
enhances	O
edges	O
,	O
filtering	O
the	O
input	O
image	O
by	O
a	O
difference	O
of	O
Gaussians	B-Method
,	O
using	O
a	O
filter	O
size	O
of	O
5x5	O
pixels	O
.	O
	
Note	O
that	O
the	O
above	O
normalizations	B-Method
,	O
except	O
Conorm	O
,	O
are	O
performed	O
in	O
a	O
color	O
space	O
with	O
image	O
intensity	O
as	O
one	O
of	O
its	O
components	O
.	O
	
For	O
this	O
purpose	O
we	O
transform	O
the	O
image	O
from	O
RGB	O
-	O
to	O
Lab	O
-	O
space	O
,	O
then	O
perform	O
normalization	B-Method
,	O
then	O
transform	O
the	O
result	O
back	O
to	O
RGB	O
-	O
space	O
.	O
	
The	O
effect	O
of	O
the	O
four	O
different	O
normalizations	B-Method
is	O
summarized	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
where	O
histograms	O
of	O
pixel	O
intensities	O
together	O
with	O
original	O
and	O
normalized	O
images	O
are	O
shown	O
.	O
	
The	O
DNN	B-Method
have	O
three	O
maps	O
for	O
the	O
input	O
layer	O
,	O
one	O
for	O
each	O
color	O
channel	O
(	O
RGB	O
)	O
.	O
	
The	O
rest	O
of	O
the	O
net	B-Method
architecture	I-Method
is	O
detailed	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
We	O
use	O
a	O
10	B-Method
-	I-Method
layer	I-Method
architecture	I-Method
with	O
very	O
small	O
max	B-Method
-	I-Method
pooling	I-Method
kernels	I-Method
.	O
	
subsubsection	O
:	O
CIFAR10	B-Material
	
subsubsection	O
:	O
NORB	B-Material
	
We	O
introduce	O
a	O
simple	O
recurrent	B-Method
variational	I-Method
auto	I-Method
-	I-Method
encoder	I-Method
architecture	I-Method
that	O
significantly	O
improves	O
image	B-Task
modeling	I-Task
.	O
	
The	O
system	O
represents	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
in	O
latent	B-Method
variable	I-Method
models	I-Method
for	O
both	O
the	O
ImageNet	B-Method
and	O
Omniglot	B-Method
datasets	I-Method
.	O
	
We	O
show	O
that	O
it	O
naturally	O
separates	O
global	O
conceptual	O
information	O
from	O
lower	O
level	O
details	O
,	O
thus	O
addressing	O
one	O
of	O
the	O
fundamentally	O
desired	O
properties	O
of	O
unsupervised	B-Method
learning	I-Method
.	O
	
Furthermore	O
,	O
the	O
possibility	O
of	O
restricting	O
ourselves	O
to	O
storing	O
only	O
global	O
information	O
about	O
an	O
image	O
allows	O
us	O
to	O
achieve	O
high	O
quality	O
‘	O
conceptual	B-Metric
compression	I-Metric
’	O
.	O
	
ConceptualCompression	B-Method
	
section	O
:	O
Introduction	O
	
Images	O
contain	O
a	O
large	O
amount	O
of	O
information	O
that	O
is	O
a	O
priori	O
stored	O
independently	O
in	O
the	O
pixels	O
.	O
	
In	O
the	O
semi	B-Task
-	I-Task
supervised	I-Task
learning	I-Task
regime	I-Task
where	O
a	O
large	O
number	O
of	O
images	O
is	O
available	O
but	O
only	O
a	O
small	O
number	O
of	O
labels	O
,	O
one	O
would	O
like	O
to	O
leverage	O
this	O
information	O
to	O
create	O
representations	O
that	O
allow	O
for	O
better	O
(	O
and	O
especially	O
faster	O
)	O
generalization	B-Task
.	O
	
Intuitively	O
one	O
expects	O
such	O
representations	O
to	O
explicitly	O
extract	O
global	O
conceptual	O
aspects	O
of	O
an	O
image	O
.	O
	
In	O
this	O
paper	O
we	O
propose	O
a	O
method	O
that	O
is	O
able	O
to	O
transform	O
an	O
image	O
into	O
a	O
progression	O
of	O
increasingly	O
detailed	O
representations	O
,	O
ranging	O
from	O
global	O
conceptual	O
aspects	O
to	O
low	O
level	O
details	O
(	O
see	O
Figures	O
[	O
reference	O
]	O
&	O
[	O
reference	O
]	O
)	O
.	O
	
At	O
the	O
same	O
time	O
,	O
our	O
model	O
greatly	O
improves	O
latent	B-Task
variable	I-Task
image	I-Task
modeling	I-Task
compared	O
to	O
earlier	O
implementations	O
of	O
deep	B-Method
variational	I-Method
auto	I-Method
-	I-Method
encoders	I-Method
.	O
	
Furthermore	O
,	O
it	O
has	O
the	O
advantage	O
of	O
being	O
a	O
simple	O
homogeneous	B-Method
architecture	I-Method
not	O
requiring	O
complex	O
design	O
choices	O
,	O
which	O
is	O
similar	O
to	O
the	O
recurrent	B-Method
structure	I-Method
of	I-Method
DRAW	I-Method
(	I-Method
)	O
.	O
	
Last	O
,	O
it	O
provides	O
an	O
important	O
insight	O
into	O
building	O
good	O
variational	B-Method
auto	I-Method
-	I-Method
encoder	I-Method
models	I-Method
of	I-Method
images	I-Method
:	O
the	O
use	O
of	O
multiple	O
layers	O
of	O
stochastic	O
variables	O
that	O
are	O
all	O
‘	O
close	O
’	O
to	O
the	O
pixels	O
significantly	O
improves	O
performance	O
.	O
	
The	O
system	O
’s	O
ability	O
to	O
stratify	O
information	O
enables	O
it	O
to	O
perform	O
high	O
quality	O
lossy	B-Task
compression	I-Task
,	O
by	O
storing	O
only	O
a	O
subset	O
of	O
latent	O
variables	O
,	O
starting	O
with	O
the	O
high	O
level	O
ones	O
,	O
and	O
generating	O
the	O
remainder	O
during	O
decompression	B-Task
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
Currently	O
the	O
ultimate	O
arbiter	O
of	O
lossy	B-Task
compression	I-Task
remains	O
human	B-Task
evaluation	I-Task
.	O
	
Other	O
simple	O
measures	O
such	O
as	O
the	O
L2	O
distance	O
between	O
compressed	O
and	O
original	O
images	O
are	O
inappropriate	O
–	O
for	O
example	O
if	O
a	O
particular	O
generated	O
grass	O
texture	O
is	O
sharp	O
,	O
but	O
different	O
from	O
the	O
one	O
in	O
the	O
original	O
image	O
,	O
it	O
will	O
yield	O
a	O
large	O
L2	B-Metric
distance	I-Metric
yet	O
should	O
,	O
at	O
the	O
same	O
time	O
,	O
be	O
considered	O
conceptually	O
close	O
to	O
the	O
original	O
.	O
	
Achieving	O
good	O
lossy	B-Metric
compression	I-Metric
while	O
storing	O
only	O
high	O
level	O
latent	O
variables	O
would	O
imply	O
that	O
representations	O
learned	O
at	O
a	O
high	O
level	O
contain	O
information	O
similar	O
to	O
that	O
used	O
by	O
humans	O
to	O
judge	O
images	O
.	O
	
As	O
humans	O
outperform	O
the	O
best	O
machines	O
at	O
learning	O
abstract	B-Method
representations	I-Method
,	O
human	B-Metric
evaluation	I-Metric
of	O
lossy	B-Metric
compression	I-Metric
obtained	O
by	O
these	O
generative	B-Method
models	I-Method
constitutes	O
a	O
reasonable	O
test	O
of	O
the	O
quality	O
of	O
representations	O
learned	O
by	O
these	O
models	O
.	O
	
In	O
the	O
following	O
we	O
discuss	O
variational	B-Method
auto	I-Method
-	I-Method
encoders	I-Method
and	O
compression	B-Task
in	O
more	O
detail	O
,	O
present	O
the	O
algorithm	O
and	O
demonstrate	O
the	O
results	O
on	O
generation	B-Task
quality	O
and	O
compression	B-Task
.	O
	
subsection	O
:	O
Variational	B-Method
Auto	I-Method
-	I-Method
Encoders	I-Method
	
Numerous	O
techniques	O
exist	O
for	O
unsupervised	B-Task
learning	I-Task
in	I-Task
deep	I-Task
networks	I-Task
,	O
e.g.	O
sparse	B-Method
auto	I-Method
-	I-Method
encoders	I-Method
and	O
sparse	B-Method
coding	I-Method
,	O
denoising	B-Method
auto	I-Method
-	I-Method
encoders	I-Method
,	O
deconvolutional	B-Method
networks	I-Method
,	O
restricted	B-Method
Boltzmann	I-Method
machines	I-Method
,	O
deep	B-Method
Boltzmann	I-Method
machines	I-Method
,	O
generative	B-Method
adversarial	I-Method
networks	I-Method
and	O
variational	B-Method
auto	I-Method
-	I-Method
encoders	I-Method
.	O
	
In	O
this	O
paper	O
we	O
focus	O
on	O
the	O
class	O
of	O
models	O
in	O
the	O
variational	B-Method
auto	I-Method
-	I-Method
encoding	I-Method
framework	I-Method
.	O
	
Since	O
we	O
are	O
also	O
interested	O
in	O
compression	B-Task
,	O
we	O
present	O
them	O
from	O
an	O
information	B-Method
-	I-Method
theoretic	I-Method
perspective	I-Method
.	O
	
Variational	B-Method
auto	I-Method
-	I-Method
encoders	I-Method
typically	O
consist	O
of	O
two	O
neural	B-Method
networks	I-Method
:	O
one	O
that	O
generates	O
samples	O
from	O
latent	O
variables	O
(	O
‘	O
imagination	O
’	O
)	O
,	O
and	O
one	O
that	O
infers	O
latent	O
variables	O
from	O
observations	O
(	O
‘	O
recognition	B-Task
’	O
)	O
.	O
	
The	O
two	O
networks	O
share	O
the	O
latent	O
variables	O
.	O
	
Intuitively	O
speaking	O
one	O
might	O
think	O
of	O
these	O
variables	O
as	O
specifying	O
,	O
for	O
a	O
given	O
image	O
,	O
at	O
different	O
levels	O
of	O
abstraction	O
,	O
whether	O
a	O
particular	O
object	O
such	O
as	O
a	O
cat	O
or	O
a	O
dog	O
is	O
present	O
in	O
the	O
input	O
,	O
or	O
perhaps	O
what	O
the	O
exact	O
position	O
and	O
intensity	O
of	O
an	O
edge	O
at	O
a	O
given	O
location	O
might	O
be	O
.	O
	
During	O
the	O
recognition	B-Task
phase	O
the	O
network	O
acquires	O
information	O
about	O
the	O
input	O
and	O
stores	O
it	O
in	O
the	O
latent	O
variables	O
,	O
reducing	O
their	O
uncertainty	O
.	O
	
For	O
example	O
,	O
at	O
first	O
not	O
knowing	O
whether	O
a	O
cat	O
or	O
a	O
dog	O
is	O
present	O
in	O
the	O
image	O
,	O
the	O
network	O
observes	O
the	O
input	O
and	O
becomes	O
nearly	O
certain	O
that	O
it	O
is	O
a	O
cat	O
.	O
	
The	O
reduction	B-Metric
in	I-Metric
uncertainty	I-Metric
is	O
quantitatively	O
equal	O
to	O
the	O
amount	O
of	O
information	O
the	O
network	O
acquired	O
about	O
the	O
input	O
.	O
	
During	O
generation	B-Task
the	O
network	O
starts	O
with	O
uncertain	O
latent	O
variables	O
and	O
selects	O
their	O
values	O
from	O
a	O
prior	O
distribution	O
that	O
specifies	O
this	O
uncertainty	O
(	O
e.g.	O
it	O
chooses	O
a	O
dog	O
)	O
.	O
	
Different	O
choices	O
will	O
produce	O
different	O
samples	O
.	O
	
Variational	B-Method
auto	I-Method
-	I-Method
encoders	I-Method
provide	O
a	O
natural	O
framework	O
for	O
unsupervised	B-Task
learning	I-Task
–	O
we	O
can	O
build	O
networks	B-Method
with	O
layers	O
of	O
stochastic	O
variables	O
and	O
expect	O
that	O
,	O
after	O
learning	O
,	O
the	O
representations	O
become	O
increasingly	O
more	O
abstract	O
for	O
higher	O
levels	O
of	O
the	O
hierarchy	O
.	O
	
The	O
questions	O
then	O
are	O
:	O
can	O
such	O
a	O
framework	O
indeed	O
discover	O
such	O
representations	O
both	O
in	O
principle	O
and	O
in	O
practice	O
,	O
are	O
such	O
networks	O
powerful	O
enough	O
for	O
modeling	O
real	O
data	O
,	O
and	O
what	O
techniques	O
one	O
needs	O
to	O
make	O
it	O
work	O
well	O
.	O
	
subsection	O
:	O
Conceptual	B-Method
Compression	I-Method
	
Variational	B-Method
auto	I-Method
-	I-Method
encoders	I-Method
can	O
not	O
only	O
be	O
used	O
for	O
representation	B-Task
learning	I-Task
but	O
also	O
for	O
compression	B-Task
.	O
	
The	O
training	O
objective	O
of	O
variational	B-Method
auto	I-Method
-	I-Method
encoders	I-Method
is	O
to	O
compress	O
the	O
total	O
amount	O
of	O
information	O
needed	O
to	O
encode	O
the	O
input	O
.	O
	
They	O
achieve	O
this	O
by	O
using	O
information	O
-	O
carrying	O
latent	O
variables	O
that	O
express	O
what	O
,	O
before	O
compression	O
,	O
was	O
encoded	O
using	O
a	O
larger	O
amount	O
of	O
information	O
in	O
the	O
input	O
.	O
	
The	O
information	O
in	O
the	O
layers	O
and	O
the	O
remaining	O
information	O
in	O
the	O
input	O
can	O
be	O
encoded	O
in	O
practice	O
as	O
explained	O
later	O
in	O
this	O
paper	O
.	O
	
The	O
amount	O
of	O
lossless	B-Task
compression	I-Task
one	O
is	O
able	O
to	O
achieve	O
is	O
bounded	O
by	O
the	O
underlying	O
entropy	B-Metric
of	O
the	O
image	O
distribution	O
.	O
	
Additionally	O
,	O
most	O
image	O
information	O
as	O
measured	O
in	O
bits	O
is	O
contained	O
in	O
the	O
fine	O
details	O
of	O
the	O
image	O
.	O
	
Thus	O
we	O
might	O
reasonably	O
expect	O
that	O
lossless	B-Method
compression	I-Method
will	O
never	O
improve	O
by	O
more	O
than	O
a	O
factor	O
of	O
two	O
in	O
comparison	O
to	O
current	O
performance	O
.	O
	
Lossy	B-Task
compression	I-Task
,	O
on	O
the	O
other	O
hand	O
,	O
holds	O
much	O
more	O
potential	O
for	O
improvement	O
.	O
	
In	O
this	O
case	O
we	O
want	O
to	O
compress	O
an	O
image	O
by	O
a	O
certain	O
amount	O
,	O
allowing	O
some	O
information	O
loss	O
,	O
while	O
maximizing	O
both	O
quality	B-Metric
and	O
similarity	B-Metric
to	O
the	O
original	O
image	O
.	O
	
As	O
an	O
example	O
,	O
at	O
a	O
low	O
level	O
of	O
compression	B-Task
(	O
close	O
to	O
lossless	B-Task
compression	I-Task
)	O
,	O
we	O
could	O
start	O
by	O
reducing	O
pixel	O
precision	O
,	O
e.g.	O
from	O
8	O
bits	O
to	O
7	O
bits	O
.	O
	
Then	O
,	O
as	O
in	O
JPEG	B-Method
,	O
we	O
could	O
express	O
a	O
local	O
8x8	O
neighborhood	O
in	O
a	O
discrete	O
cosine	O
transform	O
basis	O
and	O
store	O
only	O
the	O
most	O
significant	O
components	O
.	O
	
This	O
way	O
,	O
instead	O
of	O
introducing	O
quantization	O
artifacts	O
in	O
the	O
image	O
that	O
would	O
appear	O
if	O
we	O
kept	O
decreasing	O
pixel	O
precision	O
,	O
we	O
preserve	O
higher	O
level	O
structures	O
but	O
to	O
a	O
lower	O
level	O
of	O
precision	O
.	O
	
However	O
,	O
what	O
can	O
we	O
do	O
beyond	O
that	O
as	O
we	O
keep	O
pushing	O
the	O
compression	B-Task
?	O
	
We	O
would	O
like	O
to	O
preserve	O
the	O
most	O
important	O
aspects	O
of	O
the	O
image	O
.	O
	
What	O
determines	O
what	O
is	O
important	O
?	O
	
Let	O
us	O
imagine	O
that	O
we	O
are	O
compressing	O
images	O
of	O
cats	O
and	O
dogs	O
and	O
would	O
like	O
to	O
compress	O
an	O
image	O
down	O
to	O
one	O
bit	O
.	O
	
What	O
would	O
that	O
bit	O
be	O
?	O
	
One	O
would	O
imagine	O
that	O
it	O
should	O
represent	O
whether	O
the	O
image	O
contains	O
either	O
a	O
cat	O
or	O
a	O
dog	O
.	O
	
How	O
would	O
we	O
then	O
get	O
an	O
image	O
out	O
of	O
this	O
single	O
bit	O
?	O
	
If	O
we	O
have	O
a	O
good	O
generative	B-Method
model	I-Method
,	O
we	O
can	O
simply	O
generate	O
the	O
entire	O
image	O
from	O
this	O
one	O
latent	O
variable	O
,	O
an	O
image	O
of	O
a	O
cat	O
if	O
the	O
bit	O
corresponds	O
to	O
‘	O
cat	O
’	O
,	O
and	O
an	O
image	O
of	O
a	O
dog	O
otherwise	O
.	O
	
Now	O
let	O
us	O
imagine	O
that	O
instead	O
of	O
compressing	O
to	O
one	O
bit	O
we	O
wanted	O
to	O
compress	O
down	O
to	O
ten	O
bits	O
.	O
	
Now	O
we	O
can	O
store	O
the	O
most	O
important	O
properties	O
of	O
the	O
animal	O
as	O
well	O
	
–	O
	
e.g.	O
its	O
type	O
,	O
color	O
,	O
and	O
basic	O
pose	O
.	O
	
The	O
rest	O
would	O
be	O
‘	O
filled	O
in	O
’	O
by	O
the	O
generative	B-Method
model	I-Method
that	O
is	O
conditioned	O
on	O
this	O
information	O
.	O
	
If	O
we	O
increase	O
the	O
number	O
of	O
bits	O
further	O
we	O
can	O
preserve	O
more	O
and	O
more	O
about	O
the	O
image	O
,	O
while	O
generating	O
the	O
fine	O
details	O
such	O
as	O
hair	O
,	O
or	O
the	O
exact	O
pattern	O
of	O
the	O
floor	O
,	O
etc	O
.	O
	
Most	O
bits	O
are	O
in	O
fact	O
about	O
such	O
low	O
level	O
details	O
.	O
	
We	O
call	O
this	O
kind	O
of	O
compression	B-Method
–	O
compressing	B-Task
by	O
giving	O
priority	O
to	O
higher	O
levels	O
of	O
representation	O
and	O
generating	O
the	O
remainder	O
–	O
	
‘	O
conceptual	B-Method
compression	I-Method
’	O
.	O
	
We	O
suggest	O
that	O
this	O
should	O
be	O
the	O
ultimate	O
objective	O
of	O
lossy	B-Task
compression	I-Task
.	O
	
Importantly	O
,	O
if	O
we	O
solve	O
deep	B-Method
representation	I-Method
learning	I-Method
with	O
latent	B-Method
variable	I-Method
generative	I-Method
models	I-Method
that	O
generate	O
high	O
quality	O
samples	O
,	O
we	O
achieve	O
the	O
objective	O
of	O
lossy	B-Task
compression	I-Task
mentioned	O
above	O
.	O
	
We	O
can	O
see	O
this	O
as	O
follows	O
.	O
	
Assume	O
that	O
the	O
network	O
has	O
learned	O
a	O
hierarchy	O
of	O
progressively	O
more	O
abstract	O
representations	O
.	O
	
Then	O
,	O
to	O
get	O
different	O
levels	O
of	O
compression	O
,	O
we	O
can	O
store	O
only	O
the	O
corresponding	O
number	O
of	O
topmost	O
layers	O
and	O
generate	O
the	O
rest	O
.	O
	
By	O
solving	O
unsupervised	B-Method
deep	I-Method
learning	I-Method
,	O
the	O
network	O
would	O
order	O
information	O
according	O
to	O
its	O
importance	O
and	O
store	O
it	O
with	O
that	O
priority	O
.	O
	
While	O
the	O
ultimate	O
goal	O
of	O
unsupervised	B-Task
learning	I-Task
remains	O
elusive	O
,	O
we	O
make	O
a	O
step	O
in	O
this	O
direction	O
,	O
and	O
show	O
that	O
our	O
network	O
learns	O
to	O
order	O
information	O
from	O
a	O
rather	O
global	O
level	O
to	O
precise	O
details	O
in	O
images	O
,	O
without	O
being	O
hand	O
-	O
engineered	O
to	O
do	O
this	O
explicitly	O
,	O
as	O
illustrated	O
in	O
Figures	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
.	O
	
This	O
information	O
separation	O
already	O
allows	O
us	O
to	O
achieve	O
better	O
compression	B-Metric
quality	I-Metric
than	O
JPEG	B-Method
and	O
JPEG2000	B-Method
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
While	O
we	O
are	O
not	O
bound	O
by	O
the	O
same	O
constraints	O
as	O
these	O
algorithms	O
,	O
such	O
as	O
speed	O
and	O
memory	O
,	O
these	O
results	O
demonstrate	O
the	O
potential	O
of	O
this	O
method	O
,	O
which	O
will	O
get	O
better	O
as	O
latent	B-Method
variable	I-Method
generative	I-Method
models	I-Method
improve	O
.	O
	
subsection	O
:	O
The	O
Importance	O
of	O
Recurrent	O
Feedback	O
	
What	O
are	O
the	O
challenges	O
involved	O
in	O
turning	O
latent	B-Method
variable	I-Method
models	I-Method
into	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
generative	B-Method
models	I-Method
of	I-Method
images	I-Method
?	O
	
Many	O
successful	O
vision	B-Method
architectures	I-Method
(	O
e.g.	O
)	O
have	O
highly	O
over	O
-	O
complete	O
representations	O
that	O
contain	O
many	O
more	O
neurons	O
in	O
hidden	O
layers	O
than	O
pixels	O
.	O
	
These	O
representations	O
need	O
to	O
be	O
combined	O
to	O
get	O
a	O
very	O
sharp	O
distribution	O
at	O
the	O
pixel	O
level	O
if	O
the	O
pixels	O
are	O
modeled	O
independently	O
.	O
	
This	O
distribution	O
corresponds	O
to	O
salt	O
and	O
pepper	O
noise	O
which	O
is	O
not	O
present	O
in	O
natural	O
images	O
to	O
a	O
perceptible	O
level	O
.	O
	
This	O
poses	O
a	O
major	O
challenge	O
.	O
	
After	O
experimenting	O
with	O
deep	B-Method
variational	I-Method
auto	I-Method
-	I-Method
encoders	I-Method
we	O
concluded	O
that	O
it	O
was	O
exceedingly	O
difficult	O
to	O
obtain	O
satisfactory	O
results	O
with	O
a	O
single	O
computational	O
pass	O
through	O
the	O
network	O
.	O
	
Instead	O
we	O
propose	O
that	O
the	O
network	O
needs	O
the	O
ability	O
to	O
correct	O
itself	O
over	O
a	O
number	O
of	O
time	O
steps	O
.	O
	
Thus	O
,	O
sharp	O
reconstructions	O
should	O
not	O
be	O
a	O
property	O
of	O
high	O
-	O
precision	O
values	O
in	O
the	O
network	O
,	O
but	O
should	O
rather	O
be	O
the	O
result	O
of	O
an	O
iterative	B-Method
feedback	I-Method
mechanism	I-Method
that	O
is	O
robust	O
to	O
network	O
parameter	O
change	O
.	O
	
Such	O
a	O
mechanism	O
is	O
provided	O
by	O
the	O
DRAW	B-Method
algorithm	I-Method
,	O
which	O
is	O
a	O
recurrent	B-Method
type	I-Method
of	I-Method
variational	I-Method
auto	I-Method
-	I-Method
encoder	I-Method
.	O
	
At	O
each	O
time	O
step	O
,	O
DRAW	O
maintains	O
a	O
provisionary	B-Method
reconstruction	I-Method
,	O
takes	O
in	O
information	O
about	O
a	O
given	O
image	O
,	O
stores	O
it	O
in	O
latent	O
variables	O
and	O
updates	O
the	O
reconstruction	O
.	O
	
Keeping	O
track	O
of	O
the	O
reconstruction	B-Task
aids	O
the	O
iterative	B-Method
feedback	I-Method
mechanism	I-Method
which	O
is	O
learned	O
by	O
back	B-Method
-	I-Method
propagation	I-Method
.	O
	
Computation	B-Task
is	O
both	O
deep	O
–	O
in	O
iterations	O
–	O
and	O
close	O
to	O
the	O
pixels	O
.	O
	
We	O
introduce	O
convolutional	B-Method
DRAW	I-Method
.	O
	
It	O
features	O
convolutions	B-Method
,	O
latent	B-Method
prior	I-Method
modeling	I-Method
,	O
a	O
Gaussian	B-Method
input	I-Method
distribution	I-Method
(	O
for	O
natural	O
images	O
)	O
and	O
,	O
in	O
some	O
experiments	O
,	O
a	O
multi	B-Method
-	I-Method
layer	I-Method
architecture	I-Method
.	O
	
However	O
,	O
it	O
does	O
not	O
use	O
an	O
explicit	O
attentional	B-Method
mechanism	I-Method
.	O
	
We	O
note	O
that	O
even	O
the	O
single	B-Method
-	I-Method
layer	I-Method
version	I-Method
is	O
already	O
a	O
deep	B-Method
generative	I-Method
model	I-Method
which	O
can	O
decide	O
to	O
process	O
higher	O
level	O
information	O
first	O
before	O
focusing	O
on	O
details	O
,	O
as	O
we	O
demonstrate	O
to	O
some	O
degree	O
.	O
	
We	O
also	O
experiment	O
with	O
making	O
convolutional	B-Method
DRAW	I-Method
hierarchical	I-Method
in	O
a	O
similar	O
way	O
that	O
we	O
would	O
build	O
conventional	O
deep	B-Method
variational	I-Method
auto	I-Method
-	I-Method
encoders	I-Method
–	O
stacking	O
more	O
layers	O
of	O
latent	O
and	O
deterministic	O
variables	O
.	O
	
We	O
believe	O
that	O
the	O
recurrence	B-Method
is	O
important	O
not	O
just	O
for	O
accurate	B-Task
pixel	I-Task
reconstructions	I-Task
,	O
but	O
also	O
at	O
higher	O
levels	O
.	O
	
For	O
example	O
,	O
when	O
the	O
network	O
decides	O
to	O
generate	O
edges	O
at	O
different	O
locations	O
,	O
it	O
needs	O
to	O
make	O
sure	O
that	O
they	O
are	O
aligned	O
.	O
	
It	O
is	O
hard	O
to	O
imagine	O
this	O
happening	O
in	O
a	O
single	O
computational	O
pass	O
through	O
the	O
network	O
.	O
	
Similarly	O
at	O
higher	O
levels	O
,	O
when	O
it	O
decides	O
to	O
generate	O
objects	O
,	O
they	O
need	O
to	O
be	O
generated	O
with	O
the	O
right	O
relationship	O
to	O
one	O
another	O
.	O
	
And	O
finally	O
at	O
the	O
scene	O
level	O
,	O
one	O
probably	O
does	O
not	O
generate	O
entire	O
scenes	O
at	O
once	O
,	O
but	O
rather	O
one	O
step	O
at	O
a	O
time	O
.	O
	
subsection	O
:	O
Comparison	O
to	O
Non	B-Method
-	I-Method
variational	I-Method
Models	I-Method
	
Let	O
us	O
relate	O
this	O
discussion	O
to	O
two	O
other	O
families	O
of	O
generative	B-Method
models	I-Method
,	O
specifically	O
generative	B-Method
adversarial	I-Method
networks	I-Method
(	O
GANs	B-Method
;	O
)	O
and	O
auto	B-Method
-	I-Method
regressive	I-Method
pixel	I-Method
models	I-Method
.	O
	
GANs	B-Method
have	O
been	O
demonstrated	O
to	O
be	O
able	O
to	O
generate	O
realistic	O
looking	O
images	O
,	O
with	O
properly	O
aligned	O
edges	O
,	O
using	O
a	O
simple	O
feedforward	B-Method
generative	I-Method
network	I-Method
.	O
	
GANs	B-Method
also	O
contain	O
two	O
networks	O
–	O
a	O
generative	B-Method
network	I-Method
that	O
is	O
the	O
same	O
as	O
in	O
variational	B-Method
auto	I-Method
-	I-Method
encoders	I-Method
,	O
and	O
a	O
classification	B-Method
network	I-Method
.	O
	
The	O
classification	B-Method
network	I-Method
is	O
presented	O
with	O
both	O
real	O
and	O
model	O
-	O
generated	O
images	O
and	O
tries	O
to	O
classify	O
them	O
according	O
to	O
their	O
true	O
nature	O
–	O
real	O
or	O
model	O
-	O
generated	O
.	O
	
The	O
generative	B-Method
network	I-Method
gets	O
gradients	O
from	O
the	O
classification	B-Method
network	I-Method
,	O
changing	O
its	O
weights	O
in	O
an	O
attempt	O
to	O
make	O
the	O
generated	O
images	O
be	O
judged	O
as	O
real	O
ones	O
by	O
the	O
classification	B-Method
network	I-Method
.	O
	
This	O
makes	O
the	O
generation	B-Task
network	O
produce	O
realistic	O
images	O
that	O
‘	O
fool	O
’	O
the	O
classification	B-Method
network	I-Method
.	O
	
It	O
needs	O
to	O
produce	O
a	O
wide	O
diversity	O
of	O
images	O
,	O
not	O
just	O
one	O
realistic	O
image	O
,	O
because	O
if	O
it	O
produced	O
only	O
one	O
(	O
or	O
a	O
small	O
number	O
of	O
them	O
)	O
,	O
the	O
classification	B-Method
network	I-Method
would	O
classify	O
that	O
image	O
as	O
generated	O
and	O
others	O
as	O
realistic	O
,	O
and	O
be	O
almost	O
always	O
correct	O
.	O
	
This	O
actually	O
happens	O
in	O
practice	O
,	O
and	O
one	O
has	O
to	O
apply	O
a	O
variety	O
of	O
techniques	O
,	O
e.g.	O
as	O
in	O
,	O
to	O
obtain	O
sufficient	O
image	O
diversity	O
.	O
	
However	O
the	O
extent	O
of	O
GANs	B-Metric
’	I-Metric
sampling	I-Metric
diversity	I-Metric
is	O
unknown	O
and	O
currently	O
there	O
is	O
no	O
satisfactory	O
measure	O
for	O
it	O
.	O
	
So	O
while	O
a	O
given	O
network	O
does	O
n’t	O
produce	O
just	O
one	O
image	O
,	O
it	O
is	O
possible	O
that	O
it	O
produces	O
only	O
a	O
tiny	O
subset	O
of	O
possible	O
realistic	O
images	O
,	O
as	O
it	O
simply	O
competes	O
with	O
the	O
power	O
of	O
the	O
classifier	B-Method
.	O
	
For	O
example	O
if	O
it	O
generates	O
a	O
sharp	O
image	O
,	O
it	O
is	O
unclear	O
whether	O
the	O
system	O
is	O
also	O
capable	O
of	O
generating	O
its	O
translated	O
version	O
,	O
or	O
simply	O
a	O
slightly	O
distorted	O
version	O
.	O
	
Finally	O
there	O
is	O
another	O
way	O
to	O
get	O
low	O
uncertainty	O
at	O
the	O
pixel	O
level	O
:	O
instead	O
of	O
predicting	O
pixels	O
independently	O
given	O
the	O
latents	O
,	O
we	O
can	O
decide	O
not	O
to	O
use	O
latents	O
and	O
iterate	O
sequentially	O
over	O
the	O
pixels	O
,	O
predicting	O
a	O
given	O
pixel	O
from	O
the	O
previous	O
ones	O
(	O
from	O
top	O
left	O
to	O
bottom	O
right	O
)	O
in	O
an	O
autoregressive	B-Method
fashion	I-Method
.	O
	
This	O
is	O
as	O
‘	O
close	O
’	O
to	O
the	O
pixels	O
as	O
one	O
can	O
possibly	O
be	O
,	O
and	O
furthermore	O
the	O
procedure	O
is	O
purely	O
deterministic	O
.	O
	
The	O
disadvantage	O
is	O
conceptual	O
–	O
the	O
information	O
and	O
decisions	O
are	O
not	O
done	O
at	O
a	O
conceptual	O
level	O
but	O
at	O
the	O
pixel	O
level	O
.	O
	
For	O
example	O
when	O
generating	O
cats	O
vs	O
dogs	O
the	O
decisions	O
at	O
the	O
first	O
set	O
of	O
pixels	O
(	O
top	O
left	O
of	O
the	O
image	O
)	O
will	O
contain	O
no	O
information	O
about	O
a	O
hypothetical	O
cat	O
or	O
dog	O
.	O
	
But	O
as	O
we	O
get	O
to	O
the	O
region	O
where	O
these	O
objects	O
are	O
,	O
we	O
start	O
choosing	O
pixels	O
that	O
will	O
slowly	O
tip	O
the	O
probability	O
of	O
generating	O
a	O
cat	O
vs	O
a	O
dog	O
one	O
way	O
or	O
the	O
other	O
.	O
	
As	O
we	O
start	O
generating	O
an	O
ear	O
,	O
it	O
will	O
more	O
likely	O
be	O
a	O
cat	O
’s	O
or	O
a	O
dog	O
’s	O
and	O
so	O
on	O
.	O
	
However	O
this	O
pixel	B-Method
level	I-Method
approach	I-Method
and	O
our	O
approach	O
are	O
orthogonal	O
and	O
can	O
be	O
easily	O
combined	O
,	O
for	O
example	O
by	O
feeding	O
the	O
output	O
of	O
convolutional	B-Method
DRAW	I-Method
into	O
the	O
conditional	B-Method
computation	I-Method
of	O
a	O
pixel	B-Method
level	I-Method
model	I-Method
.	O
	
In	O
this	O
paper	O
we	O
study	O
the	O
latent	B-Method
variable	I-Method
approach	I-Method
and	O
make	O
the	O
pixels	O
independent	O
given	O
the	O
latents	O
.	O
	
section	O
:	O
Convolutional	B-Method
DRAW	I-Method
	
In	O
this	O
section	O
we	O
describe	O
the	O
details	O
of	O
a	O
single	B-Method
-	I-Method
layer	I-Method
version	I-Method
of	O
the	O
algorithm	O
.	O
	
Convolutional	B-Method
DRAW	I-Method
contains	O
the	O
following	O
variables	O
:	O
input	O
,	O
reconstruction	O
,	O
reconstruction	O
error	O
,	O
the	O
state	O
of	O
the	O
encoder	B-Method
recurrent	I-Method
net	I-Method
,	O
the	O
state	O
of	O
the	O
decoder	O
recurrent	O
net	O
and	O
latent	O
variable	O
.	O
	
The	O
variables	O
,	O
and	O
are	O
recurrent	O
(	O
passed	O
between	O
different	O
time	O
steps	O
)	O
and	O
are	O
initialized	O
with	O
learned	O
biases	O
.	O
	
Then	O
at	O
each	O
time	O
step	O
,	O
convolutional	B-Method
DRAW	I-Method
performs	O
the	O
following	O
updates	O
:	O
where	O
denotes	O
a	O
convolution	B-Method
and	O
Rnn	B-Method
denotes	O
a	O
recurrent	B-Method
network	I-Method
.	O
	
We	O
use	O
LSTM	B-Method
with	I-Method
convolutional	I-Method
operators	I-Method
instead	O
of	O
the	O
usual	O
linear	B-Method
ones	I-Method
.	O
	
The	O
final	O
value	O
of	O
contains	O
the	O
parameters	O
of	O
the	O
input	O
distribution	O
.	O
	
For	O
binary	O
images	O
we	O
use	O
the	O
Bernoulli	B-Method
distribution	I-Method
.	O
	
For	O
natural	O
images	O
we	O
use	O
the	O
Gaussian	B-Method
distribution	I-Method
with	O
mean	O
and	O
log	O
variance	O
given	O
by	O
splitting	O
the	O
vector	O
to	O
obtain	O
the	O
input	B-Metric
cost	I-Metric
and	O
the	O
total	B-Metric
cost	I-Metric
:	O
where	O
the	O
handling	O
of	O
real	O
valued	O
-	O
ness	O
of	O
the	O
inputs	O
(	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
)	O
is	O
explained	O
below	O
,	O
and	O
being	O
the	O
standard	O
setting	O
.	O
	
The	O
algorithm	O
is	O
schematically	O
illustrated	O
in	O
the	O
first	O
layer	O
of	O
Figure	O
[	O
reference	O
]	O
.	O
	
The	O
network	O
is	O
trained	O
by	O
calculating	O
the	O
gradient	O
of	O
this	O
loss	O
and	O
using	O
a	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
algorithm	I-Method
.	O
	
Stochastic	B-Method
back	I-Method
-	I-Method
propagation	I-Method
through	O
a	O
sampling	B-Method
function	I-Method
is	O
done	O
as	O
in	O
variational	B-Method
auto	I-Method
-	I-Method
encoders	I-Method
.	O
	
Both	O
the	O
approximate	O
posterior	O
and	O
the	O
prior	O
are	O
Gaussian	O
,	O
with	O
mean	O
and	O
log	O
variance	O
being	O
linear	O
functions	O
of	O
or	O
,	O
respectively	O
.	O
	
Let	O
us	O
discuss	O
how	O
we	O
handle	O
the	O
input	O
distribution	O
for	O
natural	O
images	O
.	O
	
Each	O
pixel	O
(	O
per	O
color	O
)	O
is	O
one	O
of	O
256	O
values	O
.	O
	
We	O
could	O
use	O
a	O
soft	B-Method
-	I-Method
max	I-Method
distribution	I-Method
to	O
model	O
it	O
.	O
	
This	O
would	O
result	O
in	O
a	O
rather	O
large	O
output	O
vector	O
at	O
every	O
time	O
step	O
and	O
also	O
does	O
not	O
take	O
advantage	O
of	O
the	O
underlying	O
real	O
valued	O
-	O
ness	O
of	O
intensities	O
and	O
therefore	O
we	O
opted	O
for	O
a	O
Gaussian	B-Method
distribution	I-Method
.	O
	
However	O
this	O
still	O
needs	O
to	O
be	O
converted	O
to	O
a	O
discrete	O
distribution	O
over	O
256	O
values	O
to	O
calculate	O
the	O
negative	O
likelihood	O
loss	O
.	O
	
Instead	O
of	O
this	O
,	O
we	O
add	O
uniform	O
noise	O
to	O
the	O
input	O
with	O
width	O
corresponding	O
to	O
the	O
spacing	O
between	O
discrete	O
values	O
and	O
calculate	O
where	O
with	O
if	O
inputs	O
are	O
scaled	O
to	O
the	O
interval	O
.	O
	
subsection	O
:	O
Multi	B-Method
-	I-Method
layer	I-Method
Architectures	I-Method
	
Next	O
we	O
explain	O
how	O
we	O
can	O
stack	O
convolutional	B-Method
DRAW	I-Method
with	O
a	O
two	O
layer	O
example	O
.	O
	
The	O
first	O
layer	O
is	O
the	O
same	O
as	O
the	O
one	O
just	O
introduced	O
.	O
	
The	O
second	O
layer	O
has	O
the	O
same	O
structure	O
:	O
recurrent	B-Method
encoder	I-Method
,	O
recurrent	B-Method
decoder	I-Method
and	O
a	O
stochastic	B-Method
layer	I-Method
.	O
	
The	O
input	O
to	O
the	O
second	O
layer	O
is	O
the	O
mean	O
of	O
the	O
approximate	O
posterior	O
of	O
the	O
first	O
layer	O
.	O
	
The	O
output	O
of	O
the	O
second	O
layer	O
biases	O
the	O
prior	O
of	O
the	O
latent	O
variable	O
of	O
the	O
first	O
layer	O
and	O
is	O
also	O
passed	O
as	O
input	O
into	O
the	O
first	B-Method
layer	I-Method
decoder	I-Method
recurrent	I-Method
net	I-Method
.	O
	
This	O
is	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
We	O
do	O
n’t	O
use	O
any	O
reconstruction	O
or	O
error	O
in	O
the	O
second	O
layer	O
.	O
	
Here	O
we	O
describe	O
a	O
given	O
computational	O
step	O
in	O
detail	O
.	O
	
Indices	O
and	O
denote	O
the	O
variables	O
of	O
layers	O
and	O
,	O
respectively	O
.	O
	
In	O
addition	O
,	O
let	O
be	O
the	O
mean	O
of	O
.	O
	
Then	O
,	O
the	O
update	O
at	O
a	O
given	O
time	O
step	O
is	O
given	O
by	O
Systems	O
with	O
more	O
layers	O
can	O
be	O
built	O
analogously	O
.	O
	
section	O
:	O
Compression	B-Task
	
Here	O
we	O
show	O
how	O
one	O
can	O
turn	O
variational	B-Method
auto	I-Method
-	I-Method
encoders	I-Method
including	O
convolutional	B-Method
DRAW	I-Method
into	O
compression	B-Method
algorithms	I-Method
.	O
	
We	O
have	O
not	O
built	O
the	O
actual	O
compressor	B-Method
,	O
however	O
,	O
as	O
we	O
explain	O
,	O
we	O
have	O
strong	O
reasons	O
to	O
believe	O
it	O
would	O
perform	O
as	O
well	O
as	O
calculated	O
here	O
.	O
	
Two	O
basic	O
approaches	O
exist	O
.	O
	
The	O
first	O
one	O
is	O
less	O
convenient	O
because	O
it	O
needs	O
to	O
add	O
extra	O
data	O
to	O
the	O
bitstream	O
when	O
compressing	O
an	O
image	O
but	O
has	O
essentially	O
a	O
guaranteed	B-Metric
compression	I-Metric
rate	I-Metric
.	O
	
The	O
other	O
one	O
may	O
require	O
some	O
experimentation	O
but	O
is	O
expected	O
to	O
yield	O
a	O
similar	O
compression	B-Metric
rate	I-Metric
and	O
can	O
be	O
used	O
on	O
a	O
given	O
image	O
without	O
needing	O
extra	O
data	O
.	O
	
The	O
underlying	O
compression	B-Method
mechanism	I-Method
for	O
all	O
cases	O
is	O
arithmetic	B-Method
coding	I-Method
.	O
	
Arithmetic	B-Method
coding	I-Method
takes	O
as	O
input	O
a	O
sequence	O
of	O
discrete	O
variables	O
and	O
a	O
set	O
of	O
probabilities	O
that	O
predict	O
the	O
variable	O
at	O
time	O
from	O
previous	O
variables	O
.	O
	
It	O
then	O
compresses	O
this	O
sequence	O
to	O
bits	O
plus	O
a	O
constant	O
of	O
order	O
one	O
.	O
	
Compressing	O
inputs	O
using	O
variational	B-Method
auto	I-Method
-	I-Method
encoders	I-Method
proceeds	O
as	O
follows	O
:	O
discretize	O
each	O
latent	O
variable	O
in	O
each	O
layer	O
using	O
the	O
width	O
of	O
(	O
eq	O
.	O
	
[	O
reference	O
]	O
)	O
,	O
treat	O
the	O
resulting	O
variables	O
as	O
a	O
sequence	O
with	O
predictions	O
(	O
eq	O
.	O
	
[	O
reference	O
]	O
)	O
and	O
compress	O
using	O
arithmetic	B-Method
coding	I-Method
.	O
	
For	O
this	O
to	O
work	O
as	O
explained	O
,	O
several	O
things	O
are	O
needed	O
.	O
	
First	O
,	O
the	O
discretization	O
should	O
be	O
independent	O
of	O
the	O
input	O
.	O
	
This	O
can	O
be	O
achieved	O
by	O
training	O
the	O
network	O
with	O
the	O
variance	O
of	O
being	O
a	O
learned	O
constant	O
that	O
does	O
not	O
depend	O
on	O
the	O
input	O
.	O
	
We	O
found	O
that	O
this	O
does	O
not	O
have	O
much	O
effect	O
on	O
the	O
likelihood	O
.	O
	
Second	O
,	O
one	O
should	O
evaluate	O
the	O
log	O
likelihood	O
using	O
this	O
discretization	O
.	O
	
One	O
has	O
to	O
decide	O
on	O
the	O
exact	O
manner	O
in	O
which	O
should	O
be	O
computed	O
for	O
each	O
discrete	O
value	O
.	O
	
Significant	O
tuning	O
might	O
be	O
required	O
here	O
,	O
for	O
the	O
obtained	O
likelihoods	O
to	O
be	O
as	O
good	O
as	O
the	O
ones	O
obtained	O
with	O
sampling	B-Method
.	O
	
However	O
this	O
is	O
likely	O
to	O
be	O
fruitful	O
since	O
there	O
exists	O
a	O
second	O
,	O
less	O
convenient	O
way	O
to	O
compress	O
that	O
is	O
guaranteed	O
to	O
achieve	O
this	O
rate	O
.	O
	
This	O
second	O
approach	O
uses	O
bits	B-Method
-	I-Method
back	I-Method
coding	I-Method
.	O
	
We	O
explain	O
only	O
the	O
basic	O
idea	O
here	O
.	O
	
We	O
discretize	O
the	O
latents	O
down	O
to	O
a	O
very	O
high	O
level	O
of	O
precision	B-Metric
and	O
use	O
to	O
transmit	O
the	O
information	O
.	O
	
Because	O
the	O
discretization	O
precision	O
is	O
high	O
,	O
the	O
probabilities	O
for	O
discrete	O
values	O
are	O
easily	O
assigned	O
.	O
	
That	O
will	O
preserve	O
the	O
information	O
but	O
it	O
will	O
cost	O
many	O
bits	O
,	O
namely	O
where	O
is	O
a	O
probability	O
under	O
that	O
discretization	O
.	O
	
Now	O
,	O
instead	O
of	O
sampling	O
from	O
the	O
approximate	O
posterior	O
when	O
encoding	O
an	O
input	O
,	O
we	O
encode	O
bits	O
of	O
other	O
information	O
into	O
the	O
choice	O
of	O
,	O
that	O
we	O
also	O
want	O
to	O
transmit	O
.	O
	
When	O
is	O
recovered	O
at	O
the	O
receiving	O
end	O
,	O
both	O
the	O
information	O
about	O
the	O
current	O
input	O
and	O
the	O
other	O
information	O
is	O
recovered	O
and	O
thus	O
the	O
information	O
needed	O
to	O
encode	O
the	O
current	O
input	O
is	O
.	O
	
The	O
expectation	O
of	O
this	O
quantity	O
is	O
the	O
KL	O
-	O
divergence	O
in	O
(	O
[	O
reference	O
]	O
)	O
,	O
which	O
therefore	O
measures	O
the	O
amount	O
of	O
information	O
stored	O
in	O
a	O
given	O
latent	O
layer	O
.	O
	
The	O
disadvantage	O
of	O
this	O
approach	O
is	O
that	O
we	O
can	O
not	O
encode	O
a	O
given	O
input	O
without	O
also	O
having	O
some	O
other	O
information	O
we	O
want	O
to	O
transmit	O
.	O
	
However	O
,	O
this	O
coding	B-Method
scheme	I-Method
works	O
even	O
if	O
the	O
variance	O
of	O
the	O
approximate	O
posterior	O
is	O
dependent	O
on	O
the	O
input	O
.	O
	
section	O
:	O
Results	O
	
For	O
natural	O
images	O
,	O
all	O
models	O
except	O
otherwise	O
specified	O
were	O
single	O
-	O
layer	O
,	O
with	O
,	O
a	O
kernel	O
size	O
of	O
,	O
and	O
stride	B-Method
2	I-Method
convolutions	I-Method
between	O
input	O
layers	O
and	O
hidden	O
layers	O
with	O
latent	O
feature	O
maps	O
.	O
	
We	O
trained	O
the	O
models	O
on	O
Cifar	B-Material
-	I-Material
10	I-Material
and	O
ImageNet	B-Method
with	O
and	O
LSTM	O
feature	O
maps	O
respectively	O
.	O
	
We	O
use	O
the	O
version	O
of	O
ImageNet	B-Method
presented	O
in	O
that	O
will	O
soon	O
be	O
released	O
as	O
a	O
standard	O
dataset	O
.	O
	
We	O
train	O
the	O
network	O
with	O
the	O
Adam	B-Method
algorithm	I-Method
with	O
learning	B-Method
rate	I-Method
.	O
	
Occasionally	O
,	O
we	O
find	O
that	O
the	O
cost	O
suddenly	O
increases	O
dramatically	O
.	O
	
This	O
is	O
probably	O
due	O
to	O
the	O
Gaussian	O
nature	O
of	O
the	O
distribution	O
,	O
when	O
a	O
given	O
variable	O
is	O
produced	O
too	O
far	O
from	O
the	O
mean	O
relative	O
to	O
sigma	O
.	O
	
We	O
observed	O
this	O
happening	O
approximately	O
once	O
per	O
run	O
.	O
	
To	O
be	O
able	O
to	O
keep	O
training	O
we	O
store	O
older	O
parameters	O
,	O
detect	O
such	O
jumps	O
and	O
revert	O
to	O
the	O
old	O
parameters	O
when	O
they	O
occur	O
.	O
	
The	O
network	O
then	O
just	O
keeps	O
training	O
as	O
if	O
nothing	O
had	O
happened	O
.	O
	
subsection	O
:	O
Modeling	B-Metric
Quality	I-Metric
	
subsubsection	O
:	O
Omniglot	B-Material
	
The	O
recently	O
introduced	O
Omniglot	B-Material
dataset	O
is	O
comprised	O
of	O
character	O
classes	O
drawn	O
from	O
multiple	O
alphabets	O
with	O
just	O
samples	O
per	O
class	O
.	O
	
Referred	O
to	O
by	O
many	O
as	O
the	O
‘	O
inverse	B-Method
of	I-Method
MNIST	I-Method
’	I-Method
,	O
it	O
was	O
designed	O
to	O
study	O
conceptual	B-Method
representations	I-Method
and	O
generative	B-Method
models	I-Method
in	O
a	O
low	O
-	O
data	O
regime	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
likelihoods	O
of	O
different	O
models	O
compared	O
to	O
ours	O
.	O
	
For	O
our	O
model	O
,	O
we	O
only	O
calculate	O
the	O
upper	O
bound	O
(	O
variational	O
bound	O
)	O
and	O
therefore	O
the	O
true	O
likelihood	O
is	O
actually	O
better	O
.	O
	
Samples	O
generated	O
by	O
the	O
model	O
are	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
subsubsection	O
:	O
Cifar	B-Material
-	I-Material
10	I-Material
	
Table	O
[	O
reference	O
]	O
shows	O
likelihoods	O
of	O
different	O
models	O
on	O
Cifar	B-Material
-	I-Material
10	I-Material
.	O
	
We	O
see	O
that	O
our	O
method	O
outperforms	O
previous	O
methods	O
except	O
for	O
the	O
just	O
released	B-Method
Pixel	I-Method
RNN	I-Method
model	I-Method
of	O
.	O
	
As	O
mentioned	O
,	O
the	O
advantage	O
of	O
our	O
model	O
compared	O
to	O
such	O
auto	B-Method
-	I-Method
regressive	I-Method
models	I-Method
is	O
that	O
it	O
is	O
a	O
latent	B-Method
variable	I-Method
model	I-Method
that	O
can	O
be	O
used	O
for	O
representation	B-Task
learning	I-Task
and	O
lossy	B-Task
compression	I-Task
.	O
	
At	O
the	O
same	O
time	O
,	O
the	O
two	O
approaches	O
are	O
orthogonal	O
and	O
can	O
be	O
combined	O
,	O
for	O
example	O
by	O
feeding	O
the	O
output	O
of	O
convolutional	B-Method
DRAW	I-Method
into	O
the	O
recurrent	B-Method
network	I-Method
of	I-Method
Pixel	I-Method
RNN	I-Method
.	O
	
We	O
also	O
report	O
the	O
likelihood	O
for	O
a	O
(	O
non	B-Method
-	I-Method
recurrent	I-Method
)	I-Method
variational	I-Method
auto	I-Method
-	I-Method
encoder	I-Method
and	O
standard	B-Method
DRAW	I-Method
.	O
	
For	O
the	O
variational	B-Method
auto	I-Method
-	I-Method
encoder	I-Method
we	O
tested	O
architectures	O
with	O
multiple	O
layers	O
,	O
both	O
deterministic	B-Method
and	I-Method
stochastic	I-Method
but	O
with	O
standard	O
functional	O
forms	O
,	O
and	O
this	O
was	O
the	O
best	O
result	O
that	O
we	O
obtained	O
.	O
	
Convolutional	B-Method
DRAW	I-Method
performs	O
significantly	O
better	O
.	O
	
subsubsection	O
:	O
ImageNet	B-Method
	
Additionally	O
,	O
we	O
trained	O
on	O
the	O
version	O
of	O
ImageNet	B-Method
prepared	O
in	O
which	O
was	O
created	O
with	O
the	O
aim	O
of	O
making	O
a	O
standardized	O
dataset	O
to	O
test	O
generative	B-Method
models	I-Method
.	O
	
The	O
results	O
are	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Note	O
that	O
being	O
a	O
new	O
dataset	O
,	O
no	O
other	O
methods	O
have	O
been	O
reported	O
on	O
it	O
.	O
	
In	O
Figure	O
[	O
reference	O
]	O
and	O
Figure	O
[	O
reference	O
]	O
we	O
show	O
generations	O
from	O
the	O
model	O
.	O
	
We	O
trained	O
networks	O
with	O
varying	O
input	O
cost	O
scales	O
as	O
explained	O
in	O
the	O
next	O
section	O
.	O
	
The	O
generations	O
are	O
sharp	O
and	O
contain	O
many	O
details	O
,	O
unlike	O
previous	O
versions	O
of	O
variational	B-Method
auto	I-Method
-	I-Method
encoder	I-Method
that	O
tend	O
to	O
generate	O
blurry	O
images	O
.	O
	
subsection	O
:	O
Input	B-Method
Cost	I-Method
Scaling	I-Method
	
Each	O
pixel	O
(	O
and	O
color	O
channel	O
)	O
of	O
the	O
data	O
consists	O
of	O
256	O
values	O
,	O
and	O
as	O
such	O
,	O
likelihood	B-Method
and	O
lossless	B-Task
compression	I-Task
are	O
well	O
defined	O
.	O
	
When	O
compressing	O
the	O
image	O
there	O
is	O
much	O
to	O
be	O
gained	O
in	O
capturing	O
precise	O
correlations	O
between	O
nearby	O
pixels	O
.	O
	
There	O
are	O
a	O
lot	O
more	O
bits	O
in	O
these	O
low	O
level	O
details	O
than	O
in	O
the	O
higher	O
level	O
structure	O
that	O
we	O
are	O
actually	O
interested	O
in	O
when	O
learning	O
higher	B-Method
level	I-Method
representations	I-Method
.	O
	
The	O
network	O
might	O
focus	O
on	O
these	O
details	O
,	O
ignoring	O
higher	O
level	O
structure	O
.	O
	
One	O
way	O
to	O
make	O
it	O
focus	O
less	O
on	O
the	O
details	O
is	O
to	O
scale	O
down	O
the	O
cost	O
of	O
the	O
input	O
relative	O
to	O
the	O
latents	O
,	O
that	O
is	O
,	O
setting	O
in	O
(	O
[	O
reference	O
]	O
)	O
.	O
	
Generations	O
for	O
different	O
cost	O
scalings	O
are	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
with	O
the	O
original	O
objective	O
being	O
scale	O
.	O
	
We	O
see	O
that	O
lower	O
scales	O
indeed	O
have	O
a	O
‘	O
cleaner	O
’	O
high	O
level	O
structure	O
.	O
	
Scale	O
1	O
contains	O
a	O
lot	O
of	O
information	O
at	O
the	O
precise	O
pixel	O
values	O
and	O
the	O
network	O
tries	O
to	O
capture	O
that	O
,	O
while	O
not	O
being	O
good	O
enough	O
to	O
properly	O
align	O
details	O
and	O
produce	O
realistic	O
patterns	O
.	O
	
This	O
might	O
be	O
simply	O
a	O
matter	O
of	O
scaling	O
,	O
making	O
layers	O
larger	O
,	O
networks	O
deeper	O
,	O
using	O
more	O
iterations	O
,	O
or	O
using	O
better	O
functional	O
forms	O
.	O
	
subsection	O
:	O
The	O
Dependence	O
on	O
Computational	O
Depth	O
	
Convolutional	B-Method
DRAW	I-Method
uses	O
many	O
iterations	O
and	O
might	O
be	O
considered	O
expensive	O
.	O
	
However	O
we	O
found	O
that	O
networks	O
with	O
a	O
larger	O
number	O
of	O
time	O
steps	O
train	O
faster	O
per	O
data	O
example	O
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
(	O
left	O
)	O
.	O
	
To	O
study	O
how	O
they	O
train	O
with	O
respect	O
to	O
real	O
time	O
,	O
we	O
multiply	O
the	O
time	O
scale	O
of	O
each	O
input	O
by	O
the	O
number	O
of	O
iterations	O
as	O
seen	O
in	O
Figure	O
[	O
reference	O
]	O
	
(	O
right	O
)	O
.	O
	
We	O
see	O
that	O
despite	O
having	O
to	O
do	O
several	O
iterations	O
,	O
up	O
to	O
about	O
,	O
convolutional	B-Method
DRAW	I-Method
does	O
not	O
take	O
more	O
wall	O
clock	O
time	O
to	O
train	O
than	O
the	O
same	O
architecture	O
with	O
smaller	O
.	O
	
For	O
larger	O
,	O
the	O
training	O
slows	O
down	O
,	O
but	O
it	O
does	O
eventually	O
reach	O
better	O
performance	O
than	O
at	O
lower	O
.	O
	
subsection	O
:	O
Information	B-Task
Distribution	I-Task
	
We	O
look	O
at	O
how	O
much	O
information	O
different	O
levels	O
and	O
time	O
steps	O
contain	O
.	O
	
This	O
information	O
is	O
simply	O
the	O
KL	O
divergence	O
in	O
(	O
[	O
reference	O
]	O
)	O
and	O
(	O
[	O
reference	O
]	O
)	O
.	O
	
For	O
a	O
two	B-Method
layer	I-Method
system	I-Method
with	O
one	O
convolutional	B-Method
and	I-Method
one	I-Method
fully	I-Method
connected	I-Method
layer	I-Method
,	O
this	O
is	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
We	O
see	O
that	O
the	O
higher	O
level	O
contains	O
information	O
mainly	O
at	O
the	O
beginning	O
of	O
the	O
computation	O
,	O
whereas	O
the	O
lower	O
layer	O
starts	O
with	O
low	O
information	O
which	O
then	O
gradually	O
increases	O
.	O
	
This	O
is	O
desirable	O
from	O
a	O
conceptual	O
point	O
of	O
view	O
.	O
	
It	O
suggests	O
that	O
the	O
network	O
first	O
finds	O
out	O
about	O
an	O
overall	O
structure	O
of	O
the	O
image	O
and	O
then	O
explains	O
the	O
details	O
contained	O
within	O
that	O
structure	O
.	O
	
Understanding	O
the	O
overall	O
structure	O
rapidly	O
is	O
also	O
convenient	O
if	O
the	O
algorithm	O
needs	O
to	O
respond	O
to	O
observations	O
in	O
a	O
timely	O
manner	O
.	O
	
subsection	O
:	O
Lossy	B-Method
Compression	I-Method
	
We	O
can	O
compress	O
an	O
image	O
with	O
loss	O
of	O
information	O
by	O
storing	O
only	O
a	O
subset	O
of	O
the	O
latent	O
variables	O
,	O
typically	O
the	O
high	O
levels	O
of	O
the	O
hierarchy	O
.	O
	
We	O
can	O
do	O
this	O
in	O
multilayer	O
convolutional	B-Method
DRAW	I-Method
,	O
storing	O
only	O
higher	O
levels	O
.	O
	
However	O
we	O
can	O
also	O
store	O
only	O
a	O
subset	O
of	O
time	O
steps	O
,	O
specifically	O
a	O
given	O
number	O
of	O
time	O
steps	O
at	O
the	O
beginning	O
,	O
and	O
let	O
the	O
network	O
generate	O
the	O
rest	O
.	O
	
The	O
units	O
not	O
stored	O
should	O
be	O
generated	O
from	O
the	O
prior	O
distribution	O
(	O
Equation	O
[	O
reference	O
]	O
)	O
.	O
	
However	O
we	O
can	O
also	O
generate	O
a	O
more	O
likely	O
image	O
by	O
lowering	O
the	O
variance	O
of	O
the	O
prior	O
Gaussian	O
.	O
	
We	O
show	O
generations	O
with	O
full	O
variance	O
in	O
row	O
3	O
of	O
each	O
block	O
of	O
Figure	O
[	O
reference	O
]	O
and	O
with	O
variance	O
zero	O
in	O
row	O
4	O
of	O
that	O
figure	O
.	O
	
We	O
see	O
that	O
using	O
the	O
original	O
variance	O
,	O
the	O
network	O
generates	O
sharp	O
details	O
.	O
	
Because	O
the	O
generative	B-Method
model	I-Method
is	O
not	O
perfect	O
,	O
the	O
resulting	O
images	O
are	O
less	O
realistic	O
looking	O
as	O
we	O
lower	O
the	O
number	O
of	O
stored	O
time	O
steps	O
.	O
	
For	O
zero	O
variance	O
we	O
see	O
that	O
the	O
network	O
starts	O
with	O
rough	O
details	O
making	O
a	O
smooth	O
image	O
and	O
then	O
refines	O
it	O
with	O
more	O
time	O
steps	O
.	O
	
All	O
these	O
generations	O
are	O
produced	O
with	O
a	O
single	O
-	O
layer	O
convolutional	B-Method
DRAW	I-Method
,	O
and	O
thus	O
,	O
despite	O
being	O
single	O
-	O
layer	O
,	O
it	O
achieves	O
some	O
level	O
of	O
‘	O
conceptual	B-Task
compression	I-Task
’	O
by	O
first	O
capturing	O
the	O
global	O
structure	O
of	O
the	O
image	O
and	O
then	O
focusing	O
on	O
details	O
.	O
	
There	O
is	O
another	O
dimension	O
we	O
can	O
vary	O
for	O
lossy	B-Task
compression	I-Task
–	O
	
the	O
input	O
scale	O
introduced	O
in	O
subsection	O
[	O
reference	O
]	O
.	O
	
Even	O
if	O
we	O
store	O
all	O
the	O
latent	O
variables	O
(	O
but	O
not	O
the	O
input	O
bits	O
)	O
,	O
the	O
reconstructed	O
images	O
will	O
get	O
less	O
detailed	O
as	O
we	O
scale	O
down	O
the	O
input	O
cost	O
.	O
	
To	O
build	O
a	O
really	O
good	O
compressor	B-Method
,	O
at	O
each	O
compression	B-Metric
rate	I-Metric
,	O
we	O
need	O
to	O
find	O
which	O
of	O
the	O
networks	O
,	O
input	O
scales	O
and	O
number	O
of	O
time	O
steps	O
would	O
produce	O
visually	O
good	O
images	O
.	O
	
For	O
several	O
compression	B-Metric
levels	I-Metric
,	O
we	O
have	O
looked	O
at	O
images	O
produced	O
by	O
different	O
methods	O
and	O
selected	O
qualitatively	O
which	O
network	O
gave	O
the	O
best	O
looking	O
images	O
.	O
	
We	O
have	O
not	O
done	O
this	O
per	O
image	O
,	O
just	O
per	O
compression	B-Metric
level	I-Metric
.	O
	
We	O
then	O
display	O
compressed	O
images	O
that	O
we	O
have	O
not	O
seen	O
with	O
this	O
selection	O
.	O
	
We	O
compare	O
our	O
results	O
to	O
JPEG	B-Method
and	O
JPEG2000	O
compression	O
which	O
we	O
obtained	O
using	O
ImageMagick	B-Material
.	O
	
We	O
found	O
however	O
that	O
these	O
compressors	B-Method
are	O
unable	O
to	O
produce	O
reasonable	O
results	O
for	O
small	O
images	O
(	O
)	O
at	O
high	O
compression	B-Metric
rates	I-Metric
.	O
	
Instead	O
,	O
we	O
concatenated	O
100	O
images	O
into	O
one	O
image	O
,	O
compressed	O
that	O
and	O
extracted	O
back	O
the	O
compressed	O
small	O
images	O
.	O
	
The	O
number	O
of	O
bits	O
per	O
image	O
reported	O
is	O
then	O
the	O
number	O
of	O
bits	O
of	O
this	O
image	O
divided	O
by	O
100	O
.	O
	
This	O
is	O
actually	O
unfair	O
to	O
our	O
algorithm	O
since	O
any	O
correlations	O
between	O
nearby	O
images	O
can	O
be	O
exploited	O
.	O
	
Nevertheless	O
we	O
show	O
the	O
comparison	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Our	O
algorithm	O
shows	O
better	O
quality	B-Metric
than	O
JPEG	B-Method
and	O
JPEG	B-Method
2000	O
at	O
all	O
levels	O
where	O
a	O
corruption	O
is	O
easily	O
detectable	O
.	O
	
Note	O
that	O
even	O
when	O
our	O
algorithm	O
is	O
trained	O
on	O
one	O
specific	O
image	O
size	O
,	O
it	O
can	O
be	O
used	O
on	O
arbitrarily	O
sized	O
images	O
for	O
those	O
networks	O
that	O
contain	O
only	O
convolutional	B-Method
operators	I-Method
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
paper	O
,	O
we	O
introduced	O
convolutional	B-Method
DRAW	I-Method
,	O
a	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
generative	B-Method
model	I-Method
which	O
demonstrates	O
the	O
potential	O
of	O
sequential	B-Method
computation	I-Method
and	O
recurrent	B-Method
neural	I-Method
networks	I-Method
in	O
scaling	O
up	O
latent	B-Method
variable	I-Method
models	I-Method
.	O
	
During	O
inference	B-Task
,	O
the	O
algorithm	O
sequentially	O
arrives	O
at	O
a	O
natural	O
stratification	O
of	O
information	O
,	O
ranging	O
from	O
global	O
aspects	O
to	O
low	O
-	O
level	O
details	O
.	O
	
An	O
interesting	O
feature	O
of	O
the	O
method	O
is	O
that	O
,	O
when	O
we	O
restrict	O
ourselves	O
to	O
storing	O
just	O
the	O
high	O
level	O
latent	O
variables	O
,	O
we	O
arrive	O
at	O
a	O
‘	O
conceptual	B-Method
compression	I-Method
’	I-Method
algorithm	I-Method
that	O
rivals	O
the	O
quality	B-Metric
of	O
JPEG2000	B-Method
.	O
	
As	O
a	O
generative	B-Method
model	I-Method
,	O
it	O
outperforms	O
earlier	O
latent	B-Method
variable	I-Method
models	I-Method
on	O
both	O
the	O
Omniglot	B-Material
and	O
ImageNet	B-Material
datasets	I-Material
.	O
	
section	O
:	O
Acknowledgements	O
	
We	O
thank	O
Aaron	O
van	O
den	O
Oord	O
,	O
Diederik	O
Kingma	O
and	O
Koray	O
Kavukcuoglu	O
for	O
fruitful	O
discussions	O
.	O
	
bibliography	O
:	O
References	O
	
section	O
:	O
Appendix	O
	
Figures	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
show	O
image	O
generations	O
for	O
input	O
scaling	O
and	O
of	O
(	O
[	O
reference	O
]	O
)	O
,	O
while	O
Figures	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
show	O
generations	O
,	O
also	O
for	O
and	O
.	O
	
document	O
:	O
SegNet	B-Method
:	O
A	O
Deep	B-Method
Convolutional	I-Method
Encoder	I-Method
-	I-Method
Decoder	I-Method
Architecture	I-Method
for	O
Image	B-Task
Segmentation	I-Task
	
We	O
present	O
a	O
novel	O
and	O
practical	O
deep	B-Method
fully	I-Method
convolutional	I-Method
neural	I-Method
network	I-Method
architecture	I-Method
for	O
semantic	B-Task
pixel	I-Task
-	I-Task
wise	I-Task
segmentation	I-Task
termed	O
SegNet	B-Task
.	O
	
This	O
core	B-Method
trainable	I-Method
segmentation	I-Method
engine	I-Method
consists	O
of	O
an	O
encoder	B-Method
network	I-Method
,	O
a	O
corresponding	O
decoder	B-Method
network	I-Method
followed	O
by	O
a	O
pixel	B-Method
-	I-Method
wise	I-Method
classification	I-Method
layer	I-Method
.	O
	
The	O
architecture	O
of	O
the	O
encoder	B-Method
network	I-Method
is	O
topologically	O
identical	O
to	O
the	O
13	O
convolutional	B-Method
layers	I-Method
in	O
the	O
VGG16	B-Method
network	I-Method
.	O
	
The	O
role	O
of	O
the	O
decoder	B-Method
network	I-Method
is	O
to	O
map	O
the	O
low	O
resolution	O
encoder	O
feature	O
maps	O
to	O
full	O
input	O
resolution	O
feature	O
maps	O
for	O
pixel	B-Task
-	I-Task
wise	I-Task
classification	I-Task
.	O
	
The	O
novelty	O
of	O
SegNet	B-Method
lies	O
is	O
in	O
the	O
manner	O
in	O
which	O
the	O
decoder	O
upsamples	O
its	O
lower	O
resolution	O
input	O
feature	O
map	O
(	O
s	O
)	O
.	O
	
Specifically	O
,	O
the	O
decoder	B-Method
uses	O
pooling	O
indices	O
computed	O
in	O
the	O
max	B-Method
-	I-Method
pooling	I-Method
step	I-Method
of	O
the	O
corresponding	O
encoder	O
to	O
perform	O
non	B-Task
-	I-Task
linear	I-Task
upsampling	I-Task
.	O
	
This	O
eliminates	O
the	O
need	O
for	O
learning	O
to	O
upsample	O
.	O
	
The	O
upsampled	O
maps	O
are	O
sparse	O
and	O
are	O
then	O
convolved	O
with	O
trainable	B-Method
filters	I-Method
to	O
produce	O
dense	O
feature	O
maps	O
.	O
	
We	O
compare	O
our	O
proposed	O
architecture	O
with	O
the	O
widely	O
adopted	O
FCN	B-Method
and	O
also	O
with	O
the	O
well	O
known	O
DeepLab	B-Method
-	I-Method
LargeFOV	I-Method
,	I-Method
DeconvNet	I-Method
architectures	I-Method
.	O
	
This	O
comparison	O
reveals	O
the	O
memory	B-Metric
versus	I-Metric
accuracy	I-Metric
trade	I-Metric
-	I-Metric
off	I-Metric
involved	O
in	O
achieving	O
good	O
segmentation	B-Task
performance	O
.	O
	
SegNet	B-Method
was	O
primarily	O
motivated	O
by	O
scene	B-Task
understanding	I-Task
applications	I-Task
.	O
	
Hence	O
,	O
it	O
is	O
designed	O
to	O
be	O
efficient	O
both	O
in	O
terms	O
of	O
memory	B-Metric
and	O
computational	B-Metric
time	I-Metric
during	O
inference	B-Task
.	O
	
It	O
is	O
also	O
significantly	O
smaller	O
in	O
the	O
number	O
of	O
trainable	O
parameters	O
than	O
other	O
competing	O
architectures	O
and	O
can	O
be	O
trained	O
end	O
-	O
to	O
-	O
end	O
using	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
.	O
	
We	O
also	O
performed	O
a	O
controlled	O
benchmark	O
of	O
SegNet	B-Method
and	O
other	O
architectures	O
on	O
both	O
road	B-Task
scenes	I-Task
and	O
SUN	B-Task
RGB	I-Task
-	I-Task
D	I-Task
indoor	I-Task
scene	I-Task
segmentation	I-Task
tasks	I-Task
.	O
	
These	O
quantitative	O
assessments	O
show	O
that	O
SegNet	B-Method
provides	O
good	O
performance	O
with	O
competitive	B-Metric
inference	I-Metric
time	I-Metric
and	O
most	O
efficient	O
inference	B-Metric
memory	I-Metric
-	I-Metric
wise	I-Metric
as	O
compared	O
to	O
other	O
architectures	O
.	O
	
We	O
also	O
provide	O
a	O
Caffe	B-Method
implementation	I-Method
of	O
SegNet	B-Method
and	O
a	O
web	B-Task
demo	I-Task
at	O
.	O
	
Deep	B-Method
Convolutional	I-Method
Neural	I-Method
Networks	I-Method
,	O
Semantic	B-Task
Pixel	I-Task
-	I-Task
Wise	I-Task
Segmentation	I-Task
,	O
Indoor	B-Task
Scenes	I-Task
,	O
Road	B-Task
Scenes	I-Task
,	O
Encoder	B-Method
,	O
Decoder	B-Method
,	O
Pooling	B-Task
,	O
Upsampling	B-Method
.	O
	
section	O
:	O
Introduction	O
	
Semantic	B-Task
segmentation	I-Task
has	O
a	O
wide	O
array	O
of	O
applications	O
ranging	O
from	O
scene	B-Task
understanding	I-Task
,	O
inferring	B-Task
support	I-Task
-	I-Task
relationships	I-Task
among	I-Task
objects	I-Task
to	O
autonomous	B-Task
driving	I-Task
.	O
	
Early	O
methods	O
that	O
relied	O
on	O
low	O
-	O
level	O
vision	O
cues	O
have	O
fast	O
been	O
superseded	O
by	O
popular	O
machine	B-Method
learning	I-Method
algorithms	I-Method
.	O
	
In	O
particular	O
,	O
deep	B-Method
learning	I-Method
has	O
seen	O
huge	O
success	O
lately	O
in	O
handwritten	B-Task
digit	I-Task
recognition	I-Task
,	O
speech	B-Task
,	O
categorising	B-Task
whole	I-Task
images	I-Task
and	O
detecting	B-Task
objects	I-Task
in	I-Task
images	I-Task
.	O
	
Now	O
there	O
is	O
an	O
active	O
interest	O
for	O
semantic	B-Task
pixel	I-Task
-	I-Task
wise	I-Task
labelling	I-Task
,	O
,	O
,	O
,	O
,	O
,	O
,	O
,	O
,	O
,	O
,	O
.	O
	
However	O
,	O
some	O
of	O
these	O
recent	O
approaches	O
have	O
tried	O
to	O
directly	O
adopt	O
deep	B-Method
architectures	I-Method
designed	O
for	O
category	B-Task
prediction	I-Task
to	O
pixel	B-Task
-	I-Task
wise	I-Task
labelling	I-Task
.	O
	
The	O
results	O
,	O
although	O
very	O
encouraging	O
,	O
appear	O
coarse	O
.	O
	
This	O
is	O
primarily	O
because	O
max	B-Method
pooling	I-Method
and	O
sub	B-Method
-	I-Method
sampling	I-Method
reduce	O
feature	B-Method
map	I-Method
resolution	I-Method
.	O
	
Our	O
motivation	O
to	O
design	O
SegNet	B-Method
arises	O
from	O
this	O
need	O
to	O
map	O
low	O
resolution	O
features	O
to	O
input	O
resolution	O
for	O
pixel	B-Task
-	I-Task
wise	I-Task
classification	I-Task
.	O
	
This	O
mapping	O
must	O
produce	O
features	O
which	O
are	O
useful	O
for	O
accurate	O
boundary	B-Task
localization	I-Task
.	O
	
Our	O
architecture	O
,	O
SegNet	B-Method
,	O
is	O
designed	O
to	O
be	O
an	O
efficient	O
architecture	O
for	O
pixel	B-Task
-	I-Task
wise	I-Task
semantic	I-Task
segmentation	I-Task
.	O
	
It	O
is	O
primarily	O
motivated	O
by	O
road	B-Task
scene	I-Task
understanding	I-Task
applications	I-Task
which	O
require	O
the	O
ability	O
to	O
model	O
appearance	O
(	O
road	O
,	O
building	O
)	O
,	O
shape	O
(	O
cars	O
,	O
pedestrians	O
)	O
and	O
understand	O
the	O
spatial	O
-	O
relationship	O
(	O
context	O
)	O
between	O
different	O
classes	O
such	O
as	O
road	O
and	O
side	O
-	O
walk	O
.	O
	
In	O
typical	O
road	B-Material
scenes	I-Material
,	O
the	O
majority	O
of	O
the	O
pixels	O
belong	O
to	O
large	O
classes	O
such	O
as	O
road	O
,	O
building	O
and	O
hence	O
the	O
network	O
must	O
produce	O
smooth	B-Task
segmentations	I-Task
.	O
	
The	O
engine	O
must	O
also	O
have	O
the	O
ability	O
to	O
delineate	O
objects	O
based	O
on	O
their	O
shape	O
despite	O
their	O
small	O
size	O
.	O
	
Hence	O
it	O
is	O
important	O
to	O
retain	O
boundary	O
information	O
in	O
the	O
extracted	O
image	B-Method
representation	I-Method
.	O
	
From	O
a	O
computational	O
perspective	O
,	O
it	O
is	O
necessary	O
for	O
the	O
network	O
to	O
be	O
efficient	O
in	O
terms	O
of	O
both	O
memory	B-Metric
and	I-Metric
computation	I-Metric
time	I-Metric
during	O
inference	B-Task
.	O
	
The	O
ability	O
to	O
train	O
end	O
-	O
to	O
-	O
end	O
in	O
order	O
to	O
jointly	O
optimise	O
all	O
the	O
weights	O
in	O
the	O
network	O
using	O
an	O
efficient	O
weight	B-Method
update	I-Method
technique	I-Method
such	O
as	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
(	O
SGD	B-Method
)	I-Method
is	O
an	O
additional	O
benefit	O
since	O
it	O
is	O
more	O
easily	O
repeatable	O
.	O
	
The	O
design	O
of	O
SegNet	B-Task
arose	O
from	O
a	O
need	O
to	O
match	O
these	O
criteria	O
.	O
	
The	O
encoder	B-Method
network	I-Method
in	O
SegNet	B-Method
is	O
topologically	O
identical	O
to	O
the	O
convolutional	B-Method
layers	I-Method
in	O
VGG16	B-Method
.	O
	
We	O
remove	O
the	O
fully	B-Method
connected	I-Method
layers	I-Method
of	O
VGG16	B-Method
which	O
makes	O
the	O
SegNet	B-Method
encoder	I-Method
network	I-Method
significantly	O
smaller	O
and	O
easier	O
to	O
train	O
than	O
many	O
other	O
recent	O
architectures	O
.	O
	
The	O
key	O
component	O
of	O
SegNet	B-Method
is	O
the	O
decoder	B-Method
network	I-Method
which	O
consists	O
of	O
a	O
hierarchy	O
of	O
decoders	O
one	O
corresponding	O
to	O
each	O
encoder	O
.	O
	
Of	O
these	O
,	O
the	O
appropriate	O
decoders	B-Method
use	O
the	O
max	O
-	O
pooling	O
indices	O
received	O
from	O
the	O
corresponding	O
encoder	B-Method
to	O
perform	O
non	B-Method
-	I-Method
linear	I-Method
upsampling	I-Method
of	O
their	O
input	O
feature	O
maps	O
.	O
	
This	O
idea	O
was	O
inspired	O
from	O
an	O
architecture	O
designed	O
for	O
unsupervised	B-Task
feature	I-Task
learning	I-Task
.	O
	
Reusing	O
max	O
-	O
pooling	O
indices	O
in	O
the	O
decoding	B-Method
process	I-Method
has	O
several	O
practical	O
advantages	O
;	O
(	O
i	O
)	O
it	O
improves	O
boundary	B-Task
delineation	I-Task
,	O
(	O
ii	O
)	O
it	O
reduces	O
the	O
number	O
of	O
parameters	O
enabling	O
end	O
-	O
to	O
-	O
end	B-Task
training	I-Task
,	O
and	O
(	O
iii	O
)	O
this	O
form	O
of	O
upsampling	B-Method
can	O
be	O
incorporated	O
into	O
any	O
encoder	B-Method
-	I-Method
decoder	I-Method
architecture	I-Method
such	O
as	O
with	O
only	O
a	O
little	O
modification	O
.	O
	
One	O
of	O
the	O
main	O
contributions	O
of	O
this	O
paper	O
is	O
our	O
analysis	O
of	O
the	O
SegNet	B-Method
decoding	I-Method
technique	I-Method
and	O
the	O
widely	O
used	O
Fully	B-Method
Convolutional	I-Method
Network	I-Method
(	O
FCN	B-Method
)	O
.	O
	
This	O
is	O
in	O
order	O
to	O
convey	O
the	O
practical	O
trade	O
-	O
offs	O
involved	O
in	O
designing	O
segmentation	B-Method
architectures	I-Method
.	O
	
Most	O
recent	O
deep	B-Method
architectures	I-Method
for	O
segmentation	B-Task
have	O
identical	O
encoder	B-Method
networks	I-Method
,	O
i.e	O
VGG16	B-Method
,	O
but	O
differ	O
in	O
the	O
form	O
of	O
the	O
decoder	B-Method
network	I-Method
,	O
training	O
and	O
inference	B-Task
.	O
	
Another	O
common	O
feature	O
is	O
they	O
have	O
trainable	O
parameters	O
in	O
the	O
order	O
of	O
hundreds	O
of	O
millions	O
and	O
thus	O
encounter	O
difficulties	O
in	O
performing	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
training	I-Task
.	O
	
The	O
difficulty	O
of	O
training	O
these	O
networks	O
has	O
led	O
to	O
multi	B-Task
-	I-Task
stage	I-Task
training	I-Task
,	O
appending	O
networks	O
to	O
a	O
pre	B-Method
-	I-Method
trained	I-Method
architecture	I-Method
such	O
as	O
FCN	B-Method
,	O
use	O
of	O
supporting	B-Method
aids	I-Method
such	O
as	O
region	B-Method
proposals	I-Method
for	O
inference	B-Task
,	O
disjoint	O
training	O
of	O
classification	B-Method
and	I-Method
segmentation	I-Method
networks	I-Method
and	O
use	O
of	O
additional	O
training	O
data	O
for	O
pre	O
-	O
training	B-Task
or	O
for	O
full	B-Task
training	I-Task
.	O
	
In	O
addition	O
,	O
performance	O
boosting	B-Method
post	I-Method
-	I-Method
processing	I-Method
techniques	I-Method
have	O
also	O
been	O
popular	O
.	O
	
Although	O
all	O
these	O
factors	O
improve	O
performance	O
on	O
challenging	O
benchmarks	O
,	O
it	O
is	O
unfortunately	O
difficult	O
from	O
their	O
quantitative	O
results	O
to	O
disentangle	O
the	O
key	O
design	O
factors	O
necessary	O
to	O
achieve	O
good	O
performance	O
.	O
	
We	O
therefore	O
analysed	O
the	O
decoding	B-Method
process	I-Method
used	O
in	O
some	O
of	O
these	O
approaches	O
and	O
reveal	O
their	O
pros	O
and	O
cons	O
.	O
	
We	O
evaluate	O
the	O
performance	O
of	O
SegNet	B-Method
on	O
two	O
scene	B-Task
segmentation	I-Task
tasks	I-Task
,	O
CamVid	B-Task
road	I-Task
scene	I-Task
segmentation	I-Task
and	O
SUN	B-Task
RGB	I-Task
-	I-Task
D	I-Task
indoor	I-Task
scene	I-Task
segmentation	I-Task
.	O
	
Pascal	B-Material
VOC12	I-Material
has	O
been	O
the	O
benchmark	O
challenge	O
for	O
segmentation	B-Task
over	O
the	O
years	O
.	O
	
However	O
,	O
the	O
majority	O
of	O
this	O
task	O
has	O
one	O
or	O
two	O
foreground	O
classes	O
surrounded	O
by	O
a	O
highly	O
varied	O
background	O
.	O
	
This	O
implicitly	O
favours	O
techniques	O
used	O
for	O
detection	B-Task
as	O
shown	O
by	O
the	O
recent	O
work	O
on	O
a	O
decoupled	B-Method
classification	I-Method
-	I-Method
segmentation	I-Method
network	I-Method
where	O
the	O
classification	B-Method
network	I-Method
can	O
be	O
trained	O
with	O
a	O
large	O
set	O
of	O
weakly	B-Material
labelled	I-Material
data	I-Material
and	O
the	O
independent	B-Method
segmentation	I-Method
network	I-Method
performance	O
is	O
improved	O
.	O
	
The	O
method	O
of	O
also	O
use	O
the	O
feature	O
maps	O
of	O
the	O
classification	B-Method
network	I-Method
with	O
an	O
independent	O
CRF	B-Method
post	I-Method
-	I-Method
processing	I-Method
technique	I-Method
to	O
perform	O
segmentation	B-Task
.	O
	
The	O
performance	O
can	O
also	O
be	O
boosted	O
by	O
the	O
use	O
additional	O
inference	O
aids	O
such	O
as	O
region	B-Method
proposals	I-Method
,	O
.	O
	
Therefore	O
,	O
it	O
is	O
different	O
from	O
scene	B-Task
understanding	I-Task
where	O
the	O
idea	O
is	O
to	O
exploit	O
co	O
-	O
occurrences	O
of	O
objects	O
and	O
other	O
spatial	O
-	O
context	O
to	O
perform	O
robust	B-Task
segmentation	I-Task
.	O
	
To	O
demonstrate	O
the	O
efficacy	O
of	O
SegNet	B-Method
,	O
we	O
present	O
a	O
real	B-Task
-	I-Task
time	I-Task
online	I-Task
demo	I-Task
of	I-Task
road	I-Task
scene	I-Task
segmentation	I-Task
into	O
11	O
classes	O
of	O
interest	O
for	O
autonomous	B-Task
driving	I-Task
(	O
see	O
link	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
Some	O
example	O
test	O
results	O
produced	O
on	O
randomly	B-Material
sampled	I-Material
road	I-Material
scene	I-Material
images	I-Material
from	O
Google	B-Material
and	I-Material
indoor	I-Material
test	I-Material
scenes	I-Material
from	O
the	O
SUN	B-Material
RGB	I-Material
-	I-Material
D	I-Material
dataset	I-Material
are	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
The	O
remainder	O
of	O
the	O
paper	O
is	O
organized	O
as	O
follows	O
.	O
	
In	O
Sec	O
.	O
	
[	O
reference	O
]	O
	
we	O
review	O
related	O
recent	O
literature	O
.	O
	
We	O
describe	O
the	O
SegNet	B-Method
architecture	I-Method
and	O
its	O
analysis	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
.	O
	
In	O
Sec	O
.	O
	
[	O
reference	O
]	O
	
we	O
evaluate	O
the	O
performance	O
of	O
SegNet	B-Task
on	O
outdoor	B-Material
and	I-Material
indoor	I-Material
scene	I-Material
datasets	I-Material
.	O
	
This	O
is	O
followed	O
by	O
a	O
general	O
discussion	O
regarding	O
our	O
approach	O
with	O
pointers	O
to	O
future	O
work	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
.	O
	
We	O
conclude	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
.	O
	
section	O
:	O
Literature	O
Review	O
	
Semantic	B-Task
pixel	I-Task
-	I-Task
wise	I-Task
segmentation	I-Task
is	O
an	O
active	O
topic	O
of	O
research	O
,	O
fuelled	O
by	O
challenging	O
datasets	O
.	O
	
Before	O
the	O
arrival	O
of	O
deep	B-Method
networks	I-Method
,	O
the	O
best	O
performing	O
methods	O
mostly	O
relied	O
on	O
hand	O
engineered	O
features	O
classifying	O
pixels	O
independently	O
.	O
	
Typically	O
,	O
a	O
patch	O
is	O
fed	O
into	O
a	O
classifier	B-Method
e.g.	O
Random	B-Method
Forest	I-Method
or	O
Boosting	B-Method
to	O
predict	O
the	O
class	O
probabilities	O
of	O
the	O
center	O
pixel	O
.	O
	
Features	O
based	O
on	O
appearance	O
or	O
SfM	B-Method
and	I-Method
appearance	I-Method
have	O
been	O
explored	O
for	O
the	O
CamVid	B-Task
road	I-Task
scene	I-Task
understanding	I-Task
test	I-Task
.	O
	
These	O
per	O
-	O
pixel	O
noisy	O
predictions	O
(	O
often	O
called	O
unary	O
terms	O
)	O
from	O
the	O
classifiers	B-Method
are	O
then	O
smoothed	O
by	O
using	O
a	O
pair	O
-	O
wise	O
or	O
higher	B-Method
order	I-Method
CRF	I-Method
to	O
improve	O
the	O
accuracy	B-Metric
.	O
	
More	O
recent	O
approaches	O
have	O
aimed	O
to	O
produce	O
high	O
quality	O
unaries	O
by	O
trying	O
to	O
predict	O
the	O
labels	O
for	O
all	O
the	O
pixels	O
in	O
a	O
patch	O
as	O
opposed	O
to	O
only	O
the	O
center	O
pixel	O
.	O
	
This	O
improves	O
the	O
results	O
of	O
Random	B-Method
Forest	I-Method
based	I-Method
unaries	I-Method
but	O
thin	O
structured	O
classes	O
are	O
classified	O
poorly	O
.	O
	
Dense	O
depth	O
maps	O
computed	O
from	O
the	O
CamVid	B-Material
video	I-Material
have	O
also	O
been	O
used	O
as	O
input	O
for	O
classification	B-Task
using	O
Random	B-Method
Forests	I-Method
.	O
	
Another	O
approach	O
argues	O
for	O
the	O
use	O
of	O
a	O
combination	O
of	O
popular	O
hand	O
designed	O
features	O
and	O
spatio	B-Method
-	I-Method
temporal	I-Method
super	I-Method
-	I-Method
pixelization	I-Method
to	O
obtain	O
higher	O
accuracy	B-Metric
.	O
	
The	O
best	O
performing	O
technique	O
on	O
the	O
CamVid	B-Material
test	I-Material
addresses	O
the	O
imbalance	O
among	O
label	O
frequencies	O
by	O
combining	O
object	O
detection	O
outputs	O
with	O
classifier	B-Method
predictions	I-Method
in	O
a	O
CRF	B-Method
framework	I-Method
.	O
	
The	O
result	O
of	O
all	O
these	O
techniques	O
indicate	O
the	O
need	O
for	O
improved	O
features	O
for	O
classification	B-Task
.	O
	
Indoor	B-Task
RGBD	I-Task
pixel	I-Task
-	I-Task
wise	I-Task
semantic	I-Task
segmentation	I-Task
has	O
also	O
gained	O
popularity	O
since	O
the	O
release	O
of	O
the	O
NYU	B-Material
dataset	I-Material
.	O
	
This	O
dataset	O
showed	O
the	O
usefulness	O
of	O
the	O
depth	O
channel	O
to	O
improve	O
segmentation	B-Task
.	O
	
Their	O
approach	O
used	O
features	O
such	O
as	O
RGB	O
-	O
SIFT	O
,	O
depth	O
-	O
SIFT	O
and	O
pixel	O
location	O
as	O
input	O
to	O
a	O
neural	B-Method
network	I-Method
classifier	I-Method
to	O
predict	O
pixel	O
unaries	O
.	O
	
The	O
noisy	O
unaries	O
are	O
then	O
smoothed	O
using	O
a	O
CRF	B-Method
.	O
	
Improvements	O
were	O
made	O
using	O
a	O
richer	O
feature	O
set	O
including	O
LBP	B-Method
and	O
region	B-Method
segmentation	I-Method
to	O
obtain	O
higher	O
accuracy	B-Metric
followed	O
by	O
a	O
CRF	B-Method
.	O
	
In	O
more	O
recent	O
work	O
,	O
both	O
class	B-Task
segmentation	I-Task
and	O
support	O
relationships	O
are	O
inferred	O
together	O
using	O
a	O
combination	O
of	O
RGB	O
and	O
depth	O
based	O
cues	O
.	O
	
Another	O
approach	O
focuses	O
on	O
real	B-Task
-	I-Task
time	I-Task
joint	I-Task
reconstruction	I-Task
and	I-Task
semantic	I-Task
segmentation	I-Task
,	O
where	O
Random	B-Method
Forests	I-Method
are	O
used	O
as	O
the	O
classifier	B-Method
.	O
	
Gupta	O
et	O
al	O
.	O
	
use	O
boundary	B-Method
detection	I-Method
and	O
hierarchical	B-Method
grouping	I-Method
before	O
performing	O
category	B-Task
segmentation	I-Task
.	O
	
The	O
common	O
attribute	O
in	O
all	O
these	O
approaches	O
is	O
the	O
use	O
of	O
hand	O
engineered	O
features	O
for	O
classification	B-Task
of	I-Task
either	O
RGB	B-Material
or	I-Material
RGBD	I-Material
images	I-Material
.	O
	
The	O
success	O
of	O
deep	B-Method
convolutional	I-Method
neural	I-Method
networks	I-Method
for	O
object	B-Task
classification	I-Task
has	O
more	O
recently	O
led	O
researchers	O
to	O
exploit	O
their	O
feature	B-Method
learning	I-Method
capabilities	I-Method
for	O
structured	B-Task
prediction	I-Task
problems	I-Task
such	O
as	O
segmentation	B-Task
.	O
	
There	O
have	O
also	O
been	O
attempts	O
to	O
apply	O
networks	B-Method
designed	O
for	O
object	B-Task
categorization	I-Task
to	O
segmentation	B-Task
,	O
particularly	O
by	O
replicating	O
the	O
deepest	O
layer	O
features	O
in	O
blocks	O
to	O
match	O
image	O
dimensions	O
.	O
	
However	O
,	O
the	O
resulting	O
classification	B-Task
is	O
blocky	O
.	O
	
Another	O
approach	O
using	O
recurrent	B-Method
neural	I-Method
networks	I-Method
merges	O
several	O
low	B-Method
resolution	I-Method
predictions	I-Method
to	O
create	O
input	O
image	O
resolution	O
predictions	O
.	O
	
These	O
techniques	O
are	O
already	O
an	O
improvement	O
over	O
hand	O
engineered	O
features	O
but	O
their	O
ability	O
to	O
delineate	O
boundaries	O
is	O
poor	O
.	O
	
Newer	O
deep	B-Method
architectures	I-Method
particularly	O
designed	O
for	O
segmentation	B-Task
have	O
advanced	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
by	O
learning	O
to	O
decode	O
or	O
map	O
low	B-Task
resolution	I-Task
image	I-Task
representations	I-Task
to	O
pixel	B-Task
-	I-Task
wise	I-Task
predictions	I-Task
.	O
	
The	O
encoder	B-Method
network	I-Method
which	O
produces	O
these	O
low	B-Method
resolution	I-Method
representations	I-Method
in	O
all	O
of	O
these	O
architectures	O
is	O
the	O
VGG16	B-Method
classification	I-Method
network	I-Method
which	O
has	O
convolutional	B-Method
layers	I-Method
and	O
fully	B-Method
connected	I-Method
layers	I-Method
.	O
	
This	O
encoder	B-Method
network	I-Method
weights	I-Method
are	O
typically	O
pre	O
-	O
trained	O
on	O
the	O
large	O
ImageNet	B-Material
object	I-Material
classification	I-Material
dataset	I-Material
.	O
	
The	O
decoder	B-Method
network	I-Method
varies	O
between	O
these	O
architectures	O
and	O
is	O
the	O
part	O
which	O
is	O
responsible	O
for	O
producing	O
multi	O
-	O
dimensional	O
features	O
for	O
each	O
pixel	O
for	O
classification	B-Task
.	O
	
Each	O
decoder	O
in	O
the	O
Fully	B-Method
Convolutional	I-Method
Network	I-Method
(	I-Method
FCN	I-Method
)	I-Method
architecture	I-Method
learns	O
to	O
upsample	O
its	O
input	O
feature	O
map	O
(	O
s	O
)	O
and	O
combines	O
them	O
with	O
the	O
corresponding	O
encoder	O
feature	O
map	O
to	O
produce	O
the	O
input	O
to	O
the	O
next	O
decoder	O
.	O
	
It	O
is	O
an	O
architecture	O
which	O
has	O
a	O
large	O
number	O
of	O
trainable	O
parameters	O
in	O
the	O
encoder	B-Method
network	I-Method
(	O
134	O
M	O
)	O
but	O
a	O
very	O
small	O
decoder	B-Method
network	I-Method
(	O
0.5	O
M	O
)	O
.	O
	
The	O
overall	O
large	O
size	O
of	O
this	O
network	O
makes	O
it	O
hard	O
to	O
train	O
end	O
-	O
to	O
-	O
end	O
on	O
a	O
relevant	O
task	O
.	O
	
Therefore	O
,	O
the	O
authors	O
use	O
a	O
stage	B-Method
-	I-Method
wise	I-Method
training	I-Method
process	I-Method
.	O
	
Here	O
each	O
decoder	O
in	O
the	O
decoder	B-Method
network	I-Method
is	O
progressively	O
added	O
to	O
an	O
existing	O
trained	B-Method
network	I-Method
.	O
	
The	O
network	O
is	O
grown	O
until	O
no	O
further	O
increase	O
in	O
performance	O
is	O
observed	O
.	O
	
This	O
growth	O
is	O
stopped	O
after	O
three	O
decoders	O
thus	O
ignoring	O
high	O
resolution	O
feature	O
maps	O
can	O
certainly	O
lead	O
to	O
loss	O
of	O
edge	O
information	O
.	O
	
Apart	O
from	O
training	O
related	O
issues	O
,	O
the	O
need	O
to	O
reuse	O
the	O
encoder	O
feature	O
maps	O
in	O
the	O
decoder	B-Method
makes	O
it	O
memory	O
intensive	O
in	O
test	O
time	O
.	O
	
We	O
study	O
this	O
network	O
in	O
more	O
detail	O
as	O
it	O
the	O
core	O
of	O
other	O
recent	O
architectures	O
.	O
	
The	O
predictive	B-Task
performance	O
of	O
FCN	B-Method
has	O
been	O
improved	O
further	O
by	O
appending	O
the	O
FCN	B-Method
with	O
a	O
recurrent	B-Method
neural	I-Method
network	I-Method
(	O
RNN	B-Method
)	O
and	O
fine	O
-	O
tuning	O
them	O
on	O
large	B-Material
datasets	I-Material
,	O
.	O
	
The	O
RNN	B-Method
layers	I-Method
mimic	O
the	O
sharp	O
boundary	O
delineation	O
capabilities	O
of	O
CRFs	B-Method
while	O
exploiting	O
the	O
feature	B-Method
representation	I-Method
power	I-Method
of	I-Method
FCN	I-Method
’s	I-Method
.	O
	
They	O
show	O
a	O
significant	O
improvement	O
over	O
FCN	B-Method
-	I-Method
8	I-Method
but	O
also	O
show	O
that	O
this	O
difference	O
is	O
reduced	O
when	O
more	O
training	O
data	O
is	O
used	O
to	O
train	O
	
FCN	B-Method
-	I-Method
8	I-Method
.	O
	
The	O
main	O
advantage	O
of	O
the	O
CRF	B-Method
-	I-Method
RNN	I-Method
is	O
revealed	O
when	O
it	O
is	O
jointly	O
trained	O
with	O
an	O
architecture	O
such	O
as	O
the	O
FCN	B-Method
-	I-Method
8	I-Method
.	O
	
The	O
fact	O
that	O
joint	B-Method
training	I-Method
helps	O
is	O
also	O
shown	O
in	O
other	O
recent	O
results	O
,	O
.	O
	
Interestingly	O
,	O
the	O
deconvolutional	B-Method
network	I-Method
performs	O
significantly	O
better	O
than	O
FCN	B-Method
although	O
at	O
the	O
cost	O
of	O
a	O
more	O
complex	O
training	B-Task
and	I-Task
inference	I-Task
.	O
	
This	O
however	O
raises	O
the	O
question	O
as	O
to	O
whether	O
the	O
perceived	O
advantage	O
of	O
the	O
CRF	B-Method
-	I-Method
RNN	I-Method
would	O
be	O
reduced	O
as	O
the	O
core	B-Method
feed	I-Method
-	I-Method
forward	I-Method
segmentation	I-Method
engine	I-Method
is	O
made	O
better	O
.	O
	
In	O
any	O
case	O
,	O
the	O
CRF	B-Method
-	I-Method
RNN	I-Method
network	I-Method
can	O
be	O
appended	O
to	O
any	O
deep	B-Method
segmentation	I-Method
architecture	I-Method
including	O
SegNet	B-Method
.	O
	
Multi	B-Method
-	I-Method
scale	I-Method
deep	I-Method
architectures	I-Method
are	O
also	O
being	O
pursued	O
.	O
	
They	O
come	O
in	O
two	O
flavours	O
,	O
(	O
i	O
)	O
those	O
which	O
use	O
input	O
images	O
at	O
a	O
few	O
scales	O
and	O
corresponding	O
deep	B-Method
feature	I-Method
extraction	I-Method
networks	I-Method
,	O
and	O
(	O
ii	O
)	O
those	O
which	O
combine	O
feature	O
maps	O
from	O
different	O
layers	O
of	O
a	O
single	O
deep	B-Method
architecture	I-Method
.	O
	
The	O
common	O
idea	O
is	O
to	O
use	O
features	O
extracted	O
at	O
multiple	O
scales	O
to	O
provide	O
both	O
local	O
and	O
global	O
context	O
and	O
the	O
using	O
feature	O
maps	O
of	O
the	O
early	B-Method
encoding	I-Method
layers	I-Method
retain	O
more	O
high	O
frequency	O
detail	O
leading	O
to	O
sharper	O
class	O
boundaries	O
.	O
	
Some	O
of	O
these	O
architectures	O
are	O
difficult	O
to	O
train	O
due	O
to	O
their	O
parameter	O
size	O
.	O
	
Thus	O
a	O
multi	B-Method
-	I-Method
stage	I-Method
training	I-Method
process	I-Method
is	O
employed	O
along	O
with	O
data	B-Task
augmentation	I-Task
.	O
	
The	O
inference	B-Task
is	O
also	O
expensive	O
with	O
multiple	O
convolutional	B-Method
pathways	I-Method
for	O
feature	B-Task
extraction	I-Task
.	O
	
Others	O
append	O
a	O
CRF	B-Method
to	O
their	O
multi	B-Method
-	I-Method
scale	I-Method
network	I-Method
and	O
jointly	O
train	O
them	O
.	O
	
However	O
,	O
these	O
are	O
not	O
feed	O
-	O
forward	O
at	O
test	O
time	O
and	O
require	O
optimization	B-Task
to	O
determine	O
the	O
MAP	O
labels	O
.	O
	
Several	O
of	O
the	O
recently	O
proposed	O
deep	B-Method
architectures	I-Method
for	O
segmentation	B-Task
are	O
not	O
feed	O
-	O
forward	O
in	O
inference	B-Task
time	I-Task
,	O
,	O
.	O
	
They	O
require	O
either	O
MAP	B-Method
inference	I-Method
over	O
a	O
CRF	B-Method
,	O
or	O
aids	O
such	O
as	O
region	B-Method
proposals	I-Method
for	O
inference	B-Task
.	O
	
We	O
believe	O
the	O
perceived	O
performance	O
increase	O
obtained	O
by	O
using	O
a	O
CRF	B-Method
is	O
due	O
to	O
the	O
lack	O
of	O
good	O
decoding	B-Method
techniques	I-Method
in	O
their	O
core	O
feed	B-Method
-	I-Method
forward	I-Method
segmentation	I-Method
engine	I-Method
.	O
	
SegNet	B-Method
on	O
the	O
other	O
hand	O
uses	O
decoders	B-Method
to	O
obtain	O
features	O
for	O
accurate	O
pixel	B-Task
-	I-Task
wise	I-Task
classification	I-Task
.	O
	
The	O
recently	O
proposed	O
Deconvolutional	B-Method
Network	I-Method
and	O
its	O
semi	B-Method
-	I-Method
supervised	I-Method
variant	I-Method
the	O
Decoupled	B-Method
network	I-Method
use	O
the	O
max	O
locations	O
of	O
the	O
encoder	O
feature	O
maps	O
(	O
pooling	O
indices	O
)	O
to	O
perform	O
non	B-Method
-	I-Method
linear	I-Method
upsampling	I-Method
in	O
the	O
decoder	B-Method
network	I-Method
.	O
	
The	O
authors	O
of	O
these	O
architectures	O
,	O
independently	O
of	O
SegNet	B-Method
(	O
first	O
submitted	O
to	O
CVPR	O
2015	O
)	O
,	O
proposed	O
this	O
idea	O
of	O
decoding	B-Task
in	O
the	O
decoder	B-Method
network	I-Method
.	O
	
However	O
,	O
their	O
encoder	B-Method
network	I-Method
consists	O
of	O
the	O
fully	O
connected	O
layers	O
from	O
the	O
VGG	B-Method
-	I-Method
16	I-Method
network	I-Method
which	O
consists	O
of	O
about	O
of	O
the	O
parameters	O
of	O
their	O
entire	O
network	O
.	O
	
This	O
makes	O
training	O
of	O
their	O
network	O
very	O
difficult	O
and	O
thus	O
require	O
additional	O
aids	O
such	O
as	O
the	O
use	O
of	O
region	O
proposals	O
to	O
enable	O
training	B-Task
.	O
	
Moreover	O
,	O
during	O
inference	B-Task
these	O
proposals	O
are	O
used	O
and	O
this	O
increases	O
inference	B-Task
time	I-Task
significantly	O
.	O
	
From	O
a	O
benchmarking	O
point	O
of	O
view	O
,	O
this	O
also	O
makes	O
it	O
difficult	O
to	O
evaluate	O
the	O
performance	O
of	O
their	O
architecture	O
(	O
encoder	B-Method
-	I-Method
decoder	I-Method
network	I-Method
)	O
without	O
other	O
aids	O
.	O
	
In	O
this	O
work	O
we	O
discard	O
the	O
fully	B-Method
connected	I-Method
layers	I-Method
of	O
the	O
VGG16	B-Method
encoder	I-Method
network	I-Method
which	O
enables	O
us	O
to	O
train	O
the	O
network	O
using	O
the	O
relevant	O
training	O
set	O
using	O
SGD	B-Method
optimization	I-Method
.	O
	
Another	O
recent	O
method	O
shows	O
the	O
benefit	O
of	O
reducing	O
the	O
number	O
of	O
parameters	O
significantly	O
without	O
sacrificing	O
performance	O
,	O
reducing	O
memory	B-Metric
consumption	I-Metric
and	O
improving	O
inference	B-Metric
time	I-Metric
.	O
	
Our	O
work	O
was	O
inspired	O
by	O
the	O
unsupervised	B-Method
feature	I-Method
learning	I-Method
architecture	I-Method
proposed	O
by	O
Ranzato	O
et	O
al	O
.	O
.	O
	
The	O
key	O
learning	B-Method
module	I-Method
is	O
an	O
encoder	B-Method
-	I-Method
decoder	I-Method
network	I-Method
.	O
	
An	O
encoder	B-Method
consists	O
of	O
convolution	B-Method
with	O
a	O
filter	B-Method
bank	I-Method
,	O
element	B-Method
-	I-Method
wise	I-Method
tanh	I-Method
non	I-Method
-	I-Method
linearity	I-Method
,	O
max	B-Method
-	I-Method
pooling	I-Method
and	O
sub	B-Method
-	I-Method
sampling	I-Method
to	O
obtain	O
the	O
feature	O
maps	O
.	O
	
For	O
each	O
sample	O
,	O
the	O
indices	O
of	O
the	O
max	O
locations	O
computed	O
during	O
pooling	O
are	O
stored	O
and	O
passed	O
to	O
the	O
decoder	B-Method
.	O
	
The	O
decoder	O
upsamples	O
the	O
feature	O
maps	O
by	O
using	O
the	O
stored	O
pooled	O
indices	O
.	O
	
It	O
convolves	O
this	O
upsampled	B-Method
map	I-Method
using	O
a	O
trainable	B-Method
decoder	I-Method
filter	I-Method
bank	I-Method
to	O
reconstruct	O
the	O
input	O
image	O
.	O
	
This	O
architecture	O
was	O
used	O
for	O
unsupervised	B-Task
pre	I-Task
-	I-Task
training	I-Task
for	O
classification	B-Task
.	O
	
A	O
somewhat	O
similar	O
decoding	B-Method
technique	I-Method
is	O
used	O
for	O
visualizing	O
trained	B-Method
convolutional	I-Method
networks	I-Method
for	O
classification	B-Task
.	O
	
The	O
architecture	O
of	O
Ranzato	O
et	O
al	O
.	O
mainly	O
focused	O
on	O
layer	B-Method
-	I-Method
wise	I-Method
feature	I-Method
learning	I-Method
using	O
small	O
input	O
patches	O
.	O
	
This	O
was	O
extended	O
by	O
Kavukcuoglu	O
et	O
.	O
	
al	O
.	O
	
to	O
accept	O
full	O
image	O
sizes	O
as	O
input	O
to	O
learn	O
hierarchical	B-Method
encoders	I-Method
.	O
	
Both	O
these	O
approaches	O
however	O
did	O
not	O
attempt	O
to	O
use	O
deep	B-Method
encoder	I-Method
-	I-Method
decoder	I-Method
networks	I-Method
for	O
unsupervised	B-Task
feature	I-Task
training	I-Task
as	O
they	O
discarded	O
the	O
decoders	O
after	O
each	O
encoder	B-Method
training	I-Method
.	O
	
Here	O
,	O
SegNet	B-Method
differs	O
from	O
these	O
architectures	O
as	O
the	O
deep	B-Method
encoder	I-Method
-	I-Method
decoder	I-Method
network	I-Method
is	O
trained	O
jointly	O
for	O
a	O
supervised	B-Task
learning	I-Task
task	I-Task
and	O
hence	O
the	O
decoders	O
are	O
an	O
integral	O
part	O
of	O
the	O
network	O
in	O
test	O
time	O
.	O
	
Other	O
applications	O
where	O
pixel	B-Task
wise	I-Task
predictions	I-Task
are	O
made	O
using	O
deep	B-Method
networks	I-Method
are	O
image	B-Task
super	I-Task
-	I-Task
resolution	I-Task
and	O
depth	B-Task
map	I-Task
prediction	I-Task
from	O
a	O
single	O
image	O
.	O
	
The	O
authors	O
in	O
discuss	O
the	O
need	O
for	O
learning	B-Task
to	O
upsample	O
from	O
low	O
resolution	O
feature	O
maps	O
which	O
is	O
the	O
central	O
topic	O
of	O
this	O
paper	O
.	O
	
section	O
:	O
Architecture	O
	
SegNet	B-Method
has	O
an	O
encoder	B-Method
network	I-Method
and	O
a	O
corresponding	O
decoder	B-Method
network	I-Method
,	O
followed	O
by	O
a	O
final	O
pixelwise	B-Method
classification	I-Method
layer	I-Method
.	O
	
This	O
architecture	O
is	O
illustrated	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
The	O
encoder	B-Method
network	I-Method
consists	O
of	O
convolutional	B-Method
layers	I-Method
which	O
correspond	O
to	O
the	O
first	O
convolutional	B-Method
layers	I-Method
in	O
the	O
VGG16	B-Method
network	I-Method
designed	O
for	O
object	B-Task
classification	I-Task
.	O
	
We	O
can	O
therefore	O
initialize	O
the	O
training	B-Method
process	I-Method
from	O
weights	B-Method
trained	O
for	O
classification	B-Task
on	O
large	B-Material
datasets	I-Material
.	O
	
We	O
can	O
also	O
discard	O
the	O
fully	O
connected	O
layers	O
in	O
favour	O
of	O
retaining	O
higher	O
resolution	O
feature	O
maps	O
at	O
the	O
deepest	O
encoder	O
output	O
.	O
	
This	O
also	O
reduces	O
the	O
number	O
of	O
parameters	O
in	O
the	O
SegNet	B-Method
encoder	I-Method
network	I-Method
significantly	O
(	O
from	O
134	O
M	O
to	O
14.7	O
M	O
)	O
as	O
compared	O
to	O
other	O
recent	O
architectures	O
,	O
(	O
see	O
.	O
	
Table	O
[	O
reference	O
]	O
)	O
.	O
	
Each	O
encoder	B-Method
layer	I-Method
has	O
a	O
corresponding	O
decoder	O
layer	O
and	O
hence	O
the	O
decoder	B-Method
network	I-Method
has	O
layers	O
.	O
	
The	O
final	O
decoder	O
output	O
is	O
fed	O
to	O
a	O
multi	B-Method
-	I-Method
class	I-Method
soft	I-Method
-	I-Method
max	I-Method
classifier	I-Method
to	O
produce	O
class	O
probabilities	O
for	O
each	O
pixel	O
independently	O
.	O
	
Each	O
encoder	B-Method
in	O
the	O
encoder	B-Method
network	I-Method
performs	O
convolution	B-Method
with	O
a	O
filter	B-Method
bank	I-Method
to	O
produce	O
a	O
set	O
of	O
feature	O
maps	O
.	O
	
These	O
are	O
then	O
batch	O
normalized	O
,	O
)	O
.	O
	
Then	O
an	O
element	B-Method
-	I-Method
wise	I-Method
rectified	I-Method
-	I-Method
linear	I-Method
non	I-Method
-	I-Method
linearity	I-Method
(	I-Method
ReLU	I-Method
)	I-Method
is	O
applied	O
.	O
	
Following	O
that	O
,	O
max	B-Method
-	I-Method
pooling	I-Method
with	O
a	O
window	O
and	O
stride	O
(	O
non	O
-	O
overlapping	O
window	O
)	O
is	O
performed	O
and	O
the	O
resulting	O
output	O
is	O
sub	O
-	O
sampled	O
by	O
a	O
factor	O
of	O
.	O
	
Max	B-Method
-	I-Method
pooling	I-Method
is	O
used	O
to	O
achieve	O
translation	O
invariance	O
over	O
small	O
spatial	O
shifts	O
in	O
the	O
input	O
image	O
.	O
	
Sub	B-Method
-	I-Method
sampling	I-Method
results	O
in	O
a	O
large	O
input	O
image	O
context	O
(	O
spatial	O
window	O
)	O
for	O
each	O
pixel	O
in	O
the	O
feature	O
map	O
.	O
	
While	O
several	O
layers	O
of	O
max	B-Method
-	I-Method
pooling	I-Method
and	O
sub	B-Method
-	I-Method
sampling	I-Method
can	O
achieve	O
more	O
translation	O
invariance	O
for	O
robust	B-Task
classification	I-Task
correspondingly	O
there	O
is	O
a	O
loss	O
of	O
spatial	O
resolution	O
of	O
the	O
feature	O
maps	O
.	O
	
The	O
increasingly	O
lossy	B-Method
(	I-Method
boundary	I-Method
detail	I-Method
)	I-Method
image	I-Method
representation	I-Method
is	O
not	O
beneficial	O
for	O
segmentation	B-Task
where	O
boundary	B-Task
delineation	I-Task
is	O
vital	O
.	O
	
Therefore	O
,	O
it	O
is	O
necessary	O
to	O
capture	O
and	O
store	O
boundary	O
information	O
in	O
the	O
encoder	O
feature	O
maps	O
before	O
sub	B-Method
-	I-Method
sampling	I-Method
is	O
performed	O
.	O
	
If	O
memory	O
during	O
inference	B-Task
is	O
not	O
constrained	O
,	O
then	O
all	O
the	O
encoder	O
feature	O
maps	O
(	O
after	O
sub	B-Method
-	I-Method
sampling	I-Method
)	O
can	O
be	O
stored	O
.	O
	
This	O
is	O
usually	O
not	O
the	O
case	O
in	O
practical	O
applications	O
and	O
hence	O
we	O
propose	O
a	O
more	O
efficient	O
way	O
to	O
store	O
this	O
information	O
.	O
	
It	O
involves	O
storing	O
only	O
the	O
max	O
-	O
pooling	O
indices	O
,	O
i.e	O
,	O
the	O
locations	O
of	O
the	O
maximum	O
feature	O
value	O
in	O
each	O
pooling	O
window	O
is	O
memorized	O
for	O
each	O
encoder	O
feature	O
map	O
.	O
	
In	O
principle	O
,	O
this	O
can	O
be	O
done	O
using	O
2	O
bits	O
for	O
each	O
pooling	O
window	O
and	O
is	O
thus	O
much	O
more	O
efficient	O
to	O
store	O
as	O
compared	O
to	O
memorizing	O
feature	O
map	O
(	O
s	O
)	O
in	O
float	O
precision	O
.	O
	
As	O
we	O
show	O
later	O
in	O
this	O
work	O
,	O
this	O
lower	O
memory	O
storage	O
results	O
in	O
a	O
slight	O
loss	O
of	O
accuracy	B-Metric
but	O
is	O
still	O
suitable	O
for	O
practical	O
applications	O
.	O
	
The	O
appropriate	O
decoder	O
in	O
the	O
decoder	B-Method
network	I-Method
upsamples	O
its	O
input	O
feature	O
map	O
(	O
s	O
)	O
using	O
the	O
memorized	O
max	O
-	O
pooling	O
indices	O
from	O
the	O
corresponding	O
encoder	O
feature	O
map	O
(	O
s	O
)	O
.	O
	
This	O
step	O
produces	O
sparse	O
feature	O
map	O
(	O
s	O
)	O
.	O
	
This	O
SegNet	B-Method
decoding	I-Method
technique	I-Method
is	O
illustrated	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
These	O
feature	B-Method
maps	I-Method
are	O
then	O
convolved	O
with	O
a	O
trainable	B-Method
decoder	I-Method
filter	I-Method
bank	I-Method
to	O
produce	O
dense	O
feature	O
maps	O
.	O
	
A	O
batch	B-Method
normalization	I-Method
step	I-Method
is	O
then	O
applied	O
to	O
each	O
of	O
these	O
maps	O
.	O
	
Note	O
that	O
the	O
decoder	B-Method
corresponding	O
to	O
the	O
first	O
encoder	B-Method
(	O
closest	O
to	O
the	O
input	O
image	O
)	O
produces	O
a	O
multi	O
-	O
channel	O
feature	O
map	O
,	O
although	O
its	O
encoder	O
input	O
has	O
3	O
channels	O
(	O
RGB	O
)	O
.	O
	
This	O
is	O
unlike	O
the	O
other	O
decoders	B-Method
in	O
the	O
network	O
which	O
produce	O
feature	O
maps	O
with	O
the	O
same	O
number	O
of	O
size	O
and	O
channels	O
as	O
their	O
encoder	O
inputs	O
.	O
	
The	O
high	B-Method
dimensional	I-Method
feature	I-Method
representation	I-Method
at	O
the	O
output	O
of	O
the	O
final	O
decoder	B-Method
is	O
fed	O
to	O
a	O
trainable	O
soft	B-Method
-	I-Method
max	I-Method
classifier	I-Method
.	O
	
This	O
soft	B-Method
-	I-Method
max	I-Method
classifies	I-Method
each	O
pixel	O
independently	O
.	O
	
The	O
output	O
of	O
the	O
soft	B-Method
-	I-Method
max	I-Method
classifier	I-Method
is	O
a	O
K	O
channel	O
image	O
of	O
probabilities	O
where	O
K	O
is	O
the	O
number	O
of	O
classes	O
.	O
	
The	O
predicted	O
segmentation	O
corresponds	O
to	O
the	O
class	O
with	O
maximum	O
probability	O
at	O
each	O
pixel	O
.	O
	
We	O
add	O
here	O
that	O
two	O
other	O
architectures	O
,	O
DeconvNet	B-Method
and	O
U	B-Method
-	I-Method
Net	I-Method
share	O
a	O
similar	O
architecture	O
to	O
SegNet	B-Method
but	O
with	O
some	O
differences	O
.	O
	
DeconvNet	B-Method
has	O
a	O
much	O
larger	O
parameterization	O
,	O
needs	O
more	O
computational	O
resources	O
and	O
is	O
harder	O
to	O
train	O
end	O
-	O
to	O
-	O
end	O
(	O
Table	O
[	O
reference	O
]	O
)	O
,	O
primarily	O
due	O
to	O
the	O
use	O
of	O
fully	O
connected	O
layers	O
(	O
albeit	O
in	O
a	O
convolutional	B-Method
manner	I-Method
)	O
	
We	O
report	O
several	O
comparisons	O
with	O
DeconvNet	B-Method
later	O
in	O
the	O
paper	O
Sec	O
.	O
	
[	O
reference	O
]	O
.	O
	
As	O
compared	O
to	O
SegNet	B-Method
,	O
U	B-Method
-	I-Method
Net	I-Method
(	O
proposed	O
for	O
the	O
medical	B-Task
imaging	I-Task
community	I-Task
)	O
does	O
not	O
reuse	O
pooling	O
indices	O
but	O
instead	O
transfers	O
the	O
entire	O
feature	O
map	O
(	O
at	O
the	O
cost	O
of	O
more	O
memory	O
)	O
to	O
the	O
corresponding	O
decoders	B-Method
and	O
concatenates	O
them	O
to	O
upsampled	O
(	O
via	O
deconvolution	B-Method
)	I-Method
decoder	I-Method
feature	I-Method
maps	I-Method
.	O
	
There	O
is	O
no	O
conv5	O
and	O
max	O
-	O
pool	O
5	O
block	O
in	O
U	B-Method
-	I-Method
Net	I-Method
as	O
in	O
the	O
VGG	B-Method
net	I-Method
architecture	I-Method
.	O
	
SegNet	B-Method
,	O
on	O
the	O
other	O
hand	O
,	O
uses	O
all	O
of	O
the	O
pre	O
-	O
trained	O
convolutional	O
layer	O
weights	O
from	O
VGG	B-Method
net	I-Method
as	O
pre	O
-	O
trained	O
weights	O
.	O
	
subsection	O
:	O
Decoder	B-Method
Variants	I-Method
	
Many	O
segmentation	B-Method
architectures	I-Method
share	O
the	O
same	O
encoder	B-Method
network	I-Method
and	O
they	O
only	O
vary	O
in	O
the	O
form	O
of	O
their	O
decoder	B-Method
network	I-Method
.	O
	
Of	O
these	O
we	O
choose	O
to	O
compare	O
the	O
SegNet	B-Method
decoding	I-Method
technique	I-Method
with	O
the	O
widely	O
used	O
Fully	B-Method
Convolutional	I-Method
Network	I-Method
(	I-Method
FCN	I-Method
)	I-Method
decoding	I-Method
technique	I-Method
.	O
	
In	O
order	O
to	O
analyse	O
SegNet	B-Method
and	O
compare	O
its	O
performance	O
with	O
FCN	B-Method
(	I-Method
decoder	I-Method
variants	I-Method
)	O
we	O
use	O
a	O
smaller	O
version	O
of	O
SegNet	B-Method
,	O
termed	O
SegNet	B-Method
-	I-Method
Basic	I-Method
,	O
which	O
has	O
4	O
encoders	B-Method
and	O
4	O
decoders	B-Method
.	O
	
All	O
the	O
encoders	B-Method
in	O
SegNet	B-Method
-	I-Method
Basic	I-Method
perform	O
max	B-Method
-	I-Method
pooling	I-Method
and	O
sub	B-Method
-	I-Method
sampling	I-Method
and	O
the	O
corresponding	O
decoders	O
upsample	O
its	O
input	O
using	O
the	O
received	O
max	O
-	O
pooling	O
indices	O
.	O
	
Batch	B-Method
normalization	I-Method
is	O
used	O
after	O
each	O
convolutional	B-Method
layer	I-Method
in	O
both	O
the	O
encoder	B-Method
and	I-Method
decoder	I-Method
network	I-Method
.	O
	
No	O
biases	O
are	O
used	O
after	O
convolutions	B-Method
and	O
no	O
ReLU	B-Method
non	I-Method
-	I-Method
linearity	I-Method
is	O
present	O
in	O
the	O
decoder	B-Method
network	I-Method
.	O
	
Further	O
,	O
a	O
constant	O
kernel	O
size	O
of	O
over	O
all	O
the	O
encoder	B-Method
and	I-Method
decoder	I-Method
layers	I-Method
is	O
chosen	O
to	O
provide	O
a	O
wide	O
context	O
for	O
smooth	B-Task
labelling	I-Task
i.e.	O
a	O
pixel	O
in	O
the	O
deepest	O
layer	O
feature	O
map	O
(	O
layer	O
)	O
can	O
be	O
traced	O
back	O
to	O
a	O
context	O
window	O
in	O
the	O
input	O
image	O
of	O
pixels	O
.	O
	
This	O
small	O
size	O
of	O
SegNet	B-Method
-	I-Method
Basic	I-Method
allows	O
us	O
to	O
explore	O
many	O
different	O
variants	O
(	O
decoders	B-Method
)	O
and	O
train	O
them	O
in	O
reasonable	O
time	O
.	O
	
Similarly	O
we	O
create	O
FCN	B-Method
-	I-Method
Basic	I-Method
,	O
a	O
comparable	O
version	O
of	O
FCN	B-Method
for	O
our	O
analysis	O
which	O
shares	O
the	O
same	O
encoder	B-Method
network	I-Method
as	O
SegNet	B-Method
-	I-Method
Basic	I-Method
but	O
with	O
the	O
FCN	B-Method
decoding	I-Method
technique	I-Method
(	O
see	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
used	O
in	O
all	O
its	O
decoders	O
.	O
	
On	O
the	O
left	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
is	O
the	O
decoding	B-Method
technique	I-Method
used	O
by	O
SegNet	B-Method
(	O
also	O
SegNet	B-Method
-	I-Method
Basic	I-Method
)	O
,	O
where	O
there	O
is	O
no	O
learning	O
involved	O
in	O
the	O
upsampling	B-Method
step	I-Method
.	O
	
However	O
,	O
the	O
upsampled	O
maps	O
are	O
convolved	O
with	O
trainable	O
multi	B-Method
-	I-Method
channel	I-Method
decoder	I-Method
filters	I-Method
to	O
densify	O
its	O
sparse	O
inputs	O
.	O
	
Each	O
decoder	B-Method
filter	I-Method
has	O
the	O
same	O
number	O
of	O
channels	O
as	O
the	O
number	O
of	O
upsampled	O
feature	O
maps	O
.	O
	
A	O
smaller	O
variant	O
is	O
one	O
where	O
the	O
decoder	B-Method
filters	I-Method
are	O
single	O
channel	O
,	O
i.e	O
	
they	O
only	O
convolve	O
their	O
corresponding	O
upsampled	O
feature	O
map	O
.	O
	
This	O
variant	O
(	O
SegNet	B-Method
-	I-Method
Basic	I-Method
-	I-Method
SingleChannelDecoder	I-Method
)	O
reduces	O
the	O
number	O
of	O
trainable	O
parameters	O
and	O
inference	B-Metric
time	I-Metric
significantly	O
.	O
	
On	O
the	O
right	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
is	O
the	O
FCN	B-Method
(	O
also	O
FCN	B-Method
-	I-Method
Basic	I-Method
)	I-Method
decoding	I-Method
technique	I-Method
.	O
	
The	O
important	O
design	O
element	O
of	O
the	O
FCN	B-Method
model	I-Method
is	O
dimensionality	B-Method
reduction	I-Method
step	I-Method
of	O
the	O
encoder	B-Method
feature	I-Method
maps	I-Method
.	O
	
This	O
compresses	O
the	O
encoder	O
feature	O
maps	O
which	O
are	O
then	O
used	O
in	O
the	O
corresponding	O
decoders	B-Method
.	O
	
Dimensionality	B-Task
reduction	I-Task
of	O
the	O
encoder	B-Method
feature	I-Method
maps	I-Method
	
,	O
say	O
of	O
64	O
channels	O
,	O
is	O
performed	O
by	O
convolving	O
them	O
with	O
trainable	B-Method
filters	I-Method
,	O
where	O
is	O
the	O
number	O
of	O
classes	O
.	O
	
The	O
compressed	O
channel	O
final	O
encoder	O
layer	O
feature	O
maps	O
are	O
the	O
input	O
to	O
the	O
decoder	B-Method
network	I-Method
.	O
	
In	O
a	O
decoder	O
of	O
this	O
network	O
,	O
upsampling	B-Method
is	O
performed	O
by	O
inverse	B-Method
convolution	I-Method
using	O
a	O
fixed	B-Method
or	I-Method
trainable	I-Method
multi	I-Method
-	I-Method
channel	I-Method
upsampling	I-Method
kernel	I-Method
.	O
	
We	O
set	O
the	O
kernel	O
size	O
to	O
.	O
	
This	O
manner	O
of	O
upsampling	B-Task
is	O
also	O
termed	O
as	O
deconvolution	B-Task
.	O
	
Note	O
that	O
,	O
in	O
comparison	O
,	O
SegNet	B-Method
the	O
multi	B-Method
-	I-Method
channel	I-Method
convolution	I-Method
using	O
trainable	B-Method
decoder	I-Method
filters	I-Method
is	O
performed	O
after	O
upsampling	B-Method
to	O
densifying	O
feature	O
maps	O
.	O
	
The	O
upsampled	B-Method
feature	I-Method
map	I-Method
in	O
FCN	B-Method
has	O
channels	O
.	O
	
It	O
is	O
then	O
added	O
element	O
-	O
wise	O
to	O
the	O
corresponding	O
resolution	O
encoder	O
feature	O
map	O
to	O
produce	O
the	O
output	O
decoder	O
feature	O
map	O
.	O
	
The	O
upsampling	B-Method
kernels	I-Method
are	O
initialized	O
using	O
bilinear	B-Method
interpolation	I-Method
weights	I-Method
.	O
	
The	O
FCN	B-Method
decoder	I-Method
model	I-Method
requires	O
storing	O
encoder	O
feature	O
maps	O
during	O
inference	B-Task
.	O
	
This	O
can	O
be	O
memory	O
intensive	O
for	O
embedded	B-Task
applications	I-Task
;	O
for	O
e.g.	O
storing	O
64	O
feature	O
maps	O
of	O
the	O
first	O
layer	O
of	O
FCN	B-Method
-	I-Method
Basic	I-Method
at	O
resolution	O
in	O
32	O
bit	O
floating	O
point	O
precision	O
takes	O
11	O
MB	O
.	O
	
This	O
can	O
be	O
made	O
smaller	O
using	O
dimensionality	B-Method
reduction	I-Method
to	O
the	O
11	O
feature	O
maps	O
which	O
requires	O
1.9	O
MB	O
storage	O
.	O
	
SegNet	B-Method
on	O
the	O
other	O
hand	O
requires	O
almost	O
negligible	O
storage	B-Metric
cost	I-Metric
for	O
the	O
pooling	O
indices	O
(	O
MB	O
if	O
stored	O
using	O
2	O
bits	O
per	O
pooling	O
window	O
)	O
.	O
	
We	O
can	O
also	O
create	O
a	O
variant	O
of	O
the	O
FCN	B-Method
-	I-Method
Basic	I-Method
model	I-Method
which	O
discards	O
the	O
encoder	B-Method
feature	I-Method
map	I-Method
addition	I-Method
step	I-Method
and	O
only	O
learns	O
the	O
upsampling	B-Method
kernels	I-Method
(	O
FCN	B-Method
-	I-Method
Basic	I-Method
-	I-Method
NoAddition	I-Method
)	O
.	O
	
In	O
addition	O
to	O
the	O
above	O
variants	O
,	O
we	O
study	O
upsampling	B-Method
using	O
fixed	O
bilinear	B-Method
interpolation	I-Method
weights	I-Method
which	O
therefore	O
requires	O
no	O
learning	B-Method
for	O
upsampling	B-Task
(	O
Bilinear	B-Method
-	I-Method
Interpolation	I-Method
)	O
.	O
	
At	O
the	O
other	O
extreme	O
,	O
we	O
can	O
add	O
64	O
encoder	O
feature	O
maps	O
at	O
each	O
layer	O
to	O
the	O
corresponding	O
output	O
feature	O
maps	O
from	O
the	O
SegNet	B-Method
decoder	I-Method
to	O
create	O
a	O
more	O
memory	O
intensive	O
variant	O
of	O
SegNet	B-Method
(	O
SegNet	B-Method
-	I-Method
Basic	I-Method
-	I-Method
EncoderAddition	I-Method
)	O
.	O
	
Here	O
both	O
the	O
pooling	O
indices	O
for	O
upsampling	B-Task
are	O
used	O
,	O
followed	O
by	O
a	O
convolution	B-Method
step	I-Method
to	O
densify	O
its	O
sparse	O
input	O
.	O
	
This	O
is	O
then	O
added	O
element	O
-	O
wise	O
to	O
the	O
corresponding	O
encoder	O
feature	O
maps	O
to	O
produce	O
a	O
decoders	O
output	O
.	O
	
Another	O
and	O
more	O
memory	B-Method
intensive	I-Method
FCN	I-Method
-	I-Method
Basic	I-Method
variant	I-Method
(	O
FCN	B-Method
-	I-Method
Basic	I-Method
-	I-Method
NoDimReduction	I-Method
)	O
is	O
where	O
there	O
is	O
no	O
dimensionality	B-Method
reduction	I-Method
performed	O
for	O
the	O
encoder	O
feature	O
maps	O
.	O
	
This	O
implies	O
that	O
unlike	O
FCN	B-Method
-	I-Method
Basic	I-Method
the	O
final	O
encoder	B-Method
feature	I-Method
map	I-Method
is	O
not	O
compressed	O
to	O
channels	O
before	O
passing	O
it	O
to	O
the	O
decoder	B-Method
network	I-Method
.	O
	
Therefore	O
,	O
the	O
number	O
of	O
channels	O
at	O
the	O
end	O
of	O
each	O
decoder	O
is	O
the	O
same	O
as	O
the	O
corresponding	O
encoder	O
(	O
i.e	O
)	O
.	O
	
We	O
also	O
tried	O
other	O
generic	O
variants	O
where	O
feature	O
maps	O
are	O
simply	O
upsampled	O
by	O
replication	O
,	O
or	O
by	O
using	O
a	O
fixed	O
(	O
and	O
sparse	O
)	O
array	O
of	O
indices	O
for	O
upsampling	B-Task
.	O
	
These	O
performed	O
quite	O
poorly	O
in	O
comparison	O
to	O
the	O
above	O
variants	O
.	O
	
A	O
variant	O
without	O
max	B-Method
-	I-Method
pooling	I-Method
and	O
sub	B-Method
-	I-Method
sampling	I-Method
in	O
the	O
encoder	B-Method
network	I-Method
(	O
decoders	B-Method
are	O
redundant	O
)	O
consumes	O
more	O
memory	O
,	O
takes	O
longer	O
to	O
converge	O
and	O
performs	O
poorly	O
.	O
	
Finally	O
,	O
please	O
note	O
that	O
to	O
encourage	O
reproduction	O
of	O
our	O
results	O
we	O
release	O
the	O
Caffe	O
implementation	O
of	O
all	O
the	O
variants	O
.	O
	
subsection	O
:	O
Training	O
	
We	O
use	O
the	O
CamVid	B-Material
road	I-Material
scenes	I-Material
dataset	I-Material
to	O
benchmark	O
the	O
performance	O
of	O
the	O
decoder	B-Method
variants	I-Method
.	O
	
This	O
dataset	O
is	O
small	O
,	O
consisting	O
of	O
367	O
training	O
and	O
233	O
testing	O
RGB	B-Material
images	I-Material
(	O
day	B-Material
and	I-Material
dusk	I-Material
scenes	I-Material
)	O
at	O
resolution	O
.	O
	
The	O
challenge	O
is	O
to	O
segment	O
classes	O
such	O
as	O
road	O
,	O
building	O
,	O
cars	O
,	O
pedestrians	O
,	O
signs	O
,	O
poles	O
,	O
side	O
-	O
walk	O
etc	O
.	O
	
We	O
perform	O
local	B-Method
contrast	I-Method
normalization	I-Method
to	O
the	O
RGB	B-Material
input	I-Material
.	O
	
The	O
encoder	O
and	O
decoder	O
weights	O
were	O
all	O
initialized	O
using	O
the	O
technique	O
described	O
in	O
He	O
et	O
al	O
.	O
.	O
	
To	O
train	O
all	O
the	O
variants	O
we	O
use	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
(	O
SGD	B-Method
)	O
with	O
a	O
fixed	O
learning	B-Metric
rate	I-Metric
of	O
0.1	O
and	O
momentum	O
of	O
0.9	O
using	O
our	O
Caffe	B-Method
implementation	I-Method
of	I-Method
SegNet	I-Method
-	I-Method
Basic	I-Method
.	O
	
We	O
train	O
the	O
variants	O
until	O
the	O
training	B-Metric
loss	I-Metric
converges	O
.	O
	
Before	O
each	O
epoch	O
,	O
the	O
training	O
set	O
is	O
shuffled	O
and	O
each	O
mini	O
-	O
batch	O
(	O
12	O
images	O
)	O
is	O
then	O
picked	O
in	O
order	O
thus	O
ensuring	O
that	O
each	O
image	O
is	O
used	O
only	O
once	O
in	O
an	O
epoch	O
.	O
	
We	O
select	O
the	O
model	O
which	O
performs	O
highest	O
on	O
a	O
validation	B-Material
dataset	I-Material
.	O
	
We	O
use	O
the	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
loss	I-Metric
as	O
the	O
objective	B-Metric
function	I-Metric
for	O
training	O
the	O
network	O
.	O
	
The	O
loss	O
is	O
summed	O
up	O
over	O
all	O
the	O
pixels	O
in	O
a	O
mini	O
-	O
batch	O
.	O
	
When	O
there	O
is	O
large	O
variation	O
in	O
the	O
number	O
of	O
pixels	O
in	O
each	O
class	O
in	O
the	O
training	O
set	O
(	O
e.g	O
road	O
,	O
sky	O
and	O
building	O
pixels	O
dominate	O
the	O
CamVid	B-Material
dataset	I-Material
)	O
then	O
there	O
is	O
a	O
need	O
to	O
weight	O
the	O
loss	O
differently	O
based	O
on	O
the	O
true	O
class	O
.	O
	
This	O
is	O
termed	O
class	B-Task
balancing	I-Task
.	O
	
We	O
use	O
median	B-Method
frequency	I-Method
balancing	I-Method
where	O
the	O
weight	O
assigned	O
to	O
a	O
class	O
in	O
the	O
loss	O
function	O
is	O
the	O
ratio	O
of	O
the	O
median	O
of	O
class	O
frequencies	O
computed	O
on	O
the	O
entire	O
training	O
set	O
divided	O
by	O
the	O
class	O
frequency	O
.	O
	
This	O
implies	O
that	O
larger	O
classes	O
in	O
the	O
training	O
set	O
have	O
a	O
weight	O
smaller	O
than	O
and	O
the	O
weights	O
of	O
the	O
smallest	O
classes	O
are	O
the	O
highest	O
.	O
	
We	O
also	O
experimented	O
with	O
training	O
the	O
different	O
variants	O
without	O
class	B-Method
balancing	I-Method
or	O
equivalently	O
using	O
natural	B-Method
frequency	I-Method
balancing	I-Method
.	O
	
subsection	O
:	O
Analysis	O
	
To	O
compare	O
the	O
quantitative	O
performance	O
of	O
the	O
different	O
decoder	B-Method
variants	I-Method
,	O
we	O
use	O
three	O
commonly	O
used	O
performance	B-Metric
measures	I-Metric
:	O
global	B-Metric
accuracy	I-Metric
(	O
G	B-Metric
)	O
which	O
measures	O
the	O
percentage	O
of	O
pixels	O
correctly	O
classified	O
in	O
the	O
dataset	O
,	O
class	B-Metric
average	I-Metric
accuracy	I-Metric
(	O
C	B-Metric
)	O
is	O
the	O
mean	O
of	O
the	O
predictive	B-Metric
accuracy	I-Metric
over	O
all	O
classes	O
and	O
mean	B-Metric
intersection	I-Metric
over	I-Metric
union	I-Metric
(	O
mIoU	B-Method
)	O
over	O
all	O
classes	O
as	O
used	O
in	O
the	O
Pascal	B-Material
VOC12	I-Material
challenge	I-Material
.	O
	
The	O
mIoU	B-Metric
metric	I-Metric
is	O
a	O
more	O
stringent	O
metric	O
than	O
class	B-Metric
average	I-Metric
accuracy	I-Metric
since	O
it	O
penalizes	O
false	B-Metric
positive	I-Metric
predictions	I-Metric
.	O
	
However	O
,	O
mIoU	B-Metric
metric	I-Metric
is	O
not	O
optimized	O
for	O
directly	O
through	O
the	O
class	B-Metric
balanced	I-Metric
cross	I-Metric
-	I-Metric
entropy	I-Metric
loss	I-Metric
.	O
	
The	O
mIoU	B-Metric
metric	I-Metric
otherwise	O
known	O
as	O
the	O
Jacard	B-Method
Index	I-Method
is	O
most	O
commonly	O
used	O
in	O
benchmarking	B-Task
.	O
	
However	O
,	O
Csurka	O
et	O
al	O
.	O
note	O
that	O
this	O
metric	O
does	O
not	O
always	O
correspond	O
to	O
human	O
qualitative	O
judgements	O
(	O
ranks	O
)	O
of	O
good	O
quality	O
segmentation	B-Task
.	O
	
They	O
show	O
with	O
examples	O
that	O
mIoU	O
favours	O
region	O
smoothness	O
and	O
does	O
not	O
evaluate	O
boundary	B-Metric
accuracy	I-Metric
,	O
a	O
point	O
also	O
alluded	O
to	O
recently	O
by	O
the	O
authors	O
of	O
FCN	B-Method
.	O
	
Hence	O
they	O
propose	O
to	O
complement	O
the	O
mIoU	B-Method
metric	I-Method
with	O
a	O
boundary	B-Method
measure	I-Method
based	O
on	O
the	O
Berkeley	B-Metric
contour	I-Metric
matching	I-Metric
score	I-Metric
commonly	O
used	O
to	O
evaluate	O
unsupervised	B-Task
image	I-Task
segmentation	I-Task
quality	I-Task
.	O
	
Csurka	O
et	O
al	O
.	O
simply	O
extend	O
this	O
to	O
semantic	B-Task
segmentation	I-Task
and	O
show	O
that	O
the	O
measure	O
of	O
semantic	B-Metric
contour	I-Metric
accuracy	I-Metric
used	O
in	O
conjunction	O
with	O
the	O
mIoU	B-Method
metric	I-Method
agrees	O
more	O
with	O
human	B-Metric
ranking	I-Metric
of	I-Metric
segmentation	I-Metric
outputs	I-Metric
.	O
	
The	O
key	O
idea	O
in	O
computing	O
a	O
semantic	B-Metric
contour	I-Metric
score	I-Metric
is	O
to	O
evaluate	O
the	O
F1	B-Metric
-	I-Metric
measure	I-Metric
which	O
involves	O
computing	O
the	O
precision	B-Metric
and	I-Metric
recall	I-Metric
values	I-Metric
between	O
the	O
predicted	O
and	O
ground	O
truth	O
class	O
boundary	O
given	O
a	O
pixel	O
tolerance	O
distance	O
.	O
	
We	O
used	O
a	O
value	O
of	O
of	O
the	O
image	O
diagonal	O
as	O
the	O
tolerance	O
distance	O
.	O
	
The	O
F1	B-Method
-	I-Method
measure	I-Method
for	O
each	O
class	O
that	O
is	O
present	O
in	O
the	O
ground	B-Material
truth	I-Material
test	I-Material
image	I-Material
is	O
averaged	O
to	O
produce	O
an	O
image	O
F1	O
-	O
measure	O
.	O
	
Then	O
we	O
compute	O
the	O
whole	O
test	B-Metric
set	I-Metric
average	I-Metric
,	O
denoted	O
the	O
boundary	B-Metric
F1	I-Metric
-	I-Metric
measure	I-Metric
(	I-Metric
BF	I-Metric
)	O
by	O
average	O
the	O
image	B-Metric
F1	I-Metric
measures	I-Metric
.	O
	
We	O
test	O
each	O
architectural	O
variant	O
after	O
each	O
iterations	O
of	O
optimization	B-Task
on	O
the	O
CamVid	B-Material
validation	I-Material
set	I-Material
until	O
the	O
training	B-Metric
loss	I-Metric
converges	O
.	O
	
With	O
a	O
training	O
mini	O
-	O
batch	O
size	O
of	O
12	O
this	O
corresponds	O
to	O
testing	O
approximately	O
every	O
33	O
epochs	O
(	O
passes	O
)	O
through	O
the	O
training	O
set	O
.	O
	
We	O
select	O
the	O
iteration	O
wherein	O
the	O
global	B-Metric
accuracy	I-Metric
is	O
highest	O
amongst	O
the	O
evaluations	O
on	O
the	O
validation	O
set	O
.	O
	
We	O
report	O
all	O
the	O
three	O
measures	O
of	O
performance	O
at	O
this	O
point	O
on	O
the	O
held	O
-	O
out	O
CamVid	B-Material
test	I-Material
set	I-Material
.	O
	
Although	O
we	O
use	O
class	B-Method
balancing	I-Method
while	O
training	O
the	O
variants	O
,	O
it	O
is	O
still	O
important	O
to	O
achieve	O
high	O
global	B-Metric
accuracy	I-Metric
to	O
result	O
in	O
an	O
overall	O
smooth	B-Task
segmentation	I-Task
.	O
	
Another	O
reason	O
is	O
that	O
the	O
contribution	O
of	O
segmentation	B-Task
towards	O
autonomous	B-Task
driving	I-Task
is	O
mainly	O
for	O
delineating	O
classes	O
such	O
as	O
roads	O
,	O
buildings	O
,	O
side	O
-	O
walk	O
,	O
sky	O
.	O
	
These	O
classes	O
dominate	O
the	O
majority	O
of	O
the	O
pixels	O
in	O
an	O
image	O
and	O
a	O
high	O
global	B-Metric
accuracy	I-Metric
corresponds	O
to	O
good	O
segmentation	B-Task
of	O
these	O
important	O
classes	O
.	O
	
We	O
also	O
observed	O
that	O
reporting	O
the	O
numerical	B-Metric
performance	I-Metric
when	O
class	B-Metric
average	I-Metric
is	O
highest	O
can	O
often	O
correspond	O
to	O
low	O
global	B-Metric
accuracy	I-Metric
indicating	O
a	O
perceptually	O
noisy	O
segmentation	O
output	O
.	O
	
In	O
Table	O
[	O
reference	O
]	O
we	O
report	O
the	O
numerical	O
results	O
of	O
our	O
analysis	O
.	O
	
We	O
also	O
show	O
the	O
size	O
of	O
the	O
trainable	O
parameters	O
and	O
the	O
highest	O
resolution	O
feature	O
map	O
or	O
pooling	O
indices	O
storage	O
memory	O
,	O
i.e	O
,	O
of	O
the	O
first	B-Method
layer	I-Method
feature	I-Method
maps	I-Method
after	O
max	B-Method
-	I-Method
pooling	I-Method
and	O
sub	B-Method
-	I-Method
sampling	I-Method
.	O
	
We	O
show	O
the	O
average	B-Metric
time	I-Metric
for	O
one	O
forward	B-Method
pass	I-Method
with	O
our	O
Caffe	B-Method
implementation	I-Method
,	O
averaged	O
over	O
measurements	O
using	O
a	O
input	O
on	O
an	O
NVIDIA	B-Method
Titan	I-Method
GPU	I-Method
with	O
cuDNN	B-Method
v3	I-Method
acceleration	I-Method
.	O
	
We	O
note	O
that	O
the	O
upsampling	B-Method
layers	I-Method
in	O
the	O
SegNet	B-Method
variants	I-Method
are	O
not	O
optimised	O
using	O
cuDNN	B-Method
acceleration	I-Method
.	O
	
We	O
show	O
the	O
results	O
for	O
both	O
testing	B-Task
and	O
training	B-Task
for	O
all	O
the	O
variants	O
at	O
the	O
selected	O
iteration	O
.	O
	
The	O
results	O
are	O
also	O
tabulated	O
without	O
class	O
balancing	O
(	O
natural	O
frequency	O
)	O
for	O
training	B-Metric
and	I-Metric
testing	I-Metric
accuracies	I-Metric
.	O
	
Below	O
we	O
analyse	O
the	O
results	O
with	O
class	B-Task
balancing	I-Task
.	O
	
From	O
the	O
Table	O
[	O
reference	O
]	O
,	O
we	O
see	O
that	O
bilinear	B-Method
interpolation	I-Method
based	I-Method
upsampling	I-Method
without	O
any	O
learning	B-Method
performs	O
the	O
worst	O
based	O
on	O
all	O
the	O
measures	O
of	O
accuracy	B-Metric
.	O
	
All	O
the	O
other	O
methods	O
which	O
either	O
use	O
learning	B-Method
for	O
upsampling	B-Method
(	O
FCN	B-Method
-	I-Method
Basic	I-Method
and	I-Method
variants	I-Method
)	O
or	O
learning	B-Method
decoder	I-Method
filters	I-Method
after	O
upsampling	B-Method
(	O
SegNet	B-Method
-	I-Method
Basic	I-Method
and	O
its	O
variants	O
)	O
perform	O
significantly	O
better	O
.	O
	
This	O
emphasizes	O
the	O
need	O
to	O
learn	O
decoders	B-Method
for	O
segmentation	B-Task
.	O
	
This	O
is	O
also	O
supported	O
by	O
experimental	O
evidence	O
gathered	O
by	O
other	O
authors	O
when	O
comparing	O
FCN	B-Method
with	O
SegNet	B-Method
-	I-Method
type	I-Method
decoding	I-Method
techniques	I-Method
.	O
	
When	O
we	O
compare	O
SegNet	B-Method
-	I-Method
Basic	I-Method
and	O
FCN	B-Method
	
-	O
Basic	O
we	O
see	O
that	O
both	O
perform	O
equally	O
well	O
on	O
this	O
test	O
over	O
all	O
the	O
measures	O
of	O
accuracy	B-Metric
.	O
	
The	O
difference	O
is	O
that	O
SegNet	B-Method
uses	O
less	O
memory	O
during	O
inference	B-Task
since	O
it	O
only	O
stores	O
max	O
-	O
pooling	O
indices	O
.	O
	
On	O
the	O
other	O
hand	O
FCN	B-Method
-	I-Method
Basic	I-Method
stores	O
encoder	O
feature	O
maps	O
in	O
full	O
which	O
consumes	O
much	O
more	O
memory	O
(	O
11	O
times	O
more	O
)	O
.	O
	
SegNet	B-Method
-	I-Method
Basic	I-Method
has	O
a	O
decoder	B-Method
with	O
64	O
feature	O
maps	O
in	O
each	O
decoder	B-Method
layer	I-Method
.	O
	
In	O
comparison	O
FCN	B-Method
-	I-Method
Basic	I-Method
,	O
which	O
uses	O
dimensionality	B-Method
reduction	I-Method
,	O
has	O
fewer	O
(	O
11	O
)	O
feature	O
maps	O
in	O
each	O
decoder	O
layer	O
.	O
	
This	O
reduces	O
the	O
number	O
of	O
convolutions	O
in	O
the	O
decoder	B-Method
network	I-Method
and	O
hence	O
FCN	B-Method
-	I-Method
Basic	I-Method
is	O
faster	O
during	O
inference	B-Task
(	O
forward	O
pass	O
)	O
.	O
	
From	O
another	O
perspective	O
,	O
the	O
decoder	B-Method
network	I-Method
in	O
SegNet	B-Method
-	I-Method
Basic	I-Method
makes	O
it	O
overall	O
a	O
larger	O
network	O
than	O
FCN	B-Method
-	I-Method
Basic	I-Method
.	O
	
This	O
endows	O
it	O
with	O
more	O
flexibility	O
and	O
hence	O
achieves	O
higher	O
training	B-Metric
accuracy	I-Metric
than	O
FCN	B-Method
-	I-Method
Basic	I-Method
for	O
the	O
same	O
number	O
of	O
iterations	O
.	O
	
Overall	O
we	O
see	O
that	O
SegNet	B-Method
-	I-Method
Basic	I-Method
has	O
an	O
advantage	O
over	O
FCN	B-Method
-	I-Method
Basic	I-Method
when	O
inference	O
time	O
memory	O
is	O
constrained	O
but	O
where	O
inference	O
time	O
can	O
be	O
compromised	O
to	O
some	O
extent	O
.	O
	
SegNet	B-Method
-	I-Method
Basic	I-Method
is	O
most	O
similar	O
to	O
FCN	B-Method
-	I-Method
Basic	I-Method
-	I-Method
NoAddition	I-Method
in	O
terms	O
of	O
their	O
decoders	O
,	O
although	O
the	O
decoder	B-Method
of	O
SegNet	B-Method
is	O
larger	O
.	O
	
Both	O
learn	O
to	O
produce	O
dense	O
feature	O
maps	O
,	O
either	O
directly	O
by	O
learning	O
to	O
perform	O
deconvolution	B-Method
as	O
in	O
FCN	B-Method
-	I-Method
Basic	I-Method
-	I-Method
NoAddition	I-Method
or	O
by	O
first	O
upsampling	B-Method
and	O
then	O
convolving	O
with	O
trained	O
decoder	B-Method
filters	I-Method
.	O
	
The	O
performance	O
of	O
SegNet	B-Method
-	I-Method
Basic	I-Method
is	O
superior	O
,	O
in	O
part	O
due	O
to	O
its	O
larger	O
decoder	B-Metric
size	I-Metric
.	O
	
The	O
accuracy	B-Metric
of	O
FCN	B-Method
-	I-Method
Basic	I-Method
-	I-Method
NoAddition	I-Method
is	O
also	O
lower	O
as	O
compared	O
to	O
FCN	B-Method
-	I-Method
Basic	I-Method
.	O
	
This	O
shows	O
that	O
it	O
is	O
vital	O
to	O
capture	O
the	O
information	O
present	O
in	O
the	O
encoder	O
feature	O
maps	O
for	O
better	O
performance	O
.	O
	
In	O
particular	O
,	O
note	O
the	O
large	O
drop	O
in	O
the	O
BF	B-Metric
measure	I-Metric
between	O
these	O
two	O
variants	O
.	O
	
This	O
can	O
also	O
explain	O
the	O
part	O
of	O
the	O
reason	O
why	O
SegNet	B-Method
-	I-Method
Basic	I-Method
outperforms	O
FCN	B-Method
-	I-Method
Basic	I-Method
-	I-Method
NoAddition	I-Method
.	O
	
The	O
size	O
of	O
the	O
FCN	B-Method
-	I-Method
Basic	I-Method
-	I-Method
NoAddition	I-Method
-	I-Method
NoDimReduction	I-Method
model	I-Method
is	O
slightly	O
larger	O
than	O
SegNet	B-Method
-	I-Method
Basic	I-Method
since	O
the	O
final	O
encoder	O
feature	O
maps	O
are	O
not	O
compressed	O
to	O
match	O
the	O
number	O
of	O
classes	O
.	O
	
This	O
makes	O
it	O
a	O
fair	O
comparison	O
in	O
terms	O
of	O
the	O
size	O
of	O
the	O
model	O
.	O
	
The	O
performance	O
of	O
this	O
FCN	B-Method
variant	I-Method
is	O
poorer	O
than	O
SegNet	B-Method
-	I-Method
Basic	I-Method
in	O
test	O
but	O
also	O
its	O
training	B-Metric
accuracy	I-Metric
is	O
lower	O
for	O
the	O
same	O
number	O
of	O
training	O
epochs	O
.	O
	
This	O
shows	O
that	O
using	O
a	O
larger	O
decoder	B-Method
is	O
not	O
enough	O
but	O
it	O
is	O
also	O
important	O
to	O
capture	O
encoder	O
feature	O
map	O
information	O
to	O
learn	O
better	O
,	O
particular	O
the	O
fine	O
grained	O
contour	O
information	O
(	O
notice	O
the	O
drop	O
in	O
the	O
BF	B-Metric
measure	I-Metric
)	O
.	O
	
Here	O
it	O
is	O
also	O
interesting	O
to	O
see	O
that	O
SegNet	B-Method
-	I-Method
Basic	I-Method
has	O
a	O
competitive	O
training	B-Metric
accuracy	I-Metric
when	O
compared	O
to	O
larger	O
models	O
such	O
FCN	B-Method
-	I-Method
Basic	I-Method
-	I-Method
NoDimReduction	I-Method
.	O
	
Another	O
interesting	O
comparison	O
between	O
FCN	B-Method
-	I-Method
Basic	I-Method
-	I-Method
NoAddition	I-Method
and	I-Method
SegNet	I-Method
-	I-Method
Basic	I-Method
-	I-Method
SingleChannelDecoder	I-Method
shows	O
that	O
using	O
max	O
-	O
pooling	O
indices	O
for	O
upsampling	B-Method
and	O
an	O
overall	O
larger	O
decoder	O
leads	O
to	O
better	O
performance	O
.	O
	
This	O
also	O
lends	O
evidence	O
to	O
SegNet	B-Method
being	O
a	O
good	O
architecture	O
for	O
segmentation	B-Task
,	O
particularly	O
when	O
there	O
is	O
a	O
need	O
to	O
find	O
a	O
compromise	O
between	O
storage	B-Metric
cost	I-Metric
,	O
accuracy	B-Metric
versus	O
inference	B-Metric
time	I-Metric
.	O
	
In	O
the	O
best	O
case	O
,	O
when	O
both	O
memory	O
and	O
inference	B-Metric
time	I-Metric
is	O
not	O
constrained	O
,	O
larger	O
models	O
such	O
as	O
FCN	B-Method
-	I-Method
Basic	I-Method
-	I-Method
NoDimReduction	I-Method
and	I-Method
SegNet	I-Method
-	I-Method
EncoderAddition	I-Method
are	O
both	O
more	O
accurate	O
than	O
the	O
other	O
variants	O
.	O
	
Particularly	O
,	O
discarding	O
dimensionality	B-Task
reduction	I-Task
in	O
the	O
FCN	B-Method
-	I-Method
Basic	I-Method
model	I-Method
leads	O
to	O
the	O
best	O
performance	O
amongst	O
the	O
FCN	B-Method
-	I-Method
Basic	I-Method
variants	I-Method
with	O
a	O
high	O
BF	B-Metric
score	I-Metric
.	O
	
This	O
once	O
again	O
emphasizes	O
the	O
trade	O
-	O
off	O
involved	O
between	O
memory	B-Metric
and	O
accuracy	B-Metric
in	O
segmentation	B-Method
architectures	I-Method
.	O
	
The	O
last	O
two	O
columns	O
of	O
Table	O
[	O
reference	O
]	O
show	O
the	O
result	O
when	O
no	O
class	O
balancing	O
is	O
used	O
(	O
natural	O
frequency	O
)	O
.	O
	
Here	O
,	O
we	O
can	O
observe	O
that	O
without	O
weighting	O
the	O
results	O
are	O
poorer	O
for	O
all	O
the	O
variants	O
,	O
particularly	O
for	O
class	B-Metric
average	I-Metric
accuracy	I-Metric
and	O
mIoU	B-Metric
metric	I-Metric
.	O
	
The	O
global	B-Metric
accuracy	I-Metric
is	O
the	O
highest	O
without	O
weighting	O
since	O
the	O
majority	O
of	O
the	O
scene	O
is	O
dominated	O
by	O
sky	O
,	O
road	O
and	O
building	O
pixels	O
.	O
	
Apart	O
from	O
this	O
all	O
the	O
inference	O
from	O
the	O
comparative	B-Method
analysis	I-Method
of	I-Method
variants	I-Method
holds	O
true	O
for	O
natural	B-Task
frequency	I-Task
balancing	I-Task
too	O
,	O
including	O
the	O
trends	O
for	O
the	O
BF	B-Metric
measure	I-Metric
.	O
	
SegNet	B-Method
-	I-Method
Basic	I-Method
performs	O
as	O
well	O
as	O
FCN	B-Method
-	I-Method
Basic	I-Method
and	O
is	O
better	O
than	O
the	O
larger	O
FCN	B-Method
-	I-Method
Basic	I-Method
-	I-Method
NoAddition	I-Method
-	I-Method
NoDimReduction	I-Method
.	O
	
The	O
bigger	O
but	O
less	O
efficient	O
models	O
FCN	B-Method
-	I-Method
Basic	I-Method
-	I-Method
NoDimReduction	I-Method
and	I-Method
SegNet	I-Method
-	I-Method
EncoderAddition	I-Method
perform	O
better	O
than	O
the	O
other	O
variants	O
.	O
	
We	O
can	O
now	O
summarize	O
the	O
above	O
analysis	O
with	O
the	O
following	O
general	O
points	O
.	O
	
The	O
best	O
performance	O
is	O
achieved	O
when	O
encoder	O
feature	O
maps	O
are	O
stored	O
in	O
full	O
.	O
	
This	O
is	O
reflected	O
in	O
the	O
semantic	B-Metric
contour	I-Metric
delineation	I-Metric
metric	I-Metric
(	O
BF	B-Method
)	O
most	O
clearly	O
.	O
	
When	O
memory	O
during	O
inference	B-Task
is	O
constrained	O
,	O
then	O
compressed	O
forms	O
of	O
encoder	O
feature	O
maps	O
(	O
dimensionality	B-Method
reduction	I-Method
,	O
max	O
-	O
pooling	O
indices	O
)	O
can	O
be	O
stored	O
and	O
used	O
with	O
an	O
appropriate	O
decoder	B-Method
(	O
e.g.	O
SegNet	O
type	O
)	O
to	O
improve	O
performance	O
.	O
	
Larger	O
decoders	B-Method
increase	O
performance	O
for	O
a	O
given	O
encoder	B-Method
network	I-Method
.	O
	
section	O
:	O
Benchmarking	O
	
We	O
quantify	O
the	O
performance	O
of	O
SegNet	B-Method
on	O
two	O
scene	B-Task
segmentation	I-Task
benchmarks	I-Task
using	O
our	O
Caffe	B-Method
implementation	I-Method
.	O
	
The	O
first	O
task	O
is	O
road	B-Task
scene	I-Task
segmentation	I-Task
which	O
is	O
of	O
current	O
practical	O
interest	O
for	O
various	O
autonomous	B-Task
driving	I-Task
related	I-Task
problems	I-Task
.	O
	
The	O
second	O
task	O
is	O
indoor	B-Task
scene	I-Task
segmentation	I-Task
which	O
is	O
of	O
immediate	O
interest	O
to	O
several	O
augmented	B-Task
reality	I-Task
(	I-Task
AR	I-Task
)	I-Task
applications	I-Task
.	O
	
The	O
input	O
RGB	B-Material
images	I-Material
for	O
both	O
tasks	O
were	O
.	O
	
We	O
benchmarked	O
SegNet	B-Method
against	O
several	O
other	O
well	O
adopted	O
deep	B-Method
architectures	I-Method
for	O
segmentation	B-Task
such	O
as	O
FCN	B-Method
,	O
DeepLab	B-Method
-	I-Method
LargFOV	I-Method
and	O
DeconvNet	B-Method
.	O
	
Our	O
objective	O
was	O
to	O
understand	O
the	O
performance	O
of	O
these	O
architectures	O
when	O
trained	O
end	O
-	O
to	O
-	O
end	O
on	O
the	O
same	O
datasets	O
.	O
	
To	O
enable	O
end	O
-	O
to	O
-	O
end	B-Task
training	I-Task
we	O
added	O
batch	O
normalization	O
layers	O
after	O
each	O
convolutional	B-Method
layer	I-Method
.	O
	
For	O
DeepLab	B-Task
-	I-Task
LargeFOV	I-Task
,	O
we	O
changed	O
the	O
max	O
pooling	O
3	O
stride	O
to	O
1	O
to	O
achieve	O
a	O
final	O
predictive	B-Metric
resolution	I-Metric
of	O
.	O
	
We	O
restricted	O
the	O
feature	O
size	O
in	O
the	O
fully	B-Method
connnected	I-Method
layers	I-Method
of	O
DeconvNet	B-Method
to	O
so	O
as	O
to	O
enable	O
training	O
with	O
the	O
same	O
batch	O
size	O
as	O
other	O
models	O
.	O
	
Here	O
note	O
that	O
the	O
authors	O
of	O
DeepLab	B-Method
-	I-Method
LargeFOV	I-Method
have	O
also	O
reported	O
little	O
loss	O
in	O
performance	O
by	O
reducing	O
the	O
size	O
of	O
the	O
fully	O
connected	O
layers	O
.	O
	
In	O
order	O
to	O
perform	O
a	O
controlled	O
benchmark	O
we	O
used	O
the	O
same	O
SGD	B-Method
solver	I-Method
with	O
a	O
fixed	O
learning	B-Metric
rate	I-Metric
of	O
and	O
momentum	O
of	O
.	O
	
The	O
optimization	B-Task
was	O
performed	O
for	O
more	O
than	O
100	O
epochs	O
through	O
the	O
dataset	O
until	O
no	O
further	O
performance	O
increase	O
was	O
observed	O
.	O
	
Dropout	O
of	O
was	O
added	O
to	O
the	O
end	O
of	O
deeper	O
convolutional	O
layers	O
in	O
all	O
models	O
to	O
prevent	O
overfitting	O
(	O
see	O
for	O
example	O
caffe	B-Material
prototxt	I-Material
)	O
.	O
	
For	O
the	O
road	B-Material
scenes	I-Material
which	O
have	O
classes	O
we	O
used	O
a	O
mini	O
-	O
batch	O
size	O
of	O
and	O
for	O
indoor	B-Material
scenes	I-Material
with	O
classes	O
we	O
used	O
a	O
mini	O
-	O
batch	O
size	O
of	O
.	O
	
subsection	O
:	O
Road	B-Task
Scene	I-Task
Segmentation	I-Task
	
A	O
number	O
of	O
road	B-Material
scene	I-Material
datasets	I-Material
are	O
available	O
for	O
semantic	B-Task
parsing	I-Task
.	O
	
Of	O
these	O
we	O
choose	O
to	O
benchmark	O
SegNet	B-Method
using	O
the	O
CamVid	B-Material
dataset	I-Material
as	O
it	O
contains	O
video	B-Material
sequences	I-Material
.	O
	
This	O
enables	O
us	O
to	O
compare	O
our	O
proposed	O
architecture	O
with	O
those	O
which	O
use	O
motion	O
and	O
structure	O
and	O
video	O
segments	O
.	O
	
We	O
also	O
combine	O
to	O
form	O
an	O
ensemble	O
of	O
3433	O
images	O
to	O
train	O
SegNet	B-Method
for	O
an	O
additional	O
benchmark	O
.	O
	
For	O
a	O
web	O
demo	O
(	O
see	O
footnote	O
[	O
reference	O
]	O
)	O
of	O
road	B-Task
scene	I-Task
segmentation	I-Task
,	O
we	O
include	O
the	O
CamVid	B-Material
test	I-Material
set	I-Material
to	O
this	O
larger	O
dataset	O
.	O
	
Here	O
,	O
we	O
would	O
like	O
to	O
note	O
that	O
another	O
recent	O
and	O
independent	O
segmentation	B-Task
benchmark	I-Task
on	O
road	B-Task
scenes	I-Task
has	O
been	O
performed	O
for	O
SegNet	B-Method
and	O
the	O
other	O
competing	O
architectures	O
used	O
in	O
this	O
paper	O
.	O
	
However	O
,	O
the	O
benchmark	O
was	O
not	O
controlled	O
,	O
meaning	O
that	O
each	O
architecture	O
was	O
trained	O
with	O
a	O
separate	O
recipe	O
with	O
varying	O
input	O
resolutions	O
and	O
sometimes	O
with	O
a	O
validation	O
set	O
included	O
.	O
	
Therefore	O
,	O
we	O
believe	O
our	O
more	O
controlled	O
benchmark	O
can	O
be	O
used	O
to	O
complement	O
their	O
efforts	O
.	O
	
Building	O
Tree	O
Sky	O
Car	O
Sign	O
-	O
Symbol	O
Road	O
Pedestrian	O
Fence	O
	
Column	O
-	O
Pole	O
Side	O
-	O
walk	O
Bicyclist	O
Class	O
avg	O
.	O
	
Global	B-Metric
avg	I-Metric
.	O
	
mIoU	B-Metric
BF	O
	
The	O
qualitative	O
comparisons	O
of	O
SegNet	B-Task
predictions	I-Task
with	O
other	O
deep	B-Method
architectures	I-Method
can	O
be	O
seen	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
The	O
qualitative	O
results	O
show	O
the	O
ability	O
of	O
the	O
proposed	O
architecture	O
to	O
segment	O
smaller	O
classes	O
in	O
road	B-Task
scenes	I-Task
while	O
producing	O
a	O
smooth	O
segmentation	O
of	O
the	O
overall	O
scene	O
.	O
	
Indeed	O
,	O
under	O
the	O
controlled	O
benchmark	O
setting	O
,	O
SegNet	B-Method
shows	O
superior	O
performance	O
as	O
compared	O
to	O
some	O
of	O
the	O
larger	O
models	O
.	O
	
DeepLab	B-Method
-	I-Method
LargeFOV	I-Method
is	O
the	O
most	O
efficient	O
model	O
and	O
with	O
CRF	B-Method
post	I-Method
-	I-Method
processing	I-Method
can	O
produce	O
competitive	O
results	O
although	O
smaller	O
classes	O
are	O
lost	O
.	O
	
FCN	B-Method
with	O
learnt	B-Method
deconvolution	I-Method
is	O
clearly	O
better	O
than	O
with	O
fixed	B-Method
bilinear	I-Method
upsampling	I-Method
.	O
	
DeconvNet	B-Method
is	O
the	O
largest	O
model	O
and	O
the	O
most	O
inefficient	O
to	O
train	O
.	O
	
Its	O
predictions	O
do	O
not	O
retain	O
small	O
classes	O
.	O
	
We	O
also	O
use	O
this	O
benchmark	O
to	O
first	O
compare	O
SegNet	B-Method
with	O
several	O
non	B-Method
deep	I-Method
-	I-Method
learning	I-Method
methods	I-Method
including	O
Random	B-Method
Forests	I-Method
,	O
Boosting	B-Method
in	O
combination	O
with	O
CRF	B-Method
based	I-Method
methods	I-Method
.	O
	
This	O
was	O
done	O
to	O
give	O
the	O
user	O
a	O
perspective	O
of	O
the	O
improvements	O
in	O
accuracy	B-Metric
that	O
has	O
been	O
achieved	O
using	O
deep	B-Method
networks	I-Method
compared	O
to	O
classical	O
feature	B-Method
engineering	I-Method
based	I-Method
techniques	I-Method
.	O
	
The	O
results	O
in	O
Table	O
[	O
reference	O
]	O
show	O
SegNet	B-Method
-	O
Basic	O
,	O
SegNet	B-Method
obtain	O
competitive	O
results	O
when	O
compared	O
with	O
methods	O
which	O
use	O
CRFs	B-Method
.	O
	
This	O
shows	O
the	O
ability	O
of	O
the	O
deep	B-Method
architecture	I-Method
to	O
extract	O
meaningful	O
features	O
from	O
the	O
input	O
image	O
and	O
map	O
it	O
to	O
accurate	O
and	O
smooth	O
class	O
segment	O
labels	O
.	O
	
The	O
most	O
interesting	O
result	O
here	O
is	O
the	O
large	O
performance	O
improvement	O
in	O
class	B-Metric
average	I-Metric
and	I-Metric
mIOU	I-Metric
metrics	I-Metric
that	O
is	O
obtained	O
when	O
a	O
large	O
training	O
dataset	O
,	O
obtained	O
by	O
combining	O
,	O
is	O
used	O
to	O
train	O
SegNet	B-Method
.	O
	
Correspondingly	O
,	O
the	O
qualitative	O
results	O
of	O
SegNet	O
(	O
see	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
are	O
clearly	O
superior	O
to	O
the	O
rest	O
of	O
the	O
methods	O
.	O
	
It	O
is	O
able	O
to	O
segment	O
both	O
small	O
and	O
large	O
classes	O
well	O
.	O
	
We	O
remark	O
here	O
that	O
we	O
used	O
median	B-Method
frequency	I-Method
class	I-Method
balancing	I-Method
in	O
training	O
SegNet	B-Method
-	I-Method
Basic	I-Method
and	O
SegNet	B-Method
.	O
	
In	O
addition	O
,	O
there	O
is	O
an	O
overall	O
smooth	B-Metric
quality	I-Metric
of	I-Metric
segmentation	I-Metric
much	O
like	O
what	O
is	O
typically	O
obtained	O
with	O
CRF	B-Method
post	I-Method
-	I-Method
processing	I-Method
.	O
	
Although	O
the	O
fact	O
that	O
results	O
improve	O
with	O
larger	O
training	O
sets	O
is	O
not	O
surprising	O
,	O
the	O
percentage	O
improvement	O
obtained	O
using	O
pre	O
-	O
trained	O
encoder	B-Method
network	I-Method
and	O
this	O
training	O
set	O
indicates	O
that	O
this	O
architecture	O
can	O
potentially	O
be	O
deployed	O
for	O
practical	O
applications	O
.	O
	
Our	O
random	B-Task
testing	I-Task
on	O
urban	B-Material
and	I-Material
highway	I-Material
images	I-Material
from	O
the	O
internet	O
(	O
see	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
demonstrates	O
that	O
SegNet	B-Method
can	O
absorb	O
a	O
large	O
training	O
set	O
and	O
generalize	O
well	O
to	O
unseen	B-Material
images	I-Material
.	O
	
It	O
also	O
indicates	O
the	O
contribution	O
of	O
the	O
prior	O
(	O
CRF	B-Method
)	I-Method
can	O
be	O
lessened	O
when	O
sufficient	O
amount	O
of	O
training	B-Material
data	I-Material
is	O
made	O
available	O
.	O
	
In	O
Table	O
[	O
reference	O
]	O
we	O
compare	O
SegNet	B-Method
’s	O
performance	O
with	O
now	O
widely	O
adopted	O
fully	B-Method
convolutional	I-Method
architectures	I-Method
for	O
segmentation	B-Task
.	O
	
As	O
compared	O
to	O
the	O
experiment	O
in	O
Table	O
[	O
reference	O
]	O
,	O
we	O
did	O
not	O
use	O
any	O
class	B-Method
blancing	I-Method
for	O
training	O
any	O
of	O
the	O
deep	B-Method
architectures	I-Method
including	O
SegNet	B-Method
.	O
	
This	O
is	O
because	O
we	O
found	O
it	O
difficult	O
to	O
train	O
larger	O
models	O
such	O
as	O
DeconvNet	B-Method
with	O
median	B-Method
frequency	I-Method
balancing	I-Method
.	O
	
We	O
benchmark	O
performance	O
at	O
40	O
K	O
,	O
80	O
K	O
and	O
80	O
K	O
iterations	O
which	O
given	O
the	O
mini	O
-	O
batch	O
size	O
and	O
training	O
set	O
size	O
approximately	O
corresponds	O
to	O
and	O
100	O
epochs	O
.	O
	
For	O
the	O
last	O
test	O
point	O
we	O
also	O
report	O
the	O
maximum	O
number	O
of	O
iterations	O
(	O
here	O
atleast	O
150	O
epochs	O
)	O
beyond	O
which	O
we	O
observed	O
no	O
accuracy	B-Metric
improvements	O
or	O
when	O
over	O
-	O
fitting	O
set	O
in	O
.	O
	
We	O
report	O
the	O
metrics	O
at	O
three	O
stages	O
in	O
the	O
training	O
phase	O
to	O
reveal	O
how	O
the	O
metrics	O
varied	O
with	O
training	O
time	O
,	O
particularly	O
for	O
larger	O
networks	O
.	O
	
This	O
is	O
important	O
to	O
understand	O
if	O
additional	O
training	B-Metric
time	I-Metric
is	O
justified	O
when	O
set	O
against	O
accuracy	B-Metric
increases	O
.	O
	
Note	O
also	O
that	O
for	O
each	O
evaluation	O
we	O
performed	O
a	O
complete	O
run	O
through	O
the	O
dataset	O
to	O
obtain	O
batch	O
norm	O
statistics	O
and	O
then	O
evaluated	O
the	O
test	O
model	O
with	O
this	O
statistic	O
(	O
see	O
for	O
code	O
.	O
)	O
.	O
	
These	O
evaluations	O
are	O
expensive	O
to	O
perform	O
on	O
large	O
training	O
sets	O
and	O
hence	O
we	O
only	O
report	O
metrics	O
at	O
three	O
time	O
points	O
in	O
the	O
training	O
phase	O
.	O
	
From	O
Table	O
[	O
reference	O
]	O
we	O
immediately	O
see	O
that	O
SegNet	B-Method
,	O
DeconvNet	B-Method
achieve	O
the	O
highest	O
scores	O
in	O
all	O
the	O
metrics	O
as	O
compared	O
to	O
other	O
models	O
.	O
	
DeconvNet	B-Method
has	O
a	O
higher	O
boundary	B-Metric
delineation	I-Metric
accuracy	I-Metric
but	O
SegNet	B-Method
is	O
much	O
more	O
efficient	O
as	O
compared	O
to	O
DeconvNet	B-Method
.	O
	
This	O
can	O
be	O
seen	O
from	O
the	O
compute	O
statistics	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
FCN	B-Method
,	O
DeconvNet	B-Method
which	O
have	O
fully	O
connected	O
layers	O
(	O
turned	O
into	O
convolutional	B-Method
layers	I-Method
)	O
train	O
much	O
more	O
slowly	O
and	O
have	O
comparable	O
or	O
higher	O
forward	O
-	O
backward	O
pass	O
time	O
with	O
reference	O
to	O
SegNet	B-Method
.	O
	
Here	O
we	O
note	O
also	O
that	O
over	O
-	O
fitting	O
was	O
not	O
an	O
issue	O
in	O
training	O
these	O
larger	O
models	O
,	O
since	O
at	O
comparable	O
iterations	O
to	O
SegNet	O
their	O
metrics	O
showed	O
an	O
increasing	O
trend	O
.	O
	
For	O
the	O
FCN	B-Method
model	I-Method
learning	O
the	O
deconvolutional	B-Method
layers	I-Method
as	O
opposed	O
to	O
fixing	O
them	O
with	O
bi	O
-	O
linear	O
interpolation	O
weights	O
improves	O
performance	O
particularly	O
the	O
BF	B-Metric
score	I-Metric
.	O
	
It	O
also	O
achieves	O
higher	O
metrics	O
in	O
a	O
far	O
lesser	O
time	O
.	O
	
This	O
fact	O
agrees	O
with	O
our	O
earlier	O
analysis	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
.	O
	
Surprisingly	O
,	O
DeepLab	B-Method
-	I-Method
LargeFOV	I-Method
which	O
is	O
trained	O
to	O
predict	O
labels	O
at	O
a	O
resolution	O
of	O
produces	O
competitive	O
performance	O
given	O
that	O
it	O
is	O
the	O
smallest	O
model	O
in	O
terms	O
of	O
parameterization	O
and	O
also	O
has	O
the	O
fastest	O
training	B-Metric
time	I-Metric
as	O
per	O
Table	O
[	O
reference	O
]	O
.	O
	
However	O
,	O
the	O
boundary	B-Metric
accuracy	I-Metric
is	O
poorer	O
and	O
this	O
is	O
shared	O
by	O
the	O
other	O
architectures	O
.	O
	
DeconvNet	B-Metric
’s	I-Metric
BF	I-Metric
score	I-Metric
is	O
higher	O
than	O
the	O
other	O
networks	O
when	O
trained	O
for	O
a	O
very	O
long	O
time	O
.	O
	
Given	O
our	O
analysis	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
and	O
the	O
fact	O
that	O
it	O
shares	O
a	O
SegNet	B-Method
type	I-Method
architecture	I-Method
.	O
	
The	O
impact	O
of	O
dense	B-Method
CRF	I-Method
post	I-Method
-	I-Method
processing	I-Method
can	O
be	O
seen	O
in	O
the	O
last	O
time	O
point	O
for	O
DeepLab	B-Material
-	I-Material
LargeFOV	I-Material
-	I-Material
denseCRF	I-Material
.	O
	
Both	O
global	B-Metric
and	O
mIoU	B-Method
improve	O
but	O
class	B-Metric
average	I-Metric
diminshes	I-Metric
.	O
	
However	O
a	O
large	O
improvement	O
is	O
obtained	O
for	O
the	O
BF	B-Metric
score	I-Metric
.	O
	
Note	O
here	O
that	O
the	O
dense	B-Method
CRF	I-Method
hyperparameters	I-Method
were	O
obtained	O
by	O
an	O
expensive	O
grid	B-Method
-	I-Method
search	I-Method
process	I-Method
on	O
a	O
subset	O
of	O
the	O
training	O
set	O
since	O
no	O
validation	O
set	O
was	O
available	O
.	O
	
subsection	O
:	O
SUN	B-Material
RGB	I-Material
-	I-Material
D	I-Material
Indoor	I-Material
Scenes	I-Material
	
SUN	B-Material
RGB	I-Material
-	I-Material
D	I-Material
is	O
a	O
very	O
challenging	O
and	O
large	O
dataset	O
of	O
indoor	B-Material
scenes	I-Material
with	O
training	B-Material
and	I-Material
testing	I-Material
images	I-Material
.	O
	
The	O
images	O
are	O
captured	O
by	O
different	O
sensors	O
and	O
hence	O
come	O
in	O
various	O
resolutions	O
.	O
	
The	O
task	O
is	O
to	O
segment	O
indoor	O
scene	O
classes	O
including	O
wall	O
,	O
floor	O
,	O
ceiling	O
,	O
table	O
,	O
chair	O
,	O
sofa	O
etc	O
.	O
	
This	O
task	O
is	O
made	O
hard	O
by	O
the	O
fact	O
that	O
object	O
classes	O
come	O
in	O
various	O
shapes	O
,	O
sizes	O
and	O
in	O
different	O
poses	O
.	O
	
There	O
are	O
frequent	O
partial	O
occlusions	O
since	O
there	O
are	O
typically	O
many	O
different	O
classes	O
present	O
in	O
each	O
of	O
the	O
test	O
images	O
.	O
	
These	O
factors	O
make	O
this	O
one	O
of	O
the	O
hardest	O
segmentation	B-Task
challenges	I-Task
.	O
	
We	O
only	O
use	O
the	O
RGB	O
modality	O
for	O
our	O
training	O
and	O
testing	O
.	O
	
Using	O
the	O
depth	O
modality	O
would	O
necessitate	O
architectural	O
modifications	O
/	O
redesign	O
.	O
	
Also	O
the	O
quality	O
of	O
depth	B-Material
images	I-Material
from	O
current	O
cameras	O
require	O
careful	O
post	B-Method
-	I-Method
processing	I-Method
to	O
fill	O
-	O
in	O
missing	O
measurements	O
.	O
	
They	O
may	O
also	O
require	O
using	O
fusion	O
of	O
many	O
frames	O
to	O
robustly	O
extract	O
features	O
for	O
segmentation	B-Task
.	O
	
Therefore	O
we	O
believe	O
using	O
depth	O
for	O
segmentation	B-Task
merits	O
a	O
separate	O
body	O
of	O
work	O
which	O
is	O
not	O
in	O
the	O
scope	O
of	O
this	O
paper	O
.	O
	
We	O
also	O
note	O
that	O
an	O
earlier	O
benchmark	B-Material
dataset	I-Material
NYUv2	I-Material
is	O
included	O
as	O
part	O
of	O
this	O
dataset	O
.	O
	
Road	B-Material
scene	I-Material
images	I-Material
have	O
limited	O
variation	O
,	O
both	O
in	O
terms	O
of	O
the	O
classes	O
of	O
interest	O
and	O
their	O
spatial	O
arrangements	O
.	O
	
When	O
captured	O
from	O
a	O
moving	O
vehicle	O
where	O
the	O
camera	O
position	O
is	O
nearly	O
always	O
parallel	O
to	O
the	O
road	O
surface	O
limiting	O
variability	O
in	O
view	O
points	O
.	O
	
This	O
makes	O
it	O
easier	O
for	O
deep	B-Method
networks	I-Method
to	O
learn	O
to	O
segment	O
them	O
robustly	O
.	O
	
In	O
comparison	O
,	O
images	B-Task
of	I-Task
indoor	I-Task
scenes	I-Task
are	O
more	O
complex	O
since	O
the	O
view	O
points	O
can	O
vary	O
a	O
lot	O
and	O
there	O
is	O
less	O
regularity	O
in	O
both	O
the	O
number	O
of	O
classes	O
present	O
in	O
a	O
scene	O
and	O
their	O
spatial	O
arrangement	O
.	O
	
Another	O
difficulty	O
is	O
caused	O
by	O
the	O
widely	O
varying	O
sizes	O
of	O
the	O
object	O
classes	O
in	O
the	O
scene	O
.	O
	
Some	O
test	O
samples	O
from	O
the	O
recent	B-Material
SUN	I-Material
RGB	I-Material
-	I-Material
D	I-Material
dataset	I-Material
are	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
We	O
observe	O
some	O
scenes	O
with	O
few	O
large	O
classes	O
and	O
some	O
others	O
with	O
dense	O
clutter	O
(	O
bottom	O
row	O
and	O
right	O
)	O
.	O
	
The	O
appearance	O
(	O
texture	O
and	O
shape	O
)	O
can	O
also	O
widely	O
vary	O
in	O
indoor	B-Material
scenes	I-Material
.	O
	
Therefore	O
,	O
we	O
believe	O
this	O
is	O
the	O
hardest	O
challenge	O
for	O
segmentation	B-Method
architectures	I-Method
and	O
methods	O
in	O
computer	B-Task
vision	I-Task
.	O
	
Other	O
challenges	O
,	O
such	O
as	O
Pascal	B-Task
VOC12	I-Task
salient	I-Task
object	I-Task
segmentation	I-Task
have	O
occupied	O
researchers	O
more	O
,	O
but	O
we	O
believe	O
indoor	B-Task
scene	I-Task
segmentation	I-Task
is	O
more	O
challenging	O
and	O
has	O
more	O
current	O
practical	O
applications	O
such	O
as	O
in	O
AR	B-Task
and	I-Task
robotics	I-Task
.	O
	
To	O
encourage	O
more	O
research	O
in	O
this	O
direction	O
we	O
compared	O
well	O
known	O
deep	B-Method
architectures	I-Method
on	O
the	O
large	B-Material
SUN	I-Material
RGB	I-Material
-	I-Material
D	I-Material
dataset	I-Material
.	O
	
The	O
qualitative	O
results	O
of	O
SegNet	B-Method
on	O
samples	O
of	O
indoor	B-Material
scenes	I-Material
of	O
different	O
types	O
such	O
as	O
bedroom	O
,	O
living	O
room	O
,	O
laboratory	O
,	O
meeting	O
room	O
,	O
bathroom	O
are	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
We	O
see	O
that	O
SegNet	B-Method
obtains	O
reasonable	O
predictions	O
when	O
the	O
size	O
of	O
the	O
classes	O
are	O
large	O
under	O
different	O
view	O
points	O
.	O
	
This	O
is	O
particularly	O
interesting	O
since	O
the	O
input	O
modality	O
is	O
only	O
RGB	O
.	O
	
RGB	B-Material
images	I-Material
are	O
also	O
useful	O
to	O
segment	O
thinner	O
structures	O
such	O
as	O
the	O
legs	O
of	O
chairs	O
and	O
tables	O
,	O
lamps	O
which	O
is	O
difficult	O
to	O
achieve	O
using	O
depth	B-Material
images	I-Material
from	O
currently	O
available	O
sensors	O
.	O
	
This	O
can	O
be	O
seen	O
from	O
the	O
results	O
of	O
SegNet	O
,	O
DeconvNet	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
It	O
is	O
also	O
useful	O
to	O
segment	O
decorative	O
objects	O
such	O
as	O
paintings	O
on	O
the	O
wall	O
for	O
AR	B-Task
tasks	I-Task
.	O
	
However	O
as	O
compared	O
to	O
outdoor	O
scenes	O
the	O
segmentation	B-Metric
quality	I-Metric
is	O
clearly	O
more	O
noisy	O
.	O
	
The	O
quality	B-Metric
drops	O
significantly	O
when	O
clutter	O
is	O
increased	O
(	O
see	O
the	O
result	O
sample	O
in	O
the	O
middle	O
column	O
)	O
.	O
	
The	O
quantitative	O
results	O
in	O
Table	O
[	O
reference	O
]	O
show	O
that	O
all	O
the	O
deep	B-Method
architectures	I-Method
share	O
low	B-Metric
mIoU	I-Metric
and	I-Metric
boundary	I-Metric
metrics	I-Metric
.	O
	
The	O
global	B-Metric
and	I-Metric
class	I-Metric
averages	I-Metric
(	O
correlates	O
well	O
with	O
mIou	B-Method
)	O
are	O
also	O
small	O
.	O
	
SegNet	B-Method
outperforms	O
all	O
other	O
methods	O
in	O
terms	O
of	O
G	B-Metric
,	O
C	B-Metric
,	O
BF	B-Metric
metrics	I-Metric
and	O
has	O
a	O
slightly	O
lower	O
mIoU	B-Metric
than	O
DeepLab	B-Method
-	I-Method
LargeFOV	I-Method
.	O
	
As	O
a	O
stand	O
alone	O
experiment	O
we	O
trained	O
SegNet	B-Method
with	O
median	B-Method
frequency	I-Method
class	I-Method
balancing	I-Method
and	O
the	O
metrics	O
were	O
higher	O
(	O
see	O
Table	O
[	O
reference	O
]	O
)	O
and	O
this	O
agrees	O
with	O
our	O
analysis	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
.	O
	
Interestingly	O
,	O
using	O
the	O
grid	B-Method
search	I-Method
based	I-Method
optimal	I-Method
hyperparameters	I-Method
for	O
the	O
dense	B-Method
-	I-Method
CRF	I-Method
worsened	O
all	O
except	O
the	O
BF	B-Metric
score	I-Metric
metric	I-Metric
for	O
DeepLab	B-Material
-	I-Material
LargeFOV	I-Material
-	I-Material
denseCRF	I-Material
.	O
	
More	O
optimal	O
settings	O
could	O
perhaps	O
be	O
found	O
but	O
the	O
grid	B-Method
search	I-Method
process	I-Method
was	O
too	O
expensive	O
given	O
the	O
large	O
inference	B-Metric
time	I-Metric
for	O
dense	B-Method
-	I-Method
CRFs	I-Method
.	O
	
One	O
reason	O
for	O
the	O
overall	O
poor	O
performance	O
is	O
the	O
large	O
number	O
of	O
classes	O
in	O
this	O
segmentation	B-Task
task	I-Task
,	O
many	O
of	O
which	O
occupy	O
a	O
small	O
part	O
of	O
the	O
image	O
and	O
appear	O
infrequently	O
.	O
	
The	O
accuracies	B-Metric
reported	O
in	O
Table	O
[	O
reference	O
]	O
clearly	O
show	O
that	O
larger	O
classes	O
have	O
reasonable	O
accuracy	B-Metric
and	O
smaller	O
classes	O
have	O
lower	O
accuracies	B-Metric
.	O
	
This	O
can	O
be	O
improved	O
with	O
larger	O
sized	O
datasets	O
and	O
class	B-Method
distribution	I-Method
aware	I-Method
training	I-Method
techniques	I-Method
.	O
	
Another	O
reason	O
for	O
poor	O
performance	O
could	O
lie	O
in	O
the	O
inability	O
of	O
these	O
deep	B-Method
architectures	I-Method
(	O
all	O
are	O
based	O
on	O
the	O
VGG	B-Method
architecture	I-Method
)	O
to	O
large	O
variability	O
in	O
indoor	B-Material
scenes	I-Material
.	O
	
This	O
conjecture	O
on	O
our	O
part	O
is	O
based	O
on	O
the	O
fact	O
that	O
the	O
smallest	O
model	B-Method
DeepLab	I-Method
-	I-Method
LargeFOV	I-Method
produces	O
the	O
best	O
accuracy	B-Metric
in	O
terms	O
of	O
mIoU	B-Metric
and	O
in	O
comparison	O
,	O
larger	O
parameterizations	O
in	O
DeconvNet	B-Method
,	O
FCN	B-Method
did	O
not	O
improve	O
perfomance	O
even	O
with	O
much	O
longer	O
training	O
(	O
DeconvNet	B-Method
)	O
.	O
	
This	O
suggests	O
there	O
could	O
lie	O
a	O
common	O
reason	O
for	O
poor	O
performance	O
across	O
all	O
architectures	O
.	O
	
More	O
controlled	O
datasets	O
are	O
needed	O
to	O
verify	O
this	O
hypothesis	O
.	O
	
section	O
:	O
Discussion	O
and	O
future	O
work	O
	
Deep	B-Method
learning	I-Method
models	I-Method
have	O
often	O
achieved	O
increasing	O
success	O
due	O
to	O
the	O
availability	O
of	O
massive	B-Material
datasets	I-Material
and	O
expanding	O
model	O
depth	O
and	O
parameterisation	O
.	O
	
However	O
,	O
in	O
practice	O
factors	O
like	O
memory	B-Metric
and	O
computational	B-Metric
time	I-Metric
during	O
training	B-Task
and	O
testing	B-Task
are	O
important	O
factors	O
to	O
consider	O
when	O
choosing	O
a	O
model	O
from	O
a	O
large	O
bank	O
of	O
models	O
.	O
	
Training	B-Metric
time	I-Metric
becomes	O
an	O
important	O
consideration	O
particularly	O
when	O
the	O
performance	B-Metric
gain	I-Metric
is	O
not	O
commensurate	O
with	O
increased	O
training	B-Metric
time	I-Metric
as	O
shown	O
in	O
our	O
experiments	O
.	O
	
Test	B-Metric
time	I-Metric
memory	I-Metric
and	O
computational	B-Metric
load	I-Metric
are	O
important	O
to	O
deploy	O
models	O
on	O
specialised	O
embedded	B-Material
devices	I-Material
,	O
for	O
example	O
,	O
in	O
AR	B-Task
applications	I-Task
.	O
	
From	O
an	O
overall	O
efficiency	O
viewpoint	O
,	O
we	O
feel	O
less	O
attention	O
has	O
been	O
paid	O
to	O
smaller	O
and	O
more	O
memory	O
,	O
time	B-Method
efficient	I-Method
models	I-Method
for	O
real	B-Task
-	I-Task
time	I-Task
applications	I-Task
such	O
as	O
road	B-Task
scene	I-Task
understanding	I-Task
and	O
AR	B-Task
.	O
	
This	O
was	O
the	O
primary	O
motivation	O
behind	O
the	O
proposal	O
of	O
SegNet	B-Method
,	O
which	O
is	O
significantly	O
smaller	O
and	O
faster	O
than	O
other	O
competing	O
architectures	O
,	O
but	O
which	O
we	O
have	O
shown	O
to	O
be	O
efficient	O
for	O
tasks	O
such	O
as	O
road	B-Task
scene	I-Task
understanding	I-Task
.	O
	
Segmentation	B-Task
challenges	I-Task
such	O
as	O
Pascal	B-Task
and	O
MS	B-Method
-	I-Method
COCO	I-Method
are	O
object	B-Task
segmentation	I-Task
challenges	I-Task
wherein	O
	
a	O
few	O
classes	O
are	O
present	O
in	O
any	O
test	O
image	O
.	O
	
Scene	B-Task
segmentation	I-Task
is	O
more	O
challenging	O
due	O
to	O
the	O
high	O
variability	O
of	O
indoor	O
scenes	O
and	O
a	O
need	O
to	O
segment	O
a	O
larger	O
number	O
of	O
classes	O
simultaneously	O
.	O
	
The	O
task	O
of	O
outdoor	B-Task
and	I-Task
indoor	I-Task
scene	I-Task
segmentation	I-Task
are	O
also	O
more	O
practically	O
oriented	O
with	O
current	O
applications	O
such	O
as	O
autonomous	B-Task
driving	I-Task
,	O
robotics	B-Task
and	O
AR	B-Task
.	O
	
The	O
metrics	O
we	O
chose	O
to	O
benchmark	O
various	O
deep	B-Method
segmentation	I-Method
architectures	I-Method
like	O
the	O
boundary	O
F1	O
-	O
measure	O
(	O
BF	B-Method
)	O
was	O
done	O
to	O
complement	O
the	O
existing	O
metrics	O
which	O
are	O
more	O
biased	O
towards	O
region	B-Metric
accuracies	I-Metric
.	O
	
It	O
is	O
clear	O
from	O
our	O
experiments	O
and	O
other	O
independent	O
benchmarks	O
that	O
outdoor	B-Material
scene	I-Material
images	I-Material
captured	O
from	O
a	O
moving	O
car	O
are	O
easier	O
to	O
segment	O
and	O
deep	B-Method
architectures	I-Method
perform	O
robustly	O
.	O
	
We	O
hope	O
our	O
experiments	O
will	O
encourage	O
researchers	O
to	O
engage	O
their	O
attention	O
towards	O
the	O
more	O
challenging	O
indoor	B-Task
scene	I-Task
segmentation	I-Task
task	I-Task
.	O
	
An	O
important	O
choice	O
we	O
had	O
to	O
make	O
when	O
benchmarking	O
different	O
deep	B-Method
architectures	I-Method
of	O
varying	O
parameterization	O
was	O
the	O
manner	O
in	O
which	O
to	O
train	O
them	O
.	O
	
Many	O
of	O
these	O
architectures	O
have	O
used	O
a	O
host	O
of	O
supporting	B-Method
techniques	I-Method
and	O
multi	B-Method
-	I-Method
stage	I-Method
training	I-Method
recipes	I-Method
to	O
arrive	O
at	O
high	O
accuracies	B-Metric
on	O
datasets	O
but	O
this	O
makes	O
it	O
difficult	O
to	O
gather	O
evidence	O
about	O
their	O
true	O
performance	O
under	O
time	O
and	O
memory	O
constraints	O
.	O
	
Instead	O
we	O
chose	O
to	O
perform	O
a	O
controlled	O
benchmarking	O
where	O
we	O
used	O
batch	B-Method
normalization	I-Method
to	O
enable	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
training	I-Task
with	O
the	O
same	O
solver	O
(	O
SGD	B-Method
)	O
.	O
	
However	O
,	O
we	O
note	O
that	O
this	O
approach	O
can	O
not	O
entirely	O
disentangle	O
the	O
effects	O
of	O
model	O
versus	O
solver	O
(	O
optimization	B-Task
)	O
in	O
achieving	O
a	O
particular	O
result	O
.	O
	
This	O
is	O
mainly	O
due	O
to	O
the	O
fact	O
that	O
training	O
these	O
networks	O
involves	O
gradient	B-Method
back	I-Method
-	I-Method
propagation	I-Method
which	O
is	O
imperfect	O
and	O
the	O
optimization	B-Task
is	O
a	O
non	B-Task
-	I-Task
convex	I-Task
problem	I-Task
in	O
extremely	O
large	O
dimensions	O
.	O
	
Acknowledging	O
these	O
shortcomings	O
,	O
our	O
hope	O
is	O
that	O
this	O
controlled	B-Method
analysis	I-Method
complements	O
other	O
benchmarks	O
and	O
reveals	O
the	O
practical	O
trade	O
-	O
offs	O
involved	O
in	O
different	O
well	O
known	O
architectures	O
.	O
	
For	O
the	O
future	O
,	O
we	O
would	O
like	O
to	O
exploit	O
our	O
understanding	O
of	O
segmentation	B-Method
architectures	I-Method
gathered	O
from	O
our	O
analysis	O
to	O
design	O
more	O
efficient	O
architectures	O
for	O
real	B-Task
-	I-Task
time	I-Task
applications	I-Task
.	O
	
We	O
are	O
also	O
interested	O
in	O
estimating	O
the	O
model	O
uncertainty	O
for	O
predictions	B-Task
from	O
deep	B-Method
segmentation	I-Method
architectures	I-Method
,	O
.	O
	
section	O
:	O
Conclusion	O
	
We	O
presented	O
SegNet	B-Method
,	O
a	O
deep	B-Method
convolutional	I-Method
network	I-Method
architecture	I-Method
for	O
semantic	B-Task
segmentation	I-Task
.	O
	
The	O
main	O
motivation	O
behind	O
SegNet	B-Method
was	O
the	O
need	O
to	O
design	O
an	O
efficient	O
architecture	O
for	O
road	B-Task
and	I-Task
indoor	I-Task
scene	I-Task
understanding	I-Task
which	O
is	O
efficient	O
both	O
in	O
terms	O
of	O
memory	B-Metric
and	I-Metric
computational	I-Metric
time	I-Metric
.	O
	
We	O
analysed	O
SegNet	B-Method
and	O
compared	O
it	O
with	O
other	O
important	O
variants	O
to	O
reveal	O
the	O
practical	O
trade	O
-	O
offs	O
involved	O
in	O
designing	O
architectures	O
for	O
segmentation	B-Task
,	O
particularly	O
training	B-Metric
time	I-Metric
,	O
memory	B-Metric
versus	I-Metric
accuracy	I-Metric
.	O
	
Those	O
architectures	O
which	O
store	O
the	O
encoder	O
network	O
feature	O
maps	O
in	O
full	O
perform	O
best	O
but	O
consume	O
more	O
memory	O
during	O
inference	B-Metric
time	I-Metric
.	O
	
SegNet	B-Method
on	O
the	O
other	O
hand	O
is	O
more	O
efficient	O
since	O
it	O
only	O
stores	O
the	O
max	O
-	O
pooling	O
indices	O
of	O
the	O
feature	O
maps	O
and	O
uses	O
them	O
in	O
its	O
decoder	B-Method
network	I-Method
to	O
achieve	O
good	O
performance	O
.	O
	
On	O
large	O
and	O
well	O
known	O
datasets	O
SegNet	B-Method
performs	O
competitively	O
,	O
achieving	O
high	O
scores	O
for	O
road	B-Task
scene	I-Task
understanding	I-Task
.	O
	
End	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
learning	I-Task
of	I-Task
deep	I-Task
segmentation	I-Task
architectures	I-Task
is	O
a	O
harder	O
challenge	O
and	O
we	O
hope	O
to	O
see	O
more	O
attention	O
paid	O
to	O
this	O
important	O
problem	O
.	O
	
bibliography	O
:	O
References	O
	
[	O
]	O
Vijay	O
Badrinarayanan	O
obtained	O
his	O
Ph	O
.	O
D	O
from	O
INRIA	O
Rennes	O
,	O
France	O
in	O
2009	O
.	O
	
He	O
was	O
a	O
senior	O
post	O
-	O
doctoral	O
research	O
associate	O
at	O
the	O
Machine	B-Task
Intelligence	I-Task
Laboratory	I-Task
,	O
Department	O
of	O
Engineering	B-Task
,	O
University	O
of	O
Cambridge	O
,	O
	
U.K.	O
He	O
currently	O
works	O
as	O
a	O
Principal	O
Engineer	O
,	O
Deep	B-Task
Learning	I-Task
at	O
Magic	B-Task
Leap	I-Task
,	O
Inc.	O
in	O
Mountain	O
View	O
,	O
CA	O
.	O
	
His	O
research	O
interests	O
are	O
in	O
probabilistic	B-Method
graphical	I-Method
models	I-Method
,	O
deep	B-Method
learning	I-Method
applied	O
to	O
image	B-Task
and	I-Task
video	I-Task
based	I-Task
perception	I-Task
problems	I-Task
.	O
	
[	O
]	O
Alex	O
Kendall	O
graduated	O
with	O
a	O
Bachelor	O
of	O
Engineering	O
with	O
First	O
Class	O
Honours	O
in	O
2013	O
from	O
the	O
University	O
of	O
Auckland	O
,	O
New	O
Zealand	O
.	O
	
In	O
2014	O
he	O
was	O
awarded	O
a	O
Woolf	O
Fisher	O
Scholarship	O
to	O
study	O
towards	O
a	O
Ph	O
.	O
D	O
at	O
the	O
University	O
of	O
Cambridge	O
,	O
	
U.K.	O
He	O
is	O
a	O
member	O
of	O
the	O
Machine	B-Task
Intelligence	I-Task
Laboratory	I-Task
and	O
is	O
interested	O
in	O
applications	O
of	O
deep	B-Task
learning	I-Task
for	O
mobile	B-Task
robotics	I-Task
.	O
	
[	O
]	O
Roberto	O
Cipolla	O
obtained	O
a	O
B.A.	O
(	O
Engineering	O
)	O
degree	O
from	O
the	O
University	O
of	O
Cambridge	O
in	O
1984	O
,	O
an	O
M.S.E.	O
(	O
Electrical	B-Task
Engineering	I-Task
)	O
from	O
the	O
University	O
of	O
Pennsylvania	O
in	O
1985	O
and	O
a	O
D.Phil	O
.	O
	
(	O
Computer	B-Task
Vision	I-Task
)	O
from	O
the	O
University	O
of	O
Oxford	O
in	O
1991	O
.	O
	
from	O
1991	O
-	O
92	O
was	O
a	O
Toshiba	O
Fellow	O
and	O
engineer	O
at	O
the	O
Toshiba	O
Corporation	O
Research	O
and	O
Development	O
Centre	O
in	O
Kawasaki	O
,	O
Japan	O
.	O
	
He	O
joined	O
the	O
Department	O
of	O
Engineering	O
,	O
University	O
of	O
Cambridge	O
in	O
1992	O
as	O
a	O
Lecturer	O
and	O
a	O
Fellow	O
of	O
Jesus	O
College	O
.	O
	
He	O
became	O
a	O
Reader	O
in	O
Information	B-Task
Engineering	I-Task
in	O
1997	O
and	O
a	O
Professor	O
in	O
2000	O
.	O
	
He	O
became	O
a	O
Fellow	O
of	O
the	O
Royal	O
Academy	O
of	O
Engineering	O
(	O
FREng	B-Method
)	O
in	O
2010	O
.	O
	
His	O
research	O
interests	O
are	O
in	O
computer	B-Task
vision	I-Task
and	O
robotics	B-Task
.	O
	
He	O
has	O
authored	O
3	O
books	O
,	O
edited	O
9	O
volumes	O
and	O
co	O
-	O
authored	O
more	O
than	O
300	O
papers	O
.	O
	
On	O
gradient	B-Method
regularizers	I-Method
for	O
MMD	B-Method
GANs	O
	
section	O
:	O
Abstract	O
	
We	O
propose	O
a	O
principled	B-Method
method	I-Method
for	O
gradient	O
-	O
based	O
regularization	O
of	O
the	O
critic	O
of	O
GAN	B-Method
-	O
like	O
models	O
trained	O
by	O
adversarially	O
optimizing	O
the	O
kernel	B-Method
of	O
a	O
Maximum	B-Method
Mean	I-Method
Discrepancy	I-Method
(	O
MMD	B-Method
)	O
.	O
	
We	O
show	O
that	O
controlling	O
the	O
gradient	O
of	O
the	O
critic	O
is	O
vital	O
to	O
having	O
a	O
sensible	O
loss	B-Metric
function	I-Metric
,	O
and	O
devise	O
a	O
method	O
to	O
enforce	O
exact	O
,	O
analytical	O
gradient	O
constraints	O
at	O
no	O
additional	O
cost	O
compared	O
to	O
existing	O
approximate	B-Method
techniques	I-Method
based	O
on	O
additive	B-Method
regularizers	I-Method
.	O
	
The	O
new	O
loss	B-Metric
function	I-Metric
is	O
provably	O
continuous	O
,	O
and	O
experiments	O
show	O
that	O
it	O
stabilizes	O
and	O
accelerates	O
training	B-Task
,	O
giving	O
image	B-Task
generation	I-Task
models	O
that	O
outperform	O
state	O
-	O
of	O
-	O
the	O
art	O
methods	O
on	O
160	O
×	O
160	O
CelebA	B-Material
and	O
64	O
×	O
64	O
unconditional	O
ImageNet	O
.	O
	
section	O
:	O
	
however	O
,	O
when	O
the	O
MMD	B-Method
kernel	O
is	O
not	O
based	O
directly	O
on	O
image	O
pixels	O
,	O
but	O
on	O
learned	O
features	O
of	O
images	O
.	O
	
Wasserstein	B-Method
-	I-Method
inspired	I-Method
gradient	I-Method
regularization	I-Method
approaches	I-Method
can	O
be	O
used	O
on	O
the	O
MMD	B-Method
critic	O
when	O
learning	O
these	O
features	O
:	O
[	O
reference	O
]	O
uses	O
weight	O
clipping	O
[	O
reference	O
]	O
,	O
and	O
[	O
reference	O
][	O
reference	O
]	O
use	O
a	O
gradient	B-Method
penalty	I-Method
[	O
reference	O
]	O
.	O
	
The	O
recent	O
Sobolev	O
GAN	B-Method
[	O
reference	O
]	O
uses	O
a	O
similar	O
constraint	O
on	O
the	O
expected	O
gradient	O
norm	O
,	O
but	O
phrases	O
it	O
as	O
estimating	O
a	O
Sobolev	B-Method
IPM	I-Method
rather	O
than	O
loosely	O
approximating	B-Method
Wasserstein	I-Method
.	O
	
This	O
expectation	O
can	O
be	O
taken	O
over	O
the	O
same	O
distribution	O
as	O
[	O
reference	O
]	O
,	O
but	O
other	O
measures	O
are	O
also	O
proposed	O
,	O
such	O
as	O
(	O
P	B-Method
+	I-Method
Q	I-Method
θ	I-Method
)	O
	
/	O
2	O
.	O
	
A	O
second	O
recent	O
approach	O
,	O
the	O
spectrally	O
normalized	O
GAN	B-Method
[	O
reference	O
]	O
,	O
controls	O
the	O
Lipschitz	O
constant	O
of	O
the	O
critic	O
by	O
enforcing	O
the	O
spectral	O
norms	O
of	O
the	O
weight	O
matrices	O
to	O
be	O
1	O
.	O
	
Gradient	B-Method
penalties	I-Method
also	O
benefit	O
GANs	B-Method
based	O
on	O
f	B-Method
-	I-Method
divergences	I-Method
[	O
reference	O
]	O
:	O
for	O
instance	O
,	O
the	O
spectral	B-Method
normalization	I-Method
technique	I-Method
of	O
[	O
reference	O
]	O
can	O
be	O
applied	O
to	O
the	O
critic	B-Method
network	I-Method
of	O
an	O
f	O
-	O
GAN	B-Method
.	O
	
Alternatively	O
,	O
a	O
gradient	O
penalty	O
can	O
be	O
defined	O
to	O
approximate	O
the	O
effect	O
of	O
blurring	O
P	O
and	O
Q	O
θ	O
with	O
noise	O
[	O
reference	O
]	O
,	O
which	O
addresses	O
the	O
problem	O
of	O
non	O
-	O
overlapping	O
support	O
	
[	O
reference	O
]	O
.	O
This	O
approach	O
has	O
recently	O
been	O
shown	O
to	O
yield	O
locally	B-Task
convergent	I-Task
optimization	I-Task
in	O
some	O
cases	O
with	O
non	O
-	O
continuous	O
distributions	O
,	O
where	O
the	O
original	O
GAN	B-Method
does	O
not	O
[	O
reference	O
]	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
introduce	O
a	O
novel	O
regularization	B-Method
for	O
the	O
MMD	B-Method
GAN	I-Method
critic	O
of	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
,	O
which	O
directly	O
targets	O
generator	B-Task
performance	O
,	O
rather	O
than	O
adopting	O
regularization	B-Method
methods	I-Method
intended	O
to	O
approximate	O
Wasserstein	B-Method
distances	I-Method
	
[	O
reference	O
][	O
reference	O
]	O
.	O
	
The	O
new	O
MMD	B-Method
regularizer	O
derives	O
from	O
an	O
approach	O
widely	O
used	O
in	O
semi	B-Task
-	I-Task
supervised	I-Task
learning	I-Task
[	O
reference	O
][	O
reference	O
]	O
,	O
where	O
the	O
aim	O
is	O
to	O
define	O
a	O
classification	O
function	O
f	O
which	O
is	O
positive	O
on	O
P	O
(	O
the	O
positive	O
class	O
)	O
and	O
negative	O
on	O
Q	O
θ	O
(	O
negative	O
class	O
)	O
,	O
in	O
the	O
absence	O
of	O
labels	O
on	O
many	O
of	O
the	O
samples	O
.	O
	
The	O
decision	O
boundary	O
between	O
the	O
classes	O
is	O
assumed	O
to	O
be	O
in	O
a	O
region	O
of	O
low	O
density	O
for	O
both	O
P	O
and	O
Q	O
	
θ	O
:	O
f	O
should	O
therefore	O
be	O
flat	O
where	O
P	O
and	O
Q	O
θ	O
have	O
support	O
(	O
areas	O
with	O
constant	O
label	O
)	O
,	O
and	O
have	O
a	O
larger	O
slope	O
in	O
regions	O
of	O
low	O
density	O
.	O
	
Bousquet	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
propose	O
as	O
their	O
regularizer	B-Method
on	O
f	O
a	O
sum	O
of	O
the	O
variance	O
and	O
a	O
density	B-Method
-	I-Method
weighted	I-Method
gradient	I-Method
norm	I-Method
.	O
	
We	O
adopt	O
a	O
related	O
penalty	O
on	O
the	O
MMD	B-Method
critic	O
,	O
with	O
the	O
difference	O
that	O
we	O
only	O
apply	O
the	O
penalty	O
on	O
P	O
:	O
thus	O
,	O
the	O
critic	O
is	O
flatter	O
where	O
P	O
has	O
high	O
mass	O
,	O
but	O
does	O
not	O
vanish	O
on	O
the	O
generator	O
samples	O
from	O
Q	O
θ	O
(	O
which	O
we	O
optimize	O
)	O
.	O
	
In	O
excluding	O
Q	O
θ	O
from	O
the	O
critic	O
function	O
constraint	O
,	O
we	O
also	O
avoid	O
the	O
concern	O
raised	O
by	O
[	O
reference	O
]	O
that	O
a	O
critic	B-Method
depending	O
on	O
Q	O
θ	O
will	O
change	O
with	O
the	O
current	O
minibatch	O
-	O
potentially	O
leading	O
to	O
less	O
stable	B-Method
learning	I-Method
.	O
	
The	O
resulting	O
discrepancy	O
is	O
no	O
longer	O
an	O
integral	B-Metric
probability	I-Metric
metric	I-Metric
:	O
it	O
is	O
asymmetric	O
,	O
and	O
the	O
critic	O
function	O
class	O
depends	O
on	O
the	O
target	O
P	O
being	O
approximated	O
.	O
	
We	O
first	O
discuss	O
in	O
Section	O
2	O
how	O
MMD	B-Method
-	O
based	O
losses	O
can	O
be	O
used	O
to	O
learn	O
implicit	B-Method
generative	I-Method
models	I-Method
,	O
and	O
how	O
a	O
naive	O
approach	O
could	O
fail	O
.	O
	
This	O
motivates	O
our	O
new	O
discrepancies	O
,	O
introduced	O
in	O
Section	O
3	O
.	O
	
Section	O
4	O
demonstrates	O
that	O
these	O
losses	O
outperform	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
for	O
image	B-Task
generation	I-Task
.	O
	
section	O
:	O
Learning	O
implicit	B-Method
generative	I-Method
models	I-Method
with	O
MMD	B-Method
-	O
based	O
losses	O
	
An	O
IGM	B-Method
is	O
a	O
model	O
Q	O
	
θ	B-Method
which	O
aims	O
to	O
approximate	O
a	O
target	B-Method
distribution	I-Method
P	I-Method
over	O
a	O
space	O
X	O
⊆	O
R	O
d	O
.	O
	
We	O
will	O
define	O
Q	O
θ	O
by	O
a	O
generator	B-Method
function	I-Method
G	O
	
θ	O
:	O
	
Z	O
	
→	O
X	O
,	O
implemented	O
as	O
a	O
deep	B-Method
network	I-Method
with	O
parameters	O
θ	O
,	O
where	O
Z	O
is	O
a	O
space	O
of	O
latent	O
codes	O
,	O
say	O
R	O
128	O
.	O
	
We	O
assume	O
a	O
fixed	O
distribution	O
on	O
Z	O
,	O
say	O
Z	O
∼	O
Uniform	O
[	O
[	O
reference	O
]	O
128	O
,	O
and	O
call	O
Q	B-Method
θ	I-Method
the	O
distribution	O
of	O
G	O
θ	O
(	O
Z	O
)	O
.	O
	
We	O
will	O
consider	O
learning	B-Task
by	O
minimizing	O
a	O
discrepancy	O
D	O
between	O
distributions	O
,	O
with	O
D	O
(	O
P	O
,	O
Q	O
θ	O
)	O
≥	O
0	O
and	O
D	O
(	O
P	O
,	O
P	O
)	O
=	O
0	O
,	O
which	O
we	O
call	O
our	O
loss	O
.	O
	
We	O
aim	O
to	O
minimize	O
D	B-Task
(	I-Task
P	I-Task
,	I-Task
Q	I-Task
θ	I-Task
)	O
with	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
on	O
an	O
estimator	B-Method
of	I-Method
D.	I-Method
	
In	O
the	O
present	O
work	O
,	O
we	O
will	O
build	O
losses	B-Metric
D	I-Metric
based	O
on	O
the	O
Maximum	B-Method
Mean	I-Method
Discrepancy	I-Method
,	O
	
an	O
integral	O
probability	O
metric	O
where	O
the	O
critic	O
class	O
is	O
the	O
unit	O
ball	O
within	O
H	O
k	O
,	O
the	O
reproducing	O
kernel	O
Hilbert	O
space	O
with	O
a	O
kernel	O
	
k.	O
	
The	O
optimization	B-Task
in	O
(	O
1	O
)	O
admits	O
a	O
simple	O
closed	B-Method
-	I-Method
form	I-Method
optimal	I-Method
critic	I-Method
,	O
f	O
	
There	O
is	O
also	O
an	O
unbiased	O
,	O
closed	O
-	O
form	O
estimator	O
of	O
MMD	B-Method
2	O
k	O
with	O
appealing	O
statistical	O
properties	O
[	O
reference	O
]	O
-	O
in	O
particular	O
,	O
its	O
sample	B-Metric
complexity	I-Metric
is	O
independent	O
of	O
the	O
dimension	O
of	O
X	O
,	O
compared	O
to	O
the	O
exponential	O
dependence	O
[	O
reference	O
]	O
of	O
the	O
Wasserstein	B-Metric
distance	I-Metric
W	I-Metric
(	I-Metric
P	I-Metric
,	O
Q	O
)	O
=	O
sup	O
	
The	O
MMD	B-Method
is	O
continuous	O
in	O
the	O
weak	O
topology	O
for	O
any	O
bounded	O
kernel	O
with	O
Lipschitz	O
embeddings	O
[	O
reference	O
][	O
reference	O
]	O
]	O
,	O
meaning	O
that	O
if	O
P	O
n	O
converges	O
in	O
distribution	O
to	O
P	O
,	O
	
P	O
n	O
D	O
−	O
	
→	O
P	O
,	O
then	O
MMD	B-Method
(	O
P	O
n	O
,	O
P	O
)	O
→	O
0	O
.	O
	
(	O
W	O
is	O
continuous	O
in	O
the	O
slightly	O
stronger	O
Wasserstein	O
topology	O
[	O
reference	O
][	O
reference	O
]	O
;	O
P	O
n	O
W	O
−→	O
P	O
implies	O
	
P	O
n	O
D	O
−	O
	
→	O
P	O
,	O
and	O
the	O
two	O
notions	O
coincide	O
if	O
X	O
is	O
bounded	O
.	O
)	O
	
Continuity	O
means	O
the	O
loss	O
can	O
provide	O
better	O
signal	O
to	O
the	O
generator	O
as	O
Q	O
θ	O
approaches	O
P	O
,	O
as	O
opposed	O
to	O
e.g.	O
Jensen	O
-	O
Shannon	O
where	O
the	O
loss	O
could	O
be	O
constant	O
until	O
suddenly	O
jumping	O
to	O
0	O
	
[	O
e.g.	O
3	O
,	O
Example	O
1	O
]	O
.	O
	
The	O
MMD	B-Method
is	O
also	O
strict	O
,	O
meaning	O
it	O
is	O
zero	O
iff	O
	
P	O
=	O
Q	O
	
θ	O
,	O
for	O
characteristic	O
kernels	O
[	O
reference	O
]	O
.	O
	
The	O
Gaussian	B-Method
kernel	I-Method
yields	O
an	O
MMD	B-Method
both	O
continuous	O
in	O
the	O
weak	O
topology	O
and	O
strict	O
.	O
	
Thus	O
in	O
principle	O
,	O
one	O
need	O
not	O
conduct	O
any	O
alternating	B-Task
optimization	I-Task
in	O
an	O
IGM	B-Task
at	O
all	O
,	O
but	O
merely	O
choose	O
generator	O
parameters	O
θ	O
to	O
minimize	O
MMD	B-Method
k	O
.	O
	
Despite	O
these	O
appealing	O
properties	O
,	O
using	O
simple	O
pixel	B-Method
-	I-Method
level	I-Method
kernels	I-Method
leads	O
to	O
poor	O
generator	O
samples	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
More	O
recent	O
MMD	B-Method
GANs	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
achieve	O
better	O
results	O
by	O
using	O
a	O
parameterized	O
family	O
of	O
kernels	O
,	O
{	O
k	O
ψ	O
}	O
ψ∈Ψ	O
,	O
in	O
the	O
Optimized	O
MMD	B-Method
loss	O
previously	O
studied	O
by	O
[	O
reference	O
][	O
reference	O
]	O
:	O
	
We	O
primarily	O
consider	O
kernels	O
defined	O
by	O
some	O
fixed	O
kernel	B-Method
K	I-Method
on	O
top	O
of	O
a	O
learned	O
low	B-Method
-	I-Method
dimensional	I-Method
representation	I-Method
	
In	O
practice	O
,	O
K	O
is	O
a	O
simple	O
characteristic	B-Method
kernel	I-Method
,	O
e.g.	O
Gaussian	B-Method
,	O
and	O
φ	B-Method
ψ	I-Method
is	O
usually	O
a	O
deep	B-Method
network	I-Method
with	O
output	O
dimension	O
say	O
s	O
=	O
16	O
[	O
reference	O
]	O
or	O
even	O
s	O
=	O
1	O
(	O
in	O
our	O
experiments	O
)	O
.	O
	
If	O
φ	B-Method
ψ	I-Method
is	O
powerful	O
enough	O
,	O
this	O
choice	O
is	O
sufficient	O
;	O
we	O
need	O
not	O
try	O
to	O
ensure	O
each	O
k	O
ψ	O
is	O
characteristic	O
,	O
as	O
did	O
[	O
reference	O
]	O
.	O
Proposition	O
1	O
.	O
	
Suppose	O
k	O
=	O
	
K	O
	
•	O
φ	O
ψ	O
,	O
with	O
	
K	O
characteristic	O
and	O
{	O
φ	O
ψ	O
}	O
rich	O
enough	O
that	O
for	O
any	O
P	O
=	O
Q	O
,	O
there	O
is	O
a	O
ψ	O
∈	O
Ψ	O
for	O
which	O
φ	O
ψ	O
#	O
P	O
=	O
φ	O
ψ	O
#	O
Q.	O
	
Proof	O
.	O
	
Letψ	O
∈	O
Ψ	O
be	O
such	O
that	O
φψ	O
(	O
P	O
)	O
=	O
φψ	O
(	O
Q	O
)	O
.	O
	
Then	O
,	O
since	O
K	O
is	O
characteristic	O
,	O
	
To	O
estimate	O
D	O
Ψ	O
MMD	B-Method
,	O
one	O
can	O
conduct	O
alternating	B-Method
optimization	I-Method
to	O
estimate	O
aψ	O
and	O
then	O
update	O
the	O
generator	B-Method
according	O
to	O
MMD	B-Method
kψ	O
,	O
similar	O
to	O
the	O
scheme	O
used	O
in	O
GANs	B-Method
and	O
WGANs	B-Method
.	O
	
(	O
This	O
form	O
of	O
estimator	O
is	O
justified	O
by	O
an	O
envelope	B-Method
theorem	I-Method
[	O
reference	O
]	O
,	O
although	O
it	O
is	O
invariably	O
biased	O
[	O
reference	O
]	O
.	O
)	O
Unlike	O
D	O
GAN	B-Method
or	O
W	O
,	O
fixing	O
aψ	O
and	O
optimizing	O
the	O
generator	B-Method
still	O
yields	O
a	O
sensible	O
distance	O
MMD	B-Method
kψ	O
.	O
	
Early	O
attempts	O
at	O
minimizing	O
D	O
Ψ	O
MMD	B-Method
in	O
an	O
IGM	O
,	O
though	O
,	O
were	O
unsuccessful	O
	
[	O
reference	O
]	O
.	O
	
This	O
could	O
be	O
because	O
for	O
some	O
kernel	O
classes	O
,	O
D	O
Ψ	O
MMD	B-Method
is	O
stronger	O
than	O
Wasserstein	B-Method
or	O
MMD	B-Method
.	O
	
Example	O
1	O
	
(	O
DiracGAN	O
[	O
reference	O
]	O
)	O
.	O
	
We	O
wish	O
to	O
model	O
a	O
point	O
mass	O
at	O
the	O
origin	O
of	O
R	O
,	O
P	O
=	O
δ	O
0	O
,	O
with	O
any	O
possible	O
point	O
mass	O
,	O
Q	O
θ	O
	
=	O
δ	O
θ	O
for	O
θ	O
∈	O
R.	O
	
We	O
use	O
a	O
Gaussian	B-Method
kernel	I-Method
of	O
any	O
bandwidth	O
,	O
which	O
can	O
be	O
written	O
as	O
	
shows	O
that	O
the	O
Optimized	O
MMD	B-Method
distance	O
is	O
not	O
continuous	O
in	O
the	O
weak	O
or	O
Wasserstein	O
topologies	O
.	O
	
This	O
also	O
causes	O
optimization	B-Task
issues	I-Task
.	O
	
Figure	O
1	O
(	O
a	O
)	O
shows	O
gradient	O
vector	O
fields	O
in	O
parameter	O
space	O
,	O
	
.	O
	
Some	O
sequences	O
following	O
v	O
(	O
e.g.	O
A	O
)	O
converge	O
to	O
an	O
optimal	O
solution	O
(	O
0	O
,	O
ψ	O
)	O
,	O
but	O
some	O
(	O
B	O
)	O
move	O
in	O
the	O
wrong	O
direction	O
,	O
and	O
others	O
(	O
C	O
)	O
are	O
stuck	O
because	O
there	O
is	O
essentially	O
no	O
gradient	O
.	O
	
Figure	O
1	O
(	O
c	O
,	O
red	O
)	O
shows	O
that	O
the	O
optimal	O
D	O
Ψ	O
MMD	B-Method
critic	O
is	O
very	O
sharp	O
near	O
P	O
and	O
Q	O
;	O
this	O
is	O
less	O
true	O
for	O
cases	O
where	O
the	O
algorithm	O
converged	O
.	O
	
We	O
can	O
avoid	O
these	O
issues	O
if	O
we	O
ensure	O
a	O
bounded	O
Lipschitz	O
critic	O
:	O
	
are	O
uniformly	O
bounded	O
and	O
have	O
a	O
common	O
Lipschitz	O
constant	O
:	O
	
sup	O
x∈X	O
,	O
ψ∈Ψ	O
|f	O
	
ψ	O
(	O
x	O
)	O
|	O
<	O
∞	O
	
and	O
sup	O
ψ∈Ψ	O
	
f	O
ψ	O
	
Lip	O
<	O
∞.	O
	
In	O
particular	O
,	O
this	O
holds	O
when	O
k	O
ψ	O
	
=	O
K	O
	
•	O
φ	O
ψ	O
and	O
	
2	O
f	O
	
#	O
P	O
denotes	O
the	O
pushforward	O
of	O
a	O
distribution	O
:	O
if	O
X	O
∼	O
P	O
,	O
then	O
f	O
(	O
X	O
)	O
∼	O
f	O
#	O
P.	O
[	O
reference	O
]	O
[	O
27	O
,	O
Theorem	O
4	O
]	O
makes	O
a	O
similar	O
claim	O
to	O
Proposition	O
2	O
,	O
but	O
its	O
proof	O
was	O
incorrect	O
:	O
it	O
tries	O
to	O
uniformly	O
bound	O
MMD	B-Method
k	O
ψ	O
≤	O
W	O
2	O
,	O
but	O
the	O
bound	O
used	O
is	O
for	O
a	O
Wasserstein	O
in	O
terms	O
of	O
Proof	O
.	O
	
The	O
main	O
result	O
is	O
[	O
reference	O
][	O
reference	O
]	O
.	O
	
To	O
show	O
the	O
claim	O
for	O
	
Indeed	O
,	O
if	O
we	O
put	O
a	O
box	O
constraint	O
on	O
ψ	O
[	O
reference	O
]	O
or	O
regularize	O
the	O
gradient	O
of	O
the	O
critic	O
function	O
[	O
reference	O
]	O
,	O
the	O
resulting	O
MMD	B-Method
GAN	I-Method
generally	O
matches	O
or	O
outperforms	O
WGAN	B-Method
-	I-Method
based	I-Method
models	I-Method
.	O
	
Unfortunately	O
,	O
though	O
,	O
an	O
additive	B-Method
gradient	I-Method
penalty	I-Method
does	O
n't	O
substantially	O
change	O
the	O
vector	O
field	O
of	O
Figure	O
1	O
(	O
a	O
)	O
,	O
as	O
shown	O
in	O
Figure	O
5	O
(	O
Appendix	O
B	O
)	O
.	O
	
We	O
will	O
propose	O
distances	O
with	O
much	O
better	O
convergence	B-Metric
behavior	I-Metric
.	O
	
section	O
:	O
New	O
discrepancies	O
for	O
learning	B-Task
implicit	I-Task
generative	I-Task
models	I-Task
	
Our	O
aim	O
here	O
is	O
to	O
introduce	O
a	O
discrepancy	O
that	O
can	O
provide	O
useful	O
gradient	O
information	O
when	O
used	O
as	O
an	O
IGM	B-Task
loss	I-Task
.	O
	
Proofs	O
of	O
results	O
in	O
this	O
section	O
are	O
deferred	O
to	O
Appendix	O
A.	O
	
section	O
:	O
Lipschitz	O
Maximum	B-Method
Mean	I-Method
Discrepancy	I-Method
	
Proposition	O
2	O
shows	O
that	O
an	O
MMD	B-Method
-	O
like	O
discrepancy	O
can	O
be	O
continuous	O
under	O
the	O
weak	O
topology	O
even	O
when	O
optimizing	O
over	O
kernels	O
,	O
if	O
we	O
directly	O
restrict	O
the	O
critic	O
functions	O
to	O
be	O
Lipschitz	O
.	O
	
We	O
can	O
easily	O
define	O
such	O
a	O
distance	O
,	O
which	O
we	O
call	O
the	O
Lipschitz	O
MMD	B-Method
:	O
for	O
some	O
λ	O
>	O
0	O
,	O
LipMMD	O
	
k	O
,	O
λ	O
(	O
P	O
,	O
Q	O
)	O
	
:	O
=	O
sup	O
	
For	O
a	O
universal	O
kernel	O
k	O
,	O
we	O
conjecture	O
that	O
lim	O
λ→0	O
LipMMD	O
k	O
,	O
λ	O
(	O
P	O
,	O
Q	O
)	O
	
→	O
W	O
(	O
P	O
,	O
Q	O
)	O
.	O
	
But	O
for	O
any	O
k	O
and	O
λ	O
,	O
LipMMD	B-Method
is	O
upper	O
-	O
bounded	O
by	O
W	O
,	O
as	O
(	O
4	O
)	O
optimizes	O
over	O
a	O
smaller	O
set	O
of	O
functions	O
than	O
[	O
reference	O
]	O
.	O
	
LipMMD	B-Method
	
(	O
P	O
,	O
Q	O
)	O
:	O
=	O
sup	O
ψ∈Ψ	O
	
LipMMD	O
k	O
ψ	O
,	O
	
λ	O
(	O
P	O
,	O
Q	O
)	O
is	O
also	O
upper	O
-	O
bounded	O
by	O
W	O
,	O
and	O
hence	O
is	O
continuous	O
in	O
the	O
Wasserstein	O
topology	O
.	O
	
It	O
also	O
shows	O
excellent	O
empirical	O
behavior	O
on	O
Example	O
1	O
(	O
Figure	O
1	O
Constraining	O
the	O
mean	O
gradient	O
rather	O
than	O
the	O
maximum	O
,	O
as	O
we	O
will	O
do	O
next	O
,	O
is	O
far	O
more	O
tractable	O
.	O
	
section	O
:	O
Gradient	O
-	O
Constrained	O
Maximum	B-Method
Mean	I-Method
Discrepancy	I-Method
	
We	O
define	O
the	O
Gradient	O
-	O
Constrained	O
MMD	B-Method
for	O
λ	O
>	O
0	O
and	O
using	O
some	O
measure	O
µ	O
as	O
	
where	O
	
Rather	O
than	O
directly	O
constraining	O
the	O
Lipschitz	O
constant	O
,	O
the	O
second	O
term	O
∇f	O
	
2	O
	
L	O
2	O
(	O
µ	O
)	O
encourages	O
the	O
function	O
f	O
to	O
be	O
flat	O
where	O
µ	O
has	O
mass	O
.	O
	
In	O
experiments	O
we	O
use	O
µ	O
=	O
P	O
,	O
flattening	O
the	O
critic	O
near	O
the	O
target	O
sample	O
.	O
	
We	O
add	O
the	O
first	O
term	O
following	O
[	O
reference	O
]	O
:	O
in	O
one	O
dimension	O
and	O
with	O
µ	O
uniform	O
,	O
·	O
S	O
(	O
µ	O
),	O
·	O
,	O
0	O
is	O
then	O
an	O
RKHS	B-Method
norm	I-Method
with	O
the	O
kernel	O
κ	O
(	O
x	O
,	O
y	O
)	O
=	O
	
exp	O
(	O
−	O
x	O
	
−	O
y	O
)	O
,	O
which	O
is	O
also	O
a	O
Sobolev	O
space	O
.	O
	
The	O
correspondence	O
to	O
a	O
Sobolev	O
norm	O
is	O
lost	O
in	O
higher	O
dimensions	O
[	O
reference	O
][	O
reference	O
]	O
]	O
,	O
but	O
we	O
also	O
found	O
the	O
first	O
term	O
to	O
be	O
beneficial	O
in	O
practice	O
.	O
	
We	O
can	O
exploit	O
some	O
properties	O
of	O
H	B-Method
k	I-Method
to	O
compute	O
(	O
5	O
)	O
analytically	O
.	O
	
Call	O
the	O
difference	O
in	O
kernel	B-Metric
mean	I-Metric
	
M	O
with	O
mth	O
entry	O
η	O
(	O
X	O
m	O
)	O
,	O
and	O
∇η	O
(	O
X	O
)	O
∈	O
	
where	O
K	O
is	O
the	O
kernel	O
matrix	O
	
,	O
and	O
H	O
that	O
of	O
derivatives	O
of	O
both	O
arguments	O
	
As	O
long	O
as	O
P	O
and	O
Q	O
have	O
integrable	O
first	O
moments	O
,	O
and	O
µ	O
	
has	O
second	O
moments	O
,	O
Assumptions	O
(	O
A	O
)	O
to	O
(	O
D	O
)	O
are	O
satisfied	O
e.g.	O
by	O
a	O
Gaussian	B-Method
or	I-Method
linear	I-Method
kernel	I-Method
on	O
top	O
of	O
a	O
differentiable	O
φ	O
ψ	O
.	O
	
We	O
can	O
thus	O
estimate	O
the	O
GCMMD	B-Method
based	O
on	O
samples	O
from	O
P	O
,	O
Q	O
,	O
and	O
µ	O
by	O
using	O
the	O
empirical	O
meanη	O
for	O
η	O
.	O
	
This	O
discrepancy	O
indeed	O
works	O
well	O
in	O
practice	O
:	O
Appendix	O
F.2	O
shows	O
that	O
optimizing	O
our	O
estimate	O
of	O
D	B-Metric
µ	I-Metric
,	I-Metric
Ψ	I-Metric
,	O
λ	B-Method
GCMMD	I-Method
=	O
sup	O
ψ∈Ψ	O
GCMMD	O
µ	O
,	O
k	O
ψ	O
,	O
λ	O
yields	O
a	O
good	O
generative	B-Method
model	I-Method
on	O
MNIST	B-Material
.	O
	
But	O
the	O
linear	B-Method
system	I-Method
of	I-Method
size	I-Method
M	I-Method
+	I-Method
M	I-Method
d	I-Method
is	O
impractical	O
:	O
even	O
on	O
28	O
×	O
28	O
images	O
and	O
using	O
a	O
low	B-Method
-	I-Method
rank	I-Method
approximation	I-Method
,	O
the	O
model	O
took	O
days	O
to	O
converge	O
.	O
	
We	O
therefore	O
design	O
a	O
less	O
expensive	O
discrepancy	O
in	O
the	O
next	O
section	O
.	O
	
The	O
GCMMD	B-Method
is	O
related	O
to	O
some	O
discrepancies	O
previously	O
used	O
in	O
IGM	B-Task
training	I-Task
.	O
	
The	O
Fisher	O
GAN	B-Method
[	O
reference	O
]	O
uses	O
only	O
the	O
variance	O
constraint	O
f	O
	
along	O
with	O
a	O
vanishing	O
boundary	O
condition	O
on	O
f	O
to	O
ensure	O
a	O
well	O
-	O
defined	O
solution	O
(	O
although	O
this	O
was	O
not	O
used	O
in	O
the	O
implementation	O
,	O
and	O
can	O
cause	O
very	O
unintuitive	O
critic	O
behavior	O
;	O
see	O
Appendix	O
C	O
)	O
.	O
	
The	O
authors	O
considered	O
several	O
choices	O
of	O
µ	O
,	O
including	O
the	O
WGAN	B-Method
-	I-Method
GP	I-Method
measure	I-Method
[	O
reference	O
]	O
and	O
mixtures	O
(	O
P	O
+	O
Q	O
θ	O
)	O
	
/	O
2	O
.	O
	
Rather	O
than	O
enforcing	O
the	O
constraints	O
in	O
closed	O
form	O
as	O
we	O
do	O
,	O
though	O
,	O
these	O
models	O
used	O
additive	B-Method
regularization	I-Method
.	O
	
We	O
will	O
compare	O
to	O
the	O
Sobolev	O
GAN	B-Method
in	O
experiments	O
.	O
	
section	O
:	O
Scaled	O
Maximum	B-Method
Mean	I-Method
Discrepancy	I-Method
	
We	O
will	O
now	O
derive	O
a	O
lower	O
bound	O
on	O
the	O
Gradient	O
-	O
Constrained	O
MMD	B-Method
which	O
retains	O
many	O
of	O
its	O
attractive	O
qualities	O
but	O
can	O
be	O
estimated	O
in	O
time	O
linear	O
in	O
the	O
dimension	O
d.	O
	
We	O
then	O
define	O
the	O
Scaled	O
Maximum	B-Method
Mean	I-Method
Discrepancy	I-Method
based	O
on	O
this	O
bound	O
of	O
Proposition	O
4	O
:	O
	
4	O
	
We	O
use	O
(	O
m	O
,	O
i	O
)	O
to	O
denote	O
(	O
m	O
−	O
1	O
)	O
d	O
+	O
i	O
;	O
thus	O
∇η	O
(	O
X	O
)	O
stacks	O
∇η	O
(	O
X1	O
)	O
,	O
.	O
.	O
.	O
,	O
∇η	O
(	O
XM	O
)	O
into	O
one	O
vector	O
.	O
	
[	O
reference	O
]	O
	
We	O
use	O
∂ik	O
(	O
x	O
,	O
y	O
)	O
to	O
denote	O
the	O
partial	O
derivative	O
with	O
respect	O
to	O
xi	O
,	O
and	O
∂	O
i	O
+	O
d	O
k	O
(	O
x	O
,	O
y	O
)	O
	
that	O
for	O
yi	O
.	O
	
Because	O
the	O
constraint	O
in	O
the	O
optimization	B-Task
of	O
(	O
7	O
)	O
is	O
more	O
restrictive	O
than	O
in	O
that	O
of	O
(	O
5	O
)	O
,	O
we	O
have	O
that	O
SMMD	B-Method
µ	O
,	O
k	O
,	O
λ	O
(	O
P	O
,	O
Q	O
)	O
≤	O
GCMMD	O
µ	O
,	O
k	O
,	O
λ	O
(	O
P	O
,	O
Q	O
)	O
.	O
	
The	O
Sobolev	O
norm	O
f	O
S	O
(	O
µ	O
),	O
λ	O
,	O
and	O
a	O
fortiori	O
the	O
gradient	O
norm	O
under	O
µ	O
,	O
is	O
thus	O
also	O
controlled	O
for	O
the	O
SMMD	B-Method
critic	O
.	O
	
We	O
also	O
show	O
in	O
Appendix	O
F.1	O
that	O
SMMD	B-Method
µ	O
,	O
k	O
,	O
λ	O
behaves	O
similarly	O
to	O
GCMMD	B-Method
µ	I-Method
,	I-Method
k	I-Method
,	O
λ	O
on	O
Gaussians	B-Method
.	O
	
F	O
.	O
	
Estimating	O
these	O
terms	O
based	O
on	O
samples	O
from	O
µ	O
is	O
straightforward	O
,	O
giving	O
a	O
natural	O
estimator	B-Method
for	O
the	O
SMMD	B-Method
.	O
	
Of	O
course	O
,	O
if	O
µ	O
and	O
k	O
are	O
fixed	O
,	O
the	O
SMMD	B-Method
is	O
simply	O
a	O
constant	O
times	O
the	O
MMD	B-Method
,	O
and	O
so	O
behaves	O
in	O
essentially	O
the	O
same	O
way	O
as	O
the	O
MMD	B-Method
.	O
	
But	O
optimizing	O
the	O
SMMD	B-Method
over	O
a	O
kernel	B-Method
family	I-Method
Ψ	I-Method
,	O
D	B-Metric
µ	I-Metric
,	I-Metric
Ψ	I-Metric
,	O
λ	O
Figure	O
1	O
(	O
b	O
)	O
shows	O
the	O
vector	O
field	O
for	O
the	O
Optimized	O
SMMD	B-Method
loss	O
in	O
Example	O
1	O
,	O
using	O
the	O
WGAN	B-Method
-	I-Method
GP	I-Method
measure	I-Method
µ	O
=	O
Uniform	O
(	O
0	O
,	O
θ	O
)	O
.	O
	
The	O
optimization	O
surface	O
is	O
far	O
more	O
amenable	O
:	O
in	O
particular	O
the	O
location	O
C	O
,	O
which	O
formerly	O
had	O
an	O
extremely	O
small	O
gradient	O
that	O
made	O
learning	B-Task
effectively	O
impossible	O
	
,	O
now	O
converges	O
very	O
quickly	O
by	O
first	O
reducing	O
the	O
critic	O
gradient	O
until	O
some	O
signal	O
is	O
available	O
.	O
	
Figure	O
1	O
	
s	O
a	O
fully	B-Method
-	I-Method
connected	I-Method
L	I-Method
-	I-Method
layer	I-Method
network	I-Method
with	O
Leaky	B-Method
-	I-Method
ReLU	I-Method
α	I-Method
activations	I-Method
whose	O
layers	O
do	O
not	O
increase	O
in	O
width	O
,	O
and	O
K	O
satisfying	O
mild	O
smoothness	O
conditions	O
Q	O
K	O
<	O
∞	O
	
(	O
Assumptions	O
(	O
II	O
)	O
to	O
(	O
V	O
)	O
in	O
Appendix	O
A.2	O
)	O
.	O
	
Let	O
Ψ	O
κ	O
be	O
the	O
set	O
of	O
parameters	O
where	O
each	O
layer	O
's	O
weight	O
matrices	O
have	O
condition	O
number	O
cond	O
(	O
	
.	O
	
SMMD	B-Method
(	O
P	O
n	O
,	O
P	O
)	O
	
→	O
0	O
,	O
even	O
if	O
µ	O
is	O
chosen	O
to	O
depend	O
on	O
P	O
and	O
Q.	O
	
section	O
:	O
Uniform	O
bounds	O
vs	O
bounds	O
in	O
expectation	O
Controlling	O
	
not	O
necessarily	O
imply	O
a	O
bound	O
on	O
f	O
Lip	O
≥	O
	
sup	O
x∈X	O
∇f	O
	
ψ	O
(	O
X	O
)	O
,	O
and	O
so	O
does	O
not	O
in	O
general	O
give	O
continuity	O
via	O
Proposition	O
2	O
.	O
	
Theorem	O
1	O
implies	O
that	O
when	O
the	O
network	O
's	O
weights	O
are	O
well	O
-	O
conditioned	O
,	O
it	O
is	O
sufficient	O
to	O
only	O
control	O
∇f	O
ψ	O
2	O
L	O
2	O
(	O
µ	O
)	O
,	O
which	O
is	O
far	O
easier	O
in	O
practice	O
than	O
controlling	O
f	O
Lip	O
.	O
	
If	O
we	O
instead	O
tried	O
to	O
directly	O
controlled	O
f	O
Lip	O
with	O
e.g.	O
spectral	B-Method
normalization	I-Method
(	O
SN	B-Method
)	O
	
[	O
reference	O
]	O
,	O
we	O
could	O
significantly	O
reduce	O
the	O
expressiveness	O
of	O
the	O
parametric	B-Method
family	I-Method
.	O
	
In	O
Example	O
1	O
,	O
constraining	O
φ	O
ψ	O
Lip	O
=	O
1	O
limits	O
us	O
to	O
only	O
Ψ	O
=	O
	
{	O
1}.	O
Thus	O
D	O
	
section	O
:	O
{	O
1	O
}	O
	
MMD	B-Method
is	O
simply	O
the	O
MMD	B-Method
with	O
an	O
RBF	B-Method
kernel	I-Method
of	I-Method
bandwidth	I-Method
1	I-Method
,	O
which	O
has	O
poor	O
gradients	O
when	O
θ	O
is	O
far	O
from	O
0	O
	
(	O
Figure	O
1	O
(	O
c	O
)	O
,	O
blue	O
)	O
.	O
	
The	O
CauchySchwartz	O
bound	O
of	O
Proposition	O
4	O
allows	O
jointly	O
adjusting	O
the	O
smoothness	O
of	O
k	O
ψ	O
and	O
the	O
critic	O
f	O
,	O
while	O
SN	B-Method
must	O
control	O
the	O
two	O
independently	O
.	O
	
Relatedly	O
,	O
limiting	O
φ	O
Lip	O
by	O
limiting	O
the	O
Lipschitz	O
norm	O
of	O
each	O
layer	O
could	O
substantially	O
reduce	O
capacity	B-Metric
,	O
while	O
∇f	O
	
ψ	O
L	O
	
2	O
(	O
µ	O
)	O
need	O
not	O
be	O
decomposed	O
by	O
layer	O
.	O
	
Another	O
advantage	O
is	O
that	O
µ	O
provides	O
a	O
data	O
-	O
dependent	B-Metric
measure	I-Metric
of	I-Metric
complexity	I-Metric
as	O
in	O
[	O
reference	O
]	O
:	O
we	O
do	O
not	O
needlessly	O
prevent	O
ourselves	O
from	O
using	O
critics	B-Method
that	O
behave	O
poorly	O
only	O
far	O
from	O
the	O
data	O
.	O
	
Spectral	B-Method
parametrization	I-Method
When	O
the	O
generator	O
is	O
near	O
a	O
local	O
optimum	O
,	O
the	O
critic	O
might	O
identify	O
only	O
one	O
direction	O
on	O
which	O
Q	O
θ	O
and	O
P	O
differ	O
.	O
	
If	O
the	O
generator	B-Method
parameterization	I-Method
is	O
such	O
that	O
there	O
is	O
no	O
local	O
way	O
for	O
the	O
generator	O
to	O
correct	O
it	O
,	O
the	O
critic	O
may	O
begin	O
to	O
single	O
-	O
mindedly	O
focus	O
on	O
this	O
difference	O
,	O
choosing	O
redundant	B-Method
convolutional	I-Method
filters	I-Method
and	O
causing	O
the	O
condition	O
number	O
of	O
the	O
weights	O
to	O
diverge	O
.	O
	
If	O
this	O
occurs	O
,	O
the	O
generator	O
will	O
be	O
motivated	O
to	O
fix	O
this	O
single	O
direction	O
while	O
ignoring	O
all	O
other	O
aspects	O
of	O
the	O
distributions	O
,	O
after	O
which	O
it	O
may	O
become	O
stuck	O
.	O
	
We	O
can	O
help	O
avoid	O
this	O
collapse	O
by	O
using	O
a	O
critic	B-Method
parameterization	I-Method
that	O
encourages	O
diverse	O
filters	O
with	O
higher	O
-	O
rank	O
weight	O
matrices	O
.	O
	
Miyato	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
propose	O
to	O
parameterize	O
the	O
weight	O
matrices	O
as	O
W	O
=	O
	
γW	B-Method
/	I-Method
W	I-Method
op	I-Method
,	O
where	O
W	O
op	O
is	O
the	O
spectral	O
norm	O
ofW	O
.	O
	
This	O
parametrization	O
works	O
particularly	O
well	O
with	O
D	O
	
section	O
:	O
Experiments	O
	
We	O
evaluated	O
unsupervised	O
image	B-Task
generation	I-Task
on	O
three	O
datasets	O
:	O
CIFAR	B-Material
-	I-Material
10	I-Material
[	O
reference	O
]	O
(	O
60	O
000	O
images	O
,	O
32	O
×	O
32	O
)	O
,	O
CelebA	B-Material
[	O
reference	O
]	O
(	O
	
202	O
599	O
face	O
images	O
,	O
resized	O
and	O
cropped	O
to	O
160	O
×	O
160	O
as	O
in	O
[	O
reference	O
]	O
)	O
,	O
and	O
the	O
more	O
challenging	O
	
ILSVRC2012	B-Material
(	I-Material
ImageNet	I-Material
)	I-Material
dataset	I-Material
[	O
reference	O
]	O
(	O
1	O
281	O
167	O
images	O
,	O
resized	O
to	O
64	O
×	O
64	O
)	O
.	O
	
Code	O
for	O
all	O
of	O
these	O
experiments	O
is	O
available	O
at	O
github.com	O
/	O
MichaelArbel	O
/	O
Scaled	O
-	O
MMD	B-Method
-	O
GAN	B-Method
.	O
	
Losses	O
All	O
models	O
are	O
based	O
on	O
a	O
scalar	B-Method
-	I-Method
output	I-Method
critic	I-Method
network	I-Method
φ	O
ψ	O
:	O
X	O
→	O
R	O
,	O
except	O
MMDGAN	B-Method
-	I-Method
GP	I-Method
where	O
φ	O
ψ	O
:	O
	
X	O
→	O
R	O
16	O
as	O
in	O
[	O
reference	O
]	O
.	O
The	O
WGAN	O
and	O
Sobolev	O
GAN	B-Method
use	O
a	O
critic	B-Method
f	I-Method
=	O
φ	B-Method
ψ	I-Method
,	O
while	O
the	O
GAN	B-Method
uses	O
a	O
discriminator	B-Method
D	I-Method
ψ	I-Method
(	O
x	O
)	O
=	O
1	O
/(	O
1	O
+	O
exp	O
(	O
−φ	O
ψ	O
(	O
x	O
)	O
)	O
)	O
.	O
	
The	O
MMD	B-Method
-	O
based	O
methods	O
use	O
a	O
kernel	B-Method
	
2	O
/	O
2	O
)	O
,	O
except	O
for	O
MMDGAN	B-Method
-	I-Method
GP	I-Method
which	O
uses	O
a	O
mixture	B-Method
of	I-Method
RQ	I-Method
kernels	I-Method
as	O
in	O
[	O
reference	O
]	O
.	O
Increasing	O
the	O
output	O
dimension	O
of	O
the	O
critic	O
or	O
using	O
a	O
different	O
kernel	O
did	O
n't	O
substantially	O
change	O
the	O
performance	O
of	O
our	O
proposed	O
method	O
.	O
	
We	O
also	O
consider	O
SMMD	B-Method
with	O
a	O
linear	O
top	O
-	O
level	O
kernel	O
,	O
k	O
(	O
x	O
,	O
y	O
)	O
=	O
φ	O
ψ	O
(	O
x	O
)	O
φ	O
ψ	O
(	O
y	O
)	O
;	O
because	O
this	O
becomes	O
essentially	O
identical	O
to	O
a	O
WGAN	B-Method
(	O
Appendix	O
E	O
)	O
,	O
we	O
refer	O
to	O
this	O
method	O
as	O
SWGAN	B-Method
.	O
	
SMMD	B-Method
and	O
SWGAN	B-Method
use	O
	
µ	O
=	O
P	O
;	O
Sobolev	O
GAN	B-Method
uses	O
µ	O
=	O
	
(	O
P	O
+	O
Q	O
)/	O
2	O
	
as	O
in	O
[	O
reference	O
]	O
.	O
We	O
choose	O
λ	O
and	O
an	O
overall	O
scaling	O
to	O
obtain	O
the	O
losses	O
:	O
	
,	O
SWGAN	O
:	O
	
.	O
	
Architecture	O
	
For	O
CIFAR	B-Material
-	I-Material
10	I-Material
,	O
we	O
used	O
the	O
CNN	B-Method
architecture	I-Method
proposed	O
by	O
[	O
reference	O
]	O
with	O
a	O
7	B-Method
-	I-Method
layer	I-Method
critic	I-Method
and	O
a	O
4	B-Method
-	I-Method
layer	I-Method
generator	I-Method
.	O
	
For	O
CelebA	B-Material
,	O
we	O
used	O
a	O
5	B-Method
-	I-Method
layer	I-Method
DCGAN	I-Method
discriminator	I-Method
and	O
a	O
10	B-Method
-	I-Method
layer	I-Method
ResNet	I-Method
generator	I-Method
as	O
in	O
[	O
reference	O
]	O
.	O
For	O
ImageNet	B-Material
,	O
we	O
used	O
a	O
10	B-Method
-	I-Method
layer	I-Method
ResNet	I-Method
for	O
both	O
the	O
generator	B-Method
and	O
discriminator	B-Method
.	O
	
In	O
all	O
experiments	O
we	O
used	O
64	O
filters	O
for	O
the	O
smallest	O
convolutional	B-Method
layer	I-Method
,	O
and	O
double	O
it	O
at	O
each	O
layer	O
(	O
CelebA	B-Material
/	O
ImageNet	B-Material
)	O
or	O
every	O
other	O
layer	O
(	O
CIFAR	B-Material
-	I-Material
10	I-Material
)	O
.	O
	
The	O
input	O
codes	O
for	O
the	O
generator	O
are	O
drawn	O
from	O
Uniform	O
[	O
−1	O
,	O
1	O
]	O
128	O
.	O
	
We	O
consider	O
two	O
parameterizations	O
for	O
each	O
critic	O
:	O
a	O
standard	O
one	O
where	O
the	O
parameters	O
can	O
take	O
any	O
real	O
value	O
,	O
and	O
a	O
spectral	B-Method
parametrization	I-Method
(	O
denoted	O
SN	B-Method
-	O
)	O
as	O
above	O
[	O
reference	B-Method
]	I-Method
.	I-Method
Models	I-Method
without	O
explicit	B-Method
gradient	I-Method
control	I-Method
(	O
SN	B-Method
-	I-Method
GAN	I-Method
,	O
SN	B-Method
-	O
MMDGAN	B-Method
,	O
SN	B-Method
-	O
MMGAN	O
-	O
L2	O
,	O
	
SN	B-Method
-	O
WGAN	O
)	O
	
fix	O
γ	O
=	O
1	O
,	O
for	O
spectral	B-Method
normalization	I-Method
;	O
others	O
learn	O
γ	O
,	O
using	O
a	O
spectral	B-Method
parameterization	I-Method
.	O
	
Training	O
All	O
models	O
were	O
trained	O
for	O
150	O
000	O
generator	O
updates	O
on	O
a	O
single	O
GPU	O
,	O
except	O
for	O
ImageNet	B-Material
where	O
the	O
model	O
was	O
trained	O
on	O
3	O
GPUs	O
simultaneously	O
.	O
	
To	O
limit	O
communication	O
overhead	O
we	O
averaged	O
the	O
MMD	B-Method
estimate	O
on	O
each	O
GPU	B-Method
,	O
giving	O
the	O
block	O
MMD	B-Method
estimator	O
[	O
reference	O
]	O
.	O
	
We	O
always	O
used	O
64	O
samples	O
per	O
GPU	O
from	O
each	O
of	O
P	O
and	O
Q	O
,	O
and	O
5	O
critic	B-Method
updates	I-Method
per	O
generator	O
step	O
.	O
	
We	O
used	O
initial	O
learning	B-Metric
rates	I-Metric
of	O
0.0001	O
for	O
CIFAR	B-Material
-	I-Material
10	I-Material
and	O
CelebA	B-Material
,	O
0.0002	O
for	O
ImageNet	B-Material
,	O
and	O
decayed	O
these	O
rates	O
using	O
the	O
KID	B-Method
adaptive	I-Method
scheme	I-Method
of	O
[	O
reference	O
]	O
:	O
every	O
2	O
000	O
steps	O
,	O
generator	O
samples	O
are	O
compared	O
to	O
those	O
from	O
20	O
000	O
steps	O
ago	O
,	O
and	O
if	O
the	O
relative	O
KID	O
test	O
[	O
reference	O
]	O
fails	O
to	O
show	O
an	O
improvement	O
three	O
consecutive	O
times	O
,	O
the	O
learning	B-Metric
rate	I-Metric
is	O
decayed	O
by	O
0.8	O
.	O
	
We	O
used	O
the	O
Adam	B-Method
optimizer	I-Method
[	O
reference	O
]	O
with	O
β	O
1	O
=	O
0.5	O
,	O
β	O
2	O
=	O
0.9	O
.	O
	
Evaluation	O
To	O
compare	O
the	O
sample	B-Metric
quality	I-Metric
of	O
different	O
models	O
,	O
we	O
considered	O
three	O
different	O
scores	O
based	O
on	O
the	O
Inception	B-Method
network	I-Method
[	O
reference	O
]	O
trained	O
for	O
ImageNet	B-Task
classification	I-Task
,	O
all	O
using	O
default	O
parameters	O
in	O
the	O
implementation	O
of	O
[	O
reference	O
]	O
.	O
	
The	O
Inception	B-Metric
Score	I-Metric
(	O
IS	B-Metric
)	O
	
[	O
reference	O
]	O
is	O
based	O
on	O
the	O
entropy	O
of	O
predicted	O
labels	O
;	O
higher	O
values	O
are	O
better	O
.	O
	
Though	O
standard	O
,	O
this	O
metric	O
has	O
many	O
issues	O
,	O
particularly	O
on	O
datasets	O
other	O
than	O
ImageNet	B-Material
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
The	O
FID	B-Metric
[	O
reference	O
]	O
instead	O
measures	O
the	O
similarity	O
of	O
samples	O
from	O
the	O
generator	O
and	O
the	O
target	O
as	O
the	O
Wasserstein	O
-	O
2	O
distance	O
between	O
Gaussians	B-Method
fit	O
to	O
their	O
intermediate	B-Method
representations	I-Method
.	O
	
It	O
is	O
more	O
sensible	O
than	O
the	O
IS	B-Metric
and	O
becoming	O
standard	O
,	O
but	O
its	O
estimator	O
is	O
strongly	O
biased	O
[	O
reference	O
]	O
.	O
The	O
KID	B-Method
[	O
reference	O
]	O
is	O
similar	O
to	O
FID	B-Metric
,	O
but	O
by	O
using	O
a	O
polynomial	O
-	O
kernel	O
MMD	B-Method
its	O
estimates	O
enjoy	O
better	O
statistical	B-Metric
properties	I-Metric
and	O
are	O
easier	O
to	O
compare	O
.	O
	
(	O
A	O
similar	O
score	O
was	O
recommended	O
by	O
[	O
reference	O
]	O
.	O
)	O
	
Results	O
Table	O
1a	O
presents	O
the	O
scores	O
for	O
models	O
trained	O
on	O
both	O
CIFAR	B-Material
-	I-Material
10	I-Material
and	O
CelebA	B-Material
datasets	I-Material
.	O
	
On	O
CIFAR	B-Material
-	I-Material
10	I-Material
,	O
SN	B-Method
-	I-Method
SWGAN	I-Method
and	O
SN	B-Method
-	I-Method
SMMDGAN	I-Method
performed	O
comparably	O
to	O
SN	B-Method
-	I-Method
GAN	I-Method
.	O
	
But	O
on	O
CelebA	B-Material
,	O
SN	B-Method
-	I-Method
SWGAN	I-Method
and	O
SN	B-Method
-	I-Method
SMMDGAN	I-Method
dramatically	O
outperformed	O
the	O
other	O
methods	O
with	O
the	O
same	O
architecture	O
in	O
all	O
three	O
metrics	O
.	O
	
It	O
also	O
trained	O
faster	O
,	O
and	O
consistently	O
outperformed	O
other	O
methods	O
over	O
multiple	O
initializations	O
(	O
Figure	O
2	O
(	O
a	O
)	O
)	O
.	O
	
It	O
is	O
worth	O
noting	O
that	O
SN	B-Method
-	I-Method
SWGAN	I-Method
far	O
outperformed	O
WGAN	B-Method
-	I-Method
GP	I-Method
on	O
both	O
datasets	O
.	O
	
Table	O
1b	O
presents	O
the	O
scores	O
for	O
SMMDGAN	B-Method
and	O
SN	B-Method
-	I-Method
SMMDGAN	I-Method
trained	O
on	O
ImageNet	B-Material
,	O
and	O
the	O
scores	O
of	O
pre	B-Method
-	I-Method
trained	I-Method
models	I-Method
using	O
BGAN	B-Method
[	O
reference	O
]	O
and	O
SN	B-Method
-	I-Method
GAN	I-Method
[	O
reference	O
]	O
.	O
[	O
reference	O
]	O
	
The	O
proposed	O
methods	O
substantially	O
outperformed	O
both	O
methods	O
in	O
FID	B-Metric
and	O
KID	B-Metric
scores	I-Metric
.	O
	
Figure	O
3	O
shows	O
samples	O
on	O
ImageNet	B-Material
and	O
CelebA	B-Material
;	O
Appendix	O
F.4	O
has	O
more	O
.	O
	
Spectrally	O
normalized	O
WGANs	B-Method
/	O
MMDGANs	B-Method
To	O
control	O
for	O
the	O
contribution	O
of	O
the	O
spectral	B-Method
parametrization	I-Method
to	O
the	O
performance	O
,	O
we	O
evaluated	O
variants	O
of	O
MMDGANs	B-Method
,	O
WGANs	B-Method
and	O
Sobolev	O
-	O
GAN	B-Method
using	O
spectral	B-Method
normalization	I-Method
(	O
in	O
Table	O
2	O
,	O
Appendix	O
F.3	O
)	O
.	O
	
WGAN	B-Method
and	O
Sobolev	O
-	O
GAN	B-Method
led	O
to	O
unstable	O
training	O
and	O
did	O
n't	O
converge	O
at	O
all	O
(	O
Figure	O
11	O
)	O
despite	O
many	O
attempts	O
.	O
	
MMDGAN	B-Method
converged	O
on	O
CIFAR	B-Material
-	I-Material
10	I-Material
(	O
Figure	O
11	O
)	O
but	O
was	O
unstable	O
on	O
CelebA	B-Material
(	O
Figure	O
10	O
)	O
.	O
	
The	O
gradient	B-Method
control	I-Method
due	O
to	O
SN	B-Method
is	O
thus	O
probably	O
too	O
loose	O
for	O
these	O
methods	O
.	O
	
This	O
is	O
reinforced	O
by	O
Figure	O
2	O
(	O
c	O
)	O
,	O
which	O
shows	O
that	O
the	O
expected	O
gradient	O
of	O
the	O
critic	B-Method
network	I-Method
is	O
much	O
better	O
-	O
controlled	O
by	O
SMMD	B-Method
,	O
even	O
when	O
SN	B-Method
is	O
used	O
.	O
	
We	O
also	O
considered	O
variants	O
of	O
these	O
models	O
with	O
a	O
learned	O
γ	O
while	O
also	O
adding	O
a	O
gradient	O
penalty	O
and	O
an	O
L	O
2	O
penalty	O
on	O
critic	O
activations	O
	
[	O
reference	O
]	O
.	O
These	O
generally	O
behaved	O
similarly	O
to	O
MMDGAN	B-Method
,	O
and	O
did	O
n't	O
lead	O
to	O
substantial	O
improvements	O
.	O
	
We	O
ran	O
the	O
same	O
experiments	O
on	O
CelebA	B-Material
,	O
but	O
aborted	O
the	O
runs	O
early	O
when	O
it	O
became	O
clear	O
that	O
training	O
was	O
not	O
successful	O
.	O
	
Rank	B-Method
collapse	I-Method
	
We	O
occasionally	O
observed	O
the	O
failure	O
mode	O
for	O
SMMD	B-Method
where	O
the	O
critic	O
becomes	O
low	O
-	O
rank	O
,	O
discussed	O
in	O
Section	O
3.3	O
,	O
especially	O
on	O
CelebA	B-Material
;	O
this	O
failure	O
was	O
obvious	O
even	O
in	O
the	O
training	B-Metric
objective	I-Metric
.	O
	
Figure	O
2	O
(	O
b	O
)	O
is	O
one	O
of	O
these	O
examples	O
.	O
	
Spectral	B-Method
parametrization	I-Method
seemed	O
to	O
prevent	O
this	O
behavior	O
.	O
	
We	O
also	O
found	O
one	O
could	O
avoid	O
collapse	O
by	O
reverting	O
to	O
an	O
earlier	O
checkpoint	O
and	O
increasing	O
the	O
RKHS	O
regularization	O
parameter	O
λ	O
,	O
but	O
did	O
not	O
do	O
this	O
for	O
any	O
of	O
the	O
experiments	O
here	O
.	O
	
section	O
:	O
Conclusion	O
	
We	O
studied	O
gradient	B-Method
regularization	I-Method
for	O
MMD	B-Method
-	O
based	O
critics	O
in	O
implicit	B-Method
generative	I-Method
models	I-Method
,	O
clarifying	O
how	O
previous	O
techniques	O
relate	O
to	O
the	O
D	O
Ψ	O
MMD	B-Method
loss	O
.	O
	
Based	O
on	O
these	O
insights	O
,	O
we	O
proposed	O
the	O
GradientConstrained	O
MMD	B-Method
and	O
its	O
approximation	O
the	O
Scaled	O
MMD	B-Method
,	O
a	O
new	O
loss	B-Metric
function	I-Metric
for	O
IGMs	B-Method
that	O
controls	O
gradient	O
behavior	O
in	O
a	O
principled	O
way	O
and	O
obtains	O
excellent	O
performance	O
in	O
practice	O
.	O
	
One	O
interesting	O
area	O
of	O
future	O
study	O
for	O
these	O
distances	O
is	O
their	O
behavior	O
when	O
used	O
to	O
diffuse	O
particles	O
distributed	O
as	O
Q	O
towards	O
particles	O
distributed	O
as	O
P.	O
Mroueh	O
et	O
al	O
.	O
	
[	O
reference	O
][	O
reference	O
]	O
began	O
such	O
a	O
study	O
for	O
the	O
Sobolev	O
GAN	B-Method
loss	O
;	O
[	O
reference	O
]	O
proved	O
convergence	O
and	O
studied	O
discrete	B-Method
-	I-Method
time	I-Method
approximations	I-Method
.	O
	
Another	O
area	O
to	O
explore	O
is	O
the	O
geometry	O
of	O
these	O
losses	O
,	O
as	O
studied	O
by	O
Bottou	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
,	O
who	O
showed	O
potential	O
advantages	O
of	O
the	O
Wasserstein	B-Method
geometry	I-Method
over	O
the	O
MMD	B-Method
.	O
	
Their	O
results	O
,	O
though	O
,	O
do	O
not	O
address	O
any	O
distances	O
based	O
on	O
optimized	B-Method
kernels	I-Method
;	O
the	O
new	O
distances	O
introduced	O
here	O
might	O
have	O
interesting	O
geometry	O
of	O
their	O
own	O
.	O
	
section	O
:	O
9	O
	
section	O
:	O
A	O
Proofs	O
	
We	O
first	O
review	O
some	O
basic	O
properties	O
of	O
Reproducing	B-Method
Kernel	I-Method
Hilbert	I-Method
Spaces	I-Method
.	O
	
We	O
consider	O
here	O
a	O
separable	O
RKHS	O
H	O
with	O
basis	O
(	O
e	O
i	O
)	O
	
i∈I	O
,	O
where	O
I	O
is	O
either	O
finite	O
if	O
H	O
is	O
finite	O
-	O
dimensional	O
,	O
or	O
I	O
=	O
	
N	O
otherwise	O
.	O
	
We	O
also	O
assume	O
that	O
the	O
reproducing	B-Method
kernel	I-Method
k	I-Method
is	O
continuously	O
twice	O
differentiable	O
.	O
	
We	O
use	O
a	O
slightly	O
nonstandard	O
notation	O
for	O
derivatives	O
:	O
∂	O
	
i	O
f	O
(	O
x	O
)	O
denotes	O
the	O
ith	O
partial	O
derivative	O
of	O
f	O
evaluated	O
at	O
x	O
,	O
and	O
∂	O
i	O
∂	O
	
j	O
+	O
d	O
k	O
(	O
x	O
,	O
y	O
)	O
denotes	O
	
We	O
say	O
that	O
an	O
operator	O
A	O
:	O
H	O
	
→	O
H	O
is	O
Hilbert	O
-	O
Schmidt	O
	
if	O
A	O
2	O
HS	O
=	O
i∈I	O
	
Ae	O
i	O
	
2	O
H	O
is	O
finite	O
.	O
	
A	O
HS	O
is	O
called	O
the	O
Hilbert	O
-	O
Schmidt	O
norm	O
of	O
A.	O
The	O
space	O
of	O
Hilbert	O
-	O
Schmidt	O
operators	O
itself	O
a	O
Hilbert	O
space	O
with	O
the	O
inner	O
product	O
A	O
,	O
B	O
HS	O
	
=	O
i∈I	O
	
Ae	O
i	O
,	O
Be	O
i	O
H	O
.	O
	
Moreover	O
,	O
we	O
say	O
that	O
an	O
operator	O
A	O
is	O
trace	O
-	O
class	O
if	O
its	O
trace	O
norm	O
is	O
finite	O
,	O
i.e.	O
A	O
1	O
	
=	O
i∈I	O
	
e	O
i	O
,	O
	
(	O
A	O
*	O
A	O
)	O
	
Given	O
two	O
vectors	O
f	O
and	O
g	O
in	O
H	O
and	O
a	O
Hilbert	B-Method
-	I-Method
Schmidt	I-Method
operator	I-Method
	
A	O
	
we	O
have	O
the	O
following	O
properties	O
:	O
	
(	O
i	O
)	O
	
The	O
outer	B-Method
product	I-Method
f	I-Method
⊗	I-Method
g	I-Method
is	O
a	O
Hilbert	B-Method
-	I-Method
Schmidt	I-Method
operator	I-Method
with	O
Hilbert	B-Method
-	I-Method
Schmidt	I-Method
norm	I-Method
given	O
by	O
:	O
	
ii	O
)	O
	
The	O
inner	O
product	O
between	O
two	O
rank	O
-	O
one	O
operators	O
f	O
⊗	O
g	O
and	O
u	O
	
The	O
following	O
identity	O
holds	O
:	O
f	O
,	O
	
Ag	O
H	O
=	O
f	O
	
⊗	O
g	O
,	O
A	O
HS	O
.	O
	
Define	O
the	O
following	O
covariance	B-Method
-	I-Method
type	I-Method
operators	I-Method
:	O
[	O
reference	O
]	O
these	O
are	O
useful	O
in	O
that	O
,	O
using	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
	
section	O
:	O
A.1	O
Definitions	O
and	O
estimators	O
of	O
the	O
new	O
distances	O
	
We	O
will	O
need	O
the	O
following	O
assumptions	O
about	O
the	O
distributions	O
P	O
and	O
Q	O
,	O
the	O
measure	O
µ	O
,	O
and	O
the	O
kernel	B-Method
k	I-Method
:	O
	
(	O
A	O
)	O
P	O
and	O
Q	O
have	O
integrable	O
first	O
moments	O
.	O
	
(	O
B	O
)	O
k	O
(	O
x	O
,	O
x	O
)	O
grows	O
at	O
most	O
linearly	O
in	O
x	O
:	O
for	O
all	O
x	O
in	O
X	O
,	O
	
k	O
(	O
x	O
,	O
x	O
)	O
≤	O
C	O
(	O
x	O
+	O
1	O
)	O
for	O
some	O
constant	O
C.	O
	
is	O
automatically	O
satisfied	O
by	O
a	O
K	O
such	O
as	O
the	O
Gaussian	B-Method
;	O
when	O
K	O
is	O
linear	O
,	O
it	O
is	O
true	O
for	O
a	O
quite	O
general	O
class	O
of	O
networks	O
φ	O
ψ	O
[	O
7	O
,	O
Lemma	O
1	O
]	O
.	O
	
We	O
will	O
first	O
give	O
a	O
form	O
for	O
the	O
Gradient	O
-	O
Constrained	O
MMD	B-Method
(	O
5	O
)	O
in	O
terms	O
of	O
the	O
operator	O
(	O
10	O
)	O
:	O
	
Proposition	O
5	O
.	O
	
Under	O
Assumptions	O
(	O
A	O
)	O
to	O
(	O
D	O
)	O
,	O
the	O
Gradient	O
-	O
Constrained	O
MMD	B-Method
is	O
given	O
by	O
	
Proof	O
of	O
Proposition	O
5	O
.	O
	
Let	O
f	O
be	O
a	O
function	O
in	O
H.	O
We	O
will	O
first	O
express	O
the	O
squared	O
λ	O
-	O
regularized	O
Sobolev	O
norm	O
of	O
f	O
(	O
6	O
)	O
as	O
a	O
quadratic	O
form	O
in	O
H.	O
Recalling	O
the	O
reproducing	O
properties	O
of	O
(	O
8	O
)	O
and	O
(	O
9	O
)	O
,	O
we	O
have	O
:	O
	
Using	O
Property	O
(	O
ii	O
)	O
and	O
the	O
operator	O
(	O
10	O
)	O
,	O
one	O
further	O
gets	O
	
Under	O
Assumption	O
(	O
D	O
)	O
,	O
and	O
using	O
Lemma	O
6	O
,	O
one	O
can	O
take	O
the	O
integral	O
inside	O
the	O
inner	O
product	O
,	O
which	O
leads	O
to	O
f	O
	
H	O
.	O
	
Finally	O
,	O
using	O
Property	O
(	O
iii	O
)	O
it	O
follows	O
that	O
	
Under	O
Assumptions	O
(	O
A	O
)	O
and	O
(	O
B	O
)	O
,	O
Lemma	O
6	O
applies	O
,	O
and	O
it	O
follows	O
that	O
k	O
(	O
x	O
,	O
·	O
)	O
is	O
also	O
Bochner	O
integrable	O
under	O
P	O
and	O
Q.	O
Thus	O
	
where	O
η	O
is	O
defined	O
as	O
this	O
difference	O
in	O
mean	O
embeddings	O
.	O
	
Since	O
D	O
µ	O
,	O
λ	O
is	O
symmetric	O
positive	O
definite	O
,	O
its	O
square	O
-	O
root	O
D	O
µ	O
,	O
λ	O
is	O
well	O
-	O
defined	O
and	O
is	O
also	O
invertible	O
.	O
µ	O
,	O
λ	O
g.	O
	
Thus	O
we	O
can	O
re	O
-	O
express	O
the	O
maximization	B-Task
problem	I-Task
in	O
(	O
5	O
)	O
in	O
terms	O
of	O
g	O
:	O
	
Proposition	O
5	O
,	O
though	O
,	O
involves	O
inverting	O
the	O
infinite	B-Method
-	I-Method
dimensional	I-Method
operator	I-Method
D	I-Method
µ	I-Method
,	I-Method
λ	I-Method
and	O
thus	O
does	O
n't	O
directly	O
give	O
us	O
a	O
computable	B-Method
estimator	I-Method
.	O
	
Proposition	O
3	O
solves	O
this	O
problem	O
in	O
the	O
case	O
where	O
µ	O
is	O
a	O
discrete	O
measure	O
:	O
	
δ	O
Xm	O
be	O
an	O
empirical	O
measure	O
of	O
M	O
points	O
.	O
	
Let	O
η	O
(	O
X	O
)	O
∈	O
R	O
M	O
have	O
mth	O
entry	O
η	O
(	O
X	O
m	O
)	O
,	O
and	O
∇η	O
(	O
X	O
)	O
∈	O
R	O
M	O
d	O
have	O
(	O
m	O
,	O
i	O
)	O
th	O
entry	O
7	O
	
∂	O
i	O
η	O
(	O
X	O
m	O
)	O
.	O
	
Then	O
under	O
Assumptions	O
(	O
A	O
)	O
to	O
(	O
D	O
)	O
,	O
the	O
Gradient	O
-	O
Constrained	O
MMD	B-Method
is	O
	
where	O
K	O
is	O
the	O
kernel	O
matrix	O
	
,	O
and	O
H	O
that	O
of	O
derivatives	O
of	O
both	O
arguments	O
	
Before	O
proving	O
Proposition	O
3	O
,	O
we	O
note	O
the	O
following	O
interesting	O
alternate	O
form	O
.	O
	
Letē	O
i	O
be	O
the	O
ith	O
standard	O
basis	O
vector	O
for	O
R	O
M	O
+	O
M	O
d	O
,	O
and	O
define	O
T	O
:	O
	
H	O
→	O
R	O
M	O
+	O
M	O
d	O
as	O
the	O
linear	B-Method
operator	I-Method
	
Thus	O
we	O
can	O
write	O
	
7	O
	
We	O
use	O
(	O
m	O
,	O
i	O
)	O
to	O
denote	O
(	O
m	O
−	O
1	O
)	O
d	O
+	O
i	O
;	O
thus	O
∇η	O
(	O
X	O
)	O
stacks	O
∇η	O
(	O
X1	O
)	O
,	O
.	O
.	O
.	O
,	O
∇η	O
(	O
XM	O
)	O
into	O
one	O
vector	O
.	O
	
Proof	O
of	O
Proposition	O
3	O
.	O
	
Let	O
g	O
∈	O
H	O
be	O
the	O
solution	O
to	O
the	O
regression	B-Task
problem	I-Task
D	I-Task
µ	I-Task
,	I-Task
λ	I-Task
g	I-Task
=	O
η	O
:	O
	
Taking	O
the	O
inner	O
product	O
of	O
both	O
sides	O
of	O
(	O
12	O
)	O
with	O
k	O
(	O
X	O
m	O
,	O
·	O
)	O
for	O
each	O
1	O
≤	O
m	O
≤	O
M	O
yields	O
the	O
following	O
M	O
equations	O
:	O
	
Doing	O
the	O
same	O
with	O
∂	O
j	O
k	O
(	O
X	O
m	O
,	O
·	O
)	O
gives	O
M	O
d	O
equations	O
:	O
	
.	O
	
(	O
14	O
)	O
From	O
(	O
12	O
)	O
,	O
it	O
is	O
clear	O
that	O
g	O
is	O
a	O
linear	O
combination	O
of	O
the	O
form	O
:	O
	
where	O
the	O
coefficients	O
α	O
:	O
	
satisfy	O
the	O
system	O
of	O
equations	O
(	O
13	O
)	O
and	O
(	O
14	O
)	O
.	O
	
We	O
can	O
rewrite	O
this	O
system	O
as	O
	
where	O
I	O
M	O
,	O
I	O
M	O
d	O
are	O
the	O
identity	O
matrices	O
of	O
dimension	O
M	O
,	O
	
M	O
d.	O
	
Since	O
K	O
and	O
H	O
must	O
be	O
positive	O
semidefinite	O
,	O
an	O
inverse	O
exists	O
.	O
	
We	O
conclude	O
by	O
noticing	O
that	O
	
The	O
following	O
result	O
was	O
key	O
to	O
our	O
definition	O
of	O
the	O
SMMD	B-Method
in	O
Section	O
3.3	O
.	O
	
Proposition	O
4	O
.	O
	
Under	O
Assumptions	O
(	O
A	O
)	O
to	O
(	O
D	O
)	O
,	O
we	O
have	O
for	O
all	O
f	O
∈	O
H	O
that	O
	
Proof	O
of	O
Proposition	O
4	O
.	O
	
The	O
key	O
idea	O
here	O
is	O
to	O
use	O
the	O
Cauchy	B-Method
-	I-Method
Schwarz	I-Method
inequality	I-Method
for	O
the	O
HilbertSchmidt	O
inner	O
product	O
.	O
	
(	O
a	O
)	O
follows	O
from	O
the	O
reproducing	O
properties	O
(	O
8	O
)	O
and	O
(	O
9	O
)	O
and	O
Property	O
(	O
ii	O
)	O
.	O
	
(	O
b	O
)	O
is	O
obtained	O
using	O
Property	O
(	O
iii	O
)	O
,	O
while	O
(	O
c	O
)	O
follows	O
from	O
the	O
Cauchy	O
-	O
Schwarz	O
inequality	O
and	O
Property	O
(	O
i	O
)	O
.	O
	
Under	O
Assumptions	O
(	O
A	O
)	O
and	O
(	O
B	O
)	O
,	O
k	O
(	O
x	O
,	O
·	O
)	O
is	O
Bochner	O
integrable	O
with	O
respect	O
to	O
any	O
probability	B-Method
distribution	I-Method
P	O
with	O
finite	O
first	O
moment	O
and	O
the	O
following	O
relation	O
holds	O
:	O
	
Proof	O
.	O
	
The	O
operator	B-Method
D	I-Method
x	I-Method
is	O
positive	O
self	O
-	O
adjoint	O
.	O
	
It	O
is	O
also	O
trace	O
-	O
class	O
,	O
as	O
by	O
the	O
triangle	O
inequality	O
	
By	O
Assumption	O
(	O
D	O
)	O
,	O
we	O
have	O
that	O
The	O
Bochner	B-Method
integrability	I-Method
of	I-Method
k	I-Method
(	I-Method
x	I-Method
,	O
·	O
)	O
under	O
a	O
distribution	O
	
P	O
with	O
finite	O
moment	O
follows	O
directly	O
from	O
Assumptions	O
(	O
A	O
)	O
and	O
(	O
B	O
)	O
,	O
since	O
	
section	O
:	O
A.2	O
Continuity	O
of	O
the	O
Optimized	O
Scaled	O
MMD	B-Method
in	O
the	O
Wasserstein	B-Method
topology	I-Method
	
To	O
prove	O
Theorem	O
1	O
,	O
we	O
we	O
will	O
first	O
need	O
some	O
new	O
notation	O
.	O
	
We	O
assume	O
the	O
kernel	O
is	O
k	O
	
=	O
K	O
•	O
φ	O
ψ	O
,	O
i.e.	O
k	O
ψ	O
(	O
x	O
,	O
y	O
)	O
	
=	O
	
K	O
(	O
φ	O
ψ	O
	
(	O
x	O
)	O
,	O
φ	O
ψ	O
(	O
y	O
)	O
)	O
,	O
where	O
the	O
representation	B-Method
function	I-Method
φ	I-Method
ψ	I-Method
is	O
a	O
network	O
φ	O
ψ	O
(	O
X	O
)	O
:	O
	
The	O
intermediate	B-Method
representations	I-Method
h	O
	
The	O
elementwise	B-Method
activation	I-Method
function	I-Method
σ	I-Method
is	O
given	O
by	O
σ	O
	
0	O
(	O
x	O
)	O
=	O
x	O
,	O
and	O
for	O
l	O
	
>	O
0	O
	
the	O
activation	B-Method
σ	I-Method
l	I-Method
is	O
a	O
leaky	O
ReLU	O
with	O
leak	O
coefficient	O
0	O
<	O
α	O
<	O
1	O
:	O
	
The	O
parameter	O
ψ	O
is	O
the	O
concatenation	O
of	O
all	O
the	O
layer	O
parameters	O
:	O
	
We	O
denote	O
by	O
Ψ	O
the	O
set	O
of	O
all	O
such	O
possible	O
parameters	O
,	O
i.	O
	
.	O
	
Define	O
the	O
following	O
restrictions	O
of	O
Ψ	O
:	O
	
Ψ	O
κ	O
is	O
the	O
set	O
of	O
those	O
parameters	O
such	O
that	O
W	O
l	O
have	O
a	O
small	O
condition	O
number	O
,	O
cond	O
(	O
W	O
)	O
=	O
	
σ	O
max	O
(	O
W	O
)	O
	
/	O
σ	O
	
min	O
(	O
W	O
)	O
.	O
	
Ψ	O
κ	O
1	O
is	O
the	O
set	O
of	O
per	O
-	O
layer	O
normalized	O
parameters	O
with	O
a	O
condition	O
number	O
bounded	O
by	O
κ	O
.	O
	
Recall	O
the	O
definition	O
of	O
Scaled	O
MMD	B-Method
,	O
(	O
7	O
)	O
,	O
where	O
λ	O
>	O
0	O
and	O
µ	O
is	O
a	O
probability	O
measure	O
:	O
	
The	O
Optimized	O
SMMD	B-Method
over	O
the	O
restricted	O
set	O
Ψ	O
κ	O
is	O
given	O
by	O
:	O
	
The	O
constraint	O
to	O
ψ	O
∈	O
Ψ	O
κ	O
is	O
critical	O
to	O
the	O
proof	O
.	O
	
In	O
practice	O
,	O
using	O
a	O
spectral	B-Method
parametrization	I-Method
helps	O
enforce	O
this	O
assumption	O
,	O
as	O
shown	O
in	O
Figures	O
2	O
and	O
9	O
.	O
	
Other	O
regularization	B-Method
methods	I-Method
,	O
like	O
orthogonal	B-Method
normalization	I-Method
[	O
reference	O
]	O
,	O
are	O
also	O
possible	O
.	O
	
We	O
will	O
use	O
the	O
following	O
assumptions	O
:	O
	
(	O
I	O
)	O
µ	O
is	O
a	O
probability	O
distribution	O
absolutely	O
continuous	O
with	O
respect	O
to	O
the	O
Lebesgue	O
measure	O
.	O
	
(	O
II	O
)	O
	
The	O
dimensions	O
of	O
the	O
weights	O
are	O
decreasing	O
per	O
layer	O
:	O
	
(	O
III	O
)	O
	
The	O
non	O
-	O
linearity	O
used	O
is	O
Leaky	B-Method
-	I-Method
ReLU	I-Method
,	O
[	O
reference	O
]	O
,	O
with	O
leak	O
coefficient	O
α	O
∈	O
(	O
0	O
,	O
1	O
)	O
.	O
	
(	O
IV	O
)	O
	
The	O
top	B-Method
-	I-Method
level	I-Method
kernel	I-Method
K	I-Method
is	O
globally	O
Lipschitz	O
in	O
the	O
RKHS	B-Method
norm	I-Method
:	O
there	O
exists	O
a	O
positive	O
constant	O
	
(	O
V	O
)	O
	
There	O
is	O
some	O
γ	O
K	O
>	O
0	O
for	O
which	O
K	O
satisfies	O
	
Assumption	O
(	O
I	O
)	O
ensures	O
that	O
the	O
points	O
where	O
φ	O
ψ	O
(	O
X	O
)	O
is	O
not	O
differentiable	O
are	O
reached	O
with	O
probability	O
0	O
under	O
µ.	O
	
This	O
assumption	O
can	O
be	O
easily	O
satisfied	O
e.g.	O
if	O
we	O
define	O
µ	O
by	O
adding	O
Gaussian	O
noise	O
to	O
P.	O
	
Assumption	O
(	O
II	O
)	O
helps	O
ensure	O
that	O
the	O
span	O
of	O
W	O
l	O
is	O
never	O
contained	O
in	O
the	O
null	O
space	O
of	O
W	O
l	O
+	O
1	O
.	O
	
Using	O
Leaky	B-Method
-	I-Method
ReLU	I-Method
as	O
a	O
non	O
-	O
linearity	O
,	O
Assumption	O
(	O
III	O
)	O
,	O
further	O
ensures	O
that	O
the	O
network	B-Method
φ	I-Method
ψ	I-Method
is	O
locally	O
full	O
-	O
rank	O
almost	O
everywhere	O
;	O
this	O
might	O
not	O
be	O
true	O
with	O
ReLU	O
activations	O
,	O
where	O
it	O
could	O
be	O
always	O
0	O
.	O
	
Assumptions	O
(	O
II	O
)	O
and	O
(	O
III	O
)	O
can	O
be	O
easily	O
satisfied	O
by	O
design	O
of	O
the	O
network	O
.	O
	
Assumptions	O
(	O
IV	O
)	O
and	O
(	O
V	O
)	O
only	O
depend	O
on	O
the	O
top	O
-	O
level	O
kernel	O
K	O
and	O
are	O
easy	O
to	O
satisfy	O
in	O
practice	O
.	O
	
In	O
particular	O
,	O
they	O
always	O
hold	O
for	O
a	O
smooth	O
translation	O
-	O
invariant	O
kernel	O
,	O
such	O
as	O
the	O
Gaussian	B-Method
,	O
as	O
well	O
as	O
the	O
linear	B-Method
kernel	I-Method
.	O
	
We	O
are	O
now	O
ready	O
to	O
prove	O
Theorem	O
1	O
.	O
	
Theorem	O
1	O
.	O
	
Under	O
Assumptions	O
(	O
I	O
)	O
to	O
(	O
V	O
)	O
,	O
	
Proof	O
.	O
	
Define	O
the	O
pseudo	O
-	O
distance	O
corresponding	O
to	O
the	O
kernel	B-Method
k	I-Method
ψ	O
	
Denote	O
by	O
W	O
d	O
ψ	O
	
(	O
P	O
,	O
Q	O
)	O
the	O
optimal	O
transport	O
metric	O
between	O
P	O
and	O
Q	O
using	O
the	O
cost	B-Metric
d	I-Metric
ψ	I-Metric
,	O
given	O
by	O
	
where	O
Π	O
is	O
the	O
set	O
of	O
couplings	O
with	O
marginals	O
P	O
and	O
Q.	O
By	O
Lemma	O
7	O
,	O
	
Recall	O
that	O
φ	O
ψ	O
is	O
Lipschitz	O
,	O
φ	O
ψ	O
Lip	O
<	O
∞	O
,	O
so	O
along	O
with	O
Assumption	O
(	O
IV	O
)	O
we	O
have	O
that	O
	
where	O
W	O
is	O
the	O
standard	O
Wasserstein	O
distance	O
(	O
2	O
)	O
,	O
and	O
so	O
	
We	O
have	O
that	O
	
2	O
,	O
and	O
hence	O
	
Using	O
Lemma	O
8	O
,	O
we	O
can	O
write	O
	
where	O
we	O
used	O
φψ	O
Lip	O
≤	O
L	O
	
l=1	O
	
W	O
l	O
=	O
1	O
.	O
	
But	O
by	O
Lemma	O
9	O
,	O
for	O
Lebesgue	O
-	O
almost	O
all	O
X	O
,	O
	
Using	O
Assumption	O
(	O
I	O
)	O
,	O
this	O
implies	O
that	O
	
Thus	O
for	O
any	O
ψ	O
∈	O
Ψ	O
κ	O
,	O
	
The	O
desired	O
bound	O
on	O
D	B-Metric
µ	I-Metric
,	I-Metric
Ψ	I-Metric
κ	O
,	O
λ	O
SMMD	B-Method
follows	O
immediately	O
.	O
	
Lemma	O
7	O
.	O
	
Let	O
(	O
x	O
,	O
y	O
)	O
	
→	O
k	O
(	O
x	O
,	O
y	O
)	O
be	O
the	O
continuous	O
kernel	O
of	O
an	O
RKHS	B-Method
H	I-Method
defined	O
on	O
a	O
Polish	B-Material
space	I-Material
X	O
,	O
and	O
define	O
the	O
corresponding	O
pseudo	O
-	O
distance	O
d	O
k	O
(	O
x	O
,	O
y	O
)	O
:	O
=	O
k	O
(	O
x	O
,	O
·	O
)	O
	
−	O
k	O
(	O
y	O
,	O
·	O
)	O
H	O
.	O
	
Then	O
the	O
following	O
inequality	O
holds	O
for	O
any	O
distributions	O
P	O
and	O
Q	O
on	O
X	O
,	O
including	O
when	O
the	O
quantities	O
are	O
infinite	O
:	O
	
Proof	O
.	O
	
Let	O
P	O
and	O
Q	O
be	O
two	O
probability	O
distributions	O
,	O
and	O
let	O
Π	O
(	O
P	O
,	O
Q	O
)	O
be	O
the	O
set	O
of	O
couplings	O
between	O
them	O
.	O
	
Let	O
π	O
*	O
∈	O
argmin	O
(	O
X	O
,	O
Y	O
)	O
∼π	O
[	O
c	O
k	O
(	O
X	O
,	O
Y	O
)	O
]	O
be	O
an	O
optimal	O
coupling	O
,	O
which	O
is	O
guaranteed	O
to	O
exist	O
	
Take	O
a	O
sample	O
(	O
X	O
,	O
Y	O
)	O
∼	O
π	O
and	O
a	O
function	O
f	O
∈	O
H	O
with	O
f	O
H	O
≤	O
1	O
.	O
	
By	O
the	O
Cauchy	B-Method
-	I-Method
Schwarz	I-Method
inequality	I-Method
,	O
	
Taking	O
the	O
expectation	O
with	O
respect	O
to	O
π	O
,	O
we	O
obtain	O
	
The	O
right	O
-	O
hand	O
side	O
is	O
just	O
the	O
definition	O
of	O
W	O
d	O
k	O
	
(	O
P	O
,	O
Q	O
)	O
.	O
	
By	O
Jensen	O
's	O
inequality	O
,	O
the	O
left	O
-	O
hand	O
side	O
is	O
lower	O
-	O
bounded	O
by	O
	
since	O
π	O
has	O
marginals	O
P	O
and	O
Q.	O
	
We	O
have	O
shown	O
so	O
far	O
that	O
for	O
any	O
f	O
∈	O
H	O
with	O
f	O
H	O
≤	O
1	O
,	O
	
the	O
result	O
follows	O
by	O
taking	O
the	O
supremum	O
over	O
f	O
.	O
	
Proof	O
.	O
	
Note	O
that	O
the	O
condition	O
number	O
is	O
unchanged	O
,	O
cond	O
(	O
W	O
l	O
)	O
=	O
cond	O
(	O
W	O
l	O
)	O
≤	O
κ	O
,	O
and	O
W	O
l	O
=	O
1	O
,	O
soψ	O
∈	O
Φ	O
κ	O
1	O
.	O
	
It	O
is	O
also	O
easy	O
to	O
see	O
from	O
[	O
reference	O
]	O
that	O
	
Lemma	O
9	O
.	O
	
Make	O
Assumptions	O
(	O
II	O
)	O
and	O
(	O
III	O
)	O
,	O
and	O
let	O
ψ	O
∈	O
Ψ	O
κ	O
1	O
.	O
	
Then	O
the	O
set	O
of	O
inputs	O
for	O
which	O
any	O
intermediate	O
activation	O
is	O
exactly	O
zero	O
,	O
	
has	O
zero	O
Lebesgue	O
measure	O
.	O
	
Moreover	O
,	O
for	O
any	O
X	O
/	O
∈	O
N	O
ψ	O
,	O
∇	O
X	O
φ	O
ψ	O
(	O
X	O
)	O
exists	O
and	O
	
Proof	O
.	O
	
First	O
,	O
note	O
that	O
the	O
network	B-Method
representation	I-Method
at	O
layer	O
l	O
is	O
piecewise	O
affine	O
.	O
	
Specifically	O
,	O
define	O
M	O
l	O
X	O
∈	O
R	O
d	O
l	O
by	O
,	O
using	O
Assumption	O
(	O
III	O
)	O
,	O
	
We	O
will	O
now	O
show	O
that	O
the	O
activation	O
patterns	O
are	O
piecewise	O
constant	O
,	O
so	O
that	O
	
Thus	O
,	O
take	O
some	O
X	O
/	O
∈	O
N	O
ψ	O
,	O
and	O
find	O
the	O
smallest	O
absolute	O
value	O
of	O
its	O
activations	O
,	O
=	O
	
;	O
clearly	O
>	O
0	O
.	O
	
For	O
any	O
X	O
with	O
X	O
−	O
X	O
<	O
,	O
we	O
know	O
that	O
for	O
all	O
l	O
	
and	O
k	O
,	O
sign	O
h	O
	
Proof	O
.	O
	
A	O
more	O
general	O
version	O
of	O
this	O
result	O
can	O
be	O
found	O
in	O
[	O
reference	O
][	O
reference	O
]	O
;	O
we	O
provide	O
a	O
proof	O
here	O
for	O
completeness	O
.	O
	
If	O
B	O
has	O
a	O
nontrivial	O
null	O
space	O
,	O
σ	O
min	O
(	O
B	O
)	O
=	O
0	O
and	O
the	O
inequality	O
holds	O
.	O
	
Otherwise	O
,	O
let	O
	
R	O
n	O
*	O
denote	O
R	O
	
n	O
\	O
{	O
0}.	O
Recall	O
that	O
for	O
C	O
∈	O
R	O
m×n	O
with	O
m	O
≥	O
n	O
,	O
	
Here	O
A	O
1	O
,	O
A	O
2	O
,	O
A	O
3	O
and	O
A	O
4	O
are	O
defined	O
by	O
[	O
reference	O
]	O
and	O
are	O
represented	O
in	O
Figure	O
4	O
	
:	O
Figure	O
4	O
:	O
Decomposition	O
of	O
R	O
2	O
into	O
4	O
regions	O
A	O
1	O
,	O
A	O
2	O
,	O
A	O
3	O
and	O
A	O
4	O
as	O
defined	O
in	O
	
[	O
reference	O
]	O
.	O
As	O
α	O
approaches	O
0	O
,	O
the	O
area	O
of	O
sets	O
A	O
3	O
and	O
A	O
4	O
becomes	O
negligible	O
.	O
	
It	O
is	O
easy	O
to	O
see	O
that	O
whenever	O
µ	O
has	O
a	O
density	O
,	O
the	O
probability	O
of	O
the	O
sets	O
A	O
3	O
and	O
A	O
4	O
goes	O
to	O
0	O
are	O
α	O
→	O
0	O
.	O
	
Hence	O
one	O
can	O
deduce	O
that	O
	
On	O
the	O
other	O
hand	O
,	O
the	O
squared	O
Lipschitz	O
constant	O
of	O
φ	O
is	O
given	O
by	O
(	O
1	O
−	O
γ	O
)	O
2	O
+	O
(	O
1	O
+	O
α	O
−	O
γ	O
)	O
2	O
which	O
converges	O
to	O
2	O
(	O
1	O
−	O
γ	O
)	O
2	O
.	O
	
This	O
shows	O
that	O
controlling	O
the	O
expectation	O
of	O
the	O
gradient	O
does	O
n't	O
allow	O
to	O
effectively	O
control	O
the	O
Lipschitz	O
constant	O
of	O
φ	O
.	O
	
section	O
:	O
Monotonicity	O
of	O
the	O
dimensions	O
:	O
	
We	O
would	O
like	O
to	O
consider	O
a	O
second	O
example	O
where	O
Assumption	O
(	O
II	O
)	O
does	O
n't	O
hold	O
.	O
	
Consider	O
the	O
following	O
two	B-Method
layer	I-Method
network	I-Method
defined	O
by	O
:	O
	
for	O
β	O
>	O
0	O
.	O
	
Note	O
that	O
W	B-Method
β	I-Method
is	O
a	O
full	O
rank	O
matrix	O
,	O
but	O
Assumption	O
(	O
II	O
)	O
does	O
n't	O
hold	O
.	O
	
Depending	O
on	O
the	O
sign	O
of	O
the	O
components	O
of	O
W	O
β	O
X	O
one	O
has	O
the	O
following	O
expression	O
for	O
∇φ	O
α	O
(	O
X	O
)	O
2	O
:	O
	
where	O
(	O
B	O
i	O
)	O
1≤i≤6	O
are	O
defined	O
by	O
(	O
26	O
)	O
	
section	O
:	O
20	O
	
The	O
squared	B-Metric
Lipschitz	I-Metric
constant	I-Metric
is	O
given	O
by	O
φ	O
2	O
L	O
(	O
1	O
−	O
γ	O
)	O
2	O
+	O
β	O
2	O
while	O
the	O
expected	B-Metric
squared	I-Metric
norm	I-Metric
of	I-Metric
the	I-Metric
gradient	I-Metric
of	I-Metric
φ	I-Metric
is	O
given	O
by	O
:	O
	
Again	O
the	O
set	O
B	O
4	O
∪	O
B	O
5	O
becomes	O
negligible	O
as	O
β	O
approaches	O
0	O
which	O
implies	O
that	O
	
2	O
.	O
	
Note	O
that	O
unlike	O
in	O
the	O
first	O
example	O
in	O
(	O
21	O
)	O
,	O
the	O
matrix	B-Method
W	I-Method
β	I-Method
has	O
a	O
bounded	O
condition	O
number	O
.	O
	
In	O
this	O
example	O
,	O
the	O
columns	O
of	O
W	O
0	O
are	O
all	O
in	O
the	O
null	O
space	O
of	O
[	O
−1	O
0	O
1	O
]	O
,	O
which	O
implies	O
∇φ	O
0	O
	
(	O
X	O
)	O
	
=	O
0	O
for	O
all	O
X	O
∈	O
R	O
2	O
,	O
even	O
though	O
all	O
matrices	O
have	O
full	O
rank	O
.	O
	
B	O
DiracGAN	O
vector	O
fields	O
for	O
more	O
losses	O
Figure	O
5	O
:	O
	
Vector	O
fields	O
for	O
different	O
losses	O
with	O
respect	O
to	O
the	O
generator	O
parameter	O
θ	O
and	O
the	O
feature	O
representation	O
parameter	O
ψ	O
;	O
the	O
losses	O
use	O
a	O
Gaussian	B-Method
kernel	I-Method
,	O
and	O
are	O
shown	O
in	O
[	O
reference	O
]	O
.	O
Following	O
[	O
reference	O
]	O
,	O
P	O
=	O
δ	O
0	O
,	O
	
Q	O
=	O
δ	O
θ	O
and	O
φ	O
ψ	O
	
(	O
x	O
)	O
=	O
ψx	O
.	O
	
The	O
curves	O
show	O
the	O
result	O
of	O
taking	O
simultaneous	O
gradient	O
steps	O
in	O
(	O
θ	O
,	O
ψ	O
)	O
beginning	O
from	O
three	O
initial	O
parameter	O
values	O
.	O
	
Figure	O
5	O
shows	O
parameter	O
vector	O
fields	O
,	O
like	O
those	O
in	O
Figure	O
6	O
,	O
for	O
Example	O
1	O
for	O
a	O
variety	O
of	O
different	O
losses	O
:	O
	
section	O
:	O
21	O
	
The	O
squared	O
MMD	B-Method
between	O
δ	O
0	O
and	O
δ	O
θ	O
under	O
a	O
Gaussian	B-Method
kernel	I-Method
of	I-Method
bandwidth	I-Method
1	I-Method
/	I-Method
ψ	I-Method
and	O
is	O
given	O
by	O
	
)	O
.	O
	
MMD	B-Method
-	O
GP	O
-	O
unif	O
uses	O
a	O
gradient	B-Method
penalty	I-Method
as	O
in	O
[	O
reference	O
]	O
where	O
each	O
samples	O
from	O
µ	O
	
*	O
is	O
obtained	O
by	O
first	O
sampling	O
X	O
and	O
Y	O
from	O
P	O
and	O
Q	O
and	O
then	O
sampling	O
uniformly	O
between	O
X	O
and	O
Y	O
.	O
	
MMD	B-Method
-	O
GP	O
uses	O
the	O
same	O
gradient	O
penalty	O
,	O
but	O
the	O
expectation	O
is	O
taken	O
under	O
P	O
rather	O
than	O
µ	O
	
*	O
.	O
	
SN	B-Method
-	I-Method
MMD	I-Method
refers	O
to	O
MMD	B-Method
with	O
spectral	B-Method
normalization	I-Method
;	O
here	O
this	O
means	O
that	O
ψ	O
=	O
1	O
.	O
	
Sobolev	O
-	O
MMD	B-Method
refers	O
to	O
the	O
loss	O
used	O
in	O
[	O
reference	O
]	O
with	O
the	O
quadratic	O
penalty	O
only	O
.	O
	
GCMMD	B-Metric
µ	I-Metric
,	I-Metric
k	I-Metric
,	O
λ	O
is	O
defined	O
by	O
(	O
5	O
)	O
,	O
with	O
µ	O
=	O
N	O
(	O
0	O
,	O
10	O
	
2	O
)	O
.	O
	
C	O
Vector	O
fields	O
of	O
Gradient	O
-	O
Constrained	O
MMD	B-Method
and	O
Sobolev	O
GAN	B-Method
critics	O
	
Mroueh	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
argue	O
that	O
the	O
gradient	O
of	O
the	O
critic	O
(	O
...	O
)	O
defines	O
a	O
transportation	B-Method
plan	I-Method
for	O
moving	O
the	O
distribution	O
mass	O
(	O
from	O
generated	O
to	O
reference	O
distribution	O
)	O
and	O
present	O
the	O
solution	O
of	O
Sobolev	B-Method
PDE	I-Method
for	O
2	B-Method
-	I-Method
dimensional	I-Method
Gaussians	I-Method
.	O
	
We	O
observed	O
that	O
in	O
this	O
simple	O
example	O
the	O
gradient	O
of	O
the	O
Sobolev	O
critic	O
can	O
be	O
very	O
high	O
outside	O
of	O
the	O
areas	O
of	O
high	O
density	O
,	O
which	O
is	O
not	O
the	O
case	O
with	O
the	O
Gradient	O
-	O
Constrained	O
MMD	B-Method
.	O
	
Figure	O
6	O
presents	O
critic	O
gradients	O
in	O
both	O
cases	O
,	O
using	O
µ	O
	
=	O
(	O
P	O
+	O
Q	O
)/	O
2	O
for	O
both	O
.	O
	
(	O
a	O
)	O
Gradient	O
-	O
Constrained	O
MMD	B-Method
critic	O
gradient	O
.	O
	
This	O
unintuitive	O
behavior	O
is	O
most	O
likely	O
related	O
to	O
the	O
vanishing	O
boundary	O
condition	O
,	O
assummed	O
by	O
Sobolev	O
GAN	B-Method
.	O
	
Solving	O
the	O
actual	O
Sobolev	B-Method
PDE	I-Method
,	O
we	O
found	O
that	O
the	O
Sobolev	B-Method
critic	I-Method
has	O
very	O
high	O
gradients	O
close	O
to	O
the	O
boundary	O
in	O
order	O
to	O
match	O
the	O
condition	O
;	O
moreover	O
,	O
these	O
gradients	O
point	O
in	O
opposite	O
directions	O
to	O
the	O
target	O
distribution	O
.	O
	
and	O
the	O
corresponding	O
critic	O
function	O
is	O
	
Thus	O
if	O
we	O
assume	O
E	O
X∼P	O
φ	O
(	O
X	O
)	O
	
>	O
	
E	O
Y	O
	
∼Q	O
φ	O
(	O
Y	O
)	O
,	O
as	O
that	O
is	O
the	O
goal	O
of	O
our	O
critic	B-Task
training	I-Task
,	O
we	O
see	O
that	O
the	O
MMD	B-Method
becomes	O
identical	O
to	O
the	O
WGAN	O
loss	O
,	O
and	O
the	O
gradient	B-Method
penalty	I-Method
is	O
applied	O
to	O
the	O
same	O
function	O
.	O
	
(	O
MMD	B-Method
GANs	O
,	O
however	O
,	O
would	O
typically	O
train	O
on	O
the	O
unbiased	O
estimator	O
of	O
MMD	B-Method
2	O
,	O
giving	O
a	O
very	O
slightly	O
different	O
loss	B-Metric
function	I-Metric
.	O
	
[	O
reference	O
]	O
also	O
applied	O
the	O
gradient	O
penalty	O
to	O
η	O
rather	O
than	O
the	O
true	O
critic	O
η	O
/	O
η	O
.	O
)	O
	
The	O
SMMD	B-Method
with	O
a	O
linear	B-Method
kernel	I-Method
is	O
thus	O
analogous	O
to	O
applying	O
the	O
scaling	B-Method
operator	I-Method
to	O
a	O
WGAN	B-Method
;	O
hence	O
the	O
name	O
SWGAN	B-Method
.	O
	
F	O
Additional	O
experiments	O
F.1	O
Comparison	O
of	O
Gradient	O
-	O
Constrained	O
MMD	B-Method
to	O
Scaled	O
MMD	B-Method
Figure	O
7	O
shows	O
the	O
behavior	O
of	O
the	O
MMD	B-Method
,	O
the	O
Gradient	O
-	O
Constrained	O
SMMD	B-Method
,	O
and	O
the	O
Scaled	O
MMD	B-Method
when	O
comparing	O
Gaussian	B-Method
distributions	I-Method
.	O
	
We	O
can	O
see	O
that	O
MMD	B-Method
∝	I-Method
SMMD	I-Method
and	O
the	O
GradientConstrained	O
MMD	B-Method
behave	O
similarly	O
in	O
this	O
case	O
,	O
and	O
that	O
optimizing	O
the	O
SMMD	B-Method
and	O
the	O
GradientConstrained	O
MMD	B-Method
is	O
also	O
similar	O
.	O
	
Optimizing	O
the	O
MMD	B-Method
would	O
yield	O
an	O
essentially	O
constant	O
distance	O
.	O
	
section	O
:	O
F.2	O
IGMs	B-Method
with	O
Optimized	O
Gradient	O
-	O
Constrained	O
MMD	B-Method
loss	O
	
We	O
implemented	O
the	O
estimator	O
of	O
Proposition	O
3	O
using	O
the	O
empirical	B-Method
mean	I-Method
estimator	I-Method
of	I-Method
η	I-Method
,	O
and	O
sharing	O
samples	O
for	O
µ	O
=	O
P.	O
To	O
handle	O
the	O
large	B-Task
but	I-Task
approximately	I-Task
low	I-Task
-	I-Task
rank	I-Task
matrix	I-Task
system	I-Task
,	O
we	O
used	O
an	O
incomplete	B-Method
Cholesky	I-Method
decomposition	I-Method
[	O
reference	O
][	O
reference	O
]	O
	
Then	O
the	O
Woodbury	B-Method
matrix	I-Method
identity	I-Method
allows	O
an	O
efficient	O
evaluation	O
:	O
	
Even	O
though	O
only	O
a	O
small	O
is	O
required	O
for	O
a	O
good	O
approximation	O
,	O
and	O
the	O
full	O
matrices	O
K	O
,	O
G	O
,	O
and	O
H	O
need	O
never	O
be	O
constructed	O
,	O
backpropagation	B-Method
through	O
this	O
procedure	O
is	O
slow	O
and	O
not	O
especially	O
GPU	O
-	O
friendly	O
;	O
training	O
on	O
CPU	B-Method
was	O
faster	O
.	O
	
Thus	O
we	O
were	O
only	O
able	O
to	O
run	O
the	O
estimator	O
on	O
MNIST	B-Material
,	O
and	O
even	O
that	O
took	O
days	O
to	O
conduct	O
the	O
optimization	B-Task
on	O
powerful	O
workstations	O
.	O
	
The	O
learned	O
models	O
,	O
however	O
,	O
were	O
reasonable	O
.	O
	
Using	O
a	O
DCGAN	B-Method
architecture	I-Method
,	O
batches	O
of	O
size	O
64	O
,	O
and	O
a	O
procedure	O
that	O
otherwise	O
agreed	O
with	O
the	O
setup	O
of	O
Section	O
4	O
,	O
samples	O
with	O
and	O
without	O
spectral	B-Method
normalization	I-Method
are	O
shown	O
in	O
Figures	O
8a	O
and	O
8b	O
.	O
	
After	O
the	O
points	O
in	O
training	O
shown	O
,	O
however	O
,	O
the	O
same	O
rank	O
collapse	O
as	O
discussed	O
in	O
Section	O
4	O
occurred	O
.	O
	
Here	O
it	O
seems	O
that	O
spectral	B-Method
normalization	I-Method
may	O
have	O
delayed	O
the	O
collapse	O
,	O
but	O
not	O
prevented	O
it	O
.	O
	
Figure	O
8c	O
shows	O
generator	B-Metric
loss	I-Metric
estimates	I-Metric
through	O
training	B-Task
,	O
including	O
the	O
obvious	O
peak	O
at	O
collapse	O
;	O
Figure	O
8d	O
shows	O
KID	B-Metric
scores	I-Metric
based	O
on	O
the	O
MNIST	B-Material
-	O
trained	O
convnet	O
representation	O
[	O
reference	O
]	O
,	O
including	O
comparable	O
SMMD	B-Method
models	O
for	O
context	O
.	O
	
The	O
fact	O
that	O
SMMD	B-Method
models	O
converged	O
somewhat	O
faster	O
than	O
Gradient	O
-	O
Constrained	O
MMD	B-Method
models	O
here	O
may	O
be	O
more	O
related	O
to	O
properties	O
of	O
the	O
estimator	O
of	O
Proposition	O
3	O
rather	O
than	O
the	O
distances	O
;	O
more	O
work	O
would	O
be	O
needed	O
to	O
fully	O
compare	O
the	O
behavior	O
of	O
the	O
two	O
distances	O
.	O
	
Figure	O
9	O
shows	O
the	O
distribution	O
of	O
critic	O
weight	O
singular	O
values	O
,	O
like	O
Figure	O
2	O
,	O
at	O
more	O
layers	O
.	O
	
Figure	O
11	O
and	O
Table	O
2	O
show	O
results	O
for	O
the	O
spectral	B-Method
normalization	I-Method
variants	I-Method
considered	O
in	O
the	O
experiments	O
.	O
	
MMDGAN	B-Method
,	O
with	O
neither	O
spectral	B-Method
normalization	I-Method
nor	O
a	O
gradient	B-Method
penalty	I-Method
,	O
did	O
surprisingly	O
well	O
in	O
this	O
case	O
,	O
though	O
it	O
fails	O
badly	O
in	O
other	O
situations	O
.	O
	
Figure	O
9	O
compares	O
the	O
decay	O
of	O
singular	O
values	O
for	O
layer	O
of	O
the	O
critic	B-Method
's	I-Method
network	I-Method
at	O
both	O
early	O
and	O
later	O
stages	O
of	O
training	B-Task
in	O
two	O
cases	O
:	O
with	O
or	O
without	O
the	O
spectral	B-Method
parametrization	I-Method
.	O
	
The	O
model	O
was	O
trained	O
on	O
CelebA	B-Material
using	O
SMMD	B-Method
.	O
	
Figure	O
11	O
shows	O
the	O
evolution	O
per	O
iteration	O
of	O
Inception	B-Metric
score	I-Metric
,	O
	
section	O
:	O
F.3	O
Spectral	B-Method
normalization	I-Method
and	O
Scaled	O
MMD	B-Method
	
section	O
:	O
	
section	O
:	O
	
it	O
is	O
undefined	O
when	O
any	O
h	O
	
Because	O
ψ	O
∈	O
Ψ	O
κ	O
1	O
,	O
we	O
have	O
	
≤	O
1	O
,	O
and	O
using	O
Assumption	O
(	O
II	O
)	O
with	O
Lemma	O
10	O
gives	O
	
X	O
)	O
denote	O
the	O
full	O
activation	O
patterns	O
up	O
	
to	O
level	O
l	O
,	O
we	O
can	O
thus	O
write	O
	
There	O
are	O
only	O
finitely	O
many	O
possible	O
values	O
for	O
H	O
l	O
X	O
;	O
we	O
denote	O
the	O
set	O
of	O
such	O
values	O
as	O
H	O
l	O
.	O
	
Then	O
we	O
have	O
that	O
	
Because	O
each	O
W	O
H	O
l	O
k	O
is	O
of	O
rank	O
	
d	O
l	O
	
,	O
each	O
set	O
in	O
the	O
union	O
is	O
either	O
empty	O
or	O
an	O
affine	O
subspace	O
of	O
dimension	O
d	O
−	O
d	O
l	O
.	O
	
As	O
each	O
d	O
l	O
	
>	O
0	O
	
,	O
each	O
set	O
in	O
the	O
finite	O
union	O
has	O
zero	O
Lebesgue	O
measure	O
,	O
and	O
N	O
ψ	O
also	O
has	O
zero	O
Lebesgue	O
measure	O
.	O
	
Thus	O
,	O
as	O
Bx	O
=	O
0	O
for	O
x	O
=	O
0	O
,	O
	
section	O
:	O
A.2.1	O
When	O
some	O
of	O
the	O
assumptions	O
do	O
n't	O
hold	O
	
Here	O
we	O
analyze	O
through	O
simple	O
examples	O
what	O
happens	O
when	O
the	O
condition	O
number	O
can	O
be	O
unbounded	O
,	O
and	O
when	O
Assumption	O
(	O
II	O
)	O
,	O
about	O
decreasing	O
widths	O
of	O
the	O
network	O
,	O
is	O
violated	O
.	O
	
Condition	O
Number	O
:	O
	
We	O
start	O
by	O
a	O
first	O
example	O
where	O
the	O
condition	O
number	O
can	O
be	O
arbitrarily	O
high	O
.	O
	
We	O
consider	O
a	O
two	B-Method
-	I-Method
layer	I-Method
network	I-Method
on	O
R	O
2	O
,	O
defined	O
by	O
	
where	O
α	O
>	O
0	O
.	O
	
As	O
α	O
approaches	O
0	O
the	O
matrix	O
W	O
α	O
becomes	O
singular	O
which	O
means	O
that	O
its	O
condition	O
number	O
blows	O
up	O
.	O
	
We	O
are	O
interested	O
in	O
analyzing	O
the	O
behavior	O
of	O
the	O
Lipschitz	B-Metric
constant	I-Metric
of	I-Metric
φ	I-Metric
and	O
the	O
expected	B-Metric
squared	I-Metric
norm	I-Metric
of	O
its	O
gradient	O
under	O
µ	O
as	O
α	O
approaches	O
0	O
.	O
	
One	O
can	O
easily	O
compute	O
the	O
squared	O
norm	O
of	O
the	O
gradient	O
of	O
φ	O
which	O
is	O
given	O
by	O
	
section	O
:	O
D	O
An	O
estimator	B-Method
for	O
Lipschitz	O
MMD	B-Method
	
We	O
now	O
describe	O
briefly	O
how	O
to	O
estimate	O
the	O
Lipschitz	O
MMD	B-Method
in	O
low	O
dimensions	O
.	O
	
Recall	O
that	O
	
For	O
f	O
∈	O
H	O
k	O
,	O
it	O
is	O
the	O
case	O
that	O
	
Thus	O
we	O
can	O
approximate	O
the	O
constraint	O
f	O
2	O
Lip	O
+	O
λ	O
f	O
2	O
H	O
k	O
≤	O
1	O
by	O
enforcing	O
the	O
constraint	O
on	O
a	O
set	O
of	O
m	O
points	O
{	O
Z	O
i	O
}	O
reasonably	O
densely	O
covering	O
the	O
region	O
around	O
the	O
supports	O
of	O
P	O
and	O
Q	O
,	O
rather	O
22	O
than	O
enforcing	O
it	O
at	O
every	O
point	O
in	O
X	O
.	O
	
An	O
estimator	O
of	O
the	O
Lipschitz	O
MMD	B-Method
based	O
on	O
X	O
∼	O
P	O
n	O
X	O
and	O
	
By	O
the	O
generalized	B-Method
representer	I-Method
theorem	I-Method
,	O
the	O
optimal	O
f	O
for	O
(	O
29	O
)	O
will	O
be	O
of	O
the	O
form	O
	
Writing	O
δ	O
=	O
(	O
α	O
,	O
β	O
,	O
γ	O
)	O
,	O
the	O
objective	O
function	O
is	O
linear	O
in	O
δ	O
,	O
	
The	O
constraints	O
are	O
quadratic	O
,	O
built	O
from	O
the	O
following	O
matrices	O
,	O
where	O
the	O
X	O
and	O
Y	O
samples	O
are	O
concatenated	O
together	O
,	O
as	O
are	O
the	O
derivatives	O
with	O
each	O
dimension	O
of	O
the	O
Z	O
samples	O
:	O
	
Given	O
these	O
matrices	O
,	O
and	O
letting	O
	
where	O
e	O
(	O
i	O
,	O
j	O
)	O
is	O
the	O
(	O
i	O
,	O
j	O
)	O
th	O
standard	O
basis	O
vector	O
in	O
R	O
md	O
,	O
we	O
have	O
that	O
	
Thus	O
the	O
optimization	B-Task
problem	I-Task
(	O
29	O
)	O
is	O
a	O
linear	B-Task
problem	I-Task
with	O
convex	O
quadratic	O
constraints	O
,	O
which	O
can	O
be	O
solved	O
by	O
standard	O
convex	B-Method
optimization	I-Method
software	I-Method
.	O
	
The	O
approximation	O
is	O
reasonable	O
only	O
if	O
we	O
can	O
effectively	O
cover	O
the	O
region	O
of	O
interest	O
with	O
densely	O
spaced	O
{	O
Z	O
i	O
}	O
;	O
it	O
requires	O
a	O
nontrivial	O
amount	O
of	O
computation	O
even	O
for	O
the	O
very	O
simple	O
1	B-Task
-	I-Task
dimensional	I-Task
toy	I-Task
problem	I-Task
of	O
Example	O
1	O
.	O
	
One	O
advantage	O
of	O
this	O
estimator	O
,	O
though	O
,	O
is	O
that	O
finding	O
its	O
derivative	O
with	O
respect	O
to	O
the	O
input	O
points	O
or	O
the	O
kernel	B-Method
parameterization	I-Method
is	O
almost	O
free	O
once	O
we	O
have	O
computed	O
the	O
estimate	O
,	O
as	O
long	O
as	O
our	O
solver	O
has	O
computed	O
the	O
dual	O
variables	O
µ	O
corresponding	O
to	O
the	O
constraints	O
in	O
[	O
reference	O
]	O
.	O
	
We	O
just	O
need	O
to	O
exploit	O
the	O
envelope	B-Method
theorem	I-Method
and	O
then	O
differentiate	O
the	O
KKT	O
conditions	O
,	O
as	O
done	O
for	O
instance	O
in	O
[	O
reference	O
]	O
.	O
	
The	O
differential	O
of	O
(	O
29	O
)	O
ends	O
up	O
being	O
,	O
assuming	O
the	O
optimum	O
of	O
(	O
29	O
)	O
is	O
atδ	O
∈	O
R	O
n	O
X	O
+	O
n	O
Y	O
+	O
md	O
and	O
µ	O
∈	O
R	O
m	O
,	O
d	O
	
LipMMD	O
k	O
,	O
λ	O
(	O
X	O
,	O
Y	O
,	O
Z	O
)	O
	
=	O
	
δ	O
T	O
dK	O
	
dB	O
	
section	O
:	O
	
document	O
:	O
Supervised	B-Task
Learning	I-Task
of	I-Task
Universal	I-Task
Sentence	I-Task
Representations	I-Task
from	O
Natural	B-Material
Language	I-Material
Inference	I-Material
Data	I-Material
	
Many	O
modern	O
NLP	B-Method
systems	I-Method
rely	O
on	O
word	B-Method
embeddings	I-Method
,	O
previously	O
trained	O
in	O
an	O
unsupervised	B-Method
manner	I-Method
on	O
large	O
corpora	O
,	O
as	O
base	O
features	O
.	O
	
Efforts	O
to	O
obtain	O
embeddings	O
for	O
larger	O
chunks	O
of	O
text	O
,	O
such	O
as	O
sentences	O
,	O
have	O
however	O
not	O
been	O
so	O
successful	O
.	O
	
Several	O
attempts	O
at	O
learning	O
unsupervised	B-Method
representations	I-Method
of	I-Method
sentences	I-Method
have	O
not	O
reached	O
satisfactory	O
enough	O
performance	O
to	O
be	O
widely	O
adopted	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
show	O
how	O
universal	B-Method
sentence	I-Method
representations	I-Method
trained	O
using	O
the	O
supervised	O
data	O
of	O
the	O
Stanford	B-Material
Natural	I-Material
Language	I-Material
Inference	I-Material
datasets	I-Material
can	O
consistently	O
outperform	O
unsupervised	B-Method
methods	I-Method
like	O
SkipThought	B-Method
vectors	I-Method
on	O
a	O
wide	O
range	O
of	O
transfer	B-Task
tasks	I-Task
.	O
	
Much	O
like	O
how	O
computer	B-Task
vision	I-Task
uses	O
ImageNet	B-Material
to	O
obtain	O
features	O
,	O
which	O
can	O
then	O
be	O
transferred	O
to	O
other	O
tasks	O
,	O
our	O
work	O
tends	O
to	O
indicate	O
the	O
suitability	O
of	O
natural	B-Task
language	I-Task
inference	I-Task
for	O
transfer	B-Task
learning	I-Task
to	O
other	O
NLP	B-Task
tasks	I-Task
.	O
	
Our	O
encoder	O
is	O
publicly	O
available	O
.	O
	
section	O
:	O
Introduction	O
	
Distributed	B-Method
representations	I-Method
of	I-Method
words	I-Method
(	O
or	O
word	B-Method
embeddings	I-Method
)	O
have	O
shown	O
to	O
provide	O
useful	O
features	O
for	O
various	O
tasks	O
in	O
natural	B-Task
language	I-Task
processing	I-Task
and	O
computer	B-Task
vision	I-Task
.	O
	
While	O
there	O
seems	O
to	O
be	O
a	O
consensus	O
concerning	O
the	O
usefulness	O
of	O
word	O
embeddings	O
and	O
how	O
to	O
learn	O
them	O
,	O
this	O
is	O
not	O
yet	O
clear	O
with	O
regard	O
to	O
representations	O
that	O
carry	O
the	O
meaning	O
of	O
a	O
full	O
sentence	O
.	O
	
That	O
is	O
,	O
how	O
to	O
capture	O
the	O
relationships	O
among	O
multiple	O
words	O
and	O
phrases	O
in	O
a	O
single	O
vector	O
remains	O
an	O
question	O
to	O
be	O
solved	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
study	O
the	O
task	O
of	O
learning	O
universal	B-Task
representations	I-Task
of	I-Task
sentences	I-Task
,	O
i.e.	O
,	O
a	O
sentence	B-Method
encoder	I-Method
model	I-Method
that	O
is	O
trained	O
on	O
a	O
large	O
corpus	O
and	O
subsequently	O
transferred	O
to	O
other	O
tasks	O
.	O
	
Two	O
questions	O
need	O
to	O
be	O
solved	O
in	O
order	O
to	O
build	O
such	O
an	O
encoder	B-Method
,	O
namely	O
:	O
what	O
is	O
the	O
preferable	O
neural	B-Method
network	I-Method
architecture	I-Method
;	O
and	O
how	O
and	O
on	O
what	O
task	O
should	O
such	O
a	O
network	O
be	O
trained	O
.	O
	
Following	O
existing	O
work	O
on	O
learning	B-Task
word	I-Task
embeddings	I-Task
,	O
most	O
current	O
approaches	O
consider	O
learning	O
sentence	B-Method
encoders	I-Method
in	O
an	O
unsupervised	B-Method
manner	I-Method
like	O
SkipThought	B-Method
or	O
FastSent	B-Method
.	O
	
Here	O
,	O
we	O
investigate	O
whether	O
supervised	B-Method
learning	I-Method
can	O
be	O
leveraged	O
instead	O
,	O
taking	O
inspiration	O
from	O
previous	O
results	O
in	O
computer	B-Task
vision	I-Task
,	O
where	O
many	O
models	O
are	O
pretrained	O
on	O
the	O
ImageNet	B-Material
before	O
being	O
transferred	O
.	O
	
We	O
compare	O
sentence	B-Method
embeddings	I-Method
trained	O
on	O
various	O
supervised	B-Task
tasks	I-Task
,	O
and	O
show	O
that	O
sentence	B-Method
embeddings	I-Method
generated	O
from	O
models	O
trained	O
on	O
a	O
natural	B-Task
language	I-Task
inference	I-Task
(	O
NLI	B-Task
)	O
task	O
reach	O
the	O
best	O
results	O
in	O
terms	O
of	O
transfer	B-Metric
accuracy	I-Metric
.	O
	
We	O
hypothesize	O
that	O
the	O
suitability	O
of	O
NLI	B-Task
as	O
a	O
training	B-Task
task	I-Task
is	O
caused	O
by	O
the	O
fact	O
that	O
it	O
is	O
a	O
high	B-Task
-	I-Task
level	I-Task
understanding	I-Task
task	I-Task
that	O
involves	O
reasoning	O
about	O
the	O
semantic	O
relationships	O
within	O
sentences	O
.	O
	
Unlike	O
in	O
computer	B-Task
vision	I-Task
,	O
where	O
convolutional	B-Method
neural	I-Method
networks	I-Method
are	O
predominant	O
,	O
there	O
are	O
multiple	O
ways	O
to	O
encode	O
a	O
sentence	O
using	O
neural	B-Method
networks	I-Method
.	O
	
Hence	O
,	O
we	O
investigate	O
the	O
impact	O
of	O
the	O
sentence	B-Method
encoding	I-Method
architecture	I-Method
on	O
representational	B-Task
transferability	I-Task
,	O
and	O
compare	O
convolutional	B-Method
,	I-Method
recurrent	I-Method
and	O
even	O
simpler	O
word	B-Method
composition	I-Method
schemes	I-Method
.	O
	
Our	O
experiments	O
show	O
that	O
an	O
encoder	B-Method
based	O
on	O
a	O
bi	O
-	O
directional	O
LSTM	B-Method
architecture	O
with	O
max	B-Method
pooling	I-Method
,	O
trained	O
on	O
the	O
Stanford	B-Material
Natural	I-Material
Language	I-Material
Inference	I-Material
(	O
SNLI	B-Material
)	O
dataset	O
,	O
yields	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
sentence	B-Metric
embeddings	I-Metric
compared	O
to	O
all	O
existing	O
alternative	O
unsupervised	B-Method
approaches	I-Method
like	O
SkipThought	B-Method
or	O
FastSent	B-Method
,	O
while	O
being	O
much	O
faster	O
to	O
train	O
.	O
	
We	O
establish	O
this	O
finding	O
on	O
a	O
broad	O
and	O
diverse	O
set	O
of	O
transfer	B-Task
tasks	I-Task
that	O
measures	O
the	O
ability	O
of	O
sentence	B-Method
representations	I-Method
to	O
capture	O
general	O
and	O
useful	O
information	O
.	O
	
section	O
:	O
Related	O
work	O
	
Transfer	B-Method
learning	I-Method
using	O
supervised	O
features	O
has	O
been	O
successful	O
in	O
several	O
computer	B-Task
vision	I-Task
applications	I-Task
.	O
	
Striking	O
examples	O
include	O
face	B-Task
recognition	I-Task
and	O
visual	B-Task
question	I-Task
answering	I-Task
,	O
where	O
image	O
features	O
trained	O
on	O
ImageNet	B-Method
and	O
word	B-Method
embeddings	I-Method
trained	O
on	O
large	O
unsupervised	O
corpora	O
are	O
combined	O
.	O
	
In	O
contrast	O
,	O
most	O
approaches	O
for	O
sentence	B-Task
representation	I-Task
learning	I-Task
are	O
unsupervised	B-Task
,	O
arguably	O
because	O
the	O
NLP	B-Task
community	I-Task
has	O
not	O
yet	O
found	O
the	O
best	O
supervised	B-Task
task	I-Task
for	O
embedding	O
the	O
semantics	O
of	O
a	O
whole	O
sentence	O
.	O
	
Another	O
reason	O
is	O
that	O
neural	B-Method
networks	I-Method
are	O
very	O
good	O
at	O
capturing	O
the	O
biases	O
of	O
the	O
task	O
on	O
which	O
they	O
are	O
trained	O
,	O
but	O
can	O
easily	O
forget	O
the	O
overall	O
information	O
or	O
semantics	O
of	O
the	O
input	O
data	O
by	O
specializing	O
too	O
much	O
on	O
these	O
biases	O
.	O
	
Learning	B-Method
models	I-Method
on	O
large	O
unsupervised	B-Task
task	I-Task
makes	O
it	O
harder	O
for	O
the	O
model	O
to	O
specialize	O
.	O
	
littwin2016multiverse	O
showed	O
that	O
co	B-Method
-	I-Method
adaptation	I-Method
of	I-Method
encoders	I-Method
and	I-Method
classifiers	I-Method
,	O
when	O
trained	O
end	O
-	O
to	O
-	O
end	O
,	O
can	O
negatively	O
impact	O
the	O
generalization	B-Metric
power	I-Metric
of	O
image	O
features	O
generated	O
by	O
an	O
encoder	B-Method
.	O
	
They	O
propose	O
a	O
loss	B-Method
that	O
incorporates	O
multiple	O
orthogonal	B-Method
classifiers	I-Method
to	O
counteract	O
this	O
effect	O
.	O
	
Recent	O
work	O
on	O
generating	O
sentence	B-Task
embeddings	I-Task
range	O
from	O
models	O
that	O
compose	O
word	B-Method
embeddings	I-Method
to	O
more	O
complex	O
neural	B-Method
network	I-Method
architectures	I-Method
.	O
	
SkipThought	B-Method
vectors	I-Method
propose	O
an	O
objective	B-Method
function	I-Method
that	O
adapts	O
the	O
skip	B-Method
-	I-Method
gram	I-Method
model	I-Method
for	O
words	O
to	O
the	O
sentence	O
level	O
.	O
	
By	O
encoding	O
a	O
sentence	O
to	O
predict	O
the	O
sentences	O
around	O
it	O
,	O
and	O
using	O
the	O
features	O
in	O
a	O
linear	B-Method
model	I-Method
,	O
they	O
were	O
able	O
to	O
demonstrate	O
good	O
performance	O
on	O
8	O
transfer	B-Task
tasks	I-Task
.	O
	
They	O
further	O
obtained	O
better	O
results	O
using	O
layer	B-Method
-	I-Method
norm	I-Method
regularization	I-Method
of	O
their	O
model	O
in	O
.	O
	
hill2016learning	O
showed	O
that	O
the	O
task	O
on	O
which	O
sentence	O
embeddings	O
are	O
trained	O
significantly	O
impacts	O
their	O
quality	O
.	O
	
In	O
addition	O
to	O
unsupervised	B-Method
methods	I-Method
,	O
they	O
included	O
supervised	B-Method
training	I-Method
in	O
their	O
comparison	O
	
—	O
namely	O
,	O
on	O
machine	O
translation	O
data	O
(	O
using	O
the	O
WMT’14	O
English	O
/	O
French	B-Material
and	I-Material
English	I-Material
/	O
German	B-Material
pairs	I-Material
)	O
	
,	O
dictionary	O
definitions	O
and	O
image	O
captioning	O
data	O
(	O
see	O
also	O
kiela2017learning	O
)	O
from	O
the	O
COCO	B-Material
dataset	I-Material
.	O
	
These	O
models	O
obtained	O
significantly	O
lower	O
results	O
compared	O
to	O
the	O
unsupervised	B-Method
Skip	I-Method
-	I-Method
Thought	I-Method
approach	I-Method
.	O
	
Recent	O
work	O
has	O
explored	O
training	O
sentence	B-Method
encoders	I-Method
on	O
the	O
SNLI	B-Material
corpus	O
and	O
applying	O
them	O
on	O
the	O
SICK	B-Material
corpus	I-Material
,	O
either	O
using	O
multi	B-Method
-	I-Method
task	I-Method
learning	I-Method
or	O
pretraining	B-Method
.	O
	
The	O
results	O
were	O
inconclusive	O
and	O
did	O
not	O
reach	O
the	O
same	O
level	O
as	O
simpler	O
approaches	O
that	O
directly	O
learn	O
a	O
classifier	B-Method
on	O
top	O
of	O
unsupervised	O
sentence	O
embeddings	O
instead	O
.	O
	
To	O
our	O
knowledge	O
,	O
this	O
work	O
is	O
the	O
first	O
attempt	O
to	O
fully	O
exploit	O
the	O
SNLI	B-Material
corpus	O
for	O
building	O
generic	B-Task
sentence	I-Task
encoders	I-Task
.	O
	
As	O
we	O
show	O
in	O
our	O
experiments	O
,	O
we	O
are	O
able	O
to	O
consistently	O
outperform	O
unsupervised	B-Method
approaches	I-Method
,	O
even	O
if	O
our	O
models	O
are	O
trained	O
on	O
much	O
less	O
(	O
but	O
human	O
-	O
annotated	O
)	O
data	O
.	O
	
section	O
:	O
Approach	O
	
This	O
work	O
combines	O
two	O
research	O
directions	O
,	O
which	O
we	O
describe	O
in	O
what	O
follows	O
.	O
	
First	O
,	O
we	O
explain	O
how	O
the	O
NLI	B-Task
task	I-Task
can	O
be	O
used	O
to	O
train	O
universal	B-Method
sentence	I-Method
encoding	I-Method
models	I-Method
using	O
the	O
SNLI	B-Material
task	O
.	O
	
We	O
subsequently	O
describe	O
the	O
architectures	O
that	O
we	O
investigated	O
for	O
the	O
sentence	B-Task
encoder	I-Task
,	O
which	O
,	O
in	O
our	O
opinion	O
,	O
covers	O
a	O
suitable	O
range	O
of	O
sentence	B-Method
encoders	I-Method
currently	O
in	O
use	O
.	O
	
Specifically	O
,	O
we	O
examine	O
standard	O
recurrent	B-Method
models	I-Method
such	O
as	O
LSTMs	B-Method
and	O
GRUs	B-Method
,	O
for	O
which	O
we	O
investigate	O
mean	B-Method
and	O
max	B-Method
-	I-Method
pooling	I-Method
over	O
the	O
hidden	B-Method
representations	I-Method
;	O
a	O
self	B-Method
-	I-Method
attentive	I-Method
network	I-Method
that	O
incorporates	O
different	O
views	O
of	O
the	O
sentence	O
;	O
and	O
a	O
hierarchical	B-Method
convolutional	I-Method
network	I-Method
that	O
can	O
be	O
seen	O
as	O
a	O
tree	B-Method
-	I-Method
based	I-Method
method	I-Method
that	O
blends	O
different	O
levels	O
of	O
abstraction	O
.	O
	
subsection	O
:	O
The	O
Natural	B-Task
Language	I-Task
Inference	I-Task
task	I-Task
	
The	O
SNLI	B-Material
dataset	O
consists	O
of	O
570k	O
human	B-Material
-	I-Material
generated	I-Material
English	I-Material
sentence	I-Material
pairs	I-Material
,	O
manually	O
labeled	O
with	O
one	O
of	O
three	O
categories	O
:	O
entailment	O
,	O
contradiction	O
and	O
neutral	O
.	O
	
It	O
captures	O
natural	B-Task
language	I-Task
inference	I-Task
,	O
also	O
known	O
in	O
previous	O
incarnations	O
as	O
Recognizing	B-Task
Textual	I-Task
Entailment	I-Task
(	O
RTE	B-Task
)	O
,	O
and	O
constitutes	O
one	O
of	O
the	O
largest	O
high	O
-	O
quality	O
labeled	O
resources	O
explicitly	O
constructed	O
in	O
order	O
to	O
require	O
understanding	O
sentence	O
semantics	O
.	O
	
We	O
hypothesize	O
that	O
the	O
semantic	O
nature	O
of	O
NLI	B-Task
makes	O
it	O
a	O
good	O
candidate	O
for	O
learning	O
universal	B-Task
sentence	I-Task
embeddings	I-Task
in	O
a	O
supervised	B-Task
way	I-Task
.	O
	
That	O
is	O
,	O
we	O
aim	O
to	O
demonstrate	O
that	O
sentence	B-Method
encoders	I-Method
trained	O
on	O
natural	B-Task
language	I-Task
inference	I-Task
are	O
able	O
to	O
learn	O
sentence	B-Method
representations	I-Method
that	O
capture	O
universally	O
useful	O
features	O
.	O
	
Models	O
can	O
be	O
trained	O
on	O
SNLI	B-Material
in	O
two	O
different	O
ways	O
:	O
	
(	O
i	O
)	O
sentence	B-Method
encoding	I-Method
-	I-Method
based	I-Method
models	I-Method
that	O
explicitly	O
separate	O
the	O
encoding	O
of	O
the	O
individual	O
sentences	O
and	O
(	O
ii	O
)	O
joint	B-Method
methods	I-Method
that	O
allow	O
to	O
use	O
encoding	O
of	O
both	O
sentences	O
(	O
to	O
use	O
cross	O
-	O
features	O
or	O
attention	O
from	O
one	O
sentence	O
to	O
the	O
other	O
)	O
.	O
	
Since	O
our	O
goal	O
is	O
to	O
train	O
a	O
generic	B-Method
sentence	I-Method
encoder	I-Method
,	O
we	O
adopt	O
the	O
first	O
setting	O
.	O
	
As	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
a	O
typical	O
architecture	O
of	O
this	O
kind	O
uses	O
a	O
shared	B-Method
sentence	I-Method
encoder	I-Method
that	O
outputs	O
a	O
representation	O
for	O
the	O
premise	O
and	O
the	O
hypothesis	O
.	O
	
Once	O
the	O
sentence	O
vectors	O
are	O
generated	O
,	O
3	O
matching	B-Method
methods	I-Method
are	O
applied	O
to	O
extract	O
relations	O
between	O
and	O
:	O
(	O
i	O
)	O
concatenation	O
of	O
the	O
two	O
representations	O
;	O
(	O
ii	O
)	O
element	B-Method
-	I-Method
wise	I-Method
product	I-Method
;	O
and	O
(	O
iii	O
)	O
absolute	O
element	O
-	O
wise	O
difference	O
.	O
	
The	O
resulting	O
vector	O
,	O
which	O
captures	O
information	O
from	O
both	O
the	O
premise	O
and	O
the	O
hypothesis	O
,	O
is	O
fed	O
into	O
a	O
3	B-Method
-	I-Method
class	I-Method
classifier	I-Method
consisting	O
of	O
multiple	O
fully	B-Method
-	I-Method
connected	I-Method
layers	I-Method
culminating	O
in	O
a	O
softmax	B-Method
layer	I-Method
.	O
	
subsection	O
:	O
Sentence	B-Method
encoder	I-Method
architectures	I-Method
	
A	O
wide	O
variety	O
of	O
neural	B-Method
networks	I-Method
for	O
encoding	B-Task
sentences	I-Task
into	O
fixed	B-Task
-	I-Task
size	I-Task
representations	I-Task
exists	O
,	O
and	O
it	O
is	O
not	O
yet	O
clear	O
which	O
one	O
best	O
captures	O
generically	O
useful	O
information	O
.	O
	
We	O
compare	O
7	O
different	O
architectures	O
:	O
standard	O
recurrent	B-Method
encoders	I-Method
with	O
either	O
Long	B-Method
Short	I-Method
-	I-Method
Term	I-Method
Memory	I-Method
(	O
LSTM	B-Method
)	O
or	O
Gated	B-Method
Recurrent	I-Method
Units	I-Method
(	O
GRU	B-Method
)	O
,	O
concatenation	O
of	O
last	O
hidden	O
states	O
of	O
forward	O
and	O
backward	O
	
GRU	B-Method
,	O
Bi	B-Method
-	I-Method
directional	I-Method
LSTMs	I-Method
(	O
BiLSTM	B-Method
)	O
with	O
either	O
mean	B-Method
or	O
max	B-Method
pooling	I-Method
,	O
self	B-Method
-	I-Method
attentive	I-Method
network	I-Method
and	O
hierarchical	B-Method
convolutional	I-Method
networks	I-Method
.	O
	
subsubsection	O
:	O
LSTM	B-Method
and	O
GRU	B-Method
	
Our	O
first	O
,	O
and	O
simplest	O
,	O
encoders	B-Method
apply	O
recurrent	B-Method
neural	I-Method
networks	I-Method
using	O
either	O
LSTM	B-Method
or	O
GRU	B-Method
modules	O
,	O
as	O
in	O
sequence	B-Method
to	I-Method
sequence	I-Method
encoders	I-Method
.	O
	
For	O
a	O
sequence	O
of	O
words	O
,	O
the	O
network	O
computes	O
a	O
set	O
of	O
hidden	B-Method
representations	I-Method
,	O
with	O
(	O
or	O
using	O
GRU	B-Method
units	O
instead	O
)	O
.	O
	
A	O
sentence	O
is	O
represented	O
by	O
the	O
last	O
hidden	O
vector	O
,	O
.	O
	
We	O
also	O
consider	O
a	O
model	B-Method
BiGRU	I-Method
-	I-Method
last	I-Method
that	O
concatenates	O
the	O
last	O
hidden	O
state	O
of	O
a	O
forward	O
GRU	B-Method
,	O
and	O
the	O
last	O
hidden	O
state	O
of	O
a	O
backward	O
GRU	B-Method
to	O
have	O
the	O
same	O
architecture	O
as	O
for	O
SkipThought	O
vectors	O
.	O
	
subsubsection	O
:	O
BiLSTM	B-Method
with	O
mean	B-Method
/	O
max	B-Method
pooling	I-Method
	
For	O
a	O
sequence	O
of	O
T	O
words	O
,	O
a	O
bidirectional	O
LSTM	B-Method
computes	O
a	O
set	O
of	O
T	O
vectors	O
.	O
	
For	O
,	O
,	O
is	O
the	O
concatenation	O
of	O
a	O
forward	O
LSTM	B-Method
and	O
a	O
backward	O
LSTM	B-Method
that	O
read	O
the	O
sentences	O
in	O
two	O
opposite	O
directions	O
:	O
We	O
experiment	O
with	O
two	O
ways	O
of	O
combining	O
the	O
varying	O
number	O
of	O
to	O
form	O
a	O
fixed	O
-	O
size	O
vector	O
,	O
either	O
by	O
selecting	O
the	O
maximum	O
value	O
over	O
each	O
dimension	O
of	O
the	O
hidden	O
units	O
(	O
max	B-Method
pooling	I-Method
)	O
or	O
by	O
considering	O
the	O
average	O
of	O
the	O
representations	O
(	O
mean	B-Method
pooling	O
)	O
.	O
	
subsubsection	O
:	O
Self	B-Method
-	I-Method
attentive	I-Method
network	I-Method
	
The	O
self	B-Method
-	I-Method
attentive	I-Method
sentence	I-Method
encoder	I-Method
uses	O
an	O
attention	B-Method
mechanism	I-Method
over	O
the	O
hidden	O
states	O
of	O
a	O
BiLSTM	B-Method
to	O
generate	O
a	O
representation	O
of	O
an	O
input	O
sentence	O
.	O
	
The	O
attention	B-Method
mechanism	I-Method
is	O
defined	O
as	O
:	O
where	O
are	O
the	O
output	O
hidden	O
vectors	O
of	O
a	O
BiLSTM	B-Method
.	O
	
These	O
are	O
fed	O
to	O
an	O
affine	B-Method
transformation	I-Method
(	O
,	O
)	O
which	O
outputs	O
a	O
set	O
of	O
keys	O
.	O
	
The	O
represent	O
the	O
score	O
of	O
similarity	O
between	O
the	O
keys	O
and	O
a	O
learned	O
context	O
query	O
vector	O
.	O
	
These	O
weights	O
are	O
used	O
to	O
produce	O
the	O
final	O
representation	O
,	O
which	O
is	O
a	O
weighted	B-Method
linear	I-Method
combination	I-Method
of	O
the	O
hidden	O
vectors	O
.	O
	
Following	O
lin2017structured	O
we	O
use	O
a	O
self	B-Method
-	I-Method
attentive	I-Method
network	I-Method
with	O
multiple	O
views	O
of	O
the	O
input	O
sentence	O
,	O
so	O
that	O
the	O
model	O
can	O
learn	O
which	O
part	O
of	O
the	O
sentence	O
is	O
important	O
for	O
the	O
given	O
task	O
.	O
	
Concretely	O
,	O
we	O
have	O
4	O
context	O
vectors	O
which	O
generate	O
4	O
representations	O
that	O
are	O
then	O
concatenated	O
to	O
obtain	O
the	O
sentence	B-Method
representation	I-Method
.	O
	
Figure	O
[	O
reference	O
]	O
illustrates	O
this	O
architecture	O
.	O
	
subsubsection	O
:	O
Hierarchical	B-Method
ConvNet	I-Method
	
One	O
of	O
the	O
currently	O
best	O
performing	O
models	O
on	O
classification	B-Task
tasks	I-Task
is	O
a	O
convolutional	B-Method
architecture	I-Method
termed	O
AdaSent	B-Method
,	O
which	O
concatenates	O
different	O
representations	O
of	O
the	O
sentences	O
at	O
different	O
level	O
of	O
abstractions	O
.	O
	
Inspired	O
by	O
this	O
architecture	O
,	O
we	O
introduce	O
a	O
faster	O
version	O
consisting	O
of	O
4	O
convolutional	B-Method
layers	I-Method
.	O
	
At	O
every	O
layer	O
,	O
a	O
representation	O
is	O
computed	O
by	O
a	O
max	B-Method
-	I-Method
pooling	I-Method
operation	I-Method
over	O
the	O
feature	O
maps	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
The	O
final	O
representation	O
concatenates	O
representations	O
at	O
different	O
levels	O
of	O
the	O
input	O
sentence	O
.	O
	
The	O
model	O
thus	O
captures	O
hierarchical	O
abstractions	O
of	O
an	O
input	O
sentence	O
in	O
a	O
fixed	B-Method
-	I-Method
size	I-Method
representation	I-Method
.	O
	
subsection	O
:	O
Training	O
details	O
	
For	O
all	O
our	O
models	O
trained	O
on	O
SNLI	B-Material
,	O
we	O
use	O
SGD	B-Method
with	O
a	O
learning	B-Metric
rate	I-Metric
of	O
0.1	O
and	O
a	O
weight	O
decay	O
of	O
0.99	O
.	O
	
At	O
each	O
epoch	O
,	O
we	O
divide	O
the	O
learning	B-Metric
rate	I-Metric
by	O
5	O
if	O
the	O
dev	B-Metric
accuracy	I-Metric
decreases	O
.	O
	
We	O
use	O
mini	O
-	O
batches	O
of	O
size	O
64	O
and	O
training	O
is	O
stopped	O
when	O
the	O
learning	B-Metric
rate	I-Metric
goes	O
under	O
the	O
threshold	O
of	O
.	O
	
For	O
the	O
classifier	B-Method
,	O
we	O
use	O
a	O
multi	B-Method
-	I-Method
layer	I-Method
perceptron	I-Method
with	O
1	O
hidden	B-Method
-	I-Method
layer	I-Method
of	O
512	O
hidden	O
units	O
.	O
	
We	O
use	O
open	O
-	O
source	O
GloVe	B-Method
vectors	I-Method
trained	O
on	O
Common	O
Crawl	O
840B	O
with	O
300	O
dimensions	O
as	O
fixed	O
word	O
embeddings	O
.	O
	
section	O
:	O
Evaluation	O
of	O
sentence	B-Task
representations	I-Task
	
Our	O
aim	O
is	O
to	O
obtain	O
general	O
-	O
purpose	O
sentence	B-Method
embeddings	I-Method
that	O
capture	O
generic	O
information	O
that	O
is	O
useful	O
for	O
a	O
broad	O
set	O
of	O
tasks	O
.	O
	
To	O
evaluate	O
the	O
quality	O
of	O
these	O
representations	O
,	O
we	O
use	O
them	O
as	O
features	O
in	O
12	O
transfer	B-Task
tasks	I-Task
.	O
	
We	O
present	O
our	O
sentence	B-Task
-	I-Task
embedding	I-Task
evaluation	I-Task
procedure	I-Task
in	O
this	O
section	O
.	O
	
We	O
constructed	O
a	O
sentence	B-Method
evaluation	I-Method
tool	I-Method
called	O
SentEval	B-Material
to	O
automate	O
evaluation	B-Task
on	O
all	O
the	O
tasks	O
mentioned	O
in	O
this	O
paper	O
.	O
	
The	O
tool	O
uses	O
Adam	B-Method
to	O
fit	O
a	O
logistic	B-Method
regression	I-Method
classifier	I-Method
,	O
with	O
batch	O
size	O
64	O
.	O
	
paragraph	O
:	O
Binary	B-Task
and	I-Task
multi	I-Task
-	I-Task
class	I-Task
classification	I-Task
	
We	O
use	O
a	O
set	O
of	O
binary	B-Task
classification	I-Task
tasks	I-Task
(	O
see	O
Table	O
[	O
reference	O
]	O
)	O
that	O
covers	O
various	O
types	O
of	O
sentence	B-Task
classification	I-Task
,	O
including	O
sentiment	B-Task
analysis	I-Task
(	O
MR	B-Task
,	O
SST	B-Task
)	O
,	O
question	B-Task
-	I-Task
type	I-Task
(	O
TREC	B-Task
)	O
,	O
product	B-Task
reviews	I-Task
(	O
CR	B-Task
)	O
,	O
subjectivity	O
/	O
objectivity	O
(	O
SUBJ	O
)	O
and	O
opinion	O
polarity	O
(	O
MPQA	B-Method
)	O
.	O
	
We	O
generate	O
sentence	O
vectors	O
and	O
train	O
a	O
logistic	B-Method
regression	I-Method
on	O
top	O
.	O
	
A	O
linear	B-Method
classifier	I-Method
requires	O
fewer	B-Metric
parameters	I-Metric
than	O
an	O
MLP	B-Method
and	O
is	O
thus	O
suitable	O
for	O
small	O
datasets	O
,	O
where	O
transfer	B-Method
learning	I-Method
is	O
especially	O
well	O
-	O
suited	O
.	O
	
We	O
tune	O
the	O
L2	O
penalty	O
of	O
the	O
logistic	B-Method
regression	I-Method
with	O
grid	B-Method
-	I-Method
search	I-Method
on	O
the	O
validation	O
set	O
.	O
	
paragraph	O
:	O
Entailment	B-Task
and	O
semantic	B-Metric
relatedness	I-Metric
	
We	O
also	O
evaluate	O
on	O
the	O
SICK	B-Material
dataset	I-Material
for	O
both	O
entailment	O
(	O
SICK	B-Metric
-	I-Metric
E	I-Metric
)	O
and	O
semantic	B-Metric
relatedness	I-Metric
(	O
SICK	B-Metric
-	I-Metric
R	I-Metric
)	O
.	O
	
We	O
use	O
the	O
same	O
matching	B-Method
methods	I-Method
as	O
in	O
SNLI	B-Material
and	O
learn	O
a	O
Logistic	B-Method
Regression	I-Method
on	O
top	O
of	O
the	O
joint	B-Method
representation	I-Method
.	O
	
For	O
semantic	B-Metric
relatedness	I-Metric
evaluation	O
,	O
we	O
follow	O
the	O
approach	O
of	O
and	O
learn	O
to	O
predict	O
the	O
probability	O
distribution	O
of	O
relatedness	O
scores	O
.	O
	
We	O
report	O
Pearson	B-Metric
correlation	I-Metric
.	O
	
paragraph	O
:	O
STS14	O
-	O
Semantic	B-Method
Textual	I-Method
Similarity	I-Method
	
While	O
semantic	B-Metric
relatedness	I-Metric
is	O
supervised	O
in	O
the	O
case	O
of	O
SICK	B-Metric
-	I-Metric
R	I-Metric
,	O
we	O
also	O
evaluate	O
our	O
embeddings	O
on	O
the	O
6	O
unsupervised	B-Task
SemEval	I-Task
tasks	I-Task
of	O
STS14	B-Material
.	O
	
This	O
dataset	O
includes	O
subsets	O
of	O
news	O
articles	O
,	O
forum	O
discussions	O
,	O
image	O
descriptions	O
and	O
headlines	O
from	O
news	O
articles	O
containing	O
pairs	O
of	O
sentences	O
(	O
lower	O
-	O
cased	O
)	O
,	O
labeled	O
with	O
a	O
similarity	B-Metric
score	I-Metric
between	O
0	O
and	O
5	O
.	O
	
These	O
tasks	O
evaluate	O
how	O
the	O
cosine	O
distance	O
between	O
two	O
sentences	O
correlate	O
with	O
a	O
human	B-Metric
-	I-Metric
labeled	I-Metric
similarity	I-Metric
score	I-Metric
through	O
Pearson	B-Metric
and	I-Metric
Spearman	I-Metric
correlations	I-Metric
.	O
	
paragraph	O
:	O
Paraphrase	B-Task
detection	I-Task
	
The	O
Microsoft	B-Material
Research	I-Material
Paraphrase	I-Material
Corpus	I-Material
is	O
composed	O
of	O
pairs	O
of	O
sentences	O
which	O
have	O
been	O
extracted	O
from	O
news	O
sources	O
on	O
the	O
Web	B-Material
.	O
	
Sentence	O
pairs	O
have	O
been	O
human	O
-	O
annotated	O
according	O
to	O
whether	O
they	O
capture	O
a	O
paraphrase	O
/	O
semantic	O
equivalence	O
relationship	O
.	O
	
We	O
use	O
the	O
same	O
approach	O
as	O
with	O
SICK	B-Metric
-	I-Metric
E	I-Metric
,	O
except	O
that	O
our	O
classifier	B-Method
has	O
only	O
2	O
classes	O
.	O
	
paragraph	O
:	O
Caption	B-Task
-	O
Image	B-Task
retrieval	I-Task
	
The	O
caption	B-Task
-	I-Task
image	I-Task
retrieval	I-Task
task	I-Task
evaluates	O
joint	B-Method
image	I-Method
and	I-Method
language	I-Method
feature	I-Method
models	I-Method
.	O
	
The	O
goal	O
is	O
either	O
to	O
rank	O
a	O
large	O
collection	O
of	O
images	O
by	O
their	O
relevance	O
with	O
respect	O
to	O
a	O
given	O
query	O
caption	O
(	O
Image	B-Task
Retrieval	I-Task
)	O
,	O
or	O
ranking	B-Task
captions	I-Task
by	O
their	O
relevance	O
for	O
a	O
given	O
query	O
image	O
(	O
Caption	B-Task
Retrieval	I-Task
)	O
.	O
	
We	O
use	O
a	O
pairwise	B-Metric
ranking	I-Metric
-	I-Metric
loss	I-Metric
:	O
where	O
consists	O
of	O
an	O
image	O
with	O
one	O
of	O
its	O
associated	O
captions	O
,	O
and	O
are	O
negative	O
examples	O
of	O
the	O
ranking	B-Metric
loss	I-Metric
,	O
is	O
the	O
margin	O
and	O
corresponds	O
to	O
the	O
cosine	O
similarity	O
.	O
	
and	O
are	O
learned	O
linear	B-Method
transformations	I-Method
that	O
project	O
the	O
caption	O
and	O
the	O
image	O
to	O
the	O
same	O
embedding	O
space	O
.	O
	
We	O
use	O
a	O
margin	O
and	O
contrastive	O
terms	O
.	O
	
We	O
use	O
the	O
same	O
splits	O
as	O
in	O
,	O
i.e.	O
,	O
we	O
use	O
113k	O
images	O
from	O
the	O
COCO	B-Material
dataset	I-Material
(	O
each	O
containing	O
5	O
captions	O
)	O
for	O
training	O
,	O
5k	O
images	O
for	O
validation	O
and	O
5k	O
images	O
for	O
test	O
.	O
	
For	O
evaluation	O
,	O
we	O
split	O
the	O
5k	O
images	O
in	O
5	O
random	O
sets	O
of	O
1k	O
images	O
on	O
which	O
we	O
compute	O
Recall@K	B-Metric
,	O
with	O
K	O
and	O
median	O
(	O
Med	O
r	O
)	O
over	O
the	O
5	O
splits	O
.	O
	
For	O
fair	O
comparison	O
,	O
we	O
also	O
report	O
SkipThought	O
results	O
in	O
our	O
setting	O
,	O
using	O
2048	O
-	O
dimensional	O
pretrained	O
ResNet	B-Method
-	I-Method
101	I-Method
with	O
113k	O
training	O
images	O
.	O
	
section	O
:	O
Empirical	O
results	O
	
In	O
this	O
section	O
,	O
we	O
refer	O
to	O
”	O
micro	B-Metric
”	I-Metric
and	I-Metric
”	I-Metric
macro	I-Metric
”	I-Metric
averages	I-Metric
of	I-Metric
development	I-Metric
set	I-Metric
(	O
dev	O
)	O
results	O
on	O
transfer	B-Task
tasks	I-Task
whose	O
metrics	O
is	O
accuracy	B-Metric
:	O
we	O
compute	O
a	O
”	O
macro	B-Metric
”	I-Metric
aggregated	I-Metric
score	I-Metric
that	O
corresponds	O
to	O
the	O
classical	B-Metric
average	I-Metric
of	I-Metric
dev	I-Metric
accuracies	I-Metric
,	O
and	O
the	O
”	O
micro	B-Metric
”	I-Metric
score	I-Metric
that	O
is	O
a	O
sum	O
of	O
the	O
dev	B-Metric
accuracies	I-Metric
,	O
weighted	O
by	O
the	O
number	O
of	O
dev	O
samples	O
.	O
	
subsection	O
:	O
Architecture	O
impact	O
	
paragraph	O
:	O
Model	O
	
We	O
observe	O
in	O
Table	O
[	O
reference	O
]	O
that	O
different	O
models	O
trained	O
on	O
the	O
same	O
NLI	B-Task
corpus	O
lead	O
to	O
different	O
transfer	B-Task
tasks	I-Task
results	O
.	O
	
The	O
BiLSTM	B-Method
-	I-Method
4096	I-Method
with	O
the	O
max	B-Method
-	I-Method
pooling	I-Method
operation	I-Method
performs	O
best	O
on	O
both	O
SNLI	B-Material
and	O
transfer	O
tasks	O
.	O
	
Looking	O
at	O
the	O
micro	O
and	O
macro	O
averages	O
,	O
we	O
see	O
that	O
it	O
performs	O
significantly	O
better	O
than	O
the	O
other	O
models	O
LSTM	B-Method
,	O
GRU	B-Method
,	O
BiGRU	B-Method
-	I-Method
last	I-Method
,	O
BiLSTM	B-Method
-	I-Method
Mean	I-Method
,	O
inner	B-Method
-	I-Method
attention	I-Method
and	O
the	O
hierarchical	B-Method
-	I-Method
ConvNet	I-Method
.	O
	
Table	O
[	O
reference	O
]	O
also	O
shows	O
that	O
better	O
performance	O
on	O
the	O
training	B-Task
task	I-Task
does	O
not	O
necessarily	O
translate	O
in	O
better	O
results	O
on	O
the	O
transfer	B-Task
tasks	I-Task
like	O
when	O
comparing	O
inner	O
-	O
attention	O
and	O
BiLSTM	B-Method
-	I-Method
Mean	I-Method
for	O
instance	O
.	O
	
We	O
hypothesize	O
that	O
some	O
models	O
are	O
likely	O
to	O
over	O
-	O
specialize	O
and	O
adapt	O
too	O
well	O
to	O
the	O
biases	O
of	O
a	O
dataset	O
without	O
capturing	O
general	O
-	O
purpose	O
information	O
of	O
the	O
input	O
sentence	O
.	O
	
For	O
example	O
,	O
the	O
inner	B-Method
-	I-Method
attention	I-Method
model	I-Method
has	O
the	O
ability	O
to	O
focus	O
only	O
on	O
certain	O
parts	O
of	O
a	O
sentence	O
that	O
are	O
useful	O
for	O
the	O
SNLI	B-Material
task	O
,	O
but	O
not	O
necessarily	O
for	O
the	O
transfer	B-Task
tasks	I-Task
.	O
	
On	O
the	O
other	O
hand	O
,	O
BiLSTM	B-Method
-	I-Method
Mean	I-Method
does	O
not	O
make	O
sharp	O
choices	O
on	O
which	O
part	O
of	O
the	O
sentence	O
is	O
more	O
important	O
than	O
others	O
.	O
	
The	O
difference	O
between	O
the	O
results	O
seems	O
to	O
come	O
from	O
the	O
different	O
abilities	O
of	O
the	O
models	O
to	O
incorporate	O
general	O
information	O
while	O
not	O
focusing	O
too	O
much	O
on	O
specific	O
features	O
useful	O
for	O
the	O
task	O
at	O
hand	O
.	O
	
For	O
a	O
given	O
model	O
,	O
the	O
transfer	B-Metric
quality	I-Metric
is	O
also	O
sensitive	O
to	O
the	O
optimization	B-Method
algorithm	I-Method
:	O
when	O
training	O
with	O
Adam	B-Method
instead	O
of	O
SGD	B-Method
,	O
we	O
observed	O
that	O
the	O
BiLSTM	B-Method
-	I-Method
max	I-Method
converged	O
faster	O
on	O
SNLI	B-Material
(	O
5	O
epochs	O
instead	O
of	O
10	O
)	O
,	O
but	O
obtained	O
worse	O
results	O
on	O
the	O
transfer	B-Task
tasks	I-Task
,	O
most	O
likely	O
because	O
of	O
the	O
model	O
and	O
classifier	B-Method
’s	O
increased	O
capability	O
to	O
over	O
-	O
specialize	O
on	O
the	O
training	B-Task
task	I-Task
.	O
	
paragraph	O
:	O
Embedding	B-Metric
size	I-Metric
	
Figure	O
[	O
reference	O
]	O
compares	O
the	O
overall	O
performance	O
of	O
different	O
architectures	O
,	O
showing	O
the	O
evolution	O
of	O
micro	B-Metric
averaged	I-Metric
performance	I-Metric
with	O
regard	O
to	O
the	O
embedding	B-Metric
size	I-Metric
.	O
	
Since	O
it	O
is	O
easier	O
to	O
linearly	O
separate	O
in	O
high	O
dimension	O
,	O
especially	O
with	O
logistic	B-Method
regression	I-Method
,	O
it	O
is	O
not	O
surprising	O
that	O
increased	O
embedding	O
sizes	O
lead	O
to	O
increased	O
performance	O
for	O
almost	O
all	O
models	O
.	O
	
However	O
,	O
this	O
is	O
particularly	O
true	O
for	O
some	O
models	O
(	O
BiLSTM	B-Method
-	I-Method
Max	I-Method
,	O
HConvNet	B-Method
,	O
inner	B-Method
-	I-Method
att	I-Method
)	O
,	O
which	O
demonstrate	O
unequal	O
abilities	O
to	O
incorporate	O
more	O
information	O
as	O
the	O
size	O
grows	O
.	O
	
We	O
hypothesize	O
that	O
such	O
networks	O
are	O
able	O
to	O
incorporate	O
information	O
that	O
is	O
not	O
directly	O
relevant	O
to	O
the	O
objective	B-Task
task	I-Task
(	O
results	O
on	O
SNLI	B-Material
are	O
relatively	O
stable	O
with	O
regard	O
to	O
embedding	O
size	O
)	O
but	O
that	O
can	O
nevertheless	O
be	O
useful	O
as	O
features	O
for	O
transfer	B-Task
tasks	I-Task
.	O
	
subsection	O
:	O
Task	B-Task
transfer	I-Task
	
We	O
report	O
in	O
Table	O
[	O
reference	O
]	O
transfer	B-Task
tasks	I-Task
results	O
for	O
different	O
architectures	O
trained	O
in	O
different	O
ways	O
.	O
	
We	O
group	O
models	O
by	O
the	O
nature	O
of	O
the	O
data	O
on	O
which	O
they	O
were	O
trained	O
.	O
	
The	O
first	O
group	O
corresponds	O
to	O
models	O
trained	O
with	O
unsupervised	O
unordered	O
sentences	O
.	O
	
This	O
includes	O
bag	B-Method
-	I-Method
of	I-Method
-	I-Method
words	I-Method
models	I-Method
such	O
as	O
word2vec	B-Method
-	I-Method
SkipGram	I-Method
,	O
the	O
Unigram	B-Method
-	I-Method
TFIDF	I-Method
model	I-Method
,	O
the	O
Paragraph	B-Method
Vector	I-Method
model	I-Method
,	O
the	O
Sequential	B-Method
Denoising	I-Method
Auto	I-Method
-	I-Method
Encoder	I-Method
(	O
SDAE	B-Method
)	O
and	O
the	O
SIF	B-Method
model	I-Method
,	O
all	O
trained	O
on	O
the	O
Toronto	B-Material
book	I-Material
corpus	I-Material
.	O
	
The	O
second	O
group	O
consists	O
of	O
models	O
trained	O
with	O
unsupervised	O
ordered	O
sentences	O
such	O
as	O
FastSent	B-Method
and	O
SkipThought	B-Method
(	O
also	O
trained	O
on	O
the	O
Toronto	B-Material
book	I-Material
corpus	I-Material
)	O
.	O
	
We	O
also	O
include	O
the	O
FastSent	B-Method
variant	I-Method
“	I-Method
FastSent	I-Method
+	I-Method
AE	I-Method
”	I-Method
and	O
the	O
SkipThought	B-Method
-	I-Method
LN	I-Method
version	I-Method
that	O
uses	O
layer	B-Method
normalization	I-Method
.	O
	
We	O
report	O
results	O
from	O
models	O
trained	O
on	O
supervised	O
data	O
in	O
the	O
third	O
group	O
,	O
and	O
also	O
report	O
some	O
results	O
of	O
supervised	B-Method
methods	I-Method
trained	O
directly	O
on	O
each	O
task	O
for	O
comparison	O
with	O
transfer	B-Method
learning	I-Method
approaches	I-Method
.	O
	
paragraph	O
:	O
Comparison	O
with	O
SkipThought	B-Method
	
The	O
best	O
performing	O
sentence	B-Method
encoder	I-Method
to	O
date	O
is	O
the	O
SkipThought	B-Method
-	I-Method
LN	I-Method
model	I-Method
,	O
which	O
was	O
trained	O
on	O
a	O
very	O
large	O
corpora	O
of	O
ordered	O
sentences	O
.	O
	
With	O
much	O
less	O
data	O
(	O
570k	O
compared	O
to	O
64	O
M	O
sentences	O
)	O
but	O
with	O
high	O
-	O
quality	O
supervision	O
from	O
the	O
SNLI	B-Material
dataset	O
,	O
we	O
are	O
able	O
to	O
consistently	O
outperform	O
the	O
results	O
obtained	O
by	O
SkipThought	B-Method
vectors	I-Method
.	O
	
We	O
train	O
our	O
model	O
in	O
less	O
than	O
a	O
day	O
on	O
a	O
single	O
GPU	O
compared	O
to	O
the	O
best	O
SkipThought	B-Method
-	I-Method
LN	I-Method
network	I-Method
trained	O
for	O
a	O
month	O
.	O
	
Our	O
BiLSTM	B-Method
-	I-Method
max	I-Method
trained	O
on	O
SNLI	B-Material
performs	O
much	O
better	O
than	O
released	O
SkipThought	O
vectors	O
on	O
MR	O
,	O
CR	B-Task
,	O
MPQA	O
,	O
SST	B-Task
,	O
MRPC	B-Metric
-	I-Metric
accuracy	I-Metric
,	O
SICK	B-Metric
-	I-Metric
R	I-Metric
,	O
SICK	B-Metric
-	I-Metric
E	I-Metric
and	O
STS14	B-Method
	
(	O
see	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
Except	O
for	O
the	O
SUBJ	B-Material
dataset	I-Material
,	O
it	O
also	O
performs	O
better	O
than	O
SkipThought	B-Method
-	I-Method
LN	I-Method
on	O
MR	B-Task
,	O
CR	B-Task
and	O
MPQA	B-Task
.	O
	
We	O
also	O
observe	O
by	O
looking	O
at	O
the	O
STS14	O
results	O
that	O
the	O
cosine	B-Metric
metrics	I-Metric
in	O
our	O
embedding	O
space	O
is	O
much	O
more	O
semantically	O
informative	O
than	O
in	O
SkipThought	O
embedding	O
space	O
(	O
pearson	B-Metric
score	I-Metric
of	O
0.68	O
compared	O
to	O
0.29	O
and	O
0.44	O
for	O
ST	O
and	O
ST	B-Method
-	I-Method
LN	I-Method
)	O
.	O
	
We	O
hypothesize	O
that	O
this	O
is	O
namely	O
linked	O
to	O
the	O
matching	B-Method
method	I-Method
of	O
SNLI	B-Material
models	O
which	O
incorporates	O
a	O
notion	O
of	O
distance	O
(	O
element	O
-	O
wise	O
product	O
and	O
absolute	O
difference	O
)	O
during	O
training	O
.	O
	
paragraph	O
:	O
NLI	B-Task
as	O
a	O
supervised	O
training	O
set	O
	
Our	O
findings	O
indicate	O
that	O
our	O
model	O
trained	O
on	O
SNLI	B-Material
obtains	O
much	O
better	O
overall	O
results	O
than	O
models	O
trained	O
on	O
other	O
supervised	B-Task
tasks	I-Task
such	O
as	O
COCO	B-Material
,	O
dictionary	B-Task
definitions	I-Task
,	O
NMT	B-Method
,	O
PPDB	B-Method
and	O
SST	B-Task
.	O
	
For	O
SST	B-Task
,	O
we	O
tried	O
exactly	O
the	O
same	O
models	O
as	O
for	O
SNLI	B-Material
;	O
it	O
is	O
worth	O
noting	O
that	O
SST	B-Task
is	O
smaller	O
than	O
NLI	B-Task
.	O
	
Our	O
representations	O
constitute	O
higher	O
-	O
quality	B-Metric
features	I-Metric
for	O
both	O
classification	B-Task
and	I-Task
similarity	I-Task
tasks	I-Task
.	O
	
One	O
explanation	O
is	O
that	O
the	O
natural	B-Task
language	I-Task
inference	I-Task
task	O
constrains	O
the	O
model	O
to	O
encode	O
the	O
semantic	O
information	O
of	O
the	O
input	O
sentence	O
,	O
and	O
that	O
the	O
information	O
required	O
to	O
perform	O
NLI	B-Task
is	O
generally	O
discriminative	O
and	O
informative	O
.	O
	
paragraph	O
:	O
Domain	B-Task
adaptation	I-Task
on	O
SICK	B-Task
tasks	I-Task
	
Our	O
transfer	B-Method
learning	I-Method
approach	I-Method
obtains	O
better	O
results	O
than	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
on	O
the	O
SICK	B-Task
task	I-Task
-	O
can	O
be	O
seen	O
as	O
an	O
out	B-Method
-	I-Method
domain	I-Method
version	I-Method
of	O
SNLI	B-Material
-	O
for	O
both	O
entailment	B-Task
and	I-Task
relatedness	I-Task
.	O
	
We	O
obtain	O
a	O
pearson	B-Metric
score	I-Metric
of	O
0.885	O
on	O
SICK	B-Metric
-	I-Metric
R	I-Metric
while	O
obtained	O
0.868	O
,	O
and	O
we	O
obtain	O
86.3	O
%	O
test	B-Metric
accuracy	I-Metric
on	O
SICK	B-Metric
-	I-Metric
E	I-Metric
while	O
previous	O
best	O
hand	B-Method
-	I-Method
engineered	I-Method
models	I-Method
obtained	O
84.5	O
%	O
.	O
	
We	O
also	O
significantly	O
outperformed	O
previous	O
transfer	B-Method
learning	I-Method
approaches	I-Method
on	O
SICK	B-Metric
-	I-Metric
E	I-Metric
that	O
used	O
the	O
parameters	O
of	O
an	O
LSTM	B-Method
model	O
trained	O
on	O
SNLI	B-Material
to	O
fine	O
-	O
tune	O
on	O
SICK	O
(	O
80.8	O
%	O
accuracy	B-Metric
)	O
.	O
	
We	O
hypothesize	O
that	O
our	O
embeddings	O
already	O
contain	O
the	O
information	O
learned	O
from	O
the	O
in	B-Task
-	I-Task
domain	I-Task
task	I-Task
,	O
and	O
that	O
learning	O
only	O
the	O
classifier	B-Method
limits	O
the	O
number	O
of	O
parameters	O
learned	O
on	O
the	O
small	B-Task
out	I-Task
-	I-Task
domain	I-Task
task	I-Task
.	O
	
paragraph	O
:	O
Image	B-Task
-	I-Task
caption	I-Task
retrieval	I-Task
results	O
	
In	O
Table	O
[	O
reference	O
]	O
,	O
we	O
report	O
results	O
for	O
the	O
COCO	B-Task
image	I-Task
-	I-Task
caption	I-Task
retrieval	I-Task
task	I-Task
.	O
	
We	O
report	O
the	O
mean	B-Method
recalls	I-Metric
of	O
5	O
random	O
splits	O
of	O
1	O
K	O
test	O
images	O
.	O
	
When	O
trained	O
with	O
ResNet	O
features	O
and	O
30k	O
more	O
training	O
data	O
,	O
the	O
SkipThought	O
vectors	O
perform	O
significantly	O
better	O
than	O
the	O
original	O
setting	O
,	O
going	O
from	O
33.8	O
to	O
37.9	O
for	O
caption	B-Task
retrieval	I-Task
R@1	I-Task
,	O
and	O
from	O
25.9	O
to	O
30.6	O
on	O
image	B-Task
retrieval	I-Task
R@1	I-Task
.	O
	
Our	O
approach	O
pushes	O
the	O
results	O
even	O
further	O
,	O
from	O
37.9	O
to	O
42.4	O
on	O
caption	B-Task
retrieval	I-Task
,	O
and	O
30.6	O
to	O
33.2	O
on	O
image	B-Task
retrieval	I-Task
.	O
	
These	O
results	O
are	O
comparable	O
to	O
previous	O
approach	O
of	O
that	O
did	O
not	O
do	O
transfer	O
but	O
directly	O
learned	O
the	O
sentence	B-Method
encoding	I-Method
on	O
the	O
image	B-Task
-	I-Task
caption	I-Task
retrieval	I-Task
task	I-Task
.	O
	
This	O
supports	O
the	O
claim	O
that	O
pre	O
-	O
trained	B-Method
representations	I-Method
such	O
as	O
ResNet	O
image	O
features	O
and	O
our	O
sentence	B-Method
embeddings	I-Method
can	O
achieve	O
competitive	O
results	O
compared	O
to	O
features	O
learned	O
directly	O
on	O
the	O
objective	B-Task
task	I-Task
.	O
	
paragraph	O
:	O
MultiGenre	O
NLI	B-Task
	
The	O
MultiNLI	B-Material
corpus	O
was	O
recently	O
released	O
as	O
a	O
multi	O
-	O
genre	O
version	O
of	O
SNLI	B-Material
.	O
	
With	O
433	O
K	O
sentence	O
pairs	O
,	O
MultiNLI	B-Material
improves	O
upon	O
SNLI	B-Material
in	O
its	O
coverage	O
:	O
it	O
contains	O
ten	O
distinct	O
genres	O
of	O
written	O
and	O
spoken	O
English	O
,	O
covering	O
most	O
of	O
the	O
complexity	O
of	O
the	O
language	O
.	O
	
We	O
augment	O
Table	O
4	O
with	O
our	O
model	O
trained	O
on	O
both	O
SNLI	B-Material
and	O
MultiNLI	B-Material
(	O
AllNLI	B-Material
)	O
.	O
	
We	O
observe	O
a	O
significant	O
boost	O
in	O
performance	O
overall	O
compared	O
to	O
the	O
model	O
trained	O
only	O
on	O
SLNI	B-Material
.	O
	
Our	O
model	O
even	O
reaches	O
AdaSent	B-Method
performance	O
on	O
CR	B-Task
,	O
suggesting	O
that	O
having	O
a	O
larger	O
coverage	O
for	O
the	O
training	B-Task
task	I-Task
helps	O
learn	O
even	O
better	O
general	B-Method
representations	I-Method
.	O
	
On	O
semantic	B-Task
textual	I-Task
similarity	I-Task
STS14	O
,	O
we	O
are	O
also	O
competitive	O
with	O
PPDB	B-Method
based	I-Method
paragram	I-Method
-	I-Method
phrase	I-Method
embeddings	I-Method
with	O
a	O
pearson	B-Metric
score	I-Metric
of	O
0.70	O
.	O
	
Interestingly	O
,	O
on	O
caption	B-Task
-	I-Task
related	I-Task
transfer	I-Task
tasks	I-Task
such	O
as	O
the	O
COCO	B-Task
image	I-Task
caption	I-Task
retrieval	I-Task
task	I-Task
,	O
training	O
our	O
sentence	B-Method
encoder	I-Method
on	O
other	O
genres	O
from	O
MultiNLI	B-Material
does	O
not	O
degrade	O
the	O
performance	O
compared	O
to	O
the	O
model	O
trained	O
only	O
SNLI	B-Material
(	O
which	O
contains	O
mostly	O
captions	O
)	O
,	O
which	O
confirms	O
the	O
generalization	O
power	O
of	O
our	O
embeddings	O
.	O
	
section	O
:	O
Conclusion	O
	
This	O
paper	O
studies	O
the	O
effects	O
of	O
training	O
sentence	B-Task
embeddings	I-Task
with	O
supervised	O
data	O
by	O
testing	O
on	O
12	O
different	O
transfer	B-Task
tasks	I-Task
.	O
	
We	O
showed	O
that	O
models	O
learned	O
on	O
NLI	B-Task
can	O
perform	O
better	O
than	O
models	O
trained	O
in	O
unsupervised	O
conditions	O
or	O
on	O
other	O
supervised	B-Task
tasks	I-Task
.	O
	
By	O
exploring	O
various	O
architectures	O
,	O
we	O
showed	O
that	O
a	O
BiLSTM	B-Method
network	I-Method
with	O
max	B-Method
pooling	I-Method
makes	O
the	O
best	O
current	O
universal	B-Method
sentence	I-Method
encoding	I-Method
methods	I-Method
,	O
outperforming	O
existing	O
approaches	O
like	O
SkipThought	B-Method
vectors	I-Method
.	O
	
We	O
believe	O
that	O
this	O
work	O
only	O
scratches	O
the	O
surface	O
of	O
possible	O
combinations	O
of	O
models	O
and	O
tasks	O
for	O
learning	B-Task
generic	I-Task
sentence	I-Task
embeddings	I-Task
.	O
	
Larger	O
datasets	O
that	O
rely	O
on	O
natural	O
language	O
understanding	O
for	O
sentences	O
could	O
bring	O
sentence	B-Metric
embedding	I-Metric
quality	I-Metric
to	O
the	O
next	O
level	O
.	O
	
bibliography	O
:	O
References	O
	
section	O
:	O
Appendix	O
	
paragraph	O
:	O
Max	B-Method
-	I-Method
pooling	I-Method
visualization	I-Method
for	O
BiLSTM	B-Method
-	I-Method
max	I-Method
trained	O
and	O
untrained	O
	
Our	O
representations	O
were	O
trained	O
to	O
focus	O
on	O
parts	O
of	O
a	O
sentence	O
such	O
that	O
a	O
classifier	B-Method
can	O
easily	O
tell	O
the	O
difference	O
between	O
contradictory	O
,	O
neutral	O
or	O
entailed	O
sentences	O
.	O
	
In	O
Table	O
[	O
reference	O
]	O
and	O
Table	O
[	O
reference	O
]	O
	
,	O
we	O
investigate	O
how	O
the	O
max	B-Method
-	I-Method
pooling	I-Method
operation	I-Method
selects	O
the	O
information	O
from	O
the	O
hidden	O
states	O
of	O
the	O
BiLSTM	B-Method
,	O
for	O
our	O
trained	O
and	O
untrained	O
BiLSTM	B-Method
-	O
max	O
models	O
(	O
for	O
both	O
models	O
,	O
word	O
embeddings	O
are	O
initialized	O
with	O
GloVe	O
vectors	O
)	O
.	O
	
For	O
each	O
time	O
step	O
,	O
we	O
report	O
the	O
number	O
of	O
times	O
the	O
max	B-Method
-	I-Method
pooling	I-Method
operation	I-Method
selected	O
the	O
hidden	O
state	O
(	O
which	O
can	O
be	O
seen	O
as	O
a	O
sentence	B-Method
representation	I-Method
centered	O
around	O
word	O
)	O
.	O
	
Without	O
any	O
training	O
,	O
the	O
max	B-Method
-	I-Method
pooling	I-Method
is	O
rather	O
even	O
across	O
hidden	O
states	O
,	O
although	O
it	O
seems	O
to	O
focus	O
consistently	O
more	O
on	O
the	O
first	O
and	O
last	O
hidden	O
states	O
.	O
	
When	O
trained	O
,	O
the	O
model	O
learns	O
to	O
focus	O
on	O
specific	O
words	O
that	O
carry	O
most	O
of	O
the	O
meaning	O
of	O
the	O
sentence	O
without	O
any	O
explicit	O
attention	B-Method
mechanism	I-Method
.	O
	
Note	O
that	O
each	O
hidden	O
state	O
also	O
incorporates	O
information	O
from	O
the	O
sentence	O
at	O
different	O
levels	O
,	O
explaining	O
why	O
the	O
trained	O
model	O
also	O
incorporates	O
information	O
from	O
all	O
hidden	O
states	O
.	O
	
document	O
:	O
Classical	O
Structured	B-Method
Prediction	I-Method
Losses	I-Method
for	O
Sequence	B-Task
to	I-Task
Sequence	I-Task
Learning	I-Task
	
There	O
has	O
been	O
much	O
recent	O
work	O
on	O
training	O
neural	B-Method
attention	I-Method
models	I-Method
at	O
the	O
sequence	B-Task
-	I-Task
level	I-Task
using	O
either	O
reinforcement	B-Method
learning	I-Method
-	I-Method
style	I-Method
methods	I-Method
or	O
by	O
optimizing	O
the	O
beam	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
survey	O
a	O
range	O
of	O
classical	O
objective	B-Metric
functions	I-Metric
that	O
have	O
been	O
widely	O
used	O
to	O
train	O
linear	B-Method
models	I-Method
for	O
structured	B-Task
prediction	I-Task
and	O
apply	O
them	O
to	O
neural	B-Method
sequence	I-Method
to	I-Method
sequence	I-Method
models	I-Method
.	O
	
Our	O
experiments	O
show	O
that	O
these	O
losses	O
can	O
perform	O
surprisingly	O
well	O
by	O
slightly	O
outperforming	O
beam	B-Method
search	I-Method
optimization	I-Method
in	O
a	O
like	O
for	O
like	O
setup	O
.	O
	
We	O
also	O
report	O
new	O
state	O
of	O
the	O
art	O
results	O
on	O
both	O
IWSLT’14	B-Material
German	I-Material
-	I-Material
English	I-Material
translation	I-Material
as	O
well	O
as	O
Gigaword	B-Task
abstractive	I-Task
summarization	I-Task
.	O
	
On	O
the	O
large	O
WMT’14	B-Material
English	I-Material
-	I-Material
French	I-Material
task	I-Material
,	O
sequence	B-Method
-	I-Method
level	I-Method
training	I-Method
achieves	O
41.5	O
BLEU	B-Metric
which	O
is	O
on	O
par	O
with	O
the	O
state	O
of	O
the	O
art	O
.	O
	
section	O
:	O
Introduction	O
	
Sequence	B-Method
to	I-Method
sequence	I-Method
models	I-Method
are	O
usually	O
trained	O
with	O
a	O
simple	O
token	B-Method
-	I-Method
level	I-Method
likelihood	I-Method
loss	O
sutskever2014sequence	O
,	O
bahdanau2014neural	O
.	O
	
However	O
,	O
at	O
test	O
time	O
,	O
these	O
models	O
do	O
not	O
produce	O
a	O
single	O
token	O
but	O
a	O
whole	O
sequence	O
.	O
	
In	O
order	O
to	O
resolve	O
this	O
inconsistency	O
and	O
to	O
potentially	O
improve	O
generation	B-Task
,	O
recent	O
work	O
has	O
focused	O
on	O
training	O
these	O
models	O
at	O
the	O
sequence	O
-	O
level	O
,	O
for	O
instance	O
using	O
REINFORCE	B-Method
ranzato2015sequence	O
,	O
actor	B-Method
-	I-Method
critic	I-Method
bahdanau2016ac	O
,	O
or	O
with	O
beam	B-Method
search	I-Method
optimization	I-Method
wiseman2016acl	O
.	O
	
Before	O
the	O
recent	O
work	O
on	O
sequence	B-Task
level	I-Task
training	I-Task
for	O
neural	B-Method
networks	I-Method
,	O
there	O
has	O
been	O
a	O
large	O
body	O
of	O
research	O
on	O
training	O
linear	B-Method
models	I-Method
at	O
the	O
sequence	O
level	O
.	O
	
For	O
example	O
,	O
direct	B-Method
loss	I-Method
optimization	I-Method
has	O
been	O
popularized	O
in	O
machine	B-Task
translation	I-Task
with	O
the	O
Minimum	B-Method
Error	I-Method
Rate	I-Method
Training	I-Method
algorithm	I-Method
(	O
MERT	B-Method
;	O
Och	O
2003	O
)	O
and	O
expected	B-Method
risk	I-Method
minimization	I-Method
has	O
an	O
extensive	O
history	O
in	O
NLP	B-Task
.	O
	
This	O
paper	O
revisits	O
several	O
objective	B-Method
functions	I-Method
that	O
have	O
been	O
commonly	O
used	O
for	O
structured	B-Task
prediction	I-Task
tasks	I-Task
in	O
NLP	B-Task
gimpel	I-Task
+	O
smith2010acl	O
and	O
apply	O
them	O
to	O
a	O
neural	B-Method
sequence	I-Method
to	I-Method
sequence	I-Method
model	I-Method
gehring2017icml	O
(	O
§	O
[	O
reference	O
]	O
)	O
.	O
	
Specifically	O
,	O
we	O
consider	O
likelihood	B-Task
training	I-Task
at	O
the	O
sequence	O
-	O
level	O
,	O
a	O
margin	B-Method
loss	I-Method
as	O
well	O
as	O
expected	O
risk	B-Method
training	I-Method
.	O
	
We	O
also	O
investigate	O
several	O
combinations	O
of	O
global	O
losses	O
with	O
token	B-Method
-	I-Method
level	I-Method
likelihood	I-Method
.	O
	
This	O
is	O
,	O
to	O
our	O
knowledge	O
,	O
the	O
most	O
comprehensive	O
comparison	O
of	O
structured	O
losses	O
in	O
the	O
context	O
of	O
neural	B-Method
sequence	I-Method
to	I-Method
sequence	I-Method
models	I-Method
(	O
§	O
[	O
reference	O
]	O
)	O
.	O
	
We	O
experiment	O
on	O
the	O
IWSLT’14	B-Material
German	I-Material
-	I-Material
English	I-Material
translation	I-Material
task	I-Material
cettolo2014report	O
as	O
well	O
as	O
the	O
Gigaword	B-Task
abstractive	I-Task
summarization	I-Task
task	I-Task
rush2015abs	O
.	O
	
We	O
achieve	O
the	O
best	O
reported	O
accuracy	B-Metric
to	O
date	O
on	O
both	O
tasks	O
.	O
	
We	O
find	O
that	O
the	O
sequence	O
level	O
losses	O
we	O
survey	O
perform	O
similarly	O
to	O
one	O
another	O
and	O
outperform	O
beam	B-Method
search	I-Method
optimization	I-Method
wiseman2016acl	O
on	O
a	O
comparable	O
setup	O
.	O
	
On	O
WMT’14	B-Material
English	I-Material
-	I-Material
French	I-Material
,	O
we	O
also	O
illustrate	O
the	O
effectiveness	O
of	O
risk	B-Method
minimization	I-Method
on	O
a	O
larger	O
translation	B-Task
task	I-Task
.	O
	
Classical	O
losses	B-Method
for	O
structured	B-Task
prediction	I-Task
are	O
still	O
very	O
competitive	O
and	O
effective	O
for	O
neural	B-Method
models	I-Method
(	O
§	O
[	O
reference	O
]	O
,	O
§	O
[	O
reference	O
]	O
)	O
.	O
	
section	O
:	O
Sequence	B-Task
to	I-Task
Sequence	I-Task
Learning	I-Task
	
The	O
general	O
architecture	O
of	O
our	O
sequence	B-Method
to	I-Method
sequence	I-Method
models	I-Method
follows	O
the	O
encoder	B-Method
-	I-Method
decoder	I-Method
approach	I-Method
with	O
soft	O
attention	O
first	O
introduced	O
in	O
.	O
	
As	O
a	O
main	O
difference	O
,	O
in	O
most	O
of	O
our	O
experiments	O
we	O
parameterize	O
the	O
encoder	B-Method
and	O
the	O
decoder	B-Method
as	O
convolutional	B-Method
neural	I-Method
networks	I-Method
instead	O
of	O
recurrent	B-Method
networks	I-Method
gehring2016convolutional	I-Method
,	O
gehring2017icml	O
.	O
	
Our	O
use	O
of	O
convolution	B-Method
is	O
motivated	O
by	O
computational	B-Metric
and	I-Metric
accuracy	I-Metric
considerations	I-Metric
.	O
	
However	O
,	O
the	O
objective	O
functions	O
we	O
present	O
are	O
model	B-Method
agnostic	I-Method
and	O
equally	O
applicable	O
to	O
recurrent	B-Method
and	I-Method
convolutional	I-Method
models	I-Method
.	O
	
We	O
demonstrate	O
the	O
applicability	O
of	O
our	O
objective	B-Method
functions	I-Method
to	O
recurrent	B-Method
models	I-Method
(	O
LSTM	B-Method
)	O
in	O
our	O
comparison	O
to	O
wiseman2016acl	O
in	O
§	O
[	O
reference	O
]	O
.	O
	
Notation	O
.	O
	
We	O
denote	O
the	O
source	O
sentence	O
as	O
,	O
an	O
output	O
sentence	O
of	O
our	O
model	O
as	O
,	O
and	O
the	O
reference	O
or	O
target	O
sentence	O
as	O
.	O
	
For	O
some	O
objectives	O
,	O
we	O
choose	O
a	O
pseudo	O
reference	O
instead	O
,	O
such	O
as	O
a	O
model	O
output	O
with	O
the	O
highest	O
BLEU	B-Metric
or	O
ROUGE	B-Metric
score	O
among	O
a	O
set	O
of	O
candidate	O
outputs	O
,	O
,	O
generated	O
by	O
our	O
model	O
.	O
	
Concretely	O
,	O
the	O
encoder	B-Method
processes	O
a	O
source	O
sentence	O
containing	O
words	O
and	O
outputs	O
a	O
sequence	O
of	O
states	O
.	O
	
The	O
decoder	B-Method
takes	O
and	O
generates	O
the	O
output	O
sequence	O
left	O
to	O
right	O
,	O
one	O
element	O
at	O
a	O
time	O
.	O
	
For	O
each	O
output	O
,	O
the	O
decoder	O
computes	O
hidden	O
state	O
based	O
on	O
the	O
previous	O
state	O
,	O
an	O
embedding	O
of	O
the	O
previous	O
target	O
language	O
word	O
,	O
as	O
well	O
as	O
a	O
conditional	O
input	O
derived	O
from	O
the	O
encoder	O
output	O
.	O
	
The	O
attention	O
context	O
is	O
computed	O
as	O
a	O
weighted	O
sum	O
of	O
at	O
each	O
time	O
step	O
.	O
	
The	O
weights	O
of	O
this	O
sum	O
are	O
referred	O
to	O
as	O
attention	O
scores	O
and	O
allow	O
the	O
network	O
to	O
focus	O
on	O
the	O
most	O
relevant	O
parts	O
of	O
the	O
input	O
at	O
each	O
generation	O
step	O
.	O
	
Attention	O
scores	O
are	O
computed	O
by	O
comparing	O
each	O
encoder	O
state	O
to	O
a	O
combination	O
of	O
the	O
previous	O
decoder	O
state	O
and	O
the	O
last	O
prediction	O
;	O
the	O
result	O
is	O
normalized	O
to	O
be	O
a	O
distribution	O
over	O
input	O
elements	O
.	O
	
At	O
each	O
generation	O
step	O
,	O
the	O
model	O
scores	O
for	O
the	O
possible	O
next	O
target	O
words	O
by	O
transforming	O
the	O
decoder	O
output	O
via	O
a	O
linear	B-Method
layer	I-Method
with	O
weights	O
and	O
bias	O
:	O
.	O
	
This	O
is	O
turned	O
into	O
a	O
distribution	O
via	O
a	O
softmax	B-Method
:	O
.	O
	
Our	O
encoder	B-Method
and	I-Method
decoder	I-Method
use	O
gated	B-Method
convolutional	I-Method
neural	I-Method
networks	I-Method
which	O
enable	O
fast	O
and	O
accurate	O
generation	B-Task
.	O
	
Fast	B-Task
generation	I-Task
is	O
essential	O
to	O
efficiently	O
train	O
on	O
the	O
model	O
output	O
as	O
is	O
done	O
in	O
this	O
work	O
as	O
sequence	O
-	O
level	O
losses	O
require	O
generating	O
at	O
training	O
time	O
.	O
	
Both	O
encoder	B-Method
and	I-Method
decoder	I-Method
networks	I-Method
share	O
a	O
simple	O
block	B-Method
structure	I-Method
that	O
computes	O
intermediate	O
states	O
based	O
on	O
a	O
fixed	O
number	O
of	O
input	O
tokens	O
and	O
we	O
stack	O
several	O
blocks	O
on	O
top	O
of	O
each	O
other	O
.	O
	
Each	O
block	O
contains	O
a	O
1	B-Method
-	I-Method
D	I-Method
convolution	I-Method
that	O
takes	O
as	O
input	O
feature	O
vectors	O
and	O
outputs	O
another	O
vector	O
;	O
subsequent	O
layers	O
operate	O
over	O
the	O
output	O
elements	O
of	O
the	O
previous	O
layer	O
.	O
	
The	O
output	O
of	O
the	O
convolution	B-Method
is	O
then	O
fed	O
into	O
a	O
gated	B-Method
linear	I-Method
unit	I-Method
dauphin2017icml	O
.	O
	
In	O
the	O
decoder	B-Method
network	I-Method
,	O
we	O
rely	O
on	O
causal	B-Method
convolution	I-Method
which	O
rely	O
only	O
on	O
states	O
from	O
the	O
previous	O
time	O
steps	O
.	O
	
The	O
parameters	O
of	O
our	O
model	O
are	O
all	O
the	O
weight	O
matrices	O
in	O
the	O
encoder	B-Method
and	I-Method
decoder	I-Method
networks	I-Method
.	O
	
Further	O
details	O
can	O
be	O
found	O
in	O
gehring2017icml	O
.	O
	
section	O
:	O
Objective	B-Metric
Functions	I-Metric
	
We	O
compare	O
several	O
objective	B-Metric
functions	I-Metric
for	O
training	O
the	O
model	B-Method
architecture	I-Method
described	O
in	O
§	O
[	O
reference	O
]	O
.	O
	
The	O
corresponding	O
loss	O
functions	O
are	O
either	O
computed	O
over	O
individual	O
tokens	O
(	O
§	O
[	O
reference	O
]	O
)	O
,	O
over	O
entire	O
sequences	O
(	O
§	O
[	O
reference	O
]	O
)	O
or	O
over	O
a	O
combination	O
of	O
tokens	O
and	O
sequences	O
(	O
§	O
[	O
reference	O
]	O
)	O
.	O
	
An	O
overview	O
of	O
these	O
loss	B-Method
functions	I-Method
is	O
given	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
subsection	O
:	O
Token	B-Metric
-	I-Metric
Level	I-Metric
Objectives	I-Metric
	
Most	O
prior	O
work	O
on	O
sequence	B-Task
to	I-Task
sequence	I-Task
learning	I-Task
has	O
focused	O
on	O
optimizing	O
token	O
-	O
level	O
loss	O
functions	O
,	O
i.e.	O
,	O
functions	O
for	O
which	O
the	O
loss	O
is	O
computed	O
additively	O
over	O
individual	O
tokens	O
.	O
	
subsubsection	O
:	O
Token	B-Method
Negative	I-Method
Log	I-Method
Likelihood	I-Method
(	O
TokNLL	B-Method
)	O
	
Token	O
-	O
level	O
likelihood	O
(	O
TokNLL	O
,	O
Equation	O
[	O
reference	O
]	O
)	O
minimizes	O
the	O
negative	O
log	O
likelihood	O
of	O
individual	O
reference	O
tokens	O
.	O
	
It	O
is	O
the	O
most	O
common	O
loss	B-Method
function	I-Method
optimized	O
in	O
related	O
work	O
and	O
serves	O
as	O
a	O
baseline	O
for	O
our	O
comparison	O
.	O
	
subsubsection	O
:	O
Token	B-Method
NLL	I-Method
with	O
Label	B-Method
Smoothing	I-Method
(	O
TokLS	B-Method
)	O
	
Likelihood	B-Method
training	I-Method
forces	O
the	O
model	O
to	O
make	O
extreme	O
zero	O
or	O
one	O
predictions	O
to	O
distinguish	O
between	O
the	O
ground	O
truth	O
and	O
alternatives	O
.	O
	
This	O
may	O
result	O
in	O
a	O
model	O
that	O
is	O
too	O
confident	O
in	O
its	O
training	O
predictions	O
,	O
which	O
may	O
hurt	O
its	O
generalization	B-Task
performance	O
.	O
	
Label	B-Task
smoothing	I-Task
addresses	O
this	O
by	O
acting	O
as	O
a	O
regularizer	B-Method
that	O
makes	O
the	O
model	O
less	O
confident	O
in	O
its	O
predictions	O
.	O
	
Specifically	O
,	O
we	O
smooth	O
the	O
target	O
distribution	O
with	O
a	O
prior	O
distribution	O
that	O
is	O
independent	O
of	O
the	O
current	O
input	O
szegedy2015inception	O
,	O
pereyra2017regularize	O
,	O
vaswani2017transformer	O
.	O
	
We	O
use	O
a	O
uniform	O
prior	O
distribution	O
over	O
all	O
words	O
in	O
the	O
vocabulary	O
,	O
.	O
	
One	O
may	O
also	O
use	O
a	O
unigram	B-Method
distribution	I-Method
which	O
has	O
been	O
shown	O
to	O
work	O
better	O
on	O
some	O
tasks	O
pereyra2017regularize	O
.	O
	
Label	B-Task
smoothing	I-Task
is	O
equivalent	O
to	O
adding	O
the	O
KL	O
divergence	O
between	O
and	O
the	O
model	B-Method
prediction	I-Method
to	O
the	O
negative	O
log	O
likelihood	O
(	O
TokLS	O
,	O
Equation	O
[	O
reference	O
]	O
)	O
.	O
	
In	O
practice	O
,	O
we	O
implement	O
label	B-Method
smoothing	I-Method
by	O
modifying	O
the	O
ground	O
truth	O
distribution	O
for	O
word	O
to	O
be	O
and	O
for	O
instead	O
of	O
and	O
where	O
is	O
a	O
smoothing	O
parameter	O
.	O
	
subsection	O
:	O
Sequence	O
-	O
Level	O
Objectives	O
	
We	O
also	O
consider	O
a	O
class	O
of	O
objective	O
functions	O
that	O
are	O
computed	O
over	O
entire	O
sequences	O
,	O
i.e.	O
,	O
sequence	O
-	O
level	O
objectives	O
.	O
	
Training	O
with	O
these	O
objectives	O
requires	O
generating	O
and	O
scoring	O
multiple	O
candidate	O
output	O
sequences	O
for	O
each	O
input	O
sequence	O
during	O
training	O
,	O
which	O
is	O
computationally	O
expensive	O
but	O
allows	O
us	O
to	O
directly	O
optimize	O
task	B-Metric
-	I-Metric
specific	I-Metric
metrics	I-Metric
such	O
as	O
BLEU	B-Metric
or	O
ROUGE	B-Metric
.	O
	
Unfortunately	O
,	O
these	O
objectives	O
are	O
also	O
typically	O
defined	O
over	O
the	O
entire	O
space	O
of	O
possible	O
output	O
sequences	O
,	O
which	O
is	O
intractable	O
to	O
enumerate	O
or	O
score	O
with	O
our	O
models	O
.	O
	
Instead	O
,	O
we	O
compute	O
our	O
sequence	O
losses	O
over	O
a	O
subset	O
of	O
the	O
output	O
space	O
,	O
,	O
generated	O
by	O
the	O
model	O
.	O
	
We	O
discuss	O
approaches	O
for	O
generating	O
this	O
subset	O
in	O
§	O
[	O
reference	O
]	O
.	O
	
subsubsection	O
:	O
Sequence	B-Method
Negative	I-Method
Log	I-Method
Likelihood	I-Method
(	O
SeqNLL	B-Method
)	O
	
Similar	O
to	O
TokNLL	B-Method
,	O
we	O
can	O
minimize	O
the	O
negative	O
log	O
likelihood	O
of	O
an	O
entire	O
sequence	O
rather	O
than	O
individual	O
tokens	O
(	O
SeqNLL	O
,	O
Equation	O
[	O
reference	O
]	O
)	O
.	O
	
The	O
log	O
-	O
likelihood	O
of	O
sequence	O
is	O
the	O
sum	O
of	O
individual	O
token	O
log	O
probabilities	O
,	O
normalized	O
by	O
the	O
number	O
of	O
tokens	O
to	O
avoid	O
bias	O
towards	O
shorter	O
sequences	O
:	O
As	O
target	O
we	O
choose	O
a	O
pseudo	O
reference	O
amongst	O
the	O
candidates	O
which	O
maximizes	O
either	O
BLEU	B-Metric
or	O
ROUGE	B-Metric
with	O
respect	O
to	O
,	O
the	O
gold	O
reference	O
:	O
As	O
is	O
common	O
practice	O
when	O
computing	O
BLEU	B-Metric
at	O
the	O
sentence	O
-	O
level	O
,	O
we	O
smooth	O
all	O
initial	O
counts	O
to	O
one	O
(	O
except	O
for	O
unigram	O
counts	O
)	O
so	O
that	O
the	O
geometric	O
mean	O
is	O
not	O
dominated	O
by	O
zero	O
-	O
valued	O
-	O
gram	O
match	O
counts	O
lin2004orange	O
.	O
	
subsubsection	O
:	O
Expected	B-Method
Risk	I-Method
Minimization	I-Method
(	O
Risk	B-Method
)	O
	
This	O
objective	O
minimizes	O
the	O
expected	O
value	O
of	O
a	O
given	O
cost	B-Metric
function	I-Metric
over	O
the	O
space	O
of	O
candidate	O
sequences	O
(	O
Risk	B-Method
,	O
Equation	O
[	O
reference	O
]	O
)	O
.	O
	
In	O
this	O
work	O
we	O
use	O
task	B-Method
-	I-Method
specific	I-Method
cost	I-Method
functions	I-Method
designed	O
to	O
maximize	O
BLEU	B-Metric
or	O
ROUGE	B-Metric
lin2004rouge	O
,	O
e.g.	O
,	O
,	O
for	O
a	O
given	O
a	O
candidate	O
sequence	O
and	O
target	O
.	O
	
Different	O
to	O
SeqNLL	B-Method
(	O
§	O
[	O
reference	O
]	O
)	O
,	O
this	O
loss	O
may	O
increase	O
the	O
score	O
of	O
several	O
candidates	O
that	O
have	O
low	O
cost	O
,	O
instead	O
of	O
focusing	O
on	O
a	O
single	O
sequence	O
which	O
may	O
only	O
be	O
marginally	O
better	O
than	O
any	O
alternatives	O
.	O
	
Optimizing	O
this	O
loss	O
is	O
a	O
particularly	O
good	O
strategy	O
if	O
the	O
reference	O
is	O
not	O
always	O
reachable	O
,	O
although	O
compared	O
to	O
classical	O
phrase	B-Method
-	I-Method
based	I-Method
models	I-Method
,	O
this	O
is	O
less	O
of	O
an	O
issue	O
with	O
neural	B-Method
sequence	I-Method
to	I-Method
sequence	I-Method
models	I-Method
that	O
predict	O
individual	O
words	O
or	O
even	O
sub	O
-	O
word	O
units	O
.	O
	
The	O
Risk	B-Method
objective	O
is	O
similar	O
to	O
the	O
REINFORCE	B-Method
objective	O
used	O
in	O
Ranzato	O
et	O
al	O
.	O
	
ranzato2015sequence	O
,	O
since	O
both	O
objectives	O
optimize	O
an	O
expected	B-Metric
cost	I-Metric
or	O
reward	O
williams1992reinforce	O
.	O
	
However	O
,	O
there	O
are	O
a	O
few	O
important	O
differences	O
:	O
(	O
1	O
)	O
whereas	O
REINFORCE	B-Method
typically	O
approximates	O
the	O
expectation	O
with	O
a	O
single	O
sampled	O
sequence	O
,	O
the	O
Risk	B-Method
objective	O
considers	O
multiple	O
sequences	O
;	O
(	O
2	O
)	O
whereas	O
REINFORCE	B-Method
relies	O
on	O
a	O
baseline	O
rewardRanzato	O
et	O
al	O
.	O
estimate	O
the	O
baseline	O
reward	O
for	O
REINFORCE	B-Method
with	O
a	O
separate	O
linear	B-Method
regressor	I-Method
over	O
the	O
model	O
’s	O
current	O
hidden	O
state	O
.	O
	
to	O
determine	O
the	O
sign	O
of	O
the	O
gradients	O
for	O
the	O
current	O
sequence	O
,	O
for	O
the	O
Risk	B-Method
objective	O
we	O
instead	O
estimate	O
the	O
expected	B-Metric
cost	I-Metric
over	O
a	O
set	O
of	O
candidate	O
output	O
sequences	O
(	O
see	O
§	O
[	O
reference	O
]	O
)	O
;	O
and	O
(	O
3	O
)	O
while	O
the	O
baseline	O
reward	O
is	O
different	O
for	O
every	O
word	O
in	O
REINFORCE	B-Method
,	O
the	O
expected	B-Metric
cost	I-Metric
is	O
the	O
same	O
for	O
every	O
word	O
in	O
risk	B-Task
minimization	I-Task
since	O
it	O
is	O
computed	O
on	O
the	O
sequence	O
level	O
based	O
on	O
the	O
actual	O
cost	O
.	O
	
subsubsection	O
:	O
Max	B-Method
-	I-Method
Margin	I-Method
	
MaxMargin	B-Method
(	O
Equation	O
[	O
reference	O
]	O
)	O
is	O
a	O
classical	O
margin	B-Method
loss	I-Method
for	O
structured	B-Task
prediction	I-Task
mmmn	I-Task
,	O
structure_pred	B-Method
which	O
enforces	O
a	O
margin	O
between	O
the	O
model	O
scores	O
of	O
the	O
highest	O
scoring	O
candidate	O
sequence	O
and	O
a	O
reference	O
sequence	O
.	O
	
We	O
replace	O
the	O
human	O
reference	O
with	O
a	O
pseudo	O
-	O
reference	O
since	O
this	O
setting	O
performed	O
slightly	O
better	O
in	O
early	O
experiments	O
;	O
is	O
the	O
candidate	O
sequence	O
with	O
the	O
highest	O
BLEU	B-Metric
score	O
.	O
	
The	O
size	O
of	O
the	O
margin	O
varies	O
between	O
samples	O
and	O
is	O
given	O
by	O
the	O
difference	O
between	O
the	O
cost	O
of	O
and	O
the	O
cost	O
of	O
.	O
	
In	O
practice	O
,	O
we	O
scale	O
the	O
margin	O
by	O
a	O
hyper	O
-	O
parameter	O
determined	O
on	O
the	O
validation	O
set	O
:	O
.	O
	
For	O
this	O
loss	O
we	O
use	O
the	O
unnormalized	O
scores	O
computed	O
by	O
the	O
model	O
before	O
the	O
final	O
softmax	B-Method
:	O
	
subsubsection	O
:	O
Multi	O
-	O
Margin	O
	
MaxMargin	B-Method
only	O
updates	O
two	O
elements	O
in	O
the	O
candidate	O
set	O
.	O
	
We	O
therefore	O
consider	O
MultiMargin	B-Method
(	O
Equation	O
[	O
reference	O
]	O
)	O
which	O
enforces	O
a	O
margin	O
between	O
every	O
candidate	O
sequence	O
and	O
a	O
reference	O
sequence	O
herbrich199icann	O
,	O
hence	O
the	O
name	O
Multi	O
-	O
Margin	O
.	O
	
Similar	O
to	O
MaxMargin	B-Method
,	O
we	O
replace	O
the	O
reference	O
with	O
the	O
pseudo	O
-	O
reference	O
.	O
	
subsubsection	O
:	O
Softmax	B-Method
-	I-Method
Margin	I-Method
	
Finally	O
,	O
SoftmaxMargin	B-Method
(	O
Equation	O
[	O
reference	O
]	O
)	O
is	O
another	O
classic	O
loss	O
that	O
has	O
been	O
proposed	O
by	O
gimpel	O
+	O
smith2010acl	O
as	O
another	O
way	O
to	O
optimize	O
task	B-Task
-	I-Task
specific	I-Task
costs	I-Task
.	O
	
The	O
loss	O
augments	O
the	O
scores	O
inside	O
the	O
of	O
SeqNLL	B-Method
	
(	O
Equation	O
[	O
reference	O
]	O
)	O
by	O
a	O
cost	O
.	O
	
The	O
intuition	O
is	O
that	O
we	O
want	O
to	O
penalize	O
high	O
cost	O
outputs	O
proportional	O
to	O
their	O
cost	O
.	O
	
subsection	O
:	O
Combined	O
Objectives	O
	
We	O
also	O
experiment	O
with	O
two	O
variants	O
of	O
combining	O
sequence	O
-	O
level	O
objectives	O
(	O
§	O
[	O
reference	O
]	O
)	O
with	O
token	O
-	O
level	O
objectives	O
(	O
§	O
[	O
reference	O
]	O
)	O
.	O
	
First	O
,	O
we	O
consider	O
a	O
weighted	B-Method
combination	I-Method
(	O
Weighted	O
)	O
of	O
both	O
a	O
sequence	O
-	O
level	O
and	O
token	B-Metric
-	I-Metric
level	I-Metric
objective	I-Metric
	
wu2016google	O
,	O
e.g.	O
,	O
for	O
TokLS	B-Task
and	O
Risk	B-Method
	
we	O
have	O
:	O
where	O
is	O
a	O
scaling	O
constant	O
that	O
is	O
tuned	O
on	O
a	O
held	O
-	O
out	O
validation	O
set	O
.	O
	
Second	O
,	O
we	O
consider	O
a	O
constrained	B-Method
combination	I-Method
(	O
Constrained	O
)	O
,	O
where	O
for	O
any	O
given	O
input	O
we	O
use	O
either	O
the	O
token	O
-	O
level	O
or	O
sequence	O
-	O
level	O
loss	O
,	O
but	O
not	O
both	O
.	O
	
The	O
motivation	O
is	O
to	O
maintain	O
good	O
token	B-Metric
-	I-Metric
level	I-Metric
accuracy	I-Metric
while	O
optimizing	O
on	O
the	O
sequence	B-Metric
-	I-Metric
level	I-Metric
.	O
	
In	O
particular	O
,	O
a	O
sample	O
is	O
processed	O
with	O
the	O
sequence	O
loss	O
if	O
the	O
token	B-Metric
loss	I-Metric
under	O
the	O
current	O
model	O
is	O
at	O
least	O
as	O
good	O
as	O
the	O
token	O
loss	O
of	O
a	O
baseline	B-Method
model	I-Method
.	O
	
Otherwise	O
,	O
we	O
update	O
according	O
to	O
the	O
token	O
loss	O
:	O
In	O
this	O
work	O
we	O
use	O
a	O
fixed	B-Method
baseline	I-Method
model	I-Method
that	O
was	O
trained	O
with	O
a	O
token	O
-	O
level	O
loss	O
to	O
convergence	O
.	O
	
section	O
:	O
Candidate	B-Method
Generation	I-Method
Strategies	I-Method
	
The	O
sequence	O
-	O
level	O
objectives	O
we	O
consider	O
(	O
§	O
[	O
reference	O
]	O
)	O
are	O
defined	O
over	O
the	O
entire	O
space	O
of	O
possible	O
output	O
sequences	O
,	O
which	O
is	O
intractable	O
to	O
enumerate	O
or	O
score	O
with	O
our	O
models	O
.	O
	
We	O
therefore	O
use	O
a	O
subset	O
of	O
candidate	O
sequences	O
,	O
which	O
we	O
generate	O
with	O
our	O
models	O
.	O
	
We	O
consider	O
two	O
search	B-Method
strategies	I-Method
for	O
generating	O
the	O
set	O
of	O
candidate	O
sequences	O
.	O
	
The	O
first	O
is	O
beam	B-Method
search	I-Method
,	O
a	O
greedy	B-Method
breadth	I-Method
-	I-Method
first	I-Method
search	I-Method
that	O
maintains	O
a	O
“	O
beam	O
”	O
of	O
the	O
top	O
-	O
scoring	O
candidates	O
at	O
each	O
generation	O
step	O
.	O
	
Beam	B-Method
search	I-Method
is	O
the	O
de	O
facto	B-Method
decoding	I-Method
strategy	I-Method
for	O
achieving	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
in	O
machine	B-Task
translation	I-Task
.	O
	
The	O
second	O
strategy	O
is	O
sampling	O
chatterjee	B-Method
,	O
which	O
produces	O
independent	O
output	O
sequences	O
by	O
sampling	O
from	O
the	O
model	B-Method
’s	I-Method
conditional	I-Method
distribution	I-Method
.	O
	
Whereas	O
beam	B-Method
search	I-Method
focuses	O
on	O
high	O
probability	O
candidates	O
,	O
sampling	O
introduces	O
more	O
diverse	O
candidates	O
(	O
see	O
comparison	O
in	O
§	O
[	O
reference	O
]	O
)	O
.	O
	
We	O
also	O
consider	O
both	O
online	B-Task
and	I-Task
offline	I-Task
candidate	I-Task
generation	I-Task
settings	I-Task
in	O
§	O
[	O
reference	O
]	O
.	O
	
In	O
the	O
online	B-Task
setting	I-Task
,	O
we	O
regenerate	O
the	O
candidate	O
set	O
every	O
time	O
we	O
encounter	O
an	O
input	O
sentence	O
during	O
training	O
.	O
	
In	O
the	O
offline	B-Task
setting	I-Task
,	O
candidates	O
are	O
generated	O
before	O
training	O
and	O
are	O
never	O
regenerated	O
.	O
	
Offline	B-Task
generation	I-Task
is	O
also	O
embarrassingly	O
parallel	O
because	O
all	O
samples	O
use	O
the	O
same	O
model	O
.	O
	
The	O
disadvantage	O
is	O
that	O
the	O
candidates	O
become	O
stale	O
.	O
	
Our	O
model	O
may	O
perfectly	O
be	O
able	O
to	O
discriminate	O
between	O
them	O
after	O
only	O
a	O
single	O
update	O
,	O
hindering	O
the	O
ability	O
of	O
the	O
loss	O
to	O
correct	O
eventual	O
search	O
errors	O
.	O
	
Finally	O
,	O
while	O
some	O
past	O
work	O
has	O
added	O
the	O
reference	O
target	O
to	O
the	O
candidate	O
set	O
,	O
i.e.	O
,	O
,	O
we	O
find	O
this	O
can	O
destabilize	O
training	O
since	O
the	O
model	O
learns	O
to	O
assign	O
low	O
probabilities	O
nearly	O
everywhere	O
,	O
ruining	O
the	O
candidates	O
generated	O
by	O
the	O
model	O
,	O
while	O
still	O
assigning	O
a	O
slightly	O
higher	O
score	O
to	O
the	O
reference	O
(	O
cf	O
.	O
shen2016mrt	O
)	O
.	O
	
Accordingly	O
we	O
do	O
not	O
add	O
the	O
reference	O
translation	O
to	O
our	O
candidate	O
sets	O
.	O
	
section	O
:	O
Experimental	O
Setup	O
	
subsection	O
:	O
Translation	B-Task
	
We	O
experiment	O
on	O
the	O
IWSLT’14	B-Material
German	I-Material
to	I-Material
English	I-Material
cettolo2014report	O
task	O
using	O
a	O
similar	O
setup	O
as	O
Ranzato	O
et	O
al	O
.	O
	
ranzato2015sequence	O
,	O
which	O
allows	O
us	O
to	O
compare	O
to	O
other	O
recent	O
studies	O
that	O
also	O
adopted	O
this	O
setup	O
,	O
e.g.	O
,	O
wiseman2016acl	O
.	O
	
The	O
training	O
data	O
consists	O
of	O
160	O
K	O
sentence	O
pairs	O
and	O
the	O
validation	O
set	O
comprises	O
7	O
K	O
sentences	O
randomly	O
sampled	O
and	O
held	O
-	O
out	O
from	O
the	O
train	O
data	O
.	O
	
We	O
test	O
on	O
the	O
concatenation	O
of	O
all	O
available	O
test	O
and	O
dev	O
sets	O
of	O
IWSLT	B-Material
2014	I-Material
,	O
that	O
is	O
TED.tst2010	B-Material
,	O
TED.tst2011	B-Material
,	O
TED.tst2012	B-Material
and	O
TED.dev2010	B-Material
,	O
	
TEDX.dev2012	B-Material
which	O
is	O
of	O
similar	O
size	O
to	O
the	O
validation	O
set	O
.	O
	
All	O
data	O
is	O
lowercased	O
and	O
tokenized	O
with	O
a	O
byte	B-Method
-	I-Method
pair	I-Method
encoding	I-Method
(	O
BPE	B-Method
)	O
of	O
14	O
,	O
000	O
types	O
sennrich2016bpe	O
and	O
we	O
evaluate	O
with	O
case	O
-	O
insensitive	O
BLEU	B-Metric
.	O
	
We	O
also	O
experiment	O
on	O
the	O
much	O
larger	O
WMT’14	B-Material
English	I-Material
-	I-Material
French	I-Material
task	I-Material
.	O
	
We	O
remove	O
sentences	O
longer	O
than	O
175	O
words	O
as	O
well	O
as	O
pairs	O
with	O
a	O
source	O
/	O
target	O
length	O
ratio	O
exceeding	O
1.5	O
resulting	O
in	O
35.5	O
M	O
sentence	O
-	O
pairs	O
for	O
training	O
.	O
	
The	O
source	O
and	O
target	O
vocabulary	O
is	O
based	O
on	O
40	O
K	O
BPE	O
types	O
.	O
	
Results	O
are	O
reported	O
on	O
both	O
newstest2014	O
and	O
a	O
validation	O
set	O
held	O
-	O
out	O
from	O
the	O
training	O
data	O
comprising	O
26	O
,	O
658	O
sentence	O
pairs	O
.	O
	
We	O
modify	O
the	O
fairseq	B-Method
-	I-Method
py	I-Method
toolkit	I-Method
to	O
implement	O
the	O
objectives	O
described	O
in	O
§	O
[	O
reference	O
]	O
.	O
	
Our	O
translation	B-Method
models	I-Method
have	O
four	O
convolutional	B-Method
encoder	I-Method
layers	I-Method
and	O
three	O
convolutional	B-Method
decoder	I-Method
layers	I-Method
with	O
a	O
kernel	O
width	O
of	O
3	O
and	O
256	O
dimensional	O
hidden	O
states	O
and	O
word	O
embeddings	O
.	O
	
We	O
optimize	O
these	O
models	O
using	O
Nesterov	O
’s	O
accelerated	O
gradient	O
method	O
sutskever2013icml	O
with	O
a	O
learning	B-Metric
rate	I-Metric
of	O
0.25	O
and	O
momentum	O
of	O
0.99	O
.	O
	
Gradient	O
vectors	O
are	O
renormalized	O
to	O
norm	O
0.1	O
pascanu2013difficulty	O
.	O
	
We	O
train	O
our	O
baseline	O
token	B-Method
-	I-Method
level	I-Method
models	I-Method
for	O
200	O
epochs	O
and	O
then	O
anneal	O
the	O
learning	O
by	O
shrinking	O
it	O
by	O
a	O
factor	O
of	O
10	O
after	O
each	O
subsequent	O
epoch	O
until	O
the	O
learning	B-Metric
rate	I-Metric
falls	O
below	O
.	O
	
All	O
sequence	B-Method
-	I-Method
level	I-Method
models	I-Method
are	O
initialized	O
with	O
parameters	O
of	O
a	O
token	B-Method
-	I-Method
level	I-Method
model	I-Method
before	O
annealing	B-Method
.	O
	
We	O
then	O
train	O
sequence	B-Method
-	I-Method
level	I-Method
models	I-Method
for	O
another	O
10	O
to	O
20	O
epochs	O
depending	O
on	O
the	O
objective	O
.	O
	
Our	O
batches	O
contain	O
8	O
K	O
tokens	O
and	O
we	O
normalize	O
gradients	O
by	O
the	O
number	O
of	O
non	O
-	O
padding	O
tokens	O
per	O
mini	O
-	O
batch	O
.	O
	
We	O
use	O
weight	B-Method
normalization	I-Method
for	O
all	O
layers	O
except	O
for	O
lookup	O
tables	O
salimans2016weight	O
.	O
	
Besides	O
dropout	O
on	O
the	O
embeddings	O
and	O
the	O
decoder	O
output	O
,	O
we	O
also	O
apply	O
dropout	B-Method
to	O
the	O
input	O
of	O
the	O
convolutional	O
blocks	O
at	O
a	O
rate	O
of	O
0.3	O
srivastava2014dropout	O
.	O
	
We	O
tuned	O
the	O
various	O
parameters	O
above	O
and	O
report	O
accuracy	B-Metric
on	O
the	O
test	O
set	O
by	O
choosing	O
the	O
best	O
configuration	O
based	O
on	O
the	O
validation	O
set	O
.	O
	
We	O
length	O
normalize	O
all	O
scores	O
and	O
probabilities	O
in	O
the	O
sequence	O
-	O
level	O
losses	O
by	O
dividing	O
by	O
the	O
number	O
of	O
tokens	O
in	O
the	O
sequence	O
so	O
that	O
scores	O
are	O
comparable	O
between	O
different	O
lengths	O
.	O
	
Additionally	O
,	O
when	O
generating	O
candidate	O
output	O
sequences	O
during	O
training	O
we	O
limit	O
the	O
output	O
sequence	O
length	O
to	O
be	O
less	O
than	O
200	O
tokens	O
for	O
efficiency	O
.	O
	
We	O
generally	O
use	O
16	O
candidate	O
sequences	O
per	O
training	O
example	O
,	O
except	O
for	O
the	O
ablations	B-Task
where	O
we	O
use	O
5	O
for	O
faster	O
experimental	O
turnaround	O
.	O
	
subsection	O
:	O
Abstractive	B-Task
Summarization	I-Task
	
For	O
summarization	B-Task
we	O
use	O
the	O
Gigaword	B-Material
corpus	I-Material
as	O
training	O
data	O
and	O
pre	O
-	O
process	O
it	O
identically	O
to	O
rush2015abs	O
resulting	O
in	O
3.8	O
M	O
training	O
and	O
190	O
K	O
validation	O
examples	O
.	O
	
We	O
evaluate	O
on	O
a	O
Gigaword	B-Material
test	I-Material
set	I-Material
of	O
2	O
,	O
000	O
pairs	O
identical	O
to	O
the	O
one	O
used	O
by	O
rush2015abs	O
and	O
report	O
F1	O
ROUGE	B-Metric
similar	O
to	O
prior	O
work	O
.	O
	
Our	O
results	O
are	O
in	O
terms	O
of	O
three	O
variants	O
of	O
ROUGE	B-Metric
,	O
namely	O
,	O
ROUGE	B-Metric
-	I-Metric
1	I-Metric
(	O
RG	B-Metric
-	I-Metric
1	I-Metric
,	O
unigrams	B-Metric
)	O
,	O
ROUGE	B-Metric
-	I-Metric
2	I-Metric
(	O
RG	B-Metric
-	I-Metric
2	I-Metric
,	O
bigrams	B-Metric
)	O
,	O
and	O
ROUGE	B-Metric
-	I-Metric
L	I-Metric
(	O
RG	B-Metric
-	I-Metric
L	I-Metric
,	O
longest	B-Metric
-	I-Metric
common	I-Metric
substring	I-Metric
)	O
.	O
	
Similar	O
to	O
ayana2016neural	O
we	O
use	O
a	O
source	O
and	O
target	O
vocabulary	O
of	O
30k	O
words	O
.	O
	
Our	O
models	O
for	O
this	O
task	O
have	O
12	O
layers	O
in	O
the	O
encoder	B-Method
and	I-Method
decoder	I-Method
each	O
with	O
256	O
hidden	O
units	O
and	O
kernel	O
width	O
3	O
.	O
	
We	O
train	O
on	O
batches	O
of	O
8	O
,	O
000	O
tokens	O
with	O
a	O
learning	B-Metric
rate	I-Metric
of	O
0.25	O
for	O
20	O
epochs	O
and	O
then	O
anneal	O
as	O
in	O
§	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
Results	O
	
subsection	O
:	O
Comparison	O
of	O
Sequence	B-Metric
Level	I-Metric
Losses	I-Metric
	
First	O
,	O
we	O
compare	O
all	O
objectives	O
based	O
on	O
a	O
weighted	B-Method
combination	I-Method
with	O
token	B-Method
-	I-Method
level	I-Method
label	I-Method
smoothing	I-Method
(	O
Equation	O
[	O
reference	O
]	O
)	O
.	O
	
We	O
also	O
show	O
the	O
likelihood	B-Method
baseline	I-Method
(	O
MLE	B-Method
)	O
of	O
wiseman2016acl	O
,	O
their	O
beam	B-Method
search	I-Method
optimization	I-Method
method	O
(	O
BSO	B-Method
)	O
,	O
the	O
actor	B-Method
critic	I-Method
result	O
of	O
bahdanau2016ac	O
as	O
well	O
as	O
the	O
best	O
reported	O
result	O
on	O
this	O
dataset	O
to	O
date	O
by	O
huang2017npbmt	O
.	O
	
We	O
show	O
a	O
like	O
-	O
for	O
-	O
like	O
comparison	O
to	O
wiseman2016acl	O
with	O
a	O
similar	O
baseline	O
model	O
below	O
(	O
§	O
[	O
reference	O
]	O
)	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
that	O
all	O
sequence	O
-	O
level	O
losses	O
outperform	O
token	O
-	O
level	O
losses	O
.	O
	
Our	O
baseline	O
token	O
-	O
level	O
results	O
are	O
several	O
points	O
above	O
other	O
figures	O
in	O
the	O
literature	O
and	O
we	O
further	O
improve	O
these	O
results	O
by	O
up	O
to	O
0.61	O
BLEU	B-Metric
with	O
Risk	B-Method
training	O
.	O
	
subsection	O
:	O
Combination	O
with	O
Token	B-Method
-	I-Method
Level	I-Method
Loss	I-Method
	
Next	O
,	O
we	O
compare	O
various	O
strategies	O
to	O
combine	O
sequence	O
-	O
level	O
and	O
token	O
-	O
level	O
objectives	O
(	O
cf	O
.	O
	
§	O
	
[	O
reference	O
]	O
)	O
.	O
	
For	O
these	O
experiments	O
we	O
use	O
5	O
candidate	O
sequences	O
per	O
training	O
example	O
for	O
faster	O
experimental	O
turnaround	O
.	O
	
We	O
consider	O
Risk	B-Method
as	O
sequence	B-Task
-	I-Task
level	I-Task
loss	I-Task
and	O
label	B-Method
smoothing	I-Method
as	O
token	B-Task
-	I-Task
level	I-Task
loss	I-Task
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
that	O
combined	O
objectives	O
perform	O
better	O
than	O
pure	O
Risk	B-Method
.	O
	
The	O
weighted	B-Method
combination	I-Method
(	O
Equation	O
[	O
reference	O
]	O
)	O
with	O
performs	O
best	O
,	O
outperforming	O
constrained	B-Method
combination	I-Method
(	O
Equation	O
[	O
reference	O
]	O
)	O
.	O
	
We	O
also	O
compare	O
to	O
randomly	O
choosing	O
between	O
token	O
-	O
level	O
and	O
sequence	O
-	O
level	O
updates	O
and	O
find	O
it	O
underperforms	O
the	O
more	O
principled	O
constrained	B-Method
strategy	I-Method
.	O
	
In	O
the	O
remaining	O
experiments	O
we	O
use	O
the	O
weighted	B-Method
strategy	I-Method
.	O
	
subsection	O
:	O
Effect	O
of	O
initialization	O
	
So	O
far	O
we	O
initialized	O
sequence	B-Method
-	I-Method
level	I-Method
models	I-Method
with	O
parameters	O
from	O
a	O
token	B-Method
-	I-Method
level	I-Method
model	I-Method
trained	O
with	O
label	B-Method
smoothing	I-Method
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
that	O
initializing	O
weighted	O
Risk	B-Method
with	O
token	B-Method
-	I-Method
level	I-Method
label	I-Method
smoothing	I-Method
achieves	O
0.7	O
-	O
0.8	O
better	O
BLEU	B-Metric
compared	O
to	O
initializing	O
with	O
parameters	O
from	O
token	B-Method
-	I-Method
level	I-Method
likelihood	I-Method
.	O
	
The	O
improvement	O
of	O
initializing	O
with	O
TokNLL	B-Method
is	O
only	O
0.3	O
BLEU	B-Metric
with	O
respect	O
to	O
the	O
TokNLL	O
baseline	O
,	O
whereas	O
,	O
the	O
improvement	O
from	O
initializing	O
with	O
TokLS	B-Method
is	O
0.6	O
-	O
0.8	O
BLEU	B-Metric
.	O
	
We	O
believe	O
that	O
the	O
regularization	B-Method
provided	O
by	O
label	B-Method
smoothing	I-Method
leads	O
to	O
models	O
with	O
less	O
sharp	O
distributions	O
that	O
are	O
a	O
better	O
starting	O
point	O
for	O
sequence	B-Method
-	I-Method
level	I-Method
training	I-Method
.	O
	
subsection	O
:	O
Online	O
vs.	O
Offline	B-Task
Candidate	I-Task
Generation	I-Task
	
Next	O
,	O
we	O
consider	O
the	O
question	O
if	O
refreshing	O
the	O
candidate	O
subset	O
at	O
every	O
training	O
step	O
(	O
online	O
)	O
results	O
in	O
better	O
accuracy	B-Metric
compared	O
to	O
generating	O
candidates	O
before	O
training	O
and	O
keeping	O
the	O
set	O
static	O
throughout	O
training	O
(	O
offline	O
)	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
that	O
offline	B-Task
generation	I-Task
gives	O
lower	O
accuracy	B-Metric
.	O
	
However	O
the	O
online	B-Task
setting	I-Task
is	O
much	O
slower	O
,	O
since	O
regenerating	O
the	O
candidate	O
set	O
requires	O
incremental	O
(	O
left	O
to	O
right	O
)	O
inference	O
with	O
our	O
model	O
which	O
is	O
very	O
slow	O
compared	O
to	O
efficient	O
forward	B-Method
/	I-Method
backward	I-Method
over	O
large	O
batches	O
of	O
pre	O
-	O
generated	O
hypothesis	O
.	O
	
In	O
our	O
setting	O
,	O
offline	B-Task
generation	I-Task
has	O
26	O
times	O
higher	O
throughput	B-Metric
than	O
the	O
online	B-Task
generation	I-Task
setting	I-Task
,	O
despite	O
the	O
high	O
inference	B-Metric
speed	I-Metric
of	O
fairseq	B-Method
gehring2017icml	I-Method
.	O
	
subsection	O
:	O
Beam	B-Method
Search	I-Method
vs.	O
Sampling	B-Method
and	O
Candidate	O
Set	O
Size	O
	
So	O
far	O
we	O
generated	O
candidates	O
with	O
beam	B-Method
search	I-Method
,	O
however	O
,	O
we	O
may	O
also	O
sample	O
to	O
obtain	O
a	O
more	O
diverse	O
set	O
of	O
candidates	O
shen2016mrt	O
.	O
	
Figure	O
[	O
reference	O
]	O
compares	O
beam	B-Method
search	I-Method
and	O
sampling	B-Method
for	O
various	O
candidate	O
set	O
sizes	O
on	O
the	O
validation	O
set	O
.	O
	
Beam	B-Method
search	I-Method
performs	O
better	O
for	O
all	O
candidate	O
set	O
sizes	O
considered	O
.	O
	
In	O
other	O
experiments	O
,	O
we	O
rely	O
on	O
a	O
candidate	O
set	O
size	O
of	O
16	O
which	O
strikes	O
a	O
good	O
balance	O
between	O
efficiency	B-Metric
and	O
accuracy	B-Metric
.	O
	
subsection	O
:	O
Comparison	O
to	O
Beam	B-Method
-	I-Method
Search	I-Method
Optimization	I-Method
	
Next	O
,	O
we	O
compare	O
classical	O
sequence	B-Method
-	I-Method
level	I-Method
training	I-Method
to	O
the	O
recently	O
proposed	O
Beam	B-Method
Search	I-Method
Optimization	I-Method
wiseman2016acl	O
.	O
	
To	O
enable	O
a	O
fair	O
comparison	O
,	O
we	O
re	O
-	O
implement	O
their	O
baseline	O
,	O
a	O
single	B-Method
layer	I-Method
LSTM	I-Method
encoder	I-Method
/	I-Method
decoder	I-Method
model	I-Method
with	O
256	O
-	O
dimensional	O
hidden	O
layers	O
and	O
word	O
embeddings	O
as	O
well	O
as	O
attention	O
and	O
input	O
feeding	O
luong2015effective	O
.	O
	
This	O
baseline	O
is	O
trained	O
with	O
Adagrad	B-Method
duchi2011adaptive	O
using	O
a	O
learning	B-Metric
rate	I-Metric
of	O
for	O
five	O
epochs	O
,	O
with	O
batches	O
of	O
64	O
sequences	O
.	O
	
For	O
sequence	B-Method
-	I-Method
level	I-Method
training	I-Method
we	O
initialize	O
weights	O
with	O
the	O
baseline	O
parameters	O
and	O
train	O
with	O
Adam	B-Method
kingma2014adam	I-Method
for	O
another	O
10	O
epochs	O
with	O
learning	B-Metric
rate	I-Metric
and	O
16	O
candidate	O
sequences	O
per	O
training	O
example	O
.	O
	
We	O
conduct	O
experiments	O
with	O
Risk	B-Method
since	O
it	O
performed	O
best	O
in	O
trial	O
experiments	O
.	O
	
Different	O
from	O
other	O
sequence	O
-	O
level	O
experiments	O
(	O
§	O
[	O
reference	O
]	O
)	O
,	O
we	O
rescale	O
the	O
BLEU	B-Metric
scores	O
in	O
each	O
candidate	O
set	O
by	O
the	O
difference	O
between	O
the	O
maximum	O
and	O
minimum	O
scores	O
of	O
each	O
sentence	O
.	O
	
This	O
avoids	O
short	O
sentences	O
dominating	O
the	O
sequence	O
updates	O
,	O
since	O
candidate	O
sets	O
for	O
short	O
sentences	O
have	O
a	O
wider	O
range	O
of	O
BLEU	B-Metric
scores	O
compared	O
to	O
longer	O
sentences	O
;	O
a	O
similar	O
rescaling	O
was	O
used	O
by	O
bahdanau2016ac	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
results	O
from	O
wiseman2016acl	O
for	O
their	O
token	B-Method
-	I-Method
level	I-Method
likelihood	I-Method
baseline	I-Method
(	O
MLE	B-Method
)	O
,	O
best	O
beam	B-Method
search	I-Method
optimization	I-Method
results	O
(	O
BSO	B-Method
)	O
,	O
as	O
well	O
as	O
our	O
reimplemented	B-Method
baseline	I-Method
.	O
	
Risk	B-Method
significantly	O
improves	O
BLEU	B-Metric
compared	O
to	O
our	O
baseline	O
at	O
+	O
2.75	O
BLEU	B-Metric
,	O
which	O
is	O
slightly	O
better	O
than	O
the	O
+	O
2.33	O
BLEU	B-Metric
improvement	O
reported	O
for	O
Beam	B-Method
Search	I-Method
Optimization	I-Method
(	O
cf	O
.	O
wiseman2016acl	O
)	O
.	O
	
This	O
shows	O
that	O
classical	O
objectives	O
for	O
structured	B-Task
prediction	I-Task
are	O
still	O
very	O
competitive	O
.	O
	
subsection	O
:	O
WMT’14	B-Material
English	I-Material
-	I-Material
French	I-Material
results	O
	
Next	O
,	O
we	O
experiment	O
on	O
the	O
much	O
larger	O
WMT’14	B-Material
English	I-Material
-	I-Material
French	I-Material
task	I-Material
using	O
the	O
same	O
model	O
setup	O
as	O
gehring2017icml	O
.	O
	
We	O
TokLS	O
for	O
15	O
epochs	O
and	O
then	O
switch	O
to	O
sequence	B-Method
-	I-Method
level	I-Method
training	I-Method
for	O
another	O
epoch	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
that	O
sequence	B-Method
-	I-Method
level	I-Method
training	I-Method
can	O
improve	O
an	O
already	O
very	O
strong	O
model	O
by	O
another	O
+	O
0.37	O
BLEU	B-Metric
.	O
	
Next	O
,	O
we	O
improve	O
the	O
baseline	O
by	O
adding	O
self	O
-	O
attention	O
paulus2017summary	O
,	O
	
vaswani2017transformer	O
to	O
the	O
decoder	B-Method
network	I-Method
(	O
TokLS	B-Method
+	O
selfatt	B-Method
)	O
which	O
results	O
in	O
a	O
smaller	O
gain	O
of	O
+	O
0.2	O
BLEU	B-Metric
by	O
Risk	B-Method
.	O
	
If	O
we	O
train	O
Risk	B-Method
only	O
on	O
the	O
news	O
-	O
commentary	O
portion	O
of	O
the	O
training	O
data	O
,	O
then	O
we	O
achieve	O
state	O
of	O
the	O
art	O
accuracy	B-Metric
on	O
this	O
dataset	O
of	O
41.5	O
BLEU	B-Metric
yingce2017deliberation	O
.	O
	
subsection	O
:	O
Abstractive	B-Task
Summarization	I-Task
	
Our	O
final	O
experiment	O
evaluates	O
sequence	B-Method
-	I-Method
level	I-Method
training	I-Method
on	O
Gigaword	B-Task
headline	I-Task
summarization	I-Task
.	O
	
There	O
has	O
been	O
much	O
prior	O
art	O
on	O
this	O
dataset	O
originally	O
introduced	O
by	O
rush2015abs	O
who	O
experiment	O
with	O
a	O
feed	B-Method
-	I-Method
forward	I-Method
network	I-Method
(	O
ABS	B-Method
+	I-Method
)	O
.	O
	
ayana2016neural	O
report	O
a	O
likelihood	B-Method
baseline	I-Method
(	O
RNN	O
MLE	B-Method
)	O
and	O
also	O
experiment	O
with	O
risk	B-Method
training	I-Method
(	O
RNN	B-Method
MRT	I-Method
)	O
.	O
	
Different	O
to	O
their	O
setup	O
we	O
did	O
not	O
find	O
a	O
softmax	O
temperature	O
to	O
be	O
beneficial	O
,	O
and	O
we	O
use	O
beam	B-Method
search	I-Method
instead	O
of	O
sampling	O
to	O
obtain	O
the	O
candidate	O
set	O
(	O
cf	O
.	O
	
§	O
	
[	O
reference	O
]	O
)	O
.	O
	
suzuki2017cutting	O
improve	O
over	O
an	O
MLE	B-Method
RNN	O
baseline	O
by	O
limiting	O
generation	O
of	O
repeated	O
phrases	O
.	O
	
zhou2017seass	O
also	O
consider	O
an	O
MLE	B-Method
RNN	O
baseline	O
and	O
add	O
an	O
additional	O
gating	B-Method
mechanism	I-Method
for	O
the	O
encoder	O
.	O
	
li2017drgd	O
equip	O
the	O
decoder	B-Method
of	O
a	O
similar	B-Method
network	I-Method
with	O
additional	O
latent	O
variables	O
to	O
accommodate	O
the	O
uncertainty	O
of	O
this	O
task	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
that	O
our	O
baseline	O
(	O
TokLS	B-Method
)	O
outperforms	O
all	O
prior	O
approaches	O
in	O
terms	O
of	O
ROUGE	B-Metric
-	I-Metric
2	I-Metric
and	O
ROUGE	B-Metric
-	I-Metric
L	I-Metric
and	O
it	O
is	O
on	O
par	O
to	O
the	O
best	O
previous	O
result	O
for	O
ROUGE	B-Metric
-	I-Metric
1	I-Metric
.	O
	
We	O
optimize	O
all	O
three	O
ROUGE	B-Metric
metrics	O
separately	O
and	O
find	O
that	O
Risk	B-Method
can	O
further	O
improve	O
our	O
strong	O
baseline	O
.	O
	
We	O
also	O
compared	O
Risk	B-Method
only	O
training	O
to	O
Weighted	O
on	O
this	O
dataset	O
(	O
cf	O
.	O
	
§	O
	
[	O
reference	O
]	O
)	O
but	O
accuracy	B-Metric
was	O
generally	O
lower	O
on	O
the	O
validation	O
set	O
:	O
	
RG	B-Metric
-	I-Metric
1	I-Metric
(	O
36.59	O
Risk	B-Method
only	O
vs.	O
36.67	O
Weighted	O
)	O
,	O
	
RG	B-Metric
-	I-Metric
2	I-Metric
(	O
17.34	O
vs.	O
18.05	O
)	O
,	O
and	O
RG	B-Metric
-	I-Metric
L	I-Metric
(	O
33.66	O
vs.	O
33.98	O
)	O
.	O
	
section	O
:	O
Conclusion	O
	
We	O
present	O
a	O
comprehensive	O
comparison	O
of	O
classical	O
losses	O
for	O
structured	B-Task
prediction	I-Task
and	O
apply	O
them	O
to	O
a	O
strong	O
neural	B-Method
sequence	I-Method
to	I-Method
sequence	I-Method
model	I-Method
.	O
	
We	O
found	O
that	O
combining	O
sequence	O
-	O
level	O
and	O
token	O
-	O
level	O
losses	O
is	O
necessary	O
to	O
perform	O
best	O
,	O
and	O
so	O
is	O
training	O
on	O
candidates	O
decoded	O
with	O
the	O
current	O
model	O
.	O
	
We	O
show	O
that	O
sequence	B-Method
-	I-Method
level	I-Method
training	I-Method
improves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
baselines	O
both	O
for	O
IWSLT’14	B-Material
German	I-Material
-	I-Material
English	I-Material
translation	I-Material
and	O
Gigaword	B-Material
abstractive	I-Material
sentence	I-Material
summarization	I-Material
.	O
	
Structured	B-Method
prediction	I-Method
losses	I-Method
are	O
very	O
competitive	O
to	O
recent	O
work	O
on	O
reinforcement	B-Task
or	I-Task
beam	I-Task
optimization	I-Task
.	O
	
Classical	O
expected	B-Method
risk	I-Method
can	O
slightly	O
outperform	O
beam	B-Method
search	I-Method
optimization	I-Method
wiseman2016acl	O
in	O
a	O
like	B-Task
-	I-Task
for	I-Task
-	I-Task
like	I-Task
setup	I-Task
.	O
	
Future	O
work	O
may	O
investigate	O
better	O
use	O
of	O
already	O
generated	O
candidates	O
since	O
invoking	O
generation	O
for	O
each	O
batch	O
slows	O
down	O
training	B-Task
by	O
a	O
large	O
factor	O
,	O
e.g.	O
,	O
mixing	O
with	O
fresh	O
and	O
older	O
candidates	O
inspired	O
by	O
MERT	B-Method
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Invertible	B-Method
Conditional	I-Method
GANs	I-Method
for	O
image	B-Task
editing	I-Task
	
Generative	B-Method
Adversarial	I-Method
Networks	I-Method
(	O
GANs	B-Method
)	O
have	O
recently	O
demonstrated	O
to	O
successfully	O
approximate	O
complex	O
data	O
distributions	O
.	O
	
A	O
relevant	O
extension	O
of	O
this	O
model	O
is	O
conditional	B-Method
GANs	I-Method
(	O
cGANs	B-Method
)	O
,	O
where	O
the	O
introduction	O
of	O
external	O
information	O
allows	O
to	O
determine	O
specific	O
representations	O
of	O
the	O
generated	O
images	O
.	O
	
In	O
this	O
work	O
,	O
we	O
evaluate	O
encoders	B-Method
to	O
inverse	O
the	O
mapping	O
of	O
a	O
cGAN	B-Method
,	O
i.e.	O
,	O
mapping	O
a	O
real	O
image	O
into	O
a	O
latent	O
space	O
and	O
a	O
conditional	B-Method
representation	I-Method
.	O
	
This	O
allows	O
,	O
for	O
example	O
,	O
to	O
reconstruct	O
and	O
modify	O
real	O
images	O
of	O
faces	O
conditioning	O
on	O
arbitrary	O
attributes	O
.	O
	
Additionally	O
,	O
we	O
evaluate	O
the	O
design	O
of	O
cGANs	B-Method
.	O
	
The	O
combination	O
of	O
an	O
encoder	B-Method
with	O
a	O
cGAN	B-Method
,	O
which	O
we	O
call	O
Invertible	B-Method
cGAN	I-Method
(	O
IcGAN	B-Method
)	O
,	O
enables	O
to	O
re	O
-	O
generate	O
real	O
images	O
with	O
deterministic	O
complex	O
modifications	O
.	O
	
section	O
:	O
Introduction	O
	
Image	B-Task
editing	I-Task
can	O
be	O
performed	O
at	O
different	O
levels	O
of	O
complexity	B-Metric
and	O
abstraction	O
.	O
	
Common	O
operations	O
consist	O
in	O
simply	O
applying	O
a	O
filter	B-Method
to	O
an	O
image	O
to	O
,	O
for	O
example	O
,	O
augment	O
the	O
contrast	O
or	O
convert	O
to	O
grayscale	O
.	O
	
These	O
,	O
however	O
,	O
are	O
low	O
-	O
complex	O
operations	O
that	O
do	O
not	O
necessarily	O
require	O
to	O
comprehend	O
the	O
scene	O
or	O
object	O
that	O
the	O
image	O
is	O
representing	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
if	O
one	O
would	O
want	O
to	O
modify	O
the	O
attributes	O
of	O
a	O
face	O
(	O
e.g.	O
add	O
a	O
smile	O
,	O
change	O
the	O
hair	O
color	O
or	O
even	O
the	O
gender	O
)	O
,	O
this	O
is	O
a	O
more	O
complex	O
and	O
challenging	O
modification	O
to	O
perform	O
.	O
	
In	O
this	O
case	O
,	O
in	O
order	O
to	O
obtain	O
realistic	O
results	O
,	O
a	O
skilled	O
human	O
with	O
an	O
image	B-Method
edition	I-Method
software	I-Method
would	O
often	O
be	O
required	O
.	O
	
A	O
solution	O
to	O
automatically	O
perform	O
these	O
non	O
-	O
trivial	O
operations	O
relies	O
on	O
generative	B-Method
models	I-Method
.	O
	
Natural	B-Task
image	I-Task
generation	I-Task
has	O
been	O
a	O
strong	O
research	O
topic	O
for	O
many	O
years	O
,	O
but	O
it	O
has	O
not	O
been	O
until	O
2015	O
that	O
promising	O
results	O
have	O
been	O
achieved	O
with	O
deep	B-Method
learning	I-Method
techniques	I-Method
combined	O
with	O
generative	B-Method
modeling	I-Method
Gregor2015	O
,	O
Radford2015	O
.	O
	
Generative	B-Method
Adversarial	I-Method
Networks	I-Method
(	O
GANs	B-Method
)	O
is	O
one	O
of	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
approaches	O
for	O
image	B-Task
generation	I-Task
.	O
	
GANs	B-Method
are	O
especially	O
interesting	O
as	O
they	O
are	O
directly	O
optimized	O
towards	O
generating	O
the	O
most	O
plausible	O
and	O
realistic	O
data	O
,	O
as	O
opposed	O
to	O
other	O
models	O
(	O
e.g.	O
Variational	B-Method
Autoencoders	I-Method
)	O
,	O
which	O
focus	O
on	O
an	O
image	B-Task
reconstruction	I-Task
loss	I-Task
.	O
	
Additionally	O
,	O
GANs	B-Method
are	O
able	O
to	O
explicitly	O
control	O
generated	O
images	O
features	O
with	O
a	O
conditional	B-Method
extension	I-Method
,	O
conditional	B-Method
GANs	I-Method
(	O
cGANs	B-Method
)	O
.	O
	
However	O
,	O
the	O
GAN	B-Method
framework	O
lacks	O
an	O
inference	B-Method
mechanism	I-Method
,	O
i.e.	O
,	O
finding	O
the	O
latent	B-Method
representation	I-Method
of	O
an	O
input	O
image	O
,	O
which	O
is	O
a	O
necessary	O
step	O
for	O
being	O
able	O
to	O
reconstruct	O
and	O
modify	O
real	O
images	O
.	O
	
In	O
order	O
to	O
overcome	O
this	O
limitation	O
,	O
in	O
this	O
paper	O
we	O
introduce	O
Invertible	B-Method
Conditional	I-Method
GANs	I-Method
(	O
IcGANs	B-Method
)	O
for	O
complex	B-Task
image	I-Task
editing	I-Task
as	O
the	O
union	O
of	O
an	O
encoder	B-Method
used	O
jointly	O
with	O
a	O
cGAN	B-Method
.	O
	
This	O
model	O
allows	O
to	O
map	O
real	O
images	O
into	O
a	O
high	O
-	O
feature	O
space	O
(	O
encoder	B-Method
)	O
and	O
perform	O
meaningful	O
modifications	O
on	O
them	O
(	O
cGAN	B-Method
)	O
.	O
	
As	O
a	O
result	O
,	O
we	O
can	O
explicitly	O
control	O
the	O
attributes	O
of	O
a	O
real	O
image	O
(	O
Figure	O
[	O
reference	O
]	O
)	O
,	O
which	O
could	O
be	O
potentially	O
useful	O
in	O
several	O
applications	O
,	O
be	O
it	O
creative	B-Task
processes	I-Task
,	O
data	B-Task
augmentation	I-Task
or	O
face	B-Task
profiling	I-Task
.	O
	
[	O
width=0.85	O
]	O
images	O
/	O
1.intro	O
/	O
pull_figure	O
	
The	O
summary	O
of	O
contributions	O
of	O
our	O
work	O
is	O
the	O
following	O
:	O
Proposing	O
IcGANs	B-Method
,	O
composed	O
of	O
two	O
crucial	O
parts	O
:	O
an	O
encoder	B-Method
and	O
a	O
cGAN	B-Method
.	O
	
We	O
apply	O
this	O
model	O
to	O
MNIST	B-Material
LeCun1998	O
and	O
CelebA	B-Material
celeba	O
datasets	O
,	O
which	O
allows	O
performing	O
meaningful	O
and	O
realistic	O
editing	O
operations	O
on	O
them	O
by	O
arbitrarily	O
changing	O
the	O
conditional	O
information	O
.	O
	
Introducing	O
an	O
encoder	B-Method
in	O
the	O
conditional	O
GAN	B-Method
framework	O
to	O
compress	O
a	O
real	O
image	O
into	O
a	O
latent	B-Method
representation	I-Method
and	O
conditional	O
vector	O
.	O
	
We	O
consider	O
several	O
designs	O
and	O
training	B-Method
procedures	I-Method
to	O
leverage	O
the	O
performance	O
obtained	O
from	O
available	O
conditional	O
information	O
.	O
	
Evaluating	O
and	O
refining	O
cGANs	B-Method
through	O
conditional	B-Method
position	I-Method
and	O
conditional	B-Method
sampling	I-Method
to	O
enhance	O
the	O
quality	O
of	O
generated	O
images	O
.	O
	
section	O
:	O
Related	O
work	O
	
There	O
are	O
different	O
approaches	O
for	O
generative	B-Method
models	I-Method
.	O
	
Among	O
them	O
,	O
there	O
are	O
two	O
promising	O
ones	O
that	O
are	O
recently	O
pushing	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
with	O
highly	O
plausible	O
generated	O
images	O
.	O
	
The	O
first	O
one	O
is	O
Variational	B-Method
Autoencoders	I-Method
(	O
VAE	B-Method
)	O
Gregor2015	O
,	O
Kingma2013	O
,	O
Rezende2014	O
,	O
Kingma2014	O
,	O
which	O
impose	O
a	O
prior	O
representation	O
space	O
(	O
e.g.	O
normal	O
distribution	O
)	O
in	O
order	O
to	O
regularize	O
and	O
constrain	O
the	O
model	O
to	O
sample	O
from	O
it	O
.	O
	
However	O
,	O
VAEs	B-Method
main	O
limitation	O
is	O
the	O
pixel	B-Metric
-	I-Metric
wise	I-Metric
reconstruction	I-Metric
error	I-Metric
used	O
as	O
a	O
loss	O
function	O
,	O
which	O
causes	O
the	O
output	O
images	O
to	O
look	O
blurry	O
.	O
	
The	O
second	O
approach	O
is	O
Generative	B-Method
Adversarial	I-Method
Nets	I-Method
(	O
GANs	B-Method
)	O
.	O
	
Originally	O
proposed	O
by	O
Goodfellow	O
et	O
al	O
.	O
	
Goodfellow2014	O
,	O
GANs	B-Method
have	O
been	O
improved	O
with	O
a	O
deeper	B-Method
architecture	I-Method
(	O
DCGAN	B-Method
)	O
by	O
Radford	O
et	O
al	O
.	O
	
Radford2015	O
.	O
	
The	O
latest	O
advances	O
introduced	O
several	O
techniques	O
that	O
improve	O
the	O
overall	O
performance	O
for	O
training	O
GANs	B-Method
Salimans2016	O
and	O
an	O
unsupervised	B-Method
approach	I-Method
to	O
disentangle	O
feature	B-Method
representations	I-Method
Chen2016	O
.	O
	
Additionally	O
,	O
the	O
most	O
advanced	O
and	O
recent	O
work	O
on	O
cGANs	B-Method
trains	O
a	O
model	O
to	O
generate	O
realistic	O
images	O
from	O
text	O
descriptions	O
and	O
landmarks	O
.	O
	
Our	O
work	O
is	O
considered	O
in	O
the	O
content	O
of	O
the	O
GAN	B-Method
framework	O
.	O
	
The	O
baseline	O
will	O
be	O
the	O
work	O
of	O
Radford	O
’s	O
et	O
al	O
.	O
	
(	O
DCGANs	B-Method
)	O
	
Radford2015	O
,	O
which	O
we	O
will	O
add	O
a	O
conditional	B-Method
extension	I-Method
.	O
	
The	O
difference	O
of	O
our	O
approach	O
to	O
prior	O
work	O
is	O
that	O
we	O
also	O
propose	O
an	O
encoder	B-Method
(	O
Invertible	B-Method
cGAN	I-Method
)	O
with	O
which	O
we	O
can	O
,	O
given	O
an	O
input	O
image	O
,	O
to	O
obtain	O
its	O
representation	O
as	O
a	O
latent	O
variable	O
and	O
a	O
conditional	O
vector	O
.	O
	
Then	O
,	O
we	O
can	O
modify	O
and	O
to	O
re	O
-	O
generate	O
the	O
original	O
image	O
with	O
complex	O
variations	O
.	O
	
Dumoulin	O
et	O
al	O
.	O
	
Dumoulin2016	O
and	O
Donahue	O
et	O
al	O
.	O
	
Donahue2016	O
also	O
proposed	O
an	O
encoder	B-Method
in	O
GANs	B-Method
,	O
but	O
in	O
a	O
non	B-Task
-	I-Task
conditional	I-Task
and	I-Task
jointly	I-Task
trained	I-Task
setting	I-Task
.	O
	
Additionally	O
,	O
Makhzani	O
et	O
al	O
.	O
Makhzani2015	O
and	O
Larsen	O
et	O
	
al	O
.	O
	
Larsen2015	O
proposed	O
a	O
similar	O
idea	O
to	O
this	O
paper	O
by	O
combining	O
a	O
VAE	B-Method
and	O
a	O
GAN	B-Method
with	O
promising	O
results	O
.	O
	
Reed	O
et	O
al	O
.	O
	
Reed2016	O
implemented	O
an	O
encoder	O
in	O
a	O
similar	O
fashion	O
to	O
our	O
approach	O
.	O
	
This	O
paper	O
builds	O
alongside	O
their	O
work	O
in	O
a	O
complementary	O
manner	O
.	O
	
In	O
our	O
case	O
,	O
we	O
analyze	O
more	O
deeply	O
the	O
encoder	B-Method
by	O
including	O
conditional	B-Method
information	I-Method
encoding	I-Method
and	O
testing	O
different	O
architectures	O
and	O
training	B-Method
approaches	I-Method
.	O
	
Also	O
,	O
we	O
evaluate	O
unexplored	O
design	O
decisions	O
for	O
building	O
a	O
cGAN	B-Method
.	O
	
section	O
:	O
Background	O
:	O
Generative	B-Method
Adversarial	I-Method
Networks	I-Method
	
A	O
GAN	B-Method
is	O
composed	O
of	O
two	O
neural	B-Method
networks	I-Method
,	O
a	O
generator	B-Method
and	O
a	O
discriminator	B-Method
.	O
	
Both	O
networks	O
are	O
iteratively	O
trained	O
competing	O
against	O
each	O
other	O
in	O
a	O
minimax	B-Task
game	I-Task
.	O
	
The	O
generator	O
aims	O
to	O
approximate	O
the	O
underlying	O
unknown	O
data	O
distribution	O
to	O
fool	O
the	O
discriminator	B-Method
,	O
whilst	O
the	O
discriminator	O
is	O
focused	O
on	O
being	O
able	O
to	O
tell	O
which	O
samples	O
are	O
real	O
or	O
generated	O
.	O
	
On	O
convergence	B-Task
,	O
we	O
want	O
,	O
where	O
is	O
the	O
generator	O
distribution	O
.	O
	
More	O
formally	O
,	O
considering	O
the	O
function	O
,	O
where	O
and	O
are	O
the	O
parameters	O
of	O
the	O
generator	B-Method
and	O
discriminator	B-Method
respectively	O
,	O
we	O
can	O
formulate	O
GAN	B-Method
training	O
as	O
optimizing	O
where	O
is	O
a	O
vector	O
noise	O
sampled	O
from	O
a	O
known	O
simple	O
distribution	O
(	O
e.g.	O
normal	O
)	O
.	O
	
GAN	B-Method
framework	O
can	O
be	O
extended	O
with	O
conditional	B-Method
GANs	I-Method
(	O
cGANs	B-Method
)	O
Mirza2014	O
.	O
	
They	O
are	O
quite	O
similar	O
to	O
vanilla	O
(	O
non	O
-	O
conditional	O
)	O
GANs	B-Method
,	O
the	O
only	O
difference	O
is	O
that	O
,	O
in	O
this	O
case	O
,	O
we	O
have	O
extra	O
information	O
(	O
e.g.	O
class	O
labels	O
,	O
attribute	O
information	O
)	O
for	O
a	O
given	O
real	O
sample	O
.	O
	
Conditional	O
information	O
strictly	O
depends	O
on	O
real	O
samples	O
,	O
but	O
we	O
can	O
model	O
a	O
density	B-Method
model	I-Method
in	O
order	O
to	O
sample	O
generated	O
labels	O
for	O
generated	O
data	O
.	O
	
Then	O
,	O
Equation	O
[	O
reference	O
]	O
can	O
be	O
reformulated	O
for	O
the	O
cGAN	B-Method
extension	O
as	O
Once	O
a	O
cGAN	B-Method
is	O
trained	O
,	O
it	O
allows	O
us	O
to	O
generate	O
samples	O
using	O
two	O
level	O
of	O
variations	O
:	O
constrained	O
and	O
unconstrained	O
.	O
	
Constrained	O
variations	O
are	O
modeled	O
with	O
as	O
it	O
directly	O
correlates	O
with	O
features	O
of	O
the	O
data	O
that	O
are	O
explicitly	O
correlated	O
with	O
and	O
the	O
data	O
itself	O
.	O
	
Then	O
,	O
all	O
the	O
other	O
variations	O
of	O
the	O
data	O
not	O
modeled	O
by	O
(	O
unconstrained	O
variations	O
)	O
are	O
encoded	O
in	O
.	O
	
section	O
:	O
Invertible	B-Method
Conditional	I-Method
GANs	I-Method
	
We	O
introduce	O
Invertible	B-Method
Conditional	I-Method
GANs	I-Method
(	O
IcGANs	B-Method
)	O
,	O
which	O
are	O
composed	O
of	O
a	O
cGAN	B-Method
and	O
an	O
encoder	B-Method
.	O
	
Even	O
though	O
encoders	B-Method
have	O
recently	O
been	O
introduced	O
into	O
the	O
GAN	B-Method
framework	O
,	O
we	O
are	O
the	O
first	O
ones	O
to	O
include	O
and	O
leverage	O
the	O
conditional	O
information	O
into	O
the	O
design	O
of	O
the	O
encoding	B-Method
process	I-Method
.	O
	
In	O
section	O
[	O
reference	O
]	O
we	O
explain	O
how	O
and	O
why	O
an	O
encoder	B-Method
is	O
included	O
in	O
the	O
GAN	B-Method
framework	O
for	O
a	O
conditional	B-Task
setting	I-Task
.	O
	
In	O
section	O
[	O
reference	O
]	O
,	O
we	O
introduce	O
our	O
approach	O
to	O
refine	O
cGANs	B-Method
on	O
two	O
aspects	O
:	O
conditional	O
position	O
and	O
conditional	B-Method
sampling	I-Method
.	O
	
The	O
model	O
architecture	O
is	O
described	O
in	O
section	O
[	O
reference	O
]	O
.	O
	
subsection	O
:	O
Encoder	O
	
A	O
generator	B-Method
from	O
a	O
GAN	B-Method
framework	O
does	O
not	O
have	O
the	O
capability	O
to	O
map	O
a	O
real	O
image	O
to	O
its	O
latent	B-Method
representation	I-Method
.	O
	
To	O
overcome	O
this	O
problem	O
,	O
we	O
can	O
train	O
an	O
encoder	B-Method
/	I-Method
inference	I-Method
network	I-Method
that	O
approximately	O
inverses	O
this	O
mapping	O
.	O
	
This	O
inversion	O
would	O
allow	O
us	O
to	O
have	O
a	O
latent	B-Method
representation	I-Method
from	O
a	O
real	O
image	O
	
and	O
,	O
then	O
,	O
we	O
would	O
be	O
able	O
to	O
explore	O
the	O
latent	O
space	O
by	O
interpolating	O
or	O
adding	O
variations	O
on	O
it	O
,	O
which	O
would	O
result	O
in	O
variations	O
on	O
the	O
generated	O
image	O
.	O
	
If	O
combined	O
with	O
a	O
cGAN	B-Method
,	O
once	O
the	O
latent	B-Method
representation	I-Method
has	O
been	O
obtained	O
,	O
explicitly	O
controlled	O
variations	O
can	O
be	O
added	O
to	O
an	O
input	O
image	O
via	O
conditional	O
information	O
(	O
e.g.	O
generate	O
a	O
certain	O
digit	O
in	O
MNIST	B-Material
or	O
specify	O
face	O
attributes	O
on	O
a	O
face	O
dataset	O
)	O
.	O
	
We	O
call	O
this	O
combination	O
Invertible	O
cGAN	B-Method
,	O
as	O
now	O
the	O
mapping	O
can	O
be	O
inverted	O
:	O
and	O
,	O
where	O
is	O
an	O
input	O
image	O
and	O
its	O
reconstruction	O
.	O
	
See	O
Figure	O
[	O
reference	O
]	O
for	O
an	O
example	O
on	O
how	O
a	O
trained	O
IcGAN	B-Method
is	O
used	O
.	O
	
[	O
width=0.92	O
]	O
images	O
/	O
4.icgans	O
/	O
	
icgan_overview	B-Method
Our	O
approach	O
consists	O
of	O
training	O
an	O
encoder	B-Method
once	O
the	O
cGAN	B-Method
has	O
been	O
trained	O
,	O
as	O
similarly	O
considered	O
by	O
Reed	O
et	O
al	O
.	O
	
In	O
our	O
case	O
,	O
however	O
,	O
the	O
encoder	B-Method
is	O
composed	O
of	O
two	O
sub	B-Method
-	I-Method
encoders	I-Method
:	O
,	O
which	O
encodes	O
an	O
image	O
to	O
,	O
and	O
,	O
which	O
encodes	O
an	O
image	O
to	O
.	O
	
To	O
train	O
we	O
use	O
the	O
generator	B-Method
to	O
create	O
a	O
dataset	O
of	O
generated	O
images	O
and	O
their	O
latent	O
vectors	O
,	O
and	O
then	O
minimize	O
a	O
squared	B-Metric
reconstruction	I-Metric
loss	I-Metric
(	O
Eq	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
For	O
,	O
we	O
initially	O
used	O
generated	O
images	O
and	O
their	O
conditional	O
information	O
for	O
training	O
.	O
	
However	O
,	O
we	O
found	O
that	O
generated	O
images	O
tend	O
to	O
be	O
noisier	O
than	O
real	O
ones	O
and	O
,	O
in	O
this	O
specific	O
case	O
,	O
we	O
could	O
improve	O
by	O
directly	O
training	O
with	O
real	O
images	O
and	O
labels	O
from	O
the	O
dataset	O
(	O
Eq	O
.	O
[	O
reference	O
]	O
)	O
.	O
	
Although	O
and	O
might	O
seem	O
completely	O
independent	O
,	O
we	O
can	O
adopt	O
different	O
strategies	O
to	O
make	O
them	O
interact	O
and	O
leverage	O
the	O
conditional	O
information	O
(	O
for	O
an	O
evaluation	O
of	O
them	O
,	O
see	O
section	O
[	O
reference	O
]	O
	
)	O
:	O
	
SNG	B-Method
:	O
	
One	O
single	O
encoder	B-Method
with	O
shared	O
layers	O
and	O
two	O
outputs	O
.	O
	
That	O
is	O
,	O
and	O
are	O
embedded	O
in	O
a	O
single	O
encoder	B-Method
.	O
	
IND	O
:	O
	
Two	O
independent	B-Method
encoders	I-Method
.	O
	
and	O
are	O
trained	O
separately	O
.	O
	
IND	B-Method
-	I-Method
COND	I-Method
:	O
	
Two	O
encoders	B-Method
,	O
where	O
is	O
conditioned	O
on	O
the	O
output	O
of	O
encoder	O
.	O
	
Recently	O
,	O
Dumoulin	O
et	O
al	O
.	O
	
Dumoulin2016	O
and	O
Donahue	O
et	O
al	O
.	O
	
Donahue2016	O
proposed	O
different	O
approaches	O
on	O
how	O
to	O
train	O
an	O
encoder	B-Method
in	O
the	O
GAN	B-Method
framework	O
.	O
	
One	O
of	O
the	O
most	O
interesting	O
approaches	O
consists	O
in	O
jointly	O
training	O
the	O
encoder	B-Method
with	O
both	O
the	O
discriminator	B-Method
and	O
the	O
generator	B-Method
.	O
	
Although	O
this	O
approach	O
is	O
promising	O
,	O
our	O
work	O
has	O
been	O
completely	O
independent	O
of	O
these	O
articles	O
and	O
focuses	O
on	O
another	O
direction	O
,	O
since	O
we	O
consider	O
the	O
encoder	B-Method
in	O
a	O
conditional	B-Task
setting	I-Task
.	O
	
Consequently	O
,	O
we	O
implemented	O
our	O
aforementioned	O
approach	O
which	O
performs	O
nearly	O
equally	O
Donahue2016	O
to	O
their	O
strategy	O
.	O
	
subsection	O
:	O
Conditional	O
GAN	B-Method
	
We	O
consider	O
two	O
main	O
design	O
decisions	O
concerning	O
cGANs	B-Method
.	O
	
The	O
first	O
one	O
is	O
to	O
find	O
the	O
optimal	O
conditional	O
position	O
on	O
the	O
generator	B-Method
and	I-Method
discriminator	I-Method
,	O
which	O
,	O
to	O
our	O
knowledge	O
,	O
has	O
not	O
been	O
previously	O
addressed	O
.	O
	
Secondly	O
,	O
we	O
discuss	O
the	O
best	O
approach	O
to	O
sample	O
conditional	O
information	O
for	O
the	O
generator	B-Method
.	O
	
Conditional	O
position	O
	
In	O
the	O
cGAN	B-Method
,	O
the	O
conditional	O
information	O
vector	O
needs	O
to	O
be	O
introduced	O
in	O
both	O
the	O
generator	B-Method
and	O
the	O
discriminator	B-Method
.	O
	
In	O
the	O
generator	B-Method
,	O
and	O
(	O
where	O
are	O
always	O
concatenated	O
in	O
the	O
filter	O
dimension	O
at	O
the	O
input	O
level	O
Reed2016	O
,	O
Mirza2014	O
,	O
Gauthier2014	O
.	O
	
As	O
for	O
the	O
discriminator	O
,	O
different	O
authors	O
insert	O
in	O
different	O
parts	O
of	O
the	O
model	O
Reed2016	O
,	O
Mirza2014	O
,	O
Gauthier2014	O
.	O
	
We	O
expect	O
that	O
the	O
earlier	O
is	O
positioned	O
in	O
the	O
model	O
the	O
better	O
since	O
the	O
model	O
is	O
allowed	O
to	O
have	O
more	O
learning	O
interactions	O
with	O
.	O
	
Experiments	O
regarding	O
the	O
optimal	O
position	O
will	O
be	O
detailed	O
in	O
section	O
[	O
reference	O
]	O
.	O
	
Conditional	B-Method
sampling	I-Method
	
There	O
are	O
two	O
types	O
of	O
conditional	O
information	O
,	O
and	O
.	O
	
The	O
first	O
one	O
is	O
trivially	O
sampled	O
from	O
and	O
is	O
used	O
for	O
training	O
the	O
discriminator	B-Method
with	O
a	O
real	O
image	O
and	O
its	O
associated	O
label	O
.	O
	
The	O
second	O
one	O
is	O
sampled	O
from	O
and	O
serves	O
as	O
input	O
to	O
the	O
generator	O
along	O
with	O
a	O
latent	O
vector	O
to	O
generate	O
an	O
image	O
,	O
and	O
it	O
can	O
be	O
sampled	O
using	O
different	O
approaches	O
:	O
	
Kernel	B-Method
density	I-Method
estimation	I-Method
:	O
also	O
known	O
as	O
Parzen	B-Method
window	I-Method
estimation	I-Method
,	O
it	O
consists	O
in	O
randomly	B-Method
sampling	I-Method
from	O
a	O
kernel	B-Method
(	O
e.g.	O
Gaussian	B-Method
kernel	I-Method
with	O
a	O
cross	B-Method
-	I-Method
validated	I-Method
)	O
.	O
	
Direct	B-Method
interpolation	I-Method
:	O
interpolate	O
between	O
label	O
vectors	O
from	O
the	O
training	O
set	O
Reed2016	O
.	O
	
The	O
reasoning	O
behind	O
this	O
approach	O
is	O
that	O
interpolations	O
can	O
belong	O
to	O
the	O
label	O
distribution	O
.	O
	
Sampling	O
from	O
the	O
training	O
set	O
,	O
:	O
Use	O
directly	O
the	O
real	O
labels	O
from	O
the	O
training	O
set	O
.	O
	
As	O
Gauthier	O
Gauthier2014	O
pointed	O
out	O
,	O
unlike	O
the	O
previous	O
two	O
approaches	O
,	O
this	O
method	O
could	O
overfit	O
the	O
model	O
by	O
using	O
the	O
conditional	O
information	O
to	O
reproduce	O
the	O
images	O
of	O
the	O
training	O
set	O
.	O
	
However	O
,	O
this	O
is	O
only	O
likely	O
to	O
occur	O
if	O
the	O
conditional	O
information	O
is	O
,	O
to	O
some	O
extent	O
,	O
unique	O
for	O
each	O
image	O
.	O
	
In	O
the	O
case	O
where	O
the	O
attributes	O
of	O
an	O
image	O
are	O
binary	O
,	O
one	O
attribute	O
vector	O
could	O
describe	O
a	O
varied	O
and	O
large	O
enough	O
subset	O
of	O
images	O
,	O
preventing	O
the	O
model	O
from	O
overfitting	O
given	O
.	O
	
Kernel	B-Method
density	I-Method
estimation	I-Method
and	O
direct	B-Method
interpolation	I-Method
are	O
,	O
at	O
the	O
end	O
,	O
two	O
different	O
ways	O
to	O
interpolate	O
on	O
.	O
	
Nevertheless	O
,	O
interpolation	B-Method
is	O
mostly	O
suitable	O
when	O
the	O
attribute	O
information	O
is	O
composed	O
of	O
real	O
vectors	O
,	O
not	O
binary	O
ones	O
.	O
	
It	O
is	O
not	O
the	O
case	O
of	O
the	O
binary	O
conditional	O
information	O
of	O
the	O
datasets	O
used	O
in	O
this	O
paper	O
(	O
see	O
section	O
[	O
reference	O
]	O
for	O
dataset	O
information	O
)	O
.	O
	
Directly	O
interpolating	O
binary	O
vectors	O
would	O
not	O
create	O
plausible	O
conditional	O
information	O
,	O
as	O
an	O
interpolated	O
vector	O
would	O
not	O
belong	O
to	O
nor	O
.	O
	
Using	O
a	O
kernel	B-Method
density	I-Method
estimation	I-Method
would	O
not	O
make	O
sense	O
either	O
,	O
as	O
all	O
the	O
binary	O
labels	O
would	O
fall	O
in	O
the	O
corners	O
of	O
a	O
hypercube	O
.	O
	
Therefore	O
,	O
we	O
will	O
directly	O
sample	O
from	O
.	O
	
subsection	O
:	O
Model	O
architecture	O
	
Conditional	O
GAN	B-Method
	
The	O
work	O
of	O
this	O
paper	O
is	O
based	O
on	O
the	O
Torch	B-Method
implementation	I-Method
of	O
the	O
DCGAN	B-Method
.	O
	
We	O
use	O
the	O
recommended	O
configuration	O
for	O
the	O
DCGAN	B-Method
,	O
which	O
trains	O
with	O
the	O
Adam	B-Method
optimizer	I-Method
adam2014	I-Method
(	O
)	O
with	O
a	O
learning	B-Metric
rate	I-Metric
of	O
and	O
a	O
mini	O
-	O
batch	O
size	O
of	O
(	O
samples	O
drawn	O
independently	O
at	O
each	O
update	O
step	O
)	O
during	O
epochs	O
.	O
	
The	O
output	O
image	O
size	O
used	O
as	O
a	O
baseline	O
is	O
.	O
	
Also	O
,	O
we	O
train	O
the	O
cGAN	B-Method
with	O
the	O
matching	B-Method
-	I-Method
aware	I-Method
discriminator	I-Method
method	I-Method
from	O
Reed	O
et	O
al	O
.	O
.	O
	
In	O
Figure	O
[	O
reference	O
]	O
we	O
show	O
an	O
overview	O
architecture	O
of	O
both	O
generator	B-Method
and	I-Method
discriminator	I-Method
for	O
the	O
cGAN	B-Method
.	O
	
For	O
a	O
more	O
detailed	O
description	O
of	O
the	O
model	O
see	O
Table	O
[	O
reference	O
]	O
.	O
	
[	O
]	O
[	O
width=0.50	O
]	O
images	O
/	O
5.impl	O
/	O
cGAN_G_arch	O
[	O
]	O
	
[	O
width=0.475	O
]	O
images	O
/	O
5.impl	O
/	O
cGAN_D_arch	O
	
width=1.0	O
Encoder	O
	
For	O
simplicity	O
,	O
we	O
show	O
the	O
architecture	O
of	O
the	O
IND	B-Method
encoders	I-Method
(	O
Table	O
[	O
reference	O
]	O
)	O
,	O
as	O
they	O
are	O
the	O
ones	O
that	O
give	O
the	O
best	O
performance	O
.	O
	
Batch	B-Method
Normalization	I-Method
and	O
non	O
-	O
linear	O
activation	O
functions	O
are	O
removed	O
from	O
the	O
last	O
layer	O
to	O
guarantee	O
that	O
the	O
output	O
distribution	O
is	O
similar	O
to	O
.	O
	
Additionally	O
,	O
after	O
trying	O
different	O
configurations	O
,	O
we	O
have	O
replaced	O
the	O
last	O
two	O
convolutional	O
layers	O
with	O
two	O
fully	O
connected	O
layers	O
at	O
the	O
end	O
of	O
the	O
encoder	O
,	O
which	O
yields	O
a	O
lower	O
error	O
.	O
	
The	O
training	O
configuration	O
(	O
Adam	B-Method
optimizer	I-Method
,	O
batch	O
size	O
,	O
etc	O
)	O
is	O
the	O
same	O
as	O
the	O
one	O
used	O
for	O
the	O
cGAN	B-Method
model	I-Method
.	O
	
width=0.6	O
	
section	O
:	O
Experiments	O
	
subsection	O
:	O
Datasets	O
	
We	O
use	O
two	O
image	O
datasets	O
of	O
different	O
complexity	O
and	O
variation	O
,	O
MNIST	B-Material
LeCun1998	O
and	O
CelebFaces	B-Material
Attributes	I-Material
(	O
CelebA	B-Material
)	O
celeba	B-Material
.	O
	
MNIST	B-Material
is	O
a	O
digit	O
dataset	O
of	O
grayscale	O
images	O
composed	O
of	O
60	O
,	O
000	O
training	O
images	O
and	O
10	O
,	O
000	O
test	O
images	O
.	O
	
Each	O
sample	O
is	O
a	O
centered	O
image	O
labeled	O
with	O
the	O
class	O
of	O
the	O
digit	O
(	O
0	O
to	O
9	O
)	O
.	O
	
CelebA	B-Material
is	O
a	O
dataset	O
composed	O
of	O
202	O
,	O
599	O
face	O
colored	O
images	O
and	O
40	O
attribute	O
binary	O
vectors	O
.	O
	
We	O
use	O
the	O
aligned	O
and	O
cropped	O
version	O
and	O
scale	O
the	O
images	O
down	O
to	O
.	O
	
We	O
also	O
use	O
the	O
official	O
train	O
and	O
test	O
partitions	O
,	O
182	O
K	O
for	O
training	O
and	O
20	O
K	O
for	O
testing	O
.	O
	
Of	O
the	O
original	O
40	O
attributes	O
,	O
we	O
filter	O
those	O
that	O
do	O
not	O
have	O
a	O
clear	O
visual	O
impact	O
on	O
the	O
generated	O
images	O
,	O
which	O
leaves	O
a	O
total	O
of	O
18	O
attributes	O
.	O
	
We	O
will	O
evaluate	O
the	O
quality	O
of	O
generated	O
samples	O
of	O
both	O
datasets	O
.	O
	
However	O
,	O
a	O
quantitative	O
evaluation	O
will	O
be	O
performed	O
on	O
CelebA	B-Material
only	O
,	O
as	O
it	O
is	O
considerably	O
more	O
complex	O
than	O
MNIST	B-Material
.	O
	
subsection	O
:	O
Evaluating	O
the	O
conditional	O
GAN	B-Method
	
The	O
goals	O
of	O
this	O
experiment	O
are	O
two	O
.	O
	
First	O
,	O
we	O
evaluate	O
the	O
general	O
performance	O
of	O
the	O
cGAN	B-Method
with	O
an	O
attribute	B-Method
predictor	I-Method
network	I-Method
(	O
Anet	B-Method
)	O
on	O
CelebA	B-Material
dataset	O
.	O
	
Second	O
,	O
we	O
test	O
the	O
impact	O
of	O
adding	O
in	O
different	O
layers	O
of	O
the	O
cGAN	B-Method
(	O
section	O
[	O
reference	O
]	O
,	O
conditional	O
position	O
)	O
.	O
	
We	O
use	O
an	O
Anet	O
as	O
a	O
way	O
to	O
make	O
a	O
quantitative	O
evaluation	O
in	O
a	O
similar	O
manner	O
as	O
Salimans	O
et	O
al	O
.	O
	
Inception	B-Method
model	I-Method
,	O
as	O
the	O
output	O
given	O
by	O
this	O
Anet	O
(	O
i.e.	O
,	O
which	O
attributes	O
are	O
detected	O
on	O
a	O
generated	O
sample	O
)	O
is	O
a	O
good	O
indicator	O
of	O
the	O
generator	O
ability	O
to	O
model	O
them	O
.	O
	
In	O
other	O
words	O
,	O
if	O
the	O
predicted	O
Anet	O
attributes	O
are	O
closer	O
to	O
the	O
original	O
attributes	O
used	O
to	O
generate	O
an	O
image	O
,	O
we	O
expect	O
that	O
the	O
generator	O
has	O
successfully	O
learned	O
the	O
capability	O
to	O
generate	O
new	O
images	O
considering	O
the	O
semantic	O
meaning	O
of	O
the	O
attributes	O
.	O
	
Therefore	O
,	O
we	O
use	O
the	O
generator	O
to	O
create	O
images	O
conditioned	O
on	O
attribute	O
vectors	O
(	O
i.e.	O
)	O
,	O
and	O
make	O
the	O
Anet	O
predict	O
them	O
.	O
	
Using	O
the	O
Anet	O
output	O
,	O
we	O
build	O
a	O
confusion	O
matrix	O
for	O
each	O
attribute	O
and	O
compute	O
the	O
mean	B-Metric
accuracy	I-Metric
and	O
F1	B-Metric
-	I-Metric
Score	I-Metric
to	O
test	O
the	O
model	O
and	O
its	O
inserted	O
optimal	O
position	O
of	O
in	O
both	O
generator	O
and	O
discriminator	B-Method
.	O
	
width=0.80	O
In	O
Table	O
[	O
reference	O
]	O
we	O
can	O
see	O
how	O
cGANs	B-Method
have	O
successfully	O
learned	O
to	O
generate	O
the	O
visual	B-Method
representations	I-Method
of	O
the	O
conditional	O
attributes	O
with	O
an	O
overall	O
accuracy	B-Metric
of	O
%	O
.	O
	
The	O
best	O
accuracy	B-Metric
is	O
achieved	O
by	O
inserting	O
in	O
the	O
first	O
convolutional	B-Method
layer	I-Method
of	O
the	O
discriminator	B-Method
and	O
at	O
the	O
input	O
level	O
for	O
the	O
generator	B-Method
.	O
	
Thus	O
,	O
we	O
are	O
going	O
to	O
use	O
this	O
configuration	O
for	O
the	O
IcGAN	B-Method
.	O
	
Both	O
accuracy	B-Metric
and	O
F1	B-Metric
-	I-Metric
Score	I-Metric
are	O
similar	O
as	O
long	O
as	O
is	O
not	O
inserted	O
in	O
the	O
last	O
convolutional	O
layers	O
,	O
in	O
which	O
case	O
the	O
performance	O
considerably	O
drops	O
,	O
especially	O
in	O
the	O
generator	B-Task
.	O
	
Then	O
,	O
these	O
results	O
reinforce	O
our	O
initial	O
intuition	O
of	O
being	O
added	O
at	O
an	O
early	O
stage	O
of	O
the	O
model	O
to	O
allow	O
learning	O
interactions	O
with	O
it	O
.	O
	
subsection	O
:	O
Evaluating	O
the	O
encoder	O
	
In	O
this	O
experiment	O
,	O
we	O
prioritize	O
the	O
visual	B-Metric
quality	I-Metric
of	I-Metric
reconstructed	I-Metric
samples	I-Metric
as	O
an	O
evaluation	B-Metric
criterion	I-Metric
.	O
	
Among	O
the	O
different	O
encoder	O
configurations	O
of	O
section	O
[	O
reference	O
]	O
,	O
IND	B-Method
and	O
IND	B-Method
-	I-Method
COND	I-Method
yield	O
a	O
similar	O
qualitative	O
performance	O
,	O
being	O
IND	B-Method
slightly	O
superior	O
.	O
	
A	O
comparison	O
of	O
these	O
different	O
configurations	O
is	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
a	O
and	O
in	O
Figure	O
[	O
reference	O
]	O
b	O
we	O
focus	O
on	O
IND	B-Material
reconstructed	I-Material
samples	I-Material
.	O
	
On	O
another	O
level	O
,	O
the	O
fact	O
that	O
the	O
generator	B-Method
is	O
able	O
,	O
via	O
an	O
encoder	B-Method
,	O
to	O
reconstruct	O
unseen	O
images	O
from	O
the	O
test	O
set	O
shows	O
that	O
the	O
cGAN	B-Method
is	O
generalizing	O
and	O
suggests	O
that	O
it	O
does	O
not	O
suffer	O
from	O
overfitting	O
,	O
i.e.	O
,	O
it	O
is	O
not	O
just	O
memorizing	O
and	O
reproducing	O
training	O
samples	O
.	O
	
Additionally	O
,	O
we	O
compare	O
the	O
different	O
encoder	O
configurations	O
in	O
a	O
quantitative	O
manner	O
by	O
using	O
the	O
minimal	B-Metric
squared	I-Metric
reconstruction	I-Metric
loss	I-Metric
as	O
a	O
criterion	O
.	O
	
Each	O
encoder	B-Method
is	O
trained	O
minimizing	O
with	O
respect	O
to	O
latent	O
representations	O
(	O
)	O
or	O
conditional	O
information	O
(	O
)	O
.	O
	
Then	O
,	O
we	O
quantitatively	O
evaluate	O
different	O
model	B-Method
architectures	I-Method
using	O
as	O
a	O
metric	O
on	O
a	O
test	O
set	O
of	O
150	O
K	O
CelebA	B-Material
generated	I-Material
images	I-Material
.	O
	
We	O
find	O
that	O
the	O
encoder	B-Method
that	O
yields	O
the	O
lowest	O
is	O
also	O
IND	O
(	O
0.429	O
)	O
,	O
followed	O
closely	O
by	O
IND	B-Method
-	I-Method
CND	I-Method
(	O
0.432	O
)	O
,	O
and	O
being	O
SNG	B-Method
the	O
worst	O
case	O
(	O
0.500	O
)	O
.	O
	
Furthermore	O
,	O
we	O
can	O
see	O
an	O
interesting	O
property	O
of	O
minimizing	O
a	O
loss	B-Task
based	O
on	O
the	O
latent	O
space	O
instead	O
of	O
a	O
pixel	B-Method
-	I-Method
wise	I-Method
image	I-Method
reconstruction	I-Method
:	O
reconstructed	O
images	O
tend	O
to	O
accurately	O
keep	O
high	O
-	O
level	O
features	O
of	O
an	O
input	O
image	O
(	O
e.g.	O
how	O
a	O
face	O
generally	O
looks	O
)	O
in	O
detriment	O
to	O
more	O
local	O
details	O
such	O
as	O
the	O
exact	O
position	O
of	O
the	O
hair	O
,	O
eyes	O
or	O
face	O
.	O
	
Consequently	O
,	O
a	O
latent	B-Method
space	I-Method
based	I-Method
encoder	I-Method
is	O
invariant	O
to	O
these	O
local	O
details	O
,	O
making	O
it	O
an	O
interesting	O
approach	O
for	O
encoding	B-Task
purposes	I-Task
.	O
	
For	O
example	O
,	O
notice	O
how	O
the	O
reconstructions	O
in	O
the	O
last	O
row	O
of	O
CelebA	B-Material
samples	O
in	O
Figure	O
[	O
reference	O
]	O
	
b	O
fill	O
the	O
occluded	O
part	O
of	O
the	O
face	O
by	O
a	O
hand	O
.	O
	
Another	O
advantage	O
with	O
respect	O
to	O
element	B-Method
-	I-Method
wise	I-Method
encoders	I-Method
such	O
as	O
VAE	B-Method
is	O
that	O
GAN	B-Method
based	O
reconstructions	O
do	O
not	O
look	O
blurry	O
.	O
	
[	O
]	O
[	O
width=0.3255	O
]	O
images	O
/	O
6.exp	O
/	O
encoders_comparison	O
[	O
]	O
[	O
width=0.525	O
]	O
images	O
/	O
6.exp	O
/	O
encoder_reconstructions_all	O
	
subsection	O
:	O
Evaluating	O
the	O
IcGAN	B-Method
	
In	O
order	O
to	O
test	O
that	O
the	O
model	O
is	O
able	O
to	O
correctly	O
encode	O
and	O
re	O
-	O
generate	O
a	O
real	O
image	O
by	O
preserving	O
its	O
main	O
attributes	O
,	O
we	O
take	O
real	O
samples	O
from	O
MNIST	B-Material
and	O
CelebA	B-Material
test	O
sets	O
and	O
reconstruct	O
them	O
with	O
modifications	O
on	O
the	O
conditional	O
information	O
.	O
	
The	O
result	O
of	O
this	O
procedure	O
is	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
where	O
we	O
show	O
a	O
subset	O
of	O
9	O
of	O
the	O
18	O
for	O
CelebA	B-Material
attributes	O
for	O
image	O
clarity	O
.	O
	
We	O
can	O
see	O
that	O
,	O
in	O
MNIST	B-Material
,	O
we	O
are	O
able	O
to	O
get	O
the	O
hand	O
-	O
written	O
style	O
of	O
real	O
unseen	O
digits	O
and	O
replicate	O
these	O
style	O
on	O
all	O
the	O
other	O
digits	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
in	O
CelebA	B-Material
we	O
can	O
see	O
how	O
reconstructed	O
faces	O
generally	O
match	O
the	O
specified	O
attribute	O
.	O
	
Additionally	O
,	O
we	O
noticed	O
that	O
faces	O
with	O
uncommon	O
conditions	O
(	O
e.g.	O
,	O
looking	O
away	O
from	O
the	O
camera	O
,	O
face	O
not	O
centered	O
)	O
were	O
the	O
most	O
likely	O
to	O
be	O
noisy	O
.	O
	
Furthermore	O
,	O
attributes	O
such	O
as	O
mustache	O
often	O
fail	O
to	O
be	O
generated	O
especially	O
on	O
women	O
samples	O
,	O
which	O
might	O
indicate	O
that	O
the	O
generator	O
is	O
limited	O
to	O
some	O
unusual	O
attribute	O
combinations	O
.	O
	
[	O
]	O
	
[	O
width=0.95	O
]	O
images	O
/	O
6.exp	O
/	O
icgan_mnist_final_small	O
[	O
]	O
[	O
	
width=0.95	O
]	O
images	O
/	O
6.exp	O
/	O
icgan_celeba_final_smaller	O
Manipulating	O
the	O
latent	O
space	O
	
The	O
latent	B-Method
feature	I-Method
representation	I-Method
and	O
conditional	O
information	O
learned	O
by	O
the	O
generator	O
can	O
be	O
further	O
explored	O
beyond	O
encoding	O
real	O
images	O
or	O
randomly	B-Task
sampling	I-Task
.	O
	
In	O
order	O
to	O
do	O
so	O
,	O
we	O
linearly	O
interpolate	O
both	O
and	O
with	O
pairs	O
of	O
reconstructed	O
images	O
from	O
the	O
CelebA	B-Material
test	O
set	O
(	O
Figure	O
[	O
reference	O
]	O
a	O
)	O
.	O
	
All	O
the	O
interpolated	O
faces	O
are	O
plausible	O
and	O
the	O
transition	O
between	O
faces	O
is	O
smooth	O
,	O
demonstrating	O
that	O
the	O
IcGAN	B-Method
learned	O
manifold	O
is	O
also	O
consistent	O
between	O
interpolations	O
.	O
	
Then	O
,	O
this	O
is	O
also	O
a	O
good	O
indicator	O
that	O
the	O
model	O
is	O
generalizing	O
the	O
face	B-Method
representation	I-Method
properly	O
,	O
as	O
it	O
is	O
not	O
directly	O
memorizing	O
training	O
samples	O
.	O
	
In	O
addition	O
,	O
we	O
perform	O
in	O
Figure	O
[	O
reference	O
]	O
b	O
an	O
attribute	B-Task
transfer	I-Task
between	O
pairs	O
of	O
faces	O
.	O
	
We	O
infer	O
the	O
latent	O
representation	O
and	O
attribute	O
information	O
of	O
two	O
real	O
faces	O
from	O
the	O
test	O
set	O
,	O
swap	O
between	O
those	O
faces	O
and	O
re	O
-	O
generate	O
them	O
.	O
	
As	O
we	O
previously	O
noticed	O
,	O
the	O
results	O
suggest	O
that	O
encodes	O
pose	O
,	O
illumination	O
and	O
background	O
information	O
,	O
while	O
tends	O
to	O
represent	O
unique	O
features	O
of	O
the	O
face	O
.	O
	
[	O
]	O
[	O
width=0.555	O
]	O
images	O
/	O
6.exp	O
/	O
icgan_interpolations	O
[	O
]	O
	
[	O
width=0.44	O
]	O
images	O
/	O
6.exp	O
	
/	O
icgan_attributeTransfer	O
	
section	O
:	O
Conclusions	O
	
We	O
introduce	O
an	O
encoder	B-Method
in	O
a	O
conditional	B-Task
setting	I-Task
within	O
the	O
GAN	B-Method
framework	O
,	O
a	O
model	O
which	O
we	O
call	O
Invertible	B-Method
Conditional	I-Method
GANs	I-Method
(	O
IcGANs	B-Method
)	O
.	O
	
It	O
solves	O
the	O
problem	O
of	O
GANs	B-Method
lacking	O
the	O
ability	O
to	O
infer	O
real	O
samples	O
to	O
a	O
latent	B-Method
representation	I-Method
,	O
while	O
also	O
allowing	O
to	O
explicitly	O
control	O
complex	O
attributes	O
of	O
generated	O
samples	O
with	O
conditional	O
information	O
.	O
	
We	O
also	O
refine	O
the	O
performance	O
of	O
cGANS	B-Method
by	O
testing	O
the	O
optimal	O
position	O
in	O
which	O
the	O
conditional	O
information	O
is	O
inserted	O
in	O
the	O
model	O
.	O
	
We	O
have	O
found	O
that	O
for	O
the	O
generator	B-Method
,	O
should	O
be	O
added	O
at	O
the	O
input	O
level	O
,	O
whereas	O
the	O
discriminator	B-Method
works	O
best	O
when	O
is	O
at	O
the	O
first	O
layer	O
.	O
	
Additionally	O
,	O
we	O
evaluate	O
several	O
ways	O
to	O
training	O
an	O
encoder	B-Method
.	O
	
Training	O
two	O
independent	O
encoders	B-Method
–	O
one	O
for	O
encoding	B-Task
and	O
another	O
for	O
encoding	B-Task
–	O
has	O
proven	O
to	O
be	O
the	O
best	O
option	O
in	O
our	O
experiments	O
.	O
	
The	O
results	O
obtained	O
with	O
a	O
complex	O
face	O
dataset	O
,	O
CelebA	B-Material
,	O
are	O
satisfactory	O
and	O
promising	O
.	O
	
Acknowledgments	O
	
This	O
work	O
is	O
funded	O
by	O
the	O
Projects	O
TIN2013	O
-	O
41751	O
-	O
P	O
of	O
the	O
Spanish	O
Ministry	O
of	O
Science	O
and	O
the	O
CHIST	O
ERA	O
project	O
PCIN	O
-	O
2015	O
-	O
226	O
.	O
	
bibliography	O
:	O
References	O
	
Asymmetric	B-Method
Tri	I-Method
-	I-Method
training	I-Method
for	O
Unsupervised	B-Task
Domain	I-Task
Adaptation	I-Task
	
section	O
:	O
Abstract	O
	
Deep	B-Method
-	I-Method
layered	I-Method
models	I-Method
trained	O
on	O
a	O
large	O
number	O
of	O
labeled	O
samples	O
boost	O
the	O
accuracy	B-Metric
of	O
many	O
tasks	O
.	O
	
It	O
is	O
important	O
to	O
apply	O
such	O
models	O
to	O
different	O
domains	O
because	O
collecting	O
many	O
labeled	O
samples	O
in	O
various	O
domains	O
is	O
expensive	O
.	O
	
In	O
unsupervised	B-Task
domain	I-Task
adaptation	I-Task
,	O
one	O
needs	O
to	O
train	O
a	O
classifier	B-Method
that	O
works	O
well	O
on	O
a	O
target	O
domain	O
when	O
provided	O
with	O
labeled	O
source	O
samples	O
and	O
unlabeled	O
target	O
samples	O
.	O
	
Although	O
many	O
methods	O
aim	O
to	O
match	O
the	O
distributions	O
of	O
source	O
and	O
target	O
samples	O
,	O
simply	O
matching	O
the	O
distribution	O
can	O
not	O
ensure	O
accuracy	B-Metric
on	O
the	O
target	O
domain	O
.	O
	
To	O
learn	O
discriminative	B-Method
representations	I-Method
for	O
the	O
target	O
domain	O
,	O
we	O
assume	O
that	O
artificially	O
labeling	O
target	O
samples	O
can	O
result	O
in	O
a	O
good	O
representation	O
.	O
	
Tri	B-Method
-	I-Method
training	I-Method
leverages	O
three	O
classifiers	B-Method
equally	O
to	O
give	O
pseudo	O
-	O
labels	O
to	O
unlabeled	O
samples	O
,	O
but	O
the	O
method	O
does	O
not	O
assume	O
labeling	O
samples	O
generated	O
from	O
a	O
different	O
domain	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
an	O
asymmetric	O
tri	B-Method
-	I-Method
training	I-Method
method	O
for	O
unsupervised	B-Task
domain	I-Task
adaptation	I-Task
,	O
where	O
we	O
assign	O
pseudo	O
-	O
labels	O
to	O
unlabeled	O
samples	O
and	O
train	O
neural	B-Method
networks	I-Method
as	O
if	O
they	O
are	O
true	O
labels	O
.	O
	
In	O
our	O
work	O
,	O
we	O
use	O
three	O
networks	O
asymmetrically	O
.	O
	
By	O
asymmetric	O
,	O
we	O
mean	O
that	O
two	O
networks	O
are	O
used	O
to	O
label	O
unlabeled	O
target	O
samples	O
and	O
one	O
network	O
is	O
trained	O
by	O
the	O
samples	O
to	O
obtain	O
targetdiscriminative	B-Method
representations	I-Method
.	O
	
We	O
evaluate	O
our	O
method	O
on	O
digit	B-Task
recognition	I-Task
and	O
sentiment	O
analysis	O
datasets	O
.	O
	
Our	O
proposed	O
method	O
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
the	O
benchmark	O
digit	O
recognition	O
datasets	O
of	O
domain	B-Task
adaptation	I-Task
.	O
	
section	O
:	O
Introduction	O
	
With	O
the	O
development	O
of	O
deep	B-Method
neural	I-Method
networks	I-Method
including	O
deep	O
convolutional	O
neural	O
networks	O
(	O
CNN	B-Method
)	O
[	O
reference	O
]	O
	
The	O
University	O
of	O
Tokyo	O
,	O
Tokyo	O
,	O
Japan	O
.	O
	
Correspondence	O
to	O
:	O
Kuniaki	O
Saito	O
<	O
k	O
	
-	O
saito@mi.t.u	O
-	O
tokyo.ac.jp	O
>	O
,	O
Yoshitaka	O
Ushiku	O
<	O
ushiku@mi.t.u	O
	
-	O
tokyo.ac.jp	O
>	O
,	O
Tatsuya	O
Harada	O
<	O
	
harada@mi.t.u	O
-	O
tokyo.ac.jp>.	O
	
[	O
reference	O
]	O
,	O
the	O
recognition	B-Task
abilities	O
of	O
images	O
and	O
languages	O
have	O
improved	O
dramatically	O
.	O
	
Training	O
deep	B-Method
-	I-Method
layered	I-Method
networks	I-Method
with	O
a	O
large	O
number	O
of	O
labeled	O
samples	O
enables	O
us	O
to	O
correctly	O
categorize	O
samples	O
in	O
diverse	O
domains	O
.	O
	
In	O
addition	O
,	O
the	O
transfer	O
learning	O
of	O
CNN	B-Method
is	O
utilized	O
in	O
many	O
studies	O
.	O
	
For	O
object	B-Task
detection	I-Task
or	I-Task
segmentation	I-Task
,	O
we	O
can	O
transfer	O
the	O
knowledge	O
of	O
a	O
CNN	B-Method
trained	O
with	O
a	O
large	O
-	O
scale	O
dataset	O
by	O
fine	O
-	O
tuning	O
it	O
on	O
a	O
relatively	O
small	O
dataset	O
	
[	O
reference	O
][	O
reference	O
]	O
.	O
	
Moreover	O
,	O
features	O
from	O
a	O
CNN	B-Method
trained	O
on	O
ImageNet	B-Material
[	O
reference	O
]	O
)	O
are	O
useful	O
for	O
multimodal	B-Task
learning	I-Task
tasks	I-Task
including	O
image	B-Task
captioning	I-Task
[	O
reference	O
]	O
and	O
visual	B-Task
question	I-Task
answering	I-Task
[	O
reference	O
]	O
.	O
	
One	O
of	O
the	O
problems	O
of	O
neural	B-Method
networks	I-Method
is	O
that	O
although	O
they	O
perform	O
well	O
on	O
the	O
samples	O
generated	O
from	O
the	O
same	O
distribution	O
as	O
the	O
training	O
samples	O
,	O
they	O
may	O
find	O
it	O
difficult	O
to	O
correctly	O
recognize	O
samples	O
from	O
different	O
distributions	O
at	O
the	O
test	O
time	O
.	O
	
One	O
example	O
is	O
images	O
collected	O
from	O
the	O
Internet	B-Material
,	O
which	O
may	O
come	O
in	O
abundance	O
and	O
be	O
fully	O
labeled	O
.	O
	
They	O
have	O
a	O
distribution	O
different	O
from	O
the	O
images	O
taken	O
from	O
a	O
camera	O
.	O
	
Thus	O
,	O
a	O
classifier	B-Method
that	O
performs	O
well	O
on	O
various	O
domains	O
is	O
important	O
for	O
practical	O
use	O
.	O
	
To	O
realize	O
this	O
,	O
it	O
is	O
necessary	O
to	O
learn	O
domain	B-Method
-	I-Method
invariantly	I-Method
discriminative	I-Method
representations	I-Method
.	O
	
However	O
,	O
acquiring	O
such	O
representations	O
is	O
not	O
easy	O
because	O
it	O
is	O
often	O
difficult	O
to	O
collect	O
a	O
large	O
number	O
of	O
labeled	O
samples	O
and	O
because	O
samples	O
from	O
different	O
domains	O
have	O
domain	O
-	O
specific	O
characteristics	O
.	O
	
In	O
unsupervised	B-Task
domain	I-Task
adaptation	I-Task
,	O
we	O
try	O
to	O
train	O
a	O
classifier	B-Method
that	O
works	O
well	O
on	O
a	O
target	O
domain	O
on	O
the	O
condition	O
that	O
we	O
are	O
provided	O
labeled	O
source	O
samples	O
and	O
unlabeled	O
target	O
samples	O
during	O
training	O
.	O
	
Most	O
of	O
the	O
previous	O
deep	B-Method
domain	I-Method
adaptation	I-Method
methods	I-Method
have	O
been	O
proposed	O
mainly	O
under	O
the	O
assumption	O
that	O
the	O
adaptation	B-Task
can	O
be	O
realized	O
by	O
matching	O
the	O
distribution	O
of	O
features	O
from	O
different	O
domains	O
.	O
	
These	O
methods	O
aimed	O
to	O
obtain	O
domain	O
-	O
invariant	O
features	O
by	O
minimizing	O
the	O
divergence	O
between	O
domains	O
as	O
well	O
as	O
a	O
category	O
loss	O
on	O
the	O
source	O
domain	O
	
[	O
reference	O
][	O
reference	O
]	O
.	O
	
However	O
,	O
as	O
shown	O
in	O
[	O
reference	O
]	O
,	O
theoretically	O
,	O
if	O
a	O
classifier	B-Method
that	O
works	O
well	O
on	O
both	O
the	O
source	O
and	O
the	O
target	O
domains	O
does	O
not	O
exist	O
,	O
we	O
can	O
not	O
expect	O
a	O
discriminative	B-Method
classifier	I-Method
for	O
the	O
target	O
domain	O
.	O
	
That	O
is	O
,	O
even	O
if	O
the	O
distributions	O
are	O
matched	O
on	O
the	O
nondiscriminative	B-Method
representations	I-Method
,	O
the	O
classifier	B-Method
may	O
not	O
work	O
:	O
$	O
'	O
1.0;"#	O
-	O
'"'.	O
/	O
7#	O
(	O
8'7	O
/	O
$#34"'$	O
*	O
Figure	O
1	O
.	O
	
Outline	O
of	O
our	O
model	O
.	O
	
We	O
assign	O
pseudo	O
-	O
labels	O
to	O
unlabeled	O
target	O
samples	O
based	O
on	O
the	O
predictions	O
from	O
two	O
classifiers	B-Method
trained	O
on	O
source	O
samples	O
.	O
	
well	O
on	O
the	O
target	O
domain	O
.	O
	
Since	O
directly	O
learning	O
discriminative	B-Method
representations	I-Method
for	O
the	O
target	O
domain	O
,	O
in	O
the	O
absence	O
of	O
target	O
labels	O
,	O
is	O
considered	O
very	O
difficult	O
,	O
we	O
propose	O
to	O
assign	O
pseudo	O
-	O
labels	O
to	O
target	O
samples	O
and	O
train	O
targetspecific	B-Method
networks	I-Method
as	O
if	O
they	O
were	O
true	O
labels	O
.	O
	
Co	B-Method
-	I-Method
training	I-Method
and	O
tri	B-Method
-	I-Method
training	I-Method
[	O
reference	O
]	O
leverage	O
multiple	O
classifiers	B-Method
to	O
artificially	O
label	O
unlabeled	O
samples	O
and	O
retrain	O
the	O
classifiers	O
.	O
	
However	O
,	O
the	O
methods	O
do	O
not	O
assume	O
labeling	O
samples	O
from	O
different	O
domains	O
.	O
	
Since	O
our	O
goal	O
is	O
to	O
classify	O
unlabeled	O
target	O
samples	O
that	O
have	O
different	O
characteristics	O
from	O
labeled	O
source	O
samples	O
,	O
we	O
propose	O
asymmetric	O
tri	B-Method
-	I-Method
training	I-Method
for	O
unsupervised	B-Task
domain	I-Task
adaptation	I-Task
.	O
	
By	O
asymmetric	O
,	O
we	O
mean	O
that	O
we	O
assign	O
different	O
roles	O
to	O
three	O
classifiers	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
novel	O
tri	B-Method
-	I-Method
training	I-Method
method	O
for	O
unsupervised	B-Task
domain	I-Task
adaptation	I-Task
,	O
where	O
we	O
assign	O
pseudolabels	O
to	O
unlabeled	O
samples	O
and	O
train	O
neural	B-Method
networks	I-Method
utilizing	O
the	O
samples	O
.	O
	
As	O
described	O
in	O
Fig	O
.	O
1	O
,	O
two	O
networks	O
are	O
used	O
to	O
label	O
unlabeled	O
target	O
samples	O
and	O
the	O
remaining	O
network	O
is	O
trained	O
by	O
the	O
pseudo	O
-	O
labeled	O
target	O
samples	O
.	O
	
Our	O
method	O
does	O
not	O
need	O
any	O
special	O
implementations	O
.	O
	
We	O
evaluate	O
our	O
method	O
on	O
the	O
digit	B-Task
classification	I-Task
task	I-Task
,	O
traffic	B-Task
sign	I-Task
classification	I-Task
task	I-Task
and	O
sentiment	B-Task
analysis	I-Task
task	I-Task
using	O
the	O
Amazon	B-Material
Review	I-Material
dataset	I-Material
,	O
and	O
demonstrate	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
in	O
nearly	O
all	O
experiments	O
.	O
	
In	O
particular	O
,	O
in	O
the	O
adaptation	B-Task
scenario	I-Task
,	O
MNIST→SVHN	B-Method
,	O
our	O
method	O
outperformed	O
other	O
methods	O
by	O
more	O
than	O
10	O
%	O
.	O
	
section	O
:	O
Related	O
Work	O
	
As	O
many	O
methods	O
have	O
been	O
proposed	O
to	O
tackle	O
various	O
tasks	O
in	O
domain	B-Task
adaptation	I-Task
,	O
we	O
present	O
details	O
of	O
the	O
research	O
most	O
closely	O
related	O
to	O
our	O
paper	O
.	O
	
A	O
number	O
of	O
previous	O
methods	O
attempted	O
to	O
realize	O
adaptation	B-Task
by	O
utilizing	O
the	O
measurement	O
of	O
divergence	O
between	O
different	O
domains	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
The	O
methods	O
are	O
based	O
on	O
the	O
theory	O
proposed	O
in	O
[	O
reference	O
]	O
,	O
which	O
states	O
that	O
the	O
expected	O
loss	O
for	O
a	O
target	O
domain	O
is	O
bounded	O
by	O
three	O
terms	O
:	O
(	O
i	O
)	O
expected	B-Metric
loss	I-Metric
for	O
the	O
source	O
domain	O
;	O
(	O
ii	O
)	O
domain	O
divergence	O
between	O
source	O
and	O
target	O
;	O
and	O
(	O
iii	O
)	O
the	O
minimum	O
value	O
of	O
a	O
shared	B-Metric
expected	I-Metric
loss	I-Metric
.	O
	
The	O
shared	B-Metric
expected	I-Metric
loss	I-Metric
means	O
the	O
sum	O
of	O
the	O
loss	O
on	O
the	O
source	O
and	O
target	O
domain	O
.	O
	
As	O
the	O
third	O
term	O
,	O
which	O
is	O
usually	O
considered	O
to	O
be	O
very	O
low	O
,	O
can	O
not	O
be	O
evaluated	O
when	O
labeled	O
target	O
samples	O
are	O
absent	O
,	O
most	O
methods	O
try	O
to	O
minimize	O
the	O
first	O
term	O
and	O
the	O
second	O
term	O
.	O
	
With	O
regards	O
to	O
training	O
deep	B-Method
architectures	I-Method
,	O
the	O
maximum	B-Method
mean	I-Method
discrepancy	I-Method
(	O
MMD	B-Method
)	O
or	O
a	O
loss	B-Method
of	I-Method
domain	I-Method
classifier	I-Method
network	I-Method
is	O
utilized	O
to	O
measure	O
the	O
divergence	O
corresponding	O
to	O
the	O
second	O
term	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
	
However	O
,	O
the	O
third	O
term	O
is	O
very	O
important	O
in	O
training	O
CNN	B-Method
,	O
which	O
simultaneously	O
extract	O
representations	O
and	O
recognize	O
them	O
.	O
	
The	O
third	O
term	O
can	O
easily	O
be	O
large	O
when	O
the	O
representations	O
are	O
not	O
discriminative	O
for	O
the	O
target	O
domain	O
.	O
	
Therefore	O
,	O
we	O
focus	O
on	O
how	O
to	O
learn	O
target	B-Method
-	I-Method
discriminative	I-Method
representations	I-Method
considering	O
the	O
third	O
term	O
.	O
	
In	O
[	O
reference	O
]	O
)	O
the	O
focus	O
was	O
on	O
the	O
point	O
we	O
have	O
stated	O
and	O
a	O
target	O
-	O
specific	B-Method
classifier	I-Method
was	O
constructed	O
using	O
a	O
residual	B-Method
network	I-Method
structure	I-Method
.	O
	
Different	O
from	O
their	O
method	O
,	O
we	O
constructed	O
a	O
target	B-Method
-	I-Method
specific	I-Method
network	I-Method
by	O
providing	O
artificially	O
labeled	O
target	O
samples	O
.	O
	
Several	O
transductive	B-Method
methods	I-Method
use	O
similarity	O
of	O
features	O
to	O
provide	O
labels	O
for	O
unlabeled	O
samples	O
	
[	O
reference	O
][	O
reference	O
]	O
.	O
For	O
unsupervised	B-Task
domain	I-Task
adaptation	I-Task
,	O
in	O
[	O
reference	O
]	O
,	O
a	O
method	O
was	O
proposed	O
to	O
learn	O
labeling	O
metrics	O
by	O
using	O
the	O
k	O
-	O
nearest	O
neighbors	O
between	O
unlabeled	O
target	O
samples	O
and	O
labeled	O
source	O
samples	O
.	O
	
In	O
contrast	O
to	O
this	O
method	O
,	O
our	O
method	O
explicitly	O
and	O
simply	O
backpropagates	O
the	O
category	O
loss	O
for	O
target	O
samples	O
based	O
on	O
pseudo	O
-	O
labeled	O
samples	O
.	O
	
Our	O
approach	O
does	O
not	O
require	O
any	O
special	O
modules	O
.	O
	
Many	O
methods	O
proposed	O
to	O
give	O
pseudo	O
-	O
labels	O
to	O
unlabeled	O
samples	O
by	O
utilizing	O
the	O
predictions	O
of	O
a	O
classifier	B-Method
and	O
retraining	O
it	O
including	O
the	O
pseudo	O
-	O
labeled	O
samples	O
,	O
which	O
is	O
called	O
self	B-Task
-	I-Task
training	I-Task
.	O
	
The	O
underlying	O
assumption	O
of	O
selftraining	O
is	O
that	O
one	O
's	O
own	O
high	O
-	O
confidence	O
predictions	O
are	O
correct	O
	
[	O
reference	O
]	O
.	O
	
As	O
the	O
predictions	O
are	O
mostly	O
correct	O
,	O
utilizing	O
samples	O
with	O
high	O
confidence	O
will	O
further	O
improve	O
the	O
performance	O
of	O
the	O
classifier	B-Method
.	O
	
Co	B-Method
-	I-Method
training	I-Method
utilizes	O
two	O
classifiers	B-Method
,	O
which	O
have	O
different	O
views	O
on	O
one	O
sample	O
,	O
to	O
provide	O
pseudo	O
-	O
labels	O
	
[	O
reference	O
][	O
reference	O
]	O
.	O
	
Then	O
,	O
the	O
unlabeled	O
samples	O
are	O
added	O
to	O
training	O
set	O
if	O
at	O
least	O
one	O
classifier	B-Method
is	O
confident	O
about	O
the	O
predictions	O
.	O
	
The	O
generalization	B-Metric
ability	I-Metric
of	O
co	B-Method
-	I-Method
training	I-Method
is	O
theoretically	O
ensured	O
[	O
reference	O
][	O
reference	O
]	O
)	O
under	O
some	O
assumptions	O
and	O
applied	O
to	O
various	O
tasks	O
	
[	O
reference	O
][	O
reference	O
]	O
.	O
	
In	O
[	O
reference	O
]	O
,	O
the	O
idea	O
of	O
co	B-Method
-	I-Method
training	I-Method
was	O
incorporated	O
into	O
domain	B-Method
adaptation	I-Method
.	O
	
Tri	B-Method
-	I-Method
training	I-Method
can	O
be	O
regarded	O
as	O
the	O
extension	O
of	O
co	B-Method
-	I-Method
training	I-Method
[	O
reference	O
]	O
.	O
Similar	O
to	O
co	B-Method
-	I-Method
training	I-Method
,	O
tritraining	B-Method
uses	O
the	O
output	O
of	O
three	O
different	O
classifiers	B-Method
to	O
give	O
pseudo	O
-	O
labels	O
to	O
unlabeled	O
samples	O
.	O
	
Tri	B-Method
-	I-Method
training	I-Method
does	O
not	O
require	O
partitioning	O
features	O
into	O
different	O
views	O
;	O
instead	O
,	O
tri	B-Method
-	I-Method
training	I-Method
initializes	O
each	O
classifier	B-Method
differently	O
.	O
	
However	O
,	O
Figure	O
2	O
.	O
	
The	O
proposed	O
method	O
includes	O
a	O
shared	B-Method
feature	I-Method
extractor	I-Method
(	O
F	B-Method
)	O
,	O
classifiers	B-Method
for	O
labeled	O
samples	O
(	O
F1	O
,	O
F2	O
)	O
,	O
which	O
learn	O
from	O
labeled	O
source	O
samples	O
,	O
and	O
newly	O
labeled	O
target	O
samples	O
.	O
	
In	O
addition	O
,	O
a	O
target	B-Method
-	I-Method
specific	I-Method
classifier	I-Method
(	O
Ft	B-Method
)	O
learns	O
from	O
pseudo	O
-	O
labeled	O
target	O
samples	O
.	O
	
Our	O
method	O
first	O
trains	O
networks	O
from	O
only	O
labeled	O
source	O
samples	O
,	O
then	O
labels	O
the	O
target	O
samples	O
based	O
on	O
the	O
output	O
of	O
F1	O
,	O
F2	O
.	O
	
We	O
train	O
all	O
architectures	O
using	O
them	O
as	O
if	O
they	O
are	O
correctly	O
labeled	O
samples	O
.	O
	
tri	B-Method
-	I-Method
training	I-Method
does	O
not	O
assume	O
that	O
the	O
unlabeled	O
samples	O
follow	O
the	O
different	O
distributions	O
from	O
the	O
ones	O
which	O
labeled	O
samples	O
are	O
generated	O
from	O
.	O
	
Therefore	O
,	O
we	O
develop	O
a	O
tritraining	B-Method
method	I-Method
suitable	O
for	O
domain	B-Task
adaptation	I-Task
by	O
using	O
three	O
classifiers	B-Method
asymmetrically	O
.	O
	
In	O
[	O
reference	O
]	O
,	O
the	O
effect	O
of	O
pseudo	O
-	O
labels	O
in	O
a	O
neural	B-Method
network	I-Method
was	O
investigated	O
.	O
	
They	O
argued	O
that	O
the	O
effect	O
of	O
training	O
a	O
classifier	B-Method
with	O
pseudo	O
-	O
labels	O
is	O
equivalent	O
to	O
entropy	B-Method
regularization	I-Method
,	O
thus	O
leading	O
to	O
a	O
low	O
-	O
density	O
separation	O
between	O
classes	O
.	O
	
In	O
addition	O
,	O
in	O
our	O
experiment	O
,	O
we	O
observe	O
that	O
target	O
samples	O
are	O
separated	O
in	O
hidden	O
features	O
.	O
	
section	O
:	O
Method	O
	
In	O
this	O
section	O
,	O
we	O
provide	O
details	O
of	O
the	O
proposed	O
model	O
for	O
domain	B-Task
adaptation	I-Task
.	O
	
We	O
aim	O
to	O
construct	O
a	O
targetspecific	B-Method
network	I-Method
by	O
utilizing	O
pseudo	O
-	O
labeled	O
target	O
samples	O
.	O
	
Simultaneously	O
,	O
we	O
expect	O
two	O
labeling	B-Method
networks	I-Method
to	O
acquire	O
target	O
-	O
discriminative	O
representations	O
and	O
gradually	O
increase	O
accuracy	B-Metric
on	O
the	O
target	O
domain	O
.	O
	
We	O
show	O
our	O
proposed	O
network	B-Method
structure	I-Method
in	O
Fig	O
.	O
2	O
.	O
	
Here	O
F	O
denotes	O
the	O
network	O
which	O
outputs	O
shared	O
features	O
among	O
three	O
networks	O
,	O
F	O
1	O
and	O
F	O
2	O
classify	O
features	O
generated	O
from	O
F	O
.	O
	
Their	O
predictions	O
are	O
utilized	O
to	O
give	O
pseudo	O
-	O
labels	O
.	O
	
The	O
classifier	B-Method
F	I-Method
t	O
classifies	O
features	O
generated	O
from	O
F	O
,	O
which	O
is	O
a	O
target	B-Method
-	I-Method
specific	I-Method
network	I-Method
.	O
	
Here	O
F	O
1	O
,	O
F	O
2	O
learn	O
from	O
source	O
and	O
pseudo	O
-	O
labeled	O
target	O
samples	O
and	O
F	O
t	O
learns	O
only	O
from	O
pseudo	O
-	O
labeled	O
target	O
samples	O
.	O
	
The	O
shared	B-Method
network	I-Method
F	I-Method
learns	O
from	O
all	O
gradients	O
from	O
F	O
1	O
,	O
F	O
2	O
,	O
F	O
t	O
.	O
	
Without	O
such	O
a	O
shared	B-Method
network	I-Method
,	O
another	O
option	O
for	O
the	O
network	B-Method
architecture	I-Method
we	O
can	O
think	O
of	O
is	O
training	O
three	O
networks	O
separately	O
,	O
but	O
this	O
is	O
inefficient	O
in	O
terms	O
of	O
training	B-Task
and	O
implementation	B-Task
.	O
	
Furthermore	O
,	O
by	O
building	O
a	O
shared	B-Method
network	I-Method
F	I-Method
,	O
F	O
1	O
and	O
F	O
2	O
can	O
also	O
harness	O
the	O
target	O
-	O
discriminative	O
representations	O
learned	O
by	O
the	O
feedback	O
from	O
F	O
t	O
.	O
	
The	O
set	O
of	O
source	O
samples	O
is	O
defined	O
as	O
(	O
x	O
i	O
,	O
y	O
i	O
)	O
	
∼	O
T	O
,	O
and	O
the	O
pseudolabeled	O
target	O
set	O
is	O
	
section	O
:	O
Loss	B-Task
for	O
Multiview	B-Task
Features	I-Task
Network	I-Task
	
In	O
the	O
existing	O
works	O
[	O
reference	O
]	O
on	O
co	B-Method
-	I-Method
training	I-Method
for	O
domain	B-Task
adaptation	I-Task
,	O
given	O
features	O
are	O
divided	O
into	O
separate	O
parts	O
and	O
considered	O
to	O
be	O
different	O
views	O
.	O
	
As	O
we	O
aim	O
to	O
label	O
target	O
samples	O
with	O
high	O
accuracy	B-Metric
,	O
we	O
expect	O
F	O
1	O
,	O
F	O
2	O
to	O
classify	O
samples	O
based	O
on	O
different	O
viewpoints	O
.	O
	
Therefore	O
,	O
we	O
make	O
a	O
constraint	O
for	O
the	O
weight	O
of	O
F	O
1	O
,	O
F	O
2	O
to	O
make	O
their	O
inputs	O
different	O
to	O
each	O
other	O
.	O
	
We	O
add	O
the	O
term	O
	
|W	O
1	O
	
T	O
W	O
2	O
	
|	O
to	O
the	O
cost	O
function	O
,	O
where	O
W	O
1	O
,	O
W	O
2	O
denote	O
fully	O
connected	O
layers	O
'	O
weights	O
of	O
F	O
1	O
and	O
F	O
2	O
which	O
are	O
first	O
applied	O
to	O
the	O
feature	O
F	O
(	O
x	O
i	O
)	O
.	O
	
Each	O
network	O
will	O
learn	O
from	O
different	O
features	O
with	O
this	O
constraint	O
.	O
	
The	O
objective	O
for	O
learning	B-Task
F	I-Task
1	I-Task
,	O
F	O
2	O
is	O
defined	O
as	O
	
where	O
L	O
y	O
denotes	O
the	O
standard	O
softmax	B-Method
cross	I-Method
-	I-Method
entropy	I-Method
loss	I-Method
function	I-Method
.	O
	
We	O
decided	O
the	O
trade	O
-	O
off	O
parameter	O
λ	O
based	O
on	O
validation	O
split	O
.	O
	
section	O
:	O
Learning	B-Task
Procedure	I-Task
and	O
Labeling	B-Method
Method	I-Method
	
Pseudo	O
-	O
labeled	O
target	O
samples	O
will	O
provide	O
targetdiscriminative	O
information	O
to	O
the	O
network	O
.	O
	
However	O
,	O
since	O
they	O
certainly	O
contain	O
false	O
labels	O
,	O
we	O
have	O
to	O
pick	O
up	O
reliable	O
pseudo	O
-	O
labels	O
.	O
	
Our	O
labeling	B-Method
and	I-Method
learning	I-Method
method	I-Method
is	O
aimed	O
at	O
realizing	O
this	O
.	O
	
The	O
entire	O
procedure	O
of	O
training	O
the	O
network	O
is	O
shown	O
in	O
Algorithm	O
1	O
.	O
	
First	O
,	O
we	O
train	O
the	O
entire	O
network	O
with	O
source	O
training	O
set	O
S.	O
Here	O
F	O
1	O
,	O
F	O
2	O
are	O
optimized	O
by	O
Eq	O
.	O
	
(	O
1	O
)	O
	
and	O
F	B-Method
t	I-Method
is	O
trained	O
on	O
standard	O
category	B-Method
loss	I-Method
.	O
	
After	O
training	O
on	O
S	O
,	O
to	O
provide	O
pseudo	O
-	O
labels	O
,	O
we	O
use	O
predictions	O
of	O
F	O
1	O
and	O
F	O
2	O
,	O
namely	O
y	O
1	O
,	O
y	O
2	O
obtained	O
from	O
x	O
k	O
.	O
	
When	O
C	O
1	O
,	O
C	O
2	O
denote	O
the	O
class	O
which	O
has	O
the	O
maximum	O
predicted	O
probability	O
for	O
y	O
1	O
,	O
	
y	O
2	O
,	O
we	O
assign	O
a	O
pseudo	O
-	O
label	O
to	O
x	O
k	O
if	O
the	O
following	O
two	O
conditions	O
are	O
satisfied	O
.	O
	
First	O
,	O
we	O
require	O
C	O
1	O
=	O
C	O
2	O
to	O
give	O
pseudo	O
-	O
labels	O
,	O
which	O
means	O
two	O
different	O
classifiers	O
agree	O
with	O
the	O
prediction	O
.	O
	
The	O
second	O
requirement	O
is	O
that	O
the	O
maximizing	O
probability	O
of	O
y	O
1	O
or	O
y	O
2	O
exceeds	O
the	O
threshold	O
parameter	O
,	O
which	O
we	O
set	O
as	O
0.9	O
or	O
0.95	O
in	O
the	O
experiment	O
.	O
	
We	O
suppose	O
that	O
unless	O
one	O
of	O
two	O
classifiers	B-Method
is	O
confident	O
of	O
the	O
prediction	O
,	O
the	O
prediction	B-Task
is	O
not	O
reliable	O
.	O
	
If	O
the	O
two	O
requirements	O
are	O
satisfied	O
,	O
x	O
k	O
,	O
ŷ	O
k	O
=	O
C	O
1	O
	
=	O
C	O
2	O
is	O
added	O
to	O
T	O
l	O
.	O
	
To	O
prevent	O
the	O
overfitting	O
to	O
pseudo	O
-	O
labels	O
,	O
we	O
resample	O
the	O
candidate	O
for	O
labeling	O
samples	O
in	O
each	O
step	O
.	O
	
We	O
set	O
the	O
Algorithm	O
1	O
iter	O
denotes	O
the	O
iteration	O
of	O
training	B-Task
.	O
	
The	O
function	B-Method
Labeling	I-Method
means	O
the	O
method	O
of	O
labeling	B-Task
.	O
	
We	O
assign	O
pseudo	O
-	O
labels	O
to	O
samples	O
when	O
the	O
predictions	O
of	O
F	O
1	O
and	O
F	O
2	O
agree	O
and	O
at	O
least	O
one	O
of	O
them	O
is	O
confident	O
of	O
their	O
predictions	O
.	O
	
number	O
of	O
the	O
initial	O
candidates	O
N	O
init	O
as	O
5	O
,	O
000	O
.	O
	
We	O
gradually	O
increase	O
the	O
number	O
of	O
the	O
candidates	O
	
N	O
t	O
=	O
	
k	O
/	O
20	O
	
*	O
n	O
,	O
where	O
n	O
denotes	O
the	O
number	O
of	O
all	O
target	O
samples	O
and	O
k	O
denotes	O
the	O
number	O
of	O
steps	O
,	O
and	O
we	O
set	O
the	O
maximum	O
number	O
of	O
pseudo	O
-	O
labeled	O
candidates	O
as	O
40	O
,	O
000	O
.	O
	
After	O
the	O
pseudo	O
-	O
labeled	O
training	O
set	O
T	O
l	O
is	O
composed	O
,	O
F	O
,	O
F	O
1	O
,	O
F	O
2	O
are	O
updated	O
by	O
the	O
objective	O
Eq	O
.	O
	
(	O
1	O
)	O
on	O
the	O
labeled	O
training	O
set	O
	
L	O
=	O
S	O
∪	O
	
T	O
l	O
.	O
	
Then	O
,	O
F	O
,	O
F	O
t	O
are	O
simply	O
optimized	O
by	O
the	O
category	O
loss	O
for	O
T	O
l	O
.	O
	
Discriminative	B-Method
representations	I-Method
will	O
be	O
learned	O
by	O
constructing	O
a	O
target	B-Method
-	I-Method
specific	I-Method
network	I-Method
trained	O
only	O
on	O
target	O
samples	O
.	O
	
However	O
,	O
if	O
only	O
noisy	O
pseudo	O
-	O
labeled	O
samples	O
are	O
used	O
for	O
training	O
,	O
the	O
network	O
may	O
not	O
learn	O
useful	O
representations	O
.	O
	
Then	O
,	O
we	O
use	O
both	O
source	O
samples	O
and	O
pseudo	O
-	O
labeled	O
samples	O
for	O
training	O
F	O
,	O
F	O
1	O
,	O
F	O
2	O
to	O
ensure	O
the	O
accuracy	B-Metric
.	O
	
Also	O
,	O
as	O
the	O
learning	O
proceeds	O
,	O
F	O
will	O
learn	O
target	B-Method
-	I-Method
discriminative	I-Method
representations	I-Method
,	O
resulting	O
in	O
an	O
improvement	O
in	O
accuracy	B-Metric
in	O
F	O
1	O
,	O
F	O
2	O
.	O
	
This	O
cycle	O
will	O
gradually	O
enhance	O
the	O
accuracy	B-Metric
in	O
the	O
target	O
domain	O
.	O
	
section	O
:	O
Batch	B-Method
Normalization	I-Method
for	O
Domain	B-Task
Adaptation	I-Task
	
Batch	B-Method
normalization	I-Method
(	I-Method
BN	I-Method
)	I-Method
[	O
reference	O
]	O
,	O
which	O
whitens	O
the	O
output	O
of	O
the	O
hidden	O
layer	O
in	O
a	O
CNN	B-Method
,	O
is	O
an	O
effective	O
technique	O
to	O
accelerate	O
training	B-Metric
speed	I-Metric
and	O
enhance	O
the	O
accuracy	B-Metric
of	O
the	O
model	O
.	O
	
In	O
addition	O
,	O
in	O
domain	B-Task
adaptation	I-Task
,	O
whitening	O
the	O
hidden	O
layer	O
's	O
output	O
is	O
effective	O
for	O
improving	O
the	O
performance	O
,	O
which	O
make	O
the	O
distribution	O
in	O
different	O
domains	O
similar	O
[	O
reference	O
][	O
reference	O
]	O
.	O
	
Input	O
samples	O
of	O
F	O
1	O
,	O
F	O
2	O
include	O
both	O
pseudo	O
-	O
labeled	O
target	O
samples	O
and	O
source	O
samples	O
.	O
	
Introducing	O
BN	B-Method
will	O
be	O
useful	O
for	O
matching	O
the	O
distribution	O
and	O
improves	O
the	O
performance	O
.	O
	
We	O
add	O
the	O
BN	O
layer	O
in	O
the	O
last	O
layer	O
in	O
F	O
.	O
	
section	O
:	O
Analysis	O
	
In	O
this	O
section	O
,	O
we	O
provide	O
a	O
theoretical	O
analysis	O
to	O
our	O
approach	O
.	O
	
First	O
,	O
we	O
provide	O
an	O
insight	O
into	O
existing	O
theory	O
,	O
then	O
we	O
introduce	O
a	O
simple	O
expansion	O
of	O
the	O
theory	O
related	O
to	O
our	O
method	O
.	O
	
In	O
[	O
reference	O
]	O
,	O
an	O
equation	O
was	O
introduced	O
showing	O
that	O
the	O
upper	O
bound	O
of	O
the	O
expected	B-Metric
error	I-Metric
in	O
the	O
target	O
domain	O
depends	O
on	O
three	O
terms	O
,	O
which	O
include	O
the	O
divergence	O
between	O
different	O
domains	O
and	O
the	O
error	O
of	O
an	O
ideal	B-Method
joint	I-Method
hypothesis	I-Method
.	O
	
The	O
divergence	O
between	O
source	O
and	O
target	O
domain	O
,	O
H∆H	O
-	O
distance	O
,	O
is	O
defined	O
as	O
follows	O
:	O
	
This	O
distance	O
is	O
frequently	O
used	O
to	O
measure	O
the	O
adaptability	O
between	O
different	O
domains	O
.	O
	
section	O
:	O
The	O
ideal	O
joint	O
hypothesis	O
is	O
defined	O
as	O
	
,	O
and	O
its	O
corresponding	O
error	O
	
,	O
where	O
R	O
denotes	O
the	O
expected	O
error	O
on	O
each	O
hypothesis	O
.	O
	
The	O
theorem	O
is	O
as	O
follows	O
.	O
	
This	O
theorem	O
means	O
that	O
the	O
expected	B-Metric
error	I-Metric
on	O
the	O
target	O
domain	O
is	O
upper	O
bounded	O
by	O
three	O
terms	O
,	O
the	O
expected	B-Metric
error	I-Metric
on	O
the	O
source	O
domain	O
,	O
the	O
domain	O
divergence	O
measured	O
by	O
the	O
disagreement	O
of	O
the	O
hypothesis	O
,	O
and	O
the	O
error	O
of	O
the	O
ideal	B-Method
joint	I-Method
hypothesis	I-Method
.	O
	
In	O
the	O
existing	O
work	O
[	O
reference	O
][	O
reference	O
]	O
,	O
C	O
was	O
disregarded	O
because	O
it	O
was	O
considered	O
to	O
be	O
negligibly	O
small	O
.	O
	
If	O
we	O
are	O
provided	O
with	O
fixed	O
features	O
,	O
we	O
do	O
not	O
need	O
to	O
consider	O
the	O
term	O
because	O
the	O
term	O
is	O
also	O
fixed	O
.	O
	
However	O
,	O
if	O
we	O
assume	O
that	O
x	O
s	O
∼	O
S	O
,	O
x	O
t	O
∼	O
T	O
are	O
obtained	O
from	O
the	O
last	O
fully	B-Method
connected	I-Method
layer	I-Method
of	O
deep	B-Method
models	I-Method
,	O
we	O
note	O
that	O
C	O
is	O
determined	O
by	O
the	O
output	O
of	O
the	O
layer	O
,	O
and	O
further	O
note	O
the	O
necessity	O
of	O
considering	O
this	O
term	O
.	O
	
We	O
consider	O
the	O
pseudo	O
-	O
labeled	O
target	O
samples	O
set	O
	
given	O
false	O
labels	O
at	O
the	O
ratio	O
of	O
ρ	O
.	O
	
The	O
shared	B-Metric
error	I-Metric
of	O
h	O
*	O
on	O
S	O
,	O
T	O
l	O
is	O
denoted	O
as	O
C	O
′	O
.	O
	
Then	O
,	O
the	O
following	O
inequality	O
holds	O
:	O
	
We	O
show	O
a	O
simple	O
derivation	O
of	O
the	O
inequality	O
in	O
the	O
Supplementary	O
material	O
.	O
	
In	O
Theorem	O
1	O
,	O
we	O
can	O
not	O
measure	O
C	O
in	O
the	O
absence	O
of	O
labeled	O
target	O
samples	O
.	O
	
We	O
can	O
approximately	O
evaluate	O
and	O
minimize	O
it	O
by	O
using	O
pseudo	O
-	O
labels	O
.	O
	
Furthermore	O
,	O
when	O
we	O
consider	O
the	O
second	O
term	O
on	O
the	O
right	O
-	O
hand	O
side	O
,	O
our	O
method	O
is	O
expected	O
to	O
reduce	O
this	O
term	O
.	O
	
This	O
term	O
intuitively	O
denotes	O
the	O
discrepancy	O
between	O
different	O
domains	O
in	O
the	O
disagreement	O
of	O
two	O
classifiers	O
.	O
	
If	O
we	O
regard	O
certain	O
h	O
and	O
h	O
′	O
as	O
F	O
1	O
and	O
F	O
2	O
,	O
respectively	O
,	O
	
]	O
is	O
expected	O
to	O
be	O
low	O
,	O
although	O
we	O
use	O
the	O
training	O
set	O
T	O
l	O
instead	O
of	O
genuine	O
labeled	O
target	O
samples	O
.	O
	
Thus	O
,	O
our	O
method	O
will	O
consider	O
both	O
the	O
second	O
and	O
the	O
third	O
term	O
in	O
Theorem	O
1	O
.	O
	
section	O
:	O
Experiment	O
and	O
Evaluation	O
	
We	O
perform	O
extensive	O
evaluations	O
of	O
our	O
method	O
on	O
image	O
datasets	O
and	O
a	O
sentiment	O
analysis	O
dataset	O
.	O
	
We	O
evaluate	O
the	O
accuracy	B-Metric
of	O
target	B-Method
-	I-Method
specific	I-Method
networks	I-Method
in	O
all	O
experiments	O
.	O
	
Visual	B-Task
Domain	I-Task
Adaptation	I-Task
For	O
visual	B-Task
domain	I-Task
adaptation	I-Task
	
,	O
we	O
perform	O
our	O
evaluation	O
on	O
the	O
digits	O
datasets	O
and	O
traffic	O
signs	O
datasets	O
.	O
	
Digits	O
datasets	O
include	O
MNIST	B-Material
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
Street	B-Material
View	I-Material
House	I-Material
Numbers	I-Material
(	O
SVHN	B-Material
)	O
[	O
reference	O
]	O
,	O
and	O
Synthetic	B-Material
Digits	I-Material
(	O
SYN	B-Material
DIGITS	I-Material
)	O
	
[	O
reference	O
]	O
.	O
	
We	O
further	O
evaluate	O
our	O
method	O
on	O
traffic	O
sign	O
datasets	O
including	O
Synthetic	B-Material
Traffic	I-Material
Signs	I-Material
(	O
SYN	B-Material
SIGNS	I-Material
)	O
	
[	O
reference	O
]	O
and	O
German	B-Material
Traffic	I-Material
Signs	I-Material
Recognition	I-Material
Benchmark	I-Material
	
[	O
reference	O
]	O
.	O
	
In	O
total	O
,	O
five	O
adaptation	O
scenarios	O
are	O
evaluated	O
in	O
this	O
experiment	O
.	O
	
As	O
the	O
datasets	O
used	O
for	O
evaluation	O
are	O
varied	O
in	O
previous	O
works	O
,	O
we	O
extensively	O
evaluate	O
our	O
method	O
on	O
the	O
five	O
scenarios	O
.	O
	
We	O
do	O
not	O
evaluate	O
our	O
method	O
on	O
Office	B-Material
[	O
reference	O
]	O
,	O
which	O
is	O
the	O
most	O
commonly	O
used	O
dataset	O
for	O
visual	B-Task
domain	I-Task
adaptation	I-Task
.	O
	
As	O
pointed	O
out	O
by	O
[	O
reference	O
]	O
,	O
some	O
labels	O
in	O
that	O
dataset	O
are	O
noisy	O
and	O
some	O
images	O
contain	O
other	O
classes	O
'	O
objects	O
.	O
	
Furthermore	O
,	O
many	O
previous	O
studies	O
have	O
evaluated	O
the	O
fine	B-Task
-	I-Task
tuning	I-Task
of	I-Task
pretrained	I-Task
networks	I-Task
using	O
ImageNet	B-Material
.	O
	
This	O
protocol	O
assumes	O
the	O
existence	O
of	O
another	O
source	O
domain	O
.	O
	
In	O
our	O
work	O
,	O
we	O
want	O
to	O
evaluate	O
the	O
situation	O
where	O
we	O
have	O
access	O
to	O
only	O
one	O
source	O
domain	O
and	O
one	O
target	O
domain	O
.	O
	
section	O
:	O
Adaptation	B-Task
in	O
Amazon	B-Task
Reviews	I-Task
	
To	O
investigate	O
the	O
behavior	O
on	O
language	O
datasets	O
,	O
we	O
also	O
evaluated	O
our	O
method	O
on	O
the	O
Amazon	B-Material
Reviews	I-Material
dataset	I-Material
[	O
reference	O
]	O
with	O
the	O
same	O
preprocessing	O
as	O
used	O
by	O
[	O
reference	O
][	O
reference	O
]	O
.	O
	
The	O
dataset	O
contains	O
reviews	O
on	O
four	O
types	O
of	O
products	O
:	O
books	O
,	O
DVDs	O
,	O
electronics	O
,	O
and	O
kitchen	O
appliances	O
.	O
	
We	O
evaluate	O
our	O
method	O
on	O
12	O
domain	B-Task
adaptation	I-Task
scenarios	I-Task
.	O
	
The	O
results	O
are	O
shown	O
in	O
Table	O
1	O
.	O
	
Baseline	O
Methods	O
	
We	O
compare	O
our	O
method	O
with	O
five	O
methods	O
for	O
unsupervised	B-Task
domain	I-Task
adaptation	I-Task
including	O
state	O
-	O
of	O
-	O
the	O
art	O
methods	O
in	O
visual	B-Task
domain	I-Task
adaptation	I-Task
;	O
Maximum	B-Method
Mean	I-Method
Discrepancy	I-Method
(	O
MMD	B-Method
)	O
[	O
reference	O
]	O
,	O
Domain	B-Method
Adversarial	I-Method
Neural	I-Method
Network	I-Method
(	O
DANN	B-Method
)	O
[	O
reference	O
]	O
,	O
Deep	B-Method
Reconstruction	I-Method
Classification	I-Method
Network	I-Method
(	O
DRCN	B-Method
)	I-Method
[	O
reference	O
]	O
,	O
Domain	B-Method
Separation	I-Method
Networks	I-Method
(	O
DSN	B-Method
)	O
[	O
reference	O
]	O
,	O
and	O
k	B-Method
-	I-Method
Nearest	I-Method
Neighbor	I-Method
	
based	B-Method
adaptation	I-Method
(	O
kNN	B-Method
-	I-Method
Ad	I-Method
)	O
	
[	O
reference	O
]	O
.	O
	
We	O
cite	O
the	O
results	O
of	O
MMD	B-Method
from	O
	
[	O
reference	O
]	O
.	O
In	O
addition	O
,	O
we	O
compare	O
our	O
method	O
with	O
CNN	B-Method
trained	O
only	O
on	O
source	O
samples	O
.	O
	
We	O
compare	O
our	O
method	O
with	O
Variational	B-Method
Fair	I-Method
AutoEncoder	I-Method
(	O
VFAE	B-Method
)	O
	
[	O
reference	O
]	O
and	O
DANN	B-Method
[	O
reference	O
]	O
in	O
the	O
Amazon	B-Material
Reviews	I-Material
experiment	I-Material
.	O
	
section	O
:	O
Implementation	O
Detail	O
	
In	O
experiments	O
on	O
image	O
datasets	O
,	O
we	O
employ	O
the	O
architecture	O
of	O
CNN	B-Method
used	O
in	O
[	O
reference	O
]	O
.	O
	
For	O
a	O
fair	O
comparison	O
,	O
we	O
separate	O
the	O
network	O
at	O
the	O
hidden	O
layer	O
from	O
which	O
[	O
reference	O
]	O
constructed	O
discriminator	B-Method
networks	I-Method
.	O
	
Therefore	O
,	O
when	O
considering	O
one	O
classifier	B-Method
,	O
for	O
example	O
,	O
F	O
1	O
•	O
F	O
,	O
the	O
architecture	O
is	O
identical	O
to	O
previous	O
work	O
.	O
	
We	O
also	O
follow	O
[	O
reference	O
]	O
in	O
the	O
other	O
protocols	O
.	O
	
We	O
set	O
the	O
threshold	O
value	O
for	O
the	O
labeling	B-Method
method	I-Method
as	O
0.95	O
in	O
MNIST→SVHN	B-Method
.	O
	
In	O
other	O
scenarios	O
,	O
we	O
set	O
it	O
as	O
0.9	O
.	O
	
We	O
use	O
MomentumSGD	B-Method
for	O
optimization	B-Task
and	O
set	O
the	O
momentum	O
as	O
0.9	O
,	O
while	O
the	O
learning	B-Metric
rate	I-Metric
is	O
determined	O
on	O
validation	O
splits	O
and	O
uses	O
either	O
[	O
0.01	O
,	O
0.05	O
]	O
.	O
λ	O
is	O
set	O
0.01	O
in	O
all	O
scenarios	O
.	O
	
In	O
our	O
Supplementary	O
material	O
,	O
we	O
provide	O
details	O
of	O
the	O
network	B-Method
architecture	I-Method
and	O
hyper	O
-	O
parameters	O
.	O
	
For	O
experiments	O
on	O
the	O
Amazon	B-Material
Reviews	I-Material
dataset	I-Material
,	O
we	O
use	O
a	O
similar	O
architecture	O
to	O
that	O
used	O
in	O
[	O
reference	O
]	O
:	O
with	O
sigmoid	O
activated	O
,	O
one	O
dense	B-Method
hidden	I-Method
layer	I-Method
with	O
50	O
hidden	O
units	O
,	O
and	O
softmax	O
output	O
.	O
	
We	O
extend	O
the	O
architecture	O
to	O
our	O
method	O
similarly	O
in	O
the	O
architecture	O
of	O
CNN	B-Method
.	O
	
λ	O
is	O
set	O
as	O
0.001	O
based	O
on	O
the	O
validation	O
.	O
	
Since	O
the	O
input	O
is	O
sparse	O
,	O
we	O
use	O
Adagrad	B-Method
[	O
reference	O
]	O
for	O
optimization	B-Task
.	O
	
We	O
repeat	O
this	O
evaluation	O
10	O
times	O
and	O
report	O
mean	B-Metric
accuracy	I-Metric
.	O
	
section	O
:	O
Experimental	O
Result	O
	
In	O
Tables	O
1	O
and	O
3	O
,	O
we	O
show	O
the	O
main	O
results	O
of	O
the	O
experiments	O
.	O
	
When	O
training	O
only	O
on	O
source	O
samples	O
,	O
the	O
effect	O
of	O
the	O
BN	B-Method
is	O
not	O
clear	O
as	O
in	O
Tables	O
1	O
.	O
	
However	O
,	O
in	O
all	O
image	B-Task
recognition	I-Task
experiments	O
,	O
the	O
effect	O
of	O
BN	B-Method
in	O
our	O
method	O
is	O
clear	O
;	O
at	O
the	O
same	O
time	O
,	O
the	O
effect	O
of	O
our	O
method	O
is	O
also	O
clear	O
when	O
we	O
do	O
not	O
use	O
BN	B-Method
in	O
the	O
network	B-Method
architecture	I-Method
.	O
	
The	O
effect	O
of	O
the	O
weight	O
constraint	O
is	O
obvious	O
in	O
MNIST→SVHN	B-Method
.	O
	
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
in	O
parentheses	O
.	O
	
MNIST→MNIST	B-Method
-	I-Method
M	I-Method
:	O
last	B-Method
pooling	I-Method
layer	I-Method
	
MNIST→MNIST	B-Method
	
-	B-Method
M	I-Method
First	O
,	O
we	O
evaluate	O
the	O
adaptation	B-Task
scenario	I-Task
between	O
the	O
hand	O
-	O
written	O
digits	O
dataset	O
MNIST	B-Material
and	O
its	O
transformed	O
dataset	O
	
MNIST	B-Material
-	O
M.	O
MNIST	B-Material
-	O
M	O
is	O
composed	O
by	O
merging	O
the	O
clip	O
of	O
the	O
background	O
from	O
BSDS500	B-Material
datasets	I-Material
	
[	O
	
reference	O
]	O
.	O
A	O
patch	O
is	O
randomly	O
taken	O
from	O
the	O
images	O
in	O
BSDS500	B-Material
,	O
merged	O
to	O
MNIST	B-Material
digits	O
.	O
	
Even	O
with	O
this	O
simple	O
domain	B-Method
shift	I-Method
,	O
the	O
adaptation	B-Task
performance	O
of	O
CNN	B-Method
is	O
much	O
worse	O
than	O
the	O
case	O
where	O
it	O
was	O
trained	O
on	O
target	O
samples	O
.	O
	
From	O
59	O
,	O
001	O
target	O
training	O
samples	O
,	O
we	O
randomly	O
select	O
1	O
,	O
000	O
labeled	O
target	O
samples	O
as	O
a	O
validation	O
split	O
and	O
tuned	O
hyper	O
-	O
parameters	O
.	O
	
Our	O
method	O
outperforms	O
the	O
other	O
existing	O
method	O
by	O
about	O
7	O
%	O
.	O
	
Visualization	B-Task
of	I-Task
features	I-Task
in	O
the	O
last	O
pooling	O
layer	O
is	O
shown	O
in	O
Fig	O
.	O
	
3	O
(	O
a	O
)(	O
b	O
)	O
.	O
	
We	O
can	O
observe	O
that	O
the	O
red	O
target	O
samples	O
are	O
more	O
dispersed	O
when	O
adaptation	B-Task
is	O
achieved	O
.	O
	
We	O
show	O
the	O
comparison	O
of	O
the	O
accuracy	B-Metric
between	O
the	O
actual	O
labeling	B-Metric
accuracy	I-Metric
on	O
target	O
samples	O
during	O
training	O
and	O
the	O
test	B-Metric
accuracy	I-Metric
in	O
Fig	O
.	O
4	O
.	O
	
The	O
test	B-Metric
accuracy	I-Metric
is	O
very	O
low	O
at	O
first	O
,	O
but	O
as	O
the	O
steps	O
increase	O
,	O
the	O
accuracy	B-Metric
becomes	O
closer	O
to	O
that	O
of	O
the	O
labeling	B-Metric
accuracy	I-Metric
.	O
	
In	O
this	O
adaptation	O
,	O
we	O
can	O
clearly	O
see	O
that	O
the	O
actual	O
labeling	B-Metric
accuracy	I-Metric
gradually	O
improves	O
with	O
the	O
accuracy	B-Metric
of	O
the	O
network	O
.	O
	
SVHN↔MNIST	B-Method
	
We	O
increase	O
the	O
gap	O
between	O
distributions	O
in	O
this	O
experiment	O
.	O
	
We	O
evaluate	O
adaptation	B-Method
between	O
SVHN	B-Material
[	O
reference	O
]	O
and	O
MNIST	B-Material
in	O
a	O
ten	B-Task
-	I-Task
class	I-Task
classification	I-Task
problem	I-Task
.	O
	
SVHN	B-Material
and	O
MNIST	B-Material
have	O
distinct	O
appearance	O
,	O
thus	O
this	O
adaptation	O
is	O
a	O
challenging	O
scenario	O
especially	O
in	O
MNIST→SVHN	B-Method
.	O
	
SVHN	B-Material
is	O
colored	O
and	O
some	O
images	O
contain	O
multiple	O
digits	O
.	O
	
Therefore	O
,	O
a	O
classifier	B-Method
trained	O
on	O
SVHN	B-Material
is	O
expected	O
to	O
perform	O
well	O
on	O
MNIST	B-Material
,	O
but	O
the	O
reverse	O
is	O
not	O
true	O
.	O
	
MNIST	B-Material
does	O
not	O
include	O
any	O
samples	O
containing	O
multiple	O
digits	O
and	O
most	O
samples	O
are	O
centered	O
in	O
images	O
,	O
thus	O
adaptation	O
from	O
MNIST	B-Material
to	O
SVHN	B-Material
is	O
rather	O
difficult	O
.	O
	
In	O
both	O
settings	O
,	O
we	O
use	O
1	O
,	O
000	O
labeled	O
target	O
samples	O
to	O
find	O
the	O
optimal	O
hyperparameters	O
.	O
	
We	O
evaluate	O
our	O
method	O
on	O
both	O
adaptation	O
scenarios	O
and	O
achieved	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
both	O
datasets	O
.	O
	
In	O
particular	O
,	O
for	O
the	O
adaptation	B-Method
MNIST→SVHN	I-Method
,	O
we	O
outperformed	O
other	O
methods	O
by	O
more	O
than	O
10	O
%	O
.	O
	
In	O
Fig	O
.	O
	
3	O
(	O
c	O
)(	O
d	O
)	O
	
,	O
we	O
visualize	O
the	O
representations	O
in	O
MNIST→SVHN	B-Method
.	O
	
Although	O
the	O
distributions	O
seem	O
to	O
be	O
separated	O
between	O
domains	O
,	O
the	O
red	O
SVHN	B-Material
samples	O
become	O
more	O
discriminative	O
using	O
our	O
method	O
compared	O
with	O
non	B-Method
-	I-Method
adapted	I-Method
embedding	I-Method
.	O
	
We	O
also	O
show	O
the	O
comparison	O
between	O
actual	O
labeling	B-Metric
method	I-Metric
accuracy	I-Metric
and	O
testing	B-Metric
accuracy	I-Metric
in	O
Fig	O
.	O
4	O
(	O
b	O
)(	O
c	O
)	O
.	O
	
In	O
this	O
figure	O
,	O
we	O
can	O
see	O
that	O
the	O
labeling	B-Metric
accuracy	I-Metric
rapidly	O
drops	O
in	O
the	O
initial	O
adaptation	O
stage	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
testing	B-Metric
accuracy	I-Metric
continues	O
to	O
improve	O
,	O
and	O
finally	O
exceeds	O
the	O
labeling	B-Metric
accuracy	I-Metric
.	O
	
There	O
are	O
two	O
questions	O
about	O
this	O
interesting	O
phenomenon	O
.	O
	
The	O
first	O
question	O
is	O
why	O
does	O
the	O
labeling	B-Method
method	I-Method
continue	O
to	O
decrease	O
despite	O
the	O
increase	O
in	O
the	O
test	B-Metric
accuracy	I-Metric
?	O
	
Target	O
samples	O
given	O
pseudo	O
-	O
labels	O
always	O
include	O
mistakenly	O
labeled	O
samples	O
whereas	O
those	O
given	O
no	O
labels	O
are	O
ignored	O
in	O
our	O
method	O
.	O
	
Therefore	O
,	O
the	O
error	O
will	O
be	O
reinforced	O
in	O
the	O
target	O
samples	O
that	O
are	O
included	O
in	O
training	O
set	O
.	O
	
The	O
second	O
question	O
is	O
why	O
does	O
the	O
test	B-Metric
accuracy	I-Metric
continue	O
to	O
increase	O
despite	O
the	O
lower	O
labeling	B-Metric
accuracy	I-Metric
?	O
	
The	O
assumed	O
reasons	O
are	O
that	O
the	O
network	O
already	O
acquires	O
target	B-Method
discriminative	I-Method
representations	I-Method
in	O
this	O
phase	O
and	O
they	O
can	O
improve	O
the	O
accuracy	B-Metric
using	O
source	O
samples	O
and	O
correctly	O
labeled	O
target	O
samples	O
.	O
	
In	O
Fig	O
.	O
4	O
(	O
f	O
)	O
,	O
we	O
also	O
show	O
the	O
comparison	O
of	O
accuracy	B-Metric
of	O
the	O
three	O
networks	O
F	O
1	O
,	O
F	O
2	O
,	O
F	O
t	O
in	O
SVHN→MNIST	B-Method
.	O
	
The	O
accuracy	B-Metric
of	O
three	O
networks	O
is	O
nearly	O
the	O
same	O
in	O
every	O
step	O
.	O
	
The	O
same	O
thing	O
is	O
observed	O
in	O
other	O
scenarios	O
.	O
	
From	O
this	O
result	O
,	O
we	O
can	O
state	O
that	O
the	O
target	B-Method
-	I-Method
discriminative	I-Method
representations	I-Method
are	O
shared	O
in	O
all	O
three	O
networks	O
.	O
	
SYN	O
	
DIGITS→SVHN	B-Method
	
In	O
this	O
experiment	O
,	O
we	O
aimed	O
to	O
address	O
a	O
common	O
adaptation	B-Task
scenario	I-Task
from	O
synthetic	O
images	O
to	O
real	O
images	O
.	O
	
The	O
datasets	O
of	O
synthetic	O
numbers	O
[	O
reference	O
]	O
consist	O
of	O
500	O
,	O
000	O
images	O
generated	O
from	O
Windows	O
fonts	O
by	O
varying	O
the	O
text	O
,	O
positioning	O
,	O
orientation	O
,	O
background	O
and	O
stroke	O
colors	O
,	O
and	O
the	O
amount	O
of	O
blur	O
.	O
	
We	O
use	O
479	O
,	O
400	O
source	O
samples	O
and	O
73	O
,	O
257	O
target	O
samples	O
for	O
training	O
,	O
and	O
26	O
,	O
032	O
target	O
samples	O
for	O
testing	O
.	O
	
We	O
use	O
1	O
,	O
000	O
SVHN	B-Material
samples	O
as	O
a	O
validation	O
set	O
.	O
	
Our	O
method	O
also	O
outperforms	O
other	O
methods	O
in	O
this	O
experiment	O
.	O
	
In	O
this	O
experiment	O
,	O
the	O
effect	O
of	O
BN	B-Method
is	O
not	O
clear	O
compared	O
with	O
other	O
scenarios	O
.	O
	
The	O
domain	O
gap	O
is	O
considered	O
small	O
in	O
this	O
scenario	O
as	O
the	O
performance	O
of	O
the	O
source	B-Method
-	I-Method
only	I-Method
classifier	I-Method
shows	O
.	O
	
In	O
Fig	O
.	O
4	O
(	O
d	O
)	O
,	O
although	O
the	O
labeling	B-Metric
accuracy	I-Metric
is	O
dropping	O
,	O
the	O
accuracy	B-Metric
of	O
the	O
learned	O
network	O
's	O
prediction	B-Task
is	O
improving	O
as	O
in	O
MNIST↔SVHN	B-Method
.	O
	
SYN	B-Method
SIGNS→GTSRB	I-Method
	
This	O
setting	O
is	O
similar	O
to	O
the	O
pre	O
-	O
Table	O
2	O
.	O
	
Results	O
of	O
Gradient	O
stop	O
experiment	O
.	O
	
When	O
stopping	O
gradients	O
from	O
Ft	O
,	O
we	O
do	O
not	O
use	O
backward	O
gradients	O
from	O
Ft	O
to	O
F	O
,	O
and	O
F	O
learns	O
only	O
from	O
F1	O
,	O
F2	O
.	O
	
When	O
stopping	O
gradients	O
from	O
F1	O
,	O
F2	O
,	O
we	O
do	O
not	O
use	O
backward	O
gradients	O
from	O
F1	O
,	O
F2	O
to	O
F	O
,	O
and	O
F	O
learns	O
from	O
Ft	O
.	O
	
None	O
denotes	O
our	O
proposed	O
method	O
,	O
we	O
backward	O
all	O
gradients	O
from	O
all	O
branches	O
to	O
F	O
.	O
	
In	O
these	O
three	O
adaptation	O
scenarios	O
,	O
our	O
method	O
shows	O
stable	O
performance	O
.	O
	
vious	O
setting	O
,	O
adaptation	B-Task
from	O
synthetic	O
images	O
to	O
real	O
images	O
,	O
but	O
we	O
have	O
a	O
larger	O
number	O
of	O
classes	O
,	O
namely	O
43	O
classes	O
instead	O
of	O
10	O
.	O
	
We	O
use	O
the	O
SYN	B-Material
SIGNS	I-Material
dataset	I-Material
[	O
reference	O
]	O
for	O
the	O
source	O
dataset	O
and	O
the	O
GTSRB	B-Material
dataset	I-Material
[	O
reference	O
]	O
for	O
the	O
target	O
dataset	O
,	O
which	O
consist	O
of	O
real	O
traffic	O
sign	O
images	O
.	O
	
We	O
select	O
randomly	O
31	O
,	O
367	O
samples	O
for	O
target	O
training	O
samples	O
and	O
evaluate	O
accuracy	B-Metric
on	O
the	O
rest	O
of	O
the	O
samples	O
.	O
	
A	O
total	O
of	O
3	O
,	O
000	O
labeled	O
target	O
samples	O
are	O
used	O
for	O
validation	B-Task
.	O
	
In	O
this	O
scenario	O
,	O
our	O
method	O
outperforms	O
other	O
methods	O
.	O
	
This	O
result	O
shows	O
that	O
our	O
method	O
is	O
effective	O
for	O
the	O
adaptation	B-Task
from	O
synthesized	O
images	O
to	O
real	O
images	O
,	O
which	O
have	O
diverse	O
classes	O
.	O
	
In	O
Fig	O
.	O
	
4	O
(	O
e	O
)	O
,	O
	
the	O
same	O
tendency	O
as	O
in	O
MNIST↔SVHN	B-Method
is	O
observed	O
in	O
this	O
adaptation	B-Task
scenario	I-Task
.	O
	
section	O
:	O
Gradient	B-Task
Stop	I-Task
Experiment	O
	
We	O
evaluate	O
the	O
effect	O
of	O
the	O
target	O
-	O
specific	O
network	O
in	O
our	O
method	O
.	O
	
We	O
stop	O
the	O
gradient	O
from	O
upper	O
layer	O
networks	O
F	O
1	O
,	O
F	O
2	O
,	O
and	O
F	O
t	O
to	O
examine	O
the	O
effect	O
of	O
F	O
t	O
.	O
	
Table	O
2	O
shows	O
three	O
scenarios	O
including	O
the	O
case	O
where	O
we	O
stop	O
the	O
gradient	O
from	O
F	O
1	O
,	O
F	O
2	O
,	O
and	O
F	O
t	O
.	O
	
In	O
all	O
scenarios	O
,	O
when	O
we	O
backward	O
all	O
gradients	O
from	O
F	O
1	O
,	O
F	O
2	O
,	O
F	O
t	O
,	O
we	O
obtain	O
clear	O
performance	O
improvements	O
.	O
	
In	O
the	O
experiment	B-Method
MNIST→MNIST	I-Method
-	I-Method
M	I-Method
,	O
we	O
can	O
assume	O
that	O
only	O
the	O
backpropagation	O
from	O
F	O
1	O
,	O
F	O
2	O
can	O
not	O
construct	O
discriminative	B-Method
representations	I-Method
for	O
target	O
samples	O
and	O
confirm	O
the	O
effect	O
of	O
F	O
t	O
.	O
	
For	O
the	O
adaptation	B-Method
MNIST→SVHN	I-Method
,	O
the	O
best	O
performance	O
is	O
realized	O
when	O
F	O
receives	O
all	O
gradients	O
from	O
upper	O
networks	O
.	O
	
Backwarding	O
all	O
gradients	O
will	O
ensure	O
both	O
target	O
-	O
specific	O
discriminative	B-Method
representations	I-Method
in	O
difficult	O
adaptations	O
.	O
	
In	O
SYN	B-Method
SIGNS→GTSRB	I-Method
,	O
backwarding	O
only	O
from	O
F	O
t	O
produces	O
the	O
worst	O
performance	O
because	O
these	O
domains	O
are	O
similar	O
and	O
noisy	O
pseudo	O
-	O
labeled	O
target	O
samples	O
worsen	O
the	O
performance	O
.	O
	
section	O
:	O
A	B-Metric
-	I-Metric
distance	I-Metric
	
From	O
the	O
theoretical	O
results	O
in	O
[	O
reference	O
]	O
,	O
A	B-Metric
-	I-Metric
distance	I-Metric
is	O
usually	O
used	O
as	O
a	O
measure	B-Metric
of	I-Metric
domain	I-Metric
discrepancy	I-Metric
.	O
	
The	O
way	O
of	O
estimating	O
empirical	O
A	B-Metric
-	I-Metric
distance	I-Metric
is	O
simple	O
,	O
in	O
which	O
we	O
train	O
a	O
classifier	B-Method
to	O
classify	O
a	O
domain	O
from	O
each	O
domains	O
'	O
feature	O
.	O
	
Then	O
,	O
the	O
approximate	O
distance	O
is	O
calculated	O
Table	O
3	O
.	O
	
Amazon	B-Material
Reviews	I-Material
experimental	O
results	O
.	O
	
The	O
accuracy	B-Metric
(	O
%	O
)	O
of	O
the	O
proposed	O
method	O
is	O
shown	O
with	O
the	O
result	O
of	O
VFAE	B-Method
[	O
reference	O
]	O
and	O
DANN	B-Method
[	O
reference	O
]	O
.	O
	
asd	O
A	O
=	O
2	O
(	O
1	O
	
−	O
2ǫ	O
)	O
,	O
where	O
ǫ	O
is	O
the	O
generalization	B-Metric
error	I-Metric
of	O
the	O
classifier	B-Method
.	O
	
In	O
Fig	O
.	O
	
4	O
(	O
g	O
)	O
	
,	O
we	O
show	O
the	O
A	B-Metric
-	I-Metric
distance	I-Metric
calculated	O
from	O
each	O
CNN	B-Method
features	O
.	O
	
We	O
used	O
linear	B-Method
SVM	I-Method
to	O
calculate	O
the	O
distance	O
.	O
	
From	O
this	O
graph	O
,	O
we	O
can	O
see	O
that	O
our	O
method	O
certainly	O
reduces	O
the	O
A	B-Metric
-	I-Metric
distance	I-Metric
compared	O
with	O
the	O
CNN	B-Method
trained	O
on	O
only	O
source	O
samples	O
.	O
	
In	O
addition	O
,	O
when	O
comparing	O
DANN	B-Method
and	O
our	O
method	O
,	O
although	O
DANN	B-Method
reduces	O
A	B-Metric
-	I-Metric
distance	I-Metric
much	O
more	O
than	O
our	O
method	O
,	O
our	O
method	O
shows	O
superior	O
performance	O
.	O
	
This	O
indicates	O
that	O
minimizing	O
the	O
domain	O
discrepancy	O
is	O
not	O
necessarily	O
an	O
appropriate	O
way	O
to	O
achieve	O
better	O
performance	O
.	O
	
Amazon	B-Material
Reviews	I-Material
Reviews	I-Material
are	O
encoded	O
in	O
5	O
,	O
000	O
dimensional	O
vectors	O
of	O
bag	B-Method
-	I-Method
of	I-Method
-	I-Method
words	I-Method
unigrams	I-Method
and	O
bigrams	B-Method
with	O
binary	O
labels	O
.	O
	
Negative	O
labels	O
are	O
attached	O
to	O
the	O
samples	O
if	O
they	O
are	O
ranked	O
with	O
1	O
-	O
3	O
stars	O
.	O
	
Positive	O
labels	O
are	O
attached	O
if	O
they	O
are	O
ranked	O
with	O
4	O
or	O
5	O
stars	O
.	O
	
We	O
have	O
2	O
,	O
000	O
labeled	O
source	O
samples	O
and	O
2	O
,	O
000	O
unlabeled	O
target	O
samples	O
for	O
training	O
,	O
and	O
between	O
3	O
,	O
000	O
and	O
6	O
,	O
000	O
samples	O
for	O
testing	O
.	O
	
We	O
use	O
200	O
of	O
labeled	O
target	O
samples	O
for	O
validation	O
.	O
	
From	O
the	O
results	O
in	O
Table	O
3	O
,	O
our	O
method	O
performs	O
better	O
than	O
VFAE	B-Method
[	O
reference	O
]	O
and	O
DANN	B-Method
[	O
reference	O
]	O
in	O
nine	O
settings	O
out	O
of	O
twelve	O
.	O
	
Our	O
method	O
is	O
effective	O
in	O
learning	O
a	O
shallow	B-Task
network	I-Task
on	O
different	O
domains	O
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
paper	O
,	O
we	O
have	O
proposed	O
a	O
novel	O
asymmetric	O
tri	B-Method
-	I-Method
training	I-Method
method	O
for	O
unsupervised	B-Task
domain	I-Task
adaptation	I-Task
,	O
which	O
is	O
simply	O
implemented	O
.	O
	
We	O
aimed	O
to	O
learn	O
discriminative	B-Method
representations	I-Method
by	O
utilizing	O
pseudo	O
-	O
labels	O
assigned	O
to	O
unlabeled	O
target	O
samples	O
.	O
	
We	O
utilized	O
three	O
classifiers	B-Method
,	O
two	O
networks	O
assign	O
pseudo	O
-	O
labels	O
to	O
unlabeled	O
target	O
samples	O
and	O
the	O
remaining	O
network	O
learns	O
from	O
them	O
.	O
	
We	O
evaluated	O
our	O
method	O
both	O
on	O
domain	B-Task
adaptation	I-Task
on	O
a	O
visual	B-Task
recognition	I-Task
task	I-Task
and	O
a	O
sentiment	B-Task
analysis	I-Task
task	I-Task
,	O
outperforming	O
other	O
methods	O
.	O
	
In	O
particular	O
,	O
our	O
method	O
outperformed	O
the	O
other	O
methods	O
by	O
more	O
than	O
10	O
%	O
in	O
the	O
MNIST→SVHN	B-Method
adaptation	I-Method
task	I-Method
.	O
	
section	O
:	O
Acknowledgement	O
Proof	O
of	O
Theorem	O
	
We	O
introduce	O
the	O
derivation	O
of	O
theorem	O
of	O
the	O
main	O
paper	O
.	O
	
The	O
ideal	O
joint	O
hypothesis	O
is	O
defined	O
as	O
h	O
	
*	O
=	O
arg	O
min	O
	
,	O
and	O
its	O
corresponding	O
error	O
	
,	O
where	O
R	O
denotes	O
the	O
expected	O
error	O
on	O
each	O
hypothesis	O
.	O
	
We	O
consider	O
the	O
pseudo	O
-	O
labeled	O
target	O
samples	O
set	O
	
given	O
false	O
labels	O
at	O
the	O
ratio	O
of	O
ρ	O
.	O
	
The	O
minimum	B-Metric
shared	I-Metric
error	I-Metric
on	O
S	O
,	O
T	O
l	O
is	O
denoted	O
as	O
C	O
′	O
.	O
	
Then	O
,	O
the	O
following	O
inequality	O
holds	O
:	O
	
Proof	O
.	O
	
The	O
probabiliy	O
of	O
false	O
labels	O
in	O
the	O
pseudo	O
-	O
labeled	O
set	O
T	O
l	O
is	O
ρ	O
.	O
	
When	O
we	O
consider	O
0	O
-	O
1	O
loss	O
function	O
for	O
l	O
,	O
the	O
difference	O
between	O
the	O
error	B-Metric
based	O
on	O
the	O
true	O
labeled	O
set	O
and	O
pseudo	O
-	O
labeled	O
set	O
is	O
	
Then	O
,	O
the	O
difference	O
in	O
the	O
expected	B-Metric
error	I-Metric
is	O
,	O
	
From	O
the	O
characteritic	O
of	O
the	O
loss	O
function	O
,	O
the	O
triangle	O
inequality	O
will	O
hold	O
,	O
then	O
	
From	O
this	O
result	O
,	O
the	O
main	O
inequality	O
holds	O
.	O
	
section	O
:	O
CNN	B-Method
Architectures	O
and	O
training	O
detail	O
	
Four	O
types	O
of	O
architectures	O
are	O
used	O
for	O
our	O
method	O
,	O
which	O
is	O
based	O
on	O
[	O
reference	O
]	O
.	O
The	O
network	O
topology	O
is	O
shown	O
in	O
Figs	O
6	O
,	O
7	O
and	O
8	O
.	O
	
The	O
other	O
hyperparameters	O
are	O
decided	O
on	O
the	O
validation	O
splits	O
.	O
	
The	O
learning	B-Metric
rate	I-Metric
is	O
set	O
to	O
0.05	O
in	O
SVHN↔MNIST	B-Method
.	O
	
In	O
the	O
other	O
scenarios	O
,	O
it	O
is	O
set	O
to	O
0.01	O
.	O
	
The	O
batchsize	O
for	O
training	O
F	O
t	O
,	O
F	O
is	O
set	O
as	O
128	O
,	O
the	O
batchsize	O
for	O
training	O
F	O
1	O
,	O
F	O
2	O
,	O
F	O
is	O
set	O
as	O
64	O
in	O
all	O
scenarios	O
.	O
	
In	O
MNIST→MNIST	B-Method
-	I-Method
M	I-Method
,	O
the	O
dropout	B-Metric
rate	I-Metric
used	O
in	O
the	O
experiment	O
is	O
0.2	O
for	O
training	O
F	O
t	O
,	O
0.5	O
for	O
training	O
F	O
1	O
,	O
F	O
2	O
.	O
	
In	O
MNIST→SVHN	B-Method
,	O
we	O
did	O
not	O
use	O
dropout	O
.	O
	
We	O
decreased	O
learning	B-Metric
rate	I-Metric
to	O
0.001	O
after	O
step	O
10	O
.	O
	
In	O
SVHN→MNIST	B-Method
,	O
the	O
dropout	B-Metric
rate	I-Metric
used	O
in	O
the	O
experiment	O
is	O
0.5	O
.	O
	
In	O
SYNDIGITS→SVHN	B-Method
,	O
the	O
dropout	B-Metric
rate	I-Metric
used	O
in	O
the	O
experiment	O
is	O
0.5	O
.	O
	
In	O
SYNSIGNS→GTSRB	B-Method
,	O
the	O
dropout	B-Metric
rate	I-Metric
used	O
in	O
the	O
experiment	O
is	O
0.5	O
.	O
	
section	O
:	O
Supplementary	O
experiments	O
on	O
MNIST→MNIST	B-Method
-	I-Method
M	I-Method
	
We	O
observe	O
the	O
behavior	O
of	O
our	O
model	O
when	O
increasing	O
the	O
number	O
of	O
steps	O
up	O
to	O
one	O
hundred	O
.	O
	
We	O
show	O
the	O
result	O
in	O
Fig	O
.	O
5	O
.	O
	
Our	O
model	O
's	O
accuracy	B-Metric
gets	O
about	O
97	O
%	O
.	O
	
In	O
our	O
main	O
experiments	O
,	O
we	O
set	O
the	O
number	O
of	O
steps	O
thirty	O
,	O
but	O
from	O
this	O
experiment	O
,	O
further	O
improvements	O
can	O
be	O
expected	O
.	O
	
Figure	O
6	O
.	O
	
The	O
architecture	O
used	O
for	O
MNIST→MNIST	B-Method
-	I-Method
M.	I-Method
	
We	O
added	O
BN	O
layer	O
in	O
the	O
last	O
convolution	O
layer	O
and	O
FC	B-Method
layers	I-Method
in	O
F1	O
,	O
F2	O
.	O
	
We	O
also	O
used	O
dropout	O
in	O
our	O
experiment	O
.	O
	
Figure	O
8	O
.	O
	
The	O
architecture	O
used	O
in	O
the	O
adaptation	B-Method
Synthetic	I-Method
Signs→GTSRB	I-Method
.	O
	
We	O
added	O
a	O
BN	B-Method
layer	I-Method
after	O
the	O
last	O
convolution	O
layer	O
in	O
F	O
and	O
also	O
used	O
dropout	B-Method
.	O
	
section	O
:	O
	
section	O
:	O
	
This	O
work	O
was	O
funded	O
by	O
ImPACT	O
Program	O
of	O
Council	O
for	O
Science	O
,	O
Technology	O
and	O
Innovation	O
(	O
Cabinet	O
Office	B-Material
,	O
Government	O
of	O
Japan	O
)	O
and	O
supported	O
by	O
CREST	O
,	O
JST	O
.	O
	
section	O
:	O
	
A	O
Convolutional	B-Method
Encoder	I-Method
Model	I-Method
for	O
Neural	B-Task
Machine	I-Task
Translation	I-Task
	
section	O
:	O
Abstract	O
	
The	O
prevalent	O
approach	O
to	O
neural	B-Task
machine	I-Task
translation	I-Task
relies	O
on	O
bi	B-Method
-	I-Method
directional	I-Method
LSTMs	I-Method
to	O
encode	O
the	O
source	O
sentence	O
.	O
	
We	O
present	O
a	O
faster	O
and	O
simpler	O
architecture	O
based	O
on	O
a	O
succession	B-Method
of	I-Method
convolutional	I-Method
layers	I-Method
.	O
	
This	O
allows	O
to	O
encode	O
the	O
source	O
sentence	O
simultaneously	O
compared	O
to	O
recurrent	B-Method
networks	I-Method
for	O
which	O
computation	B-Task
is	O
constrained	O
by	O
temporal	O
dependencies	O
.	O
	
On	O
WMT'16	B-Task
EnglishRomanian	I-Task
translation	I-Task
we	O
achieve	O
competitive	O
accuracy	B-Metric
to	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
and	O
on	O
WMT'15	B-Material
English	I-Material
-	I-Material
German	I-Material
we	O
outperform	O
several	O
recently	O
published	O
results	O
.	O
	
Our	O
models	O
obtain	O
almost	O
the	O
same	O
accuracy	B-Metric
as	O
a	O
very	O
deep	B-Method
LSTM	I-Method
setup	I-Method
on	O
WMT'14	B-Material
English	I-Material
-	I-Material
French	I-Material
translation	O
.	O
	
We	O
speed	O
up	O
CPU	B-Task
decoding	I-Task
by	O
more	O
than	O
two	O
times	O
at	O
the	O
same	O
or	O
higher	O
accuracy	B-Metric
as	O
a	O
strong	O
bidirectional	B-Method
LSTM	I-Method
.	O
	
1	O
	
section	O
:	O
Introduction	O
	
Neural	B-Task
machine	I-Task
translation	I-Task
(	O
NMT	B-Task
)	O
is	O
an	O
end	O
-	O
to	O
-	O
end	B-Method
approach	I-Method
to	O
machine	B-Task
translation	I-Task
.	O
	
The	O
most	O
successful	O
approach	O
to	O
date	O
encodes	O
the	O
source	O
sentence	O
with	O
a	O
bi	B-Method
-	I-Method
directional	I-Method
recurrent	I-Method
neural	I-Method
network	I-Method
(	O
RNN	B-Method
)	O
into	O
a	O
variable	B-Method
length	I-Method
representation	I-Method
and	O
then	O
generates	O
the	O
translation	O
left	O
-	O
to	O
-	O
right	O
with	O
another	O
RNN	B-Method
where	O
both	O
components	O
interface	O
via	O
a	O
soft	B-Method
-	I-Method
attention	I-Method
mechanism	I-Method
	
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
Recurrent	B-Method
networks	I-Method
are	O
typically	O
parameterized	O
as	O
long	B-Method
short	I-Method
term	I-Method
memory	I-Method
networks	I-Method
(	O
LSTM	B-Method
;	O
[	O
reference	O
]	O
or	O
gated	B-Method
recurrent	I-Method
units	I-Method
[	O
reference	O
][	O
reference	O
]	O
,	O
often	O
with	O
residual	O
or	O
skip	O
connections	O
[	O
reference	O
][	O
reference	O
]	O
to	O
enable	O
stacking	O
of	O
several	O
layers	O
(	O
§	O
2	O
)	O
.	O
	
There	O
have	O
been	O
several	O
attempts	O
to	O
use	O
convolutional	B-Method
encoder	I-Method
models	I-Method
for	O
neural	B-Task
machine	I-Task
trans	I-Task
-	I-Task
lation	I-Task
in	O
the	O
past	O
but	O
they	O
were	O
either	O
only	O
applied	O
to	O
rescoring	O
n	O
-	O
best	O
lists	O
of	O
classical	O
systems	O
[	O
reference	O
]	O
or	O
were	O
not	O
competitive	O
to	O
recurrent	B-Method
alternatives	I-Method
[	O
	
reference	O
]	O
.	O
This	O
is	O
despite	O
several	O
attractive	O
properties	O
of	O
convolutional	B-Method
networks	I-Method
.	O
	
For	O
example	O
,	O
convolutional	B-Method
networks	I-Method
operate	O
over	O
a	O
fixed	O
-	O
size	O
window	O
of	O
the	O
input	O
sequence	O
which	O
enables	O
the	O
simultaneous	O
computation	O
of	O
all	O
features	O
for	O
a	O
source	O
sentence	O
.	O
	
This	O
contrasts	O
to	O
RNNs	B-Method
which	O
maintain	O
a	O
hidden	O
state	O
of	O
the	O
entire	O
past	O
that	O
prevents	O
parallel	O
computation	O
within	O
a	O
sequence	O
.	O
	
A	O
succession	B-Method
of	I-Method
convolutional	I-Method
layers	I-Method
provides	O
a	O
shorter	O
path	O
to	O
capture	O
relationships	O
between	O
elements	O
of	O
a	O
sequence	O
compared	O
to	O
RNNs	B-Method
.	O
	
[	O
reference	O
]	O
	
This	O
also	O
eases	O
learning	B-Task
because	O
the	O
resulting	O
tree	B-Method
-	I-Method
structure	I-Method
applies	O
a	O
fixed	O
number	O
of	O
non	O
-	O
linearities	O
compared	O
to	O
a	O
recurrent	B-Method
neural	I-Method
network	I-Method
for	O
which	O
the	O
number	O
of	O
non	O
-	O
linearities	O
vary	O
depending	O
on	O
the	O
time	O
-	O
step	O
.	O
	
Because	O
processing	B-Task
is	O
bottom	O
-	O
up	O
,	O
all	O
words	O
undergo	O
the	O
same	O
number	O
of	O
transformations	O
,	O
whereas	O
for	O
RNNs	B-Method
the	O
first	O
word	O
is	O
over	O
-	O
processed	O
and	O
the	O
last	O
word	O
is	O
transformed	O
only	O
once	O
.	O
	
In	O
this	O
paper	O
we	O
show	O
that	O
an	O
architecture	O
based	O
on	O
convolutional	B-Method
layers	I-Method
is	O
very	O
competitive	O
to	O
recurrent	B-Method
encoders	I-Method
.	O
	
We	O
investigate	O
simple	O
average	B-Method
pooling	I-Method
as	O
well	O
as	O
parameterized	B-Method
convolutions	I-Method
as	O
an	O
alternative	O
to	O
recurrent	B-Method
encoders	I-Method
and	O
enable	O
very	O
deep	B-Method
convolutional	I-Method
encoders	I-Method
by	O
using	O
residual	O
connections	O
[	O
reference	O
][	O
reference	O
]	O
.	O
	
We	O
experiment	O
on	O
several	O
standard	O
datasets	O
and	O
compare	O
our	O
approach	O
to	O
variants	O
of	O
recurrent	B-Method
encoders	I-Method
such	O
as	O
uni	B-Method
-	I-Method
directional	I-Method
and	O
bi	B-Method
-	I-Method
directional	I-Method
LSTMs	I-Method
.	O
	
On	O
WMT'16	B-Material
English	I-Material
-	I-Material
Romanian	I-Material
translation	O
we	O
achieve	O
accuracy	B-Metric
that	O
is	O
very	O
competitive	O
to	O
the	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
result	O
.	O
	
We	O
perform	O
competitively	O
on	O
WMT'15	B-Material
English	I-Material
-	I-Material
German	I-Material
,	O
and	O
nearly	O
match	O
the	O
performance	O
of	O
the	O
best	O
WMT'14	B-Material
English	I-Material
-	I-Material
French	I-Material
system	O
based	O
on	O
a	O
deep	B-Method
LSTM	I-Method
setup	I-Method
when	O
comparing	O
on	O
a	O
commonly	O
used	O
subset	O
2	O
For	O
kernel	O
width	O
k	O
and	O
sequence	O
length	O
n	O
we	O
require	O
max	O
1	O
,	O
	
forwards	B-Method
on	O
a	O
succession	O
of	O
stacked	B-Method
convolutional	I-Method
layers	I-Method
compared	O
to	O
n	B-Method
forwards	I-Method
with	O
an	O
RNN	B-Method
.	O
	
section	O
:	O
arXiv:1611.02344v3	O
[	O
cs	O
.	O
CL	O
]	O
25	O
Jul	O
2017	O
	
of	O
the	O
training	O
data	O
	
[	O
reference	O
][	O
reference	O
]	O
.	O
	
section	O
:	O
Recurrent	O
Neural	B-Task
Machine	I-Task
Translation	I-Task
	
The	O
general	O
architecture	O
of	O
the	O
models	O
in	O
this	O
work	O
follows	O
the	O
encoder	B-Method
-	I-Method
decoder	I-Method
approach	I-Method
with	O
soft	O
attention	O
first	O
introduced	O
in	O
[	O
reference	O
]	O
.	O
A	O
source	O
sentence	O
x	O
=	O
(	O
x	O
1	O
,	O
.	O
.	O
.	O
,	O
x	O
m	O
)	O
of	O
m	O
words	O
is	O
processed	O
by	O
an	O
encoder	B-Method
which	O
outputs	O
a	O
sequence	O
of	O
states	O
z	O
=	O
	
(	O
z	O
1	O
.	O
.	O
.	O
	
.	O
,	O
z	O
m	O
)	O
.	O
	
The	O
decoder	B-Method
is	O
an	O
RNN	B-Method
network	I-Method
that	O
computes	O
a	O
new	O
hidden	O
state	O
s	O
i	O
+	O
1	O
based	O
on	O
the	O
previous	O
state	O
s	O
i	O
,	O
an	O
embedding	O
g	O
i	O
of	O
the	O
previous	O
target	O
language	O
word	O
	
y	O
i	O
,	O
as	O
well	O
as	O
a	O
conditional	O
input	O
	
c	O
i	O
derived	O
from	O
the	O
encoder	O
output	O
	
z.	O
	
We	O
use	O
LSTMs	B-Method
(	O
Hochreiter	O
and	O
Schmidhuber	O
,	O
1997	O
)	O
for	O
all	O
decoder	B-Method
networks	I-Method
whose	O
state	O
s	O
	
i	O
comprises	O
of	O
a	O
cell	O
vector	O
and	O
	
a	O
hidden	O
vector	O
h	O
i	O
which	O
is	O
output	O
by	O
the	O
LSTM	B-Method
at	O
each	O
time	O
step	O
.	O
	
We	O
input	O
c	O
i	O
into	O
the	O
LSTM	B-Method
by	O
concatenating	O
it	O
to	O
g	O
i	O
.	O
	
The	O
translation	B-Method
model	I-Method
computes	O
a	O
distribution	O
over	O
the	O
V	O
possible	O
target	O
words	O
y	O
i	O
+	O
1	O
by	O
transforming	O
the	O
LSTM	B-Method
output	O
h	O
	
i	O
via	O
a	O
linear	B-Method
layer	I-Method
with	O
weights	O
	
W	O
o	O
and	O
bias	O
	
b	O
o	O
:	O
	
The	O
conditional	O
input	O
	
c	O
	
i	O
at	O
time	O
i	O
is	O
computed	O
via	O
a	O
simple	O
dot	B-Method
-	I-Method
product	I-Method
style	I-Method
attention	I-Method
mechanism	I-Method
[	O
reference	O
]	O
.	O
	
Specifically	O
,	O
we	O
transform	O
the	O
decoder	O
hidden	O
state	O
h	O
	
i	O
by	O
a	O
linear	B-Method
layer	I-Method
with	O
weights	O
W	O
d	O
and	O
b	O
d	O
to	O
match	O
the	O
size	O
of	O
the	O
embedding	O
of	O
the	O
previous	O
target	O
word	O
g	O
	
i	O
and	O
then	O
sum	O
the	O
two	O
representations	O
to	O
yield	O
d	O
i	O
.	O
	
Conditional	O
input	O
	
c	O
	
i	O
is	O
a	O
weighted	O
sum	O
of	O
attention	O
scores	O
a	O
i	O
∈	O
R	O
m	O
and	O
encoder	O
outputs	O
	
z.	O
	
The	O
attention	O
scores	O
a	O
i	O
are	O
determined	O
by	O
a	O
dot	O
product	O
between	O
h	O
i	O
with	O
each	O
z	O
	
j	O
,	O
followed	O
by	O
a	O
softmax	B-Method
over	O
the	O
source	O
sequence	O
:	O
	
In	O
preliminary	O
experiments	O
,	O
we	O
did	O
not	O
find	O
the	O
MLP	O
attention	O
of	O
[	O
reference	O
]	O
to	O
perform	O
significantly	O
better	O
in	O
terms	O
of	O
BLEU	B-Metric
nor	O
perplexity	B-Metric
.	O
	
However	O
,	O
we	O
found	O
the	O
dot	B-Method
-	I-Method
product	I-Method
attention	I-Method
to	O
be	O
more	O
favorable	O
in	O
terms	O
of	O
training	B-Metric
and	I-Metric
evaluation	I-Metric
speed	I-Metric
.	O
	
We	O
use	O
bi	B-Method
-	I-Method
directional	I-Method
LSTMs	I-Method
to	O
implement	O
recurrent	B-Method
encoders	I-Method
similar	O
to	O
[	O
reference	O
]	O
which	O
achieved	O
some	O
of	O
the	O
best	O
WMT14	B-Material
EnglishFrench	I-Material
results	O
reported	O
to	O
date	O
.	O
	
First	O
,	O
each	O
word	O
of	O
the	O
input	O
sequence	O
x	O
is	O
embedded	O
in	O
distributional	O
space	O
resulting	O
in	O
e	O
=	O
	
(	O
e	O
1	O
,	O
.	O
.	O
.	O
,	O
e	O
m	O
)	O
.	O
	
The	O
embeddings	O
are	O
input	O
to	O
two	O
stacks	O
of	O
uni	B-Method
-	I-Method
directional	I-Method
RNNs	O
where	O
the	O
output	O
of	O
each	O
layer	O
is	O
reversed	O
before	O
being	O
fed	O
into	O
the	O
next	O
layer	O
.	O
	
The	O
first	O
stack	O
takes	O
the	O
original	O
sequence	O
while	O
the	O
second	O
takes	O
the	O
reversed	O
input	O
sequence	O
;	O
the	O
output	O
of	O
the	O
second	O
stack	O
is	O
reversed	O
so	O
that	O
the	O
final	O
outputs	O
of	O
the	O
stacks	O
align	O
.	O
	
Finally	O
,	O
the	O
top	O
-	O
level	O
hidden	O
states	O
of	O
the	O
two	O
stacks	O
are	O
concatenated	O
and	O
fed	O
into	O
a	O
linear	B-Method
layer	I-Method
to	O
yield	O
z.	O
	
We	O
denote	O
this	O
encoder	B-Method
architecture	I-Method
as	O
BiLSTM	B-Method
.	O
	
3	O
Non	B-Method
-	I-Method
recurrent	I-Method
Encoders	I-Method
	
section	O
:	O
Pooling	B-Method
Encoder	I-Method
	
A	O
simple	O
baseline	O
for	O
non	B-Method
-	I-Method
recurrent	I-Method
encoders	I-Method
is	O
the	O
pooling	B-Method
model	I-Method
described	O
in	O
[	O
reference	O
]	O
which	O
simply	O
averages	O
the	O
embeddings	O
of	O
k	O
consecutive	O
words	O
.	O
	
Averaging	B-Method
word	I-Method
embeddings	I-Method
does	O
not	O
convey	O
positional	O
information	O
besides	O
that	O
the	O
words	O
in	O
the	O
input	O
are	O
somewhat	O
close	O
to	O
each	O
other	O
.	O
	
As	O
a	O
remedy	O
,	O
we	O
add	O
position	O
embeddings	O
to	O
encode	O
the	O
absolute	O
position	O
of	O
each	O
source	O
word	O
within	O
a	O
sentence	O
.	O
	
Each	O
source	O
embedding	O
e	O
j	O
therefore	O
contains	O
a	O
position	O
embedding	O
l	O
j	O
as	O
well	O
as	O
the	O
word	O
embedding	O
w	O
j	O
.	O
	
Position	B-Method
embeddings	I-Method
have	O
also	O
been	O
found	O
helpful	O
in	O
memory	B-Task
networks	I-Task
for	O
question	B-Task
-	I-Task
answering	I-Task
and	O
language	B-Task
modeling	I-Task
	
[	O
reference	O
]	O
.	O
Similar	O
to	O
the	O
recurrent	B-Method
encoder	I-Method
(	O
§	O
	
2	O
)	O
,	O
the	O
attention	O
scores	O
a	O
ij	O
are	O
computed	O
from	O
the	O
pooled	B-Method
representations	I-Method
	
z	O
j	O
,	O
however	O
,	O
the	O
conditional	O
input	O
c	O
	
i	O
is	O
a	O
weighted	O
sum	O
of	O
the	O
embeddings	O
e	O
j	O
,	O
not	O
z	O
j	O
,	O
i.e.	O
,	O
	
The	O
input	O
sequence	O
is	O
padded	O
prior	O
to	O
pooling	B-Task
such	O
that	O
the	O
encoder	O
output	O
matches	O
the	O
input	O
length	O
|z|	O
=	O
	
|x|.	O
	
We	O
set	O
k	O
to	O
5	O
in	O
all	O
experiments	O
as	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
Convolutional	B-Method
Encoder	I-Method
	
A	O
straightforward	O
extension	O
of	O
pooling	B-Method
is	O
to	O
learn	O
the	O
kernel	B-Method
in	O
a	O
convolutional	B-Method
neural	I-Method
network	I-Method
(	O
CNN	B-Method
)	O
.	O
	
The	O
encoder	O
output	O
z	O
j	O
contains	O
information	O
about	O
a	O
fixed	O
-	O
sized	O
context	O
depending	O
on	O
the	O
kernel	O
width	O
k	O
but	O
the	O
desired	O
context	O
width	O
may	O
vary	O
.	O
	
This	O
can	O
be	O
addressed	O
by	O
stacking	O
several	O
layers	B-Method
of	I-Method
convolutions	I-Method
followed	O
by	O
non	O
-	O
linearities	O
:	O
additional	O
layers	O
increase	O
the	O
total	O
context	O
size	O
while	O
non	O
-	O
linearities	O
can	O
modulate	O
the	O
effective	O
size	O
of	O
the	O
context	O
as	O
needed	O
.	O
	
For	O
instance	O
,	O
stacking	O
5	O
convolutions	O
with	O
kernel	O
width	O
k	O
=	O
3	O
results	O
in	O
an	O
input	O
field	O
of	O
11	O
words	O
,	O
i.e.	O
,	O
each	O
output	O
depends	O
on	O
11	O
input	O
words	O
,	O
and	O
the	O
non	O
-	O
linearities	O
allow	O
the	O
encoder	B-Method
to	O
exploit	O
the	O
full	O
input	O
field	O
,	O
or	O
to	O
concentrate	O
on	O
fewer	O
words	O
as	O
needed	O
.	O
	
To	O
ease	O
learning	B-Task
for	O
deep	B-Task
encoders	I-Task
,	O
we	O
add	O
residual	O
connections	O
from	O
the	O
input	O
of	O
each	O
convolution	O
to	O
the	O
output	O
and	O
then	O
apply	O
the	O
non	O
-	O
linear	O
activation	O
function	O
to	O
the	O
output	O
(	O
tanh	O
;	O
[	O
reference	O
]	O
;	O
the	O
non	O
-	O
linearities	O
are	O
therefore	O
not	O
'	O
bypassed	O
'	O
.	O
	
Multi	O
-	O
layer	O
CNNs	B-Method
are	O
constructed	O
by	O
stacking	O
several	O
blocks	O
on	O
top	O
of	O
each	O
other	O
.	O
	
The	O
CNNs	B-Method
do	O
not	O
contain	O
pooling	B-Method
layers	I-Method
which	O
are	O
commonly	O
used	O
for	O
down	B-Task
-	I-Task
sampling	I-Task
,	O
i.e.	O
,	O
the	O
full	O
source	O
sequence	O
length	O
will	O
be	O
retained	O
after	O
the	O
network	O
has	O
been	O
applied	O
.	O
	
Similar	O
to	O
the	O
pooling	B-Method
model	I-Method
,	O
the	O
convolutional	B-Method
encoder	I-Method
uses	O
position	B-Method
embeddings	I-Method
.	O
	
The	O
final	O
encoder	B-Method
consists	O
of	O
two	O
stacked	O
convolutional	B-Method
networks	I-Method
(	O
Figure	O
1	O
)	O
:	O
CNN	B-Method
-	O
a	O
produces	O
the	O
encoder	O
output	O
	
z	O
j	O
to	O
compute	O
the	O
attention	O
scores	O
a	O
i	O
,	O
while	O
the	O
conditional	O
input	O
	
c	O
	
i	O
to	O
the	O
decoder	O
is	O
computed	O
by	O
summing	O
the	O
outputs	O
of	O
CNN	B-Method
-	I-Method
c	I-Method
,	O
	
In	O
practice	O
,	O
we	O
found	O
that	O
two	O
different	O
CNNs	B-Method
resulted	O
in	O
better	O
perplexity	B-Metric
as	O
well	O
as	O
BLEU	B-Metric
compared	O
to	O
using	O
a	O
single	O
one	O
(	O
§	O
5.3	O
)	O
.	O
	
We	O
also	O
found	O
this	O
to	O
perform	O
better	O
than	O
directly	O
summing	O
the	O
e	O
i	O
without	O
transformation	O
as	O
for	O
the	O
pooling	B-Method
model	I-Method
.	O
	
section	O
:	O
Related	O
Work	O
	
There	O
are	O
several	O
past	O
attempts	O
to	O
use	O
convolutional	B-Method
encoders	I-Method
for	O
neural	B-Task
machine	I-Task
translation	I-Task
,	O
however	O
,	O
to	O
our	O
knowledge	O
none	O
of	O
them	O
were	O
able	O
to	O
match	O
the	O
performance	O
of	O
recurrent	B-Method
encoders	I-Method
.	O
	
(	O
Kalchbrenner	O
and	O
Blunsom	O
,	O
2013	O
)	O
introduce	O
a	O
convolutional	B-Method
sentence	I-Method
encoder	I-Method
in	O
which	O
a	O
multi	O
-	O
layer	O
CNN	B-Method
generates	O
a	O
fixed	B-Method
sized	I-Method
embedding	I-Method
for	O
a	O
source	O
sentence	O
,	O
or	O
an	O
n	B-Method
-	I-Method
gram	I-Method
representation	I-Method
followed	O
by	O
transposed	B-Method
convolutions	I-Method
for	O
directly	O
generating	O
a	O
per	O
-	O
token	O
decoder	O
input	O
.	O
	
The	O
latter	O
requires	O
the	O
length	O
of	O
the	O
translation	O
prior	O
to	O
generation	B-Task
and	O
both	O
models	O
were	O
evaluated	O
by	O
rescoring	O
the	O
output	O
of	O
an	O
existing	O
translation	B-Method
system	I-Method
.	O
	
[	O
reference	O
]	O
propose	O
a	O
gated	O
recursive	O
CNN	B-Method
which	O
is	O
repeatedly	O
applied	O
until	O
a	O
fixed	B-Method
-	I-Method
size	I-Method
representation	I-Method
is	O
obtained	O
but	O
the	O
recurrent	B-Method
encoder	I-Method
achieves	O
higher	O
accuracy	B-Metric
.	O
	
In	O
follow	O
-	O
up	O
work	O
,	O
the	O
authors	O
improved	O
the	O
model	O
via	O
a	O
soft	B-Method
-	I-Method
attention	I-Method
mechanism	I-Method
but	O
did	O
not	O
reconsider	O
convolutional	B-Method
encoder	I-Method
models	I-Method
[	O
reference	O
]	O
.	O
	
Concurrently	O
to	O
our	O
work	O
,	O
[	O
reference	O
]	O
have	O
introduced	O
convolutional	B-Method
translation	I-Method
models	I-Method
without	O
an	O
explicit	O
attention	B-Method
mechanism	I-Method
but	O
their	O
approach	O
does	O
not	O
yet	O
result	O
in	O
state	O
-	O
ofthe	O
-	O
art	O
accuracy	B-Metric
.	O
	
[	O
reference	O
]	O
)	O
also	O
proposed	O
a	O
multi	O
-	O
layer	O
CNN	B-Method
to	O
generate	O
a	O
fixed	B-Method
-	I-Method
size	I-Method
encoder	I-Method
representation	I-Method
but	O
their	O
work	O
lacks	O
quantitative	B-Metric
evaluation	I-Metric
in	O
terms	O
of	O
BLEU	B-Metric
.	O
	
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
applied	O
convolutional	B-Method
models	I-Method
to	O
score	O
phrase	O
-	O
pairs	O
of	O
traditional	O
phrasebased	B-Method
and	I-Method
dependency	I-Method
-	I-Method
based	I-Method
translation	I-Method
models	I-Method
.	O
	
Convolutional	B-Method
architectures	I-Method
have	O
also	O
been	O
successful	O
in	O
language	B-Task
modeling	I-Task
but	O
so	O
far	O
failed	O
to	O
outperform	O
LSTMs	B-Method
[	O
reference	O
]	O
.	O
	
section	O
:	O
Experimental	O
Setup	O
	
section	O
:	O
Datasets	O
	
We	O
evaluate	O
different	O
encoders	B-Method
and	O
ablate	O
architectural	O
choices	O
on	O
a	O
small	O
dataset	O
from	O
the	O
GermanEnglish	B-Material
machine	I-Material
translation	I-Material
track	I-Material
of	O
IWSLT	B-Material
2014	I-Material
(	O
Cettolo	O
et	O
al	O
.	O
,	O
2014	O
)	O
with	O
a	O
similar	O
setting	O
to	O
	
[	O
reference	O
]	O
.	O
Unless	O
otherwise	O
stated	O
,	O
we	O
restrict	O
training	O
sentences	O
to	O
have	O
no	O
more	O
than	O
175	O
words	O
;	O
test	O
sentences	O
are	O
not	O
filtered	O
.	O
	
This	O
is	O
a	O
higher	O
threshold	O
compared	O
to	O
other	O
publications	O
but	O
ensures	O
proper	O
training	O
of	O
the	O
position	O
embeddings	O
for	O
non	B-Method
-	I-Method
recurrent	I-Method
encoders	I-Method
;	O
the	O
length	O
threshold	O
did	O
not	O
significantly	O
effect	O
recurrent	B-Method
encoders	I-Method
.	O
	
Length	B-Task
filtering	I-Task
results	O
in	O
167	O
K	O
sentence	O
pairs	O
and	O
we	O
test	O
on	O
the	O
concatenation	O
of	O
tst2010	B-Material
,	O
tst2011	B-Material
,	O
tst2012	B-Material
,	O
tst2013	B-Material
and	O
dev2010	B-Material
comprising	O
6948	O
sentence	O
pairs	O
.	O
	
[	O
reference	O
]	O
	
Our	O
final	O
results	O
are	O
on	O
three	O
major	O
WMT	B-Material
tasks	O
:	O
WMT'16	B-Material
English	I-Material
-	I-Material
Romanian	I-Material
.	O
	
We	O
use	O
the	O
same	O
data	O
and	O
pre	B-Method
-	I-Method
processing	I-Method
as	O
[	O
reference	O
]	O
and	O
train	O
on	O
2.8	O
M	O
sentence	O
pairs	O
.	O
	
[	O
reference	O
]	O
	
Our	O
model	O
is	O
word	B-Method
-	I-Method
based	I-Method
instead	O
of	O
relying	O
on	O
byte	B-Method
-	I-Method
pair	I-Method
encoding	I-Method
	
[	O
reference	O
]	O
.	O
	
We	O
evaluate	O
on	O
newstest2016	O
.	O
	
WMT'15	B-Material
	
English	B-Material
-	I-Material
German	I-Material
.	O
	
We	O
use	O
all	O
available	O
parallel	O
training	O
data	O
,	O
namely	O
Europarl	B-Material
v7	I-Material
,	O
	
Com	B-Method
-	I-Method
mon	I-Method
Crawl	I-Method
and	O
News	B-Method
Commentary	I-Method
v10	O
and	O
apply	O
the	O
standard	O
Moses	B-Method
tokenization	I-Method
to	O
obtain	O
3.9	O
M	O
sentence	O
pairs	O
	
[	O
reference	O
]	O
.	O
	
We	O
report	O
results	O
on	O
newstest2015	O
.	O
	
WMT'14	B-Material
English	I-Material
-	I-Material
French	I-Material
.	O
	
We	O
use	O
a	O
commonly	O
used	O
subset	O
of	O
12	O
M	O
sentence	O
pairs	O
[	O
reference	O
]	O
,	O
and	O
remove	O
sentences	O
longer	O
than	O
150	O
words	O
.	O
	
This	O
results	O
in	O
10.7	O
M	O
sentence	O
-	O
pairs	O
for	O
training	O
.	O
	
Results	O
are	O
reported	O
on	O
ntst14	O
.	O
	
A	O
small	O
subset	O
of	O
the	O
training	O
data	O
serves	O
as	O
validation	O
set	O
(	O
5	O
%	O
for	O
IWSLT'14	B-Material
and	O
1	O
%	O
for	O
WMT	B-Material
)	O
for	O
early	B-Task
stopping	I-Task
and	O
learning	B-Task
rate	I-Task
annealing	I-Task
(	O
§	O
4.3	O
)	O
.	O
	
For	O
IWSLT'14	B-Material
,	O
we	O
replace	O
words	O
that	O
occur	O
fewer	O
than	O
3	O
times	O
with	O
a	O
<	O
unk	O
>	O
symbol	O
,	O
which	O
results	O
in	O
a	O
vocabulary	O
of	O
24158	O
English	O
and	O
35882	O
German	O
word	O
types	O
.	O
	
For	O
WMT	B-Material
datasets	O
,	O
we	O
retain	O
200	O
K	O
source	O
and	O
80	O
K	O
target	O
words	O
.	O
	
For	O
English	B-Material
-	I-Material
French	I-Material
only	O
,	O
we	O
set	O
the	O
target	O
vocabulary	O
to	O
30	O
K	O
types	O
to	O
be	O
comparable	O
with	O
previous	O
work	O
.	O
	
section	O
:	O
Model	O
parameters	O
	
We	O
use	O
512	O
hidden	O
units	O
for	O
both	O
recurrent	B-Method
encoders	I-Method
and	O
decoders	B-Method
.	O
	
We	O
reset	O
the	O
decoder	O
hidden	O
states	O
to	O
zero	O
between	O
sentences	O
.	O
	
For	O
the	O
convolutional	B-Method
encoder	I-Method
,	O
512	O
hidden	O
units	O
are	O
used	O
for	O
each	O
layer	O
in	O
CNN	B-Method
-	I-Method
a	I-Method
,	O
while	O
layers	O
in	O
CNN	B-Method
-	I-Method
c	I-Method
contain	O
256	O
units	O
each	O
.	O
	
All	O
embeddings	O
,	O
including	O
the	O
output	O
produced	O
by	O
the	O
decoder	B-Method
before	O
the	O
final	O
linear	B-Method
layer	I-Method
,	O
are	O
of	O
256	O
dimensions	O
.	O
	
On	O
the	O
WMT	B-Material
corpora	O
,	O
we	O
find	O
that	O
we	O
can	O
improve	O
the	O
performance	O
of	O
the	O
bidirectional	B-Method
LSTM	I-Method
models	O
(	O
BiLSTM	B-Method
)	O
by	O
using	O
512	B-Method
-	I-Method
dimensional	I-Method
word	I-Method
embeddings	I-Method
.	O
	
Model	O
weights	O
are	O
initialized	O
from	O
a	O
uniform	O
distribution	O
within	O
[	O
−0.05	O
,	O
0.05	O
]	O
.	O
	
For	O
convolutional	B-Method
layers	I-Method
,	O
we	O
use	O
a	O
uniform	O
distribution	O
of	O
−kd	O
−0.5	O
,	O
kd	O
−0.5	O
,	O
where	O
k	O
is	O
the	O
kernel	O
width	O
(	O
we	O
use	O
3	O
throughout	O
this	O
work	O
)	O
and	O
d	O
is	O
the	O
input	O
size	O
for	O
the	O
first	O
layer	O
and	O
the	O
number	O
of	O
hidden	O
units	O
for	O
subsequent	O
layers	O
[	O
reference	O
]	O
.	O
For	O
CNN	B-Method
-	I-Method
c	I-Method
	
,	O
we	O
transform	O
the	O
input	O
and	O
output	O
with	O
a	O
linear	B-Method
layer	I-Method
each	O
to	O
match	O
the	O
smaller	O
embedding	O
size	O
.	O
	
The	O
model	O
parameters	O
were	O
tuned	O
on	O
IWSLT'14	B-Material
and	O
cross	O
-	O
validated	O
on	O
the	O
larger	O
WMT	B-Material
corpora	O
.	O
	
section	O
:	O
Optimization	B-Task
	
Recurrent	B-Method
models	I-Method
are	O
trained	O
with	O
Adam	B-Method
as	O
we	O
found	O
them	O
to	O
benefit	O
from	O
aggressive	B-Method
optimization	I-Method
.	O
	
We	O
use	O
a	O
step	O
width	O
of	O
3.125	O
·	O
10	O
−4	O
and	O
early	O
stopping	O
based	O
on	O
validation	B-Method
perplexity	I-Method
(	O
Kingma	O
and	O
Ba	O
,	O
2014	O
)	O
.	O
	
For	O
non	B-Method
-	I-Method
recurrent	I-Method
encoders	I-Method
,	O
we	O
obtain	O
best	O
results	O
with	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
(	O
SGD	B-Method
)	O
and	O
annealing	B-Method
:	O
we	O
use	O
a	O
learning	B-Metric
rate	I-Metric
of	O
0.1	O
and	O
once	O
the	O
validation	B-Metric
perplexity	I-Metric
stops	O
improving	O
,	O
we	O
reduce	O
the	O
learning	B-Metric
rate	I-Metric
by	O
an	O
order	O
of	O
magnitude	O
each	O
epoch	O
until	O
it	O
falls	O
below	O
10	O
−4	O
.	O
	
For	O
all	O
models	O
,	O
we	O
use	O
mini	O
-	O
batches	O
of	O
32	O
sentences	O
for	O
IWSLT'14	B-Material
and	O
64	O
for	O
WMT	B-Material
.	O
	
We	O
use	O
truncated	B-Method
back	I-Method
-	I-Method
propagation	I-Method
through	O
time	O
to	O
limit	O
the	O
length	O
of	O
target	O
sequences	O
per	O
mini	O
-	O
batch	O
to	O
25	O
words	O
.	O
	
Gradients	O
are	O
normalized	O
by	O
the	O
mini	O
-	O
batch	O
size	O
.	O
	
We	O
re	O
-	O
normalize	O
the	O
gradients	O
if	O
their	O
norm	O
exceeds	O
25	O
[	O
reference	O
]	O
.	O
Gradients	O
of	O
convolutional	B-Method
layers	I-Method
are	O
scaled	O
by	O
sqrt	O
(	O
dim	O
(	O
input	O
)	O
)	O
	
−1	O
similar	O
to	O
[	O
reference	O
]	O
.	O
	
We	O
use	O
dropout	B-Method
on	O
the	O
embeddings	O
and	O
decoder	O
outputs	O
h	O
	
i	O
with	O
a	O
rate	O
of	O
0.2	O
for	O
IWSLT'14	B-Material
and	O
0.1	O
for	O
WMT	B-Material
	
[	O
reference	O
]	O
.	O
All	O
models	O
are	O
implemented	O
in	O
Torch	B-Method
[	O
reference	O
]	O
and	O
trained	O
on	O
a	O
single	O
GPU	B-Method
.	O
	
section	O
:	O
Evaluation	O
	
We	O
report	O
accuracy	B-Metric
of	O
single	O
systems	O
by	O
training	O
several	O
identical	O
models	O
with	O
different	O
random	O
seeds	O
(	O
5	O
for	O
IWSLT'14	B-Material
,	O
3	O
for	O
WMT	B-Material
)	O
and	O
pick	O
the	O
one	O
with	O
the	O
best	O
validation	B-Metric
perplexity	I-Metric
for	O
final	O
BLEU	B-Metric
evaluation	I-Metric
.	O
	
Translations	O
are	O
generated	O
by	O
a	O
beam	B-Method
search	I-Method
and	O
we	O
normalize	O
log	O
-	O
likelihood	O
scores	O
by	O
sentence	O
length	O
.	O
	
On	O
IWSLT'14	B-Material
we	O
use	O
a	O
beam	O
width	O
of	O
10	O
and	O
for	O
WMT	B-Material
models	O
we	O
tune	O
beam	O
width	O
and	O
word	O
penalty	O
on	O
a	O
separate	O
test	O
set	O
,	O
that	O
is	O
newsdev2016	O
for	O
WMT'16	B-Material
English	I-Material
-	I-Material
Romanian	I-Material
,	O
newstest2014	B-Material
for	O
WMT'15	B-Material
English	I-Material
-	I-Material
German	I-Material
and	O
ntst1213	O
for	O
WMT'14	B-Material
English	I-Material
-	I-Material
French	I-Material
.	O
	
[	O
reference	O
]	O
	
The	O
word	B-Method
penalty	I-Method
adds	O
a	O
constant	O
factor	O
to	O
log	O
-	O
likelihoods	O
,	O
except	O
for	O
the	O
end	O
-	O
of	O
-	O
sentence	O
token	O
.	O
	
Prior	O
to	O
scoring	O
the	O
generated	O
translations	O
against	O
the	O
respective	O
references	O
,	O
we	O
perform	O
unknown	O
word	O
replacement	O
based	O
on	O
attention	O
scores	O
	
[	O
reference	O
]	O
.	O
Unknown	O
words	O
are	O
replaced	O
by	O
looking	O
up	O
the	O
source	O
word	O
with	O
the	O
maximum	O
attention	O
score	O
in	O
a	O
pre	O
-	O
computed	O
dictionary	O
.	O
	
If	O
the	O
dictionary	O
contains	O
no	O
translation	O
,	O
then	O
we	O
simply	O
copy	O
the	O
source	O
word	O
.	O
	
Dictionaries	O
were	O
extracted	O
from	O
the	O
aligned	O
training	O
data	O
that	O
was	O
aligned	O
with	O
fast	O
align	O
	
[	O
reference	O
]	O
.	O
	
Each	O
source	O
word	O
is	O
mapped	O
to	O
the	O
target	O
word	O
it	O
is	O
most	O
frequently	O
aligned	O
to	O
.	O
	
For	O
convolutional	B-Method
encoders	I-Method
with	O
stacked	O
CNN	B-Method
-	O
c	O
layers	O
we	O
noticed	O
for	O
some	O
models	O
that	O
the	O
attention	O
maxima	O
were	O
consistently	O
shifted	O
by	O
one	O
word	O
.	O
	
We	O
determine	O
this	O
per	O
-	O
model	O
offset	O
on	O
the	O
abovementioned	O
development	O
sets	O
and	O
correct	O
for	O
it	O
.	O
	
Finally	O
,	O
we	O
compute	O
case	O
-	O
sensitive	O
tokenized	O
BLEU	B-Metric
,	O
except	O
for	O
WMT'16	B-Material
English	I-Material
-	I-Material
Romanian	I-Material
where	O
we	O
use	O
detokenized	O
BLEU	B-Metric
to	O
be	O
comparable	O
with	O
[	O
reference	O
]	O
5	O
Results	O
	
section	O
:	O
Recurrent	B-Method
vs.	I-Method
Non	I-Method
-	I-Method
recurrent	I-Method
Encoders	I-Method
	
We	O
first	O
compare	O
recurrent	B-Method
and	I-Method
non	I-Method
-	I-Method
recurrent	I-Method
encoders	I-Method
in	O
terms	O
of	O
perplexity	B-Metric
and	O
BLEU	B-Metric
on	O
IWSLT'14	B-Material
with	O
and	O
without	O
position	O
embeddings	O
(	O
§	O
3.1	O
)	O
and	O
include	O
a	O
phrase	B-Method
-	I-Method
based	I-Method
system	I-Method
[	O
reference	O
]	O
.	O
Table	O
1	O
shows	O
that	O
a	O
single	B-Method
-	I-Method
layer	I-Method
convolutional	I-Method
model	I-Method
with	O
position	B-Method
embeddings	I-Method
(	O
Convolutional	B-Method
)	O
can	O
outperform	O
both	O
a	O
uni	B-Method
-	I-Method
directional	I-Method
LSTM	I-Method
encoder	I-Method
(	O
LSTM	B-Method
)	O
as	O
well	O
as	O
a	O
bi	O
-	O
directional	O
LSTM	B-Method
encoder	O
(	O
BiLSTM	B-Method
)	O
.	O
	
Next	O
,	O
we	O
increase	O
the	O
depth	O
of	O
the	O
convolutional	B-Method
encoder	I-Method
.	O
	
We	O
choose	O
a	O
5	O
Specifically	O
,	O
we	O
select	O
a	O
beam	O
from	O
{	O
5	O
,	O
10	O
}	O
and	O
a	O
word	O
penalty	O
from	O
{	O
0	O
,	O
−0.5	O
,	O
−1	O
,	O
−1.5	O
}	O
	
6	O
https:	O
//	O
github.com	O
/	O
moses	O
-	O
smt	O
/	O
mosesdecoder	O
/	O
blob	O
/	O
617e8c8ed1630fb1d1	O
/	O
	
scripts	O
/	O
generic	O
/	O
{multi	O
-	O
bleu.perl	O
,	O
mteval	O
-	O
v13a.pl	O
}	O
good	O
setting	O
by	O
independently	O
varying	O
the	O
number	O
of	O
layers	O
in	O
CNN	B-Method
-	I-Method
a	I-Method
and	O
CNN	B-Method
-	I-Method
c	I-Method
between	O
1	O
and	O
10	O
and	O
obtained	O
best	O
validation	B-Metric
set	I-Metric
perplexity	I-Metric
with	O
six	O
layers	O
for	O
CNN	B-Method
-	I-Method
a	I-Method
and	O
three	O
layers	O
for	O
CNN	B-Method
-	I-Method
c	I-Method
.	O
	
This	O
configuration	O
outperforms	O
BiLSTM	B-Method
by	O
0.7	O
BLEU	B-Metric
(	O
	
Deep	B-Method
Convolutional	I-Method
6	I-Method
/	I-Method
3	I-Method
)	O
.	O
	
We	O
investigate	O
depth	O
in	O
the	O
convolutional	B-Method
encoder	I-Method
more	O
in	O
§	O
5.3	O
.	O
	
Among	O
recurrent	B-Method
encoders	I-Method
,	O
the	O
BiLSTM	B-Method
is	O
2.3	O
BLEU	B-Metric
better	O
than	O
the	O
uni	B-Method
-	I-Method
directional	I-Method
version	O
.	O
	
The	O
simple	O
pooling	B-Method
encoder	I-Method
which	O
does	O
not	O
contain	O
any	O
parameters	O
is	O
only	O
1.3	O
BLEU	B-Metric
lower	O
than	O
a	O
unidirectional	B-Method
LSTM	I-Method
encoder	I-Method
and	O
3.6	O
BLEU	B-Metric
lower	O
than	O
BiLSTM	B-Method
.	O
	
The	O
results	O
without	O
position	O
embeddings	O
(	O
words	O
)	O
show	O
that	O
position	O
information	O
is	O
crucial	O
for	O
convolutional	B-Method
encoders	I-Method
.	O
	
In	O
particular	O
for	O
shallow	B-Method
models	I-Method
(	O
Pooling	B-Method
and	O
Convolutional	B-Method
)	O
,	O
whereas	O
deeper	B-Method
models	I-Method
are	O
less	O
effected	O
.	O
	
Recurrent	B-Method
encoders	I-Method
do	O
not	O
benefit	O
from	O
explicit	O
position	O
information	O
because	O
this	O
information	O
can	O
be	O
naturally	O
extracted	O
through	O
the	O
sequential	B-Method
computation	I-Method
.	O
	
When	O
tuning	O
model	O
settings	O
,	O
we	O
generally	O
observe	O
good	O
correlation	B-Metric
between	O
perplexity	B-Metric
and	O
BLEU	B-Metric
.	O
	
However	O
,	O
for	O
convolutional	B-Method
encoders	I-Method
perplexity	I-Method
gains	O
translate	O
to	O
smaller	O
BLEU	B-Metric
improvements	O
compared	O
to	O
recurrent	B-Method
counterparts	I-Method
(	O
Table	O
1	O
)	O
.	O
	
We	O
observe	O
a	O
similar	O
trend	O
on	O
larger	O
datasets	O
.	O
	
section	O
:	O
Evaluation	O
on	O
WMT	B-Material
Corpora	O
	
Next	O
,	O
we	O
evaluate	O
the	O
BiLSTM	B-Method
encoder	O
and	O
the	O
convolutional	B-Method
encoder	I-Method
architecture	I-Method
on	O
three	O
larger	O
tasks	O
and	O
compare	O
against	O
previously	O
published	O
results	O
.	O
	
On	O
WMT'16	B-Material
English	I-Material
-	I-Material
Romanian	I-Material
translation	O
we	O
compare	O
to	O
[	O
reference	O
]	O
,	O
the	O
winning	O
single	O
system	O
entry	O
for	O
this	O
language	O
pair	O
.	O
	
Their	O
model	O
consists	O
of	O
a	O
bi	B-Method
-	I-Method
directional	I-Method
GRU	I-Method
encoder	I-Method
,	O
a	O
GRU	B-Method
decoder	I-Method
and	O
MLP	B-Method
-	I-Method
based	I-Method
attention	I-Method
.	O
	
Table	O
2	O
:	O
	
Accuracy	B-Metric
on	O
three	O
WMT	B-Material
tasks	O
,	O
including	O
results	O
published	O
in	O
previous	O
work	O
.	O
	
For	O
deep	B-Method
convolutional	I-Method
encoders	I-Method
,	O
we	O
include	O
the	O
number	O
of	O
layers	O
in	O
CNN	B-Method
-	I-Method
a	I-Method
and	O
CNN	B-Method
-	I-Method
c	I-Method
,	O
respectively	O
.	O
	
They	O
use	O
byte	B-Method
pair	I-Method
encoding	I-Method
(	O
BPE	B-Method
)	O
to	O
achieve	O
openvocabulary	B-Task
translation	I-Task
and	O
dropout	O
in	O
all	O
components	O
of	O
the	O
neural	B-Method
network	I-Method
to	O
achieve	O
28.1	O
BLEU	B-Metric
;	O
we	O
use	O
the	O
same	O
pre	B-Method
-	I-Method
processing	I-Method
but	O
no	O
BPE	B-Method
(	O
§	O
4	O
)	O
.	O
	
The	O
results	O
(	O
Table	O
2	O
)	O
show	O
that	O
a	O
deep	B-Method
convolutional	I-Method
encoder	I-Method
can	O
perform	O
competitively	O
to	O
the	O
state	O
of	O
the	O
art	O
on	O
this	O
dataset	O
	
[	O
reference	O
]	O
.	O
Our	O
bi	O
-	O
directional	O
LSTM	B-Method
encoder	O
baseline	O
is	O
0.6	O
BLEU	B-Metric
lower	O
than	O
the	O
state	O
of	O
the	O
art	O
but	O
uses	O
only	O
512	O
hidden	O
units	O
compared	O
to	O
1024	O
.	O
	
A	O
singlelayer	B-Method
convolutional	I-Method
encoder	I-Method
with	O
embedding	O
size	O
256	O
performs	O
at	O
27.1	O
BLEU	B-Metric
.	O
	
Increasing	O
the	O
number	O
of	O
convolutional	B-Method
layers	I-Method
to	O
8	O
in	O
CNN	B-Method
-	I-Method
a	I-Method
and	O
4	O
in	O
CNN	B-Method
-	I-Method
c	I-Method
achieves	O
27.8	O
BLEU	B-Metric
which	O
outperforms	O
our	O
baseline	O
and	O
is	O
competitive	O
to	O
the	O
state	O
of	O
the	O
art	O
.	O
	
On	O
WMT'15	B-Material
English	I-Material
to	I-Material
German	I-Material
,	O
we	O
compare	O
to	O
a	O
BiLSTM	B-Method
baseline	O
and	O
prior	O
work	O
:	O
[	O
reference	O
]	O
introduce	O
a	O
large	O
output	O
vocabulary	O
;	O
the	O
decoder	O
of	O
(	O
Chung	O
et	O
al	O
.	O
,	O
2016	O
)	O
operates	O
on	O
the	O
character	O
-	O
level	O
;	O
[	O
reference	O
]	O
uses	O
LSTMs	B-Method
instead	O
of	O
GRUs	B-Method
and	O
feeds	O
the	O
conditional	O
input	O
to	O
the	O
output	O
layer	O
as	O
well	O
as	O
to	O
the	O
decoder	O
.	O
	
Our	O
single	O
-	O
layer	O
BiLSTM	B-Method
baseline	O
is	O
competitive	O
to	O
prior	O
work	O
and	O
a	O
two	O
-	O
layer	O
BiLSTM	B-Method
encoder	O
performs	O
0.6	O
BLEU	B-Metric
better	O
at	O
24.1	O
BLEU	B-Metric
.	O
	
Previous	O
work	O
also	O
used	O
multi	O
-	O
layer	O
setups	O
,	O
e.g.	O
,	O
[	O
reference	O
]	O
has	O
two	O
layers	O
both	O
in	O
the	O
encoder	B-Method
and	O
the	O
decoder	B-Method
with	O
1024	O
hidden	O
units	O
,	O
and	O
[	O
reference	O
]	O
use	O
1000	O
hidden	O
units	O
per	O
LSTM	B-Method
.	O
	
We	O
use	O
512	O
hidden	O
units	O
for	O
both	O
LSTM	B-Method
and	O
convolutional	O
encoders	O
.	O
	
Our	O
convolutional	B-Method
model	I-Method
with	O
15	O
layers	O
in	O
CNN	B-Method
-	I-Method
a	I-Method
and	O
5	O
layers	O
in	O
CNN	B-Method
-	I-Method
c	I-Method
outperforms	O
the	O
BiLSTM	B-Method
encoder	O
with	O
both	O
a	O
single	O
decoder	B-Method
layer	I-Method
or	O
two	O
decoder	B-Method
layers	I-Method
.	O
	
Finally	O
,	O
we	O
evaluate	O
on	O
the	O
larger	O
WMT'14	B-Material
English	I-Material
-	I-Material
French	I-Material
corpus	O
.	O
	
On	O
this	O
dataset	O
the	O
recurrent	B-Method
architectures	I-Method
benefit	O
from	O
an	O
additional	O
layer	O
both	O
in	O
the	O
encoder	B-Method
and	O
the	O
decoder	B-Method
.	O
	
For	O
a	O
singlelayer	B-Method
decoder	I-Method
,	O
a	O
deep	B-Method
convolutional	I-Method
encoder	I-Method
outperforms	O
the	O
BiLSTM	B-Method
accuracy	O
by	O
0.3	O
BLEU	B-Metric
and	O
for	O
a	O
two	B-Method
-	I-Method
layer	I-Method
decoder	I-Method
,	O
our	O
very	O
deep	B-Method
convolutional	I-Method
encoder	I-Method
with	O
up	O
to	O
20	O
layers	O
outperforms	O
the	O
BiLSTM	B-Method
by	O
0.4	O
BLEU	B-Metric
.	O
	
It	O
has	O
40	O
%	O
fewer	O
parameters	O
than	O
the	O
BiLSTM	B-Method
due	O
to	O
the	O
smaller	O
embedding	O
sizes	O
.	O
	
We	O
also	O
outperform	O
several	O
previous	O
systems	O
,	O
including	O
the	O
very	B-Method
deep	I-Method
encoder	I-Method
-	I-Method
decoder	I-Method
model	I-Method
proposed	O
by	O
[	O
reference	O
]	O
.	O
Our	O
best	O
result	O
is	O
just	O
0.2	O
BLEU	B-Metric
below	O
[	O
reference	O
]	O
who	O
use	O
a	O
very	O
deep	B-Method
LSTM	I-Method
setup	I-Method
with	O
a	O
9	B-Method
-	I-Method
layer	I-Method
encoder	I-Method
,	O
a	O
7	B-Method
-	I-Method
layer	I-Method
decoder	I-Method
,	O
shortcut	B-Method
connections	I-Method
and	O
extensive	O
regularization	B-Method
with	O
dropout	B-Method
and	I-Method
L2	I-Method
regularization	I-Method
.	O
	
section	O
:	O
Convolutional	B-Method
Encoder	I-Method
Architecture	I-Method
Details	O
	
We	O
next	O
motivate	O
our	O
design	O
of	O
the	O
convolutional	B-Method
encoder	I-Method
(	O
§	O
3.2	O
)	O
.	O
	
We	O
use	O
the	O
smaller	O
IWSLT'14	B-Material
German	O
-	O
English	O
setup	O
without	O
unknown	O
word	O
replacement	O
to	O
enable	O
fast	O
experimental	O
turn	O
-	O
around	O
.	O
	
BLEU	B-Metric
results	O
are	O
averaged	O
over	O
three	O
training	O
runs	O
initialized	O
with	O
different	O
seeds	O
.	O
	
Figure	O
2	O
shows	O
accuracy	B-Metric
for	O
a	O
different	O
number	O
of	O
layers	O
of	O
both	O
CNNs	B-Method
with	O
and	O
without	O
residual	O
connections	O
.	O
	
Our	O
first	O
observation	O
is	O
that	O
computing	O
the	O
conditional	O
input	O
	
c	O
	
i	O
directly	O
over	O
	
embeddings	O
e	O
(	O
line	O
"	O
without	O
CNN	B-Method
-	I-Method
c	I-Method
"	O
)	O
is	O
already	O
working	O
well	O
at	O
28.3	O
BLEU	B-Metric
with	O
a	O
single	O
CNN	B-Method
-	O
a	O
layer	O
and	O
at	O
29.1	O
BLEU	B-Metric
for	O
CNN	B-Method
-	I-Method
a	I-Method
with	O
7	O
layers	O
(	O
Figure	O
2a	O
)	O
.	O
	
Increasing	O
the	O
number	O
of	O
CNN	B-Method
-	O
c	O
layers	O
is	O
beneficial	O
up	O
to	O
three	O
layers	O
and	O
beyond	O
this	O
we	O
did	O
not	O
observe	O
further	O
improvements	O
.	O
	
Similarly	O
,	O
increasing	O
the	O
number	O
of	O
layers	O
in	O
CNN	B-Method
-	I-Method
a	I-Method
beyond	O
six	O
does	O
not	O
increase	O
accuracy	B-Metric
on	O
this	O
relatively	O
small	O
dataset	O
.	O
	
In	O
general	O
,	O
choosing	O
two	O
to	O
three	O
times	O
as	O
many	O
layers	O
in	O
CNN	B-Method
-	I-Method
a	I-Method
as	O
in	O
CNN	B-Method
-	I-Method
c	I-Method
is	O
a	O
good	O
rule	O
of	O
thumb	O
.	O
	
Without	O
residual	O
connections	O
,	O
the	O
model	O
fails	O
to	O
utilize	O
the	O
increase	O
in	O
modeling	O
power	O
from	O
additional	O
layers	O
,	O
and	O
performance	O
drops	O
significantly	O
for	O
deeper	O
encoders	O
(	O
Figure	O
2b	O
)	O
.	O
	
Our	O
convolutional	B-Method
architecture	I-Method
relies	O
on	O
two	O
sets	O
of	O
networks	O
,	O
CNN	B-Method
-	I-Method
a	I-Method
for	O
attention	B-Task
score	I-Task
computation	I-Task
	
a	O
i	O
and	O
CNN	B-Method
-	I-Method
c	I-Method
for	O
the	O
conditional	O
input	O
	
c	O
i	O
to	O
be	O
fed	O
to	O
the	O
decoder	B-Method
.	O
	
We	O
found	O
that	O
using	O
the	O
same	O
network	O
for	O
both	O
tasks	O
,	O
similar	O
to	O
recurrent	B-Method
encoders	I-Method
,	O
resulted	O
in	O
poor	O
accuracy	B-Metric
of	O
22.9	O
BLEU	B-Metric
.	O
	
This	O
compares	O
to	O
28.5	O
BLEU	B-Metric
for	O
separate	O
singlelayer	B-Method
networks	I-Method
,	O
or	O
28.3	O
BLEU	B-Metric
when	O
aggregating	O
embeddings	O
for	O
c	O
i	O
.	O
	
Increasing	O
the	O
number	O
of	O
layers	O
in	O
the	O
single	O
network	O
setup	O
did	O
not	O
help	O
.	O
	
Figure	O
2	O
(	O
a	O
)	O
suggests	O
that	O
the	O
attention	O
weights	O
(	O
CNN	B-Method
-	I-Method
a	I-Method
)	O
need	O
to	O
integrate	O
information	O
from	O
a	O
wide	O
context	O
which	O
can	O
be	O
done	O
with	O
a	O
deep	B-Method
stack	I-Method
.	O
	
At	O
the	O
same	O
time	O
,	O
the	O
vectors	O
which	O
are	O
averaged	O
(	O
CNN	B-Method
-	I-Method
c	I-Method
)	O
seem	O
to	O
benefit	O
from	O
a	O
shallower	O
,	O
more	O
local	O
representation	O
closer	O
to	O
the	O
input	O
words	O
.	O
	
Two	O
stacks	O
are	O
an	O
easy	O
way	O
to	O
achieve	O
these	O
contradicting	O
requirements	O
.	O
	
In	O
Appendix	O
A	O
we	O
visualize	O
attention	O
scores	O
and	O
find	O
that	O
alignments	O
for	O
CNN	B-Method
encoders	I-Method
are	O
less	O
sharp	O
compared	O
to	O
BiLSTMs	B-Method
,	O
however	O
,	O
this	O
does	O
not	O
affect	O
the	O
effectiveness	O
of	O
unknown	B-Task
word	I-Task
replacement	I-Task
once	O
we	O
adjust	O
for	O
shifted	O
maxima	O
.	O
	
In	O
Appendix	O
B	O
we	O
investigate	O
whether	O
deep	B-Method
convolutional	I-Method
encoders	I-Method
are	O
required	O
for	O
translating	O
long	O
sentences	O
and	O
observe	O
that	O
even	O
relatively	O
shallow	B-Method
encoders	I-Method
perform	O
well	O
on	O
long	O
sentences	O
.	O
	
section	O
:	O
Training	O
and	O
Generation	B-Metric
Speed	I-Metric
	
For	O
training	B-Task
,	O
we	O
use	O
the	O
fast	O
CuDNN	O
LSTM	B-Method
implementation	O
for	O
layers	O
without	O
attention	O
and	O
experiment	O
on	O
IWSLT'14	B-Material
with	O
batch	O
size	O
32	O
.	O
	
The	O
single	O
-	O
layer	O
BiLSTM	B-Method
model	O
trains	O
at	O
4300	O
target	O
words	O
/	O
second	O
,	O
while	O
the	O
6	B-Method
/	I-Method
3	I-Method
deep	I-Method
convolutional	I-Method
encoder	I-Method
compares	O
at	O
6400	O
words	O
/	O
second	O
on	O
an	O
NVidia	O
Tesla	O
M40	O
GPU	O
.	O
	
We	O
do	O
not	O
observe	O
shorter	O
overall	O
training	B-Metric
time	I-Metric
since	O
SGD	B-Method
converges	O
slower	O
than	O
Adam	B-Method
which	O
we	O
use	O
for	O
BiLSTM	B-Method
models	O
.	O
	
We	O
measure	O
generation	B-Metric
speed	I-Metric
on	O
an	O
Intel	O
Haswell	O
CPU	O
clocked	O
at	O
2.50GHz	O
with	O
a	O
single	O
thread	O
for	O
BLAS	O
operations	O
.	O
	
We	O
use	O
vocabulary	B-Method
selection	I-Method
which	O
can	O
speed	O
up	O
generation	B-Task
by	O
up	O
to	O
a	O
factor	O
of	O
ten	O
at	O
no	O
cost	O
in	O
accuracy	B-Metric
via	O
making	O
the	O
time	O
to	O
compute	O
the	O
final	O
output	O
layer	O
negligible	O
	
[	O
reference	O
][	O
reference	O
]	O
.	O
	
This	O
shifts	O
the	O
focus	O
from	O
the	O
efficiency	O
of	O
the	O
encoder	B-Method
to	O
the	O
efficiency	O
of	O
the	O
decoder	B-Method
.	O
	
On	O
IWSLT'14	B-Material
(	O
Table	O
3a	O
)	O
the	O
convolutional	B-Method
encoder	I-Method
increases	O
the	O
speed	O
of	O
the	O
overall	O
model	O
by	O
a	O
factor	O
of	O
1.35	O
compared	O
to	O
the	O
BiLSTM	B-Method
encoder	O
while	O
improving	O
accuracy	B-Metric
by	O
0.7	O
BLEU	B-Metric
.	O
	
In	O
this	O
setup	O
both	O
encoders	B-Method
models	I-Method
have	O
the	O
same	O
hidden	O
layer	O
and	O
embedding	O
sizes	O
.	O
	
On	O
the	O
larger	O
WMT'15	B-Material
English	I-Material
-	I-Material
German	I-Material
task	O
(	O
Table	O
3b	O
)	O
the	O
convolutional	B-Method
encoder	I-Method
speeds	O
up	O
generation	B-Task
by	O
2.1	O
times	O
compared	O
to	O
a	O
two	O
-	O
layer	B-Method
BiL	I-Method
-	I-Method
STM	I-Method
.	O
	
This	O
corresponds	O
to	O
231	O
source	O
words	O
/	O
second	O
with	O
beam	O
size	O
5	O
.	O
	
Our	O
best	O
model	O
on	O
this	O
dataset	O
generates	O
203	O
words	O
/	O
second	O
but	O
at	O
slightly	O
lower	O
accuracy	B-Metric
compared	O
to	O
the	O
full	O
vocabulary	O
setting	O
in	O
Table	O
2	O
.	O
	
The	O
recurrent	B-Method
encoder	I-Method
uses	O
larger	O
embeddings	O
than	O
the	O
convolutional	B-Method
encoder	I-Method
which	O
were	O
required	O
for	O
the	O
models	O
to	O
match	O
in	O
accuracy	B-Metric
.	O
	
The	O
smaller	O
embedding	B-Metric
size	I-Metric
is	O
not	O
the	O
only	O
reason	O
for	O
the	O
speed	O
-	O
up	O
.	O
	
In	O
Table	O
3a	O
(	O
a	O
)	O
,	O
we	O
compare	O
a	O
Conv	B-Method
6	I-Method
/	I-Method
3	I-Method
encoder	I-Method
and	O
a	O
BiLSTM	B-Method
with	O
equal	O
embedding	O
sizes	O
.	O
	
The	O
convolutional	B-Method
encoder	I-Method
is	O
still	O
1.34x	O
faster	O
(	O
at	O
0.7	O
higher	O
BLEU	B-Metric
)	O
although	O
it	O
requires	O
roughly	O
1.6x	O
as	O
many	O
FLOPs	O
.	O
	
We	O
believe	O
that	O
this	O
is	O
likely	O
due	O
to	O
better	O
cache	O
locality	O
for	O
convolutional	B-Method
layers	I-Method
on	O
CPUs	B-Method
:	O
an	O
LSTM	B-Method
with	O
fused	O
gates	O
7	O
requires	O
two	O
big	O
matrix	B-Method
multiplications	I-Method
with	O
different	O
weights	O
as	O
well	O
as	O
additions	O
,	O
multiplications	O
and	O
non	O
-	O
linearities	O
for	O
each	O
source	O
word	O
,	O
while	O
the	O
output	O
of	O
each	O
convolutional	B-Method
layer	I-Method
can	O
be	O
computed	O
as	O
whole	O
with	O
a	O
single	O
matrix	O
multiply	O
.	O
	
For	O
comparison	O
,	O
the	O
quantized	O
deep	O
LSTM	B-Method
-	O
7	O
Our	O
bi	O
-	O
directional	O
LSTM	B-Method
implementation	O
is	O
based	O
on	O
torch	B-Method
rnnlib	I-Method
which	O
uses	O
fused	O
LSTM	B-Method
gates	O
(	O
https:	O
//	O
github.com	O
/	O
facebookresearch	O
/	O
torch	O
-	O
rnnlib	O
/	O
)	O
and	O
which	O
we	O
consider	O
an	O
efficient	O
implementation	O
.	O
	
section	O
:	O
Conclusion	O
	
We	O
introduced	O
a	O
simple	O
encoder	B-Method
model	I-Method
for	O
neural	B-Task
machine	I-Task
translation	I-Task
based	O
on	O
convolutional	B-Method
networks	I-Method
.	O
	
This	O
approach	O
is	O
more	O
parallelizable	O
than	O
recurrent	B-Method
networks	I-Method
and	O
provides	O
a	O
shorter	O
path	O
to	O
capture	O
long	O
-	O
range	O
dependencies	O
in	O
the	O
source	O
.	O
	
We	O
find	O
it	O
essential	O
to	O
use	O
source	O
position	O
embeddings	O
as	O
well	O
as	O
different	O
CNNs	B-Method
for	O
attention	B-Task
score	I-Task
computation	I-Task
and	O
conditional	B-Task
input	I-Task
aggregation	I-Task
.	O
	
Our	O
experiments	O
show	O
that	O
convolutional	B-Method
encoders	I-Method
perform	O
on	O
par	O
or	O
better	O
than	O
baselines	O
based	O
on	O
bi	O
-	O
directional	O
LSTM	B-Method
encoders	O
.	O
	
In	O
comparison	O
to	O
other	O
recent	O
work	O
,	O
our	O
deep	B-Method
convolutional	I-Method
encoder	I-Method
is	O
competitive	O
to	O
the	O
best	O
published	O
results	O
to	O
date	O
(	O
WMT'16	B-Material
English	I-Material
-	I-Material
Romanian	I-Material
)	O
which	O
are	O
obtained	O
with	O
significantly	O
more	O
complex	O
models	O
(	O
WMT'14	B-Material
English	I-Material
-	I-Material
French	I-Material
)	O
or	O
stem	O
from	O
improvements	O
that	O
are	O
orthogonal	O
to	O
our	O
work	O
(	O
WMT'15	B-Material
English	I-Material
-	I-Material
German	I-Material
)	O
.	O
	
Our	O
architecture	O
also	O
leads	O
to	O
large	O
generation	B-Metric
speed	I-Metric
improvements	I-Metric
:	O
translation	B-Method
models	I-Method
with	O
our	O
convolutional	B-Method
encoder	I-Method
can	O
translate	O
twice	O
as	O
fast	O
as	O
strong	O
baselines	O
with	O
bi	B-Method
-	I-Method
directional	I-Method
recurrent	I-Method
encoders	I-Method
.	O
	
Future	O
work	O
includes	O
better	O
training	O
to	O
enable	O
faster	O
convergence	O
with	O
the	O
convolutional	B-Method
encoder	I-Method
to	O
better	O
leverage	O
the	O
higher	O
processing	B-Metric
speed	I-Metric
.	O
	
Our	O
fast	B-Method
architecture	I-Method
is	O
interesting	O
for	O
character	B-Task
level	I-Task
encoders	I-Task
where	O
the	O
input	O
is	O
significantly	O
longer	O
than	O
for	O
words	O
.	O
	
Also	O
,	O
we	O
plan	O
to	O
investigate	O
the	O
effectiveness	O
of	O
our	O
architecture	O
on	O
other	O
sequence	B-Task
-	I-Task
tosequence	I-Task
tasks	I-Task
,	O
e.g.	B-Task
summarization	I-Task
,	O
constituency	B-Task
parsing	I-Task
,	O
dialog	B-Task
modeling	I-Task
.	O
	
section	O
:	O
A	O
Alignment	B-Task
Visualization	I-Task
	
In	O
Figure	O
4	O
and	O
Figure	O
5	O
,	O
we	O
plot	O
attention	B-Metric
scores	I-Metric
for	O
a	O
sample	O
WMT'15	B-Material
English	I-Material
-	I-Material
German	I-Material
and	O
WMT'14	B-Material
English	I-Material
-	I-Material
French	I-Material
translation	O
with	O
BiLSTM	B-Method
and	O
deep	B-Method
convolutional	I-Method
encoders	I-Method
.	O
	
The	O
translation	O
is	O
on	O
the	O
x	O
-	O
axis	O
and	O
the	O
source	O
sentence	O
on	O
the	O
y	O
-	O
axis	O
.	O
	
The	O
attention	O
scores	O
of	O
the	O
BiLSTM	B-Method
output	O
are	O
sharp	O
but	O
do	O
not	O
necessarily	O
represent	O
a	O
correct	O
alignment	O
.	O
	
For	O
CNN	B-Method
encoders	I-Method
the	O
scores	O
are	O
less	O
focused	O
but	O
still	O
indicate	O
an	O
approximate	O
source	O
location	O
,	O
e.g.	O
,	O
in	O
Figure	O
4b	O
,	O
when	O
moving	O
the	O
clause	O
"	O
over	O
1	O
,	O
000	O
people	O
were	O
taken	O
hostage	O
"	O
to	O
the	O
back	O
of	O
the	O
translation	O
.	O
	
For	O
some	O
models	O
,	O
attention	O
maxima	O
are	O
consistently	O
shifted	O
by	O
one	O
token	O
as	O
both	O
in	O
Figure	O
4b	O
and	O
Figure	O
5b	O
.	O
	
Interestingly	O
,	O
convolutional	B-Method
encoders	I-Method
tend	O
to	O
focus	O
on	O
the	O
last	O
token	O
(	O
Figure	O
4b	O
)	O
or	O
both	O
the	O
first	O
and	O
last	O
tokens	O
(	O
Figure	O
5b	O
)	O
.	O
	
Motivated	O
by	O
the	O
hypothesis	O
that	O
the	O
this	O
may	O
be	O
due	O
to	O
the	O
decoder	B-Method
depending	O
on	O
the	O
length	O
of	O
the	O
source	O
sentence	O
(	O
which	O
it	O
can	O
not	O
determine	O
without	O
position	O
embeddings	O
)	O
,	O
we	O
explicitly	O
provided	O
a	O
distributed	B-Method
representation	I-Method
of	O
the	O
input	O
length	O
to	O
the	O
decoder	B-Method
and	I-Method
attention	I-Method
module	I-Method
.	O
	
However	O
,	O
this	O
did	O
not	O
cause	O
a	O
change	O
in	O
attention	O
patterns	O
nor	O
did	O
it	O
improve	O
translation	B-Metric
accuracy	I-Metric
.	O
	
One	O
characteristic	O
of	O
our	O
convolutional	B-Method
encoder	I-Method
architecture	I-Method
is	O
that	O
the	O
context	O
over	O
which	O
outputs	O
are	O
computed	O
depends	O
on	O
the	O
number	O
of	O
layers	O
.	O
	
With	O
bi	B-Method
-	I-Method
directional	I-Method
RNNs	I-Method
,	O
every	O
encoder	O
output	O
depends	O
on	O
the	O
entire	O
source	O
sentence	O
.	O
	
In	O
Figure	O
3	O
,	O
we	O
evaluate	O
whether	O
limited	O
context	O
affects	O
the	O
translation	B-Metric
quality	I-Metric
on	O
longer	O
sentences	O
of	O
WMT'15	B-Material
English	I-Material
-	I-Material
German	I-Material
which	O
often	O
requires	O
moving	O
verbs	O
over	O
long	O
distances	O
.	O
	
We	O
sort	O
the	O
newstest2015	O
test	O
set	O
by	O
source	O
length	O
,	O
partition	O
it	O
into	O
15	O
equallysized	O
buckets	O
,	O
and	O
compare	O
the	O
BLEU	B-Metric
scores	O
of	O
models	O
listed	O
in	O
Table	O
2	O
on	O
a	O
per	O
-	O
bucket	O
basis	O
.	O
	
section	O
:	O
B	O
Performance	O
by	O
Sentence	B-Metric
Length	I-Metric
	
There	O
is	O
no	O
clear	O
evidence	O
for	O
sub	O
-	O
par	O
translations	O
on	O
sentences	O
that	O
are	O
longer	O
than	O
the	O
observable	O
context	O
per	O
encoder	O
output	O
.	O
	
We	O
include	O
a	O
small	O
encoder	B-Method
with	O
a	O
6	O
-	O
layer	O
CNN	B-Method
-	O
c	O
and	O
a	O
3	O
-	O
layer	O
CNN	B-Method
-	O
a	O
in	O
the	O
comparison	O
which	O
performs	O
worse	O
than	O
a	O
2	O
-	O
layer	O
BiLSTM	B-Method
(	O
23.3	O
BLEU	B-Metric
vs23.6	O
)	O
.	O
	
With	O
6	O
convolutional	B-Method
layers	I-Method
at	O
kernel	O
width	O
3	O
,	O
each	O
encoder	O
output	O
contains	O
information	O
of	O
13	O
adjacent	O
source	O
words	O
.	O
	
Looking	O
at	O
the	O
accuracy	B-Metric
for	O
sentences	O
with	O
15	O
words	O
or	O
more	O
,	O
this	O
relatively	O
shallow	O
CNN	B-Method
is	O
either	O
on	O
par	O
or	O
better	O
than	O
the	O
BiLSTM	B-Method
for	O
5	O
out	O
of	O
10	O
buckets	O
;	O
the	O
BiLSTM	B-Method
has	O
access	O
to	O
the	O
entire	O
source	O
context	O
.	O
	
Similar	O
observations	O
can	O
be	O
made	O
for	O
the	O
deeper	B-Method
convolutional	I-Method
encoders	I-Method
.	O
	
section	O
:	O
	
document	O
:	O
Learning	B-Task
to	O
Compare	O
:	O
Relation	B-Method
Network	I-Method
for	O
Few	B-Task
-	I-Task
Shot	I-Task
Learning	I-Task
	
We	O
present	O
a	O
conceptually	O
simple	O
,	O
flexible	O
,	O
and	O
general	O
framework	O
for	O
few	B-Task
-	I-Task
shot	I-Task
learning	I-Task
,	O
where	O
a	O
classifier	B-Method
must	O
learn	O
to	O
recognise	O
new	O
classes	O
given	O
only	O
few	O
examples	O
from	O
each	O
.	O
	
Our	O
method	O
,	O
called	O
the	O
Relation	B-Method
Network	I-Method
(	O
RN	B-Method
)	O
,	O
is	O
trained	O
end	O
-	O
to	O
-	O
end	O
from	O
scratch	O
.	O
	
During	O
meta	B-Method
-	I-Method
learning	I-Method
,	O
it	O
learns	O
to	O
learn	O
a	O
deep	O
distance	O
metric	O
to	O
compare	O
a	O
small	O
number	O
of	O
images	O
within	O
episodes	O
,	O
each	O
of	O
which	O
is	O
designed	O
to	O
simulate	O
the	O
few	B-Task
-	I-Task
shot	I-Task
setting	I-Task
.	O
	
Once	O
trained	O
,	O
a	O
RN	B-Method
is	O
able	O
to	O
classify	O
images	O
of	O
new	O
classes	O
by	O
computing	O
relation	O
scores	O
between	O
query	O
images	O
and	O
the	O
few	O
examples	O
of	O
each	O
new	O
class	O
without	O
further	O
updating	O
the	O
network	O
.	O
	
Besides	O
providing	O
improved	O
performance	O
on	O
few	B-Task
-	I-Task
shot	I-Task
learning	I-Task
,	O
our	O
framework	O
is	O
easily	O
extended	O
to	O
zero	B-Task
-	I-Task
shot	I-Task
learning	I-Task
.	O
	
Extensive	O
experiments	O
on	O
five	O
benchmarks	O
demonstrate	O
that	O
our	O
simple	O
approach	O
provides	O
a	O
unified	O
and	O
effective	O
approach	O
for	O
both	O
of	O
these	O
two	O
tasks	O
.	O
	
section	O
:	O
Introduction	O
	
Deep	B-Method
learning	I-Method
models	I-Method
have	O
achieved	O
great	O
success	O
in	O
visual	B-Task
recognition	I-Task
tasks	I-Task
.	O
	
However	O
,	O
these	O
supervised	B-Method
learning	I-Method
models	I-Method
need	O
large	O
amounts	O
of	O
labelled	O
data	O
and	O
many	O
iterations	O
to	O
train	O
their	O
large	O
number	O
of	O
parameters	O
.	O
	
This	O
severely	O
limits	O
their	O
scalability	O
to	O
new	O
classes	O
due	O
to	O
annotation	B-Metric
cost	I-Metric
,	O
but	O
more	O
fundamentally	O
limits	O
their	O
applicability	O
to	O
newly	O
emerging	O
(	O
eg	O
.	O
new	O
consumer	O
devices	O
)	O
or	O
rare	O
(	O
eg	O
.	O
	
rare	O
animals	O
)	O
categories	O
where	O
numerous	O
annotated	O
images	O
may	O
simply	O
never	O
exist	O
.	O
	
In	O
contrast	O
,	O
humans	O
are	O
very	O
good	O
at	O
recognising	B-Task
objects	I-Task
with	O
very	O
little	O
direct	O
supervision	O
,	O
or	O
none	O
at	O
all	O
,	O
few	B-Task
-	I-Task
shot	I-Task
or	O
zero	B-Task
-	I-Task
shot	I-Task
learning	I-Task
.	O
	
For	O
example	O
,	O
children	O
have	O
no	O
problem	O
generalising	O
the	O
concept	O
of	O
“	O
zebra	O
”	O
from	O
a	O
single	O
picture	O
in	O
a	O
book	O
,	O
or	O
hearing	O
its	O
description	O
as	O
looking	O
like	O
a	O
stripy	O
horse	O
.	O
	
Motivated	O
by	O
the	O
failure	O
of	O
conventional	O
deep	B-Task
learning	I-Task
methods	O
to	O
work	O
well	O
on	O
one	O
or	O
few	O
examples	O
per	O
class	O
,	O
and	O
inspired	O
by	O
the	O
few	B-Task
-	I-Task
and	O
zero	B-Task
-	I-Task
shot	I-Task
learning	I-Task
ability	O
of	O
humans	O
,	O
there	O
has	O
been	O
a	O
recent	O
resurgence	O
of	O
interest	O
in	O
machine	O
one	O
/	O
few	B-Task
-	I-Task
shot	I-Task
and	O
zero	B-Task
-	I-Task
shot	I-Task
learning	I-Task
.	O
	
Few	B-Task
-	I-Task
shot	I-Task
learning	I-Task
aims	O
to	O
recognise	O
novel	O
visual	B-Task
categories	I-Task
from	O
very	O
few	O
labelled	O
examples	O
.	O
	
The	O
availability	O
of	O
only	O
one	O
or	O
very	O
few	O
examples	O
challenges	O
the	O
standard	O
‘	O
fine	B-Method
-	I-Method
tuning	I-Method
’	I-Method
practice	I-Method
in	O
deep	B-Task
learning	I-Task
.	O
	
Data	B-Method
augmentation	I-Method
and	I-Method
regularisation	I-Method
techniques	I-Method
can	O
alleviate	O
overfitting	B-Task
in	O
such	O
a	O
limited	O
-	O
data	O
regime	O
,	O
but	O
they	O
do	O
not	O
solve	O
it	O
.	O
	
Therefore	O
contemporary	O
approaches	O
to	O
few	B-Task
-	I-Task
shot	I-Task
learning	I-Task
often	O
decompose	O
training	B-Task
into	O
an	O
auxiliary	O
meta	B-Method
learning	I-Method
phase	I-Method
where	O
transferrable	O
knowledge	O
is	O
learned	O
in	O
the	O
form	O
of	O
good	O
initial	O
conditions	O
,	O
embeddings	O
or	O
optimisation	B-Method
strategies	I-Method
.	O
	
The	O
target	O
few	B-Task
-	I-Task
shot	O
learning	O
problem	O
is	O
then	O
learned	O
by	O
fine	B-Method
-	I-Method
tuning	I-Method
with	O
the	O
learned	O
optimisation	B-Method
strategy	I-Method
or	O
computed	O
in	O
a	O
feed	B-Method
-	I-Method
forward	I-Method
pass	I-Method
without	O
updating	B-Method
network	I-Method
weights	I-Method
.	O
	
Zero	B-Method
-	I-Method
shot	I-Method
learning	I-Method
also	O
suffers	O
from	O
a	O
related	O
challenge	O
.	O
	
Recognisers	B-Method
are	O
trained	O
by	O
a	O
single	O
example	O
in	O
the	O
form	O
of	O
a	O
class	B-Method
description	I-Method
(	O
c.f	O
.	O
,	O
single	O
exemplar	O
image	O
in	O
one	B-Task
-	I-Task
shot	I-Task
)	O
,	O
making	O
data	B-Task
insufficiency	I-Task
for	O
gradient	B-Method
-	I-Method
based	I-Method
learning	I-Method
a	O
challenge	O
.	O
	
While	O
promising	O
,	O
most	O
existing	O
few	B-Task
-	I-Task
shot	O
learning	O
approaches	O
either	O
require	O
complex	O
inference	B-Method
mechanisms	I-Method
,	O
complex	O
recurrent	O
neural	O
network	O
(	O
RNN	B-Method
)	O
architectures	O
,	O
or	O
fine	O
-	O
tuning	O
the	O
target	O
problem	O
.	O
	
Our	O
approach	O
is	O
most	O
related	O
to	O
others	O
that	O
aim	O
to	O
train	O
an	O
effective	O
metric	B-Metric
for	O
one	B-Task
-	I-Task
shot	I-Task
learning	O
.	O
	
Where	O
they	O
focus	O
on	O
the	O
learning	O
of	O
the	O
transferrable	B-Method
embedding	I-Method
and	O
pre	O
-	O
define	O
a	O
fixed	O
metric	O
(	O
e.g.	O
,	O
as	O
Euclidean	O
)	O
,	O
we	O
further	O
aim	O
to	O
learn	O
a	O
transferrable	B-Method
deep	I-Method
metric	I-Method
for	O
comparing	O
the	O
relation	O
between	O
images	O
(	O
few	B-Task
-	I-Task
shot	I-Task
learning	I-Task
)	O
,	O
or	O
between	O
images	O
and	O
class	O
descriptions	O
(	O
zero	B-Task
-	I-Task
shot	I-Task
learning	I-Task
)	O
.	O
	
By	O
expressing	O
the	O
inductive	O
bias	O
of	O
a	O
deeper	O
solution	O
(	O
multiple	O
non	O
-	O
linear	O
learned	O
stages	O
at	O
both	O
embedding	B-Method
and	I-Method
relation	I-Method
modules	I-Method
)	O
,	O
we	O
make	O
it	O
easier	O
to	O
learn	O
a	O
generalisable	O
solution	O
to	O
the	O
problem	O
.	O
	
Specifically	O
,	O
we	O
propose	O
a	O
two	O
-	O
branch	O
Relation	B-Method
Network	I-Method
(	O
RN	B-Method
)	O
that	O
performs	O
few	B-Task
-	I-Task
shot	O
recognition	O
by	O
learning	O
to	O
compare	O
query	O
images	O
against	O
few	B-Task
-	I-Task
shot	O
labeled	O
sample	O
images	O
.	O
	
First	O
an	O
embedding	B-Method
module	I-Method
generates	O
representations	O
of	O
the	O
query	O
and	O
training	O
images	O
.	O
	
Then	O
these	O
embeddings	O
are	O
compared	O
by	O
a	O
relation	B-Method
module	I-Method
that	O
determines	O
if	O
they	O
are	O
from	O
matching	O
categories	O
or	O
not	O
.	O
	
Defining	O
an	O
episode	B-Method
-	I-Method
based	I-Method
strategy	I-Method
inspired	O
by	O
,	O
the	O
embedding	B-Method
and	I-Method
relation	I-Method
modules	I-Method
are	O
meta	O
-	O
learned	O
end	O
-	O
to	O
-	O
end	O
to	O
support	O
few	B-Task
-	I-Task
shot	I-Task
learning	I-Task
.	O
	
This	O
can	O
be	O
seen	O
as	O
extending	O
the	O
strategy	O
of	O
to	O
include	O
a	O
learnable	O
non	O
-	O
linear	O
comparator	O
,	O
instead	O
of	O
a	O
fixed	B-Method
linear	I-Method
comparator	I-Method
.	O
	
Our	O
approach	O
outperforms	O
prior	O
approaches	O
,	O
while	O
being	O
simpler	O
(	O
no	O
RNNs	B-Method
)	O
and	O
faster	O
(	O
no	O
fine	B-Method
-	I-Method
tuning	I-Method
)	O
.	O
	
Our	O
proposed	O
strategy	O
also	O
directly	O
generalises	O
to	O
zero	B-Task
-	I-Task
shot	I-Task
learning	I-Task
.	O
	
In	O
this	O
case	O
the	O
sample	O
branch	O
embeds	O
a	O
single	O
-	O
shot	O
category	O
description	O
rather	O
than	O
a	O
single	O
exemplar	O
training	O
image	O
,	O
and	O
the	O
relation	B-Method
module	I-Method
learns	O
to	O
compare	O
query	O
image	O
and	O
category	B-Method
description	I-Method
embeddings	I-Method
.	O
	
Overall	O
our	O
contribution	O
is	O
to	O
provide	O
a	O
clean	O
framework	O
that	O
elegantly	O
encompasses	O
both	O
few	O
and	O
zero	B-Task
-	I-Task
shot	I-Task
learning	I-Task
.	O
	
Our	O
evaluation	O
on	O
four	O
benchmarks	O
show	O
that	O
it	O
provides	O
compelling	O
performance	O
across	O
the	O
board	O
while	O
being	O
simpler	O
and	O
faster	O
than	O
the	O
alternatives	O
.	O
	
section	O
:	O
Related	O
Work	O
	
The	O
study	O
of	O
one	O
or	O
few	B-Task
-	I-Task
shot	O
object	O
recognition	O
has	O
been	O
of	O
interest	O
for	O
some	O
time	O
.	O
	
Earlier	O
work	O
on	O
few	B-Task
-	I-Task
shot	I-Task
learning	I-Task
tended	O
to	O
involve	O
generative	B-Method
models	I-Method
with	O
complex	O
iterative	B-Method
inference	I-Method
strategies	I-Method
.	O
	
With	O
the	O
success	O
of	O
discriminative	O
deep	B-Task
learning	I-Task
-	O
based	O
approaches	O
in	O
the	O
data	B-Task
-	I-Task
rich	I-Task
many	I-Task
-	I-Task
shot	I-Task
setting	I-Task
,	O
there	O
has	O
been	O
a	O
surge	O
of	O
interest	O
in	O
generalising	O
such	O
deep	B-Task
learning	I-Task
approaches	O
to	O
the	O
few	B-Task
-	I-Task
shot	O
learning	O
setting	O
.	O
	
Many	O
of	O
these	O
approaches	O
use	O
a	O
meta	B-Method
-	I-Method
learning	I-Method
or	I-Method
learning	I-Method
-	I-Method
to	I-Method
-	I-Method
learn	I-Method
strategy	I-Method
in	O
the	O
sense	O
that	O
they	O
extract	O
some	O
transferrable	O
knowledge	O
from	O
a	O
set	O
of	O
auxiliary	O
tasks	O
(	O
meta	B-Method
-	I-Method
learning	I-Method
,	O
learning	O
-	O
to	O
-	O
learn	O
)	O
,	O
which	O
then	O
helps	O
them	O
to	O
learn	O
the	O
target	O
few	B-Task
-	I-Task
shot	O
problem	O
well	O
without	O
suffering	O
from	O
the	O
overfitting	O
that	O
might	O
be	O
expected	O
when	O
applying	O
deep	B-Method
models	I-Method
to	O
sparse	B-Task
data	I-Task
problems	I-Task
.	O
	
Learning	O
to	O
Fine	O
-	O
Tune	O
	
The	O
successful	O
MAML	B-Method
approach	I-Method
aimed	O
to	O
meta	O
-	O
learn	O
an	O
initial	O
condition	O
(	O
set	O
of	O
neural	O
network	O
weights	O
)	O
that	O
is	O
good	O
for	O
fine	B-Task
-	I-Task
tuning	I-Task
on	O
few	B-Task
-	I-Task
shot	O
problems	O
.	O
	
The	O
strategy	O
here	O
is	O
to	O
search	O
for	O
the	O
weight	O
configuration	O
of	O
a	O
given	O
neural	B-Method
network	I-Method
such	O
that	O
it	O
can	O
be	O
effectively	O
fine	O
-	O
tuned	O
on	O
a	O
sparse	B-Task
data	I-Task
problem	I-Task
within	O
a	O
few	O
gradient	B-Method
-	I-Method
descent	I-Method
update	I-Method
steps	I-Method
.	O
	
Many	O
distinct	O
target	O
problems	O
are	O
sampled	O
from	O
a	O
multiple	O
task	O
training	O
set	O
;	O
the	O
base	B-Method
neural	I-Method
network	I-Method
model	I-Method
is	O
then	O
fine	O
-	O
tuned	O
to	O
solve	O
each	O
of	O
them	O
,	O
and	O
the	O
success	O
at	O
each	O
target	O
problem	O
after	O
fine	O
-	O
tuning	O
drives	O
updates	O
in	O
the	O
base	O
model	O
–	O
thus	O
driving	O
the	O
production	O
of	O
an	O
easy	O
to	O
fine	O
-	O
tune	O
initial	O
condition	O
.	O
	
The	O
few	B-Task
-	I-Task
shot	O
optimisation	O
approach	O
goes	O
further	O
in	O
meta	B-Method
-	I-Method
learning	I-Method
not	O
only	O
a	O
good	O
initial	O
condition	O
but	O
an	O
LSTM	B-Method
-	I-Method
based	I-Method
optimizer	I-Method
that	O
is	O
trained	O
to	O
be	O
specifically	O
effective	O
for	O
fine	B-Task
-	I-Task
tuning	I-Task
.	O
	
However	O
both	O
of	O
these	O
approaches	O
suffer	O
from	O
the	O
need	O
to	O
fine	O
-	O
tune	O
on	O
the	O
target	O
problem	O
.	O
	
In	O
contrast	O
,	O
our	O
approach	O
solves	O
target	B-Task
problems	I-Task
in	O
an	O
entirely	O
feed	B-Method
-	I-Method
forward	I-Method
manner	I-Method
with	O
no	O
model	O
updates	O
required	O
,	O
making	O
it	O
more	O
convenient	O
for	O
low	B-Task
-	I-Task
latency	I-Task
or	I-Task
low	I-Task
-	I-Task
power	I-Task
applications	I-Task
.	O
	
RNN	B-Method
Memory	O
Based	O
Another	O
category	O
of	O
approaches	O
leverage	O
recurrent	B-Method
neural	I-Method
networks	I-Method
with	O
memories	B-Method
.	O
	
Here	O
the	O
idea	O
is	O
typically	O
that	O
an	O
RNN	B-Method
iterates	O
over	O
an	O
examples	O
of	O
given	O
problem	O
and	O
accumulates	O
the	O
knowledge	O
required	O
to	O
solve	O
that	O
problem	O
in	O
its	O
hidden	O
activations	O
,	O
or	O
external	O
memory	O
.	O
	
New	O
examples	O
can	O
be	O
classified	O
,	O
for	O
example	O
by	O
comparing	O
them	O
to	O
historic	O
information	O
stored	O
in	O
the	O
memory	O
.	O
	
So	O
‘	O
learning	O
’	O
a	O
single	O
target	O
problem	O
can	O
occur	O
in	O
unrolling	O
the	O
RNN	B-Method
,	O
while	O
learning	O
-	O
to	O
-	O
learn	O
means	O
training	O
the	O
weights	O
of	O
the	O
RNN	B-Method
by	O
learning	O
many	O
distinct	O
problems	O
.	O
	
While	O
appealing	O
,	O
these	O
architectures	O
face	O
issues	O
in	O
ensuring	O
that	O
they	O
reliably	O
store	O
all	O
the	O
,	O
potentially	O
long	O
term	O
,	O
historical	O
information	O
of	O
relevance	O
without	O
forgetting	O
.	O
	
In	O
our	O
approach	O
we	O
avoid	O
the	O
complexity	O
of	O
recurrent	B-Method
networks	I-Method
,	O
and	O
the	O
issues	O
involved	O
in	O
ensuring	O
the	O
adequacy	O
of	O
their	O
memory	O
.	O
	
Instead	O
our	O
learning	B-Method
-	I-Method
to	I-Method
-	I-Method
learn	I-Method
approach	I-Method
is	O
defined	O
entirely	O
with	O
simple	O
and	O
fast	O
feed	B-Method
forward	I-Method
CNNs	I-Method
.	O
	
Embedding	B-Method
and	I-Method
Metric	I-Method
Learning	I-Method
Approaches	I-Method
	
The	O
prior	O
approaches	O
entail	O
some	O
complexity	O
when	O
learning	O
the	O
target	O
few	B-Task
-	I-Task
shot	O
problem	O
.	O
	
Another	O
category	O
of	O
approach	O
aims	O
to	O
learn	O
a	O
set	O
of	O
projection	B-Method
functions	I-Method
that	O
take	O
query	O
and	O
sample	O
images	O
from	O
the	O
target	O
problem	O
and	O
classify	O
them	O
in	O
a	O
feed	B-Method
forward	I-Method
manner	I-Method
.	O
	
One	O
approach	O
is	O
to	O
parameterise	O
the	O
weights	O
of	O
a	O
feed	B-Method
-	I-Method
forward	I-Method
classifier	I-Method
in	O
terms	O
of	O
the	O
sample	O
set	O
.	O
	
The	O
meta	B-Method
-	I-Method
learning	I-Method
here	O
is	O
to	O
train	O
the	O
auxiliary	B-Method
parameterisation	I-Method
net	I-Method
that	O
learns	O
how	O
to	O
paramaterise	O
a	O
given	O
feed	B-Task
-	I-Task
forward	I-Task
classification	I-Task
problem	I-Task
in	O
terms	O
of	O
a	O
few	B-Task
-	I-Task
shot	O
sample	O
set	O
.	O
	
Metric	B-Method
-	I-Method
learning	I-Method
based	I-Method
approaches	I-Method
aim	O
to	O
learn	O
a	O
set	O
of	O
projection	B-Method
functions	I-Method
such	O
that	O
when	O
represented	O
in	O
this	O
embedding	O
,	O
images	O
are	O
easy	O
to	O
recognise	O
using	O
simple	O
nearest	B-Method
neighbour	I-Method
or	O
linear	B-Method
classifiers	I-Method
.	O
	
In	O
this	O
case	O
the	O
meta	O
-	O
learned	O
transferrable	O
knowledge	O
are	O
the	O
projection	B-Method
functions	I-Method
and	O
the	O
target	O
problem	O
is	O
a	O
simple	O
feed	B-Method
-	I-Method
forward	I-Method
computation	I-Method
.	O
	
The	O
most	O
related	O
methodologies	O
to	O
ours	O
are	O
the	O
prototypical	B-Method
networks	I-Method
of	O
and	O
the	O
siamese	B-Method
networks	I-Method
of	O
.	O
	
These	O
approaches	O
focus	O
on	O
learning	O
embeddings	B-Method
that	O
transform	O
the	O
data	O
such	O
that	O
it	O
can	O
be	O
recognised	O
with	O
a	O
fixed	O
nearest	B-Method
-	I-Method
neighbour	I-Method
or	I-Method
linear	I-Method
classifier	I-Method
.	O
	
In	O
contrast	O
,	O
our	O
framework	O
further	O
defines	O
a	O
relation	B-Method
classifier	I-Method
CNN	I-Method
,	O
in	O
the	O
style	O
of	O
(	O
While	O
focuses	O
on	O
reasoning	O
about	O
relation	O
between	O
two	O
objects	O
in	O
a	O
same	O
image	O
which	O
is	O
to	O
address	O
a	O
different	O
problem	O
.	O
)	O
.	O
	
Compared	O
to	O
,	O
this	O
can	O
be	O
seen	O
as	O
providing	O
a	O
learnable	O
rather	O
than	O
fixed	O
metric	O
,	O
or	O
non	B-Method
-	I-Method
linear	I-Method
rather	O
than	O
linear	B-Method
classifier	I-Method
.	O
	
Compared	O
to	O
we	O
benefit	O
from	O
an	O
episodic	B-Method
training	I-Method
strategy	I-Method
with	O
an	O
end	O
-	O
to	O
-	O
end	O
manner	O
from	O
scratch	O
,	O
and	O
compared	O
to	O
we	O
avoid	O
the	O
complexity	O
of	O
set	O
-	O
to	O
-	O
set	O
RNN	B-Method
embedding	O
of	O
the	O
sample	O
-	O
set	O
,	O
and	O
simply	O
rely	O
on	O
pooling	B-Method
.	O
	
Zero	B-Method
-	I-Method
Shot	I-Method
Learning	I-Method
	
Our	O
approach	O
is	O
designed	O
for	O
few	B-Task
-	I-Task
shot	I-Task
learning	I-Task
,	O
but	O
elegantly	O
spans	O
the	O
space	O
into	O
zero	B-Task
-	I-Task
shot	I-Task
learning	I-Task
(	O
ZSL	B-Method
)	O
by	O
modifying	O
the	O
sample	O
branch	O
to	O
input	O
a	O
single	O
category	O
description	O
rather	O
than	O
single	O
training	O
image	O
.	O
	
When	O
applied	O
to	O
ZSL	B-Method
our	O
architecture	O
is	O
related	O
to	O
methods	O
that	O
learn	O
to	O
align	O
images	O
and	O
category	O
embeddings	O
and	O
perform	O
recognition	B-Task
by	O
predicting	O
if	O
an	O
image	O
and	O
category	O
embedding	O
pair	O
match	O
.	O
	
Similarly	O
to	O
the	O
case	O
with	O
the	O
prior	O
metric	O
-	O
based	O
few	B-Task
-	I-Task
shot	O
approaches	O
,	O
most	O
of	O
these	O
apply	O
a	O
fixed	O
manually	B-Method
defined	I-Method
similarity	I-Method
metric	I-Method
or	O
linear	B-Method
classifier	I-Method
after	O
combining	O
the	O
image	B-Method
and	I-Method
category	I-Method
embedding	I-Method
.	O
	
In	O
contrast	O
,	O
we	O
again	O
benefit	O
from	O
a	O
deeper	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
architecture	I-Method
including	O
a	O
learned	O
non	O
-	O
linear	O
metric	O
in	O
the	O
form	O
of	O
our	O
learned	O
convolutional	B-Method
relation	I-Method
network	I-Method
;	O
as	O
well	O
as	O
from	O
an	O
episode	B-Method
-	I-Method
based	I-Method
training	I-Method
strategy	I-Method
.	O
	
section	O
:	O
Methodology	O
	
subsection	O
:	O
Problem	O
Definition	O
	
We	O
consider	O
the	O
task	O
of	O
few	B-Task
-	I-Task
shot	O
classifier	O
learning	O
.	O
	
Formally	O
,	O
we	O
have	O
three	O
datasets	O
:	O
a	O
training	O
set	O
,	O
a	O
support	O
set	O
,	O
and	O
a	O
testing	O
set	O
.	O
	
The	O
support	O
set	O
and	O
testing	O
set	O
share	O
the	O
same	O
label	O
space	O
,	O
but	O
the	O
training	O
set	O
has	O
its	O
own	O
label	O
space	O
that	O
is	O
disjoint	O
with	O
support	O
/	O
testing	O
set	O
.	O
	
If	O
the	O
support	O
set	O
contains	O
labelled	O
examples	O
for	O
each	O
of	O
unique	O
classes	O
,	O
the	O
target	O
few	B-Task
-	I-Task
shot	O
problem	O
is	O
called	O
-	O
way	O
-	O
shot	O
.	O
	
With	O
the	O
support	O
set	O
only	O
,	O
we	O
can	O
in	O
principle	O
train	O
a	O
classifier	B-Method
to	O
assign	O
a	O
class	O
label	O
to	O
each	O
sample	O
in	O
the	O
test	O
set	O
.	O
	
However	O
,	O
due	O
to	O
the	O
lack	O
of	O
labelled	O
samples	O
in	O
the	O
support	O
set	O
,	O
the	O
performance	O
of	O
such	O
a	O
classifier	B-Method
is	O
usually	O
not	O
satisfactory	O
.	O
	
Therefore	O
we	O
aim	O
to	O
perform	O
meta	B-Method
-	I-Method
learning	I-Method
on	O
the	O
training	O
set	O
,	O
in	O
order	O
to	O
extract	O
transferrable	O
knowledge	O
that	O
will	O
allow	O
us	O
to	O
perform	O
better	O
few	B-Task
-	I-Task
shot	I-Task
learning	I-Task
on	O
the	O
support	O
set	O
and	O
thus	O
classify	O
the	O
test	O
set	O
more	O
successfully	O
.	O
	
An	O
effective	O
way	O
to	O
exploit	O
the	O
training	O
set	O
is	O
to	O
mimic	O
the	O
few	B-Task
-	I-Task
shot	O
learning	O
setting	O
via	O
episode	B-Method
based	I-Method
training	I-Method
,	O
as	O
proposed	O
in	O
.	O
	
In	O
each	O
training	O
iteration	O
,	O
an	O
episode	O
is	O
formed	O
by	O
randomly	O
selecting	O
classes	O
from	O
the	O
training	O
set	O
with	O
labelled	O
samples	O
from	O
each	O
of	O
the	O
classes	O
to	O
act	O
as	O
the	O
sample	O
set	O
(	O
)	O
,	O
as	O
well	O
as	O
a	O
fraction	O
of	O
the	O
remainder	O
of	O
those	O
classes	O
’	O
samples	O
to	O
serve	O
as	O
the	O
query	O
set	O
.	O
	
This	O
sample	O
/	O
query	O
set	O
split	O
is	O
designed	O
to	O
simulate	O
the	O
support	O
/	O
test	O
set	O
that	O
will	O
be	O
encountered	O
at	O
test	O
time	O
.	O
	
A	O
model	O
trained	O
from	O
sample	O
/	O
query	O
set	O
can	O
be	O
further	O
fine	O
-	O
tuned	O
using	O
the	O
support	O
set	O
,	O
if	O
desired	O
.	O
	
In	O
this	O
work	O
we	O
adopt	O
such	O
an	O
episode	B-Method
-	I-Method
based	I-Method
training	I-Method
strategy	I-Method
.	O
	
In	O
our	O
few	B-Task
-	I-Task
shot	O
experiments	O
(	O
see	O
Section	O
[	O
reference	O
]	O
)	O
we	O
consider	O
one	B-Task
-	I-Task
shot	I-Task
(	O
,	O
Figure	O
[	O
reference	O
]	O
)	O
and	O
five	O
-	O
shot	O
(	O
)	O
settings	O
.	O
	
We	O
also	O
address	O
the	O
zero	B-Task
-	I-Task
shot	I-Task
learning	I-Task
case	I-Task
as	O
explained	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
subsection	O
:	O
Model	O
	
One	O
	
-	O
Shot	O
	
Our	O
Relation	B-Method
Network	I-Method
(	O
RN	B-Method
)	O
consists	O
of	O
two	O
modules	O
:	O
an	O
embedding	B-Method
module	I-Method
and	O
a	O
relation	B-Method
module	I-Method
,	O
as	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Samples	O
in	O
the	O
query	O
set	O
,	O
and	O
samples	O
in	O
the	O
sample	O
set	O
are	O
fed	O
through	O
the	O
embedding	B-Method
module	I-Method
,	O
which	O
produces	O
feature	O
maps	O
and	O
.	O
	
The	O
feature	O
maps	O
and	O
are	O
combined	O
with	O
operator	B-Method
.	O
	
In	O
this	O
work	O
we	O
assume	O
to	O
be	O
concatenation	O
of	O
feature	O
maps	O
in	O
depth	O
,	O
although	O
other	O
choices	O
are	O
possible	O
.	O
	
The	O
combined	O
feature	O
map	O
of	O
the	O
sample	O
and	O
query	O
are	O
fed	O
into	O
the	O
relation	B-Method
module	I-Method
,	O
which	O
eventually	O
produces	O
a	O
scalar	O
in	O
range	O
of	O
to	O
representing	O
the	O
similarity	O
between	O
and	O
,	O
which	O
is	O
called	O
relation	B-Metric
score	I-Metric
.	O
	
Thus	O
,	O
in	O
the	O
-	O
way	O
one	B-Task
-	I-Task
shot	I-Task
setting	O
,	O
we	O
generate	O
relation	O
scores	O
for	O
the	O
relation	O
between	O
one	O
query	O
input	O
and	O
training	O
sample	O
set	O
examples	O
,	O
K	O
-	O
shot	O
	
For	O
-	O
shot	O
where	O
,	O
we	O
element	O
-	O
wise	O
sum	O
over	O
the	O
embedding	B-Method
module	I-Method
outputs	O
of	O
all	O
samples	O
from	O
each	O
training	O
class	O
to	O
form	O
this	O
class	O
’	O
feature	O
map	O
.	O
	
This	O
pooled	O
class	B-Method
-	I-Method
level	I-Method
feature	I-Method
map	I-Method
is	O
combined	O
with	O
the	O
query	O
image	O
feature	O
map	O
as	O
above	O
.	O
	
Thus	O
,	O
the	O
number	O
of	O
relation	O
scores	O
for	O
one	O
query	O
is	O
always	O
in	O
both	O
one	B-Task
-	I-Task
shot	I-Task
or	O
few	B-Task
-	I-Task
shot	I-Task
setting	I-Task
.	O
	
Objective	B-Metric
function	I-Metric
We	O
use	O
mean	B-Metric
square	I-Metric
error	I-Metric
(	O
MSE	B-Metric
)	O
loss	O
(	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
)	O
to	O
train	O
our	O
model	O
,	O
regressing	O
the	O
relation	B-Metric
score	I-Metric
to	O
the	O
ground	O
truth	O
:	O
	
matched	O
pairs	O
have	O
similarity	O
and	O
the	O
mismatched	O
pair	O
have	O
similarity	O
.	O
	
The	O
choice	O
of	O
MSE	B-Metric
is	O
somewhat	O
non	O
-	O
standard	O
.	O
	
Our	O
problem	O
may	O
seem	O
to	O
be	O
a	O
classification	B-Task
problem	I-Task
with	O
a	O
label	O
space	O
.	O
	
However	O
conceptually	O
we	O
are	O
predicting	O
relation	O
scores	O
,	O
which	O
can	O
be	O
considered	O
a	O
regression	B-Task
problem	I-Task
despite	O
that	O
for	O
ground	O
-	O
truth	O
we	O
can	O
only	O
automatically	O
generate	O
targets	O
.	O
	
subsection	O
:	O
Zero	B-Task
-	I-Task
shot	I-Task
Learning	I-Task
	
Zero	B-Method
-	I-Method
shot	I-Method
learning	I-Method
is	O
analogous	O
to	O
one	B-Task
-	I-Task
shot	I-Task
learning	O
in	O
that	O
one	O
datum	O
is	O
given	O
to	O
define	O
each	O
class	O
to	O
recognise	O
.	O
	
However	O
instead	O
of	O
being	O
given	O
a	O
support	O
set	O
with	O
one	B-Task
-	I-Task
shot	I-Task
image	O
for	O
each	O
of	O
training	O
classes	O
,	O
it	O
contains	O
a	O
semantic	O
class	O
embedding	O
vector	O
for	O
each	O
.	O
	
Modifying	O
our	O
framework	O
to	O
deal	O
with	O
the	O
zero	B-Task
-	I-Task
shot	I-Task
case	I-Task
is	O
straightforward	O
:	O
as	O
a	O
different	O
modality	O
of	O
semantic	O
vectors	O
is	O
used	O
for	O
the	O
support	O
set	O
(	O
attribute	O
vectors	O
instead	O
of	O
images	O
)	O
,	O
we	O
use	O
a	O
second	O
heterogeneous	B-Method
embedding	I-Method
module	I-Method
besides	O
the	O
embedding	B-Method
module	I-Method
used	O
for	O
the	O
image	O
query	O
set	O
.	O
	
Then	O
the	O
relation	B-Method
net	I-Method
is	O
applied	O
as	O
before	O
.	O
	
Therefore	O
,	O
the	O
relation	B-Metric
score	I-Metric
for	O
each	O
query	O
input	O
will	O
be	O
:	O
The	O
objective	B-Metric
function	I-Metric
for	O
zero	B-Task
-	I-Task
shot	I-Task
learning	I-Task
is	O
the	O
same	O
as	O
that	O
for	O
few	B-Task
-	I-Task
shot	I-Task
learning	I-Task
.	O
	
subsection	O
:	O
Network	B-Method
Architecture	I-Method
	
As	O
most	O
few	B-Task
-	I-Task
shot	O
learning	O
models	O
utilise	O
four	O
convolutional	B-Method
blocks	I-Method
for	O
embedding	B-Method
module	I-Method
,	O
we	O
follow	O
the	O
same	O
architecture	O
setting	O
for	O
fair	O
comparison	O
,	O
see	O
Figure	O
[	O
reference	O
]	O
.	O
	
More	O
concretely	O
,	O
each	O
convolutional	B-Method
block	I-Method
contains	O
a	O
64	B-Method
-	I-Method
filter	I-Method
convolution	I-Method
,	O
a	O
batch	B-Method
normalisation	I-Method
and	O
a	O
ReLU	B-Method
nonlinearity	I-Method
layer	I-Method
respectively	O
.	O
	
The	O
first	O
two	O
blocks	O
also	O
contain	O
a	O
max	B-Method
-	I-Method
pooling	I-Method
layer	I-Method
while	O
the	O
latter	O
two	O
do	O
not	O
.	O
	
We	O
do	O
so	O
because	O
we	O
need	O
the	O
output	O
feature	O
maps	O
for	O
further	O
convolutional	B-Method
layers	I-Method
in	O
the	O
relation	B-Method
module	I-Method
.	O
	
The	O
relation	B-Method
module	I-Method
consists	O
of	O
two	O
convolutional	B-Method
blocks	I-Method
and	O
two	O
fully	B-Method
-	I-Method
connected	I-Method
layers	I-Method
.	O
	
Each	O
of	O
convolutional	B-Method
block	I-Method
is	O
a	O
convolution	B-Method
with	O
64	B-Method
filters	I-Method
followed	O
by	O
batch	B-Method
normalisation	I-Method
,	O
ReLU	B-Method
non	I-Method
-	I-Method
linearity	I-Method
and	O
max	B-Method
-	I-Method
pooling	I-Method
.	O
	
The	O
output	O
size	O
of	O
last	O
max	B-Method
pooling	I-Method
layer	I-Method
is	O
and	O
for	O
Omniglot	B-Material
and	O
mini	B-Material
ImageNet	I-Material
respectively	O
.	O
	
The	O
two	O
fully	B-Method
-	I-Method
connected	I-Method
layers	I-Method
are	O
8	O
and	O
1	O
dimensional	O
,	O
respectively	O
.	O
	
All	O
fully	B-Method
-	I-Method
connected	I-Method
layers	I-Method
are	O
ReLU	B-Method
except	O
the	O
output	O
layer	O
is	O
Sigmoid	O
in	O
order	O
to	O
generate	O
relation	O
scores	O
in	O
a	O
reasonable	O
range	O
for	O
all	O
versions	O
of	O
our	O
network	B-Method
architecture	I-Method
.	O
	
The	O
zero	B-Task
-	I-Task
shot	I-Task
learning	I-Task
architecture	O
is	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
In	O
this	O
architecture	O
,	O
the	O
DNN	B-Method
subnet	I-Method
is	O
an	O
existing	O
network	O
(	O
e.g.	O
,	O
Inception	B-Method
or	O
ResNet	B-Method
)	O
pretrained	O
on	O
ImageNet	B-Material
.	O
	
section	O
:	O
Experiments	O
	
We	O
evaluate	O
our	O
approach	O
on	O
two	O
related	O
tasks	O
:	O
few	B-Task
-	I-Task
shot	O
classification	O
on	O
Omniglot	B-Material
and	O
mini	B-Material
Imagenet	I-Material
,	O
and	O
zero	B-Task
-	I-Task
shot	I-Task
classification	I-Task
on	O
Animals	B-Material
with	I-Material
Attributes	I-Material
(	O
AwA	B-Material
)	O
and	O
Caltech	B-Material
-	I-Material
UCSD	I-Material
Birds	I-Material
-	I-Material
200	I-Material
-	I-Material
2011	I-Material
(	O
CUB	B-Material
)	O
.	O
	
All	O
the	O
experiments	O
are	O
implemented	O
based	O
on	O
PyTorch	B-Method
.	O
	
subsection	O
:	O
Few	B-Task
-	I-Task
shot	I-Task
Recognition	I-Task
	
Settings	O
Few	B-Task
-	I-Task
shot	I-Task
learning	I-Task
in	O
all	O
experiments	O
uses	O
Adam	B-Method
with	O
initial	O
learning	B-Metric
rate	I-Metric
,	O
annealed	O
by	O
half	O
for	O
every	O
100	O
,	O
000	O
episodes	O
.	O
	
All	O
our	O
models	O
are	O
end	O
-	O
to	O
-	O
end	O
trained	O
from	O
scratch	O
with	O
no	O
additional	O
dataset	O
.	O
	
Baselines	O
We	O
compare	O
against	O
various	O
state	O
of	O
the	O
art	O
baselines	O
for	O
few	B-Task
-	I-Task
shot	O
recognition	O
,	O
including	O
neural	B-Method
statistician	I-Method
,	O
Matching	B-Method
Nets	I-Method
with	O
and	O
without	O
fine	B-Method
-	I-Method
tuning	I-Method
,	O
MANN	B-Method
,	O
Siamese	B-Method
Nets	I-Method
with	O
Memory	B-Method
,	O
Convolutional	B-Method
Siamese	I-Method
Nets	I-Method
,	O
MAML	B-Method
,	O
Meta	B-Method
Nets	I-Method
,	O
Prototypical	B-Method
Nets	I-Method
and	O
Meta	B-Method
-	I-Method
Learner	I-Method
LSTM	I-Method
.	O
	
subsubsection	O
:	O
Omniglot	B-Material
	
Dataset	O
Omniglot	B-Material
contains	O
1623	O
characters	O
(	O
classes	O
)	O
from	O
50	O
different	O
alphabets	O
.	O
	
Each	O
class	O
contains	O
20	O
samples	O
drawn	O
by	O
different	O
people	O
.	O
	
Following	O
,	O
we	O
augment	O
new	O
classes	O
through	O
,	O
and	O
rotations	O
of	O
existing	O
data	O
and	O
use	O
1200	O
original	O
classes	O
plus	O
rotations	O
for	O
training	O
and	O
remaining	O
423	O
classes	O
plus	O
rotations	O
for	O
testing	O
.	O
	
All	O
input	O
images	O
are	O
resized	O
to	O
.	O
	
Training	O
Besides	O
the	O
sample	O
images	O
,	O
the	O
5	B-Material
-	I-Material
way	I-Material
1	I-Material
-	I-Material
shot	I-Material
contains	O
19	O
query	O
images	O
,	O
the	O
5	B-Material
-	I-Material
way	I-Material
5	I-Material
-	I-Material
shot	I-Material
has	O
15	O
query	O
images	O
,	O
	
the	O
20	B-Material
-	I-Material
way	I-Material
1	I-Material
-	I-Material
shot	I-Material
has	O
10	O
query	O
images	O
and	O
the	O
20	O
-	O
way	O
5	O
-	O
shot	O
has	O
5	O
query	O
images	O
for	O
each	O
of	O
the	O
sampled	O
classes	O
in	O
each	O
training	O
episode	O
.	O
	
This	O
means	O
for	O
example	O
that	O
there	O
are	O
images	O
in	O
one	O
training	O
episode	O
/	O
mini	O
-	O
batch	O
for	O
the	O
5	B-Material
-	I-Material
way	I-Material
1	I-Material
-	I-Material
shot	I-Material
experiments	O
.	O
	
Results	O
Following	O
,	O
we	O
computed	O
few	B-Task
-	I-Task
shot	O
classification	O
accuracies	O
on	O
Omniglot	B-Material
by	O
averaging	O
over	O
1000	O
randomly	O
generated	O
episodes	O
from	O
the	O
testing	O
set	O
.	O
	
For	O
the	O
1	B-Task
-	I-Task
shot	I-Task
and	I-Task
5	I-Task
-	I-Task
shot	I-Task
experiments	I-Task
,	O
we	O
batch	O
one	O
and	O
five	O
query	O
images	O
per	O
class	O
respectively	O
for	O
evaluation	O
during	O
testing	O
.	O
	
The	O
results	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
We	O
achieved	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
under	O
all	O
experiments	O
setting	O
with	O
higher	O
averaged	B-Metric
accuracies	I-Metric
and	O
lower	O
standard	O
deviations	O
,	O
except	O
5	B-Material
-	I-Material
way	I-Material
5	I-Material
-	I-Material
shot	I-Material
where	O
our	O
model	O
is	O
0.1	O
%	O
lower	O
in	O
accuracy	B-Metric
than	O
.	O
	
This	O
is	O
despite	O
that	O
many	O
alternatives	O
have	O
significantly	O
more	O
complicated	O
machinery	O
,	O
or	O
fine	O
-	O
tune	O
on	O
the	O
target	O
problem	O
,	O
while	O
we	O
do	O
not	O
.	O
	
subsubsection	O
:	O
mini	B-Material
ImageNet	I-Material
	
paragraph	O
:	O
Dataset	O
	
The	O
mini	B-Material
Imagenet	I-Material
dataset	O
,	O
originally	O
proposed	O
by	O
,	O
consists	O
of	O
60	O
,	O
000	O
colour	O
images	O
with	O
100	O
classes	O
,	O
each	O
having	O
600	O
examples	O
.	O
	
We	O
followed	O
the	O
split	O
introduced	O
by	O
,	O
with	O
64	O
,	O
16	O
,	O
and	O
20	O
classes	O
for	O
training	O
,	O
validation	B-Task
and	O
testing	B-Task
,	O
respectively	O
.	O
	
The	O
16	O
validation	O
classes	O
is	O
used	O
for	O
monitoring	B-Task
generalisation	I-Task
performance	I-Task
only	O
.	O
	
Training	O
Following	O
the	O
standard	O
setting	O
adopted	O
by	O
most	O
existing	O
few	B-Task
-	I-Task
shot	I-Task
learning	I-Task
work	O
,	O
we	O
conducted	O
5	O
way	B-Task
1	I-Task
-	I-Task
shot	I-Task
and	I-Task
5	I-Task
-	I-Task
shot	I-Task
classification	I-Task
.	O
	
Beside	O
the	O
sample	O
images	O
,	O
the	O
5	B-Material
-	I-Material
way	I-Material
1	I-Material
-	I-Material
shot	I-Material
contains	O
15	O
query	O
images	O
,	O
and	O
the	O
5	B-Material
-	I-Material
way	I-Material
5	I-Material
-	I-Material
shot	I-Material
has	O
10	O
query	O
images	O
for	O
each	O
of	O
the	O
sampled	O
classes	O
in	O
each	O
training	O
episode	O
.	O
	
This	O
means	O
for	O
example	O
that	O
there	O
are	O
images	O
in	O
one	O
training	O
episode	O
/	O
mini	O
-	O
batch	O
for	O
5	B-Material
-	I-Material
way	I-Material
1	I-Material
-	I-Material
shot	I-Material
experiments	O
.	O
	
We	O
resize	O
input	O
images	O
to	O
.	O
	
Our	O
model	O
is	O
trained	O
end	O
-	O
to	O
-	O
end	O
from	O
scratch	O
,	O
with	O
random	B-Method
initialisation	I-Method
,	O
and	O
no	O
additional	O
training	O
set	O
.	O
	
Results	O
Following	O
,	O
we	O
batch	O
15	O
query	O
images	O
per	O
class	O
in	O
each	O
episode	O
for	O
evaluation	O
in	O
both	O
1	B-Task
-	I-Task
shot	I-Task
and	I-Task
5	I-Task
-	I-Task
shot	I-Task
scenarios	I-Task
and	O
the	O
few	B-Task
-	I-Task
shot	O
classification	O
accuracies	O
are	O
computed	O
by	O
averaging	O
over	O
600	O
randomly	O
generated	O
episodes	O
from	O
the	O
test	O
set	O
.	O
	
From	O
Table	O
[	O
reference	O
]	O
,	O
we	O
can	O
see	O
that	O
our	O
model	O
achieved	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
5	B-Material
-	I-Material
way	I-Material
1	I-Material
-	I-Material
shot	I-Material
settings	O
and	O
competitive	O
results	O
on	O
5	B-Material
-	I-Material
way	I-Material
5	I-Material
-	I-Material
shot	I-Material
.	O
	
However	O
,	O
the	O
1	O
-	O
shot	O
result	O
reported	O
by	O
prototypical	B-Method
networks	I-Method
reqired	O
to	O
be	O
trained	O
on	O
30	O
-	O
way	O
15	O
queries	O
per	O
training	O
episode	O
,	O
and	O
5	O
-	O
shot	O
result	O
was	O
trained	O
on	O
20	O
-	O
way	O
15	O
queries	O
per	O
training	O
episode	O
.	O
	
When	O
trained	O
with	O
5	O
-	O
way	O
15	O
query	O
per	O
training	O
episode	O
,	O
only	O
got	O
for	O
1	B-Task
-	I-Task
shot	I-Task
evaluation	I-Task
,	O
clearly	O
weaker	O
than	O
ours	O
.	O
	
In	O
contrast	O
,	O
all	O
our	O
models	O
are	O
trained	O
on	O
5	O
-	O
way	O
,	O
1	O
query	O
for	O
1	B-Material
-	I-Material
shot	I-Material
and	O
5	O
queries	O
for	O
5	O
-	O
shot	O
per	O
training	O
episode	O
,	O
with	O
much	O
less	O
training	O
queries	O
than	O
.	O
	
subsection	O
:	O
Zero	B-Task
-	I-Task
shot	I-Task
Recognition	I-Task
	
Datasets	O
and	O
settings	O
We	O
follow	O
two	O
ZSL	B-Method
settings	I-Method
:	O
the	O
old	O
setting	O
and	O
the	O
new	O
GBU	B-Method
setting	I-Method
provided	O
by	O
for	O
training	O
/	O
test	O
splits	O
.	O
	
Under	O
the	O
old	O
setting	O
,	O
adopted	O
by	O
most	O
existing	O
ZSL	B-Method
works	O
before	O
,	O
some	O
of	O
the	O
test	O
classes	O
also	O
appear	O
in	O
the	O
ImageNet	B-Material
1	I-Material
K	I-Material
classes	I-Material
,	O
which	O
have	O
been	O
used	O
to	O
pretrain	O
the	O
image	B-Method
embedding	I-Method
network	I-Method
,	O
thus	O
violating	O
the	O
zero	O
-	O
shot	O
assumption	O
.	O
	
In	O
contrast	O
,	O
the	O
new	O
GBU	B-Method
setting	I-Method
ensures	O
that	O
none	O
of	O
the	O
test	O
classes	O
of	O
the	O
datasets	O
appear	O
in	O
the	O
ImageNet	B-Material
1	I-Material
K	I-Material
classes	I-Material
.	O
	
Under	O
both	O
settings	O
,	O
the	O
test	O
set	O
can	O
comprise	O
only	O
the	O
unseen	O
class	O
samples	O
(	O
conventional	O
test	O
set	O
setting	O
)	O
or	O
a	O
mixture	O
of	O
seen	O
and	O
unseen	O
class	O
samples	O
.	O
	
The	O
latter	O
,	O
termed	O
generalised	B-Method
zero	I-Method
-	I-Method
shot	I-Method
learning	I-Method
(	O
GZSL	B-Method
)	O
,	O
is	O
more	O
realistic	O
in	O
practice	O
.	O
	
Two	O
widely	O
used	O
ZSL	B-Method
benchmarks	I-Method
are	O
selected	O
for	O
the	O
old	O
setting	O
:	O
AwA	B-Material
(	O
Animals	B-Material
with	I-Material
Attributes	I-Material
)	O
consists	O
of	O
30	O
,	O
745	O
images	O
of	O
50	O
classes	O
of	O
animals	O
.	O
	
It	O
has	O
a	O
fixed	O
split	O
for	O
evaluation	O
with	O
40	O
training	O
classes	O
and	O
10	O
test	O
classes	O
.	O
	
CUB	B-Material
(	O
Caltech	B-Material
-	I-Material
UCSD	I-Material
Birds	I-Material
-	I-Material
200	I-Material
-	I-Material
2011	I-Material
)	O
contains	O
11	O
,	O
788	O
images	O
of	O
200	O
bird	O
species	O
with	O
150	O
seen	O
classes	O
and	O
50	O
disjoint	O
unseen	O
classes	O
.	O
	
Three	O
datasets	O
are	O
selected	O
for	O
GBU	B-Task
setting	I-Task
:	O
AwA1	B-Material
,	O
AwA2	B-Material
and	O
CUB	B-Material
.	O
	
The	O
newly	O
released	O
AwA2	B-Material
consists	O
of	O
37	O
,	O
322	O
images	O
of	O
50	O
classes	O
which	O
is	O
an	O
extension	O
of	O
AwA	B-Material
while	O
AwA1	B-Material
is	O
same	O
as	O
AwA	B-Material
but	O
under	O
the	O
GBU	O
setting	O
.	O
	
Semantic	B-Method
representation	I-Method
For	O
AwA	B-Material
,	O
we	O
use	O
the	O
continuous	O
85	O
-	O
dimension	O
class	O
-	O
level	O
attribute	O
vector	O
from	O
,	O
which	O
has	O
been	O
used	O
by	O
all	O
recent	O
works	O
.	O
	
For	O
CUB	B-Material
,	O
a	O
continuous	O
312	O
-	O
dimension	O
class	O
-	O
level	O
attribute	O
vector	O
is	O
used	O
.	O
	
Implementation	O
details	O
Two	O
different	O
embedding	B-Method
modules	I-Method
are	O
used	O
for	O
the	O
two	O
input	O
modalities	O
in	O
zero	B-Task
-	I-Task
shot	I-Task
learning	I-Task
.	O
	
Unless	O
otherwise	O
specified	O
,	O
we	O
use	O
Inception	B-Method
-	I-Method
V2	I-Method
as	O
the	O
query	B-Method
image	I-Method
embedding	I-Method
DNN	I-Method
in	O
the	O
old	O
and	O
conventional	O
setting	O
and	O
ResNet101	B-Method
for	O
the	O
GBU	B-Task
and	I-Task
generalised	I-Task
setting	I-Task
,	O
taking	O
the	O
top	O
pooling	B-Method
units	I-Method
as	O
image	B-Method
embedding	I-Method
with	O
dimension	O
and	O
respectively	O
.	O
	
This	O
DNN	B-Method
is	O
pre	O
-	O
trained	O
on	O
ILSVRC	B-Task
2012	I-Task
1	I-Task
K	I-Task
classification	I-Task
without	O
fine	B-Task
-	I-Task
tuning	I-Task
,	O
as	O
in	O
recent	O
deep	B-Method
ZSL	I-Method
works	I-Method
.	O
	
A	O
MLP	B-Method
network	I-Method
is	O
used	O
for	O
embedding	O
semantic	O
attribute	O
vectors	O
.	O
	
The	O
size	O
of	O
hidden	B-Method
layer	I-Method
FC1	I-Method
(	O
Figure	O
[	O
reference	O
]	O
)	O
is	O
set	O
to	O
1024	O
and	O
1200	O
for	O
AwA	B-Material
and	O
CUB	B-Material
respectively	O
,	O
and	O
the	O
output	O
size	O
FC2	B-Method
is	O
set	O
to	O
the	O
same	O
dimension	O
as	O
the	O
image	B-Task
embedding	I-Task
for	O
both	O
datasets	O
.	O
	
For	O
the	O
relation	B-Method
module	I-Method
,	O
the	O
image	O
and	O
semantic	O
embeddings	O
are	O
concatenated	O
before	O
being	O
fed	O
into	O
MLPs	B-Method
with	O
hidden	B-Method
layer	I-Method
FC3	I-Method
size	O
400	O
and	O
1200	O
for	O
AwA	B-Material
and	O
CUB	B-Material
,	O
respectively	O
.	O
	
We	O
add	O
weight	B-Method
decay	I-Method
(	O
L2	B-Method
regularisation	I-Method
)	O
in	O
FC1	B-Method
&	O
2	O
as	O
there	O
is	O
a	O
hubness	B-Task
problem	I-Task
in	O
cross	B-Task
-	I-Task
modal	I-Task
mapping	I-Task
for	O
ZSL	B-Task
which	O
can	O
be	O
best	O
solved	O
by	O
mapping	O
the	O
semantic	O
feature	O
vector	O
to	O
the	O
visual	O
feature	O
space	O
with	O
regularisation	B-Method
.	O
	
After	O
that	O
,	O
FC3	B-Method
&	O
4	O
(	O
relation	B-Method
module	I-Method
)	O
are	O
used	O
to	O
compute	O
the	O
relation	O
between	O
the	O
semantic	B-Method
representation	I-Method
(	O
in	O
the	O
visual	O
feature	O
space	O
)	O
and	O
the	O
visual	B-Method
representation	I-Method
.	O
	
Since	O
the	O
hubness	B-Task
problem	I-Task
does	O
not	O
existing	O
in	O
this	O
step	O
,	O
no	O
L2	B-Method
regularisation	I-Method
/	I-Method
weight	I-Method
decay	I-Method
is	O
needed	O
.	O
	
All	O
the	O
ZSL	B-Method
models	I-Method
are	O
trained	O
with	O
weight	O
decay	O
in	O
the	O
embedding	B-Method
network	I-Method
.	O
	
The	O
learning	B-Metric
rate	I-Metric
is	O
initialised	O
to	O
with	O
Adam	B-Method
and	O
then	O
annealed	O
by	O
half	O
every	O
200	O
,	O
000	O
iterations	O
.	O
	
Results	O
under	O
the	O
old	O
setting	O
The	O
conventional	O
evaluation	O
for	O
ZSL	B-Task
followed	O
by	O
the	O
majority	O
of	O
prior	O
work	O
is	O
to	O
assume	O
that	O
the	O
test	O
data	O
all	O
comes	O
from	O
unseen	O
classes	O
.	O
	
We	O
evaluate	O
this	O
setting	O
first	O
.	O
	
We	O
compare	O
15	O
alternative	O
approaches	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
With	O
only	O
the	O
attribute	O
vector	O
used	O
as	O
the	O
sample	B-Method
class	I-Method
embedding	I-Method
,	O
our	O
model	O
achieves	O
competitive	O
result	O
on	O
AwA	B-Material
and	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
the	O
more	O
challenging	O
CUB	B-Material
dataset	O
,	O
outperforming	O
the	O
most	O
related	O
alternative	O
prototypical	B-Method
networks	I-Method
by	O
a	O
big	O
margin	O
.	O
	
Note	O
that	O
only	O
inductive	B-Method
methods	I-Method
are	O
considered	O
.	O
	
Some	O
recent	O
methods	O
are	O
tranductive	O
in	O
that	O
they	O
use	O
all	O
test	O
data	O
at	O
once	O
for	O
model	B-Task
training	I-Task
,	O
which	O
gives	O
them	O
a	O
big	O
advantage	O
at	O
the	O
cost	O
of	O
making	O
a	O
very	O
strong	O
assumption	O
that	O
may	O
not	O
be	O
met	O
in	O
practical	O
applications	O
,	O
so	O
we	O
do	O
not	O
compare	O
with	O
them	O
here	O
.	O
	
Results	O
under	O
the	O
GBU	O
setting	O
We	O
follow	O
the	O
evaluation	O
setting	O
of	O
.	O
	
We	O
compare	O
our	O
model	O
with	O
11	O
alternative	O
ZSL	B-Method
models	I-Method
in	O
Table	O
[	O
reference	O
]	O
.	O
	
The	O
10	O
shallow	B-Method
modelsâ	I-Method
results	O
are	O
from	O
and	O
the	O
result	O
of	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
method	O
DEM	O
is	O
from	O
the	O
authors	O
’	O
GitHub	O
page	O
.	O
	
We	O
can	O
see	O
that	O
on	O
AwA2	B-Material
and	O
CUB	B-Material
,	O
Our	O
model	O
is	O
particularly	O
strong	O
under	O
the	O
more	O
realistic	O
GZSL	B-Method
setting	O
measured	O
using	O
the	O
harmonic	B-Metric
mean	I-Metric
(	I-Metric
H	I-Metric
)	I-Metric
metric	I-Metric
.	O
	
While	O
on	O
AwA1	B-Material
,	O
our	O
method	O
is	O
only	O
outperformed	O
by	O
DEM	B-Method
.	O
	
section	O
:	O
Why	O
does	O
Relation	B-Method
Network	I-Method
Work	O
?	O
	
subsection	O
:	O
Relationship	O
to	O
existing	O
models	O
	
Related	O
prior	O
few	B-Task
-	I-Task
shot	O
work	O
uses	O
fixed	O
pre	O
-	O
specified	O
distance	B-Metric
metrics	I-Metric
such	O
as	O
Euclidean	B-Method
or	I-Method
cosine	I-Method
distance	I-Method
to	O
perform	O
classification	B-Task
.	O
	
These	O
studies	O
can	O
be	O
seen	O
as	O
distance	B-Method
metric	I-Method
learning	I-Method
,	O
but	O
where	O
all	O
the	O
learning	B-Task
occurs	O
in	O
the	O
feature	B-Method
embedding	I-Method
,	O
and	O
a	O
fixed	O
metric	O
is	O
used	O
given	O
the	O
learned	O
embedding	O
.	O
	
Also	O
related	O
are	O
conventional	O
metric	B-Method
learning	I-Method
approaches	I-Method
that	O
focus	O
on	O
learning	O
a	O
shallow	B-Method
(	I-Method
linear	I-Method
)	I-Method
Mahalanobis	I-Method
metric	I-Method
for	O
a	O
fixed	O
feature	B-Method
representation	I-Method
.	O
	
In	O
contrast	O
to	O
prior	O
work	O
’s	O
fixed	O
metric	O
or	O
fixed	O
features	O
and	O
shallow	O
learned	O
metric	O
,	O
Relation	B-Method
Network	I-Method
can	O
be	O
seen	O
as	O
both	O
learning	O
a	O
deep	B-Method
embedding	I-Method
and	O
learning	O
a	O
deep	O
non	O
-	O
linear	O
metric	O
(	O
similarity	O
function	O
)	O
.	O
	
These	O
are	O
mutually	O
tuned	O
end	O
-	O
to	O
-	O
end	O
to	O
support	O
each	O
other	O
in	O
few	B-Task
short	I-Task
learning	I-Task
.	O
	
Why	O
might	O
this	O
be	O
particularly	O
useful	O
?	O
	
By	O
using	O
a	O
flexible	O
function	B-Method
approximator	I-Method
to	O
learn	O
similarity	O
,	O
we	O
learn	O
a	O
good	O
metric	O
in	O
a	O
data	O
driven	O
way	O
and	O
do	O
not	O
have	O
to	O
manually	O
choose	O
the	O
right	O
metric	O
(	O
Euclidean	O
,	O
cosine	O
,	O
Mahalanobis	O
)	O
.	O
	
Fixed	B-Metric
metrics	I-Metric
like	O
assume	O
that	O
features	O
are	O
solely	O
compared	O
element	O
-	O
wise	O
,	O
and	O
the	O
most	O
related	O
assumes	O
linear	B-Method
separability	I-Method
after	O
the	O
embedding	B-Method
.	O
	
These	O
are	O
thus	O
critically	O
dependent	O
on	O
the	O
efficacy	O
of	O
the	O
learned	O
embedding	B-Method
network	I-Method
,	O
and	O
hence	O
limited	O
by	O
the	O
extent	O
to	O
which	O
the	O
embedding	B-Method
networks	I-Method
generate	O
inadequately	O
discriminative	B-Method
representations	I-Method
.	O
	
In	O
contrast	O
,	O
by	O
deep	B-Task
learning	I-Task
a	O
non	B-Method
-	I-Method
linear	I-Method
similarity	I-Method
metric	I-Method
jointly	O
with	O
the	O
embedding	B-Method
,	O
Relation	B-Method
Network	I-Method
can	O
better	O
identify	O
matching	O
/	O
mismatching	O
pairs	O
.	O
	
[	O
b	O
]	O
0.5	O
[	O
b	O
]	O
0.5	O
[	O
b	O
]	O
0.5	O
[	O
b	O
]	O
0.5	O
	
subsection	O
:	O
Visualisation	B-Task
	
To	O
illustrate	O
the	O
previous	O
point	O
about	O
adequacy	O
of	O
learned	O
input	O
embeddings	O
,	O
we	O
show	O
a	O
synthetic	O
example	O
where	O
existing	O
approaches	O
definitely	O
fail	O
and	O
our	O
Relation	B-Method
Network	I-Method
can	O
succeed	O
due	O
to	O
using	O
a	O
deep	O
relation	B-Method
module	I-Method
.	O
	
Assuming	O
2D	O
query	O
and	O
sample	O
input	O
embeddings	O
to	O
a	O
relation	B-Method
module	I-Method
,	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
a	O
)	O
shows	O
the	O
space	O
of	O
2D	O
sample	O
inputs	O
for	O
a	O
fixed	O
2D	O
query	O
input	O
.	O
	
Each	O
sample	O
input	O
(	O
pixel	O
)	O
is	O
colored	O
according	O
to	O
whether	O
it	O
matches	O
the	O
fixed	O
query	O
or	O
not	O
.	O
	
This	O
represents	O
a	O
case	O
where	O
the	O
output	O
of	O
the	O
embedding	B-Method
modules	I-Method
is	O
not	O
discriminative	O
enough	O
for	O
trivial	O
(	O
Euclidean	B-Method
NN	I-Method
)	I-Method
comparison	I-Method
between	O
query	O
and	O
sample	O
set	O
.	O
	
In	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
(	O
c	O
)	O
we	O
attempt	O
to	O
learn	O
matching	B-Task
via	O
a	O
Mahalanobis	O
metric	O
learning	O
relation	B-Method
module	I-Method
,	O
and	O
we	O
can	O
see	O
the	O
result	O
is	O
inadequate	O
.	O
	
In	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
(	O
d	O
)	O
we	O
learn	O
a	O
further	O
2	B-Method
-	I-Method
hidden	I-Method
layer	I-Method
MLP	I-Method
embedding	I-Method
of	I-Method
query	I-Method
and	I-Method
sample	I-Method
inputs	I-Method
as	O
well	O
as	O
the	O
subsequent	O
Mahalanobis	B-Metric
metric	I-Metric
,	O
which	O
is	O
also	O
not	O
adequate	O
.	O
	
Only	O
by	O
learning	O
the	O
full	O
deep	O
relation	B-Method
module	I-Method
for	O
similarity	B-Task
can	O
we	O
solve	O
this	O
problem	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
b	O
)	O
.	O
	
In	O
a	O
real	O
problem	O
the	O
difficulty	O
of	O
comparing	B-Task
embeddings	I-Task
may	O
not	O
be	O
this	O
extreme	O
,	O
but	O
it	O
can	O
still	O
be	O
challenging	O
.	O
	
We	O
qualitatively	O
illustrate	O
the	O
challenge	O
of	O
matching	O
two	O
example	O
Omniglot	B-Material
query	O
images	O
(	O
embeddings	O
projected	O
to	O
2D	O
,	O
Figure	O
[	O
reference	O
]	O
(	O
left	O
)	O
)	O
by	O
showing	O
an	O
analogous	O
plot	O
of	O
real	O
sample	O
images	O
colored	O
by	O
match	O
(	O
cyan	O
)	O
or	O
mismatch	O
(	O
magenta	O
)	O
to	O
two	O
example	O
queries	O
(	O
yellow	O
)	O
.	O
	
Under	O
standard	O
assumptions	O
the	O
cyan	O
matching	O
samples	O
should	O
be	O
nearest	O
neighbours	O
to	O
the	O
yellow	O
query	O
image	O
with	O
some	O
metric	O
(	O
Euclidean	O
,	O
Cosine	O
,	O
Mahalanobis	B-Method
)	O
.	O
	
But	O
we	O
can	O
see	O
that	O
the	O
match	O
relation	O
is	O
more	O
complex	O
than	O
this	O
.	O
	
In	O
Figure	O
[	O
reference	O
]	O
(	O
right	O
)	O
,	O
we	O
instead	O
plot	O
the	O
same	O
two	O
example	O
queries	O
in	O
terms	O
of	O
a	O
2D	B-Method
PCA	I-Method
representation	I-Method
of	O
each	O
query	O
-	O
sample	O
pair	O
,	O
as	O
represented	O
by	O
the	O
relation	B-Method
module	I-Method
’s	O
penultimate	O
layer	O
.	O
	
We	O
can	O
see	O
that	O
the	O
relation	B-Method
network	I-Method
has	O
mapped	O
the	O
data	O
into	O
a	O
space	O
where	O
the	O
(	O
mis	O
)	O
matched	O
pairs	O
are	O
linearly	O
separable	O
.	O
	
section	O
:	O
Conclusion	O
	
We	O
proposed	O
a	O
simple	O
method	O
called	O
the	O
Relation	B-Method
Network	I-Method
for	O
few	B-Task
-	I-Task
shot	I-Task
and	O
zero	B-Task
-	I-Task
shot	I-Task
learning	I-Task
.	O
	
Relation	B-Method
network	I-Method
learns	O
an	O
embedding	B-Method
and	O
a	O
deep	B-Method
non	I-Method
-	I-Method
linear	I-Method
distance	I-Method
metric	I-Method
for	O
comparing	O
query	O
and	O
sample	O
items	O
.	O
	
Training	O
the	O
network	O
end	O
-	O
to	O
-	O
end	O
with	O
episodic	B-Method
training	I-Method
tunes	O
the	O
embedding	B-Metric
and	I-Metric
distance	I-Metric
metric	I-Metric
for	O
effective	O
few	B-Task
-	I-Task
shot	I-Task
learning	I-Task
.	O
	
This	O
approach	O
is	O
far	O
simpler	O
and	O
more	O
efficient	O
than	O
recent	O
few	B-Task
-	I-Task
shot	O
meta	O
-	O
learning	O
approaches	O
,	O
and	O
produces	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
.	O
	
It	O
further	O
proves	O
effective	O
at	O
both	O
conventional	O
and	O
generalised	B-Task
zero	I-Task
-	I-Task
shot	I-Task
settings	I-Task
.	O
	
Acknowledgements	O
This	O
work	O
was	O
supported	O
by	O
the	O
ERC	O
grant	O
ERC	O
-	O
2012	O
-	O
AdG	O
321162	O
-	O
HELIOS	O
,	O
EPSRC	O
grant	O
Seebibyte	O
EP	O
/	O
M013774	O
/	O
1	O
	
,	O
EPSRC	O
/	O
MURI	O
grant	O
EP	O
/	O
N019474	O
/	O
1	O
,	O
EPSRC	O
grant	O
EP	O
/	O
R026173	O
/	O
1	O
,	O
and	O
the	O
European	O
Union	O
’s	O
Horizon	O
2020	O
research	O
and	O
innovation	O
program	O
(	O
grant	O
agreement	O
no	O
.	O
640891	O
)	O
.	O
	
We	O
gratefully	O
acknowledge	O
the	O
support	O
of	O
NVIDIA	O
Corporation	O
with	O
the	O
donation	O
of	O
the	O
Titan	O
Xp	O
GPU	O
and	O
the	O
ESPRC	O
funded	O
Tier	O
2	O
facility	O
,	O
JADE	O
used	O
for	O
this	O
research	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
EAST	B-Method
:	O
An	O
Efficient	B-Method
and	I-Method
Accurate	I-Method
Scene	I-Method
Text	I-Method
Detector	I-Method
	
Previous	O
approaches	O
for	O
scene	B-Task
text	I-Task
detection	I-Task
have	O
already	O
achieved	O
promising	O
performances	O
across	O
various	O
benchmarks	O
.	O
	
However	O
,	O
they	O
usually	O
fall	O
short	O
when	O
dealing	O
with	O
challenging	O
scenarios	O
,	O
even	O
when	O
equipped	O
with	O
deep	B-Method
neural	I-Method
network	I-Method
models	I-Method
,	O
because	O
the	O
overall	O
performance	O
is	O
determined	O
by	O
the	O
interplay	O
of	O
multiple	O
stages	O
and	O
components	O
in	O
the	O
pipelines	O
.	O
	
In	O
this	O
work	O
,	O
we	O
propose	O
a	O
simple	O
yet	O
powerful	O
pipeline	O
that	O
yields	O
fast	O
and	O
accurate	O
text	B-Task
detection	I-Task
in	I-Task
natural	I-Task
scenes	I-Task
.	O
	
The	O
pipeline	O
directly	O
predicts	O
words	O
or	O
text	O
lines	O
of	O
arbitrary	O
orientations	O
and	O
quadrilateral	O
shapes	O
in	O
full	O
images	O
,	O
eliminating	O
unnecessary	O
intermediate	O
steps	O
(	O
e.g.	O
,	O
candidate	B-Task
aggregation	I-Task
and	O
word	B-Task
partitioning	I-Task
)	O
,	O
with	O
a	O
single	O
neural	B-Method
network	I-Method
.	O
	
The	O
simplicity	O
of	O
our	O
pipeline	O
allows	O
concentrating	O
efforts	O
on	O
designing	O
loss	B-Method
functions	I-Method
and	O
neural	B-Method
network	I-Method
architecture	I-Method
.	O
	
Experiments	O
on	O
standard	O
datasets	O
including	O
ICDAR	B-Material
2015	I-Material
,	O
COCO	B-Material
-	I-Material
Text	I-Material
and	O
MSRA	B-Material
-	I-Material
TD500	I-Material
demonstrate	O
that	O
the	O
proposed	O
algorithm	O
significantly	O
outperforms	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
in	O
terms	O
of	O
both	O
accuracy	B-Metric
and	O
efficiency	B-Metric
.	O
	
On	O
the	O
ICDAR	B-Material
2015	I-Material
dataset	O
,	O
the	O
proposed	O
algorithm	O
achieves	O
an	O
F	B-Metric
-	I-Metric
score	I-Metric
of	O
0.7820	O
at	O
13.2fps	O
at	O
720p	O
resolution	O
.	O
	
Megvii	B-Method
Technology	I-Method
Inc.	O
,	O
Beijing	O
,	O
China	O
{	O
zxy	O
,	O
yaocong	O
,	O
wenhe	O
,	O
wangyuzhi	O
,	O
zsc	O
,	O
hwr	O
,	O
liangjiajun}@megvii.com	O
	
section	O
:	O
Introduction	O
	
Recently	O
,	O
extracting	B-Task
and	I-Task
understanding	I-Task
textual	I-Task
information	I-Task
embodied	O
in	O
natural	O
scenes	O
have	O
become	O
increasingly	O
important	O
and	O
popular	O
,	O
which	O
is	O
evidenced	O
by	O
the	O
unprecedented	O
large	O
numbers	O
of	O
participants	O
of	O
the	O
ICDAR	B-Task
series	I-Task
contests	I-Task
and	O
the	O
launch	O
of	O
the	O
TRAIT	O
2016	O
evaluation	O
by	O
NIST	B-Metric
.	O
	
Text	B-Task
detection	I-Task
,	O
as	O
a	O
prerequisite	O
of	O
the	O
subsequent	O
processes	O
,	O
plays	O
a	O
critical	O
role	O
in	O
the	O
whole	O
procedure	O
of	O
textual	B-Task
information	I-Task
extraction	I-Task
and	I-Task
understanding	I-Task
.	O
	
Previous	O
text	B-Method
detection	I-Method
approaches	I-Method
have	O
already	O
obtained	O
promising	O
performances	O
on	O
various	O
benchmarks	O
in	O
this	O
field	O
.	O
	
The	O
core	O
of	O
text	B-Task
detection	I-Task
is	O
the	O
design	O
of	O
features	O
to	O
distinguish	O
text	O
from	O
backgrounds	O
.	O
	
Traditionally	O
,	O
features	O
are	O
manually	O
designed	O
to	O
capture	O
the	O
properties	O
of	O
scene	O
text	O
,	O
while	O
in	O
deep	B-Method
learning	I-Method
based	I-Method
methods	I-Method
effective	O
features	O
are	O
directly	O
learned	O
from	O
training	O
data	O
.	O
	
compat=1.8	O
every	O
tick	O
label	O
/	O
.append	O
style	O
=	O
font=	O
grid	O
style	O
=	O
dotted	O
,	O
gray	O
[	O
xmin=0	O
,	O
xmax=17	O
,	O
ymin=0.49	O
,	O
ymax=0.85	O
,	O
grid	O
=	O
both	O
,	O
axis	O
lines	O
=	O
middle	O
,	O
line	O
width=.8pt	O
,	O
	
width=1.1height=.7xlabel=	O
Speed	O
(	O
FPS	B-Metric
)	O
,	O
ylabel=	O
F	B-Metric
-	I-Metric
score	I-Metric
]	O
	
[	O
only	O
marks	O
,	O
draw	O
=	O
black	O
,	O
fill	O
=	O
	
blue	O
,	O
mark	O
size=3pt	O
]	O
table	O
x	O
y	O
+	O
7.14	O
+	O
0.6085	O
	
+	O
1.61	O
+	O
0.6477	O
+	O
0.476	O
+	O
0.5358	O
;	O
[	O
only	O
marks	O
,	O
draw	O
=	O
black	O
,	O
fill	O
	
=	O
red	O
,	O
mark	O
size=3pt	O
]	O
table	O
x	O
y	O
+	O
13.245e	O
+	O
00	O
	
+	O
0.7820	O
+	O
16.779e	O
+	O
00	O
+	O
0.7571	O
;	O
at	O
(	O
axis	O
cs:7.3	O
,	O
0.58	O
)	O
	
[	O
anchor	O
=	O
base	O
west	O
,	O
text	O
=	O
black	O
,	O
rotate=0.0	O
,	O
align	O
=	O
left	O
]	O
Tian	O
(	O
0.609@7.14fps	O
)	O
;	O
at	O
(	O
axis	O
cs:1.3	O
,	O
0.6677	O
)	O
	
[	O
anchor	O
=	O
base	O
west	O
,	O
text	O
=	O
black	O
,	O
rotate=0.0	O
,	O
align	O
=	O
left	O
]	O
Yao	O
(	O
0.648@1.61fps	O
)	O
;	O
at	O
(	O
axis	O
cs:0.6	O
,	O
0.505	O
)	O
	
[	O
anchor	O
=	O
base	O
west	O
,	O
text	O
=	O
black	O
,	O
rotate=0.0	O
,	O
align	O
=	O
left	O
]	O
	
Zhang	O
(	O
0.532@0.476fps	O
)	O
	
;	O
at	O
(	O
axis	O
cs:13.0	O
,	O
0.78	O
)	O
[	O
anchor	O
=	O
base	O
east	O
,	O
text	O
=	O
black	O
,	O
rotate=0.0	O
,	O
align	O
	
=	O
right	O
]	O
	
Ours	O
+	O
PVANet2x	O
(	O
0.782@13.2fps	O
)	O
;	O
at	O
(	O
axis	O
cs:16.8	O
,	O
0.69	O
)	O
[	O
anchor	O
	
=	O
base	O
east	O
,	O
text	O
=	O
black	O
,	O
	
rotate=0.0	O
,	O
align	O
=	O
right	O
]	O
	
Ours	B-Method
+	I-Method
PVANet	I-Method
(	I-Method
0.757@16.8fps	I-Method
)	O
;	O
However	O
,	O
existing	O
methods	O
,	O
either	O
conventional	O
or	O
deep	B-Method
neural	I-Method
network	I-Method
based	O
,	O
mostly	O
consist	O
of	O
several	O
stages	O
and	O
components	O
,	O
which	O
are	O
probably	O
sub	O
-	O
optimal	O
and	O
time	O
-	O
consuming	O
.	O
	
Therefore	O
,	O
the	O
accuracy	B-Metric
and	O
efficiency	O
of	O
such	O
methods	O
are	O
still	O
far	O
from	O
satisfactory	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
fast	O
and	O
accurate	O
scene	B-Task
text	I-Task
detection	I-Task
pipeline	O
that	O
has	O
only	O
two	O
stages	O
.	O
	
The	O
pipeline	O
utilizes	O
a	O
fully	B-Method
convolutional	I-Method
network	I-Method
(	I-Method
FCN	I-Method
)	I-Method
model	I-Method
that	O
directly	O
produces	O
word	O
or	O
text	O
-	O
line	O
level	O
predictions	O
,	O
excluding	O
redundant	O
and	O
slow	O
intermediate	O
steps	O
.	O
	
The	O
produced	O
text	O
predictions	O
,	O
which	O
can	O
be	O
either	O
rotated	O
rectangles	O
or	O
quadrangles	O
,	O
are	O
sent	O
to	O
Non	O
-	O
Maximum	B-Method
Suppression	I-Method
to	O
yield	O
final	O
results	O
.	O
	
Compared	O
with	O
existing	O
methods	O
,	O
the	O
proposed	O
algorithm	O
achieves	O
significantly	O
enhanced	O
performance	O
,	O
while	O
running	O
much	O
faster	O
,	O
according	O
to	O
the	O
qualitative	O
and	O
quantitative	O
experiments	O
on	O
standard	O
benchmarks	O
.	O
	
Specifically	O
,	O
the	O
proposed	O
algorithm	O
achieves	O
an	O
F	B-Metric
-	I-Metric
score	I-Metric
of	O
0.7820	O
on	O
ICDAR	B-Material
2015	I-Material
(	O
0.8072	O
when	O
tested	O
in	O
multi	B-Task
-	I-Task
scale	I-Task
)	O
,	O
0.7608	O
on	O
MSRA	B-Material
-	I-Material
TD500	I-Material
and	O
0.3945	O
on	O
COCO	B-Material
-	I-Material
Text	I-Material
,	O
outperforming	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
algorithms	O
in	O
performance	O
while	O
taking	O
much	O
less	O
time	O
on	O
average	O
(	O
13.2fps	O
at	O
720p	O
resolution	O
on	O
a	O
Titan	O
-	O
X	O
GPU	O
for	O
our	O
best	O
performing	O
model	O
,	O
16.8fps	O
for	O
our	O
fastest	O
model	O
)	O
.	O
	
The	O
contributions	O
of	O
this	O
work	O
are	O
three	O
-	O
fold	O
:	O
We	O
propose	O
a	O
scene	B-Task
text	I-Task
detection	I-Task
method	O
that	O
consists	O
of	O
two	O
stages	O
:	O
a	O
Fully	B-Method
Convolutional	I-Method
Network	I-Method
and	O
an	O
NMS	B-Method
merging	I-Method
stage	I-Method
.	O
	
The	O
FCN	B-Method
directly	O
produces	O
text	O
regions	O
,	O
excluding	O
redundant	O
and	O
time	O
-	O
consuming	O
intermediate	O
steps	O
.	O
	
The	O
pipeline	O
is	O
flexible	O
to	O
produce	O
either	O
word	O
level	O
or	O
line	O
level	O
predictions	O
,	O
whose	O
geometric	O
shapes	O
can	O
be	O
rotated	O
boxes	O
or	O
quadrangles	O
,	O
depending	O
on	O
specific	O
applications	O
.	O
	
The	O
proposed	O
algorithm	O
significantly	O
outperforms	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
in	O
both	O
accuracy	B-Metric
and	O
speed	B-Metric
.	O
	
section	O
:	O
Related	O
Work	O
	
Scene	B-Task
text	I-Task
detection	I-Task
and	O
recognition	B-Task
have	O
been	O
active	O
research	O
topics	O
in	O
computer	B-Task
vision	I-Task
for	O
a	O
long	O
period	O
of	O
time	O
.	O
	
Numerous	O
inspiring	O
ideas	O
and	O
effective	O
approaches	O
have	O
been	O
investigated	O
.	O
	
Comprehensive	O
reviews	O
and	O
detailed	O
analyses	O
can	O
be	O
found	O
in	O
survey	O
papers	O
.	O
	
This	O
section	O
will	O
focus	O
on	O
works	O
that	O
are	O
mostly	O
relevant	O
to	O
the	O
proposed	O
algorithm	O
.	O
	
Conventional	O
approaches	O
rely	O
on	O
manually	O
designed	O
features	O
.	O
	
Stroke	B-Method
Width	I-Method
Transform	I-Method
(	O
SWT	B-Method
)	O
and	O
Maximally	B-Method
Stable	I-Method
Extremal	I-Method
Regions	I-Method
(	O
MSER	B-Method
)	O
based	O
methods	O
generally	O
seek	O
character	O
candidates	O
via	O
edge	B-Method
detection	I-Method
or	O
extremal	B-Method
region	I-Method
extraction	I-Method
.	O
	
Zhang	O
made	O
use	O
of	O
the	O
local	O
symmetry	O
property	O
of	O
text	O
and	O
designed	O
various	O
features	O
for	O
text	B-Task
region	I-Task
detection	I-Task
.	O
	
FASText	B-Method
is	O
a	O
fast	B-Method
text	I-Method
detection	I-Method
system	I-Method
that	O
adapted	O
and	O
modified	O
the	O
well	O
-	O
known	O
FAST	B-Method
key	I-Method
point	I-Method
detector	I-Method
for	O
stroke	B-Task
extraction	I-Task
.	O
	
However	O
,	O
these	O
methods	O
fall	O
behind	O
of	O
those	O
based	O
on	O
deep	B-Method
neural	I-Method
networks	I-Method
,	O
in	O
terms	O
of	O
both	O
accuracy	B-Metric
and	O
adaptability	B-Metric
,	O
especially	O
when	O
dealing	O
with	O
challenging	O
scenarios	O
,	O
such	O
as	O
low	O
resolution	O
and	O
geometric	O
distortion	O
.	O
	
Recently	O
,	O
the	O
area	O
of	O
scene	B-Task
text	I-Task
detection	I-Task
has	O
entered	O
a	O
new	O
era	O
that	O
deep	B-Method
neural	I-Method
network	I-Method
based	I-Method
algorithms	I-Method
have	O
gradually	O
become	O
the	O
mainstream	O
.	O
	
Huang	O
first	O
found	O
candidates	O
using	O
MSER	B-Method
and	O
then	O
employed	O
a	O
deep	B-Method
convolutional	I-Method
network	I-Method
as	O
a	O
strong	O
classifier	B-Method
to	O
prune	O
false	O
positives	O
.	O
	
The	O
method	O
of	O
Jaderberg	O
scanned	O
the	O
image	O
in	O
a	O
sliding	O
-	O
window	O
fashion	O
and	O
produced	O
a	O
dense	O
heatmap	B-Method
for	O
each	O
scale	O
with	O
a	O
convolutional	B-Method
neural	I-Method
network	I-Method
model	I-Method
.	O
	
Later	O
,	O
Jaderberg	O
employed	O
both	O
a	O
CNN	B-Method
and	O
an	O
ACF	B-Method
to	O
hunt	O
word	O
candidates	O
and	O
further	O
refined	O
them	O
using	O
regression	B-Method
.	O
	
Tian	O
developed	O
vertical	B-Method
anchors	I-Method
and	O
constructed	O
a	O
CNN	B-Method
-	I-Method
RNN	I-Method
joint	I-Method
model	I-Method
to	O
detect	O
horizontal	O
text	O
lines	O
.	O
	
Different	O
from	O
these	O
methods	O
,	O
Zhang	O
proposed	O
to	O
utilize	O
FCN	B-Method
for	O
heatmap	B-Task
generation	I-Task
and	O
to	O
use	O
component	B-Method
projection	I-Method
for	O
orientation	B-Task
estimation	I-Task
.	O
	
These	O
methods	O
obtained	O
excellent	O
performance	O
on	O
standard	O
benchmarks	O
.	O
	
However	O
,	O
as	O
illustrated	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
a	O
-	O
d	O
)	O
,	O
they	O
mostly	O
consist	O
of	O
multiple	O
stages	O
and	O
components	O
,	O
such	O
as	O
false	B-Task
positive	I-Task
removal	I-Task
by	O
post	B-Method
filtering	I-Method
,	O
candidate	B-Task
aggregation	I-Task
,	O
line	B-Task
formation	I-Task
and	O
word	B-Task
partition	I-Task
.	O
	
The	O
multitude	O
of	O
stages	O
and	O
components	O
may	O
require	O
exhaustive	O
tuning	O
,	O
leading	O
to	O
sub	O
-	O
optimal	O
performance	O
,	O
and	O
add	O
to	O
processing	B-Metric
time	I-Metric
of	O
the	O
whole	O
pipeline	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
devise	O
a	O
deep	B-Method
FCN	I-Method
-	I-Method
based	I-Method
pipeline	I-Method
that	O
directly	O
targets	O
the	O
final	O
goal	O
of	O
text	B-Task
detection	I-Task
:	O
word	B-Task
or	I-Task
text	I-Task
-	I-Task
line	I-Task
level	I-Task
detection	I-Task
.	O
	
As	O
depicted	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
e	O
)	O
,	O
the	O
model	O
abandons	O
unnecessary	O
intermediate	O
components	O
and	O
steps	O
,	O
and	O
allows	O
for	O
end	O
-	O
to	O
-	O
end	B-Task
training	I-Task
and	O
optimization	B-Task
.	O
	
The	O
resultant	O
system	O
,	O
equipped	O
with	O
a	O
single	O
,	O
light	B-Method
-	I-Method
weighted	I-Method
neural	I-Method
network	I-Method
,	O
surpasses	O
all	O
previous	O
methods	O
by	O
an	O
obvious	O
margin	O
in	O
both	O
performance	O
and	O
speed	B-Metric
.	O
	
section	O
:	O
Methodology	O
	
The	O
key	O
component	O
of	O
the	O
proposed	O
algorithm	O
is	O
a	O
neural	B-Method
network	I-Method
model	I-Method
,	O
which	O
is	O
trained	O
to	O
directly	O
predict	O
the	O
existence	O
of	O
text	O
instances	O
and	O
their	O
geometries	O
from	O
full	O
images	O
.	O
	
The	O
model	O
is	O
a	O
fully	B-Method
-	I-Method
convolutional	I-Method
neural	I-Method
network	I-Method
adapted	O
for	O
text	B-Task
detection	I-Task
that	O
outputs	O
dense	B-Task
per	I-Task
-	I-Task
pixel	I-Task
predictions	I-Task
of	I-Task
words	I-Task
or	O
text	O
lines	O
.	O
	
This	O
eliminates	O
intermediate	O
steps	O
such	O
as	O
candidate	B-Task
proposal	I-Task
,	O
text	B-Task
region	I-Task
formation	I-Task
and	O
word	B-Task
partition	I-Task
.	O
	
The	O
post	O
-	O
processing	O
steps	O
only	O
include	O
thresholding	B-Method
and	O
NMS	B-Method
on	O
predicted	O
geometric	O
shapes	O
.	O
	
The	O
detector	O
is	O
named	O
as	O
EAST	B-Method
,	O
since	O
it	O
is	O
an	O
E	O
fficient	O
and	O
A	O
ccuracy	O
S	O
cene	O
T	O
ext	O
detection	B-Method
pipeline	I-Method
.	O
	
subsection	O
:	O
Pipeline	O
	
A	O
high	O
-	O
level	O
overview	O
of	O
our	O
pipeline	O
is	O
illustrated	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
e	O
)	O
.	O
	
The	O
algorithm	O
follows	O
the	O
general	O
design	O
of	O
DenseBox	B-Method
,	O
in	O
which	O
an	O
image	O
is	O
fed	O
into	O
the	O
FCN	B-Method
and	O
multiple	O
channels	O
of	O
pixel	O
-	O
level	O
text	O
score	O
map	O
and	O
geometry	O
are	O
generated	O
.	O
	
One	O
of	O
the	O
predicted	O
channels	O
is	O
a	O
score	B-Method
map	I-Method
whose	O
pixel	O
values	O
are	O
in	O
the	O
range	O
of	O
.	O
	
The	O
remaining	O
channels	O
represent	O
geometries	O
that	O
encloses	O
the	O
word	O
from	O
the	O
view	O
of	O
each	O
pixel	O
.	O
	
The	O
score	O
stands	O
for	O
the	O
confidence	O
of	O
the	O
geometry	O
shape	O
predicted	O
at	O
the	O
same	O
location	O
.	O
	
We	O
have	O
experimented	O
with	O
two	O
geometry	O
shapes	O
for	O
text	O
regions	O
,	O
rotated	O
box	O
(	O
RBOX	O
)	O
and	O
quadrangle	O
(	O
QUAD	O
)	O
,	O
and	O
designed	O
different	O
loss	B-Method
functions	I-Method
for	O
each	O
geometry	O
.	O
	
Thresholding	B-Method
is	O
then	O
applied	O
to	O
each	O
predicted	O
region	O
,	O
where	O
the	O
geometries	O
whose	O
scores	O
are	O
over	O
the	O
predefined	O
threshold	O
is	O
considered	O
valid	O
and	O
saved	O
for	O
later	O
non	B-Task
-	I-Task
maximum	I-Task
-	I-Task
suppression	I-Task
.	O
	
Results	O
after	O
NMS	B-Method
are	O
considered	O
the	O
final	O
output	O
of	O
the	O
pipeline	O
.	O
	
subsection	O
:	O
Network	B-Method
Design	I-Method
	
Several	O
factors	O
must	O
be	O
taken	O
into	O
account	O
when	O
designing	O
neural	B-Method
networks	I-Method
for	O
text	B-Task
detection	I-Task
.	O
	
Since	O
the	O
sizes	O
of	O
word	O
regions	O
,	O
as	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
vary	O
tremendously	O
,	O
determining	O
the	O
existence	O
of	O
large	O
words	O
would	O
require	O
features	O
from	O
late	O
-	O
stage	O
of	O
a	O
neural	B-Method
network	I-Method
,	O
while	O
predicting	O
accurate	O
geometry	O
enclosing	O
a	O
small	O
word	O
regions	O
need	O
low	O
-	O
level	O
information	O
in	O
early	O
stages	O
.	O
	
Therefore	O
the	O
network	O
must	O
use	O
features	O
from	O
different	O
levels	O
to	O
fulfill	O
these	O
requirements	O
.	O
	
HyperNet	B-Method
meets	O
these	O
conditions	O
on	O
features	B-Task
maps	I-Task
,	O
but	O
merging	O
a	O
large	O
number	O
of	O
channels	O
on	O
large	O
feature	O
maps	O
would	O
significantly	O
increase	O
the	O
computation	B-Metric
overhead	I-Metric
for	O
later	O
stages	O
.	O
	
In	O
remedy	O
of	O
this	O
,	O
we	O
adopt	O
the	O
idea	O
from	O
U	O
-	O
shape	O
to	O
merge	O
feature	O
maps	O
gradually	O
,	O
while	O
keeping	O
the	O
up	O
-	O
sampling	O
branches	O
small	O
.	O
	
Together	O
we	O
end	O
up	O
with	O
a	O
network	O
that	O
can	O
both	O
utilize	O
different	O
levels	O
of	O
features	O
and	O
keep	O
a	O
small	O
computation	B-Metric
cost	I-Metric
.	O
	
A	O
schematic	O
view	O
of	O
our	O
model	O
is	O
depicted	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
The	O
model	O
can	O
be	O
decomposed	O
in	O
to	O
three	O
parts	O
:	O
feature	B-Method
extractor	I-Method
stem	I-Method
,	O
feature	O
-	O
merging	O
branch	O
and	O
output	B-Method
layer	I-Method
.	O
	
The	O
stem	O
can	O
be	O
a	O
convolutional	B-Method
network	I-Method
pre	O
-	O
trained	O
on	O
ImageNet	B-Material
dataset	I-Material
,	O
with	O
interleaving	B-Method
convolution	I-Method
and	I-Method
pooling	I-Method
layers	I-Method
.	O
	
Four	O
levels	O
of	O
feature	O
maps	O
,	O
denoted	O
as	O
,	O
are	O
extracted	O
from	O
the	O
stem	O
,	O
whose	O
sizes	O
are	O
,	O
,	O
and	O
of	O
the	O
input	O
image	O
,	O
respectively	O
.	O
	
In	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
PVANet	B-Method
is	O
depicted	O
.	O
	
In	O
our	O
experiments	O
,	O
we	O
also	O
adopted	O
the	O
well	O
-	O
known	O
VGG16	B-Method
model	I-Method
,	O
where	O
feature	O
maps	O
after	O
pooling	O
-	O
2	O
to	O
pooling	O
-	O
5	O
are	O
extracted	O
.	O
	
In	O
the	O
feature	B-Task
-	I-Task
merging	I-Task
branch	I-Task
,	O
we	O
gradually	O
merge	O
them	O
:	O
where	O
is	O
the	O
merge	O
base	O
,	O
and	O
is	O
the	O
merged	O
feature	O
map	O
,	O
and	O
the	O
operator	O
represents	O
concatenation	O
along	O
the	O
channel	O
axis	O
.	O
	
In	O
each	O
merging	O
stage	O
,	O
the	O
feature	O
map	O
from	O
the	O
last	O
stage	O
is	O
first	O
fed	O
to	O
an	O
unpooling	B-Method
layer	I-Method
to	O
double	O
its	O
size	O
,	O
and	O
then	O
concatenated	O
with	O
the	O
current	O
feature	O
map	O
.	O
	
Next	O
,	O
a	O
bottleneck	O
cuts	O
down	O
the	O
number	O
of	O
channels	O
and	O
reduces	O
computation	O
,	O
followed	O
by	O
a	O
that	O
fuses	O
the	O
information	O
to	O
finally	O
produce	O
the	O
output	O
of	O
this	O
merging	B-Method
stage	I-Method
.	O
	
Following	O
the	O
last	O
merging	O
stage	O
,	O
a	O
layer	O
produces	O
the	O
final	O
feature	O
map	O
of	O
the	O
merging	O
branch	O
and	O
feed	O
it	O
to	O
the	O
output	O
layer	O
.	O
	
The	O
number	O
of	O
output	O
channels	O
for	O
each	O
convolution	B-Method
is	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
We	O
keep	O
the	O
number	O
of	O
channels	O
for	O
convolutions	O
in	O
branch	O
small	O
,	O
which	O
adds	O
only	O
a	O
fraction	O
of	O
computation	B-Metric
overhead	I-Metric
over	O
the	O
stem	O
,	O
making	O
the	O
network	B-Method
computation	I-Method
-	O
efficient	O
.	O
	
The	O
final	O
output	O
layer	O
contains	O
several	O
operations	O
to	O
project	O
32	O
channels	O
of	O
feature	O
maps	O
into	O
1	O
channel	O
of	O
score	B-Method
map	I-Method
and	O
a	O
multi	B-Method
-	I-Method
channel	I-Method
geometry	I-Method
map	I-Method
.	O
	
The	O
geometry	O
output	O
can	O
be	O
either	O
one	O
of	O
RBOX	O
or	O
QUAD	O
,	O
summarized	O
in	O
Tab	O
.	O
	
[	O
reference	O
]	O
	
For	O
RBOX	B-Method
,	O
the	O
geometry	O
is	O
represented	O
by	O
4	O
channels	O
of	O
axis	O
-	O
aligned	O
bounding	O
box	O
(	O
AABB	B-Method
)	O
and	O
1	O
channel	O
rotation	O
angle	O
.	O
	
The	O
formulation	O
of	O
is	O
the	O
same	O
as	O
that	O
in	O
,	O
where	O
the	O
4	O
channels	O
represents	O
4	O
distances	O
from	O
the	O
pixel	O
location	O
to	O
the	O
top	O
,	O
right	O
,	O
bottom	O
,	O
left	O
boundaries	O
of	O
the	O
rectangle	O
respectively	O
.	O
	
For	O
QUAD	O
,	O
we	O
use	O
8	O
numbers	O
to	O
denote	O
the	O
coordinate	O
shift	O
from	O
four	O
corner	O
vertices	O
of	O
the	O
quadrangle	O
to	O
the	O
pixel	O
location	O
.	O
	
As	O
each	O
distance	O
offset	O
contains	O
two	O
numbers	O
,	O
the	O
geometry	O
output	O
contains	O
8	O
channels	O
.	O
	
subsection	O
:	O
Label	B-Task
Generation	I-Task
	
subsubsection	B-Method
:	O
Score	B-Method
Map	I-Method
Generation	I-Method
for	O
Quadrangle	B-Task
	
Without	O
loss	O
of	O
generality	O
,	O
we	O
only	O
consider	O
the	O
case	O
where	O
the	O
geometry	O
is	O
a	O
quadrangle	O
.	O
	
The	O
positive	O
area	O
of	O
the	O
quadrangle	O
on	O
the	O
score	B-Metric
map	I-Metric
is	O
designed	O
to	O
be	O
roughly	O
a	O
shrunk	O
version	O
of	O
the	O
original	O
one	O
,	O
illustrated	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
a	O
)	O
.	O
	
For	O
a	O
quadrangle	O
,	O
where	O
are	O
vertices	O
on	O
the	O
quadrangle	O
in	O
clockwise	O
order	O
.	O
	
To	O
shrink	O
,	O
we	O
first	O
compute	O
a	O
reference	O
length	O
for	O
each	O
vertex	O
as	O
where	O
	
is	O
the	O
distance	O
between	O
and	O
.	O
	
We	O
first	O
shrink	O
the	O
two	O
longer	O
edges	O
of	O
a	O
quadrangle	O
,	O
and	O
then	O
the	O
two	O
shorter	O
ones	O
.	O
	
For	O
each	O
pair	O
of	O
two	O
opposing	O
edges	O
,	O
we	O
determine	O
the	O
“	O
longer	O
”	O
pair	O
by	O
comparing	O
the	O
mean	O
of	O
their	O
lengths	O
.	O
	
For	O
each	O
edge	O
,	O
we	O
shrink	O
it	O
by	O
moving	O
its	O
two	O
endpoints	O
inward	O
along	O
the	O
edge	O
by	O
and	O
respectively	O
.	O
	
subsubsection	O
:	O
Geometry	B-Task
Map	I-Task
Generation	I-Task
	
As	O
discussed	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
,	O
the	O
geometry	O
map	O
is	O
either	O
one	O
of	O
RBOX	B-Method
or	O
QUAD	B-Method
.	O
	
The	O
generation	B-Method
process	I-Method
for	O
RBOX	B-Method
is	O
illustrated	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
c	O
-	O
e	O
)	O
.	O
	
For	O
those	O
datasets	O
whose	O
text	O
regions	O
are	O
annotated	O
in	O
QUAD	O
style	O
(	O
,	O
ICDAR	B-Material
2015	I-Material
)	O
,	O
we	O
first	O
generate	O
a	O
rotated	O
rectangle	O
that	O
covers	O
the	O
region	O
with	O
minimal	O
area	O
.	O
	
Then	O
for	O
each	O
pixel	O
which	O
has	O
positive	O
score	O
,	O
we	O
calculate	O
its	O
distances	O
to	O
the	O
4	O
boundaries	O
of	O
the	O
text	O
box	O
,	O
and	O
put	O
them	O
to	O
the	O
4	O
channels	O
of	O
RBOX	O
ground	O
truth	O
.	O
	
For	O
the	O
QUAD	B-Task
ground	I-Task
truth	I-Task
,	O
the	O
value	O
of	O
each	O
pixel	O
with	O
positive	O
score	O
in	O
the	O
8	O
-	O
channel	O
geometry	O
map	O
is	O
its	O
coordinate	O
shift	O
from	O
the	O
4	O
vertices	O
of	O
the	O
quadrangle	O
.	O
	
subsection	O
:	O
Loss	B-Method
Functions	I-Method
	
The	O
loss	O
can	O
be	O
formulated	O
as	O
where	O
and	O
represents	O
the	O
losses	O
for	O
the	O
score	O
map	O
and	O
the	O
geometry	O
,	O
respectively	O
,	O
and	O
weighs	O
the	O
importance	O
between	O
two	O
losses	O
.	O
	
In	O
our	O
experiment	O
,	O
we	O
set	O
to	O
1	O
.	O
	
subsubsection	O
:	O
Loss	O
for	O
Score	B-Task
Map	I-Task
	
In	O
most	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
detection	B-Method
pipelines	I-Method
,	O
training	O
images	O
are	O
carefully	O
processed	O
by	O
balanced	B-Method
sampling	I-Method
and	O
hard	B-Method
negative	I-Method
mining	I-Method
to	O
tackle	O
with	O
the	O
imbalanced	O
distribution	O
of	O
target	O
objects	O
.	O
	
Doing	O
so	O
would	O
potentially	O
improve	O
the	O
network	O
performance	O
.	O
	
However	O
,	O
using	O
such	O
techniques	O
inevitably	O
introduces	O
a	O
non	O
-	O
differentiable	O
stage	O
and	O
more	O
parameters	O
to	O
tune	O
and	O
a	O
more	O
complicated	O
pipeline	O
,	O
which	O
contradicts	O
our	O
design	O
principle	O
.	O
	
To	O
facilitate	O
a	O
simpler	O
training	O
procedure	O
,	O
we	O
use	O
class	O
-	O
balanced	O
cross	O
-	O
entropy	O
introduced	O
in	O
,	O
given	O
by	O
where	O
is	O
the	O
prediction	O
of	O
the	O
score	B-Metric
map	I-Metric
,	O
and	O
is	O
the	O
ground	O
truth	O
.	O
	
The	O
parameter	O
is	O
the	O
balancing	O
factor	O
between	O
positive	O
and	O
negative	O
samples	O
,	O
given	O
by	O
This	O
balanced	B-Method
cross	I-Method
-	I-Method
entropy	I-Method
loss	I-Method
is	O
first	O
adopted	O
in	O
text	B-Task
detection	I-Task
by	O
Yao	O
as	O
the	O
objective	B-Metric
function	I-Metric
for	O
score	B-Task
map	I-Task
prediction	I-Task
.	O
	
We	O
find	O
it	O
works	O
well	O
in	O
practice	O
.	O
	
subsubsection	O
:	O
Loss	O
for	O
Geometries	B-Task
	
One	O
challenge	O
for	O
text	B-Task
detection	I-Task
is	O
that	O
the	O
sizes	O
of	O
text	O
in	O
natural	O
scene	O
images	O
vary	O
tremendously	O
.	O
	
Directly	O
using	O
L1	O
or	O
L2	O
loss	O
for	O
regression	B-Task
would	O
guide	O
the	O
loss	O
bias	O
towards	O
larger	O
and	O
longer	O
text	O
regions	O
.	O
	
As	O
we	O
need	O
to	O
generate	O
accurate	O
text	B-Task
geometry	I-Task
prediction	I-Task
for	O
both	O
large	O
and	O
small	O
text	O
regions	O
,	O
the	O
regression	O
loss	O
should	O
be	O
scale	O
-	O
invariant	O
.	O
	
Therefore	O
,	O
we	O
adopt	O
the	O
IoU	B-Metric
loss	I-Metric
in	O
the	O
AABB	B-Method
part	I-Method
of	I-Method
RBOX	I-Method
regression	I-Method
,	O
and	O
a	O
scale	B-Metric
-	I-Metric
normalized	I-Metric
smoothed	I-Metric
-	I-Metric
L1	I-Metric
loss	I-Metric
for	O
QUAD	B-Method
regression	I-Method
.	O
	
paragraph	O
:	O
RBOX	O
	
For	O
the	O
AABB	B-Task
part	I-Task
,	O
we	O
adopt	O
IoU	B-Metric
loss	I-Metric
in	O
,	O
since	O
it	O
is	O
invariant	O
against	O
objects	O
of	O
different	O
scales	O
.	O
	
where	O
represents	O
the	O
predicted	O
AABB	O
geometry	O
and	O
is	O
its	O
corresponding	O
ground	O
truth	O
.	O
	
It	O
is	O
easy	O
to	O
see	O
that	O
the	O
width	O
and	O
height	O
of	O
the	O
intersected	O
rectangle	O
are	O
where	O
,	O
,	O
and	O
represents	O
the	O
distance	O
from	O
a	O
pixel	O
to	O
the	O
top	O
,	O
right	O
,	O
bottom	O
and	O
left	O
boundary	O
of	O
its	O
corresponding	O
rectangle	O
,	O
respectively	O
.	O
	
The	O
union	O
area	O
is	O
given	O
by	O
Therefore	O
,	O
both	O
the	O
intersection	O
/	O
union	O
area	O
can	O
be	O
computed	O
easily	O
.	O
	
Next	O
,	O
the	O
loss	O
of	O
rotation	O
angle	O
is	O
computed	O
as	O
where	O
is	O
the	O
prediction	O
to	O
the	O
rotation	O
angle	O
and	O
represents	O
the	O
ground	O
truth	O
.	O
	
Finally	O
,	O
the	O
overall	B-Metric
geometry	I-Metric
loss	I-Metric
is	O
the	O
weighted	B-Metric
sum	I-Metric
of	I-Metric
AABB	I-Metric
loss	I-Metric
and	O
angle	B-Metric
loss	I-Metric
,	O
given	O
by	O
Where	O
is	O
set	O
to	O
in	O
our	O
experiments	O
.	O
	
Note	O
that	O
we	O
compute	O
regardless	O
of	O
rotation	O
angle	O
.	O
	
This	O
can	O
be	O
seen	O
as	O
an	O
approximation	O
of	O
quadrangle	B-Task
IoU	I-Task
when	O
the	O
angle	O
is	O
perfectly	O
predicted	O
.	O
	
Although	O
it	O
is	O
not	O
the	O
case	O
during	O
training	O
,	O
it	O
could	O
still	O
impose	O
the	O
correct	O
gradient	O
for	O
the	O
network	O
to	O
learn	O
to	O
predict	O
.	O
	
paragraph	O
:	O
QUAD	O
	
We	O
extend	O
the	O
smoothed	B-Method
-	I-Method
L1	I-Method
loss	I-Method
proposed	O
in	O
by	O
adding	O
an	O
extra	O
normalization	B-Method
term	I-Method
designed	O
for	O
word	O
quadrangles	O
,	O
which	O
is	O
typically	O
longer	O
in	O
one	O
direction	O
.	O
	
Let	O
all	O
coordinate	O
values	O
of	O
be	O
an	O
ordered	O
set	O
then	O
the	O
loss	O
can	O
be	O
written	O
as	O
where	O
the	O
normalization	O
term	O
is	O
the	O
shorted	O
edge	O
length	O
of	O
the	O
quadrangle	O
,	O
given	O
by	O
and	O
is	O
the	O
set	O
of	O
all	O
equivalent	O
quadrangles	O
of	O
with	O
different	O
vertices	O
ordering	O
.	O
	
This	O
ordering	O
permutation	O
is	O
required	O
since	O
the	O
annotations	O
of	O
quadrangles	O
in	O
the	O
public	O
training	O
datasets	O
are	O
inconsistent	O
.	O
	
subsection	O
:	O
Training	O
	
The	O
network	O
is	O
trained	O
end	O
-	O
to	O
-	O
end	O
using	O
ADAM	B-Method
optimizer	I-Method
.	O
	
To	O
speed	O
up	O
learning	B-Task
,	O
we	O
uniformly	O
sample	O
512x512	O
crops	O
from	O
images	O
to	O
form	O
a	O
minibatch	O
of	O
size	O
24	O
.	O
	
Learning	B-Metric
rate	I-Metric
of	O
ADAM	B-Method
starts	O
from	O
1e	O
-	O
3	O
,	O
decays	O
to	O
one	O
-	O
tenth	O
every	O
27300	O
minibatches	O
,	O
and	O
stops	O
at	O
1e	O
-	O
5	O
.	O
	
The	O
network	O
is	O
trained	O
until	O
performance	O
stops	O
improving	O
.	O
	
subsection	O
:	O
Locality	B-Method
-	I-Method
Aware	I-Method
NMS	I-Method
	
To	O
form	O
the	O
final	O
results	O
,	O
the	O
geometries	O
survived	O
after	O
thresholding	O
should	O
be	O
merged	O
by	O
NMS	B-Method
.	O
	
A	O
naïve	O
NMS	B-Method
algorithm	I-Method
runs	O
in	O
ï¼	O
where	O
is	O
the	O
number	O
of	O
candidate	O
geometries	O
,	O
which	O
is	O
unacceptable	O
as	O
we	O
are	O
facing	O
tens	O
of	O
thousands	O
of	O
geometries	O
from	O
dense	O
predictions	O
.	O
	
Under	O
the	O
assumption	O
that	O
the	O
geometries	O
from	O
nearby	O
pixels	O
tend	O
to	O
be	O
highly	O
correlated	O
,	O
we	O
proposed	O
to	O
merge	O
the	O
geometries	O
row	O
by	O
row	O
,	O
and	O
while	O
merging	O
geometries	O
in	O
the	O
same	O
row	O
,	O
we	O
will	O
iteratively	O
merge	O
the	O
geometry	O
currently	O
encountered	O
with	O
the	O
last	O
merged	O
one	O
.	O
	
This	O
improved	O
technique	O
runs	O
in	O
in	O
best	O
scenarios	O
.	O
	
Even	O
though	O
its	O
worst	O
case	O
is	O
the	O
same	O
as	O
the	O
naïve	O
one	O
,	O
as	O
long	O
as	O
the	O
locality	O
assumption	O
holds	O
,	O
the	O
algorithm	O
runs	O
sufficiently	O
fast	O
in	O
practice	O
.	O
	
The	O
procedure	O
is	O
summarized	O
in	O
Algorithm	O
[	O
reference	O
]	O
	
It	O
is	O
worth	O
mentioning	O
that	O
,	O
in	O
,	O
the	O
coordinates	O
of	O
merged	O
quadrangle	O
are	O
weight	O
-	O
averaged	O
by	O
the	O
scores	O
of	O
two	O
given	O
quadrangles	O
.	O
	
To	O
be	O
specific	O
,	O
if	O
,	O
then	O
and	O
,	O
where	O
is	O
one	O
of	O
the	O
coordinates	O
of	O
subscripted	O
by	O
,	O
and	O
is	O
the	O
score	O
of	O
geometry	O
.	O
	
In	O
fact	O
,	O
there	O
is	O
a	O
subtle	O
difference	O
that	O
we	O
are	O
”	O
averaging	O
”	O
rather	O
than	O
”	O
selecting	O
”	O
geometries	O
,	O
as	O
in	O
a	O
standard	O
NMS	B-Method
procedure	I-Method
will	O
do	O
,	O
acting	O
as	O
a	O
voting	B-Method
mechanism	I-Method
,	O
which	O
in	O
turn	O
introduces	O
a	O
stabilization	O
effect	O
when	O
feeding	O
videos	O
.	O
	
Nonetheless	O
,	O
we	O
still	O
adopt	O
the	O
word	O
”	O
NMS	B-Method
”	I-Method
for	O
functional	B-Task
description	I-Task
.	O
	
[	O
t	O
]	O
Locality	B-Method
-	I-Method
Aware	I-Method
NMS	I-Method
[	O
1	O
]	O
NMSLocality	B-Method
,	O
in	O
row	O
first	O
order	O
	
section	O
:	O
Experiments	O
	
To	O
compare	O
the	O
proposed	O
algorithm	O
with	O
existing	O
methods	O
,	O
we	O
conducted	O
qualitative	O
and	O
quantitative	O
experiments	O
on	O
three	O
public	O
benchmarks	O
:	O
	
ICDAR2015	B-Material
,	O
COCO	B-Material
-	I-Material
Text	I-Material
and	O
MSRA	B-Material
-	I-Material
TD500	I-Material
.	O
	
subsection	O
:	O
Benchmark	O
Datasets	O
	
ICDAR	B-Material
2015	I-Material
is	O
used	O
in	O
Challenge	O
4	O
of	O
ICDAR	B-Material
2015	I-Material
Robust	O
Reading	O
Competition	O
.	O
	
It	O
includes	O
a	O
total	O
of	O
1500	O
pictures	O
,	O
1000	O
of	O
which	O
are	O
used	O
for	O
training	O
and	O
the	O
remaining	O
are	O
for	O
testing	O
.	O
	
The	O
text	O
regions	O
are	O
annotated	O
by	O
4	O
vertices	O
of	O
the	O
quadrangle	O
,	O
corresponding	O
to	O
the	O
QUAD	O
geometry	O
in	O
this	O
paper	O
.	O
	
We	O
also	O
generate	O
RBOX	O
output	O
by	O
fitting	O
a	O
rotated	O
rectangle	O
which	O
has	O
the	O
minimum	O
area	O
.	O
	
These	O
images	O
are	O
taken	O
by	O
Google	O
Glass	O
in	O
an	O
incidental	O
way	O
.	O
	
Therefore	O
text	O
in	O
the	O
scene	O
can	O
be	O
in	O
arbitrary	O
orientations	O
,	O
or	O
suffer	O
from	O
motion	O
blur	O
and	O
low	O
resolution	O
.	O
	
We	O
also	O
used	O
the	O
229	O
training	O
images	O
from	O
ICDAR	B-Material
2013	I-Material
.	O
	
COCO	B-Material
-	I-Material
Text	I-Material
is	O
the	O
largest	O
text	O
detection	O
dataset	O
to	O
date	O
.	O
	
It	O
reuses	O
the	O
images	O
from	O
MS	B-Material
-	I-Material
COCO	I-Material
dataset	I-Material
.	O
	
A	O
total	O
of	O
63	O
,	O
686	O
images	O
are	O
annotated	O
,	O
in	O
which	O
43	O
,	O
686	O
are	O
chosen	O
to	O
be	O
the	O
training	O
set	O
and	O
the	O
rest	O
20	O
,	O
000	O
for	O
testing	O
.	O
	
Word	O
regions	O
are	O
annotated	O
in	O
the	O
form	O
of	O
axis	O
-	O
aligned	O
bounding	O
box	O
(	O
AABB	B-Method
)	O
,	O
which	O
is	O
a	O
special	O
case	O
of	O
RBOX	B-Method
.	O
	
For	O
this	O
dataset	O
,	O
we	O
set	O
angle	O
to	O
zero	O
.	O
	
We	O
use	O
the	O
same	O
data	O
processing	O
and	O
test	O
method	O
as	O
in	O
ICDAR	B-Material
2015	I-Material
.	O
	
MSRA	B-Material
-	I-Material
TD500	I-Material
is	O
a	O
dataset	O
comprises	O
of	O
300	O
training	O
images	O
and	O
200	O
test	O
images	O
.	O
	
Text	O
regions	O
are	O
of	O
arbitrary	O
orientations	O
and	O
annotated	O
at	O
sentence	O
level	O
.	O
	
Different	O
from	O
the	O
other	O
datasets	O
,	O
it	O
contains	O
text	O
in	O
both	O
English	B-Material
and	O
Chinese	B-Material
.	O
	
The	O
text	O
regions	O
are	O
annotated	O
in	O
RBOX	B-Material
format	I-Material
.	O
	
Since	O
the	O
number	O
of	O
training	O
images	O
is	O
too	O
few	O
to	O
learn	O
a	O
deep	B-Method
model	I-Method
,	O
we	O
also	O
harness	O
400	O
images	O
from	O
HUST	B-Material
-	I-Material
TR400	I-Material
dataset	I-Material
as	O
training	O
data	O
.	O
	
subsection	O
:	O
Base	B-Method
Networks	I-Method
	
As	O
except	O
for	O
COCO	B-Material
-	I-Material
Text	I-Material
,	O
all	O
text	O
detection	O
datasets	O
are	O
relatively	O
small	O
compared	O
to	O
the	O
datasets	O
for	O
general	B-Task
object	I-Task
detection	I-Task
,	O
therefore	O
if	O
a	O
single	O
network	O
is	O
adopted	O
for	O
all	O
the	O
benchmarks	O
,	O
it	O
may	O
suffer	O
from	O
either	O
over	O
-	O
fitting	O
or	O
under	O
-	O
fitting	O
.	O
	
We	O
experimented	O
with	O
three	O
different	O
base	B-Method
networks	I-Method
,	O
with	O
different	O
output	O
geometries	O
,	O
on	O
all	O
the	O
datasets	O
to	O
evaluate	O
the	O
proposed	O
framework	O
.	O
	
These	O
networks	O
are	O
summarized	O
in	O
Tab	O
.	O
	
[	O
reference	O
]	O
.	O
	
VGG16	B-Method
is	O
widely	O
used	O
as	O
base	B-Method
network	I-Method
in	O
many	O
tasks	O
to	O
support	O
subsequent	O
task	B-Task
-	I-Task
specific	I-Task
fine	I-Task
-	I-Task
tuning	I-Task
,	O
including	O
text	B-Task
detection	I-Task
.	O
	
There	O
are	O
two	O
drawbacks	O
of	O
this	O
network	O
:	O
(	O
1	O
)	O
.	O
	
The	O
receptive	O
field	O
for	O
this	O
network	O
is	O
small	O
.	O
	
Each	O
pixel	O
in	O
output	O
of	O
conv5_3	B-Method
only	O
has	O
a	O
receptive	O
field	O
of	O
196	O
.	O
	
(	O
2	O
)	O
.	O
	
It	O
is	O
a	O
rather	O
large	O
network	O
.	O
	
PVANET	B-Method
is	O
a	O
light	B-Method
weight	I-Method
network	I-Method
introduced	O
in	O
,	O
aiming	O
as	O
a	O
substitution	O
of	O
the	O
feature	B-Method
extractor	I-Method
in	O
Faster	B-Method
-	I-Method
RCNN	I-Method
framework	I-Method
.	O
	
Since	O
it	O
is	O
too	O
small	O
for	O
GPU	O
to	O
fully	O
utilizes	O
computation	O
parallelism	O
,	O
we	O
also	O
adopt	O
PVANET2x	B-Method
that	O
doubles	O
the	O
channels	O
of	O
the	O
original	O
PVANET	B-Method
,	O
exploiting	O
more	O
computation	O
parallelism	O
while	O
running	O
slightly	O
slower	O
than	O
PVANET	B-Method
.	O
	
This	O
is	O
detailed	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
.	O
	
The	O
receptive	O
field	O
of	O
the	O
output	O
of	O
the	O
last	O
convolution	B-Method
layer	I-Method
is	O
809	O
,	O
which	O
is	O
much	O
larger	O
than	O
VGG16	B-Method
.	O
	
The	O
models	O
are	O
pre	O
-	O
trained	O
on	O
the	O
ImageNet	B-Material
dataset	I-Material
.	O
	
subsection	O
:	O
Qualitative	O
Results	O
	
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
a	O
)	O
(	O
c	O
)	O
(	O
b	O
)	O
(	O
d	O
)	O
Fig	O
.	O
	
[	O
reference	O
]	O
depicts	O
several	O
detection	O
examples	O
by	O
the	O
proposed	O
algorithm	O
.	O
	
It	O
is	O
able	O
to	O
handle	O
various	O
challenging	O
scenarios	O
,	O
such	O
as	O
non	O
-	O
uniform	O
illumination	O
,	O
low	O
resolution	O
,	O
varying	O
orientation	O
and	O
perspective	O
distortion	O
.	O
	
Moreover	O
,	O
due	O
to	O
the	O
voting	B-Method
mechanism	I-Method
in	O
the	O
NMS	B-Method
procedure	I-Method
,	O
the	O
proposed	O
method	O
shows	O
a	O
high	O
level	O
of	O
stability	B-Metric
on	O
videos	O
with	O
various	O
forms	O
of	O
text	O
instances	O
.	O
	
The	O
intermediate	O
results	O
of	O
the	O
proposed	O
method	O
are	O
illustrated	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
As	O
can	O
be	O
seen	O
,	O
the	O
trained	O
model	O
produces	O
highly	O
accurate	O
geometry	B-Metric
maps	I-Metric
and	O
score	B-Metric
map	I-Metric
,	O
in	O
which	O
detections	O
of	O
text	O
instances	O
in	O
varying	O
orientations	O
are	O
easily	O
formed	O
.	O
	
subsection	O
:	O
Quantitative	O
Results	O
	
As	O
shown	O
in	O
Tab	O
.	O
	
[	O
reference	O
]	O
and	O
Tab	O
.	O
	
[	O
reference	O
]	O
	
,	O
our	O
approach	O
outperforms	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
by	O
a	O
large	O
margin	O
on	O
ICDAR	B-Material
2015	I-Material
and	O
COCO	B-Material
-	I-Material
Text	I-Material
.	O
	
In	O
ICDAR	B-Material
2015	I-Material
Challenge	O
4	O
,	O
when	O
images	O
are	O
fed	O
at	O
their	O
original	O
scale	O
,	O
the	O
proposed	O
method	O
achieves	O
an	O
F	B-Metric
-	I-Metric
score	I-Metric
of	O
0.7820	O
.	O
	
When	O
tested	O
at	O
multiple	O
scales	O
using	O
the	O
same	O
network	O
,	O
our	O
method	O
reaches	O
0.8072	O
in	O
F	B-Metric
-	I-Metric
score	I-Metric
,	O
which	O
is	O
nearly	O
0.16	O
higher	O
than	O
the	O
best	O
method	O
in	O
terms	O
of	O
absolute	B-Metric
value	I-Metric
(	O
0.8072	O
vs.	O
0.6477	O
)	O
.	O
	
Comparing	O
the	O
results	O
using	O
VGG16	B-Method
network	I-Method
,	O
the	O
proposed	O
method	O
also	O
outperforms	O
best	O
previous	O
work	O
by	O
0.0924	O
when	O
using	O
QUAD	O
output	O
,	O
0.116	O
when	O
using	O
RBOX	O
output	O
.	O
	
Meanwhile	O
these	O
networks	O
are	O
quite	O
efficient	O
,	O
as	O
will	O
be	O
shown	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
.	O
	
In	O
COCO	B-Material
-	I-Material
Text	I-Material
,	O
all	O
of	O
the	O
three	O
settings	O
of	O
the	O
proposed	O
algorithm	O
result	O
in	O
higher	O
accuracy	B-Metric
than	O
previous	O
top	O
performer	O
.	O
	
Specifically	O
,	O
the	O
improvement	O
over	O
in	O
F	B-Metric
-	I-Metric
score	I-Metric
is	O
0.0614	O
while	O
that	O
in	O
recall	B-Metric
is	O
0.053	O
,	O
which	O
confirm	O
the	O
advantage	O
of	O
the	O
proposed	O
algorithm	O
,	O
considering	O
that	O
COCO	B-Material
-	I-Material
Text	I-Material
is	O
the	O
largest	O
and	O
most	O
challenging	O
benchmark	O
to	O
date	O
.	O
	
Note	O
that	O
we	O
also	O
included	O
the	O
results	O
from	O
as	O
reference	O
,	O
but	O
these	O
results	O
are	O
actually	O
not	O
valid	O
baselines	O
,	O
since	O
the	O
methods	O
(	O
A	O
,	O
B	O
and	O
C	O
)	O
are	O
used	O
in	O
data	B-Task
annotation	I-Task
.	O
	
The	O
improvements	O
of	O
the	O
proposed	O
algorithm	O
over	O
previous	O
methods	O
prove	O
that	O
a	O
simple	O
text	B-Method
detection	I-Method
pipeline	I-Method
,	O
which	O
directly	O
targets	O
the	O
final	O
goal	O
and	O
eliminating	O
redundant	O
processes	O
,	O
can	O
beat	O
elaborated	O
pipelines	O
,	O
even	O
those	O
integrated	O
with	O
large	B-Method
neural	I-Method
network	I-Method
models	I-Method
.	O
	
As	O
shown	O
in	O
Tab	O
.	O
	
[	O
reference	O
]	O
,	O
on	O
MSRA	B-Material
-	I-Material
TD500	I-Material
	
all	O
of	O
the	O
three	O
settings	O
of	O
our	O
method	O
achieve	O
excellent	O
results	O
.	O
	
The	O
F	B-Metric
-	I-Metric
score	I-Metric
of	O
the	O
best	O
performer	O
(	O
Ours	B-Method
+	I-Method
PVANET2x	I-Method
)	O
is	O
slightly	O
higher	O
than	O
that	O
of	O
.	O
	
Compared	O
with	O
the	O
method	O
of	O
Zhang	B-Method
,	O
the	O
previous	O
published	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
system	O
,	O
the	O
best	O
performer	O
(	O
Ours	B-Method
+	I-Method
PVANET2x	I-Method
)	O
obtains	O
an	O
improvement	O
of	O
0.0208	O
in	O
F	B-Metric
-	I-Metric
score	I-Metric
and	O
0.0428	O
in	O
precision	B-Metric
.	O
	
Note	O
that	O
on	O
MSRA	B-Material
-	I-Material
TD500	I-Material
our	O
algorithm	O
equipped	O
with	O
VGG16	B-Method
performs	O
much	O
poorer	O
than	O
that	O
with	O
PVANET	B-Method
and	O
PVANET2x	B-Method
(	O
0.7023	O
vs.	O
0.7445	O
and	O
0.7608	O
)	O
,	O
the	O
main	O
reason	O
is	O
that	O
the	O
effective	O
receptive	O
field	O
of	O
VGG16	B-Method
is	O
smaller	O
than	O
that	O
of	O
PVANET	B-Method
and	O
PVANET2x	B-Method
,	O
while	O
the	O
evaluation	B-Metric
protocol	I-Metric
of	O
MSRA	B-Material
-	I-Material
TD500	I-Material
requires	O
text	B-Method
detection	I-Method
algorithms	I-Method
output	O
line	O
level	O
instead	O
of	O
word	O
level	O
predictions	O
.	O
	
In	O
addition	O
,	O
we	O
also	O
evaluated	O
Ours	O
+	O
PVANET2x	O
on	O
the	O
ICDAR	B-Material
2013	I-Material
benchmark	I-Material
.	O
	
It	O
achieves	O
0.8267	O
,	O
0.9264	O
and	O
0.8737	O
in	O
recall	B-Metric
,	O
precision	B-Metric
and	O
F	B-Metric
-	I-Metric
score	I-Metric
,	O
which	O
are	O
comparable	O
with	O
the	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
method	O
,	O
which	O
obtains	O
0.8298	O
,	O
0.9298	O
and	O
0.8769	O
in	O
recall	B-Metric
,	O
precision	B-Metric
and	O
F	B-Metric
-	I-Metric
score	I-Metric
,	O
respectively	O
.	O
	
subsection	O
:	O
Speed	B-Metric
Comparison	I-Metric
	
The	O
overall	O
speed	B-Metric
comparison	I-Metric
is	O
demonstrated	O
in	O
Tab	O
.	O
	
[	O
reference	O
]	O
.	O
	
The	O
numbers	O
we	O
reported	O
are	O
averages	O
from	O
running	O
through	O
500	O
test	O
images	O
from	O
the	O
ICDAR	B-Material
2015	I-Material
dataset	O
at	O
their	O
original	O
resolution	O
(	O
1280x720	O
)	O
using	O
our	O
best	O
performing	O
networks	O
.	O
	
These	O
experiments	O
were	O
conducted	O
on	O
a	O
server	O
using	O
a	O
single	O
NVIDIA	B-Method
Titan	I-Method
X	I-Method
graphic	I-Method
card	I-Method
with	O
Maxwell	B-Method
architecture	I-Method
and	O
an	O
Intel	O
E5	O
-	O
2670	O
v3	O
@	O
2.30GHz	O
CPU	O
.	O
	
For	O
the	O
proposed	O
method	O
,	O
the	O
post	B-Task
-	I-Task
processing	I-Task
includes	O
thresholding	B-Method
and	O
NMS	B-Method
,	O
while	O
others	O
should	O
refer	O
to	O
their	O
original	O
paper	O
.	O
	
While	O
the	O
proposed	O
method	O
significantly	O
outperforms	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
,	O
the	O
computation	B-Metric
cost	I-Metric
is	O
kept	O
very	O
low	O
,	O
attributing	O
to	O
the	O
simple	O
and	O
efficient	O
pipeline	B-Method
.	O
	
As	O
can	O
be	O
observed	O
from	O
Tab	O
.	O
	
[	O
reference	O
]	O
,	O
the	O
fastest	O
setting	O
of	O
our	O
method	O
runs	O
at	O
a	O
speed	O
of	O
16.8	O
FPS	B-Metric
,	O
while	O
slowest	O
setting	O
runs	O
at	O
6.52	O
FPS	B-Metric
.	O
	
Even	O
the	O
best	O
performing	O
model	O
Ours	B-Method
+	I-Method
PVANET2x	I-Method
runs	O
at	O
a	O
speed	O
of	O
13.2	O
FPS	B-Metric
.	O
	
This	O
confirm	O
that	O
our	O
method	O
is	O
among	O
the	O
most	O
efficient	O
text	B-Method
detectors	I-Method
that	O
achieve	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
benchmarks	O
.	O
	
subsection	O
:	O
Limitations	O
	
The	O
maximal	O
size	O
of	O
text	O
instances	O
the	O
detector	B-Method
can	O
handle	O
is	O
proportional	O
to	O
the	O
receptive	O
field	O
of	O
the	O
network	O
.	O
	
This	O
limits	O
the	O
capability	O
of	O
the	O
network	O
to	O
predict	O
even	O
longer	O
text	O
regions	O
like	O
text	O
lines	O
running	O
across	O
the	O
images	O
.	O
	
Also	O
,	O
the	O
algorithm	O
might	O
miss	O
or	O
give	O
imprecise	O
predictions	O
for	O
vertical	O
text	O
instances	O
as	O
they	O
take	O
only	O
a	O
small	O
portion	O
of	O
text	O
regions	O
in	O
the	O
ICDAR	B-Material
2015	I-Material
training	O
set	O
.	O
	
section	O
:	O
Conclusion	O
and	O
Future	O
Work	O
	
We	O
have	O
presented	O
a	O
scene	B-Method
text	I-Method
detector	I-Method
that	O
directly	O
produces	O
word	B-Task
or	I-Task
line	I-Task
level	I-Task
predictions	I-Task
from	O
full	O
images	O
with	O
a	O
single	O
neural	B-Method
network	I-Method
.	O
	
By	O
incorporating	O
proper	O
loss	O
functions	O
,	O
the	O
detector	O
can	O
predict	O
either	O
rotated	O
rectangles	O
or	O
quadrangles	O
for	O
text	O
regions	O
,	O
depending	O
on	O
specific	O
applications	O
.	O
	
The	O
experiments	O
on	O
standard	O
benchmarks	O
confirm	O
that	O
the	O
proposed	O
algorithm	O
substantially	O
outperforms	O
previous	O
methods	O
in	O
terms	O
of	O
both	O
accuracy	B-Metric
and	O
efficiency	B-Metric
.	O
	
Possible	O
directions	O
for	O
future	O
research	O
include	O
:	O
(	O
1	O
)	O
adapting	O
the	O
geometry	B-Method
formulation	I-Method
to	O
allow	O
direct	B-Task
detection	I-Task
of	I-Task
curved	I-Task
text	I-Task
;	O
(	O
2	O
)	O
integrating	O
the	O
detector	O
with	O
a	O
text	B-Method
recognizer	I-Method
;	O
(	O
3	O
)	O
extending	O
the	O
idea	O
to	O
general	O
object	B-Task
detection	I-Task
.	O
	
bibliography	O
:	O
References	O