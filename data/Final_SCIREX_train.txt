Full	B-Method
-	I-Method
Resolution	I-Method
Residual	I-Method
Networks	I-Method
for	O
Semantic	B-Task
Segmentation	I-Task
in	O
Street	O
Scenes	O
	
section	O
:	O
Abstract	O
	
Semantic	B-Task
image	I-Task
segmentation	I-Task
is	O
an	O
essential	O
component	O
of	O
modern	O
autonomous	B-Task
driving	I-Task
systems	I-Task
,	O
as	O
an	O
accurate	B-Task
understanding	I-Task
of	I-Task
the	I-Task
surrounding	I-Task
scene	I-Task
is	O
crucial	O
to	O
navigation	B-Task
and	I-Task
action	I-Task
planning	I-Task
.	O
	
Current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
approaches	O
in	O
semantic	B-Task
image	I-Task
segmentation	I-Task
rely	O
on	O
pretrained	B-Method
networks	I-Method
that	O
were	O
initially	O
developed	O
for	O
classifying	B-Task
images	I-Task
as	O
a	O
whole	O
.	O
	
While	O
these	O
networks	O
exhibit	O
outstanding	O
recognition	B-Metric
performance	I-Metric
(	O
i.e.	O
,	O
what	O
is	O
visible	O
?	O
)	O
,	O
they	O
lack	O
localization	B-Metric
accuracy	O
(	O
i.e.	O
,	O
where	O
precisely	O
is	O
something	O
located	O
?	O
)	O
.	O
	
Therefore	O
,	O
additional	O
processing	O
steps	O
have	O
to	O
be	O
performed	O
in	O
order	O
to	O
obtain	O
pixel	O
-	O
accurate	O
segmentation	O
masks	O
at	O
the	O
full	O
image	O
resolution	O
.	O
	
To	O
alleviate	O
this	O
problem	O
we	O
propose	O
a	O
novel	O
ResNet	B-Method
-	O
like	O
architecture	O
that	O
exhibits	O
strong	O
localization	B-Metric
and	O
recognition	B-Metric
performance	I-Metric
.	O
	
We	O
combine	O
multi	O
-	O
scale	O
context	O
with	O
pixel	B-Metric
-	I-Metric
level	I-Metric
accuracy	I-Metric
by	O
using	O
two	O
processing	B-Method
streams	I-Method
within	O
our	O
network	O
:	O
One	O
stream	O
carries	O
information	O
at	O
the	O
full	O
image	O
resolution	O
,	O
enabling	O
precise	O
adherence	O
to	O
segment	O
boundaries	O
.	O
	
The	O
other	O
stream	O
undergoes	O
a	O
sequence	O
of	O
pooling	B-Method
operations	O
to	O
obtain	O
robust	O
features	O
for	O
recognition	B-Task
.	O
	
The	O
two	O
streams	O
are	O
coupled	O
at	O
the	O
full	O
image	O
resolution	O
using	O
residuals	O
.	O
	
Without	O
additional	O
processing	O
steps	O
and	O
without	O
pretraining	B-Method
,	O
our	O
approach	O
achieves	O
an	O
intersection	B-Metric
-	I-Metric
over	I-Metric
-	I-Metric
union	I-Metric
score	I-Metric
of	O
71.8	O
%	O
on	O
the	O
Cityscapes	B-Material
dataset	O
.	O
	
section	O
:	O
Introduction	O
	
Recent	O
years	O
have	O
seen	O
an	O
increasing	O
interest	O
in	O
self	B-Task
driving	I-Task
cars	I-Task
and	O
in	O
driver	B-Task
assistance	I-Task
systems	I-Task
.	O
	
A	O
crucial	O
aspect	O
of	O
autonomous	B-Task
driving	I-Task
is	O
to	O
acquire	O
a	O
comprehensive	O
understanding	O
of	O
the	O
surroundings	O
in	O
which	O
a	O
car	O
is	O
moving	O
.	O
	
Semantic	B-Task
image	I-Task
segmentation	I-Task
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
,	O
the	O
task	O
of	O
assigning	O
a	O
set	O
of	O
predefined	O
class	O
labels	O
to	O
image	O
pixels	O
,	O
is	O
an	O
important	O
tool	O
for	O
modeling	O
the	O
complex	O
relationships	O
of	O
the	O
semantic	O
entities	O
usually	O
found	O
in	O
street	O
scenes	O
,	O
such	O
as	O
cars	O
,	O
pedestrians	O
,	O
road	O
,	O
or	O
sidewalks	O
.	O
	
In	O
automotive	B-Task
scenarios	I-Task
it	O
is	O
used	O
in	O
various	O
ways	O
,	O
e.g.	O
as	O
a	O
pre	B-Task
-	I-Task
processing	I-Task
step	I-Task
to	O
discard	O
image	O
regions	O
that	O
are	O
unlikely	O
to	O
contain	O
objects	O
of	O
interest	O
[	O
reference	O
][	O
reference	O
]	O
,	O
to	O
improve	O
object	B-Task
detection	I-Task
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
	
Example	O
output	O
and	O
the	O
abstract	O
structure	O
of	O
our	O
fullresolution	B-Method
residual	I-Method
network	I-Method
.	O
	
The	O
network	O
has	O
two	O
processing	O
streams	O
.	O
	
The	O
residual	O
stream	O
(	O
blue	O
)	O
stays	O
at	O
the	O
full	O
image	O
resolution	O
,	O
the	O
pooling	B-Method
stream	O
(	O
red	O
)	O
undergoes	O
a	O
sequence	O
of	O
pooling	B-Method
and	O
unpooling	B-Method
operations	I-Method
.	O
	
The	O
two	O
processing	O
streams	O
are	O
coupled	O
using	O
full	B-Method
-	I-Method
resolution	I-Method
residual	I-Method
units	I-Method
[	O
reference	O
]	O
or	O
in	O
combination	O
with	O
3D	O
scene	O
geometry	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
Many	O
of	O
those	O
applications	O
require	O
precise	O
region	O
boundaries	O
	
[	O
reference	O
]	O
.	O
	
In	O
this	O
work	O
,	O
we	O
therefore	O
pursue	O
the	O
goal	O
of	O
achieving	O
high	O
-	O
quality	O
semantic	B-Task
segmentation	I-Task
with	O
precise	O
boundary	O
adherence	O
.	O
	
Current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
approaches	O
for	O
image	B-Task
segmentation	I-Task
all	O
employ	O
some	O
form	O
of	O
fully	B-Method
convolutional	I-Method
network	I-Method
(	O
FCNs	B-Method
)	O
	
[	O
reference	O
]	O
that	O
takes	O
the	O
image	O
as	O
input	O
and	O
outputs	O
a	O
probability	O
map	O
for	O
each	O
class	O
.	O
	
Many	O
papers	O
rely	O
on	O
network	B-Method
architectures	I-Method
that	O
have	O
already	O
been	O
proven	O
successful	O
for	O
image	B-Task
classification	I-Task
such	O
as	O
variants	O
of	O
the	O
ResNet	B-Method
[	O
reference	O
]	O
or	O
the	O
VGG	B-Method
architecture	I-Method
[	O
reference	O
]	O
.	O
Starting	O
from	O
pre	O
-	O
trained	O
nets	O
,	O
where	O
a	O
large	O
number	O
of	O
weights	O
for	O
the	O
target	O
task	O
can	O
be	O
pre	O
-	O
set	O
by	O
an	O
auxiliary	B-Task
classification	I-Task
task	I-Task
,	O
reduces	O
training	B-Metric
time	I-Metric
and	O
often	O
yields	O
superior	O
performance	O
compared	O
to	O
training	O
a	O
network	O
from	O
scratch	O
using	O
the	O
(	O
possibly	O
limited	O
amount	O
of	O
)	O
data	O
of	O
the	O
target	O
application	O
.	O
	
However	O
,	O
a	O
main	O
limitation	O
of	O
using	O
such	O
pre	B-Method
-	I-Method
trained	I-Method
networks	I-Method
is	O
that	O
they	O
severely	O
restrict	O
the	O
design	O
space	O
of	O
novel	O
approaches	O
,	O
since	O
new	O
network	O
elements	O
such	O
as	O
batch	B-Method
normalization	I-Method
[	O
reference	O
]	O
or	O
new	O
activation	O
functions	O
often	O
can	O
not	O
be	O
added	O
into	O
an	O
existing	O
architecture	O
.	O
	
When	O
performing	O
semantic	B-Task
segmentation	I-Task
using	O
FCNs	B-Method
,	O
a	O
common	O
strategy	O
is	O
to	O
successively	O
reduce	O
the	O
spatial	O
size	O
of	O
the	O
feature	O
maps	O
using	O
pooling	B-Method
operations	O
or	O
strided	B-Method
convolutions	I-Method
.	O
	
This	O
is	O
done	O
for	O
two	O
reasons	O
:	O
First	O
,	O
it	O
significantly	O
increases	O
the	O
size	O
of	O
the	O
receptive	O
field	O
and	O
second	O
,	O
it	O
makes	O
the	O
network	O
robust	O
against	O
small	O
translations	O
in	O
the	O
image	O
.	O
	
While	O
pooling	B-Method
operations	O
are	O
highly	O
desirable	O
for	O
recognizing	B-Task
objects	I-Task
in	I-Task
images	I-Task
,	O
they	O
significantly	O
deteriorate	O
localization	B-Metric
performance	O
of	O
the	O
networks	O
when	O
applied	O
to	O
semantic	B-Task
image	I-Task
segmentation	I-Task
.	O
	
Several	O
approaches	O
exist	O
to	O
overcome	O
this	O
problem	O
and	O
obtain	O
pixel	B-Task
-	I-Task
accurate	I-Task
segmentations	I-Task
.	O
	
Noh	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
learn	O
a	O
mirrored	B-Method
VGG	I-Method
network	I-Method
as	O
a	O
decoder	B-Method
,	O
Yu	O
and	O
Koltun	O
[	O
reference	O
]	O
introduce	O
dilated	B-Method
convolutions	I-Method
to	O
reduce	O
the	O
pooling	B-Method
factor	O
of	O
their	O
pre	B-Method
-	I-Method
trained	I-Method
network	I-Method
.	O
	
Ghiasi	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
use	O
multi	O
-	O
scale	O
predictions	O
to	O
successively	O
improve	O
their	O
boundary	O
adherence	O
.	O
	
An	O
alternative	O
approach	O
used	O
by	O
several	O
methods	O
is	O
to	O
apply	O
post	B-Method
-	I-Method
processing	I-Method
steps	I-Method
such	O
as	O
CRF	B-Method
-	I-Method
smoothing	I-Method
[	O
reference	O
]	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
novel	O
network	B-Method
architecture	I-Method
that	O
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
segmentation	B-Task
performance	O
without	O
the	O
need	O
for	O
additional	O
post	B-Task
-	I-Task
processing	I-Task
steps	I-Task
and	O
without	O
the	O
limitations	O
imposed	O
by	O
pre	B-Method
-	I-Method
trained	I-Method
architectures	I-Method
.	O
	
Our	O
proposed	O
ResNet	B-Method
-	O
like	O
architecture	O
unites	O
strong	O
recognition	B-Metric
performance	I-Metric
with	O
precise	O
localization	B-Metric
capabilities	O
by	O
combining	O
two	O
distinct	O
processing	B-Method
streams	I-Method
.	O
	
One	O
stream	O
undergoes	O
a	O
sequence	O
of	O
pooling	B-Method
operations	O
and	O
is	O
responsible	O
for	O
understanding	O
large	B-Task
-	I-Task
scale	I-Task
relationships	I-Task
of	I-Task
image	I-Task
elements	I-Task
;	O
the	O
other	O
stream	O
carries	O
feature	O
maps	O
at	O
the	O
full	O
image	O
resolution	O
,	O
resulting	O
in	O
precise	O
boundary	O
adherence	O
.	O
	
This	O
idea	O
is	O
visualized	O
in	O
Figure	O
1	O
,	O
where	O
the	O
two	O
processing	O
streams	O
are	O
shown	O
in	O
blue	O
and	O
red	O
.	O
	
The	O
blue	O
residual	O
lane	O
reflects	O
the	O
high	O
-	O
resolution	O
stream	O
.	O
	
It	O
can	O
be	O
combined	O
with	O
classical	B-Method
residual	I-Method
units	I-Method
(	O
left	O
and	O
right	O
)	O
,	O
as	O
well	O
as	O
with	O
our	O
new	O
full	B-Method
-	I-Method
resolution	I-Method
residual	I-Method
units	I-Method
(	O
FRRU	B-Method
)	O
.	O
	
The	O
FRRUs	B-Method
from	O
the	O
red	O
pooling	B-Method
lane	O
act	O
as	O
residual	O
units	O
for	O
the	O
blue	O
stream	O
,	O
but	O
also	O
undergo	O
pooling	B-Method
operations	O
and	O
carry	O
high	O
-	O
level	O
information	O
through	O
the	O
network	O
.	O
	
This	O
results	O
in	O
a	O
network	O
that	O
successively	O
combines	O
and	O
computes	O
features	O
at	O
two	O
resolutions	O
.	O
	
This	O
paper	O
makes	O
the	O
following	O
contributions	O
:	O
(	O
i	O
)	O
	
We	O
propose	O
a	O
novel	O
network	B-Method
architecture	I-Method
geared	O
towards	O
precise	O
semantic	B-Task
segmentation	I-Task
in	O
street	B-Task
scenes	I-Task
which	O
is	O
not	O
limited	O
to	O
pre	O
-	O
trained	B-Method
architectures	I-Method
and	O
achieves	O
state	O
-	O
ofthe	O
-	O
art	O
results	O
.	O
	
(	O
ii	O
)	O
	
We	O
propose	O
to	O
use	O
two	O
processing	B-Method
streams	I-Method
to	O
realize	O
strong	O
recognition	B-Task
and	O
strong	O
localization	B-Metric
performance	O
:	O
One	O
stream	O
undergoes	O
a	O
sequence	O
of	O
pooling	B-Method
operations	O
while	O
the	O
other	O
stream	O
stays	O
at	O
the	O
full	O
image	O
resolution	O
.	O
	
(	O
iii	O
)	O
	
In	O
order	O
to	O
foster	O
further	O
research	O
in	O
this	O
area	O
,	O
we	O
publish	O
our	O
code	O
and	O
the	O
trained	O
models	O
in	O
Theano	O
/	O
Lasagne	O
[	O
reference	O
][	O
reference	O
]	O
1	O
.	O
	
1	O
https:	O
//	O
github.com	O
/	O
TobyPDE	O
/	O
FRRN	O
	
section	O
:	O
Related	O
Work	O
	
The	O
dramatic	O
performance	O
improvements	O
from	O
using	O
CNNs	B-Method
for	O
semantic	B-Task
segmentation	I-Task
have	O
brought	O
about	O
an	O
increasing	O
demand	O
for	O
such	O
algorithms	O
in	O
the	O
context	O
of	O
autonomous	B-Task
driving	I-Task
scenarios	I-Task
.	O
	
As	O
a	O
large	O
amount	O
of	O
annotated	O
data	O
is	O
crucial	O
in	O
order	O
to	O
train	O
such	O
deep	B-Method
networks	I-Method
,	O
multiple	O
new	O
datasets	O
have	O
been	O
released	O
to	O
encourage	O
further	O
research	O
in	O
this	O
area	O
,	O
including	O
Synthia	B-Material
[	O
reference	O
]	O
,	O
Virtual	B-Material
KITTI	I-Material
[	O
reference	O
]	O
,	O
and	O
Cityscapes	B-Material
[	O
reference	O
]	O
.	O
	
In	O
this	O
work	O
,	O
we	O
focus	O
on	O
Cityscapes	B-Material
,	O
a	O
recent	O
large	O
-	O
scale	O
dataset	O
consisting	O
of	O
real	O
-	O
world	O
imagery	O
with	O
well	O
-	O
curated	O
annotations	O
.	O
	
Given	O
their	O
success	O
,	O
we	O
will	O
constrain	O
our	O
literature	O
review	O
to	O
deep	B-Method
learning	I-Method
based	I-Method
semantic	I-Method
segmentation	I-Method
approaches	I-Method
and	O
deep	B-Method
learning	I-Method
network	I-Method
architectures	I-Method
.	O
	
Semantic	B-Task
Segmentation	I-Task
Approaches	O
.	O
	
Over	O
the	O
last	O
years	O
,	O
the	O
most	O
successful	O
semantic	B-Task
segmentation	I-Task
approaches	O
have	O
been	O
based	O
on	O
convolutional	B-Method
neural	I-Method
networks	I-Method
(	O
CNNs	B-Method
)	O
.	O
	
Early	O
approaches	O
constrained	O
their	O
output	O
to	O
a	O
bottom	B-Task
-	I-Task
up	I-Task
segmentation	I-Task
followed	O
by	O
a	O
CNN	B-Method
based	I-Method
region	I-Method
classification	I-Method
[	O
reference	O
]	O
.	O
Rather	O
than	O
classifying	O
entire	O
regions	O
in	O
the	O
first	O
place	O
,	O
the	O
approach	O
by	O
Farabet	O
et	O
al	O
.	O
performs	O
pixel	B-Method
-	I-Method
wise	I-Method
classification	I-Method
using	O
CNN	B-Method
features	I-Method
originating	O
from	O
multiple	O
scales	O
,	O
followed	O
by	O
aggregation	B-Method
of	O
these	O
noisy	O
pixel	O
predictions	O
over	O
superpixel	O
regions	O
[	O
reference	O
]	O
.	O
	
The	O
introduction	O
of	O
so	O
-	O
called	O
fully	B-Method
convolutional	I-Method
networks	I-Method
(	O
FCNs	B-Method
)	O
for	O
semantic	B-Task
image	I-Task
segmentation	I-Task
by	O
Long	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
opened	O
a	O
wide	O
range	O
of	O
semantic	B-Task
segmentation	I-Task
research	O
using	O
end	O
-	O
to	O
-	O
end	O
training	O
[	O
reference	O
]	O
.	O
Long	O
et	O
al	O
.	O
	
further	O
reformulated	O
the	O
popular	O
VGG	B-Method
architecture	I-Method
[	O
reference	O
]	O
as	O
a	O
fully	B-Method
convolutional	I-Method
network	I-Method
(	O
FCN	B-Method
)	O
,	O
enabling	O
the	O
use	O
of	O
pretrained	B-Method
models	I-Method
for	O
this	O
architecture	O
.	O
	
To	O
improve	O
segmentation	B-Task
performance	O
at	O
object	O
boundaries	O
,	O
skip	O
connections	O
were	O
added	O
which	O
allow	O
information	O
to	O
propagate	O
directly	O
from	O
early	O
,	O
high	O
-	O
resolution	O
layers	O
to	O
deeper	O
layers	O
.	O
	
Pooling	B-Method
layers	I-Method
in	O
FCNs	B-Method
fulfill	O
a	O
crucial	O
role	O
in	O
order	O
to	O
increase	O
the	O
receptive	O
field	O
size	O
of	O
later	O
units	O
and	O
with	O
it	O
the	O
classification	B-Task
performance	O
.	O
	
However	O
,	O
they	O
have	O
the	O
downside	O
that	O
the	O
resulting	O
network	O
outputs	O
are	O
at	O
a	O
lower	O
resolution	O
.	O
	
To	O
overcome	O
this	O
,	O
various	O
strategies	O
have	O
been	O
proposed	O
.	O
	
Some	O
approaches	O
extract	O
features	O
from	O
intermediate	O
layers	O
via	O
some	O
sort	O
of	O
skip	O
connections	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
Noh	O
et	O
al	O
.	O
propose	O
an	O
encoder	B-Method
/	I-Method
decoder	I-Method
network	I-Method
[	O
reference	O
]	O
.	O
	
The	O
encoder	B-Method
computes	O
low	B-Method
-	I-Method
dimensional	I-Method
feature	I-Method
representations	I-Method
via	O
a	O
sequence	O
of	O
pooling	B-Method
and	O
convolution	B-Method
operations	I-Method
.	O
	
The	O
decoder	B-Method
,	O
which	O
is	O
stacked	O
on	O
top	O
of	O
the	O
encoder	B-Method
,	O
then	O
learns	O
an	O
upscaling	O
of	O
these	O
low	O
-	O
dimensional	O
features	O
via	O
subsequent	O
unpooling	B-Method
and	O
deconvolution	B-Method
operations	I-Method
[	O
reference	O
]	O
.	O
Similarly	O
,	O
Badrinarayanan	O
et	O
al	O
.	O
	
[	O
reference	O
][	O
reference	O
]	O
use	O
convolutions	B-Method
instead	O
of	O
deconvolutions	B-Method
in	O
the	O
decoder	B-Method
network	I-Method
.	O
	
In	O
contrast	O
,	O
our	O
approach	O
preserves	O
high	O
-	O
resolution	O
information	O
throughout	O
the	O
entire	O
network	O
by	O
keeping	O
a	O
separate	O
high	B-Method
-	I-Method
resolution	I-Method
processing	I-Method
stream	I-Method
.	O
	
Many	O
approaches	O
apply	O
smoothing	B-Method
operations	I-Method
to	O
the	O
output	O
of	O
a	O
CNN	B-Method
in	O
order	O
to	O
obtain	O
more	O
consistent	O
predictions	O
.	O
	
Most	O
commonly	O
,	O
conditional	B-Method
random	I-Method
fields	I-Method
(	O
CRFs	B-Method
)	O
[	O
reference	O
]	O
are	O
applied	O
on	O
the	O
network	O
output	O
	
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
More	O
recently	O
,	O
some	O
papers	O
approximate	O
the	O
mean	B-Method
-	I-Method
field	I-Method
inference	I-Method
of	I-Method
CRFs	I-Method
using	O
specialized	B-Method
network	I-Method
architectures	I-Method
	
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
Other	O
approaches	O
to	O
smoothing	O
the	O
network	B-Task
predictions	I-Task
include	O
domain	B-Method
transform	I-Method
[	O
reference	O
][	O
reference	O
]	O
and	O
superpixel	B-Method
-	I-Method
based	I-Method
smoothing	I-Method
[	O
reference	O
][	O
reference	O
]	O
.	O
Our	O
approach	O
is	O
able	O
to	O
swiftly	O
combine	O
high	O
-	O
and	O
low	O
-	O
resolution	O
information	O
,	O
resulting	O
in	O
already	O
smooth	O
output	O
predictions	O
.	O
	
Experiments	O
with	O
additional	O
CRF	B-Method
smoothing	I-Method
therefore	O
did	O
not	O
result	O
in	O
significant	O
performance	O
improvements	O
.	O
	
Network	B-Method
architectures	I-Method
.	O
	
Since	O
the	O
success	O
of	O
the	O
AlexNet	B-Method
architecture	I-Method
[	O
reference	O
]	O
in	O
the	O
ImageNet	B-Task
Large	I-Task
-	I-Task
Scale	I-Task
Visual	I-Task
Classification	I-Task
Challenge	I-Task
(	O
ILSVRC	B-Task
)	O
[	O
reference	O
]	O
,	O
the	O
vision	B-Task
community	I-Task
has	O
seen	O
several	O
milestones	O
with	O
respect	O
to	O
CNN	B-Method
architectures	I-Method
.	O
	
The	O
network	O
depth	O
has	O
been	O
constantly	O
increased	O
,	O
first	O
with	O
the	O
popular	O
VGG	B-Method
net	I-Method
[	O
reference	O
]	O
,	O
then	O
by	O
using	O
batch	B-Method
normalization	I-Method
with	O
GoogleNet	B-Method
	
[	O
reference	O
]	O
.	O
Lately	O
,	O
many	O
computer	B-Task
vision	I-Task
applications	I-Task
have	O
adopted	O
the	O
ResNet	B-Method
architecture	O
[	O
reference	O
]	O
,	O
which	O
often	O
leads	O
to	O
signification	O
performance	O
boosts	O
compared	O
to	O
earlier	O
network	B-Method
architectures	I-Method
.	O
	
All	O
of	O
these	O
developments	O
show	O
how	O
important	O
a	O
proper	O
architecture	O
is	O
.	O
	
However	O
,	O
so	O
far	O
most	O
of	O
these	O
networks	O
have	O
been	O
specifically	O
tailored	O
towards	O
the	O
task	O
of	O
classification	B-Task
,	O
in	O
many	O
cases	O
including	O
a	O
pre	B-Method
-	I-Method
training	I-Method
step	I-Method
on	O
ILSVRC	B-Task
.	O
	
As	O
a	O
result	O
,	O
some	O
of	O
their	O
design	O
choices	O
may	O
contribute	O
to	O
a	O
suboptimal	O
performance	O
when	O
performing	O
pixel	B-Task
-	I-Task
to	I-Task
-	I-Task
pixel	I-Task
tasks	I-Task
such	O
as	O
semantic	B-Task
segmentation	I-Task
.	O
	
In	O
contrast	O
,	O
our	O
proposed	O
architecture	O
has	O
been	O
specifically	O
designed	O
for	O
segmentation	B-Task
tasks	I-Task
and	O
reaches	O
competitive	O
performance	O
on	O
the	O
Cityscapes	B-Material
dataset	O
without	O
requiring	O
ILSVRC	B-Method
pre	I-Method
-	I-Method
training	I-Method
.	O
	
section	O
:	O
Network	B-Method
Architectures	I-Method
for	O
Segmentation	B-Task
	
Feed	B-Method
-	I-Method
Forward	I-Method
Networks	I-Method
.	O
	
Until	O
recently	O
,	O
the	O
majority	O
of	O
feedforward	B-Method
networks	I-Method
,	O
such	O
as	O
the	O
VGG	B-Method
-	I-Method
variants	I-Method
[	O
reference	O
]	O
,	O
were	O
composed	O
of	O
a	O
linear	B-Method
sequence	I-Method
of	I-Method
layers	I-Method
.	O
	
Each	O
layer	O
in	O
such	O
a	O
network	O
computes	O
a	O
function	O
F	O
and	O
the	O
output	O
x	O
n	O
of	O
the	O
n	O
-	O
th	O
layer	O
is	O
computed	O
as	O
	
where	O
W	O
n	O
are	O
the	O
parameters	O
of	O
the	O
layer	O
(	O
see	O
2a	O
)	O
.	O
	
We	O
refer	O
to	O
this	O
class	O
of	O
network	B-Method
architectures	I-Method
as	O
traditional	O
feedforward	B-Method
networks	I-Method
.	O
	
Residual	B-Method
Networks	I-Method
(	O
ResNets	B-Method
)	O
.	O
	
He	O
et	O
al	O
.	O
observed	O
that	O
deepening	O
traditional	O
feedforward	B-Method
networks	I-Method
often	O
results	O
in	O
an	O
increased	O
training	B-Metric
loss	I-Metric
[	O
	
reference	O
]	O
.	O
In	O
theory	O
,	O
however	O
,	O
the	O
training	B-Metric
loss	I-Metric
of	O
a	O
shallow	B-Method
network	I-Method
should	O
be	O
an	O
upper	O
bound	O
on	O
the	O
training	B-Metric
loss	I-Metric
of	O
a	O
corresponding	O
deep	B-Method
network	I-Method
.	O
	
This	O
is	O
due	O
to	O
the	O
fact	O
that	O
increasing	O
the	O
depth	O
by	O
adding	O
layers	O
strictly	O
increases	O
the	O
expressive	O
power	O
of	O
the	O
model	O
.	O
	
A	O
deep	B-Method
network	I-Method
can	O
express	O
all	O
functions	O
that	O
the	O
original	O
shallow	B-Method
network	I-Method
can	O
express	O
by	O
using	O
identity	O
mappings	O
for	O
the	O
added	O
layers	O
.	O
	
Hence	O
a	O
deep	B-Method
network	I-Method
should	O
perform	O
at	O
least	O
as	O
well	O
as	O
the	O
shallower	B-Method
model	I-Method
on	O
the	O
training	O
data	O
.	O
	
The	O
violation	O
of	O
this	O
principle	O
implied	O
that	O
current	O
training	B-Method
algorithms	I-Method
have	O
difficulties	O
optimizing	O
very	O
deep	O
traditional	O
feedforward	B-Method
networks	I-Method
.	O
	
He	O
et	O
al	O
.	O
proposed	O
residual	B-Method
networks	I-Method
(	O
ResNets	B-Method
)	O
that	O
exhibit	O
significantly	O
improved	O
training	B-Metric
characteristics	I-Metric
,	O
allowing	O
network	O
depths	O
that	O
were	O
previously	O
unattainable	O
.	O
	
A	O
ResNet	B-Method
is	O
composed	O
of	O
a	O
sequence	O
of	O
residual	B-Method
units	I-Method
(	O
RUs	O
)	O
.	O
	
As	O
depicted	O
in	O
Figure	O
2b	O
,	O
the	O
output	O
x	O
n	O
of	O
the	O
n	O
-	O
th	O
RU	O
in	O
a	O
ResNet	B-Method
is	O
computed	O
as	O
	
where	O
F	O
(	O
x	O
n−1	O
;	O
W	O
n	O
)	O
is	O
the	O
residual	O
,	O
which	O
is	O
parametrized	O
by	O
W	O
n	O
.	O
	
Thus	O
,	O
instead	O
of	O
computing	O
the	O
output	O
x	O
n	O
directly	O
,	O
F	O
only	O
computes	O
a	O
residual	O
that	O
is	O
added	O
to	O
the	O
input	O
x	O
n−1	O
.	O
	
One	O
commonly	O
refers	O
to	O
this	O
design	O
as	O
skip	O
connection	O
,	O
because	O
there	O
is	O
a	O
connection	O
from	O
the	O
input	O
x	O
n−1	O
to	O
the	O
output	O
x	O
n	O
that	O
skips	O
the	O
actual	O
computation	O
	
F.	O
It	O
has	O
been	O
empirically	O
observed	O
that	O
ResNets	B-Method
have	O
superior	O
training	B-Metric
properties	I-Metric
over	O
traditional	O
feedforward	B-Method
networks	I-Method
.	O
	
This	O
can	O
be	O
explained	O
by	O
an	O
improved	O
gradient	O
flow	O
within	O
the	O
network	O
.	O
	
In	O
oder	O
to	O
understand	O
this	O
,	O
consider	O
the	O
n	O
-	O
th	O
and	O
m	O
-	O
th	O
residual	O
units	O
in	O
a	O
ResNet	B-Method
where	O
m	O
>	O
n	O
(	O
i.e.	O
,	O
the	O
m	O
-	O
th	O
unit	O
is	O
closer	O
to	O
the	O
output	O
layer	O
of	O
the	O
network	O
)	O
.	O
	
By	O
applying	O
the	O
recursion	O
(	O
2	O
)	O
several	O
times	O
,	O
He	O
et	O
al	O
.	O
showed	O
in	O
[	O
reference	O
]	O
that	O
the	O
output	O
of	O
the	O
m	O
-	O
th	O
residual	O
unit	O
admits	O
a	O
representation	O
of	O
the	O
form	O
	
Furthermore	O
,	O
if	O
l	O
is	O
the	O
loss	O
that	O
is	O
used	O
to	O
train	O
the	O
network	O
,	O
we	O
can	O
use	O
the	O
chain	B-Method
rule	I-Method
of	I-Method
calculus	I-Method
and	O
express	O
the	O
derivative	O
of	O
the	O
loss	O
l	O
with	O
respect	O
to	O
the	O
output	O
x	O
n	O
of	O
the	O
n	O
-	O
th	O
RU	O
as	O
	
Thus	O
,	O
we	O
find	O
	
We	O
see	O
that	O
the	O
weight	O
updates	O
depend	O
on	O
two	O
sources	O
of	O
information	O
,	O
.	O
	
While	O
the	O
amount	O
of	O
information	O
that	O
is	O
contained	O
in	O
the	O
latter	O
may	O
depend	O
crucially	O
on	O
the	O
depth	O
n	O
,	O
the	O
former	O
allows	O
a	O
gradient	B-Method
flow	I-Method
that	O
is	O
independent	O
of	O
the	O
depth	O
.	O
	
Hence	O
,	O
gradients	O
can	O
flow	O
unhindered	O
from	O
the	O
deeper	O
unit	O
to	O
the	O
shallower	O
unit	O
.	O
	
This	O
makes	O
training	O
even	O
extremely	O
deep	B-Task
ResNets	I-Task
possible	O
.	O
	
section	O
:	O
Full	B-Method
-	I-Method
Resolution	I-Method
Residual	I-Method
Networks	I-Method
(	O
FRRNs	B-Method
)	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
unify	O
the	O
two	O
above	O
-	O
mentioned	O
principles	O
of	O
network	B-Method
design	I-Method
and	O
propose	O
full	B-Method
-	I-Method
resolution	I-Method
residual	I-Method
networks	I-Method
(	O
FRRNs	B-Method
)	O
that	O
exhibit	O
the	O
same	O
superior	O
training	B-Metric
properties	I-Metric
as	O
ResNets	B-Method
but	O
have	O
two	O
processing	O
streams	O
.	O
	
The	O
features	O
on	O
one	O
stream	O
,	O
the	O
residual	O
stream	O
,	O
are	O
computed	O
by	O
adding	O
successive	O
residuals	O
,	O
while	O
the	O
features	O
on	O
the	O
other	O
stream	O
,	O
the	O
pooling	B-Method
stream	O
,	O
are	O
the	O
direct	O
result	O
of	O
a	O
sequence	O
of	O
convolution	O
and	O
pooling	B-Method
operations	O
applied	O
to	O
the	O
input	O
.	O
	
Our	O
design	O
is	O
motivated	O
by	O
the	O
need	O
to	O
have	O
networks	O
that	O
can	O
jointly	O
compute	O
good	O
high	O
-	O
level	O
features	O
for	O
recognition	B-Task
and	O
good	O
low	O
-	O
level	O
features	O
for	O
localization	B-Metric
.	O
	
Regardless	O
of	O
the	O
specific	O
network	B-Method
design	I-Method
,	O
obtaining	O
good	O
highlevel	O
features	O
requires	O
a	O
sequence	O
of	O
pooling	B-Method
operations	O
.	O
	
The	O
pooling	B-Method
operations	O
reduce	O
the	O
size	O
of	O
the	O
feature	O
maps	O
and	O
increase	O
the	O
network	O
's	O
receptive	O
field	O
,	O
as	O
well	O
as	O
its	O
robustness	O
against	O
small	O
translations	O
in	O
the	O
image	O
.	O
	
While	O
this	O
is	O
crucial	O
to	O
obtaining	O
robust	O
high	B-Task
-	I-Task
level	I-Task
features	I-Task
,	O
networks	O
that	O
employ	O
a	O
deep	O
pooling	B-Method
hierarchy	O
have	O
difficulties	O
tracking	O
low	O
-	O
level	O
features	O
,	O
such	O
as	O
edges	O
and	O
boundaries	O
,	O
in	O
deeper	O
layers	O
.	O
	
This	O
makes	O
them	O
good	O
at	O
recognizing	O
the	O
elements	O
in	O
a	O
scene	O
but	O
bad	O
at	O
localizing	O
them	O
to	O
pixel	B-Metric
accuracy	I-Metric
.	O
	
On	O
the	O
other	O
hand	O
,	O
a	O
network	O
that	O
does	O
not	O
employ	O
any	O
pooling	B-Method
operations	O
behaves	O
the	O
opposite	O
way	O
.	O
	
It	O
is	O
good	O
at	O
localizing	B-Task
object	I-Task
boundaries	I-Task
,	O
but	O
performs	O
poorly	O
at	O
recognizing	O
the	O
actual	O
objects	O
.	O
	
By	O
using	O
the	O
two	O
processing	O
streams	O
together	O
,	O
we	O
are	O
able	O
to	O
compute	O
both	O
kinds	O
of	O
features	O
simultaneously	O
.	O
	
While	O
the	O
residual	B-Method
stream	I-Method
of	O
an	O
FRRN	B-Method
computes	O
successive	O
residuals	O
at	O
the	O
full	O
image	O
resolution	O
,	O
allowing	O
low	O
level	O
features	O
to	O
propagate	O
effortlessly	O
through	O
the	O
network	O
,	O
the	O
pooling	B-Method
stream	O
undergoes	O
a	O
sequence	O
of	O
pooling	B-Method
and	O
unpooling	B-Method
operations	I-Method
resulting	O
in	O
good	O
high	O
-	O
level	O
features	O
.	O
	
Figure	O
1	O
visualizes	O
the	O
concept	O
of	O
having	O
two	O
distinct	O
processing	B-Method
streams	I-Method
.	O
	
An	O
FRRN	B-Method
is	O
composed	O
of	O
a	O
sequence	O
of	O
full	B-Method
-	I-Method
resolution	I-Method
residual	I-Method
units	I-Method
(	O
FRRUs	B-Method
)	O
.	O
	
Each	O
FRRU	B-Method
has	O
two	O
inputs	O
and	O
two	O
outputs	O
,	O
because	O
it	O
simultaneously	O
operates	O
on	O
both	O
streams	O
.	O
	
Figure	O
2c	O
shows	O
the	O
structure	O
of	O
an	O
FRRU	B-Method
.	O
	
Let	O
z	O
n−1	O
be	O
the	O
residual	O
input	O
to	O
the	O
n	O
-	O
th	O
FRRU	B-Method
and	O
let	O
y	O
n−1	O
be	O
its	O
pooling	B-Method
input	O
.	O
	
Then	O
the	O
outputs	O
are	O
computed	O
as	O
	
where	O
W	O
n	O
are	O
the	O
parameters	O
of	O
the	O
functions	O
G	O
and	O
H	O
,	O
respectively	O
.	O
	
If	O
G	O
≡	O
0	O
,	O
then	O
an	O
FRRU	B-Method
corresponds	O
to	O
an	O
RU	O
since	O
it	O
disregards	O
the	O
pooling	B-Method
input	O
y	O
n	O
,	O
and	O
the	O
network	O
effectively	O
becomes	O
an	O
ordinary	O
ResNet	B-Method
.	O
	
On	O
the	O
other	O
hand	O
,	O
if	O
H	O
≡	O
0	O
,	O
then	O
the	O
output	O
of	O
an	O
FRRU	B-Method
only	O
depends	O
on	O
its	O
input	O
via	O
the	O
function	O
	
G.	O
Hence	O
,	O
no	O
residuals	O
are	O
computed	O
and	O
we	O
obtain	O
a	O
traditional	O
feedforward	B-Method
network	I-Method
.	O
	
By	O
carefully	O
constructing	O
G	O
and	O
H	O
,	O
we	O
can	O
combine	O
the	O
two	O
network	B-Method
principles	I-Method
.	O
	
In	O
order	O
to	O
show	O
that	O
FRRNs	B-Method
have	O
similar	O
training	O
characteristics	O
as	O
ResNets	B-Method
,	O
we	O
adapt	O
the	O
analysis	O
presented	O
in	O
[	O
reference	O
]	O
to	O
our	O
case	O
.	O
	
Using	O
the	O
same	O
recursive	O
argument	O
as	O
before	O
,	O
we	O
find	O
that	O
for	O
m	O
	
>	O
n	O
,	O
z	O
m	O
has	O
the	O
representation	O
	
We	O
can	O
then	O
express	O
the	O
derivative	O
of	O
the	O
loss	O
l	O
with	O
respect	O
to	O
the	O
weights	O
W	O
n	O
as	O
	
Hence	O
,	O
the	O
weight	B-Method
updates	I-Method
depend	O
on	O
three	O
sources	O
of	O
information	O
.	O
	
Analogous	O
to	O
the	O
analysis	O
of	O
ResNets	B-Task
,	O
the	O
two	O
sources	O
∂H	O
(	O
yi	O
,	O
	
zi;Wi	O
+	O
1	O
)	O
∂zn	O
depend	O
crucially	O
on	O
the	O
depth	O
n	O
,	O
while	O
the	O
term	O
∂l	O
∂zm	O
is	O
independent	O
of	O
the	O
depth	O
.	O
	
Thus	O
,	O
we	O
achieve	O
a	O
depth	O
-	O
independent	O
gradient	O
flow	O
for	O
all	O
parameters	O
that	O
are	O
used	O
by	O
the	O
residual	O
function	O
H.	O
	
If	O
we	O
use	O
some	O
of	O
these	O
weights	O
in	O
order	O
to	O
compute	O
the	O
output	O
of	O
G	O
,	O
all	O
weights	O
of	O
the	O
unit	O
benefit	O
from	O
the	O
improved	O
gradient	B-Method
flow	I-Method
.	O
	
This	O
is	O
most	O
easily	O
achieved	O
by	O
reusing	O
the	O
output	O
of	O
G	O
in	O
order	O
to	O
compute	O
H.	O
	
However	O
,	O
we	O
note	O
that	O
other	O
designs	O
are	O
possible	O
.	O
	
Figure	O
3	O
shows	O
our	O
proposed	O
FRRU	B-Method
design	I-Method
.	O
	
The	O
unit	O
first	O
concatenates	O
the	O
two	O
incoming	O
streams	O
by	O
using	O
a	O
pooling	B-Method
layer	O
in	O
order	O
to	O
reduce	O
the	O
size	O
of	O
the	O
residual	O
stream	O
.	O
	
Then	O
the	O
concatenated	O
features	O
are	O
fed	O
through	O
two	O
convolution	B-Method
units	I-Method
.	O
	
Each	O
convolution	B-Method
unit	I-Method
consists	O
of	O
a	O
3	B-Method
×	I-Method
3	I-Method
convolution	I-Method
layer	I-Method
followed	O
by	O
a	O
batch	B-Method
normalization	I-Method
layer	I-Method
[	O
reference	O
]	O
and	O
a	O
ReLU	B-Method
activation	I-Method
function	I-Method
.	O
	
The	O
result	O
of	O
the	O
second	O
convolution	B-Method
unit	I-Method
is	O
used	O
in	O
two	O
ways	O
.	O
	
First	O
,	O
it	O
forms	O
the	O
pooling	B-Method
stream	O
input	O
of	O
the	O
next	O
FRRU	B-Method
in	O
the	O
network	O
and	O
second	O
it	O
is	O
the	O
basis	O
for	O
the	O
computed	O
residual	O
.	O
	
To	O
this	O
end	O
,	O
we	O
first	O
adjust	O
the	O
number	O
of	O
feature	O
channels	O
using	O
a	O
1	O
×	B-Method
1	I-Method
convolution	I-Method
and	O
then	O
upscale	O
the	O
spatial	O
dimensions	O
using	O
an	O
unpooling	B-Method
layer	O
.	O
	
Because	O
the	O
features	O
might	O
have	O
to	O
be	O
upscaled	O
significantly	O
(	O
e.g.	O
,	O
by	O
a	O
factor	O
of	O
16	O
)	O
,	O
we	O
found	O
that	O
simply	O
upscaling	O
by	O
repeating	O
the	O
entries	O
along	O
the	O
spatial	O
dimensions	O
performed	O
superior	O
to	O
bilinear	B-Method
interpolation	I-Method
.	O
	
In	O
Figure	O
3	O
,	O
the	O
inner	O
red	O
box	O
corresponds	O
to	O
the	O
function	O
G	O
while	O
the	O
outer	O
blue	O
box	O
corresponds	O
to	O
the	O
function	O
H.	O
	
We	O
can	O
see	O
that	O
the	O
output	O
of	O
G	O
is	O
used	O
in	O
order	O
to	O
compute	O
H	O
,	O
because	O
the	O
red	O
box	O
is	O
entirely	O
contained	O
within	O
the	O
blue	O
box	O
.	O
	
As	O
shown	O
above	O
,	O
this	O
design	O
choice	O
results	O
in	O
superior	O
gradient	O
flow	O
properties	O
for	O
all	O
weights	O
of	O
the	O
unit	O
.	O
	
Table	O
1	O
shows	O
the	O
two	O
network	B-Method
architectures	I-Method
that	O
we	O
used	O
in	O
order	O
to	O
assess	O
our	O
approach	O
's	O
segmentation	B-Task
performance	O
.	O
	
The	O
proposed	O
architectures	O
are	O
based	O
on	O
several	O
principles	O
employed	O
by	O
other	O
authors	O
.	O
	
We	O
follow	O
Noh	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
and	O
use	O
an	O
encoder	B-Method
/	I-Method
decoder	I-Method
formulation	I-Method
.	O
	
In	O
the	O
encoder	B-Method
,	O
we	O
reduce	O
the	O
size	O
of	O
the	O
pooling	B-Method
stream	O
using	O
max	O
pooling	B-Method
operations	O
.	O
	
The	O
pooled	O
feature	O
maps	O
are	O
then	O
successively	O
upscaled	O
using	O
bilinear	B-Method
interpolation	I-Method
in	O
the	O
decoder	B-Method
.	O
	
Furthermore	O
,	O
similar	O
to	O
Simonyan	O
and	O
Zisserman	O
[	O
reference	O
]	O
	
,	O
we	O
define	O
a	O
number	O
of	O
base	O
channels	O
that	O
we	O
double	O
after	O
each	O
pooling	B-Method
operation	O
(	O
up	O
to	O
a	O
certain	O
upper	O
limit	O
)	O
.	O
	
Instead	O
of	O
choosing	O
64	O
base	O
channels	O
as	O
in	O
VGG	B-Method
net	I-Method
,	O
we	O
use	O
48	O
channels	O
in	O
order	O
to	O
have	O
a	O
manageable	O
number	O
of	O
trainable	O
parameters	O
.	O
	
Depending	O
on	O
the	O
input	O
image	O
resolution	O
,	O
we	O
use	O
FRRN	O
A	O
or	O
FRRN	O
B	O
to	O
keep	O
the	O
relative	O
size	O
of	O
the	O
receptive	O
fields	O
consistent	O
.	O
	
section	O
:	O
Training	O
Procedure	O
	
Following	O
Wu	O
et	O
al	O
.	O
	
,	O
we	O
train	O
our	O
network	O
by	O
minimizing	O
a	O
bootstrapped	B-Method
cross	I-Method
-	I-Method
entropy	I-Method
loss	I-Method
	
[	O
reference	O
]	O
.	O
Let	O
c	O
be	O
the	O
number	O
of	O
classes	O
,	O
y	O
1	O
,	O
...	O
,	O
y	O
N	O
∈	O
{	O
1	O
,	O
...	O
	
,	O
c	O
}	O
be	O
the	O
target	O
class	O
labels	O
for	O
the	O
pixels	O
1	O
,	O
...	O
,	O
N	O
,	O
and	O
let	O
p	O
i	O
,	O
j	O
be	O
the	O
posterior	O
class	O
+	O
Bias	O
Softmax	O
probability	O
for	O
class	O
j	O
and	O
pixel	O
	
i.	O
	
Then	O
,	O
the	O
bootstrapped	B-Metric
cross	I-Metric
-	I-Metric
entropy	I-Metric
loss	I-Metric
over	O
K	O
pixels	O
is	O
defined	O
as	O
	
where	O
1	O
[	O
x	O
]	O
=	O
	
1	O
iff	O
x	O
is	O
true	O
and	O
t	O
k	O
∈	O
R	O
is	O
chosen	O
such	O
that	O
|{i	O
∈	O
{	O
1	O
,	O
...	O
,	O
N	O
}	O
:	O
	
p	O
i	O
,	O
yi	O
<	O
t	O
k	O
	
}	O
|	O
=	O
	
K.	O
	
The	O
threshold	O
parameter	O
	
t	O
k	O
can	O
easily	O
be	O
determined	O
by	O
sorting	O
the	O
predicted	O
log	O
probabilities	O
and	O
choosing	O
the	O
K	O
+	O
	
1	O
-	O
th	O
one	O
as	O
threshold	O
.	O
	
Figure	O
4	O
visualizes	O
the	O
concept	O
.	O
	
Depending	O
on	O
the	O
number	O
of	O
pixels	O
K	O
that	O
we	O
consider	O
,	O
we	O
select	O
misclassified	O
pixels	O
or	O
pixels	O
where	O
we	O
predict	O
the	O
correct	O
label	O
with	O
a	O
small	O
probability	O
.	O
	
We	O
minimize	O
the	O
loss	B-Metric
using	O
ADAM	B-Method
[	O
reference	O
]	O
.	O
Because	O
each	O
FRRU	B-Method
processes	O
features	O
at	O
the	O
full	O
image	O
resolution	O
,	O
training	O
a	O
full	B-Method
-	I-Method
resolution	I-Method
residual	I-Method
network	I-Method
is	O
very	O
memory	O
intensive	O
.	O
	
Recall	O
that	O
in	O
order	O
for	O
the	O
backpropagation	B-Method
algorithm	I-Method
[	O
reference	O
]	O
to	O
work	O
,	O
the	O
entire	O
forward	O
pass	O
has	O
to	O
be	O
stored	O
in	O
memory	O
.	O
	
If	O
the	O
memory	O
required	O
to	O
store	O
the	O
forward	O
pass	O
for	O
a	O
given	O
network	O
exceeds	O
the	O
available	O
GPU	O
memory	O
,	O
we	O
can	O
no	O
longer	O
use	O
the	O
standard	O
backpropagation	B-Method
algorithm	I-Method
.	O
	
In	O
order	O
to	O
alleviate	O
this	O
problem	O
,	O
Figure	O
4	O
.	O
	
Pixels	O
used	O
by	O
the	O
bootstrapped	B-Method
cross	I-Method
-	I-Method
entropy	I-Method
loss	I-Method
for	O
varying	O
values	O
of	O
K.	O
	
The	O
images	O
and	O
ground	O
truth	O
annotations	O
originate	O
from	O
the	O
twice	O
-	O
subsampled	O
Cityscapes	B-Material
validation	O
set	O
[	O
reference	O
]	O
.	O
Pixels	O
that	O
are	O
labeled	O
void	O
are	O
not	O
considered	O
for	O
the	O
bootstrapping	B-Method
process	I-Method
.	O
	
we	O
partition	O
the	O
computation	O
graph	O
into	O
several	O
subsequent	O
blocks	O
by	O
manually	O
placing	O
cut	O
points	O
in	O
the	O
graph	O
.	O
	
We	O
then	O
compute	O
the	O
derivatives	O
for	O
each	O
block	O
individually	O
.	O
	
To	O
this	O
end	O
,	O
we	O
perform	O
one	O
(	O
partial	O
)	O
forward	B-Method
pass	I-Method
per	O
block	O
and	O
only	O
store	O
the	O
feature	O
maps	O
for	O
the	O
block	O
whose	O
derivatives	O
are	O
computed	O
given	O
the	O
derivative	O
of	O
the	O
subsequent	O
block	O
.	O
	
This	O
simple	O
scheme	O
allows	O
us	O
to	O
manually	O
control	O
a	O
spacetime	O
trade	O
-	O
off	O
.	O
	
The	O
idea	O
of	O
recomputing	O
some	O
intermediate	O
results	O
on	O
demand	O
is	O
also	O
used	O
in	O
[	O
reference	O
]	O
and	O
	
[	O
reference	O
]	O
.	O
Note	O
that	O
these	O
memory	O
limitations	O
only	O
apply	O
during	O
training	B-Task
.	O
	
During	O
testing	O
,	O
there	O
is	O
no	O
need	O
to	O
store	O
results	O
of	O
each	O
operation	O
in	O
the	O
network	O
and	O
our	O
architecture	O
's	O
memory	B-Metric
footprint	I-Metric
is	O
comparable	O
to	O
that	O
of	O
a	O
ResNet	B-Method
encoder	I-Method
/	I-Method
decoder	I-Method
architecture	I-Method
.	O
	
We	O
will	O
make	O
code	O
for	O
the	O
gradient	B-Task
computation	I-Task
for	O
arbitrary	B-Task
networks	I-Task
publicly	O
available	O
in	O
Theano	O
/	O
Lasagne	O
.	O
	
In	O
order	O
to	O
reduce	O
overfitting	O
,	O
we	O
used	O
two	O
methods	O
of	O
data	B-Task
augmentation	I-Task
:	O
translation	B-Task
augmentation	I-Task
and	O
gamma	B-Task
augmentation	I-Task
.	O
	
The	O
former	O
method	O
randomly	O
translates	O
an	O
image	O
and	O
its	O
annotations	O
.	O
	
In	O
order	O
to	O
keep	O
consistent	O
image	O
dimensions	O
,	O
we	O
have	O
to	O
pad	O
the	O
translated	O
images	O
and	O
annotations	O
.	O
	
To	O
this	O
end	O
,	O
we	O
use	O
reflection	O
padding	O
on	O
the	O
image	O
and	O
constant	O
padding	O
with	O
void	O
labels	O
on	O
the	O
annotations	O
.	O
	
Our	O
second	O
method	O
of	O
data	B-Task
augmentation	I-Task
is	O
gamma	B-Task
augmentation	I-Task
.	O
	
We	O
use	O
a	O
slightly	O
modified	O
gamma	B-Method
augmentation	I-Method
method	I-Method
detailed	O
in	O
Appendix	O
A.	O
	
section	O
:	O
Experimental	O
Evaluation	O
	
We	O
evaluate	O
our	O
approach	O
on	O
the	O
recently	O
released	O
Cityscapes	B-Material
benchmark	O
[	O
reference	O
]	O
containing	O
images	O
recorded	O
in	O
50	O
different	O
cities	O
.	O
	
This	O
benchmark	O
provides	O
5	O
,	O
000	O
images	O
with	O
high	O
-	O
quality	O
annotations	O
split	O
up	O
into	O
a	O
training	O
,	O
validation	O
,	O
and	O
test	O
set	O
(	O
2	O
,	O
975	O
,	O
500	O
,	O
and	O
1	O
,	O
525	O
images	O
,	O
respectively	O
)	O
.	O
	
The	O
dense	O
pixel	O
annotations	O
span	O
30	O
classes	O
frequently	O
occurring	O
in	O
urban	O
street	O
scenes	O
,	O
out	O
of	O
which	O
19	O
are	O
used	O
for	O
actual	O
training	O
and	O
evaluation	B-Task
.	O
	
Annotations	O
for	O
the	O
test	O
set	O
remain	O
private	O
and	O
comparison	O
to	O
other	O
methods	O
is	O
performed	O
via	O
a	O
dedicated	O
evaluation	O
server	O
.	O
	
We	O
report	O
the	O
results	O
of	O
our	O
FRRNs	B-Method
for	O
two	O
settings	O
:	O
FRRN	B-Method
A	I-Method
trained	O
on	O
quarter	O
-	O
resolution	O
(	O
256	O
×	O
512	O
)	O
Cityscapes	B-Material
images	O
;	O
and	O
FRRN	B-Method
B	I-Method
trained	O
on	O
half	O
-	O
resolution	O
(	O
512	O
×	O
1024	O
)	O
images	O
.	O
	
We	O
then	O
upsample	O
our	O
predictions	O
using	O
bilinear	B-Method
interpolation	I-Method
in	O
order	O
to	O
report	O
scores	O
at	O
the	O
full	O
image	O
resolution	O
of	O
1024	O
×	O
2048	O
pixels	O
.	O
	
Directly	O
training	O
at	O
the	O
full	O
Cityscapes	B-Material
resolution	O
turned	O
out	O
to	O
be	O
too	O
memory	O
intensive	O
with	O
our	O
current	O
design	O
.	O
	
However	O
,	O
as	O
our	O
experimental	O
results	O
will	O
show	O
,	O
even	O
when	O
trained	O
only	O
on	O
halfresolution	O
images	O
,	O
our	O
FRRN	B-Method
B	I-Method
's	O
results	O
are	O
competitive	O
with	O
the	O
best	O
published	O
methods	O
trained	O
on	O
full	O
-	O
resolution	O
data	O
.	O
	
Unless	O
specified	O
otherwise	O
,	O
the	O
reported	O
results	O
are	O
based	O
on	O
the	O
Cityscapes	B-Material
test	O
set	O
.	O
	
Qualitative	O
results	O
are	O
shown	O
in	O
Figure	O
7	O
,	O
in	O
Appendix	O
C	O
,	O
and	O
in	O
our	O
result	O
video	O
2	O
.	O
	
section	O
:	O
Residual	B-Method
Network	I-Method
Baseline	O
	
Our	O
network	B-Method
architecture	I-Method
can	O
be	O
described	O
as	O
a	O
ResNet	B-Method
[	O
reference	O
]	O
encoder	B-Method
/	I-Method
decoder	I-Method
architecture	I-Method
,	O
where	O
the	O
residuals	O
remain	O
at	O
the	O
full	O
input	O
resolution	O
throughout	O
the	O
network	O
.	O
	
A	O
natural	O
baseline	O
is	O
thus	O
a	O
traditional	O
ResNet	B-Method
encoder	I-Method
/	I-Method
decoder	I-Method
architecture	I-Method
with	O
long	B-Method
-	I-Method
range	I-Method
skip	I-Method
connections	I-Method
	
[	O
reference	O
][	O
reference	O
]	O
.	O
	
In	O
fact	O
,	O
such	O
an	O
architecture	O
resembles	O
a	O
single	O
deep	B-Method
hourglass	I-Method
module	I-Method
in	O
the	O
stacked	B-Method
hourglass	I-Method
network	I-Method
architecture	I-Method
	
[	O
reference	O
]	O
.	O
	
This	O
baseline	O
differs	O
from	O
our	O
proposed	O
architecture	O
in	O
two	O
important	O
ways	O
:	O
While	O
the	O
feature	O
maps	O
on	O
our	O
residual	O
stream	O
are	O
processed	O
by	O
each	O
FRRU	B-Method
,	O
the	O
feature	O
maps	O
on	O
the	O
long	O
-	O
range	O
skip	O
connections	O
are	O
not	O
processed	O
by	O
intermediate	B-Method
layers	I-Method
.	O
	
Furthermore	O
,	O
long	O
-	O
range	O
skip	O
connections	O
are	O
scale	O
dependent	O
,	O
meaning	O
that	O
features	O
at	O
one	O
scale	O
travel	O
over	O
a	O
different	O
skip	O
connection	O
than	O
features	O
at	O
another	O
scale	O
.	O
	
This	O
is	O
in	O
contrast	O
to	O
our	O
network	B-Method
design	I-Method
,	O
where	O
the	O
residual	O
stream	O
can	O
carry	O
upscaled	O
features	O
from	O
several	O
pooling	B-Method
stages	O
simultaneously	O
.	O
	
In	O
order	O
to	O
illustrate	O
the	O
benefits	O
of	O
our	O
approach	O
over	O
the	O
natural	O
baseline	O
,	O
we	O
converted	O
the	O
architecture	O
FRRN	B-Method
A	O
(	O
Table	O
1a	O
)	O
to	O
a	O
ResNet	B-Method
as	O
follows	O
:	O
	
We	O
first	O
replaced	O
all	O
FRRUs	B-Method
by	O
RUs	O
and	O
then	O
added	O
skip	O
connections	O
that	O
connect	O
the	O
input	O
of	O
each	O
pooling	B-Method
layer	O
to	O
the	O
output	O
of	O
the	O
corresponding	O
unpooling	B-Method
layer	O
.	O
	
The	O
resulting	O
ResNet	B-Method
has	O
slightly	O
fewer	O
parameters	O
than	O
the	O
original	O
FRRN	B-Method
(	O
16.7	O
×	O
10	O
6	O
vs.	O
17.7	O
×	O
10	O
6	O
)	O
.	O
	
This	O
is	O
due	O
to	O
the	O
fact	O
that	O
RUs	O
lack	O
the	O
1	B-Method
×	I-Method
1	I-Method
convolutions	I-Method
that	O
connect	O
the	O
pooling	B-Method
to	O
the	O
residual	O
Table	O
2	O
.	O
	
IoU	B-Metric
scores	I-Metric
from	O
the	O
cityscapes	B-Material
test	I-Material
set	I-Material
.	O
	
We	O
highlight	O
the	O
best	O
published	O
baselines	O
for	O
the	O
different	O
sampling	B-Metric
rates	I-Metric
.	O
	
(	O
Additional	O
anonymous	O
submissions	O
exist	O
as	O
concurrent	O
work	O
.	O
)	O
	
Bold	O
numbers	O
represent	O
the	O
best	O
,	O
italic	O
numbers	O
the	O
second	O
best	O
score	O
for	O
a	O
class	O
.	O
	
We	O
also	O
indicate	O
the	O
subsampling	O
factor	O
used	O
on	O
the	O
input	O
images	O
,	O
whether	O
additional	O
coarsely	O
annotated	O
data	O
was	O
used	O
,	O
and	O
whether	O
the	O
model	O
was	O
initialized	O
with	O
pre	O
-	O
trained	O
weights	O
.	O
	
stream	O
.	O
	
section	O
:	O
Method	O
	
We	O
train	O
both	O
networks	O
on	O
the	O
quarter	O
-	O
resolution	O
Cityscapes	B-Material
dataset	O
for	O
45	O
,	O
000	O
iterations	O
at	O
a	O
batch	O
size	O
of	O
3	O
.	O
	
We	O
use	O
a	O
learning	B-Metric
rate	I-Metric
of	O
10	O
−3	O
for	O
the	O
first	O
35	O
,	O
000	O
iterations	O
and	O
then	O
reduce	O
it	O
to	O
10	O
−4	O
for	O
the	O
following	O
10	O
,	O
000	O
iterations	O
.	O
	
Both	O
networks	O
converged	O
within	O
these	O
iterations	O
.	O
	
The	O
FRRN	B-Method
A	I-Method
resulted	O
in	O
a	O
validation	O
set	O
mean	B-Metric
IoU	I-Metric
score	I-Metric
of	O
65.7	O
%	O
while	O
the	O
ResNet	B-Method
baseline	O
only	O
achieved	O
62.8	O
%	O
,	O
showing	O
a	O
significant	O
advantage	O
of	O
our	O
FRRNs	B-Method
.	O
	
Training	O
FRRN	B-Method
B	O
is	O
performed	O
in	O
a	O
similar	O
fashion	O
.	O
	
Detailed	O
training	O
curves	O
are	O
shown	O
in	O
Appendix	O
B.	O
	
section	O
:	O
Quantitative	O
Evaluation	O
	
Overview	O
In	O
Table	O
2	O
we	O
compare	O
our	O
method	O
to	O
the	O
best	O
(	O
published	O
)	O
performers	O
on	O
the	O
Cityscapes	B-Material
leader	O
board	O
,	O
namely	O
LRR	B-Method
[	O
reference	O
]	O
,	O
Adelaide	O
[	O
reference	O
]	O
,	O
and	O
Dilation	O
	
[	O
reference	O
]	O
.	O
Note	O
that	O
our	O
network	O
performs	O
on	O
par	O
with	O
the	O
very	O
complex	O
and	O
well	O
engineered	O
system	O
by	O
[	O
reference	O
]	O
.	O
Among	O
the	O
top	O
performers	O
on	O
Cityscapes	B-Material
,	O
only	O
ENet	B-Method
refrain	O
from	O
using	O
a	O
pre	B-Method
-	I-Method
trained	I-Method
network	I-Method
.	O
	
However	O
,	O
they	O
design	O
their	O
network	O
for	O
real	O
time	O
performance	O
and	O
thus	O
do	O
not	O
obtain	O
top	O
scores	O
.	O
	
To	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
we	O
are	O
the	O
first	O
to	O
show	O
that	O
it	O
is	O
possible	O
to	O
obtain	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
even	O
without	O
pre	B-Method
-	I-Method
training	I-Method
.	O
	
This	O
gives	O
credibility	O
to	O
our	O
claim	O
that	O
network	B-Method
architectures	I-Method
can	O
have	O
a	O
crucial	O
effect	O
on	O
a	O
system	O
's	O
overall	O
performance	O
.	O
	
Subsampling	B-Method
Factor	I-Method
.	O
	
An	O
interesting	O
observation	O
that	O
we	O
made	O
on	O
the	O
Cityscapes	B-Material
test	O
set	O
is	O
a	O
correlation	O
between	O
the	O
subsampling	O
factor	O
and	O
the	O
test	O
performance	O
.	O
	
This	O
correlation	O
can	O
be	O
seen	O
in	O
Figure	O
5	O
where	O
we	O
show	O
the	O
scores	O
of	O
several	O
approaches	O
currently	O
listed	O
on	O
the	O
leader	O
board	O
against	O
their	O
respective	O
subsampling	O
factors	O
.	O
	
Unsurprisingly	O
,	O
most	O
of	O
the	O
best	O
performers	O
operate	O
on	O
the	O
fullresolution	O
input	O
images	O
.	O
	
Throughout	O
our	O
experiments	O
,	O
we	O
consistently	O
outperformed	O
other	O
approaches	O
who	O
trained	O
on	O
Mean	B-Metric
IoU	I-Metric
Score	I-Metric
(	O
%	O
)	O
	
section	O
:	O
Subsampling	O
factor	O
	
Published	O
Unpublished	O
LRR	O
[	O
reference	O
]	O
	
Adelaide	O
[	O
reference	O
]	O
Dilation	O
[	O
reference	O
]	O
	
ENet	B-Method
[	O
reference	O
]	O
SegNet	O
[	O
reference	O
]	O
	
DeepLab	B-Method
[	O
reference	O
]	O
	
FRRN	B-Method
A	O
/	O
B	O
Figure	O
5	O
.	O
	
Comparison	O
of	O
the	O
mean	B-Metric
IoU	I-Metric
scores	I-Metric
of	O
all	O
approaches	O
on	O
the	O
leader	O
board	O
of	O
the	O
Cityscapes	B-Material
segmentation	O
benchmark	O
based	O
on	O
the	O
subsampling	O
factor	O
of	O
the	O
images	O
that	O
they	O
were	O
trained	O
on	O
.	O
	
Dilation	B-Method
[	O
reference	O
]	O
	
LRR	B-Method
[	O
reference	O
]	O
	
FRRN	B-Method
B	O
Figure	O
6	O
.	O
	
The	O
trimap	B-Method
evaluation	I-Method
on	O
the	O
validation	O
set	O
.	O
	
The	O
solid	O
lines	O
show	O
the	O
mean	O
IoU	B-Metric
score	I-Metric
of	O
our	O
approach	O
and	O
two	O
top	O
performing	O
methods	O
that	O
released	O
their	O
code	O
.	O
	
The	O
dashed	O
lines	O
show	O
the	O
mean	O
IoU	B-Metric
score	I-Metric
when	O
using	O
the	O
7	O
Cityscapes	B-Material
category	O
labels	O
for	O
the	O
same	O
methods	O
.	O
	
the	O
same	O
image	O
resolutions	O
.	O
	
Even	O
though	O
we	O
only	O
train	O
on	O
half	O
-	O
resolution	O
images	O
,	O
Figure	O
5	O
clearly	O
shows	O
we	O
can	O
match	O
the	O
current	O
published	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
(	O
LRR	B-Method
[	O
reference	O
]	O
Figure	O
7	O
.	O
	
Qualitative	O
comparison	O
on	O
the	O
Cityscapes	B-Material
validation	O
set	O
.	O
	
Interesting	O
cases	O
are	O
the	O
fence	O
in	O
the	O
first	O
row	O
,	O
the	O
truck	O
in	O
the	O
second	O
row	O
,	O
or	O
the	O
street	O
light	O
poles	O
in	O
the	O
last	O
row	O
.	O
	
An	O
interesting	O
failure	O
case	O
is	O
shown	O
in	O
the	O
third	O
row	O
:	O
all	O
methods	O
struggle	O
to	O
find	O
the	O
correct	O
sidewalk	O
boundary	O
,	O
however	O
our	O
network	O
makes	O
a	O
clean	O
and	O
reasonable	O
prediction	O
.	O
	
section	O
:	O
Boundary	B-Task
Adherence	I-Task
	
Due	O
to	O
several	O
pooling	B-Method
operations	O
(	O
and	O
subsequent	O
upsampling	B-Method
)	O
in	O
many	O
of	O
today	O
's	O
FCN	B-Method
architectures	I-Method
,	O
boundaries	O
are	O
often	O
overly	O
smooth	O
,	O
resulting	O
in	O
lost	O
details	O
and	O
edge	O
-	O
bleeding	O
.	O
	
This	O
leads	O
to	O
suboptimal	O
scores	O
,	O
but	O
it	O
also	O
makes	O
the	O
output	O
of	O
a	O
semantic	B-Method
segmentation	I-Method
approach	I-Method
harder	O
to	O
use	O
without	O
further	O
post	B-Task
-	I-Task
processing	I-Task
.	O
	
Since	O
inaccurate	O
boundaries	O
are	O
often	O
not	O
apparent	O
from	O
the	O
standard	O
evaluation	B-Metric
metric	I-Metric
scores	I-Metric
,	O
a	O
typical	O
approach	O
is	O
a	O
trimap	B-Task
evaluation	I-Task
in	O
order	O
to	O
quantify	O
detailed	O
boundary	O
adherence	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
During	O
trimap	B-Task
evaluation	I-Task
,	O
all	O
predictions	O
are	O
ignored	O
if	O
they	O
do	O
not	O
fall	O
within	O
a	O
certain	O
radius	O
r	O
of	O
a	O
ground	O
truth	O
label	O
boundary	O
.	O
	
Figure	O
6	O
visualizes	O
our	O
trimap	B-Method
evaluation	I-Method
performed	O
on	O
the	O
validation	O
set	O
for	O
varying	O
trimap	O
widths	O
r	O
between	O
1	O
and	O
80	O
pixels	O
.	O
	
We	O
compare	O
to	O
LRR	B-Method
[	O
reference	O
]	O
and	O
Dilation	B-Method
[	O
reference	O
]	O
,	O
who	O
made	O
code	O
and	O
pre	O
-	O
trained	O
models	O
available	O
.	O
	
We	O
see	O
that	O
our	O
approach	O
outperforms	O
the	O
competition	O
consistently	O
for	O
all	O
radii	O
r.	O
	
Furthermore	O
,	O
it	O
shall	O
be	O
noted	O
that	O
the	O
method	O
of	O
[	O
reference	O
]	O
is	O
based	O
on	O
an	O
architecture	O
specifically	O
designed	O
for	O
clean	B-Task
boundaries	I-Task
.	O
	
Our	O
method	O
achieves	O
better	O
boundary	B-Metric
adherence	I-Metric
,	O
both	O
numerically	O
and	O
qualitatively	O
(	O
see	O
Figure	O
7	O
)	O
,	O
with	O
a	O
much	O
simpler	O
architecture	O
and	O
without	O
ImageNet	B-Method
pre	I-Method
-	I-Method
training	I-Method
.	O
	
Often	O
one	O
can	O
boost	O
both	O
the	O
numerical	B-Metric
score	I-Metric
and	O
the	O
boundary	O
adherence	O
by	O
using	O
a	O
fully	B-Method
connected	I-Method
CRF	I-Method
as	O
post	O
-	O
processing	O
step	O
.	O
	
We	O
tried	O
to	O
apply	O
a	O
fully	B-Method
connected	I-Method
CRF	I-Method
with	O
Gaussian	B-Method
kernel	I-Method
,	O
as	O
introduced	O
by	O
Krähenbühl	O
and	O
Kolton	O
	
[	O
reference	O
]	O
.	O
	
We	O
used	O
the	O
standard	O
appearance	B-Method
and	I-Method
smoothness	I-Method
kernels	I-Method
and	O
tuned	O
parameters	O
on	O
the	O
validation	O
set	O
by	O
running	O
several	O
thousand	O
Hyperopt	O
iterations	O
[	O
	
reference	O
]	O
.	O
Surprisingly	O
the	O
color	B-Metric
standard	I-Metric
deviation	I-Metric
for	O
the	O
appearance	O
kernel	O
tended	O
towards	O
very	O
small	O
values	O
,	O
while	O
the	O
weight	O
did	O
not	O
go	O
to	O
zero	O
.	O
	
This	O
indicates	O
that	O
the	O
appearance	B-Method
kernel	I-Method
would	O
only	O
smooth	O
labels	O
across	O
pixels	O
with	O
very	O
similar	O
colors	O
.	O
	
Nevertheless	O
,	O
with	O
the	O
best	O
parameters	O
we	O
only	O
obtained	O
an	O
IoU	B-Metric
boost	I-Metric
of	O
∼	O
0.5	O
%	O
on	O
the	O
validation	O
set	O
.	O
	
Given	O
the	O
high	O
computation	B-Metric
time	I-Metric
we	O
decided	O
against	O
any	O
post	B-Method
-	I-Method
processing	I-Method
steps	I-Method
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
paper	O
we	O
propose	O
a	O
novel	O
network	B-Method
architecture	I-Method
for	O
semantic	B-Task
segmentation	I-Task
in	O
street	O
scenes	O
.	O
	
Our	O
architecture	O
is	O
clean	O
,	O
does	O
not	O
require	O
additional	O
post	B-Method
-	I-Method
processing	I-Method
,	O
can	O
be	O
trained	O
from	O
scratch	O
,	O
shows	O
superior	O
boundary	B-Metric
adherence	I-Metric
,	O
and	O
reaches	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
the	O
Cityscapes	B-Material
benchmark	O
.	O
	
We	O
will	O
provide	O
code	O
and	O
all	O
trained	O
models	O
.	O
	
Since	O
we	O
do	O
not	O
incorporate	O
design	O
choices	O
specifically	O
tailored	O
towards	O
semantic	B-Task
segmentation	I-Task
,	O
we	O
believe	O
that	O
our	O
architecture	O
will	O
also	O
be	O
applicable	O
to	O
other	O
tasks	O
such	O
as	O
stereo	B-Task
or	O
optical	B-Task
flow	I-Task
where	O
predictions	B-Task
are	O
performed	O
per	O
pixel	O
.	O
	
Our	O
goal	O
is	O
to	O
find	O
γ	O
such	O
that	O
E	O
U	O
[	O
U	O
]	O
=	O
0.5	O
.	O
	
The	O
key	O
idea	O
to	O
solving	O
this	O
problem	O
is	O
to	O
look	O
at	O
the	O
deviation	O
of	O
U	O
from	O
0.5	O
.	O
	
Let	O
Z	O
be	O
this	O
deviation	O
.	O
	
Then	O
(	O
11	O
)	O
is	O
equivalent	O
to	O
	
Hence	O
,	O
without	O
solving	O
for	O
the	O
implicitly	O
defined	O
variable	O
U	O
explicitly	O
,	O
we	O
found	O
a	O
transformation	O
of	O
a	O
zero	O
-	O
mean	O
random	O
variable	O
Z	O
such	O
that	O
γ	O
has	O
the	O
desired	O
properties	O
.	O
	
Because	O
Z	O
was	O
defined	O
to	O
be	O
the	O
offset	O
from	O
0.5	O
and	O
U	O
∈	O
[	O
0	O
,	O
1	O
]	O
,	O
it	O
follows	O
Z	O
∈	O
	
[	O
−0.5	O
,	O
0.5	O
]	O
.	O
	
We	O
are	O
free	O
to	O
choose	O
any	O
distribution	O
such	O
that	O
Z	O
has	O
	
zero	O
mean	O
and	O
falls	O
into	O
the	O
range	O
[	O
−0.5	O
,	O
0.5	O
]	O
.	O
	
For	O
simplicity	O
reasons	O
,	O
we	O
choose	O
Z	O
to	O
be	O
uniformly	O
distributed	O
over	O
[	O
−a	O
,	O
a	O
]	O
where	O
a	O
∈	O
[	O
0	O
,	O
0.5	O
]	O
determines	O
the	O
strength	O
of	O
the	O
augmentation	O
.	O
	
Figure	O
8b	O
illustrates	O
the	O
obvious	O
bias	B-Task
reduction	I-Task
.	O
	
section	O
:	O
B.	O
Baseline	O
Evaluation	O
	
In	O
Section	O
5.2	O
of	O
the	O
main	O
paper	O
,	O
we	O
describe	O
the	O
setting	O
of	O
our	O
baseline	O
method	O
(	O
Residual	B-Method
Network	I-Method
Baseline	I-Method
)	O
and	O
compare	O
it	O
to	O
our	O
FRRN	B-Method
A	I-Method
network	I-Method
.	O
	
To	O
emphasize	O
on	O
a	O
proper	O
training	O
procedure	O
of	O
both	O
baselines	O
,	O
Figure	O
9	O
shows	O
the	O
mean	B-Metric
IoU	I-Metric
score	I-Metric
on	O
the	O
validation	O
set	O
over	O
time	O
.	O
	
We	O
can	O
see	O
that	O
our	O
model	O
outperforms	O
the	O
baseline	O
with	O
a	O
significant	O
margin	O
and	O
both	O
methods	O
are	O
trained	O
until	O
convergence	O
.	O
	
Figure	O
10	O
shows	O
and	O
compares	O
addtional	O
output	O
labelings	O
of	O
our	O
method	O
.	O
	
Please	O
also	O
consult	O
our	O
labeled	O
video	O
sequence	O
[	O
reference	O
]	O
to	O
gain	O
a	O
better	O
sense	O
of	O
the	O
quality	O
of	O
our	O
method	O
.	O
	
We	O
all	O
know	O
Latex	O
is	O
a	O
pain	O
.	O
	
section	O
:	O
C.	O
Qualitative	O
Results	O
	
section	O
:	O
Image	B-Task
Ground	I-Task
Truth	I-Task
	
Ours	O
LRR	B-Method
[	O
reference	O
]	O
Figure	O
10	O
.	O
	
Additional	O
qualitative	O
results	O
on	O
the	O
Cityscapes	B-Material
validation	O
set	O
.	O
	
We	O
omit	O
the	O
comparison	O
to	O
Dilation	O
[	O
reference	O
]	O
in	O
order	O
to	O
show	O
bigger	O
images	O
here	O
.	O
	
section	O
:	O
	
section	O
:	O
Appendix	O
	
section	O
:	O
A.	O
Gamma	B-Method
Augmentation	I-Method
	
Gamma	B-Method
augmentation	I-Method
is	O
an	O
augmentation	B-Method
method	I-Method
that	O
varies	O
the	O
image	O
contrast	O
and	O
brightness	O
.	O
	
Assume	O
the	O
intensity	O
values	O
of	O
an	O
image	O
are	O
scaled	O
to	O
the	O
unit	O
interval	O
[	O
0	O
,	O
1	O
]	O
.	O
	
Then	O
gamma	B-Method
augmentation	I-Method
applies	O
the	O
intensity	B-Method
transformation	I-Method
x	O
	
→	O
x	O
γ	O
for	O
a	O
randomly	O
sampled	O
augmentation	O
parameter	O
	
γ	O
>	O
0	O
.	O
	
However	O
,	O
sampling	O
the	O
augmentation	O
parameter	O
γ	O
is	O
not	O
trivial	O
.	O
	
Naively	O
drawing	O
samples	O
from	O
a	O
uniform	B-Method
or	O
truncated	B-Method
Gaussian	I-Method
distribution	I-Method
with	O
a	O
mean	O
of	O
1	O
results	O
in	O
a	O
noticeable	O
bias	O
(	O
Figure	O
8a	O
)	O
.	O
	
In	O
order	O
to	O
reduce	O
the	O
bias	O
,	O
we	O
deduce	O
a	O
novel	O
sampling	B-Method
schema	I-Method
for	O
γ	O
.	O
	
Let	O
U	O
be	O
a	O
random	O
variable	O
that	O
is	O
implicitly	O
defined	O
as	O
the	O
solution	O
to	O
the	O
fixed	B-Task
-	I-Task
point	I-Task
problem	I-Task
	
section	O
:	O
	
document	O
:	O
V	B-Method
-	I-Method
Net	I-Method
:	O
Fully	O
Convolutional	B-Method
Neural	I-Method
Networks	I-Method
for	O
Volumetric	B-Task
Medical	I-Task
Image	I-Task
Segmentation	I-Task
	
Convolutional	B-Method
Neural	I-Method
Networks	I-Method
(	O
CNNs	B-Method
)	O
have	O
been	O
recently	O
employed	O
to	O
solve	O
problems	O
from	O
both	O
the	O
computer	B-Task
vision	I-Task
and	O
medical	B-Task
image	I-Task
analysis	I-Task
fields	I-Task
.	O
	
Despite	O
their	O
popularity	O
,	O
most	O
approaches	O
are	O
only	O
able	O
to	O
process	O
2D	O
images	O
while	O
most	O
medical	O
data	O
used	O
in	O
clinical	O
practice	O
consists	O
of	O
3D	O
volumes	O
.	O
	
In	O
this	O
work	O
we	O
propose	O
an	O
approach	O
to	O
3D	B-Task
image	I-Task
segmentation	I-Task
based	O
on	O
a	O
volumetric	B-Method
,	I-Method
fully	I-Method
convolutional	I-Method
,	I-Method
neural	I-Method
network	I-Method
.	O
	
Our	O
CNN	B-Method
is	O
trained	O
end	O
-	O
to	O
-	O
end	O
on	O
MRI	O
volumes	O
depicting	O
prostate	O
,	O
and	O
learns	O
to	O
predict	O
segmentation	B-Task
for	O
the	O
whole	O
volume	O
at	O
once	O
.	O
	
We	O
introduce	O
a	O
novel	O
objective	B-Method
function	I-Method
,	O
that	O
we	O
optimise	O
during	O
training	B-Task
,	O
based	O
on	O
Dice	B-Method
coefficient	O
.	O
	
In	O
this	O
way	O
we	O
can	O
deal	O
with	O
situations	O
where	O
there	O
is	O
a	O
strong	O
imbalance	O
between	O
the	O
number	O
of	O
foreground	O
and	O
background	O
voxels	O
.	O
	
To	O
cope	O
with	O
the	O
limited	O
number	O
of	O
annotated	O
volumes	O
available	O
for	O
training	O
,	O
we	O
augment	O
the	O
data	O
applying	O
random	B-Method
non	I-Method
-	I-Method
linear	I-Method
transformations	I-Method
and	O
histogram	B-Method
matching	I-Method
.	O
	
We	O
show	O
in	O
our	O
experimental	O
evaluation	O
that	O
our	O
approach	O
achieves	O
good	O
performances	O
on	O
challenging	O
test	O
data	O
while	O
requiring	O
only	O
a	O
fraction	O
of	O
the	O
processing	B-Metric
time	I-Metric
needed	O
by	O
other	O
previous	O
methods	O
.	O
	
section	O
:	O
Introduction	O
and	O
Related	O
Work	O
	
Recent	O
research	O
in	O
computer	B-Task
vision	I-Task
and	O
pattern	B-Task
recognition	I-Task
has	O
highlighted	O
the	O
capabilities	O
of	O
Convolutional	B-Method
Neural	I-Method
Networks	I-Method
(	O
CNNs	B-Method
)	O
to	O
solve	O
challenging	O
tasks	O
such	O
as	O
classification	B-Task
,	O
segmentation	B-Task
and	O
object	B-Task
detection	I-Task
,	O
achieving	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performances	O
.	O
	
This	O
success	O
has	O
been	O
attributed	O
to	O
the	O
ability	O
of	O
CNNs	B-Method
to	O
learn	O
a	O
hierarchical	B-Method
representation	I-Method
of	O
raw	O
input	O
data	O
,	O
without	O
relying	O
on	O
handcrafted	O
features	O
.	O
	
As	O
the	O
inputs	O
are	O
processed	O
through	O
the	O
network	B-Method
layers	I-Method
,	O
the	O
level	O
of	O
abstraction	O
of	O
the	O
resulting	O
features	O
increases	O
.	O
	
Shallower	O
layers	O
grasp	O
local	O
information	O
while	O
deeper	O
layers	O
use	O
filters	O
whose	O
receptive	O
fields	O
are	O
much	O
broader	O
that	O
therefore	O
capture	O
global	O
information	O
.	O
	
Segmentation	B-Task
is	O
a	O
highly	O
relevant	O
task	O
in	O
medical	B-Task
image	I-Task
analysis	I-Task
.	O
	
Automatic	B-Task
delineation	I-Task
of	I-Task
organs	I-Task
and	I-Task
structures	I-Task
of	I-Task
interest	I-Task
is	O
often	O
necessary	O
to	O
perform	O
tasks	O
such	O
as	O
visual	B-Task
augmentation	I-Task
,	O
computer	B-Task
assisted	I-Task
diagnosis	I-Task
,	O
interventions	B-Task
and	O
extraction	B-Task
of	I-Task
quantitative	I-Task
indices	I-Task
from	O
images	O
.	O
	
In	O
particular	O
,	O
since	O
diagnostic	B-Task
and	O
interventional	B-Task
imagery	I-Task
often	O
consists	O
of	O
3D	O
images	O
,	O
being	O
able	O
to	O
perform	O
volumetric	B-Task
segmentations	I-Task
by	O
taking	O
into	O
account	O
the	O
whole	O
volume	O
content	O
at	O
once	O
,	O
has	O
a	O
particular	O
relevance	O
.	O
	
In	O
this	O
work	O
,	O
we	O
aim	O
to	O
segment	O
prostate	O
MRI	O
volumes	O
.	O
	
This	O
is	O
a	O
challenging	O
task	O
due	O
to	O
the	O
wide	O
range	O
of	O
appearance	O
the	O
prostate	O
can	O
assume	O
in	O
different	O
scans	O
due	O
to	O
deformations	O
and	O
variations	O
of	O
the	O
intensity	O
distribution	O
.	O
	
Moreover	O
,	O
MRI	O
volumes	O
are	O
often	O
affected	O
by	O
artefacts	O
and	O
distortions	O
due	O
to	O
field	O
inhomogeneity	O
.	O
	
Prostate	B-Task
segmentation	I-Task
is	O
nevertheless	O
an	O
important	O
task	O
having	O
clinical	O
relevance	O
both	O
during	O
diagnosis	B-Task
,	O
where	O
the	O
volume	O
of	O
the	O
prostate	O
needs	O
to	O
be	O
assessed	O
,	O
and	O
during	O
treatment	B-Task
planning	I-Task
,	O
where	O
the	O
estimate	O
of	O
the	O
anatomical	O
boundary	O
needs	O
to	O
be	O
accurate	O
.	O
	
CNNs	B-Method
have	O
been	O
recently	O
used	O
for	O
medical	B-Task
image	I-Task
segmentation	I-Task
.	O
	
Early	O
approaches	O
obtain	O
anatomy	B-Task
delineation	I-Task
in	O
images	O
or	O
volumes	O
by	O
performing	O
patch	B-Method
-	I-Method
wise	I-Method
image	I-Method
classification	I-Method
.	O
	
Such	O
segmentations	O
are	O
obtained	O
by	O
only	O
considering	O
local	O
context	O
and	O
therefore	O
are	O
prone	O
to	O
failure	O
,	O
especially	O
in	O
challenging	O
modalities	O
such	O
as	O
ultrasound	B-Task
,	O
where	O
a	O
high	O
number	O
of	O
mis	O
-	O
classified	O
voxel	O
are	O
to	O
be	O
expected	O
.	O
	
Post	B-Method
-	I-Method
processing	I-Method
approaches	I-Method
such	O
as	O
connected	B-Method
components	I-Method
analysis	I-Method
normally	O
yield	O
no	O
improvement	O
and	O
therefore	O
,	O
more	O
recent	O
works	O
,	O
propose	O
to	O
use	O
the	O
network	B-Method
predictions	I-Method
in	O
combination	O
with	O
Markov	B-Method
random	I-Method
fields	I-Method
,	O
voting	B-Method
strategies	I-Method
or	O
more	O
traditional	O
approaches	O
such	O
as	O
level	B-Method
-	I-Method
sets	I-Method
.	O
	
Patch	B-Method
-	I-Method
wise	I-Method
approaches	I-Method
also	O
suffer	O
from	O
efficiency	B-Metric
issues	I-Metric
.	O
	
When	O
densely	O
extracted	O
patches	O
are	O
processed	O
in	O
a	O
CNN	B-Method
,	O
a	O
high	O
number	O
of	O
computations	O
is	O
redundant	O
and	O
therefore	O
the	O
total	O
algorithm	B-Metric
runtime	I-Metric
is	O
high	O
.	O
	
In	O
this	O
case	O
,	O
more	O
efficient	O
computational	B-Method
schemes	I-Method
can	O
be	O
adopted	O
.	O
	
Fully	B-Method
convolutional	I-Method
network	I-Method
trained	O
end	O
-	O
to	O
-	O
end	O
were	O
so	O
far	O
applied	O
only	O
to	O
2D	O
images	O
both	O
in	O
computer	B-Task
vision	I-Task
and	O
microscopy	B-Task
image	I-Task
analysis	I-Task
.	O
	
These	O
models	O
,	O
which	O
served	O
as	O
an	O
inspiration	O
for	O
our	O
work	O
,	O
employed	O
different	O
network	B-Method
architectures	I-Method
and	O
were	O
trained	O
to	O
predict	O
a	O
segmentation	O
mask	O
,	O
delineating	O
the	O
structures	O
of	O
interest	O
,	O
for	O
the	O
whole	O
image	O
.	O
	
In	O
a	O
pre	O
-	O
trained	O
VGG	B-Method
network	I-Method
architecture	I-Method
was	O
used	O
in	O
conjunction	O
with	O
its	O
mirrored	B-Method
,	I-Method
de	I-Method
-	I-Method
convolutional	I-Method
,	O
equivalent	O
to	O
segment	O
RGB	O
images	O
by	O
leveraging	O
the	O
descriptive	O
power	O
of	O
the	O
features	O
extracted	O
by	O
the	O
innermost	B-Method
layer	I-Method
.	O
	
In	O
three	O
fully	B-Method
convolutional	I-Method
deep	I-Method
neural	I-Method
networks	I-Method
,	O
pre	O
-	O
trained	O
on	O
a	O
classification	B-Task
task	I-Task
,	O
were	O
refined	O
to	O
produce	O
segmentations	B-Task
while	O
in	O
a	O
brand	O
new	O
CNN	B-Method
model	I-Method
,	O
especially	O
tailored	O
to	O
tackle	O
biomedical	B-Task
image	I-Task
analysis	I-Task
problems	I-Task
in	O
2D	O
,	O
was	O
proposed	O
.	O
	
In	O
this	O
work	O
we	O
present	O
our	O
approach	O
to	O
medical	B-Task
image	I-Task
segmentation	I-Task
that	O
leverages	O
the	O
power	O
of	O
a	O
fully	B-Method
convolutional	I-Method
neural	I-Method
networks	I-Method
,	O
trained	O
end	O
-	O
to	O
-	O
end	O
,	O
to	O
process	O
MRI	O
volumes	O
.	O
	
Differently	O
from	O
other	O
recent	O
approaches	O
we	O
refrain	O
from	O
processing	O
the	O
input	O
volumes	O
slice	O
-	O
wise	O
	
and	O
we	O
propose	O
to	O
use	O
volumetric	B-Task
convolutions	I-Task
instead	O
.	O
	
We	O
propose	O
a	O
novel	O
objective	B-Method
function	I-Method
based	O
on	O
Dice	B-Method
coefficient	I-Method
maximisation	I-Method
,	O
that	O
we	O
optimise	O
during	O
training	O
.	O
	
We	O
demonstrate	O
fast	O
and	O
accurate	O
results	O
on	O
prostate	O
MRI	O
test	O
volumes	O
and	O
we	O
provide	O
direct	O
comparison	O
with	O
other	O
methods	O
which	O
were	O
evaluated	O
on	O
the	O
same	O
test	O
data	O
.	O
	
section	O
:	O
Method	O
	
In	O
Figure	O
[	O
reference	O
]	O
we	O
provide	O
a	O
schematic	O
representation	O
of	O
our	O
convolutional	B-Method
neural	I-Method
network	I-Method
.	O
	
We	O
perform	O
convolutions	B-Method
aiming	O
to	O
both	O
extract	O
features	O
from	O
the	O
data	O
and	O
,	O
at	O
the	O
end	O
of	O
each	O
stage	O
,	O
to	O
reduce	O
its	O
resolution	O
by	O
using	O
appropriate	O
stride	O
.	O
	
The	O
left	O
part	O
of	O
the	O
network	O
consists	O
of	O
a	O
compression	B-Method
path	I-Method
,	O
while	O
the	O
right	O
part	O
decompresses	O
the	O
signal	O
until	O
its	O
original	O
size	O
is	O
reached	O
.	O
	
Convolutions	B-Method
are	O
all	O
applied	O
with	O
appropriate	O
padding	B-Method
.	O
	
The	O
left	O
side	O
of	O
the	O
network	O
is	O
divided	O
in	O
different	O
stages	O
that	O
operate	O
at	O
different	O
resolutions	O
.	O
	
Each	O
stage	O
comprises	O
one	O
to	O
three	O
convolutional	B-Method
layers	I-Method
.	O
	
Similarly	O
to	O
the	O
approach	O
presented	O
in	O
,	O
we	O
formulate	O
each	O
stage	O
such	O
that	O
it	O
learns	O
a	O
residual	O
function	O
:	O
the	O
input	O
of	O
each	O
stage	O
is	O
(	O
a	O
)	O
used	O
in	O
the	O
convolutional	B-Method
layers	I-Method
and	O
processed	O
through	O
the	O
non	O
-	O
linearities	O
and	O
(	O
b	O
)	O
added	O
to	O
the	O
output	O
of	O
the	O
last	O
convolutional	B-Method
layer	I-Method
of	O
that	O
stage	O
in	O
order	O
to	O
enable	O
learning	O
a	O
residual	O
function	O
.	O
	
As	O
confirmed	O
by	O
our	O
empirical	O
observations	O
,	O
this	O
architecture	O
ensures	O
convergence	O
in	O
a	O
fraction	O
of	O
the	O
time	O
required	O
by	O
a	O
similar	O
network	O
that	O
does	O
not	O
learn	O
residual	O
functions	O
.	O
	
The	O
convolutions	B-Method
performed	O
in	O
each	O
stage	O
use	O
volumetric	B-Method
kernels	I-Method
having	O
size	O
voxels	O
.	O
	
As	O
the	O
data	O
proceeds	O
through	O
different	O
stages	O
along	O
the	O
compression	O
path	O
,	O
its	O
resolution	O
is	O
reduced	O
.	O
	
This	O
is	O
performed	O
through	O
convolution	B-Method
with	O
voxels	B-Method
wide	I-Method
kernels	I-Method
applied	O
with	O
stride	O
(	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
Since	O
the	O
second	O
operation	O
extracts	O
features	O
by	O
considering	O
only	O
non	O
overlapping	O
volume	O
patches	O
,	O
the	O
size	O
of	O
the	O
resulting	O
feature	O
maps	O
is	O
halved	O
.	O
	
This	O
strategy	O
serves	O
a	O
similar	O
purpose	O
as	O
pooling	B-Method
layers	I-Method
that	O
,	O
motivated	O
by	O
and	O
other	O
works	O
discouraging	O
the	O
use	O
of	O
max	B-Method
-	I-Method
pooling	I-Method
operations	I-Method
in	O
CNNs	B-Method
,	O
have	O
been	O
replaced	O
in	O
our	O
approach	O
by	O
convolutional	B-Method
ones	I-Method
.	O
	
Moreover	O
,	O
since	O
the	O
number	O
of	O
feature	O
channels	O
doubles	O
at	O
each	O
stage	O
of	O
the	O
compression	B-Method
path	I-Method
of	O
the	O
V	B-Method
-	I-Method
Net	I-Method
,	O
and	O
due	O
to	O
the	O
formulation	O
of	O
the	O
model	O
as	O
a	O
residual	B-Method
network	I-Method
,	O
we	O
resort	O
to	O
these	O
convolution	B-Method
operations	I-Method
to	O
double	O
the	O
number	O
of	O
feature	O
maps	O
as	O
we	O
reduce	O
their	O
resolution	O
.	O
	
PReLu	O
non	O
linearities	O
are	O
applied	O
throughout	O
the	O
network	O
.	O
	
Replacing	O
pooling	B-Method
operations	I-Method
with	O
convolutional	B-Method
ones	I-Method
results	O
also	O
to	O
networks	O
that	O
,	O
depending	O
on	O
the	O
specific	O
implementation	O
,	O
can	O
have	O
a	O
smaller	O
memory	O
footprint	O
during	O
training	O
,	O
due	O
to	O
the	O
fact	O
that	O
no	O
switches	O
mapping	O
the	O
output	O
of	O
pooling	O
layers	O
back	O
to	O
their	O
inputs	O
are	O
needed	O
for	O
back	B-Method
-	I-Method
propagation	I-Method
,	O
and	O
that	O
can	O
be	O
better	O
understood	O
and	O
analysed	O
by	O
applying	O
only	O
de	B-Method
-	I-Method
convolutions	I-Method
instead	O
of	O
un	B-Method
-	I-Method
pooling	I-Method
operations	I-Method
.	O
	
Downsampling	B-Method
allows	O
us	O
to	O
reduce	O
the	O
size	O
of	O
the	O
signal	O
presented	O
as	O
input	O
and	O
to	O
increase	O
the	O
receptive	O
field	O
of	O
the	O
features	O
being	O
computed	O
in	O
subsequent	O
network	B-Method
layers	I-Method
.	O
	
Each	O
of	O
the	O
stages	O
of	O
the	O
left	O
part	O
of	O
the	O
network	O
,	O
computes	O
a	O
number	O
of	O
features	O
which	O
is	O
two	O
times	O
higher	O
than	O
the	O
one	O
of	O
the	O
previous	O
layer	O
.	O
	
The	O
right	O
portion	O
of	O
the	O
network	O
extracts	O
features	O
and	O
expands	O
the	O
spatial	O
support	O
of	O
the	O
lower	O
resolution	O
feature	O
maps	O
in	O
order	O
to	O
gather	O
and	O
assemble	O
the	O
necessary	O
information	O
to	O
output	O
a	O
two	B-Task
channel	I-Task
volumetric	I-Task
segmentation	I-Task
.	O
	
The	O
two	O
features	O
maps	O
computed	O
by	O
the	O
very	O
last	O
convolutional	B-Method
layer	I-Method
,	O
having	O
kernel	O
size	O
and	O
producing	O
outputs	O
of	O
the	O
same	O
size	O
as	O
the	O
input	O
volume	O
,	O
are	O
converted	O
to	O
probabilistic	B-Method
segmentations	I-Method
of	O
the	O
foreground	O
and	O
background	O
regions	O
by	O
applying	O
soft	B-Method
-	I-Method
max	I-Method
voxelwise	I-Method
.	O
	
After	O
each	O
stage	O
of	O
the	O
right	O
portion	O
of	O
the	O
CNN	B-Method
,	O
a	O
de	B-Method
-	I-Method
convolution	I-Method
operation	I-Method
is	O
employed	O
in	O
order	O
increase	O
the	O
size	O
of	O
the	O
inputs	O
(	O
Figure	O
[	O
reference	O
]	O
)	O
followed	O
by	O
one	O
to	O
three	O
convolutional	B-Method
layers	I-Method
involving	O
half	O
the	O
number	O
of	O
kernels	O
employed	O
in	O
the	O
previous	O
layer	O
.	O
	
Similar	O
to	O
the	O
left	O
part	O
of	O
the	O
network	O
,	O
also	O
in	O
this	O
case	O
we	O
resort	O
to	O
learn	O
residual	O
functions	O
in	O
the	O
convolutional	B-Method
stages	I-Method
.	O
	
Similarly	O
to	O
,	O
we	O
forward	O
the	O
features	O
extracted	O
from	O
early	O
stages	O
of	O
the	O
left	O
part	O
of	O
the	O
CNN	B-Method
to	O
the	O
right	O
part	O
.	O
	
This	O
is	O
schematically	O
represented	O
in	O
Figure	O
[	O
reference	O
]	O
by	O
horizontal	O
connections	O
.	O
	
In	O
this	O
way	O
we	O
gather	O
fine	O
grained	O
detail	O
that	O
would	O
be	O
otherwise	O
lost	O
in	O
the	O
compression	O
path	O
and	O
we	O
improve	O
the	O
quality	O
of	O
the	O
final	O
contour	B-Task
prediction	I-Task
.	O
	
We	O
also	O
observed	O
that	O
when	O
these	O
connections	O
improve	O
the	O
convergence	B-Metric
time	I-Metric
of	O
the	O
model	O
.	O
	
We	O
report	O
in	O
Table	O
[	O
reference	O
]	O
the	O
receptive	O
fields	O
of	O
each	O
network	B-Method
layer	I-Method
,	O
showing	O
the	O
fact	O
that	O
the	O
innermost	O
portion	O
of	O
our	O
CNN	B-Method
already	O
captures	O
the	O
content	O
of	O
the	O
whole	O
input	O
volume	O
.	O
	
We	O
believe	O
that	O
this	O
characteristic	O
is	O
important	O
during	O
segmentation	B-Task
of	I-Task
poorly	I-Task
visible	I-Task
anatomy	I-Task
:	O
the	O
features	O
computed	O
in	O
the	O
deepest	O
layer	O
perceive	O
the	O
whole	O
anatomy	O
of	O
interest	O
at	O
once	O
,	O
since	O
they	O
are	O
computed	O
from	O
data	O
having	O
a	O
spatial	O
support	O
much	O
larger	O
than	O
the	O
typical	O
size	O
of	O
the	O
anatomy	O
we	O
seek	O
to	O
delineate	O
,	O
and	O
therefore	O
impose	O
global	O
constraints	O
.	O
	
section	O
:	O
Dice	B-Method
loss	O
layer	O
	
The	O
network	B-Method
predictions	I-Method
,	O
which	O
consist	O
of	O
two	O
volumes	O
having	O
the	O
same	O
resolution	O
as	O
the	O
original	O
input	O
data	O
,	O
are	O
processed	O
through	O
a	O
soft	B-Method
-	I-Method
max	I-Method
layer	I-Method
which	O
outputs	O
the	O
probability	O
of	O
each	O
voxel	O
to	O
belong	O
to	O
foreground	O
and	O
to	O
background	O
.	O
	
In	O
medical	O
volumes	O
such	O
as	O
the	O
ones	O
we	O
are	O
processing	O
in	O
this	O
work	O
,	O
it	O
is	O
not	O
uncommon	O
that	O
the	O
anatomy	O
of	O
interest	O
occupies	O
only	O
a	O
very	O
small	O
region	O
of	O
the	O
scan	O
.	O
	
This	O
often	O
causes	O
the	O
learning	B-Method
process	I-Method
to	O
get	O
trapped	O
in	O
local	O
minima	O
of	O
the	O
loss	O
function	O
yielding	O
a	O
network	O
whose	O
predictions	O
are	O
strongly	O
biased	O
towards	O
background	O
.	O
	
As	O
a	O
result	O
the	O
foreground	O
region	O
is	O
often	O
missing	O
or	O
only	O
partially	O
detected	O
.	O
	
Several	O
previous	O
approaches	O
resorted	O
to	O
loss	B-Method
functions	I-Method
based	O
on	O
sample	B-Method
re	I-Method
-	I-Method
weighting	I-Method
where	O
foreground	O
regions	O
are	O
given	O
more	O
importance	O
than	O
background	O
ones	O
during	O
learning	B-Task
.	O
	
In	O
this	O
work	O
we	O
propose	O
a	O
novel	O
objective	B-Metric
function	I-Metric
based	O
on	O
dice	B-Method
coefficient	I-Method
,	O
which	O
is	O
a	O
quantity	O
ranging	O
between	O
and	O
which	O
we	O
aim	O
to	O
maximise	O
.	O
	
The	O
dice	B-Method
coefficient	I-Method
between	O
two	O
binary	O
volumes	O
can	O
be	O
written	O
as	O
where	O
the	O
sums	O
run	O
over	O
the	O
voxels	O
,	O
of	O
the	O
predicted	O
binary	O
segmentation	O
volume	O
and	O
the	O
ground	O
truth	O
binary	O
volume	O
.	O
	
This	O
formulation	O
of	O
Dice	B-Method
can	O
be	O
differentiated	O
yielding	O
the	O
gradient	O
computed	O
with	O
respect	O
to	O
the	O
-	O
th	O
voxel	O
of	O
the	O
prediction	O
.	O
	
Using	O
this	O
formulation	O
we	O
do	O
not	O
need	O
to	O
assign	O
weights	O
to	O
samples	O
of	O
different	O
classes	O
to	O
establish	O
the	O
right	O
balance	O
between	O
foreground	O
and	O
background	O
voxels	O
,	O
and	O
we	O
obtain	O
results	O
that	O
we	O
experimentally	O
observed	O
are	O
much	O
better	O
than	O
the	O
ones	O
computed	O
through	O
the	O
same	O
network	O
trained	O
optimising	O
a	O
multinomial	B-Method
logistic	I-Method
loss	I-Method
with	O
sample	B-Method
re	I-Method
-	I-Method
weighting	I-Method
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
subsection	O
:	O
Training	O
	
Our	O
CNN	B-Method
is	O
trained	O
end	O
-	O
to	O
-	O
end	O
on	O
a	O
dataset	O
of	O
prostate	O
scans	O
in	O
MRI	O
.	O
	
An	O
example	O
of	O
the	O
typical	O
content	O
of	O
such	O
volumes	O
is	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
All	O
the	O
volumes	O
processed	O
by	O
the	O
network	O
have	O
fixed	O
size	O
of	O
voxels	O
and	O
a	O
spatial	O
resolution	O
of	O
millimeters	O
.	O
	
Annotated	O
medical	O
volumes	O
are	O
not	O
easy	O
to	O
obtain	O
due	O
to	O
the	O
fact	O
that	O
one	O
or	O
more	O
experts	O
are	O
required	O
to	O
manually	O
trace	O
a	O
reliable	O
ground	O
truth	O
annotation	O
and	O
that	O
there	O
is	O
a	O
cost	O
associated	O
with	O
their	O
acquisition	O
.	O
	
In	O
this	O
work	O
we	O
found	O
necessary	O
to	O
augment	O
the	O
original	O
training	O
dataset	O
in	O
order	O
to	O
obtain	O
robustness	B-Metric
and	O
increased	O
precision	B-Metric
on	O
the	O
test	O
dataset	O
.	O
	
During	O
every	O
training	O
iteration	O
,	O
we	O
fed	O
as	O
input	O
to	O
the	O
network	O
randomly	O
deformed	O
versions	O
of	O
the	O
training	O
images	O
by	O
using	O
a	O
dense	O
deformation	O
field	O
obtained	O
through	O
a	O
grid	O
of	O
control	O
-	O
points	O
and	O
B	B-Method
-	I-Method
spline	I-Method
interpolation	I-Method
.	O
	
This	O
augmentation	O
has	O
been	O
performed	O
”	O
on	O
-	O
the	O
-	O
fly	O
”	O
,	O
prior	O
to	O
each	O
optimisation	B-Task
iteration	I-Task
,	O
in	O
order	O
to	O
alleviate	O
the	O
otherwise	O
excessive	O
storage	O
requirements	O
.	O
	
Additionally	O
we	O
vary	O
the	O
intensity	O
distribution	O
of	O
the	O
data	O
by	O
adapting	O
,	O
using	O
histogram	B-Method
matching	I-Method
,	O
the	O
intensity	O
distributions	O
of	O
the	O
training	O
volumes	O
used	O
in	O
each	O
iteration	O
,	O
to	O
the	O
ones	O
of	O
other	O
randomly	O
chosen	O
scans	O
belonging	O
to	O
the	O
dataset	O
.	O
	
subsection	O
:	O
Testing	O
	
A	O
Previously	O
unseen	O
MRI	O
volume	O
can	O
be	O
segmented	O
by	O
processing	O
it	O
in	O
a	O
feed	O
-	O
forward	O
manner	O
through	O
the	O
network	O
.	O
	
The	O
output	O
of	O
the	O
last	O
convolutional	B-Method
layer	I-Method
,	O
after	O
soft	B-Method
-	I-Method
max	I-Method
,	O
consists	O
of	O
a	O
probability	O
map	O
for	O
background	O
and	O
foreground	O
.	O
	
The	O
voxels	O
having	O
higher	O
probability	O
(	O
)	O
to	O
belong	O
to	O
the	O
foreground	O
than	O
to	O
the	O
background	O
are	O
considered	O
part	O
of	O
the	O
anatomy	O
.	O
	
section	O
:	O
Results	O
	
We	O
trained	O
our	O
method	O
on	O
MRI	O
volumes	O
,	O
and	O
the	O
relative	O
manual	O
ground	O
truth	O
annotation	O
,	O
obtained	O
from	O
the	O
”	B-Material
PROMISE2012	I-Material
”	I-Material
challenge	I-Material
dataset	I-Material
.	O
	
This	O
dataset	O
contains	O
medical	O
data	O
acquired	O
in	O
different	O
hospitals	O
,	O
using	O
different	O
equipment	O
and	O
different	O
acquisition	O
protocols	O
.	O
	
The	O
data	O
in	O
this	O
dataset	O
is	O
representative	O
of	O
the	O
clinical	O
variability	O
and	O
challenges	O
encountered	O
in	O
clinical	O
settings	O
.	O
	
As	O
previously	O
stated	O
we	O
massively	O
augmented	O
this	O
dataset	O
through	O
random	B-Method
transformation	I-Method
performed	O
in	O
each	O
training	O
iteration	O
,	O
for	O
each	O
mini	O
-	O
batch	O
fed	O
to	O
the	O
network	O
.	O
	
The	O
mini	O
-	O
batches	O
used	O
in	O
our	O
implementation	O
contained	O
two	O
volumes	O
each	O
,	O
mainly	O
due	O
to	O
the	O
high	O
memory	O
requirement	O
of	O
the	O
model	O
during	O
training	O
.	O
	
We	O
used	O
a	O
momentum	O
of	O
and	O
a	O
initial	O
learning	B-Metric
rate	I-Metric
of	O
which	O
decreases	O
by	O
one	O
order	O
of	O
magnitude	O
every	O
K	O
iterations	O
.	O
	
We	O
tested	O
V	B-Method
-	I-Method
Net	I-Method
on	O
MRI	O
volumes	O
depicting	O
prostate	O
whose	O
ground	O
truth	O
annotation	O
was	O
secret	O
.	O
	
All	O
the	O
results	O
reported	O
in	O
this	O
section	O
of	O
the	O
paper	O
were	O
obtained	O
directly	O
from	O
the	O
organisers	O
of	O
the	O
challenge	O
after	O
submitting	O
the	O
segmentation	B-Task
obtained	O
through	O
our	O
approach	O
.	O
	
The	O
test	O
set	O
was	O
representative	O
of	O
the	O
clinical	O
variability	O
encountered	O
in	O
prostate	O
scans	O
in	O
real	O
clinical	O
settings	O
.	O
	
We	O
evaluated	O
the	O
approach	O
performance	O
in	O
terms	O
of	O
Dice	B-Method
coefficient	O
,	O
Hausdorff	B-Metric
distance	I-Metric
of	O
the	O
predicted	B-Metric
delineation	I-Metric
to	O
the	O
ground	O
truth	O
annotation	O
and	O
in	O
terms	O
of	O
score	B-Metric
obtained	O
on	O
the	O
challenge	O
data	O
as	O
computed	O
by	O
the	O
organisers	O
of	O
”	O
PROMISE	B-Material
2012	I-Material
”	O
.	O
	
The	O
results	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
and	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Our	O
implementation	O
was	O
realised	O
in	O
python	B-Method
,	O
using	O
a	O
custom	O
version	O
of	O
the	O
Caffe	B-Method
framework	I-Method
which	O
was	O
enabled	O
to	O
perform	O
volumetric	B-Task
convolutions	I-Task
via	O
CuDNN	B-Method
v3	I-Method
.	O
	
All	O
the	O
trainings	O
and	O
experiments	O
were	O
ran	O
on	O
a	O
standard	O
workstation	O
equipped	O
with	O
GB	O
of	O
memory	O
,	O
an	O
Intel	O
(	O
R	O
)	O
	
Core	O
(	O
TM	O
)	O
	
i7	O
-	O
5820	O
K	O
CPU	O
working	O
at	O
3.30GHz	O
,	O
and	O
a	O
NVidia	O
GTX	O
1080	O
with	O
GB	O
of	O
video	O
memory	O
.	O
	
We	O
let	O
our	O
model	O
train	O
for	O
hours	O
,	O
or	O
K	O
iterations	O
circa	O
,	O
and	O
we	O
were	O
able	O
to	O
segment	O
a	O
previously	O
unseen	O
volume	O
in	O
circa	O
second	O
.	O
	
The	O
datasets	O
were	O
first	O
normalised	O
using	O
the	O
N4	B-Method
bias	I-Method
filed	I-Method
correction	I-Method
function	I-Method
of	O
the	O
ANTs	B-Method
framework	I-Method
and	O
then	O
resampled	O
to	O
a	O
common	O
resolution	O
of	O
mm	O
.	O
	
We	O
applied	O
random	O
deformations	O
to	O
the	O
scans	O
used	O
for	O
training	O
by	O
varying	O
the	O
position	O
of	O
the	O
control	O
points	O
with	O
random	O
quantities	O
obtained	O
from	O
gaussian	B-Method
distribution	I-Method
with	O
zero	O
mean	O
and	O
voxels	O
standard	O
deviation	O
.	O
	
Qualitative	O
results	O
can	O
be	O
seen	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
section	O
:	O
Conclusion	O
	
We	O
presented	O
and	O
approach	O
based	O
on	O
a	O
volumetric	O
convolutional	B-Method
neural	I-Method
network	I-Method
that	O
performs	O
segmentation	B-Task
of	I-Task
MRI	I-Task
prostate	I-Task
volumes	I-Task
in	O
a	O
fast	O
and	O
accurate	O
manner	O
.	O
	
We	O
introduced	O
a	O
novel	O
objective	B-Metric
function	I-Metric
that	O
we	O
optimise	O
during	O
training	B-Task
based	O
on	O
the	O
Dice	B-Method
overlap	I-Method
coefficient	I-Method
between	O
the	O
predicted	O
segmentation	O
and	O
the	O
ground	O
truth	O
annotation	O
.	O
	
Our	O
Dice	B-Method
loss	I-Method
layer	I-Method
does	O
not	O
need	O
sample	B-Method
re	I-Method
-	I-Method
weighting	I-Method
when	O
the	O
amount	O
of	O
background	O
and	O
foreground	O
pixels	O
is	O
strongly	O
unbalanced	O
and	O
is	O
indicated	O
for	O
binary	B-Task
segmentation	I-Task
tasks	I-Task
.	O
	
Although	O
we	O
inspired	O
our	O
architecture	O
to	O
the	O
one	O
proposed	O
in	O
,	O
we	O
divided	O
it	O
into	O
stages	O
that	O
learn	O
residuals	O
and	O
,	O
as	O
empirically	O
observed	O
,	O
improve	O
both	O
results	O
and	O
convergence	B-Metric
time	I-Metric
.	O
	
Future	O
works	O
will	O
aim	O
at	O
segmenting	O
volumes	O
containing	O
multiple	O
regions	O
in	O
other	O
modalities	O
such	O
as	O
ultrasound	O
and	O
at	O
higher	O
resolutions	O
by	O
splitting	O
the	O
network	O
over	O
multiple	O
GPUs	O
.	O
	
section	O
:	O
Acknowledgement	O
	
We	O
would	O
like	O
to	O
acknowledge	O
NVidia	O
corporation	O
,	O
that	O
donated	O
a	O
Tesla	O
K40	O
GPU	O
to	O
our	O
group	O
enabling	O
this	O
research	O
,	O
Dr.	O
Geert	O
Litjens	O
who	O
dedicated	O
some	O
of	O
his	O
time	O
to	O
evaluate	O
our	O
results	O
against	O
the	O
ground	O
truth	O
of	O
the	O
PROMISE	B-Material
2012	I-Material
dataset	I-Material
and	O
Ms.	O
Iro	O
Laina	O
for	O
her	O
support	O
to	O
this	O
project	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Bi	B-Method
-	I-Method
Directional	I-Method
Attention	I-Method
Flow	I-Method
for	O
Machine	B-Task
Comprehension	I-Task
	
Machine	B-Task
comprehension	I-Task
(	O
MC	B-Task
)	O
,	O
answering	O
a	O
query	O
about	O
a	O
given	O
context	O
paragraph	O
,	O
requires	O
modeling	O
complex	O
interactions	O
between	O
the	O
context	O
and	O
the	O
query	O
.	O
	
Recently	O
,	O
attention	B-Method
mechanisms	I-Method
have	O
been	O
successfully	O
extended	O
to	O
MC	B-Task
.	O
	
Typically	O
these	O
methods	O
use	O
attention	O
to	O
focus	O
on	O
a	O
small	O
portion	O
of	O
the	O
context	O
and	O
summarize	O
it	O
with	O
a	O
fixed	O
-	O
size	O
vector	O
,	O
couple	O
attentions	O
temporally	O
,	O
and	O
/	O
or	O
often	O
form	O
a	O
uni	O
-	O
directional	O
attention	O
.	O
	
In	O
this	O
paper	O
we	O
introduce	O
the	O
Bi	B-Method
-	I-Method
Directional	I-Method
Attention	I-Method
Flow	I-Method
(	O
BiDAF	O
)	O
network	O
,	O
a	O
multi	B-Method
-	I-Method
stage	I-Method
hierarchical	I-Method
process	I-Method
that	O
represents	O
the	O
context	O
at	O
different	O
levels	O
of	O
granularity	O
and	O
uses	O
bi	B-Method
-	I-Method
directional	I-Method
attention	I-Method
flow	I-Method
mechanism	I-Method
to	O
obtain	O
a	O
query	B-Method
-	I-Method
aware	I-Method
context	I-Method
representation	I-Method
without	O
early	B-Task
summarization	I-Task
.	O
	
Our	O
experimental	O
evaluations	O
show	O
that	O
our	O
model	O
achieves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
in	O
Stanford	B-Material
Question	I-Material
Answering	I-Material
Dataset	I-Material
(	O
SQuAD	B-Material
)	O
and	O
CNN	B-Material
/	I-Material
DailyMail	I-Material
cloze	I-Material
test	I-Material
.	O
	
section	O
:	O
Introduction	O
	
The	O
tasks	O
of	O
machine	B-Task
comprehension	I-Task
(	I-Task
MC	I-Task
)	I-Task
and	O
question	B-Task
answering	I-Task
(	I-Task
QA	I-Task
)	O
have	O
gained	O
significant	O
popularity	O
over	O
the	O
past	O
few	O
years	O
within	O
the	O
natural	B-Task
language	I-Task
processing	I-Task
and	O
computer	B-Task
vision	I-Task
communities	I-Task
.	O
	
Systems	O
trained	O
end	O
-	O
to	O
-	O
end	O
now	O
achieve	O
promising	O
results	O
on	O
a	O
variety	O
of	O
tasks	O
in	O
the	O
text	O
and	O
image	O
domains	O
.	O
	
One	O
of	O
the	O
key	O
factors	O
to	O
the	O
advancement	O
has	O
been	O
the	O
use	O
of	O
neural	B-Method
attention	I-Method
mechanism	I-Method
,	O
which	O
enables	O
the	O
system	O
to	O
focus	O
on	O
a	O
targeted	O
area	O
within	O
a	O
context	O
paragraph	O
(	O
for	O
MC	B-Task
)	O
or	O
within	O
an	O
image	O
(	O
for	O
Visual	B-Task
QA	I-Task
)	O
,	O
that	O
is	O
most	O
relevant	O
to	O
answer	O
the	O
question	O
memnn	O
,	O
antol2015vqa	O
,	O
xiong2016dynamic	O
.	O
	
Attention	B-Method
mechanisms	I-Method
in	O
previous	O
works	O
typically	O
have	O
one	O
or	O
more	O
of	O
the	O
following	O
characteristics	O
.	O
	
First	O
,	O
the	O
computed	O
attention	O
weights	O
are	O
often	O
used	O
to	O
extract	O
the	O
most	O
relevant	O
information	O
from	O
the	O
context	O
for	O
answering	O
the	O
question	O
by	O
summarizing	O
the	O
context	O
into	O
a	O
fixed	O
-	O
size	O
vector	O
.	O
	
Second	O
,	O
in	O
the	O
text	O
domain	O
,	O
they	O
are	O
often	O
temporally	O
dynamic	O
,	O
whereby	O
the	O
attention	O
weights	O
at	O
the	O
current	O
time	O
step	O
are	O
a	O
function	O
of	O
the	O
attended	O
vector	O
at	O
the	O
previous	O
time	O
step	O
.	O
	
Third	O
,	O
they	O
are	O
usually	O
uni	O
-	O
directional	O
,	O
wherein	O
the	O
query	O
attends	O
on	O
the	O
context	O
paragraph	O
or	O
the	O
image	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
introduce	O
the	O
Bi	B-Method
-	I-Method
Directional	I-Method
Attention	I-Method
Flow	I-Method
(	O
BiDAF	O
)	O
network	O
,	O
a	O
hierarchical	B-Method
multi	I-Method
-	I-Method
stage	I-Method
architecture	I-Method
for	O
modeling	O
the	O
representations	O
of	O
the	O
context	O
paragraph	O
at	O
different	O
levels	O
of	O
granularity	O
(	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
BiDAF	B-Method
includes	O
character	O
-	O
level	O
,	O
word	O
-	O
level	O
,	O
and	O
contextual	O
embeddings	O
,	O
and	O
uses	O
bi	B-Method
-	I-Method
directional	I-Method
attention	I-Method
flow	O
to	O
obtain	O
a	O
query	B-Method
-	I-Method
aware	I-Method
context	I-Method
representation	I-Method
.	O
	
Our	O
attention	B-Method
mechanism	I-Method
offers	O
following	O
improvements	O
to	O
the	O
previously	O
popular	O
attention	B-Method
paradigms	I-Method
.	O
	
First	O
,	O
our	O
attention	B-Method
layer	I-Method
is	O
not	O
used	O
to	O
summarize	O
the	O
context	O
paragraph	O
into	O
a	O
fixed	O
-	O
size	O
vector	O
.	O
	
Instead	O
,	O
the	O
attention	O
is	O
computed	O
for	O
every	O
time	O
step	O
,	O
and	O
the	O
attended	O
vector	O
at	O
each	O
time	O
step	O
,	O
along	O
with	O
the	O
representations	O
from	O
previous	O
layers	O
,	O
is	O
allowed	O
to	O
flow	O
through	O
to	O
the	O
subsequent	O
modeling	B-Method
layer	I-Method
.	O
	
This	O
reduces	O
the	O
information	O
loss	O
caused	O
by	O
early	B-Task
summarization	I-Task
.	O
	
Second	O
,	O
we	O
use	O
a	O
memory	B-Method
-	I-Method
less	I-Method
attention	I-Method
mechanism	I-Method
.	O
	
That	O
is	O
,	O
while	O
we	O
iteratively	O
compute	O
attention	O
through	O
time	O
as	O
in	O
,	O
the	O
attention	O
at	O
each	O
time	O
step	O
is	O
a	O
function	O
of	O
only	O
the	O
query	O
and	O
the	O
context	O
paragraph	O
at	O
the	O
current	O
time	O
step	O
and	O
does	O
not	O
directly	O
depend	O
on	O
the	O
attention	O
at	O
the	O
previous	O
time	O
step	O
.	O
	
We	O
hypothesize	O
that	O
this	O
simplification	O
leads	O
to	O
the	O
division	O
of	O
labor	O
between	O
the	O
attention	B-Method
layer	I-Method
and	O
the	O
modeling	B-Method
layer	I-Method
.	O
	
It	O
forces	O
the	O
attention	B-Method
layer	I-Method
to	O
focus	O
on	O
learning	O
the	O
attention	O
between	O
the	O
query	O
and	O
the	O
context	O
,	O
and	O
enables	O
the	O
modeling	B-Method
layer	I-Method
to	O
focus	O
on	O
learning	O
the	O
interaction	O
within	O
the	O
query	B-Method
-	I-Method
aware	I-Method
context	I-Method
representation	I-Method
(	O
the	O
output	O
of	O
the	O
attention	B-Method
layer	I-Method
)	O
.	O
	
It	O
also	O
allows	O
the	O
attention	O
at	O
each	O
time	O
step	O
to	O
be	O
unaffected	O
from	O
incorrect	O
attendances	O
at	O
previous	O
time	O
steps	O
.	O
	
Our	O
experiments	O
show	O
that	O
memory	B-Task
-	I-Task
less	I-Task
attention	I-Task
gives	O
a	O
clear	O
advantage	O
over	O
dynamic	O
attention	O
.	O
	
Third	O
,	O
we	O
use	O
attention	B-Method
mechanisms	I-Method
in	O
both	O
directions	O
,	O
query	O
-	O
to	O
-	O
context	O
and	O
context	O
-	O
to	O
-	O
query	O
,	O
which	O
provide	O
complimentary	O
information	O
to	O
each	O
other	O
.	O
	
Our	O
BiDAF	B-Method
model	I-Method
outperforms	O
all	O
previous	O
approaches	O
on	O
the	O
highly	O
-	O
competitive	O
Stanford	B-Material
Question	I-Material
Answering	I-Material
Dataset	I-Material
	
(	O
SQuAD	B-Material
)	O
test	O
set	O
leaderboard	O
at	O
the	O
time	O
of	O
submission	O
.	O
	
With	O
a	O
modification	O
to	O
only	O
the	O
output	O
layer	O
,	O
BiDAF	B-Method
achieves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
the	O
CNN	B-Material
/	I-Material
DailyMail	I-Material
cloze	I-Material
test	I-Material
.	O
	
We	O
also	O
provide	O
an	O
in	O
-	O
depth	O
ablation	O
study	O
of	O
our	O
model	O
on	O
the	O
SQuAD	B-Material
development	O
set	O
,	O
visualize	O
the	O
intermediate	O
feature	O
spaces	O
in	O
our	O
model	O
,	O
and	O
analyse	O
its	O
performance	O
as	O
compared	O
to	O
a	O
more	O
traditional	O
language	B-Method
model	I-Method
for	O
machine	B-Task
comprehension	I-Task
rajpurkar2016squad	O
.	O
	
section	O
:	O
Model	O
	
Our	O
machine	B-Method
comprehension	I-Method
model	I-Method
is	O
a	O
hierarchical	B-Method
multi	I-Method
-	I-Method
stage	I-Method
process	I-Method
and	O
consists	O
of	O
six	O
layers	O
(	O
Figure	O
[	O
reference	O
]	O
)	O
:	O
	
Character	B-Method
Embedding	I-Method
Layer	I-Method
maps	O
each	O
word	O
to	O
a	O
vector	O
space	O
using	O
character	B-Method
-	I-Method
level	I-Method
CNNs	I-Method
.	O
	
Word	B-Method
Embedding	I-Method
Layer	I-Method
maps	O
each	O
word	O
to	O
a	O
vector	O
space	O
using	O
a	O
pre	O
-	O
trained	O
word	B-Method
embedding	I-Method
model	I-Method
.	O
	
Contextual	B-Method
Embedding	I-Method
Layer	I-Method
utilizes	O
contextual	O
cues	O
from	O
surrounding	O
words	O
to	O
refine	O
the	O
embedding	O
of	O
the	O
words	O
.	O
	
These	O
first	O
three	O
layers	O
are	O
applied	O
to	O
both	O
the	O
query	O
and	O
context	O
.	O
	
Attention	B-Method
Flow	I-Method
Layer	I-Method
couples	O
the	O
query	O
and	O
context	O
vectors	O
and	O
produces	O
a	O
set	O
of	O
query	O
-	O
aware	O
feature	O
vectors	O
for	O
each	O
word	O
in	O
the	O
context	O
.	O
	
Modeling	B-Method
Layer	I-Method
employs	O
a	O
Recurrent	B-Method
Neural	I-Method
Network	I-Method
to	O
scan	O
the	O
context	O
.	O
	
Output	B-Method
Layer	I-Method
provides	O
an	O
answer	O
to	O
the	O
query	O
.	O
	
paragraph	O
:	O
1	O
.	O
Character	B-Method
Embedding	I-Method
Layer	I-Method
.	O
	
Character	B-Method
embedding	I-Method
layer	I-Method
is	O
responsible	O
for	O
mapping	O
each	O
word	O
to	O
a	O
high	O
-	O
dimensional	O
vector	O
space	O
.	O
	
Let	O
and	O
represent	O
the	O
words	O
in	O
the	O
input	O
context	O
paragraph	O
and	O
query	O
,	O
respectively	O
.	O
	
Following	O
,	O
we	O
obtain	O
the	O
character	B-Method
-	I-Method
level	I-Method
embedding	I-Method
of	O
each	O
word	O
using	O
Convolutional	B-Method
Neural	I-Method
Networks	I-Method
(	O
CNN	B-Method
)	O
.	O
	
Characters	O
are	O
embedded	O
into	O
vectors	O
,	O
which	O
can	O
be	O
considered	O
as	O
1D	O
inputs	O
to	O
the	O
CNN	B-Method
,	O
and	O
whose	O
size	O
is	O
the	O
input	O
channel	O
size	O
of	O
the	O
CNN	B-Method
.	O
	
The	O
outputs	O
of	O
the	O
CNN	B-Method
are	O
max	O
-	O
pooled	O
over	O
the	O
entire	O
width	O
to	O
obtain	O
a	O
fixed	O
-	O
size	O
vector	O
for	O
each	O
word	O
.	O
	
paragraph	O
:	O
2	O
.	O
Word	B-Method
Embedding	I-Method
Layer	I-Method
.	O
	
Word	B-Method
embedding	I-Method
layer	I-Method
also	O
maps	O
each	O
word	O
to	O
a	O
high	O
-	O
dimensional	O
vector	O
space	O
.	O
	
We	O
use	O
pre	O
-	O
trained	O
word	O
vectors	O
,	O
GloVe	B-Method
glove	I-Method
,	O
to	O
obtain	O
the	O
fixed	O
word	O
embedding	O
of	O
each	O
word	O
.	O
	
The	O
concatenation	O
of	O
the	O
character	O
and	O
word	O
embedding	O
vectors	O
is	O
passed	O
to	O
a	O
two	O
-	O
layer	B-Method
Highway	I-Method
Network	I-Method
highway	I-Method
.	O
	
The	O
outputs	O
of	O
the	O
Highway	B-Method
Network	I-Method
are	O
two	O
sequences	O
of	O
-	O
dimensional	O
vectors	O
,	O
or	O
more	O
conveniently	O
,	O
two	O
matrices	O
:	O
for	O
the	O
context	O
and	O
for	O
the	O
query	O
.	O
	
paragraph	O
:	O
3	O
.	O
Contextual	B-Method
Embedding	I-Method
Layer	I-Method
.	O
	
We	O
use	O
a	O
Long	B-Method
Short	I-Method
-	I-Method
Term	I-Method
Memory	I-Method
Network	I-Method
(	I-Method
LSTM	I-Method
)	I-Method
lstm	I-Method
on	O
top	O
of	O
the	O
embeddings	O
provided	O
by	O
the	O
previous	O
layers	O
to	O
model	O
the	O
temporal	O
interactions	O
between	O
words	O
.	O
	
We	O
place	O
an	O
LSTM	B-Method
in	O
both	O
directions	O
,	O
and	O
concatenate	O
the	O
outputs	O
of	O
the	O
two	O
LSTMs	B-Method
.	O
	
Hence	O
we	O
obtain	O
from	O
the	O
context	O
word	O
vectors	O
,	O
and	O
from	O
query	O
word	O
vectors	O
.	O
	
Note	O
that	O
each	O
column	O
vector	O
of	O
and	O
is	O
-	O
dimensional	O
because	O
of	O
the	O
concatenation	O
of	O
the	O
outputs	O
of	O
the	O
forward	B-Method
and	I-Method
backward	I-Method
LSTMs	I-Method
,	O
each	O
with	O
-	O
dimensional	O
output	O
.	O
	
It	O
is	O
worth	O
noting	O
that	O
the	O
first	O
three	O
layers	O
of	O
the	O
model	O
are	O
computing	O
features	O
from	O
the	O
query	O
and	O
context	O
at	O
different	O
levels	O
of	O
granularity	O
,	O
akin	O
to	O
the	O
multi	B-Method
-	I-Method
stage	I-Method
feature	I-Method
computation	I-Method
of	O
convolutional	B-Method
neural	I-Method
networks	I-Method
in	O
the	O
computer	B-Task
vision	I-Task
field	I-Task
.	O
	
paragraph	O
:	O
4	O
.	O
Attention	B-Method
Flow	I-Method
Layer	I-Method
.	O
	
Attention	B-Method
flow	I-Method
layer	I-Method
is	O
responsible	O
for	O
linking	O
and	O
fusing	O
information	O
from	O
the	O
context	O
and	O
the	O
query	O
words	O
.	O
	
Unlike	O
previously	O
popular	O
attention	B-Method
mechanisms	I-Method
memnn	I-Method
,	O
hill2015goldilocks	O
,	O
iterative	B-Method
,	O
reasonet	B-Method
,	O
the	O
attention	B-Method
flow	I-Method
layer	I-Method
is	O
not	O
used	O
to	O
summarize	O
the	O
query	O
and	O
context	O
into	O
single	O
feature	O
vectors	O
.	O
	
Instead	O
,	O
the	O
attention	O
vector	O
at	O
each	O
time	O
step	O
,	O
along	O
with	O
the	O
embeddings	O
from	O
previous	O
layers	O
,	O
are	O
allowed	O
to	O
flow	O
through	O
to	O
the	O
subsequent	O
modeling	B-Method
layer	I-Method
.	O
	
This	O
reduces	O
the	O
information	O
loss	O
caused	O
by	O
early	B-Task
summarization	I-Task
.	O
	
The	O
inputs	O
to	O
the	O
layer	O
are	O
contextual	B-Method
vector	I-Method
representations	I-Method
of	O
the	O
context	O
and	O
the	O
query	O
.	O
	
The	O
outputs	O
of	O
the	O
layer	O
are	O
the	O
query	B-Method
-	I-Method
aware	I-Method
vector	I-Method
representations	I-Method
of	O
the	O
context	O
words	O
,	O
,	O
along	O
with	O
the	O
contextual	O
embeddings	O
from	O
the	O
previous	O
layer	O
.	O
	
In	O
this	O
layer	O
,	O
we	O
compute	O
attentions	O
in	O
two	O
directions	O
:	O
from	O
context	O
to	O
query	O
as	O
well	O
as	O
from	O
query	O
to	O
context	O
.	O
	
Both	O
of	O
these	O
attentions	O
,	O
which	O
will	O
be	O
discussed	O
below	O
,	O
are	O
derived	O
from	O
a	O
shared	O
similarity	O
matrix	O
,	O
,	O
between	O
the	O
contextual	O
embeddings	O
of	O
the	O
context	O
(	O
)	O
and	O
the	O
query	O
(	O
)	O
,	O
where	O
indicates	O
the	O
similarity	O
between	O
-	O
th	O
context	O
word	O
and	O
-	O
th	O
query	O
word	O
.	O
	
The	O
similarity	O
matrix	O
is	O
computed	O
by	O
where	O
is	O
a	O
trainable	O
scalar	O
function	O
that	O
encodes	O
the	O
similarity	O
between	O
its	O
two	O
input	O
vectors	O
,	O
is	O
-	O
th	O
column	O
vector	O
of	O
,	O
and	O
is	O
-	O
th	O
column	O
vector	O
of	O
,	O
We	O
choose	O
,	O
where	O
is	O
a	O
trainable	O
weight	O
vector	O
,	O
is	O
elementwise	B-Method
multiplication	I-Method
,	O
is	O
vector	O
concatenation	O
across	O
row	O
,	O
and	O
implicit	B-Method
multiplication	I-Method
is	O
matrix	B-Method
multiplication	I-Method
.	O
	
Now	O
we	O
use	O
to	O
obtain	O
the	O
attentions	O
and	O
the	O
attended	O
vectors	O
in	O
both	O
directions	O
.	O
	
Context	B-Task
-	I-Task
to	I-Task
-	I-Task
query	I-Task
Attention	I-Task
.	O
	
Context	B-Task
-	I-Task
to	I-Task
-	I-Task
query	I-Task
(	O
C2Q	O
)	O
attention	B-Task
signifies	O
which	O
query	O
words	O
are	O
most	O
relevant	O
to	O
each	O
context	O
word	O
.	O
	
Let	O
represent	O
the	O
attention	O
weights	O
on	O
the	O
query	O
words	O
by	O
-	O
th	O
context	O
word	O
,	O
for	O
all	O
.	O
	
The	O
attention	O
weight	O
is	O
computed	O
by	O
,	O
and	O
subsequently	O
each	O
attended	O
query	O
vector	O
is	O
.	O
	
Hence	O
is	O
a	O
-	O
by	O
-	O
matrix	O
containing	O
the	O
attended	O
query	O
vectors	O
for	O
the	O
entire	O
context	O
.	O
	
Query	B-Task
-	I-Task
to	I-Task
-	I-Task
context	I-Task
Attention	I-Task
.	O
	
Query	B-Task
-	I-Task
to	I-Task
-	I-Task
context	I-Task
(	I-Task
Q2C	I-Task
)	I-Task
attention	I-Task
signifies	O
which	O
context	O
words	O
have	O
the	O
closest	O
similarity	O
to	O
one	O
of	O
the	O
query	O
words	O
and	O
are	O
hence	O
critical	O
for	O
answering	O
the	O
query	O
.	O
	
We	O
obtain	O
the	O
attention	O
weights	O
on	O
the	O
context	O
words	O
by	O
,	O
where	O
the	O
maximum	O
function	O
(	O
)	O
is	O
performed	O
across	O
the	O
column	O
.	O
	
Then	O
the	O
attended	O
context	O
vector	O
is	O
.	O
	
This	O
vector	O
indicates	O
the	O
weighted	O
sum	O
of	O
the	O
most	O
important	O
words	O
in	O
the	O
context	O
with	O
respect	O
to	O
the	O
query	O
.	O
	
is	O
tiled	O
times	O
across	O
the	O
column	O
,	O
thus	O
giving	O
.	O
	
Finally	O
,	O
the	O
contextual	O
embeddings	O
and	O
the	O
attention	O
vectors	O
are	O
combined	O
together	O
to	O
yield	O
,	O
where	O
each	O
column	O
vector	O
can	O
be	O
considered	O
as	O
the	O
query	B-Method
-	I-Method
aware	I-Method
representation	I-Method
of	O
each	O
context	O
word	O
.	O
	
We	O
define	O
by	O
where	O
is	O
the	O
-	O
th	O
column	O
vector	O
(	O
corresponding	O
to	O
-	O
th	O
context	O
word	O
)	O
,	O
is	O
a	O
trainable	B-Method
vector	I-Method
function	I-Method
that	O
fuses	O
its	O
(	O
three	O
)	O
input	O
vectors	O
,	O
and	O
is	O
the	O
output	O
dimension	O
of	O
the	O
function	O
.	O
	
While	O
the	O
function	O
can	O
be	O
an	O
arbitrary	O
trainable	B-Method
neural	I-Method
network	I-Method
,	O
such	O
as	O
multi	B-Method
-	I-Method
layer	I-Method
perceptron	I-Method
,	O
a	O
simple	O
concatenation	B-Method
as	O
following	O
still	O
shows	O
good	O
performance	O
in	O
our	O
experiments	O
:	O
(	O
i.e.	O
,	O
)	O
.	O
	
paragraph	O
:	O
5	O
.	O
Modeling	B-Method
Layer	I-Method
.	O
	
The	O
input	O
to	O
the	O
modeling	B-Method
layer	I-Method
is	O
,	O
which	O
encodes	O
the	O
query	B-Method
-	I-Method
aware	I-Method
representations	I-Method
of	I-Method
context	I-Method
words	I-Method
.	O
	
The	O
output	O
of	O
the	O
modeling	B-Method
layer	I-Method
captures	O
the	O
interaction	O
among	O
the	O
context	O
words	O
conditioned	O
on	O
the	O
query	O
.	O
	
This	O
is	O
different	O
from	O
the	O
contextual	B-Method
embedding	I-Method
layer	I-Method
,	O
which	O
captures	O
the	O
interaction	O
among	O
context	O
words	O
independent	O
of	O
the	O
query	O
.	O
	
We	O
use	O
two	O
layers	O
of	O
bi	B-Method
-	I-Method
directional	I-Method
LSTM	I-Method
,	O
with	O
the	O
output	O
size	O
of	O
for	O
each	O
direction	O
.	O
	
Hence	O
we	O
obtain	O
a	O
matrix	O
,	O
which	O
is	O
passed	O
onto	O
the	O
output	B-Method
layer	I-Method
to	O
predict	O
the	O
answer	O
.	O
	
Each	O
column	O
vector	O
of	O
is	O
expected	O
to	O
contain	O
contextual	O
information	O
about	O
the	O
word	O
with	O
respect	O
to	O
the	O
entire	O
context	O
paragraph	O
and	O
the	O
query	O
.	O
	
paragraph	O
:	O
6	O
.	O
Output	O
Layer	O
.	O
	
The	O
output	B-Method
layer	I-Method
is	O
application	O
-	O
specific	O
.	O
	
The	O
modular	O
nature	O
of	O
BiDAF	B-Method
allows	O
us	O
to	O
easily	O
swap	O
out	O
the	O
output	O
layer	O
based	O
on	O
the	O
task	O
,	O
with	O
the	O
rest	O
of	O
the	O
architecture	O
remaining	O
exactly	O
the	O
same	O
.	O
	
Here	O
,	O
we	O
describe	O
the	O
output	B-Method
layer	I-Method
for	O
the	O
QA	B-Task
task	I-Task
.	O
	
In	O
section	O
[	O
reference	O
]	O
,	O
we	O
use	O
a	O
slight	O
modification	O
of	O
this	O
output	B-Method
layer	I-Method
for	O
cloze	B-Task
-	I-Task
style	I-Task
comprehension	I-Task
.	O
	
The	O
QA	B-Task
task	I-Task
requires	O
the	O
model	O
to	O
find	O
a	O
sub	O
-	O
phrase	O
of	O
the	O
paragraph	O
to	O
answer	O
the	O
query	O
.	O
	
The	O
phrase	O
is	O
derived	O
by	O
predicting	O
the	O
start	O
and	O
the	O
end	O
indices	O
of	O
the	O
phrase	O
in	O
the	O
paragraph	O
.	O
	
We	O
obtain	O
the	O
probability	O
distribution	O
of	O
the	O
start	O
index	O
over	O
the	O
entire	O
paragraph	O
by	O
where	O
is	O
a	O
trainable	O
weight	O
vector	O
.	O
	
For	O
the	O
end	O
index	O
of	O
the	O
answer	O
phrase	O
,	O
we	O
pass	O
to	O
another	O
bidirectional	B-Method
LSTM	I-Method
layer	I-Method
and	O
obtain	O
.	O
	
Then	O
we	O
use	O
to	O
obtain	O
the	O
probability	O
distribution	O
of	O
the	O
end	O
index	O
in	O
a	O
similar	O
manner	O
:	O
Training	B-Task
.	O
	
We	O
define	O
the	O
training	B-Metric
loss	I-Metric
(	O
to	O
be	O
minimized	O
)	O
as	O
the	O
sum	O
of	O
the	O
negative	O
log	O
probabilities	O
of	O
the	O
true	O
start	O
and	O
end	O
indices	O
by	O
the	O
predicted	O
distributions	O
,	O
averaged	O
over	O
all	O
examples	O
:	O
where	O
is	O
the	O
set	O
of	O
all	O
trainable	O
weights	O
in	O
the	O
model	O
(	O
the	O
weights	O
and	O
biases	O
of	O
CNN	B-Method
filters	I-Method
and	O
LSTM	B-Method
cells	I-Method
,	O
,	O
and	O
)	O
,	O
is	O
the	O
number	O
of	O
examples	O
in	O
the	O
dataset	O
,	O
and	O
are	O
the	O
true	O
start	O
and	O
end	O
indices	O
of	O
the	O
-	O
th	O
example	O
,	O
respectively	O
,	O
and	O
indicates	O
the	O
-	O
th	O
value	O
of	O
the	O
vector	O
.	O
	
Test	O
.	O
	
The	O
answer	O
span	O
where	O
with	O
the	O
maximum	O
value	O
of	O
is	O
chosen	O
,	O
which	O
can	O
be	O
computed	O
in	O
linear	O
time	O
with	O
dynamic	B-Method
programming	I-Method
.	O
	
section	O
:	O
Related	O
Work	O
	
paragraph	O
:	O
Machine	B-Task
comprehension	I-Task
.	O
	
A	O
significant	O
contributor	O
to	O
the	O
advancement	O
of	O
MC	B-Method
models	I-Method
has	O
been	O
the	O
availability	O
of	O
large	O
datasets	O
.	O
	
Early	O
datasets	O
such	O
as	O
MCTest	B-Material
richardson2013mctest	O
were	O
too	O
small	O
to	O
train	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
neural	I-Method
models	I-Method
.	O
	
Massive	O
cloze	O
test	O
datasets	O
(	O
CNN	O
/	O
DailyMail	B-Material
by	O
Hermann2015TeachingMT	O
and	O
Childrens	O
Book	O
Test	O
by	O
)	O
,	O
enabled	O
the	O
application	O
of	O
deep	B-Method
neural	I-Method
architectures	I-Method
to	O
this	O
task	O
.	O
	
More	O
recently	O
,	O
rajpurkar2016squad	O
released	O
the	O
Stanford	B-Material
Question	I-Material
Answering	I-Material
(	O
SQuAD	B-Material
)	O
dataset	O
with	O
over	O
100	O
,	O
000	O
questions	O
.	O
	
We	O
evaluate	O
the	O
performance	O
of	O
our	O
comprehension	B-Method
system	I-Method
on	O
both	O
SQuAD	B-Material
and	O
CNN	B-Material
/	I-Material
DailyMail	I-Material
datasets	I-Material
.	O
	
Previous	O
works	O
in	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
machine	I-Task
comprehension	I-Task
use	O
attention	B-Method
mechanisms	I-Method
in	O
three	O
distinct	O
ways	O
.	O
	
The	O
first	O
group	O
(	O
largely	O
inspired	O
by	O
)	O
uses	O
a	O
dynamic	B-Method
attention	I-Method
mechanism	I-Method
,	O
in	O
which	O
the	O
attention	O
weights	O
are	O
updated	O
dynamically	O
given	O
the	O
query	O
and	O
the	O
context	O
as	O
well	O
as	O
the	O
previous	O
attention	O
.	O
	
argue	O
that	O
the	O
dynamic	B-Method
attention	I-Method
model	I-Method
performs	O
better	O
than	O
using	O
a	O
single	O
fixed	O
query	O
vector	O
to	O
attend	O
on	O
context	O
words	O
on	O
CNN	O
&	O
DailyMail	B-Material
datasets	O
.	O
	
show	O
that	O
simply	O
using	O
bilinear	O
term	O
for	O
computing	O
the	O
attention	O
weights	O
in	O
the	O
same	O
model	O
drastically	O
improves	O
the	O
accuracy	B-Metric
.	O
	
reverse	O
the	O
direction	O
of	O
the	O
attention	O
(	O
attending	O
on	O
query	O
words	O
as	O
the	O
context	O
RNN	O
progresses	O
)	O
for	O
SQuAD	B-Material
.	O
	
In	O
contrast	O
to	O
these	O
models	O
,	O
BiDAF	B-Method
uses	O
a	O
memory	B-Method
-	I-Method
less	I-Method
attention	I-Method
mechanism	I-Method
.	O
	
The	O
second	O
group	O
computes	O
the	O
attention	O
weights	O
once	O
,	O
which	O
are	O
then	O
fed	O
into	O
an	O
output	B-Method
layer	I-Method
for	O
final	O
prediction	B-Task
(	O
e.g.	O
,	O
)	O
.	O
	
Attention	B-Method
-	I-Method
over	I-Method
-	I-Method
attention	I-Method
model	I-Method
	
aoa	B-Method
uses	O
a	O
2D	O
similarity	O
matrix	O
between	O
the	O
query	O
and	O
context	O
words	O
(	O
similar	O
to	O
Equation	O
[	O
reference	O
]	O
)	O
to	O
compute	O
the	O
weighted	B-Task
average	I-Task
of	I-Task
query	I-Task
-	I-Task
to	I-Task
-	I-Task
context	I-Task
attention	I-Task
.	O
	
In	O
contrast	O
to	O
these	O
models	O
,	O
BiDAF	B-Method
does	O
not	O
summarize	O
the	O
two	O
modalities	O
in	O
the	O
attention	B-Method
layer	I-Method
and	O
instead	O
lets	O
the	O
attention	O
vectors	O
flow	O
into	O
the	O
modeling	B-Method
(	I-Method
RNN	I-Method
)	I-Method
layer	I-Method
.	O
	
The	O
third	O
group	O
(	O
considered	O
as	O
variants	O
of	O
Memory	B-Method
Network	I-Method
memnn	I-Method
)	O
repeats	O
computing	O
an	O
attention	O
vector	O
between	O
the	O
query	O
and	O
the	O
context	O
through	O
multiple	O
layers	O
,	O
typically	O
referred	O
to	O
as	O
multi	B-Method
-	I-Method
hop	I-Method
iterative	I-Method
,	O
ga	B-Method
.	O
	
combine	O
Memory	B-Method
Networks	I-Method
with	O
Reinforcement	B-Method
Learning	I-Method
in	O
order	O
to	O
dynamically	O
control	O
the	O
number	O
of	O
hops	O
.	O
	
One	O
can	O
also	O
extend	O
our	O
BiDAF	B-Method
model	I-Method
to	O
incorporate	O
multiple	O
hops	O
.	O
	
paragraph	O
:	O
Visual	B-Task
question	I-Task
answering	I-Task
.	O
	
The	O
task	O
of	O
question	B-Task
answering	I-Task
has	O
also	O
gained	O
a	O
lot	O
of	O
interest	O
in	O
the	O
computer	B-Task
vision	I-Task
community	I-Task
.	O
	
Early	O
works	O
on	O
visual	B-Task
question	I-Task
answering	I-Task
(	O
VQA	B-Task
)	O
involved	O
encoding	O
the	O
question	O
using	O
an	O
RNN	B-Method
,	O
encoding	O
the	O
image	O
using	O
a	O
CNN	B-Method
and	O
combining	O
them	O
to	O
answer	O
the	O
question	O
antol2015vqa	O
,	O
Malinowski2015AskYN	O
.	O
	
Attention	B-Method
mechanisms	I-Method
have	O
also	O
been	O
successfully	O
employed	O
for	O
the	O
VQA	B-Task
task	I-Task
and	O
can	O
be	O
broadly	O
clustered	O
based	O
on	O
the	O
granularity	O
of	O
their	O
attention	O
and	O
the	O
approach	O
to	O
construct	O
the	O
attention	O
matrix	O
.	O
	
At	O
the	O
coarse	O
level	O
of	O
granularity	O
,	O
the	O
question	O
attends	O
to	O
different	O
patches	O
in	O
the	O
image	O
Zhu2015Visual7WGQ	O
,	O
xiong2016dynamic	O
.	O
	
At	O
a	O
finer	O
level	O
,	O
each	O
question	O
word	O
attends	O
to	O
each	O
image	O
patch	O
and	O
the	O
highest	O
attention	O
value	O
for	O
each	O
spatial	O
location	O
Xu2016AskAA	O
is	O
adopted	O
.	O
	
A	O
hybrid	O
approach	O
is	O
to	O
combine	O
questions	B-Method
representations	I-Method
at	O
multiple	O
levels	O
of	O
granularity	O
(	O
unigrams	O
,	O
bigrams	O
,	O
trigrams	O
)	O
yang2015stacked	O
.	O
	
Several	O
approaches	O
to	O
constructing	O
the	O
attention	O
matrix	O
have	O
been	O
used	O
including	O
element	B-Method
-	I-Method
wise	I-Method
product	I-Method
,	O
element	B-Method
-	I-Method
wise	I-Method
sum	I-Method
,	O
concatenation	B-Method
and	O
Multimodal	B-Method
Compact	I-Method
	
Bilinear	B-Method
Pooling	I-Method
fukui2016multimodal	O
.	O
	
lu2016hierarchical	O
have	O
recently	O
shown	O
that	O
in	O
addition	O
to	O
attending	O
from	O
the	O
question	O
to	O
image	O
patches	O
,	O
attending	O
from	O
the	O
image	O
back	O
to	O
the	O
question	O
words	O
provides	O
an	O
improvement	O
on	O
the	O
VQA	B-Task
task	I-Task
.	O
	
This	O
finding	O
in	O
the	O
visual	B-Task
domain	I-Task
is	O
consistent	O
with	O
our	O
finding	O
in	O
the	O
language	O
domain	O
,	O
where	O
our	O
bi	B-Method
-	I-Method
directional	I-Method
attention	I-Method
between	O
the	O
query	O
and	O
context	O
provides	O
improved	O
results	O
.	O
	
Their	O
model	O
,	O
however	O
,	O
uses	O
the	O
attention	O
weights	O
directly	O
in	O
the	O
output	O
layer	O
and	O
does	O
not	O
take	O
advantage	O
of	O
the	O
attention	O
flow	O
to	O
the	O
modeling	B-Method
layer	I-Method
.	O
	
section	O
:	O
Question	B-Task
Answering	I-Task
Experiments	O
	
In	O
this	O
section	O
,	O
we	O
evaluate	O
our	O
model	O
on	O
the	O
task	O
of	O
question	B-Task
answering	I-Task
using	O
the	O
recently	O
released	O
SQuAD	B-Material
rajpurkar2016squad	O
,	O
which	O
has	O
gained	O
a	O
huge	O
attention	O
over	O
a	O
few	O
months	O
.	O
	
In	O
the	O
next	O
section	O
,	O
we	O
evaluate	O
our	O
model	O
on	O
the	O
task	O
of	O
cloze	B-Task
-	I-Task
style	I-Task
reading	I-Task
comprehension	I-Task
.	O
	
paragraph	O
:	O
Dataset	O
.	O
	
SQuAD	B-Material
is	O
a	O
machine	O
comprehension	O
dataset	O
on	O
a	O
large	O
set	O
of	O
Wikipedia	O
articles	O
,	O
with	O
more	O
than	O
100	O
,	O
000	O
questions	O
.	O
	
The	O
answer	O
to	O
each	O
question	O
is	O
always	O
a	O
span	O
in	O
the	O
context	O
.	O
	
The	O
model	O
is	O
given	O
a	O
credit	O
if	O
its	O
answer	O
matches	O
one	O
of	O
the	O
human	O
written	O
answers	O
.	O
	
Two	O
metrics	O
are	O
used	O
to	O
evaluate	O
models	O
:	O
Exact	B-Metric
Match	I-Metric
(	I-Metric
EM	I-Metric
)	I-Metric
and	O
a	O
softer	O
metric	O
,	O
F1	B-Metric
score	I-Metric
,	O
which	O
measures	O
the	O
weighted	B-Metric
average	I-Metric
of	I-Metric
the	I-Metric
precision	I-Metric
and	O
recall	B-Metric
rate	I-Metric
at	O
character	O
level	O
.	O
	
The	O
dataset	O
consists	O
of	O
90k	O
/	O
10k	O
train	O
/	O
dev	O
question	O
-	O
context	O
tuples	O
with	O
a	O
large	O
hidden	O
test	O
set	O
.	O
	
It	O
is	O
one	O
of	O
the	O
largest	O
available	O
MC	O
datasets	O
with	O
human	O
-	O
written	O
questions	O
and	O
serves	O
as	O
a	O
great	O
test	O
bed	O
for	O
our	O
model	O
.	O
	
paragraph	O
:	O
Model	O
Details	O
.	O
	
The	O
model	O
architecture	O
used	O
for	O
this	O
task	O
is	O
depicted	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Each	O
paragraph	O
and	O
question	O
are	O
tokenized	O
by	O
a	O
regular	B-Method
-	I-Method
expression	I-Method
-	I-Method
based	I-Method
word	I-Method
tokenizer	I-Method
(	O
PTB	B-Method
Tokenizer	I-Method
)	O
and	O
fed	O
into	O
the	O
model	O
.	O
	
We	O
use	O
100	O
1D	B-Method
filters	I-Method
for	O
CNN	B-Task
char	I-Task
embedding	I-Task
,	O
each	O
with	O
a	O
width	O
of	O
5	O
.	O
	
The	O
hidden	O
state	O
size	O
(	O
)	O
of	O
the	O
model	O
is	O
100	O
.	O
	
The	O
model	O
has	O
about	O
2.6	O
million	O
parameters	O
.	O
	
We	O
use	O
the	O
AdaDelta	B-Method
adadelta	I-Method
optimizer	I-Method
,	O
with	O
a	O
minibatch	O
size	O
of	O
60	O
and	O
an	O
initial	O
learning	B-Metric
rate	I-Metric
of	O
,	O
for	O
12	O
epochs	O
.	O
	
A	O
dropout	B-Metric
dropout	I-Metric
rate	I-Metric
of	I-Metric
is	O
used	O
for	O
the	O
CNN	B-Method
,	O
all	O
LSTM	B-Method
layers	I-Method
,	O
and	O
the	O
linear	B-Method
transformation	I-Method
before	O
the	O
softmax	O
for	O
the	O
answers	O
.	O
	
During	O
training	O
,	O
the	O
moving	O
averages	O
of	O
all	O
weights	O
of	O
the	O
model	O
are	O
maintained	O
with	O
the	O
exponential	O
decay	O
rate	O
of	O
.	O
	
At	O
test	O
time	O
,	O
the	O
moving	O
averages	O
instead	O
of	O
the	O
raw	O
weights	O
are	O
used	O
.	O
	
The	O
training	O
process	O
takes	O
roughly	O
20	O
hours	O
on	O
a	O
single	O
Titan	O
X	O
GPU	O
.	O
	
We	O
also	O
train	O
an	O
ensemble	B-Method
model	I-Method
consisting	O
of	O
12	O
training	O
runs	O
with	O
the	O
identical	O
architecture	O
and	O
hyper	O
-	O
parameters	O
.	O
	
At	O
test	O
time	O
,	O
we	O
choose	O
the	O
answer	O
with	O
the	O
highest	O
sum	O
of	O
confidence	O
scores	O
amongst	O
the	O
12	O
runs	O
for	O
each	O
question	O
.	O
	
paragraph	O
:	O
Results	O
.	O
	
The	O
results	O
of	O
our	O
model	O
and	O
competing	O
approaches	O
on	O
the	O
hidden	B-Task
test	I-Task
are	O
summarized	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
BiDAF	B-Method
(	I-Method
ensemble	I-Method
)	I-Method
achieves	O
an	O
EM	B-Metric
score	O
of	O
73.3	O
and	O
an	O
F1	B-Metric
score	I-Metric
of	O
81.1	O
,	O
outperforming	O
all	O
previous	O
approaches	O
.	O
	
[	O
htbp	O
]	O
0.6	O
[	O
htbp	O
]	O
0.4	O
	
paragraph	O
:	O
Ablations	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
performance	O
of	O
our	O
model	O
and	O
its	O
ablations	O
on	O
the	O
SQuAD	B-Material
dev	O
set	O
.	O
	
Both	O
char	O
-	O
level	O
and	O
word	B-Method
-	I-Method
level	I-Method
embeddings	I-Method
contribute	O
towards	O
the	O
model	O
	
’s	O
performance	O
.	O
	
We	O
conjecture	O
that	O
word	B-Method
-	I-Method
level	I-Method
embedding	I-Method
is	O
better	O
at	O
representing	O
the	O
semantics	O
of	O
each	O
word	O
as	O
a	O
whole	O
,	O
while	O
char	B-Method
-	I-Method
level	I-Method
embedding	I-Method
can	O
better	O
handle	O
out	O
-	O
of	O
-	O
vocab	O
(	O
OOV	O
)	O
or	O
rare	O
words	O
.	O
	
To	O
evaluate	O
bi	B-Method
-	I-Method
directional	I-Method
attention	I-Method
,	O
we	O
remove	O
C2Q	O
and	O
Q2C	O
attentions	O
.	O
	
For	O
ablating	B-Task
C2Q	I-Task
attention	I-Task
,	O
we	O
replace	O
the	O
attended	O
question	O
vector	O
with	O
the	O
average	O
of	O
the	O
output	O
vectors	O
of	O
the	O
question	O
	
’s	O
contextual	B-Method
embedding	I-Method
layer	I-Method
(	O
LSTM	B-Method
)	I-Method
.	O
	
C2Q	O
attention	O
proves	O
to	O
be	O
critical	O
with	O
a	O
drop	O
of	O
more	O
than	O
10	O
points	O
on	O
both	O
metrics	O
.	O
	
For	O
ablating	B-Task
Q2C	I-Task
attention	I-Task
,	O
the	O
output	O
of	O
the	O
attention	B-Method
layer	I-Method
,	O
,	O
does	O
not	O
include	O
terms	O
that	O
have	O
the	O
attended	O
Q2C	O
vectors	O
,	O
.	O
	
To	O
evaluate	O
the	O
attention	O
flow	O
,	O
we	O
study	O
a	O
dynamic	B-Method
attention	I-Method
model	I-Method
,	O
where	O
the	O
attention	O
is	O
dynamically	O
computed	O
within	O
the	O
modeling	B-Method
layer	I-Method
’s	O
LSTM	B-Method
,	O
following	O
previous	O
work	O
Bahdanau2014NeuralMT	O
,	O
wang2016machine	O
.	O
	
This	O
is	O
in	O
contrast	O
with	O
our	O
approach	O
,	O
where	O
the	O
attention	O
is	O
pre	O
-	O
computed	O
before	O
flowing	O
to	O
the	O
modeling	B-Method
layer	I-Method
.	O
	
Despite	O
being	O
a	O
simpler	O
attention	B-Method
mechanism	I-Method
,	O
our	O
proposed	O
static	B-Method
attention	I-Method
outperforms	O
the	O
dynamically	O
computed	O
attention	O
by	O
more	O
than	O
3	O
points	O
.	O
	
We	O
conjecture	O
that	O
separating	O
out	O
the	O
attention	B-Method
layer	I-Method
results	O
in	O
a	O
richer	O
set	O
of	O
features	O
computed	O
in	O
the	O
first	O
4	O
layers	O
which	O
are	O
then	O
incorporated	O
by	O
the	O
modeling	B-Method
layer	I-Method
.	O
	
We	O
also	O
show	O
the	O
performance	O
of	O
BiDAF	B-Method
with	O
several	O
different	O
definitions	O
of	O
and	O
functions	O
(	O
Equation	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
)	O
in	O
Appendix	O
[	O
reference	O
]	O
.	O
	
paragraph	O
:	O
Visualizations	B-Task
.	O
	
We	O
now	O
provide	O
a	O
qualitative	O
analysis	O
of	O
our	O
model	O
on	O
the	O
SQuAD	B-Material
dev	O
set	O
.	O
	
First	O
,	O
we	O
visualize	O
the	O
feature	O
spaces	O
after	O
the	O
word	B-Method
and	I-Method
contextual	I-Method
embedding	I-Method
layers	I-Method
.	O
	
These	O
two	O
layers	O
are	O
responsible	O
for	O
aligning	O
the	O
embeddings	O
between	O
the	O
query	O
and	O
context	O
words	O
which	O
are	O
the	O
inputs	O
to	O
the	O
subsequent	O
attention	B-Method
layer	I-Method
.	O
	
To	O
visualize	O
the	O
embeddings	O
,	O
we	O
choose	O
a	O
few	O
frequent	O
query	O
words	O
in	O
the	O
dev	O
data	O
and	O
look	O
at	O
the	O
context	O
words	O
that	O
have	O
the	O
highest	O
cosine	O
similarity	O
to	O
the	O
query	O
words	O
(	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
At	O
the	O
word	B-Method
embedding	I-Method
layer	I-Method
,	O
query	O
words	O
such	O
as	O
When	O
,	O
Where	O
and	O
Who	O
are	O
not	O
well	O
aligned	O
to	O
possible	O
answers	O
in	O
the	O
context	O
,	O
but	O
this	O
dramatically	O
changes	O
in	O
the	O
contextual	B-Method
embedding	I-Method
layer	I-Method
which	O
has	O
access	O
to	O
context	O
from	O
surrounding	O
words	O
and	O
is	O
just	O
1	O
layer	O
below	O
the	O
attention	B-Method
layer	I-Method
.	O
	
When	O
begins	O
to	O
match	O
years	O
,	O
Where	O
matches	O
locations	O
,	O
and	O
Who	O
matches	O
names	O
.	O
	
We	O
also	O
visualize	O
these	O
two	O
feature	O
spaces	O
using	O
t	B-Method
-	I-Method
SNE	I-Method
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
t	B-Method
-	I-Method
SNE	I-Method
is	O
performed	O
on	O
a	O
large	O
fraction	O
of	O
dev	O
data	O
but	O
we	O
only	O
plot	O
data	O
points	O
corresponding	O
to	O
the	O
months	O
of	O
the	O
year	O
.	O
	
An	O
interesting	O
pattern	O
emerges	O
in	O
the	O
Word	O
space	O
,	O
where	O
May	O
is	O
separated	O
from	O
the	O
rest	O
of	O
the	O
months	O
because	O
May	O
has	O
multiple	O
meanings	O
in	O
the	O
English	O
language	O
.	O
	
The	O
contextual	B-Method
embedding	I-Method
layer	I-Method
uses	O
contextual	O
cues	O
from	O
surrounding	O
words	O
and	O
is	O
able	O
to	O
separate	O
the	O
usages	O
of	O
the	O
word	O
May	O
.	O
	
Finally	O
we	O
visualize	O
the	O
attention	O
matrices	O
for	O
some	O
question	O
-	O
context	O
tuples	O
in	O
the	O
dev	O
data	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
In	O
the	O
first	O
example	O
,	O
Where	O
matches	O
locations	O
and	O
in	O
the	O
second	O
example	O
,	O
many	O
matches	O
quantities	O
and	O
numerical	O
symbols	O
.	O
	
Also	O
,	O
entities	O
in	O
the	O
question	O
typically	O
attend	O
to	O
the	O
same	O
entities	O
in	O
the	O
context	O
,	O
thus	O
providing	O
a	O
feature	O
for	O
the	O
model	O
to	O
localize	O
possible	O
answers	O
.	O
	
paragraph	O
:	O
Discussions	O
.	O
	
We	O
analyse	O
the	O
performance	O
of	O
our	O
our	O
model	O
with	O
a	O
traditional	O
language	B-Method
-	I-Method
feature	I-Method
-	I-Method
based	I-Method
baseline	I-Method
rajpurkar2016squad	O
.	O
	
Figure	O
[	O
reference	O
]	O
	
b	O
shows	O
a	O
Venn	O
diagram	O
of	O
the	O
dev	O
set	O
questions	O
correctly	O
answered	O
by	O
the	O
models	O
.	O
	
Our	O
model	O
is	O
able	O
to	O
answer	O
more	O
than	O
86	O
%	O
of	O
the	O
questions	O
correctly	O
answered	O
by	O
the	O
baseline	O
.	O
	
The	O
14	O
%	O
that	O
are	O
incorrectly	O
answered	O
does	O
not	O
have	O
a	O
clear	O
pattern	O
.	O
	
This	O
suggests	O
that	O
neural	B-Method
architectures	I-Method
are	O
able	O
to	O
exploit	O
much	O
of	O
the	O
information	O
captured	O
by	O
the	O
language	O
features	O
.	O
	
We	O
also	O
break	O
this	O
comparison	O
down	O
by	O
the	O
first	O
words	O
in	O
the	O
questions	O
(	O
Figure	O
[	O
reference	O
]	O
c	O
)	O
.	O
	
Our	O
model	O
outperforms	O
the	O
traditional	O
baseline	O
comfortably	O
in	O
every	O
category	O
.	O
	
paragraph	O
:	O
Error	B-Method
Analysis	I-Method
.	O
	
We	O
randomly	O
select	O
50	O
incorrect	O
questions	O
(	O
based	O
on	O
EM	B-Metric
)	O
and	O
categorize	O
them	O
into	O
6	O
classes	O
.	O
	
50	O
%	O
of	O
errors	O
are	O
due	O
to	O
the	O
imprecise	O
boundaries	O
of	O
the	O
answers	O
,	O
28	O
%	O
involve	O
syntactic	O
complications	O
and	O
ambiguities	O
,	O
14	O
%	O
are	O
paraphrase	B-Task
problems	I-Task
,	O
4	O
%	O
require	O
external	O
knowledge	O
,	O
2	O
%	O
need	O
multiple	O
sentences	O
to	O
answer	O
,	O
and	O
2	O
%	O
are	O
due	O
to	O
mistakes	O
during	O
tokenization	B-Task
.	O
	
See	O
Appendix	O
[	O
reference	O
]	O
for	O
the	O
examples	O
of	O
the	O
error	O
modes	O
.	O
	
section	O
:	O
Cloze	O
Test	O
Experiments	O
	
We	O
also	O
evaluate	O
our	O
model	O
on	O
the	O
task	O
of	O
cloze	B-Task
-	I-Task
style	I-Task
reading	I-Task
comprehension	I-Task
using	O
the	O
CNN	B-Material
and	I-Material
Daily	I-Material
Mail	I-Material
datasets	I-Material
Hermann2015TeachingMT	O
.	O
	
paragraph	O
:	O
Dataset	O
.	O
	
In	O
a	O
cloze	B-Task
test	I-Task
,	O
the	O
reader	O
is	O
asked	O
to	O
fill	O
in	O
words	O
that	O
have	O
been	O
removed	O
from	O
a	O
passage	O
,	O
for	O
measuring	O
one	O
’s	O
ability	O
to	O
comprehend	O
text	O
.	O
	
Hermann2015TeachingMT	O
have	O
recently	O
compiled	O
a	O
massive	O
Cloze	O
-	O
style	O
comprehension	O
dataset	O
,	O
consisting	O
of	O
300k	O
/	O
4k	O
/	O
3k	O
and	O
879k	O
/	O
65k	O
/	O
53k	O
(	O
train	O
/	O
dev	O
/	O
test	O
)	O
examples	O
from	O
CNN	O
and	O
DailyMail	B-Material
news	O
articles	O
,	O
respectively	O
.	O
	
Each	O
example	O
has	O
a	O
news	O
article	O
and	O
an	O
incomplete	O
sentence	O
extracted	O
from	O
the	O
human	O
-	O
written	O
summary	O
of	O
the	O
article	O
.	O
	
To	O
distinguish	O
this	O
task	O
from	O
language	B-Task
modeling	I-Task
and	O
force	O
one	O
to	O
refer	O
to	O
the	O
article	O
to	O
predict	O
the	O
correct	O
missing	O
word	O
,	O
the	O
missing	O
word	O
is	O
always	O
a	O
named	O
entity	O
,	O
anonymized	O
with	O
a	O
random	O
ID	O
.	O
	
Also	O
,	O
the	O
IDs	O
must	O
be	O
shuffled	O
constantly	O
during	O
test	O
,	O
which	O
is	O
also	O
critical	O
for	O
full	B-Task
anonymization	I-Task
.	O
	
paragraph	O
:	O
Model	O
Details	O
.	O
	
The	O
model	O
architecture	O
used	O
for	O
this	O
task	O
is	O
very	O
similar	O
to	O
that	O
for	O
SQuAD	B-Material
(	O
Section	O
[	O
reference	O
]	O
)	O
with	O
only	O
a	O
few	O
small	O
changes	O
to	O
adapt	O
it	O
to	O
the	O
cloze	B-Task
test	I-Task
.	O
	
Since	O
each	O
answer	O
in	O
the	O
CNN	B-Material
/	I-Material
DailyMail	I-Material
datasets	I-Material
is	O
always	O
a	O
single	O
word	O
(	O
entity	O
)	O
,	O
we	O
only	O
need	O
to	O
predict	O
the	O
start	O
index	O
(	O
)	O
;	O
the	O
prediction	O
for	O
the	O
end	O
index	O
(	O
)	O
is	O
omitted	O
from	O
the	O
loss	O
function	O
.	O
	
Also	O
,	O
we	O
mask	O
out	O
all	O
non	O
-	O
entity	O
words	O
in	O
the	O
final	O
classification	B-Method
layer	I-Method
so	O
that	O
they	O
are	O
forced	O
to	O
be	O
excluded	O
from	O
possible	O
answers	O
.	O
	
Another	O
important	O
difference	O
from	O
SQuAD	B-Material
is	O
that	O
the	O
answer	O
entity	O
might	O
appear	O
more	O
than	O
once	O
in	O
the	O
context	O
paragraph	O
.	O
	
To	O
address	O
this	O
,	O
we	O
follow	O
a	O
similar	O
strategy	O
from	O
.	O
	
During	O
training	O
,	O
after	O
we	O
obtain	O
,	O
we	O
sum	O
all	O
probability	O
values	O
of	O
the	O
entity	O
instances	O
in	O
the	O
context	O
that	O
correspond	O
to	O
the	O
correct	O
answer	O
.	O
	
Then	O
the	O
loss	O
function	O
is	O
computed	O
from	O
the	O
summed	O
probability	O
.	O
	
We	O
use	O
a	O
minibatch	O
size	O
of	O
48	O
and	O
train	O
for	O
8	O
epochs	O
,	O
with	O
early	O
stop	O
when	O
the	O
accuracy	B-Metric
on	O
validation	O
data	O
starts	O
to	O
drop	O
.	O
	
Inspired	O
by	O
the	O
window	B-Method
-	I-Method
based	I-Method
method	I-Method
hill2015goldilocks	O
,	O
we	O
split	O
each	O
article	O
into	O
short	O
sentences	O
where	O
each	O
sentence	O
is	O
a	O
19	O
-	O
word	O
window	O
around	O
each	O
entity	O
(	O
hence	O
the	O
same	O
word	O
might	O
appear	O
in	O
multiple	O
sentences	O
)	O
.	O
	
The	O
RNNs	B-Method
in	O
BiDAF	B-Method
are	O
not	O
feed	O
-	O
forwarded	O
or	O
back	O
-	O
propagated	O
across	O
sentences	O
,	O
which	O
speed	O
up	O
the	O
training	B-Method
process	I-Method
by	O
parallelization	B-Task
.	O
	
The	O
entire	O
training	O
process	O
takes	O
roughly	O
60	O
hours	O
on	O
eight	O
Titan	O
X	O
GPUs	O
.	O
	
The	O
other	O
hyper	O
-	O
parameters	O
are	O
identical	O
to	O
the	O
model	O
described	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
paragraph	O
:	O
Results	O
.	O
	
The	O
results	O
of	O
our	O
single	B-Method
-	I-Method
run	I-Method
models	I-Method
and	O
competing	O
approaches	O
on	O
the	O
CNN	B-Material
/	I-Material
DailyMail	I-Material
datasets	I-Material
are	O
summarized	O
in	O
Table	O
[	O
reference	O
]	O
.	O
indicates	O
ensemble	B-Method
methods	I-Method
.	O
	
BiDAF	B-Method
outperforms	O
previous	O
single	B-Method
-	I-Method
run	I-Method
models	I-Method
on	O
both	O
datasets	O
for	O
both	O
val	O
and	O
test	O
data	O
.	O
	
On	O
the	O
DailyMail	B-Material
test	O
,	O
our	O
single	B-Method
-	I-Method
run	I-Method
model	I-Method
even	O
outperforms	O
the	O
best	O
ensemble	B-Method
method	I-Method
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
paper	O
,	O
we	O
introduce	O
BiDAF	B-Method
,	O
a	O
multi	B-Method
-	I-Method
stage	I-Method
hierarchical	I-Method
process	I-Method
that	O
represents	O
the	O
context	O
at	O
different	O
levels	O
of	O
granularity	O
and	O
uses	O
a	O
bi	B-Method
-	I-Method
directional	I-Method
attention	I-Method
flow	I-Method
mechanism	I-Method
to	O
achieve	O
a	O
query	B-Task
-	I-Task
aware	I-Task
context	I-Task
representation	I-Task
without	O
early	B-Task
summarization	I-Task
.	O
	
The	O
experimental	O
evaluations	O
show	O
that	O
our	O
model	O
achieves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
in	O
Stanford	B-Material
Question	I-Material
Answering	I-Material
Dataset	I-Material
(	O
SQuAD	B-Material
)	O
and	O
CNN	O
/	O
DailyMail	B-Material
cloze	O
test	O
.	O
	
The	O
ablation	O
analyses	O
demonstrate	O
the	O
importance	O
of	O
each	O
component	O
in	O
our	O
model	O
.	O
	
The	O
visualizations	O
and	O
discussions	O
show	O
that	O
our	O
model	O
is	O
learning	O
a	O
suitable	O
representation	O
for	O
MC	B-Task
and	O
is	O
capable	O
of	O
answering	O
complex	O
questions	O
by	O
attending	O
to	O
correct	O
locations	O
in	O
the	O
given	O
paragraph	O
.	O
	
Future	O
work	O
involves	O
extending	O
our	O
approach	O
to	O
incorporate	O
multiple	O
hops	O
of	O
the	O
attention	B-Method
layer	I-Method
.	O
	
subsubsection	O
:	O
Acknowledgments	O
	
This	O
research	O
was	O
supported	O
by	O
the	O
NSF	O
(	O
IIS	O
1616112	O
)	O
,	O
NSF	O
(	O
III	O
1703166	O
)	O
,	O
Allen	O
Institute	O
for	O
AI	O
(	O
66	O
-	O
9175	O
)	O
,	O
Allen	O
Distinguished	O
Investigator	O
Award	O
,	O
Google	O
Research	O
Faculty	O
Award	O
,	O
and	O
Samsung	O
GRO	O
Award	O
.	O
	
We	O
thank	O
the	O
anonymous	O
reviewers	O
for	O
their	O
helpful	O
comments	O
.	O
	
bibliography	O
:	O
References	O
	
appendix	O
:	O
Error	B-Method
Analysis	I-Method
	
Table	O
[	O
reference	O
]	O
summarizes	O
the	O
modes	O
of	O
errors	O
by	O
BiDAF	O
and	O
shows	O
examples	O
for	O
each	O
category	O
of	O
error	O
in	O
SQuAD	B-Material
.	O
	
Context	O
:	O
	
“	O
	
The	O
Free	O
Movement	O
of	O
Workers	O
Regulation	O
articles	O
1	O
to	O
7	O
set	O
out	O
the	O
main	O
provisions	O
on	O
equal	O
treatment	O
of	O
workers	O
.	O
	
”	O
	
Question	O
:	O
“	O
	
Which	O
articles	O
of	O
the	O
Free	O
Movement	O
of	O
Workers	O
Regulation	O
set	O
out	O
the	O
primary	O
provisions	O
on	O
equal	O
treatment	O
of	O
workers	O
?	O
	
”	O
	
Prediction	B-Task
:	O
	
“	O
1	O
to	O
7	O
”	O
,	O
	
Answer	O
:	O
	
“	O
articles	O
1	O
to	O
7	O
”	O
Context	O
:	O
	
“	O
	
A	O
piece	O
of	O
paper	O
was	O
later	O
found	O
on	O
which	O
Luther	O
had	O
written	O
his	O
last	O
statement	O
.	O
	
”	O
Question	O
:	O
“	O
	
What	O
was	O
later	O
discovered	O
written	O
by	O
Luther	O
?	O
	
”	O
	
Prediction	B-Task
:	O
	
“	O
	
A	O
piece	O
of	O
paper	O
”	O
,	O
Answer	O
:	O
	
“	O
	
his	O
last	O
statement	O
”	O
Context	O
:	O
	
“	O
	
Generally	O
,	O
education	O
in	O
Australia	O
follows	O
the	O
three	B-Method
-	I-Method
tier	I-Method
model	I-Method
which	O
includes	O
primary	O
education	O
(	O
primary	O
schools	O
)	O
,	O
followed	O
by	O
secondary	O
education	O
(	O
secondary	O
schools	O
/	O
high	O
schools	O
)	O
and	O
tertiary	O
education	O
(	O
universities	O
and	O
/	O
or	O
TAFE	O
colleges	O
)	O
.	O
	
”	O
	
Question	O
:	O
	
“	O
	
What	O
is	O
the	O
first	O
model	O
of	O
education	B-Task
,	O
in	O
the	O
Australian	B-Task
system	I-Task
?	O
	
”	O
	
Prediction	B-Task
:	O
	
“	O
three	O
-	O
tier	O
”	O
,	O
	
Answer	O
:	O
	
“	O
primary	O
education	O
”	O
Context	O
:	O
	
“	O
	
On	O
June	O
4	O
,	O
2014	O
,	O
the	O
NFL	O
announced	O
that	O
the	O
practice	O
of	O
branding	O
Super	O
Bowl	O
games	O
with	O
Roman	O
numerals	O
,	O
a	O
practice	O
established	O
at	O
Super	O
Bowl	O
V	O
,	O
would	O
be	O
temporarily	O
suspended	O
,	O
and	O
that	O
the	O
game	O
would	O
be	O
named	O
using	O
Arabic	O
numerals	O
as	O
Super	O
Bowl	O
50	O
as	O
opposed	O
to	O
	
Super	O
Bowl	O
L.	O
”	O
Question	O
:	O
“	O
	
If	O
Roman	O
numerals	O
were	O
used	O
in	O
the	O
naming	O
of	O
the	O
50th	O
Super	O
Bowl	O
,	O
which	O
one	O
would	O
have	O
been	O
used	O
?	O
	
’	O
	
Prediction	B-Task
:	O
	
“	O
	
Super	O
Bowl	O
50	O
”	O
,	O
Answer	O
:	O
	
“	O
	
L	O
”	O
Context	O
:	O
	
“	O
	
Over	O
the	O
next	O
several	O
years	O
in	O
addition	O
to	O
host	O
to	O
host	O
interactive	O
connections	O
the	O
network	O
was	O
enhanced	O
to	O
support	O
terminal	O
to	O
host	O
connections	O
,	O
host	O
to	O
host	O
batch	O
connections	O
(	O
remote	B-Task
job	I-Task
submission	I-Task
,	O
remote	B-Task
printing	I-Task
,	O
batch	B-Task
file	I-Task
transfer	I-Task
)	O
,	O
interactive	B-Task
file	I-Task
transfer	I-Task
,	O
gateways	O
to	O
the	O
Tymnet	O
and	O
Telenet	O
public	O
data	O
networks	O
,	O
X.25	O
host	O
attachments	O
,	O
gateways	O
to	O
X.25	O
data	O
networks	O
,	O
Ethernet	O
attached	O
hosts	O
,	O
and	O
eventually	O
TCP	O
/	O
IP	O
and	O
additional	O
public	O
universities	O
in	O
Michigan	O
join	O
the	O
network	O
.	O
	
All	O
of	O
this	O
set	O
the	O
stage	O
for	O
Merit	O
’s	O
role	O
in	O
the	O
NSFNET	B-Task
project	I-Task
starting	O
in	O
the	O
mid	O
-	O
1980s	O
.	O
	
”	O
Question	O
:	O
“	O
	
What	O
set	O
the	O
stage	O
for	O
Merits	O
role	O
in	O
NSFNET	O
	
”	O
Prediction	B-Task
:	O
	
“	O
	
All	O
of	O
this	O
set	O
the	O
stage	O
for	O
Merit	O
’s	O
role	O
in	O
the	O
NSFNET	B-Task
project	I-Task
starting	O
in	O
the	O
mid	O
-	O
1980s	O
”	O
,	O
Answer	O
:	O
	
“	O
Ethernet	O
attached	O
hosts	O
,	O
and	O
eventually	O
TCP	B-Method
/	I-Method
IP	I-Method
and	O
additional	O
public	O
universities	O
in	O
Michigan	O
join	O
the	O
network	O
”	O
Context	O
:	O
	
“	O
English	O
chemist	O
John	O
Mayow	O
(	O
1641	O
-	O
1679	O
)	O
refined	O
this	O
work	O
by	O
showing	O
that	O
fire	O
requires	O
only	O
a	O
part	O
of	O
air	O
that	O
he	O
called	O
spiritus	O
nitroaereus	O
or	O
just	O
nitroaereus	O
.	O
	
”	O
	
Question	O
:	O
	
“	O
John	O
Mayow	O
died	O
in	O
what	O
year	O
?	O
	
”	O
	
Prediction	B-Task
:	O
“	O
1641	O
-	O
1679	O
”	O
,	O
Answer	O
:	O
	
“	O
1679	O
”	O
	
appendix	O
:	O
Variations	O
of	O
Similarity	B-Method
and	I-Method
Fusion	I-Method
Functions	I-Method
	
In	O
this	O
appendix	O
section	O
,	O
we	O
experimentally	O
demonstrate	O
how	O
different	O
choices	O
of	O
the	O
similarity	O
function	O
(	O
Equation	O
[	O
reference	O
]	O
)	O
and	O
the	O
fusion	O
function	O
(	O
Equation	O
[	O
reference	O
]	O
)	O
impact	O
the	O
performance	O
of	O
our	O
model	O
.	O
	
Each	O
variation	O
is	O
defined	O
as	O
following	O
:	O
	
paragraph	O
:	O
Eqn	O
.	O
[	O
reference	O
]	O
:	O
dot	O
product	O
.	O
	
Dot	O
product	O
is	O
defined	O
as	O
where	O
indicates	O
matrix	O
transpose	O
.	O
	
Dot	B-Method
product	I-Method
has	O
been	O
used	O
for	O
the	O
measurement	O
of	O
similarity	O
between	O
two	O
vectors	O
by	O
.	O
	
paragraph	O
:	O
Eqn	O
.	O
[	O
reference	O
]	O
:	O
linear	O
.	O
	
Linear	O
is	O
defined	O
as	O
where	O
is	O
a	O
trainable	O
weight	O
matrix	O
.	O
	
This	O
can	O
be	O
considered	O
as	O
the	O
simplification	O
of	O
Equation	O
[	O
reference	O
]	O
by	O
dropping	O
the	O
term	O
in	O
the	O
concatenation	O
.	O
	
paragraph	O
:	O
Eqn	O
.	O
[	O
reference	O
]	O
:	O
bilinear	O
.	O
	
Bilinear	O
is	O
defined	O
as	O
where	O
is	O
a	O
trainable	O
weight	O
matrix	O
.	O
	
Bilinear	O
term	O
has	O
been	O
used	O
by	O
.	O
	
paragraph	O
:	O
Eqn	O
.	O
[	O
reference	O
]	O
:	O
linear	O
after	O
MLP	B-Method
.	O
	
We	O
can	O
also	O
perform	O
linear	B-Method
mapping	I-Method
after	O
single	B-Method
layer	I-Method
of	I-Method
perceptron	I-Method
:	O
where	O
and	O
are	O
trainable	O
weight	O
matrix	O
and	O
bias	O
,	O
respectively	O
.	O
	
Linear	B-Method
mapping	I-Method
after	O
perceptron	B-Method
layer	I-Method
has	O
been	O
used	O
by	O
.	O
	
paragraph	O
:	O
Eqn	O
.	O
[	O
reference	O
]	O
:	O
MLP	B-Method
after	O
concatenation	B-Method
.	O
	
We	O
can	O
define	O
as	O
where	O
and	O
are	O
trainable	O
weight	O
matrix	O
and	O
bias	O
.	O
	
This	O
is	O
equivalent	O
to	O
adding	O
ReLU	O
after	O
linearly	O
transforming	O
the	O
original	O
definition	O
of	O
.	O
	
Since	O
the	O
output	O
dimension	O
of	O
changes	O
,	O
the	O
input	O
dimension	O
of	O
the	O
first	O
LSTM	B-Method
of	O
the	O
modeling	B-Method
layer	I-Method
will	O
change	O
as	O
well	O
.	O
	
The	O
results	O
of	O
these	O
variations	O
on	O
the	O
dev	O
data	O
of	O
SQuAD	B-Material
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
It	O
is	O
important	O
to	O
note	O
that	O
there	O
are	O
non	O
-	O
trivial	O
gaps	O
between	O
our	O
definition	O
of	O
and	O
other	O
definitions	O
employed	O
by	O
previous	O
work	O
.	O
	
Adding	O
MLP	B-Method
in	I-Method
does	O
not	O
seem	O
to	O
help	O
,	O
yielding	O
slightly	O
worse	O
result	O
than	O
without	O
MLP	B-Method
.	O
	
document	O
:	O
Modelling	B-Task
Interaction	I-Task
of	I-Task
Sentence	I-Task
Pair	I-Task
with	O
Coupled	O
-	O
LSTMs	B-Method
	
Recently	O
,	O
there	O
is	O
rising	O
interest	O
in	O
modelling	O
the	O
interactions	B-Task
of	I-Task
two	I-Task
sentences	I-Task
with	O
deep	B-Method
neural	I-Method
networks	I-Method
.	O
	
However	O
,	O
most	O
of	O
the	O
existing	O
methods	O
encode	O
two	O
sequences	O
with	O
separate	O
encoders	B-Method
,	O
in	O
which	O
a	O
sentence	O
is	O
encoded	O
with	O
little	O
or	O
no	O
information	O
from	O
the	O
other	O
sentence	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
deep	B-Method
architecture	I-Method
to	O
model	O
the	O
strong	B-Task
interaction	I-Task
of	I-Task
sentence	I-Task
pair	I-Task
with	O
two	O
coupled	O
-	O
LSTMs	B-Method
.	O
	
Specifically	O
,	O
we	O
introduce	O
two	O
coupled	O
ways	O
to	O
model	O
the	O
interdependences	O
of	O
two	O
LSTMs	B-Method
,	O
coupling	O
the	O
local	O
contextualized	O
interactions	B-Task
of	I-Task
two	I-Task
sentences	I-Task
.	O
	
We	O
then	O
aggregate	O
these	O
interactions	O
and	O
use	O
a	O
dynamic	B-Method
pooling	I-Method
to	O
select	O
the	O
most	O
informative	O
features	O
.	O
	
Experiments	O
on	O
two	O
very	O
large	O
datasets	O
demonstrate	O
the	O
efficacy	O
of	O
our	O
proposed	O
architecture	O
and	O
its	O
superiority	O
to	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
.	O
	
section	O
:	O
Introduction	O
	
Distributed	B-Method
representations	I-Method
of	I-Method
words	I-Method
or	O
sentences	O
have	O
been	O
widely	O
used	O
in	O
many	O
natural	B-Task
language	I-Task
processing	I-Task
(	I-Task
NLP	I-Task
)	I-Task
tasks	I-Task
,	O
such	O
as	O
text	B-Task
classification	I-Task
,	O
question	B-Task
answering	I-Task
and	O
machine	B-Task
translation	I-Task
and	O
so	O
on	O
.	O
	
Among	O
these	O
tasks	O
,	O
a	O
common	O
problem	O
is	O
modelling	O
the	O
relevance	O
/	O
similarity	O
of	O
the	O
sentence	O
pair	O
,	O
which	O
is	O
also	O
called	O
text	B-Task
semantic	I-Task
matching	I-Task
.	O
	
Recently	O
,	O
deep	B-Method
learning	I-Method
based	I-Method
models	I-Method
is	O
rising	O
a	O
substantial	O
interest	O
in	O
text	B-Task
semantic	I-Task
matching	I-Task
and	O
have	O
achieved	O
some	O
great	O
progresses	O
.	O
	
According	O
to	O
the	O
phases	O
of	O
interaction	O
between	O
two	O
sentences	O
,	O
previous	O
models	O
can	O
be	O
classified	O
into	O
three	O
categories	O
.	O
	
paragraph	O
:	O
Weak	B-Method
interaction	I-Method
Models	I-Method
	
Some	O
early	O
works	O
focus	O
on	O
sentence	O
level	O
interactions	O
,	O
such	O
as	O
ARC	B-Method
-	I-Method
I	I-Method
,	O
CNTN	B-Method
and	O
so	O
on	O
.	O
	
These	O
models	O
first	O
encode	O
two	O
sequences	O
with	O
some	O
basic	O
(	O
Neural	B-Method
Bag	I-Method
-	I-Method
of	I-Method
-	I-Method
words	I-Method
,	I-Method
BOW	I-Method
)	O
or	O
advanced	B-Method
(	I-Method
RNN	I-Method
,	I-Method
CNN	I-Method
)	I-Method
components	I-Method
of	O
neural	B-Method
networks	I-Method
separately	O
,	O
and	O
then	O
compute	O
the	O
matching	B-Metric
score	I-Metric
based	O
on	O
the	O
distributed	O
vectors	O
of	O
two	O
sentences	O
.	O
	
In	O
this	O
paradigm	O
,	O
two	O
sentences	O
have	O
no	O
interaction	O
until	O
arriving	O
final	O
phase	O
.	O
	
paragraph	O
:	O
Semi	B-Method
-	I-Method
interaction	I-Method
Models	I-Method
	
Some	O
improved	O
methods	O
focus	O
on	O
utilizing	O
multi	B-Method
-	I-Method
granularity	I-Method
representation	I-Method
(	O
word	O
,	O
phrase	O
and	O
sentence	O
level	O
)	O
,	O
such	O
as	O
MultiGranCNN	B-Method
and	O
Multi	B-Method
-	I-Method
Perspective	I-Method
CNN	I-Method
.	O
	
Another	O
kind	O
of	O
models	O
use	O
soft	B-Method
attention	I-Method
mechanism	I-Method
to	O
obtain	O
the	O
representation	O
of	O
one	O
sentence	O
by	O
depending	O
on	O
representation	O
of	O
another	O
sentence	O
,	O
such	O
as	O
ABCNN	B-Method
,	O
Attention	O
LSTM	B-Method
.	O
	
These	O
models	O
can	O
alleviate	O
the	O
weak	B-Task
interaction	I-Task
problem	I-Task
,	O
but	O
are	O
still	O
insufficient	O
to	O
model	O
the	O
contextualized	O
interaction	O
on	O
the	O
word	O
as	O
well	O
as	O
phrase	O
level	O
.	O
	
paragraph	O
:	O
Strong	B-Method
Interaction	I-Method
Models	I-Method
	
These	O
models	O
directly	O
build	O
an	O
interaction	O
space	O
between	O
two	O
sentences	O
and	O
model	O
the	O
interaction	O
at	O
different	O
positions	O
.	O
	
ARC	B-Method
-	I-Method
II	I-Method
and	O
MV	O
-	O
LSTM	B-Method
.	O
	
These	O
models	O
enable	O
the	O
model	O
to	O
easily	O
capture	O
the	O
difference	O
between	O
semantic	O
capacity	O
of	O
two	O
sentences	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
new	O
deep	B-Method
neural	I-Method
network	I-Method
architecture	I-Method
to	O
model	O
the	O
strong	O
interactions	B-Task
of	I-Task
two	I-Task
sentences	I-Task
.	O
	
Different	O
with	O
modelling	O
two	O
sentences	O
with	O
separated	O
LSTMs	B-Method
,	O
we	O
utilize	O
two	O
interdependent	O
LSTMs	B-Method
,	O
called	O
coupled	O
-	O
LSTMs	B-Method
,	O
to	O
fully	O
affect	O
each	O
other	O
at	O
different	O
time	O
steps	O
.	O
	
The	O
output	O
of	O
coupled	O
-	O
LSTMs	B-Method
at	O
each	O
step	O
depends	O
on	O
both	O
sentences	O
.	O
	
Specifically	O
,	O
we	O
propose	O
two	O
interdependent	O
ways	O
for	O
the	O
coupled	O
-	O
LSTMs	B-Method
:	O
loosely	B-Method
coupled	I-Method
model	I-Method
(	O
LC	B-Method
-	I-Method
LSTMs	I-Method
)	O
and	O
tightly	B-Method
coupled	I-Method
model	I-Method
(	O
TC	B-Method
-	I-Method
LSTMs	I-Method
)	O
.	O
	
Similar	O
to	O
bidirectional	O
LSTM	B-Method
for	O
single	O
sentence	O
,	O
there	O
are	O
four	O
directions	O
can	O
be	O
used	O
in	O
coupled	O
-	O
LSTMs	B-Method
.	O
	
To	O
utilize	O
all	O
the	O
information	O
of	O
four	O
directions	O
of	O
coupled	O
-	O
LSTMs	B-Method
,	O
we	O
aggregate	O
them	O
and	O
adopt	O
a	O
dynamic	B-Method
pooling	I-Method
strategy	I-Method
to	O
automatically	O
select	O
the	O
most	O
informative	O
interaction	O
signals	O
.	O
	
Finally	O
,	O
we	O
feed	O
them	O
into	O
a	O
fully	B-Method
connected	I-Method
layer	I-Method
,	O
followed	O
by	O
an	O
output	B-Method
layer	I-Method
to	O
compute	O
the	O
matching	B-Metric
score	I-Metric
.	O
	
The	O
contributions	O
of	O
this	O
paper	O
can	O
be	O
summarized	O
as	O
follows	O
.	O
	
Different	O
with	O
the	O
architectures	O
of	O
using	O
similarity	B-Method
matrix	I-Method
,	O
our	O
proposed	O
architecture	O
directly	O
model	O
the	O
strong	O
interactions	B-Task
of	I-Task
two	I-Task
sentences	I-Task
with	O
coupled	O
-	O
LSTMs	B-Method
,	O
which	O
can	O
capture	O
the	O
useful	O
local	O
semantic	O
relevances	O
of	O
two	O
sentences	O
.	O
	
Our	O
architecture	O
can	O
also	O
capture	O
the	O
multiple	O
granular	O
interactions	O
by	O
several	O
stacked	O
coupled	O
-	O
LSTMs	B-Method
layers	O
.	O
	
Compared	O
to	O
the	O
previous	O
works	O
on	O
text	B-Task
matching	I-Task
,	O
we	O
perform	O
extensive	O
empirical	O
studies	O
on	O
two	O
very	O
large	O
datasets	O
.	O
	
The	O
massive	O
scale	O
of	O
the	O
datasets	O
allows	O
us	O
to	O
train	O
a	O
very	O
deep	B-Method
neural	I-Method
networks	I-Method
.	O
	
Experiment	O
results	O
demonstrate	O
that	O
our	O
proposed	O
architecture	O
is	O
more	O
effective	O
than	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
.	O
	
section	O
:	O
Sentence	B-Method
Modelling	I-Method
with	O
LSTM	B-Method
	
Long	O
short	O
-	O
term	O
memory	O
network	O
(	O
LSTM	B-Method
)	O
is	O
a	O
type	O
of	O
recurrent	B-Method
neural	I-Method
network	I-Method
(	O
RNN	B-Method
)	O
,	O
and	O
specifically	O
addresses	O
the	O
issue	O
of	O
learning	B-Task
long	I-Task
-	I-Task
term	I-Task
dependencies	I-Task
.	O
	
LSTM	B-Method
maintains	O
a	O
memory	O
cell	O
that	O
updates	O
and	O
exposes	O
its	O
content	O
only	O
when	O
deemed	O
necessary	O
.	O
	
While	O
there	O
are	O
numerous	O
LSTM	B-Method
variants	O
,	O
here	O
we	O
use	O
the	O
LSTM	B-Method
architecture	O
used	O
by	O
,	O
which	O
is	O
similar	O
to	O
the	O
architecture	O
of	O
but	O
without	O
peep	O
-	O
hole	O
connections	O
.	O
	
We	O
define	O
the	O
LSTM	B-Method
units	O
at	O
each	O
time	O
step	O
to	O
be	O
a	O
collection	O
of	O
vectors	O
in	O
:	O
an	O
input	O
gate	O
,	O
a	O
forget	O
gate	O
,	O
an	O
output	O
gate	O
,	O
a	O
memory	O
cell	O
and	O
a	O
hidden	O
state	O
.	O
	
is	O
the	O
number	O
of	O
the	O
LSTM	B-Method
units	O
.	O
	
The	O
elements	O
of	O
the	O
gating	O
vectors	O
,	O
and	O
are	O
in	O
.	O
	
The	O
LSTM	B-Method
is	O
precisely	O
specified	O
as	O
follows	O
.	O
	
where	O
is	O
the	O
input	O
at	O
the	O
current	O
time	O
step	O
;	O
is	O
an	O
affine	B-Method
transformation	I-Method
which	O
depends	O
on	O
parameters	O
of	O
the	O
network	O
and	O
.	O
	
denotes	O
the	O
logistic	B-Method
sigmoid	I-Method
function	I-Method
and	O
denotes	O
elementwise	B-Method
multiplication	I-Method
.	O
	
Intuitively	O
,	O
the	O
forget	O
gate	O
controls	O
the	O
amount	O
of	O
which	O
each	O
unit	O
of	O
the	O
memory	O
cell	O
is	O
erased	O
,	O
the	O
input	O
gate	O
controls	O
how	O
much	O
each	O
unit	O
is	O
updated	O
,	O
and	O
the	O
output	O
gate	O
controls	O
the	O
exposure	O
of	O
the	O
internal	O
memory	O
state	O
.	O
	
The	O
update	O
of	O
each	O
LSTM	B-Method
unit	O
can	O
be	O
written	O
precisely	O
as	O
follows	O
Here	O
,	O
the	O
function	O
is	O
a	O
shorthand	O
for	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
-	O
[	O
reference	O
]	O
)	O
.	O
	
section	O
:	O
Coupled	O
-	O
LSTMs	B-Method
for	O
Strong	B-Task
Sentence	I-Task
Interaction	I-Task
	
To	O
deal	O
with	O
two	O
sentences	O
,	O
one	O
straightforward	O
method	O
is	O
to	O
model	O
them	O
with	O
two	O
separate	O
LSTMs	B-Method
.	O
	
However	O
,	O
this	O
method	O
is	O
difficult	O
to	O
model	O
local	O
interactions	B-Task
of	I-Task
two	I-Task
sentences	I-Task
.	O
	
An	O
improved	O
way	O
is	O
to	O
introduce	O
attention	B-Method
mechanism	I-Method
,	O
which	O
has	O
been	O
used	O
in	O
many	O
tasks	O
,	O
such	O
as	O
machine	B-Task
translation	I-Task
and	O
question	B-Task
answering	I-Task
.	O
	
Inspired	O
by	O
the	O
multi	B-Method
-	I-Method
dimensional	I-Method
recurrent	I-Method
neural	I-Method
network	I-Method
and	O
grid	O
LSTM	B-Method
in	O
computer	B-Task
vision	I-Task
community	I-Task
,	O
we	O
propose	O
two	O
models	O
to	O
capture	O
the	O
interdependences	O
between	O
two	O
parallel	O
LSTMs	B-Method
,	O
called	O
coupled	O
-	O
LSTMs	B-Method
(	O
C	B-Method
-	I-Method
LSTMs	I-Method
)	O
.	O
	
[	O
Parallel	O
LSTMs	B-Method
]	O
	
[	O
Attention	O
LSTMs	B-Method
]	O
[	O
Loosely	O
coupled	O
-	O
LSTMs	B-Method
]	O
	
[	O
Tightly	B-Method
coupled	I-Method
-	I-Method
LSTMs	I-Method
]	O
	
To	O
facilitate	O
our	O
models	O
,	O
we	O
firstly	O
give	O
some	O
definitions	O
.	O
	
Given	O
two	O
sequences	O
and	O
,	O
we	O
let	O
denote	O
the	O
embedded	B-Method
representation	I-Method
of	O
the	O
word	O
.	O
	
The	O
standard	O
LSTM	B-Method
have	O
one	O
temporal	O
dimension	O
.	O
	
When	O
dealing	O
with	O
a	O
sentence	O
,	O
LSTM	B-Method
regards	O
the	O
position	O
as	O
time	O
step	O
.	O
	
At	O
position	O
of	O
sentence	O
,	O
the	O
output	O
reflects	O
the	O
meaning	O
of	O
subsequence	O
.	O
	
To	O
model	O
the	O
interaction	O
of	O
two	O
sentences	O
as	O
early	O
as	O
possible	O
,	O
we	O
define	O
to	O
represent	O
the	O
interaction	O
of	O
the	O
subsequences	O
and	O
.	O
	
Figure	O
[	O
reference	O
]	O
	
(	O
c	O
)	O
and	O
[	O
reference	O
]	O
(	O
d	O
)	O
illustrate	O
our	O
two	O
propose	O
models	O
.	O
	
For	O
intuitive	O
comparison	O
of	O
weak	B-Method
interaction	I-Method
parallel	I-Method
LSTMs	I-Method
,	O
we	O
also	O
give	O
parallel	O
LSTMs	B-Method
and	O
attention	O
LSTMs	B-Method
in	O
Figure	O
[	O
reference	O
]	O
(	O
a	O
)	O
and	O
[	O
reference	O
]	O
(	O
b	O
)	O
.	O
	
We	O
describe	O
our	O
two	O
proposed	O
models	O
as	O
follows	O
.	O
	
subsection	O
:	O
Loosely	O
Coupled	O
-	O
LSTMs	B-Method
(	O
LC	O
-	O
LSTMs	B-Method
)	O
	
To	O
model	O
the	O
local	O
contextual	O
interactions	B-Task
of	I-Task
two	I-Task
sentences	I-Task
,	O
we	O
enable	O
two	O
LSTMs	B-Method
to	O
be	O
interdependent	O
at	O
different	O
positions	O
.	O
	
Inspired	O
by	O
Grid	O
LSTM	B-Method
and	O
word	O
-	O
by	O
-	O
word	O
attention	O
LSTMs	B-Method
,	O
we	O
propose	O
a	O
loosely	B-Method
coupling	I-Method
model	I-Method
for	O
two	O
interdependent	O
LSTMs	B-Method
.	O
	
More	O
concretely	O
,	O
we	O
refer	O
to	O
as	O
the	O
encoding	O
of	O
subsequence	O
in	O
the	O
first	O
LSTM	B-Method
influenced	O
by	O
the	O
output	O
of	O
the	O
second	O
LSTM	B-Method
on	O
subsequence	O
.	O
	
Meanwhile	O
,	O
is	O
the	O
encoding	O
of	O
subsequence	O
in	O
the	O
second	O
LSTM	B-Method
influenced	O
by	O
the	O
output	O
of	O
the	O
first	O
LSTM	B-Method
on	O
subsequence	O
and	O
are	O
computed	O
as	O
where	O
	
subsection	O
:	O
Tightly	B-Method
Coupled	I-Method
-	I-Method
LSTMs	I-Method
(	O
TC	B-Method
-	I-Method
LSTMs	I-Method
)	O
	
The	O
hidden	O
states	O
of	O
LC	B-Method
-	I-Method
LSTMs	I-Method
are	O
the	O
combination	O
of	O
the	O
hidden	O
states	O
of	O
two	O
interdependent	O
LSTMs	B-Method
,	O
whose	O
memory	O
cells	O
are	O
separated	O
.	O
	
Inspired	O
by	O
the	O
configuration	O
of	O
the	O
multi	O
-	O
dimensional	O
LSTM	B-Method
,	O
we	O
further	O
conflate	O
both	O
the	O
hidden	O
states	O
and	O
the	O
memory	O
cells	O
of	O
two	O
LSTMs	B-Method
.	O
	
We	O
assume	O
that	O
directly	O
model	O
the	O
interaction	O
of	O
the	O
subsequences	O
and	O
,	O
which	O
depends	O
on	O
two	O
previous	O
interaction	O
and	O
,	O
where	O
are	O
the	O
positions	O
in	O
sentence	O
and	O
.	O
	
We	O
define	O
a	O
tightly	B-Method
coupled	I-Method
-	I-Method
LSTMs	I-Method
units	I-Method
as	O
follows	O
.	O
	
where	O
the	O
gating	B-Method
units	I-Method
and	O
determine	O
which	O
memory	O
units	O
are	O
affected	O
by	O
the	O
inputs	O
through	O
,	O
and	O
which	O
memory	O
cells	O
are	O
written	O
to	O
the	O
hidden	O
units	O
.	O
	
is	O
an	O
affine	B-Method
transformation	I-Method
which	O
depends	O
on	O
parameters	O
of	O
the	O
network	O
and	O
.	O
	
In	O
contrast	O
to	O
the	O
standard	O
LSTM	B-Method
defined	O
over	O
time	O
,	O
each	O
memory	B-Method
unit	I-Method
of	O
a	O
tightly	O
coupled	O
-	O
LSTMs	B-Method
has	O
two	O
preceding	O
states	O
and	O
and	O
two	O
corresponding	O
forget	O
gates	O
and	O
.	O
	
subsection	O
:	O
Analysis	O
of	O
Two	O
Proposed	O
Models	O
	
Our	O
two	O
proposed	O
coupled	O
-	O
LSTMs	B-Method
can	O
be	O
formulated	O
as	O
where	O
C	B-Method
-	I-Method
LSTMs	I-Method
can	O
be	O
either	O
TC	B-Method
-	I-Method
LSTMs	I-Method
or	O
LC	B-Method
-	I-Method
LSTMs	I-Method
.	O
	
The	O
input	O
consisted	O
of	O
two	O
type	O
of	O
information	O
at	O
step	O
(	O
i	O
,	O
j	O
)	O
in	O
coupled	O
-	O
LSTMs	B-Method
:	O
temporal	O
dimension	O
h	O
-	O
i1	O
,	O
j	O
,	O
hi	O
,-	O
j1	O
,	O
c	O
-	O
i1	O
,	O
j	O
,	O
ci	O
,-	O
j1	O
and	O
depth	O
dimension	O
xi	O
,	O
yj	O
.	O
	
The	O
difference	O
between	O
TC	B-Method
-	I-Method
LSTMs	I-Method
and	O
LC	B-Method
-	I-Method
LSTMs	I-Method
is	O
the	O
dependence	O
of	O
information	O
from	O
temporal	O
and	O
depth	O
dimension	O
.	O
	
paragraph	O
:	O
Interaction	O
Between	O
Temporal	O
Dimensions	O
	
The	O
TC	B-Method
-	I-Method
LSTMs	I-Method
model	I-Method
the	O
interactions	O
at	O
position	O
by	O
merging	O
the	O
internal	O
memory	O
and	O
hidden	O
state	O
along	O
row	O
and	O
column	O
dimensions	O
.	O
	
In	O
contrast	O
with	O
TC	B-Method
-	I-Method
LSTMs	I-Method
,	O
LC	B-Method
-	I-Method
LSTMs	I-Method
firstly	O
use	O
two	O
standard	O
LSTMs	B-Method
in	O
parallel	O
,	O
producing	O
hidden	O
states	O
and	O
along	O
row	O
and	O
column	O
dimensions	O
respectively	O
,	O
which	O
are	O
then	O
merged	O
together	O
flowing	O
next	O
step	O
.	O
	
paragraph	O
:	O
Interaction	O
Between	O
Depth	O
Dimension	O
	
In	O
TC	B-Method
-	I-Method
LSTMs	I-Method
,	O
each	O
hidden	O
state	O
at	O
higher	O
layer	O
receives	O
a	O
fusion	O
of	O
information	O
and	O
,	O
flowed	O
from	O
lower	O
layer	O
.	O
	
However	O
,	O
in	O
LC	B-Method
-	I-Method
LSTMs	I-Method
,	O
the	O
information	O
and	O
are	O
accepted	O
by	O
two	O
corresponding	O
LSTMs	B-Method
at	O
the	O
higher	O
layer	O
separately	O
.	O
	
The	O
two	O
architectures	O
have	O
their	O
own	O
characteristics	O
,	O
TC	B-Method
-	I-Method
LSTMs	I-Method
give	O
more	O
strong	O
interactions	O
among	O
different	O
dimensions	O
while	O
LC	B-Method
-	I-Method
LSTMs	I-Method
ensures	O
the	O
two	O
sequences	O
interact	O
closely	O
without	O
being	O
conflated	O
using	O
two	O
separated	O
LSTMs	B-Method
.	O
	
subsubsection	O
:	O
Comparison	O
of	O
LC	B-Method
-	I-Method
LSTMs	I-Method
and	O
word	O
-	O
by	O
-	O
word	O
Attention	O
LSTMs	B-Method
	
The	O
main	O
idea	O
of	O
attention	O
LSTMs	B-Method
is	O
that	O
the	O
representation	O
of	O
sentence	O
X	O
is	O
obtained	O
dynamically	O
based	O
on	O
the	O
alignment	O
degree	O
between	O
the	O
words	O
in	O
sentence	O
X	O
and	O
Y	O
,	O
which	O
is	O
asymmetric	O
unidirectional	B-Method
encoding	I-Method
.	O
	
Nevertheless	O
,	O
in	O
LC	O
-	O
LSTM	B-Method
,	O
each	O
hidden	O
state	O
of	O
each	O
step	O
is	O
obtained	O
with	O
the	O
consideration	O
of	O
interaction	O
between	O
two	O
sequences	O
with	O
symmetrical	O
encoding	O
fashion	O
.	O
	
section	O
:	O
End	O
-	O
to	O
-	O
End	B-Method
Architecture	I-Method
for	O
Sentence	B-Task
Matching	I-Task
	
In	O
this	O
section	O
,	O
we	O
present	O
an	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
deep	I-Method
architecture	I-Method
for	O
matching	O
two	O
sentences	O
,	O
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
subsection	O
:	O
Embedding	B-Method
Layer	I-Method
	
To	O
model	O
the	O
sentences	O
with	O
neural	B-Method
model	I-Method
,	O
we	O
firstly	O
need	O
transform	O
the	O
one	B-Method
-	I-Method
hot	I-Method
representation	I-Method
of	I-Method
word	I-Method
into	O
the	O
distributed	B-Method
representation	I-Method
.	O
	
All	O
words	O
of	O
two	O
sequences	O
and	O
will	O
be	O
mapped	O
into	O
low	B-Method
dimensional	I-Method
vector	I-Method
representations	I-Method
,	O
which	O
are	O
taken	O
as	O
input	O
of	O
the	O
network	O
.	O
	
subsection	O
:	O
Stacked	O
Coupled	O
-	O
LSTMs	B-Method
Layers	O
	
After	O
the	O
embedding	B-Method
layer	I-Method
,	O
we	O
use	O
our	O
proposed	O
coupled	O
-	O
LSTMs	B-Method
to	O
capture	O
the	O
strong	O
interactions	O
between	O
two	O
sentences	O
.	O
	
A	O
basic	O
block	O
consists	O
of	O
five	O
layers	O
.	O
	
We	O
firstly	O
use	O
four	O
directional	O
coupled	O
-	O
LSTMs	B-Method
to	O
model	O
the	O
local	O
interactions	O
with	O
different	O
information	O
flows	O
.	O
	
And	O
then	O
we	O
sum	O
the	O
outputs	O
of	O
these	O
LSTMs	B-Method
by	O
aggregation	B-Method
layer	I-Method
.	O
	
To	O
increase	O
the	O
learning	B-Task
capabilities	O
of	O
the	O
coupled	O
-	O
LSTMs	B-Method
,	O
we	O
stack	O
the	O
basic	O
block	O
on	O
top	O
of	O
each	O
other	O
.	O
	
subsubsection	O
:	O
Four	O
Directional	O
Coupled	O
-	O
LSTMs	B-Method
Layers	O
	
The	O
C	B-Method
-	I-Method
LSTMs	I-Method
is	O
defined	O
along	O
a	O
certain	O
pre	O
-	O
defined	O
direction	O
,	O
we	O
can	O
extend	O
them	O
to	O
access	O
to	O
the	O
surrounding	O
context	O
in	O
all	O
directions	O
.	O
	
Similar	O
to	O
bi	O
-	O
directional	O
LSTM	B-Method
,	O
there	O
are	O
four	O
directions	O
in	O
coupled	O
-	O
LSTMs	B-Method
.	O
	
subsubsection	O
:	O
Aggregation	B-Method
Layer	I-Method
	
The	O
aggregation	B-Method
layer	I-Method
sums	O
the	O
outputs	O
of	O
four	O
directional	O
coupled	O
-	O
LSTMs	B-Method
into	O
a	O
vector	O
.	O
	
where	O
the	O
superscript	O
of	O
denotes	O
the	O
different	O
directions	O
.	O
	
subsubsection	O
:	O
Stacking	B-Method
C	I-Method
-	I-Method
LSTMs	I-Method
Blocks	I-Method
	
To	O
increase	O
the	O
capabilities	O
of	O
network	O
of	O
learning	B-Task
multiple	I-Task
granularities	I-Task
of	I-Task
interactions	I-Task
,	O
we	O
stack	O
several	O
blocks	O
(	O
four	O
C	O
-	O
LSTMs	B-Method
layers	O
and	O
one	O
aggregation	B-Method
layer	I-Method
)	O
to	O
form	O
deep	B-Method
architectures	I-Method
.	O
	
subsection	O
:	O
Pooling	B-Method
Layer	I-Method
	
The	O
output	O
of	O
stacked	O
coupled	O
-	O
LSTMs	B-Method
layers	O
is	O
a	O
tensor	O
,	O
where	O
and	O
are	O
the	O
lengths	O
of	O
sentences	O
,	O
and	O
is	O
the	O
number	O
of	O
hidden	O
neurons	O
.	O
	
We	O
apply	O
dynamic	B-Method
pooling	I-Method
to	O
automatically	O
extract	O
subsampling	O
matrix	O
in	O
each	O
slice	O
,	O
similar	O
to	O
.	O
	
More	O
formally	O
,	O
for	O
each	O
slice	O
matrix	O
,	O
we	O
partition	O
the	O
rows	O
and	O
columns	O
of	O
into	O
roughly	O
equal	O
grids	O
.	O
	
These	O
grid	O
are	O
non	O
-	O
overlapping	O
.	O
	
Then	O
we	O
select	O
the	O
maximum	O
value	O
within	O
each	O
grid	O
.	O
	
Since	O
each	O
slice	O
consists	O
of	O
the	O
hidden	O
states	O
of	O
one	O
neuron	O
at	O
different	O
positions	O
,	O
the	O
pooling	B-Method
operation	I-Method
can	O
be	O
regarded	O
as	O
the	O
most	O
informative	O
interactions	O
captured	O
by	O
the	O
neuron	O
.	O
	
Thus	O
,	O
we	O
get	O
a	O
tensor	O
,	O
which	O
is	O
further	O
reshaped	O
into	O
a	O
vector	O
.	O
	
subsection	O
:	O
Fully	B-Method
-	I-Method
Connected	I-Method
Layer	I-Method
	
The	O
vector	O
obtained	O
by	O
pooling	B-Method
layer	I-Method
is	O
fed	O
into	O
a	O
full	B-Method
connection	I-Method
layer	I-Method
to	O
obtain	O
a	O
final	O
more	O
abstractive	B-Method
representation	I-Method
.	O
	
subsection	O
:	O
Output	O
Layer	O
	
The	O
output	O
layer	O
depends	O
on	O
the	O
types	O
of	O
the	O
tasks	O
,	O
we	O
choose	O
the	O
corresponding	O
form	O
of	O
output	O
layer	O
.	O
	
There	O
are	O
two	O
popular	O
types	O
of	O
text	B-Task
matching	I-Task
tasks	I-Task
in	O
NLP	B-Task
.	O
	
One	O
is	O
ranking	B-Task
task	I-Task
,	O
such	O
as	O
community	B-Task
question	I-Task
answering	I-Task
.	O
	
Another	O
is	O
classification	B-Task
task	I-Task
,	O
such	O
as	O
textual	B-Task
entailment	I-Task
.	O
	
For	O
ranking	B-Task
task	I-Task
,	O
the	O
output	O
is	O
a	O
scalar	B-Metric
matching	I-Metric
score	I-Metric
,	O
which	O
is	O
obtained	O
by	O
a	O
linear	B-Method
transformation	I-Method
after	O
the	O
last	O
fully	B-Method
-	I-Method
connected	I-Method
layer	I-Method
.	O
	
For	O
classification	B-Task
task	I-Task
,	O
the	O
outputs	O
are	O
the	O
probabilities	O
of	O
the	O
different	O
classes	O
,	O
which	O
is	O
computed	O
by	O
a	O
softmax	B-Method
function	I-Method
after	O
the	O
last	O
fully	B-Method
-	I-Method
connected	I-Method
layer	I-Method
.	O
	
section	O
:	O
Training	O
	
Our	O
proposed	O
architecture	O
can	O
deal	O
with	O
different	O
sentence	B-Task
matching	I-Task
tasks	I-Task
.	O
	
The	O
loss	B-Method
functions	I-Method
varies	O
with	O
different	O
tasks	O
.	O
	
paragraph	O
:	O
Max	B-Metric
-	I-Metric
Margin	I-Metric
Loss	I-Metric
for	O
Ranking	B-Task
Task	I-Task
	
Given	O
a	O
positive	O
sentence	O
pair	O
and	O
its	O
corresponding	O
negative	O
pair	O
.	O
	
The	O
matching	B-Metric
score	I-Metric
should	O
be	O
larger	O
than	O
.	O
	
For	O
this	O
task	O
,	O
we	O
use	O
the	O
contrastive	B-Method
max	I-Method
-	I-Method
margin	I-Method
criterion	I-Method
to	O
train	O
our	O
models	O
on	O
matching	B-Task
task	I-Task
.	O
	
The	O
ranking	B-Metric
-	I-Metric
based	I-Metric
loss	I-Metric
is	O
defined	O
as	O
where	O
is	O
predicted	B-Metric
matching	I-Metric
score	I-Metric
for	O
.	O
	
paragraph	O
:	O
Cross	B-Metric
-	I-Metric
entropy	I-Metric
Loss	I-Metric
for	O
Classification	B-Task
Task	I-Task
	
Given	O
a	O
sentence	O
pair	O
and	O
its	O
label	O
.	O
	
The	O
output	O
of	O
neural	B-Method
network	I-Method
is	O
the	O
probabilities	O
of	O
the	O
different	O
classes	O
.	O
	
The	O
parameters	O
of	O
the	O
network	O
are	O
trained	O
to	O
minimise	O
the	O
cross	O
-	O
entropy	O
of	O
the	O
predicted	O
and	O
true	O
label	O
distributions	O
.	O
	
where	O
l	O
is	O
one	O
-	O
hot	B-Method
representation	I-Method
of	O
the	O
ground	O
-	O
truth	O
label	O
;	O
is	O
predicted	O
probabilities	O
of	O
labels	O
;	O
is	O
the	O
class	O
number	O
.	O
	
To	O
minimize	O
the	O
objective	O
,	O
we	O
use	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
with	O
the	O
diagonal	B-Method
variant	I-Method
of	I-Method
AdaGrad	I-Method
.	O
	
To	O
prevent	O
exploding	O
gradients	O
,	O
we	O
perform	O
gradient	B-Method
clipping	I-Method
by	O
scaling	O
the	O
gradient	O
when	O
the	O
norm	O
exceeds	O
a	O
threshold	O
.	O
	
section	O
:	O
Experiment	O
	
In	O
this	O
section	O
,	O
we	O
investigate	O
the	O
empirical	O
performances	O
of	O
our	O
proposed	O
model	O
on	O
two	O
different	O
text	B-Task
matching	I-Task
tasks	I-Task
:	O
classification	B-Task
task	I-Task
(	O
recognizing	B-Task
textual	I-Task
entailment	I-Task
)	O
and	O
ranking	B-Task
task	I-Task
(	O
matching	B-Task
of	I-Task
question	I-Task
and	I-Task
answer	I-Task
)	O
.	O
	
subsection	O
:	O
Hyperparameters	B-Method
and	O
Training	O
	
The	O
word	O
embeddings	O
for	O
all	O
of	O
the	O
models	O
are	O
initialized	O
with	O
the	O
100d	O
GloVe	O
vectors	O
(	O
840B	O
token	O
version	O
,	O
)	O
and	O
fine	O
-	O
tuned	O
during	O
training	O
to	O
improve	O
the	O
performance	O
.	O
	
The	O
other	O
parameters	O
are	O
initialized	O
by	O
randomly	O
sampling	O
from	O
uniform	O
distribution	O
in	O
.	O
	
For	O
each	O
task	O
,	O
we	O
take	O
the	O
hyperparameters	O
which	O
achieve	O
the	O
best	O
performance	O
on	O
the	O
development	O
set	O
via	O
an	O
small	O
grid	O
search	O
over	O
combinations	O
of	O
the	O
initial	O
learning	B-Metric
rate	I-Metric
,	O
regularization	O
and	O
the	O
threshold	O
value	O
of	O
gradient	O
norm	O
[	O
5	O
,	O
10	O
,	O
100	O
]	O
.	O
	
The	O
final	O
hyper	O
-	O
parameters	O
are	O
set	O
as	O
Table	O
[	O
reference	O
]	O
.	O
	
subsection	O
:	O
Competitor	B-Method
Methods	I-Method
	
Neural	B-Task
bag	I-Task
-	I-Task
of	I-Task
-	I-Task
words	I-Task
(	O
NBOW	B-Method
)	O
:	O
	
Each	O
sequence	O
as	O
the	O
sum	O
of	O
the	O
embeddings	O
of	O
the	O
words	O
it	O
contains	O
,	O
then	O
they	O
are	O
concatenated	O
and	O
fed	O
to	O
a	O
MLP	B-Method
.	O
	
Single	O
LSTM	B-Method
:	O
	
A	O
single	O
LSTM	B-Method
to	O
encode	O
the	O
two	O
sequences	O
,	O
which	O
is	O
used	O
in	O
.	O
	
Parallel	O
LSTMs	B-Method
:	O
	
Two	O
sequences	O
are	O
encoded	O
by	O
two	O
LSTMs	B-Method
separately	O
,	O
then	O
they	O
are	O
concatenated	O
and	O
fed	O
to	O
a	O
MLP	B-Method
.	O
	
Attention	O
LSTMs	B-Method
:	O
An	O
attentive	O
LSTM	B-Method
to	O
encode	O
two	O
sentences	O
into	O
a	O
semantic	O
space	O
,	O
which	O
used	O
in	O
.	O
	
Word	O
-	O
by	O
-	O
word	O
Attention	O
LSTMs	B-Method
:	O
An	O
improvement	O
of	O
attention	O
LSTM	B-Method
by	O
introducing	O
word	B-Method
-	I-Method
by	I-Method
-	I-Method
word	I-Method
attention	I-Method
mechanism	I-Method
,	O
which	O
used	O
in	O
.	O
	
subsection	O
:	O
Experiment	O
-	O
I	O
:	O
Recognizing	B-Task
Textual	I-Task
Entailment	I-Task
	
Recognizing	B-Task
textual	I-Task
entailment	I-Task
(	O
RTE	B-Task
)	O
is	O
a	O
task	O
to	O
determine	O
the	O
semantic	O
relationship	O
between	O
two	O
sentences	O
.	O
	
We	O
use	O
the	O
Stanford	B-Material
Natural	I-Material
Language	I-Material
Inference	I-Material
Corpus	I-Material
(	O
SNLI	B-Material
)	O
.	O
	
This	O
corpus	O
contains	O
570	O
K	O
sentence	O
pairs	O
,	O
and	O
all	O
of	O
the	O
sentences	O
and	O
labels	O
stem	O
from	O
human	O
annotators	O
.	O
	
SNLI	B-Material
is	O
two	O
orders	O
of	O
magnitude	O
larger	O
than	O
all	O
other	O
existing	O
RTE	B-Task
corpora	O
.	O
	
Therefore	O
,	O
the	O
massive	O
scale	O
of	O
SNLI	B-Material
allows	O
us	O
to	O
train	O
powerful	O
neural	B-Method
networks	I-Method
such	O
as	O
our	O
proposed	O
architecture	O
in	O
this	O
paper	O
.	O
	
subsubsection	O
:	O
Results	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
evaluation	O
results	O
on	O
SNLI	B-Material
.	O
	
The	O
rd	O
column	O
of	O
the	O
table	O
gives	O
the	O
number	O
of	O
parameters	O
of	O
different	O
models	O
without	O
the	O
word	O
embeddings	O
.	O
	
Our	O
proposed	O
two	O
C	O
-	O
LSTMs	B-Method
models	O
with	O
four	O
stacked	O
blocks	O
outperform	O
all	O
the	O
competitor	O
models	O
,	O
which	O
indicates	O
that	O
our	O
thinner	O
and	O
deeper	B-Method
network	I-Method
does	O
work	O
effectively	O
.	O
	
Besides	O
,	O
we	O
can	O
see	O
both	O
LC	B-Method
-	I-Method
LSTMs	I-Method
and	O
TC	B-Method
-	I-Method
LSTMs	I-Method
benefit	O
from	O
multi	O
-	O
directional	O
layer	O
,	O
while	O
the	O
latter	O
obtains	O
more	O
gains	O
than	O
the	O
former	O
.	O
	
We	O
attribute	O
this	O
discrepancy	O
between	O
two	O
models	O
to	O
their	O
different	O
mechanisms	O
of	O
controlling	O
the	O
information	O
flow	O
from	O
depth	O
dimension	O
.	O
	
Compared	O
with	O
attention	O
LSTMs	B-Method
,	O
our	O
two	O
models	O
achieve	O
comparable	O
results	O
to	O
them	O
using	O
much	O
fewer	O
parameters	O
(	O
nearly	O
)	O
.	O
	
By	O
stacking	B-Method
C	I-Method
-	I-Method
LSTMs	I-Method
,	O
the	O
performance	O
of	O
them	O
are	O
improved	O
significantly	O
,	O
and	O
the	O
four	O
stacked	O
TC	O
-	O
LSTMs	B-Method
achieve	O
accuracy	B-Metric
on	O
this	O
dataset	O
.	O
	
Moreover	O
,	O
we	O
can	O
see	O
TC	B-Method
-	I-Method
LSTMs	I-Method
achieve	O
better	O
performance	O
than	O
LC	B-Method
-	I-Method
LSTMs	I-Method
on	O
this	O
task	O
,	O
which	O
need	O
fine	O
-	O
grained	O
reasoning	O
over	O
pairs	O
of	O
words	O
as	O
well	O
as	O
phrases	O
.	O
	
[	O
3rd	O
neuron	O
]	O
	
[	O
17th	O
neuron	O
]	O
	
subsubsection	O
:	O
Understanding	B-Task
Behaviors	I-Task
of	I-Task
Neurons	I-Task
in	O
C	B-Method
-	I-Method
LSTMs	I-Method
	
To	O
get	O
an	O
intuitive	O
understanding	O
of	O
how	O
the	O
C	B-Method
-	I-Method
LSTMs	I-Method
work	O
on	O
this	O
problem	O
,	O
we	O
examined	O
the	O
neuron	O
activations	O
in	O
the	O
last	O
aggregation	B-Method
layer	I-Method
while	O
evaluating	O
the	O
test	O
set	O
using	O
TC	B-Method
-	I-Method
LSTMs	I-Method
.	O
	
We	O
find	O
that	O
some	O
cells	O
are	O
bound	O
to	O
certain	O
roles	O
.	O
	
Let	O
denotes	O
the	O
activation	O
of	O
the	O
-	O
th	O
neuron	O
at	O
the	O
position	O
of	O
,	O
where	O
and	O
.	O
	
By	O
visualizing	O
the	O
hidden	O
state	O
and	O
analyzing	O
the	O
maximum	O
activation	O
,	O
we	O
can	O
find	O
that	O
there	O
exist	O
multiple	O
interpretable	O
neurons	O
.	O
	
For	O
example	O
,	O
when	O
some	O
contextualized	O
local	O
perspectives	O
are	O
semantically	O
related	O
at	O
point	O
of	O
the	O
sentence	O
pair	O
,	O
the	O
activation	O
value	O
of	O
hidden	O
neuron	O
tend	O
to	O
be	O
maximum	O
,	O
meaning	O
that	O
the	O
model	O
could	O
capture	O
some	O
reasoning	O
patterns	O
.	O
	
Figure	O
[	O
reference	O
]	O
illustrates	O
this	O
phenomenon	O
.	O
	
In	O
Figure	O
[	O
reference	O
]	O
(	O
a	O
)	O
,	O
a	O
neuron	O
shows	O
its	O
ability	O
to	O
monitor	O
the	O
local	O
contextual	O
interactions	O
about	O
color	O
.	O
	
The	O
activation	O
in	O
the	O
patch	O
,	O
including	O
the	O
word	O
pair	O
“	O
(	O
red	O
,	O
green	O
)	O
”	O
,	O
is	O
much	O
higher	O
than	O
others	O
.	O
	
This	O
is	O
informative	O
pattern	O
for	O
the	O
relation	B-Task
prediction	I-Task
of	O
these	O
two	O
sentences	O
,	O
whose	O
ground	O
truth	O
is	O
contradiction	O
.	O
	
An	O
interesting	O
thing	O
is	O
there	O
are	O
two	O
words	O
describing	O
color	O
in	O
the	O
sentence	O
	
“	O
	
A	O
person	O
in	O
a	O
red	O
shirt	O
and	O
black	O
pants	O
hunched	O
over	O
.	O
”	O
.	O
	
Our	O
model	O
ignores	O
the	O
useless	O
word	O
“	O
black	O
”	O
,	O
which	O
indicates	O
that	O
this	O
neuron	O
selectively	O
captures	O
pattern	O
by	O
contextual	O
understanding	O
,	O
not	O
just	O
word	O
level	O
interaction	O
.	O
	
In	O
Figure	O
[	O
reference	O
]	O
(	O
b	O
)	O
,	O
another	O
neuron	O
shows	O
that	O
it	O
can	O
capture	O
the	O
local	O
contextual	O
interactions	O
,	O
such	O
as	O
	
“	O
(	O
walking	O
down	O
the	O
street	O
,	O
outside	O
)	O
”	O
.	O
	
These	O
patterns	O
can	O
be	O
easily	O
captured	O
by	O
pooling	B-Method
layer	I-Method
and	O
provide	O
a	O
strong	O
support	O
for	O
the	O
final	O
prediction	B-Task
.	O
	
Table	O
[	O
reference	O
]	O
illustrates	O
multiple	O
interpretable	O
neurons	O
and	O
some	O
representative	O
word	O
or	O
phrase	O
pairs	O
which	O
can	O
activate	O
these	O
neurons	O
.	O
	
These	O
cases	O
show	O
that	O
our	O
models	O
can	O
capture	O
contextual	O
interactions	O
beyond	O
word	O
level	O
.	O
	
subsubsection	O
:	O
Error	B-Method
Analysis	I-Method
	
Although	O
our	O
models	O
C	O
-	O
LSTMs	B-Method
are	O
more	O
sensitive	O
to	O
the	O
discrepancy	O
of	O
the	O
semantic	O
capacity	O
between	O
two	O
sentences	O
,	O
some	O
semantic	O
mistakes	O
at	O
the	O
phrasal	O
level	O
still	O
exist	O
.	O
	
For	O
example	O
,	O
our	O
models	O
failed	O
to	O
capture	O
the	O
key	O
informative	O
pattern	O
when	O
predicting	O
the	O
entailment	O
sentence	O
pair	O
	
“	O
	
A	O
girl	O
takes	O
off	O
her	O
shoes	O
and	O
eats	O
blue	O
cotton	O
candy	O
/	O
	
The	O
girl	O
is	O
eating	O
while	O
barefoot	O
.	O
	
”	O
	
Besides	O
,	O
despite	O
the	O
large	O
size	O
of	O
the	O
training	O
corpus	O
,	O
it	O
’s	O
still	O
very	O
different	O
to	O
solve	O
some	O
cases	O
,	O
which	O
depend	O
on	O
the	O
combination	O
of	O
the	O
world	O
knowledge	O
and	O
context	O
-	O
sensitive	O
inferences	O
.	O
	
For	O
example	O
,	O
given	O
an	O
entailment	O
pair	O
“	O
a	O
man	O
grabs	O
his	O
crotch	O
during	O
a	O
political	O
demonstration	O
/	O
	
The	O
man	O
is	O
making	O
a	O
crude	O
gesture	O
”	O
,	O
all	O
models	O
predict	O
“	O
neutral	O
”	O
.	O
	
This	O
analysis	O
suggests	O
that	O
some	O
architectural	O
improvements	O
or	O
external	O
world	O
knowledge	O
are	O
necessary	O
to	O
eliminate	O
all	O
errors	O
instead	O
of	O
simply	O
scaling	O
up	O
the	O
basic	B-Method
model	I-Method
.	O
	
subsection	O
:	O
Experiment	O
-	O
II	O
:	O
Matching	B-Task
Question	I-Task
and	O
Answer	O
	
Matching	B-Task
question	I-Task
answering	I-Task
(	O
MQA	B-Task
)	O
is	O
a	O
typical	O
task	O
for	O
semantic	B-Task
matching	I-Task
.	O
	
Given	O
a	O
question	O
,	O
we	O
need	O
select	O
a	O
correct	O
answer	O
from	O
some	O
candidate	O
answers	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
use	O
the	O
dataset	O
collected	O
from	O
Yahoo	O
!	O
	
Answers	O
with	O
the	O
getByCategory	O
function	O
provided	O
in	O
Yahoo	O
!	O
	
Answers	B-Task
API	I-Task
,	O
which	O
produces	O
questions	O
and	O
corresponding	O
best	O
answers	O
.	O
	
We	O
then	O
select	O
the	O
pairs	O
in	O
which	O
the	O
length	O
of	O
questions	O
and	O
answers	O
are	O
both	O
in	O
the	O
interval	O
,	O
thus	O
obtaining	O
question	O
answer	O
pairs	O
to	O
form	O
the	O
positive	O
pairs	O
.	O
	
For	O
negative	O
pairs	O
,	O
we	O
first	O
use	O
each	O
question	O
’s	O
best	O
answer	O
as	O
a	O
query	O
to	O
retrieval	O
top	O
results	O
from	O
the	O
whole	O
answer	O
set	O
with	O
Lucene	O
,	O
where	O
or	O
answers	O
will	O
be	O
selected	O
randomly	O
to	O
construct	O
the	O
negative	O
pairs	O
.	O
	
The	O
whole	O
dataset	O
is	O
divided	O
into	O
training	O
,	O
validation	O
and	O
testing	O
data	O
with	O
proportion	O
.	O
	
Moreover	O
,	O
we	O
give	O
two	O
test	O
settings	O
:	O
selecting	O
the	O
best	O
answer	O
from	O
5	O
and	O
10	O
candidates	O
respectively	O
.	O
	
subsubsection	O
:	O
Results	O
	
Results	O
of	O
MQA	B-Method
are	O
shown	O
in	O
the	O
Table	O
[	O
reference	O
]	O
.	O
	
For	O
our	O
models	O
,	O
due	O
to	O
stacking	O
block	O
more	O
than	O
three	O
layers	O
can	O
not	O
make	O
significant	O
improvements	O
on	O
this	O
task	O
,	O
we	O
just	O
use	O
three	O
stacked	B-Method
C	I-Method
-	I-Method
LSTMs	I-Method
.	O
	
By	O
analyzing	O
the	O
evaluation	O
results	O
of	O
question	B-Task
-	I-Task
answer	I-Task
matching	I-Task
in	O
table	O
[	O
reference	O
]	O
,	O
we	O
can	O
see	O
strong	O
interaction	B-Method
models	I-Method
(	O
attention	O
LSTMs	B-Method
,	O
our	O
C	B-Method
-	I-Method
LSTMs	I-Method
)	O
consistently	O
outperform	O
the	O
weak	B-Method
interaction	I-Method
models	I-Method
(	O
NBOW	B-Method
,	O
parallel	O
LSTMs	B-Method
)	O
with	O
a	O
large	O
margin	O
,	O
which	O
suggests	O
the	O
importance	O
of	O
modelling	O
strong	O
interaction	O
of	O
two	O
sentences	O
.	O
	
Our	O
proposed	O
two	O
C	B-Method
-	I-Method
LSTMs	I-Method
surpass	O
	
the	O
competitor	B-Method
methods	I-Method
and	O
C	B-Method
-	I-Method
LSTMs	I-Method
augmented	O
with	O
multi	O
-	O
directions	O
layers	O
and	O
multiple	O
stacked	O
blocks	O
fully	O
utilize	O
multiple	O
levels	O
of	O
abstraction	O
to	O
directly	O
boost	O
the	O
performance	O
.	O
	
Additionally	O
,	O
LC	B-Method
-	I-Method
LSTMs	I-Method
is	O
superior	O
to	O
TC	B-Method
-	I-Method
LSTMs	I-Method
.	O
	
The	O
reason	O
may	O
be	O
that	O
MQA	B-Method
is	O
a	O
relative	B-Task
simple	I-Task
task	I-Task
,	O
which	O
requires	O
less	O
reasoning	O
abilities	O
,	O
compared	O
with	O
RTE	B-Task
task	O
.	O
	
Moreover	O
,	O
the	O
parameters	O
of	O
LC	B-Method
-	I-Method
LSTMs	I-Method
are	O
less	O
than	O
TC	B-Method
-	I-Method
LSTMs	I-Method
,	O
which	O
ensures	O
the	O
former	O
can	O
avoid	O
suffering	O
from	O
overfitting	O
on	O
a	O
relatively	O
smaller	O
corpus	O
.	O
	
section	O
:	O
Related	O
Work	O
	
Our	O
architecture	O
for	O
sentence	B-Task
pair	I-Task
encoding	I-Task
can	O
be	O
regarded	O
as	O
strong	O
interaction	B-Method
models	I-Method
,	O
which	O
have	O
been	O
explored	O
in	O
previous	O
models	O
.	O
	
An	O
intuitive	O
paradigm	O
is	O
to	O
compute	O
similarities	O
between	O
all	O
the	O
words	O
or	O
phrases	O
of	O
the	O
two	O
sentences	O
.	O
	
socher2011dynamic	O
[	O
socher2011dynamic	O
]	O
firstly	O
used	O
this	O
paradigm	O
for	O
paraphrase	B-Task
detection	I-Task
.	O
	
The	O
representations	O
of	O
words	O
or	O
phrases	O
are	O
learned	O
based	O
on	O
recursive	B-Method
autoencoders	I-Method
.	O
	
wan2015deep	O
[	O
wan2015deep	O
]	O
used	O
LSTM	B-Method
to	O
enhance	O
the	O
positional	O
contextual	O
interactions	O
of	O
the	O
words	O
or	O
phrases	O
between	O
two	O
sentences	O
.	O
	
The	O
input	O
of	O
LSTM	B-Method
for	O
one	O
sentence	O
does	O
not	O
involve	O
another	O
sentence	O
.	O
	
A	O
major	O
limitation	O
of	O
this	O
paradigm	O
is	O
the	O
interaction	O
of	O
two	O
sentence	O
is	O
captured	O
by	O
a	O
pre	O
-	O
defined	O
similarity	B-Metric
measure	I-Metric
.	O
	
Thus	O
,	O
it	O
is	O
not	O
easy	O
to	O
increase	O
the	O
depth	O
of	O
the	O
network	O
.	O
	
Compared	O
with	O
this	O
paradigm	O
,	O
we	O
can	O
stack	O
our	O
C	B-Method
-	I-Method
LSTMs	I-Method
to	O
model	O
multiple	O
-	O
granularity	O
interactions	B-Task
of	I-Task
two	I-Task
sentences	I-Task
.	O
	
rocktaschel2015reasoning	O
[	O
rocktaschel2015reasoning	O
]	O
used	O
two	O
LSTMs	B-Method
equipped	O
with	O
attention	B-Method
mechanism	I-Method
to	O
capture	O
the	O
iteration	O
between	O
two	O
sentences	O
.	O
	
This	O
architecture	O
is	O
asymmetrical	O
for	O
two	O
sentences	O
,	O
where	O
the	O
obtained	O
final	B-Method
representation	I-Method
is	O
sensitive	O
to	O
the	O
two	O
sentences	O
’	O
order	O
.	O
	
Compared	O
with	O
the	O
attentive	O
LSTM	B-Method
,	O
our	O
proposed	O
C	B-Method
-	I-Method
LSTMs	I-Method
are	O
symmetrical	O
and	O
model	O
the	O
local	O
contextual	O
interaction	O
of	O
two	O
sequences	O
directly	O
.	O
	
section	O
:	O
Conclusion	O
and	O
Future	O
Work	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
an	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
deep	I-Method
architecture	I-Method
to	O
capture	O
the	O
strong	O
interaction	O
information	O
of	O
sentence	O
pair	O
.	O
	
Experiments	O
on	O
two	O
large	B-Task
scale	I-Task
text	I-Task
matching	I-Task
tasks	I-Task
demonstrate	O
the	O
efficacy	O
of	O
our	O
proposed	O
model	O
and	O
its	O
superiority	O
to	O
competitor	O
models	O
.	O
	
Besides	O
,	O
our	O
visualization	B-Task
analysis	I-Task
revealed	O
that	O
multiple	O
interpretable	O
neurons	O
in	O
our	O
proposed	O
models	O
can	O
capture	O
the	O
contextual	O
interactions	O
of	O
the	O
words	O
or	O
phrases	O
.	O
	
In	O
future	O
work	O
,	O
we	O
would	O
like	O
to	O
incorporate	O
some	O
gating	B-Method
strategies	I-Method
into	O
the	O
depth	O
dimension	O
of	O
our	O
proposed	O
models	O
,	O
like	O
highway	B-Method
or	I-Method
residual	I-Method
network	I-Method
,	O
to	O
enhance	O
the	O
interactions	O
between	O
depth	O
and	O
other	O
dimensions	O
thus	O
training	O
more	O
deep	B-Method
and	I-Method
powerful	I-Method
neural	I-Method
networks	I-Method
.	O
	
.	O
/	O
nlp	O
,	O
..	O
	
/	O
ours	O
.	O
	
document	O
:	O
Mastering	O
Chess	B-Task
and	O
Shogi	B-Task
by	O
Self	O
-	O
Play	O
with	O
a	O
General	B-Method
Reinforcement	I-Method
Learning	I-Method
Algorithm	I-Method
	
The	O
game	B-Task
of	I-Task
chess	I-Task
is	O
the	O
most	O
widely	O
-	O
studied	O
domain	O
in	O
the	O
history	O
of	O
artificial	B-Task
intelligence	I-Task
.	O
	
The	O
strongest	O
programs	O
are	O
based	O
on	O
a	O
combination	O
of	O
sophisticated	O
search	B-Method
techniques	I-Method
,	O
domain	B-Method
-	I-Method
specific	I-Method
adaptations	I-Method
,	O
and	O
handcrafted	B-Method
evaluation	I-Method
functions	I-Method
that	O
have	O
been	O
refined	O
by	O
human	O
experts	O
over	O
several	O
decades	O
.	O
	
In	O
contrast	O
,	O
the	O
AlphaGo	B-Method
Zero	I-Method
program	I-Method
recently	O
achieved	O
superhuman	O
performance	O
in	O
the	O
game	O
of	O
Go	B-Task
,	O
by	O
tabula	B-Method
rasa	I-Method
reinforcement	I-Method
learning	I-Method
from	O
games	O
of	O
self	B-Task
-	I-Task
play	I-Task
.	O
	
In	O
this	O
paper	O
,	O
we	O
generalise	O
this	O
approach	O
into	O
a	O
single	O
AlphaZero	B-Method
algorithm	O
that	O
can	O
achieve	O
,	O
tabula	B-Method
rasa	I-Method
,	O
superhuman	O
performance	O
in	O
many	O
challenging	O
domains	O
.	O
	
Starting	O
from	O
random	O
play	O
,	O
and	O
given	O
no	O
domain	O
knowledge	O
except	O
the	O
game	O
rules	O
,	O
AlphaZero	B-Method
achieved	O
within	O
24	O
hours	O
a	O
superhuman	O
level	O
of	O
play	O
in	O
the	O
games	O
of	O
chess	B-Task
and	O
shogi	B-Task
(	O
Japanese	B-Task
chess	I-Task
)	O
as	O
well	O
as	O
Go	B-Task
,	O
and	O
convincingly	O
defeated	O
a	O
world	B-Method
-	I-Method
champion	I-Method
program	I-Method
in	O
each	O
case	O
.	O
	
The	O
study	O
of	O
computer	B-Task
chess	I-Task
is	O
as	O
old	O
as	O
computer	B-Task
science	I-Task
itself	O
.	O
	
Babbage	O
,	O
Turing	O
,	O
Shannon	B-Method
,	O
and	O
von	B-Method
Neumann	I-Method
devised	O
hardware	B-Method
,	O
algorithms	O
and	O
theory	O
to	O
analyse	O
and	O
play	O
the	O
game	B-Task
of	I-Task
chess	I-Task
.	O
	
Chess	B-Task
subsequently	O
became	O
the	O
grand	O
challenge	O
task	O
for	O
a	O
generation	O
of	O
artificial	B-Task
intelligence	I-Task
researchers	I-Task
,	O
culminating	O
in	O
high	O
-	O
performance	O
computer	B-Task
chess	I-Task
programs	I-Task
that	O
perform	O
at	O
superhuman	O
level	O
.	O
	
However	O
,	O
these	O
systems	O
are	O
highly	O
tuned	O
to	O
their	O
domain	O
,	O
and	O
can	O
not	O
be	O
generalised	O
to	O
other	O
problems	O
without	O
significant	O
human	O
effort	O
.	O
	
A	O
long	O
-	O
standing	O
ambition	O
of	O
artificial	B-Task
intelligence	I-Task
has	O
been	O
to	O
create	O
programs	O
that	O
can	O
instead	O
learn	O
for	O
themselves	O
from	O
first	O
principles	O
.	O
	
Recently	O
,	O
the	O
AlphaGo	B-Method
Zero	I-Method
algorithm	O
achieved	O
superhuman	O
performance	O
in	O
the	O
game	O
of	O
Go	B-Task
,	O
by	O
representing	O
Go	B-Task
knowledge	O
using	O
deep	B-Method
convolutional	I-Method
neural	I-Method
networks	I-Method
,	O
trained	O
solely	O
by	O
reinforcement	B-Method
learning	I-Method
from	O
games	B-Method
of	I-Method
self	I-Method
-	I-Method
play	I-Method
.	O
	
In	O
this	O
paper	O
,	O
we	O
apply	O
a	O
similar	O
but	O
fully	O
generic	O
algorithm	O
,	O
which	O
we	O
call	O
AlphaZero	B-Method
,	O
to	O
the	O
games	O
of	O
chess	B-Task
and	O
shogi	B-Task
as	O
well	O
as	O
Go	B-Task
,	O
without	O
any	O
additional	O
domain	O
knowledge	O
except	O
the	O
rules	O
of	O
the	O
game	O
,	O
demonstrating	O
that	O
a	O
general	B-Method
-	I-Method
purpose	I-Method
reinforcement	I-Method
learning	I-Method
algorithm	I-Method
can	O
achieve	O
,	O
tabula	B-Method
rasa	I-Method
,	O
superhuman	O
performance	O
across	O
many	O
challenging	O
domains	O
.	O
	
A	O
landmark	O
for	O
artificial	B-Task
intelligence	I-Task
was	O
achieved	O
in	O
1997	O
when	O
Deep	O
Blue	O
defeated	O
the	O
human	O
world	O
champion	O
.	O
	
Computer	B-Task
chess	I-Task
programs	I-Task
continued	O
to	O
progress	O
steadily	O
beyond	O
human	O
level	O
in	O
the	O
following	O
two	O
decades	O
.	O
	
These	O
programs	O
evaluate	O
positions	O
using	O
features	O
handcrafted	O
by	O
human	O
grandmasters	O
and	O
carefully	O
tuned	O
weights	O
,	O
combined	O
with	O
a	O
high	O
-	O
performance	O
alpha	B-Method
-	I-Method
beta	I-Method
search	I-Method
that	O
expands	O
a	O
vast	O
search	O
tree	O
using	O
a	O
large	O
number	O
of	O
clever	O
heuristics	O
and	O
domain	O
-	O
specific	O
adaptations	O
.	O
	
In	O
the	O
Methods	O
we	O
describe	O
these	O
augmentations	O
,	O
focusing	O
on	O
the	O
2016	O
Top	O
Chess	O
Engine	O
Championship	O
(	O
TCEC	O
)	O
world	O
-	O
champion	O
Stockfish	O
;	O
other	O
strong	O
chess	B-Method
programs	I-Method
,	O
including	O
Deep	B-Method
Blue	I-Method
,	O
use	O
very	O
similar	O
architectures	O
.	O
	
Shogi	B-Task
is	O
a	O
significantly	O
harder	O
game	O
,	O
in	O
terms	O
of	O
computational	B-Metric
complexity	I-Metric
,	O
than	O
chess	B-Task
:	O
it	O
is	O
played	O
on	O
a	O
larger	O
board	O
,	O
and	O
any	O
captured	O
opponent	O
piece	O
changes	O
sides	O
and	O
may	O
subsequently	O
be	O
dropped	O
anywhere	O
on	O
the	O
board	O
.	O
	
The	O
strongest	O
shogi	B-Task
programs	O
,	O
such	O
as	O
Computer	O
Shogi	B-Task
Association	O
(	O
CSA	B-Method
)	O
world	O
-	O
champion	O
Elmo	O
,	O
have	O
only	O
recently	O
defeated	O
human	O
champions	O
.	O
	
These	O
programs	O
use	O
a	O
similar	O
algorithm	O
to	O
computer	B-Method
chess	I-Method
programs	I-Method
,	O
again	O
based	O
on	O
a	O
highly	O
optimised	O
alpha	B-Method
-	I-Method
beta	I-Method
search	I-Method
engine	I-Method
with	O
many	O
domain	O
-	O
specific	O
adaptations	O
.	O
	
Go	B-Task
is	O
well	O
suited	O
to	O
the	O
neural	B-Method
network	I-Method
architecture	I-Method
used	O
in	O
AlphaGo	B-Method
because	O
the	O
rules	O
of	O
the	O
game	O
are	O
translationally	O
invariant	O
(	O
matching	O
the	O
weight	O
sharing	O
structure	O
of	O
convolutional	B-Method
networks	I-Method
)	O
,	O
are	O
defined	O
in	O
terms	O
of	O
liberties	O
corresponding	O
to	O
the	O
adjacencies	O
between	O
points	O
on	O
the	O
board	O
(	O
matching	O
the	O
local	B-Method
structure	I-Method
of	I-Method
convolutional	I-Method
networks	I-Method
)	O
,	O
and	O
are	O
rotationally	O
and	O
reflectionally	O
symmetric	O
(	O
allowing	O
for	O
data	B-Method
augmentation	I-Method
and	O
ensembling	B-Method
)	O
.	O
	
Furthermore	O
,	O
the	O
action	O
space	O
is	O
simple	O
(	O
a	O
stone	O
may	O
be	O
placed	O
at	O
each	O
possible	O
location	O
)	O
,	O
and	O
the	O
game	O
outcomes	O
are	O
restricted	O
to	O
binary	O
wins	O
or	O
losses	O
,	O
both	O
of	O
which	O
may	O
help	O
neural	B-Method
network	I-Method
training	I-Method
.	O
	
Chess	B-Task
and	O
shogi	B-Task
are	O
,	O
arguably	O
,	O
less	O
innately	O
suited	O
to	O
AlphaGo	B-Method
’s	I-Method
neural	I-Method
network	I-Method
architectures	I-Method
.	O
	
The	O
rules	O
are	O
position	O
-	O
dependent	O
(	O
e.g.	O
pawns	O
may	O
move	O
two	O
steps	O
forward	O
from	O
the	O
second	O
rank	O
and	O
promote	O
on	O
the	O
eighth	O
rank	O
)	O
and	O
asymmetric	O
(	O
e.g.	O
pawns	O
only	O
move	O
forward	O
,	O
and	O
castling	O
is	O
different	O
on	O
kingside	O
and	O
queenside	O
)	O
.	O
	
The	O
rules	O
include	O
long	O
-	O
range	O
interactions	O
(	O
e.g.	O
the	O
queen	O
may	O
traverse	O
the	O
board	O
in	O
one	O
move	O
,	O
or	O
checkmate	O
the	O
king	O
from	O
the	O
far	O
side	O
of	O
the	O
board	O
)	O
.	O
	
The	O
action	O
space	O
for	O
chess	O
includes	O
all	O
legal	O
destinations	O
for	O
all	O
of	O
the	O
players	O
	
’	O
pieces	O
on	O
the	O
board	O
;	O
shogi	B-Task
also	O
allows	O
captured	O
pieces	O
to	O
be	O
placed	O
back	O
on	O
the	O
board	O
.	O
	
Both	O
chess	O
and	O
shogi	B-Task
may	O
result	O
in	O
draws	O
in	O
addition	O
to	O
wins	O
and	O
losses	O
;	O
indeed	O
it	O
is	O
believed	O
that	O
the	O
optimal	O
solution	O
to	O
chess	B-Task
is	O
a	O
draw	O
.	O
	
The	O
AlphaZero	B-Method
algorithm	O
is	O
a	O
more	O
generic	O
version	O
of	O
the	O
AlphaGo	B-Method
Zero	I-Method
algorithm	O
that	O
was	O
first	O
introduced	O
in	O
the	O
context	O
of	O
Go	B-Task
.	O
	
It	O
replaces	O
the	O
handcrafted	O
knowledge	O
and	O
domain	B-Method
-	I-Method
specific	I-Method
augmentations	I-Method
used	O
in	O
traditional	O
game	B-Method
-	I-Method
playing	I-Method
programs	I-Method
with	O
deep	B-Method
neural	I-Method
networks	I-Method
and	O
a	O
tabula	B-Method
rasa	I-Method
reinforcement	I-Method
learning	I-Method
algorithm	I-Method
.	O
	
Instead	O
of	O
a	O
handcrafted	O
evaluation	O
function	O
and	O
move	B-Method
ordering	I-Method
heuristics	I-Method
,	O
AlphaZero	B-Method
utilises	O
a	O
deep	B-Method
neural	I-Method
network	I-Method
with	O
parameters	O
.	O
	
This	O
neural	B-Method
network	I-Method
takes	O
the	O
board	O
position	O
as	O
an	O
input	O
and	O
outputs	O
a	O
vector	O
of	O
move	O
probabilities	O
with	O
components	O
for	O
each	O
action	O
,	O
and	O
a	O
scalar	O
value	O
estimating	O
the	O
expected	O
outcome	O
from	O
position	O
,	O
.	O
	
AlphaZero	B-Method
learns	O
these	O
move	O
probabilities	O
and	O
value	B-Method
estimates	I-Method
entirely	O
from	O
self	O
-	O
play	O
;	O
these	O
are	O
then	O
used	O
to	O
guide	O
its	O
search	O
.	O
	
Instead	O
of	O
an	O
alpha	B-Method
-	I-Method
beta	I-Method
search	I-Method
with	O
domain	O
-	O
specific	O
enhancements	O
,	O
AlphaZero	B-Method
uses	O
a	O
general	B-Method
-	I-Method
purpose	I-Method
Monte	I-Method
-	I-Method
Carlo	I-Method
tree	I-Method
search	I-Method
(	O
MCTS	B-Method
)	I-Method
algorithm	I-Method
.	O
	
Each	O
search	O
consists	O
of	O
a	O
series	O
of	O
simulated	B-Method
games	I-Method
of	O
self	O
-	O
play	O
that	O
traverse	O
a	O
tree	O
from	O
root	O
to	O
leaf	O
.	O
	
Each	O
simulation	O
proceeds	O
by	O
selecting	O
in	O
each	O
state	O
a	O
move	O
with	O
low	O
visit	O
count	O
,	O
high	O
move	O
probability	O
and	O
high	O
value	O
(	O
averaged	O
over	O
the	O
leaf	O
states	O
of	O
simulations	O
that	O
selected	O
from	O
)	O
according	O
to	O
the	O
current	O
neural	B-Method
network	I-Method
.	O
	
The	O
search	O
returns	O
a	O
vector	O
representing	O
a	O
probability	O
distribution	O
over	O
moves	O
,	O
either	O
proportionally	O
or	O
greedily	O
with	O
respect	O
to	O
the	O
visit	O
counts	O
at	O
the	O
root	O
state	O
.	O
	
The	O
parameters	O
of	O
the	O
deep	B-Method
neural	I-Method
network	I-Method
in	O
AlphaZero	B-Method
are	O
trained	O
by	O
self	B-Method
-	I-Method
play	I-Method
reinforcement	I-Method
learning	I-Method
,	O
starting	O
from	O
randomly	O
initialised	O
parameters	O
.	O
	
Games	O
are	O
played	O
by	O
selecting	O
moves	O
for	O
both	O
players	O
by	O
MCTS	B-Method
,	O
.	O
	
At	O
the	O
end	O
of	O
the	O
game	O
,	O
the	O
terminal	O
position	O
is	O
scored	O
according	O
to	O
the	O
rules	O
of	O
the	O
game	O
to	O
compute	O
the	O
game	O
outcome	O
:	O
for	O
a	O
loss	O
,	O
for	O
a	O
draw	O
,	O
and	O
for	O
a	O
win	O
.	O
	
The	O
neural	B-Method
network	I-Method
parameters	I-Method
are	O
updated	O
so	O
as	O
to	O
minimise	O
the	O
error	O
between	O
the	O
predicted	O
outcome	O
and	O
the	O
game	O
outcome	O
,	O
and	O
to	O
maximise	O
the	O
similarity	O
of	O
the	O
policy	O
vector	O
to	O
the	O
search	O
probabilities	O
.	O
	
Specifically	O
,	O
the	O
parameters	O
are	O
adjusted	O
by	O
gradient	B-Method
descent	I-Method
on	O
a	O
loss	B-Method
function	I-Method
that	O
sums	O
over	O
mean	B-Metric
-	I-Metric
squared	I-Metric
error	I-Metric
and	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
losses	I-Metric
respectively	O
,	O
where	O
is	O
a	O
parameter	O
controlling	O
the	O
level	O
of	O
weight	B-Method
regularisation	I-Method
.	O
	
The	O
updated	O
parameters	O
are	O
used	O
in	O
subsequent	O
games	B-Task
of	I-Task
self	I-Task
-	I-Task
play	I-Task
.	O
	
The	O
AlphaZero	B-Method
algorithm	O
described	O
in	O
this	O
paper	O
differs	O
from	O
the	O
original	O
AlphaGo	B-Method
Zero	I-Method
algorithm	O
in	O
several	O
respects	O
.	O
	
AlphaGo	B-Method
Zero	I-Method
estimates	O
and	O
optimises	O
the	O
probability	O
of	O
winning	O
,	O
assuming	O
binary	O
win	O
/	O
loss	O
outcomes	O
.	O
	
AlphaZero	B-Method
instead	O
estimates	O
and	O
optimises	O
the	O
expected	O
outcome	O
,	O
taking	O
account	O
of	O
draws	O
or	O
potentially	O
other	O
outcomes	O
.	O
	
The	O
rules	O
of	O
Go	B-Task
are	O
invariant	O
to	O
rotation	O
and	O
reflection	O
.	O
	
This	O
fact	O
was	O
exploited	O
in	O
AlphaGo	B-Method
and	O
AlphaGo	B-Method
Zero	I-Method
in	O
two	O
ways	O
.	O
	
First	O
,	O
training	O
data	O
was	O
augmented	O
by	O
generating	O
8	O
symmetries	O
for	O
each	O
position	O
.	O
	
Second	O
,	O
during	O
MCTS	B-Method
,	O
board	O
positions	O
were	O
transformed	O
using	O
a	O
randomly	O
selected	O
rotation	O
or	O
reflection	O
before	O
being	O
evaluated	O
by	O
the	O
neural	B-Method
network	I-Method
,	O
so	O
that	O
the	O
Monte	B-Method
-	I-Method
Carlo	I-Method
evaluation	I-Method
is	O
averaged	O
over	O
different	O
biases	O
.	O
	
The	O
rules	O
of	O
chess	B-Task
and	O
shogi	B-Task
are	O
asymmetric	O
,	O
and	O
in	O
general	O
symmetries	O
can	O
not	O
be	O
assumed	O
.	O
	
AlphaZero	B-Method
does	O
not	O
augment	O
the	O
training	O
data	O
and	O
does	O
not	O
transform	O
the	O
board	O
position	O
during	O
MCTS	B-Method
.	O
	
In	O
AlphaGo	B-Method
Zero	I-Method
,	O
self	O
-	O
play	O
games	O
were	O
generated	O
by	O
the	O
best	O
player	O
from	O
all	O
previous	O
iterations	O
.	O
	
After	O
each	O
iteration	O
of	O
training	O
,	O
the	O
performance	O
of	O
the	O
new	O
player	O
was	O
measured	O
against	O
the	O
best	O
player	O
;	O
if	O
it	O
won	O
by	O
a	O
margin	O
of	O
then	O
it	O
replaced	O
the	O
best	O
player	O
and	O
self	O
-	O
play	O
games	O
were	O
subsequently	O
generated	O
by	O
this	O
new	O
player	O
.	O
	
In	O
contrast	O
,	O
AlphaZero	B-Method
simply	O
maintains	O
a	O
single	O
neural	B-Method
network	I-Method
that	O
is	O
updated	O
continually	O
,	O
rather	O
than	O
waiting	O
for	O
an	O
iteration	O
to	O
complete	O
.	O
	
Self	B-Task
-	I-Task
play	I-Task
games	I-Task
are	O
generated	O
by	O
using	O
the	O
latest	O
parameters	O
for	O
this	O
neural	B-Method
network	I-Method
,	O
omitting	O
the	O
evaluation	O
step	O
and	O
the	O
selection	O
of	O
best	O
player	O
.	O
	
AlphaGo	B-Method
Zero	I-Method
tuned	O
the	O
hyper	O
-	O
parameter	O
of	O
its	O
search	O
by	O
Bayesian	B-Method
optimisation	I-Method
.	O
	
In	O
AlphaZero	B-Method
we	O
reuse	O
the	O
same	O
hyper	O
-	O
parameters	O
for	O
all	O
games	O
without	O
game	O
-	O
specific	O
tuning	O
.	O
	
The	O
sole	O
exception	O
is	O
the	O
noise	O
that	O
is	O
added	O
to	O
the	O
prior	O
policy	O
to	O
ensure	O
exploration	B-Task
;	O
this	O
is	O
scaled	O
in	O
proportion	O
to	O
the	O
typical	O
number	O
of	O
legal	O
moves	O
for	O
that	O
game	O
type	O
.	O
	
Like	O
AlphaGo	B-Method
Zero	I-Method
,	O
the	O
board	O
state	O
is	O
encoded	O
by	O
spatial	O
planes	O
based	O
only	O
on	O
the	O
basic	O
rules	O
for	O
each	O
game	O
.	O
	
The	O
actions	O
are	O
encoded	O
by	O
either	O
spatial	O
planes	O
or	O
a	O
flat	O
vector	O
,	O
again	O
based	O
only	O
on	O
the	O
basic	O
rules	O
for	O
each	O
game	O
(	O
see	O
Methods	O
)	O
.	O
	
We	O
applied	O
the	O
AlphaZero	B-Method
algorithm	O
to	O
chess	B-Task
,	O
shogi	B-Task
,	O
and	O
also	O
Go	B-Task
.	O
	
Unless	O
otherwise	O
specified	O
,	O
the	O
same	O
algorithm	O
settings	O
,	O
network	O
architecture	O
,	O
and	O
hyper	O
-	O
parameters	O
were	O
used	O
for	O
all	O
three	O
games	O
.	O
	
We	O
trained	O
a	O
separate	O
instance	O
of	O
AlphaZero	B-Method
for	O
each	O
game	O
.	O
	
Training	O
proceeded	O
for	O
700	O
,	O
000	O
steps	O
(	O
mini	O
-	O
batches	O
of	O
size	O
4	O
,	O
096	O
)	O
starting	O
from	O
randomly	O
initialised	O
parameters	O
,	O
using	O
5	O
,	O
000	O
first	O
-	O
generation	O
TPUs	B-Method
to	O
generate	O
self	B-Task
-	I-Task
play	I-Task
games	I-Task
and	O
64	O
second	O
-	O
generation	O
TPUs	B-Method
to	O
train	O
the	O
neural	B-Method
networks	I-Method
.	O
	
Further	O
details	O
of	O
the	O
training	O
procedure	O
are	O
provided	O
in	O
the	O
Methods	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
the	O
performance	O
of	O
AlphaZero	B-Method
during	O
self	B-Method
-	I-Method
play	I-Method
reinforcement	I-Method
learning	I-Method
,	O
as	O
a	O
function	O
of	O
training	O
steps	O
,	O
on	O
an	O
Elo	O
scale	O
.	O
	
In	O
chess	B-Task
,	O
AlphaZero	B-Method
outperformed	O
Stockfish	B-Method
after	O
just	O
4	O
hours	O
(	O
300k	O
steps	O
)	O
;	O
in	O
shogi	B-Task
,	O
AlphaZero	B-Method
outperformed	O
Elmo	B-Method
after	O
less	O
than	O
2	O
hours	O
(	O
110k	O
steps	O
)	O
;	O
and	O
in	O
Go	B-Task
,	O
AlphaZero	B-Method
outperformed	O
AlphaGo	B-Method
Lee	I-Method
after	O
8	O
hours	O
(	O
165k	O
steps	O
)	O
.	O
	
We	O
evaluated	O
the	O
fully	O
trained	O
instances	O
of	O
AlphaZero	B-Method
against	O
Stockfish	B-Method
,	O
Elmo	B-Method
and	O
the	O
previous	O
version	O
of	O
AlphaGo	B-Method
Zero	I-Method
(	O
trained	O
for	O
3	O
days	O
)	O
in	O
chess	B-Task
,	O
shogi	B-Task
and	O
Go	B-Task
respectively	O
,	O
playing	O
100	O
game	O
matches	O
at	O
tournament	O
time	O
controls	O
of	O
one	O
minute	O
per	O
move	O
.	O
	
AlphaZero	B-Method
and	O
the	O
previous	O
AlphaGo	B-Method
Zero	I-Method
used	O
a	O
single	O
machine	O
with	O
4	O
TPUs	O
.	O
	
Stockfish	B-Method
and	O
Elmo	B-Method
played	O
at	O
their	O
strongest	O
skill	O
level	O
using	O
64	O
threads	O
and	O
a	O
hash	O
size	O
of	O
1	O
GB	O
.	O
	
AlphaZero	B-Method
convincingly	O
defeated	O
all	O
opponents	O
,	O
losing	O
zero	O
games	O
to	O
Stockfish	O
and	O
eight	O
games	O
to	O
Elmo	O
(	O
see	O
Supplementary	O
Material	O
for	O
several	O
example	O
games	O
)	O
,	O
as	O
well	O
as	O
defeating	O
the	O
previous	O
version	O
of	O
AlphaGo	B-Method
Zero	I-Method
(	O
see	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
We	O
also	O
analysed	O
the	O
relative	O
performance	O
of	O
AlphaZero	B-Method
’s	O
MCTS	O
search	O
compared	O
to	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
alpha	B-Method
-	I-Method
beta	I-Method
search	I-Method
engines	I-Method
used	O
by	O
Stockfish	B-Method
and	O
Elmo	B-Method
.	O
	
AlphaZero	B-Method
searches	O
just	O
80	O
thousand	O
positions	O
per	O
second	O
in	O
chess	B-Task
and	O
40	O
thousand	O
in	O
shogi	B-Task
,	O
compared	O
to	O
70	O
million	O
for	O
Stockfish	B-Method
and	O
35	O
million	O
for	O
Elmo	B-Method
.	O
	
AlphaZero	B-Method
compensates	O
for	O
the	O
lower	O
number	O
of	O
evaluations	O
by	O
using	O
its	O
deep	B-Method
neural	I-Method
network	I-Method
to	O
focus	O
much	O
more	O
selectively	O
on	O
the	O
most	O
promising	O
variations	O
–	O
arguably	O
a	O
more	O
“	O
human	O
-	O
like	O
”	O
approach	O
to	O
search	B-Task
,	O
as	O
originally	O
proposed	O
by	O
Shannon	B-Method
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
the	O
scalability	O
of	O
each	O
player	O
with	O
respect	O
to	O
thinking	O
time	O
,	O
measured	O
on	O
an	O
Elo	O
scale	O
,	O
relative	O
to	O
Stockfish	B-Method
or	O
Elmo	B-Method
with	O
40ms	O
thinking	O
time	O
.	O
	
AlphaZero	B-Method
’s	O
MCTS	O
scaled	O
more	O
effectively	O
with	O
thinking	O
time	O
than	O
either	O
Stockfish	B-Method
or	O
Elmo	B-Method
,	O
calling	O
into	O
question	O
the	O
widely	O
held	O
belief	O
that	O
alpha	B-Method
-	I-Method
beta	I-Method
search	I-Method
is	O
inherently	O
superior	O
in	O
these	O
domains	O
.	O
	
Finally	O
,	O
we	O
analysed	O
the	O
chess	O
knowledge	O
discovered	O
by	O
AlphaZero	B-Method
.	O
	
Table	O
[	O
reference	O
]	O
analyses	O
the	O
most	O
common	O
human	O
openings	O
(	O
those	O
played	O
more	O
than	O
100	O
,	O
000	O
times	O
in	O
an	O
online	O
database	O
of	O
human	O
chess	O
games	O
)	O
.	O
	
Each	O
of	O
these	O
openings	O
is	O
independently	O
discovered	O
and	O
played	O
frequently	O
by	O
AlphaZero	B-Method
during	O
self	B-Task
-	I-Task
play	I-Task
training	I-Task
.	O
	
When	O
starting	O
from	O
each	O
human	O
opening	O
,	O
AlphaZero	B-Method
convincingly	O
defeated	O
Stockfish	B-Method
,	O
suggesting	O
that	O
it	O
has	O
indeed	O
mastered	O
a	O
wide	O
spectrum	O
of	O
chess	B-Task
play	I-Task
.	O
	
The	O
game	B-Task
of	I-Task
chess	I-Task
represented	O
the	O
pinnacle	O
of	O
AI	B-Task
research	I-Task
over	O
several	O
decades	O
.	O
	
State	O
-	O
of	O
-	O
the	O
-	O
art	O
programs	O
are	O
based	O
on	O
powerful	O
engines	O
that	O
search	O
many	O
millions	O
of	O
positions	O
,	O
leveraging	O
handcrafted	O
domain	O
expertise	O
and	O
sophisticated	O
domain	B-Method
adaptations	I-Method
.	O
	
AlphaZero	B-Method
is	O
a	O
generic	O
reinforcement	B-Method
learning	I-Method
algorithm	I-Method
–	O
originally	O
devised	O
for	O
the	O
game	O
of	O
Go	B-Task
–	O
that	O
achieved	O
superior	O
results	O
within	O
a	O
few	O
hours	O
,	O
searching	O
a	O
thousand	O
times	O
fewer	O
positions	O
,	O
given	O
no	O
domain	O
knowledge	O
except	O
the	O
rules	O
of	O
chess	O
.	O
	
Furthermore	O
,	O
the	O
same	O
algorithm	O
was	O
applied	O
without	O
modification	O
to	O
the	O
more	O
challenging	O
game	O
of	O
shogi	B-Task
,	O
again	O
outperforming	O
the	O
state	O
of	O
the	O
art	O
within	O
a	O
few	O
hours	O
.	O
	
bibliography	O
:	O
References	O
	
section	O
:	O
Methods	O
	
subsection	O
:	O
Anatomy	O
of	O
a	O
Computer	B-Task
Chess	I-Task
Program	I-Task
	
In	O
this	O
section	O
we	O
describe	O
the	O
components	O
of	O
a	O
typical	O
computer	B-Method
chess	I-Method
program	I-Method
,	O
focusing	O
specifically	O
on	O
Stockfish	B-Method
,	O
an	O
open	O
source	O
program	O
that	O
won	O
the	O
2016	O
TCEC	O
computer	O
chess	O
championship	O
.	O
	
For	O
an	O
overview	O
of	O
standard	O
methods	O
,	O
see	O
.	O
	
Each	O
position	O
is	O
described	O
by	O
a	O
sparse	O
vector	O
of	O
handcrafted	O
features	O
,	O
including	O
midgame	O
/	O
endgame	O
-	O
specific	O
material	O
point	O
values	O
,	O
material	O
imbalance	O
tables	O
,	O
piece	O
-	O
square	O
tables	O
,	O
mobility	O
and	O
trapped	O
pieces	O
,	O
pawn	O
structure	O
,	O
king	O
safety	O
,	O
outposts	O
,	O
bishop	O
pair	O
,	O
and	O
other	O
miscellaneous	O
evaluation	O
patterns	O
.	O
	
Each	O
feature	O
is	O
assigned	O
,	O
by	O
a	O
combination	O
of	O
manual	B-Method
and	I-Method
automatic	I-Method
tuning	I-Method
,	O
a	O
corresponding	O
weight	O
and	O
the	O
position	O
is	O
evaluated	O
by	O
a	O
linear	B-Method
combination	I-Method
.	O
	
However	O
,	O
this	O
raw	O
evaluation	O
is	O
only	O
considered	O
accurate	O
for	O
positions	O
that	O
are	O
“	O
quiet	O
”	O
,	O
with	O
no	O
unresolved	O
captures	O
or	O
checks	O
.	O
	
A	O
domain	B-Method
-	I-Method
specialised	I-Method
quiescence	I-Method
search	I-Method
is	O
used	O
to	O
resolve	O
ongoing	O
tactical	O
situations	O
before	O
the	O
evaluation	O
function	O
is	O
applied	O
.	O
	
The	O
final	O
evaluation	O
of	O
a	O
position	O
is	O
computed	O
by	O
a	O
minimax	B-Method
search	I-Method
that	O
evaluates	O
each	O
leaf	O
using	O
a	O
quiescence	B-Method
search	I-Method
.	O
	
Alpha	B-Method
-	I-Method
beta	I-Method
pruning	I-Method
is	O
used	O
to	O
safely	O
cut	O
any	O
branch	O
that	O
is	O
provably	O
dominated	O
by	O
another	O
variation	O
.	O
	
Additional	O
cuts	O
are	O
achieved	O
using	O
aspiration	O
windows	O
and	O
principal	B-Method
variation	I-Method
search	I-Method
.	O
	
Other	O
pruning	B-Method
strategies	I-Method
include	O
null	B-Method
move	I-Method
pruning	I-Method
(	O
which	O
assumes	O
a	O
pass	O
move	O
should	O
be	O
worse	O
than	O
any	O
variation	O
,	O
in	O
positions	O
that	O
are	O
unlikely	O
to	O
be	O
in	O
zugzwang	O
,	O
as	O
determined	O
by	O
simple	O
heuristics	B-Method
)	O
,	O
futility	B-Method
pruning	I-Method
(	O
which	O
assumes	O
knowledge	O
of	O
the	O
maximum	O
possible	O
change	O
in	O
evaluation	O
)	O
,	O
and	O
other	O
domain	B-Method
-	I-Method
dependent	I-Method
pruning	I-Method
rules	I-Method
(	O
which	O
assume	O
knowledge	O
of	O
the	O
value	O
of	O
captured	O
pieces	O
)	O
.	O
	
The	O
search	O
is	O
focused	O
on	O
promising	O
variations	O
both	O
by	O
extending	O
the	O
search	O
depth	O
of	O
promising	O
variations	O
,	O
and	O
by	O
reducing	O
the	O
search	O
depth	O
of	O
unpromising	O
variations	O
based	O
on	O
heuristics	B-Method
like	O
history	O
,	O
static	B-Method
-	I-Method
exchange	I-Method
evaluation	I-Method
(	O
SEE	O
)	O
,	O
and	O
moving	B-Method
piece	I-Method
type	I-Method
.	O
	
Extensions	O
are	O
based	O
on	O
domain	B-Method
-	I-Method
independent	I-Method
rules	I-Method
that	O
identify	O
singular	O
moves	O
with	O
no	O
sensible	O
alternative	O
,	O
and	O
domain	O
-	O
dependent	O
rules	O
,	O
such	O
as	O
extending	O
check	O
moves	O
.	O
	
Reductions	B-Method
,	O
such	O
as	O
late	B-Method
move	I-Method
reductions	I-Method
,	O
are	O
based	O
heavily	O
on	O
domain	O
knowledge	O
.	O
	
The	O
efficiency	O
of	O
alpha	B-Method
-	I-Method
beta	I-Method
search	I-Method
depends	O
critically	O
upon	O
the	O
order	O
in	O
which	O
moves	O
are	O
considered	O
.	O
	
Moves	O
are	O
therefore	O
ordered	O
by	O
iterative	B-Method
deepening	I-Method
(	O
using	O
a	O
shallower	O
search	O
to	O
order	O
moves	O
for	O
a	O
deeper	O
search	O
)	O
.	O
	
In	O
addition	O
,	O
a	O
combination	O
of	O
domain	B-Method
-	I-Method
independent	I-Method
move	I-Method
ordering	I-Method
heuristics	I-Method
,	O
such	O
as	O
killer	B-Method
heuristic	I-Method
,	O
history	B-Method
heuristic	I-Method
,	O
counter	B-Method
-	I-Method
move	I-Method
heuristic	I-Method
,	O
and	O
also	O
domain	O
-	O
dependent	O
knowledge	O
based	O
on	O
captures	O
(	O
SEE	O
)	O
and	O
potential	B-Method
captures	I-Method
(	O
MVV	B-Method
/	I-Method
LVA	I-Method
)	O
.	O
	
A	O
transposition	O
table	O
facilitates	O
the	O
reuse	O
of	O
values	O
and	O
move	O
orders	O
when	O
the	O
same	O
position	O
is	O
reached	O
by	O
multiple	O
paths	O
.	O
	
A	O
carefully	O
tuned	O
opening	O
book	O
is	O
used	O
to	O
select	O
moves	O
at	O
the	O
start	O
of	O
the	O
game	O
.	O
	
An	O
endgame	O
tablebase	O
,	O
precalculated	O
by	O
exhaustive	B-Method
retrograde	I-Method
analysis	I-Method
of	O
endgame	O
positions	O
,	O
provides	O
the	O
optimal	O
move	O
in	O
all	O
positions	O
with	O
six	O
and	O
sometimes	O
seven	O
pieces	O
or	O
less	O
.	O
	
Other	O
strong	O
chess	B-Method
programs	I-Method
,	O
and	O
also	O
earlier	O
programs	O
such	O
as	O
Deep	B-Method
Blue	I-Method
,	O
have	O
used	O
very	O
similar	O
architectures	O
including	O
the	O
majority	O
of	O
the	O
components	O
described	O
above	O
,	O
although	O
important	O
details	O
vary	O
considerably	O
.	O
	
None	O
of	O
the	O
techniques	O
described	O
in	O
this	O
section	O
are	O
used	O
by	O
AlphaZero	B-Method
.	O
	
It	O
is	O
likely	O
that	O
some	O
of	O
these	O
techniques	O
could	O
further	O
improve	O
the	O
performance	O
of	O
AlphaZero	B-Method
;	O
however	O
,	O
we	O
have	O
focused	O
on	O
a	O
pure	O
self	B-Method
-	I-Method
play	I-Method
reinforcement	I-Method
learning	I-Method
approach	I-Method
and	O
leave	O
these	O
extensions	O
for	O
future	O
research	O
.	O
	
subsection	O
:	O
Prior	O
Work	O
on	O
Computer	B-Task
Chess	I-Task
and	O
Shogi	B-Task
	
In	O
this	O
section	O
we	O
discuss	O
some	O
notable	O
prior	O
work	O
on	O
reinforcement	B-Task
learning	I-Task
in	O
computer	B-Task
chess	I-Task
.	O
	
NeuroChess	B-Method
evaluated	O
positions	O
by	O
a	O
neural	B-Method
network	I-Method
that	O
used	O
175	O
handcrafted	O
input	O
features	O
.	O
	
It	O
was	O
trained	O
by	O
temporal	B-Method
-	I-Method
difference	I-Method
learning	I-Method
to	O
predict	O
the	O
final	O
game	O
outcome	O
,	O
and	O
also	O
the	O
expected	O
features	O
after	O
two	O
moves	O
.	O
	
NeuroChess	B-Method
won	O
13	O
%	O
of	O
games	O
against	O
GnuChess	B-Method
using	O
a	O
fixed	O
depth	B-Method
2	I-Method
search	I-Method
.	O
	
Beal	O
and	O
Smith	O
applied	O
temporal	B-Method
-	I-Method
difference	I-Method
learning	I-Method
to	O
estimate	O
the	O
piece	O
values	O
in	O
chess	B-Task
and	O
shogi	B-Task
,	O
starting	O
from	O
random	O
values	O
and	O
learning	O
solely	O
by	O
self	O
-	O
play	O
.	O
	
KnightCap	O
evaluated	O
positions	O
by	O
a	O
neural	B-Method
network	I-Method
that	O
used	O
an	O
attack	O
-	O
table	O
based	O
on	O
knowledge	O
of	O
which	O
squares	O
are	O
attacked	O
or	O
defended	O
by	O
which	O
pieces	O
.	O
	
It	O
was	O
trained	O
by	O
a	O
variant	O
of	O
temporal	B-Method
-	I-Method
difference	I-Method
learning	I-Method
,	O
known	O
as	O
TD	B-Method
(	I-Method
leaf	I-Method
)	I-Method
,	O
that	O
updates	O
the	O
leaf	O
value	O
of	O
the	O
principal	O
variation	O
of	O
an	O
alpha	B-Method
-	I-Method
beta	I-Method
search	I-Method
.	O
	
KnightCap	O
achieved	O
human	O
master	O
level	O
after	O
training	O
against	O
a	O
strong	O
computer	O
opponent	O
with	O
hand	O
-	O
initialised	O
piece	O
-	O
value	O
weights	O
.	O
	
Meep	O
evaluated	O
positions	O
by	O
a	O
linear	B-Method
evaluation	I-Method
function	I-Method
based	O
on	O
handcrafted	O
features	O
.	O
	
It	O
was	O
trained	O
by	O
another	O
variant	O
of	O
temporal	B-Method
-	I-Method
difference	I-Method
learning	I-Method
,	O
known	O
as	O
TreeStrap	B-Method
,	O
that	O
updated	O
all	O
nodes	O
of	O
an	O
alpha	B-Method
-	I-Method
beta	I-Method
search	I-Method
.	O
	
Meep	O
defeated	O
human	O
international	O
master	O
players	O
in	O
13	O
out	O
of	O
15	O
games	O
,	O
after	O
training	O
by	O
self	O
-	O
play	O
with	O
randomly	O
initialised	O
weights	O
.	O
	
Kaneko	O
and	O
Hoki	O
trained	O
the	O
weights	O
of	O
a	O
shogi	B-Task
evaluation	O
function	O
comprising	O
a	O
million	O
features	O
,	O
by	O
learning	O
to	O
select	O
expert	O
human	O
moves	O
during	O
alpha	O
-	O
beta	O
serach	O
.	O
	
They	O
also	O
performed	O
a	O
large	B-Task
-	I-Task
scale	I-Task
optimization	I-Task
based	O
on	O
minimax	B-Method
search	I-Method
regulated	O
by	O
expert	O
game	O
logs	O
;	O
this	O
formed	O
part	O
of	O
the	O
Bonanza	B-Method
engine	I-Method
that	O
won	O
the	O
2013	O
World	O
Computer	O
Shogi	B-Task
Championship	O
.	O
	
Giraffe	O
evaluated	O
positions	O
by	O
a	O
neural	B-Method
network	I-Method
that	O
included	O
mobility	O
maps	O
and	O
attack	B-Method
and	I-Method
defend	I-Method
maps	I-Method
describing	O
the	O
lowest	O
valued	O
attacker	O
and	O
defender	O
of	O
each	O
square	O
.	O
	
It	O
was	O
trained	O
by	O
self	O
-	O
play	O
using	O
TD	B-Method
(	I-Method
leaf	I-Method
)	I-Method
,	O
also	O
reaching	O
a	O
standard	O
of	O
play	O
comparable	O
to	O
international	O
masters	O
.	O
	
DeepChess	B-Method
trained	O
a	O
neural	B-Method
network	I-Method
to	O
performed	O
pair	O
-	O
wise	O
evaluations	O
of	O
positions	O
.	O
	
It	O
was	O
trained	O
by	O
supervised	B-Method
learning	I-Method
from	O
a	O
database	O
of	O
human	O
expert	O
games	O
that	O
was	O
pre	O
-	O
filtered	O
to	O
avoid	O
capture	O
moves	O
and	O
drawn	O
games	O
.	O
	
DeepChess	O
reached	O
a	O
strong	O
grandmaster	O
level	O
of	O
play	O
.	O
	
All	O
of	O
these	O
programs	O
combined	O
their	O
learned	O
evaluation	B-Method
functions	I-Method
with	O
an	O
alpha	B-Method
-	I-Method
beta	I-Method
search	I-Method
enhanced	O
by	O
a	O
variety	O
of	O
extensions	O
.	O
	
An	O
approach	O
based	O
on	O
training	O
dual	B-Method
policy	I-Method
and	I-Method
value	I-Method
networks	I-Method
using	O
AlphaZero	B-Method
-	O
like	O
policy	O
iteration	O
was	O
successfully	O
applied	O
to	O
improve	O
on	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
in	O
Hex	B-Task
.	O
	
subsection	O
:	O
MCTS	B-Method
and	O
Alpha	B-Method
-	I-Method
Beta	I-Method
Search	I-Method
	
For	O
at	O
least	O
four	O
decades	O
the	O
strongest	O
computer	B-Method
chess	I-Method
programs	I-Method
have	O
used	O
alpha	B-Method
-	I-Method
beta	I-Method
search	I-Method
.	O
	
AlphaZero	B-Method
uses	O
a	O
markedly	O
different	O
approach	O
that	O
averages	O
over	O
the	O
position	O
evaluations	O
within	O
a	O
subtree	O
,	O
rather	O
than	O
computing	O
the	O
minimax	O
evaluation	O
of	O
that	O
subtree	O
.	O
	
However	O
,	O
chess	B-Method
programs	I-Method
using	O
traditional	O
MCTS	B-Method
were	O
much	O
weaker	O
than	O
alpha	B-Method
-	I-Method
beta	I-Method
search	I-Method
programs	I-Method
,	O
;	O
while	O
alpha	B-Method
-	I-Method
beta	I-Method
programs	I-Method
based	O
on	O
neural	B-Method
networks	I-Method
have	O
previously	O
been	O
unable	O
to	O
compete	O
with	O
faster	O
,	O
handcrafted	O
evaluation	O
functions	O
.	O
	
AlphaZero	B-Method
evaluates	O
positions	O
using	O
non	B-Method
-	I-Method
linear	I-Method
function	I-Method
approximation	I-Method
based	O
on	O
a	O
deep	B-Method
neural	I-Method
network	I-Method
,	O
rather	O
than	O
the	O
linear	B-Method
function	I-Method
approximation	I-Method
used	O
in	O
typical	O
chess	B-Method
programs	I-Method
.	O
	
This	O
provides	O
a	O
much	O
more	O
powerful	O
representation	O
,	O
but	O
may	O
also	O
introduce	O
spurious	O
approximation	O
errors	O
.	O
	
MCTS	B-Method
averages	O
over	O
these	O
approximation	O
errors	O
,	O
which	O
therefore	O
tend	O
to	O
cancel	O
out	O
when	O
evaluating	O
a	O
large	O
subtree	O
.	O
	
In	O
contrast	O
,	O
alpha	B-Method
-	I-Method
beta	I-Method
search	I-Method
computes	O
an	O
explicit	O
minimax	B-Method
,	O
which	O
propagates	O
the	O
biggest	O
approximation	O
errors	O
to	O
the	O
root	O
of	O
the	O
subtree	O
.	O
	
Using	O
MCTS	B-Method
may	O
allow	O
AlphaZero	B-Method
to	O
effectively	O
combine	O
its	O
neural	B-Method
network	I-Method
representations	I-Method
with	O
a	O
powerful	O
,	O
domain	B-Method
-	I-Method
independent	I-Method
search	I-Method
.	O
	
subsection	O
:	O
Domain	O
Knowledge	O
	
The	O
input	O
features	O
describing	O
the	O
position	O
,	O
and	O
the	O
output	O
features	O
describing	O
the	O
move	O
,	O
are	O
structured	O
as	O
a	O
set	O
of	O
planes	O
;	O
i.e.	O
the	O
neural	B-Method
network	I-Method
architecture	I-Method
is	O
matched	O
to	O
the	O
grid	O
-	O
structure	O
of	O
the	O
board	O
.	O
	
AlphaZero	B-Method
is	O
provided	O
with	O
perfect	O
knowledge	O
of	O
the	O
game	O
rules	O
.	O
	
These	O
are	O
used	O
during	O
MCTS	B-Method
,	O
to	O
simulate	O
the	O
positions	O
resulting	O
from	O
a	O
sequence	O
of	O
moves	O
,	O
to	O
determine	O
game	O
termination	O
,	O
and	O
to	O
score	O
any	O
simulations	O
that	O
reach	O
a	O
terminal	O
state	O
.	O
	
Knowledge	O
of	O
the	O
rules	O
is	O
also	O
used	O
to	O
encode	O
the	O
input	O
planes	O
(	O
i.e.	O
castling	O
,	O
repetition	O
,	O
no	O
-	O
progress	O
)	O
and	O
output	O
planes	O
(	O
how	O
pieces	O
move	O
,	O
promotions	O
,	O
and	O
piece	O
drops	O
in	O
shogi	B-Task
)	O
.	O
	
The	O
typical	O
number	O
of	O
legal	O
moves	O
is	O
used	O
to	O
scale	O
the	O
exploration	O
noise	O
(	O
see	O
below	O
)	O
.	O
	
Chess	B-Task
and	O
shogi	B-Task
games	O
exceeding	O
a	O
maximum	O
number	O
of	O
steps	O
(	O
determined	O
by	O
typical	O
game	O
length	O
)	O
were	O
terminated	O
and	O
assigned	O
a	O
drawn	O
outcome	O
;	O
Go	B-Task
games	O
were	O
terminated	O
and	O
scored	O
with	O
Tromp	B-Method
-	I-Method
Taylor	I-Method
rules	I-Method
,	O
similarly	O
to	O
previous	O
work	O
.	O
	
AlphaZero	B-Method
did	O
not	O
use	O
any	O
form	O
of	O
domain	O
knowledge	O
beyond	O
the	O
points	O
listed	O
above	O
.	O
	
subsection	O
:	O
Representation	O
	
In	O
this	O
section	O
we	O
describe	O
the	O
representation	O
of	O
the	O
board	O
inputs	O
,	O
and	O
the	O
representation	O
of	O
the	O
action	O
outputs	O
,	O
used	O
by	O
the	O
neural	B-Method
network	I-Method
in	O
AlphaZero	B-Method
.	O
	
Other	O
representations	O
could	O
have	O
been	O
used	O
;	O
in	O
our	O
experiments	O
the	O
training	B-Method
algorithm	I-Method
worked	O
robustly	O
for	O
many	O
reasonable	O
choices	O
.	O
	
The	O
input	O
to	O
the	O
neural	B-Method
network	I-Method
is	O
an	O
image	O
stack	O
that	O
represents	O
state	O
using	O
a	O
concatenation	O
of	O
sets	O
of	O
planes	O
of	O
size	O
.	O
	
Each	O
set	O
of	O
planes	O
represents	O
the	O
board	O
position	O
at	O
a	O
time	O
-	O
step	O
,	O
and	O
is	O
set	O
to	O
zero	O
for	O
time	O
-	O
steps	O
less	O
than	O
1	O
.	O
	
The	O
board	O
is	O
oriented	O
to	O
the	O
perspective	O
of	O
the	O
current	O
player	O
.	O
	
The	O
feature	O
planes	O
are	O
composed	O
of	O
binary	O
feature	O
planes	O
indicating	O
the	O
presence	O
of	O
the	O
player	O
’s	O
pieces	O
,	O
with	O
one	O
plane	O
for	O
each	O
piece	O
type	O
,	O
and	O
a	O
second	O
set	O
of	O
planes	O
indicating	O
the	O
presence	O
of	O
the	O
opponent	O
’s	O
pieces	O
.	O
	
For	O
shogi	B-Task
there	O
are	O
additional	O
planes	O
indicating	O
the	O
number	O
of	O
captured	O
prisoners	O
of	O
each	O
type	O
.	O
	
There	O
are	O
an	O
additional	O
constant	O
-	O
valued	O
input	O
planes	O
denoting	O
the	O
player	O
’s	O
colour	O
,	O
the	O
total	O
move	O
count	O
,	O
and	O
the	O
state	O
of	O
special	O
rules	O
:	O
the	O
legality	O
of	O
castling	O
in	O
chess	O
(	O
kingside	O
or	O
queenside	O
)	O
;	O
the	O
repetition	O
count	O
for	O
that	O
position	O
(	O
3	O
repetitions	O
is	O
an	O
automatic	O
draw	O
in	O
chess	O
;	O
4	O
in	O
shogi	B-Task
)	O
;	O
and	O
the	O
number	O
of	O
moves	O
without	O
progress	O
in	O
chess	O
(	O
50	O
moves	O
without	O
progress	O
is	O
an	O
automatic	O
draw	O
)	O
.	O
	
Input	O
features	O
are	O
summarised	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
A	O
move	O
in	O
chess	B-Task
may	O
be	O
described	O
in	O
two	O
parts	O
:	O
selecting	O
the	O
piece	O
to	O
move	O
,	O
and	O
then	O
selecting	O
among	O
the	O
legal	O
moves	O
for	O
that	O
piece	O
.	O
	
We	O
represent	O
the	O
policy	O
by	O
a	O
stack	B-Method
of	I-Method
planes	I-Method
encoding	O
a	O
probability	O
distribution	O
over	O
4	O
,	O
672	O
possible	O
moves	O
.	O
	
Each	O
of	O
the	O
positions	O
identifies	O
the	O
square	O
from	O
which	O
to	O
“	O
pick	O
up	O
”	O
a	O
piece	O
.	O
	
The	O
first	O
56	O
planes	O
encode	O
possible	O
	
‘	O
	
queen	O
moves	O
’	O
for	O
any	O
piece	O
:	O
	
a	O
number	O
of	O
squares	O
in	O
which	O
the	O
piece	O
will	O
be	O
moved	O
,	O
along	O
one	O
of	O
eight	O
relative	O
compass	O
directions	O
.	O
	
The	O
next	O
8	O
planes	O
encode	O
possible	O
knight	O
moves	O
for	O
that	O
piece	O
.	O
	
The	O
final	O
9	O
planes	O
encode	O
possible	O
underpromotions	O
for	O
pawn	O
moves	O
or	O
captures	O
in	O
two	O
possible	O
diagonals	O
,	O
to	O
knight	O
,	O
bishop	O
or	O
rook	O
respectively	O
.	O
	
Other	O
pawn	O
moves	O
or	O
captures	O
from	O
the	O
seventh	O
rank	O
are	O
promoted	O
to	O
a	O
queen	O
.	O
	
The	O
policy	O
in	O
shogi	B-Task
is	O
represented	O
by	O
a	O
stack	B-Method
of	I-Method
planes	I-Method
similarly	O
encoding	O
a	O
probability	O
distribution	O
over	O
11	O
,	O
259	O
possible	O
moves	O
.	O
	
The	O
first	O
64	O
planes	O
encode	O
‘	O
queen	O
moves	O
’	O
and	O
the	O
next	O
2	O
moves	O
encode	O
knight	O
moves	O
.	O
	
An	O
additional	O
planes	O
encode	O
promoting	O
queen	O
moves	O
and	O
promoting	O
knight	O
moves	O
respectively	O
.	O
	
The	O
last	O
7	O
planes	O
encode	O
a	O
captured	O
piece	O
dropped	O
back	O
into	O
the	O
board	O
at	O
that	O
location	O
.	O
	
The	O
policy	O
in	O
Go	B-Task
is	O
represented	O
identically	O
to	O
AlphaGo	B-Method
Zero	I-Method
,	O
using	O
a	O
flat	O
distribution	O
over	O
moves	O
representing	O
possible	O
stone	O
placements	O
and	O
the	O
pass	O
move	O
.	O
	
We	O
also	O
tried	O
using	O
a	O
flat	O
distribution	O
over	O
moves	O
for	O
chess	B-Task
and	O
shogi	B-Task
;	O
the	O
final	O
result	O
was	O
almost	O
identical	O
although	O
training	O
was	O
slightly	O
slower	O
.	O
	
The	O
action	B-Method
representations	I-Method
are	O
summarised	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Illegal	O
moves	O
are	O
masked	O
out	O
by	O
setting	O
their	O
probabilities	O
to	O
zero	O
,	O
and	O
re	O
-	O
normalising	O
the	O
probabilities	O
for	O
remaining	O
moves	O
.	O
	
subsection	O
:	O
Configuration	O
	
During	O
training	O
,	O
each	O
MCTS	B-Method
used	O
800	O
simulations	O
.	O
	
The	O
number	O
of	O
games	O
,	O
positions	O
,	O
and	O
thinking	O
time	O
varied	O
per	O
game	O
due	O
largely	O
to	O
different	O
board	O
sizes	O
and	O
game	O
lengths	O
,	O
and	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
The	O
learning	B-Metric
rate	I-Metric
was	O
set	O
to	O
0.2	O
for	O
each	O
game	O
,	O
and	O
was	O
dropped	O
three	O
times	O
(	O
to	O
0.02	O
,	O
0.002	O
and	O
0.0002	O
respectively	O
)	O
during	O
the	O
course	O
of	O
training	O
.	O
	
Moves	O
are	O
selected	O
in	O
proportion	O
to	O
the	O
root	O
visit	O
count	O
.	O
	
Dirichlet	O
noise	O
was	O
added	O
to	O
the	O
prior	O
probabilities	O
in	O
the	O
root	O
node	O
;	O
this	O
was	O
scaled	O
in	O
inverse	O
proportion	O
to	O
the	O
approximate	O
number	O
of	O
legal	O
moves	O
in	O
a	O
typical	O
position	O
,	O
to	O
a	O
value	O
of	O
for	O
chess	B-Task
,	O
shogi	B-Task
and	O
Go	B-Task
respectively	O
.	O
	
Unless	O
otherwise	O
specified	O
,	O
the	O
training	B-Method
and	I-Method
search	I-Method
algorithm	I-Method
and	O
parameters	O
are	O
identical	O
to	O
AlphaGo	B-Method
Zero	I-Method
.	O
	
During	O
evaluation	B-Task
,	O
AlphaZero	B-Method
selects	O
moves	O
greedily	O
with	O
respect	O
to	O
the	O
root	O
visit	O
count	O
.	O
	
Each	O
MCTS	B-Method
was	O
executed	O
on	O
a	O
single	O
machine	O
with	O
4	O
TPUs	O
.	O
	
subsection	O
:	O
Evaluation	O
	
To	O
evaluate	O
performance	O
in	O
chess	B-Task
,	O
we	O
used	O
Stockfish	B-Method
version	I-Method
8	O
(	O
official	O
Linux	O
release	O
)	O
as	O
a	O
baseline	O
program	O
,	O
using	O
64	O
CPU	O
threads	O
and	O
a	O
hash	O
size	O
of	O
1	O
GB	O
.	O
	
To	O
evaluate	O
performance	O
in	O
shogi	B-Task
,	O
we	O
used	O
Elmo	B-Method
version	I-Method
WCSC27	I-Method
in	O
combination	O
with	O
YaneuraOu	O
2017	O
Early	O
KPPT	B-Method
4.73	O
64AVX2	O
with	O
64	O
CPU	O
threads	O
and	O
a	O
hash	O
size	O
of	O
1	O
GB	O
with	O
the	O
usi	O
option	O
of	O
EnteringKingRule	O
set	O
to	O
NoEnteringKing	O
.	O
	
We	O
evaluated	O
the	O
relative	O
strength	O
of	O
AlphaZero	B-Method
(	O
Figure	O
[	O
reference	O
]	O
)	O
by	O
measuring	O
the	O
Elo	B-Metric
rating	I-Metric
of	O
each	O
player	O
.	O
	
We	O
estimate	O
the	O
probability	O
that	O
player	O
will	O
defeat	O
player	O
by	O
a	O
logistic	B-Method
function	I-Method
,	O
and	O
estimate	O
the	O
ratings	O
by	O
Bayesian	B-Method
logistic	I-Method
regression	I-Method
,	O
computed	O
by	O
the	O
BayesElo	B-Method
program	I-Method
using	O
the	O
standard	O
constant	O
.	O
	
Elo	B-Metric
ratings	I-Metric
were	O
computed	O
from	O
the	O
results	O
of	O
a	O
1	O
second	O
per	O
move	O
tournament	O
between	O
iterations	O
of	O
AlphaZero	B-Method
during	O
training	O
,	O
and	O
also	O
a	O
baseline	O
player	O
:	O
either	O
Stockfish	B-Method
,	O
Elmo	B-Method
or	O
AlphaGo	B-Method
Lee	I-Method
respectively	O
.	O
	
The	O
Elo	B-Metric
rating	I-Metric
of	O
the	O
baseline	O
players	O
was	O
anchored	O
to	O
publicly	O
available	O
values	O
.	O
	
We	O
also	O
measured	O
the	O
head	O
-	O
to	O
-	O
head	O
performance	O
of	O
AlphaZero	B-Method
against	O
each	O
baseline	O
player	O
.	O
	
Settings	O
were	O
chosen	O
to	O
correspond	O
with	O
computer	O
chess	O
tournament	O
conditions	O
:	O
each	O
player	O
was	O
allowed	O
1	O
minute	O
per	O
move	O
,	O
resignation	O
was	O
enabled	O
for	O
all	O
players	O
(	O
-	O
900	O
centipawns	O
for	O
10	O
consecutive	O
moves	O
for	O
Stockfish	O
and	O
Elmo	O
,	O
5	O
%	O
winrate	O
for	O
AlphaZero	B-Method
)	O
.	O
	
Pondering	O
was	O
disabled	O
for	O
all	O
players	O
.	O
	
subsection	O
:	O
Example	O
games	O
	
In	O
this	O
section	O
we	O
include	O
10	O
example	O
games	O
played	O
by	O
AlphaZero	B-Method
against	O
Stockfish	O
during	O
the	O
100	O
game	O
match	O
using	O
1	O
minute	O
per	O
move	O
.	O
	
document	O
:	O
Large	B-Task
Pose	I-Task
3D	I-Task
Face	I-Task
Reconstruction	I-Task
from	O
a	O
Single	O
Image	O
via	O
Direct	B-Method
Volumetric	I-Method
CNN	I-Method
Regression	I-Method
	
3D	B-Task
face	I-Task
reconstruction	I-Task
is	O
a	O
fundamental	O
Computer	B-Task
Vision	I-Task
problem	I-Task
of	O
extraordinary	O
difficulty	O
.	O
	
Current	O
systems	O
often	O
assume	O
the	O
availability	O
of	O
multiple	O
facial	O
images	O
(	O
sometimes	O
from	O
the	O
same	O
subject	O
)	O
as	O
input	O
,	O
and	O
must	O
address	O
a	O
number	O
of	O
methodological	O
challenges	O
such	O
as	O
establishing	O
dense	O
correspondences	O
across	O
large	O
facial	O
poses	O
,	O
expressions	O
,	O
and	O
non	O
-	O
uniform	O
illumination	O
.	O
	
In	O
general	O
these	O
methods	O
require	O
complex	O
and	O
inefficient	O
pipelines	O
for	O
model	B-Task
building	I-Task
and	I-Task
fitting	I-Task
.	O
	
In	O
this	O
work	O
,	O
we	O
propose	O
to	O
address	O
many	O
of	O
these	O
limitations	O
by	O
training	O
a	O
Convolutional	B-Method
Neural	I-Method
Network	I-Method
(	I-Method
CNN	I-Method
)	O
on	O
an	O
appropriate	O
dataset	O
consisting	O
of	O
2D	O
images	O
and	O
3D	O
facial	O
models	O
or	O
scans	O
.	O
	
Our	O
CNN	B-Method
works	O
with	O
just	O
a	O
single	O
2D	O
facial	O
image	O
,	O
does	O
not	O
require	O
accurate	O
alignment	O
nor	O
establishes	O
dense	O
correspondence	O
between	O
images	O
,	O
works	O
for	O
arbitrary	O
facial	O
poses	O
and	O
expressions	O
,	O
and	O
can	O
be	O
used	O
to	O
reconstruct	O
the	O
whole	O
3D	O
facial	O
geometry	O
(	O
including	O
the	O
non	O
-	O
visible	O
parts	O
of	O
the	O
face	O
)	O
bypassing	O
the	O
construction	O
(	O
during	O
training	B-Task
)	O
and	O
fitting	B-Task
(	O
during	O
testing	O
)	O
of	O
a	O
3D	B-Method
Morphable	I-Method
Model	I-Method
.	O
	
We	O
achieve	O
this	O
via	O
a	O
simple	O
CNN	B-Method
architecture	I-Method
that	O
performs	O
direct	B-Method
regression	I-Method
of	O
a	O
volumetric	B-Method
representation	I-Method
of	I-Method
the	I-Method
3D	I-Method
facial	I-Method
geometry	I-Method
from	O
a	O
single	O
2D	O
image	O
.	O
	
We	O
also	O
demonstrate	O
how	O
the	O
related	O
task	O
of	O
facial	B-Task
landmark	I-Task
localization	I-Task
can	O
be	O
incorporated	O
into	O
the	O
proposed	O
framework	O
and	O
help	O
improve	O
reconstruction	B-Metric
quality	I-Metric
,	O
especially	O
for	O
the	O
cases	O
of	O
large	O
poses	O
and	O
facial	O
expressions	O
.	O
	
Code	O
and	O
models	O
will	O
be	O
made	O
available	O
at	O
http:	O
//	O
aaronsplace.co.uk	O
[	O
enumerate	O
]	O
leftmargin=*	O
,	O
itemsep=	O
-	O
1	O
mm	O
[	O
itemize	O
]	O
leftmargin=*	O
,	O
itemsep=	O
-	O
1	O
mm	O
	
section	O
:	O
Introduction	O
	
3D	B-Task
face	I-Task
reconstruction	I-Task
is	O
the	O
problem	O
of	O
recovering	O
the	O
3D	B-Task
facial	I-Task
geometry	I-Task
from	O
2D	O
images	O
.	O
	
Despite	O
many	O
years	O
of	O
research	O
,	O
it	O
is	O
still	O
an	O
open	O
problem	O
in	O
Vision	B-Task
and	I-Task
Graphics	I-Task
research	I-Task
.	O
	
Depending	O
on	O
the	O
setting	O
and	O
the	O
assumptions	O
made	O
,	O
there	O
are	O
many	O
variations	O
of	O
it	O
as	O
well	O
as	O
a	O
multitude	O
of	O
approaches	O
to	O
solve	O
it	O
.	O
	
This	O
work	O
is	O
on	O
3D	B-Task
face	I-Task
reconstruction	I-Task
using	O
only	O
a	O
single	O
image	O
.	O
	
Under	O
this	O
setting	O
,	O
the	O
problem	O
is	O
considered	O
far	O
from	O
being	O
solved	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
to	O
approach	O
it	O
,	O
for	O
the	O
first	O
time	O
to	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
by	O
directly	O
learning	O
a	O
mapping	O
from	O
pixels	O
to	O
3D	O
coordinates	O
using	O
a	O
Convolutional	B-Method
Neural	I-Method
Network	I-Method
(	O
CNN	B-Method
)	O
.	O
	
Besides	O
its	O
simplicity	O
,	O
our	O
approach	O
works	O
with	O
totally	O
unconstrained	O
images	O
downloaded	O
from	O
the	O
web	O
,	O
including	O
facial	O
images	O
of	O
arbitrary	O
poses	O
,	O
facial	O
expressions	O
and	O
occlusions	O
,	O
as	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Motivation	O
.	O
	
No	O
matter	O
what	O
the	O
underlying	O
assumptions	O
are	O
,	O
what	O
the	O
input	O
(	O
s	O
)	O
and	O
output	O
(	O
s	O
)	O
to	O
the	O
algorithm	O
are	O
,	O
3D	B-Task
face	I-Task
reconstruction	I-Task
requires	O
in	O
general	O
complex	O
pipelines	O
and	O
solving	O
non	B-Task
-	I-Task
convex	I-Task
difficult	I-Task
optimization	I-Task
problems	I-Task
for	O
both	O
model	B-Task
building	I-Task
(	O
during	O
training	B-Task
)	O
and	O
model	B-Task
fitting	I-Task
(	O
during	O
testing	O
)	O
.	O
	
In	O
the	O
following	O
paragraph	O
,	O
we	O
provide	O
examples	O
from	O
5	O
predominant	O
approaches	O
:	O
	
In	O
the	O
3D	B-Method
Morphable	I-Method
Model	I-Method
(	O
3DMM	B-Method
)	I-Method
,	O
the	O
most	O
popular	O
approach	O
for	O
estimating	O
the	O
full	B-Task
3D	I-Task
facial	I-Task
structure	I-Task
from	O
a	O
single	O
image	O
(	O
among	O
others	O
)	O
,	O
training	O
includes	O
an	O
iterative	B-Method
flow	I-Method
procedure	I-Method
for	O
dense	B-Task
image	I-Task
correspondence	I-Task
which	O
is	O
prone	O
to	O
failure	O
.	O
	
Additionally	O
,	O
testing	O
requires	O
a	O
careful	O
initialisation	O
for	O
solving	O
a	O
difficult	O
highly	B-Task
non	I-Task
-	I-Task
convex	I-Task
optimization	I-Task
problem	I-Task
,	O
which	O
is	O
slow	O
.	O
	
The	O
work	O
of	O
,	O
a	O
popular	O
approach	O
for	O
2.5D	B-Task
reconstruction	I-Task
from	O
a	O
single	O
image	O
,	O
formulates	O
and	O
solves	O
a	O
carefully	O
initialised	O
(	O
for	O
frontal	O
images	O
only	O
)	O
non	B-Task
-	I-Task
convex	I-Task
optimization	I-Task
problem	I-Task
for	O
recovering	O
the	O
lighting	O
,	O
depth	O
,	O
and	O
albedo	O
in	O
an	O
alternating	O
manner	O
where	O
each	O
of	O
the	O
sub	O
-	O
problems	O
is	O
a	O
difficult	O
optimization	B-Task
problem	I-Task
per	O
se	O
.	O
	
In	O
,	O
a	O
quite	O
popular	O
recent	O
approach	O
for	O
creating	O
a	O
neutral	B-Task
subject	I-Task
-	I-Task
specific	I-Task
2.5D	I-Task
model	I-Task
from	O
a	O
near	O
frontal	O
image	O
,	O
an	O
iterative	B-Method
procedure	I-Method
is	O
proposed	O
which	O
entails	O
localising	O
facial	O
landmarks	O
,	O
face	B-Task
frontalization	I-Task
,	O
solving	O
a	O
photometric	B-Task
stereo	I-Task
problem	I-Task
,	O
local	B-Method
surface	I-Method
normal	I-Method
estimation	I-Method
,	O
and	O
finally	O
shape	B-Method
integration	I-Method
.	O
	
In	O
,	O
a	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
pipeline	O
for	O
reconstructing	O
a	O
highly	O
detailed	O
2.5D	O
facial	O
shape	O
for	O
each	O
video	O
frame	O
,	O
an	O
average	O
shape	O
and	O
an	O
illumination	O
subspace	O
for	O
the	O
specific	O
person	O
is	O
firstly	O
computed	O
(	O
offline	O
)	O
,	O
while	O
testing	O
is	O
an	O
iterative	B-Method
process	I-Method
requiring	O
a	O
sophisticated	O
pose	B-Method
estimation	I-Method
algorithm	I-Method
,	O
3D	B-Method
flow	I-Method
computation	I-Method
between	O
the	O
model	O
and	O
the	O
video	O
frame	O
,	O
and	O
finally	O
shape	B-Task
refinement	I-Task
by	O
solving	O
a	O
shape	B-Task
-	I-Task
from	I-Task
-	I-Task
shading	I-Task
optimization	I-Task
problem	I-Task
.	O
	
More	O
recently	O
,	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
method	O
of	O
that	O
produces	O
the	O
average	O
(	O
neutral	O
)	O
	
3D	B-Task
face	I-Task
from	O
a	O
collection	O
of	O
personal	O
photos	O
,	O
firstly	O
performs	O
landmark	B-Task
detection	I-Task
,	O
then	O
fits	O
a	O
3DMM	B-Method
using	O
a	O
sparse	O
set	O
of	O
points	O
,	O
then	O
solves	O
an	O
optimization	B-Task
problem	I-Task
similar	O
to	O
the	O
one	O
in	O
,	O
then	O
performs	O
surface	B-Method
normal	I-Method
estimation	I-Method
as	O
in	O
and	O
finally	O
performs	O
surface	B-Task
reconstruction	I-Task
by	O
solving	O
another	O
energy	B-Task
minimisation	I-Task
problem	I-Task
.	O
	
Simplifying	O
the	O
technical	O
challenges	O
involved	O
in	O
the	O
aforementioned	O
works	O
is	O
the	O
main	O
motivation	O
of	O
this	O
paper	O
.	O
	
subsection	O
:	O
Main	O
contributions	O
	
We	O
describe	O
a	O
very	O
simple	O
approach	O
which	O
bypasses	O
many	O
of	O
the	O
difficulties	O
encountered	O
in	O
3D	B-Task
face	I-Task
reconstruction	I-Task
by	O
using	O
a	O
novel	O
volumetric	B-Method
representation	I-Method
of	I-Method
the	I-Method
3D	I-Method
facial	I-Method
geometry	I-Method
,	O
and	O
an	O
appropriate	O
CNN	B-Method
architecture	I-Method
that	O
is	O
trained	O
to	O
regress	O
directly	O
from	O
a	O
2D	O
facial	O
image	O
to	O
the	O
corresponding	O
3D	O
volume	O
.	O
	
An	O
overview	O
of	O
our	O
method	O
is	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
In	O
summary	O
,	O
our	O
contributions	O
are	O
:	O
Given	O
a	O
dataset	O
consisting	O
of	O
2D	O
images	O
and	O
3D	O
face	O
scans	O
,	O
we	O
investigate	O
whether	O
a	O
CNN	B-Method
can	O
learn	O
directly	O
,	O
in	O
an	O
end	O
-	O
to	O
-	O
end	O
fashion	O
,	O
the	O
mapping	O
from	O
image	O
pixels	O
to	O
the	O
full	O
3D	O
facial	O
structure	O
geometry	O
(	O
including	O
the	O
non	O
-	O
visible	O
facial	O
parts	O
)	O
.	O
	
Indeed	O
,	O
we	O
show	O
that	O
the	O
answer	O
to	O
this	O
question	O
is	O
positive	O
.	O
	
We	O
demonstrate	O
that	O
our	O
CNN	B-Method
works	O
with	O
just	O
a	O
single	O
2D	O
facial	O
image	O
,	O
does	O
not	O
require	O
accurate	O
alignment	O
nor	O
establishes	O
dense	O
correspondence	O
between	O
images	O
,	O
works	O
for	O
arbitrary	O
facial	O
poses	O
and	O
expressions	O
,	O
and	O
can	O
be	O
used	O
to	O
reconstruct	O
the	O
whole	O
3D	O
facial	O
geometry	O
bypassing	O
the	O
construction	O
(	O
during	O
training	B-Task
)	O
and	O
fitting	B-Task
(	O
during	O
testing	O
)	O
of	O
a	O
3DMM	B-Method
.	O
	
We	O
achieve	O
this	O
via	O
a	O
simple	O
CNN	B-Method
architecture	I-Method
that	O
performs	O
direct	B-Method
regression	I-Method
of	O
a	O
volumetric	B-Method
representation	I-Method
of	I-Method
the	I-Method
3D	I-Method
facial	I-Method
geometry	I-Method
from	O
a	O
single	O
2D	O
image	O
.	O
	
3DMM	B-Method
fitting	I-Method
is	O
not	O
used	O
.	O
	
Our	O
method	O
uses	O
only	O
2D	O
images	O
as	O
input	O
to	O
the	O
proposed	O
CNN	B-Method
architecture	I-Method
.	O
	
We	O
show	O
how	O
the	O
related	O
task	O
of	O
3D	B-Task
facial	I-Task
landmark	I-Task
localisation	I-Task
can	O
be	O
incorporated	O
into	O
the	O
proposed	O
framework	O
and	O
help	O
improve	O
reconstruction	B-Metric
quality	I-Metric
,	O
especially	O
for	O
the	O
cases	O
of	O
large	O
poses	O
and	O
facial	O
expressions	O
.	O
	
We	O
report	O
results	O
for	O
a	O
large	O
number	O
of	O
experiments	O
on	O
both	O
controlled	O
and	O
completely	O
unconstrained	O
images	O
from	O
the	O
web	O
,	O
illustrating	O
that	O
our	O
method	O
outperforms	O
prior	O
work	O
on	O
single	B-Task
image	I-Task
3D	I-Task
face	I-Task
reconstruction	I-Task
by	O
a	O
large	O
margin	O
.	O
	
section	O
:	O
Closely	O
related	O
work	O
	
This	O
section	O
reviews	O
closely	O
related	O
work	O
in	O
3D	B-Task
face	I-Task
reconstruction	I-Task
,	O
depth	B-Task
estimation	I-Task
using	O
CNNs	B-Method
and	O
work	O
on	O
3D	B-Task
representation	I-Task
modelling	I-Task
with	O
CNNs	B-Method
.	O
	
3D	B-Task
face	I-Task
reconstruction	I-Task
.	O
	
A	O
full	O
literature	O
review	O
of	O
3D	B-Task
face	I-Task
reconstruction	I-Task
falls	O
beyond	O
the	O
scope	O
of	O
the	O
paper	O
;	O
we	O
simply	O
note	O
that	O
our	O
method	O
makes	O
minimal	O
assumptions	O
i.e.	O
it	O
requires	O
just	O
a	O
single	O
2D	O
image	O
to	O
reconstruct	O
the	O
full	O
3D	O
facial	O
structure	O
,	O
and	O
works	O
under	O
arbitrary	O
poses	O
and	O
expressions	O
.	O
	
Under	O
the	O
single	O
image	O
setting	O
,	O
the	O
most	O
related	O
works	O
to	O
our	O
method	O
are	O
based	O
on	O
3DMM	B-Method
fitting	I-Method
and	O
the	O
work	O
of	O
which	O
performs	O
joint	B-Task
face	I-Task
reconstruction	I-Task
and	I-Task
alignment	I-Task
,	O
reconstructing	O
however	O
a	O
neutral	O
frontal	O
face	O
.	O
	
The	O
work	O
of	O
describes	O
a	O
multi	B-Method
-	I-Method
feature	I-Method
based	I-Method
approach	I-Method
to	O
3DMM	B-Task
fitting	I-Task
using	O
non	B-Method
-	I-Method
linear	I-Method
least	I-Method
-	I-Method
squares	I-Method
optimization	I-Method
(	O
Levenberg	B-Method
-	I-Method
Marquardt	I-Method
)	O
,	O
which	O
given	O
appropriate	O
initialisation	O
produces	O
results	O
of	O
good	O
accuracy	B-Metric
.	O
	
More	O
recent	O
work	O
has	O
proposed	O
to	O
estimate	O
the	O
update	O
for	O
the	O
3DMM	O
parameters	O
using	O
CNN	B-Method
regression	I-Method
,	O
as	O
opposed	O
to	O
non	B-Method
-	I-Method
linear	I-Method
optimization	I-Method
.	O
	
In	O
,	O
the	O
3DMM	O
parameters	O
are	O
estimated	O
in	O
six	O
steps	O
each	O
of	O
which	O
employs	O
a	O
different	O
CNN	B-Method
.	O
	
Notably	O
,	O
estimates	O
the	O
3DMM	O
parameters	O
on	O
a	O
sparse	O
set	O
of	O
landmarks	O
,	O
i.e.	O
the	O
purpose	O
of	O
is	O
3D	B-Task
face	I-Task
alignment	I-Task
rather	O
than	O
face	B-Task
reconstruction	I-Task
.	O
	
The	O
method	O
of	O
is	O
currently	O
considered	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
in	O
3DMM	B-Task
fitting	I-Task
.	O
	
It	O
is	O
based	O
on	O
a	O
single	O
CNN	B-Method
that	O
is	O
iteratively	O
applied	O
to	O
estimate	O
the	O
model	O
parameters	O
using	O
as	O
input	O
the	O
2D	O
image	O
and	O
a	O
3D	B-Method
-	I-Method
based	I-Method
representation	I-Method
produced	O
at	O
the	O
previous	O
iteration	O
.	O
	
Finally	O
,	O
a	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
cascaded	B-Method
regression	I-Method
landmark	I-Method
-	I-Method
based	I-Method
3DMM	I-Method
fitting	I-Method
method	I-Method
is	O
proposed	O
in	O
.	O
	
Our	O
method	O
is	O
different	O
from	O
the	O
aforementioned	O
methods	O
in	O
the	O
following	O
ways	O
:	O
Our	O
method	O
is	O
direct	O
.	O
	
It	O
does	O
not	O
estimate	O
3DMM	O
parameters	O
and	O
,	O
in	O
fact	O
,	O
it	O
completely	O
bypasses	O
the	O
fitting	O
of	O
a	O
3DMM	O
.	O
	
Instead	O
,	O
our	O
method	O
directly	O
produces	O
a	O
3D	B-Task
volumetric	I-Task
representation	I-Task
of	I-Task
the	I-Task
facial	I-Task
geometry	I-Task
.	O
	
Because	O
of	O
this	O
fundamental	O
difference	O
,	O
our	O
method	O
is	O
also	O
radically	O
different	O
in	O
terms	O
of	O
the	O
CNN	B-Method
architecture	I-Method
used	O
:	O
we	O
used	O
one	O
that	O
is	O
able	O
to	O
make	O
spatial	O
predictions	O
at	O
a	O
voxel	O
level	O
,	O
as	O
opposed	O
to	O
the	O
networks	O
of	O
which	O
holistically	O
predict	O
the	O
3DMM	O
parameters	O
.	O
	
Our	O
method	O
is	O
capable	O
of	O
producing	O
reconstruction	B-Task
results	O
for	O
completely	O
unconstrained	O
facial	O
images	O
from	O
the	O
web	O
covering	O
the	O
full	O
spectrum	O
of	O
facial	O
poses	O
with	O
arbitrary	O
facial	O
expression	O
and	O
occlusions	O
.	O
	
When	O
compared	O
to	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
CNN	B-Method
method	I-Method
for	O
3DMM	B-Task
fitting	I-Task
of	I-Task
,	O
we	O
report	O
large	O
performance	O
improvement	O
.	O
	
Compared	O
to	O
works	O
based	O
on	O
shape	B-Method
from	I-Method
shading	I-Method
,	O
our	O
method	O
can	O
not	O
capture	O
such	O
fine	O
details	O
.	O
	
However	O
,	O
we	O
believe	O
that	O
this	O
is	O
primarily	O
a	O
problem	O
related	O
to	O
the	O
dataset	O
used	O
rather	O
than	O
of	O
the	O
method	O
.	O
	
Given	O
training	O
data	O
like	O
the	O
one	O
produced	O
by	O
,	O
then	O
we	O
believe	O
that	O
our	O
method	O
has	O
the	O
capacity	O
to	O
learn	O
finer	O
facial	O
details	O
,	O
too	O
.	O
	
CNN	B-Method
-	I-Method
based	I-Method
depth	I-Method
estimation	I-Method
.	O
	
Our	O
work	O
has	O
been	O
inspired	O
by	O
the	O
work	O
of	O
who	O
showed	O
that	O
a	O
CNN	B-Method
can	O
be	O
directly	O
trained	O
to	O
regress	O
from	O
pixels	O
to	O
depth	O
values	O
using	O
as	O
input	O
a	O
single	O
image	O
.	O
	
Our	O
work	O
is	O
different	O
from	O
in	O
3	O
important	O
respects	O
:	O
Firstly	O
,	O
we	O
focus	O
on	O
faces	O
(	O
i.e.	O
deformable	O
objects	O
)	O
whereas	O
on	O
general	O
scenes	O
containing	O
mainly	O
rigid	O
objects	O
.	O
	
Secondly	O
,	O
learn	O
a	O
mapping	B-Task
from	O
2D	O
images	O
to	O
2D	B-Task
depth	I-Task
maps	I-Task
,	O
whereas	O
we	O
demonstrate	O
that	O
one	O
can	O
actually	O
learn	O
a	O
mapping	O
from	O
2D	O
to	O
the	O
full	O
3D	O
facial	O
structure	O
including	O
the	O
non	O
-	O
visible	O
part	O
of	O
the	O
face	O
.	O
	
Thirdly	O
,	O
use	O
a	O
multi	B-Method
-	I-Method
scale	I-Method
approach	I-Method
by	O
processing	O
images	O
from	O
low	O
to	O
high	O
resolution	O
.	O
	
In	O
contrast	O
,	O
we	O
process	O
faces	O
at	O
fixed	O
scale	O
(	O
assuming	O
that	O
this	O
is	O
provided	O
by	O
a	O
face	B-Method
detector	I-Method
)	O
,	O
but	O
we	O
build	O
our	O
CNN	B-Method
based	O
on	O
a	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
bottom	B-Method
-	I-Method
up	I-Method
top	I-Method
-	I-Method
down	I-Method
module	I-Method
that	O
allows	O
analysing	O
and	O
combining	O
CNN	O
features	O
at	O
different	O
resolutions	O
for	O
eventually	O
making	O
predictions	B-Task
at	O
voxel	O
level	O
.	O
	
Recent	O
work	O
on	O
3D.	O
	
We	O
are	O
aware	O
of	O
only	O
one	O
work	O
which	O
regresses	O
a	O
volume	O
using	O
a	O
CNN	B-Method
.	O
	
The	O
work	O
of	O
uses	O
an	O
LSTM	B-Method
to	O
regress	O
the	O
3D	O
structure	O
of	O
multiple	O
object	O
classes	O
from	O
one	O
or	O
more	O
images	O
.	O
	
This	O
is	O
different	O
from	O
our	O
work	O
in	O
at	O
least	O
two	O
ways	O
.	O
	
Firstly	O
,	O
we	O
treat	O
our	O
reconstruction	B-Task
as	O
a	O
semantic	B-Task
segmentation	I-Task
problem	I-Task
by	O
regressing	O
a	O
volume	O
which	O
is	O
spatially	O
aligned	O
with	O
the	O
image	O
.	O
	
Secondly	O
,	O
we	O
work	O
from	O
only	O
one	O
image	O
in	O
one	O
single	O
step	O
,	O
regressing	O
a	O
much	O
larger	O
volume	O
of	O
as	O
opposed	O
to	O
the	O
used	O
in	O
.	O
	
The	O
work	O
of	O
decomposes	O
an	O
input	O
3D	O
shape	O
into	O
shape	O
primitives	O
which	O
along	O
with	O
a	O
set	O
of	O
parameters	O
can	O
be	O
used	O
to	O
re	O
-	O
assemble	O
the	O
given	O
shape	O
.	O
	
Given	O
the	O
input	O
shape	O
,	O
the	O
goal	O
of	O
is	O
to	O
regress	O
the	O
shape	O
primitive	O
parameters	O
which	O
is	O
achieved	O
via	O
a	O
CNN	B-Method
.	O
	
The	O
method	O
of	O
extends	O
classical	O
work	O
on	O
heatmap	B-Method
regression	I-Method
by	O
proposing	O
a	O
4D	B-Method
representation	I-Method
for	O
regressing	B-Task
the	I-Task
location	I-Task
of	I-Task
sparse	I-Task
3D	I-Task
landmarks	I-Task
for	O
human	B-Task
pose	I-Task
estimation	I-Task
.	O
	
Different	O
from	O
,	O
we	O
demonstrate	O
that	O
a	O
3D	B-Method
volumetric	I-Method
representation	I-Method
is	O
particular	O
effective	O
for	O
learning	B-Task
dense	I-Task
3D	I-Task
facial	I-Task
geometry	I-Task
.	O
	
In	O
terms	O
of	O
3DMM	B-Task
fitting	I-Task
,	O
very	O
recent	O
work	O
includes	O
which	O
uses	O
a	O
CNN	B-Method
similar	O
to	O
the	O
one	O
of	O
for	O
producing	O
coarse	O
facial	O
geometry	O
but	O
additionally	O
includes	O
a	O
second	O
network	O
for	O
refining	O
the	O
facial	O
geometry	O
and	O
a	O
novel	O
rendering	B-Method
layer	I-Method
for	O
connecting	O
the	O
two	O
networks	O
.	O
	
Another	O
recent	O
work	O
is	O
which	O
uses	O
a	O
very	O
deep	B-Method
CNN	I-Method
for	O
3DMM	B-Task
fitting	I-Task
.	O
	
section	O
:	O
Method	O
	
This	O
section	O
describes	O
our	O
framework	O
including	O
the	O
proposed	O
data	B-Method
representation	I-Method
used	O
.	O
	
subsection	O
:	O
Dataset	O
	
Our	O
aim	O
is	O
to	O
regress	O
the	O
full	O
3D	O
facial	O
structure	O
from	O
a	O
2D	O
image	O
.	O
	
To	O
this	O
end	O
,	O
our	O
method	O
requires	O
an	O
appropriate	O
dataset	O
consisting	O
of	O
2D	O
images	O
and	O
3D	O
facial	O
scans	O
.	O
	
As	O
our	O
target	O
is	O
to	O
apply	O
the	O
method	O
on	O
completely	O
unconstrained	O
images	O
from	O
the	O
web	O
,	O
we	O
chose	O
the	O
dataset	O
of	O
for	O
forming	O
our	O
training	O
and	O
test	O
sets	O
.	O
	
The	O
dataset	O
has	O
been	O
produced	O
by	O
fitting	O
a	O
3DMM	B-Method
built	O
from	O
the	O
combination	O
of	O
the	O
Basel	B-Method
and	I-Method
FaceWarehouse	I-Method
models	I-Method
to	O
the	O
unconstrained	O
images	O
of	O
the	O
300W	O
dataset	O
using	O
the	O
multi	B-Method
-	I-Method
feature	I-Method
fitting	I-Method
approach	I-Method
of	O
,	O
careful	O
initialisation	O
and	O
by	O
constraining	O
the	O
solution	O
using	O
a	O
sparse	O
set	O
of	O
landmarks	O
.	O
	
Face	B-Task
profiling	I-Task
is	O
then	O
used	O
to	O
render	O
each	O
image	O
to	O
10	O
-	O
15	O
different	O
poses	O
resulting	O
in	O
a	O
large	O
scale	O
dataset	O
(	O
more	O
than	O
60	O
,	O
000	O
2D	O
facial	O
images	O
and	O
3D	O
meshes	O
)	O
called	O
300W	O
-	O
LP	O
.	O
	
Note	O
that	O
because	O
each	O
mesh	O
is	O
produced	O
by	O
a	O
3DMM	B-Method
,	O
the	O
vertices	O
of	O
all	O
produced	O
meshes	O
are	O
in	O
dense	O
correspondence	O
;	O
however	O
this	O
is	O
not	O
a	O
prerequisite	O
for	O
our	O
method	O
and	O
unregistered	O
raw	O
facial	O
scans	O
could	O
be	O
also	O
used	O
if	O
available	O
	
(	O
e.g.	O
the	O
BU	O
-	O
4DFE	O
dataset	O
)	O
.	O
	
subsection	O
:	O
Proposed	O
volumetric	B-Method
representation	I-Method
	
Our	O
goal	O
is	O
to	O
predict	O
the	O
coordinates	O
of	O
the	O
3D	O
vertices	O
of	O
each	O
facial	O
scan	O
from	O
the	O
corresponding	O
2D	O
image	O
via	O
CNN	B-Method
regression	I-Method
.	O
	
As	O
a	O
number	O
of	O
works	O
have	O
pointed	O
out	O
(	O
see	O
for	O
example	O
)	O
,	O
direct	B-Method
regression	I-Method
of	O
all	O
3D	O
points	O
concatenated	O
as	O
a	O
vector	O
using	O
the	O
standard	O
L2	B-Method
loss	I-Method
might	O
cause	O
difficulties	O
in	O
learning	B-Task
because	O
a	O
single	O
correct	O
value	O
for	O
each	O
3D	O
vertex	O
must	O
be	O
predicted	O
.	O
	
Additionally	O
,	O
such	O
an	O
approach	O
requires	O
interpolating	O
all	O
scans	O
to	O
a	O
vector	O
of	O
a	O
fixed	O
dimension	O
,	O
a	O
pre	O
-	O
processing	O
step	O
not	O
required	O
by	O
our	O
method	O
.	O
	
Note	O
that	O
similar	O
learning	B-Task
problems	I-Task
are	O
encountered	O
when	O
a	O
CNN	B-Method
is	O
used	O
to	O
regress	O
model	O
parameters	O
like	O
the	O
3DMM	O
parameters	O
rather	O
than	O
the	O
actual	O
vertices	O
.	O
	
In	O
this	O
case	O
,	O
special	O
care	O
must	O
be	O
taken	O
to	O
weight	O
parameters	O
appropriately	O
using	O
the	O
Mahalanobis	B-Method
distance	I-Method
or	O
in	O
general	O
some	O
normalisation	B-Method
method	I-Method
,	O
see	O
for	O
example	O
.	O
	
We	O
compare	O
the	O
performance	O
of	O
our	O
method	O
with	O
that	O
of	O
a	O
similar	O
method	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
To	O
alleviate	O
the	O
aforementioned	O
learning	B-Task
problem	I-Task
,	O
we	O
propose	O
to	O
reformulate	O
the	O
problem	O
of	O
3D	B-Task
face	I-Task
reconstruction	I-Task
as	O
one	O
of	O
2D	B-Task
to	I-Task
3D	I-Task
image	I-Task
segmentation	I-Task
:	O
in	O
particular	O
,	O
we	O
convert	O
each	O
3D	O
facial	O
scan	O
into	O
a	O
3D	O
binary	O
volume	O
by	O
discretizing	O
the	O
3D	O
space	O
into	O
voxels	O
,	O
assigning	O
a	O
value	O
of	O
1	O
to	O
all	O
points	O
enclosed	O
by	O
the	O
3D	O
facial	O
scan	O
,	O
and	O
0	O
otherwise	O
.	O
	
That	O
is	O
to	O
say	O
is	O
the	O
ground	O
truth	O
for	O
voxel	O
and	O
is	O
equal	O
to	O
1	O
,	O
	
if	O
voxel	O
belongs	O
to	O
the	O
3D	B-Method
volumetric	I-Method
representation	I-Method
of	O
the	O
face	O
and	O
0	O
otherwise	O
(	O
i.e.	O
it	O
belongs	O
to	O
the	O
background	O
)	O
.	O
	
The	O
conversion	O
is	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Notice	O
that	O
the	O
process	O
creates	O
a	O
volume	O
fully	O
aligned	O
with	O
the	O
2D	O
image	O
.	O
	
The	O
importance	O
of	O
spatial	B-Task
alignment	I-Task
is	O
analysed	O
in	O
more	O
detail	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
The	O
error	O
caused	O
by	O
discretization	O
for	O
a	O
randomly	O
picked	O
facial	O
scan	O
as	O
a	O
function	O
of	O
the	O
volume	O
size	O
is	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Given	O
that	O
the	O
error	O
of	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
is	O
of	O
the	O
order	O
of	O
a	O
few	O
mms	O
,	O
we	O
conclude	O
that	O
discretization	B-Method
by	O
produces	O
negligible	O
error	O
.	O
	
Given	O
our	O
volumetric	B-Method
facial	I-Method
representation	I-Method
,	O
the	O
problem	O
of	O
regressing	O
the	O
3D	O
coordinates	O
of	O
all	O
vertices	O
of	O
a	O
facial	O
scan	O
is	O
reduced	O
to	O
one	O
of	O
3D	B-Task
binary	I-Task
volume	I-Task
segmentation	I-Task
.	O
	
We	O
approach	O
this	O
problem	O
using	O
recent	O
CNN	B-Method
architectures	I-Method
from	O
semantic	B-Task
image	I-Task
segmentation	I-Task
and	O
their	O
extensions	O
,	O
as	O
described	O
in	O
the	O
next	O
subsection	O
.	O
	
subsection	O
:	O
Volumetric	B-Method
Regression	I-Method
Networks	I-Method
	
In	O
this	O
section	O
,	O
we	O
describe	O
the	O
proposed	O
volumetric	B-Method
regression	I-Method
network	I-Method
,	O
exploring	O
several	O
architectural	O
variations	O
described	O
in	O
detail	O
in	O
the	O
following	O
subsections	O
:	O
Volumetric	B-Method
Regression	I-Method
Network	I-Method
(	O
VRN	B-Method
)	O
.	O
	
We	O
wish	O
to	O
learn	O
a	O
mapping	O
from	O
the	O
2D	O
facial	O
image	O
to	O
its	O
corresponding	O
3D	O
volume	O
.	O
	
Given	O
the	O
training	O
set	O
of	O
2D	O
images	O
and	O
constructed	O
volumes	O
,	O
we	O
learn	O
this	O
mapping	O
using	O
a	O
CNN	B-Method
.	O
	
Our	O
CNN	B-Method
architecture	I-Method
for	O
3D	B-Task
segmentation	I-Task
is	O
based	O
on	O
the	O
“	O
hourglass	B-Method
network	I-Method
”	O
of	O
an	O
extension	O
of	O
the	O
fully	B-Method
convolutional	I-Method
network	I-Method
of	O
using	O
skip	B-Method
connections	I-Method
and	O
residual	B-Method
learning	I-Method
.	O
	
Our	O
volumetric	B-Method
architecture	I-Method
consists	O
of	O
two	O
hourglass	B-Method
modules	I-Method
which	O
are	O
stacked	O
together	O
without	O
intermediate	O
supervision	O
.	O
	
The	O
input	O
is	O
an	O
RGB	O
image	O
and	O
the	O
output	O
is	O
a	O
volume	O
of	O
of	O
real	O
values	O
.	O
	
This	O
architecture	O
is	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
As	O
it	O
can	O
be	O
observed	O
,	O
the	O
network	O
has	O
an	O
encoding	B-Method
/	I-Method
decoding	I-Method
structure	I-Method
where	O
a	O
set	O
of	O
convolutional	B-Method
layers	I-Method
are	O
firstly	O
used	O
to	O
compute	O
a	O
feature	B-Method
representation	I-Method
of	I-Method
fixed	I-Method
dimension	I-Method
.	O
	
This	O
representation	O
is	O
further	O
processed	O
back	O
to	O
the	O
spatial	O
domain	O
,	O
re	O
-	O
establishing	O
spatial	O
correspondence	O
between	O
the	O
input	O
image	O
and	O
the	O
output	O
volume	O
.	O
	
Features	O
are	O
hierarchically	O
combined	O
from	O
different	O
resolutions	O
to	O
make	O
per	B-Task
-	I-Task
pixel	I-Task
predictions	I-Task
.	O
	
The	O
second	O
hourglass	B-Method
is	O
used	O
to	O
refine	O
this	O
output	O
,	O
and	O
has	O
an	O
identical	O
structure	O
to	O
that	O
of	O
the	O
first	O
one	O
.	O
	
[	O
t	O
]	O
1	O
[	O
t	O
]	O
0.98	O
[	O
t	O
]	O
1	O
We	O
train	O
our	O
volumetric	B-Method
regression	I-Method
network	I-Method
using	O
the	O
sigmoid	B-Method
cross	I-Method
entropy	I-Method
loss	I-Method
function	I-Method
:	O
where	O
is	O
the	O
corresponding	O
sigmoid	O
output	O
at	O
voxel	O
of	O
the	O
regressed	O
volume	O
.	O
	
At	O
test	O
time	O
,	O
and	O
given	O
an	O
input	O
2D	O
image	O
,	O
the	O
network	O
regresses	O
a	O
3D	O
volume	O
from	O
which	O
the	O
outer	O
3D	O
facial	O
mesh	O
is	O
recovered	O
.	O
	
Rather	O
than	O
making	O
hard	O
(	O
binary	O
)	O
predictions	O
at	O
pixel	O
level	O
,	O
we	O
found	O
that	O
the	O
soft	O
sigmoid	O
output	O
is	O
more	O
useful	O
for	O
further	O
processing	O
.	O
	
Both	O
representations	O
are	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
where	O
clearly	O
the	O
latter	O
results	O
in	O
smoother	O
results	O
.	O
	
Finally	O
,	O
from	O
the	O
3D	O
volume	O
,	O
a	O
mesh	O
can	O
be	O
formed	O
by	O
generating	O
the	O
iso	O
-	O
surface	O
of	O
the	O
volume	O
.	O
	
If	O
needed	O
,	O
correspondence	O
between	O
this	O
variable	O
length	O
mesh	O
and	O
a	O
fixed	O
mesh	O
can	O
be	O
found	O
using	O
Iterative	B-Method
Closest	I-Method
Point	I-Method
(	I-Method
ICP	I-Method
)	O
.	O
	
VRN	B-Method
-	O
Multitask	O
.	O
	
We	O
also	O
propose	O
a	O
Multitask	O
VRN	B-Method
,	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
consisting	O
of	O
three	O
hourglass	B-Method
modules	I-Method
.	O
	
The	O
first	O
hourglass	O
provides	O
features	O
to	O
a	O
fork	O
of	O
two	O
hourglasses	O
.	O
	
The	O
first	O
of	O
this	O
fork	O
regresses	O
the	O
68	O
iBUG	O
landmarks	O
as	O
2D	B-Method
Gaussians	I-Method
,	O
each	O
on	O
a	O
separate	O
channel	O
.	O
	
The	O
second	O
hourglass	O
of	O
this	O
fork	O
directly	O
regresses	O
the	O
3D	O
structure	O
of	O
the	O
face	O
as	O
a	O
volume	O
,	O
as	O
in	O
the	O
aforementioned	O
unguided	B-Method
volumetric	I-Method
regression	I-Method
method	I-Method
.	O
	
The	O
goal	O
of	O
this	O
multitask	B-Method
network	I-Method
is	O
to	O
learn	O
more	O
reliable	O
features	O
which	O
are	O
better	O
suited	O
to	O
the	O
two	O
tasks	O
.	O
	
VRN	B-Method
-	I-Method
Guided	I-Method
.	O
	
We	O
argue	O
that	O
reconstruction	B-Task
should	O
benefit	O
from	O
firstly	O
performing	O
a	O
simpler	O
face	B-Task
analysis	I-Task
task	I-Task
;	O
in	O
particular	O
we	O
propose	O
an	O
architecture	O
for	O
volumetric	B-Task
regression	I-Task
guided	O
by	O
facial	O
landmarks	O
.	O
	
To	O
this	O
end	O
,	O
we	O
train	O
a	O
stacked	B-Method
hourglass	I-Method
network	I-Method
which	O
accepts	O
guidance	O
from	O
landmarks	O
during	O
training	O
and	O
inference	B-Task
.	O
	
This	O
network	O
has	O
a	O
similar	O
architecture	O
to	O
the	O
unguided	B-Method
volumetric	I-Method
regression	I-Method
method	I-Method
,	O
however	O
the	O
input	O
to	O
this	O
architecture	O
is	O
an	O
RGB	O
image	O
stacked	O
with	O
68	O
channels	O
,	O
each	O
containing	O
a	O
Gaussian	O
(	O
,	O
approximate	O
diameter	O
of	O
6	O
pixels	O
)	O
centred	O
on	O
each	O
of	O
the	O
68	O
landmarks	O
.	O
	
This	O
stacked	B-Method
representation	I-Method
and	O
architecture	O
is	O
demonstrated	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
During	O
training	O
we	O
used	O
the	O
ground	O
truth	O
landmarks	O
while	O
during	O
testing	O
we	O
used	O
a	O
stacked	B-Method
hourglass	I-Method
network	I-Method
trained	O
for	O
facial	B-Task
landmark	I-Task
localisation	I-Task
.	O
	
We	O
call	O
this	O
network	O
VRN	B-Method
-	O
Guided	O
.	O
	
subsection	O
:	O
Training	O
	
Each	O
of	O
our	O
architectures	O
was	O
trained	O
end	O
-	O
to	O
-	O
end	O
using	O
RMSProp	B-Method
with	O
an	O
initial	O
learning	B-Metric
rate	I-Metric
of	O
,	O
which	O
was	O
lowered	O
after	O
40	O
epochs	O
to	O
.	O
	
During	O
training	B-Task
,	O
random	B-Method
augmentation	I-Method
was	O
applied	O
to	O
each	O
input	O
sample	O
(	O
face	O
image	O
)	O
and	O
its	O
corresponding	O
target	O
(	O
3D	O
volume	O
)	O
:	O
we	O
applied	O
in	O
-	O
plane	O
rotation	O
,	O
translation	O
and	O
scale	O
jitter	O
.	O
	
In	O
20	O
%	O
of	O
cases	O
,	O
the	O
input	O
and	O
target	O
were	O
flipped	O
horizontally	O
.	O
	
Finally	O
,	O
the	O
input	O
samples	O
were	O
adjusted	O
with	O
some	O
colour	B-Method
scaling	I-Method
on	O
each	O
RGB	O
channel	O
.	O
	
In	O
the	O
case	O
of	O
the	O
VRN	B-Method
-	I-Method
Guided	I-Method
,	O
the	O
landmark	B-Method
detection	I-Method
module	I-Method
was	O
trained	O
to	O
regress	O
Gaussians	B-Method
with	O
standard	O
deviation	O
of	O
approximately	O
3	O
pixels	O
(	O
)	O
.	O
	
section	O
:	O
Results	O
	
[	O
t	O
]	O
0.43	O
[	O
t	O
]	O
0.43	O
We	O
performed	O
cross	O
-	O
database	O
experiments	O
only	O
,	O
on	O
3	O
different	O
databases	O
,	O
namely	O
AFLW2000	O
-	O
3D	O
,	O
BU	O
-	O
4DFE	O
,	O
and	O
Florence	B-Material
reporting	O
the	O
performance	O
of	O
all	O
the	O
proposed	O
networks	O
(	O
VRN	B-Method
,	O
VRN	B-Method
-	O
Multitask	O
and	O
VRN	B-Method
-	I-Method
Guided	I-Method
)	O
along	O
with	O
the	O
performance	O
of	O
two	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
,	O
namely	O
3DDFA	B-Method
and	O
EOS	B-Method
.	O
	
Both	O
methods	O
perform	O
3DMM	B-Method
fitting	I-Method
(	O
3DDFA	B-Method
uses	O
a	O
CNN	B-Method
)	O
,	O
a	O
process	O
completely	O
bypassed	O
by	O
VRN	B-Method
.	O
	
Our	O
results	O
can	O
be	O
found	O
in	O
Table	O
[	O
reference	O
]	O
and	O
Figs	O
.	O
	
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
.	O
	
Visual	O
results	O
of	O
the	O
proposed	O
VRN	B-Method
-	I-Method
Guided	I-Method
on	O
some	O
very	O
challenging	O
images	O
from	O
AFLW2000	O
-	O
3D	O
can	O
be	O
seen	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Examples	O
of	O
failure	O
cases	O
along	O
with	O
a	O
visual	O
comparison	O
between	O
VRN	B-Method
and	O
VRN	B-Method
-	I-Method
Guided	I-Method
can	O
be	O
found	O
in	O
the	O
supplementary	O
material	O
.	O
	
From	O
these	O
results	O
,	O
we	O
can	O
conclude	O
the	O
following	O
:	O
Volumetric	B-Method
Regression	I-Method
Networks	I-Method
largely	O
outperform	O
3DDFA	B-Method
and	O
EOS	B-Method
on	O
all	O
datasets	O
,	O
verifying	O
that	O
directly	O
regressing	O
the	O
3D	O
facial	O
structure	O
is	O
a	O
much	O
easier	O
problem	O
for	O
CNN	B-Method
learning	I-Method
.	O
	
All	O
VRNs	B-Method
perform	O
well	O
across	O
the	O
whole	O
spectrum	O
of	O
facial	O
poses	O
,	O
expressions	O
and	O
occlusions	O
.	O
	
Also	O
,	O
there	O
are	O
no	O
significant	O
performance	O
discrepancies	O
across	O
different	O
datasets	O
(	O
ALFW2000	O
-	O
3D	O
seems	O
to	O
be	O
slightly	O
more	O
difficult	O
)	O
.	O
	
The	O
best	O
performing	O
VRN	B-Method
is	O
the	O
one	O
guided	O
by	O
detected	O
landmarks	O
(	O
VRN	B-Method
-	I-Method
Guided	I-Method
)	O
,	O
however	O
at	O
the	O
cost	O
of	O
higher	O
computational	B-Metric
complexity	I-Metric
:	O
	
VRN	B-Method
-	I-Method
Guided	I-Method
uses	O
another	O
stacked	B-Method
hourglass	I-Method
network	I-Method
for	O
landmark	B-Task
localization	I-Task
.	O
	
VRN	B-Method
-	O
Multitask	O
does	O
not	O
always	O
perform	O
particularly	O
better	O
than	O
the	O
plain	O
VRN	B-Method
(	O
in	O
fact	O
on	O
BU	O
-	O
4DFE	O
it	O
performs	O
worse	O
)	O
,	O
not	O
justifying	O
the	O
increase	O
of	O
network	B-Metric
complexity	I-Metric
.	O
	
It	O
seems	O
that	O
it	O
might	O
be	O
preferable	O
to	O
train	O
a	O
network	O
to	O
focus	O
on	O
the	O
task	O
in	O
hand	O
.	O
	
Details	O
about	O
our	O
experiments	O
are	O
as	O
follows	O
:	O
Datasets	O
.	O
	
(	O
a	O
)	O
AFLW2000	O
-	O
3D	O
:	O
	
As	O
our	O
target	O
was	O
to	O
test	O
our	O
network	O
on	O
totally	O
unconstrained	O
images	O
,	O
we	O
firstly	O
conducted	O
experiments	O
on	O
the	O
AFLW2000	O
-	O
3D	O
dataset	O
which	O
contains	O
3D	O
facial	O
meshes	O
for	O
the	O
first	O
2000	O
images	O
from	O
AFLW	O
.	O
	
(	O
b	O
)	O
BU	O
-	O
4DFE	O
:	O
We	O
also	O
conducted	O
experiments	O
on	O
rendered	O
images	O
from	O
BU	O
-	O
4DFE	O
.	O
	
We	O
rendered	O
each	O
participant	O
for	O
both	O
Happy	O
and	O
Surprised	O
expressions	O
with	O
three	O
different	O
pitch	O
rotations	O
between	O
and	O
degrees	O
.	O
	
For	O
each	O
pitch	O
,	O
seven	O
roll	O
rotations	O
from	O
to	O
degrees	O
were	O
also	O
rendered	O
.	O
	
Large	O
variations	O
in	O
lighting	O
direction	O
and	O
colour	O
were	O
added	O
randomly	O
to	O
make	O
the	O
images	O
more	O
challenging	O
.	O
	
(	O
c	O
)	O
Florence	B-Material
:	O
	
Finally	O
,	O
we	O
conducted	O
experiments	O
on	O
rendered	O
images	O
from	O
the	O
Florence	B-Material
dataset	O
.	O
	
Facial	O
images	O
were	O
rendered	O
in	O
a	O
similar	O
fashion	O
to	O
the	O
ones	O
of	O
BU	B-Method
-	I-Method
4DFE	I-Method
but	O
for	O
slightly	O
different	O
parameters	O
:	O
Each	O
face	O
is	O
rendered	O
in	O
20	O
difference	O
poses	O
,	O
using	O
a	O
pitch	O
of	O
-	O
15	O
,	O
20	O
or	O
25	O
degrees	O
and	O
each	O
of	O
the	O
five	O
evenly	O
spaced	O
rotations	O
between	O
-	O
80	O
and	O
80	O
.	O
	
Error	B-Metric
metric	I-Metric
.	O
	
To	O
measure	O
the	O
accuracy	B-Metric
of	O
reconstruction	B-Task
for	O
each	O
face	O
,	O
we	O
used	O
the	O
Normalised	B-Metric
Mean	I-Metric
Error	I-Metric
(	I-Metric
NME	I-Metric
)	I-Metric
defined	O
as	O
the	O
average	B-Metric
per	I-Metric
vertex	I-Metric
Euclidean	I-Metric
distance	I-Metric
between	O
the	O
estimated	O
and	O
ground	O
truth	O
reconstruction	O
normalised	O
by	O
the	O
outer	O
3D	O
interocular	O
distance	O
:	O
where	O
is	O
the	O
number	O
of	O
vertices	O
per	O
facial	O
mesh	O
,	O
is	O
the	O
3D	O
interocular	O
distance	O
and	O
,	O
are	O
vertices	O
of	O
the	O
grouthtruth	O
and	O
predicted	O
meshes	O
.	O
	
The	O
error	O
is	O
calculated	O
on	O
the	O
face	O
region	O
only	O
on	O
approximately	O
19	O
,	O
000	O
vertices	O
per	O
facial	O
mesh	O
.	O
	
Notice	O
that	O
when	O
there	O
is	O
no	O
point	O
correspondence	O
between	O
the	O
ground	O
truth	O
and	O
the	O
estimated	O
mesh	O
,	O
ICP	O
was	O
used	O
but	O
only	O
to	O
establish	O
the	O
correspondence	O
,	O
i.e.	O
the	O
rigid	O
alignment	O
was	O
not	O
used	O
.	O
	
If	O
the	O
rigid	O
alignment	O
is	O
used	O
,	O
we	O
found	O
that	O
,	O
for	O
all	O
methods	O
,	O
the	O
error	B-Metric
decreases	O
	
but	O
it	O
turns	O
out	O
that	O
the	O
relative	O
difference	O
in	O
performance	O
remains	O
the	O
same	O
.	O
	
For	O
completeness	O
,	O
we	O
included	O
these	O
results	O
in	O
the	O
supplementary	O
material	O
.	O
	
Comparison	O
with	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
.	O
	
We	O
compared	O
against	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
3D	B-Method
reconstruction	I-Method
methods	I-Method
for	O
which	O
code	O
is	O
publicly	O
available	O
.	O
	
These	O
include	O
the	O
very	O
recent	O
methods	O
of	O
3DDFA	B-Method
,	O
and	O
EOS	B-Method
.	O
	
section	O
:	O
Importance	O
of	O
spatial	B-Task
alignment	I-Task
	
The	O
3D	B-Method
reconstruction	I-Method
method	I-Method
described	O
in	O
regresses	O
a	O
3D	O
volume	O
of	O
fixed	O
orientation	O
from	O
one	O
or	O
more	O
images	O
using	O
an	O
LSTM	B-Method
.	O
	
This	O
is	O
different	O
to	O
our	O
approach	O
of	O
taking	O
a	O
single	O
image	O
and	O
regressing	O
a	O
spatially	O
aligned	O
volume	O
,	O
which	O
we	O
believe	O
is	O
easier	O
to	O
learn	O
.	O
	
To	O
explore	O
what	O
the	O
repercussions	O
of	O
ignoring	O
spatial	O
alignment	O
are	O
,	O
we	O
trained	O
a	O
variant	O
of	O
VRN	B-Method
which	O
regresses	O
a	O
frontal	O
version	O
of	O
the	O
face	O
,	O
i.e.	O
a	O
face	O
of	O
fixed	O
orientation	O
as	O
in	O
.	O
	
Although	O
this	O
network	O
produces	O
a	O
reasonable	O
face	O
,	O
it	O
can	O
only	O
capture	O
diminished	O
expression	O
,	O
and	O
the	O
shape	O
for	O
all	O
faces	O
appears	O
to	O
remain	O
almost	O
identical	O
.	O
	
This	O
is	O
very	O
noticeable	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Numeric	O
comparison	O
is	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
left	O
)	O
,	O
as	O
VRN	B-Method
without	O
alignment	O
.	O
	
We	O
believe	O
that	O
this	O
further	O
confirms	O
that	O
spatial	B-Task
alignment	I-Task
is	O
of	O
paramount	O
importance	O
when	O
performing	O
3D	B-Task
reconstruction	I-Task
in	O
this	O
way	O
.	O
	
section	O
:	O
Ablation	B-Task
studies	I-Task
	
In	O
this	O
section	O
,	O
we	O
report	O
the	O
results	O
of	O
experiments	O
aiming	O
to	O
shed	O
further	O
light	O
into	O
the	O
performance	O
of	O
the	O
proposed	O
networks	O
.	O
	
For	O
all	O
experiments	O
reported	O
,	O
we	O
used	O
the	O
best	O
performing	O
VRN	B-Method
-	I-Method
Guided	I-Method
.	O
	
Effect	O
of	O
pose	O
.	O
	
To	O
measure	O
the	O
influence	O
of	O
pose	O
on	O
the	O
reconstruction	B-Metric
error	I-Metric
,	O
we	O
measured	O
the	O
NME	B-Metric
for	O
different	O
yaw	O
angles	O
using	O
all	O
of	O
our	O
Florence	B-Material
renderings	O
.	O
	
As	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
the	O
performance	O
of	O
our	O
method	O
decreases	O
as	O
the	O
pose	O
increases	O
.	O
	
This	O
is	O
to	O
be	O
expected	O
,	O
due	O
to	O
less	O
of	O
the	O
face	O
being	O
visible	O
which	O
makes	O
evaluation	O
for	O
the	O
invisible	O
part	O
difficult	O
.	O
	
We	O
believe	O
that	O
our	O
error	O
is	O
still	O
very	O
low	O
considering	O
these	O
poses	O
.	O
	
Effect	O
of	O
expression	O
.	O
	
Certain	O
expressions	O
are	O
usually	O
considered	O
harder	O
to	O
accurately	O
reproduce	O
in	O
3D	B-Task
face	I-Task
reconstruction	I-Task
.	O
	
To	O
measure	O
the	O
effect	O
of	O
facial	O
expressions	O
on	O
performance	O
,	O
we	O
rendered	O
frontal	O
images	O
in	O
difference	O
expressions	O
from	O
BU	O
-	O
4DFE	O
(	O
since	O
Florence	B-Material
only	O
exhibits	O
a	O
neutral	O
expression	O
)	O
and	O
measured	O
the	O
performance	O
for	O
each	O
expression	O
.	O
	
This	O
kind	O
of	O
extreme	O
acted	O
facial	O
expressions	O
generally	O
do	O
not	O
occur	O
in	O
the	O
training	O
set	O
,	O
yet	O
as	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
the	O
performance	O
variation	O
across	O
different	O
expressions	O
is	O
quite	O
minor	O
.	O
	
Effect	O
of	O
Gaussian	O
size	O
for	O
guidance	B-Task
.	O
	
We	O
trained	O
a	O
VRN	B-Method
-	I-Method
Guided	I-Method
,	O
however	O
,	O
this	O
time	O
,	O
the	O
facial	B-Method
landmark	I-Method
detector	I-Method
network	I-Method
of	O
the	O
VRN	B-Method
-	I-Method
Guided	I-Method
regresses	O
larger	O
Gaussians	B-Method
(	O
as	O
opposed	O
to	O
the	O
normal	O
)	O
.	O
	
The	O
performance	O
of	O
the	O
3D	B-Task
reconstruction	I-Task
dropped	O
by	O
a	O
negligible	O
amount	O
,	O
suggesting	O
that	O
as	O
long	O
as	O
the	O
Gaussians	O
are	O
of	O
a	O
sensible	O
size	O
,	O
guidance	O
will	O
always	O
help	O
.	O
	
section	O
:	O
Conclusions	O
	
We	O
proposed	O
a	O
direct	O
approach	O
to	O
3D	B-Task
facial	I-Task
reconstruction	I-Task
from	O
a	O
single	O
2D	O
image	O
using	O
volumetric	B-Method
CNN	I-Method
regression	I-Method
.	O
	
To	O
this	O
end	O
,	O
we	O
proposed	O
and	O
exhaustively	O
evaluated	O
three	O
different	O
networks	O
for	O
volumetric	B-Task
regression	I-Task
,	O
reporting	O
results	O
that	O
show	O
that	O
the	O
proposed	O
networks	O
perform	O
well	O
for	O
the	O
whole	O
spectrum	O
of	O
facial	O
pose	O
,	O
and	O
can	O
deal	O
with	O
facial	O
expressions	O
as	O
well	O
as	O
occlusions	O
.	O
	
We	O
also	O
compared	O
the	O
performance	O
of	O
our	O
networks	O
against	O
that	O
of	O
recent	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
based	O
on	O
3DMM	B-Method
fitting	I-Method
reporting	O
large	O
performance	O
improvement	O
on	O
three	O
different	O
datasets	O
.	O
	
Future	O
work	O
may	O
include	O
improving	O
detail	O
and	O
establishing	O
a	O
fixed	O
correspondence	O
from	O
the	O
isosurface	O
of	O
the	O
mesh	O
.	O
	
section	O
:	O
Acknowledgements	O
	
Aaron	O
Jackson	O
is	O
funded	O
by	O
a	O
PhD	O
scholarship	O
from	O
the	O
University	O
of	O
Nottingham	O
.	O
	
We	O
are	O
grateful	O
for	O
access	O
to	O
the	O
University	O
of	O
Nottingham	O
High	O
Performance	O
Computing	O
Facility	O
.	O
	
Finally	O
,	O
we	O
would	O
like	O
to	O
express	O
our	O
thanks	O
to	O
Patrik	O
Huber	O
for	O
his	O
help	O
testing	O
EOS	O
.	O
	
bibliography	O
:	O
References	O
	
Long	B-Task
Text	I-Task
Generation	I-Task
via	O
Adversarial	B-Method
Training	I-Method
with	O
Leaked	O
Information	O
	
section	O
:	O
Abstract	O
	
Automatically	B-Task
generating	I-Task
coherent	I-Task
and	I-Task
semantically	I-Task
meaningful	I-Task
text	I-Task
has	O
many	O
applications	O
in	O
machine	B-Task
translation	I-Task
,	O
dialogue	B-Task
systems	I-Task
,	O
image	B-Task
captioning	I-Task
,	O
etc	O
.	O
	
Recently	O
,	O
by	O
combining	O
with	O
policy	B-Method
gradient	I-Method
,	O
Generative	B-Method
Adversarial	I-Method
Nets	I-Method
(	O
GAN	B-Method
)	O
that	O
use	O
a	O
discriminative	B-Method
model	I-Method
to	O
guide	O
the	O
training	O
of	O
the	O
generative	B-Method
model	I-Method
as	O
a	O
reinforcement	B-Method
learning	I-Method
policy	I-Method
has	O
shown	O
promising	O
results	O
in	O
text	O
generation	B-Task
.	O
	
However	O
,	O
the	O
scalar	O
guiding	O
signal	O
is	O
only	O
available	O
after	O
the	O
entire	O
text	O
has	O
been	O
generated	O
and	O
lacks	O
intermediate	O
information	O
about	O
text	O
structure	O
during	O
the	O
generative	B-Method
process	I-Method
.	O
	
As	O
such	O
,	O
it	O
limits	O
its	O
success	O
when	O
the	O
length	O
of	O
the	O
generated	O
text	O
samples	O
is	O
long	O
(	O
more	O
than	O
20	O
words	O
)	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
new	O
framework	O
,	O
called	O
LeakGAN	B-Method
,	O
to	O
address	O
the	O
problem	O
for	O
long	O
text	O
generation	B-Task
.	O
	
We	O
allow	O
the	O
discriminative	B-Method
net	I-Method
to	O
leak	O
its	O
own	O
high	O
-	O
level	O
extracted	O
features	O
to	O
the	O
generative	B-Method
net	I-Method
to	O
further	O
help	O
the	O
guidance	B-Task
.	O
	
The	O
generator	B-Method
incorporates	O
such	O
informative	O
signals	O
into	O
all	O
generation	B-Task
steps	O
through	O
an	O
additional	O
MANAGER	B-Method
module	O
,	O
which	O
takes	O
the	O
extracted	O
features	O
of	O
current	O
generated	O
words	O
and	O
outputs	O
a	O
latent	O
vector	O
to	O
guide	O
the	O
WORKER	B-Method
module	O
for	O
next	O
-	O
word	O
generation	B-Task
.	O
	
Our	O
extensive	O
experiments	O
on	O
synthetic	O
data	O
and	O
various	O
realworld	O
tasks	O
with	O
Turing	O
test	O
demonstrate	O
that	O
LeakGAN	B-Method
is	O
highly	O
effective	O
in	O
long	O
text	O
generation	B-Task
and	O
also	O
improves	O
the	O
performance	O
in	O
short	O
text	O
generation	B-Task
scenarios	O
.	O
	
More	O
importantly	O
,	O
without	O
any	O
supervision	O
,	O
LeakGAN	B-Method
would	O
be	O
able	O
to	O
implicitly	O
learn	O
sentence	O
structures	O
only	O
through	O
the	O
interaction	O
between	O
MANAGER	B-Method
and	O
WORKER	B-Method
.	O
	
section	O
:	O
Introduction	O
	
The	O
ability	O
to	O
generate	O
coherent	B-Task
and	I-Task
semantically	I-Task
meaningful	I-Task
text	I-Task
plays	O
a	O
key	O
role	O
in	O
many	O
natural	B-Task
language	I-Task
processing	I-Task
applications	I-Task
such	O
as	O
machine	B-Task
translation	I-Task
,	O
dialogue	B-Task
generation	I-Task
,	O
and	O
image	B-Task
captioning	I-Task
[	O
reference	O
]	O
.	O
	
While	O
most	O
previous	O
work	O
focuses	O
on	O
task	B-Task
-	I-Task
specific	I-Task
applications	I-Task
in	O
supervised	B-Task
settings	I-Task
[	O
reference	O
][	O
reference	O
]	O
,	O
the	O
generic	O
unsupervised	O
text	O
generation	B-Task
,	O
which	O
aims	O
to	O
mimic	O
the	O
distribution	O
over	O
real	O
text	O
from	O
a	O
corpus	O
,	O
has	O
recently	O
drawn	O
much	O
attention	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
;	O
	
*	O
Correspondence	O
to	O
Weinan	O
Zhang	O
.	O
	
This	O
work	O
is	O
financially	O
supported	O
by	O
NSFC	O
(	O
61702327	O
)	O
and	O
Shanghai	O
Sailing	O
Program	O
(	O
17YF1428200	O
)	O
.	O
	
Copyright	O
c	O
2018	O
,	O
Association	O
for	O
the	O
Advancement	O
of	O
Artificial	O
Intelligence	O
(	O
www.aaai.org	O
)	O
.	O
	
All	O
rights	O
reserved	O
.	O
	
[	O
	
reference	O
]	O
.	O
A	O
typical	O
approach	O
is	O
to	O
train	O
a	O
recurrent	B-Method
neural	I-Method
network	I-Method
(	O
RNN	B-Method
)	O
to	O
maximize	O
the	O
log	O
-	O
likelihood	O
of	O
each	O
ground	O
-	O
truth	O
word	O
given	O
prior	O
observed	O
words	O
[	O
reference	O
]	O
,	O
which	O
,	O
however	O
,	O
suffers	O
from	O
so	O
-	O
called	O
exposure	O
bias	O
due	O
to	O
the	O
discrepancy	O
between	O
training	O
and	O
inference	B-Task
stage	I-Task
:	O
the	O
model	O
sequentially	O
generates	O
the	O
next	O
word	O
based	O
on	O
previously	O
generated	O
words	O
during	O
inference	B-Task
but	O
itself	O
is	O
trained	O
to	O
generate	O
words	O
given	O
ground	O
-	O
truth	O
words	O
[	O
	
reference	O
]	O
.	O
A	O
scheduled	B-Method
sampling	I-Method
approach	I-Method
is	O
proposed	O
to	O
addressed	O
this	O
problem	O
,	O
but	O
is	O
proved	O
to	O
be	O
fundamentally	O
inconsistent	O
	
[	O
reference	O
]	O
.	O
Generative	O
Adversarial	O
Nets	O
(	O
GAN	B-Method
)	O
[	O
reference	O
]	O
,	O
which	O
is	O
firstly	O
proposed	O
for	O
continous	O
data	O
(	O
image	B-Task
generation	I-Task
etc	O
.	O
)	O
,	O
is	O
then	O
extended	O
to	O
discrete	O
,	O
sequential	O
data	O
to	O
alleviate	O
the	O
above	O
problem	O
and	O
has	O
shown	O
promising	O
results	O
[	O
reference	O
]	O
)	O
.	O
	
Due	O
to	O
the	O
discrete	O
nature	O
of	O
text	O
samples	O
,	O
text	O
generation	B-Task
is	O
modeled	O
as	O
a	O
sequential	B-Task
decision	I-Task
making	I-Task
process	I-Task
,	O
where	O
the	O
state	O
is	O
previously	O
generated	O
words	O
,	O
the	O
action	O
is	O
the	O
next	O
word	O
to	O
be	O
generated	O
,	O
and	O
the	O
generative	B-Method
net	I-Method
G	I-Method
is	O
a	O
stochastic	B-Method
policy	I-Method
that	O
maps	O
current	O
state	O
to	O
a	O
distribution	O
over	O
the	O
action	O
space	O
.	O
	
After	O
the	O
whole	O
text	O
generation	B-Task
is	O
done	O
,	O
the	O
generated	O
text	O
samples	O
are	O
then	O
fed	O
to	O
the	O
discriminative	B-Method
net	I-Method
D	I-Method
,	O
a	O
classifier	B-Method
that	O
is	O
trained	O
to	O
distinguish	O
real	O
and	O
generated	O
text	O
samples	O
,	O
to	O
get	O
reward	O
signals	O
for	O
updating	O
G.	O
	
Since	O
then	O
,	O
various	O
methods	O
have	O
been	O
proposed	O
in	O
text	O
generation	B-Task
via	O
GAN	B-Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
Nonetheless	O
,	O
the	O
reported	O
results	O
are	O
limited	O
to	O
the	O
cases	O
that	O
the	O
generated	O
text	O
samples	O
are	O
short	O
(	O
say	O
,	O
fewer	O
than	O
20	O
words	O
)	O
while	O
more	O
challenging	O
long	O
text	O
generation	B-Task
is	O
hardly	O
studied	O
,	O
which	O
is	O
necessary	O
for	O
practical	O
tasks	O
such	O
as	O
auto	O
-	O
generation	B-Task
of	O
news	O
articles	O
or	O
product	B-Task
descriptions	I-Task
.	O
	
A	O
main	O
drawback	O
of	O
existing	O
methods	O
to	O
long	O
text	O
generation	B-Task
is	O
that	O
the	O
binary	O
guiding	O
signal	O
from	O
D	O
is	O
sparse	O
as	O
it	O
is	O
only	O
available	O
when	O
the	O
whole	O
text	O
sample	O
is	O
generated	O
.	O
	
Also	O
,	O
the	O
scalar	O
guiding	O
signal	O
for	O
a	O
whole	O
text	O
is	O
non	O
-	O
informative	O
as	O
it	O
does	O
not	O
necessarily	O
preserve	O
the	O
picture	O
about	O
the	O
intermediate	O
syntactic	O
structure	O
and	O
semantics	O
of	O
the	O
text	O
that	O
is	O
being	O
generated	O
for	O
G	O
to	O
sufficiently	O
learn	O
.	O
	
On	O
one	O
hand	O
,	O
to	O
make	O
the	O
guiding	O
signals	O
more	O
informative	O
,	O
discriminator	B-Method
D	I-Method
could	O
potentially	O
provide	O
more	O
guidance	O
beside	O
the	O
final	O
reward	B-Metric
value	I-Metric
,	O
since	O
D	O
is	O
a	O
trained	O
model	O
,	O
e.g.	O
a	O
convolutional	B-Method
neural	I-Method
network	I-Method
(	O
CNN	B-Method
)	O
[	O
reference	O
]	O
,	O
rather	O
than	O
an	O
unknown	O
black	O
box	O
.	O
	
With	O
that	O
idea	O
,	O
proposed	O
to	O
train	O
generator	B-Method
G	O
via	O
forcing	O
learned	O
feature	B-Method
representations	I-Method
of	O
real	O
and	O
generated	O
text	O
by	O
D	O
to	O
be	O
matched	O
,	O
instead	O
of	O
directly	O
training	O
G	O
to	O
maximize	O
the	O
reward	O
from	O
D	O
	
[	O
reference	O
]	O
.	O
	
Such	O
a	O
method	O
can	O
be	O
effective	O
in	O
short	O
text	O
generation	B-Task
,	O
but	O
the	O
guiding	O
signals	O
are	O
still	O
absent	O
until	O
the	O
end	O
of	O
the	O
text	O
)	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
to	O
alleviate	O
the	O
sparsity	B-Task
problem	I-Task
of	I-Task
the	I-Task
guiding	I-Task
signal	I-Task
,	O
the	O
idea	O
of	O
hierarchy	O
naturally	O
arises	O
in	O
text	O
generation	B-Task
,	O
since	O
the	O
real	O
text	O
samples	O
are	O
generated	O
following	O
some	O
kinds	O
of	O
hierarchy	O
such	O
as	O
the	O
semantic	O
structure	O
and	O
the	O
part	O
-	O
of	O
-	O
speech	O
[	O
reference	O
]	O
.	O
	
By	O
decomposing	O
the	O
whole	O
generation	B-Task
task	O
into	O
various	O
sub	O
-	O
tasks	O
according	O
to	O
the	O
hierarchical	O
structure	O
,	O
it	O
becomes	O
much	O
easier	O
for	O
the	O
model	O
to	O
learn	O
.	O
	
Early	O
efforts	O
have	O
been	O
made	O
to	O
incorporate	O
the	O
hierarchy	B-Method
idea	I-Method
in	O
text	O
generation	B-Task
[	O
reference	O
][	O
reference	O
]	O
)	O
but	O
all	O
use	O
a	O
predefined	O
sub	O
-	O
task	O
set	O
from	O
domain	O
knowledge	O
,	O
which	O
makes	O
them	O
unable	O
to	O
adapt	O
to	O
arbitrary	O
sequence	O
generation	B-Task
tasks	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
new	O
algorithmic	B-Method
framework	I-Method
called	O
LeakGAN	B-Method
to	O
address	O
both	O
the	O
non	B-Task
-	I-Task
informativeness	I-Task
and	O
the	O
sparsity	B-Task
issues	I-Task
.	O
	
LeakGAN	B-Method
is	O
a	O
new	O
way	O
of	O
providing	O
richer	O
information	O
from	O
the	O
discriminator	B-Method
to	O
the	O
generator	B-Method
by	O
borrowing	O
the	O
recent	O
advances	O
in	O
hierarchical	B-Method
reinforcement	I-Method
learning	I-Method
[	O
reference	O
]	O
.	O
As	O
illustrated	O
in	O
Figure	O
1	O
,	O
we	O
specifically	O
introduce	O
a	O
hierarchical	O
generator	B-Method
G	O
,	O
which	O
consists	O
of	O
a	O
high	O
-	O
level	O
MANAGER	B-Method
module	O
and	O
a	O
low	O
-	O
level	O
WORKER	B-Method
module	O
.	O
	
The	O
MANAGER	B-Method
is	O
a	O
long	B-Method
shortterm	I-Method
memory	I-Method
network	I-Method
(	I-Method
LSTM	I-Method
)	I-Method
[	O
reference	O
]	O
and	O
serves	O
as	O
a	O
mediator	O
.	O
	
In	O
each	O
step	O
,	O
it	O
receives	O
generator	B-Method
D	O
's	O
high	O
-	O
level	O
feature	O
representation	O
,	O
e.g.	O
,	O
the	O
feature	O
map	O
of	O
the	O
CNN	B-Method
,	O
and	O
uses	O
it	O
to	O
form	O
the	O
guiding	O
goal	O
for	O
the	O
WORKER	B-Method
module	O
in	O
that	O
timestep	O
.	O
	
As	O
the	O
information	O
from	O
D	O
is	O
internally	O
-	O
maintained	O
and	O
in	O
an	O
adversarial	B-Method
game	I-Method
it	O
is	O
not	O
supposed	O
to	O
provide	O
G	O
with	O
such	O
information	O
.	O
	
We	O
thus	O
call	O
it	O
a	O
leakage	O
of	O
information	O
from	O
D.	O
	
Next	O
,	O
given	O
the	O
goal	O
embedding	O
produced	O
by	O
the	O
MAN	B-Method
-	I-Method
AGER	I-Method
,	O
the	O
WORKER	B-Method
first	O
encodes	O
current	O
generated	O
words	O
with	O
another	O
LSTM	B-Method
,	O
then	O
combines	O
the	O
output	O
of	O
the	O
LSTM	B-Method
and	O
the	O
goal	B-Method
embedding	I-Method
to	O
take	O
a	O
final	O
action	O
at	O
current	O
state	O
.	O
	
As	O
such	O
,	O
the	O
guiding	O
signals	O
from	O
D	O
are	O
not	O
only	O
available	O
to	O
G	O
at	O
the	O
end	O
in	O
terms	O
of	O
the	O
scalar	O
reward	O
signals	O
,	O
but	O
also	O
available	O
in	O
terms	O
of	O
a	O
goal	O
embedding	O
vector	O
during	O
the	O
generation	B-Method
process	I-Method
to	O
guide	O
G	O
how	O
to	O
get	O
improved	O
.	O
	
We	O
conduct	O
extensive	O
experiments	O
based	O
on	O
synthetic	O
and	O
real	O
data	O
.	O
	
For	O
synthetic	O
data	O
,	O
LeakGAN	B-Method
obtains	O
much	O
lower	O
negative	B-Metric
log	I-Metric
-	I-Metric
likelihood	I-Metric
than	O
previous	O
models	O
with	O
sequence	O
length	O
set	O
to	O
20	O
and	O
40	O
.	O
	
For	O
real	O
data	O
,	O
we	O
use	O
the	O
text	O
in	O
EMNLP2017	B-Material
WMT	I-Material
News	I-Material
,	O
COCO	B-Material
Image	I-Material
Caption	I-Material
and	O
Chinese	B-Material
Poems	I-Material
as	O
the	O
long	O
,	O
mid	O
-	O
length	O
and	O
short	O
text	O
corpus	O
,	O
respectively	O
.	O
	
In	O
all	O
those	O
cases	O
,	O
LeakGAN	B-Method
shows	O
significant	O
improvements	O
compared	O
to	O
previous	O
models	O
in	O
terms	O
of	O
BLEU	B-Metric
statistics	I-Metric
and	O
human	B-Metric
Turing	I-Metric
test	I-Metric
.	O
	
We	O
further	O
provide	O
a	O
deep	O
investigation	O
on	O
the	O
interaction	O
between	O
MAN	B-Task
-	I-Task
AGER	I-Task
and	O
WORKER	B-Method
,	O
which	O
indicates	O
LeakGAN	B-Method
implicitly	O
learns	O
sentence	O
structures	O
,	O
such	O
as	O
punctuation	O
,	O
clause	O
structure	O
and	O
long	O
suffix	O
without	O
any	O
supervision	O
.	O
	
Figure	O
1	O
:	O
	
An	O
overview	O
of	O
our	O
LeakGAN	B-Method
text	O
generation	B-Task
framework	O
.	O
	
While	O
the	O
generator	B-Method
is	O
responsible	O
to	O
generate	O
the	O
next	O
word	O
,	O
the	O
discriminator	B-Method
adversarially	I-Method
judges	O
the	O
generated	O
sentence	O
once	O
it	O
is	O
complete	O
.	O
	
The	O
chief	O
novelty	O
lies	O
in	O
that	O
,	O
unlike	O
conventional	O
adversarial	B-Method
training	I-Method
,	O
during	O
the	O
process	O
,	O
the	O
discriminator	O
reveals	O
its	O
internal	O
state	O
(	O
feature	O
f	O
t	O
)	O
in	O
order	O
to	O
guide	O
the	O
generator	B-Method
more	O
informatively	O
and	O
frequently	O
.	O
	
(	O
See	O
Methodology	O
Section	O
for	O
more	O
details	O
.	O
)	O
	
section	O
:	O
Related	O
Work	O
	
Generating	B-Task
text	I-Task
that	O
mimics	O
human	O
's	O
expression	O
has	O
been	O
studied	O
for	O
poem	B-Task
generation	I-Task
[	O
reference	O
]	O
,	O
image	B-Task
captioning	I-Task
,	O
dialogue	B-Task
system	I-Task
)	O
machine	B-Task
translation	I-Task
.	O
	
[	O
reference	O
]	O
proposed	O
a	O
recurent	B-Method
neural	I-Method
network	I-Method
(	I-Method
RNN	I-Method
)	I-Method
based	I-Method
generative	I-Method
model	I-Method
to	O
use	O
the	O
human	O
-	O
generated	O
text	O
where	O
at	O
each	O
step	O
the	O
model	O
tries	O
to	O
predict	O
the	O
next	O
word	O
given	O
previous	O
real	O
word	O
sequence	O
and	O
is	O
trained	O
in	O
a	O
supervised	B-Method
fashion	I-Method
.	O
	
A	O
common	O
difficulty	O
of	O
all	O
supervised	B-Method
generative	I-Method
models	I-Method
is	O
that	O
it	O
is	O
hard	O
to	O
design	O
an	O
appropriate	O
,	O
differentiable	B-Metric
,	I-Metric
lowbias	I-Metric
metric	I-Metric
to	O
evaluate	O
the	O
output	O
of	O
the	O
generator	B-Method
,	O
which	O
inspires	O
the	O
adversarial	B-Method
training	I-Method
mechanisms	I-Method
.	O
	
[	O
reference	O
]	O
proposed	O
generative	B-Method
adversarial	I-Method
nets	I-Method
(	O
GANs	B-Method
)	O
to	O
generate	O
continuous	O
data	O
like	O
images	O
.	O
	
GAN	B-Method
introduces	O
a	O
minimax	B-Method
game	I-Method
between	O
a	O
generative	B-Method
model	I-Method
and	O
a	O
discriminative	B-Method
model	I-Method
,	O
where	O
the	O
discriminator	B-Method
can	O
be	O
viewed	O
as	O
the	O
dynamically	O
-	O
updated	O
evaluation	B-Metric
metric	I-Metric
to	O
guide	O
the	O
tuning	O
of	O
the	O
generated	O
data	O
.	O
	
To	O
apply	O
GANs	B-Method
to	O
text	O
generation	B-Task
,	O
[	O
reference	O
]	O
proposed	O
SeqGAN	B-Method
that	O
models	O
the	O
text	O
generation	B-Task
as	O
a	O
sequential	B-Task
decision	I-Task
making	I-Task
process	I-Task
and	O
trains	O
the	O
generative	B-Method
model	I-Method
with	O
policy	B-Method
gradient	I-Method
methods	I-Method
.	O
	
MaliGAN	O
[	O
reference	O
]	O
)	O
modifies	O
the	O
orginal	O
GAN	B-Method
objective	O
and	O
proposes	O
a	O
set	O
of	O
training	B-Method
techniques	I-Method
to	O
reduce	O
the	O
potential	O
variance	O
.	O
	
To	O
deal	O
with	O
the	O
gradient	O
vanishing	O
problem	O
of	O
GAN	B-Method
,	O
RankGAN	B-Method
[	O
reference	O
]	O
proposes	O
an	O
alternative	O
solution	O
to	O
this	O
problem	O
by	O
replacing	O
the	O
original	O
binary	B-Method
classifier	I-Method
discriminator	I-Method
with	O
a	O
ranking	B-Method
model	I-Method
by	O
taking	O
a	O
softmax	O
over	O
the	O
expected	O
cosine	O
distances	O
from	O
the	O
generated	O
sequences	O
to	O
the	O
real	O
data	O
.	O
	
Another	O
problem	O
for	O
the	O
adversarial	O
sequence	O
generation	B-Task
models	O
is	O
that	O
the	O
binary	O
feedback	O
from	O
the	O
discriminator	B-Method
is	O
not	O
sufficiently	O
informative	O
,	O
which	O
requires	O
a	O
huge	O
number	O
of	O
training	O
and	O
generated	O
samples	O
to	O
improve	O
the	O
generator	B-Method
and	O
could	O
result	O
in	O
mode	B-Task
collapse	I-Task
problems	I-Task
.	O
	
Feature	B-Method
Matching	I-Method
)	O
provides	O
a	O
mechanism	O
that	O
matches	O
the	O
latent	O
feature	O
distributions	O
of	O
real	O
and	O
generated	O
sequences	O
via	O
a	O
kernelized	B-Method
discepancy	I-Method
metric	I-Method
to	O
alleviate	O
the	O
weak	B-Task
guidance	I-Task
and	I-Task
mode	I-Task
collapse	I-Task
problems	I-Task
.	O
	
However	O
,	O
such	O
enhancement	O
only	O
happens	O
when	O
the	O
whole	O
text	O
sample	O
is	O
generated	O
and	O
thus	O
the	O
guiding	O
signal	O
is	O
still	O
sparse	O
during	O
the	O
training	O
.	O
	
Reinforcement	B-Method
learning	I-Method
(	O
RL	B-Method
)	O
on	O
the	O
other	O
hand	O
also	O
faces	O
a	O
similar	O
difficulty	O
when	O
reward	O
signals	O
are	O
sparse	O
[	O
reference	O
]	O
)	O
.	O
	
Hierarchical	B-Method
RL	I-Method
is	O
one	O
of	O
the	O
promising	O
techniques	O
for	O
handling	O
the	O
sparse	B-Task
reward	I-Task
issue	I-Task
	
[	O
	
reference	O
]	O
.	O
A	O
typical	O
approach	O
in	O
hierarchical	B-Task
RL	I-Task
is	O
to	O
manually	O
identify	O
the	O
hierarchical	O
structure	O
for	O
the	O
agent	O
by	O
defining	O
several	O
low	O
-	O
level	O
sub	O
-	O
tasks	O
and	O
learning	O
micropolicies	O
for	O
each	O
sub	O
-	O
task	O
while	O
learning	O
a	O
macro	B-Method
-	I-Method
policy	I-Method
for	O
choosing	O
which	O
sub	O
-	O
task	O
to	O
solve	O
.	O
	
Such	O
methods	O
can	O
be	O
very	O
effective	O
when	O
the	O
hierarchical	O
structure	O
is	O
known	O
a	O
priori	O
using	O
domain	O
knowledge	O
in	O
a	O
given	O
specific	O
task	O
,	O
but	O
fail	O
to	O
flexibly	O
adapt	O
to	O
other	O
tasks	O
.	O
	
Recently	O
,	O
[	O
reference	O
]	O
proposed	O
an	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
framework	I-Method
for	O
hierarchical	B-Task
RL	I-Task
where	O
the	O
sub	O
-	O
tasks	O
are	O
not	O
identified	O
manually	O
but	O
implicitly	O
learned	O
by	O
a	O
MANAGER	B-Method
module	O
which	O
takes	O
current	O
state	O
as	O
input	O
and	O
output	O
a	O
goal	O
embedding	O
vector	O
to	O
guide	O
the	O
low	O
-	O
level	O
WORKER	B-Method
module	O
.	O
	
In	O
this	O
work	O
,	O
we	O
model	O
the	O
text	O
generation	B-Task
procedure	O
via	O
adversarial	B-Method
training	I-Method
and	O
policy	B-Method
gradient	I-Method
	
[	O
reference	O
]	O
.	O
	
To	O
address	O
the	O
sparse	B-Task
reward	I-Task
issue	I-Task
in	O
long	O
text	O
generation	B-Task
,	O
we	O
follow	O
[	O
reference	O
]	O
and	O
propose	O
a	O
hierarchy	B-Method
design	I-Method
,	O
i.e.	O
MANAGER	B-Method
and	O
WORKER	B-Method
,	O
for	O
the	O
generator	B-Method
.	O
	
As	O
the	O
reward	O
function	O
in	O
our	O
case	O
is	O
a	O
discriminative	B-Method
model	I-Method
rather	O
than	O
a	O
black	O
box	O
in	O
[	O
reference	O
]	O
,	O
the	O
high	O
-	O
level	O
feature	O
extracted	O
by	O
the	O
discriminator	B-Method
given	O
the	O
current	O
generated	O
word	O
sequence	O
is	O
sent	O
to	O
the	O
MANAGER	B-Method
module	O
.	O
	
As	O
such	O
,	O
the	O
MANAGER	B-Method
module	O
can	O
be	O
also	O
viewed	O
as	O
a	O
spy	O
that	O
leaks	O
information	O
from	O
the	O
discriminator	B-Method
to	O
better	O
guide	O
the	O
generator	B-Method
.	O
	
To	O
our	O
knowledge	O
,	O
this	O
is	O
the	O
first	O
work	O
that	O
considers	O
the	O
information	O
leaking	O
in	O
GAN	B-Method
framework	O
for	O
better	O
training	B-Task
generators	I-Task
and	O
combines	O
hierarchical	B-Method
RL	I-Method
to	O
address	O
long	O
text	O
generation	B-Task
problems	O
.	O
	
section	O
:	O
Methodology	O
	
We	O
formalize	O
the	O
text	O
generation	B-Task
problem	O
as	O
a	O
sequential	B-Task
decision	I-Task
making	I-Task
process	I-Task
[	O
reference	O
]	O
.	O
Specifically	O
,	O
at	O
each	O
timestep	O
t	O
,	O
the	O
agent	O
takes	O
the	O
previously	O
generated	O
words	O
as	O
its	O
current	O
state	O
,	O
denoted	O
as	O
s	O
t	O
=	O
(	O
x	O
1	O
,	O
.	O
.	O
.	O
	
,	O
x	O
	
i	O
,	O
.	O
.	O
.	O
	
,	O
x	O
t	O
)	O
,	O
where	O
x	O
i	O
represents	O
a	O
word	O
token	O
in	O
the	O
given	O
vocabulary	O
V	O
.	O
	
A	O
θ	B-Method
-	I-Method
parameterized	I-Method
generative	I-Method
net	I-Method
G	I-Method
θ	I-Method
,	O
which	O
corresponds	O
to	O
a	O
stochastic	B-Method
policy	I-Method
,	O
maps	O
s	O
	
t	O
to	O
a	O
distribution	O
over	O
the	O
whole	O
vocabulary	O
,	O
i.e.	O
G	O
θ	O
(	O
·	O
|s	O
t	O
)	O
,	O
from	O
which	O
the	O
action	O
x	O
t	O
+	O
1	O
,	O
i.e.	O
the	O
next	O
word	O
to	O
select	O
is	O
sampled	O
.	O
	
We	O
also	O
train	O
a	O
φ	B-Method
-	I-Method
parameterized	I-Method
discriminative	I-Method
model	I-Method
D	I-Method
φ	I-Method
that	O
provides	O
a	O
scalar	O
guiding	O
signal	O
D	O
φ	O
(	O
s	O
T	O
)	O
for	O
G	O
θ	O
to	O
adjust	O
its	O
parameters	O
when	O
the	O
whole	O
sentence	O
s	O
T	O
has	O
been	O
generated	O
.	O
	
As	O
we	O
discussed	O
previously	O
,	O
although	O
the	O
above	O
adversarial	B-Method
training	I-Method
is	O
principled	O
,	O
the	O
scalar	O
guiding	O
signal	O
becomes	O
relatively	O
less	O
informative	O
when	O
the	O
sentence	O
length	O
T	O
goes	O
larger	O
.	O
	
To	O
address	O
this	O
,	O
the	O
proposed	O
LeakGAN	B-Method
framework	O
allows	O
discriminator	B-Method
D	I-Method
φ	I-Method
to	O
provide	O
additional	O
information	O
,	O
denoted	O
as	O
features	O
f	O
t	O
,	O
of	O
the	O
current	O
sentence	O
s	O
t	O
(	O
it	O
is	O
internally	O
used	O
for	O
D	O
φ	O
itself	O
for	O
discrimination	B-Task
)	O
to	O
generator	B-Method
G	O
θ	O
(	O
·	O
|s	O
t	O
)	O
.	O
	
In	O
LeakGAN	B-Method
,	O
a	O
hierarchical	B-Method
RL	I-Method
architecture	I-Method
is	O
used	O
as	O
a	O
promising	O
mechanism	O
to	O
effectively	O
incorporate	O
such	O
leaked	O
information	O
f	O
t	O
into	O
the	O
generation	B-Task
procedure	I-Task
of	O
G	B-Method
θ	I-Method
(	O
also	O
see	O
Figure	O
1	O
)	O
.	O
	
section	O
:	O
Leaked	O
Features	O
from	O
D	O
as	O
Guiding	B-Method
Signals	I-Method
	
Different	O
from	O
typical	O
model	B-Method
-	I-Method
free	I-Method
RL	I-Method
settings	I-Method
where	O
the	O
reward	O
function	O
is	O
a	O
black	O
box	O
,	O
our	O
adversarial	O
text	O
generation	B-Task
uses	O
D	B-Method
φ	I-Method
as	O
a	O
learned	O
reward	O
function	O
.	O
	
Typically	O
,	O
D	B-Method
φ	I-Method
is	O
a	O
neural	B-Method
network	I-Method
and	O
can	O
be	O
decomposed	O
into	O
a	O
feature	B-Method
extractor	I-Method
F	I-Method
(	O
·	O
;	O
φ	O
f	O
)	O
and	O
a	O
final	O
sigmoid	B-Method
classification	I-Method
layer	I-Method
with	O
weight	O
vector	O
φ	O
l	O
.	O
	
Mathematically	O
,	O
given	O
input	O
s	O
,	O
we	O
have	O
	
where	O
φ	O
=	O
(	O
φ	O
f	O
,	O
φ	O
l	O
)	O
and	O
sigmoid	O
(	O
z	O
)	O
=	O
1	O
/(	O
1	O
+	O
e	O
−z	O
)	O
.	O
	
f	O
	
=	O
F	O
(	O
s	O
;	O
φ	O
f	O
)	O
is	O
the	O
feature	O
vector	O
of	O
s	O
in	O
the	O
last	O
layer	O
of	O
D	O
φ	O
,	O
which	O
is	O
to	O
be	O
leaked	O
to	O
generator	B-Method
G	O
θ	O
.	O
	
As	O
is	O
shown	O
in	O
Eq	O
.	O
	
(	O
1	O
)	O
,	O
for	O
a	O
given	O
D	O
φ	O
,	O
the	O
reward	O
value	O
for	O
each	O
state	O
s	O
mainly	O
depends	O
on	O
the	O
extracted	O
features	O
f	O
.	O
	
As	O
such	O
,	O
the	O
objective	O
of	O
getting	O
a	O
higher	O
reward	O
from	O
D	O
φ	O
is	O
equivalent	O
to	O
finding	O
a	O
higher	O
reward	O
region	O
in	O
this	O
extracted	O
feature	O
space	O
F	O
(	O
S	O
;	O
φ	O
f	O
)	O
=	O
{	O
F	O
(	O
s	O
;	O
φ	O
f	O
)	O
}	O
s∈S	O
.	O
	
Specifically	O
,	O
our	O
feature	B-Method
extractor	I-Method
F	O
(	O
·	O
;	O
φ	O
f	O
)	O
in	O
D	O
φ	O
is	O
implemented	O
by	O
a	O
CNN	B-Method
[	O
reference	O
]	O
;	O
thus	O
F	O
(	O
s	O
;	O
φ	O
f	O
)	O
outputs	O
the	O
CNN	O
feature	O
map	O
vector	O
as	O
f	O
after	O
its	O
convolution	B-Method
-	I-Method
pooling	I-Method
-	I-Method
activation	I-Method
layer	I-Method
.	O
	
Other	O
neural	B-Method
network	I-Method
models	I-Method
such	O
as	O
LSTM	B-Method
(	O
Hochreiter	O
and	O
Schmidhuber	O
1997	O
)	O
can	O
also	O
be	O
used	O
to	O
implement	O
	
Compared	O
to	O
the	O
scalar	O
signal	O
D	O
φ	O
(	O
s	O
)	O
,	O
the	O
feature	O
vector	O
f	O
is	O
a	O
much	O
more	O
informative	O
guiding	O
signal	O
for	O
G	B-Task
θ	I-Task
,	O
since	O
it	O
tells	O
what	O
the	O
position	O
of	O
currently	O
-	O
generated	O
words	O
is	O
in	O
the	O
extracted	O
feature	O
space	O
.	O
	
section	O
:	O
A	O
Hierarchical	O
Structure	O
of	O
G	O
	
In	O
each	O
step	O
t	O
during	O
the	O
generation	B-Task
procedure	I-Task
,	O
to	O
utilize	O
the	O
leaked	O
information	O
f	O
t	O
from	O
D	O
φ	O
,	O
we	O
follow	O
hierarchical	B-Method
RL	I-Method
[	O
reference	O
]	O
to	O
have	O
a	O
hierarchical	B-Method
architecture	I-Method
of	I-Method
G	I-Method
θ	I-Method
.	O
	
Specifically	O
,	O
we	O
introduce	O
a	O
MANAGER	B-Method
module	O
,	O
an	O
LSTM	B-Method
that	O
takes	O
the	O
extracted	O
feature	O
vector	O
	
f	O
t	O
as	O
its	O
input	O
at	O
each	O
step	O
t	O
and	O
outputs	O
a	O
goal	O
vector	O
g	O
t	O
,	O
which	O
is	O
then	O
fed	O
into	O
the	O
WORKER	B-Method
module	O
to	O
guide	O
the	O
generation	B-Task
of	O
the	O
next	O
word	O
in	O
order	O
to	O
approach	O
the	O
higher	O
reward	O
region	O
in	O
F	O
(	O
S	O
;	O
	
φ	O
f	O
)	O
.	O
	
Next	O
we	O
will	O
first	O
describe	O
the	O
detailed	O
generator	B-Method
model	O
in	O
LeakGAN	B-Method
and	O
then	O
show	O
how	O
the	O
MANAGER	B-Method
and	O
WORKER	B-Method
are	O
trained	O
with	O
the	O
guiding	O
signals	O
from	O
D	O
φ	O
.	O
	
Generation	B-Task
Process	I-Task
.	O
	
The	O
MANAGER	B-Method
and	O
WORKER	B-Method
modules	I-Method
both	O
start	O
from	O
an	O
all	O
-	O
zero	O
hidden	O
state	O
,	O
denoted	O
as	O
h	O
M	O
0	O
and	O
h	O
W	O
0	O
respectively	O
.	O
	
At	O
each	O
step	O
,	O
the	O
MANAGER	B-Method
receives	O
the	O
leaked	O
feature	O
vector	O
f	O
t	O
from	O
the	O
discriminator	B-Method
D	I-Method
φ	I-Method
,	O
which	O
is	O
further	O
combined	O
with	O
current	O
hidden	O
state	O
of	O
the	O
MANAGER	B-Method
to	O
produce	O
the	O
goal	O
vector	O
g	O
t	O
	
aŝ	O
	
where	O
M	O
(	O
·	O
;	O
θ	O
m	O
)	O
denotes	O
the	O
MANAGER	B-Method
module	O
implemented	O
by	O
an	O
LSTM	B-Method
with	O
parameters	O
θ	O
m	O
and	O
h	O
M	O
t	O
is	O
the	O
recurrent	O
hidden	O
vector	O
of	O
the	O
LSTM	B-Method
.	O
	
To	O
incorporate	O
goals	O
produced	O
by	O
MANAGER	B-Method
,	O
a	O
linear	B-Method
transformation	I-Method
ψ	I-Method
with	O
weight	O
matrix	O
	
W	O
ψ	O
is	O
performed	O
on	O
a	O
summation	O
over	O
recent	O
c	O
goals	O
to	O
produce	O
a	O
k	O
-	O
dimensional	O
goal	O
embedding	O
vector	O
w	O
t	O
as	O
	
Given	O
the	O
goal	O
embedding	O
vector	O
w	O
t	O
,	O
the	O
WORKER	B-Method
module	O
takes	O
the	O
current	O
word	O
x	O
t	O
as	O
input	O
and	O
outputs	O
a	O
matrix	O
O	O
t	O
,	O
which	O
is	O
further	O
combined	O
with	O
w	O
t	O
by	O
matrix	B-Method
product	I-Method
to	O
determine	O
the	O
final	O
action	O
space	O
distribution	O
under	O
current	O
state	O
	
s	O
t	O
through	O
a	O
softmax	B-Method
	
where	O
W	O
(	O
·	O
;	O
θ	O
w	O
)	O
denotes	O
the	O
WORKER	B-Method
module	O
,	O
i.e.	O
an	O
LSTM	B-Method
with	O
h	O
W	O
t	O
as	O
its	O
recurrent	O
hidden	O
vector	O
	
,	O
O	O
t	O
is	O
a	O
|V	O
|×k	O
matrix	O
that	O
represents	O
the	O
current	O
vector	O
for	O
all	O
words	O
,	O
thus	O
O	O
t	O
·	O
w	O
t	O
yields	O
the	O
calculated	O
logits	O
for	O
all	O
words	O
,	O
and	O
α	O
is	O
the	O
temperature	O
parameter	O
to	O
control	O
the	O
generation	B-Task
entropy	O
.	O
	
section	O
:	O
Training	O
of	O
G	O
	
Notice	O
that	O
the	O
above	O
procedure	O
is	O
fully	O
differentiable	O
.	O
	
One	O
can	O
train	O
G	B-Method
θ	I-Method
in	O
an	O
end	O
-	O
to	O
-	O
end	O
manner	O
using	O
a	O
policy	B-Method
gradient	I-Method
algorithm	I-Method
such	O
as	O
REINFORCE	B-Method
	
[	O
reference	O
]	O
.	O
In	O
LeakGAN	B-Method
,	O
we	O
would	O
hope	O
the	O
MANAGER	B-Method
module	O
to	O
capture	O
some	O
meaningful	O
patterns	O
.	O
	
Thus	O
,	O
we	O
follow	O
[	O
reference	O
]	O
)	O
and	O
train	O
the	O
MANAGER	B-Method
and	O
WORKER	B-Method
modules	I-Method
separately	O
,	O
where	O
the	O
MANAGER	B-Method
is	O
trained	O
to	O
predict	O
advantageous	O
directions	O
in	O
the	O
discriminative	O
feature	O
space	O
and	O
the	O
WORKER	B-Method
is	O
intrinsically	O
rewarded	O
to	O
follow	O
such	O
directions	O
.	O
	
Similar	O
to	O
[	O
reference	O
]	O
,	O
the	O
gradient	O
of	O
the	O
MAN	B-Method
-	I-Method
AGER	I-Method
module	I-Method
is	O
defined	O
as	O
	
is	O
the	O
expected	O
reward	O
under	O
the	O
current	O
policy	O
which	O
can	O
be	O
approximately	O
estimated	O
via	O
Monte	B-Method
Carlo	I-Method
search	I-Method
	
[	O
reference	O
][	O
reference	O
]	O
.	O
d	O
cos	O
represents	O
the	O
cosine	O
similarity	O
between	O
the	O
change	O
of	O
feature	B-Method
representation	I-Method
after	O
cstep	O
transitions	O
,	O
i.e.	O
f	O
t	O
+	O
c	O
	
−	O
f	O
t	O
,	O
and	O
the	O
goal	O
vector	O
g	O
t	O
(	O
θ	O
m	O
)	O
1	O
produced	O
by	O
MANAGER	B-Method
as	O
in	O
Eq	O
.	O
	
(	O
2	O
)	O
.	O
	
Intuitively	O
,	O
the	O
loss	O
function	O
is	O
to	O
force	O
the	O
goal	O
vector	O
to	O
match	O
the	O
transition	O
in	O
the	O
feature	O
space	O
while	O
achieving	O
high	O
reward	O
.	O
	
At	O
the	O
same	O
time	O
,	O
the	O
WORKER	B-Method
is	O
trained	O
to	O
maximize	O
the	O
reward	O
using	O
the	O
REINFORCE	B-Method
algorithm	I-Method
[	O
reference	O
]	O
as	O
is	O
done	O
in	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
	
We	O
use	O
gt	B-Method
(	I-Method
θm	I-Method
)	O
to	O
explicitly	O
show	O
gt	B-Method
is	O
parameterized	O
by	O
θm	O
.	O
which	O
can	O
be	O
approximated	O
by	O
sampling	O
the	O
state	O
s	O
t−1	O
and	O
the	O
action	O
x	O
t	O
taken	O
by	O
WORKER	B-Method
.	O
	
As	O
the	O
WORKER	B-Method
is	O
encouraged	O
to	O
follow	O
the	O
directions	O
produced	O
by	O
the	O
MANAGER	B-Method
,	O
following	O
[	O
reference	O
]	O
,	O
the	O
intrinsic	O
reward	O
for	O
the	O
WORKER	B-Method
is	O
defined	O
as	O
	
In	O
practice	O
,	O
before	O
the	O
adversarial	B-Method
training	I-Method
,	O
we	O
need	O
to	O
pretrain	O
G	O
θ	O
.	O
	
To	O
be	O
consistent	O
,	O
in	O
the	O
pre	B-Task
-	I-Task
train	I-Task
stage	I-Task
,	O
we	O
also	O
use	O
the	O
separate	O
training	B-Method
scheme	I-Method
,	O
where	O
the	O
gradient	B-Method
of	I-Method
MAN	I-Method
-	I-Method
AGER	I-Method
is	O
	
wheref	O
t	O
	
=	O
F	O
(	O
ŝ	O
t	O
)	O
	
,	O
ŝ	O
t	O
andŝ	O
t	O
+	O
c	O
are	O
states	O
of	O
real	O
text	O
,	O
and	O
the	O
state	O
-	O
action	O
value	O
Q	O
F	O
(	O
s	O
t	O
,	O
g	O
t	O
)	O
in	O
Eq	O
.	O
	
(	O
7	O
)	O
is	O
set	O
as	O
1	O
here	O
since	O
the	O
data	O
instances	O
used	O
in	O
pre	O
-	O
training	O
are	O
all	O
real	O
sentences	O
.	O
	
As	O
such	O
,	O
the	O
MANAGER	B-Method
is	O
trained	O
to	O
mimic	O
the	O
transition	O
of	O
real	O
text	O
samples	O
in	O
the	O
feature	O
space	O
.	O
	
While	O
the	O
WORKER	B-Method
is	O
trained	O
via	O
maximum	B-Method
likelihood	I-Method
estimation	I-Method
(	O
MLE	B-Method
)	O
.	O
	
In	O
the	O
training	B-Task
process	I-Task
,	O
the	O
generator	B-Method
G	O
θ	O
and	O
discriminator	B-Method
D	I-Method
φ	I-Method
are	O
alternatively	O
trained	O
.	O
	
In	O
the	O
generator	B-Method
,	O
the	O
MAN	B-Method
-	I-Method
AGER	I-Method
M	I-Method
(	O
·	O
;	O
θ	O
m	O
)	O
and	O
WORKER	B-Method
W	I-Method
(	O
·	O
;	O
θ	O
w	O
)	O
(	O
including	O
ψ	B-Method
and	O
softmax	B-Method
)	O
are	O
alternatively	O
trained	O
while	O
fixing	O
the	O
other	O
.	O
	
The	O
details	O
of	O
the	O
training	O
procedure	O
are	O
attached	O
in	O
the	O
supplementary	O
material	O
2	O
.	O
	
section	O
:	O
Training	O
Techniques	O
	
Bootstrapped	B-Method
Rescaled	I-Method
Activation	I-Method
.	O
	
During	O
the	O
adversarial	B-Task
training	I-Task
of	O
[	O
reference	O
]	O
,	O
severe	O
gradient	B-Task
vanishing	I-Task
occurs	O
when	O
D	O
is	O
much	O
stronger	O
than	O
G	O
,	O
i.e.	O
the	O
reward	O
is	O
too	O
small	O
value	O
to	O
update	O
the	O
parameters	O
and	O
thus	O
need	O
be	O
rescaled	O
before	O
being	O
fed	O
into	O
G.	O
Inspired	O
by	O
ranking	O
idea	O
from	O
RankGAN	B-Method
[	O
reference	O
]	O
)	O
	
,	O
we	O
propose	O
a	O
simple	O
,	O
time	O
-	O
efficient	O
,	O
rank	B-Method
-	I-Method
based	I-Method
method	I-Method
to	O
rescale	O
the	O
rewards	O
,	O
named	O
as	O
bootstrapped	B-Method
rescaled	I-Method
activation	I-Method
.	O
	
For	O
a	O
mini	O
-	O
batch	O
with	O
B	O
sequences	O
,	O
after	O
the	O
rollout	O
of	O
the	O
generative	B-Method
model	I-Method
,	O
the	O
reward	O
matrix	O
is	O
denoted	O
as	O
R	O
B×T	O
.	O
	
For	O
each	O
timestep	O
t	O
,	O
we	O
rescale	O
the	O
t	O
-	O
th	O
column	O
vector	O
R	O
	
where	O
rank	O
(	O
i	O
)	O
denotes	O
the	O
i	O
-	O
th	O
element	O
's	O
high	O
-	O
to	O
-	O
low	O
ranking	O
in	O
this	O
column	O
vector	O
.	O
	
δ	O
is	O
a	O
hyperparameter	O
that	O
controls	O
the	O
smoothness	O
of	O
the	O
rescale	O
activation	O
.	O
	
σ	O
(	O
·	O
)	O
is	O
an	O
activation	B-Method
function	I-Method
that	O
re	O
-	O
projects	O
the	O
equidifferent	O
scoring	O
based	O
on	O
ranking	B-Task
to	O
a	O
more	O
effective	O
distribution	O
.	O
	
In	O
our	O
experiment	O
,	O
for	O
example	O
,	O
the	O
model	O
adopts	O
hyperparameter	O
δ	O
=	O
12.0	O
and	O
the	O
sigmoid	O
function	O
as	O
σ	O
(	O
·	O
)	O
.	O
	
There	O
are	O
two	O
main	O
advantages	O
of	O
the	O
bootstrapped	B-Method
rescaled	I-Method
activation	I-Method
.	O
	
First	O
,	O
after	O
this	O
transformation	O
,	O
the	O
expectation	O
and	O
variance	O
of	O
the	O
reward	O
in	O
each	O
mini	O
-	O
batch	O
are	O
constant	O
.	O
	
In	O
this	O
case	O
,	O
the	O
rescale	O
activation	O
serves	O
as	O
a	O
value	B-Method
stabilizer	I-Method
that	O
is	O
helpful	O
for	O
algorithms	O
that	O
are	O
sensitive	O
in	O
numerical	O
variance	O
.	O
	
Second	O
,	O
as	O
all	O
ranking	B-Method
methods	I-Method
do	O
,	O
it	O
prevents	O
the	O
gradient	B-Task
vanishing	I-Task
problem	I-Task
,	O
which	O
accelerates	O
the	O
model	B-Task
convergence	I-Task
.	O
	
Interleaved	B-Method
Training	I-Method
.	O
	
In	O
traditional	O
generative	B-Method
adversarial	I-Method
models	I-Method
,	O
mode	B-Task
collapse	I-Task
is	O
a	O
common	O
problem	O
.	O
	
Here	O
we	O
propose	O
a	O
training	B-Method
scheme	I-Method
called	O
interleaved	B-Method
training	I-Method
to	O
alleviate	O
such	O
a	O
problem	O
.	O
	
As	O
its	O
name	O
is	O
,	O
we	O
adopt	O
an	O
interleaving	B-Method
of	I-Method
supervised	I-Method
training	I-Method
(	O
i.e.	B-Method
MLE	I-Method
)	O
and	O
adversarial	B-Method
training	I-Method
(	O
i.e.	O
GAN	B-Method
)	O
instead	O
of	O
full	O
GAN	B-Method
after	O
the	O
pre	B-Method
-	I-Method
training	I-Method
.	O
	
For	O
example	O
,	O
we	O
perform	O
one	O
epoch	O
of	O
supervised	B-Method
learning	I-Method
for	O
G	O
after	O
15	O
epochs	O
of	O
adversarial	B-Method
training	I-Method
.	O
	
An	O
explanation	O
of	O
why	O
this	O
scheme	O
works	O
is	O
that	O
blending	O
these	O
two	O
trainings	O
would	O
help	O
GAN	B-Method
get	O
rid	O
of	O
some	O
bad	O
local	O
minimums	O
and	O
alleviate	O
mode	O
collapse	O
.	O
	
Another	O
justification	O
is	O
that	O
the	O
inserted	O
supervised	B-Method
learning	I-Method
performs	O
an	O
implicit	B-Method
regularization	I-Method
on	O
the	O
generative	B-Method
model	I-Method
to	O
prevent	O
it	O
from	O
going	O
too	O
far	O
away	O
from	O
the	O
MLE	B-Method
solution	I-Method
.	O
	
Temperature	B-Task
Control	I-Task
.	O
	
The	O
Boltzmann	O
temperature	O
α	O
in	O
Eq	O
.	O
	
(	O
6	O
)	O
is	O
a	O
factor	O
that	O
could	O
be	O
used	O
to	O
balance	O
the	O
exploration	B-Task
and	I-Task
exploitation	I-Task
for	O
reinforcement	B-Task
learning	I-Task
problems	I-Task
.	O
	
Here	O
we	O
select	O
a	O
higher	O
temperature	O
when	O
we	O
are	O
training	O
the	O
model	O
and	O
a	O
lower	O
temperature	O
when	O
we	O
adopt	O
the	O
model	O
to	O
generate	O
samples	O
.	O
	
section	O
:	O
Experiment	O
	
The	O
experiment	O
consists	O
of	O
three	O
parts	O
:	O
synthetic	O
data	O
experiments	O
,	O
experiments	O
in	O
real	O
-	O
world	O
scenarios	O
and	O
some	O
explanation	O
study	O
.	O
	
The	O
repeatable	O
experiment	O
code	O
is	O
published	O
for	O
further	O
research	O
3	O
.	O
	
section	O
:	O
Training	O
Settings	O
	
Synthetic	O
Oracle	O
.	O
	
For	O
the	O
synthetic	O
data	O
experiments	O
,	O
simlar	O
to	O
(	O
Yu	O
et	O
al	O
.	O
2017	O
)	O
,	O
we	O
first	O
initialize	O
the	O
parameters	O
of	O
an	O
LSTM	B-Method
following	O
the	O
normal	O
distribution	O
N	O
(	O
0	O
,	O
1	O
)	O
as	O
the	O
oracle	O
describing	O
the	O
real	O
data	O
distribution	O
G	O
oracle	O
(	O
x	O
t	O
|x	O
1	O
,	O
.	O
.	O
.	O
	
,	O
x	O
t−1	O
)	O
.	O
	
We	O
use	O
it	O
to	O
generate	O
10	O
,	O
000	O
sequences	O
of	O
length	O
20	O
and	O
40	O
respectively	O
as	O
the	O
training	O
set	O
S	O
for	O
the	O
generative	B-Method
models	I-Method
.	O
	
GAN	B-Method
Setting	O
.	O
	
For	O
the	O
discriminator	B-Method
,	O
we	O
choose	O
the	O
CNN	B-Method
architecture	I-Method
[	O
reference	O
]	O
as	O
the	O
feature	B-Method
extractor	I-Method
and	O
the	O
binary	B-Method
classifier	I-Method
.	O
	
Note	O
that	O
one	O
could	O
design	O
specific	O
structure	O
for	O
different	O
tasks	O
to	O
refine	O
the	O
CNN	B-Task
performance	O
.	O
	
For	O
the	O
synthetic	O
data	O
experiment	O
,	O
the	O
CNN	O
kernel	O
size	O
ranges	O
from	O
1	O
to	O
T	O
.	O
	
The	O
number	O
of	O
each	O
kernel	O
is	O
between	O
100	O
and	O
200	O
.	O
	
In	O
this	O
case	O
,	O
the	O
feature	O
of	O
text	O
is	O
a	O
1	O
,	O
720	O
dimensional	O
vector	O
.	O
	
Dropout	B-Method
[	O
reference	O
]	O
)	O
with	O
the	O
keep	B-Metric
rate	I-Metric
0.75	I-Metric
and	O
L2	B-Method
regularization	I-Method
are	O
performed	O
to	O
avoid	O
overfitting	O
.	O
	
For	O
the	O
generator	B-Method
,	O
we	O
adopt	O
LSTM	B-Method
[	O
reference	O
]	O
as	O
the	O
architectures	O
of	O
MANAGER	B-Method
and	O
WORKER	B-Method
to	O
capture	O
the	O
sequence	O
context	O
information	O
.	O
	
The	O
MANAGER	B-Method
produces	O
the	O
16	O
-	O
dimensional	O
goal	O
embedding	O
feature	O
vector	O
w	O
t	O
using	O
the	O
feature	O
map	O
extracted	O
by	O
CNN	B-Method
.	O
	
The	O
goal	O
duration	O
time	O
c	O
is	O
a	O
hyperparameter	O
set	O
as	O
4	O
after	O
some	O
preliminary	O
experiments	O
.	O
	
Compared	O
Models	O
.	O
	
For	O
most	O
parts	O
of	O
our	O
experiment	O
,	O
three	O
baseline	O
models	O
are	O
mainly	O
compared	O
with	O
LeakGAN	B-Method
,	O
namely	O
an	O
MLE	B-Method
trained	I-Method
LSTM	I-Method
,	O
[	O
reference	O
]	O
and	O
RankGAN	B-Method
.	O
	
We	O
also	O
compare	O
model	O
3	O
https:	O
//	O
github.com	O
/	O
CR	O
-	O
Gjx	O
/	O
LeakGAN	B-Method
.	O
	
variants	O
,	O
such	O
as	O
SeqGAN	B-Method
with	O
bootstrapped	B-Method
rescaled	I-Method
activation	I-Method
,	O
and	O
include	O
the	O
real	O
data	O
to	O
be	O
referred	O
as	O
the	O
performance	O
upperbound	O
.	O
	
Evaluation	B-Metric
Metrics	I-Metric
.	O
	
Negative	B-Method
log	I-Method
-	I-Method
likehood	I-Method
(	I-Method
NLL	I-Method
)	I-Method
is	O
used	O
for	O
synthetic	O
data	O
experiment	O
since	O
there	O
is	O
the	O
oracle	O
data	O
distribution	O
available	O
for	O
evaluation	O
.	O
	
For	O
real	O
-	O
world	O
data	O
experiments	O
,	O
BLEU	B-Metric
statistics	I-Metric
[	O
reference	O
]	O
and	O
human	B-Metric
rating	I-Metric
scores	I-Metric
in	O
the	O
Turing	B-Metric
test	I-Metric
are	O
reported	O
.	O
	
We	O
further	O
perform	O
a	O
t	B-Metric
-	I-Metric
test	I-Metric
for	O
the	O
improvement	O
of	O
LeakGAN	B-Method
over	O
the	O
second	O
highest	O
performance	O
and	O
report	O
the	O
p	B-Metric
-	I-Metric
value	I-Metric
.	O
	
section	O
:	O
Synthetic	O
Data	O
Experiments	O
	
We	O
run	O
the	O
synthetic	O
data	O
experiment	O
with	O
the	O
text	O
-	O
length	O
set	O
as	O
20	O
and	O
40	O
respectively	O
.	O
	
The	O
training	O
curves	O
are	O
depicted	O
in	O
Figure	O
2	O
and	O
the	O
overall	O
NLL	B-Metric
performance	O
is	O
presented	O
in	O
Table	O
1	O
.	O
	
One	O
could	O
have	O
two	O
observations	O
from	O
the	O
results	O
.	O
	
(	O
i	O
)	O
	
In	O
the	O
pre	B-Task
-	I-Task
training	I-Task
stage	I-Task
,	O
LeakGAN	B-Method
has	O
already	O
shown	O
observable	O
performance	O
superiority	O
compared	O
to	O
other	O
models	O
,	O
which	O
indicates	O
that	O
the	O
proposed	O
hierarchical	B-Method
architecture	I-Method
itself	O
brings	O
improvement	O
over	O
the	O
previous	O
ones	O
.	O
	
(	O
ii	O
)	O
	
In	O
the	O
adversarial	B-Task
training	I-Task
stage	I-Task
,	O
LeakGAN	B-Method
shows	O
a	O
better	O
speed	O
of	O
convergence	B-Metric
,	O
and	O
the	O
local	O
minimum	O
it	O
explores	O
is	O
significantly	O
better	O
than	O
previous	O
results	O
.	O
	
The	O
results	O
demonstrate	O
the	O
effectiveness	O
of	O
the	O
information	B-Method
leakage	I-Method
framework	I-Method
and	O
the	O
hierarchical	B-Method
RL	I-Method
architecture	I-Method
for	O
generating	O
both	O
short	O
and	O
long	O
texts	O
.	O
	
section	O
:	O
Long	B-Task
Text	I-Task
Generation	I-Task
:	O
EMNLP2017	B-Material
WMT	I-Material
News	I-Material
	
We	O
choose	O
the	O
EMNLP2017	B-Material
WMT	I-Material
4	I-Material
Dataset	I-Material
as	O
the	O
long	O
text	O
corpus	O
.	O
	
Specifically	O
,	O
we	O
pick	O
the	O
News	O
section	O
from	O
the	O
original	O
dataset	O
.	O
	
The	O
news	O
dataset	O
consists	O
of	O
646	O
,	O
459	O
words	O
and	O
397	O
,	O
726	O
sentences	O
.	O
	
We	O
preprocess	O
the	O
data	O
by	O
eliminating	O
the	O
words	O
with	O
frequency	O
lower	O
than	O
4	O
,	O
050	O
as	O
well	O
as	O
the	O
sentence	O
containing	O
these	O
low	O
frequency	O
words	O
.	O
	
Besides	O
,	O
to	O
focus	O
on	O
long	O
sentences	O
,	O
we	O
remove	O
the	O
sentences	O
with	O
length	O
less	O
than	O
20	O
.	O
	
After	O
the	O
preprocessing	O
,	O
the	O
news	O
dataset	O
has	O
5	O
,	O
742	O
words	O
and	O
397	O
,	O
726	O
sentences	O
.	O
	
Then	O
we	O
randomly	O
sample	O
200	O
,	O
000	O
sentences	O
as	O
the	O
training	O
set	O
and	O
another	O
10	O
,	O
000	O
sentences	O
as	O
the	O
test	O
set	O
.	O
	
We	O
use	O
the	O
BLEU	B-Metric
-(	I-Metric
2	I-Metric
to	I-Metric
5	I-Metric
)	I-Metric
scores	O
[	O
reference	O
]	O
as	O
the	O
evaluation	B-Metric
metrics	I-Metric
.	O
	
The	O
results	O
are	O
provided	O
in	O
Table	O
2	O
.	O
	
In	O
all	O
measured	O
metrics	B-Metric
,	O
LeakGAN	B-Method
shows	O
significant	O
performance	O
gain	O
compared	O
to	O
baseline	O
models	O
.	O
	
The	O
consistently	O
higher	O
BLEU	B-Metric
scores	I-Metric
indicate	O
that	O
the	O
generated	O
sentences	O
of	O
LeakGAN	B-Method
are	O
of	O
high	O
quality	O
in	O
local	O
features	O
to	O
mimic	O
the	O
real	O
text	O
.	O
	
section	O
:	O
Middle	B-Task
Text	I-Task
Generation	I-Task
:	O
COCO	B-Material
Image	I-Material
Captions	I-Material
	
Another	O
real	O
dataset	O
we	O
use	O
is	O
the	O
COCO	B-Material
Image	I-Material
Captions	I-Material
Dataset	I-Material
[	O
reference	O
]	O
,	O
a	O
dataset	O
which	O
contains	O
groups	O
of	O
image	O
-	O
description	O
pairs	O
.	O
	
We	O
take	O
the	O
image	O
captions	O
as	O
the	O
text	O
to	O
generate	O
.	O
	
Note	O
that	O
the	O
COCO	B-Material
Dataset	I-Material
is	O
not	O
a	O
long	O
text	O
dataset	O
,	O
in	O
which	O
most	O
sentences	O
are	O
of	O
about	O
10	O
words	O
.	O
	
Thus	O
we	O
apply	O
some	O
preprocessing	O
on	O
the	O
dataset	O
.	O
	
The	O
COCO	B-Material
Image	I-Material
Captions	I-Material
training	I-Material
dataset	I-Material
consists	O
of	O
20	O
,	O
734	O
words	O
and	O
417	O
,	O
126	O
sentences	O
.	O
	
We	O
remove	O
the	O
words	O
with	O
frequency	O
lower	O
than	O
10	O
as	O
well	O
as	O
the	O
sentence	O
containing	O
them	O
.	O
	
After	O
the	O
preprocessing	O
,	O
the	O
dataset	O
includes	O
4	O
,	O
980	O
words	O
.	O
	
We	O
randomly	O
sample	O
80	O
,	O
000	O
sentences	O
for	O
the	O
training	O
set	O
,	O
and	O
another	O
5	O
,	O
000	O
for	O
the	O
test	O
set	O
.	O
	
The	O
results	O
BLEU	B-Metric
scores	I-Metric
are	O
provided	O
in	O
Table	O
3	O
.	O
	
The	O
results	O
of	O
the	O
BLEU	B-Metric
scores	I-Metric
on	O
the	O
COCO	B-Material
dataset	I-Material
indicate	O
that	O
LeakGAN	B-Method
performs	O
significantly	O
better	O
than	O
baseline	O
models	O
in	O
mid	O
-	O
length	O
text	O
generation	B-Task
task	O
.	O
	
section	O
:	O
Short	B-Task
Text	I-Task
Generation	I-Task
:	O
Chinese	B-Material
Poems	I-Material
	
To	O
evaluate	O
the	O
performance	O
of	O
LeakGAN	B-Method
in	O
short	O
text	O
generation	B-Task
,	O
we	O
pick	O
the	O
dataset	O
of	O
Chinese	B-Material
poems	I-Material
which	O
is	O
proposed	O
by	O
[	O
reference	O
]	O
and	O
most	O
related	O
work	O
such	O
as	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
)	O
.	O
	
The	O
dataset	O
consists	O
of	O
4	B-Material
-	I-Material
line	I-Material
5	I-Material
-	I-Material
character	I-Material
poems	I-Material
.	O
	
Following	O
the	O
above	O
work	O
,	O
we	O
use	O
the	O
BLEU	B-Metric
-	I-Metric
2	I-Metric
scores	I-Metric
as	O
the	O
evaluating	B-Metric
metrics	I-Metric
.	O
	
The	O
experimental	O
results	O
are	O
provided	O
in	O
Table	O
4	O
.	O
	
The	O
results	O
on	O
Chinese	B-Material
Poems	I-Material
indicate	O
that	O
LeakGAN	B-Method
successfully	O
handles	O
the	O
short	O
text	O
generation	B-Task
tasks	O
.	O
	
Figure	O
3	O
:	O
	
The	O
illustration	O
of	O
BLEU	B-Metric
improvement	I-Metric
change	O
along	O
with	O
the	O
generated	O
text	O
length	O
on	O
WMT	B-Material
News	I-Material
.	O
	
section	O
:	O
Performance	O
Robustness	B-Metric
in	O
Long	B-Task
Text	I-Task
Generation	I-Task
	
Long	O
text	O
generation	B-Task
has	O
always	O
been	O
difficult	O
among	O
all	O
text	O
generation	B-Task
problems	O
.	O
	
The	O
difficulty	O
of	O
the	O
problem	O
is	O
due	O
to	O
many	O
factors	O
,	O
such	O
as	O
LSTM	B-Method
-	I-Method
RNN	I-Method
's	O
failure	O
to	O
capture	O
longterm	O
dependency	O
,	O
discriminator	O
's	O
failure	O
to	O
give	O
those	O
"	O
good	O
but	O
tiny	O
"	O
sequences	O
appropriate	O
penalty	O
.	O
	
To	O
explicitly	O
evaluate	O
the	O
superiority	O
of	O
LeakGAN	B-Method
in	O
long	O
text	O
generation	B-Task
,	O
here	O
we	O
use	O
the	O
relative	O
performance	O
gain	O
of	O
LeakGAN	B-Method
over	O
[	O
reference	O
]	O
and	O
RankGAN	B-Method
	
[	O
reference	O
]	O
.	O
	
The	O
results	O
over	O
EMNLP2017	B-Material
WMT	I-Material
News	I-Material
data	O
are	O
shown	O
in	O
Figure	O
3	O
.	O
	
The	O
curves	O
clearly	O
show	O
that	O
LeakGAN	B-Method
yields	O
larger	O
performance	O
gain	O
over	O
the	O
baselines	O
when	O
the	O
generated	O
sentences	O
are	O
longer	O
.	O
	
This	O
fact	O
supports	O
our	O
claim	O
that	O
LeakGAN	B-Method
is	O
a	O
robust	O
framework	O
for	O
long	B-Task
text	I-Task
.	O
	
section	O
:	O
Turing	B-Task
Test	I-Task
and	O
Generated	O
Samples	O
	
Since	O
BLEU	B-Metric
score	I-Metric
is	O
a	O
metric	O
focusing	O
on	O
the	O
local	O
text	O
statistics	O
,	O
which	O
may	O
not	O
be	O
sufficient	O
for	O
evaluating	O
text	O
generation	B-Task
quality	O
,	O
we	O
also	O
conduct	O
a	O
Turing	B-Method
test	I-Method
based	O
on	O
questionnaires	O
on	O
the	O
Internet	O
.	O
	
In	O
the	O
questionnaire	O
,	O
each	O
(	O
machine	O
generated	O
or	O
real	O
)	O
sentence	O
gets	O
+	O
1	O
score	O
when	O
it	O
is	O
regarded	O
as	O
a	O
real	O
one	O
,	O
and	O
0	O
score	O
otherwise	O
.	O
	
We	O
conduct	O
the	O
test	O
with	O
text	O
generated	O
by	O
the	O
models	O
trained	O
on	O
WMT	B-Material
News	I-Material
and	O
COCO	B-Material
Image	I-Material
Captions	I-Material
.	O
	
The	O
average	O
score	O
for	O
each	O
algorithm	O
is	O
calculated	O
.	O
	
In	O
practice	O
,	O
we	O
sample	O
20	O
sentences	O
from	O
every	O
method	O
and	O
invite	O
62	O
people	O
to	O
participate	O
the	O
test	O
,	O
where	O
everyone	O
should	O
judge	O
the	O
quality	O
of	O
30	O
sentences	O
from	O
the	O
compared	O
three	O
methods	O
and	O
thus	O
each	O
sentence	O
is	O
judged	O
by	O
31	O
people	O
.	O
	
For	O
the	O
comparison	O
fairness	O
,	O
the	O
sentences	O
used	O
in	O
the	O
questionnaires	O
are	O
randomly	O
sampled	O
.	O
	
Table	O
5	O
gives	O
the	O
results	O
.	O
	
The	O
performance	O
on	O
two	O
datasets	O
indicates	O
that	O
the	O
generated	O
sentences	O
of	O
LeakGAN	B-Method
are	O
of	O
higher	O
global	B-Metric
consistency	I-Metric
and	O
better	O
readability	B-Metric
than	O
those	O
of	O
SeqGAN	B-Method
.	O
	
A	O
few	O
samples	O
generated	O
by	O
LeakGAN	B-Method
are	O
illustrated	O
in	O
Table	O
6	O
.	O
	
More	O
samples	O
and	O
their	O
comparison	O
with	O
those	O
from	O
(	O
1	O
)	O
A	O
bathroom	O
with	O
tiled	O
walls	O
and	O
a	O
shower	O
on	O
it	O
.	O
	
(	O
2	O
)	O
	
A	O
young	O
man	O
is	O
holding	O
a	O
bottle	O
of	O
wine	O
in	O
his	O
hand	O
.	O
	
(	O
2	O
)	O
A	O
couple	O
of	O
kids	O
in	O
front	O
of	O
a	O
bathroom	O
that	O
is	O
in	O
a	O
bathroom	O
.	O
	
EMNLP2017	B-Material
	
WMT	B-Method
(	O
1	O
)	O
	
The	O
American	O
Medical	O
Association	O
said	O
that	O
the	O
militants	O
had	O
been	O
arrested	O
in	O
connection	O
with	O
the	O
murder	O
of	O
the	O
same	O
incident	O
.	O
	
(	O
1	O
)	O
	
"	O
	
I	O
think	O
you	O
should	O
really	O
really	O
leave	O
for	O
because	O
we	O
had	O
n't	O
been	O
busy	O
,	O
where	O
it	O
goes	O
to	O
one	O
,	O
"	O
he	O
wrote	O
.	O
	
(	O
2	O
)	O
	
This	O
is	O
the	O
first	O
time	O
that	O
the	O
Fed	O
has	O
been	O
able	O
to	O
launch	O
a	O
probe	O
into	O
the	O
country	O
'	O
s	O
nuclear	O
program	O
.	O
	
(	O
2	O
)	O
What	O
you	O
have	O
to	O
stop	O
,	O
if	O
we	O
do	O
that	O
,	O
as	O
late	O
,	O
law	O
enforcement	O
and	O
where	O
schools	O
use	O
a	O
list	O
of	O
aid	O
,	O
it	O
can	O
rise	O
.	O
	
section	O
:	O
Model	O
Explanation	O
	
Feature	O
Trace	O
.	O
	
To	O
verify	O
that	O
LeakGAN	B-Method
successfully	O
exploits	O
of	O
the	O
leaked	O
message	O
,	O
we	O
visualize	O
the	O
feature	O
vector	O
f	O
T	O
extracted	O
from	O
the	O
real	O
data	O
by	O
discriminator	B-Method
.	O
	
Besides	O
,	O
we	O
visualize	O
the	O
feature	O
trace	O
,	O
i.e.	O
the	O
features	O
f	O
t	O
of	O
prefix	O
s	O
t	O
during	O
the	O
generation	B-Task
,	O
for	O
LeakGAN	B-Method
,	O
SeqGAN	B-Method
and	O
RankGAN	B-Method
via	O
a	O
2	B-Method
-	I-Method
D	I-Method
principal	I-Method
component	I-Method
analysis	I-Method
(	O
PCA	B-Method
)	O
.	O
	
The	O
visualized	O
traces	O
are	O
plotted	O
in	O
Figure	O
4	O
and	O
more	O
cases	O
are	O
presented	O
in	O
the	O
supplementary	O
material	O
.	O
	
As	O
we	O
can	O
see	O
,	O
during	O
the	O
generation	B-Method
process	I-Method
,	O
in	O
LeakGAN	B-Method
,	O
the	O
feature	O
vector	O
gradually	O
approaches	O
the	O
real	O
data	O
feature	O
vector	O
region	O
.	O
	
However	O
,	O
previous	O
models	O
,	O
i.e.	O
SeqGAN	B-Method
and	O
RankGAN	B-Method
,	O
fail	O
to	O
match	O
the	O
features	O
even	O
when	O
the	O
generation	B-Task
is	O
completed	O
.	O
	
This	O
indicates	O
that	O
the	O
proposed	O
Leak	O
-	O
GAN	B-Method
does	O
finish	O
its	O
design	O
purpose	O
of	O
exploiting	O
the	O
leaked	O
information	O
from	O
D	O
φ	O
to	O
better	O
match	O
the	O
feature	O
vector	O
distributions	O
of	O
real	O
data	O
.	O
	
Behaviors	O
of	O
Worker	O
and	O
Manager	O
.	O
	
To	O
give	O
more	O
details	O
of	O
how	O
WORKER	B-Method
and	O
MANAGER	B-Method
interact	O
with	O
each	O
other	O
and	O
make	O
use	O
of	O
the	O
leaked	O
information	O
in	O
the	O
generative	B-Method
model	I-Method
,	O
we	O
visualize	O
the	O
interaction	O
vector	O
of	O
the	O
WORKER	B-Method
and	O
MANAGER	B-Method
,	O
i.e.	O
,	O
the	O
dimension	O
-	O
wise	O
product	O
of	O
their	O
output	O
(	O
O	O
t	O
·	O
w	O
t	O
as	O
in	O
Eq	O
.	O
	
(	O
6	O
)	O
)	O
.	O
	
Note	O
that	O
to	O
simplify	O
the	O
explanation	O
,	O
here	O
we	O
reduce	O
the	O
signal	O
dimension	O
from	O
16	O
to	O
8	O
.	O
	
Figure	O
5	O
presents	O
an	O
example	O
sentence	O
and	O
more	O
cases	O
are	O
provided	O
in	O
the	O
supplementary	O
material	O
.	O
	
From	O
Figure	O
5	O
,	O
we	O
find	O
some	O
intuitive	O
interpretations	O
of	O
the	O
implicit	O
rules	O
learned	O
by	O
the	O
interaction	O
of	O
WORKER	B-Method
and	O
MANAGER	B-Method
.	O
	
(	O
i	O
)	O
	
The	O
5th	O
dimension	O
stands	O
for	O
current	O
token	O
's	O
divergence	O
from	O
an	O
entity	O
token	O
.	O
	
If	O
the	O
5th	O
value	O
is	O
high	O
,	O
the	O
token	O
would	O
most	O
possibly	O
be	O
a	O
structural	O
token	O
,	O
such	O
as	O
a	O
modal	O
verb	O
,	O
an	O
article	O
or	O
a	O
preposition	O
.	O
	
(	O
ii	O
)	O
	
The	O
6th	O
dimension	O
suggests	O
how	O
long	O
the	O
suffix	O
from	O
current	O
step	O
will	O
be	O
.	O
	
If	O
a	O
peak	O
occurs	O
in	O
the	O
curve	O
,	O
there	O
must	O
be	O
some	O
token	O
that	O
triggers	O
a	O
long	O
suffix	O
.	O
	
A	O
frequently	O
occurring	O
example	O
is	O
the	O
formal	O
subject	O
.	O
	
(	O
iii	O
)	O
	
Although	O
hard	O
to	O
observe	O
,	O
we	O
do	O
find	O
connections	O
of	O
the	O
7th	O
dimension	O
and	O
the	O
substructure	O
of	O
a	O
sentence	O
.	O
	
For	O
example	O
,	O
when	O
the	O
start	O
or	O
the	O
end	O
of	O
a	O
subsentence	O
occurs	O
,	O
there	O
is	O
an	O
observable	O
fluctuation	O
in	O
the	O
7th	O
dimension	O
.	O
	
This	O
indicates	O
that	O
the	O
token	O
is	O
most	O
likely	O
to	O
be	O
a	O
punctuation	O
or	O
a	O
conjuction	O
.	O
	
section	O
:	O
Conclusion	O
and	O
Future	O
work	O
	
In	O
this	O
paper	O
,	O
we	O
proposed	O
a	O
new	O
algorithmic	B-Method
framework	I-Method
called	O
LeakGAN	B-Method
for	O
generating	B-Task
long	I-Task
text	I-Task
via	O
adversarial	B-Task
training	I-Task
.	O
	
By	O
leaking	O
the	O
feature	O
extracted	O
by	O
the	O
discriminator	B-Method
as	O
the	O
step	O
-	O
by	O
-	O
step	O
guiding	O
signal	O
to	O
guide	O
the	O
generator	B-Method
better	O
generating	B-Task
long	I-Task
text	I-Task
,	O
LeakGAN	B-Method
addresses	O
the	O
non	B-Task
-	I-Task
informativeness	I-Task
and	I-Task
sparsity	I-Task
problems	I-Task
of	O
the	O
scalar	O
reward	O
signal	O
in	O
previous	O
GAN	B-Method
solutions	O
.	O
	
In	O
the	O
extensive	O
experiments	O
with	O
synthetic	O
data	O
and	O
real	O
world	O
data	O
including	O
long	O
,	O
mid	O
-	O
length	O
and	O
short	O
text	O
,	O
LeakGAN	B-Method
achieved	O
significant	O
performance	O
improvement	O
over	O
previous	O
solutions	O
,	O
on	O
both	O
BLEU	B-Metric
scores	I-Metric
and	O
human	B-Metric
ratings	I-Metric
.	O
	
Moreover	O
,	O
the	O
analysis	O
of	O
the	O
results	O
shows	O
that	O
LeakGAN	B-Method
yields	O
larger	O
performance	O
gain	O
when	O
the	O
longer	O
sentences	O
are	O
generated	O
.	O
	
Finally	O
,	O
we	O
also	O
visualize	O
and	O
explain	O
the	O
efficacy	O
of	O
the	O
guiding	O
signals	O
that	O
LeakGAN	B-Method
learns	O
without	O
any	O
supervision	O
.	O
	
For	O
future	O
work	O
,	O
we	O
plan	O
to	O
apply	O
LeakGAN	B-Method
in	O
more	O
natural	B-Task
language	I-Task
process	I-Task
applications	I-Task
like	O
dialogue	B-Task
systems	I-Task
and	O
image	B-Task
captioning	I-Task
by	O
providing	O
more	O
task	O
-	O
specific	O
guiding	O
information	O
.	O
	
Also	O
,	O
enhancing	O
the	O
capacity	O
of	O
the	O
discriminator	B-Method
to	O
check	O
the	O
global	O
consistency	O
of	O
the	O
whole	O
sentence	O
is	O
a	O
promising	O
direction	O
.	O
	
section	O
:	O
Experiment	O
Settings	O
	
For	O
synthetic	O
data	O
with	O
length	O
20	O
,	O
the	O
learning	B-Metric
rate	I-Metric
for	O
MANAGER	B-Method
and	O
WORKER	B-Method
is	O
set	O
to	O
0.001	O
.	O
	
The	O
goal	O
dimension	O
size	O
k	O
is	O
set	O
to	O
16	O
.	O
	
The	O
embedding	B-Metric
size	I-Metric
of	O
the	O
LSTM	B-Method
-	I-Method
RNNs	I-Method
is	O
set	O
to	O
32	O
.	O
	
For	O
the	O
discriminative	B-Method
model	I-Method
,	O
we	O
set	O
the	O
hyperparameters	O
of	O
the	O
CNN	B-Method
as	O
Table	O
1	O
For	O
synthetic	O
data	O
with	O
length	O
40	O
,	O
the	O
learning	B-Metric
rate	I-Metric
for	O
MANAGER	B-Method
and	O
WORKER	B-Method
is	O
set	O
to	O
0.0005	O
.	O
	
The	O
goal	O
dimension	O
size	O
k	O
is	O
set	O
to	O
16	O
.	O
	
The	O
embedding	B-Metric
size	I-Metric
of	O
the	O
LSTM	B-Method
-	I-Method
RNNs	I-Method
is	O
set	O
to	O
32	O
.	O
	
For	O
the	O
discriminative	B-Method
model	I-Method
,	O
we	O
set	O
the	O
hyperparameters	O
of	O
the	O
CNN	B-Method
as	O
Table	O
1	O
Table	O
1	O
:	O
Convolutional	O
layer	O
structures	O
.	O
	
section	O
:	O
Discussions	O
	
The	O
Necessity	O
of	O
the	O
Hierarchical	B-Method
Architecture	I-Method
	
The	O
hierarchical	B-Method
architecture	I-Method
in	O
LeakGAN	B-Method
serves	O
as	O
the	O
mechanism	O
of	O
incorporating	O
leaked	O
information	O
from	O
D	O
into	O
G.	O
However	O
,	O
in	O
the	O
body	O
part	O
,	O
we	O
have	O
n't	O
shown	O
whether	O
the	O
explotation	O
of	O
hierachical	B-Method
architecture	I-Method
is	O
a	O
must	O
.	O
	
Actually	O
,	O
what	O
we	O
have	O
to	O
point	O
out	O
is	O
,	O
the	O
explotation	O
of	O
hierarchical	B-Method
reinforment	I-Method
learning	I-Method
is	O
not	O
a	O
must	O
,	O
but	O
a	O
good	O
choice	O
in	O
sequence	B-Task
decision	I-Task
scenarios	I-Task
.	O
	
We	O
attempt	O
to	O
replace	O
the	O
hierarchical	B-Method
architecture	I-Method
by	O
a	O
fully	B-Method
connected	I-Method
layer	I-Method
.	O
	
However	O
,	O
the	O
model	O
is	O
so	O
numerically	O
sensitive	O
that	O
we	O
can	O
not	O
operate	O
a	O
stable	O
training	O
on	O
it	O
the	O
original	O
training	O
settings	O
.	O
	
A	O
possible	O
reason	O
is	O
that	O
,	O
since	O
the	O
feature	O
space	O
of	O
CNN	O
changes	O
rapidly	O
during	O
the	O
training	B-Method
procedure	I-Method
,	O
linear	B-Method
transformation	I-Method
without	O
any	O
normalization	B-Method
may	O
not	O
be	O
able	O
to	O
incorporate	O
the	O
information	O
contained	O
in	O
the	O
feature	O
vector	O
leaked	O
from	O
D.	O
	
Here	O
we	O
present	O
more	O
examples	O
for	O
illustrating	O
the	O
interaction	O
of	O
WORKER	B-Method
and	O
MANAGER	B-Method
to	O
support	O
our	O
claims	O
in	O
the	O
main	O
text	O
as	O
below	O
.	O
	
Each	O
curve	O
shows	O
a	O
subscore	O
of	O
the	O
token	O
of	O
that	O
time	O
step	O
.	O
	
Each	O
dimension	O
of	O
the	O
score	O
,	O
i.e.	O
each	O
subscore	O
measures	O
a	O
specific	O
feature	O
of	O
the	O
token	O
in	O
that	O
context	O
.	O
	
section	O
:	O
Illustration	O
of	O
WORKER	B-Method
and	O
MANAGER	B-Method
's	I-Method
Behaviors	I-Method
	
(	O
i	O
)	O
	
The	O
5th	O
dimension	O
stands	O
for	O
current	O
token	O
's	O
divergence	O
from	O
an	O
entity	O
token	O
.	O
	
If	O
the	O
5th	O
value	O
is	O
high	O
,	O
the	O
token	O
would	O
most	O
possibly	O
be	O
a	O
structural	O
token	O
,	O
such	O
as	O
a	O
modal	O
verb	O
,	O
an	O
article	O
or	O
a	O
preposition	O
.	O
	
(	O
ii	O
)	O
	
The	O
6th	O
dimension	O
suggests	O
how	O
long	O
the	O
suffix	O
from	O
current	O
step	O
will	O
be	O
.	O
	
If	O
a	O
peak	O
occurs	O
in	O
the	O
curve	O
,	O
there	O
must	O
be	O
some	O
token	O
that	O
triggers	O
a	O
long	O
suffix	O
.	O
	
A	O
frequently	O
occurring	O
example	O
is	O
the	O
formal	O
subject	O
.	O
	
(	O
iii	O
)	O
	
Although	O
hard	O
to	O
observe	O
,	O
we	O
do	O
find	O
connections	O
of	O
the	O
7th	O
dimension	O
and	O
the	O
substructure	O
of	O
a	O
sentence	O
.	O
	
For	O
example	O
,	O
when	O
the	O
start	O
or	O
end	O
of	O
a	O
sub	O
-	O
sentence	O
occurs	O
,	O
there	O
is	O
an	O
observable	O
fluctuation	O
in	O
the	O
7th	O
dimension	O
.	O
	
This	O
indicates	O
that	O
the	O
token	O
is	O
most	O
likely	O
to	O
be	O
a	O
punctuation	O
or	O
a	O
conjuction	O
.	O
	
As	O
we	O
can	O
see	O
,	O
during	O
the	O
generation	B-Method
process	I-Method
,	O
in	O
LeakGAN	B-Method
,	O
the	O
feature	O
vector	O
gradually	O
approaches	O
the	O
real	O
data	O
feature	O
vector	O
region	O
.	O
	
However	O
,	O
previous	O
models	O
,	O
i.e.	O
SeqGAN	B-Method
and	O
RankGAN	B-Method
,	O
fail	O
to	O
match	O
the	O
features	O
even	O
when	O
the	O
generation	B-Task
is	O
completed	O
.	O
	
This	O
indicates	O
that	O
the	O
proposed	O
LeakGAN	B-Method
does	O
finish	O
its	O
designed	O
purpose	O
of	O
exploiting	O
the	O
leaked	O
information	O
from	O
D	O
φ	O
to	O
better	O
match	O
the	O
feature	O
vector	O
distributions	O
of	O
real	O
data	O
.	O
	
A	O
man	O
wearing	O
a	O
suit	O
and	O
coat	O
holds	O
a	O
tie	O
through	O
and	O
wood	O
pants	O
.	O
	
Two	O
men	O
are	O
working	O
on	O
a	O
laptop	O
in	O
a	O
room	O
.	O
	
A	O
man	O
who	O
is	O
standing	O
next	O
to	O
a	O
brown	O
and	O
white	O
horse	O
.	O
	
A	O
street	O
sign	O
with	O
a	O
red	O
stop	O
sign	O
on	O
the	O
street	O
pole	O
.	O
	
A	O
cat	O
is	O
laying	O
on	O
a	O
keyboard	O
and	O
mouse	O
in	O
the	O
air	O
.	O
	
A	O
man	O
with	O
a	O
rainbow	O
-	O
colored	O
shirt	O
and	O
a	O
black	O
dog	O
.	O
	
A	O
crowd	O
of	O
people	O
standing	O
around	O
or	O
standing	O
on	O
a	O
sidewalk	O
.	O
	
A	O
man	O
is	O
sitting	O
on	O
his	O
desk	O
holding	O
an	O
umbrella	O
.	O
	
SeqGAN	O
A	O
woman	O
is	O
riding	O
a	O
bike	O
on	O
the	O
street	O
next	O
to	O
a	O
bus	O
.	O
	
section	O
:	O
Illustration	O
of	O
Feature	O
Trace	O
	
A	O
silver	O
stove	O
,	O
the	O
refrigerator	O
,	O
sitting	O
in	O
a	O
kitchen	O
.	O
	
A	O
guy	O
doing	O
tricks	O
on	O
a	O
skateboard	O
while	O
a	O
man	O
is	O
standing	O
on	O
a	O
cellphone	O
.	O
	
A	O
bunch	O
of	O
birds	O
that	O
are	O
sitting	O
in	O
the	O
sand	O
.	O
	
A	O
bathroom	O
with	O
tiled	O
walls	O
and	O
a	O
shower	O
on	O
it	O
.	O
	
A	O
couple	O
of	O
people	O
are	O
riding	O
bikes	O
down	O
an	O
asphalt	O
road	O
.	O
	
An	O
old	O
photo	O
of	O
a	O
man	O
riding	O
on	O
a	O
motorcycle	O
with	O
some	O
people	O
.	O
	
A	O
beautiful	O
young	O
girl	O
in	O
the	O
bathroom	O
has	O
one	O
has	O
wine	O
glasses	O
and	O
bottles	O
above	O
the	O
counters	O
.	O
	
A	O
person	O
in	O
a	O
helmet	O
standing	O
next	O
to	O
a	O
red	O
street	O
.	O
	
An	O
empty	O
clean	O
bathroom	O
with	O
a	O
toilet	O
and	O
sink	O
and	O
tub	O
.	O
	
A	O
kid	O
in	O
a	O
black	O
shirt	O
and	O
dog	O
arms	O
in	O
a	O
restaurant	O
kitchen	O
.	O
	
A	O
bathroom	O
has	O
a	O
toilet	O
,	O
a	O
sink	O
and	O
mirror	O
.	O
	
Two	O
bicycles	O
are	O
parked	O
outside	O
inside	O
a	O
small	O
brown	O
field	O
.	O
	
The	O
large	O
rug	O
is	O
on	O
the	O
city	O
under	O
the	O
city	O
.	O
	
A	O
bathroom	O
that	O
is	O
has	O
a	O
picture	O
above	O
and	O
a	O
sink	O
.	O
	
A	O
small	O
child	O
jumping	O
with	O
glasses	O
to	O
a	O
motor	O
scooter	O
.	O
	
A	O
white	O
bathroom	O
with	O
a	O
toilet	O
,	O
television	O
and	O
bathtub	O
and	O
a	O
sink	O
.	O
	
A	O
baby	O
in	O
a	O
blue	O
dress	O
standing	O
in	O
front	O
of	O
a	O
Frisbee	O
.	O
	
A	O
cat	O
and	O
a	O
woman	O
standing	O
by	O
two	O
computer	O
preparing	O
food	O
.	O
	
A	O
pair	O
of	O
skis	O
and	O
pedestrians	O
in	O
a	O
parking	O
area	O
near	O
some	O
different	O
go	O
.	O
	
Two	O
bikes	O
in	O
a	O
parking	O
lot	O
with	O
a	O
dog	O
that	O
has	O
a	O
back	O
on	O
her	O
.	O
	
Out	O
of	O
those	O
who	O
came	O
last	O
year	O
,	O
69	O
per	O
cent	O
were	O
men	O
,	O
18	O
per	O
cent	O
were	O
children	O
and	O
just	O
13	O
per	O
cent	O
were	O
women	O
.	O
'	O
	
Sometimes	O
I	O
think	O
about	O
leaving	O
sex	O
work	O
,	O
but	O
because	O
I	O
am	O
alone	O
living	O
costs	O
are	O
really	O
expensive	O
,	O
'	O
she	O
said	O
.	O
'	O
	
I	O
was	O
then	O
stuck	O
in	O
the	O
house	O
for	O
nearly	O
two	O
years	O
only	O
going	O
out	O
for	O
short	O
periods	O
of	O
time	O
,	O
'	O
she	O
said	O
.	O
	
He	O
has	O
not	O
played	O
for	O
Tottenham	O
's	O
first	O
team	O
since	O
and	O
it	O
is	O
now	O
nearly	O
two	O
years	O
since	O
he	O
completed	O
a	O
full	O
Premier	O
League	O
match	O
for	O
the	O
club	O
.	O
	
This	O
is	O
a	O
part	O
of	O
the	O
population	O
that	O
is	O
notorious	O
for	O
its	O
lack	O
of	O
interest	O
in	O
actually	O
showing	O
up	O
when	O
the	O
political	O
process	O
takes	O
place	O
.	O
	
I	O
was	O
paid	O
far	O
too	O
little	O
to	O
pick	O
up	O
a	O
dead	O
off	O
of	O
the	O
ground	O
and	O
put	O
it	O
back	O
in	O
the	O
box	O
.	O
	
Local	O
media	O
reported	O
the	O
group	O
were	O
not	O
looking	O
to	O
hurt	O
anybody	O
,	O
but	O
they	O
would	O
not	O
rule	O
out	O
violence	O
if	O
police	O
tried	O
to	O
remove	O
them	O
.	O
	
The	O
55	O
to	O
43	O
vote	O
was	O
largely	O
split	O
down	O
party	O
lines	O
and	O
fell	O
short	O
of	O
the	O
60	O
votes	O
needed	O
for	O
the	O
bill	O
to	O
advance	O
.	O
	
We	O
got	O
to	O
a	O
bus	O
station	O
in	O
the	O
evening	O
,	O
but	O
our	O
connection	O
did	O
n't	O
leave	O
until	O
the	O
following	O
morning	O
.	O
	
It	O
's	O
actually	O
something	O
that	O
I	O
had	O
to	O
add	O
,	O
because	O
I	O
was	O
getting	O
really	O
frustrated	O
losing	O
to	O
my	O
hitting	O
partner	O
all	O
the	O
time	O
.	O
	
Taiwan	O
's	O
Defence	O
Ministry	O
said	O
it	O
was	O
"	O
aware	O
of	O
the	O
information	O
,	O
"	O
and	O
declined	O
further	O
immediate	O
comment	O
,	O
Reuters	O
reported	O
.	O
	
Her	O
response	O
to	O
the	O
international	O
refugee	O
crisis	O
gave	O
a	O
million	O
refugees	O
hope	O
that	O
they	O
may	O
be	O
able	O
to	O
begin	O
a	O
new	O
life	O
.	O
	
I	O
'	O
m	O
racing	O
against	O
a	O
guy	O
who	O
I	O
lost	O
a	O
medal	O
to	O
-	O
but	O
am	O
I	O
ever	O
going	O
to	O
get	O
that	O
medal	O
back	O
?	O
	
LeakGAN	B-Method
	
A	O
man	O
has	O
been	O
arrested	O
at	O
age	O
28	O
,	O
a	O
resident	O
in	O
Seattle	O
,	O
which	O
was	O
widely	O
reported	O
in	O
2007	O
.	O
	
I	O
also	O
think	O
that	O
'	O
s	O
a	O
good	O
place	O
for	O
us	O
,	O
	
I	O
'	O
m	O
sure	O
that	O
this	O
would	O
be	O
a	O
good	O
opportunity	O
for	O
me	O
to	O
get	O
in	O
touch	O
.	O
	
What	O
is	O
the	O
biggest	O
problem	O
for	O
Clinton	O
is	O
that	O
Donald	O
Trump	O
will	O
be	O
in	O
the	O
race	O
and	O
he	O
'	O
s	O
unlikely	O
to	O
be	O
the	O
nominee	O
.	O
	
"	O
	
We	O
'	O
re	O
going	O
to	O
do	O
and	O
we	O
'	O
re	O
going	O
to	O
put	O
it	O
out	O
and	O
get	O
the	O
ball	O
,	O
"	O
he	O
said	O
.	O
	
"	O
	
I	O
would	O
be	O
afraid	O
to	O
blame	O
the	O
girls	O
to	O
go	O
back	O
	
but	O
I	O
was	O
just	O
disappointed	O
with	O
the	O
race	O
,	O
"	O
he	O
said	O
.	O
	
"	O
	
I	O
'	O
m	O
not	O
going	O
to	O
work	O
together	O
with	O
a	O
different	O
role	O
and	O
we	O
can	O
win	O
the	O
game	O
,	O
"	O
he	O
added	O
.	O
	
The	O
couple	O
's	O
lives	O
are	O
still	O
missing	O
and	O
they	O
have	O
been	O
killed	O
in	O
the	O
city	O
's	O
way	O
to	O
play	O
against	O
them	O
,	O
and	O
	
because	O
I	O
came	O
out	O
there	O
.	O
	
For	O
the	O
last	O
three	O
years	O
,	O
we	O
'	O
ve	O
got	O
a	O
lot	O
of	O
things	O
that	O
we	O
need	O
to	O
do	O
with	O
this	O
is	O
based	O
on	O
the	O
financial	O
markets	O
.	O
	
Do	O
n't	O
ask	O
me	O
,	O
but	O
I	O
know	O
,	O
if	O
I	O
'	O
ll	O
be	O
able	O
to	O
be	O
out	O
of	O
Hillary	O
Clinton	O
,	O
I	O
think	O
it	O
's	O
being	O
made	O
for	O
the	O
Congress	O
.	O
	
"	O
	
I	O
am	O
proud	O
to	O
be	O
able	O
to	O
move	O
forward	O
because	O
we	O
do	O
n't	O
have	O
to	O
look	O
at	O
about	O
,	O
"	O
he	O
said	O
.	O
	
That	O
'	O
s	O
why	O
we	O
'	O
re	O
the	O
most	O
important	O
people	O
for	O
the	O
African	O
American	O
community	O
	
and	O
we	O
'	O
ve	O
made	O
a	O
good	O
response	O
.	O
	
But	O
the	O
move	O
will	O
be	O
only	O
in	O
a	O
fight	O
against	O
them	O
,	O
as	O
well	O
as	O
likely	O
to	O
prevent	O
an	O
agreement	O
to	O
remain	O
in	O
the	O
EU	O
.	O
	
The	O
American	O
Medical	O
Association	O
said	O
that	O
the	O
militants	O
had	O
been	O
arrested	O
in	O
connection	O
with	O
the	O
murder	O
of	O
the	O
same	O
incident	O
.	O
	
The	O
two	O
-	O
year	O
-	O
old	O
girl	O
has	O
been	O
charged	O
with	O
a	O
suspect	O
who	O
was	O
in	O
the	O
vehicle	O
to	O
the	O
police	O
station	O
.	O
	
It	O
is	O
hard	O
to	O
buy	O
on	O
the	O
Olympics	O
,	O
but	O
we	O
probably	O
do	O
n't	O
see	O
a	O
lot	O
of	O
it	O
.	O
	
"	O
	
I	O
'	O
m	O
not	O
going	O
to	O
be	O
very	O
proud	O
of	O
the	O
other	O
countries	O
,	O
"	O
he	O
said	O
.	O
	
He	O
said	O
the	O
U.	O
N.	O
intelligence	O
industry	O
will	O
not	O
comment	O
on	O
the	O
ground	O
,	O
which	O
would	O
be	O
sensitive	O
to	O
the	O
European	O
Union	O
.	O
	
I	O
take	O
my	O
work	O
in	O
the	O
days	O
,	O
but	O
I	O
would	O
have	O
to	O
go	O
down	O
on	O
Wednesday	O
night	O
.	O
	
section	O
:	O
SeqGAN	O
	
You	O
only	O
certainly	O
might	O
not	O
rush	O
it	O
down	O
for	O
those	O
circumstances	O
where	O
we	O
are	O
when	O
they	O
were	O
the	O
heads	O
,	O
and	O
when	O
she	O
's	O
name	O
.	O
	
"	O
	
I	O
think	O
you	O
should	O
really	O
really	O
leave	O
for	O
because	O
we	O
had	O
n't	O
been	O
busy	O
,	O
where	O
it	O
goes	O
to	O
one	O
,	O
"	O
he	O
wrote	O
.	O
	
All	O
the	O
study	O
knew	O
was	O
that	O
they	O
are	O
,	O
so	O
they	O
continue	O
to	O
provide	O
support	O
service	O
and	O
it	O
does	O
n't	O
exist	O
.	O
'	O
	
It	O
can	O
say	O
become	O
up	O
with	O
nothing	O
sales	O
have	O
reached	O
the	O
charge	O
for	O
the	O
other	O
any	O
evidence	O
that	O
been	O
virtually	O
well	O
below	O
the	O
$	O
800	O
.	O
	
Three	O
times	O
before	O
the	O
start	O
of	O
the	O
season	O
is	O
much	O
early	O
on	O
2015	O
	
we	O
are	O
in	O
the	O
third	O
training	O
every	O
year	O
.	O
	
That	O
's	O
the	O
idea	O
of	O
strength	O
	
that	O
decision	O
they	O
said	O
,	O
we	O
have	O
n't	O
already	O
lost	O
four	O
or	O
seven	O
,	O
or	O
Liverpool	O
's	O
team	O
.	O
	
That	O
is	O
not	O
the	O
time	O
for	O
the	O
cost	O
of	O
changing	O
the	O
system	O
and	O
it	O
was	O
pushing	O
for	O
$	O
20	O
million	O
.	O
	
We	O
had	O
to	O
take	O
it	O
a	O
good	O
day	O
for	O
a	O
military	O
,	O
but	O
nearly	O
6	O
,	O
000	O
]	O
and	O
prepare	O
for	O
them	O
through	O
.	O
	
I	O
actually	O
did	O
n't	O
tell	O
the	O
background	O
check	O
the	O
difference	O
after	O
my	O
hour	O
was	O
to	O
be	O
recalled	O
...	O
and	O
it	O
was	O
great	O
.	O
	
We	O
are	O
thinking	O
about	O
40	O
,	O
000	O
and	O
jobs	O
in	O
what	O
is	O
wrong	O
in	O
the	O
coming	O
	
and	O
you	O
know	O
.	O
	
That	O
is	O
out	O
how	O
working	O
you	O
ca	O
n't	O
set	O
out	O
some	O
pretty	O
tight	O
...	O
or	O
what	O
I	O
'	O
m	O
going	O
through	O
.	O
	
"	O
	
I	O
wanted	O
to	O
be	O
made	O
you	O
decided	O
to	O
have	O
a	O
crisis	O
that	O
way	O
up	O
and	O
get	O
some	O
sort	O
of	O
weapon	O
,	O
not	O
much	O
to	O
give	O
birth	O
to	O
for	O
an	O
American	O
room	O
.	O
	
She	O
had	O
been	O
fined	O
almost	O
200	O
,	O
000	O
with	O
couple	O
of	O
asylum	O
seekers	O
in	O
Syria	O
and	O
Iraq	O
.	O
	
Perhaps	O
not	O
,	O
in	O
looking	O
for	O
,	O
housing	O
officials	O
would	O
help	O
the	O
frustration	O
of	O
Government	O
,	O
with	O
an	O
FBI	O
shortly	O
before	O
2020	O
.	O
	
Once	O
we	O
got	O
to	O
real	O
show	O
for	O
the	O
young	O
man	O
since	O
I	O
'	O
m	O
sure	O
she	O
went	O
to	O
love	O
it	O
just	O
,	O
whether	O
to	O
be	O
late	O
later	O
last	O
year	O
.	O
	
But	O
,	O
after	O
a	O
holiday	O
period	O
we	O
might	O
have	O
to	O
go	O
on	O
a	O
total	O
-	O
out	O
debate	O
like	O
that	O
	
could	O
have	O
happened	O
to	O
us	O
.	O
	
section	O
:	O
	
section	O
:	O
Appendix	O
	
Formulas	O
for	O
Reference	O
Discriminator	O
f	O
=	O
F	O
(	O
s	O
;	O
φ	O
f	O
)	O
,	O
	
(	O
1	O
)	O
	
MANAGER	B-Method
of	O
Generatorĝ	O
	
WORKER	B-Method
of	O
Generator	O
	
Pseudo	O
Code	O
	
section	O
:	O
Algorithm	O
1	O
Adversarial	B-Method
Training	I-Method
with	O
Leaked	O
Information	O
	
Require	O
:	O
Hierachical	B-Method
policy	I-Method
G	O
θm	O
,	O
θw	O
;	O
discriminator	O
D	O
φ	O
;	O
a	O
sequence	O
dataset	O
S	O
	
=	O
{	O
X1:T	O
}	O
1	O
:	O
Initialize	O
G	O
θm	O
,	O
θw	O
,	O
D	O
φ	O
with	O
random	O
weights	O
θm	O
,	O
θw	O
,	O
φ	O
.	O
2	O
:	O
	
Pre	O
-	O
train	O
D	O
φ	O
(	O
i.e.	O
the	O
feature	B-Method
extractor	I-Method
F	O
(	O
·	O
;	O
φ	O
f	O
)	O
and	O
the	O
output	O
layer	O
sigmoid	O
(	O
φ	O
l	O
,	O
·	O
)	O
)	O
using	O
S	O
as	O
positive	O
samples	O
and	O
output	O
from	O
G	O
θm	O
,	O
θw	O
as	O
negative	O
samples	O
.	O
	
3	O
:	O
	
Pre	O
-	O
train	O
G	O
θm	O
	
,	O
θw	O
using	O
leaked	O
information	O
from	O
D	O
φ	O
4	O
:	O
Perform	O
the	O
two	O
parts	O
of	O
pre	B-Method
-	I-Method
training	I-Method
interleavingly	I-Method
until	O
convergence	O
.	O
	
5	O
:	O
repeat	O
6	O
:	O
	
for	O
g	O
-	O
steps	O
do	O
7	O
:	O
	
Generate	O
a	O
sequence	O
Y1:T	O
=	O
(	O
y1	O
,	O
.	O
.	O
.	O
	
,	O
yT	O
)	O
	
∼	O
G	O
θ	O
8	O
:	O
	
for	O
t	O
in	O
1	O
:	O
T	O
do	O
9	O
:	O
	
Store	O
leaked	O
information	O
ft	O
from	O
D	O
φ	O
10	O
:	O
	
Get	O
Q	O
(	O
ft	O
,	O
gt	O
)	O
by	O
Monte	B-Method
Carlo	I-Method
Search	I-Method
via	O
Eq	O
.	O
	
(	O
8	O
)	O
	
section	O
:	O
	
Aggregated	B-Method
Residual	I-Method
Transformations	I-Method
for	O
Deep	B-Method
Neural	I-Method
Networks	I-Method
	
section	O
:	O
Abstract	O
	
We	O
present	O
a	O
simple	O
,	O
highly	O
modularized	B-Method
network	I-Method
architecture	I-Method
for	O
image	B-Task
classification	I-Task
.	O
	
Our	O
network	O
is	O
constructed	O
by	O
repeating	O
a	O
building	O
block	O
that	O
aggregates	O
a	O
set	O
of	O
transformations	O
with	O
the	O
same	O
topology	O
.	O
	
Our	O
simple	O
design	O
results	O
in	O
a	O
homogeneous	O
,	O
multi	O
-	O
branch	O
architecture	O
that	O
has	O
only	O
a	O
few	O
hyper	O
-	O
parameters	O
to	O
set	O
.	O
	
This	O
strategy	O
exposes	O
a	O
new	O
dimension	O
,	O
which	O
we	O
call	O
"	O
cardinality	O
"	O
(	O
the	O
size	O
of	O
the	O
set	O
of	O
transformations	O
)	O
,	O
as	O
an	O
essential	O
factor	O
in	O
addition	O
to	O
the	O
dimensions	O
of	O
depth	O
and	O
width	O
.	O
	
On	O
the	O
ImageNet	B-Material
-	I-Material
1	I-Material
K	I-Material
dataset	I-Material
,	O
we	O
empirically	O
show	O
that	O
even	O
under	O
the	O
restricted	O
condition	O
of	O
maintaining	O
complexity	B-Metric
,	O
increasing	O
cardinality	O
is	O
able	O
to	O
improve	O
classification	B-Metric
accuracy	I-Metric
.	O
	
Moreover	O
,	O
increasing	O
cardinality	O
is	O
more	O
effective	O
than	O
going	O
deeper	O
or	O
wider	O
when	O
we	O
increase	O
the	O
capacity	O
.	O
	
Our	O
models	O
,	O
named	O
ResNeXt	B-Method
,	O
are	O
the	O
foundations	O
of	O
our	O
entry	O
to	O
the	O
ILSVRC	B-Task
2016	I-Task
classification	I-Task
task	I-Task
in	O
which	O
we	O
secured	O
2nd	O
place	O
.	O
	
We	O
further	O
investigate	O
ResNeXt	B-Method
on	O
an	O
ImageNet	B-Material
-	I-Material
5	I-Material
K	I-Material
set	I-Material
and	O
the	O
COCO	O
detection	O
set	O
,	O
also	O
showing	O
better	O
results	O
than	O
its	O
ResNet	B-Method
counterpart	O
.	O
	
The	O
code	O
and	O
models	O
are	O
publicly	O
available	O
online	O
1	O
.	O
	
section	O
:	O
Introduction	O
	
Research	O
on	O
visual	B-Task
recognition	I-Task
is	O
undergoing	O
a	O
transition	O
from	O
"	O
feature	B-Method
engineering	I-Method
"	O
to	O
"	O
network	B-Method
engineering	I-Method
	
"	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
	
In	O
contrast	O
to	O
traditional	O
handdesigned	O
features	O
(	O
e.g.	O
,	O
SIFT	O
[	O
reference	O
]	O
and	O
HOG	O
[	O
reference	O
]	O
)	O
,	O
features	O
learned	O
by	O
neural	B-Method
networks	I-Method
from	O
large	O
-	O
scale	O
data	O
[	O
reference	O
]	O
require	O
minimal	O
human	O
involvement	O
during	O
training	O
,	O
and	O
can	O
be	O
transferred	O
to	O
a	O
variety	O
of	O
recognition	B-Task
tasks	I-Task
	
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
Nevertheless	O
,	O
human	O
effort	O
has	O
been	O
shifted	O
to	O
designing	O
better	O
network	B-Method
architectures	I-Method
for	O
learning	B-Task
representations	I-Task
.	O
	
Designing	B-Method
architectures	I-Method
becomes	O
increasingly	O
difficult	O
with	O
the	O
growing	O
number	O
of	O
hyper	O
-	O
parameters	O
(	O
width	O
[	O
reference	O
]	O
,	O
filter	O
sizes	O
,	O
strides	O
,	O
etc	O
.	O
)	O
,	O
especially	O
when	O
there	O
are	O
many	O
layers	O
.	O
	
The	O
VGG	B-Method
-	I-Method
nets	I-Method
[	O
reference	O
]	O
exhibit	O
a	O
simple	O
yet	O
effective	O
strategy	O
of	O
constructing	O
very	O
deep	B-Method
networks	I-Method
:	O
stacking	B-Task
build	O
-	O
1	O
https:	O
//	O
github.com	O
/	O
facebookresearch	O
/	O
ResNeXt	B-Method
	
2	O
Width	O
refers	O
to	O
the	O
number	O
of	O
channels	O
in	O
a	O
layer	O
.	O
	
[	O
reference	O
]	O
.	O
Right	O
:	O
	
A	O
block	O
of	O
ResNeXt	B-Method
with	O
cardinality	O
=	O
32	O
,	O
with	O
roughly	O
the	O
same	O
complexity	B-Metric
.	O
	
A	O
layer	O
is	O
shown	O
as	O
(	O
#	O
in	O
channels	O
,	O
filter	O
size	O
,	O
#	O
out	O
channels	O
)	O
.	O
	
ing	O
blocks	O
of	O
the	O
same	O
shape	O
.	O
	
This	O
strategy	O
is	O
inherited	O
by	O
ResNets	B-Method
[	O
reference	O
]	O
which	O
stack	O
modules	O
of	O
the	O
same	O
topology	O
.	O
	
This	O
simple	O
rule	O
reduces	O
the	O
free	O
choices	O
of	O
hyperparameters	O
,	O
and	O
depth	O
is	O
exposed	O
as	O
an	O
essential	O
dimension	O
in	O
neural	B-Method
networks	I-Method
.	O
	
Moreover	O
,	O
we	O
argue	O
that	O
the	O
simplicity	O
of	O
this	O
rule	O
may	O
reduce	O
the	O
risk	O
of	O
over	O
-	O
adapting	O
the	O
hyperparameters	O
to	O
a	O
specific	O
dataset	O
.	O
	
The	O
robustness	B-Metric
of	O
VGGnets	B-Method
and	O
ResNets	B-Method
has	O
been	O
proven	O
by	O
various	O
visual	B-Task
recognition	I-Task
tasks	I-Task
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
and	O
by	O
non	B-Task
-	I-Task
visual	I-Task
tasks	I-Task
involving	O
speech	O
[	O
reference	O
][	O
reference	O
]	O
and	O
language	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
	
Unlike	O
VGG	B-Method
-	I-Method
nets	I-Method
,	O
the	O
family	O
of	O
Inception	B-Method
models	I-Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
have	O
demonstrated	O
that	O
carefully	O
designed	O
topologies	O
are	O
able	O
to	O
achieve	O
compelling	O
accuracy	B-Metric
with	O
low	O
theoretical	O
complexity	B-Metric
.	O
	
The	O
Inception	B-Method
models	I-Method
have	O
evolved	O
over	O
time	O
[	O
reference	O
][	O
reference	O
]	O
,	O
but	O
an	O
important	O
common	O
property	O
is	O
a	O
split	B-Method
-	I-Method
transform	I-Method
-	I-Method
merge	I-Method
strategy	I-Method
.	O
	
In	O
an	O
Inception	B-Method
module	I-Method
,	O
the	O
input	O
is	O
split	O
into	O
a	O
few	O
lower	O
-	O
dimensional	O
embeddings	O
(	O
by	O
1×1	O
convolutions	O
)	O
,	O
transformed	O
by	O
a	O
set	O
of	O
specialized	B-Method
filters	I-Method
(	O
3×3	O
,	O
5×5	O
,	O
etc	O
.	O
)	O
,	O
and	O
merged	O
by	O
concatenation	B-Method
.	O
	
It	O
can	O
be	O
shown	O
that	O
the	O
solution	O
space	O
of	O
this	O
architecture	O
is	O
a	O
strict	O
subspace	O
of	O
the	O
solution	O
space	O
of	O
a	O
single	O
large	O
layer	O
(	O
e.g.	O
,	O
5×5	O
)	O
operating	O
on	O
a	O
high	B-Method
-	I-Method
dimensional	I-Method
embedding	I-Method
.	O
	
The	O
split	B-Method
-	I-Method
transform	I-Method
-	I-Method
merge	I-Method
behavior	I-Method
of	I-Method
Inception	I-Method
modules	I-Method
is	O
expected	O
to	O
approach	O
the	O
representational	O
power	O
of	O
large	O
and	O
dense	O
layers	O
,	O
but	O
at	O
a	O
considerably	O
lower	O
computational	O
complexity	B-Metric
.	O
	
Despite	O
good	O
accuracy	B-Metric
,	O
the	O
realization	O
of	O
Inception	B-Method
models	I-Method
has	O
been	O
accompanied	O
with	O
a	O
series	O
of	O
complicating	O
fac	O
-	O
tors	O
-	O
the	O
filter	O
numbers	O
and	O
sizes	O
are	O
tailored	O
for	O
each	O
individual	O
transformation	O
,	O
and	O
the	O
modules	O
are	O
customized	O
stage	O
-	O
by	O
-	O
stage	O
.	O
	
Although	O
careful	O
combinations	O
of	O
these	O
components	O
yield	O
excellent	O
neural	B-Method
network	I-Method
recipes	I-Method
,	O
it	O
is	O
in	O
general	O
unclear	O
how	O
to	O
adapt	O
the	O
Inception	B-Method
architectures	I-Method
to	O
new	O
datasets	O
/	O
tasks	O
,	O
especially	O
when	O
there	O
are	O
many	O
factors	O
and	O
hyper	O
-	O
parameters	O
to	O
be	O
designed	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
present	O
a	O
simple	O
architecture	O
which	O
adopts	O
VGG	O
/	O
ResNets	B-Method
'	O
strategy	O
of	O
repeating	O
layers	O
,	O
while	O
exploiting	O
the	O
split	B-Method
-	I-Method
transform	I-Method
-	I-Method
merge	I-Method
strategy	I-Method
in	O
an	O
easy	O
,	O
extensible	O
way	O
.	O
	
A	O
module	O
in	O
our	O
network	O
performs	O
a	O
set	O
of	O
transformations	O
,	O
each	O
on	O
a	O
low	O
-	O
dimensional	O
embedding	O
,	O
whose	O
outputs	O
are	O
aggregated	O
by	O
summation	B-Method
.	O
	
We	O
pursuit	O
a	O
simple	O
realization	O
of	O
this	O
idea	O
-	O
the	O
transformations	O
to	O
be	O
aggregated	O
are	O
all	O
of	O
the	O
same	O
topology	O
(	O
e.g.	O
,	O
Fig	O
.	O
1	O
	
(	O
right	O
)	O
)	O
.	O
	
This	O
design	O
allows	O
us	O
to	O
extend	O
to	O
any	O
large	O
number	O
of	O
transformations	O
without	O
specialized	O
designs	O
.	O
	
Interestingly	O
,	O
under	O
this	O
simplified	O
situation	O
we	O
show	O
that	O
our	O
model	O
has	O
two	O
other	O
equivalent	O
forms	O
(	O
Fig	O
.	O
3	O
)	O
.	O
	
The	O
reformulation	O
in	O
Fig	O
.	O
3	O
(	O
b	O
)	O
appears	O
similar	O
to	O
the	O
InceptionResNet	B-Method
module	I-Method
[	O
reference	O
]	O
in	O
that	O
it	O
concatenates	O
multiple	O
paths	O
;	O
but	O
our	O
module	O
differs	O
from	O
all	O
existing	O
Inception	B-Method
modules	I-Method
in	O
that	O
all	O
our	O
paths	O
share	O
the	O
same	O
topology	O
and	O
thus	O
the	O
number	O
of	O
paths	O
can	O
be	O
easily	O
isolated	O
as	O
a	O
factor	O
to	O
be	O
investigated	O
.	O
	
In	O
a	O
more	O
succinct	O
reformulation	O
,	O
our	O
module	O
can	O
be	O
reshaped	O
by	O
Krizhevsky	O
et	O
al	O
.	O
	
's	O
grouped	B-Method
convolutions	I-Method
[	O
reference	O
]	O
	
(	O
Fig	O
.	O
3	O
(	O
c	O
)	O
)	O
,	O
which	O
,	O
however	O
,	O
had	O
been	O
developed	O
as	O
an	O
engineering	O
compromise	O
.	O
	
We	O
empirically	O
demonstrate	O
that	O
our	O
aggregated	B-Method
transformations	I-Method
outperform	O
the	O
original	O
ResNet	B-Method
module	O
,	O
even	O
under	O
the	O
restricted	O
condition	O
of	O
maintaining	O
computational	O
complexity	B-Metric
and	O
model	B-Metric
size	I-Metric
-	O
e.g	O
.	O
,	O
Fig	O
.	O
	
1	O
(	O
right	O
)	O
is	O
designed	O
to	O
keep	O
the	O
FLOPs	O
complexity	B-Metric
and	O
number	O
of	O
parameters	O
of	O
Fig	O
.	O
	
1	O
(	O
left	O
)	O
.	O
	
We	O
emphasize	O
that	O
while	O
it	O
is	O
relatively	O
easy	O
to	O
increase	O
accuracy	B-Metric
by	O
increasing	O
capacity	O
(	O
going	O
deeper	O
or	O
wider	O
)	O
,	O
methods	O
that	O
increase	O
accuracy	B-Metric
while	O
maintaining	O
(	O
or	O
reducing	O
)	O
complexity	B-Metric
are	O
rare	O
in	O
the	O
literature	O
.	O
	
Our	O
method	O
indicates	O
that	O
cardinality	O
(	O
the	O
size	O
of	O
the	O
set	O
of	O
transformations	O
)	O
is	O
a	O
concrete	O
,	O
measurable	O
dimension	O
that	O
is	O
of	O
central	O
importance	O
,	O
in	O
addition	O
to	O
the	O
dimensions	O
of	O
width	O
and	O
depth	O
.	O
	
Experiments	O
demonstrate	O
that	O
increasing	O
cardinality	O
is	O
a	O
more	O
effective	O
way	O
of	O
gaining	O
accuracy	B-Metric
than	O
going	O
deeper	O
or	O
wider	O
,	O
especially	O
when	O
depth	O
and	O
width	O
starts	O
to	O
give	O
diminishing	O
returns	O
for	O
existing	O
models	O
.	O
	
Our	O
neural	B-Method
networks	I-Method
,	O
named	O
ResNeXt	B-Method
(	O
suggesting	O
the	O
next	O
dimension	O
)	O
,	O
outperform	O
ResNet	B-Method
-	I-Method
101	I-Method
/	I-Method
152	I-Method
[	O
reference	O
]	O
,	O
ResNet	B-Method
-	O
200	O
[	O
reference	O
]	O
,	O
Inception	O
-	O
v3	O
[	O
reference	O
]	O
,	O
and	O
Inception	O
-	O
ResNet	B-Method
-	O
v2	O
[	O
reference	O
]	O
on	O
the	O
ImageNet	B-Material
classification	I-Material
dataset	I-Material
.	O
	
In	O
particular	O
,	O
a	O
101	O
-	O
layer	O
ResNeXt	B-Method
is	O
able	O
to	O
achieve	O
better	O
accuracy	B-Metric
than	O
ResNet	B-Method
-	I-Method
200	I-Method
[	O
reference	O
]	O
but	O
has	O
only	O
50	O
%	O
complexity	B-Metric
.	O
	
Moreover	O
,	O
ResNeXt	B-Method
exhibits	O
considerably	O
simpler	O
designs	O
than	O
all	O
Inception	B-Method
models	I-Method
.	O
	
ResNeXt	B-Method
was	O
the	O
foundation	O
of	O
our	O
submission	O
to	O
the	O
ILSVRC	B-Task
2016	I-Task
classification	I-Task
task	I-Task
,	O
in	O
which	O
we	O
secured	O
second	O
place	O
.	O
	
This	O
paper	O
further	O
evaluates	O
ResNeXt	B-Method
on	O
a	O
larger	O
ImageNet	B-Material
-	I-Material
5	I-Material
K	I-Material
set	I-Material
and	O
the	O
COCO	O
object	O
detection	O
dataset	O
[	O
reference	O
]	O
,	O
showing	O
consistently	O
better	O
accuracy	B-Metric
than	O
its	O
ResNet	B-Method
counterparts	O
.	O
	
We	O
expect	O
that	O
ResNeXt	B-Method
will	O
also	O
generalize	O
well	O
to	O
other	O
visual	B-Task
(	I-Task
and	I-Task
non	I-Task
-	I-Task
visual	I-Task
)	I-Task
recognition	I-Task
tasks	I-Task
.	O
	
section	O
:	O
Related	O
Work	O
	
Multi	B-Method
-	I-Method
branch	I-Method
convolutional	I-Method
networks	I-Method
.	O
	
The	O
Inception	B-Method
models	I-Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
are	O
successful	O
multi	B-Method
-	I-Method
branch	I-Method
architectures	I-Method
where	O
each	O
branch	O
is	O
carefully	O
customized	O
.	O
	
ResNets	B-Method
[	O
reference	O
]	O
can	O
be	O
thought	O
of	O
as	O
two	O
-	O
branch	B-Method
networks	I-Method
where	O
one	O
branch	O
is	O
the	O
identity	B-Method
mapping	I-Method
.	O
	
Deep	B-Method
neural	I-Method
decision	I-Method
forests	I-Method
[	O
reference	O
]	O
are	O
tree	B-Method
-	I-Method
patterned	I-Method
multi	I-Method
-	I-Method
branch	I-Method
networks	I-Method
with	O
learned	O
splitting	O
functions	O
.	O
	
Grouped	B-Method
convolutions	I-Method
.	O
	
The	O
use	O
of	O
grouped	B-Method
convolutions	I-Method
dates	O
back	O
to	O
the	O
AlexNet	O
paper	O
[	O
reference	O
]	O
,	O
if	O
not	O
earlier	O
.	O
	
The	O
motivation	O
given	O
by	O
Krizhevsky	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
is	O
for	O
distributing	O
the	O
model	O
over	O
two	O
GPUs	B-Method
.	O
	
Grouped	B-Method
convolutions	I-Method
are	O
supported	O
by	O
Caffe	B-Method
[	O
reference	O
]	O
,	O
Torch	B-Method
[	O
reference	O
]	O
,	O
and	O
other	O
libraries	O
,	O
mainly	O
for	O
compatibility	O
of	O
AlexNet	B-Method
.	O
	
To	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
there	O
has	O
been	O
little	O
evidence	O
on	O
exploiting	O
grouped	B-Method
convolutions	I-Method
to	O
improve	O
accuracy	B-Metric
.	O
	
A	O
special	O
case	O
of	O
grouped	B-Method
convolutions	I-Method
is	O
channel	B-Method
-	I-Method
wise	I-Method
convolutions	I-Method
in	O
which	O
the	O
number	O
of	O
groups	O
is	O
equal	O
to	O
the	O
number	O
of	O
channels	O
.	O
	
Channel	B-Method
-	I-Method
wise	I-Method
convolutions	I-Method
are	O
part	O
of	O
the	O
separable	B-Method
convolutions	I-Method
in	O
[	O
reference	O
]	O
.	O
	
Compressing	B-Method
convolutional	I-Method
networks	I-Method
.	O
	
Decomposition	B-Method
(	O
at	O
spatial	O
[	O
reference	O
][	O
reference	O
]	O
and	O
/	O
or	O
channel	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
level	O
)	O
is	O
a	O
widely	O
adopted	O
technique	O
to	O
reduce	O
redundancy	B-Method
of	I-Method
deep	I-Method
convolutional	I-Method
networks	I-Method
and	O
accelerate	O
/	O
compress	O
them	O
.	O
	
Ioannou	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
present	O
a	O
"	O
root"	B-Method
-	I-Method
patterned	I-Method
network	I-Method
for	O
reducing	B-Task
computation	I-Task
,	O
and	O
branches	O
in	O
the	O
root	O
are	O
realized	O
by	O
grouped	B-Method
convolutions	I-Method
.	O
	
These	O
methods	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
have	O
shown	O
elegant	O
compromise	O
of	O
accuracy	B-Metric
with	O
lower	O
complexity	B-Metric
and	O
smaller	O
model	B-Metric
sizes	I-Metric
.	O
	
Instead	O
of	O
compression	B-Method
,	O
our	O
method	O
is	O
an	O
architecture	O
that	O
empirically	O
shows	O
stronger	O
representational	O
power	O
.	O
	
Ensembling	B-Method
.	O
	
Averaging	O
a	O
set	O
of	O
independently	B-Method
trained	I-Method
networks	I-Method
is	O
an	O
effective	O
solution	O
to	O
improving	O
accuracy	B-Metric
[	O
reference	O
]	O
,	O
widely	O
adopted	O
in	O
recognition	B-Task
competitions	I-Task
[	O
reference	O
]	O
.	O
Veit	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
interpret	O
a	O
single	O
ResNet	B-Method
as	O
an	O
ensemble	B-Method
of	I-Method
shallower	I-Method
networks	I-Method
,	O
which	O
results	O
from	O
ResNet	B-Method
's	O
additive	O
behaviors	O
	
[	O
reference	O
]	O
.	O
Our	O
method	O
harnesses	O
additions	O
to	O
aggregate	O
a	O
set	O
of	O
transformations	O
.	O
	
But	O
we	O
argue	O
that	O
it	O
is	O
imprecise	O
to	O
view	O
our	O
method	O
as	O
ensembling	B-Task
,	O
because	O
the	O
members	O
to	O
be	O
aggregated	O
are	O
trained	O
jointly	O
,	O
not	O
independently	O
.	O
	
section	O
:	O
Method	O
	
section	O
:	O
Template	O
	
We	O
adopt	O
a	O
highly	O
modularized	B-Method
design	I-Method
following	O
VGG	B-Method
/	I-Method
ResNets	I-Method
.	O
	
Our	O
network	O
consists	O
of	O
a	O
stack	O
of	O
resid	O
-	O
Fig	O
.	O
3	O
(	O
c	O
)	O
)	O
.	O
	
Inside	O
the	O
brackets	O
are	O
the	O
shape	O
of	O
a	O
residual	O
block	O
,	O
and	O
outside	O
the	O
brackets	O
is	O
the	O
number	O
of	O
stacked	O
blocks	O
on	O
a	O
stage	O
.	O
	
"	O
	
C=32	O
"	O
suggests	O
grouped	B-Method
convolutions	I-Method
[	O
reference	O
]	O
with	O
32	O
groups	O
.	O
	
The	O
numbers	O
of	O
parameters	O
and	O
FLOPs	O
are	O
similar	O
between	O
these	O
two	O
models	O
.	O
	
ual	O
blocks	O
.	O
	
These	O
blocks	O
have	O
the	O
same	O
topology	O
,	O
and	O
are	O
subject	O
to	O
two	O
simple	O
rules	O
inspired	O
by	O
VGG	B-Method
/	I-Method
ResNets	I-Method
:	O
(	O
i	O
)	O
if	O
producing	O
spatial	O
maps	O
of	O
the	O
same	O
size	O
,	O
the	O
blocks	O
share	O
the	O
same	O
hyper	O
-	O
parameters	O
(	O
width	O
and	O
filter	O
sizes	O
)	O
,	O
and	O
(	O
ii	O
)	O
each	O
time	O
when	O
the	O
spatial	O
map	O
is	O
downsampled	O
by	O
a	O
factor	O
of	O
2	O
,	O
the	O
width	O
of	O
the	O
blocks	O
is	O
multiplied	O
by	O
a	O
factor	O
of	O
2	O
.	O
	
The	O
second	O
rule	O
ensures	O
that	O
the	O
computational	O
complexity	B-Metric
,	O
in	O
terms	O
of	O
FLOPs	O
(	O
floating	O
-	O
point	O
operations	O
,	O
in	O
#	O
of	O
multiply	O
-	O
adds	O
)	O
,	O
is	O
roughly	O
the	O
same	O
for	O
all	O
blocks	O
.	O
	
With	O
these	O
two	O
rules	O
,	O
we	O
only	O
need	O
to	O
design	O
a	O
template	B-Method
module	I-Method
,	O
and	O
all	O
modules	O
in	O
a	O
network	O
can	O
be	O
determined	O
accordingly	O
.	O
	
So	O
these	O
two	O
rules	O
greatly	O
narrow	O
down	O
the	O
design	O
space	O
and	O
allow	O
us	O
to	O
focus	O
on	O
a	O
few	O
key	O
factors	O
.	O
	
The	O
networks	O
constructed	O
by	O
these	O
rules	O
are	O
in	O
Table	O
1	O
.	O
	
section	O
:	O
Revisiting	O
Simple	O
Neurons	O
	
The	O
simplest	O
neurons	B-Method
in	O
artificial	B-Method
neural	I-Method
networks	I-Method
perform	O
inner	B-Method
product	I-Method
(	O
weighted	B-Method
sum	I-Method
)	O
,	O
which	O
is	O
the	O
elementary	O
transformation	O
done	O
by	O
fully	B-Method
-	I-Method
connected	I-Method
and	I-Method
convolutional	I-Method
layers	I-Method
.	O
	
Inner	O
product	O
can	O
be	O
thought	O
of	O
as	O
a	O
form	O
of	O
aggregating	B-Method
transformation	I-Method
:	O
	
where	O
nel	O
.	O
	
This	O
operation	O
(	O
usually	O
including	O
some	O
output	O
nonlinearity	O
)	O
is	O
referred	O
to	O
as	O
a	O
"	O
neuron	B-Method
"	O
.	O
	
See	O
Fig	O
.	O
	
2	O
.	O
	
The	O
above	O
operation	O
can	O
be	O
recast	O
as	O
a	O
combination	O
of	O
splitting	B-Task
,	O
transforming	B-Task
,	O
and	O
aggregating	B-Task
.	O
	
(	O
i	O
)	O
	
Splitting	O
:	O
the	O
vector	O
x	O
is	O
sliced	O
as	O
a	O
low	B-Method
-	I-Method
dimensional	I-Method
embedding	I-Method
,	O
and	O
in	O
the	O
above	O
,	O
it	O
is	O
a	O
single	O
-	O
dimension	O
subspace	O
x	O
	
i	O
.	O
	
(	O
ii	O
)	O
	
Transforming	B-Task
:	O
the	O
low	B-Method
-	I-Method
dimensional	I-Method
representation	I-Method
is	O
transformed	O
,	O
and	O
in	O
the	O
above	O
,	O
it	O
is	O
simply	O
scaled	O
:	O
w	O
i	O
x	O
i	O
.	O
	
(	O
iii	O
)	O
	
Aggregating	O
:	O
the	O
transformations	O
in	O
all	O
embeddings	O
are	O
aggregated	O
by	O
	
section	O
:	O
Aggregated	B-Method
Transformations	I-Method
	
Given	O
the	O
above	O
analysis	O
of	O
a	O
simple	O
neuron	O
,	O
we	O
consider	O
replacing	O
the	O
elementary	O
transformation	O
(	O
w	O
i	O
x	O
i	O
)	O
with	O
a	O
more	O
generic	O
function	O
,	O
which	O
in	O
itself	O
can	O
also	O
be	O
a	O
network	O
.	O
	
In	O
contrast	O
to	O
"	O
Network	B-Method
-	I-Method
in	I-Method
-	I-Method
Network	I-Method
"	O
[	O
reference	O
]	O
that	O
turns	O
out	O
to	O
increase	O
the	O
dimension	O
of	O
depth	O
,	O
we	O
show	O
that	O
our	O
"	O
Network	B-Method
-	I-Method
in	I-Method
-	I-Method
Neuron	I-Method
"	O
expands	O
along	O
a	O
new	O
dimension	O
.	O
	
Formally	O
,	O
we	O
present	O
aggregated	B-Method
transformations	I-Method
as	O
:	O
	
where	O
T	O
i	O
(	O
x	O
)	O
can	O
be	O
an	O
arbitrary	O
function	O
.	O
	
Analogous	O
to	O
a	O
simple	O
neuron	B-Method
,	O
T	O
i	O
should	O
project	O
x	O
into	O
an	O
(	O
optionally	O
lowdimensional	B-Method
)	I-Method
embedding	I-Method
and	O
then	O
transform	O
it	O
.	O
	
In	O
Eqn	O
.	O
	
(	O
2	O
)	O
,	O
C	O
is	O
the	O
size	O
of	O
the	O
set	O
of	O
transformations	O
to	O
be	O
aggregated	O
.	O
	
We	O
refer	O
to	O
C	O
as	O
cardinality	O
[	O
reference	O
]	O
.	O
	
In	O
Eqn.	O
(	O
2	O
)	O
	
C	O
is	O
in	O
a	O
position	O
similar	O
to	O
D	O
in	O
Eqn	O
.	O
	
(	O
1	O
)	O
,	O
but	O
C	O
need	O
not	O
equal	O
D	O
and	O
can	O
be	O
an	O
arbitrary	O
number	O
.	O
	
While	O
the	O
dimension	O
of	O
width	O
is	O
related	O
to	O
the	O
number	O
of	O
simple	O
transformations	O
(	O
inner	O
product	O
)	O
,	O
we	O
argue	O
that	O
the	O
dimension	O
of	O
cardinality	B-Metric
controls	O
the	O
number	O
of	O
more	O
complex	O
transformations	O
.	O
	
We	O
show	O
by	O
experiments	O
that	O
cardinality	O
is	O
an	O
essential	O
dimension	O
and	O
can	O
be	O
more	O
effective	O
than	O
the	O
dimensions	O
of	O
width	O
and	O
depth	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
consider	O
a	O
simple	O
way	O
of	O
designing	O
the	O
transformation	O
functions	O
:	O
	
all	O
T	O
i	O
's	O
have	O
the	O
same	O
topology	O
.	O
	
This	O
extends	O
the	O
VGG	B-Method
-	I-Method
style	I-Method
strategy	I-Method
of	O
repeating	O
layers	O
of	O
the	O
same	O
shape	O
,	O
which	O
is	O
helpful	O
for	O
isolating	O
a	O
few	O
factors	O
and	O
extending	O
to	O
any	O
large	O
number	O
of	O
transformations	O
.	O
	
We	O
set	O
the	O
individual	O
transformation	O
T	O
i	O
to	O
be	O
the	O
bottleneckshaped	B-Method
architecture	I-Method
[	O
reference	O
]	O
,	O
as	O
illustrated	O
in	O
Fig	O
.	O
	
1	O
	
(	O
right	O
)	O
.	O
	
In	O
this	O
case	O
,	O
the	O
first	O
1×1	O
layer	O
in	O
each	O
T	O
i	O
produces	O
the	O
lowdimensional	O
embedding	O
.	O
,	O
implemented	O
as	O
grouped	B-Method
convolutions	I-Method
	
[	O
reference	O
]	O
.	O
Notations	O
in	O
bold	O
text	O
highlight	O
the	O
reformulation	O
changes	O
.	O
	
A	O
layer	O
is	O
denoted	O
as	O
(	O
#	O
input	O
channels	O
,	O
filter	O
size	O
,	O
#	O
output	O
channels	O
)	O
.	O
	
The	O
aggregated	O
transformation	O
in	O
Eqn	O
.	O
	
(	O
2	O
)	O
serves	O
as	O
the	O
residual	O
function	O
[	O
reference	O
]	O
(	O
Fig	O
.	O
1	O
right	O
)	O
:	O
	
where	O
y	O
is	O
the	O
output	O
.	O
	
Relation	O
to	O
Inception	O
-	O
ResNet	B-Method
.	O
	
Some	O
tensor	O
manipulations	O
show	O
that	O
the	O
module	O
in	O
Fig	O
.	O
	
1	O
(	O
right	O
)	O
	
(	O
also	O
shown	O
in	O
Fig	O
.	O
	
3	O
(	O
a	O
)	O
)	O
is	O
equivalent	O
to	O
Fig	O
.	O
	
3	O
(	O
b	O
)	O
.	O
	
[	O
reference	O
]	O
	
Fig	O
.	O
3	O
(	O
b	O
)	O
appears	O
similar	O
to	O
the	O
Inception	O
-	O
ResNet	B-Method
[	O
reference	O
]	O
block	O
in	O
that	O
it	O
involves	O
branching	O
and	O
concatenating	O
in	O
the	O
residual	O
function	O
.	O
	
But	O
unlike	O
all	O
Inception	O
or	O
Inception	O
-	O
ResNet	B-Method
modules	O
,	O
we	O
share	O
the	O
same	O
topology	O
among	O
the	O
multiple	O
paths	O
.	O
	
Our	O
module	O
requires	O
minimal	O
extra	O
effort	O
designing	O
each	O
path	O
.	O
	
Relation	O
to	O
Grouped	B-Method
Convolutions	I-Method
.	O
	
The	O
above	O
module	O
becomes	O
more	O
succinct	O
using	O
the	O
notation	O
of	O
grouped	B-Method
convolutions	I-Method
[	O
reference	O
]	O
.	O
[	O
reference	O
]	O
	
This	O
reformulation	O
is	O
illustrated	O
in	O
Fig	O
.	O
3	O
(	O
c	O
)	O
.	O
	
All	O
the	O
low	O
-	O
dimensional	O
embeddings	O
(	O
the	O
first	O
1×1	O
layers	O
)	O
can	O
be	O
replaced	O
by	O
a	O
single	O
,	O
wider	O
layer	O
(	O
e.g.	O
,	O
1×1	O
,	O
128	O
-	O
d	O
in	O
Fig	O
3	O
(	O
c	O
)	O
)	O
.	O
	
Splitting	B-Task
is	O
essentially	O
done	O
by	O
the	O
grouped	B-Method
convolutional	I-Method
layer	I-Method
when	O
it	O
divides	O
its	O
input	O
channels	O
into	O
groups	O
.	O
	
The	O
grouped	B-Method
convolutional	I-Method
layer	I-Method
in	O
Fig	O
.	O
	
3	B-Method
(	I-Method
c	I-Method
)	O
performs	O
32	O
groups	O
of	O
convolutions	B-Method
whose	O
input	O
and	O
output	O
channels	O
are	O
4	O
-	O
dimensional	O
.	O
	
The	O
grouped	B-Method
convolutional	I-Method
layer	I-Method
concatenates	O
them	O
as	O
the	O
outputs	O
of	O
the	O
layer	O
.	O
	
The	O
block	O
in	O
Fig	O
.	O
3	O
(	O
c	O
)	O
looks	O
like	O
the	O
original	O
bottleneck	O
residual	O
block	O
in	O
Fig	O
.	O
	
1	O
(	O
left	O
)	O
,	O
except	O
that	O
Fig	O
.	O
3	O
(	O
c	O
)	O
is	O
a	O
wider	O
but	O
sparsely	O
connected	O
module	O
.	O
	
[	O
reference	O
]	O
	
An	O
informal	O
but	O
descriptive	O
proof	O
is	O
as	O
follows	O
.	O
	
Note	O
the	O
equality	O
:	O
	
is	O
horizontal	O
concatenation	O
and	O
[	O
;	O
]	O
is	O
vertical	O
concatenation	O
.	O
	
Let	O
A	O
i	O
be	O
the	O
weight	O
of	O
the	O
last	O
layer	O
and	O
B	O
	
i	O
be	O
the	O
output	O
response	O
of	O
the	O
second	O
-	O
last	O
layer	O
in	O
the	O
block	O
.	O
	
In	O
the	O
case	O
of	O
C	O
=	O
2	O
,	O
the	O
element	O
-	O
wise	O
addition	O
in	O
Fig	O
.	O
	
3	O
(	O
a	O
)	O
is	O
	
A	O
1	O
B	O
1	O
+	O
A	O
2	O
B	O
2	O
,	O
the	O
weight	O
of	O
the	O
last	O
layer	O
in	O
Fig	O
.	O
	
3	O
(	O
b	O
)	O
is	O
[	O
A	O
1	O
,	O
A	O
2	O
]	O
,	O
and	O
the	O
concatenation	O
of	O
outputs	O
of	O
second	O
-	O
last	O
layers	O
in	O
Fig	O
.	O
	
3	O
(	O
b	O
)	O
is	O
[	O
B	O
1	O
;	O
B	O
2	O
]	O
.	O
	
[	O
reference	O
]	O
	
In	O
a	O
group	B-Method
conv	I-Method
layer	I-Method
[	O
reference	O
]	O
,	O
input	O
and	O
output	O
channels	O
are	O
divided	O
into	O
C	O
groups	O
,	O
and	O
convolutions	B-Method
are	O
separately	O
performed	O
within	O
each	O
group	O
.	O
	
We	O
note	O
that	O
the	O
reformulations	O
produce	O
nontrivial	O
topologies	O
only	O
when	O
the	O
block	O
has	O
depth	O
≥3	O
.	O
	
If	O
the	O
block	O
has	O
depth	O
=	O
2	O
(	O
e.g.	O
,	O
the	O
basic	O
block	O
in	O
[	O
reference	O
]	O
)	O
,	O
the	O
reformulations	O
lead	O
to	O
trivially	O
a	O
wide	O
,	O
dense	O
module	O
.	O
	
See	O
the	O
illustration	O
in	O
Fig	O
.	O
4	O
.	O
	
Discussion	O
.	O
	
We	O
note	O
that	O
although	O
we	O
present	O
reformulations	O
that	O
exhibit	O
concatenation	O
(	O
Fig	O
.	O
3	O
(	O
b	O
)	O
)	O
or	O
grouped	O
convolutions	O
(	O
Fig	O
.	O
3	O
(	O
c	O
)	O
)	O
,	O
such	O
reformulations	O
are	O
not	O
always	O
applicable	O
for	O
the	O
general	O
form	O
of	O
Eqn	O
.	O
	
(	O
3	O
)	O
,	O
e.g.	O
,	O
if	O
the	O
transformation	O
	
T	O
i	O
takes	O
arbitrary	O
forms	O
and	O
are	O
heterogenous	O
.	O
	
We	O
choose	O
to	O
use	O
homogenous	O
forms	O
in	O
this	O
paper	O
because	O
they	O
are	O
simpler	O
and	O
extensible	O
.	O
	
Under	O
this	O
simplified	O
case	O
,	O
grouped	O
convolutions	O
in	O
the	O
form	O
of	O
Fig	O
.	O
3	O
(	O
c	O
)	O
are	O
helpful	O
for	O
easing	O
implementation	O
.	O
	
section	O
:	O
Model	O
Capacity	O
	
Our	O
experiments	O
in	O
the	O
next	O
section	O
will	O
show	O
that	O
our	O
models	O
improve	O
accuracy	B-Metric
when	O
maintaining	O
the	O
model	O
complexity	B-Metric
and	O
number	O
of	O
parameters	O
.	O
	
This	O
is	O
not	O
only	O
interesting	O
in	O
practice	O
,	O
but	O
more	O
importantly	O
,	O
the	O
complexity	B-Metric
and	O
number	O
of	O
parameters	O
represent	O
inherent	O
capacity	O
of	O
models	O
and	O
thus	O
are	O
often	O
investigated	O
as	O
fundamental	O
properties	O
of	O
deep	B-Method
networks	I-Method
[	O
reference	O
]	O
.	O
	
When	O
we	O
evaluate	O
different	O
cardinalities	O
C	O
while	O
preserving	O
complexity	B-Metric
,	O
we	O
want	O
to	O
minimize	O
the	O
modification	O
of	O
other	O
hyper	O
-	O
parameters	O
.	O
	
We	O
choose	O
to	O
adjust	O
the	O
width	O
of	O
cardinality	O
C	O
the	O
bottleneck	O
(	O
e.g.	O
,	O
4	O
-	O
d	O
in	O
Fig	O
1	O
(	O
right	O
)	O
)	O
,	O
because	O
it	O
can	O
be	O
isolated	O
from	O
the	O
input	O
and	O
output	O
of	O
the	O
block	O
.	O
	
This	O
strategy	O
introduces	O
no	O
change	O
to	O
other	O
hyper	O
-	O
parameters	O
(	O
depth	O
or	O
input	O
/	O
output	O
width	O
of	O
blocks	O
)	O
,	O
so	O
is	O
helpful	O
for	O
us	O
to	O
focus	O
on	O
the	O
impact	O
of	O
cardinality	O
.	O
	
In	O
Fig	O
.	O
	
1	O
(	O
left	O
)	O
	
,	O
the	O
original	O
ResNet	B-Method
bottleneck	O
block	O
[	O
reference	O
]	O
	
Fig	O
.	O
	
1	O
(	O
right	O
)	O
has	O
:	O
	
parameters	O
and	O
proportional	B-Method
FLOPs	I-Method
.	O
	
When	O
C	O
=	O
32	O
and	O
d	O
=	O
4	O
,	O
Eqn.	O
(	O
4	O
)	O
≈	O
70k	O
.	O
	
Table	O
2	O
shows	O
the	O
relationship	O
between	O
cardinality	O
C	O
and	O
bottleneck	O
width	O
	
d.	O
	
Because	O
we	O
adopt	O
the	O
two	O
rules	O
in	O
Sec	O
.	O
	
3.1	O
,	O
the	O
above	O
approximate	O
equality	O
is	O
valid	O
between	O
a	O
ResNet	B-Method
bottleneck	O
block	O
and	O
our	O
ResNeXt	B-Method
on	O
all	O
stages	O
(	O
except	O
for	O
the	O
subsampling	O
layers	O
where	O
the	O
feature	O
maps	O
size	O
changes	O
)	O
.	O
	
Table	O
1	O
compares	O
the	O
original	O
ResNet	B-Method
-	I-Method
50	I-Method
and	O
our	O
ResNeXt	B-Method
-	I-Method
50	I-Method
that	O
is	O
of	O
similar	O
capacity	O
.	O
	
[	O
reference	O
]	O
	
We	O
note	O
that	O
the	O
complexity	B-Metric
can	O
only	O
be	O
preserved	O
approximately	O
,	O
but	O
the	O
difference	O
of	O
the	O
complexity	B-Metric
is	O
minor	O
and	O
does	O
not	O
bias	O
our	O
results	O
.	O
	
section	O
:	O
Implementation	O
details	O
	
Our	O
implementation	O
follows	O
[	O
reference	O
]	O
and	O
the	O
publicly	O
available	O
code	O
of	O
fb.resnet.torch	O
	
[	O
reference	O
]	O
.	O
On	O
the	O
ImageNet	B-Material
dataset	I-Material
	
,	O
the	O
input	O
image	O
is	O
224×224	O
randomly	O
cropped	O
from	O
a	O
resized	O
image	O
using	O
the	O
scale	B-Method
and	I-Method
aspect	I-Method
ratio	I-Method
augmentation	I-Method
of	O
[	O
reference	O
]	O
implemented	O
by	O
[	O
reference	O
]	O
.	O
	
The	O
shortcuts	O
are	O
identity	O
connections	O
except	O
for	O
those	O
increasing	O
dimensions	O
which	O
are	O
projections	O
(	O
type	O
B	O
in	O
[	O
reference	O
]	O
)	O
.	O
	
Downsampling	B-Task
of	I-Task
conv3	I-Task
,	O
4	O
,	O
and	O
5	O
is	O
done	O
by	O
stride	B-Method
-	I-Method
2	I-Method
convolutions	I-Method
in	O
the	O
3×3	O
layer	O
of	O
the	O
first	O
block	O
in	O
each	O
stage	O
,	O
as	O
suggested	O
in	O
[	O
reference	O
]	O
.	O
We	O
use	O
SGD	B-Method
with	O
a	O
mini	O
-	O
batch	O
size	O
of	O
256	O
on	O
8	O
GPUs	O
(	O
32	O
per	O
GPU	O
)	O
.	O
	
The	O
weight	O
decay	O
is	O
0.0001	O
and	O
the	O
momentum	O
is	O
0.9	O
.	O
	
We	O
start	O
from	O
a	O
learning	B-Metric
rate	I-Metric
of	O
0.1	O
,	O
and	O
divide	O
it	O
by	O
10	O
for	O
three	O
times	O
using	O
the	O
schedule	O
in	O
[	O
reference	O
]	O
.	O
	
We	O
adopt	O
the	O
weight	B-Method
initialization	I-Method
of	O
[	O
reference	O
]	O
.	O
	
In	O
all	O
ablation	O
comparisons	O
,	O
we	O
evaluate	O
the	O
error	B-Metric
on	O
the	O
single	O
224×224	O
center	O
crop	O
from	O
an	O
image	O
whose	O
shorter	O
side	O
is	O
256	O
.	O
	
Our	O
models	O
are	O
realized	O
by	O
the	O
form	O
of	O
Fig	O
.	O
3	O
(	O
c	O
)	O
.	O
	
We	O
perform	O
batch	B-Method
normalization	I-Method
(	O
BN	B-Method
)	O
[	O
reference	O
]	O
right	O
after	O
the	O
con	O
-	O
[	O
reference	O
]	O
	
The	O
marginally	O
smaller	O
number	O
of	O
parameters	O
and	O
marginally	O
higher	O
FLOPs	O
are	O
mainly	O
caused	O
by	O
the	O
blocks	O
where	O
the	O
map	O
sizes	O
change	O
.	O
	
volutions	O
in	O
Fig	O
.	O
3	O
(	O
c	O
)	O
.	O
	
[	O
reference	O
]	O
	
ReLU	B-Method
is	O
performed	O
right	O
after	O
each	O
BN	O
,	O
expect	O
for	O
the	O
output	O
of	O
the	O
block	O
where	O
ReLU	B-Method
is	O
performed	O
after	O
the	O
adding	O
to	O
the	O
shortcut	O
,	O
following	O
[	O
reference	O
]	O
.	O
	
We	O
note	O
that	O
the	O
three	O
forms	O
in	O
Fig	O
.	O
	
3	O
are	O
strictly	O
equivalent	O
,	O
when	O
BN	B-Method
and	O
ReLU	B-Method
are	O
appropriately	O
addressed	O
as	O
mentioned	O
above	O
.	O
	
We	O
have	O
trained	O
all	O
three	O
forms	O
and	O
obtained	O
the	O
same	O
results	O
.	O
	
We	O
choose	O
to	O
implement	O
by	O
Fig	O
.	O
3	O
(	O
c	O
)	O
because	O
it	O
is	O
more	O
succinct	O
and	O
faster	O
than	O
the	O
other	O
two	O
forms	O
.	O
	
section	O
:	O
Experiments	O
	
section	O
:	O
Experiments	O
on	O
ImageNet	B-Material
-	I-Material
1	I-Material
K	I-Material
	
We	O
conduct	O
ablation	O
experiments	O
on	O
the	O
1000	B-Material
-	I-Material
class	I-Material
ImageNet	I-Material
classification	I-Material
task	I-Material
[	O
reference	O
]	O
.	O
	
We	O
follow	O
[	O
reference	O
]	O
to	O
construct	O
50	B-Method
-	I-Method
layer	I-Method
and	O
101	B-Method
-	I-Method
layer	I-Method
residual	I-Method
networks	I-Method
.	O
	
We	O
simply	O
replace	O
all	O
blocks	O
in	O
ResNet	B-Method
-	O
50	O
/	O
101	O
with	O
our	O
blocks	O
.	O
	
Notations	O
.	O
	
Because	O
we	O
adopt	O
the	O
two	O
rules	O
in	O
Sec	O
.	O
	
3.1	O
,	O
it	O
is	O
sufficient	O
for	O
us	O
to	O
refer	O
to	O
an	O
architecture	O
by	O
the	O
template	O
.	O
	
For	O
example	O
,	O
Table	O
1	O
shows	O
a	O
ResNeXt	B-Method
-	O
50	O
constructed	O
by	O
a	O
template	O
with	O
cardinality	O
=	O
32	O
and	O
bottleneck	O
width	O
=	O
	
4d	O
	
(	O
Fig	O
.	O
3	O
)	O
.	O
	
This	O
network	O
is	O
denoted	O
as	O
ResNeXt	B-Method
-	O
50	O
(	O
32×4d	O
)	O
for	O
simplicity	O
.	O
	
We	O
note	O
that	O
the	O
input	O
/	O
output	O
width	O
of	O
the	O
template	O
is	O
fixed	O
as	O
256	O
-	O
d	O
(	O
Fig	O
.	O
3	O
)	O
,	O
and	O
all	O
widths	O
are	O
doubled	O
each	O
time	O
when	O
the	O
feature	O
map	O
is	O
subsampled	O
(	O
see	O
Table	O
1	O
)	O
.	O
	
Cardinality	O
vs.	O
Width	O
.	O
	
We	O
first	O
evaluate	O
the	O
trade	O
-	O
off	O
between	O
cardinality	O
C	O
and	O
bottleneck	O
width	O
,	O
under	O
preserved	O
complexity	B-Metric
as	O
listed	O
in	O
Table	O
2	O
.	O
	
Table	O
3	O
shows	O
the	O
results	O
and	O
Fig	O
.	O
5	O
shows	O
the	O
curves	O
of	O
error	B-Metric
vs.	O
epochs	O
.	O
	
Comparing	O
with	O
ResNet	B-Method
-	I-Method
50	I-Method
	
(	O
Table	O
3	O
top	O
and	O
Fig	O
.	O
5	O
left	O
)	O
	
,	O
the	O
32×4d	B-Method
ResNeXt	I-Method
-	I-Method
50	I-Method
has	O
a	O
validation	B-Metric
error	I-Metric
of	O
22.2	O
%	O
,	O
which	O
is	O
1.7	O
%	O
lower	O
than	O
the	O
ResNet	B-Method
baseline	O
's	O
23.9	O
%	O
.	O
	
With	O
cardinality	O
C	O
increasing	O
from	O
1	O
to	O
32	O
while	O
keeping	O
complexity	B-Metric
,	O
the	O
error	B-Metric
rate	I-Metric
keeps	O
reducing	O
.	O
	
Furthermore	O
,	O
the	O
32×4d	O
ResNeXt	B-Method
also	O
has	O
a	O
much	O
lower	O
training	B-Metric
error	I-Metric
than	O
the	O
ResNet	B-Method
counterpart	O
,	O
suggesting	O
that	O
the	O
gains	O
are	O
not	O
from	O
regularization	B-Method
but	O
from	O
stronger	O
representations	O
.	O
	
Similar	O
trends	O
are	O
observed	O
in	O
the	O
case	O
of	O
ResNet	B-Method
-	O
101	O
	
(	O
Fig	O
.	O
5	O
right	O
,	O
Table	O
3	O
bottom	O
)	O
,	O
where	O
the	O
32×4d	B-Method
ResNeXt	I-Method
-	I-Method
101	I-Method
outperforms	O
the	O
ResNet	B-Method
-	O
101	O
counterpart	O
by	O
0.8	O
%	O
.	O
	
Although	O
this	O
improvement	O
of	O
validation	B-Metric
error	I-Metric
is	O
smaller	O
than	O
that	O
of	O
the	O
50	B-Method
-	I-Method
layer	I-Method
case	O
,	O
the	O
improvement	O
of	O
training	B-Metric
error	I-Metric
is	O
still	O
big	O
(	O
20	O
%	O
for	O
ResNet	B-Method
-	I-Method
101	I-Method
and	O
16	O
%	O
for	O
32×4d	O
ResNeXt	B-Method
-	I-Method
101	I-Method
,	O
Fig	O
.	O
5	O
right	O
)	O
.	O
	
In	O
fact	O
,	O
more	O
training	O
data	O
will	O
enlarge	O
the	O
gap	O
of	O
validation	B-Metric
error	I-Metric
,	O
as	O
we	O
show	O
on	O
an	O
ImageNet	B-Material
-	I-Material
5	I-Material
K	I-Material
set	I-Material
in	O
the	O
next	O
subsection	O
.	O
	
Table	O
3	O
also	O
suggests	O
that	O
with	O
complexity	B-Metric
preserved	O
,	O
increasing	O
cardinality	O
at	O
the	O
price	O
of	O
reducing	O
width	O
starts	O
to	O
show	O
saturating	O
accuracy	B-Metric
when	O
the	O
bottleneck	O
width	O
is	O
[	O
reference	O
]	O
With	O
BN	O
,	O
for	O
the	O
equivalent	O
form	O
in	O
Fig	O
.	O
	
3	O
(	O
a	O
)	O
,	O
BN	B-Method
is	O
employed	O
after	O
aggregating	O
the	O
transformations	O
and	O
before	O
adding	O
to	O
the	O
shortcut	O
.	O
	
[	O
reference	O
]	O
.	O
	
(	O
ii	O
)	O
Going	O
wider	O
by	O
increasing	O
the	O
bottleneck	O
width	O
.	O
	
(	O
iii	O
)	O
Increasing	O
cardinality	O
by	O
doubling	O
C.	O
Table	O
4	O
shows	O
that	O
increasing	O
complexity	B-Metric
by	O
2×	O
consistently	O
reduces	O
error	B-Metric
vs.	O
the	O
ResNet	B-Method
-	O
101	O
baseline	O
(	O
22.0	O
%	O
)	O
.	O
	
But	O
the	O
improvement	O
is	O
small	O
when	O
going	O
deeper	O
(	O
ResNet	B-Method
-	O
200	O
,	O
by	O
0.3	O
%	O
)	O
or	O
wider	O
(	O
wider	O
ResNet	B-Method
-	O
101	O
,	O
by	O
0.7	O
%	O
)	O
.	O
	
On	O
the	O
contrary	O
,	O
increasing	O
cardinality	O
C	O
shows	O
much	O
better	O
results	O
than	O
going	O
deeper	O
or	O
wider	O
.	O
	
The	O
2×64d	O
ResNeXt	B-Method
-	I-Method
101	I-Method
(	O
i.e.	O
,	O
doubling	O
C	O
on	O
1×64d	O
ResNet	B-Method
-	O
101	O
baseline	O
and	O
keeping	O
the	O
width	O
)	O
reduces	O
the	O
top	B-Metric
-	I-Metric
1	I-Metric
error	I-Metric
by	O
1.3	O
%	O
to	O
20.7	O
%	O
.	O
	
The	O
64×4d	O
ResNeXt	B-Method
-	I-Method
101	I-Method
(	O
i.e.	O
,	O
doubling	O
C	O
on	O
32×4d	O
ResNeXt	B-Method
-	I-Method
101	I-Method
and	O
keeping	O
the	O
width	O
)	O
reduces	O
the	O
top	B-Metric
-	I-Metric
1	I-Metric
error	I-Metric
to	O
20.4	O
%	O
.	O
	
We	O
also	O
note	O
that	O
32×4d	O
ResNet	B-Method
-	O
101	O
(	O
21.2	O
%	O
)	O
performs	O
better	O
than	O
the	O
deeper	O
ResNet	B-Method
-	O
200	O
and	O
the	O
wider	O
ResNet	B-Method
-	O
101	O
,	O
even	O
though	O
it	O
has	O
only	O
∼50	O
%	O
complexity	B-Metric
.	O
	
This	O
again	O
shows	O
that	O
cardinality	O
is	O
a	O
more	O
effective	O
dimension	O
than	O
the	O
dimensions	O
of	O
depth	O
and	O
width	O
.	O
	
Removing	O
shortcuts	O
from	O
the	O
ResNeXt	B-Method
-	O
50	O
increases	O
the	O
error	B-Metric
by	O
3.9	O
points	O
to	O
26.1	O
%	O
.	O
	
Removing	O
shortcuts	O
from	O
its	O
ResNet	B-Method
-	O
50	O
counterpart	O
is	O
much	O
worse	O
(	O
31.2	O
%	O
)	O
.	O
	
These	O
comparisons	O
suggest	O
that	O
the	O
residual	O
connections	O
are	O
helpful	O
for	O
optimization	B-Task
,	O
whereas	O
aggregated	B-Method
transformations	I-Method
are	O
stronger	O
representations	O
,	O
as	O
shown	O
by	O
the	O
fact	O
that	O
they	O
perform	O
consistently	O
better	O
than	O
their	O
counterparts	O
with	O
or	O
without	O
residual	O
connections	O
.	O
	
Performance	O
.	O
	
For	O
simplicity	O
we	O
use	O
Torch	O
's	O
built	O
-	O
in	O
grouped	B-Method
convolution	I-Method
implementation	I-Method
,	O
without	O
special	O
optimization	O
.	O
	
We	O
note	O
that	O
this	O
implementation	O
was	O
brute	O
-	O
force	O
and	O
not	O
parallelization	O
-	O
friendly	O
.	O
	
On	O
8	O
GPUs	O
of	O
NVIDIA	B-Method
M40	I-Method
,	O
training	O
32×4d	O
ResNeXt	B-Method
-	O
101	O
in	O
Table	O
3	O
takes	O
0.95s	O
per	O
mini	O
-	O
batch	O
,	O
vs.	O
0.70s	O
of	O
ResNet	B-Method
-	O
101	O
baseline	O
that	O
has	O
similar	O
FLOPs	O
.	O
	
We	O
argue	O
that	O
this	O
is	O
a	O
reasonable	O
overhead	O
.	O
	
We	O
expect	O
carefully	O
engineered	O
lower	O
-	O
level	O
implementation	O
(	O
e.g.	O
,	O
in	O
CUDA	B-Method
)	O
will	O
reduce	O
this	O
overhead	O
.	O
	
We	O
also	O
expect	O
that	O
the	O
inference	B-Metric
time	I-Metric
on	O
CPUs	O
will	O
present	O
less	O
overhead	O
.	O
	
Training	O
the	O
2×complexity	B-Method
model	I-Method
(	O
64×4d	O
ResNeXt	B-Method
-	O
101	O
)	O
takes	O
1.7s	O
per	O
mini	O
-	O
batch	O
and	O
10	O
days	O
total	O
on	O
8	O
GPUs	O
.	O
	
Comparisons	O
with	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
.	O
	
Table	O
5	O
shows	O
more	O
results	O
of	O
single	B-Task
-	I-Task
crop	I-Task
testing	I-Task
on	O
the	O
ImageNet	B-Material
validation	I-Material
set	I-Material
.	O
	
In	O
addition	O
to	O
testing	O
a	O
224×224	O
crop	O
,	O
we	O
also	O
evaluate	O
a	O
320×320	O
crop	O
following	O
[	O
reference	O
]	O
.	O
Our	O
results	O
compare	O
favorably	O
with	O
ResNet	B-Method
,	O
Inception	B-Method
-	I-Method
v3	I-Method
/	I-Method
v4	I-Method
,	O
and	O
	
Inception	O
-	O
ResNet	B-Method
-	O
v2	O
,	O
achieving	O
a	O
single	O
-	O
crop	O
top	B-Metric
-	I-Metric
5	I-Metric
error	I-Metric
rate	I-Metric
of	O
4.4	O
%	O
.	O
	
In	O
addition	O
,	O
our	O
architecture	B-Method
design	I-Method
is	O
much	O
simpler	O
than	O
all	O
Inception	B-Method
models	I-Method
,	O
and	O
requires	O
considerably	O
fewer	O
hyper	O
-	O
parameters	O
to	O
be	O
set	O
by	O
hand	O
.	O
	
ResNeXt	B-Method
is	O
the	O
foundation	O
of	O
our	O
entries	O
to	O
the	O
ILSVRC	B-Task
2016	I-Task
classification	I-Task
task	I-Task
,	O
in	O
which	O
we	O
achieved	O
2	O
nd	O
place	O
.	O
	
We	O
note	O
that	O
many	O
models	O
(	O
including	O
ours	O
)	O
start	O
to	O
get	O
saturated	O
on	O
this	O
dataset	O
after	O
using	O
multi	B-Method
-	I-Method
scale	I-Method
and	I-Method
/	I-Method
or	I-Method
multicrop	I-Method
testing	I-Method
.	O
	
We	O
had	O
a	O
single	O
-	O
model	O
top	O
-	O
1	O
/	O
top	B-Metric
-	I-Metric
5	I-Metric
error	I-Metric
rates	I-Metric
of	O
17.7%	O
/	O
3.7	O
%	O
using	O
the	O
multi	O
-	O
scale	O
dense	O
testing	O
in	O
[	O
reference	O
]	O
,	O
on	O
par	O
with	O
Inception	O
-	O
ResNet	B-Method
-	O
v2	O
's	O
single	O
-	O
model	O
results	O
of	O
17.8%	O
/	O
3.7	O
%	O
that	O
adopts	O
multi	B-Method
-	I-Method
scale	I-Method
,	I-Method
multi	I-Method
-	I-Method
crop	I-Method
testing	I-Method
.	O
	
We	O
had	O
an	O
ensemble	O
result	O
of	O
3.03	O
%	O
	
top	B-Metric
-	I-Metric
5	I-Metric
error	I-Metric
on	O
the	O
test	O
set	O
,	O
on	O
par	O
with	O
the	O
winner	O
's	O
2.99	O
%	O
and	O
Inception	O
-	O
v4	O
/	O
InceptionResNet	O
-	O
v2	O
's	O
3.08	O
%	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
224×224	O
	
320×320	O
/	O
299×299	O
Table	O
5	O
.	O
	
State	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
on	O
the	O
ImageNet	B-Material
-	I-Material
1	I-Material
K	I-Material
validation	O
set	O
(	O
single	B-Task
-	I-Task
crop	I-Task
testing	I-Task
)	O
.	O
	
The	O
test	O
size	O
of	O
ResNet	B-Method
/	O
ResNeXt	B-Method
is	O
224×224	O
and	O
320×320	O
as	O
in	O
[	O
reference	O
]	O
and	O
of	O
the	O
Inception	B-Method
models	I-Method
is	O
299×299	O
.	O
	
Table	O
6	O
.	O
	
Error	B-Metric
(	O
%	O
)	O
on	O
ImageNet	B-Material
-	I-Material
5K.	I-Material
	
The	O
models	O
are	O
trained	O
on	O
ImageNet	B-Material
-	I-Material
5	I-Material
K	I-Material
and	O
tested	O
on	O
the	O
ImageNet	B-Material
-	I-Material
1	I-Material
K	I-Material
val	O
set	O
,	O
treated	O
as	O
a	O
5	O
K	B-Task
-	I-Task
way	I-Task
classification	I-Task
task	I-Task
or	O
a	O
1	O
K	B-Task
-	I-Task
way	I-Task
classification	I-Task
task	I-Task
at	O
test	O
time	O
.	O
	
ResNeXt	B-Method
and	O
its	O
ResNet	B-Method
counterpart	O
have	O
similar	O
complexity	B-Metric
.	O
	
The	O
error	O
is	O
evaluated	O
on	O
the	O
single	O
crop	O
of	O
224×224	O
pixels	O
.	O
	
section	O
:	O
Experiments	O
on	O
ImageNet	B-Material
-	I-Material
5	I-Material
K	I-Material
	
The	O
performance	O
on	O
ImageNet	B-Material
-	I-Material
1	I-Material
K	I-Material
appears	O
to	O
saturate	O
.	O
	
But	O
we	O
argue	O
that	O
this	O
is	O
not	O
because	O
of	O
the	O
capability	O
of	O
the	O
models	O
but	O
because	O
of	O
the	O
complexity	B-Metric
of	O
the	O
dataset	O
.	O
	
Next	O
we	O
evaluate	O
our	O
models	O
on	O
a	O
larger	O
ImageNet	B-Material
subset	I-Material
that	O
has	O
5000	O
categories	O
.	O
	
Our	O
5	B-Material
K	I-Material
dataset	I-Material
is	O
a	O
subset	O
of	O
the	O
full	B-Material
ImageNet	I-Material
-	I-Material
22	I-Material
K	I-Material
set	I-Material
[	O
reference	O
]	O
.	O
	
The	O
5000	O
categories	O
consist	O
of	O
the	O
original	O
ImageNet	B-Material
-	I-Material
1	I-Material
K	I-Material
categories	O
and	O
additional	O
4000	O
categories	O
that	O
have	O
the	O
largest	O
number	O
of	O
images	O
in	O
the	O
full	O
ImageNet	B-Material
set	I-Material
.	O
	
The	O
5	O
K	O
set	O
has	O
6.8	O
million	O
images	O
,	O
about	O
5×	O
of	O
the	O
1	O
K	O
set	O
.	O
	
There	O
is	O
no	O
official	O
train	O
/	O
val	O
split	O
available	O
,	O
so	O
we	O
opt	O
to	O
evaluate	O
on	O
the	O
original	O
ImageNet	B-Material
-	I-Material
1	I-Material
K	I-Material
validation	O
set	O
.	O
	
On	O
this	O
1	O
K	O
-	O
class	O
val	O
set	O
,	O
the	O
models	O
can	O
be	O
evaluated	O
as	O
a	O
5	O
K	B-Task
-	I-Task
way	I-Task
classification	I-Task
task	I-Task
(	O
all	O
labels	O
predicted	O
to	O
be	O
the	O
other	O
4	O
K	O
classes	O
are	O
automatically	O
erroneous	O
)	O
or	O
as	O
a	O
1	O
K	O
-	O
way	O
classification	B-Task
task	I-Task
(	O
softmax	B-Method
is	O
applied	O
only	O
on	O
the	O
1	O
K	O
classes	O
)	O
at	O
test	O
time	O
.	O
	
The	O
implementation	O
details	O
are	O
the	O
same	O
as	O
in	O
Sec	O
.	O
	
4	O
.	O
	
The	O
5	B-Method
K	I-Method
-	I-Method
training	I-Method
models	I-Method
are	O
all	O
trained	O
from	O
scratch	O
,	O
and	O
#	O
params	O
CIFAR	O
-	O
10	O
CIFAR	O
-	O
100	O
	
Wide	O
ResNet	B-Method
[	O
reference	O
]	O
	
36	O
are	O
trained	O
for	O
the	O
same	O
number	O
of	O
mini	O
-	O
batches	O
as	O
the	O
1	B-Method
K	I-Method
-	I-Method
training	I-Method
models	I-Method
(	O
so	O
1	O
/	O
5×	O
epochs	O
)	O
.	O
	
Table	O
6	O
and	O
Fig	O
.	O
	
6	O
show	O
the	O
comparisons	O
under	O
preserved	O
complexity	B-Metric
.	O
	
ResNeXt	B-Method
-	I-Method
50	I-Method
reduces	O
the	O
5	O
K	O
-	O
way	O
top	B-Metric
-	I-Metric
1	I-Metric
error	I-Metric
by	O
3.2	O
%	O
comparing	O
with	O
ResNet	B-Method
-	I-Method
50	I-Method
,	O
and	O
ResNetXt	B-Method
-	I-Method
101	I-Method
reduces	O
the	O
5	B-Metric
K	I-Metric
-	I-Metric
way	I-Metric
top	I-Metric
-	I-Metric
1	I-Metric
error	I-Metric
by	O
2.3	O
%	O
comparing	O
with	O
ResNet	B-Method
-	I-Method
101	I-Method
.	O
	
Similar	O
gaps	O
are	O
observed	O
on	O
the	O
1	B-Metric
K	I-Metric
-	I-Metric
way	I-Metric
error	I-Metric
.	O
	
These	O
demonstrate	O
the	O
stronger	O
representational	O
power	O
of	O
ResNeXt	B-Method
.	O
	
Moreover	O
,	O
we	O
find	O
that	O
the	O
models	O
trained	O
on	O
the	O
5	O
K	O
set	O
(	O
with	O
1	B-Metric
K	I-Metric
-	I-Metric
way	I-Metric
error	I-Metric
22.2%	O
/	O
5.7	O
%	O
in	O
Table	O
6	O
)	O
perform	O
competitively	O
comparing	O
with	O
those	O
trained	O
on	O
the	O
1	O
K	O
set	O
(	O
21.2%	O
/	O
5.6	O
%	O
in	O
Table	O
3	O
)	O
,	O
evaluated	O
on	O
the	O
same	O
1	O
K	O
-	O
way	O
classification	B-Task
task	I-Task
on	O
the	O
validation	O
set	O
.	O
	
This	O
result	O
is	O
achieved	O
without	O
increasing	O
the	O
training	B-Metric
time	I-Metric
(	O
due	O
to	O
the	O
same	O
number	O
of	O
mini	O
-	O
batches	O
)	O
and	O
without	O
fine	B-Method
-	I-Method
tuning	I-Method
.	O
	
We	O
argue	O
that	O
this	O
is	O
a	O
promising	O
result	O
,	O
given	O
that	O
the	O
training	B-Task
task	I-Task
of	O
classifying	B-Task
5	I-Task
K	I-Task
categories	I-Task
is	O
a	O
more	O
challenging	O
one	O
.	O
	
section	O
:	O
Experiments	O
on	O
CIFAR	O
	
We	O
conduct	O
more	O
experiments	O
on	O
CIFAR	O
-	O
10	O
and	O
100	O
datasets	O
[	O
reference	O
]	O
.	O
	
We	O
use	O
the	O
architectures	O
as	O
in	O
[	O
reference	O
]	O
and	O
replace	O
the	O
basic	O
residual	O
block	O
by	O
the	O
bottleneck	O
template	O
Our	O
networks	O
start	O
with	O
a	O
single	O
3×3	B-Method
conv	I-Method
layer	I-Method
,	O
followed	O
by	O
3	O
stages	O
each	O
having	O
3	O
residual	O
blocks	O
,	O
and	O
end	O
with	O
average	B-Method
pooling	I-Method
and	O
a	O
fully	B-Method
-	I-Method
connected	I-Method
classifier	I-Method
(	O
total	O
29	O
-	O
layer	O
deep	O
)	O
,	O
following	O
[	O
reference	O
]	O
.	O
	
We	O
adopt	O
the	O
same	O
translation	B-Method
and	I-Method
flipping	I-Method
data	I-Method
augmentation	I-Method
as	O
[	O
reference	O
]	O
.	O
Implementation	O
details	O
are	O
in	O
the	O
appendix	O
.	O
	
We	O
compare	O
two	O
cases	O
of	O
increasing	O
complexity	B-Metric
based	O
on	O
the	O
above	O
baseline	O
:	O
(	O
i	O
)	O
increase	O
cardinality	O
and	O
fix	O
all	O
widths	O
,	O
or	O
(	O
ii	O
)	O
increase	O
width	O
of	O
the	O
bottleneck	O
and	O
fix	O
cardinality	O
=	O
1	O
.	O
	
We	O
train	O
and	O
evaluate	O
a	O
series	O
of	O
networks	O
under	O
these	O
changes	O
.	O
	
Fig	O
.	O
	
7	O
shows	O
the	O
comparisons	O
of	O
test	B-Metric
error	I-Metric
rates	I-Metric
vs.	O
model	B-Metric
sizes	I-Metric
.	O
	
We	O
find	O
that	O
increasing	O
cardinality	O
is	O
more	O
effective	O
than	O
increasing	O
width	O
,	O
consistent	O
to	O
what	O
we	O
have	O
observed	O
on	O
ImageNet	B-Material
-	I-Material
1K.	I-Material
Table	O
7	O
shows	O
the	O
results	O
and	O
model	O
sizes	O
,	O
comparing	O
with	O
the	O
Wide	O
ResNet	B-Method
[	O
reference	O
]	O
which	O
is	O
the	O
best	O
published	O
record	O
.	O
	
Our	O
model	O
with	O
a	O
similar	O
model	O
size	O
(	O
34.4	O
M	O
)	O
shows	O
results	O
better	O
than	O
Wide	B-Method
ResNet	I-Method
.	O
	
Our	O
larger	O
method	O
achieves	O
3.58	O
%	O
test	B-Metric
error	I-Metric
(	O
average	O
of	O
10	O
runs	O
)	O
on	O
CIFAR	O
-	O
10	O
and	O
17.31	O
%	O
on	O
CIFAR	O
-	O
100	O
.	O
	
To	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
these	O
are	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
(	O
with	O
similar	O
data	O
augmentation	O
)	O
in	O
the	O
literature	O
including	O
unpublished	O
technical	O
reports	O
.	O
	
section	O
:	O
Experiments	O
on	O
COCO	O
object	O
detection	O
	
Next	O
we	O
evaluate	O
the	O
generalizability	O
on	O
the	O
COCO	O
object	O
detection	O
set	O
[	O
reference	O
]	O
.	O
	
We	O
train	O
the	O
models	O
on	O
the	O
80k	O
training	O
set	O
plus	O
a	O
35k	O
val	O
subset	O
and	O
evaluate	O
on	O
a	O
5k	O
val	O
subset	O
(	O
called	O
minival	B-Method
)	O
,	O
following	O
[	O
reference	O
]	O
.	O
	
We	O
evaluate	O
the	O
COCOstyle	B-Metric
Average	I-Metric
Precision	I-Metric
(	I-Metric
AP	I-Metric
)	O
as	O
well	O
as	O
AP@IoU=0.5	B-Metric
	
[	O
reference	O
]	O
.	O
	
We	O
adopt	O
the	O
basic	O
Faster	B-Method
R	I-Method
-	I-Method
CNN	I-Method
[	O
reference	O
]	O
and	O
follow	O
[	O
reference	O
]	O
to	O
plug	O
ResNet	B-Method
/	O
ResNeXt	B-Method
into	O
it	O
.	O
	
The	O
models	O
are	O
pre	O
-	O
trained	O
on	O
ImageNet	B-Material
-	I-Material
1	I-Material
K	I-Material
and	O
fine	O
-	O
tuned	O
on	O
the	O
detection	B-Task
set	I-Task
.	O
	
Implementation	O
details	O
are	O
in	O
the	O
appendix	O
.	O
	
Table	O
8	O
shows	O
the	O
comparisons	O
.	O
	
On	O
the	O
50	B-Method
-	I-Method
layer	I-Method
baseline	O
,	O
ResNeXt	B-Method
improves	O
AP@0.5	B-Metric
by	O
2.1	O
%	O
and	O
AP	B-Metric
by	O
1.0	O
%	O
,	O
without	O
increasing	O
complexity	B-Metric
.	O
	
ResNeXt	B-Method
shows	O
smaller	O
improvements	O
on	O
the	O
101	O
-	O
layer	O
baseline	O
.	O
	
We	O
conjecture	O
that	O
more	O
training	O
data	O
will	O
lead	O
to	O
a	O
larger	O
gap	O
,	O
as	O
observed	O
on	O
the	O
ImageNet	B-Material
-	I-Material
5	I-Material
K	I-Material
set	I-Material
.	O
	
It	O
is	O
also	O
worth	O
noting	O
that	O
recently	O
ResNeXt	B-Method
has	O
been	O
adopted	O
in	O
Mask	B-Method
R	I-Method
-	I-Method
CNN	I-Method
[	O
reference	O
]	O
that	O
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
COCO	B-Task
instance	I-Task
segmentation	I-Task
and	O
object	B-Task
detection	I-Task
tasks	I-Task
.	O
	
section	O
:	O
A.	O
Implementation	O
Details	O
:	O
CIFAR	O
	
We	O
train	O
the	O
models	O
on	O
the	O
50k	O
training	O
set	O
and	O
evaluate	O
on	O
the	O
10k	O
test	O
set	O
.	O
	
The	O
input	O
image	O
is	O
32×32	O
randomly	O
cropped	O
from	O
a	O
zero	O
-	O
padded	O
40×40	O
image	O
or	O
its	O
flipping	O
,	O
following	O
[	O
reference	O
]	O
.	O
	
No	O
other	O
data	B-Method
augmentation	I-Method
is	O
used	O
.	O
	
The	O
first	O
layer	O
is	O
3×3	O
conv	O
with	O
64	O
filters	O
.	O
	
There	O
are	O
3	O
stages	O
each	O
having	O
3	O
residual	O
blocks	O
,	O
and	O
the	O
output	O
map	O
size	O
is	O
32	O
,	O
16	O
,	O
and	O
8	O
for	O
each	O
stage	O
	
[	O
reference	O
]	O
.	O
	
The	O
network	O
ends	O
with	O
a	O
global	B-Method
average	I-Method
pooling	I-Method
and	O
a	O
fully	B-Method
-	I-Method
connected	I-Method
layer	I-Method
.	O
	
Width	O
is	O
increased	O
by	O
2×	O
when	O
the	O
stage	O
changes	O
(	O
downsampling	O
)	O
,	O
as	O
in	O
Sec	O
.	O
	
3.1	O
.	O
	
The	O
models	O
are	O
trained	O
on	O
8	O
GPUs	B-Method
with	O
a	O
mini	O
-	O
batch	O
size	O
of	O
128	O
,	O
with	O
a	O
weight	O
decay	O
of	O
0.0005	O
and	O
a	O
momentum	O
of	O
0.9	O
.	O
	
We	O
start	O
with	O
a	O
learning	B-Metric
rate	I-Metric
of	O
0.1	O
and	O
train	O
the	O
models	O
for	O
300	O
epochs	O
,	O
reducing	O
the	O
learning	B-Metric
rate	I-Metric
at	O
the	O
150	O
-	O
th	O
and	O
225	O
-	O
th	O
epoch	O
.	O
	
Other	O
implementation	O
details	O
are	O
as	O
in	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
B.	O
Implementation	O
Details	O
:	O
Object	B-Task
Detection	I-Task
	
We	O
adopt	O
the	O
Faster	O
R	B-Method
-	I-Method
CNN	I-Method
system	I-Method
[	O
	
reference	O
]	O
.	O
For	O
simplicity	O
we	O
do	O
not	O
share	O
the	O
features	O
between	O
RPN	B-Method
and	O
Fast	B-Method
R	I-Method
-	I-Method
CNN	I-Method
.	O
	
In	O
the	O
RPN	B-Method
step	I-Method
,	O
we	O
train	O
on	O
8	O
GPUs	B-Method
with	O
each	O
GPU	O
holding	O
2	O
images	O
per	O
mini	O
-	O
batch	O
and	O
256	O
anchors	O
per	O
image	O
.	O
	
We	O
train	O
the	O
RPN	B-Method
step	I-Method
for	O
120k	O
mini	O
-	O
batches	O
at	O
a	O
learning	B-Metric
rate	I-Metric
of	O
0.02	O
and	O
next	O
60k	O
at	O
0.002	O
.	O
	
In	O
the	O
Fast	B-Task
R	I-Task
-	I-Task
CNN	I-Task
step	I-Task
,	O
we	O
train	O
on	O
8	O
GPUs	B-Method
with	O
each	O
GPU	O
holding	O
1	O
image	O
and	O
64	O
regions	O
per	O
mini	O
-	O
batch	O
.	O
	
We	O
train	O
the	O
Fast	B-Method
R	I-Method
-	I-Method
CNN	I-Method
step	I-Method
for	O
120k	O
mini	O
-	O
batches	O
at	O
a	O
learning	B-Metric
rate	I-Metric
of	O
0.005	O
and	O
next	O
60k	O
at	O
0.0005	O
,	O
We	O
use	O
a	O
weight	O
decay	O
of	O
0.0001	O
and	O
a	O
momentum	O
of	O
0.9	O
.	O
	
Other	O
implementation	O
details	O
are	O
as	O
in	O
https:	O
//	O
github.com	O
/	O
rbgirshick	O
/	O
py	O
-	O
faster	O
-	O
rcnn	O
.	O
	
section	O
:	O
	
section	O
:	O
Acknowledgment	O
	
S.X.	O
and	O
Z.T.	O
's	O
research	O
was	O
partly	O
supported	O
by	O
NSF	O
IIS	O
-	O
1618477	O
.	O
	
The	O
authors	O
would	O
like	O
to	O
thank	O
Tsung	O
-	O
Yi	O
Lin	O
and	O
Priya	O
Goyal	O
for	O
valuable	O
discussions	O
.	O
	
section	O
:	O
	
VQA	B-Task
:	O
Visual	B-Task
Question	I-Task
Answering	I-Task
	
section	O
:	O
	
Abstract	O
-	O
We	O
propose	O
the	O
task	O
of	O
free	O
-	O
form	O
and	O
open	O
-	O
ended	O
Visual	B-Task
Question	I-Task
Answering	I-Task
(	O
VQA	B-Task
)	O
.	O
	
Given	O
an	O
image	O
and	O
a	O
natural	O
language	O
question	O
about	O
the	O
image	O
,	O
the	O
task	O
is	O
to	O
provide	O
an	O
accurate	O
natural	O
language	O
answer	O
.	O
	
Mirroring	B-Task
real	I-Task
-	I-Task
world	I-Task
scenarios	I-Task
,	O
such	O
as	O
helping	O
the	O
visually	O
impaired	O
,	O
both	O
the	O
questions	O
and	O
answers	O
are	O
open	O
-	O
ended	O
.	O
	
Visual	O
questions	O
selectively	O
target	O
different	O
areas	O
of	O
an	O
image	O
,	O
including	O
background	O
details	O
and	O
underlying	O
context	O
.	O
	
As	O
a	O
result	O
,	O
a	O
system	O
that	O
succeeds	O
at	O
VQA	B-Task
typically	O
needs	O
a	O
more	O
detailed	O
understanding	O
of	O
the	O
image	O
and	O
complex	O
reasoning	O
than	O
a	O
system	O
producing	O
generic	B-Task
image	I-Task
captions	I-Task
.	O
	
Moreover	O
,	O
VQA	B-Task
is	O
amenable	O
to	O
automatic	B-Task
evaluation	I-Task
,	O
since	O
many	O
open	O
-	O
ended	O
answers	O
contain	O
only	O
a	O
few	O
words	O
or	O
a	O
closed	O
set	O
of	O
answers	O
that	O
can	O
be	O
provided	O
in	O
a	O
multiple	O
-	O
choice	O
format	O
.	O
	
We	O
provide	O
a	O
dataset	O
containing	O
∼0.25	O
M	O
images	O
,	O
∼0.76	O
M	O
questions	O
,	O
and	O
	
∼10	O
	
M	O
answers	O
(	O
www.visualqa.org	O
)	O
,	O
and	O
discuss	O
the	O
information	O
it	O
provides	O
.	O
	
Numerous	O
baselines	O
and	O
methods	O
for	O
VQA	B-Task
are	O
provided	O
and	O
compared	O
with	O
human	B-Metric
performance	I-Metric
.	O
	
Our	O
VQA	B-Task
demo	O
is	O
available	O
on	O
CloudCV	O
(	O
http:	O
//	O
cloudcv.org	O
/	O
vqa	O
)	O
.	O
	
section	O
:	O
INTRODUCTION	O
	
We	O
are	O
witnessing	O
a	O
renewed	O
excitement	O
in	O
multi	O
-	O
discipline	O
Artificial	O
Intelligence	O
(	O
AI	O
)	O
research	O
problems	O
.	O
	
In	O
particular	O
,	O
research	O
in	O
image	B-Task
and	I-Task
video	I-Task
captioning	I-Task
that	O
combines	O
Computer	B-Method
Vision	I-Method
(	O
CV	B-Method
)	O
,	O
Natural	B-Method
Language	I-Method
Processing	I-Method
(	O
NLP	B-Method
)	O
,	O
and	O
Knowledge	B-Method
Representation	I-Method
&	I-Method
Reasoning	I-Method
(	O
KR	B-Method
)	O
has	O
dramatically	O
increased	O
in	O
the	O
past	O
year	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
.	O
Part	O
of	O
this	O
excitement	O
stems	O
from	O
a	O
belief	O
that	O
multi	B-Task
-	I-Task
discipline	I-Task
tasks	I-Task
like	O
image	B-Task
captioning	I-Task
are	O
a	O
step	O
towards	O
solving	O
AI	O
.	O
	
However	O
,	O
the	O
current	O
state	O
of	O
the	O
art	O
demonstrates	O
that	O
a	O
coarse	O
scene	O
-	O
level	O
understanding	O
of	O
an	O
image	O
paired	O
with	O
word	O
n	O
-	O
gram	O
statistics	O
suffices	O
to	O
generate	O
reasonable	O
image	B-Task
captions	I-Task
,	O
which	O
suggests	O
image	B-Task
captioning	I-Task
may	O
not	O
be	O
as	O
"	O
AI	O
-	O
complete	O
"	O
as	O
desired	O
.	O
	
What	O
makes	O
for	O
a	O
compelling	O
"	O
AI	B-Task
-	I-Task
complete	I-Task
"	I-Task
task	I-Task
?	O
	
We	O
believe	O
that	O
in	O
order	O
to	O
spawn	O
the	O
next	O
generation	O
of	O
AI	B-Method
algorithms	I-Method
,	O
an	O
ideal	O
task	O
should	O
(	O
i	O
)	O
require	O
multi	O
-	O
modal	O
knowledge	O
beyond	O
a	O
single	O
sub	O
-	O
domain	O
(	O
such	O
as	O
CV	B-Method
)	O
and	O
(	O
ii	O
)	O
have	O
a	O
well	O
-	O
defined	O
quantitative	B-Metric
evaluation	I-Metric
metric	I-Metric
to	O
track	O
progress	O
.	O
	
For	O
some	O
tasks	O
,	O
such	O
as	O
image	B-Task
captioning	I-Task
,	O
automatic	B-Task
evaluation	I-Task
is	O
still	O
a	O
difficult	O
and	O
open	O
research	O
problem	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
	
[	O
reference	O
]	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
introduce	O
the	O
task	O
of	O
free	B-Task
-	I-Task
form	I-Task
and	I-Task
openended	I-Task
Visual	I-Task
Question	I-Task
Answering	I-Task
(	O
VQA	B-Task
)	O
.	O
	
A	O
VQA	B-Task
system	O
takes	O
as	O
input	O
an	O
image	O
and	O
a	O
free	O
-	O
form	O
,	O
open	O
-	O
ended	O
,	O
naturallanguage	O
question	O
about	O
the	O
image	O
and	O
produces	O
a	O
naturallanguage	O
answer	O
as	O
the	O
output	O
.	O
	
This	O
goal	B-Task
-	I-Task
driven	I-Task
task	I-Task
is	O
applicable	O
to	O
scenarios	O
encountered	O
when	O
visually	O
-	O
impaired	O
users	O
[	O
reference	O
]	O
or	O
intelligence	B-Task
analysts	I-Task
actively	O
elicit	O
visual	O
information	O
.	O
	
Example	O
questions	O
are	O
shown	O
in	O
Fig	O
.	O
	
1	O
.	O
	
Open	O
-	O
ended	O
questions	O
require	O
a	O
potentially	O
vast	O
set	O
of	O
AI	B-Task
capabilities	I-Task
to	O
answer	O
-	O
fine	B-Method
-	I-Method
grained	I-Method
recognition	I-Method
(	O
e.g.	O
,	O
"	O
What	O
kind	O
of	O
cheese	O
is	O
on	O
the	O
pizza	O
?	O
"	O
)	O
,	O
object	B-Method
detection	I-Method
(	O
e.g.	O
,	O
"	O
How	O
many	O
bikes	O
are	O
there	O
?	O
"	O
)	O
,	O
activity	B-Method
recognition	I-Method
(	O
e.g.	O
,	O
"	O
Is	O
this	O
man	O
crying	O
?	O
"	O
)	O
,	O
knowledge	B-Method
base	I-Method
reasoning	I-Method
(	O
e.g.	O
,	O
"	O
Is	O
this	O
a	O
vegetarian	O
pizza	O
?	O
"	O
)	O
,	O
and	O
commonsense	B-Method
reasoning	I-Method
(	O
e.g.	O
,	O
"	O
Does	O
this	O
person	O
have	O
20	O
/	O
20	O
vision	O
?	O
"	O
,	O
"	O
Is	O
this	O
person	O
expecting	O
company	O
?	O
"	O
)	O
.	O
	
VQA	B-Task
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
is	O
also	O
amenable	O
to	O
automatic	B-Task
quantitative	I-Task
evaluation	I-Task
,	O
making	O
it	O
possible	O
to	O
effectively	O
track	O
progress	O
on	O
this	O
task	O
.	O
	
While	O
the	O
answer	O
to	O
many	O
questions	O
is	O
simply	O
"	O
yes	O
"	O
or	O
"	O
no	O
"	O
,	O
the	O
process	O
for	O
determining	O
a	O
correct	O
answer	O
is	O
typically	O
far	O
from	O
trivial	O
(	O
e.g.	O
in	O
Fig	O
.	O
1	O
,	O
"	O
Does	O
this	O
person	O
have	O
20	O
/	O
20	O
vision	O
?	O
"	O
)	O
.	O
	
Moreover	O
,	O
since	O
questions	O
about	O
images	O
often	O
tend	O
to	O
seek	O
specific	O
information	O
,	O
simple	O
oneto	O
-	O
three	O
word	O
answers	O
are	O
sufficient	O
for	O
many	O
questions	O
.	O
	
In	O
such	O
scenarios	O
,	O
we	O
can	O
easily	O
evaluate	O
a	O
proposed	O
algorithm	O
by	O
the	O
number	O
of	O
questions	O
it	O
answers	O
correctly	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
present	O
both	O
an	O
open	B-Task
-	I-Task
ended	I-Task
answering	I-Task
task	I-Task
and	O
a	O
multiplechoice	B-Task
task	I-Task
[	O
reference	O
]	O
,	O
	
[	O
reference	O
]	O
.	O
Unlike	O
the	O
open	B-Task
-	I-Task
ended	I-Task
task	I-Task
that	O
requires	O
a	O
free	O
-	O
form	O
response	O
,	O
the	O
multiple	B-Task
-	I-Task
choice	I-Task
task	I-Task
only	O
requires	O
an	O
algorithm	O
to	O
pick	O
from	O
a	O
predefined	O
list	O
of	O
possible	O
answers	O
.	O
	
We	O
present	O
a	O
large	O
dataset	O
that	O
contains	O
204	O
,	O
721	O
images	O
from	O
the	O
MS	B-Material
COCO	I-Material
dataset	I-Material
[	O
reference	O
]	O
and	O
a	O
newly	O
created	O
abstract	B-Material
scene	I-Material
dataset	I-Material
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
that	O
contains	O
50	O
,	O
000	O
scenes	O
.	O
	
The	O
MS	B-Material
COCO	I-Material
dataset	I-Material
has	O
images	O
depicting	O
diverse	O
and	O
complex	O
scenes	O
that	O
are	O
effective	O
at	O
eliciting	O
compelling	O
and	O
diverse	O
questions	O
.	O
	
We	O
collected	O
a	O
new	O
dataset	O
of	O
"	O
realistic	O
"	O
abstract	B-Material
scenes	I-Material
to	O
enable	O
research	O
focused	O
only	O
on	O
the	O
high	O
-	O
level	O
reasoning	O
required	O
for	O
VQA	B-Task
by	O
removing	O
the	O
need	O
to	O
parse	O
real	B-Material
images	I-Material
.	O
	
Three	O
questions	O
were	O
collected	O
for	O
each	O
image	O
or	O
scene	O
.	O
	
Each	O
question	O
was	O
answered	O
by	O
ten	O
subjects	O
along	O
with	O
their	O
confidence	O
.	O
	
The	O
dataset	O
contains	O
over	O
760	O
K	O
questions	O
with	O
around	O
10	O
M	O
answers	O
.	O
	
While	O
the	O
use	O
of	O
open	O
-	O
ended	O
questions	O
offers	O
many	O
benefits	O
,	O
it	O
is	O
still	O
useful	O
to	O
understand	O
the	O
types	O
of	O
questions	O
that	O
are	O
being	O
asked	O
and	O
which	O
types	O
various	O
algorithms	O
may	O
be	O
good	O
at	O
answering	O
.	O
	
To	O
this	O
end	O
,	O
we	O
analyze	O
the	O
types	O
of	O
questions	O
asked	O
and	O
the	O
types	O
of	O
answers	O
provided	O
.	O
	
Through	O
several	O
visualizations	B-Method
,	O
we	O
demonstrate	O
the	O
astonishing	O
diversity	O
of	O
the	O
questions	O
asked	O
.	O
	
We	O
also	O
explore	O
how	O
the	O
information	O
content	O
of	O
questions	O
and	O
their	O
answers	O
differs	O
from	O
image	O
captions	O
.	O
	
For	O
baselines	O
,	O
we	O
offer	O
several	O
approaches	O
that	O
use	O
a	O
combination	O
of	O
both	O
text	O
and	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
visual	B-Method
features	I-Method
	
[	O
reference	O
]	O
.	O
As	O
part	O
of	O
the	O
VQA	B-Task
initiative	I-Task
,	O
we	O
will	O
organize	O
an	O
annual	O
challenge	O
and	O
associated	O
workshop	O
to	O
discuss	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
and	O
best	O
practices	O
.	O
	
VQA	B-Task
poses	O
a	O
rich	O
set	O
of	O
challenges	O
,	O
many	O
of	O
which	O
have	O
been	O
viewed	O
as	O
the	O
holy	O
grail	O
of	O
automatic	B-Task
image	I-Task
understanding	I-Task
and	O
AI	O
in	O
general	O
.	O
	
However	O
,	O
it	O
includes	O
as	O
building	O
blocks	O
several	O
components	O
that	O
the	O
CV	B-Method
,	O
NLP	B-Method
,	O
and	O
KR	B-Method
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
communities	O
have	O
made	O
significant	O
progress	O
on	O
during	O
the	O
past	O
few	O
decades	O
.	O
	
VQA	B-Task
provides	O
an	O
attractive	O
balance	O
between	O
pushing	O
the	O
state	O
of	O
the	O
art	O
,	O
while	O
being	O
accessible	O
enough	O
for	O
the	O
communities	O
to	O
start	O
making	O
progress	O
on	O
the	O
task	O
.	O
	
section	O
:	O
RELATED	O
WORK	O
	
VQA	B-Task
Efforts	O
.	O
	
Several	O
recent	O
papers	O
have	O
begun	O
to	O
study	O
visual	B-Task
question	I-Task
answering	I-Task
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
	
reference	O
]	O
.	O
However	O
,	O
unlike	O
our	O
work	O
,	O
these	O
are	O
fairly	O
restricted	O
(	O
sometimes	O
synthetic	O
)	O
settings	O
with	O
small	O
datasets	O
.	O
	
For	O
instance	O
,	O
[	O
reference	O
]	O
only	O
considers	O
questions	O
whose	O
answers	O
come	O
from	O
a	O
predefined	O
closed	O
world	O
of	O
16	O
basic	O
colors	O
or	O
894	O
object	O
categories	O
.	O
	
[	O
reference	O
]	O
also	O
considers	O
questions	O
generated	O
from	O
templates	O
from	O
a	O
fixed	O
vocabulary	O
of	O
objects	O
,	O
attributes	O
,	O
relationships	O
between	O
objects	O
,	O
etc	O
.	O
	
In	O
contrast	O
,	O
our	O
proposed	O
task	O
involves	O
open	O
-	O
ended	O
,	O
free	O
-	O
form	O
questions	O
and	O
answers	O
provided	O
by	O
humans	O
.	O
	
Our	O
goal	O
is	O
to	O
increase	O
the	O
diversity	O
of	O
knowledge	O
and	O
kinds	O
of	O
reasoning	O
needed	O
to	O
provide	O
correct	O
answers	O
.	O
	
Critical	O
to	O
achieving	O
success	O
on	O
this	O
more	O
difficult	O
and	O
unconstrained	B-Task
task	I-Task
,	O
our	O
VQA	B-Material
dataset	I-Material
is	O
two	O
orders	O
of	O
magnitude	O
larger	O
than	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
(	O
>	O
250	O
,	O
000	O
vs.	O
2	O
,	O
591	O
and	O
1	O
,	O
449	O
images	O
respectively	O
)	O
.	O
	
The	O
proposed	O
VQA	B-Task
task	I-Task
has	O
connections	O
to	O
other	O
related	O
work	O
:	O
[	O
reference	O
]	O
has	O
studied	O
joint	B-Task
parsing	I-Task
of	I-Task
videos	I-Task
and	O
corresponding	O
text	O
to	O
answer	O
queries	O
on	O
two	O
datasets	O
containing	O
15	O
video	O
clips	O
each	O
.	O
	
[	O
reference	O
]	O
uses	O
crowdsourced	O
workers	O
to	O
answer	O
questions	O
about	O
visual	O
content	O
asked	O
by	O
visually	O
-	O
impaired	O
users	O
.	O
	
In	O
concurrent	O
work	O
,	O
[	O
reference	O
]	O
proposed	O
combining	O
an	O
LSTM	B-Method
for	O
the	O
question	O
with	O
a	O
CNN	B-Method
for	O
the	O
image	O
to	O
generate	O
an	O
answer	O
.	O
	
In	O
their	O
model	O
,	O
the	O
LSTM	B-Method
question	O
representation	O
is	O
conditioned	O
on	O
the	O
CNN	O
image	O
features	O
at	O
each	O
time	O
step	O
,	O
and	O
the	O
final	O
LSTM	B-Method
hidden	O
state	O
is	O
used	O
to	O
sequentially	O
decode	O
the	O
answer	O
phrase	O
.	O
	
In	O
contrast	O
,	O
the	O
model	O
developed	O
in	O
this	O
paper	O
explores	O
"	O
late	B-Task
fusion	I-Task
"	I-Task
-	O
i.e	O
.	O
,	O
the	O
LSTM	B-Method
question	O
representation	O
and	O
the	O
CNN	O
image	O
features	O
are	O
computed	O
independently	O
,	O
fused	O
via	O
an	O
element	B-Method
-	I-Method
wise	I-Method
multiplication	I-Method
,	O
and	O
then	O
passed	O
through	O
fullyconnected	B-Method
layers	I-Method
to	O
generate	O
a	O
softmax	O
distribution	O
over	O
output	O
answer	O
classes	O
.	O
	
[	O
reference	O
]	O
generates	O
abstract	B-Material
scenes	I-Material
to	O
capture	O
visual	O
common	O
sense	O
relevant	O
to	O
answering	O
(	O
purely	O
textual	O
)	O
fill	B-Task
-	I-Task
inthe	I-Task
-	I-Task
blank	I-Task
and	I-Task
visual	I-Task
paraphrasing	I-Task
questions	I-Task
.	O
	
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
use	O
visual	O
information	O
to	O
assess	O
the	O
plausibility	O
of	O
common	O
sense	O
assertions	O
.	O
	
[	O
reference	O
]	O
introduced	O
a	O
dataset	O
of	O
10k	O
images	O
and	O
prompted	O
captions	O
that	O
describe	O
specific	O
aspects	O
of	O
a	O
scene	O
(	O
e.g.	O
,	O
individual	O
objects	O
,	O
what	O
will	O
happen	O
next	O
)	O
.	O
	
Concurrent	O
with	O
our	O
work	O
,	O
[	O
reference	O
]	O
collected	O
questions	O
&	O
answers	O
in	O
Chinese	O
(	O
later	O
translated	O
to	O
English	O
by	O
humans	O
)	O
for	O
COCO	B-Material
images	I-Material
.	O
	
[	O
reference	O
]	O
automatically	O
generated	O
four	O
types	O
of	O
questions	O
(	O
object	O
,	O
count	O
,	O
color	O
,	O
location	O
)	O
using	O
COCO	O
captions	O
.	O
	
Text	B-Method
-	I-Method
based	I-Method
Q	I-Method
&	I-Method
A	I-Method
is	O
a	O
well	O
studied	O
problem	O
in	O
the	O
NLP	B-Task
and	I-Task
text	I-Task
processing	I-Task
communities	I-Task
(	O
recent	O
examples	O
being	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
)	O
.	O
	
Other	O
related	O
textual	B-Task
tasks	I-Task
include	O
sentence	B-Task
completion	I-Task
(	O
e.g.	O
,	O
[	O
reference	O
]	O
with	O
multiple	O
-	O
choice	O
answers	O
)	O
.	O
	
These	O
approaches	O
provide	O
inspiration	O
for	O
VQA	B-Task
techniques	O
.	O
	
One	O
key	O
concern	O
in	O
text	B-Task
is	O
the	O
grounding	B-Task
of	I-Task
questions	I-Task
.	O
	
For	O
instance	O
,	O
[	O
reference	O
]	O
synthesized	O
textual	O
descriptions	O
and	O
QA	O
-	O
pairs	O
grounded	O
in	O
a	O
simulation	O
of	O
actors	O
and	O
objects	O
in	O
a	O
fixed	O
set	O
of	O
locations	O
.	O
	
VQA	B-Task
is	O
naturally	O
grounded	O
in	O
images	O
-	O
requiring	O
	
the	O
understanding	O
of	O
both	O
text	O
(	O
questions	O
)	O
and	O
vision	O
(	O
images	O
)	O
.	O
	
Our	O
questions	O
are	O
generated	O
by	O
humans	O
,	O
making	O
the	O
need	O
for	O
commonsense	O
knowledge	O
and	O
complex	O
reasoning	O
more	O
essential	O
.	O
	
Describing	B-Task
Visual	I-Task
Content	I-Task
.	O
	
Related	O
to	O
VQA	B-Task
are	O
the	O
tasks	O
of	O
image	B-Task
tagging	I-Task
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
image	B-Task
captioning	I-Task
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
and	O
video	B-Task
captioning	I-Task
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
where	O
words	O
or	O
sentences	O
are	O
generated	O
to	O
describe	O
visual	O
content	O
.	O
	
While	O
these	O
tasks	O
require	O
both	O
visual	O
and	O
semantic	O
knowledge	O
,	O
captions	O
can	O
often	O
be	O
non	O
-	O
specific	O
(	O
e.g.	O
,	O
observed	O
by	O
[	O
reference	O
]	O
)	O
.	O
	
The	O
questions	O
in	O
VQA	B-Task
require	O
detailed	O
specific	O
information	O
about	O
the	O
image	O
for	O
which	O
generic	O
image	O
captions	O
are	O
of	O
little	O
use	O
	
[	O
reference	O
]	O
.	O
Other	O
Vision	B-Task
+	I-Task
Language	I-Task
Tasks	I-Task
.	O
	
Several	O
recent	O
papers	O
have	O
explored	O
tasks	O
at	O
the	O
intersection	O
of	O
vision	B-Task
and	I-Task
language	I-Task
that	O
are	O
easier	O
to	O
evaluate	O
than	O
image	B-Task
captioning	I-Task
,	O
such	O
as	O
coreference	B-Task
resolution	I-Task
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
or	O
generating	O
referring	O
expressions	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
for	O
a	O
particular	O
object	O
in	O
an	O
image	O
that	O
would	O
allow	O
a	O
human	O
to	O
identify	O
which	O
object	O
is	O
being	O
referred	O
to	O
(	O
e.g.	O
,	O
"	O
the	O
one	O
in	O
a	O
red	O
shirt	O
"	O
,	O
"	O
the	O
dog	O
on	O
the	O
left	O
"	O
)	O
.	O
	
While	O
task	O
-	O
driven	O
and	O
concrete	O
,	O
a	O
limited	O
set	O
of	O
visual	O
concepts	O
(	O
e.g.	O
,	O
color	O
,	O
location	O
)	O
tend	O
to	O
be	O
captured	O
by	O
referring	O
expressions	O
.	O
	
As	O
we	O
demonstrate	O
,	O
a	O
richer	O
variety	O
of	O
visual	O
concepts	O
emerge	O
from	O
visual	O
questions	O
and	O
their	O
answers	O
.	O
	
section	O
:	O
VQA	B-Task
DATASET	O
COLLECTION	O
	
We	O
now	O
describe	O
the	O
Visual	B-Task
Question	I-Task
Answering	I-Task
	
(	O
VQA	B-Task
)	O
dataset	O
.	O
	
We	O
begin	O
by	O
describing	O
the	O
real	B-Material
images	I-Material
and	O
abstract	B-Material
scenes	I-Material
used	O
to	O
collect	O
the	O
questions	O
.	O
	
Next	O
,	O
we	O
describe	O
our	O
process	O
of	O
collecting	O
questions	O
and	O
their	O
corresponding	O
answers	O
.	O
	
Analysis	O
of	O
the	O
questions	O
and	O
answers	O
gathered	O
as	O
well	O
as	O
baselines	O
'	O
&	O
methods	O
'	O
results	O
are	O
provided	O
in	O
following	O
sections	O
.	O
	
Real	B-Material
Images	I-Material
.	O
	
We	O
use	O
the	O
123	O
,	O
287	O
training	O
and	O
validation	O
images	O
and	O
81	O
,	O
434	O
test	O
images	O
from	O
the	O
newly	O
-	O
released	O
Microsoft	B-Material
Common	I-Material
Objects	I-Material
in	I-Material
Context	I-Material
(	O
MS	B-Material
COCO	I-Material
)	O
	
[	O
reference	O
]	O
dataset	O
.	O
	
The	O
MS	B-Material
COCO	I-Material
dataset	I-Material
was	O
gathered	O
to	O
find	O
images	O
containing	O
multiple	O
objects	O
and	O
rich	O
contextual	O
information	O
.	O
	
Given	O
the	O
visual	O
complexity	O
of	O
these	O
images	O
,	O
they	O
are	O
well	O
-	O
suited	O
for	O
our	O
VQA	B-Task
task	I-Task
.	O
	
The	O
more	O
diverse	O
our	O
collection	O
of	O
images	O
,	O
the	O
more	O
diverse	O
,	O
comprehensive	O
,	O
and	O
interesting	O
the	O
resultant	O
set	O
of	O
questions	O
and	O
their	O
answers	O
.	O
	
Abstract	O
Scenes	O
.	O
	
The	O
VQA	B-Task
task	I-Task
with	O
real	B-Material
images	I-Material
requires	O
the	O
use	O
of	O
complex	O
and	O
often	O
noisy	O
visual	B-Method
recognizers	I-Method
.	O
	
To	O
attract	O
researchers	O
interested	O
in	O
exploring	O
the	O
high	B-Task
-	I-Task
level	I-Task
reasoning	I-Task
required	O
for	O
VQA	B-Task
,	O
but	O
not	O
the	O
low	B-Task
-	I-Task
level	I-Task
vision	I-Task
tasks	I-Task
,	O
we	O
create	O
a	O
new	O
abstract	B-Material
scenes	I-Material
dataset	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
containing	O
50	O
K	O
scenes	O
.	O
	
The	O
dataset	O
contains	O
20	O
"	O
paperdoll	O
"	O
human	B-Method
models	I-Method
[	O
reference	O
]	O
spanning	O
genders	O
,	O
races	O
,	O
and	O
ages	O
with	O
8	O
different	O
expressions	O
.	O
	
The	O
limbs	O
are	O
adjustable	O
to	O
allow	O
for	O
continuous	O
pose	O
variations	O
.	O
	
The	O
clipart	O
may	O
be	O
used	O
to	O
depict	O
both	O
indoor	O
and	O
outdoor	O
scenes	O
.	O
	
The	O
set	O
contains	O
over	O
100	O
objects	O
and	O
31	O
animals	O
in	O
various	O
poses	O
.	O
	
The	O
use	O
of	O
this	O
clipart	O
enables	O
the	O
creation	O
of	O
more	O
realistic	O
scenes	O
(	O
see	O
bottom	O
row	O
of	O
Fig	O
.	O
2	O
)	O
that	O
more	O
closely	O
mirror	O
real	B-Material
images	I-Material
than	O
previous	O
papers	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
	
[	O
reference	O
]	O
.	O
See	O
the	O
appendix	O
for	O
the	O
user	O
interface	O
,	O
additional	O
details	O
,	O
and	O
examples	O
.	O
	
Splits	O
.	O
	
For	O
real	B-Material
images	I-Material
,	O
we	O
follow	O
the	O
same	O
train	B-Method
/	I-Method
val	I-Method
/	I-Method
test	I-Method
split	I-Method
strategy	I-Method
as	O
the	O
MC	B-Material
COCO	I-Material
dataset	I-Material
[	O
reference	O
]	O
(	O
including	O
testdev	O
,	O
test	O
-	O
standard	O
,	O
test	O
-	O
challenge	O
,	O
test	O
-	O
reserve	O
)	O
.	O
	
For	O
the	O
VQA	B-Task
challenge	O
(	O
see	O
section	O
6	O
)	O
,	O
test	O
-	O
dev	O
is	O
used	O
for	O
debugging	O
and	O
validation	O
experiments	O
and	O
allows	O
for	O
unlimited	O
submission	O
to	O
the	O
evaluation	O
server	O
.	O
	
Test	O
-	O
standard	O
is	O
the	O
'	O
default	O
'	O
test	O
data	O
for	O
the	O
VQA	B-Task
competition	I-Task
.	O
	
When	O
comparing	O
to	O
the	O
state	O
of	O
the	O
art	O
(	O
e.g.	O
,	O
in	O
papers	O
)	O
,	O
results	O
should	O
be	O
reported	O
on	O
test	O
-	O
standard	O
.	O
	
Test	O
-	O
standard	O
is	O
also	O
used	O
to	O
maintain	O
a	O
public	O
leaderboard	O
that	O
is	O
updated	O
upon	O
submission	O
.	O
	
Test	O
-	O
reserve	O
is	O
used	O
to	O
protect	O
against	O
possible	O
overfitting	O
.	O
	
If	O
there	O
are	O
substantial	O
differences	O
between	O
a	O
method	O
's	O
scores	O
on	O
test	O
-	O
standard	O
and	O
test	O
-	O
reserve	O
,	O
this	O
raises	O
a	O
red	O
-	O
flag	O
and	O
prompts	O
further	O
investigation	O
.	O
	
Results	O
on	O
test	O
-	O
reserve	O
are	O
not	O
publicly	O
revealed	O
.	O
	
Finally	O
,	O
test	O
-	O
challenge	O
is	O
used	O
to	O
determine	O
the	O
winners	O
of	O
the	O
challenge	O
.	O
	
For	O
abstract	B-Material
scenes	I-Material
,	O
we	O
created	O
splits	O
for	O
standardization	B-Task
,	O
separating	O
the	O
scenes	O
into	O
20K	O
/	O
10K	O
/	O
20	O
K	O
for	O
train	O
/	O
val	O
/	O
test	O
splits	O
,	O
respectively	O
.	O
	
There	O
are	O
no	O
subsplits	O
(	O
test	O
-	O
dev	O
,	O
test	O
-	O
standard	O
,	O
test	O
-	O
challenge	O
,	O
test	O
-	O
reserve	O
)	O
for	O
abstract	B-Material
scenes	I-Material
.	O
	
Captions	O
.	O
	
The	O
MS	B-Material
COCO	I-Material
dataset	I-Material
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
already	O
contains	O
five	O
single	O
-	O
sentence	O
captions	O
for	O
all	O
images	O
.	O
	
We	O
also	O
collected	O
five	O
single	O
-	O
captions	O
for	O
all	O
abstract	B-Material
scenes	I-Material
using	O
the	O
same	O
user	O
interface	O
1	O
for	O
collection	O
.	O
	
Questions	O
.	O
	
Collecting	O
interesting	O
,	O
diverse	O
,	O
and	O
well	O
-	O
posed	O
questions	O
is	O
a	O
significant	O
challenge	O
.	O
	
Many	O
simple	O
questions	O
may	O
only	O
require	O
low	O
-	O
level	O
computer	O
vision	O
knowledge	O
,	O
such	O
as	O
"	O
What	O
color	O
is	O
the	O
cat	O
?	O
"	O
or	O
"	O
How	O
many	O
chairs	O
are	O
present	O
in	O
the	O
scene	O
?	O
"	O
.	O
	
However	O
,	O
we	O
also	O
want	O
questions	O
that	O
require	O
commonsense	O
knowledge	O
about	O
the	O
scene	O
,	O
such	O
as	O
"	O
What	O
sound	O
does	O
the	O
pictured	O
animal	O
make	O
?	O
"	O
.	O
	
Importantly	O
,	O
questions	O
should	O
also	O
require	O
the	O
image	O
to	O
correctly	O
answer	O
and	O
not	O
be	O
answerable	O
using	O
just	O
commonsense	O
information	O
,	O
e.g.	O
,	O
in	O
Fig	O
.	O
1	O
,	O
"	O
What	O
is	O
the	O
mustache	O
made	O
of	O
?	O
"	O
.	O
	
By	O
having	O
a	O
wide	O
variety	O
of	O
question	O
types	O
and	O
difficulty	O
,	O
we	O
may	O
be	O
able	O
to	O
measure	O
the	O
continual	O
progress	O
of	O
both	O
visual	B-Task
understanding	I-Task
and	O
commonsense	B-Method
reasoning	I-Method
.	O
	
We	O
tested	O
and	O
evaluated	O
a	O
number	O
of	O
user	B-Method
interfaces	I-Method
for	O
collecting	O
such	O
"	O
interesting	O
"	O
questions	O
.	O
	
Specifically	O
,	O
we	O
ran	O
pilot	O
studies	O
asking	O
human	O
subjects	O
to	O
ask	O
questions	O
about	O
a	O
given	O
image	O
that	O
they	O
believe	O
a	O
"	O
toddler	O
"	O
,	O
"	O
alien	O
"	O
,	O
or	O
"	O
smart	O
robot	O
"	O
would	O
have	O
trouble	O
answering	O
.	O
	
We	O
found	O
the	O
"	O
smart	O
robot	O
"	O
interface	O
to	O
elicit	O
the	O
most	O
interesting	O
and	O
diverse	O
questions	O
.	O
	
As	O
shown	O
in	O
the	O
appendix	O
,	O
our	O
final	O
interface	O
stated	O
:	O
	
"	O
	
We	O
have	O
built	O
a	O
smart	O
robot	O
.	O
	
It	O
understands	O
a	O
lot	O
about	O
images	O
.	O
	
It	O
can	O
recognize	O
and	O
name	O
all	O
the	O
objects	O
,	O
it	O
knows	O
where	O
the	O
objects	O
are	O
,	O
it	O
can	O
recognize	O
the	O
scene	O
(	O
e.g.	O
,	O
kitchen	O
,	O
beach	O
)	O
,	O
people	O
's	O
expressions	O
and	O
poses	O
,	O
and	O
properties	O
of	O
objects	O
(	O
e.g.	O
,	O
color	O
of	O
objects	O
,	O
their	O
texture	O
)	O
.	O
	
Your	O
task	O
is	O
to	O
stump	O
this	O
smart	O
robot	O
!	O
	
Ask	O
a	O
question	O
about	O
this	O
scene	O
that	O
this	O
smart	O
robot	O
probably	O
can	O
not	O
answer	O
,	O
but	O
any	O
human	O
can	O
easily	O
answer	O
while	O
looking	O
at	O
the	O
scene	O
in	O
the	O
image	O
.	O
	
"	O
	
To	O
bias	O
against	O
generic	O
image	O
-	O
independent	O
questions	O
,	O
subjects	O
were	O
instructed	O
to	O
ask	O
questions	O
that	O
require	O
the	O
image	O
to	O
answer	O
.	O
	
The	O
same	O
user	O
interface	O
was	O
used	O
for	O
both	O
the	O
real	B-Material
images	I-Material
and	O
abstract	B-Material
scenes	I-Material
.	O
	
In	O
total	O
,	O
three	O
questions	O
from	O
unique	O
workers	O
were	O
gathered	O
for	O
each	O
image	O
/	O
scene	O
.	O
	
When	O
writing	O
a	O
question	O
,	O
the	O
subjects	O
were	O
shown	O
the	O
previous	O
questions	O
already	O
asked	O
for	O
that	O
image	O
to	O
increase	O
the	O
question	O
diversity	O
.	O
	
In	O
total	O
,	O
the	O
dataset	O
contains	O
over	O
∼0.76	O
M	O
questions	O
.	O
	
Answers	O
.	O
	
Open	O
-	O
ended	O
questions	O
result	O
in	O
a	O
diverse	O
set	O
of	O
possible	O
answers	O
.	O
	
For	O
many	O
questions	O
,	O
a	O
simple	O
"	O
yes	O
"	O
or	O
"	O
no	O
"	O
response	O
is	O
sufficient	O
.	O
	
However	O
,	O
other	O
questions	O
may	O
require	O
a	O
short	O
phrase	O
.	O
	
Multiple	O
different	O
answers	O
may	O
also	O
be	O
correct	O
.	O
	
For	O
instance	O
,	O
the	O
answers	O
"	O
white	O
"	O
,	O
"	O
tan	O
"	O
,	O
or	O
"	O
off	O
-	O
white	O
"	O
may	O
all	O
be	O
correct	O
answers	O
to	O
the	O
same	O
question	O
.	O
	
Human	O
subjects	O
may	O
also	O
disagree	O
on	O
the	O
"	O
correct	O
"	O
answer	O
,	O
e.g.	O
,	O
some	O
saying	O
"	O
yes	O
"	O
while	O
others	O
say	O
"	O
no	O
"	O
.	O
	
To	O
handle	O
these	O
discrepancies	O
,	O
we	O
gather	O
10	O
answers	O
for	O
each	O
question	O
from	O
unique	O
workers	O
,	O
while	O
also	O
ensuring	O
that	O
the	O
worker	O
answering	O
a	O
question	O
did	O
not	O
ask	O
it	O
.	O
	
We	O
ask	O
the	O
subjects	O
to	O
provide	O
answers	O
that	O
are	O
"	O
a	O
brief	O
phrase	O
and	O
not	O
a	O
complete	O
sentence	O
.	O
	
Respond	O
matter	O
-	O
offactly	O
and	O
avoid	O
using	O
conversational	O
language	O
or	O
inserting	O
your	O
opinion	O
.	O
	
"	O
	
In	O
addition	O
to	O
answering	O
the	O
questions	O
,	O
the	O
subjects	O
were	O
asked	O
"	O
Do	O
you	O
think	O
you	O
were	O
able	O
to	O
answer	O
the	O
question	O
correctly	O
?	O
"	O
and	O
given	O
the	O
choices	O
of	O
"	O
no	O
"	O
,	O
"	O
maybe	O
"	O
,	O
and	O
"	O
yes	O
"	O
.	O
	
See	O
the	O
appendix	O
for	O
more	O
details	O
about	O
the	O
user	O
interface	O
to	O
collect	O
answers	O
.	O
	
See	O
Section	O
4	O
for	O
an	O
analysis	O
of	O
the	O
answers	O
provided	O
.	O
	
For	O
testing	O
,	O
we	O
offer	O
two	O
modalities	O
for	O
answering	O
the	O
ques	O
-	O
	
For	O
the	O
open	B-Task
-	I-Task
ended	I-Task
task	I-Task
,	O
the	O
generated	O
answers	O
are	O
evaluated	O
using	O
the	O
following	O
accuracy	B-Metric
metric	I-Metric
:	O
accuracy	B-Metric
=	O
min	O
(	O
#	O
humans	O
that	O
provided	O
that	O
answer	O
3	O
,	O
1	O
)	O
	
i.e.	O
,	O
an	O
answer	O
is	O
deemed	O
100	O
%	O
accurate	O
if	O
at	O
least	O
3	O
workers	O
provided	O
that	O
exact	O
answer	O
.	O
	
[	O
reference	O
]	O
	
Before	O
comparison	O
,	O
all	O
responses	O
are	O
made	O
lowercase	O
,	O
numbers	O
converted	O
to	O
digits	O
,	O
and	O
punctuation	O
&	O
articles	O
removed	O
.	O
	
We	O
avoid	O
using	O
soft	B-Metric
metrics	I-Metric
such	O
as	O
Word2Vec	B-Method
[	O
reference	O
]	O
,	O
since	O
they	O
often	O
group	O
together	O
words	O
that	O
we	O
wish	O
to	O
distinguish	O
,	O
such	O
as	O
"	O
left	O
"	O
and	O
"	O
right	O
"	O
.	O
	
We	O
also	O
avoid	O
using	O
evaluation	B-Metric
metrics	I-Metric
from	O
machine	B-Task
translation	I-Task
such	O
as	O
BLEU	B-Metric
and	O
ROUGE	B-Metric
because	O
such	O
metrics	O
are	O
typically	O
applicable	O
and	O
reliable	O
for	O
sentences	O
containing	O
multiple	O
words	O
.	O
	
In	O
VQA	B-Task
,	O
most	O
answers	O
(	O
89.32	O
%	O
)	O
are	O
single	O
word	O
;	O
thus	O
there	O
no	O
high	O
-	O
order	O
n	O
-	O
gram	O
matches	O
between	O
predicted	O
answers	O
and	O
ground	O
-	O
truth	O
answers	O
,	O
and	O
low	O
-	O
order	O
n	O
-	O
gram	O
matches	O
degenerate	O
to	O
exact	B-Method
-	I-Method
string	I-Method
matching	I-Method
.	O
	
Moreover	O
,	O
these	O
automatic	B-Metric
metrics	I-Metric
such	O
as	O
BLEU	B-Metric
and	O
ROUGE	B-Metric
have	O
been	O
found	O
to	O
poorly	O
correlate	O
with	O
human	B-Metric
judgement	I-Metric
for	O
tasks	O
such	O
as	O
image	B-Task
caption	I-Task
evaluation	I-Task
[	O
reference	O
]	O
.	O
For	O
multiple	B-Task
-	I-Task
choice	I-Task
task	I-Task
,	O
18	O
candidate	O
answers	O
are	O
created	O
for	O
each	O
question	O
.	O
	
As	O
with	O
the	O
open	B-Task
-	I-Task
ended	I-Task
task	I-Task
,	O
the	O
accuracy	B-Metric
of	O
a	O
chosen	O
option	O
is	O
computed	O
based	O
on	O
the	O
number	O
of	O
human	O
subjects	O
who	O
provided	O
that	O
answer	O
(	O
divided	O
by	O
3	O
and	O
clipped	O
at	O
1	O
)	O
.	O
	
We	O
generate	O
a	O
candidate	O
set	O
of	O
correct	O
and	O
incorrect	O
answers	O
from	O
four	O
sets	O
of	O
answers	O
:	O
	
Correct	O
:	O
The	O
most	O
common	O
(	O
out	O
of	O
ten	O
)	O
correct	O
answer	O
.	O
	
Plausible	O
:	O
To	O
generate	O
incorrect	O
,	O
but	O
still	O
plausible	O
answers	O
we	O
ask	O
three	O
subjects	O
to	O
answer	O
the	O
questions	O
without	O
seeing	O
the	O
image	O
.	O
	
See	O
the	O
appendix	O
for	O
more	O
details	O
about	O
the	O
user	O
interface	O
to	O
collect	O
these	O
answers	O
.	O
	
If	O
three	O
unique	O
answers	O
are	O
not	O
found	O
,	O
we	O
gather	O
additional	O
answers	O
from	O
nearest	B-Method
neighbor	I-Method
questions	O
using	O
a	O
bag	B-Method
-	I-Method
of	I-Method
-	I-Method
words	I-Method
model	I-Method
.	O
	
The	O
use	O
of	O
these	O
answers	O
helps	O
ensure	O
the	O
image	O
,	O
and	O
not	O
just	O
commonsense	O
knowledge	O
,	O
is	O
necessary	O
to	O
answer	O
the	O
question	O
.	O
	
Popular	O
:	O
These	O
are	O
the	O
10	O
most	O
popular	O
answers	O
.	O
	
For	O
instance	O
,	O
these	O
are	O
"	O
yes	O
"	O
,	O
"	O
no	O
"	O
,	O
"	O
2	O
"	O
,	O
"	O
1	O
"	O
,	O
"	O
white	O
"	O
,	O
"	O
3	O
"	O
,	O
"	O
red	O
"	O
,	O
"	O
blue	O
"	O
,	O
"	O
4	O
"	O
,	O
"	O
green	O
"	O
for	O
real	B-Material
images	I-Material
.	O
	
The	O
inclusion	O
of	O
the	O
most	O
popular	O
answers	O
makes	O
it	O
more	O
difficult	O
for	O
algorithms	O
to	O
infer	O
the	O
type	O
of	O
question	O
from	O
the	O
set	O
of	O
answers	O
provided	O
,	O
i.e.	O
,	O
learning	O
that	O
it	O
is	O
a	O
"	O
yes	O
or	O
no	O
"	O
question	O
just	O
because	O
"	O
yes	O
"	O
and	O
"	O
no	O
"	O
are	O
present	O
in	O
the	O
answers	O
.	O
	
Random	O
:	O
	
Correct	O
answers	O
from	O
random	O
questions	O
in	O
the	O
dataset	O
.	O
	
To	O
generate	O
a	O
total	O
of	O
18	O
candidate	O
answers	O
,	O
we	O
first	O
find	O
the	O
union	O
of	O
the	O
correct	O
,	O
plausible	O
,	O
and	O
popular	O
answers	O
.	O
	
We	O
include	O
random	O
answers	O
until	O
18	O
unique	O
answers	O
are	O
found	O
.	O
	
The	O
order	O
of	O
the	O
answers	O
is	O
randomized	O
.	O
	
Example	O
multiple	O
choice	O
questions	O
are	O
in	O
the	O
appendix	O
.	O
	
Note	O
that	O
all	O
18	O
candidate	O
answers	O
are	O
unique	O
.	O
	
But	O
since	O
10	O
different	O
subjects	O
answered	O
every	O
question	O
,	O
it	O
is	O
possible	O
that	O
more	O
than	O
one	O
of	O
those	O
10	O
answers	O
be	O
present	O
in	O
the	O
18	O
choices	O
.	O
	
In	O
such	O
cases	O
,	O
according	O
to	O
the	O
accuracy	B-Metric
metric	I-Metric
,	O
multiple	O
options	O
could	O
have	O
a	O
non	O
-	O
zero	O
accuracy	O
.	O
	
section	O
:	O
Real	B-Material
Images	I-Material
	
Abstract	O
Scenes	O
	
section	O
:	O
VQA	B-Task
DATASET	I-Task
ANALYSIS	I-Task
	
In	O
this	O
section	O
,	O
we	O
provide	O
an	O
analysis	O
of	O
the	O
questions	O
and	O
answers	O
in	O
the	O
VQA	B-Material
train	I-Material
dataset	I-Material
.	O
	
To	O
gain	O
an	O
understanding	O
of	O
the	O
types	O
of	O
questions	O
asked	O
and	O
answers	O
provided	O
,	O
we	O
visualize	O
the	O
distribution	O
of	O
question	O
types	O
and	O
answers	O
.	O
	
We	O
also	O
explore	O
how	O
often	O
the	O
questions	O
may	O
be	O
answered	O
without	O
the	O
image	O
using	O
just	O
commonsense	O
information	O
.	O
	
Finally	O
,	O
we	O
analyze	O
whether	O
the	O
information	O
contained	O
in	O
an	O
image	O
caption	O
is	O
sufficient	O
to	O
answer	O
the	O
questions	O
.	O
	
The	O
dataset	O
includes	O
614	O
,	O
163	O
questions	O
and	O
7	O
,	O
984	O
,	O
119	O
answers	O
(	O
including	O
answers	O
provided	O
by	O
workers	O
with	O
and	O
without	O
looking	O
at	O
the	O
image	O
)	O
for	O
204	O
,	O
721	O
images	O
from	O
the	O
MS	B-Material
COCO	I-Material
dataset	I-Material
[	O
reference	O
]	O
and	O
150	O
,	O
000	O
questions	O
with	O
1	O
,	O
950	O
,	O
000	O
answers	O
for	O
50	O
,	O
000	O
abstract	B-Material
scenes	I-Material
.	O
	
section	O
:	O
Questions	O
	
Types	O
of	O
Question	O
.	O
	
Given	O
the	O
structure	O
of	O
questions	O
generated	O
in	O
the	O
English	O
language	O
,	O
we	O
can	O
cluster	O
questions	O
into	O
different	O
types	O
based	O
on	O
the	O
words	O
that	O
start	O
the	O
question	O
.	O
	
Fig	O
.	O
	
3	O
shows	O
the	O
distribution	O
of	O
questions	O
based	O
on	O
the	O
first	O
four	O
words	O
of	O
the	O
questions	O
for	O
both	O
the	O
real	B-Material
images	I-Material
(	O
left	O
)	O
and	O
abstract	B-Material
scenes	I-Material
(	O
right	O
)	O
.	O
	
Interestingly	O
,	O
the	O
distribution	O
of	O
questions	O
is	O
quite	O
similar	O
for	O
both	O
real	B-Material
images	I-Material
and	O
abstract	B-Material
scenes	I-Material
.	O
	
This	O
helps	O
demonstrate	O
that	O
the	O
type	O
of	O
questions	O
elicited	O
by	O
the	O
abstract	B-Material
scenes	I-Material
is	O
similar	O
to	O
those	O
elicited	O
by	O
the	O
real	B-Material
images	I-Material
.	O
	
There	O
exists	O
a	O
surprising	O
variety	O
of	O
question	O
types	O
,	O
including	O
"	O
What	O
is	O
.	O
.	O
.	O
	
"	O
,	O
"	O
Is	O
there	O
.	O
.	O
.	O
	
"	O
,	O
"	O
How	O
many	O
.	O
.	O
.	O
"	O
,	O
and	O
"	O
Does	O
the	O
.	O
.	O
.	O
"	O
.	O
	
Quantitatively	O
,	O
the	O
percentage	O
of	O
questions	O
for	O
different	O
types	O
is	O
shown	O
in	O
Table	O
3	O
.	O
	
Several	O
example	O
questions	O
and	O
answers	O
are	O
shown	O
in	O
Fig	O
.	O
2	O
.	O
	
A	O
particularly	O
interesting	O
type	O
of	O
question	O
is	O
the	O
"	O
What	O
is	O
.	O
.	O
.	O
	
"	O
questions	O
,	O
since	O
they	O
have	O
a	O
diverse	O
set	O
2	O
.	O
	
In	O
order	O
to	O
be	O
consistent	O
with	O
'	O
human	B-Metric
accuracies	I-Metric
'	O
reported	O
in	O
Section	O
4	O
,	O
machine	B-Metric
accuracies	I-Metric
are	O
averaged	O
over	O
all	O
[	O
reference	O
]	O
sets	O
of	O
human	O
annotators	O
Lengths	O
.	O
	
Fig	O
.	O
	
4	O
shows	O
the	O
distribution	O
of	O
question	O
lengths	O
.	O
	
We	O
see	O
that	O
most	O
questions	O
range	O
from	O
four	O
to	O
ten	O
words	O
.	O
	
section	O
:	O
Answers	O
	
Typical	O
Answers	O
.	O
	
Lengths	O
.	O
	
Most	O
answers	O
consist	O
of	O
a	O
single	O
word	O
,	O
with	O
the	O
distribution	O
of	O
answers	O
containing	O
one	O
,	O
two	O
,	O
or	O
three	O
words	O
,	O
respectively	O
being	O
89.32	O
%	O
,	O
6.91	O
%	O
,	O
and	O
2.74	O
%	O
for	O
real	B-Material
images	I-Material
and	O
90.51	O
%	O
,	O
5.89	O
%	O
,	O
and	O
2.49	O
%	O
for	O
abstract	B-Material
scenes	I-Material
.	O
	
The	O
brevity	O
of	O
answers	O
is	O
not	O
surprising	O
,	O
since	O
the	O
questions	O
tend	O
to	O
elicit	O
specific	O
information	O
from	O
the	O
images	O
.	O
	
This	O
is	O
in	O
contrast	O
	
section	O
:	O
Answers	O
with	O
Images	O
	
Answers	O
without	O
Images	O
with	O
image	O
captions	O
that	O
generically	O
describe	O
the	O
entire	O
image	O
and	O
hence	O
tend	O
to	O
be	O
longer	O
.	O
	
The	O
brevity	O
of	O
our	O
answers	O
makes	O
automatic	B-Task
evaluation	I-Task
feasible	O
.	O
	
While	O
it	O
may	O
be	O
tempting	O
to	O
believe	O
the	O
brevity	O
of	O
the	O
answers	O
makes	O
the	O
problem	O
easier	O
,	O
recall	O
that	O
they	O
are	O
human	O
-	O
provided	O
open	O
-	O
ended	O
answers	O
to	O
open	O
-	O
ended	O
questions	O
.	O
	
The	O
questions	O
typically	O
require	O
complex	O
reasoning	O
to	O
arrive	O
at	O
these	O
deceptively	O
simple	O
answers	O
(	O
see	O
Fig	O
.	O
2	O
)	O
.	O
	
There	O
are	O
currently	O
23	O
,	O
234	O
unique	O
one	O
-	O
word	O
answers	O
in	O
our	O
dataset	O
for	O
real	B-Material
images	I-Material
and	O
3	O
,	O
770	O
for	O
abstract	B-Material
scenes	I-Material
.	O
'	O
	
Yes	O
/	O
No	O
'	O
and	O
'	O
Number	O
'	O
Answers	O
.	O
	
Many	O
questions	O
are	O
answered	O
using	O
either	O
"	O
yes	O
"	O
or	O
"	O
no	O
"	O
(	O
or	O
sometimes	O
"	O
maybe	O
"	O
)	O
-	O
38.37	O
%	O
and	O
40.66	O
%	O
of	O
the	O
questions	O
on	O
real	B-Material
images	I-Material
and	O
abstract	B-Material
scenes	I-Material
respectively	O
.	O
	
Among	O
these	O
'	O
yes	O
/	O
no	O
'	O
questions	O
,	O
there	O
is	O
a	O
bias	O
towards	O
"	O
yes	O
"	O
-	O
58.83	O
%	O
and	O
55.86	O
%	O
of	O
'	O
yes	O
/	O
no	O
'	O
answers	O
are	O
"	O
yes	O
"	O
for	O
real	B-Material
images	I-Material
and	O
abstract	B-Material
scenes	I-Material
.	O
	
Question	O
types	O
such	O
as	O
"	O
How	O
many	O
.	O
.	O
.	O
	
"	O
are	O
answered	O
using	O
numbers	O
-	O
12.31	O
%	O
and	O
14.48	O
%	O
of	O
the	O
questions	O
on	O
real	B-Material
images	I-Material
and	O
abstract	B-Material
scenes	I-Material
are	O
'	O
number	O
'	O
questions	O
.	O
	
"	O
2	O
"	O
is	O
the	O
most	O
popular	O
answer	O
among	O
the	O
'	O
number	O
'	O
questions	O
,	O
making	O
up	O
26.04	O
%	O
of	O
the	O
'	O
number	O
'	O
answers	O
for	O
real	B-Material
images	I-Material
and	O
39.85	O
%	O
for	O
abstract	B-Material
scenes	I-Material
.	O
	
Subject	O
Confidence	O
.	O
	
When	O
the	O
subjects	O
answered	O
the	O
questions	O
,	O
we	O
asked	O
"	O
Do	O
you	O
think	O
you	O
were	O
able	O
to	O
answer	O
the	O
question	O
correctly	O
?	O
"	O
.	O
	
Fig	O
.	O
	
6	O
shows	O
the	O
distribution	O
of	O
responses	O
.	O
	
A	O
majority	O
of	O
the	O
answers	O
were	O
labeled	O
as	O
confident	O
for	O
both	O
real	B-Material
images	I-Material
and	O
abstract	B-Material
scenes	I-Material
.	O
	
Inter	B-Metric
-	I-Metric
human	I-Metric
Agreement	I-Metric
.	O
	
Does	O
the	O
self	O
-	O
judgment	O
of	O
confidence	O
correspond	O
to	O
the	O
answer	O
agreement	O
between	O
subjects	O
?	O
	
Fig	O
.	O
	
6	O
shows	O
the	O
percentage	O
of	O
questions	O
in	O
which	O
(	O
i	O
)	O
7	O
or	O
more	O
,	O
	
(	O
ii	O
)	O
3−7	O
,	O
or	O
(	O
iii	O
)	O
less	O
than	O
3	O
subjects	O
agree	O
on	O
the	O
answers	O
given	O
their	O
average	O
confidence	O
score	O
(	O
0	O
=	O
not	O
confident	O
,	O
1	O
=	O
confident	O
)	O
.	O
	
As	O
expected	O
,	O
the	O
agreement	O
between	O
subjects	O
7	O
or	O
more	O
same	O
3	O
-	O
7	O
same	O
less	O
than	O
3	O
same	O
#	O
of	O
Questions	O
increases	O
with	O
confidence	O
.	O
	
However	O
,	O
even	O
if	O
all	O
of	O
the	O
subjects	O
are	O
confident	O
the	O
answers	O
may	O
still	O
vary	O
.	O
	
This	O
is	O
not	O
surprising	O
since	O
some	O
answers	O
may	O
vary	O
,	O
yet	O
have	O
very	O
similar	O
meaning	O
,	O
such	O
as	O
"	O
happy	O
"	O
and	O
"	O
joyful	O
"	O
.	O
	
As	O
shown	O
in	O
Table	O
1	O
(	O
Question	B-Material
+	I-Material
Image	I-Material
)	O
,	O
there	O
is	O
significant	O
inter	O
-	O
human	O
agreement	O
in	O
the	O
answers	O
for	O
both	O
real	B-Material
images	I-Material
(	O
83.30	O
%	O
)	O
and	O
abstract	B-Material
scenes	I-Material
(	O
87.49	O
%	O
)	O
.	O
	
Note	O
that	O
on	O
average	O
each	O
question	O
has	O
2.70	O
unique	O
answers	O
for	O
real	B-Material
images	I-Material
and	O
2.39	O
for	O
abstract	B-Material
scenes	I-Material
.	O
	
The	O
agreement	O
is	O
significantly	O
higher	O
(	O
>	O
95	O
%	O
)	O
for	O
"	O
yes	O
/	O
no	O
"	O
questions	O
and	O
lower	O
for	O
other	O
questions	O
(	O
<	O
76	O
%	O
)	O
,	O
possibly	O
due	O
to	O
the	O
fact	O
that	O
we	O
perform	O
exact	B-Method
string	I-Method
matching	I-Method
and	O
do	O
not	O
account	O
for	O
synonyms	O
,	O
plurality	O
,	O
etc	O
.	O
	
Note	O
that	O
the	O
automatic	B-Task
determination	I-Task
of	I-Task
synonyms	I-Task
is	O
a	O
difficult	O
problem	O
,	O
since	O
the	O
level	O
of	O
answer	O
granularity	O
can	O
vary	O
across	O
questions	O
.	O
	
section	O
:	O
Commonsense	O
Knowledge	O
	
Is	O
the	O
Image	O
Necessary	O
?	O
	
Clearly	O
,	O
some	O
questions	O
can	O
sometimes	O
be	O
answered	O
correctly	O
using	O
commonsense	O
knowledge	O
alone	O
without	O
the	O
need	O
for	O
an	O
image	O
,	O
e.g.	O
,	O
"	O
What	O
is	O
the	O
color	O
of	O
the	O
fire	O
hydrant	O
?	O
"	O
.	O
	
We	O
explore	O
this	O
issue	O
by	O
asking	O
three	O
subjects	O
to	O
answer	O
the	O
questions	O
without	O
seeing	O
the	O
image	O
(	O
see	O
the	O
examples	O
in	O
blue	O
in	O
Fig	O
.	O
2	O
)	O
.	O
	
In	O
Table	O
1	O
(	O
Question	O
)	O
,	O
we	O
show	O
the	O
percentage	O
of	O
questions	O
for	O
which	O
the	O
correct	O
answer	O
is	O
provided	O
over	O
all	O
questions	O
,	O
"	O
yes	O
/	O
no	O
"	O
questions	O
,	O
and	O
the	O
other	O
questions	O
that	O
are	O
not	O
"	O
yes	O
/	O
no	O
"	O
.	O
	
For	O
"	O
yes	O
/	O
no	O
"	O
questions	O
,	O
the	O
human	O
subjects	O
respond	O
better	O
than	O
chance	O
.	O
	
For	O
other	O
questions	O
,	O
humans	O
are	O
only	O
correct	O
about	O
21	O
%	O
of	O
the	O
time	O
.	O
	
This	O
demonstrates	O
that	O
understanding	O
the	O
visual	O
information	O
is	O
critical	O
to	O
VQA	B-Task
and	O
that	O
commonsense	O
information	O
alone	O
is	O
not	O
sufficient	O
.	O
	
To	O
show	O
the	O
qualitative	O
difference	O
in	O
answers	O
provided	O
with	O
and	O
without	O
images	O
,	O
we	O
show	O
the	O
distribution	O
of	O
answers	O
for	O
various	O
question	O
types	O
in	O
Fig	O
.	O
5	O
	
(	O
bottom	O
)	O
.	O
	
The	O
distribution	O
of	O
colors	O
,	O
numbers	O
,	O
and	O
even	O
"	O
yes	O
/	O
no	O
"	O
responses	O
is	O
surprisingly	O
different	O
for	O
answers	O
with	O
and	O
without	O
images	O
.	O
	
Which	O
Questions	O
Require	O
Common	O
Sense	O
?	O
	
In	O
order	O
to	O
identify	O
questions	O
that	O
require	O
commonsense	B-Method
reasoning	I-Method
to	O
answer	O
,	O
we	O
conducted	O
two	O
AMT	B-Method
studies	I-Method
(	O
on	O
a	O
subset	O
10	O
K	O
questions	O
from	O
the	O
real	B-Material
images	I-Material
of	O
VQA	B-Task
trainval	O
)	O
asking	O
subjects	O
-	O
1	O
)	O
	
Whether	O
or	O
not	O
they	O
believed	O
a	O
question	O
required	O
commonsense	O
to	O
answer	O
the	O
question	O
,	O
and	O
2	O
)	O
	
The	O
youngest	O
age	O
group	O
that	O
they	O
believe	O
a	O
person	O
must	O
be	O
in	O
order	O
to	O
be	O
able	O
to	O
correctly	O
answer	O
the	O
question	O
-	O
toddler	O
	
(	O
3	O
-	O
4	O
)	O
,	O
younger	O
child	O
(	O
5	O
-	O
8	O
)	O
,	O
older	O
child	O
(	O
9	O
-	O
12	O
)	O
,	O
teenager	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
,	O
adult	O
(	O
18	O
+	O
)	O
.	O
	
Each	O
question	O
was	O
shown	O
to	O
10	O
subjects	O
.	O
	
We	O
found	O
that	O
for	O
47.43	O
%	O
of	O
questions	O
3	O
or	O
more	O
subjects	O
voted	O
'	O
yes	O
'	O
to	O
commonsense	O
,	O
(	O
18.14	O
%	O
:	O
6	O
or	O
more	O
)	O
.	O
	
In	O
the	O
'	O
perceived	O
human	O
age	O
required	O
to	O
answer	O
question	O
'	O
study	O
,	O
we	O
found	O
the	O
following	O
distribution	O
of	O
responses	O
:	O
toddler	O
:	O
15.3	O
%	O
,	O
younger	O
child	O
:	O
39.7	O
%	O
,	O
older	O
child	O
:	O
28.4	O
%	O
,	O
teenager	O
:	O
11.2	O
%	O
,	O
adult	O
:	O
5.5	O
%	O
.	O
	
In	O
Figure	O
7	O
we	O
show	O
several	O
questions	O
for	O
which	O
a	O
majority	O
of	O
subjects	O
picked	O
the	O
specified	O
age	O
range	O
.	O
	
Surprisingly	O
the	O
perceived	O
age	O
needed	O
to	O
answer	O
the	O
questions	O
is	O
fairly	O
well	O
distributed	O
across	O
the	O
different	O
age	O
ranges	O
.	O
	
As	O
expected	O
the	O
questions	O
that	O
were	O
judged	O
answerable	O
by	O
an	O
adult	O
(	O
18	O
+	O
)	O
generally	O
need	O
specialized	O
knowledge	O
,	O
whereas	O
those	O
answerable	O
by	O
a	O
toddler	O
(	O
3	O
-	O
4	O
)	O
are	O
more	O
generic	O
.	O
	
We	O
measure	O
the	O
degree	O
of	O
commonsense	O
required	O
to	O
answer	O
a	O
question	O
as	O
the	O
percentage	O
of	O
subjects	O
(	O
out	O
of	O
10	O
)	O
who	O
voted	O
"	O
yes	O
"	O
in	O
our	O
"	O
whether	O
or	O
not	O
a	O
question	O
requires	O
commonsense	O
"	O
study	O
.	O
	
A	O
fine	O
-	O
grained	O
breakdown	O
of	O
average	B-Metric
age	I-Metric
and	O
average	B-Metric
degree	I-Metric
of	I-Metric
common	I-Metric
sense	I-Metric
(	O
on	O
a	O
scale	O
of	O
0	O
−	O
100	O
)	O
required	O
to	O
answer	O
a	O
question	O
is	O
shown	O
in	O
Table	O
3	O
.	O
	
The	O
average	O
age	O
and	O
the	O
average	O
degree	O
of	O
commonsense	O
across	O
all	O
questions	O
is	O
8.92	O
and	O
31.01	O
%	O
respectively	O
.	O
	
It	O
is	O
important	O
to	O
distinguish	O
between	O
:	O
1	O
)	O
How	O
old	O
someone	O
needs	O
to	O
be	O
to	O
be	O
able	O
to	O
answer	O
a	O
question	O
correctly	O
,	O
and	O
2	O
)	O
How	O
old	O
people	O
think	O
someone	O
needs	O
to	O
be	O
to	O
be	O
able	O
to	O
answer	O
a	O
question	O
correctly	O
.	O
	
Our	O
age	B-Method
annotations	I-Method
capture	O
the	O
latter	O
-	O
perceptions	O
of	O
MTurk	O
workers	O
in	O
an	O
uncontrolled	O
environment	O
.	O
	
As	O
such	O
,	O
the	O
relative	O
ordering	O
of	O
question	O
types	O
in	O
Table	O
3	O
is	O
more	O
important	O
than	O
absolute	O
age	O
numbers	O
.	O
	
The	O
two	O
rankings	O
of	O
questions	O
in	O
terms	O
of	O
common	O
sense	O
required	O
according	O
to	O
the	O
two	O
studies	O
were	O
largely	O
correlated	O
(	O
Pearson	B-Metric
's	I-Metric
rank	I-Metric
correlation	I-Metric
:	O
0.58	O
)	O
.	O
	
section	O
:	O
Captions	O
vs.	O
Questions	O
	
Do	O
generic	O
image	O
captions	O
provide	O
enough	O
information	O
to	O
answer	O
the	O
questions	O
?	O
	
section	O
:	O
VQA	B-Task
BASELINES	O
AND	O
METHODS	O
	
In	O
this	O
section	O
,	O
we	O
explore	O
the	O
difficulty	O
of	O
the	O
VQA	B-Material
dataset	I-Material
for	O
the	O
MS	B-Material
COCO	I-Material
images	O
using	O
several	O
baselines	O
and	O
novel	O
methods	O
.	O
	
We	O
train	O
on	O
VQA	B-Task
train	O
+	O
val	O
.	O
	
Unless	O
stated	O
otherwise	O
,	O
all	O
human	B-Metric
accuracies	I-Metric
are	O
on	O
test	O
-	O
standard	O
,	O
machine	B-Metric
accuracies	I-Metric
are	O
on	O
test	O
-	O
dev	O
,	O
and	O
results	O
involving	O
human	O
captions	O
(	O
in	O
gray	O
font	O
)	O
are	O
trained	O
on	O
train	O
and	O
tested	O
on	O
val	O
(	O
because	O
captions	O
are	O
not	O
available	O
for	O
test	O
)	O
.	O
	
section	O
:	O
Baselines	O
	
We	O
implemented	O
the	O
following	O
baselines	O
:	O
1	O
)	O
random	O
:	O
We	O
randomly	O
choose	O
an	O
answer	O
from	O
the	O
top	O
1	O
K	O
answers	O
of	O
the	O
VQA	B-Task
train	O
/	O
val	O
dataset	O
.	O
	
2	O
)	O
prior	O
(	O
"	O
yes	O
"	O
)	O
:	O
We	O
always	O
select	O
the	O
most	O
popular	O
answer	O
(	O
"	O
yes	O
"	O
)	O
for	O
both	O
the	O
open	B-Task
-	I-Task
ended	I-Task
and	I-Task
multiple	I-Task
-	I-Task
choice	I-Task
tasks	I-Task
.	O
	
Note	O
that	O
"	O
yes	O
"	O
is	O
always	O
one	O
of	O
the	O
choices	O
for	O
the	O
multiple	O
-	O
choice	O
questions	O
.	O
	
3	O
)	O
per	O
Q	B-Method
-	I-Method
type	I-Method
prior	I-Method
:	O
For	O
the	O
open	B-Task
-	I-Task
ended	I-Task
task	I-Task
,	O
we	O
pick	O
the	O
most	O
popular	O
answer	O
per	O
question	O
type	O
(	O
see	O
the	O
appendix	O
for	O
details	O
)	O
.	O
	
For	O
the	O
multiple	B-Task
-	I-Task
choice	I-Task
task	I-Task
,	O
we	O
pick	O
the	O
answer	O
(	O
from	O
the	O
provided	O
choices	O
)	O
that	O
is	O
most	O
similar	O
to	O
the	O
picked	O
answer	O
for	O
the	O
open	O
-	O
ended	O
task	O
using	O
cosine	O
similarity	O
in	O
Word2Vec	O
[	O
reference	O
]	O
feature	O
space	O
.	O
	
4	O
)	O
nearest	B-Method
neighbor	I-Method
:	O
	
Given	O
a	O
test	O
image	O
,	O
question	O
pair	O
,	O
we	O
first	O
find	O
the	O
K	O
nearest	B-Method
neighbor	I-Method
questions	O
and	O
associated	O
images	O
from	O
the	O
training	O
set	O
.	O
	
See	O
appendix	O
for	O
details	O
on	O
how	O
neighbors	O
are	O
found	O
.	O
	
Next	O
,	O
for	O
the	O
open	B-Task
-	I-Task
ended	I-Task
task	I-Task
,	O
we	O
pick	O
the	O
most	O
frequent	O
ground	O
truth	O
answer	O
from	O
this	O
set	O
of	O
nearest	B-Method
neighbor	I-Method
question	O
,	O
image	O
pairs	O
.	O
	
Similar	O
to	O
the	O
"	O
per	O
Q	B-Method
-	I-Method
type	I-Method
prior	I-Method
"	O
baseline	O
,	O
for	O
the	O
multiple	B-Task
-	I-Task
choice	I-Task
task	I-Task
,	O
we	O
pick	O
the	O
answer	O
(	O
from	O
the	O
provided	O
choices	O
)	O
that	O
is	O
most	O
similar	O
to	O
the	O
picked	O
answer	O
for	O
the	O
open	O
-	O
ended	O
task	O
using	O
cosine	O
similarity	O
in	O
Word2Vec	B-Method
[	O
reference	O
]	O
feature	O
space	O
.	O
	
section	O
:	O
Methods	O
	
For	O
our	O
methods	O
,	O
we	O
develop	O
a	O
2	B-Method
-	I-Method
channel	I-Method
vision	I-Method
(	I-Method
image	I-Method
)	I-Method
+	I-Method
language	I-Method
(	I-Method
question	I-Method
)	I-Method
model	I-Method
that	O
culminates	O
with	O
a	O
softmax	O
over	O
K	O
possible	O
outputs	O
.	O
	
We	O
choose	O
the	O
top	O
K	O
=	O
1000	O
most	O
frequent	O
answers	O
as	O
possible	O
outputs	O
.	O
	
This	O
set	O
of	O
answers	O
covers	O
82.67	O
%	O
of	O
the	O
train	O
+	O
val	O
answers	O
.	O
	
We	O
describe	O
the	O
different	O
components	O
of	O
our	O
model	O
below	O
:	O
	
Image	B-Task
Channel	I-Task
:	O
	
This	O
channel	O
provides	O
an	O
embedding	O
for	O
the	O
image	O
.	O
	
We	O
experiment	O
with	O
two	O
embeddings	O
-	O
1	O
)	O
	
I	O
:	O
	
The	O
activations	O
from	O
the	O
last	O
hidden	B-Method
layer	I-Method
of	O
VGGNet	B-Method
[	O
reference	O
]	O
are	O
used	O
as	O
4096	B-Task
-	I-Task
dim	I-Task
image	I-Task
embedding	I-Task
.	O
	
2	O
)	O
norm	O
I	O
	
:	O
These	O
are	O
2	O
normalized	O
activations	O
from	O
the	O
last	O
hidden	B-Method
layer	I-Method
of	O
VGGNet	B-Method
[	O
reference	O
]	O
.	O
Question	B-Task
Channel	I-Task
:	O
This	O
channel	O
provides	O
an	O
embedding	O
for	O
the	O
question	O
.	O
	
We	O
experiment	O
with	O
three	O
embeddings	O
-	O
1	O
)	O
	
Bag	B-Task
-	I-Task
of	I-Task
-	I-Task
Words	I-Task
Question	I-Task
(	O
BoW	B-Task
Q	I-Task
)	O
:	O
	
The	O
top	O
1	O
,	O
000	O
words	O
in	O
the	O
questions	O
are	O
used	O
to	O
create	O
a	O
bag	B-Method
-	I-Method
of	I-Method
-	I-Method
words	I-Method
representation	I-Method
.	O
	
Since	O
there	O
is	O
a	O
strong	O
correlation	O
between	O
the	O
words	O
that	O
start	O
a	O
question	O
and	O
the	O
answer	O
(	O
see	O
Fig	O
.	O
5	O
)	O
,	O
we	O
find	O
the	O
top	O
10	O
first	O
,	O
second	O
,	O
and	O
third	O
words	O
of	O
the	O
questions	O
and	O
create	O
a	O
30	B-Method
dimensional	I-Method
bag	I-Method
-	I-Method
of	I-Method
-	I-Method
words	I-Method
representation	I-Method
.	O
	
These	O
features	O
are	O
concatenated	O
to	O
get	O
a	O
1	B-Method
,	I-Method
030	I-Method
-	I-Method
dim	I-Method
embedding	I-Method
for	O
the	O
question	O
.	O
.	O
	
This	O
model	O
uses	O
a	O
two	O
layer	O
LSTM	B-Method
to	O
encode	O
the	O
questions	O
and	O
the	O
last	O
hidden	B-Method
layer	I-Method
of	O
VGGNet	B-Method
[	O
reference	O
]	O
to	O
encode	O
the	O
images	O
.	O
	
The	O
image	O
features	O
are	O
then	O
2	O
normalized	O
.	O
	
Both	O
the	O
question	O
and	O
image	O
features	O
are	O
transformed	O
to	O
a	O
common	O
space	O
and	O
fused	O
via	O
element	B-Method
-	I-Method
wise	I-Method
multiplication	I-Method
,	O
which	O
is	O
then	O
passed	O
through	O
a	O
fully	B-Method
connected	I-Method
layer	I-Method
followed	O
by	O
a	O
softmax	B-Method
layer	I-Method
to	O
obtain	O
a	O
distribution	O
over	O
answers	O
.	O
	
being	O
512	O
-	O
dim	O
)	O
from	O
each	O
of	O
the	O
two	O
hidden	B-Method
layers	I-Method
of	O
the	O
LSTM	B-Method
.	O
	
Hence	O
2	O
(	O
hidden	B-Method
layers	I-Method
)	O
x	O
2	O
(	O
cell	O
state	O
and	O
hidden	O
state	O
)	O
x	O
512	O
(	O
dimensionality	O
of	O
each	O
of	O
the	O
cell	O
states	O
,	O
as	O
well	O
as	O
hidden	O
states	O
)	O
in	O
Fig	O
.	O
8	O
.	O
	
This	O
is	O
followed	O
by	O
a	O
fully	B-Method
-	I-Method
connected	I-Method
layer	I-Method
+	I-Method
tanh	I-Method
non	I-Method
-	I-Method
linearity	I-Method
to	O
transform	O
2048	B-Task
-	I-Task
dim	I-Task
embedding	I-Task
to	O
1024	O
-	O
dim	O
.	O
	
The	O
question	O
words	O
are	O
encoded	O
in	O
the	O
same	O
way	O
as	O
in	O
LSTM	B-Method
Q.	O
Multi	O
-	O
Layer	O
Perceptron	O
(	O
MLP	O
)	O
:	O
The	O
image	O
and	O
question	O
embeddings	O
are	O
combined	O
to	O
obtain	O
a	O
single	O
embedding	O
.	O
	
1	O
)	O
For	O
BoW	B-Task
Q	I-Task
	
+	O
I	B-Method
method	I-Method
,	O
we	O
simply	O
concatenate	O
the	O
BoW	O
Q	O
and	O
	
I	O
embeddings	O
.	O
	
2	O
)	O
	
For	O
LSTM	B-Method
Q	O
+	O
I	O
,	O
and	O
deeper	O
LSTM	B-Method
Q	O
+	O
norm	O
I	O
(	O
Fig	O
.	O
	
8	O
)	O
methods	O
,	O
the	O
image	B-Task
embedding	I-Task
is	O
first	O
transformed	O
to	O
1024	O
-	O
dim	O
by	O
a	O
fully	B-Method
-	I-Method
connected	I-Method
layer	I-Method
+	I-Method
tanh	I-Method
non	I-Method
-	I-Method
linearity	I-Method
to	O
match	O
the	O
LSTM	B-Method
embedding	O
of	O
the	O
question	O
.	O
	
The	O
transformed	O
image	O
and	O
LSTM	B-Method
embeddings	O
(	O
being	O
in	O
a	O
common	O
space	O
)	O
are	O
then	O
fused	O
via	O
element	B-Method
-	I-Method
wise	I-Method
multiplication	I-Method
.	O
	
This	O
combined	O
image	B-Method
+	I-Method
question	I-Method
embedding	I-Method
is	O
then	O
passed	O
to	O
an	O
MLP	B-Method
-	I-Method
a	I-Method
fully	I-Method
connected	I-Method
neural	I-Method
network	I-Method
classifier	I-Method
with	O
2	O
hidden	B-Method
layers	I-Method
and	O
1000	O
hidden	O
units	O
(	O
dropout	O
0.5	O
)	O
in	O
each	O
layer	O
with	O
tanh	O
non	O
-	O
linearity	O
,	O
followed	O
by	O
a	O
softmax	B-Method
layer	I-Method
to	O
obtain	O
a	O
distribution	O
over	O
K	O
answers	O
.	O
	
The	O
entire	O
model	O
is	O
learned	O
end	O
-	O
to	O
-	O
end	O
with	O
a	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
loss	I-Metric
.	O
	
VGGNet	B-Method
parameters	I-Method
are	O
frozen	O
to	O
those	O
learned	O
for	O
ImageNet	B-Task
classification	I-Task
and	O
not	O
fine	O
-	O
tuned	O
in	O
the	O
image	O
channel	O
.	O
	
We	O
also	O
experimented	O
with	O
providing	O
captions	O
as	O
input	O
to	O
our	O
model	O
.	O
	
Similar	O
to	O
Table	O
1	O
,	O
we	O
assume	O
that	O
a	O
human	O
-	O
generated	O
caption	O
is	O
given	O
as	O
input	O
.	O
	
We	O
use	O
a	O
bag	B-Method
-	I-Method
of	I-Method
-	I-Method
words	I-Method
representation	I-Method
containing	O
the	O
1	O
,	O
000	O
most	O
popular	O
words	O
in	O
the	O
captions	O
as	O
the	O
caption	O
embedding	O
(	O
Caption	O
)	O
.	O
	
For	O
BoW	B-Method
Question	I-Method
+	I-Method
Caption	I-Method
(	O
BoW	B-Method
Q	I-Method
+	I-Method
C	I-Method
)	I-Method
method	I-Method
,	O
we	O
simply	O
concatenate	O
the	O
BoW	B-Method
Q	I-Method
and	I-Method
C	I-Method
embeddings	I-Method
.	O
	
possible	O
K	O
answers	O
and	O
multiple	O
-	O
choice	O
picks	O
the	O
answer	O
that	O
has	O
the	O
highest	O
activation	O
from	O
the	O
potential	O
answers	O
.	O
	
[	O
reference	O
]	O
.	O
	
The	O
accuracy	B-Metric
of	O
our	O
best	O
model	O
(	O
deeper	O
LSTM	B-Method
Q	O
+	O
norm	O
I	O
(	O
Fig	O
.	O
8	O
)	O
,	O
selected	O
using	O
VQA	B-Task
test	O
-	O
dev	O
accuracies	O
)	O
on	O
VQA	B-Task
teststandard	O
is	O
[	O
reference	O
]	O
.16	O
%	O
(	O
open	O
-	O
ended	O
)	O
/	O
63.09	O
%	O
(	O
multiple	B-Metric
-	I-Metric
choice	I-Metric
)	O
.	O
	
section	O
:	O
Results	O
	
We	O
can	O
see	O
that	O
our	O
model	O
is	O
able	O
to	O
significantly	O
outperform	O
both	O
the	O
vision	B-Method
-	I-Method
alone	I-Method
and	I-Method
language	I-Method
-	I-Method
alone	I-Method
baselines	I-Method
.	O
	
As	O
a	O
general	O
trend	O
,	O
results	O
on	O
multiple	B-Task
-	I-Task
choice	I-Task
are	O
better	O
than	O
open	O
-	O
ended	O
.	O
	
All	O
methods	O
are	O
significantly	O
worse	O
than	O
human	O
performance	O
.	O
	
Our	O
VQA	B-Task
demo	O
is	O
available	O
on	O
CloudCV	O
	
[	O
1	O
]	O
-	O
http:	O
//	O
cloudcv	O
.	O
	
org	O
/	O
vqa	O
.	O
	
This	O
will	O
be	O
updated	O
with	O
newer	O
models	O
as	O
we	O
develop	O
them	O
.	O
	
To	O
gain	O
further	O
insights	O
into	O
these	O
results	O
,	O
we	O
computed	O
accuracies	B-Metric
by	O
question	O
type	O
in	O
Table	O
3	O
.	O
	
Interestingly	O
,	O
for	O
question	O
types	O
that	O
require	O
more	O
reasoning	O
,	O
such	O
as	O
"	O
Is	O
the	O
"	O
or	O
"	O
How	O
many	O
"	O
,	O
the	O
scene	O
-	O
level	O
image	O
features	O
do	O
not	O
provide	O
any	O
additional	O
information	O
.	O
	
However	O
,	O
for	O
questions	O
that	O
can	O
be	O
answered	O
using	O
scene	O
-	O
level	O
information	O
,	O
such	O
as	O
"	O
What	O
sport	O
,	O
"	O
we	O
do	O
see	O
an	O
improvement	O
.	O
	
Similarly	O
,	O
for	O
questions	O
whose	O
answer	O
may	O
be	O
contained	O
in	O
a	O
generic	O
caption	O
we	O
see	O
improvement	O
,	O
such	O
as	O
"	O
What	O
animal	O
"	O
.	O
	
For	O
all	O
question	O
types	O
,	O
the	O
results	O
are	O
worse	O
than	O
human	B-Metric
accuracies	I-Metric
.	O
	
We	O
also	O
analyzed	O
the	O
accuracies	B-Metric
of	O
our	O
best	O
model	O
(	O
deeper	O
LSTM	B-Method
Q	O
+	O
norm	O
I	O
)	O
on	O
a	O
subset	O
of	O
questions	O
with	O
certain	O
specific	O
(	O
ground	O
truth	O
)	O
answers	O
.	O
	
In	O
Fig	O
.	O
	
9	O
,	O
we	O
show	O
the	O
average	O
accuracy	B-Metric
of	O
the	O
model	O
on	O
questions	O
with	O
50	O
most	O
frequent	O
ground	O
truth	O
answers	O
on	O
the	O
VQA	B-Material
validation	I-Material
set	I-Material
(	O
plot	O
is	O
sorted	O
by	O
accuracy	B-Metric
,	O
not	O
frequency	O
)	O
.	O
	
We	O
can	O
see	O
that	O
the	O
model	O
performs	O
well	O
for	O
answers	O
that	O
are	O
common	O
visual	O
objects	O
such	O
as	O
"	O
wii	O
"	O
,	O
"	O
tennis	O
"	O
,	O
"	O
bathroom	O
"	O
while	O
the	O
performance	O
is	O
somewhat	O
underwhelming	O
for	O
counts	O
(	O
e.g.	O
,	O
"	O
2	O
"	O
,	O
"	O
1	O
"	O
,	O
"	O
3	O
"	O
)	O
,	O
and	O
particularly	O
poor	O
for	O
higher	O
counts	O
(	O
e.g.	O
,	O
"	O
5	O
"	O
,	O
"	O
6	O
"	O
,	O
"	O
10	O
"	O
,	O
"	O
8	O
"	O
,	O
"	O
7	O
"	O
)	O
.	O
	
In	O
Fig	O
.	O
	
10	O
,	O
we	O
show	O
the	O
distribution	O
of	O
50	O
most	O
frequently	O
predicted	O
answers	O
when	O
the	O
system	O
is	O
correct	O
on	O
the	O
VQA	B-Material
validation	I-Material
set	I-Material
(	O
plot	O
is	O
sorted	O
by	O
prediction	O
frequency	O
,	O
not	O
accuracy	B-Metric
)	O
.	O
	
In	O
this	O
analysis	O
,	O
"	O
system	O
is	O
correct	O
"	O
implies	O
that	O
it	O
has	O
VQA	B-Task
accuracy	O
1.0	O
(	O
see	O
section	O
3	O
for	O
accuracy	B-Metric
metric	I-Metric
)	O
.	O
	
We	O
can	O
see	O
that	O
the	O
frequent	O
ground	O
truth	O
answers	O
(	O
e.g.	O
,	O
"	O
yes	O
"	O
,	O
"	O
no	O
"	O
,	O
"	O
2	O
"	O
,	O
"	O
white	O
"	O
,	O
"	O
red	O
"	O
,	O
"	O
blue	O
"	O
,	O
"	O
1	O
"	O
,	O
"	O
green	O
"	O
)	O
are	O
more	O
frequently	O
predicted	O
than	O
others	O
when	O
the	O
model	O
is	O
correct	O
.	O
	
Finally	O
,	O
evaluating	O
our	O
best	O
model	O
(	O
deeper	O
LSTM	B-Method
Q	O
+	O
norm	O
I	O
)	O
on	O
the	O
validation	O
questions	O
for	O
which	O
we	O
have	O
age	O
annotations	O
(	O
how	O
old	O
a	O
human	O
needs	O
to	O
be	O
to	O
answer	O
the	O
question	O
correctly	O
)	O
,	O
we	O
estimate	O
that	O
our	O
model	O
performs	O
as	O
well	O
as	O
a	O
4.74	O
year	O
old	O
child	O
!	O
	
The	O
average	O
age	O
required	O
on	O
the	O
same	O
set	O
of	O
questions	O
is	O
8.98	O
.	O
	
Evaluating	O
the	O
same	O
model	O
on	O
the	O
validation	O
questions	O
for	O
which	O
we	O
have	O
commonsense	O
annotations	O
(	O
whether	O
the	O
question	O
requires	O
commonsense	O
to	O
answer	O
it	O
)	O
,	O
we	O
estimate	O
that	O
it	O
has	O
degree	O
of	O
commonsense	O
of	O
17.35	O
%	O
.	O
	
The	O
average	O
degree	O
of	O
commonsense	O
required	O
on	O
same	O
set	O
of	O
questions	O
is	O
31.23	O
%	O
.	O
	
Again	O
,	O
these	O
estimates	O
reflect	O
the	O
age	O
and	O
commonsense	O
perceived	O
by	O
MTurk	O
workers	O
that	O
would	O
be	O
required	O
to	O
answer	O
the	O
question	O
.	O
	
See	O
the	O
appendix	O
for	O
details	O
.	O
	
We	O
further	O
analyzed	O
the	O
performance	O
of	O
the	O
model	O
for	O
different	O
age	O
groups	O
on	O
the	O
validation	O
questions	O
for	O
which	O
we	O
have	O
age	O
annotations	O
.	O
	
In	O
Fig	O
.	O
	
11	O
,	O
we	O
computed	O
the	O
average	O
accuracy	B-Metric
of	O
the	O
predictions	O
made	O
by	O
the	O
model	O
for	O
questions	O
belonging	O
to	O
different	O
age	O
groups	O
.	O
	
Perhaps	O
as	O
expected	O
,	O
the	O
accuracy	B-Metric
of	O
the	O
model	O
decreases	O
as	O
the	O
age	O
of	O
the	O
question	O
increases	O
(	O
from	O
61.07	O
%	O
at	O
3	O
−	O
4	O
age	O
group	O
to	O
47.83	O
%	O
at	O
18	O
+	O
age	O
group	O
)	O
.	O
	
In	O
Fig	O
.	O
	
12	O
,	O
we	O
show	O
the	O
distribution	O
of	O
age	O
of	O
questions	O
for	O
different	O
levels	O
of	O
accuracies	B-Metric
achieved	O
by	O
our	O
system	O
on	O
the	O
validation	O
questions	O
for	O
which	O
we	O
have	O
age	O
annotations	O
.	O
	
It	O
is	O
interesting	O
to	O
see	O
that	O
the	O
relative	O
proportions	O
of	O
different	O
age	O
groups	O
is	O
consistent	O
across	O
all	O
accuracy	O
bins	O
with	O
questions	O
belonging	O
to	O
the	O
age	O
group	O
5	O
-	O
8	O
comprising	O
the	O
majority	O
of	O
the	O
predictions	O
which	O
is	O
expected	O
because	O
5	O
-	O
8	O
is	O
the	O
most	O
common	O
age	O
group	O
in	O
the	O
dataset	O
(	O
see	O
Fig	O
.	O
7	O
)	O
.	O
	
Table	O
4	O
shows	O
the	O
accuracy	B-Metric
of	O
different	O
ablated	B-Method
versions	I-Method
of	O
our	O
best	O
model	O
(	O
deeper	O
LSTM	B-Method
Q	O
+	O
norm	O
I	O
)	O
for	O
both	O
the	O
openended	B-Task
and	I-Task
multiple	I-Task
-	I-Task
choice	I-Task
tasks	I-Task
on	O
the	O
VQA	B-Material
test	I-Material
-	I-Material
dev	I-Material
for	O
real	B-Material
images	I-Material
.	O
	
The	O
different	O
ablated	O
versions	O
are	O
as	O
follows	O
-	O
1	O
)	O
	
Without	O
I	O
Norm	O
:	O
In	O
this	O
model	O
,	O
the	O
activations	O
from	O
the	O
last	O
hidden	B-Method
layer	I-Method
of	O
VGGNet	B-Method
[	O
reference	O
]	O
are	O
not	O
2	O
-	O
normalized	O
.	O
	
Comparing	O
the	O
accuracies	B-Metric
in	O
Table	O
4	O
and	O
parameters	O
in	O
the	O
following	O
fully	B-Method
-	I-Method
connected	I-Method
layer	I-Method
.	O
	
Comparing	O
the	O
accuracies	B-Metric
in	O
Table	O
4	O
and	O
Table	O
2	O
,	O
we	O
can	O
see	O
that	O
element	B-Method
-	I-Method
wise	I-Method
fusion	I-Method
performs	O
better	O
by	O
0.95	O
%	O
for	O
open	B-Task
-	I-Task
ended	I-Task
task	I-Task
and	O
by	O
1.24	O
%	O
for	O
multiple	B-Task
-	I-Task
choice	I-Task
task	I-Task
.	O
	
3	O
)	O
	
K	O
=	O
500	O
	
:	O
In	O
this	O
model	O
,	O
we	O
use	O
K	O
=	O
500	O
most	O
frequent	O
answers	O
as	O
possible	O
outputs	O
.	O
	
Comparing	O
the	O
accuracies	B-Metric
in	O
Table	O
4	O
and	O
Table	O
2	O
,	O
we	O
can	O
see	O
that	O
K	O
=	O
1000	O
performs	O
better	O
than	O
K	O
=	O
500	O
by	O
0	O
	
.82	O
%	O
for	O
open	B-Task
-	I-Task
ended	I-Task
task	I-Task
and	O
by	O
1.92	O
%	O
for	O
multiple	B-Task
-	I-Task
choice	I-Task
task	I-Task
.	O
	
section	O
:	O
4	O
)	O
K	O
=	O
2000	O
:	O
	
In	O
this	O
model	O
,	O
we	O
use	O
K	O
=	O
2000	O
most	O
frequent	O
answers	O
as	O
possible	O
outputs	O
.	O
	
Comparing	O
the	O
accuracies	B-Metric
in	O
Table	O
4	O
and	O
Table	O
2	O
,	O
we	O
can	O
see	O
that	O
K	O
=	O
2000	O
performs	O
better	O
then	O
K	O
=	O
1000	O
by	O
0.40	O
%	O
for	O
open	B-Task
-	I-Task
ended	I-Task
task	I-Task
and	O
by	O
1.16	O
%	O
for	O
multiple	B-Task
-	I-Task
choice	I-Task
task	I-Task
.	O
	
5	O
)	O
Truncated	O
Q	O
Vocab	O
@	O
5	O
:	O
In	O
this	O
model	O
,	O
the	O
input	O
vocabulary	O
to	O
the	O
embedding	B-Method
layer	I-Method
(	O
which	O
encodes	O
the	O
question	O
words	O
)	O
consists	O
of	O
only	O
those	O
question	O
words	O
which	O
occur	O
atleast	O
5	O
times	O
in	O
the	O
training	O
dataset	O
,	O
thus	O
reducing	O
the	O
vocabulary	B-Metric
size	I-Metric
from	O
14770	O
(	O
when	O
all	O
question	O
words	O
are	O
used	O
)	O
to	O
5134	O
(	O
65.24	O
%	O
reduction	O
)	O
.	O
	
Remaining	O
question	O
words	O
are	O
replaced	O
with	O
UNK	O
(	O
unknown	O
)	O
tokens	O
.	O
	
Comparing	O
the	O
accuracies	B-Metric
in	O
Table	O
4	O
and	O
Table	O
2	O
,	O
we	O
can	O
see	O
that	O
truncating	O
the	O
question	O
vocabulary	O
@	O
5	O
performs	O
better	O
than	O
using	O
all	O
questions	O
words	O
by	O
0.24	O
%	O
for	O
openended	B-Task
task	I-Task
and	O
by	O
0.17	O
%	O
for	O
multiple	B-Task
-	I-Task
choice	I-Task
task	I-Task
.	O
	
6	O
)	O
Truncated	O
Q	O
Vocab	O
@	O
11	O
:	O
In	O
this	O
model	O
,	O
the	O
input	O
vocabulary	O
to	O
the	O
embedding	B-Method
layer	I-Method
(	O
which	O
encodes	O
the	O
question	O
words	O
)	O
consists	O
of	O
only	O
those	O
question	O
words	O
which	O
occur	O
atleast	O
11	O
times	O
in	O
the	O
training	O
dataset	O
,	O
thus	O
reducing	O
the	O
vocabulary	B-Metric
size	I-Metric
from	O
14770	O
(	O
when	O
all	O
question	O
words	O
are	O
used	O
)	O
to	O
3561	O
(	O
75.89	O
%	O
reduction	O
)	O
.	O
	
Remaining	O
question	O
words	O
are	O
replaced	O
with	O
UNK	O
(	O
unknown	O
)	O
tokens	O
.	O
	
Comparing	O
the	O
accuracies	B-Metric
in	O
Table	O
4	O
and	O
Table	O
2	O
,	O
we	O
can	O
see	O
that	O
truncating	O
the	O
question	O
vocabulary	O
@	O
11	O
performs	O
better	O
than	O
using	O
all	O
questions	O
words	O
by	O
0.06	O
%	O
for	O
open	B-Task
-	I-Task
ended	I-Task
task	I-Task
and	O
by	O
0.02	O
%	O
for	O
multiple	B-Task
-	I-Task
choice	I-Task
task	I-Task
.	O
	
7	O
)	O
	
Filtered	O
Dataset	O
	
:	O
We	O
created	O
a	O
filtered	O
version	O
of	O
the	O
VQA	B-Material
train	I-Material
+	I-Material
val	I-Material
dataset	I-Material
in	O
which	O
we	O
only	O
keep	O
the	O
answers	O
with	O
subject	O
confidence	O
"	O
yes	O
"	O
.	O
	
Also	O
,	O
we	O
keep	O
only	O
those	O
questions	O
for	O
which	O
at	O
least	O
50	O
%	O
(	O
5	O
out	O
of	O
10	O
)	O
answers	O
are	O
annotated	O
with	O
subject	O
confidence	O
"	O
yes	O
"	O
.	O
	
The	O
resulting	O
filtered	O
dataset	O
consists	O
of	O
344600	O
questions	O
,	O
compared	O
to	O
369861	O
questions	O
in	O
the	O
original	O
dataset	O
,	O
thus	O
leading	O
to	O
only	O
6.83	O
%	O
reduction	O
in	O
the	O
size	O
of	O
the	O
dataset	O
.	O
	
The	O
filtered	O
dataset	O
has	O
8.77	O
answers	O
per	O
question	O
on	O
average	O
.	O
	
We	O
did	O
not	O
filter	O
the	O
test	O
set	O
so	O
that	O
accuracies	B-Metric
of	O
the	O
model	O
trained	O
on	O
the	O
filtered	O
dataset	O
can	O
be	O
compared	O
with	O
that	O
of	O
the	O
model	O
trained	O
on	O
the	O
original	O
dataset	O
.	O
	
The	O
row	O
"	O
Filtered	O
Dataset	O
"	O
in	O
Table	O
4	O
shows	O
the	O
performance	O
of	O
the	O
deeper	O
LSTM	B-Method
Q	O
+	O
norm	O
I	O
model	O
when	O
trained	O
on	O
the	O
filtered	O
dataset	O
.	O
	
Comparing	O
these	O
accuracies	B-Metric
with	O
the	O
corresponding	O
accuracies	B-Metric
in	O
Table	O
2	O
,	O
we	O
can	O
see	O
that	O
the	O
model	O
trained	O
on	O
filtered	B-Method
version	I-Method
performs	O
worse	O
by	O
[	O
reference	O
]	O
.13	O
%	O
for	O
open	B-Task
-	I-Task
ended	I-Task
task	I-Task
and	O
by	O
1.88	O
%	O
for	O
multiplechoice	B-Task
task	I-Task
.	O
	
section	O
:	O
VQA	B-Task
CHALLENGE	O
AND	O
WORKSHOP	O
	
We	O
have	O
set	O
up	O
an	O
evaluation	O
server	O
[	O
reference	O
]	O
where	O
results	O
may	O
be	O
uploaded	O
for	O
the	O
test	O
set	O
and	O
it	O
returns	O
an	O
accuracy	B-Metric
breakdown	I-Metric
.	O
	
We	O
are	O
organizing	O
an	O
annual	O
challenge	O
and	O
workshop	O
to	O
facilitate	O
systematic	O
progress	O
in	O
this	O
area	O
;	O
the	O
first	O
instance	O
of	O
the	O
workshop	O
will	O
be	O
held	O
at	O
CVPR	O
2016	O
[	O
reference	O
]	O
.	O
	
We	O
suggest	O
that	O
papers	O
reporting	O
results	O
on	O
the	O
VQA	B-Material
dataset	I-Material
-	O
1	O
)	O
Report	O
test	B-Metric
-	I-Metric
standard	I-Metric
accuracies	I-Metric
,	O
which	O
can	O
be	O
calculated	O
using	O
either	O
of	O
the	O
non	B-Method
-	I-Method
test	I-Method
-	I-Method
dev	I-Method
phases	I-Method
,	O
i.e.	O
,	O
"	O
test2015	O
"	O
or	O
"	O
Challenge	O
test2015	O
"	O
on	O
the	O
following	O
links	O
:	O
[	O
oe	O
-	O
real	O
	
|	O
oe	O
-	O
abstract	O
	
|	O
mc	O
-	O
real	O
	
|	O
mc	O
-	O
abstract	O
]	O
.	O
2	O
)	O
Compare	O
their	O
test	O
-	O
standard	O
accuracies	B-Metric
with	O
those	O
on	O
the	O
corresponding	O
test2015	O
leaderboards	O
[	O
oe	O
-	O
real	O
-	O
leaderboard	O
|	O
oe	O
-	O
abstract	O
-	O
leaderboard	O
|	O
mc	O
-	O
real	O
-	O
leaderboard	O
|	O
mcabstract	B-Method
-	O
leaderboard	O
]	O
.	O
For	O
more	O
details	O
,	O
please	O
see	O
the	O
challenge	O
page	O
[	O
reference	O
]	O
.	O
	
Screenshots	O
of	O
leaderboards	B-Method
for	O
open	B-Material
-	I-Material
ended	I-Material
-	I-Material
real	I-Material
and	O
multiple	B-Material
-	I-Material
choice	I-Material
-	I-Material
real	I-Material
are	O
shown	O
in	O
Fig	O
.	O
13	O
.	O
	
We	O
also	O
compare	O
the	O
test	O
-	O
standard	O
accuracies	B-Metric
of	O
our	O
best	O
model	O
(	O
deeper	O
LSTM	B-Method
Q	O
+	O
norm	O
I	O
)	O
for	O
both	O
open	B-Task
-	I-Task
ended	I-Task
and	I-Task
multiple	I-Task
-	I-Task
choice	I-Task
tasks	I-Task
(	O
real	B-Material
images	I-Material
)	O
with	O
other	O
entries	O
(	O
as	O
of	O
October	O
28	O
,	O
2016	O
)	O
on	O
the	O
corresponding	O
leaderboards	O
in	O
Table	O
5	O
.	O
	
section	O
:	O
CONCLUSION	O
AND	O
DISCUSSION	O
	
In	O
conclusion	O
,	O
we	O
introduce	O
the	O
task	O
of	O
Visual	B-Task
Question	I-Task
Answering	I-Task
(	O
VQA	B-Task
)	O
.	O
	
[	O
reference	O
]	O
language	O
question	O
about	O
the	O
image	O
,	O
the	O
task	O
is	O
to	O
provide	O
an	O
accurate	O
natural	O
language	O
answer	O
.	O
	
We	O
provide	O
a	O
dataset	O
containing	O
over	O
250	O
K	O
images	O
,	O
760	O
K	O
questions	O
,	O
and	O
around	O
10	O
M	O
answers	O
.	O
	
We	O
demonstrate	O
the	O
wide	O
variety	O
of	O
questions	O
and	O
answers	O
in	O
our	O
dataset	O
,	O
as	O
well	O
as	O
the	O
diverse	O
set	O
of	O
AI	O
capabilities	O
in	O
computer	B-Method
vision	I-Method
,	O
natural	B-Method
language	I-Method
processing	I-Method
,	O
and	O
commonsense	B-Method
reasoning	I-Method
required	O
to	O
answer	O
these	O
questions	O
accurately	O
.	O
	
The	O
questions	O
we	O
solicited	O
from	O
our	O
human	O
subjects	O
were	O
open	O
-	O
ended	O
and	O
not	O
task	O
-	O
specific	O
.	O
	
For	O
some	O
application	O
domains	O
,	O
it	O
would	O
be	O
useful	O
to	O
collect	O
task	O
-	O
specific	O
questions	O
.	O
	
For	O
instance	O
,	O
questions	O
may	O
be	O
gathered	O
from	O
subjects	O
who	O
are	O
visually	O
impaired	O
[	O
reference	O
]	O
,	O
or	O
the	O
questions	O
could	O
focused	O
on	O
one	O
specific	O
domain	O
(	O
say	O
sports	O
)	O
.	O
	
Bigham	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
created	O
an	O
application	O
that	O
allows	O
the	O
visually	O
impaired	O
to	O
capture	O
images	O
and	O
ask	O
open	O
-	O
ended	O
questions	O
that	O
are	O
answered	O
by	O
human	O
subjects	O
.	O
	
Interestingly	O
,	O
these	O
questions	O
can	O
rarely	O
be	O
answered	O
using	O
generic	B-Method
captions	I-Method
.	O
	
Training	O
on	O
task	O
-	O
specific	O
datasets	O
may	O
help	O
enable	O
practical	O
VQA	B-Task
applications	I-Task
.	O
	
We	O
believe	O
VQA	B-Task
has	O
the	O
distinctive	O
advantage	O
of	O
pushing	O
the	O
frontiers	O
on	O
"	O
AI	B-Task
-	I-Task
complete	I-Task
"	I-Task
problems	I-Task
,	O
while	O
being	O
amenable	O
to	O
automatic	B-Task
evaluation	I-Task
.	O
	
Given	O
the	O
recent	O
progress	O
in	O
the	O
community	O
,	O
we	O
believe	O
the	O
time	O
is	O
ripe	O
to	O
take	O
on	O
such	O
an	O
endeavor	O
.	O
	
section	O
:	O
APPENDIX	O
OVERVIEW	O
	
In	O
the	O
appendix	O
,	O
we	O
provide	O
:	O
	
I	O
-	O
Additional	O
analysis	O
comparing	O
captions	O
and	O
Q	O
&	O
A	O
data	O
II	O
-	O
Qualitative	O
visualizations	B-Method
for	O
"	O
What	O
is	O
"	O
questions	O
III	O
-	O
Human	O
accuracy	B-Metric
on	O
multiple	B-Task
-	I-Task
choice	I-Task
questions	I-Task
	
IV	O
-	O
Details	O
on	O
VQA	B-Task
baselines	O
V	O
-	O
"Age	O
"	O
and	O
"	O
Commonsense	O
"	O
of	O
our	O
model	O
VI	O
-	O
Details	O
on	O
the	O
abstract	O
scene	O
dataset	O
	
VII	O
-	O
User	O
interfaces	O
used	O
to	O
collect	O
the	O
dataset	O
VIII	O
-	O
List	O
of	O
the	O
top	O
answers	O
in	O
the	O
dataset	O
IX	O
-	O
Additional	O
examples	O
from	O
the	O
VQA	B-Material
dataset	I-Material
	
APPENDIX	O
	
I	O
:	O
CAPTIONS	O
vs.	O
QUESTIONS	O
Do	O
questions	O
and	O
answers	O
provide	O
further	O
information	O
about	O
the	O
visual	O
world	O
beyond	O
that	O
captured	O
by	O
captions	O
?	O
	
One	O
method	O
for	O
determining	O
whether	O
the	O
information	O
captured	O
by	O
questions	O
&	O
answers	O
is	O
different	O
from	O
the	O
information	O
captured	O
by	O
captions	O
is	O
to	O
measure	O
some	O
of	O
the	O
differences	O
in	O
the	O
word	O
distributions	O
from	O
the	O
two	O
datasets	O
.	O
	
We	O
cast	O
this	O
comparison	O
in	O
terms	O
of	O
nouns	O
,	O
verbs	O
,	O
and	O
adjectives	O
by	O
extracting	O
all	O
words	O
from	O
the	O
caption	O
data	O
(	O
MS	B-Material
COCO	I-Material
captions	I-Material
for	O
real	B-Material
images	I-Material
and	O
captions	O
collected	O
by	O
us	O
for	O
abstract	B-Material
scenes	I-Material
)	O
using	O
the	O
Stanford	B-Method
part	I-Method
-	I-Method
of	I-Method
-	I-Method
speech	I-Method
(	I-Method
POS	I-Method
)	O
[	O
reference	O
]	O
tagger	O
	
[	O
reference	O
]	O
.	O
	
We	O
normalize	O
the	O
word	O
frequencies	O
from	O
captions	O
,	O
questions	O
,	O
and	O
answers	O
per	O
image	O
,	O
and	O
compare	O
captions	O
vs.	O
questions	O
and	O
answers	O
combined	O
.	O
	
Using	O
a	O
Kolmogorov	B-Method
-	I-Method
Smirnov	I-Method
test	I-Method
to	O
determine	O
whether	O
the	O
underlying	O
distributions	O
of	O
the	O
two	O
datasets	O
differ	O
,	O
we	O
find	O
a	O
significant	O
difference	O
for	O
all	O
three	O
parts	O
of	O
speech	O
(	O
p	O
<	O
.001	O
)	O
for	O
both	O
real	B-Material
images	I-Material
and	O
abstract	B-Material
scenes	I-Material
.	O
	
This	O
helps	O
motivate	O
the	O
VQA	B-Task
task	I-Task
as	O
a	O
way	O
to	O
learn	O
information	O
about	O
visual	O
scenes	O
;	O
although	O
both	O
captions	O
and	O
questions	O
&	O
answers	O
provide	O
information	O
about	O
the	O
visual	O
world	O
,	O
they	O
do	O
it	O
from	O
different	O
perspectives	O
,	O
with	O
different	O
underlying	O
biases	O
[	O
reference	O
]	O
,	O
and	O
can	O
function	O
as	O
complementary	O
to	O
one	O
another	O
.	O
	
[	O
reference	O
]	O
.	O
Noun	O
tags	O
begin	O
with	O
NN	O
,	O
verb	O
tags	O
begin	O
with	O
VB	O
,	O
adjective	O
tags	O
begin	O
with	O
JJ	O
,	O
and	O
prepositions	O
are	O
tagged	O
as	O
IN	O
.	O
	
We	O
illustrate	O
the	O
similarities	O
and	O
differences	O
between	O
the	O
word	O
distributions	O
in	O
captions	O
vs.	O
questions	O
&	O
answers	O
as	O
Venn	O
-	O
style	O
word	O
clouds	O
[	O
reference	O
]	O
with	O
size	O
indicating	O
the	O
normalized	O
count	O
-	O
Fig	O
.	O
15	O
(	O
nouns	O
)	O
,	O
Fig	O
.	O
	
16	O
(	O
verbs	O
)	O
,	O
and	O
Fig	O
.	O
	
17	O
(	O
adjectives	O
)	O
for	O
real	B-Material
images	I-Material
and	O
Fig	O
.	O
	
18	O
(	O
nouns	O
)	O
,	O
Fig	O
.	O
	
19	O
(	O
verbs	O
)	O
,	O
and	O
Fig	O
.	O
	
20	O
(	O
adjectives	O
)	O
for	O
abstract	B-Material
scenes	I-Material
.	O
	
[	O
reference	O
]	O
	
The	O
left	O
side	O
shows	O
the	O
top	O
words	O
in	O
questions	O
&	O
answers	O
,	O
the	O
right	O
the	O
top	O
words	O
in	O
captions	O
,	O
and	O
the	O
center	O
the	O
words	O
common	O
to	O
both	O
,	O
with	O
size	O
indicating	O
the	O
harmonic	O
mean	O
of	O
the	O
counts	O
.	O
	
We	O
see	O
that	O
adjectives	O
in	O
captions	O
capture	O
some	O
clearly	O
visual	O
properties	O
discussed	O
in	O
previous	O
work	O
on	O
vision	O
to	O
language	O
[	O
reference	O
]	O
,	O
such	O
as	O
material	O
and	O
pattern	O
,	O
while	O
the	O
questions	O
&	O
answers	O
have	O
more	O
adjectives	O
that	O
capture	O
what	O
is	O
usual	O
(	O
e.g.	O
,	O
"	O
dominant	O
"	O
,	O
"	O
approximate	O
"	O
,	O
"	O
higher	O
"	O
)	O
and	O
other	O
kinds	O
of	O
commonsense	O
properties	O
(	O
e.g.	O
,	O
"	O
edible	O
"	O
,	O
"	O
possible	O
"	O
,	O
"	O
unsafe	O
"	O
,	O
"	O
acceptable	O
"	O
)	O
.	O
	
Interestingly	O
,	O
we	O
see	O
that	O
question	O
&	O
answer	O
nouns	O
capture	O
information	O
about	O
"	O
ethnicity	O
"	O
and	O
"	O
hairstyle	O
"	O
,	O
while	O
caption	O
nouns	O
capture	O
information	O
about	O
pluralized	O
visible	O
objects	O
(	O
e.g.	O
,	O
"	O
cellphones	O
"	O
,	O
"	O
daughters	O
"	O
)	O
and	O
groups	O
(	O
e.g.	O
,	O
"	O
trio	O
"	O
,	O
"	O
some	O
"	O
)	O
,	O
among	O
other	O
differences	O
.	O
	
"	O
	
Man	O
"	O
and	O
"	O
people	O
"	O
are	O
common	O
in	O
both	O
captions	O
and	O
questions	O
&	O
answers	O
.	O
	
One	O
key	O
piece	O
to	O
understanding	O
the	O
visual	B-Task
world	I-Task
is	O
understanding	O
spatial	O
relationships	O
,	O
and	O
so	O
we	O
additionally	O
extract	O
spatial	O
prepositions	O
and	O
plot	O
their	O
proportions	O
in	O
the	O
captions	O
vs.	O
the	O
questions	O
&	O
answers	O
data	O
in	O
Fig	O
.	O
	
14	O
(	O
left	O
)	O
for	O
real	B-Material
images	I-Material
and	O
Fig	O
.	O
	
14	O
	
(	O
right	O
)	O
for	O
abstract	B-Material
scenes	I-Material
.	O
	
We	O
see	O
that	O
questions	O
&	O
7	O
.	O
	
Visualization	B-Task
created	O
using	O
http:	O
//	O
worditout.com	O
/	O
.	O
	
answers	O
have	O
a	O
higher	O
proportion	O
of	O
specific	O
spatial	O
relations	O
(	O
i.e.	O
,	O
"	O
in	O
"	O
,	O
"	O
on	O
"	O
)	O
compared	O
to	O
captions	O
,	O
which	O
have	O
a	O
higher	O
proportion	O
of	O
general	O
spatial	O
relations	O
(	O
i.e.	O
,	O
"	O
with	O
"	O
,	O
"	O
near	O
"	O
)	O
.	O
	
For	O
each	O
of	O
the	O
two	O
datasets	O
,	O
real	O
and	O
abstract	O
,	O
first	O
two	O
rows	O
are	O
the	O
human	B-Metric
accuracies	I-Metric
for	O
multiple	B-Task
-	I-Task
choice	I-Task
questions	I-Task
when	O
subjects	O
were	O
shown	O
both	O
the	O
image	O
and	O
the	O
question	O
.	O
	
Majority	O
vote	O
means	O
we	O
consider	O
the	O
answer	O
picked	O
by	O
majority	O
of	O
the	O
three	O
subjects	O
to	O
be	O
the	O
predicted	O
answer	O
by	O
humans	O
and	O
compute	O
accuracy	B-Metric
of	O
that	O
answer	O
for	O
each	O
question	O
.	O
	
Average	O
means	O
we	O
compute	O
the	O
accuracy	B-Metric
of	O
each	O
of	O
the	O
answers	O
picked	O
by	O
the	O
subjects	O
and	O
record	O
their	O
average	O
for	O
each	O
question	O
.	O
	
The	O
last	O
row	O
is	O
the	O
inter	O
-	O
human	O
agreement	O
for	O
open	B-Task
-	I-Task
ended	I-Task
answers	I-Task
task	I-Task
when	O
subjects	O
were	O
shown	O
both	O
the	O
image	O
and	O
the	O
question	O
.	O
	
All	O
accuracies	B-Metric
are	O
evaluated	O
on	O
a	O
random	O
subset	O
of	O
3000	O
questions	O
.	O
	
section	O
:	O
APPENDIX	O
II	O
:	O
"	O
WHAT	O
IS	O
"	O
ANALYSIS	O
	
In	O
Fig	O
.	O
21	O
,	O
we	O
show	O
the	O
distribution	O
of	O
questions	O
starting	O
with	O
"	O
What	O
is	O
"	O
by	O
their	O
first	O
five	O
words	O
for	O
both	O
real	B-Material
images	I-Material
and	O
abstract	B-Material
scenes	I-Material
.	O
	
Note	O
the	O
diversity	O
of	O
objects	O
referenced	O
in	O
the	O
questions	O
,	O
as	O
well	O
as	O
,	O
the	O
relations	O
between	O
objects	O
,	O
such	O
as	O
"	O
holding	O
"	O
and	O
"	O
sitting	O
on	O
"	O
.	O
	
In	O
Fig	O
.	O
	
22	O
,	O
we	O
show	O
the	O
distribution	O
of	O
answers	O
for	O
"	O
What	O
is	O
"	O
questions	O
ending	O
in	O
different	O
words	O
.	O
	
For	O
instance	O
,	O
questions	O
ending	O
in	O
"	O
eating	O
"	O
have	O
answers	O
such	O
as	O
"	O
pizza	O
"	O
,	O
"	O
watermelon	O
"	O
and	O
"	O
hot	O
dog	O
"	O
.	O
	
Notice	O
the	O
diversity	O
in	O
answers	O
for	O
some	O
questions	O
,	O
such	O
as	O
those	O
that	O
end	O
with	O
"	O
for	O
?	O
"	O
or	O
"	O
picture	O
?	O
"	O
.	O
	
Other	O
questions	O
result	O
in	O
intuitive	O
responses	O
,	O
such	O
as	O
"	O
holding	O
?	O
"	O
and	O
the	O
response	O
"	O
umbrella	O
"	O
.	O
	
section	O
:	O
APPENDIX	O
III	O
:	O
MULTIPLE	B-Task
-	I-Task
CHOICE	I-Task
HUMAN	I-Task
AC	I-Task
-	I-Task
CURACY	I-Task
	
To	O
compute	O
human	B-Metric
accuracy	I-Metric
for	O
multiple	B-Task
-	I-Task
choice	I-Task
questions	I-Task
,	O
we	O
collected	O
three	O
human	O
answers	O
per	O
question	O
on	O
a	O
random	O
subset	O
of	O
3	O
,	O
000	O
questions	O
for	O
both	O
real	B-Material
images	I-Material
and	O
abstract	B-Material
scenes	I-Material
.	O
	
In	O
Table	O
6	O
,	O
we	O
show	O
the	O
human	B-Metric
accuracies	I-Metric
for	O
multiple	O
choice	O
questions	O
.	O
	
Table	O
6	O
also	O
shows	O
the	O
inter	O
-	O
human	B-Metric
agreement	I-Metric
for	O
open	B-Task
-	I-Task
ended	I-Task
answer	I-Task
task	I-Task
.	O
	
In	O
comparison	O
to	O
openended	O
answer	O
,	O
the	O
multiple	B-Metric
-	I-Metric
choice	I-Metric
accuracies	I-Metric
are	O
more	O
or	O
less	O
same	O
for	O
"	O
yes	O
/	O
no	O
"	O
questions	O
and	O
significantly	O
better	O
(	O
≈	O
15	O
%	O
increase	O
for	O
real	B-Material
images	I-Material
and	O
≈	O
11	O
%	O
increase	O
for	O
abstract	B-Material
scenes	I-Material
)	O
for	O
"	O
other	O
"	O
questions	O
.	O
	
Since	O
"	O
other	O
"	O
questions	O
may	O
be	O
ambiguous	O
,	O
the	O
increase	O
in	O
accuracy	B-Metric
using	O
multiple	O
choice	O
is	O
not	O
surprising	O
.	O
	
section	O
:	O
APPENDIX	O
IV	O
:	O
DETAILS	O
ON	O
VQA	B-Task
BASELINES	O
	
"	O
per	O
Q	B-Method
-	I-Method
type	I-Method
prior	I-Method
"	O
baseline	O
.	O
	
We	O
decide	O
on	O
different	O
question	O
types	O
based	O
on	O
first	O
few	O
words	O
of	O
questions	O
in	O
the	O
real	B-Material
images	I-Material
training	O
set	O
and	O
ensure	O
that	O
each	O
question	O
type	O
has	O
at	O
least	O
30	O
questions	O
in	O
the	O
training	O
dataset	O
.	O
	
The	O
most	O
popular	O
answer	O
for	O
each	O
question	O
type	O
is	O
also	O
computed	O
on	O
real	B-Material
images	I-Material
training	O
set	O
.	O
	
"	O
nearest	B-Method
neighbor	I-Method
"	O
baseline	O
.	O
	
For	O
every	O
question	O
in	O
the	O
VQA	B-Task
test	O
-	O
standard	O
set	O
,	O
we	O
find	O
its	O
k	O
nearest	B-Method
neighbor	I-Method
questions	O
in	O
the	O
training	O
set	O
using	O
cosine	O
similarity	O
in	O
Skip	O
-	O
Thought	O
[	O
reference	O
]	O
feature	O
space	O
.	O
	
We	O
also	O
experimented	O
with	O
bag	O
of	O
words	O
and	O
Word2Vec	O
[	O
reference	O
]	O
feature	O
spaces	O
but	O
we	O
obtained	O
the	O
best	O
performance	O
with	O
Skip	O
-	O
Thought	O
.	O
	
In	O
this	O
set	O
of	O
k	O
questions	O
and	O
their	O
associated	O
images	O
,	O
we	O
find	O
the	O
image	O
which	O
is	O
most	O
similar	O
to	O
the	O
query	O
image	O
using	O
cosine	O
similarity	O
in	O
fc7	O
feature	O
space	O
.	O
	
We	O
use	O
the	O
fc7	O
features	O
from	O
the	O
caffenet	B-Method
model	I-Method
in	O
BVLC	B-Method
Caffe	I-Method
	
[	O
reference	O
]	O
.	O
	
The	O
most	O
common	O
ground	O
truth	O
answer	O
of	O
this	O
most	O
similar	O
image	O
and	O
question	O
pair	O
is	O
the	O
predicted	O
answer	O
for	O
the	O
query	O
image	O
and	O
question	O
pair	O
.	O
	
We	O
pick	O
k	O
=	O
4	O
on	O
the	O
test	O
-	O
dev	O
set	O
.	O
	
APPENDIX	O
V	O
:	O
"	O
AGE	O
"	O
AND	O
"	O
COMMONSENSE	O
"	O
	
section	O
:	O
OF	O
OUR	O
MODEL	O
	
We	O
estimate	O
the	O
age	O
and	O
degree	O
of	O
commonsense	O
of	O
our	O
best	O
model	O
(	O
deeper	O
LSTM	B-Method
Q	O
+	O
norm	O
I	O
)	O
,	O
selected	O
using	O
VQA	B-Task
testdev	O
accuracies	O
)	O
.	O
	
To	O
estimate	O
the	O
age	O
,	O
we	O
compute	O
a	O
weighted	O
average	O
of	O
the	O
average	B-Metric
age	I-Metric
per	O
question	O
,	O
weighted	O
by	O
the	O
accuracy	B-Metric
of	O
the	O
model	O
's	O
predicted	O
answer	O
for	O
that	O
question	O
,	O
on	O
the	O
subset	O
of	O
questions	O
in	O
the	O
VQA	B-Material
validation	I-Material
set	I-Material
for	O
which	O
we	O
have	O
age	O
annotations	O
(	O
how	O
old	O
a	O
human	O
needs	O
to	O
be	O
to	O
answer	O
the	O
question	O
correctly	O
)	O
.	O
	
To	O
estimate	O
the	O
degree	O
of	O
commonsense	O
,	O
we	O
compute	O
a	O
weighted	O
average	O
of	O
the	O
average	B-Metric
degree	I-Metric
of	I-Metric
commonsense	I-Metric
per	O
question	O
,	O
weighted	O
by	O
the	O
accuracy	B-Metric
of	O
the	O
model	O
's	O
predicted	O
answer	O
for	O
that	O
question	O
,	O
on	O
the	O
subset	O
of	O
questions	O
in	O
the	O
VQA	B-Task
validation	O
set	O
for	O
which	O
we	O
have	O
commonsense	O
annotations	O
(	O
whether	O
the	O
question	O
requires	O
commonsense	O
to	O
answer	O
it	O
)	O
.	O
	
section	O
:	O
APPENDIX	O
VI	O
:	O
ABSTRACT	O
SCENES	O
DATASET	O
	
In	O
Fig	O
.	O
23	O
(	O
left	O
)	O
,	O
we	O
show	O
a	O
subset	O
of	O
the	O
objects	O
that	O
are	O
present	O
in	O
the	O
abstract	B-Material
scenes	I-Material
dataset	O
.	O
	
For	O
more	O
examples	O
of	O
the	O
scenes	O
generated	O
,	O
please	O
see	O
Fig	O
.	O
28	O
.	O
	
The	O
user	O
interface	O
used	O
to	O
create	O
the	O
scenes	O
is	O
shown	O
in	O
Fig	O
.	O
	
23	O
	
(	O
right	O
)	O
.	O
	
Subjects	O
used	O
a	O
drag	B-Method
-	I-Method
and	I-Method
-	I-Method
drop	I-Method
interface	I-Method
to	O
create	O
the	O
scenes	O
.	O
	
Each	O
object	O
could	O
be	O
flipped	O
horizontally	O
and	O
scaled	O
.	O
	
The	O
scale	O
of	O
the	O
object	O
determined	O
the	O
rendering	O
order	O
of	O
the	O
objects	O
.	O
	
Many	O
objects	O
have	O
different	O
attributes	O
corresponding	O
to	O
different	O
poses	O
or	O
types	O
.	O
	
Most	O
animals	O
have	O
five	O
different	O
discrete	O
poses	O
.	O
	
Humans	O
have	O
eight	O
discrete	O
expressions	O
and	O
their	O
poses	O
may	O
be	O
continuously	O
adjusted	O
using	O
a	O
"	O
paperdoll	B-Method
"	I-Method
model	I-Method
[	O
reference	O
]	O
.	O
	
section	O
:	O
APPENDIX	O
VII	O
:	O
USER	O
INTERFACES	O
	
In	O
Fig	O
.	O
	
24	O
	
,	O
we	O
show	O
the	O
AMT	B-Method
interface	I-Method
that	O
we	O
used	O
to	O
collect	O
questions	O
for	O
images	O
.	O
	
Note	O
that	O
we	O
tell	O
the	O
workers	O
that	O
the	O
robot	O
already	O
knows	O
the	O
answer	O
to	O
the	O
previously	O
asked	O
question	O
(	O
s	O
)	O
,	O
inspiring	O
them	O
to	O
ask	O
different	O
kinds	O
of	O
questions	O
,	O
thereby	O
increasing	O
the	O
diversity	O
of	O
our	O
dataset	O
.	O
	
Fig	O
.	O
	
25	O
shows	O
the	O
AMT	B-Method
interface	I-Method
used	O
for	O
collecting	O
answers	O
to	O
the	O
previously	O
collected	O
questions	O
when	O
subjects	O
were	O
shown	O
the	O
corresponding	O
images	O
.	O
	
Fig	O
.	O
	
26	O
shows	O
the	O
interface	O
that	O
was	O
used	O
to	O
collect	O
answers	O
to	O
questions	O
when	O
subjects	O
were	O
not	O
shown	O
the	O
corresponding	O
image	O
(	O
i.e.	O
,	O
to	O
help	O
in	O
gathering	O
incorrect	O
,	O
but	O
plausible	O
,	O
answers	O
for	O
the	O
multiplechoice	B-Task
task	I-Task
and	O
to	O
assess	O
how	O
accurately	O
the	O
questions	O
can	O
be	O
answered	O
using	O
common	O
sense	O
knowledge	O
alone	O
)	O
.	O
	
section	O
:	O
Real	B-Material
Images	I-Material
Abstract	O
Scenes	O
	
What	O
is	O
What	O
is	O
The	O
AMT	B-Method
interface	I-Method
used	O
to	O
collect	O
answers	O
to	O
a	O
question	O
when	O
subjects	O
were	O
not	O
shown	O
the	O
image	O
while	O
answering	O
the	O
question	O
using	O
only	O
commonsense	O
to	O
collect	O
the	O
plausible	O
,	O
but	O
incorrect	O
,	O
multiple	O
-	O
choice	O
answers	O
.	O
	
section	O
:	O
21	O
	
section	O
:	O
APPENDIX	O
VIII	O
:	O
ANSWER	B-Task
DISTRIBUTION	I-Task
	
The	O
top	O
250	O
answers	O
in	O
our	O
real	B-Material
images	I-Material
dataset	O
along	O
with	O
their	O
counts	O
and	O
percentage	O
counts	O
are	O
given	O
below	O
.	O
	
The	O
answers	O
have	O
been	O
presented	O
in	O
different	O
colors	O
to	O
show	O
the	O
different	O
Part	O
-	O
of	O
-	O
Speech	O
(	O
POS	O
)	O
tagging	O
of	O
the	O
answers	O
with	O
the	O
following	O
color	O
code	O
:	O
yes	O
/	O
no	O
,	O
noun	O
,	O
verb	O
,	O
adjective	O
,	O
adverb	O
,	O
and	O
numeral	O
.	O
	
"	O
	
yes	O
"	O
(	O
566613	O
,	O
22.82	O
%	O
)	O
,	O
"	O
no	O
"	O
(	O
381307	O
,	O
15.35	O
%	O
)	O
,	O
"	O
2	O
"	O
(	O
80031	O
,	O
3.22	O
%	O
)	O
,	O
"	O
1	O
"	O
(	O
46537	O
,	O
1.87	O
%	O
)	O
,	O
"	O
white	O
"	O
(	O
41753	O
,	O
1.68	O
%	O
)	O
,	O
"	O
3	O
"	O
(	O
41334	O
,	O
1.66	O
%	O
)	O
,	O
"	O
red	O
"	O
(	O
33834	O
,	O
1.36	O
%	O
)	O
,	O
"	O
blue	O
"	O
(	O
28881	O
,	O
1.16	O
%	O
)	O
,	O
"	O
4	O
"	O
(	O
27174	O
,	O
1.09	O
%	O
)	O
,	O
"	O
green	O
"	O
(	O
22453	O
,	O
0.9	O
%	O
)	O
,	O
"	O
black	O
"	O
(	O
21852	O
,	O
0.88	O
%	O
)	O
,	O
"	O
yellow	O
"	O
(	O
17312	O
,	O
0.7	O
%	O
)	O
,	O
"	O
brown	O
"	O
(	O
14488	O
,	O
0.58	O
%	O
)	O
,	O
"	O
5	O
"	O
(	O
14373	O
,	O
0.58	O
%	O
)	O
,	O
"	O
tennis	O
"	O
(	O
10941	O
,	O
0.44%	O
),	O
"baseball	O
"	O
(	O
10299	O
,	O
0.41	O
%	O
)	O
,	O
"	O
6	O
"	O
(	O
10103	O
,	O
0.41	O
%	O
)	O
,	O
"	O
orange	O
"	O
(	O
9136	O
,	O
0.37	O
%	O
)	O
,	O
"	O
0	O
"	O
(	O
8812	O
,	O
0.35	O
%	O
)	O
,	O
"	O
bathroom	O
"	O
(	O
8473	O
,	O
0.34	O
%	O
)	O
,	O
"	O
wood	O
"	O
(	O
8219	O
,	O
0.33	O
%	O
)	O
,	O
"	O
right	O
"	O
(	O
8209	O
,	O
0.33	O
%	O
)	O
,	O
"	O
left	O
"	O
(	O
8058	O
,	O
0.32	O
%	O
)	O
,	O
"	O
frisbee	O
"	O
(	O
7671	O
,	O
0.31	O
%	O
)	O
,	O
"	O
pink	O
"	O
(	O
7519	O
,	O
0.3	O
%	O
)	O
,	O
"	O
gray	O
"	O
(	O
7385	O
,	O
0.3	O
%	O
)	O
,	O
"	O
pizza	O
"	O
(	O
6892	O
,	O
0.28	O
%	O
)	O
,	O
"	O
7	O
"	O
(	O
6005	O
,	O
0.24	O
%	O
)	O
,	O
"	O
kitchen	O
"	O
(	O
5926	O
,	O
0.24	O
%	O
)	O
,	O
"	O
8	O
"	O
(	O
5592	O
,	O
0.23	O
%	O
)	O
,	O
"	O
cat	O
"	O
(	O
5514	O
,	O
0.22	O
%	O
)	O
,	O
"	O
skiing	O
"	O
(	O
5189	O
,	O
0.21	O
%	O
)	O
,	O
"	O
skateboarding	O
"	O
(	O
5122	O
,	O
0.21	O
%	O
)	O
,	O
"	O
dog	O
"	O
(	O
5092	O
,	O
0.21	O
%	O
)	O
,	O
"	O
snow	O
"	O
(	O
4867	O
,	O
0.2	O
%	O
)	O
,	O
"	O
black	O
and	O
white	O
"	O
(	O
4852	O
,	O
0.2	O
%	O
)	O
,	O
"	O
skateboard	O
"	O
(	O
4697	O
,	O
0.19	O
%	O
)	O
,	O
"	O
surfing	O
"	O
(	O
4544	O
,	O
0.18	O
%	O
)	O
,	O
"	O
water	O
"	O
(	O
4513	O
,	O
0.18	O
%	O
)	O
,	O
"	O
giraffe	O
"	O
(	O
4027	O
,	O
0.16	O
%	O
)	O
,	O
"	O
grass	O
"	O
(	O
3979	O
,	O
0.16	O
%	O
)	O
,	O
"	O
surfboard	O
"	O
(	O
3934	O
,	O
0.16	O
%	O
)	O
,	O
"	O
wii	O
"	O
(	O
3898	O
,	O
0.16	O
%	O
)	O
,	O
"	O
kite	O
"	O
(	O
3852	O
,	O
0.16	O
%	O
)	O
,	O
"	O
10	O
"	O
(	O
3756	O
,	O
0.15	O
%	O
)	O
,	O
"	O
purple	O
"	O
(	O
3722	O
,	O
0.15	O
%	O
)	O
,	O
"	O
elephant	O
"	O
(	O
3646	O
,	O
0.15	O
%	O
)	O
,	O
"	O
broccoli	O
"	O
(	O
3604	O
,	O
0.15	O
%	O
)	O
,	O
"	O
man	O
"	O
(	O
3590	O
,	O
0.14	O
%	O
)	O
,	O
"	O
winter	O
"	O
(	O
3490	O
,	O
0.14	O
%	O
)	O
,	O
"	O
stop	O
"	O
(	O
3413	O
,	O
0.14	O
%	O
)	O
,	O
"	O
train	O
"	O
(	O
3226	O
,	O
0.13	O
%	O
)	O
,	O
"	O
9	O
"	O
(	O
3217	O
,	O
0.13	O
%	O
)	O
,	O
"	O
apple	O
"	O
(	O
3189	O
,	O
0.13	O
%	O
)	O
,	O
"	O
silver	O
"	O
(	O
3186	O
,	O
0.13	O
%	O
)	O
,	O
"	O
horse	O
"	O
(	O
3159	O
,	O
0.13	O
%	O
)	O
,	O
"	O
banana	O
"	O
(	O
3151	O
,	O
0.13	O
%	O
)	O
,	O
"	O
umbrella	O
"	O
(	O
3139	O
,	O
0.13	O
%	O
)	O
,	O
"	O
eating	O
"	O
(	O
3117	O
,	O
0.13	O
%	O
)	O
,	O
"	O
sheep	O
"	O
(	O
2927	O
,	O
0.12	O
%	O
)	O
,	O
"	O
bear	O
"	O
(	O
2803	O
,	O
0.11	O
%	O
)	O
,	O
"	O
phone	O
"	O
(	O
2772	O
,	O
0.11	O
%	O
)	O
,	O
"	O
12	O
"	O
(	O
2633	O
,	O
0.11	O
%	O
)	O
,	O
"	O
motorcycle	O
"	O
(	O
2608	O
,	O
0.11	O
%	O
)	O
,	O
"	O
cake	O
"	O
(	O
2602	O
,	O
0.1	O
%	O
)	O
,	O
"	O
wine	O
"	O
(	O
2574	O
,	O
0.1	O
%	O
)	O
,	O
"	O
beach	O
"	O
(	O
2536	O
,	O
0.1	O
%	O
)	O
,	O
"	O
soccer	O
"	O
(	O
2504	O
,	O
0.1	O
%	O
)	O
,	O
"	O
sunny	O
"	O
(	O
2475	O
,	O
0.1	O
%	O
)	O
,	O
"	O
zebra	O
"	O
(	O
2403	O
,	O
0.1	O
%	O
)	O
,	O
"	O
tan	O
"	O
(	O
2402	O
,	O
0.1	O
%	O
)	O
,	O
"	O
brick	O
"	O
(	O
2395	O
,	O
0.1	O
%	O
)	O
,	O
"	O
female	O
"	O
(	O
2372	O
,	O
0.1	O
%	O
)	O
,	O
"	O
bananas	O
"	O
(	O
2350	O
,	O
0.09	O
%	O
)	O
,	O
"	O
table	O
"	O
(	O
2331	O
,	O
0.09	O
%	O
)	O
,	O
"	O
laptop	O
"	O
(	O
2316	O
,	O
0.09	O
%	O
)	O
,	O
"	O
hat	O
"	O
(	O
2277	O
,	O
0.09	O
%	O
)	O
,	O
"	O
bench	O
"	O
(	O
2259	O
,	O
0.09	O
%	O
)	O
,	O
"	O
flowers	O
"	O
(	O
2219	O
,	O
0.09	O
%	O
)	O
,	O
"	O
woman	O
"	O
(	O
2197	O
,	O
0.09	O
%	O
)	O
,	O
"	O
male	O
"	O
(	O
2170	O
,	O
0.09	O
%	O
)	O
,	O
"	O
cow	O
"	O
(	O
2084	O
,	O
0.08	O
%	O
)	O
,	O
"	O
food	O
"	O
(	O
2083	O
,	O
0.08	O
%	O
)	O
,	O
"	O
living	O
room	O
"	O
(	O
2022	O
,	O
0.08	O
%	O
)	O
,	O
"	O
bus	O
"	O
(	O
2011	O
,	O
0.08	O
%	O
)	O
,	O
"	O
snowboarding	O
"	O
(	O
1990	O
,	O
0.08	O
%	O
)	O
,	O
"	O
kites	O
"	O
(	O
1979	O
,	O
0.08	O
%	O
)	O
,	O
"	O
cell	O
phone	O
"	O
(	O
1943	O
,	O
0.08	O
%	O
)	O
,	O
"	O
helmet	O
"	O
(	O
1885	O
,	O
0.08	O
%	O
)	O
,	O
"	O
maybe	O
"	O
(	O
1853	O
,	O
0.07	O
%	O
)	O
,	O
"	O
outside	O
"	O
(	O
1846	O
,	O
0.07	O
%	O
)	O
,	O
"	O
hot	O
dog	O
"	O
(	O
1809	O
,	O
0.07	O
%	O
)	O
,	O
"	O
night	O
"	O
(	O
1805	O
,	O
0.07	O
%	O
)	O
,	O
"	O
trees	O
"	O
(	O
1785	O
,	O
0.07	O
%	O
)	O
,	O
"	O
11	O
"	O
(	O
1753	O
,	O
0.07	O
%	O
)	O
,	O
"	O
bird	O
"	O
(	O
1739	O
,	O
0.07	O
%	O
)	O
,	O
"	O
down	O
"	O
(	O
1732	O
,	O
0.07	O
%	O
)	O
,	O
"	O
bed	O
"	O
(	O
1587	O
,	O
0.06	O
%	O
)	O
,	O
"	O
camera	O
"	O
(	O
1560	O
,	O
0.06	O
%	O
)	O
,	O
"	O
tree	O
"	O
(	O
1547	O
,	O
0.06	O
%	O
)	O
,	O
"	O
christmas	O
"	O
(	O
1544	O
,	O
0.06	O
%	O
)	O
,	O
"	O
fence	O
"	O
(	O
1543	O
,	O
0.06	O
%	O
)	O
,	O
"	O
nothing	O
"	O
(	O
1538	O
,	O
0.06	O
%	O
)	O
,	O
"	O
unknown	O
"	O
(	O
1532	O
,	O
0.06	O
%	O
)	O
,	O
"	O
tennis	O
racket	O
"	O
(	O
1525	O
,	O
0.06	O
%	O
)	O
,	O
"	O
red	O
and	O
white	O
"	O
(	O
1518	O
,	O
0.06	O
%	O
)	O
,	O
"	O
bedroom	O
"	O
(	O
1500	O
,	O
0.06	O
%	O
)	O
,	O
"	O
bat	O
"	O
(	O
1494	O
,	O
0.06	O
%	O
)	O
,	O
"	O
glasses	O
"	O
(	O
1491	O
,	O
0.06	O
%	O
)	O
,	O
"	O
tile	O
"	O
(	O
1487	O
,	O
0.06	O
%	O
)	O
,	O
"	O
metal	O
"	O
(	O
1470	O
,	O
0.06	O
%	O
)	O
,	O
"	O
blue	O
and	O
white	O
"	O
(	O
1440	O
,	O
0.06	O
%	O
)	O
,	O
"	O
fork	O
"	O
(	O
1439	O
,	O
0.06	O
%	O
)	O
,	O
"	O
plane	O
"	O
(	O
1439	O
,	O
0.06	O
%	O
)	O
,	O
"	O
airport	O
"	O
(	O
1422	O
,	O
0.06	O
%	O
)	O
,	O
"	O
cloudy	O
"	O
(	O
1413	O
,	O
0.06	O
%	O
)	O
,	O
"	O
15	O
"	O
(	O
1407	O
,	O
0.06	O
%	O
)	O
,	O
"	O
up	O
"	O
(	O
1399	O
,	O
0.06	O
%	O
)	O
,	O
"	O
blonde	O
"	O
(	O
1398	O
,	O
0.06	O
%	O
)	O
,	O
"	O
day	O
"	O
(	O
1396	O
,	O
0.06	O
%	O
)	O
,	O
"	O
teddy	O
bear	O
"	O
(	O
1386	O
,	O
0.06	O
%	O
)	O
,	O
"	O
glass	O
"	O
(	O
1379	O
,	O
0.06	O
%	O
)	O
,	O
"	O
20	O
"	O
(	O
1365	O
,	O
0.05	O
%	O
)	O
,	O
"	O
beer	O
"	O
(	O
1345	O
,	O
0.05	O
%	O
)	O
,	O
"	O
car	O
"	O
(	O
1331	O
,	O
0.05	O
%	O
)	O
,	O
"	O
sitting	O
"	O
(	O
1328	O
,	O
0.05	O
%	O
)	O
,	O
"	O
boat	O
"	O
(	O
1326	O
,	O
0.05	O
%	O
)	O
,	O
"	O
standing	O
"	O
(	O
1326	O
,	O
0.05	O
%	O
)	O
,	O
"	O
clear	O
"	O
(	O
1318	O
,	O
0.05	O
%	O
)	O
,	O
"	O
13	O
"	O
(	O
1318	O
,	O
0.05	O
%	O
)	O
,	O
"	O
nike	O
"	O
(	O
1293	O
,	O
0.05	O
%	O
)	O
,	O
"	O
sand	O
"	O
(	O
1282	O
,	O
0.05	O
%	O
)	O
,	O
"	O
open	O
"	O
(	O
1279	O
,	O
0.05	O
%	O
)	O
,	O
"	O
cows	O
"	O
(	O
1271	O
,	O
0.05	O
%	O
)	O
,	O
"	O
bike	O
"	O
(	O
1267	O
,	O
0.05	O
%	O
)	O
,	O
"	O
chocolate	O
"	O
(	O
1266	O
,	O
0.05	O
%	O
)	O
,	O
"	O
donut	O
"	O
(	O
1263	O
,	O
0.05	O
%	O
)	O
,	O
"	O
airplane	O
"	O
(	O
1247	O
,	O
0.05	O
%	O
)	O
,	O
"	O
birthday	O
"	O
(	O
1241	O
,	O
0.05	O
%	O
)	O
,	O
"	O
carrots	O
"	O
(	O
1239	O
,	O
0.05	O
%	O
)	O
,	O
"	O
skis	O
"	O
(	O
1220	O
,	O
0.05	O
%	O
)	O
,	O
"	O
girl	O
"	O
(	O
1220	O
,	O
0.05	O
%	O
)	O
,	O
"	O
many	O
"	O
(	O
1211	O
,	O
0.05	O
%	O
)	O
,	O
"	O
zoo	O
"	O
(	O
1204	O
,	O
0.05	O
%	O
)	O
,	O
"	O
suitcase	O
"	O
(	O
1199	O
,	O
0.05	O
%	O
)	O
,	O
"	O
old	O
"	O
(	O
1180	O
,	O
0.05	O
%	O
)	O
,	O
"	O
chair	O
"	O
(	O
1174	O
,	O
0.05	O
%	O
)	O
,	O
"	O
beige	O
"	O
(	O
1170	O
,	O
0.05	O
%	O
)	O
,	O
"	O
ball	O
"	O
(	O
1169	O
,	O
0.05	O
%	O
)	O
,	O
"	O
ocean	O
"	O
(	O
1168	O
,	O
0.05	O
%	O
)	O
,	O
"	O
sandwich	O
"	O
(	O
1168	O
,	O
0.05	O
%	O
)	O
,	O
"	O
tie	O
"	O
(	O
1166	O
,	O
0.05	O
%	O
)	O
,	O
"	O
horses	O
"	O
(	O
1163	O
,	O
0.05	O
%	O
)	O
,	O
"	O
palm	O
"	O
(	O
1163	O
,	O
0.05	O
%	O
)	O
,	O
"	O
stripes	O
"	O
(	O
1155	O
,	O
0.05	O
%	O
)	O
,	O
"	O
fall	O
"	O
(	O
1146	O
,	O
0.05	O
%	O
)	O
,	O
"	O
cheese	O
"	O
(	O
1142	O
,	O
0.05	O
%	O
)	O
,	O
"	O
scissors	O
"	O
(	O
1134	O
,	O
0.05	O
%	O
)	O
,	O
"	O
round	O
"	O
(	O
1125	O
,	O
0.05	O
%	O
)	O
,	O
"	O
chinese	O
"	O
(	O
1123	O
,	O
0.05	O
%	O
)	O
,	O
"	O
knife	O
"	O
(	O
1120	O
,	O
0.05	O
%	O
)	O
,	O
"	O
14	O
"	O
(	O
1110	O
,	O
0.04	O
%	O
)	O
,	O
"	O
toilet	O
"	O
(	O
1099	O
,	O
0.04	O
%	O
)	O
,	O
	
"	O
do	O
n't	O
know	O
"	O
(	O
1085	O
,	O
0.04	O
%	O
)	O
,	O
"	O
snowboard	O
"	O
(	O
1083	O
,	O
0.04	O
%	O
)	O
,	O
"	O
truck	O
"	O
(	O
1076	O
,	O
0.04	O
%	O
)	O
,	O
"	O
boy	O
"	O
(	O
1070	O
,	O
0.04	O
%	O
)	O
,	O
"	O
coffee	O
"	O
(	O
1070	O
,	O
0.04	O
%	O
)	O
,	O
"	O
cold	O
"	O
(	O
1064	O
,	O
0.04	O
%	O
)	O
,	O
"	O
fruit	O
"	O
(	O
1064	O
,	O
0.04	O
%	O
)	O
,	O
"	O
walking	O
"	O
(	O
1053	O
,	O
0.04	O
%	O
)	O
,	O
"	O
wedding	O
"	O
(	O
1051	O
,	O
0.04	O
%	O
)	O
,	O
"	O
lot	O
"	O
(	O
1050	O
,	O
0.04	O
%	O
)	O
,	O
"	O
sunglasses	O
"	O
(	O
1047	O
,	O
0.04	O
%	O
)	O
,	O
"	O
mountains	O
"	O
(	O
1030	O
,	O
0.04	O
%	O
)	O
,	O
"	O
wall	O
"	O
(	O
1009	O
,	O
0.04	O
%	O
)	O
,	O
"	O
elephants	O
"	O
(	O
1006	O
,	O
0.04	O
%	O
)	O
,	O
"	O
wetsuit	O
"	O
(	O
998	O
,	O
0.04	O
%	O
)	O
,	O
"	O
square	O
"	O
(	O
994	O
,	O
0.04	O
%	O
)	O
,	O
"	O
toothbrush	O
"	O
(	O
989	O
,	O
0.04	O
%	O
)	O
,	O
"	O
sleeping	O
"	O
(	O
986	O
,	O
0.04	O
%	O
)	O
,	O
"	O
fire	O
hydrant	O
"	O
(	O
977	O
,	O
0.04	O
%	O
)	O
,	O
"	O
bicycle	O
"	O
(	O
973	O
,	O
0.04	O
%	O
)	O
,	O
"	O
overcast	O
"	O
(	O
968	O
,	O
0.04	O
%	O
)	O
,	O
"	O
donuts	O
"	O
(	O
961	O
,	O
0.04	O
%	O
)	O
,	O
"	O
plastic	O
"	O
(	O
961	O
,	O
0.04	O
%	O
)	O
,	O
"	O
breakfast	O
"	O
(	O
955	O
,	O
0.04	O
%	O
)	O
,	O
"	O
tv	O
"	O
(	O
953	O
,	O
0.04	O
%	O
)	O
,	O
"	O
paper	O
"	O
(	O
952	O
,	O
0.04	O
%	O
)	O
,	O
"	O
ground	O
"	O
(	O
949	O
,	O
0.04	O
%	O
)	O
,	O
"	O
asian	O
"	O
(	O
938	O
,	O
0.04	O
%	O
)	O
,	O
"	O
plaid	O
"	O
(	O
936	O
,	O
0.04	O
%	O
)	O
,	O
"	O
dirt	O
"	O
(	O
933	O
,	O
0.04	O
%	O
)	O
,	O
"	O
mirror	O
"	O
(	O
928	O
,	O
0.04	O
%	O
)	O
,	O
"	O
usa	O
"	O
(	O
928	O
,	O
0.04	O
%	O
)	O
,	O
"	O
chicken	O
"	O
(	O
925	O
,	O
0.04	O
%	O
)	O
,	O
"	O
plate	O
"	O
(	O
920	O
,	O
0.04	O
%	O
)	O
,	O
"	O
clock	O
"	O
(	O
912	O
,	O
0.04	O
%	O
)	O
,	O
"	O
luggage	O
"	O
(	O
908	O
,	O
0.04	O
%	O
)	O
,	O
"	O
none	O
"	O
(	O
908	O
,	O
0.04	O
%	O
)	O
,	O
"	O
street	O
"	O
(	O
905	O
,	O
0.04	O
%	O
)	O
,	O
"	O
on	O
table	O
"	O
(	O
904	O
,	O
0.04	O
%	O
)	O
,	O
"	O
spoon	O
"	O
(	O
899	O
,	O
0.04	O
%	O
)	O
,	O
"	O
cooking	O
"	O
(	O
898	O
,	O
0.04	O
%	O
)	O
,	O
"	O
daytime	O
"	O
(	O
896	O
,	O
0.04	O
%	O
)	O
,	O
"	O
16	O
"	O
(	O
893	O
,	O
0.04	O
%	O
)	O
,	O
"	O
africa	O
"	O
(	O
890	O
,	O
0.04	O
%	O
)	O
,	O
"	O
stone	O
"	O
(	O
884	O
,	O
0.04	O
%	O
)	O
,	O
"	O
not	O
sure	O
"	O
(	O
873	O
,	O
0.04	O
%	O
)	O
,	O
"	O
window	O
"	O
(	O
868	O
,	O
0.03	O
%	O
)	O
,	O
"	O
sun	O
"	O
(	O
865	O
,	O
0.03	O
%	O
)	O
,	O
"	O
gold	O
"	O
(	O
860	O
,	O
0.03	O
%	O
)	O
,	O
"	O
people	O
"	O
(	O
856	O
,	O
0.03	O
%	O
)	O
,	O
"	O
racket	O
"	O
(	O
847	O
,	O
0.03	O
%	O
)	O
,	O
"	O
zebras	O
"	O
(	O
845	O
,	O
0.03	O
%	O
)	O
,	O
"	O
carrot	O
"	O
(	O
841	O
,	O
0.03	O
%	O
)	O
,	O
"	O
person	O
"	O
(	O
835	O
,	O
0.03	O
%	O
)	O
,	O
"	O
fish	O
"	O
(	O
835	O
,	O
0.03	O
%	O
)	O
,	O
"	O
happy	O
"	O
(	O
824	O
,	O
0.03	O
%	O
)	O
,	O
"	O
circle	O
"	O
(	O
822	O
,	O
0.03	O
%	O
)	O
,	O
"	O
oranges	O
"	O
(	O
817	O
,	O
0.03	O
%	O
)	O
,	O
"	O
backpack	O
"	O
(	O
812	O
,	O
0.03	O
%	O
)	O
,	O
"	O
25	O
"	O
(	O
810	O
,	O
0.03	O
%	O
)	O
,	O
"	O
leaves	O
"	O
(	O
809	O
,	O
0.03	O
%	O
)	O
,	O
"	O
watch	O
"	O
(	O
804	O
,	O
0.03	O
%	O
)	O
,	O
"	O
mountain	O
"	O
(	O
800	O
,	O
0.03	O
%	O
)	O
,	O
"	O
no	O
one	O
"	O
(	O
798	O
,	O
0.03	O
%	O
)	O
,	O
"	O
ski	O
poles	O
"	O
(	O
792	O
,	O
0.03	O
%	O
)	O
,	O
"	O
city	O
"	O
(	O
791	O
,	O
0.03	O
%	O
)	O
,	O
"	O
couch	O
"	O
(	O
790	O
,	O
0.03	O
%	O
)	O
,	O
"	O
afternoon	O
"	O
(	O
782	O
,	O
0.03	O
%	O
)	O
,	O
"	O
jeans	O
"	O
(	O
781	O
,	O
0.03	O
%	O
)	O
,	O
"	O
brown	O
and	O
white	O
"	O
(	O
779	O
,	O
0.03	O
%	O
)	O
,	O
"	O
summer	O
"	O
(	O
774	O
,	O
0.03	O
%	O
)	O
,	O
"	O
giraffes	O
"	O
(	O
772	O
,	O
0.03	O
%	O
)	O
,	O
"	O
computer	O
"	O
(	O
771	O
,	O
0.03	O
%	O
)	O
,	O
"	O
refrigerator	O
"	O
(	O
768	O
,	O
0.03	O
%	O
)	O
,	O
"	O
birds	O
"	O
(	O
762	O
,	O
0.03	O
%	O
)	O
,	O
"	O
child	O
"	O
(	O
761	O
,	O
0.03	O
%	O
)	O
,	O
"	O
park	O
"	O
(	O
759	O
,	O
0.03	O
%	O
)	O
,	O
"	O
flying	O
kite	O
"	O
(	O
756	O
,	O
0.03	O
%	O
)	O
,	O
"	O
restaurant	O
"	O
(	O
747	O
,	O
0.03	O
%	O
)	O
,	O
"	O
evening	O
"	O
(	O
738	O
,	O
0.03	O
%	O
)	O
,	O
"	O
graffiti	O
"	O
(	O
736	O
,	O
0.03	O
%	O
)	O
,	O
"	O
30	O
"	O
(	O
730	O
,	O
0.03	O
%	O
)	O
,	O
"	O
grazing	O
"	O
(	O
727	O
,	O
0.03	O
%	O
)	O
,	O
"	O
flower	O
"	O
(	O
723	O
,	O
0.03	O
%	O
)	O
,	O
"	O
remote	O
"	O
(	O
720	O
,	O
0.03	O
%	O
)	O
,	O
"	O
hay	O
"	O
(	O
719	O
,	O
0.03	O
%	O
)	O
,	O
"	O
50	O
"	O
(	O
716	O
,	O
0.03	O
%	O
)	O
.	O
	
section	O
:	O
APPENDIX	O
IX	O
:	O
ADDITIONAL	O
EXAMPLES	O
	
To	O
provide	O
insight	O
into	O
the	O
dataset	O
,	O
we	O
provide	O
additional	O
examples	O
.	O
	
In	O
Fig	O
.	O
	
27	O
,	O
Fig	O
.	O
28	O
,	O
and	O
Fig	O
.	O
29	O
,	O
we	O
show	O
a	O
random	O
selection	O
of	O
the	O
VQA	B-Material
dataset	I-Material
for	O
the	O
MS	B-Material
COCO	I-Material
[	O
reference	O
]	O
images	O
,	O
abstract	B-Material
scenes	I-Material
,	O
and	O
multiple	B-Material
-	I-Material
choice	I-Material
questions	I-Material
,	O
respectively	O
.	O
	
section	O
:	O
	
section	O
:	O
	
woman	O
on	O
right	O
Q	O
:	O
Is	O
the	O
girl	O
standing	O
?	O
	
Q	O
:	O
	
Does	O
the	O
girl	O
have	O
a	O
lot	O
of	O
toys	O
?	O
	
(	O
p	O
)	O
yes	O
3	O
of	O
them	O
	
(	O
q	O
)	O
no	O
image	O
	
(	O
r	O
)	O
children	O
and	O
toys	O
Q	O
:	O
What	O
sport	O
are	O
they	O
playing	O
?	O
	
(	O
p	O
)	O
n200	O
	
(	O
q	O
)	O
public	O
storage	O
(	O
r	O
)	O
pasta	O
,	O
sauce	O
,	O
	
meat	O
Q	O
:	O
	
How	O
many	O
umbrellas	O
are	O
in	O
the	O
photo	O
?	O
	
(	O
p	O
)	O
dresses	O
(	O
q	O
)	O
3	O
to	O
5	O
	
(	O
r	O
)	O
two	O
way	O
	
traffic	O
Q	O
:	O
	
Where	O
is	O
the	O
blanket	O
?	O
	
(	O
p	O
)	O
to	O
be	O
pet	O
(	O
q	O
)	O
she	O
fell	O
(	O
r	O
)	O
boy	O
is	O
playing	O
with	O
her	O
toys	O
Q	O
:	O
Why	O
is	O
the	O
boy	O
playing	O
with	O
his	O
sister	O
's	O
toys	O
?	O
	
(	O
a	O
)	O
yes	O
	
section	O
:	O
	
document	O
:	O
Stacked	B-Method
Generative	I-Method
Adversarial	I-Method
Networks	I-Method
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
novel	O
generative	B-Method
model	I-Method
named	O
Stacked	B-Method
Generative	I-Method
Adversarial	I-Method
Networks	I-Method
(	O
SGAN	B-Method
)	I-Method
,	O
which	O
is	O
trained	O
to	O
invert	O
the	O
hierarchical	B-Method
representations	I-Method
of	O
a	O
bottom	B-Method
-	I-Method
up	I-Method
discriminative	I-Method
network	I-Method
.	O
	
Our	O
model	O
consists	O
of	O
a	O
top	B-Method
-	I-Method
down	I-Method
stack	I-Method
of	I-Method
GANs	I-Method
,	O
each	O
learned	O
to	O
generate	O
lower	O
-	O
level	O
representations	O
conditioned	O
on	O
higher	O
-	O
level	O
representations	O
.	O
	
A	O
representation	B-Method
discriminator	I-Method
is	O
introduced	O
at	O
each	O
feature	O
hierarchy	O
to	O
encourage	O
the	O
representation	O
manifold	O
of	O
the	O
generator	B-Method
to	O
align	O
with	O
that	O
of	O
the	O
bottom	B-Method
-	I-Method
up	I-Method
discriminative	I-Method
network	I-Method
,	O
leveraging	O
the	O
powerful	O
discriminative	B-Method
representations	I-Method
to	O
guide	O
the	O
generative	B-Method
model	I-Method
.	O
	
In	O
addition	O
,	O
we	O
introduce	O
a	O
conditional	B-Method
loss	I-Method
that	O
encourages	O
the	O
use	O
of	O
conditional	O
information	O
from	O
the	O
layer	O
above	O
,	O
and	O
a	O
novel	O
entropy	B-Method
loss	I-Method
that	O
maximizes	O
a	O
variational	B-Metric
lower	I-Metric
bound	I-Metric
on	O
the	O
conditional	O
entropy	O
of	O
generator	O
outputs	O
.	O
	
We	O
first	O
train	O
each	O
stack	O
independently	O
,	O
and	O
then	O
train	O
the	O
whole	O
model	O
end	O
-	O
to	O
-	O
end	O
.	O
	
Unlike	O
the	O
original	O
GAN	B-Method
that	O
uses	O
a	O
single	O
noise	O
vector	O
to	O
represent	O
all	O
the	O
variations	O
,	O
our	O
SGAN	B-Method
decomposes	O
variations	O
into	O
multiple	O
levels	O
and	O
gradually	O
resolves	O
uncertainties	O
in	O
the	O
top	B-Method
-	I-Method
down	I-Method
generative	I-Method
process	I-Method
.	O
	
Based	O
on	O
visual	B-Metric
inspection	I-Metric
,	O
Inception	B-Metric
scores	I-Metric
and	O
visual	B-Metric
Turing	I-Metric
test	I-Metric
,	O
we	O
demonstrate	O
that	O
SGAN	B-Method
is	O
able	O
to	O
generate	O
images	O
of	O
much	O
higher	O
quality	B-Metric
than	O
GANs	B-Method
without	O
stacking	O
.	O
	
section	O
:	O
Introduction	O
	
Recent	O
years	O
have	O
witnessed	O
tremendous	O
success	O
of	O
deep	B-Method
neural	I-Method
networks	I-Method
(	O
DNNs	B-Method
)	O
,	O
especially	O
the	O
kind	O
of	O
bottom	B-Method
-	I-Method
up	I-Method
neural	I-Method
networks	I-Method
trained	O
for	O
discriminative	B-Task
tasks	I-Task
.	O
	
In	O
particular	O
,	O
Convolutional	B-Method
Neural	I-Method
Networks	I-Method
(	O
CNNs	B-Method
)	O
have	O
achieved	O
impressive	O
accuracy	B-Metric
on	O
the	O
challenging	O
ImageNet	B-Task
classification	I-Task
benchmark	I-Task
.	O
	
Interestingly	O
,	O
it	O
has	O
been	O
shown	O
that	O
CNNs	B-Method
trained	O
on	O
ImageNet	O
for	O
classification	B-Task
can	O
learn	O
representations	O
that	O
are	O
transferable	O
to	O
other	O
tasks	O
,	O
and	O
even	O
to	O
other	O
modalities	O
.	O
	
However	O
,	O
bottom	B-Method
-	I-Method
up	I-Method
discriminative	I-Method
models	I-Method
are	O
focused	O
on	O
learning	O
useful	O
representations	O
from	O
data	O
,	O
being	O
incapable	O
of	O
capturing	O
the	O
data	O
distribution	O
.	O
	
Learning	O
top	B-Method
-	I-Method
down	I-Method
generative	I-Method
models	I-Method
that	O
can	O
explain	O
complex	O
data	B-Task
distribution	I-Task
is	O
a	O
long	O
-	O
standing	O
problem	O
in	O
machine	B-Task
learning	I-Task
research	I-Task
.	O
	
The	O
expressive	O
power	O
of	O
deep	B-Method
neural	I-Method
networks	I-Method
makes	O
them	O
natural	O
candidates	O
for	O
generative	B-Method
models	I-Method
,	O
and	O
several	O
recent	O
works	O
have	O
shown	O
promising	O
results	O
.	O
	
While	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
DNNs	B-Method
can	O
rival	O
human	O
performance	O
in	O
certain	O
discriminative	B-Task
tasks	I-Task
,	O
current	O
best	O
deep	B-Method
generative	I-Method
models	I-Method
still	O
fail	O
when	O
there	O
are	O
large	O
variations	O
in	O
the	O
data	O
distribution	O
.	O
	
A	O
natural	O
question	O
therefore	O
arises	O
:	O
can	O
we	O
leverage	O
the	O
hierarchical	B-Method
representations	I-Method
in	O
a	O
discriminatively	B-Method
trained	I-Method
model	I-Method
to	O
help	O
the	O
learning	O
of	O
top	B-Method
-	I-Method
down	I-Method
generative	I-Method
models	I-Method
?	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
generative	B-Method
model	I-Method
named	O
Stacked	B-Method
Generative	I-Method
Adversarial	I-Method
Networks	I-Method
(	O
SGAN	B-Method
)	I-Method
.	O
	
Our	O
model	O
consists	O
of	O
a	O
top	B-Method
-	I-Method
down	I-Method
stack	I-Method
of	I-Method
GANs	I-Method
,	O
each	O
trained	O
to	O
generate	O
“	O
plausible	O
”	O
lower	O
-	O
level	O
representations	O
conditioned	O
on	O
higher	O
-	O
level	O
representations	O
.	O
	
Similar	O
to	O
the	O
image	B-Method
discriminator	I-Method
in	O
the	O
original	O
GAN	B-Method
model	O
which	O
is	O
trained	O
to	O
distinguish	O
“	O
fake	O
”	O
images	O
from	O
“	O
real	O
”	O
ones	O
,	O
we	O
introduce	O
a	O
set	O
of	O
representation	B-Method
discriminators	I-Method
that	O
are	O
trained	O
to	O
distinguish	O
“	O
fake	O
”	O
representations	O
from	O
“	O
real	O
”	O
representations	O
.	O
	
The	O
adversarial	O
loss	O
introduced	O
by	O
the	O
representation	B-Method
discriminator	I-Method
forces	O
the	O
intermediate	B-Method
representations	I-Method
of	O
the	O
SGAN	B-Method
to	O
lie	O
on	O
the	O
manifold	O
of	O
the	O
bottom	B-Method
-	I-Method
up	I-Method
DNN	I-Method
’s	I-Method
representation	I-Method
space	I-Method
.	O
	
In	O
addition	O
to	O
the	O
adversarial	O
loss	O
,	O
we	O
also	O
introduce	O
a	O
conditional	O
loss	O
that	O
imposes	O
each	O
generator	O
to	O
use	O
the	O
higher	O
-	O
level	O
conditional	O
information	O
,	O
and	O
a	O
novel	O
entropy	B-Method
loss	I-Method
that	O
encourages	O
each	O
generator	O
to	O
generate	O
diverse	O
representations	O
.	O
	
By	O
stacking	O
several	O
GANs	B-Method
in	O
a	O
top	O
-	O
down	O
way	O
and	O
using	O
the	O
top	B-Method
-	I-Method
most	I-Method
GAN	I-Method
to	O
receive	O
labels	O
and	O
the	O
bottom	B-Method
-	I-Method
most	I-Method
GAN	I-Method
to	O
generate	O
images	O
,	O
SGAN	B-Method
can	O
be	O
trained	O
to	O
model	O
the	O
data	O
distribution	O
conditioned	O
on	O
class	O
labels	O
.	O
	
Through	O
extensive	O
experiments	O
,	O
we	O
demonstrate	O
that	O
our	O
SGAN	B-Method
is	O
able	O
to	O
generate	O
images	O
of	O
much	O
higher	O
quality	B-Metric
than	O
a	O
vanilla	O
GAN	B-Method
.	O
	
In	O
particular	O
,	O
our	O
model	O
obtains	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
Inception	B-Metric
scores	I-Metric
on	O
CIFAR	B-Material
-	I-Material
10	I-Material
dataset	I-Material
.	O
	
section	O
:	O
Related	O
Work	O
	
Deep	B-Method
Generative	I-Method
Image	I-Method
Models	I-Method
.	O
	
There	O
has	O
been	O
a	O
large	O
body	O
of	O
work	O
on	O
generative	B-Task
image	I-Task
modeling	I-Task
with	O
deep	B-Method
learning	I-Method
.	O
	
Some	O
early	O
efforts	O
include	O
Restricted	B-Method
Boltzmann	I-Method
Machines	I-Method
and	O
Deep	B-Method
Belief	I-Method
Networks	I-Method
.	O
	
More	O
recently	O
,	O
several	O
successful	O
paradigms	O
of	O
deep	B-Method
generative	I-Method
models	I-Method
have	O
emerged	O
,	O
including	O
the	O
auto	B-Method
-	I-Method
regressive	I-Method
models	I-Method
,	O
Variational	B-Method
Auto	I-Method
-	I-Method
encoders	I-Method
(	O
VAEs	B-Method
)	O
,	O
and	O
Generative	B-Method
Adversarial	I-Method
Networks	I-Method
(	O
GANs	B-Method
)	O
.	O
	
Our	O
work	O
builds	O
upon	O
the	O
GAN	B-Method
framework	O
,	O
which	O
employs	O
a	O
generator	B-Method
that	O
transforms	O
a	O
noise	O
vector	O
into	O
an	O
image	O
and	O
a	O
discriminator	B-Method
that	O
distinguishes	O
between	O
real	O
and	O
generated	O
images	O
.	O
	
However	O
,	O
due	O
to	O
the	O
vast	O
variations	O
in	O
image	O
content	O
,	O
it	O
is	O
still	O
challenging	O
for	O
GANs	B-Method
to	O
generate	O
diverse	O
images	O
with	O
sufficient	O
details	O
.	O
	
To	O
this	O
end	O
,	O
several	O
works	O
have	O
attempted	O
to	O
factorize	O
a	O
GAN	B-Method
into	O
a	O
series	O
of	O
GANs	B-Method
,	O
decomposing	O
the	O
difficult	O
task	O
into	O
several	O
more	O
tractable	O
sub	B-Task
-	I-Task
tasks	I-Task
.	O
	
Denton	O
propose	O
a	O
LAPGAN	B-Method
model	I-Method
that	O
factorizes	O
the	O
generative	B-Method
process	I-Method
into	O
multi	B-Method
-	I-Method
resolution	I-Method
GANs	I-Method
,	O
with	O
each	O
GAN	B-Method
generating	O
a	O
higher	O
-	O
resolution	O
residual	O
conditioned	O
on	O
a	O
lower	O
-	O
resolution	O
image	O
.	O
	
Although	O
both	O
LAPGAN	B-Method
and	O
SGAN	B-Method
consist	O
of	O
a	O
sequence	O
of	O
GANs	B-Method
each	O
working	O
at	O
one	O
scale	O
,	O
LAPGAN	B-Method
focuses	O
on	O
generating	O
multi	B-Task
-	I-Task
resolution	I-Task
images	I-Task
from	O
coarse	O
to	O
fine	O
while	O
our	O
SGAN	B-Method
aims	O
at	O
modeling	O
multi	B-Method
-	I-Method
level	I-Method
representations	I-Method
from	O
abstract	O
to	O
specific	O
.	O
	
Wang	O
and	O
Gupta	O
propose	O
a	O
-	O
GAN	B-Method
,	O
using	O
one	O
GAN	B-Method
to	O
generate	O
surface	O
normals	O
and	O
another	O
GAN	B-Method
to	O
generate	O
images	O
conditioned	O
on	O
surface	O
normals	O
.	O
	
Surface	O
normals	O
can	O
be	O
viewed	O
as	O
a	O
specific	O
type	O
of	O
image	B-Method
representations	I-Method
,	O
capturing	O
the	O
underlying	O
3D	O
structure	O
of	O
an	O
indoor	O
scene	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
our	O
framework	O
can	O
leverage	O
the	O
more	O
general	O
and	O
powerful	O
multi	B-Method
-	I-Method
level	I-Method
representations	I-Method
in	O
a	O
pre	O
-	O
trained	O
discriminative	B-Method
DNN	I-Method
.	O
	
There	O
are	O
several	O
works	O
that	O
use	O
a	O
pre	B-Method
-	I-Method
trained	I-Method
discriminative	I-Method
model	I-Method
to	O
aid	O
the	O
training	O
of	O
a	O
generator	B-Method
.	O
	
add	O
a	O
regularization	B-Method
term	I-Method
that	O
encourages	O
the	O
reconstructed	O
image	O
to	O
be	O
similar	O
to	O
the	O
original	O
image	O
in	O
the	O
feature	O
space	O
of	O
a	O
discriminative	B-Method
network	I-Method
.	O
	
use	O
an	O
additional	O
“	O
style	O
loss	O
”	O
based	O
on	O
Gram	O
matrices	O
of	O
feature	O
activations	O
.	O
	
Different	O
from	O
our	O
method	O
,	O
all	O
the	O
works	O
above	O
only	O
add	O
loss	O
terms	O
to	O
regularize	O
the	O
generator	O
’s	O
output	O
,	O
without	O
regularizing	O
its	O
internal	B-Method
representations	I-Method
.	O
	
Matching	B-Task
Intermediate	I-Task
Representations	I-Task
Between	O
Two	O
DNNs	B-Method
.	O
	
There	O
have	O
been	O
some	O
works	O
that	O
attempt	O
to	O
“	O
match	O
”	O
	
the	O
intermediate	B-Method
representations	I-Method
between	O
two	O
DNNs	B-Method
.	O
	
use	O
the	O
intermediate	B-Method
representations	I-Method
of	O
one	O
pre	B-Method
-	I-Method
trained	I-Method
DNN	I-Method
to	O
guide	O
another	O
DNN	B-Method
in	O
the	O
context	O
of	O
knowledge	B-Task
transfer	I-Task
.	O
	
Our	O
method	O
can	O
be	O
considered	O
as	O
a	O
special	O
kind	O
of	O
knowledge	B-Task
transfer	I-Task
.	O
	
However	O
,	O
we	O
aim	O
at	O
transferring	O
the	O
knowledge	O
in	O
a	O
bottom	B-Method
-	I-Method
up	I-Method
DNN	I-Method
to	O
a	O
top	B-Method
-	I-Method
down	I-Method
generative	I-Method
model	I-Method
,	O
instead	O
of	O
another	O
bottom	B-Method
-	I-Method
up	I-Method
DNN	I-Method
.	O
	
Also	O
,	O
some	O
auto	B-Method
-	I-Method
encoder	I-Method
architectures	I-Method
employ	O
layer	B-Method
-	I-Method
wise	I-Method
reconstruction	I-Method
loss	I-Method
.	O
	
The	O
layer	O
-	O
wise	O
loss	O
is	O
usually	O
accompanied	O
by	O
lateral	O
connections	O
from	O
the	O
encoder	B-Method
to	O
the	O
decodery	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
SGAN	B-Method
is	O
a	O
generative	B-Method
model	I-Method
and	O
does	O
not	O
require	O
any	O
information	O
from	O
the	O
encoder	B-Method
once	O
training	O
completes	O
.	O
	
Another	O
important	O
difference	O
is	O
that	O
we	O
use	O
adversarial	O
loss	O
instead	O
of	O
reconstruction	O
loss	O
to	O
match	O
intermediate	O
representations	O
.	O
	
Visualizing	B-Task
Deep	I-Task
Representations	I-Task
.	O
	
Our	O
work	O
is	O
also	O
related	O
to	O
the	O
recent	O
efforts	O
in	O
visualizing	O
the	O
internal	B-Task
representations	I-Task
of	I-Task
DNNs	I-Task
.	O
	
One	O
popular	O
approach	O
uses	O
gradient	B-Method
-	I-Method
based	I-Method
optimization	I-Method
to	O
find	O
an	O
image	O
whose	O
representation	O
is	O
close	O
to	O
the	O
one	O
we	O
want	O
to	O
visualize	O
.	O
	
Other	O
approaches	O
,	O
such	O
as	O
,	O
train	O
a	O
top	B-Method
-	I-Method
down	I-Method
deconvolutional	I-Method
network	I-Method
to	O
reconstruct	O
the	O
input	O
image	O
from	O
a	O
feature	B-Method
representation	I-Method
by	O
minimizing	O
the	O
Euclidean	B-Metric
reconstruction	I-Metric
error	I-Metric
in	O
image	O
space	O
.	O
	
However	O
,	O
there	O
is	O
inherent	O
uncertainty	O
in	O
the	O
reconstruction	B-Task
process	I-Task
,	O
since	O
the	O
representations	O
in	O
higher	O
layers	O
of	O
the	O
DNN	B-Method
are	O
trained	O
to	O
be	O
invariant	O
to	O
irrelevant	O
transformations	O
and	O
to	O
ignore	O
low	O
-	O
level	O
details	O
.	O
	
With	O
Euclidean	B-Metric
training	I-Metric
objective	I-Metric
,	O
the	O
deconvolutional	B-Method
network	I-Method
tends	O
to	O
produce	O
blurry	O
images	O
.	O
	
To	O
alleviate	O
this	O
problem	O
,	O
Dosovitskiy	O
abd	O
Brox	O
further	O
propose	O
a	O
feature	B-Method
loss	I-Method
and	O
an	O
adversarial	B-Method
loss	I-Method
that	O
enables	O
much	O
sharper	B-Task
reconstructions	I-Task
.	O
	
However	O
,	O
it	O
still	O
does	O
not	O
tackle	O
the	O
problem	O
of	O
uncertainty	B-Task
in	I-Task
reconstruction	I-Task
.	O
	
Given	O
a	O
high	O
-	O
level	B-Method
feature	I-Method
representation	I-Method
,	O
the	O
deconvolutional	B-Method
network	I-Method
deterministically	O
generates	O
a	O
single	O
image	O
,	O
despite	O
the	O
fact	O
that	O
there	O
exist	O
many	O
images	O
having	O
the	O
same	O
representation	O
.	O
	
Also	O
,	O
there	O
is	O
no	O
obvious	O
way	O
to	O
sample	O
images	O
because	O
the	O
feature	O
prior	O
distribution	O
is	O
unknown	O
.	O
	
Concurrent	O
to	O
our	O
work	O
,	O
Nguyen	O
incorporate	O
the	O
feature	B-Method
prior	I-Method
with	O
a	O
variant	O
of	O
denoising	B-Method
auto	I-Method
-	I-Method
encoder	I-Method
(	I-Method
DAE	I-Method
)	O
.	O
	
Their	O
sampling	O
relies	O
on	O
an	O
iterative	B-Method
optimization	I-Method
procedure	I-Method
,	O
while	O
we	O
are	O
focused	O
on	O
efficient	O
feed	B-Method
-	I-Method
forward	I-Method
sampling	I-Method
.	O
	
section	O
:	O
Methods	O
	
In	O
this	O
section	O
we	O
introduce	O
our	O
model	O
architecture	O
.	O
	
In	O
Sec	O
.	O
	
[	O
reference	O
]	O
we	O
briefly	O
overview	O
the	O
framework	O
of	O
Generative	B-Method
Adversarial	I-Method
Networks	I-Method
.	O
	
We	O
then	O
describe	O
our	O
proposal	O
for	O
Stacked	B-Method
Generative	I-Method
Adversarial	I-Method
Networks	I-Method
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
.	O
	
In	O
Sect	O
.	O
	
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
	
we	O
will	O
focus	O
on	O
our	O
two	O
novel	O
loss	B-Metric
functions	I-Metric
,	O
conditional	O
loss	O
and	O
entropy	B-Method
loss	I-Method
,	O
respectively	O
.	O
	
subsection	O
:	O
Background	O
:	O
Generative	B-Method
Adversarial	I-Method
Network	I-Method
	
As	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
a	O
)	O
,	O
the	O
original	O
GAN	B-Method
is	O
trained	O
using	O
a	O
two	O
-	O
player	B-Method
min	I-Method
-	I-Method
max	I-Method
game	I-Method
:	O
a	O
discriminator	B-Method
trained	O
to	O
distinguish	O
generated	O
images	O
from	O
real	O
images	O
,	O
and	O
a	O
generator	B-Method
trained	O
to	O
fool	O
.	O
	
The	O
discriminator	B-Metric
loss	I-Metric
and	O
the	O
generator	B-Metric
loss	I-Metric
are	O
defined	O
as	O
follows	O
:	O
	
In	O
practice	O
,	O
and	O
are	O
usually	O
updated	O
alternately	O
.	O
	
The	O
training	O
process	O
matches	O
the	O
generated	O
image	O
distribution	O
with	O
the	O
real	O
image	O
distribution	O
in	O
the	O
training	O
set	O
.	O
	
In	O
other	O
words	O
,	O
The	O
adversarial	B-Method
training	I-Method
forces	O
to	O
generate	O
images	O
that	O
reside	O
on	O
the	O
natural	O
images	O
manifold	O
.	O
	
subsection	O
:	O
Stacked	B-Method
Generative	I-Method
Adversarial	I-Method
Networks	I-Method
	
Pre	O
-	O
trained	O
Encoder	B-Method
.	O
	
We	O
first	O
consider	O
a	O
bottom	B-Method
-	I-Method
up	I-Method
DNN	I-Method
pre	I-Method
-	I-Method
trained	O
for	O
classification	B-Task
,	O
which	O
is	O
referred	O
to	O
as	O
the	O
encoder	O
throughout	O
.	O
	
We	O
define	O
a	O
stack	B-Method
of	I-Method
bottom	I-Method
-	I-Method
up	I-Method
deterministic	I-Method
nonlinear	I-Method
mappings	I-Method
:	O
,	O
where	O
,	O
consists	O
of	O
a	O
sequence	O
of	O
neural	O
layers	O
(	O
e.g.	O
,	O
convolution	B-Method
,	O
pooling	B-Method
)	O
,	O
is	O
the	O
number	O
of	O
hierarchies	O
(	O
stacks	O
)	O
,	O
are	O
intermediate	B-Method
representations	I-Method
,	O
is	O
the	O
classification	O
result	O
,	O
and	O
is	O
the	O
input	O
image	O
.	O
	
Note	O
that	O
in	O
our	O
formulation	O
,	O
each	O
can	O
contain	O
multiple	O
layers	O
and	O
the	O
way	O
of	O
grouping	O
layers	O
together	O
into	O
is	O
determined	O
by	O
us	O
.	O
	
The	O
number	O
of	O
stacks	O
is	O
therefore	O
less	O
than	O
the	O
number	O
of	O
layers	O
in	O
and	O
is	O
also	O
determined	O
by	O
us	O
.	O
	
Stacked	B-Method
Generators	I-Method
.	O
	
Provided	O
with	O
a	O
pre	O
-	O
trained	O
encoder	B-Method
,	O
our	O
goal	O
is	O
to	O
train	O
a	O
top	B-Method
-	I-Method
down	I-Method
generator	I-Method
that	O
inverts	O
.	O
	
Specifically	O
,	O
consists	O
of	O
a	O
top	B-Method
-	I-Method
down	I-Method
stack	I-Method
of	I-Method
generators	I-Method
,	O
each	O
trained	O
to	O
invert	O
a	O
bottom	B-Method
-	I-Method
up	I-Method
mapping	I-Method
.	O
	
Each	O
takes	O
in	O
a	O
higher	O
-	O
level	O
feature	O
and	O
a	O
noise	O
vector	O
as	O
inputs	O
,	O
and	O
outputs	O
the	O
lower	O
-	O
level	O
feature	O
.	O
	
We	O
first	O
train	O
each	O
GAN	B-Method
independently	O
and	O
then	O
train	O
them	O
jointly	O
in	O
an	O
end	O
-	O
to	O
-	O
end	O
manner	O
,	O
as	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Each	O
generator	O
receives	O
conditional	O
input	O
from	O
encoders	B-Method
in	O
the	O
independent	B-Method
training	I-Method
stage	I-Method
,	O
and	O
from	O
the	O
upper	B-Method
generators	I-Method
in	O
the	O
joint	B-Method
training	I-Method
stage	I-Method
.	O
	
In	O
other	O
words	O
,	O
during	O
independent	B-Task
training	I-Task
and	O
during	O
joint	B-Task
training	I-Task
.	O
	
The	O
loss	B-Method
equations	I-Method
shown	O
in	O
this	O
section	O
are	O
for	O
independent	B-Task
training	I-Task
stage	I-Task
but	O
can	O
be	O
easily	O
modified	O
to	O
joint	B-Task
training	I-Task
by	O
replacing	O
with	O
.	O
	
Intuitively	O
,	O
the	O
total	O
variations	O
of	O
images	O
could	O
be	O
decomposed	O
into	O
multiple	O
levels	O
,	O
with	O
higher	O
-	O
level	O
semantic	O
variations	O
(	O
e.g.	O
,	O
attributes	O
,	O
object	O
categories	O
,	O
rough	O
shapes	O
)	O
and	O
lower	O
-	O
level	O
variations	O
(	O
e.g.	O
,	O
detailed	O
contours	O
and	O
textures	O
,	O
background	O
clutters	O
)	O
.	O
	
Our	O
model	O
allows	O
using	O
different	O
noise	O
variables	O
to	O
represent	O
different	O
levels	O
of	O
variations	O
.	O
	
The	O
training	O
procedure	O
is	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
b	O
)	O
.	O
	
Each	O
generator	O
is	O
trained	O
with	O
a	O
linear	B-Method
combination	I-Method
of	I-Method
three	I-Method
loss	I-Method
terms	I-Method
:	O
adversarial	O
loss	O
,	O
conditional	B-Method
loss	I-Method
,	O
and	O
entropy	B-Method
loss	I-Method
.	O
	
where	O
,	O
,	O
denote	O
adversarial	O
loss	O
,	O
conditional	O
loss	O
,	O
and	O
entropy	O
loss	O
respectively	O
.	O
	
,	O
,	O
are	O
the	O
weights	O
associated	O
with	O
different	O
loss	O
terms	O
.	O
	
In	O
practice	O
,	O
we	O
find	O
it	O
sufficient	O
to	O
set	O
the	O
weights	O
such	O
that	O
the	O
magnitude	O
of	O
different	O
terms	O
are	O
of	O
similar	O
scales	O
.	O
	
In	O
this	O
subsection	O
we	O
first	O
introduce	O
the	O
adversarial	O
loss	O
.	O
	
We	O
will	O
then	O
introduce	O
and	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
respectively	O
.	O
	
For	O
each	O
generator	O
,	O
we	O
introduce	O
a	O
representation	B-Method
discriminator	I-Method
that	O
distinguishes	O
generated	B-Method
representations	I-Method
,	O
from	O
“	O
real	B-Method
”	I-Method
representations	I-Method
.	O
	
Specifically	O
,	O
the	O
discriminator	B-Method
is	O
trained	O
with	O
the	O
loss	O
function	O
:	O
And	O
is	O
trained	O
to	O
“	O
fool	O
”	O
the	O
representation	B-Method
discriminator	I-Method
,	O
with	O
the	O
adversarial	O
loss	O
defined	O
by	O
:	O
During	O
joint	B-Method
training	I-Method
,	O
the	O
adversarial	O
loss	O
provided	O
by	O
representational	B-Method
discriminators	I-Method
can	O
also	O
be	O
regarded	O
as	O
a	O
type	O
of	O
deep	B-Method
supervision	I-Method
,	O
providing	O
intermediate	O
supervision	O
signals	O
.	O
	
In	O
our	O
current	O
formulation	O
,	O
is	O
a	O
discriminative	B-Method
model	I-Method
,	O
and	O
is	O
a	O
generative	B-Method
model	I-Method
conditioned	O
on	O
labels	O
.	O
	
However	O
,	O
it	O
is	O
also	O
possible	O
to	O
train	O
SGAN	B-Method
without	O
using	O
label	O
information	O
:	O
can	O
be	O
trained	O
with	O
an	O
unsupervised	O
objective	O
and	O
can	O
be	O
cast	O
into	O
an	O
unconditional	B-Method
generative	I-Method
model	I-Method
by	O
removing	O
the	O
label	O
input	O
from	O
the	O
top	B-Method
generator	I-Method
.	O
	
We	O
leave	O
this	O
for	O
future	O
exploration	O
.	O
	
Sampling	B-Task
.	O
	
To	O
sample	O
images	O
,	O
all	O
s	O
are	O
stacked	O
together	O
in	O
a	O
top	O
-	O
down	O
manner	O
,	O
as	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
c	O
)	O
.	O
	
Our	O
SGAN	B-Method
is	O
capable	O
of	O
modeling	O
the	O
data	O
distribution	O
conditioned	O
on	O
the	O
class	O
label	O
:	O
,	O
where	O
each	O
is	O
modeled	O
by	O
a	O
generator	B-Method
.	O
	
From	O
an	O
information	O
-	O
theoretic	O
perspective	O
,	O
SGAN	B-Method
factorizes	O
the	O
total	O
entropy	O
of	O
the	O
image	O
distribution	O
into	O
multiple	O
(	O
smaller	O
)	O
conditional	O
entropy	O
terms	O
:	O
,	O
thereby	O
decomposing	O
one	O
difficult	O
task	O
into	O
multiple	O
easier	O
tasks	O
.	O
	
subsection	O
:	O
Conditional	O
Loss	O
	
At	O
each	O
stack	O
,	O
a	O
generator	B-Method
is	O
trained	O
to	O
capture	O
the	O
distribution	O
of	O
lower	O
-	O
level	O
representations	O
,	O
conditioned	O
on	O
higher	O
-	O
level	O
representations	O
.	O
	
However	O
,	O
in	O
the	O
above	O
formulation	O
,	O
the	O
generator	B-Method
might	O
choose	O
to	O
ignore	O
,	O
and	O
generate	O
plausible	O
from	O
scratch	O
.	O
	
Some	O
previous	O
works	O
tackle	O
this	O
problem	O
by	O
feeding	O
the	O
conditional	O
information	O
to	O
both	O
the	O
generator	B-Method
and	I-Method
discriminator	I-Method
.	O
	
This	O
approach	O
,	O
however	O
,	O
might	O
introduce	O
unnecessary	O
complexity	O
to	O
the	O
discriminator	B-Method
and	O
increase	O
model	O
instability	O
.	O
	
Here	O
we	O
adopt	O
a	O
different	O
approach	O
:	O
we	O
regularize	O
the	O
generator	O
by	O
adding	O
a	O
loss	B-Method
term	I-Method
named	O
conditional	O
loss	O
.	O
	
We	O
feed	O
the	O
generated	O
lower	O
-	O
level	O
representations	O
back	O
to	O
the	O
encoder	B-Method
,	O
and	O
compute	O
the	O
recovered	O
higher	B-Method
-	I-Method
level	I-Method
representations	I-Method
.	O
	
We	O
then	O
enforce	O
the	O
recovered	O
representations	O
to	O
be	O
similar	O
to	O
the	O
conditional	B-Method
representations	I-Method
.	O
	
Formally	O
:	O
where	O
is	O
a	O
distance	B-Metric
measure	I-Metric
.	O
	
We	O
define	O
to	O
be	O
the	O
Euclidean	O
distance	O
for	O
intermediate	B-Method
representations	I-Method
and	O
cross	O
-	O
entropy	O
for	O
labels	O
.	O
	
Our	O
conditional	B-Method
loss	I-Method
is	O
similar	O
to	O
the	O
“	O
feature	O
loss	O
”	O
used	O
by	O
and	O
the	O
“	O
FCN	B-Method
loss	I-Method
”	O
in	O
.	O
	
subsection	O
:	O
Entropy	B-Metric
Loss	I-Metric
	
Simply	O
adding	O
the	O
conditional	O
loss	O
leads	O
to	O
another	O
issue	O
:	O
the	O
generator	B-Method
learns	O
to	O
ignore	O
the	O
noise	O
,	O
and	O
compute	O
deterministically	O
from	O
.	O
	
This	O
problem	O
has	O
been	O
encountered	O
in	O
various	O
applications	O
of	O
conditional	O
GANs	B-Method
,	O
e.g.	O
,	O
synthesizing	O
future	O
frames	O
conditioned	O
on	O
previous	O
frames	O
,	O
generating	O
images	O
conditioned	O
on	O
label	O
maps	O
,	O
and	O
most	O
related	O
to	O
our	O
work	O
,	O
synthesizing	O
images	O
conditioned	O
on	O
feature	B-Method
representations	I-Method
.	O
	
All	O
the	O
above	O
works	O
attempted	O
to	O
generate	O
diverse	O
images	O
/	O
videos	O
by	O
feeding	O
noise	O
to	O
the	O
generator	O
,	O
but	O
failed	O
because	O
the	O
conditional	B-Method
generator	I-Method
simply	O
ignores	O
the	O
noise	O
.	O
	
To	O
our	O
knowledge	O
,	O
there	O
is	O
still	O
no	O
principled	O
way	O
to	O
deal	O
with	O
this	O
issue	O
.	O
	
It	O
might	O
be	O
tempting	O
to	O
think	O
that	O
minibatch	B-Method
discrimination	I-Method
,	O
which	O
encourages	O
sample	O
diversity	O
in	O
each	O
minibatch	O
,	O
could	O
solve	O
this	O
problem	O
.	O
	
However	O
,	O
even	O
if	O
the	O
generator	B-Method
generates	O
deterministically	O
from	O
,	O
the	O
generated	O
samples	O
in	O
each	O
minibatch	O
are	O
still	O
diverse	O
since	O
generators	O
are	O
conditioned	O
on	O
different	O
.	O
	
Thus	O
,	O
there	O
is	O
no	O
obvious	O
way	O
minibatch	B-Method
discrimination	I-Method
could	O
penalize	O
a	O
collapsed	B-Method
conditional	I-Method
generator	I-Method
.	O
	
Variational	B-Method
Conditional	I-Method
Entropy	I-Method
Maximization	I-Method
.	O
	
To	O
tackle	O
this	O
problem	O
,	O
we	O
would	O
like	O
to	O
encourage	O
the	O
generated	O
representation	O
to	O
be	O
sufficiently	O
diverse	O
when	O
conditioned	O
on	O
,	O
i.e.	O
,	O
the	O
conditional	O
entropy	O
should	O
be	O
as	O
high	O
as	O
possible	O
.	O
	
Since	O
directly	O
maximizing	O
is	O
intractable	O
,	O
we	O
propose	O
to	O
maximize	O
instead	O
a	O
variational	O
lower	O
bound	O
on	O
the	O
conditional	O
entropy	O
.	O
	
Specifically	O
,	O
we	O
use	O
an	O
auxiliary	O
distribution	O
to	O
approximate	O
the	O
true	O
posterior	O
,	O
and	O
augment	O
the	O
training	B-Metric
objective	I-Metric
with	O
a	O
loss	O
term	O
named	O
entropy	B-Metric
loss	I-Metric
:	O
	
Below	O
we	O
give	O
a	O
proof	O
that	O
minimizing	B-Task
is	O
equivalent	O
to	O
maximizing	O
a	O
variational	O
lower	O
bound	O
for	O
.	O
	
In	O
practice	O
,	O
we	O
parameterize	O
with	O
a	O
deep	B-Method
network	I-Method
that	O
predicts	O
the	O
posterior	O
distribution	O
of	O
given	O
.	O
	
shares	O
most	O
of	O
the	O
parameters	O
with	O
.	O
	
We	O
treat	O
the	O
posterior	O
as	O
a	O
diagonal	B-Method
Gaussian	I-Method
with	O
fixed	O
standard	O
deviations	O
,	O
and	O
use	O
the	O
network	O
to	O
only	O
predict	O
the	O
posterior	O
mean	O
,	O
making	O
equivalent	O
to	O
the	O
Euclidean	B-Metric
reconstruction	I-Metric
error	I-Metric
.	O
	
In	O
each	O
iteration	O
we	O
update	O
both	O
and	O
to	O
minimize	O
.	O
	
Our	O
method	O
is	O
similar	O
to	O
the	O
variational	B-Method
mutual	I-Method
information	I-Method
maximization	I-Method
technique	I-Method
proposed	O
by	O
Chen	O
.	O
	
A	O
key	O
difference	O
is	O
that	O
uses	O
the	O
-	O
network	O
to	O
predict	O
only	O
a	O
small	O
set	O
of	O
deliberately	O
constructed	O
“	O
latent	O
code	O
”	O
,	O
while	O
our	O
tries	O
to	O
predict	O
all	O
the	O
noise	O
variables	O
in	O
each	O
stack	O
.	O
	
The	O
loss	O
used	O
in	O
therefore	O
maximizes	O
the	O
mutual	O
information	O
between	O
the	O
output	O
and	O
the	O
latent	O
code	O
,	O
while	O
ours	O
maximizes	O
the	O
entropy	O
of	O
the	O
output	O
,	O
conditioned	O
on	O
.	O
	
also	O
train	O
a	O
separate	O
network	O
to	O
map	O
images	O
back	O
to	O
latent	O
space	O
to	O
perform	O
unsupervised	B-Task
feature	I-Task
learning	I-Task
.	O
	
Independent	O
of	O
our	O
work	O
,	O
proposes	O
to	O
regularize	O
EBGAN	B-Method
with	O
entropy	B-Method
maximization	I-Method
in	O
order	O
to	O
prevent	O
the	O
discriminator	O
from	O
degenerating	O
to	O
uniform	B-Task
prediction	I-Task
.	O
	
Our	O
entropy	B-Method
loss	I-Method
is	O
motivated	O
from	O
generating	O
multiple	O
possible	O
outputs	O
from	O
the	O
same	O
conditional	O
input	O
.	O
	
section	O
:	O
Experiments	O
	
In	O
this	O
section	O
,	O
we	O
perform	O
experiments	O
on	O
a	O
variety	O
of	O
datasets	O
including	O
MNIST	O
,	O
SVHN	O
,	O
and	O
CIFAR	B-Material
-	I-Material
10	I-Material
.	O
	
Code	O
and	O
pre	O
-	O
trained	O
models	O
are	O
available	O
at	O
:	O
.	O
	
Readers	O
may	O
refer	O
to	O
our	O
code	O
repository	O
for	O
more	O
details	O
about	O
experimental	O
setup	O
,	O
hyper	O
-	O
parameters	O
,	O
etc	O
.	O
	
Encoder	B-Method
:	O
For	O
all	O
datasets	O
we	O
use	O
a	O
small	O
CNN	B-Method
with	O
two	O
convolutional	B-Method
layers	I-Method
as	O
our	O
encoder	O
:	O
conv1	B-Method
-	I-Method
pool1	I-Method
-	I-Method
conv2	I-Method
-	I-Method
pool2	I-Method
-	I-Method
fc3	I-Method
-	I-Method
fc4	I-Method
,	O
where	O
fc3	B-Method
is	O
a	O
fully	B-Method
connected	I-Method
layer	I-Method
and	O
fc4	B-Method
outputs	O
classification	O
scores	O
before	O
softmax	O
.	O
	
On	O
CIFAR	B-Material
-	I-Material
10	I-Material
we	O
apply	O
horizontal	B-Method
flipping	I-Method
to	O
train	O
the	O
encoder	O
.	O
	
No	O
data	B-Method
augmentation	I-Method
is	O
used	O
on	O
other	O
datasets	O
.	O
	
Generator	O
:	O
	
We	O
use	O
generators	O
with	O
two	O
stacks	O
throughout	O
our	O
experiments	O
.	O
	
Note	O
that	O
our	O
framework	O
is	O
generally	O
applicable	O
to	O
the	O
setting	O
with	O
multiple	O
stacks	O
,	O
and	O
we	O
hypothesize	O
that	O
using	O
more	O
stacks	O
would	O
be	O
helpful	O
for	O
large	B-Task
-	I-Task
scale	I-Task
and	I-Task
high	I-Task
-	I-Task
resolution	I-Task
datasets	I-Task
.	O
	
For	O
all	O
datasets	O
,	O
our	O
top	B-Method
GAN	I-Method
generates	O
fc3	O
features	O
from	O
some	O
random	O
noise	O
,	O
conditioned	O
on	O
label	O
.	O
	
The	O
bottom	O
GAN	B-Method
generates	O
images	O
from	O
some	O
noise	O
,	O
conditioned	O
on	O
fc3	O
features	O
generated	O
from	O
GAN	B-Method
.	O
	
We	O
set	O
the	O
loss	O
coefficient	O
parameters	O
and	O
.	O
	
subsection	O
:	O
Datasets	O
	
We	O
thoroughly	O
evaluate	O
SGAN	B-Method
on	O
three	O
widely	O
adopted	O
datasets	O
:	O
MNIST	O
,	O
SVHN	O
,	O
and	O
CIFAR	B-Material
-	I-Material
10	I-Material
.	O
	
The	O
details	O
of	O
each	O
dataset	O
is	O
described	O
in	O
the	O
following	O
.	O
	
MNIST	O
:	O
	
The	O
MNIST	O
dataset	O
contains	O
labeled	O
images	O
of	O
hand	O
-	O
written	O
digits	O
with	O
in	O
the	O
training	O
set	O
and	O
in	O
the	O
test	O
set	O
.	O
	
Each	O
image	O
is	O
sized	O
by	O
.	O
	
SVHN	O
:	O
	
The	O
SVHN	O
dataset	O
is	O
composed	O
of	O
real	O
-	O
world	O
color	O
images	O
of	O
house	O
numbers	O
collected	O
by	O
Google	O
Street	O
View	O
.	O
	
Each	O
image	O
is	O
of	O
size	O
and	O
the	O
task	O
is	O
to	O
classify	O
the	O
digit	O
at	O
the	O
center	O
of	O
the	O
image	O
.	O
	
The	O
dataset	O
contains	O
training	O
images	O
and	O
test	O
images	O
.	O
	
CIFAR	B-Material
-	I-Material
10	I-Material
	
:	O
The	O
CIFAR	B-Material
-	I-Material
10	I-Material
dataset	I-Material
consists	O
of	O
colored	O
natural	O
scene	O
images	O
sized	O
at	O
pixels	O
.	O
	
There	O
are	O
50	O
,	O
000	O
training	O
images	O
and	O
10	O
,	O
000	O
test	O
images	O
in	O
classes	O
.	O
	
subsection	O
:	O
Samples	O
	
In	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
a	O
)	O
,	O
we	O
show	O
MNIST	O
samples	O
generated	O
by	O
SGAN	B-Method
.	O
	
Each	O
row	O
corresponds	O
to	O
samples	O
conditioned	O
on	O
a	O
given	O
digit	O
class	O
label	O
.	O
	
SGAN	B-Method
is	O
able	O
to	O
generate	O
diverse	O
images	O
with	O
different	O
characteristics	O
.	O
	
The	O
samples	O
are	O
visually	O
indistinguishable	O
from	O
real	O
MNIST	O
images	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
b	O
)	O
,	O
but	O
still	O
have	O
differences	O
compared	O
with	O
corresponding	O
nearest	O
neighbor	O
training	O
images	O
.	O
	
We	O
further	O
examine	O
the	O
effect	O
of	O
entropy	O
loss	O
.	O
	
In	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
(	O
c	O
)	O
we	O
show	O
the	O
samples	O
generated	O
by	O
bottom	O
GAN	B-Method
when	O
conditioned	O
on	O
a	O
fixed	O
fc3	O
feature	O
generated	O
by	O
the	O
top	B-Method
GAN	I-Method
.	O
	
The	O
samples	O
(	O
per	O
row	O
)	O
have	O
sufficient	O
low	O
-	O
level	O
variations	O
,	O
which	O
reassures	O
that	O
bottom	O
GAN	B-Method
learns	O
to	O
generate	O
images	O
without	O
ignoring	O
the	O
noise	O
.	O
	
In	O
contrast	O
,	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
d	O
)	O
	
,	O
we	O
show	O
samples	O
generated	O
without	O
using	O
entropy	O
loss	O
for	O
bottom	B-Method
generator	I-Method
,	O
where	O
we	O
observe	O
that	O
the	O
bottom	O
GAN	B-Method
ignores	O
the	O
noise	O
and	O
instead	O
deterministically	O
generates	O
images	O
from	O
fc3	O
features	O
.	O
	
An	O
advantage	O
of	O
SGAN	B-Method
compared	O
with	O
a	O
vanilla	O
GAN	B-Method
is	O
its	O
interpretability	O
:	O
it	O
decomposes	O
the	O
total	O
variations	O
of	O
an	O
image	O
into	O
different	O
levels	O
.	O
	
For	O
example	O
,	O
in	O
MNIST	B-Method
it	O
decomposes	O
the	O
variations	O
into	O
that	O
represents	O
the	O
high	O
-	O
level	O
digit	O
label	O
,	O
that	O
captures	O
the	O
mid	O
-	O
level	O
coarse	O
pose	O
of	O
the	O
digit	O
and	O
that	O
represents	O
the	O
low	O
-	O
level	O
spatial	O
details	O
.	O
	
The	O
samples	O
generated	O
on	O
SVHN	O
and	O
CIFAR	B-Material
-	I-Material
10	I-Material
datasets	O
can	O
be	O
seen	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
and	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
respectively	O
.	O
	
Provided	O
with	O
the	O
same	O
fc3	O
feature	O
,	O
we	O
see	O
in	O
each	O
row	O
of	O
panel	O
(	O
c	O
)	O
that	O
SGAN	B-Method
is	O
able	O
to	O
generate	O
samples	O
with	O
similar	O
coarse	O
outline	O
but	O
different	O
lighting	O
conditions	O
and	O
background	O
clutters	O
.	O
	
Also	O
,	O
the	O
nearest	O
neighbor	O
images	O
in	O
the	O
training	O
set	O
indicate	O
that	O
SGAN	B-Method
is	O
not	O
simply	O
memorizing	O
training	O
data	O
,	O
but	O
can	O
truly	O
generate	O
novel	O
images	O
.	O
	
subsection	O
:	O
Comparison	O
with	O
the	O
state	O
of	O
the	O
art	O
	
Here	O
,	O
we	O
compare	O
SGAN	B-Method
with	O
other	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
generative	B-Method
models	I-Method
on	O
CIFAR	B-Material
-	I-Material
10	I-Material
dataset	I-Material
.	O
	
The	O
visual	B-Metric
quality	I-Metric
of	O
generated	O
images	O
is	O
measured	O
by	O
the	O
widely	O
used	O
metric	O
,	O
Inception	B-Metric
score	I-Metric
.	O
	
Following	O
,	O
we	O
sample	O
images	O
from	O
our	O
model	O
and	O
use	O
the	O
code	O
provided	O
by	O
to	O
compute	O
the	O
score	O
.	O
	
As	O
shown	O
in	O
Tab	O
.	O
	
[	O
reference	O
]	O
,	O
SGAN	B-Method
obtains	O
a	O
score	O
of	O
,	O
outperforming	O
AC	B-Method
-	I-Method
GAN	I-Method
(	I-Method
)	O
and	O
Improved	O
GAN	B-Method
(	O
)	O
.	O
	
Also	O
,	O
note	O
that	O
the	O
techniques	O
introduced	O
in	O
are	O
not	O
used	O
in	O
our	O
implementations	O
.	O
	
Incorporating	O
these	O
techniques	O
might	O
further	O
boost	O
the	O
performance	O
of	O
our	O
model	O
.	O
	
Trained	O
with	O
labels	O
.	O
	
subsection	O
:	O
Visual	B-Task
Turing	I-Task
test	I-Task
	
To	O
further	O
verify	O
the	O
effectiveness	O
of	O
SGAN	B-Method
,	O
we	O
conduct	O
human	B-Task
visual	I-Task
Turing	I-Task
test	I-Task
in	O
which	O
we	O
ask	O
AMT	B-Method
workers	I-Method
to	O
distinguish	O
between	O
real	O
images	O
and	O
images	O
generated	O
by	O
our	O
networks	O
.	O
	
We	O
exactly	O
follow	O
the	O
interface	O
used	O
in	O
Improved	O
GAN	B-Method
,	O
in	O
which	O
the	O
workers	O
are	O
given	O
images	O
at	O
each	O
time	O
and	O
can	O
receive	O
feedback	O
about	O
whether	O
their	O
answers	O
are	O
correct	O
.	O
	
With	O
votes	O
for	O
each	O
evaluated	O
model	O
,	O
our	O
AMT	B-Method
workers	I-Method
got	O
error	B-Metric
rate	I-Metric
for	O
samples	O
from	O
SGAN	B-Method
and	O
for	O
samples	O
from	O
DCGAN	B-Method
.	O
	
This	O
further	O
confirms	O
that	O
our	O
stacked	B-Method
design	I-Method
can	O
significantly	O
improve	O
the	O
image	B-Metric
quality	I-Metric
over	O
GAN	B-Method
without	O
stacking	O
.	O
	
subsection	O
:	O
More	O
ablation	B-Task
studies	I-Task
	
In	O
Sec	O
.	O
	
[	O
reference	O
]	O
	
we	O
have	O
examined	O
the	O
effect	O
of	O
entropy	O
loss	O
.	O
	
In	O
order	O
to	O
further	O
understand	O
the	O
effect	O
of	O
different	O
model	B-Method
components	I-Method
,	O
we	O
conduct	O
extensive	O
ablation	B-Task
studies	I-Task
by	O
evaluating	O
several	O
baseline	O
methods	O
on	O
CIFAR	B-Material
-	I-Material
10	I-Material
dataset	I-Material
.	O
	
If	O
not	O
mentioned	O
otherwise	O
,	O
all	O
models	O
below	O
use	O
the	O
same	O
training	O
hyper	O
-	O
parameters	O
as	O
the	O
full	B-Method
SGAN	I-Method
model	I-Method
.	O
	
SGAN	B-Method
:	O
	
The	O
full	O
model	O
,	O
as	O
described	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
.	O
	
SGAN	B-Method
-	I-Method
no	I-Method
-	I-Method
joint	I-Method
:	O
Same	O
architecture	O
as	O
(	O
a	O
)	O
,	O
but	O
each	O
GAN	B-Method
is	O
trained	O
independently	O
,	O
and	O
there	O
is	O
no	O
final	O
joint	B-Method
training	I-Method
stage	I-Method
.	O
	
DCGAN	B-Method
(	O
)	O
:	O
	
This	O
is	O
a	O
single	O
GAN	B-Method
model	O
with	O
the	O
same	O
architecture	O
as	O
the	O
bottom	O
GAN	B-Method
in	O
SGAN	B-Method
,	O
except	O
that	O
the	O
generator	B-Method
is	O
conditioned	O
on	O
labels	O
instead	O
of	O
fc3	O
features	O
.	O
	
Note	O
that	O
other	O
techniques	O
proposed	O
in	O
this	O
paper	O
,	O
including	O
conditional	O
loss	O
and	O
entropy	B-Method
loss	I-Method
,	O
are	O
still	O
employed	O
.	O
	
We	O
also	O
tried	O
to	O
use	O
the	O
full	B-Method
generator	I-Method
in	O
SGAN	B-Method
as	O
the	O
baseline	O
,	O
instead	O
of	O
only	O
the	O
bottom	B-Method
generator	I-Method
.	O
	
However	O
,	O
we	O
failed	O
to	O
make	O
it	O
converge	O
,	O
possibly	O
because	O
is	O
too	O
deep	O
to	O
be	O
trained	O
without	O
intermediate	O
supervision	O
from	O
representation	B-Method
discriminators	I-Method
.	O
	
DCGAN	B-Method
(	O
)	O
:	O
Same	O
architecture	O
as	O
(	O
c	O
)	O
,	O
but	O
trained	O
without	O
entropy	O
loss	O
.	O
	
DCGAN	B-Method
(	O
)	O
:	O
Same	O
architecture	O
as	O
(	O
c	O
)	O
,	O
but	O
trained	O
without	O
conditional	O
loss	O
.	O
	
This	O
model	O
therefore	O
does	O
not	O
use	O
label	O
information	O
.	O
	
DCGAN	B-Method
(	O
)	O
:	O
Same	O
architecture	O
as	O
(	O
c	O
)	O
,	O
but	O
trained	O
with	O
neither	O
conditional	O
loss	O
nor	O
entropy	O
loss	O
.	O
	
This	O
model	O
also	O
does	O
not	O
use	O
label	O
information	O
.	O
	
It	O
can	O
be	O
viewed	O
as	O
a	O
plain	O
unconditional	B-Method
DCGAN	I-Method
model	I-Method
and	O
serves	O
as	O
the	O
ultimate	O
baseline	O
.	O
	
We	O
compare	O
the	O
generated	O
samples	O
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
and	O
Inception	B-Metric
scores	I-Metric
(	O
Tab	O
.	O
	
[	O
reference	O
]	O
)	O
of	O
the	O
baseline	O
methods	O
.	O
	
Below	O
we	O
summarize	O
some	O
of	O
our	O
results	O
:	O
SGAN	B-Method
obtains	O
slightly	O
higher	O
Inception	B-Metric
score	I-Metric
than	O
SGAN	B-Method
-	I-Method
no	I-Method
-	I-Method
joint	I-Method
.	O
	
Yet	O
SGAN	B-Method
-	I-Method
no	I-Method
-	I-Method
joint	I-Method
also	O
generates	O
very	O
high	O
quality	O
samples	O
and	O
outperforms	O
all	O
previous	O
methods	O
in	O
terms	O
of	O
Inception	B-Metric
scores	I-Metric
.	O
	
SGAN	B-Method
,	O
either	O
with	O
or	O
without	O
joint	B-Method
training	I-Method
,	O
achieves	O
significantly	O
higher	O
Inception	B-Metric
score	I-Metric
and	O
better	O
sample	B-Metric
quality	I-Metric
than	O
the	O
baseline	O
DCGANs	B-Method
.	O
	
This	O
demonstrates	O
the	O
effectiveness	O
of	O
the	O
proposed	O
stacked	B-Method
approach	I-Method
.	O
	
As	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
d	O
)	O
,	O
DCGAN	B-Method
(	I-Method
)	O
collapses	O
to	O
generating	O
a	O
single	O
image	O
per	O
category	O
,	O
while	O
adding	O
the	O
entropy	O
loss	O
enables	O
it	O
to	O
generate	O
diverse	O
images	O
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
(	O
c	O
)	O
)	O
.	O
	
This	O
further	O
demonstrates	O
that	O
entropy	O
loss	O
is	O
effective	O
at	O
improving	O
output	O
diversity	O
.	O
	
The	O
single	B-Method
DCGAN	I-Method
(	I-Method
)	I-Method
model	I-Method
obtains	O
higher	O
Inception	B-Metric
score	I-Metric
than	O
the	O
conditional	B-Method
DCGAN	I-Method
reported	O
in	O
.	O
	
This	O
suggests	O
that	O
might	O
offer	O
some	O
advantages	O
compared	O
to	O
a	O
plain	O
conditional	B-Method
DCGAN	I-Method
,	O
even	O
without	O
stacking	B-Method
.	O
	
In	O
general	O
,	O
Inception	B-Metric
score	I-Metric
correlates	O
well	O
with	O
visual	B-Metric
quality	I-Metric
of	I-Metric
images	I-Metric
.	O
	
However	O
,	O
it	O
seems	O
to	O
be	O
insensitive	O
to	O
diversity	O
issues	O
.	O
	
For	O
example	O
,	O
it	O
gives	O
the	O
same	O
score	O
to	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
d	O
)	O
and	O
(	O
e	O
)	O
while	O
(	O
d	O
)	O
has	O
clearly	O
collapsed	O
.	O
	
This	O
is	O
consistent	O
with	O
results	O
in	O
.	O
	
section	O
:	O
Discussion	O
and	O
Future	O
Work	O
	
This	O
paper	O
introduces	O
a	O
top	B-Method
-	I-Method
down	I-Method
generative	I-Method
framework	I-Method
named	O
SGAN	B-Method
,	O
which	O
effectively	O
leverages	O
the	O
representational	O
information	O
from	O
a	O
pre	B-Method
-	I-Method
trained	I-Method
discriminative	I-Method
network	I-Method
.	O
	
Our	O
approach	O
decomposes	O
the	O
hard	O
problem	O
of	O
estimating	B-Task
image	I-Task
distribution	I-Task
into	O
multiple	O
relatively	O
easier	O
tasks	O
–	O
each	O
generating	O
plausible	B-Method
representations	I-Method
conditioned	O
on	O
higher	O
-	O
level	B-Method
representations	I-Method
.	O
	
The	O
key	O
idea	O
is	O
to	O
use	O
representation	B-Method
discriminators	I-Method
at	O
different	O
training	O
hierarchies	O
to	O
provide	O
intermediate	O
supervision	O
.	O
	
We	O
also	O
propose	O
a	O
novel	O
entropy	B-Method
loss	I-Method
to	O
tackle	O
the	O
problem	O
that	O
conditional	O
GANs	B-Method
tend	O
to	O
ignore	O
the	O
noise	O
.	O
	
Our	O
entropy	B-Method
loss	I-Method
could	O
be	O
employed	O
in	O
other	O
applications	O
of	O
conditional	O
GANs	B-Method
,	O
e.g.	O
,	O
synthesizing	O
different	O
future	O
frames	O
given	O
the	O
same	O
past	O
frames	O
,	O
or	O
generating	O
a	O
diverse	O
set	O
of	O
images	O
conditioned	O
on	O
the	O
same	O
label	O
map	O
.	O
	
We	O
believe	O
this	O
is	O
an	O
interesting	O
research	O
direction	O
in	O
the	O
future	O
.	O
	
subsubsection	O
:	O
Acknowledgments	O
	
We	O
would	O
like	O
to	O
thank	O
Danlu	O
Chen	O
for	O
the	O
help	O
with	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Also	O
,	O
we	O
want	O
to	O
thank	O
Danlu	O
Chen	O
,	O
Shuai	O
Tang	O
,	O
Saining	O
Xie	O
,	O
Zhuowen	O
Tu	O
,	O
Felix	O
Wu	O
and	O
Kilian	O
Weinberger	O
for	O
helpful	O
discussions	O
.	O
	
Yixuan	O
Li	O
is	O
supported	O
by	O
US	O
Army	O
Research	O
Office	O
W911NF	O
-	O
14	O
-	O
1	O
-	O
0477	O
.	O
	
Serge	O
Belongie	O
is	O
supported	O
in	O
part	O
by	O
a	O
Google	O
Focused	O
Research	O
Award	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
DensePose	B-Task
:	O
Dense	B-Task
Human	I-Task
Pose	I-Task
Estimation	I-Task
In	O
The	O
Wild	O
	
In	O
this	O
work	O
,	O
we	O
establish	O
dense	O
correspondences	O
between	O
an	O
RGB	O
image	O
and	O
a	O
surface	B-Method
-	I-Method
based	I-Method
representation	I-Method
of	I-Method
the	I-Method
human	I-Method
body	I-Method
,	O
a	O
task	O
we	O
refer	O
to	O
as	O
dense	B-Task
human	I-Task
pose	I-Task
estimation	I-Task
.	O
	
We	O
first	O
gather	O
dense	O
correspondences	O
for	O
50	O
K	O
persons	O
appearing	O
in	O
the	O
COCO	B-Material
dataset	I-Material
by	O
introducing	O
an	O
efficient	O
annotation	B-Method
pipeline	I-Method
.	O
	
We	O
then	O
use	O
our	O
dataset	O
to	O
train	O
CNN	B-Method
-	I-Method
based	I-Method
systems	I-Method
that	O
deliver	O
dense	B-Task
correspondence	I-Task
‘	O
in	O
the	O
wild	O
’	O
,	O
namely	O
in	O
the	O
presence	O
of	O
background	O
,	O
occlusions	O
and	O
scale	O
variations	O
.	O
	
We	O
improve	O
our	O
training	O
set	O
’s	O
effectiveness	O
by	O
training	O
an	O
‘	O
inpainting	B-Method
’	I-Method
network	I-Method
that	O
can	O
fill	O
in	O
missing	O
ground	O
truth	O
values	O
,	O
and	O
report	O
clear	O
improvements	O
with	O
respect	O
to	O
the	O
best	O
results	O
that	O
would	O
be	O
achievable	O
in	O
the	O
past	O
.	O
	
We	O
experiment	O
with	O
fully	B-Method
-	I-Method
convolutional	I-Method
networks	I-Method
and	O
region	B-Method
-	I-Method
based	I-Method
models	I-Method
and	O
observe	O
a	O
superiority	O
of	O
the	O
latter	O
;	O
we	O
further	O
improve	O
accuracy	B-Metric
through	O
cascading	O
,	O
obtaining	O
a	O
system	O
that	O
delivers	O
highly	O
-	O
accurate	O
results	O
in	O
real	O
time	O
.	O
	
Supplementary	O
materials	O
and	O
videos	O
are	O
provided	O
on	O
the	O
project	O
page	O
.	O
	
section	O
:	O
Introduction	O
	
This	O
work	O
aims	O
at	O
pushing	O
further	O
the	O
envelope	O
of	O
human	B-Task
understanding	I-Task
in	O
images	O
by	O
establishing	O
dense	B-Task
correspondences	I-Task
from	O
a	O
2D	O
image	O
to	O
a	O
3D	B-Method
,	I-Method
surface	I-Method
-	I-Method
based	I-Method
representation	I-Method
of	I-Method
the	I-Method
human	I-Method
body	I-Method
.	O
	
We	O
can	O
understand	O
this	O
task	O
as	O
involving	O
several	O
other	O
problems	O
,	O
such	O
as	O
object	B-Task
detection	I-Task
,	O
pose	B-Task
estimation	I-Task
,	O
part	B-Task
and	I-Task
instance	I-Task
segmentation	I-Task
either	O
as	O
special	O
cases	O
or	O
prerequisites	O
.	O
	
Addressing	O
this	O
task	O
has	O
applications	O
in	O
problems	O
that	O
require	O
going	O
beyond	O
plain	B-Task
landmark	I-Task
localization	I-Task
,	O
such	O
as	O
graphics	B-Task
,	O
augmented	B-Task
reality	I-Task
,	O
or	O
human	B-Task
-	I-Task
computer	I-Task
interaction	I-Task
,	O
and	O
could	O
also	O
be	O
a	O
stepping	O
stone	O
towards	O
general	O
3D	B-Task
-	I-Task
based	I-Task
object	I-Task
understanding	I-Task
.	O
	
The	O
task	O
of	O
establishing	O
dense	B-Task
correspondences	I-Task
from	O
an	O
image	O
to	O
a	O
surface	B-Method
-	I-Method
based	I-Method
model	I-Method
has	O
been	O
addressed	O
mostly	O
in	O
the	O
setting	O
where	O
a	O
depth	O
sensor	O
is	O
available	O
,	O
as	O
in	O
the	O
Vitruvian	O
manifold	O
of	O
,	O
metric	B-Method
regression	I-Method
forests	I-Method
,	O
or	O
the	O
more	O
recent	O
dense	B-Method
point	I-Method
cloud	I-Method
correspondence	I-Method
of	O
.	O
	
By	O
contrast	O
,	O
in	O
our	O
case	O
we	O
consider	O
a	O
single	O
RGB	O
image	O
as	O
input	O
,	O
based	O
on	O
which	O
we	O
establish	O
a	O
correspondence	O
between	O
surface	O
points	O
and	O
image	O
pixels	O
.	O
	
Several	O
other	O
works	O
have	O
recently	O
aimed	O
at	O
recovering	O
dense	B-Task
correspondences	I-Task
between	O
pairs	O
or	O
sets	O
of	O
RGB	O
images	O
in	O
an	O
unsupervised	B-Task
setting	I-Task
.	O
	
More	O
recently	O
,	O
used	O
the	O
equivariance	B-Method
principle	I-Method
in	O
order	O
to	O
align	O
sets	O
of	O
images	O
to	O
a	O
common	O
coordinate	O
system	O
,	O
while	O
following	O
the	O
general	O
idea	O
of	O
groupwise	B-Task
image	I-Task
alignment	I-Task
,	O
e.g.	O
.	O
	
While	O
these	O
works	O
are	O
aiming	O
at	O
general	O
categories	O
,	O
our	O
work	O
is	O
focused	O
on	O
arguably	O
the	O
most	O
important	O
visual	O
category	O
,	O
humans	O
.	O
	
For	O
humans	O
one	O
can	O
simplify	O
the	O
task	O
by	O
exploiting	O
parametric	B-Method
deformable	I-Method
surface	I-Method
models	I-Method
,	O
such	O
as	O
the	O
Skinned	B-Method
Multi	I-Method
-	I-Method
Person	I-Method
Linear	I-Method
(	I-Method
SMPL	I-Method
)	I-Method
model	I-Method
of	O
,	O
or	O
the	O
more	O
recent	O
Adam	B-Method
model	I-Method
of	O
obtained	O
through	O
carefully	O
controlled	B-Method
3D	I-Method
surface	I-Method
acquisition	I-Method
.	O
	
Turning	O
to	O
the	O
task	O
of	O
image	B-Task
-	I-Task
to	I-Task
-	I-Task
surface	I-Task
mapping	I-Task
,	O
in	O
,	O
the	O
authors	O
propose	O
a	O
two	O
-	O
stage	O
method	O
of	O
first	O
detecting	B-Task
human	I-Task
landmarks	I-Task
through	O
a	O
CNN	B-Method
and	O
then	O
fitting	O
a	O
parametric	B-Method
deformable	I-Method
surface	I-Method
model	I-Method
to	O
the	O
image	O
through	O
iterative	B-Method
minimization	I-Method
.	O
	
In	O
parallel	O
to	O
our	O
work	O
,	O
develop	O
the	O
method	O
of	O
to	O
operate	O
in	O
an	O
end	O
-	O
to	O
-	O
end	O
fashion	O
,	O
incorporating	O
the	O
iterative	B-Method
reprojection	I-Method
error	I-Method
minimization	I-Method
as	O
a	O
module	O
of	O
a	O
deep	B-Method
network	I-Method
that	O
recovers	O
3D	O
camera	O
pose	O
and	O
the	O
low	O
-	O
dimensional	O
body	O
parametrization	O
.	O
	
Our	O
methodology	O
differs	O
from	O
all	O
these	O
works	O
in	O
that	O
we	O
take	O
a	O
full	O
-	O
blown	O
supervised	B-Method
learning	I-Method
approach	I-Method
and	O
gather	O
ground	O
-	O
truth	O
correspondences	O
between	O
images	O
and	O
a	O
detailed	O
,	O
accurate	O
parametric	B-Method
surface	I-Method
model	I-Method
of	O
the	O
human	O
body	O
:	O
rather	O
than	O
using	O
the	O
SMPL	B-Method
model	I-Method
at	O
test	O
time	O
we	O
only	O
use	O
it	O
as	O
a	O
means	O
of	O
defining	O
our	O
problem	O
during	O
training	B-Task
.	O
	
Our	O
approach	O
can	O
be	O
understood	O
as	O
the	O
next	O
step	O
in	O
the	O
line	O
of	O
works	O
on	O
extending	O
the	O
standard	O
for	O
humans	O
in	O
.	O
	
Human	B-Task
part	I-Task
segmentation	I-Task
masks	I-Task
have	O
been	O
provided	O
in	O
the	O
Fashionista	O
,	O
PASCAL	O
-	O
Parts	O
,	O
and	O
Look	O
-	O
Into	O
-	O
People	O
(	O
LIP	O
)	O
datasets	O
;	O
these	O
can	O
be	O
understood	O
as	O
providing	O
a	O
coarsened	O
version	O
of	O
image	B-Task
-	I-Task
to	I-Task
-	I-Task
surface	I-Task
correspondence	I-Task
,	O
where	O
rather	O
than	O
continuous	O
coordinates	O
one	O
predicts	O
discretized	O
part	O
labels	O
.	O
	
Surface	B-Method
-	I-Method
level	I-Method
supervision	I-Method
was	O
only	O
recently	O
introduced	O
for	O
synthetic	O
images	O
in	O
,	O
while	O
in	O
a	O
dataset	O
of	O
8515	O
images	O
is	O
annotated	O
with	O
keypoints	O
and	O
semi	O
-	O
automated	B-Method
fits	I-Method
of	I-Method
3D	I-Method
models	I-Method
to	O
images	O
.	O
	
In	O
this	O
work	O
instead	O
of	O
compromising	O
the	O
extent	O
and	O
realism	O
of	O
our	O
training	O
set	O
we	O
introduce	O
a	O
novel	O
annotation	B-Method
pipeline	I-Method
that	O
allows	O
us	O
to	O
gather	O
ground	O
-	O
truth	O
correspondences	O
for	O
50	O
K	O
images	O
of	O
the	O
COCO	B-Material
dataset	I-Material
,	O
yielding	O
our	O
new	O
DensePose	B-Material
-	I-Material
COCO	I-Material
dataset	O
.	O
	
Our	O
work	O
is	O
closest	O
in	O
spirit	O
to	O
the	O
recent	O
DenseReg	B-Method
framework	I-Method
,	O
where	O
CNNs	B-Method
were	O
trained	O
to	O
successfully	O
establish	O
dense	O
correspondences	O
between	O
a	O
3D	B-Method
model	I-Method
and	O
images	O
‘	O
in	O
the	O
wild	O
’	O
.	O
	
That	O
work	O
focused	O
mainly	O
on	O
faces	O
,	O
and	O
evaluated	O
their	O
results	O
on	O
datasets	O
with	O
moderate	O
pose	O
variability	O
.	O
	
Here	O
,	O
however	O
,	O
we	O
are	O
facing	O
new	O
challenges	O
,	O
due	O
to	O
the	O
higher	O
complexity	O
and	O
flexibility	O
of	O
the	O
human	O
body	O
,	O
as	O
well	O
as	O
the	O
larger	O
variation	O
in	O
poses	O
.	O
	
We	O
address	O
these	O
challenges	O
by	O
designing	O
appropriate	O
architectures	O
,	O
as	O
described	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
,	O
which	O
yield	O
substantial	O
improvements	O
over	O
a	O
DenseReg	B-Method
-	I-Method
type	I-Method
fully	I-Method
convolutional	I-Method
architecture	I-Method
.	O
	
By	O
combining	O
our	O
approach	O
with	O
the	O
recent	O
Mask	B-Method
-	I-Method
RCNN	I-Method
system	I-Method
of	O
we	O
show	O
that	O
a	O
discriminatively	B-Method
trained	I-Method
model	I-Method
can	O
recover	O
highly	O
-	O
accurate	O
correspondence	O
fields	O
for	O
complex	O
scenes	O
involving	O
tens	O
of	O
persons	O
with	O
real	B-Metric
-	I-Metric
time	I-Metric
speed	I-Metric
:	O
on	O
a	O
GTX	O
1080	O
	
GPU	B-Method
our	O
system	O
operates	O
at	O
20	O
-	O
26	O
frames	O
per	O
second	O
for	O
a	O
image	O
or	O
4	O
-	O
5	O
frames	O
per	O
second	O
for	O
a	O
image	O
.	O
	
Our	O
contributions	O
can	O
be	O
summarized	O
in	O
three	O
points	O
.	O
	
Firstly	O
,	O
as	O
described	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
	
,	O
we	O
introduce	O
the	O
first	O
manually	O
-	O
collected	O
ground	O
truth	O
dataset	O
for	O
the	O
task	O
,	O
by	O
gathering	O
dense	O
correspondences	O
between	O
the	O
SMPL	B-Method
model	I-Method
and	O
persons	O
appearing	O
in	O
the	O
COCO	B-Material
dataset	I-Material
.	O
	
This	O
is	O
accomplished	O
through	O
a	O
novel	O
annotation	B-Method
pipeline	I-Method
that	O
exploits	O
3D	O
surface	O
information	O
during	O
annotation	B-Task
.	O
	
Secondly	O
,	O
as	O
described	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
,	O
we	O
use	O
the	O
resulting	O
dataset	O
to	O
train	O
CNN	B-Method
-	I-Method
based	I-Method
systems	I-Method
that	O
deliver	O
dense	B-Task
correspondence	I-Task
‘	O
in	O
the	O
wild	O
’	O
,	O
by	O
regressing	O
body	O
surface	O
coordinates	O
at	O
any	O
image	O
pixel	O
.	O
	
We	O
experiment	O
with	O
both	O
fully	B-Method
-	I-Method
convolutional	I-Method
architectures	I-Method
,	O
relying	O
on	O
Deeplab	B-Method
,	O
and	O
also	O
with	O
region	B-Method
-	I-Method
based	I-Method
systems	I-Method
,	O
relying	O
on	O
Mask	B-Method
-	I-Method
RCNN	I-Method
,	O
observing	O
a	O
superiority	O
of	O
region	B-Method
-	I-Method
based	I-Method
models	I-Method
over	O
fully	B-Method
-	I-Method
convolutional	I-Method
networks	I-Method
.	O
	
We	O
also	O
consider	O
cascading	O
variants	O
of	O
our	O
approach	O
,	O
yielding	O
further	O
improvements	O
over	O
existing	O
architectures	O
.	O
	
Thirdly	O
,	O
we	O
explore	O
different	O
ways	O
of	O
exploiting	O
our	O
constructed	O
ground	O
truth	O
information	O
.	O
	
Our	O
supervision	O
signal	O
is	O
defined	O
over	O
a	O
randomly	O
chosen	O
subset	O
of	O
image	O
pixels	O
per	O
training	O
sample	O
.	O
	
We	O
use	O
these	O
sparse	O
correspondences	O
to	O
train	O
a	O
‘	O
teacher	B-Method
’	I-Method
network	I-Method
that	O
can	O
‘	O
inpaint	O
’	O
the	O
supervision	O
signal	O
in	O
the	O
rest	O
of	O
the	O
image	O
domain	O
.	O
	
Using	O
this	O
inpainted	O
signal	O
results	O
in	O
clearly	O
better	O
performance	O
when	O
compared	O
to	O
either	O
sparse	O
points	O
,	O
or	O
any	O
other	O
existing	O
dataset	O
,	O
as	O
shown	O
experimentally	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
.	O
	
Our	O
experiments	O
indicate	O
that	O
dense	B-Task
human	I-Task
pose	I-Task
estimation	I-Task
is	O
to	O
a	O
large	O
extent	O
feasible	O
,	O
but	O
still	O
has	O
space	O
for	O
improvement	O
.	O
	
We	O
conclude	O
our	O
paper	O
with	O
some	O
qualitative	O
results	O
and	O
directions	O
that	O
show	O
the	O
potential	O
of	O
the	O
method	O
.	O
	
We	O
will	O
make	O
code	O
and	O
data	O
publicly	O
available	O
from	O
our	O
project	O
’s	O
webpage	O
,	O
.	O
	
section	O
:	O
COCO	B-Material
-	I-Material
DensePose	I-Material
Dataset	I-Material
	
Gathering	O
rich	O
,	O
high	O
-	O
quality	O
training	O
sets	O
has	O
been	O
a	O
catalyst	O
for	O
progress	O
in	O
the	O
classification	B-Task
,	I-Task
detection	I-Task
and	I-Task
segmentation	I-Task
tasks	I-Task
.	O
	
There	O
currently	O
exists	O
no	O
manually	O
collected	O
ground	O
-	O
truth	O
for	O
dense	B-Task
human	I-Task
pose	I-Task
estimation	I-Task
for	O
real	O
images	O
.	O
	
The	O
works	O
of	O
and	O
can	O
be	O
used	O
as	O
surrogates	O
,	O
but	O
as	O
we	O
show	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
provide	O
worse	O
supervision	O
.	O
	
In	O
this	O
Section	O
we	O
introduce	O
our	O
COCO	B-Material
-	I-Material
DensePose	I-Material
dataset	I-Material
,	O
alongside	O
with	O
evaluation	B-Metric
measures	I-Metric
that	O
allow	O
us	O
to	O
quantify	O
progress	O
in	O
the	O
task	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
.	O
	
We	O
have	O
gathered	O
annotations	O
for	O
50	O
K	O
humans	O
,	O
collecting	O
more	O
then	O
5	O
million	O
manually	O
annotated	O
correspondences	O
.	O
	
We	O
start	O
with	O
a	O
presentation	O
of	O
our	O
annotation	B-Method
pipeline	I-Method
,	O
since	O
this	O
required	O
several	O
design	O
choices	O
that	O
may	O
be	O
more	O
generally	O
useful	O
for	O
3D	B-Task
annotation	I-Task
.	O
	
We	O
then	O
turn	O
to	O
an	O
analysis	O
of	O
the	O
accuracy	B-Metric
of	O
the	O
gathered	O
ground	B-Metric
-	I-Metric
truth	I-Metric
,	O
alongside	O
with	O
the	O
resulting	O
performance	O
measures	O
used	O
to	O
assess	O
the	O
different	O
methods	O
.	O
	
subsection	O
:	O
Annotation	B-Method
System	I-Method
	
In	O
this	O
work	O
,	O
we	O
involve	O
human	B-Task
annotators	I-Task
to	O
establish	O
dense	O
correspondences	O
from	O
2D	O
images	O
to	O
surface	B-Method
-	I-Method
based	I-Method
representations	I-Method
of	I-Method
the	I-Method
human	I-Method
body	I-Method
.	O
	
If	O
done	O
naively	O
,	O
this	O
would	O
require	O
‘	O
hunting	O
vertices	O
’	O
for	O
every	O
2D	O
image	O
point	O
,	O
by	O
manipulating	O
a	O
surface	O
through	O
rotations	O
-	O
which	O
can	O
be	O
frustratingly	O
inefficient	O
.	O
	
Instead	O
,	O
we	O
construct	O
an	O
annotation	B-Method
pipeline	I-Method
through	O
which	O
we	O
can	O
efficiently	O
gather	O
annotations	O
for	O
image	B-Task
-	I-Task
to	I-Task
-	I-Task
surface	I-Task
correspondence	I-Task
.	O
	
As	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
,	O
in	O
the	O
first	O
stage	O
we	O
ask	O
annotators	O
to	O
delineate	O
regions	O
corresponding	O
to	O
visible	O
,	O
semantically	O
defined	O
body	O
parts	O
.	O
	
These	O
include	O
Head	O
,	O
Torso	O
,	O
Lower	O
/	O
Upper	O
Arms	O
,	O
Lower	O
/	O
Upper	O
Legs	O
,	O
Hands	O
and	O
Feet	O
.	O
	
In	O
order	O
to	O
use	O
simplify	O
the	O
UV	B-Method
parametrization	I-Method
we	O
design	O
the	O
parts	O
to	O
be	O
isomorphic	O
to	O
a	O
plane	O
,	O
partitioning	O
the	O
limbs	O
and	O
torso	O
into	O
lower	O
-	O
upper	O
and	O
frontal	O
-	O
back	O
parts	O
.	O
	
For	O
head	O
,	O
hands	O
and	O
feet	O
,	O
we	O
use	O
the	O
manually	O
obtained	O
UV	O
fields	O
provided	O
in	O
the	O
SMPL	B-Method
model	I-Method
.	O
	
For	O
the	O
rest	O
of	O
the	O
parts	O
we	O
obtain	O
the	O
unwrapping	B-Method
via	O
multi	B-Method
-	I-Method
dimensional	I-Method
scaling	I-Method
applied	O
to	O
pairwise	O
geodesic	O
distances	O
.	O
	
The	O
UV	O
fields	O
for	O
the	O
resulting	O
24	O
parts	O
are	O
visualized	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
(	O
right	O
)	O
.	O
	
We	O
instruct	O
the	O
annotators	O
to	O
estimate	O
the	O
body	O
part	O
behind	O
the	O
clothes	O
,	O
so	O
that	O
for	O
instance	O
wearing	O
a	O
large	O
skirt	O
would	O
not	O
complicate	O
the	O
subsequent	O
annotation	B-Task
of	I-Task
correspondences	I-Task
.	O
	
In	O
the	O
second	O
stage	O
we	O
sample	O
every	O
part	O
region	O
with	O
a	O
set	O
of	O
roughly	O
equidistant	O
points	O
obtained	O
via	O
k	B-Method
-	I-Method
means	I-Method
and	O
request	O
the	O
annotators	O
to	O
bring	O
these	O
points	O
in	O
correspondence	O
with	O
the	O
surface	O
.	O
	
The	O
number	O
of	O
sampled	O
points	O
varies	O
based	O
on	O
the	O
size	O
of	O
the	O
part	O
and	O
the	O
maximum	O
number	O
of	O
sampled	O
points	O
per	O
part	O
is	O
14	O
.	O
	
In	O
order	O
to	O
simplify	O
this	O
task	O
we	O
‘	O
unfold	O
’	O
the	O
part	O
surface	O
by	O
providing	O
six	O
pre	O
-	O
rendered	O
views	O
of	O
the	O
same	O
body	O
part	O
and	O
allow	O
the	O
user	O
to	O
place	O
landmarks	O
on	O
any	O
of	O
them	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
This	O
allows	O
the	O
annotator	O
to	O
choose	O
the	O
most	O
convenient	O
point	O
of	O
view	O
by	O
selecting	O
one	O
among	O
six	O
options	O
instead	O
of	O
manually	O
rotating	O
the	O
surface	O
.	O
	
As	O
the	O
user	O
indicates	O
a	O
point	O
on	O
any	O
of	O
the	O
rendered	O
part	O
views	O
,	O
its	O
surface	O
coordinates	O
are	O
used	O
to	O
simultaneously	O
show	O
its	O
position	O
on	O
the	O
remaining	O
views	O
–	O
	
this	O
gives	O
a	O
global	O
overview	O
of	O
the	O
correspondence	O
.	O
	
The	O
image	O
points	O
are	O
presented	O
to	O
the	O
annotator	O
in	O
a	O
horizontal	O
/	O
vertical	O
succession	O
,	O
which	O
makes	O
it	O
easier	O
to	O
deliver	O
geometrically	O
consistent	O
annotations	O
by	O
avoiding	O
self	O
-	O
crossings	O
of	O
the	O
surface	O
.	O
	
This	O
two	O
-	O
stage	O
annotation	B-Method
process	I-Method
has	O
allowed	O
us	O
to	O
very	O
efficiently	O
gather	O
highly	O
accurate	O
correspondences	O
.	O
	
If	O
we	O
quantify	O
the	O
complexity	B-Metric
of	O
the	O
annotation	B-Task
task	I-Task
in	O
terms	O
of	O
the	O
time	O
it	O
takes	O
to	O
complete	O
it	O
,	O
we	O
have	O
seen	O
that	O
the	O
part	B-Task
segmentation	I-Task
and	O
correspondence	B-Task
annotation	I-Task
tasks	I-Task
take	O
approximately	O
the	O
same	O
time	O
,	O
which	O
is	O
surprising	O
given	O
the	O
more	O
challenging	O
nature	O
of	O
the	O
latter	O
task	O
.	O
	
Visualizations	O
of	O
the	O
collected	O
annotations	O
are	O
provided	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
where	O
the	O
partitioning	O
of	O
the	O
surface	O
and	O
U	O
,	O
V	O
coordinates	O
are	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
subsection	O
:	O
Accuracy	B-Metric
of	O
human	O
annotators	O
	
We	O
assess	O
human	O
annotator	O
with	O
respect	O
to	O
a	O
gold	O
-	O
standard	O
measure	O
of	O
performance	O
.	O
	
Typically	O
in	O
pose	B-Task
estimation	I-Task
one	O
asks	O
multiple	O
annotators	O
to	O
label	O
the	O
same	O
landmark	O
,	O
which	O
is	O
then	O
used	O
to	O
assess	O
the	O
variance	O
in	O
position	O
,	O
e.g.	O
.	O
	
In	O
our	O
case	O
,	O
we	O
can	O
render	O
images	O
where	O
we	O
have	O
access	O
to	O
the	O
true	O
mesh	O
coordinates	O
used	O
to	O
render	O
a	O
pixel	O
.	O
	
We	O
thereby	O
directly	O
compare	O
the	O
true	O
position	O
used	O
during	O
rendering	B-Task
and	O
the	O
one	O
estimated	O
by	O
annotators	O
,	O
rather	O
than	O
first	O
estimating	O
a	O
’	O
consensus	O
’	O
landmark	O
location	O
among	O
multiple	O
human	O
annotators	O
.	O
	
In	O
particular	O
,	O
we	O
provide	O
annotators	O
with	O
synthetic	O
images	O
generated	O
through	O
the	O
exact	O
same	O
surface	B-Method
model	I-Method
as	O
the	O
one	O
we	O
use	O
in	O
our	O
ground	B-Task
-	I-Task
truth	I-Task
annotation	I-Task
,	O
exploiting	O
the	O
rendering	B-Method
system	I-Method
and	O
textures	O
of	O
.	O
	
We	O
then	O
ask	O
annotators	O
to	O
bring	O
the	O
synthesized	O
images	O
into	O
correspondence	O
with	O
the	O
surface	O
using	O
our	O
annotation	B-Method
tool	I-Method
,	O
and	O
for	O
every	O
image	O
estimate	O
the	O
geodesic	O
distance	O
between	O
the	O
correct	O
surface	O
point	O
,	O
and	O
the	O
point	O
estimated	O
by	O
human	O
annotators	O
:	O
where	O
measures	O
the	O
geodesic	O
distance	O
between	O
two	O
surface	O
points	O
.	O
	
For	O
any	O
image	O
,	O
we	O
annotate	O
and	O
estimate	O
the	O
error	O
only	O
on	O
a	O
randomly	O
sampled	O
set	O
of	O
surface	O
points	O
and	O
interpolate	O
the	O
errors	O
on	O
the	O
remainder	O
of	O
the	O
surface	O
.	O
	
Finally	O
,	O
we	O
average	O
the	O
errors	O
across	O
all	O
examples	O
used	O
to	O
assess	O
annotator	B-Task
performance	O
.	O
	
As	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
the	O
annotation	B-Metric
errors	I-Metric
are	O
substantially	O
smaller	O
on	O
small	O
surface	O
parts	O
with	O
distinctive	O
features	O
that	O
could	O
help	O
localization	B-Task
(	O
face	O
,	O
hands	O
,	O
feet	O
)	O
,	O
while	O
on	O
larger	O
uniform	O
areas	O
that	O
are	O
typically	O
covered	O
by	O
clothes	O
(	O
torso	O
,	O
back	O
,	O
hips	O
)	O
the	O
annotator	O
errors	O
can	O
get	O
larger	O
.	O
	
subsection	O
:	O
Evaluation	B-Metric
Measures	I-Metric
	
We	O
consider	O
two	O
different	O
ways	O
of	O
summarizing	O
correspondence	O
accuracy	B-Metric
over	O
the	O
whole	O
human	O
body	O
,	O
including	O
pointwise	B-Method
and	I-Method
per	I-Method
-	I-Method
instance	I-Method
evaluation	I-Method
.	O
	
paragraph	O
:	O
Pointwise	B-Task
evaluation	I-Task
.	O
	
This	O
approach	O
evaluates	O
correspondence	O
accuracy	B-Metric
over	O
the	O
whole	O
image	O
domain	O
through	O
the	O
Ratio	O
of	O
Correct	O
Point	O
(	O
RCP	O
)	O
correspondences	O
,	O
where	O
a	O
correspondence	O
is	O
declared	O
correct	O
if	O
the	O
geodesic	O
distance	O
is	O
below	O
a	O
certain	O
threshold	O
.	O
	
As	O
the	O
threshold	O
varies	O
,	O
we	O
obtain	O
a	O
curve	O
,	O
whose	O
area	O
provides	O
us	O
with	O
a	O
scalar	O
summary	O
of	O
the	O
correspondence	O
accuracy	B-Metric
.	O
	
For	O
any	O
given	O
image	O
we	O
have	O
a	O
varying	O
set	O
of	O
points	O
coming	O
with	O
ground	O
-	O
truth	O
signals	O
.	O
	
We	O
summarize	O
performance	O
on	O
the	O
ensemble	O
of	O
such	O
points	O
,	O
gathered	O
across	O
images	O
.	O
	
We	O
evaluate	O
the	O
area	O
under	O
the	O
curve	O
(	O
AUC	B-Metric
)	O
,	O
,	O
for	O
two	O
different	O
values	O
of	O
yielding	O
and	O
respectively	O
,	O
where	O
is	O
understood	O
as	O
being	O
an	O
accuracy	B-Metric
measure	O
for	O
more	O
refined	O
correspondence	B-Task
.	O
	
This	O
performance	B-Metric
measure	I-Metric
is	O
easily	O
applicable	O
to	O
both	O
single	O
-	O
and	O
multi	B-Task
-	I-Task
person	I-Task
scenarios	I-Task
and	O
can	O
deliver	O
directly	O
comparable	O
values	O
.	O
	
In	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
,	O
we	O
provide	O
the	O
per	O
-	O
part	O
pointwise	O
evaluation	O
of	O
the	O
human	B-Metric
annotator	I-Metric
performance	I-Metric
on	O
synthetic	O
data	O
,	O
which	O
can	O
be	O
seen	O
as	O
an	O
upper	O
bound	O
for	O
the	O
performance	O
of	O
our	O
systems	O
.	O
	
paragraph	O
:	O
Per	B-Metric
-	I-Metric
instance	I-Metric
evaluation	I-Metric
.	O
	
Inspired	O
by	O
the	O
object	B-Method
keypoint	I-Method
similarity	I-Method
(	I-Method
OKS	I-Method
)	I-Method
measure	I-Method
used	O
for	O
pose	B-Task
evaluation	I-Task
on	O
the	O
COCO	B-Material
dataset	I-Material
,	O
we	O
introduce	O
geodesic	B-Method
point	I-Method
similarity	I-Method
(	O
GPS	B-Method
)	O
as	O
a	O
correspondence	O
matching	B-Method
score	O
:	O
where	O
is	O
the	O
set	O
of	O
ground	O
truth	O
points	O
annotated	O
on	O
person	O
instance	O
,	O
is	O
the	O
vertex	O
estimated	O
by	O
a	O
model	O
at	O
point	O
,	O
is	O
the	O
ground	O
truth	O
vertex	O
and	O
is	O
a	O
normalizing	O
parameter	O
.	O
	
We	O
set	O
so	O
that	O
a	O
single	O
point	O
has	O
a	O
GPS	O
value	O
of	O
if	O
its	O
geodesic	O
distance	O
from	O
the	O
ground	O
truth	O
equals	O
the	O
average	O
half	O
-	O
size	O
of	O
a	O
body	O
segment	O
,	O
corresponding	O
to	O
approximately	O
cm	O
.	O
	
Intuitively	O
,	O
this	O
means	O
that	O
a	O
score	O
of	O
can	O
be	O
achieved	O
by	O
a	O
perfect	O
part	B-Method
segmentation	I-Method
model	I-Method
,	O
while	O
going	O
above	O
that	O
also	O
requires	O
a	O
more	O
precise	O
localization	O
of	O
a	O
point	O
on	O
the	O
surface	O
.	O
	
Once	O
the	O
matching	B-Method
is	O
performed	O
,	O
we	O
follow	O
the	O
COCO	B-Method
challenge	I-Method
protocol	I-Method
and	O
evaluate	O
Average	B-Metric
Precision	I-Metric
(	O
AP	B-Metric
)	O
and	O
Average	B-Metric
Recall	I-Metric
(	O
AR	B-Metric
)	O
at	O
a	O
number	O
of	O
GPS	O
thresholds	O
ranging	O
from	O
0.5	O
to	O
0.95	O
,	O
which	O
corresponds	O
to	O
the	O
range	O
of	O
geodesic	O
distances	O
between	O
and	O
cm	O
.	O
	
We	O
use	O
the	O
same	O
range	O
of	O
distances	O
to	O
perform	O
both	O
per	B-Task
-	I-Task
instance	I-Task
and	O
per	B-Task
-	I-Task
point	I-Task
evaluation	I-Task
.	O
	
section	O
:	O
Learning	O
Dense	B-Task
Human	I-Task
Pose	I-Task
Estimation	I-Task
	
We	O
now	O
turn	O
to	O
the	O
task	O
of	O
training	O
a	O
deep	B-Method
network	I-Method
that	O
predicts	O
dense	O
correspondences	O
between	O
image	O
pixels	O
and	O
surface	O
points	O
.	O
	
Such	O
a	O
task	O
was	O
recently	O
addressed	O
in	O
the	O
Dense	B-Method
Regression	I-Method
(	I-Method
DenseReg	I-Method
)	I-Method
system	I-Method
of	O
through	O
a	O
fully	B-Method
-	I-Method
convolutional	I-Method
network	I-Method
architecture	I-Method
.	O
	
In	O
this	O
work	O
,	O
we	O
introduce	O
improved	O
architectures	O
by	O
combining	O
the	O
DenseReg	B-Method
approach	I-Method
with	O
the	O
Mask	B-Method
-	I-Method
RCNN	I-Method
architecture	I-Method
,	O
yielding	O
our	O
‘	O
DensePose	B-Method
-	I-Method
RCNN	I-Method
’	I-Method
system	I-Method
.	O
	
We	O
develop	O
cascaded	B-Method
extensions	I-Method
of	O
DensePose	B-Method
-	I-Method
RCNN	I-Method
that	O
further	O
improve	O
accuracy	B-Metric
and	O
describe	O
a	O
training	B-Method
-	I-Method
based	I-Method
interpolation	I-Method
method	I-Method
that	O
allows	O
us	O
to	O
turn	O
a	O
sparse	O
supervision	O
signal	O
into	O
a	O
denser	O
and	O
more	O
effective	O
variant	O
.	O
	
subsection	O
:	O
Fully	B-Task
-	I-Task
convolutional	I-Task
dense	I-Task
pose	I-Task
regression	I-Task
	
The	O
simplest	O
architecture	O
choice	O
consists	O
in	O
using	O
a	O
fully	B-Method
convolutional	I-Method
network	I-Method
(	O
FCN	B-Method
)	O
that	O
combines	O
a	O
classification	B-Task
and	O
a	O
regression	B-Task
task	I-Task
,	O
similar	O
to	O
DenseReg	B-Method
.	O
	
In	O
a	O
first	O
step	O
,	O
we	O
classify	O
a	O
pixel	O
as	O
belonging	O
to	O
either	O
background	O
,	O
or	O
one	O
among	O
several	O
region	O
parts	O
which	O
provide	O
a	O
coarse	O
estimate	O
of	O
surface	O
coordinates	O
.	O
	
This	O
amounts	O
to	O
a	O
labelling	B-Task
task	I-Task
that	O
is	O
trained	O
using	O
a	O
standard	O
cross	B-Method
-	I-Method
entropy	I-Method
loss	I-Method
.	O
	
In	O
a	O
second	O
step	O
,	O
a	O
regression	B-Method
system	I-Method
indicates	O
the	O
exact	O
coordinates	O
of	O
the	O
pixel	O
within	O
the	O
part	O
.	O
	
Since	O
the	O
human	O
body	O
has	O
a	O
complicated	O
structure	O
,	O
we	O
break	O
it	O
into	O
multiple	O
independent	O
pieces	O
and	O
parameterize	O
each	O
piece	O
using	O
a	O
local	B-Method
two	I-Method
-	I-Method
dimensional	I-Method
coordinate	I-Method
system	I-Method
,	O
that	O
identifies	O
the	O
position	O
of	O
any	O
node	O
on	O
this	O
surface	O
part	O
.	O
	
Intuitively	O
,	O
we	O
can	O
say	O
that	O
we	O
first	O
use	O
appearance	O
to	O
make	O
a	O
coarse	O
estimate	O
of	O
where	O
the	O
pixel	O
belongs	O
to	O
and	O
then	O
align	O
it	O
to	O
the	O
exact	O
position	O
through	O
some	O
small	B-Method
-	I-Method
scale	I-Method
correction	I-Method
.	O
	
Concretely	O
,	O
coordinate	B-Task
regression	I-Task
at	O
an	O
image	O
position	O
can	O
be	O
formulated	O
as	O
follows	O
:	O
	
where	O
in	O
the	O
first	O
stage	O
we	O
assign	O
position	O
to	O
the	O
body	O
part	O
that	O
has	O
highest	O
posterior	O
probability	O
,	O
as	O
calculated	O
by	O
the	O
classification	O
branch	O
,	O
and	O
in	O
the	O
second	O
stage	O
we	O
use	O
the	O
regressor	B-Method
that	O
places	O
the	O
point	O
in	O
the	O
continuous	O
coordinates	O
parametrization	O
of	O
part	O
.	O
	
In	O
our	O
case	O
,	O
can	O
take	O
25	O
values	O
(	O
one	O
is	O
background	O
)	O
,	O
meaning	O
that	O
is	O
a	O
25	O
-	O
way	O
classification	O
unit	O
,	O
and	O
we	O
train	O
24	O
regression	B-Method
functions	I-Method
,	O
each	O
of	O
which	O
provides	O
2D	O
coordinates	O
within	O
its	O
respective	O
part	O
.	O
	
While	O
training	B-Task
,	O
we	O
use	O
a	O
cross	B-Method
-	I-Method
entropy	I-Method
loss	I-Method
for	O
the	O
part	B-Task
classification	I-Task
and	O
a	O
smooth	B-Method
loss	I-Method
for	O
training	O
each	O
regressor	O
.	O
	
The	O
regression	B-Task
loss	I-Task
is	O
only	O
taken	O
into	O
account	O
for	O
a	O
part	O
if	O
the	O
pixel	O
is	O
within	O
the	O
specific	O
part	O
.	O
	
subsection	O
:	O
Region	B-Method
-	I-Method
based	I-Method
Dense	I-Method
Pose	I-Method
Regression	I-Method
	
Using	O
an	O
FCN	B-Method
makes	O
the	O
system	O
particularly	O
easy	O
to	O
train	O
,	O
but	O
loads	O
the	O
same	O
deep	B-Method
network	I-Method
with	O
too	O
many	O
tasks	O
,	O
including	O
part	B-Task
segmentation	I-Task
and	O
pixel	B-Task
localization	I-Task
,	O
while	O
at	O
the	O
same	O
time	O
requiring	O
scale	O
-	O
invariance	O
which	O
becomes	O
challenging	O
for	O
humans	O
in	O
COCO	B-Material
.	O
	
Here	O
we	O
adopt	O
the	O
region	B-Method
-	I-Method
based	I-Method
approach	I-Method
of	O
,	O
which	O
consists	O
in	O
a	O
cascade	B-Method
of	I-Method
proposing	I-Method
regions	I-Method
-	I-Method
of	I-Method
-	I-Method
interest	I-Method
(	O
ROI	O
)	O
,	O
extracting	O
region	O
-	O
adapted	O
features	O
through	O
ROI	B-Method
pooling	I-Method
and	O
feeding	O
the	O
resulting	O
features	O
into	O
a	O
region	B-Method
-	I-Method
specific	I-Method
branch	I-Method
.	O
	
Such	O
architectures	O
decompose	O
the	O
complexity	O
of	O
the	O
task	O
into	O
controllable	O
modules	O
and	O
implement	O
a	O
scale	B-Method
-	I-Method
selection	I-Method
mechanism	I-Method
through	O
ROI	B-Method
-	I-Method
pooling	I-Method
.	O
	
At	O
the	O
same	O
time	O
,	O
they	O
can	O
also	O
be	O
trained	O
jointly	O
in	O
an	O
end	O
-	O
to	O
-	O
end	O
manner	O
.	O
	
We	O
adopt	O
the	O
settings	O
introduced	O
in	O
,	O
involving	O
the	O
construction	O
of	O
Feature	B-Method
Pyramid	I-Method
Network	I-Method
features	I-Method
,	O
and	O
ROI	B-Method
-	I-Method
Align	I-Method
pooling	I-Method
,	O
which	O
have	O
been	O
shown	O
to	O
be	O
important	O
for	O
tasks	O
that	O
require	O
spatial	O
accuracy	B-Metric
.	O
	
We	O
adapt	O
this	O
architecture	O
to	O
our	O
task	O
,	O
so	O
as	O
to	O
obtain	O
dense	O
part	O
labels	O
and	O
coordinates	O
within	O
each	O
of	O
the	O
selected	O
regions	O
.	O
	
As	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
,	O
we	O
introduce	O
a	O
fully	B-Method
-	I-Method
convolutional	I-Method
network	I-Method
on	O
top	O
of	O
ROI	B-Method
-	I-Method
pooling	I-Method
that	O
is	O
entirely	O
devoted	O
to	O
these	O
two	O
tasks	O
,	O
generating	O
a	O
classification	B-Method
and	O
a	O
regression	B-Method
head	I-Method
that	O
provide	O
the	O
part	B-Task
assignment	I-Task
and	O
part	O
coordinate	O
predictions	O
,	O
as	O
in	O
DenseReg	B-Method
.	O
	
For	O
simplicity	O
,	O
we	O
use	O
the	O
exact	O
same	O
architecture	O
used	O
in	O
the	O
keypoint	O
branch	O
of	O
Mask	B-Method
-	I-Method
RCNN	I-Method
,	O
consisting	O
of	O
a	O
stack	O
of	O
8	O
alternating	B-Method
fully	I-Method
convolutional	I-Method
and	I-Method
ReLU	I-Method
layers	I-Method
with	O
512	O
channels	O
.	O
	
At	O
the	O
top	O
of	O
this	O
branch	O
we	O
have	O
the	O
same	O
classification	O
and	O
regression	O
losses	O
as	O
in	O
the	O
FCN	B-Method
baseline	I-Method
,	O
but	O
we	O
now	O
use	O
a	O
supervision	O
signal	O
that	O
is	O
cropped	O
within	O
the	O
proposed	O
region	O
.	O
	
During	O
inference	B-Task
,	O
our	O
system	O
operates	O
at	O
25fps	O
on	O
320x240	O
images	O
and	O
4	O
-	O
5fps	O
on	O
800x1100	O
images	O
using	O
a	O
GTX1080	O
graphics	O
card	O
.	O
	
subsection	O
:	O
Multi	B-Method
-	I-Method
task	I-Method
cascaded	I-Method
architectures	I-Method
	
Inspired	O
by	O
the	O
success	O
of	O
recent	O
pose	B-Method
estimation	I-Method
models	I-Method
based	O
on	O
iterative	B-Method
refinement	I-Method
we	O
experiment	O
with	O
cascaded	B-Method
architectures	I-Method
.	O
	
Cascading	B-Method
can	O
improve	O
performance	O
both	O
by	O
providing	O
context	O
to	O
the	O
following	O
stages	O
,	O
and	O
also	O
through	O
the	O
benefits	O
of	O
deep	B-Method
supervision	I-Method
.	O
	
As	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
,	O
we	O
do	O
not	O
confine	O
ourselves	O
to	O
cascading	O
within	O
a	O
single	O
task	O
,	O
but	O
also	O
exploit	O
information	O
from	O
related	O
tasks	O
,	O
such	O
as	O
keypoint	B-Task
estimation	I-Task
and	O
instance	B-Task
segmentation	I-Task
,	O
which	O
have	O
successfully	O
been	O
addressed	O
by	O
the	O
Mask	B-Method
-	I-Method
RCNN	I-Method
architecture	I-Method
.	O
	
This	O
allows	O
us	O
to	O
exploit	O
task	O
synergies	O
and	O
the	O
complementary	O
merits	O
of	O
different	O
sources	O
of	O
supervision	O
.	O
	
subsection	O
:	O
Distillation	B-Task
-	I-Task
based	I-Task
ground	I-Task
-	I-Task
truth	I-Task
interpolation	I-Task
	
Even	O
though	O
we	O
aim	O
at	O
dense	B-Task
pose	I-Task
estimation	I-Task
at	O
test	O
time	O
,	O
in	O
every	O
training	O
sample	O
we	O
annotate	O
only	O
a	O
sparse	O
subset	O
of	O
the	O
pixels	O
,	O
approximately	O
100	O
-	O
150	O
per	O
human	O
.	O
	
This	O
does	O
not	O
necessarily	O
pose	O
a	O
problem	O
during	O
training	B-Task
,	O
since	O
we	O
can	O
make	O
our	O
classification	B-Method
/	I-Method
regression	I-Method
losses	I-Method
oblivious	O
to	O
points	O
where	O
the	O
ground	O
-	O
truth	O
correspondence	O
was	O
not	O
collected	O
,	O
simply	O
by	O
not	O
including	O
them	O
in	O
the	O
summation	O
over	O
the	O
per	O
-	O
pixel	O
losses	O
.	O
	
However	O
,	O
we	O
have	O
observed	O
that	O
we	O
obtain	O
substantially	O
better	O
results	O
by	O
“	O
inpainting	O
”	O
the	O
values	O
of	O
the	O
supervision	O
signal	O
on	O
positions	O
that	O
were	O
not	O
originally	O
annotated	O
.	O
	
For	O
this	O
we	O
adopt	O
a	O
learning	B-Method
-	I-Method
based	I-Method
approach	I-Method
where	O
we	O
firstly	O
train	O
a	O
“	O
teacher	B-Method
”	I-Method
network	I-Method
(	O
depicted	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
to	O
reconstruct	O
the	O
ground	O
-	O
truth	O
values	O
wherever	O
these	O
are	O
observed	O
,	O
and	O
then	O
deploy	O
it	O
on	O
the	O
full	O
image	O
domain	O
,	O
yielding	O
a	O
dense	O
supervision	O
signal	O
.	O
	
In	O
particular	O
,	O
we	O
only	O
keep	O
the	O
network	O
	
’s	O
predictions	O
on	O
areas	O
that	O
are	O
labelled	O
as	O
foreground	O
,	O
as	O
indicated	O
by	O
the	O
part	O
masks	O
collected	O
by	O
humans	O
,	O
in	O
order	O
to	O
ignore	O
network	O
errors	O
on	O
background	O
regions	O
.	O
	
section	O
:	O
Experiments	O
	
In	O
all	O
of	O
the	O
following	O
experiments	O
,	O
we	O
assess	O
the	O
methods	O
on	O
a	O
test	O
set	O
of	O
1.5k	O
images	O
containing	O
2.3k	O
humans	O
,	O
using	O
as	O
training	O
set	O
of	O
48	O
K	O
humans	O
.	O
	
Our	O
test	O
-	O
set	O
coincides	O
with	O
the	O
COCO	O
keypoints	O
-	O
minival	O
partition	O
used	O
by	O
and	O
the	O
training	O
set	O
with	O
the	O
COCO	O
-	O
train	O
partition	O
.	O
	
We	O
are	O
currently	O
collecting	O
annotations	O
for	O
the	O
remainder	O
of	O
the	O
COCO	B-Material
dataset	I-Material
,	O
which	O
will	O
soon	O
allow	O
us	O
to	O
also	O
have	O
a	O
competition	O
mode	O
evaluation	O
.	O
	
Before	O
assessing	O
dense	B-Task
pose	I-Task
estimation	I-Task
‘	O
in	O
the	O
-	O
wild	O
’	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
,	O
we	O
start	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
with	O
the	O
more	O
restricted	O
‘	O
Single	O
-	O
Person	O
’	O
setting	O
where	O
we	O
use	O
as	O
inputs	O
images	O
cropped	O
around	O
ground	O
-	O
truth	O
boxes	O
.	O
	
This	O
factors	O
out	O
the	O
effects	O
of	O
detection	B-Task
performance	O
and	O
provides	O
us	O
with	O
a	O
controlled	O
setting	O
to	O
assess	O
the	O
usefulness	O
of	O
the	O
COCO	B-Material
-	I-Material
DensePose	I-Material
dataset	I-Material
.	O
	
subsection	O
:	O
Single	B-Task
-	I-Task
Person	I-Task
Dense	I-Task
Pose	I-Task
Estimation	I-Task
	
We	O
start	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
by	O
comparing	O
the	O
COCO	B-Material
-	I-Material
DensePose	I-Material
dataset	I-Material
to	O
other	O
sources	O
of	O
supervision	B-Method
for	O
dense	B-Task
pose	I-Task
estimation	I-Task
and	O
then	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
compare	O
the	O
performance	O
of	O
the	O
model	B-Method
-	I-Method
based	I-Method
system	I-Method
of	O
with	O
our	O
discriminatively	B-Method
-	I-Method
trained	I-Method
system	I-Method
.	O
	
Clearly	O
the	O
system	O
of	O
was	O
not	O
trained	O
with	O
the	O
same	O
amount	O
of	O
data	O
as	O
our	O
model	O
;	O
this	O
comparison	O
therefore	O
serves	O
primarily	O
to	O
show	O
the	O
merit	O
of	O
our	O
large	O
-	O
scale	O
dataset	O
for	O
discriminative	B-Task
training	I-Task
.	O
	
subsubsection	O
:	O
Manual	B-Task
supervision	I-Task
versus	O
surrogates	O
	
We	O
start	O
by	O
assessing	O
whether	O
COCO	B-Method
-	I-Method
DensePose	I-Method
improves	O
the	O
accuracy	B-Metric
of	O
dense	B-Task
pose	I-Task
estimation	I-Task
with	O
respect	O
to	O
the	O
prior	O
semi	O
-	O
automated	O
,	O
or	O
synthetic	O
supervision	O
signals	O
described	O
below	O
.	O
	
A	O
semi	B-Method
-	I-Method
automated	I-Method
method	I-Method
is	O
used	O
for	O
the	O
‘	O
Unite	O
the	O
People	O
’	O
(	O
UP	O
)	O
dataset	O
of	O
,	O
where	O
human	O
annotators	O
verified	O
the	O
results	O
of	O
fitting	O
the	O
SMPL	B-Method
3D	I-Method
deformable	I-Method
model	I-Method
to	O
2D	O
images	O
.	O
	
However	O
,	O
model	B-Method
fitting	I-Method
often	O
fails	O
in	O
the	O
presence	O
of	O
occlusions	O
,	O
or	O
extreme	O
poses	O
,	O
and	O
is	O
never	O
guaranteed	O
to	O
be	O
entirely	O
successful	O
–	O
for	O
instance	O
,	O
even	O
after	O
rejecting	O
a	O
large	O
fraction	O
of	O
the	O
fitting	O
results	O
,	O
the	O
feet	O
are	O
still	O
often	O
misaligned	O
in	O
.	O
	
This	O
both	O
decimates	O
the	O
training	O
set	O
and	O
obfuscates	O
evaluation	O
,	O
since	O
the	O
ground	O
-	O
truth	O
itself	O
may	O
have	O
systematic	O
errors	O
.	O
	
Synthetic	B-Task
ground	I-Task
-	I-Task
truth	I-Task
can	O
be	O
established	O
by	O
rendering	B-Method
images	I-Method
using	O
surface	B-Method
-	I-Method
based	I-Method
models	I-Method
.	O
	
This	O
has	O
recently	O
been	O
applied	O
to	O
human	B-Task
pose	I-Task
in	O
the	O
SURREAL	O
dataset	O
of	O
,	O
where	O
the	O
SMPL	B-Method
model	I-Method
was	O
rendered	O
with	O
the	O
CMU	O
Mocap	O
dataset	O
poses	O
.	O
	
However	O
,	O
covariate	O
shift	O
can	O
emerge	O
because	O
of	O
the	O
different	O
statistics	O
of	O
rendered	O
and	O
natural	O
images	O
.	O
	
Since	O
both	O
of	O
these	O
two	O
methods	O
use	O
the	O
same	O
SMPL	B-Method
surface	I-Method
model	I-Method
as	O
the	O
one	O
we	O
use	O
in	O
our	O
work	O
,	O
we	O
can	O
directly	O
compare	O
results	O
,	O
and	O
also	O
combine	O
datasets	O
.	O
	
We	O
render	O
our	O
dense	O
coordinates	O
and	O
our	O
dense	O
part	O
labels	O
on	O
the	O
SMPL	B-Method
model	I-Method
for	O
all	O
8514	O
images	O
of	O
UP	O
dataset	O
and	O
60k	O
SURREAL	B-Method
models	I-Method
for	O
comparison	O
.	O
	
In	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
we	O
assess	O
the	O
test	O
performance	O
of	O
ResNet	B-Method
-	I-Method
101	I-Method
FCNs	I-Method
of	I-Method
stride	I-Method
8	I-Method
trained	O
with	O
different	O
datasets	O
,	O
using	O
a	O
Deeplab	B-Method
-	I-Method
type	I-Method
architecture	I-Method
.	O
	
During	O
training	O
we	O
augment	O
samples	O
from	O
all	O
of	O
the	O
datasets	O
with	O
scaling	O
,	O
cropping	O
and	O
rotation	O
.	O
	
We	O
observe	O
that	O
the	O
surrogate	O
datasets	O
lead	O
to	O
weaker	O
performance	O
,	O
while	O
their	O
combination	O
yields	O
improved	O
results	O
.	O
	
Still	O
,	O
their	O
performance	O
is	O
substantially	O
lower	O
than	O
the	O
one	O
obtained	O
by	O
training	O
on	O
our	O
DensePose	B-Material
dataset	I-Material
,	O
while	O
combining	O
the	O
DensePose	B-Method
with	O
SURREAL	B-Method
results	O
in	O
a	O
moderate	O
drop	O
in	O
network	B-Task
performance	O
.	O
	
Based	O
on	O
these	O
results	O
we	O
rely	O
exclusively	O
on	O
the	O
DensePose	B-Material
dataset	I-Material
for	O
training	O
in	O
the	O
remaining	O
experiments	O
,	O
even	O
though	O
domain	B-Method
adaptation	I-Method
could	O
be	O
used	O
in	O
the	O
future	O
to	O
exploit	O
synthetic	O
sources	O
of	O
supervision	O
.	O
	
The	O
last	O
line	O
in	O
the	O
table	O
of	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
’	O
DensePose	O
’	O
)	O
indicates	O
an	O
additional	O
performance	O
boost	O
that	O
we	O
get	O
by	O
using	O
the	O
COCO	O
human	O
segmentation	O
masks	O
in	O
order	O
to	O
replace	O
background	O
intensities	O
with	O
an	O
average	O
intensity	O
during	O
both	O
training	O
and	O
testing	O
and	O
also	O
by	O
evaluating	O
the	O
network	O
at	O
multiple	O
scales	O
and	O
averaging	O
the	O
results	O
.	O
	
Clearly	O
,	O
the	O
results	O
with	O
other	O
methods	O
are	O
not	O
directly	O
comparable	O
,	O
since	O
we	O
are	O
using	O
additional	O
information	O
to	O
remove	O
background	O
structures	O
.	O
	
Still	O
,	O
the	O
resulting	O
predictions	O
are	O
substantially	O
closer	O
to	O
human	O
performance	O
–	O
	
we	O
therefore	O
use	O
this	O
as	O
the	O
‘	O
teacher	B-Method
network	I-Method
’	O
to	O
obtain	O
dense	O
supervision	O
for	O
the	O
experiments	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
.	O
	
subsubsection	O
:	O
FCNN	B-Method
-	I-Method
vs	I-Method
Model	I-Method
-	I-Method
based	I-Method
pose	I-Method
estimation	I-Method
	
In	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
we	O
compare	O
our	O
method	O
to	O
the	O
SMPLify	B-Method
pipeline	I-Method
of	O
,	O
which	O
fits	O
the	O
3D	B-Method
SMPL	I-Method
model	I-Method
to	O
an	O
image	O
based	O
on	O
a	O
pre	O
-	O
computed	O
set	O
of	O
landmark	O
points	O
.	O
	
We	O
use	O
the	O
code	O
provided	O
by	O
with	O
both	O
DeeperCut	B-Method
pose	I-Method
estimation	I-Method
landmark	I-Method
detector	I-Method
for	O
14	O
-	O
landmark	O
results	O
and	O
with	O
the	O
91	O
-	O
landmark	O
alternative	O
proposed	O
in	O
.	O
	
Note	O
that	O
these	O
landmark	B-Method
detectors	I-Method
were	O
trained	O
on	O
the	O
MPII	O
dataset	O
.	O
	
Since	O
the	O
whole	O
body	O
is	O
visible	O
in	O
the	O
MPII	O
dataset	O
,	O
for	O
a	O
fair	O
comparison	O
we	O
separately	O
evaluate	O
on	O
images	O
where	O
16	O
/	O
17	O
or	O
17	O
/	O
17	O
landmarks	O
are	O
visible	O
and	O
on	O
the	O
whole	O
test	O
set	O
.	O
	
We	O
observe	O
that	O
while	O
being	O
orders	O
of	O
magnitude	O
faster	O
(	O
0.04	O
-	O
0.25	O
”	O
vs	O
60	O
-	O
200	O
”	O
)	O
our	O
bottom	B-Method
-	I-Method
up	I-Method
,	O
feedforward	B-Method
method	I-Method
largely	O
outperforms	O
the	O
iterative	B-Method
,	I-Method
model	I-Method
fitting	I-Method
result	O
.	O
	
As	O
mentioned	O
above	O
,	O
this	O
difference	O
in	O
accuracy	B-Metric
indicates	O
the	O
merit	O
of	O
having	O
at	O
our	O
disposal	O
DensePose	B-Material
-	I-Material
COCO	I-Material
for	O
discriminative	B-Task
training	I-Task
.	O
	
subsection	O
:	O
Multi	B-Task
-	I-Task
Person	I-Task
Dense	I-Task
Pose	I-Task
Estimation	I-Task
	
Having	O
established	O
the	O
merit	O
of	O
the	O
DensePose	B-Material
-	I-Material
COCO	I-Material
dataset	O
,	O
we	O
now	O
turn	O
to	O
examining	O
the	O
impact	O
of	O
network	B-Method
architecture	I-Method
on	O
dense	B-Task
pose	I-Task
estimation	I-Task
in	I-Task
-	I-Task
the	I-Task
-	I-Task
wild	I-Task
.	O
	
In	O
Fig	O
.	O
	
[	O
reference	O
]	O
we	O
summarize	O
our	O
experimental	O
findings	O
using	O
the	O
same	O
RCP	B-Metric
measure	I-Metric
used	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
We	O
observe	O
firstly	O
that	O
the	O
FCN	B-Method
-	I-Method
based	I-Method
performance	O
in	O
-	O
the	O
-	O
wild	O
(	O
curve	O
‘	O
DensePose	B-Method
-	I-Method
FCN	I-Method
’	I-Method
)	O
is	O
now	O
dramatically	O
lower	O
than	O
that	O
of	O
the	O
DensePose	O
curve	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Even	O
though	O
we	O
apply	O
a	O
multi	B-Method
-	I-Method
scale	I-Method
testing	I-Method
strategy	I-Method
that	O
fuses	O
probabilities	O
from	O
multiple	O
runs	O
using	O
input	O
images	O
of	O
different	O
scale	O
,	O
the	O
FCN	B-Method
is	O
not	O
sufficiently	O
robust	O
to	O
deal	O
with	O
the	O
variability	O
in	O
object	O
scale	O
.	O
	
We	O
then	O
observe	O
in	O
curve	O
	
‘	O
	
DensePose	B-Method
-	I-Method
RCNN	I-Method
’	O
a	O
big	O
boost	O
in	O
performance	O
thanks	O
to	O
switching	O
to	O
a	O
region	B-Method
-	I-Method
based	I-Method
system	I-Method
.	O
	
The	O
networks	O
up	O
to	O
here	O
have	O
been	O
trained	O
using	O
the	O
sparse	O
set	O
of	O
points	O
that	O
have	O
been	O
manually	O
annotated	O
.	O
	
In	O
curve	O
‘	O
DensePose	B-Task
-	I-Task
RCNN	I-Task
-	I-Task
Distillation	I-Task
’	I-Task
we	O
see	O
that	O
using	O
the	O
dense	O
supervision	O
signal	O
delivered	O
by	O
our	O
DensePose	B-Method
system	I-Method
on	O
the	O
training	O
set	O
yields	O
a	O
substantial	O
improvement	O
.	O
	
Finally	O
,	O
in	O
‘	O
DensePose	B-Method
-	I-Method
RCNN	I-Method
-	I-Method
Cascade	I-Method
’	O
we	O
show	O
the	O
performance	O
achieved	O
thanks	O
to	O
the	O
introduction	O
of	O
cascading	O
:	O
Sec	O
.	O
	
[	O
reference	O
]	O
almost	O
matches	O
the	O
’	O
DensePose	O
’	O
curve	O
of	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
This	O
is	O
a	O
remarkably	O
positive	O
result	O
:	O
as	O
described	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
	
,	O
the	O
‘	O
DensePose	O
’	O
curve	O
corresponds	O
to	O
a	O
very	O
privileged	O
evaluation	O
,	O
involving	O
(	O
a	O
)	O
cropping	O
objects	O
around	O
their	O
ground	O
-	O
truth	O
boxes	O
and	O
fixing	O
their	O
scale	O
(	O
b	O
)	O
removing	O
background	O
variation	O
from	O
both	O
training	O
and	O
testing	O
,	O
by	O
using	O
ground	O
-	O
truth	O
object	O
masks	O
and	O
(	O
c	O
)	O
ensembling	O
over	O
scales	O
.	O
	
It	O
can	O
therefore	O
be	O
understood	O
as	O
an	O
upper	O
bound	O
of	O
what	O
we	O
could	O
expect	O
to	O
obtain	O
when	O
operating	O
in	O
-	O
the	O
-	O
wild	O
.	O
	
We	O
see	O
that	O
our	O
best	O
system	O
is	O
marginally	O
below	O
that	O
level	O
of	O
performance	O
,	O
which	O
clearly	O
reveals	O
the	O
power	O
of	O
the	O
three	O
modifications	O
we	O
introduce	O
,	O
namely	O
region	B-Method
-	I-Method
based	I-Method
processing	I-Method
,	O
inpainting	O
the	O
supervision	O
signal	O
,	O
and	O
cascading	B-Method
.	O
	
In	O
Table	O
[	O
reference	O
]	O
we	O
report	O
the	O
AP	B-Metric
and	O
AR	B-Metric
metrics	O
described	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
as	O
we	O
change	O
different	O
choices	O
in	O
our	O
architecture	O
.	O
	
We	O
have	O
conducted	O
experiments	O
using	O
both	O
ResNet	B-Method
-	I-Method
50	I-Method
and	I-Method
ResNet	I-Method
-	I-Method
101	I-Method
backbones	I-Method
and	O
observed	O
an	O
only	O
insignificant	O
boost	O
in	O
performance	O
with	O
the	O
larger	O
model	O
(	O
first	O
two	O
rows	O
in	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
The	O
rest	O
of	O
our	O
experiments	O
are	O
therefore	O
based	O
on	O
the	O
ResNet	B-Method
-	I-Method
50	I-Method
-	I-Method
FPN	I-Method
version	I-Method
of	I-Method
DensePose	I-Method
-	I-Method
RCNN	I-Method
.	O
	
The	O
following	O
two	O
experiments	O
shown	O
in	O
the	O
middle	O
section	O
of	O
Table	O
[	O
reference	O
]	O
indicate	O
the	O
impact	O
on	O
multi	B-Task
-	I-Task
task	I-Task
learning	I-Task
.	O
	
Augmenting	O
the	O
network	O
with	O
the	O
mask	O
or	O
keypoint	O
branches	O
yields	O
improvements	O
with	O
any	O
of	O
these	O
two	O
auxiliary	B-Task
tasks	I-Task
.	O
	
The	O
last	O
section	O
of	O
Table	O
[	O
reference	O
]	O
reports	O
improvements	O
in	O
dense	B-Task
pose	I-Task
estimation	I-Task
obtained	O
through	O
cascading	O
using	O
the	O
network	O
setup	O
from	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Incorporating	O
additional	O
guidance	O
in	O
particular	O
from	O
the	O
keypoint	O
branch	O
significantly	O
boosts	O
performance	O
.	O
	
subsection	O
:	O
Qualitative	O
Results	O
	
In	O
this	O
section	O
we	O
provide	O
additional	O
qualitative	O
results	O
to	O
further	O
demonstrate	O
the	O
performance	O
of	O
our	O
method	O
.	O
	
In	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
we	O
show	O
qualitative	O
results	O
generated	O
by	O
our	O
method	O
,	O
where	O
the	O
correspondence	O
is	O
visualized	O
in	O
terms	O
of	O
‘	O
fishnets	O
’	O
,	O
namely	O
isocontours	O
of	O
estimated	O
UV	O
coordinates	O
that	O
are	O
superimposed	O
on	O
humans	O
.	O
	
As	O
these	O
results	O
indicate	O
,	O
our	O
method	O
is	O
able	O
to	O
handle	O
large	O
amounts	O
of	O
occlusion	O
,	O
scale	O
,	O
and	O
pose	O
variation	O
,	O
while	O
also	O
successfully	O
hallucinating	O
the	O
human	O
body	O
behind	O
clothes	O
such	O
as	O
dresses	O
or	O
skirts	O
.	O
	
In	O
Fig	O
.	O
	
[	O
reference	O
]	O
we	O
demonstrate	O
a	O
simple	O
graphics	B-Task
-	I-Task
oriented	I-Task
application	I-Task
,	O
where	O
we	O
map	O
texture	O
RGB	O
intensities	O
taken	O
from	O
to	O
estimated	O
UV	O
body	O
coordinates	O
-	O
the	O
whole	O
video	O
is	O
available	O
on	O
our	O
project	O
’s	O
website	O
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
work	O
we	O
have	O
tackled	O
the	O
task	O
of	O
dense	B-Task
human	I-Task
pose	I-Task
estimation	I-Task
using	O
discriminative	B-Method
trained	I-Method
models	I-Method
.	O
	
We	O
have	O
introduced	O
COCO	B-Material
-	I-Material
DensePose	I-Material
,	O
a	O
large	O
-	O
scale	O
dataset	O
of	O
ground	O
-	O
truth	O
image	O
-	O
surface	O
correspondences	O
and	O
developed	O
novel	O
architectures	O
that	O
allow	O
us	O
to	O
recover	O
highly	O
-	O
accurate	O
dense	O
correspondences	O
between	O
images	O
and	O
the	O
body	O
surface	O
in	O
multiple	O
frames	O
per	O
second	O
.	O
	
We	O
anticipate	O
that	O
this	O
will	O
pave	O
the	O
way	O
both	O
for	O
downstream	B-Task
tasks	I-Task
in	O
augmented	B-Task
reality	I-Task
or	I-Task
graphics	I-Task
,	O
but	O
also	O
help	O
us	O
tackle	O
the	O
general	O
problem	O
of	O
associating	B-Task
images	I-Task
with	O
semantic	B-Method
3D	I-Method
object	I-Method
representations	I-Method
.	O
	
section	O
:	O
Acknowledgements	O
	
We	O
thank	O
the	O
authors	O
of	O
for	O
sharing	O
their	O
code	O
,	O
Piotr	O
Dollar	O
for	O
guidance	O
and	O
proposals	O
related	O
to	O
our	O
dataset	O
’s	O
quality	O
,	O
Tsung	O
-	O
Yi	O
Lin	O
for	O
his	O
help	O
with	O
COCO	O
-	O
related	O
issues	O
and	O
H.	O
Yiğit	O
Güler	O
for	O
his	O
help	O
with	O
backend	B-Task
development	I-Task
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Incentivizing	B-Task
Exploration	I-Task
In	O
Reinforcement	B-Task
Learning	I-Task
With	O
Deep	B-Method
Predictive	I-Method
Models	I-Method
	
Achieving	O
efficient	B-Task
and	I-Task
scalable	I-Task
exploration	I-Task
in	I-Task
complex	I-Task
domains	I-Task
poses	O
a	O
major	O
challenge	O
in	O
reinforcement	B-Task
learning	I-Task
.	O
	
While	O
Bayesian	B-Method
and	I-Method
PAC	I-Method
-	I-Method
MDP	I-Method
approaches	I-Method
to	O
the	O
exploration	B-Task
problem	I-Task
offer	O
strong	O
formal	O
guarantees	O
,	O
they	O
are	O
often	O
impractical	O
in	O
higher	O
dimensions	O
due	O
to	O
their	O
reliance	O
on	O
enumerating	O
the	O
state	O
-	O
action	O
space	O
.	O
	
Hence	O
,	O
exploration	B-Task
in	I-Task
complex	I-Task
domains	I-Task
is	O
often	O
performed	O
with	O
simple	O
epsilon	B-Method
-	I-Method
greedy	I-Method
methods	I-Method
.	O
	
In	O
this	O
paper	O
,	O
we	O
consider	O
the	O
challenging	O
Atari	B-Material
games	I-Material
domain	I-Material
,	O
which	O
requires	O
processing	O
raw	O
pixel	O
inputs	O
and	O
delayed	O
rewards	O
.	O
	
We	O
evaluate	O
several	O
more	O
sophisticated	O
exploration	B-Method
strategies	I-Method
,	O
including	O
Thompson	B-Method
sampling	I-Method
and	O
Boltzman	B-Method
exploration	I-Method
,	O
and	O
propose	O
a	O
new	O
exploration	B-Method
method	I-Method
based	O
on	O
assigning	O
exploration	O
bonuses	O
from	O
a	O
concurrently	O
learned	O
model	B-Method
of	I-Method
the	I-Method
system	I-Method
dynamics	I-Method
.	O
	
By	O
parameterizing	O
our	O
learned	O
model	O
with	O
a	O
neural	B-Method
network	I-Method
,	O
we	O
are	O
able	O
to	O
develop	O
a	O
scalable	O
and	O
efficient	O
approach	O
to	O
exploration	B-Task
bonuses	I-Task
that	O
can	O
be	O
applied	O
to	O
tasks	O
with	O
complex	O
,	O
high	O
-	O
dimensional	O
state	O
spaces	O
.	O
	
In	O
the	O
Atari	B-Material
domain	I-Material
,	O
our	O
method	O
provides	O
the	O
most	O
consistent	O
improvement	O
across	O
a	O
range	O
of	O
games	O
that	O
pose	O
a	O
major	O
challenge	O
for	O
prior	O
methods	O
.	O
	
In	O
addition	O
to	O
raw	O
game	O
-	O
scores	O
,	O
we	O
also	O
develop	O
an	O
AUC	B-Metric
-	I-Metric
100	I-Metric
metric	I-Metric
for	O
the	O
Atari	B-Material
Learning	I-Material
domain	I-Material
to	O
evaluate	O
the	O
impact	O
of	O
exploration	B-Task
on	O
this	O
benchmark	O
.	O
	
section	O
:	O
Introduction	O
	
In	O
reinforcement	B-Task
learning	I-Task
(	O
RL	B-Task
)	O
,	O
agents	O
acting	O
in	O
unknown	O
environments	O
face	O
the	O
exploration	O
versus	O
exploitation	O
tradeoff	O
.	O
	
Without	O
adequate	O
exploration	O
,	O
the	O
agent	O
might	O
fail	O
to	O
discover	O
effective	O
control	B-Method
strategies	I-Method
,	O
particularly	O
in	O
complex	O
domains	O
.	O
	
Both	O
PAC	B-Method
-	I-Method
MDP	I-Method
algorithms	I-Method
,	O
such	O
as	O
MBIE	B-Method
-	I-Method
EB	I-Method
,	O
and	O
Bayesian	B-Method
algorithms	I-Method
such	O
as	O
Bayesian	B-Method
Exploration	I-Method
Bonuses	I-Method
(	O
BEB	B-Method
)	O
have	O
managed	O
this	O
tradeoff	O
by	O
assigning	O
exploration	O
bonuses	O
to	O
novel	O
states	O
.	O
	
In	O
these	O
methods	O
,	O
the	O
novelty	O
of	O
a	O
state	O
-	O
action	O
pair	O
is	O
derived	O
from	O
the	O
number	O
of	O
times	O
an	O
agent	O
has	O
visited	O
that	O
pair	O
.	O
	
While	O
these	O
approaches	O
offer	O
strong	O
formal	O
guarantees	O
,	O
their	O
requirement	O
of	O
an	O
enumerable	B-Method
representation	I-Method
of	O
the	O
agent	O
’s	O
environment	O
renders	O
them	O
impractical	O
for	O
large	B-Task
-	I-Task
scale	I-Task
tasks	I-Task
.	O
	
As	O
such	O
,	O
exploration	B-Task
in	I-Task
large	I-Task
RL	I-Task
tasks	I-Task
is	O
still	O
most	O
often	O
performed	O
using	O
simple	O
heuristics	B-Method
,	O
such	O
as	O
the	O
epsilon	B-Method
-	I-Method
greedy	I-Method
strategy	I-Method
,	O
which	O
can	O
be	O
inadequate	O
in	O
more	O
complex	O
settings	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
evaluate	O
several	O
exploration	B-Method
strategies	I-Method
that	O
can	O
be	O
scaled	O
up	O
to	O
complex	O
tasks	O
with	O
high	O
-	O
dimensional	O
inputs	O
.	O
	
Our	O
results	O
show	O
that	O
Boltzman	B-Method
exploration	I-Method
and	O
Thompson	B-Method
sampling	I-Method
significantly	O
improve	O
on	O
the	O
naïve	B-Method
epsilon	I-Method
-	I-Method
greedy	I-Method
strategy	I-Method
.	O
	
However	O
,	O
we	O
show	O
that	O
the	O
biggest	O
and	O
most	O
consistent	O
improvement	O
can	O
be	O
achieved	O
by	O
assigning	O
exploration	O
bonuses	O
based	O
on	O
a	O
learned	O
model	O
of	O
the	O
system	B-Method
dynamics	I-Method
with	O
learned	B-Method
representations	I-Method
.	O
	
To	O
that	O
end	O
,	O
we	O
describe	O
a	O
method	O
that	O
learns	O
a	O
state	B-Method
representation	I-Method
from	O
observations	O
,	O
trains	O
a	O
dynamics	B-Method
model	I-Method
using	O
this	O
representation	O
concurrently	O
with	O
the	O
policy	B-Method
,	O
and	O
uses	O
the	O
misprediction	O
error	O
in	O
this	O
model	O
to	O
asses	O
the	O
novelty	O
of	O
each	O
state	O
.	O
	
Novel	O
states	O
are	O
expected	O
to	O
disagree	O
more	O
strongly	O
with	O
the	O
model	O
than	O
those	O
states	O
that	O
have	O
been	O
visited	O
frequently	O
in	O
the	O
past	O
,	O
and	O
assigning	O
exploration	O
bonuses	O
based	O
on	O
this	O
disagreement	O
can	O
produce	O
rapid	O
and	O
effective	O
exploration	B-Task
.	O
	
Using	O
learned	O
model	B-Method
dynamics	I-Method
to	O
assess	O
a	O
state	O
’s	O
novelty	O
presents	O
several	O
challenges	O
.	O
	
Capturing	O
an	O
adequate	O
representation	O
of	O
the	O
agent	O
’s	O
environment	O
for	O
use	O
in	O
dynamics	B-Task
predictions	I-Task
can	O
be	O
accomplished	O
by	O
training	O
a	O
model	O
to	O
predict	O
the	O
next	O
state	O
from	O
the	O
previous	O
ground	O
-	O
truth	O
state	O
-	O
action	O
pair	O
.	O
	
However	O
,	O
one	O
would	O
not	O
expect	O
pixel	O
intensity	O
values	O
to	O
adequately	O
capture	O
the	O
salient	O
features	O
of	O
a	O
given	O
state	O
-	O
space	O
.	O
	
To	O
provide	O
a	O
more	O
suitable	O
representation	O
of	O
the	O
system	O
’s	O
state	O
space	O
,	O
we	O
propose	O
a	O
method	O
for	O
encoding	O
the	O
state	O
space	O
into	O
lower	O
dimensional	O
domains	O
.	O
	
To	O
achieve	O
sufficient	O
generality	O
and	O
scalability	O
,	O
we	O
modeled	O
the	O
system	O
	
’s	O
dynamics	O
with	O
a	O
deep	B-Method
neural	I-Method
network	I-Method
.	O
	
This	O
allows	O
for	O
on	O
-	O
the	O
-	O
fly	O
learning	O
of	O
a	O
model	B-Method
representation	I-Method
that	O
can	O
easily	O
be	O
trained	O
in	O
parallel	O
to	O
learning	O
a	O
policy	B-Method
.	O
	
Our	O
main	O
contribution	O
is	O
a	O
scalable	O
and	O
efficient	O
method	O
for	O
assigning	B-Task
exploration	I-Task
bonuses	I-Task
in	O
large	B-Task
RL	I-Task
problems	I-Task
with	O
complex	O
observations	O
,	O
as	O
well	O
as	O
an	O
extensive	O
empirical	O
evaluation	O
of	O
this	O
approach	O
and	O
other	O
simple	O
alternative	O
strategies	O
,	O
such	O
as	O
Boltzman	B-Method
exploration	I-Method
and	O
Thompson	B-Method
sampling	I-Method
.	O
	
Our	O
approach	O
assigns	O
model	B-Method
-	I-Method
based	I-Method
exploration	I-Method
bonuses	I-Method
from	O
learned	O
representations	O
and	O
dynamics	O
,	O
using	O
only	O
the	O
observations	O
and	O
actions	O
.	O
	
It	O
can	O
scale	O
to	O
large	O
problems	O
where	O
Bayesian	B-Method
approaches	I-Method
to	O
exploration	B-Task
become	O
impractical	O
,	O
and	O
we	O
show	O
that	O
it	O
achieves	O
significant	O
improvement	O
in	O
learning	B-Metric
speed	I-Metric
on	O
the	O
task	O
of	O
learning	B-Task
to	O
play	O
Atari	B-Task
games	I-Task
from	O
raw	O
images	O
.	O
	
Our	O
approach	O
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
a	O
number	O
of	O
games	O
,	O
and	O
achieves	O
particularly	O
large	O
improvements	O
for	O
games	O
on	O
which	O
human	O
players	O
strongly	O
outperform	O
prior	O
methods	O
.	O
	
Aside	O
from	O
achieving	O
a	O
high	O
final	O
score	O
,	O
our	O
method	O
also	O
achieves	O
substantially	O
faster	O
learning	B-Task
.	O
	
To	O
evaluate	O
the	O
speed	O
of	O
the	O
learning	B-Method
process	I-Method
,	O
we	O
propose	O
the	O
AUC	B-Metric
-	I-Metric
100	I-Metric
benchmark	I-Metric
to	O
evaluate	O
learning	B-Task
progress	I-Task
on	O
the	O
Atari	B-Material
domain	I-Material
.	O
	
section	O
:	O
Preliminaries	O
	
We	O
consider	O
an	O
infinite	B-Task
-	I-Task
horizon	I-Task
discounted	I-Task
Markov	I-Task
decision	I-Task
process	I-Task
(	I-Task
MDP	I-Task
)	I-Task
,	O
defined	O
by	O
the	O
tuple	O
,	O
where	O
is	O
a	O
finite	O
set	O
of	O
states	O
,	O
a	O
finite	O
set	O
of	O
actions	O
,	O
the	O
transition	O
probability	O
distribution	O
,	O
the	O
reward	O
function	O
,	O
an	O
initial	O
state	O
distribution	O
,	O
and	O
the	O
discount	O
factor	O
.	O
	
We	O
are	O
interested	O
in	O
finding	O
a	O
policy	O
that	O
maximizes	O
the	O
expected	O
reward	O
over	O
all	O
time	O
.	O
	
This	O
maximization	O
can	O
be	O
accomplished	O
using	O
a	O
variety	O
of	O
reinforcement	B-Method
learning	I-Method
algorithms	I-Method
.	O
	
In	O
this	O
work	O
,	O
we	O
are	O
concerned	O
with	O
online	B-Task
reinforcement	I-Task
learning	I-Task
wherein	O
the	O
algorithm	O
receives	O
a	O
tuple	O
at	O
each	O
step	O
.	O
	
Here	O
,	O
is	O
the	O
previous	O
state	O
,	O
is	O
the	O
previous	O
action	O
,	O
is	O
the	O
new	O
state	O
,	O
and	O
is	O
the	O
reward	O
collected	O
as	O
a	O
result	O
of	O
this	O
transition	O
.	O
	
The	O
reinforcement	B-Method
learning	I-Method
algorithm	I-Method
must	O
use	O
this	O
tuple	O
to	O
update	O
its	O
policy	O
and	O
maximize	O
long	O
-	O
term	O
reward	O
and	O
then	O
choose	O
the	O
new	O
action	O
.	O
	
It	O
is	O
often	O
insufficient	O
to	O
simply	O
choose	O
the	O
best	O
action	O
based	O
on	O
previous	O
experience	O
,	O
since	O
this	O
strategy	O
can	O
quickly	O
fall	O
into	O
a	O
local	O
optimum	O
.	O
	
Instead	O
,	O
the	O
learning	B-Method
algorithm	I-Method
must	O
perform	O
exploration	B-Task
.	O
	
Prior	O
work	O
has	O
suggested	O
methods	O
that	O
address	O
the	O
exploration	B-Task
problem	I-Task
by	O
acting	O
with	O
“	O
optimism	O
under	O
uncertainty	O
.	O
	
”	O
	
If	O
one	O
assumes	O
that	O
the	O
reinforcement	B-Method
learning	I-Method
algorithm	I-Method
will	O
tend	O
to	O
choose	O
the	O
best	O
action	O
,	O
it	O
can	O
be	O
encouraged	O
to	O
visit	O
state	O
-	O
action	O
pairs	O
that	O
it	O
has	O
not	O
frequently	O
seen	O
by	O
augmenting	O
the	O
reward	O
function	O
to	O
deliver	O
a	O
bonus	O
for	O
visiting	O
novel	O
states	O
.	O
	
This	O
is	O
accomplished	O
with	O
the	O
augmented	O
reward	O
function	O
where	O
is	O
a	O
novelty	O
function	O
designed	O
to	O
capture	O
the	O
novelty	O
of	O
a	O
given	O
state	O
-	O
action	O
pair	O
.	O
	
Prior	O
work	O
has	O
suggested	O
a	O
variety	O
of	O
different	O
novelty	O
functions	O
e.g.	O
,	O
based	O
on	O
state	O
visitation	O
frequency	O
.	O
	
While	O
such	O
methods	O
offer	O
a	O
number	O
of	O
appealing	O
guarantees	O
,	O
such	O
as	O
near	B-Task
-	I-Task
Bayesian	I-Task
exploration	I-Task
in	O
polynomial	O
time	O
,	O
they	O
require	O
a	O
concise	O
,	O
often	O
discrete	B-Method
representation	I-Method
of	O
the	O
agent	O
’s	O
state	O
-	O
action	O
space	O
to	O
measure	O
state	O
visitation	O
frequencies	O
.	O
	
In	O
our	O
approach	O
,	O
we	O
will	O
employ	O
function	B-Method
approximation	I-Method
and	O
representation	B-Method
learning	I-Method
to	O
devise	O
an	O
alternative	O
to	O
these	O
requirements	O
.	O
	
section	O
:	O
Model	B-Method
Learning	I-Method
For	O
Exploration	B-Task
Bonuses	I-Task
	
We	O
would	O
like	O
to	O
encourage	O
agent	B-Task
exploration	I-Task
by	O
giving	O
the	O
agent	O
exploration	O
bonuses	O
for	O
visiting	O
novel	O
states	O
.	O
	
Identifying	O
states	O
as	O
novel	O
requires	O
we	O
supply	O
some	O
representation	O
of	O
the	O
agent	O
’s	O
state	O
space	O
,	O
as	O
well	O
as	O
a	O
mechanism	O
to	O
use	O
this	O
representation	O
to	O
assess	O
novelty	O
.	O
	
Unsupervised	B-Method
learning	I-Method
methods	I-Method
offer	O
one	O
promising	O
avenue	O
for	O
acquiring	O
a	O
concise	B-Task
representation	I-Task
of	I-Task
the	I-Task
state	I-Task
with	O
a	O
good	O
similarity	B-Metric
metric	I-Metric
.	O
	
This	O
can	O
be	O
accomplished	O
using	O
dimensionality	B-Method
reduction	I-Method
,	O
clustering	B-Method
,	O
or	O
graph	B-Method
-	I-Method
based	I-Method
techniques	I-Method
.	O
	
In	O
our	O
work	O
,	O
we	O
draw	O
on	O
recent	O
developments	O
in	O
representation	B-Task
learning	I-Task
with	O
neural	B-Method
networks	I-Method
,	O
as	O
discussed	O
in	O
the	O
following	O
section	O
.	O
	
However	O
,	O
even	O
with	O
a	O
good	O
learned	O
state	B-Method
representation	I-Method
,	O
maintaining	O
a	O
table	O
of	O
visitation	O
frequencies	O
becomes	O
impractical	O
for	O
complex	O
tasks	O
.	O
	
Instead	O
,	O
we	O
learn	O
a	O
model	O
of	O
the	O
task	O
dynamics	O
that	O
can	O
be	O
used	O
to	O
assess	O
the	O
novelty	O
of	O
a	O
new	O
state	O
.	O
	
Formally	O
,	O
let	O
denote	O
the	O
encoding	O
of	O
the	O
state	O
,	O
and	O
let	O
be	O
a	O
dynamics	B-Method
predictor	I-Method
parameterized	O
by	O
.	O
	
takes	O
an	O
encoded	O
version	O
of	O
a	O
state	O
at	O
time	O
and	O
the	O
agent	O
’s	O
action	O
at	O
time	O
and	O
attempts	O
to	O
predict	O
an	O
encoded	O
version	O
of	O
the	O
agent	O
	
’s	O
state	O
at	O
time	O
.	O
	
The	O
parameterization	O
of	O
is	O
discussed	O
further	O
in	O
the	O
next	O
section	O
.	O
	
For	O
each	O
state	O
transition	O
,	O
we	O
can	O
attempt	O
to	O
predict	O
from	O
using	O
our	O
predictive	B-Method
model	I-Method
.	O
	
This	O
prediction	O
will	O
have	O
some	O
error	O
Let	O
,	O
the	O
normalized	B-Metric
prediction	I-Metric
error	I-Metric
at	O
time	O
,	O
be	O
given	O
by	O
.	O
	
We	O
can	O
assign	O
a	O
novelty	O
function	O
to	O
via	O
where	O
is	O
a	O
decay	O
constant	O
.	O
	
We	O
can	O
now	O
realize	O
our	O
augmented	B-Method
reward	I-Method
function	I-Method
as	O
This	O
approach	O
is	O
motivated	O
by	O
the	O
idea	O
that	O
,	O
as	O
our	O
ability	O
to	O
model	O
the	O
dynamics	O
of	O
a	O
particular	O
state	O
-	O
action	O
pair	O
improves	O
,	O
we	O
have	O
come	O
to	O
understand	O
the	O
state	O
better	O
and	O
hence	O
its	O
novelty	O
is	O
lower	O
.	O
	
When	O
we	O
do	O
n’t	O
understand	O
the	O
state	O
-	O
action	O
pair	O
well	O
enough	O
to	O
make	O
accurate	O
predictions	O
,	O
we	O
assume	O
that	O
more	O
knowledge	O
about	O
that	O
particular	O
area	O
of	O
the	O
model	O
dynamics	O
is	O
needed	O
and	O
hence	O
a	O
higher	O
novelty	B-Metric
measure	I-Metric
is	O
assigned	O
.	O
	
Using	O
learned	O
model	B-Method
dynamics	I-Method
to	O
assign	O
novelty	O
functions	O
allows	O
us	O
to	O
address	O
the	O
exploration	B-Task
versus	I-Task
exploitation	I-Task
problem	I-Task
in	O
a	O
non	O
-	O
greedy	O
way	O
.	O
	
With	O
an	O
appropriate	O
representation	O
,	O
even	O
when	O
we	O
encounter	O
a	O
new	O
state	O
-	O
action	O
pair	O
,	O
we	O
expect	O
to	O
be	O
accurate	O
so	O
long	O
as	O
enough	O
similar	O
state	O
-	O
action	O
pairs	O
have	O
been	O
encountered	O
.	O
	
[	O
tb	O
]	O
Reinforcement	B-Method
learning	I-Method
with	O
model	B-Method
prediction	I-Method
exploration	I-Method
bonuses	O
{	O
algorithmic}	O
[	O
1	O
]	O
=	O
	
maxe1	O
,	O
EpochLength	O
,	O
β	O
,	O
C	O
t	O
in	O
T	O
	
(	O
st	O
,	O
at	O
,	O
s	O
+	O
t1	O
,	O
⁢R	O
(	O
st	O
,	O
at	O
)	O
)	O
	
the	O
observations	O
to	O
obtain	O
⁢σ	O
(	O
st	O
)	O
and	O
⁢σ	O
(	O
s	O
+	O
t1	O
)	O
	
=	O
⁢e	O
(	O
st	O
,	O
at	O
)	O
∥	O
-	O
⁢σ	O
(	O
s	O
+	O
t1	O
)	O
⁢Mϕ	O
(	O
⁢σ	O
(	O
st	O
),	O
at	O
)	O
∥22	O
and	O
=	O
⁢¯e	O
(	O
st	O
,	O
at	O
)	O
⁢e	O
(	O
st	O
,	O
at	O
)	O
maxe	O
.	O
	
=	O
⁢R⁢Bonus	O
(	O
st	O
,	O
at	O
)+	O
⁢R	O
(	O
s	O
,	O
	
a	O
)	O
⁢β	O
(	O
⁢¯et	O
(	O
st	O
,	O
at	O
)	O
∗tC	O
)	O
>	O
⁢e	O
(	O
st	O
,	O
at	O
)	O
maxe	O
	
(	O
st	O
,	O
at	O
,	O
R⁢bonus	O
)	O
in	O
a	O
memory	O
bank	O
Ω.	O
Ω	O
to	O
the	O
reinforcement	B-Method
learning	I-Method
algorithm	I-Method
to	O
update	O
π	O
.	O
	
tmodEpochLength==0	O
	
Ω	O
to	O
update	O
M.	O
update	O
σ	O
.	O
	
optimized	B-Method
policy	I-Method
	
π	O
	
Our	O
model	B-Method
-	I-Method
based	I-Method
exploration	I-Method
bonuses	I-Method
can	O
be	O
incorporated	O
into	O
any	O
online	B-Method
reinforcement	I-Method
learning	I-Method
algorithm	I-Method
that	O
updates	O
the	O
policy	O
based	O
on	O
state	O
,	O
action	O
,	O
reward	O
tuples	O
of	O
the	O
form	O
,	O
such	O
as	O
Q	B-Method
-	I-Method
learning	I-Method
or	O
actor	B-Method
-	I-Method
critic	I-Method
algorithms	I-Method
.	O
	
Our	O
method	O
is	O
summarized	O
in	O
Algorithm	O
[	O
reference	O
]	O
.	O
	
At	O
each	O
step	O
,	O
we	O
receive	O
a	O
tuple	O
and	O
compute	O
the	O
Euclidean	O
distance	O
between	O
the	O
encoded	O
state	O
to	O
the	O
prediction	O
made	O
by	O
our	O
model	O
.	O
	
This	O
is	O
used	O
to	O
compute	O
the	O
exploration	O
-	O
augmented	O
reward	O
using	O
Equation	O
(	O
[	O
reference	O
]	O
)	O
.	O
	
The	O
tuples	O
are	O
stored	O
in	O
a	O
memory	O
bank	O
at	O
the	O
end	O
of	O
every	O
step	O
.	O
	
Every	O
step	O
,	O
the	O
policy	O
is	O
updated	O
.	O
	
Once	O
per	O
epoch	O
,	O
corresponding	O
to	O
50000	O
observations	O
in	O
our	O
implementation	O
,	O
the	O
dynamics	B-Method
model	I-Method
is	O
updated	O
to	O
improve	O
its	O
accuracy	B-Metric
.	O
	
If	O
desired	O
,	O
the	O
representation	B-Method
encoder	I-Method
can	O
also	O
be	O
updated	O
at	O
this	O
time	O
.	O
	
We	O
found	O
that	O
retraining	O
once	O
every	O
5	O
epochs	O
to	O
be	O
sufficient	O
.	O
	
This	O
approach	O
is	O
modular	O
and	O
compatible	O
with	O
any	O
representation	B-Method
of	I-Method
and	I-Method
,	O
as	O
well	O
as	O
any	O
reinforcement	B-Method
learning	I-Method
method	I-Method
that	O
updates	O
its	O
policy	O
based	O
on	O
a	O
continuous	O
stream	O
of	O
observation	O
,	O
action	O
,	O
reward	O
tuples	O
.	O
	
Incorporating	O
exploration	O
bonuses	O
does	O
make	O
the	O
reinforcement	B-Task
learning	I-Task
task	I-Task
nonstationary	O
,	O
though	O
we	O
did	O
not	O
find	O
this	O
to	O
be	O
a	O
major	O
issue	O
in	O
practice	O
,	O
as	O
shown	O
in	O
our	O
experimental	O
evaluation	O
.	O
	
In	O
the	O
following	O
section	O
,	O
we	O
discuss	O
the	O
particular	O
choice	O
for	O
and	O
that	O
we	O
use	O
for	O
learning	B-Method
policies	I-Method
for	O
playing	O
Atari	B-Task
games	I-Task
from	O
raw	O
images	O
.	O
	
section	O
:	O
Deep	B-Method
Learning	I-Method
Architectures	I-Method
	
Though	O
the	O
dynamics	B-Method
model	I-Method
and	O
the	O
encoder	B-Method
from	O
the	O
previous	O
section	O
can	O
be	O
parametrized	O
by	O
any	O
appropriate	O
method	O
,	O
we	O
found	O
that	O
using	O
deep	B-Method
neural	I-Method
networks	I-Method
for	O
both	O
achieved	O
good	O
empirical	O
results	O
on	O
the	O
Atari	B-Material
games	I-Material
benchmark	I-Material
.	O
	
In	O
this	O
section	O
,	O
we	O
discuss	O
the	O
particular	O
networks	O
used	O
in	O
our	O
implementation	O
.	O
	
subsection	O
:	O
Autoencoders	B-Method
	
The	O
most	O
direct	O
way	O
of	O
learning	O
a	O
dynamics	B-Method
model	I-Method
is	O
to	O
directly	O
predict	O
the	O
state	O
at	O
the	O
next	O
time	O
step	O
,	O
which	O
in	O
the	O
Atari	B-Material
games	I-Material
benchmark	I-Material
corresponds	O
to	O
the	O
next	O
frame	O
’s	O
pixel	O
intensity	O
values	O
.	O
	
However	O
,	O
directly	O
predicting	O
these	O
pixel	O
intensity	O
values	O
is	O
unsatisfactory	O
,	O
since	O
we	O
do	O
not	O
expect	O
pixel	O
intensity	O
to	O
capture	O
the	O
salient	O
features	O
of	O
the	O
environment	O
in	O
a	O
robust	O
way	O
.	O
	
In	O
our	O
experiments	O
,	O
a	O
dynamics	B-Method
model	I-Method
trained	O
to	O
predict	O
raw	O
frames	O
exhibited	O
extremely	O
poor	O
behavior	O
,	O
assigning	O
exploration	O
bonuses	O
in	O
near	O
equality	O
at	O
most	O
time	O
steps	O
,	O
as	O
discussed	O
in	O
our	O
experimental	O
results	O
section	O
.	O
	
To	O
overcome	O
these	O
difficulties	O
,	O
we	O
seek	O
a	O
function	O
which	O
encodes	O
a	O
lower	B-Method
dimensional	I-Method
representation	I-Method
of	I-Method
the	I-Method
state	I-Method
.	O
	
For	O
the	O
task	O
of	O
representing	B-Task
Atari	I-Task
frames	I-Task
,	O
we	O
found	O
that	O
an	O
autoencoder	B-Method
could	O
be	O
used	O
to	O
successfully	O
obtain	O
an	O
encoding	B-Method
function	I-Method
and	O
achieve	O
dimensionality	B-Task
reduction	I-Task
and	O
feature	B-Task
extraction	I-Task
.	O
	
Our	O
autoencoder	B-Method
has	O
8	O
hidden	O
layers	O
,	O
followed	O
by	O
a	O
Euclidean	B-Method
loss	I-Method
layer	I-Method
,	O
which	O
computes	O
the	O
distance	O
between	O
the	O
output	O
features	O
and	O
the	O
original	O
input	O
image	O
.	O
	
The	O
hidden	O
layers	O
are	O
reduced	O
in	O
dimension	O
until	O
maximal	O
compression	O
occurs	O
with	O
128	O
units	O
.	O
	
After	O
this	O
,	O
the	O
activations	O
are	O
decoded	O
by	O
passing	O
through	O
hidden	B-Method
layers	I-Method
with	O
increasingly	O
large	O
size	O
.	O
	
We	O
train	O
the	O
network	O
on	O
a	O
set	O
of	O
250	O
,	O
000	O
images	O
and	O
test	O
on	O
a	O
further	O
set	O
of	O
25	O
,	O
000	O
images	O
.	O
	
We	O
compared	O
two	O
separate	O
methodologies	O
for	O
capturing	O
these	O
images	O
.	O
	
Static	O
AE	O
:	O
	
A	O
random	B-Method
agent	I-Method
plays	O
for	O
enough	O
time	O
to	O
collect	O
the	O
required	O
images	O
.	O
	
The	O
auto	B-Method
-	I-Method
encoder	I-Method
is	O
trained	O
offline	O
before	O
the	O
policy	B-Method
learning	I-Method
algorithm	I-Method
begins	O
.	O
	
Dynamic	B-Task
AE	I-Task
:	O
	
Initialize	O
with	O
an	O
epsilon	B-Method
-	I-Method
greedy	I-Method
strategy	I-Method
and	O
collect	O
images	O
and	O
actions	O
while	O
the	O
agent	O
acts	O
under	O
the	O
policy	B-Method
learning	I-Method
algorithm	I-Method
.	O
	
After	O
5	O
epochs	O
,	O
train	O
the	O
auto	B-Method
encoder	I-Method
from	O
this	O
data	O
.	O
	
Continue	O
to	O
collect	O
data	O
and	O
periodically	O
retrain	O
the	O
auto	B-Method
encoder	I-Method
in	O
parallel	O
with	O
the	O
policy	B-Method
training	I-Method
algorithm	I-Method
.	O
	
We	O
found	O
that	O
the	O
reconstructed	O
input	O
achieves	O
a	O
small	O
but	O
non	O
-	O
trivial	O
residual	O
on	O
the	O
test	O
set	O
regardless	O
of	O
which	O
auto	B-Method
encoder	I-Method
training	I-Method
technique	I-Method
is	O
utilized	O
,	O
suggesting	O
that	O
in	O
both	O
cases	O
it	O
learns	O
underlying	O
features	O
of	O
the	O
state	O
space	O
while	O
avoiding	O
overfitting	O
.	O
	
To	O
obtain	O
a	O
lower	B-Method
dimensional	I-Method
representation	I-Method
of	O
the	O
agent	O
’s	O
state	O
space	O
,	O
a	O
snapshot	O
of	O
the	O
network	O
’s	O
first	O
six	O
layers	O
is	O
saved	O
.	O
	
The	O
sixth	O
layer	O
’s	O
output	O
(	O
circled	O
in	O
figure	O
one	O
)	O
is	O
then	O
utilized	O
as	O
an	O
encoding	O
for	O
the	O
original	O
state	O
space	O
.	O
	
That	O
is	O
,	O
we	O
construct	O
an	O
encoding	O
by	O
running	O
through	O
the	O
first	O
six	O
hidden	O
layers	O
of	O
our	O
autoencoder	B-Method
and	O
then	O
taking	O
the	O
sixth	O
layers	O
output	O
to	O
be	O
.	O
	
In	O
practice	O
,	O
we	O
found	O
that	O
using	O
the	O
sixth	O
layer	O
’s	O
output	O
(	O
rather	O
than	O
the	O
bottleneck	O
at	O
the	O
fifth	O
layer	O
)	O
obtained	O
the	O
best	O
model	O
learning	O
results	O
.	O
	
See	O
the	O
appendix	O
for	O
further	O
discussion	O
on	O
this	O
result	O
.	O
	
subsection	O
:	O
Model	B-Method
Learning	I-Method
Architecture	I-Method
	
Equipped	O
with	O
an	O
encoding	O
,	O
we	O
can	O
now	O
consider	O
the	O
task	O
of	O
predicting	B-Task
model	I-Task
dynamics	I-Task
.	O
	
For	O
this	O
task	O
,	O
a	O
much	O
simpler	O
two	B-Method
layer	I-Method
neural	I-Method
network	I-Method
suffices	O
.	O
takes	O
as	O
input	O
the	O
encoded	O
version	O
of	O
a	O
state	O
at	O
time	O
along	O
with	O
the	O
agent	O
’s	O
action	O
and	O
seeks	O
to	O
predict	O
the	O
encoded	O
next	O
frame	O
.	O
	
Loss	B-Method
is	O
computed	O
via	O
a	O
Euclidean	B-Method
loss	I-Method
layer	I-Method
regressing	I-Method
on	O
the	O
ground	O
truth	O
.	O
	
We	O
find	O
that	O
this	O
model	O
initially	O
learns	O
a	O
representation	O
close	O
to	O
the	O
identity	O
function	O
and	O
consequently	O
the	O
loss	O
residual	O
is	O
similar	O
for	O
most	O
state	O
-	O
action	O
pairs	O
.	O
	
However	O
,	O
after	O
approximately	O
5	O
epochs	O
,	O
it	O
begins	O
to	O
learn	O
more	O
complex	O
dynamics	O
and	O
consequently	O
better	O
identify	O
novel	O
states	O
.	O
	
We	O
evaluate	O
the	O
quality	O
of	O
the	O
learned	O
model	O
in	O
the	O
appendix	O
.	O
	
section	O
:	O
Related	O
Work	O
	
Exploration	B-Task
is	O
an	O
intensely	O
studied	O
area	O
of	O
reinforcement	B-Task
learning	I-Task
.	O
	
Many	O
of	O
the	O
pioneering	O
algorithms	O
in	O
this	O
area	O
,	O
such	O
as	O
and	O
,	O
achieve	O
efficient	O
exploration	B-Task
that	O
scales	O
polynomially	O
with	O
the	O
number	O
of	O
parameters	O
in	O
the	O
agent	O
’s	O
state	O
space	O
(	O
see	O
also	O
)	O
.	O
	
However	O
,	O
as	O
the	O
size	O
of	O
state	O
spaces	O
increases	O
,	O
these	O
methods	O
quickly	O
become	O
intractable	O
.	O
	
A	O
number	O
of	O
prior	O
methods	O
also	O
examine	O
various	O
techniques	O
for	O
using	O
models	B-Method
and	O
prediction	B-Method
to	O
incentivize	B-Task
exploration	I-Task
.	O
	
However	O
,	O
such	O
methods	O
typically	O
operate	O
directly	O
on	O
the	O
transition	O
matrix	O
of	O
a	O
discrete	B-Method
MDP	I-Method
,	O
and	O
do	O
not	O
provide	O
for	O
a	O
straightforward	O
extension	O
to	O
very	O
large	B-Task
or	I-Task
continuous	I-Task
spaces	I-Task
,	O
where	O
function	B-Method
approximation	I-Method
is	O
required	O
.	O
	
A	O
number	O
of	O
prior	O
methods	O
have	O
also	O
been	O
proposed	O
to	O
incorporate	O
domain	O
-	O
specific	O
factors	O
to	O
improve	O
exploration	B-Task
.	O
	
Doshi	O
-	O
Velez	O
et	O
al	O
.	O
proposed	O
incorporating	O
priors	O
into	O
policy	B-Task
optimization	I-Task
,	O
while	O
Lang	O
et	O
al	O
.	O
developed	O
a	O
method	O
specific	O
to	O
relational	B-Task
domains	I-Task
.	O
	
Finally	O
,	O
Schmidhuber	O
et	O
al	O
.	O
have	O
developed	O
a	O
curiosity	B-Method
driven	I-Method
approach	I-Method
to	O
exploration	B-Task
which	O
uses	O
model	B-Method
predictors	I-Method
to	O
aid	O
in	O
control	B-Task
.	O
	
Several	O
exploration	B-Method
techniques	I-Method
have	O
been	O
proposed	O
that	O
can	O
extend	O
more	O
readily	O
to	O
large	O
state	O
spaces	O
.	O
	
Among	O
these	O
,	O
methods	O
such	O
as	O
C	B-Method
-	I-Method
PACE	I-Method
and	O
metric	B-Method
-	I-Method
require	O
a	O
good	O
metric	O
on	O
the	O
state	O
space	O
that	O
satisfies	O
the	O
assumptions	O
of	O
the	O
algorithm	O
.	O
	
The	O
corresponding	O
representation	B-Task
learning	I-Task
issue	I-Task
has	O
some	O
parallels	O
to	O
the	O
representation	B-Task
problem	I-Task
that	O
we	O
address	O
by	O
using	O
an	O
autoecoder	B-Method
,	O
but	O
it	O
is	O
unclear	O
how	O
the	O
appropriate	O
metric	O
for	O
the	O
prior	O
methods	O
can	O
be	O
acquired	O
automatically	O
on	O
tasks	O
with	O
raw	O
sensory	O
input	O
,	O
such	O
as	O
the	O
Atari	B-Task
games	I-Task
in	O
our	O
experimental	O
evaluation	O
.	O
	
Methods	O
based	O
on	O
Monte	B-Method
-	I-Method
Carlo	I-Method
tree	I-Method
search	I-Method
can	O
also	O
scale	O
gracefully	O
to	O
complex	O
domains	O
,	O
and	O
indeed	O
previous	O
work	O
has	O
applied	O
such	O
techniques	O
to	O
the	O
task	O
of	O
playing	O
Atari	B-Task
games	I-Task
from	O
screen	O
images	O
.	O
	
However	O
,	O
this	O
approach	O
is	O
computationally	O
very	O
intensive	O
,	O
and	O
requires	O
access	O
to	O
a	O
generative	B-Method
model	I-Method
of	O
the	O
system	O
in	O
order	O
to	O
perform	O
the	O
tree	B-Task
search	I-Task
,	O
which	O
is	O
not	O
always	O
available	O
in	O
online	B-Method
reinforcement	I-Method
learning	I-Method
.	O
	
On	O
the	O
other	O
hand	O
,	O
our	O
method	O
readily	O
integrates	O
into	O
any	O
online	B-Method
reinforcement	I-Method
learning	I-Method
algorithm	I-Method
.	O
	
Finally	O
,	O
several	O
recent	O
papers	O
have	O
focused	O
on	O
driving	O
the	O
Q	O
value	O
higher	O
.	O
	
In	O
,	O
the	O
authors	O
use	O
network	B-Method
dropout	I-Method
to	O
perform	O
Thompson	B-Method
sampling	I-Method
.	O
	
In	O
Boltzman	B-Task
exploration	I-Task
,	O
a	O
positive	O
probability	O
is	O
assigned	O
to	O
any	O
possible	O
action	O
according	O
to	O
its	O
expected	O
utility	O
and	O
according	O
to	O
a	O
temperature	O
parameter	O
.	O
	
Both	O
of	O
these	O
methods	O
focus	O
on	O
controlling	O
Q	O
values	O
rather	O
than	O
model	B-Method
-	I-Method
based	I-Method
exploration	I-Method
.	O
	
A	O
comparison	O
to	O
both	O
is	O
provided	O
in	O
the	O
next	O
section	O
.	O
	
section	O
:	O
Experimental	O
Results	O
	
We	O
evaluate	O
our	O
approach	O
on	O
14	O
games	O
from	O
the	O
Arcade	B-Task
Learning	I-Task
Environment	I-Task
.	O
	
The	O
task	O
consists	O
of	O
choosing	O
actions	O
in	O
an	O
Atari	B-Method
emulator	I-Method
based	O
on	O
raw	O
images	O
of	O
the	O
screen	O
.	O
	
Previous	O
work	O
has	O
tackled	O
this	O
task	O
using	O
Q	B-Method
-	I-Method
learning	I-Method
with	O
epsilon	B-Method
-	I-Method
greedy	I-Method
exploration	I-Method
,	O
as	O
well	O
as	O
Monte	B-Method
Carlo	I-Method
tree	I-Method
search	I-Method
and	O
policy	B-Method
gradient	I-Method
methods	I-Method
.	O
	
We	O
use	O
Deep	B-Method
Q	I-Method
Networks	I-Method
(	O
DQN	B-Method
)	I-Method
as	O
the	O
reinforcement	B-Method
learning	I-Method
algorithm	I-Method
within	O
our	O
method	O
,	O
and	O
compare	O
its	O
performance	O
to	O
the	O
same	O
DQN	B-Method
method	I-Method
using	O
only	O
epsilon	B-Method
-	I-Method
greedy	I-Method
exploration	I-Method
,	O
Boltzman	B-Method
exploration	I-Method
,	O
and	O
a	O
Thompson	B-Method
sampling	I-Method
approach	I-Method
.	O
	
The	O
results	O
for	O
14	O
games	O
in	O
the	O
Arcade	B-Task
Learning	I-Task
Environment	I-Task
are	O
presented	O
in	O
Table	O
1	O
.	O
	
We	O
chose	O
those	O
games	O
that	O
were	O
particularly	O
challenging	O
for	O
prior	O
methods	O
and	O
ones	O
where	O
human	O
experts	O
outperform	O
prior	B-Method
learning	I-Method
methods	I-Method
.	O
	
We	O
evaluated	O
two	O
versions	O
of	O
our	O
approach	O
;	O
using	O
either	O
an	O
autoencoder	B-Method
trained	O
in	O
advance	O
by	O
running	O
epsilon	B-Method
-	I-Method
greedy	I-Method
Q	I-Method
-	I-Method
learning	I-Method
to	O
collect	O
data	O
(	O
denoted	O
as	O
“	O
Static	O
AE	O
”	O
)	O
,	O
or	O
using	O
an	O
autoencoder	B-Method
trained	O
concurrently	O
with	O
the	O
model	O
and	O
policy	B-Method
on	O
the	O
same	O
image	O
data	O
(	O
denoted	O
as	O
“	O
Dynamic	O
AE	O
”	O
)	O
.	O
	
Table	O
1	O
also	O
shows	O
results	O
from	O
the	O
DQN	B-Method
implementation	I-Method
reported	O
in	O
previous	O
work	O
,	O
along	O
with	O
human	O
expert	O
performance	O
on	O
each	O
game	O
.	O
	
Note	O
that	O
our	O
DQN	B-Method
implementation	I-Method
did	O
not	O
attain	O
the	O
same	O
score	O
on	O
all	O
of	O
the	O
games	O
as	O
prior	O
work	O
due	O
to	O
a	O
shorter	O
running	B-Metric
time	I-Metric
.	O
	
Since	O
we	O
are	O
primarily	O
concerned	O
with	O
the	O
rate	O
of	O
learning	B-Task
and	O
not	O
the	O
final	O
results	O
,	O
we	O
do	O
not	O
consider	O
this	O
a	O
deficiency	O
.	O
	
To	O
directly	O
evaluate	O
the	O
benefit	O
of	O
including	O
exploration	O
bonuses	O
,	O
we	O
compare	O
the	O
performance	O
of	O
our	O
approach	O
primarily	O
to	O
our	O
own	O
DQN	B-Method
implementation	I-Method
,	O
with	O
the	O
prior	O
scores	O
provided	O
for	O
reference	O
.	O
	
In	O
addition	O
to	O
raw	O
-	O
game	O
scores	O
,	O
and	O
learning	O
curves	O
,	O
we	O
also	O
analyze	O
our	O
results	O
on	O
a	O
new	O
benchmark	O
we	O
have	O
named	O
Area	B-Metric
Under	I-Metric
Curve	I-Metric
100	I-Metric
(	O
AUC	B-Metric
-	I-Metric
100	I-Metric
)	O
.	O
	
For	O
each	O
game	O
,	O
this	O
benchmark	O
computes	O
the	O
area	O
under	O
the	O
game	O
-	O
score	O
learning	O
curve	O
(	O
using	O
the	O
trapezoid	B-Method
rule	I-Method
to	O
approximate	O
the	O
integral	O
)	O
.	O
	
This	O
area	O
is	O
then	O
normalized	O
by	O
100	O
times	O
the	O
score	O
maximum	O
game	O
score	O
achieved	O
in	O
,	O
which	O
represents	O
100	O
epochs	O
of	O
play	O
at	O
the	O
best	O
-	O
known	O
levels	O
.	O
	
This	O
metric	O
more	O
effectively	O
captures	O
improvements	O
to	O
the	O
game	O
’s	O
learning	B-Metric
rate	I-Metric
and	O
does	O
not	O
require	O
running	O
the	O
games	O
for	O
1000	O
epochs	O
as	O
in	O
.	O
	
For	O
this	O
reason	O
,	O
we	O
suggest	O
it	O
as	O
an	O
alternative	O
metric	O
to	O
raw	O
game	O
-	O
score	O
.	O
	
paragraph	O
:	O
Bowling	O
	
The	O
policy	O
without	O
exploration	O
tended	O
to	O
fixate	O
on	O
a	O
set	O
pattern	O
of	O
nocking	O
down	O
six	O
pins	O
per	O
frame	O
.	O
	
When	O
bonuses	O
were	O
added	O
,	O
the	O
dynamics	B-Method
learner	I-Method
quickly	O
became	O
adept	O
at	O
predicting	O
this	O
outcome	O
and	O
was	O
thus	O
encouraged	O
to	O
explore	O
other	O
release	O
points	O
.	O
	
paragraph	O
:	O
Frostbite	O
	
This	O
game	O
’s	O
dynamics	O
changed	O
substantially	O
via	O
the	O
addition	O
of	O
extra	O
platforms	O
as	O
the	O
player	O
progressed	O
.	O
	
As	O
the	O
dynamics	O
of	O
these	O
more	O
complex	O
systems	O
was	O
not	O
well	O
understood	O
,	O
the	O
system	O
was	O
encouraged	O
to	O
visit	O
them	O
often	O
(	O
which	O
required	O
making	O
further	O
progress	O
in	O
the	O
game	O
)	O
.	O
	
paragraph	O
:	O
Seaquest	O
	
A	O
submarine	O
must	O
surface	O
for	O
air	O
between	O
bouts	O
of	O
fighting	O
sharks	O
.	O
	
However	O
,	O
if	O
the	O
player	O
resurfaces	O
too	O
soon	O
they	O
will	O
suffer	O
a	O
penalty	O
with	O
effects	O
on	O
the	O
game	O
’s	O
dynamics	O
.	O
	
Since	O
these	O
effects	O
are	O
poorly	O
understood	O
by	O
the	O
model	B-Method
learning	I-Method
algorithm	I-Method
,	O
resurfacing	B-Method
receives	O
a	O
high	O
exploration	O
bonus	O
and	O
hence	O
the	O
agent	O
eventually	O
learns	O
to	O
successfully	O
resurface	O
at	O
the	O
correct	O
time	O
.	O
	
paragraph	O
:	O
bert	O
	
Exploration	O
bonuses	O
resulted	O
in	O
a	O
lower	O
score	O
.	O
	
In	O
bert	O
,	O
the	O
background	O
changes	O
color	O
after	O
level	O
one	O
.	O
	
The	O
dynamics	B-Method
predictor	I-Method
is	O
unable	O
to	O
quickly	O
adapt	O
to	O
such	O
a	O
dramatic	O
change	O
in	O
the	O
environment	O
and	O
consequently	O
,	O
exploration	O
bonuses	O
are	O
assigned	O
in	O
near	O
equality	O
to	O
almost	O
every	O
state	O
that	O
is	O
visited	O
.	O
	
This	O
negatively	O
impacts	O
the	O
final	O
policy	O
.	O
	
Learning	O
curves	O
for	O
each	O
of	O
the	O
games	O
are	O
shown	O
in	O
Figure	O
(	O
3	O
)	O
.	O
	
Note	O
that	O
both	O
of	O
the	O
exploration	B-Method
bonus	I-Method
algorithms	I-Method
learn	O
significantly	O
faster	O
than	O
epsilon	B-Method
-	I-Method
greedy	I-Method
Q	I-Method
-	I-Method
learning	I-Method
,	O
and	O
often	O
continue	O
learning	O
even	O
after	O
the	O
epsilon	B-Method
-	I-Method
greedy	I-Method
strategy	I-Method
converges	O
.	O
	
All	O
games	O
had	O
the	O
inputs	O
normalized	O
according	O
to	O
and	O
were	O
run	O
for	O
100	O
epochs	O
(	O
where	O
one	O
epoch	O
is	O
50	O
,	O
000	O
time	O
steps	O
)	O
.	O
	
Between	O
each	O
epoch	O
,	O
the	O
policy	O
was	O
updated	O
and	O
then	O
the	O
new	O
policy	O
underwent	O
10	O
,	O
000	O
time	O
steps	O
of	O
testing	O
.	O
	
The	O
results	O
represent	O
the	O
average	O
testing	O
score	O
across	O
three	O
trials	O
after	O
100	O
epoch	O
each	O
.	O
	
The	O
results	O
show	O
that	O
more	O
nuanced	B-Method
exploration	I-Method
strategies	I-Method
generally	O
improve	O
on	O
the	O
naive	O
epsilon	B-Method
greedy	I-Method
approach	I-Method
,	O
with	O
the	O
Boltzman	B-Method
and	I-Method
Thompson	I-Method
sampling	I-Method
methods	I-Method
achieving	O
the	O
best	O
results	O
on	O
three	O
of	O
the	O
games	O
.	O
	
However	O
,	O
exploration	B-Method
bonuses	I-Method
achieve	O
the	O
fastest	O
learning	B-Task
and	O
the	O
best	O
results	O
most	O
consistently	O
,	O
outperforming	O
the	O
other	O
three	O
methods	O
on	O
7	O
of	O
the	O
14	O
games	O
in	O
terms	O
of	O
AUC	B-Metric
-	I-Metric
100	I-Metric
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
paper	O
,	O
we	O
evaluated	O
several	O
scalable	O
and	O
efficient	O
exploration	B-Method
algorithms	I-Method
for	O
reinforcement	B-Task
learning	I-Task
in	O
tasks	O
with	O
complex	O
,	O
high	O
-	O
dimensional	O
observations	O
.	O
	
Our	O
results	O
show	O
that	O
a	O
new	O
method	O
based	O
on	O
assigning	O
exploration	O
bonuses	O
most	O
consistently	O
achieves	O
the	O
largest	O
improvement	O
on	O
a	O
range	O
of	O
challenging	O
Atari	B-Task
games	I-Task
,	O
particularly	O
those	O
on	O
which	O
human	O
players	O
outperform	O
prior	B-Method
learning	I-Method
methods	I-Method
.	O
	
Our	O
exploration	B-Method
method	I-Method
learns	O
a	O
model	O
of	O
the	O
dynamics	O
concurrently	O
with	O
the	O
policy	O
.	O
	
This	O
model	O
predicts	O
a	O
learned	O
representation	O
of	O
the	O
state	O
,	O
and	O
a	O
function	O
of	O
this	O
prediction	O
error	O
is	O
added	O
to	O
the	O
reward	O
as	O
an	O
exploration	O
bonus	O
to	O
encourage	O
the	O
policy	O
to	O
visit	O
states	O
with	O
high	O
novelty	O
.	O
	
One	O
of	O
the	O
limitations	O
of	O
our	O
approach	O
is	O
that	O
the	O
misprediction	B-Metric
error	I-Metric
metric	I-Metric
assumes	O
that	O
any	O
misprediction	O
in	O
the	O
state	O
is	O
caused	O
by	O
inaccuracies	O
in	O
the	O
model	O
.	O
	
While	O
this	O
is	O
true	O
in	O
determinstic	O
environments	O
,	O
stochastic	O
dynamics	O
violate	O
this	O
assumption	O
.	O
	
An	O
extension	O
of	O
our	O
approach	O
to	O
stochastic	B-Task
systems	I-Task
requires	O
a	O
more	O
nuanced	O
treatment	O
of	O
the	O
distinction	O
between	O
stochastic	O
dynamics	O
and	O
uncertain	O
dynamics	O
,	O
which	O
we	O
hope	O
to	O
explore	O
in	O
future	O
work	O
.	O
	
Another	O
intriguing	O
direction	O
for	O
future	O
work	O
is	O
to	O
examine	O
how	O
the	O
learned	B-Method
dynamics	I-Method
model	I-Method
can	O
be	O
incorporated	O
into	O
the	O
policy	B-Method
learning	I-Method
process	I-Method
,	O
beyond	O
just	O
providing	O
exploration	O
bonuses	O
.	O
	
This	O
could	O
in	O
principle	O
enable	O
substantially	O
faster	O
learning	B-Task
than	O
purely	O
model	B-Method
-	I-Method
free	I-Method
approaches	I-Method
.	O
	
bibliography	O
:	O
References	O
	
appendix	O
:	O
Appendix	O
	
subsection	O
:	O
On	O
auto	B-Method
encoder	I-Method
layer	I-Method
selection	I-Method
	
Recall	O
that	O
we	O
trained	O
an	O
auto	B-Method
-	I-Method
encoder	I-Method
to	O
encode	O
the	O
game	O
’s	O
state	O
space	O
.	O
	
We	O
then	O
trained	O
a	O
predictive	B-Method
model	I-Method
on	O
the	O
next	O
auto	O
-	O
encoded	O
frame	O
rather	O
than	O
directly	O
training	O
on	O
the	O
pixel	O
intensity	O
values	O
of	O
the	O
next	O
frame	O
.	O
	
To	O
obtain	O
the	O
encoded	O
space	O
,	O
we	O
ran	O
each	O
state	O
through	O
an	O
eight	B-Method
layer	I-Method
auto	I-Method
-	I-Method
encoder	I-Method
for	O
training	O
and	O
then	O
utilized	O
the	O
auto	B-Method
-	I-Method
encoder	I-Method
’s	I-Method
sixth	I-Method
layer	I-Method
as	O
an	O
encoded	O
state	O
space	O
.	O
	
We	O
chose	O
to	O
use	O
the	O
sixth	B-Method
layer	I-Method
rather	O
than	O
the	O
bottleneck	B-Method
fourth	I-Method
layer	I-Method
because	O
we	O
found	O
that	O
,	O
over	O
20	O
iterations	O
of	O
Seaquest	O
at	O
100	O
epochs	O
per	O
iteration	O
,	O
using	O
this	O
layer	O
for	O
encoding	B-Task
delivered	O
measurably	O
better	O
performance	O
than	O
using	O
the	O
bottleneck	B-Method
layer	I-Method
.	O
	
The	O
results	O
of	O
that	O
experiment	O
are	O
presented	O
below	O
.	O
	
subsection	O
:	O
On	O
the	O
quality	O
of	O
the	O
learned	O
model	B-Method
dynamics	I-Method
	
Evaluating	O
the	O
quality	O
of	O
the	O
learned	O
dynamics	B-Method
model	I-Method
is	O
somewhat	O
difficult	O
because	O
the	O
system	O
is	O
rewarded	O
achieving	O
higher	O
error	B-Metric
rates	I-Metric
.	O
	
A	O
dynamics	B-Method
model	I-Method
that	O
converges	O
quickly	O
is	O
not	O
useful	O
for	O
exploration	B-Task
bonuses	I-Task
.	O
	
Nevertheless	O
,	O
when	O
we	O
plot	O
the	O
mean	O
of	O
the	O
normalized	O
residuals	O
across	O
all	O
games	O
and	O
all	O
trials	O
used	O
in	O
our	O
experiments	O
,	O
we	O
see	O
that	O
the	O
errors	O
of	O
the	O
learned	O
dynamics	B-Method
models	I-Method
continually	O
decrease	O
over	O
time	O
.	O
	
The	O
mean	O
normalized	O
residual	O
after	O
100	O
epochs	O
is	O
approximately	O
half	O
of	O
the	O
maximal	O
mean	O
achieved	O
.	O
	
This	O
suggests	O
that	O
each	O
dynamics	B-Method
model	I-Method
was	O
able	O
to	O
correctly	O
learn	O
properties	O
of	O
underlying	O
dynamics	O
for	O
its	O
given	O
game	O
.	O
	
subsection	O
:	O
Raw	B-Metric
AUC	I-Metric
-	I-Metric
100	I-Metric
scores	I-Metric
	
InfoGAN	B-Method
:	O
	
Interpretable	B-Method
Representation	I-Method
Learning	I-Method
by	O
Information	B-Method
Maximizing	I-Method
Generative	I-Method
Adversarial	I-Method
Nets	I-Method
	
section	O
:	O
Abstract	O
	
This	O
paper	O
describes	O
InfoGAN	B-Method
,	O
an	O
information	B-Method
-	I-Method
theoretic	I-Method
extension	I-Method
to	O
the	O
Generative	B-Method
Adversarial	I-Method
Network	I-Method
that	O
is	O
able	O
to	O
learn	O
disentangled	B-Method
representations	I-Method
in	O
a	O
completely	O
unsupervised	B-Method
manner	I-Method
.	O
	
InfoGAN	B-Method
is	O
a	O
generative	B-Method
adversarial	I-Method
network	I-Method
that	O
also	O
maximizes	O
the	O
mutual	O
information	O
between	O
a	O
small	O
subset	O
of	O
the	O
latent	O
variables	O
and	O
the	O
observation	O
.	O
	
We	O
derive	O
a	O
lower	B-Metric
bound	I-Metric
of	O
the	O
mutual	B-Metric
information	I-Metric
objective	I-Metric
that	O
can	O
be	O
optimized	O
efficiently	O
.	O
	
Specifically	O
,	O
InfoGAN	B-Method
successfully	O
disentangles	O
writing	O
styles	O
from	O
digit	O
shapes	O
on	O
the	O
MNIST	B-Material
dataset	I-Material
,	O
pose	O
from	O
lighting	O
of	O
3D	O
rendered	O
images	O
,	O
and	O
background	O
digits	O
from	O
the	O
central	O
digit	O
on	O
the	O
SVHN	O
dataset	O
.	O
	
It	O
also	O
discovers	O
visual	O
concepts	O
that	O
include	O
hair	O
styles	O
,	O
presence	O
/	O
absence	O
of	O
eyeglasses	O
,	O
and	O
emotions	O
on	O
the	O
CelebA	O
face	O
dataset	O
.	O
	
Experiments	O
show	O
that	O
InfoGAN	B-Method
learns	O
interpretable	B-Method
representations	I-Method
that	O
are	O
competitive	O
with	O
representations	O
learned	O
by	O
existing	O
supervised	B-Method
methods	I-Method
.	O
	
section	O
:	O
Introduction	O
	
Unsupervised	B-Task
learning	I-Task
can	O
be	O
described	O
as	O
the	O
general	O
problem	O
of	O
extracting	B-Task
value	I-Task
from	O
unlabelled	O
data	O
which	O
exists	O
in	O
vast	O
quantities	O
.	O
	
A	O
popular	O
framework	O
for	O
unsupervised	B-Task
learning	I-Task
is	O
that	O
of	O
representation	B-Method
learning	I-Method
[	O
reference	O
][	O
reference	O
]	O
,	O
whose	O
goal	O
is	O
to	O
use	O
unlabelled	O
data	O
to	O
learn	O
a	O
representation	O
that	O
exposes	O
important	O
semantic	O
features	O
as	O
easily	O
decodable	O
factors	O
.	O
	
A	O
method	O
that	O
can	O
learn	O
such	O
representations	O
is	O
likely	O
to	O
exist	O
[	O
reference	O
]	O
,	O
and	O
to	O
be	O
useful	O
for	O
many	O
downstream	B-Task
tasks	I-Task
which	O
include	O
classification	B-Task
,	O
regression	B-Task
,	O
visualization	B-Task
,	O
and	O
policy	B-Task
learning	I-Task
in	O
reinforcement	B-Task
learning	I-Task
.	O
	
While	O
unsupervised	B-Task
learning	I-Task
is	O
ill	O
-	O
posed	O
because	O
the	O
relevant	O
downstream	B-Task
tasks	I-Task
are	O
unknown	O
at	O
training	O
time	O
,	O
a	O
disentangled	B-Method
representation	I-Method
,	O
one	O
which	O
explicitly	O
represents	O
the	O
salient	O
attributes	O
of	O
a	O
data	O
instance	O
,	O
should	O
be	O
helpful	O
for	O
the	O
relevant	O
but	O
unknown	O
tasks	O
.	O
	
For	O
example	O
,	O
for	O
a	O
dataset	O
of	O
faces	O
,	O
a	O
useful	O
disentangled	B-Method
representation	I-Method
may	O
allocate	O
a	O
separate	O
set	O
of	O
dimensions	O
for	O
each	O
of	O
the	O
following	O
attributes	O
:	O
facial	O
expression	O
,	O
eye	O
color	O
,	O
hairstyle	O
,	O
presence	O
or	O
absence	O
of	O
eyeglasses	O
,	O
and	O
the	O
identity	O
of	O
the	O
corresponding	O
person	O
.	O
	
A	O
disentangled	B-Method
representation	I-Method
can	O
be	O
useful	O
for	O
natural	B-Task
tasks	I-Task
that	O
require	O
knowledge	O
of	O
the	O
salient	O
attributes	O
of	O
the	O
data	O
,	O
which	O
include	O
tasks	O
like	O
face	B-Task
recognition	I-Task
and	O
object	B-Task
recognition	I-Task
.	O
	
It	O
is	O
not	O
the	O
case	O
for	O
unnatural	B-Task
supervised	I-Task
tasks	I-Task
,	O
where	O
the	O
goal	O
could	O
be	O
,	O
for	O
example	O
,	O
to	O
determine	O
whether	O
the	O
number	O
of	O
red	O
pixels	O
in	O
an	O
image	O
is	O
even	O
or	O
odd	O
.	O
	
Thus	O
,	O
to	O
be	O
useful	O
,	O
an	O
unsupervised	B-Task
learning	I-Task
algorithm	O
must	O
in	O
effect	O
correctly	O
guess	O
the	O
likely	O
set	O
of	O
downstream	O
classification	B-Task
tasks	O
without	O
being	O
directly	O
exposed	O
to	O
them	O
.	O
	
A	O
significant	O
fraction	O
of	O
unsupervised	B-Task
learning	I-Task
research	I-Task
is	O
driven	O
by	O
generative	B-Method
modelling	I-Method
.	O
	
It	O
is	O
motivated	O
by	O
the	O
belief	O
that	O
the	O
ability	O
to	O
synthesize	O
,	O
or	O
"	O
create	O
"	O
the	O
observed	O
data	O
entails	O
some	O
form	O
of	O
understanding	O
,	O
and	O
it	O
is	O
hoped	O
that	O
a	O
good	O
generative	B-Method
model	I-Method
will	O
automatically	O
learn	O
a	O
disentangled	B-Method
representation	I-Method
,	O
even	O
though	O
it	O
is	O
easy	O
to	O
construct	O
perfect	O
generative	B-Method
models	I-Method
with	O
arbitrarily	O
bad	O
representations	O
.	O
	
The	O
most	O
prominent	O
generative	B-Method
models	I-Method
are	O
the	O
variational	B-Method
autoencoder	I-Method
(	I-Method
VAE	I-Method
)	O
	
[	O
reference	O
]	O
and	O
the	O
generative	B-Method
adversarial	I-Method
network	I-Method
(	I-Method
GAN	I-Method
)	O
	
[	O
reference	O
]	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
present	O
a	O
simple	O
modification	O
to	O
the	O
generative	B-Method
adversarial	I-Method
network	I-Method
objective	I-Method
that	O
encourages	O
it	O
to	O
learn	O
interpretable	B-Task
and	I-Task
meaningful	I-Task
representations	I-Task
.	O
	
We	O
do	O
so	O
by	O
maximizing	O
the	O
mutual	O
information	O
between	O
a	O
fixed	O
small	O
subset	O
of	O
the	O
GAN	O
's	O
noise	O
variables	O
and	O
the	O
observations	O
,	O
which	O
turns	O
out	O
to	O
be	O
relatively	O
straightforward	O
.	O
	
Despite	O
its	O
simplicity	O
,	O
we	O
found	O
our	O
method	O
to	O
be	O
surprisingly	O
effective	O
:	O
it	O
was	O
able	O
to	O
discover	O
highly	O
semantic	O
and	O
meaningful	O
hidden	B-Method
representations	I-Method
on	O
a	O
number	O
of	O
image	O
datasets	O
:	O
digits	O
(	O
MNIST	B-Material
)	O
,	O
faces	O
(	O
CelebA	O
)	O
,	O
and	O
house	O
numbers	O
(	O
SVHN	O
)	O
.	O
	
The	O
quality	O
of	O
our	O
unsupervised	B-Method
disentangled	I-Method
representation	I-Method
matches	O
previous	O
works	O
that	O
made	O
use	O
of	O
supervised	O
label	O
information	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
	
These	O
results	O
suggest	O
that	O
generative	B-Method
modelling	I-Method
augmented	O
with	O
a	O
mutual	O
information	O
cost	O
could	O
be	O
a	O
fruitful	O
approach	O
for	O
learning	B-Task
disentangled	I-Task
representations	I-Task
.	O
	
In	O
the	O
remainder	O
of	O
the	O
paper	O
,	O
we	O
begin	O
with	O
a	O
review	O
of	O
the	O
related	O
work	O
,	O
noting	O
the	O
supervision	O
that	O
is	O
required	O
by	O
previous	O
methods	O
that	O
learn	O
disentangled	B-Method
representations	I-Method
.	O
	
Then	O
we	O
review	O
GANs	B-Method
,	O
which	O
is	O
the	O
basis	O
of	O
InfoGAN	B-Method
.	O
	
We	O
describe	O
how	O
maximizing	O
mutual	O
information	O
results	O
in	O
interpretable	B-Method
representations	I-Method
and	O
derive	O
a	O
simple	O
and	O
efficient	O
algorithm	O
for	O
doing	O
so	O
.	O
	
Finally	O
,	O
in	O
the	O
experiments	O
section	O
,	O
we	O
first	O
compare	O
InfoGAN	B-Method
with	O
prior	O
approaches	O
on	O
relatively	O
clean	O
datasets	O
and	O
then	O
show	O
that	O
InfoGAN	B-Method
can	O
learn	O
interpretable	B-Method
representations	I-Method
on	O
complex	O
datasets	O
where	O
no	O
previous	O
unsupervised	B-Method
approach	I-Method
is	O
known	O
to	O
learn	O
representations	O
of	O
comparable	B-Metric
quality	I-Metric
.	O
	
section	O
:	O
Related	O
Work	O
	
There	O
exists	O
a	O
large	O
body	O
of	O
work	O
on	O
unsupervised	B-Task
representation	I-Task
learning	I-Task
.	O
	
Early	O
methods	O
were	O
based	O
on	O
stacked	B-Method
(	I-Method
often	I-Method
denoising	I-Method
)	I-Method
autoencoders	I-Method
or	O
restricted	B-Method
Boltzmann	I-Method
machines	I-Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
	
A	O
lot	O
of	O
promising	O
recent	O
work	O
originates	O
from	O
the	O
Skip	B-Method
-	I-Method
gram	I-Method
model	I-Method
[	O
reference	O
]	O
,	O
which	O
inspired	O
the	O
skip	O
-	O
thought	O
vectors	O
[	O
reference	O
]	O
and	O
several	O
techniques	O
for	O
unsupervised	B-Task
feature	I-Task
learning	I-Task
of	I-Task
images	I-Task
[	O
reference	O
]	O
.	O
	
Another	O
intriguing	O
line	O
of	O
work	O
consists	O
of	O
the	O
ladder	B-Method
network	I-Method
[	O
reference	O
]	O
,	O
which	O
has	O
achieved	O
spectacular	O
results	O
on	O
a	O
semi	B-Method
-	I-Method
supervised	I-Method
variant	I-Method
of	O
the	O
MNIST	B-Material
dataset	I-Material
.	O
	
More	O
recently	O
,	O
a	O
model	O
based	O
on	O
the	O
VAE	B-Method
has	O
achieved	O
even	O
better	O
semi	B-Metric
-	I-Metric
supervised	I-Metric
results	I-Metric
on	O
MNIST	B-Material
[	O
reference	O
]	O
.	O
GANs	B-Method
[	O
reference	O
]	O
have	O
been	O
used	O
by	O
Radford	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
to	O
learn	O
an	O
image	B-Method
representation	I-Method
that	O
supports	O
basic	O
linear	B-Method
algebra	I-Method
on	O
code	O
space	O
.	O
	
Lake	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
have	O
been	O
able	O
to	O
learn	O
representations	O
using	O
probabilistic	B-Method
inference	I-Method
over	O
Bayesian	B-Method
programs	I-Method
,	O
which	O
achieved	O
convincing	O
one	O
-	O
shot	B-Task
learning	I-Task
results	O
on	O
the	O
OMNI	B-Material
dataset	I-Material
.	O
	
In	O
addition	O
,	O
prior	O
research	O
attempted	O
to	O
learn	O
disentangled	B-Method
representations	I-Method
using	O
supervised	O
data	O
.	O
	
One	O
class	O
of	O
such	O
methods	O
trains	O
a	O
subset	O
of	O
the	O
representation	O
to	O
match	O
the	O
supplied	O
label	O
using	O
supervised	B-Method
learning	I-Method
:	O
bilinear	B-Method
models	I-Method
[	O
reference	O
]	O
separate	O
style	O
and	O
content	O
;	O
multi	B-Method
-	I-Method
view	I-Method
perceptron	I-Method
[	O
reference	O
]	O
separate	O
face	O
identity	O
and	O
view	O
point	O
;	O
and	O
Yang	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
developed	O
a	O
recurrent	B-Method
variant	I-Method
that	O
generates	O
a	O
sequence	O
of	O
latent	B-Method
factor	I-Method
transformations	I-Method
.	O
	
Similarly	O
,	O
VAEs	B-Method
[	O
reference	O
]	O
and	O
Adversarial	B-Method
Autoencoders	I-Method
[	O
reference	O
]	O
were	O
shown	O
to	O
learn	O
representations	O
in	O
which	O
class	O
label	O
is	O
separated	O
from	O
other	O
variations	O
.	O
	
Recently	O
several	O
weakly	B-Method
supervised	I-Method
methods	I-Method
were	O
developed	O
to	O
remove	O
the	O
need	O
of	O
explicitly	O
labeling	O
variations	O
.	O
	
disBM	B-Method
[	O
reference	O
]	O
is	O
a	O
higher	B-Method
-	I-Method
order	I-Method
Boltzmann	I-Method
machine	I-Method
which	O
learns	O
a	O
disentangled	B-Method
representation	I-Method
by	O
"	O
clamping	O
"	O
a	O
part	O
of	O
the	O
hidden	O
units	O
for	O
a	O
pair	O
of	O
data	O
points	O
that	O
are	O
known	O
to	O
match	O
in	O
all	O
but	O
one	O
factors	O
of	O
variation	O
.	O
	
DC	B-Method
-	I-Method
IGN	I-Method
[	O
reference	O
]	O
extends	O
this	O
"	O
clamping	B-Method
"	I-Method
idea	I-Method
to	O
VAE	B-Method
and	O
successfully	O
learns	O
graphics	B-Method
codes	I-Method
that	O
can	O
represent	O
pose	O
and	O
light	O
in	O
3D	O
rendered	O
images	O
.	O
	
This	O
line	O
of	O
work	O
yields	O
impressive	O
results	O
,	O
but	O
they	O
rely	O
on	O
a	O
supervised	B-Method
grouping	I-Method
of	O
the	O
data	O
that	O
is	O
generally	O
not	O
available	O
.	O
	
Whitney	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
proposed	O
to	O
alleviate	O
the	O
grouping	O
requirement	O
by	O
learning	O
from	O
consecutive	O
frames	O
of	O
images	O
and	O
use	O
temporal	O
continuity	O
as	O
supervisory	O
signal	O
.	O
	
Unlike	O
the	O
cited	O
prior	O
works	O
that	O
strive	O
to	O
recover	O
disentangled	O
representations	O
,	O
InfoGAN	B-Method
requires	O
no	O
supervision	O
of	O
any	O
kind	O
.	O
	
To	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
the	O
only	O
other	O
unsupervised	B-Method
method	I-Method
that	O
learns	O
disentangled	B-Method
representations	I-Method
is	O
hossRBM	B-Method
[	O
reference	O
]	O
,	O
a	O
higher	O
-	O
order	O
extension	O
of	O
the	O
spike	B-Method
-	I-Method
and	I-Method
-	I-Method
slab	I-Method
restricted	I-Method
Boltzmann	I-Method
machine	I-Method
that	O
can	O
disentangle	O
emotion	O
from	O
identity	O
on	O
the	O
Toronto	O
Face	O
Dataset	O
	
[	O
reference	O
]	O
.	O
However	O
,	O
hossRBM	B-Method
can	O
only	O
disentangle	O
discrete	O
latent	O
factors	O
,	O
and	O
its	O
computation	B-Metric
cost	I-Metric
grows	O
exponentially	O
in	O
the	O
number	O
of	O
factors	O
.	O
	
InfoGAN	B-Method
can	O
disentangle	O
both	O
discrete	O
and	O
continuous	O
latent	O
factors	O
,	O
scale	O
to	O
complicated	O
datasets	O
,	O
and	O
typically	O
requires	O
no	O
more	O
training	O
time	O
than	O
regular	B-Method
GAN	I-Method
.	O
	
section	O
:	O
Background	O
:	O
Generative	B-Method
Adversarial	I-Method
Networks	I-Method
	
Goodfellow	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
introduced	O
the	O
Generative	B-Method
Adversarial	I-Method
Networks	I-Method
(	I-Method
GAN	I-Method
)	I-Method
,	O
a	O
framework	O
for	O
training	O
deep	B-Method
generative	I-Method
models	I-Method
using	O
a	O
minimax	B-Method
game	I-Method
.	O
	
The	O
goal	O
is	O
to	O
learn	O
a	O
generator	B-Method
distribution	I-Method
P	I-Method
G	I-Method
(	O
x	O
)	O
that	O
matches	O
the	O
real	O
data	O
distribution	O
P	O
data	O
(	O
x	O
)	O
.	O
	
Instead	O
of	O
trying	O
to	O
explicitly	O
assign	O
probability	O
to	O
every	O
x	O
in	O
the	O
data	O
distribution	O
,	O
GAN	B-Method
learns	O
a	O
generator	B-Method
network	I-Method
G	I-Method
that	O
generates	O
samples	O
from	O
the	O
generator	B-Method
distribution	I-Method
P	I-Method
G	I-Method
by	O
transforming	O
a	O
noise	O
variable	O
z	O
	
∼	O
P	O
noise	O
(	O
z	O
)	O
into	O
a	O
sample	O
G	O
(	O
z	O
)	O
.	O
	
This	O
generator	O
is	O
trained	O
by	O
playing	O
against	O
an	O
adversarial	B-Method
discriminator	I-Method
network	I-Method
D	I-Method
that	O
aims	O
to	O
distinguish	O
between	O
samples	O
from	O
the	O
true	O
data	O
distribution	O
P	O
data	O
and	O
the	O
generator	O
's	O
distribution	O
P	O
G	O
.	O
	
So	O
for	O
a	O
given	O
generator	O
,	O
the	O
optimal	O
discriminator	B-Method
is	O
D	O
(	O
x	O
)	O
=	O
	
P	O
data	O
(	O
x	O
)/(	O
P	O
data	O
(	O
x	O
)	O
+	O
P	O
G	O
(	O
x	O
)	O
)	O
.	O
	
More	O
formally	O
,	O
the	O
minimax	B-Task
game	I-Task
is	O
given	O
by	O
the	O
following	O
expression	O
:	O
	
section	O
:	O
Mutual	O
Information	O
for	O
Inducing	B-Task
Latent	I-Task
Codes	I-Task
	
The	O
GAN	B-Method
formulation	I-Method
uses	O
a	O
simple	O
factored	O
continuous	O
input	O
noise	O
vector	O
z	O
,	O
while	O
imposing	O
no	O
restrictions	O
on	O
the	O
manner	O
in	O
which	O
the	O
generator	O
may	O
use	O
this	O
noise	O
.	O
	
As	O
a	O
result	O
,	O
it	O
is	O
possible	O
that	O
the	O
noise	O
will	O
be	O
used	O
by	O
the	O
generator	O
in	O
a	O
highly	O
entangled	O
way	O
,	O
causing	O
the	O
individual	O
dimensions	O
of	O
z	O
to	O
not	O
correspond	O
to	O
semantic	O
features	O
of	O
the	O
data	O
.	O
	
However	O
,	O
many	O
domains	O
naturally	O
decompose	O
into	O
a	O
set	O
of	O
semantically	O
meaningful	O
factors	O
of	O
variation	O
.	O
	
For	O
instance	O
,	O
when	O
generating	O
images	O
from	O
the	O
MNIST	B-Material
dataset	I-Material
,	O
it	O
would	O
be	O
ideal	O
if	O
the	O
model	O
automatically	O
chose	O
to	O
allocate	O
a	O
discrete	O
random	O
variable	O
to	O
represent	O
the	O
numerical	O
identity	O
of	O
the	O
digit	O
(	O
0	O
-	O
9	O
)	O
,	O
and	O
chose	O
to	O
have	O
two	O
additional	O
continuous	O
variables	O
that	O
represent	O
the	O
digit	O
's	O
angle	O
and	O
thickness	O
of	O
the	O
digit	O
's	O
stroke	O
.	O
	
It	O
is	O
the	O
case	O
that	O
these	O
attributes	O
are	O
both	O
independent	O
and	O
salient	O
,	O
and	O
it	O
would	O
be	O
useful	O
if	O
we	O
could	O
recover	O
these	O
concepts	O
without	O
any	O
supervision	O
,	O
by	O
simply	O
specifying	O
that	O
an	O
MNIST	B-Material
digit	O
is	O
generated	O
by	O
an	O
independent	O
1	O
-	O
of	O
-	O
10	O
variable	O
and	O
two	O
independent	O
continuous	O
variables	O
.	O
	
In	O
this	O
paper	O
,	O
rather	O
than	O
using	O
a	O
single	O
unstructured	O
noise	O
vector	O
,	O
we	O
propose	O
to	O
decompose	O
the	O
input	O
noise	O
vector	O
into	O
two	O
parts	O
:	O
(	O
i	O
)	O
	
z	O
,	O
which	O
is	O
treated	O
as	O
source	O
of	O
incompressible	O
noise	O
;	O
	
(	O
ii	O
)	O
c	O
,	O
which	O
we	O
will	O
call	O
the	O
latent	O
code	O
and	O
will	O
target	O
the	O
salient	O
structured	O
semantic	O
features	O
of	O
the	O
data	O
distribution	O
.	O
	
Mathematically	O
,	O
we	O
denote	O
the	O
set	O
of	O
structured	O
latent	O
variables	O
by	O
c	O
1	O
,	O
c	O
2	O
,	O
.	O
.	O
.	O
,	O
c	O
L	O
.	O
	
In	O
its	O
simplest	O
form	O
,	O
we	O
may	O
assume	O
a	O
factored	B-Method
distribution	I-Method
,	O
given	O
by	O
	
For	O
ease	O
of	O
notation	O
,	O
we	O
will	O
use	O
latent	O
codes	O
c	O
to	O
denote	O
the	O
concatenation	O
of	O
all	O
latent	O
variables	O
c	O
i	O
.	O
	
We	O
now	O
propose	O
a	O
method	O
for	O
discovering	O
these	O
latent	O
factors	O
in	O
an	O
unsupervised	O
way	O
:	O
we	O
provide	O
the	O
generator	B-Method
network	I-Method
with	O
both	O
the	O
incompressible	O
noise	O
z	O
and	O
the	O
latent	O
code	O
c	O
,	O
so	O
the	O
form	O
of	O
the	O
generator	O
becomes	O
G	O
(	O
z	O
,	O
c	O
)	O
.	O
	
However	O
,	O
in	O
standard	O
GAN	B-Method
,	O
the	O
generator	B-Method
is	O
free	O
to	O
ignore	O
the	O
additional	O
latent	O
code	O
c	O
by	O
finding	O
a	O
solution	O
satisfying	O
P	O
G	O
(	O
x|c	O
)	O
=	O
	
P	O
G	O
(	O
x	O
)	O
.	O
	
To	O
cope	O
with	O
the	O
problem	O
of	O
trivial	O
codes	O
,	O
we	O
propose	O
an	O
information	B-Method
-	I-Method
theoretic	I-Method
regularization	I-Method
:	O
there	O
should	O
be	O
high	O
mutual	O
information	O
between	O
latent	O
codes	O
c	O
and	O
generator	B-Method
distribution	I-Method
G	I-Method
(	I-Method
z	I-Method
,	O
c	O
)	O
.	O
	
Thus	O
I	O
(	O
c	O
;	O
G	O
(	O
z	O
,	O
c	O
)	O
)	O
should	O
be	O
high	O
.	O
	
In	O
information	B-Method
theory	I-Method
,	O
mutual	O
information	O
between	O
X	O
and	O
Y	O
,	O
I	O
(	O
X	O
;	O
Y	O
)	O
,	O
measures	O
the	O
"	O
amount	O
of	O
information	O
"	O
learned	O
from	O
knowledge	O
of	O
random	O
variable	O
Y	O
about	O
the	O
other	O
random	O
variable	O
X.	O
	
The	O
mutual	B-Metric
information	I-Metric
can	O
be	O
expressed	O
as	O
the	O
difference	O
of	O
two	O
entropy	O
terms	O
:	O
	
This	O
definition	O
has	O
an	O
intuitive	O
interpretation	O
:	O
I	O
(	O
X	O
;	O
Y	O
)	O
is	O
the	O
reduction	O
of	O
uncertainty	O
in	O
X	O
when	O
Y	O
is	O
observed	O
.	O
	
If	O
X	O
and	O
Y	O
are	O
independent	O
,	O
then	O
I	O
(	O
X	O
;	O
Y	O
)	O
	
=	O
0	O
,	O
because	O
knowing	O
one	O
variable	O
reveals	O
nothing	O
about	O
the	O
other	O
;	O
by	O
contrast	O
,	O
if	O
X	O
and	O
Y	O
are	O
related	O
by	O
a	O
deterministic	O
,	O
invertible	O
function	O
,	O
then	O
maximal	O
mutual	O
information	O
is	O
attained	O
.	O
	
This	O
interpretation	O
makes	O
it	O
easy	O
to	O
formulate	O
a	O
cost	O
:	O
	
given	O
any	O
x	O
∼	O
P	O
G	O
(	O
x	O
)	O
,	O
we	O
want	O
P	O
G	O
(	O
c|x	O
)	O
to	O
have	O
a	O
small	O
entropy	O
.	O
	
In	O
other	O
words	O
,	O
the	O
information	O
in	O
the	O
latent	O
code	O
c	O
should	O
not	O
be	O
lost	O
in	O
the	O
generation	B-Task
process	I-Task
.	O
	
Similar	O
mutual	B-Metric
information	I-Metric
inspired	I-Metric
objectives	I-Metric
have	O
been	O
considered	O
before	O
in	O
the	O
context	O
of	O
clustering	B-Task
	
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
Therefore	O
,	O
we	O
propose	O
to	O
solve	O
the	O
following	O
information	B-Method
-	I-Method
regularized	I-Method
minimax	I-Method
game	I-Method
:	O
	
section	O
:	O
Variational	B-Task
Mutual	I-Task
Information	I-Task
Maximization	I-Task
	
In	O
practice	O
,	O
the	O
mutual	O
information	O
term	O
I	O
(	O
c	O
;	O
G	O
(	O
z	O
,	O
c	O
)	O
)	O
is	O
hard	O
to	O
maximize	O
directly	O
as	O
it	O
requires	O
access	O
to	O
the	O
posterior	O
P	O
(	O
c|x	O
)	O
.	O
	
Fortunately	O
we	O
can	O
obtain	O
a	O
lower	O
bound	O
of	O
it	O
by	O
defining	O
an	O
auxiliary	B-Method
distribution	I-Method
Q	I-Method
(	I-Method
c|x	I-Method
)	O
to	O
approximate	O
P	O
(	O
c|x	O
)	O
:	O
	
This	O
technique	O
of	O
lower	B-Task
bounding	I-Task
mutual	I-Task
information	I-Task
is	O
known	O
as	O
Variational	B-Task
Information	I-Task
Maximization	I-Task
	
[	O
reference	O
]	O
.	O
	
We	O
note	O
in	O
addition	O
that	O
the	O
entropy	O
of	O
latent	B-Method
codes	I-Method
H	I-Method
(	I-Method
c	I-Method
)	I-Method
can	O
be	O
optimized	O
over	O
as	O
well	O
since	O
for	O
common	O
distributions	O
it	O
has	O
a	O
simple	O
analytical	O
form	O
.	O
	
However	O
,	O
in	O
this	O
paper	O
we	O
opt	O
for	O
simplicity	O
by	O
fixing	O
the	O
latent	O
code	O
distribution	O
and	O
we	O
will	O
treat	O
H	O
(	O
c	O
)	O
as	O
a	O
constant	O
.	O
	
So	O
far	O
we	O
have	O
bypassed	O
the	O
problem	O
of	O
having	O
to	O
compute	O
the	O
posterior	O
P	O
(	O
c|x	O
)	O
explicitly	O
via	O
this	O
lower	O
bound	O
but	O
we	O
still	O
need	O
to	O
be	O
able	O
to	O
sample	O
from	O
the	O
posterior	O
in	O
the	O
inner	O
expectation	O
.	O
	
Next	O
we	O
state	O
a	O
simple	O
lemma	O
,	O
with	O
its	O
proof	O
deferred	O
to	O
Appendix	O
,	O
that	O
removes	O
the	O
need	O
to	O
sample	O
from	O
the	O
posterior	O
.	O
	
Lemma	O
5.1	O
For	O
random	O
variables	O
X	O
,	O
Y	O
and	O
function	O
f	O
(	O
x	O
,	O
y	O
)	O
under	O
suitable	O
regularity	O
conditions	O
:	O
	
By	O
using	O
Lemma	O
A.1	O
,	O
we	O
can	O
define	O
a	O
variational	B-Metric
lower	I-Metric
bound	I-Metric
,	O
L	O
I	O
(	O
G	O
,	O
Q	O
)	O
,	O
of	O
the	O
mutual	B-Metric
information	I-Metric
,	O
	
We	O
note	O
that	O
L	O
I	O
(	O
G	O
,	O
Q	O
)	O
is	O
easy	O
to	O
approximate	O
with	O
Monte	B-Method
Carlo	I-Method
simulation	I-Method
.	O
	
In	O
particular	O
,	O
L	O
I	O
can	O
be	O
maximized	O
w.r.t	O
.	O
	
Q	O
directly	O
and	O
w.r.t	O
.	O
	
G	O
via	O
the	O
reparametrization	B-Method
trick	I-Method
.	O
	
Hence	O
L	O
I	O
(	O
G	O
,	O
Q	O
)	O
can	O
be	O
added	O
to	O
GAN	B-Method
's	I-Method
objectives	I-Method
with	O
no	O
change	O
to	O
GAN	B-Method
's	I-Method
training	I-Method
procedure	I-Method
and	O
we	O
call	O
the	O
resulting	O
algorithm	O
Information	B-Method
Maximizing	I-Method
Generative	I-Method
Adversarial	I-Method
Networks	I-Method
(	O
InfoGAN	B-Method
)	O
.	O
	
Eq	O
[	O
reference	O
]	O
shows	O
that	O
the	O
lower	O
bound	O
becomes	O
tight	O
as	O
the	O
auxiliary	O
distribution	O
Q	O
approaches	O
the	O
true	O
posterior	O
distribution	O
:	O
	
In	O
addition	O
,	O
we	O
know	O
that	O
when	O
the	O
variational	B-Metric
lower	I-Metric
bound	I-Metric
attains	O
its	O
maximum	O
L	O
I	O
(	O
G	O
,	O
Q	O
)	O
=	O
H	O
(	O
c	O
)	O
for	O
discrete	B-Method
latent	I-Method
codes	I-Method
,	O
the	O
bound	O
becomes	O
tight	O
and	O
the	O
maximal	B-Metric
mutual	I-Metric
information	I-Metric
is	O
achieved	O
.	O
	
In	O
Appendix	O
,	O
we	O
note	O
how	O
InfoGAN	B-Method
can	O
be	O
connected	O
to	O
the	O
Wake	B-Method
-	I-Method
Sleep	I-Method
algorithm	I-Method
[	O
reference	O
]	O
to	O
provide	O
an	O
alternative	O
interpretation	O
.	O
	
Hence	O
,	O
InfoGAN	B-Method
is	O
defined	O
as	O
the	O
following	O
minimax	B-Method
game	I-Method
with	O
a	O
variational	B-Method
regularization	I-Method
of	I-Method
mutual	I-Method
information	I-Method
and	O
a	O
hyperparameter	O
λ	O
:	O
	
6	O
Implementation	O
	
In	O
practice	O
,	O
we	O
parametrize	O
the	O
auxiliary	B-Method
distribution	I-Method
Q	I-Method
as	O
a	O
neural	B-Method
network	I-Method
.	O
	
In	O
most	O
experiments	O
,	O
Q	O
and	O
D	O
share	O
all	O
convolutional	B-Method
layers	I-Method
and	O
there	O
is	O
one	O
final	O
fully	B-Method
connected	I-Method
layer	I-Method
to	O
output	O
parameters	O
for	O
the	O
conditional	O
distribution	O
Q	O
(	O
c|x	O
)	O
,	O
which	O
means	O
InfoGAN	B-Method
only	O
adds	O
a	O
negligible	B-Metric
computation	I-Metric
cost	I-Metric
to	O
GAN	B-Method
.	O
	
We	O
have	O
also	O
observed	O
that	O
L	O
I	O
(	O
G	O
,	O
Q	O
)	O
always	O
converges	O
faster	O
than	O
normal	B-Method
GAN	I-Method
objectives	I-Method
and	O
hence	O
InfoGAN	B-Method
essentially	O
comes	O
for	O
free	O
with	O
GAN	B-Method
.	O
	
For	O
categorical	O
latent	O
code	O
c	O
i	O
,	O
we	O
use	O
the	O
natural	O
choice	O
of	O
softmax	O
nonlinearity	O
to	O
represent	O
Q	O
(	O
c	O
i	O
|x	O
)	O
.	O
	
For	O
continuous	O
latent	O
code	O
c	O
	
j	O
,	O
there	O
are	O
more	O
options	O
depending	O
on	O
what	O
is	O
the	O
true	O
posterior	O
P	O
(	O
c	O
j	O
	
|x	O
)	O
.	O
	
In	O
our	O
experiments	O
,	O
we	O
have	O
found	O
that	O
simply	O
treating	O
Q	O
(	O
c	O
j	O
|x	O
)	O
as	O
a	O
factored	B-Method
Gaussian	I-Method
is	O
sufficient	O
.	O
	
Even	O
though	O
InfoGAN	B-Method
introduces	O
an	O
extra	O
hyperparameter	O
λ	O
,	O
it	O
's	O
easy	O
to	O
tune	O
and	O
simply	O
setting	O
to	O
1	O
is	O
sufficient	O
for	O
discrete	O
latent	O
codes	O
.	O
	
When	O
the	O
latent	O
code	O
contains	O
continuous	O
variables	O
,	O
a	O
smaller	O
λ	O
is	O
typically	O
used	O
to	O
ensure	O
that	O
λL	O
	
I	O
(	O
G	O
,	O
Q	O
)	O
,	O
which	O
now	O
involves	O
differential	O
entropy	O
,	O
is	O
on	O
the	O
same	O
scale	O
as	O
GAN	O
objectives	O
.	O
	
Since	O
GAN	B-Method
is	O
known	O
to	O
be	O
difficult	O
to	O
train	O
,	O
we	O
design	O
our	O
experiments	O
based	O
on	O
existing	O
techniques	O
introduced	O
by	O
DC	B-Method
-	I-Method
GAN	I-Method
[	O
reference	O
]	O
,	O
which	O
are	O
enough	O
to	O
stabilize	O
InfoGAN	B-Method
training	O
and	O
we	O
did	O
not	O
have	O
to	O
introduce	O
new	O
trick	O
.	O
	
Detailed	O
experimental	O
setup	O
is	O
described	O
in	O
Appendix	O
.	O
	
section	O
:	O
Experiments	O
	
The	O
first	O
goal	O
of	O
our	O
experiments	O
is	O
to	O
investigate	O
if	O
mutual	B-Metric
information	I-Metric
can	O
be	O
maximized	O
efficiently	O
.	O
	
The	O
second	O
goal	O
is	O
to	O
evaluate	O
if	O
InfoGAN	B-Method
can	O
learn	O
disentangled	O
and	O
interpretable	B-Method
representations	I-Method
by	O
making	O
use	O
of	O
the	O
generator	O
to	O
vary	O
only	O
one	O
latent	O
factor	O
at	O
a	O
time	O
in	O
order	O
to	O
assess	O
if	O
varying	O
such	O
factor	O
results	O
in	O
only	O
one	O
type	O
of	O
semantic	O
variation	O
in	O
generated	O
images	O
.	O
	
DC	B-Method
-	I-Method
IGN	I-Method
[	O
reference	O
]	O
also	O
uses	O
this	O
method	O
to	O
evaluate	O
their	O
learned	O
representations	O
on	O
3D	O
image	O
datasets	O
,	O
on	O
which	O
we	O
also	O
apply	O
InfoGAN	B-Method
to	O
establish	O
direct	O
comparison	O
.	O
	
To	O
evaluate	O
whether	O
the	O
mutual	O
information	O
between	O
latent	O
codes	O
c	O
and	O
generated	O
images	O
G	O
(	O
z	O
,	O
c	O
)	O
can	O
be	O
maximized	O
efficiently	O
with	O
proposed	O
method	O
,	O
we	O
train	O
InfoGAN	B-Method
on	O
MNIST	B-Material
dataset	I-Material
with	O
a	O
uniform	O
categorical	O
distribution	O
on	O
latent	O
codes	O
c	O
∼	O
Cat	O
(	O
K	O
	
=	O
10	O
,	O
p	O
=	O
0.1	O
)	O
.	O
	
In	O
Fig	O
1	O
,	O
the	O
lower	O
bound	O
L	O
I	O
(	O
G	O
,	O
Q	O
)	O
is	O
quickly	O
maximized	O
to	O
H	O
(	O
c	O
)	O
≈	O
2.30	O
,	O
which	O
means	O
the	O
bound	O
(	O
4	O
)	O
is	O
tight	O
and	O
maximal	O
mutual	O
information	O
is	O
achieved	O
.	O
	
section	O
:	O
Mutual	B-Task
Information	I-Task
Maximization	I-Task
	
As	O
a	O
baseline	O
,	O
we	O
also	O
train	O
a	O
regular	B-Method
GAN	I-Method
with	O
an	O
auxiliary	O
distribution	O
Q	O
when	O
the	O
generator	B-Method
is	O
not	O
explicitly	O
encouraged	O
to	O
maximize	O
the	O
mutual	O
information	O
with	O
the	O
latent	O
codes	O
.	O
	
Since	O
we	O
use	O
expressive	B-Method
neural	I-Method
network	I-Method
to	O
parametrize	O
Q	O
,	O
we	O
can	O
assume	O
that	O
Q	O
reasonably	O
approximates	O
the	O
true	O
posterior	O
P	O
(	O
c|x	O
)	O
and	O
hence	O
there	O
is	O
little	O
mutual	O
information	O
between	O
latent	O
codes	O
and	O
generated	O
images	O
in	O
regular	B-Method
GAN	I-Method
.	O
	
We	O
note	O
that	O
with	O
a	O
different	O
neural	B-Method
network	I-Method
architecture	I-Method
,	O
there	O
might	O
be	O
a	O
higher	O
mutual	O
information	O
between	O
latent	O
codes	O
and	O
generated	O
images	O
even	O
though	O
we	O
have	O
not	O
observed	O
such	O
case	O
in	O
our	O
experiments	O
.	O
	
This	O
comparison	O
is	O
meant	O
to	O
demonstrate	O
that	O
in	O
a	O
regular	B-Method
GAN	I-Method
,	O
there	O
is	O
no	O
guarantee	O
that	O
the	O
generator	B-Method
will	O
make	O
use	O
of	O
the	O
latent	O
codes	O
.	O
	
section	O
:	O
Disentangled	B-Method
Representation	I-Method
	
To	O
disentangle	O
digit	O
shape	O
from	O
styles	O
on	O
MNIST	B-Material
,	O
we	O
choose	O
to	O
model	O
the	O
latent	O
codes	O
with	O
one	O
categorical	O
code	O
,	O
c	O
1	O
∼	O
Cat	O
(	O
K	O
=	O
10	O
,	O
p	O
=	O
0.1	O
)	O
,	O
which	O
can	O
model	O
discontinuous	O
variation	O
in	O
data	O
,	O
and	O
two	O
continuous	B-Method
codes	I-Method
that	O
can	O
capture	O
variations	O
that	O
are	O
continuous	O
in	O
nature	O
:	O
c	O
2	O
,	O
c	O
3	O
∼	O
Unif	O
(	O
−1	O
,	O
1	O
)	O
.	O
	
In	O
Figure	O
2	O
,	O
we	O
show	O
that	O
the	O
discrete	B-Method
code	I-Method
c	I-Method
1	I-Method
captures	O
drastic	O
change	O
in	O
shape	O
.	O
	
Changing	O
categorical	O
code	O
c	O
1	O
switches	O
between	O
digits	O
most	O
of	O
the	O
time	O
.	O
	
In	O
fact	O
even	O
if	O
we	O
just	O
train	O
InfoGAN	B-Method
without	O
any	O
label	O
,	O
c	O
1	O
can	O
be	O
used	O
as	O
a	O
classifier	B-Method
that	O
achieves	O
5	O
%	O
error	B-Metric
rate	I-Metric
in	O
classifying	O
MNIST	B-Material
digits	O
by	O
matching	O
each	O
category	O
in	O
c	O
1	O
to	O
a	O
digit	O
type	O
.	O
	
In	O
the	O
second	O
row	O
of	O
Figure	O
2a	O
,	O
we	O
can	O
observe	O
a	O
digit	O
7	O
is	O
classified	O
as	O
a	O
9	O
.	O
	
Continuous	B-Method
codes	I-Method
	
c	O
2	O
,	O
c	O
3	O
capture	O
continuous	O
variations	O
in	O
style	O
:	O
c	O
2	O
models	O
rotation	O
of	O
digits	O
and	O
c	O
3	O
controls	O
the	O
width	O
.	O
	
What	O
is	O
remarkable	O
is	O
that	O
in	O
both	O
cases	O
,	O
the	O
generator	O
does	O
not	O
simply	O
stretch	O
or	O
rotate	O
the	O
digits	O
but	O
instead	O
adjust	O
other	O
details	O
like	O
thickness	O
or	O
stroke	O
style	O
to	O
make	O
sure	O
the	O
resulting	O
images	O
are	O
natural	O
looking	O
.	O
	
As	O
a	O
test	O
to	O
check	O
whether	O
the	O
latent	B-Method
representation	I-Method
learned	O
by	O
InfoGAN	B-Method
is	O
generalizable	O
,	O
we	O
manipulated	O
the	O
latent	O
codes	O
in	O
an	O
exaggerated	O
way	O
:	O
instead	O
of	O
plotting	O
latent	O
codes	O
from	O
−1	O
to	O
1	O
,	O
we	O
plot	O
it	O
from	O
−2	O
to	O
2	O
covering	O
a	O
wide	O
region	O
that	O
the	O
network	O
was	O
never	O
trained	O
on	O
	
and	O
we	O
still	O
get	O
meaningful	O
generalization	B-Task
.	O
	
Next	O
we	O
evaluate	O
InfoGAN	B-Method
on	O
two	O
datasets	O
of	O
3D	O
images	O
:	O
faces	O
[	O
reference	O
]	O
and	O
chairs	O
[	O
reference	O
]	O
,	O
on	O
which	O
DC	B-Method
-	I-Method
IGN	I-Method
was	O
shown	O
to	O
learn	O
highly	O
interpretable	O
graphics	O
codes	O
.	O
	
On	O
the	O
faces	O
dataset	O
,	O
DC	B-Method
-	I-Method
IGN	I-Method
learns	O
to	O
represent	O
latent	O
factors	O
as	O
azimuth	O
(	O
pose	O
)	O
,	O
elevation	O
,	O
and	O
lighting	O
as	O
continuous	O
latent	O
variables	O
by	O
using	O
supervision	O
.	O
	
Using	O
the	O
same	O
dataset	O
,	O
we	O
demonstrate	O
that	O
InfoGAN	B-Method
learns	O
a	O
disentangled	B-Method
representation	I-Method
that	O
recover	O
azimuth	O
(	O
pose	O
)	O
,	O
elevation	O
,	O
and	O
lighting	O
on	O
the	O
same	O
dataset	O
.	O
	
In	O
this	O
experiment	O
,	O
we	O
choose	O
to	O
model	O
the	O
latent	O
codes	O
with	O
five	O
continuous	O
codes	O
,	O
c	O
i	O
∼	O
Unif	O
(	O
−1	O
,	O
1	O
)	O
with	O
1	O
≤	O
i	O
≤	O
5	O
.	O
	
Since	O
DC	B-Method
-	I-Method
IGN	I-Method
requires	O
supervision	O
,	O
it	O
was	O
previously	O
not	O
possible	O
to	O
learn	O
a	O
latent	O
code	O
for	O
a	O
variation	O
that	O
's	O
unlabeled	O
and	O
hence	O
salient	O
latent	O
factors	O
of	O
variation	O
can	O
not	O
be	O
discovered	O
automatically	O
from	O
data	O
.	O
	
By	O
contrast	O
,	O
InfoGAN	B-Method
is	O
able	O
to	O
discover	O
such	O
variation	O
on	O
its	O
own	O
:	O
for	O
instance	O
,	O
in	O
Figure	O
3d	O
latent	O
code	O
that	O
smoothly	O
changes	O
a	O
face	O
from	O
wide	O
to	O
narrow	O
is	O
learned	O
even	O
though	O
this	O
variation	O
was	O
neither	O
explicitly	O
generated	O
or	O
labeled	O
in	O
prior	O
work	O
.	O
	
On	O
the	O
chairs	O
dataset	O
,	O
DC	B-Method
-	I-Method
IGN	I-Method
can	O
learn	O
a	O
continuous	B-Method
code	I-Method
that	O
representes	O
rotation	O
.	O
	
InfoGAN	B-Method
again	O
is	O
able	O
to	O
learn	O
the	O
same	O
concept	O
as	O
a	O
continuous	O
code	O
(	O
Figure	O
4a	O
)	O
and	O
we	O
show	O
in	O
addition	O
that	O
InfoGAN	B-Method
is	O
also	O
able	O
to	O
continuously	O
interpolate	O
between	O
similar	O
chair	O
types	O
of	O
different	O
widths	O
using	O
a	O
single	O
continuous	B-Method
code	I-Method
(	O
Figure	O
4b	O
)	O
.	O
	
In	O
this	O
experiment	O
,	O
we	O
choose	O
to	O
model	O
the	O
latent	O
factors	O
with	O
four	O
categorical	O
codes	O
,	O
c	O
1	O
,	O
c	O
2	O
,	O
c	O
3	O
,	O
c	O
4	O
∼	O
Cat	O
(	O
K	O
=	O
20	O
,	O
p	O
=	O
0.05	O
)	O
and	O
one	O
continuous	O
code	O
c	O
5	O
∼	O
Unif	O
(	O
−1	O
,	O
1	O
)	O
.	O
	
Next	O
we	O
evaluate	O
InfoGAN	B-Method
on	O
the	O
Street	O
View	O
House	O
Number	O
(	O
SVHN	O
)	O
dataset	O
,	O
which	O
is	O
significantly	O
more	O
challenging	O
to	O
learn	O
an	O
interpretable	B-Method
representation	I-Method
because	O
it	O
is	O
noisy	O
,	O
containing	O
images	O
of	O
variable	O
-	O
resolution	O
and	O
distracting	O
digits	O
,	O
and	O
it	O
does	O
not	O
have	O
multiple	O
variations	O
of	O
the	O
same	O
object	O
.	O
	
In	O
this	O
experiment	O
,	O
we	O
make	O
use	O
of	O
four	O
10−dimensional	O
categorical	O
variables	O
and	O
two	O
uniform	O
continuous	O
variables	O
as	O
latent	O
codes	O
.	O
	
We	O
show	O
two	O
of	O
the	O
learned	O
latent	O
factors	O
in	O
Figure	O
5	O
.	O
	
Finally	O
we	O
show	O
in	O
Figure	O
6	O
that	O
InfoGAN	B-Method
is	O
able	O
to	O
learn	O
many	O
visual	O
concepts	O
on	O
another	O
challenging	O
dataset	O
:	O
CelebA	O
[	O
reference	O
]	O
,	O
which	O
includes	O
200	O
,	O
000	O
celebrity	O
images	O
with	O
large	O
pose	O
variations	O
and	O
background	O
clutter	O
.	O
	
In	O
this	O
dataset	O
,	O
we	O
model	O
the	O
latent	O
variation	O
as	O
10	O
uniform	O
categorical	O
variables	O
,	O
each	O
of	O
dimension	O
10	O
.	O
	
Surprisingly	O
,	O
even	O
in	O
this	O
complicated	O
dataset	O
,	O
InfoGAN	B-Method
can	O
recover	O
azimuth	O
as	O
in	O
3D	O
images	O
even	O
though	O
in	O
this	O
dataset	O
no	O
single	O
face	O
appears	O
in	O
multiple	O
pose	O
positions	O
.	O
	
Moreover	O
InfoGAN	B-Method
can	O
disentangle	O
other	O
highly	O
semantic	O
variations	O
like	O
presence	O
or	O
absence	O
of	O
glasses	O
,	O
hairstyles	O
and	O
emotion	O
,	O
demonstrating	O
a	O
level	O
of	O
visual	B-Task
understanding	I-Task
is	O
acquired	O
without	O
any	O
supervision	O
.	O
	
,	O
we	O
show	O
that	O
the	O
continuous	B-Method
code	I-Method
can	O
alternatively	O
learn	O
to	O
capture	O
the	O
widths	O
of	O
different	O
chair	O
types	O
,	O
and	O
smoothly	O
interpolate	O
between	O
them	O
.	O
	
For	O
each	O
factor	O
,	O
we	O
present	O
the	O
representation	O
that	O
most	O
resembles	O
prior	O
supervised	O
results	O
[	O
reference	O
]	O
out	O
of	O
5	O
random	O
runs	O
to	O
provide	O
direct	O
comparison	O
.	O
	
section	O
:	O
Conclusion	O
	
This	O
paper	O
introduces	O
a	O
representation	B-Method
learning	I-Method
algorithm	I-Method
called	O
Information	B-Method
Maximizing	I-Method
Generative	I-Method
Adversarial	I-Method
Networks	I-Method
(	O
InfoGAN	B-Method
)	O
.	O
	
In	O
contrast	O
to	O
previous	O
approaches	O
,	O
which	O
require	O
supervision	O
,	O
InfoGAN	B-Method
is	O
completely	O
unsupervised	O
and	O
learns	O
interpretable	B-Method
and	I-Method
disentangled	I-Method
representations	I-Method
on	O
challenging	O
datasets	O
.	O
	
In	O
addition	O
,	O
InfoGAN	B-Method
adds	O
only	O
negligible	B-Metric
computation	I-Metric
cost	I-Metric
on	O
top	O
of	O
GAN	B-Method
and	O
is	O
easy	O
to	O
train	O
.	O
	
The	O
core	O
idea	O
of	O
using	O
mutual	O
information	O
to	O
induce	B-Task
representation	I-Task
can	O
be	O
applied	O
to	O
other	O
methods	O
like	O
VAE	B-Method
[	O
reference	O
]	O
,	O
which	O
is	O
a	O
promising	O
area	O
of	O
future	O
work	O
.	O
	
Other	O
possible	O
extensions	O
to	O
this	O
work	O
include	O
:	O
learning	O
hierarchical	B-Method
latent	I-Method
representations	I-Method
,	O
improving	O
semi	B-Method
-	I-Method
supervised	I-Method
learning	I-Method
with	O
better	O
codes	O
[	O
reference	O
]	O
,	O
and	O
using	O
InfoGAN	B-Method
as	O
a	O
high	B-Method
-	I-Method
dimensional	I-Method
data	I-Method
discovery	I-Method
tool	I-Method
.	O
	
A	O
Proof	O
of	O
Lemma	O
5.1	O
	
Lemma	O
A.1	O
	
For	O
random	O
variables	O
X	O
,	O
Y	O
and	O
function	O
f	O
(	O
x	O
,	O
y	O
)	O
under	O
suitable	O
regularity	O
conditions	O
:	O
	
B	O
Interpretation	O
as	O
"	O
Sleep	B-Method
-	I-Method
Sleep	I-Method
"	I-Method
Algorithm	I-Method
	
We	O
note	O
that	O
InfoGAN	B-Method
can	O
be	O
viewed	O
as	O
a	O
Helmholtz	B-Method
machine	I-Method
[	O
reference	O
]	O
:	O
P	O
G	O
(	O
x|c	O
)	O
is	O
the	O
generative	B-Method
distribution	I-Method
and	O
Q	B-Method
(	I-Method
c|x	I-Method
)	O
is	O
the	O
recognition	B-Method
distribution	I-Method
.	O
	
Wake	B-Method
-	I-Method
Sleep	I-Method
algorithm	I-Method
[	O
reference	O
]	O
was	O
proposed	O
to	O
train	O
Helmholtz	B-Method
machines	I-Method
by	O
performing	O
"	O
wake	O
"	O
phase	O
and	O
"	O
sleep	O
"	O
phase	O
updates	O
.	O
	
The	O
"	O
wake	B-Method
"	I-Method
phase	I-Method
update	I-Method
proceeds	O
by	O
optimizing	O
the	O
variational	O
lower	O
bound	O
of	O
log	O
P	O
G	O
(	O
x	O
)	O
w.r.t	O
.	O
generator	O
:	O
max	O
	
The	O
"	O
sleep	O
"	O
phase	O
updates	O
the	O
auxiliary	B-Method
distribution	I-Method
Q	I-Method
by	O
"	O
dreaming	O
"	O
up	O
samples	O
from	O
current	O
generator	B-Method
distribution	I-Method
rather	O
than	O
drawing	O
from	O
real	B-Method
data	I-Method
distribution	I-Method
:	O
	
Hence	O
we	O
can	O
see	O
that	O
when	O
we	O
optimize	O
the	O
surrogate	O
loss	O
	
L	O
	
I	O
w.r.t	O
.	O
	
Q	O
,	O
the	O
update	B-Method
step	I-Method
is	O
exactly	O
the	O
"	O
sleep	B-Method
"	I-Method
phase	I-Method
update	I-Method
in	O
Wake	B-Method
-	I-Method
Sleep	I-Method
algorithm	I-Method
.	O
	
InfoGAN	B-Method
differs	O
from	O
Wake	O
-	O
Sleep	O
when	O
we	O
optimize	O
L	O
I	O
	
w.r.t	O
.	O
	
G	O
,	O
encouraging	O
the	O
generator	B-Method
network	I-Method
G	I-Method
to	O
make	O
use	O
of	O
latent	O
codes	O
c	O
for	O
the	O
whole	O
prior	O
distribution	O
on	O
latent	O
codes	O
P	O
(	O
c	O
)	O
.	O
	
Since	O
InfoGAN	B-Method
also	O
updates	O
generator	O
in	O
"	O
sleep	O
"	O
phase	O
,	O
our	O
method	O
can	O
be	O
interpreted	O
as	O
"	O
Sleep	B-Method
-	I-Method
Sleep	I-Method
"	I-Method
algorithm	I-Method
.	O
	
This	O
interpretation	O
highlights	O
InfoGAN	B-Method
's	O
difference	O
from	O
previous	O
generative	B-Method
modeling	I-Method
techniques	I-Method
:	O
the	O
generator	B-Method
is	O
explicitly	O
encouraged	O
to	O
convey	O
information	O
in	O
latent	O
codes	O
and	O
suggests	O
that	O
the	O
same	O
principle	O
can	O
be	O
applied	O
to	O
other	O
generative	B-Method
models	I-Method
.	O
	
section	O
:	O
C	O
Experiment	O
Setup	O
	
For	O
all	O
experiments	O
,	O
we	O
use	O
Adam	B-Method
[	O
reference	O
]	O
for	O
online	B-Task
optimization	I-Task
and	O
apply	O
batch	B-Method
normalization	I-Method
[	O
reference	O
]	O
after	O
most	O
layers	O
,	O
the	O
details	O
of	O
which	O
are	O
specified	O
for	O
each	O
experiment	O
.	O
	
We	O
use	O
an	O
up	B-Method
-	I-Method
convolutional	I-Method
architecture	I-Method
for	O
the	O
generator	B-Method
networks	I-Method
	
[	O
reference	O
]	O
.	O
	
We	O
use	O
leaky	B-Method
rectified	I-Method
linear	I-Method
units	I-Method
(	O
lRELU	B-Method
)	O
	
[	O
reference	O
]	O
with	O
leaky	O
rate	O
0.1	O
as	O
the	O
nonlinearity	O
applied	O
to	O
hidden	O
layers	O
of	O
the	O
discrminator	B-Method
networks	I-Method
,	O
and	O
normal	B-Method
rectified	I-Method
linear	I-Method
units	I-Method
(	O
RELU	B-Method
)	O
for	O
the	O
generator	B-Method
networks	I-Method
.	O
	
Unless	O
noted	O
otherwise	O
,	O
learning	B-Metric
rate	I-Metric
is	O
2e	O
-	O
4	O
for	O
D	O
and	O
1e	O
-	O
3	O
for	O
G	O
;	O
λ	O
is	O
set	O
to	O
1	O
.	O
	
For	O
discrete	O
latent	O
codes	O
,	O
we	O
apply	O
a	O
softmax	O
nonlinearity	O
over	O
the	O
corresponding	O
units	O
in	O
the	O
recognition	B-Method
network	I-Method
output	O
.	O
	
For	O
continuous	O
latent	O
codes	O
,	O
we	O
parameterize	O
the	O
approximate	O
posterior	O
through	O
a	O
diagonal	B-Method
Gaussian	I-Method
distribution	I-Method
,	O
and	O
the	O
recognition	B-Method
network	I-Method
outputs	O
its	O
mean	O
and	O
standard	O
deviation	O
,	O
where	O
the	O
standard	O
deviation	O
is	O
parameterized	O
through	O
an	O
exponential	B-Method
transformation	I-Method
of	O
the	O
network	O
output	O
to	O
ensure	O
positivity	O
.	O
	
The	O
details	O
for	O
each	O
set	O
of	O
experiments	O
are	O
presented	O
below	O
.	O
	
section	O
:	O
C.1	O
MNIST	B-Material
	
The	O
network	B-Method
architectures	I-Method
are	O
shown	O
in	O
Table	O
1	O
.	O
	
The	O
discriminator	B-Method
D	I-Method
and	O
the	O
recognition	B-Method
network	I-Method
Q	I-Method
shares	O
most	O
of	O
the	O
network	O
.	O
	
For	O
this	O
task	O
,	O
we	O
use	O
1	O
ten	O
-	O
dimensional	O
categorical	O
code	O
,	O
2	O
continuous	O
latent	O
codes	O
and	O
62	O
noise	O
variables	O
,	O
resulting	O
in	O
a	O
concatenated	O
dimension	O
of	O
74	O
.	O
	
section	O
:	O
C.2	O
SVHN	O
	
The	O
network	B-Method
architectures	I-Method
are	O
shown	O
in	O
Table	O
2	O
.	O
	
The	O
discriminator	B-Method
D	I-Method
and	O
the	O
recognition	B-Method
network	I-Method
Q	I-Method
shares	O
most	O
of	O
the	O
network	O
.	O
	
For	O
this	O
task	O
,	O
we	O
use	O
4	O
ten	O
-	O
dimensional	O
categorical	O
code	O
,	O
4	O
continuous	O
latent	O
codes	O
and	O
124	O
noise	O
variables	O
,	O
resulting	O
in	O
a	O
concatenated	O
dimension	O
of	O
168	O
.	O
	
section	O
:	O
C.3	O
CelebA	O
	
The	O
network	B-Method
architectures	I-Method
are	O
shown	O
in	O
Table	O
3	O
.	O
	
The	O
discriminator	B-Method
D	I-Method
and	O
the	O
recognition	B-Method
network	I-Method
Q	I-Method
shares	O
most	O
of	O
the	O
network	O
.	O
	
For	O
this	O
task	O
,	O
we	O
use	O
10	O
ten	O
-	O
dimensional	O
categorical	O
code	O
and	O
128	O
noise	O
variables	O
,	O
resulting	O
in	O
a	O
concatenated	O
dimension	O
of	O
228	O
.	O
	
section	O
:	O
C.4	O
Faces	O
	
The	O
network	B-Method
architectures	I-Method
are	O
shown	O
in	O
Table	O
4	O
.	O
	
The	O
discriminator	B-Method
D	I-Method
and	O
the	O
recognition	B-Method
network	I-Method
Q	I-Method
shares	O
the	O
same	O
network	O
,	O
and	O
only	O
have	O
separate	O
output	O
units	O
at	O
the	O
last	O
layer	O
.	O
	
For	O
this	O
task	O
,	O
we	O
use	O
5	O
continuous	O
latent	O
codes	O
and	O
128	O
noise	O
variables	O
,	O
so	O
the	O
input	O
to	O
the	O
generator	O
has	O
dimension	O
133	O
.	O
	
We	O
used	O
separate	O
configurations	O
for	O
each	O
learned	O
variation	O
,	O
shown	O
in	O
Table	O
5	O
.	O
	
section	O
:	O
C.5	O
Chairs	O
	
The	O
network	B-Method
architectures	I-Method
are	O
shown	O
in	O
Table	O
6	O
.	O
	
The	O
discriminator	B-Method
D	I-Method
and	O
the	O
recognition	B-Method
network	I-Method
Q	I-Method
shares	O
the	O
same	O
network	O
,	O
and	O
only	O
have	O
separate	O
output	O
units	O
at	O
the	O
last	O
layer	O
.	O
	
For	O
this	O
task	O
,	O
we	O
use	O
1	O
continuous	O
latent	O
code	O
,	O
3	O
discrete	B-Method
latent	I-Method
codes	I-Method
(	O
each	O
with	O
dimension	O
20	O
)	O
,	O
and	O
128	O
noise	O
variables	O
,	O
so	O
the	O
input	O
to	O
the	O
generator	O
has	O
dimension	O
189	O
.	O
	
section	O
:	O
	
section	O
:	O
	
We	O
used	O
separate	O
configurations	O
for	O
each	O
learned	O
variation	O
,	O
shown	O
in	O
Table	O
7	O
.	O
	
For	O
this	O
task	O
,	O
we	O
found	O
it	O
necessary	O
to	O
use	O
different	O
regularization	O
coefficients	O
for	O
the	O
continuous	O
and	O
discrete	O
latent	O
codes	O
.	O
	
section	O
:	O
	
document	O
:	O
Bag	B-Method
of	I-Method
Tricks	I-Method
for	O
Efficient	O
Text	B-Task
Classification	I-Task
	
This	O
paper	O
explores	O
a	O
simple	O
and	O
efficient	O
baseline	O
for	O
text	B-Task
classification	I-Task
.	O
	
Our	O
experiments	O
show	O
that	O
our	O
fast	O
text	O
classifier	O
fastText	B-Method
is	O
often	O
on	O
par	O
with	O
deep	B-Method
learning	I-Method
classifiers	I-Method
in	O
terms	O
of	O
accuracy	B-Metric
,	O
and	O
many	O
orders	O
of	O
magnitude	O
faster	O
for	O
training	B-Task
and	O
evaluation	B-Task
.	O
	
We	O
can	O
train	O
fastText	B-Method
on	O
more	O
than	O
one	O
billion	O
words	O
in	O
less	O
than	O
ten	O
minutes	O
using	O
a	O
standard	O
multicore	B-Method
CPU	I-Method
,	O
and	O
classify	O
half	O
a	O
million	O
sentences	O
among	O
312	O
K	O
classes	O
in	O
less	O
than	O
a	O
minute	O
.	O
	
section	O
:	O
Introduction	O
	
Text	B-Task
classification	I-Task
is	O
an	O
important	O
task	O
in	O
Natural	B-Task
Language	I-Task
Processing	I-Task
with	O
many	O
applications	O
,	O
such	O
as	O
web	B-Task
search	I-Task
,	O
information	B-Task
retrieval	I-Task
,	O
ranking	B-Task
and	O
document	B-Task
classification	I-Task
.	O
	
Recently	O
,	O
models	O
based	O
on	O
neural	B-Method
networks	I-Method
have	O
become	O
increasingly	O
popular	O
.	O
	
While	O
these	O
models	O
achieve	O
very	O
good	O
performance	O
in	O
practice	O
,	O
they	O
tend	O
to	O
be	O
relatively	O
slow	O
both	O
at	O
train	B-Metric
and	I-Metric
test	I-Metric
time	I-Metric
,	O
limiting	O
their	O
use	O
on	O
very	O
large	O
datasets	O
.	O
	
Meanwhile	O
,	O
linear	B-Method
classifiers	I-Method
are	O
often	O
considered	O
as	O
strong	O
baselines	O
for	O
text	B-Task
classification	I-Task
problems	I-Task
.	O
	
Despite	O
their	O
simplicity	O
,	O
they	O
often	O
obtain	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performances	O
if	O
the	O
right	O
features	O
are	O
used	O
.	O
	
They	O
also	O
have	O
the	O
potential	O
to	O
scale	O
to	O
very	O
large	O
corpus	O
.	O
	
In	O
this	O
work	O
,	O
we	O
explore	O
ways	O
to	O
scale	O
these	O
baselines	O
to	O
very	O
large	O
corpus	O
with	O
a	O
large	O
output	O
space	O
,	O
in	O
the	O
context	O
of	O
text	B-Task
classification	I-Task
.	O
	
Inspired	O
by	O
the	O
recent	O
work	O
in	O
efficient	O
word	B-Task
representation	I-Task
learning	I-Task
,	O
we	O
show	O
that	O
linear	B-Method
models	I-Method
with	O
a	O
rank	O
constraint	O
and	O
a	O
fast	B-Method
loss	I-Method
approximation	I-Method
can	O
train	O
on	O
a	O
billion	O
words	O
within	O
ten	O
minutes	O
,	O
while	O
achieving	O
performance	O
on	O
par	O
with	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
.	O
	
We	O
evaluate	O
the	O
quality	O
of	O
our	O
approach	O
	
fastTexthttps:	O
//	O
github.com	O
/	O
facebookresearch	O
/	O
fastText	B-Method
on	O
two	O
different	O
tasks	O
,	O
namely	O
tag	B-Task
prediction	I-Task
and	O
sentiment	B-Task
analysis	I-Task
.	O
	
section	O
:	O
Model	O
architecture	O
	
A	O
simple	O
and	O
efficient	O
baseline	O
for	O
sentence	B-Task
classification	I-Task
is	O
to	O
represent	O
sentences	O
as	O
bag	O
of	O
words	O
(	O
BoW	B-Method
)	O
and	O
train	O
a	O
linear	B-Method
classifier	I-Method
,	O
e.g.	O
,	O
a	O
logistic	B-Method
regression	I-Method
or	O
an	O
SVM	B-Method
.	O
	
However	O
,	O
linear	B-Method
classifiers	I-Method
do	O
not	O
share	O
parameters	O
among	O
features	O
and	O
classes	O
.	O
	
This	O
possibly	O
limits	O
their	O
generalization	O
in	O
the	O
context	O
of	O
large	O
output	O
space	O
where	O
some	O
classes	O
have	O
very	O
few	O
examples	O
.	O
	
Common	O
solutions	O
to	O
this	O
problem	O
are	O
to	O
factorize	O
the	O
linear	B-Method
classifier	I-Method
into	O
low	O
rank	O
matrices	O
or	O
to	O
use	O
multilayer	B-Method
neural	I-Method
networks	I-Method
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
a	O
simple	O
linear	B-Method
model	I-Method
with	O
rank	O
constraint	O
.	O
	
The	O
first	O
weight	B-Method
matrix	I-Method
is	O
a	O
look	O
-	O
up	O
table	O
over	O
the	O
words	O
.	O
	
The	O
word	B-Method
representations	I-Method
are	O
then	O
averaged	O
into	O
a	O
text	B-Method
representation	I-Method
,	O
which	O
is	O
in	O
turn	O
fed	O
to	O
a	O
linear	B-Method
classifier	I-Method
.	O
	
The	O
text	B-Method
representation	I-Method
is	O
an	O
hidden	O
variable	O
which	O
can	O
be	O
potentially	O
be	O
reused	O
.	O
	
This	O
architecture	O
is	O
similar	O
to	O
the	O
cbow	B-Method
model	I-Method
of	O
mikolov2013efficient	O
,	O
where	O
the	O
middle	O
word	O
is	O
replaced	O
by	O
a	O
label	O
.	O
	
We	O
use	O
the	O
softmax	B-Method
function	I-Method
to	O
compute	O
the	O
probability	O
distribution	O
over	O
the	O
predefined	O
classes	O
.	O
	
For	O
a	O
set	O
of	O
documents	O
,	O
this	O
leads	O
to	O
minimizing	O
the	O
negative	O
log	O
-	O
likelihood	O
over	O
the	O
classes	O
:	O
where	O
is	O
the	O
normalized	O
bag	O
of	O
features	O
of	O
the	O
-	O
th	O
document	O
,	O
the	O
label	O
,	O
and	O
the	O
weight	O
matrices	O
.	O
	
This	O
model	O
is	O
trained	O
asynchronously	O
on	O
multiple	O
CPUs	B-Method
using	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
and	O
a	O
linearly	B-Method
decaying	I-Method
learning	I-Method
rate	I-Method
.	O
	
subsection	O
:	O
Hierarchical	B-Method
softmax	I-Method
	
hidden	O
output	O
	
When	O
the	O
number	O
of	O
classes	O
is	O
large	O
,	O
computing	O
the	O
linear	B-Method
classifier	I-Method
is	O
computationally	O
expensive	O
.	O
	
More	O
precisely	O
,	O
the	O
computational	B-Metric
complexity	I-Metric
is	O
where	O
is	O
the	O
number	O
of	O
classes	O
and	O
the	O
dimension	O
of	O
the	O
text	B-Method
representation	I-Method
.	O
	
In	O
order	O
to	O
improve	O
our	O
running	O
time	O
,	O
we	O
use	O
a	O
hierarchical	B-Method
softmax	I-Method
based	O
on	O
the	O
Huffman	B-Method
coding	I-Method
tree	I-Method
.	O
	
During	O
training	B-Task
,	O
the	O
computational	B-Metric
complexity	I-Metric
drops	O
to	O
.	O
	
The	O
hierarchical	B-Method
softmax	I-Method
is	O
also	O
advantageous	O
at	O
test	O
time	O
when	O
searching	O
for	O
the	O
most	O
likely	O
class	O
.	O
	
Each	O
node	O
is	O
associated	O
with	O
a	O
probability	O
that	O
is	O
the	O
probability	O
of	O
the	O
path	O
from	O
the	O
root	O
to	O
that	O
node	O
.	O
	
If	O
the	O
node	O
is	O
at	O
depth	O
with	O
parents	O
,	O
its	O
probability	O
is	O
	
This	O
means	O
that	O
the	O
probability	O
of	O
a	O
node	O
is	O
always	O
lower	O
than	O
the	O
one	O
of	O
its	O
parent	O
.	O
	
Exploring	O
the	O
tree	O
with	O
a	O
depth	B-Method
first	I-Method
search	I-Method
and	O
tracking	O
the	O
maximum	O
probability	O
among	O
the	O
leaves	O
allows	O
us	O
to	O
discard	O
any	O
branch	O
associated	O
with	O
a	O
small	O
probability	O
.	O
	
In	O
practice	O
,	O
we	O
observe	O
a	O
reduction	O
of	O
the	O
complexity	B-Metric
to	O
at	O
test	O
time	O
.	O
	
This	O
approach	O
is	O
further	O
extended	O
to	O
compute	O
the	O
-	O
top	O
targets	O
at	O
the	O
cost	O
of	O
,	O
using	O
a	O
binary	O
heap	O
.	O
	
subsection	O
:	O
N	B-Method
-	I-Method
gram	I-Method
features	I-Method
	
Bag	O
of	O
words	O
is	O
invariant	O
to	O
word	O
order	O
but	O
taking	O
explicitly	O
this	O
order	O
into	O
account	O
is	O
often	O
computationally	O
very	O
expensive	O
.	O
	
Instead	O
,	O
we	O
use	O
a	O
bag	B-Method
of	I-Method
n	I-Method
-	I-Method
grams	I-Method
as	O
additional	O
features	O
to	O
capture	O
some	O
partial	O
information	O
about	O
the	O
local	O
word	O
order	O
.	O
	
This	O
is	O
very	O
efficient	O
in	O
practice	O
while	O
achieving	O
comparable	O
results	O
to	O
methods	O
that	O
explicitly	O
use	O
the	O
order	O
.	O
	
We	O
maintain	O
a	O
fast	O
and	O
memory	O
efficient	O
mapping	O
of	O
the	O
n	O
-	O
grams	O
by	O
using	O
the	O
hashing	B-Method
trick	I-Method
with	O
the	O
same	O
hashing	O
function	O
as	O
in	O
mikolov2011strategies	O
and	O
10	O
M	O
bins	O
if	O
we	O
only	O
used	O
bigrams	O
,	O
and	O
100	O
M	O
otherwise	O
.	O
	
section	O
:	O
Experiments	O
	
We	O
evaluate	O
fastText	B-Method
on	O
two	O
different	O
tasks	O
.	O
	
First	O
,	O
we	O
compare	O
it	O
to	O
existing	O
text	B-Method
classifers	I-Method
on	O
the	O
problem	O
of	O
sentiment	B-Task
analysis	I-Task
.	O
	
Then	O
,	O
we	O
evaluate	O
its	O
capacity	O
to	O
scale	O
to	O
large	O
output	O
space	O
on	O
a	O
tag	B-Task
prediction	I-Task
dataset	I-Task
.	O
	
Note	O
that	O
our	O
model	O
could	O
be	O
implemented	O
with	O
the	O
Vowpal	B-Method
Wabbit	I-Method
library	I-Method
,	O
but	O
we	O
observe	O
in	O
practice	O
,	O
that	O
our	O
tailored	O
implementation	O
is	O
at	O
least	O
2	O
-	O
5	O
faster	O
.	O
	
subsection	O
:	O
Sentiment	B-Task
analysis	I-Task
	
paragraph	O
:	O
Datasets	O
and	O
baselines	O
.	O
	
We	O
employ	O
the	O
same	O
8	O
datasets	O
and	O
evaluation	O
protocol	O
of	O
zhang2015character	O
.	O
	
We	O
report	O
the	O
n	O
-	O
grams	O
and	O
TFIDF	B-Method
baselines	I-Method
from	O
zhang2015character	O
,	O
as	O
well	O
as	O
the	O
character	B-Method
level	I-Method
convolutional	I-Method
model	I-Method
(	O
char	B-Method
-	I-Method
CNN	I-Method
)	O
of	O
zhang2015text	O
,	O
the	O
character	B-Method
based	I-Method
convolution	I-Method
recurrent	I-Method
network	I-Method
(	O
char	B-Method
-	I-Method
CRNN	I-Method
)	O
of	O
and	O
the	O
very	B-Method
deep	I-Method
convolutional	I-Method
network	I-Method
(	O
VDCNN	B-Method
)	O
of	O
conneau2016	O
.	O
	
We	O
also	O
compare	O
to	O
tang2015document	O
following	O
their	O
evaluation	O
protocol	O
.	O
	
We	O
report	O
their	O
main	O
baselines	O
as	O
well	O
as	O
their	O
two	O
approaches	O
based	O
on	O
recurrent	B-Method
networks	I-Method
(	O
Conv	B-Method
-	I-Method
GRNN	I-Method
and	I-Method
LSTM	I-Method
-	I-Method
GRNN	I-Method
)	O
.	O
	
paragraph	O
:	O
Results	O
.	O
	
We	O
present	O
the	O
results	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
We	O
use	O
10	O
hidden	O
units	O
and	O
run	O
fastText	B-Method
for	O
5	O
epochs	O
with	O
a	O
learning	B-Metric
rate	I-Metric
selected	O
on	O
a	O
validation	O
set	O
from	O
0.05	O
,	O
0.1	O
,	O
0.25	O
,	O
0.5	O
.	O
	
On	O
this	O
task	O
,	O
adding	O
bigram	O
information	O
improves	O
the	O
performance	O
by	O
1	O
-	O
4	O
.	O
	
Overall	O
our	O
accuracy	B-Metric
is	O
slightly	O
better	O
than	O
char	B-Method
-	I-Method
CNN	I-Method
and	O
char	B-Method
-	I-Method
CRNN	I-Method
and	O
,	O
a	O
bit	O
worse	O
than	O
VDCNN	B-Method
.	O
	
Note	O
that	O
we	O
can	O
increase	O
the	O
accuracy	B-Metric
slightly	O
by	O
using	O
more	O
n	O
-	O
grams	O
,	O
for	O
example	O
with	O
trigrams	O
,	O
the	O
performance	O
on	O
Sogou	B-Method
goes	O
up	O
to	O
97.1	O
.	O
	
Finally	O
,	O
Figure	O
[	O
reference	O
]	O
shows	O
that	O
our	O
method	O
is	O
competitive	O
with	O
the	O
methods	O
presented	O
in	O
tang2015document	B-Method
.	O
	
We	O
tune	O
the	O
hyper	O
-	O
parameters	O
on	O
the	O
validation	O
set	O
and	O
observe	O
that	O
using	O
n	O
-	O
grams	O
up	O
to	O
5	O
leads	O
to	O
the	O
best	O
performance	O
.	O
	
Unlike	O
tang2015document	O
,	O
fastText	B-Method
does	O
not	O
use	O
pre	O
-	O
trained	O
word	O
embeddings	O
,	O
which	O
can	O
be	O
explained	O
the	O
1	O
difference	O
in	O
accuracy	B-Metric
.	O
	
paragraph	O
:	O
Training	B-Metric
time	I-Metric
.	O
	
Both	O
char	B-Method
-	I-Method
CNN	I-Method
and	O
VDCNN	B-Method
are	O
trained	O
on	O
a	O
NVIDIA	B-Method
Tesla	I-Method
K40	I-Method
GPU	I-Method
,	O
while	O
our	O
models	O
are	O
trained	O
on	O
a	O
CPU	B-Method
using	O
20	O
threads	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
that	O
methods	O
using	O
convolutions	B-Method
are	O
several	O
orders	O
of	O
magnitude	O
slower	O
than	O
fastText	B-Method
.	O
	
While	O
it	O
is	O
possible	O
to	O
have	O
a	O
10	O
speed	B-Metric
up	I-Metric
for	O
char	B-Method
-	I-Method
CNN	I-Method
by	O
using	O
more	O
recent	O
CUDA	B-Method
implementations	I-Method
of	O
convolutions	B-Method
,	O
fastText	B-Method
takes	O
less	O
than	O
a	O
minute	O
to	O
train	O
on	O
these	O
datasets	O
.	O
	
The	O
GRNNs	B-Method
method	I-Method
of	O
tang2015document	B-Method
takes	O
around	O
12	O
hours	O
per	O
epoch	O
on	O
CPU	O
with	O
a	O
single	O
thread	O
.	O
	
Our	O
speed	O
-	O
up	O
compared	O
to	O
neural	B-Method
network	I-Method
based	I-Method
methods	I-Method
increases	O
with	O
the	O
size	O
of	O
the	O
dataset	O
,	O
going	O
up	O
to	O
at	O
least	O
a	O
15	O
,	O
000	O
speed	O
-	O
up	O
.	O
	
subsection	O
:	O
Tag	B-Task
prediction	I-Task
	
paragraph	O
:	O
Dataset	O
and	O
baselines	O
.	O
	
To	O
test	O
scalability	O
of	O
our	O
approach	O
,	O
further	O
evaluation	O
is	O
carried	O
on	O
the	O
YFCC100	O
M	O
dataset	O
which	O
consists	O
of	O
almost	O
100	O
M	O
images	O
with	O
captions	O
,	O
titles	O
and	O
tags	O
.	O
	
We	O
focus	O
on	O
predicting	O
the	O
tags	O
according	O
to	O
the	O
title	O
and	O
caption	O
(	O
we	O
do	O
not	O
use	O
the	O
images	O
)	O
.	O
	
We	O
remove	O
the	O
words	O
and	O
tags	O
occurring	O
less	O
than	O
100	O
times	O
and	O
split	O
the	O
data	O
into	O
a	O
train	O
,	O
validation	O
and	O
test	O
set	O
.	O
	
The	O
train	O
set	O
contains	O
91	O
,	O
188	O
,	O
648	O
examples	O
(	O
1.5B	O
tokens	O
)	O
.	O
	
The	O
validation	O
has	O
930	O
,	O
497	O
examples	O
and	O
the	O
test	O
set	O
543	O
,	O
424	O
.	O
	
The	O
vocabulary	B-Metric
size	I-Metric
is	O
297	O
,	O
141	O
and	O
there	O
are	O
312	O
,	O
116	O
unique	O
tags	O
.	O
	
We	O
will	O
release	O
a	O
script	O
that	O
recreates	O
this	O
dataset	O
so	O
that	O
our	O
numbers	O
could	O
be	O
reproduced	O
.	O
	
We	O
report	O
precision	B-Metric
at	O
1	O
.	O
	
We	O
consider	O
a	O
frequency	B-Method
-	I-Method
based	I-Method
baseline	I-Method
which	O
predicts	O
the	O
most	O
frequent	O
tag	O
.	O
	
We	O
also	O
compare	O
with	O
Tagspace	B-Method
,	O
which	O
is	O
a	O
tag	B-Method
prediction	I-Method
model	I-Method
similar	O
to	O
ours	O
,	O
but	O
based	O
on	O
the	O
Wsabie	B-Method
model	I-Method
of	O
weston2011wsabie	O
.	O
	
While	O
the	O
Tagspace	B-Method
model	I-Method
is	O
described	O
using	O
convolutions	B-Method
,	O
we	O
consider	O
the	O
linear	B-Method
version	I-Method
,	O
which	O
achieves	O
comparable	O
performance	O
but	O
is	O
much	O
faster	O
.	O
	
paragraph	O
:	O
Results	O
and	O
training	O
time	O
.	O
	
Table	O
[	O
reference	O
]	O
presents	O
a	O
comparison	O
of	O
fastText	B-Method
and	O
the	O
baselines	O
.	O
	
We	O
run	O
fastText	B-Method
for	O
5	O
epochs	O
and	O
compare	O
it	O
to	O
Tagspace	O
for	O
two	O
sizes	O
of	O
the	O
hidden	O
layer	O
,	O
i.e.	O
,	O
50	O
and	O
200	O
.	O
	
Both	O
models	O
achieve	O
a	O
similar	O
performance	O
with	O
a	O
small	O
hidden	O
layer	O
,	O
but	O
adding	O
bigrams	B-Method
gives	O
us	O
a	O
significant	O
boost	O
in	O
accuracy	B-Metric
.	O
	
At	O
test	O
time	O
,	O
Tagspace	O
needs	O
to	O
compute	O
the	O
scores	O
for	O
all	O
the	O
classes	O
which	O
makes	O
it	O
relatively	O
slow	O
,	O
while	O
our	O
fast	B-Method
inference	I-Method
gives	O
a	O
significant	O
speed	O
-	O
up	O
when	O
the	O
number	O
of	O
classes	O
is	O
large	O
(	O
more	O
than	O
300	O
K	O
here	O
)	O
.	O
	
Overall	O
,	O
we	O
are	O
more	O
than	O
an	O
order	O
of	O
magnitude	O
faster	O
to	O
obtain	O
model	O
with	O
a	O
better	O
quality	O
.	O
	
The	O
speedup	O
of	O
the	O
test	B-Method
phase	I-Method
is	O
even	O
more	O
significant	O
(	O
a	O
600	O
speedup	O
)	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
some	O
qualitative	O
examples	O
.	O
	
section	O
:	O
Discussion	O
and	O
conclusion	O
	
In	O
this	O
work	O
,	O
we	O
propose	O
a	O
simple	O
baseline	O
method	O
for	O
text	B-Task
classification	I-Task
.	O
	
Unlike	O
unsupervisedly	B-Method
trained	I-Method
word	I-Method
vectors	I-Method
from	O
word2vec	B-Method
,	O
our	O
word	O
features	O
can	O
be	O
averaged	O
together	O
to	O
form	O
good	O
sentence	B-Method
representations	I-Method
.	O
	
In	O
several	O
tasks	O
,	O
fastText	B-Method
obtains	O
performance	O
on	O
par	O
with	O
recently	O
proposed	O
methods	O
inspired	O
by	O
deep	B-Method
learning	I-Method
,	O
while	O
being	O
much	O
faster	O
.	O
	
Although	O
deep	B-Method
neural	I-Method
networks	I-Method
have	O
in	O
theory	O
much	O
higher	O
representational	B-Method
power	I-Method
than	O
shallow	B-Method
models	I-Method
,	O
it	O
is	O
not	O
clear	O
if	O
simple	O
text	B-Task
classification	I-Task
problems	I-Task
such	O
as	O
sentiment	B-Task
analysis	I-Task
are	O
the	O
right	O
ones	O
to	O
evaluate	O
them	O
.	O
	
We	O
will	O
publish	O
our	O
code	O
so	O
that	O
the	O
research	O
community	O
can	O
easily	O
build	O
on	O
top	O
of	O
our	O
work	O
.	O
	
paragraph	O
:	O
Acknowledgement	O
.	O
	
We	O
thank	O
Gabriel	O
Synnaeve	O
,	O
Hervé	O
Gégou	O
,	O
Jason	O
Weston	O
and	O
Léon	O
Bottou	O
for	O
their	O
help	O
and	O
comments	O
.	O
	
We	O
also	O
thank	O
Alexis	O
Conneau	O
,	O
Duyu	O
Tang	O
and	O
Zichao	O
Zhang	O
for	O
providing	O
us	O
with	O
information	O
about	O
their	O
methods	O
.	O
	
bibliography	O
:	O
References	O
	
Learning	O
to	O
Compose	O
Task	O
-	O
Specific	O
Tree	O
Structures	O
	
section	O
:	O
Abstract	O
	
For	O
years	O
,	O
recursive	B-Method
neural	I-Method
networks	I-Method
(	O
RvNNs	B-Method
)	O
have	O
been	O
shown	O
to	O
be	O
suitable	O
for	O
representing	O
text	O
into	O
fixed	O
-	O
length	O
vectors	O
and	O
achieved	O
good	O
performance	O
on	O
several	O
natural	B-Task
language	I-Task
processing	I-Task
tasks	I-Task
.	O
	
However	O
,	O
the	O
main	O
drawback	O
of	O
RvNNs	B-Method
is	O
that	O
they	O
require	O
structured	O
input	O
,	O
which	O
makes	O
data	B-Task
preparation	I-Task
and	O
model	B-Task
implementation	I-Task
hard	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
Gumbel	B-Method
Tree	I-Method
-	I-Method
LSTM	I-Method
,	O
a	O
novel	O
tree	B-Method
-	I-Method
structured	I-Method
long	I-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
architecture	I-Method
that	O
learns	O
how	O
to	O
compose	O
task	O
-	O
specific	O
tree	O
structures	O
only	O
from	O
plain	O
text	O
data	O
efficiently	O
.	O
	
Our	O
model	O
uses	O
Straight	O
-	O
Through	O
Gumbel	B-Method
-	I-Method
Softmax	I-Method
estimator	I-Method
to	O
decide	O
the	O
parent	O
node	O
among	O
candidates	O
dynamically	O
and	O
to	O
calculate	O
gradients	O
of	O
the	O
discrete	O
decision	O
.	O
	
We	O
evaluate	O
the	O
proposed	O
model	O
on	O
natural	B-Task
language	I-Task
inference	I-Task
and	O
sentiment	B-Task
analysis	I-Task
,	O
and	O
show	O
that	O
our	O
model	O
outperforms	O
or	O
is	O
at	O
least	O
comparable	O
to	O
previous	O
models	O
.	O
	
We	O
also	O
find	O
that	O
our	O
model	O
converges	O
significantly	O
faster	O
than	O
other	O
models	O
.	O
	
section	O
:	O
Introduction	O
	
Techniques	O
for	O
mapping	B-Task
natural	I-Task
language	I-Task
into	O
vector	B-Task
space	I-Task
have	O
received	O
a	O
lot	O
of	O
attention	O
,	O
due	O
to	O
their	O
capability	O
of	O
representing	O
ambiguous	O
semantics	O
of	O
natural	O
language	O
using	O
dense	O
vectors	O
.	O
	
Among	O
them	O
,	O
methods	O
of	O
learning	B-Task
representations	I-Task
of	I-Task
words	I-Task
,	O
e.g.	O
word2vec	O
[	O
reference	O
]	O
or	O
GloVe	B-Method
,	O
are	O
relatively	O
well	O
-	O
studied	O
empirically	O
and	O
theoretically	O
[	O
reference	O
][	O
reference	O
]	O
,	O
and	O
some	O
of	O
them	O
became	O
typical	O
choices	O
to	O
consider	O
when	O
initializing	O
word	B-Method
representations	I-Method
for	O
better	O
performance	O
at	O
downstream	B-Task
tasks	I-Task
.	O
	
Meanwhile	O
,	O
research	O
on	O
sentence	B-Task
representation	I-Task
is	O
still	O
in	O
active	O
progress	O
,	O
and	O
accordingly	O
various	O
architecturesdesigned	O
with	O
different	O
intuition	O
and	O
tailored	O
for	O
different	O
tasks	O
-	O
are	O
being	O
proposed	O
.	O
	
In	O
the	O
midst	O
of	O
them	O
,	O
three	O
architectures	O
are	O
most	O
frequently	O
used	O
in	O
obtaining	O
sentence	B-Task
representation	I-Task
from	O
words	O
.	O
	
Convolutional	B-Method
neural	I-Method
networks	I-Method
(	O
CNNs	B-Method
)	O
[	O
reference	O
][	O
reference	O
]	O
utilize	O
local	O
distribution	O
of	O
words	O
to	O
encode	O
sentences	O
,	O
similar	O
to	O
n	B-Method
-	I-Method
gram	I-Method
models	I-Method
.	O
	
Recurrent	B-Method
neural	I-Method
networks	I-Method
(	O
RNNs	B-Method
)	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
encode	O
sentences	O
by	O
reading	O
words	O
in	O
sequential	O
order	O
.	O
	
Recursive	B-Method
neural	I-Method
networks	I-Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
)	O
,	O
on	O
which	O
this	O
paper	O
focuses	O
,	O
rely	O
on	O
structured	O
input	O
(	O
e.g.	O
parse	O
tree	O
)	O
to	O
encode	O
sentences	O
,	O
based	O
on	O
the	O
intuition	O
that	O
there	O
is	O
significant	O
semantics	O
in	O
the	O
hierarchical	O
structure	O
of	O
words	O
.	O
	
It	O
is	O
also	O
notable	O
that	O
RvNNs	B-Method
are	O
generalization	B-Method
of	I-Method
RNNs	I-Method
,	O
as	O
linear	O
chain	O
structures	O
on	O
which	O
RNNs	B-Method
operate	O
are	O
equivalent	O
to	O
left	O
-	O
or	O
right	O
-	O
skewed	O
trees	O
.	O
	
Although	O
there	O
is	O
significant	O
benefit	O
in	O
processing	O
a	O
sentence	O
in	O
a	O
tree	O
-	O
structured	O
recursive	O
manner	O
,	O
data	O
annotated	O
with	O
parse	O
trees	O
could	O
be	O
expensive	O
to	O
prepare	O
and	O
hard	O
to	O
be	O
computed	O
in	O
batches	O
	
[	O
reference	O
]	O
.	O
Furthermore	O
,	O
the	O
optimal	O
hierarchical	O
composition	O
of	O
words	O
might	O
differ	O
depending	O
on	O
the	O
properties	O
of	O
a	O
task	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
Gumbel	B-Method
Tree	I-Method
-	I-Method
LSTM	I-Method
,	O
which	O
is	O
a	O
novel	O
RvNN	B-Method
architecture	I-Method
that	O
does	O
not	O
require	O
structured	O
data	O
and	O
learns	O
to	O
compose	O
task	O
-	O
specific	O
tree	O
structures	O
without	O
explicit	O
guidance	O
.	O
	
Our	O
Gumbel	B-Method
Tree	I-Method
-	I-Method
LSTM	I-Method
model	O
is	O
based	O
on	O
tree	O
-	O
structured	O
long	O
short	O
-	O
term	O
memory	O
(	O
Tree	O
-	O
LSTM	B-Method
)	O
architecture	O
[	O
reference	O
][	O
reference	O
]	O
,	O
which	O
is	O
one	O
of	O
the	O
most	O
renowned	O
variants	O
of	O
RvNN	B-Method
.	O
	
To	O
learn	O
how	O
to	O
compose	O
task	O
-	O
specific	O
tree	O
structures	O
without	O
depending	O
on	O
structured	O
input	O
,	O
our	O
model	O
introduces	O
composition	O
query	O
vector	O
that	O
measures	O
validity	O
of	O
a	O
composition	O
.	O
	
Using	O
validity	O
scores	O
computed	O
by	O
the	O
composition	O
query	O
vector	O
,	O
our	O
model	O
recursively	O
selects	O
compositions	O
until	O
only	O
a	O
single	O
representation	O
remains	O
.	O
	
We	O
use	O
StraightThrough	B-Method
(	I-Method
ST	I-Method
)	I-Method
Gumbel	I-Method
-	I-Method
Softmax	I-Method
estimator	I-Method
[	O
reference	O
][	O
reference	O
]	O
to	O
sample	O
compositions	O
in	O
the	O
training	O
phase	O
.	O
	
ST	B-Method
Gumbel	I-Method
-	I-Method
Softmax	I-Method
estimator	I-Method
relaxes	O
the	O
discrete	O
sampling	O
operation	O
to	O
be	O
continuous	O
in	O
the	O
backward	O
pass	O
,	O
thus	O
our	O
model	O
can	O
be	O
trained	O
via	O
the	O
standard	O
backpropagation	B-Method
.	O
	
Also	O
,	O
since	O
the	O
computation	O
is	O
performed	O
layer	O
-	O
wise	O
,	O
our	O
model	O
is	O
easy	O
to	O
implement	O
and	O
naturally	O
supports	O
batched	B-Task
computation	I-Task
.	O
	
From	O
experiments	O
on	O
natural	B-Task
language	I-Task
inference	I-Task
and	O
sentiment	B-Task
analysis	I-Task
tasks	I-Task
,	O
we	O
find	O
that	O
our	O
proposed	O
model	O
outperforms	O
or	O
is	O
at	O
least	O
comparable	O
to	O
previous	O
sentence	B-Method
encoder	I-Method
models	I-Method
and	O
converges	O
significantly	O
faster	O
than	O
them	O
.	O
	
The	O
contributions	O
of	O
our	O
work	O
are	O
as	O
follows	O
:	O
	
•	O
	
We	O
designed	O
a	O
novel	O
sentence	B-Method
encoder	I-Method
architecture	I-Method
that	O
learns	O
to	O
compose	O
task	O
-	O
specific	O
trees	O
from	O
plain	O
text	O
data	O
.	O
	
•	O
	
We	O
showed	O
from	O
experiments	O
that	O
the	O
proposed	O
architecture	O
outperforms	O
or	O
is	O
competitive	O
to	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
.	O
	
We	O
also	O
observed	O
that	O
our	O
model	O
converges	O
faster	O
than	O
others	O
.	O
	
•	O
	
Specifically	O
,	O
we	O
saw	O
that	O
our	O
model	O
significantly	O
outperforms	O
previous	O
RvNN	B-Method
works	I-Method
trained	O
on	O
parse	O
trees	O
in	O
all	O
conducted	O
experiments	O
,	O
from	O
which	O
we	O
hypothesize	O
that	O
syntactic	O
parse	O
tree	O
may	O
not	O
be	O
the	O
best	O
structure	O
for	O
every	O
task	O
and	O
the	O
optimal	O
structure	O
could	O
differ	O
per	O
task	O
.	O
	
In	O
the	O
next	O
section	O
,	O
we	O
briefly	O
introduce	O
previous	O
works	O
which	O
have	O
similar	O
objectives	O
to	O
that	O
of	O
our	O
work	O
.	O
	
Then	O
we	O
describe	O
the	O
proposed	O
model	O
in	O
detail	O
and	O
present	O
findings	O
from	O
experiments	O
.	O
	
Lastly	O
we	O
summarize	O
the	O
overall	O
content	O
and	O
discuss	O
future	O
work	O
.	O
	
section	O
:	O
Related	O
Work	O
	
There	O
have	O
been	O
several	O
works	O
that	O
aim	O
to	O
learn	O
hierarchical	O
latent	O
structure	O
of	O
text	O
by	O
recursively	O
composing	O
words	O
into	O
sentence	B-Method
representation	I-Method
.	O
	
Some	O
of	O
them	O
carry	O
unsupervised	B-Task
learning	I-Task
on	O
structures	O
by	O
making	O
composition	O
operations	O
soft	O
.	O
	
To	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
gated	B-Method
recursive	I-Method
convolutional	I-Method
neural	I-Method
network	I-Method
(	O
grConv	B-Method
)	I-Method
[	O
reference	O
]	O
)	O
is	O
the	O
first	O
model	O
of	O
its	O
kind	O
and	O
used	O
as	O
an	O
encoder	B-Method
for	O
neural	B-Task
machine	I-Task
translation	I-Task
.	O
	
The	O
grConv	B-Method
architecture	I-Method
uses	O
gating	B-Method
mechanism	I-Method
to	O
control	O
the	O
information	O
flow	O
from	O
children	O
to	O
parent	O
.	O
	
grConv	B-Method
and	O
its	O
variants	O
are	O
also	O
applied	O
to	O
sentence	B-Task
classification	I-Task
tasks	I-Task
[	O
reference	O
][	O
reference	O
]	O
.	O
Neural	B-Method
tree	I-Method
indexer	I-Method
(	O
NTI	B-Method
)	O
	
[	O
reference	O
]	O
utilizes	O
soft	O
hierarchical	O
structures	O
by	O
using	O
Tree	O
-	O
LSTM	B-Method
instead	O
of	O
grConv	B-Method
.	O
	
Although	O
models	O
that	O
operate	O
with	O
soft	O
structures	O
are	O
naturally	O
capable	O
of	O
being	O
trained	O
via	O
backpropagation	B-Method
,	O
the	O
structures	O
predicted	O
by	O
them	O
are	O
ambiguous	O
and	O
thus	O
it	O
is	O
hard	O
to	O
interpret	O
them	O
.	O
	
CYK	O
Tree	O
-	O
LSTM	B-Method
[	O
reference	O
]	O
resolves	O
this	O
ambiguity	O
while	O
maintaining	O
the	O
soft	O
property	O
by	O
introducing	O
the	O
concept	O
of	O
CYK	B-Method
parsing	I-Method
algorithm	I-Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
)	O
.	O
	
Though	O
their	O
model	O
reduces	O
the	O
ambiguity	O
by	O
explicitly	O
representing	O
a	O
node	O
as	O
a	O
weighted	O
sum	O
of	O
all	O
candidate	O
compositions	O
,	O
it	O
is	O
memory	O
intensive	O
since	O
the	O
number	O
of	O
candidates	O
linearly	O
increases	O
by	O
depth	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
there	O
exist	O
some	O
previous	O
works	O
that	O
maintain	O
the	O
discreteness	O
of	O
tree	O
composition	O
processes	O
,	O
instead	O
of	O
relying	O
on	O
the	O
soft	O
hierarchical	O
structure	O
.	O
	
The	O
architecture	O
proposed	O
by	O
[	O
reference	O
]	O
greedily	O
selects	O
two	O
adjacent	O
nodes	O
whose	O
reconstruction	B-Metric
error	I-Metric
is	O
the	O
smallest	O
and	O
merges	O
them	O
into	O
the	O
parent	O
.	O
	
In	O
their	O
work	O
,	O
rather	O
than	O
directly	O
optimized	O
on	O
classification	O
loss	O
,	O
a	O
composition	B-Method
function	I-Method
is	O
optimized	O
to	O
minimize	O
reconstruction	B-Metric
error	I-Metric
.	O
	
[	O
reference	O
]	O
introduce	O
reinforcement	B-Method
learning	I-Method
to	O
achieve	O
the	O
desired	O
effect	O
of	O
discretization	B-Task
.	O
	
They	O
show	O
that	O
REINFORCE	O
[	O
reference	O
]	O
)	O
	
algorithm	O
can	O
be	O
used	O
in	O
estimating	B-Task
gradients	I-Task
to	O
learn	O
a	O
tree	O
composition	O
function	O
minimizing	O
classification	B-Metric
error	I-Metric
.	O
	
However	O
,	O
slow	O
convergence	B-Metric
due	O
to	O
the	O
reinforcement	B-Method
learning	I-Method
setting	I-Method
is	O
one	O
of	O
its	O
drawbacks	O
,	O
according	O
to	O
the	O
authors	O
.	O
	
In	O
the	O
research	O
area	O
outside	O
the	O
RvNN	B-Method
,	O
compositionality	B-Task
in	I-Task
vector	I-Task
space	I-Task
also	O
has	O
been	O
a	O
longstanding	O
subject	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
,	O
to	O
name	O
a	O
few	O
)	O
.	O
	
And	O
more	O
recently	O
,	O
there	O
exist	O
works	O
aiming	O
to	O
learn	O
hierarchical	O
latent	O
structure	O
from	O
unstructured	O
data	O
[	O
reference	O
][	O
reference	O
]	O
)	O
.	O
	
section	O
:	O
Model	O
Description	O
	
Our	O
proposed	O
architecture	O
is	O
built	O
based	O
on	O
the	O
treestructured	B-Method
long	I-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
network	I-Method
architecture	I-Method
.	O
	
We	O
introduce	O
several	O
additional	O
components	O
into	O
the	O
Tree	O
-	O
LSTM	B-Method
architecture	O
to	O
allow	O
the	O
model	O
to	O
dynamically	O
compose	O
tree	O
structure	O
in	O
a	O
bottom	O
-	O
up	O
manner	O
and	O
to	O
effectively	O
encode	O
a	O
sentence	O
into	O
a	O
vector	O
.	O
	
In	O
this	O
section	O
,	O
we	O
describe	O
the	O
components	O
of	O
our	O
model	O
in	O
detail	O
.	O
	
section	O
:	O
Tree	O
-	O
LSTM	B-Method
	
Tree	B-Method
-	I-Method
structured	I-Method
long	I-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
network	I-Method
(	O
Tree	O
-	O
LSTM	B-Method
)	O
	
[	O
reference	O
][	O
reference	O
]	O
is	O
an	O
elegant	O
variant	O
of	O
RvNN	B-Method
,	O
where	O
it	O
controls	O
information	O
flow	O
from	O
children	O
to	O
parent	O
using	O
similar	O
mechanism	O
to	O
long	B-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
(	O
LSTM	B-Method
)	O
	
[	O
reference	O
]	O
.	O
Tree	O
-	O
LSTM	B-Method
introduces	O
cell	O
state	O
in	O
computing	O
parent	B-Method
representation	I-Method
,	O
which	O
assists	O
each	O
cell	O
to	O
capture	O
distant	O
vertical	O
dependencies	O
.	O
	
The	O
following	O
are	O
formulae	O
that	O
our	O
model	O
uses	O
to	O
compute	O
parent	B-Method
representation	I-Method
from	O
its	O
children	O
:	O
	
where	O
	
,	O
and	O
is	O
the	O
element	O
-	O
wise	O
product	O
.	O
	
Note	O
that	O
our	O
formulation	O
is	O
akin	O
to	O
that	O
of	O
SPINN	B-Method
[	O
reference	O
]	O
)	O
,	O
but	O
our	O
version	O
does	O
not	O
include	O
the	O
tracking	O
LSTM	B-Method
.	O
	
Instead	O
,	O
our	O
model	O
can	O
apply	O
an	O
LSTM	B-Method
to	O
leaf	O
nodes	O
,	O
which	O
we	O
will	O
soon	O
describe	O
.	O
	
section	O
:	O
Gumbel	B-Method
-	I-Method
Softmax	I-Method
	
Gumbel	B-Method
-	I-Method
Softmax	I-Method
(	O
Jang	O
,	O
Gu	O
,	O
and	O
Poole	O
2017	O
)	O
(	O
or	O
Concrete	B-Method
distribution	I-Method
[	O
reference	O
]	O
)	O
is	O
a	O
method	O
of	O
utilizing	O
discrete	O
random	O
variables	O
in	O
a	O
network	O
.	O
	
Since	O
it	O
approximates	O
one	O
-	O
hot	O
vectors	O
sampled	O
from	O
a	O
categorical	O
distribution	O
by	O
making	O
them	O
continuous	O
,	O
gradients	O
of	O
model	O
parameters	O
can	O
be	O
calculated	O
using	O
the	O
reparameterization	B-Method
trick	I-Method
and	O
the	O
standard	O
backpropagation	B-Method
.	O
	
GumbelSoftmax	B-Method
is	O
known	O
to	O
have	O
an	O
advantage	O
over	O
score	B-Method
-	I-Method
functionbased	I-Method
gradient	I-Method
estimators	I-Method
such	O
as	O
REINFORCE	B-Method
[	O
reference	O
]	O
which	O
suffer	O
from	O
high	O
variance	B-Metric
and	O
slow	B-Metric
convergence	I-Metric
	
[	O
reference	O
]	O
.	O
	
Gumbel	B-Method
-	I-Method
Softmax	I-Method
distribution	I-Method
is	O
motivated	O
by	O
GumbelMax	B-Method
trick	I-Method
[	O
reference	O
]	O
,	O
an	O
algorithm	O
for	O
sampling	B-Task
from	O
a	O
categorical	O
distribution	O
.	O
	
Consider	O
	
Figure	O
1	O
:	O
Visualization	O
of	O
forward	O
and	O
backward	O
computation	O
path	O
of	O
ST	B-Method
Gumbel	I-Method
-	I-Method
Softmax	I-Method
.	O
	
In	O
the	O
forward	O
pass	O
,	O
a	O
model	O
can	O
maintain	O
sparseness	O
due	O
to	O
arg	B-Method
max	I-Method
operation	I-Method
.	O
	
In	O
the	O
backward	O
pass	O
,	O
since	O
there	O
is	O
no	O
discrete	O
operation	O
,	O
the	O
error	O
signal	O
can	O
backpropagate	O
.	O
	
a	O
k	O
-	O
dimensional	O
categorical	O
distribution	O
whose	O
class	O
probabilities	O
p	O
1	O
,	O
·	O
·	O
·	O
,	O
p	O
k	O
are	O
defined	O
in	O
terms	O
of	O
unnormalized	O
log	O
probabilities	O
π	O
1	O
,	O
·	O
·	O
·	O
,	O
π	O
k	O
:	O
	
Then	O
a	O
one	O
-	O
hot	O
sample	O
	
from	O
the	O
distribution	O
can	O
be	O
easily	O
drawn	O
by	O
the	O
following	O
equations	O
:	O
	
Here	O
,	O
g	O
i	O
,	O
namely	O
Gumbel	O
noise	O
,	O
perturbs	O
each	O
log	O
(	O
π	O
i	O
)	O
term	O
so	O
that	O
taking	O
arg	B-Task
max	I-Task
becomes	O
equivalent	O
to	O
drawing	O
a	O
sample	O
weighted	O
on	O
p	O
1	O
,	O
·	O
·	O
·	O
,	O
p	O
k	O
.	O
	
In	O
Gumbel	B-Method
-	I-Method
Softmax	I-Method
,	O
the	O
discontinuous	B-Method
arg	I-Method
max	I-Method
function	I-Method
of	O
Gumbel	B-Method
-	I-Method
Max	I-Method
trick	I-Method
is	O
replaced	O
by	O
the	O
differentiable	O
softmax	O
function	O
.	O
	
That	O
is	O
,	O
given	O
unnormalized	O
probabilities	O
π	O
1	O
,	O
·	O
·	O
·	O
,	O
π	O
k	O
,	O
a	O
sample	O
y	O
	
=	O
(	O
y	O
1	O
,	O
·	O
·	O
·	O
,	O
y	O
k	O
)	O
from	O
the	O
GumbelSoftmax	B-Method
distribution	I-Method
is	O
drawn	O
by	O
	
where	O
τ	O
is	O
a	O
temperature	O
parameter	O
;	O
as	O
τ	O
diminishes	O
to	O
zero	O
,	O
a	O
sample	O
from	O
the	O
Gumbel	B-Method
-	I-Method
Softmax	I-Method
distribution	I-Method
becomes	O
cold	O
and	O
resembles	O
the	O
one	O
-	O
hot	O
sample	O
.	O
	
Straight	B-Method
-	I-Method
Through	I-Method
(	I-Method
ST	I-Method
)	I-Method
Gumbel	I-Method
-	I-Method
Softmax	I-Method
estimator	I-Method
[	O
reference	O
]	O
,	O
whose	O
name	O
reminds	O
of	O
StraightThrough	B-Method
estimator	I-Method
(	O
STE	B-Method
)	O
[	O
reference	O
]	O
,	O
is	O
a	O
discrete	B-Method
version	I-Method
of	O
the	O
continuous	B-Method
GumbelSoftmax	I-Method
estimator	I-Method
.	O
	
Similar	O
to	O
the	O
STE	B-Method
,	O
it	O
maintains	O
sparsity	O
by	O
taking	O
different	O
paths	O
in	O
the	O
forward	B-Method
and	I-Method
backward	I-Method
propagation	I-Method
.	O
	
Obviously	O
ST	B-Method
estimators	I-Method
are	O
biased	O
,	O
however	O
they	O
perform	O
well	O
in	O
practice	O
,	O
according	O
to	O
several	O
previous	O
works	O
[	O
reference	O
][	O
reference	O
]	O
and	O
our	O
own	O
result	O
.	O
	
In	O
the	O
forward	O
pass	O
,	O
it	O
discretizes	O
a	O
continuous	O
probability	O
vector	O
y	O
sampled	O
from	O
the	O
Gumbel	B-Method
-	I-Method
Softmax	I-Method
distribution	I-Method
into	O
the	O
one	O
-	O
hot	O
vector	O
	
where	O
	
And	O
in	O
the	O
backward	O
pass	O
it	O
simply	O
uses	O
the	O
continuous	O
y	O
,	O
thus	O
the	O
error	O
signal	O
is	O
still	O
able	O
to	O
backpropagate	O
.	O
	
See	O
Figure	O
1	O
for	O
the	O
visualization	O
of	O
the	O
forward	O
and	O
backward	O
pass	O
.	O
	
ST	B-Method
Gumbel	I-Method
-	I-Method
Softmax	I-Method
estimator	I-Method
is	O
useful	O
when	O
a	O
model	O
needs	O
to	O
utilize	O
discrete	O
values	O
directly	O
,	O
for	O
example	O
in	O
the	O
case	O
that	O
a	O
model	O
alters	O
its	O
computation	O
path	O
based	O
on	O
samples	O
drawn	O
from	O
a	O
categorical	O
distribution	O
.	O
	
section	O
:	O
Gumbel	B-Method
Tree	I-Method
-	I-Method
LSTM	I-Method
	
In	O
our	O
Gumbel	B-Method
Tree	I-Method
-	I-Method
LSTM	I-Method
model	O
,	O
an	O
input	O
sentence	O
composed	O
of	O
N	O
words	O
is	O
represented	O
as	O
a	O
sequence	O
of	O
word	O
vectors	O
(	O
x	O
1	O
,	O
·	O
·	O
·	O
,	O
x	O
N	O
)	O
,	O
where	O
x	O
i	O
∈	O
R	O
Dx	O
.	O
	
Our	O
basic	O
model	O
applies	O
an	O
affine	B-Method
transformation	I-Method
to	O
each	O
x	O
i	O
to	O
obtain	O
the	O
initial	O
hidden	O
and	O
cell	O
state	O
:	O
	
which	O
we	O
call	O
leaf	B-Method
transformation	I-Method
.	O
	
In	O
Eq	O
.	O
	
10	O
	
,	O
W	O
leaf	O
∈	O
R	O
2D	O
h	O
×Dx	O
and	O
b	O
leaf	O
∈	O
R	O
2D	O
h	O
.	O
	
Note	O
that	O
we	O
denote	O
the	O
representation	O
of	O
i	O
-	O
th	O
node	O
at	O
t	O
-	O
th	O
layer	O
as	O
r	O
.	O
	
Node	B-Method
representations	I-Method
which	O
are	O
not	O
selected	O
are	O
copied	O
to	O
the	O
corresponding	O
positions	O
at	O
layer	O
t	O
+	O
1	O
.	O
	
In	O
other	O
words	O
,	O
the	O
(	O
t	O
+	O
1	O
)-	O
th	O
layer	O
is	O
composed	O
of	O
	
This	O
procedure	O
is	O
repeated	O
until	O
the	O
model	O
reaches	O
	
N	O
-	O
th	O
layer	O
and	O
only	O
a	O
single	O
node	O
is	O
left	O
.	O
	
It	O
is	O
notable	O
that	O
the	O
property	O
of	O
selecting	O
the	O
best	O
node	O
pair	O
at	O
each	O
stage	O
resembles	O
that	O
of	O
easy	B-Method
-	I-Method
first	I-Method
parsing	I-Method
[	O
reference	O
]	O
	
Figure	O
2	O
:	O
	
An	O
example	O
of	O
the	O
parent	B-Method
selection	I-Method
.	O
	
At	O
layer	O
t	O
(	O
the	O
bottom	O
layer	O
)	O
,	O
the	O
model	O
computes	O
parent	O
candidates	O
(	O
the	O
middle	O
layer	O
)	O
.	O
	
Then	O
the	O
validity	B-Metric
score	I-Metric
of	O
each	O
candidate	O
is	O
computed	O
using	O
the	O
query	O
vector	O
q	O
(	O
denoted	O
as	O
v	O
1	O
,	O
v	O
2	O
,	O
v	O
3	O
)	O
.	O
	
In	O
the	O
training	O
time	O
,	O
the	O
model	O
samples	O
a	O
parent	O
node	O
among	O
candidates	O
weighted	O
on	O
v	O
1	O
,	O
v	O
2	O
,	O
v	O
3	O
,	O
using	O
ST	B-Method
Gumbel	I-Method
-	I-Method
Softmax	I-Method
estimator	I-Method
,	O
and	O
in	O
the	O
testing	O
time	O
the	O
model	O
selects	O
the	O
candidate	O
with	O
the	O
highest	O
validity	O
.	O
	
At	O
layer	O
t	O
+	O
1	O
(	O
the	O
top	O
layer	O
)	O
,	O
the	O
representation	O
of	O
the	O
selected	O
candidate	O
(	O
'	O
the	O
cat	O
'	O
)	O
is	O
used	O
as	O
a	O
parent	O
,	O
and	O
the	O
rest	O
are	O
copied	O
from	O
those	O
of	O
layer	O
t	O
(	O
'	O
sat	O
'	O
,	O
'	O
on	O
'	O
)	O
.	O
	
Best	O
viewed	O
in	O
color	O
.	O
	
Parent	B-Method
selection	I-Method
.	O
	
Since	O
information	O
about	O
the	O
tree	O
structure	O
of	O
an	O
input	O
is	O
not	O
given	O
to	O
the	O
model	O
,	O
a	O
special	O
mechanism	O
is	O
needed	O
for	O
the	O
model	O
to	O
learn	O
to	O
compose	O
taskspecific	O
tree	O
structures	O
in	O
an	O
end	O
-	O
to	O
-	O
end	O
manner	O
.	O
	
We	O
now	O
describe	O
the	O
mechanism	O
for	O
building	O
up	O
the	O
tree	O
structure	O
from	O
an	O
unstructured	O
sentence	O
.	O
	
First	O
,	O
our	O
model	O
introduces	O
the	O
trainable	O
composition	O
query	O
vector	O
q	O
∈	O
R	O
D	O
h	O
.	O
	
The	O
composition	O
query	O
vector	O
measures	O
how	O
valid	O
a	O
representation	O
is	O
.	O
	
Specifically	O
,	O
the	O
validity	B-Metric
score	I-Metric
of	O
a	O
representation	O
r	O
=	O
	
[	O
h	O
;	O
c	O
]	O
is	O
defined	O
by	O
q	O
·	O
h.	O
	
At	O
layer	O
t	O
,	O
the	O
model	O
computes	O
candidates	O
for	O
the	O
parent	O
representations	O
using	O
Eqs	O
.	O
1	O
-	O
3	O
:	O
	
(	O
r	O
	
In	O
the	O
training	O
phase	O
,	O
the	O
model	O
samples	O
a	O
parent	O
from	O
candidates	O
weighted	O
on	O
v	O
i	O
,	O
using	O
the	O
ST	B-Method
Gumbel	I-Method
-	I-Method
Softmax	I-Method
estimator	I-Method
described	O
above	O
.	O
	
Since	O
the	O
continuous	O
GumbelSoftmax	O
function	O
is	O
used	O
in	O
the	O
backward	O
pass	O
,	O
the	O
error	O
backpropagation	O
signal	O
safely	O
passes	O
through	O
the	O
sampling	B-Method
operation	I-Method
,	O
hence	O
the	O
model	O
is	O
able	O
to	O
learn	O
to	O
construct	O
the	O
task	O
-	O
specific	O
tree	O
structures	O
that	O
minimize	O
the	O
loss	O
by	O
backpropagation	B-Method
.	O
	
In	O
the	O
validation	O
(	O
or	O
testing	O
)	O
phase	O
,	O
the	O
model	O
simply	O
selects	O
the	O
parent	O
which	O
maximizes	O
the	O
validity	B-Metric
score	I-Metric
.	O
	
An	O
example	O
of	O
the	O
parent	B-Task
selection	I-Task
is	O
depicted	O
in	O
Figure	O
2	O
.	O
	
LSTM	B-Method
-	O
based	O
leaf	O
transformation	O
.	O
	
The	O
basic	O
leaf	B-Method
transformation	I-Method
using	O
an	O
affine	B-Method
transformation	I-Method
(	O
Eq	O
.	O
10	O
)	O
does	O
not	O
consider	O
information	O
about	O
the	O
entire	O
sentence	O
of	O
an	O
input	O
and	O
thus	O
the	O
parent	B-Method
selection	I-Method
is	O
performed	O
based	O
only	O
on	O
local	O
information	O
.	O
	
SPINN	B-Method
[	O
reference	O
]	O
)	O
addresses	O
this	O
issue	O
by	O
using	O
the	O
tracking	O
LSTM	B-Method
which	O
sequentially	O
reads	O
input	O
words	O
.	O
	
The	O
tracking	O
LSTM	B-Method
makes	O
the	O
SPINN	B-Method
model	I-Method
hybrid	O
,	O
where	O
the	O
model	O
takes	O
advantage	O
of	O
both	O
tree	B-Method
-	I-Method
structured	I-Method
composition	I-Method
and	O
sequential	O
reading	O
.	O
	
However	O
,	O
the	O
tracking	O
LSTM	B-Method
is	O
not	O
applicable	O
to	O
our	O
model	O
,	O
since	O
our	O
model	O
does	O
not	O
use	O
shift	B-Method
-	I-Method
reduce	I-Method
parsing	I-Method
or	O
maintain	O
a	O
stack	O
.	O
	
In	O
the	O
tracking	O
LSTM	B-Method
's	O
stead	O
,	O
our	O
model	O
applies	O
an	O
LSTM	B-Method
on	O
input	B-Method
representations	I-Method
to	O
give	O
information	O
about	O
previous	O
words	O
to	O
each	O
leaf	O
node	O
:	O
	
where	O
h	O
1	O
0	O
	
=	O
c	O
1	O
0	O
=	O
0	O
.	O
	
From	O
the	O
experimental	O
results	O
,	O
we	O
validate	O
that	O
the	O
LSTM	B-Method
applied	O
to	O
leaf	O
nodes	O
has	O
a	O
substantial	O
gain	O
over	O
the	O
basic	O
leaf	B-Method
transformer	I-Method
.	O
	
section	O
:	O
Experiments	O
	
We	O
evaluate	O
performance	O
of	O
the	O
proposed	O
Gumbel	B-Method
Tree	I-Method
-	I-Method
LSTM	I-Method
model	O
on	O
two	O
tasks	O
:	O
natural	B-Task
language	I-Task
inference	I-Task
and	O
sentiment	B-Task
analysis	I-Task
.	O
	
The	O
implementation	O
is	O
made	O
publicly	O
available	O
.	O
	
section	O
:	O
2	O
	
The	O
detailed	O
experimental	O
settings	O
are	O
described	O
in	O
the	O
supplementary	O
material	O
.	O
	
section	O
:	O
Natural	B-Task
Language	I-Task
Inference	I-Task
	
Natural	B-Task
language	I-Task
inference	I-Task
(	O
NLI	B-Task
)	O
is	O
a	O
task	O
of	O
predicting	O
the	O
relationship	O
between	O
two	O
sentences	O
(	O
hypothesis	O
and	O
premise	O
)	O
.	O
	
In	O
the	O
Stanford	B-Material
Natural	I-Material
Language	I-Material
Inference	I-Material
(	O
SNLI	B-Material
)	I-Material
dataset	I-Material
[	O
reference	O
]	O
)	O
,	O
which	O
we	O
use	O
for	O
NLI	B-Task
experiments	I-Task
,	O
a	O
relationship	O
is	O
either	O
contradiction	O
,	O
entailment	O
,	O
or	O
neutral	O
.	O
	
For	O
a	O
model	O
to	O
correctly	O
predict	O
the	O
relationship	O
between	O
two	O
sentences	O
,	O
it	O
should	O
encode	O
semantics	O
of	O
sentences	O
accurately	O
,	O
thus	O
the	O
task	O
has	O
been	O
used	O
as	O
one	O
of	O
standard	O
tasks	O
for	O
evaluating	O
the	O
quality	O
of	O
sentence	B-Method
representations	I-Method
.	O
	
The	O
SNLI	B-Material
dataset	I-Material
is	O
composed	O
of	O
about	O
550	O
,	O
000	O
sentences	O
,	O
each	O
of	O
which	O
is	O
binary	O
-	O
parsed	O
.	O
	
However	O
,	O
since	O
our	O
model	O
operate	O
on	O
plain	O
text	O
,	O
we	O
do	O
not	O
use	O
the	O
parse	O
tree	O
information	O
in	O
both	O
training	O
and	O
testing	O
.	O
	
The	O
classifier	B-Method
architecture	I-Method
used	O
in	O
our	O
SNLI	B-Material
experiments	O
follows	O
	
[	O
reference	O
][	O
reference	O
]	O
.	O
	
Given	O
the	O
premise	O
sentence	O
vector	O
(	O
h	O
pre	O
)	O
and	O
the	O
hypothesis	O
sentence	O
vector	O
(	O
h	O
hyp	O
)	O
which	O
are	O
encoded	O
by	O
the	O
proposed	O
Gumbel	B-Method
Tree	I-Method
-	I-Method
LSTM	I-Method
model	O
,	O
the	O
probability	O
of	O
relationship	O
r	O
∈	O
{	O
entailment	O
,	O
contradiction	O
,	O
neutral	O
}	O
is	O
computed	O
by	O
the	O
following	O
equations	O
:	O
[	O
reference	O
]	O
followed	O
by	O
dropout	O
[	O
reference	O
]	O
)	O
with	O
probability	O
0.1	O
to	O
the	O
input	O
and	O
the	O
output	O
of	O
the	O
MLP	B-Method
.	O
	
We	O
also	O
apply	O
dropout	B-Method
on	O
the	O
word	O
vectors	O
with	O
probability	O
0.1	O
.	O
	
Similar	O
to	O
100D	O
experiments	O
,	O
we	O
initialize	O
the	O
word	B-Method
embedding	I-Method
matrix	I-Method
with	O
GloVe	B-Method
300D	I-Method
pretrained	I-Method
vectors	I-Method
4	O
,	O
however	O
we	O
do	O
not	O
update	O
the	O
word	B-Method
representations	I-Method
during	O
training	O
.	O
	
Since	O
our	O
model	O
converges	O
relatively	O
fast	O
,	O
it	O
is	O
possible	O
to	O
train	O
a	O
model	O
of	O
larger	O
size	O
in	O
a	O
reasonable	O
time	O
.	O
	
In	O
the	O
600D	O
experiment	O
,	O
we	O
set	O
D	O
x	O
=	O
300	O
,	O
	
D	O
h	O
	
=	O
600	O
,	O
and	O
an	O
MLP	B-Method
with	O
three	O
hidden	B-Method
layers	I-Method
(	O
D	O
c	O
=	O
1024	O
)	O
is	O
used	O
.	O
	
The	O
dropout	O
probability	O
is	O
set	O
to	O
0.2	O
and	O
word	O
embeddings	O
are	O
not	O
updated	O
during	O
training	O
.	O
	
The	O
size	O
of	O
mini	O
-	O
batches	O
is	O
set	O
to	O
128	O
in	O
all	O
experiments	O
,	O
and	O
hyperparameters	O
are	O
tuned	O
using	O
the	O
validation	O
split	O
.	O
	
The	O
temperature	O
parameter	O
τ	O
of	O
Gumbel	B-Method
-	I-Method
Softmax	I-Method
is	O
set	O
to	O
1.0	O
,	O
and	O
we	O
did	O
not	O
find	O
that	O
temperature	B-Method
annealing	I-Method
improves	O
performance	O
.	O
	
For	O
training	B-Method
models	I-Method
,	O
Adam	B-Method
optimizer	I-Method
is	O
used	O
.	O
	
The	O
results	O
of	O
SNLI	B-Material
experiments	O
are	O
summarized	O
in	O
Table	O
1	O
.	O
	
First	O
,	O
we	O
can	O
see	O
that	O
LSTM	B-Method
-	O
based	O
leaf	O
transformation	O
has	O
a	O
clear	O
advantage	O
over	O
the	O
affine	B-Method
-	I-Method
transformation	I-Method
-	I-Method
based	I-Method
one	I-Method
.	O
	
It	O
improves	O
the	O
performance	O
substantially	O
and	O
also	O
leads	O
to	O
faster	O
convergence	B-Metric
.	O
	
Secondly	O
,	O
comparing	O
ours	O
with	O
other	O
models	O
,	O
we	O
find	O
that	O
our	O
100D	B-Method
and	I-Method
300D	I-Method
model	I-Method
outperform	O
all	O
other	O
models	O
of	O
similar	O
numbers	O
of	O
parameters	O
.	O
	
Our	O
600D	B-Method
model	I-Method
achieves	O
the	O
accuracy	B-Metric
of	O
86.0	O
%	O
,	O
which	O
is	O
comparable	O
to	O
that	O
of	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
model	O
[	O
reference	O
]	O
,	O
while	O
using	O
far	O
less	O
parameters	O
.	O
	
It	O
is	O
also	O
worth	O
noting	O
that	O
our	O
models	O
converge	O
much	O
faster	O
than	O
other	O
models	O
.	O
	
All	O
of	O
our	O
models	O
converged	O
within	O
a	O
few	O
hours	O
on	O
a	O
machine	O
with	O
NVIDIA	O
Titan	O
Xp	O
GPU	O
.	O
	
We	O
also	O
plot	O
validation	B-Metric
accuracies	I-Metric
of	O
various	O
models	O
during	O
first	O
5	O
training	O
epochs	O
in	O
Figure	O
3	O
,	O
and	O
validate	O
that	O
our	O
Model	O
	
SST	B-Method
-	I-Method
2	I-Method
(	O
%	O
)	O
SST	B-Method
-	I-Method
5	I-Method
(	O
%	O
)	O
DMN	B-Method
[	O
reference	O
]	O
88.6	O
52.1	O
NSE	B-Method
[	O
reference	O
]	O
89.7	O
52.8	O
byte	O
-	O
mLSTM	B-Method
[	O
reference	O
]	O
	
91.8	O
52.9	O
BCN	O
+	O
Char	O
+	O
CoVe	O
[	O
reference	O
]	O
90.3	O
	
53.7	O
RNTN	B-Method
[	O
reference	O
]	O
	
85.4	O
45.7	O
Constituency	O
Tree	O
-	O
LSTM	B-Method
[	O
reference	O
]	O
88.0	O
51.0	O
NTI	O
-	O
SLSTM	O
-	O
LSTM	B-Method
[	O
reference	O
]	O
89.3	O
53.1	O
	
Latent	O
Syntax	O
Tree	O
-	O
LSTM	B-Method
86.5	O
-	O
Constituency	O
Tree	O
-	O
LSTM	B-Method
+	O
Recurrent	O
Dropout	O
[	O
reference	O
]	O
	
89.4	O
52.3	O
Gumbel	B-Method
Tree	I-Method
-	I-Method
LSTM	I-Method
(	O
Ours	O
)	O
	
90.7	O
53.7	O
Table	O
2	O
:	O
Results	O
of	O
SST	B-Method
experiments	I-Method
.	O
	
The	O
bottom	O
section	O
contains	O
results	O
of	O
RvNN	B-Method
-	I-Method
based	I-Method
models	I-Method
.	O
	
Underlined	O
score	O
indicates	O
the	O
best	O
among	O
RvNN	B-Method
-	I-Method
based	I-Method
models	I-Method
.	O
	
models	O
converge	O
significantly	O
faster	O
than	O
others	O
,	O
not	O
only	O
in	O
terms	O
of	O
total	B-Metric
training	I-Metric
time	I-Metric
but	O
also	O
in	O
the	O
number	O
of	O
iterations	O
.	O
	
section	O
:	O
5	O
	
section	O
:	O
Sentiment	B-Task
Analysis	I-Task
	
To	O
evaluate	O
the	O
performance	O
of	O
our	O
model	O
in	O
single	B-Task
-	I-Task
sentence	I-Task
classification	I-Task
,	O
we	O
conducted	O
experiments	O
on	O
Stanford	O
Sentiment	O
Treebank	O
(	O
SST	O
)	O
	
[	O
reference	O
]	O
dataset	O
.	O
	
In	O
the	O
SST	O
dataset	O
,	O
each	O
sentence	O
is	O
represented	O
as	O
a	O
binary	O
parse	O
tree	O
,	O
and	O
each	O
subtree	O
of	O
a	O
parse	O
tree	O
is	O
annotated	O
with	O
the	O
corresponding	O
sentiment	O
score	O
.	O
	
Following	O
the	O
experimental	O
setting	O
of	O
previous	O
works	O
,	O
we	O
use	O
all	O
subtrees	O
and	O
their	O
labels	O
for	O
training	O
,	O
and	O
only	O
the	O
root	O
labels	O
are	O
used	O
for	O
evaluation	B-Task
.	O
	
The	O
classifier	B-Method
has	O
a	O
similar	O
architecture	O
to	O
SNLI	B-Material
experiments	I-Material
.	O
	
Specifically	O
,	O
for	O
a	O
sentence	O
embedding	O
h	O
,	O
the	O
probability	O
for	O
the	O
sentence	O
to	O
be	O
predicted	O
as	O
label	O
s	O
∈	O
{	O
0	O
,	O
1	O
}	O
(	O
in	O
the	O
binary	O
setting	O
,	O
SST	O
-	O
2	O
)	O
or	O
s	O
∈	O
{	O
1	O
,	O
2	O
,	O
3	O
,	O
4	O
,	O
5	O
}	O
(	O
in	O
the	O
fine	O
-	O
grained	O
setting	O
,	O
SST	O
-	O
5	O
)	O
is	O
computed	O
as	O
follows	O
:	O
,	O
and	O
Φ	B-Method
is	O
a	O
single	B-Method
-	I-Method
hidden	I-Method
layer	I-Method
MLP	I-Method
with	O
the	O
ReLU	B-Method
activation	I-Method
function	I-Method
.	O
	
Note	O
that	O
subtrees	O
labeled	O
as	O
neutral	O
are	O
ignored	O
in	O
the	O
binary	O
setting	O
in	O
both	O
training	B-Task
and	O
evaluation	B-Task
.	O
	
We	O
trained	O
our	O
SST	B-Method
-	I-Method
2	I-Method
model	I-Method
with	O
hyperparameters	O
D	O
x	O
=	O
300	O
,	O
D	O
h	O
=	O
300	O
,	O
D	O
c	O
=	O
300	O
.	O
	
The	O
word	O
vectors	O
are	O
initialized	O
with	O
GloVe	O
300D	O
pretrained	O
vectors	O
and	O
fine	O
-	O
tuned	O
during	O
training	O
.	O
	
We	O
apply	O
dropout	B-Method
(	O
p	O
=	O
0.5	O
)	O
on	O
the	O
output	O
of	O
the	O
word	B-Method
embedding	I-Method
layer	I-Method
and	O
the	O
input	O
and	O
the	O
output	O
of	O
the	O
MLP	B-Method
layer	I-Method
.	O
	
The	O
size	O
of	O
mini	O
-	O
batches	O
is	O
set	O
to	O
32	O
and	O
Adadelta	B-Method
optimizer	I-Method
is	O
used	O
for	O
optimization	B-Task
.	O
	
For	O
our	O
SST	B-Method
-	I-Method
5	I-Method
model	I-Method
,	O
hyperparameters	O
are	O
set	O
to	O
D	O
x	O
=	O
300	O
,	O
D	O
h	O
=	O
300	O
,	O
D	O
c	O
=	O
1024	O
.	O
	
Similar	O
to	O
the	O
SST	B-Method
-	I-Method
2	I-Method
model	I-Method
,	O
we	O
optimize	O
the	O
model	O
using	O
Adadelta	B-Method
optimizer	I-Method
with	O
batch	O
size	O
64	O
and	O
apply	O
dropout	B-Method
with	O
p	O
=	O
0.5	O
.	O
	
Table	O
2	O
summarizes	O
the	O
results	O
of	O
SST	O
experiments	O
.	O
	
Our	O
SST	B-Method
-	I-Method
2	I-Method
model	I-Method
outperforms	O
all	O
other	O
models	O
substantially	O
[	O
reference	O
]	O
	
In	O
the	O
figure	O
,	O
our	O
models	O
and	O
300D	B-Method
NSE	I-Method
are	O
trained	O
with	O
batch	O
size	O
128	O
.	O
	
100D	O
CYK	B-Method
and	O
300D	B-Method
SPINN	I-Method
are	O
trained	O
with	O
batch	O
size	O
16	O
and	O
32	O
respectively	O
,	O
as	O
in	O
the	O
original	O
papers	O
.	O
	
We	O
observed	O
that	O
our	O
models	O
still	O
converge	O
faster	O
than	O
others	O
when	O
a	O
smaller	O
batch	O
size	O
(	O
16	O
or	O
32	O
)	O
is	O
used	O
.	O
except	O
	
byte	O
-	O
mLSTM	B-Method
(	O
Radford	O
,	O
Jozefowicz	O
,	O
and	O
Sutskever	O
2017	O
)	O
,	O
where	O
a	O
byte	B-Method
-	I-Method
level	I-Method
language	I-Method
model	I-Method
trained	O
on	O
the	O
large	O
product	O
review	O
dataset	O
is	O
used	O
to	O
obtain	O
sentence	B-Method
representations	I-Method
.	O
	
We	O
also	O
see	O
that	O
the	O
performance	O
of	O
our	O
SST	B-Method
-	I-Method
5	I-Method
model	I-Method
is	O
on	O
par	O
with	O
that	O
of	O
the	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
model	O
[	O
reference	O
]	O
,	O
which	O
is	O
pretrained	O
on	O
large	O
parallel	O
datasets	O
and	O
uses	O
character	O
n	O
-	O
gram	O
embeddings	O
alongside	O
word	O
embeddings	O
,	O
even	O
though	O
our	O
model	O
does	O
not	O
utilize	O
external	O
resources	O
other	O
than	O
GloVe	O
vectors	O
and	O
only	O
uses	O
wordlevel	B-Method
representations	I-Method
.	O
	
The	O
authors	O
of	O
[	O
reference	O
]	O
stated	O
that	O
utilizing	O
pretraining	B-Method
and	I-Method
character	I-Method
n	I-Method
-	I-Method
gram	I-Method
embeddings	I-Method
improves	O
validation	O
accuracy	B-Metric
by	O
2.8	O
%	O
(	O
SST	B-Method
-	I-Method
2	I-Method
)	O
or	O
1.7	O
%	O
(	O
SST	B-Method
-	I-Method
5	I-Method
)	O
.	O
	
In	O
addition	O
,	O
from	O
the	O
fact	O
that	O
our	O
models	O
substantially	O
outperform	O
all	O
other	O
RvNN	B-Method
-	I-Method
based	I-Method
models	I-Method
,	O
we	O
conjecture	O
that	O
task	O
-	O
specific	O
tree	O
structures	O
built	O
by	O
our	O
model	O
help	O
encode	O
sentences	O
into	O
vectors	O
more	O
efficiently	O
than	O
constituency	B-Method
-	I-Method
based	I-Method
or	I-Method
dependency	I-Method
-	I-Method
based	I-Method
parse	I-Method
trees	I-Method
do	O
.	O
	
section	O
:	O
Qualitative	B-Task
Analysis	I-Task
	
We	O
conduct	O
a	O
set	O
of	O
experiments	O
to	O
observe	O
various	O
properties	O
of	O
our	O
trained	O
models	O
.	O
	
First	O
,	O
to	O
see	O
how	O
well	O
the	O
model	O
encodes	O
sentences	O
with	O
similar	O
meaning	O
or	O
syntax	O
into	O
close	O
vectors	O
,	O
we	O
find	O
nearest	O
neighbors	O
of	O
a	O
query	O
sentence	O
.	O
	
Second	O
,	O
to	O
validate	O
that	O
the	O
trained	O
composition	B-Method
functions	I-Method
are	O
non	O
-	O
trivial	O
and	O
task	O
-	O
specific	O
,	O
we	O
visualize	O
trees	O
composed	O
by	O
SNLI	B-Material
and	O
SST	O
model	O
given	O
identical	O
sentence	O
.	O
	
Nearest	O
neighbors	O
	
We	O
encode	O
sentences	O
in	O
the	O
test	O
split	O
of	O
SNLI	B-Material
dataset	I-Material
using	O
the	O
trained	O
300D	B-Method
model	I-Method
and	O
find	O
nearest	O
neighbors	O
given	O
a	O
query	O
sentence	O
.	O
	
Table	O
3	O
presents	O
five	O
nearest	O
neighbors	O
for	O
each	O
selected	O
query	O
sentence	O
.	O
	
In	O
finding	B-Task
nearest	I-Task
neighbors	I-Task
,	O
cosine	B-Metric
distance	I-Metric
is	O
used	O
as	O
metric	O
.	O
	
The	O
result	O
shows	O
that	O
our	O
model	O
effectively	O
maps	O
similar	O
sentences	O
into	O
vectors	O
close	O
to	O
each	O
other	O
;	O
the	O
neighboring	O
sentences	O
are	O
similar	O
to	O
a	O
query	O
sentence	O
not	O
only	O
in	O
terms	O
of	O
word	O
overlap	O
,	O
but	O
also	O
in	O
semantics	O
.	O
	
For	O
example	O
in	O
the	O
second	O
column	O
,	O
the	O
nearest	O
sentence	O
is	O
'	O
the	O
woman	O
is	O
looking	O
at	O
a	O
dog	O
'	O
,	O
whose	O
meaning	O
is	O
almost	O
same	O
as	O
the	O
query	O
sentence	O
.	O
	
We	O
can	O
also	O
see	O
that	O
other	O
neighbors	O
partially	O
share	O
semantics	O
with	O
the	O
query	O
sentence	O
.	O
	
#	O
sunshine	O
is	O
on	O
a	O
man	O
's	O
face	O
.	O
	
a	O
girl	O
is	O
staring	O
at	O
a	O
dog	O
.	O
	
the	O
woman	O
is	O
wearing	O
boots	O
.	O
	
1	O
	
a	O
man	O
is	O
walking	O
on	O
sunshine	O
.	O
	
the	O
woman	O
is	O
looking	O
at	O
a	O
dog	O
.	O
	
the	O
girl	O
is	O
wearing	O
shoes	O
2	O
a	O
guy	O
is	O
in	O
a	O
hot	O
,	O
sunny	O
place	O
a	O
girl	O
takes	O
a	O
photo	O
of	O
a	O
dog	O
.	O
	
a	O
person	O
is	O
wearing	O
boots	O
.	O
	
3	O
a	O
man	O
is	O
working	O
in	O
the	O
sun	O
.	O
	
a	O
girl	O
is	O
petting	O
her	O
dog	O
.	O
	
the	O
woman	O
is	O
wearing	O
jeans	O
.	O
	
4	O
	
it	O
is	O
sunny	O
.	O
	
a	O
man	O
is	O
taking	O
a	O
picture	O
of	O
a	O
dog	O
,	O
while	O
a	O
woman	O
watches	O
.	O
	
a	O
woman	O
wearing	O
sunglasses	O
.	O
	
5	O
a	O
man	O
enjoys	O
the	O
sun	O
coming	O
through	O
the	O
window	O
.	O
	
a	O
woman	O
is	O
playing	O
with	O
her	O
dog	O
.	O
	
the	O
woman	O
is	O
wearing	O
a	O
vest	O
.	O
	
Tree	O
examples	O
	
Figure	O
4	O
show	O
that	O
two	O
models	O
(	O
300D	B-Method
SNLI	I-Method
and	O
SST	B-Method
-	I-Method
2	I-Method
)	O
generate	O
different	O
tree	O
structures	O
given	O
an	O
identical	O
sentence	O
.	O
	
In	O
Figure	O
4a	O
and	O
4b	O
,	O
the	O
SNLI	B-Material
model	I-Material
groups	O
the	O
phrase	O
'	O
i	O
love	O
this	O
'	O
first	O
,	O
while	O
the	O
SST	B-Method
model	I-Method
groups	O
'	O
this	O
very	O
much	O
'	O
first	O
.	O
	
Figure	O
4c	O
and	O
4d	O
present	O
how	O
differently	O
the	O
two	O
models	O
process	O
a	O
sentence	O
containing	O
relative	O
pronoun	O
	
'	O
which	O
'	O
.	O
	
It	O
is	O
intriguing	O
that	O
the	O
models	O
compose	O
visually	O
plausible	O
tree	O
structures	O
,	O
where	O
the	O
sentence	O
is	O
divided	O
into	O
two	O
phrases	O
by	O
relative	O
pronoun	O
,	O
even	O
though	O
they	O
are	O
trained	O
without	O
explicit	O
parse	O
trees	O
.	O
	
We	O
hypothesize	O
that	O
these	O
examples	O
demonstrate	O
that	O
each	O
model	O
generates	O
a	O
distinct	O
tree	O
structure	O
based	O
on	O
semantic	O
properties	O
of	O
the	O
task	O
and	O
learns	O
non	O
-	O
trivial	O
tree	B-Method
composition	I-Method
scheme	I-Method
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
Gumbel	B-Method
Tree	I-Method
-	I-Method
LSTM	I-Method
,	O
a	O
novel	O
Tree	O
-	O
LSTM	B-Method
-	O
based	O
architecture	O
that	O
learns	O
to	O
compose	O
taskspecific	O
tree	O
structures	O
.	O
	
Our	O
model	O
introduces	O
the	O
composition	O
query	O
vector	O
to	O
compute	O
validity	O
of	O
the	O
candidate	O
parents	O
and	O
selects	O
the	O
appropriate	O
parent	O
according	O
to	O
validity	O
scores	O
.	O
	
In	O
training	O
time	O
,	O
the	O
model	O
samples	O
the	O
parent	O
from	O
candidates	O
using	O
ST	B-Method
Gumbel	I-Method
-	I-Method
Softmax	I-Method
estimator	I-Method
,	O
hence	O
it	O
is	O
able	O
to	O
be	O
trained	O
by	O
standard	O
backpropagation	B-Method
while	O
maintaining	O
its	O
property	O
of	O
discretely	O
determining	O
the	O
computation	O
path	O
in	O
forward	B-Method
propagation	I-Method
.	O
	
From	O
experiments	O
,	O
we	O
validate	O
that	O
our	O
model	O
outperforms	O
all	O
other	O
RvNN	B-Method
models	I-Method
and	O
is	O
competitive	O
to	O
state	O
-	O
ofthe	O
-	O
art	O
models	O
,	O
and	O
also	O
observed	O
that	O
our	O
model	O
converges	O
faster	O
than	O
other	O
complex	O
models	O
.	O
	
The	O
result	O
poses	O
an	O
important	O
question	O
:	O
what	O
is	O
the	O
optimal	O
input	O
structure	O
for	O
RvNN	B-Method
?	O
	
We	O
empirically	O
showed	O
that	O
the	O
optimal	O
structure	O
might	O
differ	O
per	O
task	O
,	O
and	O
investigating	O
task	O
-	O
specific	O
latent	O
tree	O
structures	O
could	O
be	O
an	O
interesting	O
future	O
research	O
direction	O
.	O
	
For	O
future	O
work	O
,	O
we	O
plan	O
to	O
apply	O
the	O
core	O
idea	O
beyond	O
sentence	B-Task
encoding	I-Task
.	O
	
The	O
performance	O
could	O
be	O
further	O
improved	O
by	O
applying	O
intra	B-Method
-	I-Method
sentence	I-Method
or	I-Method
inter	I-Method
-	I-Method
sentence	I-Method
attention	I-Method
mechanisms	I-Method
.	O
	
We	O
also	O
plan	O
to	O
design	O
an	O
architecture	O
that	O
generates	O
sentences	O
using	O
recursive	O
structures	O
.	O
	
section	O
:	O
Implementation	O
Details	O
	
Implementation	O
-	O
wise	O
,	O
we	O
used	O
multiple	O
mask	O
matrices	O
in	O
implementing	O
the	O
proposed	O
Gumbel	B-Method
Tree	I-Method
-	I-Method
LSTM	I-Method
model	O
.	O
	
Using	O
the	O
mask	O
matrices	O
,	O
Eq	O
.	O
11	O
can	O
be	O
rewritten	O
as	O
a	O
single	O
equation	O
:	O
	
,	O
and	O
r	O
	
is	O
a	O
matrix	O
whose	O
columns	O
are	O
r	O
	
The	O
mask	O
matrices	O
are	O
defined	O
by	O
the	O
following	O
equations	O
.	O
	
is	O
a	O
vector	O
which	O
will	O
be	O
defined	O
below	O
,	O
and	O
1	O
∈	O
R	O
Mt	O
+	O
1	O
is	O
a	O
vector	O
whose	O
values	O
are	O
all	O
ones	O
.	O
	
In	O
the	O
forward	O
pass	O
,	O
ȳ	O
1:Mt	O
+	O
1	O
is	O
defined	O
by	O
a	O
one	B-Method
-	I-Method
hot	I-Method
vector	I-Method
y	I-Method
ST	I-Method
1:Mt	I-Method
+	I-Method
1	I-Method
,	O
which	O
is	O
sampled	O
from	O
the	O
categorical	O
distribution	O
of	O
validity	O
scores	O
(	O
v	O
1	O
,	O
·	O
·	O
·	O
,	O
v	O
Mt	O
+	O
1	O
)	O
using	O
Gumbel	B-Method
-	I-Method
Max	I-Method
trick	I-Method
.	O
	
is	O
added	O
when	O
calculating	O
g	O
i	O
for	O
numerical	O
stability	O
.	O
	
In	O
the	O
backward	O
pass	O
,	O
instead	O
of	O
the	O
one	B-Method
-	I-Method
hot	I-Method
version	I-Method
,	O
the	O
continuous	O
vector	O
y	O
1:Mt	O
+	O
1	O
obtained	O
from	O
Gumbel	B-Method
-	I-Method
Softmax	I-Method
is	O
used	O
asȳ	O
1:Mt	O
+	O
1	O
.	O
	
Note	O
that	O
the	O
Gumbel	O
noise	O
samples	O
g	O
1	O
,	O
·	O
·	O
·	O
,	O
g	O
Mt	O
+	O
1	O
drawn	O
in	O
the	O
forward	O
pass	O
are	O
reused	O
in	O
the	O
backward	O
pass	O
(	O
i.e.	O
noise	O
values	O
are	O
not	O
resampled	O
in	O
the	O
backward	O
pass	O
)	O
.	O
	
In	O
typical	O
deep	B-Method
learning	I-Method
libraries	I-Method
supporting	O
automatic	B-Task
differentiation	I-Task
(	O
e.g.	O
PyTorch	O
,	O
TensorFlow	O
)	O
,	O
this	O
discrepancy	O
between	O
forward	O
and	O
backward	O
pass	O
can	O
be	O
implemented	O
as	O
y	B-Method
1:Mt	I-Method
+	I-Method
1	I-Method
=	O
	
detach	O
(	O
y	O
ST	O
1:Mt	O
+	O
1	O
	
−	O
y	O
1:Mt	O
+	O
1	O
)	O
+	O
y	O
1:Mt	O
+	O
1	O
,	O
(	O
S11	O
)	O
	
where	O
detach	O
(	O
·	O
)	O
is	O
a	O
function	O
that	O
prevents	O
error	O
from	O
backpropagating	O
through	O
its	O
input	O
.	O
	
section	O
:	O
Detailed	O
Experimental	O
Settings	O
	
All	O
experiments	O
are	O
conducted	O
using	O
the	O
publicized	O
codebase	O
.	O
	
section	O
:	O
1	O
	
section	O
:	O
SNLI	B-Material
	
The	O
composition	O
query	O
vector	O
is	O
initialized	O
by	O
sampling	O
from	O
Gaussian	B-Method
distribution	I-Method
N	I-Method
(	O
0	O
,	O
0.01	O
	
2	O
)	O
.	O
	
The	O
last	O
linear	B-Method
transformation	I-Method
that	O
outputs	O
the	O
unnormalized	O
log	O
probability	O
for	O
each	O
class	O
is	O
initialized	O
by	O
sampling	O
from	O
uniform	O
distribution	O
U	O
(	O
−0.005	O
,	O
0.005	O
)	O
.	O
	
All	O
other	O
parameters	O
are	O
initialized	O
following	O
the	O
scheme	O
proposed	O
by	O
[	O
reference	O
]	O
.	O
	
We	O
used	O
Adam	B-Method
optimizer	I-Method
with	O
default	O
hyperparameters	O
and	O
halved	O
learning	B-Metric
rate	I-Metric
if	O
there	O
is	O
no	O
improvement	O
in	O
accuracy	B-Metric
for	O
one	O
epoch	O
.	O
	
The	O
size	O
of	O
minibatch	O
is	O
set	O
to	O
128	O
in	O
all	O
experiments	O
.	O
	
In	O
100D	O
experiments	O
(	O
D	O
x	O
=	O
D	O
h	O
=	O
100	O
,	O
D	O
c	O
=	O
200	O
,	O
single	B-Method
-	I-Method
hidden	I-Method
layer	I-Method
MLP	I-Method
classifier	I-Method
)	O
,	O
GloVe	B-Method
(	O
6B	O
,	O
100D	O
)	O
pretrained	B-Method
word	I-Method
embeddings	I-Method
are	O
used	O
in	O
initializing	O
word	B-Method
representations	I-Method
.	O
	
We	O
fine	O
-	O
tuned	O
word	O
embedding	O
parameters	O
during	O
training	O
.	O
	
In	O
300D	O
(	O
D	O
x	O
=	O
D	O
h	O
=	O
300	O
,	O
D	O
c	O
=	O
1024	O
,	O
single	O
-	O
hidden	B-Method
layer	I-Method
MLP	I-Method
classifier	I-Method
)	O
and	O
600D	O
(	O
D	O
x	O
=	O
300	O
,	O
D	O
h	O
	
=	O
600	O
,	O
	
D	O
c	O
=	O
1024	O
,	O
MLP	B-Method
classifier	I-Method
with	O
three	O
hidden	O
layers	O
)	O
experiments	O
,	O
GloVe	B-Method
(	O
840B	O
,	O
300D	O
)	O
	
pretrained	B-Method
word	I-Method
embeddings	I-Method
are	O
used	O
as	O
word	B-Method
representations	I-Method
and	O
fixed	O
during	O
training	O
.	O
	
Batch	B-Method
normalization	I-Method
is	O
applied	O
before	O
the	O
input	O
and	O
after	O
the	O
output	O
of	O
the	O
MLP	B-Method
.	O
	
Dropout	B-Method
is	O
applied	O
to	O
word	O
embeddings	O
and	O
the	O
input	O
and	O
the	O
output	O
of	O
the	O
MLP	B-Method
with	O
dropout	O
probability	O
0.1	O
(	O
300D	O
)	O
or	O
0.2	O
(	O
600D	O
)	O
.	O
	
section	O
:	O
SST	O
	
The	O
composition	O
query	O
vector	O
is	O
initialized	O
by	O
sampling	O
from	O
Gaussian	B-Method
distribution	I-Method
N	I-Method
(	O
0	O
,	O
0.01	O
	
2	O
)	O
.	O
	
The	O
last	O
linear	B-Method
transformation	I-Method
that	O
outputs	O
the	O
unnormalized	O
log	O
probability	O
for	O
each	O
class	O
is	O
initialized	O
by	O
sampling	O
from	O
uniform	O
distribution	O
U	O
(	O
−0.002	O
,	O
0.002	O
)	O
.	O
	
All	O
other	O
parameters	O
are	O
initialized	O
following	O
the	O
scheme	O
proposed	O
by	O
[	O
reference	O
]	O
.	O
	
We	O
used	O
Adadelta	B-Method
optimizer	I-Method
)	O
with	O
default	O
hyperparameters	O
and	O
halved	O
learning	B-Metric
rate	I-Metric
if	O
there	O
is	O
no	O
improvement	O
in	O
accuracy	B-Metric
for	O
two	O
epochs	O
.	O
	
In	O
both	O
SST	B-Method
-	I-Method
2	I-Method
and	O
SST	B-Method
-	I-Method
5	I-Method
experiments	O
,	O
we	O
set	O
D	O
x	O
=	O
	
D	O
h	O
=	O
300	O
,	O
used	O
GloVe	O
(	O
840B	O
,	O
300D	O
)	O
pretrained	O
vectors	O
with	O
fine	B-Method
-	I-Method
tuning	I-Method
,	O
and	O
single	B-Method
-	I-Method
hidden	I-Method
layer	I-Method
MLP	I-Method
is	O
used	O
as	O
classifier	B-Method
.	O
	
Dropout	B-Method
is	O
applied	O
to	O
word	O
embeddings	O
and	O
the	O
input	O
and	O
the	O
output	O
of	O
the	O
MLP	B-Method
classifier	I-Method
with	O
probability	B-Method
0.5	I-Method
.	O
	
In	O
the	O
SST	B-Task
-	I-Task
2	I-Task
experiment	O
,	O
we	O
set	O
D	O
c	O
to	O
300	O
and	O
set	O
batch	O
size	O
to	O
32	O
.	O
	
In	O
the	O
SST	B-Method
-	I-Method
5	I-Method
experiment	O
,	O
D	O
c	O
is	O
increased	O
to	O
1024	O
,	O
and	O
mini	O
-	O
batches	O
of	O
64	O
sentences	O
are	O
fed	O
to	O
the	O
model	O
during	O
training	O
.	O
	
section	O
:	O
	
section	O
:	O
Acknowledgments	O
	
This	O
work	O
is	O
part	O
of	O
SNU	B-Task
-	I-Task
Samsung	I-Task
smart	I-Task
campus	I-Task
research	I-Task
program	I-Task
,	O
which	O
is	O
supported	O
by	O
Samsung	O
Electronics	O
.	O
	
The	O
authors	O
would	O
like	O
to	O
thank	O
anonymous	O
reviewers	O
for	O
valuable	O
comments	O
and	O
Volkan	O
Cirik	O
for	O
helpful	O
feedback	O
on	O
the	O
early	O
version	O
of	O
the	O
manuscript	O
.	O
	
section	O
:	O
	
section	O
:	O
Appendix	O
	
The	O
supplementary	O
material	O
is	O
available	O
at	O
https:	O
//	O
github.com	O
/	O
jihunchoi	O
/	O
unsupervised	O
-	O
treelstm	O
/	O
blob	O
/	O
master	O
/	O
aaai18	O
/	O
supp.pdf	O
.	O
	
section	O
:	O
	
Fast	B-Task
Online	I-Task
Object	I-Task
Tracking	I-Task
and	I-Task
Segmentation	I-Task
:	O
	
A	O
Unifying	B-Method
Approach	I-Method
	
section	O
:	O
Abstract	O
	
In	O
this	O
paper	O
we	O
illustrate	O
how	O
to	O
perform	O
both	O
visual	B-Task
object	I-Task
tracking	I-Task
and	O
semi	B-Task
-	I-Task
supervised	I-Task
video	I-Task
object	I-Task
segmentation	I-Task
,	O
in	O
real	O
-	O
time	O
,	O
with	O
a	O
single	O
simple	O
approach	O
.	O
	
Our	O
method	O
,	O
dubbed	O
SiamMask	B-Method
,	O
improves	O
the	O
offline	B-Method
training	I-Method
procedure	I-Method
of	O
popular	O
fully	B-Method
-	I-Method
convolutional	I-Method
Siamese	I-Method
approaches	I-Method
for	O
object	B-Task
tracking	I-Task
by	O
augmenting	O
their	O
loss	O
with	O
a	O
binary	B-Task
segmentation	I-Task
task	I-Task
.	O
	
Once	O
trained	O
,	O
SiamMask	B-Method
solely	O
relies	O
on	O
a	O
single	O
bounding	B-Method
box	I-Method
initialisation	I-Method
and	O
operates	O
online	O
,	O
producing	O
class	B-Method
-	I-Method
agnostic	I-Method
object	I-Method
segmentation	I-Method
masks	I-Method
and	O
rotated	O
bounding	O
boxes	O
at	O
35	O
frames	O
per	O
second	O
.	O
	
Despite	O
its	O
simplicity	O
,	O
versatility	O
and	O
fast	O
speed	O
,	O
our	O
strategy	O
allows	O
us	O
to	O
establish	O
a	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
among	O
real	B-Method
-	I-Method
time	I-Method
trackers	I-Method
on	O
VOT	B-Material
-	I-Material
2018	I-Material
,	O
while	O
at	O
the	O
same	O
time	O
demonstrating	O
competitive	O
performance	O
and	O
the	O
best	O
speed	O
for	O
the	O
semisupervised	B-Task
video	I-Task
object	I-Task
segmentation	I-Task
task	I-Task
on	O
DAVIS	O
-	O
2016	O
and	O
DAVIS	O
-	O
2017	O
.	O
	
The	O
project	O
website	O
is	O
http:	O
//	O
www	O
.	O
robots.ox.ac.uk	O
/	O
˜qwang	O
/	O
SiamMask	B-Method
.	O
	
section	O
:	O
Introduction	O
	
Tracking	B-Task
is	O
a	O
fundamental	O
task	O
in	O
any	O
video	B-Task
application	I-Task
requiring	O
some	O
degree	O
of	O
reasoning	O
about	O
objects	O
of	O
interest	O
,	O
as	O
it	O
allows	O
to	O
establish	O
object	O
correspondances	O
between	O
frames	O
	
[	O
reference	O
]	O
.	O
It	O
finds	O
use	O
in	O
a	O
wide	O
range	O
of	O
scenarios	O
such	O
as	O
automatic	B-Task
surveillance	I-Task
,	O
vehicle	B-Task
navigation	I-Task
,	O
video	B-Task
labelling	I-Task
,	O
human	B-Task
-	I-Task
computer	I-Task
interaction	I-Task
and	O
activity	B-Task
recognition	I-Task
.	O
	
Given	O
the	O
location	O
of	O
an	O
arbitrary	O
target	O
of	O
interest	O
in	O
the	O
first	O
frame	O
of	O
a	O
video	O
,	O
the	O
aim	O
of	O
visual	B-Task
object	I-Task
tracking	I-Task
is	O
to	O
estimate	O
its	O
position	O
in	O
all	O
the	O
subsequent	O
frames	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
	
For	O
many	O
applications	O
,	O
it	O
is	O
important	O
that	O
tracking	B-Task
can	O
be	O
performed	O
online	O
,	O
while	O
the	O
video	O
is	O
streaming	O
.	O
	
In	O
other	O
words	O
,	O
the	O
tracker	O
should	O
not	O
make	O
use	O
of	O
future	O
frames	O
to	O
*	O
Equal	O
contribution	O
.	O
	
Work	O
done	O
while	O
at	O
University	O
of	O
Oxford	O
.	O
	
section	O
:	O
Init	O
	
Estimates	O
Figure	O
1	O
.	O
	
Our	O
proposed	O
method	O
aims	O
at	O
distilling	O
the	O
best	O
from	O
the	O
two	O
tasks	O
of	O
object	B-Task
tracking	I-Task
and	O
video	B-Task
object	I-Task
segmentation	I-Task
.	O
	
Like	O
conventional	O
object	B-Method
trackers	I-Method
,	O
it	O
relies	O
on	O
a	O
simple	O
bounding	B-Method
box	I-Method
initialisation	I-Method
(	O
blue	O
)	O
and	O
operates	O
online	O
.	O
	
Differently	O
from	O
state	O
-	O
ofthe	O
-	O
art	O
trackers	O
such	O
as	O
ECO	B-Method
[	O
reference	O
]	O
(	O
red	O
)	O
,	O
SiamMask	B-Method
(	O
green	O
)	O
is	O
able	O
to	O
produce	O
binary	O
segmentation	O
masks	O
,	O
which	O
can	O
more	O
accurately	O
describe	O
the	O
target	O
object	O
.	O
	
reason	O
about	O
the	O
current	O
position	O
of	O
the	O
object	O
	
[	O
reference	O
]	O
.	O
This	O
is	O
the	O
scenario	O
portrayed	O
by	O
visual	B-Task
object	I-Task
tracking	I-Task
benchmarks	O
,	O
which	O
represent	O
the	O
target	O
object	O
with	O
a	O
simple	O
axisaligned	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
or	O
rotated	O
[	O
reference	O
]	O
bounding	O
box	O
.	O
	
Such	O
a	O
simple	O
annotation	O
helps	O
to	O
keep	O
the	O
cost	O
of	O
data	B-Task
labelling	I-Task
low	O
;	O
what	O
is	O
more	O
,	O
it	O
allows	O
a	O
user	O
to	O
perform	O
a	O
quick	O
and	O
simple	O
initialisation	O
of	O
the	O
target	O
.	O
	
Similar	O
to	O
object	B-Task
tracking	I-Task
,	O
the	O
task	O
of	O
semi	B-Task
-	I-Task
supervised	I-Task
video	I-Task
object	I-Task
segmentation	I-Task
(	O
VOS	B-Task
)	O
requires	O
estimating	O
the	O
position	O
of	O
an	O
arbitrary	O
target	O
specified	O
in	O
the	O
first	O
frame	O
of	O
a	O
video	O
.	O
	
However	O
,	O
in	O
this	O
case	O
the	O
object	B-Method
representation	I-Method
consists	O
of	O
a	O
binary	B-Method
segmentation	I-Method
mask	I-Method
which	O
expresses	O
whether	O
each	O
pixel	O
belongs	O
to	O
the	O
target	O
or	O
not	O
	
[	O
reference	O
]	O
.	O
Such	O
a	O
detailed	B-Method
representation	I-Method
is	O
more	O
desirable	O
for	O
applications	O
that	O
require	O
pixel	O
-	O
level	O
information	O
,	O
like	O
video	B-Task
editing	I-Task
[	O
reference	O
]	O
and	O
rotoscoping	O
[	O
reference	O
]	O
.	O
Understandably	O
,	O
producing	O
pixel	B-Task
-	I-Task
level	I-Task
estimates	I-Task
requires	O
more	O
computational	O
re	O
-	O
sources	O
than	O
a	O
simple	O
bounding	B-Method
box	I-Method
.	O
	
As	O
a	O
consequence	O
,	O
VOS	B-Method
methods	I-Method
have	O
been	O
traditionally	O
slow	O
,	O
often	O
requiring	O
several	O
seconds	O
per	O
frame	O
(	O
e.g.	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
)	O
.	O
	
Very	O
recently	O
,	O
there	O
has	O
been	O
a	O
surge	O
of	O
interest	O
in	O
faster	O
approaches	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
	
However	O
,	O
even	O
the	O
fastest	O
still	O
can	O
not	O
operate	O
in	O
real	O
-	O
time	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
aim	O
at	O
narrowing	O
the	O
gap	O
between	O
arbitrary	B-Task
object	I-Task
tracking	I-Task
and	O
VOS	B-Task
by	O
proposing	O
SiamMask	B-Method
,	O
a	O
simple	O
multi	B-Method
-	I-Method
task	I-Method
learning	I-Method
approach	I-Method
that	O
can	O
be	O
used	O
to	O
address	O
both	O
problems	O
.	O
	
Our	O
method	O
is	O
motivated	O
by	O
the	O
success	O
of	O
fast	B-Method
tracking	I-Method
approaches	I-Method
based	O
on	O
fullyconvolutional	B-Method
Siamese	I-Method
networks	I-Method
trained	O
offline	O
on	O
millions	O
of	O
pairs	O
of	O
video	O
frames	O
[	O
reference	O
][	O
reference	O
]	O
and	O
by	O
the	O
very	O
recent	O
availability	O
of	O
a	O
large	O
video	O
dataset	O
with	O
pixel	O
-	O
wise	O
annotations	O
such	O
as	O
YouTube	O
-	O
VOS	O
	
[	O
reference	O
]	O
.	O
	
We	O
aim	O
at	O
retaining	O
the	O
offline	B-Metric
trainability	I-Metric
and	O
online	B-Metric
speed	I-Metric
of	O
these	O
methods	O
while	O
at	O
the	O
same	O
time	O
significantly	O
refining	O
their	O
representation	O
of	O
the	O
target	O
object	O
,	O
which	O
is	O
limited	O
to	O
a	O
simple	O
axis	O
-	O
aligned	O
bounding	O
box	O
.	O
	
To	O
achieve	O
this	O
goal	O
,	O
we	O
simultaneously	O
train	O
a	O
Siamese	B-Method
network	I-Method
on	O
three	O
tasks	O
,	O
each	O
corresponding	O
to	O
a	O
different	O
strategy	O
to	O
establish	O
correspondances	O
between	O
the	O
target	O
object	O
and	O
candidate	O
regions	O
in	O
the	O
new	O
frames	O
.	O
	
As	O
in	O
the	O
fully	B-Method
-	I-Method
convolutional	I-Method
approach	I-Method
of	O
Bertinetto	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
	
,	O
one	O
task	O
is	O
to	O
learn	O
a	O
measure	O
of	O
similarity	O
between	O
the	O
target	O
object	O
and	O
multiple	O
candidates	O
in	O
a	O
sliding	B-Method
window	I-Method
fashion	I-Method
.	O
	
The	O
output	O
is	O
a	O
dense	O
response	O
map	O
which	O
only	O
indicates	O
the	O
location	O
of	O
the	O
object	O
,	O
without	O
providing	O
any	O
information	O
about	O
its	O
spatial	O
extent	O
.	O
	
To	O
refine	O
this	O
information	O
,	O
we	O
simultaneously	O
learn	O
two	O
further	O
tasks	O
:	O
bounding	B-Method
box	I-Method
regression	I-Method
using	O
a	O
Region	B-Method
Proposal	I-Method
Network	I-Method
[	O
reference	O
][	O
reference	O
]	O
and	O
classagnostic	B-Method
binary	I-Method
segmentation	I-Method
	
[	O
reference	O
]	O
.	O
Notably	O
,	O
binary	O
labels	O
are	O
only	O
required	O
during	O
offline	B-Task
training	I-Task
to	O
compute	O
the	O
segmentation	B-Task
loss	I-Task
and	O
not	O
during	O
tracking	B-Task
.	O
	
In	O
our	O
proposed	O
architecture	O
,	O
each	O
task	O
is	O
represented	O
by	O
a	O
different	O
branch	O
departing	O
from	O
a	O
shared	B-Method
CNN	I-Method
and	O
contributes	O
towards	O
a	O
final	O
loss	B-Metric
,	O
which	O
sums	O
the	O
three	O
outputs	O
together	O
.	O
	
Once	O
trained	O
,	O
SiamMask	B-Method
solely	O
relies	O
on	O
a	O
single	O
bounding	B-Method
box	I-Method
initialisation	I-Method
,	O
operates	O
online	O
without	O
updates	O
and	O
produces	O
object	O
segmentation	O
masks	O
and	O
rotated	O
bounding	O
boxes	O
at	O
35	O
frames	O
per	O
second	O
.	O
	
Despite	O
its	O
simplicity	O
and	O
fast	O
speed	O
,	O
SiamMask	B-Method
establishes	O
a	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
on	O
VOT	B-Material
-	I-Material
2018	I-Material
for	O
the	O
problem	O
of	O
real	B-Task
-	I-Task
time	I-Task
object	I-Task
tracking	I-Task
.	O
	
Moreover	O
,	O
the	O
same	O
method	O
is	O
also	O
very	O
competitive	O
against	O
recent	O
semi	B-Method
-	I-Method
supervised	I-Method
VOS	I-Method
approaches	I-Method
on	O
DAVIS	O
-	O
2016	O
and	O
DAVIS	O
-	O
2017	O
,	O
while	O
being	O
the	O
fastest	O
by	O
a	O
large	O
margin	O
.	O
	
This	O
result	O
is	O
achieved	O
with	O
a	O
simple	O
bounding	B-Method
box	I-Method
initialisation	I-Method
(	O
as	O
opposed	O
to	O
a	O
mask	O
)	O
and	O
without	O
adopting	O
costly	O
techniques	O
often	O
used	O
by	O
VOS	B-Method
approaches	I-Method
such	O
as	O
fine	B-Method
-	I-Method
tuning	I-Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
,	O
data	B-Method
augmentation	I-Method
[	O
reference	O
][	O
reference	O
]	O
and	O
optical	B-Method
flow	I-Method
	
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
	
The	O
rest	O
of	O
this	O
paper	O
is	O
organised	O
as	O
follows	O
.	O
	
Section	O
2	O
briefly	O
outlines	O
some	O
of	O
the	O
most	O
relevant	O
prior	O
work	O
in	O
visual	B-Task
object	I-Task
tracking	I-Task
and	O
semi	B-Task
-	I-Task
supervised	I-Task
VOS	I-Task
;	O
Section	O
3	O
describes	O
our	O
proposal	O
;	O
Section	O
4	O
evaluates	O
it	O
on	O
four	O
benchmarks	O
and	O
illustrates	O
several	O
ablative	O
studies	O
;	O
Section	O
5	O
concludes	O
the	O
paper	O
.	O
	
section	O
:	O
Related	O
Work	O
	
In	O
this	O
section	O
,	O
we	O
briefly	O
cover	O
most	O
representative	O
techniques	O
for	O
the	O
two	O
problems	O
tackled	O
in	O
this	O
paper	O
.	O
	
Visual	B-Task
object	I-Task
tracking	I-Task
.	O
	
Arguably	O
,	O
until	O
very	O
recently	O
,	O
the	O
most	O
popular	O
paradigm	O
for	O
tracking	B-Task
arbitrary	I-Task
objects	I-Task
has	O
been	O
to	O
train	O
online	O
a	O
discriminative	B-Method
classifier	I-Method
exclusively	O
from	O
the	O
ground	O
-	O
truth	O
information	O
provided	O
in	O
the	O
first	O
frame	O
of	O
a	O
video	O
(	O
and	O
then	O
update	O
it	O
online	O
)	O
.	O
	
This	O
strategy	O
has	O
often	O
been	O
referred	O
to	O
as	O
tracking	B-Task
-	I-Task
by	I-Task
-	I-Task
detection	I-Task
(	O
e.g.	O
[	O
reference	O
][	O
reference	O
]	O
)	O
.	O
	
In	O
the	O
past	O
few	O
years	O
,	O
the	O
Correlation	B-Method
Filter	I-Method
,	O
a	O
simple	O
algorithm	O
that	O
allows	O
to	O
discriminate	O
between	O
the	O
template	O
of	O
an	O
arbitrary	O
target	O
and	O
its	O
2D	O
translations	O
,	O
rose	O
to	O
prominence	O
as	O
particularly	O
fast	O
and	O
effective	O
strategy	O
for	O
tracking	B-Task
-	I-Task
by	I-Task
-	I-Task
detection	I-Task
thanks	O
to	O
the	O
pioneering	O
work	O
of	O
Bolme	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
.	O
Performance	O
of	O
Correlation	B-Method
Filter	I-Method
-	I-Method
based	I-Method
trackers	I-Method
has	O
then	O
been	O
notably	O
improved	O
with	O
the	O
adoption	O
of	O
multi	B-Method
-	I-Method
channel	I-Method
formulations	I-Method
[	O
reference	O
][	O
reference	O
]	O
,	O
spatial	O
constraints	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
and	O
deep	O
features	O
(	O
e.g.	O
[	O
reference	O
][	O
reference	O
]	O
)	O
.	O
	
Recently	O
,	O
a	O
radically	O
different	O
approach	O
has	O
been	O
introduced	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
Instead	O
of	O
learning	O
a	O
discrimative	B-Method
classifier	I-Method
online	O
,	O
the	O
idea	O
is	O
to	O
train	O
(	O
offline	O
)	O
a	O
similarity	B-Method
function	I-Method
on	O
pairs	O
of	O
video	O
frames	O
.	O
	
At	O
test	O
time	O
,	O
this	O
function	O
can	O
be	O
simply	O
evaluated	O
on	O
a	O
new	O
video	O
,	O
once	O
per	O
frame	O
.	O
	
Evolutions	O
of	O
the	O
fully	B-Method
-	I-Method
convolutional	I-Method
Siamese	I-Method
approach	I-Method
[	O
reference	O
]	O
considerably	O
improved	O
tracking	B-Task
performance	O
by	O
making	O
use	O
of	O
region	B-Method
proposals	I-Method
[	O
reference	O
]	O
,	O
hard	B-Method
negative	I-Method
mining	I-Method
[	O
reference	O
]	O
,	O
ensembling	B-Method
[	O
reference	O
]	O
and	O
memory	B-Method
networks	I-Method
[	O
reference	O
]	O
.	O
	
Most	O
modern	O
trackers	O
,	O
including	O
all	O
the	O
ones	O
mentioned	O
above	O
,	O
use	O
a	O
rectangular	O
bounding	O
box	O
both	O
to	O
initialise	O
the	O
target	O
and	O
to	O
estimate	O
its	O
position	O
in	O
the	O
subsequent	O
frames	O
.	O
	
Despite	O
its	O
convenience	O
,	O
a	O
simple	O
rectangle	O
often	O
fails	O
to	O
properly	O
represent	O
an	O
object	O
,	O
as	O
it	O
is	O
evident	O
in	O
the	O
examples	O
of	O
Figure	O
1	O
.	O
	
This	O
motivated	O
us	O
to	O
propose	O
a	O
tracker	B-Method
able	O
to	O
produce	O
binary	O
segmentation	O
masks	O
while	O
still	O
only	O
relying	O
on	O
a	O
bounding	B-Method
box	I-Method
initialisation	I-Method
.	O
	
Interestingly	O
,	O
in	O
the	O
past	O
it	O
was	O
not	O
uncommon	O
for	O
trackers	B-Method
to	O
produce	O
a	O
coarse	O
binary	O
mask	O
of	O
the	O
target	O
object	O
(	O
e.g.	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
)	O
.	O
	
However	O
,	O
to	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
the	O
only	O
recent	O
tracker	O
that	O
,	O
like	O
ours	O
,	O
is	O
able	O
to	O
operate	O
online	O
and	O
produce	O
a	O
binary	O
mask	O
starting	O
from	O
a	O
bounding	B-Method
box	I-Method
initialisation	I-Method
is	O
the	O
superpixel	B-Method
-	I-Method
based	I-Method
approach	I-Method
of	O
Yeo	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
.	O
	
However	O
,	O
at	O
4	O
frames	O
per	O
seconds	O
(	O
fps	O
)	O
,	O
its	O
fastest	O
variant	O
is	O
significantly	O
slower	O
that	O
our	O
proposal	O
(	O
35	O
fps	O
)	O
.	O
	
Furthermore	O
,	O
When	O
using	O
CNN	O
features	O
,	O
its	O
speed	O
is	O
affected	O
by	O
a	O
60	O
-	O
fold	O
decrease	O
,	O
plummeting	O
below	O
0.1	O
fps	O
.	O
	
Finally	O
,	O
it	O
has	O
not	O
demonstrated	O
to	O
be	O
competitive	O
on	O
mod	B-Task
-	I-Task
ern	I-Task
tracking	I-Task
or	O
VOS	B-Method
benchmarks	I-Method
[	O
reference	O
]	O
.	O
	
Similar	O
to	O
us	O
,	O
the	O
methods	O
of	O
Perazzi	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
and	O
Ci	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
can	O
also	O
start	O
from	O
a	O
rectangle	O
and	O
output	O
per	O
-	O
frame	O
masks	O
.	O
	
However	O
,	O
they	O
require	O
fine	O
-	O
tuning	O
at	O
test	O
time	O
,	O
which	O
makes	O
them	O
slow	O
.	O
	
Semi	B-Task
-	I-Task
supervised	I-Task
video	I-Task
object	I-Task
segmentation	I-Task
.	O
	
Benchmarks	O
for	O
arbitrary	B-Task
object	I-Task
tracking	I-Task
(	O
e.g.	O
[	O
reference	O
][	O
reference	O
]	O
)	O
assume	O
that	O
trackers	O
receive	O
input	O
frames	O
in	O
a	O
sequential	O
fashion	O
.	O
	
This	O
aspect	O
is	O
generally	O
referred	O
to	O
with	O
the	O
attributes	O
online	O
or	O
causal	O
	
[	O
reference	O
]	O
.	O
	
Moreover	O
,	O
methods	O
are	O
often	O
focused	O
on	O
achieving	O
a	O
speed	O
that	O
exceeds	O
the	O
ones	O
of	O
typical	O
video	O
framerates	O
	
[	O
reference	O
]	O
.	O
Conversely	O
,	O
semi	B-Method
-	I-Method
supervised	I-Method
VOS	I-Method
algorithms	I-Method
have	O
been	O
traditionally	O
more	O
concerned	O
with	O
an	O
accurate	O
representation	O
of	O
the	O
object	O
of	O
interest	O
[	O
reference	O
][	O
reference	O
]	O
.	O
	
In	O
order	O
to	O
exploit	O
consistency	O
between	O
video	O
frames	O
,	O
several	O
methods	O
propagate	O
the	O
supervisory	O
segmentation	O
mask	O
of	O
the	O
first	O
frame	O
to	O
the	O
temporally	O
adjacent	O
ones	O
via	O
graph	B-Method
labeling	I-Method
approaches	I-Method
(	O
e.g.	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
)	O
.	O
	
In	O
particular	O
,	O
Bao	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
recently	O
proposed	O
a	O
very	O
accurate	O
method	O
that	O
makes	O
use	O
of	O
a	O
spatio	B-Method
-	I-Method
temporal	I-Method
MRF	I-Method
in	O
which	O
temporal	O
dependencies	O
are	O
modelled	O
by	O
optical	O
flow	O
,	O
while	O
spatial	O
dependencies	O
are	O
expressed	O
by	O
a	O
CNN	B-Method
.	O
	
Another	O
popular	O
strategy	O
is	O
to	O
process	O
video	O
frames	O
independently	O
(	O
e.g.	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
)	O
,	O
similarly	O
to	O
what	O
happens	O
in	O
most	O
tracking	B-Method
approaches	I-Method
.	O
	
For	O
example	O
,	O
in	O
OSVOS	O
-	O
S	O
Maninis	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
do	O
not	O
make	O
use	O
of	O
any	O
temporal	O
information	O
.	O
	
They	O
rely	O
on	O
a	O
fully	B-Method
-	I-Method
convolutional	I-Method
network	I-Method
pretrained	O
for	O
classification	B-Task
and	O
then	O
,	O
at	O
test	O
time	O
,	O
they	O
finetune	O
it	O
using	O
the	O
ground	O
-	O
truth	O
mask	O
provided	O
in	O
the	O
first	O
frame	O
.	O
	
MaskTrack	B-Method
[	O
reference	O
]	O
instead	O
is	O
trained	O
from	O
scratch	O
on	O
individual	O
images	O
,	O
but	O
it	O
does	O
exploit	O
some	O
form	O
of	O
temporality	O
at	O
test	O
time	O
by	O
using	O
the	O
latest	O
mask	O
prediction	O
and	O
optical	O
flow	O
as	O
additional	O
input	O
to	O
the	O
network	O
.	O
	
Aiming	O
towards	O
the	O
highest	O
possible	O
accuracy	B-Metric
,	O
at	O
test	O
time	O
VOS	B-Method
methods	I-Method
often	O
feature	O
computationally	O
intensive	O
techniques	O
such	O
as	O
fine	B-Method
-	I-Method
tuning	I-Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
,	O
data	B-Method
augmentation	I-Method
[	O
reference	O
][	O
reference	O
]	O
and	O
optical	B-Method
flow	I-Method
	
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
	
Therefore	O
,	O
these	O
approaches	O
are	O
generally	O
characterised	O
by	O
low	O
framerates	O
and	O
the	O
inability	O
to	O
operate	O
online	O
.	O
	
For	O
example	O
,	O
it	O
is	O
not	O
uncommon	O
for	O
methods	O
to	O
require	O
minutes	O
[	O
reference	O
][	O
reference	O
]	O
or	O
even	O
hours	O
[	O
reference	O
][	O
reference	O
]	O
for	O
videos	O
that	O
are	O
just	O
a	O
few	O
seconds	O
long	O
.	O
	
Recently	O
,	O
there	O
has	O
been	O
an	O
increasing	O
interest	O
in	O
the	O
VOS	O
community	O
towards	O
faster	O
methods	O
	
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
To	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
the	O
fastest	O
approaches	O
with	O
a	O
performance	O
competitive	O
with	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
are	O
the	O
ones	O
of	O
Yang	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
and	O
Wug	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
.	O
	
The	O
former	O
uses	O
a	O
meta	B-Method
-	I-Method
network	I-Method
"	I-Method
modulator	I-Method
"	I-Method
to	O
quickly	O
adapt	O
the	O
parameters	O
of	O
a	O
segmentation	B-Method
network	I-Method
during	O
test	O
time	O
,	O
while	O
the	O
latter	O
does	O
not	O
use	O
any	O
fine	B-Method
-	I-Method
tuning	I-Method
and	O
adopts	O
an	O
encoder	B-Method
-	I-Method
decoder	I-Method
Siamese	I-Method
architecture	I-Method
trained	O
in	O
multiple	O
stages	O
.	O
	
Both	O
these	O
methods	O
run	O
below	O
10	O
frames	O
per	O
sec	O
-	O
	
section	O
:	O
Methodology	O
	
To	O
allow	O
online	O
operability	O
and	O
fast	O
speed	O
,	O
we	O
adopt	O
the	O
fully	B-Method
-	I-Method
convolutional	I-Method
Siamese	I-Method
framework	I-Method
[	O
reference	O
]	O
.	O
Moreover	O
,	O
to	O
illustratate	O
that	O
our	O
approach	O
is	O
agnostic	O
to	O
the	O
specific	O
fully	B-Method
-	I-Method
convolutional	I-Method
method	I-Method
used	O
as	O
a	O
starting	O
point	O
(	O
e.g.	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
)	O
,	O
we	O
consider	O
the	O
popular	O
SiamFC	B-Method
[	O
reference	O
]	O
and	O
SiamRPN	B-Method
[	O
reference	O
]	O
as	O
two	O
representative	O
examples	O
.	O
	
We	O
first	O
introduce	O
them	O
in	O
Section	O
3.1	O
and	O
then	O
describe	O
our	O
approach	O
in	O
Section	O
3.2	O
.	O
	
section	O
:	O
Fully	B-Method
-	I-Method
convolutional	I-Method
Siamese	I-Method
networks	I-Method
	
SiamFC	O
.	O
	
Bertinetto	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
propose	O
to	O
use	O
,	O
as	O
a	O
fundamental	O
building	O
block	O
of	O
a	O
tracking	B-Method
system	I-Method
,	O
an	O
offlinetrained	B-Method
fully	I-Method
-	I-Method
convolutional	I-Method
Siamese	I-Method
network	I-Method
that	O
compares	O
an	O
exemplar	O
image	O
z	O
against	O
a	O
(	O
larger	O
)	O
search	O
image	O
x	O
to	O
obtain	O
a	O
dense	O
response	O
map	O
.	O
	
z	O
and	O
x	O
are	O
,	O
respectively	O
,	O
a	O
w×h	O
crop	O
centered	O
on	O
the	O
target	O
object	O
and	O
a	O
larger	O
crop	O
centered	O
on	O
the	O
last	O
estimated	O
position	O
of	O
the	O
target	O
.	O
	
The	O
two	O
inputs	O
are	O
processed	O
by	O
the	O
same	O
CNN	B-Method
f	I-Method
θ	I-Method
,	O
yielding	O
two	O
feature	O
maps	O
that	O
are	O
cross	O
-	O
correlated	O
:	O
	
In	O
this	O
paper	O
,	O
we	O
refer	O
to	O
each	O
spatial	O
element	O
of	O
the	O
response	O
map	O
(	O
left	O
-	O
hand	O
side	O
of	O
Eq	O
.	O
1	O
)	O
as	O
response	O
of	O
a	O
candidate	O
window	O
(	O
RoW	O
)	O
.	O
	
For	O
example	O
,	O
g	O
n	O
θ	O
(	O
z	O
,	O
x	O
)	O
,	O
encodes	O
a	O
similarity	O
between	O
the	O
examplar	O
z	O
and	O
n	O
-	O
th	O
candidate	O
window	O
in	O
x.	O
	
For	O
SiamFC	B-Method
,	O
the	O
goal	O
is	O
for	O
the	O
maximum	O
value	O
of	O
the	O
response	O
map	O
to	O
correspond	O
to	O
the	O
target	O
location	O
in	O
the	O
search	O
area	O
	
x.	O
	
Instead	O
,	O
in	O
order	O
to	O
allow	O
each	O
RoW	O
to	O
encode	O
richer	O
information	O
about	O
the	O
target	O
object	O
,	O
we	O
replace	O
the	O
simple	O
cross	B-Method
-	I-Method
correlation	I-Method
of	O
Eq	O
.	O
1	O
with	O
depth	O
-	O
wise	O
crosscorrelation	O
[	O
reference	O
]	O
and	O
produce	O
a	O
multi	B-Method
-	I-Method
channel	I-Method
response	I-Method
map	I-Method
.	O
	
SiamFC	B-Method
is	O
trained	O
offline	O
on	O
millions	O
of	O
video	O
frames	O
with	O
the	O
logistic	O
loss	O
[	O
4	O
,	O
Section	O
2.2	O
]	O
,	O
which	O
we	O
refer	O
to	O
as	O
L	O
sim	O
.	O
	
SiamRPN	B-Method
.	O
	
Li	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
considerably	O
improve	O
the	O
performance	O
of	O
SiamFC	B-Method
by	O
relying	O
on	O
a	O
region	B-Method
proposal	I-Method
network	I-Method
(	O
RPN	B-Method
)	O
[	O
reference	O
]	O
,	O
which	O
allows	O
to	O
estimate	O
the	O
target	O
location	O
with	O
a	O
bounding	O
box	O
of	O
variable	O
aspect	O
ratio	O
.	O
	
In	O
particular	O
,	O
in	O
SiamRPN	B-Method
each	O
RoW	O
encodes	O
a	O
set	O
of	O
k	O
anchor	O
box	O
proposals	O
and	O
corresponding	O
object	O
/	O
background	O
scores	O
.	O
	
Therefore	O
,	O
SiamRPN	B-Method
outputs	O
box	B-Method
predictions	I-Method
in	O
parallel	O
with	O
classification	O
scores	O
.	O
	
The	O
two	O
output	O
branches	O
are	O
trained	O
using	O
the	O
smooth	O
L	O
1	O
and	O
the	O
cross	O
-	O
entropy	O
losses	O
[	O
31	O
,	O
Section	O
3.2	O
]	O
.	O
	
In	O
the	O
following	O
,	O
we	O
refer	O
to	O
them	O
as	O
L	O
box	O
and	O
L	B-Metric
score	I-Metric
respectively	O
.	O
	
section	O
:	O
SiamMask	B-Method
	
Unlike	O
existing	O
tracking	B-Method
methods	I-Method
that	O
rely	O
on	O
lowfidelity	B-Method
object	I-Method
representations	I-Method
,	O
we	O
argue	O
the	O
importance	O
of	O
producing	O
per	O
-	O
frame	O
binary	O
segmentation	O
masks	O
.	O
	
To	O
this	O
aim	O
we	O
show	O
that	O
,	O
besides	O
similarity	O
scores	O
and	O
bounding	O
box	O
coordinates	O
,	O
it	O
is	O
possible	O
for	O
the	O
RoW	O
of	O
a	O
fullyconvolutional	B-Method
Siamese	I-Method
network	I-Method
to	O
also	O
encode	O
the	O
information	O
necessary	O
to	O
produce	O
a	O
pixel	O
-	O
wise	O
binary	O
mask	O
.	O
	
This	O
can	O
be	O
achieved	O
by	O
extending	O
existing	O
Siamese	B-Method
trackers	I-Method
with	O
an	O
extra	O
branch	O
and	O
loss	O
.	O
	
We	O
predict	O
w×h	O
binary	O
masks	O
(	O
one	O
for	O
each	O
RoW	O
)	O
using	O
a	O
simple	O
two	B-Method
-	I-Method
layers	I-Method
neural	I-Method
network	I-Method
h	I-Method
φ	I-Method
with	O
learnable	O
parameters	O
φ	O
.	O
	
Let	O
m	O
n	O
denote	O
the	O
predicted	O
mask	O
corresponding	O
to	O
the	O
n	O
-	O
th	O
RoW	O
,	O
	
From	O
Eq	O
.	O
2	O
we	O
can	O
see	O
that	O
the	O
mask	B-Task
prediction	I-Task
is	O
a	O
function	O
of	O
both	O
the	O
image	O
to	O
segment	O
x	O
and	O
the	O
target	O
object	O
in	O
z.	O
	
In	O
this	O
way	O
,	O
z	O
can	O
be	O
used	O
as	O
a	O
reference	O
to	O
guide	O
the	O
segmentation	B-Task
process	I-Task
,	O
such	O
that	O
objects	O
of	O
any	O
arbitrary	O
class	O
can	O
be	O
tracked	O
.	O
	
This	O
clearly	O
means	O
that	O
,	O
given	O
a	O
different	O
reference	O
image	O
z	O
,	O
the	O
network	O
will	O
produce	O
a	O
different	O
segmentation	O
mask	O
for	O
x.	O
Loss	O
function	O
.	O
	
During	O
training	O
,	O
each	O
RoW	O
is	O
labelled	O
with	O
a	O
ground	O
-	O
truth	O
binary	O
label	O
	
y	O
n	O
∈	O
{	O
±1	O
}	O
and	O
also	O
associated	O
with	O
a	O
pixel	O
-	O
wise	O
ground	O
-	O
truth	O
mask	O
c	O
n	O
of	O
size	O
w×h	O
.	O
	
Let	O
c	O
ij	O
n	O
∈	O
{	O
±1	O
}	O
denote	O
the	O
label	O
corresponding	O
to	O
pixel	O
(	O
i	O
,	O
j	O
)	O
of	O
the	O
object	O
mask	O
in	O
the	O
n	O
-	O
th	O
candidate	O
RoW.	O
	
The	O
loss	O
function	O
L	O
mask	O
(	O
Eq	O
.	O
3	O
)	O
for	O
the	O
mask	B-Task
prediction	I-Task
task	I-Task
	
is	O
a	O
binary	B-Method
logistic	I-Method
regression	I-Method
loss	I-Method
over	O
all	O
RoWs	O
:	O
	
Thus	O
,	O
the	O
classification	B-Method
layer	I-Method
of	O
h	B-Method
φ	I-Method
consists	O
of	O
w×h	B-Method
classifiers	I-Method
,	O
each	O
indicating	O
whether	O
a	O
given	O
pixel	O
belongs	O
to	O
the	O
object	O
in	O
the	O
candidate	O
window	O
or	O
not	O
.	O
	
Note	O
that	O
L	O
mask	O
is	O
considered	O
only	O
for	O
positive	O
RoWs	O
(	O
i.e.	O
with	O
y	O
n	O
=	O
1	O
)	O
.	O
	
Mask	B-Method
representation	I-Method
.	O
	
In	O
contrast	O
to	O
semantic	B-Method
segmentation	I-Method
methodsà	I-Method
-	I-Method
la	I-Method
FCN	I-Method
[	O
reference	O
]	O
and	O
Mask	B-Method
R	I-Method
-	I-Method
CNN	I-Method
[	O
reference	O
]	O
,	O
which	O
maintain	O
explicit	O
spatial	O
information	O
throughout	O
the	O
network	O
,	O
our	O
approach	O
follows	O
the	O
spirit	O
of	O
[	O
reference	O
][	O
reference	O
]	O
and	O
generates	O
masks	O
starting	O
from	O
a	O
flattened	B-Method
representation	I-Method
of	I-Method
the	I-Method
object	I-Method
.	O
	
In	O
particular	O
,	O
in	O
our	O
case	O
this	O
representation	O
corresponds	O
to	O
one	O
of	O
the	O
1×1×256	O
RoWs	O
produced	O
by	O
the	O
depth	O
-	O
wise	O
cross	O
-	O
correlation	O
between	O
f	O
θ	O
(	O
z	O
)	O
and	O
f	O
θ	O
(	O
x	O
)	O
.	O
	
Importantly	O
,	O
the	O
network	B-Method
h	I-Method
φ	I-Method
of	O
the	O
segmentation	B-Task
task	I-Task
is	O
composed	O
of	O
two	O
1×1	B-Method
convolutional	I-Method
layers	I-Method
,	O
one	O
with	O
256	O
and	O
the	O
other	O
with	O
63	O
2	O
channels	O
(	O
Figure	O
2	O
)	O
.	O
	
This	O
allows	O
every	O
pixel	B-Method
classifier	I-Method
to	O
utilise	O
information	O
contained	O
in	O
the	O
entire	O
RoW	O
and	O
thus	O
to	O
have	O
a	O
complete	O
view	O
of	O
its	O
corresponding	O
candidate	O
window	O
in	O
x	O
,	O
which	O
is	O
critical	O
to	O
disambiguate	O
between	O
instances	O
that	O
look	O
like	O
the	O
target	O
(	O
e.g.	O
last	O
row	O
of	O
Figure	O
5	O
)	O
,	O
also	O
known	O
as	O
distractors	O
[	O
reference	O
]	O
.	O
	
With	O
the	O
aim	O
of	O
producing	O
a	O
more	O
accurate	O
object	O
mask	O
,	O
we	O
follow	O
the	O
strategy	O
of	O
[	O
reference	O
]	O
,	O
which	O
merges	O
low	O
and	O
high	O
resolution	O
features	O
using	O
multiple	O
refinement	B-Method
modules	I-Method
made	O
of	O
upsampling	B-Method
layers	I-Method
and	O
skip	O
connections	O
.	O
	
Further	O
details	O
can	O
be	O
found	O
in	O
the	O
appendix	O
A.	O
Two	O
variants	O
.	O
	
For	O
our	O
experiments	O
,	O
we	O
augment	O
the	O
architectures	O
of	O
SiamFC	B-Method
[	O
reference	O
]	O
and	O
SiamRPN	B-Method
[	O
reference	O
]	O
with	O
our	O
segmentation	O
branch	O
and	O
the	O
loss	O
L	O
mask	O
,	O
obtaining	O
what	O
we	O
call	O
the	O
two	O
-	O
branch	B-Method
and	I-Method
three	I-Method
-	I-Method
branch	I-Method
variants	I-Method
of	O
SiamMask	B-Method
.	O
	
These	O
respectively	O
optimise	O
the	O
multi	O
-	O
task	O
losses	O
L	O
2B	O
and	O
L	O
3B	O
,	O
defined	O
as	O
:	O
	
We	O
refer	O
the	O
reader	O
to	O
[	O
4	O
,	O
Section	O
2.2	O
]	O
for	O
L	O
sim	O
and	O
to	O
[	O
reference	O
][	O
reference	O
]	O
for	O
L	O
box	O
and	O
L	B-Metric
score	I-Metric
.	O
	
For	O
L	O
3B	O
,	O
a	O
RoW	O
is	O
considered	O
positive	O
(	O
y	O
n	O
=	O
1	O
)	O
if	O
one	O
of	O
its	O
anchor	O
boxes	O
has	O
IOU	O
with	O
the	O
ground	O
-	O
truth	O
box	O
of	O
at	O
least	O
0.6	O
and	O
negative	O
(	O
y	O
n	O
=	O
−1	O
)	O
otherwise	O
.	O
	
For	O
L	O
2B	O
,	O
we	O
adopt	O
the	O
same	O
strategy	O
of	O
[	O
reference	O
]	O
to	O
define	O
positive	O
and	O
negative	O
samples	O
.	O
	
We	O
did	O
not	O
search	O
over	O
the	O
hyperparameters	O
of	O
Eq	O
.	O
4	O
and	O
Eq	O
.	O
5	O
and	O
simply	O
set	O
λ	O
	
1	O
=	O
32	O
	
like	O
in	O
[	O
reference	O
]	O
and	O
λ	O
2	O
=	O
λ	O
	
3	O
=	O
1	O
.	O
	
The	O
taskspecific	O
branches	O
for	O
the	O
box	O
and	O
score	O
outputs	O
are	O
consti	O
-	O
tuted	O
by	O
two	O
1×1	O
convolutional	B-Method
layers	I-Method
.	O
	
Figure	O
2	O
illustrates	O
the	O
two	O
variants	O
of	O
SiamMask	B-Method
.	O
	
Box	B-Task
generation	I-Task
.	O
	
Note	O
that	O
,	O
while	O
VOS	B-Metric
benchmarks	I-Metric
require	O
binary	O
masks	O
,	O
typical	O
tracking	B-Method
benchmarks	I-Method
such	O
as	O
VOT	B-Task
[	O
reference	O
]	O
require	O
a	O
bounding	O
box	O
as	O
final	O
representation	O
of	O
the	O
target	O
object	O
.	O
	
We	O
consider	O
three	O
different	O
strategies	O
to	O
generate	O
a	O
bounding	O
box	O
from	O
a	O
binary	O
mask	O
(	O
Figure	O
3	O
)	O
:	O
	
(	O
1	O
)	O
axis	O
-	O
aligned	O
bounding	O
rectangle	O
(	O
Min	B-Method
-	I-Method
max	I-Method
)	O
,	O
(	O
2	O
)	O
rotated	B-Method
minimum	I-Method
bounding	I-Method
rectangle	I-Method
(	O
MBR	B-Method
)	O
and	O
(	O
3	O
)	O
the	O
optimisation	B-Method
strategy	I-Method
used	O
for	O
the	O
automatic	B-Task
bounding	I-Task
box	I-Task
generation	I-Task
proposed	O
in	O
VOT	B-Task
-	O
2016	O
[	O
reference	O
]	O
(	O
Opt	O
)	O
.	O
	
We	O
empirically	O
evaluate	O
these	O
alternatives	O
in	O
Section	O
4	O
(	O
Table	O
1	O
)	O
.	O
	
section	O
:	O
Implementation	O
details	O
	
Network	B-Method
architecture	I-Method
.	O
	
For	O
both	O
our	O
variants	O
,	O
we	O
use	O
a	O
ResNet	B-Method
-	I-Method
50	I-Method
[	O
reference	O
]	O
until	O
the	O
final	O
convolutional	O
layer	O
of	O
the	O
4	O
-	O
th	O
stage	O
as	O
our	O
backbone	O
f	O
θ	O
.	O
	
In	O
order	O
to	O
obtain	O
a	O
high	O
spatial	O
resolution	O
in	O
deeper	O
layers	O
,	O
we	O
reduce	O
the	O
output	O
stride	O
to	O
8	O
by	O
using	O
convolutions	B-Method
with	O
stride	O
1	O
.	O
	
Moreover	O
,	O
we	O
increase	O
the	O
receptive	O
field	O
by	O
using	O
dilated	B-Method
convolutions	I-Method
[	O
reference	O
]	O
.	O
	
In	O
our	O
model	O
,	O
we	O
add	O
to	O
the	O
shared	O
backbone	O
	
f	O
θ	O
an	O
unshared	B-Method
adjust	I-Method
layer	I-Method
(	O
1×1	O
conv	O
with	O
256	O
outputs	O
)	O
.	O
	
For	O
simplicity	O
,	O
we	O
omit	O
it	O
in	O
Eq	O
.	O
1	O
.	O
	
We	O
describe	O
the	O
network	B-Method
architectures	I-Method
in	O
more	O
detail	O
in	O
Appendix	O
A.	O
Training	O
.	O
	
Like	O
SiamFC	B-Method
[	O
reference	O
]	O
,	O
we	O
use	O
examplar	O
and	O
search	O
image	O
patches	O
of	O
127×127	O
and	O
255×255	O
pixels	O
respectively	O
.	O
	
During	O
training	O
,	O
we	O
randomly	O
jitter	O
examplar	O
and	O
search	O
patches	O
.	O
	
Specifically	O
,	O
we	O
consider	O
random	O
translations	O
(	O
up	O
to	O
±8	O
pixels	O
)	O
and	O
rescaling	O
(	O
of	O
2	O
±1	O
/	O
8	O
and	O
2	O
	
section	O
:	O
±1	O
/	O
4	O
	
for	O
examplar	O
and	O
search	B-Task
respectively	O
)	O
.	O
	
The	O
network	B-Method
backbone	I-Method
is	O
pre	O
-	O
trained	O
on	O
the	O
ImageNet	B-Task
-	I-Task
1k	I-Task
classification	I-Task
task	I-Task
.	O
	
We	O
use	O
SGD	B-Method
with	O
a	O
first	O
warmup	O
phase	O
in	O
which	O
the	O
learning	B-Metric
rate	I-Metric
increases	O
linearly	O
from	O
10	O
−3	O
to	O
5×10	O
−3	O
for	O
the	O
first	O
5	O
epochs	O
and	O
then	O
descreases	O
logarithmically	O
until	O
5×10	O
	
−4	O
for	O
15	O
more	O
epochs	O
.	O
	
We	O
train	O
all	O
our	O
models	O
using	O
COCO	B-Method
[	O
reference	O
]	O
,	O
ImageNet	O
-	O
VID	O
[	O
reference	O
]	O
and	O
YouTube	O
-	O
VOS	O
[	O
reference	O
]	O
.	O
Inference	O
.	O
	
During	O
tracking	B-Task
,	O
SiamMask	B-Method
is	O
simply	O
evaluated	O
once	O
per	O
frame	O
,	O
without	O
any	O
adaptation	O
.	O
	
In	O
both	O
our	O
variants	O
,	O
we	O
select	O
the	O
output	O
mask	O
using	O
the	O
location	O
attaining	O
the	O
maximum	O
score	O
in	O
the	O
classification	O
branch	O
.	O
	
Then	O
,	O
after	O
having	O
applied	O
a	O
per	B-Method
-	I-Method
pixel	I-Method
sigmoid	I-Method
,	O
we	O
binarise	O
the	O
output	O
of	O
the	O
mask	O
branch	O
with	O
a	O
threshold	O
0.5	O
.	O
	
In	O
the	O
twobranch	O
variant	O
,	O
for	O
each	O
video	O
frame	O
after	O
the	O
first	O
one	O
,	O
we	O
fit	O
the	O
output	O
mask	O
with	O
the	O
Min	O
-	O
max	O
box	O
and	O
use	O
it	O
as	O
reference	O
to	O
crop	O
the	O
next	O
frame	O
search	O
region	O
.	O
	
Instead	O
,	O
in	O
the	O
three	O
-	O
branch	O
variant	O
,	O
we	O
find	O
more	O
effecitve	O
to	O
exploit	O
the	O
highest	O
-	O
scoring	O
output	O
of	O
the	O
box	O
branch	O
as	O
reference	O
.	O
	
For	O
the	O
implementation	O
of	O
SiamMask	B-Method
,	O
we	O
used	O
PyTorch	B-Method
.	O
	
Code	O
,	O
pre	O
-	O
computed	O
results	O
and	O
pre	O
-	O
trained	O
models	O
will	O
be	O
made	O
available	O
.	O
	
section	O
:	O
Experiments	O
	
In	O
this	O
section	O
,	O
we	O
evaluate	O
our	O
approach	O
on	O
two	O
related	O
tasks	O
:	O
visual	B-Task
object	I-Task
tracking	I-Task
(	O
on	O
VOT	B-Task
-	O
2016	O
and	O
VOT	B-Material
-	I-Material
2018	I-Material
)	O
and	O
semi	B-Task
-	I-Task
supervised	I-Task
video	I-Task
object	I-Task
segmentation	I-Task
(	O
on	O
DAVIS	O
-	O
2016	O
and	O
DAVIS	O
-	O
2017	O
)	O
.	O
	
We	O
refer	O
to	O
our	O
two	O
-	O
branch	B-Method
and	I-Method
three	I-Method
-	I-Method
branch	I-Method
variants	I-Method
with	O
SiamMask	B-Method
-	O
2B	O
and	O
SiamMask	B-Method
respectively	O
.	O
	
section	O
:	O
Evaluation	O
for	O
visual	B-Task
object	I-Task
tracking	I-Task
	
Datasets	O
and	O
settings	O
.	O
	
We	O
adopt	O
two	O
widely	O
used	O
benchmarks	O
for	O
the	O
evaluation	O
of	O
the	O
object	B-Task
tracking	I-Task
task	I-Task
:	O
VOT	B-Task
-	O
2016	O
[	O
reference	O
]	O
and	O
VOT	B-Material
-	I-Material
2018	I-Material
[	O
reference	O
]	O
,	O
both	O
annotated	O
with	O
rotated	O
bounding	O
boxes	O
.	O
	
We	O
use	O
VOT	B-Task
-	O
2016	O
to	O
conduct	O
an	O
experiment	O
to	O
understand	O
how	O
different	O
types	O
of	O
representation	O
affect	O
the	O
performance	O
.	O
	
For	O
this	O
first	O
experiment	O
,	O
we	O
use	O
mean	B-Metric
intersection	I-Metric
over	I-Metric
union	I-Metric
(	I-Metric
IOU	I-Metric
)	O
and	O
Average	B-Metric
Precision	I-Metric
(	O
AP	B-Metric
)	I-Metric
@{0.5	I-Metric
,	O
0.7	O
}	O
IOU	B-Metric
.	O
	
We	O
then	O
compare	O
against	O
the	O
stateof	O
-	O
the	O
-	O
art	O
on	O
VOT	B-Material
-	I-Material
2018	I-Material
,	O
using	O
the	O
official	O
VOT	B-Task
toolkit	O
and	O
the	O
Expected	B-Metric
Average	I-Metric
Overlap	I-Metric
(	O
EAO	B-Metric
)	O
,	O
a	O
measure	O
that	O
considers	O
both	O
accuracy	B-Metric
and	O
robustness	B-Metric
of	O
a	O
tracker	O
	
[	O
reference	O
]	O
.	O
	
How	O
much	O
does	O
the	O
object	B-Method
representation	I-Method
matter	O
?	O
	
Existing	O
tracking	B-Method
methods	I-Method
typically	O
predict	O
axis	O
-	O
aligned	O
bounding	O
boxes	O
with	O
a	O
fixed	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
or	O
variable	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
aspect	O
ratio	O
.	O
	
We	O
are	O
interested	O
in	O
understanding	O
to	O
which	O
extent	O
producing	O
a	O
per	O
-	O
frame	O
binary	O
mask	O
can	O
improve	O
tracking	B-Task
.	O
	
In	O
order	O
to	O
focus	O
on	O
representation	B-Task
accuracy	I-Task
,	O
for	O
this	O
experiment	O
only	O
we	O
ignore	O
the	O
temporal	O
aspect	O
and	O
sample	O
video	O
frames	O
at	O
random	O
.	O
	
The	O
approaches	O
described	O
in	O
the	O
following	O
paragraph	O
are	O
tested	O
on	O
randomly	O
cropped	O
search	O
patches	O
(	O
with	O
random	O
shifts	O
within	O
±16	O
pixels	O
and	O
scale	O
deformations	O
up	O
to	O
2	O
1±0.25	O
)	O
from	O
the	O
sequences	O
of	O
VOT	B-Task
-	O
2016	O
.	O
	
In	O
Table	O
1	O
,	O
we	O
compare	O
our	O
three	O
-	O
branch	B-Method
variant	I-Method
using	O
the	O
Min	B-Method
-	I-Method
max	I-Method
,	I-Method
MBR	I-Method
and	I-Method
Opt	I-Method
approaches	I-Method
(	O
described	O
at	O
the	O
end	O
of	O
Section	O
3.2	O
and	O
in	O
Figure	O
3	O
)	O
.	O
	
For	O
perspective	O
,	O
we	O
also	O
report	O
results	O
for	O
SiamFC	B-Method
and	I-Method
SiamRPN	I-Method
as	O
representative	O
of	O
the	O
fixed	B-Method
and	I-Method
variable	I-Method
aspect	I-Method
-	I-Method
ratio	I-Method
approaches	I-Method
,	O
together	O
with	O
three	O
oracles	O
that	O
have	O
access	O
to	O
per	O
-	O
frame	O
groundtruth	O
information	O
and	O
serve	O
as	O
upper	O
bound	O
for	O
the	O
different	O
representation	B-Method
strategies	I-Method
.	O
	
(	O
1	O
)	O
The	O
fixed	O
aspect	O
-	O
ratio	O
oracle	O
uses	O
the	O
per	O
-	O
frame	O
ground	O
-	O
truth	O
area	O
and	O
center	O
location	O
,	O
but	O
fixes	O
the	O
aspect	O
reatio	O
to	O
the	O
one	O
of	O
the	O
first	O
frame	O
mIOU	B-Metric
(	O
%	O
)	O
mAP@0	O
.	O
	
[	O
reference	O
]	O
and	O
produces	O
an	O
axis	O
-	O
aligned	O
bounding	O
box	O
.	O
	
(	O
2	O
)	O
	
The	O
Minmax	B-Method
oracle	I-Method
uses	O
the	O
minimal	O
enclosing	O
rectangle	O
of	O
the	O
rotated	O
ground	O
-	O
truth	O
bounding	O
box	O
to	O
produce	O
an	O
axis	O
-	O
aligned	O
bounding	O
box	O
.	O
	
(	O
3	O
)	O
	
Finally	O
,	O
the	O
MBR	B-Method
oracle	I-Method
uses	O
the	O
rotated	O
minimum	O
bounding	O
rectangle	O
of	O
the	O
ground	O
-	O
truth	O
.	O
	
Note	O
that	O
(	O
1	O
)	O
,	O
(	O
2	O
)	O
and	O
(	O
3	O
)	O
can	O
be	O
considered	O
,	O
respectively	O
,	O
the	O
performance	B-Metric
upper	I-Metric
bounds	I-Metric
for	O
the	O
representation	B-Method
strategies	I-Method
of	O
SiamFC	B-Method
,	O
SiamRPN	B-Method
and	O
SiamMask	B-Method
.	O
	
Table	O
1	O
shows	O
that	O
our	O
method	O
achieves	O
the	O
best	O
mIOU	B-Metric
,	O
no	O
matter	O
the	O
box	B-Method
generation	I-Method
strategy	I-Method
used	O
(	O
Figure	O
3	O
)	O
.	O
	
Albeit	O
SiamMask	B-Method
-	O
Opt	O
offers	O
the	O
highest	O
IOU	B-Metric
and	I-Metric
mAP	I-Metric
,	O
it	O
requires	O
significant	O
computational	O
resources	O
due	O
to	O
its	O
slow	O
optimisation	B-Method
procedure	I-Method
	
[	O
reference	O
]	O
.	O
Instead	O
,	O
we	O
adopt	O
the	O
MBR	B-Method
strategy	I-Method
(	O
whose	O
computational	B-Metric
overhead	I-Metric
is	O
negligible	O
)	O
for	O
our	O
final	O
object	B-Task
tracking	I-Task
evaluation	I-Task
.	O
	
SiamMask	B-Method
-	O
MBR	O
achieves	O
a	O
mAP@0.5	B-Metric
	
IOU	B-Metric
of	O
85.4	O
,	O
with	O
a	O
respective	O
improvement	O
of	O
+	O
29	O
and	O
+	O
9.2	O
points	O
	
w.r.t	O
.	O
	
the	O
two	O
fully	B-Method
-	I-Method
convolutional	I-Method
baselines	I-Method
.	O
	
Interestingly	O
,	O
the	O
gap	O
significantly	O
widens	O
when	O
considering	O
mAP	B-Metric
at	O
the	O
higher	O
accuracy	O
regime	O
of	O
0.7	O
IOU	B-Metric
:	O
+	O
41.6	O
and	O
+	O
18.4	O
respectively	O
.	O
	
Notably	O
,	O
our	O
accuracy	B-Metric
results	O
are	O
not	O
far	O
from	O
the	O
fixed	O
aspectratio	O
oracle	O
.	O
	
Moreover	O
,	O
comparing	O
the	O
upper	B-Metric
bound	I-Metric
performance	I-Metric
represented	O
by	O
the	O
oracles	O
,	O
it	O
is	O
possible	O
to	O
notice	O
how	O
,	O
by	O
simply	O
changing	O
the	O
bounding	B-Method
box	I-Method
representation	I-Method
,	O
there	O
is	O
a	O
great	O
room	O
of	O
improvement	O
(	O
e.g.	O
+	O
10.6	O
%	O
mIOU	B-Metric
improvement	O
between	O
the	O
fixed	B-Metric
aspect	I-Metric
-	I-Metric
ratio	I-Metric
and	O
the	O
MBR	B-Method
oracles	I-Method
)	O
.	O
	
Overall	O
,	O
this	O
study	O
shows	O
how	O
the	O
MBR	B-Method
strategy	I-Method
to	O
obtain	O
a	O
rotated	O
bounding	O
box	O
from	O
a	O
binary	O
mask	O
of	O
the	O
object	O
offers	O
a	O
significant	O
advantage	O
over	O
popular	O
strategies	O
that	O
simply	O
report	O
axis	O
-	O
aligned	O
bounding	O
boxes	O
.	O
	
Results	O
on	O
VOT	B-Material
-	I-Material
2018	I-Material
.	O
	
In	O
Table	O
2	O
we	O
compare	O
the	O
two	O
variants	O
of	O
SiamMask	B-Method
against	O
seven	O
recently	O
published	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
trackers	O
on	O
the	O
VOT	B-Material
-	I-Material
2018	I-Material
benchmark	I-Material
.	O
	
Both	O
achieve	O
outstanding	O
performance	O
and	O
run	O
in	O
real	O
-	O
time	O
.	O
	
In	O
particular	O
,	O
our	O
three	O
-	O
branch	B-Method
variant	I-Method
(	O
SiamMask	B-Method
)	O
significantly	O
outperforms	O
the	O
very	O
recent	O
and	O
top	O
performing	O
DaSiamRPN	B-Method
	
[	O
reference	O
]	O
.	O
Even	O
without	O
box	B-Method
regression	I-Method
branch	I-Method
,	O
our	O
simpler	O
two	O
-	O
branch	B-Method
variant	I-Method
(	O
SiamMask	B-Method
-	O
2B	O
)	O
achieves	O
a	O
high	O
EAO	B-Metric
of	O
0.334	O
,	O
which	O
is	O
in	O
par	O
with	O
SA	B-Method
Siam	I-Method
R	I-Method
[	O
reference	O
]	O
and	O
superior	O
to	O
any	O
other	O
real	B-Method
-	I-Method
time	I-Method
method	I-Method
in	O
the	O
published	O
lit	O
-	O
erature	O
.	O
	
SiamMask	B-Method
provides	O
a	O
further	O
relative	O
gain	O
of	O
3.9	O
%	O
,	O
achieving	O
a	O
EAO	B-Metric
of	O
0.347	O
,	O
which	O
establishes	O
a	O
new	O
stateof	O
-	O
the	O
-	O
art	O
for	O
real	B-Task
-	I-Task
time	I-Task
tracking	I-Task
.	O
	
Our	O
model	O
is	O
particularly	O
strong	O
under	O
the	O
accuracy	B-Metric
metric	I-Metric
,	O
showing	O
a	O
significant	O
advantage	O
with	O
respect	O
to	O
the	O
Correlation	B-Method
Filter	I-Method
-	I-Method
based	I-Method
trackers	I-Method
CSRDCF	I-Method
[	O
reference	O
]	O
,	O
STRCF	B-Method
[	O
reference	O
]	O
and	O
ECO	O
	
[	O
reference	O
]	O
.	O
	
This	O
is	O
not	O
surprising	O
,	O
as	O
SiamMask	B-Method
relies	O
on	O
a	O
richer	O
object	B-Method
representation	I-Method
,	O
as	O
outlined	O
in	O
Table	O
1	O
.	O
	
Interestingly	O
,	O
similarly	O
to	O
us	O
He	O
et	O
al	O
.	O
	
(	O
SA	O
Siam	O
R	O
)	O
	
[	O
reference	O
]	O
are	O
motivated	O
to	O
achieve	O
a	O
more	O
accurate	O
target	B-Method
representation	I-Method
.	O
	
To	O
this	O
aim	O
,	O
they	O
consider	O
multiple	O
rotated	O
and	O
rescaled	O
bounding	O
boxes	O
as	O
candidates	O
.	O
	
However	O
,	O
like	O
SiamFC	B-Method
[	O
reference	O
]	O
,	O
SA	B-Method
Siam	I-Method
R	I-Method
is	O
still	O
constrained	O
to	O
a	O
fixed	O
aspect	O
-	O
ratio	O
bounding	O
box	O
.	O
	
section	O
:	O
Evaluation	O
for	O
semi	B-Task
-	I-Task
supervised	I-Task
VOS	I-Task
	
In	O
the	O
following	O
we	O
show	O
how	O
,	O
once	O
trained	O
,	O
the	O
same	O
method	O
can	O
also	O
be	O
used	O
for	O
the	O
task	O
of	O
video	B-Task
object	I-Task
segmentation	I-Task
,	O
achieving	O
competitive	O
performance	O
without	O
requiring	O
any	O
adaptation	O
at	O
test	O
time	O
.	O
	
Importantly	O
,	O
differently	O
to	O
typical	O
VOS	B-Method
approaches	I-Method
,	O
ours	O
can	O
operate	O
online	O
,	O
runs	O
in	O
real	O
-	O
time	O
and	O
only	O
requires	O
a	O
simple	O
bounding	B-Method
box	I-Method
initialisation	I-Method
.	O
	
Datasets	O
and	O
settings	O
.	O
	
We	O
report	O
the	O
performance	O
of	O
SiamMask	B-Method
on	O
the	O
popular	O
DAVIS	O
-	O
2016	O
[	O
reference	O
]	O
and	O
DAVIS	O
-	O
2017	O
[	O
reference	O
]	O
benchmarks	O
.	O
	
For	O
both	O
datasets	O
,	O
we	O
use	O
the	O
official	B-Metric
performance	I-Metric
measures	I-Metric
:	O
the	O
Jaccard	B-Metric
index	I-Metric
(	O
J	B-Metric
)	O
to	O
express	O
region	B-Metric
similarity	I-Metric
and	O
the	O
F	B-Metric
-	I-Metric
measure	I-Metric
(	O
F	B-Metric
)	O
to	O
express	O
contour	B-Metric
accuracy	I-Metric
.	O
	
For	O
each	O
measure	O
C	O
∈	O
{	O
J	O
,	O
F	O
}	O
,	O
three	O
statistics	O
are	O
considered	O
:	O
mean	B-Metric
C	I-Metric
M	I-Metric
,	O
recall	B-Metric
C	I-Metric
O	I-Metric
,	O
and	O
decay	B-Metric
C	I-Metric
D	I-Metric
,	O
which	O
informs	O
us	O
about	O
the	O
gain	O
/	O
loss	O
of	O
performance	O
over	O
time	O
[	O
reference	O
]	O
.	O
	
To	O
initialise	O
SiamMask	B-Method
,	O
we	O
extract	O
the	O
axis	O
-	O
aligned	O
bounding	O
box	O
(	O
Min	B-Method
-	I-Method
max	I-Method
strategy	I-Method
,	O
Figure	O
3	O
)	O
from	O
the	O
mask	O
provided	O
in	O
the	O
first	O
frame	O
.	O
	
Similarly	O
to	O
most	O
VOS	B-Method
methods	I-Method
,	O
in	O
case	O
of	O
multiple	O
objects	O
in	O
the	O
same	O
video	O
(	O
DAVIS	O
-	O
2017	O
)	O
we	O
simply	O
perform	O
multiple	O
inferences	O
.	O
	
Results	O
on	O
DAVIS	O
-	O
2016	O
and	O
2017	O
.	O
	
In	O
the	O
semisupervised	B-Task
setting	I-Task
,	O
VOS	B-Method
methods	I-Method
are	O
initialised	O
with	O
a	O
binary	O
mask	O
[	O
reference	O
]	O
Table	O
3	O
.	O
	
Results	O
on	O
DAVIS	O
2016	O
(	O
validation	O
set	O
)	O
.	O
	
FT	O
and	O
M	O
respectively	O
denote	O
if	O
the	O
method	O
requires	O
fine	B-Task
-	I-Task
tuning	I-Task
and	O
whether	O
it	O
is	O
initialised	O
with	O
a	O
mask	O
(	O
)	O
or	O
a	O
bounding	O
box	O
(	O
)	O
.	O
	
Speed	B-Metric
is	O
measured	O
in	O
frames	O
per	O
second	O
(	O
fps	O
)	O
.	O
	
tionally	O
intensive	O
techniques	O
at	O
test	O
time	O
such	O
as	O
finetuning	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
,	O
data	B-Method
augmentation	I-Method
[	O
reference	O
][	O
reference	O
]	O
,	O
inference	O
on	O
MRF	B-Method
/	I-Method
CRF	I-Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
and	O
optical	B-Method
flow	I-Method
	
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
	
As	O
a	O
consequence	O
,	O
it	O
is	O
not	O
uncommon	O
for	O
VOS	B-Method
techniques	I-Method
to	O
require	O
several	O
minutes	O
to	O
process	O
the	O
short	O
sequences	O
of	O
DAVIS	O
.	O
	
Clearly	O
,	O
these	O
strategies	O
make	O
the	O
online	B-Task
applicability	I-Task
(	O
which	O
is	O
our	O
focus	O
)	O
impossible	O
.	O
	
For	O
this	O
reason	O
,	O
in	O
our	O
comparison	O
(	O
Table	O
3	O
and	O
4	O
,	O
Figure	O
4	O
)	O
we	O
mainly	O
concentrate	O
on	O
fast	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
approaches	O
.	O
	
Table	O
3	O
shows	O
how	O
SiamMask	B-Method
can	O
be	O
considered	O
as	O
a	O
strong	O
baseline	O
for	O
online	B-Task
VOS	I-Task
.	O
	
First	O
,	O
it	O
is	O
almost	O
two	O
orders	O
of	O
magnitude	O
faster	O
than	O
accurate	O
approaches	O
such	O
as	O
OnAVOS	B-Method
[	O
reference	O
]	O
or	O
SFL	B-Method
[	O
reference	O
]	O
.	O
Second	O
,	O
it	O
is	O
competitive	O
with	O
recent	O
VOS	B-Method
methods	I-Method
that	O
do	O
not	O
employ	O
fine	B-Method
-	I-Method
tuning	I-Method
,	O
while	O
being	O
four	O
times	O
more	O
efficient	O
than	O
the	O
fastest	O
ones	O
(	O
i.e.	O
OSMN	B-Method
[	O
reference	O
]	O
and	O
RGMP	B-Method
[	O
reference	O
]	O
)	O
.	O
	
Interestingly	O
,	O
we	O
note	O
that	O
SiamMask	B-Method
achieves	O
the	O
best	O
decay	B-Metric
[	O
reference	O
]	O
for	O
region	B-Metric
similarity	I-Metric
(	O
J	B-Metric
D	I-Metric
,	O
)	O
and	O
contour	B-Metric
accuracy	I-Metric
(	O
F	B-Metric
D	I-Metric
)	O
on	O
both	O
DAVIS	O
-	O
2016	O
and	O
DAVIS	O
-	O
2017	O
.	O
	
This	O
suggests	O
that	O
our	O
method	O
is	O
robust	O
over	O
time	O
and	O
thus	O
it	O
is	O
indicated	O
for	O
particularly	O
long	O
sequences	O
.	O
	
Table	O
5	O
.	O
	
Ablation	O
studies	O
on	O
VOT	B-Material
-	I-Material
2018	I-Material
and	O
DAVIS	O
-	O
2016	O
.	O
	
Figure	O
4	O
offers	O
a	O
clearer	O
overview	O
of	O
the	O
tradeoff	O
between	O
segmentation	B-Metric
accuracy	I-Metric
(	O
as	O
mean	B-Metric
IOU	I-Metric
,	O
which	O
corresponds	O
to	O
J	O
M	O
)	O
and	O
speed	B-Metric
(	O
in	O
frames	O
per	O
second	O
)	O
.	O
	
Among	O
the	O
methods	O
of	O
Table	O
3	O
that	O
do	O
not	O
fine	O
tune	O
the	O
model	O
online	O
,	O
the	O
recently	O
proposed	O
FAVOS	B-Method
[	O
reference	O
]	O
obtains	O
the	O
best	O
results	O
.	O
	
However	O
,	O
it	O
combines	O
several	O
independent	O
modules	O
(	O
a	O
part	B-Method
-	I-Method
based	I-Method
tracker	I-Method
,	O
a	O
segmentation	B-Method
network	I-Method
and	O
a	O
similarity	B-Method
-	I-Method
based	I-Method
aggregation	I-Method
module	I-Method
)	O
,	O
while	O
SiamMask	B-Method
is	O
only	O
evaluated	O
with	O
a	O
single	O
model	O
and	O
it	O
is	O
almost	O
50	O
times	O
faster	O
.	O
	
Qualitative	O
results	O
of	O
SiamMask	B-Method
for	O
both	O
VOT	B-Task
and	O
DAVIS	O
sequences	O
are	O
shown	O
in	O
Figure	O
5	O
,	O
10	O
and	O
11	O
.	O
	
Despite	O
the	O
high	O
speed	O
,	O
SiamMask	B-Method
produces	O
accurate	O
segmentation	O
masks	O
even	O
in	O
presence	O
of	O
distractors	O
.	O
	
section	O
:	O
Further	O
analysis	O
	
In	O
this	O
section	O
,	O
we	O
illustrate	O
ablation	B-Task
studies	I-Task
,	O
failure	O
cases	O
and	O
timings	O
of	O
our	O
methods	O
.	O
	
Network	B-Method
architecture	I-Method
.	O
	
In	O
Table	O
5	O
,	O
AN	O
and	O
RN	O
denote	O
whether	O
we	O
use	O
AlexNet	O
or	O
ResNet	O
-	O
50	O
as	O
the	O
shared	O
backbone	O
f	O
θ	O
(	O
Figure	O
2	O
)	O
,	O
while	O
with	O
"	O
w	O
/	O
o	O
R	O
"	O
we	O
mean	O
that	O
the	O
method	O
does	O
not	O
use	O
the	O
refinement	B-Method
strategy	I-Method
of	O
Pinheiro	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
.	O
From	O
the	O
results	O
of	O
Table	O
5	O
,	O
it	O
is	O
possible	O
to	O
make	O
several	O
observations	O
.	O
	
(	O
1	O
)	O
	
The	O
first	O
set	O
of	O
rows	O
shows	O
that	O
,	O
by	O
simply	O
updating	O
the	O
architecture	B-Method
of	I-Method
f	I-Method
θ	I-Method
,	O
it	O
is	O
possible	O
to	O
achieve	O
an	O
important	O
performance	O
improvement	O
.	O
	
However	O
,	O
this	O
comes	O
at	O
the	O
cost	O
of	O
speed	B-Metric
,	O
especially	O
for	O
SiamRPN	B-Method
.	O
	
(	O
2	O
)	O
SiamMask	B-Method
-	O
2B	O
	
and	O
SiamMask	B-Method
considerably	O
improve	O
over	O
their	O
baselines	O
(	O
with	O
same	O
f	O
θ	O
)	O
SiamFC	B-Method
and	O
SiamRPN	B-Method
.	O
	
With	O
a	O
relative	O
+	O
33	O
%	O
in	O
EAO	B-Metric
,	O
the	O
gap	O
of	O
the	O
two	B-Method
-	I-Method
branch	I-Method
variant	I-Method
is	O
particularly	O
important	O
.	O
	
(	O
3	O
)	O
	
Interestingly	O
,	O
the	O
refinement	B-Method
approach	I-Method
of	O
Pinheiro	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
is	O
very	O
important	O
for	O
the	O
contour	B-Metric
accuracy	I-Metric
F	I-Metric
M	I-Metric
,	O
but	O
less	O
so	O
for	O
the	O
other	O
metrics	O
.	O
	
Multi	B-Task
-	I-Task
task	I-Task
learning	I-Task
.	O
	
We	O
conducted	O
two	O
further	O
experiments	O
to	O
disentangle	O
the	O
effect	O
of	O
multi	B-Task
-	I-Task
task	I-Task
learning	I-Task
[	O
reference	O
][	O
reference	O
]	O
to	O
the	O
one	O
of	O
using	O
the	O
MBR	O
box	O
(	O
from	O
a	O
binary	O
mask	O
)	O
as	O
representation	O
for	O
the	O
target	O
object	O
instead	O
of	O
a	O
traditional	O
axis	O
-	O
aligned	O
bounding	O
box	O
.	O
	
Results	O
are	O
reported	O
in	O
Table	O
5	O
.	O
	
To	O
achieve	O
this	O
,	O
we	O
modified	O
the	O
two	O
variants	O
of	O
SiamMask	B-Method
so	O
that	O
,	O
respectively	O
,	O
they	O
report	O
an	O
axis	O
-	O
aligned	O
bounding	O
box	O
from	O
the	O
score	O
branch	O
(	O
SiamMask	B-Method
-	I-Method
2B	I-Method
-	I-Method
box	I-Method
)	O
or	O
the	O
box	O
branch	O
(	O
SiamMask	B-Method
-	I-Method
box	I-Method
)	O
.	O
	
Therefore	O
,	O
despite	O
having	O
been	O
trained	O
,	O
the	O
mask	O
branch	O
is	O
not	O
used	O
during	O
inference	B-Task
.	O
	
We	O
can	O
observe	O
how	O
both	O
variants	O
obtain	O
an	O
improvement	O
with	O
respect	O
to	O
their	O
simpler	O
counterparts	O
:	O
from	O
0.251	O
to	O
0.265	O
EAO	B-Metric
for	O
the	O
two	O
-	O
branch	O
and	O
from	O
0.329	O
to	O
0.331	O
for	O
the	O
three	O
-	O
branch	O
.	O
	
However	O
,	O
for	O
both	O
variants	O
the	O
gap	O
between	O
SiamMask	B-Method
-	I-Method
box	I-Method
and	O
SiamMask	B-Method
is	O
higher	O
.	O
	
This	O
implies	O
that	O
,	O
despite	O
being	O
meaningful	O
,	O
the	O
improvement	O
brought	O
simply	O
by	O
training	O
multiple	O
related	O
tasks	O
together	O
is	O
less	O
relevant	O
than	O
the	O
type	O
of	O
target	O
object	B-Method
representation	I-Method
used	O
.	O
	
Timing	O
.	O
	
SiamMask	B-Method
operates	O
online	O
without	O
any	O
adaptation	O
to	O
the	O
test	O
sequence	O
.	O
	
On	O
a	O
single	O
NVIDIA	B-Method
Titan	I-Method
X	I-Method
GPU	I-Method
,	O
we	O
measured	O
an	O
average	B-Metric
speed	I-Metric
of	O
35	O
and	O
40	O
frames	O
per	O
second	O
,	O
respectively	O
for	O
the	O
two	O
-	O
branch	O
and	O
three	B-Method
-	I-Method
branch	I-Method
variants	I-Method
.	O
	
Note	O
that	O
the	O
highest	O
computational	B-Metric
burden	I-Metric
comes	O
from	O
the	O
feature	B-Method
extractor	I-Method
	
f	O
θ	O
.	O
	
For	O
this	O
reason	O
,	O
changing	O
architecture	O
is	O
a	O
convenient	O
way	O
to	O
obtain	O
different	O
speed	O
/	O
performance	O
trade	O
-	O
offs	O
.	O
	
Failure	O
cases	O
.	O
	
Finally	O
,	O
we	O
discuss	O
two	O
scenarios	O
in	O
which	O
SiamMask	B-Method
fails	O
:	O
motion	O
blur	O
and	O
"	O
non	O
-	O
object	O
"	O
pattern	O
(	O
Figure	O
6	O
)	O
.	O
	
Despite	O
being	O
different	O
in	O
nature	O
,	O
these	O
two	O
cases	O
arguably	O
arise	O
from	O
the	O
complete	O
lack	O
of	O
similar	O
training	O
samples	O
in	O
a	O
training	O
set	O
such	O
as	O
YouTube	O
-	O
VOS	O
[	O
reference	O
]	O
,	O
which	O
is	O
focused	O
on	O
objects	O
that	O
can	O
be	O
unambiguously	O
segmented	O
from	O
the	O
foreground	O
.	O
	
section	O
:	O
Conclusion	O
	
We	O
introduced	O
SiamMask	B-Method
,	O
a	O
simple	O
approach	O
that	O
enables	O
fully	B-Method
-	I-Method
convolutional	I-Method
Siamese	I-Method
trackers	I-Method
to	O
produce	O
classagnostic	O
binary	O
segmentation	O
masks	O
of	O
the	O
target	O
object	O
.	O
	
We	O
show	O
how	O
it	O
can	O
be	O
applied	O
with	O
success	O
to	O
both	O
tasks	O
of	O
visual	B-Task
object	I-Task
tracking	I-Task
and	O
semi	B-Task
-	I-Task
supervised	I-Task
video	I-Task
object	I-Task
segmentation	I-Task
,	O
showing	O
better	O
accuracy	B-Metric
than	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
trackers	O
and	O
,	O
at	O
the	O
same	O
time	O
,	O
the	O
fastest	O
speed	O
among	O
VOS	B-Method
methods	I-Method
.	O
	
The	O
two	O
variants	O
of	O
SiamMask	B-Method
we	O
proposed	O
are	O
initialised	O
with	O
a	O
simple	O
bounding	B-Method
box	I-Method
,	O
operate	O
online	O
,	O
run	O
in	O
real	O
-	O
time	O
and	O
do	O
not	O
require	O
any	O
adaptation	O
to	O
the	O
test	O
sequence	O
.	O
	
We	O
hope	O
that	O
our	O
work	O
will	O
inspire	O
further	O
studies	O
that	O
consider	O
the	O
two	O
problems	O
of	O
visual	B-Task
object	I-Task
tracking	I-Task
and	O
video	B-Task
object	I-Task
segmentation	I-Task
together	O
.	O
	
section	O
:	O
A.	O
Network	B-Method
architecture	I-Method
details	O
	
Network	O
backbone	O
.	O
	
Table	O
6	O
illustrates	O
the	O
details	O
of	O
our	O
backbone	B-Method
architecture	I-Method
(	O
f	O
θ	O
in	O
the	O
main	O
paper	O
)	O
.	O
	
For	O
both	O
variants	O
,	O
we	O
use	O
a	O
ResNet	B-Method
-	I-Method
50	I-Method
[	O
reference	O
]	O
until	O
the	O
final	O
convolutional	B-Method
layer	I-Method
of	O
the	O
4	O
-	O
th	O
stage	O
.	O
	
In	O
order	O
to	O
obtain	O
a	O
higher	O
spatial	O
resolution	O
in	O
deep	O
layers	O
,	O
we	O
reduce	O
the	O
output	O
stride	O
to	O
8	O
by	O
using	O
convolutions	B-Method
with	O
stride	O
1	O
.	O
	
Moreover	O
,	O
we	O
increase	O
the	O
receptive	O
field	O
by	O
using	O
dilated	B-Method
convolutions	I-Method
[	O
reference	O
]	O
.	O
	
Specifically	O
,	O
we	O
set	O
the	O
stride	O
to	O
1	O
and	O
the	O
dilation	O
rate	O
to	O
2	O
in	O
the	O
3×3	O
conv	O
layer	O
of	O
conv4	B-Method
1	O
.	O
	
Differently	O
to	O
the	O
original	O
ResNet	O
-	O
50	O
,	O
there	O
is	O
no	O
downsampling	O
in	O
conv4	O
	
x.	O
	
We	O
also	O
add	O
to	O
the	O
backbone	O
an	O
adjust	B-Method
layer	I-Method
(	O
a	O
1×1	B-Method
convolutional	I-Method
layer	I-Method
with	O
256	O
output	O
channels	O
)	O
.	O
	
Examplar	O
and	O
search	O
patches	O
share	O
the	O
network	O
's	O
parameters	O
from	O
conv1	O
to	O
conv4	O
x	O
,	O
while	O
the	O
parameters	O
of	O
the	O
adjust	B-Method
layer	I-Method
are	O
not	O
shared	O
.	O
	
The	O
output	O
features	O
of	O
the	O
adjust	B-Method
layer	I-Method
are	O
then	O
depth	O
-	O
wise	O
cross	O
-	O
correlated	O
,	O
resulting	O
a	O
feature	O
map	O
of	O
size	O
17	O
×	O
17	O
.	O
	
Network	O
heads	O
.	O
	
The	O
network	B-Method
architecture	I-Method
of	O
the	O
branches	O
of	O
both	O
variants	O
are	O
shows	O
in	O
Table	O
7	O
Mask	B-Method
refinement	I-Method
module	I-Method
.	O
	
With	O
the	O
aim	O
of	O
producing	O
a	O
more	O
accurate	O
object	O
mask	O
,	O
we	O
follow	O
the	O
strategy	O
of	O
[	O
reference	O
]	O
,	O
which	O
merges	O
low	O
and	O
high	O
resolution	O
features	O
using	O
multiple	O
refinement	B-Method
modules	I-Method
made	O
of	O
upsampling	B-Method
layers	I-Method
and	O
skip	O
connections	O
.	O
	
Figure	O
9	O
illustrates	O
how	O
a	O
mask	O
is	O
generated	O
with	O
stacked	B-Method
refinement	I-Method
modules	I-Method
.	O
	
Figure	O
7	O
gives	O
an	O
example	O
of	O
refinement	B-Method
module	I-Method
U	O
3	O
.	O
	
section	O
:	O
B.	O
Further	O
qualitative	O
results	O
	
Different	O
masks	O
at	O
different	O
locations	O
.	O
	
Our	O
model	O
generates	O
a	O
mask	O
for	O
each	O
RoW.	O
	
During	O
inference	B-Task
,	O
we	O
rely	O
on	O
the	O
score	O
branch	O
to	O
select	O
the	O
final	O
output	O
mask	O
(	O
using	O
the	O
location	O
attaining	O
the	O
maximum	O
score	O
)	O
.	O
	
The	O
example	O
of	O
Figure	O
8	O
illustrates	O
the	O
multiple	O
output	O
masks	O
produced	O
by	O
the	O
mask	O
branch	O
,	O
each	O
corresponding	O
to	O
a	O
different	O
RoW.	O
	
Benchmark	O
sequences	O
.	O
	
More	O
qualitative	O
results	O
for	O
VOT	B-Task
and	O
DAVIS	B-Task
sequences	I-Task
are	O
shown	O
in	O
Figure	O
10	O
and	O
11	O
.	O
	
ResNet	O
-	O
50	O
	
Figure	O
11	O
.	O
	
Further	O
qualitative	O
results	O
of	O
our	O
method	O
on	O
sequences	O
from	O
the	O
semi	B-Task
-	I-Task
supervised	I-Task
video	I-Task
object	I-Task
segmentation	I-Task
benchmarks	O
DAVIS	O
-	O
2016	O
[	O
reference	O
]	O
and	O
DAVIS	O
-	O
2017	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
	
document	O
:	O
Efficient	O
Multi	B-Method
-	I-Method
Scale	I-Method
3D	I-Method
CNN	I-Method
with	O
fully	B-Method
connected	I-Method
CRF	I-Method
for	O
Accurate	B-Task
Brain	I-Task
Lesion	I-Task
Segmentation	I-Task
	
We	O
propose	O
a	O
dual	O
pathway	O
,	O
11	O
-	O
layers	O
deep	O
,	O
three	O
-	O
dimensional	O
Convolutional	B-Method
Neural	I-Method
Network	I-Method
for	O
the	O
challenging	O
task	O
of	O
brain	O
lesion	O
segmentation	B-Task
.	O
	
The	O
devised	O
architecture	O
is	O
the	O
result	O
of	O
an	O
in	O
-	O
depth	O
analysis	O
of	O
the	O
limitations	O
of	O
current	O
networks	B-Method
proposed	O
for	O
similar	O
applications	O
.	O
	
To	O
overcome	O
the	O
computational	B-Metric
burden	O
of	O
processing	B-Task
3D	I-Task
medical	I-Task
scans	I-Task
,	O
we	O
have	O
devised	O
an	O
efficient	O
and	O
effective	O
dense	O
training	B-Method
scheme	O
which	O
joins	O
the	O
processing	O
of	O
adjacent	O
image	O
patches	O
into	O
one	O
pass	O
through	O
the	O
network	O
while	O
automatically	O
adapting	O
to	O
the	O
inherent	O
class	O
imbalance	O
present	O
in	O
the	O
data	O
.	O
	
Further	O
,	O
we	O
analyze	O
the	O
development	O
of	O
deeper	O
,	O
thus	O
more	O
discriminative	B-Method
3D	I-Method
CNNs	I-Method
.	O
	
In	O
order	O
to	O
incorporate	O
both	O
local	O
and	O
larger	O
contextual	O
information	O
,	O
we	O
employ	O
a	O
dual	B-Method
pathway	I-Method
architecture	I-Method
that	O
processes	O
the	O
input	O
images	O
at	O
multiple	O
scales	O
simultaneously	O
.	O
	
For	O
post	O
-	O
processing	O
of	O
the	O
network	O
’s	O
soft	O
segmentation	B-Task
,	O
we	O
use	O
a	O
3D	B-Method
fully	I-Method
connected	I-Method
Conditional	I-Method
Random	I-Method
Field	I-Method
which	O
effectively	O
removes	O
false	O
positives	O
.	O
	
Our	O
pipeline	O
is	O
extensively	O
evaluated	O
on	O
three	O
challenging	O
tasks	O
of	O
lesion	O
segmentation	B-Task
in	O
multi	O
-	O
channel	O
MRI	O
patient	O
data	O
with	O
traumatic	O
brain	O
injuries	O
,	O
brain	O
tumors	O
,	O
and	O
ischemic	O
stroke	O
.	O
	
We	O
improve	O
on	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
for	O
all	O
three	O
applications	O
,	O
with	O
top	O
ranking	B-Metric
performance	I-Metric
on	O
the	O
public	O
benchmarks	O
BRATS	B-Material
2015	I-Material
and	O
ISLES	O
2015	O
.	O
	
Our	O
method	O
is	O
computationally	O
efficient	O
,	O
which	O
allows	O
its	O
adoption	O
in	O
a	O
variety	O
of	O
research	O
and	O
clinical	O
settings	O
.	O
	
The	O
source	O
code	O
of	O
our	O
implementation	O
is	O
made	O
publicly	O
available	O
.	O
	
section	O
:	O
Introduction	O
	
Segmentation	B-Task
and	O
the	O
subsequent	O
quantitative	B-Task
assessment	I-Task
of	I-Task
lesions	I-Task
in	O
medical	O
images	O
provide	O
valuable	O
information	O
for	O
the	O
analysis	B-Task
of	I-Task
neuropathologies	I-Task
and	O
are	O
important	O
for	O
planning	B-Task
of	I-Task
treatment	I-Task
strategies	I-Task
,	O
monitoring	B-Task
of	I-Task
disease	I-Task
progression	I-Task
and	O
prediction	B-Task
of	I-Task
patient	I-Task
outcome	I-Task
.	O
	
For	O
a	O
better	O
understanding	O
of	O
the	O
pathophysiology	B-Task
of	I-Task
diseases	I-Task
,	O
quantitative	B-Task
imaging	I-Task
can	O
reveal	O
clues	O
about	O
the	O
disease	O
characteristics	O
and	O
effects	O
on	O
particular	O
anatomical	O
structures	O
.	O
	
For	O
example	O
,	O
the	O
associations	O
of	O
different	O
lesion	O
types	O
,	O
their	O
spatial	O
distribution	O
and	O
extent	O
with	O
acute	O
and	O
chronic	O
sequelae	O
after	O
traumatic	O
brain	O
injury	O
(	O
TBI	O
)	O
are	O
still	O
poorly	O
understood	O
(	O
)	O
.	O
	
However	O
,	O
there	O
is	O
growing	O
evidence	O
that	O
quantification	B-Task
of	I-Task
lesion	I-Task
burden	I-Task
may	O
add	O
insight	O
into	O
the	O
functional	O
outcome	O
of	O
patients	O
(	O
)	O
.	O
	
Additionally	O
,	O
exact	O
locations	O
of	O
injuries	O
relate	O
to	O
particular	O
deficits	O
depending	O
on	O
the	O
brain	O
structure	O
that	O
is	O
affected	O
(	O
)	O
.	O
	
This	O
is	O
in	O
line	O
with	O
estimates	O
that	O
functional	O
deficits	O
caused	O
by	O
stroke	O
are	O
associated	O
with	O
the	O
extent	O
of	O
damage	O
to	O
particular	O
parts	O
of	O
the	O
brain	O
(	O
)	O
.	O
	
Lesion	O
burden	O
is	O
commonly	O
quantified	O
by	O
means	O
of	O
volume	O
and	O
number	O
of	O
lesions	O
,	O
biomarkers	O
that	O
have	O
been	O
shown	O
to	O
be	O
related	O
to	O
cognitive	B-Task
deficits	I-Task
.	O
	
For	O
example	O
,	O
volume	O
of	O
white	O
matter	O
lesions	O
(	O
WML	O
)	O
correlates	O
with	O
cognitive	O
decline	O
and	O
increased	O
risk	O
of	O
dementia	O
(	O
)	O
.	O
	
In	O
clinical	O
research	O
on	O
multiple	O
sclerosis	O
(	O
MS	O
)	O
,	O
lesion	O
count	O
and	O
volume	O
are	O
used	O
to	O
analyse	B-Task
disease	I-Task
progression	I-Task
and	O
effectiveness	B-Task
of	I-Task
pharmaceutical	I-Task
treatment	I-Task
(	O
)	O
.	O
	
Finally	O
,	O
accurate	B-Task
delineation	I-Task
of	I-Task
the	I-Task
pathology	I-Task
is	O
important	O
in	O
the	O
case	O
of	O
brain	O
tumors	O
,	O
where	O
estimation	O
of	O
the	O
relative	O
volume	O
of	O
a	O
tumor	O
’s	O
sub	O
-	O
components	O
is	O
required	O
for	O
planning	B-Task
radiotherapy	I-Task
and	I-Task
treatment	I-Task
follow	I-Task
-	I-Task
up	I-Task
(	O
)	O
.	O
	
The	O
quantitative	B-Task
analysis	I-Task
of	I-Task
lesions	I-Task
requires	O
accurate	O
lesion	O
segmentation	B-Task
in	O
multi	O
-	O
modal	O
,	O
three	O
-	O
dimensional	O
images	O
which	O
is	O
a	O
challenging	O
task	O
for	O
a	O
number	O
of	O
reasons	O
.	O
	
The	O
heterogeneous	O
appearance	O
of	O
lesions	O
including	O
the	O
large	O
variability	O
in	O
location	O
,	O
size	O
,	O
shape	O
and	O
frequency	O
make	O
it	O
difficult	O
to	O
devise	O
effective	O
segmentation	B-Task
rules	O
.	O
	
It	O
is	O
thus	O
highly	O
non	O
-	O
trivial	O
to	O
delineate	O
contusions	O
,	O
edema	O
and	O
haemorrhages	O
in	O
TBI	O
(	O
)	O
,	O
or	O
sub	O
-	O
components	O
of	O
brain	O
tumors	O
such	O
as	O
proliferating	O
cells	O
and	O
necrotic	O
core	O
(	O
)	O
.	O
	
The	O
arguably	O
most	O
accurate	O
segmentation	B-Task
results	O
can	O
be	O
obtained	O
through	O
manual	B-Method
delineation	I-Method
by	O
a	O
human	O
expert	O
which	O
is	O
tedious	O
,	O
expensive	O
,	O
time	O
-	O
consuming	O
,	O
impractical	O
in	O
larger	O
studies	O
,	O
and	O
introduces	O
inter	B-Metric
-	I-Metric
observer	I-Metric
variability	I-Metric
.	O
	
Additionally	O
,	O
for	O
deciding	O
whether	O
a	O
particular	O
region	O
is	O
part	O
of	O
a	O
lesion	O
multiple	O
image	O
sequences	O
with	O
varying	O
contrasts	O
need	O
to	O
be	O
considered	O
,	O
and	O
the	O
level	O
of	O
expert	O
knowledge	O
and	O
experience	O
are	O
important	O
factors	O
that	O
impact	O
segmentation	B-Task
accuracy	O
.	O
	
Hence	O
,	O
in	O
clinical	O
routine	O
often	O
only	O
qualitative	O
,	O
visual	B-Metric
inspection	I-Metric
,	O
or	O
at	O
best	O
crude	O
measures	O
like	O
approximate	O
lesion	O
volume	O
and	O
number	O
of	O
lesions	O
are	O
used	O
(	O
)	O
.	O
	
In	O
order	O
to	O
capture	O
and	O
better	O
understand	O
the	O
complexity	O
of	O
brain	O
pathologies	O
it	O
is	O
important	O
to	O
conduct	O
large	O
studies	O
with	O
many	O
subjects	O
to	O
gain	O
the	O
statistical	O
power	O
for	O
drawing	O
conclusions	O
across	O
a	O
whole	O
patient	O
population	O
.	O
	
The	O
development	O
of	O
accurate	O
,	O
automatic	O
segmentation	B-Task
algorithms	O
has	O
therefore	O
become	O
a	O
major	O
research	O
focus	O
in	O
medical	B-Task
image	I-Task
computing	I-Task
with	O
the	O
potential	O
to	O
offer	O
objective	O
,	O
reproducible	O
,	O
and	O
scalable	O
approaches	O
to	O
quantitative	B-Task
assessment	I-Task
of	I-Task
brain	I-Task
lesions	I-Task
.	O
	
Figure	O
[	O
reference	O
]	O
illustrates	O
some	O
of	O
the	O
challenges	O
that	O
arise	O
when	O
devising	O
a	O
computational	B-Metric
approach	O
for	O
the	O
task	O
of	O
automatic	O
lesion	O
segmentation	B-Task
.	O
	
The	O
figure	O
summarizes	O
statistics	O
and	O
shows	O
examples	O
of	O
brain	O
lesions	O
in	O
the	O
case	O
of	O
TBI	O
,	O
but	O
is	O
representative	O
of	O
other	O
pathologies	O
such	O
as	O
brain	O
tumors	O
and	O
ischemic	O
stroke	O
.	O
	
Lesions	O
can	O
occur	O
at	O
multiple	O
sites	O
,	O
with	O
varying	O
shapes	O
and	O
sizes	O
,	O
and	O
their	O
image	O
intensity	O
profiles	O
largely	O
overlap	O
with	O
non	O
-	O
affected	O
,	O
healthy	O
parts	O
of	O
the	O
brain	O
or	O
lesions	O
which	O
are	O
not	O
in	O
the	O
focus	O
of	O
interest	O
.	O
	
For	O
example	O
,	O
stroke	O
and	O
MS	O
lesions	O
have	O
a	O
similar	O
hyper	O
-	O
intense	O
appearance	O
in	O
FLAIR	O
sequences	O
as	O
other	O
WMLs	O
(	O
)	O
.	O
	
It	O
is	O
generally	O
difficult	O
to	O
derive	O
statistical	O
prior	O
information	O
about	O
lesion	O
shape	O
and	O
appearance	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
in	O
some	O
applications	O
there	O
is	O
an	O
expectation	O
on	O
the	O
spatial	O
configuration	O
of	O
segmentation	B-Task
labels	O
,	O
for	O
example	O
there	O
is	O
a	O
hierarchical	O
layout	O
of	O
sub	O
-	O
components	O
in	O
brain	O
tumors	O
.	O
	
Ideally	O
,	O
a	O
computational	B-Metric
approach	O
is	O
able	O
to	O
adjust	O
itself	O
to	O
application	O
specific	O
characteristics	O
by	O
learning	O
from	O
a	O
set	O
of	O
a	O
few	O
example	O
images	O
.	O
	
[	O
b	O
]	O
0.225	O
[	O
b	O
]	O
0.225	O
[	O
b	O
]	O
0.225	O
[	O
b	O
]	O
0.22	O
[	O
b	O
]	O
1.0	O
	
subsection	O
:	O
Related	O
Work	O
	
A	O
multitude	O
of	O
automatic	O
lesion	O
segmentation	B-Task
methods	O
have	O
been	O
proposed	O
over	O
the	O
last	O
decade	O
,	O
and	O
several	O
main	O
categories	O
of	O
approaches	O
can	O
be	O
identified	O
.	O
	
One	O
group	O
of	O
methods	O
poses	O
the	O
lesion	O
segmentation	B-Task
task	O
as	O
an	O
abnormality	B-Task
detection	I-Task
problem	I-Task
,	O
for	O
example	O
by	O
employing	O
image	B-Task
registration	I-Task
.	O
	
The	O
early	O
work	O
of	O
and	O
more	O
recent	O
ones	O
by	O
and	O
align	O
the	O
pathological	O
scan	O
to	O
a	O
healthy	O
atlas	O
and	O
lesions	O
are	O
detected	O
based	O
on	O
deviations	O
in	O
tissue	O
appearance	O
between	O
the	O
patient	O
and	O
the	O
atlas	O
image	O
.	O
	
Lesions	O
,	O
however	O
,	O
may	O
cause	O
large	O
structural	O
deformations	O
that	O
may	O
lead	O
to	O
incorrect	O
segmentation	B-Task
due	O
to	O
incorrect	O
registration	B-Task
.	O
	
alleviate	O
this	O
problem	O
by	O
jointly	O
solving	O
the	O
segmentation	B-Task
and	O
registration	B-Task
tasks	I-Task
.	O
	
showed	O
that	O
registration	B-Method
together	O
with	O
a	O
low	B-Method
-	I-Method
rank	I-Method
decomposition	I-Method
gives	O
as	O
a	O
by	O
-	O
product	O
the	O
abnormal	O
structures	O
in	O
the	O
sparse	O
components	O
,	O
although	O
,	O
this	O
may	O
not	O
be	O
precise	O
enough	O
for	O
detection	B-Task
of	I-Task
small	I-Task
lesions	I-Task
.	O
	
Abnormality	B-Task
detection	I-Task
has	O
also	O
been	O
proposed	O
within	O
image	B-Task
synthesis	I-Task
works	O
.	O
	
Representative	O
approaches	O
are	O
those	O
of	O
using	O
dictionary	B-Method
learning	I-Method
and	O
using	O
a	O
patch	B-Method
-	I-Method
based	I-Method
approach	I-Method
.	O
	
The	O
idea	O
is	O
to	O
synthesize	O
pseudo	O
-	O
healthy	O
images	O
that	O
when	O
compared	O
to	O
the	O
patient	O
scan	O
allow	O
to	O
highlight	O
abnormal	O
regions	O
.	O
	
In	O
this	O
context	O
,	O
present	O
a	O
generative	B-Method
model	I-Method
for	O
image	B-Task
synthesis	I-Task
that	O
yields	O
a	O
probabilistic	O
segmentation	B-Task
of	O
abnormalities	O
.	O
	
Another	O
unsupervised	B-Method
technique	I-Method
is	O
proposed	O
by	O
,	O
a	O
saliency	B-Method
-	I-Method
based	I-Method
method	I-Method
that	O
exploits	O
brain	O
asymmetry	O
in	O
pathological	O
cases	O
.	O
	
A	O
common	O
advantage	O
of	O
the	O
above	O
methods	O
is	O
that	O
they	O
do	O
not	O
require	O
a	O
training	B-Method
dataset	O
with	O
corresponding	O
manual	O
annotations	O
.	O
	
In	O
general	O
,	O
these	O
approaches	O
are	O
more	O
suitable	O
for	O
detecting	B-Task
lesions	I-Task
rather	O
than	O
accurately	O
segmenting	O
them	O
.	O
	
Some	O
of	O
the	O
most	O
successful	O
,	O
supervised	B-Method
segmentation	I-Method
methods	I-Method
for	O
brain	B-Task
lesions	I-Task
are	O
based	O
on	O
voxel	B-Method
-	I-Method
wise	I-Method
classifiers	I-Method
,	O
such	O
as	O
Random	B-Method
Forests	I-Method
.	O
	
Representative	O
work	O
is	O
that	O
of	O
on	O
MS	O
lesions	O
,	O
employing	O
intensity	O
features	O
to	O
capture	O
the	O
appearance	O
of	O
the	O
region	O
around	O
each	O
voxel	O
.	O
	
combine	O
this	O
with	O
a	O
generative	B-Method
Gaussian	I-Method
Mixture	I-Method
Model	I-Method
(	I-Method
GMM	I-Method
)	I-Method
to	O
obtain	O
tissue	O
-	O
specific	O
probabilistic	O
priors	O
(	O
)	O
.	O
	
This	O
framework	O
was	O
adopted	O
in	O
multiple	O
works	O
,	O
with	O
representative	O
pipelines	O
for	O
brain	O
tumors	O
by	O
and	O
TBI	O
by	O
.	O
	
Both	O
works	O
incorporate	O
morphological	O
and	O
contextual	O
features	O
to	O
better	O
capture	O
the	O
heterogeneity	O
of	O
lesions	O
.	O
also	O
incorporate	O
brain	O
structure	O
segmentation	B-Task
results	O
obtained	O
from	O
a	O
multi	B-Method
-	I-Method
atlas	I-Method
label	I-Method
propagation	I-Method
approach	I-Method
(	O
)	O
to	O
provide	O
strong	O
tissue	O
-	O
class	O
priors	O
to	O
the	O
Random	B-Method
Forests	I-Method
.	O
	
additionally	O
use	O
a	O
Markov	B-Method
Random	I-Method
Field	I-Method
(	O
MRF	B-Method
)	I-Method
to	O
incorporate	O
spatial	B-Method
regularization	I-Method
.	O
	
MRFs	B-Method
are	O
commonly	O
used	O
to	O
encourage	O
spatial	O
continuity	O
of	O
the	O
segmentation	B-Task
(	O
)	O
.	O
	
Although	O
those	O
methods	O
have	O
been	O
very	O
successful	O
,	O
it	O
appears	O
that	O
their	O
modeling	O
capabilities	O
still	O
have	O
significant	O
limitations	O
.	O
	
This	O
is	O
confirmed	O
by	O
the	O
results	O
of	O
the	O
most	O
recent	O
challenges	O
,	O
and	O
also	O
by	O
our	O
own	O
experience	O
and	O
experimentation	O
with	O
such	O
approaches	O
.	O
	
At	O
the	O
same	O
time	O
,	O
deep	B-Method
learning	I-Method
techniques	I-Method
have	O
emerged	O
as	O
a	O
powerful	O
alternative	O
for	O
supervised	B-Task
learning	I-Task
with	O
great	O
model	B-Metric
capacity	I-Metric
and	O
the	O
ability	O
to	O
learn	O
highly	O
discriminative	O
features	O
for	O
the	O
task	O
at	O
hand	O
.	O
	
These	O
features	O
often	O
outperform	O
hand	O
-	O
crafted	O
and	O
pre	O
-	O
defined	O
feature	O
sets	O
.	O
	
In	O
particular	O
,	O
Convolutional	B-Method
Neural	I-Method
Networks	I-Method
(	O
CNNs	B-Method
)	O
(	O
)	O
have	O
been	O
applied	O
with	O
promising	O
results	O
on	O
a	O
variety	O
of	O
biomedical	B-Task
imaging	I-Task
problems	I-Task
.	O
	
presented	O
the	O
first	O
GPU	B-Method
implementation	I-Method
of	O
a	O
two	B-Method
-	I-Method
dimensional	I-Method
CNN	I-Method
for	O
the	O
segmentation	B-Task
of	O
neural	O
membranes	O
.	O
	
From	O
the	O
CNN	B-Method
based	O
work	O
that	O
followed	O
,	O
related	O
to	O
our	O
approach	O
are	O
the	O
methods	O
of	O
,	O
with	O
the	O
latter	O
being	O
the	O
best	O
performing	O
automatic	O
approach	O
in	O
the	O
BRATS	B-Material
2015	I-Material
challenge	O
(	O
)	O
.	O
	
These	O
methods	O
are	O
based	O
on	O
2D	B-Method
CNNs	I-Method
,	O
which	O
have	O
been	O
used	O
extensively	O
in	O
computer	B-Task
vision	I-Task
applications	I-Task
on	O
natural	O
images	O
.	O
	
Here	O
,	O
the	O
segmentation	B-Task
of	O
a	O
3D	O
brain	O
scan	O
is	O
achieved	O
by	O
processing	O
each	O
2D	O
slice	O
independently	O
,	O
which	O
is	O
arguably	O
a	O
non	O
-	O
optimal	O
use	O
of	O
the	O
volumetric	O
medical	O
image	O
data	O
.	O
	
Despite	O
the	O
simplicity	O
in	O
the	O
architecture	O
,	O
the	O
promising	O
results	O
obtained	O
by	O
these	O
methods	O
indicate	O
the	O
potential	O
of	O
CNNs	B-Method
.	O
	
Fully	B-Method
3D	I-Method
CNNs	I-Method
come	O
with	O
an	O
increased	O
number	O
of	O
parameters	O
and	O
significant	O
memory	O
and	O
computational	B-Metric
requirements	O
.	O
	
Previous	O
work	O
discusses	O
problems	O
and	O
apparent	O
limitations	O
when	O
employing	O
a	O
3D	B-Method
CNN	I-Method
on	O
medical	O
imaging	O
data	O
(	O
)	O
.	O
	
To	O
incorporate	O
3D	O
contextual	O
information	O
,	O
multiple	O
works	O
used	O
2D	B-Method
CNNs	I-Method
on	O
three	O
orthogonal	O
2D	O
patches	O
(	O
)	O
.	O
	
In	O
their	O
work	O
for	O
structural	O
brain	O
segmentation	B-Task
,	O
extracted	O
large	O
2D	O
patches	O
from	O
multiple	O
scales	O
of	O
the	O
image	O
and	O
combined	O
them	O
with	O
small	O
single	O
-	O
scale	O
3D	O
patches	O
,	O
in	O
order	O
to	O
avoid	O
the	O
memory	B-Metric
requirements	I-Metric
of	O
fully	O
3D	O
networks	B-Method
.	O
	
One	O
of	O
the	O
reasons	O
that	O
discouraged	O
the	O
use	O
of	O
3D	B-Method
CNNs	I-Method
is	O
the	O
slow	O
inference	B-Method
due	O
to	O
the	O
computationally	O
expensive	O
3D	B-Method
convolutions	I-Method
.	O
	
In	O
contrast	O
to	O
the	O
2D	B-Method
/	I-Method
3D	I-Method
hybrid	I-Method
variants	I-Method
(	I-Method
)	I-Method
,	O
3D	B-Method
CNNs	I-Method
can	O
fully	O
exploit	O
dense	O
-	O
inference	B-Method
(	O
)	O
,	O
a	O
technique	O
that	O
greatly	O
decreases	O
inference	B-Metric
times	I-Metric
and	O
which	O
we	O
will	O
further	O
discuss	O
in	O
section	O
[	O
reference	O
]	O
.	O
	
By	O
employing	O
dense	O
-	O
inference	B-Method
with	O
3D	B-Method
CNNs	I-Method
,	O
and	O
reported	O
computation	B-Metric
times	O
of	O
a	O
few	O
seconds	O
and	O
approximately	O
a	O
minute	O
respectively	O
for	O
the	O
processing	O
of	O
a	O
single	O
brain	O
scan	O
.	O
	
Even	O
though	O
the	O
size	O
of	O
their	O
developed	O
networks	B-Method
was	O
limited	O
,	O
a	O
factor	O
that	O
is	O
directly	O
related	O
to	O
a	O
network	O
’s	O
representational	O
power	O
,	O
their	O
results	O
on	O
MS	O
and	O
brain	B-Task
tumor	I-Task
segmentation	I-Task
respectively	O
were	O
very	O
promising	O
.	O
	
Performance	O
of	O
CNNs	B-Method
is	O
significantly	O
influenced	O
by	O
the	O
strategy	O
for	O
extracting	O
training	B-Method
samples	O
.	O
	
A	O
commonly	O
adopted	O
approach	O
is	O
training	B-Method
on	O
image	O
patches	O
that	O
are	O
equally	O
sampled	O
from	O
each	O
class	O
.	O
	
This	O
,	O
however	O
,	O
biases	O
the	O
classifier	B-Method
towards	O
rare	O
classes	O
and	O
may	O
result	O
in	O
over	B-Task
-	I-Task
segmentation	I-Task
.	O
	
To	O
counter	O
this	O
,	O
proposes	O
to	O
train	O
a	O
second	O
CNN	B-Method
on	O
samples	O
with	O
a	O
class	O
distribution	O
close	O
to	O
the	O
real	O
one	O
,	O
but	O
oversample	O
pixels	O
that	O
were	O
incorrectly	O
classified	O
in	O
the	O
first	O
stage	O
.	O
	
A	O
secondary	O
training	B-Method
stage	O
was	O
also	O
suggested	O
by	O
,	O
who	O
retrain	O
the	O
classification	B-Method
layer	I-Method
on	O
patches	O
extracted	O
uniformly	O
from	O
the	O
image	O
.	O
	
In	O
practice	O
,	O
two	O
stage	O
training	B-Method
schemes	O
can	O
be	O
prone	O
to	O
overfitting	O
and	O
sensitive	O
to	O
the	O
state	O
of	O
the	O
first	O
classifier	B-Method
.	O
	
Alternatively	O
,	O
dense	O
training	B-Method
(	O
)	O
has	O
been	O
used	O
to	O
train	O
a	O
network	O
on	O
multiple	O
or	O
all	O
voxels	O
of	O
a	O
single	O
image	O
per	O
optimisation	O
step	O
(	O
)	O
.	O
	
This	O
can	O
introduce	O
severe	O
class	O
imbalance	O
,	O
similarly	O
to	O
uniform	B-Method
sampling	I-Method
.	O
	
Weighted	B-Method
cost	I-Method
functions	I-Method
have	O
been	O
proposed	O
in	O
the	O
two	O
latter	O
works	O
to	O
alleviate	O
this	O
problem	O
.	O
	
manually	O
adjusted	O
the	O
sensitivity	O
of	O
the	O
network	O
,	O
but	O
the	O
method	O
can	O
become	O
difficult	O
to	O
calibrate	O
for	O
multi	B-Task
-	I-Task
class	I-Task
problems	I-Task
.	O
	
first	O
balance	O
the	O
cost	O
from	O
each	O
class	O
,	O
which	O
has	O
an	O
effect	O
similar	O
to	O
equal	B-Method
sampling	I-Method
,	O
and	O
further	O
adjust	O
it	O
for	O
the	O
specific	O
task	O
by	O
estimating	O
the	O
difficulty	O
of	O
segmenting	O
each	O
pixel	O
.	O
	
subsection	O
:	O
Contributions	O
	
We	O
present	O
a	O
fully	B-Method
automatic	I-Method
approach	I-Method
for	O
lesion	O
segmentation	B-Task
in	O
multi	B-Task
-	I-Task
modal	I-Task
brain	I-Task
MRI	I-Task
based	O
on	O
an	O
11	O
-	O
layers	O
deep	O
,	O
multi	B-Method
-	I-Method
scale	I-Method
,	I-Method
3D	I-Method
CNN	I-Method
with	O
the	O
following	O
main	O
contributions	O
:	O
We	O
propose	O
an	O
efficient	O
hybrid	O
training	B-Method
scheme	O
,	O
utilizing	O
dense	O
training	B-Method
(	O
)	O
on	O
sampled	O
image	O
segments	O
,	O
and	O
analyze	O
its	O
behaviour	O
in	O
adapting	O
to	O
class	O
imbalance	O
of	O
the	O
segmentation	B-Task
problem	O
at	O
hand	O
.	O
	
We	O
analyze	O
in	O
depth	O
the	O
development	O
of	O
deeper	O
,	O
thus	O
more	O
discriminative	O
,	O
yet	O
computationally	O
efficient	O
3D	B-Method
CNNs	I-Method
.	O
	
We	O
exploit	O
the	O
utilization	O
of	O
small	B-Method
kernels	I-Method
,	O
a	O
design	B-Method
approach	I-Method
previously	O
found	O
beneficial	O
in	O
2D	O
networks	B-Method
(	O
)	O
that	O
impacts	O
3D	B-Method
CNNs	I-Method
even	O
more	O
,	O
and	O
present	O
adopted	O
solutions	O
that	O
enable	O
training	B-Method
deeper	O
networks	B-Method
.	O
	
We	O
employ	O
parallel	B-Method
convolutional	I-Method
pathways	I-Method
for	O
multi	B-Task
-	I-Task
scale	I-Task
processing	I-Task
,	O
a	O
solution	O
to	O
efficiently	O
incorporate	O
both	O
local	O
and	O
contextual	O
information	O
which	O
greatly	O
improves	O
segmentation	B-Task
results	O
.	O
	
We	O
demonstrate	O
the	O
generalization	O
capabilities	O
of	O
our	O
system	O
,	O
which	O
without	O
significant	O
modifications	O
outperforms	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
on	O
a	O
variety	O
of	O
challenging	O
segmentation	B-Task
tasks	O
,	O
with	O
top	O
ranking	O
results	O
in	O
two	O
MICCAI	O
challenges	O
,	O
ISLES	O
and	O
BRATS	B-Material
.	O
	
Furthermore	O
,	O
a	O
detailed	O
analysis	O
of	O
the	O
network	O
reveals	O
valuable	O
insights	O
into	O
the	O
powerful	O
black	O
box	O
of	O
deep	B-Method
learning	I-Method
with	O
CNNs	B-Method
.	O
	
For	O
example	O
,	O
we	O
have	O
found	O
that	O
our	O
network	O
is	O
capable	O
of	O
learning	O
very	O
complex	O
,	O
high	O
level	O
features	O
that	O
separate	O
gray	O
matter	O
(	O
GM	O
)	O
,	O
cerebrospinal	O
fluid	O
(	O
CSF	O
)	O
and	O
other	O
anatomical	O
structures	O
to	O
identify	O
the	O
image	O
regions	O
corresponding	O
to	O
lesions	O
.	O
	
Additionally	O
,	O
we	O
have	O
extended	O
the	O
fully	B-Method
-	I-Method
connected	I-Method
Conditional	I-Method
Random	I-Method
Field	I-Method
(	O
CRF	B-Method
)	O
model	O
by	O
to	O
3D	O
which	O
we	O
use	O
for	O
final	O
post	B-Task
-	I-Task
processing	I-Task
of	O
the	O
CNN	B-Task
’s	I-Task
soft	I-Task
segmentation	I-Task
maps	I-Task
.	O
	
This	O
CRF	B-Method
overcomes	O
limitations	O
of	O
previous	O
models	O
as	O
it	O
can	O
handle	O
arbitrarily	O
large	O
neighborhoods	O
while	O
preserving	O
fast	O
inference	B-Metric
times	I-Metric
.	O
	
To	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
this	O
is	O
the	O
first	O
use	O
of	O
a	O
fully	B-Method
connected	I-Method
CRF	I-Method
on	O
medical	O
data	O
.	O
	
To	O
facilitate	O
further	O
research	O
and	O
encourage	O
other	O
researchers	O
to	O
build	O
upon	O
our	O
results	O
,	O
the	O
source	O
code	O
of	O
our	O
lesion	O
segmentation	B-Task
method	O
including	O
the	O
CNN	B-Method
and	O
the	O
3D	O
fully	B-Method
connected	I-Method
CRF	I-Method
is	O
made	O
publicly	O
available	O
on	O
.	O
	
section	O
:	O
Method	O
	
Our	O
proposed	O
lesion	O
segmentation	B-Task
method	O
consists	O
of	O
two	O
main	O
components	O
,	O
a	O
3D	B-Method
CNN	I-Method
that	O
produces	O
highly	O
accurate	O
,	O
soft	O
segmentation	B-Task
maps	O
,	O
and	O
a	O
fully	O
connected	O
3D	O
CRF	B-Method
that	O
imposes	O
regularization	O
constraints	O
on	O
the	O
CNN	O
output	O
and	O
produces	O
the	O
final	O
hard	O
segmentation	B-Task
labels	O
.	O
	
The	O
main	O
contributions	O
of	O
our	O
work	O
are	O
within	O
the	O
CNN	B-Method
component	I-Method
which	O
we	O
describe	O
first	O
in	O
the	O
following	O
.	O
	
subsection	O
:	O
3D	B-Method
CNNs	I-Method
for	O
Dense	B-Task
Segmentation	I-Task
–	O
Setting	O
the	O
Baseline	O
	
CNNs	B-Method
produce	O
estimates	O
for	O
the	O
voxel	O
-	O
wise	O
segmentation	B-Task
labels	O
by	O
classifying	O
each	O
voxel	O
in	O
an	O
image	O
independently	O
taking	O
the	O
neighborhood	O
,	O
i.e.	O
local	O
and	O
contextual	O
image	O
information	O
,	O
into	O
account	O
.	O
	
This	O
is	O
achieved	O
by	O
sequential	B-Method
convolutions	I-Method
of	O
the	O
input	O
with	O
multiple	O
filters	O
at	O
the	O
cascaded	B-Method
layers	I-Method
of	I-Method
the	I-Method
network	I-Method
.	O
	
Each	O
layer	O
consists	O
of	O
feature	O
maps	O
(	O
FMs	B-Method
)	O
,	O
also	O
referred	O
to	O
as	O
channels	O
.	O
	
Every	O
FM	B-Method
is	O
a	O
group	O
of	O
neurons	O
that	O
detects	O
a	O
particular	O
pattern	O
,	O
i.e.	O
a	O
feature	O
,	O
in	O
the	O
channels	O
of	O
the	O
previous	O
layer	O
.	O
	
The	O
pattern	O
is	O
defined	O
by	O
the	O
kernel	O
weights	O
associated	O
with	O
the	O
FM	B-Method
.	O
	
If	O
the	O
neurons	O
of	O
the	O
-	O
th	O
FM	O
in	O
the	O
-	O
th	O
layer	O
are	O
arranged	O
in	O
a	O
3D	O
grid	O
,	O
their	O
activations	O
constitute	O
the	O
image	O
.	O
	
This	O
is	O
the	O
result	O
of	O
convolving	O
each	O
of	O
the	O
previous	O
layer	O
’s	O
channels	O
with	O
a	O
3	B-Method
-	I-Method
dimensional	I-Method
kernel	I-Method
,	O
adding	O
a	O
learned	O
bias	O
and	O
applying	O
a	O
non	B-Method
-	I-Method
linearity	I-Method
.	O
	
Each	O
kernel	O
is	O
a	O
matrix	O
of	O
learned	O
hidden	O
weights	O
.	O
	
The	O
images	O
,	O
input	O
to	O
the	O
first	O
layer	O
,	O
correspond	O
to	O
the	O
channels	O
of	O
the	O
original	O
input	O
image	O
,	O
for	O
instance	O
a	O
multi	O
-	O
sequence	O
3D	O
MRI	O
scan	O
of	O
the	O
brain	O
.	O
	
The	O
concatenation	B-Method
of	I-Method
the	I-Method
kernels	I-Method
can	O
be	O
viewed	O
as	O
a	O
4	B-Method
-	I-Method
dimensional	I-Method
kernel	I-Method
convolving	O
the	O
concatenated	O
channels	O
,	O
which	O
then	O
intuitively	O
expresses	O
that	O
the	O
neurons	O
of	O
higher	O
layers	O
combine	O
the	O
patterns	O
extracted	O
in	O
previous	O
layers	O
,	O
which	O
results	O
in	O
the	O
detection	B-Task
of	O
increasingly	O
more	O
complex	O
patterns	O
.	O
	
The	O
activations	O
of	O
the	O
neurons	O
in	O
the	O
last	O
layer	O
correspond	O
to	O
particular	O
segmentation	B-Task
class	O
labels	O
,	O
hence	O
this	O
layer	O
is	O
also	O
referred	O
to	O
as	O
the	O
classification	B-Method
layer	I-Method
.	O
	
The	O
neurons	O
are	O
thus	O
grouped	O
in	O
FMs	B-Method
,	O
one	O
for	O
each	O
of	O
the	O
segmentation	B-Task
classes	O
.	O
	
Their	O
activations	O
are	O
fed	O
into	O
a	O
position	B-Method
-	I-Method
wise	I-Method
softmax	I-Method
function	I-Method
that	O
produces	O
the	O
predicted	O
posterior	O
for	O
each	O
class	O
,	O
which	O
form	O
soft	O
segmentation	B-Task
maps	O
with	O
(	O
pseudo	O
-)	O
probabilities	O
.	O
is	O
the	O
activation	O
of	O
the	O
-	O
th	O
classification	B-Method
FM	I-Method
at	O
position	O
.	O
	
This	O
baseline	O
network	O
is	O
depicted	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
[	O
b	O
]	O
1.0	O
The	O
neighborhood	O
of	O
voxels	O
in	O
the	O
input	O
that	O
influence	O
the	O
activation	O
of	O
a	O
neuron	O
is	O
its	O
receptive	O
field	O
.	O
	
Its	O
size	O
,	O
,	O
increases	O
at	O
each	O
subsequent	O
layer	O
and	O
is	O
given	O
by	O
the	O
3	O
-	O
dimensional	O
vector	O
:	O
where	O
are	O
vectors	O
expressing	O
the	O
size	O
of	O
the	O
kernels	O
and	O
stride	O
of	O
the	O
receptive	O
field	O
at	O
layer	O
.	O
is	O
given	O
by	O
the	O
product	O
of	O
the	O
strides	O
of	O
kernels	O
in	O
layers	O
preceding	O
.	O
	
In	O
this	O
work	O
only	O
unary	O
strides	O
are	O
used	O
,	O
as	O
larger	O
strides	O
downsample	O
the	O
FMs	O
(	O
)	O
,	O
which	O
is	O
unwanted	O
behaviour	O
for	O
accurate	O
segmentation	B-Task
.	O
	
Thus	O
in	O
our	O
system	O
.	O
	
The	O
receptive	O
field	O
of	O
a	O
neuron	O
in	O
the	O
classification	B-Method
layer	I-Method
corresponds	O
to	O
the	O
image	O
patch	O
that	O
influences	O
the	O
prediction	O
for	O
its	O
central	O
voxel	O
.	O
	
This	O
is	O
called	O
the	O
CNN	B-Method
’s	I-Method
receptive	I-Method
field	I-Method
,	O
with	O
.	O
	
If	O
input	O
of	O
size	O
is	O
provided	O
,	O
the	O
dimensions	O
of	O
the	O
FMs	O
in	O
layer	O
are	O
given	O
by	O
:	O
	
In	O
the	O
common	O
patch	B-Task
-	I-Task
wise	I-Task
classification	I-Task
setting	I-Task
,	O
an	O
input	O
patch	O
of	O
size	O
is	O
provided	O
and	O
the	O
network	O
outputs	O
a	O
single	O
prediction	O
for	O
its	O
central	O
voxel	O
.	O
	
In	O
this	O
case	O
the	O
classification	B-Method
layer	I-Method
consists	O
of	O
FMs	B-Method
with	O
size	O
.	O
	
Networks	B-Method
that	O
are	O
implemented	O
as	O
fully	B-Method
-	I-Method
convolutionals	I-Method
are	O
capable	O
of	O
dense	O
-	O
inference	B-Method
,	O
which	O
is	O
performed	O
when	O
input	O
of	O
size	O
greater	O
than	O
is	O
provided	O
(	O
)	O
.	O
	
In	O
this	O
case	O
,	O
the	O
dimensions	O
of	O
FMs	O
increase	O
according	O
to	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
	
This	O
includes	O
the	O
classification	B-Method
FMs	I-Method
which	O
then	O
output	O
multiple	O
predictions	O
simultaneously	O
,	O
one	O
for	O
each	O
stride	O
of	O
the	O
CNN	O
’s	O
receptive	O
field	O
on	O
the	O
input	O
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
All	O
predictions	O
are	O
equally	O
trustworthy	O
,	O
as	O
long	O
as	O
the	O
receptive	O
field	O
is	O
fully	O
contained	O
within	O
the	O
input	O
and	O
captures	O
only	O
original	O
content	O
,	O
i.e.	O
no	O
padding	O
is	O
used	O
.	O
	
This	O
strategy	O
significantly	O
reduces	O
the	O
computational	B-Metric
costs	O
and	O
memory	O
loads	O
since	O
the	O
otherwise	O
repeated	O
computations	O
of	O
convolutions	O
on	O
the	O
same	O
voxels	O
in	O
overlapping	O
patches	O
are	O
avoided	O
.	O
	
Optimal	O
performance	B-Metric
is	O
achieved	O
if	O
the	O
whole	O
image	O
is	O
scanned	O
in	O
one	O
forward	O
pass	O
.	O
	
If	O
GPU	O
memory	O
constraints	O
do	O
not	O
allow	O
it	O
,	O
such	O
as	O
in	O
the	O
case	O
of	O
large	O
3D	O
networks	B-Method
where	O
a	O
large	O
number	O
of	O
FMs	O
need	O
to	O
be	O
cached	O
,	O
the	O
volume	O
is	O
tiled	O
in	O
multiple	O
image	O
-	O
segments	O
,	O
which	O
are	O
larger	O
than	O
individual	O
patches	O
,	O
but	O
small	O
enough	O
to	O
fit	O
into	O
memory	O
.	O
	
Before	O
analyzing	O
how	O
we	O
exploit	O
the	O
above	O
dense	O
-	O
inference	B-Method
technique	O
for	O
training	B-Method
,	O
which	O
is	O
the	O
first	O
main	O
contribution	O
of	O
our	O
work	O
,	O
we	O
present	O
the	O
commonly	O
used	O
setting	O
in	O
which	O
CNNs	B-Method
are	O
trained	O
patch	O
-	O
by	O
-	O
patch	O
.	O
	
Random	O
patches	O
of	O
size	O
are	O
extracted	O
from	O
the	O
training	B-Method
images	O
.	O
	
A	O
batch	O
is	O
formed	O
out	O
of	O
of	O
these	O
samples	O
,	O
which	O
is	O
then	O
processed	O
by	O
the	O
network	O
for	O
one	O
training	B-Method
iteration	O
of	O
Stochastic	B-Method
Gradient	I-Method
Descent	I-Method
(	O
SGD	B-Method
)	I-Method
.	O
	
This	O
step	O
aims	O
to	O
alter	O
the	O
network	O
	
’s	O
parameters	O
,	O
such	O
as	O
weights	O
and	O
biases	O
,	O
in	O
order	O
to	O
maximize	O
the	O
log	O
likelihood	O
of	O
the	O
data	O
or	O
,	O
equally	O
,	O
minimize	O
the	O
Cross	O
Entropy	O
via	O
the	O
cost	O
function	O
:	O
where	O
the	O
pair	O
is	O
the	O
-	O
th	O
patch	O
in	O
the	O
batch	O
and	O
the	O
true	O
label	O
of	O
its	O
central	O
voxel	O
,	O
while	O
the	O
scalar	O
value	O
is	O
the	O
predicted	O
posterior	O
for	O
class	O
.	O
	
Regularization	O
terms	O
were	O
omitted	O
for	O
simplicity	O
.	O
	
Multiple	O
sequential	B-Method
optimization	I-Method
steps	O
over	O
different	O
batches	O
gradually	O
lead	O
to	O
convergence	O
.	O
	
subsection	O
:	O
Dense	O
Training	B-Method
on	O
Image	B-Task
Segments	I-Task
and	O
Class	B-Task
Balance	I-Task
	
Larger	O
training	B-Method
batch	O
sizes	O
are	O
preferred	O
as	O
they	O
approximate	O
the	O
overall	O
data	O
more	O
accurately	O
and	O
lead	O
to	O
better	O
estimation	O
of	O
the	O
true	O
gradient	O
by	O
SGD	B-Method
.	O
	
However	O
,	O
the	O
memory	B-Metric
requirement	I-Metric
and	O
computation	B-Metric
time	O
increase	O
with	O
the	O
batch	B-Metric
size	I-Metric
.	O
	
This	O
limitation	O
is	O
especially	O
relevant	O
for	O
3D	B-Method
CNNs	I-Method
,	O
where	O
only	O
a	O
few	O
dozens	O
of	O
patches	O
can	O
be	O
processed	O
within	O
reasonable	O
time	O
on	O
modern	O
GPUs	B-Method
.	O
	
To	O
overcome	O
this	O
problem	O
,	O
we	O
devise	O
a	O
training	B-Method
strategy	O
that	O
exploits	O
the	O
dense	O
inference	B-Method
technique	O
on	O
image	O
segments	O
.	O
	
Following	O
from	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
,	O
if	O
an	O
image	O
segment	O
of	O
size	O
greater	O
than	O
is	O
given	O
as	O
input	O
to	O
our	O
network	O
,	O
the	O
output	O
is	O
a	O
posterior	O
probability	O
for	O
multiple	O
voxels	O
.	O
	
If	O
the	O
training	B-Method
batches	O
are	O
formed	O
of	O
segments	O
extracted	O
from	O
the	O
training	B-Method
images	O
,	O
the	O
cost	B-Method
function	I-Method
(	O
[	O
reference	O
]	O
)	O
in	O
the	O
case	O
of	O
dense	O
-	O
training	B-Method
becomes	O
:	O
where	O
and	O
are	O
the	O
-	O
th	O
segment	O
of	O
the	O
batch	O
and	O
the	O
true	O
labels	O
of	O
its	O
predicted	O
voxels	O
respectively	O
.	O
	
is	O
the	O
true	O
label	O
of	O
the	O
-	O
th	O
voxel	O
,	O
the	O
corresponding	O
position	O
in	O
the	O
classification	B-Method
FMs	I-Method
and	O
the	O
output	O
of	O
the	O
softmax	B-Method
function	I-Method
.	O
	
The	O
effective	O
batch	B-Metric
size	I-Metric
is	O
increased	O
by	O
a	O
factor	O
of	O
without	O
a	O
corresponding	O
increase	O
in	O
computational	B-Metric
and	O
memory	B-Metric
requirements	I-Metric
,	O
as	O
earlier	O
discussed	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
.	O
	
Notice	O
that	O
this	O
is	O
a	O
hybrid	B-Method
scheme	I-Method
between	O
the	O
commonly	O
used	O
training	B-Method
on	O
individual	O
patches	O
and	O
the	O
dense	O
training	B-Method
scheme	O
on	O
a	O
whole	O
image	O
(	O
)	O
,	O
with	O
the	O
latter	O
being	O
problematic	O
to	O
apply	O
for	O
training	B-Method
large	I-Method
3D	I-Method
CNNs	I-Method
on	O
volumes	O
of	O
high	O
resolution	O
due	O
to	O
memory	O
limitations	O
.	O
	
[	O
b	O
]	O
0.5	O
An	O
appealing	O
consequence	O
of	O
this	O
scheme	O
is	O
that	O
the	O
sampling	B-Method
of	I-Method
input	I-Method
segments	I-Method
provides	O
a	O
flexible	O
and	O
automatic	O
way	O
to	O
balance	O
the	O
distribution	O
of	O
training	B-Method
samples	O
from	O
different	O
segmentation	B-Task
classes	O
which	O
is	O
an	O
important	O
issue	O
that	O
directly	O
impacts	O
the	O
segmentation	B-Task
accuracy	O
.	O
	
Specifically	O
,	O
we	O
build	O
the	O
training	B-Method
batches	O
by	O
extracting	O
segments	O
from	O
the	O
training	B-Method
images	O
with	O
50	O
%	O
probability	O
being	O
centred	O
on	O
a	O
foreground	O
or	O
background	O
voxel	O
,	O
alleviating	O
class	O
-	O
imbalance	O
.	O
	
Note	O
that	O
the	O
predicted	O
voxels	O
in	O
a	O
segment	O
do	O
not	O
have	O
to	O
be	O
of	O
the	O
same	O
class	O
,	O
something	O
that	O
occurs	O
when	O
a	O
segment	O
is	O
sampled	O
from	O
a	O
region	O
near	O
class	O
boundaries	O
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
Hence	O
,	O
the	O
sampling	B-Metric
rate	I-Metric
of	O
the	O
proposed	O
hybrid	B-Method
method	I-Method
adjusts	O
to	O
the	O
true	O
distribution	O
of	O
the	O
segmentation	B-Task
task	O
’s	O
classes	O
.	O
	
Specifically	O
,	O
the	O
smaller	O
a	O
labelled	O
object	O
,	O
the	O
more	O
background	O
voxels	O
will	O
be	O
captured	O
within	O
segments	O
centred	O
on	O
the	O
foreground	O
voxel	O
.	O
	
Implicitly	O
,	O
this	O
yields	O
a	O
balance	O
between	O
sensitivity	B-Metric
and	O
specificity	B-Metric
in	O
the	O
case	O
of	O
binary	O
segmentation	B-Task
tasks	O
.	O
	
In	O
multi	B-Task
-	I-Task
class	I-Task
problems	I-Task
,	O
the	O
rate	O
at	O
which	O
different	O
classes	O
are	O
captured	O
within	O
a	O
segment	O
centred	O
on	O
foreground	O
reflects	O
the	O
real	O
relative	O
distribution	O
of	O
the	O
foreground	O
classes	O
,	O
while	O
adjusting	O
their	O
frequency	O
relatively	O
to	O
the	O
background	O
.	O
	
subsection	O
:	O
Building	O
Deeper	B-Method
Networks	I-Method
	
Deeper	O
networks	B-Method
have	O
greater	O
discriminative	O
power	O
due	O
to	O
the	O
additional	O
non	O
-	O
linearities	O
and	O
better	O
quality	O
of	O
local	O
optima	O
(	O
)	O
.	O
	
However	O
,	O
convolutions	B-Method
with	I-Method
3D	I-Method
kernels	I-Method
are	O
computationally	O
expensive	O
in	O
comparison	O
to	O
the	O
2D	B-Method
variants	I-Method
,	O
which	O
hampers	O
the	O
addition	O
of	O
more	O
layers	O
.	O
	
Additionally	O
,	O
3D	B-Method
architectures	I-Method
have	O
a	O
larger	O
number	O
of	O
trainable	O
parameters	O
,	O
with	O
each	O
layer	O
adding	O
weights	O
to	O
the	O
model	O
.	O
	
is	O
the	O
number	O
of	O
FMs	O
in	O
layer	O
and	O
the	O
size	O
of	O
its	O
kernel	O
in	O
the	O
respective	O
spatial	O
dimension	O
.	O
	
Overall	O
this	O
makes	O
the	O
network	O
increasingly	O
prone	O
to	O
over	O
-	O
fitting	O
.	O
	
In	O
order	O
to	O
build	O
a	O
deeper	O
3D	B-Method
architecture	I-Method
,	O
we	O
adopt	O
the	O
sole	O
use	O
of	O
small	B-Method
kernels	I-Method
that	O
are	O
faster	O
to	O
convolve	O
with	O
and	O
contain	O
less	O
weights	O
.	O
	
This	O
design	O
approach	O
was	O
previously	O
found	O
beneficial	O
for	O
classification	B-Task
of	I-Task
natural	I-Task
images	I-Task
(	O
)	O
but	O
its	O
effect	O
is	O
even	O
more	O
drastic	O
on	O
3D	O
networks	B-Method
.	O
	
When	O
compared	O
to	O
common	O
kernel	O
choices	O
of	O
(	O
)	O
and	O
in	O
our	O
baseline	B-Method
CNN	I-Method
,	O
the	O
smaller	O
kernels	O
reduce	O
the	O
element	O
-	O
wise	O
multiplications	O
by	O
a	O
factor	O
of	O
approximately	O
while	O
reducing	O
the	O
number	O
of	O
trainable	O
parameters	O
by	O
the	O
same	O
factor	O
.	O
	
Thus	O
deeper	O
network	B-Method
variants	I-Method
that	O
are	O
implicitly	O
regularised	O
and	O
more	O
efficient	O
can	O
be	O
designed	O
by	O
simply	O
replacing	O
each	O
layer	O
of	O
common	B-Method
architectures	I-Method
with	O
more	O
layers	O
that	O
use	O
smaller	O
kernels	O
	
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
[	O
b	O
]	O
0.5	O
However	O
,	O
deeper	O
networks	B-Method
are	O
more	O
difficult	O
to	O
train	O
.	O
	
It	O
has	O
been	O
shown	O
that	O
the	O
forward	O
(	O
neuron	O
activations	O
)	O
and	O
backwards	O
(	O
gradients	O
)	O
propagated	O
signal	O
may	O
explode	O
or	O
vanish	O
if	O
care	O
is	O
not	O
given	O
to	O
retain	O
its	O
variance	O
(	O
)	O
.	O
	
This	O
occurs	O
because	O
at	O
every	O
successive	O
layer	O
,	O
the	O
variance	O
of	O
the	O
signal	O
is	O
multiplied	O
by	O
,	O
where	O
is	O
the	O
number	O
of	O
weights	O
through	O
which	O
a	O
neuron	O
of	O
layer	O
is	O
connected	O
to	O
its	O
input	O
and	O
is	O
the	O
variance	O
of	O
the	O
layer	O
’s	O
weights	O
.	O
	
To	O
better	O
preserve	O
the	O
signal	O
in	O
the	O
initial	O
training	B-Method
stage	O
we	O
adopt	O
a	O
scheme	O
recently	O
derived	O
for	O
ReLu	O
-	O
based	O
networks	B-Method
by	O
and	O
initialize	O
the	O
kernel	O
weights	O
of	O
our	O
system	O
by	O
sampling	O
from	O
the	O
normal	B-Method
distribution	I-Method
.	O
	
A	O
phenomenon	O
of	O
similar	O
nature	O
that	O
hinders	O
the	O
network	O
	
’s	O
performance	B-Metric
is	O
the	O
“	O
internal	O
covariate	O
shift	O
”	O
(	O
)	O
.	O
	
It	O
occurs	O
throughout	O
training	B-Method
,	O
because	O
the	O
weight	O
updates	O
to	O
deeper	O
layers	O
result	O
in	O
a	O
continuously	O
changing	O
distribution	O
of	O
signal	O
at	O
higher	O
layers	O
,	O
which	O
hinders	O
the	O
convergence	O
of	O
their	O
weights	O
.	O
	
Specifically	O
,	O
at	O
training	B-Method
iteration	O
the	O
weight	B-Method
updates	I-Method
may	O
cause	O
deviation	O
to	O
the	O
variance	O
of	O
the	O
weights	O
.	O
	
At	O
the	O
next	O
iteration	O
the	O
signal	O
will	O
be	O
amplified	O
by	O
.	O
	
Thus	O
before	O
influencing	O
the	O
signal	O
,	O
any	O
deviation	O
is	O
amplified	O
by	O
which	O
is	O
exponential	O
in	O
the	O
number	O
of	O
dimensions	O
.	O
	
For	O
this	O
reason	O
the	O
problem	O
affects	O
training	B-Method
of	O
3D	B-Task
CNNs	I-Task
more	O
severely	O
than	O
conventional	O
2D	B-Method
systems	I-Method
.	O
	
For	O
countering	O
it	O
,	O
we	O
adopt	O
the	O
recently	O
proposed	O
Batch	B-Method
Normalisation	I-Method
(	I-Method
BN	I-Method
)	I-Method
technique	I-Method
to	O
all	O
hidden	O
layers	O
(	O
)	O
,	O
which	O
allows	O
normalization	O
of	O
the	O
FM	O
activations	O
at	O
every	O
optimization	O
step	O
in	O
order	O
to	O
better	O
preserve	O
the	O
signal	O
.	O
	
subsection	O
:	O
Multi	B-Task
-	I-Task
Scale	I-Task
Processing	I-Task
via	O
Parallel	B-Method
Convolutional	I-Method
Pathways	I-Method
	
The	O
segmentation	B-Task
of	O
each	O
voxel	O
is	O
performed	O
by	O
taking	O
into	O
account	O
the	O
contextual	O
information	O
that	O
is	O
captured	O
by	O
the	O
receptive	O
field	O
of	O
the	O
CNN	B-Method
when	O
it	O
is	O
centred	O
on	O
the	O
voxel	O
.	O
	
The	O
spatial	O
context	O
is	O
providing	O
important	O
information	O
for	O
being	O
able	O
to	O
discriminate	O
voxels	O
that	O
otherwise	O
appear	O
very	O
similar	O
when	O
considering	O
only	O
local	O
appearance	O
.	O
	
From	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
follows	O
that	O
an	O
increase	O
of	O
the	O
CNN	O
’s	O
receptive	O
field	O
requires	O
bigger	O
kernels	O
or	O
more	O
convolutional	O
layers	O
,	O
which	O
increases	O
computation	B-Metric
and	O
memory	B-Metric
requirements	I-Metric
.	O
	
An	O
alternative	O
would	O
be	O
the	O
use	O
of	O
pooling	B-Method
(	I-Method
)	I-Method
,	O
which	O
however	O
leads	O
to	O
loss	O
of	O
the	O
exact	O
position	O
of	O
the	O
segmented	O
voxel	O
and	O
thus	O
can	O
negatively	O
impact	O
accuracy	B-Metric
.	O
	
In	O
order	O
to	O
incorporate	O
both	O
local	O
and	O
larger	O
contextual	O
information	O
into	O
our	O
3D	B-Method
CNN	I-Method
,	O
we	O
add	O
a	O
second	O
pathway	O
that	O
operates	O
on	O
down	O
-	O
sampled	O
images	O
.	O
	
Thus	O
,	O
our	O
dual	B-Method
pathway	I-Method
3D	I-Method
CNN	I-Method
simultaneously	O
processes	O
the	O
input	O
image	O
at	O
multiple	O
scales	O
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
Higher	O
level	O
features	O
such	O
as	O
the	O
location	O
within	O
the	O
brain	O
are	O
learned	O
in	O
the	O
second	O
pathway	O
,	O
while	O
the	O
detailed	O
local	O
appearance	O
of	O
structures	O
is	O
captured	O
in	O
the	O
first	O
.	O
	
As	O
the	O
two	O
pathways	O
are	O
decoupled	O
in	O
this	O
architecture	O
,	O
arbitrarily	O
large	O
context	O
can	O
be	O
processed	O
by	O
the	O
second	O
pathway	O
by	O
simply	O
adjusting	O
the	O
down	O
-	O
sampling	O
factor	O
.	O
	
The	O
size	O
of	O
the	O
pathways	O
can	O
be	O
independently	O
adjusted	O
according	O
to	O
the	O
computational	B-Metric
capacity	O
and	O
the	O
task	O
at	O
hand	O
,	O
which	O
may	O
require	O
relatively	O
more	O
or	O
less	O
filters	O
focused	O
on	O
the	O
down	O
-	O
sampled	O
context	O
.	O
	
[	O
b	O
]	O
1.0	O
To	O
preserve	O
the	O
capability	O
of	O
dense	O
inference	B-Method
,	O
spatial	O
correspondence	O
of	O
the	O
activations	O
in	O
the	O
FMs	O
of	O
the	O
last	O
convolutional	O
layers	O
of	O
the	O
two	O
pathways	O
,	O
and	O
,	O
should	O
be	O
ensured	O
.	O
	
In	O
networks	B-Method
where	O
only	O
unary	O
kernel	O
strides	O
are	O
used	O
,	O
such	O
as	O
the	O
proposed	O
architecture	O
,	O
this	O
requires	O
that	O
for	O
every	O
shifts	O
of	O
the	O
receptive	O
field	O
over	O
the	O
normal	O
resolution	O
input	O
,	O
only	O
one	O
shift	O
is	O
performed	O
by	O
over	O
the	O
down	O
-	O
sampled	O
input	O
.	O
	
Hence	O
it	O
is	O
required	O
that	O
the	O
dimensions	O
of	O
the	O
FMs	O
in	O
are	O
.	O
	
From	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
,	O
	
the	O
size	O
of	O
the	O
input	O
to	O
the	O
second	O
pathway	O
is	O
and	O
similar	O
is	O
the	O
relation	O
between	O
and	O
.	O
	
These	O
establish	O
the	O
relation	O
between	O
the	O
required	O
dimensions	O
of	O
the	O
input	O
segments	O
from	O
the	O
two	O
resolutions	O
,	O
which	O
can	O
then	O
be	O
extracted	O
centered	O
on	O
the	O
same	O
image	O
location	O
.	O
	
The	O
FMs	O
of	O
are	O
up	O
-	O
sampled	O
to	O
match	O
the	O
dimensions	O
of	O
’s	O
FMs	O
and	O
are	O
then	O
concatenated	O
together	O
.	O
	
We	O
add	O
two	O
more	O
hidden	O
layers	O
for	O
combining	O
the	O
multi	O
-	O
scale	O
features	O
before	O
the	O
final	O
classification	B-Task
,	O
as	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Integration	O
of	O
the	O
multi	B-Task
-	I-Task
scale	I-Task
parallel	I-Task
pathways	I-Task
in	O
architectures	O
with	O
non	O
-	O
unary	O
strides	O
is	O
discussed	O
in	O
[	O
reference	O
]	O
.	O
	
Combining	O
multi	O
-	O
scale	O
features	O
has	O
been	O
found	O
beneficial	O
in	O
other	O
recent	O
works	O
(	O
)	O
,	O
in	O
which	O
whole	O
2D	O
images	O
are	O
processed	O
in	O
the	O
network	O
by	O
applying	O
a	O
few	O
number	O
of	O
convolutions	B-Method
and	O
then	O
down	O
-	O
sampling	O
the	O
FMs	B-Method
for	O
further	O
processing	O
at	O
various	O
scales	O
.	O
	
Our	O
decoupled	O
pathways	O
allow	O
arbitrarily	O
large	O
context	O
to	O
be	O
provided	O
while	O
avoiding	O
the	O
need	O
to	O
load	O
large	O
parts	O
of	O
the	O
3D	O
volume	O
into	O
memory	O
.	O
	
Additionally	O
,	O
our	O
architecture	O
extracts	O
features	O
completely	O
independently	O
from	O
the	O
multiple	O
resolutions	O
.	O
	
This	O
way	O
,	O
the	O
features	O
learned	O
by	O
the	O
first	O
pathway	O
retain	O
finest	O
details	O
,	O
as	O
they	O
are	O
not	O
involved	O
in	O
processing	B-Task
low	I-Task
resolution	I-Task
context	I-Task
.	O
	
subsection	O
:	O
3D	O
Fully	O
Connected	O
CRF	B-Method
for	O
Structured	B-Task
Prediction	I-Task
	
Because	O
neighboring	O
voxels	O
share	O
substantial	O
spatial	O
context	O
,	O
the	O
soft	O
segmentation	B-Task
maps	O
produced	O
by	O
the	O
CNN	B-Method
tend	O
to	O
be	O
smooth	O
,	O
even	O
though	O
neighborhood	O
dependencies	O
are	O
not	O
modeled	O
directly	O
.	O
	
However	O
,	O
local	O
minima	O
in	O
training	B-Method
and	O
noise	O
in	O
the	O
input	O
images	O
can	O
still	O
result	O
in	O
some	O
spurious	O
outputs	O
,	O
with	O
small	O
isolated	O
regions	O
or	O
holes	O
in	O
the	O
predictions	O
.	O
	
We	O
employ	O
a	O
fully	B-Method
connected	I-Method
CRF	I-Method
(	O
)	O
as	O
a	O
post	B-Method
-	I-Method
processing	I-Method
step	I-Method
to	O
achieve	O
more	O
structured	B-Task
predictions	I-Task
.	O
	
As	O
we	O
describe	O
below	O
,	O
this	O
CRF	B-Method
is	O
capable	O
of	O
modeling	O
arbitrarily	B-Task
large	I-Task
voxel	I-Task
-	I-Task
neighborhoods	I-Task
but	O
is	O
also	O
computationally	O
efficient	O
,	O
making	O
it	O
ideal	O
for	O
processing	O
3D	B-Task
multi	I-Task
-	I-Task
modal	I-Task
medical	I-Task
scans	I-Task
.	O
	
For	O
an	O
input	O
image	O
and	O
the	O
label	O
configuration	O
(	O
segmentation	B-Task
)	O
,	O
the	O
Gibbs	O
energy	O
in	O
a	O
CRF	B-Method
model	I-Method
is	O
given	O
by	O
The	O
unary	O
potential	O
is	O
the	O
negative	O
log	O
-	O
likelihood	O
,	O
where	O
in	O
our	O
case	O
is	O
the	O
CNN	B-Method
’s	O
output	O
for	O
voxel	O
.	O
	
In	O
a	O
fully	B-Method
connected	I-Method
CRF	I-Method
,	O
the	O
pairwise	O
potential	O
is	O
of	O
form	O
between	O
any	O
pair	O
of	O
voxels	O
,	O
regardless	O
of	O
their	O
spatial	O
distance	O
.	O
	
The	O
Pott	B-Method
’s	I-Method
Model	I-Method
is	O
commonly	O
used	O
as	O
the	O
label	O
compatibility	O
function	O
,	O
giving	O
.	O
	
The	O
corresponding	O
energy	O
penalty	O
is	O
given	O
by	O
the	O
function	O
,	O
which	O
is	O
defined	O
over	O
an	O
arbitrary	O
feature	O
space	O
,	O
with	O
being	O
the	O
feature	O
vectors	O
of	O
the	O
pair	O
of	O
voxels	O
.	O
	
observed	O
that	O
if	O
the	O
penalty	O
function	O
is	O
defined	O
as	O
a	O
linear	B-Method
combination	I-Method
of	I-Method
Gaussian	I-Method
kernels	I-Method
,	O
,	O
the	O
model	O
lends	O
itself	O
for	O
very	O
efficient	O
inference	B-Method
with	O
mean	B-Method
field	I-Method
approximation	I-Method
,	O
after	O
expressing	O
message	B-Method
passing	I-Method
as	O
convolutions	B-Method
with	O
the	O
Gaussian	B-Method
kernels	I-Method
in	O
the	O
space	O
of	O
the	O
feature	O
vectors	O
.	O
	
We	O
extended	O
the	O
work	O
of	O
the	O
original	O
authors	O
and	O
implemented	O
a	O
3D	B-Method
version	I-Method
of	O
the	O
CRF	B-Method
for	O
processing	B-Task
multi	I-Task
-	I-Task
modal	I-Task
scans	I-Task
.	O
	
We	O
make	O
use	O
of	O
two	O
Gaussian	B-Method
kernels	I-Method
,	O
which	O
operate	O
in	O
the	O
feature	O
space	O
defined	O
by	O
the	O
voxel	O
coordinates	O
and	O
the	O
intensities	O
of	O
the	O
-	O
th	O
modality	O
-	O
channel	O
for	O
voxel	O
.	O
	
The	O
smoothness	O
kernel	O
,	O
,	O
is	O
defined	O
by	O
a	O
diagonal	O
covariance	O
matrix	O
with	O
elements	O
the	O
configurable	O
parameters	O
,	O
one	O
for	O
each	O
axis	O
.	O
	
These	O
parameters	O
express	O
the	O
size	O
and	O
shape	O
of	O
neighborhoods	O
that	O
homogeneous	O
labels	O
are	O
encouraged	O
.	O
	
The	O
appearance	O
kernel	O
is	O
defined	O
similarly	O
.	O
	
The	O
additional	O
parameters	O
can	O
be	O
interpreted	O
as	O
how	O
strongly	O
to	O
enforce	O
homogeneous	O
appearance	O
in	O
the	O
input	O
channels	O
,	O
when	O
voxels	O
in	O
an	O
area	O
spatially	O
defined	O
by	O
are	O
identically	O
labelled	O
.	O
	
Finally	O
,	O
the	O
configurable	O
weights	O
define	O
the	O
relative	O
strength	O
of	O
the	O
two	O
factors	O
.	O
	
section	O
:	O
Analysis	B-Task
of	I-Task
Network	I-Task
Architecture	I-Task
	
In	O
this	O
section	O
we	O
present	O
a	O
series	O
of	O
experiments	O
in	O
order	O
to	O
analyze	O
the	O
impact	O
of	O
each	O
of	O
the	O
main	O
contributions	O
and	O
to	O
justify	O
the	O
choices	O
made	O
in	O
the	O
design	O
of	O
the	O
proposed	O
11	B-Method
-	I-Method
layers	I-Method
,	O
multi	B-Method
-	I-Method
scale	I-Method
3D	I-Method
CNN	I-Method
architecture	I-Method
,	O
referred	O
to	O
as	O
the	O
DeepMedic	B-Method
.	O
	
Starting	O
from	O
the	O
CNN	B-Method
baseline	I-Method
as	O
discussed	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
	
,	O
we	O
first	O
explore	O
the	O
benefit	O
of	O
our	O
proposed	O
dense	O
training	B-Method
scheme	O
(	O
cf	O
.	O
	
Sec	O
.	O
	
[	O
reference	O
]	O
)	O
,	O
then	O
investigate	O
the	O
use	O
of	O
deeper	B-Method
models	I-Method
(	O
cf	O
.	O
	
Sec	O
.	O
	
[	O
reference	O
]	O
)	O
and	O
then	O
evaluate	O
the	O
influence	O
of	O
the	O
multi	O
-	O
scale	O
dual	O
pathway	O
(	O
cf	O
.	O
	
Sec	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
Finally	O
,	O
we	O
compare	O
our	O
method	O
with	O
corresponding	O
2D	B-Method
variants	I-Method
to	O
assess	O
the	O
benefit	O
of	O
processing	B-Task
3D	I-Task
context	I-Task
.	O
	
subsection	O
:	O
Experimental	O
Setting	O
	
The	O
following	O
experiments	O
are	O
conducted	O
using	O
the	O
TBI	O
dataset	O
with	O
61	O
multi	O
-	O
channel	O
MRIs	O
which	O
is	O
described	O
in	O
more	O
detail	O
later	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
.	O
	
Here	O
,	O
the	O
images	O
are	O
randomly	O
split	O
into	O
a	O
validation	O
and	O
training	B-Method
set	O
,	O
with	O
15	O
and	O
46	O
images	O
each	O
.	O
	
The	O
same	O
sets	O
are	O
used	O
in	O
all	O
analyses	O
.	O
	
To	O
monitor	O
the	O
progress	O
of	O
segmentation	B-Task
accuracy	O
during	O
training	B-Method
,	O
we	O
extract	O
10k	O
random	O
patches	O
at	O
regular	O
intervals	O
,	O
with	O
equal	O
numbers	O
extracted	O
from	O
each	O
of	O
the	O
validation	O
images	O
.	O
	
The	O
patches	O
are	O
uniformly	O
sampled	O
from	O
the	O
brain	O
region	O
in	O
order	O
to	O
approximate	O
the	O
true	O
distribution	O
of	O
lesions	O
and	O
healthy	O
tissue	O
.	O
	
Full	O
segmentation	B-Task
of	O
the	O
validation	O
datasets	O
is	O
performed	O
every	O
five	O
epochs	O
and	O
the	O
mean	B-Metric
Dice	I-Metric
similarity	I-Metric
coefficient	I-Metric
(	O
DSC	B-Metric
)	O
is	O
determined	O
.	O
	
Details	O
on	O
the	O
configuration	O
of	O
the	O
networks	B-Method
are	O
provided	O
in	O
[	O
reference	O
]	O
.	O
	
subsection	O
:	O
Effect	O
of	O
Dense	O
Training	B-Method
on	O
Image	B-Task
Segments	I-Task
	
[	O
b	O
]	O
1.0	O
We	O
compare	O
our	O
proposed	O
dense	O
training	B-Method
method	O
with	O
two	O
other	O
commonly	O
used	O
training	B-Method
schemes	O
on	O
the	O
5	B-Method
-	I-Method
layers	I-Method
baseline	I-Method
CNN	I-Method
(	O
see	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
The	O
first	O
common	O
scheme	O
trains	O
on	O
patches	O
extracted	O
uniformly	O
from	O
the	O
brain	O
region	O
,	O
and	O
the	O
second	O
scheme	O
samples	O
patches	O
equally	O
from	O
the	O
lesion	O
and	O
background	O
class	O
.	O
	
We	O
refer	O
to	O
these	O
schemes	O
as	O
P	O
and	O
P	O
.	O
	
The	O
results	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
show	O
a	O
correlation	O
of	O
sensitivity	B-Metric
and	O
specificity	B-Metric
with	O
the	O
percentage	O
of	O
training	B-Method
samples	O
that	O
come	O
from	O
the	O
lesion	O
class	O
.	O
	
P	B-Method
performs	O
poorly	O
because	O
of	O
over	O
-	O
segmentation	B-Task
(	O
high	O
sensitivity	B-Metric
,	O
low	O
specificity	B-Metric
)	O
.	O
	
P	B-Method
has	O
better	O
classification	B-Task
on	O
the	O
background	O
class	O
(	O
high	O
specificity	B-Metric
)	O
,	O
which	O
leads	O
to	O
high	O
mean	B-Metric
voxel	I-Metric
-	I-Metric
wise	I-Metric
accuracy	I-Metric
since	O
the	O
majority	O
corresponds	O
to	O
background	O
,	O
but	O
not	O
particularly	O
high	O
DSC	B-Metric
scores	O
due	O
to	O
under	O
-	O
segmentation	B-Task
(	O
low	O
sensitivity	B-Metric
)	O
.	O
	
To	O
evaluate	O
our	O
dense	O
training	B-Method
scheme	O
,	O
we	O
train	O
multiple	O
models	O
with	O
varying	O
sized	O
image	O
segments	O
,	O
equally	O
sampled	O
from	O
lesions	O
and	O
background	O
.	O
	
The	O
tested	O
sizes	O
of	O
the	O
segments	O
go	O
from	O
upwards	O
to	O
.	O
	
The	O
models	O
are	O
referred	O
to	O
as	O
“	O
S	O
-	O
”	O
,	O
where	O
is	O
the	O
side	O
length	O
of	O
the	O
cubic	O
segments	O
.	O
	
For	O
fair	O
comparison	O
,	O
the	O
batch	O
sizes	O
in	O
all	O
the	O
experiments	O
are	O
adjusted	O
to	O
have	O
a	O
similar	O
memory	O
footprint	O
and	O
lead	O
to	O
similar	O
training	B-Method
times	O
as	O
compared	O
to	O
training	B-Method
on	O
P	O
and	O
P	O
.	O
	
We	O
observe	O
a	O
great	O
performance	B-Metric
increase	O
for	O
model	O
S	O
-	O
over	O
P	O
.	O
	
We	O
account	O
this	O
partly	O
to	O
the	O
efficient	O
increase	O
of	O
the	O
effective	B-Metric
batch	I-Metric
size	I-Metric
(	O
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
)	O
,	O
but	O
also	O
to	O
the	O
altered	O
distribution	O
of	O
training	B-Method
samples	O
.	O
	
As	O
we	O
increase	O
the	O
size	O
of	O
the	O
training	B-Method
segments	O
further	O
,	O
we	O
quickly	O
reach	O
a	O
balance	O
between	O
the	O
sensitivity	B-Metric
of	O
P	O
and	O
the	O
specificity	O
of	O
P	O
,	O
which	O
results	O
in	O
improved	O
segmentation	B-Task
as	O
expressed	O
by	O
the	O
DSC	B-Metric
.	O
	
The	O
segment	O
size	O
is	O
a	O
hyper	O
-	O
parameter	O
in	O
our	O
model	O
.	O
	
We	O
observe	O
that	O
the	O
increase	O
in	O
performance	B-Metric
with	O
increasing	O
segment	O
size	O
quickly	O
levels	O
off	O
,	O
and	O
similar	O
performance	B-Metric
is	O
obtained	O
for	O
a	O
wide	O
range	O
of	O
segment	O
sizes	O
,	O
which	O
allows	O
for	O
easy	O
configuration	O
.	O
	
For	O
the	O
remaining	O
experiments	O
,	O
all	O
models	O
were	O
trained	O
on	O
segments	O
of	O
size	O
.	O
	
subsection	O
:	O
Effect	O
of	O
Deeper	O
Networks	O
	
[	O
b	O
]	O
0.5	O
The	O
5	B-Method
-	I-Method
layers	I-Method
baseline	I-Method
CNN	I-Method
	
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
,	O
here	O
referred	O
to	O
as	O
the	O
“	O
Shallow	B-Method
”	I-Method
model	I-Method
,	O
is	O
extended	O
to	O
9	O
-	O
layers	O
by	O
replacing	O
each	O
convolutional	B-Method
layer	I-Method
that	O
uses	O
kernels	O
with	O
two	O
layers	O
that	O
use	O
kernels	O
	
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
This	O
model	O
is	O
referred	O
to	O
as	O
“	O
Deep	O
”	O
.	O
	
Training	B-Method
the	O
latter	O
,	O
however	O
,	O
utterly	O
fails	O
with	O
the	O
model	O
making	O
only	O
predictions	O
corresponding	O
to	O
the	O
background	O
class	O
.	O
	
This	O
problem	O
is	O
related	O
to	O
the	O
challenge	O
of	O
preserving	O
the	O
signal	O
as	O
it	O
propagates	O
through	O
deep	O
networks	B-Method
and	O
its	O
variance	O
gets	O
multiplied	O
with	O
the	O
variance	O
of	O
the	O
weights	O
,	O
as	O
previously	O
discussed	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
.	O
	
One	O
of	O
the	O
causes	O
is	O
that	O
the	O
weights	O
of	O
both	O
models	O
have	O
been	O
initialized	O
with	O
the	O
commonly	O
used	O
scheme	O
of	O
sampling	O
from	O
the	O
normal	B-Method
distribution	I-Method
(	O
cf	O
.	O
)	O
.	O
	
In	O
comparison	O
,	O
the	O
initialization	B-Method
scheme	I-Method
by	O
,	O
derived	O
for	O
preserving	O
the	O
signal	O
in	O
the	O
initial	O
stage	O
of	O
training	B-Method
,	O
results	O
in	O
higher	O
values	O
and	O
overcomes	O
this	O
problem	O
.	O
	
Further	O
preservation	O
of	O
the	O
signal	O
is	O
obtained	O
by	O
employing	O
Batch	B-Method
Normalization	I-Method
.	O
	
This	O
results	O
in	O
an	O
enhanced	O
9	B-Method
-	I-Method
layers	I-Method
model	I-Method
which	O
we	O
refer	O
to	O
as	O
“	O
Deep	O
+	O
”	O
,	O
and	O
using	O
the	O
same	O
enhancements	O
on	O
the	O
Shallow	B-Method
model	I-Method
yields	O
“	O
Shallow	O
+	O
”	O
.	O
	
The	O
significant	O
performance	B-Metric
improvement	O
of	O
Deep	B-Method
+	I-Method
over	O
Shallow	B-Method
+	I-Method
,	O
as	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
is	O
the	O
result	O
of	O
the	O
greater	O
representational	O
power	O
of	O
the	O
deeper	B-Method
network	I-Method
.	O
	
The	O
two	O
models	O
need	O
similar	O
computational	B-Metric
times	O
,	O
which	O
highlights	O
the	O
benefits	O
of	O
utilizing	O
small	B-Method
kernels	I-Method
in	O
the	O
design	O
of	O
3D	B-Task
CNNs	I-Task
.	O
	
Although	O
the	O
deeper	B-Method
model	I-Method
requires	O
more	O
sequential	O
(	O
layer	B-Method
by	I-Method
layer	I-Method
)	O
computations	O
on	O
the	O
GPU	O
,	O
those	O
are	O
faster	O
due	O
to	O
the	O
smaller	O
kernel	O
size	O
.	O
	
subsection	O
:	O
Effect	O
of	O
the	O
Multi	B-Method
-	I-Method
Scale	I-Method
Dual	I-Method
Pathway	I-Method
	
[	O
b	O
]	O
0.5	O
The	O
final	O
version	O
of	O
the	O
proposed	O
network	B-Method
architecture	I-Method
,	O
referred	O
to	O
as	O
“	O
DeepMedic	B-Method
”	I-Method
,	O
is	O
built	O
by	O
extending	O
the	O
Deep	B-Method
+	I-Method
model	I-Method
with	O
a	O
second	O
convolutional	B-Method
pathway	I-Method
that	O
is	O
identical	O
to	O
the	O
first	O
one	O
.	O
	
Two	O
hidden	O
layers	O
are	O
added	O
for	O
combining	O
the	O
multi	O
-	O
scale	O
features	O
before	O
the	O
classification	B-Method
layer	I-Method
,	O
resulting	O
in	O
a	O
deep	B-Method
network	I-Method
of	I-Method
11	I-Method
-	I-Method
layers	I-Method
(	O
cf	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
The	O
input	O
segments	O
to	O
the	O
second	O
pathway	O
are	O
extracted	O
from	O
the	O
images	O
down	O
-	O
sampled	O
by	O
a	O
factor	O
of	O
three	O
.	O
	
Thus	O
,	O
the	O
network	O
is	O
capable	O
of	O
capturing	O
context	O
in	O
a	O
area	O
of	O
the	O
original	O
image	O
through	O
the	O
receptive	O
field	O
of	O
the	O
lower	B-Method
-	I-Method
resolution	I-Method
pathway	I-Method
,	O
while	O
only	O
doubling	O
the	O
computational	B-Metric
and	O
memory	B-Metric
requirements	I-Metric
over	O
the	O
single	B-Method
pathway	I-Method
CNN	I-Method
.	O
	
In	O
comparison	O
,	O
the	O
most	O
recent	O
2D	B-Method
CNN	I-Method
systems	I-Method
proposed	O
for	O
lesion	O
segmentation	B-Task
(	O
)	O
have	O
a	O
receptive	O
field	O
limited	O
to	O
voxels	O
.	O
	
[	O
b	O
]	O
0.85	O
Figure	O
[	O
reference	O
]	O
shows	O
the	O
improvement	O
DeepMedic	B-Method
achieves	O
over	O
the	O
single	B-Method
pathway	I-Method
model	I-Method
	
Deep	O
	
+	O
.	O
	
In	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
we	O
show	O
two	O
representative	O
visual	O
examples	O
of	O
this	O
improvement	O
when	O
using	O
the	O
multi	B-Method
-	I-Method
scale	I-Method
CNN	I-Method
.	O
	
Finally	O
,	O
we	O
confirm	O
that	O
the	O
performance	B-Metric
increase	O
can	O
be	O
accounted	O
to	O
the	O
additional	O
context	O
and	O
not	O
the	O
additional	O
capacity	O
of	O
DeepMedic	B-Method
.	O
	
To	O
this	O
end	O
,	O
we	O
build	O
a	O
big	O
single	B-Method
-	I-Method
scale	I-Method
model	I-Method
by	O
doubling	O
the	O
FMs	B-Method
at	O
each	O
of	O
the	O
9	B-Method
-	I-Method
layers	I-Method
of	I-Method
Deep	I-Method
+	I-Method
and	O
adding	O
two	O
hidden	O
layers	O
.	O
	
This	O
11	B-Method
-	I-Method
layers	I-Method
deep	I-Method
and	I-Method
wide	I-Method
model	I-Method
,	O
referred	O
to	O
as	O
“	O
BigDeep	B-Method
+	I-Method
”	I-Method
,	O
has	O
the	O
same	O
number	O
of	O
parameters	O
as	O
DeepMedic	B-Method
.	O
	
The	O
performance	B-Metric
of	O
the	O
model	O
is	O
not	O
improved	O
,	O
while	O
showing	O
signs	O
of	O
over	O
-	O
fitting	O
.	O
	
subsection	O
:	O
Processing	B-Task
3D	I-Task
in	O
comparison	O
to	O
2D	O
Context	O
	
Acquired	O
brain	O
MRI	O
scans	O
are	O
often	O
anisotropic	O
.	O
	
Such	O
is	O
the	O
case	O
for	O
most	O
sequences	O
in	O
our	O
TBI	O
dataset	O
,	O
which	O
have	O
been	O
acquired	O
with	O
lower	O
axial	O
resolution	O
,	O
except	O
for	O
the	O
isotropic	B-Method
MPRAGE	I-Method
.	O
	
We	O
perform	O
a	O
series	O
of	O
experiments	O
to	O
investigate	O
the	O
behaviour	O
of	O
2D	O
networks	B-Method
and	O
assess	O
the	O
benefit	O
of	O
processing	B-Task
3D	I-Task
context	I-Task
in	O
this	O
setting	O
.	O
	
DeepMedic	B-Method
can	O
be	O
converted	O
to	O
2D	O
by	O
setting	O
the	O
third	O
dimension	O
of	O
each	O
kernel	O
to	O
one	O
.	O
	
This	O
way	O
only	O
information	O
from	O
the	O
surrounding	O
context	O
on	O
the	O
axial	O
plane	O
influences	O
the	O
classification	B-Task
of	O
each	O
voxel	O
.	O
	
If	O
2D	O
segments	O
are	O
given	O
as	O
input	O
,	O
the	O
dimensionality	O
of	O
the	O
feature	O
maps	O
decreases	O
and	O
	
so	O
does	O
the	O
memory	O
required	O
.	O
	
This	O
allows	O
developing	O
2D	B-Method
variants	I-Method
with	O
increased	O
width	O
,	O
depth	O
and	O
size	O
of	O
training	B-Method
batch	O
with	O
similar	O
requirements	O
as	O
the	O
3D	B-Method
version	I-Method
,	O
which	O
are	O
valid	O
candidates	O
for	O
model	B-Task
selection	I-Task
in	O
practical	O
scenarios	O
.	O
	
We	O
assess	O
various	O
configurations	O
and	O
present	O
some	O
representatives	O
in	O
Table	O
[	O
reference	O
]	O
along	O
with	O
their	O
performance	B-Metric
.	O
	
Best	O
segmentation	B-Task
among	O
investigated	O
2D	B-Method
variants	I-Method
is	O
achieved	O
by	O
a	O
19	O
-	O
layers	O
,	O
multi	B-Method
-	I-Method
scale	I-Method
network	I-Method
,	O
reaching	O
61.5	O
%	O
average	B-Metric
DSC	I-Metric
on	O
the	O
validation	B-Metric
fold	I-Metric
.	O
	
The	O
decline	O
from	O
the	O
66.6	O
%	O
DSC	B-Metric
achieved	O
by	O
the	O
3D	B-Method
version	I-Method
of	O
DeepMedic	B-Method
indicates	O
the	O
importance	O
of	O
processing	O
3D	O
context	O
even	O
in	O
settings	O
where	O
most	O
acquired	O
sequences	O
have	O
low	O
resolution	O
along	O
a	O
certain	O
axis	O
.	O
	
section	O
:	O
Evaluation	O
on	O
Clinical	O
Data	O
	
The	O
proposed	O
system	O
consisting	O
of	O
the	O
DeepMedic	B-Method
CNN	I-Method
architecture	I-Method
,	O
optionally	O
coupled	O
with	O
a	O
fully	B-Method
connected	I-Method
CRF	I-Method
,	O
is	O
evaluated	O
on	O
three	O
lesion	O
segmentation	B-Task
tasks	O
including	O
challenging	O
clinical	O
data	O
from	O
patients	O
with	O
traumatic	O
brain	O
injuries	O
,	O
brain	O
tumors	O
,	O
and	O
ischemic	O
stroke	O
.	O
	
Quantitative	O
evaluation	O
and	O
comparisons	O
with	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
are	O
reported	O
for	O
each	O
of	O
the	O
tasks	O
.	O
	
subsection	O
:	O
Traumatic	O
Brain	O
Injuries	O
	
subsubsection	O
:	O
Material	O
and	O
Pre	O
-	O
Processing	O
	
Sixty	O
-	O
six	O
patients	O
with	O
moderate	O
-	O
to	O
-	O
severe	O
TBI	O
who	O
required	O
admission	O
to	O
the	O
Neurosciences	O
Critical	O
Care	O
Unit	O
at	O
Addenbrooke	O
’s	O
Hospital	O
,	O
Cambridge	O
,	O
UK	O
,	O
underwent	O
imaging	O
using	O
a	O
3	B-Method
-	I-Method
Tesla	I-Method
Siemens	I-Method
Magnetom	I-Method
TIM	I-Method
Trio	I-Method
within	O
the	O
first	O
week	O
of	O
injury	O
.	O
	
Ethical	O
approval	O
was	O
obtained	O
from	O
the	O
Local	O
Research	O
Ethics	O
Committee	O
(	O
LREC	O
97	O
/	O
290	O
)	O
and	O
written	O
assent	O
via	O
consultee	O
agreement	O
was	O
obtained	O
for	O
all	O
patients	O
.	O
	
The	O
structural	B-Method
MRI	I-Method
sequences	I-Method
that	O
are	O
used	O
in	O
this	O
work	O
are	O
isotropic	O
MPRAGE	O
(	O
1	O
1	O
1	O
)	O
,	O
axial	O
FLAIR	O
,	O
T2	O
and	O
Proton	O
Density	O
(	O
PD	O
)	O
(	O
0.7	O
0.7	O
5	O
)	O
,	O
and	O
Gradient	B-Method
-	I-Method
Echo	I-Method
(	O
GE	B-Method
)	O
(	O
0.86	O
0.86	O
5	O
)	O
.	O
	
All	O
visible	O
lesions	O
were	O
manually	O
annotated	O
on	O
the	O
FLAIR	O
and	O
GE	O
sequences	O
with	O
separate	O
labeling	O
for	O
each	O
lesion	O
type	O
.	O
	
In	O
nine	O
patients	O
the	O
presence	O
of	O
hyperintense	O
white	O
matter	O
lesions	O
that	O
were	O
felt	O
to	O
be	O
chronic	O
in	O
nature	O
were	O
also	O
annotated	O
.	O
	
Artifacts	O
,	O
for	O
example	O
,	O
signal	O
loss	O
secondary	O
to	O
intraparenchymal	O
pressure	O
probes	O
,	O
were	O
also	O
noted	O
.	O
	
For	O
the	O
purpose	O
of	O
this	O
study	O
we	O
focus	O
on	O
binary	O
segmentation	B-Task
of	O
all	O
abnormalities	O
within	O
the	O
brain	O
tissue	O
.	O
	
Thus	O
,	O
we	O
merged	O
all	O
classes	O
that	O
correspond	O
to	O
intra	O
-	O
cerebral	O
abnormalities	O
into	O
a	O
single	O
“	O
lesion	O
”	O
label	O
.	O
	
Extra	O
-	O
cerebral	O
pathologies	O
such	O
as	O
epidural	O
and	O
subdural	O
hematoma	O
were	O
treated	O
as	O
background	O
.	O
	
We	O
excluded	O
two	O
datasets	O
because	O
of	O
corrupted	O
FLAIR	O
images	O
,	O
two	O
cases	O
because	O
no	O
lesions	O
were	O
found	O
and	O
one	O
case	O
because	O
of	O
a	O
major	O
scanning	O
artifact	O
corrupting	O
the	O
images	O
.	O
	
This	O
results	O
in	O
a	O
total	O
of	O
61	O
cases	O
used	O
for	O
quantitative	B-Task
evaluation	I-Task
.	O
	
Brain	O
masks	O
were	O
obtained	O
using	O
the	O
ROBEX	B-Method
tool	I-Method
(	O
)	O
.	O
	
All	O
images	O
were	O
resampled	O
to	O
an	O
isotropic	O
resolution	O
,	O
with	O
dimensions	O
193	O
229	O
193	O
and	O
affinely	O
registered	O
(	O
)	O
to	O
MNI	O
space	O
using	O
the	O
atlas	O
by	O
.	O
	
No	O
bias	B-Method
field	I-Method
correction	I-Method
was	O
used	O
as	O
preliminary	O
results	O
showed	O
that	O
this	O
can	O
negatively	O
affect	O
lesion	O
appearance	O
.	O
	
Image	O
intensities	O
were	O
normalized	O
to	O
have	O
zero	O
-	O
mean	O
and	O
unit	O
variance	O
,	O
as	O
it	O
has	O
been	O
reported	O
that	O
this	O
improves	O
CNN	B-Task
results	O
(	O
)	O
.	O
	
subsubsection	O
:	O
Experimental	O
Setting	O
	
Network	B-Method
configuration	I-Method
and	O
training	B-Method
:	O
The	O
network	B-Method
architecture	I-Method
corresponds	O
to	O
the	O
one	O
described	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
,	O
i.e.	O
a	O
dual	B-Method
-	I-Method
pathway	I-Method
,	I-Method
11	I-Method
-	I-Method
layers	I-Method
deep	I-Method
CNN	I-Method
.	O
	
The	O
training	B-Method
data	O
is	O
augmented	O
by	O
adding	O
images	O
reflected	O
along	O
the	O
sagittal	O
axis	O
.	O
	
To	O
make	O
the	O
network	O
invariant	O
to	O
absolute	O
intensities	O
we	O
also	O
shift	O
the	O
intensities	O
of	O
each	O
MR	O
channel	O
of	O
every	O
training	B-Method
segment	O
by	O
.	O
is	O
sampled	O
for	O
every	O
segment	O
from	O
and	O
is	O
the	O
standard	O
deviation	O
of	O
intensities	O
under	O
the	O
brain	O
mask	O
in	O
the	O
corresponding	O
image	O
.	O
	
The	O
network	O
is	O
regularized	O
using	O
dropout	B-Method
(	I-Method
)	O
with	O
a	O
rate	O
of	O
2	O
%	O
on	O
all	O
convolutional	O
layers	O
,	O
which	O
is	O
in	O
addition	O
to	O
a	O
50	O
%	O
rate	O
used	O
on	O
the	O
last	O
two	O
layers	O
.	O
	
The	O
network	O
is	O
evaluated	O
with	O
5	B-Method
-	I-Method
fold	I-Method
cross	I-Method
-	I-Method
validation	I-Method
on	O
the	O
61	O
subjects	O
.	O
	
CRF	B-Method
configuration	I-Method
:	O
	
The	O
parameters	O
of	O
the	O
fully	B-Method
connected	I-Method
CRF	I-Method
are	O
determined	O
in	O
a	O
configuration	O
experiment	O
using	O
random	B-Method
-	I-Method
search	I-Method
and	O
15	O
randomly	O
selected	O
subjects	O
from	O
the	O
TBI	O
database	O
with	O
predictions	O
from	O
a	O
preliminary	O
version	O
of	O
the	O
corresponding	O
model	O
.	O
	
The	O
15	O
subjects	O
are	O
reshuffled	O
into	O
the	O
5	O
-	O
folds	O
used	O
for	O
subsequent	O
evaluation	O
.	O
	
Random	B-Method
Forest	I-Method
baseline	I-Method
	
:	O
We	O
have	O
done	O
our	O
best	O
to	O
set	O
up	O
a	O
competitive	O
baseline	O
for	O
comparison	O
.	O
	
We	O
employ	O
a	O
context	B-Method
-	I-Method
sensitive	I-Method
Random	I-Method
Forest	I-Method
,	O
similar	O
to	O
the	O
model	O
presented	O
by	O
for	O
brain	B-Task
tumors	I-Task
except	O
that	O
we	O
apply	O
the	O
forest	O
to	O
the	O
MR	O
images	O
without	O
additional	O
tissue	O
specific	O
priors	O
.	O
	
We	O
train	O
a	O
forest	B-Method
with	O
50	O
trees	O
and	O
maximum	O
depth	O
of	O
30	O
.	O
	
Larger	O
size	O
did	O
not	O
improve	O
results	O
.	O
	
Training	B-Method
data	O
points	O
are	O
approximately	O
equally	O
sampled	O
from	O
lesion	O
and	O
background	O
classes	O
,	O
with	O
the	O
optimal	O
balance	O
empirically	O
chosen	O
.	O
	
Two	O
hundred	O
randomized	O
cross	O
-	O
channel	O
box	O
features	O
are	O
evaluated	O
at	O
each	O
split	O
node	O
with	O
maximum	O
offsets	O
and	O
box	O
sizes	O
of	O
20	O
mm	O
.	O
	
The	O
same	O
folds	O
of	O
training	B-Method
and	O
test	O
sets	O
are	O
used	O
as	O
for	O
our	O
CNN	B-Method
approach	I-Method
.	O
	
subsubsection	O
:	O
Results	O
	
Table	O
[	O
reference	O
]	O
summarizes	O
the	O
results	O
on	O
TBI	O
.	O
	
Our	O
CNN	B-Method
significantly	O
outperforms	O
the	O
Random	B-Method
Forest	I-Method
baseline	I-Method
,	O
while	O
the	O
relatively	O
overall	O
low	O
DSC	B-Metric
values	I-Metric
indicate	O
the	O
difficulty	O
of	O
the	O
task	O
.	O
	
Due	O
to	O
randomness	O
during	O
training	B-Method
the	O
local	O
minima	O
where	O
a	O
network	O
converges	O
are	O
different	O
between	O
training	B-Method
sessions	O
and	O
some	O
errors	O
they	O
produce	O
differ	O
(	O
)	O
.	O
	
To	O
clear	O
the	O
unbiased	O
errors	O
of	O
the	O
network	O
we	O
form	O
an	O
ensemble	O
of	O
three	O
similar	O
networks	B-Method
,	O
aggregating	O
their	O
output	O
by	O
averaging	B-Method
.	O
	
This	O
ensemble	O
yields	O
better	O
performance	B-Metric
in	O
all	O
metrics	O
but	O
also	O
allows	O
us	O
to	O
investigate	O
the	O
behaviour	O
of	O
our	O
network	O
focusing	O
only	O
on	O
the	O
biased	O
errors	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
the	O
DSC	B-Metric
obtained	O
by	O
the	O
ensemble	O
on	O
each	O
subject	O
in	O
relation	O
to	O
the	O
manually	O
segmented	O
and	O
predicted	O
lesion	O
volume	O
.	O
	
The	O
network	O
is	O
capable	O
of	O
segmenting	B-Task
cases	I-Task
with	O
very	O
small	O
lesions	O
,	O
although	O
,	O
performance	B-Metric
is	O
less	O
robust	O
in	O
these	O
cases	O
as	O
even	O
small	O
errors	O
have	O
large	O
influence	O
on	O
the	O
DSC	B-Metric
metric	I-Metric
.	O
	
Investigation	O
of	O
the	O
predicted	O
lesion	O
volume	O
,	O
which	O
is	O
an	O
important	O
biomarker	O
for	O
prognostication	B-Task
,	O
shows	O
that	O
the	O
network	O
is	O
neither	O
biased	O
towards	O
the	O
lesion	O
nor	O
background	O
class	O
,	O
with	O
promising	O
results	O
even	O
on	O
cases	O
with	O
very	O
small	O
lesions	O
.	O
	
Furthermore	O
,	O
we	O
separately	O
evaluate	O
the	O
influence	O
of	O
the	O
post	B-Method
-	I-Method
processing	I-Method
with	O
the	O
fully	B-Method
connected	I-Method
CRF	I-Method
.	O
	
As	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
,	O
the	O
CRF	B-Method
yields	O
improvements	O
over	O
all	O
classifiers	B-Method
.	O
	
Effects	O
are	O
more	O
prominent	O
when	O
the	O
performance	B-Metric
of	O
the	O
primary	O
segmenter	O
degrades	O
,	O
which	O
shows	O
the	O
robustness	O
of	O
this	O
regulariser	B-Method
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
three	O
representative	O
cases	O
.	O
	
[	O
b	O
]	O
1.0	O
[	O
b	O
]	O
1.0	O
	
subsection	O
:	O
Brain	B-Task
Tumor	I-Task
Segmentation	I-Task
	
subsubsection	O
:	O
Material	O
and	O
Pre	B-Task
-	I-Task
Processing	I-Task
	
For	O
brain	B-Task
tumors	I-Task
,	O
we	O
evaluate	O
our	O
system	O
on	O
the	O
data	O
from	O
the	O
2015	B-Material
Brain	I-Material
Tumor	I-Material
Segmentation	I-Material
Challenge	I-Material
(	O
BRATS	B-Material
)	I-Material
(	O
)	O
.	O
	
The	O
training	B-Method
set	O
consists	O
of	O
220	O
cases	O
with	O
high	O
grade	O
(	O
HG	O
)	O
and	O
54	O
cases	O
with	O
low	O
grade	O
(	O
LG	O
)	O
glioma	O
for	O
which	O
corresponding	O
reference	B-Method
segmentations	I-Method
are	O
provided	O
.	O
	
The	O
segmentations	B-Task
include	O
the	O
following	O
tumor	O
tissue	O
classes	O
:	O
1	O
)	O
necrotic	O
core	O
,	O
2	O
)	O
edema	O
,	O
3	O
)	O
non	O
-	O
enhancing	O
and	O
4	O
)	O
enhancing	O
core	O
.	O
	
The	O
test	O
set	O
consists	O
of	O
110	O
cases	O
of	O
both	O
HG	O
and	O
LG	O
	
but	O
the	O
grade	O
is	O
not	O
revealed	O
.	O
	
Reference	B-Method
segmentations	I-Method
for	O
the	O
test	O
set	O
are	O
hidden	O
and	O
evaluation	O
is	O
carried	O
out	O
via	O
an	O
online	B-Method
system	I-Method
.	O
	
For	O
evaluation	O
,	O
the	O
four	O
predicted	O
labels	O
are	O
merged	O
into	O
different	O
sets	O
of	O
whole	O
tumor	O
(	O
all	O
four	O
classes	O
)	O
,	O
the	O
core	O
(	O
classes	O
1	O
,	O
3	O
,	O
4	O
)	O
,	O
and	O
the	O
enhancing	O
tumor	O
(	O
class	O
4	O
)	O
.	O
	
For	O
each	O
subject	O
,	O
four	O
MRI	O
sequences	O
are	O
available	O
,	O
FLAIR	O
,	O
T1	O
,	O
T1	O
-	O
contrast	O
and	O
T2	O
.	O
	
The	O
datasets	O
are	O
pre	O
-	O
processed	O
by	O
the	O
organizers	O
and	O
provided	O
as	O
skull	O
-	O
stripped	O
,	O
registered	O
to	O
a	O
common	O
space	O
and	O
resampled	O
to	O
isotropic	O
resolution	O
.	O
	
Dimensions	O
of	O
each	O
volume	O
are	O
240	O
240	O
155	O
.	O
	
We	O
add	O
minimal	O
pre	B-Method
-	I-Method
processing	I-Method
of	O
normalizing	O
the	O
brain	O
-	O
tissue	O
intensities	O
of	O
each	O
sequence	O
to	O
have	O
zero	O
-	O
mean	O
and	O
unit	O
variance	O
.	O
	
subsubsection	O
:	O
Experimental	O
Setting	O
	
Network	B-Method
configuration	I-Method
and	O
training	B-Method
:	O
We	O
modify	O
the	O
DeepMedic	B-Method
architecture	I-Method
to	O
handle	O
multi	B-Task
-	I-Task
class	I-Task
problems	I-Task
by	O
extending	O
the	O
classification	B-Method
layer	I-Method
to	O
five	O
feature	O
maps	O
(	O
four	O
tumor	O
classes	O
plus	O
background	O
)	O
.	O
	
The	O
rest	O
of	O
the	O
configuration	O
remains	O
unchanged	O
.	O
	
We	O
enrich	O
the	O
dataset	O
with	O
sagittal	O
reflections	O
.	O
	
Opposite	O
to	O
the	O
experiments	O
on	O
TBI	O
,	O
we	O
do	O
not	O
employ	O
the	O
intensity	B-Method
perturbation	I-Method
and	O
dropout	B-Method
on	O
convolutional	B-Method
layers	I-Method
,	O
because	O
the	O
network	O
should	O
not	O
require	O
as	O
much	O
regularisation	O
with	O
this	O
large	O
database	O
.	O
	
The	O
network	O
is	O
trained	O
on	O
image	O
segments	O
extracted	O
with	O
equal	O
probability	O
centred	O
on	O
the	O
whole	O
tumor	O
and	O
healthy	O
tissue	O
.	O
	
The	O
distribution	O
of	O
the	O
classes	O
captured	O
by	O
our	O
training	B-Method
scheme	O
is	O
provided	O
in	O
[	O
reference	O
]	O
.	O
	
To	O
examine	O
our	O
network	O
’s	O
behaviour	O
,	O
we	O
first	O
evaluate	O
it	O
on	O
the	O
training	B-Method
data	O
of	O
the	O
challenge	O
.	O
	
For	O
this	O
,	O
we	O
run	O
a	O
5	B-Method
-	I-Method
fold	I-Method
cross	I-Method
validation	I-Method
where	O
each	O
fold	O
contains	O
both	O
HG	O
and	O
LG	O
images	O
.	O
	
We	O
then	O
retrain	O
the	O
network	O
using	O
all	O
training	B-Method
images	O
,	O
before	O
applying	O
it	O
on	O
the	O
test	O
data	O
.	O
	
CRF	B-Method
configuration	I-Method
:	O
	
For	O
the	O
multi	B-Task
-	I-Task
class	I-Task
problem	I-Task
it	O
is	O
challenging	O
to	O
find	O
a	O
global	O
set	O
of	O
parameters	O
for	O
the	O
CRF	B-Method
which	O
can	O
consistently	O
improve	O
the	O
segmentation	B-Task
of	O
all	O
classes	O
.	O
	
So	O
instead	O
we	O
merge	O
the	O
four	O
predicted	O
probability	O
maps	O
into	O
a	O
single	O
“	O
whole	O
tumor	O
”	O
map	O
for	O
CRF	B-Method
post	O
-	O
processing	O
.	O
	
The	O
CRF	B-Method
then	O
only	O
refines	O
the	O
boundaries	O
between	O
tumor	O
and	O
background	O
and	O
additionally	O
removes	O
isolated	O
false	O
positives	O
.	O
	
Similarly	O
to	O
the	O
experiments	O
on	O
TBI	O
,	O
the	O
CRF	B-Method
is	O
configured	O
on	O
a	O
random	O
subset	O
of	O
44	O
HG	O
and	O
18	O
LG	O
training	B-Method
images	O
,	O
which	O
are	O
then	O
reshuffled	O
into	O
the	O
subsequent	O
5	B-Method
-	I-Method
fold	I-Method
cross	I-Method
validation	I-Method
.	O
	
subsubsection	O
:	O
Results	O
	
Quantitative	O
results	O
from	O
the	O
application	O
of	O
the	O
DeepMedic	B-Method
,	O
the	O
CRF	B-Method
and	O
an	O
ensemble	O
of	O
three	O
similar	O
networks	B-Method
on	O
the	O
training	B-Method
data	O
are	O
presented	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
The	O
latter	O
two	O
offer	O
an	O
improvement	O
,	O
albeit	O
fairly	O
small	O
since	O
the	O
performance	B-Metric
of	O
DeepMedic	B-Method
is	O
already	O
rather	O
high	O
in	O
this	O
task	O
.	O
	
Also	O
shown	O
are	O
results	O
from	O
previous	O
works	O
,	O
as	O
reported	O
on	O
the	O
online	B-Task
evaluation	I-Task
platform	I-Task
.	O
	
Various	O
settings	O
may	O
vary	O
among	O
submissions	O
,	O
such	O
as	O
the	O
pre	B-Method
-	I-Method
processing	I-Method
pipeline	O
or	O
the	O
number	O
of	O
folds	O
used	O
for	O
cross	B-Method
-	I-Method
validation	I-Method
.	O
	
Still	O
it	O
appears	O
that	O
our	O
system	O
performs	O
favourably	O
compared	O
to	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
,	O
including	O
the	O
semi	B-Method
-	I-Method
automatic	I-Method
system	I-Method
of	O
(	O
bakas1	O
)	O
who	O
won	O
the	O
latest	O
challenge	O
and	O
the	O
method	O
of	O
(	O
peres1	O
)	O
,	O
which	O
is	O
based	O
on	O
grade	B-Method
-	I-Method
specific	I-Method
2D	I-Method
CNNs	I-Method
and	O
requires	O
visual	O
inspection	O
of	O
the	O
tumor	O
and	O
identification	O
of	O
the	O
grade	O
by	O
the	O
user	O
prior	O
to	O
segmentation	B-Task
.	O
	
Examples	O
of	O
segmentations	B-Task
obtained	O
with	O
our	O
method	O
are	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
DeepMedic	B-Method
behaves	O
very	O
well	O
in	O
preserving	O
the	O
hierarchical	O
structure	O
of	O
the	O
tumor	O
,	O
which	O
we	O
account	O
to	O
the	O
large	O
context	O
processed	O
by	O
our	O
multi	B-Method
-	I-Method
scale	I-Method
network	I-Method
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
results	O
of	O
our	O
method	O
on	O
the	O
BRATS	B-Material
test	I-Material
data	I-Material
.	O
	
Results	O
of	O
other	O
submissions	O
are	O
not	O
accessible	O
.	O
	
The	O
decrease	O
in	O
performance	B-Metric
is	O
possibly	O
due	O
to	O
the	O
the	O
inclusion	O
of	O
test	O
images	O
that	O
vary	O
significantly	O
from	O
the	O
training	B-Method
data	O
,	O
such	O
as	O
cases	O
acquired	O
in	O
clinical	O
centers	O
that	O
did	O
not	O
provide	O
any	O
of	O
the	O
training	B-Method
images	O
,	O
something	O
that	O
was	O
confirmed	O
by	O
the	O
organisers	O
.	O
	
Note	O
that	O
performance	B-Metric
gains	O
obtained	O
with	O
the	O
CRF	B-Method
are	O
larger	O
in	O
this	O
case	O
.	O
	
This	O
indicates	O
not	O
only	O
that	O
its	O
configuration	O
has	O
not	O
overfitted	O
to	O
the	O
training	B-Method
database	O
but	O
also	O
that	O
the	O
CRF	B-Method
is	O
robust	O
to	O
factors	O
of	O
variation	O
between	O
acquisition	O
sites	O
,	O
which	O
complements	O
nicely	O
the	O
more	O
sensitive	O
CNN	B-Method
.	O
	
[	O
b	O
]	O
1.0	O
	
subsection	O
:	O
Ischemic	B-Task
Stroke	I-Task
Lesion	I-Task
Segmentation	I-Task
	
subsubsection	O
:	O
Material	O
and	O
Pre	O
-	O
Processing	O
	
We	O
participated	O
in	O
the	O
2015	O
Ischemic	B-Task
Stroke	I-Task
Lesion	I-Task
Segmentation	I-Task
(	I-Task
ISLES	I-Task
)	I-Task
challenge	I-Task
,	O
where	O
our	O
system	O
achieved	O
the	O
best	O
results	O
among	O
all	O
participants	O
on	O
sub	B-Task
-	I-Task
acute	I-Task
ischemic	I-Task
stroke	I-Task
lesions	I-Task
(	O
)	O
.	O
	
In	O
the	O
training	B-Method
phase	O
of	O
the	O
challenge	O
,	O
28	O
datasets	O
have	O
been	O
made	O
available	O
,	O
along	O
with	O
manual	O
segmentations	O
.	O
	
Each	O
dataset	O
included	O
T1	O
,	O
T1	O
-	O
contrast	O
,	O
FLAIR	O
and	O
DWI	O
sequences	O
.	O
	
All	O
images	O
were	O
provided	O
as	O
skull	O
-	O
stripped	O
and	O
resampled	O
to	O
isotropic	O
voxel	O
resolution	O
.	O
	
Each	O
volume	O
is	O
of	O
size	O
230	O
230	O
154	O
.	O
	
In	O
the	O
testing	O
stage	O
,	O
teams	O
were	O
provided	O
with	O
36	O
datasets	O
for	O
evaluation	O
.	O
	
The	O
test	O
data	O
were	O
acquired	O
in	O
two	O
clinical	O
centers	O
,	O
with	O
one	O
of	O
them	O
being	O
the	O
same	O
that	O
provided	O
all	O
training	B-Method
images	O
.	O
	
Corresponding	O
expert	B-Method
segmentations	I-Method
were	O
hidden	O
and	O
results	O
had	O
to	O
be	O
submitted	O
to	O
an	O
online	B-Method
evaluation	I-Method
platform	I-Method
.	O
	
Similar	O
to	O
BRATS	B-Material
,	O
the	O
only	O
pre	B-Method
-	I-Method
processing	I-Method
that	O
we	O
applied	O
is	O
the	O
normalization	B-Method
of	O
each	O
image	O
to	O
the	O
zero	O
-	O
mean	O
and	O
unit	O
variance	O
.	O
	
subsubsection	O
:	O
Experimental	O
Setting	O
	
Network	B-Method
Configuration	I-Method
and	O
Training	B-Method
:	O
	
The	O
configuration	O
of	O
the	O
network	O
employed	O
is	O
described	O
in	O
.	O
	
The	O
main	O
difference	O
with	O
the	O
configuration	O
used	O
for	O
TBI	O
and	O
tumors	O
as	O
employed	O
above	O
is	O
the	O
relatively	O
smaller	O
number	O
of	O
FMs	O
in	O
the	O
low	O
-	O
resolution	O
pathway	O
.	O
	
This	O
choice	O
should	O
not	O
significantly	O
influence	O
accuracy	B-Metric
on	O
the	O
generally	O
small	O
SISS	O
lesions	O
but	O
it	O
allowed	O
us	O
to	O
lower	O
the	O
computational	B-Metric
cost	O
.	O
	
Similar	O
to	O
the	O
other	O
experiments	O
,	O
we	O
evaluate	O
our	O
network	O
with	O
a	O
5	B-Method
-	I-Method
fold	I-Method
cross	I-Method
validation	I-Method
on	O
the	O
training	B-Method
datasets	O
.	O
	
We	O
use	O
data	B-Method
augmentation	I-Method
with	O
sagittal	O
reflections	O
.	O
	
For	O
the	O
testing	O
phase	O
of	O
the	O
challenge	O
,	O
we	O
trained	O
an	O
ensemble	O
of	O
three	O
networks	B-Method
on	O
all	O
training	B-Method
cases	O
and	O
aggregate	O
their	O
predictions	O
by	O
averaging	O
.	O
	
CRF	B-Method
configuration	I-Method
:	O
The	O
parameters	O
of	O
the	O
CRF	B-Method
were	O
configured	O
via	O
a	O
random	B-Method
search	I-Method
on	O
the	O
whole	O
training	B-Method
dataset	O
.	O
	
subsubsection	O
:	O
Results	O
	
The	O
performance	B-Metric
of	O
our	O
system	O
on	O
the	O
training	B-Method
data	O
is	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Significant	O
improvement	O
is	O
achieved	O
by	O
the	O
structural	B-Method
regularisation	I-Method
offered	O
by	O
the	O
CRF	B-Method
,	O
although	O
it	O
could	O
be	O
partially	O
accounted	O
for	O
by	O
overfitting	O
the	O
training	B-Method
data	O
during	O
the	O
CRF	B-Method
’s	I-Method
configuration	I-Method
.	O
	
Examples	O
for	O
visual	B-Task
inspection	I-Task
are	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
For	O
the	O
testing	O
phase	O
of	O
the	O
challenge	O
we	O
formed	O
an	O
ensemble	O
of	O
three	O
networks	B-Method
,	O
coupled	O
with	O
the	O
fully	B-Method
connected	I-Method
CRF	I-Method
.	O
	
Our	O
submission	O
ranked	O
first	O
,	O
indicating	O
superior	O
performance	B-Metric
on	O
this	O
challenging	O
task	O
among	O
14	O
submissions	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
our	O
results	O
,	O
along	O
with	O
the	O
other	O
two	O
top	O
entries	O
(	O
)	O
.	O
	
Among	O
the	O
other	O
participating	O
methods	O
was	O
the	O
CNN	B-Method
of	I-Method
with	O
3	B-Method
layers	I-Method
of	I-Method
2D	I-Method
convolutions	I-Method
.	O
	
That	O
method	O
perfomed	O
less	O
well	O
on	O
this	O
challenging	O
task	O
(	O
)	O
.	O
	
This	O
points	O
out	O
the	O
advantage	O
offered	O
by	O
3D	O
context	O
,	O
the	O
large	O
field	O
of	O
view	O
of	O
DeepMedic	B-Method
thanks	O
to	O
multi	B-Method
-	I-Method
scale	I-Method
processing	I-Method
and	O
the	O
representational	O
power	O
of	O
deeper	O
networks	B-Method
.	O
	
It	O
is	O
important	O
to	O
note	O
the	O
decrease	O
of	O
performance	B-Metric
in	O
comparison	O
to	O
the	O
training	B-Method
set	O
.	O
	
All	O
methods	O
performed	O
worse	O
on	O
the	O
data	O
coming	O
from	O
the	O
second	O
clinical	O
center	O
,	O
including	O
the	O
method	O
of	O
that	O
is	O
not	O
machine	B-Method
-	I-Method
learning	I-Method
based	I-Method
.	O
	
This	O
highlights	O
a	O
general	O
difficulty	O
with	O
current	O
approaches	O
when	O
applied	O
on	O
multi	O
-	O
center	O
data	O
.	O
	
[	O
b	O
]	O
1.0	O
	
subsection	O
:	O
Implementation	O
Details	O
	
Our	O
CNN	B-Method
is	O
implemented	O
using	O
the	O
Theano	B-Method
library	I-Method
(	O
)	O
.	O
	
Each	O
training	B-Method
session	O
requires	O
approximately	O
one	O
day	O
on	O
an	O
NVIDIA	B-Method
GTX	I-Method
Titan	I-Method
X	I-Method
GPU	I-Method
using	O
cuDNN	B-Method
v5.0	I-Method
.	O
	
The	O
efficient	O
architecture	O
of	O
DeepMedic	B-Method
also	O
allows	O
models	O
to	O
be	O
trained	O
on	O
GPUs	B-Method
with	O
only	O
3	O
GB	O
of	O
memory	O
.	O
	
Note	O
that	O
although	O
dimensions	O
of	O
the	O
volumes	O
in	O
the	O
processed	O
databases	O
do	O
not	O
allow	O
dense	O
training	B-Method
on	O
whole	O
volumes	O
for	O
this	O
size	O
of	O
network	O
,	O
dense	O
inference	B-Method
on	O
a	O
whole	O
volume	O
is	O
still	O
possible	O
,	O
as	O
it	O
requires	O
only	O
a	O
forward	O
-	O
pass	O
and	O
thus	O
less	O
memory	O
.	O
	
In	O
this	O
fashion	O
segmentation	B-Task
of	O
a	O
volume	O
takes	O
less	O
than	O
30	O
seconds	O
but	O
requires	O
12	O
GB	O
of	O
GPU	O
memory	O
.	O
	
Tiling	O
the	O
volume	O
into	O
multiple	O
segments	O
of	O
size	O
allows	O
inference	B-Method
on	O
3	O
GB	O
GPUs	O
in	O
less	O
than	O
three	O
minutes	O
.	O
	
Our	O
3D	O
fully	B-Method
connected	I-Method
CRF	I-Method
is	O
implemented	O
by	O
extending	O
the	O
original	O
source	O
code	O
by	O
.	O
	
A	O
CPU	B-Method
implementation	I-Method
is	O
fast	O
,	O
capable	O
of	O
processing	O
a	O
five	B-Task
-	I-Task
channel	I-Task
brain	I-Task
scan	I-Task
in	O
under	O
three	O
minutes	O
.	O
	
Further	O
speed	O
-	O
up	O
could	O
be	O
achieved	O
with	O
a	O
GPU	B-Method
implementation	I-Method
,	O
but	O
was	O
not	O
found	O
necessary	O
in	O
the	O
scope	O
of	O
this	O
work	O
.	O
	
section	O
:	O
Discussion	O
and	O
Conclusion	O
	
We	O
have	O
presented	O
DeepMedic	B-Method
,	O
a	O
3D	B-Method
CNN	I-Method
architecture	I-Method
for	O
automatic	O
lesion	O
segmentation	B-Task
that	O
surpasses	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
on	O
challenging	O
data	O
.	O
	
The	O
proposed	O
novel	O
training	B-Method
scheme	O
is	O
not	O
only	O
computationally	O
efficient	O
but	O
also	O
offers	O
an	O
adaptive	O
way	O
of	O
partially	O
alleviating	O
the	O
inherent	O
class	O
-	O
imbalance	O
of	O
segmentation	B-Task
problems	O
.	O
	
We	O
analyzed	O
the	O
benefits	O
of	O
using	O
small	B-Method
convolutional	I-Method
kernels	I-Method
in	O
3D	B-Method
CNNs	I-Method
,	O
which	O
allowed	O
us	O
to	O
develop	O
a	O
deeper	O
and	O
thus	O
more	O
discriminative	B-Method
network	I-Method
,	O
without	O
increasing	O
the	O
computational	B-Metric
cost	O
and	O
number	O
of	O
trainable	O
parameters	O
.	O
	
We	O
discussed	O
the	O
challenges	O
of	O
training	B-Method
deep	O
neural	O
networks	B-Method
and	O
the	O
adopted	O
solutions	O
from	O
the	O
latest	O
advances	O
in	O
deep	B-Method
learning	I-Method
.	O
	
Furthermore	O
,	O
we	O
proposed	O
an	O
efficient	O
solution	O
for	O
processing	B-Task
large	I-Task
image	I-Task
context	I-Task
by	O
the	O
use	O
of	O
parallel	B-Method
convolutional	I-Method
pathways	I-Method
for	O
multi	B-Task
-	I-Task
scale	I-Task
processing	I-Task
,	O
alleviating	O
one	O
of	O
the	O
main	O
computational	B-Metric
limitations	O
of	O
previous	O
3D	B-Method
CNNs	I-Method
.	O
	
Finally	O
,	O
we	O
presented	O
the	O
first	O
application	O
of	O
a	O
3D	O
fully	B-Method
connected	I-Method
CRF	I-Method
on	O
medical	O
data	O
,	O
employed	O
as	O
a	O
post	O
-	O
processing	O
step	O
to	O
refine	O
the	O
network	O
	
’s	O
output	O
,	O
a	O
method	O
that	O
has	O
also	O
been	O
shown	O
promising	O
for	O
processing	O
2D	O
natural	O
images	O
(	O
)	O
.	O
	
The	O
design	O
of	O
the	O
proposed	O
system	O
is	O
well	O
suited	O
for	O
processing	O
medical	B-Task
volumes	I-Task
thanks	O
to	O
its	O
generic	O
3D	O
nature	O
.	O
	
The	O
capabilities	O
of	O
DeepMedic	B-Method
and	O
the	O
employed	O
CRF	B-Method
for	O
capturing	B-Task
3D	I-Task
patterns	I-Task
exceed	O
those	O
of	O
2D	O
networks	B-Method
and	O
locally	B-Method
connected	I-Method
random	I-Method
fields	I-Method
,	O
models	O
that	O
have	O
been	O
commonly	O
used	O
in	O
previous	O
work	O
.	O
	
At	O
the	O
same	O
time	O
,	O
our	O
system	O
is	O
very	O
efficient	O
at	O
inference	B-Method
time	O
,	O
which	O
allows	O
its	O
adoption	O
in	O
a	O
variety	O
of	O
research	O
and	O
clinical	O
settings	O
.	O
	
The	O
generic	O
nature	O
of	O
our	O
system	O
allows	O
its	O
straightforward	O
application	O
for	O
different	O
lesion	O
segmentation	B-Task
tasks	O
without	O
major	O
adaptations	O
.	O
	
To	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
our	O
system	O
achieved	O
the	O
highest	O
reported	O
accuracy	B-Metric
on	O
a	O
cohort	O
of	O
patients	O
with	O
severe	O
TBI	O
.	O
	
As	O
a	O
comparison	O
,	O
we	O
improved	O
over	O
the	O
reported	O
performance	B-Metric
of	O
the	O
pipeline	B-Method
in	O
.	O
	
Important	O
to	O
note	O
is	O
that	O
the	O
latter	O
work	O
focused	O
only	O
on	O
segmentation	B-Task
of	O
contusions	O
,	O
while	O
our	O
system	O
has	O
been	O
shown	O
capable	O
of	O
segmenting	O
even	O
small	O
and	O
diffused	O
pathologies	O
.	O
	
Additionally	O
,	O
our	O
pipeline	O
achieved	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	B-Metric
on	O
both	O
public	O
benchmarks	O
of	O
brain	O
tumors	O
(	O
BRATS	B-Material
2015	I-Material
)	O
and	O
stroke	O
lesions	O
(	O
SISS	O
ISLES	O
2015	O
)	O
.	O
	
We	O
believe	O
performance	B-Metric
can	O
be	O
further	O
improved	O
with	O
task	B-Task
-	I-Task
and	I-Task
data	I-Task
-	I-Task
specific	I-Task
adjustments	I-Task
,	O
for	O
instance	O
in	O
the	O
pre	B-Method
-	I-Method
processing	I-Method
,	O
but	O
our	O
results	O
show	O
the	O
potential	O
of	O
this	O
generically	O
designed	O
segmentation	B-Task
system	O
.	O
	
When	O
applying	O
our	O
pipeline	O
to	O
new	O
tasks	O
,	O
a	O
laborious	O
process	O
is	O
the	O
reconfiguration	O
of	O
the	O
CRF	B-Method
.	O
	
The	O
model	O
improved	O
our	O
system	O
	
’s	O
performance	B-Metric
with	O
statistical	B-Metric
significance	I-Metric
in	O
all	O
investigated	O
tasks	O
,	O
most	O
profoundly	O
when	O
the	O
performance	B-Metric
of	O
the	O
underlying	O
classifier	B-Method
degrades	O
,	O
proving	O
its	O
flexibility	O
and	O
robustness	O
.	O
	
Finding	O
optimal	O
parameters	O
for	O
each	O
task	O
,	O
however	O
,	O
can	O
be	O
challenging	O
.	O
	
This	O
became	O
most	O
obvious	O
on	O
the	O
task	O
of	O
multi	O
-	O
class	O
tumor	O
segmentation	B-Task
.	O
	
Because	O
the	O
tumor	O
’s	O
substructures	O
vary	O
significantly	O
in	O
appearance	O
,	O
finding	O
a	O
global	O
set	O
of	O
parameters	O
that	O
yields	O
improvements	O
on	O
all	O
classes	O
proved	O
difficult	O
.	O
	
Instead	O
,	O
we	O
applied	O
the	O
CRF	B-Method
in	O
a	O
binary	B-Method
fashion	I-Method
.	O
	
This	O
CRF	B-Method
model	I-Method
can	O
be	O
configured	O
with	O
a	O
separate	O
set	O
of	O
parameters	O
for	O
each	O
class	O
.	O
	
However	O
the	O
larger	O
parameter	O
space	O
would	O
complicate	O
its	O
configuration	O
further	O
.	O
	
Recent	O
work	O
from	O
showed	O
that	O
this	O
particular	O
CRF	B-Method
can	O
be	O
casted	O
as	O
a	O
neural	B-Method
network	I-Method
and	O
its	O
parameters	O
can	O
be	O
learned	O
with	O
regular	B-Method
gradient	I-Method
descent	I-Method
.	O
	
Training	B-Method
it	O
in	O
an	O
end	O
-	O
to	O
-	O
end	O
fashion	O
on	O
top	O
of	O
a	O
neural	B-Method
network	I-Method
would	O
alleviate	O
the	O
discussed	O
problems	O
.	O
	
This	O
will	O
be	O
explored	O
as	O
part	O
of	O
future	O
work	O
.	O
	
[	O
b	O
]	O
0.95	O
The	O
discriminative	O
power	O
of	O
the	O
learned	O
features	O
is	O
indicated	O
by	O
the	O
success	O
of	O
recent	O
CNN	B-Method
-	I-Method
based	I-Method
systems	I-Method
in	O
matching	O
human	O
performance	B-Metric
in	O
domains	O
where	O
it	O
was	O
previously	O
considered	O
too	O
ambitious	O
(	O
)	O
.	O
	
Analysis	O
of	O
the	O
automatically	O
extracted	O
information	O
could	O
potentially	O
provide	O
novel	O
insights	O
and	O
facilitate	O
research	O
on	O
pathologies	O
for	O
which	O
little	O
prior	O
knowledge	O
is	O
currently	O
available	O
.	O
	
In	O
an	O
attempt	O
to	O
illustrate	O
this	O
,	O
we	O
explore	O
what	O
patterns	O
have	O
been	O
learned	O
automatically	O
for	O
the	O
lesion	O
segmentation	B-Task
tasks	O
.	O
	
We	O
visualize	O
the	O
activations	O
of	O
DeepMedic	B-Method
’s	I-Method
FMs	I-Method
when	O
processing	O
a	O
subject	O
from	O
our	O
TBI	O
database	O
.	O
	
Many	O
appearing	O
patterns	O
are	O
difficult	O
to	O
interpret	O
,	O
especially	O
in	O
deeper	O
layers	O
.	O
	
In	O
Fig	O
.	O
	
[	O
reference	O
]	O
we	O
provide	O
some	O
examples	O
that	O
have	O
an	O
intuitive	O
explanation	O
.	O
	
One	O
of	O
the	O
most	O
interesting	O
findings	O
is	O
that	O
the	O
network	O
learns	O
to	O
identify	O
the	O
ventricles	O
,	O
CSF	O
,	O
white	O
and	O
gray	O
matter	O
.	O
	
This	O
reveals	O
that	O
differentiation	O
of	O
tissue	O
type	O
is	O
beneficial	O
for	O
lesion	O
segmentation	B-Task
.	O
	
This	O
is	O
in	O
line	O
with	O
findings	O
in	O
the	O
literature	O
,	O
where	O
segmentation	B-Task
performance	I-Metric
of	O
traditional	O
classifiers	B-Method
was	O
significantly	O
improved	O
by	O
incorporation	O
of	O
tissue	O
priors	O
(	O
)	O
.	O
	
It	O
is	O
intuitive	O
that	O
different	O
types	O
of	O
lesions	O
affect	O
different	O
parts	O
of	O
the	O
brain	O
depending	O
on	O
the	O
underlying	O
mechanisms	O
of	O
the	O
pathology	O
.	O
	
A	O
rigorous	O
analysis	O
of	O
spatial	O
cues	O
extracted	O
by	O
the	O
network	O
may	O
reveal	O
correlations	O
that	O
are	O
not	O
well	O
defined	O
yet	O
.	O
	
Similarly	O
intriguing	O
is	O
the	O
information	O
extracted	O
in	O
the	O
low	O
-	O
resolution	O
pathway	O
.	O
	
As	O
they	O
process	O
greater	O
context	O
,	O
these	O
neurons	O
gain	O
additional	O
localization	O
capabilities	O
.	O
	
The	O
activations	O
of	O
certain	O
FMs	O
form	O
fields	O
in	O
the	O
surrounding	O
areas	O
of	O
the	O
brain	O
.	O
	
These	O
patterns	O
are	O
preserved	O
in	O
the	O
deepest	O
hidden	O
layers	O
,	O
which	O
indicates	O
they	O
are	O
beneficial	O
for	O
the	O
final	O
segmentation	B-Task
(	O
see	O
two	O
last	O
rows	O
of	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
We	O
believe	O
these	O
cues	O
provide	O
a	O
spatial	O
bias	O
to	O
the	O
system	O
,	O
for	O
instance	O
that	O
large	O
TBI	O
contusions	O
tend	O
to	O
occur	O
towards	O
the	O
front	O
and	O
sides	O
of	O
the	O
brain	O
(	O
see	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
Furthermore	O
,	O
the	O
interaction	O
of	O
the	O
multi	O
-	O
resolution	O
features	O
can	O
be	O
observed	O
in	O
FMs	O
of	O
the	O
hidden	O
layer	O
that	O
follows	O
the	O
concatenation	O
of	O
the	O
pathways	O
.	O
	
The	O
network	O
learns	O
to	O
weight	O
the	O
output	O
of	O
the	O
two	O
pathways	O
,	O
preserving	O
low	O
resolution	O
in	O
certain	O
parts	O
and	O
show	O
fine	O
details	O
in	O
others	O
(	O
bottom	O
row	O
of	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
first	O
three	O
FMs	O
)	O
.	O
	
Our	O
assumption	O
is	O
that	O
the	O
low	B-Method
-	I-Method
resolution	I-Method
pathway	I-Method
provides	O
a	O
rough	O
localization	O
of	O
large	O
pathologies	O
and	O
brain	O
areas	O
that	O
are	O
challenging	O
to	O
segment	O
,	O
which	O
reserves	O
the	O
rest	O
of	O
the	O
network	O
	
’s	O
capacity	O
for	O
learning	O
detailed	O
patterns	O
associated	O
with	O
the	O
detection	B-Task
of	I-Task
smaller	I-Task
lesions	I-Task
,	O
fine	O
structures	O
and	O
ambiguous	O
areas	O
.	O
	
The	O
findings	O
of	O
the	O
above	O
exploration	O
lead	O
us	O
to	O
believe	O
that	O
great	O
potential	O
lies	O
into	O
fusing	O
the	O
discriminative	O
power	O
of	O
the	O
“	O
deep	O
black	O
box	O
”	O
with	O
the	O
knowledge	O
acquired	O
over	O
years	O
of	O
targeted	O
biomedical	O
research	O
.	O
	
Clinical	O
knowledge	O
is	O
available	O
for	O
certain	O
pathologies	O
,	O
such	O
as	O
spatial	O
priors	O
for	O
white	O
matter	O
lesions	O
.	O
	
Previously	O
engineered	B-Method
models	I-Method
have	O
been	O
proven	O
effective	O
in	O
tackling	O
fundamental	B-Task
imaging	I-Task
problems	I-Task
,	O
such	O
as	O
brain	B-Task
extraction	I-Task
,	O
tissue	B-Task
segmentation	I-Task
and	O
bias	B-Task
field	I-Task
correction	I-Task
.	O
	
We	O
show	O
that	O
a	O
network	O
is	O
capable	O
of	O
automatically	O
extracting	O
some	O
of	O
this	O
information	O
.	O
	
It	O
would	O
be	O
interesting	O
,	O
however	O
,	O
to	O
investigate	O
structured	O
ways	O
for	O
incorporating	O
such	O
existing	O
information	O
as	O
priors	O
into	O
the	O
network	O
’s	O
feature	O
space	O
,	O
which	O
should	O
simplify	O
the	O
optimization	B-Task
problem	I-Task
while	O
letting	O
a	O
specialist	O
guide	O
the	O
network	O
towards	O
an	O
optimal	O
solution	O
.	O
	
Although	O
neural	O
networks	B-Method
seem	O
promising	O
for	O
medical	B-Task
image	I-Task
analysis	I-Task
,	O
making	O
the	O
inference	B-Method
process	O
more	O
interpretable	O
is	O
required	O
.	O
	
This	O
would	O
allow	O
understanding	O
when	O
the	O
network	O
fails	O
,	O
an	O
important	O
aspect	O
in	O
biomedical	B-Task
applications	I-Task
.	O
	
Although	O
the	O
output	O
is	O
bounded	O
in	O
the	O
range	O
and	O
commonly	O
referred	O
to	O
as	O
probability	O
for	O
convenience	O
,	O
it	O
is	O
not	O
a	O
true	O
probability	O
in	O
a	O
Bayesian	O
sense	O
.	O
	
Research	O
towards	O
Bayesian	O
networks	B-Method
aims	O
to	O
alleviate	O
this	O
limitation	O
.	O
	
An	O
example	O
is	O
the	O
recent	O
work	O
of	O
who	O
show	O
that	O
model	O
confidence	O
can	O
be	O
estimated	O
via	O
sampling	B-Method
the	I-Method
dropout	I-Method
mask	I-Method
.	O
	
A	O
general	O
point	O
should	O
be	O
made	O
about	O
the	O
performance	B-Metric
drop	O
observed	O
when	O
our	O
system	O
is	O
applied	O
on	O
test	O
datasets	O
of	O
BRATS	B-Material
and	O
ISLES	O
in	O
comparison	O
to	O
its	O
cross	O
-	O
validated	O
performance	B-Metric
on	O
the	O
training	B-Method
data	O
.	O
	
In	O
both	O
cases	O
,	O
subsets	O
of	O
the	O
test	O
images	O
were	O
acquired	O
in	O
clinical	O
centers	O
different	O
from	O
the	O
ones	O
of	O
training	B-Method
datasets	O
.	O
	
Differences	O
in	O
scanner	O
type	O
and	O
acquisition	O
protocols	O
have	O
significant	O
impact	O
on	O
the	O
appearance	O
of	O
the	O
images	O
.	O
	
The	O
issue	O
of	O
multi	B-Task
-	I-Task
center	I-Task
data	I-Task
heterogeneity	I-Task
is	O
considered	O
a	O
major	O
bottleneck	O
for	O
enabling	O
large	B-Task
-	I-Task
scale	I-Task
imaging	I-Task
studies	I-Task
.	O
	
This	O
is	O
not	O
specific	O
to	O
our	O
approach	O
,	O
but	O
a	O
general	O
problem	O
in	O
medical	B-Task
image	I-Task
analysis	I-Task
.	O
	
One	O
possible	O
way	O
of	O
making	O
the	O
CNN	B-Method
invariant	O
to	O
the	O
data	O
heterogeneity	O
is	O
to	O
learn	O
a	O
generative	B-Method
model	I-Method
for	O
the	O
data	B-Task
acquisition	I-Task
process	I-Task
,	O
and	O
use	O
this	O
model	O
in	O
the	O
data	B-Task
augmentation	I-Task
step	I-Task
.	O
	
This	O
is	O
a	O
direction	O
we	O
explore	O
as	O
part	O
of	O
future	O
work	O
.	O
	
In	O
order	O
to	O
facilitate	O
further	O
research	O
in	O
this	O
area	O
and	O
to	O
provide	O
a	O
baseline	O
for	O
future	O
evaluations	O
,	O
we	O
make	O
the	O
source	O
code	O
of	O
the	O
entire	O
system	O
publicly	O
available	O
.	O
	
section	O
:	O
Acknowledgements	O
	
This	O
work	O
is	O
supported	O
by	O
the	O
EPSRC	O
First	O
Grant	O
scheme	O
(	O
grant	O
ref	O
no	O
.	O
	
EP	O
/	O
N023668	O
/	O
1	O
)	O
and	O
partially	O
funded	O
under	O
the	O
7th	O
Framework	O
Programme	O
by	O
the	O
European	O
Commission	O
	
(	O
TBIcare	O
:	O
http:	O
//	O
www.tbicare.eu	O
/	O
;	O
	
CENTER	O
-	O
TBI	O
:	O
https:	O
//	O
www.center	O
-	O
tbi.eu	O
/	O
)	O
.	O
	
This	O
work	O
was	O
further	O
supported	O
by	O
a	O
Medical	O
Research	O
Council	O
(	O
UK	O
)	O
Program	O
Grant	O
(	O
Acute	O
brain	O
injury	O
:	O
heterogeneity	O
of	O
mechanisms	O
,	O
therapeutic	O
targets	O
and	O
outcome	O
effects	O
[	O
G9439390	O
ID	O
65883	O
]	O
)	O
,	O
the	O
UK	O
National	O
Institute	O
of	O
Health	O
Research	O
Biomedical	O
Research	O
Centre	O
at	O
Cambridge	O
and	O
Technology	O
Platform	O
funding	O
provided	O
by	O
the	O
UK	O
Department	O
of	O
Health	O
.	O
	
KK	O
is	O
supported	O
by	O
the	O
Imperial	O
College	O
London	O
PhD	O
Scholarship	O
Programme	O
.	O
	
VFJN	B-Method
is	O
supported	O
by	O
a	O
Health	O
Foundation	O
/	O
Academy	O
of	O
Medical	O
Sciences	O
Clinician	O
Scientist	O
Fellowship	O
.	O
	
DKM	B-Method
is	O
supported	O
by	O
an	O
NIHR	O
Senior	O
Investigator	O
Award	O
.	O
	
We	O
gratefully	O
acknowledge	O
the	O
support	O
of	O
NVIDIA	O
Corporation	O
with	O
the	O
donation	O
of	O
two	O
Titan	O
X	O
GPUs	O
for	O
our	O
research	O
.	O
	
appendix	O
:	O
Additional	O
Details	O
on	O
Multi	B-Task
-	I-Task
Scale	I-Task
Processing	I-Task
	
The	O
integration	O
of	O
multi	B-Task
-	I-Task
scale	I-Task
parallel	I-Task
pathways	I-Task
in	O
architectures	O
that	O
use	O
solely	O
unary	O
kernel	O
strides	O
,	O
such	O
as	O
the	O
proposed	O
,	O
was	O
described	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
.	O
	
The	O
required	O
up	B-Method
-	I-Method
sampling	I-Method
of	O
the	O
low	O
-	O
resolution	O
features	O
was	O
performed	O
with	O
simple	O
repetition	O
in	O
our	O
experiments	O
.	O
	
This	O
was	O
found	O
sufficient	O
,	O
with	O
the	O
following	O
hidden	B-Method
layers	I-Method
learning	I-Method
to	O
combine	O
the	O
multi	O
-	O
scale	O
features	O
.	O
	
In	O
the	O
case	O
of	O
architectures	O
with	O
strides	O
greater	O
than	O
unary	O
,	O
the	O
last	O
convolutional	B-Method
layers	I-Method
of	O
the	O
two	O
pathways	O
,	O
and	O
,	O
have	O
receptive	O
fields	O
and	O
with	O
strides	O
and	O
respectively	O
.	O
	
To	O
preserve	O
spatial	O
correspondence	O
of	O
the	O
multi	O
-	O
scale	O
features	O
and	O
enable	O
the	O
network	O
for	O
dense	O
inference	B-Method
,	O
the	O
dimensions	O
of	O
the	O
input	O
segments	O
should	O
be	O
chosen	O
such	O
that	O
the	O
FMs	O
in	O
can	O
be	O
brought	O
to	O
the	O
dimensions	O
of	O
the	O
FMs	O
in	O
after	O
sequential	O
resampling	O
by	O
,	O
,	O
or	O
equivalent	O
combinations	O
.	O
	
Here	O
and	O
represent	O
up	O
-	O
and	O
down	O
-	O
sampling	O
by	O
the	O
given	O
factor	O
.	O
	
Because	O
they	O
are	O
more	O
reliant	O
on	O
these	O
operations	O
,	O
utilization	O
of	O
more	O
elaborate	O
,	O
learnt	B-Method
upsampling	I-Method
schemes	I-Method
(	O
)	O
should	O
be	O
beneficial	O
in	O
such	O
networks	B-Method
.	O
	
appendix	O
:	O
Additional	O
Details	O
on	O
Network	O
Configurations	O
	
3D	B-Task
Networks	I-Task
:	O
	
The	O
main	O
description	O
of	O
our	O
system	O
is	O
presented	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
.	O
	
All	O
models	O
discussed	O
in	O
this	O
work	O
outside	O
Sec	O
.	O
	
[	O
reference	O
]	O
are	O
fully	B-Method
3D	I-Method
CNNs	I-Method
.	O
	
Their	O
architectures	O
are	O
presented	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
They	O
all	O
use	O
the	O
PReLu	B-Method
non	I-Method
-	I-Method
linearity	I-Method
(	O
)	O
.	O
	
They	O
are	O
trained	O
using	O
the	O
RMSProp	B-Method
optimizer	I-Method
(	O
)	O
and	O
Nesterov	B-Method
momentum	I-Method
(	O
)	O
with	O
value	O
.	O
	
and	O
regularisation	B-Method
is	O
applied	O
.	O
	
We	O
train	O
the	O
networks	B-Method
with	O
dense	O
-	O
training	B-Method
on	O
batches	O
of	O
10	O
segments	O
,	O
each	O
of	O
size	O
.	O
	
Exceptions	O
are	O
the	O
experiments	O
in	O
Sec	O
[	O
reference	O
]	O
,	O
where	O
the	O
batch	O
sizes	O
were	O
adjusted	O
along	O
with	O
the	O
segment	O
sizes	O
,	O
to	O
achieve	O
similar	O
memory	B-Metric
footprint	I-Metric
and	O
training	B-Method
time	O
per	O
batch	O
.	O
	
The	O
weights	O
of	O
our	O
shallow	O
,	O
5	O
-	O
layers	O
networks	B-Method
are	O
initialized	O
by	O
sampling	O
from	O
a	O
normal	B-Method
distribution	I-Method
and	O
their	O
initial	O
learning	B-Metric
rate	I-Metric
is	O
set	O
to	O
.	O
	
Deeper	B-Method
models	I-Method
(	O
and	O
the	O
“	O
Shallow	B-Method
+	I-Method
”	I-Method
model	I-Method
in	O
Sec	O
[	O
reference	O
]	O
)	O
use	O
the	O
weight	B-Method
initialisation	I-Method
scheme	I-Method
of	O
.	O
	
The	O
scheme	O
increases	O
the	O
signal	O
’s	O
variance	O
in	O
our	O
settings	O
,	O
which	O
leads	O
to	O
RMSProm	O
decreasing	O
the	O
effective	B-Metric
learning	I-Metric
rate	I-Metric
.	O
	
To	O
counter	O
this	O
,	O
we	O
accompany	O
it	O
with	O
an	O
increased	O
initial	B-Metric
learning	I-Metric
rate	I-Metric
.	O
	
Throughout	O
training	B-Method
,	O
the	O
learning	B-Metric
rate	I-Metric
of	O
all	O
models	O
is	O
halved	O
whenever	O
convergence	O
plateaus	O
.	O
	
Dropout	B-Method
with	O
50	O
%	O
rate	B-Metric
is	O
employed	O
on	O
the	O
two	O
last	O
hidden	B-Method
layers	I-Method
of	I-Method
11	I-Method
-	I-Method
layers	I-Method
deep	I-Method
models	I-Method
.	O
	
2D	B-Method
Networks	I-Method
:	O
Table	O
[	O
reference	O
]	O
presents	O
representative	O
examples	O
of	O
2D	O
configurations	O
that	O
were	O
employed	O
for	O
the	O
experiments	O
discussed	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
.	O
	
Width	O
,	O
depth	O
and	O
batch	O
size	O
were	O
adjusted	O
so	O
that	O
total	O
required	O
memory	O
was	O
similar	O
to	O
the	O
3D	B-Method
version	I-Method
of	O
DeepMedic	B-Method
.	O
	
Wider	O
or	O
deeper	O
variants	O
than	O
the	O
ones	O
presented	O
did	O
not	O
show	O
greater	O
performance	B-Metric
.	O
	
A	O
possible	O
reason	O
is	O
that	O
this	O
number	O
of	O
filters	O
is	O
enough	O
for	O
the	O
extraction	O
of	O
the	O
limited	O
2D	O
information	O
and	O
that	O
the	O
field	O
of	O
view	O
of	O
the	O
deep	B-Method
multi	I-Method
-	I-Method
scale	I-Method
variant	I-Method
is	O
already	O
sufficient	O
for	O
the	O
application	O
.	O
	
The	O
presented	O
2D	B-Method
models	I-Method
were	O
regularized	O
with	O
and	O
since	O
they	O
have	O
less	O
parameters	O
than	O
the	O
3D	B-Method
variants	I-Method
.	O
	
All	O
but	O
Dm2dPatch	B-Method
were	O
trained	O
with	O
momentum	O
and	O
initial	B-Metric
learning	I-Metric
rate	I-Metric
,	O
while	O
the	O
rest	O
with	O
and	O
as	O
this	O
setting	O
increased	O
performance	B-Metric
.	O
	
The	O
rest	O
of	O
the	O
hyper	O
parameters	O
are	O
the	O
same	O
as	O
for	O
the	O
3D	O
DeepMedic	O
.	O
	
1.0	B-Method
1.0	I-Method
Sampling	I-Method
was	O
manually	O
calibrated	O
to	O
achieve	O
similar	O
class	O
balance	O
as	O
models	O
that	O
are	O
trained	O
on	O
image	O
segments	O
.	O
	
Model	O
underperformed	O
otherwise	O
.	O
	
appendix	O
:	O
Distribution	O
of	O
Tumor	O
Classes	O
Captured	O
in	O
Training	B-Method
	
le	O
:	O
trainingSamplesPercBrats2015Training	O
]	O
Table	O
C.1	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Evaluation	O
of	O
Output	B-Method
Embeddings	I-Method
for	O
Fine	B-Task
-	I-Task
Grained	I-Task
Image	I-Task
Classification	I-Task
	
Image	B-Task
classification	I-Task
has	O
advanced	O
significantly	O
in	O
recent	O
years	O
with	O
the	O
availability	O
of	O
large	O
-	O
scale	O
image	O
sets	O
.	O
	
However	O
,	O
fine	B-Task
-	I-Task
grained	I-Task
classification	I-Task
remains	O
a	O
major	O
challenge	O
due	O
to	O
the	O
annotation	B-Metric
cost	I-Metric
of	O
large	O
numbers	O
of	O
fine	O
-	O
grained	O
categories	O
.	O
	
This	O
project	O
shows	O
that	O
compelling	O
classification	B-Task
performance	O
can	O
be	O
achieved	O
on	O
such	O
categories	O
even	O
without	O
labeled	O
training	O
data	O
.	O
	
Given	O
image	O
and	O
class	O
embeddings	O
,	O
we	O
learn	O
a	O
compatibility	O
function	O
such	O
that	O
matching	O
embeddings	O
are	O
assigned	O
a	O
higher	O
score	O
than	O
mismatching	O
ones	O
;	O
zero	B-Task
-	I-Task
shot	I-Task
classification	I-Task
of	O
an	O
image	O
proceeds	O
by	O
finding	O
the	O
label	O
yielding	O
the	O
highest	O
joint	B-Metric
compatibility	I-Metric
score	I-Metric
.	O
	
We	O
use	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
image	O
features	O
and	O
focus	O
on	O
different	O
supervised	O
attributes	O
and	O
unsupervised	O
output	O
embeddings	O
either	O
derived	O
from	O
hierarchies	B-Method
or	O
learned	O
from	O
unlabeled	O
text	O
corpora	O
.	O
	
We	O
establish	O
a	O
substantially	O
improved	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
on	O
the	O
Animals	O
with	O
Attributes	O
and	O
Caltech	O
-	O
UCSD	O
Birds	O
datasets	O
.	O
	
Most	O
encouragingly	O
,	O
we	O
demonstrate	O
that	O
purely	O
unsupervised	O
output	O
embeddings	O
(	O
learned	O
from	O
Wikipedia	O
and	O
improved	O
with	O
fine	O
-	O
grained	O
text	O
)	O
achieve	O
compelling	O
results	O
,	O
even	O
outperforming	O
the	O
previous	O
supervised	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
.	O
	
By	O
combining	O
different	O
output	O
embeddings	O
,	O
we	O
further	O
improve	O
results	O
.	O
	
section	O
:	O
Introduction	O
	
The	O
image	B-Task
classification	I-Task
problem	I-Task
has	O
been	O
redefined	O
by	O
the	O
emergence	O
of	O
large	O
scale	O
datasets	O
such	O
as	O
ImageNet	O
.	O
	
Since	O
deep	B-Method
learning	I-Method
methods	I-Method
dominated	O
recent	O
Large	B-Task
-	I-Task
Scale	I-Task
Visual	I-Task
Recognition	I-Task
Challenges	I-Task
(	O
ILSVRC12	B-Task
-	O
14	O
)	O
,	O
the	O
attention	O
of	O
the	O
computer	B-Task
vision	I-Task
community	I-Task
has	O
been	O
drawn	O
to	O
Convolutional	B-Method
Neural	I-Method
Networks	I-Method
(	O
CNN	B-Method
)	O
.	O
	
Training	O
CNNs	B-Method
requires	O
massive	O
amounts	O
of	O
labeled	O
data	O
;	O
but	O
,	O
in	O
fine	O
-	O
grained	O
image	O
collections	O
,	O
where	O
the	O
categories	O
are	O
visually	O
very	O
similar	O
,	O
the	O
data	O
population	O
decreases	O
significantly	O
.	O
	
We	O
are	O
interested	O
in	O
the	O
most	O
extreme	O
case	O
of	O
learning	B-Task
with	O
a	O
limited	O
amount	O
of	O
labeled	O
data	O
,	O
zero	B-Task
-	I-Task
shot	I-Task
learning	I-Task
,	O
in	O
which	O
no	O
labeled	O
data	O
is	O
available	O
for	O
some	O
classes	O
.	O
	
Without	O
labels	O
,	O
we	O
need	O
alternative	O
sources	O
of	O
information	O
that	O
relate	O
object	O
classes	O
.	O
	
Attributes	O
,	O
which	O
describe	O
well	O
-	O
known	O
common	O
characteristics	O
of	O
objects	O
,	O
are	O
an	O
appealing	O
source	O
of	O
information	O
,	O
and	O
they	O
can	O
be	O
easily	O
obtained	O
through	O
crowd	B-Method
-	I-Method
sourcing	I-Method
techniques	I-Method
.	O
	
However	O
,	O
fine	O
-	O
grained	O
concepts	O
present	O
a	O
special	O
challenge	O
:	O
due	O
to	O
the	O
high	O
degree	O
of	O
similarity	O
among	O
categories	O
,	O
a	O
large	O
number	O
of	O
attributes	O
are	O
required	O
to	O
effectively	O
model	O
these	O
subtle	O
differences	O
.	O
	
This	O
increases	O
the	O
cost	O
of	O
attribute	B-Task
annotation	I-Task
.	O
	
One	O
aim	O
of	O
this	O
work	O
is	O
to	O
move	O
towards	O
eliminating	O
the	O
human	B-Method
labeling	I-Method
component	I-Method
from	O
zero	B-Method
-	I-Method
shot	I-Method
learning	I-Method
,	O
e.g.	O
by	O
using	O
alternative	O
sources	O
of	O
information	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
large	B-Method
-	I-Method
margin	I-Method
support	I-Method
vector	I-Method
machines	I-Method
(	O
SVM	B-Method
)	I-Method
operate	O
with	O
labeled	O
training	O
images	O
,	O
so	O
a	O
lack	O
of	O
labels	O
limits	O
their	O
use	O
for	O
this	O
task	O
.	O
	
Inspired	O
by	O
previous	O
work	O
on	O
label	B-Task
embedding	I-Task
and	O
structured	B-Task
SVMs	I-Task
,	O
we	O
propose	O
to	O
use	O
a	O
Structured	B-Method
Joint	I-Method
Embedding	I-Method
(	O
SJE	B-Method
)	O
framework	O
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
that	O
relates	O
input	O
embeddings	O
(	O
i.e.	O
image	O
features	O
)	O
and	O
output	O
embeddings	O
(	O
i.e.	O
side	O
information	O
)	O
through	O
a	O
compatibility	O
function	O
,	O
therefore	O
taking	O
advantage	O
of	O
a	O
structure	O
in	O
the	O
output	O
space	O
.	O
	
The	O
SJE	B-Method
framework	O
separates	O
the	O
subspace	B-Task
learning	I-Task
problem	I-Task
from	O
the	O
specific	O
input	O
and	O
output	O
features	O
used	O
in	O
a	O
given	O
application	O
.	O
	
As	O
a	O
general	O
framework	O
,	O
it	O
can	O
be	O
applied	O
to	O
any	O
learning	B-Task
problem	I-Task
where	O
more	O
than	O
one	O
modality	O
is	O
provided	O
for	O
an	O
object	O
.	O
	
Our	O
contributions	O
are	O
:	O
(	O
1	O
)	O
We	O
demonstrate	O
that	O
unsupervised	B-Method
class	I-Method
embeddings	I-Method
trained	O
from	O
large	O
unlabeled	O
text	O
corpora	O
are	O
competitive	O
to	O
previously	O
published	O
results	O
that	O
use	O
human	O
supervision	O
.	O
	
(	O
2	O
)	O
Using	O
the	O
most	O
recent	O
deep	B-Method
architectures	I-Method
as	O
input	O
embeddings	O
,	O
we	O
significantly	O
improve	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
(	O
SoA	O
)	O
.	O
	
(	O
3	O
)	O
We	O
extensively	O
evaluate	O
several	O
unsupervised	B-Method
output	I-Method
embeddings	I-Method
for	O
fine	B-Task
-	I-Task
grained	I-Task
classification	I-Task
in	O
a	O
zero	B-Method
-	I-Method
shot	I-Method
setting	I-Method
on	O
three	O
challenging	O
datasets	O
.	O
	
(	O
4	O
)	O
	
By	O
combining	O
different	O
output	O
embeddings	O
we	O
obtain	O
best	O
results	O
,	O
surpassing	O
the	O
SoA	O
by	O
a	O
large	O
margin	O
.	O
	
(	O
5	O
)	O
	
We	O
propose	O
a	O
novel	O
weakly	B-Method
-	I-Method
supervised	I-Method
Word2Vec	I-Method
variant	I-Method
that	O
improves	O
the	O
accuracy	B-Metric
when	O
combined	O
with	O
other	O
output	O
embeddings	O
.	O
	
The	O
rest	O
of	O
the	O
paper	O
is	O
organized	O
as	O
follows	O
.	O
	
Section	O
[	O
reference	O
]	O
provides	O
a	O
review	O
of	O
the	O
relevant	O
literature	O
;	O
Sec	O
.	O
	
[	O
reference	O
]	O
details	O
the	O
SJE	B-Method
method	O
;	O
Sec	O
.	O
	
[	O
reference	O
]	O
explains	O
the	O
output	O
embeddings	O
that	O
we	O
analyze	O
;	O
Sec	O
.	O
	
[	O
reference	O
]	O
presents	O
our	O
experimental	O
evaluation	O
;	O
Sec	O
.	O
	
[	O
reference	O
]	O
presents	O
the	O
discussion	O
and	O
our	O
conclusions	O
.	O
	
section	O
:	O
Related	O
Work	O
	
Learning	B-Task
to	O
classify	B-Task
in	O
the	O
absence	O
of	O
labeled	O
data	O
(	O
zero	B-Task
-	I-Task
shot	I-Task
learning	I-Task
)	O
is	O
a	O
challenging	O
problem	O
,	O
and	O
achieving	O
better	O
-	O
than	O
-	O
chance	O
performance	O
requires	O
structure	O
in	O
the	O
output	O
space	O
.	O
	
Attributes	O
provide	O
one	O
such	O
space	O
;	O
they	O
relate	O
different	O
classes	O
through	O
well	O
-	O
known	O
and	O
shared	O
characteristics	O
of	O
objects	O
.	O
	
Attributes	O
,	O
which	O
are	O
often	O
collected	O
manually	O
,	O
have	O
shown	O
promising	O
results	O
in	O
various	O
applications	O
,	O
i.e.	O
caption	B-Task
generation	I-Task
,	O
face	B-Task
recognition	I-Task
,	O
image	B-Task
retrieval	I-Task
,	O
action	B-Task
recognition	I-Task
and	O
image	B-Task
classification	I-Task
.	O
	
The	O
main	O
challenge	O
of	O
attribute	B-Method
-	I-Method
based	I-Method
zero	I-Method
-	I-Method
shot	I-Method
learning	I-Method
arises	O
on	O
more	O
challenging	O
fine	O
-	O
grained	O
data	O
collections	O
,	O
in	O
which	O
categories	O
may	O
visually	O
differ	O
only	O
subtly	O
.	O
	
Therefore	O
,	O
generic	O
attributes	O
fail	O
at	O
modeling	O
small	O
intra	O
-	O
class	O
variance	O
between	O
objects	O
.	O
	
Improved	O
performance	O
requires	O
a	O
large	O
number	O
of	O
specific	O
attributes	O
which	O
increases	O
the	O
cost	O
of	O
data	B-Task
gathering	I-Task
.	O
	
As	O
an	O
alternative	O
to	O
manual	B-Method
annotation	I-Method
,	O
side	O
information	O
can	O
be	O
collected	O
automatically	O
from	O
text	O
corpora	O
.	O
	
Bag	B-Task
-	I-Task
of	I-Task
-	I-Task
words	I-Task
is	O
an	O
example	O
where	O
class	O
embeddings	O
correspond	O
to	O
histograms	O
of	O
vocabulary	O
words	O
extracted	O
automatically	O
from	O
unlabeled	O
text	O
.	O
	
Another	O
example	O
is	O
using	O
taxonomical	O
order	O
of	O
classes	O
as	O
structured	O
output	O
embeddings	O
.	O
	
Such	O
a	O
taxonomy	O
can	O
be	O
built	O
automatically	O
from	O
a	O
pre	O
-	O
defined	O
ontology	B-Method
such	O
as	O
WordNet	O
.	O
	
In	O
this	O
case	O
,	O
the	O
distance	O
between	O
nodes	O
is	O
measured	O
using	O
semantic	B-Metric
similarity	I-Metric
metrics	I-Metric
.	O
	
Finally	O
,	O
distributed	B-Method
text	I-Method
representations	I-Method
learned	O
from	O
large	O
unsupervised	O
text	O
corpora	O
can	O
be	O
employed	O
as	O
structured	O
embeddings	O
.	O
	
We	O
compare	O
several	O
representatives	O
of	O
these	O
methods	O
(	O
and	O
their	O
combinations	O
)	O
in	O
our	O
evaluation	O
.	O
	
Embedding	O
labels	O
in	O
an	O
Euclidean	O
space	O
is	O
an	O
effective	O
tool	O
to	O
model	O
latent	O
relationships	O
between	O
classes	O
.	O
	
These	O
relationships	O
can	O
be	O
collected	O
separately	O
from	O
the	O
data	O
,	O
learned	O
from	O
the	O
data	O
or	O
derived	O
from	O
side	O
information	O
.	O
	
In	O
order	O
to	O
collect	O
relationships	O
independently	O
of	O
data	O
,	O
compressed	B-Method
sensing	I-Method
uses	O
random	B-Method
projections	I-Method
whereas	O
Error	B-Method
Correcting	I-Method
Output	I-Method
Codes	I-Method
builds	O
embeddings	O
inspired	O
from	O
information	B-Method
theory	I-Method
.	O
	
WSABIE	B-Method
uses	O
images	O
with	O
their	O
corresponding	O
labels	O
to	O
learn	O
an	O
embedding	O
of	O
the	O
labels	O
,	O
and	O
CCA	B-Method
maximizes	O
the	O
correlation	B-Metric
between	O
two	O
different	O
data	O
modalities	O
.	O
	
DeViSE	O
employs	O
a	O
ranking	B-Method
formulation	I-Method
for	O
zero	B-Task
-	I-Task
shot	I-Task
learning	I-Task
using	O
images	O
and	O
distributed	B-Method
text	I-Method
representations	I-Method
.	O
	
The	O
ALE	B-Method
method	I-Method
employs	O
an	O
approximate	B-Method
ranking	I-Method
formulation	I-Method
for	O
the	O
same	O
using	O
images	O
and	O
attributes	O
.	O
	
ConSe	B-Method
uses	O
the	O
probabilities	O
of	O
a	O
softmax	B-Method
-	I-Method
output	I-Method
layer	I-Method
to	O
weigh	O
the	O
semantic	O
vectors	O
of	O
all	O
the	O
classes	O
.	O
	
In	O
this	O
work	O
,	O
we	O
use	O
the	O
multiclass	O
objective	O
to	O
learn	O
structured	O
output	O
embeddings	O
obtained	O
from	O
various	O
sources	O
.	O
	
Among	O
the	O
closest	O
related	O
work	O
,	O
ALE	B-Method
uses	O
Fisher	O
Vectors	O
(	O
FV	B-Method
)	O
as	O
input	O
and	O
binary	O
attributes	O
/	O
hierarchies	O
as	O
output	O
embeddings	O
.	O
	
Similarly	O
,	O
DeviSe	O
uses	O
CNN	O
features	O
as	O
input	O
and	O
Word2Vec	B-Method
representations	I-Method
as	O
output	O
embeddings	O
.	O
	
In	O
this	O
work	O
,	O
we	O
benefit	O
from	O
both	O
ideas	O
:	O
(	O
1	O
)	O
We	O
use	O
SoA	O
image	O
features	O
,	O
i.e.	O
FV	B-Method
and	O
CNN	B-Method
,	O
(	O
2	O
)	O
among	O
others	O
,	O
we	O
also	O
use	O
attributes	O
and	O
Word2Vec	O
as	O
output	O
embeddings	O
.	O
	
Our	O
work	O
differs	O
from	O
w.r.t	B-Method
.	O
	
two	O
aspects	O
:	O
(	O
1	O
)	O
We	O
propose	O
and	O
evaluate	O
several	O
output	B-Method
embedding	I-Method
methods	I-Method
specifically	O
built	O
for	O
fine	B-Task
-	I-Task
grained	I-Task
classification	I-Task
.	O
	
(	O
2	O
)	O
	
We	O
show	O
how	O
some	O
of	O
these	O
output	O
embeddings	O
complement	O
each	O
other	O
for	O
zero	B-Task
-	I-Task
shot	I-Task
learning	I-Task
on	O
general	O
and	O
fine	O
-	O
grained	O
datasets	O
.	O
	
The	O
reader	O
should	O
be	O
aware	O
of	O
.	O
	
section	O
:	O
Structured	B-Method
Joint	I-Method
Embedding	I-Method
s	O
	
In	O
this	O
work	O
,	O
we	O
aim	O
to	O
leverage	O
input	O
and	O
output	O
embeddings	O
in	O
a	O
joint	B-Method
framework	I-Method
by	O
learning	O
a	O
compatibility	O
between	O
these	O
embeddings	O
.	O
	
We	O
are	O
interested	O
in	O
the	O
problem	O
of	O
zero	B-Task
-	I-Task
shot	I-Task
learning	I-Task
for	O
image	B-Task
classification	I-Task
where	O
training	O
and	O
test	O
images	O
belong	O
to	O
two	O
disjoint	O
sets	O
of	O
classes	O
.	O
	
Following	O
,	O
given	O
input	O
/	O
output	O
and	O
from	O
,	O
Structured	B-Method
Joint	I-Method
Embedding	I-Method
(	O
SJE	B-Method
)	O
learns	O
by	O
minimizing	O
the	O
empirical	B-Metric
risk	I-Metric
where	O
defines	O
the	O
cost	O
of	O
predicting	O
when	O
the	O
true	O
label	O
is	O
.	O
	
Here	O
,	O
we	O
use	O
the	O
loss	O
.	O
	
subsection	O
:	O
Model	O
	
We	O
define	O
a	O
compatibility	O
function	O
between	O
an	O
input	O
space	O
and	O
a	O
structured	O
output	O
space	O
.	O
	
Given	O
a	O
specific	O
input	O
embedding	O
,	O
we	O
derive	O
a	O
prediction	B-Task
by	O
maximizing	O
the	O
compatibility	O
over	O
SJE	B-Method
as	O
follows	O
:	O
	
The	O
parameter	O
vector	O
can	O
be	O
written	O
as	O
a	O
matrix	O
with	O
being	O
the	O
input	O
embedding	O
dimension	O
and	O
being	O
the	O
output	O
embedding	O
dimension	O
.	O
	
This	O
leads	O
to	O
the	O
bi	O
-	O
linear	O
form	O
of	O
the	O
compatibility	O
function	O
:	O
Here	O
,	O
the	O
input	O
embedding	O
is	O
denoted	O
by	O
and	O
the	O
output	O
embedding	O
by	O
.	O
	
The	O
matrix	O
is	O
learned	O
by	O
enforcing	O
the	O
correct	O
label	O
to	O
be	O
ranked	O
higher	O
than	O
any	O
of	O
the	O
other	O
labels	O
(	O
Sec	O
.	O
	
[	O
reference	O
]	O
)	O
,	O
i.e.	O
multiclass	O
objective	O
.	O
	
This	O
formulation	O
is	O
closely	O
related	O
to	O
.	O
	
Within	O
the	O
label	B-Method
embedding	I-Method
framework	I-Method
,	O
ALE	B-Method
and	O
DeViSe	O
use	O
pairwise	B-Metric
ranking	I-Metric
objective	I-Metric
,	O
WSABIE	B-Method
learns	O
both	O
and	O
through	O
ranking	B-Task
,	O
whereas	O
we	O
use	O
multiclass	O
objective	O
.	O
	
Similarly	O
,	O
use	O
the	O
regression	O
objective	O
and	O
CCA	B-Method
maximizes	O
the	O
correlation	O
of	O
input	O
and	O
output	O
embeddings	O
.	O
	
subsection	O
:	O
Parameter	B-Method
Learning	I-Method
	
According	O
to	O
the	O
unregularized	B-Method
structured	I-Method
SVM	I-Method
formulation	I-Method
,	O
the	O
objective	O
is	O
:	O
where	O
the	O
misclassification	B-Metric
loss	I-Metric
takes	O
the	O
form	O
:	O
	
For	O
the	O
zero	B-Task
-	I-Task
shot	I-Task
learning	I-Task
scenario	I-Task
,	O
the	O
training	O
and	O
test	O
classes	O
are	O
disjoint	O
.	O
	
Therefore	O
,	O
we	O
fix	O
to	O
the	O
output	O
embeddings	O
of	O
training	O
classes	O
and	O
learn	O
.	O
	
For	O
prediction	B-Task
,	O
we	O
project	O
a	O
test	O
image	O
onto	O
the	O
and	O
search	O
for	O
the	O
nearest	O
output	O
embedding	O
vector	O
(	O
using	O
the	O
dot	O
product	O
similarity	O
)	O
that	O
corresponds	O
to	O
one	O
of	O
the	O
test	O
classes	O
.	O
	
We	O
use	O
Stochastic	B-Method
Gradient	I-Method
Descent	I-Method
(	O
SGD	B-Method
)	I-Method
for	O
optimization	B-Task
which	O
consists	O
in	O
sampling	O
at	O
each	O
step	O
and	O
searching	O
for	O
the	O
highest	O
ranked	O
class	O
.	O
	
If	O
,	O
we	O
update	O
as	O
follows	O
:	O
where	O
is	O
the	O
learning	O
step	O
-	O
size	O
used	O
at	O
iteration	O
.	O
	
We	O
use	O
a	O
constant	O
step	O
size	O
chosen	O
by	O
	
cross	B-Method
-	I-Method
validation	I-Method
and	O
we	O
perform	O
regularization	B-Method
through	O
early	B-Method
stopping	I-Method
.	O
	
subsection	O
:	O
Learning	O
Combined	B-Task
Embeddings	I-Task
	
For	O
some	O
classification	B-Task
tasks	I-Task
,	O
there	O
may	O
be	O
multiple	O
output	O
embeddings	O
available	O
,	O
each	O
capturing	O
a	O
different	O
aspect	O
of	O
the	O
structure	O
of	O
the	O
output	O
space	O
.	O
	
Each	O
may	O
also	O
have	O
a	O
different	O
signal	B-Metric
-	I-Metric
to	I-Metric
-	I-Metric
noise	I-Metric
ratio	I-Metric
.	O
	
Since	O
each	O
output	B-Method
embedding	I-Method
possibly	O
offers	O
non	O
-	O
redundant	O
information	O
about	O
the	O
output	O
space	O
,	O
as	O
also	O
shown	O
in	O
,	O
we	O
can	O
learn	O
a	O
better	O
joint	B-Method
embedding	I-Method
by	O
combining	O
them	O
together	O
.	O
	
We	O
model	O
the	O
resulting	O
compatibility	B-Metric
score	I-Metric
as	O
where	O
are	O
the	O
joint	O
embedding	O
weight	O
matrices	O
corresponding	O
to	O
the	O
output	O
embeddings	O
(	O
)	O
.	O
	
In	O
our	O
experiments	O
,	O
we	O
first	O
train	O
each	O
independently	O
,	O
then	O
perform	O
a	O
grid	B-Method
search	I-Method
over	O
on	O
a	O
validation	O
set	O
.	O
	
Interestingly	O
,	O
we	O
found	O
that	O
the	O
optimal	O
for	O
previously	O
-	O
seen	O
classes	O
is	O
often	O
different	O
from	O
the	O
one	O
for	O
unseen	O
classes	O
.	O
	
Therefore	O
,	O
it	O
is	O
critical	O
to	O
cross	O
-	O
validate	O
on	O
the	O
zero	B-Method
-	I-Method
shot	I-Method
setting	I-Method
.	O
	
Note	O
that	O
if	O
we	O
take	O
,	O
Equation	O
[	O
reference	O
]	O
is	O
equivalent	O
to	O
simply	O
concatenating	O
the	O
.	O
	
This	O
corresponds	O
to	O
stacking	O
the	O
into	O
a	O
single	O
matrix	O
and	O
computing	O
the	O
standard	O
compatibility	O
as	O
in	O
Equation	O
[	O
reference	O
]	O
.	O
	
However	O
,	O
such	O
a	O
stacking	B-Method
learns	O
a	O
large	O
where	O
a	O
high	O
dimensional	O
biases	O
the	O
final	O
prediction	O
.	O
	
In	O
contrast	O
,	O
eliminates	O
the	O
bias	O
,	O
leading	O
to	O
better	O
predictions	O
.	O
	
Thus	O
,	O
can	O
be	O
thought	O
of	O
as	O
the	O
confidence	O
associated	O
with	O
whose	O
contribution	O
we	O
can	O
control	O
.	O
	
We	O
show	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
that	O
finding	O
an	O
appropriate	O
can	O
yield	O
improved	O
accuracy	B-Metric
compared	O
to	O
any	O
single	O
.	O
	
section	O
:	O
Output	B-Method
Embeddings	I-Method
	
In	O
this	O
section	O
,	O
we	O
describe	O
three	O
types	O
of	O
output	O
embeddings	O
:	O
human	O
-	O
annotated	O
attributes	O
,	O
unsupervised	O
word	O
embeddings	O
learned	O
from	O
large	O
text	O
corpora	O
,	O
and	O
hierarchical	B-Method
embeddings	I-Method
derived	O
from	O
WordNet	O
.	O
	
subsection	O
:	O
Embedding	B-Task
by	O
Human	B-Task
Annotation	I-Task
:	O
Attributes	O
	
Annotating	B-Task
images	I-Task
with	O
class	O
labels	O
is	O
a	O
laborious	O
process	O
when	O
the	O
objects	O
represent	O
fine	O
-	O
grained	O
concepts	O
that	O
are	O
not	O
common	O
in	O
our	O
daily	O
lives	O
.	O
	
Attributes	O
provide	O
a	O
means	O
to	O
describe	O
such	O
fine	O
-	O
grained	O
concepts	O
.	O
	
They	O
model	O
shared	O
characteristics	O
of	O
objects	O
such	O
as	O
color	O
and	O
texture	O
which	O
are	O
easily	O
annotated	O
by	O
humans	O
and	O
converted	O
to	O
machine	O
-	O
readable	O
vector	O
format	O
.	O
	
The	O
set	O
of	O
descriptive	O
attributes	O
may	O
be	O
determined	O
by	O
language	O
experts	O
or	O
by	O
fine	O
-	O
grained	O
object	O
experts	O
.	O
	
The	O
association	O
between	O
an	O
attribute	O
and	O
a	O
category	O
can	O
be	O
a	O
binary	O
value	O
depicting	O
the	O
presence	O
/	O
absence	O
of	O
an	O
attribute	O
(	O
)	O
or	O
a	O
continuous	O
value	O
that	O
defines	O
the	O
confidence	O
level	O
of	O
an	O
attribute	O
(	O
)	O
for	O
each	O
class	O
.	O
	
We	O
write	O
per	O
-	O
class	O
attributes	O
as	O
:	O
where	O
can	O
be	O
or	O
a	O
real	O
number	O
that	O
associates	O
a	O
class	O
with	O
an	O
attribute	O
,	O
denotes	O
the	O
associated	O
class	O
and	O
is	O
the	O
number	O
of	O
attributes	O
.	O
	
Potentially	O
,	O
encodes	O
more	O
information	O
than	O
.	O
	
For	O
instance	O
,	O
for	O
classes	O
rat	O
,	O
monkey	O
,	O
whale	O
and	O
the	O
attribute	O
big	O
,	O
implies	O
that	O
in	O
terms	O
of	O
size	O
rat	O
monkey	O
whale	O
,	O
whereas	O
can	O
be	O
interpreted	O
as	O
rat	O
monkey	O
whale	O
which	O
is	O
more	O
accurate	O
.	O
	
We	O
empirically	O
show	O
the	O
benefit	O
of	O
over	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
.	O
	
In	O
practice	O
,	O
our	O
output	B-Method
embeddings	I-Method
use	O
a	O
per	O
-	O
class	O
vector	O
form	O
,	O
but	O
they	O
can	O
vary	O
in	O
dimensionality	O
(	O
)	O
.	O
	
For	O
the	O
rest	O
of	O
the	O
section	O
we	O
denote	O
the	O
output	O
embeddings	O
as	O
for	O
brevity	O
.	O
	
subsection	O
:	O
Learning	B-Task
Label	I-Task
Embeddings	I-Task
from	O
Text	O
	
In	O
this	O
section	O
,	O
we	O
describe	O
unsupervised	B-Task
and	I-Task
weakly	I-Task
-	I-Task
supervised	I-Task
label	I-Task
embeddings	I-Task
mined	O
from	O
text	O
.	O
	
With	O
these	O
label	B-Method
embeddings	I-Method
,	O
we	O
can	O
(	O
1	O
)	O
avoid	O
dependence	O
on	O
costly	O
manual	O
annotation	O
of	O
attributes	O
and	O
(	O
2	O
)	O
combine	O
the	O
embeddings	O
with	O
attributes	O
,	O
where	O
available	O
,	O
to	O
achieve	O
better	O
performance	O
.	O
	
Word2Vec	B-Method
	
(	O
φW	O
)	O
.	O
	
In	O
Word2Vec	B-Method
,	O
a	O
two	B-Method
-	I-Method
layer	I-Method
neural	I-Method
network	I-Method
is	O
trained	O
to	O
predict	O
a	O
set	O
of	O
target	O
words	O
from	O
a	O
set	O
of	O
context	O
words	O
.	O
	
Words	O
in	O
the	O
vocabulary	O
are	O
assigned	O
with	O
one	B-Method
-	I-Method
shot	I-Method
encoding	I-Method
so	O
that	O
the	O
first	O
layer	O
acts	O
as	O
a	O
look	O
-	O
up	O
table	O
to	O
retrieve	O
the	O
embedding	O
for	O
any	O
word	O
in	O
the	O
vocabulary	O
.	O
	
The	O
second	O
layer	O
predicts	O
the	O
target	O
word	O
(	O
s	O
)	O
via	O
hierarchical	B-Method
soft	I-Method
-	I-Method
max	I-Method
.	O
	
Word2Vec	B-Method
has	O
two	O
main	O
formulations	O
for	O
the	O
target	B-Task
prediction	I-Task
:	O
skip	B-Method
-	I-Method
gram	I-Method
(	I-Method
SG	I-Method
)	O
and	O
continuous	B-Method
bag	I-Method
-	I-Method
of	I-Method
-	I-Method
words	I-Method
(	O
CBOW	B-Method
)	O
.	O
	
In	O
SG	B-Method
,	O
words	O
within	O
a	O
local	O
context	O
window	O
are	O
predicted	O
from	O
the	O
centering	O
word	O
.	O
	
In	O
CBOW	B-Method
,	O
the	O
center	O
word	O
of	O
a	O
context	O
window	O
is	O
predicted	O
from	O
the	O
surrounding	O
words	O
.	O
	
Embeddings	B-Method
are	O
obtained	O
by	O
back	O
-	O
propagating	O
the	O
prediction	O
error	O
gradient	O
over	O
a	O
training	O
set	O
of	O
context	O
windows	O
sampled	O
from	O
the	O
text	O
corpus	O
.	O
	
GloVe	O
(	O
φG	O
)	O
.	O
	
GloVe	B-Method
incorporates	O
co	O
-	O
occurrence	O
statistics	O
of	O
words	O
that	O
frequently	O
appear	O
together	O
within	O
the	O
document	O
.	O
	
Intuitively	O
,	O
the	O
co	O
-	O
occurrence	O
statistics	O
encode	O
meaning	O
since	O
semantically	O
similar	O
words	O
such	O
as	O
“	O
ice	O
”	O
and	O
“	O
water	O
”	O
occur	O
together	O
more	O
frequently	O
than	O
semantically	O
dissimilar	O
words	O
such	O
as	O
“	O
ice	O
”	O
and	O
“	O
fashion	O
.	O
	
”	O
	
The	O
training	O
objective	O
is	O
to	O
learn	O
word	O
vectors	O
such	O
that	O
their	O
dot	O
product	O
equals	O
the	O
co	O
-	O
occurrence	O
probability	O
of	O
these	O
two	O
words	O
.	O
	
This	O
approach	O
has	O
recently	O
been	O
shown	O
to	O
outperform	O
Word2Vec	B-Method
on	O
the	O
word	B-Task
analogy	I-Task
prediction	I-Task
task	I-Task
.	O
	
Weakly	B-Method
-	I-Method
supervised	I-Method
Word2Vec	I-Method
(	I-Method
φW⁢ws	I-Method
)	O
.	O
	
The	O
standard	O
Word2Vec	B-Method
scans	O
the	O
entire	O
document	O
using	O
each	O
word	O
within	O
a	O
sample	O
window	O
as	O
the	O
target	O
for	O
prediction	B-Task
.	O
	
However	O
,	O
if	O
we	O
know	O
the	O
global	O
context	O
,	O
i.e.	O
the	O
topic	O
of	O
the	O
document	O
,	O
we	O
can	O
use	O
that	O
topic	O
as	O
our	O
target	O
.	O
	
For	O
instance	O
,	O
in	O
Wikipedia	O
,	O
the	O
entire	O
article	O
is	O
related	O
to	O
the	O
same	O
topic	O
.	O
	
Therefore	O
,	O
we	O
can	O
sample	O
our	O
context	O
windows	O
from	O
any	O
location	O
within	O
the	O
article	O
rather	O
than	O
searching	O
for	O
context	O
windows	O
where	O
the	O
topic	O
explicitly	O
appears	O
in	O
the	O
text	O
.	O
	
We	O
consider	O
this	O
method	O
as	O
a	O
weak	B-Method
form	I-Method
of	I-Method
supervision	I-Method
.	O
	
We	O
achieve	O
the	O
best	O
results	O
in	O
our	O
experiments	O
using	O
our	O
novel	O
variant	O
of	O
the	O
CBOW	B-Method
formulation	I-Method
.	O
	
Here	O
,	O
we	O
pre	O
-	O
train	O
the	O
first	O
layer	O
weights	O
using	O
standard	O
Word2Vec	B-Method
on	O
Wikipedia	O
,	O
and	O
fine	O
-	O
tune	O
the	O
second	B-Method
layer	I-Method
weights	I-Method
using	O
a	O
negative	B-Method
-	I-Method
sampling	I-Method
objective	I-Method
only	O
on	O
the	O
fine	O
-	O
grained	O
text	O
corpus	O
.	O
	
These	O
weights	O
correspond	O
to	O
the	O
final	O
output	O
embedding	O
.	O
	
The	O
negative	B-Task
sampling	I-Task
objective	I-Task
is	O
formulated	O
as	O
follows	O
:	O
where	O
and	O
are	O
the	O
label	O
embeddings	O
we	O
seek	O
to	O
learn	O
,	O
and	O
is	O
the	O
average	O
of	O
word	O
embeddings	O
within	O
a	O
context	O
window	O
around	O
word	O
.	O
	
consists	O
of	O
context	O
and	O
matching	O
targets	O
,	O
and	O
consists	O
of	O
the	O
same	O
and	O
mismatching	O
.	O
	
To	O
find	O
the	O
(	O
which	O
are	O
the	O
columns	O
of	O
the	O
first	O
-	O
layer	O
network	O
weights	O
)	O
,	O
we	O
take	O
them	O
from	O
a	O
standard	O
unsupervised	B-Method
Word2Vec	I-Method
model	I-Method
trained	O
on	O
Wikipedia	O
.	O
	
During	O
SGD	B-Method
,	O
the	O
are	O
fixed	O
and	O
we	O
update	O
each	O
sampled	O
and	O
at	O
each	O
iteration	O
.	O
	
Intuitively	O
,	O
we	O
seek	O
to	O
maximize	O
the	O
similarity	O
between	O
context	O
and	O
target	O
vectors	O
for	O
matching	O
pairs	O
,	O
and	O
minimize	O
it	O
for	O
mismatching	O
pairs	O
.	O
	
Bag	B-Method
-	I-Method
of	I-Method
-	I-Method
Words	I-Method
(	O
φB	O
)	O
.	O
	
BoW	B-Method
builds	O
a	O
“	O
bag	O
”	O
of	O
word	O
frequencies	O
by	O
counting	O
the	O
occurrence	O
of	O
each	O
vocabulary	O
word	O
that	O
appears	O
within	O
a	O
document	O
.	O
	
It	O
does	O
not	O
preserve	O
the	O
order	O
in	O
which	O
words	O
appear	O
in	O
a	O
document	O
,	O
so	O
it	O
disregards	O
the	O
grammar	O
.	O
	
We	O
collect	O
Wikipedia	O
articles	O
that	O
correspond	O
to	O
each	O
object	O
class	O
and	O
build	O
a	O
vocabulary	O
of	O
most	O
frequently	O
occurring	O
words	O
.	O
	
We	O
then	O
build	O
histograms	O
of	O
these	O
words	O
to	O
vectorize	O
our	O
classes	O
.	O
	
subsection	O
:	O
Hierarchical	B-Method
Embeddings	I-Method
	
Semantic	O
similarity	B-Method
measures	I-Method
how	O
closely	O
related	O
two	O
word	O
senses	O
are	O
according	O
to	O
their	O
meaning	O
.	O
	
Such	O
a	O
similarity	O
can	O
be	O
estimated	O
by	O
measuring	O
the	O
distance	O
between	O
terms	O
in	O
an	O
ontology	O
.	O
	
WordNet	B-Method
,	O
a	O
large	O
-	O
scale	O
hierarchical	O
database	O
of	O
over	O
100	O
,	O
000	O
words	O
for	O
English	O
,	O
provides	O
us	O
a	O
means	O
of	O
building	O
our	O
class	O
hierarchy	O
.	O
	
To	O
measure	O
similarity	B-Metric
,	O
we	O
use	O
Jiang	O
-	O
Conrath	O
(	O
)	O
,	O
Lin	O
(	O
)	O
and	O
path	O
(	O
)	O
similarities	O
formulated	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
We	O
denote	O
our	O
whole	O
family	O
of	O
hierarchical	O
embeddings	O
as	O
.	O
	
For	O
a	O
more	O
detailed	O
survey	O
,	O
the	O
reader	O
may	O
refer	O
to	O
.	O
	
section	O
:	O
Experiments	O
	
While	O
our	O
main	O
contribution	O
is	O
a	O
detailed	O
analysis	O
of	O
output	B-Task
embeddings	I-Task
,	O
good	O
image	B-Method
representations	I-Method
are	O
crucial	O
to	O
obtain	O
good	O
classification	B-Task
performance	O
.	O
	
In	O
Sec	O
.	O
	
[	O
reference	O
]	O
we	O
detail	O
datasets	O
,	O
input	O
and	O
output	O
embeddings	O
used	O
in	O
our	O
experiments	O
and	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
	
we	O
present	O
our	O
results	O
.	O
	
subsection	O
:	O
Experimental	O
Setting	O
	
We	O
evaluate	O
SJE	B-Method
on	O
three	O
datasets	O
:	O
Caltech	B-Material
UCSD	I-Material
Birds	I-Material
(	O
CUB	B-Material
)	O
and	O
Stanford	O
Dogs	O
(	O
Dogs	O
)	O
are	O
fine	O
-	O
grained	O
,	O
and	O
Animals	O
With	O
Attributes	O
(	O
AWA	O
)	O
is	O
a	O
standard	O
attribute	O
dataset	O
for	O
zero	B-Task
-	I-Task
shot	I-Task
classification	I-Task
.	O
	
CUB	B-Material
contains	O
11	O
,	O
788	O
images	O
of	O
200	O
bird	O
species	O
	
,	O
Dogs	O
contains	O
19	O
,	O
501	O
images	O
of	O
113	O
dog	O
breeds	O
and	O
AWA	O
contains	O
30	O
,	O
475	O
images	O
of	O
50	O
different	O
animals	O
.	O
	
We	O
use	O
a	O
truly	O
zero	B-Method
-	I-Method
shot	I-Method
setting	I-Method
where	O
the	O
train	O
,	O
val	O
,	O
and	O
test	O
sets	O
belong	O
to	O
mutually	O
exclusive	O
classes	O
.	O
	
We	O
employ	O
train	O
and	O
val	O
,	O
i.e.	O
disjoint	O
subsets	O
of	O
training	O
set	O
,	O
for	O
cross	B-Metric
-	I-Metric
validation	I-Metric
.	O
	
We	O
report	O
average	O
per	O
-	O
class	O
top	O
-	O
1	O
accuracy	B-Metric
on	O
the	O
test	O
set	O
.	O
	
For	O
CUB	B-Material
,	O
we	O
use	O
the	O
same	O
zero	O
-	O
shot	O
split	O
as	O
with	O
150	O
classes	O
for	O
the	O
train	O
+	O
val	O
set	O
and	O
50	O
disjoint	O
classes	O
for	O
the	O
test	O
set	O
.	O
	
AWA	O
has	O
a	O
predefined	O
split	O
for	O
40	O
train	O
+	O
val	O
and	O
10	O
test	O
classes	O
.	O
	
For	O
Dogs	O
,	O
we	O
use	O
approximately	O
the	O
same	O
ratio	O
of	O
classes	O
for	O
train	O
+	O
val	O
/	O
test	O
as	O
CUB	B-Material
,	O
i.e.	O
85	O
classes	O
for	O
train	O
+	O
val	O
and	O
28	O
classes	O
for	O
test	O
.	O
	
This	O
is	O
the	O
first	O
attempt	O
to	O
perform	O
zero	B-Method
-	I-Method
shot	I-Method
learning	I-Method
on	O
the	O
Dogs	O
dataset	O
.	O
	
Input	O
Embeddings	O
.	O
	
We	O
use	O
Fisher	O
Vectors	O
(	O
FV	B-Method
)	O
and	O
Deep	B-Method
CNN	I-Method
Features	I-Method
(	O
CNN	B-Method
)	O
.	O
	
FV	B-Method
aggregates	O
per	O
image	O
statistics	O
computed	O
from	O
local	O
image	O
patches	O
into	O
a	O
fixed	B-Method
-	I-Method
length	I-Method
local	I-Method
image	I-Method
descriptor	I-Method
.	O
	
We	O
extract	O
128	O
-	O
dim	O
SIFT	O
from	O
regular	O
grids	O
at	O
multiple	O
scales	O
,	O
reduce	O
them	O
to	O
64	O
-	O
dim	O
using	O
PCA	B-Method
,	O
build	O
a	O
visual	O
vocabulary	O
with	O
256	O
Gaussians	B-Method
and	O
finally	O
reduce	O
the	O
FVs	B-Method
to	O
4	O
,	O
096	O
.	O
	
As	O
an	O
alternative	O
,	O
we	O
extract	O
features	O
from	O
a	O
deep	B-Method
convolutional	I-Method
network	I-Method
.	O
	
Features	O
that	O
are	O
typically	O
obtained	O
from	O
the	O
activations	O
of	O
the	O
fully	B-Method
connected	I-Method
layers	I-Method
have	O
been	O
shown	O
to	O
induce	O
semantic	O
similarities	O
.	O
	
We	O
resize	O
each	O
image	O
to	O
224	O
224	O
and	O
feed	O
into	O
the	O
network	O
which	O
was	O
pre	O
-	O
trained	O
following	O
the	O
model	B-Method
architecture	I-Method
of	O
either	O
AlexNet	B-Method
or	O
GoogLeNet	B-Method
.	O
	
For	O
AlexNet	O
(	O
denoted	O
as	O
CNN	B-Method
)	O
we	O
use	O
the	O
4	O
,	O
096	O
-	O
dim	O
top	O
-	O
layer	O
hidden	O
unit	O
activations	O
(	O
âfc7â	O
)	O
as	O
features	O
,	O
and	O
for	O
GoogLeNet	O
(	O
denoted	O
as	O
GOOG	O
)	O
we	O
use	O
the	O
1	B-Method
,	I-Method
024	I-Method
-	I-Method
dim	I-Method
top	I-Method
-	I-Method
layer	I-Method
pooling	I-Method
units	I-Method
.	O
	
For	O
both	O
networks	O
,	O
we	O
used	O
the	O
publicly	O
-	O
available	O
BVLC	B-Method
implementations	I-Method
.	O
	
We	O
do	O
not	O
perform	O
any	O
task	B-Method
-	I-Method
specific	I-Method
pre	I-Method
-	I-Method
processing	I-Method
,	O
such	O
as	O
cropping	O
foreground	O
objects	O
or	O
detecting	O
parts	O
.	O
	
Output	B-Method
Embeddings	I-Method
.	O
	
AWA	O
classes	O
have	O
85	O
binary	O
and	O
continuous	O
attributes	O
.	O
	
CUB	B-Material
classes	O
have	O
312	O
continuous	O
attributes	O
and	O
the	O
continuous	O
values	O
are	O
thresholded	O
around	O
the	O
mean	O
to	O
obtain	O
binary	O
attributes	O
.	O
	
The	O
Dogs	O
dataset	O
does	O
not	O
have	O
human	O
-	O
annotated	O
attributes	O
available	O
.	O
	
We	O
train	O
Word2Vec	B-Method
(	I-Method
)	I-Method
and	O
GloVe	B-Method
(	I-Method
)	O
on	O
the	O
English	O
-	O
language	O
Wikipedia	O
from	O
13.02.2014	O
.	O
	
We	O
first	O
pre	O
-	O
process	O
it	O
by	O
replacing	O
the	O
class	O
-	O
names	O
,	O
i.e.	O
black	O
-	O
footed	O
albatross	O
,	O
with	O
alternative	O
unique	O
names	O
,	O
i.e.	O
scientific	O
name	O
,	O
phoebastrianigripes	O
.	O
	
We	O
cross	O
-	O
validate	O
the	O
skip	O
-	O
window	O
size	O
and	O
embedding	O
dimensions	O
.	O
	
For	O
our	O
proposed	O
weakly	B-Method
-	I-Method
supervised	I-Method
Word2Vec	I-Method
(	I-Method
)	I-Method
,	O
we	O
use	O
the	O
same	O
embedding	O
dimensions	O
as	O
the	O
plain	O
Word2Vec	O
(	O
)	O
.	O
	
For	O
BoW	B-Method
,	O
we	O
download	O
the	O
Wikipedia	O
articles	O
that	O
correspond	O
to	O
each	O
class	O
and	O
build	O
the	O
vocabulary	O
by	O
omitting	O
least	O
-	O
and	O
most	O
-	O
frequently	O
occurring	O
words	O
.	O
	
We	O
cross	O
-	O
validate	O
the	O
vocabulary	O
size	O
.	O
	
is	O
a	O
histogram	O
of	O
the	O
vocabulary	O
words	O
as	O
they	O
appear	O
in	O
the	O
respective	O
document	O
.	O
	
For	O
hierarchical	B-Task
embeddings	I-Task
(	O
)	O
,	O
we	O
use	O
the	O
WordNet	O
hierarchy	O
spanning	O
our	O
classes	O
and	O
their	O
ancestors	O
up	O
to	O
the	O
root	O
of	O
the	O
tree	O
.	O
	
We	O
employ	O
the	O
widely	O
used	O
NLTK	B-Method
library	I-Method
for	O
building	O
the	O
hierarchy	O
and	O
measuring	O
the	O
similarity	O
between	O
nodes	O
.	O
	
Therefore	O
,	O
each	O
vector	O
is	O
populated	O
with	O
similarity	B-Method
measures	I-Method
of	O
the	O
class	O
to	O
all	O
other	O
classes	O
.	O
	
Combination	B-Method
of	I-Method
output	I-Method
embeddings	I-Method
.	O
	
We	O
explore	O
combinations	O
of	O
five	O
types	O
of	O
output	O
embeddings	O
:	O
supervised	O
attributes	O
,	O
unsupervised	O
Word2Vec	O
,	O
GloVe	B-Method
,	O
BoW	B-Method
and	O
WordNet	B-Method
-	I-Method
derived	I-Method
similarity	I-Method
embeddings	I-Method
.	O
	
We	O
either	O
concatenate	O
(	O
cnc	B-Method
)	O
or	O
combine	O
(	O
cmb	B-Method
)	O
different	O
embeddings	B-Method
.	O
	
In	O
cnc	B-Method
,	O
for	O
instance	O
in	O
AWA	O
,	O
85	O
-	O
dim	O
and	O
400	O
-	O
dim	O
would	O
be	O
merged	O
to	O
485	O
-	O
dim	O
output	O
embeddings	O
.	O
	
In	O
this	O
case	O
,	O
if	O
we	O
use	O
1	O
,	O
024	O
-	O
dim	O
GOOG	O
as	O
input	O
embeddings	O
,	O
we	O
learn	O
a	O
single	O
1	O
,	O
024	O
485	O
-	O
dim	O
.	O
	
In	O
cmb	B-Method
,	O
we	O
first	O
learn	O
1	O
,	O
024	O
85	O
-	O
dim	O
and	O
1	O
,	O
024	O
400	O
-	O
dim	O
and	O
then	O
cross	O
-	O
validate	O
the	O
coefficients	O
to	O
determine	O
the	O
amount	O
each	O
embedding	O
contributes	O
to	O
the	O
final	O
score	O
.	O
	
subsection	O
:	O
Experimental	O
Results	O
	
In	O
this	O
section	O
,	O
we	O
evaluate	O
several	O
output	B-Method
embeddings	I-Method
on	O
the	O
CUB	B-Material
,	O
AWA	O
and	O
Dogs	O
datasets	O
.	O
	
Discrete	O
vs	O
Continuous	O
Attributes	O
.	O
	
Attribute	B-Method
representations	I-Method
are	O
defined	O
as	O
a	O
vector	O
per	O
class	O
,	O
or	O
a	O
column	O
of	O
the	O
(	O
class	O
attribute	O
)	O
matrix	O
.	O
	
These	O
vectors	O
(	O
85	O
-	O
dim	O
for	O
AWA	O
,	O
312	O
-	O
dim	O
for	O
CUB	B-Material
)	O
can	O
either	O
model	O
the	O
presence	O
/	O
absence	O
(	O
)	O
or	O
the	O
confidence	O
level	O
(	O
)	O
of	O
each	O
attribute	O
.	O
	
We	O
show	O
that	O
continuous	O
attributes	O
indeed	O
encode	O
more	O
semantics	O
than	O
binary	O
attributes	O
by	O
observing	O
a	O
substantial	O
improvement	O
with	O
over	O
with	O
deep	O
features	O
(	O
Tab	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
Overall	O
,	O
CNN	B-Method
outperforms	O
FV	B-Method
,	O
while	O
GOOG	B-Method
gives	O
the	O
best	O
performing	O
results	O
;	O
therefore	O
in	O
the	O
following	O
,	O
we	O
comment	O
only	O
on	O
our	O
results	O
obtained	O
using	O
GOOG	B-Method
.	O
	
On	O
CUB	B-Material
,	O
i.e.	O
a	O
fine	O
-	O
grained	O
dataset	O
,	O
obtains	O
37.8	O
%	O
accuracy	B-Metric
,	O
which	O
is	O
significantly	O
above	O
the	O
SoA	O
(	O
26.9	O
%	O
)	O
.	O
	
Moreover	O
,	O
achieves	O
an	O
impressive	O
50.1	O
%	O
accuracy	B-Metric
;	O
outperforming	O
the	O
SoA	O
by	O
a	O
large	O
margin	O
.	O
	
We	O
observe	O
the	O
same	O
trend	O
for	O
AWA	O
,	O
which	O
is	O
a	O
benchmark	O
dataset	O
for	O
zero	B-Task
-	I-Task
shot	I-Task
learning	I-Task
.	O
	
On	O
AWA	O
,	O
obtains	O
52.0	O
%	O
accuracy	B-Metric
and	O
improves	O
the	O
accuracy	B-Metric
substantially	O
to	O
66.7	O
%	O
,	O
significantly	O
outperforming	O
the	O
SoA	O
(	O
48.5	O
%	O
)	O
.	O
	
To	O
summarize	O
,	O
we	O
have	O
shown	O
that	O
improves	O
the	O
performance	O
of	O
using	O
deep	O
features	O
,	O
which	O
indicates	O
that	O
with	O
,	O
the	O
SJE	B-Method
method	O
learns	O
a	O
matrix	O
that	O
better	O
approximates	O
the	O
compatibility	O
of	O
images	O
and	O
side	O
information	O
than	O
.	O
	
Learned	O
Embeddings	O
from	O
Text	O
.	O
	
As	O
the	O
visual	O
similarity	O
between	O
objects	O
in	O
different	O
classes	O
increases	O
,	O
e.g.	O
in	O
fine	O
-	O
grained	O
datasets	O
,	O
the	O
cost	O
of	O
collecting	O
attributes	O
also	O
increases	O
.	O
	
Therefore	O
,	O
we	O
aim	O
to	O
extract	O
class	O
similarities	O
automatically	O
from	O
unlabeled	O
online	O
textual	O
resources	O
.	O
	
We	O
evaluate	O
three	O
methods	O
,	O
Word2Vec	B-Method
(	I-Method
)	O
,	O
GloVe	B-Method
(	I-Method
)	O
and	O
the	O
historically	O
most	O
commonly	O
-	O
used	O
method	O
BoW	B-Method
(	O
)	O
.	O
	
We	O
build	O
and	O
on	O
the	O
entire	O
English	O
Wikipedia	O
dump	O
.	O
	
Note	O
that	O
the	O
plain	O
Word2Vec	O
was	O
used	O
in	O
;	O
however	O
,	O
rather	O
than	O
using	O
Word2Vec	B-Method
in	O
an	O
averaging	B-Method
mechanism	I-Method
,	O
we	O
pre	O
-	O
process	O
the	O
Wikipedia	O
as	O
described	O
in	O
Sec	O
[	O
reference	O
]	O
so	O
that	O
our	O
class	O
names	O
are	O
directly	O
present	O
in	O
the	O
Word2Vec	O
vocabulary	O
.	O
	
This	O
leads	O
to	O
a	O
significant	O
accuracy	B-Metric
improvement	O
.	O
	
For	O
we	O
use	O
a	O
subset	O
of	O
Wikipedia	O
populated	O
only	O
with	O
articles	O
that	O
correspond	O
to	O
our	O
classes	O
.	O
	
On	O
CUB	B-Material
(	O
Tab	O
.	O
	
[	O
reference	O
]	O
)	O
	
,	O
the	O
best	O
accuracy	B-Metric
is	O
observed	O
with	O
(	O
28.4	O
%	O
)	O
improving	O
the	O
supervised	O
SoA	O
(	O
26.9	O
%	O
,	O
Tab	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
This	O
is	O
promising	O
and	O
impressive	O
since	O
does	O
not	O
use	O
any	O
human	O
supervision	O
.	O
	
On	O
AWA	O
(	O
Tab	O
.	O
	
[	O
reference	O
]	O
)	O
	
,	O
the	O
best	O
accuracy	B-Metric
is	O
observed	O
with	O
(	O
58.8	O
%	O
)	O
followed	O
by	O
(	O
51.2	O
%	O
)	O
,	O
improving	O
the	O
supervised	O
SoA	O
(	O
48.5	O
%	O
)	O
significantly	O
.	O
	
On	O
Dogs	O
(	O
Tab	O
.	O
	
[	O
reference	O
]	O
)	O
	
,	O
the	O
best	O
accuracy	B-Metric
is	O
obtained	O
with	O
(	O
33.0	O
%	O
)	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
using	O
(	O
19.6	O
%	O
)	O
and	O
(	O
17.8	O
%	O
)	O
leads	O
to	O
significantly	O
lower	O
accuracies	B-Metric
.	O
	
Unlike	O
birds	O
,	O
different	O
dog	O
breeds	O
belong	O
to	O
the	O
same	O
species	O
and	O
thus	O
they	O
share	O
a	O
common	O
scientific	O
name	O
.	O
	
As	O
a	O
result	O
,	O
our	O
method	O
of	O
cleanly	B-Task
pre	I-Task
-	I-Task
processing	I-Task
Wikipedia	I-Task
by	O
replacing	O
the	O
occurrences	O
of	O
bird	O
names	O
with	O
a	O
unique	O
scientific	O
name	O
was	O
not	O
possible	O
for	O
Dogs	O
.	O
	
This	O
may	O
lead	O
to	O
vectors	O
obtained	O
from	O
Wikipedia	O
for	O
dogs	O
that	O
are	O
vulnerable	O
to	O
variation	O
in	O
nomenclature	O
.	O
	
In	O
summary	O
,	O
our	O
results	O
indicate	O
no	O
winner	O
among	O
,	O
and	O
.	O
	
These	O
embeddings	O
may	O
be	O
task	O
specific	O
and	O
complement	O
each	O
other	O
.	O
	
We	O
investigate	O
the	O
complementarity	O
of	O
embeddings	O
in	O
the	O
following	O
sections	O
.	O
	
Effect	O
of	O
Text	O
Corpus	O
.	O
	
For	O
and	O
,	O
we	O
analyze	O
the	O
effects	O
of	O
three	O
text	O
corpora	O
(	O
B	O
,	O
W	O
,	O
B	O
+	O
W	O
)	O
with	O
varying	O
size	O
and	O
specificity	O
.	O
	
We	O
build	O
our	O
specialized	O
bird	O
corpus	O
(	O
B	O
)	O
by	O
collecting	O
bird	O
-	O
related	O
information	O
from	O
various	O
online	O
resources	O
,	O
i.e.	O
audubon.org	O
,	O
birdweb.org	O
,	O
allaboutbirds.org	O
and	O
BNA	O
.	O
	
In	O
combination	O
,	O
this	O
corresponds	O
to	O
50	O
MB	O
of	O
bird	O
-	O
related	O
text	O
.	O
	
We	O
use	O
the	O
English	O
-	O
language	O
Wikipedia	O
from	O
13.02.2014	O
as	O
our	O
large	O
and	O
general	O
corpus	O
(	O
W	O
)	O
which	O
is	O
40	O
GB	O
of	O
text	O
.	O
	
Finally	O
,	O
we	O
combine	O
B	O
and	O
W	O
to	O
build	O
a	O
large	O
-	O
scale	O
text	O
corpus	O
enriched	O
with	O
bird	O
specific	O
text	O
(	O
B	O
+	O
W	O
)	O
.	O
	
On	O
W	O
and	O
B	O
+	O
W	O
,	O
a	O
small	O
window	O
size	O
(	O
10	O
for	O
and	O
20	O
for	O
)	O
;	O
on	O
B	O
,	O
a	O
large	O
window	O
size	O
(	O
35	O
for	O
and	O
50	O
for	O
)	O
is	O
required	O
.	O
	
We	O
choose	O
parameters	O
after	O
a	O
grid	B-Method
search	I-Method
.	O
	
Increased	O
specificity	O
of	O
the	O
text	O
corpus	O
implies	O
semantic	O
consistency	O
throughout	O
the	O
text	O
.	O
	
Therefore	O
,	O
large	O
context	O
windows	O
capture	O
semantics	O
well	O
in	O
our	O
bird	O
specific	O
(	O
B	O
)	O
corpus	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
W	O
is	O
organized	O
alphabetically	O
w.r.t	O
.	O
	
the	O
document	O
title	O
;	O
hence	O
,	O
a	O
large	O
sampling	O
window	O
can	O
include	O
content	O
from	O
another	O
article	O
that	O
is	O
adjacent	O
to	O
the	O
target	O
word	O
alphabetically	O
.	O
	
Here	O
,	O
small	O
windows	O
capture	O
semantics	O
better	O
by	O
looking	O
at	O
the	O
text	O
locally	O
.	O
	
We	O
report	O
our	O
results	O
in	O
Tab	O
.	O
	
[	O
reference	O
]	O
.	O
	
Using	O
,	O
B	O
+	O
W	O
(	O
26.1	O
%	O
)	O
gives	O
the	O
highest	O
accuracy	B-Metric
,	O
followed	O
by	O
W	O
(	O
24.2	O
%	O
)	O
.	O
	
One	O
possible	O
reason	O
is	O
that	O
when	O
the	O
semantic	O
similarity	O
is	O
modeled	O
with	O
cooccurrence	O
statistics	O
,	O
output	O
embeddings	O
become	O
more	O
informative	O
with	O
the	O
increasing	O
corpus	O
size	O
,	O
since	O
the	O
probability	O
of	O
cooccurrence	O
of	O
similar	O
concepts	O
increases	O
.	O
	
Using	O
,	O
the	O
accuracy	B-Metric
obtained	O
with	O
B	O
(	O
22.5	O
%	O
)	O
is	O
already	O
higher	O
than	O
the	O
-	O
based	O
SoA	O
(	O
22.3	O
%	O
)	O
,	O
illustrating	O
the	O
benefit	O
of	O
using	O
fine	O
-	O
grained	O
text	O
for	O
fine	B-Task
-	I-Task
grained	I-Task
tasks	I-Task
.	O
	
Another	O
advantage	O
of	O
using	O
B	O
is	O
that	O
,	O
since	O
it	O
is	O
short	O
,	O
building	O
is	O
efficient	O
.	O
	
Moreover	O
,	O
building	O
with	O
B	O
does	O
not	O
require	O
any	O
annotation	O
effort	O
.	O
	
Building	O
using	O
W	B-Method
(	O
28.4	O
%	O
)	O
gives	O
the	O
highest	O
accuracy	B-Metric
,	O
followed	O
by	O
W	B-Method
+	I-Method
B	I-Method
(	O
27.5	O
%	O
)	O
which	O
improves	O
the	O
supervised	O
SoA	O
(	O
26.9	O
%	O
)	O
.	O
	
We	O
speculate	O
that	O
since	O
Word2Vec	B-Method
is	O
a	O
variant	O
of	O
the	O
Feedforward	B-Method
Neural	I-Method
Network	I-Method
Language	I-Method
Model	I-Method
(	I-Method
FNNLM	I-Method
)	I-Method
,	O
a	O
deep	B-Method
architecture	I-Method
,	O
it	O
may	O
learn	O
more	O
from	O
negative	O
data	O
than	O
positives	O
.	O
	
This	O
was	O
also	O
observed	O
for	O
CNN	O
features	O
learned	O
with	O
a	O
large	O
number	O
of	O
unlabeled	O
surrogate	O
classes	O
.	O
	
Additionally	O
,	O
we	O
propose	O
a	O
weakly	B-Method
-	I-Method
supervised	I-Method
alternative	I-Method
to	O
Word2Vec	B-Method
framework	I-Method
(	O
,	O
Sec	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
The	O
weak	O
-	O
supervision	O
comes	O
from	O
using	O
the	O
specialized	O
B	O
corpus	O
to	O
fine	O
-	O
tune	O
the	O
weights	O
of	O
the	O
network	O
and	O
model	O
the	O
bird	O
-	O
related	O
information	O
.	O
	
With	O
alone	O
,	O
we	O
obtain	O
21.0	O
%	O
accuracy	B-Metric
.	O
	
However	O
,	O
when	O
it	O
is	O
combined	O
with	O
(	O
28.4	O
%	O
)	O
,	O
the	O
accuracy	B-Metric
improves	O
to	O
29.7	O
%	O
.	O
	
Compared	O
to	O
the	O
results	O
in	O
Tab	O
.	O
	
[	O
reference	O
]	O
	
,	O
29.7	O
%	O
is	O
the	O
highest	O
accuracy	B-Metric
obtained	O
using	O
unsupervised	B-Method
embeddings	I-Method
.	O
	
We	O
regard	O
these	O
results	O
as	O
a	O
very	O
encouraging	O
evidence	O
that	O
Word2Vec	B-Method
representations	I-Method
can	O
indeed	O
be	O
made	O
more	O
discriminative	O
for	O
fine	B-Task
-	I-Task
grained	I-Task
zero	I-Task
-	I-Task
shot	I-Task
learning	I-Task
by	O
integrating	O
a	O
fine	O
-	O
grained	O
text	O
corpus	O
directly	O
to	O
the	O
output	B-Task
embedding	I-Task
learning	I-Task
problem	I-Task
.	O
	
Hierarchical	B-Method
Embeddings	I-Method
.	O
	
The	O
hierarchical	O
organization	O
of	O
concepts	O
typically	O
embodies	O
a	O
fair	O
amount	O
of	O
hidden	O
information	O
about	O
language	O
,	O
such	O
as	O
synonymy	O
,	O
semantic	O
relations	O
,	O
etc	O
.	O
	
Therefore	O
,	O
semantic	O
relatedness	O
defined	O
by	O
hierarchical	O
distance	O
between	O
classes	O
can	O
form	O
numerical	O
vectors	O
to	O
be	O
used	O
as	O
output	B-Task
embeddings	I-Task
for	O
zero	B-Task
-	I-Task
shot	I-Task
learning	I-Task
.	O
	
We	O
build	O
ontological	O
relationships	O
between	O
our	O
classes	O
using	O
the	O
WordNet	B-Method
taxonomy	I-Method
.	O
	
Due	O
to	O
its	O
large	O
size	O
,	O
WordNet	O
encapsulates	O
all	O
of	O
our	O
AWA	O
and	O
Dog	O
classes	O
.	O
	
For	O
CUB	B-Material
,	O
the	O
high	O
level	O
bird	O
species	O
,	O
i.e.	O
albatross	O
,	O
appear	O
as	O
synsets	O
in	O
WordNet	O
,	O
but	O
the	O
specific	O
bird	O
names	O
,	O
i.e.	O
black	O
-	O
footed	O
albatross	O
,	O
are	O
not	O
always	O
present	O
.	O
	
Therefore	O
we	O
take	O
the	O
hierarchy	O
up	O
to	O
high	O
level	O
bird	O
species	O
as	O
-	O
is	O
and	O
we	O
assume	O
the	O
specific	O
bird	O
classes	O
are	O
all	O
at	O
the	O
bottom	O
of	O
the	O
hierarchy	O
located	O
with	O
the	O
same	O
distance	O
to	O
their	O
immediate	O
ancestors	O
.	O
	
The	O
WordNet	O
hierarchy	O
contains	O
319	O
nodes	O
for	O
CUB	B-Material
(	O
200	O
classes	O
)	O
,	O
104	O
nodes	O
for	O
AWA	O
(	O
50	O
classes	O
)	O
and	O
163	O
nodes	O
for	O
Dogs	O
(	O
113	O
classes	O
)	O
.	O
	
We	O
measure	O
the	O
distance	O
between	O
classes	O
using	O
the	O
similarity	B-Method
measures	I-Method
from	O
Sec	O
[	O
reference	O
]	O
.	O
	
While	O
as	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
different	O
hierarchical	O
similarity	B-Method
measures	I-Method
have	O
very	O
different	O
behaviors	O
on	O
each	O
dataset	O
.	O
	
The	O
best	O
performing	O
obtains	O
51.2	O
%	O
(	O
Tab	O
.	O
	
[	O
reference	O
]	O
)	O
	
accuracy	B-Metric
on	O
AWA	O
which	O
reaches	O
our	O
(	O
52.0	O
%	O
)	O
and	O
improves	O
(	O
44.9	O
%	O
)	O
significantly	O
.	O
	
On	O
CUB	B-Material
,	O
obtains	O
20.6	O
%	O
(	O
Tab	O
.	O
	
[	O
reference	O
]	O
)	O
which	O
remain	O
below	O
our	O
(	O
37.8	O
%	O
)	O
and	O
approaches	O
(	O
22.1	O
%	O
)	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
on	O
Dogs	O
obtains	O
24.3	O
%	O
(	O
Tab	O
.	O
	
[	O
reference	O
]	O
)	O
which	O
is	O
significantly	O
higher	O
than	O
the	O
unsupervised	B-Method
text	I-Method
embeddings	I-Method
(	O
19.6	O
%	O
)	O
and	O
(	O
17.8	O
%	O
)	O
.	O
	
Combining	O
Output	B-Method
Embeddings	I-Method
.	O
	
In	O
this	O
section	O
,	O
we	O
combine	O
output	O
embeddings	O
obtained	O
through	O
human	O
annotation	O
(	O
)	O
,	O
from	O
text	O
(	O
)	O
and	O
from	O
hierarchies	O
(	O
)	O
.	O
	
As	O
a	O
reference	O
,	O
Tab	O
.	O
	
[	O
reference	O
]	O
summarizes	O
the	O
results	O
obtained	O
using	O
one	O
output	B-Method
embedding	I-Method
at	O
a	O
time	O
.	O
	
Our	O
intuition	O
is	O
that	O
because	O
the	O
different	O
embeddings	O
attempt	O
to	O
encapsulate	O
different	O
information	O
,	O
accuracy	B-Metric
should	O
improve	O
when	O
multiple	O
embeddings	O
are	O
combined	O
.	O
	
We	O
can	O
observe	O
this	O
complementarity	O
either	O
by	O
simple	O
concatenation	B-Method
(	O
cnc	B-Method
)	O
or	O
systematically	O
combining	O
(	O
cmb	B-Method
)	I-Method
output	I-Method
embeddings	I-Method
(	O
Sec	O
.	O
	
[	O
reference	O
]	O
)	O
also	O
known	O
as	O
early	O
/	O
late	O
fusion	O
.	O
	
For	O
cnc	B-Method
,	O
we	O
perform	O
full	O
SJE	B-Method
training	O
and	O
cross	B-Method
-	I-Method
validation	I-Method
on	O
the	O
concatenated	O
output	O
embeddings	O
.	O
	
For	O
cmb	B-Method
,	O
we	O
learn	O
joint	O
embeddings	O
for	O
each	O
output	O
separately	O
(	O
which	O
is	O
trivially	O
parallelized	O
)	O
,	O
and	O
find	O
ensemble	O
weights	O
via	O
cross	B-Method
-	I-Method
validation	I-Method
.	O
	
In	O
contrast	O
to	O
the	O
cnc	B-Method
method	I-Method
,	O
no	O
additional	O
joint	B-Method
training	I-Method
is	O
used	O
,	O
although	O
it	O
can	O
improve	O
performance	O
in	O
practice	O
.	O
	
We	O
observe	O
(	O
Tab	O
.	O
[	O
reference	O
]	O
)	O
in	O
almost	O
all	O
cases	O
cmb	B-Method
outperforms	O
cnc	B-Method
.	O
	
We	O
analyze	O
the	O
combination	O
of	O
unsupervised	B-Method
embeddings	I-Method
(	O
)	O
.	O
	
On	O
AWA	O
,	O
(	O
58.8	O
%	O
,	O
Tab	O
.	O
	
[	O
reference	O
]	O
)	O
combined	O
with	O
(	O
51.2	O
%	O
,	O
Tab	O
.	O
	
[	O
reference	O
]	O
)	O
	
,	O
we	O
achieve	O
60.1	O
%	O
(	O
Tab	O
.	O
	
[	O
reference	O
]	O
)	O
which	O
improves	O
the	O
SoA	O
(	O
48.5	O
%	O
,	O
Tab	O
.	O
	
[	O
reference	O
]	O
)	O
by	O
a	O
large	O
margin	O
.	O
	
On	O
CUB	B-Material
,	O
combining	O
(	O
24.2	O
%	O
,	O
Tab	O
.	O
	
[	O
reference	O
]	O
)	O
with	O
(	O
20.6	O
%	O
,	O
Tab	O
.	O
	
[	O
reference	O
]	O
)	O
,	O
we	O
get	O
29.9	O
%	O
(	O
Tab	O
.	O
	
[	O
reference	O
]	O
)	O
and	O
improve	O
the	O
supervised	O
-	O
SoA	O
(	O
26.9	O
%	O
,	O
Tab	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
Supporting	O
our	O
initial	O
claim	O
,	O
unsupervised	O
output	O
embeddings	O
obtained	O
from	O
different	O
sources	O
,	O
i.e.	O
text	O
vs	O
hierarchy	O
,	O
seem	O
to	O
be	O
complementary	O
to	O
each	O
other	O
.	O
	
In	O
some	O
cases	O
,	O
cmb	B-Method
performs	O
worse	O
than	O
cnc	B-Method
;	O
e.g.	O
28.2	O
%	O
versus	O
35.1	O
%	O
when	O
using	O
with	O
on	O
Dogs	O
.	O
	
In	O
most	O
other	O
cases	O
cmb	B-Method
performs	O
equivalent	O
or	O
better	O
.	O
	
Combining	O
supervised	B-Method
(	I-Method
)	O
and	O
unsupervised	B-Method
embeddings	I-Method
(	O
)	O
shows	O
a	O
similar	O
trend	O
.	O
	
On	O
AWA	O
,	O
combining	O
(	O
66.7	O
%	O
,	O
Tab	O
.	O
	
[	O
reference	O
]	O
)	O
with	O
and	O
leads	O
to	O
73.9	O
%	O
(	O
Tab	O
.	O
	
[	O
reference	O
]	O
)	O
which	O
significantly	O
exceeds	O
the	O
SoA	O
(	O
48.5	O
%	O
,	O
Tab	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
On	O
CUB	B-Material
,	O
combining	O
with	O
and	O
leads	O
to	O
51.7	O
%	O
(	O
Tab	O
.	O
	
[	O
reference	O
]	O
)	O
,	O
improving	O
both	O
the	O
results	O
we	O
obtained	O
with	O
(	O
50.1	O
%	O
,	O
Tab	O
.	O
	
[	O
reference	O
]	O
)	O
and	O
the	O
supervised	O
-	O
SoA	O
(	O
26.9	O
%	O
,	O
Tab	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
We	O
have	O
shown	O
with	O
these	O
experiments	O
that	O
output	O
embeddings	O
obtained	O
through	O
human	O
annotation	O
can	O
also	O
be	O
complemented	O
with	O
unsupervised	B-Method
output	I-Method
embeddings	I-Method
using	O
the	O
SJE	B-Method
framework	O
.	O
	
Qualitative	O
Results	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
top	O
-	O
5	O
highest	O
ranked	O
images	O
for	O
classes	O
chimpanzee	O
,	O
leopard	O
and	O
seal	O
that	O
are	O
selected	O
from	O
10	O
test	O
classes	O
of	O
AWA	O
.	O
	
We	O
use	O
GOOG	O
as	O
input	O
embeddings	O
and	O
as	O
output	O
embeddings	O
we	O
use	O
supervised	B-Method
,	O
the	O
best	O
performing	O
unsupervised	B-Method
embedding	I-Method
on	O
AWA	O
(	O
)	O
,	O
and	O
the	O
combination	O
of	O
the	O
two	O
(	O
)	O
.	O
	
For	O
the	O
class	O
chimpanzee	O
,	O
emphasizes	O
that	O
chimpanzees	O
live	O
on	O
trees	O
,	O
which	O
is	O
among	O
the	O
list	O
of	O
attributes	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
models	O
the	O
social	O
nature	O
of	O
the	O
animal	O
,	O
ranking	O
a	O
group	O
of	O
chimpanzees	O
interacting	O
with	O
each	O
other	O
at	O
the	O
highest	O
.	O
	
Indeed	O
this	O
information	O
can	O
easily	O
be	O
retrieved	O
from	O
Wikipedia	O
.	O
	
synthesizes	O
both	O
aspects	O
.	O
	
Similarly	O
,	O
for	O
leopard	O
puts	O
an	O
emphasis	O
on	O
the	O
head	O
where	O
we	O
can	O
observe	O
several	O
of	O
the	O
attributes	O
,	O
i.e.	O
color	O
,	O
spotted	O
,	O
whereas	O
seems	O
to	O
place	O
the	O
animal	O
in	O
the	O
wild	O
.	O
	
combines	O
both	O
aspects	O
.	O
	
In	O
case	O
of	O
class	B-Task
seal	I-Task
,	O
retrieves	O
images	O
related	O
to	O
water	O
and	O
ranks	O
whales	O
and	O
seals	O
highest	O
,	O
whereas	O
adds	O
more	O
context	O
by	O
placing	O
seals	O
in	O
the	O
icy	O
natural	O
environment	O
and	O
within	O
groups	O
.	O
	
Finally	O
,	O
ranks	O
seal	O
-	O
shaped	O
animals	O
on	O
ice	O
,	O
close	O
to	O
water	O
and	O
within	O
groups	O
the	O
highest	O
.	O
	
We	O
find	O
these	O
qualitative	O
results	O
interesting	O
as	O
they	O
depict	O
how	O
(	O
1	O
)	O
unsupervised	O
embeddings	O
capture	O
nameable	O
semantics	O
about	O
objects	O
and	O
(	O
2	O
)	O
different	O
output	O
embeddings	O
are	O
semantically	O
complementary	O
for	O
zero	B-Method
-	I-Method
shot	I-Method
learning	I-Method
.	O
	
section	O
:	O
Conclusion	O
	
We	O
evaluated	O
the	O
Structured	B-Method
Joint	I-Method
Embedding	I-Method
(	O
SJE	B-Method
)	O
framework	O
on	O
supervised	O
attributes	O
and	O
unsupervised	O
output	O
embeddings	O
obtained	O
from	O
hierarchies	O
and	O
unlabeled	O
text	O
corpora	O
.	O
	
We	O
proposed	O
a	O
novel	O
weakly	B-Method
-	I-Method
supervised	I-Method
label	I-Method
embedding	I-Method
technique	I-Method
.	O
	
By	O
combining	O
multiple	O
output	O
embeddings	O
(	O
cmb	B-Method
)	O
,	O
we	O
established	O
a	O
new	O
SoA	O
on	O
AWA	O
(	O
73.9	O
%	O
,	O
Tab	O
.	O
	
[	O
reference	O
]	O
)	O
and	O
CUB	B-Material
(	O
51.7	O
%	O
,	O
Tab	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
Moreover	O
,	O
we	O
showed	O
that	O
unsupervised	B-Task
zero	I-Task
-	I-Task
shot	I-Task
learning	I-Task
with	O
SJE	B-Method
improves	O
the	O
SoA	O
,	O
to	O
60.1	O
%	O
on	O
AWA	O
and	O
29.9	O
%	O
on	O
CUB	B-Material
,	O
and	O
obtains	O
35.1	O
%	O
on	O
Dogs	O
(	O
Tab	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
We	O
emphasize	O
the	O
following	O
take	O
-	O
home	O
points	O
:	O
(	O
1	O
)	O
Unsupervised	B-Method
label	I-Method
embeddings	I-Method
learned	O
from	O
text	O
corpora	O
yield	O
compelling	O
zero	O
-	O
shot	O
results	O
,	O
outperforming	O
previous	O
supervised	O
SoA	O
on	O
AWA	O
and	O
CUB	B-Material
	
(	O
Tab	O
.	O
	
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
)	O
.	O
	
(	O
2	O
)	O
Integrating	O
specialized	O
text	O
corpora	O
helps	O
due	O
to	O
incorporating	O
more	O
fine	O
-	O
grained	O
information	O
to	O
output	O
embeddings	O
(	O
Tab	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
(	O
3	O
)	O
Combining	O
unsupervised	B-Method
output	I-Method
embeddings	I-Method
improve	O
the	O
zero	B-Metric
-	I-Metric
shot	I-Metric
performance	I-Metric
,	O
suggesting	O
that	O
they	O
provide	O
complementary	O
information	O
(	O
Tab	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
(	O
4	O
)	O
There	O
is	O
still	O
a	O
large	O
gap	O
between	O
the	O
performance	O
of	O
unsupervised	O
output	O
embeddings	O
and	O
human	O
-	O
annotated	O
attributes	O
on	O
AWA	O
and	O
CUB	B-Material
,	O
suggesting	O
that	O
better	O
methods	O
are	O
needed	O
for	O
learning	O
discriminative	B-Task
output	I-Task
embeddings	I-Task
from	O
text	O
.	O
	
(	O
5	O
)	O
Finally	O
,	O
supporting	O
,	O
encoding	O
continuous	O
nature	O
of	O
attributes	O
significantly	O
improve	O
upon	O
binary	O
attributes	O
for	O
zero	B-Task
-	I-Task
shot	I-Task
classification	I-Task
(	O
Tab	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
As	O
future	O
work	O
,	O
we	O
plan	O
to	O
investigate	O
other	O
methods	O
to	O
combine	O
multiple	O
output	O
embeddings	O
and	O
to	O
improve	O
the	O
discriminative	B-Metric
power	I-Metric
of	O
unsupervised	B-Method
and	I-Method
weakly	I-Method
-	I-Method
supervised	I-Method
label	I-Method
embeddings	I-Method
for	O
fine	B-Task
-	I-Task
grained	I-Task
classification	I-Task
.	O
	
subsection	O
:	O
Acknowledgments	O
	
This	O
work	O
was	O
supported	O
in	O
part	O
by	O
ONR	O
N00014	O
-	O
13	O
-	O
1	O
-	O
0762	O
,	O
NSF	O
CMMI	O
-	O
1266184	O
,	O
Google	O
Faculty	O
Research	O
Award	O
,	O
and	O
NSF	O
Graduate	O
Fellowship	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Deep	B-Method
Residual	I-Method
Networks	I-Method
with	O
Exponential	B-Method
Linear	I-Method
Unit	I-Method
	
Very	O
deep	B-Method
convolutional	I-Method
neural	I-Method
networks	I-Method
introduced	O
new	O
problems	O
like	O
vanishing	O
gradient	O
and	O
degradation	O
.	O
	
The	O
recent	O
successful	O
contributions	O
towards	O
solving	O
these	O
problems	O
are	O
Residual	B-Method
and	O
Highway	B-Method
Networks	I-Method
.	O
	
These	O
networks	O
introduce	O
skip	O
connections	O
that	O
allow	O
the	O
information	O
(	O
from	O
the	O
input	O
or	O
those	O
learned	O
in	O
earlier	O
layers	O
)	O
to	O
flow	O
more	O
into	O
the	O
deeper	O
layers	O
.	O
	
These	O
very	O
deep	B-Method
models	I-Method
have	O
lead	O
to	O
a	O
considerable	O
decrease	O
in	O
test	B-Metric
errors	I-Metric
,	O
on	O
benchmarks	O
like	O
ImageNet	O
and	O
COCO	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
the	O
use	O
of	O
exponential	B-Method
linear	I-Method
unit	I-Method
instead	O
of	O
the	O
combination	O
of	O
ReLU	B-Method
and	O
Batch	B-Method
Normalization	I-Method
in	O
Residual	B-Method
Networks	I-Method
.	O
	
We	O
show	O
that	O
this	O
not	O
only	O
speeds	O
up	O
learning	B-Task
in	O
Residual	B-Method
Networks	I-Method
but	O
also	O
improves	O
the	O
accuracy	B-Metric
as	O
the	O
depth	O
increases	O
.	O
	
It	O
improves	O
the	O
test	B-Metric
error	I-Metric
on	O
almost	O
all	O
data	O
sets	O
,	O
like	O
CIFAR	B-Material
-	I-Material
10	I-Material
and	O
CIFAR	B-Material
-	I-Material
100	I-Material
.	O
	
section	O
:	O
Introduction	O
	
The	O
Vision	B-Task
Community	I-Task
has	O
been	O
mesmerized	O
by	O
the	O
effectiveness	O
of	O
deep	B-Method
convolutional	I-Method
neural	I-Method
networks	I-Method
(	O
CNNs	B-Method
)	O
that	O
have	O
led	O
to	O
a	O
breakthrough	O
in	O
computer	B-Task
vision	I-Task
-	I-Task
related	I-Task
problems	I-Task
.	O
	
Hence	O
,	O
there	O
has	O
been	O
a	O
notable	O
shift	O
towards	O
CNNs	B-Method
in	O
many	O
areas	O
of	O
computer	B-Task
vision	I-Task
.	O
	
Convolutional	B-Method
neural	I-Method
networks	I-Method
were	O
popularized	O
through	O
AlexNet	B-Method
in	O
2009	O
and	O
their	O
much	O
celebrated	O
victory	O
at	O
the	O
2012	O
ImageNet	O
competiton	O
.	O
	
After	O
that	O
,	O
there	O
have	O
been	O
several	O
attempts	O
at	O
building	O
deeper	B-Method
and	I-Method
deeper	I-Method
CNNs	I-Method
like	O
the	O
VGG	B-Method
network	I-Method
and	O
GoogLeNet	B-Method
in	O
2014	O
which	O
have	O
19	O
and	O
22	O
layers	O
respectively	O
.	O
	
But	O
,	O
very	O
deep	B-Method
models	I-Method
introduce	O
problems	O
like	O
vanishing	O
and	O
exploding	O
gradients	O
,	O
which	O
hamper	O
their	O
convergence	O
.	O
	
The	O
vanishing	B-Task
gradient	I-Task
problem	I-Task
is	O
trivial	O
in	O
very	O
deep	B-Task
networks	I-Task
.	O
	
During	O
the	O
backpropagation	O
phase	O
,	O
the	O
gradients	O
are	O
computed	O
by	O
the	O
chain	B-Method
rule	I-Method
.	O
	
Multiplication	O
of	O
small	O
numbers	O
in	O
the	O
chain	B-Method
rule	I-Method
leads	O
to	O
an	O
exponential	O
decrease	O
in	O
the	O
gradient	O
.	O
	
Due	O
to	O
this	O
,	O
very	O
deep	B-Method
networks	I-Method
learn	O
very	O
slowly	O
.	O
	
Sometimes	O
,	O
the	O
gradient	O
in	O
the	O
earlier	O
layer	O
gets	O
larger	O
because	O
derivatives	O
of	O
some	O
activation	O
functions	O
can	O
take	O
larger	O
values	O
.	O
	
This	O
leads	O
to	O
the	O
problem	O
of	O
exploding	O
gradient	O
.	O
	
These	O
problems	O
have	O
been	O
reduced	O
in	O
practice	O
through	O
normalized	B-Method
initialization	I-Method
and	O
most	O
recently	O
,	O
Batch	B-Method
Normalization	I-Method
.	O
	
Exponential	B-Method
linear	I-Method
unit	I-Method
(	O
ELU	B-Method
)	O
also	O
reduces	O
the	O
vanishing	B-Task
gradient	I-Task
problem	I-Task
.	O
	
ELUs	B-Method
introduce	O
negative	O
values	O
which	O
push	O
the	O
mean	O
activation	O
towards	O
zero	O
.	O
	
This	O
reduces	O
the	O
bias	O
shift	O
and	O
speeds	O
up	O
learning	B-Task
.	O
	
ELUs	B-Method
give	O
better	O
accuracy	B-Metric
and	O
learning	B-Metric
speed	I-Metric
-	I-Metric
up	I-Metric
compared	O
to	O
the	O
combination	O
of	O
ReLU	B-Method
and	O
Batch	B-Method
Normalization	I-Method
.	O
	
After	O
reducing	O
the	O
vanishing	B-Task
/	I-Task
exploding	I-Task
gradient	I-Task
problem	I-Task
,	O
the	O
networks	O
start	O
converging	O
.	O
	
However	O
,	O
the	O
accuracy	B-Metric
degrades	O
in	O
such	O
very	O
deep	B-Method
models	I-Method
.	O
	
The	O
most	O
recent	O
contributions	O
towards	O
solving	O
this	O
problem	O
are	O
Highway	B-Method
Networks	I-Method
and	O
Residual	B-Method
Networks	I-Method
.	O
	
These	O
networks	O
introduce	O
skip	O
connections	O
,	O
which	O
allow	O
information	O
flow	O
into	O
the	O
deeper	O
layers	O
and	O
enable	O
us	O
to	O
have	O
deeper	O
networks	O
with	O
better	O
accuracy	B-Metric
.	O
	
The	O
152	O
-	O
layer	O
ResNet	B-Method
outperforms	O
all	O
other	O
models	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
to	O
use	O
exponential	B-Method
linear	I-Method
unit	I-Method
instead	O
of	O
the	O
combination	O
of	O
ReLU	B-Method
and	O
Batch	B-Method
Normalization	I-Method
.	O
	
Since	O
exponential	B-Method
linear	I-Method
units	I-Method
reduce	O
the	O
vanishing	B-Task
gradient	I-Task
problem	I-Task
and	O
give	O
better	O
accuracy	B-Metric
compared	O
to	O
the	O
combination	O
of	O
ReLU	B-Method
and	O
Batch	B-Method
Normalization	I-Method
,	O
we	O
use	O
it	O
in	O
our	O
model	O
to	O
further	O
increase	O
the	O
accuracy	B-Metric
of	O
Residual	B-Method
Networks	I-Method
.	O
	
We	O
also	O
notice	O
that	O
ELU	B-Method
speeds	O
up	O
learning	B-Task
in	O
very	O
deep	B-Task
networks	I-Task
as	O
well	O
.	O
	
We	O
show	O
that	O
our	O
model	O
increases	O
the	O
accuracy	B-Metric
on	O
datasets	O
like	O
CIFAR	B-Material
-	I-Material
10	I-Material
and	O
CIFAR	B-Material
-	I-Material
100	I-Material
,	O
compared	O
to	O
the	O
original	O
model	O
.	O
	
It	O
is	O
seen	O
that	O
as	O
the	O
depth	O
increases	O
,	O
the	O
difference	O
in	O
accuracy	B-Metric
between	O
our	O
model	O
and	O
the	O
original	O
model	O
increases	O
.	O
	
section	O
:	O
Background	O
	
Deeper	B-Method
neural	I-Method
networks	I-Method
are	O
very	O
difficult	O
to	O
train	O
.	O
	
The	O
vanishing	B-Task
/	I-Task
exploding	I-Task
gradients	I-Task
problem	I-Task
impedes	O
the	O
convergence	B-Task
of	I-Task
deeper	I-Task
networks	I-Task
.	O
	
This	O
problem	O
has	O
been	O
solved	O
by	O
normalized	B-Method
initialization	I-Method
.	O
	
A	O
notable	O
recent	O
contribution	O
towards	O
reducing	O
the	O
vanishing	B-Task
gradients	I-Task
problem	I-Task
is	O
Batch	B-Method
Normalization	I-Method
.	O
	
Instead	O
of	O
normalized	B-Method
initialization	I-Method
and	O
keeping	O
a	O
lower	O
learning	B-Metric
rate	I-Metric
,	O
Batch	B-Method
Normalization	I-Method
makes	O
normalization	B-Method
a	O
part	O
of	O
the	O
model	O
and	O
performs	O
it	O
for	O
each	O
mini	O
-	O
batch	O
.	O
	
Once	O
the	O
deeper	O
networks	O
start	O
converging	O
,	O
a	O
degradation	B-Task
problem	I-Task
occurs	O
.	O
	
Due	O
to	O
this	O
,	O
the	O
accuracy	B-Metric
degrades	O
rapidly	O
after	O
it	O
is	O
saturated	O
.	O
	
The	O
training	B-Metric
error	I-Metric
increases	O
as	O
we	O
add	O
more	O
layers	O
to	O
a	O
deep	B-Method
model	I-Method
,	O
as	O
mentioned	O
in	O
.	O
	
To	O
solve	O
this	O
problem	O
,	O
several	O
authors	O
introduced	O
skip	O
connections	O
to	O
improve	O
the	O
information	O
flow	O
across	O
several	O
layers	O
.	O
	
Highway	B-Method
Networks	I-Method
have	O
parameterized	O
skip	O
connections	O
,	O
known	O
as	O
information	O
highways	O
,	O
which	O
allow	O
information	O
to	O
flow	O
unimpeded	O
into	O
deeper	O
layers	O
.	O
	
During	O
the	O
training	O
phase	O
,	O
the	O
skip	O
connection	O
parameters	O
are	O
adjusted	O
to	O
control	O
the	O
amount	O
of	O
information	O
allowed	O
on	O
these	O
highways	O
.	O
	
Residual	B-Method
Networks	I-Method
(	O
ResNets	B-Method
)	O
utilize	O
shortcut	O
connections	O
with	O
the	O
help	O
of	O
identity	B-Method
transformation	I-Method
.	O
	
Unlike	O
Highway	B-Method
Networks	I-Method
,	O
these	O
neither	O
introduce	O
extra	O
parameter	O
nor	O
computation	B-Metric
complexity	I-Metric
.	O
	
This	O
improves	O
the	O
accuracy	B-Metric
of	O
deeper	B-Method
networks	I-Method
.	O
	
With	O
increasing	O
depth	O
,	O
ResNets	B-Method
give	O
better	O
function	B-Method
approximation	I-Method
capabilities	O
as	O
they	O
gain	O
more	O
parameters	O
.	O
	
The	O
authors	O
’	O
hypothesis	O
is	O
that	O
the	O
plain	O
deeper	B-Method
networks	I-Method
give	O
worse	O
function	B-Method
approximation	I-Method
because	O
the	O
gradients	O
vanish	O
when	O
they	O
are	O
propagated	O
through	O
many	O
layers	O
.	O
	
To	O
fix	O
this	O
problem	O
,	O
they	O
introduce	O
skip	O
connections	O
to	O
the	O
network	O
.	O
	
Formally	O
,	O
If	O
the	O
output	O
of	O
layer	O
is	O
and	O
represents	O
multiple	O
convolutional	B-Method
transformation	O
from	O
layer	O
to	O
,	O
we	O
obtain	O
where	O
represents	O
the	O
identity	O
function	O
and	O
is	O
the	O
default	O
activation	O
function	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
illustrates	O
the	O
basic	O
building	O
block	O
of	O
a	O
Residual	B-Method
Network	O
which	O
consists	O
of	O
multiple	O
convolutional	B-Method
and	O
Batch	B-Method
Normalization	I-Method
layers	I-Method
.	O
	
The	O
identity	B-Method
transformation	I-Method
,	O
is	O
used	O
to	O
reduce	O
the	O
dimensions	O
of	O
to	O
match	O
those	O
of	O
.	O
	
In	O
Residual	B-Method
Networks	I-Method
,	O
the	O
gradients	O
and	O
features	O
learned	O
in	O
earlier	O
layers	O
are	O
passed	O
back	O
and	O
forth	O
between	O
the	O
layers	O
via	O
the	O
identity	B-Method
transformations	I-Method
.	O
	
Exponential	B-Method
Linear	I-Method
Unit	I-Method
(	O
ELU	B-Method
)	O
alleviates	O
the	O
vanishing	B-Task
gradient	I-Task
problem	I-Task
and	O
also	O
speeds	O
up	O
learning	B-Task
in	O
deep	B-Method
neural	I-Method
networks	I-Method
which	O
leads	O
to	O
higher	O
classification	B-Metric
accuracies	I-Metric
.	O
	
The	O
exponential	O
linear	O
unit	O
(	O
ELU	B-Method
)	O
is	O
The	O
ReLUs	B-Method
are	O
non	O
-	O
negative	O
and	O
thus	O
have	O
mean	O
activations	O
larger	O
than	O
zero	O
,	O
whereas	O
ELUs	B-Method
have	O
negative	O
values	O
,	O
which	O
push	O
the	O
mean	O
activations	O
towards	O
zero	O
.	O
	
ELUs	B-Method
saturate	O
to	O
a	O
negative	O
value	O
when	O
the	O
input	O
gets	O
smaller	O
.	O
	
This	O
decreases	O
the	O
forward	O
propagated	O
variation	O
and	O
information	O
,	O
which	O
draws	O
the	O
mean	O
activations	O
to	O
zero	O
.	O
	
Units	O
with	O
non	O
-	O
zero	O
mean	O
activations	O
act	O
as	O
a	O
bias	O
for	O
the	O
next	O
layer	O
.	O
	
If	O
these	O
units	O
do	O
not	O
cancel	O
each	O
other	O
out	O
,	O
then	O
the	O
learning	B-Method
causes	O
a	O
bias	O
shift	O
for	O
units	O
in	O
the	O
next	O
layer	O
.	O
	
Therefore	O
,	O
ELUs	B-Method
decrease	O
the	O
bias	O
shift	O
as	O
the	O
mean	O
activations	O
are	O
closer	O
to	O
zero	O
.	O
	
Less	O
bias	O
shift	O
also	O
speeds	O
up	O
learning	B-Task
by	O
bringing	O
standard	O
gradient	O
closer	O
towards	O
the	O
unit	O
natural	O
gradient	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
the	O
comparison	O
of	O
ReLU	B-Method
and	O
ELU	B-Method
(	O
)	O
.	O
	
.24	O
	
.24	O
.24	O
	
.24	O
	
section	O
:	O
Residual	B-Method
Networks	I-Method
with	O
Exponential	B-Method
Linear	I-Method
Unit	I-Method
	
subsection	O
:	O
ResNet	B-Method
Architecture	O
	
The	O
Residual	B-Method
Network	O
in	O
is	O
a	O
functional	B-Method
composition	I-Method
of	I-Method
residual	I-Method
blocks	I-Method
(	O
ResBlocks	B-Method
)	O
,	O
each	O
encoding	O
the	O
update	B-Method
rule	I-Method
(	O
[	O
reference	O
]	O
)	O
.	O
	
Fig	O
[	O
reference	O
]	O
shows	O
the	O
schematic	O
illustration	O
of	O
the	O
ResBlock	O
.	O
	
In	O
this	O
example	O
,	O
consists	O
of	O
a	O
sequence	O
of	O
layers	O
:	O
	
Conv	B-Method
-	O
BN	B-Method
-	O
ReLU	B-Method
-	O
Conv	B-Method
-	O
BN	B-Method
,	O
where	O
Conv	B-Method
and	O
BN	B-Method
stands	O
for	O
Convolution	B-Method
and	O
Batch	B-Method
Normalization	I-Method
respectively	O
.	O
	
This	O
construction	B-Method
scheme	I-Method
is	O
adopted	O
in	O
all	O
our	O
experiments	O
while	O
reproducing	O
the	O
results	O
of	O
.	O
	
The	O
function	O
is	O
parameterized	O
by	O
some	O
set	O
of	O
parameters	O
,	O
which	O
we	O
omit	O
for	O
notational	O
simplicity	O
.	O
	
Normally	O
,	O
we	O
use	O
64	O
,	O
32	O
or	O
16	O
filters	O
in	O
the	O
convolutional	B-Method
layers	O
.	O
	
The	O
size	O
of	O
receptive	O
field	O
is	O
.	O
	
Although	O
it	O
does	O
not	O
seem	O
attractive	O
but	O
,	O
in	O
practice	O
it	O
gives	O
better	O
accuracy	B-Metric
without	O
adding	O
any	O
overhead	B-Metric
costs	I-Metric
,	O
as	O
compared	O
to	O
plain	B-Method
networks	I-Method
.	O
	
subsection	O
:	O
ResNet	B-Method
with	O
ELU	B-Method
	
In	O
comparison	O
with	O
the	O
ResNet	B-Method
model	O
,	O
we	O
use	O
Exponential	B-Method
Linear	I-Method
Unit	I-Method
(	O
ELU	B-Method
)	O
in	O
place	O
of	O
a	O
combination	O
of	O
ReLU	B-Method
with	O
Batch	B-Method
Normalization	I-Method
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
illustrates	O
our	O
different	O
experiments	O
with	O
ELUs	B-Method
in	O
ResBlock	B-Method
.	O
	
subsubsection	O
:	O
Conv	B-Method
-	O
ELU	B-Method
-	O
Conv	B-Method
-	O
ELU	B-Method
	
In	O
this	O
model	O
,	O
consists	O
of	O
a	O
sequence	O
of	O
layers	O
:	O
	
Conv	B-Method
-	O
ELU	B-Method
-	O
Conv	B-Method
-	O
ELU	B-Method
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
represents	O
the	O
basic	O
building	O
block	O
of	O
this	O
experiment	O
.	O
	
We	O
trained	O
our	O
model	O
using	O
the	O
specification	O
mentioned	O
in	O
[	O
reference	O
]	O
.	O
	
But	O
we	O
found	O
that	O
after	O
few	O
iterations	O
,	O
the	O
gradients	O
blew	O
up	O
.	O
	
When	O
the	O
learning	B-Metric
rate	I-Metric
is	O
decreased	O
,	O
the	O
20	B-Method
-	I-Method
layer	I-Method
model	O
starts	O
converging	O
but	O
to	O
very	O
less	O
accuracy	B-Metric
.	O
	
The	O
deeper	O
models	O
like	O
56	O
and	O
110	O
-	O
layer	O
still	O
do	O
not	O
converge	O
after	O
decreasing	O
the	O
learning	B-Metric
rate	I-Metric
.	O
	
This	O
model	O
clearly	O
fails	O
as	O
the	O
trivial	O
problem	O
of	O
exploding	O
gradient	O
can	O
not	O
be	O
reduced	O
in	O
very	O
deep	B-Method
models	I-Method
.	O
	
subsubsection	O
:	O
ELU	B-Method
-	O
Conv	B-Method
-	O
ELU	B-Method
-	O
Conv	B-Method
	
This	O
is	O
a	O
full	O
pre	B-Method
-	I-Method
activation	I-Method
unit	I-Method
ResBlock	O
with	O
ELU	B-Method
.	O
	
The	O
sequence	O
of	O
layers	O
is	O
ELU	B-Method
-	O
Conv	B-Method
-	O
ELU	B-Method
-	O
Conv	B-Method
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
highlights	O
the	O
basic	O
ResBlock	O
of	O
this	O
experiment	O
.	O
	
During	O
the	O
training	O
of	O
this	O
model	O
too	O
,	O
the	O
gradients	O
exploded	O
after	O
few	O
iterations	O
.	O
	
Due	O
to	O
the	O
exponential	O
function	O
,	O
the	O
gradients	O
get	O
larger	O
and	O
lead	O
to	O
exploding	B-Task
gradient	I-Task
problem	I-Task
.	O
	
Even	O
decreasing	O
the	O
learning	B-Metric
rate	I-Metric
also	O
does	O
not	O
reduce	O
this	O
problem	O
.	O
	
We	O
decided	O
to	O
add	O
a	O
Batch	B-Method
Normalization	I-Method
layer	O
before	O
Addition	O
to	O
control	O
this	O
problem	O
.	O
	
subsubsection	O
:	O
Conv	B-Method
-	O
ELU	B-Method
-	O
Conv	B-Method
-	O
BN	B-Method
and	O
ELU	B-Method
after	O
Addition	O
	
.23	O
	
.23	O
	
To	O
control	O
the	O
exploding	O
gradient	O
,	O
we	O
added	O
a	O
Batch	B-Method
Normalization	I-Method
before	O
addition	O
.	O
	
So	O
,	O
the	O
sequence	O
of	O
layers	O
in	O
this	O
ResBlock	O
is	O
Conv	B-Method
-	O
ELU	B-Method
-	O
Conv	B-Method
-	O
BN	B-Method
and	O
ELU	B-Method
after	O
addition	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
represents	O
the	O
ResBlock	O
used	O
in	O
this	O
experiment	O
.	O
	
Thus	O
in	O
this	O
ResBlock	O
,	O
the	O
update	O
rule	O
(	O
[	O
reference	O
]	O
)	O
for	O
the	O
layer	O
is	O
The	O
Batch	B-Method
Normalization	I-Method
layer	O
reduces	O
the	O
exploding	B-Task
gradient	I-Task
problem	I-Task
found	O
in	O
the	O
previous	O
two	O
models	O
.	O
	
We	O
found	O
that	O
this	O
model	O
gives	O
better	O
accuracy	B-Metric
for	O
20	B-Method
-	I-Method
layer	I-Method
model	O
.	O
	
However	O
,	O
as	O
we	O
increased	O
the	O
depth	O
of	O
the	O
network	O
,	O
the	O
accuracy	B-Metric
degrades	O
for	O
the	O
deeper	B-Method
models	I-Method
.	O
	
If	O
the	O
ELU	B-Method
activation	O
function	O
is	O
placed	O
after	O
addtion	O
,	O
then	O
the	O
mean	O
activation	O
of	O
the	O
output	O
pushes	O
towards	O
zero	O
.	O
	
This	O
could	O
be	O
beneficial	O
.	O
	
However	O
,	O
this	O
forces	O
each	O
skip	O
connection	O
to	O
perturb	O
the	O
output	O
.	O
	
This	O
has	O
a	O
harmful	O
effect	O
and	O
we	O
found	O
that	O
this	O
leads	O
to	O
degradation	O
of	O
accuracy	B-Metric
in	O
very	O
deep	O
ResNets	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
depicts	O
the	O
effects	O
of	O
including	O
ELU	B-Method
after	O
addition	O
in	O
this	O
ResBlock	O
.	O
	
subsubsection	O
:	O
Conv	B-Method
-	O
ELU	B-Method
-	O
Conv	B-Method
-	O
BN	B-Method
and	O
No	O
ELU	B-Method
after	O
Addition	O
	
.33	O
	
.33	O
	
.33	O
.4	O
	
.4	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
gives	O
an	O
illustration	O
of	O
the	O
basic	O
building	O
block	O
of	O
our	O
model	O
.	O
	
Thus	O
in	O
our	O
model	O
,	O
represents	O
the	O
following	O
sequence	O
of	O
layers	O
:	O
	
Conv	B-Method
-	O
ELU	B-Method
-	O
Conv	B-Method
-	O
BN	B-Method
.	O
	
The	O
update	O
rule	O
(	O
[	O
reference	O
]	O
)	O
for	O
the	O
layer	O
is	O
	
This	O
is	O
the	O
basic	O
building	O
block	O
for	O
all	O
our	O
experiments	O
on	O
CIFAR	B-Material
-	I-Material
10	I-Material
and	O
CIFAR	B-Material
-	I-Material
100	I-Material
datasets	I-Material
.	O
	
We	O
show	O
that	O
not	O
including	O
ELU	B-Method
after	O
addition	O
does	O
not	O
degrade	O
the	O
accuracy	B-Metric
,	O
unlike	O
the	O
previous	O
model	O
.	O
	
This	O
ResBlock	O
improves	O
the	O
learning	O
behavior	O
and	O
the	O
classification	B-Metric
performance	I-Metric
of	O
the	O
Residual	B-Method
Network	O
.	O
	
section	O
:	O
Results	O
	
We	O
empirically	O
demonstrate	O
the	O
effectiveness	O
of	O
our	O
model	O
on	O
a	O
series	O
of	O
benchmark	O
data	O
sets	O
:	O
CIFAR	B-Material
-	I-Material
10	I-Material
and	O
CIFAR	B-Material
-	I-Material
100	I-Material
.	O
	
In	O
our	O
experiments	O
,	O
we	O
compare	O
the	O
learning	B-Metric
behavior	I-Metric
and	O
the	O
classification	B-Metric
performance	I-Metric
of	O
both	O
the	O
models	O
on	O
the	O
CIFAR	B-Material
-	I-Material
10	I-Material
and	O
CIFAR	B-Material
-	I-Material
100	I-Material
datasets	I-Material
.	O
	
The	O
experiments	O
prove	O
that	O
our	O
model	O
outperforms	O
the	O
original	O
ResNet	B-Method
model	O
in	O
terms	O
of	O
learning	B-Metric
behavior	I-Metric
and	O
classification	B-Metric
performance	I-Metric
on	O
both	O
the	O
datasets	O
.	O
	
Finally	O
,	O
we	O
compare	O
the	O
classification	B-Metric
performance	I-Metric
of	O
our	O
model	O
with	O
other	O
previously	O
published	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
.	O
	
subsection	O
:	O
CIFAR	B-Material
-	I-Material
10	I-Material
Analysis	O
	
The	O
first	O
experiment	O
was	O
performed	O
on	O
the	O
CIFAR	B-Material
-	I-Material
10	I-Material
dataset	O
,	O
which	O
consists	O
of	O
50k	O
training	O
images	O
and	O
10k	O
test	O
images	O
in	O
10	O
classes	O
.	O
	
In	O
our	O
experiments	O
,	O
we	O
performed	O
training	O
on	O
the	O
training	O
set	O
and	O
evaluation	O
on	O
the	O
test	O
set	O
.	O
	
The	O
inputs	O
to	O
the	O
network	O
are	O
images	O
which	O
are	O
color	O
-	O
normalized	O
.	O
	
We	O
use	O
a	O
receptive	O
field	O
in	O
the	O
convolution	B-Method
layer	I-Method
.	O
	
We	O
use	O
a	O
stack	B-Method
of	I-Method
layers	I-Method
with	O
convolution	B-Method
on	O
the	O
feature	O
maps	O
of	O
sizes	O
respectively	O
,	O
with	O
on	O
each	O
feature	O
map	O
.	O
	
The	O
number	O
of	O
filters	O
are	O
respectively	O
.	O
	
The	O
original	O
ResNet	B-Method
model	O
ends	O
with	O
a	O
global	B-Method
average	I-Method
pooling	I-Method
,	O
a	O
10	B-Method
-	I-Method
way	I-Method
fully	I-Method
-	I-Method
connected	I-Method
layer	I-Method
and	O
a	O
softmax	B-Method
layer	I-Method
.	O
	
In	O
our	O
model	O
,	O
we	O
add	O
an	O
ELU	B-Method
activation	O
function	O
just	O
before	O
the	O
global	B-Method
average	I-Method
pooling	I-Method
layer	I-Method
.	O
	
These	O
two	O
models	O
are	O
trained	O
on	O
a	O
AWS	B-Method
g2.2xlarge	I-Method
instance	I-Method
(	O
which	O
has	O
a	O
single	O
GPU	O
)	O
with	O
a	O
mini	O
batch	O
-	O
size	O
of	O
128	O
.	O
	
We	O
use	O
a	O
weight	O
decay	O
of	O
0.0001	O
and	O
a	O
momentum	O
of	O
0.9	O
,	O
and	O
adopt	O
the	O
weight	B-Method
initialization	I-Method
in	O
and	O
BN	B-Method
but	O
with	O
no	O
dropout	B-Method
.	O
	
We	O
start	O
with	O
a	O
learning	B-Metric
rate	I-Metric
of	O
0.1	O
and	O
divide	O
by	O
10	O
after	O
81	O
epochs	O
,	O
and	O
again	O
divide	O
by	O
10	O
after	O
122	O
epochs	O
.	O
	
We	O
use	O
the	O
data	B-Method
augmentation	I-Method
mentioned	O
in	O
during	O
the	O
training	O
phase	O
:	O
	
Add	O
4	O
pixels	O
on	O
each	O
side	O
and	O
do	O
a	O
random	O
crop	O
from	O
the	O
padded	O
image	O
or	O
its	O
horizontal	O
flip	O
.	O
	
During	O
the	O
testing	O
phase	O
,	O
we	O
only	O
use	O
a	O
color	O
-	O
normalized	O
image	O
.	O
	
Our	O
experiments	O
are	O
executed	O
on	O
20	O
,	O
32	O
,	O
44	O
,	O
56	O
and	O
110	O
-	O
layer	O
networks	O
.	O
	
subsubsection	O
:	O
Learning	B-Task
Behavior	I-Task
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
the	O
comparison	O
of	O
learning	B-Metric
behaviours	I-Metric
between	O
our	O
model	O
and	O
the	O
original	O
ResNet	B-Method
model	O
on	O
CIFAR	B-Material
-	I-Material
10	I-Material
dataset	O
for	O
20	O
,	O
32	O
,	O
44	O
,	O
56	O
and	O
110	O
-	O
layers	O
.	O
	
The	O
graphs	O
prove	O
that	O
for	O
all	O
the	O
different	O
number	O
of	O
layers	O
,	O
our	O
model	O
possesses	O
a	O
superior	O
learning	B-Metric
behavior	I-Metric
and	O
converges	O
many	O
epochs	O
before	O
the	O
original	O
model	O
.	O
	
As	O
the	O
depth	O
of	O
the	O
model	O
increases	O
,	O
our	O
model	O
also	O
learns	O
faster	O
than	O
the	O
original	O
model	O
.	O
	
The	O
difference	O
between	O
the	O
learning	B-Metric
rate	I-Metric
of	O
these	O
two	O
models	O
increases	O
as	O
the	O
depth	O
increases	O
.	O
	
Comparing	O
Fig	O
.	O
	
[	O
reference	O
]	O
and	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
,	O
we	O
can	O
easily	O
notice	O
the	O
huge	O
difference	O
in	O
learning	B-Metric
rates	I-Metric
for	O
20	B-Method
-	I-Method
layer	I-Method
and	O
110	B-Method
-	I-Method
layer	I-Method
models	I-Method
.	O
	
After	O
125	O
epochs	O
,	O
both	O
the	O
models	O
converge	O
to	O
almost	O
the	O
same	O
value	O
.	O
	
But	O
,	O
our	O
model	O
has	O
a	O
slightly	O
lower	O
training	B-Metric
loss	I-Metric
compared	O
to	O
the	O
original	O
model	O
.	O
	
subsubsection	O
:	O
Classification	B-Metric
Performance	I-Metric
	
Fig	O
.	O
	
[	O
reference	O
]	O
illustrates	O
the	O
comparison	O
of	O
classification	B-Metric
performance	I-Metric
between	O
our	O
model	O
and	O
the	O
original	O
one	O
on	O
CIFAR	B-Material
-	I-Material
10	I-Material
dataset	O
for	O
20	O
,	O
32	O
,	O
44	O
,	O
56	O
and	O
110	O
layers	O
.	O
	
We	O
observe	O
that	O
for	O
the	O
20	B-Method
-	I-Method
layer	I-Method
model	O
,	O
the	O
test	B-Metric
error	I-Metric
is	O
nearly	O
the	O
same	O
for	O
both	O
the	O
models	O
.	O
	
But	O
,	O
as	O
the	O
depth	O
increases	O
,	O
our	O
model	O
significantly	O
outperforms	O
the	O
original	O
model	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
test	O
error	O
for	O
both	O
the	O
models	O
from	O
the	O
epoch	O
with	O
the	O
lowest	O
validation	B-Metric
error	I-Metric
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
that	O
the	O
gap	O
between	O
the	O
test	O
error	O
of	O
the	O
two	O
models	O
increases	O
as	O
the	O
depth	O
is	O
also	O
increased	O
.	O
	
.33	O
	
.33	O
	
.33	O
.4	O
.4	O
	
subsection	O
:	O
CIFAR	B-Material
-	I-Material
100	I-Material
Analysis	O
	
Similar	O
to	O
CIFAR	B-Material
-	I-Material
10	I-Material
,	O
the	O
CIFAR	B-Material
-	I-Material
100	I-Material
dataset	I-Material
also	O
contains	O
images	O
with	O
the	O
same	O
train	O
-	O
test	O
split	O
,	O
but	O
from	O
100	O
classes	O
.	O
	
For	O
both	O
the	O
original	O
model	O
and	O
our	O
model	O
,	O
the	O
experimental	O
settings	O
are	O
exactly	O
the	O
same	O
as	O
those	O
of	O
CIFAR	B-Material
-	I-Material
10	I-Material
.	O
	
We	O
trained	O
only	O
for	O
the	O
110	B-Method
-	I-Method
layer	I-Method
models	I-Method
as	O
it	O
gives	O
us	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
that	O
for	O
CIFAR	B-Material
-	I-Material
100	I-Material
dataset	I-Material
as	O
well	O
,	O
our	O
model	O
learns	O
faster	O
than	O
the	O
original	O
ResNet	B-Method
model	O
.	O
	
The	O
original	O
model	O
yields	O
a	O
test	B-Metric
error	I-Metric
of	O
27.23	O
%	O
,	O
which	O
is	O
already	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
in	O
CIFAR	B-Material
-	I-Material
100	I-Material
with	O
standard	O
data	B-Method
augmentation	I-Method
.	O
	
Our	O
model	O
reduces	O
the	O
test	B-Metric
error	I-Metric
to	O
26.55	O
%	O
and	O
is	O
again	O
one	O
of	O
the	O
best	O
published	O
single	O
model	O
performances	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
that	O
the	O
test	O
error	O
of	O
our	O
model	O
is	O
much	O
lower	O
from	O
the	O
starting	O
epoch	O
itself	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
comparison	O
of	O
our	O
result	O
with	O
other	O
previously	O
published	O
results	O
on	O
the	O
CIFAR	B-Material
-	I-Material
10	I-Material
and	O
CIFAR	B-Material
-	I-Material
100	I-Material
datasets	I-Material
.	O
	
.23	O
.23	O
	
section	O
:	O
Conclusions	O
	
In	O
this	O
paper	O
,	O
we	O
introduce	O
Residual	B-Method
Networks	I-Method
with	O
exponential	B-Method
linear	I-Method
units	I-Method
which	O
learn	O
faster	O
than	O
the	O
current	O
Residual	B-Method
Networks	I-Method
.	O
	
They	O
also	O
give	O
better	O
accuracy	B-Metric
than	O
the	O
original	O
ones	O
when	O
the	O
depth	O
is	O
increased	O
.	O
	
On	O
datasets	O
like	O
CIFAR	B-Material
-	I-Material
10	I-Material
and	O
CIFAR	B-Material
-	I-Material
100	I-Material
,	O
we	O
improve	O
beyond	O
the	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
in	O
terms	O
of	O
test	B-Metric
error	I-Metric
,	O
while	O
also	O
learning	O
faster	O
than	O
these	O
models	O
using	O
ELUs	B-Method
.	O
	
ELUs	B-Method
push	O
the	O
mean	O
activations	O
towards	O
zero	O
as	O
they	O
introduce	O
small	O
negative	O
values	O
.	O
	
This	O
reduces	O
the	O
bias	O
shift	O
and	O
increases	O
the	O
learning	B-Metric
speed	I-Metric
.	O
	
Our	O
experiments	O
show	O
that	O
not	O
only	O
does	O
our	O
model	O
have	O
superior	O
learning	O
behavior	O
,	O
but	O
it	O
also	O
provides	O
better	O
accuracy	B-Metric
as	O
compared	O
to	O
the	O
current	O
model	O
on	O
CIFAR	B-Material
-	I-Material
10	I-Material
and	O
CIFAR	B-Material
-	I-Material
100	I-Material
datasets	I-Material
.	O
	
This	O
enables	O
the	O
researchers	O
to	O
use	O
very	O
deep	B-Method
models	I-Method
and	O
also	O
increase	O
their	O
learning	B-Metric
behavior	I-Metric
and	O
classification	B-Metric
performance	I-Metric
at	O
the	O
same	O
time	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Real	B-Task
-	I-Task
Time	I-Task
Single	I-Task
Image	I-Task
and	O
Video	B-Task
Super	I-Task
-	I-Task
Resolution	I-Task
Using	O
an	O
Efficient	B-Method
Sub	I-Method
-	I-Method
Pixel	I-Method
Convolutional	I-Method
Neural	I-Method
Network	I-Method
	
Recently	O
,	O
several	O
models	O
based	O
on	O
deep	B-Method
neural	I-Method
networks	I-Method
have	O
achieved	O
great	O
success	O
in	O
terms	O
of	O
both	O
reconstruction	B-Metric
accuracy	I-Metric
and	O
computational	B-Metric
performance	O
for	O
single	O
image	B-Task
super	I-Task
-	I-Task
resolution	I-Task
.	O
	
In	O
these	O
methods	O
,	O
the	O
low	B-Task
resolution	I-Task
(	O
LR	B-Task
)	O
input	O
image	B-Task
is	O
upscaled	O
to	O
the	O
high	O
resolution	O
(	O
HR	O
)	O
space	O
using	O
a	O
single	O
filter	B-Method
,	O
commonly	O
bicubic	B-Method
interpolation	I-Method
,	O
before	O
reconstruction	B-Task
.	O
	
This	O
means	O
that	O
the	O
super	B-Task
-	I-Task
resolution	I-Task
(	O
SR	B-Task
)	O
operation	O
is	O
performed	O
in	O
HR	O
space	O
.	O
	
We	O
demonstrate	O
that	O
this	O
is	O
sub	O
-	O
optimal	O
and	O
adds	O
computational	B-Metric
complexity	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
present	O
the	O
first	O
convolutional	B-Method
neural	I-Method
network	I-Method
(	I-Method
CNN	I-Method
)	I-Method
capable	O
of	O
real	B-Task
-	I-Task
time	I-Task
SR	I-Task
of	O
1080p	O
videos	O
on	O
a	O
single	O
K2	O
GPU	O
.	O
	
To	O
achieve	O
this	O
,	O
we	O
propose	O
a	O
novel	O
CNN	B-Method
architecture	I-Method
where	O
the	O
feature	O
maps	O
are	O
extracted	O
in	O
the	O
LR	B-Task
space	O
.	O
	
In	O
addition	O
,	O
we	O
introduce	O
an	O
efficient	O
sub	B-Method
-	I-Method
pixel	I-Method
convolution	I-Method
layer	I-Method
which	O
learns	O
an	O
array	B-Method
of	I-Method
upscaling	I-Method
filters	I-Method
to	O
upscale	O
the	O
final	O
LR	B-Task
feature	O
maps	O
into	O
the	O
HR	O
output	O
.	O
	
By	O
doing	O
so	O
,	O
we	O
effectively	O
replace	O
the	O
handcrafted	B-Method
bicubic	I-Method
filter	I-Method
in	O
the	O
SR	B-Task
pipeline	O
with	O
more	O
complex	O
upscaling	B-Method
filters	I-Method
specifically	O
trained	O
for	O
each	O
feature	O
map	O
,	O
whilst	O
also	O
reducing	O
the	O
computational	B-Metric
complexity	O
of	O
the	O
overall	O
SR	B-Task
operation	O
.	O
	
We	O
evaluate	O
the	O
proposed	O
approach	O
using	O
images	O
and	O
videos	O
from	O
publicly	O
available	O
datasets	O
and	O
show	O
that	O
it	O
performs	O
significantly	O
better	O
(	O
+	O
0.15dB	O
on	O
Images	O
and	O
+	O
0.39dB	O
on	O
Videos	O
)	O
and	O
is	O
an	O
order	O
of	O
magnitude	O
faster	O
than	O
previous	O
CNN	B-Method
-	I-Method
based	I-Method
methods	I-Method
.	O
	
⌈⌉	O
⌊⌋	O
SISRSISRsingleimagesuper	O
-	O
resolution	O
PSNRPSNRpeaksignaltonoiseratio	O
MSEMSEmeansquarederror	O
CNNCNNconvolutionalneuralnetwork	O
ESPCNESPCNefficientsub	O
-	O
pixelconvolutionalneuralnetwork	O
LRLRlowresolution	O
	
HRHRhighresolution	O
SRSRsuper	O
-	O
resolution	O
HDHDhighdefinition	O
	
FPSFPSframespersecond	O
TNRDTNRDtrainablenonlinearreactiondiffusion	O
	
section	O
:	O
Introduction	O
	
The	O
recovery	O
of	O
a	O
HR	O
image	B-Task
or	O
video	O
from	O
its	O
LR	B-Task
counter	O
part	O
is	O
topic	O
of	O
great	O
interest	O
in	O
digital	O
image	B-Task
processing	O
.	O
	
This	O
task	O
,	O
referred	O
to	O
as	O
SR	B-Task
,	O
finds	O
direct	O
applications	O
in	O
many	O
areas	O
such	O
as	O
HDTV	B-Task
,	O
medical	B-Task
imaging	I-Task
,	O
satellite	B-Task
imaging	I-Task
,	O
face	B-Task
recognition	I-Task
and	O
surveillance	B-Task
.	O
	
The	O
global	O
SR	B-Task
problem	O
assumes	O
LR	B-Task
data	O
to	O
be	O
a	O
low	O
-	O
pass	O
filtered	O
(	O
blurred	O
)	O
,	O
downsampled	O
and	O
noisy	O
version	O
of	O
HR	O
data	O
.	O
	
It	O
is	O
a	O
highly	O
ill	B-Task
-	I-Task
posed	I-Task
problem	I-Task
,	O
due	O
to	O
the	O
loss	O
of	O
high	O
-	O
frequency	O
information	O
that	O
occurs	O
during	O
the	O
non	B-Method
-	I-Method
invertible	I-Method
low	I-Method
-	I-Method
pass	I-Method
filtering	I-Method
and	O
subsampling	B-Method
operations	I-Method
.	O
	
Furthermore	O
,	O
the	O
SR	B-Task
operation	O
is	O
effectively	O
a	O
one	B-Method
-	I-Method
to	I-Method
-	I-Method
many	I-Method
mapping	I-Method
from	O
LR	B-Task
to	O
HR	O
space	O
which	O
can	O
have	O
multiple	O
solutions	O
,	O
of	O
which	O
determining	O
the	O
correct	O
solution	O
is	O
non	O
-	O
trivial	O
.	O
	
A	O
key	O
assumption	O
that	O
underlies	O
many	O
SR	B-Task
techniques	O
is	O
that	O
much	O
of	O
the	O
high	O
-	O
frequency	O
data	O
is	O
redundant	O
and	O
thus	O
can	O
be	O
accurately	O
reconstructed	O
from	O
low	O
frequency	O
components	O
.	O
	
SR	B-Task
is	O
therefore	O
an	O
inference	B-Task
problem	I-Task
,	O
and	O
thus	O
relies	O
on	O
our	O
model	O
of	O
the	O
statistics	B-Task
of	I-Task
images	I-Task
in	I-Task
question	I-Task
.	O
	
Many	O
methods	O
assume	O
multiple	O
images	O
are	O
available	O
as	O
LR	B-Task
instances	O
of	O
the	O
same	O
scene	O
with	O
different	O
perspectives	O
,	O
i.e.	O
with	O
unique	O
prior	O
affine	O
transformations	O
.	O
	
These	O
can	O
be	O
categorised	O
as	O
multi	O
-	O
image	B-Task
SR	I-Task
methods	O
and	O
exploit	O
explicit	O
redundancy	O
by	O
constraining	O
the	O
ill	B-Task
-	I-Task
posed	I-Task
problem	I-Task
with	O
additional	O
information	O
and	O
attempting	O
to	O
invert	O
the	O
downsampling	B-Method
process	I-Method
.	O
	
However	O
,	O
these	O
methods	O
usually	O
require	O
computationally	O
complex	O
image	B-Task
registration	O
and	O
fusion	O
stages	O
,	O
the	O
accuracy	B-Metric
of	O
which	O
directly	O
impacts	O
the	O
quality	O
of	O
the	O
result	O
.	O
	
An	O
alternative	O
family	O
of	O
methods	O
are	O
SISR	B-Method
techniques	I-Method
.	O
	
These	O
techniques	O
seek	O
to	O
learn	O
implicit	O
redundancy	O
that	O
is	O
present	O
in	O
natural	O
data	O
to	O
recover	O
missing	O
HR	O
information	O
from	O
a	O
single	O
LR	B-Task
instance	O
.	O
	
This	O
usually	O
arises	O
in	O
the	O
form	O
of	O
local	O
spatial	O
correlations	O
for	O
images	O
and	O
additional	O
temporal	O
correlations	O
in	O
videos	O
.	O
	
In	O
this	O
case	O
,	O
prior	O
information	O
in	O
the	O
form	O
of	O
reconstruction	O
constraints	O
is	O
needed	O
to	O
restrict	O
the	O
solution	O
space	O
of	O
the	O
reconstruction	O
.	O
	
subsection	O
:	O
Related	O
Work	O
	
The	O
goal	O
of	O
SISR	B-Method
methods	I-Method
is	O
to	O
recover	O
a	O
HR	O
image	B-Task
from	O
a	O
single	O
LR	B-Task
input	O
image	B-Task
.	O
	
Recent	O
popular	O
SISR	B-Method
methods	I-Method
can	O
be	O
classified	O
into	O
edge	B-Method
-	I-Method
based	I-Method
,	O
image	B-Task
statistics	O
-	O
based	O
and	O
patch	O
-	O
based	O
methods	O
.	O
	
A	O
detailed	O
review	O
of	O
more	O
generic	O
SISR	B-Method
methods	I-Method
can	O
be	O
found	O
in	O
.	O
	
One	O
family	O
of	O
approaches	O
that	O
has	O
recently	O
thrived	O
in	O
tackling	O
the	O
SISR	B-Task
problem	I-Task
is	O
sparsity	B-Method
-	I-Method
based	I-Method
techniques	I-Method
.	O
	
Sparse	B-Method
coding	I-Method
is	O
an	O
effective	O
mechanism	O
that	O
assumes	O
any	O
natural	O
image	B-Task
can	O
be	O
sparsely	O
represented	O
in	O
a	O
transform	O
domain	O
.	O
	
This	O
transform	O
domain	O
is	O
usually	O
a	O
dictionary	O
of	O
image	B-Task
atoms	O
,	O
which	O
can	O
be	O
learnt	O
through	O
a	O
training	B-Method
process	I-Method
that	O
tries	O
to	O
discover	O
the	O
correspondence	O
between	O
LR	B-Task
and	O
HR	O
patches	O
.	O
	
This	O
dictionary	O
is	O
able	O
to	O
embed	O
the	O
prior	O
knowledge	O
necessary	O
to	O
constrain	O
the	O
ill	B-Task
-	I-Task
posed	I-Task
problem	I-Task
of	I-Task
super	I-Task
-	I-Task
resolving	I-Task
unseen	I-Task
data	I-Task
.	O
	
This	O
approach	O
is	O
proposed	O
in	O
the	O
methods	O
of	O
.	O
	
A	O
drawback	O
of	O
sparsity	B-Method
-	I-Method
based	I-Method
techniques	I-Method
is	O
that	O
introducing	O
the	O
sparsity	O
constraint	O
through	O
a	O
nonlinear	B-Method
reconstruction	I-Method
is	O
generally	O
computationally	O
expensive	O
.	O
	
Image	B-Method
representations	I-Method
derived	O
via	O
neural	B-Method
networks	I-Method
have	O
recently	O
also	O
shown	O
promise	O
for	O
SISR	B-Method
.	O
	
These	O
methods	O
,	O
employ	O
the	O
back	B-Method
-	I-Method
propagation	I-Method
algorithm	I-Method
to	O
train	O
on	O
large	O
image	B-Task
databases	O
such	O
as	O
ImageNet	B-Method
in	O
order	O
to	O
learn	O
nonlinear	O
mappings	O
of	O
LR	B-Task
and	O
HR	O
image	B-Task
patches	O
.	O
	
Stacked	B-Method
collaborative	I-Method
local	I-Method
auto	I-Method
-	I-Method
encoders	I-Method
are	O
used	O
in	O
to	O
super	O
-	O
resolve	O
the	O
LR	B-Task
image	I-Task
layer	O
by	O
layer	O
.	O
	
Osendorfer	O
et	O
al	O
.	O
suggested	O
a	O
method	O
for	O
SISR	B-Method
based	O
on	O
an	O
extension	O
of	O
the	O
predictive	B-Method
convolutional	I-Method
sparse	I-Method
coding	I-Method
framework	I-Method
.	O
	
A	O
multiple	B-Method
layer	I-Method
CNN	I-Method
inspired	O
by	O
sparse	B-Method
-	I-Method
coding	I-Method
methods	I-Method
is	O
proposed	O
in	O
.	O
	
Chen	O
et	O
.	O
	
al	O
.	O
proposed	O
to	O
use	O
multi	B-Method
-	I-Method
stage	I-Method
TNRD	I-Method
as	O
an	O
alternative	O
to	O
CNN	B-Method
where	O
the	O
weights	O
and	O
the	O
nonlinearity	O
is	O
trainable	O
.	O
	
Wang	O
et	O
.	O
	
al	O
trained	O
a	O
cascaded	B-Method
sparse	I-Method
coding	I-Method
network	I-Method
from	O
end	O
to	O
end	O
inspired	O
by	O
LISTA	B-Method
	
(	O
Learning	B-Method
iterative	I-Method
shrinkage	I-Method
and	I-Method
thresholding	I-Method
algorithm	I-Method
)	O
to	O
fully	O
exploit	O
the	O
natural	O
sparsity	O
of	O
images	O
.	O
	
The	O
network	B-Method
structure	I-Method
is	O
not	O
limited	O
to	O
neural	B-Method
networks	I-Method
,	O
for	O
example	O
,	O
a	O
random	B-Method
forest	I-Method
has	O
also	O
been	O
successfully	O
used	O
for	O
SISR	B-Method
.	O
	
subsection	O
:	O
Motivations	O
and	O
contributions	O
	
With	O
the	O
development	O
of	O
CNN	B-Method
,	O
the	O
efficiency	O
of	O
the	O
algorithms	O
,	O
especially	O
their	O
computational	B-Metric
and	O
memory	B-Metric
cost	I-Metric
,	O
gains	O
importance	O
.	O
	
The	O
flexibility	O
of	O
deep	B-Method
network	I-Method
models	I-Method
to	O
learn	O
nonlinear	O
relationships	O
has	O
been	O
shown	O
to	O
attain	O
superior	O
reconstruction	B-Metric
accuracy	I-Metric
compared	O
to	O
previously	O
hand	B-Method
-	I-Method
crafted	I-Method
models	I-Method
.	O
	
To	O
super	O
-	O
resolve	O
a	O
LR	B-Task
image	I-Task
into	O
HR	O
space	O
,	O
it	O
is	O
necessary	O
to	O
increase	O
the	O
resolution	O
of	O
the	O
LR	B-Task
image	I-Task
to	O
match	O
that	O
of	O
the	O
HR	O
image	B-Task
at	O
some	O
point	O
.	O
	
In	O
Osendorfer	O
et	O
al	O
.	O
,	O
the	O
image	B-Task
resolution	O
is	O
increased	O
in	O
the	O
middle	O
of	O
the	O
network	O
gradually	O
.	O
	
Another	O
popular	O
approach	O
is	O
to	O
increase	O
the	O
resolution	O
before	O
or	O
at	O
the	O
first	O
layer	O
of	O
the	O
network	O
.	O
	
However	O
,	O
this	O
approach	O
has	O
a	O
number	O
of	O
drawbacks	O
.	O
	
Firstly	O
,	O
increasing	O
the	O
resolution	O
of	O
the	O
LR	B-Task
images	O
before	O
the	O
image	B-Task
enhancement	O
step	O
increases	O
the	O
computational	B-Metric
complexity	O
.	O
	
This	O
is	O
especially	O
problematic	O
for	O
convolutional	B-Method
networks	I-Method
,	O
where	O
the	O
processing	B-Metric
speed	I-Metric
directly	O
depends	O
on	O
the	O
input	O
image	B-Task
resolution	O
.	O
	
Secondly	O
,	O
interpolation	B-Method
methods	I-Method
typically	O
used	O
to	O
accomplish	O
the	O
task	O
,	O
such	O
as	O
bicubic	B-Method
interpolation	I-Method
,	O
do	O
not	O
bring	O
additional	O
information	O
to	O
solve	O
the	O
ill	B-Task
-	I-Task
posed	I-Task
reconstruction	I-Task
problem	I-Task
.	O
	
Learning	B-Method
upscaling	I-Method
filters	I-Method
was	O
briefly	O
suggested	O
in	O
the	O
footnote	O
of	O
Dong	O
et.al	O
.	O
.	O
	
However	O
,	O
the	O
importance	O
of	O
integrating	O
it	O
into	O
the	O
CNN	B-Method
as	O
part	O
of	O
the	O
SR	B-Task
operation	O
was	O
not	O
fully	O
recognised	O
and	O
the	O
option	O
not	O
explored	O
.	O
	
Additionally	O
,	O
as	O
noted	O
by	O
Dong	O
et	O
al	O
.	O
,	O
there	O
are	O
no	O
efficient	O
implementations	O
of	O
a	O
convolution	B-Method
layer	I-Method
whose	O
output	O
size	O
is	O
larger	O
than	O
the	O
input	O
size	O
and	O
well	O
-	O
optimized	B-Method
implementations	I-Method
such	O
as	O
convnet	B-Method
do	O
not	O
trivially	O
allow	O
such	O
behaviour	O
.	O
	
In	O
this	O
paper	O
,	O
contrary	O
to	O
previous	O
works	O
,	O
we	O
propose	O
to	O
increase	O
the	O
resolution	B-Metric
from	O
LR	B-Task
to	O
HR	O
only	O
at	O
the	O
very	O
end	O
of	O
the	O
network	O
and	O
super	O
-	O
resolve	O
HR	O
data	O
from	O
LR	B-Task
feature	O
maps	O
.	O
	
This	O
eliminates	O
the	O
need	O
to	O
perform	O
most	O
of	O
the	O
SR	B-Task
operation	O
in	O
the	O
far	O
larger	O
HR	O
resolution	O
.	O
	
For	O
this	O
purpose	O
,	O
we	O
propose	O
an	O
efficient	O
sub	B-Method
-	I-Method
pixel	I-Method
convolution	I-Method
layer	I-Method
to	O
learn	O
the	O
upscaling	B-Method
operation	I-Method
for	O
image	B-Task
and	O
video	B-Task
super	I-Task
-	I-Task
resolution	I-Task
.	O
	
The	O
advantages	O
of	O
these	O
contributions	O
are	O
two	O
fold	O
:	O
In	O
our	O
network	O
,	O
upscaling	B-Task
is	O
handled	O
by	O
the	O
last	B-Method
layer	I-Method
of	O
the	O
network	O
.	O
	
This	O
means	O
each	O
LR	B-Task
image	I-Task
is	O
directly	O
fed	O
to	O
the	O
network	O
and	O
feature	B-Task
extraction	I-Task
occurs	O
through	O
nonlinear	B-Method
convolutions	I-Method
in	O
LR	B-Task
space	O
.	O
	
Due	O
to	O
the	O
reduced	O
input	O
resolution	O
,	O
we	O
can	O
effectively	O
use	O
a	O
smaller	O
filter	O
size	O
to	O
integrate	O
the	O
same	O
information	O
while	O
maintaining	O
a	O
given	O
contextual	O
area	O
.	O
	
The	O
resolution	B-Method
and	O
filter	B-Method
size	I-Method
reduction	I-Method
lower	O
the	O
computational	B-Metric
and	O
memory	O
complexity	O
substantially	O
enough	O
to	O
allow	O
super	B-Task
-	I-Task
resolution	I-Task
of	O
HD	O
videos	O
in	O
real	O
-	O
time	O
as	O
shown	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
.	O
	
For	O
a	O
network	O
with	O
layers	O
,	O
we	O
learn	O
upscaling	B-Method
filters	I-Method
for	O
the	O
feature	O
maps	O
as	O
opposed	O
to	O
one	O
upscaling	B-Method
filter	I-Method
for	O
the	O
input	O
image	B-Task
.	O
	
In	O
addition	O
,	O
not	O
using	O
an	O
explicit	O
interpolation	B-Method
filter	I-Method
means	O
that	O
the	O
network	O
implicitly	O
learns	O
the	O
processing	O
necessary	O
for	O
SR	B-Task
.	O
	
Thus	O
,	O
the	O
network	O
is	O
capable	O
of	O
learning	O
a	O
better	O
and	O
more	O
complex	O
LR	B-Task
to	O
HR	O
mapping	O
compared	O
to	O
a	O
single	O
fixed	B-Method
filter	I-Method
upscaling	I-Method
at	O
the	O
first	O
layer	O
.	O
	
This	O
results	O
in	O
additional	O
gains	O
in	O
the	O
reconstruction	B-Metric
accuracy	I-Metric
of	O
the	O
model	O
as	O
shown	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
and	O
Sec	O
.	O
	
[	O
reference	O
]	O
.	O
	
We	O
validate	O
the	O
proposed	O
approach	O
using	O
images	O
and	O
videos	O
from	O
publicly	O
available	O
benchmarks	O
datasets	O
and	O
compared	O
our	O
performance	O
against	O
previous	O
works	O
including	O
.	O
	
We	O
show	O
that	O
the	O
proposed	O
model	O
achieves	O
state	O
-	O
of	O
-	O
art	O
performance	O
and	O
is	O
nearly	O
an	O
order	O
of	O
magnitude	O
faster	O
than	O
previously	O
published	O
methods	O
on	O
images	O
and	O
videos	O
.	O
	
section	O
:	O
Method	O
	
The	O
task	O
of	O
SISR	B-Task
is	O
to	O
estimate	O
a	O
HR	O
image	B-Task
given	O
a	O
LR	B-Task
image	I-Task
downscaled	O
from	O
the	O
corresponding	O
original	O
HR	O
image	B-Task
.	O
	
The	O
downsampling	B-Method
operation	I-Method
is	O
deterministic	O
and	O
known	O
:	O
to	O
produce	O
from	O
,	O
we	O
first	O
convolve	O
using	O
a	O
Gaussian	B-Method
filter	I-Method
-	O
thus	O
simulating	O
the	O
camera	B-Method
’s	I-Method
point	I-Method
spread	I-Method
function	I-Method
-	O
then	O
downsample	O
the	O
image	B-Task
by	O
a	O
factor	O
of	O
.	O
	
We	O
will	O
refer	O
to	O
as	O
the	O
upscaling	O
ratio	O
.	O
	
In	O
general	O
,	O
both	O
and	O
can	O
have	O
colour	O
channels	O
,	O
thus	O
they	O
are	O
represented	O
as	O
real	O
-	O
valued	O
tensors	O
of	O
size	O
and	O
,	O
respectively	O
.	O
	
To	O
solve	O
the	O
SISR	B-Task
problem	I-Task
,	O
the	O
SRCNN	B-Method
proposed	O
in	O
recovers	O
from	O
an	O
upscaled	O
and	O
interpolated	O
version	O
of	O
instead	O
of	O
.	O
	
To	O
recover	O
,	O
a	O
3	B-Method
layer	I-Method
convolutional	I-Method
network	I-Method
is	O
used	O
.	O
	
In	O
this	O
section	O
we	O
propose	O
a	O
novel	O
network	B-Method
architecture	I-Method
,	O
as	O
illustrated	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
to	O
avoid	O
upscaling	O
before	O
feeding	O
it	O
into	O
the	O
network	O
.	O
	
In	O
our	O
architecture	O
,	O
we	O
first	O
apply	O
a	O
layer	B-Method
convolutional	I-Method
neural	I-Method
network	I-Method
directly	O
to	O
the	O
LR	B-Task
image	I-Task
,	O
and	O
then	O
apply	O
a	O
sub	B-Method
-	I-Method
pixel	I-Method
convolution	I-Method
layer	I-Method
that	O
upscales	O
the	O
LR	B-Task
feature	O
maps	O
to	O
produce	O
.	O
	
For	O
a	O
network	O
composed	O
of	O
layers	O
,	O
the	O
first	O
layers	O
can	O
be	O
described	O
as	O
follows	O
:	O
	
Where	O
are	O
learnable	O
network	O
weights	O
and	O
biases	O
respectively	O
.	O
	
is	O
a	O
2D	B-Method
convolution	I-Method
tensor	I-Method
of	O
size	O
,	O
where	O
is	O
the	O
number	O
of	O
features	O
at	O
layer	O
,	O
,	O
and	O
is	O
the	O
filter	O
size	O
at	O
layer	O
.	O
	
The	O
biases	O
are	O
vectors	O
of	O
length	O
.	O
	
The	O
nonlinearity	O
function	O
(	O
or	O
activation	O
function	O
)	O
is	O
applied	O
element	O
-	O
wise	O
and	O
is	O
fixed	O
.	O
	
The	O
last	O
layer	O
has	O
to	O
convert	O
the	O
LR	B-Task
feature	O
maps	O
to	O
a	O
HR	O
image	B-Task
.	O
	
subsection	O
:	O
Deconvolution	B-Method
layer	I-Method
	
The	O
addition	O
of	O
a	O
deconvolution	B-Method
layer	I-Method
is	O
a	O
popular	O
choice	O
for	O
recovering	B-Task
resolution	I-Task
from	O
max	B-Method
-	I-Method
pooling	I-Method
and	O
other	O
image	B-Task
down	O
-	O
sampling	O
layers	O
.	O
	
This	O
approach	O
has	O
been	O
successfully	O
used	O
in	O
visualizing	B-Task
layer	I-Task
activations	I-Task
and	O
for	O
generating	O
semantic	B-Task
segmentations	I-Task
using	O
high	O
level	O
features	O
from	O
the	O
network	O
.	O
	
It	O
is	O
trivial	O
to	O
show	O
that	O
the	O
bicubic	B-Method
interpolation	I-Method
used	O
in	O
SRCNN	B-Method
is	O
a	O
special	O
case	O
of	O
the	O
deconvolution	B-Method
layer	I-Method
,	O
as	O
suggested	O
already	O
in	O
.	O
	
The	O
deconvolution	B-Method
layer	I-Method
proposed	O
in	O
can	O
be	O
seen	O
as	O
multiplication	O
of	O
each	O
input	O
pixel	O
by	O
a	O
filter	O
element	O
-	O
wise	O
with	O
stride	O
,	O
and	O
sums	O
over	O
the	O
resulting	O
output	O
windows	O
also	O
known	O
as	O
backwards	B-Method
convolution	I-Method
.	O
	
subsection	O
:	O
Efficient	O
sub	B-Method
-	I-Method
pixel	I-Method
convolution	I-Method
layer	I-Method
	
The	O
other	O
way	O
to	O
upscale	O
a	O
LR	B-Task
image	I-Task
is	O
convolution	B-Method
with	O
fractional	O
stride	O
of	O
in	O
the	O
LR	B-Task
space	O
as	O
mentioned	O
by	O
,	O
which	O
can	O
be	O
naively	O
implemented	O
by	O
interpolation	B-Method
,	O
perforate	O
or	O
un	B-Method
-	I-Method
pooling	I-Method
from	O
LR	B-Task
space	O
to	O
HR	O
space	O
followed	O
by	O
a	O
convolution	B-Method
with	O
a	O
stride	O
of	O
in	O
HR	O
space	O
.	O
	
These	O
implementations	O
increase	O
the	O
computational	B-Metric
cost	I-Metric
by	O
a	O
factor	O
of	O
,	O
since	O
convolution	B-Method
happens	O
in	O
HR	O
space	O
.	O
	
Alternatively	O
,	O
a	O
convolution	B-Method
with	O
stride	O
of	O
in	O
the	O
LR	B-Task
space	O
with	O
a	O
filter	O
of	O
size	O
with	O
weight	O
spacing	O
would	O
activate	O
different	O
parts	O
of	O
for	O
the	O
convolution	O
.	O
	
The	O
weights	O
that	O
fall	O
between	O
the	O
pixels	O
are	O
simply	O
not	O
activated	O
and	O
do	O
not	O
need	O
to	O
be	O
calculated	O
.	O
	
The	O
number	O
of	O
activation	O
patterns	O
is	O
exactly	O
.	O
	
Each	O
activation	O
pattern	O
,	O
according	O
to	O
its	O
location	O
,	O
has	O
at	O
most	O
weights	O
activated	O
.	O
	
These	O
patterns	O
are	O
periodically	O
activated	O
during	O
the	O
convolution	O
of	O
the	O
filter	B-Method
across	O
the	O
image	B-Task
depending	O
on	O
different	O
sub	O
-	O
pixel	O
location	O
:	O
where	O
are	O
the	O
output	O
pixel	O
coordinates	O
in	O
HR	O
space	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
an	O
effective	O
way	O
to	O
implement	O
the	O
above	O
operation	O
when	O
:	O
where	O
is	O
an	O
periodic	B-Method
shuffling	I-Method
operator	I-Method
that	O
rearranges	O
the	O
elements	O
of	O
a	O
tensor	O
to	O
a	O
tensor	O
of	O
shape	O
.	O
	
The	O
effects	O
of	O
this	O
operation	O
are	O
illustrated	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Mathematically	O
,	O
this	O
operation	O
can	O
be	O
described	O
in	O
the	O
following	O
way	O
The	O
convolution	B-Method
operator	I-Method
thus	O
has	O
shape	O
.	O
	
Note	O
that	O
we	O
do	O
not	O
apply	O
nonlinearity	O
to	O
the	O
outputs	O
of	O
the	O
convolution	B-Method
at	O
the	O
last	O
layer	O
.	O
	
It	O
is	O
easy	O
to	O
see	O
that	O
when	O
and	O
it	O
is	O
equivalent	O
to	O
sub	O
-	O
pixel	O
convolution	O
in	O
the	O
LR	B-Task
space	O
with	O
the	O
filter	B-Method
.	O
	
We	O
will	O
refer	O
to	O
our	O
new	O
layer	O
as	O
the	O
sub	B-Method
-	I-Method
pixel	I-Method
convolution	I-Method
layer	I-Method
and	O
our	O
network	O
as	O
ESPCN	B-Method
.	O
	
This	O
last	O
layer	O
produces	O
a	O
HR	O
image	B-Task
from	O
LR	B-Task
feature	O
maps	O
directly	O
with	O
one	O
upscaling	B-Method
filter	I-Method
for	O
each	O
feature	O
map	O
as	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Given	O
a	O
training	O
set	O
consisting	O
of	O
HR	O
image	B-Task
examples	O
,	O
we	O
generate	O
the	O
corresponding	O
LR	B-Task
images	O
,	O
and	O
calculate	O
the	O
pixel	B-Metric
-	I-Metric
wise	I-Metric
MSE	I-Metric
of	I-Metric
the	I-Metric
reconstruction	I-Metric
as	O
an	O
objective	B-Metric
function	I-Metric
to	O
train	O
the	O
network	O
:	O
It	O
is	O
noticeable	O
that	O
the	O
implementation	O
of	O
the	O
above	O
periodic	B-Method
shuffling	I-Method
can	O
be	O
avoided	O
in	O
training	O
time	O
.	O
	
Instead	O
of	O
shuffling	O
the	O
output	O
as	O
part	O
of	O
the	O
layer	O
,	O
we	O
can	O
pre	O
-	O
shuffle	O
the	O
training	O
data	O
to	O
match	O
the	O
output	O
of	O
the	O
layer	O
before	O
.	O
	
Thus	O
our	O
proposed	O
layer	O
is	O
times	O
faster	O
compared	O
to	O
deconvolution	B-Method
layer	I-Method
in	O
training	B-Task
and	O
times	O
faster	O
compared	O
to	O
implementations	O
using	O
various	O
forms	O
of	O
upscaling	B-Method
before	I-Method
convolution	I-Method
.	O
	
section	O
:	O
Experiments	O
	
[	O
Baboon	O
Original	O
]	O
	
[	O
Bicubic	B-Method
/	O
23.21db	O
]	O
	
[	O
SRCNN	B-Method
/	O
23.67db	O
]	O
	
[	O
TNRD	B-Method
/	O
23.62db	O
]	O
[	O
ESPCN	B-Method
/	O
23.72db	O
]	O
	
[	O
Comic	O
Original	O
]	O
[	O
Bicubic	B-Method
/	O
23.12db	O
]	O
	
[	O
SRCNN	B-Method
/	O
24.56db	O
]	O
	
[	O
TNRD	B-Method
/	O
24.68db	O
]	O
[	O
ESPCN	B-Method
/	O
24.82db	O
]	O
	
[	O
Monarch	O
Original	O
]	O
	
[	O
Bicubic	B-Method
/	O
29.43db	O
]	O
	
[	O
SRCNN	B-Method
/	O
32.81db	O
]	O
	
[	O
TNRD	B-Method
/	O
33.62db	O
]	O
	
[	O
ESPCN	B-Method
/	O
33.66db	O
]	O
	
The	O
detailed	O
report	O
of	O
quantitative	O
evaluation	O
including	O
the	O
original	O
data	O
including	O
images	O
and	O
videos	O
,	O
down	O
-	O
sampled	O
data	O
,	O
super	O
-	O
resolved	O
data	O
,	O
overall	O
and	O
individual	O
scores	O
and	O
run	B-Metric
-	I-Metric
times	I-Metric
on	O
a	O
K2	B-Method
GPU	I-Method
are	O
provided	O
in	O
the	O
supplemental	O
material	O
.	O
	
subsection	O
:	O
Datasets	O
	
During	O
the	O
evaluation	O
,	O
we	O
used	O
publicly	O
available	O
benchmark	O
datasets	O
including	O
the	O
Timofte	O
dataset	O
widely	O
used	O
by	O
SISR	O
papers	O
which	O
provides	O
source	O
code	O
for	O
multiple	O
methods	O
,	O
91	O
training	O
images	O
and	O
two	O
test	O
datasets	O
Set5	B-Material
and	O
Set14	B-Material
which	O
provides	O
5	O
and	O
14	O
images	O
;	O
	
The	O
Berkeley	O
segmentation	O
dataset	O
BSD300	O
and	O
BSD500	O
which	O
provides	O
100	O
and	O
200	O
images	O
for	O
testing	O
and	O
the	O
super	O
texture	O
dataset	O
which	O
provides	O
136	O
texture	O
images	O
.	O
	
For	O
our	O
final	O
models	O
,	O
we	O
use	O
50	O
,	O
000	O
randomly	O
selected	O
images	O
from	O
ImageNet	B-Method
for	O
the	O
training	O
.	O
	
Following	O
previous	O
works	O
,	O
we	O
only	O
consider	O
the	O
luminance	O
channel	O
in	O
YCbCr	O
colour	O
space	O
in	O
this	O
section	O
because	O
humans	O
are	O
more	O
sensitive	O
to	O
luminance	O
changes	O
.	O
	
For	O
each	O
upscaling	O
factor	O
,	O
we	O
train	O
a	O
specific	O
network	O
.	O
	
For	O
video	O
experiments	O
we	O
use	O
1080p	O
HD	O
videos	O
from	O
the	O
publicly	O
available	O
Xiph	B-Material
database	I-Material
,	O
which	O
has	O
been	O
used	O
to	O
report	O
video	O
SR	B-Task
results	O
in	O
previous	O
methods	O
.	O
	
The	O
database	O
contains	O
a	O
collection	O
of	O
HD	O
videos	O
approximately	O
seconds	O
in	O
length	O
and	O
with	O
width	O
and	O
height	O
.	O
	
In	O
addition	O
,	O
we	O
also	O
use	O
the	O
Ultra	B-Material
Video	I-Material
Group	I-Material
database	I-Material
,	O
containing	O
videos	O
of	O
in	O
size	O
and	O
seconds	O
in	O
length	O
.	O
	
subsection	O
:	O
Implementation	O
details	O
	
[	O
14092	O
Original	O
]	O
	
[	O
Bicubic	B-Method
/	O
29.06db	O
]	O
	
[	O
SRCNN	B-Method
/	O
29.74db	O
]	O
	
[	O
TNRD	B-Method
/	O
29.74db	O
]	O
	
[	O
ESPCN	B-Method
/	O
29.78db	O
]	O
	
[	O
335094	O
Original	O
]	O
	
[	O
Bicubic	B-Method
/	O
22.24db	O
]	O
	
[	O
SRCNN	B-Method
/	O
23.96db	O
]	O
	
[	O
TNRD	B-Method
/	O
24.15db	O
]	O
	
[	O
ESPCN	B-Method
/	O
24.14db	O
]	O
	
[	O
384022	O
Original	O
]	O
	
[	O
Bicubic	B-Method
/	O
25.42db	O
]	O
[	O
SRCNN	B-Method
/	O
26.72db	O
]	O
	
[	O
TNRD	B-Method
/	O
26.74db	O
]	O
	
[	O
ESPCN	B-Method
/	O
26.86db	O
]	O
	
For	O
the	O
ESPCN	B-Method
,	O
we	O
set	O
,	O
,	O
and	O
in	O
our	O
evaluations	O
.	O
	
The	O
choice	O
of	O
the	O
parameter	O
is	O
inspired	O
by	O
SRCNN	B-Method
’s	I-Method
3	I-Method
layer	I-Method
9	O
-	O
5	O
-	O
5	O
model	O
and	O
the	O
equations	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
.	O
	
In	O
the	O
training	O
phase	O
,	O
pixel	O
sub	O
-	O
images	O
are	O
extracted	O
from	O
the	O
training	O
ground	O
truth	O
images	O
,	O
where	O
is	O
the	O
upscaling	O
factor	O
.	O
	
To	O
synthesize	O
the	O
low	O
-	O
resolution	O
samples	O
,	O
we	O
blur	O
using	O
a	O
Gaussian	B-Method
filter	I-Method
and	O
sub	O
-	O
sample	O
it	O
by	O
the	O
upscaling	O
factor	O
.	O
	
The	O
sub	O
-	O
images	O
are	O
extracted	O
from	O
original	O
images	O
with	O
a	O
stride	O
of	O
from	O
and	O
a	O
stride	O
of	O
from	O
.	O
	
This	O
ensures	O
that	O
all	O
pixels	O
in	O
the	O
original	O
image	B-Task
appear	O
once	O
and	O
only	O
once	O
as	O
the	O
ground	O
truth	O
of	O
the	O
training	O
data	O
.	O
	
We	O
choose	O
instead	O
of	O
as	O
the	O
activation	O
function	O
for	O
the	O
final	O
model	O
motivated	O
by	O
our	O
experimental	O
results	O
.	O
	
The	O
training	O
stops	O
after	O
no	O
improvement	O
of	O
the	O
cost	O
function	O
is	O
observed	O
after	O
100	O
epochs	O
.	O
	
Initial	B-Metric
learning	I-Metric
rate	I-Metric
is	O
set	O
to	O
0.01	O
and	O
final	O
learning	B-Metric
rate	I-Metric
is	O
set	O
to	O
0.0001	O
and	O
updated	O
gradually	O
when	O
the	O
improvement	O
of	O
the	O
cost	O
function	O
is	O
smaller	O
than	O
a	O
threshold	O
.	O
	
The	O
final	O
layer	O
learns	O
10	O
times	O
slower	O
as	O
in	O
.	O
	
The	O
training	O
takes	O
roughly	O
three	O
hours	O
on	O
a	O
K2	B-Method
GPU	I-Method
on	O
91	O
images	O
,	O
and	O
seven	O
days	O
on	O
images	O
from	O
ImageNet	B-Method
for	O
upscaling	O
factor	O
of	O
3	O
.	O
	
We	O
use	O
the	O
PSNR	B-Metric
as	O
the	O
performance	B-Metric
metric	I-Metric
to	O
evaluate	O
our	O
models	O
.	O
	
PSNR	B-Metric
of	O
SRCNN	B-Method
and	O
Chen	B-Method
’s	I-Method
models	I-Method
on	O
our	O
extended	O
benchmark	O
set	O
are	O
calculated	O
based	O
on	O
the	O
Matlab	B-Method
code	I-Method
and	O
models	O
provided	O
by	O
.	O
	
subsection	O
:	O
Image	O
super	B-Task
-	I-Task
resolution	I-Task
results	O
	
subsubsection	O
:	O
Benefits	O
of	O
the	O
sub	B-Method
-	I-Method
pixel	I-Method
convolution	I-Method
layer	I-Method
	
In	O
this	O
section	O
,	O
we	O
demonstrate	O
the	O
positive	O
effect	O
of	O
the	O
sub	B-Method
-	I-Method
pixel	I-Method
convolution	I-Method
layer	I-Method
as	O
well	O
as	O
activation	O
function	O
.	O
	
We	O
first	O
evaluate	O
the	O
power	O
of	O
the	O
sub	B-Method
-	I-Method
pixel	I-Method
convolution	I-Method
layer	I-Method
by	O
comparing	O
against	O
SRCNN	B-Method
’s	O
standard	O
9	B-Method
-	I-Method
1	I-Method
-	I-Method
5	I-Method
model	I-Method
.	O
	
Here	O
,	O
we	O
follow	O
the	O
approach	O
in	O
,	O
using	O
as	O
the	O
activation	O
function	O
for	O
our	O
models	O
in	O
this	O
experiment	O
,	O
and	O
training	O
a	O
set	O
of	O
models	O
with	O
91	O
images	O
and	O
another	O
set	O
with	O
images	O
from	O
ImageNet	B-Method
.	O
	
The	O
results	O
are	O
shown	O
in	O
Tab	O
.	O
	
[	O
reference	O
]	O
.	O
	
ESPCN	B-Method
with	O
trained	O
on	O
ImageNet	B-Method
images	O
achieved	O
statistically	O
significantly	O
better	O
performance	O
compared	O
to	O
SRCNN	B-Method
models	I-Method
.	O
	
It	O
is	O
noticeable	O
that	O
ESPCN	B-Method
(	O
91	O
)	O
performs	O
very	O
similar	O
to	O
SRCNN	B-Method
(	O
91	O
)	O
.	O
	
Training	O
with	O
more	O
images	O
using	O
ESPCN	B-Method
has	O
a	O
far	O
more	O
significant	O
impact	O
on	O
PSNR	B-Metric
compared	O
to	O
SRCNN	B-Method
with	O
similar	O
number	O
of	O
parameters	O
(	O
+	O
0.33	O
vs	O
+	O
0.07	O
)	O
.	O
	
To	O
make	O
a	O
visual	O
comparison	O
between	O
our	O
model	O
with	O
the	O
sub	B-Method
-	I-Method
pixel	I-Method
convolution	I-Method
layer	I-Method
and	O
SRCNN	B-Method
,	O
we	O
visualized	O
weights	O
of	O
our	O
ESPCN	B-Method
(	O
ImageNet	B-Method
)	O
model	O
against	O
SRCNN	B-Method
9	O
-	O
5	O
-	O
5	O
ImageNet	B-Method
model	O
from	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
and	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
The	O
weights	O
of	O
our	O
first	O
and	O
last	B-Method
layer	I-Method
filters	I-Method
have	O
a	O
strong	O
similarity	O
to	O
designed	O
features	O
including	O
the	O
log	B-Method
-	I-Method
Gabor	I-Method
filters	I-Method
,	O
wavelets	B-Method
and	O
Haar	O
features	O
.	O
	
It	O
is	O
noticeable	O
that	O
despite	O
each	O
filter	O
is	O
independent	O
in	O
LR	B-Task
space	O
,	O
our	O
independent	B-Method
filters	I-Method
is	O
actually	O
smooth	O
in	O
the	O
HR	O
space	O
after	O
.	O
	
Compared	O
to	O
SRCNN	B-Method
’s	I-Method
last	I-Method
layer	I-Method
filters	I-Method
,	O
our	O
final	B-Method
layer	I-Method
filters	I-Method
has	O
complex	O
patterns	O
for	O
different	O
feature	O
maps	O
,	O
it	O
also	O
has	O
much	O
richer	O
and	O
more	O
meaningful	O
representations	O
.	O
	
We	O
also	O
evaluated	O
the	O
effect	O
of	O
activation	O
function	O
based	O
on	O
the	O
above	O
model	O
trained	O
on	O
91	O
images	O
and	O
ImageNet	B-Method
images	O
.	O
	
Results	O
in	O
Tab	O
.	O
	
[	O
reference	O
]	O
suggests	O
that	O
function	O
performs	O
better	O
for	O
SISR	B-Method
compared	O
to	O
.	O
	
The	O
results	O
for	O
ImageNet	B-Method
images	O
with	O
activation	O
is	O
shown	O
in	O
Tab	O
.	O
	
[	O
reference	O
]	O
.	O
	
subsubsection	O
:	O
Comparison	O
to	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
	
In	O
this	O
section	O
,	O
we	O
show	O
ESPCN	B-Method
trained	O
on	O
ImageNet	B-Method
compared	O
to	O
results	O
from	O
SRCNN	B-Method
and	O
the	O
TNRD	B-Method
which	O
is	O
currently	O
the	O
best	O
performing	O
approach	O
published	O
.	O
	
For	O
simplicity	O
,	O
we	O
do	O
not	O
show	O
results	O
which	O
are	O
known	O
to	O
be	O
worse	O
than	O
.	O
	
For	O
the	O
interested	O
reader	O
,	O
the	O
results	O
of	O
other	O
previous	O
methods	O
can	O
be	O
found	O
in	O
.	O
	
We	O
choose	O
to	O
compare	O
against	O
the	O
best	O
SRCNN	O
9	O
-	O
5	O
-	O
5	O
ImageNet	B-Method
model	O
in	O
this	O
section	O
.	O
	
And	O
for	O
,	O
results	O
are	O
calculated	O
based	O
on	O
the	O
stages	B-Method
model	I-Method
.	O
	
Our	O
results	O
shown	O
in	O
Tab	O
.	O
	
[	O
reference	O
]	O
are	O
significantly	O
better	O
than	O
the	O
SRCNN	O
9	O
-	O
5	O
-	O
5	O
ImageNet	B-Method
model	O
,	O
whilst	O
being	O
close	O
to	O
,	O
and	O
in	O
some	O
cases	O
out	O
-	O
performing	O
,	O
the	O
TNRD	B-Method
.	O
	
Although	O
TNRD	B-Method
uses	O
a	O
single	O
bicubic	B-Method
interpolation	I-Method
to	O
upscale	O
the	O
input	O
image	B-Task
to	O
HR	O
space	O
,	O
it	O
possibly	O
benefits	O
from	O
a	O
trainable	B-Method
nonlinearity	I-Method
function	I-Method
.	O
	
This	O
trainable	B-Method
nonlinearity	I-Method
function	I-Method
is	O
not	O
exclusive	O
from	O
our	O
network	O
and	O
will	O
be	O
interesting	O
to	O
explore	O
in	O
the	O
future	O
.	O
	
Visual	O
comparison	O
of	O
the	O
super	O
-	O
resolved	O
images	O
is	O
given	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
and	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
,	O
the	O
CNN	B-Method
methods	I-Method
create	O
a	O
much	O
sharper	O
and	O
higher	O
contrast	O
images	O
,	O
ESPCN	B-Method
provides	O
noticeably	O
improvement	O
over	O
SRCNN	B-Method
.	O
	
subsection	O
:	O
Video	O
super	B-Task
-	I-Task
resolution	I-Task
results	O
	
In	O
this	O
section	O
,	O
we	O
compare	O
the	O
ESPCN	B-Method
trained	O
models	O
against	O
single	O
frame	O
bicubic	B-Method
interpolation	I-Method
and	O
SRCNN	B-Method
on	O
two	O
popular	O
video	O
benchmarks	O
.	O
	
One	O
big	O
advantage	O
of	O
our	O
network	O
is	O
its	O
speed	O
.	O
	
This	O
makes	O
it	O
an	O
ideal	O
candidate	O
for	O
video	O
SR	B-Task
which	O
allows	O
us	O
to	O
super	O
-	O
resolve	O
the	O
videos	O
frame	O
by	O
frame	O
.	O
	
Our	O
results	O
shown	O
in	O
Tab	O
.	O
	
[	O
reference	O
]	O
and	O
Tab	O
.	O
	
[	O
reference	O
]	O
are	O
better	O
than	O
the	O
SRCNN	O
9	O
-	O
5	O
-	O
5	O
ImageNet	B-Method
model	O
.	O
	
The	O
improvement	O
is	O
more	O
significant	O
than	O
the	O
results	O
on	O
the	O
image	B-Task
data	O
,	O
this	O
maybe	O
due	O
to	O
differences	O
between	O
datasets	O
.	O
	
Similar	O
disparity	O
can	O
be	O
observed	O
in	O
different	O
categories	O
of	O
the	O
image	B-Task
benchmark	O
as	O
Set5	B-Material
vs	O
SuperTexture	O
.	O
	
subsection	O
:	O
Run	B-Metric
time	I-Metric
evaluations	I-Metric
	
In	O
this	O
section	O
,	O
we	O
evaluated	O
our	O
best	O
model	O
	
’s	O
run	B-Metric
time	I-Metric
on	O
Set14It	O
should	O
be	O
noted	O
our	O
results	O
outperform	O
all	O
other	O
algorithms	O
in	O
accuracy	B-Metric
on	O
the	O
larger	O
BSD	B-Material
datasets	I-Material
.	O
	
However	O
,	O
the	O
use	O
of	O
Set14	B-Material
on	O
a	O
single	O
CPU	O
core	O
is	O
selected	O
here	O
in	O
order	O
to	O
allow	O
a	O
straight	O
-	O
forward	O
comparison	O
with	O
results	O
from	O
previous	O
published	O
results	O
[	O
]	O
.	O
	
with	O
an	O
upscale	O
factor	O
of	O
3	O
.	O
	
We	O
evaluate	O
the	O
run	B-Metric
time	I-Metric
of	O
other	O
methods	O
from	O
the	O
Matlab	B-Method
codes	I-Method
provided	O
by	O
and	O
.	O
	
For	O
methods	O
which	O
use	O
convolutions	B-Method
including	O
our	O
own	O
,	O
a	O
python	B-Method
/	I-Method
theano	I-Method
implementation	I-Method
is	O
used	O
to	O
improve	O
the	O
efficiency	O
based	O
on	O
the	O
Matlab	B-Method
codes	I-Method
provided	O
in	O
.	O
	
The	O
results	O
are	O
presented	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Our	O
model	O
runs	O
a	O
magnitude	O
faster	O
than	O
the	O
fastest	O
methods	O
published	O
so	O
far	O
.	O
	
Compared	O
to	O
SRCNN	O
9	O
-	O
5	O
-	O
5	O
ImageNet	B-Method
model	O
,	O
the	O
number	O
of	O
convolution	O
required	O
to	O
super	O
-	O
resolve	O
one	O
image	B-Task
is	O
times	O
smaller	O
and	O
the	O
number	O
of	O
total	O
parameters	O
of	O
the	O
model	O
is	O
times	O
smaller	O
.	O
	
The	O
total	O
complexity	B-Metric
of	O
the	O
super	B-Task
-	I-Task
resolution	I-Task
operation	O
is	O
thus	O
times	O
lower	O
.	O
	
We	O
have	O
achieved	O
a	O
stunning	O
average	O
speed	O
of	O
for	O
super	O
-	O
resolving	O
one	O
single	O
image	B-Task
from	O
Set14	B-Material
on	O
a	O
K2	O
GPU	O
.	O
	
Utilising	O
the	O
amazing	O
speed	O
of	O
the	O
network	O
,	O
it	O
will	O
be	O
interesting	O
to	O
explore	O
ensemble	B-Method
prediction	I-Method
using	O
independently	O
trained	O
models	O
as	O
discussed	O
in	O
to	O
achieve	O
better	O
SR	B-Task
performance	O
in	O
the	O
future	O
.	O
	
We	O
also	O
evaluated	O
run	B-Metric
time	I-Metric
of	O
1080	O
HD	O
video	O
super	B-Task
-	I-Task
resolution	I-Task
using	O
videos	O
from	O
the	O
Xiph	B-Material
and	O
the	O
Ultra	B-Material
Video	I-Material
Group	I-Material
database	I-Material
.	O
	
With	O
upscale	O
factor	O
of	O
3	O
,	O
SRCNN	O
9	O
-	O
5	O
-	O
5	O
ImageNet	B-Method
model	O
takes	O
0.435s	O
per	O
frame	O
whilst	O
our	O
ESPCN	B-Method
model	O
takes	O
only	O
0.038s	O
per	O
frame	O
.	O
	
With	O
upscale	O
factor	O
of	O
4	O
,	O
SRCNN	O
9	O
-	O
5	O
-	O
5	O
ImageNet	B-Method
model	O
takes	O
0.434s	O
per	O
frame	O
whilst	O
our	O
ESPCN	B-Method
model	O
takes	O
only	O
0.029s	O
per	O
frame	O
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
paper	O
,	O
we	O
demonstrate	O
that	O
a	O
non	B-Method
-	I-Method
adaptive	I-Method
upscaling	I-Method
at	O
the	O
first	O
layer	O
provides	O
worse	O
results	O
than	O
an	O
adaptive	B-Method
upscaling	I-Method
for	O
SISR	B-Method
and	O
requires	O
more	O
computational	B-Metric
complexity	O
.	O
	
To	O
address	O
the	O
problem	O
,	O
we	O
propose	O
to	O
perform	O
the	O
feature	B-Method
extraction	I-Method
stages	I-Method
in	O
the	O
LR	B-Task
space	O
instead	O
of	O
HR	O
space	O
.	O
	
To	O
do	O
that	O
we	O
propose	O
a	O
novel	O
sub	B-Method
-	I-Method
pixel	I-Method
convolution	I-Method
layer	I-Method
which	O
is	O
capable	O
of	O
super	O
-	O
resolving	O
LR	B-Task
data	O
into	O
HR	O
space	O
with	O
very	O
little	O
additional	O
computational	B-Metric
cost	I-Metric
compared	O
to	O
a	O
deconvolution	B-Method
layer	I-Method
at	O
training	O
time	O
.	O
	
Evaluation	O
performed	O
on	O
an	O
extended	O
bench	O
mark	O
data	O
set	O
with	O
upscaling	O
factor	O
of	O
4	O
shows	O
that	O
we	O
have	O
a	O
significant	O
speed	O
(	O
)	O
and	O
performance	O
(	O
+	O
0.15dB	O
on	O
Images	O
and	O
+	O
0.39dB	O
on	O
videos	O
)	O
boost	O
compared	O
to	O
the	O
previous	O
CNN	B-Method
approach	I-Method
with	O
more	O
parameters	O
(	O
5	O
-	O
3	O
-	O
3	O
vs	O
9	O
-	O
5	O
-	O
5	O
)	O
.	O
	
This	O
makes	O
our	O
model	O
the	O
first	O
CNN	B-Method
model	I-Method
that	O
is	O
capable	O
of	O
SR	B-Task
HD	I-Task
videos	I-Task
in	O
real	O
time	O
on	O
a	O
single	O
GPU	O
.	O
	
section	O
:	O
Future	O
work	O
	
A	O
reasonable	O
assumption	O
when	O
processing	O
video	B-Task
information	I-Task
is	O
that	O
most	O
of	O
a	O
scene	O
	
’s	O
content	O
is	O
shared	O
by	O
neighbouring	O
video	O
frames	O
.	O
	
Exceptions	O
to	O
this	O
assumption	O
are	O
scene	O
changes	O
and	O
objects	O
sporadically	O
appearing	O
or	O
disappearing	O
from	O
the	O
scene	O
.	O
	
This	O
creates	O
additional	O
data	O
-	O
implicit	O
redundancy	O
that	O
can	O
be	O
exploited	O
for	O
video	B-Task
super	I-Task
-	I-Task
resolution	I-Task
as	O
has	O
been	O
shown	O
in	O
.	O
	
Spatio	B-Method
-	I-Method
temporal	I-Method
networks	I-Method
are	O
popular	O
as	O
they	O
fully	O
utilise	O
the	O
temporal	O
information	O
from	O
videos	O
for	O
human	B-Task
action	I-Task
recognition	I-Task
.	O
	
In	O
the	O
future	O
,	O
we	O
will	O
investigate	O
extending	O
our	O
ESPCN	B-Method
network	O
into	O
a	O
spatio	B-Method
-	I-Method
temporal	I-Method
network	I-Method
to	O
super	O
-	O
resolve	O
one	O
frame	O
from	O
multiple	O
neighbouring	O
frames	O
using	O
3D	B-Method
convolutions	I-Method
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Positional	B-Method
Encoding	I-Method
to	O
Control	O
Output	O
Sequence	O
Length	O
	
Neural	B-Method
encoder	I-Method
-	I-Method
decoder	I-Method
models	I-Method
have	O
been	O
successful	O
in	O
natural	B-Task
language	I-Task
generation	I-Task
tasks	I-Task
.	O
	
However	O
,	O
real	O
applications	O
of	O
abstractive	B-Task
summarization	I-Task
must	O
consider	O
additional	O
constraint	O
that	O
a	O
generated	O
summary	O
should	O
not	O
exceed	O
a	O
desired	O
length	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
simple	O
but	O
effective	O
extension	O
of	O
a	O
sinusoidal	B-Method
positional	I-Method
encoding	I-Method
to	O
enable	O
neural	B-Method
encoder	I-Method
-	I-Method
decoder	I-Method
model	I-Method
to	O
preserves	O
the	O
length	O
constraint	O
.	O
	
Unlike	O
in	O
previous	O
studies	O
where	O
that	O
learn	O
embeddings	O
representing	O
each	O
length	O
,	O
the	O
proposed	O
method	O
can	O
generate	O
a	O
text	O
of	O
any	O
length	O
even	O
if	O
the	O
target	O
length	O
is	O
not	O
present	O
in	O
training	O
data	O
.	O
	
The	O
experimental	O
results	O
show	O
that	O
the	O
proposed	O
method	O
can	O
not	O
only	O
control	O
the	O
generation	O
length	O
but	O
also	O
improve	O
the	O
ROUGE	B-Metric
scores	I-Metric
.	O
	
section	O
:	O
Introduction	O
	
Neural	B-Method
encoder	I-Method
-	I-Method
decoder	I-Method
models	I-Method
have	O
been	O
successfully	O
applied	O
to	O
various	O
natural	B-Task
language	I-Task
generation	I-Task
tasks	I-Task
including	O
machine	B-Task
translation	I-Task
,	O
summarization	B-Task
,	O
and	O
caption	B-Task
generation	I-Task
.	O
	
Still	O
,	O
it	O
is	O
necessary	O
to	O
control	O
the	O
output	O
length	O
for	O
abstractive	B-Task
summarization	I-Task
,	O
which	O
generates	O
a	O
summary	O
for	O
a	O
given	O
text	O
while	O
satisfying	O
a	O
space	O
constraint	O
.	O
	
In	O
fact	O
,	O
Figure	O
[	O
reference	O
]	O
shows	O
a	O
large	O
variance	O
in	O
output	O
sequences	O
produced	O
by	O
a	O
widely	O
used	O
encoder	B-Method
-	I-Method
decoder	I-Method
model	I-Method
,	O
which	O
has	O
no	O
mechanism	O
for	O
controlling	O
the	O
length	O
of	O
the	O
output	O
sequences	O
.	O
	
W18	O
-	O
2706	O
trained	O
embeddings	O
that	O
correspond	O
to	O
each	O
output	O
length	O
to	O
control	O
the	O
output	O
sequence	O
length	O
.	O
	
Since	O
the	O
embeddings	O
for	O
different	O
lengths	O
are	O
independent	O
,	O
it	O
is	O
hard	O
to	O
generate	O
a	O
sequence	O
of	O
the	O
length	O
that	O
is	O
infrequent	O
in	O
training	O
data	O
.	O
	
Thus	O
,	O
a	O
method	O
that	O
can	O
model	O
any	O
lengths	O
continuously	O
is	O
required	O
.	O
	
kikuchi	O
-	O
EtAl:2016:EMNLP2016	O
proposed	O
two	O
learning	B-Method
based	I-Method
methods	I-Method
for	O
an	O
LSTM	B-Method
encoder	I-Method
-	I-Method
decoder	I-Method
:	O
LenEmb	B-Method
and	O
LenInit	B-Method
.	O
	
LenEmb	B-Method
inputs	O
an	O
embedding	O
representing	O
the	O
remaining	O
length	O
in	O
each	O
decoding	O
step	O
.	O
	
Since	O
this	O
approach	O
also	O
prepares	O
embeddings	O
for	O
each	O
length	O
independently	O
,	O
it	O
suffers	O
from	O
the	O
same	O
problem	O
as	O
that	O
in	O
W18	O
-	O
2706	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
LenInit	B-Method
can	O
handle	O
arbitrary	O
lengths	O
because	O
it	O
combines	O
the	O
scalar	O
value	O
of	O
a	O
desired	O
length	O
with	O
a	O
trainable	B-Method
embedding	I-Method
.	O
	
LenInit	B-Method
initializes	O
the	O
LSTM	B-Method
cell	I-Method
of	O
the	O
decoder	B-Method
with	O
the	O
embedding	O
depending	O
on	O
the	O
scalar	O
value	O
of	O
the	O
desired	O
length	O
.	O
	
D18	O
-	O
1444	O
incorporated	O
such	O
scalar	O
values	O
into	O
the	O
initial	O
state	O
of	O
the	O
decoder	B-Method
in	O
a	O
CNN	B-Method
encoder	I-Method
-	I-Method
decoder	I-Method
.	O
	
These	O
approaches	O
deal	O
with	O
any	O
length	O
but	O
it	O
is	O
reasonable	O
to	O
incorporate	O
the	O
distance	O
to	O
the	O
desired	O
terminal	O
position	O
into	O
each	O
decoding	O
step	O
such	O
as	O
in	O
LenEmb	O
.	O
	
In	O
this	O
study	O
,	O
we	O
focused	O
on	O
Transformer	B-Method
,	O
which	O
recently	O
achieved	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
score	O
on	O
the	O
machine	B-Task
translation	I-Task
task	I-Task
.	O
	
We	O
extend	O
the	O
sinusoidal	B-Method
positional	I-Method
encoding	I-Method
,	O
which	O
represents	O
a	O
position	O
of	O
each	O
token	O
in	O
Transformer	O
,	O
to	O
represent	O
a	O
distance	O
from	O
a	O
terminal	O
position	O
on	O
the	O
decoder	O
side	O
.	O
	
In	O
this	O
way	O
,	O
the	O
proposed	O
method	O
considers	O
the	O
remaining	O
length	O
explicitly	O
at	O
each	O
decoding	O
step	O
.	O
	
Moreover	O
,	O
the	O
proposed	O
method	O
can	O
handle	O
any	O
desired	O
length	O
regardless	O
of	O
its	O
appearance	O
in	O
a	O
training	O
corpus	O
because	O
it	O
uses	O
the	O
same	O
continuous	O
space	O
for	O
any	O
length	O
.	O
	
We	O
conduct	O
experiments	O
on	O
the	O
headline	B-Task
generation	I-Task
task	I-Task
.	O
	
The	O
experimental	O
results	O
show	O
that	O
our	O
proposed	O
method	O
is	O
able	O
to	O
not	O
only	O
control	O
the	O
output	O
length	O
but	O
also	O
improve	O
the	O
ROUGE	B-Metric
scores	I-Metric
from	O
the	O
baselines	O
.	O
	
Our	O
code	O
and	O
constructed	O
test	O
data	O
are	O
publicly	O
available	O
at	O
:	O
https:	O
//	O
github.com	O
/	O
takase	O
/	O
control	O
-	O
lengthhttps:	O
//	O
github.com	O
/	O
takase	O
/	O
control	O
-	O
length	O
.	O
	
section	O
:	O
Positional	B-Method
Encoding	I-Method
	
Transformer	B-Method
uses	O
a	O
sinusoidal	B-Method
positional	I-Method
encoding	I-Method
to	O
represent	O
the	O
position	O
of	O
an	O
input	O
.	O
	
Transformer	B-Method
feeds	O
the	O
sum	O
of	O
the	O
positional	B-Method
encoding	I-Method
and	O
token	B-Method
embedding	I-Method
to	O
the	O
input	O
layer	O
of	O
its	O
encoder	B-Method
and	I-Method
decoder	I-Method
.	O
	
Let	O
be	O
the	O
position	O
and	O
be	O
the	O
embedding	O
size	O
.	O
	
Then	O
,	O
the	O
-	O
th	O
dimension	O
of	O
the	O
sinusoidal	B-Method
positional	I-Method
encoding	I-Method
is	O
as	O
follows	O
:	O
	
In	O
short	O
,	O
each	O
dimension	O
of	O
the	O
positional	B-Method
encoding	I-Method
corresponds	O
to	O
a	O
sinusoid	O
whose	O
period	O
is	O
.	O
	
Since	O
this	O
function	O
returns	O
an	O
identical	O
value	O
at	O
the	O
same	O
position	O
,	O
the	O
above	O
positional	B-Method
encoding	I-Method
can	O
be	O
interpreted	O
as	O
representing	O
the	O
absolute	O
position	O
of	O
each	O
input	O
token	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
extend	O
Equations	O
(	O
[	O
reference	O
]	O
)	O
and	O
(	O
[	O
reference	O
]	O
)	O
to	O
depend	O
on	O
the	O
given	O
output	O
length	O
and	O
the	O
distance	O
from	O
the	O
terminal	O
position	O
.	O
	
We	O
propose	O
two	O
extensions	O
:	O
length	B-Method
-	I-Method
difference	I-Method
positional	I-Method
encoding	I-Method
(	O
)	O
and	O
length	B-Method
-	I-Method
ratio	I-Method
positional	I-Method
encoding	I-Method
(	O
)	O
.	O
	
Then	O
we	O
replace	O
Equations	O
(	O
[	O
reference	O
]	O
)	O
and	O
(	O
[	O
reference	O
]	O
)	O
with	O
(	O
[	O
reference	O
]	O
)	O
and	O
(	O
[	O
reference	O
]	O
)	O
	
(	O
or	O
(	O
[	O
reference	O
]	O
)	O
and	O
(	O
[	O
reference	O
]	O
)	O
)	O
on	O
the	O
decoder	O
side	O
to	O
control	O
the	O
output	O
sequence	O
length	O
.	O
	
We	O
define	O
and	O
as	O
follows	O
:	O
where	O
presents	O
the	O
given	O
length	O
constraint	O
.	O
	
returns	O
an	O
identical	O
value	O
at	O
the	O
position	O
where	O
the	O
remaining	O
length	O
to	O
the	O
terminal	O
position	O
is	O
the	O
same	O
.	O
	
returns	O
a	O
similar	O
value	O
at	O
the	O
positions	O
where	O
the	O
ratio	O
of	O
the	O
remaining	O
length	O
to	O
the	O
terminal	O
position	O
is	O
similar	O
.	O
	
Let	O
us	O
consider	O
the	O
-	O
th	O
dimension	O
as	O
the	O
simplest	O
example	O
.	O
	
Since	O
we	O
obtain	O
(	O
or	O
)	O
at	O
this	O
dimension	O
,	O
the	O
equations	O
yield	O
the	O
same	O
value	O
when	O
the	O
remaining	O
length	O
ratio	O
is	O
the	O
same	O
,	O
e.g.	O
,	O
,	O
and	O
,	O
.	O
	
We	O
add	O
(	O
or	O
)	O
to	O
the	O
input	O
layer	O
of	O
Transformer	B-Method
in	O
the	O
same	O
manner	O
as	O
in	O
NIPS2017_7181	O
.	O
	
In	O
the	O
training	O
step	O
,	O
we	O
assign	O
the	O
length	O
of	O
the	O
correct	O
output	O
to	O
.	O
	
In	O
the	O
test	O
phase	O
,	O
we	O
control	O
the	O
output	O
length	O
by	O
assigning	O
the	O
desired	O
length	O
to	O
.	O
	
section	O
:	O
Experiments	O
	
subsection	O
:	O
Datasets	O
	
We	O
conduct	O
experiments	O
on	O
the	O
headline	B-Task
generation	I-Task
task	I-Task
on	O
Japanese	O
and	O
English	O
datasets	O
.	O
	
The	O
purpose	O
of	O
the	O
experiments	O
is	O
to	O
evaluate	O
the	O
ability	O
of	O
the	O
proposed	O
method	O
to	O
generate	O
a	O
summary	O
of	O
good	O
quality	O
within	O
a	O
specified	O
length	O
.	O
	
We	O
used	O
JAMUL	O
corpus	O
as	O
the	O
Japanese	O
test	O
set	O
.	O
	
This	O
test	O
set	O
contains	O
three	O
kinds	O
of	O
headlines	O
for	O
1	O
,	O
181	O
news	O
articles	O
written	O
by	O
professional	O
editors	O
under	O
the	O
different	O
upper	O
bounds	O
of	O
headline	O
lengths	O
.	O
	
The	O
upper	O
bounds	O
are	O
10	O
,	O
13	O
,	O
and	O
26	O
characters	O
(	O
)	O
.	O
	
This	O
test	O
set	O
is	O
suitable	O
for	O
simulating	O
the	O
real	B-Task
process	I-Task
of	I-Task
news	I-Task
production	I-Task
because	O
it	O
is	O
constructed	O
by	O
a	O
Japanese	O
media	O
company	O
.	O
	
In	O
contrast	O
,	O
we	O
have	O
no	O
English	O
test	O
sets	O
that	O
contain	O
headlines	O
of	O
multiple	O
lengths	O
.	O
	
Thus	O
,	O
we	O
randomly	O
extracted	O
3	O
,	O
000	O
sentence	O
-	O
headline	O
pairs	O
that	O
satisfy	O
a	O
length	O
constraint	O
from	O
the	O
test	O
set	O
constructed	O
from	O
annotated	O
English	O
Gigaword	O
by	O
pre	O
-	O
processing	O
scripts	O
of	O
rush	O
-	O
chopra	O
-	O
weston:2015:EMNLP	O
.	O
	
We	O
set	O
three	O
configurations	O
for	O
the	O
number	O
of	O
characters	O
as	O
the	O
length	O
constraint	O
:	O
0	O
to	O
30	O
characters	O
(	O
)	O
,	O
30	O
to	O
50	O
characters	O
(	O
)	O
,	O
and	O
50	O
to	O
75	O
characters	O
(	O
)	O
.	O
	
Moreover	O
,	O
we	O
also	O
evaluate	O
the	O
proposed	O
method	O
on	O
the	O
DUC	B-Material
-	I-Material
2004	I-Material
task	I-Material
1	I-Material
for	O
comparison	O
with	O
published	O
scores	O
in	O
previous	O
studies	O
.	O
	
Unfortunately	O
,	O
we	O
have	O
no	O
large	O
supervision	O
data	O
with	O
multiple	O
headlines	O
of	O
different	O
lengths	O
associated	O
with	O
each	O
news	O
article	O
in	O
both	O
languages	O
.	O
	
Thus	O
,	O
we	O
trained	O
the	O
proposed	O
method	O
on	O
pairs	O
with	O
a	O
one	O
-	O
to	O
-	O
one	O
correspondences	O
between	O
the	O
source	O
articles	O
and	O
headlines	O
.	O
	
In	O
the	O
training	O
step	O
,	O
we	O
regarded	O
the	O
length	O
of	O
the	O
target	O
headline	O
as	O
the	O
desired	O
length	O
.	O
	
For	O
Japanese	O
,	O
we	O
used	O
the	O
JNC	O
corpus	O
,	O
which	O
contains	O
a	O
pair	O
of	O
the	O
lead	O
three	O
sentences	O
of	O
a	O
news	O
article	O
and	O
its	O
headline	O
.	O
	
The	O
training	O
set	O
contains	O
about	O
1.6	O
M	O
pairs	O
.	O
	
For	O
English	O
,	O
we	O
used	O
sentence	O
-	O
headline	O
pairs	O
extracted	O
from	O
the	O
annotated	O
English	O
Gigaword	O
with	O
the	O
same	O
pre	O
-	O
processing	O
script	O
used	O
in	O
the	O
construction	O
of	O
the	O
test	O
set	O
.	O
	
The	O
training	O
set	O
contains	O
about	O
3.8	O
M	O
pairs	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
used	O
a	O
character	B-Method
-	I-Method
level	I-Method
decoder	I-Method
to	O
control	O
the	O
number	O
of	O
characters	O
.	O
	
On	O
the	O
encoder	O
side	O
,	O
we	O
used	O
subword	O
units	O
to	O
construct	O
the	O
vocabulary	O
.	O
	
We	O
set	O
the	O
hyper	O
-	O
parameter	O
to	O
fit	O
the	O
vocabulary	O
size	O
to	O
about	O
8k	O
for	O
Japanese	O
and	O
16k	O
for	O
English	O
.	O
	
subsection	O
:	O
Baselines	O
	
We	O
implemented	O
two	O
methods	O
proposed	O
by	O
previous	O
studies	O
to	O
control	O
the	O
output	O
length	O
and	O
handle	O
arbitrary	O
lengths	O
.	O
	
We	O
employed	O
them	O
and	O
Transformer	B-Method
as	O
baselines	O
.	O
	
paragraph	O
:	O
LenInit	O
	
kikuchi	O
-	O
EtAl:2016:EMNLP2016	O
proposed	O
LenInit	B-Method
,	O
which	O
controls	O
the	O
output	O
length	O
by	O
initializing	O
the	O
LSTM	B-Method
cell	I-Method
of	O
the	O
decoder	B-Method
as	O
follows	O
:	O
where	O
is	O
a	O
trainable	O
vector	O
.	O
	
We	O
incorporated	O
this	O
method	O
with	O
a	O
widely	O
used	O
LSTM	B-Method
encoder	I-Method
-	I-Method
decoder	I-Method
model	I-Method
.	O
	
For	O
a	O
fair	O
comparison	O
,	O
we	O
set	O
the	O
same	O
hyper	O
-	O
parameters	O
as	O
in	O
D18	O
-	O
1489	O
because	O
they	O
indicated	O
that	O
the	O
LSTM	B-Method
encoder	I-Method
-	I-Method
decoder	I-Method
model	I-Method
trained	O
with	O
the	O
hyper	O
-	O
parameters	O
achieved	O
a	O
similar	O
performance	O
to	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
on	O
the	O
headline	B-Task
generation	I-Task
.	O
	
paragraph	O
:	O
Length	O
Control	O
(	O
LC	O
)	O
	
D18	O
-	O
1444	O
proposed	O
a	O
length	B-Method
control	I-Method
method	I-Method
that	O
multiplies	O
the	O
desired	O
length	O
by	O
input	O
token	O
embeddings	O
.	O
	
We	O
trained	O
the	O
model	O
with	O
their	O
hyper	O
-	O
parameters	O
.	O
	
paragraph	O
:	O
Transformer	B-Method
	
Our	O
proposed	O
method	O
is	O
based	O
on	O
Transformer	B-Method
.	O
	
We	O
trained	O
Transformer	B-Method
with	O
the	O
equal	O
hyper	O
-	O
parameters	O
as	O
in	O
the	O
base	O
model	O
in	O
NIPS2017_7181	O
.	O
	
subsection	O
:	O
Results	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
recall	O
-	O
oriented	O
ROUGE	B-Metric
-	I-Metric
1	I-Metric
(	O
R	B-Metric
-	I-Metric
1	I-Metric
)	O
,	O
2	O
(	O
R	B-Metric
-	I-Metric
2	I-Metric
)	O
,	O
and	O
L	O
(	O
R	B-Metric
-	I-Metric
L	I-Metric
)	O
scores	O
of	O
each	O
method	O
on	O
the	O
Japanese	O
test	O
set	O
.	O
	
This	O
table	O
indicates	O
that	O
Transformer	B-Method
with	O
the	O
proposed	O
method	O
(	O
Transformer	B-Method
+	I-Method
and	O
Transformer	B-Method
+	I-Method
)	O
outperformed	O
the	O
baselines	O
for	O
all	O
given	O
constraints	O
(	O
)	O
.	O
	
Transformer	B-Method
+	I-Method
performed	O
slightly	O
better	O
than	O
Transformer	B-Method
+	I-Method
.	O
	
Moreover	O
,	O
we	O
improved	O
the	O
performance	O
by	O
incorporating	O
the	O
standard	O
sinusoidal	B-Method
positional	I-Method
encoding	I-Method
(	O
+	O
)	O
on	O
and	O
.	O
	
The	O
results	O
imply	O
that	O
the	O
absolute	O
position	O
also	O
helps	O
to	O
generate	O
better	O
headlines	O
while	O
controlling	O
the	O
output	O
length	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
recall	O
-	O
oriented	O
ROUGE	B-Metric
scores	I-Metric
on	O
the	O
English	O
Gigaword	O
test	O
set	O
.	O
	
This	O
table	O
indicates	O
that	O
and	O
significantly	O
improved	O
the	O
performance	O
on	O
.	O
	
Moreover	O
,	O
the	O
absolute	O
position	O
(	O
)	O
also	O
improved	O
the	O
performance	O
in	O
this	O
test	O
set	O
.	O
	
In	O
particular	O
,	O
was	O
very	O
effective	O
in	O
the	O
setting	O
of	O
very	O
short	O
headlines	O
(	O
)	O
.	O
	
However	O
,	O
the	O
proposed	O
method	O
slightly	O
lowered	O
ROUGE	B-Metric
-	I-Metric
2	I-Metric
scores	I-Metric
from	O
the	O
bare	O
Transformer	O
on	O
.	O
	
We	O
infer	O
that	O
the	O
bare	B-Method
Transformer	I-Method
can	O
generate	O
headlines	O
whose	O
lengths	O
are	O
close	O
to	O
30	O
and	O
50	O
because	O
the	O
majority	O
of	O
the	O
training	O
set	O
consists	O
of	O
headlines	O
whose	O
lengths	O
are	O
less	O
than	O
or	O
equal	O
to	O
50	O
.	O
	
However	O
,	O
most	O
of	O
the	O
generated	O
headlines	O
breached	O
the	O
length	O
constraints	O
,	O
as	O
explained	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
To	O
investigate	O
whether	O
the	O
proposed	O
method	O
can	O
generate	O
good	O
headlines	O
for	O
unseen	O
lengths	O
,	O
we	O
excluded	O
headlines	O
whose	O
lengths	O
are	O
equal	O
to	O
the	O
desired	O
length	O
(	O
)	O
from	O
the	O
training	O
data	O
.	O
	
The	O
lower	O
parts	O
of	O
Table	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
show	O
ROUGE	B-Metric
scores	I-Metric
of	O
the	O
proposed	O
method	O
trained	O
on	O
the	O
modified	O
training	O
data	O
.	O
	
These	O
parts	O
show	O
that	O
the	O
proposed	O
method	O
achieved	O
comparable	O
scores	O
to	O
ones	O
trained	O
on	O
whole	O
training	O
dataset	O
.	O
	
These	O
results	O
indicate	O
that	O
the	O
proposed	O
method	O
can	O
generate	O
high	O
-	O
quality	O
headlines	O
even	O
if	O
the	O
length	O
does	O
not	O
appear	O
in	O
the	O
training	O
data	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
recall	O
-	O
oriented	O
ROUGE	B-Metric
scores	I-Metric
on	O
the	O
DUC	B-Material
-	I-Material
2004	I-Material
test	I-Material
set	I-Material
.	O
	
Following	O
the	O
evaluation	O
protocol	O
,	O
we	O
truncated	O
characters	O
over	O
75	O
bytes	O
.	O
	
The	O
table	O
indicates	O
that	O
and	O
significantly	O
improved	O
the	O
performance	O
compared	O
to	O
the	O
bare	O
Transformer	O
,	O
and	O
achieved	O
better	O
performance	O
than	O
the	O
baselines	O
except	O
for	O
R	B-Metric
-	I-Metric
2	I-Metric
of	O
LenInit	B-Method
.	O
	
This	O
table	O
also	O
shows	O
the	O
scores	O
reported	O
in	O
the	O
previous	O
studies	O
.	O
	
The	O
proposed	O
method	O
outperformed	O
the	O
previous	O
methods	O
that	O
control	O
the	O
output	O
length	O
and	O
achieved	O
the	O
competitive	O
score	O
to	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
scores	O
.	O
	
Since	O
the	O
proposed	O
method	O
consists	O
of	O
a	O
character	B-Method
-	I-Method
based	I-Method
decoder	I-Method
,	O
it	O
sometimes	O
generated	O
words	O
unrelated	O
to	O
a	O
source	O
sentence	O
.	O
	
Thus	O
,	O
we	O
applied	O
a	O
simple	O
re	B-Method
-	I-Method
ranking	I-Method
to	O
each	O
-	O
best	O
headlines	O
generated	O
by	O
the	O
proposed	O
method	O
(	O
in	O
this	O
experiment	O
)	O
based	O
on	O
the	O
contained	O
words	O
.	O
	
Our	O
re	B-Method
-	I-Method
ranking	I-Method
strategy	I-Method
selects	O
a	O
headline	O
that	O
contains	O
source	O
-	O
side	O
words	O
the	O
most	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
that	O
Transformer	B-Method
+	I-Method
+	I-Method
with	O
this	O
re	B-Method
-	I-Method
ranking	I-Method
(	O
+	O
Re	B-Metric
-	I-Metric
ranking	I-Metric
)	O
achieved	O
better	O
scores	O
than	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
.	O
	
subsection	O
:	O
Analysis	O
of	O
Output	B-Metric
Length	I-Metric
	
Following	O
D18	O
-	O
1444	O
,	O
we	O
used	O
the	O
variance	O
of	O
the	O
generated	O
summary	O
lengths	O
against	O
the	O
desired	O
lengths	O
as	O
an	O
indicator	O
of	O
the	O
preciseness	O
of	O
the	O
output	O
lengths	O
.	O
	
We	O
calculated	O
variance	O
(	O
)	O
for	O
generated	O
summaries	O
as	O
follows	O
:	O
where	O
is	O
the	O
desired	O
length	O
and	O
is	O
the	O
length	O
of	O
the	O
generated	O
summary	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
values	O
of	O
Equation	O
(	O
[	O
reference	O
]	O
)	O
computed	O
for	O
each	O
method	O
and	O
the	O
desired	O
lengths	O
.	O
	
This	O
table	O
indicates	O
that	O
could	O
control	O
the	O
length	O
of	O
headlines	O
precisely	O
.	O
	
In	O
particular	O
,	O
could	O
generate	O
headlines	O
with	O
the	O
identical	O
length	O
to	O
the	O
desired	O
one	O
in	O
comparison	O
with	O
LenInit	B-Method
and	O
LC	B-Method
.	O
also	O
generated	O
headlines	O
with	O
a	O
precise	O
length	O
but	O
its	O
variance	O
is	O
larger	O
than	O
those	O
of	O
previous	O
studies	O
in	O
very	O
short	O
lengths	O
,	O
i.e.	O
,	O
and	O
in	O
Japanese	O
.	O
	
However	O
,	O
we	O
consider	O
is	O
enough	O
for	O
real	O
applications	O
because	O
the	O
averaged	O
difference	O
between	O
its	O
output	O
and	O
the	O
desired	O
length	O
is	O
small	O
,	O
e.g.	O
,	O
for	O
.	O
	
The	O
lower	O
part	O
of	O
Table	O
[	O
reference	O
]	O
shows	O
the	O
variances	O
of	O
the	O
proposed	O
method	O
trained	O
on	O
the	O
modified	O
training	O
data	O
that	O
does	O
not	O
contain	O
headlines	O
whose	O
lengths	O
are	O
equal	O
to	O
the	O
desired	O
length	O
,	O
similar	O
to	O
the	O
lower	O
parts	O
of	O
Table	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
.	O
	
The	O
variances	O
for	O
this	O
part	O
are	O
comparable	O
to	O
the	O
ones	O
obtained	O
when	O
we	O
trained	O
the	O
proposed	O
method	O
with	O
whole	O
training	O
dataset	O
.	O
	
This	O
fact	O
indicates	O
that	O
the	O
proposed	O
method	O
can	O
generate	O
an	O
output	O
that	O
satisfies	O
the	O
constraint	O
of	O
the	O
desired	O
length	O
even	O
if	O
the	O
training	O
data	O
does	O
not	O
contain	O
instances	O
of	O
such	O
a	O
length	O
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
paper	O
,	O
we	O
proposed	O
length	B-Method
-	I-Method
dependent	I-Method
positional	I-Method
encodings	I-Method
,	O
and	O
,	O
that	O
can	O
control	O
the	O
output	O
sequence	O
length	O
in	O
Transformer	O
.	O
	
The	O
experimental	O
results	O
demonstrate	O
that	O
the	O
proposed	O
method	O
can	O
generate	O
a	O
headline	O
with	O
the	O
desired	O
length	O
even	O
if	O
the	O
desired	O
length	O
is	O
not	O
present	O
in	O
the	O
training	O
data	O
.	O
	
Moreover	O
,	O
the	O
proposed	O
method	O
significantly	O
improved	O
the	O
quality	B-Metric
of	O
headlines	B-Task
on	O
the	O
Japanese	B-Task
headline	I-Task
generation	I-Task
task	I-Task
while	O
preserving	O
the	O
given	O
length	O
constraint	O
.	O
	
For	O
English	O
,	O
the	O
proposed	O
method	O
also	O
generated	O
headlines	O
with	O
the	O
desired	O
length	O
precisely	O
and	O
achieved	O
the	O
top	O
ROUGE	B-Metric
scores	I-Metric
on	O
the	O
DUC	B-Material
-	I-Material
2004	I-Material
test	I-Material
set	I-Material
.	O
	
section	O
:	O
Acknowledgments	O
	
The	O
research	O
results	O
have	O
been	O
achieved	O
by	O
“	O
Research	O
and	O
Development	O
of	O
Deep	B-Method
Learning	I-Method
Technology	I-Method
for	O
Advanced	B-Task
Multilingual	I-Task
Speech	I-Task
Translation	I-Task
”	O
,	O
the	O
Commissioned	O
Research	O
of	O
National	O
Institute	O
of	O
Information	O
and	O
Communications	O
Technology	O
(	O
NICT	O
)	O
,	O
Japan	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Wide	B-Method
Residual	I-Method
Networks	I-Method
	
Deep	B-Method
residual	I-Method
networks	I-Method
were	O
shown	O
to	O
be	O
able	O
to	O
scale	O
up	O
to	O
thousands	O
of	O
layers	O
and	O
still	O
have	O
improving	O
performance	O
.	O
	
However	O
,	O
each	O
fraction	O
of	O
a	O
percent	O
of	O
improved	O
accuracy	B-Metric
costs	O
nearly	O
doubling	O
the	O
number	O
of	O
layers	O
,	O
and	O
so	O
training	O
very	O
deep	B-Method
residual	I-Method
networks	I-Method
has	O
a	O
problem	O
of	O
diminishing	B-Task
feature	I-Task
reuse	I-Task
,	O
which	O
makes	O
these	O
networks	O
very	O
slow	O
to	O
train	O
.	O
	
To	O
tackle	O
these	O
problems	O
,	O
in	O
this	O
paper	O
we	O
conduct	O
a	O
detailed	O
experimental	O
study	O
on	O
the	O
architecture	O
of	O
ResNet	B-Method
blocks	I-Method
,	O
based	O
on	O
which	O
we	O
propose	O
a	O
novel	O
architecture	O
where	O
we	O
decrease	O
depth	O
and	O
increase	O
width	O
of	O
residual	B-Method
networks	I-Method
.	O
	
We	O
call	O
the	O
resulting	O
network	O
structures	O
wide	B-Method
residual	I-Method
networks	I-Method
(	O
WRNs	B-Method
)	O
and	O
show	O
that	O
these	O
are	O
far	O
superior	O
over	O
their	O
commonly	O
used	O
thin	O
and	O
very	O
deep	O
counterparts	O
.	O
	
For	O
example	O
,	O
we	O
demonstrate	O
that	O
even	O
a	O
simple	O
16	B-Method
-	I-Method
layer	I-Method
-	I-Method
deep	I-Method
wide	I-Method
residual	I-Method
network	I-Method
outperforms	O
in	O
accuracy	B-Metric
and	O
efficiency	O
all	O
previous	O
deep	B-Method
residual	I-Method
networks	I-Method
,	O
including	O
thousand	B-Method
-	I-Method
layer	I-Method
-	I-Method
deep	I-Method
networks	I-Method
,	O
achieving	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
CIFAR	B-Material
,	O
SVHN	B-Material
,	O
COCO	O
,	O
and	O
significant	O
improvements	O
on	O
ImageNet	O
.	O
	
Our	O
code	O
and	O
models	O
are	O
available	O
at	O
https:	O
//	O
github.com	O
/	O
szagoruyko	O
/	O
wide	O
-	O
residual	O
-	O
networks	O
.	O
	
[	O
reference	O
]	O
[	O
reference	O
]	O
SergeyZagoruykosergey.zagoruyko@enpc.fr1	O
	
NikosKomodakisnikos.komodakis@enpc.fr1	O
UniversitéParis	O
-	O
Est	O
,	O
ÉcoledesPontsParisTech	O
Paris	O
,	O
France	O
SergeyZagoruykoandNikosKomodakisWideresidualnetworks	O
	
section	O
:	O
Introduction	O
	
Convolutional	B-Method
neural	I-Method
networks	I-Method
have	O
seen	O
a	O
gradual	O
increase	O
of	O
the	O
number	O
of	O
layers	O
in	O
the	O
last	O
few	O
years	O
,	O
starting	O
from	O
AlexNet	B-Method
,	O
VGG	B-Method
,	O
Inception	O
to	O
Residual	B-Method
networks	I-Method
,	O
corresponding	O
to	O
improvements	O
in	O
many	O
image	B-Task
recognition	I-Task
tasks	I-Task
.	O
	
The	O
superiority	O
of	O
deep	B-Method
networks	I-Method
has	O
been	O
spotted	O
in	O
several	O
works	O
in	O
the	O
recent	O
years	O
.	O
	
However	O
,	O
training	O
deep	B-Method
neural	I-Method
networks	I-Method
has	O
several	O
difficulties	O
,	O
including	O
exploding	O
/	O
vanishing	O
gradients	O
and	O
degradation	O
.	O
	
Various	O
techniques	O
were	O
suggested	O
to	O
enable	O
training	O
of	O
deeper	B-Method
neural	I-Method
networks	I-Method
,	O
such	O
as	O
well	O
-	O
designed	O
initialization	B-Method
strategies	I-Method
,	O
better	O
optimizers	B-Method
,	O
skip	O
connections	O
,	O
knowledge	B-Method
transfer	I-Method
and	O
layer	B-Method
-	I-Method
wise	I-Method
training	I-Method
.	O
	
The	O
latest	O
residual	B-Method
networks	I-Method
had	O
a	O
large	O
success	O
winning	O
ImageNet	O
and	O
COCO	O
2015	O
competition	O
and	O
achieving	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
in	O
several	O
benchmarks	O
,	O
including	O
object	B-Task
classification	I-Task
on	O
ImageNet	O
and	O
CIFAR	B-Material
,	O
object	B-Task
detection	I-Task
and	I-Task
segmentation	I-Task
on	O
PASCAL	O
VOC	O
and	O
MS	O
COCO	O
.	O
	
Compared	O
to	O
Inception	B-Method
architectures	I-Method
they	O
show	O
better	O
generalization	B-Task
,	O
meaning	O
the	O
features	O
can	O
be	O
utilized	O
in	O
transfer	B-Method
learning	I-Method
with	O
better	O
efficiency	O
.	O
	
Also	O
,	O
follow	O
-	O
up	O
work	O
showed	O
that	O
residual	O
links	O
speed	O
up	O
convergence	B-Task
of	O
deep	B-Method
networks	I-Method
.	O
	
Recent	O
follow	O
-	O
up	O
work	O
explored	O
the	O
order	O
of	O
activations	O
in	O
residual	B-Method
networks	I-Method
,	O
presenting	O
identity	O
mappings	O
in	O
residual	O
blocks	O
and	O
improving	O
training	O
of	O
very	B-Method
deep	I-Method
networks	I-Method
.	O
	
Successful	O
training	O
of	O
very	B-Task
deep	I-Task
networks	I-Task
was	O
also	O
shown	O
to	O
be	O
possible	O
through	O
the	O
use	O
of	O
highway	B-Method
networks	I-Method
,	O
which	O
is	O
an	O
architecture	O
that	O
had	O
been	O
proposed	O
prior	O
to	O
residual	B-Method
networks	I-Method
.	O
	
The	O
essential	O
difference	O
between	O
residual	B-Method
and	I-Method
highway	I-Method
networks	I-Method
is	O
that	O
in	O
the	O
latter	O
residual	O
links	O
are	O
gated	O
and	O
weights	O
of	O
these	O
gates	O
are	O
learned	O
.	O
	
Therefore	O
,	O
up	O
to	O
this	O
point	O
,	O
the	O
study	O
of	O
residual	B-Task
networks	I-Task
has	O
focused	O
mainly	O
on	O
the	O
order	O
of	O
activations	O
inside	O
a	O
ResNet	O
block	O
and	O
the	O
depth	B-Method
of	I-Method
residual	I-Method
networks	I-Method
.	O
	
In	O
this	O
work	O
we	O
attempt	O
to	O
conduct	O
an	O
experimental	O
study	O
that	O
goes	O
beyond	O
the	O
above	O
points	O
.	O
	
By	O
doing	O
so	O
,	O
our	O
goal	O
is	O
to	O
explore	O
a	O
much	O
richer	O
set	O
of	O
network	B-Method
architectures	I-Method
of	O
ResNet	B-Method
blocks	I-Method
and	O
thoroughly	O
examine	O
how	O
several	O
other	O
different	O
aspects	O
besides	O
the	O
order	O
of	O
activations	O
affect	O
performance	O
.	O
	
As	O
we	O
explain	O
below	O
,	O
such	O
an	O
exploration	O
of	O
architectures	O
has	O
led	O
to	O
new	O
interesting	O
findings	O
with	O
great	O
practical	O
importance	O
concerning	O
residual	B-Method
networks	I-Method
.	O
	
Width	O
vs	O
depth	O
in	O
residual	B-Method
networks	I-Method
.	O
	
The	O
problem	O
of	O
shallow	B-Task
vs	I-Task
deep	I-Task
networks	I-Task
has	O
been	O
in	O
discussion	O
for	O
a	O
long	O
time	O
in	O
machine	B-Task
learning	I-Task
with	O
pointers	O
to	O
the	O
circuit	B-Metric
complexity	I-Metric
theory	I-Metric
literature	I-Metric
showing	O
that	O
shallow	O
circuits	O
can	O
require	O
exponentially	O
more	O
components	O
than	O
deeper	O
circuits	O
.	O
	
The	O
authors	O
of	O
residual	B-Method
networks	I-Method
tried	O
to	O
make	O
them	O
as	O
thin	O
as	O
possible	O
in	O
favor	O
of	O
increasing	O
their	O
depth	O
and	O
having	O
less	O
parameters	O
,	O
and	O
even	O
introduced	O
	
a	O
¡	O
¡	O
bottleneck	O
¿	O
¿	O
block	O
which	O
makes	O
ResNet	B-Method
blocks	I-Method
even	O
thinner	O
.	O
	
[	O
basic	O
]	O
	
[	O
scale=0.4	O
]	O
images	O
/	O
basic_a.pdf	O
[	O
bottleneck	O
]	O
	
[	O
scale=0.4	O
]	O
images	O
/	O
	
basic_b.pdf	O
[	O
basic	O
-	O
wide	O
]	O
	
[	O
scale=0.4	O
]	O
images	O
/	O
	
basic_c.pdf	O
	
[	O
wide	B-Method
-	I-Method
dropout	I-Method
]	O
	
[	O
scale=0.4	O
]	O
images	O
/	O
	
basic_d.pdf	O
	
We	O
note	O
,	O
however	O
,	O
that	O
the	O
residual	B-Method
block	I-Method
with	O
identity	B-Method
mapping	I-Method
that	O
allows	O
to	O
train	O
very	O
deep	B-Method
networks	I-Method
is	O
at	O
the	O
same	O
time	O
a	O
weakness	O
of	O
residual	B-Method
networks	I-Method
.	O
	
As	O
gradient	O
flows	O
through	O
the	O
network	O
there	O
is	O
nothing	O
to	O
force	O
it	O
to	O
go	O
through	O
residual	O
block	O
weights	O
	
and	O
it	O
can	O
avoid	O
learning	O
anything	O
during	O
training	O
,	O
so	O
it	O
is	O
possible	O
that	O
there	O
is	O
either	O
only	O
a	O
few	O
blocks	O
that	O
learn	O
useful	O
representations	O
,	O
or	O
many	O
blocks	O
share	O
very	O
little	O
information	O
with	O
small	O
contribution	O
to	O
the	O
final	O
goal	O
.	O
	
This	O
problem	O
was	O
formulated	O
as	O
diminishing	B-Task
feature	I-Task
reuse	I-Task
in	O
.	O
	
The	O
authors	O
of	O
tried	O
to	O
address	O
this	O
problem	O
with	O
the	O
idea	O
of	O
randomly	O
disabling	O
residual	O
blocks	O
during	O
training	O
.	O
	
This	O
method	O
can	O
be	O
viewed	O
as	O
a	O
special	O
case	O
of	O
dropout	B-Method
,	O
where	O
each	O
residual	O
block	O
has	O
an	O
identity	O
scalar	O
weight	O
on	O
which	O
dropout	B-Method
is	O
applied	O
.	O
	
The	O
effectiveness	O
of	O
this	O
approach	O
proves	O
the	O
hypothesis	O
above	O
.	O
	
Motivated	O
by	O
the	O
above	O
observation	O
,	O
our	O
work	O
builds	O
on	O
top	O
of	O
and	O
tries	O
to	O
answer	O
the	O
question	O
of	O
how	O
wide	O
deep	B-Method
residual	I-Method
networks	I-Method
should	O
be	O
and	O
address	O
the	O
problem	O
of	O
training	B-Task
.	O
	
In	O
this	O
context	O
,	O
we	O
show	O
that	O
the	O
widening	O
of	O
ResNet	B-Method
blocks	I-Method
(	O
if	O
done	O
properly	O
)	O
provides	O
a	O
much	O
more	O
effective	O
way	O
of	O
improving	O
performance	O
of	O
residual	B-Method
networks	I-Method
compared	O
to	O
increasing	O
their	O
depth	O
.	O
	
In	O
particular	O
,	O
we	O
present	O
wider	O
deep	B-Method
residual	I-Method
networks	I-Method
that	O
significantly	O
improve	O
over	O
,	O
having	O
50	O
times	O
less	O
layers	O
and	O
being	O
more	O
than	O
2	O
times	O
faster	O
.	O
	
We	O
call	O
the	O
resulting	O
network	B-Method
architectures	I-Method
wide	I-Method
residual	I-Method
networks	I-Method
.	O
	
For	O
instance	O
,	O
our	O
wide	B-Method
16	I-Method
-	I-Method
layer	I-Method
deep	I-Method
network	I-Method
has	O
the	O
same	O
accuracy	B-Metric
as	O
a	O
1000	B-Method
-	I-Method
layer	I-Method
thin	I-Method
deep	I-Method
network	I-Method
and	O
a	O
comparable	O
number	O
of	O
parameters	O
,	O
although	O
being	O
several	O
times	O
faster	O
to	O
train	O
.	O
	
This	O
type	O
of	O
experiments	O
thus	O
seem	O
to	O
indicate	O
that	O
the	O
main	O
power	O
of	O
deep	B-Method
residual	I-Method
networks	I-Method
is	O
in	O
residual	O
blocks	O
,	O
and	O
that	O
the	O
effect	O
of	O
depth	O
is	O
supplementary	O
.	O
	
We	O
note	O
that	O
one	O
can	O
train	O
even	O
better	O
wide	B-Method
residual	I-Method
networks	I-Method
that	O
have	O
twice	O
as	O
many	O
parameters	O
(	O
and	O
more	O
)	O
,	O
which	O
suggests	O
that	O
to	O
further	O
improve	O
performance	O
by	O
increasing	O
depth	O
of	O
thin	B-Method
networks	I-Method
one	O
needs	O
to	O
add	O
thousands	O
of	O
layers	O
in	O
this	O
case	O
.	O
	
Use	O
of	O
dropout	B-Method
in	O
ResNet	B-Method
blocks	I-Method
.	O
	
Dropout	B-Method
was	O
first	O
introduced	O
in	O
and	O
then	O
was	O
adopted	O
by	O
many	O
successful	O
architectures	O
as	O
etc	O
.	O
	
It	O
was	O
mostly	O
applied	O
on	O
top	O
layers	O
that	O
had	O
a	O
large	O
number	O
of	O
parameters	O
to	O
prevent	O
feature	O
coadaptation	O
and	O
overfitting	O
.	O
	
It	O
was	O
then	O
mainly	O
substituted	O
by	O
batch	B-Method
normalization	I-Method
which	O
was	O
introduced	O
as	O
a	O
technique	O
to	O
reduce	O
internal	O
covariate	O
shift	O
in	O
neural	O
network	O
activations	O
by	O
normalizing	O
them	O
to	O
have	O
specific	O
distribution	O
.	O
	
It	O
also	O
works	O
as	O
a	O
regularizer	B-Method
and	O
the	O
authors	O
experimentally	O
showed	O
that	O
a	O
network	O
with	O
batch	B-Method
normalization	I-Method
achieves	O
better	O
accuracy	B-Metric
than	O
a	O
network	O
with	O
dropout	B-Method
.	O
	
In	O
our	O
case	O
,	O
as	O
widening	B-Task
of	I-Task
residual	I-Task
blocks	I-Task
results	O
in	O
an	O
increase	O
of	O
the	O
number	O
of	O
parameters	O
,	O
we	O
studied	O
the	O
effect	O
of	O
dropout	B-Method
to	O
regularize	B-Task
training	I-Task
and	O
prevent	O
overfitting	O
.	O
	
Previously	O
,	O
dropout	B-Method
in	I-Method
residual	I-Method
networks	I-Method
was	O
studied	O
in	O
with	O
dropout	B-Method
being	O
inserted	O
in	O
the	O
identity	O
part	O
of	O
the	O
block	O
,	O
and	O
the	O
authors	O
showed	O
negative	O
effects	O
of	O
that	O
.	O
	
Instead	O
,	O
we	O
argue	O
here	O
that	O
dropout	O
should	O
be	O
inserted	O
between	O
convolutional	B-Method
layers	I-Method
.	O
	
Experimental	O
results	O
on	O
wide	B-Method
residual	I-Method
networks	I-Method
show	O
that	O
this	O
leads	O
to	O
consistent	O
gains	O
,	O
yielding	O
even	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
(	O
e.g	O
,	O
16	B-Method
-	I-Method
layer	I-Method
-	I-Method
deep	I-Method
wide	I-Method
residual	I-Method
network	I-Method
with	O
dropout	B-Method
achieves	O
1.64	O
%	O
error	B-Metric
on	O
SVHN	B-Material
)	O
.	O
	
In	O
summary	O
,	O
the	O
contributions	O
of	O
this	O
work	O
are	O
as	O
follows	O
:	O
	
We	O
present	O
a	O
detailed	O
experimental	O
study	O
of	O
residual	B-Method
network	I-Method
architectures	I-Method
that	O
thoroughly	O
examines	O
several	O
important	O
aspects	O
of	O
ResNet	O
block	O
structure	O
.	O
	
We	O
propose	O
a	O
novel	O
widened	B-Method
architecture	I-Method
for	O
ResNet	B-Method
blocks	I-Method
that	O
allows	O
for	O
residual	B-Method
networks	I-Method
with	O
significantly	O
improved	O
performance	O
.	O
	
We	O
propose	O
a	O
new	O
way	O
of	O
utilizing	O
dropout	B-Method
within	O
deep	B-Method
residual	I-Method
networks	I-Method
so	O
as	O
to	O
properly	O
regularize	O
them	O
and	O
prevent	O
overfitting	O
during	O
training	O
.	O
	
Last	O
,	O
we	O
show	O
that	O
our	O
proposed	O
ResNet	B-Method
architectures	I-Method
achieve	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
several	O
datasets	O
dramatically	O
improving	O
accuracy	B-Metric
and	O
speed	B-Metric
of	O
residual	B-Method
networks	I-Method
.	O
	
section	O
:	O
Wide	B-Method
residual	I-Method
networks	I-Method
	
Residual	B-Method
block	I-Method
with	O
identity	B-Method
mapping	I-Method
can	O
be	O
represented	O
by	O
the	O
following	O
formula	O
:	O
where	O
and	O
are	O
input	O
and	O
output	O
of	O
the	O
-	O
th	O
unit	O
in	O
the	O
network	O
,	O
is	O
a	O
residual	O
function	O
and	O
are	O
parameters	O
of	O
the	O
block	O
.	O
	
Residual	B-Method
network	I-Method
consists	O
of	O
sequentially	O
stacked	O
residual	O
blocks	O
.	O
	
In	O
residual	B-Method
networks	I-Method
consisted	O
of	O
two	O
type	O
of	O
blocks	O
:	O
basic	O
-	O
with	O
two	O
consecutive	B-Method
convolutions	I-Method
with	O
batch	B-Method
normalization	I-Method
and	O
ReLU	B-Method
preceding	I-Method
convolution	I-Method
:	O
conv×33	B-Method
-	I-Method
conv×33	I-Method
Fig	O
.	O
	
[	O
reference	O
]	O
bottleneck	O
-	O
with	O
one	O
convolution	B-Method
surrounded	O
by	O
dimensionality	B-Method
reducing	I-Method
and	I-Method
expanding	I-Method
convolution	I-Method
layers	I-Method
:	O
	
conv×11	B-Method
-	I-Method
conv×33	I-Method
-	I-Method
conv×11	I-Method
Fig	O
.	O
	
[	O
reference	O
]	O
	
Compared	O
to	O
the	O
original	O
architecture	O
in	O
the	O
order	O
of	O
batch	O
normalization	O
,	O
activation	O
and	O
convolution	O
in	O
residual	O
block	O
was	O
changed	O
from	O
conv	B-Method
-	I-Method
BN	I-Method
-	I-Method
ReLU	I-Method
to	O
BN	B-Method
-	I-Method
ReLU	I-Method
-	I-Method
conv	I-Method
.	O
	
As	O
the	O
latter	O
was	O
shown	O
to	O
train	O
faster	O
and	O
achieve	O
better	O
results	O
we	O
do	O
n’t	O
consider	O
the	O
original	O
version	O
.	O
	
Furthermore	O
,	O
so	O
-	O
called	O
¡	O
¡	O
bottleneck	O
	
¿	O
¿	O
blocks	O
were	O
initially	O
used	O
to	O
make	O
blocks	O
less	O
computationally	O
expensive	O
to	O
increase	O
the	O
number	O
of	O
layers	O
.	O
	
As	O
we	O
want	O
to	O
study	O
the	O
effect	O
of	O
widening	O
and	O
	
¡	O
¡	O
bottleneck	O
¿	O
¿	O
is	O
used	O
to	O
make	O
networks	O
thinner	O
we	O
do	O
n’t	O
consider	O
it	O
too	O
,	O
focusing	O
instead	O
on	O
	
¡	O
¡	O
basic	O
¿	O
¿	O
residual	B-Method
architecture	I-Method
.	O
	
There	O
are	O
essentially	O
three	O
simple	O
ways	O
to	O
increase	O
representational	O
power	O
of	O
residual	O
blocks	O
:	O
to	O
add	O
more	O
convolutional	B-Method
layers	I-Method
per	O
block	O
to	O
widen	O
the	O
convolutional	B-Method
layers	I-Method
by	O
adding	O
more	O
feature	O
planes	O
to	O
increase	O
filter	O
sizes	O
in	O
convolutional	O
layers	O
As	O
small	O
filters	O
were	O
shown	O
to	O
be	O
very	O
effective	O
in	O
several	O
works	O
including	O
we	O
do	O
not	O
consider	O
using	O
filters	O
larger	O
than	O
.	O
	
Let	O
us	O
also	O
introduce	O
two	O
factors	O
,	O
deepening	O
factor	O
and	O
widening	O
factor	O
,	O
where	O
is	O
the	O
number	O
of	O
convolutions	O
in	O
a	O
block	O
and	O
multiplies	O
the	O
number	O
of	O
features	O
in	O
convolutional	O
layers	O
,	O
	
thus	O
the	O
baseline	O
¡	O
¡	O
basic	O
¿	O
¿	O
block	O
corresponds	O
to	O
,	O
.	O
	
Figures	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
show	O
schematic	O
examples	O
of	O
	
¡	O
¡	O
basic	O
¿	O
¿	O
and	O
	
¡	O
¡	O
basic	O
-	O
wide	O
¿	O
¿	O
blocks	O
respectively	O
.	O
	
The	O
general	O
structure	O
of	O
our	O
residual	B-Method
networks	I-Method
is	O
illustrated	O
in	O
table	O
[	O
reference	O
]	O
:	O
it	O
consists	O
of	O
an	O
initial	O
convolutional	B-Method
layer	I-Method
conv1	I-Method
that	O
is	O
followed	O
by	O
3	O
groups	O
(	O
each	O
of	O
size	O
)	O
of	O
residual	O
blocks	O
conv2	B-Method
,	O
conv3	B-Method
and	O
conv4	B-Method
,	O
followed	O
by	O
average	B-Method
pooling	I-Method
and	O
final	O
classification	B-Method
layer	I-Method
.	O
	
The	O
size	O
of	O
conv1	O
is	O
fixed	O
in	O
all	O
of	O
our	O
experiments	O
,	O
while	O
the	O
introduced	O
widening	O
factor	O
scales	O
the	O
width	O
of	O
the	O
residual	O
blocks	O
in	O
the	O
three	O
groups	O
conv2	O
	
-	O
4	O
(	O
e.g	O
,	O
the	O
original	O
¡	B-Method
¡	I-Method
basic	I-Method
¿	I-Method
¿	I-Method
architecture	I-Method
is	O
equivalent	O
to	O
)	O
.	O
	
We	O
want	O
to	O
study	O
the	O
effect	O
of	O
representational	O
power	O
of	O
residual	O
block	O
and	O
,	O
to	O
that	O
end	O
,	O
we	O
perform	O
and	O
test	O
several	O
modifications	O
to	O
	
the	O
¡	O
¡	O
basic	O
¿	O
¿	O
architecture	O
,	O
which	O
are	O
detailed	O
in	O
the	O
following	O
subsections	O
.	O
	
subsection	O
:	O
Type	O
of	O
convolutions	O
in	O
residual	O
block	O
	
Let	O
denote	O
residual	O
block	O
structure	O
,	O
where	O
is	O
a	O
list	O
with	O
the	O
kernel	O
sizes	O
of	O
the	O
convolutional	B-Method
layers	I-Method
in	O
a	O
block	O
.	O
	
For	O
example	O
,	O
denotes	O
a	O
residual	O
block	O
with	O
and	O
convolutional	O
layers	O
(	O
we	O
always	O
assume	O
square	O
spatial	O
kernels	O
)	O
.	O
	
Note	O
that	O
,	O
as	O
we	O
do	O
not	O
consider	O
	
¡	O
¡	O
bottleneck	O
¿	O
¿	O
blocks	O
as	O
explained	O
earlier	O
,	O
the	O
number	O
of	O
feature	O
planes	O
is	O
always	O
kept	O
the	O
same	O
across	O
the	O
block	O
.	O
	
We	O
would	O
like	O
to	O
answer	O
the	O
question	O
of	O
how	O
important	O
each	O
of	O
the	O
convolutional	B-Method
layers	I-Method
of	O
	
the	O
¡	O
¡	O
basic	O
¿	O
¿	O
residual	B-Method
architecture	I-Method
is	O
and	O
if	O
they	O
can	O
be	O
substituted	O
by	O
a	O
less	O
computationally	O
expensive	O
layer	O
or	O
even	O
a	O
combination	B-Method
of	I-Method
and	I-Method
convolutional	I-Method
layers	I-Method
,	O
e.g	O
,	O
or	O
.	O
	
This	O
can	O
increase	O
or	O
decrease	O
the	O
representational	O
power	O
of	O
the	O
block	O
.	O
	
We	O
thus	O
experiment	O
with	O
the	O
following	O
combinations	O
(	O
note	O
that	O
the	O
last	O
combination	O
,	O
i.e.	O
,	O
is	O
similar	O
to	O
effective	O
Network	B-Method
-	I-Method
in	I-Method
-	I-Method
Network	I-Method
architecture	I-Method
)	O
:	O
	
-	O
original	O
¡	O
¡	O
basic	O
¿	O
¿	O
block	O
-	O
with	O
one	O
extra	O
layer	O
-	O
with	O
the	O
same	O
dimensionality	O
of	O
all	O
convolutions	O
,	O
¡	O
¡	O
straightened	O
¿	O
¿	O
bottleneck	O
-	O
the	O
network	O
has	O
alternating	O
-	O
convolutions	O
everywhere	O
-	O
similar	O
idea	O
to	O
the	O
previous	O
block	B-Method
-	I-Method
Network	I-Method
-	I-Method
in	I-Method
-	I-Method
Network	I-Method
style	I-Method
block	I-Method
	
subsection	O
:	O
Number	O
of	O
convolutional	O
layers	O
per	O
residual	O
block	O
	
We	O
also	O
experiment	O
with	O
the	O
block	O
deepening	O
factor	O
to	O
see	O
how	O
it	O
affects	O
performance	O
.	O
	
The	O
comparison	O
has	O
to	O
be	O
done	O
among	O
networks	O
with	O
the	O
same	O
number	O
of	O
parameters	O
,	O
so	O
in	O
this	O
case	O
we	O
need	O
to	O
build	O
networks	O
with	O
different	O
and	O
(	O
where	O
denotes	O
the	O
total	O
number	O
of	O
blocks	O
)	O
while	O
ensuring	O
that	O
network	B-Metric
complexity	I-Metric
is	O
kept	O
roughly	O
constant	O
.	O
	
This	O
means	O
,	O
for	O
instance	O
,	O
that	O
should	O
decrease	O
whenever	O
increases	O
.	O
	
subsection	O
:	O
Width	O
of	O
residual	O
blocks	O
	
In	O
addition	O
to	O
the	O
above	O
modifications	O
,	O
we	O
experiment	O
with	O
the	O
widening	O
factor	O
of	O
a	O
block	O
.	O
	
While	O
the	O
number	O
of	O
parameters	O
increases	O
linearly	O
with	O
(	O
the	O
deepening	O
factor	O
)	O
and	O
(	O
the	O
number	O
of	O
ResNet	B-Method
blocks	I-Method
)	O
,	O
number	O
of	O
parameters	O
and	O
computational	B-Metric
complexity	I-Metric
are	O
quadratic	O
in	O
.	O
	
However	O
,	O
it	O
is	O
more	O
computationally	O
effective	O
to	O
widen	O
the	O
layers	O
than	O
have	O
thousands	O
of	O
small	O
kernels	O
as	O
GPU	B-Method
is	O
much	O
more	O
efficient	O
in	O
parallel	B-Task
computations	I-Task
on	O
large	B-Task
tensors	I-Task
,	O
so	O
we	O
are	O
interested	O
in	O
an	O
optimal	O
to	B-Metric
ratio	I-Metric
.	O
	
One	O
argument	O
for	O
wider	O
residual	B-Method
networks	I-Method
would	O
be	O
that	O
almost	O
all	O
architectures	O
before	O
residual	B-Method
networks	I-Method
,	O
including	O
the	O
most	O
successful	O
Inception	B-Method
and	O
VGG	B-Method
,	O
were	O
much	O
wider	O
compared	O
to	O
.	O
	
For	O
example	O
,	O
residual	B-Method
networks	I-Method
WRN	I-Method
-	I-Method
22	I-Method
-	I-Method
8	I-Method
and	O
WRN	B-Method
-	I-Method
16	I-Method
-	I-Method
10	I-Method
(	O
see	O
next	O
paragraph	O
for	O
explanation	O
of	O
this	O
notation	O
)	O
are	O
very	O
similar	O
in	O
width	O
,	O
depth	O
and	O
number	O
of	O
parameters	O
to	O
VGG	B-Method
architectures	I-Method
.	O
	
We	O
further	O
refer	O
to	O
original	O
residual	B-Method
networks	I-Method
with	O
as	O
	
¡	O
¡	O
thin	O
¿	O
¿	O
and	O
to	O
networks	O
with	O
	
as	O
¡	O
¡	O
wide¿¿.	O
	
In	O
the	O
rest	O
of	O
the	O
paper	O
we	O
use	O
the	O
following	O
notation	O
:	O
WRN	B-Method
-	I-Method
-	O
denotes	O
a	O
residual	B-Method
network	I-Method
that	O
has	O
a	O
total	O
number	O
of	O
convolutional	O
layers	O
and	O
a	O
widening	O
factor	O
(	O
for	O
example	O
,	O
network	O
with	O
40	O
layers	O
and	O
times	O
wider	O
than	O
original	O
would	O
be	O
denoted	O
as	O
WRN	B-Method
-	I-Method
40	I-Method
-	I-Method
2	I-Method
)	O
.	O
	
Also	O
,	O
when	O
applicable	O
we	O
append	O
block	O
type	O
,	O
	
e.g	O
	
WRN	B-Method
-	I-Method
40	I-Method
-	I-Method
2	I-Method
-	I-Method
.	O
	
subsection	O
:	O
Dropout	B-Task
in	I-Task
residual	I-Task
blocks	I-Task
	
As	O
widening	O
increases	O
the	O
number	O
of	O
parameters	O
we	O
would	O
like	O
to	O
study	O
ways	O
of	O
regularization	B-Task
.	O
	
Residual	B-Method
networks	I-Method
already	O
have	O
batch	B-Method
normalization	I-Method
that	O
provides	O
a	O
regularization	O
effect	O
,	O
however	O
it	O
requires	O
heavy	O
data	B-Task
augmentation	I-Task
,	O
which	O
we	O
would	O
like	O
to	O
avoid	O
,	O
and	O
it	O
’s	O
not	O
always	O
possible	O
.	O
	
We	O
add	O
a	O
dropout	B-Method
layer	I-Method
into	O
each	O
residual	O
block	O
between	O
convolutions	O
as	O
shown	O
in	O
fig	O
.	O
	
[	O
reference	O
]	O
and	O
after	O
ReLU	B-Method
to	O
perturb	O
batch	B-Task
normalization	I-Task
in	O
the	O
next	O
residual	O
block	O
and	O
prevent	O
it	O
from	O
overfitting	O
.	O
	
In	O
very	O
deep	B-Method
residual	I-Method
networks	I-Method
that	O
should	O
help	O
deal	O
with	O
diminishing	B-Task
feature	I-Task
reuse	I-Task
problem	I-Task
enforcing	I-Task
learning	I-Task
in	O
different	O
residual	O
blocks	O
.	O
	
section	O
:	O
Experimental	O
results	O
	
For	O
experiments	O
we	O
chose	O
well	O
-	O
known	O
CIFAR	B-Material
-	I-Material
10	I-Material
,	O
CIFAR	B-Material
-	I-Material
100	I-Material
,	O
SVHN	B-Material
and	O
ImageNet	O
image	O
classification	O
datasets	O
.	O
	
CIFAR	B-Material
-	I-Material
10	I-Material
and	O
	
CIFAR	B-Material
-	O
100	O
datasets	O
consist	O
of	O
color	O
images	O
drawn	O
from	O
10	O
and	O
100	O
classes	O
split	O
into	O
50	O
,	O
000	O
train	O
and	O
10	O
,	O
000	O
test	O
images	O
.	O
	
For	O
data	B-Task
augmentation	I-Task
we	O
do	O
horizontal	O
flips	O
and	O
take	O
random	O
crops	O
from	O
image	O
padded	O
by	O
4	O
pixels	O
on	O
each	O
side	O
,	O
filling	O
missing	O
pixels	O
with	O
reflections	O
of	O
original	O
image	O
.	O
	
We	O
do	O
n’t	O
use	O
heavy	O
data	B-Task
augmentation	I-Task
as	O
proposed	O
in	O
.	O
	
SVHN	B-Material
is	O
a	O
dataset	O
of	O
Google	B-Material
’s	I-Material
Street	I-Material
View	I-Material
House	I-Material
Numbers	I-Material
images	I-Material
and	O
contains	O
about	O
600	O
,	O
000	O
digit	O
images	O
,	O
coming	O
from	O
a	O
significantly	O
harder	O
real	O
world	O
problem	O
.	O
	
For	O
experiments	O
on	O
SVHN	B-Material
	
we	O
do	O
n’t	O
	
do	O
any	O
image	B-Task
preprocessing	I-Task
,	O
except	O
dividing	O
images	O
by	O
255	O
to	O
provide	O
them	O
in	O
[	O
0	O
,	O
1	O
]	O
range	O
as	O
input	O
.	O
	
All	O
of	O
our	O
experiments	O
except	O
ImageNet	O
are	O
based	O
on	O
architecture	B-Method
with	O
pre	O
-	O
activation	O
residual	O
blocks	O
and	O
we	O
use	O
it	O
as	O
baseline	O
.	O
	
For	O
ImageNet	O
,	O
we	O
find	O
that	O
using	O
pre	B-Method
-	I-Method
activation	I-Method
in	O
networks	O
with	O
less	O
than	O
100	O
layers	O
does	O
not	O
make	O
any	O
significant	O
difference	O
	
and	O
so	O
we	O
decide	O
to	O
use	O
the	O
original	O
ResNet	B-Method
architecture	I-Method
in	O
this	O
case	O
.	O
	
Unless	O
mentioned	O
otherwise	O
,	O
for	O
CIFAR	B-Material
we	O
follow	O
the	O
image	B-Method
preprocessing	I-Method
of	O
with	O
ZCA	B-Method
whitening	I-Method
.	O
	
However	O
,	O
for	O
some	O
CIFAR	B-Material
experiments	O
we	O
instead	O
use	O
simple	O
mean	B-Method
/	I-Method
std	I-Method
normalization	I-Method
such	O
that	O
we	O
can	O
directly	O
compare	O
with	O
and	O
other	O
ResNet	O
related	O
works	O
that	O
make	O
use	O
of	O
this	O
type	O
of	O
preprocessing	O
.	O
	
In	O
the	O
following	O
we	O
describe	O
our	O
findings	O
w.r.t	O
.	O
	
the	O
different	O
ResNet	B-Method
block	I-Method
architectures	I-Method
and	O
also	O
analyze	O
the	O
performance	O
of	O
our	O
proposed	O
wide	B-Method
residual	I-Method
networks	I-Method
.	O
	
We	O
note	O
that	O
for	O
all	O
experiments	O
related	O
to	O
¡	O
¡	O
type	O
of	O
convolutions	O
in	O
a	O
block	O
¿	O
¿	O
and	O
¡	O
¡	O
number	O
of	O
convolutions	O
per	O
block	O
	
¿	O
¿	O
we	O
use	O
and	O
reduced	O
depth	O
compared	O
to	O
in	O
order	O
to	O
speed	O
up	O
training	B-Task
.	O
	
subsubsection	O
:	O
Type	O
of	O
convolutions	B-Method
in	O
a	O
block	O
	
We	O
start	O
by	O
reporting	O
results	O
using	O
trained	B-Method
networks	I-Method
with	O
different	O
block	O
types	O
(	O
reported	O
results	O
are	O
on	O
CIFAR	B-Material
-	I-Material
10	I-Material
)	O
.	O
	
We	O
used	O
WRN	B-Method
-	I-Method
40	I-Method
-	I-Method
2	I-Method
for	O
blocks	O
,	O
,	O
and	O
as	O
these	O
blocks	O
have	O
only	O
one	O
convolution	O
.	O
	
To	O
keep	O
the	O
number	O
of	O
parameters	O
comparable	O
we	O
trained	O
other	O
networks	O
with	O
less	O
layers	O
:	O
WRN	B-Method
-	I-Method
28	I-Method
-	I-Method
2	I-Method
-	I-Method
and	O
	
WRN	B-Method
-	I-Method
22	I-Method
-	I-Method
2	I-Method
-	I-Method
.	O
	
We	O
provide	O
the	O
results	O
including	O
test	B-Metric
accuracy	I-Metric
in	O
median	O
over	O
5	O
runs	O
and	O
time	O
per	O
training	O
epoch	O
in	O
the	O
table	O
[	O
reference	O
]	O
.	O
	
Block	B-Method
turned	O
out	O
to	O
be	O
the	O
best	O
by	O
a	O
little	O
margin	O
,	O
and	O
with	O
are	O
very	O
close	O
to	O
in	O
accuracy	B-Metric
having	O
less	O
parameters	O
and	O
less	O
layers	O
.	O
is	O
faster	O
than	O
others	O
by	O
a	O
small	O
margin	O
.	O
	
Based	O
on	O
the	O
above	O
,	O
blocks	O
with	O
comparable	O
number	O
of	O
parameters	O
turned	O
out	O
to	O
give	O
more	O
or	O
less	O
the	O
same	O
results	O
.	O
	
Due	O
to	O
this	O
fact	O
,	O
we	O
hereafter	O
restrict	O
our	O
attention	O
to	O
only	O
WRNs	B-Method
with	O
convolutions	B-Method
so	O
as	O
to	O
be	O
also	O
consistent	O
with	O
other	O
methods	O
.	O
	
subsubsection	O
:	O
Number	O
of	O
convolutions	B-Method
per	O
block	O
	
We	O
next	O
proceed	O
with	O
the	O
experiments	O
related	O
to	O
varying	O
the	O
deepening	O
factor	O
(	O
which	O
represents	O
the	O
number	O
of	O
convolutional	O
layers	O
per	O
block	O
)	O
.	O
	
We	O
show	O
indicative	O
results	O
in	O
table	O
[	O
reference	O
]	O
,	O
where	O
in	O
this	O
case	O
we	O
took	O
WRN	B-Method
-	I-Method
40	I-Method
-	O
2	O
with	O
convolutions	B-Method
and	O
trained	O
several	O
networks	O
with	O
different	O
deepening	O
factor	O
,	O
same	O
number	O
of	O
parameters	O
(	O
2.2	O
)	O
and	O
same	O
number	O
of	O
convolutional	B-Method
layers	I-Method
.	O
	
As	O
can	O
be	O
noticed	O
,	O
turned	O
out	O
to	O
be	O
the	O
best	O
,	O
whereas	O
and	O
had	O
the	O
worst	O
performance	O
.	O
	
We	O
speculate	O
that	O
this	O
is	O
probably	O
due	O
to	O
the	O
increased	O
difficulty	O
in	O
optimization	B-Task
as	O
a	O
result	O
of	O
the	O
decreased	O
number	O
of	O
residual	O
connections	O
in	O
the	O
last	O
two	O
cases	O
.	O
	
Furthermore	O
,	O
turned	O
out	O
to	O
be	O
quite	O
worse	O
.	O
	
The	O
conclusion	O
is	O
that	O
is	O
optimal	O
in	O
terms	O
of	O
number	O
of	O
convolutions	O
per	O
block	O
.	O
	
For	O
this	O
reason	O
,	O
in	O
the	O
remaining	O
experiments	O
we	O
only	O
consider	O
wide	B-Method
residual	I-Method
networks	I-Method
with	O
a	O
block	O
of	O
type	O
.	O
	
subsubsection	O
:	O
Width	O
of	O
residual	O
blocks	O
	
As	O
we	O
try	O
to	O
increase	O
widening	O
parameter	O
we	O
have	O
to	O
decrease	O
total	O
number	O
of	O
layers	O
.	O
	
To	O
find	O
an	O
optimal	O
ratio	O
we	O
experimented	O
with	O
from	O
2	O
to	O
12	O
and	O
depth	O
from	O
16	O
to	O
40	O
.	O
	
The	O
results	O
are	O
presented	O
in	O
table	O
[	O
reference	O
]	O
.	O
	
As	O
can	O
be	O
seen	O
,	O
all	O
networks	O
with	O
40	O
,	O
22	O
and	O
16	O
layers	O
see	O
consistent	O
gains	O
when	O
width	O
is	O
increased	O
by	O
1	O
to	O
12	O
times	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
when	O
keeping	O
the	O
same	O
fixed	O
widening	O
factor	O
or	O
and	O
varying	O
depth	O
from	O
16	O
to	O
28	O
there	O
is	O
a	O
consistent	O
improvement	O
,	O
however	O
when	O
we	O
further	O
increase	O
depth	O
to	O
40	O
accuracy	B-Metric
decreases	O
(	O
	
e.g	O
,	O
WRN	B-Method
-	I-Method
40	I-Method
-	I-Method
8	I-Method
loses	O
in	O
accuracy	B-Metric
to	O
WRN	B-Method
-	I-Method
22	I-Method
-	I-Method
8	I-Method
)	O
.	O
	
We	O
show	O
additional	O
results	O
in	O
table	O
[	O
reference	O
]	O
where	O
we	O
compare	O
thin	O
and	O
wide	B-Method
residual	I-Method
networks	I-Method
.	O
	
As	O
can	O
be	O
observed	O
,	O
wide	O
	
WRN	B-Method
-	I-Method
40	I-Method
	
-	O
4	O
compares	O
favorably	O
to	O
thin	O
ResNet	B-Method
-	I-Method
1001	I-Method
as	O
it	O
achieves	O
better	O
accuracy	B-Metric
on	O
both	O
CIFAR	B-Material
-	I-Material
10	I-Material
and	O
CIFAR	B-Material
-	I-Material
100	I-Material
.	O
	
Yet	O
,	O
it	O
is	O
interesting	O
that	O
these	O
networks	O
have	O
comparable	O
number	O
of	O
parameters	O
,	O
8.9	O
and	O
10.2	O
,	O
suggesting	O
that	O
depth	O
does	O
not	O
add	O
regularization	O
effects	O
compared	O
to	O
width	O
at	O
this	O
level	O
.	O
	
As	O
we	O
show	O
further	O
in	O
benchmarks	O
,	O
WRN	B-Method
-	I-Method
40	I-Method
-	I-Method
4	I-Method
is	O
8	O
times	O
faster	O
to	O
train	O
,	O
so	O
evidently	O
depth	O
to	O
width	O
ratio	O
in	O
the	O
original	O
thin	B-Method
residual	I-Method
networks	I-Method
is	O
far	O
from	O
optimal	O
.	O
	
Also	O
,	O
wide	B-Method
WRN	I-Method
-	I-Method
28	I-Method
-	I-Method
10	I-Method
outperforms	O
thin	O
ResNet	B-Method
-	I-Method
1001	I-Method
by	O
0.92	O
%	O
(	O
with	O
the	O
same	O
minibatch	O
size	O
during	O
training	O
)	O
on	O
CIFAR	B-Material
-	I-Material
10	I-Material
and	O
3.46	O
%	O
on	O
CIFAR	B-Material
-	I-Material
100	I-Material
,	O
having	O
36	O
times	O
less	O
layers	O
(	O
see	O
table	O
[	O
reference	O
]	O
)	O
.	O
	
We	O
note	O
that	O
the	O
result	O
of	O
4.64	O
%	O
with	O
ResNet	B-Method
-	I-Method
1001	I-Method
was	O
obtained	O
with	O
batch	O
size	O
64	O
,	O
whereas	O
we	O
use	O
a	O
batch	O
size	O
128	O
in	O
all	O
of	O
our	O
experiments	O
(	O
i.e.	O
,	O
all	O
other	O
results	O
reported	O
in	O
table	O
[	O
reference	O
]	O
are	O
with	O
batch	O
size	O
128	O
)	O
.	O
	
Training	O
curves	O
for	O
these	O
networks	O
are	O
presented	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Despite	O
previous	O
arguments	O
that	O
depth	O
gives	O
regularization	O
effects	O
and	O
width	O
causes	O
network	O
to	O
overfit	O
,	O
we	O
successfully	O
train	O
networks	O
with	O
several	O
times	O
more	O
parameters	O
than	O
ResNet	B-Method
-	I-Method
1001	I-Method
.	O
	
For	O
instance	O
,	O
wide	O
WRN	B-Method
-	I-Method
28	I-Method
-	I-Method
10	I-Method
(	O
table	O
[	O
reference	O
]	O
)	O
and	O
wide	B-Method
WRN	I-Method
-	I-Method
40	I-Method
	
-	O
10	O
(	O
table	O
[	O
reference	O
]	O
)	O
have	O
respectively	O
and	O
times	O
more	O
parameters	O
than	O
ResNet	B-Method
-	I-Method
1001	I-Method
and	O
both	O
outperform	O
it	O
by	O
a	O
significant	O
margin	O
.	O
	
In	O
general	O
,	O
we	O
observed	O
that	O
CIFAR	B-Material
mean	O
/	O
std	O
preprocessing	O
allows	O
training	O
wider	O
and	O
deeper	B-Method
networks	I-Method
with	O
better	O
accuracy	B-Metric
,	O
and	O
achieved	O
18.3	O
%	O
on	O
CIFAR	B-Material
-	I-Material
100	I-Material
using	O
WRN	B-Method
-	I-Method
40	I-Method
-	O
10	O
with	O
parameters	O
(	O
table	O
[	O
reference	O
]	O
)	O
,	O
giving	O
a	O
total	O
improvement	O
of	O
4.4	O
%	O
over	O
ResNet	B-Method
-	I-Method
1001	I-Method
and	O
establishing	O
a	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
result	O
on	O
this	O
dataset	O
.	O
	
To	O
summarize	O
:	O
widening	O
consistently	O
improves	O
performance	O
across	O
residual	B-Method
networks	I-Method
of	O
different	O
depth	O
;	O
increasing	O
both	O
depth	O
and	O
width	O
helps	O
until	O
the	O
number	O
of	O
parameters	O
becomes	O
too	O
high	O
and	O
stronger	O
regularization	O
is	O
needed	O
;	O
there	O
does	O
n’t	O
seem	O
to	O
be	O
a	O
regularization	O
effect	O
from	O
very	O
high	O
depth	O
in	O
residual	B-Method
networks	I-Method
as	O
wide	B-Method
networks	I-Method
with	O
the	O
same	O
number	O
of	O
parameters	O
as	O
thin	O
ones	O
can	O
learn	O
same	O
or	O
better	O
representations	O
.	O
	
Furthermore	O
,	O
wide	B-Method
networks	I-Method
can	O
successfully	O
learn	O
with	O
a	O
2	O
or	O
more	O
times	O
larger	O
number	O
of	O
parameters	O
than	O
thin	O
ones	O
,	O
which	O
would	O
require	O
doubling	O
the	O
depth	O
of	O
thin	B-Method
networks	I-Method
,	O
making	O
them	O
infeasibly	O
expensive	O
to	O
train	O
.	O
	
[	O
scale=0.42	O
]	O
.	O
/	O
images	O
/	O
cifar10.pdf	O
[	O
scale=0.42	O
]	O
.	O
/	O
images	O
/	O
cifar100.pdf	O
	
subsubsection	O
:	O
Dropout	B-Method
in	O
residual	O
blocks	O
	
We	O
trained	O
networks	O
with	O
dropout	O
inserted	O
into	O
residual	O
block	O
between	O
convolutions	B-Method
on	O
all	O
datasets	O
.	O
	
We	O
used	O
cross	B-Method
-	I-Method
validation	I-Method
to	O
determine	O
dropout	B-Metric
probability	I-Metric
values	I-Metric
,	O
0.3	O
on	O
CIFAR	B-Material
and	O
0.4	O
on	O
SVHN	B-Material
.	O
	
Also	O
,	O
we	O
did	O
n’t	O
have	O
to	O
increase	O
number	O
of	O
training	O
epochs	O
compared	O
to	O
baseline	B-Method
networks	I-Method
without	O
dropout	B-Method
.	O
	
Dropout	B-Method
decreases	O
test	O
error	B-Metric
on	O
CIFAR	B-Material
-	I-Material
10	I-Material
and	O
CIFAR	B-Material
-	I-Material
100	I-Material
by	O
0.11	O
%	O
and	O
0.4	O
%	O
correnspondingly	O
(	O
over	O
median	O
of	O
5	O
runs	O
and	O
mean	B-Method
/	I-Method
std	I-Method
preprocessing	I-Method
)	O
with	O
WRN	B-Method
-	I-Method
28	I-Method
-	O
10	O
,	O
and	O
gives	O
improvements	O
with	O
other	O
ResNets	B-Method
as	O
well	O
(	O
table	O
[	O
reference	O
]	O
)	O
.	O
	
To	O
our	O
knowledge	O
,	O
that	O
was	O
the	O
first	O
result	O
to	O
approach	O
20	O
%	O
error	B-Metric
on	O
CIFAR	B-Material
-	I-Material
100	I-Material
,	O
even	O
outperforming	O
methods	O
with	O
heavy	O
data	B-Method
augmentation	I-Method
.	O
	
There	O
is	O
only	O
a	O
slight	O
drop	O
in	O
accuracy	B-Metric
with	O
WRN	B-Method
-	I-Method
16	I-Method
-	I-Method
4	I-Method
on	O
CIFAR	B-Material
-	I-Material
10	I-Material
which	O
we	O
speculate	O
is	O
due	O
to	O
the	O
relatively	O
small	O
number	O
of	O
parameters	O
.	O
	
We	O
notice	O
a	O
disturbing	O
effect	O
in	O
residual	B-Method
network	I-Method
training	I-Method
after	O
the	O
first	O
learning	B-Metric
rate	I-Metric
drop	I-Metric
when	O
both	O
loss	B-Metric
and	O
validation	B-Metric
error	I-Metric
suddenly	O
start	O
to	O
go	O
up	O
and	O
oscillate	O
on	O
high	O
values	O
until	O
the	O
next	O
learning	B-Metric
rate	I-Metric
drop	I-Metric
.	O
	
We	O
found	O
out	O
that	O
it	O
is	O
caused	O
by	O
weight	B-Method
decay	I-Method
,	O
however	O
making	O
it	O
lower	O
leads	O
to	O
a	O
significant	O
drop	O
in	O
accuracy	B-Metric
.	O
	
Interestingly	O
,	O
dropout	B-Method
partially	O
removes	O
this	O
effect	O
in	O
most	O
cases	O
,	O
see	O
figures	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
.	O
	
The	O
effect	O
of	O
dropout	O
becomes	O
more	O
evident	O
on	O
SVHN	B-Material
.	O
	
This	O
is	O
probably	O
due	O
to	O
the	O
fact	O
that	O
we	O
do	O
	
n’t	B-Method
do	O
any	O
data	B-Method
augmentation	I-Method
and	O
batch	B-Method
normalization	I-Method
overfits	O
,	O
so	O
dropout	B-Method
adds	O
a	O
regularization	O
effect	O
.	O
	
Evidence	O
for	O
this	O
can	O
be	O
found	O
on	O
training	O
curves	O
in	O
figure	O
[	O
reference	O
]	O
where	O
the	O
loss	B-Metric
without	O
dropout	B-Method
drops	O
to	O
very	O
low	O
values	O
.	O
	
The	O
results	O
are	O
presented	O
in	O
table	O
[	O
reference	O
]	O
.	O
	
We	O
observe	O
significant	O
improvements	O
from	O
using	O
dropout	B-Method
on	O
both	O
thin	O
and	O
wide	B-Method
networks	I-Method
.	O
	
Thin	B-Method
50	I-Method
-	I-Method
layer	I-Method
deep	I-Method
network	I-Method
even	O
outperforms	O
thin	B-Method
152	I-Method
-	I-Method
layer	I-Method
deep	I-Method
network	I-Method
with	O
stochastic	O
depth	O
.	O
	
We	O
additionally	O
trained	O
WRN	B-Method
-	I-Method
16	I-Method
-	I-Method
8	I-Method
with	O
dropout	B-Method
on	O
SVHN	B-Material
(	O
table	O
[	O
reference	O
]	O
)	O
,	O
which	O
achieves	O
1.54	O
%	O
on	O
SVHN	B-Material
-	O
the	O
best	O
published	O
result	O
to	O
our	O
knowledge	O
.	O
	
Without	O
dropout	B-Method
it	O
achieves	O
1.81	O
%	O
.	O
	
Overall	O
,	O
despite	O
the	O
arguments	O
of	O
combining	O
with	O
batch	B-Method
normalization	I-Method
,	O
dropout	B-Method
shows	O
itself	O
as	O
an	O
effective	O
techique	O
of	O
regularization	O
of	O
thin	O
and	O
wide	B-Method
networks	I-Method
.	O
	
It	O
can	O
be	O
used	O
to	O
further	O
improve	O
results	O
from	O
widening	B-Task
,	O
while	O
also	O
being	O
complementary	O
to	O
it	O
.	O
	
[	O
scale=0.42	O
]	O
.	O
/	O
images	O
/	O
svhn.pdf	O
	
[	O
scale=0.42	O
]	O
.	O
/	O
images	O
/	O
svhn	O
-	O
dropout.pdf	O
	
subsubsection	O
:	O
ImageNet	O
and	O
COCO	O
experiments	O
	
For	O
ImageNet	O
we	O
first	O
experiment	O
with	O
non	O
-	O
bottleneck	O
ResNet	O
-	O
18	O
and	O
ResNet	B-Method
-	I-Method
34	I-Method
,	O
trying	O
to	O
gradually	O
increase	O
their	O
width	O
from	O
1.0	O
to	O
3.0	O
.	O
	
The	O
results	O
are	O
shown	O
in	O
table	O
[	O
reference	O
]	O
.	O
	
Increasing	O
width	O
gradually	O
increases	O
accuracy	B-Metric
of	O
both	O
networks	O
,	O
and	O
networks	O
with	O
a	O
comparable	O
number	O
of	O
parameters	O
achieve	O
similar	O
results	O
,	O
despite	O
having	O
different	O
depth	O
.	O
	
Althouth	O
these	O
networks	O
have	O
a	O
large	O
number	O
of	O
parameters	O
,	O
they	O
are	O
outperfomed	O
by	O
bottleneck	B-Method
networks	I-Method
,	O
which	O
is	O
probably	O
either	O
due	O
to	O
that	O
bottleneck	B-Method
architecture	I-Method
is	O
simply	O
better	O
suited	O
for	O
ImageNet	B-Task
classification	I-Task
task	I-Task
,	O
or	O
due	O
to	O
that	O
this	O
more	O
complex	O
task	O
needs	O
a	O
deeper	B-Method
network	I-Method
.	O
	
To	O
test	O
this	O
,	O
we	O
took	O
the	O
ResNet	O
-	O
50	O
,	O
and	O
tried	O
to	O
make	O
it	O
wider	O
by	O
increasing	O
inner	O
layer	O
width	O
.	O
	
With	O
widening	O
factor	O
of	O
2.0	O
the	O
resulting	O
WRN	B-Method
-	I-Method
50	I-Method
-	I-Method
2	I-Method
-	I-Method
bottleneck	I-Method
outperforms	O
ResNet	B-Method
-	I-Method
152	I-Method
having	O
3	O
times	O
less	O
layers	O
,	O
and	O
being	O
significantly	O
faster	O
.	O
	
WRN	B-Method
-	I-Method
50	I-Method
	
-	B-Method
2	I-Method
-	I-Method
bottleneck	I-Method
is	O
only	O
slightly	O
worse	O
and	O
almost	O
faster	O
than	O
the	O
best	O
-	O
performing	O
pre	B-Method
-	I-Method
activation	I-Method
ResNet	I-Method
-	I-Method
200	I-Method
,	O
althouth	O
having	O
slightly	O
more	O
parameters	O
(	O
table	O
[	O
reference	O
]	O
)	O
.	O
	
In	O
general	O
,	O
we	O
find	O
that	O
,	O
unlike	O
CIFAR	B-Material
,	O
ImageNet	B-Method
networks	I-Method
need	O
more	O
width	O
at	O
the	O
same	O
depth	O
to	O
achieve	O
the	O
same	O
accuracy	B-Metric
.	O
	
It	O
is	O
however	O
clear	O
that	O
it	O
is	O
unnecessary	O
to	O
have	O
residual	B-Method
networks	I-Method
with	O
more	O
than	O
50	O
layers	O
due	O
to	O
computational	O
reasons	O
.	O
	
We	O
did	O
n’t	O
try	O
to	O
train	O
bigger	O
bottleneck	B-Method
networks	I-Method
as	O
8	B-Method
-	I-Method
GPU	I-Method
machines	I-Method
are	O
needed	O
for	O
that	O
.	O
	
We	O
also	O
used	O
WRN	B-Method
-	I-Method
34	I-Method
-	I-Method
2	I-Method
to	O
participate	O
in	O
COCO	B-Task
2016	I-Task
object	I-Task
detection	I-Task
challenge	I-Task
,	O
using	O
a	O
combination	O
of	O
MultiPathNet	B-Method
and	O
LocNet	B-Method
.	O
	
Despite	O
having	O
only	O
34	O
layers	O
,	O
this	O
model	O
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
single	O
model	O
performance	O
,	O
outperforming	O
even	O
ResNet	B-Method
-	I-Method
152	I-Method
and	O
Inception	B-Method
-	I-Method
v4	I-Method
-	O
based	O
models	O
.	O
	
Finally	O
,	O
in	O
table	O
[	O
reference	O
]	O
we	O
summarize	O
our	O
best	O
WRN	O
results	O
over	O
various	O
commonly	O
used	O
datasets	O
.	O
	
subsubsection	O
:	O
Computational	B-Metric
efficiency	I-Metric
	
Thin	B-Method
and	I-Method
deep	I-Method
residual	I-Method
networks	I-Method
with	O
small	B-Method
kernels	I-Method
are	O
against	O
the	O
nature	O
of	O
GPU	B-Method
computations	I-Method
because	O
of	O
their	O
sequential	O
structure	O
.	O
	
Increasing	O
width	O
helps	O
effectively	O
balance	O
computations	O
in	O
much	O
more	O
optimal	O
way	O
,	O
so	O
that	O
wide	B-Method
networks	I-Method
are	O
many	O
times	O
more	O
efficient	O
than	O
thin	O
ones	O
as	O
our	O
benchmarks	O
show	O
.	O
	
We	O
use	O
cudnn	B-Method
v5	I-Method
and	O
Titan	B-Method
X	I-Method
to	O
measure	O
forward	B-Metric
+	I-Metric
backward	I-Metric
update	I-Metric
times	I-Metric
with	O
minibatch	O
size	O
32	O
for	O
several	O
networks	O
,	O
the	O
results	O
are	O
in	O
the	O
figure	O
[	O
reference	O
]	O
.	O
	
We	O
show	O
that	O
our	O
best	O
CIFAR	B-Material
wide	O
WRN	B-Method
-	I-Method
28	I-Method
	
-	O
10	O
is	O
1.6	O
times	O
faster	O
than	O
thin	B-Method
ResNet	I-Method
-	I-Method
1001	I-Method
.	O
	
Furthermore	O
,	O
wide	B-Method
WRN	I-Method
-	I-Method
40	I-Method
-	I-Method
4	I-Method
,	O
which	O
has	O
approximately	O
the	O
same	O
accuracy	B-Metric
as	O
ResNet	B-Method
-	I-Method
1001	I-Method
,	O
is	O
8	O
times	O
faster	O
.	O
	
[	O
scale=0.6	O
]	O
.	O
/	O
images	O
/	O
benchmark	O
-	O
edited.pdf	O
	
subsubsection	O
:	O
Implementation	O
details	O
	
In	O
all	O
our	O
experiments	O
we	O
use	O
SGD	B-Method
with	O
Nesterov	B-Method
momentum	I-Method
and	O
cross	O
-	O
entropy	O
loss	B-Metric
.	O
	
The	O
initial	O
learning	B-Metric
rate	I-Metric
is	O
set	O
to	O
0.1	O
,	O
weight	O
decay	O
to	O
0.0005	O
,	O
dampening	O
to	O
0	O
,	O
momentum	O
to	O
0.9	O
and	O
minibatch	O
size	O
to	O
128	O
.	O
	
On	O
CIFAR	B-Material
learning	O
rate	O
dropped	O
by	O
0.2	O
at	O
60	O
,	O
120	O
and	O
160	O
epochs	O
and	O
we	O
train	O
for	O
total	O
200	O
epochs	O
.	O
	
On	O
SVHN	B-Material
initial	O
learning	O
rate	O
is	O
set	O
to	O
0.01	O
and	O
we	O
drop	O
it	O
at	O
80	O
and	O
120	O
epochs	O
by	O
0.1	O
,	O
training	O
for	O
total	O
160	O
epochs	O
.	O
	
Our	O
implementation	O
is	O
based	O
on	O
Torch	B-Method
.	O
	
We	O
use	O
to	O
reduce	O
memory	O
footprints	O
of	O
all	O
our	O
networks	O
.	O
	
For	O
ImageNet	B-Task
experiments	O
we	O
used	O
fb.resnet.torch	B-Method
implementation	I-Method
.	O
	
Our	O
code	O
and	O
models	O
are	O
available	O
at	O
https:	O
//	O
github.com	O
/	O
szagoruyko	O
/	O
wide	O
-	O
residual	O
-	O
networks	O
.	O
	
section	O
:	O
Conclusions	O
	
We	O
presented	O
a	O
study	O
on	O
the	O
width	O
of	O
residual	B-Method
networks	I-Method
as	O
well	O
as	O
on	O
the	O
use	O
of	O
dropout	B-Method
in	I-Method
residual	I-Method
architectures	I-Method
.	O
	
Based	O
on	O
this	O
study	O
,	O
we	O
proposed	O
a	O
wide	B-Method
residual	I-Method
network	I-Method
architecture	I-Method
that	O
provides	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
several	O
commonly	O
used	O
benchmark	O
datasets	O
(	O
including	O
CIFAR	B-Material
-	I-Material
10	I-Material
,	O
CIFAR	B-Material
-	I-Material
100	I-Material
,	O
SVHN	B-Material
and	O
COCO	O
)	O
,	O
as	O
well	O
as	O
significant	O
improvements	O
on	O
ImageNet	O
.	O
	
We	O
demonstrate	O
that	O
wide	B-Method
networks	I-Method
with	O
only	O
16	B-Method
layers	I-Method
can	O
significantly	O
outperform	O
1000	B-Method
-	I-Method
layer	I-Method
deep	I-Method
networks	I-Method
on	O
CIFAR	B-Material
,	O
as	O
well	O
as	O
that	O
50	B-Method
-	I-Method
layer	I-Method
outperform	O
152	O
-	O
layer	O
on	O
ImageNet	O
,	O
thus	O
showing	O
that	O
the	O
main	O
power	O
of	O
residual	B-Method
networks	I-Method
is	O
in	O
residual	O
blocks	O
,	O
and	O
not	O
in	O
extreme	O
depth	O
as	O
claimed	O
earlier	O
.	O
	
Also	O
,	O
wide	B-Method
residual	I-Method
networks	I-Method
are	O
several	O
times	O
faster	O
to	O
train	O
.	O
	
We	O
think	O
that	O
these	O
intriguing	O
findings	O
will	O
help	O
further	O
advances	O
in	O
research	O
in	O
deep	B-Task
neural	I-Task
networks	I-Task
.	O
	
section	O
:	O
Acknowledgements	O
	
We	O
thank	O
startup	O
company	O
VisionLabs	O
and	O
Eugenio	O
Culurciello	O
for	O
giving	O
us	O
access	O
to	O
their	O
clusters	O
,	O
without	O
them	O
ImageNet	O
experiments	O
would	O
n’t	O
be	O
possible	O
.	O
	
We	O
also	O
thank	O
Adam	O
Lerer	O
and	O
Sam	O
Gross	O
for	O
helpful	O
discussions	O
.	O
	
Work	O
supported	O
by	O
EC	O
project	O
FP7	O
-	O
ICT	O
-	O
611145	O
ROBOSPECT	O
.	O
	
bibliography	O
:	O
References	O
	
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
:	O
	
Delving	O
into	O
High	B-Task
Quality	I-Task
Object	I-Task
Detection	I-Task
	
section	O
:	O
Abstract	O
	
In	O
object	B-Task
detection	I-Task
,	O
an	O
intersection	B-Metric
over	I-Metric
union	I-Metric
(	O
IoU	B-Metric
)	O
	
section	O
:	O
Introduction	O
	
Object	B-Task
detection	I-Task
is	O
a	O
complex	O
problem	O
,	O
requiring	O
the	O
solution	O
of	O
two	O
main	O
tasks	O
.	O
	
First	O
,	O
the	O
detector	B-Method
must	O
solve	O
the	O
recognition	B-Task
problem	I-Task
,	O
to	O
distinguish	O
foreground	O
objects	O
from	O
background	O
and	O
assign	O
them	O
the	O
proper	O
object	O
class	O
labels	O
.	O
	
Second	O
,	O
the	O
detector	B-Method
must	O
solve	O
the	O
localization	B-Metric
problem	O
,	O
to	O
assign	O
accurate	O
bounding	O
boxes	O
to	O
different	O
objects	O
.	O
	
Both	O
of	O
these	O
are	O
particularly	O
difficult	O
because	O
the	O
detector	O
faces	O
many	O
"	O
close	O
"	O
false	O
positives	O
,	O
corresponding	O
to	O
"	O
close	O
but	O
not	O
correct	O
"	O
bounding	O
boxes	O
.	O
	
The	O
detector	O
must	O
find	O
the	O
true	O
positives	O
while	O
suppressing	O
these	O
close	O
false	O
positives	O
.	O
	
Many	O
of	O
the	O
recently	O
proposed	O
object	B-Method
detectors	I-Method
are	O
based	O
on	O
the	O
two	B-Method
-	I-Method
stage	I-Method
R	I-Method
-	I-Method
CNN	I-Method
framework	I-Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
,	O
where	O
detection	B-Task
is	O
framed	O
as	O
a	O
multi	B-Task
-	I-Task
task	I-Task
learning	I-Task
problem	I-Task
that	O
combines	O
classification	B-Task
and	O
bounding	B-Method
box	I-Method
regression	O
.	O
	
Unlike	O
object	B-Task
recognition	I-Task
,	O
an	O
intersection	B-Metric
over	I-Metric
union	I-Metric
[	O
reference	O
]	O
threshold	O
is	O
required	O
to	O
define	O
positives	O
/	O
negatives	O
.	O
	
However	O
,	O
the	O
commonly	O
used	O
threshold	O
values	O
u	O
,	O
typically	O
u	O
=	O
0.5	O
,	O
establish	O
quite	O
a	O
loose	O
requirement	O
for	O
positives	O
.	O
	
The	O
resulting	O
detectors	O
frequently	O
produce	O
noisy	O
bounding	O
boxes	O
,	O
as	O
shown	O
in	O
Figure	O
1	O
(	O
a	O
)	O
.	O
	
Hypotheses	O
that	O
most	O
humans	O
would	O
consider	O
close	O
false	O
positives	O
frequently	O
pass	O
the	O
IoU	B-Metric
≥	O
0.5	O
test	O
.	O
	
While	O
the	O
examples	O
assembled	O
under	O
the	O
u	O
=	O
0.5	O
criterion	O
are	O
rich	O
and	O
diversified	O
,	O
they	O
make	O
it	O
difficult	O
to	O
train	O
detectors	B-Method
that	O
can	O
effectively	O
reject	O
close	O
false	O
positives	O
.	O
	
In	O
this	O
work	O
,	O
we	O
define	O
the	O
quality	O
of	O
an	O
hypothesis	O
as	O
its	O
IoU	B-Metric
with	O
the	O
ground	O
truth	O
,	O
and	O
the	O
quality	O
of	O
the	O
detector	B-Method
as	O
the	O
IoU	B-Metric
threshold	O
u	O
used	O
to	O
train	O
it	O
.	O
	
The	O
goal	O
is	O
to	O
investi	O
-	O
gate	O
the	O
,	O
so	O
far	O
,	O
poorly	O
researched	O
problem	O
of	O
learning	O
high	O
quality	O
object	B-Task
detectors	I-Task
,	O
whose	O
outputs	O
contain	O
few	O
close	O
false	O
positives	O
,	O
as	O
shown	O
in	O
Figure	O
1	O
	
[	O
reference	O
]	O
.	O
	
The	O
basic	O
idea	O
is	O
that	O
a	O
single	O
detector	B-Method
can	O
only	O
be	O
optimal	O
for	O
a	O
single	O
quality	O
level	O
.	O
	
This	O
is	O
known	O
in	O
the	O
cost	O
-	O
sensitive	O
learning	O
literature	O
[	O
reference	O
][	O
reference	O
]	O
,	O
where	O
the	O
optimization	O
of	O
different	O
points	O
of	O
the	O
receiver	B-Metric
operating	I-Metric
characteristic	I-Metric
(	O
ROC	B-Metric
)	O
requires	O
different	O
loss	O
functions	O
.	O
	
The	O
main	O
difference	O
is	O
that	O
we	O
consider	O
the	O
optimization	B-Task
for	O
a	O
given	O
IoU	B-Metric
threshold	O
,	O
rather	O
than	O
false	B-Metric
positive	I-Metric
rate	I-Metric
.	O
	
The	O
idea	O
is	O
illustrated	O
by	O
Figure	O
1	O
(	O
c	O
)	O
and	O
(	O
d	O
)	O
,	O
which	O
present	O
the	O
localization	B-Metric
and	O
detection	B-Metric
performance	I-Metric
,	O
respectively	O
,	O
of	O
three	O
detectors	B-Method
trained	O
with	O
IoU	B-Metric
thresholds	O
of	O
u	O
=	O
0.5	O
,	O
0.6	O
,	O
0.7	O
.	O
	
The	O
localization	B-Metric
performance	I-Metric
is	O
evaluated	O
as	O
a	O
function	O
of	O
the	O
IoU	B-Metric
of	O
the	O
input	O
proposals	O
,	O
and	O
the	O
detection	B-Metric
performance	I-Metric
as	O
a	O
function	O
of	O
IoU	B-Metric
threshold	O
,	O
as	O
in	O
COCO	B-Material
	
[	O
reference	O
]	O
.	O
Note	O
that	O
,	O
in	O
Figure	O
1	O
(	O
c	O
)	O
,	O
each	O
bounding	B-Method
box	I-Method
regressor	O
performs	O
best	O
for	O
examples	O
of	O
IoU	B-Metric
close	O
to	O
the	O
threshold	O
that	O
the	O
detector	B-Method
was	O
trained	O
.	O
	
This	O
also	O
holds	O
for	O
detection	B-Metric
performance	I-Metric
,	O
up	O
to	O
overfitting	O
.	O
	
Figure	O
1	O
(	O
d	O
)	O
shows	O
that	O
,	O
the	O
detector	B-Method
of	I-Method
u	I-Method
=	I-Method
0.5	I-Method
outperforms	O
the	O
detector	O
of	O
u	O
=	O
0.6	O
for	O
low	O
IoU	B-Metric
examples	O
,	O
underperforming	O
it	O
at	O
higher	O
IoU	B-Metric
levels	O
.	O
	
In	O
general	O
,	O
a	O
detector	B-Method
optimized	O
at	O
a	O
single	O
IoU	B-Metric
level	O
is	O
not	O
necessarily	O
optimal	O
at	O
other	O
levels	O
.	O
	
These	O
observations	O
suggest	O
that	O
higher	O
quality	O
detection	B-Task
requires	O
a	O
closer	O
quality	O
match	O
between	O
the	O
detector	B-Method
and	O
the	O
hypotheses	O
that	O
it	O
processes	O
.	O
	
In	O
general	O
,	O
a	O
detector	B-Method
can	O
only	O
have	O
high	O
quality	O
if	O
presented	O
with	O
high	O
quality	O
proposals	O
.	O
	
However	O
,	O
to	O
produce	O
a	O
high	O
quality	O
detector	B-Method
,	O
it	O
does	O
not	O
suffice	O
to	O
simply	O
increase	O
u	O
during	O
training	O
.	O
	
In	O
fact	O
,	O
as	O
seen	O
for	O
the	O
detector	O
of	O
u	O
=	O
0.7	O
of	O
Figure	O
1	O
(	O
d	O
)	O
,	O
this	O
can	O
degrade	O
detection	B-Metric
performance	I-Metric
.	O
	
The	O
problem	O
is	O
that	O
the	O
distribution	O
of	O
hypotheses	O
out	O
of	O
a	O
proposal	B-Method
detector	I-Method
is	O
usually	O
heavily	O
imbalanced	O
towards	O
low	B-Metric
quality	I-Metric
.	O
	
In	O
general	O
,	O
forcing	O
larger	O
IoU	B-Metric
thresholds	O
leads	O
to	O
an	O
exponentially	O
smaller	O
numbers	O
of	O
positive	O
training	O
samples	O
.	O
	
This	O
is	O
particularly	O
problematic	O
for	O
neural	B-Method
networks	I-Method
,	O
which	O
are	O
known	O
to	O
be	O
very	O
example	O
intensive	O
,	O
and	O
makes	O
the	O
"	O
high	B-Method
u	I-Method
"	I-Method
training	I-Method
strategy	I-Method
quite	O
prone	O
to	O
overfitting	O
.	O
	
Another	O
difficulty	O
is	O
the	O
mismatch	O
between	O
the	O
quality	O
of	O
the	O
detector	B-Method
and	O
that	O
of	O
the	O
testing	O
hypotheses	O
at	O
inference	B-Task
.	O
	
As	O
shown	O
in	O
Figure	O
1	O
,	O
high	O
quality	O
detectors	O
are	O
only	O
necessarily	O
optimal	O
for	O
high	O
quality	O
hypotheses	O
.	O
	
The	O
detection	B-Task
could	O
be	O
suboptimal	O
when	O
they	O
are	O
asked	O
to	O
work	O
on	O
the	O
hypotheses	O
of	O
other	O
quality	O
levels	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
new	O
detector	B-Method
architecture	I-Method
,	O
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
,	O
that	O
addresses	O
these	O
problems	O
.	O
	
It	O
is	O
a	O
multi	B-Method
-	I-Method
stage	I-Method
extension	I-Method
of	O
the	O
R	B-Method
-	I-Method
CNN	I-Method
,	O
where	O
detector	B-Method
stages	I-Method
deeper	O
into	O
the	O
cascade	B-Method
are	O
sequentially	O
more	O
selective	O
against	O
close	O
false	O
positives	O
.	O
	
The	O
cascade	O
of	O
R	B-Method
-	I-Method
CNN	I-Method
stages	O
are	O
trained	O
sequentially	O
,	O
using	O
the	O
output	O
of	O
one	O
stage	O
to	O
train	O
the	O
next	O
.	O
	
This	O
is	O
motivated	O
by	O
the	O
observation	O
that	O
the	O
output	O
IoU	B-Metric
of	O
a	O
regressor	B-Method
is	O
almost	O
invariably	O
better	O
than	O
the	O
input	O
IoU.	O
	
This	O
observation	O
can	O
be	O
made	O
in	O
Figure	O
1	O
(	O
c	O
)	O
,	O
where	O
all	O
plots	O
are	O
above	O
the	O
gray	O
line	O
.	O
	
It	O
suggests	O
that	O
the	O
output	O
of	O
a	O
detector	B-Method
trained	O
with	O
a	O
certain	O
IoU	B-Metric
threshold	O
is	O
a	O
good	O
distribution	O
to	O
train	O
the	O
detector	O
of	O
the	O
next	O
higher	O
IoU	B-Metric
threshold	O
.	O
	
This	O
is	O
similar	O
to	O
boostrapping	B-Method
methods	I-Method
commonly	O
used	O
to	O
assemble	O
datasets	O
in	O
object	B-Task
detection	I-Task
literature	O
	
[	O
reference	O
][	O
reference	O
]	O
.	O
	
The	O
main	O
difference	O
is	O
that	O
the	O
resampling	B-Method
procedure	I-Method
of	O
the	O
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
does	O
not	O
aim	O
to	O
mine	O
hard	O
negatives	O
.	O
	
Instead	O
,	O
by	O
adjusting	O
bounding	O
boxes	O
,	O
each	O
stage	O
aims	O
to	O
find	O
a	O
good	O
set	O
of	O
close	O
false	O
positives	O
for	O
training	O
the	O
next	O
stage	O
.	O
	
When	O
operating	O
in	O
this	O
manner	O
,	O
a	O
sequence	O
of	O
detectors	B-Method
adapted	O
to	O
increasingly	O
higher	O
IoUs	O
can	O
beat	O
the	O
overfitting	B-Task
problem	I-Task
,	O
and	O
thus	O
be	O
effectively	O
trained	O
.	O
	
At	O
inference	B-Task
,	O
the	O
same	O
cascade	B-Method
procedure	I-Method
is	O
applied	O
.	O
	
The	O
progressively	O
improved	O
hypotheses	O
are	O
better	O
matched	O
to	O
the	O
increasing	O
detector	B-Metric
quality	I-Metric
at	O
each	O
stage	O
.	O
	
This	O
enables	O
higher	O
detection	B-Task
accuracies	O
,	O
as	O
suggested	O
by	O
Figure	O
1	O
(	O
c	O
)	O
and	O
(	O
d	O
)	O
.	O
	
The	O
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
is	O
quite	O
simple	O
to	O
implement	O
and	O
trained	O
end	O
-	O
to	O
-	O
end	O
.	O
	
Our	O
results	O
show	O
that	O
a	O
vanilla	B-Method
implementation	I-Method
,	O
without	O
any	O
bells	O
and	O
whistles	O
,	O
surpasses	O
all	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
single	B-Method
-	I-Method
model	I-Method
detectors	I-Method
by	O
a	O
large	O
margin	O
,	O
on	O
the	O
challenging	O
COCO	B-Material
detection	I-Task
task	O
[	O
reference	O
]	O
,	O
especially	O
under	O
the	O
higher	O
quality	B-Metric
evaluation	I-Metric
metrics	I-Metric
.	O
	
In	O
addition	O
,	O
the	O
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
can	O
be	O
built	O
with	O
any	O
two	B-Method
-	I-Method
stage	I-Method
object	I-Method
detector	I-Method
based	O
on	O
the	O
R	B-Method
-	I-Method
CNN	I-Method
framework	O
.	O
	
We	O
have	O
observed	O
consistent	O
gains	O
(	O
of	O
2∼4	O
points	O
)	O
,	O
at	O
a	O
marginal	O
increase	O
in	O
computation	B-Task
.	O
	
This	O
gain	O
is	O
independent	O
of	O
the	O
strength	O
of	O
the	O
baseline	B-Method
object	I-Method
detectors	I-Method
.	O
	
We	O
thus	O
believe	O
that	O
this	O
simple	O
and	O
effective	O
detection	B-Task
architecture	O
can	O
be	O
of	O
interest	O
for	O
many	O
object	B-Task
detection	I-Task
research	O
efforts	O
.	O
	
section	O
:	O
Related	O
Work	O
	
Due	O
to	O
the	O
success	O
of	O
the	O
R	B-Method
-	I-Method
CNN	I-Method
[	O
reference	O
]	O
architecture	O
,	O
the	O
two	B-Method
-	I-Method
stage	I-Method
formulation	I-Method
of	O
the	O
detection	B-Task
problems	O
,	O
by	O
combining	O
a	O
proposal	B-Method
detector	I-Method
and	O
a	O
region	B-Method
-	I-Method
wise	I-Method
classifier	I-Method
has	O
become	O
predominant	O
in	O
the	O
recent	O
past	O
.	O
	
To	O
reduce	O
redundant	O
CNN	O
computations	O
in	O
the	O
R	B-Method
-	I-Method
CNN	I-Method
,	O
the	O
SPP	B-Method
-	I-Method
Net	I-Method
[	O
reference	O
]	O
and	O
Fast	O
-	O
RCNN	B-Method
[	O
reference	O
]	O
introduced	O
the	O
idea	O
of	O
region	B-Method
-	I-Method
wise	I-Method
feature	I-Method
extraction	I-Method
,	O
significantly	O
speeding	O
up	O
the	O
overall	O
detector	B-Task
.	O
	
Later	O
,	O
the	O
Faster	O
-	O
RCNN	B-Method
[	O
reference	O
]	O
achieved	O
further	O
speedsup	O
by	O
introducing	O
a	O
Region	B-Method
Proposal	I-Method
Network	I-Method
(	O
RPN	B-Method
)	O
.	O
	
This	O
architecture	O
has	O
become	O
a	O
leading	O
object	B-Task
detection	I-Task
framework	O
.	O
	
Some	O
more	O
recent	O
works	O
have	O
extended	O
it	O
to	O
address	O
various	O
problems	O
of	O
detail	O
.	O
	
For	O
example	O
,	O
the	O
R	B-Method
-	I-Method
FCN	I-Method
[	O
reference	O
]	O
proposed	O
efficient	O
region	B-Method
-	I-Method
wise	I-Method
fully	I-Method
convolutions	I-Method
without	O
accuracy	B-Metric
loss	I-Metric
,	O
to	O
avoid	O
the	O
heavy	O
region	B-Method
-	I-Method
wise	I-Method
CNN	I-Method
computations	I-Method
of	O
the	O
Faster	O
-	O
RCNN	B-Method
;	O
while	O
the	O
MS	B-Method
-	I-Method
CNN	I-Method
[	O
reference	O
]	O
and	O
FPN	B-Method
[	O
reference	O
]	O
detect	O
proposals	O
at	O
multiple	O
output	O
layers	O
,	O
so	O
as	O
to	O
alleviate	O
the	O
scale	O
mismatch	O
between	O
the	O
RPN	O
receptive	O
fields	O
and	O
actual	O
object	O
size	O
,	O
for	O
high	O
-	O
recall	O
proposal	O
detection	B-Task
.	O
	
Alternatively	O
,	O
one	O
-	O
stage	O
object	B-Task
detection	I-Task
architectures	O
have	O
also	O
become	O
popular	O
,	O
mostly	O
due	O
to	O
their	O
computational	B-Metric
efficiency	I-Metric
.	O
	
These	O
architectures	O
are	O
close	O
to	O
the	O
classic	O
sliding	B-Method
window	I-Method
strategy	I-Method
[	O
reference	O
][	O
reference	O
]	O
.	O
YOLO	O
[	O
reference	O
]	O
outputs	O
very	O
sparse	O
detection	B-Task
results	O
by	O
forwarding	O
the	O
input	O
image	O
once	O
.	O
	
When	O
implemented	O
with	O
an	O
efficient	O
backbone	B-Method
network	I-Method
,	O
it	O
enables	O
real	O
time	O
object	B-Task
detection	I-Task
with	O
fair	O
performance	O
.	O
	
SSD	B-Method
[	O
reference	O
]	O
detects	O
objects	O
in	O
a	O
way	O
similar	O
to	O
the	O
RPN	B-Method
[	O
reference	O
]	O
,	O
but	O
uses	O
multiple	O
feature	O
maps	O
at	O
different	O
resolutions	O
to	O
cover	O
objects	O
at	O
various	O
scales	O
.	O
	
The	O
main	O
limitation	O
of	O
these	O
architectures	O
is	O
that	O
their	O
accuracies	B-Metric
are	O
typically	O
below	O
that	O
of	O
two	B-Method
-	I-Method
stage	I-Method
detectors	I-Method
.	O
	
Recently	O
,	O
RetinaNet	B-Method
[	O
reference	O
]	O
was	O
proposed	O
to	O
address	O
the	O
extreme	O
foreground	O
-	O
background	O
class	O
imbalance	O
in	O
dense	O
object	B-Task
detection	I-Task
,	O
achieving	O
better	O
results	O
than	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
two	B-Method
-	I-Method
stage	I-Method
object	I-Method
detectors	I-Method
.	O
	
Some	O
explorations	O
in	O
multi	O
-	O
stage	O
object	B-Task
detection	I-Task
have	O
also	O
been	O
proposed	O
.	O
	
The	O
multi	B-Method
-	I-Method
region	I-Method
detector	I-Method
[	O
reference	O
]	O
introduced	O
iterative	O
bounding	B-Method
box	I-Method
regression	O
,	O
where	O
a	O
R	B-Method
-	I-Method
CNN	I-Method
is	O
applied	O
several	O
times	O
,	O
to	O
produce	O
better	O
bounding	O
boxes	O
.	O
	
CRAFT	O
[	O
reference	O
]	O
and	O
AttractioNet	O
[	O
reference	O
]	O
used	O
a	O
multi	B-Method
-	I-Method
stage	I-Method
procedure	I-Method
to	O
generate	O
accurate	O
proposals	O
,	O
and	O
forwarded	O
them	O
to	O
a	O
Fast	O
-	O
RCNN	B-Method
.	O
	
[	O
reference	O
][	O
reference	O
]	O
embedded	O
the	O
classic	O
cascade	B-Method
architecture	I-Method
of	O
[	O
reference	O
]	O
in	O
object	B-Task
detection	I-Task
networks	O
.	O
	
[	O
reference	O
]	O
iterated	O
a	O
detection	B-Task
and	O
a	O
segmentation	B-Task
task	I-Task
alternatively	O
,	O
for	O
instance	B-Task
segmentation	I-Task
.	O
	
section	O
:	O
Object	B-Task
Detection	I-Task
	
In	O
this	O
paper	O
,	O
we	O
extend	O
the	O
two	B-Method
-	I-Method
stage	I-Method
architecture	I-Method
of	O
the	O
Faster	O
-	O
RCNN	B-Method
[	O
reference	O
][	O
reference	O
]	O
,	O
shown	O
in	O
Figure	O
3	O
(	O
a	O
)	O
.	O
	
The	O
first	O
stage	O
is	O
a	O
proposal	B-Method
sub	I-Method
-	I-Method
network	I-Method
(	O
"	O
H0	O
"	O
)	O
,	O
applied	O
to	O
the	O
entire	O
image	O
,	O
to	O
produce	O
preliminary	O
detection	B-Task
hypotheses	O
,	O
known	O
as	O
object	O
proposals	O
.	O
	
In	O
the	O
second	O
stage	O
,	O
these	O
hypotheses	O
are	O
then	O
processed	O
by	O
a	O
region	O
-	O
of	O
-	O
interest	O
detection	B-Task
subnetwork	O
(	O
"	O
H1	O
"	O
)	O
,	O
denoted	O
as	O
detection	B-Task
head	O
.	O
	
A	O
final	O
classification	B-Metric
score	I-Metric
(	O
"	O
C	O
"	O
)	O
and	O
a	O
bounding	B-Method
box	I-Method
(	O
"	O
B	O
"	O
)	O
are	O
assigned	O
to	O
each	O
hypothesis	O
.	O
	
We	O
focus	O
on	O
modeling	O
a	O
multi	O
-	O
stage	O
detection	B-Task
sub	O
-	O
network	O
,	O
and	O
adopt	O
,	O
but	O
are	O
not	O
limited	O
to	O
,	O
the	O
RPN	B-Method
[	O
reference	O
]	O
for	O
proposal	O
detection	B-Task
.	O
	
section	O
:	O
Bounding	B-Task
Box	I-Task
Regression	I-Task
	
A	O
bounding	B-Method
box	I-Method
b	O
=	O
	
(	O
b	O
x	O
,	O
b	O
y	O
,	O
b	O
w	O
,	O
b	O
h	O
)	O
contains	O
the	O
four	O
coordinates	O
of	O
an	O
image	O
patch	O
x.	O
	
The	O
task	O
of	O
bounding	B-Method
box	I-Method
regression	O
is	O
to	O
regress	O
a	O
candidate	O
bounding	B-Method
box	I-Method
b	O
into	O
a	O
target	O
bounding	B-Method
box	I-Method
g	O
,	O
using	O
a	O
regressor	B-Method
f	I-Method
(	O
x	O
,	O
b	O
)	O
.	O
	
This	O
is	O
learned	O
from	O
a	O
training	O
sample	O
{	O
g	O
i	O
,	O
b	O
i	O
}	O
,	O
so	O
as	O
to	O
minimize	O
the	O
bounding	B-Method
box	I-Method
risk	O
	
where	O
L	O
loc	O
was	O
a	O
L	O
2	O
loss	O
function	O
in	O
R	B-Method
-	I-Method
CNN	I-Method
[	O
reference	O
]	O
,	O
but	O
updated	O
to	O
a	O
smoothed	O
L	B-Method
1	I-Method
loss	I-Method
function	I-Method
in	O
Fast	O
-	O
RCNN	B-Method
[	O
reference	O
]	O
.	O
	
To	O
encourage	O
a	O
regression	O
invariant	O
to	O
scale	O
and	O
location	O
,	O
L	B-Method
loc	I-Method
operates	O
on	O
the	O
distance	O
vector	O
∆	O
=	O
	
(	O
δ	O
x	O
,	O
δ	O
y	O
,	O
δ	O
w	O
,	O
δ	O
h	O
)	O
defined	O
by	O
	
Since	O
bounding	B-Method
box	I-Method
regression	O
usually	O
performs	O
minor	O
adjustments	O
on	O
b	O
,	O
the	O
numerical	O
values	O
of	O
(	O
2	O
)	O
can	O
be	O
very	O
small	O
.	O
	
Hence	O
,	O
the	O
risk	O
of	O
(	O
1	O
)	O
is	O
usually	O
much	O
smaller	O
than	O
the	O
classification	B-Metric
risk	I-Metric
.	O
	
To	O
improve	O
the	O
effectiveness	O
of	O
multi	B-Task
-	I-Task
task	I-Task
learning	I-Task
,	O
∆	O
is	O
usually	O
normalized	O
by	O
its	O
mean	O
and	O
variance	O
,	O
i.e.	O
δ	O
x	O
is	O
replaced	O
by	O
δ	O
′	O
x	O
=	O
	
(	O
δ	O
x	O
−	O
µ	O
x	O
)	O
	
/	O
σ	O
	
x	O
.	O
	
This	O
is	O
widely	O
used	O
in	O
the	O
literature	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
	
Some	O
works	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
have	O
argued	O
that	O
a	O
single	O
regression	B-Method
step	I-Method
of	I-Method
f	I-Method
is	O
insufficient	O
for	O
accurate	O
localization	B-Metric
.	O
	
Instead	O
,	O
f	O
is	O
applied	O
iteratively	O
,	O
as	O
a	O
post	O
-	O
processing	O
step	O
	
to	O
refine	O
a	O
bounding	B-Method
box	I-Method
b.	O
	
This	O
is	O
called	O
iterative	O
bounding	B-Method
box	I-Method
regression	O
,	O
denoted	O
as	O
iterative	B-Method
BBox	I-Method
.	O
	
It	O
can	O
be	O
implemented	O
with	O
the	O
inference	B-Method
architecture	I-Method
of	O
Figure	O
3	O
(	O
b	O
)	O
where	O
all	O
heads	O
are	O
the	O
same	O
.	O
	
This	O
idea	O
,	O
however	O
,	O
ignores	O
two	O
problems	O
.	O
	
First	O
,	O
as	O
shown	O
in	O
Figure	O
1	O
,	O
a	O
regressor	B-Method
f	I-Method
trained	O
at	O
u	O
=	O
0.5	O
,	O
is	O
suboptimal	O
for	O
hypotheses	O
of	O
higher	O
IoUs	O
.	O
	
It	O
actually	O
degrades	O
bounding	O
boxes	O
of	O
IoU	B-Metric
larger	O
than	O
0.85	O
.	O
	
Second	O
,	O
as	O
shown	O
in	O
Figure	O
2	O
,	O
the	O
distribution	O
of	O
bounding	O
boxes	O
changes	O
significantly	O
after	O
each	O
iteration	O
.	O
	
While	O
the	O
regressor	B-Method
is	O
optimal	O
for	O
the	O
initial	O
distribution	O
it	O
can	O
be	O
quite	O
suboptimal	O
after	O
that	O
.	O
	
Due	O
to	O
these	O
problems	O
,	O
iterative	B-Method
BBox	I-Method
requires	O
a	O
fair	O
amount	O
of	O
human	O
engineering	O
,	O
in	O
the	O
form	O
of	O
proposal	B-Task
accumulation	I-Task
,	O
box	B-Task
voting	I-Task
,	O
etc	O
.	O
	
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
,	O
and	O
has	O
somewhat	O
unreliable	O
gains	O
.	O
	
Usually	O
,	O
there	O
is	O
no	O
benefit	O
beyond	O
applying	O
f	O
twice	O
.	O
	
section	O
:	O
Classification	B-Task
	
The	O
classifier	B-Method
is	O
a	O
function	B-Method
h	I-Method
(	I-Method
x	I-Method
)	O
that	O
assigns	O
an	O
image	O
patch	O
x	O
to	O
one	O
of	O
M	O
+	O
1	O
classes	O
,	O
where	O
class	O
0	O
contains	O
(	O
d	O
)	O
	
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
Figure	O
3	O
.	O
	
The	O
architectures	O
of	O
different	O
frameworks	O
.	O
	
"	O
	
I	O
"	O
is	O
input	O
image	O
,	O
"	O
conv	B-Method
"	I-Method
backbone	I-Method
convolutions	I-Method
,	O
"	O
pool	O
"	O
region	B-Method
-	I-Method
wise	I-Method
feature	I-Method
extraction	I-Method
,	O
"	O
H	O
"	O
network	O
head	O
,	O
"	O
B	O
"	O
bounding	B-Method
box	I-Method
,	O
and	O
"	O
C	O
"	O
classification	B-Task
.	O
	
"	O
B0	O
"	O
is	O
proposals	O
in	O
all	O
architectures	O
.	O
	
background	O
and	O
the	O
remaining	O
the	O
objects	O
to	O
detect	O
.	O
	
h	O
(	O
x	O
	
)	O
is	O
a	O
M	O
+	O
1	O
-	O
dimensional	O
estimate	O
of	O
the	O
posterior	O
distribution	O
over	O
classes	O
,	O
i.e.	O
h	O
k	O
(	O
x	O
)	O
	
=	O
	
p	O
(	O
y	O
	
=	O
k|x	O
)	O
	
,	O
where	O
y	O
is	O
the	O
class	O
label	O
.	O
	
Given	O
a	O
training	O
set	O
(	O
x	O
i	O
,	O
y	O
i	O
)	O
,	O
it	O
is	O
learned	O
by	O
minimizing	O
a	O
classification	B-Method
risk	I-Method
	
where	O
L	B-Method
cls	I-Method
is	O
the	O
classic	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
loss	I-Metric
.	O
	
section	O
:	O
Detection	B-Metric
Quality	I-Metric
	
Since	O
a	O
bounding	B-Method
box	I-Method
usually	O
includes	O
an	O
object	O
and	O
some	O
amount	O
of	O
background	O
,	O
it	O
is	O
difficult	O
to	O
determine	O
if	O
a	O
detection	B-Task
is	O
positive	O
or	O
negative	O
.	O
	
This	O
is	O
usually	O
addressed	O
by	O
the	O
IoU	B-Metric
metric	O
.	O
	
If	O
the	O
IoU	B-Metric
is	O
above	O
a	O
threshold	O
u	O
,	O
the	O
patch	O
is	O
considered	O
an	O
example	O
of	O
the	O
class	O
.	O
	
Thus	O
,	O
the	O
class	O
label	O
of	O
a	O
hypothesis	O
x	O
is	O
a	O
function	O
of	O
u	O
,	O
	
where	O
g	O
y	O
is	O
the	O
class	O
label	O
of	O
the	O
ground	O
truth	O
object	O
g.	O
	
This	O
IoU	B-Metric
threshold	O
u	O
defines	O
the	O
quality	O
of	O
a	O
detector	B-Method
.	O
	
Object	B-Task
detection	I-Task
is	O
challenging	O
because	O
,	O
no	O
matter	O
threshold	O
,	O
the	O
detection	B-Task
setting	I-Task
is	O
highly	O
adversarial	O
.	O
	
When	O
u	O
is	O
high	O
,	O
the	O
positives	O
contain	O
less	O
background	O
,	O
but	O
it	O
is	O
difficult	O
to	O
assemble	O
enough	O
positive	O
training	O
examples	O
.	O
	
When	O
u	O
is	O
low	O
,	O
a	O
richer	O
and	O
more	O
diversified	O
positive	O
training	O
set	O
is	O
available	O
,	O
but	O
the	O
trained	O
detector	O
has	O
little	O
incentive	O
to	O
reject	O
close	O
false	O
positives	O
.	O
	
In	O
general	O
,	O
it	O
is	O
very	O
difficult	O
to	O
ask	O
a	O
single	O
classifier	B-Method
to	O
perform	O
uniformly	O
well	O
over	O
all	O
IoU	B-Metric
levels	O
.	O
	
At	O
inference	B-Task
,	O
since	O
the	O
majority	O
of	O
the	O
hypotheses	O
produced	O
by	O
a	O
proposal	B-Method
detector	I-Method
,	O
e.g.	O
RPN	B-Method
[	O
reference	O
]	O
or	O
selective	B-Method
search	I-Method
[	O
reference	O
]	O
,	O
have	O
low	O
quality	O
,	O
the	O
detector	O
must	O
be	O
more	O
discriminant	O
for	O
lower	O
quality	O
hypotheses	O
.	O
	
A	O
standard	O
compromise	O
between	O
these	O
conflicting	O
requirements	O
is	O
to	O
settle	O
on	O
u	O
=	O
0.5	O
.	O
	
This	O
,	O
however	O
,	O
is	O
a	O
relatively	O
low	O
threshold	O
,	O
leading	O
to	O
low	O
quality	O
detections	O
that	O
most	O
humans	O
consider	O
close	O
false	O
positives	O
,	O
as	O
shown	O
in	O
Figure	O
1	O
(	O
a	O
)	O
.	O
	
A	O
naïve	O
solution	O
is	O
to	O
develop	O
an	O
ensemble	B-Method
of	I-Method
classifiers	I-Method
,	O
with	O
the	O
architecture	O
of	O
Figure	O
3	O
that	O
targets	O
various	O
quality	O
levels	O
,	O
	
where	O
U	O
is	O
a	O
set	O
of	O
IoU	B-Metric
thresholds	O
.	O
	
This	O
is	O
closely	O
related	O
to	O
the	O
integral	O
loss	O
of	O
[	O
reference	O
]	O
,	O
in	O
which	O
U	O
=	O
{	O
0.5	O
,	O
0.55	O
,	O
·	O
·	O
·	O
,	O
0.75	O
}	O
,	O
designed	O
to	O
fit	O
the	O
evaluation	B-Metric
metric	I-Metric
of	O
the	O
COCO	B-Material
challenge	I-Material
.	O
	
By	O
definition	O
,	O
the	O
classifiers	B-Method
need	O
to	O
be	O
ensembled	O
at	O
inference	B-Task
.	O
	
This	O
solution	O
fails	O
to	O
address	O
the	O
problem	O
that	O
the	O
different	O
losses	O
of	O
(	O
6	O
)	O
operate	O
on	O
different	O
numbers	O
of	O
positives	O
.	O
	
As	O
shown	O
in	O
the	O
first	O
figure	O
of	O
Figure	O
4	O
,	O
the	O
set	O
of	O
positive	O
samples	O
decreases	O
quickly	O
with	O
u.	O
	
This	O
is	O
particularly	O
problematic	O
because	O
the	O
high	O
quality	O
classifiers	B-Method
are	O
prone	O
to	O
overfitting	O
.	O
	
In	O
addition	O
,	O
those	O
high	O
quality	O
classifiers	B-Method
are	O
required	O
to	O
process	O
proposals	O
of	O
overwhelming	O
low	O
quality	O
at	O
inference	B-Task
,	O
for	O
which	O
they	O
are	O
not	O
optimized	O
.	O
	
Due	O
to	O
all	O
this	O
,	O
the	O
ensemble	O
of	O
(	O
6	O
)	O
fails	O
to	O
achieve	O
higher	O
accuracy	B-Metric
at	O
most	O
quality	O
levels	O
,	O
and	O
the	O
architecture	O
has	O
very	O
little	O
gain	O
over	O
that	O
of	O
Figure	O
3	O
(	O
a	O
)	O
.	O
	
section	O
:	O
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
	
In	O
this	O
section	O
we	O
introduce	O
the	O
proposed	O
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
object	I-Task
detection	I-Task
architecture	O
of	O
Figure	O
3	O
(	O
d	O
)	O
.	O
	
section	O
:	O
Cascaded	B-Method
Bounding	I-Method
Box	I-Method
Regression	I-Method
	
As	O
seen	O
in	O
Figure	O
1	O
(	O
c	O
)	O
,	O
it	O
is	O
very	O
difficult	O
to	O
ask	O
a	O
single	O
regressor	B-Method
to	O
perform	O
perfectly	O
uniformly	O
at	O
all	O
quality	O
levels	O
.	O
	
The	O
difficult	B-Task
regression	I-Task
task	I-Task
can	O
be	O
decomposed	O
into	O
a	O
sequence	O
of	O
simpler	O
steps	O
,	O
inspired	O
by	O
the	O
works	O
of	O
cascade	B-Method
pose	I-Method
regression	I-Method
[	O
reference	O
]	O
and	O
face	B-Task
alignment	I-Task
	
[	O
reference	O
][	O
reference	O
]	O
.	O
	
In	O
the	O
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
,	O
it	O
is	O
framed	O
as	O
a	O
cascaded	B-Task
regression	I-Task
problem	I-Task
,	O
with	O
the	O
architecture	O
of	O
Figure	O
3	O
(	O
d	O
)	O
.	O
	
This	O
relies	O
on	O
a	O
cascade	B-Method
of	I-Method
specialized	I-Method
regressors	I-Method
	
where	O
T	O
is	O
the	O
total	O
number	O
of	O
cascade	O
stages	O
.	O
	
Note	O
that	O
each	O
regressor	O
f	O
t	O
in	O
the	O
cascade	B-Method
is	O
optimized	O
w.r.t	O
.	O
	
the	O
sample	O
distribution	O
{	O
b	O
t	O
}	O
arriving	O
at	O
the	O
corresponding	O
stage	O
,	O
instead	O
of	O
the	O
initial	O
distribution	O
of	O
{	O
b	O
1	O
}	O
.	O
	
This	O
cascade	O
improves	O
hypotheses	O
progressively	O
.	O
	
It	O
differs	O
from	O
the	O
iterative	B-Method
BBox	I-Method
architecture	I-Method
of	O
Figure	O
3	O
(	O
b	O
)	O
in	O
several	O
ways	O
.	O
	
First	O
,	O
while	O
iterative	B-Method
BBox	I-Method
is	O
a	O
postprocessing	B-Method
procedure	I-Method
used	O
to	O
improve	O
bounding	O
boxes	O
,	O
cascaded	B-Method
regression	I-Method
is	O
a	O
resampling	B-Method
procedure	I-Method
that	O
changes	O
the	O
distribution	O
of	O
hypotheses	O
to	O
be	O
processed	O
by	O
the	O
different	O
stages	O
.	O
	
Second	O
,	O
because	O
it	O
is	O
used	O
at	O
both	O
training	B-Task
and	I-Task
inference	I-Task
,	O
there	O
is	O
no	O
discrepancy	O
between	O
training	O
and	O
inference	O
distributions	O
.	O
	
Third	O
,	O
the	O
multiple	O
specialized	O
regressors	O
{	O
f	O
T	O
,	O
f	O
T	O
−1	O
,	O
·	O
·	O
·	O
,	O
f	O
1	O
}	O
are	O
optimized	O
for	O
the	O
resampled	O
distributions	O
of	O
the	O
different	O
stages	O
.	O
	
This	O
opposes	O
to	O
the	O
single	O
f	O
of	O
(	O
3	O
)	O
,	O
which	O
is	O
only	O
optimal	O
for	O
the	O
initial	O
distribution	O
.	O
	
These	O
differences	O
enable	O
more	O
precise	O
localization	B-Metric
than	O
iterative	B-Method
BBox	I-Method
,	O
with	O
no	O
further	O
human	O
engineering	O
.	O
	
As	O
discussed	O
in	O
Section	O
3.1	O
,	O
∆	O
=	O
(	O
δ	O
x	O
,	O
δ	O
y	O
,	O
δ	O
w	O
,	O
δ	O
h	O
)	O
in	O
(	O
2	O
)	O
needs	O
to	O
be	O
normalized	O
by	O
its	O
mean	O
and	O
variance	O
for	O
effective	O
multi	B-Task
-	I-Task
task	I-Task
learning	I-Task
.	O
	
After	O
each	O
regression	O
stage	O
,	O
these	O
statistics	O
will	O
evolve	O
sequentially	O
,	O
as	O
displayed	O
in	O
Figure	O
2	O
.	O
	
At	O
training	O
,	O
the	O
corresponding	O
statistics	O
are	O
used	O
to	O
normalize	O
∆	O
at	O
each	O
stage	O
.	O
	
section	O
:	O
Cascaded	B-Task
Detection	I-Task
	
As	O
shown	O
in	O
the	O
left	O
of	O
Figure	O
4	O
,	O
the	O
distribution	O
of	O
the	O
initial	O
hypotheses	O
,	O
e.g.	O
RPN	O
proposals	O
,	O
is	O
heavily	O
tilted	O
towards	O
low	O
quality	O
.	O
	
This	O
inevitably	O
induces	O
ineffective	O
learning	O
of	O
higher	O
quality	B-Method
classifiers	I-Method
.	O
	
The	O
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
addresses	O
the	O
problem	O
by	O
relying	O
on	O
cascade	B-Method
regression	I-Method
as	O
a	O
resampling	B-Method
mechanism	I-Method
.	O
	
This	O
is	O
is	O
motivated	O
by	O
the	O
fact	O
that	O
in	O
Figure	O
1	O
(	O
c	O
)	O
all	O
curves	O
are	O
above	O
the	O
diagonal	O
gray	O
line	O
,	O
i.e.	O
a	O
bounding	B-Method
box	I-Method
regressor	O
trained	O
for	O
a	O
certain	O
u	O
tends	O
to	O
produce	O
bounding	O
boxes	O
of	O
higher	O
IoU.	O
	
Hence	O
,	O
starting	O
from	O
a	O
set	O
of	O
examples	O
(	O
x	O
i	O
,	O
b	O
i	O
)	O
,	O
cascade	B-Method
regression	I-Method
successively	O
resamples	O
an	O
example	O
distribution	O
(	O
x	O
′	O
i	O
,	O
b	O
′	O
i	O
)	O
of	O
higher	O
IoU.	O
	
In	O
this	O
manner	O
,	O
it	O
is	O
possible	O
to	O
keep	O
the	O
set	O
of	O
positive	O
examples	O
of	O
the	O
successive	O
stages	O
at	O
a	O
roughly	O
constant	O
size	O
,	O
even	O
when	O
the	O
detector	B-Metric
quality	I-Metric
(	O
IoU	B-Metric
threshold	O
)	O
is	O
increased	O
.	O
	
This	O
is	O
illustrated	O
in	O
Figure	O
4	O
,	O
where	O
the	O
distribution	O
tilts	O
more	O
heavily	O
towards	O
high	O
quality	O
examples	O
after	O
each	O
resampling	O
step	O
.	O
	
Two	O
consequences	O
ensue	O
.	O
	
First	O
,	O
there	O
is	O
no	O
overfitting	O
,	O
since	O
examples	O
are	O
plentiful	O
at	O
all	O
levels	O
.	O
	
Second	O
,	O
the	O
detectors	O
of	O
the	O
deeper	O
stages	O
are	O
optimized	O
for	O
higher	O
IoU	B-Metric
thresholds	O
.	O
	
Note	O
that	O
,	O
some	O
outliers	O
are	O
sequentially	O
removed	O
by	O
increasing	O
IoU	B-Metric
thresholds	O
,	O
as	O
illustrated	O
in	O
Figure	O
2	O
,	O
enabling	O
a	O
better	O
trained	O
sequence	O
of	O
specialized	B-Method
detectors	I-Method
.	O
	
At	O
each	O
stage	O
t	O
,	O
the	O
R	B-Method
-	I-Method
CNN	I-Method
includes	O
a	O
classifier	B-Method
h	I-Method
t	I-Method
and	O
a	O
regressor	B-Method
f	I-Method
t	I-Method
optimized	O
for	O
IoU	B-Metric
threshold	O
u	O
t	O
,	O
where	O
u	O
t	O
	
>	O
u	O
t−1	O
.	O
	
This	O
is	O
guaranteed	O
by	O
minimizing	O
the	O
loss	O
	
,	O
g	O
is	O
the	O
ground	O
truth	O
object	O
for	O
x	O
t	O
,	O
λ	O
=	O
1	O
	
the	O
trade	O
-	O
off	O
coefficient	O
,	O
[	O
·	O
]	O
the	O
indicator	O
function	O
,	O
and	O
y	O
t	O
is	O
the	O
label	O
of	O
x	O
t	O
given	O
u	O
t	O
by	O
[	O
reference	O
]	O
.	O
Unlike	O
the	O
integral	O
loss	O
of	O
(	O
6	O
)	O
	
,	O
this	O
guarantees	O
a	O
sequence	O
of	O
effectively	O
trained	O
detectors	B-Method
of	O
increasing	O
quality	O
.	O
	
At	O
inference	B-Task
,	O
the	O
quality	O
of	O
the	O
hypotheses	O
is	O
sequentially	O
improved	O
,	O
by	O
applications	O
of	O
the	O
same	O
cascade	B-Method
procedure	I-Method
,	O
and	O
higher	O
quality	B-Method
detectors	I-Method
are	O
only	O
required	O
to	O
operate	O
on	O
higher	O
quality	O
hypotheses	O
.	O
	
This	O
enables	O
high	O
quality	O
object	B-Task
detection	I-Task
,	O
as	O
suggested	O
by	O
Figure	O
1	O
(	O
c	O
)	O
and	O
(	O
d	O
)	O
.	O
	
section	O
:	O
Experimental	O
Results	O
	
The	O
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
was	O
evaluated	O
on	O
MS	B-Material
-	I-Material
COCO	I-Material
2017	I-Material
	
[	O
reference	O
]	O
,	O
which	O
contains	O
∼118k	O
images	O
for	O
training	O
,	O
5k	O
for	O
validation	B-Metric
(	O
val	O
)	O
and	O
∼20k	O
for	O
testing	O
without	O
provided	O
annotations	O
(	O
test	O
-	O
dev	O
)	O
.	O
	
The	O
COCO	B-Metric
-	I-Metric
style	I-Metric
Average	I-Metric
Precision	I-Metric
(	O
AP	B-Metric
)	O
averages	O
AP	B-Metric
across	O
IoU	B-Metric
thresholds	O
from	O
0.5	O
to	O
0.95	O
with	O
an	O
interval	O
of	O
0.05	O
.	O
	
These	O
evaluation	B-Metric
metrics	I-Metric
measure	O
the	O
detection	B-Metric
performance	I-Metric
of	O
various	O
qualities	O
.	O
	
All	O
models	O
were	O
trained	O
on	O
COCO	B-Material
training	I-Material
set	I-Material
,	O
and	O
evaluated	O
on	O
val	O
set	O
.	O
	
Final	O
results	O
were	O
also	O
reported	O
on	O
test	O
-	O
dev	O
set	O
.	O
	
section	O
:	O
Implementation	O
Details	O
	
All	O
regressors	B-Method
are	O
class	O
agnostic	O
for	O
simplicity	O
.	O
	
All	O
cascade	O
detection	B-Task
stages	O
in	O
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
have	O
the	O
same	O
architecture	O
,	O
which	O
is	O
the	O
head	O
of	O
the	O
baseline	O
detection	B-Task
network	O
.	O
	
In	O
total	O
,	O
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
have	O
four	O
stages	O
,	O
one	O
RPN	B-Method
and	O
three	O
for	O
detection	B-Task
with	O
U	O
=	O
{	O
0.5	O
,	O
0.6	O
,	O
0.7	O
}	O
,	O
unless	O
otherwise	O
noted	O
.	O
	
The	O
sampling	O
of	O
the	O
first	O
detection	B-Task
stage	O
follows	O
	
[	O
reference	O
][	O
reference	O
]	O
.	O
	
In	O
the	O
following	O
stages	O
,	O
resampling	B-Task
is	O
implemented	O
by	O
simply	O
using	O
the	O
regressed	O
outputs	O
from	O
the	O
previous	O
stage	O
,	O
as	O
in	O
Section	O
4.2	O
.	O
	
No	O
data	B-Method
augmentation	I-Method
was	O
used	O
except	O
standard	O
horizontal	O
image	O
flipping	O
.	O
	
Inference	B-Task
was	O
performed	O
on	O
a	O
single	O
image	O
scale	O
,	O
with	O
no	O
further	O
bells	O
and	O
whistles	O
.	O
	
All	O
baseline	O
detectors	O
were	O
reimplemented	O
with	O
Caffe	B-Method
[	O
reference	O
]	O
,	O
on	O
the	O
same	O
codebase	O
for	O
fair	O
comparison	O
.	O
	
section	O
:	O
Baseline	O
Networks	O
	
To	O
test	O
the	O
versatility	O
of	O
the	O
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
,	O
experiments	O
were	O
performed	O
with	O
three	O
popular	O
baseline	B-Method
detectors	I-Method
:	O
Faster	O
-	O
RCNN	B-Method
with	O
backbone	B-Method
VGG	I-Method
-	I-Method
Net	I-Method
[	O
reference	O
]	O
,	O
R	B-Method
-	I-Method
FCN	I-Method
[	O
reference	O
]	O
and	O
	
FPN	B-Method
[	O
reference	O
]	O
with	O
ResNet	B-Method
backbone	I-Method
	
[	O
reference	O
]	O
.	O
	
These	O
baselines	O
have	O
a	O
wide	O
range	O
of	O
detection	B-Task
performances	O
.	O
	
Unless	O
noted	O
,	O
their	O
default	O
settings	O
were	O
used	O
.	O
	
End	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
training	I-Method
was	O
used	O
instead	O
of	O
multi	B-Method
-	I-Method
step	I-Method
training	I-Method
.	O
	
section	O
:	O
Faster	O
-	O
RCNN	B-Method
:	O
	
The	O
network	B-Method
head	I-Method
has	O
two	O
fully	O
connected	O
layers	O
.	O
	
To	O
reduce	O
parameters	O
,	O
we	O
used	O
[	O
reference	O
]	O
to	O
prune	O
less	O
important	O
connections	O
.	O
	
2048	O
units	O
were	O
retained	O
per	O
fully	O
connected	O
layer	O
and	O
dropout	O
layers	O
were	O
removed	O
.	O
	
Training	B-Task
started	O
with	O
a	O
learning	B-Metric
rate	I-Metric
of	O
0.002	O
,	O
reduced	O
by	O
a	O
factor	O
of	O
10	O
at	O
60k	O
and	O
90k	O
iterations	O
,	O
and	O
stopped	O
at	O
100k	O
iterations	O
,	O
on	O
2	O
synchronized	O
GPUs	B-Method
,	O
each	O
holding	O
4	O
images	O
per	O
iteration	O
.	O
	
128	O
RoIs	O
were	O
used	O
per	O
image	O
.	O
	
section	O
:	O
R	B-Method
-	I-Method
FCN	I-Method
:	O
	
R	B-Method
-	I-Method
FCN	I-Method
adds	O
a	O
convolutional	B-Method
,	O
a	O
bounding	B-Method
box	I-Method
regression	O
,	O
and	O
a	O
classification	B-Method
layer	I-Method
to	O
the	O
ResNet	B-Method
.	O
	
All	O
heads	O
of	O
the	O
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
have	O
this	O
structure	O
.	O
	
Online	B-Task
hard	I-Task
negative	I-Task
mining	I-Task
[	O
reference	O
]	O
was	O
not	O
used	O
.	O
	
Training	B-Task
started	O
with	O
a	O
learning	B-Metric
rate	I-Metric
of	I-Metric
0.003	I-Metric
,	O
which	O
was	O
decreased	O
by	O
a	O
factor	O
of	O
10	O
at	O
160k	O
and	O
240k	O
iterations	O
,	O
and	O
stopped	O
at	O
280k	O
iterations	O
,	O
on	O
4	O
synchronized	O
GPUs	O
,	O
each	O
holding	O
one	O
image	O
per	O
iteration	O
.	O
	
256	O
RoIs	O
were	O
used	O
per	O
image	O
.	O
	
section	O
:	O
FPN	B-Method
:	O
	
Since	O
no	O
source	O
code	O
is	O
publicly	O
available	O
yet	O
for	O
FPN	B-Method
,	O
our	O
implementation	O
details	O
could	O
be	O
different	O
.	O
	
RoIAlign	B-Method
[	O
reference	O
]	O
was	O
used	O
for	O
a	O
stronger	O
baseline	O
.	O
	
This	O
is	O
denoted	O
as	O
FPN	B-Method
+	I-Method
and	O
was	O
used	O
in	O
all	O
ablation	B-Task
studies	I-Task
.	O
	
As	O
usual	O
,	O
ResNet	B-Method
-	I-Method
50	I-Method
was	O
used	O
for	O
ablation	B-Task
studies	I-Task
,	O
and	O
ResNet	B-Method
-	I-Method
101	I-Method
for	O
final	B-Task
detection	I-Task
.	O
	
Training	B-Method
used	O
a	O
learning	B-Metric
rate	I-Metric
of	O
0.005	O
for	O
120k	O
iterations	O
and	O
0.0005	O
for	O
the	O
next	O
60k	O
iterations	O
,	O
on	O
8	O
synchronized	O
GPUs	O
,	O
each	O
holding	O
one	O
image	O
per	O
iteration	O
.	O
	
256	O
RoIs	O
were	O
used	O
per	O
image	O
.	O
	
{	O
0.5	O
,	O
0.6	O
,	O
0.7}.	O
	
The	O
detector	O
of	O
u	O
=	O
0.5	O
outperforms	O
the	O
detector	O
of	O
u	O
=	O
0.6	O
at	O
low	O
IoU	B-Metric
levels	O
,	O
but	O
underperforms	O
it	O
at	O
higher	O
levels	O
.	O
	
However	O
,	O
the	O
detector	O
of	O
u	O
=	O
0.7	O
underperforms	O
the	O
other	O
two	O
.	O
	
To	O
understand	O
why	O
this	O
happens	O
,	O
we	O
changed	O
the	O
quality	O
of	O
the	O
proposals	O
at	O
inference	B-Task
.	O
	
Figure	O
5	O
(	O
b	O
)	O
shows	O
the	O
results	O
obtained	O
when	O
ground	O
truth	O
bounding	O
boxes	O
were	O
added	O
to	O
the	O
set	O
of	O
proposals	O
.	O
	
While	O
all	O
detectors	O
improve	O
,	O
the	O
detector	O
of	O
u	O
=	O
0.7	O
has	O
the	O
largest	O
gains	O
,	O
achieving	O
the	O
best	O
performance	O
at	O
almost	O
all	O
IoU	B-Metric
levels	O
.	O
	
These	O
results	O
suggest	O
two	O
conclusions	O
.	O
	
First	O
,	O
u	O
=	O
0.5	O
is	O
not	O
a	O
good	O
choice	O
for	O
precise	B-Task
detection	I-Task
,	O
simply	O
more	O
robust	O
to	O
low	O
quality	O
proposals	O
.	O
	
Second	O
,	O
highly	O
precise	O
detection	B-Task
requires	O
hypotheses	O
that	O
match	O
the	O
detector	B-Metric
quality	I-Metric
.	O
	
Next	O
,	O
the	O
original	O
detector	O
proposals	O
were	O
replaced	O
by	O
the	O
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
proposals	O
of	O
higher	O
quality	O
(	O
u	O
=	O
0.6	O
and	O
u	O
=	O
0.7	O
used	O
the	O
2nd	O
and	O
3rd	O
stage	O
proposals	O
,	O
respectively	O
)	O
.	O
	
Figure	O
5	O
(	O
a	O
)	O
also	O
suggests	O
that	O
the	O
performance	O
of	O
the	O
two	O
detectors	O
is	O
significantly	O
improved	O
when	O
the	O
testing	O
proposals	O
closer	O
match	O
the	O
detector	B-Metric
quality	I-Metric
.	O
	
section	O
:	O
Quality	B-Metric
Mismatch	I-Metric
	
Testing	O
all	O
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
detectors	O
at	O
all	O
cascade	B-Method
stages	I-Method
produced	O
similar	O
observations	O
.	O
	
Figure	O
6	O
shows	O
that	O
each	O
detector	O
was	O
improved	O
when	O
used	O
more	O
precise	O
hypotheses	O
,	O
while	O
higher	O
quality	O
detector	O
had	O
larger	O
gain	O
.	O
	
For	O
example	O
,	O
the	O
detector	B-Method
of	O
u	O
=	O
0.7	O
performed	O
poorly	O
for	O
the	O
low	O
quality	O
proposals	O
of	O
the	O
1st	O
stage	O
,	O
but	O
much	O
better	O
for	O
the	O
more	O
precise	O
hypotheses	O
available	O
at	O
the	O
deeper	O
cascade	B-Method
stages	I-Method
.	O
	
In	O
addition	O
,	O
the	O
jointly	O
trained	O
detectors	B-Method
of	O
Figure	O
6	O
outperformed	O
the	O
individually	O
trained	O
detectors	B-Method
of	O
Figure	O
5	O
(	O
a	O
)	O
,	O
even	O
when	O
the	O
same	O
proposals	O
were	O
used	O
.	O
	
This	O
indicates	O
that	O
the	O
detectors	B-Method
are	O
better	O
trained	O
within	O
the	O
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
framework	O
.	O
	
section	O
:	O
Comparison	O
with	O
Iterative	B-Method
BBox	I-Method
and	O
Integral	B-Method
Loss	I-Method
	
In	O
this	O
section	O
,	O
we	O
compare	O
the	O
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
to	O
iterative	B-Method
BBox	I-Method
and	O
the	O
integral	B-Method
loss	I-Method
detector	I-Method
.	O
	
Iterative	B-Method
BBox	I-Method
was	O
implemented	O
by	O
applying	O
the	O
FPN	B-Method
+	I-Method
baseline	I-Method
iteratively	O
,	O
three	O
times	O
.	O
	
The	O
integral	B-Method
loss	I-Method
detector	I-Method
has	O
the	O
same	O
number	O
of	O
classification	O
heads	O
as	O
the	O
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
,	O
with	O
U	O
=	O
{	O
0.5	O
,	O
0.6	O
,	O
0.7}.	O
Localization	B-Task
:	O
	
The	O
localization	B-Metric
performances	O
of	O
cascade	B-Method
regression	I-Method
and	O
iterative	B-Method
BBox	I-Method
are	O
compared	O
in	O
Figure	O
7	O
(	O
a	O
)	O
.	O
	
The	O
use	O
of	O
a	O
single	O
regressor	B-Method
degrades	O
localization	B-Metric
for	O
hypotheses	B-Task
of	I-Task
high	I-Task
IoU.	I-Task
	
This	O
effect	O
accumulates	O
when	O
the	O
regressor	B-Method
is	O
applied	O
iteratively	O
,	O
as	O
in	O
iterative	B-Method
BBox	I-Method
,	O
and	O
performance	O
actually	O
drops	O
.	O
	
Note	O
the	O
very	O
poor	O
performance	O
of	O
iterative	B-Method
BBox	I-Method
after	O
3	O
iterations	O
.	O
	
On	O
the	O
contrary	O
,	O
the	O
cascade	B-Method
regressor	I-Method
has	O
better	O
performance	O
at	O
later	O
stages	O
,	O
outperforming	O
iterative	B-Method
BBox	I-Method
at	O
almost	O
all	O
IoU	B-Metric
levels	O
.	O
	
Integral	O
Loss	O
:	O
	
The	O
detection	B-Task
performances	O
of	O
all	O
classifiers	B-Method
in	O
the	O
integral	B-Method
loss	I-Method
detector	I-Method
,	O
sharing	O
a	O
single	O
regressor	B-Method
,	O
are	O
shown	O
in	O
Figure	O
7	O
(	O
b	O
)	O
.	O
	
The	O
classifier	B-Method
of	O
u	O
=	O
0.6	O
is	O
the	O
best	O
at	O
all	O
IoU	B-Metric
levels	O
,	O
while	O
the	O
classifier	B-Method
of	O
u	O
=	O
0.7	O
is	O
the	O
worst	O
.	O
	
The	O
ensemble	O
of	O
all	O
classifiers	B-Method
shows	O
no	O
visible	O
gain	O
.	O
	
Table	O
1	O
shows	O
,	O
both	O
iterative	B-Method
BBox	I-Method
and	O
integral	B-Method
loss	I-Method
detector	I-Method
improve	O
the	O
baseline	B-Method
detector	I-Method
marginally	O
.	O
	
The	O
cascade	O
R	B-Method
-	I-Method
CNN	I-Method
has	O
the	O
best	O
performance	O
for	O
all	O
evaluation	B-Metric
metrics	I-Metric
.	O
	
The	O
gains	O
are	O
mild	O
for	O
low	O
IoU	B-Metric
thresholds	O
but	O
significant	O
for	O
the	O
higher	O
ones	O
.	O
	
section	O
:	O
Ablation	B-Task
Experiments	O
	
Ablation	B-Task
experiments	O
were	O
also	O
performed	O
.	O
	
Table	O
2	O
summarizes	O
stage	O
performance	O
.	O
	
The	O
1st	O
stage	O
already	O
outperforms	O
the	O
baseline	B-Method
detector	I-Method
,	O
due	O
to	O
the	O
benefits	O
of	O
multi	B-Task
-	I-Task
stage	I-Task
multi	I-Task
-	I-Task
task	I-Task
learning	I-Task
.	O
	
The	O
2nd	O
stage	O
improves	O
performance	O
substantially	O
,	O
and	O
the	O
3rd	O
is	O
equivalent	O
to	O
the	O
2nd	O
.	O
	
This	O
differs	O
from	O
the	O
integral	B-Method
loss	I-Method
detector	I-Method
,	O
where	O
the	O
higher	O
IOU	B-Method
classifier	I-Method
is	O
relatively	O
weak	O
.	O
	
While	O
the	O
former	O
(	O
later	O
)	O
stage	O
is	O
better	O
at	O
low	O
(	O
high	O
)	O
IoU	B-Metric
metrics	O
,	O
the	O
ensemble	O
of	O
all	O
classifiers	B-Method
is	O
the	O
best	O
overall	O
.	O
	
section	O
:	O
Stage	B-Metric
-	I-Metric
wise	I-Metric
Comparison	I-Metric
:	O
	
IoU	B-Metric
	
Thresholds	O
:	O
	
A	O
preliminary	O
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
was	O
trained	O
using	O
the	O
same	O
IoU	B-Metric
threshold	O
u	O
=	O
0.5	O
for	O
all	O
heads	O
.	O
	
In	O
this	O
case	O
,	O
the	O
stages	O
differ	O
only	O
in	O
the	O
hypotheses	O
they	O
Table	O
4	O
.	O
	
The	O
impact	O
of	O
the	O
number	O
of	O
stages	O
in	O
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
.	O
	
receive	O
.	O
	
Each	O
stage	O
is	O
trained	O
with	O
the	O
corresponding	O
hypotheses	O
,	O
i.e.	O
accounting	O
for	O
the	O
distributions	O
of	O
Figure	O
2	O
.	O
	
The	O
first	O
row	O
of	O
Table	O
3	O
shows	O
that	O
the	O
cascade	B-Method
improves	O
on	O
the	O
baseline	B-Method
detector	I-Method
.	O
	
This	O
suggests	O
the	O
importance	O
of	O
optimizing	O
stages	O
for	O
the	O
corresponding	O
sample	O
distributions	O
.	O
	
The	O
second	O
row	O
shows	O
that	O
,	O
by	O
increasing	O
the	O
stage	O
threshold	O
u	O
,	O
the	O
detector	O
can	O
be	O
made	O
more	O
selective	O
against	O
close	O
false	O
positives	O
and	O
specialized	O
for	O
more	O
precise	O
hypotheses	O
,	O
leading	O
to	O
additional	O
gains	O
.	O
	
This	O
supports	O
the	O
conclusions	O
of	O
Section	O
4.2	O
.	O
	
Regression	B-Task
Statistics	I-Task
:	O
	
Exploiting	O
the	O
progressively	O
updated	O
regression	O
statistics	O
,	O
of	O
Figure	O
2	O
,	O
helps	O
the	O
effective	O
multi	B-Task
-	I-Task
task	I-Task
learning	I-Task
of	I-Task
classification	I-Task
and	I-Task
regression	I-Task
.	O
	
Its	O
benefit	O
is	O
noted	O
by	O
comparing	O
the	O
models	O
with	O
/	O
without	O
it	O
in	O
Table	O
3	O
.	O
	
The	O
learning	B-Method
is	O
not	O
sensitive	O
to	O
these	O
statistics	O
.	O
	
section	O
:	O
Number	O
of	O
Stages	O
:	O
	
The	O
impact	O
of	O
the	O
number	O
of	O
stages	O
is	O
summarized	O
in	O
Table	O
4	O
.	O
	
Adding	O
a	O
second	O
detection	B-Task
stage	O
significantly	O
improves	O
the	O
baseline	O
detector	O
.	O
	
Three	O
detection	B-Task
stages	O
still	O
produce	O
non	O
-	O
trivial	O
improvement	O
,	O
but	O
the	O
addition	O
of	O
a	O
4th	O
stage	O
(	O
u	O
=	O
0.75	O
)	O
led	O
to	O
a	O
slight	O
performance	O
decrease	O
.	O
	
Note	O
,	O
however	O
,	O
that	O
while	O
the	O
overall	O
AP	B-Metric
performance	O
degrades	O
,	O
the	O
four	B-Method
-	I-Method
stage	I-Method
cascade	I-Method
has	O
the	O
best	O
performance	O
for	O
high	O
IoU	B-Metric
levels	O
.	O
	
The	O
three	O
-	O
stage	B-Method
cascade	I-Method
achieves	O
the	O
best	O
trade	O
-	O
off	O
.	O
	
section	O
:	O
Comparison	O
with	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
	
The	O
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
,	O
based	O
on	O
FPN	B-Method
+	I-Method
and	I-Method
ResNet	I-Method
-	I-Method
101	I-Method
backbone	I-Method
,	O
is	O
compared	O
to	O
state	B-Method
-	I-Method
of	I-Method
-	I-Method
the	I-Method
-	I-Method
art	I-Method
single	I-Method
-	I-Method
model	I-Method
object	I-Method
detectors	I-Method
in	O
Table	O
5	O
.	O
	
The	O
settings	O
are	O
as	O
described	O
in	O
Section	O
5.1.1	O
,	O
but	O
a	O
total	O
of	O
280k	O
training	O
iterations	O
were	O
run	O
and	O
the	O
learning	B-Metric
rate	I-Metric
dropped	O
at	O
160k	O
and	O
240k	O
iterations	O
.	O
	
The	O
number	O
of	O
RoIs	O
was	O
also	O
increased	O
to	O
512	O
.	O
	
The	O
first	O
group	O
of	O
detectors	O
on	O
Table	O
5	O
are	O
one	B-Method
-	I-Method
stage	I-Method
detectors	I-Method
,	O
the	O
second	O
group	O
two	O
-	O
stage	O
,	O
and	O
the	O
last	O
group	O
multi	O
-	O
stage	O
(	O
3	B-Method
-	I-Method
stages	I-Method
+	I-Method
RPN	I-Method
for	O
the	O
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
)	O
.	O
	
All	O
the	O
compared	O
state	B-Method
-	I-Method
of	I-Method
-	I-Method
the	I-Method
-	I-Method
art	I-Method
detectors	I-Method
were	O
trained	O
with	O
u	O
=	O
0	O
.	O
	
Table	O
6	O
.	O
	
Detailed	O
comparison	O
on	O
multiple	O
popular	O
baseline	B-Method
object	I-Method
detectors	I-Method
.	O
	
All	O
speeds	O
are	O
reported	O
per	O
image	O
on	O
a	O
single	O
Titan	B-Method
Xp	I-Method
GPU	I-Method
.	O
	
noted	O
that	O
our	O
FPN	B-Method
+	I-Method
implementation	I-Method
is	O
better	O
than	O
the	O
original	O
FPN	B-Method
[	O
reference	O
]	O
,	O
providing	O
a	O
very	O
strong	O
baseline	O
.	O
	
In	O
addition	O
,	O
the	O
extension	O
from	O
FPN	B-Method
+	I-Method
to	O
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
improved	O
performance	O
by	O
∼4	O
points	O
.	O
	
The	O
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
also	O
outperformed	O
all	O
single	B-Method
-	I-Method
model	I-Method
detectors	I-Method
by	O
a	O
large	O
margin	O
,	O
under	O
all	O
evaluation	B-Metric
metrics	I-Metric
.	O
	
This	O
includes	O
the	O
single	O
-	O
model	O
entries	O
of	O
the	O
COCO	B-Material
challenge	O
winners	O
in	O
2015	O
and	O
2016	O
(	O
Faster	O
R	B-Method
-	I-Method
CNN	I-Method
+++	I-Method
[	O
reference	O
]	O
,	O
and	O
G	B-Method
-	I-Method
RMI	I-Method
[	O
reference	O
]	O
)	O
,	O
and	O
the	O
very	O
recent	O
Deformable	B-Method
R	I-Method
-	I-Method
FCN	I-Method
[	O
reference	O
]	O
,	O
RetinaNet	B-Method
[	O
reference	O
]	O
and	O
Mask	O
R	B-Method
-	I-Method
CNN	I-Method
	
[	O
reference	O
]	O
.	O
The	O
best	O
multi	B-Method
-	I-Method
stage	I-Method
detector	I-Method
on	O
COCO	B-Material
,	O
AttractioNet	O
[	O
reference	O
]	O
,	O
used	O
iterative	B-Method
BBox	I-Method
for	O
proposal	B-Task
generation	I-Task
.	O
	
Although	O
many	O
enhancements	O
were	O
used	O
in	O
AttractioNet	B-Task
,	O
the	O
vanilla	O
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
still	O
outperforms	O
it	O
by	O
7.1	O
points	O
.	O
	
Note	O
that	O
,	O
unlike	O
Mask	O
R	B-Method
-	I-Method
CNN	I-Method
,	O
no	O
segmentation	O
information	O
is	O
exploited	O
in	O
the	O
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
.	O
	
Finally	O
,	O
the	O
vanilla	O
single	O
-	O
model	O
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
also	O
surpasses	O
the	O
heavily	O
engineered	O
ensemble	B-Method
detectors	I-Method
that	O
won	O
the	O
COCO	B-Material
challenge	I-Material
in	O
2015	O
and	O
2016	O
(	O
AP	B-Metric
37.4	O
and	O
41.6	O
,	O
respectively	O
)	O
	
1	O
.	O
	
section	O
:	O
Generalization	B-Method
Capacity	I-Method
	
Three	O
-	O
stage	O
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
of	O
all	O
three	O
baseline	B-Method
detectors	I-Method
are	O
compared	O
in	O
Table	O
6	O
.	O
	
All	O
settings	O
are	O
as	O
above	O
,	O
with	O
the	O
changes	O
of	O
Section	O
5.5	O
for	O
FPN	B-Method
+	I-Method
.	O
	
[	O
reference	O
]	O
http:	O
//	O
cocodataset.org	O
/	O
#detections	O
-	O
leaderboard	O
	
Detection	B-Metric
Performance	I-Metric
:	O
Again	O
,	O
our	O
implementations	O
are	O
better	O
than	O
the	O
original	O
detectors	O
	
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
Still	O
,	O
the	O
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
improves	O
on	O
these	O
baselines	O
consistently	O
by	O
2∼4	O
points	O
,	O
independently	O
of	O
their	O
strength	O
.	O
	
These	O
gains	O
are	O
also	O
consistent	O
on	O
val	O
and	O
test	O
-	O
dev	O
.	O
	
These	O
results	O
suggest	O
that	O
the	O
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
is	O
widely	O
applicable	O
across	O
detector	B-Method
architectures	I-Method
.	O
	
Parameter	O
and	O
Timing	O
:	O
The	O
number	O
of	O
the	O
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
parameters	O
increases	O
with	O
the	O
number	O
of	O
cascade	O
stages	O
.	O
	
The	O
increase	O
is	O
linear	O
in	O
the	O
parameter	O
number	O
of	O
the	O
baseline	O
detector	O
heads	O
.	O
	
In	O
addition	O
,	O
because	O
the	O
computational	B-Metric
cost	I-Metric
of	O
a	O
detection	B-Task
head	I-Task
is	O
usually	O
small	O
when	O
compared	O
to	O
the	O
RPN	B-Method
,	O
the	O
computational	B-Metric
overhead	I-Metric
of	O
the	O
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
is	O
small	O
,	O
at	O
both	O
training	O
and	O
testing	B-Task
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
paper	O
,	O
we	O
proposed	O
a	O
multi	O
-	O
stage	O
object	B-Task
detection	I-Task
framework	O
,	O
the	O
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
,	O
for	O
the	O
design	O
of	O
high	B-Task
quality	I-Task
object	I-Task
detectors	I-Task
.	O
	
This	O
architecture	O
was	O
shown	O
to	O
avoid	O
the	O
problems	O
of	O
overfitting	O
at	O
training	B-Task
and	O
quality	B-Metric
mismatch	I-Metric
at	O
inference	B-Task
.	O
	
The	O
solid	O
and	O
consistent	O
detection	B-Task
improvements	O
of	O
the	O
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
on	O
the	O
challenging	O
COCO	B-Material
dataset	O
suggest	O
the	O
modeling	O
and	O
understanding	O
of	O
various	O
concurring	O
factors	O
are	O
required	O
to	O
advance	O
object	B-Task
detection	I-Task
.	O
	
The	O
Cascade	B-Method
R	I-Method
-	I-Method
CNN	I-Method
was	O
shown	O
to	O
be	O
applicable	O
to	O
many	O
object	B-Task
detection	I-Task
architectures	O
.	O
	
We	O
believe	O
that	O
it	O
can	O
be	O
useful	O
to	O
many	O
future	O
object	B-Task
detection	I-Task
research	O
efforts	O
.	O
	
section	O
:	O
	
section	O
:	O
	
Acknowledgment	O
We	O
would	O
like	O
to	O
thank	O
Kaiming	O
He	O
for	O
valuable	O
discussions	O
.	O
	
section	O
:	O
	
document	O
:	O
LiteFlowNet	B-Method
:	O
A	O
Lightweight	B-Method
Convolutional	I-Method
Neural	I-Method
Network	I-Method
for	O
Optical	B-Task
Flow	I-Task
Estimation	I-Task
	
FlowNet2	B-Method
,	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
convolutional	B-Method
neural	I-Method
network	I-Method
(	I-Method
CNN	I-Method
)	I-Method
for	O
optical	B-Task
flow	I-Task
estimation	O
,	O
requires	O
over	O
160	O
M	O
parameters	O
to	O
achieve	O
accurate	O
flow	B-Task
estimation	I-Task
.	O
	
In	O
this	O
paper	O
we	O
present	O
an	O
alternative	O
network	O
that	O
outperforms	O
FlowNet2	B-Method
on	O
the	O
challenging	O
Sintel	B-Material
final	I-Material
pass	I-Material
and	O
KITTI	O
benchmarks	O
,	O
while	O
being	O
30	O
times	O
smaller	O
in	O
the	O
model	B-Metric
size	I-Metric
and	O
1.36	O
times	O
faster	O
in	O
the	O
running	B-Metric
speed	I-Metric
.	O
	
This	O
is	O
made	O
possible	O
by	O
drilling	O
down	O
to	O
architectural	O
details	O
that	O
might	O
have	O
been	O
missed	O
in	O
the	O
current	O
frameworks	O
:	O
(	O
1	O
)	O
We	O
present	O
a	O
more	O
effective	O
flow	B-Method
inference	I-Method
approach	I-Method
at	O
each	O
pyramid	O
level	O
through	O
a	O
lightweight	B-Method
cascaded	I-Method
network	I-Method
.	O
	
It	O
not	O
only	O
improves	O
flow	B-Metric
estimation	I-Metric
accuracy	I-Metric
through	O
early	B-Task
correction	I-Task
,	O
but	O
also	O
permits	O
seamless	O
incorporation	O
of	O
descriptor	B-Task
matching	I-Task
in	O
our	O
network	O
.	O
	
(	O
2	O
)	O
	
We	O
present	O
a	O
novel	O
flow	B-Method
regularization	I-Method
layer	I-Method
to	O
ameliorate	O
the	O
issue	O
of	O
outliers	O
and	O
vague	O
flow	O
boundaries	O
by	O
using	O
a	O
feature	B-Method
-	I-Method
driven	I-Method
local	I-Method
convolution	I-Method
.	O
	
(	O
3	O
)	O
Our	O
network	O
owns	O
an	O
effective	O
structure	O
for	O
pyramidal	B-Task
feature	I-Task
extraction	I-Task
and	O
embraces	O
feature	B-Task
warping	I-Task
rather	O
than	O
image	B-Task
warping	I-Task
as	O
practiced	O
in	O
FlowNet2	B-Method
.	O
	
Our	O
code	O
and	O
trained	O
models	O
are	O
available	O
at	O
.	O
	
section	O
:	O
Introduction	O
	
Optical	B-Task
flow	I-Task
estimation	I-Task
is	O
a	O
long	O
-	O
standing	O
problem	O
in	O
computer	B-Task
vision	I-Task
.	O
	
Due	O
to	O
the	O
well	O
-	O
known	O
aperture	B-Task
problem	I-Task
,	O
optical	B-Task
flow	I-Task
is	O
not	O
directly	O
measurable	O
.	O
	
Hence	O
,	O
the	O
estimation	B-Task
is	O
typically	O
solved	O
by	O
energy	B-Method
minimization	I-Method
in	O
a	O
coarse	B-Method
-	I-Method
to	I-Method
-	I-Method
fine	I-Method
framework	I-Method
.	O
	
This	O
class	O
of	O
techniques	O
,	O
however	O
,	O
involves	O
complex	O
energy	B-Task
optimization	I-Task
and	O
thus	O
it	O
is	O
not	O
scalable	O
for	O
applications	O
that	O
demand	O
real	B-Task
-	I-Task
time	I-Task
estimation	I-Task
.	O
	
FlowNet	B-Method
and	O
its	O
successor	O
FlowNet2	B-Method
,	O
have	O
marked	O
a	O
milestone	O
by	O
using	O
CNN	B-Method
for	O
optical	B-Task
flow	I-Task
estimation	O
.	O
	
Their	O
accuracies	B-Metric
especially	O
the	O
successor	O
are	O
approaching	O
that	O
of	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
energy	B-Method
minimization	I-Method
approaches	I-Method
,	O
while	O
the	O
speed	O
is	O
several	O
orders	O
of	O
magnitude	O
faster	O
.	O
	
To	O
push	O
the	O
envelop	O
of	O
accuracy	B-Metric
,	O
FlowNet2	B-Method
is	O
designed	O
as	O
a	O
cascade	B-Method
of	I-Method
variants	I-Method
of	O
FlowNet	B-Method
that	O
each	O
network	O
in	O
the	O
cascade	O
refines	O
the	O
preceding	O
flow	O
field	O
by	O
contributing	O
on	O
the	O
flow	O
increment	O
between	O
the	O
first	O
image	O
and	O
the	O
warped	O
second	O
image	O
.	O
	
The	O
model	O
,	O
as	O
a	O
result	O
,	O
comprises	O
over	O
160	O
M	O
parameters	O
,	O
which	O
could	O
be	O
formidable	O
in	O
many	O
applications	O
.	O
	
A	O
recent	O
network	O
termed	O
SPyNet	B-Method
attempts	O
a	O
network	O
with	O
smaller	O
size	O
of	O
1.2	O
M	O
parameters	O
by	O
adopting	O
image	O
warping	O
in	O
each	O
pyramid	O
level	O
.	O
	
Nonetheless	O
,	O
the	O
accuracy	B-Metric
can	O
only	O
match	O
that	O
of	O
FlowNet	B-Method
but	O
not	O
FlowNet2	B-Method
.	O
	
The	O
objective	O
of	O
this	O
study	O
is	O
to	O
explore	O
alternative	O
CNN	B-Method
architectures	I-Method
for	O
accurate	B-Task
flow	I-Task
estimation	I-Task
yet	O
with	O
high	O
efficiency	O
.	O
	
Our	O
work	O
is	O
inspired	O
by	O
the	O
successes	O
of	O
FlowNet2	B-Method
and	O
SPyNet	B-Method
,	O
but	O
we	O
further	O
drill	O
down	O
the	O
key	O
elements	O
to	O
fully	O
unleash	O
the	O
potential	O
of	O
deep	B-Method
convolutional	I-Method
network	I-Method
combined	O
with	O
classical	B-Method
principles	I-Method
.	O
	
There	O
are	O
two	O
general	O
principles	O
to	O
improve	O
the	O
design	O
of	O
FlowNet2	B-Method
and	O
SPyNet	B-Method
.	O
	
The	O
first	O
principle	O
is	O
pyramidal	B-Task
feature	I-Task
extraction	I-Task
.	O
	
The	O
proposed	O
network	O
,	O
dubbed	O
LiteFlowNet	B-Method
,	O
consists	O
of	O
an	O
encoder	B-Method
and	O
a	O
decoder	B-Method
.	O
	
The	O
encoder	O
maps	O
the	O
given	O
image	O
pair	O
,	O
respectively	O
,	O
into	O
two	O
pyramids	O
of	O
multi	O
-	O
scale	O
high	O
-	O
dimensional	O
features	O
.	O
	
The	O
decoder	O
then	O
estimates	O
the	O
flow	B-Task
field	I-Task
in	O
a	O
coarse	B-Method
-	I-Method
to	I-Method
-	I-Method
fine	I-Method
framework	I-Method
.	O
	
At	O
each	O
pyramid	O
level	O
,	O
the	O
decoder	B-Method
infers	O
the	O
flow	O
field	O
by	O
selecting	O
and	O
using	O
the	O
features	O
of	O
the	O
same	O
resolution	O
from	O
the	O
feature	O
pyramids	O
.	O
	
This	O
design	O
leads	O
to	O
a	O
lighter	O
network	O
compared	O
to	O
FlowNet2	B-Method
that	O
adopts	O
U	B-Method
-	I-Method
Net	I-Method
architecture	I-Method
for	O
flow	B-Task
inference	I-Task
.	O
	
In	O
comparison	O
to	O
SPyNet	B-Method
,	O
our	O
network	O
separates	O
the	O
process	O
of	O
feature	B-Task
extraction	I-Task
and	O
flow	B-Task
estimation	I-Task
.	O
	
This	O
helps	O
us	O
to	O
better	O
pinpoint	O
the	O
bottleneck	O
of	O
accuracy	B-Metric
and	O
model	B-Metric
size	I-Metric
.	O
	
The	O
second	O
general	O
principle	O
is	O
feature	B-Method
warping	I-Method
.	O
	
FlowNet2	B-Method
and	O
SPyNet	B-Method
warp	O
the	O
second	O
image	O
towards	O
the	O
first	O
image	O
in	O
the	O
pair	O
using	O
the	O
previous	O
flow	B-Method
estimate	I-Method
,	O
and	O
then	O
refine	O
the	O
estimate	O
using	O
the	O
feature	O
maps	O
generated	O
by	O
the	O
warped	O
and	O
the	O
first	O
images	O
.	O
	
Warping	O
an	O
image	O
and	O
then	O
generating	O
the	O
feature	O
maps	O
of	O
the	O
warped	O
image	O
are	O
two	O
ordered	O
steps	O
.	O
	
We	O
find	O
that	O
the	O
two	O
steps	O
can	O
be	O
reduced	O
to	O
a	O
single	O
one	O
by	O
directly	O
warping	O
the	O
feature	O
maps	O
of	O
the	O
second	O
image	O
,	O
which	O
have	O
been	O
computed	O
by	O
the	O
encoder	B-Method
.	O
	
This	O
one	O
-	O
step	O
feature	B-Method
warping	I-Method
process	I-Method
reduces	O
the	O
more	O
discriminative	O
feature	O
-	O
space	O
distance	O
instead	O
of	O
the	O
RGB	O
-	O
space	O
distance	O
between	O
the	O
two	O
images	O
.	O
	
This	O
makes	O
our	O
network	O
more	O
powerful	O
and	O
efficient	O
in	O
addressing	O
the	O
flow	B-Task
problem	I-Task
.	O
	
We	O
now	O
highlight	O
the	O
more	O
specific	O
differences	O
between	O
our	O
network	O
and	O
existing	O
CNN	O
-	O
based	O
optical	B-Task
flow	I-Task
estimation	O
frameworks	O
:	O
1	O
)	O
Cascaded	B-Method
flow	I-Method
inference	I-Method
–	O
	
At	O
each	O
pyramid	O
level	O
,	O
we	O
introduce	O
a	O
novel	O
cascade	B-Method
of	I-Method
two	I-Method
lightweight	I-Method
networks	I-Method
.	O
	
Each	O
of	O
them	O
has	O
a	O
feature	B-Method
warping	I-Method
(	I-Method
f	I-Method
-	I-Method
warp	I-Method
)	I-Method
layer	I-Method
to	O
displace	O
the	O
feature	O
maps	O
of	O
the	O
second	O
image	O
towards	O
the	O
first	O
image	O
using	O
the	O
flow	B-Method
estimate	I-Method
from	O
the	O
previous	O
level	O
.	O
	
Flow	O
residue	O
is	O
computed	O
to	O
further	O
reduce	O
the	O
feature	O
-	O
space	O
distance	O
between	O
the	O
images	O
.	O
	
This	O
design	O
is	O
advantageous	O
to	O
the	O
conventional	O
design	O
of	O
using	O
a	O
single	B-Method
network	I-Method
for	O
flow	B-Task
inference	I-Task
.	O
	
First	O
,	O
the	O
cascade	B-Method
progressively	O
improves	O
flow	B-Metric
accuracy	I-Metric
thus	O
allowing	O
an	O
early	O
correction	O
of	O
the	O
estimate	O
without	O
passing	O
more	O
errors	O
to	O
the	O
next	O
level	O
.	O
	
Second	O
,	O
this	O
design	O
allows	O
seamless	O
integration	O
with	O
descriptor	B-Task
matching	I-Task
.	O
	
We	O
assign	O
a	O
matching	B-Method
network	I-Method
to	O
the	O
first	O
inference	B-Task
.	O
	
Consequently	O
,	O
pixel	O
-	O
accuracy	O
flow	O
field	O
can	O
be	O
generated	O
first	O
and	O
then	O
refined	O
to	O
sub	O
-	O
pixel	O
accuracy	O
in	O
the	O
subsequent	O
inference	B-Method
network	I-Method
.	O
	
Since	O
at	O
each	O
pyramid	O
level	O
the	O
feature	O
-	O
space	O
distance	O
between	O
the	O
images	O
has	O
been	O
reduced	O
by	O
feature	B-Method
warping	I-Method
,	O
we	O
can	O
use	O
a	O
rather	O
short	O
displacement	O
than	O
to	O
establish	O
the	O
cost	O
volume	O
.	O
	
Besides	O
,	O
matching	B-Task
is	O
performed	O
only	O
at	O
sampled	O
positions	O
and	O
thus	O
a	O
sparse	O
cost	O
-	O
volume	O
is	O
aggregated	O
.	O
	
This	O
effectively	O
reduces	O
the	O
computational	B-Metric
burden	I-Metric
raised	O
by	O
the	O
explicit	B-Method
matching	I-Method
.	O
	
2	O
	
)	O
Flow	B-Method
regularization	I-Method
	
–	O
	
The	O
cascaded	B-Method
flow	I-Method
inference	I-Method
resembles	O
the	O
role	O
of	O
data	O
fidelity	O
in	O
energy	B-Method
minimization	I-Method
methods	I-Method
.	O
	
Using	O
data	O
term	O
alone	O
,	O
vague	O
flow	O
boundaries	O
and	O
undesired	O
artifacts	O
exist	O
in	O
flow	O
fields	O
.	O
	
To	O
tackle	O
this	O
problem	O
,	O
local	O
flow	O
consistency	O
and	O
co	O
-	O
occurrence	O
between	O
flow	O
boundaries	O
and	O
intensity	O
edges	O
are	O
commonly	O
used	O
as	O
the	O
cues	O
to	O
regularize	O
flow	O
field	O
.	O
	
Some	O
of	O
the	O
representative	O
methods	O
include	O
anisotropic	B-Task
image	I-Task
-	I-Task
driven	I-Task
,	O
image	B-Task
-	I-Task
and	I-Task
flow	I-Task
-	I-Task
driven	I-Task
,	O
and	O
complementary	B-Method
regularizations	I-Method
.	O
	
After	O
cascaded	B-Method
flow	I-Method
inference	I-Method
,	O
we	O
allow	O
the	O
flow	O
field	O
to	O
be	O
further	O
regularized	O
by	O
our	O
novel	O
feature	B-Method
-	I-Method
driven	I-Method
local	I-Method
convolution	I-Method
(	I-Method
f	I-Method
-	I-Method
lconv	I-Method
)	I-Method
layer	I-Method
at	O
each	O
pyramid	O
level	O
.	O
	
The	O
kernels	O
of	O
such	O
a	O
local	B-Method
convolution	I-Method
are	O
adaptive	O
to	O
the	O
pyramidal	O
features	O
from	O
the	O
encoder	B-Method
,	O
flow	B-Method
estimate	I-Method
and	O
occlusion	O
probability	O
map	O
.	O
	
This	O
makes	O
the	O
flow	B-Method
regularization	I-Method
to	O
be	O
both	O
flow	O
-	O
	
and	O
image	B-Task
-	I-Task
aware	I-Task
.	O
	
To	O
our	O
best	O
knowledge	O
,	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
CNNs	B-Method
do	O
not	O
explore	O
such	O
a	O
flow	B-Method
regularization	I-Method
.	O
	
The	O
effectiveness	O
of	O
the	O
aforementioned	O
contributions	O
are	O
depicted	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
In	O
summary	O
,	O
we	O
propose	O
a	O
compact	O
LiteFlowNet	B-Method
to	O
estimate	O
optical	B-Task
flow	I-Task
.	O
	
Our	O
network	O
innovates	O
the	O
useful	O
elements	O
from	O
conventional	O
methods	O
.	O
	
,	O
brightness	O
constraint	O
in	O
data	O
fidelity	O
to	O
pyramidal	O
CNN	O
features	O
and	O
image	B-Task
warping	I-Task
to	O
CNN	B-Method
feature	I-Method
warping	I-Method
.	O
	
More	O
specifically	O
,	O
we	O
present	O
a	O
cascaded	B-Method
flow	I-Method
inference	I-Method
with	O
feature	B-Method
warping	I-Method
and	O
flow	B-Method
regularization	I-Method
in	O
each	O
pyramid	O
level	O
,	O
which	O
are	O
new	O
in	O
the	O
literature	O
.	O
	
Overall	O
,	O
our	O
network	O
outperforms	O
FlowNet	B-Method
and	O
SPyNet	B-Method
and	O
is	O
on	O
par	O
with	O
or	O
outperforms	O
the	O
recent	O
FlowNet2	B-Method
on	O
public	O
benchmarks	O
,	O
while	O
having	O
30	O
times	O
fewer	O
parameters	O
and	O
being	O
1.36	O
times	O
faster	O
than	O
FlowNet2	B-Method
.	O
	
section	O
:	O
Related	O
Work	O
	
Here	O
,	O
we	O
briefly	O
review	O
some	O
of	O
the	O
major	O
approaches	O
for	O
optical	B-Task
flow	I-Task
estimation	O
.	O
	
Variational	B-Method
methods	I-Method
.	O
	
Since	O
the	O
pioneering	O
work	O
by	O
Horn	O
and	O
Schunck	O
,	O
variational	B-Method
methods	I-Method
have	O
dominated	O
optical	B-Task
flow	I-Task
estimation	O
.	O
	
Brox	O
address	O
illumination	O
changes	O
by	O
combining	O
the	O
brightness	O
and	O
gradient	O
constancy	O
assumptions	O
.	O
	
Brox	O
integrate	O
rich	O
descriptors	O
into	O
variational	B-Method
formulation	I-Method
.	O
	
In	O
DeepFlow	B-Method
,	O
Weinzaepfel	O
propose	O
to	O
correlate	O
multi	O
-	O
scale	O
patches	O
and	O
incorporate	O
this	O
as	O
the	O
matching	O
term	O
in	O
functional	O
.	O
	
In	O
PatchMatch	B-Method
Filter	I-Method
,	O
Lu	O
establish	O
dense	B-Task
correspondence	I-Task
using	O
the	O
superpixel	B-Method
-	I-Method
based	I-Method
PatchMatch	I-Method
.	O
	
Revaud	B-Method
propose	O
a	O
method	O
EpicFlow	B-Method
that	O
uses	O
externally	O
matched	O
flows	O
as	O
initialization	O
and	O
then	O
performs	O
interpolation	B-Method
.	O
	
Zimmer	O
design	O
the	O
complementary	B-Method
regularization	I-Method
that	O
exploits	O
directional	O
information	O
from	O
the	O
constraints	O
imposed	O
in	O
data	O
term	O
.	O
	
Our	O
network	O
that	O
infers	O
optical	B-Task
flow	I-Task
and	O
performs	O
flow	B-Method
regularization	I-Method
is	O
inspired	O
by	O
the	O
use	O
of	O
data	B-Method
fidelity	I-Method
and	O
regularization	B-Method
in	O
variational	B-Method
methods	I-Method
.	O
	
Machine	B-Method
learning	I-Method
methods	I-Method
.	O
	
Black	O
propose	O
to	O
represent	O
complex	O
image	O
motion	O
as	O
a	O
linear	B-Method
combination	I-Method
of	O
the	O
learned	O
basis	O
vectors	O
.	O
	
Roth	O
formulates	O
the	O
prior	O
probability	O
of	O
flow	O
field	O
as	O
Field	B-Method
-	I-Method
of	I-Method
-	I-Method
Experts	I-Method
model	I-Method
that	O
captures	O
higher	O
order	O
spatial	O
statistics	O
.	O
	
Sun	O
study	O
the	O
probabilistic	B-Method
model	I-Method
of	O
brightness	B-Task
inconstancy	I-Task
in	O
a	O
high	B-Method
-	I-Method
order	I-Method
random	I-Method
field	I-Method
framework	I-Method
.	O
	
Nir	O
represent	O
image	O
motion	O
using	O
the	O
over	B-Method
-	I-Method
parameterization	I-Method
model	I-Method
.	O
	
Rosenbaum	B-Method
model	I-Method
the	O
local	O
statistics	O
of	O
optical	B-Task
flow	I-Task
using	O
Gaussian	B-Method
mixtures	I-Method
.	O
	
Given	O
a	O
set	O
of	O
sparse	O
matches	O
,	O
Wulff	O
propose	O
to	O
regress	O
them	O
to	O
a	O
dense	O
flow	O
field	O
using	O
a	O
set	O
of	O
basis	B-Method
flow	I-Method
fields	I-Method
(	O
PCA	B-Method
-	I-Method
Flow	I-Method
)	O
.	O
	
It	O
can	O
be	O
shown	O
that	O
the	O
parameterized	B-Method
model	I-Method
can	O
be	O
efficiently	O
implemented	O
using	O
CNN	B-Method
.	O
	
CNN	B-Method
-	I-Method
based	I-Method
methods	I-Method
.	O
	
In	O
the	O
work	O
of	O
Fischer	O
termed	O
FlowNet	B-Method
,	O
a	O
post	B-Method
-	I-Method
processing	I-Method
step	I-Method
that	O
involves	O
energy	B-Method
minimization	I-Method
is	O
required	O
to	O
reduce	O
smoothing	O
effect	O
across	O
flow	O
boundaries	O
.	O
	
This	O
process	O
is	O
not	O
end	O
-	O
to	O
-	O
end	O
trainable	O
.	O
	
In	O
our	O
work	O
,	O
we	O
present	O
an	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
approach	I-Method
that	O
performs	O
in	B-Task
-	I-Task
network	I-Task
flow	I-Task
regularization	I-Task
using	O
the	O
proposed	O
f	B-Method
-	I-Method
lconv	I-Method
layer	I-Method
,	O
which	O
plays	O
similar	O
role	O
as	O
the	O
regularization	O
term	O
in	O
variational	B-Method
methods	I-Method
.	O
	
In	O
FlowNet2	B-Method
,	O
Ilg	B-Method
introduce	O
a	O
huge	O
network	B-Method
cascade	I-Method
(	O
over	O
160	O
M	O
parameters	O
)	O
that	O
consists	O
of	O
variants	O
of	O
FlowNet	B-Method
.	O
	
The	O
cascade	B-Method
improves	O
flow	B-Metric
accuracy	I-Metric
with	O
an	O
expense	O
of	O
model	B-Metric
size	I-Metric
and	O
computational	B-Metric
complexity	I-Metric
.	O
	
Our	O
model	O
uses	O
a	O
more	O
efficient	O
architecture	O
containing	O
30	O
times	O
fewer	O
parameters	O
than	O
FlowNet2	B-Method
while	O
the	O
performance	O
is	O
on	O
par	O
with	O
it	O
.	O
	
A	O
compact	B-Method
network	I-Method
termed	O
SPyNet	B-Method
from	O
Ranjan	B-Method
is	O
inspired	O
from	O
spatial	O
pyramid	O
.	O
	
Nevertheless	O
,	O
the	O
accuracy	B-Metric
is	O
far	O
below	O
FlowNet2	B-Method
.	O
	
A	O
small	O
-	O
sized	O
variant	O
of	O
our	O
network	O
outperforms	O
SPyNet	B-Method
while	O
being	O
1.33	O
times	O
smaller	O
in	O
the	O
model	B-Metric
size	I-Metric
.	O
	
Zweig	B-Method
present	O
a	O
network	O
to	O
interpolate	O
third	O
-	O
party	O
sparse	O
flows	O
but	O
requiring	O
off	O
-	O
the	O
-	O
shelf	O
edge	B-Method
detector	I-Method
.	O
	
DeepFlow	B-Method
that	O
involves	O
convolution	B-Method
and	I-Method
pooling	I-Method
operations	I-Method
is	O
however	O
not	O
a	O
CNN	B-Method
,	O
since	O
the	O
“	O
filter	O
weights	O
”	O
are	O
non	O
-	O
trainable	O
image	O
patches	O
.	O
	
According	O
to	O
the	O
terminology	O
used	O
in	O
FlowNet	B-Method
,	O
DeepFlow	B-Method
uses	O
correlation	B-Method
.	O
	
An	O
alternative	O
approach	O
for	O
establishing	O
point	B-Task
correspondence	I-Task
is	O
to	O
match	O
image	O
patches	O
.	O
	
Zagoruyko	O
first	O
introduce	O
to	O
CNN	B-Method
-	I-Method
feature	I-Method
matching	I-Method
.	O
	
Güney	O
find	O
feature	B-Method
representation	I-Method
and	O
formulate	O
optical	B-Task
flow	I-Task
estimation	O
in	O
MRF	B-Method
.	O
	
Bailer	O
use	O
multi	O
-	O
scale	O
features	O
and	O
then	O
perform	O
feature	B-Method
matching	I-Method
as	O
Flow	O
Fields	O
.	O
	
Although	O
pixel	B-Method
-	I-Method
wise	I-Method
matching	I-Method
can	O
establish	O
accurate	O
point	B-Task
correspondence	I-Task
,	O
the	O
computational	B-Metric
demand	I-Metric
is	O
too	O
high	O
for	O
practical	O
use	O
(	O
it	O
takes	O
several	O
seconds	O
even	O
a	O
GPU	O
is	O
used	O
)	O
.	O
	
As	O
a	O
tradeoff	O
,	O
Fischer	B-Method
and	O
Ilg	B-Method
perform	O
feature	B-Method
matching	I-Method
only	O
at	O
a	O
reduced	O
spatial	O
resolution	O
.	O
	
We	O
reduce	O
the	O
computational	B-Metric
burden	I-Metric
of	O
feature	B-Task
matching	I-Task
by	O
using	O
a	O
short	B-Method
-	I-Method
ranged	I-Method
matching	I-Method
of	I-Method
warped	I-Method
CNN	I-Method
features	I-Method
at	O
sampled	O
positions	O
and	O
a	O
sub	B-Method
-	I-Method
pixel	I-Method
refinement	I-Method
at	O
every	O
pyramid	O
level	O
.	O
	
We	O
are	O
inspired	O
by	O
the	O
feature	B-Method
transformation	I-Method
used	O
in	O
Spatial	B-Method
Transformer	I-Method
.	O
	
Our	O
network	O
uses	O
the	O
proposed	O
f	B-Method
-	I-Method
warp	I-Method
layer	I-Method
to	O
displace	O
each	O
channel	O
of	O
the	O
given	O
vector	O
-	O
valued	O
feature	O
according	O
to	O
the	O
provided	O
flow	O
field	O
.	O
	
Unlike	O
Spatial	B-Method
Transformer	I-Method
,	O
f	B-Method
-	I-Method
warp	I-Method
layer	I-Method
is	O
not	O
fully	O
constrained	O
and	O
is	O
a	O
relaxed	O
version	O
of	O
it	O
as	O
the	O
flow	O
field	O
is	O
not	O
parameterized	O
.	O
	
While	O
transformation	B-Task
in	O
FlowNet2	B-Method
and	O
SPyNet	B-Method
is	O
limited	O
to	O
images	O
,	O
our	O
decider	B-Method
network	I-Method
is	O
a	O
more	O
generic	O
warping	B-Method
network	I-Method
that	O
warps	O
high	O
-	O
level	O
CNN	O
features	O
.	O
	
section	O
:	O
LiteFlowNet	B-Method
	
LiteFlowNet	B-Method
is	O
composed	O
of	O
two	O
compact	B-Method
sub	I-Method
-	I-Method
networks	I-Method
that	O
are	O
specialized	O
in	O
pyramidal	B-Task
feature	I-Task
extraction	I-Task
and	O
optical	B-Task
flow	I-Task
estimation	O
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Since	O
the	O
spatial	O
dimension	O
of	O
feature	O
maps	O
is	O
contracting	O
in	O
feature	B-Task
extraction	I-Task
and	O
that	O
of	O
flow	O
fields	O
is	O
expanding	O
in	O
flow	B-Task
estimation	I-Task
,	O
we	O
call	O
the	O
two	O
sub	B-Method
-	I-Method
networks	I-Method
as	O
NetC	B-Method
and	O
NetE	B-Method
respectively	O
.	O
	
NetC	B-Method
transforms	O
any	O
given	O
image	O
pair	O
into	O
two	O
pyramids	O
of	O
multi	O
-	O
scale	O
high	O
-	O
dimensional	O
features	O
.	O
	
NetE	B-Method
consists	O
of	O
cascaded	B-Method
flow	I-Method
inference	I-Method
and	O
regularization	B-Method
modules	I-Method
that	O
estimate	O
coarse	B-Task
-	I-Task
to	I-Task
-	I-Task
fine	I-Task
flow	I-Task
fields	I-Task
.	O
	
Pyramidal	B-Method
Feature	I-Method
Extraction	I-Method
.	O
	
As	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
NetC	B-Method
is	O
a	O
two	O
-	O
stream	B-Method
network	I-Method
in	O
which	O
the	O
filter	O
weights	O
are	O
shared	O
across	O
the	O
two	O
streams	O
.	O
	
Each	O
of	O
them	O
functions	O
as	O
a	O
feature	B-Method
descriptor	I-Method
that	O
transforms	O
an	O
image	O
to	O
a	O
pyramid	O
of	O
multi	O
-	O
scale	O
high	O
-	O
dimensional	O
features	O
from	O
the	O
highest	O
spatial	O
resolution	O
(	O
)	O
to	O
the	O
lowest	O
spatial	O
resolution	O
(	O
)	O
.	O
	
The	O
pyramidal	O
features	O
are	O
generated	O
by	O
stride	B-Method
-	I-Method
convolutions	I-Method
with	O
the	O
reduction	O
of	O
spatial	O
resolution	O
by	O
a	O
factor	O
up	O
the	O
pyramid	O
.	O
	
In	O
the	O
following	O
,	O
we	O
omit	O
the	O
subscript	O
that	O
indicates	O
the	O
level	O
of	O
pyramid	O
for	O
brevity	O
.	O
	
We	O
use	O
to	O
represent	O
CNN	O
features	O
for	O
.	O
	
When	O
we	O
discuss	O
the	O
operations	O
in	O
a	O
pyramid	O
level	O
,	O
the	O
same	O
operations	O
are	O
applicable	O
to	O
other	O
levels	O
.	O
	
Feature	B-Method
Warping	I-Method
.	O
	
At	O
each	O
pyramid	O
level	O
,	O
a	O
flow	O
field	O
is	O
inferred	O
from	O
high	O
-	O
level	O
features	O
and	O
of	O
images	O
and	O
.	O
	
Flow	B-Task
inference	I-Task
becomes	O
more	O
challenging	O
if	O
and	O
are	O
captured	O
far	O
away	O
from	O
each	O
other	O
.	O
	
With	O
the	O
motivation	O
of	O
image	B-Task
warping	I-Task
used	O
in	O
conventional	O
methods	O
and	O
recent	O
CNNs	B-Method
for	O
addressing	B-Task
large	I-Task
-	I-Task
displacement	I-Task
flow	I-Task
,	O
we	O
propose	O
to	O
reduce	O
feature	O
-	O
space	O
distance	O
between	O
and	O
by	O
feature	B-Method
warping	I-Method
(	O
f	B-Method
-	I-Method
warp	I-Method
)	O
.	O
	
Specifically	O
,	O
is	O
warped	O
towards	O
by	O
f	B-Method
-	I-Method
warp	I-Method
via	O
flow	B-Method
estimate	I-Method
to	O
.	O
	
This	O
allows	O
our	O
network	O
to	O
infer	O
residual	O
flow	O
between	O
and	O
that	O
has	O
smaller	O
flow	O
magnitude	O
(	O
more	O
details	O
in	O
Section	O
[	O
reference	O
]	O
)	O
but	O
not	O
the	O
complete	O
flow	O
field	O
that	O
is	O
more	O
difficult	O
to	O
infer	O
.	O
	
Unlike	O
conventional	O
methods	O
,	O
f	B-Method
-	I-Method
warp	I-Method
is	O
performed	O
on	O
high	O
-	O
level	O
CNN	O
features	O
but	O
not	O
on	O
images	O
.	O
	
This	O
makes	O
our	O
network	O
more	O
powerful	O
and	O
efficient	O
in	O
addressing	O
the	O
optical	B-Task
flow	I-Task
problem	O
.	O
	
To	O
allow	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
training	I-Task
,	O
is	O
interpolated	O
to	O
for	O
any	O
sub	O
-	O
pixel	O
displacement	O
as	O
follows	O
:	O
where	O
denotes	O
the	O
source	O
coordinates	O
in	O
the	O
input	O
feature	O
map	O
that	O
defines	O
the	O
sample	O
point	O
,	O
denotes	O
the	O
target	O
coordinates	O
of	O
the	O
regular	O
grid	O
in	O
the	O
interpolated	O
feature	O
map	O
,	O
and	O
denotes	O
the	O
four	O
pixel	O
neighbors	O
of	O
.	O
	
The	O
above	O
bilinear	B-Method
interpolation	I-Method
allows	O
back	B-Method
-	I-Method
propagation	I-Method
during	O
training	B-Task
as	O
its	O
gradients	O
can	O
be	O
efficiently	O
computed	O
.	O
	
subsection	O
:	O
Cascaded	B-Task
Flow	I-Task
Inference	I-Task
	
At	O
each	O
pyramid	O
level	O
of	O
NetE	O
,	O
pixel	B-Method
-	I-Method
by	I-Method
-	I-Method
pixel	I-Method
matching	I-Method
of	O
high	O
-	O
level	O
features	O
yields	O
coarse	B-Task
flow	I-Task
estimate	I-Task
.	O
	
A	O
subsequent	O
refinement	O
on	O
the	O
coarse	O
flow	O
further	O
improves	O
it	O
to	O
sub	B-Metric
-	I-Metric
pixel	I-Metric
accuracy	I-Metric
.	O
	
First	B-Task
Flow	I-Task
Inference	I-Task
(	O
descriptor	B-Task
matching	I-Task
)	O
.	O
	
Point	O
correspondence	O
between	O
and	O
is	O
established	O
through	O
computing	O
correlation	O
of	O
high	O
-	O
level	O
feature	O
vectors	O
in	O
individual	O
pyramidal	O
features	O
and	O
as	O
follows	O
:	O
where	O
is	O
the	O
matching	O
cost	O
between	O
point	O
in	O
and	O
point	O
in	O
,	O
is	O
the	O
displacement	O
vector	O
from	O
,	O
and	O
is	O
the	O
length	O
of	O
the	O
feature	O
vector	O
.	O
	
A	O
cost	O
volume	O
is	O
built	O
by	O
aggregating	O
all	O
the	O
matching	B-Metric
costs	I-Metric
into	O
a	O
3D	O
grid	O
.	O
	
We	O
reduce	O
the	O
computational	B-Metric
burden	I-Metric
raised	O
by	O
cost	B-Method
-	I-Method
volume	I-Method
processing	I-Method
in	O
three	O
ways	O
:	O
1	O
)	O
We	O
perform	O
short	B-Method
-	I-Method
range	I-Method
matching	I-Method
at	O
every	O
pyramid	O
level	O
instead	O
of	O
long	B-Method
-	I-Method
range	I-Method
matching	I-Method
at	O
a	O
single	O
level	O
.	O
	
2	O
)	O
	
We	O
reduce	O
feature	O
-	O
space	O
distance	O
between	O
and	O
by	O
warping	O
towards	O
using	O
our	O
proposed	O
f	B-Method
-	I-Method
warp	I-Method
through	O
flow	B-Method
estimate	I-Method
from	O
previous	O
level	O
.	O
	
3	O
)	O
	
We	O
perform	O
matching	B-Task
only	O
at	O
the	O
sampled	O
positions	O
in	O
the	O
pyramid	O
levels	O
of	O
high	O
-	O
spatial	O
resolution	O
.	O
	
The	O
sparse	O
cost	O
volume	O
is	O
interpolated	O
in	O
the	O
spatial	O
dimension	O
to	O
fill	O
the	O
missed	O
matching	O
costs	O
for	O
the	O
unsampled	O
positions	O
.	O
	
The	O
first	O
two	O
techniques	O
effectively	O
reduce	O
the	O
searching	O
space	O
needed	O
,	O
while	O
the	O
last	O
technique	O
reduces	O
the	O
frequency	O
of	O
matching	O
per	O
pyramid	O
level	O
.	O
	
In	O
the	O
descriptor	B-Task
matching	I-Task
unit	I-Task
,	O
residual	O
flow	O
is	O
inferred	O
by	O
filtering	O
the	O
cost	O
volume	O
as	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
A	O
complete	O
flow	O
field	O
is	O
computed	O
as	O
follows	O
:	O
	
Second	O
Flow	B-Method
Inference	I-Method
(	O
sub	B-Task
-	I-Task
pixel	I-Task
refinement	I-Task
)	O
.	O
	
Since	O
the	O
cost	O
volume	O
in	O
descriptor	B-Method
matching	I-Method
unit	I-Method
is	O
aggregated	O
by	O
measuring	O
pixel	O
-	O
by	O
-	O
pixel	O
correlation	O
,	O
flow	B-Method
estimate	I-Method
from	O
the	O
previous	O
inference	O
is	O
only	O
up	O
to	O
pixel	B-Metric
-	I-Metric
level	I-Metric
accuracy	I-Metric
.	O
	
We	O
introduce	O
the	O
second	O
flow	B-Method
inference	I-Method
in	O
the	O
wake	O
of	O
descriptor	B-Task
matching	I-Task
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
It	O
aims	O
to	O
refine	O
the	O
pixel	O
-	O
level	O
flow	O
field	O
to	O
sub	O
-	O
pixel	B-Metric
accuracy	I-Metric
.	O
	
This	O
prevents	O
erroneous	O
flows	O
being	O
amplified	O
by	O
upsampling	O
and	O
passing	O
to	O
the	O
next	O
pyramid	O
level	O
.	O
	
Specifically	O
,	O
is	O
warped	O
to	O
via	O
flow	B-Method
estimate	I-Method
.	O
	
Sub	B-Method
-	I-Method
pixel	I-Method
refinement	I-Method
unit	I-Method
yields	O
a	O
more	O
accurate	O
flow	O
field	O
by	O
minimizing	O
feature	O
-	O
space	O
distance	O
between	O
and	O
through	O
computing	O
residual	O
flow	O
as	O
the	O
following	O
:	O
	
subsection	O
:	O
Flow	B-Method
Regularization	I-Method
	
Cascaded	B-Method
flow	I-Method
inference	I-Method
resembles	O
the	O
role	O
of	O
data	B-Metric
fidelity	I-Metric
in	O
conventional	O
minimization	B-Method
methods	I-Method
.	O
	
Using	O
data	O
term	O
alone	O
,	O
vague	O
flow	O
boundaries	O
and	O
undesired	O
artifacts	O
commonly	O
exist	O
in	O
flow	O
field	O
.	O
	
To	O
tackle	O
this	O
problem	O
,	O
we	O
propose	O
to	O
use	O
a	O
feature	B-Method
-	I-Method
driven	I-Method
local	I-Method
convolution	I-Method
(	I-Method
f	I-Method
-	I-Method
lcon	I-Method
)	O
to	O
regularize	O
flow	O
field	O
from	O
the	O
cascaded	B-Method
flow	I-Method
inference	I-Method
.	O
	
The	O
operation	O
of	O
f	B-Method
-	I-Method
lcon	I-Method
is	O
well	O
-	O
governed	O
by	O
the	O
Laplacian	B-Method
formulation	I-Method
of	I-Method
diffusion	I-Method
of	I-Method
pixel	I-Method
values	I-Method
.	O
	
In	O
contrast	O
to	O
local	B-Method
convolution	I-Method
(	O
lcon	B-Method
)	O
used	O
in	O
conventional	O
CNNs	B-Method
,	O
f	B-Method
-	I-Method
lcon	I-Method
is	O
more	O
generalized	O
.	O
	
Not	O
only	O
is	O
a	O
distinct	O
filter	B-Method
used	O
for	O
each	O
position	O
of	O
feature	O
map	O
,	O
but	O
the	O
filter	O
is	O
adaptively	O
constructed	O
for	O
individual	O
flow	O
patches	O
.	O
	
Consider	O
a	O
general	O
case	O
,	O
a	O
vector	O
-	O
valued	O
feature	O
that	O
has	O
to	O
be	O
regularized	O
has	O
channels	O
and	O
a	O
spatial	O
dimension	O
.	O
	
Define	O
as	O
the	O
set	O
of	O
filters	O
used	O
in	O
f	B-Method
-	I-Method
lcon	I-Method
layer	I-Method
.	O
	
The	O
operation	O
of	O
f	B-Method
-	I-Method
lcon	I-Method
to	O
can	O
be	O
formulated	O
as	O
follow	O
:	O
where	O
“	O
”	O
denotes	O
convolution	O
,	O
is	O
a	O
patch	O
centered	O
at	O
position	O
of	O
channel	O
in	O
,	O
is	O
the	O
corresponding	O
regularization	B-Method
filter	I-Method
,	O
and	O
is	O
a	O
scalar	O
output	O
for	O
and	O
.	O
	
To	O
be	O
specific	O
for	O
regularizing	B-Task
flow	I-Task
field	I-Task
from	O
the	O
cascaded	B-Task
flow	I-Task
inference	I-Task
,	O
we	O
replace	O
to	O
.	O
	
Flow	B-Method
regularization	I-Method
module	I-Method
is	O
defined	O
as	O
follows	O
:	O
	
The	O
f	B-Method
-	I-Method
lcon	I-Method
filters	I-Method
need	O
to	O
be	O
specialized	O
for	O
smoothing	B-Task
flow	I-Task
field	I-Task
.	O
	
It	O
should	O
behave	O
as	O
an	O
averaging	B-Method
filter	I-Method
if	O
the	O
variation	O
of	O
flow	O
vectors	O
over	O
the	O
patch	O
is	O
smooth	O
.	O
	
It	O
should	O
also	O
not	O
over	O
-	O
smooth	O
flow	O
field	O
across	O
flow	O
boundary	O
.	O
	
We	O
define	O
a	O
feature	B-Method
-	I-Method
driven	I-Method
CNN	I-Method
distance	I-Method
metric	I-Method
that	O
estimates	O
local	O
flow	O
variation	O
using	O
pyramidal	O
feature	O
,	O
flow	O
field	O
from	O
the	O
cascaded	B-Method
flow	I-Method
inference	I-Method
,	O
and	O
occlusion	B-Method
probability	I-Method
map	I-Method
.	O
	
In	O
summary	O
,	O
is	O
adaptively	O
constructed	O
by	O
a	O
CNN	B-Method
unit	I-Method
as	O
follows	O
:	O
	
With	O
the	O
introduction	O
of	O
feature	B-Method
-	I-Method
driven	I-Method
distance	I-Method
metric	I-Method
,	O
each	O
filter	B-Method
of	I-Method
f	I-Method
-	I-Method
lcon	I-Method
is	O
constructed	O
as	O
follows	O
:	O
where	O
denotes	O
the	O
neighborhood	O
containing	O
pixels	O
centered	O
at	O
position	O
.	O
	
Here	O
,	O
we	O
provide	O
a	O
mechanism	O
to	O
perform	O
f	B-Method
-	I-Method
lcon	I-Method
efficiently	O
.	O
	
For	O
a	O
-	O
channel	O
input	O
,	O
we	O
use	O
tensors	O
to	O
store	O
f	O
-	O
lcon	O
filter	O
set	O
.	O
	
As	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
each	O
f	B-Method
-	I-Method
lcon	I-Method
filter	I-Method
is	O
folded	O
into	O
a	O
3D	O
column	O
and	O
then	O
packed	O
into	O
the	O
-	O
entry	O
of	O
a	O
3D	O
tensor	O
.	O
	
Same	O
folding	B-Method
and	I-Method
packing	I-Method
operations	I-Method
are	O
also	O
applied	O
to	O
each	O
patch	O
in	O
each	O
channel	O
of	O
.	O
	
This	O
results	O
tensors	O
for	O
.	O
	
In	O
this	O
way	O
,	O
Equation	O
(	O
[	O
reference	O
]	O
)	O
can	O
be	O
reformulated	O
to	O
:	O
where	O
“	O
”	O
denotes	O
element	O
-	O
wise	O
dot	O
product	O
between	O
the	O
corresponding	O
columns	O
of	O
the	O
tensors	O
.	O
	
With	O
the	O
abuse	O
of	O
notation	O
,	O
means	O
the	O
-	O
th	O
-	O
slice	O
of	O
the	O
regularized	O
-	O
channel	O
feature	O
.	O
	
Equation	O
(	O
[	O
reference	O
]	O
)	O
reduces	O
the	O
dimension	O
of	O
tensors	O
from	O
(	O
right	O
-	O
hand	O
side	O
in	O
prior	O
to	O
the	O
dot	O
product	O
)	O
to	O
(	O
left	O
-	O
hand	O
side	O
)	O
.	O
	
section	O
:	O
Experiments	O
	
Network	O
Details	O
.	O
	
In	O
LiteFlowNet	B-Method
,	O
NetC	B-Method
generates	O
	
6	O
-	O
level	O
pyramidal	O
features	O
and	O
	
NetE	B-Task
predicts	I-Task
flow	I-Task
fields	I-Task
for	O
levels	O
6	O
to	O
2	O
.	O
	
Flow	O
field	O
in	O
level	O
2	O
is	O
upsampled	O
to	O
yield	O
flow	O
field	O
in	O
level	O
1	O
.	O
	
We	O
set	O
the	O
maximum	O
searching	O
radius	O
in	O
cost	O
-	O
volume	O
to	O
3	O
pixels	O
(	O
levels	O
6	O
to	O
4	O
)	O
or	O
6	O
pixels	O
(	O
levels	O
3	O
to	O
2	O
)	O
.	O
	
Matching	B-Task
is	O
performed	O
at	O
each	O
position	O
in	O
pyramidal	O
features	O
,	O
except	O
for	O
levels	O
3	O
to	O
2	O
that	O
it	O
is	O
performed	O
at	O
a	O
regularly	O
sampled	O
grid	O
(	O
a	O
stride	O
of	O
2	O
)	O
.	O
	
All	O
convolution	B-Method
layers	I-Method
use	O
filters	B-Method
,	O
except	O
each	O
last	O
layer	O
in	O
descriptor	B-Task
matching	I-Task
,	O
sub	B-Task
-	I-Task
pixel	I-Task
refinement	I-Task
,	O
and	O
flow	B-Method
regularization	I-Method
units	I-Method
uses	O
(	O
levels	O
4	O
to	O
3	O
)	O
or	O
(	O
level	O
2	O
)	O
filters	O
.	O
	
Each	O
convolution	B-Method
layer	I-Method
is	O
followed	O
by	O
a	O
leaky	B-Method
rectified	I-Method
linear	I-Method
unit	I-Method
layer	I-Method
,	O
except	O
f	B-Method
-	I-Method
lcon	I-Method
and	O
the	O
last	O
layer	O
in	O
,	O
and	O
CNN	B-Method
units	I-Method
.	O
	
More	O
details	O
can	O
be	O
found	O
in	O
the	O
supplementary	O
material	O
.	O
	
Training	O
Details	O
.	O
	
We	O
train	O
our	O
network	O
stage	O
-	O
wise	O
by	O
the	O
following	O
steps	O
:	O
1	O
)	O
NetC	B-Method
and	O
:	O
of	O
	
NetE	B-Method
is	O
trained	O
for	O
300k	O
iterations	O
.	O
	
2	O
)	O
together	O
with	O
the	O
trained	O
network	O
in	O
step	O
1	O
is	O
trained	O
for	O
300k	O
iterations	O
.	O
	
3	O
)	O
	
For	O
levels	O
,	O
:	O
followed	O
by	O
is	O
added	O
into	O
the	O
trained	O
network	O
each	O
time	O
.	O
	
The	O
new	O
network	B-Method
cascade	I-Method
is	O
trained	O
for	O
200k	O
(	O
level	O
2	O
:	O
300k	O
)	O
iterations	O
.	O
	
Filter	O
weights	O
are	O
initialized	O
from	O
previous	O
level	O
.	O
	
Learning	B-Metric
rates	I-Metric
are	O
initially	O
set	O
to	O
1e	O
-	O
4	O
,	O
5e	O
-	O
5	O
,	O
and	O
4e	O
-	O
5	O
for	O
levels	O
6	O
to	O
4	O
,	O
3	O
and	O
2	O
respectively	O
.	O
	
We	O
reduce	O
it	O
by	O
a	O
factor	O
of	O
2	O
starting	O
at	O
120k	O
,	O
160k	O
,	O
200k	O
,	O
and	O
240k	O
iterations	O
.	O
	
We	O
use	O
the	O
same	O
loss	O
weight	O
,	O
L2	O
training	O
loss	O
,	O
Adam	B-Method
optimization	I-Method
,	O
data	B-Method
augmentation	I-Method
(	O
including	O
noise	O
injection	O
)	O
,	O
and	O
training	B-Method
schedule	I-Method
(	O
Chairs	O
Things3D	O
)	O
as	O
FlowNet2	B-Method
.	O
	
We	O
denote	O
LiteFlowNet	B-Method
-	I-Method
pre	I-Method
and	O
LiteFlowNet	B-Method
as	O
the	O
networks	O
trained	O
on	O
Chairs	O
and	O
Chairs	O
Things3D	O
,	O
respectively	O
.	O
	
subsection	O
:	O
Results	O
	
We	O
compare	O
several	O
variants	O
of	O
LiteFlowNet	B-Method
to	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
on	O
public	O
benchmarks	O
including	O
FlyingChairs	O
(	O
Chairs	O
)	O
,	O
Sintel	B-Material
clean	I-Material
and	O
final	B-Material
,	O
KITTI12	O
,	O
KITTI15	O
,	O
and	O
Middlebury	O
.	O
	
Conventional	O
Hybrid	O
Heavyweight	O
CNN	O
Lightweight	O
CNN	O
FlyingChairs	O
.	O
	
We	O
first	O
compare	O
the	O
intermediate	O
results	O
of	O
different	O
well	O
-	O
performing	O
networks	O
trained	O
on	O
Chairs	O
alone	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Average	B-Metric
end	I-Metric
-	I-Metric
point	I-Metric
error	I-Metric
(	O
AEE	B-Metric
)	O
is	O
reported	O
.	O
	
LiteFlowNet	B-Method
-	I-Method
pre	I-Method
outperforms	O
the	O
compared	O
networks	O
.	O
	
No	O
intermediate	O
result	O
is	O
available	O
for	O
FlowNet2	B-Method
as	O
each	O
cascade	B-Method
is	O
trained	O
on	O
the	O
Chairs	O
Things3D	O
schedule	O
individually	O
.	O
	
Since	O
FlowNetC	B-Method
,	O
FlowNetS	B-Method
	
(	O
variants	O
of	O
FlowNet	B-Method
)	O
,	O
and	O
SPyNet	B-Method
have	O
fewer	O
parameters	O
than	O
FlowNet2	B-Method
and	O
the	O
later	O
two	O
models	O
do	O
not	O
perform	O
feature	B-Method
matching	I-Method
,	O
we	O
also	O
construct	O
a	O
small	O
-	O
size	O
counterpart	O
LiteFlowNetX	B-Method
-	I-Method
pre	I-Method
by	O
removing	O
the	O
matching	O
part	O
and	O
shrinking	O
the	O
model	O
sizes	O
of	O
NetC	B-Method
and	O
	
NetE	B-Method
by	O
about	O
4	O
and	O
5	O
times	O
,	O
respectively	O
.	O
	
Despite	O
that	O
LiteFlowNetX	B-Method
-	I-Method
pre	I-Method
is	O
43	O
and	O
1.33	O
times	O
smaller	O
than	O
FlowNetC	B-Method
and	O
SPyNet	B-Method
,	O
respectively	O
,	O
it	O
still	O
outperforms	O
these	O
networks	O
and	O
is	O
on	O
par	O
with	O
FlowNetC	B-Method
that	O
uses	O
explicit	B-Method
matching	I-Method
.	O
	
MPI	O
Sintel	B-Material
.	O
	
In	O
Table	O
[	O
reference	O
]	O
,	O
LiteFlowNetX	B-Method
-	I-Method
pre	I-Method
outperforms	O
	
FlowNetS	B-Method
	
(	O
and	O
C	O
)	O
and	O
SPyNet	B-Method
that	O
are	O
trained	O
on	O
Chairs	O
on	O
all	O
cases	O
except	O
the	O
Middlebury	O
benchmark	O
.	O
	
LiteFlowNet	B-Method
,	O
trained	O
on	O
the	O
Chairs	O
Things3D	O
schedule	O
,	O
performs	O
better	O
than	O
LiteFlowNet	B-Method
-	I-Method
pre	I-Method
as	O
expected	O
.	O
	
LiteFlowNet	B-Method
also	O
outperforms	O
SPyNet	B-Method
,	O
FlowNet2	B-Method
-	I-Method
S	I-Method
(	O
and	O
-	O
C	O
)	O
.	O
	
We	O
also	O
fine	O
-	O
tuned	O
LiteFlowNet	B-Method
on	O
a	O
mixture	O
of	O
Sintel	B-Material
clean	I-Material
and	O
final	B-Material
training	O
data	O
(	O
LiteFlowNet	B-Method
-	O
ft	O
)	O
using	O
the	O
generalized	B-Method
Charbonnier	I-Method
loss	I-Method
.	O
	
No	O
noise	B-Method
augmentation	I-Method
was	O
performed	O
but	O
we	O
introduced	O
image	O
mirroring	O
to	O
improve	O
the	O
diversity	O
of	O
the	O
training	O
set	O
.	O
	
LiteFlowNet	B-Method
-	O
ft	O
outperforms	O
FlowNet2	B-Method
-	I-Method
ft	I-Method
-	I-Method
sintel	I-Method
and	O
EpicFlow	B-Method
for	O
Sintel	B-Material
final	I-Material
testing	O
set	O
.	O
	
Despite	O
DC	B-Method
Flow	I-Method
(	O
a	O
hybrid	B-Method
method	I-Method
consists	O
of	O
CNN	B-Method
and	I-Method
post	I-Method
-	I-Method
processing	I-Method
)	O
performs	O
better	O
than	O
LiteFlowNet	B-Method
,	O
its	O
GPU	B-Metric
runtime	I-Metric
requires	O
several	O
seconds	O
that	O
makes	O
it	O
formidable	O
in	O
many	O
applications	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
some	O
examples	O
of	O
flow	O
fields	O
on	O
Sintel	B-Material
dataset	I-Material
.	O
	
LiteFlowNet	B-Method
-	O
ft	O
and	O
FlowNet2	B-Method
-	I-Method
ft	I-Method
	
-	O
sintel	O
perform	O
the	O
best	O
among	O
the	O
compared	O
methods	O
.	O
	
As	O
LiteFlowNet	B-Method
has	O
flow	B-Method
regularization	I-Method
module	I-Method
,	O
sharper	O
flow	O
boundaries	O
and	O
lesser	O
artifacts	O
can	O
be	O
observed	O
in	O
the	O
generated	O
flow	O
fields	O
.	O
	
KITTI	O
.	O
	
LiteFlowNet	B-Method
consistently	O
performs	O
better	O
than	O
LiteFlowNet	B-Method
-	I-Method
pre	I-Method
especially	O
on	O
KITTI15	O
as	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
It	O
also	O
outperforms	O
SPyNet	B-Method
and	O
FlowNet2	B-Method
-	I-Method
S	I-Method
(	O
and	O
C	O
)	O
.	O
	
We	O
also	O
fine	O
-	O
tuned	O
LiteFlowNet	B-Method
on	O
a	O
mixture	O
of	O
KITTI12	O
and	O
KITTI15	O
training	O
data	O
(	O
LiteFlowNet	B-Method
-	O
ft	O
)	O
using	O
the	O
same	O
augmentation	O
as	O
the	O
case	O
of	O
Sintel	B-Material
except	O
that	O
we	O
reduced	O
the	O
amount	O
of	O
augmentation	O
for	O
spatial	O
motion	O
to	O
fit	O
the	O
driving	O
scene	O
.	O
	
After	O
fine	O
-	O
tuning	O
,	O
LiteFlowNet	B-Method
generalizes	O
well	O
to	O
real	O
-	O
world	O
data	O
.	O
	
LiteFlowNet	B-Method
-	O
ft	O
outperforms	O
	
FlowNet2	B-Method
-	I-Method
ft	I-Method
-	I-Method
kitti	I-Method
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
some	O
examples	O
of	O
flow	O
fields	O
on	O
KITTI	O
.	O
	
As	O
in	O
the	O
case	O
for	O
Sintel	B-Material
,	O
LiteFlowNet	B-Method
-	O
ft	O
and	O
FlowNet2	B-Method
-	I-Method
ft	I-Method
-	I-Method
kitti	I-Method
performs	O
the	O
best	O
among	O
the	O
compared	O
methods	O
.	O
	
Even	O
though	O
LiteFlowNet	B-Method
and	O
its	O
variants	O
perform	O
pyramidal	B-Method
descriptor	I-Method
matching	I-Method
in	O
a	O
limited	O
searching	O
range	O
,	O
it	O
yields	O
reliable	O
large	B-Task
-	I-Task
displacement	I-Task
flow	I-Task
fields	I-Task
for	O
real	O
-	O
world	O
data	O
due	O
to	O
	
the	O
feature	B-Method
warping	I-Method
(	I-Method
f	I-Method
-	I-Method
warp	I-Method
)	I-Method
layer	I-Method
introduced	O
.	O
	
More	O
analysis	O
will	O
be	O
presented	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Middlebury	O
.	O
	
LiteFlowNet	B-Method
has	O
comparable	O
performance	O
with	O
conventional	O
methods	O
.	O
	
It	O
outperforms	O
FlowNetS	B-Method
(	O
and	O
C	O
)	O
,	O
FlowNet2	B-Method
-	I-Method
S	I-Method
	
(	O
and	O
C	O
)	O
,	O
SPyNet	B-Method
,	O
and	O
FlowNet2	B-Method
.	O
	
On	O
the	O
benchmark	O
,	O
LiteFlowNet	B-Method
-	O
ft	O
refers	O
to	O
the	O
one	O
fine	O
-	O
tuned	O
on	O
Sintel	B-Material
.	O
	
subsection	O
:	O
Runtime	O
and	O
Parameters	O
	
We	O
measure	O
runtime	B-Metric
of	O
a	O
CNN	B-Method
using	O
a	O
machine	O
equipped	O
with	O
an	O
Intel	O
Xeon	O
E5	O
2.2GHz	O
and	O
an	O
NVIDIA	O
GTX	O
1080	O
.	O
	
Timings	O
are	O
averaged	O
over	O
100	O
runs	O
for	O
Sintel	B-Material
image	I-Material
pairs	I-Material
of	O
size	O
.	O
	
As	O
summarized	O
in	O
Table	O
[	O
reference	O
]	O
,	O
LiteFlowNet	B-Method
has	O
about	O
30	O
times	O
fewer	O
parameters	O
than	O
FlowNet2	B-Method
and	O
is	O
1.36	O
times	O
faster	O
in	O
runtime	B-Metric
.	O
	
LiteFlowNetX	B-Method
,	O
a	O
variant	O
of	O
LiteFlowNet	B-Method
having	O
a	O
smaller	O
model	B-Metric
size	I-Metric
and	O
without	O
descriptor	B-Method
matching	I-Method
,	O
has	O
about	O
43	O
times	O
fewer	O
parameters	O
than	O
FlowNetC	B-Method
and	O
a	O
comparable	O
runtime	B-Metric
.	O
	
LiteFlowNetX	B-Method
also	O
has	O
1.33	O
times	O
fewer	O
parameters	O
than	O
SPyNet	B-Method
.	O
	
LiteFlowNet	B-Method
and	O
its	O
variants	O
are	O
currently	O
the	O
most	O
compact	O
CNNs	B-Method
for	O
flow	B-Task
estimation	I-Task
.	O
	
subsection	O
:	O
Ablation	B-Task
Study	I-Task
	
We	O
investigate	O
the	O
role	O
of	O
each	O
component	O
in	O
LiteFlowNet	B-Method
-	I-Method
pre	I-Method
trained	O
on	O
Chairs	O
by	O
evaluating	O
the	O
performance	O
of	O
different	O
variants	O
with	O
some	O
of	O
the	O
components	O
disabled	O
.	O
	
The	O
AEE	B-Metric
results	O
are	O
summarized	O
in	O
Table	O
[	O
reference	O
]	O
and	O
examples	O
of	O
flow	O
fields	O
are	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Feature	B-Method
Warping	I-Method
.	O
	
We	O
consider	O
two	O
variants	O
	
LiteFlowNet	B-Method
-	I-Method
pre	I-Method
	
(	O
WM	O
and	O
WMS	O
)	O
	
and	O
compare	O
them	O
to	O
the	O
counterparts	O
with	O
warping	O
disabled	O
(	O
M	O
and	O
MS	O
)	O
.	O
	
Flow	O
fields	O
from	O
M	O
and	O
MS	B-Method
are	O
more	O
vague	O
.	O
	
Large	O
degradation	O
in	O
AEE	B-Metric
is	O
noticed	O
especially	O
for	O
KITTI12	O
(	O
)	O
and	O
KITTI15	O
(	O
)	O
.	O
	
With	O
feature	B-Method
warping	I-Method
,	O
pyramidal	O
features	O
that	O
input	O
to	O
flow	B-Task
inference	I-Task
are	O
closer	O
to	O
each	O
other	O
.	O
	
This	O
facilitates	O
flow	B-Task
estimation	I-Task
in	O
subsequent	O
pyramid	O
level	O
by	O
computing	O
residual	O
flow	O
.	O
	
Descriptor	B-Task
Matching	I-Task
.	O
	
We	O
compare	O
the	O
variant	O
WSR	B-Method
without	I-Method
descriptor	I-Method
matching	I-Method
for	O
which	O
the	O
flow	B-Method
inference	I-Method
part	I-Method
is	O
made	O
as	O
deep	O
as	O
that	O
in	O
the	O
unamended	O
LiteFlowNet	B-Method
-	I-Method
pre	I-Method
(	O
ALL	O
)	O
.	O
	
No	O
noticeable	O
difference	O
between	O
the	O
flow	O
fields	O
from	O
WSR	B-Method
and	O
ALL	O
.	O
	
Since	O
the	O
maximum	O
displacement	O
of	O
the	O
example	O
flow	O
field	O
is	O
not	O
very	O
large	O
(	O
only	O
14.7	O
pixels	O
)	O
,	O
accurate	O
flow	O
field	O
can	O
still	O
be	O
yielded	O
from	O
WSR	B-Method
.	O
	
For	O
evaluation	O
covering	O
a	O
wide	O
range	O
of	O
flow	O
displacement	O
(	O
especially	O
large	O
-	O
displacement	O
benchmark	O
,	O
KITTI	O
)	O
,	O
degradation	O
in	O
AEE	B-Metric
is	O
noticed	O
for	O
WSR	B-Method
.	O
	
This	O
suggests	O
that	O
descriptor	B-Method
matching	I-Method
is	O
useful	O
in	O
addressing	O
large	B-Task
-	I-Task
displacement	I-Task
flow	I-Task
.	O
	
Sub	B-Task
-	I-Task
Pixel	I-Task
Refinement	I-Task
.	O
	
The	O
flow	O
field	O
generated	O
from	O
WMS	B-Method
is	O
more	O
crisp	O
and	O
contains	O
more	O
fine	O
details	O
than	O
that	O
generated	O
from	O
WM	B-Method
with	O
sub	B-Method
-	I-Method
pixel	I-Method
refinement	I-Method
disabled	O
.	O
	
Less	O
small	O
-	O
magnitude	O
flow	O
artifacts	O
(	O
represented	O
by	O
light	O
color	O
on	O
the	O
background	O
)	O
are	O
also	O
observed	O
.	O
	
Besides	O
,	O
WMS	B-Method
achieves	O
smaller	O
AEE	B-Metric
.	O
	
Since	O
descriptor	B-Method
matching	I-Method
establishes	O
pixel	O
-	O
by	O
-	O
pixel	O
correspondence	O
,	O
sub	B-Method
-	I-Method
pixel	I-Method
refinement	I-Method
is	O
necessary	O
to	O
yield	O
detail	O
-	O
preserving	O
flow	O
field	O
.	O
	
Regularization	B-Method
.	O
	
In	O
comparison	O
WMS	B-Method
with	O
regularization	O
disabled	O
to	O
ALL	O
,	O
undesired	O
artifacts	O
exist	O
in	O
homogeneous	O
regions	O
(	O
represented	O
by	O
very	O
dim	O
color	O
on	O
the	O
background	O
)	O
of	O
the	O
flow	O
field	O
generated	O
from	O
WMS	B-Method
.	O
	
Flow	O
bleeding	O
and	O
vague	O
flow	O
boundaries	O
are	O
observed	O
.	O
	
Degradation	O
in	O
AEE	B-Metric
is	O
also	O
noticed	O
.	O
	
This	O
suggests	O
that	O
the	O
proposed	O
feature	B-Method
-	I-Method
driven	I-Method
local	I-Method
convolution	I-Method
(	I-Method
f	I-Method
-	I-Method
lcon	I-Method
)	I-Method
plays	O
the	O
vital	O
role	O
to	O
smooth	O
flow	O
field	O
and	O
maintain	O
crisp	O
flow	O
boundaries	O
as	O
regularization	O
term	O
in	O
conventional	O
variational	B-Method
methods	I-Method
.	O
	
section	O
:	O
Conclusion	O
	
We	O
have	O
presented	O
a	O
compact	B-Method
network	I-Method
for	O
accurate	B-Task
flow	I-Task
estimation	I-Task
.	O
	
LiteFlowNet	B-Method
outperforms	O
FlowNet	B-Method
and	O
is	O
on	O
par	O
with	O
or	O
outperforms	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
FlowNet2	B-Method
on	O
public	O
benchmarks	O
while	O
being	O
faster	O
in	O
runtime	B-Metric
and	O
30	O
times	O
smaller	O
in	O
model	B-Metric
size	I-Metric
.	O
	
Pyramidal	B-Method
feature	I-Method
extraction	I-Method
and	O
feature	B-Method
warping	I-Method
(	O
f	B-Method
-	I-Method
warp	I-Method
)	O
help	O
us	O
to	O
break	O
the	O
de	O
facto	O
rule	O
of	O
accurate	O
flow	B-Method
network	I-Method
requiring	O
large	O
model	O
size	O
.	O
	
To	O
address	O
large	B-Task
-	I-Task
displacement	I-Task
and	I-Task
detail	I-Task
-	I-Task
preserving	I-Task
flows	I-Task
,	O
LiteFlowNet	B-Method
exploits	O
short	B-Method
-	I-Method
range	I-Method
matching	I-Method
to	O
generate	O
pixel	O
-	O
level	O
flow	O
field	O
and	O
further	O
improves	O
the	O
estimate	O
to	O
sub	B-Metric
-	I-Metric
pixel	I-Metric
accuracy	I-Metric
in	O
the	O
cascaded	B-Method
flow	I-Method
inference	I-Method
.	O
	
To	O
result	O
crisp	O
flow	O
boundaries	O
,	O
LiteFlowNet	B-Method
regularizes	O
flow	O
field	O
through	O
feature	B-Method
-	I-Method
driven	I-Method
local	I-Method
convolution	I-Method
(	O
f	B-Method
-	I-Method
lcon	I-Method
)	O
.	O
	
With	O
its	O
lightweight	O
,	O
accurate	O
,	O
and	O
fast	O
flow	B-Task
computation	I-Task
,	O
we	O
expect	O
that	O
LiteFlowNet	B-Method
can	O
be	O
deployed	O
to	O
many	O
applications	O
such	O
as	O
motion	B-Task
segmentation	I-Task
,	O
action	B-Task
recognition	I-Task
,	O
SLAM	B-Task
,	O
3D	B-Task
reconstruction	I-Task
and	O
more	O
.	O
	
Acknowledgement	O
.	O
	
This	O
work	O
is	O
supported	O
by	O
SenseTime	O
Group	O
Limited	O
and	O
the	O
General	O
Research	O
Fund	O
sponsored	O
by	O
the	O
Research	O
Grants	O
Council	O
of	O
the	O
Hong	O
Kong	O
SAR	O
(	O
CUHK	O
14241716	O
,	O
14224316	O
,	O
14209217	O
)	O
.	O
	
section	O
:	O
Appendix	O
	
LiteFlowNet	B-Method
consists	O
of	O
two	O
compact	B-Method
sub	I-Method
-	I-Method
networks	I-Method
,	O
namely	O
NetC	B-Method
and	I-Method
NetE.	I-Method
NetC	I-Method
is	O
a	O
two	O
-	O
steam	B-Method
network	I-Method
in	O
which	O
the	O
two	O
network	O
streams	O
share	O
the	O
same	O
set	O
of	O
filters	O
.	O
	
The	O
input	O
to	O
NetC	B-Method
is	O
an	O
image	O
pair	O
(	O
,	O
)	O
.	O
	
The	O
network	B-Method
architectures	I-Method
of	O
the	O
6	O
-	O
level	O
NetC	O
and	O
NetE	B-Method
at	O
pyramid	O
level	O
5	O
are	O
provided	O
in	O
Table	O
[	O
reference	O
]	O
and	O
Tables	O
[	O
reference	O
]	O
to	O
[	O
reference	O
]	O
,	O
respectively	O
.	O
	
We	O
use	O
suffixes	O
	
“	O
M	O
”	O
,	O
“	O
S	O
”	O
and	O
“	O
R	O
”	O
to	O
highlight	O
the	O
layers	O
that	O
are	O
used	O
in	O
descriptor	B-Task
matching	I-Task
,	O
sub	B-Task
-	I-Task
pixel	I-Task
refinement	I-Task
,	O
and	O
flow	B-Method
regularization	I-Method
units	I-Method
in	O
NetE	B-Method
,	O
respectively	O
.	O
	
We	O
declare	O
a	O
layer	O
as	O
“	O
flow	O
”	O
to	O
highlight	O
when	O
the	O
output	O
is	O
a	O
flow	O
field	O
.	O
	
Our	O
code	O
and	O
trained	O
models	O
are	O
available	O
at	O
.	O
	
A	O
video	O
clip	O
(	O
)	O
and	O
a	O
supplementary	O
material	O
are	O
available	O
on	O
our	O
project	O
page	O
(	O
)	O
to	O
showcase	O
the	O
performance	O
of	O
LiteFlowNet	B-Method
and	O
the	O
effectiveness	O
of	O
the	O
proposed	O
components	O
in	O
our	O
network	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
The	O
Reactor	B-Method
:	O
A	O
fast	B-Method
and	I-Method
sample	I-Method
-	I-Method
efficient	I-Method
Actor	I-Method
-	I-Method
Critic	I-Method
agent	I-Method
for	O
Reinforcement	B-Task
Learning	I-Task
	
In	O
this	O
work	O
,	O
we	O
present	O
a	O
new	O
agent	B-Method
architecture	I-Method
,	O
called	O
Reactor	B-Method
,	O
which	O
combines	O
multiple	O
algorithmic	B-Method
and	I-Method
architectural	I-Method
contributions	I-Method
to	O
produce	O
an	O
agent	O
with	O
higher	O
sample	B-Metric
-	I-Metric
efficiency	I-Metric
than	O
Prioritized	B-Method
Dueling	I-Method
DQN	I-Method
wang2017sample	O
and	O
Categorical	B-Method
DQN	I-Method
bellemare2017distributional	O
,	O
while	O
giving	O
better	O
run	B-Metric
-	I-Metric
time	I-Metric
performance	O
than	O
A3C	O
mnih2016asynchronous	O
.	O
	
Our	O
first	O
contribution	O
is	O
a	O
new	O
policy	B-Method
evaluation	I-Method
algorithm	I-Method
called	O
Distributional	B-Method
Retrace	I-Method
,	O
which	O
brings	O
multi	B-Task
-	I-Task
step	I-Task
off	I-Task
-	I-Task
policy	I-Task
updates	I-Task
to	O
the	O
distributional	B-Task
reinforcement	I-Task
learning	I-Task
setting	I-Task
.	O
	
The	O
same	O
approach	O
can	O
be	O
used	O
to	O
convert	O
several	O
classes	O
of	O
multi	B-Method
-	I-Method
step	I-Method
policy	I-Method
evaluation	I-Method
algorithms	I-Method
,	O
designed	O
for	O
expected	B-Task
value	I-Task
evaluation	I-Task
,	O
into	O
distributional	B-Method
algorithms	I-Method
.	O
	
Next	O
,	O
we	O
introduce	O
the	O
-	B-Method
leave	I-Method
-	I-Method
one	I-Method
-	I-Method
out	I-Method
policy	I-Method
gradient	I-Method
algorithm	I-Method
,	O
which	O
improves	O
the	O
trade	O
-	O
off	O
between	O
variance	B-Metric
and	O
bias	O
by	O
using	O
action	O
values	O
as	O
a	O
baseline	O
.	O
	
Our	O
final	O
algorithmic	O
contribution	O
is	O
a	O
new	O
prioritized	B-Method
replay	I-Method
algorithm	I-Method
for	O
sequences	O
,	O
which	O
exploits	O
the	O
temporal	O
locality	O
of	O
neighboring	O
observations	O
for	O
more	O
efficient	O
replay	B-Task
prioritization	I-Task
.	O
	
Using	O
the	O
Atari	B-Material
2600	I-Material
benchmarks	I-Material
,	O
we	O
show	O
that	O
each	O
of	O
these	O
innovations	O
contribute	O
to	O
both	O
sample	B-Metric
efficiency	I-Metric
and	O
final	B-Metric
agent	I-Metric
performance	I-Metric
.	O
	
Finally	O
,	O
we	O
demonstrate	O
that	O
Reactor	B-Method
reaches	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
after	O
200	O
million	O
frames	O
and	O
less	O
than	O
a	O
day	O
of	O
training	O
.	O
	
section	O
:	O
Introduction	O
	
Model	B-Method
-	I-Method
free	I-Method
deep	I-Method
reinforcement	I-Method
learning	I-Method
has	O
achieved	O
several	O
remarkable	O
successes	O
in	O
domains	O
ranging	O
from	O
super	B-Task
-	I-Task
human	I-Task
-	I-Task
level	I-Task
control	I-Task
in	O
video	O
games	O
mnih15human	O
and	O
the	O
game	O
of	O
Go	O
silver2016mastering	O
,	O
agzero	O
,	O
to	O
continuous	B-Task
motor	I-Task
control	I-Task
tasks	I-Task
lillicrap2015continuous	O
,	O
schulman2015trust	O
.	O
	
Much	O
of	O
the	O
recent	O
work	O
can	O
be	O
divided	O
into	O
two	O
categories	O
.	O
	
First	O
,	O
those	O
of	O
which	O
that	O
,	O
often	O
building	O
on	O
the	O
DQN	B-Method
framework	I-Method
,	O
act	O
-	O
greedily	O
according	O
to	O
an	O
action	B-Method
-	I-Method
value	I-Method
function	I-Method
and	O
train	O
using	O
mini	O
-	O
batches	O
of	O
transitions	O
sampled	O
from	O
an	O
experience	O
replay	O
buffer	O
van2016deep	O
,	O
wang2015dueling	O
,	O
he2016learning	O
,	O
anschel2017averaged	O
.	O
	
These	O
value	B-Method
-	I-Method
function	I-Method
agents	I-Method
benefit	O
from	O
improved	O
sample	B-Metric
complexity	I-Metric
,	O
but	O
tend	O
to	O
suffer	O
from	O
long	O
runtimes	B-Metric
(	O
e.g.	O
DQN	B-Method
requires	O
approximately	O
a	O
week	O
to	O
train	O
on	O
Atari	B-Material
)	O
.	O
	
The	O
second	O
category	O
are	O
the	O
actor	B-Method
-	I-Method
critic	I-Method
agents	I-Method
,	O
which	O
includes	O
the	O
asynchronous	B-Method
advantage	I-Method
actor	I-Method
-	I-Method
critic	I-Method
(	I-Method
A3C	I-Method
)	I-Method
algorithm	I-Method
,	O
introduced	O
by	O
mnih2016asynchronous	O
.	O
	
These	O
agents	O
train	O
on	O
transitions	O
collected	O
by	O
multiple	O
actors	O
running	O
,	O
and	O
often	O
training	O
,	O
in	O
parallel	O
schulman2017proximal	O
,	O
vezhnevets2017feudal	O
.	O
	
The	O
deep	B-Method
actor	I-Method
-	I-Method
critic	I-Method
agents	I-Method
train	O
on	O
each	O
trajectory	O
only	O
once	O
,	O
and	O
thus	O
tend	O
to	O
have	O
worse	O
sample	B-Metric
complexity	I-Metric
.	O
	
However	O
,	O
their	O
distributed	O
nature	O
allows	O
significantly	O
faster	O
training	B-Task
in	O
terms	O
of	O
wall	B-Metric
-	I-Metric
clock	I-Metric
time	I-Metric
.	O
	
Still	O
,	O
not	O
all	O
existing	O
algorithms	O
can	O
be	O
put	O
in	O
the	O
above	O
two	O
categories	O
and	O
various	O
hybrid	O
approaches	O
do	O
exist	O
zhao2016deep	O
,	O
o2016combining	O
,	O
gu2016q	O
,	O
wang2017sample	O
.	O
	
Data	B-Task
-	I-Task
efficiency	I-Task
and	O
off	B-Task
-	I-Task
policy	I-Task
learning	I-Task
are	O
essential	O
for	O
many	O
real	B-Task
-	I-Task
world	I-Task
domains	I-Task
where	O
interactions	O
with	O
the	O
environment	O
are	O
expensive	O
.	O
	
Similarly	O
,	O
wall	O
-	O
clock	O
time	O
(	O
time	B-Metric
-	I-Metric
efficiency	I-Metric
)	O
directly	O
impacts	O
an	O
algorithm	O
’s	O
applicability	O
through	O
resource	B-Metric
costs	I-Metric
.	O
	
The	O
focus	O
of	O
this	O
work	O
is	O
to	O
produce	O
an	O
agent	O
that	O
is	O
sample	O
-	O
and	O
time	O
-	O
efficient	O
.	O
	
To	O
this	O
end	O
,	O
we	O
introduce	O
a	O
new	O
reinforcement	B-Method
learning	I-Method
agent	I-Method
,	O
called	O
Reactor	B-Method
(	O
Retrace	B-Method
-	I-Method
Actor	I-Method
)	O
,	O
which	O
takes	O
a	O
principled	O
approach	O
to	O
combining	O
the	O
sample	B-Metric
-	I-Metric
efficiency	I-Metric
of	O
off	B-Method
-	I-Method
policy	I-Method
experience	I-Method
replay	I-Method
with	O
the	O
time	O
-	O
efficiency	O
of	O
asynchronous	B-Method
algorithms	I-Method
.	O
	
We	O
combine	O
recent	O
advances	O
in	O
both	O
categories	O
of	O
agents	O
with	O
novel	O
contributions	O
to	O
produce	O
an	O
agent	O
that	O
inherits	O
the	O
benefits	O
of	O
both	O
and	O
reaches	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
over	O
57	O
Atari	B-Material
2600	O
games	O
.	O
	
Our	O
primary	O
contributions	O
are	O
(	O
1	O
)	O
a	O
novel	O
policy	B-Method
gradient	I-Method
algorithm	I-Method
,	O
-	O
LOO	O
,	O
which	O
makes	O
better	O
use	O
of	O
action	O
-	O
value	O
estimates	O
to	O
improve	O
the	O
policy	O
gradient	O
;	O
(	O
2	O
)	O
the	O
first	O
multi	B-Method
-	I-Method
step	I-Method
off	I-Method
-	I-Method
policy	I-Method
distributional	I-Method
reinforcement	I-Method
learning	I-Method
algorithm	I-Method
,	O
distributional	B-Method
Retrace	I-Method
(	O
)	O
;	O
(	O
3	O
)	O
a	O
novel	O
prioritized	B-Method
replay	I-Method
for	O
off	B-Task
-	I-Task
policy	I-Task
sequences	I-Task
of	I-Task
transitions	I-Task
;	O
and	O
(	O
4	O
)	O
an	O
optimized	B-Method
network	I-Method
and	I-Method
parallel	I-Method
training	I-Method
architecture	I-Method
.	O
	
We	O
begin	O
by	O
reviewing	O
background	O
material	O
,	O
including	O
relevant	O
improvements	O
to	O
both	O
value	B-Method
-	I-Method
function	I-Method
agents	I-Method
and	O
actor	B-Method
-	I-Method
critic	I-Method
agents	I-Method
.	O
	
In	O
Section	O
[	O
reference	O
]	O
we	O
introduce	O
each	O
of	O
our	O
primary	O
contributions	O
and	O
present	O
the	O
Reactor	B-Method
agent	O
.	O
	
Finally	O
,	O
in	O
Section	O
[	O
reference	O
]	O
,	O
we	O
present	O
experimental	O
results	O
on	O
the	O
57	O
Atari	B-Material
2600	O
games	O
from	O
the	O
Arcade	O
Learning	O
Environment	O
(	O
ALE	O
)	O
bellemare2013arcade	O
,	O
as	O
well	O
as	O
a	O
series	O
of	O
ablation	B-Task
studies	I-Task
for	O
the	O
various	O
components	O
of	O
Reactor	B-Method
.	O
	
section	O
:	O
Background	O
	
We	O
consider	O
a	O
Markov	B-Method
decision	I-Method
process	I-Method
(	I-Method
MDP	I-Method
)	I-Method
with	O
state	O
space	O
and	O
finite	O
action	O
space	O
.	O
	
A	O
(	O
stochastic	B-Method
)	I-Method
policy	I-Method
is	O
a	O
mapping	O
from	O
states	O
to	O
a	O
probability	O
distribution	O
over	O
actions	O
.	O
	
We	O
consider	O
a	O
-	O
discounted	O
infinite	O
-	O
horizon	O
criterion	O
,	O
with	O
the	O
discount	O
factor	O
,	O
and	O
define	O
for	O
policy	O
the	O
action	O
-	O
value	O
of	O
a	O
state	O
-	O
action	O
pair	O
as	O
where	O
is	O
a	O
trajectory	O
generated	O
by	O
choosing	O
in	O
and	O
following	O
thereafter	O
,	O
i.e.	O
,	O
(	O
for	O
)	O
,	O
and	O
is	O
the	O
reward	O
signal	O
.	O
	
The	O
objective	O
in	O
reinforcement	B-Task
learning	I-Task
is	O
to	O
find	O
an	O
optimal	B-Method
policy	I-Method
,	O
which	O
maximises	O
.	O
	
The	O
optimal	O
action	O
-	O
values	O
are	O
given	O
by	O
.	O
	
subsection	O
:	O
Value	B-Method
-	I-Method
based	I-Method
algorithms	I-Method
	
The	O
Deep	B-Method
Q	I-Method
-	I-Method
Network	I-Method
(	I-Method
DQN	I-Method
)	I-Method
framework	I-Method
,	O
introduced	O
by	O
mnih15human	O
,	O
popularised	O
the	O
current	O
line	O
of	O
research	O
into	O
deep	B-Method
reinforcement	I-Method
learning	I-Method
by	O
reaching	O
human	O
-	O
level	O
,	O
and	O
beyond	O
,	O
performance	O
across	O
57	O
Atari	B-Material
2600	O
games	O
in	O
the	O
ALE	O
.	O
	
While	O
DQN	B-Method
includes	O
many	O
specific	O
components	O
,	O
the	O
essence	O
of	O
the	O
framework	O
,	O
much	O
of	O
which	O
is	O
shared	O
by	O
Neural	B-Method
Fitted	I-Method
Q	I-Method
-	O
Learning	O
riedmiller2005neural	O
,	O
is	O
to	O
use	O
of	O
a	O
deep	B-Method
convolutional	I-Method
neural	I-Method
network	I-Method
to	O
approximate	O
an	O
action	B-Method
-	I-Method
value	I-Method
function	I-Method
,	O
training	O
this	O
approximate	B-Method
action	I-Method
-	I-Method
value	I-Method
function	I-Method
using	O
the	O
Q	B-Method
-	I-Method
Learning	I-Method
algorithm	I-Method
watkins1992	O
and	O
mini	O
-	O
batches	O
of	O
one	O
-	O
step	O
transitions	O
(	O
)	O
drawn	O
randomly	O
from	O
an	O
experience	O
replay	O
buffer	O
lin1992self	O
.	O
	
Additionally	O
,	O
the	O
next	O
-	O
state	O
action	O
-	O
values	O
are	O
taken	O
from	O
a	O
target	O
network	O
,	O
which	O
is	O
updated	O
to	O
match	O
the	O
current	O
network	O
periodically	O
.	O
	
Thus	O
,	O
the	O
temporal	B-Metric
difference	I-Metric
(	I-Metric
TD	I-Metric
)	I-Metric
error	I-Metric
for	O
transition	O
used	O
by	O
these	O
algorithms	O
is	O
given	O
by	O
where	O
denotes	O
the	O
parameters	O
of	O
the	O
network	O
and	O
are	O
the	O
parameters	O
of	O
the	O
target	O
network	O
.	O
	
Since	O
this	O
seminal	O
work	O
,	O
we	O
have	O
seen	O
numerous	O
extensions	O
and	O
improvements	O
that	O
all	O
share	O
the	O
same	O
underlying	O
framework	O
.	O
	
Double	B-Method
DQN	I-Method
van2016deep	O
,	O
attempts	O
to	O
correct	O
for	O
the	O
over	B-Task
-	I-Task
estimation	I-Task
bias	I-Task
inherent	O
in	O
Q	B-Method
-	I-Method
Learning	I-Method
by	O
changing	O
the	O
second	O
term	O
of	O
eq	O
:	O
tderr	O
to	O
.	O
	
The	O
dueling	B-Method
architecture	I-Method
wang2015dueling	O
,	O
changes	O
the	O
network	O
to	O
estimate	O
action	O
-	O
values	O
using	O
separate	O
network	B-Method
heads	I-Method
and	O
with	O
Recently	O
,	O
rainbow	O
introduced	O
Rainbow	B-Method
,	O
a	O
value	B-Method
-	I-Method
based	I-Method
reinforcement	I-Method
learning	I-Method
agent	I-Method
combining	O
many	O
of	O
these	O
improvements	O
into	O
a	O
single	O
agent	O
and	O
demonstrating	O
that	O
they	O
are	O
largely	O
complementary	O
.	O
	
Rainbow	B-Method
significantly	O
out	O
performs	O
previous	O
methods	O
,	O
but	O
also	O
inherits	O
the	O
poorer	O
time	B-Metric
-	I-Metric
efficiency	I-Metric
of	O
the	O
DQN	B-Method
framework	I-Method
.	O
	
We	O
include	O
a	O
detailed	O
comparison	O
between	O
Reactor	B-Method
and	O
Rainbow	O
in	O
the	O
Appendix	O
.	O
	
In	O
the	O
remainder	O
of	O
the	O
section	O
we	O
will	O
describe	O
in	O
more	O
depth	O
other	O
recent	O
improvements	O
to	O
DQN	B-Method
.	O
	
subsubsection	O
:	O
Prioritized	B-Task
experience	I-Task
replay	I-Task
	
The	O
experience	B-Method
replay	I-Method
buffer	I-Method
was	O
first	O
introduced	O
by	O
lin1992self	O
and	O
later	O
used	O
in	O
DQN	O
mnih15human	O
.	O
	
Typically	O
,	O
the	O
replay	B-Method
buffer	I-Method
is	O
essentially	O
a	O
first	B-Method
-	I-Method
in	I-Method
-	I-Method
first	I-Method
-	I-Method
out	I-Method
queue	I-Method
with	O
new	O
transitions	O
gradually	O
replacing	O
older	O
transitions	O
.	O
	
The	O
agent	O
would	O
then	O
sample	O
a	O
mini	O
-	O
batch	O
uniformly	O
at	O
random	O
from	O
the	O
replay	O
buffer	O
.	O
	
Drawing	O
inspiration	O
from	O
prioritized	B-Method
sweeping	I-Method
moore1993prioritized	I-Method
,	O
prioritized	B-Method
experience	I-Method
replay	I-Method
replaces	O
the	O
uniform	B-Method
sampling	I-Method
with	O
prioritized	B-Method
sampling	I-Method
proportional	O
to	O
the	O
absolute	B-Metric
TD	I-Metric
error	I-Metric
schaul16prioritized	O
.	O
	
Specifically	O
,	O
for	O
a	O
replay	O
buffer	O
of	O
size	O
,	O
prioritized	O
experience	O
replay	O
samples	O
transition	O
with	O
probability	O
,	O
and	O
applies	O
weighted	B-Method
importance	I-Method
-	I-Method
sampling	I-Method
with	O
to	O
correct	O
for	O
the	O
prioritization	O
bias	O
,	O
where	O
Prioritized	B-Method
DQN	I-Method
significantly	O
increases	O
both	O
the	O
sample	B-Metric
-	I-Metric
efficiency	I-Metric
and	O
final	O
performance	O
over	O
DQN	B-Method
on	O
the	O
Atari	B-Material
2600	I-Material
benchmarks	I-Material
schaul2015prioritized	O
.	O
	
subsubsection	O
:	O
Retrace	B-Method
(	O
)	O
	
Retrace	B-Method
(	I-Method
)	I-Method
is	O
a	O
convergent	B-Method
off	I-Method
-	I-Method
policy	I-Method
multi	I-Method
-	I-Method
step	I-Method
algorithm	I-Method
extending	O
the	O
DQN	B-Method
agent	I-Method
munos2016safe	O
.	O
	
Assume	O
that	O
some	O
trajectory	O
has	O
been	O
generated	O
according	O
to	O
behaviour	O
policy	O
,	O
i.e.	O
,	O
.	O
	
Now	O
,	O
we	O
aim	O
to	O
evaluate	O
the	O
value	O
of	O
a	O
different	O
target	O
policy	O
,	O
i.e.	O
we	O
want	O
to	O
estimate	O
.	O
	
The	O
Retrace	B-Method
algorithm	I-Method
will	O
update	O
our	O
current	O
estimate	O
of	O
in	O
the	O
direction	O
of	O
where	O
is	O
the	O
temporal	O
difference	O
at	O
time	O
under	O
,	O
and	O
The	O
Retrace	B-Method
algorithm	I-Method
comes	O
with	O
the	O
theoretical	O
guarantee	O
that	O
in	O
finite	O
state	O
and	O
action	O
spaces	O
,	O
repeatedly	O
updating	O
our	O
current	O
estimate	O
according	O
to	O
(	O
[	O
reference	O
]	O
)	O
produces	O
a	O
sequence	O
of	O
Q	B-Method
functions	I-Method
which	O
converges	O
to	O
for	O
a	O
fixed	O
or	O
to	O
if	O
we	O
consider	O
a	O
sequence	O
of	O
policies	O
which	O
become	O
increasingly	O
greedy	O
w.r.t	O
.	O
	
the	O
estimates	O
munos2016safe	O
.	O
	
subsubsection	O
:	O
Distributional	B-Method
RL	I-Method
	
Distributional	B-Method
reinforcement	I-Method
learning	I-Method
refers	O
to	O
a	O
class	O
of	O
algorithms	O
that	O
directly	O
estimate	O
the	O
distribution	O
over	O
returns	O
,	O
whose	O
expectation	O
gives	O
the	O
traditional	O
value	O
function	O
bellemare2017distributional	O
.	O
	
Such	O
approaches	O
can	O
be	O
made	O
tractable	O
with	O
a	O
distributional	B-Method
Bellman	I-Method
equation	I-Method
,	O
and	O
the	O
recently	O
proposed	O
algorithm	O
showed	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
in	O
the	O
Atari	B-Material
2600	I-Material
benchmarks	I-Material
.	O
	
parameterizes	O
the	O
distribution	O
over	O
returns	O
with	O
a	O
mixture	B-Method
over	I-Method
Diracs	I-Method
centered	O
on	O
a	O
uniform	O
grid	O
,	O
with	O
hyperparameters	O
that	O
bound	O
the	O
distribution	O
support	O
of	O
size	O
.	O
	
subsection	O
:	O
Actor	B-Method
-	I-Method
critic	I-Method
algorithms	I-Method
	
In	O
this	O
section	O
we	O
review	O
the	O
actor	B-Method
-	I-Method
critic	I-Method
framework	I-Method
for	O
reinforcement	B-Method
learning	I-Method
algorithms	I-Method
and	O
then	O
discuss	O
recent	O
advances	O
in	O
actor	B-Method
-	I-Method
critic	I-Method
algorithms	I-Method
along	O
with	O
their	O
various	O
trade	O
-	O
offs	O
.	O
	
The	O
asynchronous	B-Method
advantage	I-Method
actor	I-Method
-	I-Method
critic	I-Method
(	I-Method
A3C	I-Method
)	I-Method
algorithm	I-Method
mnih2016asynchronous	I-Method
,	O
maintains	O
a	O
parameterized	B-Method
policy	I-Method
and	I-Method
value	I-Method
function	I-Method
,	O
which	O
are	O
updated	O
with	O
A3C	O
uses	O
parallel	B-Method
CPU	I-Method
workers	I-Method
,	O
each	O
acting	O
independently	O
in	O
the	O
environment	O
and	O
applying	O
the	O
above	O
updates	O
asynchronously	O
to	O
a	O
shared	O
set	O
of	O
parameters	O
.	O
	
In	O
contrast	O
to	O
the	O
previously	O
discussed	O
value	B-Method
-	I-Method
based	I-Method
methods	I-Method
,	O
A3C	B-Method
is	O
an	O
on	B-Method
-	I-Method
policy	I-Method
algorithm	I-Method
,	O
and	O
does	O
not	O
use	O
a	O
GPU	B-Method
nor	O
a	O
replay	B-Method
buffer	I-Method
.	O
	
Proximal	B-Method
Policy	I-Method
Optimization	I-Method
(	O
PPO	B-Method
)	O
is	O
a	O
closely	O
related	O
actor	B-Method
-	I-Method
critic	I-Method
algorithm	I-Method
schulman2017proximal	I-Method
,	O
which	O
replaces	O
the	O
advantage	O
pgadv	B-Method
with	O
,	O
where	O
is	O
as	O
defined	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Although	O
both	O
PPO	B-Method
and	O
A3C	O
run	O
parallel	B-Method
workers	I-Method
collecting	O
trajectories	O
independently	O
in	O
the	O
environment	O
,	O
PPO	B-Method
collects	O
these	O
experiences	O
to	O
perform	O
a	O
single	O
,	O
synchronous	O
,	O
update	O
in	O
contrast	O
with	O
the	O
asynchronous	B-Method
updates	I-Method
of	O
A3C.	O
Actor	B-Method
-	I-Method
Critic	I-Method
Experience	I-Method
Replay	I-Method
(	O
ACER	B-Method
)	I-Method
extends	O
the	O
A3C	B-Method
framework	I-Method
with	O
an	O
experience	B-Method
replay	I-Method
buffer	I-Method
,	O
Retrace	B-Method
algorithm	I-Method
for	O
off	B-Task
-	I-Task
policy	I-Task
corrections	I-Task
,	O
and	O
the	O
Truncated	B-Method
Importance	I-Method
Sampling	I-Method
Likelihood	I-Method
Ratio	I-Method
(	I-Method
TISLR	I-Method
)	I-Method
algorithm	I-Method
used	O
for	O
off	B-Task
-	I-Task
policy	I-Task
policy	I-Task
optimization	I-Task
wang2017sample	O
.	O
	
section	O
:	O
The	O
Reactor	B-Method
	
The	O
Reactor	B-Method
is	O
a	O
combination	O
of	O
four	O
novel	O
contributions	O
on	O
top	O
of	O
recent	O
improvements	O
to	O
both	O
deep	B-Method
value	I-Method
-	I-Method
based	I-Method
RL	I-Method
and	O
policy	B-Method
-	I-Method
gradient	I-Method
algorithms	I-Method
.	O
	
Each	O
contribution	O
moves	O
Reactor	B-Method
towards	O
our	O
goal	O
of	O
achieving	O
both	O
sample	B-Metric
and	I-Metric
time	I-Metric
efficiency	I-Metric
.	O
	
subsection	O
:	O
-	O
LOO	O
	
The	O
Reactor	B-Method
architecture	O
represents	O
both	O
a	O
policy	B-Method
and	I-Method
action	I-Method
-	I-Method
value	I-Method
function	I-Method
.	O
	
We	O
use	O
a	O
policy	B-Method
gradient	I-Method
algorithm	I-Method
to	O
train	O
the	O
actor	B-Method
which	O
makes	O
use	O
of	O
our	O
current	O
estimate	O
of	O
.	O
	
Let	O
be	O
the	O
value	O
function	O
at	O
some	O
initial	O
state	O
,	O
the	O
policy	B-Method
gradient	I-Method
theorem	I-Method
says	O
that	O
,	O
where	O
refers	O
to	O
the	O
gradient	O
w.r.t	O
.	O
policy	O
parameters	O
Sutton00policygradient	O
.	O
	
We	O
now	O
consider	O
several	O
possible	O
ways	O
to	O
estimate	O
this	O
gradient	O
.	O
	
To	O
simplify	O
notation	O
,	O
we	O
drop	O
the	O
dependence	O
on	O
the	O
state	O
for	O
now	O
and	O
consider	O
the	O
problem	O
of	O
estimating	O
the	O
quantity	O
In	O
the	O
off	B-Task
-	I-Task
policy	I-Task
case	I-Task
,	O
we	O
consider	O
estimating	O
using	O
a	O
single	O
action	O
drawn	O
from	O
a	O
(	O
possibly	O
different	O
from	O
)	O
behaviour	O
distribution	O
.	O
	
Let	O
us	O
assume	O
that	O
for	O
the	O
chosen	O
action	O
we	O
have	O
access	O
to	O
an	O
unbiased	O
estimate	O
of	O
.	O
	
Then	O
,	O
we	O
can	O
use	O
likelihood	B-Method
ratio	I-Method
(	I-Method
LR	I-Method
)	I-Method
method	I-Method
combined	O
with	O
an	O
importance	B-Method
sampling	I-Method
(	I-Method
IS	I-Method
)	I-Method
ratio	I-Method
(	O
which	O
we	O
call	O
ISLR	B-Method
)	O
to	O
build	O
an	O
unbiased	O
estimate	O
of	O
:	O
where	O
is	O
a	O
baseline	O
that	O
depends	O
on	O
the	O
state	O
but	O
not	O
on	O
the	O
chosen	O
action	O
.	O
	
However	O
this	O
estimate	O
suffers	O
from	O
high	O
variance	O
.	O
	
A	O
possible	O
way	O
for	O
reducing	O
variance	B-Metric
is	O
to	O
estimate	O
directly	O
from	O
(	O
[	O
reference	O
]	O
)	O
by	O
using	O
the	O
return	O
for	O
the	O
chosen	O
action	O
and	O
our	O
current	O
estimate	O
of	O
for	O
the	O
other	O
actions	O
,	O
which	O
leads	O
to	O
the	O
so	O
-	O
called	O
leave	B-Method
-	I-Method
one	I-Method
-	I-Method
out	I-Method
(	I-Method
LOO	I-Method
)	I-Method
policy	I-Method
-	I-Method
gradient	I-Method
estimate	I-Method
:	O
This	O
estimate	O
has	O
low	O
variance	O
but	O
may	O
be	O
biased	O
if	O
the	O
estimated	O
values	O
differ	O
from	O
.	O
	
A	O
better	O
bias	B-Metric
-	I-Metric
variance	I-Metric
tradeoff	I-Metric
may	O
be	O
obtained	O
by	O
the	O
more	O
general	B-Method
-	I-Method
LOO	I-Method
policy	I-Method
-	I-Method
gradient	I-Method
estimate	I-Method
:	O
where	O
can	O
be	O
a	O
function	O
of	O
both	O
policies	O
,	O
and	O
,	O
and	O
the	O
selected	O
action	O
.	O
	
Notice	O
that	O
when	O
,	O
(	O
[	O
reference	O
]	O
)	O
reduces	O
to	O
(	O
[	O
reference	O
]	O
)	O
,	O
and	O
when	O
,	O
then	O
(	O
[	O
reference	O
]	O
)	O
	
is	O
This	O
estimate	O
is	O
unbiased	O
and	O
can	O
be	O
seen	O
as	O
a	O
generalization	O
of	O
where	O
instead	O
of	O
using	O
a	O
state	O
-	O
only	O
dependent	O
baseline	O
,	O
we	O
use	O
a	O
state	O
-	O
and	O
-	O
action	O
-	O
dependent	O
baseline	O
(	O
our	O
current	O
estimate	O
)	O
and	O
add	O
the	O
correction	B-Method
term	I-Method
to	O
cancel	O
the	O
bias	O
.	O
	
Proposition	O
[	O
reference	O
]	O
gives	O
our	O
analysis	O
of	O
the	O
bias	O
of	O
,	O
with	O
a	O
proof	O
left	O
to	O
the	O
Appendix	O
.	O
	
propositionpropbias	O
Assume	O
and	O
that	O
.	O
	
Then	O
,	O
the	O
bias	O
of	O
is	O
.	O
	
Thus	O
the	O
bias	O
is	O
small	O
when	O
is	O
close	O
to	O
,	O
or	O
when	O
the	O
-	O
estimates	O
are	O
close	O
to	O
the	O
true	O
values	O
,	O
and	O
unbiased	O
regardless	O
of	O
the	O
estimates	O
if	O
.	O
	
The	O
variance	O
is	O
low	O
when	O
is	O
small	O
,	O
therefore	O
,	O
in	O
order	O
to	O
improve	O
the	O
bias	B-Metric
-	I-Metric
variance	I-Metric
tradeoff	I-Metric
we	O
recommend	O
using	O
the	O
-	B-Method
LOO	I-Method
estimate	I-Method
with	O
defined	O
as	O
:	O
for	O
some	O
constant	O
.	O
	
This	O
truncated	O
coefficient	O
shares	O
similarities	O
with	O
the	O
truncated	B-Method
IS	I-Method
gradient	I-Method
estimate	I-Method
introduced	O
in	O
wang2017sample	O
(	O
which	O
we	O
call	O
TISLR	B-Method
for	O
truncated	B-Method
-	I-Method
ISLR	I-Method
)	O
:	O
	
The	O
differences	O
are	O
:	O
(	O
i	O
)	O
we	O
truncate	O
instead	O
of	O
truncating	B-Method
,	O
which	O
provides	O
an	O
additional	O
variance	B-Metric
reduction	I-Metric
due	O
to	O
the	O
variance	O
of	O
the	O
LR	B-Method
(	O
since	O
this	O
LR	B-Method
may	O
be	O
large	O
when	O
a	O
low	O
probability	O
action	O
is	O
chosen	O
)	O
,	O
and	O
(	O
ii	O
)	O
we	O
use	O
our	O
-	O
baseline	O
instead	O
of	O
a	O
baseline	O
,	O
reducing	O
further	O
the	O
variance	O
of	O
the	O
LR	B-Method
estimate	I-Method
.	O
	
subsection	O
:	O
Distributional	B-Task
Retrace	I-Task
	
In	O
off	B-Task
-	I-Task
policy	I-Task
learning	I-Task
it	O
is	O
very	O
difficult	O
to	O
produce	O
an	O
unbiased	O
sample	O
of	O
when	O
following	O
another	O
policy	O
.	O
	
This	O
would	O
require	O
using	O
full	O
importance	B-Method
sampling	I-Method
correction	I-Method
along	O
the	O
trajectory	O
.	O
	
Instead	O
,	O
we	O
use	O
the	O
off	O
-	O
policy	O
corrected	O
return	O
computed	O
by	O
the	O
Retrace	B-Method
algorithm	I-Method
,	O
which	O
produces	O
a	O
(	O
biased	O
)	O
estimate	O
of	O
but	O
whose	O
bias	O
vanishes	O
asymptotically	O
munos2016safe	O
.	O
	
In	O
Reactor	B-Method
,	O
we	O
consider	O
predicting	O
an	O
approximation	O
of	O
the	O
return	B-Method
distribution	I-Method
function	I-Method
from	O
any	O
state	O
-	O
action	O
pair	O
in	O
a	O
similar	O
way	O
as	O
in	O
bellemare2017distributional	O
.	O
	
The	O
original	O
algorithm	O
C51	O
described	O
in	O
that	O
paper	O
considered	O
single	O
-	O
step	O
Bellman	B-Method
updates	I-Method
only	O
.	O
	
Here	O
we	O
need	O
to	O
extend	O
this	O
idea	O
to	O
multi	B-Task
-	I-Task
step	I-Task
updates	I-Task
and	O
handle	O
the	O
off	B-Task
-	I-Task
policy	I-Task
correction	I-Task
performed	O
by	O
the	O
Retrace	B-Method
algorithm	I-Method
,	O
as	O
defined	O
in	O
eq	O
:	O
retrace	B-Method
.	O
	
Next	O
,	O
we	O
describe	O
these	O
two	O
extensions	O
.	O
	
paragraph	O
:	O
Multi	B-Method
-	I-Method
step	I-Method
distributional	I-Method
Bellman	I-Method
operator	I-Method
:	O
	
First	O
,	O
we	O
extend	O
C51	B-Method
to	O
multi	O
-	O
step	O
Bellman	B-Task
backups	I-Task
.	O
	
We	O
consider	O
return	O
-	O
distributions	O
from	O
of	O
the	O
form	O
(	O
where	O
denotes	O
a	O
Dirac	O
in	O
)	O
which	O
are	O
supported	O
on	O
a	O
finite	O
uniform	O
grid	O
,	O
,	O
,	O
.	O
	
The	O
coefficients	O
(	O
discrete	O
distribution	O
)	O
corresponds	O
to	O
the	O
probabilities	O
assigned	O
to	O
each	O
atom	O
of	O
the	O
grid	O
.	O
	
From	O
an	O
observed	O
-	O
step	O
sequence	O
,	O
generated	O
by	O
behavior	B-Method
policy	I-Method
(	O
i.e	O
,	O
for	O
)	O
,	O
we	O
build	O
the	O
-	B-Method
step	I-Method
backed	I-Method
-	I-Method
up	I-Method
return	I-Method
-	I-Method
distribution	I-Method
from	O
.	O
	
The	O
-	O
step	O
distributional	O
Bellman	O
target	O
,	O
whose	O
expectation	O
is	O
,	O
is	O
given	O
by	O
:	O
Since	O
this	O
distribution	O
is	O
supported	O
on	O
the	O
set	O
of	O
atoms	O
,	O
which	O
is	O
not	O
necessarily	O
aligned	O
with	O
the	O
grid	O
,	O
we	O
do	O
a	O
projection	B-Method
step	I-Method
and	O
minimize	O
the	O
KL	B-Metric
-	I-Metric
loss	I-Metric
between	O
the	O
projected	O
target	O
and	O
the	O
current	O
estimate	O
,	O
just	O
as	O
with	O
C51	O
except	O
with	O
a	O
different	O
target	O
distribution	O
bellemare2017distributional	O
.	O
	
paragraph	O
:	O
Distributional	O
Retrace	O
:	O
	
Now	O
,	O
the	O
Retrace	B-Method
algorithm	I-Method
defined	O
in	O
eq	O
:	O
retrace	B-Method
involves	O
an	O
off	B-Method
-	I-Method
policy	I-Method
correction	I-Method
which	O
is	O
not	O
handled	O
by	O
the	O
previous	O
-	O
step	O
distributional	B-Method
Bellman	I-Method
backup	I-Method
.	O
	
The	O
key	O
to	O
extending	O
this	O
distributional	B-Task
back	I-Task
-	I-Task
up	I-Task
to	O
off	B-Task
-	I-Task
policy	I-Task
learning	I-Task
is	O
to	O
rewrite	O
the	O
Retrace	B-Method
algorithm	I-Method
as	O
a	O
linear	B-Method
combination	I-Method
of	I-Method
-	I-Method
step	I-Method
Bellman	I-Method
backups	I-Method
,	O
weighted	O
by	O
some	O
coefficients	O
.	O
	
Indeed	O
,	O
notice	O
that	O
eq	O
:	O
retrace	O
rewrites	O
as	O
where	O
.	O
	
These	O
coefficients	O
depend	O
on	O
the	O
degree	O
of	O
off	O
-	O
policy	O
-	O
ness	O
(	O
between	O
and	O
)	O
along	O
the	O
trajectory	O
.	O
	
We	O
have	O
that	O
,	O
but	O
notice	O
some	O
coefficients	O
may	O
be	O
negative	O
.	O
	
However	O
,	O
in	O
expectation	O
(	O
over	O
the	O
behavior	B-Method
policy	I-Method
)	O
they	O
are	O
non	O
-	O
negative	O
.	O
	
Indeed	O
,	O
by	O
definition	O
of	O
the	O
coefficients	O
eq	O
:	O
trace.cut	O
.	O
	
Thus	O
in	O
expectation	O
(	O
over	O
the	O
behavior	O
policy	O
)	O
,	O
the	O
Retrace	B-Method
update	I-Method
can	O
be	O
seen	O
as	O
a	O
convex	B-Method
combination	I-Method
of	I-Method
-	I-Method
step	I-Method
Bellman	I-Method
updates	I-Method
.	O
	
Then	O
,	O
the	O
distributional	B-Method
Retrace	I-Method
algorithm	I-Method
can	O
be	O
defined	O
as	O
backing	O
up	O
a	O
mixture	B-Method
of	I-Method
-	I-Method
step	I-Method
distributions	I-Method
.	O
	
More	O
precisely	O
,	O
we	O
define	O
the	O
Retrace	O
target	O
distribution	O
as	O
:	O
where	O
is	O
a	O
linear	B-Method
interpolation	I-Method
kernel	I-Method
,	O
projecting	O
onto	O
the	O
support	O
:	O
We	O
update	O
the	O
current	O
probabilities	O
by	O
performing	O
a	O
gradient	B-Method
step	I-Method
on	O
the	O
KL	B-Method
-	I-Method
loss	I-Method
	
Again	O
,	O
notice	O
that	O
some	O
target	O
	
‘	O
	
‘	O
probabilities	O
’	O
’	O
may	O
be	O
negative	O
for	O
some	O
sample	O
trajectory	O
,	O
but	O
in	O
expectation	O
they	O
will	O
be	O
non	O
-	O
negative	O
.	O
	
Since	O
the	O
gradient	O
of	O
a	O
KL	B-Method
-	I-Method
loss	I-Method
is	O
linear	O
w.r.t	O
.	O
	
its	O
first	O
argument	O
,	O
our	O
update	B-Method
rule	I-Method
eq	I-Method
:	O
	
kl.gradient	B-Method
provides	O
an	O
unbiased	O
estimate	O
of	O
the	O
gradient	O
of	O
the	O
KL	O
between	O
the	O
expected	O
(	O
over	O
the	O
behavior	B-Method
policy	I-Method
)	O
Retrace	O
target	O
distribution	O
and	O
the	O
current	O
predicted	O
distribution	O
.	O
	
paragraph	O
:	O
Remark	O
:	O
	
The	O
same	O
method	O
can	O
be	O
applied	O
to	O
other	O
algorithms	O
(	O
such	O
as	O
TB	B-Method
(	I-Method
)	I-Method
precup2000eligibility	O
and	O
importance	B-Method
sampling	I-Method
precup01offpolicy	I-Method
)	O
in	O
order	O
to	O
derive	O
distributional	B-Method
versions	I-Method
of	O
other	O
off	B-Method
-	I-Method
policy	I-Method
multi	I-Method
-	I-Method
step	I-Method
RL	I-Method
algorithms	I-Method
.	O
	
subsection	O
:	O
Prioritized	B-Task
sequence	I-Task
replay	I-Task
	
Prioritized	B-Task
experience	I-Task
replay	I-Task
has	O
been	O
shown	O
to	O
boost	O
both	O
statistical	B-Metric
efficiency	I-Metric
and	O
final	O
performance	O
of	O
deep	B-Method
RL	I-Method
agents	I-Method
schaul16prioritized	O
.	O
	
However	O
,	O
as	O
originally	O
defined	O
prioritized	B-Method
replay	I-Method
does	O
not	O
handle	O
sequences	O
of	O
transitions	O
and	O
weights	O
all	O
unsampled	O
transitions	O
identically	O
.	O
	
In	O
this	O
section	O
we	O
present	O
an	O
alternative	O
initialization	B-Method
strategy	I-Method
,	O
called	O
lazy	B-Method
initialization	I-Method
,	O
and	O
argue	O
that	O
it	O
better	O
encodes	O
prior	O
information	O
about	O
temporal	O
difference	O
errors	O
.	O
	
We	O
then	O
briefly	O
describe	O
our	O
computationally	O
efficient	O
prioritized	B-Method
sequence	I-Method
sampling	I-Method
algorithm	I-Method
,	O
with	O
full	O
details	O
left	O
to	O
the	O
appendix	O
.	O
	
It	O
is	O
widely	O
recognized	O
that	O
TD	O
errors	O
tend	O
to	O
be	O
temporally	O
correlated	O
	
,	O
indeed	O
the	O
need	O
to	O
break	O
this	O
temporal	O
correlation	O
has	O
been	O
one	O
of	O
the	O
primary	O
justifications	O
for	O
the	O
use	O
of	O
experience	B-Task
replay	I-Task
mnih15human	O
.	O
	
Our	O
proposed	O
algorithm	O
begins	O
with	O
this	O
fundamental	O
assumption	O
.	O
	
theorem	O
:	O
.	O
	
Temporal	O
differences	O
are	O
temporally	O
correlated	O
,	O
with	O
correlation	O
decaying	O
on	O
average	O
with	O
the	O
time	O
-	O
difference	O
between	O
two	O
transitions	O
.	O
	
Prioritized	B-Method
experience	I-Method
replay	I-Method
adds	O
new	O
transitions	O
to	O
the	O
replay	O
buffer	O
with	O
a	O
constant	O
priority	O
,	O
but	O
given	O
the	O
above	O
assumption	O
we	O
can	O
devise	O
a	O
better	O
method	O
.	O
	
Specifically	O
,	O
we	O
propose	O
to	O
add	O
experience	O
to	O
the	O
buffer	O
with	O
no	O
priority	O
,	O
inserting	O
a	O
priority	O
only	O
after	O
the	O
transition	O
has	O
been	O
sampled	O
and	O
used	O
for	O
training	O
.	O
	
Also	O
,	O
instead	O
of	O
sampling	O
transitions	O
,	O
we	O
assign	O
priorities	O
to	O
all	O
(	O
overlapping	O
)	O
sequences	O
of	O
length	O
.	O
	
When	O
sampling	O
,	O
sequences	O
with	O
an	O
assigned	O
priority	O
are	O
sampled	O
proportionally	O
to	O
that	O
priority	O
.	O
	
Sequences	O
with	O
no	O
assigned	O
priority	O
are	O
sampled	O
proportionally	O
to	O
the	O
average	O
priority	O
of	O
assigned	O
priority	O
sequences	O
within	O
some	O
local	O
neighbourhood	O
.	O
	
Averages	B-Method
are	O
weighted	O
to	O
compensate	O
for	O
sampling	O
biases	O
(	O
i.e.	O
more	O
samples	O
are	O
made	O
in	O
areas	O
of	O
high	O
estimated	O
priorities	O
,	O
and	O
in	O
the	O
absence	O
of	O
weighting	O
this	O
would	O
lead	O
to	O
overestimation	O
of	O
unassigned	O
priorities	O
)	O
.	O
	
The	O
lazy	B-Method
initialization	I-Method
scheme	I-Method
starts	O
with	O
priorities	O
corresponding	O
to	O
the	O
sequences	O
for	O
which	O
a	O
priority	O
was	O
already	O
assigned	O
.	O
	
Then	O
it	O
extrapolates	O
a	O
priority	O
of	O
all	O
other	O
sequences	O
in	O
the	O
following	O
way	O
.	O
	
Let	O
us	O
define	O
a	O
partition	O
of	O
the	O
states	O
ordered	O
by	O
increasing	O
time	O
such	O
that	O
each	O
cell	O
contains	O
exactly	O
one	O
state	O
with	O
already	O
assigned	O
priority	O
.	O
	
We	O
define	O
the	O
estimated	O
priority	O
to	O
all	O
other	O
sequences	O
as	O
,	O
where	O
is	O
a	O
collection	O
of	O
contiguous	O
cells	O
containing	O
time	O
,	O
and	O
is	O
the	O
length	O
of	O
the	O
cell	O
containing	O
.	O
	
For	O
already	O
defined	O
priorities	O
denote	O
.	O
	
Cell	O
sizes	O
work	O
as	O
estimates	O
of	O
inverse	O
local	O
density	O
and	O
are	O
used	O
as	O
importance	O
weights	O
for	O
priority	B-Task
estimation	I-Task
.	O
	
For	O
the	O
algorithm	O
to	O
be	O
unbiased	O
,	O
partition	O
must	O
not	O
be	O
a	O
function	O
of	O
the	O
assigned	O
priorities	O
.	O
	
So	O
far	O
we	O
have	O
defined	O
a	O
class	O
of	O
algorithms	O
all	O
free	O
to	O
choose	O
the	O
partition	O
and	O
the	O
collection	O
of	O
cells	O
,	O
as	O
long	O
that	O
they	O
satisfy	O
the	O
above	O
constraints	O
.	O
	
Figure	O
[	O
reference	O
]	O
in	O
the	O
Appendix	O
illustrates	O
the	O
above	O
description	O
.	O
	
Now	O
,	O
with	O
probability	O
we	O
sample	O
uniformly	O
at	O
random	O
,	O
and	O
with	O
probability	O
we	O
sample	O
proportionally	O
to	O
.	O
	
We	O
implemented	O
an	O
algorithm	O
satisfying	O
the	O
above	O
constraints	O
and	O
called	O
it	O
Contextual	B-Method
Priority	I-Method
Tree	I-Method
(	O
CPT	B-Method
)	O
.	O
	
It	O
is	O
based	O
on	O
AVL	B-Method
trees	I-Method
velskii1976avl	O
and	O
can	O
execute	O
sampling	B-Method
,	O
insertion	B-Method
,	O
deletion	B-Method
and	O
density	B-Method
evaluation	I-Method
in	O
time	O
.	O
	
We	O
describe	O
CPT	O
in	O
detail	O
in	O
the	O
Appendix	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
We	O
treated	O
prioritization	B-Method
as	O
purely	O
a	O
variance	B-Method
reduction	I-Method
technique	I-Method
.	O
	
Importance	O
-	O
sampling	O
weights	O
were	O
evaluated	O
as	O
in	O
prioritized	B-Task
experience	I-Task
replay	I-Task
,	O
with	O
fixed	O
in	O
(	O
[	O
reference	O
]	O
)	O
.	O
	
We	O
used	O
simple	O
gradient	B-Method
magnitude	I-Method
estimates	I-Method
as	O
priorities	O
,	O
corresponding	O
to	O
a	O
mean	B-Metric
absolute	I-Metric
TD	I-Metric
error	I-Metric
along	O
a	O
sequence	O
for	O
Retrace	B-Task
,	O
as	O
defined	O
in	O
(	O
[	O
reference	O
]	O
)	O
for	O
the	O
classical	B-Task
RL	I-Task
case	I-Task
,	O
and	O
total	O
variation	O
in	O
the	O
distributional	B-Task
Retrace	I-Task
case	I-Task
.	O
	
subsection	O
:	O
Agent	B-Method
architecture	I-Method
	
In	O
order	O
to	O
improve	O
CPU	O
utilization	O
we	O
decoupled	O
acting	O
from	O
learning	B-Task
.	O
	
This	O
is	O
an	O
important	O
aspect	O
of	O
our	O
architecture	O
:	O
an	O
acting	B-Method
thread	I-Method
receives	O
observations	O
,	O
submits	O
actions	O
to	O
the	O
environment	O
,	O
and	O
stores	O
transitions	O
in	O
memory	O
,	O
while	O
a	O
learning	B-Method
thread	I-Method
re	O
-	O
samples	O
sequences	O
of	O
experiences	O
from	O
memory	O
and	O
trains	O
on	O
them	O
(	O
Figure	O
[	O
reference	O
]	O
,	O
left	O
)	O
.	O
	
We	O
typically	O
execute	O
4	O
-	O
6	O
acting	O
steps	O
per	O
each	O
learning	O
step	O
.	O
	
We	O
sample	O
sequences	O
of	O
length	O
in	O
batches	O
of	O
4	O
.	O
	
A	O
moving	B-Method
network	I-Method
is	O
unrolled	O
over	O
frames	O
1	O
-	O
32	O
while	O
the	O
target	O
network	O
is	O
unrolled	O
over	O
frames	O
2	O
-	O
33	O
.	O
	
We	O
allow	O
the	O
agent	O
to	O
be	O
distributed	O
over	O
multiple	O
machines	O
each	O
containing	O
action	O
-	O
learner	O
pairs	O
.	O
	
Each	O
worker	O
downloads	O
the	O
newest	O
network	O
parameters	O
before	O
each	O
learning	O
step	O
and	O
sends	O
delta	O
-	O
updates	O
at	O
the	O
end	O
of	O
it	O
.	O
	
Both	O
the	O
network	O
and	O
target	O
network	O
are	O
stored	O
on	O
a	O
shared	O
parameter	O
server	O
while	O
each	O
machine	O
contains	O
its	O
own	O
local	O
replay	O
memory	O
.	O
	
Training	B-Task
is	O
done	O
by	O
downloading	O
a	O
shared	B-Method
network	I-Method
,	O
evaluating	O
local	O
gradients	O
and	O
sending	O
them	O
to	O
be	O
applied	O
on	O
the	O
shared	B-Method
network	I-Method
.	O
	
While	O
the	O
agent	O
can	O
also	O
be	O
trained	O
on	O
a	O
single	O
machine	O
,	O
in	O
this	O
work	O
we	O
present	O
results	O
of	O
training	O
obtained	O
with	O
either	O
10	O
or	O
20	O
actor	B-Method
-	I-Method
learner	I-Method
workers	I-Method
and	O
one	O
parameter	B-Method
server	I-Method
.	O
	
In	O
Figure	O
[	O
reference	O
]	O
(	O
right	O
)	O
we	O
compare	O
resources	O
and	O
runtimes	O
of	O
Reactor	B-Method
with	O
related	O
algorithms	O
.	O
	
subsubsection	O
:	O
Network	B-Method
architecture	I-Method
	
In	O
some	O
domains	O
,	O
such	O
as	O
Atari	B-Material
,	O
it	O
is	O
useful	O
to	O
base	O
decisions	O
on	O
a	O
short	O
history	O
of	O
past	O
observations	O
.	O
	
The	O
two	O
techniques	O
generally	O
used	O
to	O
achieve	O
this	O
are	O
frame	B-Method
stacking	I-Method
and	O
recurrent	B-Method
network	I-Method
architectures	I-Method
.	O
	
We	O
chose	O
the	O
latter	O
over	O
the	O
former	O
for	O
reasons	O
of	O
implementation	B-Metric
simplicity	I-Metric
and	O
computational	B-Metric
efficiency	I-Metric
.	O
	
As	O
the	O
Retrace	B-Method
algorithm	I-Method
requires	O
evaluating	O
action	O
-	O
values	O
over	O
contiguous	O
sequences	O
of	O
trajectories	O
,	O
using	O
a	O
recurrent	B-Method
architecture	I-Method
allowed	O
each	O
frame	O
to	O
be	O
processed	O
by	O
the	O
convolutional	B-Method
network	I-Method
only	O
once	O
,	O
as	O
opposed	O
to	O
times	O
times	O
if	O
frame	O
concatenations	O
were	O
used	O
.	O
	
The	O
Reactor	B-Method
architecture	O
uses	O
a	O
recurrent	B-Method
neural	I-Method
network	I-Method
which	O
takes	O
an	O
observation	O
as	O
input	O
and	O
produces	O
two	O
outputs	O
:	O
categorical	O
action	O
-	O
value	O
distributions	O
(	O
here	O
is	O
a	O
bin	O
identifier	O
)	O
,	O
and	O
policy	O
probabilities	O
.	O
	
We	O
use	O
an	O
architecture	O
inspired	O
by	O
the	O
duelling	B-Method
network	I-Method
architecture	I-Method
wang2015dueling	O
.	O
	
We	O
split	O
action	O
-	O
value	O
-	O
distribution	O
logits	O
into	O
state	O
-	O
value	O
logits	O
and	O
advantage	O
logits	O
,	O
which	O
in	O
turn	O
are	O
connected	O
to	O
the	O
same	O
LSTM	B-Method
network	I-Method
hochreiter1997long	O
.	O
	
Final	O
action	O
-	O
value	O
logits	O
are	O
produced	O
by	O
summing	O
state	O
-	O
and	O
action	O
-	O
specific	O
logits	O
,	O
as	O
in	O
wang2015dueling	O
.	O
	
Finally	O
,	O
a	O
softmax	B-Method
layer	I-Method
on	O
top	O
for	O
each	O
action	O
produces	O
the	O
distributions	O
over	O
discounted	O
future	O
returns	O
.	O
	
The	O
policy	B-Method
head	I-Method
uses	O
a	O
softmax	B-Method
layer	I-Method
mixed	O
with	O
a	O
fixed	O
uniform	O
distribution	O
over	O
actions	O
,	O
where	O
this	O
mixing	O
ratio	O
is	O
a	O
hyperparameter	O
[	O
Section	O
5.1.3	O
]	O
wiering1999explorations	O
.	O
	
Policy	B-Method
and	I-Method
Q	I-Method
-	I-Method
networks	I-Method
have	O
separate	O
LSTMs	B-Method
.	O
	
Both	O
LSTMs	B-Method
are	O
connected	O
to	O
a	O
shared	B-Method
linear	I-Method
layer	I-Method
which	O
is	O
connected	O
to	O
a	O
shared	B-Method
convolutional	I-Method
neural	I-Method
network	I-Method
krizhevsky2012imagenet	I-Method
.	O
	
The	O
precise	O
network	O
specification	O
is	O
given	O
in	O
Table	O
[	O
reference	O
]	O
in	O
the	O
Appendix	O
.	O
	
Gradients	O
coming	O
from	O
the	O
policy	B-Method
LSTM	I-Method
are	O
blocked	O
and	O
only	O
gradients	O
originating	O
from	O
the	O
Q	B-Method
-	I-Method
network	I-Method
LSTM	I-Method
are	O
allowed	O
to	O
back	O
-	O
propagate	O
into	O
the	O
convolutional	B-Method
neural	I-Method
network	I-Method
.	O
	
We	O
block	O
gradients	O
from	O
the	O
policy	O
head	O
for	O
increased	O
stability	O
,	O
as	O
this	O
avoids	O
positive	O
feedback	O
loops	O
between	O
and	O
caused	O
by	O
shared	O
representations	O
.	O
	
We	O
used	O
the	O
Adam	B-Method
optimiser	I-Method
kingma2014adam	O
,	O
with	O
a	O
learning	B-Metric
rate	I-Metric
of	O
and	O
zero	O
momentum	O
because	O
asynchronous	O
updates	O
induce	O
implicit	O
momentum	O
mitliagkas2016asynchrony	O
.	O
	
Further	O
discussion	O
of	O
hyperparameters	O
and	O
their	O
optimization	B-Task
can	O
be	O
found	O
in	O
Appendix	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
Experimental	O
Results	O
	
We	O
trained	O
and	O
evaluated	O
Reactor	B-Method
on	O
57	O
Atari	B-Material
games	O
bellemare2013arcade	O
.	O
	
Figure	O
[	O
reference	O
]	O
compares	O
the	O
performance	O
of	O
Reactor	B-Method
with	O
different	O
versions	O
of	O
Reactor	B-Method
each	O
time	O
leaving	O
one	O
of	O
the	O
algorithmic	O
improvements	O
out	O
.	O
	
We	O
can	O
see	O
that	O
each	O
of	O
the	O
algorithmic	O
improvements	O
(	O
Distributional	B-Method
retrace	I-Method
,	O
beta	B-Method
-	I-Method
LOO	I-Method
and	O
prioritized	B-Method
replay	I-Method
)	O
contributed	O
to	O
the	O
final	O
results	O
.	O
	
While	O
prioritization	B-Method
was	O
arguably	O
the	O
most	O
important	O
component	O
,	O
Beta	B-Method
-	I-Method
LOO	I-Method
clearly	O
outperformed	O
TISLR	B-Method
algorithm	I-Method
.	O
	
Although	O
distributional	B-Method
and	I-Method
non	I-Method
-	I-Method
distributional	I-Method
versions	I-Method
performed	O
similarly	O
in	O
terms	O
of	O
median	B-Metric
human	I-Metric
normalized	I-Metric
scores	I-Metric
,	O
distributional	B-Method
version	I-Method
of	O
the	O
algorithm	O
generalized	O
better	O
when	O
tested	O
with	O
random	O
human	O
starts	O
(	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
subsection	O
:	O
Comparing	O
to	O
prior	O
work	O
	
We	O
evaluated	O
Reactor	B-Method
with	O
target	O
update	O
frequency	O
,	O
and	O
-	O
LOO	O
with	O
on	O
57	O
Atari	B-Material
games	O
trained	O
on	O
10	O
machines	O
in	O
parallel	O
.	O
	
We	O
averaged	O
scores	O
over	O
200	O
episodes	O
using	O
30	O
random	O
human	O
starts	O
and	O
noop	O
starts	O
(	O
Tables	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
in	O
the	O
Appendix	O
)	O
.	O
	
We	O
calculated	O
mean	O
and	O
median	O
human	O
normalised	O
scores	O
across	O
all	O
games	O
.	O
	
We	O
also	O
ranked	O
all	O
algorithms	O
(	O
including	O
random	O
and	O
human	O
scores	O
)	O
for	O
each	O
game	O
and	O
evaluated	O
mean	B-Metric
rank	I-Metric
of	O
each	O
algorithm	O
across	O
all	O
57	O
Atari	B-Material
games	O
.	O
	
We	O
also	O
evaluated	O
mean	O
	
Rank	B-Metric
and	O
Elo	B-Metric
scores	I-Metric
for	O
each	O
algorithm	O
for	O
both	O
human	O
and	O
noop	O
start	O
settings	O
.	O
	
Please	O
refer	O
to	O
Section	O
[	O
reference	O
]	O
in	O
the	O
Appendix	O
for	O
more	O
details	O
.	O
	
Tables	O
[	O
reference	O
]	O
&	O
[	O
reference	O
]	O
compare	O
versions	O
of	O
our	O
algorithm	O
,	O
with	O
several	O
other	O
state	O
-	O
of	O
-	O
art	O
algorithms	O
across	O
57	O
Atari	B-Material
games	O
for	O
a	O
fixed	O
random	O
seed	O
across	O
all	O
games	O
bellemare2013arcade	O
.	O
	
We	O
compare	O
Reactor	B-Method
against	O
are	O
:	O
DQN	B-Method
mnih15human	O
,	O
Double	B-Method
DQN	I-Method
van2016deep	O
,	O
DQN	B-Method
with	I-Method
prioritised	I-Method
experience	I-Method
replay	I-Method
schaul2015prioritized	O
,	O
dueling	B-Method
architecture	I-Method
and	I-Method
prioritised	I-Method
dueling	I-Method
wang2015dueling	O
,	O
ACER	B-Method
wang2017sample	O
,	O
A3C	B-Method
mnih2016asynchronous	O
,	O
and	O
Rainbow	B-Method
rainbow	I-Method
.	O
	
Each	O
algorithm	O
was	O
exposed	O
to	O
200	O
million	O
frames	O
of	O
experience	O
,	O
or	O
500	O
million	O
frames	O
when	O
followed	O
by	O
,	O
and	O
the	O
same	O
pre	B-Method
-	I-Method
processing	I-Method
pipeline	I-Method
including	O
4	O
action	O
repeats	O
was	O
used	O
as	O
in	O
the	O
original	O
DQN	O
paper	O
mnih15human	O
.	O
	
In	O
Table	O
[	O
reference	O
]	O
,	O
we	O
see	O
that	O
Reactor	B-Method
exceeds	O
the	O
performance	O
of	O
all	O
algorithms	O
across	O
all	O
metrics	O
,	O
despite	O
requiring	O
under	O
two	O
days	O
of	O
training	O
.	O
	
With	O
500	O
million	O
frames	O
and	O
four	O
days	O
training	O
we	O
see	O
Reactor	B-Method
’s	O
performance	O
continue	O
to	O
improve	O
significantly	O
.	O
	
The	O
difference	O
in	O
time	B-Metric
-	I-Metric
efficiency	I-Metric
is	O
especially	O
apparent	O
when	O
comparing	O
Reactor	B-Method
and	O
Rainbow	O
	
(	O
see	O
Figure	O
[	O
reference	O
]	O
,	O
right	O
)	O
.	O
	
Additionally	O
,	O
unlike	O
Rainbow	B-Method
,	O
Reactor	B-Method
does	O
not	O
use	O
Noisy	B-Method
Networks	I-Method
fortunato2017noisy	O
,	O
which	O
was	O
reported	O
to	O
have	O
contributed	O
to	O
the	O
performance	O
gains	O
.	O
	
When	O
evaluating	O
under	O
the	O
no	O
-	O
op	O
starts	O
regime	O
(	O
Table	O
[	O
reference	O
]	O
)	O
,	O
Reactor	B-Method
out	O
performs	O
all	O
methods	O
except	O
for	O
Rainbow	B-Method
.	O
	
This	O
suggests	O
that	O
Rainbow	B-Method
is	O
more	O
sample	O
-	O
efficient	O
when	O
training	O
and	O
evaluation	O
regimes	O
match	O
exactly	O
,	O
but	O
may	O
be	O
overfitting	O
to	O
particular	O
trajectories	O
due	O
to	O
the	O
significant	O
drop	O
in	O
performance	O
when	O
evaluated	O
on	O
the	O
random	O
human	O
starts	O
.	O
	
Regarding	O
ACER	B-Method
,	O
another	O
Retrace	B-Method
-	I-Method
based	I-Method
actor	I-Method
-	I-Method
critic	I-Method
architecture	I-Method
,	O
both	O
classical	O
and	O
distributional	B-Method
versions	I-Method
of	O
Reactor	B-Method
(	O
Figure	O
[	O
reference	O
]	O
)	O
exceeded	O
the	O
best	O
reported	O
median	O
human	B-Metric
normalized	I-Metric
score	I-Metric
of	O
1.9	O
with	O
noop	O
starts	O
achieved	O
in	O
500	O
million	O
steps	O
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
work	O
we	O
presented	O
a	O
new	O
off	B-Method
-	I-Method
policy	I-Method
agent	I-Method
based	O
on	O
Retrace	B-Method
actor	I-Method
-	I-Method
critic	I-Method
architecture	I-Method
and	O
show	O
that	O
it	O
achieves	O
similar	O
performance	O
as	O
the	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
while	O
giving	O
significant	O
real	O
-	O
time	O
performance	O
gains	O
.	O
	
We	O
demonstrate	O
the	O
benefits	O
of	O
each	O
of	O
the	O
suggested	O
algorithmic	B-Method
improvements	I-Method
,	O
including	O
Distributional	B-Method
Retrace	I-Method
,	O
beta	B-Method
-	I-Method
LOO	I-Method
policy	I-Method
gradient	I-Method
and	O
contextual	B-Method
priority	I-Method
tree	I-Method
.	O
	
bibliography	O
:	O
References	O
	
section	O
:	O
Appendix	O
	
*	O
	
proof	O
:	O
Proof	O
.	O
	
The	O
bias	O
of	O
is	O
∎	O
	
subsection	O
:	O
Hyperparameter	B-Method
optimization	I-Method
	
As	O
we	O
believe	O
that	O
algorithms	O
should	O
be	O
robust	O
with	O
respect	O
to	O
the	O
choice	O
of	O
hyperparameters	O
,	O
we	O
spent	O
little	O
effort	O
on	O
parameter	B-Task
optimization	I-Task
.	O
	
In	O
total	O
,	O
we	O
explored	O
three	O
distinct	O
values	O
of	O
learning	B-Metric
rates	I-Metric
and	O
two	O
values	O
of	O
ADAM	O
momentum	O
(	O
the	O
default	O
and	O
zero	O
)	O
and	O
two	O
values	O
of	O
on	O
a	O
subset	O
of	O
7	O
Atari	B-Material
games	O
without	O
prioritization	B-Method
using	O
non	B-Method
-	I-Method
distributional	I-Method
version	I-Method
of	I-Method
Reactor	I-Method
.	O
	
We	O
later	O
used	O
those	O
values	O
for	O
all	O
experiments	O
.	O
	
We	O
did	O
not	O
optimize	O
for	O
batch	O
sizes	O
and	O
sequence	O
length	O
or	O
any	O
prioritization	B-Method
hyperparamters	I-Method
.	O
	
subsection	O
:	O
Rank	B-Metric
and	O
Elo	B-Metric
evaluation	I-Metric
	
Commonly	O
used	O
mean	O
and	O
median	B-Metric
human	I-Metric
normalized	I-Metric
scores	I-Metric
have	O
several	O
disadvantages	O
.	O
	
A	O
mean	O
human	O
normalized	O
score	O
implicitly	O
puts	O
more	O
weight	O
on	O
games	O
that	O
computers	O
are	O
good	O
and	O
humans	O
are	O
bad	O
at	O
.	O
	
Comparing	O
algorithm	O
by	O
a	O
mean	O
human	B-Metric
normalized	I-Metric
score	I-Metric
across	O
57	O
Atari	B-Material
games	O
is	O
almost	O
equivalent	O
to	O
comparing	O
algorithms	O
on	O
a	O
small	O
subset	O
of	O
games	O
close	O
to	O
the	O
median	O
and	O
thus	O
dominating	O
the	O
signal	O
.	O
	
Typically	O
a	O
set	O
of	O
ten	O
most	O
score	O
-	O
generous	O
games	O
,	O
namely	O
Assault	O
,	O
Asterix	O
,	O
Breakout	O
,	O
Demon	O
Attack	O
,	O
Double	O
Dunk	O
,	O
Gopher	O
,	O
Pheonix	O
,	O
Stargunner	O
,	O
Up’n	O
Down	O
and	O
Video	O
Pinball	O
can	O
explain	O
more	O
than	O
half	O
of	O
inter	B-Metric
-	I-Metric
algorithm	I-Metric
variance	I-Metric
.	O
	
A	O
median	B-Metric
human	I-Metric
normalized	I-Metric
score	I-Metric
has	O
the	O
opposite	O
disadvantage	O
by	O
effectively	O
discarding	O
very	O
easy	O
and	O
very	O
hard	O
games	O
from	O
the	O
comparison	O
.	O
	
As	O
typical	O
median	B-Metric
human	I-Metric
normalized	I-Metric
scores	I-Metric
are	O
within	O
the	O
range	O
of	O
1	O
-	O
2.5	O
,	O
an	O
algorithm	O
which	O
scores	O
zero	O
points	O
on	O
Montezuma	O
’s	O
Revenge	O
is	O
evaluated	O
equal	O
to	O
the	O
one	O
which	O
scores	O
2500	O
points	O
,	O
as	O
both	O
performance	O
levels	O
are	O
still	O
below	O
human	O
performance	O
making	O
incremental	O
improvements	O
on	O
hard	O
games	O
not	O
being	O
reflected	O
in	O
the	O
overall	O
evaluation	O
.	O
	
In	O
order	O
to	O
address	O
both	O
problem	O
,	O
we	O
also	O
evaluated	O
mean	B-Metric
rank	I-Metric
and	O
Elo	B-Metric
metrics	I-Metric
for	O
inter	B-Metric
-	I-Metric
algorithm	I-Metric
comparison	I-Metric
.	O
	
Those	O
metrics	O
implicitly	O
assign	O
the	O
same	O
weight	O
to	O
each	O
game	O
,	O
and	O
as	O
a	O
result	O
is	O
more	O
sensitive	O
of	O
relative	O
performance	O
on	O
very	O
hard	O
and	O
easy	O
games	O
:	O
swapping	O
scores	O
of	O
two	O
algorithms	O
on	O
any	O
game	O
would	O
result	O
in	O
the	O
change	O
of	O
both	O
mean	B-Metric
rank	I-Metric
and	O
Elo	B-Metric
metrics	I-Metric
.	O
	
We	O
calculated	O
separate	O
mean	B-Metric
rank	I-Metric
and	O
Elo	B-Metric
scores	I-Metric
for	O
each	O
algorithm	O
using	O
results	O
of	O
test	O
evaluations	O
with	O
30	O
random	O
noop	O
-	O
starts	O
and	O
30	O
random	O
human	O
starts	O
(	O
Tables	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
)	O
.	O
	
All	O
algorithms	O
were	O
ranked	O
across	O
each	O
game	O
separately	O
,	O
and	O
a	O
mean	B-Metric
rank	I-Metric
was	O
evaluated	O
across	O
57	O
Atari	B-Material
games	O
.	O
	
For	O
Elo	B-Method
score	I-Method
evaluation	I-Method
algorithm	I-Method
,	O
was	O
considered	O
to	O
win	O
over	O
algorithm	O
if	O
it	O
obtained	O
more	O
scores	O
on	O
a	O
given	O
Atari	B-Material
.	O
	
We	O
produced	O
an	O
empirical	B-Metric
win	I-Metric
-	I-Metric
probability	I-Metric
matrix	I-Metric
by	O
summing	O
wins	O
across	O
all	O
games	O
and	O
used	O
this	O
matrix	O
to	O
evaluate	O
Elo	B-Metric
scores	I-Metric
.	O
	
A	O
ranking	O
difference	O
of	O
400	O
corresponds	O
to	O
the	O
odds	O
of	O
winning	O
of	O
10:1	O
under	O
the	O
Gaussian	B-Method
assumption	I-Method
.	O
	
subsection	O
:	O
Contextual	B-Method
priority	I-Method
tree	I-Method
	
Contextual	B-Method
priority	I-Method
tree	I-Method
is	O
one	O
possible	O
implementation	O
of	O
lazy	B-Task
prioritization	I-Task
(	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
All	O
sequence	O
keys	O
are	O
put	O
into	O
a	O
balanced	B-Method
binary	I-Method
search	I-Method
tree	I-Method
which	O
maintains	O
a	O
temporal	O
order	O
.	O
	
An	O
AVL	B-Method
tree	I-Method
(	O
)	O
was	O
chosen	O
due	O
to	O
the	O
ease	O
of	O
implementation	O
and	O
because	O
it	O
is	O
on	O
average	O
more	O
evenly	O
balanced	O
than	O
a	O
Red	O
-	O
Black	O
Tree	O
.	O
	
Each	O
tree	O
node	O
has	O
up	O
to	O
two	O
children	O
(	O
left	O
and	O
right	O
)	O
and	O
contains	O
currently	O
stored	O
key	O
and	O
a	O
priority	O
of	O
the	O
key	O
which	O
is	O
either	O
set	O
or	O
is	O
unknown	O
.	O
	
Some	O
trees	O
may	O
only	O
have	O
a	O
single	O
child	O
subtree	O
while	O
some	O
may	O
have	O
none	O
.	O
	
In	O
addition	O
to	O
this	O
information	O
,	O
we	O
were	O
tracking	O
other	O
summary	O
statistics	O
at	O
each	O
node	O
which	O
was	O
re	O
-	O
evaluated	O
after	O
each	O
tree	B-Method
rotation	I-Method
.	O
	
The	O
summary	B-Metric
statistics	I-Metric
was	O
evaluated	O
by	O
consuming	O
previously	O
evaluated	O
summary	B-Metric
statistics	I-Metric
of	O
both	O
children	O
and	O
a	O
priority	O
of	O
the	O
key	O
stored	O
within	O
the	O
current	O
node	O
.	O
	
In	O
particular	O
,	O
we	O
were	O
tracking	O
a	O
total	O
number	O
of	O
nodes	O
within	O
each	O
subtree	O
and	O
mean	O
-	O
priority	O
estimates	O
updated	O
according	O
to	O
rules	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
The	O
total	O
number	O
of	O
nodes	O
within	O
each	O
subtree	O
was	O
always	O
known	O
(	O
in	O
Figure	O
[	O
reference	O
]	O
)	O
,	O
while	O
mean	O
priority	O
estimates	O
per	O
key	O
(	O
in	O
Figure	O
[	O
reference	O
]	O
)	O
could	O
either	O
be	O
known	O
or	O
unknown	O
.	O
	
If	O
a	O
mean	O
priority	O
of	O
either	O
one	O
child	O
subtree	O
or	O
a	O
key	O
stored	O
within	O
the	O
current	O
node	O
is	O
unknown	O
then	O
it	O
can	O
be	O
estimated	O
to	O
by	O
exploiting	O
information	O
coming	O
from	O
another	O
sibling	O
subtree	O
or	O
a	O
priority	O
stored	O
within	O
the	O
parent	O
node	O
.	O
	
Sampling	O
was	O
done	O
by	O
traversing	O
the	O
tree	O
from	O
the	O
root	O
node	O
up	O
while	O
sampling	O
either	O
one	O
of	O
the	O
children	O
subtrees	O
or	O
the	O
currently	O
held	O
key	O
proportionally	O
to	O
the	O
total	O
estimated	O
priority	O
masses	O
contained	O
within	O
.	O
	
The	O
rules	O
used	O
to	O
evaluate	O
proportions	O
are	O
shown	O
in	O
orange	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Similarly	O
,	O
probabilities	O
of	O
arbitrary	O
keys	O
can	O
be	O
queried	O
by	O
traversing	O
the	O
tree	O
from	O
the	O
root	O
node	O
towards	O
the	O
child	O
node	O
of	O
an	O
interest	O
while	O
maintaining	O
a	O
product	O
of	O
probabilities	O
at	O
each	O
branching	O
point	O
.	O
	
Insertion	B-Method
,	O
deletion	B-Method
,	O
sampling	B-Method
and	O
probability	B-Method
query	I-Method
operations	I-Method
can	O
be	O
done	O
in	O
O	O
(	O
ln	O
(	O
n	O
)	O
)	O
time	O
.	O
	
The	O
suggested	O
algorithm	O
has	O
the	O
desired	O
property	O
that	O
it	O
becomes	O
a	O
simple	O
proportional	B-Method
sampling	I-Method
algorithm	I-Method
once	O
all	O
the	O
priorities	O
are	O
known	O
.	O
	
While	O
some	O
key	O
priorities	O
are	O
unknown	O
,	O
they	O
are	O
estimated	O
by	O
using	O
nearby	O
known	O
key	O
priorities	O
(	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
Each	O
time	O
when	O
a	O
new	O
sequence	O
key	O
is	O
added	O
to	O
the	O
tree	O
,	O
it	O
was	O
set	O
to	O
have	O
an	O
unknown	O
priority	O
.	O
	
Any	O
priority	O
was	O
assigned	O
only	O
after	O
the	O
key	O
got	O
first	O
sampled	O
and	O
the	O
corresponding	O
sequence	O
got	O
passed	O
through	O
the	O
learner	O
.	O
	
When	O
a	O
priority	O
of	O
a	O
key	O
is	O
set	O
or	O
updated	O
,	O
the	O
key	O
node	O
is	O
deliberately	O
removed	O
from	O
and	O
placed	O
back	O
to	O
the	O
tree	O
in	O
order	O
to	O
become	O
a	O
leaf	O
-	O
node	O
.	O
	
This	O
helped	O
to	O
set	O
priorities	O
of	O
nodes	O
in	O
the	O
immediate	O
vicinity	O
more	O
accurately	O
by	O
using	O
the	O
freshest	O
information	O
available	O
.	O
	
subsection	O
:	O
Network	B-Method
architecture	I-Method
	
The	O
value	O
of	O
is	O
the	O
minimum	O
probability	O
of	O
choosing	O
a	O
random	O
action	O
and	O
it	O
is	O
hard	O
-	O
coded	O
into	O
the	O
policy	B-Method
network	I-Method
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
the	O
overall	O
network	O
topology	O
while	O
Table	O
[	O
reference	O
]	O
specifies	O
network	O
layer	O
sizes	O
.	O
	
subsection	O
:	O
Comparisons	O
with	O
Rainbow	O
	
In	O
this	O
section	O
we	O
compare	O
Reactor	B-Method
with	O
the	O
recently	O
published	O
Rainbow	B-Method
agent	I-Method
rainbow	I-Method
.	O
	
While	O
ACER	B-Method
is	O
the	O
most	O
closely	O
related	O
algorithmically	O
,	O
Rainbow	B-Method
is	O
most	O
closely	O
related	O
in	O
terms	O
of	O
performance	O
and	O
thus	O
a	O
deeper	O
understanding	O
of	O
the	O
trade	O
-	O
offs	O
between	O
Rainbow	B-Method
and	O
Reactor	B-Method
may	O
benefit	O
interested	O
readers	O
.	O
	
There	O
are	O
many	O
architectural	O
and	O
algorithmic	O
differences	O
between	O
Rainbow	B-Method
and	O
Reactor	B-Method
.	O
	
We	O
will	O
therefore	O
begin	O
by	O
highlighting	O
where	O
they	O
agree	O
.	O
	
Both	O
use	O
a	O
categorical	O
action	O
-	O
value	O
distribution	O
critic	O
bellemare2017distributional	O
,	O
factored	O
into	O
state	O
and	O
state	O
-	O
action	O
logits	O
wang2015dueling	O
,	O
Both	O
use	O
prioritized	B-Method
replay	I-Method
,	O
and	O
finally	O
,	O
both	O
perform	O
-	O
step	O
Bellman	B-Method
updates	I-Method
.	O
	
Despite	O
these	O
similarities	O
,	O
Reactor	B-Method
and	O
Rainbow	B-Method
are	O
fundamentally	O
different	O
algorithms	O
and	O
are	O
based	O
upon	O
different	O
lines	O
of	O
research	O
.	O
	
While	O
Rainbow	B-Method
uses	O
Q	B-Method
-	I-Method
Learning	I-Method
and	O
is	O
based	O
upon	O
DQN	B-Method
mnih15human	O
,	O
Reactor	B-Method
is	O
an	O
actor	B-Method
-	I-Method
critic	I-Method
algorithm	I-Method
most	O
closely	O
based	O
upon	O
A3C	B-Method
mnih2016asynchronous	O
.	O
	
Each	O
inherits	O
some	O
design	O
choices	O
from	O
their	O
predecessors	O
,	O
and	O
we	O
have	O
not	O
performed	O
an	O
extensive	O
ablation	O
comparing	O
these	O
various	O
differences	O
.	O
	
Instead	O
,	O
we	O
will	O
discuss	O
four	O
of	O
the	O
differences	O
we	O
believe	O
are	O
important	O
but	O
less	O
obvious	O
.	O
	
First	O
,	O
the	O
network	O
structures	O
are	O
substantially	O
different	O
.	O
	
Rainbow	B-Method
uses	O
noisy	B-Method
linear	I-Method
layers	I-Method
and	O
ReLU	O
activations	O
throughout	O
the	O
network	O
,	O
whereas	O
Reactor	B-Method
uses	O
standard	O
linear	B-Method
layers	I-Method
and	O
concatenated	O
ReLU	O
activations	O
throughout	O
.	O
	
To	O
overcome	O
partial	O
observability	O
,	O
Rainbow	B-Method
,	O
inheriting	O
this	O
choice	O
from	O
DQN	B-Method
,	O
uses	O
frame	B-Method
stacking	I-Method
.	O
	
On	O
the	O
other	O
hand	O
,	O
Reactor	B-Method
,	O
inheriting	O
its	O
choice	O
from	O
A3C	B-Method
,	O
uses	O
LSTMs	B-Method
after	O
the	O
convolutional	B-Method
layers	I-Method
of	O
the	O
network	O
.	O
	
It	O
is	O
also	O
difficult	O
to	O
directly	O
compare	O
the	O
number	O
of	O
parameters	O
in	O
each	O
network	O
because	O
the	O
use	O
of	O
noisy	B-Method
linear	I-Method
layers	I-Method
doubles	O
the	O
number	O
of	O
parameters	O
,	O
although	O
half	O
of	O
these	O
are	O
used	O
to	O
control	O
noise	O
,	O
while	O
the	O
LSTM	B-Method
units	I-Method
in	O
Reactor	B-Method
require	O
more	O
parameters	O
than	O
a	O
corresponding	O
linear	B-Method
layer	I-Method
would	O
.	O
	
Second	O
,	O
both	O
algorithms	O
perform	O
-	O
step	O
	
updates	O
,	O
however	O
,	O
the	O
Rainbow	B-Method
-	I-Method
step	I-Method
update	I-Method
does	O
not	O
use	O
any	O
form	O
of	O
off	B-Method
-	I-Method
policy	I-Method
correction	I-Method
.	O
	
Because	O
of	O
this	O
,	O
Rainbow	B-Method
is	O
restricted	O
to	O
using	O
only	O
small	O
values	O
of	O
(	O
e.g.	O
)	O
because	O
larger	O
values	O
would	O
make	O
sequences	O
more	O
off	O
-	O
policy	O
and	O
hurt	O
performance	O
.	O
	
By	O
comparison	O
,	O
Reactor	B-Method
uses	O
our	O
proposed	O
distributional	B-Method
Retrace	I-Method
algorithm	I-Method
for	O
off	B-Task
-	I-Task
policy	I-Task
correction	I-Task
of	I-Task
-	I-Task
step	I-Task
updates	I-Task
.	O
	
This	O
allows	O
the	O
use	O
of	O
larger	O
values	O
of	O
(	O
e.g.	O
)	O
without	O
loss	O
of	O
performance	O
.	O
	
Third	O
,	O
while	O
both	O
agents	O
use	O
prioritized	O
replay	O
buffers	O
schaul16prioritized	O
,	O
they	O
each	O
store	O
different	O
information	O
and	O
prioritize	O
using	O
different	O
algorithms	O
.	O
	
Rainbow	B-Method
stores	O
a	O
tuple	O
containing	O
the	O
state	O
,	O
action	O
,	O
sum	O
of	O
discounted	O
rewards	O
,	O
product	O
of	O
discount	O
factors	O
,	O
and	O
next	O
-	O
state	O
steps	O
away	O
.	O
	
Tuples	O
are	O
prioritized	O
based	O
upon	O
the	O
last	O
observed	O
TD	O
error	O
,	O
and	O
inserted	O
into	O
replay	O
with	O
a	O
maximum	O
priority	O
.	O
	
Reactor	B-Method
stores	O
length	O
sequences	O
of	O
tuples	O
and	O
also	O
prioritizes	O
based	O
upon	O
the	O
observed	O
TD	B-Metric
error	I-Metric
.	O
	
However	O
,	O
when	O
inserted	O
into	O
the	O
buffer	O
the	O
priority	O
is	O
instead	O
inferred	O
based	O
upon	O
the	O
known	O
priorities	O
of	O
neighboring	O
sequences	O
.	O
	
This	O
priority	B-Method
inference	I-Method
was	O
made	O
efficient	O
using	O
the	O
previously	O
introduced	O
contextual	B-Method
priority	I-Method
tree	I-Method
,	O
and	O
anecdotally	O
we	O
have	O
seen	O
it	O
improve	O
performance	O
over	O
a	O
simple	O
maximum	B-Method
priority	I-Method
approach	I-Method
.	O
	
Finally	O
,	O
the	O
two	O
algorithms	O
have	O
different	O
approaches	O
to	O
exploration	B-Task
.	O
	
Rainbow	B-Method
,	O
unlike	O
DQN	B-Method
,	O
does	O
not	O
use	O
-	B-Method
greedy	I-Method
exploration	I-Method
,	O
but	O
instead	O
replaces	O
all	O
linear	O
layers	O
with	O
noisy	O
linear	O
layers	O
which	O
induce	O
randomness	O
throughout	O
the	O
network	O
.	O
	
This	O
method	O
,	O
called	O
Noisy	B-Method
Networks	I-Method
fortunato2017noisy	O
,	O
creates	O
an	O
adaptive	B-Method
exploration	I-Method
integrated	O
into	O
the	O
agent	B-Method
’s	I-Method
network	I-Method
.	O
	
Reactor	B-Method
does	O
not	O
use	O
noisy	B-Method
networks	I-Method
,	O
but	O
instead	O
uses	O
the	O
same	O
entropy	B-Method
cost	I-Method
method	I-Method
used	O
by	O
A3C	O
and	O
many	O
others	O
mnih2016asynchronous	O
,	O
which	O
penalizes	O
deterministic	B-Method
policies	I-Method
thus	O
encouraging	O
indifference	O
between	O
similarly	O
valued	O
actions	O
.	O
	
Because	O
Rainbow	O
can	O
essentially	O
learn	O
not	O
to	O
explore	O
,	O
it	O
may	O
learn	O
to	O
become	O
entirely	O
greedy	O
in	O
the	O
early	O
parts	O
of	O
the	O
episode	O
,	O
while	O
still	O
exploring	O
in	O
states	O
not	O
as	O
frequently	O
seen	O
.	O
	
In	O
some	O
sense	O
,	O
this	O
is	O
precisely	O
what	O
we	O
want	O
from	O
an	O
exploration	B-Method
technique	I-Method
,	O
but	O
it	O
may	O
also	O
lead	O
to	O
highly	O
deterministic	O
trajectories	O
in	O
the	O
early	O
part	O
of	O
the	O
episode	O
and	O
an	O
increase	O
in	O
overfitting	O
to	O
those	O
trajectories	O
.	O
	
We	O
hypothesize	O
that	O
this	O
may	O
be	O
the	O
explanation	O
for	O
the	O
significant	O
difference	O
in	O
Rainbow	O
’s	O
performance	O
between	O
evaluation	B-Task
under	O
no	O
-	O
op	O
and	O
random	O
human	O
starts	O
,	O
and	O
why	O
Reactor	B-Method
does	O
not	O
show	O
such	O
a	O
large	O
difference	O
.	O
	
subsection	O
:	O
Atari	B-Material
results	O
	
Factoring	B-Task
Variations	I-Task
in	O
Natural	O
Images	O
with	O
Deep	B-Method
Gaussian	I-Method
Mixture	I-Method
Models	I-Method
Generative	I-Method
models	I-Method
can	O
be	O
seen	O
as	O
the	O
swiss	O
army	O
knives	O
of	O
machine	B-Task
learning	I-Task
,	O
as	O
many	O
problems	O
can	O
be	O
written	O
probabilistically	O
in	O
terms	O
of	O
the	O
distribution	O
of	O
the	O
data	O
,	O
including	O
prediction	B-Task
,	O
reconstruction	B-Task
,	O
imputation	B-Task
and	O
simulation	B-Task
.	O
	
One	O
of	O
the	O
most	O
promising	O
directions	O
for	O
unsupervised	B-Task
learning	I-Task
may	O
lie	O
in	O
Deep	B-Method
Learning	I-Method
methods	I-Method
,	O
given	O
their	O
success	O
in	O
supervised	B-Task
learning	I-Task
.	O
	
However	O
,	O
one	O
of	O
the	O
current	O
problems	O
with	O
deep	B-Method
unsupervised	I-Method
learning	I-Method
methods	I-Method
,	O
is	O
that	O
they	O
often	O
are	O
harder	O
to	O
scale	O
.	O
	
As	O
a	O
result	O
there	O
are	O
some	O
easier	O
,	O
more	O
scalable	O
shallow	B-Method
methods	I-Method
,	O
such	O
as	O
the	O
Gaussian	B-Method
Mixture	I-Method
Model	I-Method
and	O
the	O
Student	B-Method
-	I-Method
t	I-Method
Mixture	I-Method
Model	I-Method
,	O
that	O
remain	O
surprisingly	O
competitive	O
.	O
	
In	O
this	O
paper	O
we	O
propose	O
a	O
new	O
scalable	B-Method
deep	I-Method
generative	I-Method
model	I-Method
for	O
images	O
,	O
called	O
the	O
Deep	B-Method
Gaussian	I-Method
Mixture	I-Method
Model	I-Method
,	O
that	O
is	O
a	O
straightforward	O
but	O
powerful	O
generalization	B-Method
of	I-Method
GMMs	I-Method
to	O
multiple	O
layers	O
.	O
	
The	O
parametrization	B-Method
of	O
a	O
Deep	B-Method
GMM	I-Method
allows	O
it	O
to	O
efficiently	O
capture	O
products	O
of	O
variations	O
in	O
natural	O
images	O
.	O
	
We	O
propose	O
a	O
new	O
EM	B-Method
-	O
based	O
algorithm	O
that	O
scales	O
well	O
to	O
large	O
datasets	O
,	O
and	O
we	O
show	O
that	O
both	O
the	O
Expectation	O
and	O
the	O
Maximization	B-Method
steps	I-Method
can	O
easily	O
be	O
distributed	O
over	O
multiple	O
machines	O
.	O
	
In	O
our	O
density	B-Task
estimation	I-Task
experiments	O
we	O
show	O
that	O
deeper	O
GMM	B-Method
architectures	O
generalize	O
better	O
than	O
more	O
shallow	O
ones	O
,	O
with	O
results	O
in	O
the	O
same	O
ballpark	O
as	O
the	O
state	O
of	O
the	O
art	O
.	O
	
1	O
Introduction	O
	
There	O
has	O
been	O
an	O
increasing	O
interest	O
in	O
generative	B-Method
models	I-Method
for	O
unsupervised	B-Task
learning	I-Task
,	O
with	O
many	O
applications	O
in	O
Image	B-Task
processing	I-Task
[	O
1	O
,	O
2	O
]	O
,	O
natural	B-Task
language	I-Task
processing	I-Task
[	O
3	O
,	O
4	O
]	O
,	O
vision	B-Task
[	O
5	O
]	O
and	O
audio	B-Task
[	O
6	O
]	O
.	O
Generative	B-Method
models	I-Method
can	O
be	O
seen	O
as	O
the	O
swiss	O
army	O
knives	O
of	O
machine	B-Task
learning	I-Task
,	O
as	O
many	O
problems	O
can	O
be	O
written	O
probabilistically	O
in	O
terms	O
of	O
the	O
distribution	O
of	O
the	O
data	O
,	O
including	O
prediction	B-Task
,	O
reconstruction	B-Task
,	O
imputation	B-Task
and	O
simulation	B-Task
.	O
	
One	O
of	O
the	O
most	O
promising	O
directions	O
for	O
unsupervised	B-Task
learning	I-Task
may	O
lie	O
in	O
Deep	B-Method
Learning	I-Method
methods	I-Method
,	O
given	O
their	O
recent	O
results	O
in	O
supervised	B-Task
learning	I-Task
[	O
7	O
]	O
.	O
	
Although	O
not	O
a	O
universal	O
recipe	O
for	O
success	O
,	O
the	O
merits	O
of	O
deep	B-Method
learning	I-Method
are	O
well	O
-	O
established	O
[	O
8	O
]	O
.	O
	
Because	O
of	O
their	O
multilayered	O
nature	O
,	O
these	O
methods	O
provide	O
ways	O
to	O
efficiently	O
represent	O
increasingly	O
complex	O
relationships	O
as	O
the	O
number	O
of	O
layers	O
increases	O
.	O
	
“	O
	
Shallow	B-Method
”	I-Method
methods	I-Method
will	O
often	O
require	O
a	O
very	O
large	O
number	O
of	O
units	O
to	O
represent	O
the	O
same	O
functions	O
,	O
and	O
may	O
therefore	O
overfit	O
more	O
.	O
	
Looking	O
at	O
real	O
-	O
valued	O
data	O
,	O
one	O
of	O
the	O
current	O
problems	O
with	O
deep	B-Method
unsupervised	I-Method
learning	I-Method
methods	I-Method
,	O
is	O
that	O
they	O
are	O
often	O
hard	O
to	O
scale	O
to	O
large	O
datasets	O
.	O
	
This	O
is	O
especially	O
a	O
problem	O
for	O
unsupervised	B-Task
learning	I-Task
,	O
because	O
there	O
is	O
usually	O
a	O
lot	O
of	O
data	O
available	O
,	O
as	O
it	O
does	O
not	O
have	O
to	O
be	O
labeled	O
(	O
e.g.	O
images	O
,	O
videos	O
,	O
text	O
)	O
.	O
	
As	O
a	O
result	O
there	O
are	O
some	O
easier	O
,	O
more	O
scalable	O
shallow	B-Method
methods	I-Method
,	O
such	O
as	O
the	O
Gaussian	O
Mixture	O
Model	O
(	O
GMM	B-Method
)	O
and	O
the	O
Student	B-Method
-	I-Method
t	I-Method
Mixture	I-Method
Model	I-Method
(	O
STM	B-Method
)	I-Method
,	O
that	O
remain	O
surprisingly	O
competitive	O
	
[	O
2	O
]	O
.	O
	
Of	O
course	O
,	O
the	O
disadvantage	O
of	O
these	O
mixture	B-Method
models	I-Method
is	O
that	O
they	O
have	O
less	O
representational	B-Method
power	I-Method
than	O
deep	B-Method
models	I-Method
.	O
	
In	O
this	O
paper	O
we	O
propose	O
a	O
new	O
scalable	B-Method
deep	I-Method
generative	I-Method
model	I-Method
for	O
images	O
,	O
called	O
the	O
Deep	B-Method
Gaussian	I-Method
Mixture	I-Method
Model	I-Method
(	O
Deep	B-Method
GMM	I-Method
)	O
.	O
	
The	O
Deep	B-Method
GMM	I-Method
is	O
a	O
straightforward	O
but	O
powerful	O
generalization	B-Method
of	I-Method
Gaussian	I-Method
Mixture	I-Method
Models	I-Method
to	O
multiple	O
layers	O
.	O
	
It	O
is	O
constructed	O
by	O
stacking	O
multiple	O
GMM	B-Method
-	O
layers	O
on	O
top	O
of	O
each	O
other	O
,	O
which	O
is	O
similar	O
to	O
many	O
other	O
Deep	B-Method
Learning	I-Method
techniques	I-Method
.	O
	
Although	O
for	O
every	O
deep	O
GMM	B-Method
,	O
one	O
could	O
construct	O
a	O
shallow	O
GMM	B-Method
with	O
the	O
same	O
density	O
function	O
,	O
it	O
would	O
require	O
an	O
exponential	O
number	O
of	O
mixture	O
components	O
to	O
do	O
so	O
.	O
	
The	O
multilayer	B-Method
architecture	I-Method
of	O
the	O
Deep	B-Method
GMM	I-Method
gives	O
rise	O
to	O
a	O
specific	O
kind	O
of	O
parameter	B-Method
tying	I-Method
.	O
	
The	O
parameterization	O
is	O
most	O
interpretable	O
in	O
the	O
case	O
of	O
images	O
:	O
the	O
layers	O
in	O
the	O
architecture	O
are	O
able	O
to	O
efficiently	O
factorize	O
the	O
different	O
variations	O
that	O
are	O
present	O
in	O
natural	O
images	O
:	O
changes	O
in	O
brightness	O
,	O
contrast	O
,	O
color	O
and	O
even	O
translations	O
or	O
rotations	O
of	O
the	O
objects	O
in	O
the	O
image	O
.	O
	
Because	O
each	O
of	O
these	O
variations	O
will	O
affect	O
the	O
image	O
separately	O
,	O
a	O
traditional	O
mixture	B-Method
model	I-Method
would	O
need	O
an	O
exponential	O
number	O
of	O
components	O
to	O
model	O
each	O
combination	O
of	O
variations	O
,	O
whereas	O
a	O
Deep	B-Method
GMM	I-Method
can	O
factor	O
these	O
variations	O
and	O
model	O
them	O
individually	O
.	O
	
The	O
proposed	O
training	B-Method
algorithm	I-Method
for	O
the	O
Deep	B-Method
GMM	I-Method
is	O
based	O
on	O
the	O
most	O
popular	O
principle	O
for	O
training	O
GMMs	B-Method
:	O
	
Expectation	B-Method
Maximization	I-Method
(	O
EM	B-Method
)	O
.	O
	
Although	O
stochastic	B-Method
gradient	I-Method
(	I-Method
SGD	I-Method
)	I-Method
is	O
also	O
a	O
possible	O
option	O
,	O
we	O
suggest	O
the	O
use	O
of	O
EM	B-Method
,	O
as	O
it	O
is	O
inherently	O
more	O
parallelizable	O
.	O
	
As	O
we	O
will	O
show	O
later	O
,	O
both	O
the	O
Expectation	O
and	O
the	O
Maximization	B-Method
steps	I-Method
can	O
easily	O
be	O
distributed	O
on	O
multiple	O
computation	O
units	O
or	O
machines	O
,	O
with	O
only	O
limited	O
communication	O
between	O
compute	O
nodes	O
.	O
	
Although	O
there	O
has	O
been	O
a	O
lot	O
of	O
effort	O
in	O
scaling	O
up	O
SGD	B-Method
for	O
deep	B-Task
networks	I-Task
[	O
9	O
]	O
,	O
the	O
Deep	B-Method
GMM	I-Method
is	O
parallelizable	O
by	O
design	O
.	O
	
The	O
remainder	O
of	O
this	O
paper	O
is	O
organized	O
as	O
follows	O
.	O
	
We	O
start	O
by	O
introducing	O
the	O
design	O
of	O
deep	B-Method
GMMs	I-Method
before	O
explaining	O
the	O
EM	B-Method
algorithm	O
for	O
training	O
them	O
.	O
	
Next	O
,	O
we	O
discuss	O
the	O
experiments	O
where	O
we	O
examine	O
the	O
density	B-Task
estimation	I-Task
performance	O
of	O
the	O
deep	O
GMM	B-Method
,	O
as	O
a	O
function	O
of	O
the	O
number	O
of	O
layers	O
,	O
and	O
in	O
comparison	O
with	O
other	O
methods	O
.	O
	
We	O
conclude	O
in	O
Section	O
5	O
,	O
where	O
also	O
discuss	O
some	O
unsolved	O
problems	O
for	O
future	O
work	O
.	O
	
2	O
	
Stacking	B-Method
Gaussian	I-Method
Mixture	I-Method
layers	I-Method
	
Deep	B-Method
GMMs	I-Method
are	O
best	O
introduced	O
by	O
looking	O
at	O
some	O
special	O
cases	O
:	O
the	O
multivariate	B-Method
normal	I-Method
distribution	I-Method
and	O
the	O
Gaussian	B-Method
Mixture	I-Method
model	I-Method
.	O
	
One	O
way	O
to	O
define	O
a	O
multivariate	O
normal	O
variable	O
x	O
is	O
as	O
a	O
standard	O
normal	O
variable	O
z	O
⇠	O
N	O
(	O
0	O
,	O
In	O
)	O
that	O
has	O
been	O
transformed	O
with	O
a	O
certain	O
linear	B-Method
transformation	I-Method
:	O
x	O
	
=	O
Az	O
+	O
b	O
,	O
so	O
that	O
p	O
(	O
x	O
)	O
=	O
	
N	O
x|b	O
,	O
AAT	O
.	O
	
This	O
is	O
visualized	O
in	O
Figure	O
1	O
(	O
a	O
)	O
.	O
	
The	O
same	O
interpretation	O
can	O
be	O
applied	O
to	O
Gaussian	B-Method
Mixture	I-Method
Models	I-Method
,	O
see	O
Figure	O
1	O
(	O
b	O
)	O
.	O
	
A	O
transformation	O
is	O
chosen	O
from	O
set	O
of	O
(	O
square	O
)	O
transformations	O
	
Ai	O
,	O
i	O
=	O
1	O
.	O
.	O
.	O
	
N	O
(	O
each	O
having	O
a	O
bias	O
term	O
bi	O
)	O
with	O
probabilities	O
	
⇡	O
i	O
,	O
	
i	O
=	O
1	O
.	O
.	O
.	O
	
N	O
,	O
such	O
that	O
the	O
resulting	O
distribution	O
becomes	O
:	O
p	O
(	O
x	O
)	O
=	O
NX	O
i=1	O
	
⇡	O
iN	O
x|bi	O
,	O
AiATi	O
.	O
	
With	O
this	O
in	O
mind	O
,	O
it	O
is	O
easy	O
to	O
generalize	O
GMMs	B-Method
in	O
a	O
multi	O
-	O
layered	O
fashion	O
.	O
	
Instead	O
of	O
sampling	O
one	O
transformation	O
from	O
a	O
set	O
,	O
we	O
can	O
sample	O
a	O
path	O
of	O
transformations	O
in	O
a	O
network	O
of	O
k	O
layers	O
,	O
see	O
Figure	O
1	O
(	O
c	O
)	O
.	O
	
The	O
standard	O
normal	O
variable	O
z	O
is	O
now	O
successively	O
transformed	O
with	O
a	O
transformation	O
from	O
each	O
layer	O
of	O
the	O
network	O
.	O
	
Let	O
be	O
the	O
set	O
of	O
all	O
possible	O
paths	O
through	O
the	O
network	O
.	O
	
Each	O
path	O
p	O
=	O
	
(	O
p1	O
,	O
p2	O
,	O
.	O
.	O
.	O
,	O
pk	O
)	O
2	O
has	O
a	O
probability	O
⇡	O
p	O
of	O
being	O
sampled	O
,	O
with	O
X	O
p2	O
	
⇡	O
p	O
=	O
X	O
	
p1	O
,	O
p2	O
,	O
...	O
	
,	O
pk	O
⇡	O
(	O
p1	O
,	O
p2	O
,	O
...	O
	
,	O
pk	O
)	O
=	O
	
1	O
.	O
	
Here	O
Nj	O
is	O
the	O
number	O
of	O
components	O
in	O
layer	O
	
j.	O
	
The	O
density	O
function	O
of	O
x	O
is	O
:	O
p	O
(	O
x	O
)	O
=	O
X	O
p2	O
⇡	O
pN	O
	
x|	O
p	O
,	O
⌦	O
	
p	O
⌦	O
Tp	O
,	O
(	O
1	O
)	O
with	O
p	O
=	O
bk	O
,	O
pk	O
+	O
Ak	O
,	O
ik	O
(	O
.	O
.	O
.	O
	
(	O
b2	O
,	O
p2	O
+	O
A2	O
,	O
p2b1	O
,	O
p1	O
)	O
)	O
	
(	O
2	O
)	O
⌦	O
p	O
=	O
1Y	O
	
j	O
=	O
	
k	O
	
Aj	O
,	O
pj	O
.	O
	
(	O
3	O
)	O
Here	O
Am	O
,	O
n	O
and	O
bm	O
,	O
n	O
are	O
the	O
n’th	O
transformation	O
matrix	O
and	O
bias	O
of	O
the	O
m’th	O
layer	O
.	O
	
Notice	O
that	O
one	O
can	O
also	O
factorize	O
⇡	O
p	O
as	O
follows	O
:	O
	
⇡	O
(	O
p1	O
,	O
p2	O
,	O
...	O
	
,	O
pk	O
)	O
	
=	O
	
⇡	O
p1	O
	
⇡	O
	
p2	O
.	O
.	O
.	O
	
⇡	O
pk	O
,	O
so	O
that	O
each	O
layer	O
has	O
its	O
own	O
set	O
of	O
parameters	O
associated	O
with	O
it	O
.	O
	
In	O
our	O
experiments	O
,	O
however	O
,	O
this	O
had	O
very	O
little	O
difference	O
on	O
the	O
log	O
likelihood	O
.	O
	
This	O
would	O
mainly	O
be	O
useful	O
for	O
very	O
large	O
networks	O
.	O
	
The	O
GMM	B-Method
is	O
a	O
special	O
case	O
of	O
the	O
deep	O
GMM	B-Method
having	O
only	O
one	O
layer	O
.	O
	
Moreover	O
,	O
each	O
deep	O
GMM	B-Method
can	O
be	O
constructed	O
by	O
a	O
GMM	B-Method
with	O
Qk	O
j	O
	
Nj	O
components	O
,	O
where	O
every	O
path	O
in	O
the	O
network	O
represents	O
one	O
component	O
in	O
the	O
GMM	B-Method
.	O
	
The	O
parameters	O
of	O
these	O
components	O
are	O
tied	O
to	O
each	O
other	O
in	O
the	O
way	O
the	O
deep	O
GMM	B-Method
is	O
defined	O
.	O
	
Because	O
of	O
this	O
tying	O
,	O
the	O
number	O
of	O
parameters	O
to	O
train	O
is	O
proportional	O
toPk	O
	
j	O
Nj	O
.	O
	
Still	O
,	O
the	O
density	B-Method
estimator	I-Method
is	O
quite	O
expressive	O
as	O
it	O
can	O
represent	O
a	O
large	O
number	O
of	O
Gaussian	B-Method
mixture	I-Method
components	I-Method
.	O
	
This	O
is	O
often	O
the	O
case	O
with	O
deep	B-Method
learning	I-Method
methods	I-Method
:	O
Shallow	B-Method
architectures	I-Method
can	O
often	O
theoretically	O
learn	O
the	O
same	O
functions	O
,	O
but	O
will	O
require	O
a	O
much	O
larger	O
number	O
of	O
parameters	O
[	O
8	O
]	O
.	O
	
When	O
the	O
kind	O
of	O
compound	O
functions	O
that	O
a	O
deep	B-Method
learning	I-Method
method	I-Method
is	O
able	O
to	O
model	O
are	O
appropriate	O
for	O
the	O
type	O
of	O
data	O
,	O
their	O
performance	O
will	O
often	O
be	O
better	O
than	O
their	O
shallow	O
equivalents	O
,	O
because	O
of	O
the	O
smaller	O
risk	O
of	O
overfitting	O
.	O
	
In	O
the	O
case	O
of	O
images	O
,	O
but	O
also	O
for	O
other	O
types	O
of	O
data	O
,	O
we	O
can	O
imagine	O
why	O
this	O
network	B-Method
structure	I-Method
might	O
be	O
useful	O
.	O
	
A	O
lot	O
of	O
images	O
share	O
the	O
same	O
variations	O
such	O
as	O
rotations	O
,	O
translations	O
,	O
brightness	O
changes	O
,	O
etc	O
..	O
	
These	O
deformations	O
can	O
be	O
represented	O
by	O
a	O
linear	B-Method
transformation	I-Method
in	O
the	O
pixel	O
space	O
.	O
	
When	O
learning	O
a	O
deep	O
GMM	B-Method
,	O
the	O
model	O
may	O
pick	O
up	O
on	O
these	O
variations	O
in	O
the	O
data	O
that	O
are	O
shared	O
amongst	O
images	O
by	O
factoring	O
and	O
describing	O
them	O
with	O
the	O
transformations	O
in	O
the	O
network	O
.	O
	
The	O
hypothesis	O
of	O
this	O
paper	O
is	O
that	O
Deep	B-Method
GMMs	I-Method
overfit	O
less	O
than	O
normal	B-Method
GMMs	I-Method
as	O
the	O
complexity	O
of	O
their	O
density	O
functions	O
increase	O
because	O
the	O
parameter	B-Method
tying	I-Method
of	O
the	O
Deep	B-Method
GMM	I-Method
will	O
force	O
it	O
to	O
learn	O
more	O
useful	O
functions	O
.	O
	
Note	O
that	O
this	O
is	O
one	O
of	O
the	O
reasons	O
why	O
other	O
deep	B-Method
learning	I-Method
methods	I-Method
are	O
so	O
successful	O
.	O
	
The	O
only	O
difference	O
is	O
that	O
the	O
parameter	B-Method
tying	I-Method
in	O
deep	B-Method
GMMs	I-Method
is	O
more	O
explicit	O
and	O
interpretable	O
.	O
	
A	O
closely	O
related	O
method	O
is	O
the	O
deep	B-Method
mixture	I-Method
of	I-Method
factor	I-Method
analyzers	I-Method
(	I-Method
DMFA	I-Method
)	I-Method
model	I-Method
[	O
10	O
]	O
,	O
which	O
is	O
an	O
extension	O
of	O
the	O
Mixture	B-Method
of	I-Method
Factor	I-Method
Analyzers	I-Method
(	O
MFA	B-Method
)	I-Method
model	I-Method
	
[	O
11	O
]	O
.	O
The	O
DMFA	B-Method
model	I-Method
has	O
a	O
tree	O
structure	O
in	O
which	O
every	O
node	O
is	O
a	O
factor	B-Method
analyzer	I-Method
that	O
inherits	O
the	O
low	O
-	O
dimensional	O
latent	O
factors	O
from	O
its	O
parent	O
.	O
	
Training	B-Method
is	O
performed	O
layer	O
by	O
layer	O
,	O
where	O
the	O
dataset	O
is	O
hierarchically	O
clustered	O
and	O
the	O
children	O
of	O
each	O
node	O
are	O
trained	O
as	O
a	O
MFA	B-Method
on	O
a	O
different	O
subset	O
of	O
the	O
data	O
using	O
the	O
MFA	O
EM	B-Method
algorithm	O
.	O
	
The	O
parents	O
nodes	O
are	O
kept	O
constant	O
when	O
training	O
its	O
children	O
.	O
	
The	O
main	O
difference	O
with	O
the	O
proposed	O
method	O
is	O
that	O
in	O
the	O
Deep	B-Method
GMM	I-Method
the	O
nodes	O
of	O
each	O
layer	O
are	O
connected	O
to	O
all	O
nodes	O
of	O
the	O
layer	O
above	O
.	O
	
The	O
layers	O
are	O
trained	O
jointly	O
and	O
the	O
higher	O
level	O
nodes	O
will	O
adapt	O
to	O
the	O
lower	O
level	O
nodes	O
.	O
	
3	O
Training	O
deep	B-Method
GMMs	I-Method
with	O
EM	B-Method
	
The	O
algorithm	O
we	O
propose	O
for	O
training	O
Deep	B-Method
GMMs	I-Method
is	O
based	O
on	O
Expectation	O
Maximization	O
(	O
EM	B-Method
)	O
.	O
	
The	O
optimization	B-Task
is	O
similar	O
to	O
that	O
of	O
a	O
GMM	B-Method
:	O
in	O
the	O
E	O
-	O
step	O
we	O
will	O
compute	O
the	O
posterior	O
probabilities	O
np	O
that	O
a	O
path	O
p	O
was	O
responsible	O
for	O
generating	O
xn	O
,	O
also	O
called	O
the	O
responsibilities	O
.	O
	
In	O
the	O
maximization	B-Task
step	I-Task
,	O
the	O
parameters	O
of	O
the	O
model	O
will	O
be	O
optimized	O
given	O
those	O
responsibilities	O
.	O
	
3.1	O
Expectation	O
From	O
Equation	O
1	O
we	O
get	O
	
the	O
the	O
log	O
-	O
likelihood	O
given	O
the	O
data	O
:	O
X	O
n	O
	
log	O
p	O
(	O
xn	O
)	O
=	O
X	O
n	O
log	O
2	O
4	O
X	O
	
p2	O
	
⇡	O
	
pN	O
xn|	O
	
p	O
,	O
	
⌦	O
p	O
	
⌦	O
Tp	O
3	O
5	O
.	O
	
This	O
is	O
the	O
global	O
objective	O
for	O
the	O
Deep	B-Method
GMM	I-Method
to	O
optimize	O
.	O
	
When	O
taking	O
the	O
derivative	O
with	O
respect	O
to	O
a	O
parameter	O
✓	O
we	O
get	O
:	O
r	O
✓	O
X	O
n	O
log	O
p	O
(	O
xn	O
)	O
=	O
	
X	O
n	O
,	O
p	O
⇡	O
	
pN	O
xn|	O
p	O
,	O
⌦	O
p	O
	
⌦	O
Tp	O
⇥	O
r	O
✓	O
	
logN	O
	
xn|	O
p	O
,	O
	
⌦	O
p	O
⌦	O
	
Tp	O
⇤	O
P	O
q	O
⇡	O
	
qN	O
xn|	O
	
q	O
,	O
	
⌦	O
q	O
	
⌦	O
Tq	O
=	O
	
X	O
n	O
,	O
p	O
npr	O
✓	O
	
logN	O
	
xn|	O
p	O
,	O
	
⌦	O
	
p	O
⌦	O
Tp	O
,	O
with	O
np	O
=	O
⇡	O
	
pN	O
xn|	O
	
p	O
,	O
	
⌦	O
p	O
	
⌦	O
Tp	O
P	O
q2	O
	
⇡	O
	
qN	O
xn|	O
	
q	O
,	O
	
⌦	O
q	O
	
⌦	O
Tq	O
,	O
the	O
equation	O
for	O
the	O
responsibilities	O
.	O
	
Although	O
np	O
generally	O
depend	O
on	O
the	O
parameter	O
✓	O
,	O
in	O
the	O
EM	B-Method
algorithm	O
the	O
responsibilities	O
are	O
assumed	O
to	O
remain	O
constant	O
when	O
optimizing	O
the	O
model	O
parameters	O
in	O
the	O
M	O
-	O
step	O
.	O
	
The	O
E	O
-	O
step	O
is	O
very	O
similar	O
to	O
that	O
of	O
a	O
standard	O
GMM	B-Method
,	O
but	O
instead	O
of	O
computing	O
the	O
responsibilities	O
nk	O
for	O
every	O
component	O
k	O
,	O
one	O
needs	O
to	O
compute	O
them	O
for	O
every	O
path	O
p	O
=	O
	
(	O
p1	O
,	O
p2	O
,	O
.	O
.	O
.	O
,	O
pk	O
)	O
2	O
.	O
	
This	O
is	O
because	O
every	O
path	O
represents	O
a	O
Gaussian	B-Method
mixture	I-Method
component	I-Method
in	O
the	O
equivalent	O
shallow	O
GMM	B-Method
.	O
	
Because	O
np	O
needs	O
to	O
be	O
computed	O
for	O
each	O
datapoint	O
independently	O
,	O
the	O
E	B-Method
-	I-Method
step	I-Method
is	O
very	O
easy	O
to	O
parallelize	O
.	O
	
Often	O
a	O
simple	O
way	O
to	O
increase	O
the	O
speed	O
of	O
convergence	B-Metric
and	O
to	O
reduce	O
computation	B-Metric
time	I-Metric
is	O
to	O
use	O
an	O
EM	B-Method
-	O
variant	O
with	O
“	O
hard	O
”	O
assignments	O
.	O
	
Here	O
only	O
one	O
of	O
the	O
responsibilities	O
of	O
each	O
datapoint	O
is	O
set	O
to	O
1	O
:	O
np	O
=	O
	
⇢	O
1	O
p	O
=	O
argmaxq	O
⇡	O
	
qN	O
xn|	O
q	O
,	O
⌦	O
q	O
	
⌦	O
Tq	O
0	O
otherwise	O
	
(	O
4	O
)	O
Heuristic	O
Because	O
the	O
number	O
of	O
paths	O
is	O
the	O
product	O
of	O
the	O
number	O
of	O
components	O
per	O
layer	O
	
(	O
Qk	O
j	O
	
Nj	O
)	O
,	O
computing	O
the	O
responsibilities	O
can	O
become	O
intractable	O
for	O
big	O
Deep	O
GMM	B-Method
networks	O
.	O
	
However	O
,	O
when	O
using	O
hard	O
-	O
EM	B-Method
variant	O
(	O
eq	O
.	O
4	O
)	O
,	O
this	O
problem	O
reduces	O
to	O
finding	O
the	O
best	O
path	O
for	O
each	O
datapoint	O
,	O
for	O
which	O
we	O
can	O
use	O
efficient	O
heuristics	O
.	O
	
Here	O
we	O
introduce	O
such	O
a	O
heuristic	O
that	O
does	O
not	O
hurt	O
the	O
performance	O
significantly	O
,	O
while	O
allowing	O
us	O
to	O
train	O
much	O
larger	O
networks	O
.	O
	
We	O
optimize	O
the	O
path	O
p	O
=	O
	
(	O
p1	O
,	O
p2	O
,	O
.	O
.	O
.	O
,	O
pk	O
)	O
,	O
which	O
is	O
a	O
multivariate	O
discrete	O
variable	O
,	O
with	O
a	O
coordinate	B-Method
ascent	I-Method
algorithm	I-Method
.	O
	
This	O
means	O
we	O
change	O
the	O
parameters	O
pi	O
layer	O
per	O
layer	O
,	O
while	O
keeping	O
the	O
parameter	O
values	O
of	O
the	O
other	O
layers	O
constant	O
.	O
	
After	O
we	O
have	O
changed	O
all	O
the	O
variables	O
one	O
time	O
(	O
one	O
pass	O
)	O
,	O
we	O
can	O
repeat	O
.	O
	
The	O
heuristic	O
described	O
above	O
only	O
requires	O
Pk	O
	
j	O
	
Nj	O
path	O
evaluations	O
per	O
pass	O
.	O
	
In	O
Figure	O
2	O
we	O
compare	O
the	O
heuristic	O
with	O
the	O
full	B-Method
search	I-Method
.	O
	
On	O
the	O
left	O
we	O
see	O
that	O
after	O
3	O
passes	O
the	O
heuristic	O
converges	O
to	O
a	O
local	O
optimum	O
.	O
	
In	O
the	O
middle	O
we	O
see	O
that	O
when	O
repeating	O
the	O
heuristic	B-Method
algorithm	I-Method
a	O
couple	O
of	O
times	O
with	O
different	O
random	O
initializations	O
,	O
and	O
keeping	O
the	O
best	O
path	O
after	O
each	O
iteration	O
,	O
the	O
loglikelihood	B-Method
converges	O
to	O
the	O
optimum	O
.	O
	
In	O
our	O
experiments	O
we	O
initialized	O
the	O
heuristic	O
with	O
the	O
optimal	O
path	O
from	O
the	O
previous	O
E	O
-	O
step	O
(	O
warm	O
start	O
)	O
and	O
performed	O
the	O
heuristic	B-Method
algorithm	I-Method
for	O
1	O
pass	O
.	O
	
Subsequently	O
we	O
ran	O
the	O
algorithm	O
for	O
a	O
second	O
time	O
with	O
a	O
random	O
initialization	O
for	O
two	O
passes	O
for	O
the	O
possibility	O
of	O
finding	O
a	O
better	O
optimum	O
for	O
each	O
datapoint	O
.	O
	
Each	O
E	O
-	O
step	O
thus	O
required	O
3	O
⇣	O
Pk	O
j	O
Nj	O
⌘	O
path	O
evaluations	O
.	O
	
In	O
Figure	O
2	O
(	O
c	O
)	O
we	O
show	O
an	O
example	O
of	O
the	O
percentage	O
of	O
data	O
points	O
(	O
called	O
the	O
switch	B-Metric
-	I-Metric
rate	I-Metric
)	O
that	O
had	O
a	O
better	O
optimum	O
with	O
this	O
second	O
initialization	O
for	O
each	O
EM	B-Method
-	O
iteration	O
.	O
	
We	O
can	O
see	O
from	O
this	O
Figure	O
that	O
the	O
switchrate	O
quickly	O
becomes	O
very	O
small	O
,	O
which	O
means	O
that	O
using	O
the	O
responsibilities	O
from	O
the	O
previous	O
E	O
-	O
step	O
is	O
an	O
efficient	O
initialization	O
for	O
the	O
current	O
one	O
.	O
	
Although	O
the	O
number	O
of	O
path	O
evaluations	O
with	O
the	O
heuristic	B-Method
is	O
substantially	O
smaller	O
than	O
with	O
the	O
full	O
search	O
,	O
we	O
saw	O
in	O
our	O
experiments	O
that	O
the	O
performance	O
of	O
the	O
resulting	O
trained	O
Deep	B-Method
GMMs	I-Method
was	O
ultimately	O
similar	O
.	O
	
3.2	O
Maximization	B-Task
	
In	O
the	O
maximization	B-Task
step	I-Task
,	O
the	O
parameters	O
are	O
updated	O
to	O
maximize	O
the	O
log	O
likelihood	O
of	O
the	O
data	O
,	O
given	O
the	O
responsibilities	O
.	O
	
Although	O
standard	O
optimization	B-Method
techniques	I-Method
for	O
training	O
deep	B-Method
networks	I-Method
can	O
be	O
used	O
(	O
such	O
as	O
SGD	B-Method
)	O
,	O
Deep	B-Method
GMMs	I-Method
have	O
some	O
interesting	O
properties	O
that	O
allow	O
us	O
to	O
train	O
them	O
more	O
efficiently	O
.	O
	
Because	O
these	O
properties	O
are	O
not	O
obvious	O
at	O
first	O
sight	O
,	O
we	O
will	O
derive	O
the	O
objective	O
and	O
gradient	O
for	O
the	O
transformation	O
matrices	O
	
Ai	O
,	O
j	O
in	O
a	O
Deep	B-Method
GMM	I-Method
.	O
	
After	O
that	O
we	O
will	O
discuss	O
various	O
ways	O
for	O
optimizing	O
them	O
.	O
	
For	O
convenience	O
,	O
the	O
derivations	O
in	O
this	O
section	O
are	O
based	O
on	O
the	O
hard	O
-	O
EM	B-Method
variant	O
and	O
with	O
omission	O
of	O
the	O
bias	O
-	O
terms	O
parameters	O
.	O
	
Equations	O
without	O
these	O
simplifications	O
can	O
be	O
obtained	O
in	O
a	O
similar	O
manner	O
.	O
	
In	O
the	O
hard	O
-	O
EM	B-Method
variant	O
,	O
it	O
is	O
assumed	O
that	O
each	O
datapoint	O
in	O
the	O
dataset	O
was	O
generated	O
by	O
a	O
path	O
p	O
,	O
for	O
which	O
n	O
,	O
p	O
=	O
1	O
.	O
	
The	O
likelihood	O
of	O
x	O
given	O
the	O
parameters	O
of	O
the	O
transformations	O
on	O
this	O
path	O
is	O
p	O
(	O
x	O
)	O
=	O
	
A	O
1	O
1	O
,	O
p1	O
.	O
.	O
.	O
	
A	O
1k	O
,	O
pk	O
N	O
	
⇣	O
A	O
	
1	O
1	O
,	O
p1	O
.	O
.	O
.	O
	
A	O
1	O
k	O
,	O
pk	O
x|0	O
,	O
	
In	O
⌘	O
,	O
(	O
5	O
)	O
where	O
we	O
use	O
|·|	O
to	O
denote	O
the	O
absolute	O
value	O
of	O
the	O
determinant	O
.	O
	
Now	O
let	O
’s	O
rewrite	O
:	O
	
z	O
=	O
	
A	O
1	O
i	O
+	O
1	O
,	O
pi	O
+	O
1	O
.	O
.	O
.	O
	
A	O
1	O
k	O
,	O
pk	O
x	O
	
(	O
6	O
)	O
Q	O
=	O
	
A	O
	
1	O
i	O
,	O
pi	O
(	O
7	O
)	O
	
Rp	O
=	O
	
A	O
1	O
1	O
,	O
p1	O
.	O
.	O
.	O
	
A	O
1	O
i	O
1	O
,	O
pi	O
1	O
,	O
(	O
8	O
)	O
z	O
	
so	O
that	O
we	O
get	O
(	O
omitting	O
the	O
constant	O
term	O
w.r.t	O
.	O
	
Q	O
)	O
:	O
log	O
p	O
	
(	O
x	O
)	O
/	O
log	O
	
|Q|	O
+	O
	
logN	O
	
(	O
RpQz|0	O
,	O
In	O
)	O
.	O
	
(	O
9	O
)	O
Figure	O
3	O
gives	O
a	O
visual	O
overview	O
.	O
	
We	O
have	O
“	O
folded	O
”	O
the	O
layers	O
above	O
the	O
current	O
layer	O
into	O
one	O
.	O
	
This	O
means	O
that	O
each	O
path	O
p	O
through	O
the	O
network	O
above	O
the	O
current	O
layer	O
is	O
equivalent	O
to	O
a	O
transformation	B-Method
Rp	I-Method
in	O
the	O
folded	B-Method
version	I-Method
.	O
	
The	O
transformation	O
matrix	O
for	O
which	O
we	O
will	O
derive	O
the	O
objective	O
and	O
gradient	O
is	O
called	O
Q.	O
	
The	O
average	O
log	O
-	O
likelihood	O
of	O
all	O
the	O
data	O
points	O
that	O
are	O
generated	O
by	O
paths	O
that	O
pass	O
through	O
Q	O
is	O
:	O
	
1	O
N	O
X	O
i	O
log	O
p	O
	
(	O
xi	O
)	O
/	O
log	O
|Q|	O
+	O
1	O
N	O
X	O
	
p	O
X	O
i2	O
p	O
logN	O
(	O
RpQzi|0	O
,	O
I	O
)	O
	
(	O
10	O
)	O
=	O
log	O
|Q|	O
1	O
2	O
X	O
	
p	O
⇡	O
pTr	O
⇥	O
pQ	O
T	O
⌦	O
	
pQ	O
	
⇤	O
,	O
(	O
11	O
)	O
where	O
⇡	O
p	O
=	O
Np	O
N	O
,	O
p	O
=	O
1	O
	
Np	O
P	O
	
i2	O
p	O
ziz	O
T	O
i	O
and	O
⌦	O
p	O
=	O
RTp	O
	
Rp	O
.	O
	
For	O
the	O
gradient	O
we	O
get	O
:	O
1	O
N	O
rQ	O
X	O
i	O
log	O
p	O
(	O
xi	O
)	O
=	O
	
Q	O
T	O
X	O
p	O
⇡	O
p	O
pQ	O
T	O
⌦	O
p.	O
(	O
12	O
)	O
Optimization	B-Task
Notice	O
how	O
in	O
Equation	O
11	O
the	O
summation	O
over	O
the	O
data	O
points	O
has	O
been	O
converted	O
to	O
a	O
summation	B-Method
over	I-Method
covariance	I-Method
matrices	I-Method
:	O
one	O
for	O
each	O
path1	O
.	O
	
If	O
the	O
number	O
of	O
paths	O
is	O
small	O
enough	O
,	O
this	O
means	O
we	O
can	O
use	O
full	B-Method
gradient	I-Method
updates	I-Method
instead	O
of	O
mini	B-Method
-	I-Method
batched	I-Method
updates	I-Method
(	O
e.g.	O
SGD	B-Method
)	O
.	O
	
The	O
computation	O
of	O
the	O
covariance	O
matrices	O
is	O
fairly	O
efficient	O
and	O
can	O
be	O
done	O
in	O
parallel	O
.	O
	
This	O
formulation	O
also	O
allows	O
us	O
to	O
use	O
more	O
advanced	O
optimization	B-Method
methods	I-Method
,	O
such	O
as	O
LBFGS	B-Method
-	I-Method
B	I-Method
[	O
12	O
]	O
.	O
	
In	O
the	O
setup	O
described	O
above	O
,	O
we	O
need	O
to	O
keep	O
the	O
transformation	O
Rp	O
constant	O
while	O
optimizing	O
Q.	O
	
This	O
is	O
why	O
in	O
each	O
M	O
-	O
step	O
	
the	O
Deep	B-Method
GMM	I-Method
is	O
optimized	O
layer	O
-	O
wise	O
from	O
top	O
to	O
bottom	O
,	O
updating	O
one	O
layer	O
at	O
a	O
time	O
.	O
	
It	O
is	O
possible	O
to	O
go	O
over	O
this	O
process	O
multiple	O
times	O
for	O
each	O
M	O
-	O
step	O
.	O
	
Important	O
to	O
note	O
is	O
that	O
this	O
way	O
the	O
optimization	B-Task
of	I-Task
Q	I-Task
does	O
not	O
depend	O
on	O
any	O
other	O
parameters	O
in	O
the	O
same	O
layer	O
.	O
	
So	O
for	O
each	O
layer	O
,	O
the	O
optimization	B-Task
of	O
the	O
different	O
nodes	O
can	O
be	O
done	O
in	O
parallel	O
on	O
multiple	O
cores	O
or	O
machines	O
.	O
	
Moreover	O
,	O
nodes	O
in	O
the	O
same	O
layer	O
do	O
not	O
share	O
data	O
points	O
when	O
using	O
the	O
EMvariant	B-Method
with	O
hard	O
-	O
assignments	O
.	O
	
Another	O
advantage	O
is	O
that	O
this	O
method	O
is	O
easy	O
to	O
control	O
,	O
as	O
there	O
are	O
no	O
learning	O
rates	O
or	O
other	O
optimization	O
parameters	O
to	O
be	O
tuned	O
,	O
when	O
using	O
L	B-Method
-	I-Method
BFGS	I-Method
-	I-Method
B	I-Method
“	O
out	O
of	O
the	O
box	O
”	O
.	O
	
A	O
disadvantage	O
is	O
that	O
one	O
needs	O
to	O
sum	O
over	O
all	O
possible	O
paths	O
above	O
the	O
current	O
node	O
in	O
the	O
gradient	B-Task
computation	I-Task
.	O
	
For	O
deeper	B-Task
networks	I-Task
,	O
this	O
may	O
become	O
problematic	O
when	O
optimizing	O
the	O
lower	O
-	O
level	O
nodes	O
.	O
	
Alternatively	O
,	O
one	O
can	O
also	O
evaluate	O
(	O
11	O
)	O
using	O
Kronecker	O
products	O
as	O
·	O
·	O
·	O
=	O
log	O
	
|Q|	O
+	O
	
vec	O
(	O
Q	O
)	O
T	O
	
(	O
X	O
p	O
⇡	O
p	O
	
(	O
⌦	O
p	O
⌦	O
p	O
)	O
)	O
	
vec	O
(	O
Q	O
)	O
	
(	O
13	O
)	O
	
1Actually	O
we	O
only	O
need	O
to	O
sum	O
over	O
the	O
number	O
of	O
possible	O
transformations	O
Rp	O
above	O
the	O
node	O
Q.	O
and	O
Equation	O
12	O
as	O
·	O
·	O
·	O
=	O
Q	O
T	O
+	O
2mat	O
(	O
X	O
p	O
⇡	O
p	O
(	O
⌦	O
p	O
⌦	O
p	O
)	O
)	O
	
vec	O
(	O
Q	O
)	O
!	O
.	O
	
(	O
14	O
)	O
	
Here	O
vec	B-Method
is	O
the	O
vectorization	B-Method
operator	I-Method
and	O
mat	O
its	O
inverse	O
.	O
	
With	O
these	O
formulations	O
we	O
do	O
n’t	O
have	O
to	O
loop	O
over	O
the	O
number	O
of	O
paths	O
anymore	O
during	O
the	O
optimization	B-Task
.	O
	
This	O
makes	O
the	O
inner	B-Method
optimization	I-Method
with	O
LBFGS	B-Method
-	I-Method
B	I-Method
even	O
faster	O
.	O
	
We	O
only	O
have	O
to	O
construct	O
P	O
p	O
⇡	O
p	O
(	O
⌦	O
p	O
⌦	O
p	O
)	O
once	O
,	O
which	O
is	O
also	O
easy	O
to	O
parallelize	O
.	O
	
These	O
equation	O
thus	O
allow	O
us	O
to	O
train	O
even	O
bigger	O
Deep	O
GMM	B-Method
architectures	O
.	O
	
A	O
disadvantage	O
,	O
however	O
,	O
is	O
that	O
it	O
requires	O
the	O
dimensionality	O
of	O
the	O
data	O
to	O
be	O
small	O
enough	O
to	O
efficiently	O
construct	O
the	O
Kronecker	O
products	O
.	O
	
When	O
the	O
aforementioned	O
formulations	O
are	O
intractable	O
because	O
there	O
are	O
too	O
number	O
layers	O
in	O
the	O
Deep	B-Method
GMM	I-Method
and	O
the	O
data	O
dimensionality	O
is	O
to	O
high	O
,	O
we	O
can	O
also	O
optimize	O
the	O
parameters	O
using	O
backpropagation	B-Method
with	O
a	O
minibatch	B-Method
algorithm	I-Method
,	O
such	O
as	O
Stochastic	B-Method
Gradient	I-Method
Descent	I-Method
(	O
SGD	B-Method
)	O
.	O
	
This	O
approach	O
works	O
for	O
much	O
deeper	B-Task
networks	I-Task
,	O
because	O
we	O
do	O
n’t	O
need	O
to	O
sum	O
over	O
the	O
number	O
of	O
paths	O
.	O
	
From	O
Equation	O
9	O
we	O
see	O
that	O
this	O
is	O
basically	O
the	O
same	O
as	O
minimizing	O
the	O
L2	O
norm	O
of	O
RpQz	O
,	O
with	O
log	O
|Q|	O
as	O
regularization	O
term	O
.	O
	
Disadvantages	O
include	O
the	O
use	O
of	O
learning	O
rates	O
and	O
other	O
parameters	O
such	O
as	O
momentum	O
,	O
which	O
requires	O
more	O
engineering	O
and	O
fine	O
-	O
tuning	O
.	O
	
The	O
most	O
naive	O
way	O
is	O
to	O
optimize	O
the	O
deep	O
GMM	B-Method
with	O
SGD	B-Method
is	O
by	O
simultaneously	O
optimizing	O
all	O
parameters	O
,	O
as	O
is	O
common	O
in	O
neural	B-Method
networks	I-Method
.	O
	
When	O
doing	O
this	O
it	O
is	O
important	O
that	O
the	O
parameters	O
of	O
all	O
nodes	O
are	O
converged	O
enough	O
in	O
each	O
M	O
-	O
step	O
,	O
otherwise	O
nodes	O
that	O
are	O
not	O
optimized	O
enough	O
may	O
have	O
very	O
low	O
responsibilities	O
in	O
the	O
following	O
E	O
-	O
step	O
(	O
s	O
)	O
.	O
	
This	O
results	O
in	O
whole	O
parts	O
of	O
the	O
network	O
becoming	O
unused	O
,	O
which	O
is	O
the	O
equivalent	O
of	O
empty	O
clusters	O
during	O
GMM	B-Method
or	O
k	O
-	O
means	O
training	O
.	O
	
An	O
alternative	O
way	O
of	O
using	O
SGD	B-Method
is	O
again	O
by	O
optimizing	O
the	O
Deep	O
GMM	B-Method
layer	O
by	O
layer	O
.	O
	
This	O
has	O
the	O
advantage	O
that	O
we	O
have	O
more	O
control	O
over	O
the	O
optimization	B-Task
,	O
which	O
prevents	O
the	O
aforementioned	O
problem	O
of	O
unused	O
paths	O
.	O
	
But	O
more	O
importantly	O
,	O
we	O
can	O
now	O
again	O
parallelize	O
over	O
the	O
number	O
of	O
nodes	O
per	O
layer	O
.	O
	
4	O
Experiments	O
and	O
Results	O
For	O
our	O
experiments	O
we	O
used	O
the	O
Berkeley	O
Segmentation	O
Dataset	O
(	O
BSDS300	O
)	O
[	O
13	O
]	O
,	O
which	O
is	O
a	O
commonly	O
used	O
benchmark	O
for	O
density	B-Task
modeling	I-Task
of	I-Task
image	I-Task
patches	I-Task
and	O
the	O
tiny	O
images	O
dataset	O
	
[	O
14	O
]	O
.	O
	
For	O
BSDS300	O
we	O
follow	O
the	O
same	O
setup	O
of	O
Uria	O
et	O
al	O
.	O
	
[	O
15	O
]	O
,	O
which	O
is	O
best	O
practice	O
for	O
this	O
dataset	O
.	O
	
8	O
by	O
8	O
grayscale	O
patches	O
are	O
drawn	O
from	O
images	O
of	O
the	O
dataset	O
.	O
	
The	O
train	O
and	O
test	O
sets	O
consists	O
of	O
200	O
and	O
100	O
images	O
respectively	O
.	O
	
Because	O
each	O
pixel	O
is	O
quantized	O
,	O
it	O
can	O
only	O
contain	O
integer	O
values	O
between	O
0	O
and	O
255	O
.	O
	
To	O
make	O
the	O
integer	O
pixel	O
values	O
continuous	O
,	O
uniform	O
noise	O
(	O
between	O
0	O
and	O
1	O
)	O
is	O
added	O
.	O
	
Afterwards	O
,	O
the	O
images	O
are	O
divided	O
by	O
256	O
so	O
that	O
the	O
pixel	O
values	O
lie	O
in	O
the	O
range	O
[	O
0	O
,	O
	
1	O
]	O
.	O
	
Next	O
,	O
the	O
patches	O
are	O
preprocessed	O
by	O
removing	O
the	O
mean	O
pixel	O
value	O
of	O
every	O
image	O
patch	O
.	O
	
Because	O
this	O
reduces	O
the	O
implicit	O
dimensionality	O
of	O
the	O
data	O
,	O
the	O
last	O
pixel	O
value	O
is	O
removed	O
.	O
	
This	O
results	O
in	O
the	O
data	O
points	O
having	O
63	O
dimensions	O
.	O
	
For	O
the	O
tiny	O
images	O
dataset	O
we	O
rescale	O
the	O
images	O
to	O
8	O
by	O
8	O
and	O
then	O
follow	O
the	O
same	O
setup	O
.	O
	
This	O
way	O
we	O
also	O
have	O
low	O
resolution	O
image	O
data	O
to	O
evaluate	O
on	O
.	O
	
In	O
all	O
the	O
experiments	O
described	O
in	O
this	O
section	O
,	O
we	O
used	O
the	O
following	O
setup	O
for	O
training	O
Deep	B-Method
GMMs	I-Method
.	O
	
We	O
used	O
the	O
hard	O
-	O
EM	B-Method
variant	O
,	O
with	O
the	O
aforementioned	O
heuristic	O
in	O
the	O
E	O
-	O
step	O
.	O
	
For	O
each	O
M	O
-	O
step	O
we	O
used	O
LBFGS	B-Method
-	I-Method
B	I-Method
for	O
1000	O
iterations	O
by	O
using	O
equations	O
(	O
13	O
)	O
and	O
(	O
14	O
)	O
for	O
the	O
objective	O
and	O
gradient	O
.	O
	
The	O
total	O
number	O
of	O
iterations	O
we	O
used	O
for	O
EM	B-Method
was	O
fixed	O
to	O
100	O
,	O
although	O
fewer	O
iterations	O
were	O
usually	O
sufficient	O
.	O
	
The	O
only	O
hyperparameters	O
were	O
the	O
number	O
of	O
components	O
for	O
each	O
layer	O
,	O
which	O
were	O
optimized	O
on	O
a	O
validation	O
set	O
.	O
	
Because	O
GMMs	B-Method
are	O
in	O
theory	O
able	O
to	O
represent	O
the	O
same	O
probability	O
density	O
functions	O
as	O
a	O
Deep	B-Method
GMM	I-Method
,	O
we	O
first	O
need	O
to	O
assess	O
wether	O
using	O
multiple	B-Method
layers	I-Method
with	O
a	O
deep	O
GMM	B-Method
improves	O
performance	O
.	O
	
The	O
results	O
of	O
a	O
GMM	B-Method
(	O
one	O
layer	O
)	O
and	O
Deep	B-Method
GMMs	I-Method
with	O
two	O
or	O
three	O
layers	O
are	O
given	O
in	O
4	O
(	O
a	O
)	O
.	O
	
As	O
we	O
increase	O
the	O
complexity	O
and	O
number	O
of	O
parameters	O
of	O
the	O
model	O
by	O
changing	O
the	O
number	O
of	O
components	O
in	O
the	O
top	O
layer	O
,	O
a	O
plateau	O
is	O
reached	O
and	O
the	O
models	O
ultimately	O
start	O
overfitting	O
.	O
	
For	O
the	O
deep	B-Method
GMMs	I-Method
,	O
the	O
number	O
of	O
components	O
in	O
the	O
other	O
layers	O
was	O
kept	O
constant	O
(	O
5	O
components	O
)	O
.	O
	
The	O
Deep	B-Method
GMMs	I-Method
seem	O
to	O
generalize	O
better	O
.	O
	
Although	O
they	O
have	O
a	O
similar	O
number	O
of	O
parameters	O
,	O
they	O
are	O
able	O
to	O
model	O
more	O
complex	O
relationships	O
,	O
without	O
overfitting	O
.	O
	
We	O
also	O
tried	O
this	O
experiment	O
on	O
a	O
more	O
difficult	O
dataset	O
by	O
using	O
highly	O
downscaled	O
images	O
from	O
the	O
tiny	O
images	O
dataset	O
,	O
see	O
Figure	O
4	O
(	O
b	O
)	O
.	O
	
Because	O
there	O
are	O
less	O
correlations	O
between	O
the	O
pixels	O
of	O
a	O
downscaled	O
image	O
than	O
between	O
those	O
of	O
an	O
image	O
patch	O
,	O
the	O
average	B-Metric
log	I-Metric
likelihood	I-Metric
values	I-Metric
are	O
lower	O
.	O
	
Overall	O
we	O
can	O
see	O
that	O
the	O
Deep	B-Method
GMM	I-Method
performs	O
well	O
on	O
both	O
low	O
and	O
high	O
resolution	O
natural	O
images	O
.	O
	
Next	O
we	O
will	O
compare	O
the	O
deep	O
GMM	B-Method
with	O
other	O
published	O
methods	O
on	O
this	O
task	O
.	O
	
Results	O
are	O
shown	O
in	O
Table	O
1	O
.	O
	
The	O
first	O
method	O
is	O
the	O
RNADE	B-Method
model	I-Method
,	O
a	O
new	O
deep	B-Method
density	I-Method
estimation	I-Method
technique	I-Method
which	O
is	O
an	O
extension	O
of	O
the	O
NADE	B-Method
model	I-Method
for	O
real	O
valued	O
data	O
[	O
16	O
,	O
15	O
]	O
.	O
EoRNADE	B-Method
,	O
which	O
stands	O
for	O
ensemble	B-Method
of	I-Method
RNADE	I-Method
models	I-Method
,	O
is	O
currently	O
the	O
state	O
of	O
the	O
art	O
.	O
	
We	O
also	O
report	O
the	O
log	B-Metric
-	I-Metric
likelihood	I-Metric
results	O
of	O
two	O
mixture	B-Method
models	I-Method
:	O
the	O
GMM	B-Method
and	O
the	O
Student	B-Method
-	I-Method
T	I-Method
Mixture	I-Method
model	I-Method
,	O
from	O
[	O
2	O
]	O
.	O
	
Overall	O
we	O
see	O
that	O
the	O
Deep	B-Method
GMM	I-Method
has	O
a	O
strong	O
performance	O
.	O
	
It	O
scores	O
better	O
than	O
other	O
single	O
models	O
(	O
RNADE	B-Method
,	O
STM	B-Method
)	O
,	O
but	O
not	O
as	O
well	O
as	O
the	O
ensemble	B-Method
of	I-Method
RNADE	I-Method
models	I-Method
.	O
	
5	O
Conclusion	O
	
In	O
this	O
work	O
we	O
introduced	O
the	O
deep	B-Method
Gaussian	I-Method
Mixture	I-Method
Model	I-Method
:	O
a	O
novel	O
density	B-Method
estimation	I-Method
technique	I-Method
for	O
modeling	B-Task
real	I-Task
valued	I-Task
data	I-Task
.	O
	
we	O
show	O
that	O
the	O
Deep	B-Method
GMM	I-Method
is	O
on	O
par	O
with	O
the	O
current	O
state	O
of	O
the	O
art	O
in	O
image	B-Method
patch	I-Method
modeling	I-Method
,	O
and	O
surpasses	O
other	O
mixture	B-Method
models	I-Method
.	O
	
We	O
conclude	O
that	O
the	O
Deep	B-Method
GMM	I-Method
is	O
a	O
viable	O
and	O
scalable	O
alternative	O
for	O
unsupervised	B-Task
learning	I-Task
.	O
	
The	O
deep	O
GMM	B-Method
tackles	O
unsupervised	B-Task
learning	I-Task
from	O
a	O
different	O
angle	O
than	O
other	O
recent	O
deep	B-Method
unsupervised	I-Method
learning	I-Method
techniques	I-Method
[	O
17	O
,	O
18	O
,	O
19	O
]	O
,	O
which	O
makes	O
it	O
very	O
interesting	O
for	O
future	O
research	O
.	O
	
In	O
follow	O
-	O
up	O
work	O
,	O
we	O
would	O
like	O
to	O
make	O
Deep	B-Method
GMMs	I-Method
suitable	O
for	O
larger	O
images	O
and	O
other	O
highdimensional	O
data	O
.	O
	
Locally	B-Method
connected	I-Method
filters	I-Method
,	O
such	O
as	O
convolutions	B-Method
would	O
be	O
useful	O
for	O
this	O
.	O
	
We	O
would	O
also	O
like	O
to	O
extend	O
our	O
method	O
to	O
modeling	B-Task
discrete	I-Task
data	I-Task
.	O
	
Deep	B-Method
GMMs	I-Method
are	O
currently	O
only	O
designed	O
for	O
continuous	O
real	O
-	O
valued	O
data	O
,	O
but	O
our	O
approach	O
of	O
reparametrizing	O
the	O
model	O
into	O
layers	O
of	O
successive	B-Method
transformations	I-Method
can	O
also	O
be	O
applied	O
to	O
other	O
types	O
of	O
mixture	O
distributions	O
.	O
	
We	O
would	O
also	O
like	O
to	O
compare	O
this	O
extension	O
to	O
other	O
discrete	B-Method
density	I-Method
estimators	I-Method
such	O
as	O
Restricted	B-Method
Boltzmann	I-Method
Machines	I-Method
,	O
Deep	B-Method
Belief	I-Method
Networks	I-Method
and	O
the	O
NADE	B-Method
model	I-Method
	
[	O
15	O
]	O
.	O
	
Seven	O
ways	O
to	O
improve	O
example	B-Task
-	I-Task
based	I-Task
single	I-Task
image	I-Task
super	I-Task
resolution	I-Task
	
section	O
:	O
Abstract	O
	
In	O
this	O
paper	O
we	O
present	O
seven	O
techniques	O
that	O
everybody	O
should	O
know	O
to	O
improve	O
example	B-Task
-	I-Task
based	I-Task
single	I-Task
image	I-Task
super	I-Task
resolution	I-Task
(	O
SR	B-Task
)	O
	
:	O
1	O
)	O
augmentation	B-Method
of	I-Method
data	I-Method
,	O
2	O
)	O
use	O
of	O
large	B-Method
dictionaries	I-Method
with	O
efficient	O
search	O
structures	O
,	O
3	O
)	O
cascading	B-Method
,	O
4	O
)	O
image	B-Method
self	I-Method
-	I-Method
similarities	I-Method
,	O
5	O
)	O
back	B-Method
projection	I-Method
refinement	I-Method
,	O
6	O
)	O
enhanced	O
prediction	B-Method
by	O
consistency	O
check	O
,	O
and	O
7	O
)	O
context	B-Method
reasoning	I-Method
.	O
	
We	O
validate	O
our	O
seven	O
techniques	O
on	O
standard	O
SR	B-Task
benchmarks	O
(	O
i.e.	O
Set5	B-Material
,	O
Set14	B-Material
,	O
B100	B-Material
)	O
and	O
methods	O
(	O
i.e.	O
A	B-Method
+	I-Method
,	O
SR	B-Task
-	O
CNN	O
,	O
ANR	B-Method
,	O
Zeyde	B-Method
,	O
Yang	B-Method
)	O
and	O
achieve	O
substantial	O
improvements	O
.	O
	
The	O
techniques	O
are	O
widely	O
applicable	O
and	O
require	O
no	O
changes	O
or	O
only	O
minor	O
adjustments	O
of	O
the	O
SR	B-Task
methods	O
.	O
	
Moreover	O
,	O
our	O
Improved	B-Method
A	I-Method
+	I-Method
(	O
IA	B-Method
)	O
method	O
sets	O
new	O
stateof	O
-	O
the	O
-	O
art	O
results	O
outperforming	O
A	B-Method
+	O
by	O
up	O
to	O
0.9dB	O
on	O
average	B-Metric
PSNR	I-Metric
whilst	O
maintaining	O
a	O
low	O
time	B-Metric
complexity	I-Metric
.	O
	
section	O
:	O
Introduction	O
	
Single	B-Task
image	I-Task
super	I-Task
-	I-Task
resolution	I-Task
(	O
SR	B-Task
)	O
aims	O
at	O
reconstructing	O
a	O
high	B-Task
-	I-Task
resolution	I-Task
(	I-Task
HR	I-Task
)	I-Task
image	I-Task
by	O
restoring	O
the	O
high	O
frequencies	O
details	O
from	O
a	O
single	O
low	O
-	O
resolution	O
(	O
LR	O
)	O
image	O
.	O
	
SR	B-Task
is	O
heavily	O
ill	O
-	O
posed	O
since	O
multiple	O
HR	O
patches	O
could	O
correspond	O
to	O
the	O
same	O
LR	O
image	O
patch	O
.	O
	
To	O
address	O
this	O
problem	O
,	O
the	O
SR	B-Method
literature	I-Method
proposes	O
interpolation	B-Method
-	I-Method
based	I-Method
methods	I-Method
[	O
reference	O
]	O
,	O
reconstruction	B-Method
-	I-Method
based	I-Method
methods	I-Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
,	O
and	O
learning	B-Method
-	I-Method
based	I-Method
methods	I-Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
	
The	O
example	O
-	O
based	O
SR	B-Task
[	O
reference	O
]	O
uses	O
prior	O
knowledge	O
under	O
the	O
form	O
of	O
corresponding	O
pairs	O
of	O
LR	O
-	O
HR	O
image	O
patches	O
extracted	O
internally	O
from	O
the	O
input	O
LR	O
image	O
or	O
from	O
external	O
images	O
.	O
	
Most	O
recent	O
methods	O
fit	O
into	O
this	O
category	O
.	O
	
In	O
this	O
paper	O
we	O
present	O
seven	O
ways	O
to	O
improve	O
examplebased	B-Task
SR	I-Task
.	O
	
We	O
apply	O
them	O
to	O
the	O
major	O
recent	O
methods	O
:	O
the	O
Adjusted	B-Method
Anchored	I-Method
Neighborhood	I-Method
Regression	I-Method
(	O
A	B-Method
+	I-Method
)	O
method	O
introduced	O
recently	O
by	O
Timofte	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
,	O
	
the	O
prior	B-Method
Anchored	I-Method
Neighborhood	I-Method
Regression	I-Method
(	O
ANR	B-Method
)	O
method	O
by	O
the	O
same	O
authors	O
[	O
reference	O
]	O
,	O
the	O
efficient	O
K	B-Method
-	I-Method
SVD	I-Method
/	I-Method
OMP	I-Method
method	I-Method
of	O
Zeyde	B-Method
et	O
al	O
.	O
	
[	O
reference	O
]	O
,	O
the	O
sparse	B-Method
coding	I-Method
method	I-Method
of	O
Yang	B-Method
et	O
al	O
.	O
	
[	O
reference	O
]	O
,	O
and	O
the	O
convolutional	B-Method
neural	I-Method
network	I-Method
method	I-Method
(	O
SR	B-Task
-	O
+	O
0.9dB	O
Figure	O
1	O
.	O
	
We	O
largely	O
improve	O
(	O
red	O
)	O
over	O
the	O
original	O
examplebased	B-Method
single	I-Method
image	I-Method
super	I-Method
-	I-Method
resolution	I-Method
methods	I-Method
(	O
blue	O
)	O
,	O
i.e.	O
our	O
IA	B-Method
method	I-Method
is	O
0.9dB	O
better	O
than	O
A	B-Method
+	O
[	O
reference	O
]	O
and	O
2dB	O
better	O
than	O
Yang	B-Method
et	O
al	O
.	O
	
[	O
reference	O
]	O
.	O
Results	O
reported	O
on	O
Set5	B-Material
,	O
×3	O
.	O
	
Details	O
in	O
Section	O
4.1	O
.	O
	
CNN	B-Method
)	O
of	O
Dong	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
.	O
	
We	O
achieve	O
consistently	O
significant	O
improvements	O
on	O
standard	O
benchmarks	O
.	O
	
Also	O
,	O
we	O
combine	O
the	O
techniques	O
to	O
derive	O
our	O
Improved	B-Method
A	I-Method
+	I-Method
(	O
IA	B-Method
)	O
method	O
.	O
	
Fig	O
.	O
	
1	O
shows	O
a	O
comparison	O
of	O
the	O
large	O
relative	O
improvements	O
when	O
starting	O
from	O
the	O
A	B-Method
+	I-Method
,	O
ANR	B-Method
,	O
Zeyde	B-Method
,	O
or	O
Yang	B-Method
methods	O
on	O
Set5	B-Material
test	O
images	O
for	O
magnification	O
factor	O
×3	O
.	O
	
Zeyde	B-Method
is	O
improved	O
by	O
0.7dB	O
in	O
Peak	B-Metric
Signal	I-Metric
to	I-Metric
Noise	I-Metric
Ratio	I-Metric
(	I-Metric
PSNR	I-Metric
)	I-Metric
,	O
Yang	B-Method
and	O
ANR	B-Method
by	O
0.8dB	O
,	O
and	O
A	B-Method
+	I-Method
by	O
0.9dB.	O
	
Also	O
,	O
in	O
Fig	O
.	O
	
8	O
	
we	O
draw	O
a	O
summary	O
of	O
improvements	O
for	O
A	B-Method
+	O
in	O
relation	O
to	O
our	O
proposed	O
Improved	B-Method
A	I-Method
+	I-Method
(	O
IA	B-Method
)	O
method	O
.	O
	
The	O
remainder	O
of	O
the	O
paper	O
is	O
structured	O
as	O
follows	O
.	O
	
First	O
,	O
in	O
Section	O
2	O
we	O
describe	O
the	O
framework	O
that	O
we	O
use	O
in	O
all	O
our	O
experiments	O
and	O
briefly	O
review	O
the	O
anchored	B-Method
regression	I-Method
baseline	I-Method
-	O
the	O
	
A	B-Method
+	O
method	O
	
[	O
reference	O
]	O
.	O
	
Then	O
in	O
Section	O
3	O
we	O
present	O
the	O
seven	O
ways	O
to	O
improve	O
SR	B-Task
and	O
introduce	O
our	O
Improved	B-Method
A	I-Method
+	I-Method
(	O
IA	B-Method
)	O
method	O
.	O
	
In	O
Section	O
4	O
we	O
discuss	O
the	O
generality	O
of	O
the	O
proposed	O
techniques	O
and	O
the	O
results	O
,	O
to	O
then	O
draw	O
the	O
conclusions	O
in	O
Section	O
5	O
.	O
	
section	O
:	O
General	O
framework	O
	
We	O
adopt	O
the	O
framework	O
of	O
[	O
reference	O
][	O
reference	O
]	O
we	O
use	O
91	O
training	O
images	O
proposed	O
by	O
[	O
reference	O
]	O
,	O
and	O
work	O
in	O
the	O
YCbCr	O
color	O
space	O
on	O
the	O
luminance	O
component	O
while	O
the	O
chroma	O
components	O
are	O
bicubically	O
interpolated	O
.	O
	
For	O
a	O
given	O
magnification	O
factor	O
,	O
these	O
HR	O
images	O
are	O
(	O
bicubically	O
)	O
downscaled	O
to	O
the	O
corresponding	O
LR	O
images	O
.	O
	
The	O
magnification	O
factor	O
is	O
fixed	O
to	O
×3	O
when	O
comparing	O
the	O
7	O
techniques	O
.	O
	
The	O
LR	B-Method
and	O
their	O
corresponding	O
HR	O
images	O
are	O
then	O
used	O
for	O
training	O
example	B-Task
-	I-Task
based	I-Task
super	I-Task
-	I-Task
resolution	I-Task
methods	I-Task
such	O
as	O
A	B-Method
+	O
[	O
reference	O
]	O
,	O
ANR	B-Method
[	O
reference	O
]	O
,	O
or	O
Zeyde	B-Method
	
[	O
reference	O
]	O
.	O
For	O
quantitative	O
(	O
PSNR	B-Metric
)	O
and	O
qualitative	B-Metric
evaluation	I-Metric
3	O
datasets	O
Set5	B-Material
,	O
Set14	B-Material
,	O
and	O
B100	B-Material
are	O
used	O
as	O
in	O
[	O
reference	O
]	O
.	O
	
In	O
the	O
next	O
section	O
we	O
first	O
describe	O
the	O
employed	O
datasets	O
,	O
then	O
the	O
methods	O
we	O
use	O
or	O
compare	O
with	O
,	O
to	O
finally	O
briefly	O
review	O
the	O
A	B-Method
+	O
[	O
reference	O
]	O
baseline	O
method	O
.	O
	
section	O
:	O
Datasets	O
	
We	O
use	O
the	O
same	O
standard	O
benchmarks	O
and	O
datasets	O
as	O
used	O
in	O
[	O
reference	O
]	O
for	O
introducing	O
A	B-Method
+	O
,	O
and	O
in	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
among	O
others	O
.	O
	
Train91	B-Method
is	O
a	O
training	O
set	O
of	O
91	O
RGB	O
color	O
bitmap	O
images	O
as	O
proposed	O
by	O
Yang	B-Method
et	O
al	O
.	O
	
[	O
reference	O
]	O
.	O
Train91	O
contains	O
mainly	O
small	O
sized	O
flower	O
images	O
.	O
	
The	O
average	O
image	O
size	O
is	O
only	O
∼	O
6	O
,	O
500	O
pixels	O
.	O
	
Fig	O
.	O
	
2	O
shows	O
one	O
of	O
the	O
training	O
images	O
.	O
	
Set5	B-Material
is	O
used	O
for	O
reporting	O
results	O
.	O
	
It	O
contains	O
five	O
popular	O
images	O
:	O
one	O
medium	O
size	O
image	O
(	O
'	O
baby	O
'	O
,	O
512	O
×	O
512	O
)	O
and	O
four	O
smaller	O
ones	O
(	O
'	O
bird	O
'	O
,	O
'	O
butterfly'	O
,	O
'head	O
'	O
,	O
'	O
women	O
'	O
)	O
.	O
	
They	O
were	O
used	O
in	O
[	O
reference	O
]	O
and	O
adopted	O
under	O
the	O
name	O
'	O
Set5	B-Material
'	O
in	O
[	O
reference	O
]	O
.	O
Set14	B-Material
is	O
a	O
larger	O
,	O
more	O
diverse	O
set	O
than	O
Set5	B-Material
.	O
	
It	O
contains	O
14	O
commonly	O
used	O
bitmap	O
images	O
for	O
reporting	O
image	B-Task
processing	I-Task
results	O
.	O
	
The	O
images	O
in	O
Set14	B-Material
are	O
larger	O
on	O
average	O
than	O
those	O
in	O
Set5	B-Material
.	O
	
This	O
selection	O
of	O
14	O
images	O
was	O
proposed	O
by	O
Zeyde	B-Method
et	O
al	O
.	O
	
[	O
reference	O
]	O
.	O
B100	B-Material
is	O
the	O
testing	O
set	O
of	O
100	O
images	O
from	O
the	O
Berkeley	B-Material
Segmentation	I-Material
Dataset	I-Material
[	O
reference	O
]	O
.	O
	
The	O
images	O
cover	O
a	O
large	O
variety	O
of	O
real	O
-	O
life	O
scenes	O
and	O
all	O
have	O
the	O
same	O
size	O
of	O
481×321	O
pixels	O
.	O
	
We	O
use	O
them	O
for	O
testing	O
as	O
in	O
[	O
reference	O
]	O
.	O
L20	O
is	O
our	O
newly	O
proposed	O
dataset	O
.	O
	
Since	O
all	O
the	O
above	O
mentioned	O
datasets	O
have	O
images	O
of	O
medium	O
-	O
low	O
resolution	O
,	O
below	O
0.5	O
m	O
pixels	O
,	O
we	O
decided	O
to	O
created	O
a	O
new	O
dataset	O
,	O
L20	O
,	O
with	O
20	O
large	O
high	O
resolution	O
images	O
.	O
	
The	O
images	O
,	O
as	O
seen	O
in	O
Fig	O
.	O
	
10	O
,	O
are	O
diverse	O
in	O
content	O
,	O
and	O
their	O
sizes	O
vary	O
from	O
3	O
m	O
pixels	O
to	O
up	O
to	O
29	O
m	O
pixels	O
.	O
	
We	O
conduct	O
the	O
selfsimilarity	B-Method
(	I-Method
S	I-Method
)	O
experiments	O
on	O
the	O
L20	O
dataset	O
as	O
discussed	O
in	O
Section	O
3.6	O
.	O
	
section	O
:	O
Methods	O
	
We	O
report	O
results	O
for	O
a	O
number	O
of	O
representative	O
SR	B-Task
methods	O
.	O
	
Yang	B-Method
is	O
a	O
method	O
of	O
Yang	B-Method
et	O
al	O
.	O
	
[	O
reference	O
]	O
that	O
employs	O
sparse	B-Method
coding	I-Method
and	O
sparse	B-Method
dictionaries	I-Method
for	O
learning	O
a	O
compact	B-Method
representation	I-Method
of	O
the	O
LR	O
-	O
HR	O
priors	O
/	O
training	O
samples	O
and	O
for	O
sharp	B-Task
HR	I-Task
reconstruction	I-Task
results	O
.	O
	
Zeyde	B-Method
is	O
a	O
method	O
of	O
Zeyde	B-Method
et	O
al	O
.	O
	
[	O
reference	O
]	O
that	O
improves	O
the	O
Yang	B-Method
method	O
by	O
efficiently	O
learning	O
dictionaries	B-Method
using	O
K	B-Method
-	I-Method
SVD	I-Method
[	O
reference	O
]	O
and	O
employing	O
Orthogonal	B-Method
Matching	I-Method
Pursuit	I-Method
(	O
OMP	B-Method
)	I-Method
for	O
sparse	B-Task
solutions	I-Task
.	O
	
ANR	B-Method
or	O
Anchored	B-Method
Neighborhood	I-Method
Regression	I-Method
of	O
Timofte	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
relaxes	O
the	O
sparse	B-Task
decomposition	I-Task
optimization	I-Task
of	I-Task
patches	I-Task
from	O
Yang	B-Method
and	O
Zeyde	B-Method
to	O
a	O
ridge	B-Method
regression	I-Method
which	O
can	O
be	O
solved	O
offline	O
and	O
stored	O
per	O
each	O
dictionary	O
atom	O
/	O
anchor	O
.	O
	
This	O
results	O
in	O
large	O
speed	O
benefits	O
.	O
	
A	B-Method
+	O
of	O
Timofte	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
learns	O
the	O
regressors	O
from	O
all	O
the	O
training	O
patches	O
in	O
the	O
local	O
neighborhood	O
of	O
the	O
anchoring	O
point	O
/	O
dictionary	O
atom	O
,	O
and	O
not	O
solely	O
from	O
the	O
anchoring	O
points	O
/	O
dictionary	O
atoms	O
as	O
ANR	B-Method
does	O
.	O
	
A	B-Method
+	O
and	O
ANR	B-Method
have	O
the	O
same	O
run	B-Metric
-	I-Metric
time	I-Metric
complexity	I-Metric
.	O
	
See	O
more	O
in	O
Section	O
2.3	O
.	O
	
SRCNN	B-Method
is	O
a	O
method	O
introduced	O
by	O
Dong	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
,	O
and	O
is	O
based	O
on	O
Convolutional	B-Method
Neural	I-Method
Networks	I-Method
(	I-Method
CNN	I-Method
)	O
	
[	O
reference	O
]	O
.	O
	
It	O
directly	O
learns	O
to	O
map	O
patches	O
from	O
low	O
to	O
high	O
resolution	O
images	O
.	O
	
section	O
:	O
Anchored	B-Method
regression	I-Method
baseline	I-Method
(	O
A	B-Method
+	O
)	O
	
Our	O
main	O
baseline	O
is	O
the	O
efficient	O
Adjusted	B-Method
Anchored	I-Method
Neighborhood	I-Method
Regression	I-Method
(	O
A	B-Method
+	I-Method
)	O
method	O
[	O
reference	O
]	O
.	O
	
The	O
choice	O
is	O
motivated	O
by	O
the	O
low	B-Metric
time	I-Metric
complexity	I-Metric
of	O
A	B-Method
+	O
both	O
at	O
training	B-Task
and	O
testing	B-Task
and	O
the	O
superior	O
performance	O
that	O
it	O
achieves	O
.	O
	
A	B-Method
+	O
and	O
our	O
improved	O
methods	O
share	O
the	O
same	O
features	O
for	O
LR	O
and	O
HR	O
patches	O
and	O
the	O
same	O
dictionary	B-Method
training	I-Method
(	O
K	B-Method
-	I-Method
SVD	I-Method
[	O
reference	O
]	O
)	O
as	O
the	O
ANR	B-Method
[	O
reference	O
]	O
and	O
Zeyde	B-Method
[	O
reference	O
]	O
methods	O
.	O
	
The	O
LR	O
features	O
are	O
vertical	O
and	O
horizontal	O
gradient	O
responses	O
,	O
PCA	B-Method
projected	O
for	O
99	O
%	O
energy	B-Metric
preservation	I-Metric
.	O
	
The	O
reference	O
LR	O
patch	O
size	O
is	O
fixed	O
to	O
3	O
×	O
3	O
while	O
the	O
HR	O
patch	O
is	O
s	O
2	O
larger	O
,	O
with	O
s	O
being	O
the	O
scaling	O
factor	O
,	O
as	O
in	O
A	B-Method
+	O
.	O
	
A	B-Method
+	O
assumes	O
a	O
partition	O
of	O
the	O
LR	O
space	O
around	O
the	O
dictionary	O
atoms	O
,	O
called	O
anchors	O
.	O
	
For	O
each	O
anchor	O
j	O
a	O
ridge	B-Method
regressor	I-Method
is	O
trained	O
on	O
the	O
local	O
neighborhood	O
N	O
l	O
of	O
fixed	O
size	O
of	O
LR	O
training	O
patches	O
(	O
features	O
)	O
.	O
	
Thus	O
,	O
for	O
each	O
LR	O
input	O
patch	O
y	O
we	O
minimize	O
	
(	O
1	O
)	O
Then	O
the	O
LR	O
input	O
patch	O
y	O
can	O
be	O
projected	O
to	O
the	O
HR	O
space	O
as	O
	
where	O
N	O
h	O
are	O
the	O
corresponding	O
HR	O
patches	O
of	O
the	O
LR	O
neighborhood	O
N	O
l	O
.	O
	
P	O
j	O
is	O
the	O
stored	O
projection	O
matrix	O
for	O
the	O
anchor	O
j.	O
	
The	O
SR	B-Task
process	O
for	O
A	B-Method
+	I-Method
(	O
and	O
ANR	B-Method
)	O
at	O
test	O
time	O
then	O
becomes	O
a	O
nearest	B-Method
anchor	I-Method
search	I-Method
followed	O
by	O
a	O
matrix	B-Method
multiplication	I-Method
(	O
application	O
of	O
the	O
corresponding	O
stored	O
regressor	B-Method
)	O
for	O
each	O
input	O
LR	O
patch	O
.	O
	
section	O
:	O
Proposed	O
methods	O
	
section	O
:	O
Augmentation	B-Task
of	I-Task
training	I-Task
data	I-Task
(	O
A	B-Method
)	O
	
More	O
training	O
data	O
results	O
in	O
an	O
increase	O
in	O
performance	O
up	O
to	O
a	O
point	O
where	O
exponentially	O
more	O
data	O
is	O
necessary	O
for	O
any	O
further	O
improvement	O
.	O
	
This	O
has	O
been	O
shown	O
,	O
among	O
others	O
,	O
by	O
Timofte	O
et	O
al	O
.	O
in	O
[	O
reference	O
][	O
reference	O
]	O
for	O
neighbor	B-Method
embedding	I-Method
methods	I-Method
and	O
anchored	B-Method
regression	I-Method
methods	I-Method
and	O
by	O
Dong	O
et	O
al	O
.	O
in	O
[	O
reference	O
][	O
reference	O
]	O
for	O
the	O
convolutional	B-Method
neural	I-Method
networks	I-Method
-	I-Method
based	I-Method
methods	I-Method
.	O
	
Zhu	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
assume	O
deformable	O
patches	O
and	O
Huang	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
transform	O
self	O
-	O
exemplars	O
.	O
	
Around	O
∼	O
0.5	O
million	O
corresponding	O
patches	O
of	O
3×3	O
pixels	O
for	O
LR	O
and	O
9	O
×	O
9	O
for	O
HR	O
are	O
extracted	O
from	O
the	O
Train91	O
images	O
.	O
	
By	O
scaling	O
the	O
training	O
images	O
in	O
[	O
reference	O
]	O
5	O
million	O
patches	O
are	O
extracted	O
for	O
A	B-Method
+	O
and	O
improve	O
the	O
PSNR	B-Metric
performance	O
from	O
32.39dB	O
with	O
0.5	O
million	O
to	O
32.55dB	O
on	O
Set5	B-Material
and	O
magnification	O
×3	O
.	O
	
Inspired	O
by	O
the	O
image	B-Task
classification	I-Task
literature	O
[	O
reference	O
]	O
,	O
we	O
consider	O
also	O
the	O
flipped	O
and	O
rotated	O
versions	O
of	O
the	O
training	O
images	O
/	O
patches	O
.	O
	
If	O
we	O
rotate	O
the	O
original	O
images	O
by	O
90	O
	
•	O
,	O
180	O
	
•	O
,	O
270	O
	
•	O
and	O
flip	O
them	O
upside	O
-	O
down	O
(	O
see	O
Fig	O
.	O
2	O
)	O
,	O
we	O
get	O
728	O
images	O
without	O
altered	O
content	O
.	O
	
In	O
Fig	O
.	O
	
3	O
	
we	O
show	O
how	O
the	O
number	O
of	O
training	O
LR	O
-	O
HR	O
samples	O
affects	O
the	O
PSNR	B-Metric
performance	O
of	O
the	O
A	B-Method
+	O
method	O
on	O
the	O
Set5	B-Material
images	O
.	O
	
The	O
performance	O
of	O
A	B-Method
+	O
with	O
1024	O
regressors	B-Method
varies	O
from	O
31.83dB	O
when	O
trained	O
on	O
5000	O
samples	O
to	O
32.39dB	O
for	O
0.5	O
million	O
and	O
32.71dB	O
when	O
using	O
50	O
million	O
training	O
samples	O
.	O
	
Note	O
that	O
the	O
running	B-Metric
time	I-Metric
at	O
test	O
stays	O
the	O
same	O
as	O
it	O
does	O
not	O
depend	O
on	O
the	O
number	O
of	O
training	O
samples	O
but	O
on	O
the	O
number	O
of	O
regressors	O
.	O
	
By	O
A	B-Method
+	O
A	B-Method
we	O
mark	O
our	O
setup	O
with	O
A	B-Method
+	O
,	O
65	O
,	O
536	O
regressors	O
and	O
50	O
million	O
training	O
samples	O
,	O
improving	O
0.3dB	O
over	O
A	B-Method
+	O
.	O
	
section	O
:	O
Large	O
dictionary	O
and	O
hierarchical	B-Method
search	I-Method
(	O
H	B-Method
)	O
	
In	O
general	O
,	O
if	O
the	O
dictionary	O
size	O
(	O
basis	O
of	O
samples	O
/	O
anchoring	O
points	O
)	O
is	O
increased	O
,	O
the	O
performance	O
for	O
sparse	B-Method
coding	I-Method
(	O
such	O
as	O
Zeyde	B-Method
[	O
reference	O
]	O
or	O
Yang	B-Method
[	O
reference	O
]	O
)	O
or	O
anchored	B-Method
methods	I-Method
(	O
such	O
as	O
ANR	B-Method
[	O
reference	O
]	O
or	O
A	B-Method
+	O
[	O
reference	O
]	O
)	O
improves	O
as	O
the	O
learned	O
model	O
generalizes	O
better	O
,	O
as	O
shown	O
in	O
Fig	O
.	O
4	O
.	O
	
We	O
show	O
in	O
Fig	O
.	O
	
3	O
on	O
Set5	B-Material
,	O
	
×3	O
how	O
the	O
performance	O
of	O
A	B-Method
+	O
increases	O
when	O
using	O
16	O
up	O
to	O
65	O
,	O
536	O
regressors	O
for	O
any	O
fixed	O
size	O
pool	O
of	O
training	O
samples	O
.	O
	
In	O
A	B-Method
+	O
each	O
regressor	O
is	O
associated	O
with	O
an	O
anchoring	O
point	O
.	O
	
The	O
anchors	O
quantize	O
the	O
LR	O
feature	O
space	O
.	O
	
The	O
more	O
anchors	O
are	O
used	O
,	O
the	O
smaller	O
the	O
quantization	B-Metric
error	I-Metric
gets	O
and	O
the	O
easier	O
is	O
the	O
local	B-Method
regression	I-Method
.	O
	
On	O
Set5	B-Material
the	O
PSNR	B-Metric
is	O
32.17dB	O
for	O
16	O
regressors	O
,	O
while	O
it	O
reaches	O
32.92dB	O
for	O
65536	O
regressors	O
with	O
50	O
million	O
training	O
samples	O
(	O
our	O
A	B-Method
+	O
A	B-Method
setup	O
)	O
.	O
	
However	O
,	O
the	O
more	O
regressors	O
(	O
anchors	O
)	O
are	O
used	O
,	O
the	O
slower	O
the	O
method	O
gets	O
.	O
	
At	O
running	B-Metric
time	I-Metric
,	O
each	O
LR	O
patch	O
(	O
feature	O
)	O
is	O
linearly	O
matched	O
to	O
all	O
the	O
anchors	O
.	O
	
The	O
regressor	O
of	O
the	O
closest	O
anchor	O
is	O
applied	O
to	O
reconstruct	O
the	O
HR	O
patch	O
.	O
	
Obviously	O
,	O
this	O
linear	B-Method
search	I-Method
in	O
O	O
(	O
N	O
)	O
can	O
be	O
improved	O
.	O
	
Yet	O
,	O
the	O
LR	O
features	O
are	O
high	O
dimensional	O
(	O
30	O
after	O
PCA	B-Method
reduction	I-Method
for	O
×3	O
for	O
A	B-Method
+	O
)	O
and	O
the	O
speedup	O
achievable	O
with	O
data	B-Method
search	I-Method
structures	I-Method
such	O
as	O
kd	B-Method
-	I-Method
trees	I-Method
,	O
forests	B-Method
,	O
or	O
spherical	B-Method
hashing	I-Method
codes	I-Method
are	O
rather	O
small	O
(	O
3	O
-	O
4	O
times	O
in	O
[	O
reference	O
][	O
reference	O
]	O
)	O
.	O
	
Instead	O
,	O
we	O
propose	O
a	O
hierarchical	B-Method
search	I-Method
structure	I-Method
in	O
O	O
(	O
√	O
N	O
)	O
with	O
very	O
good	O
empirical	B-Metric
precision	I-Metric
,	O
that	O
does	O
not	O
change	O
the	O
training	O
procedure	O
of	O
A	B-Method
+	O
.	O
	
Given	O
N	O
anchors	O
and	O
their	O
N	O
regressors	O
,	O
we	O
cluster	O
them	O
into	O
√	O
N	O
groups	O
using	O
k	B-Method
-	I-Method
means	I-Method
,	O
each	O
with	O
an	O
l	O
2	O
-	O
normalized	O
centroid	O
.	O
	
To	O
each	O
centroid	O
we	O
assign	O
the	O
c	O
√	O
N	O
most	O
correlated	O
anchors	O
.	O
	
This	O
results	O
in	O
a	O
2	O
-	O
layers	O
structure	O
.	O
	
For	O
each	O
query	O
we	O
linearly	O
search	O
for	O
the	O
most	O
correlated	O
centroid	O
(	O
1	O
st	O
layer	O
)	O
to	O
then	O
linearly	O
search	O
within	O
the	O
anchors	O
assigned	O
to	O
it	O
(	O
2	O
nd	O
layer	O
)	O
.	O
	
c	O
=	O
4	O
is	O
fixed	O
in	O
all	O
our	O
experiments	O
,	O
so	O
that	O
one	O
anchor	O
potentially	O
can	O
be	O
assigned	O
to	O
more	O
centroids	O
to	O
handle	O
the	O
cluster	O
boundary	O
well	O
.	O
	
In	O
Fig	O
.	O
5	O
we	O
depict	O
the	O
performance	O
of	O
A	B-Method
+	O
A	B-Method
with	O
and	O
without	O
our	O
hierarchical	B-Method
search	I-Method
structure	I-Method
in	O
relation	O
to	O
the	O
number	O
of	O
trained	O
regressors	O
.	O
	
The	O
hierarchical	O
structure	O
looses	O
at	O
most	O
only	O
0.03dB	O
but	O
consistently	O
speeds	O
up	O
above	O
1	O
,	O
024	O
regressors	O
.	O
	
A	B-Method
+	I-Method
A	I-Method
with	O
hierarchical	B-Method
search	I-Method
(	O
H	B-Method
)	O
and	O
65	O
,	O
536	O
regressors	B-Method
has	O
a	O
running	B-Metric
time	I-Metric
comparable	O
to	O
the	O
original	O
A	B-Method
+	I-Method
with	O
linear	B-Method
search	I-Method
and	O
1	O
,	O
024	O
regressors	O
,	O
but	O
is	O
0.3dB	O
better	O
.	O
	
section	O
:	O
Back	O
projection	O
(	O
B	B-Method
)	O
	
Applying	O
an	O
iterative	B-Method
back	I-Method
projection	I-Method
(	I-Method
B	I-Method
)	I-Method
refinement	I-Method
[	O
reference	O
]	O
generally	O
improves	O
the	O
PSNR	B-Metric
as	O
it	O
makes	O
the	O
HR	B-Task
reconstruction	I-Task
consistent	O
with	O
the	O
LR	O
input	O
and	O
the	O
employed	O
degradation	O
operators	O
such	O
as	O
blur	O
,	O
downscaling	O
,	O
and	O
downsampling	O
.	O
	
Knowing	O
the	O
degradation	O
operators	O
is	O
a	O
must	O
for	O
the	O
IBP	B-Method
approaches	I-Method
	
and	O
therefore	O
they	O
need	O
to	O
be	O
estimated	O
	
[	O
reference	O
]	O
.	O
Assuming	O
the	O
degradation	O
operators	O
to	O
be	O
known	O
,	O
(	O
B	B-Method
)	O
improves	O
the	O
PSNR	B-Metric
of	O
A	B-Method
+	O
by	O
up	O
to	O
0.06dB	O
,	O
depending	O
on	O
the	O
settings	O
as	O
shown	O
in	O
column	O
A	B-Method
+	O
B	B-Method
in	O
Table	O
5	O
,	O
when	O
starting	O
from	O
the	O
A	B-Method
+	O
results	O
.	O
	
In	O
Table	O
1	O
we	O
compare	O
the	O
improvements	O
obtained	O
with	O
our	O
iterative	B-Method
back	I-Method
projection	I-Method
(	I-Method
B	I-Method
)	I-Method
refinement	I-Method
when	O
starting	O
from	O
different	O
SR	B-Task
methods	O
.	O
	
The	O
largest	O
improvement	O
is	O
of	O
0.59dB	O
when	O
starting	O
from	O
the	O
sparse	B-Method
coding	I-Method
method	I-Method
of	O
Yang	B-Method
et	O
al	O
.	O
	
[	O
reference	O
]	O
,	O
whereas	O
for	O
A	B-Method
+	O
it	O
only	O
improves	O
0.04dB.	O
	
This	O
behaviour	O
can	O
be	O
explained	O
by	O
the	O
fact	O
that	O
the	O
reference	O
A	B-Method
+	I-Method
is	O
1.18dB	O
better	O
than	O
the	O
reference	O
Yang	B-Method
method	O
.	O
	
Therefore	O
A	B-Method
+	I-Method
's	O
HR	B-Method
reconstruction	I-Method
is	O
much	O
more	O
consistent	O
with	O
the	O
LR	O
image	O
than	O
Yang	B-Method
's	O
and	O
improving	O
by	O
using	O
(	O
B	B-Method
)	O
is	O
more	O
difficult	O
.	O
	
The	O
refined	O
Yang	B-Method
result	O
is	O
0.59dB	O
better	O
than	O
the	O
baseline	B-Method
Yang	I-Method
method	I-Method
but	O
still	O
0.59dB	O
behind	O
A	B-Method
+	O
without	O
refinement	O
.	O
	
Note	O
that	O
generally	O
the	O
degradation	O
operators	O
are	O
unknown	O
and	O
their	O
estimation	O
is	O
not	O
precise	O
,	O
therefore	O
our	O
reported	O
results	O
with	O
(	O
B	B-Method
)	O
refinement	O
are	O
an	O
upper	O
bound	O
for	O
a	O
practical	O
implementation	O
and	O
difficult	O
to	O
reach	O
.	O
	
section	O
:	O
Cascade	B-Method
of	I-Method
anchored	I-Method
regressors	I-Method
(	O
C	O
)	O
	
As	O
the	O
magnification	O
factor	O
is	O
decreased	O
,	O
the	O
superresolution	B-Task
becomes	O
more	O
accurate	O
,	O
since	O
the	O
space	O
of	O
possible	O
HR	O
solutions	O
for	O
each	O
LR	O
patch	O
and	O
thus	O
the	O
ambiguity	O
decreases	O
.	O
	
Glasner	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
use	O
small	O
SR	B-Task
steps	O
to	O
gradually	O
refine	O
the	O
contents	O
up	O
to	O
the	O
desired	O
HR	O
.	O
	
The	O
errors	O
are	O
usually	O
enlarged	O
by	O
the	O
subsequent	O
steps	O
and	O
the	O
time	B-Metric
complexity	I-Metric
depends	O
on	O
the	O
number	O
of	O
steps	O
.	O
	
Instead	O
of	O
superresolving	O
the	O
LR	O
image	O
in	O
small	O
steps	O
,	O
we	O
can	O
go	O
in	O
one	O
step	O
(	O
stage	O
)	O
and	O
then	O
refine	O
the	O
prediction	O
using	O
the	O
same	O
SR	B-Task
method	O
again	O
adapted	O
to	O
this	O
input	O
.	O
	
We	O
consider	O
the	O
output	O
of	O
the	O
previous	O
stage	O
as	O
LR	O
image	O
input	O
and	O
as	O
target	O
the	O
HR	O
image	O
for	O
each	O
stage	O
.	O
	
Thus	O
,	O
we	O
build	O
a	O
cascade	B-Method
of	I-Method
trained	I-Method
models	I-Method
,	O
where	O
each	O
stage	O
brings	O
the	O
prediction	O
closer	O
to	O
the	O
target	O
HR	O
image	O
.	O
	
The	O
cascades	B-Method
and	O
the	O
layered	B-Method
or	I-Method
recurrent	I-Method
processing	I-Method
are	O
broadly	O
used	O
concepts	O
in	O
vision	B-Task
tasks	I-Task
(	O
i.e.	O
object	B-Task
detection	I-Task
[	O
reference	O
]	O
and	O
deep	B-Task
learning	I-Task
[	O
reference	O
]	O
)	O
.	O
	
The	O
method	O
of	O
Peleg	O
and	O
Elad	O
[	O
reference	O
]	O
and	O
the	O
SRCNN	B-Method
method	I-Method
of	O
Dong	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
are	O
layered	O
by	O
design	O
.	O
	
While	O
the	O
incremental	B-Method
approach	I-Method
has	O
a	O
loose	O
control	O
over	O
the	O
errors	O
,	O
the	O
cascade	B-Method
explicitly	O
minimizes	O
the	O
prediction	O
errors	O
at	O
each	O
stage	O
.	O
	
In	O
our	O
cascaded	O
A	B-Method
+	O
,	O
called	O
A	B-Method
+	O
C	O
,	O
with	O
50	O
million	O
training	O
samples	O
,	O
we	O
keep	O
the	O
same	O
features	O
and	O
settings	O
for	O
all	O
the	O
stages	O
but	O
have	O
models	O
that	O
have	O
been	O
trained	O
per	O
stage	O
.	O
	
As	O
shown	O
in	O
Fig	O
.	O
6	O
and	O
Table	O
2	O
	
section	O
:	O
Enhanced	B-Task
prediction	I-Task
(	O
E	B-Method
)	O
	
In	O
image	B-Task
classification	I-Task
[	O
reference	O
]	O
often	O
the	O
prediction	B-Task
for	O
an	O
input	O
image	O
is	O
enhanced	O
by	O
averaging	O
the	O
predictions	O
on	O
a	O
set	O
of	O
transformed	O
images	O
derived	O
from	O
it	O
.	O
	
The	O
most	O
common	O
transformations	O
include	O
cropping	O
,	O
flipping	O
,	O
and	O
rotations	O
.	O
	
In	O
SR	B-Task
image	O
rotations	O
and	O
flips	O
should	O
lead	O
to	O
the	O
same	O
HR	O
results	O
at	O
pixel	O
level	O
.	O
	
Therefore	O
,	O
we	O
apply	O
rotations	O
and	O
flips	O
on	O
the	O
LR	O
image	O
as	O
shown	O
in	O
see	O
Fig	O
.	O
2	O
to	O
get	O
a	O
set	O
of	O
8	O
LR	O
images	O
,	O
then	O
apply	O
the	O
SR	B-Task
method	O
on	O
each	O
,	O
reverse	O
the	O
transformation	O
on	O
the	O
HR	O
outputs	O
and	O
average	O
for	O
the	O
final	O
HR	O
result	O
.	O
	
PSNR	B-Metric
	
(	O
dB	O
)	O
gain	O
combined	O
internal	B-Method
dictionary	I-Method
external	I-Method
dictionary	I-Method
(	O
reference	O
)	O
Figure	O
7	O
.	O
	
Average	O
PSNR	B-Metric
gain	O
comparison	O
of	O
internal	B-Method
dictionary	I-Method
,	O
external	B-Method
dictionary	I-Method
and	O
combined	B-Method
dictionary	I-Method
with	O
respect	O
to	O
the	O
input	O
LR	O
image	O
size	O
(	O
L20	O
,	O
×3	O
)	O
.	O
	
On	O
Set5	B-Material
(	O
see	O
Fig	O
.	O
6	O
and	O
Table	O
2	O
)	O
the	O
enhanced	B-Method
prediction	I-Method
(	O
E	B-Method
)	O
gives	O
a	O
0.05dB	O
improvement	O
for	O
a	O
single	O
stage	O
and	O
more	O
than	O
0.24dB	O
when	O
4	O
stages	O
are	O
employed	O
in	O
the	O
cascade	B-Method
.	O
	
The	O
running	B-Metric
time	I-Metric
is	O
linear	O
in	O
the	O
number	O
of	O
transformations	O
.	O
	
In	O
Table	O
3	O
we	O
report	O
the	O
improvements	O
due	O
to	O
(	O
E	B-Method
)	O
for	O
different	O
SR	B-Task
methods	O
.	O
	
It	O
varies	O
from	O
+	O
0.05dB	O
for	O
ANR	B-Method
up	O
to	O
+	O
0.25dB	O
for	O
the	O
Yang	B-Method
method	O
.	O
	
section	O
:	O
Self	O
-	O
similarities	O
(	O
S	O
)	O
	
The	O
image	B-Method
self	I-Method
-	I-Method
similarities	I-Method
(	O
or	O
patch	O
redundancy	O
)	O
at	O
different	O
image	O
scales	O
can	O
help	O
to	O
discriminate	O
between	O
equally	O
possible	O
HR	O
reconstructions	O
.	O
	
While	O
we	O
considered	O
external	B-Method
dictionaries	I-Method
,	O
thus	O
priors	O
from	O
LR	O
and	O
HR	O
training	O
images	O
,	O
some	O
advocate	O
internal	B-Method
dictionaries	I-Method
,	O
i.e.	O
dictionaries	O
built	O
from	O
the	O
input	O
LR	O
image	O
,	O
matching	O
the	O
image	O
context	O
.	O
	
Exponents	O
are	O
Glasner	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
or	O
Dong	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
,	O
among	O
others	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
Extracting	O
and	O
building	B-Method
models	I-Method
adapted	O
to	O
each	O
new	O
input	O
image	O
is	O
expensive	O
.	O
	
Also	O
,	O
in	O
recent	O
works	O
,	O
and	O
on	O
the	O
standard	O
benchmarks	O
,	O
methods	O
such	O
as	O
SRCNN	B-Method
[	O
reference	O
]	O
and	O
A	B-Method
+	O
[	O
reference	O
]	O
based	O
on	O
external	B-Method
dictionaries	I-Method
proved	O
better	O
in	O
terms	O
of	O
PSNR	B-Metric
and	O
running	B-Metric
time	I-Metric
.	O
	
We	O
point	O
out	O
that	O
depending	O
on	O
the	O
size	O
of	O
the	O
input	O
LR	O
image	O
and	O
the	O
textural	O
complexity	O
,	O
the	O
internal	B-Method
dictionaries	I-Method
can	O
be	O
better	O
than	O
the	O
external	B-Method
dictionaries	I-Method
.	O
	
Huang	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
report	O
better	O
results	O
with	O
internal	B-Method
dictionaries	I-Method
when	O
using	O
urban	O
HR	O
images	O
with	O
high	O
geometric	O
regularities	O
.	O
	
We	O
downsize	O
the	O
L20	O
images	O
and	O
plot	O
the	O
improvements	O
over	O
an	O
external	B-Method
dictionary	I-Method
in	O
Fig	O
.	O
7	O
.	O
	
Above	O
246	O
,	O
000	O
LR	O
pixels	O
the	O
internal	B-Method
dictionary	I-Method
improves	O
over	O
the	O
external	O
one	O
.	O
	
However	O
,	O
the	O
best	O
results	O
are	O
obtained	O
using	O
both	O
external	O
and	O
internal	B-Method
dictionaries	I-Method
.	O
	
section	O
:	O
Reasoning	O
with	O
context	O
(	O
R	B-Method
)	O
	
Intuition	O
says	O
that	O
using	O
the	O
immediate	O
surrounding	O
of	O
a	O
LR	O
patch	O
should	O
help	O
.	O
	
For	O
example	O
,	O
Dong	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
train	O
domain	B-Method
specific	I-Method
models	I-Method
and	O
Sun	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
hallucinate	O
using	O
context	O
constraints	O
.	O
	
We	O
consider	O
context	O
images	O
centered	O
on	O
each	O
LR	O
patch	O
of	O
size	O
equal	O
with	O
the	O
LR	O
patch	O
size	O
times	O
the	O
scaling	O
factor	O
(	O
×3	O
)	O
.	O
	
We	O
extract	O
the	O
same	O
features	O
as	O
for	O
the	O
LR	O
patches	O
but	O
in	O
the	O
(	O
×3	O
)	O
downscaled	O
image	O
and	O
cluster	O
them	O
into	O
4	O
groups	O
with	O
4	O
centroids	O
.	O
	
A	B-Method
small	O
number	O
that	O
does	O
not	O
increase	O
the	O
time	B-Metric
complexity	I-Metric
much	O
but	O
it	O
is	O
still	O
relevant	O
for	O
analyzing	O
the	O
context	O
idea	O
.	O
	
We	O
keep	O
the	O
standard	O
A	B-Method
+	O
pipeline	O
with	O
1024	O
anchors	O
and	O
0.5	O
million	O
training	O
patches	O
(	O
A	B-Method
+(	O
0.5	O
m	O
)	O
)	O
.	O
	
To	O
each	O
anchor	O
we	O
assign	O
the	O
closest	O
patches	O
and	O
instead	O
of	O
training	O
one	O
regressor	O
as	O
A	B-Method
+	O
would	O
,	O
we	O
train	O
4	O
context	B-Method
specific	I-Method
regressors	I-Method
.	O
	
For	O
each	O
context	O
we	O
compute	O
a	O
regressor	B-Method
using	O
the	O
1024	O
patches	O
closest	O
to	O
both	O
anchor	O
and	O
context	O
centroid	O
,	O
in	O
a	O
10	O
to	O
1	O
contribution	O
.	O
	
For	O
patches	O
of	O
comparable	O
distances	O
to	O
the	O
anchor	O
the	O
distance	O
to	O
the	O
context	O
centroid	O
makes	O
the	O
difference	O
.	O
	
At	O
testing	O
time	O
,	O
each	O
LR	O
patch	O
is	O
first	O
matched	O
against	O
the	O
anchors	O
and	O
then	O
the	O
regressor	O
of	O
the	O
closest	O
context	O
is	O
used	O
to	O
get	O
the	O
HR	O
output	O
.	O
	
By	O
reasoning	O
with	O
context	O
we	O
improve	O
from	O
32.39dB	O
to	O
32.55dB	O
on	O
Set5	B-Material
,	O
while	O
the	O
running	B-Metric
time	I-Metric
only	O
slightly	O
increases	O
.	O
	
In	O
Table	O
4	O
we	O
report	O
the	O
improvements	O
achieved	O
using	O
reasoning	O
with	O
context	O
(	O
R	B-Method
)	O
over	O
original	O
SR	B-Task
methods	O
.	O
	
The	O
(	O
R	B-Method
)	O
derivations	O
were	O
similar	O
to	O
the	O
one	O
explained	O
for	O
the	O
A	B-Method
+	O
(	O
0.5	O
m	O
)	O
setup	O
.	O
	
section	O
:	O
Improved	B-Method
A	I-Method
+	I-Method
(	O
IA	B-Method
)	O
	
Any	O
combination	O
of	O
the	O
proposed	O
techniques	O
would	O
likely	O
improve	O
over	O
the	O
baseline	B-Method
example	I-Method
-	I-Method
based	I-Method
superresolution	I-Method
method	I-Method
.	O
	
If	O
we	O
start	O
from	O
the	O
A	B-Method
+	O
method	O
,	O
and	O
(	O
A	B-Method
)	O
add	O
augmentation	B-Method
(	O
50	O
million	O
training	O
samples	O
)	O
,	O
increase	O
the	O
number	O
of	O
regressors	O
(	O
to	O
65536	O
)	O
and	O
(	O
H	B-Method
)	O
use	O
the	O
hierarchical	B-Method
search	I-Method
structure	O
,	O
we	O
achieve	O
0.33dB	O
improvement	O
over	O
A	B-Method
+	O
(	O
Set5	B-Material
,	O
×3	O
)	O
without	O
an	O
increase	O
in	O
running	B-Metric
time	I-Metric
.	O
	
Adding	O
reasoning	O
with	O
context	O
(	O
R	B-Method
)	O
slightly	O
increases	O
the	O
running	B-Metric
time	I-Metric
for	O
a	O
gain	O
of	O
0.1dB.	O
	
The	O
cascade	B-Method
(	O
C	O
)	O
allows	O
for	O
another	O
jump	O
in	O
performance	O
,	O
+	O
0.27dB	O
,	O
while	O
the	O
enhanced	O
prediction	B-Method
(	O
E	B-Method
)	O
brings	O
another	O
0.25dB.	O
	
The	O
gain	O
brought	O
by	O
(	O
C	O
)	O
and	O
(	O
E	B-Method
)	O
comes	O
at	O
the	O
price	O
of	O
increasing	O
the	O
computation	B-Metric
time	I-Metric
.	O
	
The	O
full	O
setup	O
,	O
using	O
(	O
A	B-Method
,	O
H	B-Method
,	O
R	B-Method
,	O
C	O
,	O
E	B-Method
)	O
is	O
marked	O
as	O
our	O
proposed	O
Improved	B-Method
A	I-Method
+	I-Method
(	O
IA	B-Method
)	O
method	O
.	O
	
The	O
addition	O
of	O
internal	B-Method
dictionaries	I-Method
(	O
S	O
)	O
is	O
possible	O
but	O
undesirable	O
due	O
to	O
the	O
computational	B-Metric
cost	I-Metric
.	O
	
Adding	O
IBP	B-Method
(	O
B	B-Method
)	O
to	O
the	O
IA	B-Method
method	I-Method
can	O
further	O
improve	O
the	O
performance	O
by	O
0.05dB.	O
	
The	O
seven	O
ways	O
to	O
improve	O
A	B-Method
+	O
are	O
summarized	O
in	O
Fig	O
.	O
8	O
.	O
	
The	O
Improved	B-Method
A	I-Method
+	I-Method
(	O
IA	B-Method
)	O
method	O
is	O
0.9dB	O
better	O
than	O
the	O
baseline	B-Method
A	I-Method
+	I-Method
method	I-Method
by	O
using	O
5	O
techniques	O
(	O
A	B-Method
,	O
H	B-Method
,	O
R	B-Method
,	O
C	O
,	O
E	B-Method
)	O
.	O
	
section	O
:	O
Discussion	O
	
section	O
:	O
Generality	O
of	O
the	O
seven	O
ways	O
	
Our	O
study	O
focused	O
and	O
demonstrated	O
the	O
seven	O
ways	O
to	O
improve	O
SR	B-Task
mainly	O
on	O
the	O
A	B-Method
+	O
method	O
.	O
	
As	O
a	O
result	O
,	O
the	O
IA	B-Method
method	I-Method
has	O
been	O
proposed	O
,	O
combining	O
5	O
out	O
of	O
7	O
ways	O
,	O
namely	O
(	O
A	B-Method
,	O
H	B-Method
,	O
R	B-Method
,	O
C	O
,	O
E	B-Method
)	O
.	O
	
The	O
effect	O
of	O
applying	O
the	O
different	O
techniques	O
is	O
additive	O
,	O
each	O
contributing	O
to	O
the	O
final	O
performance	O
.	O
	
These	O
techniques	O
are	O
general	O
in	O
the	O
sense	O
that	O
they	O
can	O
be	O
applied	O
to	O
other	O
example	B-Method
-	I-Method
based	I-Method
single	I-Method
image	I-Method
super	I-Method
-	I-Method
resolution	I-Method
methods	I-Method
as	O
well	O
.	O
	
We	O
demonstrated	O
the	O
techniques	O
on	O
five	O
methods	O
.	O
	
In	O
Fig	O
.	O
	
1	O
	
we	O
report	O
on	O
a	O
running	B-Metric
time	I-Metric
versus	O
PSNR	B-Metric
performance	O
scale	O
the	O
results	O
(	O
Set5	B-Material
,	O
×3	O
)	O
of	O
the	O
reference	O
methods	O
A	B-Method
+	I-Method
,	O
ANR	B-Method
,	O
Zeyde	B-Method
,	O
and	O
Yang	B-Method
together	O
with	O
the	O
improved	O
results	O
starting	O
from	O
these	O
methods	O
.	O
	
The	O
A	B-Method
+	O
A	B-Method
method	O
combines	O
A	B-Method
+	O
with	O
A	B-Method
and	O
H	B-Method
,	O
while	O
the	O
A	B-Method
+	O
C	O
method	O
combines	O
A	B-Method
+	O
with	O
A	B-Method
,	O
H	B-Method
,	O
and	O
C.	O
A	B-Method
+	I-Method
A	I-Method
and	O
A	B-Method
+	I-Method
C	I-Method
are	O
lighter	O
versions	O
of	O
our	O
IA	B-Method
.	O
	
For	O
the	O
improved	O
ANR	B-Method
result	O
we	O
combined	O
the	O
A	B-Method
,	O
H	B-Method
,	O
R	B-Method
,	O
B	B-Method
,	O
and	O
E	B-Method
techniques	O
,	O
for	O
the	O
improved	O
Zeyde	B-Method
result	O
	
we	O
combined	O
A	B-Method
,	O
R	B-Method
,	O
B	B-Method
,	O
and	O
E	B-Method
,	O
while	O
for	O
Yang	B-Method
we	O
combined	O
B	B-Method
and	O
E	B-Method
without	O
retraining	O
the	O
original	O
model	O
.	O
	
Note	O
that	O
using	O
combinations	O
of	O
the	O
seven	O
techniques	O
we	O
are	O
able	O
to	O
improve	O
significantly	O
all	O
the	O
methods	O
considered	O
in	O
our	O
study	O
which	O
validates	O
the	O
wide	O
applicability	O
of	O
these	O
techniques	O
.	O
	
Thus	O
,	O
A	B-Method
+	I-Method
is	O
improved	O
by	O
0.9dB	O
in	O
PSNR	B-Metric
,	O
Yang	B-Method
and	O
ANR	B-Method
by	O
0.8dB	O
and	O
Zeyde	B-Method
by	O
0.7dB.	O
	
section	O
:	O
Benchmark	O
results	O
	
All	O
the	O
experiments	O
until	O
now	O
used	O
Set5	B-Material
and	O
L20	O
and	O
magnification	O
factor	O
×3	O
.	O
	
In	O
Table	O
5	O
we	O
report	O
the	O
average	B-Metric
PSNR	I-Metric
performance	O
on	O
Set5	B-Material
,	O
Set14	B-Material
,	O
and	O
B100	B-Material
,	O
and	O
for	O
magnification	O
factors	O
×2	O
,	O
×3	O
,	O
and	O
×4	O
of	O
our	O
methods	O
in	O
comparison	O
with	O
the	O
baseline	O
A	B-Method
+	I-Method
[	O
reference	O
]	O
,	O
ANR	B-Method
[	O
reference	O
]	O
,	O
Zeyde	B-Method
[	O
reference	O
]	O
,	O
and	O
SRCNN	B-Method
[	O
reference	O
]	O
methods	O
.	O
	
Also	O
we	O
report	O
the	O
result	O
of	O
the	O
bicubic	B-Method
interpolation	I-Method
and	O
the	O
one	O
for	O
the	O
Neighbor	B-Method
Embedding	I-Method
with	O
Locally	B-Method
Linear	I-Method
Embedding	I-Method
	
(	O
NE	O
+	O
LLE	O
)	O
method	O
of	O
Chang	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
as	O
adapted	O
and	O
implemented	O
in	O
[	O
reference	O
]	O
.	O
	
All	O
the	O
methods	O
used	O
the	O
same	O
Train91	O
dataset	O
for	O
training	O
.	O
	
For	O
reporting	O
improved	O
results	O
also	O
for	O
magnification	O
factors	O
×2	O
and	O
×4	O
,	O
we	O
keep	O
the	O
same	O
parameters	O
/	O
settings	O
as	O
used	O
for	O
the	O
case	O
of	O
magnification	O
×3	O
for	O
our	O
A	B-Method
+	I-Method
B	I-Method
,	O
A	B-Method
+	I-Method
A	I-Method
,	O
A	B-Method
+	I-Method
C	I-Method
,	O
and	O
	
IA	B-Method
methods	O
.	O
	
A	B-Method
+	I-Method
B	I-Method
is	O
provided	O
for	O
reference	O
as	O
the	O
degradation	O
operators	O
usually	O
are	O
not	O
known	O
and	O
difficult	O
to	O
estimate	O
in	O
practice	O
.	O
	
A	B-Method
+	I-Method
B	I-Method
just	O
slightly	O
improves	O
over	O
A	B-Method
+	I-Method
.	O
	
A	B-Method
+	I-Method
A	I-Method
improves	O
0.13dB	O
up	O
to	O
0.34dB	O
over	O
A	B-Method
+	O
while	O
preserving	O
the	O
running	B-Metric
time	I-Metric
.	O
	
A	B-Method
+	I-Method
C	I-Method
	
further	O
improves	O
at	O
the	O
price	O
of	O
running	B-Metric
time	I-Metric
,	O
using	O
a	O
cascade	B-Method
with	O
3	O
stages	O
.	O
	
IA	B-Method
improves	O
0.4dB	O
up	O
to	O
0.9dB	O
over	O
the	O
A	B-Method
+	O
results	O
,	O
and	O
significantly	O
more	O
over	O
SRCNN	B-Method
,	O
Zeyde	B-Method
,	O
and	O
ANR	B-Method
.	O
	
section	O
:	O
Qualitative	B-Task
assessment	I-Task
	
For	O
qualitatively	O
assessing	O
the	O
IA	B-Method
performance	O
we	O
depict	O
in	O
Fig	O
.	O
	
11	O
several	O
cropped	O
images	O
for	O
magnification	O
factors	O
×3	O
and	O
×4	O
.	O
	
Generally	O
IA	B-Method
restores	O
more	O
sharp	O
details	O
with	O
fewer	O
artifacts	O
than	O
the	O
A	B-Method
+	I-Method
and	O
Zeyde	B-Method
methods	O
do	O
.	O
	
For	O
example	O
,	O
the	O
clarity	B-Metric
and	O
sharpness	B-Metric
of	O
the	O
HR	B-Method
reconstruction	I-Method
for	O
the	O
text	O
image	O
visibly	O
improves	O
from	O
the	O
Zeyde	B-Method
to	O
A	B-Method
+	I-Method
and	O
then	O
to	O
our	B-Method
IA	I-Method
result	O
.	O
	
The	O
same	O
for	O
other	O
face	O
features	O
such	O
as	O
chin	O
,	O
mouth	O
or	O
eyes	O
in	O
the	O
image	O
from	O
the	O
second	O
row	O
of	O
Fig	O
.	O
9	O
.	O
	
In	O
Fig	O
.	O
	
11	O
we	O
show	O
image	O
results	O
for	O
magnification	O
×4	O
on	O
Set14	B-Material
for	O
our	O
IA	B-Method
method	I-Method
in	O
comparison	O
with	O
the	O
bicubic	B-Method
,	O
Zeyde	B-Method
,	O
ANR	B-Method
,	O
and	O
A	B-Method
+	O
methods	O
.	O
	
The	O
supplementary	O
material	O
contains	O
more	O
per	O
image	O
PSNR	B-Metric
results	O
and	O
HR	O
outputs	O
for	O
qualitative	O
assessment	O
.	O
	
section	O
:	O
Conclusion	O
	
We	O
proposed	O
seven	O
ways	O
to	O
effectively	O
improve	O
the	O
performance	O
of	O
example	B-Task
-	I-Task
based	I-Task
super	I-Task
-	I-Task
resolution	I-Task
.	O
	
Combined	O
,	O
we	O
obtain	O
a	O
new	O
highly	O
efficient	O
method	O
,	O
called	O
Improved	O
	
section	O
:	O
Input	O
	
Zeyde	B-Method
[	O
reference	O
]	O
A	B-Method
+	I-Method
[	O
reference	O
]	O
	
IA	B-Method
	
(	O
ours	O
)	O
Figure	O
9	O
.	O
	
SR	B-Task
visual	O
comparison	O
.	O
	
Best	O
zoomed	O
in	O
on	O
screen	O
.	O
	
A	B-Method
+	I-Method
(	O
IA	B-Method
)	O
,	O
based	O
on	O
the	O
anchored	B-Method
regressors	I-Method
idea	I-Method
of	O
A	B-Method
+	I-Method
.	O
	
Noninvasive	B-Method
techniques	I-Method
such	O
as	O
augmentation	O
of	O
the	O
training	O
data	O
,	O
enhanced	O
prediction	B-Task
by	O
consistency	O
checks	O
,	O
context	B-Method
reasoning	I-Method
,	O
or	O
iterative	B-Method
back	I-Method
projection	I-Method
lead	O
to	O
a	O
significant	O
boost	O
in	O
PSNR	B-Metric
performance	O
without	O
significant	O
increases	O
in	O
running	B-Metric
time	I-Metric
.	O
	
Our	O
hierarchical	O
organization	O
of	O
the	O
anchors	O
in	O
the	O
IA	B-Method
method	I-Method
allows	O
us	O
to	O
handle	O
orders	O
of	O
magnitude	O
more	O
regressors	O
than	O
the	O
original	O
A	B-Method
+	I-Method
at	O
the	O
same	O
running	B-Metric
time	I-Metric
.	O
	
Another	O
technique	O
,	O
often	O
overlooked	O
,	O
is	O
the	O
cascaded	B-Method
application	I-Method
of	O
the	O
core	B-Method
super	I-Method
-	I-Method
resolution	I-Method
method	I-Method
towards	O
HR	B-Task
restoration	I-Task
.	O
	
Using	O
the	O
image	B-Method
self	I-Method
-	I-Method
similarities	I-Method
or	O
the	O
context	O
is	O
shown	O
also	O
to	O
improve	O
PSNR	B-Metric
.	O
	
On	O
standard	O
benchmarks	O
IA	B-Method
improves	O
0.4dB	O
up	O
to	O
0.9dB	O
over	O
state	O
-	O
ofthe	O
-	O
art	O
methods	O
such	O
as	O
A	B-Method
+	I-Method
[	O
reference	O
]	O
and	O
SRCNN	B-Method
[	O
reference	O
]	O
.	O
	
While	O
we	O
demonstrated	O
the	O
large	O
improvements	O
mainly	O
on	O
the	O
A	B-Method
+	O
framework	O
,	O
and	O
several	O
other	O
methods	O
(	O
ANR	B-Method
,	O
Yang	B-Method
,	O
Zeyde	B-Method
,	O
SRCNN	B-Method
)	O
,	O
we	O
strongly	O
believe	O
that	O
the	O
proposed	O
techniques	O
provide	O
similar	O
benefits	O
for	O
other	O
example	B-Method
-	I-Method
based	I-Method
superresolution	I-Method
methods	I-Method
.	O
	
The	O
proposed	O
techniques	O
are	O
generic	O
and	O
require	O
no	O
changes	O
to	O
the	O
core	O
baseline	O
method	O
.	O
	
Figure	O
10	O
.	O
	
L20	O
dataset	O
.	O
	
20	O
high	O
resolution	O
large	O
images	O
.	O
	
section	O
:	O
Bicubic	O
	
Zeyde	B-Method
[	O
reference	O
]	O
ANR	B-Method
[	O
reference	O
]	O
A	B-Method
+	O
[	O
reference	O
]	O
IA	B-Method
	
(	O
ours	O
)	O
Figure	O
11	O
.	O
	
SR	B-Task
visual	O
results	O
for	O
×4	O
.	O
	
Images	O
from	O
Set14	B-Material
.	O
	
Best	O
zoomed	O
in	O
on	O
screen	O
.	O
	
section	O
:	O
	
document	O
:	O
Multiple	B-Method
Instance	I-Method
Detection	I-Method
Network	I-Method
with	O
Online	B-Method
Instance	I-Method
Classifier	I-Method
Refinement	I-Method
	
Of	O
late	O
,	O
weakly	B-Task
supervised	I-Task
object	I-Task
detection	I-Task
is	O
with	O
great	O
importance	O
in	O
object	B-Task
recognition	I-Task
.	O
	
Based	O
on	O
deep	B-Method
learning	I-Method
,	O
weakly	B-Method
supervised	I-Method
detectors	I-Method
have	O
achieved	O
many	O
promising	O
results	O
.	O
	
However	O
,	O
compared	O
with	O
fully	B-Task
supervised	I-Task
detection	I-Task
,	O
it	O
is	O
more	O
challenging	O
to	O
train	O
deep	B-Method
network	I-Method
based	I-Method
detectors	I-Method
in	O
a	O
weakly	B-Method
supervised	I-Method
manner	I-Method
.	O
	
Here	O
we	O
formulate	O
weakly	B-Task
supervised	I-Task
detection	I-Task
as	O
a	O
Multiple	B-Task
Instance	I-Task
Learning	I-Task
(	I-Task
MIL	I-Task
)	I-Task
problem	I-Task
,	O
where	O
instance	B-Method
classifiers	I-Method
(	O
object	B-Method
detectors	I-Method
)	O
are	O
put	O
into	O
the	O
network	O
as	O
hidden	O
nodes	O
.	O
	
We	O
propose	O
a	O
novel	O
online	B-Method
instance	I-Method
classifier	I-Method
refinement	I-Method
algorithm	I-Method
to	O
integrate	O
MIL	B-Method
and	O
the	O
instance	B-Method
classifier	I-Method
refinement	I-Method
procedure	I-Method
into	O
a	O
single	O
deep	B-Method
network	I-Method
,	O
and	O
train	O
the	O
network	O
end	O
-	O
to	O
-	O
end	O
with	O
only	O
image	O
-	O
level	O
supervision	O
,	O
,	O
without	O
object	O
location	O
information	O
.	O
	
More	O
precisely	O
,	O
instance	O
labels	O
inferred	O
from	O
weak	O
supervision	O
are	O
propagated	O
to	O
their	O
spatially	O
overlapped	O
instances	O
to	O
refine	O
instance	B-Method
classifier	I-Method
online	O
.	O
	
The	O
iterative	B-Method
instance	I-Method
classifier	I-Method
refinement	I-Method
procedure	I-Method
is	O
implemented	O
using	O
multiple	O
streams	O
in	O
deep	B-Method
network	I-Method
,	O
where	O
each	O
stream	O
supervises	O
its	O
latter	O
stream	O
.	O
	
Weakly	B-Task
supervised	I-Task
object	I-Task
detection	I-Task
experiments	O
are	O
carried	O
out	O
on	O
the	O
challenging	O
PASCAL	B-Material
VOC	I-Material
2007	I-Material
and	O
2012	B-Material
benchmarks	O
.	O
	
We	O
obtain	O
mAP	B-Metric
on	O
VOC	B-Material
2007	I-Material
that	O
significantly	O
outperforms	O
the	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
.	O
	
section	O
:	O
Introduction	O
	
With	O
the	O
development	O
of	O
Convolutional	O
Neural	O
Network	O
(	O
CNN	B-Method
)	O
,	O
great	O
improvements	O
have	O
been	O
achieved	O
on	O
object	B-Task
detection	I-Task
,	O
due	O
to	O
the	O
availability	O
of	O
large	O
scale	O
datasets	O
with	O
accurate	O
boundingbox	O
-	O
level	O
annotations	O
.	O
	
However	O
,	O
collecting	O
such	O
accurate	O
annotations	O
can	O
be	O
very	O
labor	O
-	O
intensive	O
and	O
time	O
-	O
consuming	O
,	O
whereas	O
achieving	O
only	O
image	O
-	O
level	O
annotations	O
(	O
,	O
image	O
tags	O
)	O
is	O
much	O
easier	O
,	O
as	O
these	O
annotations	O
are	O
often	O
available	O
at	O
the	O
Internet	O
(	O
,	O
image	O
search	O
queries	O
)	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
aim	O
at	O
the	O
Weakly	B-Task
Supervised	I-Task
Object	I-Task
Detection	I-Task
(	O
WSOD	B-Task
)	O
problem	O
,	O
,	O
only	O
image	O
tags	O
are	O
available	O
during	O
training	O
to	O
indicate	O
whether	O
an	O
object	O
exists	O
in	O
an	O
image	O
.	O
	
Most	O
of	O
previous	O
methods	O
follow	O
the	O
Multiple	B-Method
Instance	I-Method
Learning	I-Method
(	I-Method
MIL	I-Method
)	I-Method
pipeline	I-Method
for	O
WSOD	B-Task
.	O
	
They	O
treat	O
images	O
as	O
bags	O
and	O
image	O
regions	O
generated	O
by	O
object	B-Method
proposal	I-Method
methods	I-Method
as	O
instances	O
to	O
train	O
instance	B-Method
classifiers	I-Method
(	O
object	B-Method
detectors	I-Method
)	O
under	O
the	O
MIL	O
constraints	O
.	O
	
Meanwhile	O
,	O
recent	O
efforts	O
tend	O
to	O
combine	O
MIL	B-Method
and	O
CNN	B-Method
by	O
either	O
using	O
CNN	B-Method
as	O
an	O
off	B-Method
-	I-Method
the	I-Method
-	I-Method
shelf	I-Method
feature	I-Method
extractor	I-Method
or	O
training	O
an	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
MIL	I-Method
network	I-Method
.	O
	
Here	O
we	O
are	O
also	O
along	O
the	O
MIL	O
line	O
for	O
WSOD	B-Task
,	O
and	O
train	O
an	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
network	I-Method
.	O
	
Though	O
many	O
promising	O
results	O
have	O
been	O
achieved	O
in	O
WSOD	B-Task
,	O
they	O
are	O
still	O
far	O
from	O
comparable	O
to	O
fully	O
supervised	O
ones	O
.	O
	
Weakly	B-Task
supervised	I-Task
object	I-Task
detection	I-Task
only	O
requires	O
supervision	O
at	O
image	O
category	O
level	O
.	O
	
Bilen	O
and	O
Vedaldi	O
presents	O
an	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
deep	I-Method
network	I-Method
for	O
WSOD	B-Task
,	O
in	O
which	O
final	O
image	B-Metric
classification	I-Metric
score	I-Metric
is	O
the	O
weighted	O
sum	O
of	O
proposal	O
scores	O
,	O
that	O
is	O
,	O
each	O
proposal	O
contributes	O
a	O
percentage	O
to	O
the	O
final	O
image	B-Task
classification	I-Task
.	O
	
The	O
deep	B-Method
network	I-Method
can	O
correctly	O
classify	O
image	O
even	O
only	O
“	O
see	O
”	O
a	O
part	O
of	O
object	O
,	O
and	O
as	O
a	O
result	O
,	O
the	O
top	O
ranking	O
proposal	O
may	O
fail	O
to	O
meet	O
the	O
standard	O
object	B-Metric
detection	I-Metric
requirement	I-Metric
(	O
IoU	O
0.5	O
between	O
ground	O
truths	O
and	O
predicted	O
boxes	O
)	O
.	O
	
As	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
left	O
)	O
,	O
the	O
top	O
-	O
ranking	O
proposal	O
A	O
is	O
too	O
small	O
.	O
	
Meanwhile	O
,	O
proposals	O
B	O
,	O
C	O
,	O
and	O
D	O
have	O
similar	O
detection	B-Metric
scores	I-Metric
.	O
	
This	O
shows	O
that	O
the	O
WSOD	B-Task
network	I-Task
is	O
not	O
discriminative	O
enough	O
to	O
correctly	O
localize	O
object	O
.	O
	
This	O
is	O
a	O
core	O
problem	O
of	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
deep	I-Task
network	I-Task
based	I-Task
WSOD	I-Task
.	O
	
To	O
address	O
this	O
problem	O
,	O
we	O
put	O
forward	O
two	O
improvements	O
in	O
this	O
paper	O
:	O
	
1	O
)	O
Instead	O
of	O
estimating	O
instance	O
weights	O
through	O
weighted	B-Method
sum	I-Method
pooling	I-Method
,	O
we	O
propose	O
to	O
add	O
some	O
blocks	O
in	O
the	O
network	O
for	O
learning	O
more	O
discriminative	O
instance	B-Method
classifiers	I-Method
by	O
explicitly	O
assigning	O
binary	O
instance	O
labels	O
;	O
2	O
)	O
We	O
propose	O
to	O
refine	O
instance	B-Method
classifier	I-Method
online	O
using	O
spatial	O
relation	O
.	O
	
Our	O
motivation	O
is	O
that	O
,	O
though	O
some	O
detectors	O
only	O
capture	O
objects	O
partially	O
,	O
proposals	O
having	O
high	O
spatial	O
overlaps	O
with	O
detected	O
parts	O
may	O
cover	O
the	O
whole	O
object	O
,	O
or	O
at	O
least	O
contain	O
larger	O
portion	O
of	O
the	O
object	O
.	O
	
In	O
,	O
Bilen	O
and	O
Vedaldi	O
propose	O
a	O
spatial	B-Method
regulariser	I-Method
via	O
forcing	O
features	O
of	O
highest	O
scoring	O
region	O
and	O
its	O
adjacent	O
regions	O
to	O
be	O
the	O
same	O
,	O
which	O
significantly	O
improves	O
WSOD	B-Task
performance	O
.	O
	
Nevertheless	O
,	O
forcing	O
spatially	O
overlapped	O
proposals	O
to	O
have	O
the	O
same	O
features	O
seems	O
too	O
rigorous	O
.	O
	
Rather	O
than	O
taking	O
the	O
rigorous	O
constraint	O
,	O
we	O
think	O
the	O
features	O
of	O
spatially	O
overlapped	O
proposals	O
are	O
in	O
the	O
same	O
manifold	O
.	O
	
Then	O
these	O
overlapped	O
proposals	O
could	O
share	O
similar	O
label	O
information	O
.	O
	
As	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
(	O
right	O
)	O
,	O
we	O
except	O
the	O
label	O
information	O
of	O
A	O
can	O
propagate	O
to	O
B	O
and	O
C	O
which	O
has	O
large	O
overlap	O
with	O
A	O
,	O
and	O
then	O
the	O
label	O
information	O
of	O
B	O
and	O
C	O
can	O
propagate	O
to	O
D	O
to	O
correctly	O
localize	O
object	O
.	O
	
To	O
implement	O
this	O
idea	O
,	O
we	O
design	O
some	O
instance	B-Method
classifiers	I-Method
in	O
the	O
network	O
of	O
.	O
	
The	O
labels	O
of	O
instance	O
could	O
be	O
refined	O
by	O
their	O
spatially	O
overlapped	O
instances	O
.	O
	
We	O
name	O
this	O
new	O
network	B-Method
structure	I-Method
Multiple	I-Method
Instance	I-Method
Detection	I-Method
Network	I-Method
(	O
MIDN	B-Method
)	O
with	O
instance	B-Method
classifier	I-Method
.	O
	
In	O
practice	O
,	O
there	O
are	O
two	O
important	O
issues	O
.	O
	
1	O
)	O
How	O
to	O
initialize	O
instance	O
labels	O
,	O
since	O
there	O
is	O
no	O
instance	O
-	O
level	O
supervision	O
in	O
this	O
task	O
.	O
	
2	O
)	O
How	O
to	O
train	O
the	O
network	O
with	O
instance	B-Method
classifier	I-Method
efficiently	O
.	O
	
A	O
natural	O
way	O
for	O
classifier	B-Task
refinement	I-Task
is	O
the	O
alternative	O
strategy	O
,	O
that	O
is	O
,	O
alternatively	O
relabelling	B-Method
instance	I-Method
and	I-Method
training	I-Method
instance	I-Method
classifier	I-Method
,	O
while	O
this	O
procedure	O
is	O
very	O
time	O
-	O
consuming	O
,	O
especially	O
considering	O
training	O
deep	B-Method
networks	I-Method
with	O
a	O
huge	O
number	O
of	O
Stochastic	B-Method
Gradient	I-Method
Descent	I-Method
(	O
SGD	B-Method
)	I-Method
iterations	I-Method
.	O
	
To	O
overcome	O
these	O
difficulties	O
,	O
we	O
propose	O
a	O
novel	O
Online	B-Method
Instance	I-Method
Classifier	I-Method
Refinement	I-Method
(	O
OICR	B-Method
)	I-Method
algorithm	I-Method
to	O
train	O
the	O
network	O
online	O
.	O
	
Our	O
method	O
has	O
multiple	O
output	O
streams	O
for	O
different	O
stages	O
:	O
the	O
first	O
is	O
the	O
MIDN	B-Method
to	O
train	O
a	O
basic	O
instance	B-Method
classifier	I-Method
and	O
others	O
refine	O
the	O
classifier	O
.	O
	
To	O
refine	O
instance	B-Method
classifier	I-Method
online	O
,	O
after	O
the	O
forward	O
process	O
of	O
SGD	B-Method
,	O
we	O
can	O
obtain	O
a	O
set	O
of	O
proposal	O
scores	O
.	O
	
According	O
to	O
these	O
scores	O
,	O
for	O
each	O
stage	O
,	O
we	O
can	O
label	O
the	O
top	O
-	O
scoring	O
proposal	O
along	O
with	O
its	O
spatially	O
overlapped	O
proposals	O
to	O
the	O
image	O
label	O
.	O
	
Then	O
these	O
proposal	O
labels	O
can	O
be	O
used	O
as	O
the	O
supervision	O
to	O
train	O
instance	B-Method
classifier	I-Method
in	O
the	O
next	O
stage	O
.	O
	
Though	O
the	O
top	O
-	O
scoring	O
proposal	O
may	O
only	O
contain	O
a	O
part	O
of	O
an	O
object	O
,	O
its	O
adjacent	O
proposals	O
will	O
cover	O
larger	O
portion	O
of	O
the	O
object	O
.	O
	
Thus	O
the	O
instance	B-Method
classifier	I-Method
can	O
be	O
refined	O
.	O
	
After	O
implementing	O
the	O
refinement	B-Method
procedure	I-Method
multiple	O
times	O
,	O
the	O
detector	B-Method
can	O
discover	O
the	O
whole	O
object	O
instead	O
of	O
parts	O
gradually	O
,	O
as	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
But	O
in	O
the	O
beginning	O
of	O
training	O
,	O
all	O
classifiers	B-Method
are	O
almost	O
non	O
-	O
trained	O
,	O
which	O
will	O
result	O
in	O
very	O
noisy	O
supervision	O
of	O
refined	O
classifiers	O
,	O
and	O
then	O
the	O
training	O
will	O
deviate	O
from	O
correct	O
solutions	O
a	O
lot	O
.	O
	
To	O
solve	O
this	O
problem	O
,	O
we	O
design	O
a	O
weighted	O
loss	O
further	O
by	O
assigning	O
different	O
weights	O
to	O
different	O
proposals	O
in	O
different	O
training	O
iterations	O
.	O
	
Using	O
this	O
strategy	O
,	O
all	O
classifier	B-Method
refinement	I-Method
procedures	I-Method
can	O
thus	O
be	O
integrated	O
into	O
a	O
single	O
network	O
and	O
trained	O
end	O
-	O
to	O
-	O
end	O
.	O
	
It	O
can	O
improve	O
the	O
performance	O
benefiting	O
from	O
the	O
classifier	B-Method
refinement	I-Method
procedure	I-Method
.	O
	
Meanwhile	O
,	O
the	O
multi	B-Method
-	I-Method
stage	I-Method
strategy	I-Method
and	O
online	B-Method
refinement	I-Method
algorithm	I-Method
is	O
very	O
computational	O
efficient	O
in	O
both	O
training	B-Task
and	O
testing	B-Task
.	O
	
Moreover	O
,	O
performance	O
can	O
be	O
improved	O
by	O
sharing	O
representations	O
among	O
different	O
training	O
stages	O
.	O
	
We	O
elaborately	O
conduct	O
many	O
experiments	O
on	O
the	O
challenging	B-Material
PASCAL	I-Material
VOC	I-Material
dataset	I-Material
to	O
confirm	O
the	O
effectiveness	O
of	O
our	O
method	O
.	O
	
Our	O
method	O
achieves	O
mAP	B-Metric
and	O
CorLoc	B-Task
on	O
VOC	B-Material
2007	I-Material
that	O
outperforms	O
previous	O
best	O
performed	O
methods	O
by	O
a	O
large	O
margin	O
.	O
	
In	O
summary	O
,	O
the	O
main	O
contributions	O
of	O
our	O
work	O
are	O
listed	O
as	O
follows	O
.	O
	
We	O
propose	O
a	O
framework	O
for	O
weakly	B-Task
supervised	I-Task
learning	I-Task
that	O
combines	O
MIDN	B-Method
with	O
multi	O
-	O
stage	O
instance	B-Method
classifiers	I-Method
.	O
	
With	O
only	O
supervision	O
of	O
the	O
outputs	O
from	O
its	O
preceding	O
stage	O
,	O
the	O
discriminatory	O
power	O
of	O
the	O
instance	B-Method
classifier	I-Method
can	O
be	O
enhanced	O
iteratively	O
.	O
	
We	O
further	O
design	O
a	O
novel	O
OICR	B-Method
algorithm	I-Method
that	O
integrates	O
the	O
basic	B-Method
detection	I-Method
network	I-Method
and	O
the	O
multi	B-Method
-	I-Method
stage	I-Method
instance	I-Method
-	I-Method
level	I-Method
classifier	I-Method
into	O
a	O
single	O
network	O
.	O
	
The	O
proposed	O
network	O
is	O
end	O
-	O
to	O
-	O
end	O
trainable	O
.	O
	
Compared	O
with	O
the	O
alternatively	B-Method
training	I-Method
strategy	I-Method
,	O
we	O
demonstrate	O
that	O
our	O
method	O
can	O
not	O
only	O
reduce	O
the	O
training	B-Metric
time	I-Metric
,	O
but	O
also	O
boost	O
the	O
performance	O
.	O
	
Our	O
method	O
achieves	O
significantly	O
better	O
results	O
over	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
on	O
the	O
challenging	O
PASCAL	B-Material
VOC	I-Material
2007	I-Material
and	O
2012	B-Material
benchmarks	O
for	O
weakly	B-Task
supervised	I-Task
object	I-Task
detection	I-Task
.	O
	
section	O
:	O
Related	O
work	O
	
MIL	B-Method
is	O
a	O
classical	O
weakly	B-Task
supervised	I-Task
learning	I-Task
problem	I-Task
and	O
was	O
first	O
proposed	O
in	O
for	O
drug	B-Task
activity	I-Task
prediction	I-Task
.	O
	
After	O
that	O
,	O
many	O
solutions	O
have	O
been	O
proposed	O
for	O
MIL	B-Method
.	O
	
In	O
MIL	B-Method
,	O
a	O
set	O
of	O
bags	O
are	O
given	O
,	O
and	O
each	O
bag	O
is	O
associated	O
with	O
a	O
collection	O
of	O
instances	O
.	O
	
MIL	B-Method
has	O
two	O
constraints	O
:	O
1	O
)	O
If	O
a	O
bag	O
is	O
positive	O
,	O
at	O
least	O
one	O
instance	O
in	O
the	O
bag	O
is	O
positive	O
;	O
2	O
)	O
	
If	O
a	O
bag	O
is	O
negative	O
,	O
all	O
instances	O
in	O
the	O
bag	O
are	O
negative	O
.	O
	
It	O
is	O
natural	O
to	O
treat	O
WSOD	B-Task
as	O
a	O
MIL	B-Task
problem	I-Task
.	O
	
Then	O
the	O
problem	O
turns	O
into	O
finding	O
an	O
instance	B-Method
classifier	I-Method
only	O
given	O
bag	O
labels	O
.	O
	
Our	O
method	O
also	O
follows	O
the	O
MIL	O
line	O
,	O
and	O
the	O
classifier	B-Method
refinement	I-Method
is	O
inspired	O
by	O
the	O
classifier	B-Method
updating	I-Method
procedure	I-Method
in	O
mi	B-Method
-	I-Method
SVM	I-Method
to	O
some	O
extent	O
.	O
	
The	O
differences	O
are	O
that	O
,	O
in	O
mi	B-Method
-	I-Method
SVM	I-Method
,	O
it	O
uses	O
an	O
alternative	O
strategy	O
to	O
relabel	O
instances	O
and	O
retrain	O
a	O
classifier	B-Method
,	O
while	O
we	O
adopt	O
an	O
online	B-Method
refinement	I-Method
algorithm	I-Method
;	O
the	O
mi	B-Method
-	I-Method
SVM	I-Method
relabel	O
instances	O
according	O
to	O
the	O
instance	O
score	O
predicted	O
by	O
the	O
classifier	B-Method
,	O
while	O
we	O
select	O
instances	O
according	O
to	O
the	O
spatial	O
relation	O
.	O
	
Most	O
of	O
the	O
existing	O
methods	O
solve	O
the	O
WSOD	B-Task
problem	I-Task
based	O
on	O
MIL	B-Method
.	O
	
For	O
example	O
,	O
Wang	O
relaxed	O
the	O
MIL	O
restraints	O
into	O
a	O
differentiable	O
loss	O
function	O
and	O
optimized	O
it	O
by	O
SGD	B-Method
to	O
speed	O
up	O
training	B-Task
and	O
improve	O
results	O
.	O
	
Cibis	B-Method
trained	O
a	O
multi	B-Method
-	I-Method
fold	I-Method
MIL	I-Method
detector	I-Method
by	O
alternatively	O
relabelling	O
instances	O
and	O
retraining	B-Method
classifier	I-Method
.	O
	
Recently	O
,	O
some	O
researchers	O
combined	O
CNN	B-Method
and	O
MIL	B-Method
to	O
train	O
an	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
network	I-Method
for	O
WSOD	B-Task
.	O
	
Oquab	B-Method
trained	O
a	O
CNN	B-Method
network	O
using	O
the	O
max	B-Method
-	I-Method
pooing	I-Method
MIL	I-Method
strategy	I-Method
to	O
localize	B-Task
objects	I-Task
.	O
	
But	O
their	O
methods	O
can	O
only	O
coarsely	O
localize	O
objects	O
regardless	O
of	O
their	O
sizes	O
and	O
aspect	O
ratios	O
,	O
our	O
method	O
can	O
detect	O
objects	O
more	O
accurately	O
.	O
	
Bilen	O
and	O
Vedaldi	O
proposed	O
a	O
Weakly	B-Method
Supervised	I-Method
Deep	I-Method
Detection	I-Method
Network	I-Method
(	O
WSDDN	B-Method
)	I-Method
,	O
which	O
presents	O
a	O
novel	O
weighted	B-Method
MIL	I-Method
pooling	I-Method
strategy	I-Method
and	O
combines	O
with	O
the	O
proposal	B-Method
objectness	I-Method
and	I-Method
spatial	I-Method
regulariser	I-Method
for	O
better	O
performance	O
.	O
	
Based	O
on	O
the	O
WSDDN	B-Method
,	O
Kantorov	B-Method
used	O
a	O
contrastive	B-Method
model	I-Method
to	O
consider	O
the	O
context	O
information	O
for	O
improvement	O
.	O
	
We	O
also	O
choose	O
the	O
WSDDN	B-Method
as	O
our	O
basic	O
network	O
,	O
but	O
we	O
combine	O
it	O
with	O
multi	B-Method
-	I-Method
stage	I-Method
classifier	I-Method
refinement	I-Method
,	O
and	O
propose	O
a	O
novel	O
OICR	B-Method
algorithm	I-Method
to	O
train	O
our	O
network	O
effectively	O
and	O
efficiently	O
,	O
which	O
can	O
boost	O
the	O
performance	O
significantly	O
.	O
	
Different	O
from	O
the	O
spatial	B-Method
regulariser	I-Method
in	O
WSDDN	B-Method
that	O
forces	O
features	O
of	O
highest	O
scoring	O
proposal	O
and	O
its	O
spatially	O
overlapped	O
proposals	O
to	O
be	O
the	O
same	O
,	O
our	O
OICR	B-Method
assumes	O
features	O
of	O
spatially	O
overlapped	O
proposals	O
are	O
in	O
the	O
same	O
manifold	O
,	O
which	O
is	O
more	O
reasonable	O
.	O
	
Experiments	O
on	O
Section	O
[	O
reference	O
]	O
demonstrate	O
that	O
our	O
strategy	O
can	O
obtain	O
more	O
superior	O
results	O
.	O
	
The	O
proposal	B-Method
labelling	I-Method
procedure	I-Method
is	O
also	O
related	O
to	O
the	O
semi	B-Method
-	I-Method
supervised	I-Method
label	I-Method
propagation	I-Method
method	I-Method
.	O
	
But	O
in	O
label	B-Task
propagation	I-Task
,	O
it	O
labels	O
data	O
according	O
to	O
the	O
similarity	O
among	O
labelled	O
and	O
unlabelled	O
data	O
,	O
while	O
we	O
use	O
spatial	O
overlap	O
as	O
the	O
metric	O
;	O
and	O
there	O
are	O
no	O
available	O
labelled	O
instances	O
for	O
propagation	B-Task
,	O
which	O
is	O
quite	O
different	O
from	O
semi	B-Method
-	I-Method
supervised	I-Method
methods	I-Method
.	O
	
Meanwhile	O
,	O
the	O
sharing	B-Method
representation	I-Method
strategy	I-Method
in	O
our	O
network	O
is	O
similar	O
to	O
multi	B-Task
-	I-Task
task	I-Task
learning	I-Task
.	O
	
Unlike	O
the	O
multi	B-Method
-	I-Method
task	I-Method
learning	I-Method
that	O
each	O
output	O
stream	O
has	O
their	O
own	O
relatively	O
independent	O
external	O
supervision	O
,	O
in	O
our	O
method	O
,	O
supervision	O
of	O
latter	O
streams	O
only	O
depends	O
on	O
the	O
outputs	O
from	O
their	O
preceding	O
streams	O
.	O
	
section	O
:	O
Method	O
	
The	O
overall	O
architecture	O
of	O
our	O
method	O
is	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Given	O
an	O
image	O
,	O
we	O
first	O
generate	O
about	O
object	O
proposals	O
by	O
Selective	B-Method
Search	I-Method
.	O
	
The	O
image	O
and	O
these	O
proposals	O
are	O
fed	O
into	O
some	O
convolutional	B-Method
(	I-Method
conv	I-Method
)	I-Method
layers	I-Method
with	O
Spatial	B-Method
Pyramid	I-Method
Pooling	I-Method
(	I-Method
SPP	I-Method
)	I-Method
layer	I-Method
to	O
produce	O
a	O
fixed	O
-	O
size	O
conv	O
feature	O
map	O
per	O
-	O
proposal	O
,	O
and	O
then	O
they	O
are	O
fed	O
into	O
two	O
fully	B-Method
connected	I-Method
(	I-Method
fc	I-Method
)	I-Method
layers	I-Method
to	O
generate	O
a	O
collection	O
of	O
proposal	O
feature	O
vectors	O
.	O
	
These	O
features	O
are	O
branched	O
into	O
different	O
streams	O
,	O
,	O
different	O
stages	O
:	O
the	O
first	O
one	O
is	O
the	O
MIDN	B-Method
to	O
train	O
a	O
basic	O
instance	B-Method
classifier	I-Method
and	O
others	O
refine	O
classifier	B-Method
.	O
	
Specially	O
,	O
supervision	O
for	O
classifier	B-Task
refinement	I-Task
is	O
decided	O
by	O
outputs	O
from	O
their	O
preceding	O
stages	O
,	O
,	O
supervision	O
of	O
the	O
first	O
refined	B-Method
classifier	I-Method
depends	O
on	O
the	O
output	O
from	O
the	O
basic	B-Method
classifier	I-Method
,	O
and	O
supervision	B-Method
of	I-Method
refined	I-Method
classifier	I-Method
depends	O
on	O
outputs	O
from	O
refined	B-Method
classifier	I-Method
.	O
	
In	O
this	O
section	O
,	O
we	O
will	O
introduce	O
the	O
chosen	O
basic	O
MIDN	B-Method
,	O
and	O
explain	O
our	O
OICR	B-Method
algorithm	I-Method
in	O
detail	O
.	O
	
subsection	O
:	O
Multiple	B-Method
instance	I-Method
detection	I-Method
network	I-Method
	
It	O
is	O
necessary	O
to	O
achieve	O
instance	O
-	O
level	O
supervision	O
to	O
train	O
refined	O
classifier	B-Method
,	O
yet	O
such	O
supervision	B-Method
is	O
unavailable	O
.	O
	
As	O
we	O
have	O
stated	O
before	O
,	O
the	O
top	O
-	O
scoring	O
proposal	O
by	O
instance	B-Method
classifiers	I-Method
and	O
its	O
adjacent	O
proposals	O
can	O
be	O
labelled	O
to	O
its	O
image	O
label	O
as	O
supervision	O
.	O
	
So	O
we	O
first	O
introduce	O
our	O
MIDN	B-Method
to	O
generate	O
the	O
basic	O
instance	B-Method
classifier	I-Method
.	O
	
There	O
are	O
many	O
possible	O
choices	O
to	O
achieve	O
this	O
.	O
	
Here	O
we	O
choose	O
the	O
method	O
by	O
Bilen	O
and	O
Vedaldi	O
which	O
proposes	O
a	O
weighted	B-Method
pooling	I-Method
strategy	I-Method
to	O
obtain	O
the	O
instance	B-Method
classifier	I-Method
,	O
for	O
its	O
effectiveness	O
and	O
implementation	O
convenience	O
.	O
	
Notice	O
that	O
our	O
network	O
is	O
independent	O
of	O
special	O
MIL	B-Method
methods	I-Method
,	O
so	O
any	O
method	O
that	O
can	O
be	O
trained	O
end	O
-	O
to	O
-	O
end	O
could	O
be	O
embedded	O
into	O
our	O
network	O
.	O
	
As	O
shown	O
in	O
the	O
“	O
Multiple	B-Method
instance	I-Method
detection	I-Method
network	I-Method
”	O
block	O
of	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
proposal	O
features	O
are	O
branched	O
into	O
two	O
streams	O
to	O
produce	O
two	O
matrices	O
of	O
image	O
by	O
two	O
fc	B-Method
layers	I-Method
,	O
where	O
denotes	O
the	O
number	O
of	O
image	O
classes	O
and	O
denotes	O
the	O
number	O
of	O
proposals	O
.	O
	
Then	O
the	O
two	O
matrices	O
are	O
passing	O
through	O
two	O
softmax	B-Method
layer	I-Method
along	O
different	O
directions	O
:	O
and	O
.	O
	
The	O
proposal	O
scores	O
are	O
generated	O
by	O
element	B-Method
-	I-Method
wise	I-Method
product	I-Method
.	O
	
At	O
last	O
,	O
image	O
score	O
of	O
class	O
can	O
be	O
obtained	O
by	O
the	O
sum	O
over	O
all	O
proposals	O
:	O
.	O
	
The	O
interpretation	O
of	O
the	O
two	O
streams	B-Method
framework	I-Method
is	O
as	O
follows	O
.	O
	
The	O
is	O
the	O
probability	O
of	O
proposal	O
belonging	O
to	O
class	O
.	O
	
The	O
is	O
the	O
normalized	O
weight	O
that	O
indicates	O
the	O
contribution	O
of	O
proposal	O
to	O
image	O
being	O
classified	O
to	O
class	O
.	O
	
So	O
is	O
achieved	O
by	O
weighted	B-Method
sum	I-Method
pooling	I-Method
and	O
falls	O
in	O
the	O
range	O
of	O
.	O
	
Given	O
image	O
label	O
,	O
where	O
or	O
indicates	O
the	O
image	O
with	O
or	O
without	O
object	O
.	O
	
We	O
can	O
train	O
the	O
basic	O
instance	B-Method
classifier	I-Method
by	O
standard	O
multi	B-Method
-	I-Method
class	I-Method
cross	I-Method
entropy	I-Method
loss	I-Method
,	O
as	O
shown	O
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
,	O
then	O
the	O
instance	B-Method
classifier	I-Method
can	O
be	O
obtained	O
according	O
to	O
the	O
proposal	O
score	O
.	O
	
More	O
details	O
can	O
be	O
found	O
in	O
.	O
	
subsection	O
:	O
Online	B-Task
instance	I-Task
classifier	I-Task
refinement	I-Task
	
In	O
the	O
last	O
subsection	O
,	O
we	O
have	O
obtained	O
the	O
basic	O
instance	B-Method
classifier	I-Method
.	O
	
Here	O
we	O
will	O
expound	O
how	O
to	O
refine	O
instance	B-Method
classifiers	I-Method
online	O
.	O
	
A	O
natural	O
way	O
to	O
refine	O
classifier	B-Method
is	O
an	O
alternative	O
strategy	O
,	O
that	O
is	O
,	O
fixing	O
the	O
classifier	O
and	O
labelling	O
proposals	O
,	O
fixing	O
proposal	O
labels	O
and	O
training	O
the	O
classifier	B-Method
.	O
	
But	O
it	O
has	O
some	O
limitations	O
	
:	O
1	O
)	O
It	O
is	O
very	O
time	O
-	O
consuming	O
as	O
it	O
requires	O
training	O
the	O
classifier	B-Method
multiple	O
times	O
;	O
2	O
)	O
Training	O
different	O
classifiers	B-Method
in	O
different	O
refinement	O
steps	O
separately	O
may	O
harm	O
the	O
performance	O
because	O
it	O
hinders	O
the	O
process	O
to	O
benefit	O
from	O
the	O
shared	B-Method
representations	I-Method
.	O
	
Hence	O
,	O
we	O
integrate	O
the	O
basic	O
MIDN	B-Method
and	O
different	O
classifier	B-Method
refinement	I-Method
stages	I-Method
into	O
a	O
single	O
network	O
and	O
train	O
it	O
end	O
-	O
to	O
-	O
end	O
.	O
	
The	O
difficulty	O
is	O
how	O
to	O
obtain	O
instance	O
labels	O
for	O
refinement	B-Task
when	O
there	O
are	O
no	O
available	O
labelled	O
instances	O
.	O
	
To	O
deal	O
with	O
this	O
problem	O
,	O
we	O
propose	O
an	O
online	B-Method
labelling	I-Method
and	I-Method
refinement	I-Method
strategy	I-Method
.	O
	
Different	O
from	O
the	O
basic	O
instance	B-Method
classifier	I-Method
,	O
the	O
output	O
score	O
vector	O
of	O
proposal	O
for	O
refined	B-Method
classifier	I-Method
is	O
a	O
-	O
dimensional	O
vector	O
,	O
,	O
,	O
where	O
the	O
is	O
for	O
time	B-Task
refinement	I-Task
,	O
is	O
the	O
total	O
refinement	O
times	O
,	O
and	O
the	O
dimension	O
is	O
for	O
background	O
(	O
here	O
we	O
represent	O
the	O
proposal	O
score	O
vector	O
from	O
the	O
basic	B-Method
classifier	I-Method
as	O
)	O
.	O
	
The	O
is	O
obtained	O
by	O
passing	O
the	O
proposal	O
feature	O
vector	O
through	O
a	O
single	O
fc	B-Method
layer	I-Method
and	O
a	O
softmax	B-Method
over	I-Method
classes	I-Method
layer	I-Method
,	O
as	O
shown	O
in	O
the	O
“	O
Instance	B-Method
classifier	I-Method
refinement	I-Method
”	O
block	O
of	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Suppose	O
the	O
label	O
vector	O
for	O
proposal	O
is	O
.	O
	
In	O
each	O
training	O
iteration	O
,	O
after	O
the	O
forward	B-Method
process	I-Method
of	O
SGD	B-Method
,	O
we	O
can	O
get	O
a	O
set	O
of	O
proposal	O
scores	O
.	O
	
Then	O
we	O
can	O
obtain	O
the	O
supervision	O
of	O
refinement	O
time	O
according	O
to	O
.	O
	
There	O
are	O
many	O
possible	O
methods	O
to	O
obtain	O
instance	O
labels	O
using	O
,	O
,	O
labeling	O
an	O
instance	O
as	O
positive	O
if	O
its	O
score	O
exceeds	O
a	O
threshold	O
,	O
otherwise	O
as	O
negative	O
,	O
as	O
the	O
mi	B-Method
-	I-Method
SVM	I-Method
.	O
	
But	O
in	O
our	O
case	O
,	O
the	O
score	O
for	O
each	O
instance	O
is	O
changed	O
during	O
each	O
training	O
iteration	O
,	O
and	O
for	O
different	O
classes	O
,	O
using	O
the	O
same	O
threshold	O
may	O
not	O
be	O
suitable	O
,	O
thus	O
it	O
is	O
hard	O
to	O
settle	O
a	O
threshold	O
.	O
	
Here	O
we	O
choose	O
a	O
different	O
strategy	O
,	O
inspired	O
by	O
the	O
fact	O
that	O
highly	O
spatially	O
overlapped	O
instances	O
should	O
have	O
the	O
same	O
label	O
.	O
	
Suppose	O
an	O
image	O
has	O
class	O
label	O
,	O
we	O
first	O
select	O
proposal	O
with	O
highest	O
score	O
for	O
time	O
as	O
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
,	O
and	O
label	O
it	O
to	O
class	O
,	O
,	O
and	O
.	O
	
As	O
different	O
proposals	O
always	O
have	O
overlaps	O
,	O
and	O
proposals	O
with	O
high	O
overlap	O
should	O
belong	O
to	O
the	O
same	O
class	O
,	O
we	O
can	O
label	O
proposal	O
and	O
its	O
adjacent	O
proposals	O
to	O
class	O
for	O
refinement	B-Task
,	O
,	O
if	O
proposal	O
have	O
a	O
high	O
overlap	O
with	O
proposal	O
,	O
we	O
label	O
proposal	O
to	O
class	O
(	O
)	O
,	O
otherwise	O
we	O
label	O
proposal	O
as	O
background	O
(	O
)	O
.	O
	
Here	O
we	O
label	O
proposal	O
to	O
class	O
if	O
the	O
IoU	O
between	O
proposal	O
and	O
greater	O
than	O
a	O
threshold	O
which	O
is	O
determined	O
by	O
experiments	O
.	O
	
Meanwhile	O
,	O
if	O
there	O
is	O
no	O
object	O
in	O
the	O
image	O
,	O
we	O
set	O
all	O
.	O
	
Using	O
this	O
supervision	O
,	O
we	O
can	O
train	O
the	O
refined	B-Method
classifier	I-Method
based	O
on	O
the	O
loss	O
function	O
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
	
Through	O
multiple	O
times	O
of	O
refinement	O
,	O
our	O
detector	O
can	O
detect	O
larger	O
parts	O
of	O
objects	O
gradually	O
.	O
	
[	O
t	O
]	O
Online	B-Method
instance	I-Method
classifier	I-Method
refinement	I-Method
	
[	O
1	O
]	O
Image	O
and	O
its	O
proposals	O
;	O
image	O
label	O
vector	O
;	O
refinement	O
times	O
.	O
	
Loss	O
weights	O
;	O
proposal	O
label	O
vectors	O
.	O
	
Where	O
and	O
.	O
	
Feed	O
and	O
its	O
proposals	O
into	O
the	O
network	O
to	O
produce	O
proposal	O
score	O
matrices	O
,	O
.	O
	
Set	O
all	O
elements	O
in	O
to	O
.	O
	
Set	O
all	O
and	O
.	O
	
Choose	O
the	O
top	O
-	O
scoring	O
proposal	O
by	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
	
Compute	O
IoU	O
between	O
proposal	O
and	O
.	O
	
Set	O
and	O
.	O
	
Set	O
and	O
.	O
	
Actually	O
the	O
acquired	O
supervision	O
for	O
refining	B-Task
classifier	I-Task
is	O
very	O
noisy	O
,	O
especially	O
in	O
the	O
beginning	O
of	O
training	O
,	O
which	O
will	O
result	O
in	O
unstable	O
solutions	O
.	O
	
To	O
solve	O
this	O
problem	O
,	O
we	O
change	O
the	O
loss	O
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
to	O
a	O
weighted	B-Method
version	I-Method
,	O
as	O
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
	
where	O
is	O
the	O
loss	O
weight	O
and	O
can	O
be	O
acquired	O
by	O
the	O
line	B-Method
of	I-Method
Algorithm	I-Method
[	O
reference	O
]	O
.	O
	
The	O
explanation	O
of	O
such	O
choice	O
is	O
as	O
follows	O
.	O
	
In	O
the	O
beginning	O
of	O
training	O
,	O
the	O
is	O
small	O
,	O
hence	O
,	O
the	O
loss	B-Metric
is	O
also	O
small	O
.	O
	
As	O
a	O
consequence	O
,	O
the	O
performance	O
of	O
the	O
network	O
will	O
not	O
decrease	O
a	O
lot	O
though	O
good	O
positive	O
instances	O
can	O
not	O
be	O
found	O
.	O
	
Meanwhile	O
,	O
during	O
the	O
training	O
procedure	O
,	O
the	O
network	O
can	O
achieve	O
positive	O
instances	O
with	O
high	O
scores	O
easily	O
for	O
easy	O
bags	O
,	O
and	O
these	O
positive	O
instances	O
are	O
always	O
with	O
high	O
scores	O
,	O
,	O
is	O
large	O
.	O
	
On	O
the	O
contrary	O
,	O
it	O
is	O
difficult	O
to	O
get	O
positive	O
instances	O
for	O
difficult	O
bags	O
,	O
as	O
a	O
result	O
,	O
these	O
positive	O
instances	O
are	O
always	O
very	O
noisy	O
.	O
	
Nevertheless	O
,	O
the	O
refined	O
classifier	B-Method
will	O
not	O
deviate	O
from	O
the	O
correct	O
solution	O
a	O
lot	O
,	O
because	O
the	O
scores	O
of	O
these	O
noisy	O
positive	O
instances	O
are	O
relatively	O
low	O
,	O
,	O
is	O
small	O
.	O
	
To	O
make	O
the	O
OICR	B-Method
algorithm	I-Method
more	O
clear	O
,	O
we	O
summarize	O
the	O
process	O
to	O
obtain	O
supervision	O
in	O
Algorithm	O
[	O
reference	O
]	O
,	O
where	O
indicates	O
the	O
maximum	O
IoU	O
between	O
proposal	O
and	O
the	O
top	O
-	O
scoring	O
proposal	O
.	O
	
After	O
obtaining	O
supervision	O
and	O
loss	O
for	O
training	O
refined	B-Method
classifiers	I-Method
,	O
we	O
can	O
get	O
the	O
loss	O
of	O
our	O
overall	B-Method
network	I-Method
by	O
combining	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
and	O
	
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
,	O
as	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
	
Through	O
optimizing	O
this	O
loss	O
function	O
,	O
we	O
can	O
integrate	O
the	O
basic	B-Method
network	I-Method
and	O
different	O
classifier	B-Method
refinement	I-Method
stages	I-Method
into	O
a	O
single	O
network	O
,	O
and	O
share	O
representations	O
among	O
different	O
stages	O
.	O
	
section	O
:	O
Experiments	O
	
subsection	O
:	O
Experimental	O
setup	O
	
In	O
this	O
section	O
we	O
will	O
perform	O
thorough	O
experiments	O
to	O
analyse	O
our	O
OICR	B-Method
and	O
its	O
components	O
for	O
weakly	B-Task
supervised	I-Task
object	I-Task
detection	I-Task
.	O
	
paragraph	O
:	O
Datasets	O
and	O
evaluation	B-Metric
measures	I-Metric
	
We	O
evaluate	O
our	O
method	O
on	O
the	O
challenging	O
PASCAL	B-Material
VOC	I-Material
2007	I-Material
and	O
2012	B-Material
datasets	O
which	O
have	O
and	O
images	O
respectively	O
for	O
object	O
classes	O
.	O
	
These	O
two	O
datasets	O
are	O
divided	O
into	O
train	O
,	O
val	O
,	O
and	O
test	O
sets	O
.	O
	
Here	O
we	O
choose	O
the	O
trainval	O
set	O
(	O
images	O
for	O
2007	O
and	O
for	O
2012	B-Material
)	O
to	O
train	O
our	O
network	O
.	O
	
As	O
we	O
focus	O
on	O
weakly	B-Task
supervised	I-Task
detection	I-Task
,	O
only	O
image	O
-	O
level	O
labels	O
are	O
utilized	O
during	O
training	O
.	O
	
For	O
testing	O
,	O
there	O
are	O
two	O
metrics	O
for	O
evaluation	B-Task
:	O
mAP	B-Metric
and	O
CorLoc	B-Metric
.	O
	
Average	B-Metric
Precision	I-Metric
(	O
AP	B-Metric
)	O
and	O
the	O
mean	B-Metric
of	I-Metric
AP	I-Metric
(	O
mAP	B-Metric
)	O
is	O
the	O
evaluation	B-Metric
metric	I-Metric
to	O
test	O
our	O
model	O
on	O
the	O
testing	O
set	O
,	O
which	O
follows	O
the	O
standard	O
PASCAL	B-Material
VOC	I-Material
protocol	I-Material
.	O
	
Correct	B-Metric
localization	I-Metric
(	O
CorLoc	B-Metric
)	O
is	O
to	O
test	O
our	O
model	O
on	O
the	O
training	O
set	O
measuring	O
the	O
localization	B-Metric
accuracy	I-Metric
.	O
	
All	O
these	O
two	O
metrics	O
are	O
based	O
on	O
the	O
PASCAL	B-Metric
criteria	I-Metric
,	O
,	O
IoU	O
0.5	O
between	O
ground	O
truths	O
and	O
predicted	O
boxes	O
.	O
	
paragraph	O
:	O
Implementation	O
details	O
	
Our	O
method	O
is	O
built	O
on	O
two	O
pre	B-Method
-	I-Method
trained	I-Method
ImageNet	I-Method
networks	I-Method
:	O
VGG	B-Method
M	I-Method
and	O
VGG16	B-Method
,	O
each	O
of	O
which	O
has	O
some	O
conv	B-Method
layers	I-Method
with	O
max	B-Method
-	I-Method
pooling	I-Method
layer	I-Method
and	O
three	O
fc	B-Method
layers	I-Method
.	O
	
We	O
replace	O
the	O
last	O
max	B-Method
-	I-Method
pooling	I-Method
layer	I-Method
of	O
the	O
two	O
models	O
by	O
SPP	B-Method
layer	I-Method
,	O
and	O
the	O
last	O
fc	B-Method
layer	I-Method
and	O
softmax	B-Method
loss	I-Method
layer	I-Method
by	O
the	O
layers	O
described	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
To	O
increase	O
the	O
feature	O
map	O
size	O
from	O
the	O
last	O
conv	O
layer	O
,	O
we	O
replace	O
the	O
penultimate	B-Method
max	I-Method
-	I-Method
pooling	I-Method
layer	I-Method
and	O
its	O
subsequent	O
conv	B-Method
layers	I-Method
by	O
the	O
dilated	B-Method
conv	I-Method
layers	I-Method
.	O
	
The	O
new	O
added	O
layers	O
are	O
initialized	O
using	O
Gaussian	B-Method
distributions	I-Method
with	O
-	O
mean	O
and	O
standard	O
deviations	O
.	O
	
Biases	O
are	O
initialized	O
to	O
.	O
	
During	O
training	B-Task
,	O
the	O
mini	O
-	O
batch	O
size	O
for	O
SGD	B-Method
is	O
set	O
to	O
,	O
and	O
the	O
learning	B-Metric
rate	I-Metric
is	O
set	O
to	O
for	O
the	O
first	O
K	O
iterations	O
and	O
then	O
decrease	O
to	O
in	O
the	O
following	O
K	O
iterations	O
.	O
	
The	O
momentum	O
and	O
weight	O
decay	O
are	O
set	O
to	O
and	O
respectively	O
.	O
	
As	O
we	O
have	O
stated	O
in	O
Section	O
[	O
reference	O
]	O
,	O
Selective	B-Method
Search	I-Method
(	O
SS	B-Method
)	I-Method
is	O
adopted	O
to	O
generate	O
about	O
proposals	O
per	O
-	O
image	O
.	O
	
For	O
data	B-Task
augmentation	I-Task
,	O
we	O
use	O
five	O
image	O
scales	O
(	O
resize	O
the	O
shortest	O
side	O
to	O
one	O
of	O
these	O
scales	O
)	O
and	O
cap	O
the	O
longest	O
image	O
side	O
to	O
less	O
than	O
with	O
horizontal	O
flips	O
for	O
both	O
training	O
and	O
testing	B-Task
.	O
	
We	O
refine	O
instance	B-Method
classifier	I-Method
three	O
times	O
,	O
,	O
in	O
Section	O
[	O
reference	O
]	O
,	O
so	O
there	O
are	O
four	O
stages	O
in	O
total	O
.	O
	
The	O
IoU	O
threshold	O
in	O
the	O
line	O
of	O
Algorithm	O
[	O
reference	O
]	O
is	O
set	O
to	O
.	O
	
During	O
testing	O
,	O
the	O
mean	O
output	O
of	O
these	O
three	O
refined	B-Method
classifiers	I-Method
is	O
chosen	O
.	O
	
We	O
also	O
follow	O
the	O
to	O
train	O
a	O
supervised	B-Method
object	I-Method
detector	I-Method
by	O
choosing	O
top	O
-	O
scoring	O
proposals	O
given	O
by	O
our	O
method	O
as	O
pseudo	O
ground	O
truths	O
to	O
further	O
improve	O
our	O
results	O
.	O
	
Here	O
we	O
train	O
a	O
Fast	B-Method
RCNN	I-Method
(	O
FRCNN	B-Method
)	O
detector	O
using	O
the	O
VGG16	B-Method
model	I-Method
and	O
the	O
same	O
five	O
image	O
scales	O
(	O
horizontal	O
flips	O
only	O
in	O
training	O
)	O
.	O
	
SS	B-Method
is	O
also	O
chosen	O
for	O
proposal	B-Task
generation	I-Task
to	O
train	O
the	O
FRCNN	B-Method
.	O
	
Non	B-Method
-	I-Method
maxima	I-Method
suppression	I-Method
(	O
with	O
IoU	O
threshold	O
)	O
is	O
applied	O
to	O
compute	O
AP	B-Metric
and	O
CorLoc	O
.	O
	
Our	O
experiments	O
are	O
implemented	O
based	O
on	O
the	O
Caffe	B-Method
deep	I-Method
learning	I-Method
framework	I-Method
.	O
	
All	O
of	O
our	O
experiments	O
are	O
running	O
on	O
a	O
NVIDIA	B-Method
GTX	I-Method
TitanX	I-Method
GPU	I-Method
.	O
	
Codes	O
for	O
reproducing	O
the	O
results	O
are	O
available	O
at	O
.	O
	
subsection	O
:	O
Ablation	B-Task
experiments	O
	
We	O
first	O
conduct	O
some	O
ablation	O
experiments	O
to	O
illustrate	O
the	O
effectiveness	O
of	O
our	O
training	B-Method
strategy	I-Method
,	O
including	O
the	O
influence	O
of	O
classifier	B-Method
refinement	I-Method
,	O
OICR	B-Method
,	O
weighted	B-Method
loss	I-Method
,	O
and	O
the	O
IoU	O
threshold	O
.	O
	
Without	O
loss	O
generality	O
,	O
we	O
only	O
perform	O
experiments	O
on	O
VOC	B-Material
2007	I-Material
and	O
use	O
the	O
VGG	B-Method
M	I-Method
model	I-Method
.	O
	
subsubsection	O
:	O
The	O
influence	O
of	O
instance	B-Method
classifier	I-Method
refinement	I-Method
	
As	O
in	O
the	O
blue	O
line	O
of	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
we	O
can	O
observe	O
that	O
compared	O
with	O
the	O
basic	O
network	O
,	O
even	O
just	O
refining	O
instance	B-Method
classifier	I-Method
one	O
time	O
can	O
boost	O
the	O
performance	O
a	O
lot	O
(	O
mAP	B-Metric
from	O
to	O
and	O
CorLoc	O
from	O
to	O
)	O
,	O
which	O
confirms	O
the	O
necessity	O
of	O
refinement	O
.	O
	
If	O
we	O
refine	O
the	O
classifier	O
multiple	O
times	O
,	O
the	O
results	O
can	O
be	O
improved	O
further	O
.	O
	
But	O
when	O
refinement	B-Method
is	O
implemented	O
too	O
many	O
times	O
,	O
the	O
performance	O
tends	O
to	O
be	O
saturated	O
(	O
the	O
improvement	O
from	O
2	O
times	O
to	O
3	O
times	O
is	O
small	O
)	O
.	O
	
Maybe	O
this	O
is	O
because	O
the	O
network	O
tends	O
to	O
converge	O
so	O
that	O
the	O
supervision	O
of	O
time	O
is	O
similar	O
to	O
time	O
.	O
	
In	O
the	O
rest	O
of	O
this	O
paper	O
we	O
only	O
refine	O
the	O
classifier	O
times	O
.	O
	
Notice	O
that	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
the	O
“	O
0	O
time	O
”	O
is	O
similar	O
to	O
the	O
WSDDN	B-Method
using	O
SS	B-Method
as	O
proposals	O
.	O
	
Our	O
result	O
is	O
a	O
little	O
worse	O
than	O
theirs	O
(	O
mAP	B-Metric
in	O
their	O
paper	O
)	O
,	O
due	O
to	O
the	O
different	O
implementing	O
platform	O
and	O
details	O
.	O
	
subsubsection	O
:	O
The	O
influence	O
of	O
OICR	B-Method
	
Fig	O
.	O
	
[	O
reference	O
]	O
compares	O
the	O
results	O
of	O
different	O
refinement	O
times	O
and	O
different	O
training	B-Method
strategies	I-Method
for	O
classifier	B-Task
refinement	I-Task
.	O
	
As	O
we	O
can	O
see	O
,	O
whether	O
for	O
our	O
OICR	B-Method
algorithm	I-Method
or	O
the	O
alternative	O
strategy	O
,	O
results	O
can	O
be	O
improved	O
by	O
refinement	O
.	O
	
More	O
importantly	O
,	O
compared	O
with	O
the	O
alternatively	B-Method
refinement	I-Method
strategy	I-Method
,	O
our	O
OICR	B-Method
can	O
boost	O
the	O
performance	O
consistently	O
and	O
significantly	O
,	O
which	O
confirms	O
the	O
necessity	O
of	O
sharing	O
representations	O
.	O
	
Meanwhile	O
,	O
our	O
method	O
can	O
also	O
reduce	O
the	O
training	B-Metric
time	I-Metric
a	O
lot	O
,	O
as	O
it	O
only	O
requires	O
to	O
train	O
a	O
single	O
model	O
instead	O
of	O
training	O
models	O
for	O
times	O
refinement	O
in	O
the	O
alternative	O
strategy	O
.	O
	
subsubsection	O
:	O
The	O
influence	O
of	O
weighted	B-Method
loss	I-Method
	
We	O
also	O
study	O
the	O
influence	O
of	O
our	O
weighted	B-Method
loss	I-Method
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
	
So	O
here	O
we	O
train	O
a	O
network	O
based	O
on	O
the	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
	
From	O
Table	O
[	O
reference	O
]	O
,	O
we	O
can	O
see	O
that	O
using	O
the	O
unweighted	O
loss	O
,	O
the	O
improvement	O
from	O
refinement	B-Task
is	O
very	O
scant	O
,	O
and	O
the	O
performance	O
is	O
even	O
worse	O
than	O
the	O
alternative	O
strategy	O
.	O
	
Using	O
the	O
weighted	B-Method
loss	I-Method
can	O
achieve	O
much	O
better	O
performance	O
,	O
which	O
confirms	O
our	O
theory	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
subsubsection	O
:	O
The	O
influence	O
of	O
IoU	O
threshold	O
	
In	O
previous	O
experiments	O
,	O
we	O
set	O
the	O
IoU	O
threshold	O
in	O
the	O
line	O
of	O
Algorithm	O
[	O
reference	O
]	O
to	O
.	O
	
Here	O
we	O
conduct	O
experiments	O
to	O
analyse	O
the	O
influence	O
of	O
.	O
	
As	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
outperforms	O
other	O
choices	O
,	O
and	O
the	O
results	O
are	O
not	O
very	O
sensitive	O
to	O
the	O
:	O
when	O
changing	O
from	O
to	O
,	O
the	O
performance	O
only	O
drops	O
a	O
little	O
(	O
mAP	B-Metric
from	O
to	O
,	O
CorLoc	O
maintains	O
)	O
.	O
	
Here	O
we	O
set	O
to	O
in	O
other	O
experiments	O
.	O
	
subsection	O
:	O
Comparison	O
with	O
other	O
methods	O
	
We	O
report	O
our	O
results	O
for	O
each	O
class	O
on	O
VOC	B-Material
2007	I-Material
and	O
2012	B-Material
in	O
Table	O
[	O
reference	O
]	O
,	O
Table	O
[	O
reference	O
]	O
,	O
and	O
Table	O
[	O
reference	O
]	O
.	O
	
Compared	O
with	O
other	O
methods	O
,	O
our	O
method	O
achieves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
using	O
single	O
model	O
,	O
and	O
even	O
outperforms	O
the	O
results	O
by	O
combining	O
multiple	O
different	O
models	O
.	O
	
Specially	O
,	O
our	O
methods	O
achieves	O
much	O
better	O
performance	O
than	O
the	O
method	O
by	O
Bilen	B-Method
and	O
Vedaldi	B-Method
using	O
the	O
same	O
CNN	B-Method
model	O
.	O
	
Notice	O
that	O
not	O
only	O
uses	O
the	O
weighted	B-Method
pooling	I-Method
as	O
we	O
stated	O
in	O
Section	O
[	O
reference	O
]	O
,	O
but	O
also	O
combines	O
the	O
objectness	B-Method
measure	I-Method
of	I-Method
EdgeBoxes	I-Method
and	O
the	O
spatial	B-Method
regulariser	I-Method
,	O
which	O
is	O
much	O
complicated	O
than	O
our	O
basic	O
MIDN	B-Method
.	O
	
We	O
believe	O
that	O
our	O
performance	O
can	O
be	O
improved	O
by	O
choosing	O
better	O
basic	B-Method
detection	I-Method
network	I-Method
,	O
like	O
the	O
complete	B-Method
network	I-Method
in	O
and	O
using	O
the	O
context	O
information	O
.	O
	
As	O
reimplementing	O
their	O
method	O
completely	O
is	O
trivial	O
,	O
here	O
we	O
only	O
choose	O
the	O
simplest	O
architecture	O
in	O
.	O
	
Even	O
in	O
this	O
simplified	O
case	O
,	O
our	O
method	O
can	O
achieve	O
very	O
promising	O
results	O
.	O
	
We	O
also	O
show	O
some	O
visualization	O
comparisons	O
among	O
the	O
WSDDN	B-Method
,	O
the	O
WSDDN	B-Method
+	I-Method
context	I-Method
,	O
and	O
our	O
method	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
of	O
the	O
Supplementary	O
Material	O
.	O
	
Our	O
results	O
can	O
also	O
be	O
improved	O
by	O
combing	O
multiple	B-Method
models	I-Method
.	O
	
As	O
shown	O
in	O
the	O
tables	O
,	O
if	O
we	O
simply	O
sum	O
up	O
the	O
scores	O
produced	O
by	O
the	O
VGG	B-Method
M	I-Method
model	I-Method
and	O
VGG16	B-Method
model	I-Method
	
(	O
OICR	B-Method
-	I-Method
Ens	I-Method
.	O
in	O
tables	O
)	O
,	O
there	O
is	O
little	O
improvement	O
.	O
	
Also	O
,	O
as	O
mentioned	O
in	O
Section	O
[	O
reference	O
]	O
,	O
we	O
train	O
a	O
FRCNN	B-Method
detector	O
using	O
top	O
-	O
scoring	O
proposals	O
produced	O
by	O
OICR	B-Method
-	I-Method
Ens	I-Method
.	O
as	O
ground	O
truths	O
(	O
OICR	B-Method
-	I-Method
Ens.	I-Method
+	O
FRCNN	B-Method
in	O
tables	O
)	O
.	O
	
As	O
we	O
can	O
see	O
,	O
the	O
performance	O
can	O
be	O
improved	O
further	O
.	O
	
Though	O
our	O
method	O
significantly	O
outperforms	O
other	O
methods	O
for	O
some	O
class	O
,	O
like	O
“	O
bicyle	O
”	O
,	O
“	O
bus	O
”	O
,	O
“	O
motorbike	O
”	O
,	O
etc	O
,	O
the	O
performance	O
is	O
poor	O
for	O
classes	O
like	O
“	O
cat	O
”	O
,	O
“	O
dog	O
”	O
,	O
and	O
“	O
person	O
”	O
.	O
	
For	O
analysis	O
,	O
we	O
visualize	O
some	O
success	B-Metric
and	I-Metric
failure	I-Metric
detection	I-Metric
results	O
on	O
VOC	B-Material
2007	I-Material
trainval	O
by	O
OICR	B-Method
-	I-Method
Ens	I-Method
.	O
,	O
as	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
We	O
can	O
observe	O
that	O
,	O
our	O
method	O
is	O
robust	O
to	O
the	O
size	O
and	O
aspect	O
of	O
objects	O
,	O
especially	O
for	O
rigid	O
objects	O
.	O
	
The	O
main	O
failures	O
for	O
these	O
rigid	O
objects	O
are	O
always	O
due	O
to	O
overlarge	O
boxes	O
that	O
not	O
only	O
contain	O
objects	O
,	O
but	O
also	O
include	O
their	O
adjacent	O
similar	O
objects	O
.	O
	
For	O
non	O
-	O
rigid	O
objects	O
like	O
“	O
cat	O
”	O
,	O
“	O
dog	O
”	O
,	O
and	O
“	O
person	O
”	O
,	O
they	O
are	O
always	O
with	O
great	O
deformation	O
,	O
while	O
there	O
is	O
less	O
deformation	O
of	O
their	O
most	O
representative	O
parts	O
(	O
like	O
head	O
)	O
,	O
so	O
our	O
detector	O
is	O
still	O
inclined	O
to	O
find	O
these	O
parts	O
.	O
	
An	O
ideal	O
solution	O
is	O
yet	O
wanted	O
because	O
there	O
is	O
still	O
room	O
for	O
improvement	O
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
paper	O
,	O
we	O
present	O
a	O
novel	O
algorithm	B-Method
framework	I-Method
for	O
weakly	B-Task
supervised	I-Task
object	I-Task
detection	I-Task
.	O
	
Different	O
from	O
traditional	O
approaches	O
in	O
this	O
field	O
,	O
our	O
method	O
integrates	O
a	O
basic	O
multiple	B-Method
instance	I-Method
detection	I-Method
network	I-Method
and	O
multi	O
-	O
stage	O
instance	B-Method
classifiers	I-Method
into	O
a	O
single	O
network	O
.	O
	
Moreover	O
,	O
we	O
propose	O
an	O
online	B-Method
instance	I-Method
classifier	I-Method
refinement	I-Method
algorithm	I-Method
to	O
train	O
the	O
proposed	O
network	O
end	O
-	O
to	O
-	O
end	O
.	O
	
Experiments	O
show	O
substantial	O
and	O
consistent	O
improvements	O
by	O
our	O
method	O
.	O
	
Our	O
learning	B-Method
algorithm	I-Method
is	O
potential	O
to	O
be	O
applied	O
in	O
many	O
other	O
weakly	B-Task
supervised	I-Task
visual	I-Task
learning	I-Task
tasks	I-Task
.	O
	
In	O
the	O
future	O
,	O
we	O
will	O
explore	O
other	O
cues	O
such	O
as	O
instance	O
visual	O
similarity	O
for	O
performing	O
instance	B-Task
classifier	I-Task
refinement	I-Task
better	O
.	O
	
paragraph	O
:	O
Acknowledgements	O
	
This	O
work	O
was	O
partly	O
supported	O
by	O
NSFC	O
	
(	O
No	O
.	O
61503145	O
	
,	O
No	O
.	O
61572207	O
,	O
No	O
.	O
61573160	O
)	O
and	O
the	O
CAST	O
Young	O
Talent	O
Supporting	O
Program	O
.	O
	
bibliography	O
:	O
References	O
	
Supplementary	O
Material	O
	
Here	O
are	O
the	O
supplementary	O
materials	O
for	O
“	O
Multiple	B-Method
Instance	I-Method
Detection	I-Method
Network	I-Method
with	O
Online	B-Method
Instance	I-Method
Classifier	I-Method
Refinement	I-Method
”	O
.	O
	
We	O
provide	O
detailed	O
per	O
-	O
class	O
results	O
on	O
VOC	O
2012	B-Material
,	O
and	O
some	O
visualization	O
comparisons	O
among	O
the	O
WSDDN	B-Method
,	O
the	O
WSDDN	B-Method
+	I-Method
context	I-Method
,	O
and	O
our	O
method	O
(	O
OICR	B-Method
)	O
.	O
	
section	O
:	O
Per	O
-	O
class	O
results	O
on	O
VOC	O
2012	B-Material
	
The	O
detailed	O
per	O
-	O
class	O
results	O
on	O
VOC	O
2012	B-Material
can	O
be	O
viewed	O
in	O
Supplementary	O
Table	O
[	O
reference	O
]	O
and	O
Supplementary	O
Table	O
[	O
reference	O
]	O
.	O
	
Obviously	O
our	O
method	O
outperforms	O
the	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
by	O
a	O
large	O
margin	O
.	O
	
Similar	O
to	O
results	O
on	O
VOC	B-Material
2007	I-Material
,	O
our	O
results	O
are	O
better	O
than	O
for	O
rigid	O
objects	O
such	O
as	O
“	O
bicycle	O
”	O
,	O
“	O
car	O
”	O
,	O
and	O
“	O
motorbike	O
”	O
,	O
but	O
worse	O
than	O
for	O
non	O
-	O
rigid	O
objects	O
	
“	O
cat	O
”	O
,	O
“	O
dog	O
”	O
,	O
and	O
“	O
person	O
”	O
.	O
	
This	O
is	O
because	O
non	O
-	O
rigid	O
objects	O
are	O
always	O
with	O
great	O
deformation	O
.	O
	
Our	O
method	O
tends	O
to	O
detect	O
the	O
most	O
discriminative	O
parts	O
of	O
these	O
objects	O
(	O
like	O
head	O
)	O
.	O
	
The	O
considers	O
more	O
context	O
information	O
thus	O
can	O
deal	O
with	O
these	O
classes	O
better	O
.	O
	
section	O
:	O
Visualization	B-Task
comparisons	O
	
We	O
show	O
some	O
visualization	O
comparisons	O
among	O
the	O
WSDDN	B-Method
,	O
the	O
WSDDN	B-Method
+	I-Method
context	I-Method
,	O
and	O
our	O
method	O
in	O
Supplementary	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
From	O
this	O
visualization	O
and	O
results	O
from	O
tables	O
,	O
we	O
can	O
observe	O
that	O
for	O
classes	O
such	O
as	O
aeroplane	O
,	O
bike	O
,	O
car	O
,	O
,	O
our	O
method	O
tends	O
to	O
provide	O
more	O
accurate	O
detections	O
,	O
whereas	O
other	O
two	O
methods	O
sometimes	O
fails	O
to	O
produce	O
boxes	O
that	O
are	O
overlarge	O
or	O
only	O
	
contain	O
parts	O
of	O
objects	O
(	O
the	O
first	O
four	O
rows	O
in	O
Supplementary	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
But	O
for	O
some	O
classes	O
such	O
as	O
person	O
,	O
our	O
method	O
always	O
fails	O
to	O
detect	O
only	O
parts	O
of	O
objects	O
(	O
the	O
fifth	O
row	O
in	O
Supplementary	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
Because	O
considering	O
context	O
information	O
sometimes	O
help	O
the	O
detection	B-Task
(	O
as	O
in	O
WSDDN	B-Task
+	I-Task
context	I-Task
)	O
,	O
we	O
believe	O
our	O
method	O
can	O
be	O
further	O
improved	O
by	O
incorporating	O
context	O
information	O
into	O
our	O
framework	O
.	O
	
All	O
these	O
three	O
methods	O
(	O
actually	O
almost	O
all	O
weakly	B-Task
supervised	I-Task
object	I-Task
detection	I-Task
methods	O
)	O
suffers	O
from	O
two	O
problems	O
:	O
producing	O
boxes	O
that	O
not	O
only	O
contain	O
the	O
target	O
object	O
but	O
also	O
include	O
their	O
adjacent	O
similar	O
objects	O
,	O
or	O
only	O
detecting	O
parts	O
of	O
object	O
for	O
objects	O
with	O
deformation	O
(	O
the	O
last	O
row	O
in	O
Supplementary	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
An	O
ideal	O
solution	O
for	O
these	O
problems	O
is	O
yet	O
wanted	O
.	O
	
GhostVLAD	B-Method
for	O
set	O
-	O
based	O
face	B-Task
recognition	I-Task
	
section	O
:	O
	
Abstract	O
.	O
	
The	O
objective	O
of	O
this	O
paper	O
is	O
to	O
learn	O
a	O
compact	B-Method
representation	I-Method
of	I-Method
image	I-Method
sets	I-Method
for	O
template	O
-	O
based	O
face	B-Task
recognition	I-Task
.	O
	
We	O
make	O
the	O
following	O
contributions	O
:	O
first	O
,	O
we	O
propose	O
a	O
network	B-Method
architecture	I-Method
which	O
aggregates	O
and	O
embeds	O
the	O
face	O
descriptors	O
produced	O
by	O
deep	B-Method
convolutional	I-Method
neural	I-Method
networks	I-Method
into	O
a	O
compact	O
fixed	B-Method
-	I-Method
length	I-Method
representation	I-Method
.	O
	
This	O
compact	B-Method
representation	I-Method
requires	O
minimal	O
memory	O
storage	O
and	O
enables	O
efficient	O
similarity	B-Task
computation	I-Task
.	O
	
Second	O
,	O
we	O
propose	O
a	O
novel	O
GhostVLAD	B-Method
layer	O
that	O
includes	O
ghost	O
clusters	O
,	O
that	O
do	O
not	O
contribute	O
to	O
the	O
aggregation	B-Task
.	O
	
We	O
show	O
that	O
a	O
quality	O
weighting	O
on	O
the	O
input	O
faces	O
emerges	O
automatically	O
such	O
that	O
informative	O
images	O
contribute	O
more	O
than	O
those	O
with	O
low	O
quality	O
,	O
and	O
that	O
the	O
ghost	O
clusters	O
enhance	O
the	O
network	O
's	O
ability	O
to	O
deal	O
with	O
poor	O
quality	O
images	O
.	O
	
Third	O
,	O
we	O
explore	O
how	O
input	O
feature	O
dimension	O
,	O
number	O
of	O
clusters	O
and	O
different	O
training	B-Method
techniques	I-Method
affect	O
the	O
recognition	B-Task
performance	O
.	O
	
Given	O
this	O
analysis	O
,	O
we	O
train	O
a	O
network	O
that	O
far	O
exceeds	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
on	O
the	O
IJB	B-Material
-	I-Material
B	I-Material
face	I-Material
recognition	I-Material
dataset	I-Material
.	O
	
This	O
is	O
currently	O
one	O
of	O
the	O
most	O
challenging	O
public	O
benchmarks	O
,	O
and	O
we	O
surpass	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
on	O
both	O
the	O
identification	O
and	O
verification	B-Task
protocols	O
.	O
	
section	O
:	O
Introduction	O
	
While	O
most	O
research	O
on	O
face	B-Task
recognition	I-Task
has	O
focused	O
on	O
recognition	B-Task
from	O
a	O
singleimage	O
,	O
template	O
based	O
face	B-Task
recognition	I-Task
,	O
where	O
a	O
set	O
of	O
faces	O
of	O
the	O
same	O
subject	O
is	O
available	O
,	O
is	O
now	O
gaining	O
attention	O
.	O
	
In	O
the	O
unconstrained	B-Task
scenario	I-Task
considered	O
here	O
,	O
this	O
can	O
be	O
a	O
challenging	O
task	O
as	O
face	O
images	O
may	O
have	O
various	O
poses	O
,	O
expression	O
,	O
illumination	O
,	O
and	O
may	O
also	O
be	O
of	O
quite	O
varying	O
quality	O
.	O
	
A	O
straightforward	O
method	O
to	O
tackle	O
multiple	O
images	O
per	O
subject	O
is	O
to	O
store	O
per	O
-	O
image	O
descriptors	O
extracted	O
from	O
each	O
face	O
image	O
(	O
or	O
frame	O
in	O
a	O
video	O
)	O
,	O
and	O
compare	O
every	O
pair	O
of	O
images	O
between	O
sets	O
at	O
query	O
time	O
	
[	O
reference	O
][	O
reference	O
]	O
.	O
	
However	O
,	O
this	O
type	O
of	O
approach	O
can	O
be	O
memory	O
-	O
consuming	O
and	O
prohibitively	O
slow	O
,	O
especially	O
for	O
searching	B-Task
tasks	I-Task
in	O
large	O
-	O
scale	O
datasets	O
.	O
	
Therefore	O
,	O
an	O
aggregation	B-Method
method	I-Method
that	O
can	O
produce	O
a	O
compact	O
template	B-Method
representation	I-Method
is	O
desired	O
.	O
	
Furthermore	O
,	O
this	O
representation	O
should	O
support	O
efficient	O
computation	B-Task
of	I-Task
similarity	I-Task
and	O
require	O
minimal	O
memory	O
storage	O
.	O
	
More	O
importantly	O
,	O
the	O
representation	O
obtained	O
from	O
image	O
sets	O
should	O
be	O
discriminative	O
i.e.	O
template	O
descriptors	O
of	O
the	O
same	O
subject	O
should	O
be	O
close	O
to	O
each	O
other	O
in	O
the	O
descriptor	O
space	O
,	O
whereas	O
those	O
of	O
different	O
subjects	O
should	O
be	O
far	O
apart	O
.	O
	
Although	O
common	O
aggregation	B-Method
strategies	I-Method
,	O
such	O
as	O
average	B-Method
pooling	I-Method
and	O
max	B-Method
-	I-Method
pooling	I-Method
,	O
are	O
able	O
to	O
aggregate	O
face	O
descriptors	O
to	O
produce	O
a	O
compact	O
template	B-Method
representation	I-Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
and	O
currently	O
achieves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
[	O
reference	O
]	O
,	O
we	O
seek	O
a	O
better	O
solution	O
in	O
this	O
paper	O
.	O
	
As	O
revealed	O
by	O
[	O
reference	O
]	O
,	O
image	B-Method
retrieval	I-Method
encoding	I-Method
methods	I-Method
like	O
Fisher	B-Method
Vector	I-Method
encoding	I-Method
and	O
T	B-Method
-	I-Method
embedding	I-Method
increase	O
the	O
separation	O
between	O
descriptors	O
extracted	O
from	O
related	O
and	O
unrelated	O
image	O
patches	O
.	O
	
We	O
therefore	O
expect	O
a	O
similar	O
encoding	O
to	O
be	O
beneficial	O
for	O
face	B-Task
recognition	I-Task
,	O
including	O
both	O
verification	B-Task
and	O
identification	B-Task
tasks	I-Task
.	O
	
This	O
insight	O
inspires	O
us	O
to	O
include	O
a	O
similar	O
encoding	O
,	O
NetVLAD	B-Method
[	O
reference	O
]	O
,	O
in	O
the	O
design	O
of	O
our	O
network	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
convolutional	B-Method
neural	I-Method
network	I-Method
(	O
Fig	O
.	O
1	O
)	O
that	O
satisfies	O
all	O
the	O
desired	O
properties	O
mentioned	O
above	O
:	O
it	O
can	O
take	O
any	O
number	O
of	O
input	O
faces	O
and	O
produce	O
a	O
compact	O
fixed	B-Method
-	I-Method
length	I-Method
descriptor	I-Method
to	O
represent	O
the	O
image	O
set	O
.	O
	
Moreover	O
,	O
this	O
network	O
embeds	O
face	O
descriptors	O
such	O
that	O
the	O
resultant	O
template	O
-	O
descriptors	O
are	O
more	O
discriminative	O
than	O
the	O
original	O
descriptors	O
.	O
	
The	O
representation	O
is	O
efficient	O
in	O
both	O
memory	B-Metric
and	I-Metric
query	I-Metric
speed	I-Metric
aspects	I-Metric
,	O
i.e.	O
it	O
only	O
stores	O
one	O
compact	B-Method
descriptor	I-Method
per	O
template	O
,	O
regardless	O
of	O
the	O
number	O
of	O
face	O
images	O
in	O
a	O
template	O
,	O
and	O
the	O
similarity	O
between	O
two	O
templates	O
is	O
simply	O
measured	O
as	O
the	O
scalar	O
product	O
(	O
i.e.	O
cosine	O
similarity	O
)	O
of	O
two	O
template	B-Method
descriptors	I-Method
.	O
	
However	O
,	O
one	O
of	O
the	O
key	O
problems	O
in	O
unconstrained	B-Task
real	I-Task
-	I-Task
world	I-Task
situations	I-Task
is	O
that	O
some	O
faces	O
in	O
a	O
template	O
may	O
be	O
of	O
low	O
quality	O
-	O
for	O
example	O
,	O
low	O
resolution	O
,	O
or	O
blurred	O
,	O
or	O
partially	O
occluded	O
.	O
	
These	O
low	O
-	O
quality	O
images	O
are	O
distractors	O
and	O
are	O
likely	O
to	O
hurt	O
the	O
performance	O
of	O
the	O
face	B-Task
recognition	I-Task
system	O
if	O
given	O
equal	O
weight	O
as	O
the	O
other	O
(	O
good	O
quality	O
)	O
faces	O
.	O
	
Therefore	O
,	O
a	O
sophisticated	O
network	O
should	O
be	O
able	O
to	O
reduce	O
the	O
impact	O
of	O
such	O
distracting	O
images	O
and	O
focus	O
on	O
the	O
informative	O
ones	O
.	O
	
To	O
this	O
end	O
,	O
we	O
extend	O
the	O
NetVLAD	B-Method
architecture	I-Method
to	O
include	O
ghost	O
clusters	O
.	O
	
These	O
are	O
clusters	O
that	O
face	O
descriptors	O
can	O
be	O
soft	O
assigned	O
to	O
,	O
but	O
are	O
excluded	O
from	O
the	O
aggregation	B-Task
.	O
	
They	O
provide	O
a	O
mechanism	O
for	O
the	O
network	O
to	O
handle	O
low	O
quality	O
faces	O
,	O
by	O
mainly	O
assigning	O
them	O
to	O
the	O
ghost	O
clusters	O
.	O
	
Interestingly	O
,	O
although	O
we	O
do	O
not	O
explicitly	O
learn	O
any	O
importance	O
weightings	O
between	O
faces	O
in	O
each	O
template	O
,	O
such	O
property	O
emerges	O
automatically	O
from	O
our	O
network	O
.	O
	
Specifically	O
,	O
low	O
quality	O
faces	O
generally	O
contribute	O
less	O
to	O
the	O
final	O
template	B-Method
representation	I-Method
than	O
the	O
high	O
-	O
quality	O
ones	O
.	O
	
The	O
networks	O
are	O
trained	O
in	O
an	O
end	O
-	O
to	O
-	O
end	O
fashion	O
with	O
only	O
identity	O
-	O
level	O
labels	O
.	O
	
They	O
outperform	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
by	O
a	O
large	O
margin	O
on	O
the	O
public	B-Material
IJB	I-Material
-	I-Material
A	I-Material
[	O
reference	O
]	O
and	O
IJB	B-Material
-	I-Material
B	I-Material
[	O
reference	O
]	O
face	B-Task
recognition	I-Task
benchmarks	O
.	O
	
These	O
datasets	O
are	O
currently	O
the	O
most	O
challenging	O
in	O
the	O
community	O
,	O
and	O
we	O
evaluate	O
on	O
these	O
in	O
this	O
paper	O
.	O
	
This	O
paper	O
is	O
organized	O
as	O
following	O
:	O
Sec	O
.	O
2	O
reviews	O
some	O
related	O
work	O
on	O
face	B-Task
recognition	I-Task
based	O
on	O
image	O
sets	O
or	O
videos	O
;	O
the	O
proposed	O
network	O
and	O
implementation	O
details	O
are	O
introduced	O
in	O
Sec	O
.	O
	
3	O
,	O
	
followed	O
by	O
experimental	O
results	O
reported	O
in	O
Sec	O
.	O
4	O
.	O
	
Finally	O
a	O
conclusion	O
is	O
drawn	O
in	O
Sec	O
.	O
5	O
.	O
	
section	O
:	O
Related	O
work	O
	
Early	O
face	B-Task
recognition	I-Task
approaches	O
which	O
make	O
use	O
of	O
sets	O
of	O
face	O
examples	O
(	O
extracted	O
from	O
different	O
images	O
or	O
video	O
frames	O
)	O
aim	O
to	O
represent	O
image	O
sets	O
as	O
manifolds	O
	
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
,	O
convex	O
hulls	O
[	O
reference	O
]	O
,	O
Gaussian	B-Method
Mixture	I-Method
Models	I-Method
[	O
reference	O
]	O
,	O
or	O
set	O
covariance	O
matrices	O
[	O
reference	O
]	O
,	O
and	O
measure	O
the	O
dissimilarity	O
between	O
image	O
sets	O
as	O
distance	O
between	O
these	O
spaces	O
.	O
	
Later	O
methods	O
represent	O
face	O
sets	O
more	O
efficiently	O
using	O
a	O
single	O
fixed	B-Method
-	I-Method
length	I-Method
descriptor	I-Method
.	O
	
For	O
example	O
,	O
[	O
reference	O
]	O
aggregates	O
local	O
descriptors	O
(	O
RootSIFT	O
[	O
reference	O
]	O
)	O
extracted	O
from	O
face	O
crops	O
using	O
Fisher	B-Method
Vector	I-Method
[	O
reference	O
]	O
(	O
FV	B-Method
)	I-Method
encoding	I-Method
to	O
obtain	O
a	O
single	O
descriptor	O
per	O
face	B-Task
track	I-Task
.	O
	
Since	O
the	O
success	O
of	O
deep	B-Method
learning	I-Method
in	O
image	O
-	O
based	O
face	B-Task
recognition	I-Task
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
,	O
simple	O
strategies	O
for	O
face	B-Task
descriptor	I-Task
aggregation	I-Task
prevailed	O
,	O
such	O
as	O
average	B-Method
-	I-Method
and	I-Method
max	I-Method
-	I-Method
pooling	I-Method
	
[	O
reference	O
][	O
reference	O
]	O
.	O
	
However	O
,	O
none	O
of	O
these	O
strategies	O
are	O
trained	O
end	O
-	O
to	O
-	O
end	O
for	O
face	B-Task
recognition	I-Task
as	O
typically	O
only	O
the	O
face	O
descriptors	O
are	O
learnt	O
,	O
while	O
aggregation	B-Task
is	O
performed	O
post	O
hoc	O
.	O
	
A	O
few	O
methods	O
go	O
beyond	O
simple	O
pooling	B-Method
by	O
computing	O
a	O
weighted	B-Method
average	I-Method
of	I-Method
face	I-Method
descriptors	I-Method
based	O
on	O
some	O
measure	O
of	O
per	B-Metric
-	I-Metric
face	I-Metric
example	I-Metric
importance	I-Metric
.	O
	
For	O
example	O
,	O
[	O
reference	O
]	O
train	O
a	O
module	O
to	O
predict	O
human	O
judgement	O
on	O
how	O
memorable	O
a	O
face	O
is	O
,	O
and	O
use	O
this	O
memorability	O
score	O
as	O
the	O
weight	O
.	O
	
In	O
[	O
reference	O
]	O
,	O
an	O
attention	B-Method
mechanism	I-Method
is	O
used	O
to	O
compute	O
face	O
example	O
weights	O
,	O
so	O
that	O
the	O
contribution	O
of	O
low	O
quality	O
images	O
to	O
the	O
final	O
set	B-Method
representation	I-Method
is	O
down	O
-	O
weighted	O
.	O
	
However	O
,	O
these	O
methods	O
rely	O
on	O
pretrained	O
face	O
descriptors	O
and	O
do	O
not	O
learn	O
them	O
jointly	O
with	O
the	O
weighting	B-Method
functions	I-Method
,	O
unlike	O
our	O
method	O
where	O
the	O
entire	O
system	O
is	O
trained	O
end	O
-	O
to	O
-	O
end	O
for	O
face	B-Task
recognition	I-Task
.	O
	
Two	O
other	O
recent	O
papers	O
are	O
quite	O
related	O
in	O
that	O
they	O
explicitly	O
take	O
account	O
of	O
image	B-Metric
quality	I-Metric
:	O
[	O
reference	O
]	O
first	O
bins	O
face	O
images	O
of	O
similar	O
quality	O
and	O
pose	O
before	O
aggregation	B-Task
;	O
whilst	O
[	O
reference	O
]	O
introduces	O
a	O
fully	O
end	O
-	O
to	O
-	O
end	B-Method
trainable	I-Method
method	I-Method
which	O
automatically	O
learns	O
to	O
down	O
-	O
weight	O
low	O
quality	O
images	O
.	O
	
As	O
will	O
be	O
seen	O
in	O
the	O
sequel	O
,	O
we	O
achieve	O
similar	O
functionality	O
implicitly	O
due	O
to	O
the	O
network	B-Method
architecture	I-Method
,	O
and	O
also	O
exceed	O
the	O
performance	O
of	O
both	O
these	O
methods	O
(	O
see	O
Sec	O
.	O
	
4.4	O
)	O
.	O
	
As	O
an	O
interesting	O
yet	O
different	O
method	O
which	O
can	O
also	O
filter	O
low	O
-	O
quality	O
images	O
,	O
[	O
reference	O
]	O
learns	O
to	O
aggregate	O
the	O
raw	O
face	O
images	O
and	O
then	O
computes	O
a	O
descriptor	B-Method
.	O
	
Our	O
aggregation	B-Method
approach	I-Method
is	O
inspired	O
by	O
the	O
image	B-Task
retrieval	I-Task
literature	I-Task
on	O
aggregating	B-Task
local	I-Task
descriptors	I-Task
[	O
reference	O
][	O
reference	O
]	O
.	O
Namely	O
,	O
Jégou	O
and	O
Zisserman	O
[	O
reference	O
]	O
find	O
that	O
,	O
compared	O
to	O
simple	O
average	B-Method
-	I-Method
pooling	I-Method
,	O
Fisher	B-Method
Vector	I-Method
encoding	I-Method
and	O
T	B-Method
-	I-Method
embedding	I-Method
increase	O
the	O
contrast	O
between	O
the	O
similarity	O
scores	O
of	O
matching	O
and	O
mismatching	O
local	O
descriptors	O
.	O
	
Motivated	O
by	O
this	O
fact	O
,	O
we	O
make	O
use	O
of	O
a	O
trainable	B-Method
aggregation	I-Method
layer	I-Method
,	O
NetVLAD	B-Method
[	O
reference	O
]	O
,	O
and	O
improve	O
it	O
for	O
the	O
face	B-Task
recognition	I-Task
task	O
.	O
	
section	O
:	O
Set	O
-	O
based	O
face	B-Task
recognition	I-Task
	
We	O
aim	O
to	O
learn	O
a	O
compact	B-Method
representation	I-Method
of	I-Method
a	I-Method
face	I-Method
.	O
	
Namely	O
,	O
we	O
train	O
a	O
network	O
which	O
digests	O
a	O
set	O
of	O
example	O
face	O
images	O
of	O
a	O
person	O
,	O
and	O
produces	O
a	O
fixedlength	B-Method
template	I-Method
representation	I-Method
useful	O
for	O
face	B-Task
recognition	I-Task
.	O
	
The	O
network	O
should	O
satisfy	O
the	O
following	O
properties	O
:	O
	
.	O
.	O
.	O
.	O
.	O
.	O
	
Fig	O
.	O
	
1	O
:	O
	
Network	B-Method
architecture	I-Method
.	O
	
Input	O
images	O
in	O
each	O
template	O
are	O
first	O
passed	O
through	O
a	O
convolutional	B-Method
neural	I-Method
network	I-Method
(	O
e.g.	O
ResNet	B-Method
-	I-Method
50	I-Method
or	O
SENet	B-Method
-	I-Method
50	I-Method
with	O
an	O
additional	O
FC	B-Method
layer	I-Method
and	O
L2	B-Method
-	I-Method
normalization	I-Method
)	O
to	O
produce	O
a	O
face	B-Method
descriptor	I-Method
per	O
image	O
.	O
	
The	O
descriptors	O
are	O
aggregated	O
into	O
a	O
single	O
fixed	O
-	O
length	O
vector	O
using	O
the	O
GhostVLAD	B-Method
layer	O
.	O
	
The	O
final	O
D	B-Method
-	I-Method
dimensional	I-Method
template	I-Method
descriptor	I-Method
is	O
obtained	O
by	O
reducing	O
dimensionality	O
using	O
a	O
fully	B-Method
-	I-Method
connected	I-Method
layer	I-Method
,	O
followed	O
by	O
batch	B-Method
normalization	I-Method
(	O
BN	B-Method
)	O
and	O
L2	B-Method
-	I-Method
normalization	I-Method
.	O
	
(	O
1	O
)	O
Take	O
any	O
number	O
of	O
images	O
as	O
input	O
,	O
and	O
output	O
a	O
fixed	B-Method
-	I-Method
length	I-Method
template	I-Method
descriptor	I-Method
to	O
represent	O
the	O
input	O
image	O
set	O
.	O
	
(	O
2	O
)	O
	
The	O
output	O
template	B-Method
descriptor	I-Method
should	O
be	O
compact	O
(	O
i.e.	O
low	O
-	O
dimensional	O
)	O
in	O
order	O
to	O
require	O
little	O
memory	O
and	O
facilitate	O
fast	O
template	O
comparisons	O
.	O
	
(	O
3	O
)	O
	
The	O
output	O
template	B-Method
descriptor	I-Method
should	O
be	O
discriminative	O
,	O
such	O
that	O
the	O
similarity	O
of	O
templates	O
of	O
the	O
same	O
subject	O
is	O
much	O
larger	O
than	O
that	O
of	O
different	O
subjects	O
.	O
	
We	O
propose	O
a	O
convolutional	B-Method
neural	I-Method
network	I-Method
that	O
fulfils	O
all	O
three	O
objectives	O
.	O
	
(	O
1	O
)	O
is	O
achieved	O
by	O
aggregating	B-Method
face	I-Method
descriptors	I-Method
using	O
a	O
modified	O
NetVLAD	B-Method
[	I-Method
reference	I-Method
]	I-Method
layer	I-Method
,	O
GhostVLAD	B-Method
.	O
	
Compact	B-Method
template	I-Method
descriptors	I-Method
(	O
2	O
)	O
are	O
produced	O
by	O
a	O
trained	B-Method
layer	I-Method
which	O
performs	O
dimensionality	B-Task
reduction	I-Task
.	O
	
Discriminative	B-Method
representations	I-Method
(	O
3	O
)	O
emerge	O
because	O
the	O
entire	O
network	O
is	O
trained	O
end	O
-	O
to	O
-	O
end	O
for	O
face	B-Task
recognition	I-Task
,	O
and	O
since	O
our	O
GhostVLAD	B-Method
layer	O
is	O
able	O
to	O
down	O
-	O
weight	O
the	O
contribution	O
of	O
lowquality	O
images	O
,	O
which	O
is	O
important	O
for	O
good	O
performance	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
	
The	O
network	B-Method
architecture	I-Method
and	O
the	O
new	O
GhostVLAD	B-Method
layer	O
are	O
described	O
in	O
Sec	O
.	O
	
3.1	O
and	O
Sec	O
.	O
	
3.2	O
,	O
respectively	O
,	O
followed	O
by	O
the	O
network	B-Method
training	I-Method
procedure	I-Method
(	O
Sec	O
.	O
3.3	O
)	O
and	O
implementation	O
details	O
(	O
Sec	O
.	O
3.4	O
)	O
.	O
	
section	O
:	O
Network	B-Method
architecture	I-Method
	
As	O
shown	O
in	O
Fig	O
.	O
1	O
,	O
the	O
network	O
consists	O
of	O
two	O
parts	O
:	O
feature	B-Method
extraction	I-Method
,	O
which	O
computes	O
a	O
face	B-Method
descriptor	I-Method
for	O
each	O
input	O
face	O
image	O
,	O
and	O
aggregation	B-Method
,	O
which	O
aggregates	O
all	O
face	B-Method
descriptors	I-Method
into	O
a	O
single	O
compact	B-Method
template	I-Method
representation	I-Method
of	O
the	O
input	O
image	O
set	O
.	O
	
Feature	B-Task
extraction	I-Task
.	O
	
A	O
neural	B-Method
network	I-Method
is	O
used	O
to	O
extract	O
a	O
face	B-Method
descriptor	I-Method
for	O
each	O
input	O
face	O
image	O
.	O
	
Any	O
network	O
can	O
be	O
used	O
in	O
our	O
learning	B-Method
framework	I-Method
,	O
but	O
in	O
this	O
paper	O
we	O
opt	O
for	O
ResNet	O
-	O
50	O
	
[	O
reference	O
]	O
or	O
SENet	O
-	O
50	O
	
[	O
reference	O
]	O
.	O
Both	O
networks	O
are	O
cropped	O
after	O
the	O
global	B-Method
average	I-Method
pooling	I-Method
layer	I-Method
,	O
and	O
an	O
extra	O
FC	B-Method
layer	I-Method
is	O
added	O
to	O
reduce	O
the	O
output	O
dimension	O
to	O
D	O
F	O
.	O
	
We	O
typically	O
pick	O
D	O
F	O
to	O
be	O
low	O
-	O
dimensional	O
(	O
e.g.	O
128	O
or	O
256	O
)	O
,	O
and	O
do	O
not	O
see	O
a	O
significant	O
drop	O
in	O
face	B-Task
recognition	I-Task
performance	O
compared	O
to	O
using	O
the	O
original	O
2048	B-Method
-	I-Method
D	I-Method
descriptors	I-Method
.	O
	
Finally	O
,	O
the	O
individual	O
face	B-Method
descriptors	I-Method
are	O
L2	B-Method
normalized	I-Method
.	O
	
Aggregation	B-Task
.	O
	
The	O
second	O
part	O
uses	O
GhostVLAD	B-Method
(	O
Sec	O
.	O
3.2	O
)	O
to	O
aggregate	O
multiple	O
face	O
descriptors	O
into	O
a	O
single	O
D	O
F	O
×	O
K	O
vector	O
(	O
where	O
K	O
is	O
a	O
parameter	O
of	O
the	O
method	O
)	O
.	O
	
To	O
keep	O
computational	O
and	O
memory	O
requirements	O
low	O
,	O
dimensionality	B-Task
reduction	I-Task
is	O
performed	O
via	O
an	O
FC	B-Method
layer	I-Method
,	O
where	O
we	O
pick	O
the	O
output	O
dimensionality	O
D	O
to	O
be	O
128	O
.	O
	
The	O
compact	O
D	B-Method
-	I-Method
dimensional	I-Method
descriptor	I-Method
is	O
then	O
passed	O
to	O
a	O
batch	B-Method
-	I-Method
normalization	I-Method
layer	I-Method
[	O
reference	O
]	O
and	O
L2	O
-	O
normalized	O
to	O
form	O
the	O
final	O
template	B-Method
representation	I-Method
x	I-Method
template	I-Method
.	O
	
section	O
:	O
GhostVLAD	B-Method
:	O
NetVLAD	B-Method
with	O
ghost	B-Method
clusters	I-Method
	
The	O
key	O
component	O
of	O
the	O
aggregation	B-Method
block	I-Method
is	O
our	O
GhostVLAD	B-Method
trainable	I-Method
aggregation	I-Method
layer	I-Method
,	O
which	O
given	O
N	O
D	O
F	O
-	O
dimensional	O
face	O
descriptors	O
computes	O
a	O
single	O
	
It	O
is	O
based	O
on	O
the	O
NetVLAD	B-Method
[	I-Method
reference	I-Method
]	I-Method
layer	I-Method
which	O
implements	O
an	O
encoding	O
similar	O
to	O
VLAD	B-Method
encoding	I-Method
[	O
reference	O
]	O
,	O
while	O
being	O
differentiable	O
and	O
thus	O
fully	O
-	O
trainable	O
.	O
	
NetVLAD	B-Method
has	O
been	O
shown	O
to	O
outperform	O
average	B-Method
and	I-Method
max	I-Method
pooling	I-Method
for	O
the	O
same	O
vector	O
dimensionality	O
,	O
which	O
makes	O
it	O
perfectly	O
suited	O
for	O
our	O
task	O
.	O
	
Here	O
we	O
provide	O
a	O
brief	O
overview	O
of	O
NetVLAD	B-Method
(	O
for	O
full	O
details	O
please	O
refer	O
to	O
[	O
reference	O
]	O
)	O
,	O
followed	O
by	O
our	O
improvement	O
,	O
GhostVLAD	B-Method
.	O
	
NetVLAD	B-Method
.	O
	
For	O
N	O
D	O
F	O
-	O
dimensional	O
input	O
descriptors	O
{	O
x	O
i	O
}	O
and	O
a	O
chosen	O
number	O
of	O
clusters	O
K	O
,	O
NetVLAD	B-Method
pooling	I-Method
produces	O
a	O
single	O
D	O
F	O
×	O
K	O
vector	O
V	O
(	O
for	O
convenience	O
written	O
as	O
a	O
D	O
F	O
×	O
K	O
matrix	O
)	O
according	O
to	O
the	O
following	O
equation	O
:	O
	
where	O
{	O
a	O
k	O
}	O
,	O
{	O
b	O
k	O
}	O
and	O
{	O
c	O
k	O
}	O
are	O
trainable	O
parameters	O
,	O
with	O
k	O
∈	O
[	O
1	O
,	O
2	O
,	O
.	O
.	O
	
.	O
	
,	O
	
K	O
]	O
.	O
	
The	O
first	O
term	O
corresponds	O
to	O
the	O
soft	O
-	O
assignment	O
weight	O
of	O
the	O
input	O
vector	O
x	O
i	O
for	O
cluster	O
k	O
,	O
while	O
the	O
second	O
term	O
computes	O
the	O
residual	O
between	O
the	O
vector	O
and	O
the	O
cluster	O
centre	O
.	O
	
The	O
final	O
output	O
is	O
obtained	O
by	O
performing	O
L2	B-Method
normalization	I-Method
.	O
	
GhostVLAD	B-Method
.	O
	
We	O
extend	O
NetVLAD	B-Method
with	O
"	O
ghost	O
"	O
clusters	O
to	O
form	O
GhostVLAD	B-Method
,	O
as	O
shown	O
in	O
Fig	O
.	O
2	O
.	O
	
Namely	O
,	O
we	O
add	O
further	O
G	O
"	O
ghost	O
"	O
clusters	O
which	O
contribute	O
to	O
the	O
soft	O
assignments	O
in	O
the	O
same	O
manner	O
as	O
the	O
original	O
K	O
clusters	O
,	O
but	O
residuals	O
between	O
input	O
vectors	O
and	O
the	O
ghost	O
cluster	O
centres	O
are	O
ignored	O
and	O
do	O
not	O
contribute	O
to	O
the	O
final	O
output	O
.	O
	
In	O
other	O
words	O
,	O
the	O
summation	O
in	O
the	O
denominator	O
of	O
eq	O
.	O
	
1	O
instead	O
of	O
to	O
K	O
goes	O
to	O
K	O
+	O
G	O
,	O
while	O
the	O
output	O
is	O
still	O
D	O
F	O
×	O
	
K	O
dimensional	O
	
;	O
this	O
means	O
{	O
a	O
k	O
}	O
and	O
{	O
b	O
k	O
}	O
have	O
K	O
+	O
G	O
elements	O
each	O
,	O
while	O
{	O
c	O
k	O
}	O
still	O
has	O
	
K.	O
Another	O
view	O
is	O
that	O
we	O
are	O
computing	O
NetVLAD	B-Method
with	O
K	O
+	O
G	O
clusters	O
,	O
followed	O
by	O
removing	O
the	O
elements	O
that	O
correspond	O
to	O
the	O
G	O
ghost	O
clusters	O
.	O
	
Note	O
that	O
GhostVLAD	B-Method
is	O
a	O
generalization	B-Method
of	I-Method
NetVLAD	I-Method
as	O
with	O
G	O
=	O
0	O
	
the	O
two	O
are	O
equivalent	O
.	O
	
As	O
with	O
NetVLAD	B-Method
,	O
GhostVLAD	B-Method
can	O
be	O
implemented	O
efficiently	O
using	O
For	O
each	O
input	O
descriptor	O
,	O
NetVLAD	B-Method
performs	O
softassignment	O
into	O
K	O
cluster	O
centres	O
,	O
computed	O
as	O
a	O
linear	B-Method
transformation	I-Method
followed	O
by	O
a	O
soft	B-Method
-	I-Method
max	I-Method
.	O
	
It	O
then	O
,	O
for	O
each	O
cluster	O
centre	O
,	O
aggregates	O
all	O
residuals	O
between	O
input	O
descriptors	O
and	O
the	O
cluster	O
centre	O
,	O
weighted	O
with	O
the	O
soft	O
-	O
assignment	O
values	O
.	O
	
The	O
final	O
vector	O
is	O
produced	O
as	O
a	O
concatenation	O
of	O
the	O
per	B-Method
-	I-Method
cluster	I-Method
aggregated	I-Method
residuals	I-Method
;	O
for	O
more	O
details	O
see	O
eq	O
.	O
1	O
and	O
[	O
reference	O
]	O
.	O
We	O
introduce	O
G	O
"	O
ghost	O
"	O
clusters	O
in	O
the	O
soft	B-Task
-	I-Task
assignment	I-Task
stage	I-Task
,	O
where	O
the	O
"	O
ghost	O
"	O
assignment	O
weight	O
is	O
illustrated	O
with	O
a	O
dotted	O
red	O
bar	O
(	O
here	O
we	O
show	O
only	O
G	O
=	O
1	O
ghost	O
cluster	O
)	O
.	O
	
The	O
ghost	O
assignments	O
are	O
then	O
eliminated	O
and	O
residual	B-Task
aggregation	I-Task
proceeds	O
as	O
with	O
NetVLAD	B-Method
.	O
	
This	O
mechanism	O
enables	O
the	O
network	O
to	O
assign	O
uninformative	O
descriptors	O
to	O
ghost	O
clusters	O
thus	O
decreasing	O
their	O
soft	O
-	O
assignment	O
weights	O
for	O
non	O
-	O
ghost	O
clusters	O
,	O
and	O
therefore	O
reducing	O
their	O
contribution	O
to	O
the	O
final	O
template	B-Method
representation	I-Method
.	O
	
standard	O
convolutional	B-Method
neural	I-Method
network	I-Method
building	I-Method
blocks	I-Method
,	O
e.g.	O
the	O
soft	B-Task
-	I-Task
assignment	I-Task
can	O
be	O
done	O
by	O
stacking	O
input	O
descriptors	O
and	O
applying	O
a	O
convolution	B-Method
operation	I-Method
,	O
followed	O
by	O
a	O
convolutional	B-Method
soft	I-Method
-	I-Method
max	I-Method
;	O
for	O
details	O
see	O
[	O
reference	O
]	O
.	O
	
The	O
intuition	O
behind	O
the	O
incorporation	O
of	O
ghost	O
clusters	O
is	O
to	O
make	O
it	O
easier	O
for	O
the	O
network	O
to	O
adjust	O
the	O
contribution	O
of	O
each	O
face	O
example	O
to	O
the	O
template	B-Method
representation	I-Method
by	O
assigning	O
examples	O
to	O
be	O
ignored	O
to	O
the	O
ghost	O
clusters	O
.	O
	
For	O
example	O
,	O
in	O
an	O
ideal	O
case	O
,	O
a	O
highly	O
blurry	O
face	O
image	O
would	O
be	O
strongly	O
assigned	O
to	O
a	O
ghost	O
cluster	O
,	O
making	O
the	O
assignment	O
weights	O
to	O
non	O
-	O
ghost	O
clusters	O
close	O
to	O
zero	O
,	O
thus	O
causing	O
its	O
contribution	O
to	O
the	O
template	B-Method
representation	I-Method
to	O
be	O
negligible	O
;	O
in	O
Sec	O
.	O
	
4.5	O
we	O
qualitatively	O
validate	O
this	O
intuition	O
.	O
	
However	O
,	O
note	O
that	O
we	O
do	O
not	O
explicitly	O
force	O
low	O
-	O
quality	O
images	O
to	O
get	O
assigned	O
to	O
ghost	O
clusters	O
,	O
but	O
instead	O
let	O
the	O
network	O
discover	O
the	O
optimal	O
behaviour	O
through	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
training	I-Task
for	O
face	B-Task
recognition	I-Task
.	O
	
section	O
:	O
Network	B-Method
training	I-Method
	
In	O
this	O
section	O
we	O
describe	O
how	O
to	O
train	O
the	O
network	O
for	O
face	B-Task
recognition	I-Task
,	O
but	O
note	O
that	O
GhostVLAD	B-Method
is	O
a	O
general	O
layer	O
which	O
can	O
also	O
be	O
used	O
for	O
other	O
tasks	O
.	O
	
Training	B-Metric
loss	I-Metric
.	O
	
Just	O
for	O
training	O
purposes	O
,	O
we	O
append	O
the	O
network	O
with	O
a	O
fullyconnected	B-Method
"	I-Method
classification	I-Method
"	I-Method
layer	I-Method
of	O
size	O
D	O
×T	O
,	O
where	O
D	O
is	O
the	O
size	O
of	O
the	O
template	B-Method
representation	I-Method
and	O
	
T	O
is	O
the	O
number	O
of	O
identities	O
available	O
in	O
the	O
training	O
set	O
.	O
	
We	O
use	O
the	O
one	B-Method
-	I-Method
versus	I-Method
-	I-Method
all	I-Method
logistic	I-Method
regression	I-Method
loss	I-Method
as	O
empirically	O
we	O
found	O
that	O
it	O
converges	O
faster	O
and	O
outperforms	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
loss	I-Metric
.	O
	
The	O
classification	B-Method
layer	I-Method
is	O
discarded	O
after	O
training	O
and	O
the	O
trained	B-Method
network	I-Method
is	O
used	O
to	O
extract	O
a	O
single	O
fixed	B-Method
-	I-Method
length	I-Method
template	I-Method
representation	I-Method
for	O
the	O
input	O
face	O
images	O
.	O
	
Training	O
with	O
degraded	O
images	O
.	O
	
For	O
unconstrained	O
face	B-Task
recognition	I-Task
,	O
it	O
is	O
important	O
to	O
be	O
able	O
to	O
handle	O
images	O
of	O
varying	O
quality	O
that	O
typically	O
occur	O
in	O
the	O
wild	O
.	O
	
The	O
motivation	O
behind	O
our	O
network	B-Method
architecture	I-Method
,	O
namely	O
the	O
GhostVLAD	B-Method
layer	O
,	O
is	O
to	O
enable	O
it	O
to	O
down	O
-	O
weight	O
the	O
influence	O
of	O
these	O
images	O
on	O
the	O
template	B-Method
representation	I-Method
.	O
	
However	O
,	O
since	O
our	O
training	O
dataset	O
only	O
contains	O
good	O
quality	O
images	O
,	O
it	O
is	O
necessary	O
to	O
perform	O
data	B-Task
augmentation	I-Task
in	O
the	O
form	O
of	O
image	O
degradation	O
,	O
such	O
as	O
blurring	O
or	O
compression	O
(	O
see	O
Sec	O
.	O
3.4	O
for	O
details	O
)	O
,	O
in	O
order	O
to	O
more	O
closely	O
match	O
the	O
varying	O
image	B-Metric
quality	I-Metric
encountered	O
at	O
test	O
time	O
.	O
	
section	O
:	O
Implementation	O
details	O
	
This	O
section	O
discusses	O
full	O
details	O
of	O
the	O
training	B-Method
process	I-Method
,	O
including	O
training	O
data	O
,	O
data	B-Task
augmentation	I-Task
,	O
network	B-Task
initialization	I-Task
,	O
etc	O
.	O
	
Training	O
data	O
.	O
	
We	O
use	O
face	O
images	O
from	O
the	O
training	O
set	O
of	O
the	O
VGGFace2	O
dataset	O
[	O
reference	O
]	O
to	O
train	O
the	O
network	O
.	O
	
It	O
consists	O
of	O
around	O
3	O
million	O
images	O
,	O
covering	O
8631	O
identities	O
.	O
	
For	O
each	O
identity	O
,	O
there	O
are	O
on	O
average	O
360	O
face	O
images	O
across	O
different	O
ages	O
and	O
poses	O
.	O
	
To	O
perform	O
set	B-Task
-	I-Task
based	I-Task
training	I-Task
,	O
we	O
form	O
image	O
sets	O
on	O
-	O
the	O
-	O
fly	O
by	O
repeatedly	O
sampling	O
a	O
fixed	O
number	O
of	O
images	O
belonging	O
to	O
the	O
same	O
identity	O
.	O
	
Data	B-Task
augmentation	I-Task
.	O
	
Training	O
images	O
are	O
resized	O
such	O
that	O
the	O
smallest	O
dimension	O
is	O
256	O
and	O
random	O
crops	O
of	O
size	O
224	O
×	O
224	O
are	O
used	O
as	O
inputs	O
to	O
the	O
network	O
.	O
	
Further	O
augmentations	O
include	O
random	B-Method
horizontal	I-Method
flipping	I-Method
and	O
a	O
random	O
rotation	O
of	O
no	O
greater	O
than	O
10	O
degrees	O
.	O
	
We	O
adopt	O
four	O
methods	O
to	O
degrade	O
images	O
for	O
training	B-Task
:	O
isotropic	O
blur	O
,	O
motion	O
blur	O
,	O
decreased	O
resolution	O
and	O
JPEG	B-Method
compression	I-Method
.	O
	
Each	O
degradation	B-Method
method	I-Method
has	O
a	O
probability	O
of	O
0.1	O
to	O
be	O
applied	O
to	O
a	O
training	O
image	O
,	O
where	O
,	O
to	O
prevent	O
overdegradation	O
,	O
a	O
maximum	O
of	O
two	O
transformations	O
per	O
image	O
is	O
allowed	O
.	O
	
Isotropic	B-Task
blur	I-Task
is	O
implemented	O
using	O
a	O
Gaussian	B-Method
filter	I-Method
where	O
the	O
standard	O
deviation	O
is	O
uniformly	O
sampled	O
between	O
6	O
and	O
16	O
.	O
	
For	O
motion	B-Task
blur	I-Task
,	O
the	O
angle	O
of	O
motion	O
is	O
uniformly	O
sampled	O
between	O
0	O
and	O
359	O
degrees	O
,	O
and	O
the	O
motion	O
length	O
is	O
fixed	O
to	O
11	O
.	O
	
Resolution	B-Task
decrease	I-Task
is	O
simulated	O
by	O
downscaling	O
the	O
image	O
by	O
a	O
factor	O
of	O
10	O
and	O
scaling	O
it	O
back	O
up	O
to	O
the	O
original	O
size	O
.	O
	
Finally	O
,	O
we	O
add	O
JPEG	O
compression	O
artefacts	O
by	O
randomly	O
compressing	O
the	O
images	O
to	O
one	O
of	O
three	O
compression	B-Metric
ratios	I-Metric
:	O
0.01	O
,	O
0.05	O
and	O
0.09	O
.	O
	
Training	O
procedure	O
.	O
	
The	O
network	O
can	O
be	O
trained	O
end	O
-	O
to	O
-	O
end	O
in	O
one	O
go	O
,	O
but	O
,	O
to	O
make	O
the	O
training	O
faster	O
and	O
more	O
stable	O
,	O
we	O
divide	O
it	O
into	O
three	O
stages	O
;	O
all	O
stages	O
only	O
use	O
the	O
VGGFace2	B-Method
[	O
reference	O
]	O
dataset	O
.	O
	
In	O
the	O
first	O
two	O
stages	O
,	O
parts	O
of	O
the	O
network	O
are	O
trained	O
for	O
single	B-Task
-	I-Task
image	I-Task
face	I-Task
classification	I-Task
(	O
i.e.	O
the	O
input	O
image	O
set	O
consists	O
of	O
a	O
single	O
image	O
)	O
,	O
and	O
image	O
degradation	O
is	O
not	O
performed	O
.	O
	
Firstly	O
,	O
the	O
feature	B-Method
extractor	I-Method
network	I-Method
is	O
pre	O
-	O
trained	O
for	O
single	B-Task
-	I-Task
image	I-Task
face	I-Task
classification	I-Task
by	O
temporarily	O
(	O
just	O
for	O
this	O
stage	O
)	O
appending	O
a	O
classification	B-Method
FC	I-Method
layer	I-Method
on	O
top	O
of	O
it	O
,	O
and	O
training	O
the	O
network	O
with	O
the	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
loss	I-Metric
.	O
	
Secondly	O
,	O
we	O
train	O
the	O
whole	O
network	O
end	O
-	O
to	O
-	O
end	O
for	O
single	B-Task
-	I-Task
image	I-Task
classification	I-Task
with	O
one	O
-	O
versus	O
-	O
all	O
logistic	B-Method
regression	I-Method
loss	I-Method
,	O
but	O
exclude	O
the	O
ghost	O
clusters	O
from	O
GhostVLAD	B-Method
because	O
training	O
images	O
are	O
not	O
degraded	O
in	O
this	O
stage	O
.	O
	
Finally	O
,	O
we	O
add	O
ghost	O
clusters	O
and	O
enable	O
image	O
degradation	O
,	O
and	O
train	O
the	O
whole	O
network	O
using	O
image	O
sets	O
with	O
one	O
-	O
versus	B-Method
-	I-Method
all	I-Method
logistic	I-Method
regression	I-Method
loss	I-Method
.	O
	
Parameter	B-Task
initialization	I-Task
.	O
	
The	O
non	O
-	O
ghost	O
clusters	O
of	O
GhostVLAD	B-Method
are	O
initialized	O
as	O
in	O
NetVLAD	B-Method
[	O
reference	O
]	O
by	O
clustering	O
its	O
input	O
features	O
with	O
k	B-Method
-	I-Method
means	I-Method
into	O
K	O
clusters	O
,	O
where	O
only	O
non	O
-	O
degraded	O
images	O
are	O
used	O
.	O
	
The	O
G	O
ghost	O
clusters	O
are	O
initialized	O
similarly	O
,	O
but	O
using	O
degraded	O
images	O
for	O
the	O
clustering	B-Task
;	O
note	O
that	O
for	O
G	O
=	O
1	O
(	O
a	O
setting	O
we	O
often	O
use	O
)	O
k	B-Method
-	I-Method
means	I-Method
simplifies	O
to	O
computing	O
the	O
mean	O
over	O
the	O
features	O
.	O
	
The	O
FC	B-Method
following	O
GhostVLAD	B-Method
which	O
performs	O
dimensionality	B-Task
reduction	I-Task
is	O
then	O
initialized	O
using	O
the	O
PCA	O
transformation	O
matrix	O
computed	O
on	O
the	O
GhostVLAD	B-Method
output	O
features	O
.	O
	
Training	O
details	O
.	O
	
The	O
network	O
is	O
trained	O
using	O
stochastic	B-Method
gradient	I-Method
descend	I-Method
with	O
momentum	B-Method
,	O
implemented	O
in	O
MatConvNet	B-Method
	
[	O
reference	O
]	O
.	O
	
The	O
mini	O
-	O
batch	O
consists	O
of	O
84	O
face	O
images	O
,	O
i.e.	O
if	O
we	O
train	O
with	O
image	O
sets	O
of	O
size	O
two	O
,	O
a	O
batch	O
contains	O
42	O
image	O
sets	O
,	O
one	O
per	O
identity	O
.	O
	
When	O
one	B-Method
-	I-Method
versus	I-Method
-	I-Method
all	I-Method
logistic	I-Method
regression	I-Method
loss	I-Method
is	O
used	O
,	O
for	O
each	O
image	O
set	O
,	O
we	O
update	O
the	O
network	O
weights	O
based	O
on	O
the	O
positive	O
class	O
and	O
only	O
20	O
negative	O
classes	O
(	O
instead	O
of	O
8631	O
)	O
that	O
obtain	O
the	O
highest	O
classification	B-Metric
scores	I-Metric
.	O
	
The	O
initial	O
learning	B-Metric
rate	I-Metric
of	O
0.0001	O
is	O
used	O
for	O
all	O
parameters	O
apart	O
from	O
GhostVLAD	B-Method
's	O
assignment	O
parameters	O
and	O
the	O
classification	O
FC	O
weights	O
,	O
for	O
which	O
we	O
use	O
0.1	O
and	O
1	O
,	O
respectively	O
.	O
	
The	O
learning	B-Metric
rates	I-Metric
are	O
divided	O
by	O
10	O
when	O
validation	B-Metric
error	I-Metric
stagnates	O
,	O
while	O
weight	O
decay	O
and	O
momentum	O
are	O
fixed	O
to	O
0.0005	O
and	O
0.9	O
,	O
respectively	O
.	O
	
section	O
:	O
Experiments	O
	
In	O
this	O
section	O
,	O
we	O
describe	O
the	O
experimental	O
setup	O
,	O
investigate	O
the	O
impact	O
of	O
our	O
design	O
choices	O
,	O
and	O
compare	O
results	O
with	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
.	O
	
section	O
:	O
Benchmark	O
datasets	O
and	O
evaluation	O
protocol	O
	
Standard	O
and	O
most	O
challenging	O
public	O
face	B-Task
recognition	I-Task
datasets	O
	
IJB	B-Material
-	I-Material
A	I-Material
[	O
reference	O
]	O
and	O
IJB	B-Material
-	I-Material
B	I-Material
[	O
reference	O
]	O
are	O
used	O
for	O
evaluation	O
.	O
	
In	O
contrast	O
to	O
single	O
-	O
image	O
based	O
face	O
datasets	O
such	O
as	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
,	O
IJB	B-Material
-	I-Material
A	I-Material
and	O
IJB	B-Material
-	I-Material
B	I-Material
are	O
intended	O
for	O
template	O
-	O
based	O
face	B-Task
recognition	I-Task
,	O
which	O
is	O
exactly	O
the	O
task	O
we	O
consider	O
in	O
this	O
work	O
.	O
	
The	O
IJB	B-Material
-	I-Material
A	I-Material
dataset	I-Material
contains	O
5	O
,	O
712	O
images	O
and	O
2	O
,	O
085	O
videos	O
,	O
covering	O
500	O
subjects	O
;	O
thus	O
the	O
average	O
number	O
of	O
images	O
and	O
videos	O
per	O
subject	O
are	O
11.4	O
and	O
4.2	O
videos	O
,	O
respectively	O
.	O
	
The	O
IJB	B-Material
-	I-Material
B	I-Material
dataset	I-Material
is	O
an	O
extension	O
of	O
IJB	B-Material
-	I-Material
A	I-Material
with	O
a	O
total	O
of	O
11	O
,	O
754	O
images	O
and	O
7	O
,	O
011	O
videos	O
from	O
1	O
,	O
845	O
subjects	O
,	O
as	O
well	O
as	O
10	O
,	O
044	O
non	O
-	O
face	O
images	O
.	O
	
There	O
is	O
no	O
overlap	O
between	O
subjects	O
in	O
VGGFace2	O
,	O
which	O
we	O
use	O
for	O
training	O
,	O
and	O
the	O
test	O
datasets	O
.	O
	
Faces	O
are	O
detected	O
from	O
images	O
and	O
all	O
video	O
frames	O
using	O
MTCNN	B-Method
[	O
reference	O
]	O
,	O
the	O
face	O
crops	O
are	O
then	O
resized	O
such	O
that	O
the	O
smallest	O
dimension	O
is	O
224	O
and	O
the	O
central	O
224	O
×	O
224	O
crop	O
is	O
used	O
as	O
the	O
face	O
example	O
.	O
	
Evaluation	B-Metric
protocol	I-Metric
.	O
	
We	O
follow	O
the	O
standard	O
benchmark	O
procedure	O
for	O
IJB	B-Material
-	I-Material
A	I-Material
and	O
IJB	B-Material
-	I-Material
B	I-Material
,	O
and	O
evaluate	O
on	O
"	O
1:1	O
face	O
verification	B-Task
"	O
and	O
"	O
1:N	B-Task
face	I-Task
identification	I-Task
"	O
.	O
	
The	O
goal	O
of	O
1:1	O
verification	B-Task
is	O
to	O
make	O
a	O
decision	O
whether	O
two	O
templates	O
belong	O
to	O
the	O
same	O
person	O
,	O
done	O
by	O
thresholding	O
the	O
similarity	O
between	O
the	O
templates	O
.	O
	
Verification	B-Metric
performance	I-Metric
is	O
assessed	O
via	O
the	O
receiver	B-Metric
	
operating	B-Metric
characteristic	I-Metric
(	O
ROC	B-Metric
)	I-Metric
curve	I-Metric
,	O
i.e.	O
by	O
measuring	O
the	O
trade	O
-	O
off	O
between	O
the	O
true	B-Metric
accept	I-Metric
rates	I-Metric
(	O
TAR	B-Metric
)	O
vs	O
false	B-Metric
accept	I-Metric
rates	I-Metric
(	O
FAR	B-Metric
)	O
.	O
	
For	O
1:N	B-Task
identification	I-Task
,	O
templates	O
from	O
the	O
probe	O
set	O
are	O
used	O
to	O
rank	O
all	O
templates	O
in	O
a	O
given	O
gallery	O
.	O
	
The	O
performance	O
is	O
measured	O
using	O
the	O
true	B-Metric
positive	I-Metric
identification	I-Metric
rate	I-Metric
(	I-Metric
TPIR	I-Metric
)	O
vs	O
false	B-Metric
positive	I-Metric
identification	I-Metric
rate	I-Metric
(	O
FPIR	B-Metric
)	O
(	O
i.e.	O
the	O
decision	B-Metric
error	I-Metric
trade	I-Metric
-	I-Metric
off	I-Metric
(	I-Metric
DET	I-Metric
)	I-Metric
curve	I-Metric
)	O
and	O
vs	O
Rank	B-Metric
-	I-Metric
N	I-Metric
(	O
i.e.	O
the	O
cumulative	B-Metric
match	I-Metric
characteristic	I-Metric
(	I-Metric
CMC	I-Metric
)	I-Metric
curve	I-Metric
)	O
.	O
	
Evaluation	B-Metric
protocols	I-Metric
are	O
the	O
same	O
for	O
both	O
benchmark	O
datasets	O
,	O
apart	O
from	O
the	O
fact	O
that	O
IJB	B-Material
-	I-Material
A	I-Material
defines	O
10	O
test	O
splits	O
,	O
while	O
IJB	B-Material
-	I-Material
B	I-Material
only	O
has	O
one	O
split	O
for	O
verification	B-Task
and	O
two	O
galleries	O
for	O
identification	B-Task
.	O
	
For	O
IJB	B-Material
-	I-Material
A	I-Material
and	O
for	O
IJB	B-Material
-	I-Material
B	I-Material
identification	I-Material
,	O
we	O
report	O
,	O
as	O
per	O
standard	O
,	O
the	O
mean	O
and	O
standard	O
deviation	O
of	O
the	O
performance	B-Metric
measures	I-Metric
.	O
	
section	O
:	O
Networks	O
,	O
deployment	O
and	O
baselines	O
	
Our	O
networks	O
.	O
	
As	O
explained	O
earlier	O
in	O
Sec	O
.	O
	
3.1	O
,	O
we	O
use	O
two	O
different	O
architectures	O
as	O
backbone	B-Method
feature	I-Method
extractors	I-Method
:	O
ResNet	B-Method
-	I-Method
50	I-Method
	
[	O
reference	O
]	O
and	O
SENet	O
-	O
50	O
	
[	O
reference	O
]	O
.	O
They	O
are	O
cropped	O
after	O
global	B-Method
average	I-Method
-	I-Method
pooling	I-Method
which	O
produces	O
a	O
D	O
F	O
=	O
2048	O
dimensional	B-Method
face	I-Method
descriptor	I-Method
,	O
while	O
we	O
also	O
experiment	O
with	O
reducing	O
the	O
dimensionality	O
via	O
an	O
additional	O
FC	B-Method
,	O
down	O
to	O
D	O
F	O
	
=	O
256	O
or	O
D	O
F	O
=	O
128	O
.	O
	
To	O
disambiguate	O
various	O
network	O
configurations	O
,	O
we	O
name	O
the	O
networks	O
as	O
Ext	B-Method
-	I-Method
GV	I-Method
-	I-Method
S	I-Method
(-	I-Method
gG	I-Method
)	O
,	O
where	O
Ext	B-Method
is	O
the	O
feature	B-Method
extractor	I-Method
network	I-Method
(	O
Res	O
for	O
ResNet	O
-	O
50	O
or	O
SE	O
for	O
SENet	O
-	O
50	O
)	O
	
,	O
S	O
is	O
the	O
size	O
of	O
image	O
sets	O
used	O
during	O
training	O
,	O
and	O
G	O
is	O
the	O
number	O
of	O
ghost	O
clusters	O
(	O
if	O
zero	O
,	O
the	O
suffix	O
is	O
dropped	O
)	O
.	O
	
For	O
example	O
,	O
SE	B-Method
-	I-Method
GV	I-Method
-	I-Method
3	I-Method
-	O
g2	O
denotes	O
a	O
network	O
which	O
uses	O
the	O
SENet	B-Method
-	I-Method
50	I-Method
as	O
the	O
feature	B-Method
extractor	I-Method
,	O
training	O
image	O
sets	O
of	O
size	O
3	O
,	O
and	O
2	O
ghost	O
clusters	O
.	O
	
Network	B-Task
deployment	I-Task
.	O
	
In	O
the	O
IJB	B-Material
-	I-Material
A	I-Material
and	O
IJB	B-Material
-	I-Material
B	I-Material
datasets	I-Material
,	O
there	O
are	O
images	O
and	O
videos	O
available	O
for	O
each	O
subject	O
.	O
	
Here	O
we	O
follow	O
the	O
established	O
approach	O
of	O
[	O
reference	O
][	O
reference	O
]	O
to	O
balance	O
the	O
contributions	O
of	O
face	O
examples	O
from	O
different	O
sources	O
,	O
as	O
otherwise	O
a	O
single	O
very	O
long	O
video	O
could	O
completely	O
dominate	O
the	O
representation	O
.	O
	
In	O
more	O
detail	O
,	O
face	O
examples	O
are	O
extracted	O
from	O
all	O
video	O
frames	O
,	O
and	O
their	O
additive	O
contributions	O
to	O
the	O
GhostVLAD	B-Method
representation	O
are	O
down	O
-	O
weighed	O
by	O
the	O
number	O
of	O
frames	O
in	O
the	O
video	O
.	O
	
The	O
similarity	O
between	O
two	O
templates	O
is	O
measured	O
as	O
the	O
scalar	O
product	O
between	O
the	O
template	B-Method
representations	I-Method
;	O
recall	O
that	O
they	O
have	O
unit	O
norm	O
(	O
Fig	O
.	O
1	O
)	O
.	O
	
Baselines	O
.	O
	
Our	O
network	O
is	O
compared	O
with	O
several	O
average	B-Method
-	I-Method
pooling	I-Method
baselines	I-Method
.	O
	
The	O
baseline	O
architecture	O
consists	O
of	O
a	O
feature	B-Method
extractor	I-Method
network	I-Method
which	O
produces	O
a	O
face	B-Method
descriptor	I-Method
for	O
each	O
input	O
example	O
,	O
and	O
the	O
template	B-Method
representation	I-Method
is	O
performed	O
by	O
average	B-Method
-	I-Method
pooling	I-Method
the	I-Method
face	I-Method
descriptors	I-Method
(	O
with	O
source	B-Method
balancing	I-Method
)	O
,	O
followed	O
by	O
L2	B-Method
normalization	I-Method
.	O
	
The	O
same	O
feature	B-Method
extractor	I-Method
networks	I-Method
are	O
used	O
as	O
for	O
our	O
method	O
,	O
ResNet	O
-	O
50	O
or	O
SENet	O
-	O
50	O
,	O
abbreviated	O
as	O
Res	O
and	O
SE	O
,	O
respectively	O
,	O
with	O
an	O
optionally	O
added	O
FC	B-Method
layer	I-Method
to	O
perform	O
dimensionality	B-Task
reduction	I-Task
down	O
to	O
128	O
-	O
D	O
or	O
256	O
-	O
D.	O
	
These	O
networks	O
are	O
trained	O
for	O
single	B-Task
-	I-Task
image	I-Task
face	I-Task
classification	I-Task
,	O
which	O
is	O
equivalent	O
to	O
stage	O
1	O
of	O
our	O
training	O
procedure	O
from	O
Sec	O
.	O
	
3.4	O
,	O
and	O
also	O
corresponds	O
to	O
the	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
approach	O
[	O
reference	O
]	O
(	O
albeit	O
with	O
more	O
training	O
data	O
-	O
see	O
Sec	O
.	O
	
4.4	O
for	O
details	O
and	O
comparisons	O
)	O
.	O
	
No	O
image	O
degradation	O
is	O
performed	O
as	O
it	O
decreases	O
performance	O
when	O
combined	O
with	O
single	B-Method
-	I-Method
image	I-Method
classification	I-Method
training	I-Method
.	O
	
In	O
addition	O
,	O
we	O
train	O
the	O
baseline	B-Method
architecture	I-Method
SENet	I-Method
-	I-Method
50	I-Method
with	O
average	B-Method
-	I-Method
pooling	I-Method
using	O
our	O
training	O
procedure	O
(	O
Sec	O
.	O
3.3	O
)	O
,	O
i.e.	O
with	O
image	O
sets	O
of	O
size	O
2	O
and	O
degraded	O
images	O
,	O
and	O
refer	O
to	O
it	O
as	O
SE	B-Method
-	I-Method
2	I-Method
.	O
	
section	O
:	O
Ablation	B-Task
studies	I-Task
on	O
IJB	B-Material
-	I-Material
B	I-Material
	
Here	O
we	O
evaluate	O
various	O
design	O
choices	O
of	O
our	O
architecture	O
and	O
compare	O
it	O
to	O
baselines	O
on	O
the	O
IJB	B-Material
-	I-Material
B	I-Material
dataset	I-Material
,	O
as	O
it	O
is	O
larger	O
and	O
more	O
challenging	O
than	O
IJB	B-Material
-	I-Material
A	I-Material
;	O
results	O
on	O
verification	B-Task
and	O
identification	B-Task
are	O
shown	O
in	O
Tables	O
1	O
and	O
Table	O
2	O
,	O
respectively	O
.	O
	
Feature	B-Method
extractor	I-Method
and	O
dimensionality	B-Task
reduction	I-Task
.	O
	
Comparing	O
rows	O
1	O
vs	O
2	O
of	O
the	O
two	O
tables	O
shows	O
that	O
reducing	O
the	O
dimensionality	O
of	O
the	O
face	O
features	O
from	O
2048	O
-	O
D	O
to	O
128	O
-	O
D	O
does	O
not	O
affect	O
the	O
performance	O
much	O
,	O
and	O
in	O
fact	O
sometimes	O
improves	O
it	O
due	O
to	O
added	O
parameters	O
in	O
the	O
form	O
of	O
the	O
dimensionality	B-Method
reduction	I-Method
FC	I-Method
.	O
	
As	O
the	O
feature	B-Method
extractor	I-Method
backbone	I-Method
,	O
SENet	B-Method
-	I-Method
50	I-Method
consistently	O
beats	O
ResNet	B-Method
-	I-Method
50	I-Method
,	O
as	O
summarized	O
in	O
rows	O
2	O
vs	O
3	O
.	O
	
Training	O
for	O
set	O
-	O
based	O
face	B-Task
recognition	I-Task
.	O
	
The	O
currently	O
adopted	O
set	O
-	O
based	O
face	B-Task
recognition	I-Task
approach	O
of	O
training	O
with	O
single	O
-	O
image	O
examples	O
and	O
performing	O
aggregation	O
post	O
hoc	O
(	O
SE	O
,	O
row	O
4	O
)	O
	
is	O
clearly	O
inferior	O
to	O
our	O
training	B-Method
procedure	I-Method
which	O
is	O
aware	O
of	O
image	O
sets	O
(	O
SE	O
-	O
2	O
,	O
row	O
5	O
)	O
.	O
	
Learnt	O
GhostVLAD	B-Method
aggregation	O
.	O
	
Using	O
the	O
GhostVLAD	B-Method
aggregation	O
layer	O
(	O
with	O
G	O
=	O
0	O
i.e.	O
equivalent	O
to	O
NetVLAD	B-Method
)	O
together	O
with	O
our	O
set	B-Method
-	I-Method
based	I-Method
training	I-Method
framework	I-Method
strongly	O
outperforms	O
the	O
standard	O
average	B-Method
-	I-Method
pooling	I-Method
approach	I-Method
,	O
regardless	O
of	O
whether	O
training	B-Task
is	O
done	O
with	O
non	O
-	O
degraded	O
images	O
(	O
SE	O
-	O
GV	O
-	O
2	O
,	O
row	O
8	O
vs	O
SE	O
,	O
rows	O
3	O
and	O
4	O
)	O
,	O
degraded	O
images	O
(	O
SE	O
-	O
GV	O
-	O
2	O
,	O
row	O
9	O
vs	O
SE	O
-	O
2	O
,	O
row	O
5	O
)	O
,	O
or	O
if	O
a	O
different	O
feature	B-Method
extractor	I-Method
architecture	I-Method
(	O
ResNet	B-Method
-	I-Method
50	I-Method
)	O
is	O
used	O
(	O
Res	O
-	O
GV	O
-	O
2	O
,	O
row	O
6	O
vs	O
Res	O
,	O
row	O
2	O
)	O
.	O
	
Using	O
256	O
-	O
D	O
vs	O
128	O
-	O
D	O
face	O
descriptors	O
as	O
inputs	O
to	O
GhostVLAD	B-Method
,	O
while	O
keeping	O
the	O
same	O
dimensionality	O
of	O
the	O
final	O
template	B-Method
representation	I-Method
(	O
128	O
-	O
D	O
)	O
,	O
achieves	O
better	O
results	O
(	O
rows	O
9	O
vs	O
7	O
)	O
,	O
so	O
we	O
use	O
256	O
-	O
D	O
in	O
all	O
latter	O
experiments	O
.	O
	
Training	O
with	O
degraded	O
images	O
.	O
	
When	O
using	O
our	O
set	B-Method
-	I-Method
based	I-Method
training	I-Method
procedure	I-Method
,	O
training	O
with	O
degraded	O
images	O
brings	O
a	O
consistent	O
boost	O
,	O
as	O
shown	O
in	O
rows	O
9	O
vs	O
8	O
,	O
since	O
it	O
better	O
matches	O
the	O
test	O
-	O
time	O
scenario	O
which	O
contains	O
images	O
of	O
varying	O
quality	O
.	O
	
Number	O
of	O
clusters	O
K.	O
GhostVLAD	B-Method
(	O
and	O
NetVLAD	B-Method
)	O
have	O
a	O
hyperparameter	O
K	O
-	O
the	O
number	O
of	O
non	O
-	O
ghost	O
clusters	O
	
-	O
which	O
we	O
vary	O
between	O
4	O
and	O
16	O
(	O
rows	O
9	O
to	O
11	O
)	O
to	O
study	O
its	O
effect	O
on	O
face	B-Task
recognition	I-Task
performance	O
.	O
	
It	O
is	O
expected	O
that	O
K	O
should	O
n't	O
be	O
too	O
small	O
so	O
that	O
underfitting	O
is	O
avoided	O
(	O
e.g.	O
K	O
=	O
1	O
is	O
similar	O
to	O
average	B-Method
-	I-Method
pooling	I-Method
)	O
nor	O
too	O
large	O
in	O
order	O
to	O
prevent	O
over	O
-	O
quantization	O
and	O
overfitting	O
.	O
	
As	O
in	O
traditional	O
image	B-Task
retrieval	I-Task
[	O
reference	O
]	O
,	O
we	O
find	O
that	O
a	O
wide	O
range	O
of	O
K	O
achieves	O
good	O
performance	O
,	O
with	O
K	O
=	O
8	O
being	O
the	O
best	O
.	O
	
Ghost	O
clusters	O
.	O
	
Introducing	O
a	O
single	O
ghost	O
cluster	O
(	O
G	O
=	O
1	O
)	O
brings	O
significant	O
improvement	O
over	O
the	O
vanilla	B-Method
NetVLAD	I-Method
,	O
as	O
shown	O
by	O
comparing	O
SE	B-Method
-	I-Method
GV	I-Method
-	I-Method
3	I-Method
-	O
g1	O
vs	O
SE	B-Method
-	I-Method
GV	I-Method
-	I-Method
3	I-Method
(	O
rows	O
14	O
vs	O
12	O
)	O
and	O
SE	B-Method
-	I-Method
GV	I-Method
-	I-Method
4	I-Method
-	I-Method
g1	I-Method
vs	O
SE	O
	
-	O
GV	O
-	O
4	O
	
(	O
rows	O
15	O
vs	O
13	O
)	O
.	O
	
Using	O
one	O
ghost	O
cluster	O
is	O
sufficient	O
as	O
increasing	O
the	O
number	O
of	O
ghost	O
clusters	O
to	O
two	O
does	O
not	O
result	O
in	O
significant	O
differences	O
(	O
row	O
16	O
vs	O
row	O
14	O
)	O
.	O
	
Ghost	O
clusters	O
enable	O
the	O
system	O
to	O
automatically	O
down	O
-	O
weight	O
the	O
contribution	O
of	O
low	O
quality	O
images	O
,	O
as	O
will	O
be	O
shown	O
in	O
Sec	O
.	O
	
4.5	O
,	O
which	O
improves	O
the	O
template	B-Method
representations	I-Method
and	O
benefits	O
face	B-Task
recognition	I-Task
.	O
	
Set	O
size	O
used	O
during	O
training	O
.	O
	
To	O
perform	O
set	B-Method
-	I-Method
based	I-Method
training	I-Method
,	O
as	O
described	O
in	O
Sec	O
.	O
	
3.4	O
,	O
image	O
sets	O
are	O
created	O
by	O
sampling	O
a	O
fixed	O
number	O
of	O
faces	O
for	O
a	O
subject	O
;	O
the	O
number	O
of	O
sampled	O
faces	O
is	O
another	O
parameter	O
of	O
the	O
method	O
.	O
	
Increasing	O
the	O
set	O
size	O
from	O
2	O
to	O
3	O
consistently	O
improves	O
results	O
(	O
rows	O
9	O
vs	O
12	O
)	O
,	O
while	O
there	O
is	O
no	O
clear	O
winner	O
between	O
using	O
3	O
or	O
4	O
face	O
examples	O
(	O
worse	O
for	O
G	O
=	O
0	O
,	O
rows	O
12	O
vs	O
13	O
,	O
better	O
for	O
G	O
=	O
1	O
,	O
rows	O
15	O
vs	O
14	O
)	O
.	O
	
Output	O
dimensionality	O
.	O
	
Comparisons	O
are	O
also	O
made	O
between	O
networks	O
with	O
128	O
-	O
D	O
output	O
features	O
and	O
those	O
with	O
256	O
-	O
D	O
(	O
i.e.	O
row	O
13	O
vs	O
17	O
and	O
row	O
15	O
vs	O
18	O
)	O
,	O
and	O
we	O
can	O
see	O
that	O
networks	O
with	O
128	O
-	O
D	O
output	O
achieve	O
better	O
performance	O
while	O
being	O
more	O
memory	O
-	O
efficient	O
.	O
	
section	O
:	O
Comparison	O
with	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
	
In	O
this	O
section	O
,	O
our	O
best	O
networks	O
,	O
SE	B-Method
-	I-Method
GV	I-Method
-	I-Method
3	I-Method
and	O
SE	B-Method
-	I-Method
GV	I-Method
-	I-Method
4	I-Method
-	I-Method
g1	I-Method
,	O
are	O
compared	O
against	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
on	O
the	O
IJB	B-Material
-	I-Material
A	I-Material
and	O
IJB	B-Material
-	I-Material
B	I-Material
datasets	I-Material
.	O
	
The	O
currently	O
best	O
performing	O
method	O
[	O
reference	O
]	O
is	O
the	O
same	O
as	O
our	O
SE	B-Method
baseline	I-Method
(	O
i.e.	O
average	B-Method
-	I-Method
pooling	I-Method
of	I-Method
SENet	I-Method
-	I-Method
50	I-Method
features	I-Method
trained	O
for	O
single	B-Task
-	I-Task
image	I-Task
classification	I-Task
)	O
but	O
trained	O
on	O
a	O
much	O
larger	O
training	O
set	O
,	O
MS	O
-	O
Celeb	O
-	O
1	O
M	O
dataset	O
[	O
reference	O
]	O
,	O
and	O
then	O
fine	O
-	O
tuned	O
on	O
VGGFace2	B-Method
.	O
	
From	O
Tables	O
3	O
and	O
4	O
,	O
and	O
Figure	O
3	O
,	O
it	O
is	O
clear	O
our	O
GhostVLAD	B-Method
network	O
(	O
SE	B-Method
-	I-Method
GV	I-Method
-	I-Method
4	I-Method
-	I-Method
g1	I-Method
)	O
convincingly	O
outperforms	O
previous	O
methods	O
and	O
sets	O
the	O
new	O
state	O
-	O
ofthe	O
-	O
art	O
for	O
both	O
identification	B-Task
and	O
verification	B-Task
on	O
both	O
IJB	B-Material
-	I-Material
A	I-Material
and	O
IJB	B-Material
-	I-Material
B	I-Material
datasets	I-Material
.	O
	
In	O
particular	O
,	O
it	O
surpasses	O
[	O
reference	O
]	O
marginally	O
on	O
the	O
IJB	O
-	O
A	O
verification	B-Task
task	O
,	O
despite	O
the	O
fact	O
that	O
[	O
reference	O
]	O
uses	O
a	O
deeper	O
ResNet	B-Method
and	O
performs	O
an	O
exhaustive	O
scoring	O
using	O
each	O
face	O
image	O
in	O
the	O
templates	O
.	O
	
The	O
only	O
points	O
for	O
which	O
the	O
GhostVLAD	B-Method
network	O
does	O
n't	O
beat	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
,	O
though	O
it	O
is	O
on	O
par	O
with	O
it	O
,	O
is	O
in	O
TPIR	B-Metric
at	O
Rank	O
-	O
1	O
to	O
Rank	O
-	O
10	O
for	O
identification	B-Task
on	O
IJB	B-Material
-	I-Material
A	I-Material
;	O
but	O
this	O
is	O
because	O
IJB	B-Material
-	I-Material
A	I-Material
is	O
not	O
challenging	O
enough	O
and	O
the	O
TPIR	B-Metric
values	O
have	O
saturated	O
to	O
a	O
99	O
%	O
mark	O
.	O
	
For	O
the	O
same	O
measures	O
on	O
the	O
more	O
challenging	O
IJB	B-Material
-	I-Material
B	I-Material
benchmark	I-Material
,	O
our	O
network	O
achieves	O
the	O
best	O
TAR	B-Metric
at	O
FAR=1E	B-Metric
−	O
5	O
and	O
FAR=1E	B-Metric
−	O
4	O
,	O
and	O
is	O
only	O
lower	O
than	O
a	O
concurrent	O
work	O
[	O
reference	O
]	O
at	O
FAR=1E	B-Metric
−	O
3	O
and	O
FAR=1E	B-Metric
−	O
2	O
.	O
	
Furthermore	O
,	O
our	O
networks	O
produce	O
much	O
smaller	O
template	O
descriptors	O
than	O
the	O
previous	O
stateof	O
-	O
the	O
-	O
art	O
networks	O
(	O
128	O
-	O
D	O
vs	O
2048	O
-	O
D	O
)	O
,	O
making	O
them	O
more	O
useful	O
in	O
real	O
-	O
world	O
[	O
reference	O
]	O
(	O
priv1	O
)	O
and	O
[	O
reference	O
]	O
(	O
	
priv2	O
)	O
.	O
'	O
	
512	O
-	O
pi	O
'	O
means	O
that	O
a	O
512	B-Method
-	I-Method
D	I-Method
descriptor	I-Method
is	O
used	O
per	O
image	O
.	O
'	O
	
*	O
'	O
denotes	O
the	O
value	O
given	O
by	O
the	O
author	O
.	O
	
Our	O
best	O
network	O
,	O
SE	B-Method
-	I-Method
GV	I-Method
-	I-Method
4	I-Method
-	I-Method
g1	I-Method
,	O
sets	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
by	O
a	O
significant	O
margin	O
on	O
both	O
datasets	O
(	O
except	O
for	O
concurrent	O
work	O
[	O
reference	O
]	O
)	O
.	O
	
applications	O
due	O
to	O
smaller	O
memory	O
requirements	O
and	O
faster	O
template	O
comparisons	O
.	O
	
The	O
results	O
are	O
especially	O
impressive	O
as	O
we	O
only	O
train	O
using	O
VGGFace2	B-Method
[	O
reference	O
]	O
and	O
beat	B-Method
methods	I-Method
which	O
train	O
with	O
much	O
more	O
data	O
,	O
such	O
as	O
[	O
reference	O
]	O
which	O
combine	O
VGGFace2	B-Method
and	O
MS	B-Method
	
-	O
Celeb	O
-	O
1	O
M	O
[	O
reference	O
]	O
,	O
e.g.	O
TAR	B-Metric
at	O
FAR=1E	B-Metric
−	O
5	O
of	O
0.762	O
vs	O
0.705	O
for	O
verification	B-Task
on	O
IJB	B-Material
-	I-Material
B	I-Material
,	O
and	O
TPIR	B-Metric
at	O
FPIR=0.01	B-Metric
of	O
0.776	O
vs	O
0.743	O
for	O
identification	B-Task
on	O
IJB	B-Material
-	I-Material
B.	I-Material
	
When	O
considering	O
only	O
methods	O
trained	O
on	O
the	O
same	O
data	O
(	O
VGGFace2	B-Method
)	O
,	O
our	O
improvement	O
over	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
is	O
even	O
larger	O
:	O
TAR	B-Metric
at	O
FAR=1E	B-Metric
−5	O
of	O
0.762	O
vs	O
0.671	O
for	O
verification	B-Task
on	O
IJB	B-Material
-	I-Material
B	I-Material
,	O
and	O
TPIR	B-Metric
at	O
FPIR=0.01	B-Metric
of	O
0.776	O
vs	O
0.706	O
for	O
verification	B-Task
on	O
IJB	B-Material
-	I-Material
B.	I-Material
	
section	O
:	O
Analysis	B-Task
of	I-Task
ghost	I-Task
clusters	I-Task
	
Addition	O
of	O
ghost	O
clusters	O
was	O
motivated	O
by	O
the	O
intuition	O
that	O
it	O
enables	O
our	O
network	O
to	O
learn	O
to	O
ignore	O
uninformative	O
low	O
-	O
quality	O
images	O
by	O
assigning	O
them	O
to	O
the	O
discarded	O
ghost	O
clusters	O
.	O
	
Here	O
we	O
evaluate	O
this	O
hypothesis	O
qualitatively	O
.	O
	
Recall	O
that	O
GhostVLAD	B-Method
computes	O
a	O
template	B-Method
representation	I-Method
by	O
aggregating	O
residual	O
vectors	O
of	O
input	O
descriptors	O
,	O
where	O
a	O
residual	O
vector	O
is	O
a	O
concatenation	O
of	O
per	O
non	O
-	O
ghost	O
cluster	O
residuals	O
weighted	O
by	O
their	O
non	O
-	O
ghost	O
assignment	O
weights	O
(	O
Sec	O
.	O
3.2	O
)	O
.	O
	
Therefore	O
,	O
the	O
contribution	O
of	O
a	O
specific	O
example	O
image	O
towards	O
the	O
template	B-Method
representation	I-Method
can	O
be	O
measured	O
as	O
the	O
norm	O
of	O
the	O
residual	O
.	O
	
Figure	O
4	O
show	O
that	O
our	O
intuition	O
is	O
correct	O
	
-	O
the	O
network	O
automatically	O
learns	O
to	O
dramatically	O
down	O
-	O
weight	O
blurry	O
and	O
low	O
-	O
resolution	O
images	O
,	O
thus	O
improving	O
the	O
signal	B-Metric
-	I-Metric
to	I-Metric
-	I-Metric
noise	I-Metric
ratio	I-Metric
.	O
	
Note	O
that	O
this	O
behaviour	O
emerges	O
completely	O
automatically	O
without	O
ever	O
explicitly	O
teaching	O
the	O
network	O
to	O
down	O
-	O
weight	O
low	O
-	O
quality	O
images	O
.	O
	
section	O
:	O
Conclusions	O
	
We	O
introduced	O
a	O
neural	B-Method
network	I-Method
architecture	I-Method
and	O
training	B-Method
procedure	I-Method
for	O
learning	O
compact	B-Task
representations	I-Task
of	I-Task
image	I-Task
sets	I-Task
for	O
template	O
-	O
based	O
face	B-Task
recognition	I-Task
.	O
	
Due	O
to	O
the	O
novel	O
GhostVLAD	B-Method
layer	O
,	O
the	O
network	O
is	O
able	O
to	O
automatically	O
learn	O
to	O
weight	O
face	O
descriptors	O
depending	O
on	O
their	O
information	O
content	O
.	O
	
Our	O
template	B-Method
representations	I-Method
outperform	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
on	O
the	O
challenging	O
IJB	B-Material
-	I-Material
A	I-Material
and	O
IJB	B-Material
-	I-Material
B	I-Material
benchmarks	O
by	O
a	O
large	O
margin	O
.	O
	
The	O
network	B-Method
architecture	I-Method
proposed	O
here	O
could	O
also	O
be	O
applied	O
to	O
other	O
imageset	B-Task
tasks	I-Task
such	O
as	O
person	B-Task
re	I-Task
-	I-Task
identification	I-Task
,	O
and	O
set	B-Task
-	I-Task
based	I-Task
retrieval	I-Task
.	O
	
More	O
generally	O
,	O
the	O
idea	O
of	O
having	O
a	O
'	O
null	O
'	O
vector	O
available	O
for	O
assignments	O
could	O
have	O
applicability	O
in	O
many	O
situations	O
where	O
it	O
is	O
advantageous	O
to	O
have	O
a	O
mechanism	O
to	O
remove	O
noisy	O
or	O
corrupted	O
data	O
.	O
	
section	O
:	O
	
section	O
:	O
	
Acknowledgements	O
We	O
thank	O
Weidi	O
Xie	O
for	O
his	O
useful	O
advice	O
,	O
and	O
we	O
thank	O
Li	O
Shen	O
for	O
providing	O
pre	O
-	O
trained	O
networks	O
.	O
	
This	O
work	O
was	O
funded	O
by	O
an	O
EPSRC	O
studentship	O
and	O
EPSRC	O
Programme	O
Grant	O
Seebibyte	O
EP	O
/	O
M013774	O
/	O
1	O
.	O
	
section	O
:	O
Bibliography	O
	
section	O
:	O
	
document	O
:	O
Linguistically	B-Task
-	I-Task
Informed	I-Task
Self	I-Task
-	I-Task
Attention	I-Task
for	O
Semantic	B-Task
Role	I-Task
Labeling	I-Task
	
Current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
semantic	B-Task
role	I-Task
labeling	I-Task
(	O
SRL	B-Task
)	O
uses	O
a	O
deep	B-Method
neural	I-Method
network	I-Method
with	O
no	O
explicit	O
linguistic	O
features	O
.	O
	
However	O
,	O
prior	O
work	O
has	O
shown	O
that	O
gold	O
syntax	O
trees	O
can	O
dramatically	O
improve	O
SRL	B-Task
decoding	I-Task
,	O
suggesting	O
the	O
possibility	O
of	O
increased	O
accuracy	B-Metric
from	O
explicit	B-Method
modeling	I-Method
of	I-Method
syntax	I-Method
.	O
	
In	O
this	O
work	O
,	O
we	O
present	O
linguistically	B-Method
-	I-Method
informed	I-Method
self	I-Method
-	I-Method
attention	I-Method
(	O
LISA	B-Method
)	O
:	O
a	O
neural	B-Method
network	I-Method
model	I-Method
that	O
combines	O
multi	B-Method
-	I-Method
head	I-Method
self	I-Method
-	I-Method
attention	I-Method
with	O
multi	B-Method
-	I-Method
task	I-Method
learning	I-Method
across	O
dependency	B-Task
parsing	I-Task
,	O
part	B-Task
-	I-Task
of	I-Task
-	I-Task
speech	I-Task
tagging	I-Task
,	O
predicate	B-Task
detection	I-Task
and	O
SRL	B-Task
.	O
	
Unlike	O
previous	O
models	O
which	O
require	O
significant	O
pre	O
-	O
processing	O
to	O
prepare	O
linguistic	O
features	O
,	O
LISA	B-Method
can	O
incorporate	O
syntax	O
using	O
merely	O
raw	O
tokens	O
as	O
input	O
,	O
encoding	O
the	O
sequence	O
only	O
once	O
to	O
simultaneously	O
perform	O
parsing	B-Task
,	O
predicate	B-Task
detection	I-Task
and	O
role	B-Task
labeling	I-Task
for	O
all	O
predicates	O
.	O
	
Syntax	O
is	O
incorporated	O
by	O
training	O
one	O
attention	O
head	O
to	O
attend	O
to	O
syntactic	O
parents	O
for	O
each	O
token	O
.	O
	
Moreover	O
,	O
if	O
a	O
high	O
-	O
quality	O
syntactic	O
parse	O
is	O
already	O
available	O
,	O
it	O
can	O
be	O
beneficially	O
injected	O
at	O
test	O
time	O
without	O
re	O
-	O
training	O
our	O
SRL	B-Task
model	I-Task
.	O
	
In	O
experiments	O
on	O
CoNLL	B-Material
-	I-Material
2005	I-Material
SRL	I-Material
,	O
LISA	B-Method
achieves	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
for	O
a	O
model	O
using	O
predicted	O
predicates	O
and	O
standard	O
word	B-Method
embeddings	I-Method
,	O
attaining	O
2.5	O
F1	B-Metric
absolute	O
higher	O
than	O
the	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
on	O
newswire	O
and	O
more	O
than	O
3.5	O
F1	B-Metric
on	O
out	O
-	O
of	O
-	O
domain	O
data	O
,	O
nearly	O
10	O
%	O
reduction	O
in	O
error	B-Metric
.	O
	
On	O
ConLL	B-Material
-	I-Material
2012	I-Material
English	I-Material
SRL	I-Material
we	O
also	O
show	O
an	O
improvement	O
of	O
more	O
than	O
2.5	O
F1	B-Metric
.	O
	
LISA	B-Method
also	O
out	O
-	O
performs	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
with	O
contextually	B-Method
-	I-Method
encoded	I-Method
(	I-Method
ELMo	I-Method
)	I-Method
word	I-Method
representations	I-Method
,	O
by	O
nearly	O
1.0	O
F1	B-Metric
on	O
news	O
and	O
more	O
than	O
2.0	O
F1	B-Metric
on	O
out	O
-	O
of	O
-	O
domain	O
text	O
.	O
	
section	O
:	O
Introduction	O
	
Semantic	B-Task
role	I-Task
labeling	I-Task
(	O
SRL	B-Task
)	O
extracts	O
a	O
high	O
-	O
level	O
representation	O
of	O
meaning	O
from	O
a	O
sentence	O
,	O
labeling	O
e.g.	O
who	O
did	O
what	O
to	O
whom	O
.	O
	
Explicit	B-Method
representations	I-Method
of	O
such	O
semantic	O
information	O
have	O
been	O
shown	O
to	O
improve	O
results	O
in	O
challenging	O
downstream	B-Task
tasks	I-Task
such	O
as	O
dialog	B-Task
systems	I-Task
tur2005semi	O
,	O
chen2013unsupervised	O
,	O
machine	B-Task
reading	I-Task
berant2014modeling	O
,	O
wang2015machine	O
and	O
translation	B-Task
liu2010semantic	O
,	O
bazrafshan2013semantic	O
.	O
	
Though	O
syntax	O
was	O
long	O
considered	O
an	O
obvious	O
prerequisite	O
for	O
SRL	B-Task
systems	I-Task
levin1993english	O
,	O
punyakanok2008importance	O
,	O
recently	O
deep	B-Method
neural	I-Method
network	I-Method
architectures	I-Method
have	O
surpassed	O
syntactically	B-Method
-	I-Method
informed	I-Method
models	I-Method
zhou2015end	O
,	O
marcheggiani2017simple	O
,	O
he2017deep	O
,	O
tan2018deep	O
,	O
he2018jointly	O
,	O
achieving	O
state	O
-	O
of	O
-	O
the	O
art	O
SRL	B-Task
performance	O
with	O
no	O
explicit	B-Method
modeling	I-Method
of	I-Method
syntax	I-Method
.	O
	
An	O
additional	O
benefit	O
of	O
these	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
models	I-Method
is	O
that	O
they	O
require	O
just	O
raw	O
tokens	O
and	O
(	O
usually	O
)	O
detected	O
predicates	O
as	O
input	O
,	O
whereas	O
richer	O
linguistic	O
features	O
typically	O
require	O
extraction	O
by	O
an	O
auxiliary	B-Method
pipeline	I-Method
of	I-Method
models	I-Method
.	O
	
Still	O
,	O
recent	O
work	O
roth2016neural	O
,	O
he2017deep	O
,	O
marcheggiani2017encoding	O
indicates	O
that	O
neural	B-Method
network	I-Method
models	I-Method
could	O
see	O
even	O
higher	O
accuracy	B-Metric
gains	O
by	O
leveraging	O
syntactic	O
information	O
rather	O
than	O
ignoring	O
it	O
.	O
	
he2017deep	O
indicate	O
that	O
many	O
of	O
the	O
errors	O
made	O
by	O
a	O
syntax	B-Method
-	I-Method
free	I-Method
neural	I-Method
network	I-Method
on	O
SRL	B-Task
are	O
tied	O
to	O
certain	O
syntactic	O
confusions	O
such	O
as	O
prepositional	O
phrase	O
attachment	O
,	O
and	O
show	O
that	O
while	O
constrained	B-Method
inference	I-Method
using	O
a	O
relatively	O
low	O
-	O
accuracy	B-Metric
predicted	I-Metric
parse	I-Metric
can	O
provide	O
small	O
improvements	O
in	O
SRL	B-Task
accuracy	O
,	O
providing	O
a	O
gold	B-Metric
-	I-Metric
quality	I-Metric
parse	I-Metric
leads	O
to	O
substantial	O
gains	O
.	O
	
marcheggiani2017encoding	O
incorporate	O
syntax	O
from	O
a	O
high	O
-	O
quality	O
parser	B-Method
kiperwasser2016simple	O
using	O
graph	B-Method
convolutional	I-Method
neural	I-Method
networks	I-Method
kipf2017semi	O
,	O
but	O
like	O
he2017deep	O
they	O
attain	O
only	O
small	O
increases	O
over	O
a	O
model	O
with	O
no	O
syntactic	O
parse	O
,	O
and	O
even	O
perform	O
worse	O
than	O
a	O
syntax	B-Method
-	I-Method
free	I-Method
model	I-Method
on	O
out	O
-	O
of	O
-	O
domain	O
data	O
.	O
	
These	O
works	O
suggest	O
that	O
though	O
syntax	O
has	O
the	O
potential	O
to	O
improve	O
neural	B-Method
network	I-Method
SRL	I-Method
models	I-Method
,	O
we	O
have	O
not	O
yet	O
designed	O
an	O
architecture	O
which	O
maximizes	O
the	O
benefits	O
of	O
auxiliary	O
syntactic	O
information	O
.	O
	
In	O
response	O
,	O
we	O
propose	O
linguistically	B-Method
-	I-Method
informed	I-Method
self	I-Method
-	I-Method
attention	I-Method
(	O
LISA	B-Method
)	O
:	O
a	O
model	O
that	O
combines	O
multi	B-Method
-	I-Method
task	I-Method
learning	I-Method
caruana1993multitask	O
with	O
stacked	B-Method
layers	I-Method
of	I-Method
multi	I-Method
-	I-Method
head	I-Method
self	I-Method
-	I-Method
attention	I-Method
vaswani2017attention	O
;	O
the	O
model	O
is	O
trained	O
to	O
:	O
(	O
1	O
)	O
jointly	O
predict	O
parts	O
of	O
speech	O
and	O
predicates	O
;	O
(	O
2	O
)	O
perform	O
parsing	B-Task
;	O
and	O
(	O
3	O
)	O
attend	O
to	O
syntactic	O
parse	O
parents	O
,	O
while	O
(	O
4	O
)	O
assigning	O
semantic	O
role	O
labels	O
.	O
	
Whereas	O
prior	O
work	O
typically	O
requires	O
separate	O
models	O
to	O
provide	O
linguistic	B-Task
analysis	I-Task
,	O
including	O
most	O
syntax	B-Method
-	I-Method
free	I-Method
neural	I-Method
models	I-Method
which	O
still	O
rely	O
on	O
external	B-Method
predicate	I-Method
detection	I-Method
,	O
our	O
model	O
is	O
truly	O
end	O
-	O
to	O
-	O
end	O
:	O
earlier	O
layers	O
are	O
trained	O
to	O
predict	O
prerequisite	O
parts	O
-	O
of	O
-	O
speech	O
and	O
predicates	O
,	O
the	O
latter	O
of	O
which	O
are	O
supplied	O
to	O
later	O
layers	O
for	O
scoring	B-Task
.	O
	
Though	O
prior	O
work	O
re	O
-	O
encodes	O
each	O
sentence	O
to	O
predict	O
each	O
desired	O
task	O
and	O
again	O
with	O
respect	O
to	O
each	O
predicate	O
to	O
perform	O
SRL	B-Task
,	O
we	O
more	O
efficiently	O
encode	O
each	O
sentence	O
only	O
once	O
,	O
predict	O
its	O
predicates	O
,	O
part	O
-	O
of	O
-	O
speech	O
tags	O
and	O
labeled	O
syntactic	O
parse	O
,	O
then	O
predict	O
the	O
semantic	O
roles	O
for	O
all	O
predicates	O
in	O
the	O
sentence	O
in	O
parallel	O
.	O
	
The	O
model	O
is	O
trained	O
such	O
that	O
,	O
as	O
syntactic	B-Method
parsing	I-Method
models	I-Method
improve	O
,	O
providing	O
high	O
-	O
quality	O
parses	O
at	O
test	O
time	O
will	O
improve	O
its	O
performance	O
,	O
allowing	O
the	O
model	O
to	O
leverage	O
updated	O
parsing	B-Method
models	I-Method
without	O
requiring	O
re	B-Task
-	I-Task
training	I-Task
.	O
	
In	O
experiments	O
on	O
the	O
CoNLL	B-Material
-	I-Material
2005	I-Material
and	O
CoNLL	B-Material
-	I-Material
2012	I-Material
datasets	I-Material
we	O
show	O
that	O
our	O
linguistically	B-Method
-	I-Method
informed	I-Method
models	I-Method
out	O
-	O
perform	O
the	O
syntax	B-Method
-	I-Method
free	I-Method
state	O
-	O
of	O
-	O
the	O
-	O
art	O
.	O
	
On	O
CoNLL	B-Material
-	I-Material
2005	I-Material
with	O
predicted	O
predicates	O
and	O
standard	O
word	B-Method
embeddings	I-Method
,	O
our	O
single	O
model	O
out	O
-	O
performs	O
the	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
model	O
on	O
the	O
WSJ	O
test	O
set	O
by	O
2.5	O
F1	B-Metric
points	O
absolute	O
.	O
	
On	O
the	O
challenging	O
out	O
-	O
of	O
-	O
domain	O
Brown	O
test	O
set	O
,	O
our	O
model	O
improves	O
substantially	O
over	O
the	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
by	O
more	O
than	O
3.5	O
F1	B-Metric
,	O
a	O
nearly	O
10	O
%	O
reduction	O
in	O
error	B-Metric
.	O
	
On	O
CoNLL	B-Material
-	I-Material
2012	I-Material
,	O
our	O
model	O
gains	O
more	O
than	O
2.5	O
F1	B-Metric
absolute	O
over	O
the	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
.	O
	
Our	O
models	O
also	O
show	O
improvements	O
when	O
using	O
contextually	B-Method
-	I-Method
encoded	I-Method
word	I-Method
representations	I-Method
peters2018deep	O
,	O
obtaining	O
nearly	O
1.0	O
F1	B-Metric
higher	O
than	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
on	O
CoNLL	B-Material
-	I-Material
2005	I-Material
news	O
and	O
more	O
than	O
2.0	O
F1	B-Metric
improvement	O
on	O
out	O
-	O
of	O
-	O
domain	O
text	O
.	O
	
section	O
:	O
Model	O
	
[	O
scale=.8	O
]	O
no_words_simpler_compact	O
-	O
srl	O
-	O
model.pdf	O
[	O
scale=.24	O
]	O
attention	O
-	O
keynote	O
Our	O
goal	O
is	O
to	O
design	O
an	O
efficient	O
neural	B-Method
network	I-Method
model	I-Method
which	O
makes	O
use	O
of	O
linguistic	O
information	O
as	O
effectively	O
as	O
possible	O
in	O
order	O
to	O
perform	O
end	O
-	O
to	O
-	O
end	O
SRL	B-Task
.	O
	
LISA	B-Method
achieves	O
this	O
by	O
combining	O
:	O
(	O
1	O
)	O
A	O
new	O
technique	O
of	O
supervising	B-Method
neural	I-Method
attention	I-Method
to	O
predict	B-Task
syntactic	I-Task
dependencies	I-Task
with	O
(	O
2	O
)	O
multi	B-Method
-	I-Method
task	I-Method
learning	I-Method
across	O
four	O
related	O
tasks	O
.	O
	
Figure	O
[	O
reference	O
]	O
depicts	O
the	O
overall	O
architecture	O
of	O
our	O
model	O
.	O
	
The	O
basis	O
for	O
our	O
model	O
is	O
the	O
Transformer	B-Method
encoder	I-Method
introduced	O
by	O
vaswani2017attention	O
:	O
we	O
transform	O
word	B-Method
embeddings	I-Method
into	O
contextually	B-Method
-	I-Method
encoded	I-Method
token	I-Method
representations	I-Method
using	O
stacked	O
multi	B-Method
-	I-Method
head	I-Method
self	I-Method
-	I-Method
attention	I-Method
and	O
feed	B-Method
-	I-Method
forward	I-Method
layers	I-Method
(	O
§	O
[	O
reference	O
]	O
)	O
.	O
	
To	O
incorporate	O
syntax	O
,	O
one	O
self	O
-	O
attention	O
head	O
is	O
trained	O
to	O
attend	O
to	O
each	O
token	O
’s	O
syntactic	O
parent	O
,	O
allowing	O
the	O
model	O
to	O
use	O
this	O
attention	O
head	O
as	O
an	O
oracle	O
for	O
syntactic	O
dependencies	O
.	O
	
We	O
introduce	O
this	O
syntactically	O
-	O
informed	O
self	O
-	O
attention	O
(	O
Figure	O
[	O
reference	O
]	O
)	O
in	O
more	O
detail	O
in	O
§	O
[	O
reference	O
]	O
.	O
	
Our	O
model	O
is	O
designed	O
for	O
the	O
more	O
realistic	O
setting	O
in	O
which	O
gold	O
predicates	O
are	O
not	O
provided	O
at	O
test	O
-	O
time	O
.	O
	
Our	O
model	O
predicts	O
predicates	O
and	O
integrates	O
part	O
-	O
of	O
-	O
speech	O
(	O
POS	O
)	O
information	O
into	O
earlier	O
layers	O
by	O
re	O
-	O
purposing	O
representations	O
closer	O
to	O
the	O
input	O
to	O
predict	O
predicate	O
and	O
POS	O
tags	O
using	O
hard	B-Method
parameter	I-Method
sharing	I-Method
(	O
§	O
[	O
reference	O
]	O
)	O
.	O
	
We	O
simplify	O
optimization	B-Task
and	O
benefit	O
from	O
shared	O
statistical	O
strength	O
derived	O
from	O
highly	O
correlated	O
POS	O
and	O
predicates	O
by	O
treating	O
tagging	B-Task
and	I-Task
predicate	I-Task
detection	I-Task
as	O
a	O
single	O
task	O
,	O
performing	O
multi	B-Task
-	I-Task
class	I-Task
classification	I-Task
into	O
the	O
joint	O
Cartesian	O
product	O
space	O
of	O
POS	O
and	O
predicate	O
labels	O
.	O
	
Though	O
typical	O
models	O
,	O
which	O
re	O
-	O
encode	O
the	O
sentence	O
for	O
each	O
predicate	O
,	O
can	O
simplify	O
SRL	B-Task
to	O
token	B-Task
-	I-Task
wise	I-Task
tagging	I-Task
,	O
our	O
joint	B-Method
model	I-Method
requires	O
a	O
different	O
approach	O
to	O
classify	O
roles	O
with	O
respect	O
to	O
each	O
predicate	O
.	O
	
Contextually	O
encoded	O
tokens	O
are	O
projected	O
to	O
distinct	O
predicate	O
and	O
role	O
embeddings	O
(	O
§	O
[	O
reference	O
]	O
)	O
,	O
and	O
each	O
predicted	O
predicate	O
is	O
scored	O
with	O
the	O
sequence	B-Method
’s	I-Method
role	I-Method
representations	I-Method
using	O
a	O
bilinear	B-Method
model	I-Method
(	O
Eqn	O
.	O
	
[	O
reference	O
]	O
)	O
,	O
producing	O
per	O
-	O
label	O
scores	O
for	O
BIO	O
-	O
encoded	O
semantic	O
role	O
labels	O
for	O
each	O
token	O
and	O
each	O
semantic	O
frame	O
.	O
	
The	O
model	O
is	O
trained	O
end	O
-	O
to	O
-	O
end	O
by	O
maximum	B-Method
likelihood	I-Method
using	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
(	O
§	O
[	O
reference	O
]	O
)	O
.	O
	
subsection	O
:	O
Self	B-Method
-	I-Method
attention	I-Method
token	I-Method
encoder	I-Method
	
The	O
basis	O
for	O
our	O
model	O
is	O
a	O
multi	B-Method
-	I-Method
head	I-Method
self	I-Method
-	I-Method
attention	I-Method
token	I-Method
encoder	I-Method
,	O
recently	O
shown	O
to	O
achieve	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
SRL	B-Task
tan2018deep	O
,	O
and	O
which	O
provides	O
a	O
natural	O
mechanism	O
for	O
incorporating	O
syntax	O
,	O
as	O
described	O
in	O
§	O
[	O
reference	O
]	O
.	O
	
Our	O
implementation	O
replicates	O
vaswani2017attention	O
.	O
	
The	O
input	O
to	O
the	O
network	O
is	O
a	O
sequence	B-Method
of	I-Method
token	I-Method
representations	I-Method
.	O
	
In	O
the	O
standard	O
setting	O
these	O
token	B-Method
representations	I-Method
are	O
initialized	O
to	O
pre	O
-	O
trained	O
word	B-Method
embeddings	I-Method
,	O
but	O
we	O
also	O
experiment	O
with	O
supplying	O
pre	O
-	O
trained	O
ELMo	B-Method
representations	I-Method
combined	O
with	O
task	O
-	O
specific	O
learned	O
parameters	O
,	O
which	O
have	O
been	O
shown	O
to	O
substantially	O
improve	O
performance	O
of	O
other	O
SRL	B-Task
models	I-Task
peters2018deep	O
.	O
	
For	O
experiments	O
with	O
gold	O
predicates	O
,	O
we	O
concatenate	O
a	O
predicate	B-Method
indicator	I-Method
embedding	I-Method
following	O
previous	O
work	O
he2017deep	O
.	O
	
We	O
project	O
these	O
input	O
embeddings	O
to	O
a	O
representation	O
that	O
is	O
the	O
same	O
size	O
as	O
the	O
output	O
of	O
the	O
self	B-Method
-	I-Method
attention	I-Method
layers	I-Method
.	O
	
We	O
then	O
add	O
a	O
positional	O
encoding	O
vector	O
computed	O
as	O
a	O
deterministic	O
sinusoidal	O
function	O
of	O
,	O
since	O
the	O
self	B-Method
-	I-Method
attention	I-Method
has	O
no	O
innate	O
notion	O
of	O
token	O
position	O
.	O
	
We	O
feed	O
this	O
token	B-Method
representation	I-Method
as	O
input	O
to	O
a	O
series	O
of	O
residual	B-Method
multi	I-Method
-	I-Method
head	I-Method
self	I-Method
-	I-Method
attention	I-Method
layers	I-Method
with	O
feed	B-Method
-	I-Method
forward	I-Method
connections	I-Method
.	O
	
Denoting	O
the	O
th	O
self	O
-	O
attention	O
layer	O
as	O
,	O
the	O
output	O
of	O
that	O
layer	O
,	O
and	O
layer	B-Method
normalization	I-Method
,	O
the	O
following	O
recurrence	O
applied	O
to	O
initial	O
input	O
:	O
s_t^	O
(	O
j	O
)	O
	
=	O
LN	O
(	O
s_t^	O
(	O
j	O
-	O
1	O
)	O
+	O
T^	O
(	O
j	O
)(	O
s_t^	O
(	O
j	O
-	O
1	O
)	O
)	O
)	O
gives	O
our	O
final	O
token	B-Method
representations	I-Method
.	O
	
Each	O
consists	O
of	O
:	O
(	O
a	O
)	O
multi	B-Method
-	I-Method
head	I-Method
self	I-Method
-	I-Method
attention	I-Method
and	O
(	O
b	O
)	O
a	O
feed	B-Method
-	I-Method
forward	I-Method
projection	I-Method
.	O
	
The	O
multi	B-Task
-	I-Task
head	I-Task
self	I-Task
attention	I-Task
consists	O
of	O
attention	O
heads	O
,	O
each	O
of	O
which	O
learns	O
a	O
distinct	O
attention	O
function	O
to	O
attend	O
to	O
all	O
of	O
the	O
tokens	O
in	O
the	O
sequence	O
.	O
	
This	O
self	B-Method
-	I-Method
attention	I-Method
is	O
performed	O
for	O
each	O
token	O
for	O
each	O
head	O
,	O
and	O
the	O
results	O
of	O
the	O
self	O
-	O
attentions	O
are	O
concatenated	O
to	O
form	O
the	O
final	O
self	B-Method
-	I-Method
attended	I-Method
representation	I-Method
for	O
each	O
token	O
.	O
	
Specifically	O
,	O
consider	O
the	O
matrix	B-Method
of	I-Method
token	I-Method
representations	I-Method
at	O
layer	O
.	O
	
For	O
each	O
attention	O
head	O
,	O
we	O
project	O
this	O
matrix	O
into	O
distinct	O
key	O
,	O
value	B-Method
and	I-Method
query	I-Method
representations	I-Method
,	O
and	O
of	O
dimensions	O
,	O
,	O
and	O
,	O
respectively	O
.	O
	
We	O
can	O
then	O
multiply	O
by	O
to	O
obtain	O
a	O
matrix	O
of	O
attention	O
weights	O
between	O
each	O
pair	O
of	O
tokens	O
in	O
the	O
sentence	O
.	O
	
Following	O
vaswani2017attention	O
we	O
perform	O
scaled	B-Method
dot	I-Method
-	I-Method
product	I-Method
attention	I-Method
:	O
We	O
scale	O
the	O
weights	O
by	O
the	O
inverse	O
square	O
root	O
of	O
their	O
embedding	O
dimension	O
and	O
normalize	O
with	O
the	O
softmax	O
function	O
to	O
produce	O
a	O
distinct	O
distribution	O
for	O
each	O
token	O
over	O
all	O
the	O
tokens	O
in	O
the	O
sentence	O
:	O
A_h^	O
(	O
j	O
)	O
=	O
softmax	O
(	O
d_k^	O
-	O
0.5Q_h^	O
(	O
j	O
)	O
K_h^	O
(	O
j	O
)	O
^T	O
)	O
	
These	O
attention	O
weights	O
are	O
then	O
multiplied	O
by	O
for	O
each	O
token	O
to	O
obtain	O
the	O
self	B-Method
-	I-Method
attended	I-Method
token	I-Method
representations	I-Method
:	O
M_h^	O
(	O
j	O
)	O
	
=	O
A_h^	O
(	O
j	O
)	O
V_h^	O
(	O
j	O
)	O
	
Row	O
of	O
,	O
the	O
self	B-Method
-	I-Method
attended	I-Method
representation	I-Method
for	O
token	O
at	O
layer	O
,	O
is	O
thus	O
the	O
weighted	O
sum	O
with	O
respect	O
to	O
(	O
with	O
weights	O
given	O
by	O
)	O
over	O
the	O
token	B-Method
representations	I-Method
in	O
.	O
	
The	O
outputs	O
of	O
all	O
attention	O
heads	O
for	O
each	O
token	O
are	O
concatenated	O
,	O
and	O
this	O
representation	O
is	O
passed	O
to	O
the	O
feed	B-Method
-	I-Method
forward	I-Method
layer	I-Method
,	O
which	O
consists	O
of	O
two	O
linear	B-Method
projections	I-Method
each	O
followed	O
by	O
leaky	B-Method
ReLU	I-Method
activations	I-Method
maas2012rectifier	I-Method
.	O
	
We	O
add	O
the	O
output	O
of	O
the	O
feed	B-Method
-	I-Method
forward	I-Method
to	O
the	O
initial	O
representation	O
and	O
apply	O
layer	B-Method
normalization	I-Method
to	O
give	O
the	O
final	O
output	O
of	O
self	B-Method
-	I-Method
attention	I-Method
layer	I-Method
,	O
as	O
in	O
Eqn	O
.	O
	
[	O
reference	O
]	O
.	O
	
subsection	O
:	O
Syntactically	O
-	O
informed	O
self	O
-	O
attention	O
	
Typically	O
,	O
neural	B-Method
attention	I-Method
mechanisms	I-Method
are	O
left	O
on	O
their	O
own	O
to	O
learn	O
to	O
attend	O
to	O
relevant	O
inputs	O
.	O
	
Instead	O
,	O
we	O
propose	O
training	O
the	O
self	O
-	O
attention	O
to	O
attend	O
to	O
specific	O
tokens	O
corresponding	O
to	O
the	O
syntactic	O
structure	O
of	O
the	O
sentence	O
as	O
a	O
mechanism	O
for	O
passing	O
linguistic	O
knowledge	O
to	O
later	O
layers	O
.	O
	
Specifically	O
,	O
we	O
replace	O
one	O
attention	O
head	O
with	O
the	O
deep	B-Method
bi	I-Method
-	I-Method
affine	I-Method
model	I-Method
of	O
dozat2017deep	O
,	O
trained	O
to	O
predict	O
syntactic	O
dependencies	O
.	O
	
Let	O
be	O
the	O
parse	O
attention	O
weights	O
,	O
at	O
layer	O
.	O
	
Its	O
input	O
is	O
the	O
matrix	B-Method
of	I-Method
token	I-Method
representations	I-Method
.	O
	
As	O
with	O
the	O
other	O
attention	O
heads	O
,	O
we	O
project	O
into	O
key	O
,	O
value	O
and	O
query	B-Method
representations	I-Method
,	O
denoted	O
,	O
,	O
.	O
	
Here	O
the	O
key	O
and	O
query	O
projections	O
correspond	O
to	O
and	O
representations	O
of	O
the	O
tokens	O
,	O
and	O
we	O
allow	O
their	O
dimensions	O
to	O
differ	O
from	O
the	O
rest	O
of	O
the	O
attention	O
heads	O
to	O
more	O
closely	O
follow	O
the	O
implementation	O
of	O
dozat2017deep	O
.	O
	
Unlike	O
the	O
other	O
attention	B-Method
heads	I-Method
which	O
use	O
a	O
dot	B-Method
product	I-Method
to	O
score	O
key	O
-	O
query	O
pairs	O
,	O
we	O
score	O
the	O
compatibility	O
between	O
and	O
using	O
a	O
bi	O
-	O
affine	O
operator	O
to	O
obtain	O
attention	O
weights	O
:	O
A_parse	O
=	O
	
softmax	O
(	O
Q_parse	O
	
U_heads	O
K_parse^T	O
)	O
	
These	O
attention	O
weights	O
are	O
used	O
to	O
compose	O
a	O
weighted	B-Method
average	I-Method
of	I-Method
the	I-Method
value	I-Method
representations	I-Method
as	O
in	O
the	O
other	O
attention	O
heads	O
.	O
	
We	O
apply	O
auxiliary	O
supervision	O
at	O
this	O
attention	O
head	O
to	O
encourage	O
it	O
to	O
attend	O
to	O
each	O
token	O
’s	O
parent	O
in	O
a	O
syntactic	O
dependency	O
tree	O
,	O
and	O
to	O
encode	O
information	O
about	O
the	O
token	O
’s	O
dependency	O
label	O
.	O
	
Denoting	O
the	O
attention	O
weight	O
from	O
token	O
to	O
a	O
candidate	O
head	O
as	O
,	O
we	O
model	O
the	O
probability	O
of	O
token	O
having	O
parent	O
as	O
:	O
P	O
(	O
q	O
=	O
head	O
(	O
t	O
)	O
X	O
)	O
=	O
	
A_parse	O
[	O
t	O
,	O
q	O
]	O
using	O
the	O
attention	O
weights	O
as	O
the	O
distribution	O
over	O
possible	O
heads	O
for	O
token	O
.	O
	
We	O
define	O
the	O
root	O
token	O
as	O
having	O
a	O
self	O
-	O
loop	O
.	O
	
This	O
attention	O
head	O
thus	O
emits	O
a	O
directed	O
graph	O
where	O
each	O
token	O
’s	O
parent	O
is	O
the	O
token	O
to	O
which	O
the	O
attention	O
assigns	O
the	O
highest	O
weight	O
.	O
	
We	O
also	O
predict	O
dependency	O
labels	O
using	O
per	O
-	O
class	O
bi	O
-	O
affine	O
operations	O
between	O
parent	B-Method
and	I-Method
dependent	I-Method
representations	I-Method
and	O
to	O
produce	O
per	O
-	O
label	O
scores	O
,	O
with	O
locally	O
normalized	O
probabilities	O
over	O
dependency	O
labels	O
given	O
by	O
the	O
softmax	B-Method
function	I-Method
.	O
	
We	O
refer	O
the	O
reader	O
to	O
dozat2017deep	O
for	O
more	O
details	O
.	O
	
This	O
attention	O
head	O
now	O
becomes	O
an	O
oracle	O
for	O
syntax	B-Task
,	O
denoted	O
,	O
providing	O
a	O
dependency	B-Method
parse	I-Method
to	O
downstream	O
layers	O
.	O
	
This	O
model	O
not	O
only	O
predicts	O
its	O
own	O
dependency	O
arcs	O
,	O
but	O
allows	O
for	O
the	O
injection	O
of	O
auxiliary	O
parse	O
information	O
at	O
test	O
time	O
by	O
simply	O
setting	O
to	O
the	O
parse	O
parents	O
produced	O
by	O
e.g.	O
a	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
parser	B-Method
.	O
	
In	O
this	O
way	O
,	O
our	O
model	O
can	O
benefit	O
from	O
improved	O
,	O
external	B-Method
parsing	I-Method
models	I-Method
without	O
re	O
-	O
training	O
.	O
	
Unlike	O
typical	O
multi	B-Method
-	I-Method
task	I-Method
models	I-Method
,	O
ours	O
maintains	O
the	O
ability	O
to	O
leverage	O
external	O
syntactic	O
information	O
.	O
	
subsection	O
:	O
Multi	B-Task
-	I-Task
task	I-Task
learning	I-Task
	
We	O
also	O
share	O
the	O
parameters	O
of	O
lower	O
layers	O
in	O
our	O
model	O
to	O
predict	O
POS	O
tags	O
and	O
predicates	O
.	O
	
Following	O
he2017deep	O
,	O
we	O
focus	O
on	O
the	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
setting	I-Task
,	O
where	O
predicates	O
must	O
be	O
predicted	O
on	O
-	O
the	O
-	O
fly	O
.	O
	
Since	O
we	O
also	O
train	O
our	O
model	O
to	O
predict	O
syntactic	O
dependencies	O
,	O
it	O
is	O
beneficial	O
to	O
give	O
the	O
model	O
knowledge	O
of	O
POS	O
information	O
.	O
	
While	O
much	O
previous	O
work	O
employs	O
a	O
pipelined	B-Method
approach	I-Method
to	O
both	O
POS	B-Task
tagging	I-Task
for	O
dependency	B-Task
parsing	I-Task
and	O
predicate	B-Task
detection	I-Task
for	O
SRL	B-Task
,	O
we	O
take	O
a	O
multi	B-Method
-	I-Method
task	I-Method
learning	I-Method
(	O
MTL	B-Task
)	O
approach	O
caruana1993multitask	O
,	O
sharing	O
the	O
parameters	O
of	O
earlier	O
layers	O
in	O
our	O
SRL	B-Task
model	I-Task
with	O
a	O
joint	O
POS	O
and	O
predicate	B-Task
detection	I-Task
objective	I-Task
.	O
	
Since	O
POS	O
is	O
a	O
strong	O
predictor	O
of	O
predicates	O
and	O
the	O
complexity	B-Metric
of	O
training	O
a	O
multi	B-Method
-	I-Method
task	I-Method
model	I-Method
increases	O
with	O
the	O
number	O
of	O
tasks	O
,	O
we	O
combine	O
POS	B-Task
tagging	I-Task
and	O
predicate	B-Task
detection	I-Task
into	O
a	O
joint	O
label	O
space	O
:	O
For	O
each	O
POS	O
tag	O
tag	O
which	O
is	O
observed	O
co	O
-	O
occurring	O
with	O
a	O
predicate	O
,	O
we	O
add	O
a	O
label	O
of	O
the	O
form	O
tag	O
:	O
predicate	O
.	O
	
Specifically	O
,	O
we	O
feed	O
the	O
representation	O
from	O
a	O
layer	O
preceding	O
the	O
syntactically	B-Method
-	I-Method
informed	I-Method
layer	I-Method
to	O
a	O
linear	B-Method
classifier	I-Method
to	O
produce	O
per	B-Metric
-	I-Metric
class	I-Metric
scores	I-Metric
for	O
token	B-Task
.	O
	
We	O
compute	O
locally	O
-	O
normalized	O
probabilities	O
using	O
the	O
softmax	O
function	O
:	O
,	O
where	O
is	O
a	O
label	O
in	O
the	O
joint	O
space	O
.	O
	
subsection	O
:	O
Predicting	B-Task
semantic	I-Task
roles	I-Task
	
Our	O
final	O
goal	O
is	O
to	O
predict	O
semantic	O
roles	O
for	O
each	O
predicate	O
in	O
the	O
sequence	O
.	O
	
We	O
score	O
each	O
predicate	O
against	O
each	O
token	O
in	O
the	O
sequence	O
using	O
a	O
bilinear	B-Method
operation	I-Method
,	O
producing	O
per	O
-	O
label	O
scores	O
for	O
each	O
token	O
for	O
each	O
predicate	O
,	O
with	O
predicates	O
and	O
syntax	O
determined	O
by	O
oracles	O
and	O
.	O
	
First	O
,	O
we	O
project	O
each	O
token	B-Method
representation	I-Method
to	O
a	O
predicate	B-Method
-	I-Method
specific	I-Method
representation	I-Method
and	O
a	O
role	B-Method
-	I-Method
specific	I-Method
representation	I-Method
.	O
	
We	O
then	O
provide	O
these	O
representations	O
to	O
a	O
bilinear	B-Method
transformation	I-Method
for	O
scoring	B-Task
.	O
	
So	O
,	O
the	O
role	O
label	O
scores	O
for	O
the	O
token	O
at	O
index	O
with	O
respect	O
to	O
the	O
predicate	O
at	O
index	O
(	O
i.e.	O
token	O
and	O
frame	O
)	O
are	O
given	O
by	O
:	O
s_ft	O
=	O
	
(	O
s_f^pred	O
)	O
^T	O
	
U	O
s_t^role	O
which	O
can	O
be	O
computed	O
in	O
parallel	O
across	O
all	O
semantic	O
frames	O
in	O
an	O
entire	O
minibatch	O
.	O
	
We	O
calculate	O
a	O
locally	O
normalized	O
distribution	O
over	O
role	O
labels	O
for	O
token	O
in	O
frame	O
using	O
the	O
softmax	B-Method
function	I-Method
:	O
.	O
	
At	O
test	O
time	O
,	O
we	O
perform	O
constrained	B-Method
decoding	I-Method
using	O
the	O
Viterbi	B-Method
algorithm	I-Method
to	O
emit	O
valid	O
sequences	O
of	O
BIO	O
tags	O
,	O
using	O
unary	O
scores	O
and	O
the	O
transition	O
probabilities	O
given	O
by	O
the	O
training	O
data	O
.	O
	
subsection	O
:	O
Training	O
	
We	O
maximize	O
the	O
sum	O
of	O
the	O
likelihoods	O
of	O
the	O
individual	O
tasks	O
.	O
	
In	O
order	O
to	O
maximize	O
our	O
model	O
’s	O
ability	O
to	O
leverage	O
syntax	O
,	O
during	O
training	O
we	O
clamp	O
to	O
the	O
gold	O
parse	O
(	O
)	O
and	O
to	O
gold	O
predicates	O
when	O
passing	O
parse	B-Method
and	I-Method
predicate	I-Method
representations	I-Method
to	O
later	O
layers	O
,	O
whereas	O
syntactic	B-Method
head	I-Method
prediction	I-Method
and	O
joint	B-Method
predicate	I-Method
/	I-Method
POS	I-Method
prediction	I-Method
are	O
conditioned	O
only	O
on	O
the	O
input	O
sequence	O
.	O
	
The	O
overall	O
objective	O
is	O
thus	O
:	O
_	O
t=1^T	O
	
[	O
Align∑	O
_	O
f=1^F	O
	
P	O
(	O
y_ft^role	O
	
P	O
_	O
G	O
,	O
V	O
_	O
G	O
,	O
X	O
)	O
	
+	O
P	O
(	O
y_t^prp	O
X	O
)	O
	
+	O
_	O
	
1	O
P	O
(	O
head	O
(	O
t	O
)	O
X	O
)	O
	
+	O
_	O
2	O
	
P	O
(	O
y_t^dep	O
	
P	O
_	O
G	O
,	O
X	O
)	O
]	O
where	O
and	O
are	O
penalties	O
on	O
the	O
syntactic	O
attention	O
loss	O
.	O
	
We	O
train	O
the	O
model	O
using	O
Nadam	B-Method
dozat2016incorporating	O
SGD	O
combined	O
with	O
the	O
learning	O
rate	O
schedule	O
in	O
vaswani2017attention	O
.	O
	
In	O
addition	O
to	O
MTL	B-Task
,	O
we	O
regularize	O
our	O
model	O
using	O
dropout	B-Method
srivastava2014dropout	O
.	O
	
We	O
use	O
gradient	B-Method
clipping	I-Method
to	O
avoid	O
exploding	O
gradients	O
bengio1994learning	O
,	O
pascanu2013on	O
.	O
	
Additional	O
details	O
on	O
optimization	B-Task
and	O
hyperparameters	O
are	O
included	O
in	O
Appendix	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
Related	O
work	O
	
Early	O
approaches	O
to	O
SRL	B-Task
pradhan2005semantic	O
,	O
surdeanu2007combination	O
,	O
johansson2008dependency	O
,	O
toutanova2008global	O
focused	O
on	O
developing	O
rich	O
sets	O
of	O
linguistic	O
features	O
as	O
input	O
to	O
a	O
linear	B-Method
model	I-Method
,	O
often	O
combined	O
with	O
complex	O
constrained	B-Method
inference	I-Method
e.g.	O
with	O
an	O
ILP	B-Task
punyakanok2008importance	O
.	O
	
tackstrom2015efficient	O
showed	O
that	O
constraints	O
could	O
be	O
enforced	O
more	O
efficiently	O
using	O
a	O
clever	B-Method
dynamic	I-Method
program	I-Method
for	O
exact	B-Task
inference	I-Task
.	O
	
sutton2005joint	B-Method
modeled	O
syntactic	B-Task
parsing	I-Task
and	O
SRL	B-Task
jointly	O
,	O
and	O
lewis2015joint	O
jointly	O
modeled	O
SRL	B-Task
and	O
CCG	B-Task
parsing	I-Task
.	O
	
collobert2011natural	O
were	O
among	O
the	O
first	O
to	O
use	O
a	O
neural	B-Method
network	I-Method
model	I-Method
for	O
SRL	B-Task
,	O
a	O
CNN	B-Method
over	O
word	B-Method
embeddings	I-Method
which	O
failed	O
to	O
out	O
-	O
perform	O
non	B-Method
-	I-Method
neural	I-Method
models	I-Method
.	O
	
fitzgerald2015semantic	O
successfully	O
employed	O
neural	B-Method
networks	I-Method
by	O
embedding	O
lexicalized	O
features	O
and	O
providing	O
them	O
as	O
factors	O
in	O
the	O
model	O
of	O
tackstrom2015efficient	O
.	O
	
More	O
recent	O
neural	B-Method
models	I-Method
are	O
syntax	O
-	O
free	O
.	O
	
zhou2015end	O
	
,	O
marcheggiani2017simple	O
and	O
he2017deep	O
all	O
use	O
variants	O
of	O
deep	B-Method
LSTMs	I-Method
with	O
constrained	B-Method
decoding	I-Method
,	O
while	O
tan2018deep	O
apply	O
self	B-Method
-	I-Method
attention	I-Method
to	O
obtain	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
SRL	B-Task
with	O
gold	O
predicates	O
.	O
	
Like	O
this	O
work	O
,	O
he2017deep	O
present	O
end	O
-	O
to	O
-	O
end	O
experiments	O
,	O
predicting	B-Task
predicates	I-Task
using	O
an	O
LSTM	B-Method
,	O
and	O
he2018jointly	O
jointly	O
predict	O
SRL	B-Task
spans	O
and	O
predicates	O
in	O
a	O
model	O
based	O
on	O
that	O
of	O
lee2017end	O
,	O
obtaining	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
predicted	O
predicate	O
SRL	B-Task
.	O
	
Concurrent	O
to	O
this	O
work	O
,	O
peters2018deep	O
and	O
he2018jointly	O
report	O
significant	O
gains	O
on	O
PropBank	O
SRL	B-Task
by	O
training	O
a	O
wide	B-Method
LSTM	I-Method
language	I-Method
model	I-Method
and	O
using	O
a	O
task	O
-	O
specific	O
transformation	O
of	O
its	O
hidden	B-Method
representations	I-Method
(	O
ELMo	B-Method
)	O
as	O
a	O
deep	O
,	O
and	O
computationally	O
expensive	O
,	O
alternative	O
to	O
typical	O
word	B-Method
embeddings	I-Method
.	O
	
We	O
find	O
that	O
LISA	B-Method
obtains	O
further	O
accuracy	B-Metric
increases	O
when	O
provided	O
with	O
ELMo	B-Method
word	I-Method
representations	I-Method
,	O
especially	O
on	O
out	O
-	O
of	O
-	O
domain	O
data	O
.	O
	
Some	O
work	O
has	O
incorporated	O
syntax	O
into	O
neural	B-Method
models	I-Method
for	O
SRL	B-Task
.	O
	
roth2016neural	O
incorporate	O
syntax	O
by	O
embedding	O
dependency	O
paths	O
,	O
and	O
similarly	O
marcheggiani2017encoding	O
encode	O
syntax	O
using	O
a	O
graph	B-Method
CNN	I-Method
over	O
a	O
predicted	O
syntax	O
tree	O
,	O
out	O
-	O
performing	O
models	O
without	O
syntax	O
on	O
CoNLL	O
-	O
2009	O
.	O
	
These	O
works	O
are	O
limited	O
to	O
incorporating	O
partial	O
dependency	O
paths	O
between	O
tokens	O
whereas	O
our	O
technique	O
incorporates	O
the	O
entire	O
parse	O
.	O
	
Additionally	O
,	O
marcheggiani2017encoding	O
report	O
that	O
their	O
model	O
does	O
not	O
out	O
-	O
perform	O
syntax	B-Method
-	I-Method
free	I-Method
models	I-Method
on	O
out	O
-	O
of	O
-	O
domain	O
data	O
,	O
a	O
setting	O
in	O
which	O
our	O
technique	O
excels	O
.	O
	
MTL	B-Task
caruana1993multitask	O
is	O
popular	O
in	O
NLP	B-Task
,	O
and	O
others	O
have	O
proposed	O
MTL	B-Task
models	O
which	O
incorporate	O
subsets	O
of	O
the	O
tasks	O
we	O
do	O
collobert2011natural	O
,	O
zhang2016stack	O
,	O
hashimoto2017joint	O
,	O
peng2017deep	O
,	O
swayamdipta2017	O
,	O
and	O
we	O
build	O
off	O
work	O
that	O
investigates	O
where	O
and	O
when	O
to	O
combine	O
different	O
tasks	O
to	O
achieve	O
the	O
best	O
results	O
sogaard2016deep	O
,	O
bingel2017identifying	O
,	O
alonso2017when	O
.	O
	
Our	O
specific	O
method	O
of	O
incorporating	O
supervision	B-Task
into	O
self	B-Task
-	I-Task
attention	I-Task
is	O
most	O
similar	O
to	O
the	O
concurrent	O
work	O
of	O
liu2018learning	O
,	O
who	O
use	O
edge	O
marginals	O
produced	O
by	O
the	O
matrix	B-Method
-	I-Method
tree	I-Method
algorithm	I-Method
as	O
attention	O
weights	O
for	O
document	B-Task
classification	I-Task
and	O
natural	B-Task
language	I-Task
inference	I-Task
.	O
	
The	O
question	O
of	O
training	O
on	O
gold	O
versus	O
predicted	O
labels	O
is	O
closely	O
related	O
to	O
learning	O
to	O
search	B-Task
daume2009search	O
,	O
ross2011reduction	O
,	O
chang2015learning	O
and	O
scheduled	B-Task
sampling	I-Task
bengio2015scheduled	O
,	O
with	O
applications	O
in	O
NLP	B-Task
to	O
sequence	B-Task
labeling	I-Task
and	O
transition	B-Task
-	I-Task
based	I-Task
parsing	I-Task
choi2011getting	O
,	O
goldberg2012dynamic	O
,	O
ballesteros2016training	O
.	O
	
Our	O
approach	O
may	O
be	O
interpreted	O
as	O
an	O
extension	O
of	O
teacher	B-Method
forcing	I-Method
williams1989learning	O
to	O
MTL	B-Task
.	O
	
We	O
leave	O
exploration	O
of	O
more	O
advanced	O
scheduled	B-Method
sampling	I-Method
techniques	I-Method
to	O
future	O
work	O
.	O
	
section	O
:	O
Experimental	O
results	O
	
We	O
present	O
results	O
on	O
the	O
CoNLL	B-Material
-	I-Material
2005	I-Material
shared	O
task	O
carreras2005introduction	O
and	O
the	O
CoNLL	B-Material
-	I-Material
2012	I-Material
English	I-Material
subset	I-Material
of	O
OntoNotes	O
5.0	O
pradhan2013towards	O
,	O
achieving	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
for	O
a	O
single	O
model	O
with	O
predicted	O
predicates	O
on	O
both	O
corpora	O
.	O
	
We	O
experiment	O
with	O
both	O
standard	O
pre	B-Method
-	I-Method
trained	I-Method
GloVe	I-Method
word	I-Method
embeddings	I-Method
pennington2014glove	O
and	O
	
pre	O
-	O
trained	O
ELMo	B-Method
representations	I-Method
with	O
fine	O
-	O
tuned	O
task	O
-	O
specific	O
parameters	O
peters2018deep	O
in	O
order	O
to	O
best	O
compare	O
to	O
prior	O
work	O
.	O
	
Hyperparameters	B-Method
that	O
resulted	O
in	O
the	O
best	O
performance	O
on	O
the	O
validation	O
set	O
were	O
selected	O
via	O
a	O
small	O
grid	B-Method
search	I-Method
,	O
and	O
models	O
were	O
trained	O
for	O
a	O
maximum	O
of	O
4	O
days	O
on	O
one	O
TitanX	O
GPU	O
using	O
early	O
stopping	O
on	O
the	O
validation	O
set	O
.	O
	
We	O
convert	O
constituencies	O
to	O
dependencies	O
using	O
the	O
Stanford	O
head	O
rules	O
v3.5	O
deMarneffe2008	O
.	O
	
A	O
detailed	O
description	O
of	O
hyperparameter	O
settings	O
and	O
data	B-Task
pre	I-Task
-	I-Task
processing	I-Task
can	O
be	O
found	O
in	O
Appendix	O
[	O
reference	O
]	O
.	O
	
We	O
compare	O
our	O
LISA	B-Method
models	O
to	O
four	O
strong	O
baselines	O
:	O
For	O
experiments	O
using	O
predicted	O
predicates	O
,	O
we	O
compare	O
to	O
he2018jointly	O
and	O
the	O
ensemble	B-Method
model	I-Method
(	O
PoE	B-Method
)	O
from	O
he2017deep	O
,	O
as	O
well	O
as	O
a	O
version	O
of	O
our	O
own	O
self	B-Method
-	I-Method
attention	I-Method
model	I-Method
which	O
does	O
not	O
incorporate	O
syntactic	O
information	O
(	O
SA	B-Method
)	O
.	O
	
To	O
compare	O
to	O
more	O
prior	O
work	O
,	O
we	O
present	O
additional	O
results	O
on	O
CoNLL	B-Material
-	I-Material
2005	I-Material
with	O
models	O
given	O
gold	O
predicates	O
at	O
test	O
time	O
.	O
	
In	O
these	O
experiments	O
we	O
also	O
compare	O
to	O
tan2018deep	O
,	O
the	O
previous	O
state	O
-	O
of	O
-	O
the	O
art	O
SRL	B-Task
model	I-Task
using	O
gold	O
predicates	O
and	O
standard	O
embeddings	B-Method
.	O
	
We	O
demonstrate	O
that	O
our	O
models	O
benefit	O
from	O
injecting	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
predicted	O
parses	O
at	O
test	O
time	O
(	O
+	O
D	O
&	O
M	O
)	O
by	O
fixing	O
the	O
attention	O
to	O
parses	O
predicted	O
by	O
dozat2017deep	O
,	O
the	O
winner	O
of	O
the	O
2017	O
CoNLL	B-Task
shared	I-Task
task	I-Task
zeman2017conll	O
which	O
we	O
re	O
-	O
train	O
using	O
ELMo	B-Method
embeddings	I-Method
.	O
	
In	O
all	O
cases	O
,	O
using	O
these	O
parses	O
at	O
test	O
time	O
improves	O
performance	O
.	O
	
We	O
also	O
evaluate	O
our	O
model	O
using	O
the	O
gold	O
syntactic	O
parse	O
at	O
test	O
time	O
(	O
+	O
Gold	O
)	O
,	O
to	O
provide	O
an	O
upper	O
bound	O
for	O
the	O
benefit	O
that	O
syntax	O
could	O
have	O
for	O
SRL	B-Task
using	O
LISA	B-Method
.	O
	
These	O
experiments	O
show	O
that	O
despite	O
LISA	B-Method
’s	O
strong	O
performance	O
,	O
there	O
remains	O
substantial	O
room	O
for	O
improvement	O
.	O
	
In	O
§	O
[	O
reference	O
]	O
we	O
perform	O
further	O
analysis	O
comparing	O
SRL	B-Task
models	I-Task
using	O
gold	O
and	O
predicted	O
parses	O
.	O
	
subsection	O
:	O
Semantic	B-Task
role	I-Task
labeling	I-Task
	
Table	O
[	O
reference	O
]	O
lists	O
precision	B-Metric
,	O
recall	B-Metric
and	O
F1	B-Metric
on	O
the	O
CoNLL	B-Material
-	I-Material
2005	I-Material
development	O
and	O
test	O
sets	O
using	O
predicted	O
predicates	O
.	O
	
For	O
models	O
using	O
GloVe	B-Method
embeddings	I-Method
,	O
our	O
syntax	O
-	O
free	O
SA	B-Method
model	O
already	O
achieves	O
a	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
by	O
jointly	O
predicting	B-Task
predicates	I-Task
,	O
POS	O
and	O
SRL	B-Task
.	O
	
LISA	B-Method
with	O
its	O
own	O
parses	B-Method
performs	O
comparably	O
to	O
SA	B-Method
,	O
but	O
when	O
supplied	O
with	O
D	O
&	O
M	O
parses	O
LISA	B-Method
out	O
-	O
performs	O
the	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
by	O
2.5	O
F1	B-Metric
points	O
.	O
	
On	O
the	O
out	B-Material
-	I-Material
of	I-Material
-	I-Material
domain	I-Material
Brown	I-Material
test	I-Material
set	I-Material
,	O
LISA	B-Method
also	O
performs	O
comparably	O
to	O
its	O
syntax	B-Method
-	I-Method
free	I-Method
counterpart	I-Method
with	O
its	O
own	O
parses	O
,	O
but	O
with	O
D	O
&	O
M	O
parses	O
LISA	B-Method
performs	O
exceptionally	O
well	O
,	O
more	O
than	O
3.5	O
F1	B-Metric
points	O
higher	O
than	O
he2018jointly	O
.	O
	
Incorporating	O
ELMo	B-Method
embeddings	I-Method
improves	O
all	O
scores	O
.	O
	
The	O
gap	O
in	O
SRL	B-Task
F1	I-Metric
between	O
models	O
using	O
LISA	B-Method
and	O
D	O
&	O
M	O
parses	O
is	O
smaller	O
due	O
to	O
LISA	B-Method
’s	O
improved	O
parsing	B-Metric
accuracy	I-Metric
(	O
see	O
§	O
[	O
reference	O
]	O
)	O
,	O
but	O
LISA	B-Method
with	O
D	O
&	O
M	O
parses	O
still	O
achieves	O
the	O
highest	O
F1	B-Metric
:	O
nearly	O
1.0	O
absolute	O
F1	B-Metric
higher	O
than	O
the	O
previous	O
state	O
-	O
of	O
-	O
the	O
art	O
on	O
WSJ	B-Method
,	O
and	O
more	O
than	O
2.0	O
F1	B-Metric
higher	O
on	O
Brown	O
.	O
	
In	O
both	O
settings	O
LISA	B-Method
leverages	O
domain	O
-	O
agnostic	O
syntactic	O
information	O
rather	O
than	O
over	O
-	O
fitting	O
to	O
the	O
newswire	O
training	O
data	O
which	O
leads	O
to	O
high	O
performance	O
even	O
on	O
out	O
-	O
of	O
-	O
domain	O
text	O
.	O
	
To	O
compare	O
to	O
more	O
prior	O
work	O
we	O
also	O
evaluate	O
our	O
models	O
in	O
the	O
artificial	B-Task
setting	I-Task
where	O
gold	O
predicates	O
are	O
provided	O
at	O
test	O
time	O
.	O
	
For	O
fair	O
comparison	O
we	O
use	O
GloVe	B-Method
embeddings	I-Method
,	O
provide	O
predicate	B-Method
indicator	I-Method
embeddings	I-Method
on	O
the	O
input	O
and	O
re	O
-	O
encode	O
the	O
sequence	O
relative	O
to	O
each	O
gold	O
predicate	O
.	O
	
Here	O
LISA	B-Method
still	O
excels	O
:	O
with	O
D	B-Method
&	I-Method
M	I-Method
parses	I-Method
,	O
LISA	B-Method
out	O
-	O
performs	O
the	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
by	O
more	O
than	O
2	O
F1	B-Metric
on	O
both	O
WSJ	O
and	O
Brown	O
.	O
	
Table	O
[	O
reference	O
]	O
reports	O
precision	B-Metric
,	O
recall	B-Metric
and	O
F1	B-Metric
on	O
the	O
CoNLL	B-Material
-	I-Material
2012	I-Material
test	I-Material
set	I-Material
.	O
	
We	O
observe	O
performance	O
similar	O
to	O
that	O
observed	O
on	O
ConLL	B-Material
-	I-Material
2005	I-Material
:	O
	
Using	O
GloVe	B-Method
embeddings	I-Method
our	O
SA	B-Method
baseline	O
already	O
out	O
-	O
performs	O
he2018jointly	O
by	O
nearly	O
1.5	O
F1	B-Metric
.	O
	
With	O
its	O
own	O
parses	O
,	O
LISA	B-Method
slightly	O
under	O
-	O
performs	O
our	O
syntax	B-Method
-	I-Method
free	I-Method
model	I-Method
,	O
but	O
when	O
provided	O
with	O
stronger	O
D	O
&	O
M	O
parses	O
LISA	B-Method
out	O
-	O
performs	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
by	O
more	O
than	O
2.5	O
F1	B-Metric
.	O
	
Like	O
CoNLL	B-Material
-	I-Material
2005	I-Material
,	O
ELMo	B-Method
representations	I-Method
improve	O
all	O
models	O
and	O
close	O
the	O
F1	B-Metric
gap	O
between	O
models	O
supplied	O
with	O
LISA	B-Method
and	O
D	O
&	O
M	O
parses	O
.	O
	
On	O
this	O
dataset	O
ELMo	B-Method
also	O
substantially	O
narrows	O
the	O
difference	O
between	O
models	O
with	O
-	O
and	O
without	O
syntactic	O
information	O
.	O
	
This	O
suggests	O
that	O
for	O
this	O
challenging	O
dataset	O
,	O
ELMo	B-Method
already	O
encodes	O
much	O
of	O
the	O
information	O
available	O
in	O
the	O
D	B-Method
&	I-Method
M	I-Method
parses	I-Method
.	O
	
Yet	O
,	O
higher	O
accuracy	B-Metric
parses	I-Metric
could	O
still	O
yield	O
improvements	O
since	O
providing	O
gold	O
parses	O
increases	O
F1	B-Metric
by	O
4	O
points	O
even	O
with	O
ELMo	B-Method
embeddings	I-Method
.	O
	
subsection	O
:	O
Parsing	B-Task
,	O
POS	B-Task
and	I-Task
predicate	I-Task
detection	I-Task
	
We	O
first	O
report	O
the	O
labeled	B-Metric
and	I-Metric
unlabeled	I-Metric
attachment	I-Metric
scores	I-Metric
(	O
LAS	B-Metric
,	O
UAS	O
)	O
of	O
our	O
parsing	B-Method
models	I-Method
on	O
the	O
CoNLL	B-Material
-	I-Material
2005	I-Material
and	O
2012	B-Material
test	I-Material
sets	I-Material
(	O
Table	O
[	O
reference	O
]	O
)	O
with	O
GloVe	B-Method
(	O
)	O
and	O
ELMo	B-Method
(	I-Method
)	I-Method
embeddings	I-Method
.	O
	
D	B-Method
&	I-Method
M	I-Method
achieves	O
the	O
best	O
scores	O
.	O
	
Still	O
,	O
LISA	B-Method
’s	O
GloVe	O
UAS	O
is	O
comparable	O
to	O
popular	O
off	B-Method
-	I-Method
the	I-Method
-	I-Method
shelf	I-Method
dependency	I-Method
parsers	I-Method
such	O
as	O
spaCy	B-Method
,	O
and	O
with	O
ELMo	B-Method
embeddings	I-Method
comparable	O
to	O
the	O
standalone	B-Method
D	I-Method
&	I-Method
M	I-Method
parser	I-Method
.	O
	
The	O
difference	O
in	O
parse	B-Metric
accuracy	I-Metric
between	O
LISA	B-Method
and	O
D	B-Method
&	I-Method
M	I-Method
likely	O
explains	O
the	O
large	O
increase	O
in	O
SRL	B-Task
performance	O
we	O
see	O
from	O
decoding	B-Task
with	O
D	B-Method
&	I-Method
M	I-Method
parses	I-Method
in	O
that	O
setting	O
.	O
	
In	O
Table	O
[	O
reference	O
]	O
we	O
present	O
predicate	B-Metric
detection	I-Metric
precision	I-Metric
,	O
recall	B-Metric
and	O
F1	B-Metric
on	O
the	O
CoNLL	B-Material
-	I-Material
2005	I-Material
and	O
2012	B-Material
test	I-Material
sets	I-Material
.	O
	
SA	B-Method
and	O
LISA	B-Method
with	O
and	O
without	O
ELMo	B-Method
attain	O
comparable	O
scores	O
	
so	O
we	O
report	O
only	O
LISA	B-Method
+	O
GloVe	O
.	O
	
We	O
compare	O
to	O
he2017deep	O
on	O
CoNLL	B-Material
-	I-Material
2005	I-Material
,	O
the	O
only	O
cited	O
work	O
reporting	O
comparable	O
predicate	O
detection	O
F1	B-Metric
.	O
	
LISA	B-Method
attains	O
high	O
predicate	B-Metric
detection	I-Metric
scores	I-Metric
,	O
above	O
97	O
F1	B-Metric
,	O
	
on	O
both	O
in	O
-	O
domain	O
datasets	O
,	O
and	O
out	O
-	O
performs	O
he2017deep	O
by	O
1.5	O
-	O
2	O
F1	B-Metric
points	O
even	O
on	O
the	O
out	O
-	O
of	O
-	O
domain	O
Brown	O
test	O
set	O
,	O
suggesting	O
that	O
multi	B-Method
-	I-Method
task	I-Method
learning	I-Method
works	O
well	O
for	O
SRL	B-Task
predicate	O
detection	O
.	O
	
subsection	O
:	O
Analysis	O
	
First	O
we	O
assess	O
SRL	B-Task
F1	I-Metric
on	O
sentences	O
divided	O
by	O
parse	B-Metric
accuracy	I-Metric
.	O
	
Table	O
[	O
reference	O
]	O
lists	O
average	O
SRL	B-Task
F1	I-Metric
(	O
across	O
sentences	O
)	O
for	O
the	O
four	O
conditions	O
of	O
LISA	B-Method
and	O
D	O
&	O
M	O
parses	O
being	O
correct	O
or	O
not	O
(	O
L±	O
,	O
D±	O
)	O
.	O
	
Both	O
parsers	B-Method
are	O
correct	O
on	O
26	O
%	O
of	O
sentences	O
.	O
	
Here	O
there	O
is	O
little	O
difference	O
between	O
any	O
of	O
the	O
models	O
,	O
with	O
LISA	B-Method
models	O
tending	O
to	O
perform	O
slightly	O
better	O
than	O
SA	B-Method
.	O
	
Both	O
parsers	B-Method
make	O
mistakes	O
on	O
the	O
majority	O
of	O
sentences	O
(	O
57	O
%	O
)	O
,	O
difficult	O
sentences	O
where	O
SA	B-Method
also	O
performs	O
the	O
worst	O
.	O
	
These	O
examples	O
are	O
likely	O
where	O
gold	B-Method
and	I-Method
D	I-Method
&	I-Method
M	I-Method
parses	I-Method
improve	O
the	O
most	O
over	O
other	O
models	O
in	O
overall	O
F1	B-Metric
:	O
Though	O
both	O
parsers	B-Method
fail	O
to	O
correctly	O
parse	O
the	O
entire	O
sentence	O
,	O
the	O
D	B-Method
&	I-Method
M	I-Method
parser	I-Method
is	O
less	O
wrong	O
(	O
87.5	O
vs.	O
85.7	O
average	O
LAS	O
)	O
,	O
leading	O
to	O
higher	O
SRL	B-Task
F1	I-Metric
by	O
about	O
1.5	O
average	O
F1	B-Metric
.	O
	
Following	O
he2017deep	O
,	O
we	O
next	O
apply	O
a	O
series	O
of	O
corrections	O
to	O
model	B-Task
predictions	I-Task
in	O
order	O
to	O
understand	O
which	O
error	O
types	O
the	O
gold	O
parse	O
resolves	O
:	O
	
e.g.	O
Fix	O
Labels	O
fixes	O
labels	O
on	O
spans	O
matching	O
gold	O
boundaries	O
,	O
and	O
Merge	O
Spans	O
merges	O
adjacent	O
predicted	O
spans	O
into	O
a	O
gold	O
span	O
.	O
	
[	O
scale=0.52	O
]	O
errors.pdf	O
In	O
Figure	O
[	O
reference	O
]	O
we	O
see	O
that	O
much	O
of	O
the	O
performance	O
gap	O
between	O
the	O
gold	O
and	O
predicted	O
parses	O
is	O
due	O
to	O
span	O
boundary	O
errors	O
(	O
Merge	O
Spans	O
,	O
Split	O
Spans	O
and	O
Fix	O
Span	O
Boundary	O
)	O
,	O
which	O
supports	O
the	O
hypothesis	O
proposed	O
by	O
he2017deep	O
that	O
incorporating	O
syntax	O
could	O
be	O
particularly	O
helpful	O
for	O
resolving	O
these	O
errors	O
.	O
	
he2017deep	O
also	O
point	O
out	O
that	O
these	O
errors	O
are	O
due	O
mainly	O
to	O
prepositional	O
phrase	O
(	O
PP	O
)	O
attachment	O
mistakes	O
.	O
	
We	O
also	O
find	O
this	O
to	O
be	O
the	O
case	O
:	O
Figure	O
[	O
reference	O
]	O
shows	O
a	O
breakdown	O
of	O
split	O
/	O
merge	O
corrections	O
by	O
phrase	O
type	O
.	O
	
Though	O
the	O
number	O
of	O
corrections	O
decreases	O
substantially	O
across	O
phrase	O
types	O
,	O
the	O
proportion	O
of	O
corrections	O
attributed	O
to	O
PPs	O
remains	O
the	O
same	O
(	O
approx	O
.	O
	
50	O
%	O
)	O
even	O
after	O
providing	O
the	O
correct	O
PP	O
attachment	O
to	O
the	O
model	O
,	O
indicating	O
that	O
PP	O
span	O
boundary	O
mistakes	O
are	O
a	O
fundamental	O
difficulty	O
for	O
SRL	B-Task
.	O
	
[	O
scale=0.55	O
]	O
phrase_bar_percent.pdf	O
	
section	O
:	O
Conclusion	O
	
We	O
present	O
linguistically	B-Method
-	I-Method
informed	I-Method
self	I-Method
-	I-Method
attention	I-Method
:	O
a	O
multi	O
-	O
task	O
neural	B-Method
network	I-Method
model	I-Method
that	O
effectively	O
incorporates	O
rich	O
linguistic	O
information	O
for	O
semantic	B-Task
role	I-Task
labeling	I-Task
.	O
	
LISA	B-Method
out	O
-	O
performs	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
on	O
two	O
benchmark	O
SRL	B-Task
datasets	O
,	O
including	O
out	O
-	O
of	O
-	O
domain	O
.	O
	
Future	O
work	O
will	O
explore	O
improving	O
LISA	B-Method
’s	O
parsing	O
accuracy	O
,	O
developing	O
better	O
training	B-Method
techniques	I-Method
and	O
adapting	O
to	O
more	O
tasks	O
.	O
	
section	O
:	O
Acknowledgments	O
	
We	O
are	O
grateful	O
to	O
Luheng	O
He	O
for	O
helpful	O
discussions	O
and	O
code	O
,	O
Timothy	O
Dozat	O
for	O
sharing	O
his	O
code	O
,	O
and	O
to	O
the	O
NLP	B-Task
reading	O
groups	O
at	O
Google	O
and	O
UMass	O
and	O
the	O
anonymous	O
reviewers	O
for	O
feedback	O
on	O
drafts	O
of	O
this	O
work	O
.	O
	
This	O
work	O
was	O
supported	O
in	O
part	O
by	O
an	O
IBM	O
PhD	O
Fellowship	O
Award	O
to	O
E.S.	O
,	O
in	O
part	O
by	O
the	O
Center	O
for	O
Intelligent	B-Task
Information	I-Task
Retrieval	I-Task
,	O
and	O
in	O
part	O
by	O
the	O
National	O
Science	O
Foundation	O
under	O
Grant	O
Nos	O
.	O
	
DMR	O
-	O
1534431	O
and	O
IIS	O
-	O
1514053	O
.	O
	
Any	O
opinions	O
,	O
findings	O
,	O
conclusions	O
or	O
recommendations	O
expressed	O
in	O
this	O
material	O
are	O
those	O
of	O
the	O
authors	O
and	O
do	O
not	O
necessarily	O
reflect	O
those	O
of	O
the	O
sponsor	O
.	O
	
bibliography	O
:	O
References	O
	
appendix	O
:	O
Supplemental	O
Material	O
	
subsection	O
:	O
Supplemental	O
analysis	O
	
Here	O
we	O
continue	O
the	O
analysis	O
from	O
§	O
[	O
reference	O
]	O
.	O
	
All	O
experiments	O
in	O
this	O
section	O
are	O
performed	O
on	O
CoNLL	B-Material
-	I-Material
2005	I-Material
development	O
data	O
unless	O
stated	O
otherwise	O
.	O
	
First	O
,	O
we	O
compare	O
the	O
impact	O
of	O
Viterbi	B-Method
decoding	I-Method
with	O
LISA	B-Method
,	O
D	B-Method
&	I-Method
M	I-Method
,	O
and	O
gold	O
syntax	O
trees	O
(	O
Table	O
[	O
reference	O
]	O
)	O
,	O
finding	O
the	O
same	O
trends	O
across	O
both	O
datasets	O
.	O
	
We	O
find	O
that	O
Viterbi	B-Method
has	O
nearly	O
the	O
same	O
impact	O
for	O
LISA	B-Method
,	O
D	O
&	O
M	O
and	O
gold	O
parses	O
:	O
Gold	O
parses	O
provide	O
little	O
improvement	O
over	O
predicted	O
parses	O
in	O
terms	O
of	O
BIO	B-Metric
label	I-Metric
consistency	I-Metric
.	O
	
[	O
scale=0.52	O
]	O
f1_by_sent_len.pdf	O
[	O
scale=0.52	O
]	O
f1_by_pred_dist.pdf	O
	
We	O
also	O
assess	O
SRL	B-Task
F1	I-Metric
as	O
a	O
function	O
of	O
sentence	O
length	O
and	O
distance	O
from	O
span	O
to	O
predicate	O
.	O
	
In	O
Figure	O
[	O
reference	O
]	O
we	O
see	O
that	O
providing	O
LISA	B-Method
with	O
gold	O
parses	O
is	O
particularly	O
helpful	O
for	O
sentences	O
longer	O
than	O
10	O
tokens	O
.	O
	
This	O
likely	O
directly	O
follows	O
from	O
the	O
tendency	O
of	O
syntactic	B-Method
parsers	I-Method
to	O
perform	O
worse	O
on	O
longer	O
sentences	O
.	O
	
With	O
respect	O
to	O
distance	O
between	O
arguments	O
and	O
predicates	O
,	O
(	O
Figure	O
[	O
reference	O
]	O
)	O
,	O
we	O
do	O
not	O
observe	O
this	O
same	O
trend	O
,	O
with	O
all	O
distances	O
performing	O
better	O
with	O
better	O
parses	B-Method
,	O
and	O
especially	O
gold	O
.	O
	
subsection	O
:	O
Supplemental	O
results	O
	
Due	O
to	O
space	O
constraints	O
in	O
the	O
main	O
paper	O
we	O
list	O
additional	O
experimental	O
results	O
here	O
.	O
	
Table	O
[	O
reference	O
]	O
lists	O
development	B-Metric
scores	I-Metric
on	O
the	O
CoNLL	B-Material
-	I-Material
2005	I-Material
dataset	O
with	O
predicted	O
predicates	O
,	O
which	O
follow	O
the	O
same	O
trends	O
as	O
the	O
test	O
data	O
.	O
	
subsection	O
:	O
Data	O
and	O
pre	O
-	O
processing	O
details	O
	
We	O
initialize	O
word	B-Method
embeddings	I-Method
with	O
100d	O
pre	B-Method
-	I-Method
trained	I-Method
GloVe	I-Method
embeddings	I-Method
trained	O
on	O
6	O
billion	O
tokens	O
of	O
Wikipedia	O
and	O
Gigaword	O
pennington2014glove	O
.	O
	
We	O
evaluate	O
the	O
SRL	B-Task
performance	O
of	O
our	O
models	O
using	O
the	O
srl	B-Method
-	I-Method
eval.pl	I-Method
script	I-Method
provided	O
by	O
the	O
CoNLL	B-Material
-	I-Material
2005	I-Material
shared	O
task	O
,	O
which	O
computes	O
segment	B-Metric
-	I-Metric
level	I-Metric
precision	I-Metric
,	O
recall	B-Metric
and	O
F1	B-Metric
score	O
.	O
	
We	O
also	O
report	O
the	O
predicate	B-Metric
detection	I-Metric
scores	I-Metric
output	O
by	O
this	O
script	O
.	O
	
We	O
evaluate	O
parsing	B-Task
using	O
the	O
eval.pl	B-Method
CoNLL	I-Method
script	I-Method
,	O
which	O
excludes	O
punctuation	O
.	O
	
We	O
train	O
distinct	O
D	O
&	O
M	O
parsers	O
for	O
CoNLL	B-Material
-	I-Material
2005	I-Material
and	O
CoNLL	B-Material
-	I-Material
2012	I-Material
.	O
	
Our	O
D	O
&	O
M	O
parsers	O
are	O
trained	O
and	O
validated	O
using	O
the	O
same	O
SRL	B-Task
data	O
splits	O
,	O
except	O
that	O
for	O
CoNLL	B-Material
-	I-Material
2005	I-Material
section	O
22	O
is	O
used	O
for	O
development	O
(	O
rather	O
than	O
24	O
)	O
,	O
as	O
this	O
section	O
is	O
typically	O
used	O
for	O
validation	B-Task
in	O
PTB	B-Task
parsing	I-Task
.	O
	
We	O
use	O
Stanford	O
dependencies	O
v3.5	O
	
deMarneffe2008	O
	
and	O
POS	O
tags	O
from	O
the	O
Stanford	O
	
CoreNLP	O
left3words	O
	
model	O
toutanova2003feature	O
.	O
	
We	O
use	O
the	O
pre	O
-	O
trained	O
ELMo	B-Method
models	I-Method
and	O
learn	O
task	O
-	O
specific	O
combinations	O
of	O
the	O
ELMo	B-Method
representations	I-Method
which	O
are	O
provided	O
as	O
input	O
instead	O
of	O
GloVe	O
embeddings	O
to	O
the	O
D	B-Method
&	I-Method
M	I-Method
parser	I-Method
with	O
otherwise	O
default	O
settings	O
.	O
	
subsubsection	O
:	O
CoNLL	B-Material
-	I-Material
2012	I-Material
	
We	O
follow	O
the	O
CoNLL	O
-	O
2012	O
split	O
used	O
by	O
he2018jointly	O
to	O
evaluate	O
our	O
models	O
,	O
which	O
uses	O
the	O
annotations	O
from	O
here	O
but	O
the	O
subset	O
of	O
those	O
documents	O
from	O
the	O
CoNLL	B-Method
-	I-Method
2012	I-Method
co	I-Method
-	I-Method
reference	I-Method
split	I-Method
described	O
here	O
pradhan2013towards	O
.	O
	
This	O
dataset	O
is	O
drawn	O
from	O
seven	O
domains	O
:	O
newswire	O
,	O
web	O
,	O
broadcast	O
news	O
and	O
conversation	O
,	O
magazines	O
,	O
telephone	O
conversations	O
,	O
and	O
text	O
from	O
the	O
bible	O
.	O
	
The	O
text	O
is	O
annotated	O
with	O
gold	O
part	O
-	O
of	O
-	O
speech	O
,	O
syntactic	O
constituencies	O
,	O
named	O
entities	O
,	O
word	O
sense	O
,	O
speaker	O
,	O
co	O
-	O
reference	O
and	O
semantic	O
role	O
labels	O
based	O
on	O
the	O
PropBank	O
guidelines	O
palmer2005proposition	O
.	O
	
Propositions	O
may	O
be	O
verbal	O
or	O
nominal	O
,	O
and	O
there	O
are	O
41	O
distinct	O
semantic	O
role	O
labels	O
,	O
excluding	O
continuation	O
roles	O
and	O
including	O
the	O
predicate	O
.	O
	
We	O
convert	O
the	O
semantic	O
proposition	O
and	O
role	B-Method
segmentations	I-Method
to	O
BIO	O
boundary	O
-	O
encoded	O
tags	O
,	O
resulting	O
in	O
129	O
distinct	O
BIO	O
-	O
encoded	O
tags	O
(	O
including	O
continuation	O
roles	O
)	O
.	O
	
subsubsection	O
:	O
CoNLL	B-Material
-	I-Material
2005	I-Material
	
The	O
CoNLL	B-Material
-	I-Material
2005	I-Material
data	O
carreras2005introduction	O
is	O
based	O
on	O
the	O
original	O
PropBank	O
corpus	O
palmer2005proposition	O
,	O
which	O
labels	O
the	O
Wall	O
Street	O
Journal	O
portion	O
of	O
the	O
Penn	O
TreeBank	O
corpus	O
(	O
PTB	O
)	O
	
marcus1993building	O
with	O
predicate	O
-	O
argument	O
structures	O
,	O
plus	O
a	O
challenging	O
out	O
-	O
of	O
-	O
domain	O
test	O
set	O
derived	O
from	O
the	O
Brown	O
corpus	O
francis1964manual	O
.	O
	
This	O
dataset	O
contains	O
only	O
verbal	O
predicates	O
,	O
though	O
some	O
are	O
multi	O
-	O
word	O
verbs	O
,	O
and	O
28	O
distinct	O
role	O
label	O
types	O
.	O
	
We	O
obtain	O
105	O
SRL	B-Task
labels	O
including	O
continuations	O
after	O
encoding	O
predicate	O
argument	O
segment	O
boundaries	O
with	O
BIO	O
tags	O
.	O
	
subsection	O
:	O
Optimization	B-Task
and	O
hyperparameters	O
	
We	O
train	O
the	O
model	O
using	O
the	O
Nadam	B-Method
dozat2016incorporating	O
algorithm	O
for	O
adaptive	B-Method
stochastic	I-Method
gradient	I-Method
descent	I-Method
(	O
SGD	B-Method
)	I-Method
,	O
which	O
combines	O
Adam	B-Method
kingma2014adam	O
SGD	O
with	O
Nesterov	B-Method
momentum	O
nesterov1983method	O
.	O
	
We	O
additionally	O
vary	O
the	O
learning	B-Metric
rate	I-Metric
as	O
a	O
function	O
of	O
an	O
initial	O
learning	B-Metric
rate	I-Metric
and	O
the	O
current	O
training	O
step	O
as	O
described	O
in	O
vaswani2017attention	O
using	O
the	O
following	O
function	O
:	O
lr	O
	
=	O
lr_0	O
(	O
step^	O
-	O
0.5	O
,	O
step	O
warm^	O
-	O
1.5	O
)	O
which	O
increases	O
the	O
learning	B-Metric
rate	I-Metric
linearly	O
for	O
the	O
first	O
training	O
steps	O
,	O
then	O
decays	O
it	O
proportionally	O
to	O
the	O
inverse	O
square	O
root	O
of	O
the	O
step	O
number	O
.	O
	
We	O
found	O
this	O
learning	B-Metric
rate	I-Metric
schedule	I-Metric
essential	O
for	O
training	O
the	O
self	B-Method
-	I-Method
attention	I-Method
model	I-Method
.	O
	
We	O
only	O
update	O
optimization	B-Method
moving	I-Method
-	I-Method
average	I-Method
accumulators	I-Method
for	O
parameters	O
which	O
receive	O
gradient	O
updates	O
at	O
a	O
given	O
step	O
.	O
	
In	O
all	O
of	O
our	O
experiments	O
we	O
used	O
initial	O
learning	B-Metric
rate	I-Metric
0.04	O
,	O
,	O
,	O
and	O
dropout	B-Metric
rates	I-Metric
of	O
0.1	O
everywhere	O
.	O
	
We	O
use	O
10	O
or	O
12	O
self	B-Method
-	I-Method
attention	I-Method
layers	I-Method
made	O
up	O
of	O
8	O
attention	O
heads	O
each	O
with	O
embedding	O
dimension	O
25	O
,	O
with	O
800d	B-Method
feed	I-Method
-	I-Method
forward	I-Method
projections	I-Method
.	O
	
In	O
the	O
syntactically	O
-	O
informed	O
attention	O
head	O
,	O
has	O
dimension	O
500	O
and	O
has	O
dimension	O
100	O
.	O
	
The	O
size	O
of	O
and	B-Method
representations	I-Method
and	O
the	O
representation	O
used	O
for	O
joint	B-Task
part	I-Task
-	I-Task
of	I-Task
-	I-Task
speech	I-Task
/	I-Task
predicate	I-Task
classification	I-Task
is	O
200	O
.	O
	
We	O
train	O
with	O
warmup	O
steps	O
and	O
clip	O
gradient	O
norms	O
to	O
1	O
.	O
	
We	O
use	O
batches	O
of	O
approximately	O
5000	O
tokens	O
.	O
	
Local	B-Method
Decorrelation	I-Method
For	O
Improved	O
Pedestrian	B-Task
Detection	I-Task
Even	O
with	O
the	O
advent	O
of	O
more	O
sophisticated	O
,	O
data	B-Method
-	I-Method
hungry	I-Method
methods	I-Method
,	O
boosted	B-Method
decision	I-Method
trees	I-Method
remain	O
extraordinarily	O
successful	O
for	O
fast	O
rigid	B-Task
object	I-Task
detection	I-Task
,	O
achieving	O
top	O
accuracy	B-Metric
on	O
numerous	O
datasets	O
.	O
	
While	O
effective	O
,	O
most	O
boosted	B-Method
detectors	I-Method
use	O
decision	B-Method
trees	I-Method
with	O
orthogonal	O
(	O
single	O
feature	O
)	O
splits	O
,	O
and	O
the	O
topology	O
of	O
the	O
resulting	O
decision	O
boundary	O
may	O
not	O
be	O
well	O
matched	O
to	O
the	O
natural	O
topology	O
of	O
the	O
data	O
.	O
	
Given	O
highly	O
correlated	O
data	O
,	O
decision	B-Method
trees	I-Method
with	O
oblique	O
(	O
multiple	O
feature	O
)	O
splits	O
can	O
be	O
effective	O
.	O
	
Use	O
of	O
oblique	O
splits	O
,	O
however	O
,	O
comes	O
at	O
considerable	O
computational	B-Metric
expense	I-Metric
.	O
	
Inspired	O
by	O
recent	O
work	O
on	O
discriminative	B-Task
decorrelation	I-Task
of	I-Task
HOG	I-Task
features	I-Task
,	O
we	O
instead	O
propose	O
an	O
efficient	O
feature	B-Method
transform	I-Method
that	O
removes	O
correlations	O
in	O
local	O
neighborhoods	O
.	O
	
The	O
result	O
is	O
an	O
overcomplete	B-Method
but	I-Method
locally	I-Method
decorrelated	I-Method
representation	I-Method
ideally	O
suited	O
for	O
use	O
with	O
orthogonal	O
decision	O
trees	O
.	O
	
In	O
fact	O
,	O
orthogonal	O
trees	O
with	O
our	O
locally	O
decorrelated	O
features	O
outperform	O
oblique	B-Method
trees	I-Method
trained	O
over	O
the	O
original	O
features	O
at	O
a	O
fraction	O
of	O
the	O
computational	B-Metric
cost	I-Metric
.	O
	
The	O
overall	O
improvement	O
in	O
accuracy	B-Metric
is	O
dramatic	O
:	O
on	O
the	O
Caltech	B-Material
Pedestrian	I-Material
Dataset	I-Material
,	O
we	O
reduce	O
false	B-Metric
positives	I-Metric
nearly	O
tenfold	O
over	O
the	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
.	O
	
1	O
Introduction	O
	
In	O
recent	O
years	O
object	B-Method
detectors	I-Method
have	O
undergone	O
an	O
impressive	O
transformation	O
[	O
11	O
,	O
32	O
,	O
14	O
]	O
.	O
	
Nevertheless	O
,	O
boosted	B-Method
detectors	I-Method
remain	O
extraordinarily	O
successful	O
for	O
fast	B-Task
detection	I-Task
of	I-Task
quasi	I-Task
-	I-Task
rigid	I-Task
objects	I-Task
.	O
	
Such	O
detectors	O
were	O
first	O
proposed	O
by	O
Viola	O
and	O
Jones	O
in	O
their	O
landmark	O
work	O
on	O
efficient	O
sliding	B-Method
window	I-Method
detection	I-Method
that	O
made	O
face	B-Task
detection	I-Task
practical	O
and	O
commercially	O
viable	O
[	O
35	O
]	O
.	O
	
This	O
initial	O
architecture	O
remains	O
largely	O
intact	O
today	O
:	O
boosting	B-Method
[	O
31	O
,	O
12	O
]	O
is	O
used	O
to	O
train	O
and	O
combine	O
decision	B-Method
trees	I-Method
and	O
a	O
cascade	B-Method
is	O
employed	O
to	O
allow	O
for	O
fast	B-Task
rejection	I-Task
of	I-Task
negative	I-Task
samples	I-Task
.	O
	
Details	O
,	O
however	O
,	O
have	O
evolved	O
considerably	O
;	O
in	O
particular	O
,	O
significant	O
progress	O
has	O
been	O
made	O
on	O
the	O
feature	B-Method
representation	I-Method
[	O
6	O
,	O
9	O
,	O
2	O
]	O
and	O
cascade	B-Method
architecture	I-Method
[	O
3	O
,	O
8	O
]	O
.	O
Recent	O
boosted	B-Method
detectors	I-Method
[	O
1	O
,	O
7	O
]	O
achieve	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
accuracy	B-Metric
on	O
modern	O
benchmarks	O
[	O
10	O
,	O
22	O
]	O
while	O
retaining	O
computational	B-Metric
efficiency	I-Metric
.	O
	
While	O
boosted	B-Method
detectors	I-Method
have	O
evolved	O
considerably	O
over	O
the	O
past	O
decade	O
,	O
decision	B-Method
trees	I-Method
with	O
orthogonal	O
(	O
single	O
feature	O
)	O
splits	O
–	O
also	O
known	O
as	O
axis	B-Method
-	I-Method
aligned	I-Method
decision	I-Method
trees	I-Method
–	O
remain	O
popular	O
and	O
predominant	O
.	O
	
A	O
possible	O
explanation	O
for	O
the	O
persistence	O
of	O
orthogonal	O
splits	O
is	O
their	O
efficiency	O
:	O
oblique	O
	
(	O
multiple	O
feature	O
)	O
splits	O
incur	O
considerable	O
computational	B-Metric
cost	I-Metric
during	O
both	O
training	B-Task
and	O
detection	B-Task
.	O
	
Nevertheless	O
,	O
oblique	O
trees	O
can	O
hold	O
considerable	O
advantages	O
.	O
	
In	O
particular	O
,	O
Menze	O
et	O
al	O
.	O
	
[	O
23	O
]	O
recently	O
demonstrated	O
that	O
oblique	B-Method
trees	I-Method
used	O
in	O
conjunction	O
with	O
random	B-Method
forests	I-Method
are	O
quite	O
effective	O
given	O
high	O
dimensional	O
data	O
with	O
heavily	O
correlated	O
features	O
.	O
	
To	O
achieve	O
similar	O
advantages	O
while	O
avoiding	O
the	O
computational	B-Metric
expense	I-Metric
of	O
oblique	O
trees	O
,	O
we	O
instead	O
take	O
inspiration	O
from	O
recent	O
work	O
by	O
Hariharan	O
et	O
al	O
.	O
	
[	O
15	O
]	O
and	O
propose	O
to	O
decorrelate	O
features	O
prior	O
to	O
applying	O
orthogonal	O
trees	O
.	O
	
To	O
do	O
so	O
we	O
introduce	O
an	O
efficient	O
feature	B-Method
transform	I-Method
that	O
removes	O
correlations	O
in	O
local	O
image	O
neighborhoods	O
(	O
as	O
opposed	O
to	O
decorrelating	O
features	O
globally	O
as	O
in	O
[	O
15	O
]	O
)	O
.	O
	
The	O
result	O
is	O
an	O
overcomplete	B-Method
but	I-Method
locally	I-Method
decorrelated	I-Method
representation	I-Method
that	O
is	O
ideally	O
suited	O
for	O
use	O
with	O
orthogonal	O
trees	O
.	O
	
In	O
fact	O
,	O
orthogonal	O
trees	O
with	O
our	O
locally	O
decorrelated	O
features	O
require	O
estimation	O
of	O
fewer	O
parameters	O
and	O
actually	O
outperform	O
oblique	B-Method
trees	I-Method
trained	O
over	O
the	O
original	O
features	O
.	O
	
∗This	O
research	O
was	O
performed	O
while	O
W.N.	O
was	O
a	O
postdoctoral	O
researcher	O
at	O
POSTECH	O
.	O
	
We	O
evaluate	O
boosted	B-Method
decision	I-Method
tree	I-Method
learning	I-Method
with	O
decorrelated	O
features	O
in	O
the	O
context	O
of	O
pedestrian	B-Task
detection	I-Task
.	O
	
As	O
our	O
baseline	O
we	O
utilize	O
the	O
aggregated	B-Method
channel	I-Method
features	I-Method
(	I-Method
ACF	I-Method
)	I-Method
detector	I-Method
[	O
7	O
]	O
,	O
a	O
popular	O
,	O
top	O
-	O
performing	O
detector	O
for	O
which	O
source	O
code	O
is	O
available	O
online	O
.	O
	
Coupled	O
with	O
use	O
of	O
deeper	O
trees	O
and	O
a	O
denser	O
sampling	O
of	O
the	O
data	O
,	O
the	O
improvement	O
obtained	O
using	O
our	O
locally	B-Method
decorrelated	I-Method
channel	I-Method
features	I-Method
(	O
LDCF	B-Method
)	O
is	O
substantial	O
.	O
	
While	O
in	O
the	O
past	O
year	O
the	O
use	O
of	O
deep	B-Method
learning	I-Method
[	O
25	O
]	O
,	O
motion	O
features	O
[	O
27	O
]	O
,	O
and	O
multi	B-Method
-	I-Method
resolution	I-Method
models	I-Method
[	O
36	O
]	O
has	O
brought	O
down	O
log	B-Metric
-	I-Metric
average	I-Metric
miss	I-Metric
rate	I-Metric
(	I-Metric
MR	I-Metric
)	O
to	O
under	O
40	O
%	O
on	O
the	O
Caltech	B-Material
Pedestrian	I-Material
Dataset	I-Material
[	O
10	O
]	O
,	O
LDCF	B-Method
reduces	O
MR	B-Metric
to	O
under	O
25	O
%	O
.	O
	
This	O
translates	O
to	O
a	O
nearly	O
tenfold	O
reduction	O
in	O
false	B-Metric
positives	I-Metric
over	O
the	O
(	O
very	O
recent	O
)	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
.	O
	
The	O
paper	O
is	O
organized	O
as	O
follows	O
.	O
	
In	O
§	O
2	O
we	O
review	O
orthogonal	B-Method
and	I-Method
oblique	I-Method
trees	I-Method
and	O
demonstrate	O
that	O
orthogonal	B-Method
trees	I-Method
trained	O
on	O
decorrelated	O
data	O
may	O
be	O
equally	O
or	O
more	O
effective	O
as	O
oblique	B-Method
trees	I-Method
trained	O
on	O
the	O
original	O
data	O
.	O
	
We	O
introduce	O
the	O
baseline	O
in	O
§	O
3	O
and	O
in	O
§	O
4	O
show	O
that	O
use	O
of	O
oblique	O
trees	O
improves	O
results	O
but	O
at	O
considerable	O
computational	B-Metric
expense	I-Metric
.	O
	
Next	O
,	O
in	O
§	O
5	O
,	O
we	O
demonstrate	O
that	O
orthogonal	B-Method
trees	I-Method
trained	O
with	O
locally	O
decorrelated	O
features	O
are	O
efficient	O
and	O
effective	O
.	O
	
Experiments	O
and	O
results	O
are	O
presented	O
in	O
§	O
6	O
.	O
	
We	O
begin	O
by	O
briefly	O
reviewing	O
related	O
work	O
next	O
.	O
	
1.1	O
Related	O
Work	O
Pedestrian	B-Task
Detection	I-Task
	
:	O
Recent	O
work	O
in	O
pedestrian	B-Task
detection	I-Task
includes	O
use	O
of	O
deformable	B-Method
part	I-Method
models	I-Method
and	O
their	O
extensions	O
[	O
11	O
,	O
36	O
,	O
26	O
]	O
,	O
convolutional	B-Method
nets	I-Method
and	O
deep	B-Method
learning	I-Method
[	O
33	O
,	O
37	O
,	O
25	O
]	O
,	O
and	O
approaches	O
that	O
focus	O
on	O
optimization	B-Task
and	O
learning	B-Task
[	O
20	O
,	O
18	O
,	O
34	O
]	O
.	O
Boosted	B-Method
detectors	I-Method
are	O
also	O
widely	O
used	O
.	O
	
In	O
particular	O
,	O
the	O
channel	B-Method
features	I-Method
detectors	I-Method
[	O
9	O
,	O
1	O
,	O
2	O
,	O
7	O
]	O
are	O
a	O
family	O
of	O
conceptually	O
straightforward	O
and	O
efficient	O
detectors	B-Method
based	O
on	O
boosted	B-Method
decision	I-Method
trees	I-Method
computed	O
over	O
multiple	O
feature	O
channels	O
such	O
as	O
color	O
,	O
gradient	O
magnitude	O
,	O
gradient	O
orientation	O
and	O
others	O
.	O
	
Current	O
top	O
results	O
on	O
the	O
INRIA	O
[	O
6	O
]	O
and	O
Caltech	B-Material
[	O
10	O
]	O
	
Pedestrian	O
Datasets	O
include	O
instances	O
of	O
the	O
channel	B-Method
features	I-Method
detector	I-Method
with	O
additional	O
mid	O
-	O
level	O
edge	O
features	O
[	O
19	O
]	O
and	O
motion	O
features	O
[	O
27	O
]	O
,	O
respectively	O
.	O
	
Oblique	B-Method
Decision	I-Method
Trees	I-Method
:	O
Typically	O
,	O
decision	B-Method
trees	I-Method
are	O
trained	O
with	O
orthogonal	O
(	O
single	O
feature	O
)	O
splits	O
;	O
however	O
,	O
the	O
extension	O
to	O
oblique	O
(	O
multiple	O
feature	O
)	O
splits	O
is	O
fairly	O
intuitive	O
and	O
well	O
known	O
,	O
see	O
e.g.	O
[	O
24	O
]	O
.	O
	
In	O
fact	O
,	O
Breiman	O
’s	O
foundational	O
work	O
on	O
random	B-Task
forests	I-Task
[	O
5	O
]	O
experimented	O
with	O
oblique	O
trees	O
.	O
	
Recently	O
there	O
has	O
been	O
renewed	O
interest	O
in	O
random	B-Task
forests	I-Task
with	O
oblique	O
splits	O
[	O
23	O
,	O
30	O
]	O
and	O
Marin	O
et	O
al	O
.	O
	
[	O
20	O
]	O
even	O
applied	O
such	O
a	O
technique	O
to	O
pedestrian	B-Task
detection	I-Task
.	O
	
Likewise	O
,	O
while	O
typically	O
orthogonal	B-Method
trees	I-Method
are	O
used	O
with	O
boosting	B-Method
[	O
12	O
]	O
,	O
oblique	B-Method
trees	I-Method
can	O
easily	O
be	O
used	O
instead	O
.	O
	
The	O
contribution	O
of	O
this	O
work	O
is	O
not	O
the	O
straightforward	O
coupling	O
of	O
oblique	B-Method
trees	I-Method
with	O
boosting	B-Method
,	O
rather	O
,	O
we	O
propose	O
a	O
local	B-Method
decorrelation	I-Method
transform	I-Method
that	O
eliminates	O
the	O
necessity	O
of	O
oblique	O
splits	O
altogether	O
.	O
	
Decorrelation	B-Method
:	O
Decorrelation	B-Method
is	O
a	O
common	O
pre	B-Method
-	I-Method
processing	I-Method
step	I-Method
for	O
classification	B-Task
[	O
17	O
,	O
15	O
]	O
.	O
	
In	O
recent	O
work	O
,	O
Hariharan	O
et	O
al	O
.	O
	
[	O
15	O
]	O
proposed	O
an	O
efficient	O
scheme	O
for	O
estimating	B-Task
covariances	I-Task
between	I-Task
HOG	I-Task
features	I-Task
[	O
6	O
]	O
with	O
the	O
goal	O
of	O
replacing	O
linear	B-Method
SVMs	I-Method
with	O
LDA	B-Method
and	O
thus	O
allowing	O
for	O
fast	B-Task
training	I-Task
.	O
	
Hariharan	O
et	O
al	O
.	O
demonstrated	O
that	O
the	O
global	O
covariance	O
matrix	O
for	O
a	O
detection	O
window	O
can	O
be	O
estimated	O
efficiently	O
as	O
the	O
covariance	O
between	O
two	O
features	O
should	O
depend	O
only	O
on	O
their	O
relative	O
offset	O
.	O
	
Inspired	O
by	O
[	O
15	O
]	O
,	O
we	O
likewise	O
exploit	O
the	O
stationarity	O
of	O
natural	O
image	O
statistics	O
,	O
but	O
instead	O
propose	O
to	O
estimate	O
a	O
local	O
covariance	O
matrix	O
shared	O
across	O
all	O
image	O
patches	O
.	O
	
Next	O
,	O
rather	O
than	O
applying	O
global	B-Method
decorrelation	I-Method
,	O
which	O
would	O
be	O
computationally	O
prohibitive	O
for	O
sliding	B-Task
window	I-Task
detection	I-Task
with	O
a	O
nonlinear	B-Method
classifier1	I-Method
,	O
we	O
instead	O
propose	O
to	O
apply	O
an	O
efficient	O
local	B-Method
decorrelation	I-Method
transform	I-Method
.	O
	
The	O
result	O
is	O
an	O
overcomplete	B-Method
representation	I-Method
well	O
suited	O
for	O
use	O
with	O
orthogonal	O
trees	O
.	O
	
1Global	O
decorrelation	B-Method
coupled	O
with	O
a	O
linear	B-Method
classifier	I-Method
is	O
efficient	O
as	O
the	O
two	O
linear	B-Method
operations	I-Method
can	O
be	O
merged	O
.	O
	
2	O
Boosted	B-Method
Decision	I-Method
Trees	I-Method
with	O
Correlated	B-Method
Data	I-Method
Boosting	I-Method
is	O
a	O
simple	O
yet	O
powerful	O
tool	O
for	O
classification	B-Task
and	O
can	O
model	O
complex	O
non	O
-	O
linear	O
functions	O
[	O
31	O
,	O
12	O
]	O
.	O
	
The	O
general	O
idea	O
is	O
to	O
train	O
and	O
combine	O
a	O
number	O
of	O
weak	B-Method
learners	I-Method
into	O
a	O
more	O
powerful	O
strong	B-Method
classifier	I-Method
.	O
	
Decision	B-Method
trees	I-Method
are	O
frequently	O
used	O
as	O
the	O
weak	B-Method
learner	I-Method
in	O
conjunction	O
with	O
boosting	B-Task
,	O
and	O
in	O
particular	O
orthogonal	B-Method
decision	I-Method
trees	I-Method
,	O
that	O
is	O
trees	O
in	O
which	O
every	O
split	O
is	O
a	O
threshold	O
on	O
a	O
single	O
feature	O
,	O
are	O
especially	O
popular	O
due	O
to	O
their	O
speed	O
and	O
simplicity	O
[	O
35	O
,	O
7	O
,	O
1	O
]	O
.	O
	
The	O
representational	O
power	O
obtained	O
by	O
boosting	B-Method
orthogonal	I-Method
trees	I-Method
is	O
not	O
limited	O
by	O
use	O
of	O
orthogonal	O
splits	O
;	O
however	O
,	O
the	O
number	O
and	O
depth	O
of	O
the	O
trees	O
necessary	O
to	O
fit	O
the	O
data	O
may	O
be	O
large	O
.	O
	
This	O
can	O
lead	O
to	O
complex	O
decision	O
boundaries	O
and	O
poor	O
generalization	B-Task
,	O
especially	O
given	O
highly	O
correlated	O
features	O
.	O
	
Figure	O
1	O
(	O
a	O
)-(	O
c	O
)	O
shows	O
the	O
result	O
of	O
boosted	B-Method
orthogonal	I-Method
trees	I-Method
on	O
correlated	O
data	O
.	O
	
Observe	O
that	O
the	O
orthogonal	O
trees	O
generalize	O
poorly	O
even	O
as	O
we	O
vary	O
the	O
number	O
and	O
depth	O
of	O
the	O
trees	O
.	O
	
Decision	B-Method
trees	I-Method
with	O
oblique	O
splits	O
can	O
more	O
effectively	O
model	O
data	O
with	O
correlated	O
features	O
as	O
the	O
topology	O
of	O
the	O
resulting	O
classifier	B-Method
can	O
better	O
match	O
the	O
natural	O
topology	O
of	O
the	O
data	O
[	O
23	O
]	O
.	O
	
In	O
oblique	O
trees	O
,	O
every	O
split	O
is	O
based	O
on	O
a	O
linear	B-Method
projection	I-Method
of	O
the	O
data	O
z	O
=	O
wᵀx	O
followed	O
by	O
thresholding	B-Method
.	O
	
The	O
projection	O
w	O
can	O
be	O
sparse	O
(	O
and	O
orthogonal	O
splits	O
are	O
a	O
special	O
case	O
with	O
‖w‖0	O
=	O
1	O
)	O
.	O
	
While	O
in	O
principle	O
numerous	O
approaches	O
can	O
be	O
used	O
to	O
obtain	O
w	O
,	O
in	O
practice	O
linear	B-Method
discriminant	I-Method
analysis	I-Method
(	O
LDA	B-Method
)	O
is	O
a	O
natural	O
choice	O
for	O
obtaining	O
discriminative	O
splits	O
efficiently	O
	
[	O
16	O
]	O
.	O
LDA	B-Method
aims	O
to	O
minimize	O
within	O
-	O
class	O
scatter	O
while	O
maximizing	O
between	O
-	O
class	O
scatter	O
.	O
	
w	O
is	O
computed	O
from	O
class	O
-	O
conditional	O
mean	O
vectors	O
µ	O
+	O
and	O
µ−	O
and	O
a	O
class	O
-	O
independent	O
covariance	O
matrix	O
Σ	O
as	O
follows	O
:	O
w	O
	
=	O
Σ−1	O
(	O
µ	O
+	O
	
−	O
µ−	O
)	O
.	O
	
(	O
1	O
)	O
	
The	O
covariance	O
may	O
be	O
degenerate	O
if	O
the	O
amount	O
or	O
underlying	O
dimension	O
of	O
the	O
data	O
is	O
low	O
;	O
in	O
this	O
case	O
LDA	B-Method
can	O
be	O
regularized	O
by	O
using	O
(	O
1−	O
)	O
Σ	O
+	O
I	O
in	O
place	O
of	O
Σ.	O
	
In	O
Figure	O
1	O
(	O
d	O
)	O
we	O
apply	O
boosted	B-Method
oblique	I-Method
trees	I-Method
trained	O
with	O
LDA	B-Method
on	O
the	O
same	O
data	O
as	O
before	O
.	O
	
Observe	O
the	O
resulting	O
decision	O
boundary	O
better	O
matches	O
the	O
underlying	O
data	O
distribution	O
and	O
shows	O
improved	O
generalization	B-Task
.	O
	
The	O
connection	O
between	O
whitening	B-Method
and	O
LDA	B-Method
is	O
well	O
known	O
[	O
15	O
]	O
.	O
Specifically	O
	
,	O
LDA	B-Method
simplifies	O
to	O
a	O
trivial	O
classification	B-Method
rule	I-Method
on	O
whitened	O
data	O
(	O
data	O
whose	O
covariance	O
is	O
the	O
identity	O
)	O
.	O
	
Let	O
Σ	O
=	O
QΛQᵀ	O
be	O
the	O
eigendecomposition	B-Method
of	I-Method
Σ	I-Method
where	O
Q	O
is	O
an	O
orthogonal	O
matrix	O
and	O
Λ	O
	
is	O
a	O
diagonal	O
matrix	O
of	O
eigenvalues	O
.	O
	
W	O
=	O
QΛ−	O
	
1	O
2	O
Qᵀ	O
=	O
Σ−	O
1	O
2	O
is	O
known	O
as	O
a	O
whitening	O
matrix	O
because	O
the	O
covariance	O
of	O
x′	O
=	O
	
Wx	B-Method
is	O
the	O
identity	O
matrix	O
.	O
	
Given	O
whitened	O
data	O
and	O
means	O
,	O
LDA	B-Method
can	O
be	O
interpreted	O
as	O
learning	O
the	O
trivial	O
projection	O
w′	O
=	O
µ′	O
+	O
−	O
µ′−	O
=	O
Wµ	O
+	O
−Wµ−	O
since	O
w′	O
ᵀ	O
x′	O
	
=	O
w′	O
ᵀ	O
Wx	O
=	O
wᵀx	O
.	O
	
Can	O
whitening	O
or	O
a	O
related	O
transform	O
likewise	O
simplify	O
learning	B-Task
of	I-Task
boosted	I-Task
decision	I-Task
trees	I-Task
?	O
	
Using	O
standard	O
terminology	O
[	O
17	O
]	O
,	O
we	O
define	O
the	O
following	O
related	O
transforms	O
:	O
decorrelation	B-Method
(	O
Qᵀ	O
)	O
,	O
PCA	B-Method
-	I-Method
whitening	I-Method
(	O
Λ−	O
1	O
2	O
Qᵀ	O
)	O
,	O
and	O
ZCA	B-Method
-	I-Method
whitening	I-Method
(	O
QΛ−	O
1	O
2	O
Qᵀ	O
)	O
.	O
	
Figure	O
2	O
shows	O
the	O
result	O
of	O
boosting	B-Method
orthogonal	I-Method
trees	I-Method
on	O
the	O
variously	O
transformed	O
features	O
,	O
using	O
the	O
same	O
data	O
as	O
before	O
.	O
	
Observe	O
that	O
with	O
decorrelated	O
and	O
PCA	O
-	O
whitened	O
features	O
	
orthogonal	O
trees	O
show	O
improved	O
generalization	B-Task
.	O
	
In	O
fact	O
,	O
as	O
each	O
split	O
is	O
invariant	O
to	O
scaling	O
of	O
individual	O
features	O
,	O
orthogonal	O
trees	O
with	O
PCA	O
-	O
whitened	O
and	O
decorrelated	O
features	O
give	O
identical	O
results	O
.	O
	
Decorrelating	O
the	O
features	O
is	O
critical	O
,	O
while	O
scaling	B-Method
is	O
not	O
.	O
	
The	O
intuition	O
is	O
clear	O
:	O
each	O
split	O
operates	O
on	O
a	O
single	O
feature	O
,	O
which	O
is	O
most	O
effective	O
if	O
the	O
features	O
are	O
decorrelated	O
.	O
	
Interestingly	O
,	O
the	O
standard	O
ZCA	B-Method
-	I-Method
whitened	I-Method
transform	I-Method
used	O
by	O
LDA	B-Method
is	O
ineffective	O
:	O
while	O
the	O
resulting	O
features	O
are	O
not	O
technically	O
correlated	O
,	O
due	O
to	O
the	O
additional	O
rotation	O
by	O
Q	O
each	O
resulting	O
feature	O
is	O
a	O
linear	O
combination	O
of	O
features	O
obtained	O
by	O
PCA	B-Method
-	I-Method
whitening	I-Method
.	O
	
3	O
Baseline	B-Method
Detector	I-Method
(	O
ACF	B-Method
)	O
	
We	O
next	O
briefly	O
review	O
our	O
baseline	O
detector	O
and	O
evaluation	B-Metric
benchmark	I-Metric
.	O
	
This	O
will	O
allow	O
us	O
to	O
apply	O
the	O
ideas	O
from	O
§	O
2	O
to	O
object	B-Task
detection	I-Task
in	O
subsequent	O
sections	O
.	O
	
In	O
this	O
work	O
we	O
utilize	O
the	O
channel	B-Method
features	I-Method
detectors	I-Method
[	O
9	O
,	O
7	O
,	O
1	O
,	O
2	O
]	O
,	O
a	O
family	O
of	O
conceptually	O
straightforward	O
and	O
efficient	O
detectors	O
for	O
which	O
variants	O
have	O
been	O
utilized	O
for	O
diverse	O
tasks	O
such	O
as	O
pedestrian	B-Task
detection	I-Task
[	O
10	O
]	O
,	O
sign	B-Task
recognition	I-Task
[	O
22	O
]	O
and	O
edge	B-Task
detection	I-Task
[	O
19	O
]	O
.	O
Specifically	O
,	O
for	O
our	O
experiments	O
we	O
focus	O
on	O
pedestrian	B-Task
detection	I-Task
and	O
employ	O
the	O
aggregate	O
channel	O
features	O
(	O
	
ACF	B-Method
)	I-Method
variant	I-Method
[	O
7	O
]	O
for	O
which	O
code	O
is	O
available	O
online2	O
.	O
	
Given	O
an	O
input	O
image	O
,	O
ACF	B-Method
computes	O
several	O
feature	O
channels	O
,	O
where	O
each	O
channel	O
is	O
a	O
per	O
-	O
pixel	O
feature	O
map	O
such	O
that	O
output	O
pixels	O
are	O
computed	O
from	O
corresponding	O
patches	O
of	O
input	O
pixels	O
(	O
thus	O
preserving	O
image	O
layout	O
)	O
.	O
	
We	O
use	O
the	O
same	O
channels	O
as	O
[	O
7	O
]	O
:	O
normalized	O
gradient	O
magnitude	O
(	O
1	O
channel	O
)	O
,	O
histogram	O
of	O
oriented	O
gradients	O
(	O
6	O
channels	O
)	O
,	O
and	O
LUV	O
color	O
channels	O
(	O
3	O
channels	O
)	O
,	O
for	O
a	O
total	O
of	O
10	O
channels	O
.	O
	
We	O
downsample	O
the	O
channels	O
by	O
2x	O
and	O
features	O
are	O
single	O
pixel	O
lookups	O
in	O
the	O
aggregated	O
channels	O
.	O
	
Thus	O
,	O
given	O
a	O
h	O
×	O
w	O
detection	O
window	O
,	O
there	O
are	O
h	O
/	O
2	O
·	O
w	O
/	O
2	O
·	O
10	O
candidate	O
features	O
(	O
channel	O
pixel	O
lookups	O
)	O
.	O
	
We	O
use	O
RealBoost	B-Method
[	O
12	O
]	O
with	O
multiple	O
rounds	O
of	O
bootstrapping	B-Method
to	O
train	O
and	O
combine	O
2048	O
depth	B-Method
-	I-Method
3	I-Method
decision	I-Method
trees	I-Method
over	O
these	O
features	O
to	O
distinguish	O
object	O
from	O
background	O
.	O
	
Soft	B-Method
-	I-Method
cascades	I-Method
[	O
3	O
]	O
and	O
an	O
efficient	O
multiscale	B-Method
sliding	I-Method
-	I-Method
window	I-Method
approach	I-Method
are	O
employed	O
.	O
	
Our	O
baseline	O
uses	O
slightly	O
altered	O
parameters	O
from	O
[	O
7	O
]	O
	
(	O
RealBoost	O
,	O
deeper	O
trees	O
,	O
and	O
less	O
downsampling	O
)	O
;	O
this	O
increases	O
model	O
capacity	O
and	O
benefits	O
our	O
final	O
approach	O
as	O
we	O
report	O
in	O
detail	O
in	O
§	O
6	O
.	O
	
Current	O
practice	O
is	O
to	O
use	O
the	O
INRIA	O
Pedestrian	O
Dataset	O
[	O
6	O
]	O
for	O
parameter	B-Task
tuning	I-Task
,	O
with	O
the	O
test	O
set	O
serving	O
as	O
a	O
validation	O
set	O
,	O
see	O
e.g.	O
[	O
20	O
,	O
2	O
,	O
9	O
]	O
.	O
	
We	O
utilize	O
this	O
dataset	O
in	O
much	O
the	O
same	O
way	O
and	O
report	O
full	O
results	O
on	O
the	O
more	O
challenging	O
Caltech	B-Material
Pedestrian	I-Material
Dataset	I-Material
[	O
10	O
]	O
.	O
Following	O
the	O
methodology	O
of	O
[	O
10	O
]	O
,	O
we	O
summarize	O
performance	O
using	O
the	O
log	O
-	O
average	O
miss	O
rate	O
(	O
MR	B-Metric
)	O
between	O
10−2	O
and	O
100	O
false	B-Metric
positives	I-Metric
per	O
image	O
.	O
	
We	O
repeat	O
all	O
experiments	O
10	O
times	O
and	O
report	O
the	O
mean	O
MR	B-Metric
and	O
standard	O
error	O
for	O
every	O
result	O
.	O
	
Due	O
to	O
the	O
use	O
of	O
a	O
log	O
-	O
log	O
scale	O
,	O
even	O
small	O
improvements	O
in	O
(	O
log	O
-	O
average	O
)	O
MR	B-Metric
correspond	O
to	O
large	O
reductions	O
in	O
false	B-Metric
-	I-Metric
positives	I-Metric
.	O
	
On	O
INRIA	O
,	O
our	O
(	O
slightly	O
modified	O
)	O
baseline	O
version	O
of	O
ACF	B-Metric
scores	I-Metric
at	O
17.3	O
%	O
MR	B-Metric
compared	O
to	O
17.0	O
%	O
MR	B-Metric
for	O
the	O
model	O
reported	O
in	O
[	O
7	O
]	O
.	O
4	O
Detection	B-Task
with	O
Oblique	O
Splits	O
(	O
ACF	B-Method
-	I-Method
LDA	I-Method
)	O
	
In	O
this	O
section	O
we	O
modify	O
the	O
ACF	B-Method
detector	I-Method
to	O
enable	O
oblique	O
splits	O
and	O
report	O
the	O
resulting	O
gains	O
.	O
	
Recall	O
that	O
given	O
input	O
	
x	O
,	O
at	O
each	O
split	O
of	O
an	O
oblique	O
decision	O
tree	O
we	O
need	O
to	O
compute	O
z	O
=	O
wᵀx	O
for	O
some	O
projection	O
w	O
and	O
threshold	O
the	O
result	O
.	O
	
For	O
our	O
baseline	B-Method
pedestrian	I-Method
detector	I-Method
,	O
we	O
use	O
128	O
×	O
64	O
windows	O
where	O
each	O
window	O
is	O
represented	O
by	O
a	O
feature	O
vector	O
x	O
of	O
size	O
128	O
/	O
2	O
·	O
64	O
/	O
2	O
	
·	O
10	O
=	O
20480	O
(	O
see	O
§	O
3	O
)	O
.	O
	
Given	O
the	O
high	O
dimensionality	O
of	O
the	O
input	O
x	O
coupled	O
with	O
the	O
use	O
of	O
thousands	O
of	O
trees	O
in	O
a	O
typical	O
boosted	B-Method
classifier	I-Method
,	O
for	O
efficiency	O
w	O
must	O
be	O
sparse	O
.	O
	
Local	O
w	O
:	O
We	O
opt	O
to	O
use	O
w	O
’s	O
that	O
correspond	O
to	O
localm×m	O
blocks	O
of	O
pixels	O
.	O
	
In	O
other	O
words	O
,	O
we	O
treat	O
x	O
as	O
a	O
h	O
/	O
2×w	O
/	O
2×	O
10	O
tensor	O
and	O
allow	O
w	O
to	O
operate	O
over	O
any	O
m×m×	O
1	O
patch	O
in	O
a	O
single	O
channel	O
of	O
x.	O
	
Doing	O
so	O
holds	O
multiple	O
advantages	O
.	O
	
Most	O
importantly	O
,	O
each	O
pixel	O
has	O
strongest	O
correlations	O
to	O
spatially	O
nearby	O
pixels	O
[	O
15	O
]	O
.	O
Since	O
oblique	O
splits	O
are	O
expected	O
to	O
help	O
most	O
when	O
features	O
are	O
strongly	O
correlated	O
,	O
operating	O
over	O
local	O
neighborhoods	O
is	O
a	O
natural	O
choice	O
.	O
	
In	O
addition	O
,	O
using	O
local	O
w	O
allows	O
for	O
faster	O
lookups	O
due	O
to	O
the	O
locality	O
of	O
adjacent	O
pixels	O
in	O
memory	O
.	O
	
Complexity	B-Metric
:	O
	
First	O
,	O
let	O
us	O
consider	O
the	O
complexity	B-Metric
of	O
training	O
the	O
oblique	O
splits	O
.	O
	
Let	O
d	O
=	O
	
h	O
/	O
2·w	O
/	O
2	O
be	O
the	O
window	O
size	O
of	O
a	O
single	O
channel	O
.	O
	
The	O
number	O
of	O
patches	O
per	O
channel	O
in	O
x	O
is	O
about	O
d	O
,	O
thus	O
naively	O
training	O
a	O
single	O
split	O
means	O
applying	O
LDA	B-Method
d	O
times	O
–	O
once	O
per	O
patch	O
–	O
and	O
keeping	O
w	O
with	O
lowest	O
error	O
.	O
	
Instead	O
of	O
computing	O
d	O
independent	O
matrices	O
	
Σ	O
per	O
channel	O
,	O
for	O
efficiency	O
,	O
we	O
compute	O
Σ	B-Method
,	O
a	O
d×	O
d	O
covariance	O
matrix	O
for	O
the	O
entire	O
window	O
,	O
and	O
reconstruct	O
individual	O
m2	O
	
×m2	O
	
Σ	O
’s	O
by	O
fetching	O
appropriate	O
entries	O
from	O
Σ.	O
A	O
similar	O
trick	O
can	O
be	O
used	O
for	O
the	O
µ	O
’s	O
.	O
	
Computing	B-Method
Σ	I-Method
is	O
O	O
(	O
nd2	O
)	O
given	O
n	O
training	O
examples	O
(	O
and	O
could	O
be	O
made	O
faster	O
by	O
omitting	O
unnecessary	O
elements	O
)	O
.	O
	
Inverting	O
each	O
Σ	O
,	O
the	O
bottleneck	O
of	O
computing	B-Task
Eq	I-Task
.	O
	
(	O
1	O
)	O
,	O
is	O
O	O
(	O
dm6	O
)	O
but	O
independent	O
of	O
n	O
and	O
thus	O
fairly	O
small	O
as	O
n	O
m.	O
	
Finally	O
computing	O
z	O
=	O
wᵀx	O
over	O
all	O
n	O
training	O
examples	O
and	O
d	O
projections	O
is	O
O	O
(	O
ndm2	O
)	O
.	O
	
Given	O
the	O
high	O
complexity	B-Metric
of	O
each	O
step	O
,	O
a	O
naive	B-Method
brute	I-Method
-	I-Method
force	I-Method
approach	I-Method
for	O
training	B-Task
is	O
infeasible	O
.	O
	
Speedup	O
:	O
	
While	O
the	O
weights	O
over	O
training	O
examples	O
change	O
at	O
every	O
boosting	O
iteration	O
and	O
after	O
every	O
tree	O
split	O
,	O
in	O
practice	O
we	O
find	O
it	O
is	O
unnecessary	O
to	O
recompute	O
the	O
projections	O
that	O
frequently	O
.	O
	
Table	O
1	O
,	O
rows	O
2	O
-	O
4	O
,	O
shows	O
the	O
results	O
of	O
ACF	B-Method
with	O
oblique	O
splits	O
,	O
updated	O
every	O
T	O
boosting	O
iterations	O
2http:	O
//	O
vision.ucsd.edu	O
/	O
˜pdollar	O
/	O
toolbox	O
/	O
doc	O
/	O
(	O
denoted	O
by	O
ACF	B-Method
-	I-Method
LDA	I-Method
-	I-Method
T	I-Method
)	O
.	O
	
While	O
more	O
frequent	O
updates	O
improve	O
accuracy	B-Metric
,	O
ACF	B-Method
-	I-Method
LDA	I-Method
-	I-Method
16	I-Method
has	O
negligibly	O
higher	O
MR	B-Metric
than	O
	
ACF	B-Method
-	I-Method
LDA	I-Method
-	I-Method
4	I-Method
but	O
a	O
nearly	O
fourfold	O
reduction	O
in	O
training	B-Metric
time	I-Metric
(	O
timed	O
using	O
12	O
cores	O
)	O
.	O
	
Training	O
the	O
brute	B-Method
force	I-Method
version	I-Method
of	I-Method
ACF	I-Method
-	I-Method
LDA	I-Method
,	O
updated	O
at	O
every	O
iteration	O
and	O
each	O
tree	O
split	O
(	O
7	O
interior	O
nodes	O
per	O
depth	O
-	O
3	O
tree	O
)	O
would	O
have	O
taken	O
about	O
5	O
·	O
4	O
·	O
7	O
=	O
140	O
hours	O
.	O
	
For	O
these	O
results	O
we	O
used	O
regularization	O
of	O
=	O
.1	O
and	O
patch	O
size	O
of	O
m	O
=	O
5	O
(	O
effect	O
of	O
varying	O
m	O
is	O
explored	O
in	O
§	O
6	O
)	O
.	O
	
Shared	B-Method
Σ	I-Method
:	O
The	O
crux	O
and	O
computational	B-Metric
bottleneck	I-Metric
of	O
ACF	B-Method
-	I-Method
LDA	I-Method
is	O
the	O
computation	O
and	O
application	O
of	O
a	O
separate	O
covariance	B-Method
Σ	I-Method
at	O
each	O
local	O
neighborhood	O
.	O
	
In	O
recent	O
work	O
on	O
training	O
linear	B-Task
object	I-Task
detectors	I-Task
using	O
LDA	B-Method
,	O
Hariharan	O
et	O
al	O
.	O
	
[	O
15	O
]	O
exploited	O
the	O
observation	O
that	O
the	O
statistics	O
of	O
natural	O
images	O
are	O
translationally	O
invariant	O
and	O
therefore	O
the	O
covariance	O
between	O
two	O
features	O
should	O
depend	O
only	O
on	O
their	O
relative	O
offset	O
.	O
	
Furthermore	O
,	O
as	O
positives	O
are	O
rare	O
,	O
[	O
15	O
]	O
showed	O
that	O
the	O
covariances	O
can	O
be	O
precomputed	O
using	O
natural	O
images	O
.	O
	
Inspired	O
by	O
these	O
observations	O
,	O
we	O
propose	O
to	O
use	O
a	O
single	O
,	O
fixed	O
covariance	O
Σ	O
shared	O
across	O
all	O
local	O
image	O
neighborhoods	O
.	O
	
We	O
precompute	O
one	O
Σ	O
per	O
channel	O
and	O
do	O
not	O
allow	O
it	O
to	O
vary	O
spatially	O
or	O
with	O
boosting	O
iteration	O
.	O
	
Table	O
1	O
,	O
rows	O
5	O
-	O
7	O
,	O
shows	O
the	O
results	O
of	O
ACF	B-Method
with	O
oblique	O
splits	O
using	O
fixed	O
Σ	O
,	O
denoted	O
by	O
	
ACF	B-Method
-	I-Method
LDA∗.	I-Method
As	O
before	O
,	O
the	O
µ	O
’s	O
and	O
resulting	O
w	O
are	O
updated	O
every	O
T	O
iterations	O
.	O
	
As	O
expected	O
,	O
training	B-Metric
time	I-Metric
is	O
reduced	O
relative	O
to	O
ACF	B-Method
-	I-Method
LDA	I-Method
.	O
	
Surprisingly	O
,	O
however	O
,	O
accuracy	B-Metric
improves	O
as	O
well	O
,	O
	
presumably	O
due	O
to	O
the	O
implicit	O
regularization	O
effect	O
of	O
using	O
a	O
fixed	O
Σ.	O
This	O
is	O
a	O
powerful	O
result	O
we	O
will	O
exploit	O
further	O
.	O
	
Summary	O
:	O
ACF	B-Method
with	O
local	B-Method
oblique	I-Method
splits	I-Method
and	O
a	O
single	O
shared	B-Method
Σ	I-Method
(	O
ACF	B-Method
-	I-Method
LDA∗	I-Method
-	I-Method
4	I-Method
)	O
achieves	O
14.7	O
%	O
MR	B-Metric
compared	O
to	O
17.3	O
%	O
MR	B-Metric
for	O
ACF	B-Method
with	O
orthogonal	O
splits	O
.	O
	
The	O
2.6	O
%	O
improvement	O
in	O
log	B-Metric
-	I-Metric
average	I-Metric
MR	I-Metric
corresponds	O
to	O
a	O
nearly	O
twofold	O
reduction	O
in	O
false	B-Metric
positives	I-Metric
but	O
comes	O
at	O
considerable	O
computational	B-Metric
cost	I-Metric
.	O
	
In	O
the	O
next	O
section	O
,	O
we	O
propose	O
an	O
alternative	O
,	O
more	O
efficient	O
approach	O
for	O
exploiting	O
the	O
use	O
of	O
a	O
single	O
shared	B-Method
Σ	I-Method
capturing	O
correlations	O
in	O
local	O
neighborhoods	O
.	O
	
5	O
Locally	O
Decorrelated	O
Channel	O
Features	O
(	O
LDCF	B-Method
)	O
	
We	O
now	O
have	O
all	O
the	O
necessary	O
ingredients	O
to	O
introduce	O
our	O
approach	O
.	O
	
We	O
have	O
made	O
the	O
following	O
observations	O
:	O
(	O
1	O
)	O
oblique	O
splits	O
learned	O
with	O
LDA	B-Method
over	O
local	O
m	O
×m	O
patches	O
improve	O
results	O
over	O
orthogonal	O
splits	O
,	O
(	O
2	O
)	O
a	O
single	O
covariance	O
matrix	O
Σ	O
can	O
be	O
shared	O
across	O
all	O
patches	O
per	O
channel	O
,	O
and	O
(	O
3	O
)	O
orthogonal	O
trees	O
with	O
decorrelated	O
features	O
can	O
potentially	O
be	O
used	O
in	O
place	O
of	O
oblique	O
trees	O
.	O
	
This	O
suggests	O
the	O
following	O
approach	O
:	O
for	O
every	O
m×m	O
patch	O
p	O
in	O
x	O
,	O
we	O
can	O
create	O
a	O
decorrelated	B-Method
representation	I-Method
by	O
computing	O
Qᵀp	B-Method
,	O
where	O
QΛQᵀ	O
is	O
the	O
eigendecomposition	B-Method
of	I-Method
Σ	I-Method
as	O
before	O
,	O
followed	O
by	O
use	O
of	O
orthogonal	B-Method
trees	I-Method
.	O
	
However	O
,	O
such	O
an	O
approach	O
is	O
computationally	O
expensive	O
.	O
	
First	O
,	O
due	O
to	O
use	O
of	O
overlapping	O
patches	O
,	O
computing	O
Qᵀp	O
for	O
every	O
overlapping	O
patch	O
results	O
in	O
an	O
overcomplete	B-Method
representation	I-Method
with	O
a	O
factor	O
m2	O
increase	O
in	O
feature	B-Metric
dimensionality	I-Metric
.	O
	
To	O
reduce	O
dimensionality	O
,	O
we	O
only	O
utilize	O
the	O
top	O
k	O
eigenvectors	O
in	O
Q	O
,	O
resulting	O
in	O
k	O
<	O
m2	O
features	O
per	O
pixel	O
.	O
	
The	O
intuition	O
is	O
that	O
the	O
top	O
eigenvectors	O
capture	O
the	O
salient	O
neighborhood	O
structure	O
.	O
	
Our	O
experiments	O
in	O
§	O
6	O
confirm	O
this	O
:	O
using	O
as	O
few	O
as	O
k	O
=	O
4	O
eigenvectors	O
per	O
channel	O
for	O
patches	O
of	O
size	O
m	O
=	O
5	O
is	O
sufficient	O
.	O
	
As	O
our	O
second	O
speedup	O
,	O
we	O
observe	O
that	O
the	O
projection	O
Qᵀp	O
can	O
be	O
computed	O
by	O
a	O
series	O
of	O
k	B-Method
convolutions	I-Method
between	O
a	O
channel	O
image	O
and	O
each	O
m×m	B-Method
filter	I-Method
reshaped	O
from	O
its	O
corresponding	O
eigenvector	O
(	O
column	O
of	O
Q	O
)	O
.	O
	
This	O
is	O
possible	O
because	O
the	O
covariance	O
matrix	O
Σ	O
is	O
shared	O
across	O
all	O
patches	O
per	O
channel	O
and	O
hence	O
the	O
derived	O
Q	B-Method
is	O
likewise	O
spatially	O
invariant	O
.	O
	
Decorrelating	O
all	O
10	O
channels	O
in	O
an	O
entire	O
feature	B-Method
pyramid	I-Method
for	O
a	O
640×	O
480	O
image	O
takes	O
	
about	O
.5	O
seconds	O
.	O
	
In	O
summary	O
,	O
we	O
modify	O
ACF	B-Method
by	O
taking	O
the	O
original	O
10	O
channels	O
and	O
applying	O
k	O
=	O
4	O
decorrelating	B-Method
(	I-Method
linear	I-Method
)	I-Method
filters	I-Method
per	O
channel	O
.	O
	
The	O
result	O
is	O
a	O
set	O
of	O
40	O
locally	B-Method
decorrelated	I-Method
channel	I-Method
features	I-Method
(	O
LDCF	B-Method
)	O
.	O
	
To	O
further	O
increase	O
efficiency	O
,	O
we	O
downsample	O
the	O
decorrelated	O
channels	O
by	O
a	O
factor	O
of	O
2x	O
which	O
has	O
negligible	O
impact	O
on	O
accuracy	B-Metric
but	O
reduces	O
feature	O
dimension	O
to	O
the	O
original	O
value	O
.	O
	
Given	O
the	O
new	O
locally	O
decorrelated	O
channels	O
,	O
all	O
other	O
steps	O
of	O
ACF	B-Task
training	I-Task
and	O
testing	B-Task
are	O
identical	O
.	O
	
The	O
extra	O
implementation	O
effort	O
is	O
likewise	O
minimal	O
:	O
given	O
the	O
decorrelation	B-Method
filters	I-Method
,	O
a	O
few	O
lines	O
of	O
code	O
suffice	O
to	O
convert	O
ACF	B-Method
into	O
LDCF	B-Method
.	O
	
To	O
further	O
improve	O
clarity	O
,	O
all	O
source	O
code	O
for	O
LDCF	B-Method
will	O
be	O
released	O
.	O
	
Results	O
of	O
the	O
LDCF	B-Method
detector	O
on	O
the	O
INRIA	O
dataset	O
are	O
given	O
in	O
the	O
last	O
row	O
of	O
Table	O
1	O
.	O
	
The	O
LCDF	B-Method
detector	I-Method
(	O
which	O
uses	O
orthogonal	O
splits	O
)	O
improves	O
accuracy	B-Metric
over	O
ACF	B-Method
with	O
oblique	O
splits	O
by	O
an	O
additional	O
1	O
%	O
MR	B-Metric
.	O
	
Training	B-Metric
time	I-Metric
is	O
significantly	O
faster	O
,	O
and	O
indeed	O
,	O
is	O
only	O
∼1	O
minute	O
longer	O
than	O
for	O
the	O
original	O
ACF	B-Method
detector	I-Method
.	O
	
More	O
detailed	O
experiments	O
and	O
results	O
are	O
reported	O
in	O
§	O
6	O
.	O
	
We	O
conclude	O
by	O
(	O
1	O
)	O
describing	O
the	O
estimation	O
of	O
Σ	O
for	O
each	O
channel	O
,	O
(	O
2	O
)	O
showing	O
various	O
visualizations	O
,	O
and	O
(	O
3	O
)	O
discussing	O
the	O
filters	O
themselves	O
and	O
connections	O
to	O
known	O
filters	O
.	O
	
Estimating	B-Task
Σ	I-Task
:	O
We	O
can	O
estimate	O
a	O
spatially	O
constant	O
Σ	O
for	O
each	O
channel	O
using	O
any	O
large	O
collection	O
of	O
natural	O
images	O
.	O
	
Σ	O
for	O
each	O
channel	O
is	O
represented	O
by	O
a	O
spatial	B-Method
autocorrelation	I-Method
function	I-Method
Σ	O
(	O
x	O
,	O
y	O
),(	O
x	O
+	O
∆x	O
,	O
y	O
+	O
∆y	O
)	O
	
=	O
C	O
(	O
∆x	O
,	O
∆y	O
)	O
.	O
	
Given	O
a	O
collection	O
of	O
natural	O
images	O
,	O
we	O
first	O
estimate	O
a	O
separate	O
autocorrelation	B-Method
function	I-Method
for	O
each	O
image	O
and	O
then	O
average	O
the	O
results	O
.	O
	
Naive	O
computation	O
of	O
the	O
final	O
function	O
is	O
O	O
(	O
np2	O
)	O
but	O
the	O
Wiener	B-Method
-	I-Method
Khinchin	I-Method
theorem	I-Method
reduces	O
the	O
complexity	B-Metric
to	O
O	O
(	O
np	O
log	O
p	O
)	O
via	O
the	O
FFT	B-Method
[	O
4	O
]	O
,	O
where	O
n	O
and	O
p	O
denote	O
the	O
number	O
of	O
images	O
and	O
pixels	O
per	O
image	O
,	O
respectively	O
.	O
	
Visualization	B-Task
:	O
Fig	O
.	O
	
3	O
,	O
top	O
-	O
left	O
,	O
illustrates	O
the	O
estimated	O
autocorrelations	O
for	O
each	O
channel	O
.	O
	
Nearby	O
features	O
are	O
highly	O
correlated	O
and	O
oriented	O
gradients	O
are	O
spatially	O
correlated	O
along	O
their	O
orientation	O
due	O
to	O
curvilinear	O
continuity	O
	
[	O
15	O
]	O
.	O
Fig	O
.	O
	
3	O
,	O
bottom	O
-	O
left	O
,	O
shows	O
the	O
decorrelation	B-Method
filters	I-Method
for	O
each	O
channel	O
obtained	O
by	O
reshaping	O
the	O
largest	O
eigenvectors	O
of	O
Σ.	O
	
The	O
largest	O
eigenvectors	O
are	O
smoothing	B-Method
filters	I-Method
while	O
the	O
smaller	O
ones	O
resemble	O
increasingly	O
higher	O
-	O
frequency	B-Method
filters	I-Method
.	O
	
The	O
corresponding	O
eigenvalues	O
decay	O
rapidly	O
and	O
in	O
practice	O
we	O
use	O
the	O
top	O
k	O
=	O
4	O
filters	O
.	O
	
Observe	O
that	O
the	O
decorrelation	B-Method
filters	I-Method
for	O
oriented	O
gradients	O
are	O
aligned	O
to	O
their	O
orientation	O
.	O
	
Finally	O
,	O
Fig	O
.	O
3	O
,	O
right	O
,	O
shows	O
original	O
and	O
decorrelated	O
channels	O
averaged	O
over	O
positive	O
training	O
examples	O
.	O
	
Discussion	O
:	O
	
Our	O
decorrelation	B-Method
filters	I-Method
are	O
closely	O
related	O
to	O
sinusoidal	B-Method
,	I-Method
DCT	I-Method
basis	I-Method
,	O
and	O
Gaussian	B-Method
derivative	I-Method
filters	I-Method
.	O
	
Spatial	O
interactions	O
in	O
natural	O
images	O
are	O
often	O
well	O
-	O
described	O
by	O
Markov	B-Method
models	I-Method
[	O
13	O
]	O
and	O
first	B-Method
-	I-Method
order	I-Method
stationary	I-Method
Markov	I-Method
processes	I-Method
are	O
known	O
to	O
have	O
sinusoidal	B-Method
KLT	I-Method
bases	I-Method
	
[	O
29	O
]	O
.	O
	
In	O
particular	O
,	O
for	O
the	O
LUV	O
color	O
channels	O
,	O
our	O
filters	O
are	O
similar	O
to	O
the	O
discrete	B-Method
cosine	I-Method
transform	I-Method
(	I-Method
DCT	I-Method
)	I-Method
bases	I-Method
that	O
are	O
often	O
used	O
to	O
approximate	O
the	O
KLT	B-Method
.	O
	
For	O
oriented	O
gradients	O
,	O
however	O
,	O
the	O
decorrelation	B-Method
filters	I-Method
are	O
no	O
longer	O
well	O
modeled	O
by	O
the	O
DCT	B-Method
bases	I-Method
(	O
note	O
also	O
that	O
our	O
filters	O
are	O
applied	O
densely	O
whereas	O
the	O
DCT	B-Method
typically	O
uses	O
block	B-Method
processing	I-Method
)	O
.	O
	
Alternatively	O
,	O
we	O
can	O
interpret	O
our	O
filters	O
as	O
Gaussian	B-Method
derivative	I-Method
filters	I-Method
.	O
	
Assume	O
that	O
the	O
autocorrelation	O
is	O
modeled	O
by	O
a	O
squared	B-Method
-	I-Method
exponential	I-Method
functionC	I-Method
(	I-Method
∆x	I-Method
)	O
	
=	O
exp	O
(	O
−∆x2	O
/	O
2l2	O
)	O
,	O
which	O
is	O
fairly	O
reasonable	O
given	O
the	O
estimation	O
results	O
in	O
Fig	O
.	O
	
3	O
.	O
	
In	O
1D	O
,	O
the	O
kth	O
largest	O
eigenfunction	O
of	O
such	O
an	O
autocorrelation	B-Method
function	I-Method
is	O
a	O
k	B-Method
−	I-Method
1	I-Method
order	I-Method
Gaussian	I-Method
derivative	I-Method
filter	I-Method
[	O
28	O
]	O
.	O
	
It	O
is	O
straightforward	O
to	O
extend	O
the	O
result	O
to	O
an	O
anisotropic	B-Task
multivariate	I-Task
case	I-Task
in	O
which	O
case	O
the	O
eigenfunctions	O
are	O
Gaussian	B-Method
directional	I-Method
derivative	I-Method
filters	I-Method
similar	O
to	O
our	O
filters	O
.	O
	
6	O
Experiments	O
	
In	O
this	O
section	O
,	O
we	O
demonstrate	O
the	O
effectiveness	O
of	O
locally	B-Method
decorrelated	I-Method
channel	I-Method
features	I-Method
(	O
LDCF	B-Method
)	O
in	O
the	O
context	O
of	O
pedestrian	B-Task
detection	I-Task
.	O
	
We	O
:	O
(	O
1	O
)	O
study	O
the	O
effect	O
of	O
parameter	O
settings	O
,	O
(	O
2	O
)	O
test	O
variations	O
of	O
our	O
approach	O
,	O
and	O
finally	O
(	O
3	O
)	O
compare	O
our	O
results	O
with	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
.	O
	
Parameters	O
:	O
LDCF	B-Method
has	O
two	O
parameters	O
:	O
the	O
count	O
and	O
size	O
of	O
the	O
decorrelation	B-Method
filters	I-Method
.	O
	
Fig	O
.	O
4	O
(	O
a	O
)	O
and	O
(	O
b	O
)	O
show	O
the	O
results	O
of	O
LDCF	B-Method
on	O
the	O
INRIA	O
dataset	O
while	O
varying	O
the	O
filter	O
count	O
(	O
k	O
)	O
and	O
size	O
(	O
m	O
)	O
,	O
respectively	O
.	O
	
Use	O
of	O
k	O
=	O
4	O
decorrelation	B-Method
filters	I-Method
of	O
size	O
m	O
=	O
5	O
improves	O
performance	O
up	O
to	O
∼4	O
%	O
MR	B-Metric
compared	O
to	O
ACF	B-Method
.	O
	
Inclusion	O
of	O
additional	O
higher	B-Method
-	I-Method
frequency	I-Method
filters	I-Method
or	O
use	O
of	O
larger	O
filters	O
can	O
cause	O
performance	O
degradation	O
.	O
	
For	O
all	O
remaining	O
experiments	O
we	O
fix	O
k	O
=	O
4	O
and	O
m	O
=	O
5	O
.	O
	
Variations	O
:	O
	
We	O
test	O
variants	O
of	O
LDCF	B-Method
and	O
report	O
results	O
on	O
INRIA	O
in	O
Table	O
2	O
.	O
	
LDCF	B-Method
(	O
row	O
7	O
)	O
outperforms	O
all	O
variants	O
,	O
including	O
the	O
baseline	O
(	O
1	O
)	O
.	O
	
Filtering	O
the	O
channels	O
with	O
the	O
smallest	O
k	O
eigenvectors	O
(	O
2	O
)	O
or	O
k	O
random	B-Method
filters	I-Method
(	O
3	O
)	O
performs	O
worse	O
.	O
	
Local	B-Method
decorrelation	I-Method
of	O
only	O
the	O
color	O
channels	O
(	O
4	O
)	O
or	O
only	O
the	O
gradient	O
channels	O
(	O
5	O
)	O
is	O
inferior	O
to	O
decorrelation	O
of	O
all	O
channels	O
.	O
	
Finally	O
,	O
we	O
test	O
constant	B-Method
decorrelation	I-Method
filters	I-Method
obtained	O
from	O
the	O
intensity	O
channel	O
L	O
that	O
resemble	O
the	O
first	O
k	O
DCT	B-Method
basis	I-Method
filters	I-Method
.	O
	
Use	O
of	O
unique	B-Method
filters	I-Method
per	O
channel	O
outperforms	O
use	O
of	O
constant	B-Method
filters	I-Method
across	O
all	O
channels	O
(	O
6	O
)	O
.	O
	
Model	B-Method
Capacity	I-Method
:	O
	
Use	O
of	O
locally	O
decorrelated	O
features	O
implicitly	O
allows	O
for	O
richer	O
,	O
more	O
effective	O
splitting	O
functions	O
,	O
increasing	O
modeling	B-Metric
capacity	I-Metric
and	O
generalization	B-Metric
ability	I-Metric
.	O
	
Inspired	O
by	O
their	O
success	O
,	O
we	O
explore	O
additional	O
strategies	O
for	O
augmenting	O
model	B-Task
capacity	I-Task
.	O
	
For	O
the	O
following	O
experiments	O
,	O
we	O
rely	O
solely	O
on	O
the	O
training	O
set	O
of	O
the	O
Caltech	B-Material
Pedestrian	I-Material
Dataset	I-Material
[	O
10	O
]	O
.	O
Of	O
the	O
71	O
minute	O
long	O
training	O
videos	O
(	O
∼128k	O
images	O
)	O
,	O
we	O
use	O
every	O
fourth	O
video	O
as	O
validation	O
data	O
and	O
the	O
rest	O
for	O
training	O
.	O
	
On	O
the	O
validation	O
set	O
,	O
LDCF	B-Method
outperforms	O
ACF	B-Method
by	O
a	O
considerable	O
margin	O
,	O
reducing	O
MR	B-Metric
from	O
46.2	O
%	O
to	O
41.7	O
%	O
.	O
	
We	O
first	O
augment	O
model	O
capacity	O
by	O
increasing	O
the	O
number	O
of	O
trees	O
twofold	O
(	O
to	O
4096	O
)	O
and	O
the	O
sampled	O
negatives	O
fivefold	O
(	O
to	O
50k	O
)	O
.	O
	
Surprisingly	O
,	O
doing	O
so	O
reduces	O
MR	B-Metric
by	O
an	O
additional	O
4	O
%	O
.	O
	
Next	O
,	O
we	O
experiment	O
with	O
increasing	O
maximum	O
tree	O
depth	O
while	O
simultaneously	O
enlarging	O
the	O
amount	O
of	O
data	O
available	O
for	O
training	O
.	O
	
Typically	O
,	O
every	O
30th	O
image	O
in	O
the	O
Caltech	B-Material
dataset	O
is	O
used	O
for	O
training	O
and	O
testing	O
.	O
	
Instead	O
,	O
Figure	O
4	O
(	O
c	O
)	O
shows	O
validation	B-Metric
performance	O
of	O
LDCF	B-Method
with	O
different	O
tree	O
depths	O
while	O
varying	O
the	O
training	O
data	O
sampling	O
interval	O
.	O
	
The	O
impact	O
of	O
maximum	O
depth	O
on	O
performance	O
is	O
quite	O
large	O
.	O
	
At	O
a	O
dense	O
sampling	O
interval	O
of	O
every	O
4th	O
frame	O
,	O
use	O
of	O
depth	O
-	O
5	O
trees	O
(	O
up	O
from	O
depth	O
-	O
2	O
for	O
the	O
original	O
approach	O
)	O
improves	O
performance	O
by	O
an	O
additional	O
5	O
%	O
to	O
32.6	O
%	O
MR	B-Metric
.	O
	
Note	O
that	O
consistent	O
with	O
the	O
generalization	O
bounds	O
of	O
boosting	B-Method
[	O
31	O
]	O
,	O
use	O
of	O
deeper	O
trees	O
requires	O
more	O
data	O
.	O
	
INRIA	O
Results	O
:	O
	
In	O
Figure	O
5	O
(	O
a	O
)	O
we	O
compare	O
LDCF	B-Method
with	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
detectors	O
on	O
INRIA	B-Method
[	O
6	O
]	O
using	O
benchmark	O
code	O
maintained	O
by	O
[	O
10	O
]	O
.	O
Since	O
the	O
INRIA	O
dataset	O
is	O
oft	O
-	O
used	O
as	O
a	O
validation	O
set	O
,	O
including	O
in	O
this	O
work	O
,	O
we	O
include	O
these	O
results	O
for	O
completeness	O
only	O
.	O
	
LDCF	B-Method
is	O
essentially	O
tied	O
for	O
second	O
place	O
with	O
Roerei	O
[	O
2	O
]	O
and	O
Franken	O
[	O
21	O
]	O
and	O
outperformed	O
by	O
∼1	O
%	O
MR	B-Metric
by	O
SketchTokens	O
[	O
19	O
]	O
.	O
	
These	O
approaches	O
all	O
belong	O
to	O
the	O
family	O
of	O
channel	B-Method
features	I-Method
detectors	I-Method
,	O
and	O
as	O
the	O
improvements	O
proposed	O
in	O
this	O
work	O
are	O
orthogonal	O
,	O
the	O
methods	O
could	O
potentially	O
be	O
combined	O
.	O
	
Caltech	B-Material
Results	O
:	O
We	O
present	O
our	O
main	O
result	O
on	O
the	O
Caltech	B-Material
Pedestrian	I-Material
Dataset	I-Material
[	O
10	O
]	O
,	O
see	O
Fig	O
.	O
5	O
(	O
b	O
)	O
,	O
generated	O
using	O
the	O
official	O
evaluation	O
code	O
available	O
online3	O
.	O
	
The	O
Caltech	B-Material
dataset	O
has	O
become	O
the	O
standard	O
for	O
evaluating	B-Task
pedestrian	I-Task
detectors	I-Task
and	O
the	O
latest	O
methods	O
based	O
on	O
deep	B-Method
learning	I-Method
(	O
JointDeep	B-Method
)	O
	
[	O
25	O
]	O
,	O
multi	B-Method
-	I-Method
resolution	I-Method
models	I-Method
(	O
MT	B-Method
-	I-Method
DPM	I-Method
)	O
	
[	O
36	O
]	O
and	O
motion	O
features	O
(	O
ACF	B-Method
+	I-Method
SDt	I-Method
)	O
	
[	O
27	O
]	O
achieve	O
under	O
40	O
%	O
log	B-Metric
-	I-Metric
average	I-Metric
MR	I-Metric
.	O
	
For	O
a	O
complete	O
comparison	O
,	O
we	O
first	O
present	O
results	O
for	O
an	O
augmented	B-Method
capacity	I-Method
ACF	I-Method
model	I-Method
which	O
uses	O
more	O
(	O
4096	O
)	O
and	O
deeper	O
(	O
depth	O
-	O
5	O
)	O
trees	O
trained	O
with	O
RealBoost	B-Method
using	O
dense	B-Method
sampling	I-Method
of	O
the	O
training	O
data	O
(	O
every	O
4th	O
image	O
)	O
.	O
	
See	O
preceding	O
note	O
on	O
model	O
capacity	O
for	O
details	O
and	O
motivation	O
.	O
	
This	O
augmented	B-Method
model	I-Method
(	O
ACF	O
-	O
Caltech	B-Material
+	O
)	O
achieves	O
29.8	O
%	O
MR	B-Metric
,	O
a	O
considerable	O
nearly	O
10	O
%	O
MR	B-Metric
gain	O
over	O
previous	O
methods	O
,	O
including	O
the	O
baseline	B-Method
version	I-Method
of	O
ACF	B-Method
(	O
ACFCaltech	B-Method
)	O
.	O
	
With	O
identical	O
parameters	O
,	O
locally	B-Method
decorrelated	I-Method
channel	I-Method
features	I-Method
(	O
LDCF	B-Method
)	O
further	O
reduce	O
error	B-Metric
to	O
24.9	O
%	O
MR	B-Metric
with	O
substantial	O
gains	O
at	O
higher	O
recall	B-Metric
.	O
	
Overall	O
,	O
this	O
is	O
a	O
massive	O
improvement	O
and	O
represents	O
a	O
nearly	O
10x	O
reduction	O
in	O
false	B-Metric
positives	I-Metric
over	O
the	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
.	O
	
7	O
Conclusion	O
	
In	O
this	O
work	O
we	O
have	O
presented	O
a	O
simple	O
,	O
principled	O
approach	O
for	O
improving	O
boosted	B-Task
object	I-Task
detectors	I-Task
.	O
	
Our	O
core	O
observation	O
was	O
that	O
effective	O
but	O
expensive	O
oblique	O
splits	O
in	O
decision	B-Method
trees	I-Method
can	O
be	O
replaced	O
by	O
orthogonal	O
splits	O
over	O
locally	O
decorrelated	O
data	O
.	O
	
Moreover	O
,	O
due	O
to	O
the	O
stationary	O
statistics	O
of	O
image	O
features	O
,	O
the	O
local	O
decorrelation	O
can	O
be	O
performed	O
efficiently	O
via	O
convolution	B-Method
with	O
a	O
fixed	B-Method
filter	I-Method
bank	I-Method
precomputed	O
from	O
natural	O
images	O
.	O
	
Our	O
approach	O
is	O
general	O
,	O
simple	O
and	O
fast	O
.	O
	
Our	O
method	O
showed	O
dramatic	O
improvement	O
over	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
.	O
	
While	O
some	O
of	O
the	O
gain	O
was	O
from	O
increasing	O
model	O
capacity	O
,	O
use	O
of	O
local	B-Method
decorrelation	I-Method
gave	O
a	O
clear	O
and	O
significant	O
boost	O
.	O
	
Overall	O
,	O
we	O
reduced	O
false	B-Metric
-	I-Metric
positives	I-Metric
tenfold	O
on	O
Caltech	B-Material
.	O
	
Such	O
large	O
gains	O
are	O
fairly	O
rare	O
.	O
	
In	O
the	O
present	O
work	O
we	O
did	O
not	O
decorrelate	O
features	O
across	O
channels	O
(	O
decorrelation	O
was	O
applied	O
independently	O
per	O
channel	O
)	O
.	O
	
This	O
is	O
a	O
clear	O
future	O
direction	O
.	O
	
Testing	O
local	O
decorrelation	O
in	O
the	O
context	O
of	O
other	O
classifiers	B-Method
(	O
e.g.	O
convolutional	B-Method
nets	I-Method
or	O
linear	B-Method
classifiers	I-Method
as	O
in	O
[	O
15	O
]	O
)	O
would	O
also	O
be	O
interesting	O
.	O
	
While	O
the	O
proposed	O
locally	B-Method
decorrelated	I-Method
channel	I-Method
features	I-Method
(	O
LDCF	B-Method
)	O
require	O
only	O
modest	O
modification	O
to	O
existing	O
code	O
,	O
we	O
will	O
release	O
all	O
source	O
code	O
used	O
in	O
this	O
work	O
to	O
ease	O
reproducibility	O
.	O
	
3http:	O
//	O
www.vision.caltech.edu	O
/	O
Image_Datasets	O
/	O
CaltechPedestrians	O
/	O
	
document	O
:	O
Loss	B-Method
-	I-Method
Sensitive	I-Method
Generative	I-Method
Adversarial	I-Method
Networks	I-Method
on	O
Lipschitz	B-Method
Densities	I-Method
	
In	O
this	O
paper	O
,	O
we	O
present	O
the	O
Lipschitz	B-Method
regularization	I-Method
theory	I-Method
and	O
algorithms	O
for	O
a	O
novel	O
Loss	B-Method
-	I-Method
Sensitive	I-Method
Generative	I-Method
Adversarial	I-Method
Network	I-Method
(	O
LS	B-Method
-	I-Method
GAN	I-Method
)	O
.	O
	
Specifically	O
,	O
it	O
trains	O
a	O
loss	O
function	O
to	O
distinguish	O
between	O
real	O
and	O
fake	O
samples	O
by	O
designated	O
margins	O
,	O
while	O
learning	O
a	O
generator	B-Method
alternately	O
to	O
produce	O
realistic	O
samples	O
by	O
minimizing	O
their	O
losses	O
.	O
	
The	O
LS	B-Method
-	I-Method
GAN	I-Method
further	O
regularizes	O
its	O
loss	B-Method
function	I-Method
with	O
a	O
Lipschitz	O
regularity	O
condition	O
on	O
the	O
density	O
of	O
real	O
data	O
,	O
yielding	O
a	O
regularized	B-Method
model	I-Method
that	O
can	O
better	O
generalize	O
to	O
produce	O
new	O
data	O
from	O
a	O
reasonable	O
number	O
of	O
training	O
examples	O
than	O
the	O
classic	O
GAN	B-Method
.	O
	
We	O
will	O
further	O
present	O
a	O
Generalized	B-Method
LS	I-Method
-	I-Method
GAN	I-Method
(	O
GLS	O
-	O
GAN	B-Method
)	O
and	O
show	O
it	O
contains	O
a	O
large	O
family	O
of	O
regularized	O
GAN	B-Method
models	O
,	O
including	O
both	O
LS	B-Method
-	I-Method
GAN	I-Method
and	O
Wasserstein	O
GAN	B-Method
,	O
as	O
its	O
special	O
cases	O
.	O
	
Compared	O
with	O
the	O
other	O
GAN	B-Method
models	O
,	O
we	O
will	O
conduct	O
experiments	O
to	O
show	O
both	O
LS	B-Method
-	I-Method
GAN	I-Method
and	O
GLS	B-Method
-	I-Method
GAN	I-Method
exhibit	O
competitive	O
ability	O
in	O
generating	O
new	O
images	O
in	O
terms	O
of	O
the	O
Minimum	B-Metric
Reconstruction	I-Metric
Error	I-Metric
(	O
MRE	B-Metric
)	O
assessed	O
on	O
a	O
separate	O
test	O
set	O
.	O
	
We	O
further	O
extend	O
the	O
LS	B-Method
-	I-Method
GAN	I-Method
to	O
a	O
conditional	B-Method
form	I-Method
for	O
supervised	B-Task
and	I-Task
semi	I-Task
-	I-Task
supervised	I-Task
learning	I-Task
problems	I-Task
,	O
and	O
demonstrate	O
its	O
outstanding	O
performance	O
on	O
image	O
classification	B-Task
tasks	I-Task
.	O
	
Keywords	O
:	O
	
Generative	B-Method
Adversarial	I-Method
Nets	I-Method
(	O
GANs	B-Method
)	O
,	O
Lipschitz	O
regularity	O
,	O
Minimum	B-Metric
Reconstruction	I-Metric
Error	I-Metric
(	O
MRE	B-Metric
)	O
	
section	O
:	O
Introduction	O
	
A	O
classic	O
Generative	B-Method
Adversarial	I-Method
Net	I-Method
(	O
GAN	B-Method
)	O
learns	O
a	O
discriminator	B-Method
and	O
a	O
generator	B-Method
by	O
playing	O
a	O
two	B-Method
-	I-Method
player	I-Method
minimax	I-Method
game	I-Method
to	O
generate	O
samples	O
from	O
a	O
data	O
distribution	O
.	O
	
The	O
discriminator	O
is	O
trained	O
to	O
distinguish	O
real	O
samples	O
from	O
those	O
generated	O
by	O
the	O
generator	O
,	O
and	O
it	O
in	O
turn	O
guides	O
the	O
generator	O
to	O
produce	O
realistic	O
samples	O
that	O
can	O
fool	O
the	O
discriminator	O
.	O
	
However	O
,	O
from	O
both	O
theoretical	O
and	O
practical	O
perspectives	O
,	O
a	O
critical	O
question	O
is	O
whether	O
the	O
GAN	B-Method
can	O
generate	O
realistic	O
samples	O
from	O
arbitrary	O
data	O
distribution	O
without	O
any	O
prior	O
?	O
	
If	O
not	O
,	O
what	O
kind	O
of	O
prior	O
ought	O
to	O
be	O
imposed	O
on	O
the	O
data	O
distribution	O
to	O
regularize	O
the	O
GAN	B-Method
?	O
	
Indeed	O
,	O
the	O
classic	O
GAN	B-Method
imposes	O
no	O
prior	O
on	O
the	O
data	O
distribution	O
.	O
	
This	O
represents	O
an	O
ambitious	O
goal	O
to	O
generate	O
samples	O
from	O
any	O
distributions	O
.	O
	
However	O
,	O
it	O
in	O
turn	O
requires	O
a	O
non	B-Method
-	I-Method
parametric	I-Method
discriminator	I-Method
to	O
prove	O
the	O
distributional	O
consistency	O
between	O
generated	O
and	O
real	O
samples	O
by	O
assuming	O
the	O
model	O
has	O
infinite	O
capacity	O
(	O
see	O
Section	O
4	O
of	O
)	O
.	O
	
This	O
is	O
a	O
too	O
strong	O
assumption	O
to	O
establish	O
the	O
theoretical	O
basis	O
for	O
the	O
GAN	B-Method
.	O
	
Moreover	O
,	O
with	O
such	O
an	O
assumption	O
,	O
its	O
generalizability	O
becomes	O
susceptible	O
.	O
	
Specifically	O
,	O
one	O
could	O
argue	O
the	O
learned	B-Method
generator	I-Method
may	O
be	O
overfit	O
by	O
an	O
unregularized	B-Method
discriminator	I-Method
in	O
an	O
non	O
-	O
parametric	O
fashion	O
by	O
merely	O
memorizing	O
or	O
interpolating	O
training	O
examples	O
.	O
	
In	O
other	O
words	O
,	O
it	O
could	O
lack	O
the	O
generalization	O
ability	O
to	O
generate	O
new	O
samples	O
out	O
of	O
existing	O
data	O
.	O
	
Indeed	O
,	O
Arora	O
et	O
al	O
.	O
have	O
shown	O
that	O
the	O
GAN	B-Method
minimizing	O
the	O
Jensen	B-Metric
-	I-Metric
Shannon	I-Metric
distance	I-Metric
between	O
the	O
distributions	O
of	O
generated	O
and	O
real	O
data	O
could	O
fail	O
to	O
generalize	O
to	O
produce	O
new	O
samples	O
with	O
a	O
reasonable	O
size	O
of	O
training	O
set	O
.	O
	
Thus	O
,	O
a	O
properly	O
regularized	O
GAN	B-Method
is	O
demanded	O
to	O
establish	O
provable	O
generalizability	O
by	O
focusing	O
on	O
a	O
restricted	O
yet	O
still	O
sufficiently	O
large	O
family	O
of	O
data	O
distributions	O
.	O
	
subsection	O
:	O
Objective	O
:	O
Towards	O
Regularized	O
GANs	B-Method
	
In	O
this	O
paper	O
,	O
we	O
attempt	O
to	O
develop	O
regularization	B-Method
theory	I-Method
and	O
algorithms	O
for	O
a	O
novel	O
Loss	O
-	O
Sensitive	O
GAN	B-Method
(	O
LS	B-Method
-	I-Method
GAN	I-Method
)	O
.	O
	
Specifically	O
,	O
we	O
introduce	O
a	O
loss	B-Method
function	I-Method
to	O
quantify	O
the	O
quality	B-Metric
of	I-Metric
generated	I-Metric
samples	I-Metric
.	O
	
A	O
constraint	O
is	O
imposed	O
so	O
that	O
the	O
loss	O
of	O
a	O
real	O
sample	O
should	O
be	O
smaller	O
than	O
that	O
of	O
a	O
generated	O
counterpart	O
.	O
	
Specifically	O
,	O
in	O
the	O
learning	B-Method
algorithm	I-Method
,	O
we	O
will	O
define	O
margins	O
to	O
separate	O
the	O
losses	O
between	O
generated	O
and	O
real	O
samples	O
.	O
	
Then	O
,	O
an	O
optimal	B-Method
generator	I-Method
will	O
be	O
trained	O
to	O
produce	O
realistic	O
samples	O
with	O
minimum	O
losses	O
.	O
	
The	O
loss	B-Method
function	I-Method
and	O
the	O
generator	B-Method
will	O
be	O
trained	O
in	O
an	O
adversarial	B-Method
fashion	I-Method
until	O
generated	O
samples	O
become	O
indistinguishable	O
from	O
real	O
ones	O
.	O
	
We	O
will	O
also	O
develop	O
new	O
theory	O
to	O
analyze	O
the	O
LS	B-Method
-	I-Method
GAN	I-Method
on	O
the	O
basis	O
of	O
Lipschitz	O
regularity	O
.	O
	
We	O
note	O
that	O
the	O
reason	O
of	O
making	O
non	B-Method
-	I-Method
parametric	I-Method
assumption	I-Method
of	I-Method
infinite	I-Method
capacity	I-Method
on	O
the	O
discriminator	B-Method
in	O
the	O
classic	O
GAN	B-Method
is	O
due	O
to	O
its	O
ambitious	O
goal	O
to	O
generate	O
data	O
from	O
any	O
arbitrary	O
distribution	O
.	O
	
However	O
,	O
no	O
free	O
lunch	O
principle	O
reminds	O
us	O
of	O
the	O
need	O
to	O
impose	O
a	O
suitable	O
prior	O
on	O
the	O
data	O
distribution	O
from	O
which	O
real	O
samples	O
are	O
generated	O
.	O
	
This	O
inspires	O
us	O
to	O
impose	O
a	O
Lipschitz	O
regularity	O
condition	O
by	O
assuming	O
the	O
data	O
density	O
does	O
not	O
change	O
abruptly	O
.	O
	
Based	O
on	O
this	O
mild	O
condition	O
,	O
we	O
will	O
show	O
that	O
the	O
density	O
of	O
generated	O
samples	O
by	O
LS	B-Method
-	I-Method
GAN	I-Method
can	O
exactly	O
match	O
that	O
of	O
real	O
data	O
.	O
	
More	O
importantly	O
,	O
the	O
Lipschitz	O
regularity	O
allows	O
us	O
to	O
prove	O
the	O
LS	B-Method
-	I-Method
GAN	I-Method
can	O
well	O
generalize	O
to	O
produce	O
new	O
data	O
from	O
training	O
examples	O
.	O
	
To	O
this	O
end	O
,	O
we	O
will	O
provide	O
a	O
Probably	B-Metric
Approximate	I-Metric
Correct	I-Metric
(	O
PAC	B-Metric
)-	O
style	O
theorem	O
by	O
showing	O
the	O
empirical	B-Method
LS	I-Method
-	I-Method
GAN	I-Method
model	I-Method
trained	O
with	O
a	O
reasonable	O
number	O
of	O
examples	O
can	O
be	O
sufficiently	O
close	O
to	O
the	O
oracle	B-Method
LS	I-Method
-	I-Method
GAN	I-Method
trained	O
with	O
hypothetically	O
known	O
data	O
distribution	O
,	O
thereby	O
proving	O
the	O
generalizability	O
of	O
LS	B-Method
-	I-Method
GAN	I-Method
in	O
generating	O
samples	O
from	O
any	O
Lipschitz	O
data	O
distribution	O
.	O
	
We	O
will	O
also	O
make	O
a	O
non	B-Method
-	I-Method
parametric	I-Method
analysis	I-Method
of	I-Method
the	I-Method
LS	I-Method
-	I-Method
GAN	I-Method
.	O
	
It	O
does	O
not	O
rely	O
on	O
any	O
parametric	O
form	O
of	O
the	O
loss	O
function	O
to	O
characterize	O
its	O
optimality	O
in	O
the	O
space	O
of	O
Lipschtiz	O
functions	O
.	O
	
It	O
gives	O
both	O
the	O
upper	O
and	O
lower	O
bounds	O
of	O
the	O
optimal	B-Metric
loss	I-Metric
,	O
which	O
are	O
cone	O
-	O
shaped	O
with	O
non	O
-	O
vanishing	B-Task
gradient	I-Task
.	O
	
This	O
suggests	O
that	O
the	O
LS	B-Method
-	I-Method
GAN	I-Method
can	O
provide	O
sufficient	O
gradient	O
to	O
update	O
its	O
LS	B-Method
-	I-Method
GAN	I-Method
generator	O
even	O
if	O
the	O
loss	O
function	O
has	O
been	O
fully	O
optimized	O
,	O
thus	O
avoiding	O
the	O
vanishing	B-Task
gradient	I-Task
problem	O
that	O
could	O
occur	O
in	O
training	O
the	O
GAN	B-Method
.	O
	
subsection	O
:	O
Extensions	O
:	O
Generalized	B-Method
and	O
Conditional	B-Method
LS	I-Method
-	I-Method
GANs	I-Method
	
We	O
further	O
present	O
a	O
generalized	O
form	O
of	O
LS	B-Method
-	I-Method
GAN	I-Method
(	O
GLS	B-Method
-	I-Method
GAN	I-Method
)	O
and	O
conduct	O
experiment	O
to	O
demonstrate	O
it	O
has	O
the	O
best	O
generalization	B-Metric
ability	I-Metric
.	O
	
We	O
will	O
show	O
this	O
is	O
not	O
a	O
surprising	O
result	O
as	O
the	O
GLS	B-Method
-	I-Method
GAN	I-Method
contains	O
a	O
large	O
family	O
of	O
regularized	O
GANs	B-Method
with	O
both	O
LS	B-Method
-	I-Method
GAN	I-Method
and	O
Wasserstein	O
GAN	B-Method
(	O
WGAN	B-Method
)	O
as	O
its	O
special	O
cases	O
.	O
	
Moreover	O
,	O
we	O
will	O
extend	O
a	O
Conditional	B-Method
LS	I-Method
-	I-Method
GAN	I-Method
(	O
CLS	B-Method
-	I-Method
GAN	I-Method
)	O
that	O
can	O
generate	O
samples	O
from	O
given	O
conditions	O
.	O
	
In	O
particular	O
,	O
with	O
class	O
labels	O
being	O
conditions	O
,	O
the	O
learned	O
loss	O
function	O
can	O
be	O
used	O
as	O
a	O
classifier	B-Method
for	O
both	O
supervised	B-Task
and	I-Task
semi	I-Task
-	I-Task
supervised	I-Task
learning	I-Task
.	O
	
The	O
advantage	O
of	O
such	O
a	O
classifier	B-Method
arises	O
from	O
its	O
ability	O
of	O
exploring	O
generated	O
examples	O
to	O
uncover	O
intrinsic	O
variations	O
for	O
different	O
classes	O
.	O
	
Experiment	O
results	O
demonstrate	O
competitive	O
performance	O
of	O
the	O
CLS	B-Method
-	I-Method
GAN	I-Method
classifier	I-Method
compared	O
with	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
.	O
	
subsection	O
:	O
Paper	O
Structure	O
	
The	O
remainder	O
of	O
this	O
paper	O
is	O
organized	O
as	O
follows	O
.	O
	
Section	O
[	O
reference	O
]	O
reviews	O
the	O
related	O
work	O
,	O
and	O
the	O
proposed	O
LS	B-Method
-	I-Method
GAN	I-Method
is	O
presented	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
In	O
Section	O
[	O
reference	O
]	O
,	O
we	O
will	O
analyze	O
the	O
LS	B-Method
-	I-Method
GAN	I-Method
by	O
proving	O
the	O
distributional	O
consistency	O
between	O
generated	O
and	O
real	O
data	O
with	O
the	O
Lipschitz	O
regularity	O
condition	O
on	O
the	O
data	O
distribution	O
.	O
	
In	O
Section	O
[	O
reference	O
]	O
,	O
we	O
will	O
discuss	O
the	O
generalizability	B-Task
problem	I-Task
arising	O
from	O
using	O
sample	B-Method
means	I-Method
to	O
approximate	O
the	O
expectations	O
in	O
the	O
training	O
objectives	O
.	O
	
We	O
will	O
make	O
a	O
comparison	O
with	O
Wasserstein	O
GAN	B-Method
(	O
WGAN	B-Method
)	O
in	O
Section	O
[	O
reference	O
]	O
,	O
and	O
present	O
a	O
generalized	O
LS	B-Method
-	I-Method
GAN	I-Method
with	O
both	O
WGAN	B-Method
and	O
LS	B-Method
-	I-Method
GAN	I-Method
as	O
its	O
special	O
cases	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
A	O
non	B-Method
-	I-Method
parametric	I-Method
analysis	I-Method
of	O
the	O
algorithm	O
is	O
followed	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Then	O
we	O
will	O
show	O
how	O
the	O
model	O
can	O
be	O
extended	O
to	O
a	O
conditional	B-Method
model	I-Method
for	O
both	O
supervised	B-Task
and	I-Task
semi	I-Task
-	I-Task
supervised	I-Task
learning	I-Task
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Experiment	O
results	O
are	O
presented	O
in	O
Section	O
[	O
reference	O
]	O
,	O
and	O
we	O
conclude	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Source	O
codes	O
.	O
	
The	O
source	O
codes	O
for	O
both	O
LS	B-Method
-	I-Method
GAN	I-Method
and	O
GLS	B-Method
-	I-Method
GAN	I-Method
are	O
available	O
at	O
,	O
in	O
the	O
frameworks	O
of	O
torch	O
,	O
pytorch	O
and	O
tensorflow	B-Method
.	O
	
LS	B-Method
-	I-Method
GAN	I-Method
is	O
also	O
supported	O
by	O
Microsoft	O
CNTK	O
at	O
.	O
	
section	O
:	O
Related	O
Work	O
	
Deep	B-Method
generative	I-Method
models	I-Method
,	O
especially	O
the	O
Generative	O
Adversarial	O
Net	O
(	O
GAN	B-Method
)	O
,	O
have	O
attracted	O
many	O
attentions	O
recently	O
due	O
to	O
their	O
demonstrated	O
abilities	O
of	O
generating	O
real	O
samples	O
following	O
the	O
underlying	O
data	O
densities	O
.	O
	
In	O
particular	O
,	O
the	O
GAN	B-Method
attempts	O
to	O
learn	O
a	O
pair	O
of	O
discriminator	B-Method
and	I-Method
generator	I-Method
by	O
playing	O
a	O
maximin	B-Method
game	I-Method
to	O
seek	O
an	O
equilibrium	O
,	O
in	O
which	O
the	O
discriminator	O
is	O
trained	O
by	O
distinguishing	O
real	O
samples	O
from	O
generated	O
ones	O
and	O
the	O
generator	B-Method
is	O
optimized	O
to	O
produce	O
samples	O
that	O
can	O
fool	O
the	O
discriminator	O
.	O
	
A	O
family	O
of	O
GAN	B-Method
architectures	O
have	O
been	O
proposed	O
to	O
implement	O
this	O
idea	O
.	O
	
For	O
example	O
,	O
recent	O
progresses	O
have	O
shown	O
impressive	O
performances	O
on	O
synthesizing	O
photo	O
-	O
realistic	O
images	O
by	O
constructing	O
multiple	O
strided	B-Method
and	I-Method
factional	I-Method
-	I-Method
strided	I-Method
convolutional	I-Method
layers	I-Method
for	O
discriminators	B-Method
and	O
generators	B-Method
.	O
	
On	O
the	O
contrary	O
,	O
proposed	O
to	O
use	O
a	O
Laplacian	B-Method
pyramid	I-Method
to	O
produce	O
high	O
-	O
quality	O
images	O
by	O
iteratively	O
adding	O
multiple	O
layers	O
of	O
noises	O
at	O
different	O
resolutions	O
.	O
	
presented	O
to	O
train	O
a	O
recurrent	B-Method
generative	I-Method
model	I-Method
by	O
using	O
adversarial	B-Method
training	I-Method
to	O
unroll	O
gradient	B-Method
-	I-Method
based	I-Method
optimizations	I-Method
to	O
create	O
high	O
quality	O
images	O
.	O
	
In	O
addition	O
to	O
designing	O
different	O
GAN	B-Method
networks	O
,	O
research	O
efforts	O
have	O
been	O
made	O
to	O
train	O
the	O
GAN	B-Method
by	O
different	O
criteria	O
.	O
	
For	O
example	O
,	O
presented	O
an	O
energy	O
-	O
based	O
GAN	B-Method
by	O
minimizing	O
an	O
energy	B-Method
function	I-Method
to	O
learn	O
an	O
optimal	B-Method
discriminator	I-Method
,	O
and	O
an	O
auto	B-Method
-	I-Method
encoder	I-Method
structured	I-Method
discriminator	I-Method
is	O
presented	O
to	O
compute	O
the	O
energy	O
.	O
	
The	O
authors	O
also	O
present	O
a	O
theoretical	O
analysis	O
by	O
showing	O
this	O
variant	O
of	O
GAN	B-Method
can	O
generate	O
samples	O
whose	O
density	O
can	O
recover	O
the	O
underlying	O
true	O
data	O
density	O
.	O
	
However	O
,	O
it	O
still	O
needs	O
to	O
assume	O
the	O
discriminator	B-Method
has	O
infinite	O
modeling	O
capacity	O
to	O
prove	O
the	O
result	O
in	O
a	O
non	O
-	O
parametric	O
fashion	O
,	O
and	O
its	O
generalizability	O
of	O
producing	O
new	O
data	O
out	O
of	O
training	O
examples	O
is	O
unknown	O
without	O
theoretical	O
proof	O
or	O
empirical	O
evidence	O
.	O
	
In	O
addition	O
,	O
presented	O
to	O
analyze	O
the	O
GAN	B-Method
from	O
information	B-Task
theoretical	I-Task
perspective	I-Task
,	O
and	O
they	O
seek	O
to	O
minimize	O
the	O
variational	B-Method
estimate	I-Method
of	I-Method
f	I-Method
-	I-Method
divergence	I-Method
,	O
and	O
show	O
that	O
the	O
classic	O
GAN	B-Method
is	O
included	O
as	O
a	O
special	O
case	O
of	O
f	B-Method
-	I-Method
GAN	I-Method
.	O
	
In	O
contrast	O
,	O
InfoGAN	B-Method
proposed	O
another	O
information	O
-	O
theoretic	O
GAN	B-Method
to	O
learn	O
disentangled	B-Method
representations	I-Method
capturing	O
various	O
latent	O
concepts	O
and	O
factors	O
in	O
generating	O
samples	O
.	O
	
Most	O
recently	O
,	O
propose	O
to	O
minimize	O
the	O
Earth	O
-	O
Mover	O
distance	O
between	O
the	O
density	O
of	O
generated	O
samples	O
and	O
the	O
true	O
data	O
density	O
,	O
and	O
they	O
show	O
the	O
resultant	O
Wasserstein	O
GAN	B-Method
(	O
WGAN	B-Method
)	I-Method
can	O
address	O
the	O
vanishing	B-Task
gradient	I-Task
problem	O
that	O
the	O
classic	O
GAN	B-Method
suffers	O
.	O
	
Besides	O
the	O
class	O
of	O
GANs	B-Method
,	O
there	O
exist	O
other	O
models	O
that	O
also	O
attempt	O
to	O
generate	O
natural	O
images	O
.	O
	
For	O
example	O
,	O
rendered	O
images	O
by	O
matching	O
features	O
in	O
a	O
convolutional	B-Method
network	I-Method
with	O
respect	O
to	O
reference	O
images	O
.	O
	
used	O
deconvolutional	B-Method
network	I-Method
to	O
render	O
3D	B-Method
chair	I-Method
models	I-Method
in	O
various	O
styles	O
and	O
viewpoints	O
.	O
	
introduced	O
a	O
deep	B-Method
recurrent	I-Method
neutral	I-Method
network	I-Method
architecture	I-Method
for	O
image	B-Task
generation	I-Task
with	O
a	O
sequence	O
of	O
variational	B-Method
auto	I-Method
-	I-Method
encoders	I-Method
to	O
iteratively	O
construct	O
complex	O
images	O
.	O
	
Recent	O
efforts	O
have	O
also	O
been	O
made	O
on	O
leveraging	O
the	O
learned	O
representations	O
by	O
deep	B-Method
generative	I-Method
networks	I-Method
to	O
improve	O
the	O
classification	B-Metric
accuracy	I-Metric
when	O
it	O
is	O
too	O
difficult	O
or	O
expensive	O
to	O
label	O
sufficient	O
training	O
examples	O
.	O
	
For	O
example	O
,	O
presented	O
variational	B-Method
auto	I-Method
-	I-Method
encoders	I-Method
by	O
combining	O
deep	B-Method
generative	I-Method
models	I-Method
and	O
approximate	B-Method
variational	I-Method
inference	I-Method
to	O
explore	O
both	O
labeled	O
and	O
unlabeled	O
data	O
.	O
treated	O
the	O
samples	O
from	O
the	O
GAN	B-Method
generator	O
as	O
a	O
new	O
class	O
,	O
and	O
explore	O
unlabeled	O
examples	O
by	O
assigning	O
them	O
to	O
a	O
class	O
different	O
from	O
the	O
new	O
one	O
.	O
proposed	O
to	O
train	O
a	O
ladder	B-Method
network	I-Method
by	O
minimizing	O
the	O
sum	B-Metric
of	I-Metric
supervised	I-Metric
and	O
unsupervised	B-Metric
cost	I-Metric
functions	I-Metric
through	O
back	B-Method
-	I-Method
propagation	I-Method
,	O
which	O
avoids	O
the	O
conventional	O
layer	B-Method
-	I-Method
wise	I-Method
pre	I-Method
-	I-Method
training	I-Method
approach	I-Method
.	O
	
presented	O
an	O
approach	O
to	O
learning	O
a	O
discriminative	B-Method
classifier	I-Method
by	O
trading	O
-	O
off	O
mutual	O
information	O
between	O
observed	O
examples	O
and	O
their	O
predicted	O
classes	O
against	O
an	O
adversarial	B-Method
generative	I-Method
model	I-Method
.	O
	
sought	O
to	O
jointly	O
distinguish	O
between	O
not	O
only	O
real	O
and	O
generated	O
samples	O
but	O
also	O
their	O
latent	O
variables	O
in	O
an	O
adversarial	B-Method
process	I-Method
.	O
	
Recently	O
,	O
presented	O
a	O
novel	O
paradigm	O
of	O
localized	O
GANs	B-Method
to	O
explore	O
the	O
local	O
consistency	O
of	O
classifiers	O
in	O
local	O
coordinate	O
charts	O
,	O
as	O
well	O
as	O
showed	O
an	O
intrinsic	O
connection	O
with	O
Laplace	O
-	O
Beltrami	O
operator	O
along	O
the	O
manifold	O
.	O
	
These	O
methods	O
have	O
shown	O
promising	O
results	O
for	O
classification	B-Task
tasks	I-Task
by	O
leveraging	O
deep	B-Method
generative	I-Method
models	I-Method
.	O
	
section	O
:	O
Loss	O
-	O
Sensitive	O
GAN	B-Method
	
The	O
classic	O
GAN	B-Method
consists	O
of	O
two	O
players	O
–	O
	
a	O
generator	B-Method
producing	O
samples	O
from	O
random	O
noises	O
,	O
and	O
a	O
discriminator	B-Method
distinguishing	O
real	O
and	O
fake	O
samples	O
.	O
	
The	O
generator	B-Method
and	O
discriminator	B-Method
are	O
trained	O
in	O
an	O
adversarial	B-Method
fashion	I-Method
to	O
reach	O
an	O
equilibrium	O
in	O
which	O
generated	O
samples	O
become	O
indistinguishable	O
from	O
their	O
real	O
counterparts	O
.	O
	
On	O
the	O
contrary	O
,	O
in	O
the	O
LS	B-Method
-	I-Method
GAN	I-Method
we	O
seek	O
to	O
learn	O
a	O
loss	O
function	O
parameterized	O
with	O
by	O
assuming	O
that	O
a	O
real	O
example	O
ought	O
to	O
have	O
a	O
smaller	O
loss	O
than	O
a	O
generated	O
sample	O
by	O
a	O
desired	O
margin	O
.	O
	
Then	O
the	O
generator	O
can	O
be	O
trained	O
to	O
generate	O
realistic	O
samples	O
by	O
minimizing	O
their	O
losses	O
.	O
	
Formally	O
,	O
consider	O
a	O
generator	B-Method
function	I-Method
that	O
produces	O
a	O
sample	O
by	O
transforming	O
a	O
noise	O
input	O
drawn	O
from	O
a	O
simple	O
distribution	B-Method
such	O
as	O
uniform	B-Method
and	I-Method
Gaussian	I-Method
distributions	I-Method
.	O
	
Then	O
for	O
a	O
real	O
example	O
and	O
a	O
generated	O
sample	O
,	O
the	O
loss	B-Method
function	I-Method
can	O
be	O
trained	O
to	O
distinguish	O
them	O
with	O
the	O
following	O
constraint	O
:	O
where	O
is	O
the	O
margin	O
measuring	O
the	O
difference	O
between	O
and	O
.	O
	
This	O
constraint	O
requires	O
a	O
real	O
sample	O
be	O
separated	O
from	O
a	O
generated	O
counterpart	O
in	O
terms	O
of	O
their	O
losses	O
by	O
at	O
least	O
a	O
margin	O
of	O
.	O
	
The	O
above	O
hard	O
constraint	O
can	O
be	O
relaxed	O
by	O
introducing	O
a	O
nonnegative	O
slack	O
variable	O
that	O
quantifies	O
the	O
violation	O
of	O
the	O
above	O
constraint	O
.	O
	
This	O
results	O
in	O
the	O
following	O
minimization	B-Task
problem	I-Task
to	O
learn	O
the	O
loss	O
function	O
given	O
a	O
fixed	O
generator	O
,	O
where	O
is	O
a	O
positive	O
balancing	O
parameter	O
,	O
and	O
is	O
the	O
data	O
distribution	O
of	O
real	O
samples	O
.	O
	
The	O
first	O
term	O
minimizes	O
the	O
expected	O
loss	O
function	O
over	O
data	O
distribution	O
since	O
a	O
smaller	O
loss	O
is	O
preferred	O
on	O
real	O
samples	O
.	O
	
The	O
second	O
term	O
is	O
the	O
expected	B-Metric
error	I-Metric
caused	O
by	O
the	O
violation	O
of	O
the	O
constraint	O
.	O
	
Without	O
loss	O
of	O
generality	O
,	O
we	O
require	O
the	O
loss	O
function	O
should	O
be	O
nonnegative	O
.	O
	
Given	O
a	O
fixed	O
loss	O
function	O
,	O
on	O
the	O
other	O
hand	O
,	O
one	O
can	O
solve	O
the	O
following	O
minimization	B-Task
problem	I-Task
to	O
find	O
an	O
optimal	O
generator	O
.	O
	
We	O
can	O
use	O
and	O
to	O
denote	O
the	O
density	O
of	O
samples	O
generated	O
by	O
and	O
respectively	O
,	O
with	O
being	O
drawn	O
from	O
.	O
	
However	O
,	O
for	O
the	O
simplicity	O
of	O
notations	O
,	O
we	O
will	O
use	O
and	O
to	O
denote	O
and	O
without	O
explicitly	O
mentioning	O
and	O
that	O
should	O
be	O
clear	O
in	O
the	O
context	O
.	O
	
Finally	O
,	O
let	O
us	O
summarize	O
the	O
above	O
objectives	O
.	O
	
The	O
LS	B-Method
-	I-Method
GAN	I-Method
optimizes	O
and	O
alternately	O
by	O
seeking	O
an	O
equilibrium	O
such	O
that	O
minimizes	O
which	O
is	O
an	O
equivalent	O
form	O
of	O
(	O
[	O
reference	O
]	O
)	O
with	O
,	O
and	O
minimizes	O
	
In	O
the	O
next	O
section	O
,	O
we	O
will	O
show	O
the	O
consistency	O
between	O
and	O
for	O
LS	B-Method
-	I-Method
GAN	I-Method
.	O
	
section	O
:	O
Theoretical	B-Task
Analysis	I-Task
:	O
Distributional	B-Task
Consistency	I-Task
	
Suppose	O
is	O
a	O
Nash	B-Method
equilibrium	I-Method
that	O
jointly	O
solves	O
(	O
[	O
reference	O
]	O
)	O
and	O
(	O
[	O
reference	O
]	O
)	O
.	O
	
We	O
will	O
show	O
that	O
as	O
,	O
the	O
density	O
distribution	O
of	O
the	O
samples	O
generated	O
by	O
will	O
converge	O
to	O
the	O
real	O
data	O
density	O
.	O
	
First	O
,	O
we	O
have	O
the	O
following	O
definition	O
.	O
	
Definition	O
.	O
	
For	O
any	O
two	O
samples	O
x	O
and	O
z	O
,	O
the	O
loss	O
function	O
⁢F	O
(	O
x	O
)	O
is	O
Lipschitz	O
continuous	O
with	O
respect	O
to	O
a	O
distance	O
metric	O
Δ	O
if	O
with	O
a	O
bounded	O
Lipschitz	O
constant	O
κ	O
,	O
i.e	O
,	O
<	O
κ	O
+	O
∞.	O
	
To	O
prove	O
our	O
main	O
result	O
,	O
we	O
assume	O
the	O
following	O
regularity	O
condition	O
on	O
the	O
data	O
density	O
.	O
	
theorem	O
:	O
.	O
	
The	O
data	B-Method
density	I-Method
P⁢data	I-Method
is	O
supported	O
in	O
a	O
compact	O
set	O
D	O
,	O
and	O
it	O
is	O
Lipschitz	O
continuous	O
wrt	O
Δ	O
with	O
a	O
bounded	O
constant	O
<	O
κ	O
+	O
∞.	O
	
The	O
set	O
of	O
Lipschitz	O
densities	O
with	O
a	O
compact	O
support	O
contain	O
a	O
large	O
family	O
of	O
distributions	O
that	O
are	O
dense	O
in	O
the	O
space	O
of	O
continuous	O
densities	O
.	O
	
For	O
example	O
,	O
the	O
density	O
of	O
natural	O
images	O
are	O
defined	O
over	O
a	O
compact	O
set	O
of	O
pixel	O
values	O
,	O
and	O
it	O
can	O
be	O
consider	O
as	O
Lipschitz	O
continuous	O
,	O
since	O
the	O
densities	O
of	O
two	O
similar	O
images	O
are	O
unlikely	O
to	O
change	O
abruptly	O
at	O
an	O
unbounded	O
rate	O
.	O
	
If	O
real	O
samples	O
are	O
distributed	O
on	O
a	O
manifold	O
(	O
or	O
is	O
supported	O
in	O
a	O
manifold	O
)	O
,	O
we	O
only	O
require	O
the	O
Lipschitz	O
condition	O
hold	O
on	O
this	O
manifold	O
.	O
	
This	O
makes	O
the	O
Lipschitz	O
regularity	O
applicable	O
to	O
the	O
data	O
densities	O
on	O
a	O
thin	O
manifold	O
embedded	O
in	O
the	O
ambient	O
space	O
.	O
	
Let	O
us	O
show	O
the	O
existence	O
of	O
Nash	O
equilibrium	O
such	O
that	O
both	O
the	O
loss	O
function	O
and	O
the	O
density	O
of	O
generated	O
samples	O
are	O
Lipschitz	O
.	O
	
Let	O
be	O
the	O
class	O
of	O
functions	O
over	O
with	O
a	O
bounded	O
yet	O
sufficiently	O
large	O
Lipschitz	O
constant	O
such	O
that	O
belongs	O
to	O
.	O
	
It	O
is	O
not	O
difficult	O
to	O
show	O
that	O
the	O
space	O
is	O
convex	O
and	O
compact	O
if	O
its	O
member	O
functions	O
are	O
supported	O
in	O
a	O
compact	O
set	O
.	O
	
In	O
addition	O
,	O
we	O
note	O
both	O
and	O
are	O
convex	O
in	O
and	O
in	O
.	O
	
Then	O
,	O
according	O
to	O
the	O
Sion	O
’s	O
theorem	O
,	O
with	O
and	O
being	O
optimized	O
over	O
,	O
there	O
exists	O
a	O
Nash	O
equilibrium	O
.	O
	
Thus	O
,	O
we	O
have	O
the	O
following	O
lemma	O
.	O
	
theorem	O
:	O
.	O
	
Under	O
Assumption	O
,	O
there	O
exists	O
a	O
Nash	O
equilibrium	O
(	O
θ*	O
,	O
ϕ	O
*	O
)	O
such	O
that	O
both	O
Lθ	B-Method
*	I-Method
and	O
PG	B-Method
*	I-Method
are	O
Lipschitz	O
.	O
	
Now	O
we	O
can	O
prove	O
the	O
main	O
lemma	O
of	O
this	O
paper	O
.	O
	
The	O
Lipschitz	O
regularity	O
relaxes	O
the	O
strong	O
non	O
-	O
parametric	O
assumption	O
on	O
the	O
GAN	B-Method
’s	O
discriminator	O
with	O
infinite	O
capacity	O
to	O
the	O
above	O
weaker	O
Lipschitz	O
assumption	O
for	O
the	O
LS	B-Method
-	I-Method
GAN	I-Method
.	O
	
This	O
allows	O
us	O
to	O
show	O
the	O
following	O
lemma	O
that	O
establishes	O
the	O
distributional	O
consistency	O
between	O
the	O
optimal	O
by	O
Problem	O
(	O
[	O
reference	O
]	O
)	O
	
–	O
(	O
[	O
reference	O
]	O
)	O
and	O
the	O
data	O
density	O
.	O
	
theorem	O
:	O
.	O
	
Under	O
Assumption	O
,	O
for	O
a	O
Nash	O
equilibrium	O
(	O
θ*	O
,	O
ϕ	O
*	O
)	O
in	O
Lemma	O
,	O
we	O
have	O
Thus	O
,	O
⁢PG*	O
(	O
x	O
)	O
	
converges	O
to	O
⁢P⁢data	O
(	O
x	O
)	O
as	O
→λ	O
+	O
∞.	O
	
The	O
proof	O
of	O
this	O
lemma	O
is	O
given	O
in	O
Appendix	O
[	O
reference	O
]	O
.	O
	
theorem	O
:	O
.	O
	
By	O
letting	O
λ	O
go	O
infinitely	O
large	O
,	O
the	O
density	O
⁢PG*	O
(	O
x	O
)	O
of	O
generated	O
samples	O
should	O
exactly	O
match	O
the	O
real	O
data	O
density	O
⁢P⁢data	O
(	O
x	O
)	O
.	O
	
Equivalently	O
,	O
we	O
can	O
simply	O
disregard	O
the	O
first	O
loss	O
minimization	O
term	O
in	O
(	O
)	O
as	O
it	O
plays	O
no	O
role	O
as	O
→λ	O
+	O
∞.	O
Putting	O
the	O
above	O
two	O
lemmas	O
together	O
,	O
we	O
have	O
the	O
following	O
theorem	O
.	O
	
theorem	O
:	O
.	O
	
Under	O
Assumption	O
,	O
a	O
Nash	B-Method
equilibrium	I-Method
(	O
θ*	O
,	O
ϕ	O
*	O
)	O
exists	O
such	O
that	O
(	O
i	O
)	O
Lθ	O
	
*	O
and	O
PG	O
	
*	O
are	O
Lipschitz.	O
(	O
ii	O
)	O
	
∫x⁢|	O
-	O
⁢P⁢data	O
(	O
x	O
)	O
⁢PG*	O
(	O
x	O
)	O
|dx≤2λ→0	O
,	O
as	O
→λ	O
+	O
∞.	O
	
section	O
:	O
Learning	B-Task
and	O
Generalizability	O
	
The	O
minimization	B-Task
problems	I-Task
(	O
[	O
reference	O
]	O
)	O
and	O
(	O
[	O
reference	O
]	O
)	O
can	O
not	O
be	O
solved	O
directly	O
since	O
the	O
expectations	O
over	O
the	O
distributions	O
of	O
true	O
data	O
and	O
noises	O
are	O
unavailable	O
or	O
intractable	O
.	O
	
Instead	O
,	O
one	O
can	O
approximate	O
them	O
with	O
empirical	B-Method
means	I-Method
on	O
a	O
set	O
of	O
finite	O
real	O
examples	O
and	O
noise	O
vectors	O
drawn	O
from	O
and	O
respectively	O
.	O
	
This	O
results	O
in	O
the	O
following	O
two	O
alternative	O
problems	O
.	O
	
and	O
where	O
the	O
random	O
vectors	O
used	O
in	O
(	O
[	O
reference	O
]	O
)	O
can	O
be	O
different	O
from	O
used	O
in	O
(	O
[	O
reference	O
]	O
)	O
.	O
	
The	O
sample	O
mean	O
in	O
the	O
second	O
term	O
of	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
is	O
computed	O
over	O
pairs	O
randomly	O
drawn	O
from	O
real	O
and	O
generated	O
samples	O
,	O
which	O
is	O
an	O
approximation	O
to	O
the	O
second	O
expectation	O
term	O
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
	
subsection	O
:	O
Generalizability	O
	
We	O
have	O
proved	O
the	O
density	O
of	O
generated	O
samples	O
by	O
the	O
LS	B-Method
-	I-Method
GAN	I-Method
is	O
consistent	O
with	O
the	O
real	O
data	O
density	O
in	O
Theorem	O
[	O
reference	O
]	O
.	O
	
This	O
consistency	O
is	O
established	O
based	O
on	O
the	O
two	O
oracle	B-Metric
objectives	I-Metric
(	O
[	O
reference	O
]	O
)	O
and	O
(	O
[	O
reference	O
]	O
)	O
.	O
	
However	O
,	O
in	O
practice	O
,	O
the	O
population	O
expectations	O
in	O
these	O
two	O
objectives	O
can	O
not	O
be	O
computed	O
directly	O
over	O
and	O
.	O
	
Instead	O
,	O
they	O
are	O
approximated	O
in	O
(	O
[	O
reference	O
]	O
)	O
and	O
(	O
[	O
reference	O
]	O
)	O
by	O
sample	B-Method
means	I-Method
on	O
a	O
finite	O
set	O
of	O
real	O
and	O
generated	O
examples	O
.	O
	
This	O
raises	O
the	O
question	O
about	O
the	O
generalizability	O
of	O
the	O
LS	B-Method
-	I-Method
GAN	I-Method
model	O
.	O
	
We	O
wonder	O
,	O
with	O
more	O
training	O
examples	O
,	O
if	O
the	O
empirical	B-Method
model	I-Method
trained	O
with	O
finitely	O
many	O
examples	O
can	O
generalize	O
to	O
the	O
oracle	B-Method
model	I-Method
.	O
	
In	O
particular	O
,	O
we	O
wish	O
to	O
estimate	O
the	O
sample	B-Metric
complexity	I-Metric
of	O
how	O
many	O
examples	O
are	O
required	O
to	O
sufficiently	O
bound	O
the	O
generalization	O
difference	O
between	O
the	O
empirical	O
and	O
oracle	O
objectives	O
.	O
	
Arora	O
et	O
al	O
.	O
has	O
proposed	O
a	O
neural	B-Method
network	I-Method
distance	I-Method
to	O
analyze	O
the	O
generalization	B-Metric
ability	I-Metric
for	O
the	O
GAN	B-Method
.	O
	
However	O
,	O
this	O
neural	B-Method
network	I-Method
distance	I-Method
can	O
not	O
be	O
directly	O
applied	O
here	O
,	O
as	O
it	O
is	O
not	O
related	O
with	O
the	O
objectives	O
that	O
are	O
used	O
to	O
train	O
the	O
LS	B-Method
-	I-Method
GAN	I-Method
.	O
	
So	O
the	O
generalization	B-Metric
ability	I-Metric
in	O
terms	O
of	O
the	O
neural	O
network	O
distance	O
does	O
not	O
imply	O
the	O
LS	B-Method
-	I-Method
GAN	I-Method
could	O
also	O
generalize	O
.	O
	
Thus	O
,	O
a	O
direct	O
generalization	B-Method
analysis	I-Method
of	O
the	O
LS	B-Method
-	I-Method
GAN	I-Method
is	O
required	O
based	O
on	O
its	O
own	O
objectives	O
.	O
	
First	O
,	O
let	O
us	O
consider	O
the	O
generalization	B-Task
in	O
terms	O
of	O
.	O
	
This	O
objective	O
is	O
used	O
to	O
train	O
the	O
loss	B-Method
function	I-Method
to	O
distinguish	O
between	O
real	O
and	O
generated	O
samples	O
.	O
	
Consider	O
the	O
oracle	B-Metric
objective	I-Metric
(	O
[	O
reference	O
]	O
)	O
with	O
the	O
population	O
expectations	O
and	O
the	O
empirical	B-Metric
objective	I-Metric
(	O
[	O
reference	O
]	O
)	O
with	O
the	O
sample	O
means	O
We	O
need	O
to	O
show	O
if	O
and	O
how	O
fast	O
the	O
difference	O
would	O
eventually	O
vanish	O
as	O
the	O
number	O
of	O
training	O
examples	O
grows	O
.	O
	
To	O
this	O
end	O
,	O
we	O
need	O
to	O
define	O
the	O
following	O
notations	O
about	O
the	O
model	B-Metric
complexity	I-Metric
.	O
	
theorem	O
:	O
.	O
	
We	O
assume	O
that	O
for	O
LS	B-Method
-	I-Method
GAN	I-Method
,	O
the	O
loss	B-Method
function	I-Method
is	O
-	O
Lipschitz	O
in	O
its	O
parameter	O
,	O
i.e.	O
,	O
for	O
any	O
;	O
is	O
-	O
Lipschitz	O
in	O
,	O
i.e.	O
,	O
for	O
any	O
;	O
the	O
distance	O
between	O
two	O
samples	O
is	O
bounded	O
,	O
i.e.	O
,	O
.	O
	
Then	O
we	O
can	O
prove	O
the	O
following	O
generalization	O
theorem	O
in	O
a	O
Probably	O
Approximately	O
Correct	O
(	O
PAC	B-Metric
)	O
style	O
.	O
	
theorem	O
:	O
.	O
	
Under	O
Assumption	O
,	O
with	O
at	O
least	O
probability	O
-	O
1η	O
,	O
we	O
have	O
when	O
the	O
number	O
of	O
samples	O
where	O
C	O
is	O
a	O
sufficiently	O
large	O
constant	O
,	O
and	O
N	O
is	O
the	O
number	O
of	O
parameters	O
of	O
the	O
loss	O
function	O
such	O
that	O
∈θRN	O
.	O
	
The	O
proof	O
of	O
this	O
theorem	O
is	O
given	O
in	O
Appendix	O
[	O
reference	O
]	O
.	O
	
This	O
theorem	O
shows	O
the	O
sample	B-Metric
complexity	I-Metric
to	O
bound	O
the	O
difference	O
between	O
and	O
is	O
polynomial	O
in	O
the	O
model	B-Metric
size	I-Metric
,	O
as	O
well	O
as	O
both	O
Lipschitz	O
constants	O
and	O
.	O
	
Similarly	O
,	O
we	O
can	O
establish	O
the	O
generalizability	O
to	O
train	O
the	O
generator	B-Method
function	I-Method
by	O
considering	O
the	O
empirical	B-Metric
objective	I-Metric
and	O
the	O
oracle	O
objective	O
over	O
empirical	O
and	O
real	O
distributions	O
,	O
respectively	O
.	O
	
We	O
use	O
the	O
following	O
notions	O
to	O
characterize	O
the	O
complexity	B-Metric
of	O
the	O
generator	B-Method
.	O
	
theorem	O
:	O
.	O
	
We	O
assume	O
that	O
The	O
generator	B-Method
function	I-Method
is	O
-	O
Lipschitz	O
in	O
its	O
parameter	O
,	O
i.e.	O
,	O
for	O
any	O
;	O
Also	O
,	O
we	O
have	O
is	O
-	O
Lipschitz	O
in	O
,	O
i.e.	O
,	O
;	O
The	O
samples	O
’s	O
drawn	O
from	O
are	O
bounded	O
,	O
i.e.	O
,	O
.	O
	
Then	O
we	O
can	O
prove	O
the	O
following	O
theorem	O
to	O
establish	O
the	O
generalizability	O
of	O
the	O
generator	O
in	O
terms	O
of	O
.	O
	
theorem	O
:	O
.	O
	
Under	O
Assumption	O
,	O
with	O
at	O
least	O
probability	O
-	O
1η	O
,	O
we	O
have	O
when	O
the	O
number	O
of	O
samples	O
where	O
C′	O
is	O
a	O
sufficiently	O
large	O
constant	O
,	O
and	O
M	O
is	O
the	O
number	O
of	O
parameters	O
of	O
the	O
generator	B-Method
function	I-Method
such	O
that	O
∈ϕRM	O
.	O
	
subsection	O
:	O
Bounded	O
Lipschitz	O
Constants	O
for	O
Regularization	B-Task
	
Our	O
generalization	B-Method
theory	I-Method
in	O
Theorem	O
[	O
reference	O
]	O
conjectures	O
that	O
the	O
required	O
number	O
of	O
training	O
examples	O
is	O
lower	O
bounded	O
by	O
a	O
polynomial	O
of	O
Lipschitz	O
constants	O
and	O
of	O
the	O
loss	O
function	O
wrt	O
and	O
.	O
	
This	O
suggests	O
us	O
to	O
bound	O
both	O
constants	O
to	O
reduce	O
the	O
sample	B-Metric
complexity	I-Metric
of	O
the	O
LS	B-Method
-	I-Method
GAN	I-Method
to	O
improve	O
its	O
generalization	B-Task
performance	O
.	O
	
Specifically	O
,	O
bounding	O
the	O
Lipschitz	O
constants	O
and	O
can	O
be	O
implemented	O
by	O
adding	O
two	O
gradient	O
penalties	O
(	O
I	O
)	O
and	O
(	O
II	O
)	O
to	O
the	O
objective	O
(	O
[	O
reference	O
]	O
)	O
as	O
the	O
surrogate	O
of	O
the	O
Lipschitz	O
constants	O
.	O
	
For	O
simplicity	O
,	O
we	O
ignore	O
the	O
second	O
gradient	O
penalty	O
(	O
II	O
)	O
for	O
in	O
experiments	O
,	O
as	O
the	O
sample	B-Metric
complexity	I-Metric
is	O
only	O
log	O
-	O
linear	O
in	O
it	O
,	O
whose	O
impact	O
on	O
generalization	B-Metric
performance	I-Metric
is	O
negligible	O
compared	O
with	O
that	O
of	O
.	O
	
Otherwise	O
,	O
penalizing	O
(	O
II	O
)	O
needs	O
to	O
compute	O
its	O
gradient	O
wrt	O
,	O
which	O
is	O
with	O
a	O
Hessian	O
matrix	O
,	O
and	O
this	O
is	O
usually	O
computationally	O
demanding	O
.	O
	
Note	O
that	O
the	O
above	O
gradient	B-Method
penalty	I-Method
differs	O
from	O
that	O
used	O
in	O
that	O
aims	O
to	O
constrain	O
the	O
Lipschitz	O
constant	O
close	O
to	O
one	O
as	O
in	O
the	O
definition	O
of	O
the	O
Wasserstein	O
distance	O
.	O
	
However	O
,	O
we	O
are	O
motivated	O
to	O
have	O
lower	O
sample	B-Metric
complexity	I-Metric
by	O
directly	O
minimizing	O
the	O
Lipschitz	O
constant	O
rather	O
than	O
constraining	O
it	O
to	O
one	O
.	O
	
Two	O
gradient	B-Method
penalty	I-Method
approaches	I-Method
are	O
thus	O
derived	O
from	O
different	O
theoretical	O
perspectives	O
,	O
and	O
also	O
make	O
practical	O
differences	O
in	O
experiments	O
.	O
	
section	O
:	O
Wasserstein	O
GAN	B-Method
and	O
Generalized	B-Method
LS	I-Method
-	I-Method
GAN	I-Method
	
In	O
this	O
section	O
,	O
we	O
discuss	O
two	O
issues	O
about	O
LS	B-Method
-	I-Method
GAN	I-Method
.	O
	
First	O
,	O
we	O
discuss	O
its	O
connection	O
with	O
the	O
Wasserstein	O
GAN	B-Method
(	O
WGAN	B-Method
)	O
,	O
and	O
then	O
show	O
that	O
the	O
WGAN	B-Method
is	O
a	O
special	O
case	O
of	O
a	O
generalized	O
form	O
of	O
LS	B-Method
-	I-Method
GAN	I-Method
.	O
	
subsection	O
:	O
Comparison	O
with	O
Wasserstein	O
GAN	B-Method
	
We	O
notice	O
that	O
the	O
recently	O
proposed	O
Wasserstein	O
GAN	B-Method
(	O
WGAN	B-Method
)	O
uses	O
the	O
Earth	B-Method
-	I-Method
Mover	I-Method
(	I-Method
EM	I-Method
)	I-Method
distance	I-Method
to	O
address	O
the	O
vanishing	B-Task
gradient	I-Task
and	O
saturated	B-Task
JS	I-Task
distance	I-Task
problems	I-Task
in	O
the	O
classic	O
GAN	B-Method
by	O
showing	O
the	O
EM	B-Method
distance	I-Method
is	O
continuous	O
and	O
differentiable	O
almost	O
everywhere	O
.	O
	
While	O
both	O
the	O
LS	B-Method
-	I-Method
GAN	I-Method
and	O
the	O
WGAN	B-Method
address	O
these	O
problems	O
from	O
different	O
perspectives	O
that	O
are	O
independently	O
developed	O
almost	O
simultaneously	O
,	O
both	O
turn	O
out	O
to	O
use	O
the	O
Lipschitz	O
regularity	O
in	O
training	O
their	O
GAN	B-Method
models	O
.	O
	
This	O
constraint	O
plays	O
vital	O
but	O
different	O
roles	O
in	O
the	O
two	O
models	O
.	O
	
In	O
the	O
LS	B-Method
-	I-Method
GAN	I-Method
,	O
the	O
Lipschitz	O
regularity	O
naturally	O
arises	O
from	O
the	O
Lipschitz	O
assumption	O
on	O
the	O
data	O
density	O
and	O
the	O
generalization	O
bound	O
.	O
	
Under	O
this	O
regularity	O
condition	O
,	O
we	O
have	O
proved	O
in	O
Theorem	O
[	O
reference	O
]	O
that	O
the	O
density	O
of	O
generated	O
samples	O
matches	O
the	O
underlying	O
data	O
density	O
.	O
	
On	O
the	O
contrary	O
,	O
the	O
WGAN	B-Method
introduces	O
the	O
Lipschitz	O
constraint	O
from	O
the	O
Kantorovich	B-Method
-	I-Method
Rubinstein	I-Method
duality	I-Method
of	O
the	O
EM	B-Method
distance	I-Method
but	O
it	O
is	O
not	O
proved	O
in	O
if	O
the	O
density	O
of	O
samples	O
generated	O
by	O
WGAN	B-Method
is	O
consistent	O
with	O
that	O
of	O
real	O
data	O
.	O
	
Here	O
we	O
assert	O
that	O
the	O
WGAN	B-Method
also	O
models	O
an	O
underlying	O
Lipschitz	B-Method
density	I-Method
.	O
	
To	O
prove	O
this	O
,	O
we	O
restate	O
the	O
WGAN	B-Method
as	O
follows	O
.	O
	
The	O
WGAN	B-Method
seeks	O
to	O
find	O
a	O
critic	B-Method
and	O
a	O
generator	B-Method
such	O
that	O
and	O
Let	O
be	O
the	O
density	O
of	O
samples	O
generated	O
by	O
.	O
	
Then	O
,	O
we	O
prove	O
the	O
following	O
lemma	O
about	O
the	O
WGAN	B-Method
in	O
Appendix	O
[	O
reference	O
]	O
.	O
	
theorem	O
:	O
.	O
	
Under	O
Assumption	O
,	O
given	O
an	O
optimal	O
solution	O
(	O
fw*	O
,	O
gϕ	O
*	O
)	O
to	O
the	O
WGAN	B-Method
such	O
that	O
Pgϕ	O
	
*	O
is	O
Lipschitz	O
,	O
we	O
have	O
This	O
lemma	O
shows	O
both	O
the	O
LS	B-Method
-	I-Method
GAN	I-Method
and	O
the	O
WGAN	B-Method
are	O
based	O
on	O
the	O
same	O
Lipschitz	O
regularity	O
condition	O
.	O
	
Although	O
both	O
methods	O
are	O
derived	O
from	O
very	O
different	O
perspectives	O
,	O
it	O
is	O
interesting	O
to	O
make	O
a	O
comparison	O
between	O
their	O
respective	O
forms	O
.	O
	
Formally	O
,	O
the	O
WGAN	B-Method
seeks	O
to	O
maximize	O
the	O
difference	O
between	O
the	O
first	O
-	O
order	O
moments	O
of	O
under	O
the	O
densities	O
of	O
real	O
and	O
generated	O
examples	O
.	O
	
In	O
this	O
sense	O
,	O
the	O
WGAN	B-Method
can	O
be	O
considered	O
as	O
a	O
kind	O
of	O
first	B-Method
-	I-Method
order	I-Method
moment	I-Method
method	I-Method
.	O
	
Numerically	O
,	O
as	O
shown	O
in	O
the	O
second	O
term	O
of	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
,	O
tends	O
to	O
be	O
minimized	O
to	O
be	O
arbitrarily	O
small	O
over	O
generated	O
samples	O
,	O
which	O
could	O
make	O
be	O
unbounded	O
above	O
.	O
	
This	O
is	O
why	O
the	O
WGAN	B-Method
must	O
be	O
trained	O
by	O
clipping	O
the	O
network	O
weights	O
of	O
on	O
a	O
bounded	O
box	O
to	O
prevent	O
from	O
becoming	O
unbounded	O
above	O
.	O
	
On	O
the	O
contrary	O
,	O
the	O
LS	B-Method
-	I-Method
GAN	I-Method
treats	O
real	O
and	O
generated	O
examples	O
in	O
pairs	O
,	O
and	O
maximizes	O
the	O
difference	O
of	O
their	O
losses	O
up	O
to	O
a	O
data	O
-	O
dependant	O
margin	O
.	O
	
Specifically	O
,	O
as	O
shown	O
in	O
the	O
second	O
term	O
of	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
,	O
when	O
the	O
loss	O
of	O
a	O
generated	O
sample	O
becomes	O
too	O
large	O
wrt	O
	
that	O
of	O
a	O
paired	O
real	O
example	O
,	O
the	O
maximization	O
of	O
will	O
stop	O
if	O
the	O
difference	O
exceeds	O
.	O
	
This	O
prevents	O
the	O
minimization	B-Task
problem	I-Task
(	O
[	O
reference	O
]	O
)	O
unbounded	O
below	O
,	O
making	O
it	O
better	O
posed	O
to	O
solve	O
.	O
	
More	O
importantly	O
,	O
paring	O
real	O
and	O
generated	O
samples	O
in	O
prevents	O
their	O
losses	O
from	O
being	O
decomposed	O
into	O
two	O
separate	O
first	O
-	O
order	O
moments	O
like	O
in	O
the	O
WGAN	B-Method
.	O
	
The	O
LS	B-Method
-	I-Method
GAN	I-Method
makes	O
pairwise	O
comparison	O
between	O
the	O
losses	O
of	O
real	O
and	O
generated	O
samples	O
,	O
thereby	O
enforcing	O
real	O
and	O
generated	O
samples	O
to	O
coordinate	O
with	O
each	O
other	O
to	O
learn	O
the	O
optimal	O
loss	O
function	O
.	O
	
Specifically	O
,	O
when	O
a	O
generated	O
sample	O
becomes	O
close	O
to	O
a	O
paired	O
real	O
example	O
,	O
the	O
LS	B-Method
-	I-Method
GAN	I-Method
will	O
stop	O
increasing	O
the	O
difference	O
between	O
their	O
losses	O
.	O
	
Below	O
we	O
discuss	O
a	O
Generalized	B-Method
LS	I-Method
-	I-Method
GAN	I-Method
(	O
GLS	B-Method
-	I-Method
GAN	I-Method
)	O
model	O
in	O
Section	O
[	O
reference	O
]	O
,	O
and	O
show	O
that	O
both	O
WGAN	B-Method
and	O
LS	B-Method
-	I-Method
GAN	I-Method
are	O
simply	O
two	O
special	O
cases	O
of	O
this	O
GLS	B-Method
-	I-Method
GAN	I-Method
.	O
	
subsection	O
:	O
GLS	B-Method
-	I-Method
GAN	I-Method
:	O
Generalized	B-Method
LS	I-Method
-	I-Method
GAN	I-Method
	
In	O
proving	O
Lemma	O
[	O
reference	O
]	O
,	O
it	O
is	O
noted	O
that	O
we	O
only	O
have	O
used	O
two	O
properties	O
of	O
in	O
the	O
objective	B-Metric
function	I-Metric
training	O
the	O
loss	O
function	O
:	O
1	O
)	O
for	O
any	O
;	O
2	O
)	O
for	O
.	O
	
This	O
inspires	O
us	O
to	O
generalize	O
the	O
LS	B-Method
-	I-Method
GAN	I-Method
with	O
any	O
alternative	O
cost	B-Method
function	I-Method
satisfying	O
these	O
two	O
properties	O
,	O
and	O
this	O
will	O
yield	O
the	O
Generalized	B-Method
LS	I-Method
-	I-Method
GAN	I-Method
(	O
GLS	B-Method
-	I-Method
GAN	I-Method
)	O
.	O
	
We	O
will	O
show	O
that	O
both	O
LS	B-Method
-	I-Method
GAN	I-Method
and	O
WGAN	B-Method
can	O
be	O
seen	O
as	O
two	O
extreme	O
cases	O
of	O
this	O
GLS	B-Method
-	I-Method
GAN	I-Method
with	O
two	O
properly	O
defined	O
cost	O
functions	O
.	O
	
Formally	O
,	O
if	O
a	O
cost	O
function	O
satisfies	O
for	O
any	O
and	O
for	O
any	O
,	O
given	O
a	O
fixed	O
generator	O
,	O
we	O
use	O
the	O
following	O
objective	O
to	O
learn	O
,	O
with	O
highlighting	O
its	O
dependency	O
on	O
a	O
chosen	O
cost	O
function	O
.	O
	
For	O
simplicity	O
,	O
we	O
only	O
involve	O
the	O
second	O
term	O
in	O
(	O
[	O
reference	O
]	O
)	O
to	O
define	O
the	O
generalized	O
objective	O
.	O
	
But	O
it	O
does	O
not	O
affect	O
the	O
conclusion	O
as	O
the	O
role	O
of	O
the	O
first	O
term	O
in	O
(	O
[	O
reference	O
]	O
)	O
	
would	O
vanish	O
with	O
being	O
set	O
to	O
.	O
	
Following	O
the	O
proof	O
of	O
Lemma	O
[	O
reference	O
]	O
,	O
we	O
can	O
prove	O
the	O
following	O
lemma	O
.	O
	
theorem	O
:	O
.	O
	
Under	O
Assumption	O
,	O
given	O
a	O
Nash	B-Method
equilibrium	I-Method
(	O
θ*	O
,	O
ϕ	O
*	O
)	O
jointly	O
minimizing	O
⁢SC	O
(	O
θ	O
,	O
ϕ	O
*	O
)	O
and	O
⁢T	O
(	O
θ*	O
,	O
ϕ	O
)	O
with	O
a	O
cost	O
function	O
C	O
satisfying	O
the	O
above	O
conditions	O
(	O
I	O
)	O
and	O
(	O
II	O
)	O
,	O
we	O
have	O
	
In	O
particular	O
,	O
we	O
can	O
choose	O
a	O
leaky	B-Method
rectified	I-Method
linear	I-Method
function	I-Method
for	O
this	O
cost	B-Method
function	I-Method
,	O
i.e.	O
,	O
with	O
a	O
slope	O
.	O
	
As	O
long	O
as	O
,	O
it	O
is	O
easy	O
to	O
verify	O
satisfies	O
these	O
two	O
conditions	O
.	O
	
Now	O
the	O
LS	B-Method
-	I-Method
GAN	I-Method
is	O
a	O
special	O
case	O
of	O
this	O
Generalized	B-Method
LS	I-Method
-	I-Method
GAN	I-Method
(	O
GLS	O
-	O
GAN	B-Method
)	O
when	O
,	O
as	O
.	O
	
We	O
denote	O
this	O
equivalence	O
as	O
LS	B-Method
-	I-Method
GAN	I-Method
=	O
GLS	O
-	O
GAN	B-Method
(	O
C0	O
)	O
	
What	O
is	O
more	O
interesting	O
is	O
the	O
WGAN	B-Method
,	O
an	O
independently	O
developed	O
GAN	B-Method
model	O
with	O
stable	O
training	O
performance	O
,	O
also	O
becomes	O
a	O
special	O
case	O
of	O
this	O
GLS	B-Method
-	I-Method
GAN	I-Method
with	O
.	O
	
Indeed	O
,	O
when	O
,	O
,	O
and	O
Since	O
the	O
last	O
term	O
is	O
a	O
const	O
,	O
irrespective	O
of	O
,	O
it	O
can	O
be	O
discarded	O
without	O
affecting	O
optimization	O
over	O
.	O
	
Thus	O
,	O
we	O
have	O
	
By	O
comparing	O
this	O
with	O
in	O
(	O
[	O
reference	O
]	O
)	O
,	O
it	O
is	O
not	O
hard	O
to	O
see	O
that	O
the	O
WGAN	B-Method
is	O
equivalent	O
to	O
the	O
GLS	B-Method
-	I-Method
GAN	I-Method
with	O
,	O
with	O
the	O
critic	B-Method
function	I-Method
being	O
equivalent	O
to	O
.	O
	
Thus	O
we	O
have	O
WGAN	B-Method
=	O
	
GLS	O
-	O
GAN	B-Method
(	O
C1	O
)	O
	
Therefore	O
,	O
by	O
varying	O
the	O
slope	O
in	O
,	O
we	O
will	O
obtain	O
a	O
family	O
of	O
the	O
GLS	O
-	O
GANs	B-Method
with	O
varied	O
beyond	O
the	O
LS	B-Method
-	I-Method
GAN	I-Method
and	O
the	O
WGAN	B-Method
.	O
	
Of	O
course	O
,	O
it	O
is	O
unnecessary	O
to	O
limit	O
to	O
a	O
leaky	B-Method
rectified	I-Method
linear	I-Method
function	I-Method
.	O
	
We	O
can	O
explore	O
more	O
cost	O
functions	O
as	O
long	O
as	O
they	O
satisfy	O
the	O
two	O
conditions	O
(	O
I	O
)	O
and	O
(	O
II	O
)	O
.	O
	
In	O
experiments	O
,	O
we	O
will	O
demonstrate	O
the	O
GLS	B-Method
-	I-Method
GAN	I-Method
has	O
competitive	O
generalization	B-Task
performance	O
on	O
generating	O
new	O
images	O
(	O
c.f	O
.	O
	
Section	O
[	O
reference	O
]	O
)	O
.	O
	
section	O
:	O
Non	B-Method
-	I-Method
Parametric	I-Method
Analysis	I-Method
	
Now	O
we	O
can	O
characterize	O
the	O
optimal	O
loss	O
functions	O
learned	O
from	O
the	O
objective	O
(	O
[	O
reference	O
]	O
)	O
,	O
and	O
this	O
will	O
provide	O
us	O
an	O
insight	O
into	O
the	O
LS	B-Method
-	I-Method
GAN	I-Method
model	O
.	O
	
We	O
generalize	O
the	O
non	B-Method
-	I-Method
parametric	I-Method
maximum	I-Method
likelihood	I-Method
method	I-Method
in	O
and	O
consider	O
non	B-Method
-	I-Method
parametric	I-Method
solutions	I-Method
to	O
the	O
optimal	O
loss	O
function	O
by	O
minimizing	O
(	O
[	O
reference	O
]	O
)	O
over	O
the	O
whole	O
class	O
of	O
Lipschitz	O
loss	O
functions	O
.	O
	
Let	O
,	O
i.e.	O
,	O
the	O
first	O
data	O
points	O
are	O
real	O
examples	O
and	O
the	O
rest	O
are	O
generated	O
samples	O
.	O
	
Then	O
we	O
have	O
the	O
following	O
theorem	O
.	O
	
theorem	O
:	O
.	O
	
The	O
following	O
functions	O
^Lθ	O
*	O
and	O
~Lθ	O
*	O
both	O
minimize	O
⁢Sm	O
(	O
θ	O
,	O
ϕ	O
*	O
)	O
in	O
Fκ	B-Method
:	O
with	O
the	O
parameters	O
θ*=	O
[	O
l1*	O
,	O
⋯	O
,	O
l⁢2m*	O
]	O
∈R⁢2	O
m	O
.	O
	
They	O
are	O
supported	O
in	O
the	O
convex	O
hull	O
of	O
{	O
x	O
(	O
1	O
),	O
⋯	O
,	O
x	O
(	O
⁢2	O
m	O
)	O
}	O
,	O
and	O
we	O
have	O
for	O
=	O
i1	O
,	O
⋯	O
,	O
⁢2	O
m	O
,	O
i.e.	O
,	O
their	O
values	O
coincide	O
on	O
{	O
	
x	O
(	O
1	O
),	O
x	O
(	O
2	O
),	O
⋯	O
,	O
x	O
(	O
⁢2m	O
)	O
}.	O
	
The	O
proof	O
of	O
this	O
theorem	O
is	O
given	O
in	O
the	O
appendix	O
.	O
	
From	O
the	O
theorem	O
,	O
it	O
is	O
not	O
hard	O
to	O
show	O
that	O
any	O
convex	O
combination	O
of	O
these	O
two	O
forms	O
attains	O
the	O
same	O
value	O
of	O
,	O
and	O
is	O
also	O
a	O
global	O
minimizer	O
.	O
	
Thus	O
,	O
we	O
have	O
the	O
following	O
corollary	O
.	O
	
theorem	O
:	O
.	O
	
All	O
the	O
functions	O
in	O
minimize	O
Sm	O
in	O
Fκ	O
.	O
	
This	O
shows	O
that	O
the	O
global	O
minimizer	O
is	O
not	O
unique	O
.	O
	
Moreover	O
,	O
through	O
the	O
proof	O
of	O
Theorem	O
[	O
reference	O
]	O
,	O
one	O
can	O
find	O
that	O
and	O
are	O
the	O
upper	O
and	O
lower	O
bound	O
of	O
any	O
optimal	B-Method
loss	I-Method
function	I-Method
solution	I-Method
to	O
the	O
problem	O
(	O
[	O
reference	O
]	O
)	O
.	O
	
In	O
particular	O
,	O
we	O
have	O
the	O
following	O
corollary	O
.	O
	
theorem	O
:	O
.	O
	
For	O
any	O
∈⁢Lθ*	O
(	O
x	O
)	O
Fκ	O
that	O
minimizes	O
Sm	O
,	O
the	O
corresponding	O
⁢^Lθ*	O
(	O
x	O
)	O
and	O
⁢~Lθ*	O
(	O
x	O
)	O
are	O
the	O
lower	O
and	O
upper	O
bounds	O
of	O
⁢Lθ*	O
(	O
x	O
)	O
,	O
i.e.	O
,	O
The	O
proof	O
is	O
given	O
in	O
Appendix	O
[	O
reference	O
]	O
.	O
	
The	O
parameters	O
in	O
(	O
[	O
reference	O
]	O
)	O
can	O
be	O
sought	O
by	O
minimizing	O
where	O
is	O
short	O
for	O
,	O
and	O
the	O
constraints	O
are	O
imposed	O
to	O
ensure	O
the	O
learned	O
loss	O
functions	O
stay	O
in	O
.	O
	
With	O
a	O
greater	O
value	O
of	O
,	O
a	O
larger	O
class	O
of	O
loss	B-Metric
function	I-Metric
will	O
be	O
sought	O
.	O
	
Thus	O
,	O
one	O
can	O
control	O
the	O
modeling	O
ability	O
of	O
the	O
loss	O
function	O
by	O
setting	O
a	O
proper	O
value	O
to	O
.	O
	
Problem	O
(	O
[	O
reference	O
]	O
)	O
is	O
a	O
typical	O
linear	B-Task
programming	I-Task
problem	I-Task
.	O
	
In	O
principle	O
,	O
one	O
can	O
solve	O
this	O
problem	O
to	O
obtain	O
a	O
non	B-Method
-	I-Method
parametric	I-Method
loss	I-Method
function	I-Method
for	O
the	O
LS	B-Method
-	I-Method
GAN	I-Method
.	O
	
Unfortunately	O
,	O
it	O
consists	O
of	O
a	O
large	O
number	O
of	O
constraints	O
,	O
whose	O
scale	O
is	O
at	O
an	O
order	O
of	O
.	O
	
This	O
prevents	O
us	O
from	O
using	O
(	O
[	O
reference	O
]	O
)	O
directly	O
to	O
solve	O
an	O
optimal	O
non	B-Method
-	I-Method
parametric	I-Method
LS	I-Method
-	I-Method
GAN	I-Method
model	I-Method
with	O
a	O
very	O
large	O
number	O
of	O
training	O
examples	O
.	O
	
On	O
the	O
contrary	O
,	O
a	O
more	O
tractable	O
solution	O
is	O
to	O
use	O
a	O
parameterized	B-Method
network	I-Method
to	O
solve	O
the	O
optimization	B-Task
problem	I-Task
(	O
[	O
reference	O
]	O
)	O
constrained	O
in	O
,	O
and	O
iteratively	O
update	O
parameterized	B-Method
and	I-Method
with	O
the	O
gradient	B-Method
descent	I-Method
method	I-Method
.	O
	
Although	O
the	O
non	B-Method
-	I-Method
parametric	I-Method
solution	I-Method
can	O
not	O
be	O
solved	O
directly	O
,	O
it	O
is	O
valuable	O
in	O
shedding	O
some	O
light	O
on	O
what	O
kind	O
of	O
the	O
loss	O
function	O
would	O
be	O
learned	O
by	O
a	O
deep	B-Method
network	I-Method
.	O
	
It	O
is	O
well	O
known	O
that	O
the	O
training	B-Task
of	O
the	O
classic	O
GAN	B-Method
generator	O
suffers	O
from	O
vanishing	B-Task
gradient	I-Task
problem	O
as	O
the	O
discriminator	B-Method
can	O
be	O
optimized	O
very	O
quickly	O
.	O
	
Recent	O
study	O
has	O
revealed	O
that	O
this	O
is	O
caused	O
by	O
using	O
the	O
Jensen	B-Method
-	I-Method
Shannon	I-Method
(	I-Method
JS	I-Method
)	I-Method
distance	I-Method
that	O
becomes	O
locally	O
saturated	O
and	O
gets	O
vanishing	B-Task
gradient	I-Task
to	O
train	O
the	O
GAN	B-Method
generator	O
if	O
the	O
discriminator	B-Method
is	O
over	O
-	O
trained	O
.	O
	
Similar	O
problem	O
has	O
also	O
been	O
found	O
in	O
the	O
energy	O
-	O
based	O
GAN	B-Method
(	O
EBGAN	O
)	O
as	O
it	O
minimizes	O
the	O
total	O
variation	O
that	O
is	O
not	O
continuous	O
or	O
(	O
sub	O
-)	O
differentiable	O
if	O
the	O
corresponding	O
discriminator	B-Method
is	O
fully	O
optimized	O
.	O
	
On	O
the	O
contrary	O
,	O
as	O
revealed	O
in	O
Theorem	O
[	O
reference	O
]	O
and	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
both	O
the	O
upper	O
and	O
lower	O
bounds	O
of	O
the	O
optimal	O
loss	O
function	O
of	O
the	O
LS	B-Method
-	I-Method
GAN	I-Method
are	O
cone	O
-	O
shaped	O
(	O
in	O
terms	O
of	O
that	O
defines	O
the	O
Lipschitz	O
continuity	O
)	O
,	O
and	O
have	O
non	O
-	O
vanishing	B-Task
gradient	I-Task
almost	O
everywhere	O
.	O
	
Moreover	O
,	O
Problem	O
(	O
[	O
reference	O
]	O
)	O
only	O
contains	O
linear	O
objective	O
and	O
constraints	O
;	O
this	O
is	O
contrary	O
to	O
the	O
classic	O
GAN	B-Method
that	O
involves	O
logistic	O
loss	O
terms	O
that	O
are	O
prone	O
to	O
saturation	O
with	O
vanishing	B-Task
gradient	I-Task
.	O
	
Thus	O
,	O
an	O
optimal	B-Method
loss	I-Method
function	I-Method
that	O
is	O
properly	O
sought	O
in	O
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
is	O
unlikely	O
to	O
saturate	O
between	O
these	O
two	O
bounds	O
,	O
and	O
it	O
should	O
be	O
able	O
to	O
provide	O
sufficient	O
gradient	O
to	O
update	O
the	O
generator	O
by	O
descending	O
(	O
[	O
reference	O
]	O
)	O
even	O
if	O
it	O
has	O
been	O
trained	O
till	O
optimality	O
.	O
	
Our	O
experiment	O
also	O
shows	O
that	O
,	O
even	O
if	O
the	O
loss	O
function	O
is	O
quickly	O
trained	O
to	O
optimality	O
,	O
it	O
can	O
still	O
provide	O
sufficient	O
gradient	O
to	O
continuously	O
update	O
the	O
generator	B-Method
in	O
the	O
LS	B-Method
-	I-Method
GAN	I-Method
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
section	O
:	O
Conditional	B-Method
LS	I-Method
-	I-Method
GAN	I-Method
	
The	O
LS	B-Method
-	I-Method
GAN	I-Method
can	O
easily	O
be	O
generalized	O
to	O
produce	O
a	O
sample	O
based	O
on	O
a	O
given	O
condition	O
,	O
yielding	O
a	O
new	O
paradigm	O
of	O
Conditional	B-Method
LS	I-Method
-	I-Method
GAN	I-Method
(	O
CLS	B-Method
-	I-Method
GAN	I-Method
)	O
.	O
	
For	O
example	O
,	O
if	O
the	O
condition	O
is	O
an	O
image	O
class	O
,	O
the	O
CLS	B-Method
-	I-Method
GAN	I-Method
seeks	O
to	O
produce	O
images	O
of	O
the	O
given	O
class	O
;	O
otherwise	O
,	O
if	O
a	O
text	O
description	O
is	O
given	O
as	O
a	O
condition	O
,	O
the	O
model	O
attempts	O
to	O
generate	O
images	O
aligned	O
with	O
the	O
given	O
description	O
.	O
	
This	O
gives	O
us	O
more	O
flexibility	O
in	O
controlling	O
what	O
samples	O
to	O
be	O
generated	O
.	O
	
Formally	O
,	O
the	O
generator	O
of	O
CLS	O
-	O
GAN	B-Method
takes	O
a	O
condition	O
vector	O
as	O
input	O
along	O
with	O
a	O
noise	O
vector	O
to	O
produce	O
a	O
sample	O
.	O
	
To	O
train	O
the	O
model	O
,	O
we	O
define	O
a	O
loss	B-Metric
function	I-Metric
to	O
measure	O
the	O
degree	O
of	O
the	O
misalignment	O
between	O
a	O
data	O
sample	O
and	O
a	O
given	O
condition	O
.	O
	
For	O
a	O
real	O
example	O
aligned	O
with	O
the	O
condition	O
,	O
its	O
loss	B-Metric
function	I-Metric
should	O
be	O
smaller	O
than	O
that	O
of	O
a	O
generated	O
sample	O
by	O
a	O
margin	O
of	O
.	O
	
This	O
results	O
in	O
the	O
following	O
constraint	O
,	O
Like	O
the	O
LS	B-Method
-	I-Method
GAN	I-Method
,	O
this	O
type	O
of	O
constraint	O
yields	O
the	O
following	O
non	B-Method
-	I-Method
zero	I-Method
-	I-Method
sum	I-Method
game	I-Method
to	O
train	O
the	O
CLS	B-Method
-	I-Method
GAN	I-Method
,	O
which	O
seeks	O
a	O
Nash	O
equilibrium	O
so	O
that	O
minimizes	O
and	O
minimizes	O
where	O
denotes	O
either	O
the	O
joint	O
data	O
distribution	O
over	O
in	O
(	O
[	O
reference	O
]	O
)	O
or	O
its	O
marginal	O
distribution	O
over	O
in	O
(	O
[	O
reference	O
]	O
)	O
.	O
	
Playing	O
the	O
above	O
game	O
will	O
lead	O
to	O
a	O
trained	O
pair	O
of	O
loss	O
function	O
and	O
generator	B-Method
.	O
	
We	O
can	O
show	O
that	O
the	O
learned	O
generator	B-Method
can	O
produce	O
samples	O
whose	O
distribution	O
follows	O
the	O
true	O
data	O
density	O
for	O
a	O
given	O
condition	O
.	O
	
To	O
prove	O
this	O
,	O
we	O
say	O
a	O
loss	O
function	O
is	O
Lipschitz	O
if	O
it	O
is	O
Lipschitz	O
continuous	O
in	O
its	O
first	O
argument	O
.	O
	
We	O
also	O
impose	O
the	O
following	O
regularity	O
condition	O
on	O
the	O
conditional	O
density	O
.	O
	
theorem	O
:	O
.	O
	
For	O
each	O
y	O
,	O
the	O
conditional	O
density	O
P⁢data	O
(	O
x|y	O
)	O
is	O
Lipschitz	O
,	O
and	O
is	O
supported	O
in	O
a	O
convex	O
compact	O
set	O
of	O
x.	O
	
Then	O
it	O
is	O
not	O
difficult	O
to	O
prove	O
the	O
following	O
theorem	O
,	O
which	O
shows	O
that	O
the	O
conditional	O
density	O
becomes	O
as	O
.	O
	
Here	O
denotes	O
the	O
density	O
of	O
samples	O
generated	O
by	O
with	O
sampled	O
random	O
noise	O
.	O
	
theorem	O
:	O
.	O
	
Under	O
Assumption	O
,	O
a	O
Nash	B-Method
equilibrium	I-Method
(	O
θ*	O
,	O
ϕ	O
*	O
)	O
exists	O
such	O
that	O
(	O
i	O
)	O
⁢Lθ*	O
(	O
x	O
,	O
y	O
)	O
	
is	O
Lipschitz	O
continuous	O
in	O
x	O
for	O
each	O
y;	O
(	O
ii	O
)	O
PG*	O
(	O
x|y	O
)	O
is	O
Lipschitz	O
continuous;	O
(	O
iii	O
)	O
∫x|P⁢data	O
(	O
x|y	O
)-	O
PG*	O
(	O
x|y	O
)	O
|dx≤2λ	O
.	O
	
In	O
addition	O
,	O
similar	O
upper	O
and	O
lower	O
bounds	O
can	O
be	O
derived	O
to	O
characterize	O
the	O
learned	O
conditional	O
loss	O
function	O
following	O
the	O
same	O
idea	O
for	O
LS	B-Method
-	I-Method
GAN	I-Method
.	O
	
A	O
useful	O
byproduct	O
of	O
the	O
CLS	B-Method
-	I-Method
GAN	I-Method
is	O
one	O
can	O
use	O
the	O
learned	O
loss	O
function	O
to	O
predict	O
the	O
label	O
of	O
an	O
example	O
by	O
The	O
advantage	O
of	O
such	O
a	O
CLS	B-Method
-	I-Method
GAN	I-Method
classifier	I-Method
is	O
it	O
is	O
trained	O
with	O
both	O
labeled	O
and	O
generated	O
examples	O
,	O
the	O
latter	O
of	O
which	O
can	O
improve	O
the	O
training	O
of	O
the	O
classifier	B-Method
by	O
revealing	O
more	O
potential	O
variations	O
within	O
different	O
classes	O
of	O
samples	O
.	O
	
It	O
also	O
provides	O
a	O
way	O
to	O
evaluate	O
the	O
model	O
based	O
on	O
its	O
classification	B-Metric
performance	I-Metric
.	O
	
This	O
is	O
an	O
objective	O
metric	O
we	O
can	O
use	O
to	O
assess	O
the	O
quality	O
of	O
feature	B-Method
representations	I-Method
learned	O
by	O
the	O
model	O
.	O
	
For	O
a	O
classification	B-Task
task	I-Task
,	O
a	O
suitable	O
value	O
should	O
be	O
set	O
to	O
.	O
	
Although	O
Theorem	O
[	O
reference	O
]	O
shows	O
would	O
converge	O
to	O
the	O
true	O
conditional	O
density	O
by	O
increasing	O
,	O
it	O
only	O
ensures	O
it	O
is	O
a	O
good	O
generative	O
rather	O
than	O
classification	B-Method
model	I-Method
.	O
	
However	O
,	O
a	O
too	O
large	O
value	O
of	O
tends	O
to	O
ignore	O
the	O
first	B-Method
loss	I-Method
minimization	I-Method
term	I-Method
of	O
(	O
[	O
reference	O
]	O
)	O
that	O
plays	O
an	O
important	O
role	O
in	O
minimizing	B-Task
classification	I-Task
error	I-Task
.	O
	
Thus	O
,	O
a	O
trade	O
-	O
off	O
should	O
be	O
made	O
to	O
balance	O
between	O
classification	B-Task
and	I-Task
generation	I-Task
objectives	I-Task
.	O
	
subsection	O
:	O
Semi	O
-	O
Supervised	O
LS	B-Method
-	I-Method
GAN	I-Method
	
The	O
above	O
CLS	B-Method
-	I-Method
GAN	I-Method
can	O
be	O
considered	O
as	O
a	O
fully	B-Method
supervised	I-Method
model	I-Method
to	O
classify	O
examples	O
into	O
different	O
classes	O
.	O
	
It	O
can	O
also	O
be	O
extended	O
to	O
a	O
Semi	B-Method
-	I-Method
Supervised	I-Method
model	I-Method
by	O
incorporating	O
unlabeled	O
examples	O
.	O
	
Suppose	O
we	O
have	O
classes	O
indexed	O
by	O
.	O
	
In	O
the	O
CLS	B-Method
-	I-Method
GAN	I-Method
,	O
for	O
each	O
class	O
,	O
we	O
choose	O
a	O
loss	O
function	O
that	O
,	O
for	O
example	O
,	O
can	O
be	O
defined	O
as	O
the	O
negative	O
log	O
-	O
softmax	O
,	O
where	O
is	O
the	O
th	O
activation	O
output	O
from	O
a	O
network	B-Method
layer	I-Method
.	O
	
Suppose	O
we	O
also	O
have	O
unlabeled	O
examples	O
available	O
,	O
and	O
we	O
can	O
define	O
a	O
new	O
loss	O
function	O
for	O
these	O
unlabeled	O
examples	O
so	O
that	O
they	O
can	O
be	O
involved	O
in	O
training	O
the	O
CLS	B-Method
-	I-Method
GAN	I-Method
.	O
	
Consider	O
an	O
unlabeled	O
example	O
,	O
its	O
groundtruth	O
label	O
is	O
unknown	O
.	O
	
However	O
,	O
the	O
best	O
guess	O
of	O
its	O
label	O
can	O
be	O
made	O
by	O
choosing	O
the	O
one	O
that	O
minimizes	O
over	O
,	O
and	O
this	O
inspires	O
us	O
to	O
define	O
the	O
following	O
loss	O
function	O
for	O
the	O
unlabeled	O
example	O
as	O
Here	O
we	O
modify	O
to	O
so	O
can	O
be	O
viewed	O
as	O
the	O
probability	O
that	O
does	O
not	O
belong	O
to	O
any	O
known	O
label	O
.	O
	
Then	O
we	O
have	O
the	O
following	O
loss	B-Task
-	I-Task
sensitive	I-Task
objective	I-Task
that	O
explores	O
unlabeled	O
examples	O
to	O
train	O
the	O
CLS	B-Method
-	I-Method
GAN	I-Method
,	O
This	O
objective	O
is	O
combined	O
with	O
defined	O
in	O
(	O
[	O
reference	O
]	O
)	O
to	O
train	O
the	O
loss	B-Method
function	I-Method
network	I-Method
by	O
minimizing	O
where	O
is	O
a	O
positive	O
hyperparameter	O
balancing	O
the	O
contributions	O
from	O
labeled	O
and	O
labeled	O
examples	O
.	O
	
The	O
idea	O
of	O
extending	O
the	O
GAN	B-Method
for	O
semi	B-Task
-	I-Task
supervised	I-Task
learning	I-Task
has	O
been	O
proposed	O
by	O
Odena	O
and	O
Salimans	O
et	O
al	O
.	O
,	O
where	O
generated	O
samples	O
are	O
assigned	O
to	O
an	O
artificial	O
class	O
,	O
and	O
unlabeled	O
examples	O
are	O
treated	O
as	O
the	O
negative	O
examples	O
.	O
	
Our	O
proposed	O
semi	B-Method
-	I-Method
supervised	I-Method
learning	I-Method
differs	O
in	O
creating	O
a	O
new	O
loss	O
function	O
for	O
unlabeled	O
examples	O
from	O
the	O
losses	O
for	O
existing	O
classes	O
,	O
by	O
minimizing	O
which	O
we	O
make	O
the	O
best	O
guess	O
of	O
the	O
classes	O
of	O
unlabeled	O
examples	O
.	O
	
The	O
guessed	O
labeled	O
will	O
provide	O
additional	O
information	O
to	O
train	O
the	O
CLS	O
-	O
GAN	B-Method
model	O
,	O
and	O
the	O
updated	O
model	O
will	O
in	O
turn	O
improve	O
the	O
guess	O
over	O
the	O
training	O
course	O
.	O
	
The	O
experiments	O
in	O
the	O
following	O
section	O
will	O
show	O
that	O
this	O
approach	O
can	O
generate	O
very	O
competitive	O
performance	O
especially	O
when	O
the	O
labeled	O
data	O
is	O
very	O
limited	O
.	O
	
section	O
:	O
Experiments	O
	
Objective	B-Task
evaluation	I-Task
of	O
a	O
data	B-Method
generative	I-Method
model	I-Method
is	O
not	O
an	O
easy	O
task	O
as	O
there	O
is	O
no	O
consensus	O
criteria	O
to	O
quantify	O
the	O
quality	O
of	O
generated	O
samples	O
.	O
	
For	O
this	O
reason	O
,	O
we	O
will	O
make	O
a	O
qualitative	B-Task
analysis	I-Task
of	I-Task
generated	I-Task
images	I-Task
,	O
and	O
use	O
image	B-Task
classification	I-Task
to	O
quantitatively	O
evaluate	O
the	O
resultant	O
LS	B-Method
-	I-Method
GAN	I-Method
model	O
.	O
	
First	O
,	O
we	O
will	O
assess	O
the	O
quality	O
of	O
generated	B-Metric
images	I-Metric
by	O
the	O
LS	B-Method
-	I-Method
GAN	I-Method
in	O
comparison	O
with	O
the	O
classic	O
GAN	B-Method
model	O
.	O
	
Then	O
,	O
we	O
will	O
make	O
an	O
objective	O
evaluation	O
on	O
the	O
CLS	B-Method
-	I-Method
GAN	I-Method
to	O
classify	B-Task
images	I-Task
.	O
	
This	O
task	O
evaluates	O
the	O
quality	O
of	O
feature	B-Method
representations	I-Method
learned	O
by	O
the	O
CLS	B-Method
-	I-Method
GAN	I-Method
in	O
terms	O
of	O
its	O
classification	B-Metric
accuracy	I-Metric
directly	O
.	O
	
Finally	O
,	O
we	O
will	O
assess	O
the	O
generalizability	O
of	O
various	O
GAN	B-Method
models	O
in	O
generating	O
new	O
images	O
out	O
of	O
training	O
examples	O
by	O
proposing	O
the	O
Minimum	B-Metric
Reconstruction	I-Metric
Error	I-Metric
(	O
MRE	B-Metric
)	O
on	O
a	O
separate	O
test	O
set	O
.	O
	
subsection	O
:	O
Architectures	O
	
We	O
adopted	O
the	O
ideas	O
behind	O
the	O
network	B-Method
architecture	I-Method
for	O
the	O
DCGAN	B-Method
to	O
build	O
the	O
generator	B-Method
and	I-Method
the	I-Method
loss	I-Method
function	I-Method
networks	I-Method
.	O
	
Compared	O
with	O
the	O
conventional	O
CNNs	B-Method
,	O
maxpooling	B-Method
layers	I-Method
were	O
replaced	O
with	O
strided	B-Method
convolutions	I-Method
in	O
both	O
networks	O
,	O
and	O
fractionally	B-Method
-	I-Method
strided	I-Method
convolutions	I-Method
were	O
used	O
in	O
the	O
generator	B-Method
network	I-Method
to	O
upsample	O
feature	O
maps	O
across	O
layers	O
to	O
finer	O
resolutions	O
.	O
	
Batch	B-Method
-	I-Method
normalization	I-Method
layers	I-Method
were	O
added	O
in	O
both	O
networks	O
between	O
convolutional	B-Method
layers	I-Method
,	O
and	O
fully	B-Method
connected	I-Method
layers	I-Method
were	O
removed	O
from	O
these	O
networks	O
.	O
	
However	O
,	O
unlike	O
the	O
DCGAN	B-Method
,	O
the	O
LS	B-Method
-	I-Method
GAN	I-Method
model	O
(	O
unconditional	O
version	O
in	O
Section	O
[	O
reference	O
]	O
)	O
did	O
not	O
use	O
a	O
sigmoid	O
layer	O
as	O
the	O
output	O
for	O
the	O
loss	B-Method
function	I-Method
network	I-Method
.	O
	
Instead	O
,	O
we	O
removed	O
it	O
and	O
directly	O
output	O
the	O
activation	O
before	O
the	O
removed	O
sigmoid	B-Method
layer	I-Method
.	O
	
On	O
the	O
other	O
hand	O
,	O
for	O
the	O
loss	B-Method
function	I-Method
network	I-Method
in	O
CLS	B-Method
-	I-Method
GAN	I-Method
,	O
a	O
global	B-Method
mean	I-Method
-	I-Method
pooling	I-Method
layer	I-Method
was	O
added	O
on	O
top	O
of	O
convolutional	B-Method
layers	I-Method
.	O
	
This	O
produced	O
a	O
feature	O
map	O
that	O
output	O
the	O
conditional	O
loss	O
on	O
different	O
classes	O
.	O
	
In	O
the	O
generator	B-Method
network	I-Method
,	O
Tanh	B-Method
was	O
used	O
to	O
produce	O
images	O
whose	O
pixel	O
values	O
are	O
scaled	O
to	O
.	O
	
Thus	O
,	O
all	O
image	O
examples	O
in	O
datasets	O
were	O
preprocessed	O
to	O
have	O
their	O
pixel	O
values	O
in	O
.	O
	
More	O
details	O
about	O
the	O
design	O
of	O
network	B-Method
architectures	I-Method
can	O
be	O
found	O
in	O
literature	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
network	B-Method
architecture	I-Method
for	O
the	O
CLS	O
-	O
GAN	B-Method
model	O
on	O
CIFAR	B-Material
-	I-Material
10	I-Material
and	O
SVHN	B-Material
datasets	I-Material
in	O
the	O
experiments	O
.	O
	
In	O
particular	O
,	O
the	O
architecture	O
of	O
the	O
loss	B-Method
function	I-Method
network	I-Method
was	O
adapted	O
from	O
that	O
used	O
in	O
with	O
nine	O
hidden	O
layers	O
.	O
	
subsection	O
:	O
Training	O
Details	O
	
The	O
models	O
were	O
trained	O
in	O
a	O
mini	O
-	O
batch	O
of	O
images	O
,	O
and	O
their	O
weights	O
were	O
initialized	O
from	O
a	O
zero	B-Method
-	I-Method
mean	I-Method
Gaussian	I-Method
distribution	I-Method
with	O
a	O
standard	O
deviation	O
of	O
.	O
	
The	O
Adam	B-Method
optimizer	I-Method
was	O
used	O
to	O
train	O
the	O
network	O
with	O
initial	O
learning	B-Metric
rate	I-Metric
and	O
being	O
set	O
to	O
and	O
respectively	O
,	O
while	O
the	O
learning	B-Metric
rate	I-Metric
was	O
annealed	O
every	O
epochs	O
by	O
a	O
factor	O
of	O
.	O
	
The	O
other	O
hyperparameters	O
such	O
as	O
and	O
were	O
chosen	O
based	O
on	O
an	O
independent	O
validation	O
set	O
held	O
out	O
from	O
training	O
examples	O
.	O
	
We	O
also	O
tested	O
various	O
forms	O
of	O
loss	O
margins	O
between	O
real	O
and	O
fake	O
samples	O
.	O
	
For	O
example	O
,	O
we	O
tried	O
the	O
distance	O
between	O
image	O
representations	O
as	O
the	O
margin	O
,	O
and	O
found	O
the	O
best	O
result	O
can	O
be	O
achieved	O
when	O
.	O
	
The	O
distance	O
between	O
convolutional	O
features	O
was	O
supposed	O
to	O
capture	O
perceptual	O
dissimilarity	O
between	O
images	O
.	O
	
But	O
we	O
should	O
avoid	O
a	O
direct	O
use	O
of	O
the	O
convolutional	O
features	O
from	O
the	O
loss	B-Method
function	I-Method
network	I-Method
,	O
since	O
we	O
found	O
they	O
would	O
tend	O
to	O
collapse	O
to	O
a	O
trivial	O
point	O
as	O
the	O
loss	O
margin	O
vanishes	O
.	O
	
The	O
feature	O
maps	O
from	O
a	O
separate	O
pretrained	B-Method
deep	I-Method
network	I-Method
,	O
such	O
as	O
Inception	B-Method
and	I-Method
VGG	I-Method
-	I-Method
16	I-Method
networks	I-Method
,	O
could	O
be	O
a	O
better	O
choice	O
to	O
define	O
the	O
loss	O
margin	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
the	O
images	O
generated	O
by	O
LS	B-Method
-	I-Method
GAN	I-Method
on	O
CelebA	O
with	O
the	O
inception	O
and	O
VGG	O
-	O
16	O
margins	O
.	O
	
However	O
,	O
for	O
a	O
fair	O
comparison	O
,	O
we	O
did	O
not	O
use	O
these	O
external	O
deep	B-Method
networks	I-Method
in	O
other	O
experiments	O
on	O
image	B-Task
generation	I-Task
and	O
classification	B-Task
tasks	I-Task
.	O
	
We	O
simply	O
used	O
the	O
distance	O
between	O
raw	O
images	O
as	O
the	O
loss	O
margin	O
,	O
and	O
it	O
still	O
achieved	O
competitive	O
results	O
.	O
	
This	O
demonstrates	O
the	O
robustness	O
of	O
the	O
proposed	O
method	O
without	O
having	O
to	O
choose	O
a	O
sophisticated	O
loss	O
margin	O
.	O
	
This	O
is	O
also	O
consistent	O
with	O
our	O
theoretical	O
analysis	O
where	O
we	O
do	O
not	O
assume	O
any	O
particular	O
form	O
of	O
loss	O
margin	O
to	O
prove	O
the	O
results	O
.	O
	
For	O
the	O
generator	B-Method
network	I-Method
of	O
LS	B-Method
-	I-Method
GAN	I-Method
,	O
it	O
took	O
a	O
-	O
dimensional	O
random	O
vector	O
drawn	O
from	O
Unif	B-Method
as	O
input	O
.	O
	
For	O
the	O
CLS	O
-	O
GAN	B-Method
generator	O
,	O
an	O
one	B-Method
-	I-Method
hot	I-Method
vector	I-Method
encoding	O
the	O
image	O
class	O
condition	O
was	O
concatenated	O
with	O
the	O
sampled	O
random	O
vector	O
.	O
	
The	O
CLS	B-Method
-	I-Method
GAN	I-Method
was	O
trained	O
by	O
involving	O
both	O
unlabeled	O
and	O
labeled	O
examples	O
as	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
This	O
was	O
compared	O
against	O
the	O
other	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
supervised	B-Method
and	I-Method
semi	I-Method
-	I-Method
supervised	I-Method
models	I-Method
.	O
	
subsection	O
:	O
Generated	O
Images	O
by	O
LS	B-Method
-	I-Method
GAN	I-Method
	
First	O
we	O
made	O
a	O
qualitative	O
comparison	O
between	O
the	O
images	O
generated	O
by	O
the	O
DCGAN	B-Method
and	O
the	O
LS	B-Method
-	I-Method
GAN	I-Method
on	O
the	O
celebA	O
dataset	O
.	O
	
Figure	O
[	O
reference	O
]	O
compares	O
the	O
visual	B-Metric
quality	I-Metric
of	I-Metric
images	I-Metric
generated	O
by	O
LS	B-Method
-	I-Method
GAN	I-Method
and	O
DCGAN	B-Method
after	O
they	O
were	O
trained	O
for	O
epochs	O
,	O
and	O
there	O
was	O
no	O
perceptible	O
difference	O
between	O
the	O
qualities	O
of	O
their	O
generated	O
images	O
.	O
	
However	O
,	O
the	O
DCGAN	B-Method
architecture	I-Method
has	O
been	O
exhaustively	O
fine	O
-	O
tuned	O
in	O
terms	O
of	O
the	O
classic	O
GAN	B-Method
training	O
criterion	O
to	O
maximize	O
the	O
image	B-Task
generation	I-Task
performance	O
.	O
	
It	O
was	O
susceptible	O
that	O
its	O
architecture	O
could	O
be	O
fragile	O
if	O
we	O
make	O
some	O
change	O
to	O
it	O
.	O
	
Here	O
we	O
tested	O
if	O
the	O
LS	B-Method
-	I-Method
GAN	I-Method
can	O
be	O
more	O
robust	O
than	O
the	O
DCGAN	B-Method
when	O
a	O
structure	O
change	O
was	O
made	O
.	O
	
For	O
example	O
,	O
one	O
of	O
the	O
most	O
key	O
components	O
in	O
the	O
DCGAN	B-Method
is	O
the	O
batch	B-Method
normalization	I-Method
inserted	O
between	O
the	O
fractional	B-Method
convolution	I-Method
layers	I-Method
in	O
the	O
generator	B-Method
network	I-Method
.	O
	
It	O
has	O
been	O
reported	O
in	O
literature	O
that	O
the	O
batch	B-Method
normalization	I-Method
not	O
only	O
plays	O
a	O
key	O
role	O
in	O
training	O
the	O
DCGAN	B-Method
model	I-Method
,	O
but	O
also	O
prevents	O
the	O
mode	O
collapse	O
of	O
the	O
generator	O
into	O
few	O
data	O
points	O
.	O
	
The	O
results	O
were	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
If	O
one	O
removed	O
the	O
batch	B-Method
normalization	I-Method
layers	I-Method
from	O
the	O
generator	B-Method
,	O
the	O
DCGAN	B-Method
would	O
collapse	O
without	O
producing	O
any	O
face	O
images	O
.	O
	
On	O
the	O
contrary	O
,	O
the	O
LS	B-Method
-	I-Method
GAN	I-Method
still	O
performed	O
very	O
well	O
even	O
if	O
these	O
batch	B-Method
normalization	I-Method
layers	I-Method
were	O
removed	O
,	O
and	O
there	O
was	O
no	O
perceived	O
deterioration	O
or	O
mode	O
collapse	O
of	O
the	O
generated	O
images	O
.	O
	
This	O
shows	O
that	O
the	O
LS	B-Method
-	I-Method
GAN	I-Method
was	O
more	O
resilient	O
than	O
the	O
DCGAN	B-Method
.	O
	
We	O
also	O
analyzed	O
the	O
magnitude	O
(	O
norm	O
)	O
of	O
the	O
generator	O
’s	O
gradient	O
(	O
in	O
logarithmic	O
scale	O
)	O
in	O
Figure	O
[	O
reference	O
]	O
over	O
iterations	O
.	O
	
With	O
the	O
loss	O
function	O
being	O
updated	O
every	O
iteration	O
,	O
the	O
generator	B-Method
was	O
only	O
updated	O
every	O
,	O
,	O
and	O
iterations	O
.	O
	
From	O
the	O
figure	O
,	O
we	O
note	O
that	O
the	O
magnitude	O
of	O
the	O
generator	O
’s	O
gradient	O
,	O
no	O
matter	O
how	O
frequently	O
the	O
loss	O
function	O
was	O
updated	O
,	O
gradually	O
increased	O
until	O
it	O
stopped	O
at	O
the	O
same	O
level	O
.	O
	
This	O
implies	O
the	O
objective	O
function	O
to	O
update	O
the	O
generator	B-Method
tended	O
to	O
be	O
linear	O
rather	O
than	O
saturated	O
through	O
the	O
training	B-Method
process	I-Method
,	O
which	O
was	O
consistent	O
with	O
our	O
non	B-Method
-	I-Method
parametric	I-Method
analysis	I-Method
of	O
the	O
optimal	B-Method
loss	I-Method
function	I-Method
.	O
	
Thus	O
,	O
it	O
provided	O
sufficient	O
gradient	O
to	O
continuously	O
update	O
the	O
generator	B-Method
.	O
	
Furthermore	O
,	O
we	O
compared	O
the	O
images	O
generated	O
with	O
different	O
frequencies	O
of	O
updating	O
the	O
loss	O
function	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
where	O
there	O
was	O
no	O
noticeable	O
difference	O
in	O
the	O
visual	B-Metric
quality	I-Metric
.	O
	
This	O
shows	O
the	O
LS	B-Method
-	I-Method
GAN	I-Method
was	O
not	O
affected	O
by	O
over	O
-	O
trained	O
loss	O
function	O
in	O
experiments	O
.	O
	
subsection	O
:	O
Image	B-Task
Classification	I-Task
	
We	O
conducted	O
experiments	O
on	O
CIFAR	B-Material
-	I-Material
10	I-Material
and	O
SVHN	B-Material
to	O
compare	O
the	O
classification	B-Metric
accuracy	I-Metric
of	O
LS	B-Method
-	I-Method
GAN	I-Method
with	O
the	O
other	O
approaches	O
.	O
	
subsubsection	O
:	O
CIFAR	B-Material
-	I-Material
10	I-Material
	
The	O
CIFAR	B-Material
dataset	I-Material
consists	O
of	O
50	O
,	O
000	O
training	O
images	O
and	O
test	O
images	O
on	O
ten	O
image	O
categories	O
.	O
	
We	O
tested	O
the	O
proposed	O
CLS	O
-	O
GAN	B-Method
model	O
with	O
class	O
labels	O
as	O
conditions	O
.	O
	
In	O
the	O
supervised	B-Task
training	I-Task
,	O
all	O
labeled	O
examples	O
were	O
used	O
to	O
train	O
the	O
CLS	B-Method
-	I-Method
GAN	I-Method
.	O
	
We	O
also	O
conducted	O
experiments	O
with	O
labeled	O
examples	O
per	O
class	O
,	O
which	O
was	O
a	O
more	O
challenging	O
task	O
as	O
much	O
fewer	O
labeled	O
examples	O
were	O
used	O
for	O
training	O
.	O
	
In	O
this	O
case	O
,	O
the	O
remaining	O
unlabeled	O
examples	O
were	O
used	O
to	O
train	O
the	O
model	O
in	O
a	O
semi	B-Task
-	I-Task
supervised	I-Task
fashion	I-Task
as	O
discussed	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
In	O
each	O
mini	O
-	O
batch	O
,	O
the	O
same	O
number	O
of	O
labeled	O
and	O
unlabeled	O
examples	O
were	O
used	O
to	O
update	O
the	O
model	O
by	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
.	O
	
The	O
experiment	O
results	O
on	O
this	O
task	O
were	O
reported	O
by	O
averaging	O
over	O
ten	O
subsets	O
of	O
labeled	O
examples	O
.	O
	
Both	O
hyperparameters	O
and	O
were	O
chosen	O
via	O
a	O
five	O
-	O
fold	B-Method
cross	I-Method
-	I-Method
validation	I-Method
on	O
the	O
labeled	O
examples	O
from	O
and	O
respectively	O
.	O
	
Once	O
they	O
were	O
chosen	O
,	O
the	O
model	O
was	O
trained	O
with	O
the	O
chosen	O
hyperparameters	O
on	O
the	O
whole	O
training	O
set	O
,	O
and	O
the	O
performance	O
was	O
reported	O
based	O
on	O
the	O
results	O
on	O
the	O
test	O
set	O
.	O
	
As	O
in	O
the	O
improved	O
GAN	B-Method
,	O
we	O
also	O
adopted	O
the	O
weight	B-Method
normalization	I-Method
and	O
feature	B-Method
matching	I-Method
mechanisms	I-Method
for	O
the	O
sake	O
of	O
the	O
fair	O
comparison	O
.	O
	
We	O
compared	O
the	O
proposed	O
model	O
with	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
in	O
literature	O
.	O
	
In	O
particular	O
,	O
we	O
compared	O
with	O
the	O
conditional	O
GAN	B-Method
as	O
well	O
as	O
the	O
DCGAN	B-Method
.	O
	
For	O
the	O
sake	O
of	O
fair	O
comparison	O
,	O
the	O
conditional	O
GAN	B-Method
shared	O
the	O
same	O
architecture	O
as	O
the	O
CLS	B-Method
-	I-Method
GAN	I-Method
.	O
	
On	O
the	O
other	O
hand	O
,	O
the	O
DCGAN	B-Method
algorithm	I-Method
max	O
-	O
pooled	O
the	O
discriminator	O
’s	O
convolution	O
features	O
from	O
all	O
layers	O
to	O
grids	O
as	O
the	O
image	O
features	O
,	O
and	O
a	O
L2	B-Method
-	I-Method
SVM	I-Method
was	O
then	O
trained	O
to	O
classify	O
images	O
.	O
	
The	O
DCGAN	B-Method
was	O
an	O
unsupervised	B-Method
model	I-Method
which	O
had	O
shown	O
competitive	O
performance	O
on	O
generating	O
photo	O
-	O
realistic	O
images	O
.	O
	
Its	O
feature	B-Method
representations	I-Method
were	O
believed	O
to	O
reach	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
in	O
modeling	B-Task
images	I-Task
with	O
no	O
supervision	O
.	O
	
We	O
also	O
compared	O
with	O
the	O
other	O
recently	O
developed	O
supervised	B-Method
and	I-Method
semi	I-Method
-	I-Method
supervised	I-Method
models	I-Method
in	O
literature	O
,	O
including	O
the	O
baseline	B-Method
1	I-Method
Layer	I-Method
K	I-Method
-	I-Method
means	I-Method
feature	I-Method
extraction	I-Method
pipeline	I-Method
,	O
a	O
multi	B-Method
-	I-Method
layer	I-Method
extension	I-Method
of	O
the	O
baseline	B-Method
model	I-Method
(	O
3	O
Layer	B-Method
K	I-Method
-	I-Method
means	I-Method
Learned	I-Method
RF	I-Method
)	O
,	O
View	B-Method
Invariant	I-Method
K	I-Method
-	I-Method
means	I-Method
,	O
Examplar	B-Method
CNN	I-Method
,	O
Ladder	B-Method
Network	I-Method
,	O
as	O
well	O
as	O
CatGAN	B-Method
.	O
	
In	O
particular	O
,	O
among	O
the	O
compared	O
semi	B-Method
-	I-Method
supervised	I-Method
algorithms	I-Method
,	O
the	O
improved	O
GAN	B-Method
had	O
recorded	O
the	O
best	O
performance	O
in	O
literature	O
.	O
	
Furthermore	O
,	O
we	O
also	O
compared	O
with	O
the	O
ALI	B-Method
that	O
extended	O
the	O
classic	O
GAN	B-Method
by	O
jointly	O
generating	O
data	O
and	O
inferring	O
their	O
representations	O
,	O
which	O
achieved	O
comparable	O
performance	O
to	O
the	O
Improved	O
GAN	B-Method
.	O
	
This	O
pointed	O
out	O
an	O
interesting	O
direction	O
to	O
extend	O
the	O
CLS	B-Method
-	I-Method
GAN	I-Method
by	O
directly	O
inferring	O
the	O
data	B-Method
representation	I-Method
,	O
and	O
we	O
will	O
leave	O
it	O
in	O
the	O
future	O
work	O
.	O
	
Table	O
[	O
reference	O
]	O
compares	O
the	O
experiment	O
results	O
,	O
showing	O
the	O
CSL	O
-	O
GAN	B-Method
successfully	O
outperformed	O
the	O
compared	O
algorithms	O
in	O
both	O
fully	B-Task
-	I-Task
supervised	I-Task
and	I-Task
semi	I-Task
-	I-Task
supervised	I-Task
settings	I-Task
.	O
	
subsubsection	O
:	O
SVHN	B-Material
	
The	O
SVHN	B-Material
(	O
i.e.	O
,	O
Street	B-Material
View	I-Material
House	I-Material
Number	I-Material
)	O
dataset	O
contains	O
color	O
images	O
of	O
house	O
numbers	O
collected	O
by	O
Google	O
Street	O
View	O
.	O
	
They	O
were	O
roughly	O
centered	O
on	O
a	O
digit	O
in	O
a	O
house	O
number	O
,	O
and	O
the	O
objective	O
is	O
to	O
recognize	O
the	O
digit	O
.	O
	
The	O
training	O
set	O
has	O
digits	O
while	O
the	O
test	O
set	O
consists	O
of	O
.	O
	
To	O
test	O
the	O
model	O
,	O
labeled	O
digits	O
were	O
used	O
to	O
train	O
the	O
model	O
,	O
which	O
are	O
uniformly	O
selected	O
from	O
ten	O
digit	O
classes	O
,	O
that	O
is	O
labeled	O
examples	O
per	O
digit	O
class	O
.	O
	
The	O
remaining	O
unlabeled	O
examples	O
were	O
used	O
as	O
additional	O
data	O
to	O
enhance	O
the	O
generative	B-Method
ability	I-Method
of	O
CLS	B-Method
-	I-Method
GAN	I-Method
in	O
semi	B-Task
-	I-Task
supervised	I-Task
fashion	I-Task
.	O
	
We	O
expect	O
a	O
good	O
generative	B-Method
model	I-Method
could	O
produce	O
additional	O
examples	O
to	O
augment	O
the	O
training	O
set	O
.	O
	
We	O
used	O
the	O
same	O
experiment	O
setup	O
and	O
network	B-Method
architecture	I-Method
for	O
CIFAR	B-Material
-	I-Material
10	I-Material
to	O
train	O
the	O
LS	B-Method
-	I-Method
GAN	I-Method
on	O
this	O
dataset	O
.	O
	
Table	O
[	O
reference	O
]	O
reports	O
the	O
result	O
on	O
the	O
SVHN	B-Material
,	O
and	O
it	O
shows	O
that	O
the	O
LS	B-Method
-	I-Method
GAN	I-Method
performed	O
the	O
best	O
among	O
the	O
compared	O
algorithms	O
.	O
	
subsubsection	O
:	O
Analysis	B-Task
of	I-Task
Generated	I-Task
Images	I-Task
by	O
CLS	B-Method
-	I-Method
GAN	I-Method
	
Figure	O
[	O
reference	O
]	O
illustrates	O
the	O
generated	O
images	O
by	O
CLS	B-Method
-	I-Method
GAN	I-Method
for	O
MNIST	O
,	O
CIFAR	B-Material
-	I-Material
10	I-Material
and	O
SVHN	B-Material
datasets	O
.	O
	
On	O
each	O
dataset	O
,	O
images	O
in	O
a	O
column	O
were	O
generated	O
for	O
the	O
same	O
class	O
.	O
	
On	O
the	O
MNIST	O
and	O
the	O
SVHN	B-Material
,	O
both	O
handwritten	O
and	O
street	O
-	O
view	O
digits	O
are	O
quite	O
legible	O
.	O
	
Both	O
also	O
cover	O
many	O
variants	O
for	O
each	O
digit	O
class	O
.	O
	
For	O
example	O
,	O
the	O
synthesized	O
MNIST	O
digits	O
have	O
various	O
writing	O
styles	O
,	O
rotations	O
and	O
sizes	O
,	O
and	O
the	O
generated	O
SVHN	B-Material
digits	O
have	O
various	O
lighting	O
conditions	O
,	O
sizes	O
and	O
even	O
different	O
co	O
-	O
occurring	O
digits	O
in	O
the	O
cropped	O
bounding	O
boxes	O
.	O
	
On	O
the	O
CIFAR	B-Material
-	I-Material
10	I-Material
dataset	O
,	O
image	O
classes	O
can	O
be	O
recognized	O
from	O
the	O
generated	O
images	O
although	O
some	O
visual	O
details	O
are	O
missing	O
.	O
	
This	O
is	O
because	O
the	O
images	O
in	O
the	O
CIFAR	B-Material
-	I-Material
10	I-Material
dataset	O
have	O
very	O
low	O
resolution	O
(	O
pixels	O
)	O
,	O
and	O
most	O
details	O
are	O
even	O
missing	O
from	O
input	O
examples	O
.	O
	
We	O
also	O
observe	O
that	O
if	O
we	O
set	O
a	O
small	O
value	O
to	O
the	O
hyperparameter	O
,	O
the	O
generated	O
images	O
would	O
become	O
very	O
similar	O
to	O
each	O
other	O
within	O
each	O
class	O
.	O
	
As	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
the	O
images	O
were	O
generated	O
by	O
halving	O
used	O
for	O
generating	O
images	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
A	O
smaller	O
means	O
a	O
relatively	O
large	O
weight	O
was	O
placed	O
on	O
the	O
first	O
loss	B-Method
minimization	I-Method
term	I-Method
of	O
(	O
[	O
reference	O
]	O
)	O
,	O
which	O
tends	O
to	O
collapse	O
generated	O
images	O
to	O
a	O
single	O
mode	O
as	O
it	O
aggressively	O
minimizes	O
their	O
losses	O
to	O
train	O
the	O
generator	B-Method
.	O
	
This	O
is	O
also	O
consistent	O
with	O
Theorem	O
[	O
reference	O
]	O
where	O
the	O
density	O
of	O
generated	O
samples	O
with	O
a	O
smaller	O
could	O
have	O
a	O
larger	O
deviation	O
from	O
the	O
underlying	O
density	O
.	O
	
One	O
should	O
avoid	O
the	O
collapse	O
of	O
trained	O
generator	B-Method
since	O
diversifying	O
generated	O
images	O
can	O
improve	O
the	O
classification	B-Metric
performance	I-Metric
of	O
the	O
CLS	B-Method
-	I-Method
GAN	I-Method
by	O
revealing	O
more	O
intra	O
-	O
class	O
variations	O
.	O
	
This	O
will	O
help	O
improve	O
the	O
model	O
’s	O
generalization	B-Metric
ability	I-Metric
as	O
these	O
variations	O
could	O
appear	O
in	O
future	O
images	O
.	O
	
However	O
,	O
one	O
should	O
also	O
avoid	O
setting	O
too	O
large	O
value	O
to	O
.	O
	
Otherwise	O
,	O
the	O
role	O
of	O
the	O
first	B-Method
loss	I-Method
minimization	I-Method
term	I-Method
could	O
be	O
underestimated	O
,	O
which	O
can	O
also	O
adversely	O
affect	O
the	O
classification	B-Task
results	O
without	O
reducing	O
the	O
training	B-Metric
loss	I-Metric
to	O
a	O
satisfactory	O
level	O
.	O
	
Therefore	O
,	O
we	O
choose	O
a	O
proper	O
value	O
for	O
by	O
cross	B-Method
-	I-Method
validation	I-Method
on	O
the	O
training	O
set	O
in	O
the	O
experiments	O
.	O
	
In	O
brief	O
,	O
the	O
comparison	O
between	O
Figure	O
[	O
reference	O
]	O
and	O
Figure	O
[	O
reference	O
]	O
reveals	O
a	O
trade	O
-	O
off	O
between	O
image	B-Task
generation	I-Task
quality	O
and	O
classification	B-Metric
accuracy	I-Metric
through	O
the	O
hyperparameter	B-Method
.	O
	
Such	O
a	O
trade	O
-	O
off	O
is	O
intuitive	O
:	O
while	O
a	O
classification	B-Task
task	I-Task
usually	O
focuses	O
on	O
learning	O
class	B-Task
-	I-Task
invariant	I-Task
representations	I-Task
that	O
do	O
not	O
change	O
within	O
a	O
class	O
,	O
image	B-Task
generation	I-Task
should	O
be	O
able	O
to	O
capture	O
many	O
variant	O
factors	O
(	O
e.g.	O
,	O
lighting	O
conditions	O
,	O
viewing	O
angles	O
,	O
and	O
object	O
poses	O
)	O
so	O
that	O
it	O
could	O
diversify	O
generated	O
samples	O
for	O
each	O
class	O
.	O
	
Although	O
diversified	O
examples	O
can	O
augment	O
training	O
dataset	O
,	O
it	O
comes	O
at	O
a	O
cost	O
of	O
trading	O
class	O
-	O
invariance	O
for	O
modeling	O
variant	O
generation	O
factors	O
.	O
	
Perhaps	O
,	O
this	O
is	O
an	O
intrinsic	O
dilemma	O
between	O
supervised	B-Method
learning	I-Method
and	O
data	B-Task
generation	I-Task
that	O
is	O
worth	O
more	O
theoretical	O
and	O
empirical	O
studies	O
in	O
future	O
.	O
	
subsection	O
:	O
Evaluation	O
of	O
Generalization	B-Metric
Performances	I-Metric
	
Most	O
of	O
existing	O
metrics	O
like	O
Inception	B-Metric
Score	I-Metric
for	O
evaluating	O
GAN	B-Method
models	O
focus	O
on	O
comparing	O
the	O
qualities	O
and	O
diversities	O
of	O
their	O
generated	O
images	O
.	O
	
However	O
,	O
even	O
though	O
a	O
GAN	B-Method
model	O
can	O
produce	O
diverse	O
and	O
high	O
quality	O
images	O
with	O
no	O
collapsed	B-Method
generators	I-Method
,	O
it	O
is	O
still	O
unknown	O
if	O
the	O
model	O
can	O
generate	O
unseen	O
images	O
out	O
of	O
given	O
examples	O
,	O
or	O
simply	O
memorizing	O
existing	O
ones	O
.	O
	
While	O
one	O
of	O
our	O
main	O
pursuits	O
in	O
this	O
paper	O
is	O
a	O
generalizable	O
LS	B-Method
-	I-Method
GAN	I-Method
,	O
we	O
were	O
motivated	O
to	O
propose	O
the	O
following	O
Minimum	B-Metric
Reconstruction	I-Metric
Error	I-Metric
(	O
MRE	B-Metric
)	O
to	O
compare	O
its	O
generalizability	O
with	O
various	O
GANs	B-Method
.	O
	
Specifically	O
,	O
for	O
an	O
unseen	O
test	O
image	O
,	O
we	O
aim	O
to	O
find	O
an	O
input	O
noise	O
that	O
can	O
best	O
reconstruct	O
with	O
the	O
smallest	O
error	O
,	O
i.e.	O
,	O
where	O
is	O
the	O
GAN	B-Method
generator	O
under	O
evaluation	O
.	O
	
Obviously	O
,	O
if	O
is	O
adequate	O
to	O
produce	O
new	O
images	O
,	O
it	O
should	O
have	O
a	O
small	O
reconstruction	B-Metric
error	I-Metric
on	O
a	O
separate	O
test	O
set	O
that	O
has	O
not	O
been	O
used	O
in	O
training	O
the	O
model	O
.	O
	
We	O
assessed	O
the	O
GAN	B-Method
’s	O
generalizability	O
on	O
CIFAR	B-Material
-	I-Material
10	I-Material
and	O
tiny	O
ImageNet	O
datasets	O
.	O
	
On	O
CIFAR	B-Material
-	I-Material
10	I-Material
,	O
we	O
split	O
the	O
dataset	O
into	O
50	O
%	O
training	O
examples	O
,	O
25	O
%	O
validation	O
examples	O
and	O
25	O
%	O
test	O
examples	O
;	O
the	O
tiny	O
ImageNet	O
was	O
split	O
into	O
training	O
,	O
validation	O
and	O
test	O
sets	O
in	O
a	O
ratio	O
of	O
10:1:1	O
.	O
	
For	O
a	O
fair	O
comparison	O
,	O
all	O
the	O
hyperparameters	O
,	O
including	O
the	O
number	O
of	O
epochs	O
,	O
were	O
chosen	O
based	O
on	O
the	O
average	B-Metric
MREs	I-Metric
on	O
the	O
validation	O
set	O
,	O
and	O
the	O
test	O
MREs	B-Metric
were	O
reported	O
for	O
comparison	O
.	O
	
The	O
optimal	O
’s	O
were	O
iteratively	O
updated	O
on	O
the	O
validation	O
and	O
test	O
sets	O
by	O
descending	O
the	O
gradient	O
of	O
the	O
reconstruction	O
errors	O
.	O
	
In	O
Figure	O
[	O
reference	O
]	O
,	O
we	O
compare	O
the	O
test	O
MREs	B-Metric
over	O
epochs	O
by	O
LS	B-Method
-	I-Method
GAN	I-Method
,	O
GLS	B-Method
-	I-Method
GAN	I-Method
,	O
WGAN	B-Method
,	O
WGAN	B-Method
-	O
GP	O
and	O
DCGAN	B-Method
on	O
CIFAR	B-Material
-	I-Material
10	I-Material
respectively	O
.	O
	
For	O
the	O
sake	O
of	O
a	O
fair	O
comparison	O
,	O
all	O
models	O
were	O
trained	O
with	O
the	O
network	B-Method
architecture	I-Method
used	O
in	O
.	O
	
The	O
result	O
clearly	O
shows	O
the	O
regularized	B-Method
models	I-Method
,	O
including	O
GLS	B-Method
-	I-Method
GAN	I-Method
,	O
LS	B-Method
-	I-Method
GAN	I-Method
,	O
WGAN	B-Method
-	O
GP	O
and	O
WGAN	B-Method
,	O
have	O
apparently	O
better	O
generalization	B-Metric
performances	I-Metric
than	O
the	O
unregularized	B-Method
DCGAN	I-Method
based	O
on	O
the	O
classic	O
GAN	B-Method
model	O
.	O
	
On	O
CIFAR	B-Material
-	I-Material
10	I-Material
,	O
the	O
test	O
MRE	B-Metric
was	O
reduced	O
from	O
by	O
DCGAN	B-Method
to	O
as	O
small	O
as	O
and	O
by	O
WGAN	B-Method
and	O
GLS	O
-	O
GAN	B-Method
respectively	O
;	O
on	O
tiny	O
ImageNet	O
,	O
the	O
GLS	B-Method
-	I-Method
GAN	I-Method
reaches	O
the	O
smallest	O
test	O
MRE	B-Metric
of	O
among	O
all	O
compared	O
regularized	O
and	O
unregularized	O
GANs	B-Method
.	O
	
In	O
addition	O
,	O
the	O
DCGAN	B-Method
exhibited	O
fluctuating	O
MREs	B-Metric
on	O
the	O
CIFAR	B-Material
-	I-Material
10	I-Material
,	O
while	O
the	O
regularized	B-Method
models	I-Method
steadily	O
decreased	O
the	O
MREs	B-Metric
over	O
epochs	O
.	O
	
This	O
implies	O
regularized	O
GANs	B-Method
have	O
more	O
stable	O
training	O
than	O
the	O
classic	O
GAN	B-Method
.	O
	
We	O
illustrate	O
some	O
examples	O
of	O
reconstructed	O
images	O
by	O
different	O
GANs	B-Method
on	O
the	O
test	O
set	O
along	O
with	O
their	O
test	O
MREs	B-Metric
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
The	O
results	O
show	O
the	O
GLS	B-Method
-	I-Method
GAN	I-Method
achieved	O
the	O
smallest	O
test	B-Metric
MRE	I-Metric
of	O
0.1089	O
and	O
0.2085	O
with	O
a	O
LeakyReLU	O
cost	O
function	O
of	O
slope	O
and	O
on	O
CIFAR	B-Material
-	I-Material
10	I-Material
and	O
tiny	O
ImageNet	O
,	O
followed	O
by	O
the	O
other	O
regularized	O
GAN	B-Method
models	O
.	O
	
This	O
is	O
not	O
a	O
surprising	O
result	O
since	O
it	O
has	O
been	O
shown	O
in	O
Section	O
[	O
reference	O
]	O
that	O
the	O
other	O
regularized	O
GANs	B-Method
such	O
as	O
LS	B-Method
-	I-Method
GAN	I-Method
and	O
WGAN	B-Method
are	O
only	O
special	O
cases	O
of	O
the	O
GLS	O
-	O
GAN	B-Method
model	O
that	O
covers	O
larger	O
family	O
of	O
models	O
.	O
	
Here	O
we	O
only	O
considered	O
LeakyReLU	O
as	O
the	O
cost	B-Method
function	I-Method
for	O
GLS	B-Method
-	I-Method
GAN	I-Method
.	O
	
Of	O
course	O
,	O
there	O
exist	O
many	O
more	O
cost	O
functions	O
satisfying	O
the	O
two	O
conditions	O
in	O
Section	O
[	O
reference	O
]	O
to	O
expand	O
the	O
family	O
of	O
regularized	O
GANs	B-Method
,	O
which	O
should	O
have	O
potentials	O
of	O
yielding	O
even	O
better	O
generalization	B-Metric
performances	I-Metric
.	O
	
section	O
:	O
Conclusions	O
	
In	O
this	O
paper	O
,	O
we	O
present	O
a	O
novel	O
Loss	O
-	O
Sensitive	O
GAN	B-Method
(	O
LS	B-Method
-	I-Method
GAN	I-Method
)	O
approach	O
to	O
generate	O
samples	O
from	O
a	O
data	O
distribution	O
.	O
	
The	O
LS	B-Method
-	I-Method
GAN	I-Method
learns	O
a	O
loss	B-Method
function	I-Method
to	O
distinguish	O
between	O
generated	O
and	O
real	O
samples	O
,	O
where	O
the	O
loss	O
of	O
a	O
real	O
sample	O
should	O
be	O
smaller	O
by	O
a	O
margin	O
than	O
that	O
of	O
a	O
generated	O
sample	O
.	O
	
Our	O
theoretical	O
analysis	O
shows	O
the	O
distributional	O
consistency	O
between	O
the	O
real	O
and	O
generated	O
samples	O
based	O
on	O
the	O
Lipschitz	O
regularity	O
.	O
	
This	O
no	O
longer	O
needs	O
a	O
non	B-Method
-	I-Method
parametric	I-Method
discriminator	I-Method
with	O
infinite	O
modeling	O
ability	O
in	O
the	O
classic	O
GAN	B-Method
,	O
allowing	O
us	O
to	O
search	O
for	O
the	O
optimal	O
loss	O
function	O
in	O
a	O
smaller	O
functional	O
space	O
with	O
a	O
bounded	O
Lipschitz	O
constant	O
.	O
	
Moreover	O
,	O
we	O
prove	O
the	O
generalizability	O
of	O
LS	B-Method
-	I-Method
GAN	I-Method
by	O
showing	O
its	O
required	O
number	O
of	O
training	O
examples	O
is	O
polynomial	O
in	O
its	O
complexity	B-Metric
.	O
	
This	O
suggests	O
the	O
generalization	B-Metric
performance	I-Metric
can	O
be	O
improved	O
by	O
penalizing	O
the	O
Lipschitz	O
constants	O
(	O
via	O
their	O
gradient	O
surrogates	O
)	O
of	O
the	O
loss	O
function	O
to	O
reduce	O
the	O
sample	B-Metric
complexity	I-Metric
.	O
	
Furthermore	O
,	O
our	O
non	B-Method
-	I-Method
parametric	I-Method
analysis	I-Method
of	O
the	O
optimal	B-Method
loss	I-Method
function	I-Method
shows	O
its	O
lower	O
and	O
upper	O
bounds	O
are	O
cone	O
-	O
shaped	O
with	O
non	O
-	O
vanishing	B-Task
gradient	I-Task
almost	O
everywhere	O
,	O
implying	O
the	O
generator	B-Method
can	O
be	O
continuously	O
updated	O
even	O
if	O
the	O
loss	O
function	O
is	O
over	O
-	O
trained	O
.	O
	
Finally	O
,	O
we	O
extend	O
the	O
LS	B-Method
-	I-Method
GAN	I-Method
to	O
a	O
Conditional	B-Method
LS	I-Method
-	I-Method
GAN	I-Method
(	O
CLS	B-Method
-	I-Method
GAN	I-Method
)	O
for	O
semi	B-Task
-	I-Task
supervised	I-Task
tasks	I-Task
,	O
and	O
demonstrate	O
it	O
reaches	O
competitive	O
performances	O
on	O
both	O
image	B-Task
generation	I-Task
and	O
classification	B-Task
tasks	I-Task
.	O
	
bibliography	O
:	O
References	O
	
appendix	O
:	O
Proof	O
of	O
Lemma	O
[	O
reference	O
]	O
	
To	O
prove	O
Lemma	O
[	O
reference	O
]	O
,	O
we	O
need	O
the	O
following	O
lemma	O
.	O
	
theorem	O
:	O
.	O
	
For	O
two	O
probability	O
densities	O
⁢p	O
(	O
x	O
)	O
and	O
⁢q	O
(	O
x	O
)	O
,	O
if	O
≥⁢p	O
(	O
x	O
)	O
⁢ηq	O
(	O
x	O
)	O
almost	O
everywhere	O
,	O
we	O
have	O
for	O
∈η	O
(	O
0	O
,	O
1	O
]	O
.	O
	
proof	O
:	O
Proof	O
.	O
	
We	O
have	O
the	O
following	O
equalities	O
and	O
inequalities	O
:	O
This	O
completes	O
the	O
proof	O
.	O
	
∎	O
	
Now	O
we	O
can	O
prove	O
Lemma	O
[	O
reference	O
]	O
.	O
	
proof	O
:	O
Proof	O
.	O
	
Suppose	O
is	O
a	O
Nash	O
equilibrium	O
for	O
the	O
problem	O
(	O
[	O
reference	O
]	O
)	O
and	O
(	O
[	O
reference	O
]	O
)	O
.	O
	
Then	O
,	O
on	O
one	O
hand	O
,	O
we	O
have	O
where	O
the	O
first	O
inequality	O
follows	O
from	O
.	O
	
We	O
also	O
have	O
for	O
any	O
as	O
minimizes	O
.	O
	
In	O
particular	O
,	O
we	O
can	O
replace	O
in	O
with	O
,	O
which	O
yields	O
Applying	O
this	O
inequality	O
into	O
(	O
[	O
reference	O
]	O
)	O
leads	O
to	O
where	O
the	O
last	O
inequality	O
follows	O
as	O
is	O
nonnegative	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
consider	O
a	O
particular	O
loss	B-Method
function	I-Method
	
When	O
is	O
a	O
sufficiently	O
small	O
positive	O
coefficient	O
,	O
is	O
a	O
nonexpansive	O
function	O
(	O
i.e.	O
,	O
a	O
function	O
with	O
Lipschitz	O
constant	O
no	O
larger	O
than	O
.	O
)	O
.	O
	
This	O
follows	O
from	O
the	O
assumption	O
that	O
and	O
are	O
Lipschitz	O
.	O
	
In	O
this	O
case	O
,	O
we	O
have	O
	
By	O
placing	O
this	O
into	O
,	O
one	O
can	O
show	O
that	O
where	O
the	O
first	O
equality	O
uses	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
,	O
and	O
the	O
second	O
equality	O
is	O
obtained	O
by	O
substituting	O
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
into	O
the	O
equation	O
.	O
	
Assuming	O
that	O
on	O
a	O
set	O
of	O
nonzero	O
measure	O
,	O
the	O
above	O
equation	O
would	O
be	O
strictly	O
upper	O
bounded	O
by	O
and	O
we	O
have	O
This	O
results	O
in	O
a	O
contradiction	O
with	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
	
Therefore	O
,	O
we	O
must	O
have	O
for	O
almost	O
everywhere	O
.	O
	
By	O
Lemma	O
[	O
reference	O
]	O
,	O
we	O
have	O
Let	O
,	O
this	O
leads	O
to	O
This	O
proves	O
that	O
converges	O
to	O
as	O
.	O
	
∎	O
	
appendix	O
:	O
Proof	O
of	O
Lemma	O
[	O
reference	O
]	O
	
proof	O
:	O
Proof	O
.	O
	
Suppose	O
a	O
pair	O
of	O
jointly	O
solve	O
the	O
WGAN	B-Method
problem	O
.	O
	
Then	O
,	O
on	O
one	O
hand	O
,	O
we	O
have	O
where	O
the	O
inequality	O
follows	O
from	O
by	O
replacing	O
with	O
.	O
	
Consider	O
a	O
particular	O
.	O
	
Since	O
and	O
are	O
Lipschitz	O
by	O
assumption	O
,	O
when	O
is	O
sufficiently	O
small	O
,	O
it	O
can	O
be	O
shown	O
that	O
.	O
	
Substituting	O
this	O
into	O
,	O
we	O
get	O
Let	O
us	O
assume	O
on	O
a	O
set	O
of	O
nonzero	O
measure	O
	
,	O
we	O
would	O
have	O
This	O
leads	O
to	O
a	O
contradiction	O
with	O
(	O
[	O
reference	O
]	O
)	O
,	O
so	O
we	O
must	O
have	O
almost	O
everywhere	O
.	O
	
Hence	O
,	O
by	O
Lemma	O
[	O
reference	O
]	O
,	O
we	O
prove	O
the	O
conclusion	O
that	O
∎	O
	
appendix	O
:	O
Proof	O
of	O
Theorem	O
[	O
reference	O
]	O
	
For	O
simplicity	O
,	O
throughout	O
this	O
section	O
,	O
we	O
disregard	O
the	O
first	O
loss	O
minimization	O
term	O
in	O
and	O
,	O
since	O
the	O
role	O
of	O
the	O
first	O
term	O
would	O
vanish	O
as	O
goes	O
to	O
.	O
	
However	O
,	O
even	O
if	O
it	O
is	O
involved	O
,	O
the	O
following	O
proof	O
still	O
holds	O
with	O
only	O
some	O
minor	O
changes	O
.	O
	
To	O
prove	O
Theorem	O
[	O
reference	O
]	O
,	O
we	O
need	O
the	O
following	O
lemma	O
.	O
	
theorem	O
:	O
.	O
	
For	O
all	O
loss	O
functions	O
Lθ	O
,	O
with	O
at	O
least	O
the	O
probability	O
of	O
-	O
1η	O
,	O
we	O
have	O
when	O
the	O
number	O
of	O
samples	O
with	O
a	O
sufficiently	O
large	O
constant	O
C.	O
	
The	O
proof	O
of	O
this	O
lemma	O
needs	O
to	O
apply	O
the	O
McDiarmid	O
’s	O
inequality	O
and	O
the	O
fact	O
that	O
is	O
an	O
1	O
-	O
Lipschitz	O
to	O
bound	O
the	O
difference	O
for	O
a	O
loss	O
function	O
.	O
	
Then	O
,	O
to	O
get	O
the	O
union	O
bound	O
over	O
all	O
loss	O
functions	O
,	O
a	O
standard	O
-	O
net	O
will	O
be	O
constructed	O
to	O
yield	O
finite	O
points	O
that	O
are	O
dense	O
enough	O
to	O
cover	O
the	O
parameter	O
space	O
of	O
the	O
loss	O
functions	O
.	O
	
The	O
proof	O
details	O
are	O
given	O
below	O
.	O
	
proof	O
:	O
Proof	O
.	O
	
For	O
a	O
loss	O
function	O
,	O
we	O
compute	O
over	O
a	O
set	O
of	O
samples	O
drawn	O
from	O
and	O
respectively	O
.	O
	
To	O
apply	O
the	O
McDiarmid	O
’s	O
inequality	O
,	O
we	O
need	O
to	O
bound	O
the	O
change	O
of	O
this	O
function	O
when	O
a	O
sample	O
is	O
changed	O
.	O
	
Denote	O
by	O
when	O
the	O
th	O
sample	O
is	O
replaced	O
with	O
and	O
.	O
	
Then	O
we	O
have	O
where	O
the	O
first	O
inequality	O
uses	O
the	O
fact	O
that	O
is	O
-	O
Lipschitz	O
,	O
the	O
second	O
inequality	O
follows	O
from	O
that	O
is	O
bounded	O
by	O
and	O
is	O
-	O
Lipschitz	O
in	O
.	O
	
Now	O
we	O
can	O
apply	O
the	O
McDiarmid	O
’s	O
inequality	O
.	O
	
Noting	O
that	O
we	O
have	O
The	O
above	O
bound	O
applies	O
to	O
a	O
single	O
loss	O
function	O
.	O
	
To	O
get	O
the	O
union	O
bound	O
,	O
we	O
consider	O
a	O
-	O
net	O
,	O
i.e.	O
,	O
for	O
any	O
,	O
there	O
is	O
a	O
in	O
this	O
net	O
so	O
that	O
.	O
	
This	O
standard	O
net	O
can	O
be	O
constructed	O
to	O
contain	O
finite	O
loss	O
functions	O
such	O
that	O
,	O
where	O
is	O
the	O
number	O
of	O
parameters	O
in	O
a	O
loss	O
function	O
.	O
	
Note	O
that	O
we	O
implicitly	O
assume	O
the	O
parameter	O
space	O
of	O
the	O
loss	O
function	O
is	O
bounded	O
so	O
we	O
can	O
construct	O
such	O
a	O
net	O
containing	O
finite	O
points	O
here	O
.	O
	
Therefore	O
,	O
we	O
have	O
the	O
following	O
union	O
bound	O
for	O
all	O
that	O
,	O
with	O
probability	O
,	O
when	O
.	O
	
The	O
last	O
step	O
is	O
to	O
obtain	O
the	O
union	O
bound	O
for	O
all	O
loss	O
functions	O
beyond	O
.	O
	
To	O
show	O
that	O
,	O
we	O
consider	O
the	O
following	O
inequality	O
where	O
the	O
first	O
inequality	O
uses	O
that	O
fact	O
that	O
is	O
-	O
Lipschitz	O
again	O
,	O
and	O
the	O
second	O
inequality	O
follows	O
from	O
that	O
is	O
-	O
Lipschitz	O
in	O
.	O
	
Similarly	O
,	O
we	O
can	O
also	O
show	O
that	O
Now	O
we	O
can	O
derive	O
the	O
union	O
bound	O
over	O
all	O
loss	O
functions	O
.	O
	
For	O
any	O
,	O
by	O
construction	O
we	O
can	O
find	O
a	O
such	O
that	O
.	O
	
Then	O
,	O
with	O
probability	O
,	O
we	O
have	O
This	O
proves	O
the	O
lemma	O
.	O
	
∎	O
	
Now	O
we	O
can	O
prove	O
Theorem	O
[	O
reference	O
]	O
.	O
	
proof	O
:	O
Proof	O
.	O
	
First	O
let	O
us	O
bound	O
.	O
	
Consider	O
that	O
minimizes	O
.	O
	
Then	O
with	O
probability	O
,	O
when	O
,	O
we	O
have	O
where	O
the	O
first	O
inequality	O
follows	O
from	O
the	O
inequality	O
as	O
may	O
not	O
minimize	O
,	O
and	O
the	O
second	O
inequality	O
is	O
a	O
direct	O
application	O
of	O
the	O
above	O
lemma	O
.	O
	
Similarly	O
,	O
we	O
can	O
prove	O
the	O
other	O
direction	O
.	O
	
With	O
probability	O
,	O
we	O
have	O
Finally	O
,	O
	
a	O
more	O
rigourous	O
discussion	O
about	O
the	O
generalizability	O
should	O
consider	O
that	O
is	O
updated	O
iteratively	O
.	O
	
Therefore	O
we	O
have	O
a	O
sequence	O
of	O
generated	O
over	O
iterations	O
for	O
.	O
	
Thus	O
,	O
a	O
union	O
bound	O
over	O
all	O
generators	O
should	O
be	O
considered	O
in	O
(	O
[	O
reference	O
]	O
)	O
,	O
and	O
this	O
makes	O
the	O
required	O
number	O
of	O
training	O
examples	O
become	O
However	O
,	O
the	O
iteration	O
number	O
is	O
usually	O
much	O
smaller	O
than	O
the	O
model	O
size	O
(	O
which	O
is	O
often	O
hundreds	O
of	O
thousands	O
)	O
,	O
and	O
thus	O
this	O
factor	O
will	O
not	O
affect	O
the	O
above	O
lower	O
bound	O
of	O
.	O
	
∎	O
	
appendix	O
:	O
Proof	O
of	O
Theorem	O
[	O
reference	O
]	O
and	O
Corollary	O
[	O
reference	O
]	O
	
We	O
prove	O
Theorem	O
[	O
reference	O
]	O
as	O
follows	O
.	O
	
proof	O
:	O
Proof	O
.	O
	
First	O
,	O
the	O
existence	O
of	O
a	O
minimizer	O
follows	O
from	O
the	O
fact	O
that	O
the	O
functions	O
in	O
form	O
a	O
compact	O
set	O
,	O
and	O
the	O
objective	O
function	O
is	O
convex	O
.	O
	
To	O
prove	O
the	O
minimizer	O
has	O
the	O
two	O
forms	O
in	O
(	O
[	O
reference	O
]	O
)	O
,	O
for	O
each	O
,	O
let	O
us	O
consider	O
It	O
is	O
not	O
hard	O
to	O
verify	O
that	O
and	O
for	O
.	O
	
Indeed	O
,	O
by	O
noting	O
that	O
has	O
its	O
Lipschitz	O
constant	O
bounded	O
by	O
,	O
we	O
have	O
,	O
and	O
thus	O
Because	O
by	O
the	O
assumption	O
(	O
i.e.	O
,	O
it	O
is	O
lower	O
bounded	O
by	O
zero	O
)	O
	
,	O
it	O
can	O
be	O
shown	O
that	O
for	O
all	O
Hence	O
,	O
by	O
the	O
definition	O
of	O
and	O
taking	O
the	O
maximum	O
over	O
on	O
the	O
left	O
hand	O
side	O
,	O
we	O
have	O
	
On	O
the	O
other	O
hand	O
,	O
we	O
have	O
because	O
for	O
any	O
,	O
and	O
it	O
is	O
true	O
in	O
particular	O
for	O
.	O
	
This	O
shows	O
.	O
	
Similarly	O
,	O
one	O
can	O
prove	O
.	O
	
To	O
show	O
this	O
,	O
we	O
have	O
by	O
the	O
Lipschitz	O
continuity	O
of	O
.	O
	
By	O
taking	O
the	O
minimum	O
over	O
,	O
we	O
have	O
	
On	O
the	O
other	O
hand	O
,	O
we	O
have	O
by	O
the	O
definition	O
of	O
.	O
	
Combining	O
these	O
two	O
inequalities	O
shows	O
that	O
.	O
	
Now	O
we	O
can	O
prove	O
for	O
any	O
function	O
,	O
there	O
exist	O
and	O
both	O
of	O
which	O
attain	O
the	O
same	O
value	O
of	O
as	O
,	O
since	O
only	O
depends	O
on	O
the	O
values	O
of	O
on	O
the	O
data	O
points	O
.	O
	
In	O
particular	O
,	O
this	O
shows	O
that	O
any	O
global	O
minimum	O
in	O
of	O
can	O
also	O
be	O
attained	O
by	O
the	O
corresponding	O
functions	O
of	O
the	O
form	O
(	O
[	O
reference	O
]	O
)	O
.	O
	
By	O
setting	O
for	O
,	O
this	O
completes	O
the	O
proof	O
.	O
	
∎	O
	
Finally	O
,	O
we	O
prove	O
Corollary	O
[	O
reference	O
]	O
that	O
bounds	O
with	O
and	O
constructed	O
above	O
.	O
	
proof	O
:	O
Proof	O
.	O
	
By	O
the	O
Lipschitz	O
continuity	O
,	O
we	O
have	O
Since	O
	
,	O
it	O
follows	O
that	O
Taking	O
the	O
maximum	O
over	O
on	O
the	O
left	O
hand	O
side	O
,	O
we	O
obtain	O
	
This	O
proves	O
the	O
lower	O
bound	O
.	O
	
Similarly	O
,	O
we	O
have	O
by	O
Lipschitz	O
continuity	O
which	O
,	O
by	O
taking	O
the	O
minimum	O
over	O
on	O
the	O
left	O
hand	O
side	O
,	O
leads	O
to	O
This	O
	
shows	O
the	O
upper	O
bound	O
.	O
	
∎	O
	
document	O
:	O
SentiHood	B-Material
:	O
Targeted	B-Material
Aspect	I-Material
Based	I-Material
Sentiment	I-Material
Analysis	I-Material
Dataset	I-Material
for	O
Urban	B-Task
Neighbourhoods	I-Task
	
In	O
this	O
paper	O
,	O
we	O
introduce	O
the	O
task	O
of	O
targeted	O
aspect	B-Task
-	I-Task
based	I-Task
sentiment	I-Task
analysis	I-Task
.	O
	
The	O
goal	O
is	O
to	O
extract	O
fine	O
-	O
grained	O
information	O
with	O
respect	O
to	O
entities	O
mentioned	O
in	O
user	O
comments	O
.	O
	
This	O
work	O
extends	O
both	O
aspect	B-Task
-	I-Task
based	I-Task
sentiment	I-Task
analysis	I-Task
that	O
assumes	O
a	O
single	O
entity	O
per	O
document	O
and	O
targeted	O
sentiment	B-Task
analysis	I-Task
that	O
assumes	O
a	O
single	O
sentiment	O
towards	O
a	O
target	O
entity	O
.	O
	
In	O
particular	O
,	O
we	O
identify	O
the	O
sentiment	O
towards	O
each	O
aspect	O
of	O
one	O
or	O
more	O
entities	O
.	O
	
As	O
a	O
testbed	O
for	O
this	O
task	O
,	O
we	O
introduce	O
the	O
SentiHood	B-Material
dataset	I-Material
,	O
extracted	O
from	O
a	O
question	B-Task
answering	I-Task
(	I-Task
QA	I-Task
)	I-Task
platform	I-Task
where	O
urban	O
neighbourhoods	O
are	O
discussed	O
by	O
users	O
.	O
	
In	O
this	O
context	O
units	O
of	O
text	O
often	O
mention	O
several	O
aspects	O
of	O
one	O
or	O
more	O
neighbourhoods	O
.	O
	
This	O
is	O
the	O
first	O
time	O
that	O
a	O
generic	O
social	B-Method
media	I-Method
platform	I-Method
in	O
this	O
case	O
a	O
QA	B-Method
platform	I-Method
,	O
is	O
used	O
for	O
fine	B-Task
-	I-Task
grained	I-Task
opinion	I-Task
mining	I-Task
.	O
	
Text	O
coming	O
from	O
QA	B-Method
platforms	I-Method
is	O
far	O
less	O
constrained	O
compared	O
to	O
text	O
from	O
review	O
specific	O
platforms	O
which	O
current	O
datasets	O
are	O
based	O
on	O
.	O
	
We	O
develop	O
several	O
strong	O
baselines	O
,	O
relying	O
on	O
logistic	B-Method
regression	I-Method
and	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
recurrent	B-Method
neural	I-Method
networks	I-Method
.	O
	
section	O
:	O
Introduction	O
	
This	O
work	O
is	O
licensed	O
under	O
a	O
Creative	O
Commons	O
Attribution	O
4.0	O
International	O
Licence	O
.	O
	
Licence	O
details	O
	
:	O
http:	O
//	O
creativecommons.org	O
/	O
licenses	O
/	O
by	O
/	O
4.0	O
/	O
Sentiment	B-Task
analysis	I-Task
is	O
an	O
important	O
task	O
in	O
natural	B-Task
language	I-Task
processing	I-Task
.	O
	
It	O
has	O
received	O
not	O
only	O
a	O
lot	O
of	O
interest	O
in	O
academia	O
but	O
also	O
in	O
industry	O
,	O
in	O
particular	O
for	O
identifying	O
customer	B-Task
satisfaction	I-Task
on	O
products	O
and	O
services	O
.	O
	
Early	O
research	O
in	O
the	O
field	O
of	O
sentiment	B-Task
analysis	I-Task
only	O
focused	O
on	O
identifying	O
the	O
overall	O
sentiment	O
or	O
polarity	O
of	O
a	O
given	O
text	O
.	O
	
The	O
underlying	O
assumption	O
of	O
this	O
work	O
was	O
that	O
there	O
is	O
one	O
overall	O
polarity	O
in	O
the	O
whole	O
text	O
.	O
	
Aspect	O
-	O
based	O
sentiment	B-Task
analysis	I-Task
(	O
ABSA	B-Task
)	O
relates	O
to	O
the	O
task	O
of	O
extracting	B-Task
fine	I-Task
-	I-Task
grained	I-Task
information	I-Task
by	O
identifying	O
the	O
polarity	O
towards	O
different	O
aspects	O
of	O
an	O
entity	O
in	O
the	O
same	O
unit	O
of	O
text	O
,	O
and	O
recognizing	O
the	O
polarity	O
associated	O
with	O
each	O
aspect	O
separately	O
.	O
	
The	O
datasets	O
for	O
this	O
task	O
were	O
mostly	O
based	O
on	O
specialized	O
review	B-Method
platforms	I-Method
such	O
as	O
Yelp	O
where	O
it	O
is	O
assumed	O
that	O
only	O
one	O
entity	O
is	O
discussed	O
in	O
one	O
review	O
snippet	O
,	O
but	O
the	O
opinion	O
on	O
multiple	O
aspects	O
can	O
be	O
expressed	O
.	O
	
This	O
task	O
is	O
particularly	O
useful	O
because	O
a	O
user	O
can	O
assess	O
the	O
aggregated	O
sentiment	O
for	O
each	O
individual	O
aspect	O
of	O
a	O
given	O
product	O
or	O
service	O
and	O
get	O
a	O
more	O
fine	O
-	O
grained	O
understanding	O
of	O
its	O
quality	B-Metric
.	O
	
Another	O
line	O
of	O
research	O
in	O
this	O
field	O
is	O
targeted	O
(	O
a.k.a	O
.	O
target	O
-	O
dependent	O
)	O
sentiment	B-Task
analysis	I-Task
.	O
	
Targeted	O
sentiment	B-Task
analysis	I-Task
investigates	O
the	O
classification	B-Task
of	I-Task
opinion	I-Task
polarities	I-Task
towards	O
certain	O
target	O
entity	O
mentions	O
in	O
given	O
sentences	O
(	O
often	O
a	O
tweet	O
)	O
.	O
	
For	O
instance	O
in	O
the	O
sentence	O
People	O
everywhere	O
love	O
Windows	O
&	O
vista	O
.	O
	
Bill	O
Gates	O
,	O
polarity	O
towards	O
Bill	O
Gates	O
is	O
Neutral	O
but	O
the	O
positive	O
sentiment	O
towards	O
Windows	O
&	O
vista	O
will	O
interfere	O
with	O
identifying	O
it	O
if	O
the	O
usual	O
methods	O
for	O
sentiment	B-Task
analysis	I-Task
task	I-Task
are	O
employed	O
.	O
	
However	O
this	O
task	O
assumes	O
only	O
the	O
overall	O
sentiment	O
for	O
each	O
entity	O
.	O
	
Moreover	O
,	O
the	O
existing	O
corpora	O
for	O
this	O
task	O
so	O
far	O
has	O
contained	O
only	O
a	O
single	O
target	O
entity	O
per	O
unit	O
of	O
text	O
.	O
	
Both	O
settings	O
are	O
obviously	O
limited	O
,	O
and	O
there	O
exists	O
many	O
scenarios	O
in	O
which	O
sentiments	O
towards	O
different	O
aspects	O
of	O
several	O
entities	O
are	O
discussed	O
in	O
the	O
same	O
unit	O
of	O
text	O
.	O
	
As	O
a	O
running	O
example	O
,	O
we	O
use	O
urban	O
areas	O
:	O
choosing	O
which	O
area	O
to	O
live	O
or	O
to	O
visit	O
is	O
an	O
important	O
task	O
when	O
moving	O
or	O
visiting	O
a	O
new	O
city	O
.	O
	
Currently	O
there	O
are	O
no	O
dedicated	O
platforms	O
for	O
reviewing	B-Task
and	I-Task
rating	I-Task
aspects	I-Task
of	I-Task
neighbourhoods	I-Task
of	I-Task
a	I-Task
city	I-Task
.	O
	
However	O
we	O
can	O
find	O
many	O
discussions	O
and	O
threads	O
on	O
several	O
blogs	O
and	O
question	B-Task
answering	I-Task
platforms	I-Task
that	O
discuss	O
aspects	O
of	O
areas	O
in	O
many	O
cities	O
around	O
the	O
world	O
.	O
	
In	O
general	O
,	O
these	O
conversations	O
are	O
very	O
comprehensible	O
:	O
they	O
often	O
contain	O
specific	O
information	O
about	O
several	O
aspects	O
of	O
several	O
neighbourhoods	O
.	O
	
One	O
example	O
is	O
the	O
following	O
(	O
area	O
names	O
are	O
highlighted	O
in	O
bold	O
and	O
aspect	O
related	O
terms	O
are	O
underlined	O
)	O
:	O
Other	O
places	O
to	O
look	O
at	O
in	O
South	O
London	O
are	O
Streatham	O
(	O
good	O
range	O
of	O
shops	O
and	O
restaurants	O
,	O
maybe	O
a	O
bit	O
far	O
out	O
of	O
central	O
London	O
but	O
you	O
get	O
more	O
for	O
your	O
money	O
)	O
	
Brixton	O
(	O
good	O
transport	O
links	O
,	O
trendy	O
,	O
can	O
be	O
	
a	O
bit	O
edgy	O
)	O
Clapham	O
(	O
good	O
transport	O
,	O
good	O
restaurants	O
/	O
pubs	O
,	O
can	O
feel	O
a	O
bit	O
dull	O
,	O
expensive	O
)	O
	
…	O
	
The	O
example	O
above	O
does	O
not	O
perfectly	O
fit	O
into	O
the	O
existing	O
tasks	O
in	O
sentiment	B-Task
analysis	I-Task
mentioned	O
earlier	O
.	O
	
In	O
this	O
work	O
,	O
we	O
introduce	O
a	O
new	O
task	O
that	O
not	O
only	O
subsumes	O
the	O
existing	O
sub	O
-	O
fields	O
of	O
targeted	O
and	O
aspect	B-Task
-	I-Task
based	I-Task
sentiment	I-Task
analysis	I-Task
but	O
it	O
also	O
makes	O
less	O
assumptions	O
on	O
the	O
number	O
of	O
entities	O
that	O
can	O
be	O
discussed	O
in	O
the	O
unit	O
of	O
text	O
.	O
	
To	O
compare	O
with	O
the	O
existing	O
aspect	B-Task
-	I-Task
based	I-Task
sentiment	I-Task
analysis	I-Task
task	O
,	O
take	O
the	O
following	O
example	O
from	O
the	O
restaurant	O
dataset	O
used	O
by	O
SemEval	O
shared	O
ABSA	B-Task
task	I-Task
.	O
	
The	O
design	O
of	O
the	O
space	O
is	O
good	O
but	O
the	O
service	O
is	O
horrid	O
!	O
.	O
	
The	O
ABSA	B-Task
task	I-Task
aims	O
to	O
identify	O
that	O
a	O
positive	O
sentiment	O
towards	O
the	O
ambiance	O
aspect	O
is	O
expressed	O
(	O
opinion	O
target	O
expression	O
is	O
space	O
)	O
.	O
	
Moreover	O
,	O
a	O
negative	O
sentiment	O
is	O
expressed	O
towards	O
the	O
service	O
aspect	O
(	O
opinion	O
target	O
expression	O
is	O
service	O
)	O
.	O
	
In	O
this	O
example	O
,	O
it	O
is	O
assumed	O
that	O
both	O
of	O
these	O
opinions	O
are	O
expressed	O
about	O
a	O
single	O
restaurant	O
which	O
is	O
not	O
mentioned	O
explicitly	O
.	O
	
However	O
,	O
take	O
the	O
following	O
synthetic	O
example	O
that	O
ABSA	O
is	O
not	O
addressing	O
:	O
The	O
design	O
of	O
the	O
space	O
is	O
good	O
in	O
Boqueria	O
but	O
the	O
service	O
is	O
horrid	O
,	O
on	O
the	O
other	O
hand	O
,	O
the	O
staff	O
in	O
Gremio	O
are	O
very	O
friendly	O
and	O
the	O
food	O
is	O
always	O
delicious	O
.	O
	
In	O
this	O
example	O
,	O
more	O
than	O
one	O
restaurant	O
are	O
discussed	O
and	O
restaurants	O
for	O
which	O
opinions	O
are	O
expressed	O
,	O
are	O
explicitly	O
mentioned	O
.	O
	
We	O
call	O
these	O
target	O
entities	O
.	O
	
Current	O
ABSA	B-Task
task	I-Task
can	O
only	O
recognise	O
that	O
positive	O
and	O
negative	O
opinions	O
towards	O
aspect	O
service	O
are	O
expressed	O
.	O
	
But	O
it	O
can	O
not	O
identify	O
the	O
target	O
entity	O
for	O
each	O
of	O
these	O
opinions	O
(	O
i.e.	O
Germio	O
and	O
Boqueria	O
respectively	O
)	O
.	O
	
Targeted	O
aspect	B-Task
-	I-Task
based	I-Task
sentiment	I-Task
analysis	I-Task
handles	O
extracting	O
the	O
target	O
entities	O
as	O
well	O
as	O
different	O
aspects	O
and	O
their	O
relevant	O
sentiments	O
.	O
	
In	O
the	O
following	O
,	O
we	O
argue	O
that	O
this	O
task	O
is	O
both	O
very	O
relevant	O
in	O
practice	O
,	O
and	O
raises	O
interesting	O
modelling	O
questions	O
.	O
	
To	O
facilitate	O
research	O
on	O
this	O
task	O
we	O
introduce	O
the	O
SentiHood	B-Material
dataset	I-Material
.	O
	
SentiHood	B-Material
is	O
based	O
on	O
the	O
text	O
from	O
a	O
QA	B-Method
platform	I-Method
in	O
the	O
domain	O
of	O
neighbourhoods	O
of	O
a	O
city	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
examples	O
of	O
input	O
sentences	O
and	O
annotations	O
provided	O
.	O
	
Our	O
contributions	O
in	O
this	O
paper	O
can	O
be	O
summarised	O
as	O
follows	O
:	O
	
We	O
introduce	O
the	O
task	O
of	O
targeted	O
aspect	B-Task
-	I-Task
based	I-Task
sentiment	I-Task
analysis	I-Task
as	O
a	O
further	O
step	O
towards	O
extracting	O
more	O
fine	B-Task
-	I-Task
grained	I-Task
information	I-Task
from	O
more	O
complex	O
text	O
in	O
the	O
field	O
of	O
sentiment	B-Task
analysis	I-Task
.	O
	
We	O
use	O
the	O
text	O
from	O
social	O
media	O
platforms	O
,	O
in	O
particular	O
QA	O
,	O
for	O
fine	B-Task
-	I-Task
grained	I-Task
opinion	I-Task
mining	I-Task
.	O
	
So	O
far	O
,	O
all	O
datasets	O
in	O
this	O
field	O
have	O
utilised	O
text	O
from	O
review	O
specific	O
platforms	O
where	O
certain	O
assumptions	O
can	O
be	O
made	O
and	O
data	O
is	O
more	O
constrained	O
and	O
less	O
noisy	O
.	O
	
We	O
propose	O
SentiHood	B-Material
,	O
a	O
benchmark	O
dataset	O
that	O
is	O
annotated	O
for	O
the	O
task	O
of	O
targeted	O
aspect	B-Task
-	I-Task
based	I-Task
sentiment	I-Task
analysis	I-Task
in	O
the	O
domain	B-Task
of	I-Task
urban	I-Task
neighbourhoods	I-Task
.	O
	
We	O
show	O
that	O
despite	O
the	O
fact	O
that	O
the	O
texts	O
in	O
QA	O
were	O
not	O
written	O
with	O
the	O
goal	O
of	O
writing	O
a	O
review	O
in	O
mind	O
,	O
question	B-Task
answering	I-Task
platforms	I-Task
and	O
online	O
forums	O
are	O
in	O
general	O
rich	O
in	O
information	O
.	O
	
We	O
provide	O
strong	O
baselines	O
for	O
the	O
task	O
using	O
both	O
logistic	B-Method
regression	I-Method
and	O
Long	O
Short	O
Term	O
Memory	O
(	O
LSTM	B-Method
)	O
networks	O
and	O
analysis	O
of	O
the	O
results	O
.	O
	
section	O
:	O
SentiHood	B-Material
	
SentiHood	B-Material
is	O
a	O
dataset	O
for	O
the	O
task	O
of	O
targeted	O
aspect	B-Task
-	I-Task
based	I-Task
sentiment	I-Task
analysis	I-Task
.	O
	
It	O
is	O
based	O
on	O
the	O
text	O
taken	O
from	O
question	B-Method
answering	I-Method
platform	I-Method
of	O
Yahoo	O
!	O
	
Answers	O
that	O
is	O
filtered	O
for	O
questions	O
relating	O
to	O
neighbourhoods	O
of	O
the	O
city	O
of	O
London	O
.	O
	
In	O
this	O
section	O
we	O
explain	O
the	O
data	B-Task
collection	I-Task
and	O
annotation	B-Task
process	I-Task
and	O
summarise	O
properties	O
of	O
the	O
dataset	O
.	O
	
subsection	O
:	O
Data	O
Collection	O
Process	O
	
Entities	O
in	O
the	O
dataset	O
are	O
locations	O
or	O
neighbourhoods	O
.	O
	
Yahoo	O
!	O
	
Answers	O
was	O
queried	O
using	O
the	O
name	O
of	O
each	O
neighbourhood	O
of	O
the	O
city	O
of	O
London	O
.	O
	
Location	O
(	O
entity	O
)	O
names	O
were	O
taken	O
from	O
the	O
gazetteer	O
GeoNames	O
and	O
restricted	O
to	O
those	O
within	O
the	O
boundaries	O
of	O
London	O
.	O
	
This	O
list	O
includes	O
names	O
of	O
areas	O
and	O
boroughs	O
and	O
therefore	O
entities	O
are	O
not	O
always	O
geographically	O
exclusive	O
(	O
a	O
borough	O
contains	O
several	O
areas	O
or	O
neighbourhoods	O
)	O
.	O
	
The	O
content	O
of	O
each	O
question	O
-	O
answer	O
pairs	O
was	O
aggregated	O
and	O
split	O
into	O
sentences	O
.	O
	
We	O
keep	O
only	O
sentences	O
that	O
have	O
a	O
mention	O
of	O
a	O
location	O
entity	O
name	O
and	O
discard	O
other	O
sentences	O
.	O
	
subsection	O
:	O
Categories	O
	
The	O
Number	O
of	O
location	O
mentions	O
in	O
a	O
single	O
sentence	O
in	O
our	O
dataset	O
varies	O
from	O
one	O
to	O
over	O
.	O
	
To	O
simplify	O
the	O
task	O
,	O
we	O
only	O
annotate	O
sentences	O
that	O
contain	O
one	O
or	O
two	O
location	O
mentions	O
.	O
	
These	O
sentences	O
were	O
divided	O
into	O
two	O
groups	O
:	O
sentences	O
containing	O
one	O
location	O
mention	O
—	O
Single	O
,	O
and	O
sentences	O
containing	O
two	O
location	O
mentions	O
	
—	O
Multi	O
.	O
	
This	O
is	O
to	O
observe	O
the	O
difficulty	O
of	O
annotating	O
two	O
groups	O
by	O
human	O
annotators	O
and	O
by	O
the	O
models	O
.	O
	
subsection	O
:	O
Aspects	O
	
Like	O
existing	O
work	O
in	O
the	O
aspect	B-Task
-	I-Task
based	I-Task
sentiment	I-Task
analysis	I-Task
task	O
,	O
a	O
pre	O
-	O
defined	O
list	O
of	O
aspects	O
is	O
provided	O
for	O
annotators	O
to	O
choose	O
from	O
.	O
	
These	O
aspects	O
are	O
:	O
live	O
,	O
safety	O
,	O
price	O
,	O
quiet	O
,	O
dining	O
,	O
nightlife	O
,	O
transit	O
-	O
location	O
,	O
touristy	O
,	O
shopping	O
,	O
green	O
-	O
culture	O
and	O
multicultural	O
.	O
	
Adding	O
an	O
additional	O
aspect	O
of	O
misc	O
was	O
considered	O
.	O
	
However	O
in	O
the	O
initial	O
round	O
of	O
annotations	O
,	O
we	O
realised	O
that	O
it	O
had	O
a	O
negative	O
effect	O
on	O
the	O
decisiveness	O
of	O
annotators	O
and	O
it	O
led	O
to	O
a	O
lower	O
overall	O
agreement	B-Metric
.	O
	
Aspect	O
general	O
refers	O
to	O
a	O
generic	O
opinion	O
about	O
a	O
location	O
,	O
e.g.	O
I	O
love	O
Camden	O
Town	O
.	O
	
subsection	O
:	O
Sentiment	O
	
For	O
each	O
selected	O
aspect	O
,	O
annotators	O
were	O
required	O
to	O
select	O
a	O
polarity	O
or	O
sentiment	O
.	O
	
Most	O
work	O
in	O
this	O
area	O
considers	O
three	O
sentiment	O
categories	O
of	O
Positive	O
.	O
	
Negative	O
and	O
Neutral	O
.	O
	
In	O
our	O
annotation	O
however	O
,	O
we	O
only	O
provided	O
Positive	O
and	O
Negative	O
sentiment	O
labels	O
.	O
	
This	O
is	O
because	O
in	O
our	O
data	O
we	O
rarely	O
come	O
across	O
cases	O
where	O
aspects	O
are	O
discussed	O
without	O
a	O
polarity	O
.	O
	
subsection	O
:	O
Target	O
Entity	O
	
Target	O
entity	O
is	O
a	O
location	O
entity	O
in	O
which	O
an	O
opinion	O
(	O
aspect	O
and	O
sentiment	O
)	O
is	O
expressed	O
for	O
.	O
	
We	O
also	O
refer	O
to	O
target	O
entity	O
as	O
target	O
location	O
.	O
	
subsection	O
:	O
Out	O
of	O
scope	O
	
For	O
the	O
sentences	O
that	O
do	O
not	O
comply	O
with	O
our	O
schema	O
,	O
we	O
define	O
the	O
two	O
following	O
special	O
labels	O
.	O
	
Sentences	O
marked	O
with	O
one	O
of	O
the	O
these	O
labels	O
are	O
removed	O
from	O
the	O
dataset	O
.	O
	
Irrelevant	O
:	O
When	O
the	O
identified	O
name	O
does	O
not	O
refer	O
to	O
a	O
location	O
entity	O
:	O
for	O
example	O
in	O
the	O
sentence	O
Notting	O
Hill	O
(	O
1999	O
)	O
stars	O
Julia	O
Roberts	O
and	O
Hugh	O
Grant	O
use	O
the	O
characteristic	O
features	O
of	O
the	O
area	O
as	O
a	O
backdrop	O
to	O
the	O
action	O
,	O
Notting	O
Hill	O
refers	O
to	O
the	O
movie	O
and	O
not	O
the	O
area	O
.	O
	
Uncertain	O
:	O
	
When	O
two	O
contradicting	O
sentiments	O
are	O
expressed	O
for	O
the	O
same	O
location	O
and	O
aspect	O
,	O
e.g.	O
Like	O
any	O
other	O
area	O
,	O
Camden	O
Town	O
has	O
good	O
and	O
bad	O
parts	O
.	O
	
Moreover	O
,	O
when	O
the	O
opinion	O
is	O
expressed	O
for	O
an	O
area	O
without	O
a	O
direct	O
mention	O
in	O
the	O
sentences	O
,	O
e.g.	O
It	O
’s	O
a	O
very	O
trendy	O
area	O
and	O
not	O
too	O
far	O
from	O
King	O
’s	O
Cross	O
.	O
	
subsection	O
:	O
Procedure	O
:	O
	
We	O
use	O
the	O
BRAT	B-Method
annotation	I-Method
tool	I-Method
to	O
simplify	O
the	O
annotation	B-Task
task	I-Task
.	O
	
Three	O
annotators	O
were	O
initially	O
selected	O
for	O
the	O
task	O
.	O
	
None	O
of	O
the	O
annotators	O
are	O
experts	O
in	O
linguistics	B-Task
.	O
	
Annotators	O
began	O
by	O
reading	O
the	O
guidelines	O
and	O
examples	O
.	O
	
Each	O
annotator	O
was	O
then	O
required	O
to	O
annotate	O
a	O
small	O
subset	O
of	O
the	O
data	O
.	O
	
After	O
each	O
round	O
of	O
annotation	O
,	O
agreements	O
between	O
annotators	O
were	O
calculated	O
and	O
discussed	O
and	O
this	O
procedure	O
continued	O
until	O
they	O
reached	O
a	O
reasonable	O
agreement	B-Metric
.	O
	
10	O
%	O
of	O
the	O
whole	O
dataset	O
was	O
randomly	O
selected	O
and	O
annotated	O
by	O
all	O
the	O
three	O
annotators	O
.	O
	
The	O
annotator	O
with	O
the	O
highest	O
inter	O
-	O
annotator	O
agreement	B-Metric
was	O
selected	O
to	O
annotate	O
all	O
the	O
dataset	O
.	O
	
paragraph	O
:	O
Agreements	O
:	O
	
Cohen	B-Metric
’s	I-Metric
Kappa	I-Metric
coefficient	I-Metric
(	O
)	O
is	O
often	O
used	O
for	O
measuring	O
the	O
pairwise	O
agreement	B-Metric
between	O
each	O
two	O
annotators	O
for	O
the	O
task	O
of	O
aspect	B-Task
-	I-Task
based	I-Task
sentiment	I-Task
analysis	I-Task
and	O
other	O
tasks	O
.	O
	
The	O
Kappa	B-Metric
Coefficient	I-Metric
is	O
calculated	O
over	O
aspect	O
-	O
sentiment	O
pairs	O
per	O
each	O
location	O
.	O
	
Pairwise	O
inter	O
-	O
annotator	O
agreement	B-Metric
for	O
aspect	O
categories	O
measured	O
using	O
Cohen	B-Metric
’s	I-Metric
Kappa	I-Metric
is	O
,	O
and	O
,	O
which	O
is	O
deemed	O
of	O
sufficient	O
quality	O
.	O
	
It	O
is	O
worth	O
mentioning	O
that	O
agreements	O
on	O
different	O
aspect	O
categories	O
varied	O
,	O
with	O
some	O
aspects	O
having	O
a	O
higher	O
agreement	B-Metric
rate	O
.	O
	
Agreements	O
for	O
aspect	O
expressions	O
are	O
,	O
,	O
.	O
	
These	O
agreements	O
indicate	O
reasonably	O
high	O
inter	O
-	O
annotator	O
agreements	O
.	O
	
paragraph	O
:	O
Disagreements	O
:	O
	
Main	O
disagreements	O
between	O
annotators	O
occurred	O
in	O
detecting	O
the	O
aspect	O
rather	O
than	O
detecting	O
the	O
sentiment	O
,	O
aspect	O
expression	O
or	O
the	O
target	O
location	O
.	O
	
For	O
instance	O
,	O
some	O
annotators	O
associated	O
the	O
expression	O
residential	O
area	O
with	O
a	O
Positive	O
sentiment	O
for	O
aspect	O
quiet	O
or	O
live	O
and	O
others	O
did	O
not	O
agree	O
that	O
residential	O
implies	O
quietness	O
or	O
desirable	O
for	O
living	O
.	O
	
In	O
the	O
case	O
of	O
disagreements	O
,	O
the	O
vote	O
of	O
the	O
majority	O
was	O
considered	O
as	O
the	O
correct	O
annotation	O
.	O
	
Some	O
ambiguity	O
was	O
also	O
observed	O
with	O
respect	O
to	O
detecting	O
the	O
target	O
location	O
.	O
	
This	O
occurred	O
mainly	O
when	O
a	O
location	O
is	O
confined	O
in	O
another	O
location	O
.	O
	
For	O
instance	O
the	O
sentence	O
Angel	O
in	O
Inslington	O
has	O
many	O
great	O
restaurants	O
for	O
eating	O
out	O
expresses	O
a	O
Positive	O
sentiment	O
for	O
the	O
aspect	O
dining	O
of	O
area	O
Angel	O
which	O
is	O
within	O
the	O
borough	O
of	O
Islington	O
.	O
	
Some	O
annotators	O
suggested	O
that	O
the	O
sentence	O
also	O
implies	O
the	O
same	O
opinion	O
for	O
Islington	O
.	O
	
However	O
at	O
the	O
end	O
all	O
annotators	O
agreed	O
that	O
in	O
such	O
cases	O
no	O
implicit	O
assumptions	O
should	O
be	O
made	O
and	O
only	O
confined	O
area	O
should	O
be	O
labeled	O
.	O
	
subsection	O
:	O
Dataset	O
	
SentiHood	B-Material
currently	O
contains	O
annotated	O
sentences	O
containing	O
one	O
or	O
two	O
location	O
entity	O
mentions	O
.	O
	
SentiHood	B-Material
contains	O
sentences	O
with	O
sentences	O
containing	O
a	O
single	O
location	O
and	O
sentences	O
containing	O
multiple	O
(	O
two	O
)	O
locations	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
the	O
number	O
of	O
sentences	O
that	O
are	O
labeled	O
with	O
each	O
aspect	O
,	O
breaking	O
down	O
on	O
the	O
sentiment	O
Positive	O
or	O
Negative	O
.	O
	
Positive	O
sentiment	O
is	O
dominant	O
for	O
aspects	O
such	O
as	O
dining	O
and	O
shopping	O
.	O
	
This	O
shows	O
that	O
for	O
some	O
aspects	O
,	O
people	O
usually	O
talk	O
about	O
areas	O
that	O
are	O
good	O
for	O
it	O
as	O
oppose	O
to	O
areas	O
that	O
are	O
not	O
.	O
	
The	O
general	O
aspect	O
is	O
the	O
most	O
frequent	O
aspect	O
with	O
over	O
sentences	O
while	O
aspect	O
touristy	O
has	O
occurred	O
in	O
less	O
than	O
sentences	O
.	O
	
Notice	O
that	O
since	O
each	O
sentence	O
can	O
contain	O
one	O
or	O
more	O
opinions	O
,	O
the	O
total	O
number	O
of	O
opinions	O
(	O
)	O
in	O
the	O
dataset	O
is	O
higher	O
than	O
the	O
number	O
of	O
sentences	O
.	O
	
Location	O
entity	O
names	O
are	O
masked	O
by	O
location1	O
and	O
location2	O
in	O
the	O
whole	O
dataset	O
,	O
so	O
the	O
task	O
does	O
not	O
involve	O
identification	B-Task
and	O
segmentation	B-Task
of	I-Task
the	I-Task
named	I-Task
entities	I-Task
.	O
	
We	O
also	O
provide	O
the	O
dataset	O
with	O
the	O
original	O
location	O
entity	O
names	O
.	O
	
section	O
:	O
Task	O
	
We	O
define	O
the	O
task	O
of	O
targeted	O
aspect	B-Task
-	I-Task
based	I-Task
sentiment	I-Task
analysis	I-Task
as	O
follows	O
:	O
given	O
a	O
unit	O
of	O
text	O
(	O
for	O
example	O
,	O
a	O
sentence	O
)	O
,	O
provide	O
a	O
list	O
of	O
tuples	O
(	O
labels	O
)	O
,	O
where	O
is	O
the	O
polarity	O
expressed	O
for	O
the	O
aspect	O
of	O
entity	O
.	O
	
Each	O
sentence	O
can	O
have	O
zero	O
to	O
number	O
of	O
labels	O
associated	O
with	O
it	O
.	O
	
Within	O
the	O
current	O
aspect	B-Task
-	I-Task
based	I-Task
sentiment	I-Task
analysis	I-Task
work	O
,	O
three	O
tasks	O
are	O
defined	O
:	O
detecting	O
the	O
aspect	O
,	O
detecting	O
the	O
opinion	O
target	O
expression	O
and	O
detecting	O
the	O
sentiment	O
,	O
with	O
detecting	O
the	O
opinion	O
target	O
expression	O
being	O
an	O
intermediary	O
task	O
for	O
identifying	O
the	O
sentiment	O
of	O
the	O
aspect	O
.	O
	
Here	O
we	O
focus	O
on	O
identifying	O
only	O
the	O
aspect	O
and	O
sentiment	O
for	O
each	O
entity	O
.	O
	
We	O
identify	O
each	O
aspect	O
,	O
its	O
relevant	O
sentiment	O
and	O
the	O
target	O
location	O
entity	O
jointly	O
by	O
introducing	O
a	O
new	O
polarity	O
class	O
called	O
None	O
.	O
	
None	O
indicated	O
that	O
a	O
sentence	O
does	O
not	O
contain	O
an	O
opinion	O
for	O
the	O
aspect	O
of	O
location	O
.	O
	
Therefore	O
the	O
overall	O
task	O
can	O
be	O
defined	O
as	O
a	O
three	B-Task
-	I-Task
class	I-Task
classification	I-Task
task	I-Task
for	O
each	O
pair	O
with	O
labels	O
Positive	O
,	O
Negative	O
,	O
None	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
an	O
example	O
of	O
the	O
input	O
sentence	O
and	O
output	O
labels	O
.	O
	
section	O
:	O
Evaluation	O
	
Most	O
existing	O
work	O
in	O
aspect	B-Task
-	I-Task
based	I-Task
sentiment	I-Task
analysis	I-Task
field	O
,	O
report	B-Metric
measure	I-Metric
for	O
aspect	B-Task
detection	I-Task
task	I-Task
,	O
and	O
accuracy	B-Metric
for	O
sentiment	B-Task
classification	I-Task
.	O
	
The	O
scores	O
can	O
be	O
calculated	O
over	O
2	O
-	O
class	O
or	O
3	O
-	O
class	O
sentiments	O
.	O
	
In	O
our	O
results	O
,	O
score	O
is	O
calculated	O
with	O
a	O
threshold	O
that	O
is	O
optimized	O
on	O
validation	O
set	O
.	O
	
We	O
also	O
propose	O
the	O
AUC	B-Metric
(	O
area	B-Metric
under	I-Metric
the	I-Metric
ROC	I-Metric
curve	I-Metric
)	I-Metric
metric	I-Metric
for	O
both	O
aspect	B-Task
and	I-Task
sentiment	I-Task
detection	I-Task
tasks	I-Task
.	O
	
AUC	B-Metric
captures	O
the	O
quality	O
of	O
the	O
ranking	B-Metric
of	I-Metric
output	I-Metric
scores	I-Metric
and	O
does	O
not	O
rely	O
on	O
a	O
threshold	O
.	O
	
section	O
:	O
Baseline	O
	
Here	O
we	O
propose	O
baselines	O
for	O
the	O
task	O
.	O
	
In	O
all	O
our	O
methods	O
,	O
we	O
treat	O
the	O
task	O
as	O
a	O
three	B-Task
-	I-Task
class	I-Task
classification	I-Task
for	O
each	O
aspect	O
and	O
use	O
a	O
softmax	B-Method
function	I-Method
as	O
follows	O
:	O
	
where	O
is	O
the	O
sentiment	O
label	O
of	O
aspect	O
for	O
location	O
.	O
	
and	O
are	O
the	O
weights	O
and	O
the	O
bias	O
specific	O
to	O
each	O
sentiment	O
class	O
,	O
respectively	O
.	O
	
is	O
a	O
representation	B-Task
of	I-Task
location	I-Task
.	O
	
This	O
representation	O
can	O
be	O
a	O
BoW	B-Method
or	O
a	O
distributional	B-Method
representation	I-Method
.	O
	
Each	O
method	O
that	O
we	O
propose	O
here	O
define	O
their	O
own	O
specific	O
representation	O
for	O
.	O
	
subsection	O
:	O
Logistic	B-Method
Regression	I-Method
	
Many	O
existing	O
works	O
in	O
the	O
aspect	B-Task
-	I-Task
based	I-Task
sentiment	I-Task
analysis	I-Task
task	O
,	O
use	O
a	O
classifier	B-Method
,	O
such	O
as	O
logistic	B-Method
regression	I-Method
or	O
SVM	B-Method
,	O
based	O
on	O
linguistic	O
features	O
such	O
as	O
n	O
-	O
grams	O
,	O
POS	O
information	O
or	O
more	O
hand	O
-	O
engineered	O
features	O
.	O
	
We	O
can	O
think	O
of	O
these	O
features	O
as	O
a	O
sparse	B-Method
representation	I-Method
that	O
enter	O
the	O
softmax	O
in	O
equation	O
[	O
reference	O
]	O
.	O
	
More	O
concretely	O
,	O
we	O
define	O
the	O
following	O
sparse	B-Method
representations	I-Method
of	I-Method
locations	I-Method
:	O
	
paragraph	O
:	O
Mask	O
target	O
entity	O
n	O
-	O
grams	O
:	O
	
For	O
each	O
location	O
,	O
we	O
define	O
an	O
n	B-Method
-	I-Method
gram	I-Method
representation	I-Method
over	O
the	O
sentence	O
and	O
mask	O
the	O
target	O
location	O
using	O
a	O
special	O
token	O
.	O
	
This	O
can	O
help	O
to	O
differentiate	O
between	O
representations	O
of	O
two	O
locations	O
present	O
in	O
the	O
same	O
sentence	O
.	O
	
paragraph	O
:	O
Left	O
-	O
right	O
n	O
-	O
grams	O
:	O
	
we	O
create	O
an	O
n	B-Method
-	I-Method
gram	I-Method
representation	I-Method
for	O
both	O
the	O
right	O
and	O
the	O
left	O
context	O
around	O
each	O
location	O
mention	O
.	O
	
We	O
then	O
concatenate	O
these	O
two	O
representations	O
to	O
obtain	O
one	O
single	O
feature	O
vector	O
.	O
	
paragraph	O
:	O
Left	O
right	O
pooling	O
:	O
	
Previously	O
embedding	B-Method
representations	I-Method
over	O
the	O
left	O
and	O
right	O
context	O
have	O
been	O
used	O
for	O
automatic	B-Task
feature	I-Task
detection	I-Task
in	O
the	O
targeted	O
sentiment	B-Task
analysis	I-Task
task	O
.	O
	
Inspired	O
by	O
this	O
approach	O
,	O
we	O
obtain	O
max	B-Metric
,	I-Metric
min	I-Metric
,	O
average	B-Method
and	I-Method
standard	I-Method
deviation	I-Method
pooling	I-Method
over	O
all	O
the	O
word	O
embeddings	O
for	O
left	O
and	O
right	O
context	O
separately	O
.	O
	
We	O
then	O
combine	O
the	O
pooled	O
embeddings	O
of	O
the	O
left	O
and	O
right	O
context	O
to	O
obtain	O
a	O
single	O
feature	O
vector	O
.	O
	
Word	O
embeddings	O
are	O
obtained	O
by	O
running	O
word2vec	B-Method
tool	I-Method
on	O
a	O
combination	O
of	O
our	O
Yahoo	O
!	O
	
Answers	O
corpus	O
and	O
a	O
substantially	O
big	O
corpus	O
from	O
the	O
web	O
.	O
	
subsection	O
:	O
Long	O
Short	O
-	O
Term	O
Memory	O
(	O
LSTM	B-Method
)	O
	
Inspired	O
by	O
the	O
recent	O
success	O
of	O
applying	O
deep	B-Method
neural	I-Method
networks	I-Method
on	O
language	B-Task
tasks	I-Task
,	O
we	O
use	O
a	O
bidirectional	O
LSTM	B-Method
to	O
learn	O
a	O
classifier	B-Method
for	O
each	O
of	O
the	O
aspects	O
.	O
	
Representations	O
for	O
a	O
location	O
(	O
)	O
are	O
obtained	O
using	O
one	O
of	O
the	O
following	O
two	O
approaches	O
:	O
	
paragraph	O
:	O
Final	O
output	O
state	O
(	O
LSTM	B-Method
-	I-Method
Final	I-Method
)	O
:	O
	
is	O
the	O
output	O
embedding	O
of	O
the	O
bidirectional	O
LSTM	B-Method
.	O
	
paragraph	O
:	O
Location	O
output	O
state	O
(	O
LSTM	B-Method
-	I-Method
Location	I-Method
)	O
:	O
	
is	O
the	O
output	O
representation	O
at	O
the	O
index	O
corresponding	O
to	O
the	O
location	O
entity	O
as	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
Experiments	O
	
In	O
this	O
paper	O
,	O
we	O
select	O
the	O
four	O
most	O
frequent	O
aspects	O
from	O
the	O
dataset	O
which	O
are	O
:	O
price	O
,	O
safety	O
,	O
transit	O
-	O
location	O
and	O
general	O
	
but	O
the	O
same	O
approach	O
can	O
be	O
applied	O
to	O
the	O
remaining	O
aspects	O
.	O
	
We	O
divide	O
each	O
collection	O
of	O
single	O
and	O
multiple	O
location	O
mentions	O
into	O
train	O
,	O
dev	O
and	O
test	O
set	O
,	O
with	O
each	O
having	O
,	O
and	O
of	O
data	O
respectively	O
.	O
	
We	O
choose	O
the	O
best	O
model	O
with	O
respect	O
to	O
the	O
dev	O
set	O
.	O
	
In	O
the	O
case	O
of	O
the	O
LSTM	B-Method
,	O
we	O
evaluate	O
the	O
loss	B-Metric
on	O
both	O
training	O
set	O
and	O
dev	O
set	O
after	O
each	O
iteration	O
.	O
	
We	O
save	O
the	O
best	O
model	O
which	O
has	O
the	O
lowest	O
loss	O
on	O
the	O
dev	O
set	O
over	O
all	O
the	O
iterations	O
.	O
	
We	O
then	O
run	O
this	O
model	O
on	O
the	O
test	O
set	O
and	O
report	O
the	O
results	O
.	O
	
We	O
report	O
results	O
separately	O
on	O
both	O
categories	O
of	O
single	O
location	O
sentences	O
and	O
sentences	O
with	O
two	O
locations	O
and	O
over	O
all	O
the	O
data	O
in	O
the	O
test	O
set	O
.	O
	
Results	O
on	O
single	O
location	O
sentences	O
mainly	O
show	O
the	O
ability	O
of	O
the	O
model	O
to	O
detect	O
the	O
correct	O
sentiment	O
for	O
an	O
aspect	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
results	O
on	O
two	O
location	O
sentences	O
demonstrate	O
the	O
ability	O
of	O
the	O
system	O
not	O
only	O
on	O
detecting	O
the	O
relevant	O
sentiment	O
of	O
an	O
aspect	O
but	O
also	O
on	O
recognising	O
the	O
target	O
entity	O
of	O
the	O
opinion	O
.	O
	
paragraph	O
:	O
Training	O
LSTMs	B-Method
	
We	O
implement	O
our	O
LSTM	B-Method
models	O
using	O
tensorflow	B-Method
.	O
	
To	O
tackle	O
the	O
problem	O
of	O
having	O
an	O
unbalanced	O
dataset	O
(	O
i.e.	O
too	O
many	O
None	O
instances	O
)	O
,	O
we	O
train	O
the	O
LSTM	B-Method
model	I-Method
in	O
batches	O
with	O
every	O
batch	O
having	O
the	O
same	O
number	O
of	O
sentences	O
selected	O
randomly	O
from	O
each	O
sentiment	O
class	O
.	O
	
We	O
tune	O
the	O
hyper	O
parameters	O
of	O
the	O
model	O
on	O
the	O
dev	O
set	O
.	O
	
The	O
best	O
model	O
uses	O
hidden	O
units	O
of	O
size	O
and	O
batch	O
sizes	O
of	O
size	O
.	O
	
The	O
Adam	B-Method
optimizer	I-Method
is	O
used	O
for	O
optimization	B-Task
with	O
a	O
starting	O
learning	B-Metric
rate	I-Metric
of	O
which	O
is	O
tuned	O
to	O
be	O
the	O
best	O
performing	O
on	O
the	O
dev	O
set	O
.	O
	
Dropout	B-Method
is	O
used	O
both	O
on	O
initial	O
word	O
embeddings	O
and	O
on	O
LSTM	B-Method
cells	I-Method
with	O
the	O
probability	O
of	O
.	O
	
Tensorflow	B-Method
is	O
used	O
for	O
the	O
implementation	O
of	O
LSTM	B-Method
.	O
	
paragraph	O
:	O
Training	O
Logistic	B-Method
Regression	I-Method
	
Logistic	B-Method
regression	I-Method
models	I-Method
were	O
based	O
on	O
implementations	O
from	O
scikit	B-Method
-	I-Method
learn	I-Method
.	O
	
Since	O
we	O
have	O
an	O
unbalanced	O
dataset	O
,	O
we	O
use	O
a	O
weighted	B-Method
logistic	I-Method
regression	I-Method
.	O
	
To	O
obtain	O
the	O
best	O
weights	O
,	O
we	O
cross	O
-	O
validate	O
them	O
on	O
the	O
development	O
set	O
.	O
	
Weights	O
inversely	O
proportional	O
to	O
the	O
size	O
of	O
each	O
class	O
result	O
in	O
the	O
best	O
performance	O
.	O
	
section	O
:	O
Results	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
results	O
(	O
averaged	O
over	O
all	O
selected	O
aspects	O
)	O
in	O
terms	O
of	O
both	O
/	B-Metric
accuracy	I-Metric
and	O
AUCs	B-Metric
.	O
	
It	O
also	O
shows	O
the	O
results	O
of	O
logistic	B-Method
regression	I-Method
based	I-Method
models	I-Method
versus	O
LSTM	B-Method
models	O
.	O
	
As	O
we	O
can	O
see	O
,	O
the	O
n	B-Method
-	I-Method
gram	I-Method
representation	I-Method
with	O
location	B-Method
masking	I-Method
achieves	O
slightly	O
better	O
results	O
over	O
the	O
left	O
-	O
right	O
context	O
.	O
	
N	B-Method
-	I-Method
grams	I-Method
include	O
unigrams	O
and	O
bigrams	B-Method
.	O
	
Also	O
,	O
by	O
adding	O
POS	O
information	O
,	O
we	O
gain	O
an	O
increase	O
in	O
the	O
performance	O
.	O
	
We	O
also	O
experimented	O
with	O
adding	O
tri	O
-	O
grams	O
but	O
it	O
did	O
not	O
have	O
a	O
positive	O
effect	O
on	O
the	O
overall	O
scores	O
.	O
	
Separating	O
the	O
left	O
and	O
the	O
right	O
context	O
(	O
LR	O
-	O
Left	O
-	O
Right	O
)	O
for	O
BoW	B-Method
representation	I-Method
,	O
does	O
not	O
improve	O
the	O
performance	O
.	O
	
Left	B-Method
-	I-Method
right	I-Method
pooling	I-Method
of	I-Method
dense	I-Method
embeddings	I-Method
performed	O
weakly	O
in	O
comparison	O
with	O
other	O
representations	O
and	O
therefore	O
their	O
results	O
were	O
omitted	O
.	O
	
Amongst	O
the	O
two	O
variations	O
of	O
LSTM	B-Method
,	O
the	O
model	O
with	O
final	O
state	O
embeddings	O
does	O
slightly	O
better	O
than	O
the	O
model	O
where	O
we	O
use	O
the	O
embeddings	O
at	O
the	O
location	O
index	O
,	O
however	O
they	O
are	O
not	O
significantly	O
different	O
(	O
with	O
a	O
value	O
less	O
than	O
)	O
.	O
	
It	O
is	O
interesting	O
to	O
note	O
that	O
the	O
best	O
LSTM	B-Method
model	I-Method
is	O
not	O
superior	O
to	O
logistic	B-Method
regression	I-Method
model	I-Method
,	O
especially	O
in	O
terms	O
of	O
AUC	B-Metric
.	O
	
This	O
can	O
be	O
due	O
to	O
the	O
fact	O
that	O
the	O
amount	O
of	O
training	O
data	O
is	O
not	O
sufficient	O
for	O
LSTM	B-Method
to	O
perform	O
well	O
.	O
	
Moreover	O
,	O
while	O
we	O
provide	O
some	O
grammar	O
information	O
to	O
logistic	B-Method
regression	I-Method
model	I-Method
through	O
POS	O
tags	O
,	O
such	O
information	O
is	O
not	O
incorporated	O
into	O
LSTM	B-Method
models	O
.	O
	
Another	O
interesting	O
observation	O
is	O
that	O
the	O
measure	O
for	O
logistic	B-Method
regression	I-Method
model	I-Method
with	O
n	O
-	O
grams	O
and	O
POS	O
information	O
is	O
very	O
low	O
while	O
this	O
model	O
	
’s	O
performance	O
is	O
superior	O
to	O
other	O
models	O
in	O
terms	O
of	O
AUC	B-Metric
.	O
	
This	O
is	O
because	O
in	O
general	O
,	O
it	O
is	O
easier	O
to	O
rank	O
prediction	O
scores	O
than	O
to	O
assign	O
predicted	O
labels	O
to	O
instances	O
by	O
choosing	O
a	O
hard	O
threshold	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
average	O
AUC	B-Metric
(	O
over	O
aspect	B-Task
and	I-Task
sentimentclassification	I-Task
tasks	I-Task
)	O
for	O
two	O
categories	O
of	O
data	O
:	O
Single	O
—	O
sentences	O
that	O
contain	O
one	O
location	O
entity	O
and	O
Multi	O
—	O
sentences	O
that	O
contain	O
two	O
location	O
entities	O
.	O
	
While	O
logistic	B-Method
regression	I-Method
can	O
perform	O
slightly	O
better	O
on	O
son	O
Single	O
location	O
sentences	O
,	O
LSTM	B-Method
performs	O
slightly	O
better	O
on	O
Multi	O
location	O
sentences	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
break	O
down	O
of	O
average	O
AUC	B-Metric
scores	O
for	O
each	O
aspect	O
.	O
	
We	O
can	O
see	O
that	O
aspects	O
such	O
as	O
safety	O
can	O
be	O
predicted	O
with	O
a	O
better	O
AUC	B-Metric
score	O
than	O
aspect	O
general	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
examples	O
of	O
correct	O
and	O
incorrect	O
predictions	O
using	O
the	O
best	O
logistic	B-Method
regression	I-Method
model	I-Method
.	O
	
The	O
top	O
part	O
of	O
the	O
table	O
contains	O
examples	O
that	O
each	O
contain	O
a	O
single	O
location	O
entity	O
.	O
	
At	O
the	O
bottom	O
of	O
the	O
table	O
,	O
a	O
sentence	O
with	O
two	O
location	O
entities	O
is	O
provided	O
.	O
	
The	O
system	O
correctly	O
identifies	O
that	O
a	O
Positive	O
sentiment	O
is	O
expressed	O
for	O
the	O
general	O
aspect	O
about	O
location2	O
.	O
	
However	O
,	O
no	O
sentiment	O
is	O
expressed	O
for	O
this	O
aspect	O
for	O
location1	O
.	O
	
section	O
:	O
Related	O
Work	O
	
The	O
term	O
sentiment	B-Task
analysis	I-Task
was	O
first	O
used	O
in	O
.	O
	
Since	O
then	O
,	O
the	O
field	O
has	O
received	O
much	O
attention	O
from	O
both	O
research	O
and	O
industry	O
.	O
	
Sentiment	B-Task
analysis	I-Task
has	O
applications	O
in	O
almost	O
in	O
every	O
domain	O
	
and	O
it	O
raised	O
many	O
interesting	O
research	O
questions	O
.	O
	
Furthermore	O
,	O
the	O
availability	O
of	O
a	O
huge	O
volume	O
of	O
opinionated	O
data	O
on	O
social	O
media	O
platforms	O
has	O
accelerated	O
the	O
development	O
in	O
this	O
area	O
.	O
	
In	O
the	O
beginning	O
work	O
on	O
sentiment	B-Task
analysis	I-Task
mainly	O
focused	O
on	O
identifying	O
the	O
overall	O
sentiment	O
of	O
a	O
unit	O
of	O
text	O
.	O
	
The	O
unit	O
of	O
text	O
varied	O
from	O
document	O
,	O
paragraph	O
or	O
sentences	O
.	O
	
However	O
,	O
only	O
considering	O
the	O
overall	O
sentiment	O
fails	O
to	O
capture	O
the	O
sentiments	O
over	O
the	O
aspects	O
on	O
which	O
an	O
entity	O
can	O
be	O
reviewed	O
or	O
sentiment	O
expressed	O
toward	O
different	O
entities	O
.	O
	
Two	O
remedy	O
this	O
,	O
two	O
new	O
tasks	O
have	O
been	O
introduced	O
:	O
aspect	B-Task
-	I-Task
based	I-Task
sentiment	I-Task
analysis	I-Task
and	O
targeted	O
sentiment	B-Task
analysis	I-Task
.	O
	
Aspect	O
based	O
sentiment	B-Task
analysis	I-Task
assumes	O
a	O
single	O
entity	O
per	O
a	O
unit	O
of	O
analysis	O
and	O
tries	O
to	O
identify	O
sentiments	O
towards	O
different	O
aspects	O
of	O
the	O
entity	O
.	O
	
This	O
task	O
however	O
does	O
not	O
consider	O
more	O
than	O
one	O
entity	O
in	O
the	O
given	O
text	O
.	O
	
Targeted	B-Task
(	I-Task
target	I-Task
dependent	I-Task
)	I-Task
sentiment	I-Task
analysis	I-Task
is	O
another	O
task	O
that	O
identifies	O
polarity	O
towards	O
a	O
target	O
entity	O
(	O
as	O
opposed	O
to	O
over	O
entire	O
unit	O
of	O
text	O
)	O
.	O
	
was	O
the	O
first	O
to	O
propose	O
targeted	O
sentiment	B-Task
analysis	I-Task
on	O
Twitter	O
and	O
demonstrates	O
the	O
importance	O
of	O
targets	O
by	O
showing	O
that	O
40	O
%	O
of	O
sentiment	B-Metric
errors	I-Metric
are	O
due	O
to	O
not	O
considering	O
them	O
in	O
classification	B-Task
.	O
	
However	O
this	O
task	O
only	O
identifies	O
the	O
overall	O
sentiment	O
and	O
the	O
existing	O
corpora	O
for	O
the	O
task	O
consist	O
only	O
of	O
text	O
with	O
one	O
single	O
entity	O
per	O
unit	O
of	O
analysis	O
.	O
	
The	O
task	O
of	O
targeted	O
aspect	B-Task
-	I-Task
based	I-Task
sentiment	I-Task
analysis	I-Task
caters	O
for	O
more	O
generic	O
text	O
by	O
making	O
fewer	O
assumptions	O
while	O
extracting	O
fine	O
-	O
grained	O
information	O
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
paper	O
,	O
we	O
introduced	O
the	O
task	O
of	O
targeted	O
aspect	B-Task
-	I-Task
based	I-Task
sentiment	I-Task
analysis	I-Task
and	O
a	O
new	O
dataset	O
.	O
	
We	O
also	O
provide	O
two	O
strong	O
baselines	O
using	O
logistic	B-Method
regression	I-Method
and	O
LSTM	B-Method
.	O
	
Ways	O
to	O
improve	O
the	O
baselines	O
can	O
involve	O
using	O
parse	O
trees	O
for	O
identifying	O
the	O
context	O
of	O
each	O
location	O
.	O
	
Data	B-Task
augmentation	I-Task
can	O
be	O
used	O
to	O
make	O
the	O
models	O
and	O
especially	O
LSTM	B-Method
more	O
robust	O
to	O
variations	O
in	O
the	O
data	O
.	O
	
We	O
also	O
like	O
to	O
provide	O
more	O
detailed	O
analysis	O
of	O
what	O
each	O
system	O
can	O
achieve	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Deeply	B-Method
-	I-Method
Supervised	I-Method
Nets	I-Method
	
Our	O
proposed	O
deeply	B-Method
-	I-Method
supervised	I-Method
nets	I-Method
(	O
DSN	B-Method
)	O
method	O
simultaneously	O
minimizes	O
classification	B-Metric
error	I-Metric
while	O
making	O
the	O
learning	B-Method
process	I-Method
of	O
hidden	O
layers	O
direct	O
and	O
transparent	O
.	O
	
We	O
make	O
an	O
attempt	O
to	O
boost	O
the	O
classification	B-Task
performance	O
by	O
studying	O
a	O
new	O
formulation	O
in	O
deep	B-Method
networks	I-Method
.	O
	
Three	O
aspects	O
in	O
convolutional	B-Method
neural	I-Method
networks	I-Method
	
(	O
CNN	B-Method
)	I-Method
style	I-Method
architectures	I-Method
are	O
being	O
looked	O
at	O
:	O
(	O
1	O
)	O
transparency	B-Method
of	O
the	O
intermediate	O
layers	O
to	O
the	O
overall	O
classification	B-Task
;	O
(	O
2	O
)	O
discriminativeness	B-Method
and	O
robustness	O
of	O
learned	O
features	O
,	O
especially	O
in	O
the	O
early	O
layers	O
;	O
(	O
3	O
)	O
effectiveness	B-Method
in	O
training	B-Task
due	O
to	O
the	O
presence	O
of	O
the	O
exploding	O
and	O
vanishing	O
gradients	O
.	O
	
We	O
introduce	O
“	O
companion	O
objective	O
”	O
to	O
the	O
individual	O
hidden	O
layers	O
,	O
in	O
addition	O
to	O
the	O
overall	O
objective	O
at	O
the	O
output	O
layer	O
(	O
a	O
different	O
strategy	O
to	O
layer	B-Method
-	I-Method
wise	I-Method
pre	I-Method
-	I-Method
training	I-Method
)	O
.	O
	
We	O
extend	O
techniques	O
from	O
stochastic	B-Method
gradient	I-Method
methods	I-Method
to	O
analyze	O
our	O
algorithm	O
.	O
	
The	O
advantage	O
of	O
our	O
method	O
is	O
evident	O
and	O
our	O
experimental	O
result	O
on	O
benchmark	O
datasets	O
shows	O
significant	O
performance	O
gain	O
over	O
existing	O
methods	O
(	O
e.g.	O
all	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
MNIST	B-Material
,	O
CIFAR	B-Material
-	I-Material
10	I-Material
,	O
CIFAR	B-Material
-	I-Material
100	I-Material
,	O
and	O
SVHN	B-Material
)	O
.	O
	
section	O
:	O
Introduction	O
	
Much	O
attention	O
has	O
been	O
given	O
to	O
a	O
resurgence	O
of	O
neural	B-Method
networks	I-Method
,	O
deep	B-Method
learning	I-Method
(	I-Method
DL	I-Method
)	I-Method
in	O
particular	O
,	O
which	O
can	O
be	O
of	O
unsupervised	O
,	O
supervised	O
,	O
or	O
a	O
hybrid	B-Method
form	I-Method
.	O
	
Significant	O
performance	O
gain	O
has	O
been	O
observed	O
,	O
especially	O
in	O
the	O
presence	O
of	O
large	O
amount	O
of	O
training	O
data	O
,	O
when	O
deep	B-Method
learning	I-Method
techniques	I-Method
are	O
used	O
for	O
image	B-Task
classification	I-Task
and	O
speech	B-Task
recognition	I-Task
.	O
	
On	O
the	O
one	O
hand	O
,	O
hierarchical	B-Method
and	O
recursive	B-Method
networks	I-Method
have	O
demonstrated	O
great	O
promise	O
in	O
automatically	B-Task
learning	I-Task
thousands	I-Task
or	I-Task
even	I-Task
millions	I-Task
of	I-Task
features	I-Task
for	O
pattern	B-Task
recognition	I-Task
;	O
on	O
the	O
other	O
hand	O
concerns	O
about	O
deep	B-Task
learning	I-Task
have	O
been	O
raised	O
and	O
many	O
fundamental	O
questions	O
remain	O
open	O
.	O
	
Some	O
potential	O
problems	O
with	O
the	O
current	O
DL	B-Method
frameworks	I-Method
include	O
:	O
reduced	O
transparency	O
and	O
discriminativeness	O
of	O
the	O
features	O
learned	O
at	O
hidden	O
layers	O
;	O
training	O
difficulty	O
due	O
to	O
exploding	O
and	O
vanishing	O
gradients	O
;	O
lack	O
of	O
a	O
thorough	O
mathematical	O
understanding	O
about	O
the	O
algorithmic	O
behavior	O
,	O
despite	O
of	O
some	O
attempts	O
made	O
on	O
the	O
theoretical	O
side	O
;	O
dependence	O
on	O
the	O
availability	O
of	O
large	O
amount	O
of	O
training	O
data	O
;	O
complexity	O
of	O
manual	B-Method
tuning	I-Method
during	O
training	B-Task
.	O
	
Nevertheless	O
,	O
DL	B-Method
is	O
capable	O
of	O
automatically	O
learning	O
and	O
fusing	O
rich	O
hierarchical	B-Method
features	O
in	O
an	O
integrated	B-Method
framework	I-Method
.	O
	
Recent	O
activities	O
in	O
open	B-Task
-	I-Task
sourcing	I-Task
and	O
experience	B-Task
sharing	I-Task
have	O
also	O
greatly	O
helped	O
the	O
adopting	O
and	O
advancing	O
of	O
DL	B-Method
in	O
the	O
machine	B-Task
learning	I-Task
community	I-Task
and	O
beyond	O
.	O
	
Several	O
techniques	O
,	O
such	O
as	O
dropout	B-Method
,	O
dropconnect	B-Method
,	O
pre	B-Method
-	I-Method
training	I-Method
,	O
and	O
data	B-Method
augmentation	I-Method
,	O
have	O
been	O
proposed	O
to	O
enhance	O
the	O
performance	O
of	O
DL	B-Method
from	O
various	O
angles	O
,	O
in	O
addition	O
to	O
a	O
variety	O
of	O
engineering	B-Method
tricks	I-Method
used	O
to	O
fine	O
-	O
tune	O
feature	O
scale	O
,	O
step	O
size	O
,	O
and	O
convergence	B-Metric
rate	I-Metric
.	O
	
Features	O
learned	O
automatically	O
by	O
the	O
CNN	B-Method
algorithm	I-Method
are	O
intuitive	O
.	O
	
Some	O
portion	O
of	O
features	O
,	O
especially	O
for	O
those	O
in	O
the	O
early	O
layers	O
,	O
also	O
demonstrate	O
certain	O
degree	O
of	O
opacity	O
.	O
	
This	O
finding	O
is	O
also	O
consistent	O
with	O
an	O
observation	O
that	O
different	O
initializations	O
of	O
the	O
feature	B-Method
learning	I-Method
at	O
the	O
early	O
layers	O
make	O
negligible	O
difference	O
to	O
the	O
final	O
classification	B-Task
.	O
	
In	O
addition	O
,	O
the	O
presence	O
of	O
vanishing	O
gradients	O
also	O
makes	O
the	O
DL	B-Method
training	I-Method
slow	O
and	O
ineffective	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
address	O
the	O
feature	B-Task
learning	I-Task
problem	I-Task
in	O
DL	B-Method
by	O
presenting	O
a	O
new	O
algorithm	O
,	O
deeply	B-Method
-	I-Method
supervised	I-Method
nets	I-Method
(	O
DSN	B-Method
)	O
,	O
which	O
enforces	O
direct	O
and	O
early	O
supervision	O
for	O
both	O
the	O
hidden	O
layers	O
and	O
the	O
output	O
layer	O
.	O
	
We	O
introduce	O
companion	O
objective	O
to	O
the	O
individual	O
hidden	O
layers	O
,	O
which	O
is	O
used	O
as	O
an	O
additional	O
constraint	O
(	O
or	O
a	O
new	O
regularization	O
)	O
to	O
the	O
learning	B-Method
process	I-Method
.	O
	
Our	O
new	O
formulation	O
significantly	O
enhances	O
the	O
performance	O
of	O
existing	O
supervised	B-Method
DL	I-Method
methods	I-Method
.	O
	
We	O
also	O
make	O
an	O
attempt	O
to	O
provide	O
justification	O
for	O
our	O
formulation	O
using	O
stochastic	B-Method
gradient	I-Method
techniques	I-Method
.	O
	
We	O
show	O
an	O
improvement	O
of	O
the	O
convergence	B-Metric
rate	I-Metric
of	O
the	O
proposed	O
method	O
over	O
standard	O
ones	O
,	O
assuming	O
local	O
strong	O
convexity	O
of	O
the	O
optimization	O
function	O
(	O
a	O
very	O
loose	O
assumption	O
but	O
pointing	O
to	O
a	O
promising	O
direction	O
)	O
.	O
	
Several	O
existing	O
approaches	O
are	O
particularly	O
worth	O
mentioning	O
and	O
comparing	O
with	O
.	O
	
In	O
,	O
layer	B-Method
-	I-Method
wise	I-Method
supervised	I-Method
pre	I-Method
-	I-Method
training	I-Method
is	O
performed	O
.	O
	
Our	O
proposed	O
method	O
does	O
not	O
perform	O
pre	B-Method
-	I-Method
training	I-Method
and	O
it	O
emphasizes	O
the	O
importance	O
of	O
minimizing	O
the	O
output	O
classification	B-Metric
error	I-Metric
while	O
reducing	O
the	O
prediction	B-Metric
error	I-Metric
of	O
each	O
individual	O
layer	O
.	O
	
This	O
is	O
important	O
as	O
the	O
backpropagation	B-Method
is	O
performed	O
altogether	O
in	O
an	O
integrated	B-Method
framework	I-Method
.	O
	
In	O
,	O
label	O
information	O
is	O
used	O
for	O
unsupervised	B-Task
learning	I-Task
.	O
	
Semi	B-Task
-	I-Task
supervised	I-Task
learning	I-Task
is	O
carried	O
in	O
deep	B-Method
learning	I-Method
.	O
	
In	O
,	O
an	O
SVM	B-Method
classifier	I-Method
is	O
used	O
for	O
the	O
output	O
layer	O
,	O
instead	O
of	O
the	O
standard	O
softmax	O
function	O
in	O
the	O
CNN	B-Method
.	O
	
Our	O
framework	O
(	O
DSN	B-Method
)	O
,	O
with	O
the	O
choice	O
of	O
using	O
SVM	B-Method
,	O
softmax	O
or	O
other	O
classifiers	B-Method
,	O
emphasizes	O
the	O
direct	O
supervision	O
of	O
each	O
intermediate	O
layer	O
.	O
	
In	O
the	O
experiments	O
,	O
we	O
show	O
consistent	O
improvement	O
of	O
DSN	B-Method
-	O
SVM	O
and	O
DSN	B-Method
-	O
Softmax	O
over	O
CNN	B-Method
-	I-Method
SVM	I-Method
and	O
CNN	B-Method
-	I-Method
Softmax	I-Method
respectively	O
.	O
	
We	O
observe	O
all	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
MNIST	B-Material
,	O
CIFAR	B-Material
-	I-Material
10	I-Material
,	O
CIFAR	B-Material
-	I-Material
100	I-Material
,	O
and	O
SVHN	B-Material
.	O
	
It	O
is	O
also	O
worth	O
mentioning	O
that	O
our	O
formulation	O
is	O
inclusive	O
to	O
various	O
techniques	O
proposed	O
recently	O
such	O
as	O
averaging	B-Method
,	O
dropconnect	B-Method
,	O
and	O
Maxout	B-Method
.	O
	
We	O
expect	O
to	O
see	O
more	O
classification	B-Metric
error	I-Metric
reduction	O
with	O
careful	O
engineering	O
for	O
DSN	B-Method
.	O
	
section	O
:	O
Deeply	B-Method
-	I-Method
Supervised	I-Method
Nets	I-Method
	
In	O
this	O
section	O
,	O
we	O
give	O
the	O
main	O
formulation	O
of	O
the	O
proposed	O
deeply	B-Method
-	I-Method
supervised	I-Method
nets	I-Method
(	O
DSN	B-Method
)	O
.	O
	
We	O
focus	O
on	O
building	O
our	O
infrastructure	O
around	O
supervised	B-Method
CNN	I-Method
style	I-Method
frameworks	I-Method
by	O
introducing	O
classifier	B-Method
,	O
e.g.	O
SVM	B-Method
model	I-Method
,	O
to	O
each	O
layer	O
.	O
	
An	O
early	O
attempt	O
to	O
combine	O
SVM	B-Method
with	O
DL	B-Method
was	O
made	O
in	O
,	O
which	O
however	O
has	O
a	O
different	O
motivation	O
with	O
ours	O
and	O
only	O
studies	O
the	O
output	O
layer	O
with	O
some	O
preliminary	O
experimental	O
results	O
.	O
	
subsection	O
:	O
Motivation	O
	
We	O
are	O
motivated	O
by	O
the	O
following	O
simple	O
observation	O
:	O
in	O
general	O
,	O
a	O
discriminative	B-Method
classifier	I-Method
trained	O
on	O
highly	O
discriminative	O
features	O
will	O
display	O
better	O
performance	O
than	O
a	O
discriminative	B-Method
classifier	I-Method
trained	O
on	O
less	O
discriminative	O
features	O
.	O
	
If	O
the	O
features	O
in	O
question	O
are	O
the	O
hidden	O
layer	O
feature	O
maps	O
of	O
a	O
deep	B-Method
network	I-Method
,	O
this	O
observation	O
means	O
that	O
the	O
performance	O
of	O
a	O
discriminative	B-Method
classifier	I-Method
trained	O
using	O
these	O
hidden	O
layer	O
feature	O
maps	O
can	O
serve	O
as	O
a	O
proxy	O
for	O
the	O
quality	O
/	O
discriminativeness	O
of	O
those	O
hidden	O
layer	O
feature	O
maps	O
,	O
and	O
further	O
to	O
the	O
quality	O
of	O
the	O
upper	O
layer	O
feature	O
maps	O
.	O
	
By	O
making	O
appropriate	O
use	O
of	O
this	O
feature	O
quality	O
feedback	O
at	O
each	O
hidden	O
layer	O
of	O
the	O
network	O
,	O
we	O
are	O
able	O
to	O
directly	O
influence	O
the	O
hidden	B-Method
layer	I-Method
weight	I-Method
/	I-Method
filter	I-Method
update	I-Method
process	I-Method
to	O
favor	O
highly	O
discriminative	O
feature	O
maps	O
.	O
	
This	O
is	O
a	O
source	O
of	O
supervision	O
that	O
acts	O
deep	O
within	O
the	O
network	O
at	O
each	O
layer	O
;	O
when	O
our	O
proxy	O
for	O
feature	B-Metric
quality	I-Metric
is	O
good	O
,	O
we	O
expect	O
to	O
much	O
more	O
rapidly	O
approach	O
the	O
region	O
of	O
good	O
features	O
than	O
would	O
be	O
the	O
case	O
if	O
we	O
had	O
to	O
rely	O
on	O
the	O
gradual	B-Method
backpropagation	I-Method
from	O
the	O
output	B-Method
layer	I-Method
alone	O
.	O
	
We	O
also	O
expect	O
to	O
alleviate	O
the	O
common	O
problem	O
of	O
having	O
gradients	O
that	O
“	O
explode	O
”	O
or	O
“	O
vanish	O
”	O
.	O
	
One	O
concern	O
with	O
a	O
direct	O
pursuit	O
of	O
feature	O
discriminativeness	O
at	O
all	O
hidden	O
layers	O
is	O
that	O
this	O
might	O
interfere	O
with	O
the	O
overall	O
network	O
performance	O
,	O
since	O
it	O
is	O
ultimately	O
the	O
feature	O
maps	O
at	O
the	O
output	O
layer	O
which	O
are	O
used	O
for	O
the	O
final	O
classification	B-Task
;	O
our	O
experimental	O
results	O
indicate	O
that	O
this	O
is	O
not	O
the	O
case	O
.	O
	
Our	O
basic	O
network	B-Method
architecture	I-Method
will	O
be	O
similar	O
to	O
the	O
standard	O
one	O
used	O
in	O
the	O
CNN	B-Method
framework	I-Method
.	O
	
Our	O
additional	O
deep	O
feedback	O
is	O
brought	O
in	O
by	O
associating	O
a	O
companion	O
local	O
output	O
with	O
each	O
hidden	B-Method
layer	I-Method
.	O
	
We	O
may	O
think	O
of	O
this	O
companion	O
local	O
output	O
as	O
analogous	O
to	O
the	O
final	O
output	O
that	O
a	O
truncated	B-Method
network	I-Method
would	O
have	O
produced	O
.	O
	
Backpropagation	O
of	O
error	B-Metric
now	O
proceeds	O
as	O
usual	O
,	O
with	O
the	O
crucial	O
difference	O
that	O
we	O
now	O
backpropagate	O
not	O
only	O
from	O
the	O
final	O
layer	O
but	O
also	O
simultaneously	O
from	O
our	O
local	O
companion	O
output	O
.	O
	
The	O
empirical	O
result	O
suggests	O
the	O
following	O
main	O
properties	O
of	O
the	O
companion	B-Method
objective	I-Method
:	O
(	O
1	O
)	O
it	O
acts	O
as	O
a	O
kind	O
of	O
feature	B-Method
regularization	I-Method
(	O
although	O
an	O
unusual	O
one	O
)	O
,	O
which	O
leads	O
to	O
significant	O
reduction	O
to	O
the	O
testing	B-Metric
error	I-Metric
but	O
not	O
necessarily	O
to	O
the	O
train	B-Metric
error	I-Metric
;	O
(	O
2	O
)	O
it	O
results	O
in	O
faster	O
convergence	B-Metric
,	O
especially	O
in	O
presence	O
of	O
small	O
training	O
data	O
(	O
see	O
Figure	O
(	O
[	O
reference	O
]	O
)	O
for	O
an	O
illustration	O
on	O
a	O
running	O
example	O
)	O
.	O
	
subsection	O
:	O
Formulation	O
	
We	O
focus	O
on	O
the	O
supervised	B-Task
learning	I-Task
case	I-Task
and	O
let	O
be	O
our	O
set	O
of	O
input	O
training	O
data	O
where	O
sample	O
denotes	O
the	O
raw	O
input	O
data	O
and	O
is	O
the	O
corresponding	O
groundtruth	O
label	O
for	O
sample	O
.	O
	
We	O
drop	O
for	O
notational	O
simplicity	O
,	O
since	O
each	O
sample	O
is	O
considered	O
independently	O
.	O
	
The	O
goal	O
of	O
deep	B-Method
nets	I-Method
,	O
specifically	O
convolutional	B-Method
neural	I-Method
networks	I-Method
(	I-Method
CNN	I-Method
)	I-Method
,	O
is	O
to	O
learn	O
layers	O
of	O
filters	O
and	O
weights	O
for	O
the	O
minimization	O
of	O
classification	B-Metric
error	I-Metric
at	O
the	O
output	O
layer	O
.	O
	
Here	O
,	O
we	O
absorb	O
the	O
bias	O
term	O
into	O
the	O
weight	O
parameters	O
and	O
do	O
not	O
differentiate	O
weights	O
from	O
filters	O
and	O
denote	O
a	O
recursive	B-Method
function	I-Method
for	O
each	O
layer	O
as	O
:	O
	
denotes	O
the	O
total	O
number	O
of	O
layers	O
;	O
are	O
the	O
filters	O
/	O
weights	O
to	O
be	O
learned	O
;	O
is	O
the	O
feature	O
map	O
produced	O
at	O
layer	O
;	O
refers	O
to	O
the	O
convolved	O
/	O
filtered	O
responses	O
on	O
the	O
previous	O
feature	O
map	O
;	O
is	O
a	O
pooling	O
function	O
on	O
;	O
Combining	O
all	O
layers	O
of	O
weights	O
gives	O
Now	O
we	O
introduce	O
a	O
set	O
of	O
classifiers	B-Method
,	O
e.g.	O
SVM	B-Method
(	O
other	O
classifiers	O
like	O
Softmax	B-Method
can	O
be	O
applied	O
and	O
we	O
will	O
show	O
results	O
using	O
both	O
SVM	B-Method
and	O
Softmax	B-Method
in	O
the	O
experiments	O
)	O
,	O
one	O
for	O
each	O
hidden	O
layer	O
,	O
in	O
addition	O
to	O
the	O
in	O
the	O
standard	O
CNN	B-Method
framework	I-Method
.	O
	
We	O
denote	O
the	O
as	O
the	O
SVM	O
weights	O
for	O
the	O
output	O
layer	O
.	O
	
Thus	O
,	O
we	O
build	O
our	O
overall	O
combined	B-Metric
objective	I-Metric
function	I-Metric
as	O
:	O
where	O
and	O
We	O
name	O
as	O
the	O
overall	B-Metric
loss	I-Metric
(	O
output	O
layer	O
)	O
and	O
as	O
the	O
companion	O
loss	O
(	O
hidden	O
layers	O
)	O
,	O
which	O
are	O
both	O
squared	O
hinge	O
losses	O
of	O
the	O
prediction	O
errors	O
.	O
	
The	O
above	O
formulation	O
can	O
be	O
understood	O
intuitively	O
:	O
in	O
addition	O
to	O
learning	O
convolution	O
kernels	O
and	O
weights	O
,	O
,	O
as	O
in	O
the	O
standard	O
CNN	B-Method
model	I-Method
,	O
enforcing	O
a	O
constraint	O
at	O
each	O
hidden	O
layer	O
for	O
directly	O
making	O
a	O
good	O
label	B-Task
prediction	I-Task
gives	O
a	O
strong	O
push	O
for	O
having	O
discriminative	O
and	O
sensible	O
features	O
at	O
each	O
individual	O
layer	O
.	O
	
In	O
eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
,	O
and	O
are	O
respectively	O
the	O
margin	O
and	O
squared	O
hinge	O
loss	O
of	O
the	O
SVM	B-Method
classifier	I-Method
(	O
L2SVM	B-Method
)	O
at	O
the	O
output	O
layer	O
(	O
we	O
omit	O
the	O
balance	O
term	O
in	O
front	O
of	O
the	O
hinge	O
for	O
notational	O
simplicity	O
)	O
;	O
in	O
eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
,	O
and	O
are	O
respectively	O
the	O
margin	O
and	O
squared	O
hinge	O
loss	O
of	O
the	O
SVM	B-Method
classifier	I-Method
at	O
each	O
hidden	O
layer	O
.	O
	
Note	O
that	O
for	O
each	O
,	O
the	O
directly	O
depends	O
on	O
,	O
which	O
is	O
dependent	O
on	O
up	O
to	O
the	O
th	O
layer	O
.	O
	
depends	O
on	O
,	O
which	O
is	O
decided	O
by	O
the	O
entire	O
.	O
	
The	O
second	O
term	O
in	O
eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
often	O
goes	O
to	O
zero	O
during	O
the	O
course	O
of	O
training	O
;	O
this	O
way	O
,	O
the	O
overall	O
goal	O
of	O
producing	O
good	O
classification	B-Metric
of	O
the	O
output	O
layer	O
is	O
not	O
altered	O
and	O
the	O
companion	O
objective	O
just	O
acts	O
as	O
a	O
proxy	O
or	O
regularization	O
.	O
	
This	O
is	O
achieved	O
by	O
having	O
as	O
a	O
threshold	O
(	O
a	O
hyper	O
parameter	O
)	O
in	O
the	O
second	O
term	O
of	O
eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
with	O
a	O
hinge	O
loss	O
:	O
once	O
the	O
overall	O
value	O
of	O
the	O
hidden	O
layer	O
reaches	O
or	O
is	O
below	O
,	O
it	O
vanishes	O
and	O
no	O
longer	O
plays	O
role	O
in	O
the	O
learning	B-Task
process	I-Task
.	O
	
balances	O
the	O
importance	O
of	O
the	O
error	B-Metric
in	O
the	O
output	B-Metric
objective	I-Metric
and	O
the	O
companion	B-Metric
objective	I-Metric
.	O
	
In	O
addition	O
,	O
we	O
could	O
use	O
a	O
simple	O
decay	O
function	O
as	O
to	O
enforce	O
the	O
second	O
term	O
to	O
vanish	O
after	O
certain	O
number	O
of	O
iterations	O
,	O
where	O
is	O
the	O
epoch	O
step	O
and	O
is	O
the	O
total	O
number	O
of	O
epochs	O
(	O
wheather	O
or	O
not	O
to	O
have	O
the	O
decay	O
on	O
might	O
vary	O
in	O
different	O
experiments	O
although	O
the	O
differences	O
may	O
not	O
be	O
very	O
big	O
)	O
.	O
	
To	O
summarize	O
,	O
we	O
describe	O
this	O
optimization	B-Task
problem	I-Task
as	O
follows	O
:	O
we	O
want	O
to	O
learn	O
filters	O
/	O
weights	O
for	O
the	O
entire	O
network	O
such	O
that	O
an	O
SVM	B-Method
classifier	I-Method
trained	O
on	O
the	O
output	O
feature	O
maps	O
(	O
that	O
depend	O
on	O
those	O
filters	O
/	O
features	O
)	O
will	O
display	O
good	O
performance	O
.	O
	
We	O
seek	O
this	O
output	O
performance	O
while	O
also	O
requiring	O
some	O
“	O
satisfactory	O
”	O
level	O
of	O
performance	O
on	O
the	O
part	O
of	O
the	O
hidden	B-Method
layer	I-Method
classifiers	I-Method
.	O
	
We	O
are	O
saying	O
:	O
restrict	O
attention	O
to	O
the	O
parts	O
of	O
feature	O
space	O
that	O
,	O
when	O
considered	O
at	O
the	O
internal	O
layers	O
,	O
lead	O
to	O
highly	O
discriminative	O
hidden	O
layer	O
feature	O
maps	O
(	O
as	O
measured	O
via	O
our	O
proxy	O
of	O
hidden	B-Method
-	I-Method
layer	I-Method
classifier	I-Method
performance	O
)	O
.	O
	
The	O
main	O
difference	O
between	O
eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
and	O
previous	O
attempts	O
in	O
layer	B-Task
-	I-Task
wise	I-Task
supervised	I-Task
training	I-Task
is	O
that	O
we	O
perform	O
the	O
optimization	B-Task
altogether	O
with	O
a	O
robust	B-Metric
measure	I-Metric
(	O
or	O
regularization	O
)	O
of	O
the	O
hidden	O
layer	O
.	O
	
For	O
example	O
,	O
greedy	B-Method
layer	I-Method
-	I-Method
wise	I-Method
pretraining	I-Method
was	O
performed	O
as	O
either	O
initialization	O
or	O
fine	B-Method
-	I-Method
tuning	I-Method
which	O
results	O
in	O
some	O
overfitting	O
.	O
	
The	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
benchmark	O
results	O
demonstrate	O
the	O
particular	O
advantage	O
of	O
our	O
formulation	O
.	O
	
As	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
(	O
c	O
)	O
,	O
indeed	O
both	O
CNN	B-Method
and	O
DSN	B-Method
reach	O
training	B-Metric
error	I-Metric
near	O
zero	O
but	O
DSN	B-Method
demonstrates	O
a	O
clear	O
advantage	O
of	O
having	O
a	O
better	O
generalization	B-Metric
capability	I-Metric
.	O
	
To	O
train	O
the	O
DSN	B-Method
model	O
using	O
SGD	B-Method
,	O
the	O
gradients	O
of	O
the	O
objective	O
function	O
w.r.t	O
the	O
parameters	O
in	O
the	O
model	O
are	O
:	O
The	O
gradient	O
w.r.t	O
just	O
follows	O
the	O
conventional	O
CNN	B-Method
based	I-Method
model	I-Method
plus	O
the	O
gradient	O
that	O
directly	O
comes	O
from	O
the	O
hidden	O
layer	O
supervision	O
.	O
	
Next	O
,	O
we	O
provide	O
more	O
discussions	O
to	O
and	O
try	O
to	O
understand	O
intuitively	O
about	O
our	O
formulation	O
,	O
eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
	
For	O
ease	O
of	O
reference	O
,	O
we	O
write	O
this	O
objective	O
function	O
as	O
where	O
and	O
.	O
	
subsection	O
:	O
Stochastic	B-Method
Gradient	I-Method
Descent	I-Method
View	I-Method
	
We	O
focus	O
on	O
the	O
convergence	B-Metric
advantage	O
of	O
DSN	B-Method
,	O
instead	O
of	O
the	O
regularization	B-Method
to	O
the	O
generalization	B-Task
aspect	I-Task
.	O
	
In	O
addition	O
to	O
the	O
present	O
problem	O
in	O
CNN	B-Task
where	O
learned	O
features	O
are	O
not	O
always	O
intuitive	O
and	O
discriminative	O
,	O
the	O
difficulty	O
of	O
training	O
deep	B-Method
neural	I-Method
networks	I-Method
has	O
been	O
discussed	O
.	O
	
As	O
we	O
can	O
observe	O
from	O
eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
and	O
(	O
[	O
reference	O
]	O
)	O
	
,	O
the	O
change	O
of	O
the	O
bottom	O
layer	O
weights	O
get	O
propagated	O
through	O
layers	O
of	O
functions	O
,	O
leading	O
to	O
exploding	O
or	O
vanishing	O
gradients	O
.	O
	
Various	O
techniques	O
and	O
parameter	B-Method
tuning	I-Method
tricks	I-Method
have	O
been	O
proposed	O
to	O
better	O
train	O
deep	B-Method
neural	I-Method
networks	I-Method
,	O
such	O
as	O
pre	B-Method
-	I-Method
training	I-Method
and	O
dropout	B-Method
.	O
	
Here	O
we	O
provide	O
a	O
somewhat	O
loose	O
analysis	O
to	O
our	O
proposed	O
formulation	O
,	O
in	O
a	O
hope	O
to	O
understand	O
its	O
advantage	O
in	O
effectiveness	O
.	O
	
The	O
objective	O
function	O
in	O
deep	B-Method
neural	I-Method
networks	I-Method
is	O
highly	O
non	O
-	O
convex	O
.	O
	
Here	O
we	O
make	O
the	O
following	O
assumptions	O
/	O
observations	O
:	O
(	O
1	O
)	O
the	O
objective	B-Method
/	I-Method
energy	I-Method
function	I-Method
of	O
DL	B-Method
observes	O
a	O
large	O
“	O
flat	O
”	O
area	O
around	O
the	O
“	O
optimal	O
”	O
solution	O
where	O
any	O
result	O
has	O
a	O
similar	O
performance	O
;	O
locally	O
we	O
still	O
assume	O
a	O
convex	O
(	O
or	O
even	O
-	O
strongly	O
convex	O
)	O
function	O
whose	O
optimization	B-Task
is	O
often	O
performed	O
with	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
algorithm	I-Method
.	O
	
The	O
definition	O
of	O
-	O
strongly	O
convex	O
is	O
standard	O
:	O
A	O
function	O
is	O
-	O
strongly	O
convex	O
if	O
and	O
any	O
subgradient	O
at	O
,	O
and	O
the	O
update	B-Method
rule	I-Method
in	O
Stochastic	B-Method
Gradient	I-Method
Descent	I-Method
(	O
SGD	B-Method
)	O
at	O
step	O
is	O
,	O
where	O
refers	O
to	O
the	O
step	O
rate	O
and	O
helps	O
to	O
project	O
onto	O
the	O
space	O
of	O
.	O
	
Let	O
be	O
the	O
optimum	O
solution	O
,	O
upper	O
bounds	O
for	O
and	O
in	O
for	O
the	O
strongly	O
convex	O
function	O
,	O
and	O
for	O
convex	O
function	O
in	O
.	O
	
Here	O
we	O
make	O
an	O
attempt	O
to	O
understand	O
the	O
convergence	O
of	O
eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
	
w.r.t	O
.	O
	
,	O
due	O
to	O
the	O
presence	O
of	O
large	O
area	O
of	O
flat	O
function	O
shown	O
in	O
Figure	O
(	O
[	O
reference	O
]	O
.b	O
)	O
.	O
	
In	O
,	O
a	O
convergence	B-Metric
rate	I-Metric
is	O
given	O
for	O
the	O
M	B-Method
-	I-Method
estimators	I-Method
with	O
locally	B-Method
convex	I-Method
function	I-Method
with	O
compositional	O
loss	O
and	O
regularization	O
terms	O
.	O
	
Both	O
terms	O
in	O
eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
here	O
refer	O
to	O
the	O
same	O
class	O
label	O
prediction	B-Metric
error	I-Metric
,	O
a	O
reason	O
for	O
calling	O
the	O
second	O
term	O
as	O
companion	O
objective	O
.	O
	
Our	O
motivation	O
is	O
two	O
-	O
fold	O
:	O
(	O
1	O
)	O
encourage	O
the	O
features	O
learned	O
at	O
each	O
layer	O
to	O
be	O
directly	O
discriminative	O
for	O
class	B-Task
label	I-Task
prediction	I-Task
,	O
while	O
keeping	O
the	O
ultimate	O
goal	O
of	O
minimizing	B-Task
class	I-Task
label	I-Task
prediction	I-Task
at	O
the	O
output	O
layer	O
;	O
(	O
2	O
)	O
alleviate	O
the	O
exploding	B-Task
and	I-Task
vanishing	I-Task
gradients	I-Task
problem	I-Task
as	O
each	O
layer	O
now	O
has	O
a	O
direct	O
supervision	O
from	O
the	O
ground	O
truth	O
labels	O
.	O
	
One	O
might	O
raise	O
a	O
concern	O
that	O
learning	O
highly	O
discriminative	O
intermediate	O
stage	O
filters	O
may	O
not	O
necessarily	O
lead	O
to	O
the	O
best	O
prediction	O
at	O
the	O
output	O
layer	O
.	O
	
An	O
illustration	O
can	O
been	O
seen	O
in	O
Figure	O
(	O
[	O
reference	O
]	O
.b	O
)	O
.	O
	
Next	O
,	O
we	O
give	O
a	O
loose	O
theoretical	O
analysis	O
to	O
our	O
framework	O
,	O
which	O
is	O
also	O
validated	O
by	O
comprehensive	O
experimental	O
studies	O
with	O
overwhelming	O
advantages	O
over	O
the	O
existing	O
methods	O
.	O
	
We	O
name	O
as	O
the	O
-	O
feasible	O
set	O
for	O
a	O
function	O
.	O
	
First	O
we	O
show	O
that	O
a	O
feasible	O
solution	O
for	O
leads	O
to	O
a	O
feasible	O
one	O
to	O
.	O
	
That	O
is	O
:	O
	
theorem	O
:	O
	
if	O
∥w	O
(	O
m	O
)	O
∥2	O
+	O
ℓ	O
((	O
^W	O
(	O
1	O
)	O
,	O
..	O
	
,	O
^W	O
(	O
m	O
)),	O
w	O
(	O
m	O
))	O
≤γ	O
then	O
there	O
exists	O
(	O
^W	O
(	O
1	O
)	O
,	O
..	O
	
,	O
^W	O
(	O
m	O
)	O
,	O
	
..	O
,	O
^W	O
(	O
m′	O
)	O
)	O
	
such	O
that	O
∥w	O
(	O
m′	O
)	O
∥2	O
+	O
ℓ	O
((	O
^W	O
(	O
1	O
)	O
,	O
..	O
	
,	O
^W	O
(	O
m	O
)	O
..	O
	
,	O
^W	O
(	O
m′	O
)),	O
w	O
(	O
m′	O
))	O
≤γ	O
.	O
	
Note	O
that	O
we	O
drop	O
the	O
>	O
W	O
(	O
j	O
),	O
jm	O
since	O
the	O
filters	O
above	O
layer	O
m	O
do	O
not	O
participate	O
in	O
the	O
computation	O
for	O
the	O
objective	O
function	O
of	O
this	O
layer	O
.	O
	
As	O
we	O
can	O
see	O
from	O
an	O
illustration	O
of	O
our	O
network	B-Method
architecture	I-Method
shown	O
in	O
fig	O
.	O
	
(	O
[	O
reference	O
]	O
.a	O
)	O
,	O
for	O
such	O
that	O
.	O
	
Then	O
there	O
is	O
a	O
trivial	O
solution	O
for	O
the	O
network	O
for	O
every	O
layer	O
up	O
to	O
,	O
we	O
let	O
and	O
,	O
meaning	O
that	O
the	O
filters	O
will	O
be	O
identity	O
matrices	O
.	O
	
This	O
results	O
in	O
.	O
	
Lemma	O
[	O
reference	O
]	O
shows	O
that	O
a	O
good	O
solution	O
for	O
is	O
also	O
a	O
good	O
one	O
for	O
,	O
but	O
it	O
may	O
not	O
be	O
the	O
case	O
the	O
other	O
way	O
around	O
.	O
	
That	O
is	O
:	O
a	O
that	O
makes	O
small	O
may	O
not	O
necessarily	O
produce	O
discriminative	O
features	O
for	O
the	O
hidden	O
layers	O
to	O
have	O
a	O
small	O
.	O
	
However	O
,	O
can	O
be	O
viewed	O
as	O
a	O
regularization	B-Method
term	I-Method
.	O
	
Since	O
observes	O
a	O
very	O
flat	O
area	O
near	O
even	O
zero	O
on	O
the	O
training	O
data	O
and	O
it	O
is	O
ultimately	O
the	O
test	B-Metric
error	I-Metric
that	O
we	O
really	O
care	O
about	O
,	O
we	O
thus	O
only	O
focus	O
on	O
the	O
,	O
,	O
which	O
makes	O
both	O
and	O
small	O
.	O
	
Therefore	O
,	O
it	O
is	O
not	O
unreasonable	O
to	O
assume	O
that	O
and	O
share	O
the	O
same	O
optimal	O
.	O
	
Let	O
and	O
be	O
strongly	O
convex	O
around	O
,	O
and	O
,	O
with	O
and	O
,	O
where	O
and	O
are	O
the	O
subgradients	O
for	O
and	O
at	O
respectively	O
.	O
	
It	O
can	O
be	O
directly	O
seen	O
that	O
is	O
also	O
strongly	O
convex	O
and	O
for	O
subgradient	O
of	O
at	O
,	O
.	O
	
theorem	O
:	O
	
Suppose	O
≤⁢E	O
[	O
∥^gpt∥2	O
]	O
G2	O
and	O
≤⁢E	O
[	O
∥^gqt∥2	O
]	O
G2	O
,	O
and	O
we	O
use	O
the	O
update	O
rule	O
of	O
=	O
W	O
+	O
t1⁢ΠW	O
(-	O
Wt⁢ηt	O
(+	O
^gpt^gqt	O
)	O
)	O
where	O
=	O
⁢E	O
[	O
^gpt	O
]	O
gpt	O
and	O
=	O
⁢E	O
[	O
^gqt	O
]	O
gqt	O
.	O
	
If	O
we	O
use	O
=	O
ηt⁢	O
/	O
1	O
(+	O
λ1λ2	O
)	O
t	O
,	O
then	O
at	O
time	O
stamp	O
	
T	O
Since	O
,	O
it	O
can	O
be	O
directly	O
seen	O
that	O
Based	O
on	O
lemma	O
1	O
in	O
,	O
this	O
upper	O
bound	O
directly	O
holds	O
.	O
	
theorem	O
:	O
	
Following	O
the	O
assumptions	O
in	O
lemma	O
,	O
but	O
now	O
we	O
assume	O
=	O
	
ηt	O
/	O
1	O
t	O
since	O
λ1	O
and	O
λ2	O
are	O
not	O
always	O
readily	O
available	O
,	O
then	O
started	O
from	O
≤∥	O
-	O
W1W⋆∥2D	O
the	O
convergence	B-Metric
rate	I-Metric
is	O
bounded	O
by	O
Let	O
,	O
we	O
have	O
	
Thus	O
,	O
Therefore	O
,	O
with	O
,	O
With	O
being	O
small	O
,	O
we	O
have	O
	
theorem	O
:	O
	
Let	O
⁢P	O
(	O
W	O
)	O
be	O
λ1	O
-	O
strongly	O
convex	O
and	O
⁢Q	O
(	O
W	O
)	O
be	O
λ2	O
-	O
strongly	O
convex	O
near	O
optimal	O
W⋆	O
and	O
denote	O
WT	B-Method
(	I-Method
F	I-Method
)	I-Method
and	O
WT	B-Method
(	I-Method
P	I-Method
)	I-Method
as	O
the	O
solution	O
after	O
T	O
iterations	O
when	O
applying	O
SGD	B-Method
on	O
⁢F	O
(	O
W	O
)	O
and	O
⁢P	O
(	O
W	O
)	O
respectively	O
.	O
	
Then	O
our	O
deeply	B-Method
supervised	I-Method
framework	I-Method
in	O
eqn	O
.	O
	
(	O
)	O
improves	O
the	O
the	O
speed	O
over	O
using	O
top	O
layer	O
only	O
by	O
=	O
	
⁢E	O
[	O
∥	O
-	O
WT	O
(	O
P	O
)	O
W⋆∥2	O
]	O
⁢E	O
[	O
∥	O
-	O
WT	O
(	O
F	O
)	O
W⋆∥2	O
]	O
⁢Θ	O
(+	O
1λ22λ12	O
),	O
=⁢whenηt⁢	O
/	O
1λt	O
,	O
⁢and	O
=	O
	
⁢E	O
[	O
∥	O
-	O
WT	O
(	O
P	O
)	O
W⋆∥2	O
]	O
⁢E	O
[	O
∥	O
-	O
WT	O
(	O
F	O
)	O
W⋆∥2	O
]	O
⁢Θ	O
(	O
e⁢ln	O
(	O
T	O
)	O
λ2	O
),	O
=⁢whenηt	O
/	O
1	O
t	O
Lemma	O
[	O
reference	O
]	O
shows	O
the	O
compatibility	O
of	O
the	O
companion	O
objective	O
of	O
w.r.t	O
the	O
output	B-Metric
objective	I-Metric
.	O
	
The	O
first	O
equation	O
can	O
be	O
directly	O
derived	O
from	O
lemma	O
[	O
reference	O
]	O
and	O
the	O
second	O
equation	O
can	O
be	O
seen	O
from	O
lemma	O
[	O
reference	O
]	O
.	O
	
In	O
general	O
which	O
leads	O
to	O
a	O
great	O
improvement	O
in	O
convergence	B-Metric
speed	I-Metric
and	O
the	O
constraints	O
in	O
each	O
hidden	O
layer	O
also	O
helps	O
to	O
learning	O
filters	O
which	O
are	O
directly	O
discriminative	O
.	O
	
section	O
:	O
Experiments	O
	
We	O
evaluate	O
the	O
proposed	O
DSN	B-Method
method	O
on	O
four	O
standard	O
benchmark	O
datasets	O
:	O
MNIST	B-Material
,	O
CIFAR	B-Material
-	I-Material
10	I-Material
,	O
CIFAR	B-Material
-	I-Material
100	I-Material
and	O
SVHN	B-Material
.	O
	
We	O
follow	O
a	O
common	O
training	O
protocol	O
used	O
by	O
Krizhevsky	O
et	O
al	O
.	O
in	O
all	O
experiments	O
.	O
	
We	O
use	O
SGD	B-Method
solver	I-Method
with	O
mini	O
-	O
batch	O
size	O
of	O
at	O
a	O
fixed	O
constant	O
momentum	O
value	O
of	O
.	O
	
Initial	O
value	O
for	O
learning	B-Metric
rate	I-Metric
and	O
weight	B-Metric
decay	I-Metric
factor	I-Metric
is	O
determined	O
based	O
on	O
the	O
validation	O
set	O
.	O
	
For	O
a	O
fair	O
comparison	O
and	O
clear	O
illustration	O
of	O
the	O
effectiveness	O
of	O
DSN	B-Method
,	O
we	O
match	O
the	O
complexity	B-Metric
of	O
our	O
model	O
with	O
that	O
in	O
network	B-Method
architectures	I-Method
used	O
in	O
and	O
to	O
have	O
a	O
comparable	O
number	O
of	O
parameters	O
.	O
	
We	O
also	O
incorporate	O
two	O
dropout	B-Method
layers	I-Method
with	O
dropout	O
rate	O
at	O
.	O
	
Companion	O
objective	O
at	O
the	O
convolutional	B-Method
layers	I-Method
is	O
imposed	O
to	O
backpropagate	O
the	O
classification	B-Metric
error	I-Metric
guidance	O
to	O
the	O
underlying	O
convolutional	B-Method
layers	I-Method
.	O
	
Learning	B-Metric
rates	I-Metric
are	O
annealed	O
during	O
training	O
by	O
a	O
factor	O
of	O
according	O
to	O
an	O
epoch	O
schedule	O
determined	O
on	O
the	O
validation	O
set	O
.	O
	
The	O
proposed	O
DSN	B-Method
framework	O
is	O
not	O
difficult	O
to	O
train	O
and	O
there	O
are	O
no	O
particular	O
engineering	O
tricks	O
adopted	O
.	O
	
Our	O
system	O
is	O
built	O
on	O
top	O
of	O
widely	O
used	O
Caffe	B-Method
infrastructure	I-Method
.	O
	
For	O
the	O
network	B-Method
architecture	I-Method
setup	O
,	O
we	O
adopted	O
the	O
mlpconv	B-Method
layer	I-Method
and	O
global	B-Method
averaged	I-Method
pooling	I-Method
scheme	I-Method
introduced	O
in	O
.	O
	
DSN	B-Method
can	O
be	O
equipped	O
with	O
different	O
types	O
of	O
loss	O
functions	O
,	O
such	O
as	O
Softmax	B-Method
and	O
SVM	B-Method
.	O
	
We	O
show	O
performance	O
boost	O
of	O
DSN	B-Method
-	O
SVM	O
and	O
DSN	B-Method
-	O
Softmax	O
over	O
CNN	B-Method
-	I-Method
SVM	I-Method
and	O
CNN	B-Method
-	I-Method
Softmax	I-Method
respectively	O
(	O
see	O
Figure	O
(	O
[	O
reference	O
]	O
.a	O
)	O
)	O
.	O
	
The	O
performance	O
gain	O
is	O
more	O
evident	O
in	O
presence	O
of	O
small	O
training	O
data	O
(	O
see	O
Figure	O
(	O
[	O
reference	O
]	O
.b	O
)	O
)	O
;	O
this	O
might	O
partially	O
ease	O
the	O
burden	O
of	O
requiring	O
large	O
training	O
data	O
for	O
DL	B-Method
.	O
	
Overall	O
,	O
we	O
observe	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
classification	B-Metric
error	I-Metric
in	O
all	O
four	O
datasets	O
(	O
without	O
data	O
augmentation	O
)	O
,	O
for	O
MINIST	B-Material
,	O
for	O
CIFAR	B-Material
-	I-Material
10	I-Material
,	O
for	O
CIFAR	B-Material
-	I-Material
100	I-Material
,	O
and	O
for	O
SVHN	B-Material
(	O
for	O
CIFAR	B-Material
-	I-Material
10	I-Material
with	O
data	B-Method
augmentation	I-Method
)	O
.	O
	
All	O
results	O
are	O
achieved	O
without	O
using	O
averaging	B-Method
,	O
which	O
is	O
not	O
exclusive	O
to	O
our	O
method	O
.	O
	
Figure	O
(	O
[	O
reference	O
]	O
)	O
gives	O
an	O
illustration	O
of	O
some	O
learned	O
features	O
.	O
	
subsection	O
:	O
MNIST	B-Material
	
We	O
first	O
validate	O
the	O
effectiveness	O
of	O
the	O
proposed	O
DSN	B-Method
on	O
the	O
MNIST	B-Material
handwritten	O
digits	O
classification	O
task	O
,	O
a	O
widely	O
and	O
extensively	O
adopted	O
benchmark	O
in	O
machine	B-Method
learning	I-Method
.	O
	
MNIST	B-Material
dataset	O
consists	O
of	O
images	O
of	O
10	O
different	O
classes	O
(	O
0	O
to	O
9	O
)	O
of	O
size	O
with	O
60	O
,	O
000	O
training	O
samples	O
and	O
10	O
,	O
000	O
test	O
samples	O
.	O
	
Figure	O
[	O
reference	O
]	O
(	O
a	O
)	O
and	O
(	O
b	O
)	O
show	O
results	O
from	O
four	O
methods	O
,	O
namely	O
:	O
(	O
1	O
)	O
conventional	O
CNN	B-Method
with	I-Method
softmax	I-Method
loss	I-Method
(	O
CNN	B-Method
-	I-Method
Softmax	I-Method
)	O
,	O
	
(	O
2	O
)	O
the	O
proposed	O
DSN	B-Method
with	O
softmax	O
loss	O
(	O
DSN	B-Method
-	O
Softmax	O
)	O
,	O
(	O
3	O
)	O
CNN	B-Method
with	I-Method
max	I-Method
-	I-Method
margin	I-Method
objective	I-Method
(	O
CNN	B-Method
-	I-Method
SVM	I-Method
)	O
,	O
and	O
(	O
4	O
)	O
the	O
proposed	O
DSN	B-Method
with	O
max	B-Method
-	I-Method
margin	I-Method
objective	I-Method
(	O
DSN	B-Method
-	O
SVM	O
)	O
.	O
	
DSN	B-Method
-	O
Softmax	O
and	O
DSN	B-Method
-	O
SVM	O
outperform	O
both	O
their	O
competing	O
CNN	B-Method
algorithms	I-Method
	
(	O
DSN	B-Method
-	O
SVM	O
shows	O
classification	B-Metric
error	I-Metric
of	O
under	O
a	O
single	O
model	O
without	O
data	B-Method
whitening	I-Method
and	O
augmentation	B-Method
)	O
.	O
	
Figure	O
[	O
reference	O
]	O
(	O
b	O
)	O
shows	O
classification	B-Metric
error	I-Metric
of	O
the	O
competing	O
methods	O
	
when	O
trained	O
w.r.t	O
.	O
varying	O
sizes	O
of	O
training	O
samples	O
(	O
gain	O
of	O
DSN	B-Method
-	O
SVM	O
over	O
CNN	B-Method
-	I-Method
Softmax	I-Method
at	O
samples	O
.	O
	
Figure	O
[	O
reference	O
]	O
	
(	O
c	O
)	O
shows	O
a	O
comparison	O
of	O
generalization	B-Metric
error	I-Metric
between	O
CNN	B-Method
and	O
DSN	B-Method
.	O
	
subsection	O
:	O
CIFAR	B-Material
-	I-Material
10	I-Material
and	O
CIFAR	B-Material
-	I-Material
100	I-Material
	
CIFAR	B-Material
-	I-Material
10	I-Material
dataset	I-Material
consists	O
of	O
color	O
images	O
.	O
	
A	O
total	O
number	O
of	O
60	O
,	O
000	O
images	O
are	O
split	O
into	O
50	O
,	O
000	O
training	O
and	O
10	O
,	O
000	O
testing	O
images	O
.	O
	
The	O
dataset	O
is	O
preprocessed	O
by	O
global	B-Method
contrast	I-Method
normalization	I-Method
.	O
	
To	O
compare	O
our	O
results	O
with	O
the	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
,	O
in	O
this	O
case	O
,	O
we	O
also	O
augmented	O
the	O
dataset	O
by	O
zero	O
padding	O
4	O
pixels	O
on	O
each	O
side	O
,	O
then	O
do	O
corner	O
cropping	O
and	O
random	O
flipping	O
on	O
the	O
fly	O
during	O
training	O
.	O
	
No	O
model	B-Method
averaging	I-Method
is	O
done	O
at	O
the	O
test	O
phase	O
and	O
we	O
only	O
crop	O
the	O
center	O
of	O
a	O
test	O
sample	O
.	O
	
Table	O
(	O
[	O
reference	O
]	O
)	O
shows	O
our	O
result	O
.	O
	
Our	O
DSN	B-Method
model	O
achieved	O
an	O
error	B-Metric
rates	O
of	O
without	O
data	B-Method
augmentation	I-Method
and	O
with	O
data	B-Method
agumentation	I-Method
(	O
the	O
best	O
known	O
result	O
to	O
our	O
knowledge	O
)	O
.	O
	
DSN	B-Method
also	O
provides	O
added	O
robustness	O
to	O
hyperparameter	O
choice	O
,	O
in	O
that	O
the	O
early	O
layers	O
are	O
guided	O
with	O
direct	O
classification	O
loss	O
,	O
leading	O
to	O
a	O
faster	O
convergence	B-Metric
rate	I-Metric
and	O
relieved	O
burden	O
on	O
heavy	O
hyperparameter	B-Method
tuning	I-Method
.	O
	
We	O
also	O
compared	O
the	O
gradients	O
in	O
DSN	B-Method
and	O
those	O
in	O
CNN	B-Method
,	O
observing	O
times	O
greater	O
gradient	B-Metric
variance	I-Metric
of	O
DSN	B-Method
over	O
CNN	B-Method
in	O
the	O
first	O
convolutional	B-Method
layer	I-Method
.	O
	
This	O
is	O
consistent	O
with	O
an	O
observation	O
in	O
,	O
and	O
the	O
assumptions	O
and	O
motivations	O
we	O
make	O
in	O
this	O
work	O
.	O
	
To	O
see	O
what	O
the	O
features	O
have	O
been	O
learned	O
in	O
DSN	B-Method
vs.	O
CNN	O
,	O
we	O
select	O
one	O
example	O
image	O
from	O
each	O
of	O
the	O
ten	O
categories	O
of	O
CIFAR	B-Material
-	I-Material
10	I-Material
dataset	I-Material
,	O
run	O
one	O
forward	B-Method
pass	I-Method
,	O
and	O
show	O
the	O
feature	O
maps	O
learned	O
from	O
the	O
first	O
(	O
bottom	O
)	O
convolutional	B-Method
layer	I-Method
in	O
Figure	O
(	O
[	O
reference	O
]	O
)	O
.	O
	
Only	O
the	O
top	O
30	O
%	O
activations	O
are	O
shown	O
in	O
each	O
of	O
the	O
feature	B-Method
maps	I-Method
.	O
	
Feature	O
maps	O
learned	O
by	O
DSN	B-Method
show	O
to	O
be	O
more	O
intuitive	O
than	O
those	O
by	O
CNN	B-Method
.	O
	
CIFAR	B-Material
-	I-Material
100	I-Material
dataset	O
is	O
similar	O
to	O
CIFAR	B-Material
-	I-Material
10	I-Material
dataset	I-Material
,	O
except	O
that	O
it	O
has	O
100	O
classes	O
.	O
	
The	O
number	O
of	O
images	O
for	O
each	O
class	O
is	O
then	O
instead	O
of	O
as	O
in	O
CIFAR	B-Material
-	I-Material
10	I-Material
,	O
which	O
makes	O
the	O
classification	B-Task
task	I-Task
more	O
challenging	O
.	O
	
We	O
use	O
the	O
same	O
network	O
settings	O
as	O
in	O
CIFAR	B-Material
-	I-Material
10	I-Material
.	O
	
Table	O
(	O
[	O
reference	O
]	O
)	O
shows	O
previous	O
best	O
results	O
and	O
is	O
reported	O
by	O
DSN	B-Method
.	O
	
The	O
performance	O
boost	O
consistently	O
shown	O
on	O
both	O
CIFAR	B-Material
-	I-Material
10	I-Material
	
and	O
CIFAR	B-Material
-	I-Material
100	I-Material
again	O
demonstrates	O
the	O
advantage	O
of	O
the	O
DSN	B-Method
method	O
.	O
	
subsection	O
:	O
Street	O
View	O
House	O
Numbers	O
	
Street	O
View	O
House	O
Numbers	O
(	O
SVHN	B-Material
	
)	O
dataset	O
consists	O
of	O
digits	O
for	O
training	O
,	O
digits	O
for	O
testing	O
,	O
and	O
extra	O
training	O
samples	O
on	O
color	O
images	O
.	O
	
We	O
followed	O
the	O
previous	O
works	O
for	O
data	B-Task
preparation	I-Task
,	O
namely	O
:	O
we	O
select	O
400	O
samples	O
per	O
class	O
from	O
the	O
training	O
set	O
and	O
200	O
samples	O
per	O
class	O
from	O
the	O
extra	O
set	O
.	O
	
The	O
remaining	O
598	O
,	O
388	O
images	O
are	O
used	O
for	O
training	O
.	O
	
We	O
followed	O
to	O
preprocess	O
the	O
dataset	O
by	O
Local	B-Method
Contrast	I-Method
Normalization	I-Method
(	O
LCN	B-Method
)	O
.	O
	
We	O
do	O
not	O
do	O
data	B-Method
augmentation	I-Method
in	O
training	B-Task
and	O
use	O
only	O
a	O
single	O
model	O
in	O
testing	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
recent	O
comparable	O
results	O
.	O
	
Note	O
that	O
Dropconnect	B-Method
uses	O
data	B-Method
augmentation	I-Method
and	O
multiple	B-Method
model	I-Method
voting	I-Method
.	O
	
section	O
:	O
Conclusions	O
	
In	O
this	O
paper	O
,	O
we	O
have	O
presented	O
a	O
new	O
formulation	O
,	O
deeply	B-Method
-	I-Method
supervised	I-Method
nets	I-Method
(	O
DSN	B-Method
)	O
,	O
attempting	O
to	O
make	O
a	O
more	O
transparent	O
learning	B-Method
process	I-Method
for	O
deep	B-Method
learning	I-Method
.	O
	
Evident	O
performance	O
enhancement	O
over	O
existing	O
approaches	O
has	O
been	O
obtained	O
.	O
	
A	O
stochastic	B-Method
gradient	I-Method
view	I-Method
also	O
sheds	O
light	O
to	O
the	O
understanding	O
of	O
our	O
formulation	O
.	O
	
section	O
:	O
Acknowledgments	O
	
This	O
work	O
is	O
supported	O
by	O
NSF	O
award	O
IIS	O
-	O
1216528	O
(	O
IIS	O
-	O
1360566	O
)	O
and	O
NSF	O
award	O
IIS	O
-	O
0844566	O
(	O
IIS	O
-	O
1360568	O
)	O
.	O
	
We	O
thank	O
Min	O
Lin	O
,	O
Naiyan	O
Wang	O
,	O
Baoyuan	O
Wang	O
,	O
Jingdong	O
Wang	O
,	O
Liwei	O
Wang	O
,	O
and	O
David	O
Wipf	O
for	O
help	O
discussions	O
.	O
	
We	O
are	O
greatful	O
for	O
the	O
generous	O
donation	O
of	O
the	O
GPUs	O
by	O
NVIDIA	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Deeply	B-Method
-	I-Method
Recursive	I-Method
Convolutional	I-Method
Network	I-Method
for	O
Image	B-Task
Super	I-Task
-	I-Task
Resolution	I-Task
	
We	O
propose	O
an	O
image	B-Task
super	I-Task
-	I-Task
resolution	I-Task
method	O
(	O
SR	B-Task
)	O
using	O
a	O
deeply	O
-	O
recursive	O
convolutional	B-Method
network	O
(	O
DRCN	B-Method
)	I-Method
.	O
	
Our	O
network	O
has	O
a	O
very	O
deep	B-Method
recursive	I-Method
layer	I-Method
(	O
up	O
to	O
16	O
recursions	O
)	O
.	O
	
Increasing	O
recursion	O
depth	O
can	O
improve	O
performance	O
without	O
introducing	O
new	O
parameters	O
for	O
additional	O
convolutions	O
.	O
	
Albeit	O
advantages	O
,	O
learning	O
a	O
DRCN	B-Method
is	O
very	O
hard	O
with	O
a	O
standard	O
gradient	B-Method
descent	I-Method
method	I-Method
due	O
to	O
exploding	O
/	O
vanishing	O
gradients	O
.	O
	
To	O
ease	O
the	O
difficulty	O
of	O
training	B-Task
,	O
we	O
propose	O
two	O
extensions	O
:	O
recursive	B-Method
-	I-Method
supervision	I-Method
and	O
skip	B-Method
-	I-Method
connection	I-Method
.	O
	
Our	O
method	O
outperforms	O
previous	O
methods	O
by	O
a	O
large	O
margin	O
.	O
	
section	O
:	O
Introduction	O
	
For	O
image	B-Task
super	I-Task
-	I-Task
resolution	I-Task
(	O
SR	B-Task
)	O
,	O
receptive	O
field	O
of	O
a	O
convolutional	B-Method
network	O
determines	O
the	O
amount	O
of	O
contextual	O
information	O
that	O
can	O
be	O
exploited	O
to	O
infer	O
missing	O
high	O
-	O
frequency	O
components	O
.	O
	
For	O
example	O
,	O
if	O
there	O
exists	O
a	O
pattern	O
with	O
smoothed	O
edges	O
contained	O
in	O
a	O
receptive	O
field	O
,	O
it	O
is	O
plausible	O
that	O
the	O
pattern	O
is	O
recognized	O
and	O
edges	O
are	O
appropriately	O
sharpened	O
.	O
	
As	O
SR	B-Task
is	O
an	O
ill	O
-	O
posed	O
inverse	B-Task
problem	I-Task
,	O
collecting	O
and	O
analyzing	O
more	O
neighbor	O
pixels	O
can	O
possibly	O
give	O
more	O
clues	O
on	O
what	O
may	O
be	O
lost	O
by	O
downsampling	O
.	O
	
Deep	O
convolutional	B-Method
networks	O
(	O
DCN	B-Method
)	O
succeeding	O
in	O
various	O
computer	B-Task
vision	I-Task
tasks	I-Task
often	O
use	O
very	O
large	O
receptive	O
fields	O
(	O
224x224	O
common	O
in	O
ImageNet	B-Task
classification	I-Task
)	O
.	O
	
Among	O
many	O
approaches	O
to	O
widen	O
the	O
receptive	O
field	O
,	O
increasing	O
network	O
depth	O
is	O
one	O
possible	O
way	O
:	O
a	O
convolutional	B-Method
(	O
conv	B-Method
.	O
	
)	O
layer	O
with	O
filter	O
size	O
larger	O
than	O
a	O
or	O
a	O
pooling	O
(	O
pool	O
.	O
)	O
	
layer	O
that	O
reduces	O
the	O
dimension	O
of	O
intermediate	B-Method
representation	I-Method
can	O
be	O
used	O
.	O
	
Both	O
approaches	O
have	O
drawbacks	O
:	O
a	O
conv	B-Method
.	O
	
layer	O
introduces	O
more	O
parameters	O
and	O
a	O
pool	O
.	O
	
layer	B-Method
typically	O
discards	O
some	O
pixel	O
-	O
wise	O
information	O
.	O
	
For	O
image	B-Task
restoration	I-Task
problems	I-Task
such	O
as	O
super	B-Task
-	I-Task
resolution	I-Task
and	O
denoising	B-Task
,	O
image	B-Task
details	I-Task
are	O
very	O
important	O
.	O
	
Therefore	O
,	O
most	O
deep	B-Method
-	I-Method
learning	I-Method
approaches	I-Method
for	O
such	O
problems	O
do	O
not	O
use	O
pooling	B-Method
.	O
	
Increasing	O
depth	O
by	O
adding	O
	
a	O
new	O
weight	B-Method
layer	I-Method
basically	O
introduces	O
more	O
parameters	O
.	O
	
Two	O
problems	O
can	O
arise	O
.	O
	
First	O
,	O
overfitting	O
is	O
highly	O
likely	O
.	O
	
More	O
data	O
are	O
now	O
required	O
.	O
	
Second	O
,	O
the	O
model	O
becomes	O
too	O
huge	O
to	O
be	O
stored	O
and	O
retrieved	O
.	O
	
To	O
resolve	O
these	O
issues	O
,	O
we	O
use	O
a	O
deeply	O
-	O
recursive	O
convolutional	B-Method
network	O
(	O
DRCN	B-Method
)	I-Method
.	O
	
DRCN	B-Method
repeatedly	O
applies	O
the	O
same	O
convolutional	B-Method
layer	O
as	O
many	O
times	O
as	O
desired	O
.	O
	
The	O
number	O
of	O
parameters	O
do	O
not	O
increase	O
while	O
more	O
recursions	O
are	O
performed	O
.	O
	
Our	O
network	O
has	O
the	O
receptive	O
field	O
of	O
41	O
by	O
41	O
and	O
this	O
is	O
relatively	O
large	O
compared	O
to	O
SRCNN	B-Method
(	O
13	O
by	O
13	O
)	O
.	O
	
While	O
DRCN	B-Method
has	O
good	O
properties	O
,	O
we	O
find	O
that	O
DRCN	B-Method
optimized	O
with	O
the	O
widely	O
-	O
used	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
method	I-Method
does	O
not	O
easily	O
converge	O
.	O
	
This	O
is	O
due	O
to	O
exploding	O
/	O
vanishing	O
gradients	O
.	O
	
Learning	B-Task
long	I-Task
-	I-Task
range	I-Task
dependencies	I-Task
between	O
pixels	O
with	O
a	O
single	O
weight	B-Method
layer	I-Method
is	O
very	O
difficult	O
.	O
	
We	O
propose	O
two	O
approaches	O
to	O
ease	O
the	O
difficulty	O
of	O
training	O
(	O
Figure	O
[	O
reference	O
]	O
(	O
a	O
)	O
)	O
.	O
	
First	O
,	O
all	O
recursions	O
are	O
supervised	O
.	O
	
Feature	O
maps	O
after	O
each	O
recursion	O
are	O
used	O
to	O
reconstruct	O
the	O
target	O
high	O
-	O
resolution	O
image	O
(	O
HR	O
)	O
.	O
	
Reconstruction	B-Method
method	I-Method
(	O
layers	O
dedicated	O
to	O
reconstruction	B-Task
)	O
is	O
the	O
same	O
for	O
all	O
recursions	O
.	O
	
As	O
each	O
recursion	O
leads	O
to	O
a	O
different	O
HR	B-Task
prediction	I-Task
,	O
we	O
combine	O
all	O
predictions	O
resulting	O
from	O
different	O
levels	O
of	O
recursions	O
to	O
deliver	O
a	O
more	O
accurate	O
final	O
prediction	B-Task
.	O
	
The	O
second	O
proposal	O
is	O
to	O
use	O
a	O
skip	O
-	O
connection	O
from	O
input	O
to	O
the	O
reconstruction	B-Method
layer	I-Method
.	O
	
In	O
SR	B-Task
,	O
a	O
low	O
-	O
resolution	O
image	O
(	O
input	O
)	O
and	O
a	O
high	O
-	O
resolution	O
image	O
(	O
output	O
)	O
share	O
the	O
same	O
information	O
to	O
a	O
large	O
extent	O
.	O
	
Exact	O
copy	O
of	O
input	O
,	O
however	O
,	O
is	O
likely	O
to	O
be	O
attenuated	O
during	O
many	O
forward	O
passes	O
.	O
	
We	O
explicitly	O
connect	O
the	O
input	O
to	O
the	O
layers	O
for	O
output	B-Task
reconstruction	I-Task
.	O
	
This	O
is	O
particularly	O
effective	O
when	O
input	O
and	O
output	O
are	O
highly	O
correlated	O
.	O
	
Contributions	O
	
In	O
summary	O
,	O
we	O
propose	O
an	O
image	B-Task
super	I-Task
-	I-Task
resolution	I-Task
method	O
deeply	O
recursive	O
in	O
nature	O
.	O
	
It	O
utilizes	O
a	O
very	O
large	O
context	O
compared	O
to	O
previous	O
SR	B-Task
methods	O
with	O
only	O
a	O
single	O
recursive	B-Method
layer	I-Method
.	O
	
We	O
improve	O
the	O
simple	O
recursive	B-Method
network	I-Method
in	O
two	O
ways	O
:	O
recursive	B-Method
-	I-Method
supervision	I-Method
and	O
skip	B-Method
-	I-Method
connection	I-Method
.	O
	
Our	O
method	O
demonstrates	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
in	O
common	O
benchmarks	O
.	O
	
section	O
:	O
Related	O
Work	O
	
subsection	O
:	O
Single	O
-	O
Image	B-Task
Super	I-Task
-	I-Task
Resolution	I-Task
	
We	O
apply	O
DRCN	B-Method
to	O
single	B-Task
-	I-Task
image	I-Task
super	I-Task
-	I-Task
resolution	I-Task
(	O
SR	B-Task
)	O
.	O
	
Many	O
SR	B-Task
methods	O
have	O
been	O
proposed	O
in	O
the	O
computer	B-Task
vision	I-Task
community	I-Task
.	O
	
Early	O
methods	O
use	O
very	O
fast	O
interpolations	B-Method
but	O
yield	O
poor	O
results	O
.	O
	
Some	O
of	O
the	O
more	O
powerful	O
methods	O
utilize	O
statistical	O
image	O
priors	O
or	O
internal	B-Method
patch	I-Method
recurrence	I-Method
.	O
	
Recently	O
,	O
sophisticated	O
learning	B-Method
methods	I-Method
have	O
been	O
widely	O
used	O
to	O
model	O
a	O
mapping	O
from	O
LR	O
to	O
HR	O
patches	O
.	O
	
Many	O
methods	O
have	O
paid	O
attention	O
to	O
find	O
better	O
regression	B-Method
functions	I-Method
from	O
LR	O
to	O
HR	O
images	O
.	O
	
This	O
is	O
achieved	O
with	O
various	O
techniques	O
:	O
neighbor	B-Method
embedding	I-Method
,	O
sparse	B-Method
coding	I-Method
,	O
convolutional	B-Method
neural	O
network	O
(	O
CNN	O
)	O
and	O
random	B-Method
forest	I-Method
.	O
	
Among	O
several	O
recent	O
learning	B-Method
-	O
based	O
successes	O
,	O
convolutional	B-Method
neural	O
network	O
(	O
SRCNN	B-Method
)	O
demonstrated	O
the	O
feasibility	O
of	O
an	O
end	O
-	O
to	O
-	O
end	B-Method
approach	I-Method
to	O
SR	B-Task
.	O
	
One	O
possibility	O
to	O
improve	O
SRCNN	B-Method
is	O
to	O
simply	O
stack	O
more	O
weight	O
layers	O
as	O
many	O
times	O
as	O
possible	O
.	O
	
However	O
,	O
this	O
significantly	O
increases	O
the	O
number	O
of	O
parameters	O
and	O
requires	O
more	O
data	O
to	O
prevent	O
overfitting	O
.	O
	
In	O
this	O
work	O
,	O
we	O
seek	O
to	O
design	O
a	O
convolutional	B-Method
network	O
that	O
models	O
long	O
-	O
range	O
pixel	O
dependencies	O
with	O
limited	O
capacity	O
.	O
	
Our	O
network	O
recursively	O
widens	O
the	O
receptive	O
field	O
without	O
increasing	O
model	O
capacity	O
.	O
	
subsection	O
:	O
Recursive	B-Method
Neural	I-Method
Network	I-Method
in	O
Computer	B-Task
Vision	I-Task
	
Recursive	B-Method
neural	I-Method
networks	I-Method
,	O
suitable	O
for	O
temporal	O
and	O
sequential	O
data	O
,	O
have	O
seen	O
limited	O
use	O
on	O
algorithms	O
operating	O
on	O
a	O
single	O
static	O
image	O
.	O
	
Socher	O
et	O
al	O
.	O
used	O
a	O
convolutional	B-Method
network	O
in	O
a	O
separate	O
stage	O
to	O
first	O
learn	O
features	O
on	O
RGB	O
-	O
Depth	O
data	O
,	O
prior	O
to	O
hierarchical	B-Task
merging	I-Task
.	O
	
In	O
these	O
models	O
,	O
the	O
input	O
dimension	O
is	O
twice	O
that	O
of	O
the	O
output	O
and	O
recursive	B-Method
convolutions	I-Method
are	O
applied	O
only	O
two	O
times	O
.	O
	
Similar	O
dimension	B-Task
reduction	I-Task
occurs	O
in	O
the	O
recurrent	O
convolutional	B-Method
neural	O
networks	O
used	O
for	O
semantic	B-Task
segmentation	I-Task
.	O
	
As	O
SR	B-Task
methods	O
predict	O
full	O
-	O
sized	O
images	O
,	O
dimension	B-Task
reduction	I-Task
is	O
not	O
allowed	O
.	O
	
In	O
Eigen	O
et	O
al	O
.	O
,	O
recursive	B-Method
layers	I-Method
have	O
the	O
same	O
input	O
and	O
output	O
dimension	O
,	O
but	O
recursive	B-Method
convolutions	I-Method
resulted	O
in	O
worse	O
performances	O
than	O
a	O
single	O
convolution	B-Method
due	O
to	O
overfitting	O
.	O
	
To	O
overcome	O
overfitting	O
,	O
Liang	O
and	O
Hu	O
uses	O
a	O
recurrent	B-Method
layer	I-Method
that	O
takes	O
feed	O
-	O
forward	O
inputs	O
into	O
all	O
unfolded	O
layers	O
.	O
	
They	O
show	O
that	O
performance	O
increases	O
up	O
to	O
three	O
convolutions	B-Method
.	O
	
Their	O
network	B-Method
structure	I-Method
,	O
designed	O
for	O
object	B-Task
recognition	I-Task
,	O
is	O
the	O
same	O
as	O
the	O
existing	O
CNN	B-Method
architectures	I-Method
.	O
	
Our	O
network	O
is	O
similar	O
to	O
the	O
above	O
in	O
the	O
sense	O
that	O
recursive	B-Method
or	I-Method
recurrent	I-Method
layers	I-Method
are	O
used	O
with	O
convolutions	B-Method
.	O
	
We	O
further	O
increase	O
the	O
recursion	O
depth	O
and	O
demonstrate	O
that	O
very	O
deep	B-Method
recursions	I-Method
can	O
significantly	O
boost	O
the	O
performance	O
for	O
super	B-Task
-	I-Task
resolution	I-Task
.	O
	
We	O
apply	O
the	O
same	O
convolution	B-Method
up	O
to	O
16	O
times	O
(	O
the	O
previous	O
maximum	O
is	O
three	O
)	O
.	O
	
section	O
:	O
Proposed	O
Method	O
	
subsection	O
:	O
Basic	O
Model	O
	
Our	O
first	O
model	O
,	O
outlined	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
consists	O
of	O
three	O
sub	B-Method
-	I-Method
networks	I-Method
:	O
embedding	B-Method
,	O
inference	B-Method
and	O
reconstruction	B-Method
networks	I-Method
.	O
	
The	O
embedding	B-Method
net	I-Method
is	O
used	O
to	O
represent	O
the	O
given	O
image	O
as	O
feature	O
maps	O
ready	O
for	O
inference	B-Method
.	O
	
Next	O
,	O
the	O
inference	B-Method
net	O
solves	O
the	O
task	O
.	O
	
Once	O
inference	B-Method
is	O
done	O
,	O
final	O
feature	O
maps	O
in	O
the	O
inference	B-Method
net	O
are	O
fed	O
into	O
the	O
reconstruction	B-Method
net	I-Method
to	O
generate	O
the	O
output	O
image	O
.	O
	
The	O
embedding	B-Method
net	I-Method
takes	O
the	O
input	O
image	O
(	O
grayscale	O
or	O
RGB	O
)	O
and	O
represents	O
it	O
as	O
a	O
set	O
of	O
feature	O
maps	O
.	O
	
Intermediate	B-Method
representation	I-Method
used	O
to	O
pass	O
information	O
to	O
the	O
inference	B-Method
net	O
largely	O
depends	O
on	O
how	O
the	O
inference	B-Method
net	O
internally	O
represent	O
its	O
feature	O
maps	O
in	O
its	O
hidden	O
layers	O
.	O
	
Learning	O
this	O
representation	O
is	O
done	O
end	O
-	O
to	O
-	O
end	O
altogether	O
with	O
learning	O
other	O
sub	B-Method
-	I-Method
networks	I-Method
.	O
	
Inference	B-Method
net	I-Method
is	O
the	O
main	O
component	O
that	O
solves	O
the	O
task	O
of	O
super	B-Task
-	I-Task
resolution	I-Task
.	O
	
Analyzing	O
a	O
large	O
image	O
region	O
is	O
done	O
by	O
a	O
single	O
recursive	B-Method
layer	I-Method
.	O
	
Each	O
recursion	O
applies	O
the	O
same	O
convolution	B-Method
followed	O
by	O
a	O
rectified	B-Method
linear	I-Method
unit	I-Method
(	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
With	O
convolution	B-Method
filters	I-Method
larger	O
than	O
,	O
the	O
receptive	O
field	O
is	O
widened	O
with	O
every	O
recursion	O
.	O
	
While	O
feature	O
maps	O
from	O
the	O
final	O
application	O
of	O
the	O
recursive	B-Method
layer	I-Method
represent	O
the	O
high	O
-	O
resolution	O
image	O
,	O
transforming	O
them	O
(	O
multi	O
-	O
channel	O
)	O
back	O
into	O
the	O
original	O
image	O
space	O
(	O
1	O
or	O
3	O
-	O
channel	O
)	O
is	O
necessary	O
.	O
	
This	O
is	O
done	O
by	O
the	O
reconstruction	B-Method
net	I-Method
.	O
	
We	O
have	O
a	O
single	O
hidden	B-Method
layer	I-Method
for	O
each	O
sub	O
-	O
net	O
.	O
	
Only	O
the	O
layer	O
for	O
the	O
inference	B-Method
net	O
is	O
recursive	O
.	O
	
Other	O
sub	B-Method
-	I-Method
nets	I-Method
are	O
vastly	O
similar	O
to	O
the	O
standard	O
mutilayer	B-Method
perceptrons	I-Method
(	O
MLP	B-Method
)	O
with	O
a	O
single	O
hidden	B-Method
layer	I-Method
.	O
	
For	O
MLP	B-Method
,	O
full	B-Method
connection	I-Method
of	I-Method
neurons	I-Method
is	O
equivalent	O
to	O
a	O
convolution	B-Method
with	O
.	O
	
In	O
our	O
sub	B-Method
-	I-Method
nets	I-Method
,	O
we	O
use	O
filters	B-Method
.	O
	
For	O
embedding	B-Task
net	I-Task
,	O
we	O
use	O
filters	O
because	O
image	O
gradients	O
are	O
more	O
informative	O
than	O
the	O
raw	O
intensities	O
for	O
super	B-Task
-	I-Task
resolution	I-Task
.	O
	
For	O
inference	B-Method
net	O
,	O
convolutions	B-Method
imply	O
that	O
hidden	O
states	O
are	O
passed	O
to	O
adjacent	O
pixels	O
only	O
.	O
	
Reconstruction	B-Method
net	I-Method
also	O
takes	O
direct	O
neighbors	O
into	O
account	O
.	O
	
Mathematical	B-Method
Formulation	I-Method
	
The	O
network	O
takes	O
an	O
interpolated	O
input	O
image	O
(	O
to	O
the	O
desired	O
size	O
)	O
as	O
input	O
and	O
predicts	O
the	O
target	O
image	O
as	O
in	O
SRCNN	B-Method
.	O
	
Our	O
goal	O
is	O
to	O
learn	O
a	O
model	O
that	O
predicts	O
values	O
,	O
where	O
is	O
its	O
estimate	O
of	O
ground	O
truth	O
output	O
.	O
	
Let	O
denote	O
sub	O
-	O
net	O
functions	O
:	O
embedding	B-Task
,	O
inference	B-Method
and	O
reconstruction	B-Task
,	O
respectively	O
.	O
	
Our	O
model	O
is	O
the	O
composition	O
of	O
three	O
functions	O
:	O
Embedding	B-Method
net	I-Method
takes	O
the	O
input	O
vector	O
and	O
computes	O
the	O
matrix	O
output	O
,	O
which	O
is	O
an	O
input	O
to	O
the	O
inference	B-Method
net	O
.	O
	
Hidden	O
layer	O
values	O
are	O
denoted	O
by	O
.	O
	
The	O
formula	O
for	O
embedding	B-Task
net	I-Task
is	O
as	O
follows	O
:	O
where	O
the	O
operator	O
denotes	O
a	O
convolution	O
and	O
corresponds	O
to	O
a	O
ReLU	B-Method
.	O
	
Weight	O
and	O
bias	O
matrices	O
are	O
and	O
.	O
	
Inference	B-Method
net	I-Method
takes	O
the	O
input	O
matrix	O
and	O
computes	O
the	O
matrix	O
output	O
.	O
	
Here	O
,	O
we	O
use	O
the	O
same	O
weight	O
and	O
bias	O
matrices	O
and	O
for	O
all	O
operations	O
.	O
	
Let	O
denote	O
the	O
function	O
modeled	O
by	O
a	O
single	O
recursion	B-Method
of	I-Method
the	I-Method
recursive	I-Method
layer	I-Method
:	O
.	O
	
The	O
recurrence	O
relation	O
is	O
for	O
.	O
	
Inference	B-Method
net	I-Method
is	O
equivalent	O
to	O
the	O
composition	O
of	O
the	O
same	O
elementary	O
function	O
:	O
where	O
the	O
operator	O
denotes	O
a	O
function	B-Method
composition	I-Method
and	O
denotes	O
the	O
-	O
fold	O
product	O
of	O
.	O
	
Reconstruction	B-Method
net	I-Method
takes	O
the	O
input	O
hidden	O
state	O
and	O
outputs	O
the	O
target	O
image	O
(	O
high	O
-	O
resolution	O
)	O
.	O
	
Roughly	O
speaking	O
,	O
reconstruction	O
net	O
is	O
the	O
inverse	O
operation	O
of	O
embedding	B-Method
net	I-Method
.	O
	
The	O
formula	O
is	O
as	O
follows	O
:	O
	
Model	B-Method
Properties	I-Method
	
Now	O
we	O
have	O
all	O
components	O
for	O
our	O
model	O
.	O
	
The	O
recursive	B-Method
model	I-Method
has	O
pros	O
and	O
cons	O
.	O
	
While	O
the	O
recursive	B-Method
model	I-Method
is	O
simple	O
and	O
powerful	O
,	O
we	O
find	O
training	O
a	O
deeply	B-Method
-	I-Method
recursive	I-Method
network	I-Method
very	O
difficult	O
.	O
	
This	O
is	O
in	O
accordance	O
with	O
the	O
limited	O
success	O
of	O
previous	O
methods	O
using	O
at	O
most	O
three	O
recursions	O
so	O
far	O
.	O
	
Among	O
many	O
reasons	O
,	O
two	O
severe	O
problems	O
are	O
vanishing	O
and	O
exploding	O
gradients	O
.	O
	
Exploding	O
gradients	O
refer	O
to	O
the	O
large	O
increase	O
in	O
the	O
norm	O
of	O
the	O
gradient	O
during	O
training	O
.	O
	
Such	O
events	O
are	O
due	O
to	O
the	O
multiplicative	O
nature	O
of	O
chained	O
gradients	O
.	O
	
Long	B-Method
term	I-Method
components	I-Method
can	O
grow	O
exponentially	O
for	O
deep	B-Method
recursions	I-Method
.	O
	
The	O
vanishing	B-Task
gradients	I-Task
problem	I-Task
refers	O
to	O
the	O
opposite	O
behavior	O
.	O
	
Long	B-Method
term	I-Method
components	I-Method
approach	O
exponentially	O
fast	O
to	O
the	O
zero	O
vector	O
.	O
	
Due	O
to	O
this	O
,	O
learning	O
the	O
relation	O
between	O
distant	O
pixels	O
is	O
very	O
hard	O
.	O
	
Another	O
known	O
issue	O
is	O
that	O
storing	O
an	O
exact	O
copy	O
of	O
information	O
through	O
many	O
recursions	O
is	O
not	O
easy	O
.	O
	
In	O
SR	B-Task
,	O
output	O
is	O
vastly	O
similar	O
to	O
input	O
and	O
recursive	B-Method
layer	I-Method
needs	O
to	O
keep	O
the	O
exact	O
copy	O
of	O
input	O
image	O
for	O
many	O
recursions	O
.	O
	
These	O
issues	O
are	O
also	O
observed	O
when	O
we	O
train	O
our	O
basic	O
recursive	B-Method
model	I-Method
and	O
we	O
did	O
not	O
succeed	O
in	O
training	O
a	O
deeply	B-Method
-	I-Method
recursive	I-Method
network	I-Method
.	O
	
In	O
addition	O
to	O
gradient	B-Task
problems	I-Task
,	O
there	O
exists	O
an	O
issue	O
with	O
finding	O
the	O
optimal	O
number	O
of	O
recursions	O
.	O
	
If	O
recursions	O
are	O
too	O
deep	O
for	O
a	O
given	O
task	O
,	O
we	O
need	O
to	O
reduce	O
the	O
number	O
of	O
recursions	O
.	O
	
Finding	O
the	O
optimal	O
number	O
requires	O
training	O
many	O
networks	O
with	O
different	O
recursion	O
depths	O
.	O
	
subsection	O
:	O
Advanced	O
Model	O
	
Recursive	B-Method
-	I-Method
Supervision	I-Method
	
To	O
resolve	O
the	O
gradient	B-Task
and	I-Task
optimal	I-Task
recursion	I-Task
issues	I-Task
,	O
we	O
propose	O
an	O
improved	O
model	O
.	O
	
We	O
supervise	O
all	O
recursions	O
in	O
order	O
to	O
alleviate	O
the	O
effect	O
of	O
vanishing	O
/	O
exploding	O
gradients	O
.	O
	
As	O
we	O
have	O
assumed	O
that	O
the	O
same	O
representation	O
can	O
be	O
used	O
again	O
and	O
again	O
during	O
convolutions	B-Method
in	O
the	O
inference	B-Method
net	O
,	O
the	O
same	O
reconstruction	B-Method
net	I-Method
is	O
used	O
to	O
predict	O
HR	O
images	O
for	O
all	O
recursions	O
.	O
	
Our	O
reconstruction	B-Method
net	I-Method
now	O
outputs	O
predictions	O
and	O
all	O
predictions	O
are	O
simultaneously	O
supervised	O
during	O
training	O
(	O
Figure	O
[	O
reference	O
]	O
	
(	O
a	O
)	O
)	O
.	O
	
We	O
use	O
all	O
intermediate	O
predictions	O
to	O
compute	O
the	O
final	O
output	O
.	O
	
All	O
predictions	O
are	O
averaged	O
during	O
testing	O
.	O
	
The	O
optimal	O
weights	O
are	O
automatically	O
learned	O
during	O
training	O
.	O
	
A	O
similar	O
but	O
a	O
different	O
concept	O
of	O
supervising	O
intermediate	O
layers	O
for	O
a	O
convolutional	B-Method
network	O
is	O
used	O
in	O
Lee	O
et	O
al	O
.	O
	
Their	O
method	O
simultaneously	O
minimizes	O
classification	B-Metric
error	I-Metric
while	O
improving	O
the	O
directness	O
and	O
transparency	B-Metric
of	O
the	O
hidden	B-Method
layer	I-Method
learning	I-Method
process	I-Method
.	O
	
There	O
are	O
two	O
significant	O
differences	O
between	O
our	O
recursive	B-Method
-	I-Method
supervision	I-Method
and	O
deep	B-Method
-	I-Method
supervision	I-Method
proposed	O
in	O
Lee	O
et	O
al	O
.	O
.	O
	
They	O
associate	O
a	O
unique	O
classifier	B-Method
for	O
each	O
hidden	O
layer	O
.	O
	
For	O
each	O
additional	O
layer	O
,	O
a	O
new	O
classifier	B-Method
has	O
to	O
be	O
introduced	O
,	O
as	O
well	O
as	O
new	O
parameters	O
.	O
	
If	O
this	O
approach	O
is	O
used	O
,	O
our	O
modified	B-Method
network	I-Method
would	O
resemble	O
that	O
of	O
Figure	O
[	O
reference	O
]	O
	
(	O
b	O
)	O
.	O
	
We	O
would	O
then	O
need	O
different	O
reconstruction	B-Method
networks	I-Method
.	O
	
This	O
is	O
against	O
our	O
original	O
purpose	O
of	O
using	O
recursive	B-Method
networks	I-Method
,	O
which	O
is	O
avoid	O
introducing	O
new	O
parameters	O
while	O
stacking	O
more	O
layers	O
.	O
	
In	O
addition	O
,	O
using	O
different	O
reconstruction	B-Method
nets	I-Method
no	O
longer	O
effectively	O
regularizes	O
the	O
network	O
.	O
	
The	O
second	O
difference	O
is	O
that	O
Lee	O
et	O
al	O
.	O
discards	O
all	O
intermediate	B-Method
classifiers	I-Method
during	O
testing	O
.	O
	
However	O
,	O
an	O
ensemble	O
of	O
all	O
intermediate	O
predictions	O
significantly	O
boosts	O
the	O
performance	O
.	O
	
The	O
final	O
output	O
from	O
the	O
ensemble	O
is	O
also	O
supervised	O
.	O
	
Our	O
recursive	B-Method
-	I-Method
supervision	I-Method
naturally	O
eases	O
the	O
difficulty	O
of	O
training	O
recursive	B-Method
networks	I-Method
.	O
	
Backpropagation	B-Method
goes	O
through	O
a	O
small	O
number	O
of	O
layers	O
if	O
supervising	O
signal	O
goes	O
directly	O
from	O
loss	O
layer	O
to	O
early	O
recursion	O
.	O
	
Summing	O
all	O
gradients	O
backpropagated	O
from	O
different	O
prediction	O
losses	O
gives	O
a	O
smoothing	O
effect	O
.	O
	
The	O
adversarial	O
effect	O
of	O
vanishing	O
/	O
exploding	O
gradients	O
along	O
one	O
backpropagation	O
path	O
is	O
alleviated	O
.	O
	
Moreover	O
,	O
the	O
importance	O
of	O
picking	O
the	O
optimal	O
number	O
of	O
recursions	O
is	O
reduced	O
as	O
our	O
supervision	B-Method
enables	O
utilizing	O
predictions	O
from	O
all	O
intermediate	O
layers	O
.	O
	
If	O
recursions	B-Method
are	O
too	O
deep	O
for	O
the	O
given	O
task	O
,	O
we	O
expect	O
the	O
weight	O
for	O
late	O
predictions	O
to	O
be	O
low	O
while	O
early	O
predictions	O
receive	O
high	O
weights	O
.	O
	
By	O
looking	O
at	O
weights	O
of	O
predictions	O
,	O
we	O
can	O
figure	O
out	O
the	O
marginal	O
gain	O
from	O
additional	O
recursions	O
.	O
	
We	O
present	O
an	O
expanded	O
CNN	B-Method
structure	I-Method
of	O
our	O
model	O
for	O
illustration	O
purposes	O
in	O
Figure	O
[	O
reference	O
]	O
	
(	O
c	O
)	O
.	O
	
If	O
parameters	O
are	O
not	O
allowed	O
to	O
be	O
shared	O
and	O
CNN	O
chains	O
vary	O
their	O
depths	O
,	O
the	O
number	O
of	O
free	O
parameters	O
grows	O
fast	O
(	O
quadratically	O
)	O
.	O
	
Skip	B-Method
-	I-Method
Connection	I-Method
	
Now	O
we	O
describe	O
our	O
second	O
extension	O
:	O
skip	B-Task
-	I-Task
connection	I-Task
.	O
	
For	O
SR	B-Task
,	O
input	O
and	O
output	O
images	O
are	O
highly	O
correlated	O
.	O
	
Carrying	O
most	O
if	O
not	O
all	O
of	O
input	O
values	O
until	O
the	O
end	O
of	O
the	O
network	O
is	O
inevitable	O
but	O
very	O
inefficient	O
.	O
	
Due	O
to	O
gradient	B-Task
problems	I-Task
,	O
exactly	O
learning	O
a	O
simple	O
linear	O
relation	O
between	O
input	O
and	O
output	O
is	O
very	O
difficult	O
if	O
many	O
recursions	O
exist	O
in	O
between	O
them	O
.	O
	
We	O
add	O
a	O
layer	O
skip	O
from	O
input	O
to	O
the	O
reconstruction	B-Method
net	I-Method
.	O
	
Adding	O
layer	O
skips	O
is	O
successfully	O
used	O
for	O
a	O
semantic	B-Task
segmentation	I-Task
network	I-Task
and	O
we	O
employ	O
a	O
similar	O
idea	O
.	O
	
Now	O
input	O
image	O
is	O
directly	O
fed	O
into	O
the	O
reconstruction	B-Method
net	I-Method
whenever	O
it	O
is	O
used	O
during	O
recursions	O
.	O
	
Our	O
skip	B-Method
-	I-Method
connection	I-Method
has	O
two	O
advantages	O
.	O
	
First	O
,	O
network	O
capacity	O
to	O
store	O
the	O
input	O
signal	O
during	O
recursions	O
is	O
saved	O
.	O
	
Second	O
,	O
the	O
exact	O
copy	O
of	O
input	O
signal	O
can	O
be	O
used	O
during	O
target	B-Task
prediction	I-Task
.	O
	
Our	O
skip	B-Method
-	I-Method
connection	I-Method
is	O
simple	O
yet	O
very	O
effective	O
.	O
	
In	O
super	B-Task
-	I-Task
resolution	I-Task
,	O
LR	O
and	O
HR	O
images	O
are	O
vastly	O
similar	O
.	O
	
In	O
most	O
regions	O
,	O
differences	O
are	O
zero	O
and	O
only	O
small	O
number	O
of	O
locations	O
have	O
non	O
-	O
zero	O
values	O
.	O
	
For	O
this	O
reason	O
,	O
several	O
super	B-Task
-	I-Task
resolution	I-Task
methods	O
predict	O
image	O
details	O
only	O
.	O
	
Similarly	O
,	O
we	O
find	O
that	O
this	O
domain	O
-	O
specific	O
knowledge	O
significantly	O
improves	O
our	O
learning	B-Method
procedure	I-Method
.	O
	
Mathematical	B-Method
Formulation	I-Method
	
Each	O
intermediate	B-Task
prediction	I-Task
under	O
recursive	B-Method
-	I-Method
supervision	I-Method
(	O
Figure	O
[	O
reference	O
]	O
(	O
a	O
)	O
)	O
is	O
for	O
,	O
where	O
now	O
takes	O
two	O
inputs	O
,	O
one	O
from	O
skip	O
-	O
connection	O
.	O
	
Reconstruction	B-Method
net	I-Method
with	O
skip	O
-	O
connection	O
can	O
take	O
various	O
functional	O
forms	O
.	O
	
For	O
example	O
,	O
input	O
can	O
be	O
concatenated	O
to	O
the	O
feature	O
maps	O
.	O
	
As	O
the	O
input	O
is	O
an	O
interpolated	O
input	O
image	O
(	O
roughly	O
speaking	O
,	O
)	O
,	O
we	O
find	O
is	O
enough	O
for	O
our	O
purpose	O
.	O
	
More	O
sophisticated	O
functions	O
for	O
merging	O
two	O
inputs	O
to	O
will	O
be	O
explored	O
in	O
the	O
future	O
.	O
	
Now	O
,	O
the	O
final	O
output	O
is	O
the	O
weighted	O
average	O
of	O
all	O
intermediate	O
predictions	O
:	O
where	O
denotes	O
the	O
weights	O
of	O
predictions	O
reconstructed	O
from	O
each	O
intermediate	O
hidden	O
state	O
during	O
recursion	O
.	O
	
These	O
weights	O
are	O
learned	O
during	O
training	O
.	O
	
0.5cm0.5	O
	
cm	O
0.5cm0.5	O
	
cm	O
0.5cm0.5	O
	
cm	O
0.5cm0.5	O
	
cm	O
	
subsection	O
:	O
Training	B-Metric
	
Objective	B-Metric
	
We	O
now	O
describe	O
the	O
training	B-Metric
objective	I-Metric
used	O
to	O
find	O
optimal	O
parameters	O
of	O
our	O
model	O
.	O
	
Given	O
a	O
training	O
dataset	O
,	O
our	O
goal	O
is	O
to	O
find	O
the	O
best	O
model	O
that	O
accurately	O
predicts	O
values	O
.	O
	
In	O
the	O
least	B-Method
-	I-Method
squares	I-Method
regression	I-Method
setting	I-Method
,	O
typical	O
in	O
SR	B-Task
,	O
the	O
mean	B-Metric
squared	I-Metric
error	I-Metric
averaged	O
over	O
the	O
training	O
set	O
is	O
minimized	O
.	O
	
This	O
favors	O
high	O
Peak	B-Metric
Signal	I-Metric
-	I-Metric
to	I-Metric
-	I-Metric
Noise	I-Metric
Ratio	I-Metric
(	O
PSNR	B-Metric
)	O
,	O
a	O
widely	O
-	O
used	O
evaluation	B-Metric
criteria	I-Metric
.	O
	
With	O
recursive	B-Method
-	I-Method
supervision	I-Method
,	O
we	O
have	O
objectives	O
to	O
minimize	O
:	O
supervising	O
outputs	O
from	O
recursions	O
and	O
the	O
final	O
output	O
.	O
	
For	O
intermediate	O
outputs	O
,	O
we	O
have	O
the	O
loss	O
function	O
where	O
denotes	O
the	O
parameter	O
set	O
and	O
is	O
the	O
output	O
from	O
the	O
-	O
th	O
recursion	O
.	O
	
For	O
the	O
final	O
output	O
,	O
we	O
have	O
	
Now	O
we	O
give	O
the	O
final	O
loss	B-Metric
function	I-Metric
.	O
	
The	O
training	B-Method
is	O
regularized	O
by	O
weight	B-Method
decay	I-Method
(	O
penalty	O
multiplied	O
by	O
)	O
.	O
where	O
denotes	O
the	O
importance	O
of	O
the	O
companion	O
objective	O
on	O
the	O
intermediate	O
outputs	O
and	O
denotes	O
the	O
multiplier	O
of	O
weight	B-Method
decay	I-Method
.	O
	
Setting	O
high	O
makes	O
the	O
training	B-Method
procedure	I-Method
stable	O
as	O
early	O
recursions	O
easily	O
converge	O
.	O
	
As	O
training	O
progresses	O
,	O
decays	O
to	O
boost	O
the	O
performance	O
of	O
the	O
final	O
output	O
.	O
	
Training	B-Task
is	O
carried	O
out	O
by	O
optimizing	O
the	O
regression	O
objective	O
using	O
mini	B-Method
-	I-Method
batch	I-Method
gradient	I-Method
descent	I-Method
based	O
on	O
back	B-Method
-	I-Method
propagation	I-Method
(	O
LeCun	O
et	O
al	O
.	O
)	O
.	O
	
We	O
implement	O
our	O
model	O
using	O
the	O
MatConvNet	B-Method
␣	I-Method
http:	I-Method
//	I-Method
www.vlfeat.org	I-Method
/	I-Method
matconvnet	I-Method
/	I-Method
package	I-Method
.	O
	
section	O
:	O
Experimental	O
Results	O
	
In	O
this	O
section	O
,	O
we	O
evaluate	O
the	O
performance	O
of	O
our	O
method	O
on	O
several	O
datasets	O
.	O
	
We	O
first	O
describe	O
datasets	O
used	O
for	O
training	O
and	O
testing	O
our	O
method	O
.	O
	
Next	O
,	O
our	O
training	O
setup	O
is	O
given	O
.	O
	
We	O
give	O
several	O
experiments	O
for	O
understanding	O
our	O
model	O
properties	O
.	O
	
The	O
effect	O
of	O
increasing	O
the	O
number	O
of	O
recursions	O
is	O
investigated	O
.	O
	
Finally	O
,	O
we	O
compare	O
our	O
method	O
with	O
several	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
.	O
	
subsection	O
:	O
Datasets	O
	
For	O
training	B-Task
,	O
we	O
use	O
91	O
images	O
proposed	O
in	O
Yang	O
et	O
al	O
.	O
for	O
all	O
experiments	O
.	O
	
For	O
testing	O
,	O
we	O
use	O
four	O
datasets	O
.	O
	
Datasets	O
Set5	O
and	O
Set14	O
are	O
often	O
used	O
for	O
benchmark	O
.	O
	
Dataset	B-Material
B100	I-Material
consists	O
of	O
natural	O
images	O
in	O
the	O
Berkeley	B-Material
Segmentation	I-Material
Dataset	I-Material
.	O
	
Finally	O
,	O
dataset	O
Urban100	O
,	O
urban	O
images	O
recently	O
provided	O
by	O
Huang	O
et	O
al	O
.	O
,	O
is	O
very	O
interesting	O
as	O
it	O
contains	O
many	O
challenging	O
images	O
failed	O
by	O
existing	O
methods	O
.	O
	
0cm	O
-	O
0.0	O
cm	O
	
subsection	O
:	O
Training	O
Setup	O
	
We	O
use	O
16	O
recursions	O
unless	O
stated	O
otherwise	O
.	O
	
When	O
unfolded	O
,	O
the	O
longest	O
chain	O
from	O
the	O
input	O
to	O
the	O
output	O
passes	O
20	O
conv	B-Method
.	O
	
layers	O
(	O
receptive	O
field	O
of	O
41	O
by	O
41	O
)	O
.	O
	
We	O
set	O
the	O
momentum	O
parameter	O
to	O
0.9	O
and	O
weight	O
decay	O
to	O
0.0001	O
.	O
	
We	O
use	O
256	O
filters	O
of	O
the	O
size	O
for	O
all	O
weight	O
layers	O
.	O
	
Training	O
images	O
are	O
split	O
into	O
41	O
by	O
41	O
patches	O
with	O
stride	O
21	O
and	O
64	O
patches	O
are	O
used	O
as	O
a	O
mini	O
-	O
batch	O
for	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
.	O
	
For	O
initializing	O
weights	O
in	O
non	B-Method
-	I-Method
recursive	I-Method
layers	I-Method
,	O
we	O
use	O
the	O
method	O
described	O
in	O
He	O
et	O
al	O
.	O
.	O
	
For	O
recursive	B-Method
convolutions	I-Method
,	O
we	O
set	O
all	O
weights	O
to	O
zero	O
except	O
self	O
-	O
connections	O
(	O
connection	O
to	O
the	O
same	O
neuron	O
in	O
the	O
next	O
layer	O
)	O
.	O
	
Biases	O
are	O
set	O
to	O
zero	O
.	O
	
Learning	B-Metric
rate	I-Metric
is	O
initially	O
set	O
to	O
0.01	O
and	O
then	O
decreased	O
by	O
a	O
factor	O
of	O
10	O
if	O
the	O
validation	B-Metric
error	I-Metric
does	O
not	O
decrease	O
for	O
5	O
epochs	O
.	O
	
If	O
learning	B-Metric
rate	I-Metric
is	O
less	O
than	O
,	O
the	O
procedure	O
is	O
terminated	O
.	O
	
Training	O
roughly	O
takes	O
6	O
days	O
on	O
a	O
machine	O
using	O
one	O
Titan	B-Method
X	I-Method
GPU	I-Method
.	O
	
subsection	O
:	O
Study	O
of	O
Deep	O
Recursions	O
	
We	O
study	O
the	O
effect	O
of	O
increasing	O
recursion	O
depth	O
.	O
	
We	O
trained	O
four	O
models	O
with	O
different	O
numbers	O
of	O
recursions	O
:	O
1	O
,	O
6	O
,	O
11	O
,	O
and	O
16	O
.	O
	
Four	O
models	O
use	O
the	O
same	O
number	O
of	O
parameters	O
except	O
the	O
weights	O
used	O
for	O
ensemble	B-Task
.	O
	
In	O
Figure	O
8	O
,	O
it	O
is	O
shown	O
that	O
as	O
more	O
recursions	O
are	O
performed	O
,	O
PSNR	B-Metric
measures	O
increase	O
.	O
	
Increasing	O
recursion	O
depth	O
with	O
a	O
larger	O
image	O
context	O
and	O
more	O
nonlinearities	O
boosts	O
performance	O
.	O
	
The	O
effect	O
of	O
ensemble	O
is	O
also	O
investigated	O
.	O
	
We	O
first	O
evaluate	O
intermediate	O
predictions	O
made	O
from	O
recursions	O
(	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
The	O
ensemble	O
output	O
significantly	O
improves	O
performances	O
of	O
individual	O
predictions	O
.	O
	
subsection	O
:	O
Comparisons	O
with	O
State	O
-	O
of	O
-	O
the	O
-	O
Art	O
Methods	O
	
We	O
provide	O
quantitative	O
and	O
qualitative	O
comparisons	O
.	O
	
For	O
benchmark	O
,	O
we	O
use	O
public	O
code	O
for	O
A	B-Method
+	I-Method
,	O
SRCNN	B-Method
,	O
RFL	B-Method
and	O
SelfEx	B-Method
.	O
	
We	O
deal	O
with	O
luminance	O
components	O
only	O
as	O
similarly	O
done	O
in	O
other	O
methods	O
because	O
human	B-Task
vision	I-Task
is	O
much	O
more	O
sensitive	O
to	O
details	O
in	O
intensity	O
than	O
in	O
color	O
.	O
	
As	O
some	O
methods	O
such	O
as	O
A	B-Method
+	I-Method
and	O
RFL	B-Method
do	O
not	O
predict	O
image	O
boundary	O
,	O
they	O
require	O
cropping	O
pixels	O
near	O
borders	O
.	O
	
For	O
our	O
method	O
,	O
this	O
procedure	O
is	O
unnecessary	O
as	O
our	O
network	O
predicts	O
the	O
full	O
-	O
sized	O
image	O
.	O
	
For	O
fair	O
comparison	O
,	O
however	O
,	O
we	O
also	O
crop	O
pixels	O
to	O
the	O
same	O
amount	O
.	O
	
PSNRs	B-Metric
can	O
be	O
slightly	O
different	O
from	O
original	O
papers	O
as	O
existing	O
methods	O
use	O
slightly	O
different	O
evaluation	B-Method
frameworks	I-Method
.	O
	
We	O
use	O
the	O
public	B-Metric
evaluation	I-Metric
code	I-Metric
used	O
in	O
.	O
	
In	O
Table	O
[	O
reference	O
]	O
,	O
we	O
provide	O
a	O
summary	O
of	O
quantitative	O
evaluation	O
on	O
several	O
datasets	O
.	O
	
Our	O
method	O
outperforms	O
all	O
existing	O
methods	O
in	O
all	O
datasets	O
and	O
scale	O
factors	O
(	O
both	O
PSNR	B-Metric
and	O
SSIM	B-Metric
)	O
.	O
	
In	O
Figures	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
,	O
example	O
images	O
are	O
given	O
.	O
	
Our	O
method	O
produces	O
relatively	O
sharp	O
edges	O
respective	O
to	O
patterns	O
.	O
	
In	O
contrast	O
,	O
edges	O
in	O
other	O
images	O
are	O
blurred	O
.	O
	
Our	O
method	O
takes	O
a	O
second	O
to	O
process	O
a	O
image	O
on	O
a	O
GPU	O
Titan	O
X.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
work	O
,	O
we	O
have	O
presented	O
a	O
super	B-Task
-	I-Task
resolution	I-Task
method	O
using	O
a	O
deeply	O
-	O
recursive	O
convolutional	B-Method
network	O
.	O
	
Our	O
network	O
efficiently	O
reuses	O
weight	O
parameters	O
while	O
exploiting	O
a	O
large	O
image	O
context	O
.	O
	
To	O
ease	O
the	O
difficulty	O
of	O
training	O
the	O
model	O
,	O
we	O
use	O
recursive	B-Method
-	I-Method
supervision	I-Method
and	O
skip	B-Method
-	I-Method
connection	I-Method
.	O
	
We	O
have	O
demonstrated	O
that	O
our	O
method	O
outperforms	O
existing	O
methods	O
by	O
a	O
large	O
margin	O
on	O
benchmarked	O
images	O
.	O
	
In	O
the	O
future	O
,	O
one	O
can	O
try	O
more	O
recursions	O
in	O
order	O
to	O
use	O
image	O
-	O
level	O
context	O
.	O
	
We	O
believe	O
our	O
approach	O
is	O
readily	O
applicable	O
to	O
other	O
image	B-Task
restoration	I-Task
problems	I-Task
such	O
as	O
denoising	B-Task
and	O
compression	O
artifact	O
removal	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
A	O
Multi	B-Method
-	I-Method
sentiment	I-Method
-	I-Method
resource	I-Method
Enhanced	I-Method
Attention	I-Method
Network	I-Method
for	O
Sentiment	B-Task
Classification	I-Task
	
Deep	B-Method
learning	I-Method
approaches	I-Method
for	O
sentiment	B-Task
classification	I-Task
do	O
not	O
fully	O
exploit	O
sentiment	O
linguistic	O
knowledge	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
Multi	B-Method
-	I-Method
sentiment	I-Method
-	I-Method
resource	I-Method
Enhanced	I-Method
Attention	I-Method
Network	I-Method
(	O
MEAN	B-Method
)	O
to	O
alleviate	O
the	O
problem	O
by	O
integrating	O
three	O
kinds	O
of	O
sentiment	O
linguistic	O
knowledge	O
(	O
e.g.	O
,	O
sentiment	O
lexicon	O
,	O
negation	O
words	O
,	O
intensity	O
words	O
)	O
into	O
the	O
deep	B-Method
neural	I-Method
network	I-Method
via	O
attention	B-Method
mechanisms	I-Method
.	O
	
By	O
using	O
various	O
types	O
of	O
sentiment	O
resources	O
,	O
MEAN	B-Method
utilizes	O
sentiment	O
-	O
relevant	O
information	O
from	O
different	O
representation	O
sub	O
-	O
spaces	O
,	O
which	O
makes	O
it	O
more	O
effective	O
to	O
capture	O
the	O
overall	O
semantics	O
of	O
the	O
sentiment	O
,	O
negation	O
and	O
intensity	O
words	O
for	O
sentiment	B-Task
prediction	I-Task
.	O
	
The	O
experimental	O
results	O
demonstrate	O
that	O
MEAN	B-Method
has	O
robust	O
superiority	O
over	O
strong	O
competitors	O
.	O
	
section	O
:	O
Introduction	O
	
Sentiment	B-Task
classification	I-Task
is	O
an	O
important	O
task	O
of	O
natural	B-Method
language	I-Method
processing	I-Method
(	I-Method
NLP	I-Method
)	I-Method
,	O
aiming	O
to	O
classify	O
the	O
sentiment	O
polarity	O
of	O
a	O
given	O
text	O
as	O
positive	O
,	O
negative	O
,	O
or	O
more	O
fine	O
-	O
grained	O
classes	O
.	O
	
It	O
has	O
obtained	O
considerable	O
attention	O
due	O
to	O
its	O
broad	O
applications	O
in	O
natural	B-Method
language	I-Method
processing	I-Method
.	O
	
Most	O
existing	O
studies	O
set	O
up	O
sentiment	B-Method
classifiers	I-Method
using	O
supervised	B-Method
machine	I-Method
learning	I-Method
approaches	I-Method
,	O
such	O
as	O
support	B-Method
vector	I-Method
machine	I-Method
(	I-Method
SVM	I-Method
)	I-Method
,	O
convolutional	B-Method
neural	I-Method
network	I-Method
(	I-Method
CNN	I-Method
)	O
,	O
long	B-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
(	I-Method
LSTM	I-Method
)	I-Method
,	O
Tree	B-Method
-	I-Method
LSTM	I-Method
,	O
and	O
attention	B-Method
-	I-Method
based	I-Method
methods	I-Method
.	O
	
Despite	O
the	O
remarkable	O
progress	O
made	O
by	O
the	O
previous	O
work	O
,	O
we	O
argue	O
that	O
sentiment	B-Task
analysis	I-Task
still	O
remains	O
a	O
challenge	O
.	O
	
Sentiment	B-Method
resources	I-Method
including	O
sentiment	B-Method
lexicon	I-Method
,	O
negation	B-Method
words	I-Method
,	O
intensity	B-Method
words	I-Method
play	O
a	O
crucial	O
role	O
in	O
traditional	O
sentiment	B-Method
classification	I-Method
approaches	I-Method
.	O
	
Despite	O
its	O
usefulness	O
,	O
to	O
date	O
,	O
the	O
sentiment	O
linguistic	O
knowledge	O
has	O
been	O
underutilized	O
in	O
most	O
recent	O
deep	B-Method
neural	I-Method
network	I-Method
models	I-Method
(	O
e.g.	O
,	O
CNNs	B-Method
and	O
LSTMs	B-Method
)	O
.	O
	
In	O
this	O
work	O
,	O
we	O
propose	O
a	O
Multi	B-Method
-	I-Method
sentiment	I-Method
-	I-Method
resource	I-Method
Enhanced	I-Method
Attention	I-Method
Network	I-Method
(	O
MEAN	B-Method
)	O
for	O
sentence	B-Task
-	I-Task
level	I-Task
sentiment	I-Task
classification	I-Task
to	O
integrate	O
many	O
kinds	O
of	O
sentiment	O
linguistic	O
knowledge	O
into	O
deep	B-Method
neural	I-Method
networks	I-Method
via	O
multi	B-Method
-	I-Method
path	I-Method
attention	I-Method
mechanism	I-Method
.	O
	
Specifically	O
,	O
we	O
first	O
design	O
a	O
coupled	B-Method
word	I-Method
embedding	I-Method
module	I-Method
to	O
model	O
the	O
word	B-Method
representation	I-Method
from	O
character	O
-	O
level	O
and	O
word	O
-	O
level	O
semantics	O
.	O
	
This	O
can	O
help	O
to	O
capture	O
the	O
morphological	O
information	O
such	O
as	O
prefixes	O
and	O
suffixes	O
of	O
words	O
.	O
	
Then	O
,	O
we	O
propose	O
a	O
multi	B-Method
-	I-Method
sentiment	I-Method
-	I-Method
resource	I-Method
attention	I-Method
module	I-Method
to	O
learn	O
more	O
comprehensive	O
and	O
meaningful	B-Task
sentiment	I-Task
-	I-Task
specific	I-Task
sentence	I-Task
representation	I-Task
by	O
using	O
the	O
three	O
types	O
of	O
sentiment	O
resource	O
words	O
as	O
attention	O
sources	O
attending	O
to	O
the	O
context	O
words	O
respectively	O
.	O
	
In	O
this	O
way	O
,	O
we	O
can	O
attend	O
to	O
different	O
sentiment	O
-	O
relevant	O
information	O
from	O
different	O
representation	O
subspaces	O
implied	O
by	O
different	O
types	O
of	O
sentiment	O
sources	O
and	O
capture	O
the	O
overall	O
semantics	O
of	O
the	O
sentiment	O
,	O
negation	O
and	O
intensity	O
words	O
for	O
sentiment	B-Task
prediction	I-Task
.	O
	
The	O
main	O
contributions	O
of	O
this	O
paper	O
are	O
summarized	O
as	O
follows	O
.	O
	
First	O
,	O
we	O
design	O
a	O
coupled	B-Method
word	I-Method
embedding	I-Method
obtained	O
from	O
character	B-Method
-	I-Method
level	I-Method
embedding	I-Method
and	O
word	B-Method
-	I-Method
level	I-Method
embedding	I-Method
to	O
capture	O
both	O
the	O
character	O
-	O
level	O
morphological	O
information	O
and	O
word	O
-	O
level	O
semantics	O
.	O
	
Second	O
,	O
we	O
propose	O
a	O
multi	B-Method
-	I-Method
sentiment	I-Method
-	I-Method
resource	I-Method
attention	I-Method
module	I-Method
to	O
learn	O
more	O
comprehensive	O
sentiment	B-Task
-	I-Task
specific	I-Task
sentence	I-Task
representation	I-Task
from	O
multiply	O
subspaces	O
implied	O
by	O
three	O
kinds	O
of	O
sentiment	O
resources	O
including	O
sentiment	O
lexicon	O
,	O
intensity	O
words	O
,	O
negation	O
words	O
.	O
	
Finally	O
,	O
the	O
experimental	O
results	O
show	O
that	O
MEAN	B-Method
consistently	O
outperforms	O
competitive	O
methods	O
.	O
	
section	O
:	O
Model	O
	
Our	O
proposed	O
MEAN	B-Method
model	O
consists	O
of	O
three	O
key	O
components	O
:	O
coupled	B-Method
word	I-Method
embedding	I-Method
module	I-Method
,	O
multi	B-Method
-	I-Method
sentiment	I-Method
-	I-Method
resource	I-Method
attention	I-Method
module	I-Method
,	O
sentence	B-Method
classifier	I-Method
module	I-Method
.	O
	
In	O
the	O
rest	O
of	O
this	O
section	O
,	O
we	O
will	O
elaborate	O
these	O
three	O
parts	O
in	O
details	O
.	O
	
The	O
overall	O
framework	O
is	O
shown	O
in	O
Figure	O
1	O
.	O
	
subsection	O
:	O
Coupled	B-Method
Word	I-Method
Embedding	I-Method
	
To	O
exploit	O
the	O
sentiment	O
-	O
related	O
morphological	O
information	O
implied	O
by	O
some	O
prefixes	O
and	O
suffixes	O
of	O
words	O
(	O
such	O
as	O
“	O
Non	O
-	O
”	O
,	O
“	O
	
In	O
-	O
”	O
	
,	O
“	O
Im	O
-	O
”	O
)	O
,	O
we	O
design	O
a	O
coupled	B-Method
word	I-Method
embedding	I-Method
learned	O
from	O
character	B-Method
-	I-Method
level	I-Method
embedding	I-Method
and	O
word	B-Method
-	I-Method
level	I-Method
embedding	I-Method
.	O
	
We	O
first	O
design	O
a	O
character	B-Method
-	I-Method
level	I-Method
convolution	I-Method
neural	I-Method
network	I-Method
(	I-Method
Char	I-Method
-	I-Method
CNN	I-Method
)	O
to	O
obtain	O
character	B-Task
-	I-Task
level	I-Task
embedding	I-Task
.	O
	
Different	O
from	O
,	O
the	O
designed	O
Char	B-Method
-	I-Method
CNN	I-Method
is	O
a	O
fully	B-Method
convolutional	I-Method
network	I-Method
without	O
max	B-Method
-	I-Method
pooling	I-Method
layer	I-Method
to	O
capture	O
better	O
semantic	O
information	O
in	O
character	O
chunk	O
.	O
	
Specifically	O
,	O
we	O
first	O
input	O
one	O
-	O
hot	O
-	O
encoding	O
character	O
sequences	O
to	O
a	O
convolution	B-Method
layer	I-Method
to	O
enhance	O
the	O
semantic	B-Method
nonlinear	I-Method
representation	I-Method
ability	O
of	O
our	O
model	O
,	O
and	O
the	O
output	O
is	O
then	O
fed	O
into	O
a	O
multi	O
-	O
gram	O
(	O
i.e.	O
different	O
window	O
sizes	O
)	O
convolution	B-Method
layer	I-Method
to	O
capture	O
different	O
local	O
character	O
chunk	O
information	O
.	O
	
For	O
word	B-Task
-	I-Task
level	I-Task
embedding	I-Task
,	O
we	O
use	O
pre	O
-	O
trained	O
word	O
vectors	O
,	O
GloVe	B-Method
,	O
to	O
map	O
each	O
word	O
to	O
a	O
low	O
-	O
dimensional	O
vector	O
space	O
.	O
	
Finally	O
,	O
each	O
word	O
is	O
represented	O
as	O
a	O
concatenation	O
of	O
the	O
character	B-Method
-	I-Method
level	I-Method
embedding	I-Method
and	O
word	B-Method
-	I-Method
level	I-Method
embedding	I-Method
.	O
	
This	O
is	O
performed	O
on	O
the	O
context	O
words	O
and	O
the	O
three	O
types	O
of	O
sentiment	O
resource	O
words	O
,	O
resulting	O
in	O
four	O
final	O
coupled	B-Method
word	I-Method
embedding	I-Method
matrices	I-Method
:	O
the	O
for	O
context	O
words	O
,	O
the	O
for	O
sentiment	O
words	O
,	O
the	O
for	O
intensity	O
words	O
,	O
the	O
for	O
negation	O
words	O
.	O
	
Here	O
,	O
are	O
the	O
length	O
of	O
the	O
corresponding	O
items	O
respectively	O
,	O
and	O
is	O
the	O
embedding	O
dimension	O
.	O
	
Each	O
is	O
normalized	O
to	O
better	O
calculate	O
the	O
following	O
word	O
correlation	O
.	O
	
subsection	O
:	O
Multi	B-Method
-	I-Method
sentiment	I-Method
-	I-Method
resource	I-Method
Attention	I-Method
Module	I-Method
	
After	O
obtaining	O
the	O
coupled	B-Method
word	I-Method
embedding	I-Method
,	O
we	O
propose	O
a	O
multi	B-Method
-	I-Method
sentiment	I-Method
-	I-Method
resource	I-Method
attention	I-Method
mechanism	I-Method
to	O
help	O
select	O
the	O
crucial	O
sentiment	O
-	O
resource	O
-	O
relevant	O
context	O
words	O
to	O
build	O
the	O
sentiment	B-Task
-	I-Task
specific	I-Task
sentence	I-Task
representation	I-Task
.	O
	
Concretely	O
,	O
we	O
use	O
the	O
three	O
kinds	O
of	O
sentiment	O
resource	O
words	O
as	O
attention	O
sources	O
to	O
attend	O
to	O
the	O
context	O
words	O
respectively	O
,	O
which	O
is	O
beneficial	O
to	O
capture	O
different	O
sentiment	O
-	O
relevant	O
context	O
words	O
corresponding	O
to	O
different	O
types	O
of	O
sentiment	O
sources	O
.	O
	
For	O
example	O
,	O
using	O
sentiment	O
words	O
as	O
attention	O
source	O
attending	O
to	O
the	O
context	O
words	O
helps	O
form	O
the	O
sentiment	B-Method
-	I-Method
word	I-Method
-	I-Method
enhanced	I-Method
sentence	I-Method
representation	I-Method
.	O
	
Then	O
,	O
we	O
combine	O
the	O
three	O
kinds	O
of	O
sentiment	B-Method
-	I-Method
resource	I-Method
-	I-Method
enhanced	I-Method
sentence	I-Method
representations	I-Method
to	O
learn	O
the	O
final	O
sentiment	B-Task
-	I-Task
specific	I-Task
sentence	I-Task
representation	I-Task
.	O
	
We	O
design	O
three	O
types	O
of	O
attention	B-Method
mechanisms	I-Method
:	O
sentiment	O
attention	O
,	O
intensity	O
attention	O
,	O
negation	O
attention	O
to	O
model	O
the	O
three	O
kinds	O
of	O
sentiment	O
resources	O
,	O
respectively	O
.	O
	
In	O
the	O
following	O
,	O
we	O
will	O
elaborate	O
the	O
three	O
types	O
of	O
attention	B-Method
mechanisms	I-Method
in	O
details	O
.	O
	
First	O
,	O
inspired	O
by	O
,	O
we	O
expect	O
to	O
establish	O
the	O
word	O
-	O
level	O
relationship	O
between	O
the	O
context	O
words	O
and	O
different	O
kinds	O
of	O
sentiment	O
resource	O
words	O
.	O
	
To	O
be	O
specific	O
,	O
we	O
define	O
the	O
dot	O
products	O
among	O
the	O
context	O
words	O
and	O
the	O
three	O
kinds	O
of	O
sentiment	O
resource	O
words	O
as	O
correlation	O
matrices	O
.	O
	
Mathematically	O
,	O
the	O
detailed	O
formulation	O
is	O
described	O
as	O
follows	O
.	O
	
where	O
are	O
the	O
correlation	O
matrices	O
to	O
measure	O
the	O
relationship	O
among	O
the	O
context	O
words	O
and	O
the	O
three	O
kinds	O
of	O
sentiment	O
resource	O
words	O
,	O
representing	O
the	O
relevance	O
between	O
the	O
context	O
words	O
and	O
the	O
sentiment	O
resource	O
word	O
.	O
	
After	O
obtaining	O
the	O
correlation	O
matrices	O
,	O
we	O
can	O
compute	O
the	O
context	O
-	O
word	O
-	O
relevant	O
sentiment	O
word	O
representation	O
matrix	O
,	O
the	O
context	O
-	O
word	O
-	O
relevant	O
intensity	O
word	O
representation	O
matrix	O
,	O
the	O
context	O
-	O
word	O
-	O
relevant	O
negation	O
word	O
representation	O
matrix	O
by	O
the	O
dot	O
products	O
among	O
the	O
context	O
words	O
and	O
different	O
types	O
of	O
corresponding	O
correlation	O
matrices	O
.	O
	
Meanwhile	O
,	O
we	O
can	O
also	O
obtain	O
the	O
sentiment	O
-	O
word	O
-	O
relevant	O
context	O
word	O
representation	O
matrix	O
by	O
the	O
dot	O
product	O
between	O
the	O
correlation	O
matrix	O
and	O
the	O
sentiment	O
words	O
,	O
the	O
intensity	B-Method
-	I-Method
word	I-Method
-	I-Method
relevant	I-Method
context	I-Method
word	I-Method
representation	I-Method
matrix	I-Method
by	O
the	O
dot	O
product	O
between	O
the	O
intensity	O
words	O
and	O
the	O
correlation	O
matrix	O
,	O
the	O
negation	B-Method
-	I-Method
word	I-Method
-	I-Method
relevant	I-Method
context	I-Method
word	I-Method
representation	I-Method
matrix	I-Method
by	O
the	O
dot	O
product	O
between	O
the	O
negation	O
words	O
and	O
the	O
correlation	O
matrix	O
.	O
	
The	O
detailed	O
formulas	O
are	O
presented	O
as	O
follows	O
:	O
The	O
final	O
enhanced	O
context	O
word	O
representation	O
matrix	O
is	O
computed	O
as	O
:	O
Next	O
,	O
we	O
employ	O
four	O
independent	O
GRU	B-Method
networks	I-Method
to	O
encode	O
hidden	O
states	O
of	O
the	O
context	O
words	O
and	O
the	O
three	O
types	O
of	O
sentiment	O
resource	O
words	O
,	O
respectively	O
.	O
	
Formally	O
,	O
given	O
the	O
word	B-Method
embedding	I-Method
,	O
the	O
hidden	O
state	O
matrices	O
can	O
be	O
obtained	O
as	O
follows	O
:	O
	
After	O
obtaining	O
the	O
hidden	O
state	O
matrices	O
,	O
the	O
sentiment	B-Method
-	I-Method
word	I-Method
-	I-Method
enhanced	I-Method
sentence	I-Method
representation	I-Method
can	O
be	O
computed	O
as	O
:	O
where	O
denotes	O
the	O
mean	B-Method
-	I-Method
pooling	I-Method
operation	I-Method
towards	O
,	O
is	O
the	O
attention	B-Method
function	I-Method
that	O
calculates	O
the	O
importance	O
of	O
the	O
-	O
th	O
word	O
in	O
the	O
context	O
and	O
indicates	O
the	O
importance	O
of	O
the	O
-	O
th	O
word	O
in	O
the	O
context	O
,	O
and	O
are	O
learnable	O
parameters	O
.	O
	
Similarly	O
,	O
with	O
the	O
hidden	O
states	O
and	O
for	O
the	O
intensity	O
words	O
and	O
the	O
negation	O
words	O
as	O
attention	O
sources	O
,	O
we	O
can	O
obtain	O
the	O
intensity	B-Method
-	I-Method
word	I-Method
-	I-Method
enhanced	I-Method
sentence	I-Method
representation	I-Method
and	O
the	O
negation	B-Method
-	I-Method
word	I-Method
-	I-Method
enhanced	I-Method
sentence	I-Method
representation	I-Method
.	O
	
The	O
final	O
comprehensive	O
sentiment	B-Task
-	I-Task
specific	I-Task
sentence	I-Task
representation	I-Task
is	O
the	O
composition	O
of	O
the	O
above	O
three	O
sentiment	B-Method
-	I-Method
resource	I-Method
-	I-Method
specific	I-Method
sentence	I-Method
representations	I-Method
:	O
	
subsection	O
:	O
Sentence	B-Method
Classifier	I-Method
	
After	O
obtaining	O
the	O
final	O
sentence	B-Method
representation	I-Method
,	O
we	O
feed	O
it	O
to	O
a	O
softmax	B-Method
layer	I-Method
to	O
predict	O
the	O
sentiment	O
label	O
distribution	O
of	O
a	O
sentence	O
:	O
where	O
is	O
the	O
predicted	O
sentiment	O
distribution	O
of	O
the	O
sentence	O
,	O
C	O
is	O
the	O
number	O
of	O
sentiment	O
labels	O
,	O
and	O
are	O
parameters	O
to	O
be	O
learned	O
.	O
	
For	O
model	B-Task
training	I-Task
,	O
our	O
goal	O
is	O
to	O
minimize	O
the	O
cross	O
entropy	O
between	O
the	O
ground	O
truth	O
and	O
predicted	O
results	O
for	O
all	O
sentences	O
.	O
	
Meanwhile	O
,	O
in	O
order	O
to	O
avoid	O
overfitting	O
,	O
we	O
use	O
dropout	B-Method
strategy	I-Method
to	O
randomly	O
omit	O
parts	O
of	O
the	O
parameters	O
on	O
each	O
training	O
case	O
.	O
	
Inspired	O
by	O
,	O
we	O
also	O
design	O
a	O
penalization	B-Method
term	I-Method
to	O
ensure	O
the	O
diversity	O
of	O
semantics	O
from	O
different	O
sentiment	B-Method
-	I-Method
resource	I-Method
-	I-Method
specific	I-Method
sentence	I-Method
representations	I-Method
,	O
which	O
reduces	O
information	O
redundancy	O
from	O
different	O
sentiment	O
resources	O
attention	O
.	O
	
Specifically	O
,	O
the	O
final	O
loss	B-Metric
function	I-Metric
is	O
presented	O
as	O
follows	O
:	O
	
where	O
is	O
the	O
target	O
sentiment	O
distribution	O
of	O
the	O
sentence	O
,	O
is	O
the	O
prediction	O
probabilities	O
,	O
denotes	O
each	O
parameter	O
to	O
be	O
regularized	O
,	O
is	O
parameter	O
set	O
,	O
is	O
the	O
coefficient	O
for	O
regularization	O
,	O
is	O
a	O
hyper	O
-	O
parameter	O
to	O
balance	O
the	O
three	O
terms	O
,	O
is	O
the	O
weight	O
parameter	O
,	O
denotes	O
the	O
the	O
identity	O
matrix	O
and	O
denotes	O
the	O
Frobenius	O
norm	O
of	O
a	O
matrix	O
.	O
	
Here	O
,	O
the	O
first	O
two	O
terms	O
of	O
the	O
loss	O
function	O
are	O
cross	O
-	O
entropy	O
function	O
of	O
the	O
predicted	O
and	O
true	O
distributions	O
and	O
regularization	B-Method
respectively	O
,	O
and	O
the	O
final	O
term	O
is	O
a	O
penalization	B-Method
term	I-Method
to	O
encourage	O
the	O
diversity	O
of	O
sentiment	O
sources	O
.	O
	
section	O
:	O
Experiments	O
	
subsection	O
:	O
Datasets	O
and	O
Sentiment	B-Method
Resources	I-Method
	
Movie	B-Material
Review	I-Material
(	O
MR	B-Material
)	O
blue	B-Material
and	O
Stanford	B-Material
Sentiment	I-Material
Treebank	I-Material
	
(	O
SST	B-Material
)	O
blue	O
are	O
used	O
to	O
evaluate	O
our	O
model	O
.	O
	
MR	B-Material
dataset	I-Material
has	O
5	O
,	O
331	O
positive	O
samples	O
and	O
5	O
,	O
331	O
negative	O
samples	O
.	O
	
We	O
adopt	O
the	O
same	O
data	O
split	O
as	O
in	O
.	O
	
SST	B-Material
consists	O
of	O
8	O
,	O
545	O
training	O
samples	O
,	O
1	O
,	O
101	O
validation	O
samples	O
,	O
2210	O
test	O
samples	O
.	O
	
Each	O
sample	O
is	O
marked	O
as	O
very	O
negative	O
,	O
negative	O
,	O
neutral	O
,	O
positive	O
,	O
or	O
very	O
positive	O
.	O
	
Sentiment	O
lexicon	O
combines	O
the	O
sentiment	O
words	O
from	O
both	O
and	O
,	O
resulting	O
in	O
10	O
,	O
899	O
sentiment	O
words	O
in	O
total	O
.	O
	
We	O
collect	O
negation	O
and	O
intensity	O
words	O
manually	O
as	O
the	O
number	O
of	O
these	O
words	O
is	O
limited	O
.	O
	
subsection	O
:	O
Baselines	O
	
In	O
order	O
to	O
comprehensively	O
evaluate	O
the	O
performance	O
of	O
our	O
model	O
,	O
we	O
list	O
several	O
baselines	O
for	O
sentence	B-Task
-	I-Task
level	I-Task
sentiment	I-Task
classification	I-Task
.	O
	
RNTN	B-Method
:	O
	
Recursive	B-Method
Tensor	I-Method
Neural	I-Method
Network	I-Method
is	O
used	O
to	O
model	O
correlations	O
between	O
different	O
dimensions	O
of	O
child	O
nodes¡¯	O
vectors	O
.	O
	
LSTM	B-Method
/	I-Method
Bi	I-Method
-	I-Method
LSTM	I-Method
:	O
	
DBLP	O
:	O
journals	O
/	O
corr	O
	
/	O
ChoMGBSB14	O
employs	O
Long	B-Method
Short	I-Method
-	I-Method
Term	I-Method
Memory	I-Method
and	O
the	O
bidirectional	B-Method
variant	I-Method
to	O
capture	O
sequential	O
information	O
.	O
	
Tree	B-Method
-	I-Method
LSTM	I-Method
:	O
	
Memory	O
cells	O
was	O
introduced	O
by	O
Tree	B-Method
-	I-Method
Structured	I-Method
Long	I-Method
Short	I-Method
-	I-Method
Term	I-Method
Memory	I-Method
and	O
gates	O
into	O
tree	B-Method
-	I-Method
structured	I-Method
neural	I-Method
network	I-Method
,	O
which	O
is	O
beneficial	O
to	O
capture	O
semantic	O
relatedness	O
by	O
parsing	O
syntax	O
trees	O
.	O
	
CNN	B-Method
:	O
	
Convolutional	B-Method
Neural	I-Method
Networks	I-Method
is	O
applied	O
to	O
generate	O
task	B-Task
-	I-Task
specific	I-Task
sentence	I-Task
representation	I-Task
.	O
	
NCSL	B-Method
:	O
08teng2016context16	O
designs	O
a	O
Neural	B-Method
Context	I-Method
-	I-Method
Sensitive	I-Method
Lexicon	I-Method
(	O
NSCL	B-Method
)	O
to	O
obtain	O
prior	O
sentiment	O
scores	O
of	O
words	O
in	O
the	O
sentence	O
.	O
	
LR	B-Method
-	I-Method
Bi	I-Method
-	I-Method
LSTM	I-Method
:	O
	
LR_LSTM	B-Method
imposes	O
linguistic	O
roles	O
into	O
neural	B-Method
networks	I-Method
by	O
applying	O
linguistic	B-Method
regularization	I-Method
on	O
intermediate	O
outputs	O
with	O
KL	O
divergence	O
.	O
	
Self	B-Method
-	I-Method
attention	I-Method
:	O
self	B-Method
-	I-Method
attention	I-Method
proposes	O
a	O
self	B-Method
-	I-Method
attention	I-Method
mechanism	I-Method
to	O
learn	O
structured	B-Task
sentence	I-Task
embedding	I-Task
.	O
	
ID	B-Method
-	I-Method
LSTM	I-Method
:	O
uses	O
reinforcement	B-Method
learning	I-Method
to	O
learn	O
structured	B-Task
sentence	I-Task
representation	I-Task
for	O
sentiment	B-Task
classification	I-Task
.	O
	
subsection	O
:	O
Implementation	O
Details	O
	
In	O
our	O
experiments	O
,	O
the	O
dimensions	O
of	O
character	B-Method
-	I-Method
level	I-Method
embedding	I-Method
and	O
word	B-Method
embedding	I-Method
(	O
GloVe	B-Method
)	O
are	O
both	O
set	O
to	O
300	O
.	O
	
Kernel	B-Method
sizes	I-Method
of	O
multi	B-Method
-	I-Method
gram	I-Method
convolution	I-Method
for	O
Char	B-Method
-	I-Method
CNN	I-Method
are	O
set	O
to	O
2	O
,	O
3	O
,	O
respectively	O
.	O
	
All	O
the	O
weight	O
matrices	O
are	O
initialized	O
as	O
random	O
orthogonal	O
matrices	O
,	O
and	O
we	O
set	O
all	O
the	O
bias	O
vectors	O
as	O
zero	O
vectors	O
.	O
	
We	O
optimize	O
the	O
proposed	O
model	O
with	O
RMSprop	B-Method
algorithm	I-Method
,	O
using	O
mini	B-Method
-	I-Method
batch	I-Method
training	I-Method
.	O
	
The	O
size	O
of	O
mini	O
-	O
batch	O
is	O
60	O
.	O
	
The	O
dropout	B-Metric
rate	I-Metric
is	O
0.5	O
,	O
and	O
the	O
coefficient	O
of	O
normalization	O
is	O
set	O
to	O
.	O
	
is	O
set	O
to	O
.	O
	
is	O
set	O
to	O
.	O
	
When	O
there	O
are	O
not	O
sentiment	O
resource	O
words	O
in	O
the	O
sentences	O
,	O
all	O
the	O
context	O
words	O
are	O
treated	O
as	O
sentiment	O
resource	O
words	O
to	O
implement	O
the	O
multi	B-Method
-	I-Method
path	I-Method
self	I-Method
-	I-Method
attention	I-Method
strategy	I-Method
.	O
	
subsection	O
:	O
Experiment	O
Results	O
	
In	O
our	O
experiments	O
,	O
to	O
be	O
consistent	O
with	O
the	O
recent	O
baseline	O
methods	O
,	O
we	O
adopt	O
classification	B-Metric
accuracy	I-Metric
as	O
evaluation	B-Metric
metric	I-Metric
.	O
	
We	O
summarize	O
the	O
experimental	O
results	O
in	O
Table	O
red	O
[	O
reference	O
]	O
.	O
	
Our	O
model	O
has	O
robust	O
superiority	O
over	O
competitors	O
and	O
sets	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
on	O
MR	B-Material
and	O
SST	B-Material
datasets	I-Material
.	O
	
First	O
,	O
our	O
model	O
brings	O
a	O
substantial	O
improvement	O
over	O
the	O
methods	O
that	O
do	O
not	O
leverage	O
sentiment	O
linguistic	O
knowledge	O
(	O
e.g.	O
,	O
RNTN	B-Method
,	O
LSTM	B-Method
,	O
BiLSTM	B-Method
,	O
CNN	B-Method
and	O
ID	B-Method
-	I-Method
LSTM	I-Method
)	O
on	O
both	O
datasets	O
.	O
	
This	O
verifies	O
the	O
effectiveness	O
of	O
leveraging	O
sentiment	O
linguistic	O
resource	O
with	O
the	O
deep	B-Method
learning	I-Method
algorithms	I-Method
.	O
	
Second	O
,	O
our	O
model	O
also	O
consistently	O
outperforms	O
LR	B-Method
-	I-Method
Bi	I-Method
-	I-Method
LSTM	I-Method
which	O
integrates	O
linguistic	O
roles	O
of	O
sentiment	O
,	O
negation	O
and	O
intensity	O
words	O
into	O
neural	B-Method
networks	I-Method
via	O
the	O
linguistic	B-Method
regularization	I-Method
.	O
	
For	O
example	O
,	O
our	O
model	O
achieves	O
improvements	O
over	O
the	O
MR	B-Material
dataset	I-Material
and	O
improvements	O
over	O
the	O
SST	B-Material
dataset	I-Material
compared	O
to	O
LR	B-Method
-	I-Method
Bi	I-Method
-	I-Method
LSTM	I-Method
.	O
	
This	O
is	O
because	O
that	O
MEAN	B-Method
designs	O
attention	B-Method
mechanisms	I-Method
to	O
leverage	O
sentiment	O
resources	O
efficiently	O
,	O
which	O
utilizes	O
the	O
interactive	O
information	O
between	O
context	O
words	O
and	O
sentiment	O
resource	O
words	O
.	O
	
In	O
order	O
to	O
analyze	O
the	O
effectiveness	O
of	O
each	O
component	O
of	O
MEAN	B-Method
,	O
we	O
also	O
report	O
the	O
ablation	B-Metric
test	I-Metric
in	O
terms	O
of	O
discarding	O
character	O
-	O
level	O
embedding	O
(	O
denoted	O
as	O
MEAN	B-Method
w	O
/	O
o	O
CharCNN	O
)	O
and	O
sentiment	O
words	O
/	O
negation	O
words	O
/	O
intensity	O
words	O
(	O
denoted	O
as	O
MEAN	B-Method
w	O
/	O
o	O
sentiment	O
words	O
/	O
negation	O
words	O
/	O
intensity	O
words	O
)	O
.	O
	
All	O
the	O
tested	O
factors	O
contribute	O
greatly	O
to	O
the	O
improvement	O
of	O
the	O
MEAN	B-Method
.	O
	
In	O
particular	O
,	O
the	O
accuracy	B-Metric
decreases	O
sharply	O
when	O
discarding	O
the	O
sentiment	O
words	O
.	O
	
This	O
is	O
within	O
our	O
expectation	O
since	O
sentiment	O
words	O
are	O
vital	O
when	O
classifying	O
the	O
polarity	O
of	O
the	O
sentences	O
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
novel	O
Multi	B-Method
-	I-Method
sentiment	I-Method
-	I-Method
resource	I-Method
Enhanced	I-Method
Attention	I-Method
Network	I-Method
(	O
MEAN	B-Method
)	O
to	O
enhance	O
the	O
performance	O
of	O
sentence	O
-	O
level	O
sentiment	B-Task
analysis	I-Task
,	O
which	O
integrates	O
the	O
sentiment	O
linguistic	O
knowledge	O
into	O
the	O
deep	B-Method
neural	I-Method
network	I-Method
.	O
	
section	O
:	O
Acknowledgements	O
	
We	O
thank	O
all	O
anonymous	O
reviewers	O
for	O
their	O
valuable	O
comments	O
.	O
	
The	O
corresponding	O
author	O
is	O
Yujiu	O
Yang	O
.	O
	
This	O
work	O
was	O
supported	O
in	O
part	O
by	O
the	O
Research	O
Fund	O
for	O
the	O
development	O
of	O
strategic	O
emerging	O
industries	O
by	O
ShenZhen	O
city	O
(	O
	
No	O
.	O
JCYJ20160301151844537	O
and	O
No	O
.	O
	
JCYJ20160331104524983	O
)	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
U	B-Method
-	I-Method
Net	I-Method
:	O
Convolutional	B-Method
Networks	I-Method
for	O
Biomedical	B-Task
Image	I-Task
Segmentation	I-Task
	
There	O
is	O
large	O
consent	O
that	O
successful	O
training	O
of	O
deep	B-Method
networks	I-Method
requires	O
many	O
thousand	O
annotated	O
training	O
samples	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
present	O
a	O
network	B-Method
and	I-Method
training	I-Method
strategy	I-Method
that	O
relies	O
on	O
the	O
strong	O
use	O
of	O
data	B-Task
augmentation	I-Task
to	O
use	O
the	O
available	O
annotated	O
samples	O
more	O
efficiently	O
.	O
	
The	O
architecture	O
consists	O
of	O
a	O
contracting	O
path	O
to	O
capture	O
context	O
and	O
a	O
symmetric	B-Method
expanding	I-Method
path	I-Method
that	O
enables	O
precise	B-Task
localization	I-Task
.	O
	
We	O
show	O
that	O
such	O
a	O
network	O
can	O
be	O
trained	O
end	O
-	O
to	O
-	O
end	O
from	O
very	O
few	O
images	O
and	O
outperforms	O
the	O
prior	O
best	O
method	O
(	O
a	O
sliding	B-Method
-	I-Method
window	I-Method
convolutional	I-Method
network	I-Method
)	O
on	O
the	O
ISBI	B-Task
challenge	I-Task
for	O
segmentation	B-Task
of	O
neuronal	O
structures	O
in	O
electron	O
microscopic	O
stacks	O
.	O
	
Using	O
the	O
same	O
network	O
trained	O
on	O
transmitted	O
light	O
microscopy	B-Method
images	O
(	O
phase	B-Material
contrast	I-Material
and	O
DIC	B-Method
)	O
	
we	O
won	O
the	O
ISBI	B-Task
cell	I-Task
tracking	I-Task
challenge	I-Task
2015	O
in	O
these	O
categories	O
by	O
a	O
large	O
margin	O
.	O
	
Moreover	O
,	O
the	O
network	O
is	O
fast	O
.	O
	
Segmentation	B-Task
of	O
a	O
512x512	O
image	O
takes	O
less	O
than	O
a	O
second	O
on	O
a	O
recent	O
GPU	B-Method
.	O
	
The	O
full	O
implementation	O
(	O
based	O
on	O
Caffe	B-Method
)	O
and	O
the	O
trained	B-Method
networks	I-Method
are	O
available	O
at	O
.	O
	
section	O
:	O
Introduction	O
	
In	O
the	O
last	O
two	O
years	O
,	O
deep	B-Method
convolutional	I-Method
networks	I-Method
have	O
outperformed	O
the	O
state	O
of	O
the	O
art	O
in	O
many	O
visual	B-Task
recognition	I-Task
tasks	I-Task
,	O
e.g.	O
.	O
	
While	O
convolutional	B-Method
networks	I-Method
have	O
already	O
existed	O
for	O
a	O
long	O
time	O
,	O
their	O
success	O
was	O
limited	O
due	O
to	O
the	O
size	O
of	O
the	O
available	O
training	O
sets	O
and	O
the	O
size	O
of	O
the	O
considered	O
networks	O
.	O
	
The	O
breakthrough	O
by	O
Krizhevsky	O
et	O
al	O
.	O
was	O
due	O
to	O
supervised	B-Task
training	I-Task
of	O
a	O
large	O
network	O
with	O
8	O
layers	O
and	O
millions	O
of	O
parameters	O
on	O
the	O
ImageNet	O
dataset	O
with	O
1	O
million	O
training	O
images	O
.	O
	
Since	O
then	O
,	O
even	O
larger	O
and	O
deeper	O
networks	O
have	O
been	O
trained	O
.	O
	
The	O
typical	O
use	O
of	O
convolutional	B-Method
networks	I-Method
is	O
on	O
classification	B-Task
tasks	I-Task
,	O
where	O
the	O
output	O
to	O
an	O
image	O
is	O
a	O
single	O
class	O
label	O
.	O
	
However	O
,	O
in	O
many	O
visual	B-Task
tasks	I-Task
,	O
especially	O
in	O
biomedical	B-Task
image	I-Task
processing	I-Task
,	O
the	O
desired	O
output	O
should	O
include	O
localization	B-Task
,	O
i.e.	O
,	O
a	O
class	O
label	O
is	O
supposed	O
to	O
be	O
assigned	O
to	O
each	O
pixel	O
.	O
	
Moreover	O
,	O
thousands	O
of	O
training	O
images	O
are	O
usually	O
beyond	O
reach	O
in	O
biomedical	B-Task
tasks	I-Task
.	O
	
Hence	O
,	O
Ciresan	O
et	O
al	O
.	O
trained	O
a	O
network	O
in	O
a	O
sliding	B-Method
-	I-Method
window	I-Method
setup	I-Method
to	O
predict	O
the	O
class	O
label	O
of	O
each	O
pixel	O
by	O
providing	O
a	O
local	O
region	O
(	O
patch	O
)	O
around	O
that	O
pixel	O
as	O
input	O
.	O
	
First	O
,	O
this	O
network	O
can	O
localize	O
.	O
	
Secondly	O
,	O
the	O
training	O
data	O
in	O
terms	O
of	O
patches	O
is	O
much	O
larger	O
than	O
the	O
number	O
of	O
training	O
images	O
.	O
	
The	O
resulting	O
network	O
won	O
the	O
EM	B-Task
segmentation	I-Task
challenge	I-Task
at	O
ISBI	B-Material
2012	I-Material
by	O
a	O
large	O
margin	O
.	O
	
Obviously	O
,	O
the	O
strategy	O
in	O
Ciresan	O
et	O
al	O
.	O
has	O
two	O
drawbacks	O
.	O
	
First	O
,	O
it	O
is	O
quite	O
slow	O
because	O
the	O
network	O
must	O
be	O
run	O
separately	O
for	O
each	O
patch	O
,	O
and	O
there	O
is	O
a	O
lot	O
of	O
redundancy	O
due	O
to	O
overlapping	O
patches	O
.	O
	
Secondly	O
,	O
there	O
is	O
a	O
trade	O
-	O
off	O
between	O
localization	B-Metric
accuracy	I-Metric
and	O
the	O
use	O
of	O
context	O
.	O
	
Larger	O
patches	O
require	O
more	O
max	B-Method
-	I-Method
pooling	I-Method
layers	I-Method
that	O
reduce	O
the	O
localization	B-Metric
accuracy	I-Metric
,	O
while	O
small	O
patches	O
allow	O
the	O
network	O
to	O
see	O
only	O
little	O
context	O
.	O
	
More	O
recent	O
approaches	O
proposed	O
a	O
classifier	B-Method
output	I-Method
that	O
takes	O
into	O
account	O
the	O
features	O
from	O
multiple	O
layers	O
.	O
	
Good	O
localization	B-Task
and	O
the	O
use	O
of	O
context	O
are	O
possible	O
at	O
the	O
same	O
time	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
build	O
upon	O
a	O
more	O
elegant	O
architecture	O
,	O
the	O
so	O
-	O
called	O
“	O
fully	B-Method
convolutional	I-Method
network	I-Method
”	O
.	O
	
We	O
modify	O
and	O
extend	O
this	O
architecture	O
such	O
that	O
it	O
works	O
with	O
very	O
few	O
training	O
images	O
and	O
yields	O
more	O
precise	O
segmentations	O
;	O
see	O
[	O
reference	O
]	O
.	O
	
The	O
main	O
idea	O
in	O
is	O
to	O
supplement	O
a	O
usual	O
contracting	B-Method
network	I-Method
by	O
successive	B-Method
layers	I-Method
,	O
where	O
pooling	B-Method
operators	I-Method
are	O
replaced	O
by	O
upsampling	B-Method
operators	I-Method
.	O
	
Hence	O
,	O
these	O
layers	O
increase	O
the	O
resolution	O
of	O
the	O
output	O
.	O
	
In	O
order	O
to	O
localize	O
,	O
high	O
resolution	O
features	O
from	O
the	O
contracting	O
path	O
are	O
combined	O
with	O
the	O
upsampled	O
output	O
.	O
	
A	O
successive	B-Method
convolution	I-Method
layer	I-Method
can	O
then	O
learn	O
to	O
assemble	O
a	O
more	O
precise	O
output	O
based	O
on	O
this	O
information	O
.	O
	
One	O
important	O
modification	O
in	O
our	O
architecture	O
is	O
that	O
in	O
the	O
upsampling	B-Task
part	I-Task
we	O
have	O
also	O
a	O
large	O
number	O
of	O
feature	O
channels	O
,	O
which	O
allow	O
the	O
network	O
to	O
propagate	O
context	O
information	O
to	O
higher	O
resolution	O
layers	O
.	O
	
As	O
a	O
consequence	O
,	O
the	O
expansive	O
path	O
is	O
more	O
or	O
less	O
symmetric	O
to	O
the	O
contracting	O
path	O
,	O
and	O
yields	O
a	O
u	B-Method
-	I-Method
shaped	I-Method
architecture	I-Method
.	O
	
The	O
network	O
does	O
not	O
have	O
any	O
fully	B-Method
connected	I-Method
layers	I-Method
and	O
only	O
uses	O
the	O
valid	O
part	O
of	O
each	O
convolution	O
,	O
i.e.	O
,	O
the	O
segmentation	B-Task
map	I-Task
only	O
contains	O
the	O
pixels	O
,	O
for	O
which	O
the	O
full	O
context	O
is	O
available	O
in	O
the	O
input	O
image	O
.	O
	
This	O
strategy	O
allows	O
the	O
seamless	O
segmentation	B-Task
of	O
arbitrarily	O
large	O
images	O
by	O
an	O
overlap	B-Method
-	I-Method
tile	I-Method
strategy	I-Method
(	O
see	O
[	O
reference	O
]	O
)	O
.	O
	
To	O
predict	O
the	O
pixels	O
in	O
the	O
border	O
region	O
of	O
the	O
image	O
,	O
the	O
missing	O
context	O
is	O
extrapolated	O
by	O
mirroring	O
the	O
input	O
image	O
.	O
	
This	O
tiling	B-Method
strategy	I-Method
is	O
important	O
to	O
apply	O
the	O
network	O
to	O
large	O
images	O
,	O
since	O
otherwise	O
the	O
resolution	O
would	O
be	O
limited	O
by	O
the	O
GPU	O
memory	O
.	O
	
As	O
for	O
our	O
tasks	O
there	O
is	O
very	O
little	O
training	O
data	O
available	O
,	O
we	O
use	O
excessive	O
data	B-Task
augmentation	I-Task
by	O
applying	O
elastic	B-Method
deformations	I-Method
to	O
the	O
available	O
training	O
images	O
.	O
	
This	O
allows	O
the	O
network	O
to	O
learn	O
invariance	O
to	O
such	O
deformations	O
,	O
without	O
the	O
need	O
to	O
see	O
these	O
transformations	O
in	O
the	O
annotated	O
image	O
corpus	O
.	O
	
This	O
is	O
particularly	O
important	O
in	O
biomedical	O
segmentation	B-Task
,	O
since	O
deformation	B-Task
used	O
to	O
be	O
the	O
most	O
common	O
variation	O
in	O
tissue	O
and	O
realistic	O
deformations	O
can	O
be	O
simulated	O
efficiently	O
.	O
	
The	O
value	O
of	O
data	B-Task
augmentation	I-Task
for	O
learning	B-Task
invariance	I-Task
has	O
been	O
shown	O
in	O
Dosovitskiy	O
et	O
al	O
.	O
	
in	O
the	O
scope	O
of	O
unsupervised	B-Task
feature	I-Task
learning	I-Task
.	O
	
Another	O
challenge	O
in	O
many	O
cell	B-Task
segmentation	I-Task
tasks	I-Task
is	O
the	O
separation	O
of	O
touching	O
objects	O
of	O
the	O
same	O
class	O
;	O
see	O
[	O
reference	O
]	O
.	O
	
To	O
this	O
end	O
,	O
we	O
propose	O
the	O
use	O
of	O
a	O
weighted	B-Method
loss	I-Method
,	O
where	O
the	O
separating	O
background	O
labels	O
between	O
touching	O
cells	O
obtain	O
a	O
large	O
weight	O
in	O
the	O
loss	O
function	O
.	O
	
The	O
resulting	O
network	O
is	O
applicable	O
to	O
various	O
biomedical	O
segmentation	B-Task
problems	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
show	O
results	O
on	O
the	O
segmentation	B-Task
of	O
neuronal	O
structures	O
in	O
EM	B-Task
stacks	I-Task
(	O
an	O
ongoing	O
competition	O
started	O
at	O
ISBI	B-Material
2012	I-Material
)	O
,	O
where	O
we	O
outperformed	O
the	O
network	O
of	O
Ciresan	O
et	O
al	O
.	O
.	O
	
Furthermore	O
,	O
we	O
show	O
results	O
for	O
cell	O
segmentation	B-Task
in	O
light	O
microscopy	B-Method
images	O
from	O
the	O
ISBI	O
cell	O
tracking	O
challenge	O
2015	O
.	O
	
Here	O
we	O
won	O
with	O
a	O
large	O
margin	O
on	O
the	O
two	O
most	O
challenging	O
2D	O
transmitted	O
light	O
datasets	O
.	O
	
section	O
:	O
Network	B-Method
Architecture	I-Method
	
The	O
network	B-Method
architecture	I-Method
is	O
illustrated	O
in	O
[	O
reference	O
]	O
.	O
	
It	O
consists	O
of	O
a	O
contracting	O
path	O
(	O
left	O
side	O
)	O
and	O
an	O
expansive	O
path	O
(	O
right	O
side	O
)	O
.	O
	
The	O
contracting	O
path	O
follows	O
the	O
typical	O
architecture	O
of	O
a	O
convolutional	B-Method
network	I-Method
.	O
	
It	O
consists	O
of	O
the	O
repeated	O
application	O
of	O
two	O
3x3	B-Method
convolutions	I-Method
(	O
unpadded	B-Method
convolutions	I-Method
)	O
,	O
each	O
followed	O
by	O
a	O
rectified	B-Method
linear	I-Method
unit	I-Method
(	O
ReLU	B-Method
)	O
and	O
a	O
2x2	O
max	B-Method
pooling	I-Method
operation	I-Method
with	O
stride	O
2	O
for	O
downsampling	B-Task
.	O
	
At	O
each	O
downsampling	O
step	O
we	O
double	O
the	O
number	O
of	O
feature	O
channels	O
.	O
	
Every	O
step	O
in	O
the	O
expansive	O
path	O
consists	O
of	O
an	O
upsampling	B-Method
of	I-Method
the	I-Method
feature	I-Method
map	I-Method
followed	O
by	O
a	O
2x2	B-Method
convolution	I-Method
(	O
“	O
up	B-Method
-	I-Method
convolution	I-Method
”	O
)	O
that	O
halves	O
the	O
number	O
of	O
feature	O
channels	O
,	O
a	O
concatenation	O
with	O
the	O
correspondingly	O
cropped	O
feature	O
map	O
from	O
the	O
contracting	O
path	O
,	O
and	O
two	O
3x3	B-Method
convolutions	I-Method
,	O
each	O
followed	O
by	O
a	O
ReLU	B-Method
.	O
	
The	O
cropping	B-Task
is	O
necessary	O
due	O
to	O
the	O
loss	O
of	O
border	O
pixels	O
in	O
every	O
convolution	O
.	O
	
At	O
the	O
final	O
layer	O
a	O
1x1	B-Method
convolution	I-Method
is	O
used	O
to	O
map	O
each	O
64	O
-	O
component	O
feature	O
vector	O
to	O
the	O
desired	O
number	O
of	O
classes	O
.	O
	
In	O
total	O
the	O
network	O
has	O
23	O
convolutional	B-Method
layers	I-Method
.	O
	
To	O
allow	O
a	O
seamless	O
tiling	O
of	O
the	O
output	O
segmentation	B-Task
map	I-Task
(	O
see	O
[	O
reference	O
]	O
)	O
,	O
it	O
is	O
important	O
to	O
select	O
the	O
input	O
tile	O
size	O
such	O
that	O
all	O
2x2	O
max	B-Method
-	I-Method
pooling	I-Method
operations	I-Method
are	O
applied	O
to	O
a	O
layer	O
with	O
an	O
even	O
x	O
-	O
and	O
y	O
-	O
size	O
.	O
	
section	O
:	O
Training	O
	
The	O
input	O
images	O
and	O
their	O
corresponding	O
segmentation	B-Task
maps	I-Task
are	O
used	O
to	O
train	O
the	O
network	O
with	O
the	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
implementation	I-Method
of	I-Method
Caffe	I-Method
.	O
	
Due	O
to	O
the	O
unpadded	B-Method
convolutions	I-Method
,	O
the	O
output	O
image	O
is	O
smaller	O
than	O
the	O
input	O
by	O
a	O
constant	O
border	O
width	O
.	O
	
To	O
minimize	O
the	O
overhead	O
and	O
make	O
maximum	O
use	O
of	O
the	O
GPU	O
memory	O
,	O
we	O
favor	O
large	O
input	O
tiles	O
over	O
a	O
large	O
batch	O
size	O
and	O
hence	O
reduce	O
the	O
batch	O
to	O
a	O
single	O
image	O
.	O
	
Accordingly	O
we	O
use	O
a	O
high	O
momentum	O
(	O
0.99	O
)	O
such	O
that	O
a	O
large	O
number	O
of	O
the	O
previously	O
seen	O
training	O
samples	O
determine	O
the	O
update	O
in	O
the	O
current	O
optimization	B-Task
step	I-Task
.	O
	
The	O
energy	O
function	O
is	O
computed	O
by	O
a	O
pixel	B-Method
-	I-Method
wise	I-Method
soft	I-Method
-	I-Method
max	I-Method
over	O
the	O
final	O
feature	O
map	O
combined	O
with	O
the	O
cross	B-Metric
entropy	I-Metric
loss	I-Metric
function	I-Metric
.	O
	
The	O
soft	O
-	O
max	O
is	O
defined	O
as	O
where	O
denotes	O
the	O
activation	O
in	O
feature	O
channel	O
at	O
the	O
pixel	O
position	O
with	O
.	O
	
is	O
the	O
number	O
of	O
classes	O
and	O
is	O
the	O
approximated	B-Method
maximum	I-Method
-	I-Method
function	I-Method
.	O
	
I.e.	O
for	O
the	O
that	O
has	O
the	O
maximum	O
activation	O
and	O
for	O
all	O
other	O
.	O
	
The	O
cross	O
entropy	O
then	O
penalizes	O
at	O
each	O
position	O
the	O
deviation	O
of	O
from	O
1	O
using	O
where	O
is	O
the	O
true	O
label	O
of	O
each	O
pixel	O
and	O
is	O
a	O
weight	O
map	O
that	O
we	O
introduced	O
to	O
give	O
some	O
pixels	O
more	O
importance	O
in	O
the	O
training	O
.	O
	
We	O
pre	O
-	O
compute	O
the	O
weight	B-Method
map	I-Method
for	O
each	O
ground	B-Task
truth	I-Task
segmentation	I-Task
to	O
compensate	O
the	O
different	O
frequency	O
of	O
pixels	O
from	O
a	O
certain	O
class	O
in	O
the	O
training	O
data	O
set	O
,	O
and	O
to	O
force	O
the	O
network	O
to	O
learn	O
the	O
small	O
separation	O
borders	O
that	O
we	O
introduce	O
between	O
touching	O
cells	O
(	O
See	O
[	O
reference	O
]	O
	
c	O
and	O
d	O
)	O
.	O
	
a	O
b	O
	
c	O
d	O
	
The	O
separation	O
border	O
is	O
computed	O
using	O
morphological	B-Method
operations	I-Method
.	O
	
The	O
weight	B-Method
map	I-Method
is	O
then	O
computed	O
as	O
where	O
is	O
the	O
weight	O
map	O
to	O
balance	O
the	O
class	O
frequencies	O
,	O
denotes	O
the	O
distance	O
to	O
the	O
border	O
of	O
the	O
nearest	O
cell	O
and	O
the	O
distance	O
to	O
the	O
border	O
of	O
the	O
second	O
nearest	O
cell	O
.	O
	
In	O
our	O
experiments	O
we	O
set	O
and	O
pixels	O
.	O
	
In	O
deep	B-Method
networks	I-Method
with	O
many	O
convolutional	O
layers	O
and	O
different	O
paths	O
through	O
the	O
network	O
,	O
a	O
good	O
initialization	O
of	O
the	O
weights	O
is	O
extremely	O
important	O
.	O
	
Otherwise	O
,	O
parts	O
of	O
the	O
network	O
might	O
give	O
excessive	O
activations	O
,	O
while	O
other	O
parts	O
never	O
contribute	O
.	O
	
Ideally	O
the	O
initial	O
weights	O
should	O
be	O
adapted	O
such	O
that	O
each	O
feature	O
map	O
in	O
the	O
network	O
has	O
approximately	O
unit	O
variance	O
.	O
	
For	O
a	O
network	O
with	O
our	O
architecture	O
(	O
alternating	B-Method
convolution	I-Method
and	I-Method
ReLU	I-Method
layers	I-Method
)	O
this	O
can	O
be	O
achieved	O
by	O
drawing	O
the	O
initial	O
weights	O
from	O
a	O
Gaussian	B-Method
distribution	I-Method
with	O
a	O
standard	O
deviation	O
of	O
,	O
where	O
denotes	O
the	O
number	O
of	O
incoming	O
nodes	O
of	O
one	O
neuron	O
.	O
	
E.g.	O
for	O
a	O
3x3	O
convolution	O
and	O
64	O
feature	O
channels	O
in	O
the	O
previous	O
layer	O
.	O
	
subsection	O
:	O
Data	B-Task
Augmentation	I-Task
	
Data	B-Task
augmentation	I-Task
is	O
essential	O
to	O
teach	O
the	O
network	O
the	O
desired	O
invariance	B-Metric
and	I-Metric
robustness	I-Metric
properties	I-Metric
,	O
when	O
only	O
few	O
training	O
samples	O
are	O
available	O
.	O
	
In	O
case	O
of	O
microscopical	O
images	O
we	O
primarily	O
need	O
shift	O
and	O
rotation	O
invariance	O
as	O
well	O
as	O
robustness	B-Metric
to	O
deformations	O
and	O
gray	O
value	O
variations	O
.	O
	
Especially	O
random	O
elastic	O
deformations	O
of	O
the	O
training	O
samples	O
seem	O
to	O
be	O
the	O
key	O
concept	O
to	O
train	O
a	O
segmentation	B-Task
network	O
with	O
very	O
few	O
annotated	O
images	O
.	O
	
We	O
generate	O
smooth	O
deformations	O
using	O
random	O
displacement	O
vectors	O
on	O
a	O
coarse	O
3	O
by	O
3	O
grid	O
.	O
	
The	O
displacements	O
are	O
sampled	O
from	O
a	O
Gaussian	B-Method
distribution	I-Method
with	O
10	O
pixels	O
standard	O
deviation	O
.	O
	
Per	O
-	O
pixel	O
displacements	O
are	O
then	O
computed	O
using	O
bicubic	B-Method
interpolation	I-Method
.	O
	
Drop	O
-	O
out	O
layers	O
at	O
the	O
end	O
of	O
the	O
contracting	O
path	O
perform	O
further	O
implicit	O
data	B-Task
augmentation	I-Task
.	O
	
section	O
:	O
Experiments	O
	
We	O
demonstrate	O
the	O
application	O
of	O
the	O
u	B-Method
-	I-Method
net	I-Method
to	O
three	O
different	O
segmentation	B-Task
tasks	O
.	O
	
The	O
first	O
task	O
is	O
the	O
segmentation	B-Task
of	O
neuronal	O
structures	O
in	O
electron	B-Task
microscopic	I-Task
recordings	I-Task
.	O
	
An	O
example	O
of	O
the	O
data	O
set	O
and	O
our	O
obtained	O
segmentation	B-Task
is	O
displayed	O
in	O
[	O
reference	O
]	O
.	O
	
We	O
provide	O
the	O
full	O
result	O
as	O
Supplementary	O
Material	O
.	O
	
The	O
data	O
set	O
is	O
provided	O
by	O
the	O
EM	B-Task
segmentation	I-Task
challenge	I-Task
that	O
was	O
started	O
at	O
ISBI	B-Material
2012	I-Material
and	O
is	O
still	O
open	O
for	O
new	O
contributions	O
.	O
	
The	O
training	O
data	O
is	O
a	O
set	O
of	O
30	O
images	O
(	O
512x512	O
pixels	O
)	O
from	O
serial	O
section	O
transmission	O
electron	O
microscopy	B-Method
of	O
the	O
Drosophila	O
first	O
instar	O
larva	O
ventral	O
nerve	O
cord	O
(	O
VNC	O
)	O
.	O
	
Each	O
image	O
comes	O
with	O
a	O
corresponding	O
fully	O
annotated	O
ground	O
truth	O
segmentation	B-Task
map	O
for	O
cells	O
(	O
white	O
)	O
and	O
membranes	O
(	O
black	O
)	O
.	O
	
The	O
test	O
set	O
is	O
publicly	O
available	O
,	O
but	O
its	O
segmentation	B-Task
maps	O
are	O
kept	O
secret	O
.	O
	
An	O
evaluation	O
can	O
be	O
obtained	O
by	O
sending	O
the	O
predicted	O
membrane	O
probability	O
map	O
to	O
the	O
organizers	O
.	O
	
The	O
evaluation	O
is	O
done	O
by	O
thresholding	O
the	O
map	O
at	O
10	O
different	O
levels	O
and	O
computation	O
of	O
the	O
“	O
warping	B-Metric
error	I-Metric
”	I-Metric
,	O
the	O
“	O
Rand	B-Metric
error	I-Metric
”	I-Metric
and	O
the	O
“	O
pixel	B-Metric
error	I-Metric
”	I-Metric
.	O
	
The	O
u	B-Method
-	I-Method
net	I-Method
(	O
averaged	O
over	O
7	O
rotated	O
versions	O
of	O
the	O
input	O
data	O
)	O
achieves	O
without	O
any	O
further	O
pre	O
-	O
or	O
postprocessing	O
a	O
warping	B-Metric
error	I-Metric
of	O
0.0003529	O
(	O
the	O
new	O
best	O
score	O
,	O
	
see	O
[	O
reference	O
]	O
)	O
and	O
a	O
rand	B-Metric
-	I-Metric
error	I-Metric
of	O
0.0382	O
.	O
	
This	O
is	O
significantly	O
better	O
than	O
the	O
sliding	B-Method
-	I-Method
window	I-Method
convolutional	I-Method
network	I-Method
result	O
by	O
Ciresan	O
et	O
al	O
.	O
,	O
whose	O
best	O
submission	O
had	O
a	O
warping	B-Metric
error	I-Metric
of	O
0.000420	O
and	O
a	O
rand	B-Metric
error	I-Metric
of	O
0.0504	O
.	O
	
In	O
terms	O
of	O
rand	B-Metric
error	I-Metric
the	O
only	O
better	O
performing	O
algorithms	O
on	O
this	O
data	O
set	O
use	O
highly	O
data	O
set	O
specific	O
post	B-Method
-	I-Method
processing	I-Method
methods	I-Method
applied	O
to	O
the	O
probability	O
map	O
of	O
Ciresan	O
et	O
al	O
.	O
.	O
	
We	O
also	O
applied	O
the	O
u	B-Method
-	I-Method
net	I-Method
to	O
a	O
cell	O
segmentation	B-Task
task	O
in	O
light	O
microscopic	O
images	O
.	O
	
This	O
segmenation	B-Task
task	I-Task
is	O
part	O
of	O
the	O
ISBI	B-Task
cell	I-Task
tracking	I-Task
challenge	I-Task
2014	O
and	O
2015	O
.	O
	
The	O
first	O
data	O
set	O
“	O
	
PhC	B-Material
-	I-Material
U373	I-Material
”	I-Material
contains	O
Glioblastoma	O
-	O
astrocytoma	O
U373	O
cells	O
on	O
a	O
polyacrylimide	O
substrate	O
recorded	O
by	O
phase	B-Material
contrast	I-Material
microscopy	I-Method
(	O
see	O
[	O
reference	O
]	O
a	O
,	O
b	O
and	O
Supp	O
.	O
	
Material	O
)	O
.	O
	
It	O
contains	O
35	O
partially	O
annotated	O
training	O
images	O
.	O
	
a	O
b	O
c	O
d	O
	
Here	O
we	O
achieve	O
an	O
average	O
IOU	B-Metric
(	O
“	O
intersection	B-Metric
over	I-Metric
union	I-Metric
”	I-Metric
)	O
of	O
92	O
%	O
,	O
which	O
is	O
significantly	O
better	O
than	O
the	O
second	O
best	O
algorithm	O
with	O
83	O
%	O
(	O
see	O
[	O
reference	O
]	O
)	O
.	O
	
The	O
second	O
data	O
set	O
“	O
DIC	B-Material
-	I-Material
HeLa	I-Material
”	O
are	O
HeLa	O
cells	O
on	O
a	O
flat	O
glass	O
recorded	O
by	O
differential	B-Method
interference	I-Method
contrast	I-Method
(	O
DIC	B-Method
)	O
microscopy	B-Method
(	O
	
see	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
c	O
,	O
d	O
and	O
Supp	O
.	O
	
Material	O
)	O
.	O
	
It	O
contains	O
20	O
partially	O
annotated	O
training	O
images	O
.	O
	
Here	O
we	O
achieve	O
an	O
average	O
IOU	B-Metric
of	O
77.5	O
%	O
which	O
is	O
significantly	O
better	O
than	O
the	O
second	O
best	O
algorithm	O
with	O
46	O
%	O
.	O
	
section	O
:	O
Conclusion	O
	
The	O
u	B-Method
-	I-Method
net	I-Method
architecture	I-Method
achieves	O
very	O
good	O
performance	O
on	O
very	O
different	O
biomedical	O
segmentation	B-Task
applications	O
.	O
	
Thanks	O
to	O
data	B-Task
augmentation	I-Task
with	O
elastic	B-Method
deformations	I-Method
,	O
it	O
only	O
needs	O
very	O
few	O
annotated	O
images	O
and	O
has	O
a	O
very	O
reasonable	O
training	B-Metric
time	I-Metric
of	O
only	O
10	O
hours	O
on	O
a	O
NVidia	O
Titan	O
GPU	O
(	O
6	O
GB	O
)	O
.	O
	
We	O
provide	O
the	O
full	O
Caffe	B-Method
-	I-Method
based	I-Method
implementation	I-Method
and	O
the	O
trained	B-Method
networks	I-Method
.	O
	
We	O
are	O
sure	O
that	O
the	O
u	B-Method
-	I-Method
net	I-Method
architecture	I-Method
can	O
be	O
applied	O
easily	O
to	O
many	O
more	O
tasks	O
.	O
	
section	O
:	O
Acknowlegements	O
	
This	O
study	O
was	O
supported	O
by	O
the	O
Excellence	O
Initiative	O
of	O
the	O
German	O
Federal	O
and	O
State	O
governments	O
(	O
EXC	O
294	O
)	O
and	O
by	O
the	O
BMBF	O
(	O
Fkz	O
0316185B	O
)	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Neural	B-Task
Machine	I-Task
Translation	I-Task
by	O
Jointly	B-Task
Learning	I-Task
to	O
Align	B-Task
and	O
Translate	B-Task
	
Neural	O
machine	B-Task
translation	I-Task
is	O
a	O
recently	O
proposed	O
approach	O
to	O
machine	B-Task
translation	I-Task
.	O
	
Unlike	O
the	O
traditional	O
statistical	O
machine	B-Task
translation	I-Task
,	O
the	O
neural	B-Task
machine	I-Task
translation	I-Task
aims	O
at	O
building	O
a	O
single	O
neural	B-Method
network	I-Method
that	O
can	O
be	O
jointly	O
tuned	O
to	O
maximize	O
the	O
translation	B-Metric
performance	I-Metric
.	O
	
The	O
models	O
proposed	O
recently	O
for	O
neural	B-Task
machine	I-Task
translation	I-Task
often	O
belong	O
to	O
a	O
family	O
of	O
encoder	B-Method
–	I-Method
decoders	I-Method
and	O
encode	O
a	O
source	O
sentence	O
into	O
a	O
fixed	O
-	O
length	O
vector	O
from	O
which	O
a	O
decoder	B-Method
generates	O
a	O
translation	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
conjecture	O
that	O
the	O
use	O
of	O
a	O
fixed	O
-	O
length	O
vector	O
is	O
a	O
bottleneck	O
in	O
improving	O
the	O
performance	O
of	O
this	O
basic	O
encoder	B-Method
–	I-Method
decoder	I-Method
architecture	I-Method
,	O
and	O
propose	O
to	O
extend	O
this	O
by	O
allowing	O
a	O
model	O
to	O
automatically	O
(	O
	
soft	O
-)	O
search	O
for	O
parts	O
of	O
a	O
source	O
sentence	O
that	O
are	O
relevant	O
to	O
predicting	O
a	O
target	O
word	O
,	O
without	O
having	O
to	O
form	O
these	O
parts	O
as	O
a	O
hard	O
segment	O
explicitly	O
.	O
	
With	O
this	O
new	O
approach	O
,	O
we	O
achieve	O
a	O
translation	B-Task
performance	O
comparable	O
to	O
the	O
existing	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
phrase	B-Method
-	I-Method
based	I-Method
system	I-Method
on	O
the	O
task	O
of	O
English	B-Task
-	I-Task
to	I-Task
-	I-Task
French	I-Task
translation	I-Task
.	O
	
Furthermore	O
,	O
qualitative	O
analysis	O
reveals	O
that	O
the	O
(	O
soft	O
-)	O
alignments	O
found	O
by	O
the	O
model	O
agree	O
well	O
with	O
our	O
intuition	O
.	O
	
.	O
/	O
figures	O
/	O
	
section	O
:	O
Introduction	O
	
Neural	O
machine	B-Task
translation	I-Task
is	O
a	O
newly	O
emerging	O
approach	O
to	O
machine	B-Task
translation	I-Task
,	O
recently	O
proposed	O
by	O
,	O
and	O
.	O
	
Unlike	O
the	O
traditional	O
phrase	B-Method
-	I-Method
based	I-Method
translation	I-Method
system	I-Method
which	O
consists	O
of	O
many	O
small	O
sub	O
-	O
components	O
that	O
are	O
tuned	O
separately	O
,	O
neural	B-Task
machine	I-Task
translation	I-Task
attempts	O
to	O
build	O
and	O
train	O
a	O
single	O
,	O
large	O
neural	B-Method
network	I-Method
that	O
reads	O
a	O
sentence	O
and	O
outputs	O
a	O
correct	O
translation	O
.	O
	
Most	O
of	O
the	O
proposed	O
neural	B-Method
machine	I-Method
translation	I-Method
models	I-Method
belong	O
to	O
a	O
family	O
of	O
encoder	B-Method
–	I-Method
decoders	I-Method
,	O
with	O
an	O
encoder	B-Method
and	O
a	O
decoder	O
for	O
each	O
language	O
,	O
or	O
involve	O
a	O
language	B-Method
-	I-Method
specific	I-Method
encoder	I-Method
applied	O
to	O
each	O
sentence	O
whose	O
outputs	O
are	O
then	O
compared	O
.	O
	
An	O
encoder	B-Method
neural	I-Method
network	I-Method
reads	O
and	O
encodes	O
a	O
source	O
sentence	O
into	O
a	O
fixed	O
-	O
length	O
vector	O
.	O
	
A	O
decoder	B-Method
then	O
outputs	O
a	O
translation	O
from	O
the	O
encoded	O
vector	O
.	O
	
The	O
whole	O
encoder	B-Method
–	I-Method
decoder	I-Method
system	I-Method
,	O
which	O
consists	O
of	O
the	O
encoder	B-Method
and	O
the	O
decoder	B-Method
for	O
a	O
language	O
pair	O
,	O
is	O
jointly	O
trained	O
to	O
maximize	O
the	O
probability	O
of	O
a	O
correct	O
translation	O
given	O
a	O
source	O
sentence	O
.	O
	
A	O
potential	O
issue	O
with	O
this	O
encoder	B-Method
–	I-Method
decoder	I-Method
approach	I-Method
is	O
that	O
a	O
neural	B-Method
network	I-Method
needs	O
to	O
be	O
able	O
to	O
compress	O
all	O
the	O
necessary	O
information	O
of	O
a	O
source	O
sentence	O
into	O
a	O
fixed	O
-	O
length	O
vector	O
.	O
	
This	O
may	O
make	O
it	O
difficult	O
for	O
the	O
neural	B-Method
network	I-Method
to	O
cope	O
with	O
long	O
sentences	O
,	O
especially	O
those	O
that	O
are	O
longer	O
than	O
the	O
sentences	O
in	O
the	O
training	O
corpus	O
.	O
	
showed	O
that	O
indeed	O
the	O
performance	O
of	O
a	O
basic	O
encoder	B-Method
–	I-Method
decoder	I-Method
deteriorates	O
rapidly	O
as	O
the	O
length	O
of	O
an	O
input	O
sentence	O
increases	O
.	O
	
In	O
order	O
to	O
address	O
this	O
issue	O
,	O
we	O
introduce	O
an	O
extension	O
to	O
the	O
encoder	B-Method
–	I-Method
decoder	I-Method
model	I-Method
which	O
learns	O
to	O
align	O
and	O
translate	O
jointly	O
.	O
	
Each	O
time	O
the	O
proposed	O
model	O
generates	O
a	O
word	O
in	O
a	O
translation	O
,	O
it	O
(	O
soft	O
-)	O
searches	O
for	O
a	O
set	O
of	O
positions	O
in	O
a	O
source	O
sentence	O
where	O
the	O
most	O
relevant	O
information	O
is	O
concentrated	O
.	O
	
The	O
model	O
then	O
predicts	O
a	O
target	O
word	O
based	O
on	O
the	O
context	O
vectors	O
associated	O
with	O
these	O
source	O
positions	O
and	O
all	O
the	O
previous	O
generated	O
target	O
words	O
.	O
	
The	O
most	O
important	O
distinguishing	O
feature	O
of	O
this	O
approach	O
from	O
the	O
basic	O
encoder	B-Method
–	I-Method
decoder	I-Method
is	O
that	O
it	O
does	O
not	O
attempt	O
to	O
encode	O
a	O
whole	O
input	O
sentence	O
into	O
a	O
single	O
fixed	O
-	O
length	O
vector	O
.	O
	
Instead	O
,	O
it	O
encodes	O
the	O
input	O
sentence	O
into	O
a	O
sequence	O
of	O
vectors	O
and	O
chooses	O
a	O
subset	O
of	O
these	O
vectors	O
adaptively	O
while	O
decoding	O
the	O
translation	B-Task
.	O
	
This	O
frees	O
a	O
neural	O
translation	B-Method
model	I-Method
from	O
having	O
to	O
squash	O
all	O
the	O
information	O
of	O
a	O
source	O
sentence	O
,	O
regardless	O
of	O
its	O
length	O
,	O
into	O
a	O
fixed	O
-	O
length	O
vector	O
.	O
	
We	O
show	O
this	O
allows	O
a	O
model	O
to	O
cope	O
better	O
with	O
long	O
sentences	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
show	O
that	O
the	O
proposed	O
approach	O
of	O
jointly	B-Task
learning	I-Task
to	O
align	B-Task
and	O
translate	B-Task
achieves	O
significantly	O
improved	O
translation	B-Metric
performance	I-Metric
over	O
the	O
basic	O
encoder	B-Method
–	I-Method
decoder	I-Method
approach	I-Method
.	O
	
The	O
improvement	O
is	O
more	O
apparent	O
with	O
longer	O
sentences	O
,	O
but	O
can	O
be	O
observed	O
with	O
sentences	O
of	O
any	O
length	O
.	O
	
On	O
the	O
task	O
of	O
English	B-Task
-	I-Task
to	I-Task
-	I-Task
French	I-Task
translation	I-Task
,	O
the	O
proposed	O
approach	O
achieves	O
,	O
with	O
a	O
single	O
model	O
,	O
a	O
translation	B-Task
performance	O
comparable	O
,	O
or	O
close	O
,	O
to	O
the	O
conventional	O
phrase	B-Method
-	I-Method
based	I-Method
system	I-Method
.	O
	
Furthermore	O
,	O
qualitative	O
analysis	O
reveals	O
that	O
the	O
proposed	O
model	O
finds	O
a	O
linguistically	O
plausible	O
(	O
soft	O
-)	O
alignment	O
between	O
a	O
source	O
sentence	O
and	O
the	O
corresponding	O
target	O
sentence	O
.	O
	
section	O
:	O
Background	O
:	O
Neural	B-Task
Machine	I-Task
Translation	I-Task
	
From	O
a	O
probabilistic	O
perspective	O
,	O
translation	B-Task
is	O
equivalent	O
to	O
finding	O
a	O
target	O
sentence	O
that	O
maximizes	O
the	O
conditional	O
probability	O
of	O
given	O
a	O
source	O
sentence	O
,	O
i.e.	O
,	O
.	O
	
In	O
neural	B-Task
machine	I-Task
translation	I-Task
,	O
we	O
fit	O
a	O
parameterized	B-Method
model	I-Method
to	O
maximize	O
the	O
conditional	O
probability	O
of	O
sentence	O
pairs	O
using	O
a	O
parallel	O
training	O
corpus	O
.	O
	
Once	O
the	O
conditional	O
distribution	O
is	O
learned	O
by	O
a	O
translation	B-Method
model	I-Method
,	O
given	O
a	O
source	O
sentence	O
a	O
corresponding	O
translation	O
can	O
be	O
generated	O
by	O
searching	O
for	O
the	O
sentence	O
that	O
maximizes	O
the	O
conditional	O
probability	O
.	O
	
Recently	O
,	O
a	O
number	O
of	O
papers	O
have	O
proposed	O
the	O
use	O
of	O
neural	B-Method
networks	I-Method
to	O
directly	O
learn	O
this	O
conditional	O
distribution	O
.	O
	
This	O
neural	O
machine	B-Task
translation	I-Task
approach	O
typically	O
consists	O
of	O
two	O
components	O
,	O
the	O
first	O
of	O
which	O
encodes	O
a	O
source	O
sentence	O
and	O
the	O
second	O
decodes	O
to	O
a	O
target	O
sentence	O
.	O
	
For	O
instance	O
,	O
two	O
recurrent	B-Method
neural	I-Method
networks	I-Method
(	O
RNN	B-Method
)	O
were	O
used	O
by	O
and	O
to	O
encode	O
a	O
variable	O
-	O
length	O
source	O
sentence	O
into	O
a	O
fixed	O
-	O
length	O
vector	O
and	O
to	O
decode	O
the	O
vector	O
into	O
a	O
variable	O
-	O
length	O
target	O
sentence	O
.	O
	
Despite	O
being	O
a	O
quite	O
new	O
approach	O
,	O
neural	B-Task
machine	I-Task
translation	I-Task
has	O
already	O
shown	O
promising	O
results	O
.	O
	
reported	O
that	O
the	O
neural	B-Task
machine	I-Task
translation	I-Task
based	O
on	O
RNNs	B-Method
with	I-Method
long	I-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
(	I-Method
LSTM	I-Method
)	I-Method
units	I-Method
achieves	O
close	O
to	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
of	O
the	O
conventional	O
phrase	B-Method
-	I-Method
based	I-Method
machine	I-Method
translation	I-Method
system	I-Method
on	O
an	O
English	B-Task
-	I-Task
to	I-Task
-	I-Task
French	I-Task
translation	I-Task
task	I-Task
.	O
	
Adding	O
neural	B-Method
components	I-Method
to	O
existing	O
translation	B-Method
systems	I-Method
,	O
for	O
instance	O
,	O
to	O
score	O
the	O
phrase	O
pairs	O
in	O
the	O
phrase	O
table	O
or	O
to	O
re	O
-	O
rank	O
candidate	O
translations	O
,	O
has	O
allowed	O
to	O
surpass	O
the	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
level	O
.	O
	
subsection	O
:	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
	
Here	O
,	O
we	O
describe	O
briefly	O
the	O
underlying	O
framework	O
,	O
called	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
,	O
proposed	O
by	O
and	O
upon	O
which	O
we	O
build	O
a	O
novel	O
architecture	O
that	O
learns	O
to	O
align	O
and	O
translate	O
simultaneously	O
.	O
	
In	O
the	O
Encoder	B-Method
–	I-Method
Decoder	I-Method
framework	I-Method
,	O
an	O
encoder	B-Method
reads	O
the	O
input	O
sentence	O
,	O
a	O
sequence	O
of	O
vectors	O
,	O
into	O
a	O
vector	O
.	O
	
The	O
most	O
common	O
approach	O
is	O
to	O
use	O
an	O
RNN	B-Method
such	O
that	O
and	O
where	O
is	O
a	O
hidden	O
state	O
at	O
time	O
,	O
and	O
is	O
a	O
vector	O
generated	O
from	O
the	O
sequence	O
of	O
the	O
hidden	O
states	O
.	O
	
and	O
are	O
some	O
nonlinear	O
functions	O
.	O
	
used	O
an	O
LSTM	B-Method
as	O
and	O
,	O
for	O
instance	O
.	O
	
The	O
decoder	B-Method
is	O
often	O
trained	O
to	O
predict	O
the	O
next	O
word	O
given	O
the	O
context	O
vector	O
and	O
all	O
the	O
previously	O
predicted	O
words	O
.	O
	
In	O
other	O
words	O
,	O
the	O
decoder	B-Method
defines	O
a	O
probability	O
over	O
the	O
translation	O
by	O
decomposing	O
the	O
joint	O
probability	O
into	O
the	O
ordered	O
conditionals	O
:	O
where	O
.	O
	
With	O
an	O
RNN	B-Method
,	O
each	O
conditional	O
probability	O
is	O
modeled	O
as	O
where	O
is	O
a	O
nonlinear	O
,	O
potentially	O
multi	O
-	O
layered	O
,	O
function	O
that	O
outputs	O
the	O
probability	O
of	O
,	O
and	O
is	O
the	O
hidden	O
state	O
of	O
the	O
RNN	B-Method
.	O
	
It	O
should	O
be	O
noted	O
that	O
other	O
architectures	O
such	O
as	O
a	O
hybrid	O
of	O
an	O
RNN	B-Method
and	O
a	O
de	B-Method
-	I-Method
convolutional	I-Method
neural	I-Method
network	I-Method
can	O
be	O
used	O
.	O
	
section	O
:	O
Learning	O
to	O
Align	O
and	O
Translate	B-Task
	
In	O
this	O
section	O
,	O
we	O
propose	O
a	O
novel	O
architecture	O
for	O
neural	B-Task
machine	I-Task
translation	I-Task
.	O
	
The	O
new	O
architecture	O
consists	O
of	O
a	O
bidirectional	O
RNN	B-Method
as	O
an	O
encoder	B-Method
(	O
Sec	O
.	O
	
[	O
reference	O
]	O
)	O
and	O
a	O
decoder	B-Method
that	O
emulates	O
searching	O
through	O
a	O
source	O
sentence	O
during	O
decoding	O
a	O
translation	O
(	O
Sec	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
subsection	O
:	O
Decoder	B-Method
:	O
General	O
Description	O
	
In	O
a	O
new	O
model	B-Method
architecture	I-Method
,	O
we	O
define	O
each	O
conditional	O
probability	O
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
	
as	O
:	O
where	O
is	O
an	O
RNN	B-Method
hidden	O
state	O
for	O
time	O
,	O
computed	O
by	O
It	O
should	O
be	O
noted	O
that	O
unlike	O
the	O
existing	O
encoder	B-Method
–	I-Method
decoder	I-Method
approach	I-Method
(	O
see	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
)	O
	
,	O
here	O
the	O
probability	O
is	O
conditioned	O
on	O
a	O
distinct	O
context	O
vector	O
for	O
each	O
target	O
word	O
.	O
	
The	O
context	O
vector	O
depends	O
on	O
a	O
sequence	O
of	O
annotations	O
to	O
which	O
an	O
encoder	B-Method
maps	O
the	O
input	O
sentence	O
.	O
	
Each	O
annotation	O
contains	O
information	O
about	O
the	O
whole	O
input	O
sequence	O
with	O
a	O
strong	O
focus	O
on	O
the	O
parts	O
surrounding	O
the	O
-	O
th	O
word	O
of	O
the	O
input	O
sequence	O
.	O
	
We	O
explain	O
in	O
detail	O
how	O
the	O
annotations	O
are	O
computed	O
in	O
the	O
next	O
section	O
.	O
	
The	O
context	O
vector	O
is	O
,	O
then	O
,	O
computed	O
as	O
a	O
weighted	O
sum	O
of	O
these	O
annotations	O
:	O
The	O
weight	O
of	O
each	O
annotation	O
is	O
computed	O
by	O
where	O
is	O
an	O
alignment	B-Method
model	I-Method
which	O
scores	O
how	O
well	O
the	O
inputs	O
around	O
position	O
and	O
the	O
output	O
at	O
position	O
match	O
.	O
	
The	O
score	O
is	O
based	O
on	O
the	O
RNN	B-Method
hidden	O
state	O
(	O
just	O
before	O
emitting	O
,	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
)	O
and	O
the	O
-	O
th	O
annotation	O
of	O
the	O
input	O
sentence	O
.	O
	
We	O
parametrize	O
the	O
alignment	B-Method
model	I-Method
as	O
a	O
feedforward	B-Method
neural	I-Method
network	I-Method
which	O
is	O
jointly	O
trained	O
with	O
all	O
the	O
other	O
components	O
of	O
the	O
proposed	O
system	O
.	O
	
Note	O
that	O
unlike	O
in	O
traditional	O
machine	B-Task
translation	I-Task
,	O
the	O
alignment	B-Task
is	O
not	O
considered	O
to	O
be	O
a	O
latent	O
variable	O
.	O
	
Instead	O
,	O
the	O
alignment	B-Method
model	I-Method
directly	O
computes	O
a	O
soft	O
alignment	O
,	O
which	O
allows	O
the	O
gradient	O
of	O
the	O
cost	O
function	O
to	O
be	O
backpropagated	O
through	O
.	O
	
This	O
gradient	O
can	O
be	O
used	O
to	O
train	O
the	O
alignment	B-Method
model	I-Method
as	O
well	O
as	O
the	O
whole	O
translation	B-Method
model	I-Method
jointly	O
.	O
	
We	O
can	O
understand	O
the	O
approach	O
of	O
taking	O
a	O
weighted	O
sum	O
of	O
all	O
the	O
annotations	O
as	O
computing	O
an	O
expected	O
annotation	O
,	O
where	O
the	O
expectation	O
is	O
over	O
possible	O
alignments	O
.	O
	
Let	O
be	O
a	O
probability	O
that	O
the	O
target	O
word	O
is	O
aligned	O
to	O
,	O
or	O
translated	O
from	O
,	O
a	O
source	O
word	O
.	O
	
Then	O
,	O
the	O
-	O
th	O
context	O
vector	O
is	O
the	O
expected	O
annotation	O
over	O
all	O
the	O
annotations	O
with	O
probabilities	O
.	O
	
The	O
probability	O
,	O
or	O
its	O
associated	O
energy	O
,	O
reflects	O
the	O
importance	O
of	O
the	O
annotation	O
with	O
respect	O
to	O
the	O
previous	O
hidden	O
state	O
in	O
deciding	O
the	O
next	O
state	O
and	O
generating	O
.	O
	
Intuitively	O
,	O
this	O
implements	O
a	O
mechanism	B-Method
of	I-Method
attention	I-Method
in	O
the	O
decoder	B-Method
.	O
	
The	O
decoder	O
decides	O
parts	O
of	O
the	O
source	O
sentence	O
to	O
pay	O
attention	O
to	O
.	O
	
By	O
letting	O
the	O
decoder	B-Method
have	O
an	O
attention	B-Method
mechanism	I-Method
,	O
we	O
relieve	O
the	O
encoder	O
from	O
the	O
burden	O
of	O
having	O
to	O
encode	O
all	O
information	O
in	O
the	O
source	O
sentence	O
into	O
a	O
fixed	O
-	O
length	O
vector	O
.	O
	
With	O
this	O
new	O
approach	O
the	O
information	O
can	O
be	O
spread	O
throughout	O
the	O
sequence	O
of	O
annotations	O
,	O
which	O
can	O
be	O
selectively	O
retrieved	O
by	O
the	O
decoder	B-Method
accordingly	O
.	O
	
subsection	O
:	O
Encoder	B-Method
:	O
Bidirectional	O
RNN	B-Method
for	O
Annotating	B-Task
Sequences	I-Task
	
The	O
usual	O
RNN	B-Method
,	O
described	O
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
,	O
reads	O
an	O
input	O
sequence	O
in	O
order	O
starting	O
from	O
the	O
first	O
symbol	O
to	O
the	O
last	O
one	O
.	O
	
However	O
,	O
in	O
the	O
proposed	O
scheme	O
,	O
we	O
would	O
like	O
the	O
annotation	O
of	O
each	O
word	O
to	O
summarize	O
not	O
only	O
the	O
preceding	O
words	O
,	O
but	O
also	O
the	O
following	O
words	O
.	O
	
Hence	O
,	O
we	O
propose	O
to	O
use	O
a	O
bidirectional	O
RNN	B-Method
,	O
which	O
has	O
been	O
successfully	O
used	O
recently	O
in	O
speech	B-Task
recognition	I-Task
.	O
	
A	O
BiRNN	B-Method
consists	O
of	O
forward	O
and	O
backward	O
RNN	B-Method
’s	O
.	O
	
The	O
forward	O
RNN	B-Method
reads	O
the	O
input	O
sequence	O
as	O
it	O
is	O
ordered	O
(	O
from	O
to	O
)	O
and	O
calculates	O
a	O
sequence	O
of	O
forward	O
hidden	O
states	O
.	O
	
The	O
backward	O
RNN	B-Method
reads	O
the	O
sequence	O
in	O
the	O
reverse	O
order	O
(	O
from	O
to	O
)	O
,	O
resulting	O
in	O
a	O
sequence	O
of	O
backward	O
hidden	O
states	O
.	O
	
We	O
obtain	O
an	O
annotation	O
for	O
each	O
word	O
by	O
concatenating	O
the	O
forward	O
hidden	O
state	O
and	O
the	O
backward	O
one	O
,	O
i.e.	O
,	O
.	O
	
In	O
this	O
way	O
,	O
the	O
annotation	O
contains	O
the	O
summaries	O
of	O
both	O
the	O
preceding	O
words	O
and	O
the	O
following	O
words	O
.	O
	
Due	O
to	O
the	O
tendency	O
of	O
RNNs	B-Method
to	O
better	O
represent	O
recent	O
inputs	O
,	O
the	O
annotation	O
will	O
be	O
focused	O
on	O
the	O
words	O
around	O
.	O
	
This	O
sequence	O
of	O
annotations	O
is	O
used	O
by	O
the	O
decoder	B-Method
and	O
the	O
alignment	B-Method
model	I-Method
later	O
to	O
compute	O
the	O
context	O
vector	O
(	O
Eqs	O
.	O
(	O
[	O
reference	O
]	O
)	O
	
–	O
(	O
[	O
reference	O
]	O
)	O
)	O
.	O
	
See	O
Fig	O
.	O
	
[	O
reference	O
]	O
for	O
the	O
graphical	O
illustration	O
of	O
the	O
proposed	O
model	O
.	O
	
section	O
:	O
Experiment	O
Settings	O
	
We	O
evaluate	O
the	O
proposed	O
approach	O
on	O
the	O
task	O
of	O
English	B-Task
-	I-Task
to	I-Task
-	I-Task
French	I-Task
translation	I-Task
.	O
	
We	O
use	O
the	O
bilingual	O
,	O
parallel	O
corpora	O
provided	O
by	O
ACL	O
WMT	B-Material
’	I-Material
14	I-Material
.	O
	
As	O
a	O
comparison	O
,	O
we	O
also	O
report	O
the	O
performance	O
of	O
an	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
which	O
was	O
proposed	O
recently	O
by	O
.	O
	
We	O
use	O
the	O
same	O
training	O
procedures	O
and	O
the	O
same	O
dataset	O
for	O
both	O
models	O
.	O
	
subsection	O
:	O
Dataset	O
	
WMT	B-Material
’	I-Material
14	I-Material
contains	O
the	O
following	O
English	O
-	O
French	O
parallel	O
corpora	O
:	O
Europarl	O
(	O
61	O
M	O
words	O
)	O
,	O
news	O
commentary	O
(	O
5.5	O
M	O
)	O
,	O
UN	O
(	O
421	O
M	O
)	O
and	O
two	O
crawled	O
corpora	O
of	O
90	O
M	O
and	O
272.5	O
M	O
words	O
respectively	O
,	O
totaling	O
850	O
M	O
words	O
.	O
	
Following	O
the	O
procedure	O
described	O
in	O
,	O
we	O
reduce	O
the	O
size	O
of	O
the	O
combined	O
corpus	O
to	O
have	O
348	O
M	O
words	O
using	O
the	O
data	B-Method
selection	I-Method
method	I-Method
by	O
.	O
	
We	O
do	O
not	O
use	O
any	O
monolingual	O
data	O
other	O
than	O
the	O
mentioned	O
parallel	O
corpora	O
,	O
although	O
it	O
may	O
be	O
possible	O
to	O
use	O
a	O
much	O
larger	O
monolingual	O
corpus	O
to	O
pretrain	O
an	O
encoder	B-Method
.	O
	
We	O
concatenate	O
news	O
-	O
test	O
-	O
2012	O
and	O
news	O
-	O
test	O
-	O
2013	O
to	O
make	O
a	O
development	O
(	O
validation	O
)	O
set	O
,	O
and	O
evaluate	O
the	O
models	O
on	O
the	O
test	O
set	O
(	O
news	O
-	O
test	O
-	O
2014	O
)	O
from	O
WMT	B-Material
’	I-Material
14	I-Material
,	O
which	O
consists	O
of	O
3003	O
sentences	O
not	O
present	O
in	O
the	O
training	O
data	O
.	O
	
After	O
a	O
usual	O
tokenization	B-Method
,	O
we	O
use	O
a	O
shortlist	O
of	O
30	O
,	O
000	O
most	O
frequent	O
words	O
in	O
each	O
language	O
to	O
train	O
our	O
models	O
.	O
	
Any	O
word	O
not	O
included	O
in	O
the	O
shortlist	O
is	O
mapped	O
to	O
a	O
special	O
token	O
(	O
)	O
.	O
	
We	O
do	O
not	O
apply	O
any	O
other	O
special	O
preprocessing	B-Method
,	O
such	O
as	O
lowercasing	B-Method
or	O
stemming	B-Method
,	O
to	O
the	O
data	O
.	O
	
(	O
a	O
)	O
(	O
b	O
)	O
(	O
c	O
)	O
(	O
d	O
)	O
	
subsection	O
:	O
Models	O
	
We	O
train	O
two	O
types	O
of	O
models	O
.	O
	
The	O
first	O
one	O
is	O
an	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
,	O
and	O
the	O
other	O
is	O
the	O
proposed	O
model	O
,	O
to	O
which	O
we	O
refer	O
as	O
RNNsearch	B-Method
.	O
	
We	O
train	O
each	O
model	O
twice	O
:	O
first	O
with	O
the	O
sentences	O
of	O
length	O
up	O
to	O
30	O
words	O
(	O
RNNencdec	B-Method
-	I-Method
30	I-Method
,	O
RNNsearch	B-Method
-	I-Method
30	I-Method
)	O
and	O
then	O
with	O
the	O
sentences	O
of	O
length	O
up	O
to	O
50	O
word	O
(	O
RNNencdec	B-Method
-	I-Method
50	I-Method
,	O
RNNsearch	B-Method
-	I-Method
50	I-Method
)	O
.	O
	
The	O
encoder	B-Method
and	I-Method
decoder	I-Method
of	O
the	O
RNNencdec	B-Method
have	O
1000	O
hidden	O
units	O
each	O
.	O
	
The	O
encoder	B-Method
of	O
the	O
RNNsearch	B-Method
consists	O
of	O
forward	B-Method
and	I-Method
backward	I-Method
recurrent	I-Method
neural	I-Method
networks	I-Method
(	O
RNN	B-Method
)	O
each	O
having	O
1000	O
hidden	O
units	O
.	O
	
Its	O
decoder	B-Method
has	O
1000	O
hidden	O
units	O
.	O
	
In	O
both	O
cases	O
,	O
we	O
use	O
a	O
multilayer	B-Method
network	I-Method
with	O
a	O
single	O
maxout	B-Method
hidden	I-Method
layer	I-Method
to	O
compute	O
the	O
conditional	O
probability	O
of	O
each	O
target	O
word	O
.	O
	
We	O
use	O
a	O
minibatch	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
(	O
SGD	B-Method
)	O
algorithm	O
together	O
with	O
Adadelta	B-Method
to	O
train	O
each	O
model	O
.	O
	
Each	O
SGD	B-Method
update	O
direction	O
is	O
computed	O
using	O
a	O
minibatch	O
of	O
80	O
sentences	O
.	O
	
We	O
trained	O
each	O
model	O
for	O
approximately	O
5	O
days	O
.	O
	
Once	O
a	O
model	O
is	O
trained	O
,	O
we	O
use	O
a	O
beam	B-Method
search	I-Method
to	O
find	O
a	O
translation	O
that	O
approximately	O
maximizes	O
the	O
conditional	O
probability	O
.	O
	
used	O
this	O
approach	O
to	O
generate	O
translations	O
from	O
their	O
neural	B-Method
machine	I-Method
translation	I-Method
model	I-Method
.	O
	
For	O
more	O
details	O
on	O
the	O
architectures	O
of	O
the	O
models	O
and	O
training	O
procedure	O
used	O
in	O
the	O
experiments	O
,	O
see	O
Appendices	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
Results	O
	
subsection	O
:	O
Quantitative	O
Results	O
	
In	O
Table	O
[	O
reference	O
]	O
,	O
we	O
list	O
the	O
translation	B-Metric
performances	I-Metric
measured	O
in	O
BLEU	B-Metric
score	I-Metric
.	O
	
It	O
is	O
clear	O
from	O
the	O
table	O
that	O
in	O
all	O
the	O
cases	O
,	O
the	O
proposed	O
RNNsearch	B-Method
outperforms	O
the	O
conventional	O
RNNencdec	B-Method
.	O
	
More	O
importantly	O
,	O
the	O
performance	O
of	O
the	O
RNNsearch	B-Method
is	O
as	O
high	O
as	O
that	O
of	O
the	O
conventional	O
phrase	B-Method
-	I-Method
based	I-Method
translation	I-Method
system	I-Method
(	O
Moses	B-Method
)	O
,	O
when	O
only	O
the	O
sentences	O
consisting	O
of	O
known	O
words	O
are	O
considered	O
.	O
	
This	O
is	O
a	O
significant	O
achievement	O
,	O
considering	O
that	O
Moses	O
uses	O
a	O
separate	O
monolingual	O
corpus	O
(	O
418	O
M	O
words	O
)	O
in	O
addition	O
to	O
the	O
parallel	O
corpora	O
we	O
used	O
to	O
train	O
the	O
RNNsearch	B-Method
and	O
RNNencdec	B-Method
.	O
	
One	O
of	O
the	O
motivations	O
behind	O
the	O
proposed	O
approach	O
was	O
the	O
use	O
of	O
a	O
fixed	O
-	O
length	O
context	O
vector	O
in	O
the	O
basic	O
encoder	B-Method
–	I-Method
decoder	I-Method
approach	I-Method
.	O
	
We	O
conjectured	O
that	O
this	O
limitation	O
may	O
make	O
the	O
basic	O
encoder	B-Method
–	I-Method
decoder	I-Method
approach	I-Method
to	O
underperform	O
with	O
long	O
sentences	O
.	O
	
In	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
,	O
we	O
see	O
that	O
the	O
performance	O
of	O
RNNencdec	B-Method
dramatically	O
drops	O
as	O
the	O
length	O
of	O
the	O
sentences	O
increases	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
both	O
RNNsearch	B-Method
-	I-Method
30	I-Method
and	O
RNNsearch	B-Method
-	I-Method
50	I-Method
are	O
more	O
robust	O
to	O
the	O
length	O
of	O
the	O
sentences	O
.	O
	
RNNsearch	B-Method
-	I-Method
50	I-Method
,	O
especially	O
,	O
shows	O
no	O
performance	O
deterioration	O
even	O
with	O
sentences	O
of	O
length	O
50	O
or	O
more	O
.	O
	
This	O
superiority	O
of	O
the	O
proposed	O
model	O
over	O
the	O
basic	O
encoder	B-Method
–	I-Method
decoder	I-Method
is	O
further	O
confirmed	O
by	O
the	O
fact	O
that	O
the	O
RNNsearch	B-Method
-	I-Method
30	I-Method
even	O
outperforms	O
RNNencdec	B-Method
-	I-Method
50	I-Method
(	O
see	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
subsection	O
:	O
Qualitative	B-Method
Analysis	I-Method
	
subsubsection	O
:	O
Alignment	B-Task
	
The	O
proposed	O
approach	O
provides	O
an	O
intuitive	O
way	O
to	O
inspect	O
the	O
(	O
soft	O
-)	O
alignment	O
between	O
the	O
words	O
in	O
a	O
generated	O
translation	O
and	O
those	O
in	O
a	O
source	O
sentence	O
.	O
	
This	O
is	O
done	O
by	O
visualizing	O
the	O
annotation	O
weights	O
from	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
,	O
as	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Each	O
row	O
of	O
a	O
matrix	O
in	O
each	O
plot	O
indicates	O
the	O
weights	O
associated	O
with	O
the	O
annotations	O
.	O
	
From	O
this	O
we	O
see	O
which	O
positions	O
in	O
the	O
source	O
sentence	O
were	O
considered	O
more	O
important	O
when	O
generating	O
the	O
target	O
word	O
.	O
	
We	O
can	O
see	O
from	O
the	O
alignments	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
that	O
the	O
alignment	O
of	O
words	O
between	O
English	O
and	O
French	O
is	O
largely	O
monotonic	O
.	O
	
We	O
see	O
strong	O
weights	O
along	O
the	O
diagonal	O
of	O
each	O
matrix	O
.	O
	
However	O
,	O
we	O
also	O
observe	O
a	O
number	O
of	O
non	O
-	O
trivial	O
,	O
non	O
-	O
monotonic	O
alignments	O
.	O
	
Adjectives	O
and	O
nouns	O
are	O
typically	O
ordered	O
differently	O
between	O
French	O
and	O
English	O
,	O
and	O
we	O
see	O
an	O
example	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
a	O
)	O
.	O
	
From	O
this	O
figure	O
,	O
we	O
see	O
that	O
the	O
model	O
correctly	O
translates	O
a	O
phrase	O
[	O
European	O
Economic	O
Area	O
]	O
into	O
[	O
zone	O
économique	O
européen	O
]	O
.	O
	
The	O
RNNsearch	B-Method
was	O
able	O
to	O
correctly	O
align	O
[	O
zone	O
]	O
with	O
[	O
Area	O
]	O
,	O
jumping	O
over	O
the	O
two	O
words	O
(	O
[	O
European	O
]	O
and	O
[	O
Economic	O
]	O
)	O
,	O
and	O
then	O
looked	O
one	O
word	O
back	O
at	O
a	O
time	O
to	O
complete	O
the	O
whole	O
phrase	O
[	O
zone	O
économique	O
	
européenne	O
]	O
.	O
	
The	O
strength	O
of	O
the	O
soft	B-Method
-	I-Method
alignment	I-Method
,	O
opposed	O
to	O
a	O
hard	O
-	O
alignment	O
,	O
is	O
evident	O
,	O
for	O
instance	O
,	O
from	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
d	O
)	O
.	O
	
Consider	O
the	O
source	O
phrase	O
[	O
the	O
man	O
]	O
which	O
was	O
translated	O
into	O
[	O
l	O
’	O
	
homme	O
]	O
.	O
	
Any	O
hard	O
alignment	O
will	O
map	O
[	O
the	O
]	O
to	O
[	O
l	O
’	O
]	O
and	O
[	O
man	O
]	O
to	O
[	O
homme	O
]	O
.	O
	
This	O
is	O
not	O
helpful	O
for	O
translation	B-Task
,	O
as	O
one	O
must	O
consider	O
the	O
word	O
following	O
[	O
the	O
]	O
to	O
determine	O
whether	O
it	O
should	O
be	O
translated	O
into	O
[	O
le	O
]	O
,	O
[	O
la	O
]	O
,	O
[	O
les	O
]	O
or	O
[	O
l’	O
]	O
.	O
Our	O
soft	B-Method
-	I-Method
alignment	I-Method
solves	O
this	O
issue	O
naturally	O
by	O
letting	O
the	O
model	O
look	O
at	O
both	O
[	O
the	O
]	O
and	O
[	O
man	O
]	O
,	O
and	O
in	O
this	O
example	O
,	O
we	O
see	O
that	O
the	O
model	O
was	O
able	O
to	O
correctly	O
translate	O
[	O
the	O
]	O
into	O
[	O
l’	O
]	O
.	O
We	O
observe	O
similar	O
behaviors	O
in	O
all	O
the	O
presented	O
cases	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
An	O
additional	O
benefit	O
of	O
the	O
soft	B-Task
alignment	I-Task
is	O
that	O
it	O
naturally	O
deals	O
with	O
source	O
and	O
target	O
phrases	O
of	O
different	O
lengths	O
,	O
without	O
requiring	O
a	O
counter	O
-	O
intuitive	O
way	O
of	O
mapping	O
some	O
words	O
to	O
or	O
from	O
nowhere	O
(	O
[	O
NULL	O
]	O
)	O
.	O
	
subsubsection	O
:	O
Long	O
Sentences	O
	
As	O
clearly	O
visible	O
from	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
the	O
proposed	O
model	O
(	O
RNNsearch	B-Method
)	O
is	O
much	O
better	O
than	O
the	O
conventional	O
model	O
(	O
RNNencdec	B-Method
)	O
at	O
translating	O
long	O
sentences	O
.	O
	
This	O
is	O
likely	O
due	O
to	O
the	O
fact	O
that	O
the	O
RNNsearch	B-Method
does	O
not	O
require	O
encoding	O
a	O
long	O
sentence	O
into	O
a	O
fixed	O
-	O
length	O
vector	O
perfectly	O
,	O
but	O
only	O
accurately	O
encoding	O
the	O
parts	O
of	O
the	O
input	O
sentence	O
that	O
surround	O
a	O
particular	O
word	O
.	O
	
As	O
an	O
example	O
,	O
consider	O
this	O
source	O
sentence	O
from	O
the	O
test	O
set	O
:	O
An	O
admitting	O
privilege	O
is	O
the	O
right	O
of	O
a	O
doctor	O
to	O
admit	O
a	O
patient	O
to	O
a	O
hospital	O
or	O
a	O
medical	O
centre	O
to	O
carry	O
out	O
a	O
diagnosis	O
or	O
a	O
procedure	O
,	O
based	O
on	O
his	O
status	O
as	O
a	O
health	O
care	O
worker	O
at	O
a	O
hospital	O
.	O
	
The	O
RNNencdec	O
-	O
50	O
translated	O
this	O
sentence	O
into	O
:	O
Un	O
privilège	O
d’admission	O
est	O
	
le	O
droit	O
d’un	O
	
médecin	O
de	O
reconnaître	O
un	O
patient	O
à	O
l’hôpital	O
ou	O
un	O
centre	O
médical	O
d’un	O
diagnostic	O
ou	O
de	O
prendre	O
un	O
diagnostic	O
en	O
fonction	O
de	O
son	O
état	O
de	O
santé	O
.	O
	
The	O
RNNencdec	B-Method
-	I-Method
50	I-Method
correctly	O
translated	O
the	O
source	O
sentence	O
until	O
[	O
a	O
medical	O
center	O
]	O
.	O
	
However	O
,	O
from	O
there	O
on	O
(	O
underlined	O
)	O
,	O
it	O
deviated	O
from	O
the	O
original	O
meaning	O
of	O
the	O
source	O
sentence	O
.	O
	
For	O
instance	O
,	O
it	O
replaced	O
[	O
based	O
on	O
his	O
status	O
as	O
a	O
health	O
care	O
worker	O
at	O
a	O
hospital	O
]	O
in	O
the	O
source	O
sentence	O
with	O
[	O
en	O
fonction	O
de	O
son	O
état	O
de	O
santé	O
]	O
	
(	O
“	O
based	O
on	O
his	O
state	O
of	O
health	O
”	O
)	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
the	O
RNNsearch	B-Method
-	I-Method
50	I-Method
generated	O
the	O
following	O
correct	O
translation	O
,	O
preserving	O
the	O
whole	O
meaning	O
of	O
the	O
input	O
sentence	O
without	O
omitting	O
any	O
details	O
:	O
Un	O
privilège	O
d’admission	O
est	O
le	O
droit	O
d’un	O
	
médecin	O
d’admettre	O
un	O
patient	O
à	O
un	O
hôpital	O
ou	O
un	O
centre	O
médical	O
pour	O
effectuer	O
un	O
	
diagnostic	O
ou	O
une	O
procédure	O
,	O
	
selon	O
son	O
statut	O
	
de	O
travailleur	O
des	O
soins	O
	
de	O
santé	O
à	O
l’hôpital	O
.	O
	
Let	O
us	O
consider	O
another	O
sentence	O
from	O
the	O
test	O
set	O
:	O
This	O
kind	O
of	O
experience	O
is	O
part	O
of	O
Disney	O
’s	O
efforts	O
to	O
”	O
extend	O
the	O
lifetime	O
of	O
its	O
series	O
and	O
build	O
new	O
relationships	O
with	O
audiences	O
via	O
digital	O
platforms	O
that	O
are	O
becoming	O
ever	O
more	O
important	O
,	O
”	O
he	O
added	O
.	O
	
The	O
translation	O
by	O
the	O
RNNencdec	B-Method
-	I-Method
50	I-Method
is	O
Ce	O
type	O
d’expérience	O
fait	O
partie	O
des	O
initiatives	O
	
du	O
Disney	O
pour	O
”	O
prolonger	O
la	O
durée	O
de	O
vie	O
de	O
ses	O
nouvelles	O
	
et	O
de	O
développer	O
des	O
liens	O
	
avec	O
les	O
	
lecteurs	O
numériques	O
qui	O
deviennent	O
plus	O
complexes	O
.	O
	
As	O
with	O
the	O
previous	O
example	O
,	O
the	O
RNNencdec	B-Method
began	O
deviating	O
from	O
the	O
actual	O
meaning	O
of	O
the	O
source	O
sentence	O
after	O
generating	O
approximately	O
30	O
words	O
(	O
see	O
the	O
underlined	O
phrase	O
)	O
.	O
	
After	O
that	O
point	O
,	O
the	O
quality	O
of	O
the	O
translation	O
deteriorates	O
,	O
with	O
basic	O
mistakes	O
such	O
as	O
the	O
lack	O
of	O
a	O
closing	O
quotation	O
mark	O
.	O
	
Again	O
,	O
the	O
RNNsearch	B-Method
-	I-Method
50	I-Method
was	O
able	O
to	O
translate	O
this	O
long	O
sentence	O
correctly	O
:	O
	
Ce	O
genre	O
d’expérience	O
fait	O
partie	O
	
des	O
efforts	O
	
de	O
Disney	O
pour	O
”	O
prolonger	O
la	O
durée	O
de	O
vie	O
de	O
ses	O
séries	O
	
et	O
créer	O
de	O
nouvelles	O
relations	O
avec	O
des	O
publics	O
via	O
des	O
plateformes	O
	
numériques	O
de	O
plus	O
en	O
plus	O
importantes	O
”	O
,	O
a	O
-	O
t	O
-	O
il	O
ajouté	O
.	O
	
In	O
conjunction	O
with	O
the	O
quantitative	O
results	O
presented	O
already	O
,	O
these	O
qualitative	O
observations	O
confirm	O
our	O
hypotheses	O
that	O
the	O
RNNsearch	B-Method
architecture	O
enables	O
far	O
more	O
reliable	O
translation	B-Task
of	O
long	O
sentences	O
than	O
the	O
standard	O
RNNencdec	B-Method
model	I-Method
.	O
	
In	O
Appendix	O
[	O
reference	O
]	O
,	O
we	O
provide	O
a	O
few	O
more	O
sample	O
translations	O
of	O
long	O
source	O
sentences	O
generated	O
by	O
the	O
RNNencdec	B-Method
-	I-Method
50	I-Method
,	O
RNNsearch	B-Method
-	I-Method
50	I-Method
and	O
Google	B-Method
Translate	I-Method
along	O
with	O
the	O
reference	O
translations	O
.	O
	
section	O
:	O
Related	O
Work	O
	
subsection	O
:	O
Learning	O
to	O
Align	O
	
A	O
similar	O
approach	O
of	O
aligning	O
an	O
output	O
symbol	O
with	O
an	O
input	O
symbol	O
was	O
proposed	O
recently	O
by	O
in	O
the	O
context	O
of	O
handwriting	B-Task
synthesis	I-Task
.	O
	
Handwriting	B-Task
synthesis	I-Task
is	O
a	O
task	O
where	O
the	O
model	O
is	O
asked	O
to	O
generate	O
handwriting	O
of	O
a	O
given	O
sequence	O
of	O
characters	O
.	O
	
In	O
his	O
work	O
,	O
he	O
used	O
a	O
mixture	B-Method
of	I-Method
Gaussian	I-Method
kernels	I-Method
to	O
compute	O
the	O
weights	O
of	O
the	O
annotations	O
,	O
where	O
the	O
location	O
,	O
width	O
and	O
mixture	O
coefficient	O
of	O
each	O
kernel	O
was	O
predicted	O
from	O
an	O
alignment	B-Method
model	I-Method
.	O
	
More	O
specifically	O
,	O
his	O
alignment	O
was	O
restricted	O
to	O
predict	O
the	O
location	O
such	O
that	O
the	O
location	O
increases	O
monotonically	O
.	O
	
The	O
main	O
difference	O
from	O
our	O
approach	O
is	O
that	O
,	O
in	O
,	O
the	O
modes	O
of	O
the	O
weights	O
of	O
the	O
annotations	O
only	O
move	O
in	O
one	O
direction	O
.	O
	
In	O
the	O
context	O
of	O
machine	B-Task
translation	I-Task
,	O
this	O
is	O
a	O
severe	O
limitation	O
,	O
as	O
(	O
long	O
-	O
distance	O
)	O
reordering	O
is	O
often	O
needed	O
to	O
generate	O
a	O
grammatically	O
correct	O
translation	O
(	O
for	O
instance	O
,	O
English	O
-	O
to	O
-	O
German	O
)	O
.	O
	
Our	O
approach	O
,	O
on	O
the	O
other	O
hand	O
,	O
requires	O
computing	O
the	O
annotation	O
weight	O
of	O
every	O
word	O
in	O
the	O
source	O
sentence	O
for	O
each	O
word	O
in	O
the	O
translation	O
.	O
	
This	O
drawback	O
is	O
not	O
severe	O
with	O
the	O
task	O
of	O
translation	B-Task
in	O
which	O
most	O
of	O
input	O
and	O
output	O
sentences	O
are	O
only	O
15–40	O
words	O
.	O
	
However	O
,	O
this	O
may	O
limit	O
the	O
applicability	O
of	O
the	O
proposed	O
scheme	O
to	O
other	O
tasks	O
.	O
	
subsection	O
:	O
Neural	B-Method
Networks	I-Method
for	O
Machine	B-Task
Translation	I-Task
	
Since	O
introduced	O
a	O
neural	B-Method
probabilistic	I-Method
language	I-Method
model	I-Method
which	O
uses	O
a	O
neural	B-Method
network	I-Method
to	O
model	O
the	O
conditional	O
probability	O
of	O
a	O
word	O
given	O
a	O
fixed	O
number	O
of	O
the	O
preceding	O
words	O
,	O
neural	B-Method
networks	I-Method
have	O
widely	O
been	O
used	O
in	O
machine	B-Task
translation	I-Task
.	O
	
However	O
,	O
the	O
role	O
of	O
neural	B-Method
networks	I-Method
has	O
been	O
largely	O
limited	O
to	O
simply	O
providing	O
a	O
single	O
feature	O
to	O
an	O
existing	O
statistical	B-Method
machine	I-Method
translation	I-Method
system	I-Method
or	O
to	O
re	O
-	O
rank	O
a	O
list	O
of	O
candidate	O
translations	O
provided	O
by	O
an	O
existing	O
system	O
.	O
	
For	O
instance	O
,	O
proposed	O
using	O
a	O
feedforward	B-Method
neural	I-Method
network	I-Method
to	O
compute	O
the	O
score	O
of	O
a	O
pair	O
of	O
source	O
and	O
target	O
phrases	O
and	O
to	O
use	O
the	O
score	O
as	O
an	O
additional	O
feature	O
in	O
the	O
phrase	O
-	O
based	O
statistical	O
machine	B-Task
translation	I-Task
system	O
.	O
	
More	O
recently	O
,	O
and	O
reported	O
the	O
successful	O
use	O
of	O
the	O
neural	B-Method
networks	I-Method
as	O
a	O
sub	O
-	O
component	O
of	O
the	O
existing	O
translation	B-Method
system	I-Method
.	O
	
Traditionally	O
,	O
a	O
neural	B-Method
network	I-Method
trained	O
as	O
a	O
target	B-Method
-	I-Method
side	I-Method
language	I-Method
model	I-Method
has	O
been	O
used	O
to	O
rescore	O
or	O
rerank	O
a	O
list	O
of	O
candidate	O
translations	O
.	O
	
Although	O
the	O
above	O
approaches	O
were	O
shown	O
to	O
improve	O
the	O
translation	B-Metric
performance	I-Metric
over	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
machine	B-Method
translation	I-Method
systems	I-Method
,	O
we	O
are	O
more	O
interested	O
in	O
a	O
more	O
ambitious	O
objective	O
of	O
designing	O
a	O
completely	O
new	O
translation	B-Method
system	I-Method
based	O
on	O
neural	B-Method
networks	I-Method
.	O
	
The	O
neural	O
machine	B-Task
translation	I-Task
approach	O
we	O
consider	O
in	O
this	O
paper	O
is	O
therefore	O
a	O
radical	O
departure	O
from	O
these	O
earlier	O
works	O
.	O
	
Rather	O
than	O
using	O
a	O
neural	B-Method
network	I-Method
as	O
a	O
part	O
of	O
the	O
existing	O
system	O
,	O
our	O
model	O
works	O
on	O
its	O
own	O
and	O
generates	O
a	O
translation	B-Task
from	O
a	O
source	O
sentence	O
directly	O
.	O
	
section	O
:	O
Conclusion	O
	
The	O
conventional	O
approach	O
to	O
neural	B-Task
machine	I-Task
translation	I-Task
,	O
called	O
an	O
encoder	B-Method
–	I-Method
decoder	I-Method
approach	I-Method
,	O
encodes	O
a	O
whole	O
input	O
sentence	O
into	O
a	O
fixed	O
-	O
length	O
vector	O
from	O
which	O
a	O
translation	O
will	O
be	O
decoded	O
.	O
	
We	O
conjectured	O
that	O
the	O
use	O
of	O
a	O
fixed	O
-	O
length	O
context	O
vector	O
is	O
problematic	O
for	O
translating	O
long	O
sentences	O
,	O
based	O
on	O
a	O
recent	O
empirical	O
study	O
reported	O
by	O
and	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
proposed	O
a	O
novel	O
architecture	O
that	O
addresses	O
this	O
issue	O
.	O
	
We	O
extended	O
the	O
basic	O
encoder	B-Method
–	I-Method
decoder	I-Method
by	O
letting	O
a	O
model	O
(	O
soft	O
-)	O
search	O
for	O
a	O
set	O
of	O
input	O
words	O
,	O
or	O
their	O
annotations	O
computed	O
by	O
an	O
encoder	B-Method
,	O
when	O
generating	O
each	O
target	O
word	O
.	O
	
This	O
frees	O
the	O
model	O
from	O
having	O
to	O
encode	O
a	O
whole	O
source	O
sentence	O
into	O
a	O
fixed	O
-	O
length	O
vector	O
,	O
and	O
also	O
lets	O
the	O
model	O
focus	O
only	O
on	O
information	O
relevant	O
to	O
the	O
generation	O
of	O
the	O
next	O
target	O
word	O
.	O
	
This	O
has	O
a	O
major	O
positive	O
impact	O
on	O
the	O
ability	O
of	O
the	O
neural	B-Method
machine	I-Method
translation	I-Method
system	I-Method
to	O
yield	O
good	O
results	O
on	O
longer	O
sentences	O
.	O
	
Unlike	O
with	O
the	O
traditional	O
machine	B-Method
translation	I-Method
systems	I-Method
,	O
all	O
of	O
the	O
pieces	O
of	O
the	O
translation	B-Method
system	I-Method
,	O
including	O
the	O
alignment	B-Method
mechanism	I-Method
,	O
are	O
jointly	O
trained	O
towards	O
a	O
better	O
log	B-Metric
-	I-Metric
probability	I-Metric
of	O
producing	O
correct	O
translations	O
.	O
	
We	O
tested	O
the	O
proposed	O
model	O
,	O
called	O
RNNsearch	B-Method
,	O
on	O
the	O
task	O
of	O
English	B-Task
-	I-Task
to	I-Task
-	I-Task
French	I-Task
translation	I-Task
.	O
	
The	O
experiment	O
revealed	O
that	O
the	O
proposed	O
RNNsearch	B-Method
outperforms	O
the	O
conventional	O
encoder	B-Method
–	I-Method
decoder	I-Method
model	I-Method
(	O
RNNencdec	B-Method
)	O
significantly	O
,	O
regardless	O
of	O
the	O
sentence	O
length	O
and	O
that	O
it	O
is	O
much	O
more	O
robust	O
to	O
the	O
length	O
of	O
a	O
source	O
sentence	O
.	O
	
From	O
the	O
qualitative	O
analysis	O
where	O
we	O
investigated	O
the	O
(	O
soft	O
-)	O
alignment	O
generated	O
by	O
the	O
RNNsearch	B-Method
,	O
we	O
were	O
able	O
to	O
conclude	O
that	O
the	O
model	O
can	O
correctly	O
align	O
each	O
target	O
word	O
with	O
the	O
relevant	O
words	O
,	O
or	O
their	O
annotations	O
,	O
in	O
the	O
source	O
sentence	O
as	O
it	O
generated	O
a	O
correct	O
translation	O
.	O
	
Perhaps	O
more	O
importantly	O
,	O
the	O
proposed	O
approach	O
achieved	O
a	O
translation	B-Task
performance	O
comparable	O
to	O
the	O
existing	O
phrase	B-Method
-	I-Method
based	I-Method
statistical	I-Method
machine	I-Method
translation	I-Method
.	O
	
It	O
is	O
a	O
striking	O
result	O
,	O
considering	O
that	O
the	O
proposed	O
architecture	O
,	O
or	O
the	O
whole	O
family	O
of	O
neural	B-Task
machine	I-Task
translation	I-Task
,	O
has	O
only	O
been	O
proposed	O
as	O
recently	O
as	O
this	O
year	O
.	O
	
We	O
believe	O
the	O
architecture	O
proposed	O
here	O
is	O
a	O
promising	O
step	O
toward	O
better	O
machine	B-Task
translation	I-Task
and	O
a	O
better	O
understanding	B-Task
of	I-Task
natural	I-Task
languages	I-Task
in	O
general	O
.	O
	
One	O
of	O
challenges	O
left	O
for	O
the	O
future	O
is	O
to	O
better	O
handle	O
unknown	O
,	O
or	O
rare	O
words	O
.	O
	
This	O
will	O
be	O
required	O
for	O
the	O
model	O
to	O
be	O
more	O
widely	O
used	O
and	O
to	O
match	O
the	O
performance	O
of	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
machine	B-Method
translation	I-Method
systems	I-Method
in	O
all	O
contexts	O
.	O
	
section	O
:	O
Acknowledgments	O
	
The	O
authors	O
would	O
like	O
to	O
thank	O
the	O
developers	O
of	O
Theano	O
.	O
	
We	O
acknowledge	O
the	O
support	O
of	O
the	O
following	O
agencies	O
for	O
research	O
funding	O
and	O
computing	O
support	O
:	O
NSERC	O
,	O
Calcul	O
Québec	O
,	O
Compute	O
Canada	O
,	O
the	O
Canada	O
Research	O
Chairs	O
and	O
CIFAR	O
.	O
	
Bahdanau	O
thanks	O
the	O
support	O
from	O
Planet	O
Intelligent	O
Systems	O
GmbH.	O
	
We	O
also	O
thank	O
Felix	O
Hill	O
,	O
Bart	O
van	O
Merriénboer	O
,	O
Jean	O
Pouget	O
-	O
Abadie	O
,	O
Coline	O
Devin	O
and	O
Tae	O
-	O
Ho	O
Kim	O
.	O
	
bibliography	O
:	O
References	O
	
appendix	O
:	O
Model	O
Architecture	O
	
subsection	O
:	O
Architectural	O
Choices	O
	
The	O
proposed	O
scheme	O
in	O
Section	O
[	O
reference	O
]	O
is	O
a	O
general	O
framework	O
where	O
one	O
can	O
freely	O
define	O
,	O
for	O
instance	O
,	O
the	O
activation	B-Method
functions	I-Method
of	O
recurrent	B-Method
neural	I-Method
networks	I-Method
(	O
RNN	B-Method
)	O
and	O
the	O
alignment	B-Method
model	I-Method
.	O
	
Here	O
,	O
we	O
describe	O
the	O
choices	O
we	O
made	O
for	O
the	O
experiments	O
in	O
this	O
paper	O
.	O
	
subsubsection	O
:	O
Recurrent	B-Method
Neural	I-Method
Network	I-Method
	
For	O
the	O
activation	O
function	O
of	O
an	O
RNN	B-Method
,	O
we	O
use	O
the	O
gated	B-Method
hidden	I-Method
unit	I-Method
recently	O
proposed	O
by	O
.	O
	
The	O
gated	B-Method
hidden	I-Method
unit	I-Method
is	O
an	O
alternative	O
to	O
the	O
conventional	O
simple	B-Method
units	I-Method
such	O
as	O
an	O
element	B-Method
-	I-Method
wise	I-Method
.	O
	
This	O
gated	B-Method
unit	I-Method
is	O
similar	O
to	O
a	O
long	B-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
(	I-Method
LSTM	I-Method
)	I-Method
unit	I-Method
proposed	O
earlier	O
by	O
,	O
sharing	O
with	O
it	O
the	O
ability	O
to	O
better	O
model	O
and	O
learn	O
long	O
-	O
term	O
dependencies	O
.	O
	
This	O
is	O
made	O
possible	O
by	O
having	O
computation	O
paths	O
in	O
the	O
unfolded	O
RNN	B-Method
for	O
which	O
the	O
product	O
of	O
derivatives	O
is	O
close	O
to	O
1	O
.	O
	
These	O
paths	O
allow	O
gradients	O
to	O
flow	O
backward	O
easily	O
without	O
suffering	O
too	O
much	O
from	O
the	O
vanishing	O
effect	O
.	O
	
It	O
is	O
therefore	O
possible	O
to	O
use	O
LSTM	B-Method
units	I-Method
instead	O
of	O
the	O
gated	B-Method
hidden	I-Method
unit	I-Method
described	O
here	O
,	O
as	O
was	O
done	O
in	O
a	O
similar	O
context	O
by	O
.	O
	
The	O
new	O
state	O
of	O
the	O
RNN	B-Method
employing	O
gated	B-Method
hidden	I-Method
units	I-Method
is	O
computed	O
by	O
where	O
is	O
an	O
element	B-Method
-	I-Method
wise	I-Method
multiplication	I-Method
,	O
and	O
is	O
the	O
output	O
of	O
the	O
update	O
gates	O
(	O
see	O
below	O
)	O
.	O
	
The	O
proposed	O
updated	O
state	O
is	O
computed	O
by	O
where	O
is	O
an	O
-	O
dimensional	O
embedding	O
of	O
a	O
word	O
,	O
and	O
is	O
the	O
output	O
of	O
the	O
reset	O
gates	O
(	O
see	O
below	O
)	O
.	O
	
When	O
is	O
represented	O
as	O
a	O
-	O
of	O
-	O
vector	O
,	O
is	O
simply	O
a	O
column	O
of	O
an	O
embedding	B-Method
matrix	I-Method
.	O
	
Whenever	O
possible	O
,	O
we	O
omit	O
bias	O
terms	O
to	O
make	O
the	O
equations	O
less	O
cluttered	O
.	O
	
The	O
update	O
gates	O
allow	O
each	O
hidden	B-Method
unit	I-Method
to	O
maintain	O
its	O
previous	O
activation	O
,	O
and	O
the	O
reset	O
gates	O
control	O
how	O
much	O
and	O
what	O
information	O
from	O
the	O
previous	O
state	O
should	O
be	O
reset	O
.	O
	
We	O
compute	O
them	O
by	O
where	O
is	O
a	O
logistic	B-Method
sigmoid	I-Method
function	I-Method
.	O
	
At	O
each	O
step	O
of	O
the	O
decoder	B-Method
,	O
we	O
compute	O
the	O
output	O
probability	O
(	O
Eq	O
.	O
(	O
[	O
reference	O
]	O
)	O
)	O
as	O
a	O
multi	O
-	O
layered	O
function	O
.	O
	
We	O
use	O
a	O
single	O
hidden	B-Method
layer	I-Method
of	I-Method
maxout	I-Method
units	I-Method
and	O
normalize	O
the	O
output	O
probabilities	O
(	O
one	O
for	O
each	O
word	O
)	O
with	O
a	O
softmax	O
function	O
(	O
see	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
)	O
.	O
	
subsubsection	O
:	O
Alignment	B-Method
Model	I-Method
	
The	O
alignment	B-Method
model	I-Method
should	O
be	O
designed	O
considering	O
that	O
the	O
model	O
needs	O
to	O
be	O
evaluated	O
times	O
for	O
each	O
sentence	O
pair	O
of	O
lengths	O
and	O
.	O
	
In	O
order	O
to	O
reduce	O
computation	O
,	O
we	O
use	O
a	O
single	B-Method
-	I-Method
layer	I-Method
multilayer	I-Method
perceptron	I-Method
such	O
that	O
where	O
and	O
are	O
the	O
weight	O
matrices	O
.	O
	
Since	O
does	O
not	O
depend	O
on	O
,	O
we	O
can	O
pre	O
-	O
compute	O
it	O
in	O
advance	O
to	O
minimize	O
the	O
computational	B-Metric
cost	I-Metric
.	O
	
subsection	O
:	O
Detailed	O
Description	O
of	O
the	O
Model	O
	
subsubsection	O
:	O
Encoder	B-Method
	
In	O
this	O
section	O
,	O
we	O
describe	O
in	O
detail	O
the	O
architecture	O
of	O
the	O
proposed	O
model	O
(	O
RNNsearch	B-Method
)	O
used	O
in	O
the	O
experiments	O
(	O
see	O
Sec	O
.	O
	
[	O
reference	O
]	O
	
–	O
[	O
reference	O
]	O
)	O
.	O
	
From	O
here	O
on	O
,	O
we	O
omit	O
all	O
bias	O
terms	O
in	O
order	O
to	O
increase	O
readability	O
.	O
	
The	O
model	O
takes	O
a	O
source	O
sentence	O
of	O
1	O
-	O
of	O
-	O
K	O
coded	O
word	O
vectors	O
as	O
input	O
and	O
outputs	O
a	O
translated	O
sentence	O
of	O
1	O
-	O
of	O
-	O
K	O
coded	O
word	O
vectors	O
where	O
and	O
are	O
the	O
vocabulary	O
sizes	O
of	O
source	O
and	O
target	O
languages	O
,	O
respectively	O
.	O
and	O
respectively	O
denote	O
the	O
lengths	O
of	O
source	O
and	O
target	O
sentences	O
.	O
	
First	O
,	O
the	O
forward	O
states	O
of	O
the	O
bidirectional	B-Method
recurrent	I-Method
neural	I-Method
network	I-Method
(	I-Method
BiRNN	I-Method
)	I-Method
are	O
computed	O
:	O
where	O
is	O
the	O
word	O
embedding	O
matrix	O
.	O
,	O
are	O
weight	O
matrices	O
.	O
	
and	O
are	O
the	O
word	O
embedding	O
dimensionality	O
and	O
the	O
number	O
of	O
hidden	O
units	O
,	O
respectively	O
.	O
	
is	O
as	O
usual	O
a	O
logistic	B-Method
sigmoid	I-Method
function	I-Method
.	O
	
The	O
backward	O
states	O
are	O
computed	O
similarly	O
.	O
	
We	O
share	O
the	O
word	O
embedding	O
matrix	O
between	O
the	O
forward	O
and	O
backward	O
RNNs	B-Method
,	O
unlike	O
the	O
weight	B-Method
matrices	I-Method
.	O
	
We	O
concatenate	O
the	O
forward	O
and	O
backward	O
states	O
to	O
to	O
obtain	O
the	O
annotations	O
,	O
where	O
	
subsubsection	O
:	O
Decoder	B-Method
	
The	O
hidden	O
state	O
of	O
the	O
decoder	O
given	O
the	O
annotations	O
from	O
the	O
encoder	O
is	O
computed	O
by	O
where	O
is	O
the	O
word	B-Method
embedding	I-Method
matrix	I-Method
for	O
the	O
target	O
language	O
.	O
	
,	O
,	O
and	O
are	O
weights	O
.	O
	
Again	O
,	O
and	O
are	O
the	O
word	O
embedding	O
dimensionality	O
and	O
the	O
number	O
of	O
hidden	O
units	O
,	O
respectively	O
.	O
	
The	O
initial	O
hidden	O
state	O
is	O
computed	O
by	O
where	O
.	O
	
The	O
context	O
vector	O
are	O
recomputed	O
at	O
each	O
step	O
by	O
the	O
alignment	B-Method
model	I-Method
:	O
where	O
and	O
is	O
the	O
-	O
th	O
annotation	O
in	O
the	O
source	O
sentence	O
(	O
see	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
)	O
.	O
	
and	O
are	O
weight	O
matrices	O
.	O
	
Note	O
that	O
the	O
model	O
becomes	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
,	O
if	O
we	O
fix	O
to	O
.	O
	
With	O
the	O
decoder	O
state	O
,	O
the	O
context	O
and	O
the	O
last	O
generated	O
word	O
,	O
we	O
define	O
the	O
probability	O
of	O
a	O
target	O
word	O
as	O
where	O
and	O
is	O
the	O
-	O
th	O
element	O
of	O
a	O
vector	O
which	O
is	O
computed	O
by	O
,	O
,	O
and	O
are	O
weight	O
matrices	O
.	O
	
This	O
can	O
be	O
understood	O
as	O
having	O
a	O
deep	O
output	O
with	O
a	O
single	O
maxout	B-Method
hidden	I-Method
layer	I-Method
.	O
	
subsubsection	O
:	O
Model	B-Method
Size	I-Method
	
For	O
all	O
the	O
models	O
used	O
in	O
this	O
paper	O
,	O
the	O
size	O
of	O
a	O
hidden	O
layer	O
is	O
1000	O
,	O
the	O
word	O
embedding	O
dimensionality	O
is	O
620	O
and	O
the	O
size	O
of	O
the	O
maxout	B-Method
hidden	I-Method
layer	I-Method
in	O
the	O
deep	O
output	O
is	O
500	O
.	O
	
The	O
number	O
of	O
hidden	O
units	O
in	O
the	O
alignment	B-Method
model	I-Method
is	O
1000	O
.	O
	
appendix	O
:	O
Training	O
Procedure	O
	
subsection	O
:	O
Parameter	B-Method
Initialization	I-Method
	
We	O
initialized	O
the	O
recurrent	O
weight	O
matrices	O
and	O
as	O
random	O
orthogonal	O
matrices	O
.	O
	
For	O
and	O
,	O
we	O
initialized	O
them	O
by	O
sampling	O
each	O
element	O
from	O
the	O
Gaussian	B-Method
distribution	I-Method
of	I-Method
mean	I-Method
and	I-Method
variance	I-Method
.	O
	
All	O
the	O
elements	O
of	O
and	O
all	O
the	O
bias	O
vectors	O
were	O
initialized	O
to	O
zero	O
.	O
	
Any	O
other	O
weight	O
matrix	O
was	O
initialized	O
by	O
sampling	O
from	O
the	O
Gaussian	B-Method
distribution	I-Method
of	I-Method
mean	I-Method
and	I-Method
variance	I-Method
.	O
	
subsection	O
:	O
Training	O
	
We	O
used	O
the	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
(	O
SGD	B-Method
)	O
algorithm	O
.	O
	
Adadelta	B-Method
was	O
used	O
to	O
automatically	O
adapt	O
the	O
learning	O
rate	O
of	O
each	O
parameter	O
(	O
and	O
)	O
.	O
	
We	O
explicitly	O
normalized	O
the	O
-	O
norm	O
of	O
the	O
gradient	O
of	O
the	O
cost	O
function	O
each	O
time	O
to	O
be	O
at	O
most	O
a	O
predefined	O
threshold	O
of	O
,	O
when	O
the	O
norm	O
was	O
larger	O
than	O
the	O
threshold	O
.	O
	
Each	O
SGD	B-Method
update	O
direction	O
was	O
computed	O
with	O
a	O
minibatch	O
of	O
80	O
sentences	O
.	O
	
At	O
each	O
update	O
our	O
implementation	O
requires	O
time	O
proportional	O
to	O
the	O
length	O
of	O
the	O
longest	O
sentence	O
in	O
a	O
minibatch	O
.	O
	
Hence	O
,	O
to	O
minimize	O
the	O
waste	O
of	O
computation	O
,	O
before	O
every	O
20	O
-	O
th	O
update	O
,	O
we	O
retrieved	O
1600	O
sentence	O
pairs	O
,	O
sorted	O
them	O
according	O
to	O
the	O
lengths	O
and	O
split	O
them	O
into	O
20	O
minibatches	O
.	O
	
The	O
training	O
data	O
was	O
shuffled	O
once	O
before	O
training	O
and	O
was	O
traversed	O
sequentially	O
in	O
this	O
manner	O
.	O
	
In	O
Tables	O
[	O
reference	O
]	O
we	O
present	O
the	O
statistics	O
related	O
to	O
training	O
all	O
the	O
models	O
used	O
in	O
the	O
experiments	O
.	O
	
appendix	O
:	O
Translations	O
of	O
Long	O
Sentences	O
	
document	O
:	O
Image	B-Task
-	I-Task
to	I-Task
-	I-Task
Image	I-Task
Translation	I-Task
with	O
Conditional	B-Method
Adversarial	I-Method
Networks	I-Method
	
We	O
investigate	O
conditional	B-Method
adversarial	I-Method
networks	I-Method
as	O
a	O
general	O
-	O
purpose	O
solution	O
to	O
image	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
translation	I-Task
problems	I-Task
.	O
	
These	O
networks	O
not	O
only	O
learn	O
the	O
mapping	O
from	O
input	O
image	O
to	O
output	O
image	O
,	O
but	O
also	O
learn	O
a	O
loss	O
function	O
to	O
train	O
this	O
mapping	O
.	O
	
This	O
makes	O
it	O
possible	O
to	O
apply	O
the	O
same	O
generic	O
approach	O
to	O
problems	O
that	O
traditionally	O
would	O
require	O
very	O
different	O
loss	B-Method
formulations	I-Method
.	O
	
We	O
demonstrate	O
that	O
this	O
approach	O
is	O
effective	O
at	O
synthesizing	B-Task
photos	I-Task
from	O
label	B-Method
maps	I-Method
,	O
reconstructing	O
objects	O
from	O
edge	O
maps	O
,	O
and	O
colorizing	O
images	O
,	O
among	O
other	O
tasks	O
.	O
	
Indeed	O
,	O
since	O
the	O
release	O
of	O
the	O
pix2pix	B-Method
software	O
associated	O
with	O
this	O
paper	O
,	O
a	O
large	O
number	O
of	O
internet	O
users	O
(	O
many	O
of	O
them	O
artists	O
)	O
have	O
posted	O
their	O
own	O
experiments	O
with	O
our	O
system	O
,	O
further	O
demonstrating	O
its	O
wide	O
applicability	O
and	O
ease	O
of	O
adoption	O
without	O
the	O
need	O
for	O
parameter	B-Method
tweaking	I-Method
.	O
	
As	O
a	O
community	O
,	O
we	O
no	O
longer	O
hand	O
-	O
engineer	O
our	O
mapping	B-Method
functions	I-Method
,	O
and	O
this	O
work	O
suggests	O
we	O
can	O
achieve	O
reasonable	O
results	O
without	O
hand	O
-	O
engineering	O
our	O
loss	B-Method
functions	I-Method
either	O
.	O
	
section	O
:	O
Introduction	O
	
Many	O
problems	O
in	O
image	B-Task
processing	I-Task
,	O
computer	B-Task
graphics	I-Task
,	O
and	O
computer	B-Task
vision	I-Task
can	O
be	O
posed	O
as	O
“	O
translating	O
”	O
an	O
input	O
image	O
into	O
a	O
corresponding	O
output	O
image	O
.	O
	
Just	O
as	O
a	O
concept	O
may	O
be	O
expressed	O
in	O
either	O
English	O
or	O
French	O
,	O
a	O
scene	O
may	O
be	O
rendered	O
as	O
an	O
RGB	O
image	O
,	O
a	O
gradient	O
field	O
,	O
an	O
edge	O
map	O
,	O
a	O
semantic	O
label	O
map	O
,	O
etc	O
.	O
	
In	O
analogy	O
to	O
automatic	B-Task
language	I-Task
translation	I-Task
,	O
we	O
define	O
automatic	B-Task
image	I-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
translation	I-Task
as	O
the	O
task	O
of	O
translating	O
one	O
possible	O
representation	B-Task
of	I-Task
a	I-Task
scene	I-Task
into	O
another	O
,	O
given	O
sufficient	O
training	O
data	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
Traditionally	O
,	O
each	O
of	O
these	O
tasks	O
has	O
been	O
tackled	O
with	O
separate	O
,	O
special	O
-	O
purpose	O
machinery	O
(	O
e.g.	O
,	O
)	O
,	O
despite	O
the	O
fact	O
that	O
the	O
setting	O
is	O
always	O
the	O
same	O
:	O
predict	O
pixels	O
from	O
pixels	O
.	O
	
Our	O
goal	O
in	O
this	O
paper	O
is	O
to	O
develop	O
a	O
common	O
framework	O
for	O
all	O
these	O
problems	O
.	O
	
The	O
community	O
has	O
already	O
taken	O
significant	O
steps	O
in	O
this	O
direction	O
,	O
with	O
convolutional	B-Method
neural	I-Method
nets	I-Method
(	O
CNNs	B-Method
)	O
becoming	O
the	O
common	O
workhorse	O
behind	O
a	O
wide	O
variety	O
of	O
image	B-Task
prediction	I-Task
problems	I-Task
.	O
	
CNNs	B-Method
learn	O
to	O
minimize	O
a	O
loss	O
function	O
–	O
	
an	O
objective	O
that	O
scores	O
the	O
quality	O
of	O
results	O
–	O
and	O
although	O
the	O
learning	B-Method
process	I-Method
is	O
automatic	O
,	O
a	O
lot	O
of	O
manual	O
effort	O
still	O
goes	O
into	O
designing	O
effective	O
losses	O
.	O
	
In	O
other	O
words	O
,	O
we	O
still	O
have	O
to	O
tell	O
the	O
CNN	O
what	O
we	O
wish	O
it	O
to	O
minimize	O
.	O
	
But	O
,	O
just	O
like	O
King	O
Midas	O
,	O
we	O
must	O
be	O
careful	O
what	O
we	O
wish	O
for	O
!	O
	
If	O
we	O
take	O
a	O
naive	O
approach	O
and	O
ask	O
the	O
CNN	B-Method
to	O
minimize	O
the	O
Euclidean	O
distance	O
between	O
predicted	O
and	O
ground	O
truth	O
pixels	O
,	O
it	O
will	O
tend	O
to	O
produce	O
blurry	O
results	O
.	O
	
This	O
is	O
because	O
Euclidean	O
distance	O
is	O
minimized	O
by	O
averaging	O
all	O
plausible	O
outputs	O
,	O
which	O
causes	O
blurring	O
.	O
	
Coming	O
up	O
with	O
loss	B-Method
functions	I-Method
that	O
force	O
the	O
CNN	B-Method
to	O
do	O
what	O
we	O
really	O
want	O
–	O
	
e.g.	O
,	O
output	O
sharp	O
,	O
realistic	O
images	O
–	O
is	O
an	O
open	O
problem	O
and	O
generally	O
requires	O
expert	O
knowledge	O
.	O
	
It	O
would	O
be	O
highly	O
desirable	O
if	O
we	O
could	O
instead	O
specify	O
only	O
a	O
high	O
-	O
level	O
goal	O
,	O
like	O
“	O
make	O
the	O
output	O
indistinguishable	O
from	O
reality	O
”	O
,	O
and	O
then	O
automatically	O
learn	O
a	O
loss	B-Method
function	I-Method
appropriate	O
for	O
satisfying	O
this	O
goal	O
.	O
	
Fortunately	O
,	O
this	O
is	O
exactly	O
what	O
is	O
done	O
by	O
the	O
recently	O
proposed	O
Generative	B-Method
Adversarial	I-Method
Networks	I-Method
(	O
GANs	B-Method
)	O
.	O
	
GANs	B-Method
learn	O
a	O
loss	O
that	O
tries	O
to	O
classify	O
if	O
the	O
output	O
image	O
is	O
real	O
or	O
fake	O
,	O
while	O
simultaneously	O
training	O
a	O
generative	B-Method
model	I-Method
to	O
minimize	O
this	O
loss	O
.	O
	
Blurry	O
images	O
will	O
not	O
be	O
tolerated	O
since	O
they	O
look	O
obviously	O
fake	O
.	O
	
Because	O
GANs	B-Method
learn	O
a	O
loss	B-Method
that	O
adapts	O
to	O
the	O
data	O
,	O
they	O
can	O
be	O
applied	O
to	O
a	O
multitude	O
of	O
tasks	O
that	O
traditionally	O
would	O
require	O
very	O
different	O
kinds	O
of	O
loss	O
functions	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
explore	O
GANs	B-Method
in	O
the	O
conditional	B-Task
setting	I-Task
.	O
	
Just	O
as	O
GANs	B-Method
learn	O
a	O
generative	B-Method
model	I-Method
of	I-Method
data	I-Method
,	O
conditional	B-Method
GANs	I-Method
(	O
cGANs	B-Method
)	O
learn	O
a	O
conditional	B-Method
generative	I-Method
model	I-Method
.	O
	
This	O
makes	O
cGANs	B-Method
suitable	O
for	O
image	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
translation	I-Task
tasks	I-Task
,	O
where	O
we	O
condition	O
on	O
an	O
input	O
image	O
and	O
generate	O
a	O
corresponding	O
output	O
image	O
.	O
	
GANs	B-Method
have	O
been	O
vigorously	O
studied	O
in	O
the	O
last	O
two	O
years	O
and	O
many	O
of	O
the	O
techniques	O
we	O
explore	O
in	O
this	O
paper	O
have	O
been	O
previously	O
proposed	O
.	O
	
Nonetheless	O
,	O
earlier	O
papers	O
have	O
focused	O
on	O
specific	O
applications	O
,	O
and	O
it	O
has	O
remained	O
unclear	O
how	O
effective	O
image	O
-	O
conditional	O
GANs	B-Method
can	O
be	O
as	O
a	O
general	O
-	O
purpose	O
solution	O
for	O
image	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
translation	I-Task
.	O
	
Our	O
primary	O
contribution	O
is	O
to	O
demonstrate	O
that	O
on	O
a	O
wide	O
variety	O
of	O
problems	O
,	O
conditional	B-Method
GANs	I-Method
produce	O
reasonable	O
results	O
.	O
	
Our	O
second	O
contribution	O
is	O
to	O
present	O
a	O
simple	O
framework	O
sufficient	O
to	O
achieve	O
good	O
results	O
,	O
and	O
to	O
analyze	O
the	O
effects	O
of	O
several	O
important	O
architectural	O
choices	O
.	O
	
Code	O
is	O
available	O
at	O
https:	O
//	O
github.com	O
/	O
phillipi	O
/	O
pix2pix	B-Method
.	O
	
section	O
:	O
Related	O
work	O
	
Structured	B-Method
losses	I-Method
for	O
image	B-Task
modeling	I-Task
Image	I-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
translation	I-Task
problems	I-Task
are	O
often	O
formulated	O
as	O
per	B-Task
-	I-Task
pixel	I-Task
classification	I-Task
or	I-Task
regression	I-Task
(	O
e.g.	O
,	O
)	O
.	O
	
These	O
formulations	O
treat	O
the	O
output	O
space	O
as	O
“	O
unstructured	O
”	O
in	O
the	O
sense	O
that	O
each	O
output	O
pixel	O
is	O
considered	O
conditionally	O
independent	O
from	O
all	O
others	O
given	O
the	O
input	O
image	O
.	O
	
Conditional	O
GANs	B-Method
instead	O
learn	O
a	O
structured	O
loss	O
.	O
	
Structured	O
losses	O
penalize	O
the	O
joint	O
configuration	O
of	O
the	O
output	O
.	O
	
A	O
large	O
body	O
of	O
literature	O
has	O
considered	O
losses	O
of	O
this	O
kind	O
,	O
with	O
methods	O
including	O
conditional	B-Method
random	I-Method
fields	I-Method
,	O
the	O
SSIM	B-Method
metric	I-Method
,	O
feature	B-Method
matching	I-Method
,	O
nonparametric	B-Method
losses	I-Method
,	O
the	O
convolutional	B-Method
pseudo	I-Method
-	I-Method
prior	I-Method
,	O
and	O
losses	B-Method
based	O
on	O
matching	B-Method
covariance	I-Method
statistics	I-Method
.	O
	
The	O
conditional	O
GAN	B-Method
is	O
different	O
in	O
that	O
the	O
loss	O
is	O
learned	O
,	O
and	O
can	O
,	O
in	O
theory	O
,	O
penalize	O
any	O
possible	O
structure	O
that	O
differs	O
between	O
output	O
and	O
target	O
.	O
	
Conditional	O
GANs	B-Method
	
We	O
are	O
not	O
the	O
first	O
to	O
apply	O
GANs	B-Method
in	O
the	O
conditional	O
setting	O
.	O
	
Prior	O
and	O
concurrent	O
works	O
have	O
conditioned	O
GANs	B-Method
on	O
discrete	O
labels	O
,	O
text	O
,	O
and	O
,	O
indeed	O
,	O
images	O
.	O
	
The	O
image	B-Method
-	I-Method
conditional	I-Method
models	I-Method
have	O
tackled	O
image	B-Task
prediction	I-Task
from	O
a	O
normal	B-Task
map	I-Task
,	O
future	B-Task
frame	I-Task
prediction	I-Task
,	O
product	B-Task
photo	I-Task
generation	I-Task
,	O
and	O
image	B-Task
generation	I-Task
from	O
sparse	O
annotations	O
(	O
c.f	O
.	O
for	O
an	O
autoregressive	B-Method
approach	I-Method
to	O
the	O
same	O
problem	O
)	O
.	O
	
Several	O
other	O
papers	O
have	O
also	O
used	O
GANs	B-Method
for	O
image	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
mappings	I-Task
,	O
but	O
only	O
applied	O
the	O
GAN	B-Method
unconditionally	O
,	O
relying	O
on	O
other	O
terms	O
(	O
such	O
as	O
L2	B-Method
regression	I-Method
)	O
to	O
force	O
the	O
output	O
to	O
be	O
conditioned	O
on	O
the	O
input	O
.	O
	
These	O
papers	O
have	O
achieved	O
impressive	O
results	O
on	O
inpainting	B-Task
,	O
future	B-Task
state	I-Task
prediction	I-Task
,	O
image	B-Task
manipulation	I-Task
guided	O
by	O
user	O
constraints	O
,	O
style	B-Task
transfer	I-Task
,	O
and	O
superresolution	B-Task
.	O
	
Each	O
of	O
the	O
methods	O
was	O
tailored	O
for	O
a	O
specific	O
application	O
.	O
	
Our	O
framework	O
differs	O
in	O
that	O
nothing	O
is	O
application	O
-	O
specific	O
.	O
	
This	O
makes	O
our	O
setup	O
considerably	O
simpler	O
than	O
most	O
others	O
.	O
	
Our	O
method	O
also	O
differs	O
from	O
the	O
prior	O
works	O
in	O
several	O
architectural	O
choices	O
for	O
the	O
generator	B-Method
and	I-Method
discriminator	I-Method
.	O
	
Unlike	O
past	O
work	O
,	O
for	O
our	O
generator	O
we	O
use	O
a	O
“	B-Method
U	I-Method
-	I-Method
Net”	I-Method
-	I-Method
based	I-Method
architecture	I-Method
,	O
and	O
for	O
our	O
discriminator	B-Method
we	O
use	O
a	O
convolutional	B-Method
“	I-Method
	
PatchGAN	B-Method
”	I-Method
classifier	I-Method
,	O
which	O
only	O
penalizes	O
structure	O
at	O
the	O
scale	O
of	O
image	O
patches	O
.	O
	
A	O
similar	O
PatchGAN	B-Method
architecture	I-Method
was	O
previously	O
proposed	O
in	O
to	O
capture	O
local	O
style	O
statistics	O
.	O
	
Here	O
we	O
show	O
that	O
this	O
approach	O
is	O
effective	O
on	O
a	O
wider	O
range	O
of	O
problems	O
,	O
and	O
we	O
investigate	O
the	O
effect	O
of	O
changing	O
the	O
patch	O
size	O
.	O
	
section	O
:	O
Method	O
	
GANs	B-Method
are	O
generative	B-Method
models	I-Method
that	O
learn	O
a	O
mapping	O
from	O
random	O
noise	O
vector	O
to	O
output	O
image	O
,	O
.	O
	
In	O
contrast	O
,	O
conditional	B-Method
GANs	I-Method
learn	O
a	O
mapping	O
from	O
observed	O
image	O
and	O
random	O
noise	O
vector	O
,	O
to	O
,	O
.	O
	
The	O
generator	O
is	O
trained	O
to	O
produce	O
outputs	O
that	O
can	O
not	O
be	O
distinguished	O
from	O
“	O
real	O
”	O
images	O
by	O
an	O
adversarially	O
trained	O
discriminator	B-Method
,	O
,	O
which	O
is	O
trained	O
to	O
do	O
as	O
well	O
as	O
possible	O
at	O
detecting	O
the	O
generator	O
’s	O
“	O
fakes	O
”	O
.	O
	
This	O
training	O
procedure	O
is	O
diagrammed	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
subsection	O
:	O
Objective	O
	
The	O
objective	O
of	O
a	O
conditional	O
GAN	B-Method
can	O
be	O
expressed	O
as	O
where	O
tries	O
to	O
minimize	O
this	O
objective	O
against	O
an	O
adversarial	O
that	O
tries	O
to	O
maximize	O
it	O
,	O
i.e.	O
.	O
	
To	O
test	O
the	O
importance	O
of	O
conditioning	O
the	O
discriminator	O
,	O
we	O
also	O
compare	O
to	O
an	O
unconditional	B-Method
variant	I-Method
in	O
which	O
the	O
discriminator	O
does	O
not	O
observe	O
:	O
Previous	O
approaches	O
have	O
found	O
it	O
beneficial	O
to	O
mix	O
the	O
GAN	B-Method
objective	O
with	O
a	O
more	O
traditional	O
loss	B-Metric
,	O
such	O
as	O
L2	B-Method
distance	I-Method
.	O
	
The	O
discriminator	O
	
’s	O
job	O
remains	O
unchanged	O
,	O
but	O
the	O
generator	O
is	O
tasked	O
to	O
not	O
only	O
fool	O
the	O
discriminator	B-Method
but	O
also	O
to	O
be	O
near	O
the	O
ground	O
truth	O
output	O
in	O
an	O
L2	O
sense	O
.	O
	
We	O
also	O
explore	O
this	O
option	O
,	O
using	O
L1	O
distance	O
rather	O
than	O
L2	O
as	O
L1	O
encourages	O
less	O
blurring	O
:	O
	
Our	O
final	O
objective	O
is	O
Without	O
,	O
the	O
net	O
could	O
still	O
learn	O
a	O
mapping	O
from	O
to	O
,	O
but	O
would	O
produce	O
deterministic	O
outputs	O
,	O
and	O
therefore	O
fail	O
to	O
match	O
any	O
distribution	O
other	O
than	O
a	O
delta	O
function	O
.	O
	
Past	O
conditional	B-Method
GANs	I-Method
have	O
acknowledged	O
this	O
and	O
provided	O
Gaussian	O
noise	O
as	O
an	O
input	O
to	O
the	O
generator	B-Method
,	O
in	O
addition	O
to	O
(	O
e.g.	O
,	O
)	O
.	O
	
In	O
initial	O
experiments	O
,	O
we	O
did	O
not	O
find	O
this	O
strategy	O
effective	O
–	O
the	O
generator	B-Method
simply	O
learned	O
to	O
ignore	O
the	O
noise	O
–	O
which	O
is	O
consistent	O
with	O
Mathieu	O
et	O
al	O
.	O
.	O
	
Instead	O
,	O
for	O
our	O
final	O
models	O
,	O
we	O
provide	O
noise	O
only	O
in	O
the	O
form	O
of	O
dropout	B-Method
,	O
applied	O
on	O
several	O
layers	O
of	O
our	O
generator	O
at	O
both	O
training	O
and	O
test	O
time	O
.	O
	
Despite	O
the	O
dropout	O
noise	O
,	O
we	O
observe	O
only	O
minor	O
stochasticity	O
in	O
the	O
output	O
of	O
our	O
nets	O
.	O
	
Designing	O
conditional	B-Method
GANs	I-Method
that	O
produce	O
highly	O
stochastic	O
output	O
,	O
and	O
thereby	O
capture	O
the	O
full	O
entropy	O
of	O
the	O
conditional	B-Method
distributions	I-Method
they	O
model	O
,	O
is	O
an	O
important	O
question	O
left	O
open	O
by	O
the	O
present	O
work	O
.	O
	
subsection	O
:	O
Network	B-Method
architectures	I-Method
	
We	O
adapt	O
our	O
generator	B-Method
and	I-Method
discriminator	I-Method
architectures	I-Method
from	O
those	O
in	O
.	O
	
Both	O
generator	B-Method
and	O
discriminator	B-Method
use	O
modules	O
of	O
the	O
form	O
convolution	B-Method
-	I-Method
BatchNorm	I-Method
-	I-Method
ReLu	I-Method
.	O
	
Details	O
of	O
the	O
architecture	O
are	O
provided	O
in	O
the	O
supplemental	O
materials	O
online	O
,	O
with	O
key	O
features	O
discussed	O
below	O
.	O
	
subsubsection	O
:	O
Generator	B-Method
with	O
skips	O
	
A	O
defining	O
feature	O
of	O
image	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
translation	I-Task
problems	I-Task
is	O
that	O
they	O
map	O
a	O
high	O
resolution	O
input	O
grid	O
to	O
a	O
high	O
resolution	O
output	O
grid	O
.	O
	
In	O
addition	O
,	O
for	O
the	O
problems	O
we	O
consider	O
,	O
the	O
input	O
and	O
output	O
differ	O
in	O
surface	O
appearance	O
,	O
but	O
both	O
are	O
renderings	O
of	O
the	O
same	O
underlying	O
structure	O
.	O
	
Therefore	O
,	O
structure	O
in	O
the	O
input	O
is	O
roughly	O
aligned	O
with	O
structure	O
in	O
the	O
output	O
.	O
	
We	O
design	O
the	O
generator	B-Method
architecture	I-Method
around	O
these	O
considerations	O
.	O
	
Many	O
previous	O
solutions	O
to	O
problems	O
in	O
this	O
area	O
have	O
used	O
an	O
encoder	B-Method
-	I-Method
decoder	I-Method
network	I-Method
.	O
	
In	O
such	O
a	O
network	O
,	O
the	O
input	O
is	O
passed	O
through	O
a	O
series	O
of	O
layers	O
that	O
progressively	O
downsample	O
,	O
until	O
a	O
bottleneck	O
layer	O
,	O
at	O
which	O
point	O
the	O
process	O
is	O
reversed	O
.	O
	
Such	O
a	O
network	O
requires	O
that	O
all	O
information	O
flow	O
pass	O
through	O
all	O
the	O
layers	O
,	O
including	O
the	O
bottleneck	O
.	O
	
For	O
many	O
image	B-Task
translation	I-Task
problems	I-Task
,	O
there	O
is	O
a	O
great	O
deal	O
of	O
low	O
-	O
level	O
information	O
shared	O
between	O
the	O
input	O
and	O
output	O
,	O
and	O
it	O
would	O
be	O
desirable	O
to	O
shuttle	O
this	O
information	O
directly	O
across	O
the	O
net	O
.	O
	
For	O
example	O
,	O
in	O
the	O
case	O
of	O
image	B-Task
colorization	I-Task
,	O
the	O
input	O
and	O
output	O
share	O
the	O
location	O
of	O
prominent	O
edges	O
.	O
	
To	O
give	O
the	O
generator	O
a	O
means	O
to	O
circumvent	O
the	O
bottleneck	O
for	O
information	O
like	O
this	O
,	O
we	O
add	O
skip	O
connections	O
,	O
following	O
the	O
general	O
shape	O
of	O
a	O
“	O
U	B-Method
-	I-Method
Net	I-Method
”	O
.	O
	
Specifically	O
,	O
we	O
add	O
skip	O
connections	O
between	O
each	O
layer	O
and	O
layer	O
,	O
where	O
is	O
the	O
total	O
number	O
of	O
layers	O
.	O
	
Each	O
skip	B-Method
connection	I-Method
simply	O
concatenates	O
all	O
channels	O
at	O
layer	O
with	O
those	O
at	O
layer	O
.	O
	
subsubsection	O
:	O
Markovian	B-Method
discriminator	I-Method
(	O
PatchGAN	B-Method
)	O
	
It	O
is	O
well	O
known	O
that	O
the	O
L2	O
loss	O
–	O
and	O
L1	O
,	O
see	O
Figure	O
[	O
reference	O
]	O
	
–	O
produces	O
blurry	O
results	O
on	O
image	B-Task
generation	I-Task
problems	I-Task
.	O
	
Although	O
these	O
losses	O
fail	O
to	O
encourage	O
high	O
-	O
frequency	O
crispness	O
,	O
in	O
many	O
cases	O
they	O
nonetheless	O
accurately	O
capture	O
the	O
low	O
frequencies	O
.	O
	
For	O
problems	O
where	O
this	O
is	O
the	O
case	O
,	O
we	O
do	O
not	O
need	O
an	O
entirely	O
new	O
framework	O
to	O
enforce	O
correctness	O
at	O
the	O
low	O
frequencies	O
.	O
	
L1	O
will	O
already	O
do	O
.	O
	
This	O
motivates	O
restricting	O
the	O
GAN	B-Method
discriminator	O
to	O
only	O
model	O
high	O
-	O
frequency	O
structure	O
,	O
relying	O
on	O
an	O
L1	B-Method
term	I-Method
to	O
force	O
low	O
-	O
frequency	O
correctness	O
(	O
Eqn	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
In	O
order	O
to	O
model	O
high	O
-	O
frequencies	O
,	O
it	O
is	O
sufficient	O
to	O
restrict	O
our	O
attention	O
to	O
the	O
structure	O
in	O
local	O
image	O
patches	O
.	O
	
Therefore	O
,	O
we	O
design	O
a	O
discriminator	B-Method
architecture	I-Method
–	O
which	O
we	O
term	O
a	O
Patch	B-Method
GAN	I-Method
–	O
that	O
only	O
penalizes	O
structure	O
at	O
the	O
scale	O
of	O
patches	O
.	O
	
This	O
discriminator	O
tries	O
to	O
classify	O
if	O
each	O
patch	O
in	O
an	O
image	O
is	O
real	O
or	O
fake	O
.	O
	
We	O
run	O
this	O
discriminator	O
convolutionally	O
across	O
the	O
image	O
,	O
averaging	O
all	O
responses	O
to	O
provide	O
the	O
ultimate	O
output	O
of	O
.	O
	
In	O
Section	O
[	O
reference	O
]	O
,	O
we	O
demonstrate	O
that	O
can	O
be	O
much	O
smaller	O
than	O
the	O
full	O
size	O
of	O
the	O
image	O
and	O
still	O
produce	O
high	O
quality	O
results	O
.	O
	
This	O
is	O
advantageous	O
because	O
a	O
smaller	O
PatchGAN	O
has	O
fewer	O
parameters	O
,	O
runs	O
faster	O
,	O
and	O
can	O
be	O
applied	O
to	O
arbitrarily	O
large	O
images	O
.	O
	
Such	O
a	O
discriminator	B-Method
effectively	O
models	O
the	O
image	O
as	O
a	O
Markov	B-Method
random	I-Method
field	I-Method
,	O
assuming	O
independence	O
between	O
pixels	O
separated	O
by	O
more	O
than	O
a	O
patch	O
diameter	O
.	O
	
This	O
connection	O
was	O
previously	O
explored	O
in	O
,	O
and	O
is	O
also	O
the	O
common	O
assumption	O
in	O
models	O
of	O
texture	O
and	O
style	O
.	O
	
Therefore	O
,	O
our	O
PatchGAN	B-Method
can	O
be	O
understood	O
as	O
a	O
form	O
of	O
texture	B-Task
/	I-Task
style	I-Task
loss	I-Task
.	O
	
subsection	O
:	O
Optimization	B-Task
and	O
inference	B-Task
	
To	O
optimize	O
our	O
networks	O
,	O
we	O
follow	O
the	O
standard	O
approach	O
from	O
:	O
we	O
alternate	O
between	O
one	O
gradient	B-Method
descent	I-Method
step	I-Method
on	O
,	O
then	O
one	O
step	O
on	O
.	O
	
As	O
suggested	O
in	O
the	O
original	O
GAN	B-Method
paper	O
,	O
rather	O
than	O
training	O
to	O
minimize	O
,	O
we	O
instead	O
train	O
to	O
maximize	O
.	O
	
In	O
addition	O
,	O
we	O
divide	O
the	O
objective	O
by	O
while	O
optimizing	B-Task
,	O
which	O
slows	O
down	O
the	O
rate	O
at	O
which	O
learns	O
relative	O
to	O
.	O
	
We	O
use	O
minibatch	B-Method
SGD	I-Method
and	O
apply	O
the	O
Adam	B-Method
solver	I-Method
,	O
with	O
a	O
learning	B-Metric
rate	I-Metric
of	O
,	O
and	O
momentum	O
parameters	O
,	O
.	O
	
At	O
inference	O
time	O
,	O
we	O
run	O
the	O
generator	B-Method
net	I-Method
in	O
exactly	O
the	O
same	O
manner	O
as	O
during	O
the	O
training	O
phase	O
.	O
	
This	O
differs	O
from	O
the	O
usual	O
protocol	O
in	O
that	O
we	O
apply	O
dropout	O
at	O
test	O
time	O
,	O
and	O
we	O
apply	O
batch	B-Method
normalization	I-Method
using	O
the	O
statistics	O
of	O
the	O
test	O
batch	O
,	O
rather	O
than	O
aggregated	O
statistics	O
of	O
the	O
training	O
batch	O
.	O
	
This	O
approach	O
to	O
batch	B-Task
normalization	I-Task
,	O
when	O
the	O
batch	O
size	O
is	O
set	O
to	O
1	O
,	O
has	O
been	O
termed	O
“	O
instance	B-Method
normalization	I-Method
”	O
and	O
has	O
been	O
demonstrated	O
to	O
be	O
effective	O
at	O
image	B-Task
generation	I-Task
tasks	I-Task
.	O
	
In	O
our	O
experiments	O
,	O
we	O
use	O
batch	O
sizes	O
between	O
1	O
and	O
10	O
depending	O
on	O
the	O
experiment	O
.	O
	
section	O
:	O
Experiments	O
	
To	O
explore	O
the	O
generality	O
of	O
conditional	B-Method
GANs	I-Method
,	O
we	O
test	O
the	O
method	O
on	O
a	O
variety	O
of	O
tasks	O
and	O
datasets	O
,	O
including	O
both	O
graphics	B-Task
tasks	I-Task
,	O
like	O
photo	B-Task
generation	I-Task
,	O
and	O
vision	B-Task
tasks	I-Task
,	O
like	O
semantic	B-Task
segmentation	I-Task
:	O
Semantic	O
labels↔photo	O
,	O
trained	O
on	O
the	O
Cityscapes	B-Material
dataset	I-Material
.	O
	
Architectural	O
labels→photo	O
,	O
trained	O
on	O
CMP	B-Method
Facades	I-Method
.	O
	
Map↔aerial	B-Material
photo	I-Material
,	O
trained	O
on	O
data	O
scraped	O
from	O
Google	O
Maps	O
.	O
	
BW→color	O
photos	O
,	O
trained	O
on	O
.	O
	
Edges→photo	O
,	O
trained	O
on	O
data	O
from	O
and	O
	
;	O
binary	O
edges	O
generated	O
using	O
the	O
HED	B-Method
edge	I-Method
detector	I-Method
plus	O
postprocessing	B-Method
.	O
	
Sketch→photo	B-Method
:	O
tests	O
edges	B-Method
photo	I-Method
models	I-Method
on	O
human	O
-	O
drawn	O
sketches	O
from	O
.	O
	
Day→night	O
,	O
trained	O
on	O
.	O
	
Thermal→color	O
photos	O
,	O
trained	O
on	O
data	O
from	O
.	O
	
Photo	O
with	O
missing	O
pixels→inpainted	O
photo	O
,	O
trained	O
on	O
Paris	O
StreetView	O
from	O
.	O
	
Details	O
of	O
training	O
on	O
each	O
of	O
these	O
datasets	O
are	O
provided	O
in	O
the	O
supplemental	O
materials	O
online	O
.	O
	
In	O
all	O
cases	O
,	O
the	O
input	O
and	O
output	O
are	O
simply	O
1	O
-	O
3	O
channel	O
images	O
.	O
	
Qualitative	O
results	O
are	O
shown	O
in	O
Figures	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
.	O
	
Several	O
failure	O
cases	O
are	O
highlighted	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
More	O
comprehensive	O
results	O
are	O
available	O
at	O
https:	O
//	O
phillipi.github.io	O
/	O
pix2pix	B-Method
/	O
.	O
	
Data	O
requirements	O
and	O
speed	O
	
We	O
note	O
that	O
decent	O
results	O
can	O
often	O
be	O
obtained	O
even	O
on	O
small	O
datasets	O
.	O
	
Our	O
facade	O
training	O
set	O
consists	O
of	O
just	O
400	O
images	O
(	O
see	O
results	O
in	O
Figure	O
[	O
reference	O
]	O
)	O
,	O
and	O
the	O
day	O
to	O
night	O
training	O
set	O
consists	O
of	O
only	O
91	O
unique	O
webcams	O
(	O
see	O
results	O
in	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
On	O
datasets	O
of	O
this	O
size	O
,	O
training	B-Task
can	O
be	O
very	O
fast	O
:	O
for	O
example	O
,	O
the	O
results	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
took	O
less	O
than	O
two	O
hours	O
of	O
training	O
on	O
a	O
single	O
Pascal	O
Titan	O
X	O
GPU	O
.	O
	
At	O
test	O
time	O
,	O
all	O
models	O
run	O
in	O
well	O
under	O
a	O
second	O
on	O
this	O
GPU	O
.	O
	
subsection	O
:	O
Evaluation	B-Metric
metrics	I-Metric
	
Evaluating	O
the	O
quality	B-Metric
of	O
synthesized	O
images	O
is	O
an	O
open	O
and	O
difficult	O
problem	O
.	O
	
Traditional	O
metrics	O
such	O
as	O
per	B-Metric
-	I-Metric
pixel	I-Metric
mean	I-Metric
-	I-Metric
squared	I-Metric
error	I-Metric
do	O
not	O
assess	O
joint	O
statistics	O
of	O
the	O
result	O
,	O
and	O
therefore	O
do	O
not	O
measure	O
the	O
very	O
structure	O
that	O
structured	O
losses	O
aim	O
to	O
capture	O
.	O
	
To	O
more	O
holistically	O
evaluate	O
the	O
visual	B-Metric
quality	I-Metric
of	O
our	O
results	O
,	O
we	O
employ	O
two	O
tactics	O
.	O
	
First	O
,	O
we	O
run	O
“	O
real	O
vs.	O
fake	O
”	O
perceptual	O
studies	O
on	O
Amazon	O
Mechanical	O
Turk	O
(	O
AMT	O
)	O
.	O
	
For	O
graphics	B-Task
problems	I-Task
like	O
colorization	B-Task
and	O
photo	B-Task
generation	I-Task
,	O
plausibility	O
to	O
a	O
human	O
observer	O
is	O
often	O
the	O
ultimate	O
goal	O
.	O
	
Therefore	O
,	O
we	O
test	O
our	O
map	B-Task
generation	I-Task
,	O
aerial	B-Task
photo	I-Task
generation	I-Task
,	O
and	O
image	B-Task
colorization	I-Task
using	O
this	O
approach	O
.	O
	
Second	O
,	O
we	O
measure	O
whether	O
or	O
not	O
our	O
synthesized	O
cityscapes	O
are	O
realistic	O
enough	O
that	O
off	O
-	O
the	O
-	O
shelf	O
recognition	B-Method
system	I-Method
can	O
recognize	O
the	O
objects	O
in	O
them	O
.	O
	
This	O
metric	O
is	O
similar	O
to	O
the	O
“	O
inception	B-Metric
score	I-Metric
”	I-Metric
from	O
,	O
the	O
object	B-Metric
detection	I-Metric
evaluation	I-Metric
in	O
,	O
and	O
the	O
“	O
semantic	B-Metric
interpretability	I-Metric
”	I-Metric
measures	I-Metric
in	O
and	O
.	O
	
AMT	B-Task
perceptual	I-Task
studies	I-Task
For	O
our	O
AMT	O
experiments	O
	
,	O
we	O
followed	O
the	O
protocol	O
from	O
:	O
Turkers	O
were	O
presented	O
with	O
a	O
series	O
of	O
trials	O
that	O
pitted	O
a	O
“	O
real	O
”	O
image	O
against	O
a	O
“	O
fake	O
”	O
image	O
generated	O
by	O
our	O
algorithm	O
.	O
	
On	O
each	O
trial	O
,	O
each	O
image	O
appeared	O
for	O
1	O
second	O
,	O
after	O
which	O
the	O
images	O
disappeared	O
and	O
Turkers	O
were	O
given	O
unlimited	O
time	O
to	O
respond	O
as	O
to	O
which	O
was	O
fake	O
.	O
	
The	O
first	O
10	O
images	O
of	O
each	O
session	O
were	O
practice	O
and	O
Turkers	O
were	O
given	O
feedback	O
.	O
	
No	O
feedback	O
was	O
provided	O
on	O
the	O
40	O
trials	O
of	O
the	O
main	O
experiment	O
.	O
	
Each	O
session	O
tested	O
just	O
one	O
algorithm	O
at	O
a	O
time	O
,	O
and	O
Turkers	O
were	O
not	O
allowed	O
to	O
complete	O
more	O
than	O
one	O
session	O
.	O
	
Turkers	O
evaluated	O
each	O
algorithm	O
.	O
	
Unlike	O
,	O
we	O
did	O
not	O
include	O
vigilance	O
trials	O
.	O
	
For	O
our	O
colorization	B-Task
experiments	I-Task
,	O
the	O
real	O
and	O
fake	O
images	O
were	O
generated	O
from	O
the	O
same	O
grayscale	O
input	O
.	O
	
For	O
map	B-Material
aerial	I-Material
photo	I-Material
,	O
the	O
real	O
and	O
fake	O
images	O
were	O
not	O
generated	O
from	O
the	O
same	O
input	O
,	O
in	O
order	O
to	O
make	O
the	O
task	O
more	O
difficult	O
and	O
avoid	O
floor	O
-	O
level	O
results	O
.	O
	
For	O
map	B-Material
aerial	I-Material
photo	I-Material
,	O
we	O
trained	O
on	O
resolution	O
images	O
,	O
but	O
exploited	O
fully	B-Method
-	I-Method
convolutional	I-Method
translation	I-Method
(	O
described	O
above	O
)	O
to	O
test	O
on	O
images	O
,	O
which	O
were	O
then	O
downsampled	O
and	O
presented	O
to	O
Turkers	O
at	O
resolution	O
.	O
	
For	O
colorization	B-Task
,	O
we	O
trained	O
and	O
tested	O
on	O
resolution	O
images	O
and	O
presented	O
the	O
results	O
to	O
Turkers	O
at	O
this	O
same	O
resolution	O
.	O
	
“	O
	
FCN	B-Metric
-	I-Metric
score	I-Metric
	
”	O
While	O
quantitative	B-Task
evaluation	I-Task
of	O
generative	B-Method
models	I-Method
is	O
known	O
to	O
be	O
challenging	O
,	O
recent	O
works	O
have	O
tried	O
using	O
pre	O
-	O
trained	O
semantic	B-Method
classifiers	I-Method
to	O
measure	O
the	O
discriminability	O
of	O
the	O
generated	O
stimuli	O
as	O
a	O
pseudo	B-Metric
-	I-Metric
metric	I-Metric
.	O
	
The	O
intuition	O
is	O
that	O
if	O
the	O
generated	O
images	O
are	O
realistic	O
,	O
classifiers	B-Method
trained	O
on	O
real	O
images	O
will	O
be	O
able	O
to	O
classify	O
the	O
synthesized	O
image	O
correctly	O
as	O
well	O
.	O
	
To	O
this	O
end	O
,	O
we	O
adopt	O
the	O
popular	O
FCN	B-Method
-	I-Method
8s	I-Method
architecture	I-Method
for	O
semantic	B-Task
segmentation	I-Task
,	O
and	O
train	O
it	O
on	O
the	O
cityscapes	B-Material
dataset	I-Material
.	O
	
We	O
then	O
score	O
synthesized	O
photos	O
by	O
the	O
classification	B-Metric
accuracy	I-Metric
against	O
the	O
labels	O
these	O
photos	O
were	O
synthesized	O
from	O
.	O
	
subsection	O
:	O
Analysis	O
of	O
the	O
objective	B-Metric
function	I-Metric
	
Which	O
components	O
of	O
the	O
objective	O
in	O
Eqn	O
.	O
	
[	O
reference	O
]	O
are	O
important	O
?	O
	
We	O
run	O
ablation	B-Task
studies	I-Task
to	O
isolate	O
the	O
effect	O
of	O
the	O
L1	O
term	O
,	O
the	O
GAN	B-Method
term	O
,	O
and	O
to	O
compare	O
using	O
a	O
discriminator	B-Method
conditioned	O
on	O
the	O
input	O
(	O
cGAN	B-Method
,	O
Eqn	O
.	O
	
[	O
reference	O
]	O
)	O
against	O
using	O
an	O
unconditional	B-Method
discriminator	I-Method
(	O
GAN	B-Method
,	O
Eqn	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
the	O
qualitative	O
effects	O
of	O
these	O
variations	O
on	O
two	O
labels	B-Task
photo	I-Task
problems	I-Task
.	O
	
L1	B-Method
alone	O
leads	O
to	O
reasonable	O
but	O
blurry	O
results	O
.	O
	
The	O
cGAN	B-Method
alone	O
(	O
setting	O
in	O
Eqn	O
.	O
	
[	O
reference	O
]	O
)	O
gives	O
much	O
sharper	O
results	O
but	O
introduces	O
visual	O
artifacts	O
on	O
certain	O
applications	O
.	O
	
Adding	O
both	O
terms	O
together	O
(	O
with	O
)	O
reduces	O
these	O
artifacts	O
.	O
	
We	O
quantify	O
these	O
observations	O
using	O
the	O
FCN	B-Metric
-	I-Metric
score	I-Metric
on	O
the	O
cityscapes	B-Task
labels	I-Task
photo	I-Task
task	I-Task
(	O
Table	O
[	O
reference	O
]	O
)	O
:	O
the	O
GAN	B-Method
-	O
based	O
objectives	O
achieve	O
higher	O
scores	O
,	O
indicating	O
that	O
the	O
synthesized	O
images	O
include	O
more	O
recognizable	O
structure	O
.	O
	
We	O
also	O
test	O
the	O
effect	O
of	O
removing	O
conditioning	O
from	O
the	O
discriminator	B-Method
(	O
labeled	O
as	O
GAN	B-Method
)	O
.	O
	
In	O
this	O
case	O
,	O
the	O
loss	O
does	O
not	O
penalize	O
mismatch	O
between	O
the	O
input	O
and	O
output	O
;	O
it	O
only	O
cares	O
that	O
the	O
output	O
look	O
realistic	O
.	O
	
This	O
variant	O
results	O
in	O
poor	O
performance	O
;	O
examining	O
the	O
results	O
reveals	O
that	O
the	O
generator	O
collapsed	O
into	O
producing	O
nearly	O
the	O
exact	O
same	O
output	O
regardless	O
of	O
input	O
photograph	O
.	O
	
Clearly	O
,	O
it	O
is	O
important	O
,	O
in	O
this	O
case	O
,	O
that	O
the	O
loss	B-Metric
measure	O
the	O
quality	O
of	O
the	O
match	O
between	O
input	O
and	O
output	O
,	O
and	O
indeed	O
cGAN	B-Method
performs	O
much	O
better	O
than	O
GAN	B-Method
.	O
	
Note	O
,	O
however	O
,	O
that	O
adding	O
an	O
L1	O
term	O
also	O
encourages	O
that	O
the	O
output	O
respect	O
the	O
input	O
,	O
since	O
the	O
L1	O
loss	O
penalizes	O
the	O
distance	O
between	O
ground	O
truth	O
outputs	O
,	O
which	O
correctly	O
match	O
the	O
input	O
,	O
and	O
synthesized	O
outputs	O
,	O
which	O
may	O
not	O
.	O
	
Correspondingly	O
,	O
L1	B-Method
+	I-Method
GAN	I-Method
is	O
also	O
effective	O
at	O
creating	O
realistic	B-Task
renderings	I-Task
that	O
respect	O
the	O
input	O
label	O
maps	O
.	O
	
Combining	O
all	O
terms	O
,	O
L1	O
+	O
cGAN	B-Method
,	O
performs	O
similarly	O
well	O
.	O
	
Colorfulness	O
A	O
striking	O
effect	O
of	O
conditional	B-Method
GANs	I-Method
is	O
that	O
they	O
produce	O
sharp	O
images	O
,	O
hallucinating	O
spatial	O
structure	O
even	O
where	O
it	O
does	O
not	O
exist	O
in	O
the	O
input	O
label	O
map	O
.	O
	
One	O
might	O
imagine	O
cGANs	B-Method
have	O
a	O
similar	O
effect	O
on	O
“	O
sharpening	O
”	O
in	O
the	O
spectral	O
dimension	O
–	O
	
i.e.	O
making	O
images	O
more	O
colorful	O
.	O
	
Just	O
as	O
L1	B-Method
will	O
incentivize	O
a	O
blur	O
when	O
it	O
is	O
uncertain	O
where	O
exactly	O
to	O
locate	O
an	O
edge	O
,	O
it	O
will	O
also	O
incentivize	O
an	O
average	O
,	O
grayish	O
color	O
when	O
it	O
is	O
uncertain	O
which	O
of	O
several	O
plausible	O
color	O
values	O
a	O
pixel	O
should	O
take	O
on	O
.	O
	
Specially	O
,	O
L1	O
will	O
be	O
minimized	O
by	O
choosing	O
the	O
median	O
of	O
the	O
conditional	O
probability	O
density	O
function	O
over	O
possible	O
colors	O
.	O
	
An	O
adversarial	B-Method
loss	I-Method
,	O
on	O
the	O
other	O
hand	O
,	O
can	O
in	O
principle	O
become	O
aware	O
that	O
grayish	O
outputs	O
are	O
unrealistic	O
,	O
and	O
encourage	O
matching	O
the	O
true	O
color	O
distribution	O
.	O
	
In	O
Figure	O
[	O
reference	O
]	O
,	O
we	O
investigate	O
whether	O
our	O
cGANs	B-Method
actually	O
achieve	O
this	O
effect	O
on	O
the	O
Cityscapes	B-Material
dataset	I-Material
.	O
	
The	O
plots	O
show	O
the	O
marginal	O
distributions	O
over	O
output	O
color	O
values	O
in	O
Lab	O
color	O
space	O
.	O
	
The	O
ground	B-Metric
truth	I-Metric
distributions	I-Metric
are	O
shown	O
with	O
a	O
dotted	O
line	O
.	O
	
It	O
is	O
apparent	O
that	O
L1	O
leads	O
to	O
a	O
narrower	O
distribution	O
than	O
the	O
ground	O
truth	O
,	O
confirming	O
the	O
hypothesis	O
that	O
L1	O
encourages	O
average	O
,	O
grayish	O
colors	O
.	O
	
Using	O
a	O
cGAN	B-Method
,	O
on	O
the	O
other	O
hand	O
,	O
pushes	O
the	O
output	O
distribution	O
closer	O
to	O
the	O
ground	O
truth	O
.	O
	
subsection	O
:	O
Analysis	O
of	O
the	O
generator	B-Method
architecture	I-Method
	
A	O
U	B-Method
-	I-Method
Net	I-Method
architecture	I-Method
allows	O
low	O
-	O
level	O
information	O
to	O
shortcut	O
across	O
the	O
network	O
.	O
	
Does	O
this	O
lead	O
to	O
better	O
results	O
?	O
	
Figure	O
[	O
reference	O
]	O
and	O
Table	O
[	O
reference	O
]	O
compare	O
the	O
U	B-Method
-	I-Method
Net	I-Method
against	O
an	O
encoder	B-Method
-	I-Method
decoder	I-Method
on	O
cityscape	B-Task
generation	I-Task
.	O
	
The	O
encoder	B-Method
-	I-Method
decoder	I-Method
is	O
created	O
simply	O
by	O
severing	O
the	O
skip	O
connections	O
in	O
the	O
U	O
-	O
Net	O
.	O
	
The	O
encoder	B-Method
-	I-Method
decoder	I-Method
is	O
unable	O
to	O
learn	O
to	O
generate	O
realistic	O
images	O
in	O
our	O
experiments	O
.	O
	
The	O
advantages	O
of	O
the	O
U	B-Method
-	I-Method
Net	I-Method
appear	O
not	O
to	O
be	O
specific	O
to	O
conditional	B-Method
GANs	I-Method
:	O
when	O
both	O
U	B-Method
-	I-Method
Net	I-Method
and	O
encoder	B-Method
-	I-Method
decoder	I-Method
are	O
trained	O
with	O
an	O
L1	O
loss	O
,	O
the	O
U	B-Method
-	I-Method
Net	I-Method
again	O
achieves	O
the	O
superior	O
results	O
.	O
	
subsection	O
:	O
From	O
PixelGANs	B-Method
to	O
PatchGANs	B-Method
to	O
ImageGANs	B-Method
	
We	O
test	O
the	O
effect	O
of	O
varying	O
the	O
patch	O
size	O
of	O
our	O
discriminator	O
receptive	O
fields	O
,	O
from	O
a	O
“	O
	
PixelGAN	B-Method
”	O
to	O
a	O
full	O
“	O
	
ImageGAN	O
”	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
qualitative	O
results	O
of	O
this	O
analysis	O
and	O
Table	O
[	O
reference	O
]	O
	
quantifies	O
the	O
effects	O
using	O
the	O
FCN	B-Metric
-	I-Metric
score	I-Metric
.	O
	
Note	O
that	O
elsewhere	O
in	O
this	O
paper	O
,	O
unless	O
specified	O
,	O
all	O
experiments	O
use	O
PatchGANs	B-Method
,	O
and	O
for	O
this	O
section	O
all	O
experiments	O
use	O
an	O
L1	O
+	O
cGAN	B-Method
loss	O
.	O
	
The	O
PixelGAN	B-Method
has	O
no	O
effect	O
on	O
spatial	O
sharpness	O
but	O
does	O
increase	O
the	O
colorfulness	O
of	O
the	O
results	O
(	O
quantified	O
in	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
For	O
example	O
,	O
the	O
bus	O
in	O
Figure	O
[	O
reference	O
]	O
is	O
painted	O
gray	O
when	O
the	O
net	O
is	O
trained	O
with	O
an	O
L1	B-Method
loss	I-Method
,	O
but	O
becomes	O
red	O
with	O
the	O
PixelGAN	B-Method
loss	I-Method
.	O
	
Color	B-Method
histogram	I-Method
matching	I-Method
is	O
a	O
common	O
problem	O
in	O
image	B-Task
processing	I-Task
,	O
and	O
PixelGANs	B-Method
may	O
be	O
a	O
promising	O
lightweight	O
solution	O
.	O
	
Using	O
a	O
PatchGAN	B-Method
is	O
sufficient	O
to	O
promote	O
sharp	O
outputs	O
,	O
and	O
achieves	O
good	O
FCN	B-Metric
-	I-Metric
scores	I-Metric
,	O
but	O
also	O
leads	O
to	O
tiling	O
artifacts	O
.	O
	
The	O
PatchGAN	B-Method
alleviates	O
these	O
artifacts	O
and	O
achieves	O
slightly	O
better	O
scores	O
.	O
	
Scaling	O
beyond	O
this	O
,	O
to	O
the	O
full	O
	
ImageGAN	B-Method
,	O
does	O
not	O
appear	O
to	O
improve	O
the	O
visual	B-Metric
quality	I-Metric
of	O
the	O
results	O
,	O
and	O
in	O
fact	O
gets	O
a	O
considerably	O
lower	O
FCN	B-Metric
-	I-Metric
score	I-Metric
(	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
This	O
may	O
be	O
because	O
the	O
ImageGAN	O
has	O
many	O
more	O
parameters	O
and	O
greater	O
depth	O
than	O
the	O
PatchGAN	B-Method
,	O
and	O
may	O
be	O
harder	O
to	O
train	O
.	O
	
Fully	B-Method
-	I-Method
convolutional	I-Method
translation	I-Method
	
An	O
advantage	O
of	O
the	O
PatchGAN	B-Method
is	O
that	O
a	O
fixed	B-Method
-	I-Method
size	I-Method
patch	I-Method
discriminator	I-Method
can	O
be	O
applied	O
to	O
arbitrarily	O
large	O
images	O
.	O
	
We	O
may	O
also	O
apply	O
the	O
generator	B-Method
convolutionally	I-Method
,	O
on	O
larger	O
images	O
than	O
those	O
on	O
which	O
it	O
was	O
trained	O
.	O
	
We	O
test	O
this	O
on	O
the	O
map	B-Material
aerial	I-Material
photo	I-Material
task	O
.	O
	
After	O
training	O
a	O
generator	O
on	O
images	O
,	O
we	O
test	O
it	O
on	O
images	O
.	O
	
The	O
results	O
in	O
Figure	O
[	O
reference	O
]	O
demonstrate	O
the	O
effectiveness	O
of	O
this	O
approach	O
.	O
	
subsection	O
:	O
Perceptual	B-Metric
validation	I-Metric
	
We	O
validate	O
the	O
perceptual	B-Metric
realism	I-Metric
of	O
our	O
results	O
on	O
the	O
tasks	O
of	O
map	B-Material
aerial	I-Material
photograph	I-Material
and	O
grayscale	O
color	O
.	O
	
Results	O
of	O
our	O
AMT	B-Method
experiment	I-Method
for	O
map	B-Task
photo	I-Task
are	O
given	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
The	O
aerial	B-Material
photos	I-Material
generated	O
by	O
our	O
method	O
fooled	O
participants	O
on	O
of	O
trials	O
,	O
significantly	O
above	O
the	O
L1	O
baseline	O
,	O
which	O
produces	O
blurry	O
results	O
and	O
nearly	O
never	O
fooled	O
participants	O
.	O
	
In	O
contrast	O
,	O
in	O
the	O
photo	O
map	O
direction	O
our	O
method	O
only	O
fooled	O
participants	O
on	O
%	O
of	O
trials	O
,	O
and	O
this	O
was	O
not	O
significantly	O
different	O
than	O
the	O
performance	O
of	O
the	O
L1	B-Method
baseline	I-Method
(	O
based	O
on	O
bootstrap	B-Method
test	I-Method
)	O
.	O
	
This	O
may	O
be	O
because	O
minor	O
structural	O
errors	O
are	O
more	O
visible	O
in	O
maps	O
,	O
which	O
have	O
rigid	O
geometry	O
,	O
than	O
in	O
aerial	B-Material
photographs	I-Material
,	O
which	O
are	O
more	O
chaotic	O
.	O
	
We	O
trained	O
colorization	B-Method
on	O
ImageNet	O
,	O
and	O
tested	O
on	O
the	O
test	O
split	O
introduced	O
by	O
.	O
	
Our	O
method	O
,	O
with	O
L1	O
+	O
cGAN	B-Method
loss	O
,	O
fooled	O
participants	O
on	O
of	O
trials	O
(	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
We	O
also	O
tested	O
the	O
results	O
of	O
and	O
a	O
variant	O
of	O
their	O
method	O
that	O
used	O
an	O
L2	O
loss	O
(	O
see	O
for	O
details	O
)	O
.	O
	
The	O
conditional	O
GAN	B-Method
scored	O
similarly	O
to	O
the	O
L2	B-Method
variant	I-Method
of	O
(	O
difference	O
insignificant	O
by	O
bootstrap	O
test	O
)	O
,	O
but	O
fell	O
short	O
of	O
’s	O
full	O
method	O
,	O
which	O
fooled	O
participants	O
on	O
of	O
trials	O
in	O
our	O
experiment	O
.	O
	
We	O
note	O
that	O
their	O
method	O
was	O
specifically	O
engineered	O
to	O
do	O
well	O
on	O
colorization	B-Task
.	O
	
subsection	O
:	O
Semantic	B-Task
segmentation	I-Task
	
Conditional	O
GANs	B-Method
appear	O
to	O
be	O
effective	O
on	O
problems	O
where	O
the	O
output	O
is	O
highly	O
detailed	O
or	O
photographic	O
,	O
as	O
is	O
common	O
in	O
image	B-Task
processing	I-Task
and	I-Task
graphics	I-Task
tasks	I-Task
.	O
	
What	O
about	O
vision	B-Task
problems	I-Task
,	O
like	O
semantic	B-Task
segmentation	I-Task
,	O
where	O
the	O
output	O
is	O
instead	O
less	O
complex	O
than	O
the	O
input	O
?	O
	
To	O
begin	O
to	O
test	O
this	O
,	O
we	O
train	O
a	O
cGAN	B-Method
(	O
with	O
/	O
without	O
L1	B-Method
loss	I-Method
)	O
on	O
cityscape	B-Material
photo	I-Material
labels	I-Material
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
qualitative	O
results	O
,	O
and	O
quantitative	B-Metric
classification	I-Metric
accuracies	I-Metric
are	O
reported	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Interestingly	O
,	O
cGANs	B-Method
,	O
trained	O
without	O
the	O
L1	B-Method
loss	I-Method
,	O
are	O
able	O
to	O
solve	O
this	O
problem	O
at	O
a	O
reasonable	O
degree	O
of	O
accuracy	B-Metric
.	O
	
To	O
our	O
knowledge	O
,	O
this	O
is	O
the	O
first	O
demonstration	O
of	O
GANs	B-Method
successfully	O
generating	O
“	O
labels	O
”	O
,	O
which	O
are	O
nearly	O
discrete	O
,	O
rather	O
than	O
“	O
images	O
”	O
,	O
with	O
their	O
continuous	O
-	O
valued	O
variation	O
.	O
	
Although	O
cGANs	B-Method
achieve	O
some	O
success	O
,	O
they	O
are	O
far	O
from	O
the	O
best	O
available	O
method	O
for	O
solving	O
this	O
problem	O
:	O
simply	O
using	O
L1	B-Method
regression	I-Method
gets	O
better	O
scores	O
than	O
using	O
a	O
cGAN	B-Method
,	O
as	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
We	O
argue	O
that	O
for	O
vision	B-Task
problems	I-Task
,	O
the	O
goal	O
(	O
i.e.	O
predicting	O
output	O
close	O
to	O
the	O
ground	O
truth	O
)	O
may	O
be	O
less	O
ambiguous	O
than	O
graphics	B-Task
tasks	I-Task
,	O
and	O
reconstruction	O
losses	O
like	O
L1	B-Method
are	O
mostly	O
sufficient	O
.	O
	
subsection	O
:	O
Community	O
-	O
driven	O
Research	O
	
Since	O
the	O
initial	O
release	O
of	O
the	O
paper	O
and	O
our	O
pix2pix	B-Method
codebase	O
,	O
the	O
Twitter	O
community	O
,	O
including	O
computer	B-Task
vision	I-Task
and	O
graphics	B-Task
practitioners	I-Task
as	O
well	O
as	O
visual	B-Task
artists	I-Task
,	O
have	O
successfully	O
applied	O
our	O
framework	O
to	O
a	O
variety	O
of	O
novel	O
image	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
translation	I-Task
tasks	I-Task
,	O
far	O
beyond	O
the	O
scope	O
of	O
the	O
original	O
paper	O
.	O
	
Figure	O
[	O
reference	O
]	O
and	O
Figure	O
[	O
reference	O
]	O
show	O
just	O
a	O
few	O
examples	O
from	O
the	O
#	O
pix2pix	B-Method
hashtag	O
,	O
including	O
Background	B-Task
removal	I-Task
,	O
Palette	B-Task
generation	I-Task
,	O
Sketch	O
→	O
Portrait	O
,	O
Sketch→Pokemon	O
,	O
”	O
Do	O
as	O
I	O
Do	O
”	O
pose	B-Task
transfer	I-Task
,	O
Learning	O
to	O
see	O
:	O
Gloomy	O
Sunday	O
,	O
as	O
well	O
as	O
the	O
bizarrely	O
popular	O
#	O
edges2cats	O
and	O
#	O
fotogenerator	B-Method
.	O
	
Note	O
that	O
these	O
applications	O
are	O
creative	O
projects	O
,	O
were	O
not	O
obtained	O
in	O
controlled	O
,	O
scientific	O
conditions	O
,	O
and	O
may	O
rely	O
on	O
some	O
modifications	O
to	O
the	O
pix2pix	B-Method
code	O
we	O
released	O
.	O
	
Nonetheless	O
,	O
they	O
demonstrate	O
the	O
promise	O
of	O
our	O
approach	O
as	O
a	O
generic	O
commodity	B-Method
tool	I-Method
for	O
image	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
translation	I-Task
problems	I-Task
.	O
	
section	O
:	O
Conclusion	O
	
The	O
results	O
in	O
this	O
paper	O
suggest	O
that	O
conditional	B-Method
adversarial	I-Method
networks	I-Method
are	O
a	O
promising	O
approach	O
for	O
many	O
image	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
translation	I-Task
tasks	I-Task
,	O
especially	O
those	O
involving	O
highly	O
structured	O
graphical	O
outputs	O
.	O
	
These	O
networks	O
learn	O
a	O
loss	B-Metric
adapted	O
to	O
the	O
task	O
and	O
data	O
at	O
hand	O
,	O
which	O
makes	O
them	O
applicable	O
in	O
a	O
wide	O
variety	O
of	O
settings	O
.	O
	
paragraph	O
:	O
Acknowledgments	O
:	O
	
We	O
thank	O
Richard	O
Zhang	O
,	O
Deepak	O
Pathak	O
,	O
and	O
Shubham	O
Tulsiani	O
for	O
helpful	O
discussions	O
,	O
Saining	O
Xie	O
for	O
help	O
with	O
the	O
HED	B-Method
edge	I-Method
detector	I-Method
,	O
and	O
the	O
online	O
community	O
for	O
exploring	O
many	O
applications	O
and	O
suggesting	O
improvements	O
.	O
	
Thanks	O
to	O
Christopher	O
Hesse	O
,	O
Memo	O
Akten	O
,	O
Kaihu	O
Chen	O
,	O
Jack	O
Qiao	O
,	O
Mario	O
Klingemann	O
,	O
Brannon	O
Dorsey	O
,	O
Gerda	O
Bosman	O
,	O
Ivy	O
Tsai	O
,	O
and	O
Yann	O
LeCun	O
for	O
allowing	O
the	O
use	O
of	O
their	O
creations	O
in	O
Figure	O
[	O
reference	O
]	O
and	O
Figure	O
[	O
reference	O
]	O
.	O
	
This	O
work	O
was	O
supported	O
in	O
part	O
by	O
NSF	O
SMA	O
-	O
1514512	O
,	O
NGA	O
NURI	O
,	O
IARPA	O
via	O
Air	O
Force	O
Research	O
Laboratory	O
,	O
Intel	O
Corp	O
,	O
Berkeley	O
Deep	O
Drive	O
,	O
and	O
hardware	O
donations	O
by	O
Nvidia	O
.	O
	
J.	O
-	O
Y.Z.	O
is	O
supported	O
by	O
the	O
Facebook	O
Graduate	O
Fellowship	O
.	O
	
Disclaimer	O
:	O
	
The	O
views	O
and	O
conclusions	O
contained	O
herein	O
are	O
those	O
of	O
the	O
authors	O
and	O
should	O
not	O
be	O
interpreted	O
as	O
necessarily	O
representing	O
the	O
official	O
policies	O
or	O
endorsements	O
,	O
either	O
expressed	O
or	O
implied	O
,	O
of	O
IARPA	O
,	O
AFRL	O
or	O
the	O
U.S.	O
Government	O
.	O
	
bibliography	O
:	O
References	O
	
section	O
:	O
Appendix	O
	
subsection	O
:	O
Network	B-Method
architectures	I-Method
	
We	O
adapt	O
our	O
network	B-Method
architectures	I-Method
from	O
those	O
in	O
.	O
	
Code	O
for	O
the	O
models	O
is	O
available	O
at	O
https:	O
//	O
github.com	O
/	O
phillipi	O
/	O
pix2pix	B-Method
.	O
	
Let	O
Ck	B-Method
denote	O
a	O
Convolution	B-Method
-	I-Method
BatchNorm	I-Method
-	I-Method
ReLU	I-Method
layer	I-Method
with	O
k	B-Method
filters	I-Method
.	O
	
CDk	B-Method
denotes	O
a	O
Convolution	B-Method
-	I-Method
BatchNorm	I-Method
-	I-Method
Dropout	I-Method
-	I-Method
ReLU	I-Method
layer	I-Method
with	O
a	O
dropout	O
rate	O
of	O
.	O
	
All	O
convolutions	B-Method
are	O
spatial	B-Method
filters	I-Method
applied	O
with	O
stride	O
2	O
.	O
	
Convolutions	B-Method
in	O
the	O
encoder	B-Method
,	O
and	O
in	O
the	O
discriminator	B-Method
,	O
downsample	O
by	O
a	O
factor	O
of	O
2	O
,	O
whereas	O
in	O
the	O
decoder	O
they	O
upsample	O
by	O
a	O
factor	O
of	O
2	O
.	O
	
subsubsection	O
:	O
Generator	B-Method
architectures	I-Method
	
The	O
encoder	B-Method
-	I-Method
decoder	I-Method
architecture	I-Method
consists	O
of	O
:	O
encoder	B-Method
:	O
C64	B-Method
-	I-Method
C128	I-Method
-	I-Method
C256	I-Method
-	I-Method
C512	I-Method
-	I-Method
C512	I-Method
-	I-Method
C512	I-Method
-	I-Method
C512	I-Method
-	I-Method
C512	I-Method
decoder	I-Method
:	O
	
CD512	B-Method
-	I-Method
CD512	I-Method
-	I-Method
CD512	I-Method
-	I-Method
C512	I-Method
-	I-Method
C256	I-Method
-	I-Method
C128	I-Method
-	I-Method
C64	I-Method
After	O
the	O
last	O
layer	O
in	O
the	O
decoder	B-Method
,	O
a	O
convolution	B-Method
is	O
applied	O
to	O
map	O
to	O
the	O
number	O
of	O
output	O
channels	O
(	O
3	O
in	O
general	O
,	O
except	O
in	O
colorization	O
,	O
where	O
it	O
is	O
2	O
)	O
,	O
followed	O
by	O
a	O
Tanh	B-Method
function	I-Method
.	O
	
As	O
an	O
exception	O
to	O
the	O
above	O
notation	O
,	O
BatchNorm	B-Method
is	O
not	O
applied	O
to	O
the	O
first	O
C64	O
layer	O
in	O
the	O
encoder	B-Method
.	O
	
All	O
ReLUs	O
in	O
the	O
encoder	O
are	O
leaky	O
,	O
with	O
slope	O
0.2	O
,	O
while	O
ReLUs	O
in	O
the	O
decoder	O
are	O
not	O
leaky	O
.	O
	
The	O
U	B-Method
-	I-Method
Net	I-Method
architecture	I-Method
is	O
identical	O
except	O
with	O
skip	O
connections	O
between	O
each	O
layer	O
in	O
the	O
encoder	O
and	O
layer	O
in	O
the	O
decoder	O
,	O
where	O
is	O
the	O
total	O
number	O
of	O
layers	O
.	O
	
The	O
skip	O
connections	O
concatenate	O
activations	O
from	O
layer	O
to	O
layer	O
.	O
	
This	O
changes	O
the	O
number	O
of	O
channels	O
in	O
the	O
decoder	O
:	O
U	B-Method
-	I-Method
Net	I-Method
decoder	I-Method
:	O
CD512	B-Method
-	I-Method
CD1024	I-Method
-	I-Method
CD1024	I-Method
-	I-Method
C1024	I-Method
-	I-Method
C1024	I-Method
-	I-Method
C512	I-Method
-	I-Method
C256	I-Method
-	I-Method
C128	I-Method
	
subsubsection	O
:	O
Discriminator	B-Method
architectures	I-Method
	
The	O
discriminator	B-Method
architecture	I-Method
is	O
:	O
C64	B-Method
-	I-Method
C128	I-Method
-	I-Method
C256	I-Method
-	I-Method
C512	I-Method
	
After	O
the	O
last	O
layer	O
,	O
a	O
convolution	B-Method
is	O
applied	O
to	O
map	O
to	O
a	O
1	O
-	O
dimensional	O
output	O
,	O
followed	O
by	O
a	O
Sigmoid	O
function	O
.	O
	
As	O
an	O
exception	O
to	O
the	O
above	O
notation	O
,	O
BatchNorm	B-Method
is	O
not	O
applied	O
to	O
the	O
first	O
C64	B-Method
layer	I-Method
.	O
	
All	O
ReLUs	B-Method
are	O
leaky	O
,	O
with	O
slope	O
0.2	O
.	O
	
All	O
other	O
discriminators	O
follow	O
the	O
same	O
basic	O
architecture	O
,	O
with	O
depth	O
varied	O
to	O
modify	O
the	O
receptive	O
field	O
size	O
:	O
	
discriminator	B-Method
:	O
C64	O
-	O
C128	O
	
(	O
note	O
,	O
in	O
this	O
special	O
case	O
,	O
all	O
convolutions	B-Method
are	O
spatial	B-Method
filters	I-Method
)	O
discriminator	B-Method
:	O
C64	B-Method
-	I-Method
C128×286286	I-Method
discriminator	I-Method
:	O
C64	O
-	O
C128	O
-	O
C256	O
-	O
C512	O
-	O
C512	O
-	O
C512	O
	
subsection	O
:	O
Training	O
details	O
	
Random	O
jitter	O
was	O
applied	O
by	O
resizing	O
the	O
input	O
images	O
to	O
and	O
then	O
randomly	O
cropping	O
back	O
to	O
size	O
.	O
	
All	O
networks	O
were	O
trained	O
from	O
scratch	O
.	O
	
Weights	O
were	O
initialized	O
from	O
a	O
Gaussian	B-Method
distribution	I-Method
with	O
mean	O
0	O
and	O
standard	O
deviation	O
0.02	O
.	O
	
Cityscapes	B-Material
labels→photo	I-Material
2975	O
training	O
images	O
from	O
the	O
Cityscapes	B-Material
training	I-Material
set	I-Material
,	O
trained	O
for	O
200	O
epochs	O
,	O
with	O
random	O
jitter	O
and	O
mirroring	O
.	O
	
We	O
used	O
the	O
Cityscapes	B-Material
validation	I-Material
set	I-Material
for	O
testing	O
.	O
	
To	O
compare	O
the	O
U	B-Method
-	I-Method
net	I-Method
against	O
an	O
encoder	B-Method
-	I-Method
decoder	I-Method
,	O
we	O
used	O
a	O
batch	O
size	O
of	O
10	O
,	O
whereas	O
for	O
the	O
objective	O
function	O
experiments	O
we	O
used	O
batch	O
size	O
1	O
.	O
	
We	O
find	O
that	O
batch	O
size	O
1	O
produces	O
better	O
results	O
for	O
the	O
U	B-Task
-	I-Task
net	I-Task
,	O
but	O
is	O
inappropriate	O
for	O
the	O
encoder	B-Method
-	I-Method
decoder	I-Method
.	O
	
This	O
is	O
because	O
we	O
apply	O
batchnorm	B-Method
on	O
all	O
layers	O
of	O
our	O
network	O
,	O
and	O
for	O
batch	O
size	O
1	O
this	O
operation	O
zeros	O
the	O
activations	O
on	O
the	O
bottleneck	O
layer	O
.	O
	
The	O
U	B-Method
-	I-Method
net	I-Method
can	O
skip	O
over	O
the	O
bottleneck	O
,	O
but	O
the	O
encoder	B-Method
-	I-Method
decoder	I-Method
can	O
not	O
,	O
and	O
so	O
the	O
encoder	B-Method
-	I-Method
decoder	I-Method
requires	O
a	O
batch	O
size	O
greater	O
than	O
1	O
.	O
	
Note	O
,	O
an	O
alternative	O
strategy	O
is	O
to	O
remove	O
batchnorm	O
from	O
the	O
bottleneck	B-Method
layer	I-Method
.	O
	
See	O
errata	O
for	O
more	O
details	O
.	O
	
Architectural	O
labels→photo	O
400	O
training	O
images	O
from	O
,	O
trained	O
for	O
200	O
epochs	O
,	O
batch	O
size	O
1	O
,	O
with	O
random	O
jitter	O
and	O
mirroring	O
.	O
	
Data	O
were	O
split	O
into	O
train	O
and	O
test	O
randomly	O
.	O
	
Maps↔aerial	B-Material
photograph	I-Material
1096	O
training	O
images	O
scraped	O
from	O
Google	O
Maps	O
,	O
trained	O
for	O
200	O
epochs	O
,	O
batch	O
size	O
1	O
,	O
with	O
random	O
jitter	O
and	O
mirroring	O
.	O
	
Images	O
were	O
sampled	O
from	O
in	O
and	O
around	O
New	O
York	O
City	O
.	O
	
Data	O
were	O
then	O
split	O
into	O
train	O
and	O
test	O
about	O
the	O
median	O
latitude	O
of	O
the	O
sampling	O
region	O
(	O
with	O
a	O
buffer	O
region	O
added	O
to	O
ensure	O
that	O
no	O
training	O
pixel	O
appeared	O
in	O
the	O
test	O
set	O
)	O
.	O
	
BW→color	B-Method
1.2	O
million	O
training	O
images	O
(	O
Imagenet	O
training	O
set	O
)	O
,	O
trained	O
for	O
epochs	O
,	O
batch	O
size	O
4	O
,	O
with	O
only	O
mirroring	O
,	O
no	O
random	O
jitter	O
.	O
	
Tested	O
on	O
subset	O
of	O
Imagenet	O
val	O
set	O
,	O
following	O
protocol	O
of	O
and	O
.	O
	
Edges→shoes	O
50k	O
training	O
images	O
from	O
UT	O
Zappos50	O
K	O
dataset	O
trained	O
for	O
15	O
epochs	O
,	O
batch	O
size	O
4	O
.	O
	
Data	O
were	O
split	O
into	O
train	O
and	O
test	O
randomly	O
.	O
	
Edges→Handbag	O
137	O
K	O
Amazon	O
Handbag	O
images	O
from	O
,	O
trained	O
for	O
15	O
epochs	O
,	O
batch	O
size	O
4	O
.	O
	
Data	O
were	O
split	O
into	O
train	O
and	O
test	O
randomly	O
.	O
	
Day→night	O
	
17823	O
training	O
images	O
extracted	O
from	O
91	O
webcams	O
,	O
from	O
trained	O
for	O
17	O
epochs	O
,	O
batch	O
size	O
4	O
,	O
with	O
random	O
jitter	O
and	O
mirroring	O
.	O
	
We	O
use	O
91	O
webcams	O
as	O
training	O
,	O
and	O
10	O
webcams	O
for	O
test	O
.	O
	
Thermal→color	O
photos	O
36609	O
training	O
images	O
from	O
set	O
00–05	O
of	O
,	O
trained	O
for	O
10	O
epochs	O
,	O
batch	O
size	O
4	O
.	O
	
Images	O
from	O
set	O
06	O
-	O
11	O
are	O
used	O
for	O
testing	O
.	O
	
Photo	O
with	O
missing	O
pixels→inpainted	O
photo	O
14900	O
training	O
images	O
from	O
,	O
trained	O
for	O
25	O
epochs	O
,	O
batch	O
size	O
4	O
,	O
and	O
tested	O
on	O
100	O
held	O
out	O
images	O
following	O
the	O
split	O
of	O
.	O
	
subsection	O
:	O
Errata	O
	
For	O
all	O
experiments	O
reported	O
in	O
this	O
paper	O
with	O
batch	O
size	O
1	O
,	O
the	O
activations	O
of	O
the	O
bottleneck	O
layer	O
are	O
zeroed	O
by	O
the	O
batchnorm	B-Method
operation	I-Method
,	O
effectively	O
making	O
the	O
innermost	B-Method
layer	I-Method
skipped	O
.	O
	
This	O
issue	O
can	O
be	O
fixed	O
by	O
removing	O
batchnorm	B-Method
from	O
this	O
layer	O
,	O
as	O
has	O
been	O
done	O
in	O
the	O
public	O
code	O
.	O
	
We	O
observe	O
little	O
difference	O
with	O
this	O
change	O
and	O
therefore	O
leave	O
the	O
experiments	O
as	O
is	O
in	O
the	O
paper	O
.	O
	
subsection	O
:	O
Change	O
log	O
	
arXiv	O
	
v2	O
Reran	B-Method
generator	I-Method
architecture	I-Method
comparisons	O
(	O
Section	O
[	O
reference	O
]	O
)	O
with	O
batch	O
size	O
equal	O
to	O
10	O
rather	O
than	O
1	O
,	O
so	O
that	O
bottleneck	O
layer	O
is	O
not	O
zeroed	O
(	O
see	O
Errata	O
)	O
.	O
	
Reran	O
FCN	O
-	O
scores	O
with	O
minor	O
details	O
cleaned	O
up	O
(	O
results	O
saved	O
losslessly	O
as	O
pngs	O
,	O
removed	O
unecessary	O
downsampling	O
)	O
.	O
	
FCN	B-Metric
-	I-Metric
scores	I-Metric
computed	O
using	O
scripts	O
at	O
https:	O
//	O
github.com	O
/	O
phillipi	O
/	O
pix2pix	B-Method
/	O
tree	O
/	O
master	O
/	O
scripts	O
/	O
eval_cityscapes	O
,	O
commit	O
d7e7b8b	O
.	O
	
Updated	O
several	O
figures	O
and	O
text	O
.	O
	
Added	O
additional	O
results	O
on	O
thermal	O
color	O
photos	O
and	O
inpainting	B-Task
,	O
as	O
well	O
as	O
community	O
contributions	O
.	O
	
arXiv	O
	
v3	O
	
Added	O
additional	O
results	O
on	O
community	O
contributions	O
.	O
	
Fixed	O
minor	O
typos	O
.	O
	
document	O
:	O
CyCADA	B-Method
:	O
Cycle	B-Method
-	I-Method
Consistent	I-Method
Adversarial	I-Method
Domain	I-Method
Adaptation	I-Method
	
Domain	B-Task
adaptation	I-Task
is	O
critical	O
for	O
success	O
in	O
new	O
,	O
unseen	O
environments	O
.	O
	
Adversarial	B-Method
adaptation	I-Method
models	I-Method
applied	O
in	O
feature	O
spaces	O
discover	O
domain	B-Method
invariant	I-Method
representations	I-Method
,	O
but	O
are	O
difficult	O
to	O
visualize	O
and	O
sometimes	O
fail	O
to	O
capture	O
pixel	B-Method
-	I-Method
level	I-Method
and	O
low	O
-	O
level	O
domain	O
shifts	O
.	O
	
Recent	O
work	O
has	O
shown	O
that	O
generative	B-Method
adversarial	I-Method
networks	I-Method
combined	O
with	O
cycle	O
-	O
consistency	O
constraints	O
are	O
surprisingly	O
effective	O
at	O
mapping	B-Task
images	I-Task
between	I-Task
domains	I-Task
,	O
even	O
without	O
the	O
use	O
of	O
aligned	O
image	O
pairs	O
.	O
	
We	O
propose	O
a	O
novel	O
discriminatively	O
-	O
trained	O
Cycle	B-Method
-	I-Method
Consistent	I-Method
Adversarial	I-Method
Domain	I-Method
Adaptation	I-Method
model	O
.	O
	
CyCADA	B-Method
adapts	O
representations	O
at	O
both	O
the	O
pixel	B-Method
-	I-Method
level	I-Method
and	O
feature	B-Method
-	I-Method
level	I-Method
,	O
enforces	O
cycle	O
-	O
consistency	O
while	O
leveraging	O
a	O
task	O
loss	O
,	O
and	O
does	O
not	O
require	O
aligned	O
pairs	O
.	O
	
Our	O
model	O
can	O
be	O
applied	O
in	O
a	O
variety	O
of	O
visual	B-Task
recognition	I-Task
and	I-Task
prediction	I-Task
settings	I-Task
.	O
	
We	O
show	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
across	O
multiple	O
adaptation	B-Task
tasks	I-Task
,	O
including	O
digit	B-Task
classification	I-Task
and	O
semantic	B-Task
segmentation	I-Task
of	I-Task
road	I-Task
scenes	I-Task
demonstrating	O
transfer	B-Task
from	O
synthetic	O
to	O
real	O
world	O
domains	O
.	O
	
section	O
:	O
Introduction	O
	
Deep	B-Method
neural	I-Method
networks	I-Method
excel	O
at	O
learning	O
from	O
large	O
amounts	O
of	O
data	O
,	O
but	O
can	O
be	O
poor	O
at	O
generalizing	O
learned	O
knowledge	O
to	O
new	O
datasets	O
or	O
environments	O
.	O
	
Even	O
a	O
slight	O
departure	O
from	O
a	O
network	O
’s	O
training	O
domain	O
can	O
cause	O
it	O
to	O
make	O
spurious	O
predictions	O
and	O
significantly	O
hurt	O
its	O
performance	O
tzeng_cvpr17	O
.	O
	
The	O
visual	B-Task
domain	I-Task
shift	I-Task
from	O
non	O
-	O
photorealistic	O
synthetic	O
data	O
to	O
real	O
images	O
presents	O
an	O
even	O
more	O
significant	O
challenge	O
.	O
	
While	O
we	O
would	O
like	O
to	O
train	O
models	O
on	O
large	O
amounts	O
of	O
synthetic	O
data	O
such	O
as	O
data	O
collected	O
from	O
graphics	O
game	O
engines	O
,	O
such	O
models	O
fail	O
to	O
generalize	O
to	O
real	O
-	O
world	O
imagery	O
.	O
	
For	O
example	O
,	O
a	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
semantic	B-Method
segmentation	I-Method
model	I-Method
trained	O
on	O
synthetic	O
dashcam	O
data	O
fails	O
to	O
segment	O
the	O
road	O
in	O
real	O
images	O
,	O
and	O
its	O
overall	O
per	B-Metric
-	I-Metric
pixel	I-Metric
label	I-Metric
accuracy	I-Metric
drops	O
from	O
93	O
%	O
(	O
if	O
trained	O
on	O
real	O
imagery	O
)	O
to	O
54	O
%	O
(	O
if	O
trained	O
only	O
on	O
synthetic	O
data	O
,	O
see	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
Feature	B-Method
-	I-Method
level	I-Method
unsupervised	I-Method
domain	I-Method
adaptation	I-Method
methods	I-Method
address	O
this	O
problem	O
by	O
aligning	O
the	O
features	O
extracted	O
from	O
the	O
network	O
across	O
the	O
source	O
(	O
e.g.	O
synthetic	O
)	O
and	O
target	O
(	O
e.g.	O
real	O
)	O
domains	O
,	O
without	O
any	O
labeled	O
target	O
samples	O
.	O
	
Alignment	B-Task
typically	O
involves	O
minimizing	O
some	O
measure	O
of	O
distance	O
between	O
the	O
source	O
and	O
target	O
feature	O
distributions	O
,	O
such	O
as	O
maximum	B-Metric
mean	I-Metric
discrepancy	I-Metric
long_icml15	O
,	O
correlation	B-Metric
distance	I-Metric
sun_taskcv16	O
,	O
or	O
adversarial	B-Metric
discriminator	I-Metric
accuracy	I-Metric
ganin_icml15	O
,	O
tzeng_cvpr17	O
.	O
	
This	O
class	O
of	O
techniques	O
suffers	O
from	O
two	O
main	O
limitations	O
.	O
	
First	O
,	O
aligning	O
marginal	O
distributions	O
does	O
not	O
enforce	O
any	O
semantic	O
consistency	O
,	O
e.g.	O
target	O
features	O
of	O
a	O
car	O
may	O
be	O
mapped	O
to	O
source	O
features	O
of	O
a	O
bicycle	O
.	O
	
Second	O
,	O
alignment	O
at	O
higher	O
levels	O
of	O
a	O
deep	B-Method
representation	I-Method
can	O
fail	O
to	O
model	O
aspects	O
of	O
low	O
-	O
level	O
appearance	O
variance	O
which	O
are	O
crucial	O
for	O
the	O
end	B-Task
visual	I-Task
task	I-Task
.	O
	
Generative	O
pixel	B-Method
-	I-Method
level	I-Method
domain	O
adaptation	O
models	O
perform	O
similar	O
distribution	B-Task
alignment	I-Task
—	O
not	O
in	O
feature	B-Method
space	I-Method
but	O
rather	O
in	O
	
raw	O
pixel	O
space	O
—	O
translating	O
source	O
data	O
to	O
the	O
	
‘	O
	
‘	O
style	O
’	O
’	O
of	O
a	O
target	O
domain	O
.	O
	
Recent	O
methods	O
can	O
learn	O
to	O
translate	O
images	O
given	O
only	O
unsupervised	O
data	O
from	O
both	O
domains	O
bousmalis_cvpr17	O
,	O
liu_arxiv16	O
,	O
shrivastava_cvpr17	O
.	O
	
The	O
results	O
are	O
visually	O
compelling	O
,	O
but	O
such	O
image	B-Method
-	I-Method
space	I-Method
models	I-Method
have	O
only	O
been	O
shown	O
to	O
work	O
for	O
small	O
image	O
sizes	O
and	O
limited	O
domain	O
shifts	O
.	O
	
A	O
more	O
recent	O
approach	O
bousmalis_arxiv17_robotic	O
was	O
applied	O
to	O
larger	O
(	O
but	O
still	O
not	O
high	O
resolution	O
)	O
images	O
,	O
but	O
in	O
a	O
visually	O
controlled	O
image	O
for	O
robotic	B-Task
applications	I-Task
.	O
	
Furthermore	O
,	O
they	O
also	O
do	O
not	O
necessarily	O
preserve	O
content	O
:	O
while	O
the	O
translated	O
image	O
may	O
‘	O
	
‘	O
	
look	O
’	O
’	O
like	O
it	O
came	O
from	O
the	O
right	O
domain	O
,	O
crucial	O
semantic	O
information	O
may	O
be	O
lost	O
.	O
	
For	O
example	O
,	O
a	O
model	O
adapting	O
from	O
line	O
-	O
drawings	O
to	O
photos	O
could	O
learn	O
to	O
make	O
a	O
line	O
-	O
drawing	O
of	O
a	O
cat	O
look	O
like	O
a	O
photo	O
of	O
a	O
dog	O
.	O
	
How	O
can	O
we	O
encourage	O
the	O
model	O
to	O
preserve	O
semantic	O
information	O
in	O
the	O
process	O
of	O
distribution	B-Task
alignment	I-Task
?	O
	
In	O
this	O
paper	O
,	O
we	O
explore	O
a	O
simple	O
yet	O
powerful	O
idea	O
:	O
give	O
an	O
additional	O
objective	O
to	O
the	O
model	O
to	O
reconstruct	O
the	O
original	O
data	O
from	O
the	O
adapted	O
version	O
.	O
	
Cycle	B-Method
-	I-Method
consistency	I-Method
was	O
recently	O
proposed	O
in	O
a	O
cross	B-Method
-	I-Method
domain	I-Method
image	I-Method
generation	I-Method
GAN	I-Method
model	I-Method
,	O
CycleGAN	B-Method
zhu_arxiv17	O
,	O
which	O
showed	O
transformative	B-Task
image	I-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
generation	I-Task
results	O
,	O
but	O
was	O
agnostic	O
to	O
any	O
particular	O
task	O
.	O
	
We	O
propose	O
Cycle	B-Method
-	I-Method
Consistent	I-Method
Adversarial	I-Method
Domain	I-Method
Adaptation	I-Method
(	O
CyCADA	B-Method
)	O
,	O
which	O
adapts	O
representations	O
at	O
both	O
the	O
pixel	B-Method
-	I-Method
level	I-Method
and	O
feature	B-Method
-	I-Method
level	I-Method
while	O
enforcing	O
local	O
and	O
global	O
structural	O
consistency	O
through	O
pixel	O
cycle	O
-	O
consistency	O
and	O
semantic	O
losses	O
.	O
	
CyCADA	B-Method
unifies	O
prior	O
feature	B-Method
-	I-Method
level	I-Method
ganin_icml15	O
,	O
tzeng_cvpr17	O
and	O
image	B-Method
-	I-Method
level	I-Method
liu_arxiv16	O
,	O
bousmalis_cvpr17	O
,	O
shrivastava_cvpr17	O
adversarial	B-Method
domain	I-Method
adaptation	I-Method
methods	I-Method
together	O
with	O
cycle	O
-	O
consistent	O
image	O
-	O
to	O
-	O
image	O
translation	B-Task
techniques	O
	
zhu_arxiv17	O
,	O
as	O
illustrated	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
It	O
is	O
applicable	O
across	O
a	O
range	O
of	O
deep	B-Method
architectures	I-Method
and	O
/	O
or	O
representation	O
levels	O
,	O
and	O
has	O
several	O
advantages	O
over	O
existing	O
unsupervised	B-Method
domain	I-Method
adaptation	I-Method
methods	I-Method
.	O
	
We	O
use	O
a	O
reconstruction	O
(	O
cycle	O
-	O
consistency	O
)	O
loss	O
to	O
encourage	O
the	O
cross	B-Task
-	I-Task
domain	I-Task
transformation	I-Task
to	O
preserve	O
local	O
structural	O
information	O
and	O
a	O
semantic	O
loss	O
to	O
enforce	O
semantic	O
consistency	O
.	O
	
We	O
apply	O
our	O
CyCADA	B-Method
model	I-Method
to	O
the	O
task	O
of	O
digit	B-Task
recognition	I-Task
across	I-Task
domains	I-Task
and	O
the	O
task	O
of	O
semantic	B-Task
segmentation	I-Task
of	I-Task
urban	I-Task
scenes	I-Task
across	O
domains	O
.	O
	
Experiments	O
show	O
that	O
our	O
model	O
achieves	O
state	O
of	O
the	O
art	O
results	O
on	O
digit	B-Task
adaptation	I-Task
,	O
cross	B-Task
-	I-Task
season	I-Task
adaptation	I-Task
in	O
synthetic	O
data	O
,	O
and	O
on	O
the	O
challenging	O
synthetic	B-Task
-	I-Task
to	I-Task
-	I-Task
real	I-Task
scenario	I-Task
.	O
	
In	O
the	O
latter	O
case	O
,	O
it	O
improves	O
per	B-Metric
-	I-Metric
pixel	I-Metric
accuracy	I-Metric
from	O
54	O
%	O
to	O
82	O
%	O
,	O
nearly	O
closing	O
the	O
gap	O
to	O
the	O
target	B-Method
-	I-Method
trained	I-Method
model	I-Method
.	O
	
Our	O
experiments	O
confirm	O
that	O
domain	B-Method
adaptation	I-Method
can	O
benefit	O
greatly	O
from	O
cycle	O
-	O
consistent	O
pixel	O
transformations	O
,	O
and	O
that	O
this	O
is	O
especially	O
important	O
for	O
pixel	B-Method
-	I-Method
level	I-Method
semantic	O
segmentation	O
with	O
contemporary	O
FCN	B-Method
architectures	I-Method
.	O
	
Further	O
,	O
we	O
show	O
that	O
adaptation	O
at	O
both	O
the	O
pixel	O
and	O
representation	O
level	O
can	O
offer	O
complementary	O
improvements	O
with	O
joint	B-Method
pixel	I-Method
-	I-Method
space	I-Method
and	O
feature	B-Method
adaptation	I-Method
leading	O
to	O
the	O
highest	O
performing	O
model	O
for	O
digit	B-Task
classification	I-Task
tasks	I-Task
.	O
	
section	O
:	O
Related	O
Work	O
	
The	O
problem	O
of	O
visual	B-Task
domain	I-Task
adaptation	I-Task
was	O
introduced	O
along	O
with	O
a	O
pairwise	B-Method
metric	I-Method
transform	I-Method
solution	I-Method
by	O
saenko_eccv10	O
and	O
was	O
further	O
popularized	O
by	O
the	O
broad	O
study	O
of	O
visual	O
dataset	O
bias	O
efros_cvpr11	O
.	O
	
Early	O
deep	B-Method
adaptive	I-Method
works	O
focused	O
on	O
feature	B-Method
space	I-Method
alignment	O
through	O
minimizing	O
the	O
distance	O
between	O
first	O
or	O
second	O
order	O
feature	B-Method
space	I-Method
statistics	O
of	O
the	O
source	O
and	O
target	O
tzeng_arxiv15	O
,	O
long_icml15	O
.	O
	
These	O
latent	B-Method
distribution	I-Method
alignment	I-Method
approaches	I-Method
were	O
further	O
improved	O
through	O
the	O
use	O
of	O
domain	B-Method
adversarial	I-Method
objectives	I-Method
whereby	O
a	O
domain	B-Method
classifier	I-Method
is	O
trained	O
to	O
distinguish	O
between	O
the	O
source	O
and	O
target	O
representations	O
while	O
the	O
domain	B-Method
representation	I-Method
is	O
learned	O
so	O
as	O
to	O
maximize	O
the	O
error	O
of	O
the	O
domain	B-Method
classifier	I-Method
.	O
	
The	O
representation	O
is	O
optimized	O
using	O
the	O
standard	O
minimax	B-Method
objective	I-Method
ganin_icml15	I-Method
,	O
the	O
symmetric	B-Method
confusion	I-Method
objective	I-Method
tzeng_iccv15	O
,	O
or	O
the	O
inverted	B-Method
label	I-Method
objective	I-Method
tzeng_cvpr17	O
.	O
	
Each	O
of	O
these	O
objectives	O
is	O
related	O
to	O
the	O
literature	O
on	O
generative	B-Method
adversarial	I-Method
networks	I-Method
goodfellow_nips14	O
and	O
follow	O
-	O
up	O
work	O
for	O
improved	O
training	B-Method
procedures	I-Method
for	O
these	O
networks	O
salimans_arxiv16	O
,	O
arjovsky_arxiv17	B-Method
.	O
	
The	O
feature	B-Method
-	I-Method
space	I-Method
adaptation	I-Method
methods	I-Method
described	O
above	O
focus	O
on	O
modifications	O
to	O
the	O
discriminative	O
representation	O
space	O
.	O
	
In	O
contrast	O
,	O
other	O
recent	O
methods	O
have	O
sought	O
adaptation	O
in	O
the	O
pixel	O
-	O
space	O
using	O
various	O
generative	B-Method
approaches	I-Method
.	O
	
One	O
advantage	O
of	O
pixel	B-Method
-	I-Method
space	I-Method
adaptation	I-Method
,	O
as	O
we	O
have	O
shown	O
,	O
is	O
that	O
the	O
result	O
may	O
be	O
more	O
human	O
interpretable	O
,	O
since	O
an	O
image	O
from	O
one	O
domain	O
can	O
now	O
be	O
visualized	O
in	O
a	O
new	O
domain	O
.	O
	
CoGANs	O
liu_arxiv16	O
jointly	O
learn	O
a	O
source	B-Method
and	I-Method
target	I-Method
representation	I-Method
through	O
explicit	O
weight	B-Method
sharing	I-Method
of	O
certain	O
layers	O
while	O
each	O
source	O
and	O
target	O
has	O
a	O
unique	O
generative	O
adversarial	O
objective	O
.	O
	
ghifary_eccv16	O
uses	O
an	O
additional	O
reconstruction	O
objective	O
in	O
the	O
target	O
domain	O
to	O
encourage	O
alignment	B-Task
in	O
the	O
unsupervised	B-Task
adaptation	I-Task
setting	I-Task
.	O
	
In	O
contrast	O
,	O
another	O
approach	O
is	O
to	O
directly	O
convert	O
the	O
target	O
image	O
into	O
a	O
source	O
style	O
image	O
(	O
or	O
visa	O
versa	O
)	O
,	O
largely	O
based	O
on	O
Generative	B-Method
Adversarial	I-Method
Networks	I-Method
(	O
GANs	B-Method
)	O
goodfellow_nips14	O
.	O
	
Researchers	O
have	O
successfully	O
applied	O
GANs	B-Method
to	O
various	O
applications	O
such	O
as	O
image	B-Task
generation	I-Task
denton2015deep	O
,	O
radford2015unsupervised	O
,	O
zhao2016energy	O
,	O
image	B-Task
editing	I-Task
zhu2016generative	O
and	O
feature	B-Task
learning	I-Task
salimans2016improved	O
,	O
donahue2016adversarial	O
.	O
	
Recent	O
work	O
isola2016image	O
,	O
sangkloy2016scribbler	O
,	O
karacan2016learning	O
adopt	O
conditional	B-Method
GANs	I-Method
mirza_arxiv14	O
for	O
these	O
image	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
translation	I-Task
problems	I-Task
isola2016image	O
,	O
but	O
they	O
require	O
input	O
-	O
output	O
image	O
pairs	O
for	O
training	O
,	O
which	O
is	O
in	O
general	O
not	O
available	O
in	O
domain	B-Task
adaptation	I-Task
problems	I-Task
.	O
	
There	O
also	O
exist	O
lines	O
of	O
work	O
where	O
such	O
training	O
pairs	O
are	O
not	O
given	O
.	O
	
yoo_eccv16	O
learns	O
a	O
source	O
to	O
target	O
encoder	B-Method
-	I-Method
decoder	I-Method
along	O
with	O
a	O
generative	B-Method
adversarial	I-Method
objective	I-Method
on	O
the	O
reconstruction	B-Task
which	O
is	O
is	O
applied	O
for	O
predicting	O
the	O
clothing	O
people	O
are	O
wearing	O
.	O
	
The	O
Domain	B-Method
Transfer	I-Method
Network	I-Method
taigman_iclr17	O
trains	O
a	O
generator	B-Method
to	O
transform	O
a	O
source	O
image	O
into	O
a	O
target	O
image	O
by	O
enforcing	O
consistency	O
in	O
the	O
embedding	O
space	O
.	O
	
shrivastava_cvpr17	O
instead	O
uses	O
an	O
L1	B-Method
reconstruction	I-Method
loss	I-Method
to	O
force	O
the	O
generated	O
target	O
images	O
to	O
be	O
similar	O
to	O
their	O
original	O
source	O
images	O
.	O
	
This	O
works	O
well	O
for	O
limited	O
domain	O
shifts	O
where	O
the	O
domains	O
are	O
similar	O
in	O
pixel	O
-	O
space	O
,	O
but	O
can	O
be	O
too	O
limiting	O
for	O
settings	O
with	O
larger	O
domain	O
shifts	O
.	O
	
bousmalis_cvpr17	O
use	O
a	O
content	O
similarity	O
loss	O
to	O
ensure	O
the	O
generated	O
target	O
image	O
is	O
similar	O
to	O
the	O
original	O
source	O
image	O
;	O
however	O
,	O
this	O
requires	O
prior	O
knowledge	O
about	O
which	O
parts	O
of	O
the	O
image	O
stay	O
the	O
same	O
across	O
domains	O
(	O
e.g.	O
foreground	O
)	O
.	O
	
Our	O
method	O
does	O
not	O
require	O
pre	O
-	O
defining	O
what	O
content	O
is	O
shared	O
between	O
domains	O
and	O
instead	O
simply	O
translates	O
images	O
back	O
to	O
their	O
original	O
domains	O
while	O
ensuring	O
that	O
they	O
remain	O
identical	O
to	O
their	O
original	O
versions	O
.	O
	
BiGAN	O
donahue2016adversarial	O
and	O
ALI	O
dumoulin2016adversarially	O
take	O
an	O
approach	O
of	O
simultaneously	O
learning	O
the	O
transformations	O
between	O
the	O
pixel	O
and	O
the	O
latent	O
space	O
.	O
	
More	O
recently	O
,	O
Cycle	B-Method
-	I-Method
consistent	I-Method
Adversarial	I-Method
Networks	I-Method
(	O
CycleGAN	B-Method
)	O
	
zhu_arxiv17	O
produced	O
compelling	O
image	O
translation	B-Task
results	O
such	O
as	O
generating	O
photorealistic	O
images	O
from	O
impressionism	O
paintings	O
or	O
transforming	O
horses	O
into	O
zebras	O
at	O
high	O
resolution	O
using	O
the	O
cycle	O
-	O
consistency	O
loss	O
.	O
	
This	O
loss	O
was	O
simultaneously	O
proposed	O
by	O
and	O
to	O
great	O
effect	O
as	O
well	O
.	O
	
Our	O
motivation	O
comes	O
from	O
such	O
findings	O
about	O
the	O
effectiveness	O
of	O
the	O
cycle	B-Metric
-	I-Metric
consistency	I-Metric
loss	I-Metric
.	O
	
Few	O
works	O
have	O
explicitly	O
studied	O
visual	B-Task
domain	I-Task
adaptation	I-Task
for	O
the	O
semantic	B-Task
segmentation	I-Task
task	I-Task
.	O
	
Adaptation	B-Task
across	O
weather	O
conditions	O
in	O
simple	O
road	O
scenes	O
was	O
first	O
studied	O
by	O
levinkov_iccv13	O
.	O
	
More	O
recently	O
,	O
a	O
convolutional	B-Method
domain	I-Method
adversarial	I-Method
based	I-Method
approached	I-Method
was	O
proposed	O
for	O
more	O
general	B-Task
drive	I-Task
cam	I-Task
scenes	I-Task
and	O
for	O
adaptation	B-Task
from	O
simulated	O
to	O
real	O
environments	O
hoffman_arxiv16	O
.	O
	
ros_arxiv16	O
learns	O
a	O
multi	B-Method
-	I-Method
source	I-Method
model	I-Method
through	O
concatenating	O
all	O
available	O
labeled	O
data	O
and	O
learning	O
a	O
single	O
large	B-Method
model	I-Method
and	O
then	O
transfers	O
to	O
a	O
sparsely	O
labeled	O
target	O
domain	O
through	O
distillation	O
hinton_arxiv15	O
.	O
	
chen_iccv17	O
use	O
an	O
adversarial	B-Method
objective	I-Method
to	O
align	O
both	O
global	O
and	O
class	O
-	O
specific	O
statistics	O
,	O
while	O
mining	O
additional	O
temporal	O
data	O
from	O
street	O
view	O
datasets	O
to	O
learn	O
a	O
static	O
object	O
prior	O
.	O
	
zhang_iccv17	O
instead	O
perform	O
segmentation	B-Method
adaptation	I-Method
by	O
aligning	O
label	O
distributions	O
both	O
globally	O
and	O
across	O
superpixels	O
in	O
an	O
image	O
.	O
	
section	O
:	O
Cycle	B-Method
-	I-Method
Consistent	I-Method
Adversarial	I-Method
Domain	I-Method
Adaption	I-Method
	
We	O
consider	O
the	O
problem	O
of	O
unsupervised	B-Task
adaptation	I-Task
,	O
where	O
we	O
are	O
provided	O
source	O
data	O
,	O
source	O
labels	O
,	O
and	O
target	O
data	O
,	O
but	O
no	O
target	O
labels	O
.	O
	
The	O
goal	O
is	O
to	O
learn	O
a	O
model	O
that	O
can	O
correctly	O
predict	O
the	O
label	O
for	O
the	O
target	O
data	O
.	O
	
We	O
can	O
begin	O
by	O
simply	O
learning	O
a	O
source	B-Method
model	I-Method
that	O
can	O
perform	O
the	O
task	O
on	O
the	O
source	O
data	O
.	O
	
For	O
-	B-Task
way	I-Task
classification	I-Task
with	O
a	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
loss	I-Metric
,	O
this	O
corresponds	O
to	O
where	O
denotes	O
the	O
softmax	O
function	O
.	O
	
However	O
,	O
while	O
the	O
learned	O
model	O
will	O
perform	O
well	O
on	O
the	O
source	O
data	O
,	O
typically	O
domain	O
shift	O
between	O
the	O
source	O
and	O
target	O
domain	O
leads	O
to	O
reduced	O
performance	O
when	O
evaluating	O
on	O
target	O
data	O
.	O
	
To	O
mitigate	O
the	O
effects	O
of	O
domain	B-Task
shift	I-Task
,	O
we	O
follow	O
previous	O
adversarial	B-Method
adaptation	I-Method
approaches	I-Method
and	O
learn	O
to	O
map	O
samples	O
across	O
domains	O
such	O
that	O
an	O
adversarial	B-Method
discriminator	I-Method
is	O
unable	O
to	O
distinguish	O
the	O
domains	O
.	O
	
By	O
mapping	O
samples	O
into	O
a	O
common	O
space	O
,	O
we	O
enable	O
our	O
model	O
to	O
learn	O
on	O
source	O
data	O
while	O
still	O
generalizing	O
to	O
target	O
data	O
.	O
	
To	O
this	O
end	O
,	O
we	O
introduce	O
a	O
mapping	O
from	O
source	O
to	O
target	O
and	O
train	O
it	O
to	O
produce	O
target	O
samples	O
that	O
fool	O
an	O
adversarial	B-Method
discriminator	I-Method
.	O
	
Conversely	O
,	O
the	O
adversarial	B-Method
discriminator	I-Method
attempts	O
to	O
classify	O
the	O
real	O
target	O
data	O
from	O
the	O
source	O
target	O
data	O
.	O
	
This	O
corresponds	O
to	O
the	O
loss	O
function	O
This	O
objective	O
ensures	O
that	O
,	O
given	O
source	O
samples	O
,	O
produces	O
convincing	O
target	O
samples	O
.	O
	
In	O
turn	O
,	O
this	O
ability	O
to	O
directly	O
map	O
samples	O
between	O
domains	O
allows	O
us	O
to	O
learn	O
a	O
target	O
model	O
by	O
minimizing	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
green	O
portion	O
)	O
.	O
	
However	O
,	O
while	O
previous	O
approaches	O
that	O
optimized	O
similar	O
objectives	O
have	O
shown	O
effective	O
results	O
,	O
in	O
practice	O
they	O
can	O
often	O
be	O
unstable	O
and	O
prone	O
to	O
failure	O
.	O
	
Although	O
the	O
GAN	O
loss	O
in	O
Equation	O
[	O
reference	O
]	O
ensures	O
that	O
for	O
some	O
will	O
resemble	O
data	O
drawn	O
from	O
,	O
there	O
is	O
no	O
way	O
to	O
guarantee	O
that	O
preserves	O
the	O
structure	O
or	O
content	O
of	O
the	O
original	O
sample	O
.	O
	
In	O
order	O
to	O
encourage	O
the	O
source	O
content	O
to	O
be	O
preserved	O
during	O
the	O
conversion	B-Task
process	I-Task
,	O
we	O
impose	O
a	O
cycle	O
-	O
consistency	O
constraint	O
on	O
our	O
adaptation	B-Method
method	I-Method
zhu_arxiv17	O
,	O
yi2017dualgan	O
,	O
	
kim_arxiv17	O
	
(	O
see	O
Figure	O
[	O
reference	O
]	O
red	O
portion	O
)	O
.	O
	
To	O
this	O
end	O
,	O
we	O
introduce	O
another	O
mapping	O
from	O
target	O
to	O
source	O
and	O
train	O
it	O
according	O
to	O
the	O
same	O
GAN	O
loss	O
.	O
	
We	O
then	O
require	O
that	O
mapping	O
a	O
source	O
sample	O
from	O
source	O
to	O
target	O
and	O
back	O
to	O
the	O
source	O
reproduces	O
the	O
original	O
sample	O
,	O
thereby	O
enforcing	O
cycle	O
-	O
consistency	O
.	O
	
In	O
other	O
words	O
,	O
we	O
want	O
and	O
.	O
	
This	O
is	O
done	O
by	O
imposing	O
an	O
L1	O
penalty	O
on	O
the	O
reconstruction	B-Metric
error	I-Metric
,	O
which	O
is	O
referred	O
to	O
as	O
the	O
cycle	B-Metric
-	I-Metric
consistency	I-Metric
loss	I-Metric
:	O
	
Additionally	O
,	O
as	O
we	O
have	O
access	O
to	O
source	O
labeled	O
data	O
,	O
we	O
explicitly	O
encourage	O
high	O
semantic	O
consistency	O
before	O
and	O
after	O
image	O
translation	B-Task
.	O
	
We	O
pretrain	O
a	O
source	B-Method
task	I-Method
model	I-Method
,	O
fixing	O
the	O
weights	O
,	O
we	O
use	O
this	O
model	O
as	O
a	O
noisy	O
labeler	O
by	O
which	O
we	O
encourage	O
an	O
image	O
to	O
be	O
classified	O
in	O
the	O
same	O
way	O
after	O
translation	B-Task
as	O
it	O
was	O
before	O
translation	B-Task
according	O
to	O
this	O
classifier	B-Method
.	O
	
Let	O
us	O
define	O
the	O
predicted	O
label	O
from	O
a	O
fixed	O
classifier	B-Method
,	O
,	O
for	O
a	O
given	O
input	O
as	O
.	O
	
Then	O
we	O
can	O
define	O
the	O
semantic	O
consistency	O
before	O
and	O
after	O
image	O
translation	B-Task
as	O
follows	O
:	O
	
See	O
Figure	O
[	O
reference	O
]	O
black	O
portion	O
.	O
	
This	O
can	O
be	O
viewed	O
as	O
analogously	O
to	O
content	B-Task
losses	I-Task
in	O
style	B-Task
transfer	I-Task
gatys2016image	O
or	O
in	O
pixel	B-Task
adaptation	I-Task
dtn	I-Task
,	O
where	O
the	O
shared	O
content	O
to	O
preserve	O
is	O
dictated	O
by	O
the	O
source	B-Method
task	I-Method
model	I-Method
.	O
	
We	O
have	O
thus	O
far	O
described	O
an	O
adaptation	B-Method
method	I-Method
which	O
combines	O
cycle	O
consistency	O
,	O
semantic	O
consistency	O
,	O
and	O
adversarial	O
objectives	O
to	O
produce	O
a	O
final	O
target	O
model	O
.	O
	
As	O
a	O
pixel	B-Method
-	I-Method
level	I-Method
method	O
,	O
the	O
adversarial	B-Method
objective	I-Method
consists	O
of	O
a	O
discriminator	B-Method
which	O
distinguishes	O
between	O
two	O
image	O
sets	O
,	O
e.g.	O
transformed	O
source	O
and	O
real	O
target	O
image	O
.	O
	
Note	O
that	O
we	O
could	O
also	O
consider	O
a	O
feature	B-Method
-	I-Method
level	I-Method
method	I-Method
which	O
discriminates	O
between	O
the	O
features	O
or	O
semantics	O
from	O
two	O
image	O
sets	O
as	O
viewed	O
under	O
a	O
task	B-Method
network	I-Method
.	O
	
This	O
would	O
amount	O
to	O
an	O
additional	O
feature	B-Method
level	I-Method
GAN	O
loss	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
orange	O
portion	O
)	O
:	O
Taken	O
together	O
,	O
these	O
loss	B-Method
functions	I-Method
form	O
our	O
complete	O
objective	O
:	O
This	O
ultimately	O
corresponds	O
to	O
solving	O
for	O
a	O
target	O
model	O
according	O
to	O
the	O
optimization	B-Task
problem	I-Task
We	O
have	O
introduced	O
a	O
method	O
for	O
unsupervised	B-Task
adaptation	I-Task
which	O
generalizes	O
adversarial	O
objectives	O
to	O
be	O
viewed	O
as	O
operating	O
at	O
the	O
pixel	O
or	O
feature	B-Method
level	I-Method
.	O
	
In	O
addition	O
,	O
we	O
introduce	O
the	O
use	O
of	O
cycle	O
-	O
consistency	O
together	O
with	O
semantic	O
transformation	O
constraints	O
to	O
guide	O
the	O
mapping	O
from	O
one	O
domain	O
to	O
another	O
.	O
	
In	O
this	O
work	O
,	O
we	O
apply	O
CyCADA	B-Method
to	O
both	O
digit	B-Task
adaptation	I-Task
and	O
to	O
semantic	B-Task
segmentation	I-Task
.	O
	
We	O
implement	O
as	O
a	O
pixel	B-Method
-	I-Method
to	I-Method
-	I-Method
pixel	I-Method
convnet	I-Method
,	O
as	O
a	O
convnet	B-Method
classifier	I-Method
or	O
a	O
Fully	B-Method
-	I-Method
Convolutional	I-Method
Net	I-Method
(	O
FCN	B-Method
)	O
and	O
as	O
a	O
convnet	B-Method
with	O
binary	O
outputs	O
.	O
	
section	O
:	O
Experiments	O
	
We	O
evaluate	O
CyCADA	B-Method
on	O
several	O
unsupervised	B-Task
adaptation	I-Task
scenarios	O
.	O
	
We	O
first	O
focus	O
on	O
adaptation	B-Task
for	O
digit	B-Task
classification	I-Task
using	O
the	O
MNIST	O
lecun_ieee98	O
,	O
USPS	O
,	O
and	O
Street	O
View	O
House	O
Numbers	O
(	O
SVHN	O
)	O
netzer_nips11	O
datasets	O
.	O
	
After	O
which	O
we	O
present	O
results	O
for	O
the	O
task	O
of	O
semantic	B-Task
image	I-Task
segmentation	I-Task
,	O
using	O
the	O
SYNTHIA	B-Material
ros_cvpr16	O
,	O
GTA	O
richter_eccv16	O
and	O
CityScapes	O
cordts_cvpr16	O
datasets	O
.	O
	
subsection	O
:	O
Digit	B-Method
Adaptation	I-Method
	
We	O
evaluate	O
our	O
method	O
across	O
the	O
adaptation	O
shifts	O
of	O
USPS	O
to	O
MNIST	O
,	O
MNIST	O
to	O
USPS	O
,	O
and	O
SVHN	B-Material
to	I-Material
MNIST	I-Material
,	O
using	O
the	O
full	O
training	O
sets	O
during	O
learning	O
phases	O
and	O
evaluating	O
on	O
the	O
standard	O
test	O
sets	O
.	O
	
We	O
report	O
classification	B-Metric
accuracy	I-Metric
for	O
each	O
shift	O
in	O
Table	O
[	O
reference	O
]	O
and	O
find	O
that	O
our	O
method	O
outperforms	O
competing	O
approaches	O
on	O
average	O
.	O
	
The	O
classifier	B-Method
for	O
our	O
method	O
for	O
all	O
digit	B-Task
shifts	I-Task
uses	O
a	O
variant	O
of	O
the	O
LeNet	B-Method
architecture	I-Method
(	O
see	O
[	O
reference	O
]	O
for	O
full	O
implementation	O
details	O
)	O
.	O
	
Note	O
that	O
the	O
recent	O
pixel	B-Method
-	I-Method
da	I-Method
method	I-Method
by	O
bousmalis_cvpr17	O
presents	O
results	O
for	O
only	O
the	O
MNIST	O
to	O
USPS	O
shift	O
and	O
reports	O
95.9	O
%	O
accuracy	B-Metric
,	O
while	O
our	O
method	O
achieves	O
95.6	O
%	O
accuracy	B-Metric
.	O
	
However	O
,	O
the	O
pixel	B-Method
-	I-Method
da	I-Method
approach	I-Method
cross	O
validates	O
with	O
some	O
labeled	O
data	O
which	O
is	O
not	O
an	O
equivalent	O
evaluation	O
setting	O
.	O
	
Ablation	O
:	O
Pixel	B-Method
vs	I-Method
Feature	I-Method
Level	I-Method
Transfer	I-Method
.	O
	
We	O
begin	O
by	O
evaluating	O
the	O
contribution	O
of	O
the	O
pixel	O
space	O
and	O
feature	B-Method
space	I-Method
transfer	I-Method
.	O
	
We	O
find	O
that	O
in	O
the	O
case	O
of	O
the	O
small	O
domain	O
shifts	O
between	O
USPS	O
and	O
MNIST	O
,	O
the	O
pixel	B-Method
space	I-Method
adaptation	I-Method
by	O
which	O
we	O
train	O
a	O
classifier	B-Method
using	O
images	O
translated	O
using	O
CycleGAN	B-Method
zhu_arxiv17	O
,	O
performs	O
very	O
well	O
,	O
outperforming	O
or	O
comparable	O
to	O
prior	B-Method
adaptation	I-Method
approaches	I-Method
.	O
	
Feature	B-Method
level	I-Method
adaptation	I-Method
offers	O
a	O
small	O
benefit	O
in	O
this	O
case	O
of	O
a	O
small	O
pixel	O
shift	O
.	O
	
However	O
,	O
for	O
the	O
more	O
difficult	O
shift	O
of	O
SVHN	B-Material
to	I-Material
MNIST	I-Material
,	O
we	O
find	O
that	O
feature	B-Method
level	I-Method
adaptation	I-Method
outperforms	O
the	O
pixel	B-Method
level	I-Method
adaptation	I-Method
,	O
and	O
importantly	O
,	O
both	O
may	O
be	O
combined	O
to	O
produce	O
an	O
overall	O
model	O
which	O
outperforms	O
all	O
competing	O
methods	O
.	O
	
Ablation	B-Task
:	O
No	O
Semantic	O
Consistency	O
.	O
	
We	O
experiment	O
without	O
the	O
addition	O
of	O
our	O
semantic	O
consistency	O
loss	O
and	O
find	O
that	O
the	O
standard	O
unsupervised	B-Method
CycleGAN	I-Method
approach	I-Method
diverged	O
when	O
training	O
SVHN	B-Material
to	I-Material
MNIST	I-Material
often	O
suffering	O
from	O
random	O
label	O
flipping	O
.	O
	
Figure	O
[	O
reference	O
]	O
(	O
a	O
)	O
demonstrates	O
two	O
examples	O
where	O
cycle	O
constraints	O
alone	O
fail	O
to	O
have	O
the	O
desired	O
behavior	O
for	O
our	O
end	O
task	O
.	O
	
An	O
SVHN	O
image	O
is	O
mapped	O
to	O
a	O
convincing	O
MNIST	O
type	O
image	O
and	O
back	O
to	O
a	O
SVHN	O
image	O
with	O
correct	O
semantics	O
.	O
	
However	O
,	O
the	O
MNIST	O
-	O
like	O
image	O
has	O
mismatched	O
semantics	O
.	O
	
Our	O
modified	O
version	O
,	O
which	O
uses	O
the	O
source	O
labels	O
to	O
train	O
a	O
weak	B-Method
classification	I-Method
model	I-Method
which	O
can	O
be	O
used	O
to	O
enforce	O
semantic	O
consistency	O
before	O
and	O
after	O
translation	B-Task
,	O
resolves	O
this	O
issue	O
and	O
produces	O
strong	O
performance	O
.	O
	
Ablation	O
:	O
No	O
Cycle	O
Consistency	O
.	O
	
We	O
study	O
the	O
result	O
when	O
learning	O
without	O
the	O
cycle	O
consistency	O
loss	O
.	O
	
First	O
note	O
that	O
there	O
is	O
no	O
reconstruction	O
guarantee	O
in	O
this	O
case	O
,	O
thus	O
in	O
Figure	O
[	O
reference	O
]	O
(	O
b	O
)	O
we	O
see	O
that	O
the	O
translation	B-Task
back	O
to	O
SVHN	O
fails	O
.	O
	
In	O
addition	O
,	O
we	O
find	O
that	O
while	O
the	O
semantic	O
loss	O
does	O
encourage	O
correct	O
semantics	O
it	O
relies	O
on	O
the	O
weak	O
source	O
labeler	O
and	O
thus	O
label	B-Task
flipping	I-Task
still	O
occurs	O
(	O
see	O
right	O
image	O
triple	O
)	O
.	O
	
subsection	O
:	O
Semantic	B-Task
Segmentation	I-Task
Adaptation	I-Task
	
The	O
task	O
is	O
to	O
assign	O
a	O
semantic	O
label	O
to	O
each	O
pixel	O
in	O
the	O
input	O
image	O
,	O
e.g.	O
,	O
,	O
etc	O
.	O
	
We	O
limit	O
our	O
evaluation	O
to	O
the	O
unsupervised	B-Task
adaptation	I-Task
setting	I-Task
,	O
where	O
labels	O
are	O
only	O
available	O
in	O
the	O
source	O
domain	O
,	O
but	O
we	O
are	O
evaluated	O
solely	O
on	O
our	O
performance	O
in	O
the	O
target	O
domain	O
.	O
	
For	O
each	O
experiment	O
,	O
we	O
use	O
three	O
metrics	O
to	O
evaluate	O
performance	O
.	O
	
Let	O
be	O
the	O
number	O
of	O
pixels	O
of	O
class	O
predicted	O
as	O
class	O
,	O
let	O
be	O
the	O
total	O
number	O
of	O
pixels	O
of	O
class	O
,	O
and	O
	
let	O
be	O
the	O
number	O
of	O
classes	O
.	O
	
Our	O
three	O
evaluation	B-Metric
metrics	I-Metric
are	O
,	O
mean	B-Metric
intersection	I-Metric
-	I-Metric
over	I-Metric
-	I-Metric
union	I-Metric
(	O
mIoU	B-Metric
)	O
,	O
frequency	B-Metric
weighted	I-Metric
intersection	I-Metric
-	I-Metric
over	I-Metric
-	I-Metric
union	I-Metric
(	O
fwIoU	B-Metric
)	O
,	O
and	O
pixel	B-Metric
accuracy	I-Metric
,	O
which	O
are	O
defined	O
as	O
follows	O
:	O
mIoU	B-Metric
,	O
fwIoU	B-Metric
,	O
pixel	B-Metric
acc	I-Metric
.	O
.	O
	
Cycle	B-Method
-	I-Method
consistent	I-Method
adversarial	I-Method
adaptation	I-Method
is	O
general	O
and	O
can	O
be	O
applied	O
at	O
any	O
layer	O
of	O
a	O
network	O
.	O
	
Since	O
optimizing	O
the	O
full	O
CyCADA	B-Method
objective	I-Method
in	O
Equation	O
[	O
reference	O
]	O
end	O
-	O
to	O
-	O
end	O
is	O
memory	O
-	O
intensive	O
in	O
practice	O
,	O
we	O
train	O
our	O
model	O
in	O
stages	O
.	O
	
First	O
,	O
we	O
perform	O
image	B-Method
-	I-Method
space	I-Method
adaptation	I-Method
and	O
map	O
our	O
source	O
data	O
into	O
the	O
target	O
domain	O
.	O
	
Next	O
,	O
using	O
the	O
adapted	O
source	O
data	O
with	O
the	O
original	O
source	O
labels	O
,	O
we	O
learn	O
a	O
task	B-Method
model	I-Method
that	O
is	O
suited	O
to	O
operating	O
on	O
target	O
data	O
.	O
	
Finally	O
,	O
we	O
perform	O
another	O
round	O
of	O
adaptation	B-Task
between	O
the	O
adapted	O
source	O
data	O
and	O
the	O
target	O
data	O
in	O
feature	O
-	O
space	O
,	O
using	O
one	O
of	O
the	O
intermediate	B-Method
layers	I-Method
of	O
the	O
task	B-Method
model	I-Method
.	O
	
Additionally	O
,	O
we	O
do	O
not	O
use	O
the	O
semantic	O
loss	O
for	O
the	O
segmentation	B-Task
experiments	O
as	O
it	O
would	O
require	O
loading	O
generators	B-Method
,	O
discriminators	B-Method
,	O
and	O
an	O
additional	O
semantic	B-Method
segmenter	I-Method
into	O
memory	O
all	O
at	O
once	O
for	O
two	O
images	O
.	O
	
We	O
did	O
not	O
have	O
the	O
required	O
memory	O
for	O
this	O
at	O
the	O
time	O
of	O
submission	O
,	O
but	O
leave	O
it	O
to	O
future	O
work	O
to	O
deploy	O
model	B-Method
parallelism	I-Method
or	O
experiment	O
with	O
larger	O
GPU	O
memory	O
.	O
	
For	O
our	O
first	O
evaluation	O
,	O
we	O
consider	O
the	O
SYNTHIA	B-Material
dataset	I-Material
ros_cvpr16	O
,	O
which	O
contains	O
synthetic	O
renderings	O
of	O
urban	O
scenes	O
.	O
	
We	O
use	O
the	O
SYNTHIA	B-Material
video	I-Material
sequences	I-Material
,	O
which	O
are	O
rendered	O
across	O
a	O
variety	O
of	O
environments	O
,	O
weather	O
conditions	O
,	O
and	O
lighting	O
conditions	O
.	O
	
This	O
provides	O
a	O
synthetic	O
testbed	O
for	O
evaluating	O
adaptation	B-Method
techniques	I-Method
.	O
	
For	O
comparison	O
with	O
previous	O
work	O
,	O
in	O
this	O
work	O
we	O
focus	O
on	O
adaptation	O
between	O
seasons	O
.	O
	
We	O
use	O
only	O
the	O
front	O
-	O
facing	O
views	O
in	O
the	O
sequences	O
so	O
as	O
to	O
mimic	O
dashcam	O
imagery	O
,	O
and	O
adapt	O
from	O
fall	O
to	O
winter	O
.	O
	
The	O
subset	O
of	O
the	O
dataset	O
we	O
use	O
contains	O
13	O
classes	O
and	O
consists	O
of	O
10	O
,	O
852	O
fall	B-Material
images	I-Material
and	O
7	O
,	O
654	O
winter	B-Material
images	I-Material
.	O
	
To	O
further	O
demonstrate	O
our	O
method	O
’s	O
applicability	O
to	O
real	B-Task
-	I-Task
world	I-Task
adaptation	I-Task
scenarios	I-Task
,	O
we	O
also	O
evaluate	O
our	O
model	O
in	O
a	O
challenging	O
synthetic	B-Task
-	I-Task
to	I-Task
-	I-Task
real	I-Task
adaptation	I-Task
setting	I-Task
.	O
	
For	O
our	O
synthetic	O
source	O
domain	O
,	O
we	O
use	O
the	O
GTA5	O
dataset	O
richter_eccv16	O
extracted	O
from	O
the	O
game	O
Grand	O
Theft	O
Auto	O
V	O
,	O
which	O
contains	O
24966	O
images	O
.	O
	
We	O
consider	O
adaptation	B-Task
from	O
GTA5	B-Material
to	I-Material
the	I-Material
real	I-Material
-	I-Material
world	I-Material
Cityscapes	I-Material
dataset	I-Material
cordts_cvpr16	O
,	O
from	O
which	O
we	O
used	O
19998	O
images	O
without	O
annotation	O
for	O
training	O
and	O
500	O
images	O
for	O
validation	B-Task
.	O
	
Both	O
of	O
these	O
datasets	O
are	O
evaluated	O
on	O
the	O
same	O
set	O
of	O
19	O
classes	O
,	O
allowing	O
for	O
straightforward	O
adaptation	O
between	O
the	O
two	O
domains	O
.	O
	
Image	B-Method
-	I-Method
space	I-Method
adaptation	I-Method
also	O
affords	O
us	O
the	O
ability	O
to	O
visually	O
inspect	O
the	O
results	O
of	O
the	O
adaptation	B-Method
method	I-Method
.	O
	
This	O
is	O
a	O
distinct	O
advantage	O
over	O
opaque	O
feature	B-Method
-	I-Method
space	I-Method
adaptation	I-Method
methods	I-Method
,	O
especially	O
in	O
truly	O
unsupervised	B-Task
settings	I-Task
—	O
without	O
labels	O
,	O
there	O
is	O
no	O
way	O
to	O
empirically	O
evaluate	O
the	O
adapted	O
model	O
,	O
and	O
thus	O
no	O
way	O
to	O
verify	O
that	O
adaptation	B-Method
is	O
improving	O
task	B-Task
performance	O
.	O
	
Visually	O
confirming	O
that	O
the	O
conversions	O
between	O
source	O
and	O
target	O
images	O
are	O
reasonable	O
,	O
while	O
not	O
a	O
guarantee	O
of	O
improved	O
task	O
performance	O
,	O
can	O
serve	O
as	O
a	O
sanity	O
check	O
to	O
ensure	O
that	O
adaptation	B-Task
is	O
not	O
completely	O
diverging	O
.	O
	
This	O
process	O
is	O
diagrammed	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
For	O
implementation	O
details	O
please	O
see	O
Appendix	O
[	O
reference	O
]	O
.	O
	
subsubsection	O
:	O
Cross	O
-	O
season	O
adaptation	O
	
We	O
start	O
by	O
exploring	O
the	O
abilities	O
of	O
pixel	B-Method
space	I-Method
adaptation	I-Method
alone	O
(	O
using	O
FCN8s	B-Method
architecture	I-Method
)	O
for	O
the	O
setting	O
of	O
adapting	O
across	O
seasons	O
in	O
synthetic	O
data	O
.	O
	
For	O
this	O
we	O
use	O
the	O
SYNTHIA	B-Material
dataset	I-Material
and	O
adapt	O
from	O
fall	O
to	O
winter	O
weather	O
conditions	O
.	O
	
Typically	O
in	O
unsupervised	B-Task
adaptation	I-Task
settings	O
it	O
is	O
difficult	O
to	O
interpret	O
what	O
causes	O
the	O
performance	O
improvement	O
after	O
adaptation	B-Task
.	O
	
Therefore	O
,	O
we	O
use	O
this	O
setting	O
as	O
an	O
example	O
where	O
we	O
may	O
directly	O
visualize	O
the	O
shift	O
from	O
fall	O
to	O
winter	O
and	O
inspect	O
the	O
intermediate	O
pixel	O
level	O
adaptation	O
result	O
from	O
our	O
algorithm	O
.	O
	
In	O
Figure	O
[	O
reference	O
]	O
we	O
show	O
the	O
result	O
of	O
pixel	B-Method
only	I-Method
adaptation	I-Method
as	O
we	O
generate	O
a	O
winter	B-Material
domain	I-Material
image	I-Material
(	O
b	O
)	O
from	O
a	O
fall	B-Material
domain	I-Material
image	I-Material
(	O
a	O
)	O
,	O
and	O
visa	O
versa	O
(	O
c	O
-	O
d	O
)	O
.	O
	
We	O
may	O
clearly	O
see	O
the	O
changes	O
of	O
adding	O
or	O
removing	O
snow	O
.	O
	
This	O
visually	O
interpretable	O
result	O
matches	O
our	O
expectation	O
of	O
the	O
true	O
shift	O
between	O
these	O
domains	O
and	O
indeed	O
results	O
in	O
favorable	O
final	O
semantic	B-Task
segmentation	I-Task
performance	O
from	O
fall	O
to	O
winter	O
as	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
We	O
find	O
that	O
CyCADA	B-Method
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
this	O
task	O
with	O
image	B-Method
space	I-Method
adaptation	I-Method
alone	O
,	O
however	O
does	O
not	O
recover	O
full	O
supervised	B-Method
learning	I-Method
performance	O
(	O
train	O
on	O
target	O
)	O
.	O
	
Some	O
example	O
errors	O
includes	O
adding	O
snow	O
to	O
the	O
sidewalks	O
,	O
but	O
not	O
to	O
the	O
road	O
,	O
while	O
in	O
the	O
true	O
winter	O
domain	O
snow	O
appears	O
in	O
both	O
locations	O
.	O
	
However	O
,	O
even	O
this	O
mistake	O
is	O
interesting	O
as	O
it	O
implies	O
that	O
the	O
model	O
is	O
learning	O
to	O
distinguish	O
road	O
from	O
sidewalk	O
during	O
pixel	B-Task
adaptation	I-Task
,	O
despite	O
the	O
lack	O
of	O
pixel	O
annotations	O
.	O
	
sky	O
building	O
road	O
sidewalk	O
fence	O
vegetation	O
pole	O
car	O
traffic	O
sign	O
pedestrian	O
bicycle	O
lanemarking	O
traffic	O
light	O
mIoU	B-Metric
fwIoU	O
Pixel	O
acc	O
.	O
	
Cycle	B-Method
-	I-Method
consistent	I-Method
adversarial	I-Method
adaptation	I-Method
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
adaptation	B-Metric
performance	I-Metric
.	O
	
We	O
see	O
that	O
under	O
the	O
fwIoU	B-Metric
and	O
pixel	B-Metric
accuracy	I-Metric
metrics	O
,	O
CyCADA	B-Method
approaches	O
oracle	O
performance	O
,	O
falling	O
short	O
by	O
only	O
a	O
few	O
points	O
,	O
despite	O
being	O
entirely	O
unsupervised	O
.	O
	
This	O
indicates	O
that	O
CyCADA	B-Method
is	O
extremely	O
effective	O
at	O
correcting	O
the	O
most	O
common	O
classes	O
in	O
the	O
dataset	O
.	O
	
This	O
conclusion	O
is	O
supported	O
by	O
inspection	O
of	O
the	O
individual	O
classes	O
in	O
Table	O
[	O
reference	O
]	O
,	O
where	O
we	O
see	O
the	O
largest	O
improvement	O
on	O
common	O
classes	O
such	O
as	O
road	O
and	O
sidewalk	O
.	O
	
Architecture	O
road	O
sidewalk	O
building	O
wall	O
fence	O
pole	O
traffic	O
light	O
traffic	O
sign	O
vegetation	O
terrain	O
sky	O
person	O
rider	O
car	O
truck	O
bus	O
train	O
motorbike	O
bicycle	O
mIoU	B-Metric
fwIoU	O
Pixel	O
acc	O
.	O
	
subsubsection	O
:	O
Synthetic	O
to	O
real	B-Task
adaptation	I-Task
	
To	O
evaluate	O
our	O
method	O
’s	O
applicability	O
to	O
real	B-Task
-	I-Task
world	I-Task
adaptation	I-Task
settings	I-Task
,	O
we	O
investigate	O
adaptation	B-Task
from	O
synthetic	O
to	O
real	O
-	O
world	O
imagery	O
.	O
	
The	O
results	O
of	O
this	O
evaluation	O
are	O
presented	O
in	O
Table	O
[	O
reference	O
]	O
with	O
qualitative	O
results	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Once	O
again	O
,	O
CyCADA	B-Method
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
,	O
recovering	O
approximately	O
40	O
%	O
of	O
the	O
performance	O
lost	O
to	O
domain	O
shift	O
.	O
	
CyCADA	B-Method
also	O
improves	O
or	O
maintains	O
performance	O
on	O
all	O
19	O
classes	O
.	O
	
Examination	O
of	O
fwIoU	B-Metric
and	O
pixel	B-Metric
accuracy	I-Metric
as	O
well	O
as	O
individual	O
class	B-Metric
IoUs	I-Metric
reveals	O
that	O
our	O
method	O
performs	O
well	O
on	O
most	O
of	O
the	O
common	O
classes	O
.	O
	
Although	O
some	O
classes	O
such	O
as	O
train	O
and	O
bicycle	O
see	O
little	O
or	O
no	O
improvement	O
,	O
we	O
note	O
that	O
those	O
classes	O
are	O
poorly	O
represented	O
in	O
the	O
GTA5	O
data	O
,	O
making	O
recognition	B-Task
very	O
difficult	O
.	O
	
We	O
compare	O
our	O
model	O
against	O
shrivastava_cvpr17	O
for	O
this	O
setting	O
,	O
but	O
found	O
this	O
approach	O
did	O
not	O
converge	O
and	O
resulted	O
in	O
worse	O
performance	O
than	O
the	O
source	B-Method
only	I-Method
model	I-Method
(	O
see	O
Appendix	O
for	O
full	O
details	O
)	O
.	O
	
We	O
visualize	O
the	O
results	O
of	O
image	B-Task
-	I-Task
space	I-Task
adaptation	I-Task
between	O
GTA5	B-Method
and	O
Cityscapes	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
The	O
most	O
obvious	O
difference	O
between	O
the	O
original	O
images	O
and	O
the	O
adapted	O
images	O
is	O
the	O
saturation	O
levels	O
—	O
the	O
GTA5	O
imagery	O
is	O
much	O
more	O
vivid	O
than	O
the	O
Cityscapes	O
imagery	O
,	O
so	O
adaptation	O
adjusts	O
the	O
colors	O
to	O
compensate	O
.	O
	
We	O
also	O
observe	O
texture	O
changes	O
,	O
which	O
are	O
perhaps	O
most	O
apparent	O
in	O
the	O
road	O
:	O
in	O
-	O
game	O
,	O
the	O
roads	O
appear	O
rough	O
with	O
many	O
blemishes	O
,	O
but	O
Cityscapes	O
roads	O
tend	O
to	O
be	O
fairly	O
uniform	O
in	O
appearance	O
,	O
so	O
in	O
converting	O
from	O
GTA5	B-Material
to	I-Material
Cityscapes	I-Material
,	O
our	O
model	O
removes	O
most	O
of	O
the	O
texture	O
.	O
	
Somewhat	O
amusingly	O
,	O
our	O
model	O
has	O
a	O
tendency	O
to	O
add	O
a	O
hood	O
ornament	O
to	O
the	O
bottom	O
of	O
the	O
image	O
,	O
which	O
,	O
while	O
likely	O
irrelevant	O
to	O
the	O
segmentation	B-Task
task	I-Task
,	O
serves	O
as	O
a	O
further	O
indication	O
that	O
image	B-Method
-	I-Method
space	I-Method
adaptation	I-Method
is	O
producing	O
reasonable	O
results	O
.	O
	
section	O
:	O
Conclusion	O
	
We	O
presented	O
a	O
cycle	B-Method
-	I-Method
consistent	I-Method
adversarial	I-Method
domain	I-Method
adaptation	I-Method
method	I-Method
that	O
unifies	O
cycle	B-Method
-	I-Method
consistent	I-Method
adversarial	I-Method
models	I-Method
with	O
adversarial	B-Method
adaptation	I-Method
methods	I-Method
.	O
	
CyCADA	B-Method
is	O
able	O
to	O
adapt	O
even	O
in	O
the	O
absence	O
of	O
target	O
labels	O
and	O
is	O
broadly	O
applicable	O
at	O
both	O
the	O
pixel	B-Method
-	I-Method
level	I-Method
and	O
in	O
feature	B-Method
space	I-Method
.	O
	
An	O
image	B-Method
-	I-Method
space	I-Method
adaptation	I-Method
instantiation	I-Method
of	O
CyCADA	B-Method
also	O
provides	O
additional	O
interpretability	O
and	O
serves	O
as	O
a	O
useful	O
way	O
to	O
verify	O
successful	O
adaptation	B-Task
.	O
	
Finally	O
,	O
we	O
experimentally	O
validated	O
our	O
model	O
on	O
a	O
variety	O
of	O
adaptation	B-Task
tasks	I-Task
:	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
in	O
multiple	O
evaluation	O
settings	O
indicate	O
its	O
effectiveness	O
,	O
even	O
on	O
challenging	O
synthetic	B-Task
-	I-Task
to	I-Task
-	I-Task
real	I-Task
tasks	I-Task
.	O
	
bibliography	O
:	O
References	O
	
section	O
:	O
Appendix	O
	
subsection	O
:	O
Implementation	O
Details	O
	
We	O
begin	O
by	O
pretraining	O
the	O
source	B-Method
task	I-Method
model	I-Method
,	O
,	O
using	O
the	O
task	B-Method
loss	I-Method
on	O
the	O
labeled	O
source	O
data	O
.	O
	
Next	O
,	O
we	O
perform	O
pixel	B-Method
-	I-Method
level	I-Method
adaptation	O
using	O
our	O
image	B-Method
space	I-Method
GAN	I-Method
losses	I-Method
together	O
with	O
semantic	O
consistency	O
and	O
cycle	O
consistency	O
losses	O
.	O
	
This	O
yeilds	O
learned	O
parameters	O
for	O
the	O
image	O
transformations	O
,	O
and	O
,	O
image	B-Method
discriminators	I-Method
,	O
and	O
,	O
as	O
well	O
as	O
an	O
initial	O
setting	O
of	O
the	O
task	B-Method
model	I-Method
,	O
,	O
which	O
is	O
trained	O
using	O
pixel	O
transformed	O
source	O
images	O
and	O
the	O
corresponding	O
source	O
pixel	O
labels	O
.	O
	
Finally	O
,	O
we	O
perform	O
feature	B-Method
space	I-Method
adpatation	I-Method
in	O
order	O
to	O
update	O
the	O
target	O
semantic	B-Method
model	I-Method
,	O
,	O
to	O
have	O
features	O
which	O
are	O
aligned	O
between	O
the	O
source	O
images	O
mapped	O
into	O
target	O
style	O
and	O
the	O
real	O
target	O
images	O
.	O
	
During	O
this	O
phase	O
,	O
we	O
learn	O
the	O
feature	B-Method
discriminator	I-Method
,	O
and	O
use	O
this	O
to	O
guide	O
the	O
representation	B-Task
update	I-Task
to	O
.	O
	
In	O
general	O
,	O
our	O
method	O
could	O
also	O
perform	O
phases	O
2	O
and	O
3	O
simultaneously	O
,	O
but	O
this	O
would	O
require	O
more	O
GPU	O
memory	O
then	O
available	O
at	O
the	O
time	O
of	O
these	O
experiments	O
.	O
	
For	O
all	O
feature	B-Method
space	I-Method
adaptation	O
we	O
equally	O
weight	O
the	O
generator	B-Method
and	I-Method
discriminator	I-Method
losses	I-Method
.	O
	
We	O
only	O
update	O
the	O
generator	O
when	O
the	O
discriminator	B-Metric
accuracy	I-Metric
is	O
above	O
60	O
%	O
over	O
the	O
last	O
batch	O
(	O
digits	O
)	O
or	O
last	O
100	O
iterations	O
(	O
semantic	B-Task
segmentation	I-Task
)	O
	
–	O
this	O
reduces	O
the	O
potential	O
for	O
volatile	B-Task
training	I-Task
.	O
	
If	O
after	O
an	O
epoch	O
(	O
entire	O
pass	O
over	O
dataset	O
)	O
no	O
suitable	O
discriminator	O
is	O
found	O
,	O
the	O
feature	B-Method
adaptation	I-Method
stops	O
,	O
otherwise	O
it	O
continues	O
until	O
max	O
iterations	O
are	O
reached	O
.	O
	
subsubsection	O
:	O
Digit	O
Experiments	O
	
For	O
all	O
digit	O
experiments	O
we	O
use	O
a	O
variant	O
of	O
the	O
LeNet	B-Method
architecture	I-Method
as	O
the	O
task	O
net	O
(	O
Figure	O
[	O
reference	O
]	O
left	O
)	O
.	O
	
Our	O
feature	B-Method
discriminator	I-Method
network	I-Method
consists	O
of	O
3	O
fully	B-Method
connected	I-Method
layers	I-Method
(	O
Figure	O
[	O
reference	O
]	O
mid	O
left	O
)	O
.	O
	
The	O
image	B-Method
discriminator	I-Method
network	I-Method
consists	O
of	O
6	O
convolutional	B-Method
layers	I-Method
culminating	O
in	O
a	O
single	O
value	O
per	O
pixel	O
(	O
Figure	O
[	O
reference	O
]	O
mid	O
right	O
)	O
.	O
	
Finally	O
,	O
to	O
generate	O
one	O
image	O
domain	O
from	O
another	O
we	O
use	O
a	O
multilayer	B-Method
network	I-Method
which	O
consists	O
of	O
convolution	B-Method
layers	I-Method
followed	O
by	O
two	O
residual	O
blocks	O
and	O
then	O
deconvolution	B-Method
layers	I-Method
(	O
Figure	O
[	O
reference	O
]	O
right	O
)	O
.	O
	
All	O
stages	O
are	O
trained	O
using	O
the	O
Adam	B-Method
optimizer	I-Method
.	O
	
paragraph	O
:	O
Hyperparameters	B-Method
.	O
	
For	O
training	O
the	O
source	B-Method
task	I-Method
net	I-Method
model	I-Method
,	O
we	O
use	O
learning	O
rate	O
1e	O
-	O
4	O
and	O
train	O
for	O
100	O
epochs	O
over	O
the	O
data	O
with	O
batch	O
size	O
128	O
.	O
	
For	O
feature	B-Method
space	I-Method
adaptation	O
we	O
use	O
learning	B-Method
rate	I-Method
1e	O
-	O
5	O
and	O
train	O
for	O
max	O
200	O
epochs	O
over	O
the	O
data	O
.	O
	
For	O
pixel	B-Task
space	I-Task
adaptation	I-Task
we	O
train	O
our	O
generators	B-Method
and	I-Method
discriminators	I-Method
with	O
equal	B-Method
weighting	I-Method
on	O
all	O
losses	O
,	O
use	O
batch	O
size	O
100	O
,	O
learning	B-Metric
rate	I-Metric
2e	I-Metric
-	I-Metric
4	I-Metric
(	O
default	O
from	O
CycleGAN	B-Method
)	O
,	O
and	O
trained	O
for	O
50	O
epochs	O
.	O
	
We	O
ran	O
each	O
experiment	O
4	O
times	O
and	O
report	O
the	O
average	O
and	O
standard	O
error	O
across	O
the	O
runs	O
.	O
	
subsubsection	O
:	O
Semantic	B-Task
Segmentation	I-Task
	
We	O
experiment	O
with	O
both	O
the	O
VGG16	B-Method
-	I-Method
FCN8s	I-Method
architecture	I-Method
as	O
well	O
as	O
the	O
DRN	B-Method
-	I-Method
26	I-Method
architecture	I-Method
.	O
	
For	O
FCN8s	B-Method
,	O
we	O
train	O
our	O
source	B-Method
semantic	I-Method
segmentation	I-Method
model	I-Method
for	O
100k	O
iterations	O
using	O
SGD	B-Method
with	O
learning	B-Metric
rate	I-Metric
1e	O
-	O
3	O
and	O
momentum	O
0.9	O
.	O
	
For	O
the	O
DRN	B-Method
-	I-Method
26	I-Method
architecture	I-Method
,	O
we	O
train	O
our	O
source	B-Method
semantic	I-Method
segmentation	I-Method
model	I-Method
for	O
115	O
K	O
iterations	O
using	O
SGD	B-Method
with	O
learning	B-Metric
rate	I-Metric
1e	I-Metric
-	I-Metric
3	I-Metric
and	O
momentum	O
0.9	O
.	O
	
We	O
use	O
a	O
crop	O
size	O
of	O
600x600	O
and	O
a	O
batch	O
size	O
of	O
8	O
for	O
this	O
training	O
.	O
	
For	O
cycle	B-Task
-	I-Task
consistent	I-Task
image	I-Task
level	I-Task
adaptation	I-Task
,	O
we	O
followed	O
the	O
network	B-Method
architecture	I-Method
and	O
hyperparameters	B-Method
of	O
	
CycleGAN	O
zhu_arxiv17	O
.	O
	
All	O
images	O
were	O
resized	O
to	O
have	O
width	O
of	O
1024	O
pixels	O
while	O
keeping	O
the	O
aspect	O
ratio	O
,	O
and	O
the	O
training	O
was	O
performed	O
with	O
randomly	O
cropped	O
patches	O
of	O
size	O
400	O
by	O
400	O
.	O
	
Also	O
,	O
due	O
to	O
large	O
size	O
of	O
the	O
dataset	O
,	O
we	O
trained	O
only	O
20	O
epochs	O
.	O
	
For	O
feature	B-Method
level	I-Method
adaptation	I-Method
,	O
we	O
train	O
using	O
SGD	B-Method
with	O
momentum	O
,	O
0.99	O
,	O
and	O
learning	B-Metric
rate	I-Metric
1e	I-Metric
-	I-Metric
5	I-Metric
.	O
	
We	O
weight	O
the	O
representation	O
loss	O
ten	O
times	O
less	O
than	O
the	O
discriminator	O
loss	O
as	O
a	O
convienience	O
since	O
otherwise	O
the	O
discriminator	O
did	O
not	O
learn	O
a	O
suitable	O
model	O
within	O
a	O
single	O
epoch	O
.	O
	
Then	O
the	O
segmentation	B-Method
model	I-Method
was	O
trained	O
separately	O
using	O
the	O
adapted	O
source	O
images	O
and	O
the	O
ground	O
truth	O
labels	O
of	O
the	O
source	O
data	O
.	O
	
Due	O
to	O
memory	O
limitations	O
we	O
can	O
only	O
include	O
a	O
single	O
source	O
and	O
single	O
target	O
image	O
at	O
a	O
time	O
(	O
crops	O
of	O
size	O
768x768	O
)	O
,	O
this	O
small	O
batch	O
is	O
one	O
of	O
the	O
main	O
reasons	O
for	O
using	O
a	O
high	O
momentum	O
parameter	O
.	O
	
subsection	O
:	O
Comparison	O
to	O
shrivastava_cvpr17	O
for	O
Semantic	B-Task
Segmentation	I-Task
	
We	O
illustrate	O
the	O
performance	O
of	O
a	O
recent	O
pixel	B-Method
level	I-Method
adaptation	I-Method
approach	I-Method
proposed	O
by	O
shrivastava_cvpr17	O
on	O
our	O
semantic	O
segmentation	O
data	O
–	O
GTA	B-Material
to	I-Material
Cityscapes	I-Material
.	O
	
These	O
images	O
are	O
significantly	O
larger	O
and	O
more	O
complex	O
than	O
those	O
shown	O
in	O
the	O
experiments	O
in	O
the	O
original	O
paper	O
.	O
	
We	O
show	O
image	B-Task
to	I-Task
image	I-Task
translation	I-Task
results	O
under	O
three	O
different	O
settings	O
of	O
the	O
model	O
hyperparameter	O
,	O
,	O
which	O
controls	O
the	O
tradeoff	O
between	O
the	O
reconstruction	B-Metric
loss	I-Metric
and	O
the	O
visual	O
style	O
loss	O
.	O
	
When	O
(	O
Figure	O
[	O
reference	O
]	O
right	O
)	O
,	O
the	O
resulting	O
image	O
converges	O
to	O
a	O
near	O
replica	O
of	O
the	O
original	O
image	O
,	O
thus	O
preserving	O
content	O
but	O
lacking	O
the	O
correct	O
target	O
style	O
.	O
	
When	O
or	O
(	O
Figure	O
[	O
reference	O
]	O
left	O
)	O
,	O
the	O
results	O
lack	O
any	O
consistent	O
semantics	O
making	O
it	O
difficult	O
to	O
perceive	O
the	O
style	O
of	O
the	O
transformed	O
image	O
.	O
	
Thus	O
,	O
the	O
resulting	O
performance	O
for	O
this	O
model	O
is	O
11.6	O
mIoU	B-Metric
for	O
FCN8s	B-Method
with	O
VGG	B-Method
,	O
well	O
below	O
the	O
performance	O
of	O
the	O
corresponding	O
source	B-Method
model	I-Method
of	O
17.9	O
mIoU.	B-Metric
	
subsection	O
:	O
Experiment	O
Analysis	O
	
To	O
understand	O
the	O
types	O
of	O
mistakes	O
which	O
are	O
improved	O
upon	O
and	O
those	O
which	O
still	O
persist	O
after	O
adaptation	O
,	O
we	O
present	O
the	O
confusion	O
matricies	O
before	O
and	O
after	O
our	O
approach	O
for	O
the	O
digit	O
experiment	O
of	O
SVHN	B-Material
to	I-Material
MNIST	I-Material
(	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
Before	O
adaptation	O
we	O
see	O
common	O
confusions	O
are	O
0s	O
with	O
2s	O
,	O
4s	O
,	O
and	O
7s	O
.	O
	
6	O
with	O
4	O
,	O
8	O
with	O
3	O
,	O
and	O
9	O
with	O
4	O
.	O
	
After	O
adaptation	O
all	O
errors	O
are	O
reduced	O
,	O
but	O
we	O
still	O
find	O
that	O
7s	O
are	O
confused	O
with	O
1s	O
and	O
0s	O
with	O
2s	O
.	O
	
These	O
errors	O
make	O
some	O
sense	O
as	O
with	O
hand	O
written	O
digits	O
,	O
these	O
digits	O
sometimes	O
resemble	O
one	O
another	O
.	O
	
It	O
remains	O
an	O
open	O
question	O
to	O
produce	O
a	O
model	O
which	O
may	O
overcome	O
these	O
types	O
of	O
errors	O
between	O
highly	O
similar	O
classes	O
.	O
	
document	O
:	O
Depthwise	B-Method
Separable	I-Method
Convolutions	I-Method
for	O
Neural	B-Task
Machine	I-Task
Translation	I-Task
	
Depthwise	B-Method
separable	I-Method
convolutions	I-Method
reduce	O
the	O
number	O
of	O
parameters	O
and	O
computation	O
used	O
in	O
convolutional	B-Method
operations	I-Method
while	O
increasing	O
representational	B-Metric
efficiency	I-Metric
.	O
	
They	O
have	O
been	O
shown	O
to	O
be	O
successful	O
in	O
image	B-Task
classification	I-Task
models	I-Task
,	O
both	O
in	O
obtaining	O
better	O
models	O
than	O
previously	O
possible	O
for	O
a	O
given	O
parameter	O
count	O
(	O
the	O
Xception	B-Method
architecture	I-Method
)	O
and	O
considerably	O
reducing	O
the	O
number	O
of	O
parameters	O
required	O
to	O
perform	O
at	O
a	O
given	O
level	O
(	O
the	O
MobileNets	B-Method
family	I-Method
of	I-Method
architectures	I-Method
)	O
.	O
	
Recently	O
,	O
convolutional	B-Method
sequence	I-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
networks	I-Method
have	O
been	O
applied	O
to	O
machine	B-Task
translation	I-Task
tasks	O
with	O
good	O
results	O
.	O
	
In	O
this	O
work	O
,	O
we	O
study	O
how	O
depthwise	B-Method
separable	I-Method
convolutions	I-Method
can	O
be	O
applied	O
to	O
neural	O
machine	B-Task
translation	I-Task
.	O
	
We	O
introduce	O
a	O
new	O
architecture	O
inspired	O
by	O
Xception	B-Method
and	O
ByteNet	B-Method
,	O
called	O
SliceNet	B-Method
,	O
which	O
enables	O
a	O
significant	O
reduction	O
of	O
the	O
parameter	B-Metric
count	I-Metric
and	O
amount	O
of	O
computation	O
needed	O
to	O
obtain	O
results	O
like	O
ByteNet	B-Method
,	O
and	O
,	O
with	O
a	O
similar	O
parameter	O
count	O
,	O
achieves	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
.	O
	
In	O
addition	O
to	O
showing	O
that	O
depthwise	B-Method
separable	I-Method
convolutions	I-Method
perform	O
well	O
for	O
machine	B-Task
translation	I-Task
,	O
we	O
investigate	O
the	O
architectural	O
changes	O
that	O
they	O
enable	O
:	O
we	O
observe	O
that	O
thanks	O
to	O
depthwise	B-Method
separability	I-Method
,	O
we	O
can	O
increase	O
the	O
length	O
of	O
convolution	O
windows	O
,	O
removing	O
the	O
need	O
for	O
filter	B-Method
dilation	I-Method
.	O
	
We	O
also	O
introduce	O
a	O
new	O
"	O
super	B-Method
-	I-Method
separable	I-Method
"	I-Method
convolution	I-Method
operation	I-Method
that	O
further	O
reduces	O
the	O
number	O
of	O
parameters	O
and	O
computational	B-Metric
cost	I-Metric
for	O
obtaining	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
.	O
	
section	O
:	O
Introduction	O
	
In	O
recent	O
years	O
,	O
sequence	B-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
recurrent	I-Method
neural	I-Method
networks	I-Method
(	I-Method
RNNs	I-Method
)	O
with	O
long	B-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
(	I-Method
LSTM	I-Method
)	I-Method
cells	I-Method
hochreiter1997	I-Method
have	O
proven	O
successful	O
at	O
many	O
natural	B-Task
language	I-Task
processing	I-Task
(	O
NLP	B-Task
)	O
tasks	O
,	O
including	O
machine	B-Task
translation	I-Task
sutskever14	O
,	O
bahdanau2014neural	O
,	O
cho2014learning	O
.	O
	
In	O
fact	O
,	O
the	O
results	O
they	O
yielded	O
have	O
been	O
so	O
good	O
that	O
the	O
gap	O
between	O
human	O
translations	O
and	O
machine	O
translations	O
has	O
narrowed	O
significantly	O
and	O
LSTM	B-Method
-	I-Method
based	I-Method
recurrent	I-Method
neural	I-Method
networks	I-Method
have	O
become	O
standard	O
in	O
natural	B-Task
language	I-Task
processing	I-Task
.	O
	
Even	O
more	O
recently	O
,	O
auto	B-Method
-	I-Method
regressive	I-Method
convolutional	I-Method
models	I-Method
have	O
proven	O
highly	O
effective	O
when	O
applied	O
to	O
audio	O
wavenet2016	O
,	O
image	O
pixelcnn2016	O
and	O
text	B-Task
generation	I-Task
bytenet2016	O
.	O
	
Their	O
success	O
on	O
sequence	O
data	O
in	O
particular	O
rivals	O
or	O
surpasses	O
that	O
of	O
previous	O
recurrent	B-Method
models	I-Method
bytenet2016	O
,	O
fbpaper	O
.	O
	
Convolutions	B-Method
provide	O
the	O
means	O
for	O
efficient	O
non	B-Task
-	I-Task
local	I-Task
referencing	I-Task
across	O
time	O
without	O
the	O
need	O
for	O
the	O
fully	B-Method
sequential	I-Method
processing	I-Method
of	I-Method
RNNs	I-Method
.	O
	
However	O
,	O
a	O
major	O
critique	O
of	O
such	O
models	O
is	O
their	O
computational	B-Metric
complexity	I-Metric
and	O
large	O
parameter	O
count	O
.	O
	
These	O
are	O
the	O
principal	O
concerns	O
addressed	O
within	O
this	O
work	O
:	O
inspired	O
by	O
the	O
efficiency	O
of	O
depthwise	B-Method
separable	I-Method
convolutions	I-Method
demonstrated	O
in	O
the	O
domain	O
of	O
vision	B-Task
,	O
in	O
particular	O
the	O
Xception	B-Method
architecture	I-Method
xception2016	O
and	O
MobileNets	B-Method
mobilenets2017	O
,	O
we	O
generalize	O
these	O
techniques	O
and	O
apply	O
them	O
to	O
the	O
language	B-Task
domain	I-Task
,	O
with	O
great	O
success	O
.	O
	
section	O
:	O
Our	O
contribution	O
	
We	O
present	O
a	O
new	O
convolutional	B-Method
sequence	I-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
architecture	I-Method
,	O
dubbed	O
SliceNet	B-Method
,	O
and	O
apply	O
it	O
to	O
machine	B-Task
translation	I-Task
tasks	O
,	O
achieving	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
.	O
	
Our	O
architecture	O
features	O
two	O
key	O
ideas	O
:	O
Inspired	O
by	O
the	O
Xception	B-Method
network	I-Method
,	O
our	O
model	O
is	O
a	O
stack	B-Method
of	I-Method
depthwise	I-Method
separable	I-Method
convolution	I-Method
layers	I-Method
with	O
residual	O
connections	O
.	O
	
Such	O
an	O
architecture	O
has	O
been	O
previously	O
shown	O
to	O
perform	O
well	O
for	O
image	B-Task
classification	I-Task
.	O
	
We	O
also	O
experimented	O
with	O
using	O
grouped	B-Method
convolutions	I-Method
(	O
or	O
"	O
sub	B-Method
-	I-Method
separable	I-Method
convolutions	I-Method
"	O
)	O
and	O
add	O
even	O
more	O
separation	O
with	O
our	O
new	O
super	B-Method
-	I-Method
separable	I-Method
convolutions	I-Method
.	O
	
We	O
do	O
away	O
with	O
filter	B-Method
dilation	I-Method
in	O
our	O
architecture	O
,	O
after	O
exploring	O
the	O
trade	O
-	O
off	O
between	O
filter	B-Method
dilation	I-Method
and	O
larger	O
convolution	O
windows	O
.	O
	
Filter	B-Method
dilation	I-Method
was	O
previously	O
a	O
key	O
component	O
of	O
successful	O
1D	B-Method
convolutional	I-Method
architectures	I-Method
for	O
sequence	B-Task
-	I-Task
to	I-Task
-	I-Task
sequence	I-Task
tasks	I-Task
,	O
such	O
as	O
ByteNet	B-Method
bytenet2016	O
and	O
WaveNet	B-Method
wavenet2016	O
,	O
but	O
we	O
obtain	O
better	O
results	O
without	O
dilation	B-Method
thanks	O
to	O
separability	B-Method
.	O
	
subsection	O
:	O
Separable	B-Method
convolutions	I-Method
and	O
grouped	B-Method
convolutions	I-Method
	
The	O
depthwise	B-Method
separable	I-Method
convolution	I-Method
operation	I-Method
can	O
be	O
understood	O
as	O
related	O
to	O
both	O
grouped	B-Method
convolutions	I-Method
and	O
the	O
"	O
inception	B-Method
modules	I-Method
"	O
used	O
by	O
the	O
Inception	B-Method
family	I-Method
of	I-Method
convolutional	I-Method
network	I-Method
architectures	I-Method
,	O
a	O
connection	O
explored	O
in	O
Xception	B-Method
xception2016	O
.	O
	
It	O
consists	O
of	O
a	O
depthwise	B-Method
convolution	I-Method
,	O
i.e.	O
a	O
spatial	B-Method
convolution	I-Method
performed	O
independently	O
over	O
every	O
channel	O
of	O
an	O
input	O
,	O
followed	O
by	O
a	O
pointwise	B-Method
convolution	I-Method
,	O
i.e.	O
a	O
regular	B-Method
convolution	I-Method
with	O
1x1	O
windows	O
,	O
projecting	O
the	O
channels	O
computed	O
by	O
the	O
depthwise	B-Method
convolution	I-Method
onto	O
a	O
new	O
channel	O
space	O
.	O
	
The	O
depthwise	B-Method
separable	I-Method
convolution	I-Method
operation	I-Method
should	O
not	O
be	O
confused	O
with	O
spatially	B-Method
separable	I-Method
convolutions	I-Method
,	O
which	O
are	O
also	O
often	O
called	O
“	O
separable	B-Method
convolutions	I-Method
”	O
in	O
the	O
image	B-Task
processing	I-Task
community	I-Task
.	O
	
Their	O
mathematical	O
formulation	O
is	O
as	O
follow	O
(	O
we	O
use	O
to	O
denote	O
the	O
element	O
-	O
wise	O
product	O
)	O
:	O
	
Thus	O
,	O
the	O
fundamental	O
idea	O
behind	O
depthwise	B-Method
separable	I-Method
convolutions	I-Method
is	O
to	O
replace	O
the	O
feature	B-Method
learning	I-Method
operated	O
by	O
regular	B-Method
convolutions	I-Method
over	O
a	O
joint	O
"	O
space	O
-	O
cross	O
-	O
channels	O
realm	O
"	O
into	O
two	O
simpler	O
steps	O
,	O
a	O
spatial	B-Method
feature	I-Method
learning	I-Method
step	I-Method
,	O
and	O
a	O
channel	B-Method
combination	I-Method
step	I-Method
.	O
	
This	O
is	O
a	O
powerful	O
simplification	O
under	O
the	O
oft	O
-	O
verified	O
assumption	O
that	O
the	O
2D	O
or	O
3D	O
inputs	O
that	O
convolutions	B-Method
operate	O
on	O
will	O
feature	O
both	O
fairly	O
independent	O
channels	O
and	O
highly	O
correlated	O
spatial	O
locations	O
.	O
	
A	O
deep	B-Method
neural	I-Method
network	I-Method
forms	O
a	O
chain	O
of	O
differentiable	B-Method
feature	I-Method
learning	I-Method
modules	I-Method
,	O
structured	O
as	O
a	O
discrete	O
set	O
of	O
units	O
,	O
each	O
trained	O
to	O
learn	O
a	O
particular	O
feature	O
.	O
	
These	O
units	O
are	O
subsequently	O
composed	O
and	O
combined	O
,	O
gradually	O
learning	O
higher	O
and	O
higher	O
levels	O
of	O
feature	O
abstraction	O
with	O
increasing	O
depth	O
.	O
	
Of	O
significance	O
is	O
the	O
availability	O
of	O
dedicated	O
feature	O
pathways	O
that	O
are	O
merged	O
together	O
later	O
in	O
the	O
network	O
;	O
this	O
is	O
one	O
property	O
enabled	O
by	O
depthwise	B-Method
separable	I-Method
convolutions	I-Method
,	O
which	O
define	O
independent	O
feature	O
pathways	O
that	O
are	O
later	O
merged	O
.	O
	
In	O
contrast	O
,	O
regular	B-Method
convolutional	I-Method
layers	I-Method
break	O
this	O
creed	O
by	O
learning	B-Method
filters	I-Method
that	O
must	O
simultaneously	O
perform	O
the	O
extraction	O
of	O
spatial	O
features	O
and	O
their	O
merger	O
into	O
channel	O
dimensions	O
;	O
an	O
inefficient	O
and	O
ineffective	O
use	O
of	O
parameters	O
.	O
	
Grouped	B-Method
convolutions	I-Method
(	O
or	O
"	O
sub	B-Method
-	I-Method
separable	I-Method
convolutions	I-Method
"	I-Method
)	O
are	O
an	O
intermediary	O
step	O
between	O
regular	B-Method
convolutions	I-Method
and	O
depthwise	B-Method
separable	I-Method
convolutions	I-Method
.	O
	
They	O
consist	O
in	O
splitting	O
the	O
channels	O
of	O
an	O
input	O
into	O
several	O
non	O
-	O
overlapping	O
segments	O
(	O
or	O
"	O
groups	O
"	O
)	O
,	O
performing	O
a	O
regular	B-Method
spatial	I-Method
convolution	I-Method
over	O
each	O
segment	O
independently	O
,	O
then	O
concatenating	O
the	O
resulting	O
feature	O
maps	O
along	O
the	O
channel	O
axis	O
.	O
	
Depthwise	B-Method
separable	I-Method
convolutions	I-Method
have	O
been	O
previously	O
shown	O
in	O
Xception	B-Method
xception2016	O
to	O
allow	O
for	O
image	B-Method
classification	I-Method
models	I-Method
that	O
outperform	O
similar	O
architectures	O
with	O
the	O
same	O
number	O
of	O
parameters	O
,	O
by	O
making	O
more	O
efficient	O
use	O
of	O
the	O
parameters	O
available	O
for	O
representation	B-Method
learning	I-Method
.	O
	
In	O
MobileNets	B-Method
mobilenets2017	O
,	O
depthwise	B-Method
separable	I-Method
convolutions	I-Method
allowed	O
to	O
create	O
very	O
small	O
image	B-Method
classification	I-Method
models	I-Method
(	O
e.g.	O
4.2	O
M	O
parameters	O
for	O
1.0	O
MobileNet	O
-	O
224	O
)	O
that	O
retained	O
much	O
of	O
the	O
capabilities	O
of	O
architectures	O
that	O
are	O
far	O
larger	O
	
(	O
e.g.	O
138	O
M	O
parameters	O
for	O
VGG16	O
)	O
,	O
again	O
,	O
by	O
making	O
more	O
efficient	O
use	O
of	O
parameters	O
.	O
	
The	O
theoretical	O
justifications	O
for	O
replacing	O
regular	B-Method
convolution	I-Method
with	O
depthwise	B-Method
separable	I-Method
convolution	I-Method
,	O
as	O
well	O
as	O
the	O
strong	O
gains	O
achieved	O
in	O
practice	O
by	O
such	O
architectures	O
,	O
are	O
a	O
significant	O
motivation	O
for	O
applying	O
them	O
to	O
1D	B-Method
sequence	I-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
models	I-Method
.	O
	
The	O
key	O
gains	O
from	O
separability	O
can	O
be	O
seen	O
when	O
comparing	O
the	O
number	O
of	O
parameters	O
(	O
which	O
in	O
this	O
case	O
corresponds	O
to	O
the	O
computational	B-Metric
cost	I-Metric
too	O
)	O
of	O
separable	B-Method
convolutions	I-Method
,	O
group	B-Method
convolutions	I-Method
,	O
and	O
regular	B-Method
convolutions	I-Method
.	O
	
Assume	O
we	O
have	O
channels	O
and	O
filters	O
(	O
often	O
or	O
more	O
)	O
and	O
a	O
receptive	O
field	O
of	O
size	O
(	O
often	O
but	O
we	O
will	O
use	O
upto	O
)	O
.	O
	
The	O
number	O
of	O
parameters	O
for	O
a	O
regular	B-Method
convolution	I-Method
,	O
separable	B-Method
convolution	I-Method
,	O
and	O
group	B-Method
convolution	I-Method
with	O
groups	O
is	O
:	O
	
subsection	O
:	O
Super	B-Method
-	I-Method
separable	I-Method
convolutions	I-Method
	
As	O
can	O
be	O
seen	O
above	O
,	O
the	O
size	O
(	O
and	O
cost	B-Metric
)	O
of	O
a	O
separable	B-Method
convolution	I-Method
with	I-Method
channels	I-Method
and	O
a	O
receptive	O
field	O
of	O
size	O
is	O
.	O
	
When	O
is	O
small	O
compared	O
to	O
(	O
as	O
is	O
usuallty	O
the	O
case	O
)	O
the	O
term	O
dominates	O
,	O
which	O
raises	O
the	O
question	O
how	O
it	O
could	O
be	O
reduced	O
.	O
	
We	O
use	O
the	O
idea	O
from	O
group	B-Method
convolutions	I-Method
and	O
the	O
recent	O
separable	B-Method
-	I-Method
LSTM	I-Method
paper	I-Method
to	O
further	O
reduce	O
this	O
size	O
by	O
factoring	O
the	O
final	O
convolution	O
,	O
and	O
we	O
call	O
the	O
result	O
a	O
super	B-Method
-	I-Method
separable	I-Method
convolution	I-Method
.	O
	
We	O
define	O
a	O
super	B-Method
-	I-Method
separable	I-Method
convolution	I-Method
(	O
noted	O
)	O
with	O
groups	O
as	O
follows	O
.	O
	
Applied	O
to	O
a	O
tensor	O
,	O
we	O
first	O
split	O
on	O
the	O
depth	O
dimension	O
into	O
groups	O
,	O
then	O
apply	O
a	O
separable	B-Method
convolution	I-Method
to	O
each	O
group	O
separately	O
,	O
and	O
then	O
concatenate	O
the	O
results	O
on	O
the	O
depth	O
dimension	O
.	O
	
where	O
is	O
split	O
on	O
the	O
depth	O
axis	O
and	O
for	O
are	O
the	O
parameters	O
of	O
each	O
separable	B-Method
convolution	I-Method
.	O
	
Since	O
each	O
is	O
of	O
size	O
and	O
each	O
is	O
of	O
size	O
,	O
the	O
final	O
size	O
of	O
a	O
super	B-Method
-	I-Method
separable	I-Method
convolution	I-Method
is	O
.	O
	
Parameter	O
counts	O
(	O
or	O
computational	O
budget	O
per	O
position	O
)	O
for	O
all	O
convolution	B-Method
types	I-Method
are	O
summarized	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Note	O
that	O
a	O
super	B-Method
-	I-Method
separable	I-Method
convolution	I-Method
does	O
n’t	O
allow	O
channels	O
in	O
separate	O
groups	O
to	O
exchange	O
information	O
.	O
	
To	O
avoid	O
making	O
a	O
bottleneck	O
of	O
this	O
kind	O
,	O
we	O
use	O
stack	B-Method
super	I-Method
-	I-Method
separable	I-Method
convolutions	I-Method
in	O
layer	B-Method
with	O
co	B-Method
-	I-Method
prime	I-Method
.	O
	
In	O
particular	O
,	O
in	O
our	O
experiments	O
we	O
always	O
alternate	O
and	O
.	O
	
subsection	O
:	O
Filter	B-Method
dilation	I-Method
and	O
convolution	B-Method
window	I-Method
size	I-Method
	
Filter	B-Method
dilation	I-Method
,	O
as	O
introduced	O
in	O
,	O
is	O
a	O
technique	O
for	O
aggregating	O
multiscale	O
information	O
across	O
considerably	O
larger	O
receptive	O
fields	O
in	O
convolution	O
operations	O
,	O
while	O
avoiding	O
an	O
explosion	O
in	O
parameter	O
count	O
for	O
the	O
convolution	B-Method
kernels	I-Method
.	O
	
It	O
has	O
been	O
presented	O
in	O
and	O
as	O
a	O
key	O
component	O
of	O
convolutional	B-Method
sequence	I-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
autoregressive	I-Method
architectures	I-Method
.	O
	
When	O
dilated	O
convolution	O
layers	O
are	O
stacked	O
such	O
that	O
consecutive	O
layers	O
’	O
dilation	O
values	O
have	O
common	O
divisors	O
,	O
an	O
issue	O
similar	O
to	O
the	O
checkerboard	O
artifacts	O
in	O
deconvolutions	B-Method
odena2016deconvolution	O
appears	O
.	O
	
Uneven	O
filter	O
coverage	O
results	O
in	O
dead	O
zones	O
where	O
filter	O
coverage	O
is	O
reduced	O
(	O
as	O
displayed	O
in	O
the	O
plaid	O
-	O
like	O
appearance	O
of	O
Figure	O
1	O
in	O
dilatedconv2015	O
)	O
.	O
	
Choosing	O
dilation	O
factors	O
that	O
are	O
co	O
-	O
prime	O
can	O
indeed	O
offer	O
some	O
relief	O
from	O
these	O
artifacts	O
,	O
however	O
,	O
it	O
would	O
be	O
preferable	O
to	O
do	O
away	O
with	O
the	O
necessity	O
for	O
dilation	O
entirely	O
.	O
	
The	O
purpose	O
of	O
filter	B-Method
dilation	I-Method
is	O
to	O
increase	O
the	O
receptive	O
field	O
of	O
the	O
convolution	B-Method
operation	I-Method
,	O
i.e.	O
the	O
spatial	O
extent	O
from	O
which	O
feature	O
information	O
can	O
be	O
gathered	O
,	O
at	O
a	O
reasonable	O
computational	B-Metric
cost	I-Metric
.	O
	
A	O
similar	O
effect	O
would	O
be	O
achieved	O
by	O
simply	O
using	O
larger	O
convolution	O
windows	O
.	O
	
Besides	O
,	O
the	O
use	O
of	O
larger	O
windows	O
would	O
avoid	O
an	O
important	O
shortcoming	O
of	O
filter	B-Method
dilation	I-Method
,	O
unequal	O
convolutional	O
coverage	O
of	O
the	O
input	O
space	O
.	O
	
Notably	O
,	O
the	O
use	O
of	O
depthwise	B-Method
separable	I-Method
convolutions	I-Method
in	O
our	O
network	O
in	O
place	O
of	O
regular	B-Method
convolutions	I-Method
makes	O
each	O
convolution	B-Method
operation	I-Method
significantly	O
cheaper	O
(	O
we	O
are	O
able	O
to	O
cut	O
the	O
number	O
of	O
non	O
-	O
embedding	O
model	O
parameters	O
by	O
half	O
)	O
,	O
thus	O
lifting	O
the	O
computational	O
and	O
memory	O
limitations	O
that	O
guided	O
the	O
development	O
of	O
filter	B-Method
dilation	I-Method
in	O
the	O
first	O
place	O
.	O
	
In	O
our	O
experiments	O
,	O
we	O
explore	O
the	O
trade	O
-	O
off	O
between	O
using	O
lower	O
dilation	B-Metric
rates	I-Metric
and	O
increasing	O
the	O
size	O
of	O
the	O
convolution	O
windows	O
for	O
our	O
depthwise	B-Method
separable	I-Method
convolution	I-Method
layers	I-Method
.	O
	
In	O
contrast	O
to	O
the	O
conclusions	O
drawn	O
in	O
WaveNet	B-Method
and	O
ByteNet	B-Method
,	O
we	O
find	O
that	O
the	O
computational	B-Metric
savings	I-Metric
brought	O
on	O
by	O
depthwise	B-Method
separable	I-Method
convolutions	I-Method
allow	O
us	O
to	O
do	O
away	O
with	O
dilation	O
entirely	O
.	O
	
In	O
fact	O
,	O
we	O
observe	O
no	O
benefits	O
of	O
dilations	B-Method
:	O
our	O
best	O
models	O
feature	O
larger	O
filters	B-Method
and	O
no	O
dilation	O
(	O
see	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
A	O
comparison	O
of	O
the	O
parameter	O
count	O
for	O
different	O
convolution	B-Method
operations	I-Method
is	O
found	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
SliceNet	B-Method
architecture	I-Method
	
Here	O
we	O
present	O
the	O
model	O
we	O
use	O
for	O
our	O
experiments	O
,	O
called	O
SliceNet	B-Method
in	O
reference	O
to	O
the	O
way	O
separable	B-Method
convolutions	I-Method
operate	O
on	O
channel	O
-	O
wise	O
slices	O
of	O
their	O
inputs	O
.	O
	
Our	O
model	O
follows	O
the	O
convolutional	B-Method
autoregressive	I-Method
structure	I-Method
introduced	O
by	O
ByteNet	B-Method
bytenet2016	O
,	O
WaveNet	B-Method
wavenet2016	O
and	O
PixelCNN	B-Method
pixelcnn2016	O
.	O
	
Inputs	O
and	O
outputs	O
are	O
embedded	O
into	O
the	O
same	O
feature	O
depth	O
,	O
encoded	O
by	O
two	O
separate	O
sub	B-Method
-	I-Method
networks	I-Method
and	O
concatenated	O
before	O
being	O
fed	O
into	O
a	O
decoder	B-Method
that	O
autoregressively	O
generates	O
each	O
element	O
of	O
the	O
output	O
.	O
	
At	O
each	O
step	O
,	O
the	O
autoregressive	B-Method
decoder	I-Method
produces	O
a	O
new	O
output	B-Method
prediction	I-Method
given	O
the	O
encoded	O
inputs	O
and	O
the	O
encoding	O
of	O
the	O
existing	O
predicted	O
outputs	O
.	O
	
The	O
encoders	B-Method
and	O
the	O
decoder	B-Method
(	O
described	O
in	O
Section	O
[	O
reference	O
]	O
)	O
are	O
constructed	O
from	O
stacks	O
of	O
convolutional	B-Method
modules	I-Method
(	O
described	O
in	O
Section	O
[	O
reference	O
]	O
)	O
and	O
attention	O
(	O
described	O
in	O
Section	O
[	O
reference	O
]	O
)	O
is	O
used	O
to	O
allow	O
the	O
decoder	O
to	O
get	O
information	O
from	O
the	O
encoder	O
.	O
	
subsection	O
:	O
Convolutional	B-Method
modules	I-Method
	
To	O
perform	O
local	B-Task
computation	I-Task
,	O
we	O
use	O
modules	B-Method
of	I-Method
convolutions	I-Method
with	O
ReLU	B-Method
non	I-Method
-	I-Method
linearities	I-Method
and	O
layer	B-Method
normalization	I-Method
.	O
	
A	O
module	B-Method
of	I-Method
convolutions	I-Method
gets	O
as	O
input	O
a	O
tensor	O
of	O
shape	O
[	O
sequence	O
length	O
,	O
feature	O
channels	O
]	O
and	O
returns	O
a	O
tensor	O
of	O
the	O
same	O
shape	O
.	O
	
Each	O
step	O
in	O
our	O
module	O
consist	O
of	O
three	O
components	O
:	O
a	O
activation	O
of	O
the	O
inputs	O
,	O
followed	O
by	O
a	O
depthwise	B-Method
separable	I-Method
convolution	I-Method
,	O
followed	O
by	O
layer	B-Method
normalization	I-Method
.	O
	
Layer	B-Method
normalization	I-Method
layernorm2016	O
acts	O
over	O
the	O
hidden	O
units	O
of	O
the	O
layer	O
below	O
,	O
computing	O
layer	O
-	O
wise	O
statistics	O
and	O
normalizing	O
accordingly	O
.	O
	
These	O
normalized	O
units	O
are	O
then	O
scaled	O
and	O
shifted	O
by	O
scalar	O
learned	O
parameters	O
and	O
respectively	O
,	O
producing	O
the	O
final	O
units	O
to	O
be	O
activated	O
by	O
a	O
non	B-Method
-	I-Method
linearity	I-Method
:	O
where	O
the	O
sum	O
are	O
taken	O
only	O
over	O
the	O
last	O
(	O
depth	O
)	O
dimension	O
of	O
,	O
and	O
and	O
are	O
learned	O
scalars	O
.	O
	
A	O
complete	O
convolution	B-Method
step	I-Method
is	O
therefore	O
defined	O
as	O
:	O
The	O
convolutional	B-Method
steps	I-Method
are	O
composed	O
into	O
modules	O
by	O
stacking	O
them	O
and	O
adding	O
residual	O
connections	O
as	O
depicted	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
We	O
use	O
stacks	O
of	O
four	O
convolutional	B-Method
steps	I-Method
with	O
two	O
skip	O
-	O
connections	O
between	O
the	O
stack	O
input	O
and	O
the	O
outputs	O
of	O
the	O
second	O
and	O
fourth	O
convolutional	O
steps	O
:	O
ConvModules	B-Method
are	O
used	O
in	O
stacks	O
in	O
our	O
module	O
,	O
the	O
output	O
of	O
the	O
last	O
feeding	O
into	O
the	O
next	O
.	O
	
We	O
denote	O
a	O
stack	O
with	O
modules	O
by	O
	
subsection	O
:	O
Attention	B-Method
modules	I-Method
	
For	O
attention	B-Task
,	O
we	O
use	O
a	O
simple	O
inner	B-Method
-	I-Method
product	I-Method
attention	I-Method
that	O
takes	O
as	O
input	O
two	O
tensors	O
:	O
of	O
shape	O
and	O
of	O
shape	O
.	O
	
The	O
attention	B-Method
mechanism	I-Method
computes	O
the	O
feature	O
vector	O
similarities	O
at	O
each	O
position	O
and	O
re	O
-	O
scales	O
according	O
to	O
the	O
depth	O
:	O
To	O
allow	O
the	O
attention	O
to	O
access	O
positional	O
information	O
,	O
we	O
add	O
a	O
signal	O
that	O
carries	O
it	O
.	O
	
We	O
call	O
this	O
signal	O
the	O
timing	O
,	O
it	O
is	O
a	O
tensor	O
of	O
any	O
shape	O
defined	O
by	O
concatenating	O
sine	O
and	O
cosine	O
functions	O
of	O
different	O
frequencies	O
calculated	O
upto	O
:	O
Our	O
full	O
attention	B-Method
mechanism	I-Method
consists	O
of	O
adding	O
the	O
timing	O
signal	O
to	O
the	O
targets	O
,	O
performing	O
two	O
convolutional	B-Method
steps	I-Method
,	O
and	O
then	O
attending	O
to	O
the	O
source	O
:	O
	
subsection	O
:	O
Autoregressive	B-Method
structure	I-Method
	
As	O
previously	O
discussed	O
,	O
the	O
outputs	O
of	O
our	O
model	O
are	O
generated	O
in	O
an	O
autoregressive	B-Method
manner	I-Method
.	O
	
Unlike	O
RNNs	B-Method
,	O
autoregressive	B-Method
sequence	I-Method
generation	I-Method
depends	O
not	O
only	O
on	O
the	O
previously	O
generated	O
output	O
,	O
but	O
potentially	O
all	O
previously	O
generated	O
outputs	O
.	O
	
This	O
notion	O
of	O
long	O
term	O
dependencies	O
has	O
proven	O
highly	O
effect	O
in	O
NMT	B-Task
before	O
.	O
	
By	O
using	O
attention	O
,	O
establishing	O
long	O
term	O
dependencies	O
has	O
been	O
shown	O
to	O
significantly	O
boost	O
task	O
performance	O
of	O
RNNs	B-Method
for	O
NMT	B-Task
.	O
	
Similarly	O
,	O
a	O
convolutional	B-Method
autoregressive	I-Method
generation	I-Method
scheme	I-Method
offer	O
large	O
receptive	O
fields	O
over	O
the	O
inputs	O
and	O
past	O
outputs	O
,	O
capable	O
of	O
establishing	O
these	O
long	O
term	O
dependencies	O
.	O
	
Below	O
we	O
detail	O
the	O
structure	O
of	O
the	O
InputEncoder	B-Method
,	O
IOMixer	B-Method
and	I-Method
Decoder	I-Method
.	O
	
The	O
OutputEmbedding	B-Method
simply	O
performs	O
a	O
learning	B-Method
-	I-Method
embedding	I-Method
look	I-Method
-	I-Method
up	I-Method
.	O
	
We	O
denote	O
the	O
concatenation	O
of	O
tensors	O
and	O
along	O
the	O
dimension	O
as	O
.	O
	
section	O
:	O
Related	O
Work	O
	
Machine	B-Task
translation	I-Task
using	O
deep	B-Method
neural	I-Method
networks	I-Method
achieved	O
great	O
success	O
with	O
sequence	B-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
models	I-Method
that	O
used	O
recurrent	B-Method
neural	I-Method
networks	I-Method
(	O
RNNs	B-Method
)	O
with	O
long	B-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
(	I-Method
LSTM	I-Method
,	I-Method
)	I-Method
cells	I-Method
.	O
	
The	O
basic	O
sequence	B-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
architecture	I-Method
is	O
composed	O
of	O
an	O
RNN	B-Method
encoder	I-Method
which	O
reads	O
the	O
source	O
sentence	O
one	O
token	O
at	O
a	O
time	O
and	O
transforms	O
it	O
into	O
a	O
fixed	O
-	O
sized	O
state	O
vector	O
.	O
	
This	O
is	O
followed	O
by	O
an	O
RNN	B-Method
decoder	I-Method
,	O
which	O
generates	O
the	O
target	O
sentence	O
,	O
one	O
token	O
at	O
a	O
time	O
,	O
from	O
the	O
state	O
vector	O
.	O
	
While	O
a	O
pure	O
sequence	B-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
recurrent	I-Method
neural	I-Method
network	I-Method
can	O
already	O
obtain	O
good	O
translation	B-Task
results	O
,	O
it	O
suffers	O
from	O
the	O
fact	O
that	O
the	O
whole	O
input	O
sentence	O
needs	O
to	O
be	O
encoded	O
into	O
a	O
single	O
fixed	O
-	O
size	O
vector	O
.	O
	
This	O
clearly	O
manifests	O
itself	O
in	O
the	O
degradation	O
of	O
translation	B-Metric
quality	I-Metric
on	O
longer	O
sentences	O
and	O
was	O
overcome	O
in	O
by	O
using	O
a	O
neural	B-Method
model	I-Method
of	I-Method
attention	I-Method
.	O
	
We	O
use	O
a	O
simplified	O
version	O
of	O
this	O
neural	B-Method
attention	I-Method
mechanism	I-Method
in	O
SliceNet	B-Method
,	O
as	O
introduced	O
above	O
.	O
	
Convolutional	B-Method
architectures	I-Method
have	O
been	O
used	O
to	O
obtain	O
good	O
results	O
in	O
word	O
-	O
level	O
neural	O
machine	B-Task
translation	I-Task
starting	O
from	O
and	O
later	O
in	O
.	O
	
These	O
early	O
models	O
used	O
a	O
standard	O
RNN	B-Method
on	O
top	O
of	O
the	O
convolution	B-Method
to	O
generate	O
the	O
output	O
.	O
	
The	O
state	O
of	O
this	O
RNN	B-Method
has	O
a	O
fixed	O
size	O
,	O
and	O
in	O
the	O
first	O
one	O
the	O
sentence	B-Method
representation	I-Method
generated	O
by	O
the	O
convolutional	B-Method
network	I-Method
is	O
also	O
a	O
fixed	O
-	O
size	O
vector	O
,	O
which	O
creates	O
a	O
bottleneck	O
and	O
hurts	O
performance	O
,	O
especially	O
on	O
longer	O
sentences	O
,	O
similarly	O
to	O
the	O
limitations	O
of	O
RNN	B-Method
sequence	I-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
models	I-Method
without	O
attention	B-Method
discussed	O
above	O
.	O
	
Fully	O
convolutional	O
neural	O
machine	B-Task
translation	I-Task
without	O
this	O
bottleneck	O
was	O
first	O
achieved	O
in	O
and	O
.	O
	
The	O
model	O
in	O
(	O
Extended	B-Method
Neural	I-Method
GPU	I-Method
)	O
used	O
a	O
recurrent	B-Method
stack	I-Method
of	I-Method
gated	I-Method
convolutional	I-Method
layers	I-Method
,	O
while	O
the	O
model	O
in	O
(	O
ByteNet	B-Method
)	O
did	O
away	O
with	O
recursion	B-Method
and	O
used	O
left	B-Method
-	I-Method
padded	I-Method
convolutions	I-Method
in	O
the	O
decoder	B-Method
.	O
	
This	O
idea	O
,	O
introduced	O
in	O
WaveNet	B-Method
,	O
significantly	O
improves	O
efficiency	O
of	O
the	O
model	O
.	O
	
The	O
same	O
technique	O
is	O
used	O
in	O
SliceNet	B-Method
as	O
well	O
,	O
and	O
it	O
has	O
been	O
used	O
in	O
a	O
number	O
of	O
neural	B-Method
translation	I-Method
models	I-Method
recently	O
,	O
most	O
notably	O
in	O
where	O
it	O
is	O
combined	O
with	O
an	O
attention	B-Method
mechanism	I-Method
in	O
a	O
way	O
similar	O
to	O
SliceNet	B-Method
.	O
	
Depthwise	B-Method
separable	I-Method
convolutions	I-Method
were	O
first	O
studied	O
by	O
Sifre	O
during	O
a	O
2013	O
internship	O
at	O
Google	O
Brain	O
,	O
and	O
were	O
first	O
introduced	O
in	O
an	O
ICLR	O
2014	O
presentation	O
.	O
	
In	O
2016	O
,	O
they	O
were	O
demonstrated	O
to	O
yield	O
strong	O
results	O
on	O
large	B-Task
-	I-Task
scale	I-Task
image	I-Task
classification	I-Task
in	O
Xception	B-Method
,	O
and	O
in	O
2017	O
they	O
were	O
shown	O
to	O
lead	O
to	O
small	O
and	O
parameter	O
-	O
efficient	O
image	B-Method
classification	I-Method
models	I-Method
in	O
MobileNets	B-Method
.	O
	
section	O
:	O
Experiments	O
	
We	O
design	O
our	O
experiments	O
with	O
the	O
goal	O
to	O
answer	O
two	O
key	O
questions	O
:	O
What	O
is	O
the	O
performance	O
impact	O
of	O
replacing	B-Method
convolutions	I-Method
in	O
a	O
ByteNet	B-Method
-	I-Method
like	I-Method
model	I-Method
with	O
depthwise	B-Method
separable	I-Method
convolutions	I-Method
?	O
	
What	O
is	O
the	O
performance	O
trade	O
-	O
off	O
of	O
reducing	O
dilation	B-Task
while	O
correspondingly	O
increasing	O
convolution	O
window	O
size	O
?	O
	
In	O
addition	O
,	O
we	O
make	O
two	O
auxiliary	O
experiments	O
:	O
	
One	O
experiment	O
to	O
test	O
the	O
performance	O
of	O
an	O
intermediate	B-Method
separability	I-Method
point	O
in	O
-	O
between	O
regular	B-Method
convolutions	I-Method
and	O
full	B-Method
depthwise	I-Method
separability	I-Method
:	O
we	O
replace	O
depthwise	B-Method
separable	I-Method
convolutions	I-Method
with	O
grouped	B-Method
convolutions	I-Method
(	O
sub	B-Method
-	I-Method
separable	I-Method
convolutions	I-Method
)	O
with	O
groups	O
of	O
size	O
16	O
.	O
	
One	O
experiment	O
to	O
test	O
the	O
performance	O
impact	O
of	O
our	O
newly	O
-	O
introduced	O
super	B-Method
-	I-Method
separable	I-Method
convolutions	I-Method
compared	O
to	O
depthwise	B-Method
separable	I-Method
convolutions	I-Method
.	O
	
We	O
evaluate	O
all	O
models	O
on	O
the	O
WMT	B-Task
English	I-Task
to	I-Task
German	I-Task
translation	I-Task
task	I-Task
and	O
use	O
newstest2013	O
evaluation	O
set	O
for	O
this	O
purpose	O
.	O
	
For	O
two	O
best	O
large	O
models	O
,	O
we	O
also	O
provide	O
results	O
on	O
the	O
standard	O
test	O
set	O
,	O
newstest2014	O
,	O
to	O
compare	O
with	O
other	O
works	O
.	O
	
For	O
tokenization	B-Task
,	O
we	O
use	O
subword	O
units	O
,	O
and	O
follow	O
the	O
same	O
tokenization	B-Method
process	I-Method
as	O
Sennrich	B-Method
.	O
	
All	O
of	O
our	O
experiments	O
are	O
implemented	O
using	O
the	O
TensorFlow	B-Method
framework	I-Method
.	O
	
A	O
comparison	O
of	O
our	O
different	O
models	O
in	O
terms	O
of	O
parameter	B-Metric
count	I-Metric
and	O
Negative	B-Metric
Log	I-Metric
Perplexity	I-Metric
as	O
well	O
as	O
per	B-Metric
-	I-Metric
token	I-Metric
Accuracy	I-Metric
on	O
our	O
task	O
are	O
provided	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
The	O
parameter	O
count	O
(	O
and	O
computation	B-Metric
cost	I-Metric
)	O
of	O
the	O
different	O
types	O
of	O
convolution	B-Method
operations	I-Method
used	O
was	O
already	O
presented	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Our	O
experimental	O
results	O
allow	O
us	O
to	O
draw	O
the	O
following	O
conclusions	O
:	O
Depthwise	B-Method
separable	I-Method
convolutions	I-Method
are	O
strictly	O
superior	O
to	O
regular	B-Method
convolutions	I-Method
in	O
a	O
ByteNet	B-Method
-	I-Method
like	I-Method
architecture	I-Method
,	O
resulting	O
in	O
models	O
that	O
are	O
more	O
accurate	O
while	O
requiring	O
fewer	O
parameters	O
and	O
being	O
computationally	O
cheaper	O
to	O
train	O
and	O
run	O
.	O
	
Using	O
sub	B-Method
-	I-Method
separable	I-Method
convolutions	I-Method
with	O
groups	O
of	O
size	O
16	O
instead	O
of	O
full	B-Method
depthwise	I-Method
separable	I-Method
convolutions	I-Method
results	O
in	O
a	O
performance	O
dip	O
,	O
which	O
may	O
indicate	O
that	O
higher	O
separability	O
(	O
i.e.	O
groups	O
as	O
small	O
as	O
possible	O
,	O
tending	O
to	O
full	B-Method
depthwise	I-Method
separable	I-Method
convolutions	I-Method
)	O
is	O
preferable	O
in	O
this	O
setup	O
,	O
this	O
further	O
confirming	O
the	O
advantages	O
of	O
depthwise	B-Method
separable	I-Method
convolutions	I-Method
.	O
	
The	O
need	O
for	O
dilation	B-Task
can	O
be	O
completely	O
removed	O
by	O
using	O
correspondingly	O
larger	O
convolution	O
windows	O
,	O
which	O
is	O
made	O
computationally	O
tractable	O
by	O
the	O
use	O
of	O
depthwise	B-Method
separable	I-Method
convolutions	I-Method
.	O
	
The	O
newly	O
-	O
introduced	O
super	B-Method
-	I-Method
separable	I-Method
convolution	I-Method
operation	I-Method
seems	O
to	O
offer	O
an	O
incremental	O
performance	O
improvement	O
.	O
	
Finally	O
,	O
we	O
run	O
two	O
larger	O
models	O
with	O
a	O
design	O
based	O
on	O
the	O
conclusions	O
drawn	O
from	O
our	O
first	O
round	O
of	O
experiments	O
:	O
a	O
SliceNet	B-Method
model	I-Method
which	O
uses	O
depthwise	B-Method
separable	I-Method
convolutions	I-Method
and	O
a	O
SliceNet	B-Method
model	I-Method
which	O
uses	O
super	B-Method
-	I-Method
separable	I-Method
convolutions	I-Method
,	O
with	O
significantly	O
higher	O
feature	O
depth	O
in	O
both	O
cases	O
.	O
	
We	O
achieve	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
,	O
as	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
,	O
where	O
we	O
also	O
include	O
previously	O
reported	O
results	O
for	O
comparison	O
.	O
	
For	O
getting	O
the	O
BLEU	B-Metric
,	O
we	O
used	O
a	O
beam	B-Method
-	I-Method
search	I-Method
decoder	I-Method
with	O
a	O
beam	O
size	O
of	O
and	O
a	O
length	O
penalty	O
tuned	O
on	O
the	O
evaluation	O
set	O
(	O
newstest2013	O
)	O
.	O
	
subsection	O
:	O
Conclusions	O
	
In	O
this	O
work	O
,	O
we	O
introduced	O
a	O
new	O
convolutional	B-Method
architecture	I-Method
for	O
sequence	B-Task
-	I-Task
to	I-Task
-	I-Task
sequence	I-Task
tasks	I-Task
,	O
called	O
SliceNet	B-Method
,	O
based	O
on	O
the	O
use	O
of	O
depthwise	B-Method
separable	I-Method
convolutions	I-Method
.	O
	
We	O
showed	O
how	O
this	O
architecture	O
achieves	O
results	O
beating	O
not	O
only	O
ByteNet	B-Method
but	O
also	O
the	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
,	O
while	O
using	O
over	O
two	O
times	O
less	O
(	O
non	O
-	O
embedding	O
)	O
parameters	O
and	O
floating	O
point	O
operations	O
than	O
the	O
ByteNet	B-Method
architecture	I-Method
.	O
	
Additionally	O
,	O
we	O
have	O
shown	O
that	O
filter	B-Method
dilation	I-Method
,	O
previously	O
thought	O
to	O
be	O
a	O
key	O
component	O
of	O
successful	O
convolutional	B-Method
sequence	I-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
architectures	I-Method
,	O
was	O
not	O
a	O
requirement	O
.	O
	
The	O
use	O
of	O
depthwise	B-Method
separable	I-Method
convolutions	I-Method
makes	O
much	O
larger	O
convolution	O
window	O
sizes	O
possible	O
,	O
and	O
we	O
found	O
that	O
we	O
could	O
achieve	O
the	O
best	O
results	O
by	O
using	O
larger	O
windows	O
instead	O
of	O
dilated	B-Method
filters	I-Method
.	O
	
We	O
have	O
also	O
introduced	O
a	O
new	O
type	O
of	O
depthwise	B-Method
separable	I-Method
convolution	I-Method
,	O
the	O
super	B-Method
-	I-Method
separable	I-Method
convolution	I-Method
,	O
which	O
shows	O
incremental	O
performance	O
improvements	O
over	O
depthwise	B-Method
separable	I-Method
convolutions	I-Method
.	O
	
Our	O
work	O
is	O
one	O
more	O
point	O
on	O
a	O
significant	O
trendline	O
started	O
with	O
Xception	B-Method
and	O
MobileNets	B-Method
,	O
that	O
indicates	O
that	O
in	O
any	O
convolutional	B-Method
model	I-Method
,	O
whether	O
for	O
1D	O
or	O
2D	O
data	O
,	O
it	O
is	O
possible	O
to	O
replace	O
convolutions	B-Method
with	O
depthwise	B-Method
separable	I-Method
convolutions	I-Method
and	O
obtain	O
a	O
model	O
that	O
is	O
simultaneously	O
cheaper	O
to	O
run	O
,	O
smaller	O
,	O
and	O
performs	O
a	O
few	O
percentage	O
points	O
better	O
.	O
	
This	O
trend	O
is	O
backed	O
by	O
both	O
solid	O
theoretical	O
foundations	O
and	O
strong	O
experimental	O
results	O
.	O
	
We	O
expect	O
our	O
current	O
work	O
to	O
play	O
a	O
significant	O
role	O
in	O
affirming	O
and	O
accelerating	O
this	O
trend	O
,	O
and	O
we	O
hope	O
to	O
see	O
depthwise	B-Method
separable	I-Method
convolutions	I-Method
replace	O
regular	B-Method
convolutions	I-Method
for	O
an	O
increasing	O
number	O
of	O
use	O
cases	O
in	O
the	O
future	O
.	O
	
bibliography	O
:	O
References	O
	
Inferring	B-Task
hybrid	I-Task
transportation	I-Task
modes	I-Task
from	O
sparse	B-Material
GPS	I-Material
data	I-Material
using	O
a	O
moving	B-Method
window	I-Method
SVM	I-Method
classification	I-Method
0198	O
-	O
9715	O
/	O
$	O
see	O
front	O
matter	O
2012	O
	
Elsevier	O
Ltd.	O
A	O
http:	O
//	O
dx.doi.org	O
/	O
10.1016	O
/	O
j.compenvurbsys.2012.06.00	O
⇑	O
Corresponding	O
author	O
.	O
	
Tel	O
.	O
:	O
	
+	O
44	O
788	O
983	O
1988	O
.	O
	
E	O
-	O
mail	O
addresses	O
:	O
a.bolbol@ucl.ac.uk	O
(	O
A.	O
Bolbol	O
)	O
,	O
	
ta	O
i.tsapakis@ucl.ac.uk	O
(	O
I.	O
Tsapakis	O
)	O
,	O
	
j.haworth@ucl.ac.uk	O
1	O
Tel	O
.	O
:	O
	
+	O
44	O
	
781	O
56	O
Contents	O
lists	O
available	O
at	O
SciVerse	O
ScienceDirect	O
Computers	O
,	O
Environment	O
and	O
Urban	B-Task
Systems	I-Task
journal	O
homepage	O
:	O
	
www.elsevier	O
.com	O
/	O
locate	O
/	O
compenvurbsys	O
Inferring	B-Task
hybrid	I-Task
transportation	I-Task
modes	I-Task
from	O
sparse	B-Material
GPS	I-Material
data	I-Material
using	O
a	O
moving	B-Method
window	I-Method
SVM	I-Method
classification	I-Method
Adel	O
Bolbol	O
⇑	O
,	O
Tao	O
Cheng	O
1	O
,	O
Ioannis	O
Tsapakis	O
1	O
,	O
James	O
Haworth	O
2	O
Civil	O
,	O
Environmental	O
and	O
Geomatic	O
Engineering	O
,	O
University	O
College	O
London	O
,	O
United	O
Kingdom	O
	
a	O
r	O
	
t	O
	
i	O
	
c	O
	
l	O
e	O
	
i	O
	
n	O
	
f	O
o	O
	
a	O
b	O
s	O
	
t	O
r	O
a	O
c	O
t	O
Article	O
history	O
:	O
	
Available	O
online	O
12	O
July	O
2012	O
	
Keywords	O
:	O
	
Transportation	B-Method
mode	I-Method
Classification	I-Method
Variable	I-Method
selection	O
SVM	B-Method
Travel	I-Method
behaviour	I-Method
0198	O
-	O
	
9715	O
/	O
$	O
-	O
see	O
front	O
matter	O
2012	O
	
Elsevier	O
Ltd.	O
A	O
http:	O
//	O
dx.doi.org	O
/	O
10.1016	O
/	O
j.compenvurbsys.2012.06.00	O
⇑	O
Corresponding	O
author	O
.	O
	
Tel	O
.	O
:	O
	
+	O
44	O
788	O
983	O
1988	O
.	O
	
E	O
-	O
mail	O
addresses	O
:	O
a.bolbol@ucl.ac.uk	O
(	O
A.	O
Bolbol	O
)	O
,	O
	
ta	O
i.tsapakis@ucl.ac.uk	O
(	O
I.	O
Tsapakis	O
)	O
,	O
	
j.haworth@ucl.ac.uk	O
1	O
Tel	O
.	O
:	O
	
+	O
44	O
781	O
560	O
1230	O
.	O
	
2	O
	
Tel	O
.	O
:	O
	
+	O
44	O
781	O
607	O
6958	O
.	O
	
Understanding	B-Task
travel	I-Task
behaviour	I-Task
and	I-Task
travel	I-Task
demand	I-Task
is	O
of	O
constant	O
importance	O
to	O
transportation	B-Task
communities	I-Task
and	O
agencies	O
in	O
every	O
country	O
.	O
	
Nowadays	O
,	O
attempts	O
have	O
been	O
made	O
to	O
automatically	O
infer	O
transportation	B-Task
modes	I-Task
from	O
positional	O
data	O
,	O
such	O
as	O
the	O
data	O
collected	O
by	O
using	O
GPS	B-Method
devices	I-Method
so	O
that	O
the	O
cost	O
in	O
time	O
and	O
budget	O
of	O
conventional	O
travel	B-Task
diary	I-Task
survey	I-Task
could	O
be	O
significantly	O
reduced	O
.	O
	
Some	O
limitations	O
,	O
however	O
,	O
exist	O
in	O
the	O
literature	O
,	O
in	O
aspects	O
of	O
data	O
collection	O
(	O
sample	O
size	O
selected	O
,	O
duration	O
of	O
study	O
,	O
granularity	O
of	O
data	O
)	O
,	O
selection	O
of	O
variables	O
(	O
or	O
combination	O
of	O
variables	O
)	O
,	O
and	O
method	O
of	O
inference	B-Task
(	O
the	O
number	O
of	O
transportation	O
modes	O
to	O
be	O
used	O
in	O
the	O
learning	B-Task
)	O
.	O
	
This	O
paper	O
therefore	O
,	O
attempts	O
to	O
fully	O
understand	O
these	O
aspects	O
in	O
the	O
process	O
of	O
inference	B-Task
.	O
	
We	O
aim	O
to	O
solve	O
a	O
classification	B-Task
problem	I-Task
of	O
GPS	B-Material
data	I-Material
into	O
different	O
transportation	O
modes	O
(	O
car	O
,	O
walk	O
,	O
cycle	O
,	O
underground	O
,	O
train	O
and	O
bus	O
)	O
.	O
	
We	O
first	O
study	O
the	O
variables	O
that	O
could	O
contribute	O
positively	O
to	O
this	O
classification	B-Task
,	O
and	O
statistically	O
quantify	O
their	O
discriminatory	B-Metric
power	I-Metric
.	O
	
We	O
then	O
introduce	O
a	O
novel	O
approach	O
to	O
carry	O
out	O
this	O
inference	O
using	O
a	O
framework	O
based	O
on	O
Support	B-Method
Vector	I-Method
Machines	I-Method
(	O
SVMs	B-Method
)	O
classification	O
.	O
	
The	O
framework	O
was	O
tested	O
using	O
coarse	O
-	O
grained	O
GPS	B-Material
data	I-Material
,	O
which	O
has	O
been	O
avoided	O
in	O
previous	O
studies	O
,	O
achieving	O
a	O
promising	O
accuracy	B-Metric
of	O
88	O
%	O
with	O
a	O
Kappa	B-Metric
statistic	I-Metric
reflecting	O
almost	O
perfect	O
agreement	O
.	O
	
2012	O
	
Elsevier	O
Ltd.	O
All	O
rights	O
reserved	O
.	O
	
1	O
.	O
	
Introduction	O
Understanding	B-Task
travel	I-Task
behaviour	I-Task
is	O
important	O
for	O
many	O
applications	O
such	O
as	O
studying	B-Task
tourist	I-Task
activity	I-Task
(	O
Edwards	O
,	O
Griffin	O
,	O
Hayllar	O
,	O
Dickson	O
,	O
&	O
Schweinsberg	O
,	O
2009	O
)	O
or	O
the	O
impact	O
of	O
a	O
strike	O
on	O
transportation	B-Task
systems	I-Task
(	O
Tsapakis	O
et	O
al	O
.	O
,	O
in	O
press	O
)	O
.	O
	
To	O
understand	O
travel	B-Task
behaviour	I-Task
,	O
some	O
standard	O
data	B-Method
collection	I-Method
practices	I-Method
have	O
been	O
in	O
place	O
in	O
order	O
to	O
collect	O
travel	O
data	O
.	O
	
Among	O
these	O
practices	O
are	O
GPS	B-Method
-	I-Method
based	I-Method
travel	I-Method
surveys	I-Method
,	O
where	O
participants	O
carry	O
a	O
GPS	O
device	O
for	O
a	O
certain	O
duration	O
of	O
time	O
and	O
following	O
this	O
up	O
by	O
a	O
prompt	B-Method
recall	I-Method
survey	I-Method
to	O
report	O
trip	O
information	O
,	O
such	O
as	O
the	O
transportation	O
modes	O
they	O
used	O
in	O
every	O
trip	O
(	O
e.g.	O
cycle	O
,	O
walk	O
,	O
bus	O
and	O
so	O
forth	O
)	O
(	O
Stopher	O
,	O
2008	O
)	O
.	O
	
Yet	O
,	O
many	O
studies	O
have	O
reported	O
high	O
underreporting	B-Metric
rates	I-Metric
due	O
to	O
the	O
participants	O
’	O
burden	O
to	O
fill	O
in	O
daily	O
details	O
of	O
their	O
activities	O
(	O
Bricka	O
&	O
Bhat	O
,	O
2006	O
)	O
.	O
	
As	O
a	O
result	O
,	O
research	O
has	O
emerged	O
in	O
the	O
previous	O
decade	O
attempting	O
to	O
infer	O
the	O
transportation	B-Task
mode	I-Task
from	O
GPS	B-Material
data	I-Material
.	O
	
This	O
inference	O
could	O
largely	O
replace	O
or	O
complete	O
a	O
lot	O
of	O
the	O
feedback	O
required	O
by	O
users	O
when	O
labelling	O
and	O
tagging	B-Task
travel	I-Task
diaries	I-Task
.	O
	
Studies	O
aiming	O
at	O
inferring	O
the	O
transportation	B-Task
mode	I-Task
could	O
be	O
ll	O
rights	O
reserved	O
.	O
	
1	O
o.cheng@ucl.ac.uk	O
(	O
T.	O
Cheng	O
)	O
,	O
(	O
J.	O
Haworth	O
)	O
.	O
divided	O
into	O
procedural	B-Method
and	O
Machine	B-Method
Learning	I-Method
(	I-Method
ML	I-Method
)	I-Method
approaches	I-Method
.	O
	
Procedural	B-Method
approaches	I-Method
attempt	O
mainly	O
to	O
make	O
inferences	O
based	O
on	O
logical	O
assumptions	O
,	O
such	O
as	O
how	O
a	O
typical	O
person	O
would	O
travel	O
(	O
Stopher	O
,	O
Clifford	O
,	O
Zhang	O
,	O
&	O
FitzGerald	O
,	O
2008a	O
)	O
.	O
	
Other	O
assumptions	O
include	O
the	O
surrounding	O
environment	O
,	O
such	O
as	O
the	O
nearest	O
transportation	O
networks	O
(	O
Chung	O
&	O
Shalaby	O
,	O
2005	O
)	O
,	O
or	O
the	O
temporal	O
logic	O
assumptions	O
of	O
activities	O
,	O
such	O
as	O
people	O
are	O
more	O
likely	O
to	O
have	O
no	O
activity	O
after	O
mid	O
-	O
night	O
(	O
Liao	O
,	O
Fox	O
,	O
&	O
Kautz	O
,	O
2007	O
)	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
ML	B-Method
approaches	I-Method
attempt	O
to	O
do	O
the	O
inference	B-Task
based	O
on	O
learning	O
from	O
existing	O
data	O
,	O
possibly	O
combined	O
with	O
similar	O
logical	O
assumptions	O
.	O
	
Examples	O
of	O
these	O
studies	O
use	O
Decision	B-Method
Trees	I-Method
(	O
Manzoni	O
,	O
Maniloff	O
,	O
Kloeckl	O
,	O
&	O
Ratti	O
,	O
2011	O
;	O
Reddy	O
et	O
al	O
.	O
,	O
2010	O
;	O
Zheng	O
,	O
Chen	O
,	O
Li	O
,	O
Xie	O
,	O
&	O
Ma	O
,	O
2010	O
)	O
,	O
Bayesian	B-Method
Networks	I-Method
(	O
Stenneth	O
,	O
Wolfson	O
,	O
Yu	O
,	O
&	O
Xu	O
,	O
2011	O
)	O
,	O
Fuzzy	B-Method
Logic	I-Method
(	O
Schüssler	O
&	O
Axhausen	O
,	O
2009	O
)	O
,	O
Hierarchical	B-Method
Conditional	I-Method
Random	I-Method
Fields	I-Method
(	O
Liao	O
et	O
al	O
.	O
,	O
2007	O
)	O
,	O
and	O
Support	B-Method
Vector	I-Method
Machines	I-Method
(	O
SVMs	B-Method
)	O
(	O
Zheng	O
,	O
Liu	O
,	O
Wang	O
,	O
&	O
Xie	O
,	O
2008	O
)	O
.	O
	
These	O
ML	B-Method
approaches	I-Method
could	O
be	O
broken	O
down	O
into	O
three	O
aspects	O
(	O
or	O
phases	O
)	O
:	O
data	B-Method
collection	I-Method
(	O
sample	O
size	O
selected	O
,	O
duration	O
of	O
study	O
and	O
granularity	O
of	O
data	O
)	O
,	O
selection	B-Method
of	I-Method
variables	I-Method
for	O
inference	B-Task
(	O
or	O
combination	O
of	O
variables	O
)	O
,	O
and	O
method	B-Method
of	I-Method
inference	I-Method
(	O
the	O
details	O
of	O
the	O
learning	B-Method
algorithm	I-Method
used	O
)	O
.	O
	
Most	O
of	O
the	O
previous	O
ML	B-Method
attempts	I-Method
possess	O
several	O
limitations	O
in	O
each	O
of	O
these	O
three	O
previously	O
mentioned	O
aspects	O
.	O
	
Accordingly	O
,	O
these	O
limitations	O
could	O
be	O
arranged	O
into	O
three	O
categories	O
:	O
data	B-Method
collection	I-Method
,	O
variable	B-Method
selection	I-Method
,	O
and	O
methodrelated	B-Method
issues	I-Method
.	O
	
First	O
,	O
some	O
data	B-Method
collection	I-Method
-	O
related	O
processes	O
and	O
properties	O
limitations	O
exist	O
in	O
literature	O
,	O
such	O
as	O
the	O
selected	O
sample	O
size	O
,	O
duration	O
of	O
study	O
,	O
granularity	O
of	O
the	O
data	O
,	O
the	O
data	O
collection	O
methods	O
,	O
and	O
the	O
validation	B-Method
techniques	I-Method
used	O
.	O
	
Second	O
,	O
there	O
are	O
several	O
issues	O
regarding	O
the	O
variable	B-Task
selection	I-Task
to	O
be	O
used	O
for	O
the	O
inference	B-Task
.	O
	
Different	O
studies	O
use	O
different	O
variables	O
(	O
or	O
combination	O
of	O
variables	O
)	O
,	O
such	O
as	O
speed	O
,	O
acceleration	O
,	O
maximum	O
or	O
medians	O
speed	O
,	O
and	O
acceleration	O
and	O
length	O
between	O
GPS	O
fixes	O
.	O
	
However	O
,	O
none	O
of	O
the	O
studies	O
,	O
to	O
the	O
best	O
knowledge	O
of	O
the	O
authors	O
,	O
have	O
based	O
their	O
variable	B-Method
selection	I-Method
process	I-Method
on	O
statistical	O
evidence	O
.	O
	
Third	O
,	O
the	O
method	O
-	O
related	O
issues	O
include	O
the	O
usage	O
of	O
a	O
limited	O
number	O
of	O
transportation	O
modes	O
in	O
the	O
learning	B-Task
,	O
the	O
high	O
dependence	O
on	O
segmentation	O
into	O
transportation	O
modes	O
,	O
and	O
high	O
reliance	O
on	O
temporal	O
information	O
.	O
	
Moreover	O
,	O
some	O
method	O
-	O
related	O
assumptions	O
are	O
often	O
made	O
in	O
previous	O
work	O
such	O
as	O
that	O
certain	O
modes	O
can	O
not	O
follow	O
each	O
other	O
in	O
a	O
GPS	O
sequence	O
and	O
that	O
every	O
two	O
GPS	O
consecutive	O
fixes	O
are	O
analysed	O
individually	O
ignoring	O
the	O
track	O
as	O
a	O
whole	O
.	O
	
Therefore	O
,	O
in	O
this	O
work	O
we	O
attempt	O
to	O
fully	O
understand	O
and	O
account	O
for	O
these	O
three	O
aspects	O
in	O
the	O
process	O
of	O
inference	B-Task
.	O
	
We	O
aim	O
to	O
solve	O
a	O
classification	B-Task
problem	I-Task
of	O
GPS	B-Material
data	I-Material
into	O
different	O
transportation	O
modes	O
(	O
car	O
,	O
walk	O
,	O
cycle	O
,	O
underground	O
,	O
train	O
and	O
bus	O
)	O
.	O
	
First	O
,	O
we	O
overcome	O
the	O
data	O
-	O
related	O
issues	O
by	O
collecting	O
GPS	B-Material
data	I-Material
for	O
a	O
recommended	O
sample	O
size	O
for	O
this	O
study	O
(	O
81	O
participants	O
)	O
for	O
a	O
period	O
of	O
two	O
weeks	O
to	O
account	O
for	O
the	O
weekly	O
seasonal	O
variation	O
(	O
Bolbol	O
,	O
Cheng	O
,	O
Tsapakis	O
,	O
&	O
Chow	O
,	O
2012	O
)	O
.	O
	
We	O
set	O
the	O
devices	O
to	O
a	O
collection	B-Metric
rate	I-Metric
of	O
60	O
s	O
to	O
conform	O
to	O
the	O
recommended	O
collection	B-Metric
rates	I-Metric
suitable	O
for	O
such	O
studies	O
.	O
	
The	O
data	O
is	O
collected	O
in	O
a	O
continuous	O
manner	O
over	O
the	O
two	O
weeks	O
to	O
ensure	O
the	O
natural	O
flow	O
of	O
the	O
travel	O
patterns	O
of	O
every	O
participant	O
.	O
	
The	O
data	O
is	O
simplified	O
for	O
the	O
participants	O
to	O
label	O
themselves	O
by	O
segmenting	O
the	O
track	O
into	O
individual	O
trips	O
on	O
an	O
online	O
platform	O
.	O
	
Section	O
2	O
highlights	O
these	O
data	O
-	O
limitations	O
in	O
detail	O
and	O
describes	O
the	O
sample	B-Metric
size	I-Metric
calculation	I-Metric
and	O
characteristics	O
used	O
to	O
determine	O
the	O
number	O
of	O
participants	O
and	O
duration	O
of	O
study	O
needed	O
for	O
an	O
efficient	O
validation	O
of	O
our	O
proposed	O
framework	O
.	O
	
We	O
also	O
describe	O
the	O
GPS	B-Material
data	I-Material
collected	O
for	O
this	O
research	O
with	O
a	O
brief	O
account	O
on	O
its	O
descriptive	B-Metric
statistics	I-Metric
.	O
	
Before	O
introducing	O
the	O
inference	B-Method
framework	I-Method
,	O
it	O
is	O
essential	O
to	O
select	O
the	O
best	O
classifier	B-Method
(	I-Method
s	I-Method
)	O
or	O
independent	O
variable	O
(	O
s	O
)	O
IVs	O
to	O
be	O
used	O
to	O
classify	O
GPS	O
points	O
into	O
transportation	O
modes	O
(	O
Mitchell	O
,	O
1997	O
)	O
.	O
	
Therefore	O
,	O
as	O
a	O
second	O
phase	O
,	O
we	O
run	O
an	O
analysis	B-Method
of	I-Method
variance	I-Method
(	O
ANOVA	B-Method
)	O
test	O
to	O
select	O
the	O
IV	O
(	O
s	O
)	O
that	O
best	O
discriminate	O
between	O
the	O
different	O
transportation	O
modes	O
.	O
	
In	O
turn	O
,	O
this	O
should	O
improve	O
the	O
performance	O
of	O
whichever	O
classification	B-Method
algorithm	I-Method
that	O
would	O
be	O
used	O
in	O
the	O
following	O
phase	O
.	O
	
We	O
statistically	O
compare	O
the	O
candidate	O
variables	O
using	O
different	O
statistical	B-Metric
measures	I-Metric
,	O
such	O
as	O
Wilks	B-Metric
’	I-Metric
Lambda	I-Metric
and	O
between	O
-	O
groups	O
F	O
to	O
assess	O
each	O
variable	O
’s	O
discriminatory	B-Metric
power	I-Metric
.	O
	
The	O
results	O
from	O
the	O
classification	B-Method
,	O
based	O
on	O
the	O
selected	O
variables	O
are	O
then	O
analysed	O
and	O
compared	O
illustrating	O
the	O
power	O
of	O
each	O
over	O
different	O
modes	O
(	O
categories	O
)	O
.	O
	
This	O
analysis	O
is	O
presented	O
in	O
Section	O
3	O
.	O
	
Finally	O
as	O
a	O
third	O
phase	O
,	O
we	O
attempt	O
to	O
identify	O
transportation	B-Task
modes	I-Task
from	O
the	O
collected	O
sparse	B-Material
GPS	I-Material
data	I-Material
,	O
without	O
information	O
or	O
assumptions	O
about	O
the	O
participant	O
’s	O
temporal	O
or	O
location	O
contexts	O
,	O
which	O
some	O
of	O
the	O
previous	O
approaches	O
were	O
based	O
on	O
.	O
	
We	O
use	O
Support	B-Method
Vector	I-Method
Machines	I-Method
(	O
SVMs	B-Method
)	O
to	O
perform	O
the	O
inference	B-Task
from	O
speed	O
and	O
acceleration	O
values	O
calculated	O
from	O
GPS	B-Material
data	I-Material
.	O
	
Due	O
to	O
its	O
high	O
quality	O
of	O
out	B-Metric
-	I-Metric
of	I-Metric
-	I-Metric
sample	I-Metric
generalization	I-Metric
and	O
ease	O
of	O
training	O
,	O
SVMs	B-Method
provide	O
far	O
beyond	O
the	O
capacities	O
of	O
traditional	O
ML	B-Method
methods	I-Method
used	O
in	O
previous	O
research	O
.	O
	
Furthermore	O
,	O
using	O
SVMs	B-Method
,	O
the	O
selected	B-Method
kernel	I-Method
could	O
be	O
applied	O
directly	O
to	O
the	O
data	O
without	O
the	O
need	O
for	O
a	O
feature	B-Method
extraction	I-Method
process	I-Method
.	O
	
This	O
is	O
advantageous	O
in	O
the	O
context	O
of	O
learning	O
from	O
the	O
structure	O
of	O
the	O
data	O
,	O
since	O
a	O
lot	O
of	O
this	O
structure	O
is	O
lost	O
by	O
the	O
feature	B-Method
extraction	I-Method
process	I-Method
.	O
	
This	O
enables	O
us	O
to	O
study	O
a	O
sequence	O
of	O
movements	O
of	O
a	O
participant	O
rather	O
than	O
each	O
movement	O
individually	O
,	O
and	O
hence	O
,	O
achieving	O
a	O
better	O
classification	B-Task
.	O
	
We	O
achieve	O
this	O
by	O
using	O
a	O
moving	B-Method
window	I-Method
that	O
classifies	O
instances	O
of	O
data	O
consequent	O
blocks	O
.	O
	
We	O
complement	O
this	O
by	O
using	O
logical	B-Method
filters	I-Method
that	O
apply	O
a	O
transition	O
matrix	O
between	O
different	O
phases	O
of	O
the	O
trip	O
.	O
	
This	O
is	O
presented	O
and	O
described	O
in	O
detail	O
in	O
Section	O
4	O
.	O
	
The	O
results	O
of	O
this	O
inference	O
are	O
presented	O
in	O
Section	O
5	O
along	O
with	O
some	O
discussions	O
and	O
conclusions	O
in	O
Section	O
6	O
.	O
2	O
.	O
	
Data	O
collection	O
	
This	O
section	O
illustrates	O
the	O
most	O
striking	O
data	O
collection	O
-	O
related	O
limitations	O
.	O
	
First	O
,	O
we	O
describe	O
the	O
basis	O
of	O
the	O
sample	B-Method
size	I-Method
calculation	I-Method
method	I-Method
which	O
is	O
used	O
to	O
determine	O
the	O
number	O
of	O
participants	O
and	O
duration	O
of	O
study	O
needed	O
.	O
	
Then	O
,	O
we	O
also	O
define	O
the	O
sample	O
characteristics	O
that	O
would	O
lead	O
to	O
an	O
efficient	O
validation	O
of	O
our	O
proposed	O
inference	B-Method
framework	I-Method
,	O
overcoming	O
the	O
data	O
limitations	O
that	O
exist	O
in	O
past	O
research	O
.	O
	
Lastly	O
,	O
we	O
describe	O
the	O
GPS	B-Material
data	I-Material
collected	O
for	O
this	O
research	O
with	O
a	O
brief	O
account	O
on	O
its	O
descriptive	B-Metric
statistics	I-Metric
.	O
	
2.1	O
.	O
	
Travel	B-Task
survey	I-Task
definitions	I-Task
	
In	O
order	O
to	O
de	O
-	O
construct	O
a	O
GPS	O
track	O
,	O
some	O
definitions	O
have	O
been	O
standardised	O
to	O
be	O
used	O
for	O
the	O
description	O
of	O
different	O
fragments	O
of	O
the	O
trip	O
.	O
	
For	O
example	O
,	O
the	O
route	O
between	O
any	O
two	O
consecutive	O
GPS	O
points	O
is	O
called	O
a	O
segment	O
.	O
	
Trips	O
also	O
consist	O
of	O
a	O
number	O
of	O
stages	O
(	O
a	O
group	O
of	O
segments	O
)	O
.	O
	
A	O
new	O
stage	O
is	O
defined	O
when	O
there	O
is	O
a	O
change	O
from	O
one	O
mode	O
of	O
transport	O
to	O
another	O
,	O
or	O
where	O
there	O
is	O
a	O
change	O
in	O
vehicle	O
of	O
the	O
same	O
mode	O
(	O
Anderson	O
,	O
Abeywardana	O
,	O
Wolf	O
,	O
&	O
Lee	O
,	O
2009	O
)	O
.	O
	
2.2	O
.	O
	
Limitations	O
of	O
data	B-Method
collection	I-Method
for	O
inferring	O
the	O
transportation	B-Task
mode	I-Task
Over	O
the	O
last	O
decade	O
,	O
a	O
plethora	O
of	O
studies	O
have	O
attempted	O
to	O
infer	O
the	O
transportation	B-Task
mode	I-Task
from	O
GPS	B-Material
data	I-Material
collected	O
by	O
travel	B-Method
surveys	I-Method
.	O
	
Most	O
of	O
these	O
studies	O
have	O
been	O
carried	O
out	O
in	O
complex	O
urban	O
study	O
areas	O
using	O
either	O
:	O
mobile	B-Method
applications	I-Method
on	O
smart	O
phones	O
(	O
Manzoni	O
et	O
al	O
.	O
,	O
2011	O
;	O
Stenneth	O
et	O
al	O
.	O
,	O
2011	O
)	O
;	O
strictly	O
GPS	B-Method
devices	I-Method
alone	O
(	O
Chung	O
&	O
Shalaby	O
,	O
2005	O
;	O
Liao	O
et	O
al	O
.	O
,	O
2007	O
;	O
Schüssler	O
&	O
Axhausen	O
,	O
2009	O
;	O
Stopher	O
,	O
Clifford	O
et	O
al	O
.	O
,	O
2008a	O
;	O
Zheng	O
et	O
al	O
.	O
,	O
2010	O
)	O
or	O
integrated	O
with	O
other	O
devices	O
,	O
such	O
as	O
accelerometers	O
(	O
Reddy	O
et	O
al	O
.	O
,	O
2010	O
)	O
,	O
or	O
;	O
others	O
through	O
mobile	B-Method
phone	I-Method
call	I-Method
detail	I-Method
records	I-Method
(	O
CDR	B-Method
)	O
(	O
Wang	O
,	O
Calabrese	O
,	O
Di	O
Lorenzo	O
,	O
&	O
Ratti	O
,	O
2010	O
)	O
.	O
	
Such	O
studies	O
resulted	O
in	O
collecting	O
a	O
large	O
amount	O
of	O
diverse	O
data	O
to	O
test	O
different	O
approaches	O
.	O
	
However	O
,	O
the	O
majority	O
of	O
the	O
studies	O
did	O
not	O
have	O
any	O
specifications	O
for	O
their	O
sampling	B-Method
techniques	I-Method
.	O
	
For	O
example	O
,	O
they	O
did	O
not	O
base	O
their	O
sample	O
size	O
calculations	O
on	O
any	O
statistical	B-Method
framework	I-Method
.	O
	
Some	O
of	O
them	O
used	O
as	O
low	O
as	O
4	O
participants	O
	
(	O
Liao	O
et	O
al	O
.	O
,	O
2007	O
)	O
,	O
60	O
trips	O
(	O
Chung	O
&	O
Shalaby	O
,	O
2005	O
)	O
or	O
as	O
many	O
as	O
4882	O
participants	O
(	O
Schüssler	O
&	O
Axhausen	O
,	O
2009	O
)	O
without	O
providing	O
statistical	O
justification	O
for	O
using	O
such	O
numbers	O
.	O
	
Another	O
issue	O
is	O
the	O
study	O
’s	O
duration	O
,	O
where	O
several	O
studies	O
use	O
less	O
than	O
even	O
one	O
day	O
’s	O
worth	O
of	O
data	O
(	O
Manzoni	O
et	O
al	O
.	O
,	O
2011	O
;	O
Reddy	O
et	O
al	O
.	O
,	O
2010	O
)	O
,	O
whilst	O
others	O
use	O
data	O
of	O
less	O
than	O
a	O
week	O
duration	O
(	O
Liao	O
et	O
al	O
.	O
,	O
2007	O
;	O
Schüssler	O
&	O
Axhausen	O
,	O
2009	O
)	O
.	O
	
Note	O
that	O
both	O
cases	O
do	O
not	O
account	O
for	O
the	O
weekly	O
seasonal	O
variation	O
.	O
	
We	O
discuss	O
this	O
in	O
another	O
work	O
of	O
ours	O
by	O
running	O
statistical	B-Method
analysis	I-Method
of	O
traffic	O
data	O
from	O
similar	O
complex	O
urban	O
cities	O
,	O
resulting	O
in	O
a	O
recommendation	O
of	O
no	O
less	O
than	O
81	O
participants	O
for	O
at	O
least	O
2	O
weeks	O
,	O
as	O
a	O
minimum	O
guideline	O
for	O
sample	O
sizes	O
to	O
be	O
used	O
in	O
such	O
studies	O
(	O
Bolbol	O
et	O
al	O
.	O
,	O
2012	O
)	O
.	O
	
Another	O
issue	O
is	O
the	O
temporal	O
granularity	O
of	O
the	O
GPS	B-Material
data	I-Material
(	O
also	O
called	O
the	O
epoch	B-Metric
rate	I-Metric
of	I-Metric
collection	I-Metric
)	O
,	O
where	O
most	O
studies	O
use	O
a	O
1	O
s	O
collection	B-Metric
rate	I-Metric
.	O
	
The	O
question	O
that	O
arises	O
is	O
:	O
Do	O
we	O
need	O
such	O
detail	O
?	O
	
Not	O
only	O
would	O
that	O
create	O
a	O
load	O
on	O
memory	O
and	O
on	O
battery	O
restrictions	O
on	O
current	O
GPS	O
devices	O
or	O
smart	O
phones	O
,	O
but	O
it	O
will	O
also	O
add	O
to	O
the	O
computation	B-Metric
cost	I-Metric
of	O
any	O
of	O
the	O
used	O
algorithms	O
.	O
	
This	O
will	O
Table	O
	
1	O
A	O
summary	O
of	O
previous	O
studies	O
’	O
accuracies	B-Metric
and	O
sample	O
sizes	O
and	O
durations	O
.	O
	
Study	O
Accuracy	B-Metric
(	O
%	O
)	O
	
Sample	O
size	O
Duration	O
No	O
.	O
of	O
modes	O
Chung	O
and	O
Shalaby	O
(	O
2005	O
)	O
	
92	O
60	O
Trips	O
4	O
Liao	O
et	O
al	O
.	O
	
(	O
2007	O
)	O
90	O
4	O
Participants	O
6	O
Days	O
3	O
Zheng	O
et	O
al	O
.	O
	
(	O
2010	O
)	O
76	O
65	O
participants	O
10	O
Months	O
4	O
Reddy	O
et	O
al	O
.	O
	
(	O
2010	O
)	O
94	O
16	O
Participants	O
7.5	O
h	O
5	O
Manzoni	O
et	O
al	O
.	O
	
(	O
2010	O
)	O
	
82	O
	
5	O
Participants	O
	
Several	O
hours	O
7	O
Stenneth	O
et	O
al	O
.	O
	
(	O
2011	O
)	O
	
93	O
6	O
Participants	O
3	O
h	O
6	O
also	O
impose	O
a	O
daily	O
(	O
if	O
not	O
hourly	O
)	O
burden	O
on	O
the	O
participants	O
to	O
charge	O
their	O
devices	O
and	O
act	O
as	O
a	O
constant	O
reminder	O
that	O
they	O
have	O
a	O
tracking	O
device	O
.	O
	
This	O
gives	O
rise	O
to	O
typical	O
participant	O
-	O
related	O
reported	O
problems	O
,	O
such	O
as	O
feeling	O
vulnerable	O
when	O
carrying	O
the	O
device	O
,	O
or	O
influencing	O
their	O
normal	O
behaviour	O
(	O
Anderson	O
et	O
al	O
.	O
,	O
2009	O
)	O
.	O
	
We	O
discuss	O
this	O
issue	O
in	O
Bolbol	O
and	O
Cheng	O
(	O
2010a	O
)	O
demonstrating	O
that	O
a	O
collection	B-Metric
rate	I-Metric
of	O
30–60	O
s	O
is	O
sufficient	O
enough	O
for	O
a	O
city	O
like	O
London	O
for	O
this	O
type	O
of	O
study	O
.	O
	
Some	O
of	O
the	O
current	O
studies	O
have	O
other	O
data	O
limitations	O
,	O
such	O
as	O
using	O
one	O
-	O
purpose	O
trips	O
(	O
Manzoni	O
et	O
al	O
.	O
,	O
2011	O
;	O
Stopher	O
,	O
Clifford	O
et	O
al	O
.	O
,	O
2008a	O
)	O
that	O
influence	O
the	O
results	O
of	O
any	O
inference	O
of	O
any	O
method	O
used	O
,	O
restricting	O
the	O
outcome	O
to	O
one	O
or	O
two	O
modes	O
.	O
	
Also	O
,	O
some	O
of	O
the	O
validation	O
methods	O
did	O
not	O
seem	O
to	O
be	O
based	O
on	O
actual	O
labelled	O
data	O
by	O
the	O
participants	O
.	O
	
For	O
example	O
,	O
Schüssler	O
and	O
Axhausen	O
(	O
2009	O
)	O
use	O
consensus	O
data	O
from	O
previous	O
years	O
of	O
the	O
same	O
city	O
to	O
evaluate	O
the	O
classification	B-Task
results	O
,	O
while	O
Wang	O
et	O
al	O
.	O
	
(	O
2010	O
)	O
use	O
Google	O
Maps	O
to	O
verify	O
the	O
results	O
by	O
comparing	O
them	O
to	O
the	O
proposed	O
modes	O
by	O
Google	O
for	O
the	O
corresponding	O
trip	O
travel	O
times	O
.	O
	
Although	O
other	O
methods	O
using	O
labelled	O
data	O
have	O
achieved	O
accuracies	B-Metric
of	O
90	O
%	O
or	O
more	O
,	O
yet	O
sample	O
sizes	O
and	O
durations	O
were	O
often	O
not	O
adequate	O
to	O
give	O
full	O
accreditation	O
to	O
the	O
results	O
.	O
	
Table	O
1	O
lists	O
some	O
of	O
these	O
studies	O
along	O
with	O
the	O
accuracies	B-Metric
achieved	O
,	O
sample	O
sizes	O
,	O
survey	O
durations	O
and	O
the	O
number	O
of	O
modes	O
considered	O
while	O
validating	O
each	O
method	O
’s	O
performance	O
.	O
	
We	O
overcome	O
these	O
data	O
-	O
related	O
issues	O
by	O
collecting	O
GPS	B-Material
data	I-Material
for	O
this	O
study	O
for	O
a	O
period	O
of	O
two	O
weeks	O
to	O
account	O
for	O
the	O
weekly	O
seasonal	O
variation	O
.	O
	
We	O
set	O
the	O
devices	O
to	O
a	O
collection	B-Metric
rate	I-Metric
of	O
60	O
s	O
to	O
conform	O
to	O
the	O
recommended	O
collection	B-Metric
rates	I-Metric
suitable	O
for	O
such	O
studies	O
.	O
	
The	O
data	O
is	O
collected	O
in	O
a	O
continuous	O
manner	O
over	O
the	O
two	O
weeks	O
to	O
ensure	O
the	O
natural	O
flow	O
of	O
the	O
travel	O
patterns	O
of	O
every	O
participant	O
.	O
	
The	O
data	O
is	O
simplified	O
for	O
the	O
participants	O
to	O
label	O
themselves	O
by	O
segmenting	O
the	O
track	O
into	O
individual	O
trips	O
on	O
an	O
online	O
platform	O
.	O
	
The	O
rest	O
of	O
this	O
section	O
describes	O
the	O
sample	B-Method
size	I-Method
calculation	I-Method
method	I-Method
used	O
to	O
determine	O
the	O
number	O
of	O
participants	O
and	O
duration	O
of	O
study	O
needed	O
for	O
an	O
efficient	O
validation	O
of	O
our	O
proposed	O
framework	O
,	O
along	O
with	O
the	O
description	O
of	O
the	O
data	O
properties	O
.	O
	
taset	O
in	O
Greater	O
London	O
.	O
	
2.3	O
.	O
	
Sample	O
size	O
calculation	O
	
The	O
calculation	O
of	O
the	O
minimum	B-Metric
sample	I-Metric
size	I-Metric
is	O
an	O
important	O
consideration	O
in	O
this	O
study	O
and	O
for	O
travel	B-Task
behaviour	I-Task
studies	I-Task
in	O
general	O
.	O
	
For	O
conventional	O
one	B-Task
-	I-Task
day	I-Task
or	I-Task
two	I-Task
-	I-Task
day	I-Task
travel	I-Task
surveys	I-Task
,	O
sample	B-Method
size	I-Method
procedures	I-Method
are	O
well	O
known	O
and	O
widely	O
applied	O
;	O
for	O
example	O
,	O
the	O
Travel	O
Survey	O
Manual	O
by	O
Cambridge	O
Systematics	O
(	O
1996	O
)	O
.	O
	
The	O
corresponding	O
sample	B-Method
size	I-Method
procedures	I-Method
for	O
GPS	B-Task
-	I-Task
based	I-Task
panel	I-Task
surveys	I-Task
however	O
,	O
are	O
less	O
well	O
developed	O
(	O
Xu	O
,	O
2010	O
)	O
.	O
	
Therefore	O
,	O
the	O
estimation	O
of	O
a	O
statistically	O
adequate	O
sample	B-Metric
size	I-Metric
,	O
for	O
whichever	O
survey	O
type	O
,	O
requires	O
good	O
knowledge	O
of	O
the	O
variables	O
under	O
investigation	O
,	O
their	O
coefficient	O
of	O
variation	O
and	O
the	O
desired	O
accuracy	B-Metric
of	O
measurement	O
together	O
with	O
the	O
level	O
of	O
significance	O
associated	O
with	O
it	O
(	O
Smith	O
,	O
1979	O
)	O
.	O
	
The	O
variables	O
to	O
be	O
investigated	O
in	O
this	O
study	O
,	O
speed	O
and	O
acceleration	O
,	O
are	O
calculated	O
from	O
the	O
collected	O
GPS	B-Material
data	I-Material
.	O
	
The	O
Coefficient	B-Metric
of	I-Metric
Variation	I-Metric
(	O
CV	B-Metric
)	O
is	O
also	O
an	O
important	O
element	O
for	O
the	O
estimation	B-Task
process	I-Task
,	O
where	O
the	O
sample	B-Metric
size	I-Metric
largely	O
depends	O
on	O
how	O
much	O
the	O
variable	O
deviates	O
from	O
its	O
mean	O
.	O
	
The	O
CV	B-Metric
is	O
a	O
normalized	B-Metric
measure	I-Metric
of	I-Metric
dispersion	I-Metric
of	O
a	O
probability	B-Method
distribution	I-Method
,	O
or	O
a	O
statistical	B-Metric
measure	I-Metric
of	O
the	O
dispersion	O
of	O
data	O
points	O
in	O
a	O
data	O
series	O
around	O
the	O
mean	O
.	O
	
It	O
is	O
calculated	O
by	O
dividing	O
the	O
standard	O
deviation	O
by	O
the	O
mean	O
of	O
the	O
population	O
.	O
	
The	O
third	O
element	O
is	O
the	O
accuracy	B-Metric
desired	O
(	O
and	O
significance	B-Metric
level	I-Metric
)	O
,	O
where	O
the	O
accuracy	B-Metric
level	O
is	O
the	O
percentage	O
error	O
acceptable	O
to	O
the	O
analyst	O
.	O
	
Both	O
the	O
accuracy	B-Metric
and	O
the	O
significance	O
level	O
are	O
context	O
-	O
dependant	O
elements	O
to	O
be	O
decided	O
by	O
the	O
analyst	O
according	O
to	O
the	O
analyst	O
’s	O
experience	O
(	O
Ortúzar	O
&	O
Willumsen	O
,	O
2011	O
)	O
.	O
	
Once	O
these	O
three	O
factors	O
are	O
defined	O
,	O
the	O
sample	O
size	O
(	O
n	O
)	O
could	O
be	O
computed	O
from	O
Eq	O
.	O
	
(	O
1	O
)	O
.	O
	
N	O
¼	O
	
CV2Z2a	O
=	O
	
E	O
2	O
ð1Þ	O
where	O
E	O
is	O
the	O
level	O
of	O
accuracy	B-Metric
and	O
Za	O
is	O
the	O
standard	O
normal	O
value	O
for	O
the	O
confidence	O
level	O
(	O
a	O
)	O
required	O
.	O
	
Since	O
the	O
acceleration	O
is	O
a	O
derivative	O
of	O
speed	O
,	O
the	O
CV	O
of	O
speed	O
could	O
also	O
represent	O
the	O
acceleration	O
’s	O
variability	O
.	O
	
According	O
to	O
different	O
studies	O
that	O
aim	O
to	O
measure	O
and	O
analyse	O
the	O
variability	O
of	O
speed	O
for	O
different	O
modes	O
,	O
a	O
minimum	O
of	O
81	O
participants	O
was	O
calculated	O
for	O
an	O
adequate	O
sample	O
size	O
(	O
Stopher	O
,	O
Kockelman	O
,	O
Greaves	O
,	O
&	O
Clifford	O
,	O
2008b	O
;	O
TFL	O
,	O
2011	O
;	O
Thompson	O
,	O
Rebolledo	O
,	O
&	O
Thomson	O
,	O
1997	O
;	O
Weidmann	O
,	O
1993	O
)	O
,	O
which	O
is	O
the	O
number	O
we	O
are	O
using	O
in	O
this	O
research	O
.	O
	
The	O
details	O
of	O
this	O
calculation	O
are	O
out	O
of	O
the	O
scope	O
of	O
this	O
paper	O
and	O
therefore	O
are	O
not	O
mentioned	O
here	O
explicitly	O
,	O
yet	O
further	O
details	O
on	O
this	O
calculation	O
is	O
available	O
in	O
Bolbol	O
et	O
al	O
.	O
	
(	O
2012	O
)	O
.	O
	
2.4	O
.	O
	
Sample	O
data	O
	
As	O
mentioned	O
in	O
Section	O
2.3	O
,	O
the	O
optimum	O
sample	O
characteristics	O
that	O
would	O
be	O
ideal	O
for	O
such	O
a	O
study	O
in	O
an	O
urban	O
area	O
should	O
consist	O
of	O
a	O
minimum	O
of	O
81	O
participants	O
for	O
a	O
minimum	O
period	O
of	O
2	O
weeks	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
the	O
specifications	O
of	O
the	O
data	O
to	O
be	O
collected	O
for	O
this	O
type	O
of	O
survey	O
could	O
be	O
determined	O
and	O
made	O
clear	O
from	O
the	O
discussion	O
in	O
Section	O
2.2	O
for	O
the	O
context	O
of	O
this	O
study	O
.	O
	
These	O
specifications	O
include	O
that	O
the	O
data	O
should	O
contain	O
all	O
transportation	O
modes	O
that	O
would	O
exist	O
in	O
a	O
typical	O
complex	O
urban	O
setting	O
including	O
walk	O
,	O
cycle	O
,	O
bus	O
,	O
car	O
,	O
train	O
and	O
underground	O
.	O
	
The	O
data	O
also	O
has	O
to	O
be	O
of	O
a	O
moderate	O
temporal	O
granularity	O
to	O
avoid	O
battery	O
and	O
memory	O
constraints	O
,	O
which	O
lessens	O
the	O
participants	O
’	O
burden	O
.	O
	
Nevertheless	O
,	O
it	O
should	O
also	O
provide	O
the	O
minimum	O
epoch	B-Metric
rate	I-Metric
duration	I-Metric
sufficient	O
for	O
this	O
type	O
of	O
study	O
,	O
as	O
well	O
as	O
cutting	O
down	O
the	O
computational	B-Metric
cost	I-Metric
(	O
Bolbol	O
&	O
Cheng	O
,	O
2010a	O
)	O
.	O
	
The	O
data	O
also	O
has	O
to	O
cover	O
at	O
least	O
a	O
period	O
of	O
two	O
weeks	O
to	O
account	O
for	O
the	O
weekly	O
seasonal	O
variation	O
.	O
	
Also	O
,	O
the	O
nature	O
of	O
the	O
data	O
has	O
to	O
be	O
of	O
a	O
mode	O
-	O
continuous	O
nature	O
(	O
i.e.	O
avoiding	O
recording	O
only	O
single	O
mode	O
trips	O
)	O
.	O
	
Furthermore	O
,	O
in	O
order	O
to	O
ensure	O
the	O
quality	O
of	O
the	O
validation	O
process	O
,	O
the	O
data	O
has	O
to	O
be	O
assigned	O
transportation	O
mode	O
labels	O
by	O
the	O
participants	O
for	O
each	O
stage	O
of	O
their	O
trips	O
.	O
	
Therefore	O
,	O
the	O
training	O
dataset	O
used	O
for	O
testing	O
consists	O
of	O
2	O
-	O
weeks	O
long	O
multi	O
-	O
modal	O
tracks	O
(	O
2	O
waves	O
–	O
	
to	O
account	O
for	O
seasonal	O
variation	O
)	O
of	O
81	O
users	O
within	O
2010–2011	O
	
(	O
Fig	O
.	O
1	O
)	O
.	O
	
The	O
tracks	O
are	O
collected	O
within	O
London	O
at	O
1	O
min	O
frequency	O
.	O
	
London	O
is	O
selected	O
due	O
to	O
its	O
complexity	O
and	O
the	O
diversity	O
of	O
its	O
transportation	B-Task
networks	I-Task
.	O
	
The	O
transportation	O
mode	O
of	O
each	O
segment	O
in	O
the	O
dataset	O
was	O
labelled	O
by	O
the	O
users	O
themselves	O
using	O
an	O
online	O
platform	O
enabling	O
them	O
to	O
edit	O
their	O
own	O
tracks	O
.	O
	
More	O
details	O
on	O
this	O
online	O
process	O
could	O
be	O
found	O
in	O
Bolbol	O
,	O
Cheng	O
and	O
Paracha	O
(	O
2010b	O
)	O
.	O
	
The	O
dataset	O
was	O
then	O
filtered	O
for	O
the	O
car	O
,	O
cycle	O
,	O
bus	O
,	O
walk	O
,	O
tube	O
and	O
train	O
modes	O
,	O
so	O
as	O
to	O
use	O
SVM	B-Method
classification	I-Method
to	O
infer	O
these	O
modes	O
.	O
	
The	O
number	O
of	O
fixes	O
of	O
the	O
walk	O
mode	O
in	O
the	O
dataset	O
was	O
the	O
highest	O
amongst	O
other	O
modes	O
and	O
almost	O
as	O
double	O
as	O
the	O
second	O
highest	O
mode	O
(	O
car	O
)	O
.	O
	
This	O
demonstrates	O
the	O
high	O
occurrence	O
of	O
walks	O
within	O
an	O
individual	O
’s	O
daily	O
journey	O
.	O
	
This	O
is	O
due	O
to	O
the	O
fact	O
that	O
walking	O
often	O
occurs	O
as	O
an	O
intermediate	O
link	O
between	O
different	O
modes	O
.	O
	
The	O
underground	O
(	O
tube	O
)	O
mode	O
recorded	O
the	O
least	O
number	O
of	O
GPS	O
fixes	O
since	O
nearly	O
half	O
of	O
the	O
tube	O
network	O
in	O
London	O
is	O
actually	O
underground	O
,	O
which	O
causes	O
the	O
loss	O
of	O
GPS	O
coverage	O
.	O
	
In	O
this	O
case	O
,	O
a	O
typical	O
underground	O
tube	O
segment	O
would	O
consist	O
of	O
only	O
two	O
points	O
;	O
an	O
entrance	O
and	O
an	O
exit	O
fix	O
.	O
	
Table	O
2	O
shows	O
the	O
respective	O
averages	O
of	O
speed	B-Metric
,	O
distance	O
and	O
time	O
difference	O
between	O
every	O
two	O
fixes	O
of	O
each	O
of	O
the	O
6	O
modes	O
in	O
this	O
dataset	O
.	O
	
Outliers	O
due	O
to	O
GPS	O
errors	O
are	O
accounted	O
for	O
and	O
removed	O
.	O
	
The	O
table	O
demonstrates	O
a	O
clear	O
confusion	O
and	O
overlap	O
between	O
the	O
speed	O
averages	O
of	O
bus	O
and	O
cycle	O
modes	O
.	O
	
This	O
is	O
due	O
to	O
London	O
’s	O
high	O
congestion	O
during	O
the	O
peak	O
hours	O
of	O
the	O
day	O
.	O
	
This	O
emphasizes	O
the	O
nature	O
of	O
different	O
forms	O
of	O
commute	O
in	O
London	O
’s	O
network	O
.	O
	
It	O
also	O
appears	O
that	O
train	O
and	O
tube	O
modes	O
have	O
long	O
distances	O
between	O
their	O
consecutive	O
fixes	O
due	O
to	O
their	O
high	O
speeds	O
.	O
	
However	O
,	O
the	O
average	O
time	O
difference	O
among	O
the	O
tube	O
mode	O
fixes	O
seems	O
to	O
exceed	O
that	O
of	O
the	O
train	O
by	O
a	O
tenfold	O
due	O
to	O
loss	O
of	O
signal	O
.	O
	
3	O
.	O
	
Independent	B-Task
variable	I-Task
selection	I-Task
Generally	O
in	O
a	O
classification	B-Task
problem	I-Task
,	O
the	O
variable	O
that	O
is	O
to	O
be	O
predicted	O
is	O
known	O
as	O
the	O
dependent	O
variable	O
(	O
transportation	O
mode	O
in	O
our	O
case	O
)	O
because	O
its	O
value	O
depends	O
upon	O
,	O
or	O
is	O
decided	O
by	O
,	O
the	O
values	O
of	O
all	O
the	O
other	O
attributes	O
.	O
	
The	O
other	O
attributes	O
that	O
help	O
to	O
predict	O
the	O
value	O
of	O
the	O
dependent	O
variable	O
,	O
are	O
known	O
as	O
the	O
independent	O
variables	O
(	O
IVs	O
)	O
in	O
the	O
dataset	O
.	O
	
The	O
less	O
correlated	O
(	O
or	O
statistically	O
dependent	O
)	O
the	O
IVs	O
are	O
the	O
more	O
the	O
outcome	O
of	O
the	O
classification	B-Task
is	O
inclined	O
to	O
be	O
biased	O
.	O
	
A	O
major	O
limitation	O
in	O
methods	O
attempting	O
to	O
infer	O
the	O
transportation	B-Task
mode	I-Task
is	O
the	O
choice	O
of	O
IVs	O
to	O
be	O
used	O
for	O
classification	B-Task
.	O
	
For	O
most	O
studies	O
the	O
variables	O
chosen	O
were	O
not	O
based	O
on	O
any	O
statistical	O
evaluation	O
justifying	O
the	O
variable	O
choice	O
being	O
made	O
.	O
	
Most	O
studies	O
use	O
variables	O
such	O
as	O
length	O
,	O
speed	O
,	O
acceleration	O
,	O
maximum	O
or	O
median	O
of	O
speed	O
or	O
acceleration	O
through	O
a	O
stage	O
(	O
Schüssler	O
&	O
Axhausen	O
,	O
2009	O
;	O
Zheng	O
et	O
al	O
.	O
,	O
2010	O
)	O
,	O
either	O
together	O
or	O
alone	O
for	O
classification	B-Task
without	O
providing	O
a	O
statistical	O
basis	O
for	O
the	O
choice	O
.	O
	
The	O
correlation	O
of	O
the	O
chosen	O
IVs	O
in	O
these	O
studies	O
was	O
neither	O
ac	O
-	O
counted	O
for	O
.	O
	
Therefore	O
,	O
in	O
this	O
section	O
we	O
conduct	O
a	O
statistical	O
evaluation	O
of	O
different	O
IVs	O
that	O
could	O
discriminate	O
between	O
different	O
classes	O
(	O
modes	O
)	O
in	O
this	O
classification	B-Task
problem	I-Task
.	O
	
The	O
outcome	O
of	O
the	O
evaluation	O
identifies	O
the	O
best	O
IVs	O
to	O
be	O
used	O
for	O
the	O
classification	B-Task
.	O
	
Sampling	B-Task
for	O
this	O
kind	O
of	O
GPS	B-Task
-	I-Task
based	I-Task
study	I-Task
could	O
also	O
be	O
a	O
pushing	O
problem	O
in	O
the	O
context	O
of	O
transport	B-Task
studies	I-Task
.	O
	
Therefore	O
,	O
we	O
discuss	O
the	O
sampling	B-Method
method	I-Method
used	O
to	O
identify	O
the	O
sample	O
size	O
and	O
the	O
period	O
of	O
such	O
studies	O
in	O
the	O
remaining	O
part	O
of	O
this	O
section	O
.	O
	
3.1	O
.	O
	
ANOVA	B-Method
test	I-Method
for	O
variable	B-Task
selection	I-Task
	
Four	O
potential	O
variables	O
were	O
taken	O
into	O
consideration	O
for	O
the	O
analysis	O
;	O
three	O
of	O
which	O
are	O
distance	O
,	O
speed	O
and	O
acceleration	O
,	O
(	O
a	O
)	O
Speed	O
plot	O
for	O
different	O
transportation	O
modes	O
(	O
c	O
)	O
Distance	O
plot	O
for	O
different	O
transportation	O
modes	O
Fig	O
.	O
2	O
.	O
	
Box	O
plots	O
for	O
the	O
values	O
of	O
d	O
which	O
are	O
highly	O
inter	O
-	O
correlated	O
where	O
they	O
all	O
stem	O
from	O
one	O
another	O
.	O
	
We	O
also	O
consider	O
the	O
change	O
rate	O
in	O
heading	O
(	O
direction	O
)	O
as	O
was	O
suggested	O
by	O
a	O
previous	O
study	O
(	O
Stopher	O
,	O
Clifford	O
et	O
al	O
.	O
,	O
2008a	O
)	O
.	O
	
The	O
testing	O
sequence	O
starts	O
with	O
group	O
statistics	O
to	O
examine	O
the	O
differences	O
between	O
the	O
categories	O
on	O
each	O
of	O
the	O
independent	O
variables	O
using	O
category	B-Method
means	I-Method
and	O
ANOVA	B-Method
test	I-Method
.	O
	
The	O
mean	O
differences	O
between	O
distance	O
,	O
acceleration	O
and	O
speed	O
suggest	O
that	O
these	O
may	O
be	O
good	O
discriminators	O
as	O
the	O
separations	O
are	O
large	O
.	O
	
This	O
separation	O
is	O
clear	O
in	O
Fig	O
.	O
	
2	O
representing	O
the	O
distribution	O
across	O
different	O
modes	O
as	O
box	O
plots	O
for	O
each	O
variable	O
in	O
a	O
separate	O
plot	O
.	O
	
These	O
3	O
variables	O
effectively	O
discriminate	O
the	O
walk	O
and	O
train	O
modes	O
from	O
the	O
rest	O
,	O
as	O
illustrated	O
in	O
the	O
figures	O
.	O
	
However	O
,	O
acceleration	O
appears	O
to	O
discriminate	O
the	O
car	O
mode	O
from	O
the	O
rest	O
quite	O
well	O
.	O
	
On	O
the	O
other	O
(	O
b	O
)	O
Acceleration	O
plot	O
for	O
different	O
transportation	O
modes	O
(	O
d	O
)	O
Change	O
in	O
heading	O
plot	O
for	O
different	O
transportation	O
modes	O
ifferent	O
independent	O
variables	O
.	O
	
hand	O
,	O
the	O
rate	O
of	O
change	O
in	O
direction	O
does	O
not	O
seem	O
to	O
significantly	O
discriminate	O
between	O
any	O
of	O
the	O
modes	O
,	O
except	O
for	O
the	O
train	O
,	O
which	O
could	O
be	O
caused	O
by	O
the	O
fact	O
that	O
train	O
trajectories	O
follow	O
fixed	O
tracks	O
for	O
long	O
distances	O
(	O
Fig	O
.	O
	
2d	O
)	O
.	O
	
Equality	O
of	O
group	O
means	O
results	O
are	O
presented	O
in	O
Table	O
3	O
.	O
	
In	O
order	O
to	O
assess	O
the	O
discriminability	O
of	O
the	O
different	O
IVs	O
two	O
statistical	B-Metric
measures	I-Metric
are	O
introduced	O
:	O
the	O
Wilks	B-Metric
’	I-Metric
Lambda	I-Metric
K	I-Metric
and	O
the	O
BetweenGroups	B-Metric
F.	I-Metric
	
The	O
former	O
is	O
used	O
in	O
multivariate	B-Method
analysis	I-Method
of	I-Method
variance	I-Method
(	O
MANOVA	B-Method
)	O
to	O
test	O
whether	O
there	O
are	O
differences	O
between	O
the	O
means	O
of	O
identified	O
groups	O
of	O
subjects	O
on	O
a	O
combination	O
of	O
dependent	O
variables	O
(	O
Everitt	O
&	O
Dunn	O
,	O
1991	O
)	O
.	O
	
Wilk	B-Method
’s	I-Method
Lambda	I-Method
is	O
a	O
statistic	O
that	O
takes	O
into	O
consideration	O
both	O
the	O
differences	O
between	O
groups	O
and	O
the	O
cohesiveness	O
or	O
homogeneity	O
within	O
groups	O
(	O
Klecka	O
,	O
1980	O
)	O
.	O
	
However	O
,	O
a	O
variable	O
which	O
increases	O
cohesiveness	O
without	O
changing	O
the	O
separation	O
between	O
centroids	O
may	O
be	O
selected	O
over	O
a	O
variable	O
that	O
increases	O
separation	O
without	O
changing	O
the	O
cohesiveness	O
.	O
	
When	O
the	O
IVs	O
are	O
considered	O
individually	O
,	O
K	O
is	O
given	O
from	O
Eq	O
.	O
	
(	O
2	O
)	O
.	O
	
K	O
¼Within	O
	
Groups	O
Sums	O
of	O
Squares	O
Total	O
Sums	O
of	O
Squares	O
¼	O
wil	O
til	O
ð2Þ	O
	
wil	O
¼	O
	
Xg	O
	
j¼1	O
	
Xmj	O
k¼1	O
fjkXijkXljk	O
	
Pg	O
j¼1	O
Pmj	O
k¼1fjkXijk	O
Pmj	O
k¼1fjkXljk	O
nj	O
ð3Þ	O
	
til	O
¼	O
	
Xg	O
	
j¼1	O
	
Xmj	O
k¼1	O
fjkXijkXljk	O
	
Pg	O
j¼1	O
Pmj	O
k¼1fjkXijk	O
	
Pg	O
j¼1	O
Pmj	O
k¼1fjkXljk	O
	
n	O
ð4Þ	O
where	O
g	O
is	O
the	O
number	O
of	O
groups	O
;	O
p	O
is	O
number	O
of	O
variables	O
;	O
	
i	O
,	O
l	O
is	O
1	O
,	O
.	O
.	O
.	O
	
,	O
p	O
	
;	O
Xijk	O
is	O
value	O
of	O
variable	O
i	O
for	O
case	O
k	O
in	O
group	O
	
j	O
	
;	O
Xljk	O
is	O
value	O
of	O
variable	O
l	O
for	O
case	O
k	O
in	O
group	O
	
j	O
;	O
fjk	O
is	O
case	O
weights	O
for	O
case	O
	
k	O
in	O
group	O
	
j	O
;	O
nj	O
is	O
sum	O
of	O
case	O
weights	O
in	O
group	O
j	O
;	O
	
n	O
is	O
total	O
sum	O
of	O
weights	O
;	O
mj	O
is	O
the	O
number	O
of	O
cases	O
in	O
group	O
j.	O
	
In	O
Table	O
3	O
,	O
large	O
values	O
of	O
lambda	O
indicate	O
that	O
group	O
means	O
are	O
close	O
,	O
while	O
small	O
values	O
are	O
indicators	O
of	O
different	O
means	O
.	O
	
Acceleration	O
and	O
speed	O
seem	O
to	O
be	O
the	O
best	O
discriminators	O
in	O
this	O
case	O
,	O
with	O
a	O
small	O
difference	O
between	O
their	O
performances	O
.	O
	
The	O
second	O
statistical	B-Metric
measure	I-Metric
used	O
,	O
the	O
Between	O
-	O
Groups	O
F	O
,	O
takes	O
into	O
consideration	O
the	O
sample	O
size	O
of	O
the	O
groups	O
.	O
	
This	O
differs	O
from	O
a	O
test	O
that	O
is	O
solely	O
based	O
on	O
squared	O
distance	O
(	O
Klecka	O
,	O
1980	O
)	O
.	O
	
Comparisons	O
between	O
small	O
groups	O
will	O
be	O
given	O
less	O
weight	O
than	O
comparisons	O
between	O
large	O
groups	O
.	O
	
The	O
advantage	O
here	O
is	O
that	O
this	O
criterion	O
will	O
maximize	O
differences	O
between	O
pairs	O
containing	O
larger	O
groups	O
.	O
	
Acceleration	O
and	O
speed	O
are	O
still	O
the	O
best	O
discriminators	O
in	O
this	O
case	O
;	O
however	O
,	O
the	O
difference	O
between	O
them	O
is	O
higher	O
.	O
	
This	O
finding	O
could	O
be	O
attributed	O
to	O
the	O
sample	O
size	O
of	O
the	O
car	B-Method
mode	I-Method
having	O
a	O
high	O
significance	O
in	O
manipulating	O
the	O
value	O
of	O
this	O
statistical	B-Metric
measure	I-Metric
.	O
	
Eq	O
.	O
	
(	O
5	O
)	O
is	O
used	O
to	O
calculate	O
the	O
F	B-Metric
statistic	I-Metric
based	O
on	O
another	O
statistic	B-Metric
called	O
Mahalanobis	B-Metric
Distance	I-Metric
D2	I-Metric
,	O
which	O
is	O
the	O
distance	O
between	O
two	O
groups	O
(	O
a	O
and	O
b	O
)	O
(	O
Klecka	O
,	O
1980	O
)	O
and	O
is	O
calculated	O
from	O
Eq	O
.	O
	
(	O
6	O
)	O
.	O
	
F	O
¼	O
ðn	O
	
1	O
pÞn1n2	O
pðn	O
	
2Þ	O
ðn1	O
þ	O
n2Þ	O
D2AB	O
ð5Þ	O
	
D2ab	O
¼	O
ðn	O
gÞ	O
	
Xp	O
	
i¼1	O
	
Xp	O
	
j¼1	O
w	O
ijðXia	O
	
XibÞ	O
	
ðXja	O
	
XjbÞ	O
ð6Þ	O
where	O
nz	O
is	O
the	O
sample	O
size	O
of	O
the	O
group	O
z	O
	
;	O
Xia	O
is	O
mean	O
of	O
ith	O
variable	O
in	O
group	O
a	O
;	O
Xja	O
is	O
mean	O
of	O
jth	O
variable	O
in	O
group	O
a	O
	
;	O
Xib	O
is	O
mean	O
of	O
ith	O
variable	O
in	O
group	O
b	O
,	O
and	O
Xjb	O
is	O
the	O
mean	O
of	O
jth	O
variable	O
in	O
group	O
b.	O
	
It	O
could	O
be	O
noted	O
that	O
speed	O
appears	O
to	O
be	O
a	O
better	O
discriminator	O
for	O
only	O
some	O
categories	O
when	O
calculating	O
the	O
Wilk	B-Metric
’s	I-Metric
Lambda	I-Metric
and	O
the	O
Between	O
-	O
Groups	O
F.	O
	
On	O
the	O
other	O
hand	O
,	O
acceleration	B-Task
is	O
better	O
for	O
most	O
of	O
the	O
categories	O
and	O
/	O
or	O
for	O
the	O
categories	O
of	O
the	O
highest	O
sample	O
sizes	O
.	O
	
From	O
Fig	O
.	O
	
2c	O
we	O
could	O
also	O
note	O
that	O
the	O
car	O
mode	O
is	O
better	O
discriminated	O
using	O
acceleration	O
rather	O
than	O
speed	O
in	O
Fig	O
.	O
	
2a	O
.	O
	
We	O
therefore	O
ran	O
the	O
same	O
analysis	O
again	O
but	O
this	O
time	O
using	O
only	O
3	O
categories	O
namely	O
:	O
car	O
,	O
train	O
and	O
the	O
rest	O
of	O
modes	O
aggregated	O
into	O
one	O
category	O
.	O
	
This	O
categorisation	O
was	O
due	O
to	O
the	O
natural	O
division	O
of	O
the	O
acceleration	O
data	O
illustrated	O
in	O
Fig	O
.	O
	
2c	O
.	O
	
Table	O
4	O
shows	O
the	O
results	O
of	O
this	O
second	O
run	O
,	O
proving	O
that	O
acceleration	B-Task
produces	O
a	O
better	O
discrimination	O
of	O
the	O
2	O
categories	O
.	O
	
It	O
also	O
performs	O
much	O
better	O
than	O
speed	O
,	O
while	O
it	O
yields	O
a	O
bigger	O
difference	O
than	O
that	O
shown	O
in	O
Table	O
3	O
.	O
	
We	O
could	O
comfortably	O
conclude	O
from	O
this	O
statistical	O
evaluation	O
that	O
speed	O
and	O
acceleration	O
are	O
the	O
best	O
IVs	O
for	O
discriminating	O
between	O
different	O
transportation	O
modes	O
,	O
given	O
the	O
specifications	O
of	O
the	O
data	O
collected	O
in	O
this	O
research	O
.	O
	
We	O
can	O
also	O
conclude	O
that	O
each	O
variable	O
is	O
better	O
at	O
discriminating	O
certain	O
categories	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
using	O
two	O
variables	O
that	O
are	O
highly	O
correlated	O
will	O
bias	O
the	O
inference	B-Task
results	O
.	O
	
Section	O
5	O
discusses	O
the	O
results	O
of	O
the	O
inference	B-Method
model	I-Method
using	O
each	O
of	O
these	O
IVs	O
by	O
quantifying	O
the	O
difference	O
in	O
the	O
classification	O
accuracy	B-Metric
for	O
each	O
mode	O
.	O
	
4	O
.	O
	
Inferring	B-Task
the	I-Task
transportation	I-Task
mode	I-Task
	
This	O
section	O
highlights	O
the	O
method	O
-	O
related	O
limitations	O
in	O
previous	O
attempts	O
to	O
infer	O
the	O
transportation	B-Task
mode	I-Task
.	O
	
This	O
section	O
also	O
describes	O
the	O
framework	O
used	O
to	O
classify	O
the	O
GPS	O
segments	O
into	O
transportation	O
modes	O
.	O
	
The	O
framework	O
is	O
based	O
on	O
a	O
SVM	B-Method
classification	I-Method
problem	I-Method
based	O
on	O
the	O
speed	O
and	O
acceleration	O
of	O
the	O
trajectory	O
,	O
as	O
proven	O
to	O
be	O
the	O
best	O
IVs	O
due	O
to	O
the	O
statistical	O
evidence	O
discussed	O
in	O
Section	O
3	O
.	O
	
The	O
framework	O
uses	O
an	O
innovative	O
sliding	B-Method
window	I-Method
approach	I-Method
to	O
learn	O
and	O
classify	O
the	O
data	O
instances	O
separately	O
for	O
each	O
variable	O
.	O
	
A	O
transition	B-Method
matrix	I-Method
is	O
later	O
applied	O
to	O
amend	O
the	O
sequence	O
of	O
consecutive	O
trip	O
stages	O
.	O
	
A	O
segmentation	B-Method
process	I-Method
is	O
applied	O
afterwards	O
,	O
based	O
on	O
the	O
idea	O
that	O
a	O
walk	O
stage	O
mostly	O
exists	O
as	O
a	O
transition	O
between	O
every	O
two	O
other	O
stages	O
in	O
any	O
trip	O
.	O
	
This	O
enables	O
a	O
further	O
reasoning	O
on	O
the	O
final	O
classification	B-Task
of	I-Task
nonwalk	I-Task
stages	I-Task
.	O
	
A	O
final	O
stage	O
of	O
identifying	B-Task
underground	I-Task
travel	I-Task
is	O
carried	O
out	O
,	O
followed	O
by	O
an	O
integration	O
stage	O
of	O
all	O
the	O
results	O
from	O
the	O
previous	O
stages	O
.	O
	
4.1	O
.	O
	
Method	O
-	O
related	O
limitations	O
	
The	O
range	O
of	O
the	O
methods	O
used	O
to	O
infer	O
the	O
transportation	B-Task
mode	I-Task
from	O
GPS	B-Material
data	I-Material
has	O
extended	O
from	O
logical	B-Method
procedural	I-Method
to	O
Machine	B-Method
Learning	I-Method
(	O
ML	B-Method
)	I-Method
approaches	I-Method
in	O
order	O
to	O
resolve	O
a	O
classification	B-Task
problem	I-Task
.	O
	
Stopher	O
,	O
Clifford	O
et	O
al	O
.	O
	
(	O
2008a	O
)	O
uses	O
a	O
process	O
of	O
elimination	O
of	O
different	O
modes	O
at	O
different	O
phases	O
of	O
the	O
algorithm	O
.	O
	
Schüssler	O
and	O
Axhausen	O
(	O
2009	O
)	O
developed	O
an	O
open	B-Method
source	I-Method
fuzzy	I-Method
logic	I-Method
engine	I-Method
using	O
the	O
median	B-Metric
of	I-Metric
speed	I-Metric
,	O
the	O
ninety	O
-	O
fifth	O
percentile	O
of	O
the	O
speed	O
and	O
the	O
acceleration	O
distributions	O
as	O
fuzzy	O
variables	O
.	O
	
Several	O
studies	O
employ	O
decision	B-Method
trees	I-Method
to	O
perform	O
this	O
classification	B-Task
,	O
either	O
alone	O
or	O
integrated	O
with	O
other	O
techniques	O
,	O
such	O
as	O
Hidden	B-Method
Markov	I-Method
Models	I-Method
(	O
HMM	B-Method
)	O
	
(	O
Manzoni	O
et	O
al	O
.	O
,	O
2011	O
;	O
Reddy	O
et	O
al	O
.	O
,	O
2010	O
;	O
	
Stenneth	O
et	O
al	O
.	O
,	O
2011	O
;	O
Zheng	O
et	O
al	O
.	O
,	O
2010	O
)	O
.	O
	
A	O
slight	O
limitation	O
is	O
that	O
the	O
majority	O
of	O
these	O
studies	O
only	O
considers	O
a	O
limited	O
number	O
of	O
transportation	O
modes	O
.	O
	
Some	O
use	O
as	O
few	O
as	O
3	O
modes	O
(	O
Liao	O
et	O
al	O
.	O
,	O
2007	O
;	O
Wang	O
et	O
al	O
.	O
,	O
2010	O
)	O
,	O
while	O
most	O
studies	O
exclude	O
the	O
train	O
and	O
underground	O
modes	O
.	O
	
Others	O
generalise	O
the	O
motorised	O
modes	O
together	O
(	O
Reddy	O
et	O
al	O
.	O
,	O
2010	O
)	O
,	O
grouping	O
bus	O
and	O
car	O
modes	O
.	O
	
A	O
common	O
practice	O
is	O
to	O
start	O
the	O
process	O
by	O
segmenting	O
the	O
GPS	O
track	O
into	O
trips	O
,	O
based	O
on	O
either	O
a	O
	
‘	O
	
‘	O
dwell	O
time	O
’	O
’	O
period	O
	
(	O
Stopher	O
,	O
Clifford	O
et	O
al	O
.	O
,	O
2008a	O
)	O
,	O
a	O
threshold	O
of	O
time	O
without	O
fix	O
.	O
	
Other	O
studies	O
go	O
a	O
step	O
further	O
by	O
segmenting	O
each	O
trip	O
into	O
stages	O
,	O
identifying	O
the	O
change	O
points	O
of	O
mode	O
switches	O
.	O
	
However	O
,	O
some	O
of	O
these	O
studies	O
start	O
by	O
performing	O
a	O
stage	B-Method
-	I-Method
level	I-Method
segmentation	I-Method
and	O
then	O
perform	O
the	O
classification	B-Task
based	O
on	O
the	O
identified	O
stages	O
(	O
Schüssler	O
&	O
Axhausen	O
,	O
2009	O
;	O
Zheng	O
et	O
al	O
.	O
,	O
2010	O
)	O
.	O
	
This	O
exerts	O
a	O
shortcoming	O
in	O
that	O
the	O
classification	O
accuracy	B-Metric
is	O
highly	O
reliant	O
on	O
the	O
segmentation	B-Metric
’s	I-Metric
efficiency	I-Metric
.	O
	
On	O
the	O
contrary	O
,	O
if	O
a	O
car	O
stage	O
was	O
identified	O
as	O
two	O
segments	O
,	O
based	O
on	O
the	O
fact	O
that	O
it	O
moved	O
from	O
a	O
speedy	O
main	O
road	O
to	O
a	O
highly	O
busy	O
street	O
,	O
the	O
latter	O
might	O
be	O
misclassified	O
accordingly	O
.	O
	
Other	O
studies	O
that	O
are	O
not	O
dependant	O
on	O
segmentation	B-Task
classify	O
each	O
GPS	O
segment	O
individually	O
into	O
a	O
transportation	O
mode	O
and	O
not	O
classifying	O
the	O
consequent	O
segments	O
as	O
a	O
block	O
,	O
i.e.	O
the	O
change	O
in	O
a	O
trajectory	O
’s	O
motion	O
across	O
several	O
segments	O
.	O
	
Even	O
studies	O
that	O
perform	O
segmentation	B-Task
beforehand	O
tend	O
to	O
ignore	O
this	O
consequence	O
across	O
the	O
mode	O
switch	O
points	O
.	O
	
Most	O
studies	O
also	O
assume	O
that	O
any	O
two	O
stages	O
are	O
always	O
separated	O
by	O
a	O
walk	O
stage	O
.	O
	
This	O
,	O
while	O
true	O
for	O
most	O
cases	O
,	O
might	O
fail	O
in	O
cases	O
of	O
cycling	O
or	O
driving	O
the	O
car	O
out	O
of	O
a	O
train	O
station	O
’s	O
car	O
park	O
for	O
example	O
.	O
	
A	O
useful	O
way	O
to	O
account	O
for	O
this	O
is	O
to	O
use	O
a	O
transition	O
matrix	O
to	O
verify	O
the	O
mode	O
switch	O
between	O
consecutive	O
stages	O
according	O
to	O
a	O
probability	O
matrix	O
of	O
such	O
switches	O
(	O
Zheng	O
et	O
al	O
.	O
,	O
2010	O
)	O
.	O
	
A	O
couple	O
of	O
studies	O
also	O
use	O
temporal	O
information	O
for	O
mode	B-Task
inference	I-Task
.	O
	
Liao	O
et	O
al	O
.	O
	
(	O
2007	O
)	O
use	O
the	O
time	O
of	O
day	O
to	O
use	O
in	O
a	O
probability	B-Method
model	I-Method
building	O
assumptions	O
about	O
the	O
participant	O
’s	O
context	O
.	O
	
While	O
this	O
might	O
be	O
a	O
useful	O
technique	O
to	O
identify	O
different	O
activities	O
,	O
it	O
might	O
not	O
be	O
applicable	O
to	O
participants	O
that	O
have	O
abnormal	O
working	O
hours	O
for	O
example	O
.	O
	
Stenneth	O
et	O
al	O
.	O
	
(	O
2011	O
)	O
,	O
on	O
the	O
other	O
hand	O
,	O
depends	O
on	O
live	O
bus	O
and	O
train	O
times	O
information	O
to	O
make	O
some	O
inferences	O
too	O
,	O
which	O
would	O
require	O
a	O
continuous	O
input	O
of	O
such	O
information	O
for	O
any	O
period	O
of	O
time	O
.	O
	
The	O
framework	O
we	O
propose	O
in	O
this	O
work	O
is	O
based	O
on	O
SVMs	B-Method
to	O
classify	O
GPS	B-Task
segments	I-Task
into	O
respective	O
transportation	O
modes	O
.	O
	
An	O
advantage	O
of	O
using	O
SVMs	B-Method
over	O
other	O
ML	B-Method
methods	I-Method
is	O
that	O
they	O
can	O
be	O
easily	O
trained	O
and	O
are	O
applied	O
directly	O
to	O
the	O
data	O
without	O
the	O
need	O
for	O
a	O
feature	B-Method
extraction	I-Method
process	I-Method
.	O
	
This	O
allows	O
us	O
to	O
learn	O
from	O
the	O
structure	O
of	O
the	O
data	O
.	O
	
The	O
proposed	O
method	O
uses	O
a	O
moving	O
window	O
across	O
every	O
group	O
of	O
consecutive	O
segments	O
in	O
order	O
to	O
capture	O
the	O
nature	O
of	O
participants	O
’	O
movements	O
though	O
different	O
transportation	O
modes	O
.	O
	
We	O
consider	O
all	O
the	O
possible	O
transportation	O
modes	O
,	O
while	O
testing	O
the	O
algorithm	O
to	O
avoid	O
any	O
mode	O
aggregations	O
or	O
exclusions	O
.	O
	
A	O
segmentation	B-Method
process	I-Method
is	O
applied	O
to	O
the	O
classified	O
data	O
after	O
the	O
initial	O
SVM	B-Method
inference	I-Method
is	O
performed	O
to	O
avoid	O
the	O
reliance	O
on	O
the	O
segmentation	O
accuracy	B-Metric
if	O
we	O
have	O
had	O
applied	O
the	O
segmentation	O
before	O
the	O
classification	B-Task
.	O
	
We	O
also	O
avoid	O
using	O
any	O
temporal	O
assumptions	O
to	O
ensure	O
the	O
robustness	O
of	O
our	O
algorithm	O
over	O
different	O
samples	O
.	O
	
A	O
transition	O
matrix	O
is	O
also	O
applied	O
to	O
assign	O
modes	O
in	O
the	O
case	O
of	O
potential	O
transitions	O
between	O
any	O
two	O
nonwalk	O
stages	O
.	O
	
We	O
finally	O
enhance	O
the	O
detection	B-Task
of	I-Task
underground	I-Task
stages	I-Task
by	O
using	O
the	O
underground	O
station	O
locations	O
with	O
any	O
lossof	O
-	O
signal	O
incidents	O
.	O
	
The	O
rest	O
of	O
this	O
section	O
provides	O
a	O
detailed	O
account	O
of	O
our	O
proposed	O
framework	O
and	O
a	O
summary	O
of	O
the	O
chosen	O
SVM	B-Method
model	I-Method
,	O
while	O
results	O
and	O
some	O
discussions	O
are	O
presented	O
in	O
Sections	O
5	O
and	O
6	O
.	O
4.2	O
.	O
	
Support	B-Method
Vector	I-Method
Machines	I-Method
(	O
SVMs	B-Method
)	O
classification	B-Method
and	O
model	B-Method
selection	I-Method
	
A	O
Support	B-Method
Vector	I-Method
Machine	I-Method
(	O
SVM	B-Method
)	O
is	O
a	O
non	B-Method
-	I-Method
probabilistic	I-Method
binary	I-Method
linear	I-Method
classifier	I-Method
.	O
	
A	O
SVM	B-Method
constructs	O
a	O
hyper	O
-	O
plane	O
or	O
a	O
set	O
of	O
hyper	O
-	O
planes	O
in	O
a	O
high	O
-	O
or	O
infinite	O
-	O
dimensional	O
space	O
to	O
achieve	O
the	O
largest	O
separation	O
between	O
different	O
classes	O
(	O
Steinwart	O
&	O
Christmann	O
,	O
2008	O
)	O
.	O
	
SVMs	B-Method
use	O
an	O
implicit	B-Method
mapping	I-Method
of	O
the	O
input	O
data	O
into	O
a	O
high	O
-	O
dimensional	O
feature	O
space	O
,	O
defined	O
by	O
a	O
kernel	B-Method
function	I-Method
(	O
a	O
function	O
returning	O
the	O
inner	O
product	O
(	O
U	O
(	O
x	O
)	O
,	O
U	O
(	O
x0	O
)	O
)	O
between	O
the	O
images	O
of	O
two	O
data	O
points	O
x	O
,	O
x0	O
in	O
the	O
feature	O
space	O
)	O
.	O
	
The	O
learning	O
then	O
takes	O
place	O
in	O
the	O
feature	O
space	O
,	O
and	O
the	O
data	O
points	O
only	O
appear	O
inside	O
dot	O
products	O
with	O
other	O
points	O
.	O
	
The	O
kernel	B-Method
functions	I-Method
return	O
the	O
inner	O
product	O
between	O
two	O
points	O
in	O
a	O
suitable	O
feature	O
space	O
,	O
hence	O
defining	O
a	O
notion	O
of	O
similarity	O
.	O
	
Kernel	B-Method
functions	I-Method
do	O
this	O
with	O
little	O
computational	B-Metric
cost	I-Metric
even	O
in	O
very	O
high	O
-	O
dimensional	O
spaces	O
,	O
since	O
it	O
does	O
not	O
involve	O
any	O
actual	O
computations	O
in	O
that	O
high	O
-	O
dimensional	O
space	O
,	O
which	O
is	O
a	O
major	O
advantage	O
of	O
using	O
SVMs	B-Method
.	O
	
In	O
this	O
research	O
,	O
we	O
use	O
a	O
Gaussian	B-Method
Radial	I-Method
Basis	I-Method
Function	I-Method
(	O
RBF	B-Method
)	O
kernel	O
(	O
Eq	O
.	O
(	O
7	O
)	O
)	O
.	O
	
The	O
Gaussian	O
and	O
Laplace	O
RBF	B-Method
kernel	O
is	O
a	O
general	B-Method
-	I-Method
purpose	I-Method
kernel	I-Method
used	O
when	O
there	O
is	O
no	O
prior	O
knowledge	O
about	O
the	O
data	O
.	O
	
kðx	O
;	O
x0Þ	O
¼	O
expð	O
rjjx	O
	
x0jj2Þ	O
ð7Þ	O
	
When	O
classifying	B-Task
,	O
Support	B-Method
Vector	I-Method
Machines	I-Method
separate	O
the	O
different	O
classes	O
of	O
data	O
by	O
a	O
hyper	O
-	O
plane	O
contained	O
by	O
the	O
decision	O
function	O
in	O
Eq	O
.	O
	
(	O
8	O
)	O
.	O
	
f	O
ðxÞ	O
¼	O
signðhw;UðxÞi	O
þ	O
	
bÞ	O
ð8Þ	O
	
And	O
the	O
SVM	B-Method
solution	I-Method
w	O
has	O
an	O
expansion	O
presented	O
in	O
Eq	O
.	O
	
(	O
9	O
)	O
,	O
in	O
terms	O
of	O
a	O
subset	O
of	O
training	O
patterns	O
that	O
lie	O
on	O
the	O
margin	O
.	O
	
These	O
training	O
patterns	O
,	O
called	O
support	O
vectors	O
,	O
carry	O
all	O
relevant	O
information	O
about	O
the	O
classification	B-Task
problem	I-Task
.	O
	
w	O
¼	O
Ri	O
/	O
iUðxiÞ	O
ð9Þ	O
	
The	O
optimal	O
hyper	O
-	O
plane	O
(	O
Vapnik	O
,	O
1998	O
)	O
will	O
be	O
the	O
one	O
with	O
the	O
maximal	O
margin	O
of	O
separation	O
between	O
two	O
classes	O
.	O
	
In	O
order	O
to	O
extend	O
this	O
binary	B-Method
SVM	I-Method
into	O
the	O
multi	B-Task
-	I-Task
class	I-Task
problem	I-Task
,	O
there	O
have	O
been	O
reformulations	O
of	O
the	O
support	B-Task
vector	I-Task
quadratic	I-Task
problem	I-Task
that	O
deal	O
with	O
more	O
than	O
two	O
classes	O
.	O
	
One	O
of	O
these	O
reformulations	O
,	O
introduced	O
by	O
Crammer	O
and	O
Singer	O
(	O
2000	O
)	O
and	O
referred	O
to	O
as	O
‘	O
‘	O
spoc	B-Method
-	I-Method
svc	I-Method
’	O
’	O
,	O
works	O
by	O
solving	O
a	O
single	O
optimization	B-Task
problem	I-Task
including	O
the	O
data	O
from	O
all	O
classes	O
.	O
	
The	O
algorithm	O
is	O
presented	O
in	O
Eq	O
.	O
	
(	O
10	O
)	O
.	O
	
Minimise	O
tðfwng	O
;	O
eÞ	O
¼	O
1	O
2	O
	
Xk	O
n¼1	O
jjwnjj2	O
þ	O
c	O
m	O
	
Xm	O
i¼1	O
	
ei	O
ð10Þ	O
	
subject	O
to	O
:	O
hUðxiÞ;wyii	O
hUðxiÞ;wni	O
bni	O
	
ei	O
ði	O
¼	O
1	O
;	O
.	O
.	O
.	O
;	O
mÞ	O
ð11Þ	O
where	O
the	O
decision	O
function	O
is	O
:	O
	
argmaxn¼1	O
;	O
...	O
	
;	O
khUðxiÞ;wni	O
ð12Þ	O
where	O
m	O
is	O
the	O
number	O
of	O
training	O
patterns	O
;	O
C	O
is	O
the	O
cost	O
parameter	O
.	O
	
The	O
cost	O
parameter	O
C	O
of	O
the	O
SVM	B-Method
formulation	I-Method
in	O
Eq	O
.	O
	
(	O
10	O
)	O
controls	O
the	O
penalty	O
paid	O
by	O
the	O
SVM	B-Method
for	O
misclassifying	O
a	O
training	O
point	O
and	O
thus	O
,	O
the	O
complexity	O
of	O
the	O
prediction	O
function	O
.	O
	
A	O
high	O
cost	O
value	O
C	O
will	O
force	O
the	O
SVM	B-Method
to	O
create	O
a	O
complex	O
enough	O
predic	O
-	O
tion	O
function	O
to	O
misclassify	O
as	O
few	O
training	O
points	O
as	O
possible	O
,	O
while	O
a	O
lower	O
cost	O
parameter	O
will	O
lead	O
to	O
a	O
simpler	O
prediction	O
function	O
.	O
	
The	O
best	O
C	O
selected	O
was	O
found	O
to	O
be	O
of	O
value	O
3	O
,	O
where	O
they	O
generated	O
the	O
best	O
results	O
.	O
	
This	O
value	O
is	O
not	O
too	O
small	O
where	O
it	O
allows	O
less	O
error	O
in	O
training	B-Task
(	O
due	O
to	O
GPS	O
errors	O
)	O
,	O
and	O
since	O
the	O
data	O
is	O
very	O
inseparable	O
,	O
yet	O
it	O
also	O
is	O
not	O
too	O
large	O
that	O
the	O
model	O
is	O
over	O
fit	O
.	O
	
A	O
k	B-Method
-	I-Method
fold	I-Method
cross	I-Method
validation	I-Method
on	O
the	O
training	O
data	O
of	O
value	O
3	O
is	O
performed	O
to	O
assess	O
the	O
quality	O
of	O
the	O
model	O
(	O
the	O
accuracy	B-Metric
rate	O
for	O
classification	B-Task
)	O
.	O
	
Another	O
advantage	O
of	O
SVMs	B-Method
and	O
kernel	B-Method
functions	I-Method
is	O
that	O
the	O
selected	O
kernel	B-Method
could	O
be	O
applied	O
directly	O
to	O
the	O
data	O
without	O
the	O
need	O
for	O
a	O
feature	B-Method
extraction	I-Method
process	I-Method
.	O
	
This	O
is	O
particularly	O
important	O
in	O
problems	O
where	O
a	O
lot	O
of	O
structure	O
of	O
the	O
data	O
is	O
lost	O
by	O
the	O
feature	B-Method
extraction	I-Method
process	I-Method
(	O
e.g.	O
the	O
sequence	O
of	O
a	O
GPS	O
trajectory	O
’s	O
movements	O
:	O
such	O
as	O
the	O
way	O
a	O
car	O
can	O
move	O
fast	O
,	O
stop	O
for	O
traffic	O
and	O
then	O
move	O
again	O
)	O
.	O
	
4.3	O
.	O
	
Window	B-Method
-	I-Method
based	I-Method
SVM	I-Method
classification	I-Method
	
The	O
loss	O
of	O
GPS	O
coverage	O
due	O
to	O
indoor	O
activity	O
causes	O
the	O
track	O
to	O
be	O
filled	O
with	O
long	O
gaps	O
with	O
no	O
movement	O
till	O
the	O
first	O
point	O
that	O
follows	O
that	O
gap	O
.	O
	
Therefore	O
,	O
the	O
first	O
step	O
is	O
to	O
segment	O
the	O
track	O
due	O
to	O
these	O
gaps	O
,	O
as	O
an	O
initial	O
segmentation	B-Task
process	I-Task
.	O
	
The	O
data	O
is	O
then	O
ready	O
and	O
prepared	O
for	O
the	O
SVM	B-Method
learning	I-Method
process	I-Method
and	O
classification	B-Task
,	O
being	O
a	O
supervised	B-Method
learning	I-Method
framework	I-Method
.	O
	
4.3.1	O
.	O
	
Multi	B-Task
-	I-Task
segment	I-Task
instance	I-Task
classification	I-Task
	
As	O
previously	O
mentioned	O
,	O
a	O
SVM	B-Method
constructs	O
a	O
hyper	O
-	O
plane	O
in	O
a	O
high	O
-	O
dimensional	O
space	O
to	O
achieve	O
the	O
largest	O
separation	O
between	O
different	O
classes	O
,	O
where	O
the	O
higher	O
the	O
dimension	O
,	O
the	O
better	O
the	O
separation	O
.	O
	
Consequently	O
,	O
SVM	B-Method
maps	O
original	O
finite	O
-	O
dimensional	O
space	O
into	O
a	O
much	O
higher	O
-	O
dimensional	O
space	O
to	O
increase	O
the	O
separation	O
.	O
	
In	O
this	O
work	O
,	O
we	O
enter	O
the	O
classification	B-Task
with	O
more	O
than	O
one	O
dimension	O
in	O
order	O
to	O
have	O
a	O
far	O
better	O
separation	O
to	O
start	O
with	O
.	O
	
Since	O
we	O
only	O
have	O
one	O
dimension	O
to	O
begin	O
with	O
(	O
speed	O
or	O
acceleration	O
)	O
,	O
we	O
aim	O
to	O
simulate	O
a	O
multi	O
-	O
dimensionality	O
to	O
study	O
sequences	O
of	O
GPS	O
trajectory	O
movements	O
rather	O
than	O
each	O
segment	O
on	O
its	O
own	O
(	O
e.g.	O
the	O
stop	O
and	O
go	O
motion	O
of	O
a	O
car	O
due	O
to	O
traffic	O
)	O
.	O
	
Therefore	O
,	O
the	O
data	O
is	O
divided	O
into	O
equal	O
-	O
sized	O
instances	O
of	O
several	O
segments	O
as	O
demonstrated	O
in	O
Fig	O
.	O
	
3b	O
.	O
	
This	O
simulates	O
the	O
multidimensionality	O
of	O
the	O
data	O
in	O
the	O
learning	B-Method
process	I-Method
which	O
is	O
an	O
advantage	O
of	O
SVM	B-Method
where	O
it	O
eliminates	O
the	O
need	O
for	O
feature	B-Task
extraction	I-Task
,	O
as	O
mentioned	O
in	O
the	O
previous	O
subsection	O
.	O
	
The	O
main	O
reason	O
for	O
using	O
instances	O
is	O
that	O
it	O
is	O
more	O
meaningful	O
to	O
study	O
a	O
certain	O
stage	O
of	O
a	O
trip	O
than	O
one	O
single	O
segment	O
value	O
;	O
this	O
exposes	O
the	O
learning	B-Method
process	I-Method
to	O
consequent	O
GPS	B-Material
data	I-Material
that	O
represent	O
the	O
variability	O
in	O
one	O
’s	O
manner	O
when	O
undertaking	O
each	O
transportation	O
mode	O
.	O
	
For	O
that	O
purpose	O
,	O
the	O
data	O
is	O
divided	O
into	O
two	O
thirds	O
for	O
learning	B-Task
and	O
one	O
third	O
for	O
validation	B-Task
purposes	I-Task
.	O
	
Data	O
instances	O
are	O
then	O
formed	O
out	O
of	O
the	O
learning	O
data	O
.	O
	
The	O
data	O
instances	O
then	O
enter	O
the	O
SVMs	B-Method
learning	I-Method
process	I-Method
using	O
the	O
stationary	B-Method
Gaussian	I-Method
kernel	I-Method
with	O
a	O
radial	B-Method
basis	I-Method
kernel	I-Method
function	I-Method
(	O
RBF	B-Method
)	O
using	O
the	O
multi	B-Method
-	I-Method
class	I-Method
method	I-Method
.	O
	
Fig	O
.	O
	
4	O
shows	O
several	O
window	O
(	O
instance	O
)	O
sizes	O
that	O
were	O
tested	O
.	O
	
A	O
suitable	O
size	O
from	O
3	O
to	O
8	O
segments	O
was	O
identified	O
to	O
be	O
the	O
most	O
adequate	O
.	O
	
As	O
might	O
be	O
noted	O
,	O
the	O
classification	B-Method
gives	O
better	O
results	O
for	O
longer	O
data	O
instances	O
.	O
	
However	O
,	O
a	O
longer	O
sequence	O
of	O
mixed	O
transportation	O
modes	O
could	O
introduce	O
higher	O
complexity	O
,	O
since	O
the	O
probability	O
of	O
having	O
several	O
modes	O
within	O
one	O
instance	O
is	O
introduced	O
,	O
which	O
will	O
over	O
-	O
complicate	O
the	O
classification	B-Task
problem	I-Task
.	O
	
Therefore	O
,	O
we	O
chose	O
to	O
use	O
the	O
small	O
-	O
sized	O
instance	O
that	O
still	O
contains	O
a	O
decent	O
number	O
of	O
segments	O
to	O
represent	O
a	O
realistic	O
sequence	O
;	O
in	O
this	O
case	O
three	O
.	O
	
The	O
multi	B-Method
-	I-Method
segment	I-Method
instance	I-Method
classification	I-Method
achieves	O
around	O
an	O
80	O
%	O
inference	O
accuracy	B-Metric
using	O
either	O
speed	O
or	O
acceleration	O
.	O
	
This	O
is	O
shown	O
in	O
the	O
confusion	O
matrix	O
in	O
Table	O
5	O
,	O
where	O
the	O
red	O
colour	O
lightness	O
varies	O
according	O
to	O
accuracy	B-Metric
of	O
the	O
classification	B-Task
for	O
the	O
diagonal	O
axis	O
(	O
darker	O
lightness	O
(	O
e.g.	O
car	O
)	O
reflects	O
higher	O
classification	O
accuracy	B-Metric
than	O
brighter	O
lightness	O
(	O
e.g.	O
bus	O
)	O
)	O
.	O
	
The	O
rest	O
of	O
lightness	O
variance	O
in	O
Table	O
5	O
reflects	O
the	O
confusion	O
in	O
classification	B-Task
between	O
different	O
classes	O
,	O
with	O
a	O
darker	O
lightness	O
reflecting	O
a	O
higher	O
confusion	O
(	O
e.g.	O
nearly	O
40	O
%	O
of	O
bus	O
mode	O
class	O
is	O
classified	O
as	O
car	O
)	O
.	O
	
There	O
appears	O
to	O
be	O
a	O
good	O
discrimination	O
between	O
the	O
train	O
mode	O
and	O
the	O
rest	O
,	O
yet	O
having	O
a	O
great	O
confusion	O
with	O
the	O
bus	O
mode	O
.	O
	
The	O
other	O
classes	O
seem	O
to	O
perform	O
well	O
,	O
except	O
the	O
bus	O
and	O
tube	O
modes	O
,	O
since	O
the	O
latter	O
often	O
consists	O
of	O
only	O
one	O
segment	O
and	O
therefore	O
,	O
it	O
is	O
merged	O
into	O
stages	O
that	O
are	O
dominated	O
by	O
other	O
modes	O
.	O
	
The	O
classification	B-Task
,	O
however	O
,	O
is	O
non	O
-	O
realistic	O
due	O
to	O
the	O
assumption	O
that	O
the	O
track	O
is	O
segmented	O
into	O
similar	O
-	O
mode	O
stages	O
.	O
	
4.3.2	O
.	O
	
Moving	B-Method
window	I-Method
SVM	I-Method
classification	I-Method
	
In	O
order	O
to	O
allow	O
going	O
into	O
the	O
segment	O
level	O
rather	O
than	O
merging	O
different	O
modes	O
into	O
the	O
same	O
stage	O
,	O
we	O
applied	O
a	O
fixed	O
-	O
length	O
moving	O
window	O
on	O
the	O
whole	O
track	O
;	O
sliding	O
that	O
window	O
segmentby	O
-	O
segment	O
along	O
the	O
track	O
’s	O
speed	O
values	O
once	O
and	O
once	O
more	O
for	O
acceleration	B-Task
.	O
	
Every	O
time	O
the	O
window	O
slides	O
,	O
a	O
classification	O
of	O
that	O
instance	O
of	O
data	O
is	O
performed	O
.	O
	
Figs	O
.	O
	
3c	O
and	O
5	O
illustrate	O
this	O
process	O
,	O
where	O
a	O
moving	B-Method
window	I-Method
classifies	O
each	O
3	O
-	O
sized	O
instance	O
moving	O
segment	O
-	O
by	O
-	O
segment	O
along	O
the	O
track	O
.	O
	
Table	O
5	O
Confusion	B-Metric
matrix	I-Metric
for	O
classification	B-Task
of	O
instances	O
of	O
3	O
segments	O
.	O
	
Actual	O
Total	O
count	O
Classification	O
Bus	O
Car	O
Cycle	O
Train	O
Tube	O
Walk	O
Bus	O
27.03	O
%	O
6.30	O
%	O
26.01	O
%	O
52.88	O
%	O
11.11	O
%	O
0.35	O
%	O
180	O
Car	O
39.86	O
%	O
76.72	O
%	O
11.56	O
%	O
2.88	O
%	O
55.56	O
%	O
2.12	O
%	O
523	O
Cycle	O
25.00	O
%	O
9.35	O
%	O
57.80	O
%	O
0.00	O
%	O
18.52	O
%	O
0.09	O
%	O
192	O
Train	O
0.68	O
%	O
0.38	O
%	O
0.00	O
%	O
44.23	O
%	O
0.00	O
%	O
0.00	O
%	O
49	O
Tube	O
4.05	O
%	O
4.96	O
%	O
0.58	O
%	O
0.00	O
%	O
3.70	O
%	O
0.27	O
%	O
37	O
Walk	O
3.38	O
%	O
2.29	O
%	O
4.05	O
%	O
0.00	O
%	O
11.11	O
%	O
97.17	O
%	O
	
1125	O
Total	O
count	O
148	O
524	O
173	O
104	O
27	O
1130	O
2106	O
	
Fig	O
.	O
5	O
.	O
	
A	O
moving	B-Method
window	I-Method
classifying	O
each	O
3	O
-	O
segment	O
instance	O
moving	O
segmen	O
t	O
-	O
by	O
-	O
segment	O
along	O
the	O
track	O
.	O
	
Once	O
the	O
classification	B-Task
is	O
performed	O
on	O
the	O
instances	O
,	O
the	O
classification	B-Task
is	O
passed	O
over	O
to	O
the	O
segment	O
level	O
and	O
the	O
change	O
points	O
in	O
the	O
track	O
are	O
identified	O
.	O
	
The	O
change	O
points	O
are	O
initially	O
identified	O
as	O
any	O
two	O
consequent	O
instances	O
with	O
different	O
modes	O
;	O
the	O
first	O
mode	O
being	O
a	O
and	O
the	O
second	O
b.	O
	
Then	O
,	O
the	O
algorithm	O
mines	O
into	O
the	O
last	O
instance	O
with	O
the	O
mode	O
a	O
and	O
assigns	O
the	O
classification	O
of	O
the	O
first	O
and	O
second	O
segments	O
as	O
a	O
,	O
and	O
the	O
third	O
’s	O
as	O
b.	O
	
The	O
same	O
happens	O
with	O
the	O
first	O
instance	O
with	O
the	O
b	O
mode	O
,	O
passing	O
the	O
classification	O
of	O
the	O
first	O
segment	O
as	O
mode	O
a	O
and	O
the	O
second	O
and	O
third	O
segments	O
as	O
mode	O
b.	O
4.4	O
.	O
	
Verification	B-Task
by	O
track	B-Task
segmentation	I-Task
	
The	O
framework	O
then	O
applies	O
a	O
verification	B-Method
process	I-Method
to	O
each	O
classified	O
arc	O
.	O
	
It	O
does	O
this	O
by	O
applying	O
two	O
processes	O
iteratively	O
.	O
	
The	O
first	O
of	O
these	O
two	O
processes	O
runs	O
through	O
each	O
change	O
point	O
in	O
the	O
segment	O
level	O
and	O
assesses	O
the	O
probability	O
of	O
mode	O
a	O
and	O
b	O
following	O
each	O
other	O
according	O
to	O
a	O
transition	O
matrix	O
(	O
Table	O
6	O
)	O
.	O
	
This	O
matrix	O
is	O
based	O
on	O
Zheng	O
et	O
al	O
.	O
	
(	O
2008	O
)	O
	
and	O
is	O
compiled	O
from	O
this	O
research	O
’s	O
data	O
.	O
	
The	O
matrix	O
contains	O
the	O
different	O
probabilities	O
of	O
switching	O
between	O
every	O
two	O
modes	O
,	O
which	O
is	O
a	O
good	O
indication	O
of	O
the	O
natural	O
flow	O
of	O
modal	O
mixes	O
.	O
	
As	O
could	O
be	O
noted	O
from	O
Table	O
6	O
,	O
almost	O
all	O
modes	O
are	O
followed	O
by	O
a	O
walk	B-Method
mode	I-Method
.	O
	
Therefore	O
,	O
the	O
algorithm	O
then	O
segments	O
the	O
track	O
into	O
several	O
stages	O
,	O
where	O
every	O
two	O
different	O
modal	O
stages	O
are	O
separated	O
by	O
a	O
walk	O
stage	O
.	O
	
However	O
,	O
some	O
stages	O
will	O
have	O
two	O
or	O
more	O
modes	O
.	O
	
In	O
this	O
case	O
,	O
the	O
most	O
dominant	O
mode	O
will	O
be	O
assigned	O
to	O
the	O
whole	O
stage	O
,	O
unless	O
in	O
the	O
case	O
of	O
two	O
modes	O
,	O
the	O
ratio	O
is	O
less	O
than	O
1:2	O
between	O
the	O
segments	O
of	O
a	O
and	O
b	O
or	O
vice	O
versa	O
.	O
	
This	O
creates	O
a	O
continuous	O
flow	O
of	O
modes	O
along	O
different	O
periods	O
of	O
the	O
track	O
.	O
	
4.5	O
.	O
	
Integrating	O
speed	O
and	O
acceleration	B-Method
results	O
As	O
we	O
demonstrated	O
earlier	O
in	O
Section	O
3	O
,	O
we	O
use	O
two	O
IVs	B-Method
to	O
conduct	O
this	O
classification	B-Task
;	O
namely	O
speed	B-Method
and	O
acceleration	B-Method
.	O
	
Therefore	O
,	O
we	O
run	O
the	O
classification	B-Method
framework	I-Method
once	O
for	O
speed	B-Method
and	O
once	O
for	O
acceleration	B-Method
assessing	O
the	O
performance	O
of	O
each	O
of	O
the	O
variables	O
in	O
the	O
process	O
.	O
	
We	O
integrate	O
the	O
results	O
of	O
the	O
best	O
mode	O
results	O
,	O
obtained	O
from	O
one	O
variable	O
,	O
with	O
the	O
best	O
from	O
the	O
other	O
.	O
	
This	O
relies	O
on	O
the	O
fact	O
that	O
each	O
variable	O
would	O
be	O
a	O
better	O
discriminator	O
for	O
some	O
modes	O
over	O
the	O
others	O
.	O
	
Section	O
5	O
describes	O
this	O
integration	O
in	O
details	O
along	O
with	O
the	O
results	O
obtained	O
from	O
each	O
variable	O
.	O
	
4.6	O
.	O
	
Underground	B-Task
segment	I-Task
identification	I-Task
	
In	O
London	O
,	O
the	O
occurrence	O
of	O
the	O
‘	O
‘	O
tube	O
’	O
’	O
(	O
underground	O
)	O
mode	O
could	O
be	O
overground	O
,	O
in	O
which	O
case	O
would	O
be	O
identifiable	O
at	O
the	O
SVM	B-Method
classification	I-Method
process	I-Method
from	O
speed	O
,	O
or	O
underground	O
,	O
where	O
an	O
alternative	O
process	O
needs	O
to	O
be	O
in	O
place	O
to	O
identify	O
these	O
instances	O
.	O
	
Around	O
45	O
%	O
of	O
the	O
tube	B-Method
network	I-Method
is	O
underground	O
,	O
however	O
,	O
75	O
%	O
of	O
the	O
trips	O
are	O
done	O
within	O
the	O
central	O
zones	O
where	O
the	O
network	O
is	O
underground	O
,	O
which	O
means	O
that	O
in	O
many	O
cases	O
there	O
will	O
not	O
be	O
any	O
GPS	O
fixes	O
attainable	O
at	O
several	O
areas	O
and	O
will	O
not	O
be	O
identified	O
using	O
the	O
SVM	B-Method
classification	I-Method
stage	I-Method
.	O
	
A	O
statistically	O
-	O
driven	O
time	O
-	O
distance	O
threshold	O
between	O
tube	B-Method
fixes	I-Method
is	O
tested	O
for	O
travel	O
occurring	O
above	O
a	O
certain	O
distance	O
without	O
coverage	O
though	O
not	O
exceeding	O
a	O
time	O
threshold	O
.	O
	
A	O
further	O
verification	O
test	O
is	O
applied	O
where	O
the	O
suspected	O
tube	O
-	O
entrance	O
and	O
tube	O
-	O
exit	O
fixes	O
are	O
tested	O
for	O
their	O
proximity	O
to	O
any	O
tube	O
stations	O
.	O
	
These	O
,	O
along	O
with	O
the	O
overground	O
classified	O
tube	O
segments	O
constitute	O
all	O
the	O
tube	O
-	O
classified	O
segments	O
within	O
the	O
framework	O
.	O
	
5	O
.	O
	
Results	O
Building	O
on	O
our	O
previous	O
work	O
,	O
we	O
increased	O
the	O
participant	O
numbers	O
to	O
81	O
(	O
as	O
recommended	O
in	O
Section	O
2	O
)	O
,	O
and	O
considered	O
acceleration	O
with	O
the	O
speed	O
for	O
this	O
classification	B-Task
problem	I-Task
.	O
	
The	O
results	O
of	O
the	O
moving	B-Method
window	I-Method
algorithm	I-Method
using	O
speed	B-Method
reveal	O
an	O
accuracy	B-Metric
of	O
72	O
%	O
and	O
83	O
%	O
using	O
acceleration	O
.	O
	
This	O
demonstrates	O
a	O
considerable	O
improvement	O
over	O
both	O
the	O
previous	O
accuracies	B-Metric
of	O
the	O
multi	B-Task
-	I-Task
segment	I-Task
instances	I-Task
,	O
without	O
applying	O
a	O
moving	B-Method
window	I-Method
approach	I-Method
.	O
	
It	O
also	O
has	O
the	O
advantage	O
of	O
classifying	O
on	O
a	O
segment	O
level	O
-	O
basis	O
,	O
rather	O
than	O
only	O
classifying	O
instances	O
.	O
	
Tables	O
7	O
and	O
8	O
show	O
the	O
confusion	B-Metric
matrices	I-Metric
of	O
this	O
classification	B-Method
using	O
speed	O
and	O
acceleration	O
respectively	O
.	O
	
Some	O
speed	B-Metric
classification	I-Metric
errors	I-Metric
could	O
be	O
noted	O
,	O
such	O
as	O
the	O
car	O
mode	O
with	O
other	O
transportation	O
modes	O
,	O
while	O
some	O
modes	O
,	O
such	O
as	O
the	O
walk	O
mode	O
,	O
seem	O
to	O
be	O
better	O
classified	O
using	O
speed	O
.	O
	
In	O
order	O
to	O
get	O
a	O
better	O
accuracy	B-Metric
measure	O
for	O
the	O
classification	B-Task
,	O
we	O
perform	O
an	O
inter	B-Metric
-	I-Metric
reliability	I-Metric
analysis	I-Metric
using	O
the	O
Kappa	B-Metric
statistic	I-Metric
to	O
determine	O
consistency	O
among	O
coders	O
.	O
	
Cohen	B-Metric
’s	I-Metric
Kappa	I-Metric
is	O
generally	O
thought	O
to	O
be	O
a	O
more	O
robust	O
measure	O
than	O
simple	O
percentage	B-Metric
agreement	I-Metric
calculation	I-Metric
,	O
since	O
K	O
takes	O
into	O
account	O
the	O
agreement	O
occurring	O
by	O
chance	O
(	O
Carletta	O
,	O
1996	O
)	O
.	O
	
The	O
Kappa	B-Metric
coefficient	I-Metric
(	O
K	O
)	O
measures	O
pairwise	B-Metric
agreement	I-Metric
among	O
a	O
set	O
of	O
coders	O
making	O
category	O
judgments	O
,	O
correcting	O
for	O
expected	O
chance	O
agreement	O
,	O
and	O
hence	O
is	O
thought	O
to	O
be	O
a	O
good	O
measure	O
of	O
any	O
classification	O
’s	O
accuracy	B-Metric
.	O
	
Kappa	B-Metric
is	O
calculated	O
from	O
Eq	O
.	O
	
(	O
13	O
)	O
.	O
	
K	O
¼	O
	
PðAÞ	O
PðEÞ	O
1	O
PðEÞ	O
ð13Þ	O
where	O
P	O
(	O
A	O
)	O
is	O
the	O
proportion	O
of	O
times	O
that	O
the	O
coders	O
agree	O
;	O
P	O
(	O
E	O
)	O
is	O
the	O
proportion	O
of	O
times	O
that	O
the	O
coders	O
we	O
expect	O
them	O
to	O
agree	O
by	O
chance	O
.	O
	
As	O
illustrated	O
in	O
Table	O
9	O
,	O
the	O
inter	B-Metric
-	I-Metric
rater	I-Metric
reliability	I-Metric
for	O
speed	B-Method
was	O
found	O
to	O
be	O
0.586	O
(	O
p	O
<	O
0.001	O
)	O
,	O
95	O
%	O
CI	O
(	O
0.578	O
,	O
0.594	O
)	O
and	O
for	O
acceleration	B-Method
0.743	O
(	O
p	O
<	O
0.001	O
)	O
,	O
95	O
%	O
CI	O
(	O
0.735	O
,	O
0.751	O
)	O
.	O
	
That	O
is	O
to	O
say	O
,	O
K	O
val	O
-	O
ues	O
reflect	O
a	O
moderate	O
agreement	O
for	O
speed	B-Metric
and	O
a	O
substantial	O
agreement	O
for	O
acceleration	B-Method
,	O
according	O
to	O
rule	O
of	O
thumb	O
values	O
of	O
Kappa	O
(	O
Landis	O
&	O
Koch	O
,	O
1980	O
)	O
.	O
	
5.1	O
.	O
	
Type	O
I	O
and	O
II	O
errors	O
Table	O
10	O
shows	O
the	O
difference	O
between	O
the	O
accuracies	B-Method
obtained	O
from	O
classification	B-Method
using	O
acceleration	B-Task
and	O
speed	B-Task
classification	I-Task
.	O
	
The	O
red	O
values	O
express	O
the	O
excellence	O
of	O
acceleration	B-Task
classification	I-Task
over	O
speed	O
and	O
vice	O
versa	O
for	O
the	O
blue	O
values	O
.	O
	
As	O
previously	O
noted	O
,	O
it	O
seems	O
very	O
obvious	O
that	O
some	O
modes	O
,	O
such	O
as	O
the	O
car	O
mode	O
,	O
are	O
better	O
identified	O
using	O
acceleration	O
and	O
less	O
misclassified	O
as	O
other	O
modes	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
other	O
modes	O
,	O
such	O
as	O
walk	O
,	O
are	O
less	O
confused	O
for	O
using	O
speed	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
the	O
rest	O
of	O
the	O
modes	O
have	O
little	O
difference	O
in	O
results	O
from	O
using	O
either	O
IVs	B-Method
.	O
	
An	O
interesting	O
confusion	O
,	O
however	O
,	O
occurs	O
between	O
the	O
train	O
and	O
the	O
car	O
results	O
,	O
where	O
speed	B-Method
appears	O
to	O
have	O
a	O
better	O
performance	O
by	O
not	O
classifying	O
train	O
as	O
car	O
(	O
8	O
%	O
better	O
)	O
,	O
while	O
acceleration	B-Method
performs	O
better	O
without	O
confusing	O
car	O
instances	O
with	O
a	O
train	B-Method
classification	I-Method
(	O
20	O
%	O
better	O
)	O
.	O
	
It	O
could	O
also	O
be	O
noted	O
from	O
the	O
main	O
diagonal	O
of	O
Table	O
10	O
that	O
bus	O
,	O
car	O
and	O
walk	O
are	O
better	O
classified	O
using	O
acceleration	O
,	O
while	O
cycle	O
,	O
train	O
and	O
tube	O
are	O
higher	O
classified	O
using	O
speed	O
.	O
	
This	O
does	O
not	O
mean	O
that	O
each	O
group	O
of	O
modes	O
should	O
be	O
classified	O
using	O
their	O
respective	O
IV	O
,	O
but	O
it	O
only	O
suggests	O
that	O
they	O
are	O
over	O
classified	O
using	O
these	O
specific	O
IVs	O
.	O
	
The	O
trick	O
here	O
is	O
to	O
select	O
the	O
IV	O
that	O
better	O
discriminates	O
the	O
classified	O
mode	O
from	O
the	O
rest	O
.	O
	
That	O
is	O
to	O
be	O
achieved	O
by	O
selecting	O
the	O
IV	B-Method
that	O
achieves	O
a	O
higher	O
classification	B-Task
for	O
each	O
mode	O
,	O
while	O
not	O
over	O
-	O
classifying	O
that	O
specific	O
mode	O
and	O
hence	O
,	O
decreasing	O
the	O
accuracy	B-Metric
of	O
the	O
other	O
modes	O
.	O
	
This	O
would	O
also	O
have	O
the	O
advantage	O
of	O
accounting	O
for	O
the	O
effect	O
of	O
the	O
sample	O
size	O
of	O
each	O
mode	O
.	O
	
This	O
could	O
be	O
achieved	O
by	O
testing	O
whether	O
a	O
certain	O
variable	O
on	O
average	O
dominates	O
the	O
row	O
and	O
column	O
of	O
each	O
mode	O
in	O
Table	O
10	O
(	O
actual	O
and	O
classified	O
mode	O
)	O
,	O
while	O
if	O
acceleration	O
dominates	O
in	O
the	O
column	O
level	O
	
(	O
Type	O
I	O
error	O
)	O
but	O
speed	O
dominates	O
in	O
the	O
row	O
level	O
(	O
Type	O
II	O
error	O
)	O
(	O
such	O
as	O
walk	O
)	O
,	O
that	O
would	O
mean	O
that	O
acceleration	O
is	O
only	O
over	O
-	O
classifying	O
that	O
specific	O
mode	O
.	O
	
This	O
calculation	O
results	O
in	O
Table	O
11	O
,	O
where	O
each	O
mode	O
is	O
assessed	O
for	O
the	O
Type	O
I	O
and	O
II	O
errors	O
’	O
excellence	O
of	O
one	O
IV	O
over	O
the	O
other	O
,	O
given	O
that	O
red	O
represents	O
an	O
excellence	O
of	O
acceleration	O
and	O
blue	O
for	O
speed	O
.	O
	
5.2	O
.	O
	
Integration	B-Task
results	O
As	O
can	O
be	O
noted	O
from	O
Table	O
11	O
,	O
acceleration	O
seems	O
to	O
produce	O
better	O
results	O
than	O
speed	O
for	O
most	O
transportation	O
modes	O
with	O
the	O
exception	O
of	O
walk	O
and	O
cycle	O
,	O
achieving	O
an	O
average	O
supremacy	O
of	O
nearly	O
14	O
%	O
accuracy	B-Metric
over	O
speed	B-Method
.	O
	
The	O
inter	B-Metric
-	I-Metric
rater	I-Metric
reliability	I-Metric
for	O
the	O
raters	O
was	O
found	O
to	O
be	O
K	O
=	O
0.802	O
(	O
p	O
<	O
0.001	O
)	O
,	O
95	O
%	O
CI	O
(	O
0.794	O
,	O
0.810	O
)	O
,	O
which	O
reflects	O
almost	O
perfect	O
agreement	O
.	O
	
We	O
adopted	O
these	O
results	O
into	O
our	O
final	O
integrated	O
result	O
of	O
the	O
inference	B-Task
,	O
resulting	O
in	O
an	O
accuracy	B-Metric
of	O
88	O
%	O
.	O
	
Table	O
12	O
shows	O
the	O
confusion	B-Metric
matrix	I-Metric
of	O
this	O
integration	O
,	O
demonstrating	O
a	O
better	O
separation	O
specifically	O
for	O
the	O
car	B-Task
,	I-Task
train	I-Task
and	I-Task
walk	I-Task
modes	I-Task
.	O
	
Some	O
modes	O
appear	O
to	O
be	O
performing	O
better	O
than	O
others	O
.	O
	
We	O
could	O
note	O
from	O
Table	O
12	O
that	O
the	O
car	O
,	O
train	O
and	O
walk	O
modes	O
are	O
discriminated	O
very	O
well	O
using	O
this	O
classification	O
.	O
	
In	O
contrast	O
,	O
the	O
cycle	O
mode	O
seems	O
to	O
be	O
classified	O
moderately	O
while	O
the	O
bus	O
and	O
tube	O
modes	O
still	O
require	O
enhancement	O
.	O
	
This	O
could	O
be	O
carried	O
out	O
using	O
a	O
network	B-Method
matching	I-Method
process	I-Method
to	O
both	O
the	O
bus	B-Method
and	I-Method
tube	I-Method
networks	I-Method
.	O
	
This	O
further	O
work	O
is	O
currently	O
in	O
process	O
for	O
enhancing	O
the	O
classification	B-Task
of	O
these	O
two	O
latter	O
modes	O
.	O
	
6	O
.	O
	
Conclusions	O
	
In	O
this	O
work	O
we	O
discuss	O
the	O
classification	B-Task
problem	I-Task
of	I-Task
inferring	I-Task
transportation	I-Task
mode	I-Task
from	O
sparse	B-Material
GPS	I-Material
data	I-Material
.	O
	
We	O
first	O
provide	O
the	O
speed	O
.	O
	
means	O
for	O
assessing	O
the	O
significance	O
of	O
each	O
potential	O
independent	O
variable	O
that	O
could	O
be	O
used	O
for	O
this	O
process	O
.	O
	
We	O
provide	O
a	O
statistical	B-Task
evaluation	I-Task
using	O
the	O
data	O
collected	O
by	O
this	O
research	O
within	O
Greater	O
London	O
as	O
a	O
case	O
study	O
.	O
	
The	O
outcome	O
of	O
this	O
process	O
provides	O
evidence	O
that	O
speed	O
and	O
acceleration	O
are	O
the	O
favourable	O
candidates	O
to	O
undergo	O
this	O
classification	B-Task
problem	I-Task
showing	O
a	O
great	O
discriminatory	O
power	O
in	O
this	O
context	O
.	O
	
However	O
,	O
each	O
of	O
these	O
variables	O
is	O
also	O
proven	O
to	O
be	O
fit	O
for	O
identifying	O
certain	O
modes	O
;	O
car	O
mode	O
being	O
better	O
identified	O
using	O
acceleration	O
and	O
walk	O
using	O
speed	O
as	O
examples	O
.	O
	
We	O
also	O
provide	O
a	O
brief	O
summary	O
of	O
the	O
sample	B-Task
size	I-Task
calculation	I-Task
process	I-Task
required	O
for	O
the	O
context	O
of	O
this	O
study	O
.	O
	
Building	O
on	O
previous	O
attempts	O
and	O
on	O
the	O
results	O
of	O
the	O
statistical	B-Metric
evaluation	I-Metric
,	O
we	O
provide	O
in	O
this	O
study	O
a	O
novel	O
approach	O
for	O
inferring	O
the	O
transportation	B-Task
mode	I-Task
from	O
sparse	B-Material
GPS	I-Material
data	I-Material
without	O
any	O
extra	O
information	O
.	O
	
In	O
contrast	O
to	O
existing	O
techniques	O
,	O
our	O
approach	O
uses	O
one	O
consistent	B-Method
framework	I-Method
based	O
on	O
Support	B-Method
Vector	I-Method
Machines	I-Method
(	O
SVMs	B-Method
)	O
to	O
classify	O
each	O
segment	O
into	O
its	O
respective	O
transportation	O
mode	O
.	O
	
Unlike	O
many	O
previous	O
attempts	O
,	O
the	O
framework	O
tends	O
to	O
study	O
the	O
whole	O
pattern	O
of	O
the	O
trajectory	O
motion	O
during	O
the	O
whole	O
trip	O
using	O
the	O
advantage	O
of	O
being	O
an	O
offline	B-Task
process	I-Task
.	O
	
The	O
framework	O
does	O
this	O
by	O
first	O
classifying	O
several	O
consequent	O
segments	O
together	O
(	O
named	O
as	O
an	O
instance	O
)	O
with	O
a	O
certain	O
window	O
size	O
,	O
and	O
sliding	O
this	O
window	O
along	O
the	O
whole	O
track	O
classifying	O
each	O
instance	O
.	O
	
The	O
most	O
adequate	O
window	O
size	O
was	O
found	O
to	O
be	O
of	O
3	O
segments	O
length	O
.	O
	
The	O
classification	B-Task
is	O
then	O
assigned	O
to	O
the	O
segment	O
level	O
to	O
each	O
of	O
the	O
segments	O
participating	O
in	O
each	O
instance	O
.	O
	
In	O
order	O
to	O
preserve	O
the	O
cohesiveness	O
of	O
the	O
classification	O
of	O
the	O
track	O
,	O
we	O
segment	O
the	O
track	O
into	O
stages	O
of	O
different	O
modes	O
,	O
each	O
two	O
stages	O
separated	O
by	O
a	O
walk	O
stage	O
,	O
except	O
for	O
certain	O
scenarios	O
where	O
we	O
then	O
apply	O
a	O
transition	B-Method
matrix	I-Method
to	O
assess	O
the	O
modal	O
mix	O
occurrence	O
probability	O
.	O
	
A	O
statistically	O
-	O
driven	O
time	O
-	O
distance	O
threshold	O
between	O
tube	O
fixes	O
is	O
then	O
applied	O
for	O
travel	O
occurring	O
above	O
a	O
certain	O
distance	O
without	O
coverage	O
,	O
though	O
not	O
exceeding	O
a	O
time	O
threshold	O
to	O
identify	O
the	O
tube	O
mode	O
.	O
	
Our	O
model	O
achieves	O
relatively	O
good	O
accuracies	B-Metric
using	O
either	O
speed	O
or	O
acceleration	O
.	O
	
However	O
,	O
building	O
on	O
the	O
findings	O
of	O
the	O
statistical	B-Method
evaluation	I-Method
and	O
the	O
SVM	B-Method
classification	I-Method
,	O
results	O
from	O
the	O
classification	B-Task
using	O
both	O
speed	O
and	O
acceleration	O
are	O
combined	O
together	O
.	O
	
This	O
is	O
based	O
on	O
the	O
fact	O
that	O
each	O
variable	O
is	O
better	O
at	O
classifying	O
certain	O
modes	O
.	O
	
Finally	O
,	O
an	O
accuracy	B-Metric
of	O
88	O
%	O
is	O
achieved	O
from	O
the	O
combined	O
result	O
at	O
segment	O
level	O
with	O
a	O
Kappa	B-Metric
statistic	I-Metric
reflecting	O
almost	O
perfect	O
agreement	O
.	O
	
A	O
good	O
segmentation	B-Task
is	O
also	O
achieved	O
between	O
different	O
modal	O
stages	O
;	O
which	O
enhances	O
the	O
accuracy	B-Metric
of	O
the	O
classification	B-Task
.	O
	
Further	O
work	O
shall	O
be	O
carried	O
out	O
attempting	O
to	O
further	O
separate	O
similar	O
modes	O
,	O
such	O
as	O
bus	O
and	O
tube	O
modes	O
using	O
network	B-Method
matching	I-Method
from	O
the	O
rest	O
.	O
	
The	O
accuracy	B-Metric
of	O
the	O
device	O
being	O
used	O
and	O
its	O
firmware	O
also	O
appeared	O
to	O
have	O
some	O
effect	O
on	O
the	O
classification	B-Task
results	O
that	O
could	O
be	O
explored	O
in	O
further	O
work	O
.	O
	
Finally	O
,	O
different	O
rate	O
of	O
GPS	B-Material
data	I-Material
collection	O
could	O
be	O
compared	O
to	O
perform	O
this	O
classification	B-Task
.	O
	
Acknowledgments	O
	
We	O
would	O
like	O
to	O
express	O
our	O
gratitude	O
to	O
u	O
-	O
blox	O
and	O
EPSRC	O
,	O
the	O
sponsoring	O
bodies	O
for	O
this	O
research	O
,	O
specifically	O
Chris	O
Marshall	O
for	O
his	O
invaluable	O
ideas	O
and	O
support	O
.	O
	
document	O
:	O
Convolutional	B-Method
Neural	I-Method
Network	I-Method
Architectures	I-Method
for	O
Matching	B-Task
Natural	I-Task
Language	I-Task
Sentences	I-Task
	
Semantic	B-Task
matching	I-Task
is	O
of	O
central	O
importance	O
to	O
many	O
natural	B-Task
language	I-Task
tasks	I-Task
.	O
	
A	O
successful	O
matching	B-Method
algorithm	I-Method
needs	O
to	O
adequately	O
model	O
the	O
internal	O
structures	O
of	O
language	O
objects	O
and	O
the	O
interaction	O
between	O
them	O
.	O
	
As	O
a	O
step	O
toward	O
this	O
goal	O
,	O
we	O
propose	O
convolutional	B-Method
neural	I-Method
network	I-Method
models	I-Method
for	O
matching	O
two	O
sentences	O
,	O
by	O
adapting	O
the	O
convolutional	B-Method
strategy	I-Method
in	O
vision	B-Task
and	O
speech	B-Task
.	O
	
The	O
proposed	O
models	O
not	O
only	O
nicely	O
represent	O
the	O
hierarchical	O
structures	O
of	O
sentences	O
with	O
their	O
layer	B-Method
-	I-Method
by	I-Method
-	I-Method
layer	I-Method
composition	I-Method
and	O
pooling	B-Method
,	O
but	O
also	O
capture	O
the	O
rich	O
matching	O
patterns	O
at	O
different	O
levels	O
.	O
	
Our	O
models	O
are	O
rather	O
generic	O
,	O
requiring	O
no	O
prior	O
knowledge	O
on	O
language	O
,	O
and	O
can	O
hence	O
be	O
applied	O
to	O
matching	B-Task
tasks	I-Task
of	O
different	O
nature	O
and	O
in	O
different	O
languages	O
.	O
	
The	O
empirical	O
study	O
on	O
a	O
variety	O
of	O
matching	B-Task
tasks	I-Task
demonstrates	O
the	O
efficacy	O
of	O
the	O
proposed	O
model	O
on	O
a	O
variety	O
of	O
matching	B-Task
tasks	I-Task
and	O
its	O
superiority	O
to	O
competitor	O
models	O
.	O
	
section	O
:	O
Introduction	O
	
Matching	B-Task
two	O
potentially	O
heterogenous	O
language	O
objects	O
is	O
central	O
to	O
many	O
natural	B-Task
language	I-Task
applications	I-Task
.	O
	
It	O
generalizes	O
the	O
conventional	O
notion	O
of	O
similarity	O
(	O
e.g.	O
,	O
in	O
paraphrase	B-Task
identification	I-Task
)	O
or	O
relevance	B-Task
(	O
e.g.	O
,	O
in	O
information	B-Task
retrieval	I-Task
)	O
,	O
since	O
it	O
aims	O
to	O
model	O
the	O
correspondence	O
between	O
“	O
linguistic	O
objects	O
”	O
of	O
different	O
nature	O
at	O
different	O
levels	O
of	O
abstractions	O
.	O
	
Examples	O
include	O
top	B-Task
-	I-Task
re	I-Task
-	I-Task
ranking	I-Task
in	O
machine	B-Task
translation	I-Task
(	O
e.g.	O
,	O
comparing	O
the	O
meanings	O
of	O
a	O
French	O
sentence	O
and	O
an	O
English	O
sentence	O
)	O
and	O
dialogue	O
(	O
e.g.	O
,	O
evaluating	O
the	O
appropriateness	O
of	O
a	O
response	O
to	O
a	O
given	O
utterance	O
)	O
.	O
	
Natural	O
language	O
sentences	O
have	O
complicated	O
structures	O
,	O
both	O
sequential	O
and	O
hierarchical	O
,	O
that	O
are	O
essential	O
for	O
understanding	O
them	O
.	O
	
A	O
successful	O
sentence	B-Method
-	I-Method
matching	I-Method
algorithm	I-Method
therefore	O
needs	O
to	O
capture	O
not	O
only	O
the	O
internal	O
structures	O
of	O
sentences	O
but	O
also	O
the	O
rich	O
patterns	O
in	O
their	O
interactions	O
.	O
	
Towards	O
this	O
end	O
,	O
we	O
propose	O
deep	B-Method
neural	I-Method
network	I-Method
models	I-Method
,	O
which	O
adapt	O
the	O
convolutional	B-Method
strategy	I-Method
(	O
proven	O
successful	O
on	O
image	B-Task
and	O
speech	B-Task
)	O
to	O
natural	B-Task
language	I-Task
.	O
	
To	O
further	O
explore	O
the	O
relation	O
between	O
representing	O
sentences	O
and	O
matching	O
them	O
,	O
we	O
devise	O
a	O
novel	O
model	O
that	O
can	O
naturally	O
host	O
both	O
the	O
hierarchical	B-Method
composition	I-Method
for	O
sentences	O
and	O
the	O
simple	O
-	O
to	O
-	O
comprehensive	B-Method
fusion	I-Method
of	I-Method
matching	I-Method
patterns	I-Method
with	O
the	O
same	O
convolutional	B-Method
architecture	I-Method
.	O
	
Our	O
model	O
is	O
generic	O
,	O
requiring	O
no	O
prior	O
knowledge	O
of	O
natural	O
language	O
(	O
e.g.	O
,	O
parse	O
tree	O
)	O
and	O
putting	O
essentially	O
no	O
constraints	O
on	O
the	O
matching	B-Task
tasks	I-Task
.	O
	
This	O
is	O
part	O
of	O
our	O
continuing	O
effort	O
in	O
understanding	O
natural	B-Task
language	I-Task
objects	I-Task
and	O
the	O
matching	B-Task
between	O
them	O
.	O
	
Our	O
main	O
contributions	O
can	O
be	O
summarized	O
as	O
follows	O
.	O
	
First	O
,	O
we	O
devise	O
novel	O
deep	B-Method
convolutional	I-Method
network	I-Method
architectures	I-Method
that	O
can	O
naturally	O
combine	O
1	O
)	O
the	O
hierarchical	B-Method
sentence	I-Method
modeling	I-Method
through	O
layer	B-Method
-	I-Method
by	I-Method
-	I-Method
layer	I-Method
composition	I-Method
and	O
pooling	B-Method
,	O
and	O
2	O
)	O
the	O
capturing	O
of	O
the	O
rich	O
matching	O
patterns	O
at	O
different	O
levels	O
of	O
abstraction	O
;	O
Second	O
,	O
we	O
perform	O
extensive	O
empirical	O
study	O
on	O
tasks	O
with	O
different	O
scales	O
and	O
characteristics	O
,	O
and	O
demonstrate	O
the	O
superior	O
power	O
of	O
the	O
proposed	O
architectures	O
over	O
competitor	O
methods	O
.	O
	
paragraph	O
:	O
Roadmap	O
	
We	O
start	O
by	O
introducing	O
a	O
convolution	B-Method
network	I-Method
in	O
Section	O
[	O
reference	O
]	O
as	O
the	O
basic	O
architecture	O
for	O
sentence	B-Task
modeling	I-Task
,	O
and	O
how	O
it	O
is	O
related	O
to	O
existing	O
sentence	B-Method
models	I-Method
.	O
	
Based	O
on	O
that	O
,	O
in	O
Section	O
[	O
reference	O
]	O
,	O
we	O
propose	O
two	O
architectures	O
for	O
sentence	B-Task
matching	I-Task
,	O
with	O
a	O
detailed	O
discussion	O
of	O
their	O
relation	O
.	O
	
In	O
Section	O
[	O
reference	O
]	O
,	O
we	O
briefly	O
discuss	O
the	O
learning	O
of	O
the	O
proposed	O
architectures	O
.	O
	
Then	O
in	O
Section	O
[	O
reference	O
]	O
,	O
we	O
report	O
our	O
empirical	O
study	O
,	O
followed	O
by	O
a	O
brief	O
discussion	O
of	O
related	O
work	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
Convolutional	B-Method
Sentence	I-Method
Model	I-Method
	
We	O
start	O
with	O
proposing	O
a	O
new	O
convolutional	B-Method
architecture	I-Method
for	O
modeling	B-Task
sentences	I-Task
.	O
	
As	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
it	O
takes	O
as	O
input	O
the	O
embedding	O
of	O
words	O
(	O
often	O
trained	O
beforehand	O
with	O
unsupervised	B-Method
methods	I-Method
)	O
in	O
the	O
sentence	O
aligned	O
sequentially	O
,	O
and	O
summarize	O
the	O
meaning	O
of	O
a	O
sentence	O
through	O
layers	O
of	O
convolution	B-Method
and	O
pooling	B-Method
,	O
until	O
reaching	O
a	O
fixed	B-Method
length	I-Method
vectorial	I-Method
representation	I-Method
in	O
the	O
final	O
layer	O
.	O
	
As	O
in	O
most	O
convolutional	B-Method
models	I-Method
,	O
we	O
use	O
convolution	B-Method
units	I-Method
with	O
a	O
local	O
“	O
receptive	O
field	O
”	O
and	O
shared	O
weights	O
,	O
but	O
we	O
design	O
a	O
large	O
feature	O
map	O
to	O
adequately	O
model	O
the	O
rich	O
structures	O
in	O
the	O
composition	O
of	O
words	O
.	O
	
paragraph	O
:	O
Convolution	O
	
As	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
the	O
convolution	B-Method
in	I-Method
Layer	I-Method
-	I-Method
1	I-Method
operates	O
on	O
sliding	O
windows	O
of	O
words	O
(	O
width	O
)	O
,	O
and	O
the	O
convolutions	O
in	O
deeper	O
layers	O
are	O
defined	O
in	O
a	O
similar	O
way	O
.	O
	
Generally	O
,	O
with	O
sentence	B-Method
input	I-Method
,	O
the	O
convolution	B-Method
unit	I-Method
for	O
feature	B-Method
map	I-Method
of	O
type	O
-	O
	
(	O
among	O
of	O
them	O
)	O
on	O
Layer	O
-	O
is	O
and	O
its	O
matrix	O
form	O
is	O
,	O
where	O
gives	O
the	O
output	O
of	O
feature	O
map	O
of	O
type	O
-	O
for	O
location	O
in	O
Layer	O
-	O
;	O
is	O
the	O
parameters	O
for	O
on	O
Layer	O
-	O
,	O
with	O
matrix	O
form	O
;	O
is	O
the	O
activation	O
function	O
(	O
e.g.	O
,	O
Sigmoid	B-Method
or	O
Relu	B-Method
)	O
denotes	O
the	O
segment	O
of	O
Layer	O
-	O
for	O
the	O
convolution	O
at	O
location	O
,	O
while	O
concatenates	O
the	O
vectors	O
for	O
(	O
width	O
of	O
sliding	O
window	O
)	O
words	O
from	O
sentence	O
input	O
.	O
	
paragraph	O
:	O
Max	B-Method
-	I-Method
Pooling	I-Method
	
We	O
take	O
a	O
max	B-Method
-	I-Method
pooling	I-Method
in	O
every	O
two	O
-	O
unit	O
window	O
for	O
every	O
,	O
after	O
each	O
convolution	O
The	O
effects	O
of	O
pooling	B-Method
are	O
two	O
-	O
fold	O
:	O
1	O
)	O
it	O
shrinks	O
the	O
size	O
of	O
the	O
representation	O
by	O
half	O
,	O
thus	O
quickly	O
absorbs	O
the	O
differences	O
in	O
length	O
for	O
sentence	B-Task
representation	I-Task
,	O
and	O
2	O
)	O
it	O
filters	O
out	O
undesirable	O
composition	O
of	O
words	O
(	O
see	O
Section	O
[	O
reference	O
]	O
for	O
some	O
analysis	O
)	O
.	O
	
paragraph	O
:	O
Length	O
Variability	O
	
The	O
variable	O
length	O
of	O
sentences	O
in	O
a	O
fairly	O
broad	O
range	O
can	O
be	O
readily	O
handled	O
with	O
the	O
convolution	B-Method
and	I-Method
pooling	I-Method
strategy	I-Method
.	O
	
More	O
specifically	O
,	O
we	O
put	O
all	O
-	O
zero	O
padding	O
vectors	O
after	O
the	O
last	O
word	O
of	O
the	O
sentence	O
until	O
the	O
maximum	O
length	O
.	O
	
To	O
eliminate	O
the	O
boundary	O
effect	O
caused	O
by	O
the	O
great	O
variability	O
of	O
sentence	O
lengths	O
,	O
we	O
add	O
to	O
the	O
convolutional	B-Method
unit	I-Method
a	O
gate	O
which	O
sets	O
the	O
output	O
vectors	O
to	O
all	O
-	O
zeros	O
if	O
the	O
input	O
is	O
all	O
zeros	O
.	O
	
For	O
any	O
given	O
sentence	O
input	O
,	O
the	O
output	O
of	O
type	B-Method
-	I-Method
filter	I-Method
for	O
location	O
in	O
the	O
layer	O
is	O
given	O
by	O
where	O
if	O
all	O
the	O
elements	O
in	O
vector	O
equals	O
0	O
,	O
otherwise	O
.	O
	
This	O
gate	O
,	O
working	O
with	O
max	B-Method
-	I-Method
pooling	I-Method
and	O
positive	O
activation	O
function	O
(	O
e.g.	O
,	O
Sigmoid	O
)	O
,	O
keeps	O
away	O
the	O
artifacts	O
from	O
padding	O
in	O
all	O
layers	O
.	O
	
Actually	O
it	O
creates	O
a	O
natural	O
hierarchy	O
of	O
all	O
-	O
zero	O
padding	O
(	O
as	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
)	O
,	O
consisting	O
of	O
nodes	O
in	O
the	O
neural	B-Method
net	I-Method
that	O
would	O
not	O
contribute	O
in	O
the	O
forward	O
process	O
(	O
as	O
in	O
prediction	B-Task
)	O
and	O
backward	B-Task
propagation	I-Task
(	O
as	O
in	O
learning	B-Task
)	O
.	O
	
subsection	O
:	O
Some	O
Analysis	O
on	O
the	O
Convolutional	B-Method
Architecture	I-Method
	
The	O
convolutional	B-Method
unit	I-Method
,	O
when	O
combined	O
with	O
max	B-Method
-	I-Method
pooling	I-Method
,	O
can	O
act	O
as	O
the	O
compositional	O
operator	O
with	O
local	B-Method
selection	I-Method
mechanism	I-Method
as	O
in	O
the	O
recursive	B-Method
autoencoder	I-Method
.	O
	
Figure	O
[	O
reference	O
]	O
gives	O
an	O
example	O
on	O
what	O
could	O
happen	O
on	O
the	O
first	O
two	O
layers	O
with	O
input	O
sentence	O
“	O
	
The	O
cat	O
sat	O
on	O
the	O
mat	O
”	O
.	O
	
Just	O
for	O
illustration	O
purpose	O
,	O
we	O
present	O
a	O
dramatic	O
choice	O
of	O
parameters	O
(	O
by	O
turning	O
off	O
some	O
elements	O
in	O
)	O
to	O
make	O
the	O
convolution	B-Method
units	I-Method
focus	O
on	O
different	O
segments	O
within	O
a	O
3	O
-	O
word	O
window	O
.	O
	
For	O
example	O
,	O
some	O
feature	O
maps	O
(	O
group	O
2	O
)	O
give	O
compositions	O
for	O
“	O
	
the	O
cat	O
”	O
and	O
“	O
cat	O
sat	O
”	O
,	O
each	O
being	O
a	O
vector	O
.	O
	
Different	O
feature	B-Method
maps	I-Method
offer	O
a	O
variety	O
of	O
compositions	O
,	O
with	O
confidence	O
encoded	O
in	O
the	O
values	O
(	O
color	O
coded	O
in	O
output	O
of	O
convolution	B-Method
layer	I-Method
in	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
The	O
pooling	O
then	O
chooses	O
,	O
for	O
each	O
composition	O
type	O
,	O
between	O
two	O
adjacent	O
sliding	O
windows	O
,	O
e.g.	O
,	O
between	O
“	O
on	O
the	O
”	O
and	O
“	O
the	O
mat	O
”	O
for	O
feature	O
maps	O
group	O
2	O
from	O
the	O
rightmost	O
two	O
sliding	O
windows	O
.	O
	
paragraph	O
:	O
Relation	O
to	O
Recursive	B-Method
Models	I-Method
	
Our	O
convolutional	B-Method
model	I-Method
differs	O
from	O
Recurrent	B-Method
Neural	I-Method
Network	I-Method
(	O
RNN	B-Method
,	O
)	O
and	O
Recursive	B-Method
Auto	I-Method
-	I-Method
Encoder	I-Method
(	O
RAE	B-Method
,	O
)	O
in	O
several	O
important	O
ways	O
.	O
	
First	O
,	O
unlike	O
RAE	B-Method
,	O
it	O
does	O
not	O
take	O
a	O
single	O
path	O
of	O
word	O
/	O
phrase	O
composition	O
determined	O
either	O
by	O
a	O
separate	O
gating	B-Method
function	I-Method
,	O
an	O
external	B-Method
parser	I-Method
,	O
or	O
just	O
natural	O
sequential	O
order	O
.	O
	
Instead	O
,	O
it	O
takes	O
multiple	O
choices	O
of	O
composition	O
via	O
a	O
large	O
feature	O
map	O
(	O
encoded	O
in	O
for	O
different	O
)	O
,	O
and	O
leaves	O
the	O
choices	O
to	O
the	O
pooling	O
afterwards	O
to	O
pick	O
the	O
more	O
appropriate	O
segments	O
(	O
in	O
every	O
adjacent	O
two	O
)	O
for	O
each	O
composition	O
.	O
	
With	O
any	O
window	O
width	O
,	O
the	O
type	O
of	O
composition	O
would	O
be	O
much	O
richer	O
than	O
that	O
of	O
RAE	B-Method
.	O
	
Second	O
,	O
our	O
convolutional	B-Method
model	I-Method
can	O
take	O
supervised	B-Task
training	I-Task
and	O
tune	O
the	O
parameters	O
for	O
a	O
specific	O
task	O
,	O
a	O
property	O
vital	O
to	O
our	O
supervised	B-Method
learning	I-Method
-	I-Method
to	I-Method
-	I-Method
match	I-Method
framework	I-Method
.	O
	
However	O
,	O
unlike	O
recursive	B-Method
models	I-Method
,	O
the	O
convolutional	B-Method
architecture	I-Method
has	O
a	O
fixed	O
depth	O
,	O
which	O
bounds	O
the	O
level	O
of	O
composition	O
it	O
could	O
do	O
.	O
	
For	O
tasks	O
like	O
matching	B-Task
,	O
this	O
limitation	O
can	O
be	O
largely	O
compensated	O
with	O
a	O
network	B-Method
afterwards	I-Method
that	O
can	O
take	O
a	O
“	O
global	O
”	O
synthesis	O
on	O
the	O
learned	O
sentence	B-Method
representation	I-Method
.	O
	
paragraph	O
:	O
Relation	O
to	O
“	O
Shallow	B-Method
”	I-Method
Convolutional	I-Method
Models	I-Method
	
The	O
proposed	O
convolutional	B-Method
sentence	I-Method
model	I-Method
takes	O
simple	O
architectures	O
such	O
as	O
(	O
essentially	O
the	O
same	O
convolutional	B-Method
architecture	I-Method
as	O
SENNA	B-Method
)	O
,	O
which	O
consists	O
of	O
a	O
convolution	B-Method
layer	I-Method
and	O
a	O
max	B-Method
-	I-Method
pooling	I-Method
over	O
the	O
entire	O
sentence	O
for	O
each	O
feature	O
map	O
.	O
	
This	O
type	O
of	O
models	O
,	O
with	O
local	B-Method
convolutions	I-Method
and	O
a	O
global	B-Method
pooling	I-Method
,	O
essentially	O
do	O
a	O
“	O
soft	B-Method
”	I-Method
local	I-Method
template	I-Method
matching	I-Method
and	O
is	O
able	O
to	O
detect	O
local	O
features	O
useful	O
for	O
a	O
certain	O
task	O
.	O
	
Since	O
the	O
sentence	O
-	O
level	O
sequential	O
order	O
is	O
inevitably	O
lost	O
in	O
the	O
global	B-Method
pooling	I-Method
,	O
the	O
model	O
is	O
incapable	O
of	O
modeling	O
more	O
complicated	O
structures	O
.	O
	
It	O
is	O
not	O
hard	O
to	O
see	O
that	O
our	O
convolutional	B-Method
model	I-Method
degenerates	O
to	O
the	O
SENNA	B-Method
-	I-Method
type	I-Method
architecture	I-Method
if	O
we	O
limit	O
the	O
number	O
of	O
layers	O
to	O
be	O
two	O
and	O
set	O
the	O
pooling	O
window	O
infinitely	O
large	O
.	O
	
section	O
:	O
Convolutional	B-Method
Matching	I-Method
Models	I-Method
	
Based	O
on	O
the	O
discussion	O
in	O
Section	O
[	O
reference	O
]	O
,	O
we	O
propose	O
two	O
related	O
convolutional	B-Method
architectures	I-Method
,	O
namely	O
Arc	B-Method
-	I-Method
I	I-Method
and	O
Arc	B-Method
-	I-Method
II	I-Method
)	O
,	O
for	O
matching	O
two	O
sentences	O
.	O
	
subsection	O
:	O
Architecture	B-Method
-	I-Method
I	I-Method
(	O
Arc	B-Method
-	I-Method
I	I-Method
)	O
	
Architecture	B-Method
-	I-Method
I	I-Method
(	O
Arc	B-Method
-	I-Method
I	I-Method
)	O
,	O
as	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
takes	O
a	O
conventional	O
approach	O
:	O
It	O
first	O
finds	O
the	O
representation	O
of	O
each	O
sentence	O
,	O
and	O
then	O
compares	O
the	O
representation	O
for	O
the	O
two	O
sentences	O
with	O
a	O
multi	B-Method
-	I-Method
layer	I-Method
perceptron	I-Method
(	O
MLP	B-Method
)	O
.	O
	
It	O
is	O
essentially	O
the	O
Siamese	B-Method
architecture	I-Method
introduced	O
in	O
,	O
which	O
has	O
been	O
applied	O
to	O
different	O
tasks	O
as	O
a	O
nonlinear	O
similarity	O
function	O
.	O
	
Although	O
Arc	B-Method
-	I-Method
I	I-Method
enjoys	O
the	O
flexibility	O
brought	O
by	O
the	O
convolutional	B-Method
sentence	I-Method
model	I-Method
,	O
it	O
suffers	O
from	O
a	O
drawback	O
inherited	O
from	O
the	O
Siamese	B-Method
architecture	I-Method
:	O
it	O
defers	O
the	O
interaction	O
between	O
two	O
sentences	O
(	O
in	O
the	O
final	O
MLP	B-Method
)	O
to	O
until	O
their	O
individual	O
representation	O
matures	O
(	O
in	O
the	O
convolution	B-Method
model	I-Method
)	O
,	O
therefore	O
runs	O
at	O
the	O
risk	O
of	O
losing	O
details	O
(	O
e.g.	O
,	O
a	O
city	O
name	O
)	O
important	O
for	O
the	O
matching	B-Task
task	I-Task
in	O
representing	O
the	O
sentences	O
.	O
	
In	O
other	O
words	O
,	O
in	O
the	O
forward	B-Method
phase	I-Method
(	O
prediction	B-Task
)	O
,	O
the	O
representation	O
of	O
each	O
sentence	O
is	O
formed	O
without	O
knowledge	O
of	O
each	O
other	O
.	O
	
This	O
can	O
not	O
be	O
adequately	O
circumvented	O
in	O
backward	B-Task
phase	I-Task
(	I-Task
learning	I-Task
)	O
,	O
when	O
the	O
convolutional	B-Method
model	I-Method
learns	O
to	O
extract	O
structures	O
informative	O
for	O
matching	B-Task
on	O
a	O
population	O
level	O
.	O
	
subsection	O
:	O
Architecture	B-Method
-	I-Method
II	I-Method
(	O
Arc	B-Method
-	I-Method
II	I-Method
)	O
	
In	O
view	O
of	O
the	O
drawback	O
of	O
Architecture	B-Method
-	I-Method
I	I-Method
,	O
we	O
propose	O
Architecture	B-Method
-	I-Method
II	I-Method
(	O
Arc	B-Method
-	I-Method
II	I-Method
)	O
that	O
is	O
built	O
directly	O
on	O
the	O
interaction	O
space	O
between	O
two	O
sentences	O
.	O
	
It	O
has	O
the	O
desirable	O
property	O
of	O
letting	O
two	O
sentences	O
meet	O
before	O
their	O
own	O
high	O
-	O
level	O
representations	O
mature	O
,	O
while	O
still	O
retaining	O
the	O
space	O
for	O
the	O
individual	O
development	O
of	O
abstraction	O
of	O
each	O
sentence	O
.	O
	
Basically	O
,	O
in	O
Layer	B-Method
-	I-Method
1	I-Method
,	O
we	O
take	O
sliding	O
windows	O
on	O
both	O
sentences	O
,	O
and	O
model	O
all	O
the	O
possible	O
combinations	O
of	O
them	O
through	O
“	O
one	B-Method
-	I-Method
dimensional	I-Method
”	I-Method
(	I-Method
1D	I-Method
)	I-Method
convolutions	I-Method
.	O
	
For	O
segment	O
on	O
and	O
segment	O
on	O
,	O
we	O
have	O
the	O
feature	O
map	O
where	O
simply	O
concatenates	O
the	O
vectors	O
for	O
sentence	O
segments	O
for	O
and	O
:	O
Clearly	O
the	O
1D	B-Method
convolution	I-Method
preserves	O
the	O
location	O
information	O
about	O
both	O
segments	O
.	O
	
After	O
that	O
in	O
Layer	O
-	O
2	O
,	O
it	O
performs	O
a	O
2D	B-Method
max	I-Method
-	I-Method
pooling	I-Method
in	O
non	O
-	O
overlapping	O
windows	O
(	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
)	O
	
In	O
Layer	O
-	O
3	O
,	O
we	O
perform	O
a	O
2D	B-Method
convolution	I-Method
on	O
windows	O
of	O
output	O
from	O
Layer	O
-	O
2	O
:	O
This	O
could	O
go	O
on	O
for	O
more	O
layers	O
of	O
2D	B-Method
convolution	I-Method
and	O
2D	B-Method
max	I-Method
-	I-Method
pooling	I-Method
,	O
analogous	O
to	O
that	O
of	O
convolutional	B-Method
architecture	I-Method
for	O
image	B-Task
input	I-Task
.	O
	
paragraph	O
:	O
The	O
2D	B-Method
-	I-Method
Convolution	I-Method
	
After	O
the	O
first	O
convolution	O
,	O
we	O
obtain	O
a	O
low	B-Method
level	I-Method
representation	I-Method
of	O
the	O
interaction	O
between	O
the	O
two	O
sentences	O
,	O
and	O
from	O
then	O
we	O
obtain	O
a	O
high	B-Method
level	I-Method
representation	I-Method
which	O
encodes	O
the	O
information	O
from	O
both	O
sentences	O
.	O
	
The	O
general	O
two	B-Method
-	I-Method
dimensional	I-Method
convolution	I-Method
is	O
formulated	O
as	O
where	O
concatenates	O
the	O
corresponding	O
vectors	O
from	O
its	O
2D	O
receptive	O
field	O
in	O
Layer	O
-	O
.	O
	
This	O
pooling	O
has	O
different	O
mechanism	O
as	O
in	O
the	O
1D	B-Task
case	I-Task
,	O
for	O
it	O
selects	O
not	O
only	O
among	O
compositions	O
on	O
different	O
segments	O
but	O
also	O
among	O
different	O
local	O
matchings	O
.	O
	
This	O
pooling	B-Method
strategy	I-Method
resembles	O
the	O
dynamic	B-Method
pooling	I-Method
in	O
in	O
a	O
similarity	B-Task
learning	I-Task
context	I-Task
,	O
but	O
with	O
two	O
distinctions	O
:	O
1	O
)	O
it	O
happens	O
on	O
a	O
fixed	O
architecture	O
and	O
2	O
)	O
it	O
has	O
much	O
richer	O
structure	O
than	O
just	O
similarity	O
.	O
	
subsection	O
:	O
Some	O
Analysis	O
on	O
Arc	B-Method
-	I-Method
II	I-Method
	
paragraph	O
:	O
Order	B-Method
Preservation	I-Method
	
Both	O
the	O
convolution	B-Method
and	I-Method
pooling	I-Method
operation	I-Method
in	O
Architecture	B-Method
-	I-Method
II	I-Method
have	O
this	O
order	O
preserving	O
property	O
.	O
	
Generally	O
,	O
contains	O
information	O
about	O
the	O
words	O
in	O
before	O
those	O
in	O
,	O
although	O
they	O
may	O
be	O
generated	O
with	O
slightly	O
different	O
segments	O
in	O
,	O
due	O
to	O
the	O
2D	B-Method
pooling	I-Method
(	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
The	O
orders	O
is	O
however	O
retained	O
in	O
a	O
“	O
conditional	O
”	O
sense	O
.	O
	
Our	O
experiments	O
show	O
that	O
when	O
Arc	B-Method
-	I-Method
II	I-Method
is	O
trained	O
on	O
the	O
triples	O
where	O
randomly	O
shuffles	O
the	O
words	O
in	O
,	O
it	O
consistently	O
gains	O
some	O
ability	O
of	O
finding	O
the	O
correct	O
in	O
the	O
usual	O
contrastive	B-Task
negative	I-Task
sampling	I-Task
setting	I-Task
,	O
which	O
however	O
does	O
not	O
happen	O
with	O
Arc	B-Method
-	I-Method
I	I-Method
.	O
	
paragraph	O
:	O
Model	O
Generality	O
	
It	O
is	O
not	O
hard	O
to	O
show	O
that	O
Arc	B-Method
-	I-Method
II	I-Method
actually	O
subsumes	O
Arc	B-Method
-	I-Method
I	I-Method
as	O
a	O
special	O
case	O
.	O
	
Indeed	O
,	O
in	O
Arc	B-Method
-	I-Method
II	I-Method
if	O
we	O
choose	O
(	O
by	O
turning	O
off	O
some	O
parameters	O
in	O
)	O
to	O
keep	O
the	O
representations	O
of	O
the	O
two	O
sentences	O
separated	O
until	O
the	O
final	O
MLP	B-Method
,	O
Arc	B-Method
-	I-Method
II	I-Method
can	O
actually	O
act	O
fully	O
like	O
Arc	B-Method
-	I-Method
I	I-Method
,	O
as	O
illustrated	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
More	O
specifically	O
,	O
if	O
we	O
let	O
the	O
feature	O
maps	O
in	O
the	O
first	O
convolution	B-Method
layer	I-Method
to	O
be	O
either	O
devoted	O
to	O
or	O
devoted	O
to	O
(	O
instead	O
of	O
taking	O
both	O
as	O
in	O
general	O
case	O
)	O
,	O
the	O
output	O
of	O
each	O
segment	O
-	O
pair	O
is	O
naturally	O
divided	O
into	O
two	O
corresponding	O
groups	O
.	O
	
As	O
a	O
result	O
,	O
the	O
output	O
for	O
each	O
filter	O
,	O
denoted	O
(	O
is	O
the	O
number	O
of	O
sliding	O
windows	O
)	O
,	O
will	O
be	O
of	O
rank	O
-	O
one	O
,	O
possessing	O
essentially	O
the	O
same	O
information	O
as	O
the	O
result	O
of	O
the	O
first	O
convolution	B-Method
layer	I-Method
in	O
Arc	B-Method
-	I-Method
I	I-Method
.	O
	
Clearly	O
the	O
2D	B-Task
pooling	I-Task
that	O
follows	O
will	O
reduce	O
to	O
1D	B-Method
pooling	I-Method
,	O
with	O
this	O
separateness	O
preserved	O
.	O
	
If	O
we	O
further	O
limit	O
the	O
parameters	O
in	O
the	O
second	O
convolution	B-Method
units	I-Method
(	O
more	O
specifically	O
)	O
to	O
those	O
for	O
and	O
,	O
we	O
can	O
ensure	O
the	O
individual	O
development	O
of	O
different	O
levels	O
of	O
abstraction	O
on	O
each	O
side	O
,	O
and	O
fully	O
recover	O
the	O
functionality	O
of	O
Arc	B-Method
-	I-Method
I	I-Method
.	O
	
As	O
suggested	O
by	O
the	O
order	O
-	O
preserving	O
property	O
and	O
the	O
generality	O
of	O
Arc	B-Method
-	I-Method
II	I-Method
,	O
this	O
architecture	O
offers	O
not	O
only	O
the	O
capability	O
but	O
also	O
the	O
inductive	O
bias	O
for	O
the	O
individual	O
development	O
of	O
internal	B-Task
abstraction	I-Task
on	O
each	O
sentence	O
,	O
despite	O
the	O
fact	O
that	O
it	O
is	O
built	O
on	O
the	O
interaction	O
between	O
two	O
sentences	O
.	O
	
As	O
a	O
result	O
,	O
Arc	B-Method
-	I-Method
II	I-Method
can	O
naturally	O
blend	O
two	O
seemingly	O
diverging	B-Method
processes	I-Method
:	O
1	O
)	O
the	O
successive	B-Task
composition	I-Task
within	O
each	O
sentence	O
,	O
and	O
2	O
)	O
the	O
extraction	O
and	O
fusion	B-Task
of	I-Task
matching	I-Task
patterns	I-Task
between	O
them	O
,	O
hence	O
is	O
powerful	O
for	O
matching	B-Task
linguistic	I-Task
objects	I-Task
with	O
rich	O
structures	O
.	O
	
This	O
intuition	O
is	O
verified	O
by	O
the	O
superior	O
performance	O
of	O
Arc	B-Method
-	I-Method
II	I-Method
in	O
experiments	O
(	O
Section	O
[	O
reference	O
]	O
)	O
on	O
different	O
matching	B-Task
tasks	I-Task
.	O
	
section	O
:	O
Training	O
	
We	O
employ	O
a	O
discriminative	B-Method
training	I-Method
strategy	I-Method
with	O
a	O
large	O
margin	O
objective	O
.	O
	
Suppose	O
that	O
we	O
are	O
given	O
the	O
following	O
triples	O
from	O
the	O
oracle	O
,	O
with	O
matched	O
with	O
better	O
than	O
with	O
.	O
	
We	O
have	O
the	O
following	O
ranking	B-Metric
-	I-Metric
based	I-Metric
loss	I-Metric
as	O
objective	O
:	O
where	O
is	O
predicted	B-Metric
matching	I-Metric
score	I-Metric
for	O
,	O
and	O
includes	O
the	O
parameters	O
for	O
convolution	B-Method
layers	I-Method
and	O
those	O
for	O
the	O
MLP	B-Method
.	O
	
The	O
optimization	B-Task
is	O
relatively	O
straightforward	O
for	O
both	O
architectures	O
with	O
the	O
standard	O
back	B-Method
-	I-Method
propagation	I-Method
.	O
	
The	O
gating	B-Method
function	I-Method
(	O
see	O
Section	O
[	O
reference	O
]	O
)	O
can	O
be	O
easily	O
adopted	O
into	O
the	O
gradient	O
by	O
discounting	O
the	O
contribution	O
from	O
convolution	B-Method
units	I-Method
that	O
have	O
been	O
turned	O
off	O
by	O
the	O
gating	O
function	O
.	O
	
In	O
other	O
words	O
,	O
We	O
use	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
for	O
the	O
optimization	B-Task
of	I-Task
models	I-Task
.	O
	
All	O
the	O
proposed	O
models	O
perform	O
better	O
with	O
mini	O
-	O
batch	O
(	O
in	O
sizes	O
)	O
which	O
can	O
be	O
easily	O
parallelized	O
on	O
single	O
machine	O
with	O
multi	O
-	O
cores	O
.	O
	
For	O
regularization	B-Task
,	O
we	O
find	O
that	O
for	O
both	O
architectures	O
,	O
early	B-Task
stopping	I-Task
is	O
enough	O
for	O
models	O
with	O
medium	O
size	O
and	O
large	O
training	O
sets	O
(	O
with	O
over	O
500	O
K	O
instances	O
)	O
.	O
	
For	O
small	O
datasets	O
(	O
less	O
than	O
10k	O
training	O
instances	O
)	O
however	O
,	O
we	O
have	O
to	O
combine	O
early	B-Method
stopping	I-Method
and	O
dropout	B-Method
to	O
deal	O
with	O
the	O
serious	O
overfitting	B-Task
problem	I-Task
.	O
	
We	O
use	O
50	B-Method
-	I-Method
dimensional	I-Method
word	I-Method
embedding	I-Method
trained	O
with	O
the	O
Word2Vec	B-Method
:	O
	
the	O
embedding	O
for	O
English	O
words	O
(	O
Section	O
[	O
reference	O
]	O
&	O
[	O
reference	O
]	O
)	O
is	O
learnt	O
on	O
Wikipedia	O
(	O
1B	O
words	O
)	O
,	O
while	O
that	O
for	O
Chinese	O
words	O
(	O
Section	O
[	O
reference	O
]	O
)	O
is	O
learnt	O
on	O
Weibo	O
data	O
(	O
300	O
M	O
words	O
)	O
.	O
	
Our	O
other	O
experiments	O
(	O
results	O
omitted	O
here	O
)	O
suggest	O
that	O
fine	O
-	O
tuning	O
the	O
word	B-Method
embedding	I-Method
can	O
further	O
improve	O
the	O
performances	O
of	O
all	O
models	O
,	O
at	O
the	O
cost	O
of	O
longer	O
training	B-Task
.	O
	
We	O
vary	O
the	O
maximum	O
length	O
of	O
words	O
for	O
different	O
tasks	O
to	O
cope	O
with	O
its	O
longest	O
sentence	O
.	O
	
We	O
use	O
3	O
-	O
word	O
window	O
throughout	O
all	O
experiments	O
,	O
but	O
test	O
various	O
numbers	O
of	O
feature	O
maps	O
(	O
typically	O
from	O
200	O
to	O
500	O
)	O
,	O
for	O
optimal	O
performance	O
.	O
	
Arc	B-Method
-	I-Method
II	I-Method
models	O
for	O
all	O
tasks	O
have	O
eight	O
layers	O
(	O
three	O
for	O
convolution	B-Method
,	O
three	O
for	O
pooling	B-Method
,	O
and	O
two	O
for	O
MLP	B-Method
)	O
,	O
while	O
Arc	B-Method
-	I-Method
I	I-Method
performs	O
better	O
with	O
less	O
layers	O
(	O
two	O
for	O
convolution	B-Method
,	O
two	O
for	O
pooling	B-Method
,	O
and	O
two	O
for	O
MLP	B-Method
)	O
and	O
more	O
hidden	O
nodes	O
.	O
	
We	O
use	O
ReLu	B-Method
as	O
the	O
activation	B-Method
function	I-Method
for	O
all	O
of	O
models	O
(	O
convolution	B-Method
and	I-Method
MLP	I-Method
)	O
,	O
which	O
yields	O
comparable	O
or	O
better	O
results	O
to	O
sigmoid	O
-	O
like	O
functions	O
,	O
but	O
converges	O
faster	O
.	O
	
section	O
:	O
Experiments	O
	
We	O
report	O
the	O
performance	O
of	O
the	O
proposed	O
models	O
on	O
three	O
matching	B-Task
tasks	I-Task
of	O
different	O
nature	O
,	O
and	O
compare	O
it	O
with	O
that	O
of	O
other	O
competitor	B-Method
models	I-Method
.	O
	
Among	O
them	O
,	O
the	O
first	O
two	O
tasks	O
(	O
namely	O
,	O
Sentence	B-Task
Completion	I-Task
and	O
Tweet	B-Task
-	I-Task
Response	I-Task
Matching	I-Task
)	O
are	O
about	O
matching	B-Task
of	I-Task
language	I-Task
objects	I-Task
of	O
heterogenous	O
natures	O
,	O
while	O
the	O
third	O
one	O
(	O
paraphrase	B-Task
identification	I-Task
)	O
is	O
a	O
natural	O
example	O
of	O
matching	B-Task
homogeneous	I-Task
objects	I-Task
.	O
	
Moreover	O
,	O
the	O
three	O
tasks	O
involve	O
two	O
languages	O
,	O
different	O
types	O
of	O
matching	B-Task
,	O
and	O
distinctive	O
writing	O
styles	O
,	O
proving	O
the	O
broad	O
applicability	O
of	O
the	O
proposed	O
models	O
.	O
	
subsection	O
:	O
Competitor	B-Method
Methods	I-Method
	
WordEmbed	O
:	O
	
We	O
first	O
represent	O
each	O
short	O
-	O
text	O
as	O
the	O
sum	O
of	O
the	O
embedding	O
of	O
the	O
words	O
it	O
contains	O
.	O
	
The	O
matching	B-Metric
score	I-Metric
of	O
two	O
short	O
-	O
texts	O
are	O
calculated	O
with	O
an	O
MLP	B-Method
with	O
the	O
embedding	O
of	O
the	O
two	O
documents	O
as	O
input	O
;	O
DeepMatch	B-Method
:	O
We	O
take	O
the	O
matching	B-Method
model	I-Method
in	O
and	O
train	O
it	O
on	O
our	O
datasets	O
with	O
3	O
hidden	O
layers	O
and	O
1	O
,	O
000	O
hidden	O
nodes	O
in	O
the	O
first	O
hidden	O
layer	O
;	O
	
uRAE	B-Method
+	I-Method
MLP	I-Method
:	O
	
We	O
use	O
the	O
Unfolding	B-Method
Recursive	I-Method
Autoencoder	I-Method
to	O
get	O
a	O
100	B-Method
-	I-Method
dimensional	I-Method
vector	I-Method
representation	I-Method
of	O
each	O
sentence	O
,	O
and	O
put	O
an	O
MLP	B-Method
on	O
the	O
top	O
as	O
in	O
WordEmbed	O
;	O
SENNA	O
+	O
MLP	O
/	O
sim	O
:	O
We	O
use	O
the	O
SENNA	B-Method
-	I-Method
type	I-Method
sentence	I-Method
model	I-Method
for	O
sentence	B-Task
representation	I-Task
;	O
	
SenMLP	B-Method
:	O
	
We	O
take	O
the	O
whole	O
sentence	O
as	O
input	O
(	O
with	O
word	O
embedding	O
aligned	O
sequentially	O
)	O
,	O
and	O
use	O
an	O
MLP	B-Method
to	O
obtain	O
the	O
score	B-Metric
of	I-Metric
coherence	I-Metric
.	O
	
All	O
the	O
competitor	O
models	O
are	O
trained	O
on	O
the	O
same	O
training	O
set	O
as	O
the	O
proposed	O
models	O
,	O
and	O
we	O
report	O
the	O
best	O
test	O
performance	O
over	O
different	O
choices	O
of	O
models	O
(	O
e.g.	O
,	O
the	O
number	O
and	O
size	O
of	O
hidden	O
layers	O
in	O
MLP	B-Method
)	O
.	O
	
subsection	O
:	O
Experiment	O
I	O
:	O
Sentence	B-Task
Completion	I-Task
	
This	O
is	O
an	O
artificial	B-Task
task	I-Task
designed	O
to	O
elucidate	O
how	O
different	O
matching	B-Method
models	I-Method
can	O
capture	O
the	O
correspondence	O
between	O
two	O
clauses	O
within	O
a	O
sentence	O
.	O
	
Basically	O
,	O
we	O
take	O
a	O
sentence	O
from	O
Reuters	O
with	O
two	O
	
“	O
balanced	O
”	O
clauses	O
(	O
with	O
8	O
28	O
words	O
)	O
divided	O
by	O
one	O
comma	O
,	O
and	O
use	O
the	O
first	O
clause	O
as	O
and	O
the	O
second	O
as	O
.	O
	
The	O
task	O
is	O
then	O
to	O
recover	O
the	O
original	O
second	O
clause	O
for	O
any	O
given	O
first	O
clause	O
.	O
	
The	O
matching	B-Task
here	O
is	O
considered	O
heterogeneous	O
since	O
the	O
relation	O
between	O
the	O
two	O
is	O
nonsymmetrical	O
on	O
both	O
lexical	O
and	O
semantic	O
levels	O
.	O
	
We	O
deliberately	O
make	O
the	O
task	O
harder	O
by	O
using	O
negative	O
second	O
clauses	O
similar	O
to	O
the	O
original	O
ones	O
,	O
both	O
in	O
training	O
and	O
testing	O
.	O
	
One	O
representative	O
example	O
is	O
given	O
as	O
follows	O
:	O
:	O
Although	O
the	O
state	O
has	O
only	O
four	O
votes	O
in	O
the	O
Electoral	O
College	O
,	O
:	O
its	O
loss	O
would	O
be	O
a	O
symbolic	O
blow	O
to	O
republican	O
presidential	O
candi	O
date	O
Bob	O
Dole	O
.	O
	
:	O
but	O
it	O
failed	O
to	O
garner	O
enough	O
votes	O
to	O
override	O
an	O
expected	O
veto	O
by	O
president	O
Clinton	O
.	O
	
All	O
models	O
are	O
trained	O
on	O
3	O
million	O
triples	O
(	O
from	O
600	O
K	O
positive	O
pairs	O
)	O
,	O
and	O
tested	O
on	O
50	O
K	O
positive	O
pairs	O
,	O
each	O
accompanied	O
by	O
four	O
negatives	O
,	O
with	O
results	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
The	O
two	O
proposed	O
models	O
get	O
nearly	O
half	O
of	O
the	O
cases	O
right	O
,	O
with	O
large	O
margin	O
over	O
other	O
sentence	B-Method
models	I-Method
and	O
models	O
without	O
explicit	B-Method
sequence	I-Method
modeling	I-Method
.	O
	
Arc	B-Method
-	I-Method
II	I-Method
outperforms	O
	
Arc	B-Method
-	I-Method
I	I-Method
significantly	O
,	O
showing	O
the	O
power	O
of	O
joint	B-Method
modeling	I-Method
of	I-Method
matching	I-Method
and	O
sentence	B-Task
meaning	I-Task
.	O
	
As	O
another	O
convolutional	B-Method
model	I-Method
,	O
SENNA	B-Method
+	I-Method
MLP	I-Method
performs	O
fairly	O
well	O
on	O
this	O
task	O
,	O
although	O
still	O
running	O
behind	O
the	O
proposed	O
convolutional	B-Method
architectures	I-Method
since	O
it	O
is	O
too	O
shallow	O
to	O
adequately	O
model	O
the	O
sentence	O
.	O
	
It	O
is	O
a	O
bit	O
surprising	O
that	O
uRAE	O
comes	O
last	O
on	O
this	O
task	O
,	O
which	O
might	O
be	O
caused	O
by	O
the	O
facts	O
that	O
1	O
)	O
the	O
representation	B-Method
model	I-Method
(	O
including	O
word	B-Method
-	I-Method
embedding	I-Method
)	O
is	O
not	O
trained	O
on	O
Reuters	O
,	O
and	O
2	O
)	O
the	O
split	O
-	O
sentence	O
setting	O
hurts	O
the	O
parsing	B-Task
,	O
which	O
is	O
vital	O
to	O
the	O
quality	O
of	O
learned	O
sentence	B-Method
representation	I-Method
.	O
	
subsection	O
:	O
Experiment	O
II	O
:	O
Matching	O
A	O
Response	O
to	O
A	O
Tweet	O
	
We	O
trained	O
our	O
model	O
with	O
4.5	O
million	O
original	O
(	O
tweet	O
,	O
response	O
)	O
pairs	O
collected	O
from	O
Weibo	O
,	O
a	O
major	O
Chinese	O
microblog	O
service	O
.	O
	
Compared	O
to	O
Experiment	O
I	O
,	O
the	O
writing	O
style	O
is	O
obviously	O
more	O
free	O
and	O
informal	O
.	O
	
For	O
each	O
positive	O
pair	O
,	O
we	O
find	O
ten	O
random	O
responses	O
as	O
negative	O
examples	O
,	O
rendering	O
45	O
million	O
triples	O
for	O
training	O
.	O
	
One	O
example	O
(	O
translated	O
to	O
English	O
)	O
is	O
given	O
below	O
,	O
with	O
standing	O
for	O
the	O
tweet	O
,	O
the	O
original	O
response	O
,	O
and	O
the	O
randomly	O
selected	O
response	O
:	O
:	O
Damn	O
,	O
I	O
have	O
to	O
work	O
overtime	O
this	O
weekend	O
!	O
	
:	O
Try	O
to	O
have	O
some	O
rest	O
buddy	O
.	O
	
:	O
It	O
is	O
hard	O
to	O
find	O
a	O
job	O
,	O
better	O
start	O
polishing	O
your	O
resume	O
.	O
	
We	O
hold	O
out	O
300	O
K	O
original	O
(	O
tweet	O
,	O
response	O
)	O
pairs	O
and	O
test	O
the	O
matching	B-Method
model	I-Method
on	O
their	O
ability	O
to	O
pick	O
the	O
original	O
response	O
from	O
four	O
random	O
negatives	O
,	O
with	O
results	O
reported	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
This	O
task	O
is	O
slightly	O
easier	O
than	O
Experiment	O
I	O
,	O
with	O
more	O
training	O
instances	O
and	O
purely	O
random	O
negatives	O
.	O
	
It	O
requires	O
less	O
about	O
the	O
grammatical	O
rigor	O
but	O
more	O
on	O
detailed	O
modeling	O
of	O
loose	O
and	O
local	O
matching	O
patterns	O
(	O
e.g.	O
,	O
work	O
-	O
overtime⇔	O
rest	O
)	O
.	O
	
Again	O
Arc	B-Method
-	I-Method
II	I-Method
beats	O
other	O
models	O
with	O
large	O
margins	O
,	O
while	O
two	O
convolutional	B-Method
sentence	I-Method
models	I-Method
	
Arc	B-Method
-	I-Method
I	I-Method
and	O
SENNA	B-Method
+	I-Method
MLP	I-Method
come	O
next	O
.	O
	
subsection	O
:	O
Experiment	O
III	O
:	O
Paraphrase	B-Task
Identification	I-Task
	
Paraphrase	B-Task
identification	I-Task
aims	O
to	O
determine	O
whether	O
two	O
sentences	O
have	O
the	O
same	O
meaning	O
,	O
a	O
problem	O
considered	O
a	O
touchstone	O
of	O
natural	B-Task
language	I-Task
understanding	I-Task
.	O
	
This	O
experiment	O
is	O
included	O
to	O
test	O
our	O
methods	O
on	O
matching	B-Task
homogenous	I-Task
objects	I-Task
.	O
	
Here	O
we	O
use	O
the	O
benchmark	O
MSRP	O
dataset	O
,	O
which	O
contains	O
4	O
,	O
076	O
instances	O
for	O
training	O
and	O
1	O
,	O
725	O
for	O
test	O
.	O
	
We	O
use	O
all	O
the	O
training	O
instances	O
and	O
report	O
the	O
test	O
performance	O
from	O
early	O
stopping	O
.	O
	
As	O
stated	O
earlier	O
,	O
our	O
model	O
is	O
not	O
specially	O
tailored	O
for	O
modeling	O
synonymy	B-Task
,	O
and	O
generally	O
requires	O
instances	O
to	O
work	O
favorably	O
.	O
	
Nevertheless	O
,	O
our	O
generic	B-Method
matching	I-Method
models	I-Method
still	O
manage	O
to	O
perform	O
reasonably	O
well	O
,	O
achieving	O
an	O
accuracy	B-Metric
and	O
F1	B-Metric
score	I-Metric
close	O
to	O
the	O
best	O
performer	O
in	O
2008	O
based	O
on	O
hand	O
-	O
crafted	O
features	O
,	O
but	O
still	O
significantly	O
lower	O
than	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
(	O
76.8%	O
/	O
83.6	O
%	O
)	O
,	O
achieved	O
with	O
unfolding	B-Method
-	I-Method
RAE	I-Method
and	O
other	O
features	O
designed	O
for	O
this	O
task	O
.	O
	
subsection	O
:	O
Discussions	O
	
Arc	B-Method
-	I-Method
II	I-Method
outperforms	O
others	O
significantly	O
when	O
the	O
training	O
instances	O
are	O
relatively	O
abundant	O
(	O
as	O
in	O
Experiment	O
I	O
&	O
II	O
)	O
.	O
	
Its	O
superiority	O
over	O
Arc	B-Method
-	I-Method
I	I-Method
,	O
however	O
,	O
is	O
less	O
salient	O
when	O
the	O
sentences	O
have	O
deep	O
grammatical	O
structures	O
and	O
the	O
matching	B-Task
relies	O
less	O
on	O
the	O
local	O
matching	O
patterns	O
,	O
as	O
in	O
Experiment	O
-	O
I.	O
	
This	O
therefore	O
raises	O
the	O
interesting	O
question	O
about	O
how	O
to	O
balance	O
the	O
representation	O
of	O
matching	O
and	O
the	O
representations	O
of	O
objects	O
,	O
and	O
whether	O
we	O
can	O
guide	O
the	O
learning	B-Task
process	I-Task
through	O
something	O
like	O
curriculum	B-Task
learning	I-Task
.	O
	
As	O
another	O
important	O
observation	O
,	O
convolutional	B-Method
models	I-Method
(	O
Arc	B-Method
-	I-Method
I	I-Method
&	O
II	B-Method
,	O
SENNA	B-Method
+	I-Method
MLP	I-Method
)	O
perform	O
favorably	O
over	O
bag	B-Method
-	I-Method
of	I-Method
-	I-Method
words	I-Method
models	I-Method
,	O
indicating	O
the	O
importance	O
of	O
utilizing	O
sequential	O
structures	O
in	O
understanding	O
and	O
matching	B-Task
sentences	I-Task
.	O
	
Quite	O
interestingly	O
,	O
as	O
shown	O
by	O
our	O
other	O
experiments	O
,	O
Arc	B-Method
-	I-Method
I	I-Method
and	O
Arc	B-Method
-	I-Method
II	I-Method
trained	O
purely	O
with	O
random	O
negatives	O
automatically	O
gain	O
some	O
ability	O
in	O
telling	O
whether	O
the	O
words	O
in	O
a	O
given	O
sentence	O
are	O
in	O
right	O
sequential	O
order	O
(	O
with	O
around	O
60	O
%	O
accuracy	B-Metric
for	O
both	O
)	O
.	O
	
It	O
is	O
therefore	O
a	O
bit	O
surprising	O
that	O
an	O
auxiliary	B-Task
task	I-Task
on	O
identifying	O
the	O
correctness	O
of	O
word	O
order	O
in	O
the	O
response	O
does	O
not	O
enhance	O
the	O
ability	O
of	O
the	O
model	O
on	O
the	O
original	O
matching	B-Task
tasks	I-Task
.	O
	
We	O
noticed	O
that	O
simple	O
sum	B-Method
of	I-Method
embedding	I-Method
learned	O
via	O
Word2Vec	B-Method
yields	O
reasonably	O
good	O
results	O
on	O
all	O
three	O
tasks	O
.	O
	
We	O
hypothesize	O
that	O
the	O
Word2Vec	B-Method
embedding	I-Method
is	O
trained	O
in	O
such	O
a	O
way	O
that	O
the	O
vector	B-Method
summation	I-Method
can	O
act	O
as	O
a	O
simple	O
composition	O
,	O
and	O
hence	O
retains	O
a	O
fair	O
amount	O
of	O
meaning	O
in	O
the	O
short	O
text	O
segment	O
.	O
	
This	O
is	O
in	O
contrast	O
with	O
other	O
bag	B-Method
-	I-Method
of	I-Method
-	I-Method
words	I-Method
models	I-Method
like	O
DeepMatch	B-Method
.	O
	
section	O
:	O
Related	O
Work	O
	
Matching	B-Task
structured	I-Task
objects	I-Task
rarely	O
goes	O
beyond	O
estimating	O
the	O
similarity	O
of	O
objects	O
in	O
the	O
same	O
domain	O
,	O
with	O
few	O
exceptions	O
like	O
.	O
	
When	O
dealing	O
with	O
language	B-Task
objects	I-Task
,	O
most	O
methods	O
still	O
focus	O
on	O
seeking	O
vectorial	B-Method
representations	I-Method
in	O
a	O
common	O
latent	O
space	O
,	O
and	O
calculating	O
the	O
matching	B-Metric
score	I-Metric
with	O
inner	B-Method
product	I-Method
.	O
	
Few	O
work	O
has	O
been	O
done	O
on	O
building	O
a	O
deep	B-Method
architecture	I-Method
on	O
the	O
interaction	O
space	O
for	O
texts	O
-	O
pairs	O
,	O
but	O
it	O
is	O
largely	O
based	O
on	O
a	O
bag	B-Method
-	I-Method
of	I-Method
-	I-Method
words	I-Method
representation	I-Method
of	I-Method
text	I-Method
.	O
	
Our	O
models	O
are	O
related	O
to	O
the	O
long	O
thread	O
of	O
work	O
on	O
sentence	B-Task
representation	I-Task
.	O
	
Aside	O
from	O
the	O
models	O
with	O
recursive	O
nature	O
(	O
as	O
discussed	O
in	O
Section	O
2.1	O
)	O
,	O
it	O
is	O
fairly	O
common	O
practice	O
to	O
use	O
the	O
sum	B-Method
of	I-Method
word	I-Method
-	I-Method
embedding	I-Method
to	O
represent	O
a	O
short	O
-	O
text	O
,	O
mostly	O
for	O
classification	B-Task
.	O
	
There	O
is	O
very	O
little	O
work	O
on	O
convolutional	B-Task
modeling	I-Task
of	I-Task
language	I-Task
.	O
	
In	O
addition	O
to	O
,	O
there	O
is	O
a	O
very	O
recent	O
model	O
on	O
sentence	B-Task
representation	I-Task
with	O
dynamic	B-Method
convolutional	I-Method
neural	I-Method
network	I-Method
.	O
	
This	O
work	O
relies	O
heavily	O
on	O
a	O
carefully	O
designed	O
pooling	B-Method
strategy	I-Method
to	O
handle	O
the	O
variable	O
length	O
of	O
sentence	O
with	O
a	O
relatively	O
small	O
feature	O
map	O
,	O
tailored	O
for	O
classification	B-Task
problems	I-Task
with	O
modest	O
sizes	O
.	O
	
section	O
:	O
Conclusion	O
	
We	O
propose	O
deep	B-Method
convolutional	I-Method
architectures	I-Method
for	O
matching	B-Task
natural	I-Task
language	I-Task
sentences	I-Task
,	O
which	O
can	O
nicely	O
combine	O
the	O
hierarchical	B-Method
modeling	I-Method
of	O
individual	O
sentences	O
and	O
the	O
patterns	O
of	O
their	O
matching	O
.	O
	
Empirical	O
study	O
shows	O
our	O
models	O
can	O
outperform	O
competitors	O
on	O
a	O
variety	O
of	O
matching	B-Task
tasks	I-Task
.	O
	
paragraph	O
:	O
Acknowledgments	O
:	O
	
B.	O
Hu	O
and	O
Q.	O
Chen	O
are	O
supported	O
in	O
part	O
by	O
National	O
Natural	O
Science	O
Foundation	O
of	O
China	O
61173075	O
.	O
	
Z.	O
Lu	O
and	O
H.	O
Li	O
are	O
supported	O
in	O
part	O
by	O
China	O
National	O
973	O
project	O
2014CB340301	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Generating	B-Task
Images	I-Task
from	I-Task
Captions	I-Task
with	O
Attention	B-Method
	
Motivated	O
by	O
the	O
recent	O
progress	O
in	O
generative	B-Method
models	I-Method
,	O
we	O
introduce	O
a	O
model	O
that	O
generates	B-Task
images	I-Task
from	I-Task
natural	I-Task
language	I-Task
descriptions	I-Task
.	O
	
The	O
proposed	O
model	O
iteratively	O
draws	O
patches	O
on	O
a	O
canvas	O
,	O
while	O
attending	O
to	O
the	O
relevant	O
words	O
in	O
the	O
description	O
.	O
	
After	O
training	O
on	O
Microsoft	B-Material
COCO	I-Material
,	O
we	O
compare	O
our	O
model	O
with	O
several	O
baseline	B-Method
generative	I-Method
models	I-Method
on	O
image	B-Task
generation	I-Task
and	O
retrieval	B-Task
tasks	I-Task
.	O
	
We	O
demonstrate	O
that	O
our	O
model	O
produces	O
higher	O
quality	O
samples	O
than	O
other	O
approaches	O
and	O
generates	O
images	O
with	O
novel	O
scene	O
compositions	O
corresponding	O
to	O
previously	O
unseen	O
captions	O
in	O
the	O
dataset	O
.	O
	
section	O
:	O
Introduction	O
	
Statistical	B-Method
natural	I-Method
image	I-Method
modelling	I-Method
remains	O
a	O
fundamental	O
problem	O
in	O
computer	B-Task
vision	I-Task
and	O
image	B-Task
understanding	I-Task
.	O
	
The	O
challenging	O
nature	O
of	O
this	O
task	O
has	O
motivated	O
recent	O
approaches	O
to	O
exploit	O
the	O
inference	B-Method
and	I-Method
generative	I-Method
capabilities	I-Method
of	O
deep	B-Method
neural	I-Method
networks	I-Method
.	O
	
Previously	O
studied	O
deep	B-Method
generative	I-Method
models	I-Method
of	O
images	O
often	O
defined	O
distributions	O
that	O
were	O
restricted	O
to	O
being	O
either	O
unconditioned	O
or	O
conditioned	O
on	O
classification	O
labels	O
.	O
	
In	O
real	B-Task
world	I-Task
applications	I-Task
,	O
however	O
,	O
images	O
rarely	O
appear	O
in	O
isolation	O
as	O
they	O
are	O
often	O
accompanied	O
by	O
unstructured	O
textual	O
descriptions	O
,	O
such	O
as	O
on	O
web	O
pages	O
and	O
in	O
books	O
.	O
	
The	O
additional	O
information	O
from	O
these	O
descriptions	O
could	O
be	O
used	O
to	O
simplify	O
the	O
image	B-Task
modelling	I-Task
task	I-Task
.	O
	
Moreover	O
,	O
learning	O
generative	B-Method
models	I-Method
conditioned	O
on	O
text	O
also	O
allows	O
a	O
better	O
understanding	O
of	O
the	O
generalization	B-Metric
performance	O
of	O
the	O
model	O
,	O
as	O
we	O
can	O
create	O
textual	O
descriptions	O
of	O
completely	O
new	O
scenes	O
not	O
seen	O
at	O
training	O
time	O
.	O
	
There	O
are	O
numerous	O
ways	O
to	O
learn	O
a	O
generative	B-Method
model	I-Method
over	O
both	O
image	O
and	O
text	O
modalities	O
.	O
	
One	O
approach	O
is	O
to	O
learn	O
a	O
generative	B-Method
model	I-Method
of	I-Method
text	I-Method
conditioned	O
on	O
images	O
,	O
known	O
as	O
caption	B-Task
generation	I-Task
kiros_icml14	O
,	O
karpathy_captions	O
,	O
vinyals_captions	O
,	O
xu_captions	O
.	O
	
These	O
models	O
take	O
an	O
image	B-Method
descriptor	I-Method
and	O
generate	O
unstructured	O
texts	O
using	O
a	O
recurrent	B-Method
decoder	I-Method
.	O
	
In	O
contrast	O
,	O
in	O
this	O
paper	O
we	O
explore	O
models	O
that	O
condition	O
in	O
the	O
opposite	O
direction	O
,	O
i.e.	O
taking	O
textual	O
descriptions	O
as	O
input	O
and	O
using	O
them	O
to	O
generate	O
relevant	O
images	O
.	O
	
Generating	B-Task
high	I-Task
dimensional	I-Task
realistic	I-Task
images	I-Task
from	O
their	O
descriptions	O
combines	O
the	O
two	O
challenging	O
components	O
of	O
language	B-Task
modelling	I-Task
and	O
image	B-Task
generation	I-Task
,	O
and	O
can	O
be	O
considered	O
to	O
be	O
more	O
difficult	O
than	O
caption	B-Task
generation	I-Task
.	O
	
In	O
this	O
paper	O
,	O
we	O
illustrate	O
how	O
sequential	B-Method
deep	I-Method
learning	I-Method
techniques	I-Method
can	O
be	O
used	O
to	O
build	O
a	O
conditional	B-Method
probabilistic	I-Method
model	I-Method
over	O
natural	O
image	O
space	O
effectively	O
.	O
	
By	O
extending	O
the	O
Deep	B-Method
Recurrent	I-Method
Attention	I-Method
Writer	I-Method
(	O
DRAW	B-Method
)	O
	
gregor_draw	O
	
,	O
our	O
model	O
iteratively	O
draws	O
patches	O
on	O
a	O
canvas	O
,	O
while	O
attending	O
to	O
the	O
relevant	O
words	O
in	O
the	O
description	O
.	O
	
Overall	O
,	O
the	O
main	O
contributions	O
of	O
this	O
work	O
are	O
the	O
following	O
:	O
we	O
introduce	O
a	O
conditional	B-Method
alignDRAW	I-Method
model	I-Method
,	O
a	O
generative	B-Method
model	I-Method
of	I-Method
images	I-Method
from	O
captions	B-Method
using	O
a	O
soft	B-Method
attention	I-Method
mechanism	I-Method
.	O
	
The	O
images	O
generated	O
by	O
our	O
alignDRAW	B-Method
model	I-Method
are	O
refined	O
in	O
a	O
post	B-Method
-	I-Method
processing	I-Method
step	I-Method
by	O
a	O
deterministic	B-Method
Laplacian	I-Method
pyramid	I-Method
adversarial	I-Method
network	I-Method
denton_lapgan	O
.	O
	
We	O
further	O
illustrate	O
how	O
our	O
method	O
,	O
learned	O
on	O
Microsoft	B-Material
COCO	I-Material
mscoco	I-Material
,	O
generalizes	O
to	O
captions	O
describing	O
novel	O
scenes	O
that	O
are	O
not	O
seen	O
in	O
the	O
dataset	O
,	O
such	O
as	O
“	O
A	O
stop	O
sign	O
is	O
flying	O
in	O
blue	O
skies	O
”	O
(	O
see	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
[	O
A	O
stop	O
sign	O
is	O
flying	O
in	O
blue	O
skies	O
.	O
]	O
	
[	O
A	O
herd	O
of	O
elephants	O
flying	O
in	O
the	O
blue	O
skies	O
.	O
]	O
	
[	O
A	O
toilet	O
seat	O
sits	O
open	O
in	O
the	O
grass	O
field	O
.	O
]	O
	
[	O
A	O
person	O
skiing	O
on	O
sand	O
clad	O
vast	O
desert	O
.	O
]	O
	
section	O
:	O
Related	O
Work	O
	
Deep	B-Method
Neural	I-Method
Networks	I-Method
have	O
achieved	O
significant	O
success	O
in	O
various	O
tasks	O
such	O
as	O
image	B-Task
recognition	I-Task
krizhevsky_imagenet	O
,	O
speech	B-Task
transcription	I-Task
graves_speech	O
,	O
and	O
machine	B-Task
translation	I-Task
bahdanau_mt	O
.	O
	
While	O
most	O
of	O
the	O
recent	O
success	O
has	O
been	O
achieved	O
by	O
discriminative	B-Method
models	I-Method
,	O
generative	B-Method
models	I-Method
have	O
not	O
yet	O
enjoyed	O
the	O
same	O
level	O
of	O
success	O
.	O
	
Most	O
of	O
the	O
previous	O
work	O
in	O
generative	B-Method
models	I-Method
has	O
focused	O
on	O
variants	O
of	O
Boltzmann	B-Method
Machines	I-Method
smolensky_rbm	O
,	O
russ_dbm	O
and	O
	
Deep	B-Method
Belief	I-Method
Networks	I-Method
hinton_dbn	O
.	O
	
While	O
these	O
models	O
are	O
very	O
powerful	O
,	O
each	O
iteration	O
of	O
training	B-Task
requires	O
a	O
computationally	O
costly	O
step	O
of	O
MCMC	B-Method
to	O
approximate	O
derivatives	O
of	O
an	O
intractable	O
partition	O
function	O
(	O
normalization	O
constant	O
)	O
,	O
making	O
it	O
difficult	O
to	O
scale	O
them	O
to	O
large	O
datasets	O
.	O
,	O
have	O
introduced	O
the	O
Variational	B-Method
Auto	I-Method
-	I-Method
Encoder	I-Method
(	O
VAE	B-Method
)	O
which	O
can	O
be	O
seen	O
as	O
a	O
neural	B-Method
network	I-Method
with	O
continuous	O
latent	O
variables	O
.	O
	
The	O
encoder	B-Method
is	O
used	O
to	O
approximate	O
a	O
posterior	O
distribution	O
and	O
the	O
decoder	B-Method
is	O
used	O
to	O
stochastically	O
reconstruct	O
the	O
data	O
from	O
latent	O
variables	O
.	O
	
further	O
introduced	O
the	O
Deep	B-Method
Recurrent	I-Method
Attention	I-Method
Writer	I-Method
(	I-Method
DRAW	I-Method
)	I-Method
,	O
extending	O
the	O
VAE	B-Method
approach	O
by	O
incorporating	O
a	O
novel	O
differentiable	B-Method
attention	I-Method
mechanism	I-Method
.	O
	
Generative	B-Method
Adversarial	I-Method
Networks	I-Method
(	O
GANs	B-Method
)	O
	
goodfellow_gan	O
are	O
another	O
type	O
of	O
generative	B-Method
models	I-Method
that	O
use	O
noise	B-Method
-	I-Method
contrastive	I-Method
estimation	I-Method
gutmann_nce	O
to	O
avoid	O
calculating	O
an	O
intractable	O
partition	O
function	O
.	O
	
The	O
model	O
consists	O
of	O
a	O
generator	B-Method
that	O
generates	O
samples	O
using	O
a	O
uniform	B-Method
distribution	I-Method
and	O
a	O
discriminator	B-Method
that	O
discriminates	O
between	O
real	O
and	O
generated	B-Task
images	I-Task
.	O
	
Recently	O
,	O
have	O
scaled	O
those	O
models	O
by	O
training	O
conditional	B-Method
GANs	I-Method
at	O
each	O
level	O
of	O
a	O
Laplacian	O
pyramid	O
of	O
images	O
.	O
	
While	O
many	O
of	O
the	O
previous	O
approaches	O
have	O
focused	O
on	O
unconditional	B-Method
models	I-Method
or	O
models	O
conditioned	O
on	O
labels	O
,	O
in	O
this	O
paper	O
we	O
develop	O
a	O
generative	B-Method
model	I-Method
of	I-Method
images	I-Method
conditioned	O
on	O
captions	O
.	O
	
section	O
:	O
Model	O
	
Our	O
proposed	O
model	O
defines	O
a	O
generative	B-Method
process	I-Method
of	I-Method
images	I-Method
conditioned	O
on	O
captions	O
.	O
	
In	O
particular	O
,	O
captions	O
are	O
represented	O
as	O
a	O
sequence	O
of	O
consecutive	O
words	O
and	O
images	O
are	O
represented	O
as	O
a	O
sequence	O
of	O
patches	O
drawn	O
on	O
a	O
canvas	O
over	O
time	O
.	O
	
The	O
model	O
can	O
be	O
viewed	O
as	O
a	O
part	O
of	O
the	O
sequence	B-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
framework	I-Method
ilya_mt	O
,	O
cho_mt	O
,	O
nitish_video	O
.	O
	
subsection	O
:	O
Language	B-Method
Model	I-Method
:	O
the	O
Bidirectional	B-Method
Attention	I-Method
RNN	I-Method
	
Let	O
be	O
the	O
input	O
caption	O
,	O
represented	O
as	O
a	O
sequence	O
of	O
1	O
-	O
of	O
-	O
K	O
encoded	O
words	O
,	O
where	O
is	O
the	O
size	O
of	O
the	O
vocabulary	O
and	O
is	O
the	O
length	O
of	O
the	O
sequence	O
.	O
	
We	O
obtain	O
the	O
caption	B-Method
sentence	I-Method
representation	I-Method
by	O
first	O
transforming	O
each	O
word	O
to	O
an	O
-	B-Method
dimensional	I-Method
vector	I-Method
representation	I-Method
,	O
using	O
the	O
Bidirectional	B-Method
RNN	I-Method
.	O
	
In	O
a	O
Bidirectional	B-Task
RNN	I-Task
,	O
the	O
two	O
LSTMs	B-Method
hochreiter_lstm	O
with	O
forget	O
gates	O
	
gers_forget	O
process	O
the	O
input	O
sequence	O
from	O
both	O
forward	O
and	O
backward	O
directions	O
.	O
	
The	O
Forward	B-Method
LSTM	I-Method
computes	O
the	O
sequence	O
of	O
forward	O
hidden	O
states	O
,	O
whereas	O
the	O
Backward	B-Method
LSTM	I-Method
computes	O
the	O
sequence	O
of	O
backward	O
hidden	O
states	O
.	O
	
These	O
hidden	O
states	O
are	O
then	O
concatenated	O
together	O
into	O
the	O
sequence	O
,	O
with	O
.	O
	
subsection	O
:	O
Image	B-Method
Model	I-Method
:	O
the	O
Conditional	B-Method
DRAW	I-Method
Network	I-Method
	
To	O
generate	O
an	O
image	O
conditioned	O
on	O
the	O
caption	O
information	O
,	O
we	O
extended	O
the	O
DRAW	B-Method
network	I-Method
gregor_draw	O
to	O
include	O
caption	B-Method
representation	I-Method
at	O
each	O
step	O
,	O
as	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
The	O
conditional	B-Method
DRAW	I-Method
network	I-Method
is	O
a	O
stochastic	B-Method
recurrent	I-Method
neural	I-Method
network	I-Method
that	O
consists	O
of	O
a	O
sequence	O
of	O
latent	O
variables	O
,	O
,	O
where	O
the	O
output	O
is	O
accumulated	O
over	O
all	O
time	O
-	O
steps	O
.	O
	
For	O
simplicity	O
in	O
notation	O
,	O
the	O
images	O
are	O
assumed	O
to	O
have	O
size	O
-	O
by	O
-	O
and	O
only	O
one	O
color	O
channel	O
.	O
	
Unlike	O
the	O
original	O
DRAW	B-Method
network	I-Method
where	O
latent	O
variables	O
are	O
independent	O
spherical	B-Method
Gaussians	I-Method
,	O
the	O
latent	O
variables	O
in	O
the	O
proposed	O
alignDRAW	B-Method
model	I-Method
have	O
their	O
mean	O
and	O
variance	O
depend	O
on	O
the	O
previous	O
hidden	O
states	O
of	O
the	O
generative	B-Method
LSTM	I-Method
,	O
except	O
for	O
.	O
	
Namely	O
,	O
the	O
mean	O
and	O
variance	O
of	O
the	O
prior	O
distribution	O
over	O
are	O
parameterized	O
by	O
:	O
where	O
,	O
are	O
the	O
learned	O
model	O
parameters	O
,	O
and	O
is	O
the	O
dimensionality	O
of	O
,	O
the	O
hidden	O
state	O
of	O
the	O
generative	B-Method
LSTM	I-Method
.	O
	
Similar	O
to	O
bachman_sdm	O
,	O
we	O
have	O
observed	O
that	O
the	O
model	O
performance	O
is	O
improved	O
by	O
including	O
dependencies	O
between	O
latent	O
variables	O
.	O
	
Formally	O
,	O
an	O
image	O
is	O
generated	O
by	O
iteratively	O
computing	O
the	O
following	O
set	O
of	O
equations	O
for	O
(	O
see	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
,	O
with	O
and	O
initialized	O
to	O
learned	O
biases	O
:	O
The	O
function	O
is	O
used	O
to	O
compute	O
the	O
alignment	O
between	O
the	O
input	O
caption	O
and	O
intermediate	B-Method
image	I-Method
generative	I-Method
steps	I-Method
bahdanau_mt	O
.	O
	
Given	O
the	O
caption	B-Method
representation	I-Method
from	O
the	O
language	B-Method
model	I-Method
,	O
,	O
the	O
operator	O
outputs	O
a	O
dynamic	B-Method
sentence	I-Method
representation	I-Method
at	O
each	O
step	O
through	O
a	O
weighted	O
sum	O
using	O
alignment	O
probabilities	O
:	O
The	O
corresponding	O
alignment	O
probability	O
for	O
the	O
word	O
in	O
the	O
caption	O
is	O
obtained	O
using	O
the	O
caption	B-Method
representation	I-Method
and	O
the	O
current	O
hidden	O
state	O
of	O
the	O
generative	B-Method
model	I-Method
:	O
where	O
,	O
,	O
and	O
are	O
the	O
learned	O
model	O
parameters	O
of	O
the	O
alignment	B-Method
model	I-Method
.	O
	
The	O
function	O
of	O
Eq	O
.	O
	
[	O
reference	O
]	O
is	O
defined	O
by	O
the	O
LSTM	B-Method
network	I-Method
with	O
forget	O
gates	O
gers_forget	O
at	O
a	O
single	O
time	O
-	O
step	O
.	O
	
To	O
generate	O
the	O
next	O
hidden	O
state	O
,	O
the	O
takes	O
the	O
previous	O
hidden	O
state	O
and	O
combines	O
it	O
with	O
the	O
input	O
from	O
both	O
the	O
latent	O
sample	O
and	O
the	O
sentence	B-Method
representation	I-Method
.	O
	
The	O
output	O
of	O
the	O
function	O
is	O
then	O
passed	O
through	O
the	O
operator	B-Method
which	O
is	O
added	O
to	O
a	O
cumulative	O
canvas	O
matrix	O
(	O
Eq	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
The	O
operator	O
produces	O
two	O
arrays	O
of	O
1D	B-Method
Gaussian	I-Method
filter	I-Method
banks	I-Method
and	O
whose	O
filter	O
locations	O
and	O
scales	O
are	O
computed	O
from	O
the	O
generative	O
LSTM	O
hidden	O
state	O
(	O
same	O
as	O
defined	O
in	O
)	O
.	O
	
The	O
Gaussian	B-Method
filter	I-Method
banks	I-Method
are	O
then	O
applied	O
to	O
the	O
generated	O
-	O
by	O
-	O
image	O
patch	O
,	O
placing	O
it	O
onto	O
the	O
canvas	O
:	O
Finally	O
,	O
each	O
entry	O
from	O
the	O
final	O
canvas	O
matrix	O
is	O
transformed	O
using	O
a	O
sigmoid	B-Method
function	I-Method
to	O
produce	O
a	O
conditional	B-Method
Bernoulli	I-Method
distribution	I-Method
with	O
mean	O
vector	O
over	O
the	O
image	O
pixels	O
given	O
the	O
latent	O
variables	O
and	O
the	O
input	O
caption	O
.	O
	
In	O
practice	O
,	O
when	O
generating	O
an	O
image	O
,	O
instead	O
of	O
sampling	O
from	O
the	O
conditional	O
Bernoulli	O
distribution	O
,	O
we	O
simply	O
use	O
the	O
conditional	O
mean	O
.	O
	
subsection	O
:	O
Learning	O
	
The	O
model	O
is	O
trained	O
to	O
maximize	O
a	O
variational	O
lower	O
bound	O
on	O
the	O
marginal	O
likelihood	O
of	O
the	O
correct	O
image	O
given	O
the	O
input	O
caption	O
:	O
	
Similar	O
to	O
the	O
DRAW	B-Method
model	I-Method
,	O
the	O
inference	B-Method
recurrent	I-Method
network	I-Method
produces	O
an	O
approximate	O
posterior	O
via	O
a	O
operator	B-Method
,	O
which	O
reads	O
a	O
patch	O
from	O
an	O
input	O
image	O
using	O
two	O
arrays	O
of	O
1D	B-Method
Gaussian	I-Method
filters	I-Method
(	O
inverse	O
of	O
from	O
section	O
[	O
reference	O
]	O
)	O
at	O
each	O
time	O
-	O
step	O
.	O
	
Specifically	O
,	O
where	O
is	O
the	O
error	O
image	O
and	O
is	O
initialized	O
to	O
the	O
learned	O
bias	O
.	O
	
Note	O
that	O
the	O
inference	B-Task
takes	O
as	O
its	O
input	O
both	O
the	O
output	O
of	O
the	O
operator	O
,	O
which	O
depends	O
on	O
the	O
original	O
input	O
image	O
,	O
and	O
the	O
previous	O
state	O
of	O
the	O
generative	B-Method
decoder	I-Method
,	O
which	O
depends	O
on	O
the	O
latent	O
sample	O
history	O
and	O
dynamic	B-Method
sentence	I-Method
representation	I-Method
(	O
see	O
Eq	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
Hence	O
,	O
the	O
approximate	O
posterior	O
will	O
depend	O
on	O
the	O
input	O
image	O
,	O
the	O
corresponding	O
caption	O
,	O
and	O
the	O
latent	O
history	O
,	O
except	O
for	O
the	O
first	O
step	O
,	O
which	O
depends	O
only	O
on	O
.	O
	
The	O
terms	O
in	O
the	O
variational	O
lower	O
bound	O
Eq	O
.	O
	
[	O
reference	O
]	O
can	O
be	O
rearranged	O
using	O
the	O
law	B-Method
of	I-Method
total	I-Method
expectation	I-Method
.	O
	
Therefore	O
,	O
the	O
variational	O
bound	O
is	O
calculated	O
as	O
follows	O
:	O
	
The	O
expectation	O
can	O
be	O
approximated	O
by	O
Monte	O
Carlo	O
samples	O
from	O
:	O
The	O
model	O
can	O
be	O
trained	O
using	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
.	O
	
In	O
all	O
of	O
our	O
experiments	O
,	O
we	O
used	O
only	O
a	O
single	O
sample	O
from	O
for	O
parameter	B-Task
learning	I-Task
.	O
	
Training	O
details	O
,	O
hyperparameter	O
settings	O
,	O
and	O
the	O
overall	O
model	O
architecture	O
are	O
specified	O
in	O
Appendix	O
B.	O
	
The	O
code	O
is	O
available	O
at	O
.	O
	
subsection	O
:	O
Generating	B-Task
Images	I-Task
from	I-Task
Captions	I-Task
	
During	O
the	O
image	B-Task
generation	I-Task
step	O
,	O
we	O
discard	O
the	O
inference	B-Method
network	I-Method
and	O
instead	O
sample	O
from	O
the	O
prior	O
distribution	O
.	O
	
Due	O
to	O
the	O
blurriness	O
of	O
samples	O
generated	O
by	O
the	O
DRAW	B-Method
model	I-Method
,	O
we	O
perform	O
an	O
additional	O
post	B-Task
processing	I-Task
step	I-Task
where	O
we	O
use	O
an	O
adversarial	B-Method
network	I-Method
trained	O
on	O
residuals	O
of	O
a	O
Laplacian	B-Method
pyramid	I-Method
conditioned	O
on	O
the	O
skipthought	B-Method
representation	I-Method
kiros_skipthought	O
of	O
the	O
captions	O
to	O
sharpen	O
the	O
generated	B-Task
images	I-Task
,	O
similar	O
to	O
denton_lapgan	O
.	O
	
By	O
fixing	O
the	O
prior	O
of	O
the	O
adversarial	B-Method
generator	I-Method
to	O
its	O
mean	O
,	O
it	O
gets	O
treated	O
as	O
a	O
deterministic	B-Method
neural	I-Method
network	I-Method
that	O
allows	O
us	O
to	O
define	O
the	O
conditional	O
data	O
term	O
in	O
Eq	O
.	O
	
[	O
reference	O
]	O
on	O
the	O
sharpened	O
images	O
and	O
estimate	O
the	O
variational	O
lower	O
bound	O
accordingly	O
.	O
	
[	O
A	O
yellow	O
school	O
bus	O
parked	O
in	O
a	O
parking	O
lot	O
.	O
]	O
	
[	O
A	O
red	O
school	O
bus	O
parked	O
in	O
a	O
parking	O
lot	O
.	O
]	O
	
[	O
A	O
green	O
school	O
bus	O
parked	O
in	O
a	O
parking	O
lot	O
.	O
]	O
	
[	O
A	O
blue	O
school	O
bus	O
parked	O
in	O
a	O
parking	O
lot	O
.	O
]	O
	
[	O
The	O
decadent	O
chocolate	O
desert	O
is	O
on	O
the	O
table	O
.	O
]	O
	
[	O
A	O
bowl	O
of	O
bananas	O
is	O
on	O
the	O
table	O
.	O
]	O
	
[	O
A	O
vintage	O
photo	O
of	O
a	O
cat	O
.	O
]	O
	
[	O
A	O
vintage	O
photo	O
of	O
a	O
dog	O
.	O
]	O
	
section	O
:	O
Experiments	O
	
subsection	O
:	O
Microsoft	B-Material
COCO	I-Material
	
Microsoft	B-Material
COCO	I-Material
mscoco	I-Material
is	O
a	O
large	O
dataset	O
containing	O
82	O
,	O
783	O
images	O
,	O
each	O
annotated	O
with	O
at	O
least	O
5	O
captions	O
.	O
	
The	O
rich	O
collection	O
of	O
images	O
with	O
a	O
wide	O
variety	O
of	O
styles	O
,	O
backgrounds	O
and	O
objects	O
makes	O
the	O
task	O
of	O
learning	O
a	O
good	O
generative	B-Method
model	I-Method
very	O
challenging	O
.	O
	
For	O
consistency	O
with	O
related	O
work	O
on	O
caption	B-Task
generation	I-Task
,	O
we	O
used	O
only	O
the	O
first	O
five	O
captions	O
when	O
training	O
and	O
evaluating	O
our	O
model	O
.	O
	
The	O
images	O
were	O
resized	O
to	O
pixels	O
for	O
consistency	O
with	O
other	O
tiny	O
image	O
datasets	O
krizhevsky_cifar	O
.	O
	
In	O
the	O
following	O
subsections	O
,	O
we	O
analyzed	O
both	O
the	O
qualitative	O
and	O
quantitative	O
aspects	O
of	O
our	O
model	O
as	O
well	O
as	O
compared	O
its	O
performance	O
with	O
that	O
of	O
other	O
,	O
related	O
generative	B-Method
models	I-Method
.	O
	
Appendix	O
A	O
further	O
reports	O
some	O
additional	O
experiments	O
using	O
the	O
MNIST	O
dataset	O
.	O
	
subsubsection	O
:	O
Analysis	B-Task
of	I-Task
Generated	I-Task
Images	I-Task
	
The	O
main	O
goal	O
of	O
this	O
work	O
is	O
to	O
learn	O
a	O
model	O
that	O
can	O
understand	O
the	O
semantic	O
meaning	O
expressed	O
in	O
the	O
textual	O
descriptions	O
of	O
images	O
,	O
such	O
as	O
the	O
properties	O
of	O
objects	O
,	O
the	O
relationships	O
between	O
them	O
,	O
and	O
then	O
use	O
that	O
knowledge	O
to	O
generate	O
relevant	O
images	O
.	O
	
To	O
examine	O
the	O
understanding	O
of	O
our	O
model	O
,	O
we	O
wrote	O
a	O
set	O
of	O
captions	O
inspired	O
by	O
the	O
COCO	B-Material
dataset	I-Material
and	O
changed	O
some	O
words	O
in	O
the	O
captions	O
to	O
see	O
whether	O
the	O
model	O
made	O
the	O
relevant	O
changes	O
in	O
the	O
generated	O
samples	O
.	O
	
First	O
,	O
we	O
explored	O
whether	O
the	O
model	O
understood	O
one	O
of	O
the	O
most	O
basic	O
properties	O
of	O
any	O
object	O
,	O
the	O
color	O
.	O
	
In	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
we	O
generated	B-Task
images	I-Task
of	O
school	O
buses	O
with	O
four	O
different	O
colors	O
:	O
yellow	O
,	O
red	O
,	O
green	O
and	O
blue	O
.	O
	
Although	O
,	O
there	O
are	O
images	O
of	O
buses	O
with	O
different	O
colors	O
in	O
the	O
training	O
set	O
,	O
all	O
mentioned	O
school	O
buses	O
are	O
specifically	O
colored	O
yellow	O
.	O
	
Despite	O
that	O
,	O
the	O
model	O
managed	O
to	O
generate	O
images	O
of	O
an	O
object	O
that	O
is	O
visually	O
reminiscent	O
of	O
a	O
school	O
bus	O
that	O
is	O
painted	O
with	O
the	O
specified	O
color	O
.	O
	
Apart	O
from	O
changing	O
the	O
colors	O
of	O
objects	O
,	O
we	O
next	O
examined	O
whether	O
changing	O
the	O
background	O
of	O
the	O
scene	O
described	O
in	O
a	O
caption	O
would	O
result	O
in	O
the	O
appropriate	O
changes	O
in	O
the	O
generated	O
samples	O
.	O
	
The	O
task	O
of	O
changing	O
the	O
background	O
of	O
an	O
image	O
is	O
somewhat	O
harder	O
than	O
just	O
changing	O
the	O
color	O
of	O
an	O
object	O
because	O
the	O
model	O
will	O
have	O
to	O
make	O
alterations	O
over	O
a	O
wider	O
visual	O
area	O
.	O
	
Nevertheless	O
,	O
as	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
changing	O
the	O
skies	O
from	O
blue	O
to	O
rainy	O
in	O
a	O
caption	O
as	O
well	O
as	O
changing	O
the	O
grass	O
type	O
from	O
dry	O
to	O
green	O
in	O
another	O
caption	O
resulted	O
in	O
the	O
appropriate	O
changes	O
in	O
the	O
generated	O
image	O
.	O
	
Despite	O
a	O
large	O
number	O
of	O
ways	O
of	O
changing	O
colors	O
and	O
backgrounds	O
in	O
descriptions	O
,	O
in	O
general	O
we	O
found	O
that	O
the	O
model	O
made	O
appropriate	O
changes	O
as	O
long	O
as	O
some	O
similar	O
pattern	O
was	O
present	O
in	O
the	O
training	O
set	O
.	O
	
However	O
,	O
the	O
model	O
struggled	O
when	O
the	O
visual	O
difference	O
between	O
objects	O
was	O
very	O
small	O
,	O
such	O
as	O
when	O
the	O
objects	O
have	O
the	O
same	O
general	O
shape	O
and	O
color	O
.	O
	
In	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
,	O
we	O
demonstrate	O
that	O
when	O
we	O
swap	O
two	O
objects	O
that	O
are	O
both	O
visually	O
similar	O
,	O
for	O
example	O
cats	O
and	O
dogs	O
,	O
it	O
is	O
difficult	O
to	O
discriminate	O
solely	O
from	O
the	O
generated	O
samples	O
whether	O
it	O
is	O
an	O
image	O
of	O
a	O
cat	O
or	O
dog	O
,	O
even	O
though	O
we	O
might	O
notice	O
an	O
animal	O
-	O
like	O
shape	O
.	O
	
This	O
highlights	O
a	O
limitation	O
of	O
the	O
model	O
in	O
that	O
it	O
has	O
difficulty	O
modelling	O
the	O
fine	O
-	O
grained	O
details	O
of	O
objects	O
.	O
	
As	O
a	O
test	O
of	O
model	B-Task
generalization	I-Task
,	O
we	O
tried	O
generating	B-Task
images	I-Task
corresponding	I-Task
to	I-Task
captions	I-Task
that	O
describe	O
scenarios	O
that	O
are	O
highly	O
unlikely	O
to	O
occur	O
in	O
real	O
life	O
.	O
	
These	O
captions	O
describe	O
a	O
common	O
object	O
doing	O
unusual	O
things	O
or	O
set	O
in	O
a	O
strange	O
location	O
,	O
for	O
example	O
“	O
	
A	O
toilet	O
seat	O
sits	O
open	O
in	O
the	O
grass	O
field	O
”	O
.	O
	
Even	O
though	O
some	O
of	O
these	O
scenarios	O
may	O
never	O
occur	O
in	O
real	O
life	O
,	O
it	O
is	O
very	O
easy	O
for	O
humans	O
to	O
imagine	O
the	O
corresponding	O
scene	O
.	O
	
Nevertheless	O
,	O
as	O
you	O
can	O
see	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
the	O
model	O
managed	O
to	O
generate	O
reasonable	O
images	O
.	O
	
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
[	O
A	O
very	O
large	O
commercial	O
plane	O
flying	O
in	O
blue	O
skies	O
.	O
]	O
	
[	O
A	O
very	O
large	O
commercial	O
plane	O
flying	O
in	O
rainy	O
skies	O
.	O
]	O
	
[	O
A	O
herd	O
of	O
elephants	O
walking	O
across	O
a	O
dry	O
grass	O
field	O
.	O
]	O
	
[	O
A	O
herd	O
of	O
elephants	O
walking	O
across	O
a	O
green	O
grass	O
field	O
.	O
]	O
	
subsubsection	O
:	O
Analysis	B-Task
of	I-Task
Attention	I-Task
	
After	O
flipping	O
sets	O
of	O
words	O
in	O
the	O
captions	O
,	O
we	O
further	O
explored	O
which	O
words	O
the	O
model	O
attended	O
to	O
when	O
generating	O
images	O
.	O
	
It	O
turned	O
out	O
that	O
during	O
the	O
generation	B-Task
step	I-Task
,	O
the	O
model	O
mostly	O
focused	O
on	O
the	O
specific	O
words	O
(	O
or	O
nearby	O
words	O
)	O
that	O
carried	O
the	O
main	O
semantic	O
meaning	O
expressed	O
in	O
the	O
sentences	O
.	O
	
The	O
attention	O
values	O
of	O
words	O
in	O
sentences	O
helped	O
us	O
interpret	O
the	O
reasons	O
why	O
the	O
model	O
made	O
the	O
changes	O
it	O
did	O
when	O
we	O
flipped	O
certain	O
words	O
.	O
	
For	O
example	O
,	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
top	O
row	O
	
,	O
we	O
can	O
see	O
that	O
when	O
we	O
flipped	O
the	O
word	O
“	O
desert	O
”	O
to	O
“	O
forest	O
”	O
,	O
the	O
attention	O
over	O
words	O
in	O
the	O
sentence	O
did	O
not	O
change	O
drastically	O
.	O
	
This	O
suggests	O
that	O
,	O
in	O
their	O
respective	O
sentences	O
,	O
the	O
model	O
looked	O
at	O
“	O
desert	O
”	O
and	O
“	O
forest	O
”	O
with	O
relatively	O
equal	O
probability	O
,	O
and	O
thus	O
made	O
the	O
correct	O
changes	O
.	O
	
In	O
contrast	O
,	O
when	O
we	O
swap	O
words	O
“	O
beach	O
”	O
and	O
“	O
sun	O
”	O
,	O
we	O
can	O
see	O
a	O
drastic	O
change	O
between	O
sentences	O
in	O
the	O
probability	O
distribution	O
over	O
words	O
.	O
	
By	O
noting	O
that	O
the	O
model	O
completely	O
ignores	O
the	O
word	O
“	O
sun	O
”	O
in	O
the	O
second	O
sentence	O
,	O
we	O
can	O
therefore	O
gain	O
a	O
more	O
thorough	O
understanding	O
of	O
why	O
we	O
see	O
no	O
visual	O
differences	O
between	O
the	O
images	O
generated	O
by	O
each	O
caption	O
.	O
	
[	O
3	O
A	O
rider	O
1	O
on	O
a	O
blue	O
1	O
motorcycle	O
in	O
the	O
.	O
]	O
	
[	O
3	O
A	O
rider	O
1	O
on	O
a	O
blue	O
1	O
motorcycle	O
in	O
the	O
.	O
]	O
	
[	O
2	O
A	O
1	O
surfer	O
,	O
a	O
woman	O
,	O
and	O
a	O
child	O
walk	O
on	O
the	O
.	O
]	O
	
[	O
3	O
A	O
1	O
surfer	O
,	O
a	O
woman	O
,	O
and	O
a	O
child	O
walk	O
on	O
the	O
.	O
]	O
	
[	O
alignDRAW	O
]	O
[	O
LAPGAN	O
]	O
	
[	O
Conv	B-Method
-	I-Method
Deconv	I-Method
VAE	I-Method
]	O
	
[	O
Fully	B-Method
-	I-Method
Conn	I-Method
VAE	I-Method
]	O
	
We	O
also	O
tried	O
to	O
analyze	O
the	O
way	O
the	O
model	O
generated	B-Task
images	I-Task
.	O
	
Unfortunately	O
,	O
we	O
found	O
that	O
there	O
was	O
no	O
significant	O
connection	O
between	O
the	O
patches	O
drawn	O
on	O
canvas	O
and	O
the	O
most	O
attended	O
words	O
at	O
particular	O
time	O
-	O
steps	O
.	O
	
subsubsection	O
:	O
Comparison	O
With	O
Other	O
Models	O
	
Quantitatively	O
evaluating	O
generative	B-Method
models	I-Method
remains	O
a	O
challenging	O
task	O
in	O
itself	O
as	O
each	O
method	O
of	O
evaluation	B-Task
suffers	O
from	O
its	O
own	O
specific	O
drawbacks	O
.	O
	
Compared	O
to	O
reporting	O
classification	B-Metric
accuracies	I-Metric
in	O
discriminative	B-Method
models	I-Method
,	O
the	O
measures	O
defining	O
generative	B-Method
models	I-Method
are	O
intractable	O
most	O
of	O
the	O
times	O
and	O
might	O
not	O
correctly	O
define	O
the	O
real	O
quality	O
of	O
the	O
model	O
.	O
	
To	O
get	O
a	O
better	O
comparison	O
between	O
performances	O
of	O
different	O
generative	B-Method
models	I-Method
,	O
we	O
report	O
results	O
on	O
two	O
different	O
metrics	O
as	O
well	O
as	O
a	O
qualitative	O
comparison	O
of	O
different	O
generative	B-Method
models	I-Method
.	O
	
We	O
compared	O
the	O
performance	O
of	O
the	O
proposed	O
model	O
to	O
the	O
DRAW	B-Method
model	I-Method
conditioned	O
on	O
captions	O
without	O
the	O
function	O
(	O
noalignDRAW	O
)	O
as	O
well	O
as	O
the	O
DRAW	B-Method
model	I-Method
conditioned	O
on	O
the	O
skipthought	O
vectors	O
of	O
kiros_skipthought	O
(	O
skipthoughtDRAW	O
)	O
.	O
	
All	O
of	O
the	O
conditional	B-Method
DRAW	I-Method
models	I-Method
were	O
trained	O
with	O
a	O
binary	B-Metric
cross	I-Metric
-	I-Metric
entropy	I-Metric
cost	I-Metric
function	I-Metric
,	O
i.e.	O
they	O
had	O
Bernoulli	O
conditional	O
likelihoods	O
.	O
	
We	O
also	O
compared	O
our	O
model	O
with	O
Fully	B-Method
-	I-Method
Connected	I-Method
(	O
Fully	B-Method
-	I-Method
Conn	I-Method
)	O
and	O
Convolutional	B-Method
-	I-Method
Deconvolutional	I-Method
(	O
Conv	B-Method
-	I-Method
Deconv	I-Method
)	O
Variational	B-Method
Autoencoders	I-Method
which	O
were	O
trained	O
with	O
the	O
least	B-Method
squares	I-Method
cost	I-Method
function	I-Method
.	O
	
The	O
LAPGAN	B-Method
model	I-Method
of	O
denton_lapgan	O
was	O
trained	O
on	O
a	O
two	B-Method
level	I-Method
Laplacian	I-Method
Pyramid	I-Method
with	O
a	O
GAN	B-Method
as	O
a	O
top	B-Method
layer	I-Method
generator	I-Method
and	O
all	O
stages	O
were	O
conditioned	O
on	O
the	O
same	O
skipthought	O
vector	O
.	O
	
In	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
	
bottom	O
row	O
,	O
we	O
generated	O
several	O
samples	O
from	O
the	O
prior	O
of	O
each	O
of	O
the	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
generative	B-Method
models	I-Method
,	O
conditioned	O
on	O
the	O
caption	O
	
“	O
	
A	O
group	O
of	O
people	O
walk	O
on	O
a	O
beach	O
with	O
surf	O
boards	O
”	O
.	O
	
While	O
all	O
of	O
the	O
samples	O
look	O
sharp	O
,	O
the	O
images	O
generated	O
by	O
LAPGAN	B-Method
look	O
more	O
noisy	O
and	O
it	O
is	O
harder	O
to	O
make	O
out	O
definite	O
objects	O
,	O
whereas	O
the	O
images	O
generated	O
by	O
variational	B-Method
models	I-Method
trained	O
with	O
least	B-Method
squares	I-Method
cost	I-Method
function	I-Method
have	O
a	O
watercolor	O
effect	O
on	O
the	O
images	O
.	O
	
We	O
found	O
that	O
the	O
quality	O
of	O
generated	O
samples	O
was	O
similar	O
among	O
different	O
variants	O
of	O
conditional	B-Method
DRAW	I-Method
models	I-Method
.	O
	
As	O
for	O
the	O
quantitative	O
comparison	O
of	O
different	O
models	O
,	O
we	O
first	O
compare	O
the	O
performances	O
of	O
the	O
model	O
trained	O
with	O
variational	B-Method
methods	I-Method
.	O
	
We	O
rank	O
the	O
images	O
in	O
the	O
test	O
set	O
conditioned	O
on	O
the	O
captions	O
based	O
on	O
the	O
variational	B-Metric
lower	I-Metric
bound	I-Metric
of	O
the	O
log	O
-	O
probabilities	O
and	O
then	O
report	O
the	O
Precision	B-Metric
-	I-Metric
Recall	I-Metric
metric	I-Metric
as	O
an	O
evaluation	O
of	O
the	O
quality	O
of	O
the	O
generative	B-Method
model	I-Method
(	O
see	O
Table	O
[	O
reference	O
]	O
.	O
)	O
.	O
	
Perhaps	O
unsurprisingly	O
,	O
generative	B-Method
models	I-Method
did	O
not	O
perform	O
well	O
on	O
the	O
image	B-Task
retrieval	I-Task
task	I-Task
.	O
	
To	O
deal	O
with	O
the	O
large	O
computational	B-Metric
complexity	I-Metric
involved	O
in	O
looping	O
through	O
each	O
test	O
image	O
,	O
we	O
create	O
a	O
shortlist	O
of	O
one	O
hundred	O
images	O
including	O
the	O
correct	O
one	O
,	O
based	O
on	O
the	O
images	O
having	O
the	O
closest	O
Euclidean	O
distance	O
in	O
the	O
last	O
fully	O
-	O
connected	O
feature	O
space	O
of	O
a	O
VGG	B-Method
-	I-Method
like	I-Method
model	I-Method
simonyan_convnet	I-Method
trained	O
on	O
the	O
CIFAR	O
dataset	O
krizhevsky_cifar	O
.	O
	
Since	O
there	O
are	O
“	O
easy	O
”	O
images	O
for	O
which	O
the	O
model	O
assigns	O
high	O
log	O
-	O
probabilities	O
independent	O
of	O
the	O
query	O
caption	O
,	O
we	O
instead	O
look	O
at	O
the	O
ratio	O
of	O
the	O
likelihood	O
of	O
the	O
image	O
conditioned	O
on	O
the	O
sentence	O
to	O
the	O
likelihood	O
of	O
the	O
image	O
conditioned	O
on	O
the	O
mean	O
sentence	B-Method
representation	I-Method
in	O
the	O
training	O
set	O
,	O
following	O
the	O
retrieval	B-Method
protocol	I-Method
of	O
kiros_captions	O
.	O
	
We	O
also	O
found	O
that	O
the	O
lower	O
bound	O
on	O
the	O
test	O
log	O
-	O
probabilities	O
decreased	O
for	O
sharpened	O
images	O
,	O
and	O
that	O
sharpening	O
considerably	O
hurt	O
the	O
retrieval	B-Task
results	O
.	O
	
Since	O
sharpening	O
changes	O
the	O
statistics	O
of	O
images	O
,	O
the	O
estimated	O
log	O
-	O
probabilities	O
of	O
image	O
pixels	O
is	O
not	O
necessarily	O
a	O
good	O
metric	O
.	O
	
Some	O
examples	O
of	O
generated	B-Task
images	I-Task
before	O
and	O
after	O
sharpening	O
are	O
shown	O
in	O
Appendix	O
C.	O
Instead	O
of	O
calculating	O
error	O
per	O
pixel	O
,	O
we	O
turn	O
to	O
a	O
smarter	O
metric	O
,	O
the	O
Structural	B-Metric
Similarity	I-Metric
Index	I-Metric
(	O
SSI	B-Metric
)	O
wang_ssi	O
,	O
which	O
incorporates	O
luminance	O
and	O
contrast	O
masking	O
into	O
the	O
error	B-Task
calculation	I-Task
.	O
	
Strong	O
inter	O
-	O
dependencies	O
of	O
closer	O
pixels	O
are	O
also	O
taken	O
into	O
account	O
and	O
the	O
metric	O
is	O
calculated	O
on	O
small	O
windows	O
of	O
the	O
images	O
.	O
	
Due	O
to	O
independence	O
property	O
of	O
test	O
captions	O
,	O
we	O
sampled	O
fifty	O
images	O
from	O
the	O
prior	O
of	O
each	O
generative	B-Method
model	I-Method
for	O
every	O
caption	O
in	O
the	O
test	O
set	O
in	O
order	O
to	O
calculate	O
SSI	B-Metric
.	O
	
As	O
you	O
can	O
see	O
on	O
Table	O
[	O
reference	O
]	O
,	O
SSI	B-Metric
scores	I-Metric
achieved	O
by	O
variational	B-Method
models	I-Method
were	O
higher	O
compared	O
to	O
SSI	B-Metric
score	I-Metric
achieved	O
by	O
LAPGAN	B-Method
.	O
	
c	O
	
——	O
c	O
c	O
	
c	O
c	O
c	O
——	O
c	O
c	O
Microsoft	B-Material
COCO	I-Material
(	O
prior	O
to	O
sharpening	O
)	O
Image	B-Method
Retrieval	I-Method
Image	I-Method
Similarity	I-Method
Model	I-Method
	
R@1	O
	
R@5	O
	
R@10	O
	
R@50	O
	
Med	O
r	O
	
SSI	B-Metric
LAPGAN	I-Metric
-	O
-	O
-	O
-	O
-	O
0.08	O
0.07	O
	
Fully	B-Method
-	I-Method
Conn	I-Method
VAE	I-Method
1.0	O
6.6	O
12.0	O
53.4	O
47	O
	
0.156	O
0.10	O
Conv	B-Method
-	I-Method
Deconv	I-Method
VAE	I-Method
1.0	O
6.5	O
12.0	O
52.9	O
48	O
0.164	O
0.10	O
skipthoughtDRAW	O
2.0	O
11.2	O
	
18.9	O
63.3	O
	
36	O
0.157	O
0.11	O
noalignDRAW	O
2.8	O
14.1	O
23.1	O
68.0	O
31	O
0.155	O
	
0.11	O
alignDRAW	O
3.0	O
14.0	O
	
22.9	O
68.5	O
31	O
0.156	O
0.11	O
	
section	O
:	O
Discussion	O
	
In	O
this	O
paper	O
,	O
we	O
demonstrated	O
that	O
the	O
alignDRAW	B-Method
model	I-Method
,	O
a	O
combination	O
of	O
a	O
recurrent	B-Method
variational	I-Method
autoencoder	I-Method
with	O
an	O
alignment	B-Method
model	I-Method
over	O
words	O
,	O
succeeded	O
in	O
generating	O
images	O
that	O
correspond	O
to	O
a	O
given	O
input	O
caption	O
.	O
	
By	O
extensively	O
using	O
attentional	B-Method
mechanisms	I-Method
,	O
our	O
model	O
gained	O
several	O
advantages	O
.	O
	
Namely	O
,	O
the	O
use	O
of	O
the	O
visual	B-Method
attention	I-Method
mechanism	I-Method
allowed	O
us	O
to	O
decompose	O
the	O
problem	O
of	O
image	B-Task
generation	I-Task
into	O
a	O
series	O
of	O
steps	O
instead	O
of	O
a	O
single	O
forward	O
pass	O
,	O
while	O
the	O
attention	O
over	O
words	O
provided	O
us	O
an	O
insight	O
whenever	O
our	O
model	O
failed	O
to	O
generate	O
a	O
relevant	O
image	O
.	O
	
Additionally	O
,	O
our	O
model	O
generated	B-Task
images	I-Task
corresponding	O
to	O
captions	O
which	O
generalized	O
beyond	O
the	O
training	O
set	O
,	O
such	O
as	O
sentences	O
describing	O
novel	O
scenarios	O
which	O
are	O
highly	O
unlikely	O
to	O
occur	O
in	O
real	O
life	O
.	O
	
Because	O
the	O
alignDRAW	B-Method
model	I-Method
tends	O
to	O
output	O
slightly	O
blurry	O
samples	O
,	O
we	O
augmented	O
the	O
model	O
with	O
a	O
sharpening	B-Method
post	I-Method
-	I-Method
processing	I-Method
step	I-Method
in	O
which	O
GAN	B-Method
generated	O
edges	O
which	O
were	O
added	O
to	O
the	O
alignDRAW	O
samples	O
.	O
	
Unfortunately	O
,	O
this	O
is	O
not	O
an	O
ideal	O
solution	O
due	O
to	O
the	O
fact	O
that	O
the	O
whole	O
model	O
was	O
not	O
trained	O
in	O
an	O
end	O
-	O
to	O
-	O
end	O
fashion	O
.	O
	
Therefore	O
a	O
direction	O
of	O
future	O
work	O
would	O
be	O
to	O
find	O
methods	O
that	O
can	O
bypass	O
the	O
separate	O
post	B-Method
-	I-Method
processing	I-Method
step	I-Method
and	O
output	O
sharp	O
images	O
directly	O
in	O
an	O
end	O
-	O
to	O
-	O
end	O
manner	O
.	O
	
Acknowledgments	O
:	O
	
This	O
work	O
was	O
supported	O
by	O
Samsung	O
and	O
IARPA	O
,	O
Raytheon	O
BBN	O
Contract	O
	
No	O
.	O
D11PC20071	O
.	O
	
We	O
would	O
like	O
to	O
thank	O
developers	O
of	O
Theano	O
the	O
authors	O
of	O
for	O
open	O
sourcing	O
their	O
code	O
,	O
and	O
Ryan	O
Kiros	O
and	O
Nitish	O
Srivastava	O
for	O
helpful	O
discussions	O
.	O
	
bibliography	O
:	O
References	O
	
appendix	O
:	O
Appendix	O
A	O
:	O
MNIST	O
With	O
Captions	O
	
As	O
an	O
additional	O
experiment	O
,	O
we	O
trained	O
our	O
model	O
on	O
the	O
MNIST	O
dataset	O
with	O
artificial	O
captions	O
.	O
	
Either	O
one	O
or	O
two	O
digits	O
from	O
the	O
MNIST	O
training	O
dataset	O
were	O
placed	O
on	O
a	O
blank	O
image	O
.	O
	
One	O
digit	O
was	O
placed	O
in	O
one	O
of	O
the	O
four	O
	
(	O
top	O
-	O
left	O
,	O
top	O
-	O
right	O
,	O
bottom	O
-	O
left	O
or	O
bottom	O
-	O
right	O
)	O
corners	O
of	O
the	O
image	O
.	O
	
Two	O
digits	O
were	O
either	O
placed	O
horizontally	O
or	O
vertically	O
in	O
non	O
-	O
overlapping	O
fashion	O
.	O
	
The	O
corresponding	O
artificial	O
captions	O
specified	O
the	O
identity	O
of	O
each	O
digit	O
along	O
with	O
their	O
relative	O
positions	O
,	O
e.g.	O
	
“	O
	
The	O
digit	O
three	O
is	O
at	O
the	O
top	O
of	O
the	O
digit	O
one	O
”	O
,	O
or	O
“	O
	
The	O
digit	O
seven	O
is	O
at	O
the	O
bottom	O
left	O
of	O
the	O
image	O
”	O
.	O
	
The	O
generated	B-Task
images	I-Task
together	O
with	O
the	O
attention	O
alignments	O
are	O
displayed	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
The	O
model	O
correctly	O
displayed	O
the	O
specified	O
digits	O
at	O
the	O
described	O
positions	O
and	O
even	O
managed	O
to	O
generalize	O
reasonably	O
well	O
to	O
the	O
configurations	O
that	O
were	O
never	O
present	O
during	O
training	O
.	O
	
In	O
the	O
case	O
of	O
generating	O
two	O
digits	O
,	O
the	O
model	O
would	O
dynamically	O
attend	O
to	O
the	O
digit	O
in	O
the	O
caption	O
it	O
was	O
drawing	O
at	O
that	O
particular	O
time	O
-	O
step	O
.	O
	
Similarly	O
,	O
in	O
the	O
setting	O
where	O
the	O
caption	O
specified	O
only	O
a	O
single	O
digit	O
,	O
the	O
model	O
would	O
correctly	O
attend	O
to	O
the	O
digit	O
in	O
the	O
caption	O
during	O
the	O
whole	O
generation	B-Task
process	I-Task
.	O
	
In	O
both	O
cases	O
,	O
the	O
model	O
placed	O
small	O
attention	O
values	O
on	O
the	O
words	O
describing	O
the	O
position	O
of	O
digits	O
in	O
the	O
images	O
.	O
	
appendix	O
:	O
Appendix	O
B	O
:	O
Training	O
Details	O
	
subsection	O
:	O
Hyperparameters	O
	
Each	O
parameter	O
in	O
alignDRAW	O
was	O
initialized	O
by	O
sampling	O
from	O
a	O
Gaussian	B-Method
distribution	I-Method
with	O
mean	O
and	O
standard	O
deviation	O
.	O
	
The	O
model	O
was	O
trained	O
using	O
RMSprop	B-Method
with	O
an	O
initial	O
learning	B-Metric
rate	I-Metric
of	O
.	O
	
For	O
the	O
Microsoft	B-Material
COCO	I-Material
task	O
,	O
we	O
trained	O
our	O
model	O
for	O
epochs	O
.	O
	
The	O
learning	B-Metric
rate	I-Metric
was	O
reduced	O
to	O
after	O
epochs	O
.	O
	
For	O
the	O
MNIST	B-Task
with	I-Task
Captions	I-Task
task	I-Task
,	O
the	O
model	O
was	O
trained	O
for	O
150	O
epochs	O
and	O
the	O
learning	B-Metric
rate	I-Metric
was	O
reduced	O
to	O
after	O
110	O
epochs	O
.	O
	
During	O
each	O
epoch	O
,	O
randomly	O
created	O
training	O
samples	O
were	O
used	O
for	O
learning	B-Task
.	O
	
The	O
norm	O
of	O
the	O
gradients	O
was	O
clipped	O
at	O
during	O
training	O
to	O
avoid	O
the	O
exploding	B-Task
gradients	I-Task
problem	I-Task
.	O
	
We	O
used	O
a	O
vocabulary	O
size	O
of	O
and	O
for	O
the	O
Microsoft	B-Material
COCO	I-Material
and	O
MNIST	O
with	O
Captions	O
datasets	O
respectively	O
.	O
	
All	O
capital	O
letters	O
in	O
the	O
words	O
were	O
converted	O
to	O
small	O
letters	O
as	O
a	O
preprocessing	O
step	O
.	O
	
For	O
all	O
tasks	O
,	O
the	O
hidden	O
states	O
and	O
in	O
the	O
language	B-Method
model	I-Method
had	O
units	O
.	O
	
Hence	O
the	O
dimensionality	O
of	O
the	O
concatenated	O
state	O
of	O
the	O
Bidirectional	B-Method
LSTM	I-Method
was	O
256	O
.	O
	
The	O
parameters	O
in	O
the	O
align	O
operator	O
(	O
Eq	O
.	O
	
[	O
reference	O
]	O
)	O
had	O
a	O
dimensionality	O
of	O
,	O
so	O
	
that	O
,	O
,	O
and	O
.	O
	
The	O
architectural	O
configurations	O
of	O
the	O
alignDRAW	B-Method
models	I-Method
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
c	O
—	O
c	O
c	O
c	O
c	O
	
c	O
c	O
alignDRAW	O
	
Model	O
Task	O
#	O
glimpses	O
	
Inference	O
Generative	O
Latent	O
Read	O
Size	O
Write	O
Size	O
T	O
Dim	O
of	O
Dim	O
of	O
Dim	O
of	O
MS	B-Material
COCO	I-Material
	
32	O
550	O
550	O
275	O
9	O
9	O
MNIST	O
32	O
300	O
300	O
150	O
8	O
8	O
	
The	O
GAN	B-Method
model	O
used	O
for	O
sharpening	B-Task
had	O
the	O
same	O
configuration	O
as	O
the	O
model	O
trained	O
by	O
on	O
the	O
edge	O
residuals	O
of	O
the	O
CIFAR	O
dataset	O
.	O
	
The	O
configuration	O
can	O
be	O
found	O
at	O
.	O
	
The	O
model	O
was	O
trained	O
for	O
epochs	O
.	O
	
subsection	O
:	O
Evaluation	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
estimated	O
variational	B-Metric
lower	I-Metric
bounds	I-Metric
on	O
the	O
average	B-Metric
train	I-Metric
/	I-Metric
validation	I-Metric
/	I-Metric
test	I-Metric
log	I-Metric
-	I-Metric
probabilities	I-Metric
.	O
	
Note	O
that	O
the	O
alignDRAW	B-Method
model	I-Method
does	O
not	O
suffer	O
much	O
from	O
overfitting	O
.	O
	
The	O
results	O
substantially	O
worsen	O
after	O
sharpening	O
test	O
images	O
.	O
	
c	O
	
—	O
c	O
c	O
c	O
	
c	O
Model	O
Train	O
Validation	O
Test	O
Test	O
(	O
after	O
sharpening	O
)	O
skipthoughtDRAW	O
	
-	O
1794.29	O
-	O
1797.41	O
	
-	O
1791.37	O
-	O
2045.84	O
	
noalignDRAW	O
	
-	O
1792.14	O
	
-	O
1796.94	O
-	O
1791.15	O
-	O
2051.07	O
	
alignDRAW	O
-	O
1792.15	O
-	O
1797.24	O
	
-	O
1791.53	O
-	O
2042.31	O
	
appendix	O
:	O
Appendix	O
C	O
:	O
Effect	O
of	O
Sharpening	O
Images	O
.	O
	
Some	O
examples	O
of	O
generated	B-Task
images	I-Task
before	O
(	O
top	O
row	O
)	O
and	O
after	O
(	O
bottom	O
row	O
)	O
sharpening	O
images	O
using	O
an	O
adversarial	B-Method
network	I-Method
trained	O
on	O
residuals	O
of	O
a	O
Laplacian	B-Method
pyramid	I-Method
conditioned	O
on	O
the	O
skipthought	O
vectors	O
of	O
the	O
captions	O
.	O
	
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
[	O
]	O
	
document	O
:	O
Neural	B-Method
Architectures	I-Method
for	O
Named	B-Task
Entity	I-Task
Recognition	I-Task
	
State	O
-	O
of	O
-	O
the	O
-	O
art	O
named	B-Method
entity	I-Method
recognition	I-Method
systems	I-Method
rely	O
heavily	O
on	O
hand	O
-	O
crafted	O
features	O
and	O
domain	O
-	O
specific	O
knowledge	O
in	O
order	O
to	O
learn	O
effectively	O
from	O
the	O
small	O
,	O
supervised	O
training	O
corpora	O
that	O
are	O
available	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
introduce	O
two	O
new	O
neural	B-Method
architectures	I-Method
	
—	O
one	O
based	O
on	O
bidirectional	O
LSTMs	B-Method
and	O
conditional	B-Method
random	I-Method
fields	I-Method
,	O
and	O
the	O
other	O
that	O
constructs	O
and	O
labels	O
segments	O
using	O
a	O
transition	B-Method
-	I-Method
based	I-Method
approach	I-Method
inspired	O
by	O
shift	B-Method
-	I-Method
reduce	I-Method
parsers	I-Method
.	O
	
Our	O
models	O
rely	O
on	O
two	O
sources	O
of	O
information	O
about	O
words	O
:	O
character	B-Method
-	I-Method
based	I-Method
word	I-Method
representations	I-Method
learned	O
from	O
the	O
supervised	O
corpus	O
and	O
unsupervised	B-Method
word	I-Method
representations	I-Method
learned	O
from	O
unannotated	O
corpora	O
.	O
	
Our	O
models	O
obtain	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
in	O
NER	B-Task
in	O
four	O
languages	O
without	O
resorting	O
to	O
any	O
language	O
-	O
specific	O
knowledge	O
or	O
resources	O
such	O
as	O
gazetteers	O
.	O
	
section	O
:	O
Introduction	O
	
Named	B-Task
entity	I-Task
recognition	I-Task
(	O
NER	B-Task
)	O
is	O
a	O
challenging	O
learning	B-Task
problem	I-Task
.	O
	
One	O
the	O
one	O
hand	O
,	O
in	O
most	O
languages	O
and	O
domains	O
,	O
there	O
is	O
only	O
a	O
very	O
small	O
amount	O
of	O
supervised	O
training	O
data	O
available	O
.	O
	
On	O
the	O
other	O
,	O
there	O
are	O
few	O
constraints	O
on	O
the	O
kinds	O
of	O
words	O
that	O
can	O
be	O
names	O
,	O
so	O
generalizing	O
from	O
this	O
small	O
sample	O
of	O
data	O
is	O
difficult	O
.	O
	
As	O
a	O
result	O
,	O
carefully	O
constructed	O
orthographic	O
features	O
and	O
language	O
-	O
specific	O
knowledge	O
resources	O
,	O
such	O
as	O
gazetteers	B-Method
,	O
are	O
widely	O
used	O
for	O
solving	O
this	O
task	O
.	O
	
Unfortunately	O
,	O
language	O
-	O
specific	O
resources	O
and	O
features	O
are	O
costly	O
to	O
develop	O
in	O
new	O
languages	O
and	O
new	O
domains	O
,	O
making	O
NER	B-Task
a	O
challenge	O
to	O
adapt	O
.	O
	
Unsupervised	B-Method
learning	I-Method
from	O
unannotated	O
corpora	O
offers	O
an	O
alternative	O
strategy	O
for	O
obtaining	O
better	O
generalization	B-Task
from	O
small	O
amounts	O
of	O
supervision	O
.	O
	
However	O
,	O
even	O
systems	O
that	O
have	O
relied	O
extensively	O
on	O
unsupervised	O
features	O
have	O
used	O
these	O
to	O
augment	O
,	O
rather	O
than	O
replace	O
,	O
hand	O
-	O
engineered	O
features	O
(	O
e.g.	O
,	O
knowledge	O
about	O
capitalization	O
patterns	O
and	O
character	O
classes	O
in	O
a	O
particular	O
language	O
)	O
and	O
specialized	O
knowledge	O
resources	O
(	O
e.g.	O
,	O
gazetteers	O
)	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
present	O
neural	B-Method
architectures	I-Method
for	O
NER	B-Task
that	O
use	O
no	O
language	O
-	O
specific	O
resources	O
or	O
features	O
beyond	O
a	O
small	O
amount	O
of	O
supervised	O
training	O
data	O
and	O
unlabeled	O
corpora	O
.	O
	
Our	O
models	O
are	O
designed	O
to	O
capture	O
two	O
intuitions	O
.	O
	
First	O
,	O
since	O
names	O
often	O
consist	O
of	O
multiple	O
tokens	O
,	O
reasoning	O
jointly	O
over	O
tagging	O
decisions	O
for	O
each	O
token	O
is	O
important	O
.	O
	
We	O
compare	O
two	O
models	O
here	O
,	O
(	O
i	O
)	O
a	O
bidirectional	O
LSTM	B-Method
with	O
a	O
sequential	B-Method
conditional	I-Method
random	I-Method
layer	I-Method
above	O
it	O
(	O
LSTM	B-Method
-	I-Method
CRF	I-Method
;	O
§	O
[	O
reference	O
]	O
)	O
,	O
and	O
(	O
ii	O
)	O
a	O
new	O
model	O
that	O
constructs	O
and	O
labels	O
chunks	O
of	O
input	O
sentences	O
using	O
an	O
algorithm	O
inspired	O
by	O
transition	B-Method
-	I-Method
based	I-Method
parsing	I-Method
with	O
states	O
represented	O
by	O
stack	O
LSTMs	B-Method
(	O
S	B-Method
-	I-Method
LSTM	I-Method
;	O
§	O
[	O
reference	O
]	O
)	O
.	O
	
Second	O
,	O
token	O
-	O
level	O
evidence	O
for	O
“	O
being	O
a	O
name	O
”	O
includes	O
both	O
orthographic	O
evidence	O
(	O
what	O
does	O
the	O
word	O
being	O
tagged	O
as	O
a	O
name	O
look	O
like	O
?	O
)	O
and	O
distributional	O
evidence	O
(	O
where	O
does	O
the	O
word	O
being	O
tagged	O
tend	O
to	O
occur	O
in	O
a	O
corpus	O
?	O
)	O
.	O
	
To	O
capture	O
orthographic	O
sensitivity	O
,	O
we	O
use	O
character	B-Method
-	I-Method
based	I-Method
word	I-Method
representation	I-Method
model	I-Method
to	O
capture	O
distributional	O
sensitivity	O
,	O
we	O
combine	O
these	O
representations	O
with	O
distributional	B-Method
representations	I-Method
.	O
	
Our	O
word	B-Method
representations	I-Method
combine	O
both	O
of	O
these	O
,	O
and	O
dropout	B-Method
training	I-Method
is	O
used	O
to	O
encourage	O
the	O
model	O
to	O
learn	O
to	O
trust	O
both	O
sources	O
of	O
evidence	O
(	O
§	O
[	O
reference	O
]	O
)	O
.	O
	
Experiments	O
in	O
English	B-Material
,	O
Dutch	O
,	O
German	O
,	O
and	O
Spanish	O
show	O
that	O
we	O
are	O
able	O
to	O
obtain	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
NER	B-Metric
performance	I-Metric
with	O
the	O
LSTM	B-Method
-	O
CRF	B-Method
model	O
in	O
Dutch	O
,	O
German	O
,	O
and	O
Spanish	O
,	O
and	O
very	O
near	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
in	O
English	B-Material
without	O
any	O
hand	O
-	O
engineered	O
features	O
or	O
gazetteers	O
(	O
§	O
[	O
reference	O
]	O
)	O
.	O
	
The	O
transition	B-Method
-	I-Method
based	I-Method
algorithm	I-Method
likewise	O
surpasses	O
the	O
best	O
previously	O
published	O
results	O
in	O
several	O
languages	O
,	O
although	O
it	O
performs	O
less	O
well	O
than	O
the	O
LSTM	B-Method
-	O
CRF	B-Method
model	O
.	O
	
section	O
:	O
LSTM	B-Method
-	O
CRF	B-Method
Model	O
	
We	O
provide	O
a	O
brief	O
description	O
of	O
LSTMs	B-Method
and	O
CRFs	B-Method
,	O
and	O
present	O
a	O
hybrid	B-Method
tagging	I-Method
architecture	I-Method
.	O
	
This	O
architecture	O
is	O
similar	O
to	O
the	O
ones	O
presented	O
by	O
collobert2011natural	O
and	O
huang:2015	O
.	O
	
subsection	O
:	O
LSTM	B-Method
	
Recurrent	B-Method
neural	I-Method
networks	I-Method
(	O
RNNs	B-Method
)	O
are	O
a	O
family	O
of	O
neural	B-Method
networks	I-Method
that	O
operate	O
on	O
sequential	O
data	O
.	O
	
They	O
take	O
as	O
input	O
a	O
sequence	O
of	O
vectors	O
and	O
return	O
another	O
sequence	O
that	O
represents	O
some	O
information	O
about	O
the	O
sequence	O
at	O
every	O
step	O
in	O
the	O
input	O
.	O
	
Although	O
RNNs	B-Method
can	O
,	O
in	O
theory	O
,	O
learn	O
long	O
dependencies	O
,	O
in	O
practice	O
they	O
fail	O
to	O
do	O
so	O
and	O
tend	O
to	O
be	O
biased	O
towards	O
their	O
most	O
recent	O
inputs	O
in	O
the	O
sequence	O
.	O
	
Long	B-Method
Short	I-Method
-	I-Method
term	I-Method
Memory	I-Method
Networks	I-Method
(	O
LSTMs	B-Method
)	O
have	O
been	O
designed	O
to	O
combat	O
this	O
issue	O
by	O
incorporating	O
a	O
memory	O
-	O
cell	O
and	O
have	O
been	O
shown	O
to	O
capture	O
long	O
-	O
range	O
dependencies	O
.	O
	
They	O
do	O
so	O
using	O
several	O
gates	O
that	O
control	O
the	O
proportion	O
of	O
the	O
input	O
to	O
give	O
to	O
the	O
memory	O
cell	O
,	O
and	O
the	O
proportion	O
from	O
the	O
previous	O
state	O
to	O
forget	O
.	O
	
We	O
use	O
the	O
following	O
implementation	O
:	O
where	O
is	O
the	O
element	B-Method
-	I-Method
wise	I-Method
sigmoid	I-Method
function	I-Method
,	O
and	O
is	O
the	O
element	O
-	O
wise	O
product	O
.	O
	
For	O
a	O
given	O
sentence	O
containing	O
words	O
,	O
each	O
represented	O
as	O
a	O
-	O
dimensional	O
vector	O
,	O
an	O
LSTM	B-Method
computes	O
a	O
representation	O
of	O
the	O
left	O
context	O
of	O
the	O
sentence	O
at	O
every	O
word	O
.	O
	
Naturally	O
,	O
generating	O
a	O
representation	O
of	O
the	O
right	O
context	O
as	O
well	O
should	O
add	O
useful	O
information	O
.	O
	
This	O
can	O
be	O
achieved	O
using	O
a	O
second	O
LSTM	B-Method
that	O
reads	O
the	O
same	O
sequence	O
in	O
reverse	O
.	O
	
We	O
will	O
refer	O
to	O
the	O
former	O
as	O
the	O
forward	O
LSTM	B-Method
and	O
the	O
latter	O
as	O
the	O
backward	O
LSTM	B-Method
.	O
	
These	O
are	O
two	O
distinct	O
networks	O
with	O
different	O
parameters	O
.	O
	
This	O
forward	O
and	O
backward	O
LSTM	B-Method
pair	O
is	O
referred	O
to	O
as	O
a	O
bidirectional	O
LSTM	B-Method
.	O
	
The	O
representation	O
of	O
a	O
word	O
using	O
this	O
model	O
is	O
obtained	O
by	O
concatenating	O
its	O
left	B-Method
and	I-Method
right	I-Method
context	I-Method
representations	I-Method
,	O
.	O
	
These	O
representations	O
effectively	O
include	O
a	O
representation	O
of	O
a	O
word	O
in	O
context	O
,	O
which	O
is	O
useful	O
for	O
numerous	O
tagging	B-Task
applications	I-Task
.	O
	
subsection	O
:	O
CRF	B-Method
Tagging	O
Models	O
	
A	O
very	O
simple	O
—	O
but	O
surprisingly	O
effective	O
—	O
tagging	B-Method
model	I-Method
is	O
to	O
use	O
the	O
’s	O
as	O
features	O
to	O
make	O
independent	O
tagging	O
decisions	O
for	O
each	O
output	O
.	O
	
Despite	O
this	O
model	O
’s	O
success	O
in	O
simple	O
problems	O
like	O
POS	B-Task
tagging	I-Task
,	O
its	O
independent	O
classification	B-Task
decisions	I-Task
are	O
limiting	O
when	O
there	O
are	O
strong	O
dependencies	O
across	O
output	O
labels	O
.	O
	
NER	B-Task
is	O
one	O
such	O
task	O
,	O
since	O
the	O
“	O
grammar	B-Method
”	O
that	O
characterizes	O
interpretable	O
sequences	O
of	O
tags	O
imposes	O
several	O
hard	O
constraints	O
(	O
e.g.	O
,	O
I	O
-	O
PER	O
can	O
not	O
follow	O
B	O
-	O
LOC	O
;	O
see	O
§	O
[	O
reference	O
]	O
for	O
details	O
)	O
that	O
would	O
be	O
impossible	O
to	O
model	O
with	O
independence	O
assumptions	O
.	O
	
Therefore	O
,	O
instead	O
of	O
modeling	O
tagging	B-Task
decisions	I-Task
independently	O
,	O
we	O
model	O
them	O
jointly	O
using	O
a	O
conditional	B-Method
random	I-Method
field	I-Method
.	O
	
For	O
an	O
input	O
sentence	O
we	O
consider	O
to	O
be	O
the	O
matrix	O
of	O
scores	O
output	O
by	O
the	O
bidirectional	O
LSTM	B-Method
network	O
.	O
	
is	O
of	O
size	O
,	O
where	O
is	O
the	O
number	O
of	O
distinct	O
tags	O
,	O
and	O
corresponds	O
to	O
the	O
score	O
of	O
the	O
tag	O
of	O
the	O
word	O
in	O
a	O
sentence	O
.	O
	
For	O
a	O
sequence	O
of	O
predictions	O
we	O
define	O
its	O
score	O
to	O
be	O
where	O
is	O
a	O
matrix	O
of	O
transition	O
scores	O
such	O
that	O
represents	O
the	O
score	O
of	O
a	O
transition	O
from	O
the	O
tag	O
to	O
tag	O
.	O
	
and	O
are	O
the	O
start	O
and	O
end	O
tags	O
of	O
a	O
sentence	O
,	O
that	O
we	O
add	O
to	O
the	O
set	O
of	O
possible	O
tags	O
.	O
	
is	O
therefore	O
a	O
square	O
matrix	O
of	O
size	O
.	O
	
A	O
softmax	O
over	O
all	O
possible	O
tag	O
sequences	O
yields	O
a	O
probability	O
for	O
the	O
sequence	O
:	O
During	O
training	B-Task
,	O
we	O
maximize	O
the	O
log	O
-	O
probability	O
of	O
the	O
correct	O
tag	O
sequence	O
:	O
where	O
represents	O
all	O
possible	O
tag	O
sequences	O
(	O
even	O
those	O
that	O
do	O
not	O
verify	O
the	O
IOB	O
format	O
)	O
for	O
a	O
sentence	O
.	O
	
From	O
the	O
formulation	O
above	O
,	O
it	O
is	O
evident	O
that	O
we	O
encourage	O
our	O
network	O
to	O
produce	O
a	O
valid	O
sequence	O
of	O
output	O
labels	O
.	O
	
While	O
decoding	B-Task
,	O
we	O
predict	O
the	O
output	O
sequence	O
that	O
obtains	O
the	O
maximum	O
score	O
given	O
by	O
:	O
Since	O
we	O
are	O
only	O
modeling	O
bigram	O
interactions	O
between	O
outputs	O
,	O
both	O
the	O
summation	O
in	O
Eq	O
.	O
	
[	O
reference	O
]	O
and	O
the	O
maximum	O
a	O
posteriori	O
sequence	O
in	O
Eq	O
.	O
	
[	O
reference	O
]	O
can	O
be	O
computed	O
using	O
dynamic	B-Method
programming	I-Method
.	O
	
subsection	O
:	O
Parameterization	O
and	O
Training	O
	
The	O
scores	O
associated	O
with	O
each	O
tagging	O
decision	O
for	O
each	O
token	O
(	O
i.e.	O
,	O
the	O
’s	O
)	O
are	O
defined	O
to	O
be	O
the	O
dot	O
product	O
between	O
the	O
embedding	O
of	O
a	O
word	O
-	O
in	O
-	O
context	O
computed	O
with	O
a	O
bidirectional	O
LSTM	B-Method
—	O
exactly	O
the	O
same	O
as	O
the	O
POS	B-Method
tagging	I-Method
model	I-Method
of	O
ling:2015	B-Method
and	O
these	O
are	O
combined	O
with	O
bigram	O
compatibility	O
scores	O
(	O
i.e.	O
,	O
the	O
’	O
s	O
)	O
.	O
	
This	O
architecture	O
is	O
shown	O
in	O
figure	O
[	O
reference	O
]	O
.	O
	
Circles	O
represent	O
observed	O
variables	O
,	O
diamonds	O
are	O
deterministic	O
functions	O
of	O
their	O
parents	O
,	O
and	O
double	O
circles	O
are	O
random	O
variables	O
.	O
	
The	O
parameters	O
of	O
this	O
model	O
are	O
thus	O
the	O
matrix	O
of	O
bigram	O
compatibility	O
scores	O
,	O
and	O
the	O
parameters	O
that	O
give	O
rise	O
to	O
the	O
matrix	O
,	O
namely	O
the	O
parameters	O
of	O
the	O
bidirectional	O
LSTM	B-Method
,	O
the	O
linear	O
feature	O
weights	O
,	O
and	O
the	O
word	O
embeddings	O
.	O
	
As	O
in	O
part	O
[	O
reference	O
]	O
,	O
let	O
denote	O
the	O
sequence	O
of	O
word	O
embeddings	O
for	O
every	O
word	O
in	O
a	O
sentence	O
,	O
and	O
be	O
their	O
associated	O
tags	O
.	O
	
We	O
return	O
to	O
a	O
discussion	O
of	O
how	O
the	O
embeddings	O
are	O
modeled	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
The	O
sequence	O
of	O
word	O
embeddings	O
is	O
given	O
as	O
input	O
to	O
a	O
bidirectional	O
LSTM	B-Method
,	O
which	O
returns	O
a	O
representation	O
of	O
the	O
left	O
and	O
right	O
context	O
for	O
each	O
word	O
as	O
explained	O
in	O
[	O
reference	O
]	O
.	O
	
These	O
representations	O
are	O
concatenated	O
(	O
)	O
and	O
linearly	O
projected	O
onto	O
a	O
layer	O
whose	O
size	O
is	O
equal	O
to	O
the	O
number	O
of	O
distinct	O
tags	O
.	O
	
Instead	O
of	O
using	O
the	O
softmax	O
output	O
from	O
this	O
layer	O
,	O
we	O
use	O
a	O
CRF	B-Method
as	O
previously	O
described	O
to	O
take	O
into	O
account	O
neighboring	O
tags	O
,	O
yielding	O
the	O
final	O
predictions	O
for	O
every	O
word	O
.	O
	
Additionally	O
,	O
we	O
observed	O
that	O
adding	O
a	O
hidden	O
layer	O
between	O
and	O
the	O
CRF	B-Method
layer	O
marginally	O
improved	O
our	O
results	O
.	O
	
All	O
results	O
reported	O
with	O
this	O
model	O
incorporate	O
this	O
extra	O
-	O
layer	O
.	O
	
The	O
parameters	O
are	O
trained	O
to	O
maximize	O
Eq	O
.	O
	
[	O
reference	O
]	O
of	O
observed	O
sequences	O
of	O
NER	B-Task
tags	O
in	O
an	O
annotated	O
corpus	O
,	O
given	O
the	O
observed	O
words	O
.	O
	
subsection	O
:	O
Tagging	B-Method
Schemes	I-Method
	
The	O
task	O
of	O
named	B-Task
entity	I-Task
recognition	I-Task
is	O
to	O
assign	O
a	O
named	O
entity	O
label	O
to	O
every	O
word	O
in	O
a	O
sentence	O
.	O
	
A	O
single	O
named	O
entity	O
could	O
span	O
several	O
tokens	O
within	O
a	O
sentence	O
.	O
	
Sentences	O
are	O
usually	O
represented	O
in	O
the	O
IOB	O
format	O
(	O
Inside	O
,	O
Outside	O
,	O
Beginning	O
)	O
where	O
every	O
token	O
is	O
labeled	O
as	O
B	O
-	O
label	O
if	O
the	O
token	O
is	O
the	O
beginning	O
of	O
a	O
named	O
entity	O
,	O
I	O
-	O
label	O
if	O
it	O
is	O
inside	O
a	O
named	O
entity	O
but	O
not	O
the	O
first	O
token	O
within	O
the	O
named	O
entity	O
,	O
or	O
O	O
otherwise	O
.	O
	
However	O
,	O
we	O
decided	O
to	O
use	O
the	O
IOBES	B-Method
tagging	I-Method
scheme	I-Method
,	O
a	O
variant	O
of	O
IOB	B-Method
commonly	O
used	O
for	O
named	B-Task
entity	I-Task
recognition	I-Task
,	O
which	O
encodes	O
information	O
about	O
singleton	O
entities	O
(	O
S	O
)	O
and	O
explicitly	O
marks	O
the	O
end	O
of	O
named	O
entities	O
(	O
E	O
)	O
.	O
	
Using	O
this	O
scheme	O
,	O
tagging	O
a	O
word	O
as	O
I	O
-	O
label	O
with	O
high	O
-	O
confidence	O
narrows	O
down	O
the	O
choices	O
for	O
the	O
subsequent	O
word	O
to	O
I	O
-	O
label	O
or	O
E	O
-	O
label	O
,	O
however	O
,	O
the	O
IOB	B-Method
scheme	I-Method
is	O
only	O
capable	O
of	O
determining	O
that	O
the	O
subsequent	O
word	O
can	O
not	O
be	O
the	O
interior	O
of	O
another	O
label	O
.	O
	
ratinov2009design	O
and	O
dai2015enhancing	O
showed	O
that	O
using	O
a	O
more	O
expressive	O
tagging	B-Method
scheme	I-Method
like	O
IOBES	B-Method
improves	O
model	O
performance	O
marginally	O
.	O
	
However	O
,	O
we	O
did	O
not	O
observe	O
a	O
significant	O
improvement	O
over	O
the	O
IOB	B-Method
tagging	I-Method
scheme	I-Method
.	O
	
section	O
:	O
Transition	B-Method
-	I-Method
Based	I-Method
Chunking	I-Method
Model	I-Method
	
As	O
an	O
alternative	O
to	O
the	O
LSTM	B-Method
-	I-Method
CRF	I-Method
discussed	O
in	O
the	O
previous	O
section	O
,	O
we	O
explore	O
a	O
new	O
architecture	O
that	O
chunks	O
and	O
labels	O
a	O
sequence	O
of	O
inputs	O
using	O
an	O
algorithm	O
similar	O
to	O
transition	B-Method
-	I-Method
based	I-Method
dependency	I-Method
parsing	I-Method
.	O
	
This	O
model	O
directly	O
constructs	O
representations	O
of	O
the	O
multi	O
-	O
token	O
names	O
(	O
e.g.	O
,	O
the	O
name	O
Mark	O
Watney	O
is	O
composed	O
into	O
a	O
single	O
representation	O
)	O
.	O
	
This	O
model	O
relies	O
on	O
a	O
stack	B-Method
data	I-Method
structure	I-Method
to	O
incrementally	O
construct	O
chunks	O
of	O
the	O
input	O
.	O
	
To	O
obtain	O
representations	O
of	O
this	O
stack	O
used	O
for	O
predicting	B-Task
subsequent	I-Task
actions	I-Task
,	O
we	O
use	O
the	O
Stack	B-Method
-	I-Method
LSTM	I-Method
presented	O
by	O
dyer:2015	O
,	O
in	O
which	O
the	O
LSTM	B-Method
is	O
augmented	O
with	O
a	O
“	O
stack	O
pointer	O
.	O
	
”	O
	
While	O
sequential	O
LSTMs	B-Method
model	O
sequences	O
from	O
left	O
to	O
right	O
,	O
stack	O
	
LSTMs	B-Method
permit	O
embedding	O
of	O
a	O
stack	O
of	O
objects	O
that	O
are	O
both	O
added	O
to	O
(	O
using	O
a	O
push	O
operation	O
)	O
and	O
removed	O
from	O
(	O
using	O
a	O
pop	O
operation	O
)	O
.	O
	
This	O
allows	O
the	O
Stack	B-Method
-	I-Method
LSTM	I-Method
to	O
work	O
like	O
a	O
stack	B-Method
that	O
maintains	O
a	O
“	O
summary	O
embedding	O
”	O
of	O
its	O
contents	O
.	O
	
We	O
refer	O
to	O
this	O
model	O
as	O
Stack	B-Method
-	I-Method
LSTM	I-Method
or	O
S	B-Method
-	I-Method
LSTM	I-Method
model	O
for	O
simplicity	O
.	O
	
Finally	O
,	O
we	O
refer	O
interested	O
readers	O
to	O
the	O
original	O
paper	O
for	O
details	O
about	O
the	O
Stack	O
-	O
LSTM	B-Method
model	O
since	O
in	O
this	O
paper	O
we	O
merely	O
use	O
the	O
same	O
architecture	O
through	O
a	O
new	O
transition	B-Method
-	I-Method
based	I-Method
algorithm	I-Method
presented	O
in	O
the	O
following	O
Section	O
.	O
	
subsection	O
:	O
Chunking	B-Method
Algorithm	I-Method
	
We	O
designed	O
a	O
transition	B-Method
inventory	I-Method
which	O
is	O
given	O
in	O
Figure	O
[	O
reference	O
]	O
that	O
is	O
inspired	O
by	O
transition	B-Method
-	I-Method
based	I-Method
parsers	I-Method
,	O
in	O
particular	O
the	O
arc	B-Method
-	I-Method
standard	I-Method
parser	I-Method
of	O
nivre2004	O
.	O
	
In	O
this	O
algorithm	O
,	O
we	O
make	O
use	O
of	O
two	O
stacks	O
(	O
designated	O
output	O
and	O
stack	O
representing	O
,	O
respectively	O
,	O
completed	O
chunks	O
and	O
scratch	O
space	O
)	O
and	O
a	O
buffer	O
that	O
contains	O
the	O
words	O
that	O
have	O
yet	O
to	O
be	O
processed	O
.	O
	
The	O
transition	O
inventory	O
contains	O
the	O
following	O
transitions	O
:	O
The	O
shift	B-Method
transition	I-Method
moves	O
a	O
word	O
from	O
the	O
buffer	O
to	O
the	O
stack	O
,	O
the	O
out	O
transition	O
moves	O
a	O
word	O
from	O
the	O
buffer	O
directly	O
into	O
the	O
output	O
stack	O
while	O
the	O
reduce	O
(	O
y	O
)	O
transition	O
pops	O
all	O
items	O
from	O
the	O
top	O
of	O
the	O
stack	O
creating	O
a	O
“	O
chunk	O
,	O
”	O
labels	O
this	O
with	O
label	O
,	O
and	O
pushes	O
a	O
representation	O
of	O
this	O
chunk	O
onto	O
the	O
output	O
stack	O
.	O
	
The	O
algorithm	O
completes	O
when	O
the	O
stack	O
and	O
buffer	O
are	O
both	O
empty	O
.	O
	
The	O
algorithm	O
is	O
depicted	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
which	O
shows	O
the	O
sequence	O
of	O
operations	O
required	O
to	O
process	O
the	O
sentence	O
Mark	O
Watney	O
visited	O
Mars	O
.	O
	
The	O
model	O
is	O
parameterized	O
by	O
defining	O
a	O
probability	O
distribution	O
over	O
actions	O
at	O
each	O
time	O
step	O
,	O
given	O
the	O
current	O
contents	O
of	O
the	O
stack	O
,	O
buffer	O
,	O
and	O
output	O
,	O
as	O
well	O
as	O
the	O
history	O
of	O
actions	O
taken	O
.	O
	
Following	O
dyer:2015	O
,	O
we	O
use	O
stack	O
LSTMs	B-Method
to	O
compute	O
a	O
fixed	O
dimensional	O
embedding	O
of	O
each	O
of	O
these	O
,	O
and	O
take	O
a	O
concatenation	O
of	O
these	O
to	O
obtain	O
the	O
full	O
algorithm	O
state	O
.	O
	
This	O
representation	O
is	O
used	O
to	O
define	O
a	O
distribution	O
over	O
the	O
possible	O
actions	O
that	O
can	O
be	O
taken	O
at	O
each	O
time	O
step	O
.	O
	
The	O
model	O
is	O
trained	O
to	O
maximize	O
the	O
conditional	O
probability	O
of	O
sequences	O
of	O
reference	O
actions	O
(	O
extracted	O
from	O
a	O
labeled	O
training	O
corpus	O
)	O
given	O
the	O
input	O
sentences	O
.	O
	
To	O
label	O
a	O
new	O
input	O
sequence	O
at	O
test	O
time	O
,	O
the	O
maximum	O
probability	O
action	O
is	O
chosen	O
greedily	O
until	O
the	O
algorithm	O
reaches	O
a	O
termination	O
state	O
.	O
	
Although	O
this	O
is	O
not	O
guaranteed	O
to	O
find	O
a	O
global	O
optimum	O
,	O
it	O
is	O
effective	O
in	O
practice	O
.	O
	
Since	O
each	O
token	O
is	O
either	O
moved	O
directly	O
to	O
the	O
output	O
(	O
1	O
action	O
)	O
or	O
first	O
to	O
the	O
stack	O
	
and	O
then	O
the	O
output	O
(	O
2	O
actions	O
)	O
,	O
the	O
total	O
number	O
of	O
actions	O
for	O
a	O
sequence	O
of	O
length	O
is	O
maximally	O
.	O
	
It	O
is	O
worth	O
noting	O
that	O
the	O
nature	O
of	O
this	O
algorithm	B-Method
model	I-Method
makes	O
it	O
agnostic	O
to	O
the	O
tagging	B-Method
scheme	I-Method
used	O
since	O
it	O
directly	O
predicts	O
labeled	O
chunks	O
.	O
	
subsection	O
:	O
Representing	B-Task
Labeled	I-Task
Chunks	I-Task
	
When	O
the	O
operation	O
is	O
executed	O
,	O
the	O
algorithm	O
shifts	O
a	O
sequence	O
of	O
tokens	O
(	O
together	O
with	O
their	O
vector	O
embeddings	O
)	O
from	O
the	O
stack	O
to	O
the	O
output	O
buffer	O
as	O
a	O
single	O
completed	O
chunk	O
.	O
	
To	O
compute	O
an	O
embedding	O
of	O
this	O
sequence	O
,	O
we	O
run	O
a	O
bidirectional	O
LSTM	B-Method
over	O
the	O
embeddings	O
of	O
its	O
constituent	O
tokens	O
together	O
with	O
a	O
token	O
representing	O
the	O
type	O
of	O
the	O
chunk	O
being	O
identified	O
(	O
i.e.	O
,	O
)	O
.	O
	
This	O
function	O
is	O
given	O
as	O
,	O
where	O
is	O
a	O
learned	O
embedding	O
of	O
a	O
label	O
type	O
.	O
	
Thus	O
,	O
the	O
output	O
buffer	O
contains	O
a	O
single	O
vector	B-Method
representation	I-Method
for	O
each	O
labeled	O
chunk	O
that	O
is	O
generated	O
,	O
regardless	O
of	O
its	O
length	O
.	O
	
section	O
:	O
Input	O
Word	B-Method
Embeddings	I-Method
	
The	O
input	O
layers	O
to	O
both	O
of	O
our	O
models	O
are	O
vector	B-Method
representations	I-Method
of	I-Method
individual	I-Method
words	I-Method
.	O
	
Learning	O
independent	B-Method
representations	I-Method
for	O
word	O
types	O
from	O
the	O
limited	O
NER	B-Task
training	O
data	O
is	O
a	O
difficult	O
problem	O
:	O
there	O
are	O
simply	O
too	O
many	O
parameters	O
to	O
reliably	O
estimate	O
.	O
	
Since	O
many	O
languages	O
have	O
orthographic	O
or	O
morphological	O
evidence	O
that	O
something	O
is	O
a	O
name	O
(	O
or	O
not	O
a	O
name	O
)	O
,	O
we	O
want	O
representations	O
that	O
are	O
sensitive	O
to	O
the	O
spelling	O
of	O
words	O
.	O
	
We	O
therefore	O
use	O
a	O
model	O
that	O
constructs	O
representations	O
of	O
words	O
from	O
representations	O
of	O
the	O
characters	O
they	O
are	O
composed	O
of	O
(	O
[	O
reference	O
]	O
)	O
.	O
	
Our	O
second	O
intuition	O
is	O
that	O
names	O
,	O
which	O
may	O
individually	O
be	O
quite	O
varied	O
,	O
appear	O
in	O
regular	O
contexts	O
in	O
large	O
corpora	O
.	O
	
Therefore	O
we	O
use	O
embeddings	O
learned	O
from	O
a	O
large	O
corpus	O
that	O
are	O
sensitive	O
	
to	O
word	O
order	O
(	O
[	O
reference	O
]	O
)	O
.	O
	
Finally	O
,	O
to	O
prevent	O
the	O
models	O
from	O
depending	O
on	O
one	O
representation	O
or	O
the	O
other	O
too	O
strongly	O
,	O
we	O
use	O
dropout	B-Method
training	I-Method
and	O
find	O
this	O
is	O
crucial	O
for	O
good	O
generalization	B-Task
performance	O
(	O
[	O
reference	O
]	O
)	O
.	O
	
subsection	O
:	O
Character	B-Method
-	I-Method
based	I-Method
models	I-Method
of	I-Method
words	I-Method
	
An	O
important	O
distinction	O
of	O
our	O
work	O
from	O
most	O
previous	O
approaches	O
is	O
that	O
we	O
learn	O
character	O
-	O
level	O
features	O
while	O
training	O
instead	O
of	O
hand	O
-	O
engineering	O
prefix	O
and	O
suffix	O
information	O
about	O
words	O
.	O
	
Learning	B-Task
character	I-Task
-	I-Task
level	I-Task
embeddings	I-Task
has	O
the	O
advantage	O
of	O
learning	O
representations	O
specific	O
to	O
the	O
task	O
and	O
domain	O
at	O
hand	O
.	O
	
They	O
have	O
been	O
found	O
useful	O
for	O
morphologically	O
rich	O
languages	O
and	O
to	O
handle	O
the	O
out	B-Task
-	I-Task
of	I-Task
-	I-Task
vocabulary	I-Task
problem	I-Task
for	O
tasks	O
like	O
part	B-Task
-	I-Task
of	I-Task
-	I-Task
speech	I-Task
tagging	I-Task
and	O
language	B-Task
modeling	I-Task
or	O
dependency	B-Task
parsing	I-Task
.	O
	
Figure	O
[	O
reference	O
]	O
describes	O
our	O
architecture	O
to	O
generate	O
a	O
word	B-Method
embedding	I-Method
for	O
a	O
word	O
from	O
its	O
characters	O
.	O
	
A	O
character	O
lookup	O
table	O
initialized	O
at	O
random	O
contains	O
an	O
embedding	O
for	O
every	O
character	O
.	O
	
The	O
character	O
embeddings	O
corresponding	O
to	O
every	O
character	O
in	O
a	O
word	O
are	O
given	O
in	O
direct	O
and	O
reverse	O
order	O
to	O
a	O
forward	O
and	O
a	O
backward	O
LSTM	B-Method
.	O
	
The	O
embedding	O
for	O
a	O
word	O
derived	O
from	O
its	O
characters	O
is	O
the	O
concatenation	O
of	O
its	O
forward	B-Method
and	I-Method
backward	I-Method
representations	I-Method
from	O
the	O
bidirectional	O
LSTM	B-Method
.	O
	
This	O
character	B-Method
-	I-Method
level	I-Method
representation	I-Method
is	O
then	O
concatenated	O
with	O
a	O
word	B-Method
-	I-Method
level	I-Method
representation	I-Method
from	O
a	O
word	B-Method
lookup	I-Method
-	I-Method
table	I-Method
.	O
	
During	O
testing	O
,	O
words	O
that	O
do	O
not	O
have	O
an	O
embedding	O
in	O
the	O
lookup	O
table	O
are	O
mapped	O
to	O
a	O
UNK	B-Method
embedding	I-Method
.	O
	
To	O
train	O
the	O
UNK	B-Method
embedding	I-Method
,	O
we	O
replace	O
singletons	O
with	O
the	O
UNK	B-Method
embedding	I-Method
with	O
a	O
probability	O
.	O
	
In	O
all	O
our	O
experiments	O
,	O
the	O
hidden	O
dimension	O
of	O
the	O
forward	O
and	O
backward	O
character	O
LSTMs	B-Method
are	O
each	O
,	O
which	O
results	O
in	O
our	O
character	B-Method
-	I-Method
based	I-Method
representation	I-Method
of	I-Method
words	I-Method
being	O
of	O
dimension	O
.	O
	
Recurrent	B-Method
models	I-Method
like	O
RNNs	B-Method
and	O
LSTMs	B-Method
are	O
capable	O
of	O
encoding	O
very	O
long	O
sequences	O
,	O
however	O
,	O
they	O
have	O
a	O
representation	O
biased	O
towards	O
their	O
most	O
recent	O
inputs	O
.	O
	
As	O
a	O
result	O
,	O
we	O
expect	O
the	O
final	O
representation	O
of	O
the	O
forward	O
LSTM	B-Method
to	O
be	O
an	O
accurate	O
representation	O
of	O
the	O
suffix	O
of	O
the	O
word	O
,	O
and	O
the	O
final	O
state	O
of	O
the	O
backward	O
LSTM	B-Method
to	O
be	O
a	O
better	O
representation	O
of	O
its	O
prefix	O
.	O
	
Alternative	O
approaches	O
—	O
most	O
notably	O
like	O
convolutional	B-Method
networks	I-Method
—	O
have	O
been	O
proposed	O
to	O
learn	O
representations	B-Task
of	I-Task
words	I-Task
from	O
their	O
characters	O
.	O
	
However	O
,	O
convnets	B-Method
are	O
designed	O
to	O
discover	O
position	O
-	O
invariant	O
features	O
of	O
their	O
inputs	O
.	O
	
While	O
this	O
is	O
appropriate	O
for	O
many	O
problems	O
,	O
e.g.	O
,	O
image	B-Task
recognition	I-Task
(	O
a	O
cat	O
can	O
appear	O
anywhere	O
in	O
a	O
picture	O
)	O
,	O
we	O
argue	O
that	O
important	O
information	O
is	O
position	O
dependent	O
(	O
e.g.	O
,	O
prefixes	O
and	O
suffixes	O
encode	O
different	O
information	O
than	O
stems	O
)	O
,	O
making	O
LSTMs	B-Method
an	O
a	O
priori	O
better	O
function	O
class	O
for	O
modeling	O
the	O
relationship	O
between	O
words	O
and	O
their	O
characters	O
.	O
	
subsection	O
:	O
Pretrained	B-Method
embeddings	I-Method
	
As	O
in	O
collobert2011natural	O
,	O
we	O
use	O
pretrained	O
word	O
embeddings	O
to	O
initialize	O
our	O
lookup	O
table	O
.	O
	
We	O
observe	O
significant	O
improvements	O
using	O
pretrained	B-Method
word	I-Method
embeddings	I-Method
over	O
randomly	O
initialized	O
ones	O
.	O
	
Embeddings	B-Method
are	O
pretrained	O
using	O
skip	B-Method
-	I-Method
n	I-Method
-	I-Method
gram	I-Method
,	O
a	O
variation	O
of	O
word2vec	B-Method
that	O
accounts	O
for	O
word	O
order	O
.	O
	
These	O
embeddings	O
are	O
fine	O
-	O
tuned	O
during	O
training	O
.	O
	
Word	O
embeddings	O
for	O
Spanish	O
,	O
Dutch	O
,	O
German	O
and	O
English	B-Material
are	O
trained	O
using	O
the	O
Spanish	O
Gigaword	O
version	O
3	O
,	O
the	O
Leipzig	O
corpora	O
collection	O
,	O
the	O
German	O
monolingual	O
training	O
data	O
from	O
the	O
2010	O
Machine	B-Task
Translation	I-Task
Workshop	I-Task
and	O
the	O
English	O
Gigaword	O
version	O
4	O
(	O
with	O
the	O
LA	O
Times	O
and	O
NY	O
Times	O
portions	O
removed	O
)	O
respectively	O
.	O
	
We	O
use	O
an	O
embedding	O
dimension	O
of	O
for	O
English	B-Material
,	O
for	O
other	O
languages	O
,	O
a	O
minimum	O
word	O
frequency	O
cutoff	O
of	O
,	O
and	O
a	O
window	O
size	O
of	O
.	O
	
subsection	O
:	O
Dropout	B-Method
training	I-Method
	
Initial	O
experiments	O
showed	O
that	O
character	O
-	O
level	O
embeddings	O
did	O
not	O
improve	O
our	O
overall	O
performance	O
when	O
used	O
in	O
conjunction	O
with	O
pretrained	B-Method
word	I-Method
representations	I-Method
.	O
	
To	O
encourage	O
the	O
model	O
to	O
depend	O
on	O
both	O
representations	O
,	O
we	O
use	O
dropout	B-Method
training	I-Method
,	O
applying	O
a	O
dropout	O
mask	O
to	O
the	O
final	O
embedding	B-Method
layer	I-Method
just	O
before	O
the	O
input	O
to	O
the	O
bidirectional	O
LSTM	B-Method
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
We	O
observe	O
a	O
significant	O
improvement	O
in	O
our	O
model	O
’s	O
performance	O
after	O
using	O
dropout	B-Method
(	O
see	O
table	O
[	O
reference	O
]	O
)	O
.	O
	
section	O
:	O
Experiments	O
	
This	O
section	O
presents	O
the	O
methods	O
we	O
use	O
to	O
train	O
our	O
models	O
,	O
the	O
results	O
we	O
obtained	O
on	O
various	O
tasks	O
and	O
the	O
impact	O
of	O
our	O
networks	O
’	O
configuration	O
on	O
model	O
performance	O
.	O
	
subsection	O
:	O
Training	O
	
For	O
both	O
models	O
presented	O
,	O
we	O
train	O
our	O
networks	O
using	O
the	O
back	B-Method
-	I-Method
propagation	I-Method
algorithm	I-Method
updating	O
our	O
parameters	O
on	O
every	O
training	O
example	O
,	O
one	O
at	O
a	O
time	O
,	O
using	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
(	O
SGD	B-Method
)	O
with	O
a	O
learning	O
rate	O
of	O
and	O
a	O
gradient	B-Method
clipping	I-Method
of	O
.	O
	
Several	O
methods	O
have	O
been	O
proposed	O
to	O
enhance	O
the	O
performance	O
of	O
SGD	B-Method
,	O
such	O
as	O
Adadelta	B-Method
or	O
Adam	B-Method
.	O
	
Although	O
we	O
observe	O
faster	O
convergence	B-Metric
using	O
these	O
methods	O
,	O
none	O
of	O
them	O
perform	O
as	O
well	O
as	O
SGD	B-Method
with	O
gradient	B-Method
clipping	I-Method
.	O
	
Our	O
LSTM	B-Method
-	O
CRF	B-Method
model	O
uses	O
a	O
single	B-Method
layer	I-Method
for	O
the	O
forward	O
and	O
backward	O
LSTMs	B-Method
whose	O
dimensions	O
are	O
set	O
to	O
.	O
	
Tuning	O
this	O
dimension	O
did	O
not	O
significantly	O
impact	O
model	O
performance	O
.	O
	
We	O
set	O
the	O
dropout	B-Metric
rate	I-Metric
to	O
.	O
	
Using	O
higher	O
rates	O
negatively	O
impacted	O
our	O
results	O
,	O
while	O
smaller	O
rates	O
led	O
to	O
longer	O
training	B-Metric
time	I-Metric
.	O
	
The	O
stack	O
-	O
LSTM	B-Method
model	O
uses	O
two	O
layers	O
each	O
of	O
dimension	O
for	O
each	O
stack	O
.	O
	
The	O
embeddings	O
of	O
the	O
actions	O
used	O
in	O
the	O
composition	B-Method
functions	I-Method
have	O
dimensions	O
each	O
,	O
and	O
the	O
output	O
embedding	O
is	O
of	O
dimension	O
.	O
	
We	O
experimented	O
with	O
different	O
dropout	B-Metric
rates	I-Metric
and	O
reported	O
the	O
scores	O
using	O
the	O
best	O
dropout	B-Metric
rate	I-Metric
for	O
each	O
language	O
.	O
	
It	O
is	O
a	O
greedy	B-Method
model	I-Method
that	O
apply	O
locally	O
optimal	O
actions	O
until	O
the	O
entire	O
sentence	O
is	O
processed	O
,	O
further	O
improvements	O
might	O
be	O
obtained	O
with	O
beam	B-Method
search	I-Method
or	O
training	O
with	O
exploration	B-Task
.	O
	
subsection	O
:	O
Data	O
Sets	O
	
We	O
test	O
our	O
model	O
on	O
different	O
datasets	O
for	O
named	B-Task
entity	I-Task
recognition	I-Task
.	O
	
To	O
demonstrate	O
our	O
model	O
	
’s	O
ability	O
to	O
generalize	O
to	O
different	O
languages	O
,	O
we	O
present	O
results	O
on	O
the	O
CoNLL	O
-	O
2002	O
and	O
CoNLL	B-Material
-	I-Material
2003	I-Material
datasets	I-Material
that	O
contain	O
independent	O
named	O
entity	O
labels	O
for	O
English	B-Material
,	O
Spanish	O
,	O
German	O
and	O
Dutch	O
.	O
	
All	O
datasets	O
contain	O
four	O
different	O
types	O
of	O
named	O
entities	O
:	O
locations	O
,	O
persons	O
,	O
organizations	O
,	O
and	O
miscellaneous	O
entities	O
that	O
do	O
not	O
belong	O
in	O
any	O
of	O
the	O
three	O
previous	O
categories	O
.	O
	
Although	O
POS	O
tags	O
were	O
made	O
available	O
for	O
all	O
datasets	O
,	O
we	O
did	O
not	O
include	O
them	O
in	O
our	O
models	O
.	O
	
We	O
did	O
not	O
perform	O
any	O
dataset	B-Task
preprocessing	I-Task
,	O
apart	O
from	O
replacing	O
every	O
digit	O
with	O
a	O
zero	O
in	O
the	O
English	O
NER	O
dataset	O
.	O
	
subsection	O
:	O
Results	O
	
Table	O
[	O
reference	O
]	O
presents	O
our	O
comparisons	O
with	O
other	O
models	O
for	O
named	B-Task
entity	I-Task
recognition	I-Task
in	O
English	B-Material
.	O
	
To	O
make	O
the	O
comparison	O
between	O
our	O
model	O
and	O
others	O
fair	O
,	O
we	O
report	O
the	O
scores	O
of	O
other	O
models	O
with	O
and	O
without	O
the	O
use	O
of	O
external	O
labeled	O
data	O
such	O
as	O
gazetteers	O
and	O
knowledge	O
bases	O
.	O
	
Our	O
models	O
do	O
not	O
use	O
gazetteers	O
or	O
any	O
external	O
labeled	O
resources	O
.	O
	
The	O
best	O
score	O
reported	O
on	O
this	O
task	O
is	O
by	O
luojoint	O
.	O
	
They	O
obtained	O
a	O
F	B-Metric
of	O
91.2	O
by	O
jointly	O
modeling	O
the	O
NER	B-Task
and	O
entity	B-Task
linking	I-Task
tasks	I-Task
.	O
	
Their	O
model	O
uses	O
a	O
lot	O
of	O
hand	O
-	O
engineered	O
features	O
including	O
spelling	O
features	O
,	O
WordNet	O
clusters	O
,	O
Brown	O
clusters	O
,	O
POS	O
tags	O
,	O
chunks	O
tags	O
,	O
as	O
well	O
as	O
stemming	O
and	O
external	O
knowledge	O
bases	O
like	O
Freebase	O
and	O
Wikipedia	O
.	O
	
Our	O
LSTM	B-Method
-	O
CRF	B-Method
model	O
outperforms	O
all	O
other	O
systems	O
,	O
including	O
the	O
ones	O
using	O
external	O
labeled	O
data	O
like	O
gazetteers	O
.	O
	
Our	O
Stack	O
-	O
LSTM	B-Method
model	O
also	O
outperforms	O
all	O
previous	O
models	O
that	O
do	O
not	O
incorporate	O
external	O
features	O
,	O
apart	O
from	O
the	O
one	O
presented	O
by	O
chiu2015named	O
.	O
	
Tables	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
	
present	O
our	O
results	O
on	O
NER	B-Task
for	O
German	O
,	O
Dutch	O
and	O
Spanish	O
respectively	O
in	O
comparison	O
to	O
other	O
models	O
.	O
	
On	O
these	O
three	O
languages	O
,	O
the	O
LSTM	B-Method
-	O
CRF	B-Method
model	O
significantly	O
outperforms	O
all	O
previous	O
methods	O
,	O
including	O
the	O
ones	O
using	O
external	O
labeled	O
data	O
.	O
	
The	O
only	O
exception	O
is	O
Dutch	O
,	O
where	O
the	O
model	O
of	O
gillick2015multilingual	O
can	O
perform	O
better	O
by	O
leveraging	O
the	O
information	O
from	O
other	O
NER	B-Task
datasets	O
.	O
	
The	O
Stack	B-Method
-	I-Method
LSTM	I-Method
also	O
consistently	O
presents	O
state	O
-	O
the	O
-	O
art	O
(	O
or	O
close	O
to	O
)	O
results	O
compared	O
to	O
systems	O
that	O
do	O
not	O
use	O
external	O
data	O
.	O
	
As	O
we	O
can	O
see	O
in	O
the	O
tables	O
,	O
the	O
Stack	O
-	O
LSTM	B-Method
model	O
is	O
more	O
dependent	O
on	O
character	B-Method
-	I-Method
based	I-Method
representations	I-Method
to	O
achieve	O
competitive	O
performance	O
;	O
we	O
hypothesize	O
that	O
the	O
LSTM	B-Method
-	O
CRF	B-Method
model	O
requires	O
less	O
orthographic	O
information	O
since	O
it	O
gets	O
more	O
contextual	O
information	O
out	O
of	O
the	O
bidirectional	O
LSTMs	B-Method
;	O
however	O
,	O
the	O
Stack	O
-	O
LSTM	B-Method
model	O
consumes	O
the	O
words	O
one	O
by	O
one	O
	
and	O
it	O
just	O
relies	O
on	O
the	O
word	B-Method
representations	I-Method
when	O
it	O
chunks	O
words	O
.	O
	
subsection	O
:	O
Network	B-Method
architectures	I-Method
	
Our	O
models	O
had	O
several	O
components	O
that	O
we	O
could	O
tweak	O
to	O
understand	O
their	O
impact	O
on	O
the	O
overall	O
performance	O
.	O
	
We	O
explored	O
the	O
impact	O
that	O
the	O
CRF	B-Method
,	O
the	O
character	B-Method
-	I-Method
level	I-Method
representations	I-Method
,	O
pretraining	O
of	O
our	O
word	B-Method
embeddings	I-Method
and	O
dropout	B-Method
had	O
on	O
our	O
LSTM	B-Method
-	O
CRF	B-Method
model	O
.	O
	
We	O
observed	O
that	O
pretraining	O
our	O
word	B-Method
embeddings	I-Method
gave	O
us	O
the	O
biggest	O
improvement	O
in	O
overall	O
performance	O
of	O
in	O
F	B-Metric
.	O
	
The	O
CRF	B-Method
layer	O
gave	O
us	O
an	O
increase	O
of	O
,	O
while	O
using	O
dropout	O
resulted	O
in	O
a	O
difference	O
of	O
and	O
finally	O
learning	O
character	O
-	O
level	O
word	O
embeddings	O
resulted	O
in	O
an	O
increase	O
of	O
about	O
.	O
	
For	O
the	O
Stack	B-Method
-	I-Method
LSTM	I-Method
we	O
performed	O
a	O
similar	O
set	O
of	O
experiments	O
.	O
	
Results	O
with	O
different	O
architectures	O
are	O
given	O
in	O
table	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
Related	O
Work	O
	
In	O
the	O
CoNLL	B-Task
-	I-Task
2002	I-Task
shared	I-Task
task	I-Task
,	O
carreras2002named	O
obtained	O
among	O
the	O
best	O
results	O
on	O
both	O
Dutch	O
and	O
Spanish	O
by	O
combining	O
several	O
small	O
fixed	B-Method
-	I-Method
depth	I-Method
decision	I-Method
trees	I-Method
.	O
	
Next	O
year	O
,	O
in	O
the	O
CoNLL	B-Task
-	I-Task
2003	I-Task
Shared	I-Task
Task	I-Task
,	O
florian2003named	O
obtained	O
the	O
best	O
score	O
on	O
German	O
by	O
combining	O
the	O
output	O
of	O
four	O
diverse	B-Method
classifiers	I-Method
.	O
	
qi2009combining	O
later	O
improved	O
on	O
this	O
with	O
a	O
neural	B-Method
network	I-Method
by	O
doing	O
unsupervised	B-Method
learning	I-Method
on	O
a	O
massive	O
unlabeled	O
corpus	O
.	O
	
Several	O
other	O
neural	B-Method
architectures	I-Method
have	O
previously	O
been	O
proposed	O
for	O
NER	B-Task
.	O
	
For	O
instance	O
,	O
collobert2011natural	O
uses	O
a	O
CNN	B-Method
over	O
a	O
sequence	O
of	O
word	B-Method
embeddings	I-Method
with	O
a	O
CRF	B-Method
layer	O
on	O
top	O
.	O
	
This	O
can	O
be	O
thought	O
of	O
as	O
our	O
first	O
model	O
without	O
character	O
-	O
level	O
embeddings	O
and	O
with	O
the	O
bidirectional	O
LSTM	B-Method
being	O
replaced	O
by	O
a	O
CNN	B-Method
.	O
	
More	O
recently	O
,	O
huang:2015	O
presented	O
a	O
model	O
similar	O
to	O
our	O
LSTM	B-Method
-	I-Method
CRF	I-Method
,	O
but	O
using	O
hand	O
-	O
crafted	O
spelling	O
features	O
.	O
	
zhou2015end	O
also	O
used	O
a	O
similar	O
model	O
and	O
adapted	O
it	O
to	O
the	O
semantic	B-Task
role	I-Task
labeling	I-Task
task	I-Task
.	O
	
lin2009phrase	O
used	O
a	O
linear	O
chain	O
CRF	B-Method
with	O
regularization	B-Method
,	O
they	O
added	O
phrase	O
cluster	O
features	O
extracted	O
from	O
the	O
web	O
data	O
and	O
spelling	O
features	O
.	O
	
passos2014lexicon	O
also	O
used	O
a	O
linear	O
chain	O
CRF	B-Method
with	O
spelling	O
features	O
and	O
gazetteers	O
.	O
	
Language	B-Method
independent	I-Method
NER	I-Method
models	I-Method
like	O
ours	O
have	O
also	O
been	O
proposed	O
in	O
the	O
past	O
.	O
	
Cucerzan	O
and	O
Yarowsky	O
cucerzan1999language	O
,	O
cucerzan2002language	O
present	O
semi	B-Method
-	I-Method
supervised	I-Method
bootstrapping	I-Method
algorithms	I-Method
for	O
named	B-Task
entity	I-Task
recognition	I-Task
by	O
	
co	O
-	O
training	O
character	O
-	O
level	O
(	O
word	O
-	O
internal	O
)	O
and	O
token	O
-	O
level	O
(	O
context	O
)	O
features	O
.	O
	
eisenstein2011structured	O
use	O
Bayesian	B-Method
nonparametrics	I-Method
to	O
construct	O
a	O
database	O
of	O
named	O
entities	O
in	O
an	O
almost	O
unsupervised	B-Task
setting	I-Task
.	O
	
ratinov2009design	O
quantitatively	O
compare	O
several	O
approaches	O
for	O
NER	B-Task
and	O
build	O
their	O
own	O
supervised	B-Method
model	I-Method
using	O
a	O
regularized	B-Method
average	I-Method
perceptron	I-Method
and	O
aggregating	B-Method
context	I-Method
information	I-Method
.	O
	
Finally	O
,	O
there	O
is	O
currently	O
a	O
lot	O
of	O
interest	O
in	O
models	O
for	O
NER	B-Task
that	O
use	O
letter	B-Method
-	I-Method
based	I-Method
representations	I-Method
.	O
	
gillick2015multilingual	O
model	O
the	O
task	O
of	O
sequence	B-Task
-	I-Task
labeling	I-Task
as	O
a	O
sequence	B-Task
to	I-Task
sequence	I-Task
learning	I-Task
problem	I-Task
and	O
incorporate	O
character	B-Method
-	I-Method
based	I-Method
representations	I-Method
into	O
their	O
encoder	B-Method
model	I-Method
.	O
	
chiu2015named	O
employ	O
an	O
architecture	O
similar	O
to	O
ours	O
,	O
but	O
instead	O
use	O
CNNs	B-Method
to	O
learn	O
character	O
-	O
level	O
features	O
,	O
in	O
a	O
way	O
similar	O
to	O
the	O
work	O
by	O
santos2015boosting	O
.	O
	
section	O
:	O
Conclusion	O
	
This	O
paper	O
presents	O
two	O
neural	B-Method
architectures	I-Method
for	O
sequence	B-Task
labeling	I-Task
that	O
provide	O
the	O
best	O
NER	B-Task
results	O
ever	O
reported	O
in	O
standard	O
evaluation	O
settings	O
,	O
even	O
compared	O
with	O
models	O
that	O
use	O
external	O
resources	O
,	O
such	O
as	O
gazetteers	O
.	O
	
A	O
key	O
aspect	O
of	O
our	O
models	O
are	O
that	O
they	O
model	O
output	O
label	O
dependencies	O
,	O
either	O
via	O
a	O
simple	O
CRF	B-Method
architecture	O
,	O
or	O
using	O
a	O
transition	B-Method
-	I-Method
based	I-Method
algorithm	I-Method
to	O
explicitly	O
construct	O
and	O
label	O
chunks	O
of	O
the	O
input	O
.	O
	
Word	B-Method
representations	I-Method
are	O
also	O
crucially	O
important	O
for	O
success	O
:	O
we	O
use	O
both	O
pre	O
-	O
trained	O
word	B-Method
representations	I-Method
and	O
“	O
character	B-Method
-	I-Method
based	I-Method
”	I-Method
representations	I-Method
that	O
capture	O
morphological	O
and	O
orthographic	O
information	O
.	O
	
To	O
prevent	O
the	O
learner	O
from	O
depending	O
too	O
heavily	O
on	O
one	O
representation	O
class	O
,	O
dropout	B-Method
is	O
used	O
.	O
	
section	O
:	O
Acknowledgments	O
	
This	O
work	O
was	O
sponsored	O
in	O
part	O
by	O
the	O
Defense	O
Advanced	O
Research	O
Projects	O
Agency	O
(	O
DARPA	O
)	O
Information	O
Innovation	O
Office	O
(	O
I2O	O
)	O
under	O
the	O
Low	O
Resource	O
Languages	O
for	O
Emergent	O
Incidents	O
(	O
LORELEI	O
)	O
program	O
issued	O
by	O
DARPA	O
/	O
I2O	O
under	O
	
Contract	O
No	O
.	O
	
HR0011	O
-	O
15	O
-	O
C	O
-	O
0114	O
.	O
	
Miguel	O
Ballesteros	O
is	O
supported	O
by	O
the	O
European	O
Commission	O
under	O
the	O
contract	O
numbers	O
FP7	O
-	O
ICT	O
-	O
610411	O
(	O
project	O
MULTISENSOR	O
)	O
and	O
H2020	O
-	O
RIA	O
-	O
645012	O
(	O
project	O
KRISTINA	O
)	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Implicit	B-Task
3D	I-Task
Orientation	I-Task
Learning	I-Task
for	O
6D	B-Task
Object	I-Task
Detection	I-Task
from	O
RGB	O
Images	O
	
We	O
propose	O
a	O
real	B-Method
-	I-Method
time	I-Method
RGB	I-Method
-	I-Method
based	I-Method
pipeline	I-Method
for	O
object	B-Task
detection	I-Task
and	O
6D	B-Task
pose	I-Task
estimation	I-Task
.	O
	
Our	O
novel	O
3D	B-Task
orientation	I-Task
estimation	I-Task
is	O
based	O
on	O
a	O
variant	O
of	O
the	O
Denoising	B-Method
Autoencoder	I-Method
that	O
is	O
trained	O
on	O
simulated	O
views	O
of	O
a	O
3D	B-Method
model	I-Method
using	O
Domain	B-Method
Randomization	I-Method
.	O
	
This	O
so	O
-	O
called	O
Augmented	B-Method
Autoencoder	I-Method
has	O
several	O
advantages	O
over	O
existing	O
methods	O
:	O
It	O
does	O
not	O
require	O
real	O
,	O
pose	O
-	O
annotated	O
training	O
data	O
,	O
generalizes	O
to	O
various	O
test	O
sensors	O
and	O
inherently	O
handles	O
object	O
and	O
view	O
symmetries	O
.	O
	
Instead	O
of	O
learning	O
an	O
explicit	O
mapping	O
from	O
input	O
images	O
to	O
object	O
poses	O
,	O
it	O
provides	O
an	O
implicit	O
representation	O
of	O
object	O
orientations	O
defined	O
by	O
samples	O
in	O
a	O
latent	O
space	O
.	O
	
Experiments	O
on	O
the	O
T	B-Material
-	I-Material
LESS	I-Material
and	O
LineMOD	O
datasets	O
show	O
that	O
our	O
method	O
outperforms	O
similar	O
model	B-Method
-	I-Method
based	I-Method
approaches	I-Method
and	O
competes	O
with	O
state	O
-	O
of	O
-	O
the	O
art	O
approaches	O
that	O
require	O
real	O
pose	O
-	O
annotated	O
images	O
.	O
	
VAEname	O
	
=	O
VAE	B-Method
,	O
description	O
=	O
	
VariationalAutoencoder	B-Method
,	O
first=	O
VAE	B-Method
(	O
VAE	B-Method
)	O
	
AEname	O
=	O
AE	B-Method
,	O
description	O
=	O
	
Autoencoder	B-Method
,	O
first=	O
AE	B-Method
	
(	O
AE	B-Method
),	O
plural	O
=	O
AEs	O
,	O
descriptionplural	O
=	O
Autoencoders	B-Method
,	O
firstplural=	O
AE	B-Method
(	O
AE	B-Method
)	O
	
AAEname	B-Method
=	O
	
AAE	B-Method
,	O
description	O
=	O
	
AugmentedAutoencoder	B-Method
,	O
first=	O
AAE	B-Method
	
(	O
AAE	B-Method
),	O
plural	O
=	O
AAEs	B-Method
,	O
descriptionplural	O
=	O
	
AugmentedAutoencoders	O
,	O
firstplural=	O
AAE	B-Method
(	O
AAE	B-Method
)	O
CVAEname	O
=	O
	
CVAE	B-Method
,	O
	
description	O
=	O
ConditionalVariationalAutoencoder	B-Method
,	O
first=	O
CVAE	O
	
(	O
CVAE	O
)	O
	
SSDname	B-Method
=	O
	
SSD	B-Method
,	O
description	O
=	O
	
SingleShotMultiboxDetector	B-Method
,	O
first=	B-Method
SSD	I-Method
(	I-Method
SSD	I-Method
)	I-Method
CNNname	I-Method
	
=	O
CNN	B-Method
,	O
	
description	B-Method
=	O
ConvolutionalNeuralNetwork	B-Method
,	O
first=	B-Method
CNN	I-Method
(	I-Method
CNN	I-Method
),	I-Method
plural	I-Method
	
=	O
CNNs	B-Method
,	O
descriptionplural	B-Method
=	O
ConvolutionalNeuralNetworks	B-Method
,	O
firstplural=	B-Method
CNN	I-Method
(	I-Method
CNN	I-Method
)	O
SIFTname	B-Method
=	O
	
SIFT	B-Method
,	O
	
description	O
=	O
ScaledInvariantFeatureTransform	B-Method
,	O
first	O
=	O
	
ScaledInvariantFeatureTransform	B-Method
(	I-Method
SIFT	I-Method
	
)	O
SURFname	O
=	O
SURF	O
	
,	O
description	O
=	O
SpeededUpRobustFeatures	O
,	O
first	O
=	O
	
SpeededUpRobustFeatures	B-Method
(	I-Method
SURF	I-Method
)	I-Method
PnPname	I-Method
=	O
	
PnP	B-Method
,	O
description	O
=	O
	
Perspective	O
-	O
n	O
-	O
Point	O
,	O
	
first	O
=	O
Perspective	O
-	O
n	O
-	O
Point	O
(	O
PnP	O
)	O
	
RFname	O
=	O
RF	O
,	O
description	O
=	O
	
RandomForrest	O
,	O
first	O
=	O
RandomForest	B-Method
(	I-Method
RF	I-Method
),	I-Method
plural	I-Method
=	I-Method
RFs	I-Method
,	O
	
descriptionplural	B-Method
=	O
RandomForests	B-Method
,	O
firstplural=	O
	
RF	O
(	O
RF	O
)	O
RANSACname	B-Method
=	O
	
RANSAC	B-Method
,	O
description	O
=	O
	
RandomSampleConsensus	B-Method
,	O
first	O
=	O
	
RANSAC	B-Method
,	O
PCAname	B-Method
=	O
	
PCA	B-Method
	
,	O
description	O
=	O
PrincipalComponentAnalysis	B-Method
,	O
first	O
=	O
	
PrincipalComponentAnalysis	B-Method
(	I-Method
PCA	I-Method
)	O
	
LIDARname	B-Method
	
=	O
LIDAR	B-Method
,	O
description	O
	
=	O
LightDetectionAndRanging	O
,	O
first=	O
LIDAR	O
(	O
	
LIDAR	B-Method
)	O
kNNname	B-Method
	
=	O
kNN	O
,	O
	
description	O
=	O
	
k	O
	
-	O
Nearest	B-Method
-	I-Method
Neighbor	I-Method
,	O
first=	B-Method
kNN	I-Method
	
(	O
kNN	B-Method
)	O
MLPname	B-Method
=	O
	
MLP	B-Method
,	O
description	O
=	O
	
MultilayerPerceptron	B-Method
,	O
first=	B-Method
MLP	I-Method
(	I-Method
MLP	I-Method
),	I-Method
plural	I-Method
=	I-Method
MLPs	I-Method
,	O
descriptionplural	B-Method
=	O
	
MultilayerPerceptrons	B-Method
,	O
firstplural=	B-Method
MLP	I-Method
(	I-Method
MLP	I-Method
)	O
	
EMname	B-Method
=	O
EM	O
	
,	O
description	O
=	O
ExpectationMaximization	B-Method
,	O
first=	O
EM	B-Method
(	I-Method
EM	I-Method
)	O
6DOFname=6DOF	O
,	O
description	O
=	O
sixdegreesoffreedom	O
,	O
first=	O
6DOF	O
	
(	O
6DOF	O
)	O
ICPname	O
	
=	O
ICP	B-Method
,	O
description	O
=	O
	
IterativeClosestPoint	B-Method
,	O
first=	O
ICP	B-Method
(	O
ICP	B-Method
)	O
	
KLname	O
=	O
KL	O
,	O
description	O
=	O
	
Kullback	B-Method
-	I-Method
Leibler	I-Method
,	O
first=	B-Method
KL	I-Method
(	O
	
KL	O
)	O
VSDname=	O
,	O
description	O
=	O
VisibleSurfaceDiscrepancy	O
,	O
first=	O
VSD	O
(	O
VSD	O
)	O
	
mAPname	O
=	O
mAP	B-Method
,	O
description	O
=	O
meanAveragePrecision	O
,	O
first=	O
mAP	B-Method
(	O
	
mAP	B-Method
)	O
DAname	O
=	O
DA	O
	
,	O
description	O
=	O
DomainAdaptation	O
,	O
first=	O
DA	O
(	O
DA	O
)	O
DRname	O
=	O
DR	B-Method
,	O
description	O
=	O
	
DomainRandomization	B-Method
,	O
first=	O
DR	B-Method
(	O
DR	B-Method
)	O
GANname	B-Method
=	O
	
GAN	B-Method
,	O
description	O
=	O
GenerativeAdversarialNetwork	O
,	O
first=	O
GAN	B-Method
(	O
	
GAN	B-Method
),	O
plural	O
=	O
GANs	O
,	O
descriptionplural	B-Method
=	O
GenerativeAdversarialNetworks	B-Method
,	O
firstplural=	O
GAN	B-Method
(	O
GAN	B-Method
)	O
PPFname	B-Method
	
=	O
PPF	B-Method
,	O
description	O
=	O
	
PointPairFeatures	O
,	O
first=	O
PPF	B-Method
(	O
PPF	B-Method
)	O
	
section	O
:	O
Introduction	O
	
One	O
of	O
the	O
most	O
important	O
components	O
of	O
modern	O
computer	B-Method
vision	I-Method
systems	I-Method
for	O
applications	O
such	O
as	O
mobile	B-Task
robotic	I-Task
manipulation	I-Task
and	O
augmented	B-Task
reality	I-Task
is	O
a	O
reliable	O
and	O
fast	O
6D	B-Task
object	I-Task
detection	I-Task
module	I-Task
.	O
	
Although	O
,	O
there	O
are	O
very	O
encouraging	O
recent	O
results	O
,	O
a	O
flexible	O
,	O
general	O
,	O
robust	O
and	O
fast	O
solution	O
is	O
not	O
available	O
,	O
yet	O
.	O
	
The	O
reasons	O
for	O
this	O
are	O
manifold	O
.	O
	
First	O
and	O
foremost	O
,	O
current	O
solutions	O
are	O
not	O
robust	O
enough	O
against	O
typical	O
challenges	O
such	O
as	O
object	O
occlusions	O
,	O
different	O
kinds	O
of	O
background	O
clutter	O
,	O
and	O
dynamic	O
changes	O
of	O
the	O
environment	O
.	O
	
Second	O
,	O
existing	O
methods	O
often	O
require	O
certain	O
object	O
properties	O
such	O
as	O
enough	O
textural	O
surface	O
structure	O
or	O
an	O
asymmetric	O
shape	O
to	O
avoid	O
confusions	O
.	O
	
And	O
finally	O
,	O
current	O
systems	O
are	O
not	O
efficient	O
in	O
terms	O
of	O
run	B-Metric
-	I-Metric
time	I-Metric
and	O
in	O
the	O
amount	O
of	O
annotated	O
training	O
data	O
they	O
require	O
.	O
	
Therefore	O
,	O
we	O
propose	O
a	O
novel	O
approach	O
that	O
directly	O
addresses	O
these	O
issues	O
.	O
	
Concretely	O
,	O
our	O
method	O
operates	O
on	O
single	O
RGB	O
images	O
,	O
which	O
significantly	O
increases	O
the	O
usability	O
as	O
no	O
depth	O
information	O
is	O
required	O
.	O
	
We	O
note	O
though	O
that	O
depth	O
maps	O
may	O
be	O
incorporated	O
optionally	O
to	O
refine	O
the	O
estimation	B-Task
.	O
	
As	O
a	O
first	O
step	O
,	O
we	O
apply	O
a	O
SSD	B-Method
that	O
provides	O
object	O
bounding	O
boxes	O
and	O
identifiers	O
.	O
	
On	O
the	O
resulting	O
scene	O
crops	O
,	O
we	O
employ	O
our	O
novel	O
3D	B-Task
orientation	I-Task
estimation	I-Task
algorithm	O
,	O
which	O
is	O
based	O
on	O
a	O
previously	O
trained	O
deep	B-Method
network	I-Method
architecture	I-Method
.	O
	
While	O
deep	B-Method
networks	I-Method
are	O
also	O
used	O
in	O
existing	O
approaches	O
,	O
our	O
approach	O
differs	O
in	O
that	O
we	O
do	O
not	O
explicitly	O
learn	O
from	O
3D	O
pose	O
annotations	O
during	O
training	O
.	O
	
Instead	O
,	O
we	O
implicitly	O
learn	O
representations	O
from	O
rendered	O
3D	O
model	O
views	O
.	O
	
This	O
is	O
accomplished	O
by	O
training	O
a	O
generalized	O
version	O
of	O
the	O
Denoising	B-Method
Autoencoder	I-Method
,	O
that	O
we	O
call	O
’	O
,	O
using	O
a	O
novel	O
Domain	B-Method
Randomization	I-Method
strategy	I-Method
.	O
	
Our	O
approach	O
has	O
several	O
advantages	O
:	O
First	O
,	O
since	O
the	O
training	B-Task
is	O
independent	O
from	O
concrete	O
representations	O
of	O
object	O
orientations	O
within	O
(	O
e.g.	O
quaternions	O
)	O
,	O
we	O
can	O
handle	O
ambiguous	O
poses	O
caused	O
by	O
symmetric	O
views	O
because	O
we	O
avoid	O
one	O
-	O
to	O
-	O
many	O
mappings	O
from	O
images	O
to	O
orientations	O
.	O
	
Second	O
,	O
we	O
learn	O
representations	O
that	O
specifically	O
encode	O
3D	O
orientations	O
while	O
achieving	O
robustness	B-Metric
against	O
occlusion	O
,	O
cluttered	O
backgrounds	O
and	O
generalizing	O
to	O
different	O
environments	O
and	O
test	O
sensors	O
.	O
	
Finally	O
,	O
the	O
AAE	B-Method
does	O
not	O
require	O
any	O
real	O
pose	O
-	O
annotated	O
training	O
data	O
.	O
	
Instead	O
,	O
it	O
is	O
trained	O
to	O
encode	O
3D	O
model	O
views	O
in	O
a	O
self	B-Method
-	I-Method
supervised	I-Method
way	I-Method
,	O
overcoming	O
the	O
need	O
of	O
a	O
large	O
pose	O
-	O
annotated	O
dataset	O
.	O
	
A	O
schematic	O
overview	O
of	O
the	O
approach	O
is	O
shown	O
in	O
Fig	O
[	O
reference	O
]	O
.	O
	
width=	O
	
section	O
:	O
Related	O
Work	O
	
Depth	B-Method
-	I-Method
based	I-Method
methods	I-Method
(	O
e.g.	O
using	O
PPF	B-Method
)	O
have	O
shown	O
robust	O
pose	O
estimation	B-Task
performance	O
on	O
multiple	O
datasets	O
,	O
winning	O
the	O
SIXD	O
challenge	O
2017	O
.	O
	
However	O
,	O
they	O
usually	O
rely	O
on	O
the	O
computationally	O
expensive	O
evaluation	B-Task
of	I-Task
many	I-Task
pose	I-Task
hypotheses	I-Task
.	O
	
Furthermore	O
,	O
existing	O
depth	B-Method
sensors	I-Method
are	O
often	O
more	O
sensitive	O
to	O
sunlight	O
or	O
specular	O
object	O
surfaces	O
than	O
RGB	O
cameras	O
.	O
	
CNN	B-Method
have	O
revolutionized	O
2D	B-Task
object	I-Task
detection	I-Task
from	O
RGB	O
images	O
.	O
	
But	O
,	O
in	O
comparison	O
to	O
2D	B-Task
bounding	I-Task
box	I-Task
annotation	I-Task
,	O
the	O
effort	O
of	O
labeling	O
real	O
images	O
with	O
full	O
6D	B-Task
object	I-Task
poses	I-Task
is	O
magnitudes	O
higher	O
,	O
requires	O
expert	O
knowledge	O
and	O
a	O
complex	O
setup	O
.	O
	
Nevertheless	O
,	O
the	O
majority	O
of	O
learning	O
-	O
based	O
pose	O
estimation	B-Task
methods	O
use	O
real	O
labeled	O
images	O
and	O
are	O
thus	O
restricted	O
to	O
pose	O
-	O
annotated	O
datasets	O
.	O
	
In	O
consequence	O
,	O
some	O
works	O
have	O
proposed	O
to	O
train	O
on	O
synthetic	O
images	O
rendered	O
from	O
a	O
3D	B-Method
model	I-Method
,	O
yielding	O
a	O
great	O
data	O
source	O
with	O
pose	O
labels	O
free	O
of	O
charge	O
.	O
	
However	O
,	O
naive	B-Method
training	I-Method
on	O
synthetic	O
data	O
does	O
not	O
typically	O
generalize	O
to	O
real	O
test	O
images	O
.	O
	
Therefore	O
,	O
a	O
main	O
challenge	O
is	O
to	O
bridge	O
the	O
domain	O
gap	O
that	O
separates	O
simulated	O
views	O
from	O
real	O
camera	O
recordings	O
.	O
	
subsection	O
:	O
Simulation	B-Task
to	O
Reality	B-Task
Transfer	I-Task
	
There	O
exist	O
three	O
major	O
strategies	O
to	O
generalize	O
from	O
synthetic	O
to	O
real	O
data	O
:	O
	
subsubsection	O
:	O
Photo	B-Task
-	I-Task
Realistic	I-Task
Rendering	I-Task
	
of	O
object	O
views	O
and	O
backgrounds	O
has	O
shown	O
mixed	O
generalization	B-Metric
performance	O
for	O
tasks	O
like	O
object	B-Task
detection	I-Task
and	O
viewpoint	B-Task
estimation	I-Task
.	O
	
It	O
is	O
suitable	O
for	O
simple	O
environments	O
and	O
performs	O
well	O
if	O
jointly	O
trained	O
with	O
a	O
relatively	O
small	O
amount	O
of	O
real	O
annotated	O
images	O
.	O
	
However	O
,	O
photo	B-Method
-	I-Method
realistic	I-Method
modeling	I-Method
is	O
always	O
imperfect	O
and	O
requires	O
much	O
effort	O
.	O
	
subsubsection	O
:	O
DA	O
	
refers	O
to	O
leveraging	O
training	O
data	O
from	O
a	O
source	O
domain	O
to	O
a	O
target	O
domain	O
of	O
which	O
a	O
small	O
portion	O
of	O
labeled	O
data	O
(	O
supervised	B-Method
DA	I-Method
)	O
or	O
unlabeled	O
data	O
(	O
unsupervised	B-Method
DA	I-Method
)	O
is	O
available	O
.	O
	
GAN	B-Method
have	O
been	O
deployed	O
for	O
unsupervised	B-Task
DA	I-Task
by	O
generating	O
realistic	O
from	O
synthetic	O
images	O
to	O
train	O
classifiers	B-Method
,	O
3D	B-Method
pose	I-Method
estimators	I-Method
and	O
grasping	B-Method
algorithms	I-Method
.	O
	
While	O
constituting	O
a	O
promising	O
approach	O
,	O
GAN	B-Method
often	O
yield	O
fragile	O
training	O
results	O
.	O
	
Supervised	B-Method
DA	I-Method
can	O
lower	O
the	O
need	O
for	O
real	O
annotated	O
data	O
,	O
but	O
does	O
not	O
abstain	O
from	O
it	O
.	O
	
subsubsection	O
:	O
Domain	B-Method
Randomization	I-Method
(	O
DR	B-Method
)	O
	
builds	O
upon	O
the	O
hypothesis	O
that	O
by	O
training	O
a	O
model	O
on	O
rendered	O
views	O
in	O
a	O
variety	O
of	O
semi	O
-	O
realistic	O
settings	O
(	O
augmented	O
with	O
random	O
lighting	O
conditions	O
,	O
backgrounds	O
,	O
saturation	O
,	O
etc	O
.	O
)	O
,	O
it	O
will	O
also	O
generalize	O
to	O
real	O
images	O
.	O
	
Tobin	O
et	O
al	O
.	O
demonstrated	O
the	O
potential	O
of	O
the	O
DR	B-Method
paradigm	O
for	O
3D	B-Task
shape	I-Task
detection	I-Task
using	O
CNN	B-Method
.	O
	
Hinterstoisser	O
et	O
al	O
.	O
showed	O
that	O
by	O
training	O
only	O
the	O
head	B-Method
network	I-Method
of	O
FasterRCNN	B-Method
with	O
randomized	O
synthetic	O
views	O
of	O
a	O
textured	B-Method
3D	I-Method
model	I-Method
,	O
it	O
also	O
generalizes	O
well	O
to	O
real	O
images	O
.	O
	
It	O
must	O
be	O
noted	O
,	O
that	O
their	O
rendering	O
is	O
almost	O
photo	O
-	O
realistic	O
as	O
the	O
textured	B-Method
3D	I-Method
models	I-Method
have	O
very	O
high	O
quality	O
.	O
	
Recently	O
,	O
Kehl	O
et	O
al	O
.	O
pioneered	O
an	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
CNN	I-Method
,	O
called	O
’	O
SSD6D	B-Method
’	I-Method
,	O
for	O
6D	B-Task
object	I-Task
detection	I-Task
that	O
uses	O
a	O
moderate	O
DR	B-Method
strategy	O
to	O
utilize	O
synthetic	O
training	O
data	O
.	O
	
The	O
authors	O
render	O
views	O
of	O
textured	B-Method
3D	I-Method
object	I-Method
reconstructions	I-Method
at	O
random	O
poses	O
on	O
top	O
of	O
MS	O
COCO	O
background	O
images	O
while	O
varying	O
brightness	O
and	O
contrast	O
.	O
	
This	O
lets	O
the	O
network	O
generalize	O
to	O
real	O
images	O
and	O
enables	O
6D	B-Task
detection	I-Task
at	O
10Hz	O
.	O
	
Like	O
us	O
,	O
for	O
very	O
accurate	O
distance	O
estimation	B-Task
they	O
rely	O
on	O
ICP	B-Method
post	O
-	O
processing	O
using	O
depth	O
data	O
.	O
	
In	O
contrast	O
,	O
we	O
do	O
not	O
treat	O
3D	B-Task
orientation	I-Task
estimation	I-Task
as	O
a	O
classification	B-Task
task	I-Task
.	O
	
subsection	O
:	O
Learning	B-Task
representations	I-Task
of	I-Task
3D	I-Task
orientations	I-Task
	
We	O
describe	O
the	O
difficulties	O
of	O
training	O
with	O
fixed	O
SO	B-Method
(	I-Method
3	I-Method
)	I-Method
parameterizations	I-Method
which	O
will	O
motivate	O
the	O
learning	B-Task
of	I-Task
object	I-Task
-	I-Task
specific	I-Task
representations	I-Task
.	O
	
subsubsection	O
:	O
Regression	B-Method
.	O
	
Since	O
rotations	O
live	O
in	O
a	O
continuous	O
space	O
,	O
it	O
seems	O
natural	O
to	O
directly	O
regress	O
a	O
fixed	O
SO	O
(	O
3	O
)	O
parameterizations	O
like	O
quaternions	O
.	O
	
However	O
,	O
representational	O
constraints	O
and	O
pose	O
ambiguities	O
can	O
introduce	O
convergence	O
issues	O
.	O
	
In	O
practice	O
,	O
direct	B-Method
regression	I-Method
approaches	I-Method
for	O
full	O
3D	O
object	O
orientation	O
estimation	B-Task
have	O
not	O
been	O
very	O
successful	O
.	O
	
subsubsection	O
:	O
Classification	B-Task
	
of	O
3D	O
object	O
orientations	O
requires	O
a	O
discretization	B-Method
of	I-Method
SO	I-Method
(	I-Method
3	I-Method
)	O
.	O
	
Even	O
rather	O
coarse	O
intervals	O
of	O
lead	O
to	O
over	O
50.000	O
possible	O
classes	O
.	O
	
Since	O
each	O
class	O
appears	O
only	O
sparsely	O
in	O
the	O
training	O
data	O
,	O
this	O
hinders	O
convergence	O
.	O
	
In	O
SSD6D	B-Method
the	O
3D	O
orientation	O
is	O
learned	O
by	O
separately	O
classifying	O
a	O
discretized	O
viewpoint	O
and	O
in	O
-	O
plane	O
rotation	O
,	O
thus	O
reducing	O
the	O
complexity	B-Metric
to	O
.	O
	
However	O
,	O
for	O
non	O
-	O
canonical	O
views	O
,	O
e.g.	O
if	O
an	O
object	O
is	O
seen	O
from	O
above	O
,	O
a	O
change	O
of	O
viewpoint	O
can	O
be	O
nearly	O
equivalent	O
to	O
a	O
change	O
of	O
in	O
-	O
plane	O
rotation	O
which	O
yields	O
ambiguous	O
class	O
combinations	O
.	O
	
In	O
general	O
,	O
the	O
relation	O
between	O
different	O
orientations	O
is	O
ignored	O
when	O
performing	O
one	B-Task
-	I-Task
hot	I-Task
classification	I-Task
.	O
	
subsubsection	O
:	O
Symmetries	O
	
are	O
a	O
severe	O
issue	O
when	O
relying	O
on	O
fixed	O
representations	O
of	O
3D	O
orientations	O
since	O
they	O
cause	O
pose	O
ambiguities	O
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
If	O
not	O
manually	O
addressed	O
,	O
identical	O
training	O
images	O
can	O
have	O
different	O
orientation	O
labels	O
assigned	O
which	O
can	O
significantly	O
disturb	O
the	O
learning	B-Task
process	I-Task
.	O
	
In	O
order	O
to	O
cope	O
with	O
ambiguous	O
objects	O
,	O
most	O
approaches	O
in	O
literature	O
are	O
manually	O
adapted	O
.	O
	
The	O
strategies	O
reach	O
from	O
ignoring	O
one	O
axis	O
of	O
rotation	O
over	O
adapting	O
the	O
discretization	O
according	O
to	O
the	O
object	O
to	O
the	O
training	O
of	O
an	O
extra	O
CNN	B-Method
to	O
predict	O
symmetries	O
.	O
	
These	O
depict	O
tedious	O
,	O
manual	O
ways	O
to	O
filter	O
out	O
object	O
symmetries	O
(	O
[	O
reference	O
]	O
)	O
in	O
advance	O
,	O
but	O
treating	O
ambiguities	O
due	O
to	O
self	O
-	O
occlusions	O
(	O
[	O
reference	O
]	O
)	O
and	O
occlusions	O
(	O
[	O
reference	O
]	O
)	O
are	O
harder	O
to	O
address	O
.	O
	
Symmetries	B-Method
do	O
not	O
only	O
affect	O
regression	B-Method
and	I-Method
classification	I-Method
methods	I-Method
,	O
but	O
any	O
learning	B-Method
-	I-Method
based	I-Method
algorithm	I-Method
that	O
discriminates	O
object	O
views	O
solely	O
by	O
fixed	O
SO	B-Method
(	I-Method
3	I-Method
)	I-Method
representations	I-Method
.	O
	
[	O
Object	O
symmetries	O
]	O
	
width=0.23	O
,	O
justification	O
=	O
raggedright	O
[	O
Self	O
-	O
occlusion	O
induced	O
symmetries	O
]	O
	
width=0.205justification	O
=	O
raggedright	O
[	O
Occlusion	O
induced	O
symmetries	O
]	O
width=0.9	O
	
subsubsection	O
:	O
Descriptor	B-Method
Learning	I-Method
	
can	O
be	O
used	O
to	O
learn	O
a	O
representation	O
that	O
relates	O
object	O
views	O
in	O
a	O
low	O
-	O
dimensional	O
space	O
.	O
	
Wohlhart	O
et	O
al	O
.	O
introduced	O
a	O
CNN	B-Method
-	I-Method
based	I-Method
descriptor	I-Method
learning	I-Method
approach	I-Method
using	O
a	O
triplet	B-Method
loss	I-Method
that	O
minimizes	O
/	O
maximizes	O
the	O
Euclidean	O
distance	O
between	O
similar	O
/	O
dissimilar	O
object	O
orientations	O
.	O
	
Although	O
mixing	O
in	O
synthetic	O
data	O
,	O
the	O
training	O
also	O
relies	O
on	O
pose	O
-	O
annotated	O
sensor	O
data	O
.	O
	
Furthermore	O
,	O
the	O
approach	O
is	O
not	O
immune	O
against	O
symmetries	O
because	O
the	O
loss	O
can	O
be	O
dominated	O
by	O
ambiguous	O
object	O
views	O
that	O
appear	O
the	O
same	O
but	O
have	O
opposite	O
orientations	O
.	O
	
Baltnas	O
et	O
al	O
.	O
extended	O
this	O
work	O
by	O
enforcing	O
proportionality	O
between	O
descriptor	O
and	O
pose	O
distances	O
.	O
	
They	O
acknowledge	O
the	O
problem	O
of	O
object	O
symmetries	O
by	O
weighting	O
the	O
pose	O
distance	O
loss	O
with	O
the	O
depth	O
difference	O
of	O
the	O
object	O
at	O
the	O
considered	O
poses	O
.	O
	
This	O
heuristic	O
increases	O
the	O
accuracy	B-Metric
on	O
symmetric	O
objects	O
with	O
respect	O
to	O
.	O
	
Our	O
work	O
is	O
also	O
based	O
on	O
learning	B-Task
descriptors	I-Task
,	O
but	O
we	O
train	O
self	B-Method
-	I-Method
supervised	I-Method
Augmented	I-Method
Autoencoders	I-Method
(	O
AAEs	B-Method
)	O
such	O
that	O
the	O
learning	B-Method
process	I-Method
itself	O
is	O
independent	O
of	O
any	O
fixed	O
SO	B-Method
(	I-Method
3	I-Method
)	I-Method
representation	I-Method
.	O
	
This	O
means	O
that	O
descriptors	O
are	O
learned	O
solely	O
based	O
on	O
the	O
appearance	O
of	O
object	O
views	O
and	O
thus	O
symmetrical	O
ambiguities	O
are	O
inherently	O
regarded	O
.	O
	
Assigning	O
3D	O
orientations	O
to	O
the	O
descriptors	O
only	O
happens	O
after	O
the	O
training	O
.	O
	
Furthermore	O
,	O
unlike	O
we	O
can	O
abstain	O
from	O
the	O
use	O
of	O
real	O
labeled	O
data	O
for	O
training	O
.	O
	
Kehl	O
et	O
al	O
.	O
train	O
an	O
Autoencoder	B-Method
architecture	O
on	O
random	O
RGB	O
-	O
D	O
scene	O
	
patches	O
from	O
the	O
LineMOD	O
dataset	O
.	O
	
At	O
test	O
time	O
,	O
descriptors	O
from	O
scene	O
and	O
object	O
patches	O
are	O
compared	O
to	O
find	O
the	O
6D	B-Task
pose	I-Task
.	O
	
Since	O
the	O
approach	O
requires	O
the	O
evaluation	O
of	O
a	O
lot	O
of	O
patches	O
,	O
it	O
takes	O
about	O
670ms	O
per	O
prediction	O
.	O
	
Furthermore	O
,	O
using	O
local	O
patches	O
means	O
to	O
ignore	O
holistic	O
relations	O
between	O
object	O
features	O
which	O
is	O
crucial	O
if	O
few	O
texture	O
exists	O
.	O
	
Instead	O
we	O
train	O
on	O
holistic	O
object	O
views	O
and	O
explicitly	O
learn	O
domain	O
invariance	O
.	O
	
section	O
:	O
Method	O
	
In	O
the	O
following	O
,	O
we	O
mainly	O
focus	O
on	O
the	O
novel	O
3D	B-Task
orientation	I-Task
estimation	I-Task
technique	O
based	O
on	O
the	O
Augmented	B-Method
Autoencoder	I-Method
(	O
AAE	B-Method
)	O
.	O
	
subsection	O
:	O
Autoencoders	B-Method
	
The	O
original	O
AE	B-Method
,	O
introduced	O
by	O
Hinton	O
et	O
al	O
.	O
,	O
is	O
a	O
dimensionality	B-Method
reduction	I-Method
technique	I-Method
for	O
high	O
dimensional	O
data	O
such	O
as	O
images	O
,	O
audio	O
or	O
depth	O
.	O
	
It	O
consists	O
of	O
an	O
Encoder	B-Method
and	O
a	O
Decoder	B-Method
,	O
both	O
arbitrary	O
learnable	B-Method
function	I-Method
approximators	I-Method
which	O
are	O
usually	O
neural	B-Method
networks	I-Method
.	O
	
The	O
training	O
objective	O
is	O
to	O
reconstruct	O
the	O
input	O
after	O
passing	O
through	O
a	O
low	B-Method
-	I-Method
dimensional	I-Method
bottleneck	I-Method
,	O
referred	O
to	O
as	O
the	O
latent	B-Method
representation	I-Method
with	O
:	O
The	O
per	B-Metric
-	I-Metric
sample	I-Metric
loss	I-Metric
is	O
simply	O
a	O
sum	O
over	O
the	O
pixel	O
-	O
wise	O
L2	O
distance	O
The	O
resulting	O
latent	O
space	O
can	O
,	O
for	O
example	O
,	O
be	O
used	O
for	O
unsupervised	B-Task
clustering	I-Task
.	O
	
Denoising	B-Method
Autoencoders	I-Method
have	O
a	O
modified	O
training	B-Method
procedure	I-Method
.	O
	
Here	O
,	O
artificial	O
random	O
noise	O
is	O
applied	O
to	O
the	O
input	O
images	O
while	O
the	O
reconstruction	O
target	O
stays	O
clean	O
.	O
	
The	O
trained	O
model	O
can	O
be	O
used	O
to	O
reconstruct	O
denoised	O
test	O
images	O
.	O
	
But	O
how	O
is	O
the	O
latent	B-Method
representation	I-Method
affected	O
?	O
	
Hypothesis	O
1	O
:	O
	
The	O
Denoising	O
AE	B-Method
produces	O
latent	B-Method
representations	I-Method
which	O
are	O
invariant	O
to	O
noise	O
because	O
it	O
facilitates	O
the	O
reconstruction	B-Task
of	I-Task
de	I-Task
-	I-Task
noised	I-Task
images	I-Task
.	O
	
We	O
will	O
demonstrate	O
that	O
this	O
training	B-Method
strategy	I-Method
actually	O
enforces	O
invariance	O
not	O
only	O
against	O
noise	O
but	O
against	O
a	O
variety	O
of	O
different	O
input	O
augmentations	O
.	O
	
Finally	O
,	O
it	O
allows	O
us	O
to	O
bridge	O
the	O
domain	O
gap	O
between	O
simulated	O
and	O
real	O
data	O
.	O
	
subsection	O
:	O
Augmented	B-Method
Autoencoder	I-Method
	
justification	O
=	O
centering	O
,	O
font	O
=	O
scriptsize	O
,	O
aboveskip=0.15	O
cm	O
,	O
belowskip=0.25	O
cm	O
	
(	O
a	O
)	O
X	O
=	O
s1.0	O
,	O
=t⁢xy0.0	O
,	O
∈r	O
[	O
0	O
,	O
⁢2π	O
]	O
	
(	O
b	O
)	O
X	O
=	O
s0.6	O
,	O
=t⁢xy0.0	O
,	O
∈r	O
[	O
0	O
,	O
⁢2π	O
]	O
	
(	O
c	O
)	O
X	O
=	O
s1.0	O
,	O
∼t⁢xy⁢U	O
(-	O
1	O
,	O
1	O
),	O
∈r	O
[	O
0	O
,	O
⁢2π	O
]	O
	
(	O
d	O
)	O
X∼s⁢U	O
(	O
0.5	O
,	O
1	O
),	O
∼t⁢xy⁢U	O
(-	O
1	O
,	O
1	O
),	O
∈r	O
[	O
0	O
,	O
⁢2π	O
]	O
justification	O
=	O
centering	O
,	O
aboveskip=0.03	O
cm	O
,	O
	
belowskip=0.12	O
cm	O
	
z1	O
z2	O
	
(	O
1	O
)	O
Autoencoder	B-Method
⟶	O
(	O
a	O
)(	O
a	O
)	O
	
z1	O
z2	O
	
(	O
2	O
)	O
Autoencoder	B-Method
⟶	O
(	O
d	O
)(	O
d	O
)	O
	
rotation	O
angle	O
[	O
deg	O
]	O
	
z1	O
rotation	O
angle	O
[	O
deg	O
]	O
	
z2	O
(	O
3	O
)	O
Augmented	B-Method
Autoencoder	I-Method
⟶	O
(	O
d	O
)(	O
a	O
)	O
	
The	O
motivation	O
behind	O
the	O
AAE	B-Method
is	O
to	O
control	O
what	O
the	O
latent	B-Method
representation	I-Method
encodes	O
and	O
which	O
properties	O
are	O
ignored	O
.	O
	
We	O
apply	O
random	B-Method
augmentations	I-Method
to	O
the	O
input	O
images	O
against	O
which	O
the	O
encoding	O
shall	O
become	O
invariant	O
.	O
	
The	O
reconstruction	O
target	O
remains	O
eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
but	O
eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
becomes	O
To	O
make	O
evident	O
that	O
Hypothesis	O
1	O
holds	O
for	O
geometric	O
transformations	O
,	O
we	O
learn	O
latent	B-Method
representations	I-Method
of	O
binary	O
images	O
depicting	O
a	O
2D	O
square	O
at	O
different	O
scales	O
,	O
in	O
-	O
plane	O
translations	O
and	O
rotations	O
.	O
	
Our	O
goal	O
is	O
to	O
encode	O
only	O
the	O
in	O
-	O
plane	O
rotations	O
in	O
a	O
two	O
dimensional	O
latent	O
space	O
independent	O
of	O
scale	O
or	O
translation	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
depicts	O
the	O
results	O
after	O
training	O
a	O
CNN	O
-	O
based	O
AE	B-Method
architecture	O
similar	O
to	O
the	O
model	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
It	O
can	O
be	O
observed	O
that	O
the	O
AE	B-Method
trained	O
on	O
reconstructing	O
squares	O
at	O
fixed	O
scale	O
and	O
translation	O
(	O
1	O
)	O
or	O
random	O
scale	O
and	O
translation	O
(	O
2	O
)	O
do	O
not	O
clearly	O
encode	O
rotation	O
alone	O
,	O
but	O
are	O
also	O
sensitive	O
to	O
other	O
latent	O
factors	O
.	O
	
Instead	O
,	O
the	O
encoding	O
of	O
the	O
AAE	B-Method
(	O
3	O
)	O
becomes	O
invariant	O
to	O
translation	O
and	O
scale	O
such	O
that	O
all	O
squares	O
with	O
coinciding	O
orientation	O
are	O
mapped	O
to	O
the	O
same	O
code	O
.	O
	
Furthermore	O
,	O
the	O
latent	B-Method
representation	I-Method
is	O
much	O
smoother	O
and	O
the	O
latent	O
dimensions	O
imitate	O
a	O
shifted	O
sine	O
and	O
cosine	O
function	O
with	O
frequency	O
respectively	O
.	O
	
The	O
reason	O
is	O
that	O
the	O
square	O
has	O
two	O
perpendicular	O
axes	O
of	O
symmetry	O
,	O
i.e.	O
after	O
rotating	O
the	O
square	O
appears	O
the	O
same	O
.	O
	
This	O
property	O
of	O
representing	O
the	O
orientation	O
based	O
on	O
the	O
appearance	O
of	O
an	O
object	O
rather	O
than	O
on	O
a	O
fixed	O
parametrization	O
is	O
valuable	O
to	O
avoid	O
ambiguities	O
due	O
to	O
symmetries	O
when	O
teaching	O
3D	O
object	O
orientations	O
.	O
	
subsection	O
:	O
Learning	B-Task
3D	I-Task
Orientation	I-Task
from	O
Synthetic	O
Object	O
Views	O
	
Our	O
toy	O
problem	O
showed	O
that	O
we	O
can	O
explicitly	O
learn	O
representations	B-Task
of	I-Task
object	I-Task
in	I-Task
-	I-Task
plane	I-Task
rotations	I-Task
using	O
a	O
geometric	B-Method
augmentation	I-Method
technique	I-Method
.	O
	
Applying	O
the	O
same	O
geometric	B-Method
input	I-Method
augmentations	I-Method
we	O
can	O
encode	O
the	O
whole	O
SO	O
(	O
3	O
)	O
space	O
of	O
views	O
from	O
a	O
3D	B-Method
object	I-Method
model	I-Method
(	O
CAD	B-Method
or	O
3D	B-Task
reconstruction	I-Task
)	O
while	O
being	O
robust	O
against	O
inaccurate	O
object	O
detections	O
.	O
	
However	O
,	O
the	O
encoder	B-Method
would	O
still	O
be	O
unable	O
to	O
relate	O
image	O
crops	O
from	O
real	O
RGB	O
sensors	O
because	O
(	O
1	O
)	O
the	O
3D	B-Method
model	I-Method
and	O
the	O
real	O
object	O
differ	O
,	O
(	O
2	O
)	O
simulated	O
and	O
real	O
lighting	O
conditions	O
differ	O
,	O
(	O
3	O
)	O
the	O
network	O
ca	O
n’t	O
distinguish	O
the	O
object	O
from	O
background	O
clutter	O
and	O
foreground	O
occlusions	O
.	O
	
Instead	O
of	O
trying	O
to	O
imitate	O
every	O
detail	O
of	O
specific	O
real	O
sensor	O
recordings	O
in	O
simulation	O
we	O
propose	O
a	O
Domain	O
Randomization	O
(	O
DR	B-Method
)	O
technique	O
within	O
the	O
AAE	B-Method
framework	I-Method
to	O
make	O
the	O
encodings	O
invariant	O
to	O
insignificant	O
environment	O
and	O
sensor	O
variations	O
.	O
	
The	O
goal	O
is	O
that	O
the	O
trained	O
encoder	B-Method
treats	O
the	O
differences	O
to	O
real	O
camera	O
images	O
as	O
just	O
another	O
irrelevant	O
variation	O
.	O
	
Therefore	O
,	O
while	O
keeping	O
reconstruction	O
targets	O
clean	O
,	O
we	O
randomly	O
apply	O
additional	O
augmentations	B-Method
to	O
the	O
input	O
training	O
views	O
:	O
(	O
1	O
)	O
rendering	B-Method
with	O
random	O
light	O
positions	O
and	O
randomized	O
diffuse	O
and	O
specular	O
reflection	O
(	O
simple	O
Phong	B-Method
model	I-Method
in	O
OpenGL	B-Method
)	O
,	O
(	O
2	O
)	O
inserting	O
random	O
background	O
images	O
from	O
the	O
Pascal	O
VOC	O
dataset	O
,	O
(	O
3	O
)	O
varying	O
image	O
contrast	O
,	O
brightness	O
,	O
Gaussian	O
blur	O
and	O
color	O
distortions	O
,	O
(	O
4	O
)	O
applying	O
occlusions	O
using	O
random	O
object	O
masks	O
or	O
black	O
squares	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
depicts	O
an	O
exemplary	O
training	B-Method
process	I-Method
for	O
synthetic	B-Task
views	I-Task
of	I-Task
object	I-Task
5	I-Task
from	O
T	B-Material
-	I-Material
LESS	I-Material
.	O
	
width=0.9	O
	
subsection	O
:	O
Network	B-Method
Architecture	I-Method
and	O
Training	O
Details	O
	
The	O
convolutional	O
Autoencoder	B-Method
architecture	O
that	O
is	O
used	O
in	O
our	O
experiments	O
is	O
depicted	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
We	O
use	O
a	O
bootstrapped	B-Method
pixel	I-Method
-	I-Method
wise	I-Method
L2	I-Method
loss	I-Method
which	O
is	O
only	O
computed	O
on	O
the	O
pixels	O
with	O
the	O
largest	O
errors	O
(	O
per	O
image	O
bootstrap	O
factor	O
b=4	O
)	O
.	O
	
Thereby	O
,	O
finer	O
details	O
are	O
reconstructed	O
and	O
the	O
training	B-Method
does	O
not	O
converge	O
to	O
local	O
minima	O
.	O
	
Using	O
OpenGL	B-Method
,	O
we	O
render	O
20000	O
views	O
of	O
each	O
object	O
uniformly	O
at	O
random	O
3D	O
orientations	O
and	O
constant	O
distance	O
along	O
the	O
camera	O
axis	O
(	O
700	O
mm	O
)	O
.	O
	
The	O
resulting	O
images	O
are	O
quadratically	O
cropped	O
and	O
resized	O
to	O
as	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
All	O
geometric	O
and	O
color	O
input	O
augmentations	O
besides	O
the	O
rendering	O
with	O
random	O
lighting	O
are	O
applied	O
online	O
during	O
training	O
at	O
uniform	O
random	O
strength	O
,	O
parameters	O
are	O
found	O
in	O
the	O
supplement	O
.	O
	
We	O
use	O
the	O
Adam	B-Method
optimizer	I-Method
with	O
a	O
learning	B-Metric
rate	I-Metric
of	O
,	O
Xavier	B-Method
initialization	I-Method
,	O
a	O
batch	O
size	O
=	O
64	O
and	O
30000	O
iterations	O
which	O
takes	O
hours	O
on	O
a	O
single	O
Nvidia	O
Geforce	O
GTX	O
1080	O
.	O
	
width=	O
	
subsection	O
:	O
Codebook	B-Task
Creation	I-Task
and	O
Test	O
Procedure	O
	
After	O
training	O
,	O
the	O
AAE	B-Method
is	O
able	O
to	O
extract	O
a	O
3D	O
object	O
from	O
real	O
scene	O
crops	O
of	O
many	O
different	O
camera	O
sensors	O
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
The	O
clarity	O
and	O
orientation	O
of	O
the	O
decoder	B-Method
reconstruction	I-Method
is	O
an	O
indicator	O
of	O
the	O
encoding	B-Metric
quality	I-Metric
.	O
	
To	O
determine	O
3D	O
object	O
orientations	O
from	O
test	O
scene	O
crops	O
we	O
create	O
a	O
codebook	O
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
top	O
)	O
)	O
:	O
	
Render	O
clean	O
,	O
synthetic	O
object	O
views	O
at	O
equidistant	O
viewpoints	O
from	O
a	O
full	O
view	O
-	O
sphere	O
(	O
based	O
on	O
a	O
refined	O
icosahedron	O
)	O
	
Rotate	O
each	O
view	O
in	O
-	O
plane	O
at	O
fixed	O
intervals	O
to	O
cover	O
the	O
whole	O
SO	O
(	O
3	O
)	O
	
Create	O
a	O
codebook	B-Method
by	O
generating	O
latent	B-Method
codes	I-Method
for	O
all	O
resulting	O
images	O
and	O
assigning	O
their	O
corresponding	O
rotation	O
At	O
test	O
time	O
,	O
the	O
considered	O
object	O
(	O
s	O
)	O
are	O
first	O
detected	O
in	O
an	O
RGB	O
scene	O
.	O
	
The	O
area	O
is	O
quadratically	O
cropped	O
and	O
resized	O
to	O
match	O
the	O
encoder	B-Method
input	O
size	O
.	O
	
After	O
encoding	O
we	O
compute	O
the	O
cosine	O
similarity	O
between	O
the	O
test	O
code	O
and	O
all	O
codes	O
from	O
the	O
codebook	O
:	O
The	O
highest	O
similarities	O
are	O
determined	O
in	O
a	O
kNN	B-Method
search	I-Method
and	O
the	O
corresponding	O
rotation	O
matrices	O
from	O
the	O
codebook	O
are	O
returned	O
as	O
estimates	O
of	O
the	O
3D	O
object	O
orientation	O
.	O
	
We	O
use	O
cosine	O
similarity	O
because	O
(	O
1	O
)	O
it	O
can	O
be	O
very	O
efficiently	O
computed	O
on	O
a	O
single	O
GPU	O
even	O
for	O
large	O
codebooks	O
.	O
	
In	O
our	O
experiments	O
we	O
have	O
2562	O
equidistant	O
viewpoints	O
36	O
in	O
-	O
plane	O
rotation	O
=	O
	
92232	O
total	O
entries	O
.	O
	
(	O
2	O
)	O
	
We	O
observed	O
that	O
,	O
presumably	O
due	O
to	O
the	O
circular	O
nature	O
of	O
rotations	O
,	O
scaling	O
a	O
latent	B-Method
test	I-Method
code	I-Method
does	O
not	O
change	O
the	O
object	O
orientation	O
of	O
the	O
decoder	B-Method
reconstruction	I-Method
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
width=0.93	O
	
width=0.99	O
width=0.95	O
	
subsection	O
:	O
Extending	O
to	O
6D	B-Task
Object	I-Task
Detection	I-Task
	
subsubsection	O
:	O
Training	O
the	O
Object	B-Method
Detector	I-Method
.	O
	
We	O
finetune	O
SSD	B-Method
with	O
VGG16	B-Method
base	I-Method
using	O
object	O
recordings	O
on	O
black	O
background	O
from	O
different	O
viewpoints	O
which	O
are	O
provided	O
in	O
the	O
training	O
datasets	O
of	O
LineMOD	O
and	O
T	B-Material
-	I-Material
LESS	I-Material
.	O
	
We	O
also	O
train	O
RetinaNet	B-Method
with	O
ResNet50	B-Method
backbone	I-Method
which	O
is	O
slower	O
but	O
more	O
accurate	O
.	O
	
Multiple	O
objects	O
are	O
copied	O
in	O
a	O
scene	O
at	O
random	O
orientation	O
,	O
scale	O
and	O
translation	O
.	O
	
Bounding	O
box	O
annotations	O
are	O
adapted	O
accordingly	O
.	O
	
As	O
for	O
the	O
AAE	B-Method
,	O
the	O
black	O
background	O
is	O
replaced	O
with	O
Pascal	O
VOC	O
images	O
.	O
	
During	O
training	O
with	O
60000	O
scenes	O
,	O
we	O
apply	O
various	O
color	B-Method
and	I-Method
geometric	I-Method
augmentations	I-Method
.	O
	
subsubsection	O
:	O
Projective	B-Method
Distance	I-Method
Estimation	I-Method
.	O
	
We	O
estimate	O
the	O
full	O
3D	O
translation	O
from	O
camera	O
to	O
object	O
center	O
,	O
similar	O
to	O
.	O
	
Therefore	O
,	O
for	O
each	O
synthetic	O
object	O
view	O
in	O
the	O
codebook	O
,	O
we	O
save	O
the	O
diagonal	O
length	O
of	O
its	O
2D	O
bounding	O
box	O
.	O
	
At	O
test	O
time	O
,	O
we	O
compute	O
the	O
ratio	O
between	O
the	O
detected	O
bounding	O
box	O
diagonal	O
and	O
the	O
corresponding	O
codebook	O
diagonal	O
,	O
i.e.	O
at	O
similar	O
orientation	O
.	O
	
The	O
pinhole	B-Method
camera	I-Method
model	I-Method
yields	O
the	O
distance	B-Method
estimate	I-Method
with	O
synthetic	O
rendering	O
distance	O
and	O
focal	O
lengths	O
,	O
of	O
the	O
test	O
sensor	O
and	O
synthetic	O
views	O
.	O
	
It	O
follows	O
that	O
with	O
principal	O
points	O
and	O
bounding	O
box	O
centers	O
.	O
	
In	O
contrast	O
to	O
,	O
we	O
can	O
predict	O
the	O
3D	O
translation	O
for	O
different	O
test	O
intrinsics	O
.	O
	
subsubsection	O
:	O
ICP	B-Method
Refinement	O
.	O
	
Optionally	O
,	O
the	O
estimate	O
is	O
refined	O
on	O
depth	O
data	O
using	O
a	O
standard	O
ICP	B-Method
approach	O
taking	O
on	O
CPU	B-Method
.	O
	
Details	O
in	O
supplement	O
.	O
	
subsubsection	O
:	O
Inference	O
Time	O
.	O
	
SSD	B-Method
with	O
VGG16	O
base	O
and	O
31	O
classes	O
plus	O
the	O
AAE	B-Method
	
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
with	O
a	O
codebook	O
size	O
of	O
yield	O
the	O
average	B-Metric
inference	I-Metric
times	I-Metric
depicted	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
We	O
conclude	O
that	O
the	O
RGB	B-Method
-	I-Method
based	I-Method
pipeline	I-Method
is	O
real	O
-	O
time	O
capable	O
at	O
42Hz	O
on	O
a	O
Nvidia	O
GTX	O
1080	O
.	O
	
This	O
enables	O
augmented	B-Task
reality	I-Task
and	O
robotic	B-Task
applications	I-Task
and	O
leaves	O
room	O
for	O
tracking	B-Method
algorithms	I-Method
.	O
	
Multiple	O
encoders	B-Method
and	O
corresponding	O
codebooks	O
fit	O
into	O
the	O
GPU	O
memory	O
,	O
making	O
multi	B-Task
-	I-Task
object	I-Task
pose	I-Task
estimation	I-Task
feasible	O
.	O
	
width=0.8	O
width=	O
	
section	O
:	O
Evaluation	O
	
We	O
evaluate	O
the	O
AAE	B-Method
and	O
the	O
whole	O
6D	B-Method
detection	I-Method
pipeline	I-Method
on	O
the	O
T	B-Material
-	I-Material
LESS	I-Material
and	O
LineMOD	O
datasets	O
.	O
	
Example	O
sequences	O
are	O
found	O
in	O
the	O
supplement	O
.	O
	
subsection	O
:	O
Test	O
Conditions	O
	
Few	O
RGB	O
-	O
based	O
pose	O
estimation	B-Task
approaches	O
(	O
e.g.	O
)	O
only	O
rely	O
on	O
3D	O
model	O
information	O
.	O
	
Most	O
methods	O
make	O
use	O
of	O
real	O
pose	O
annotated	O
data	O
and	O
often	O
even	O
train	O
and	O
test	O
on	O
the	O
same	O
scenes	O
(	O
e.g.	O
at	O
slightly	O
different	O
viewpoints	O
)	O
.	O
	
It	O
is	O
common	O
practice	O
to	O
ignore	O
in	O
-	O
plane	O
rotations	O
or	O
only	O
consider	O
object	O
poses	O
that	O
appear	O
in	O
the	O
dataset	O
which	O
also	O
limits	O
applicability	O
.	O
	
Symmetric	O
object	O
views	O
are	O
often	O
individually	O
treated	O
or	O
ignored	O
.	O
	
The	O
SIXD	B-Task
challenge	I-Task
is	O
an	O
attempt	O
to	O
make	O
fair	O
comparisons	O
between	O
6D	B-Method
localization	I-Method
algorithms	I-Method
by	O
prohibiting	O
the	O
use	O
of	O
test	O
scene	O
pixels	O
.	O
	
We	O
follow	O
these	O
strict	O
evaluation	O
guidelines	O
,	O
but	O
treat	O
the	O
harder	O
problem	O
of	O
6D	B-Task
detection	I-Task
where	O
it	O
is	O
unknown	O
which	O
of	O
the	O
considered	O
objects	O
are	O
present	O
in	O
the	O
scene	O
.	O
	
This	O
is	O
especially	O
difficult	O
in	O
the	O
T	B-Material
-	I-Material
LESS	I-Material
dataset	I-Material
since	O
objects	O
are	O
very	O
similar	O
.	O
	
justification	O
=	O
centering	O
,	O
	
width=	O
max	O
width=	O
Train	O
RGBTest	B-Method
RGBdyn	I-Method
.	O
	
lightaddcontrastmultiplyinvertAUC	O
ReconstructionPrimesense	O
✳	O
0.472	O
(	O
±	O
0.013	O
)	O
✳	O
✳	O
0.611	O
(	O
±	O
0.030	O
)	O
✳	O
✳	O
✳	O
0.825	O
(	O
±	O
0.015	O
)	O
✳	O
✳	O
✳	O
✳	O
0.876	O
(	O
±	O
0.019	O
)	O
✳	O
✳	O
✳	O
✳	O
✳	O
0.877	O
(	O
±	O
0.005	O
)	O
✳	O
✳	O
✳	O
0.861	O
(	O
±	O
0.014	O
)	O
PrimesensePrimesense	O
✳	O
✳	O
✳	O
0.890	O
(	O
±	O
0.003	O
)	O
3D	O
ReconstructionKinect	O
✳	O
0.461	O
(	O
±	O
0.022	O
)	O
✳	O
✳	O
0.580	O
(	O
±	O
0.014	O
)	O
✳	O
✳	O
✳	O
0.701	O
(	O
±	O
0.046	O
)	O
✳	O
✳	O
✳	O
✳	O
0.855	O
(	O
±	O
0.016	O
)	O
✳	O
✳	O
✳	O
✳	O
✳	O
0.897	O
(	O
±	O
0.008	O
)	O
✳	O
✳	O
✳	O
0.903	O
(	O
±	O
0.016	O
)	O
KinectKinect	O
✳	O
✳	O
✳	O
0.917	O
(	O
±	O
0.007	O
)	O
	
[	O
Effect	O
of	O
latent	O
space	O
size	O
,	O
standard	O
deviation	O
in	O
red	O
]	O
	
[	O
Training	O
on	O
CAD	B-Method
model	I-Method
(	O
bottom	O
)	O
vs.	O
textured	B-Task
3D	I-Task
reconstruction	I-Task
(	O
top	O
)	O
]	O
	
subsection	O
:	O
Metrics	B-Metric
	
The	O
VSD	B-Method
is	O
an	O
ambiguity	O
-	O
invariant	O
pose	O
error	O
function	O
that	O
is	O
determined	O
by	O
the	O
distance	O
between	O
the	O
estimated	O
and	O
ground	O
truth	O
visible	O
object	O
depth	O
surfaces	O
.	O
	
As	O
in	O
the	O
SIXD	B-Task
challenge	I-Task
,	O
we	O
report	O
the	O
recall	O
of	O
correct	O
6D	B-Task
object	I-Task
poses	I-Task
at	O
with	O
tolerance	O
and	O
object	O
visibility	O
.	O
	
Although	O
the	O
Average	O
Distance	O
of	O
Model	O
Points	O
(	O
ADD	O
)	O
)	O
	
metric	O
ca	O
n’t	O
handle	O
pose	O
ambiguities	O
,	O
we	O
also	O
present	O
it	O
for	O
the	O
LineMOD	O
dataset	O
following	O
the	O
protocol	O
in	O
.	O
	
For	O
objects	O
with	O
symmetric	O
views	O
(	O
eggbox	O
,	O
glue	O
)	O
,	O
computes	O
the	O
average	O
distance	O
to	O
the	O
closest	O
model	O
point	O
.	O
	
In	O
our	O
ablation	B-Task
studies	I-Task
we	O
also	O
report	O
the	O
,	O
which	O
represents	O
the	O
area	O
under	O
the	O
’	O
vs.	O
recall	O
’	O
curve	O
:	O
justification	O
=	O
centering	O
max	O
width=	O
6D	O
Detection	O
-	O
SSD6D	B-Method
Detection	I-Method
-	O
Retina6D	O
Localizationw	O
/	O
GT	O
2D	O
BBsObjectOURSOURSOURSOURSKehl	O
	
[	O
]	O
Vidal	O
[	O
]	O
OURSOURSRGB	O
+	O
Depth	O
(	O
ICP	B-Method
)	O
RGB	O
+	O
Depth	O
(	O
ICP	B-Method
)	O
RGB	O
-	O
D	O
+	O
ICPDepth	B-Method
	
+	O
ICPRGB	O
+	O
Depth	O
(	O
ICP	B-Method
)	O
15.6515.798.8722.32	O
	
-	O
4312.3328.0525.4622.1413.2229.49	O
-	O
4711.2337.3037.0532.6512.4738.26	O
-	O
6913.1146.1544.6118.586.5623.07	O
-	O
	
6312.7135.30536.4569.3934.8076.10	O
-	O
6966.7090.29623.1561.3220.2467.64	O
-	O
6752.3088.28715.9768.4516.2173.88	O
-	O
7736.5881.75810.8643.1819.7467.02	O
-	O
7922.0582.65919.5967.1236.2178.24	O
-	O
9046.4984.381010.4758.6111.5577.65	O
-	O
6814.3183.12114.3532.526.3135.89	O
-	O
6915.0157.26127.8040.538.1549.30	O
	
-	O
8231.3473.75133.3029.314.9142.50	O
-	O
5613.6065.01142.8526.124.6130.53	O
-	O
4745.3276.05157.9052.3426.7183.73	O
-	O
5250.0090.561613.0661.6421.7367.42	O
-	O
8136.0970.571741.7077.4664.8486.17	O
-	O
8381.1190.491847.1781.0814.3084.34	O
-	O
8052.6287.471915.9545.4822.4650.54	O
-	O
5550.7582.50202.177.605.2714.75	O
-	O
4737.7553.842119.7738.9817.9340.31	O
-	O
6350.8972.102211.0125.4218.6335.23	O
-	O
	
7047.6061.74237.9830.2418.6342.52	O
-	O
8535.1854.65244.7449.484.2359.54	O
	
-	O
	
7011.2481.342521.9150.0018.7670.89	O
-	O
4837.1288.542610.0457.8512.6266.20	O
-	O
5528.3390.66277.4247.2221.1373.51	O
-	O
6021.8677.632821.7844.8023.0761.20	O
-	O
6942.5867.102915.3353.7126.6573.05	O
-	O
6557.0187.683034.6386.3429.5892.90	O
-	O
8470.4296.45Mean14.6746.5118.3557.1435.966.336.7972.76	O
	
subsection	O
:	O
Ablation	B-Task
Studies	I-Task
	
To	O
assess	O
the	O
AAE	B-Method
alone	O
,	O
in	O
this	O
subsection	O
we	O
only	O
predict	O
the	O
3D	O
orientation	O
of	O
Object	O
5	O
from	O
the	O
T	B-Material
-	I-Material
LESS	I-Material
dataset	I-Material
on	O
Primesense	O
and	O
Kinect	O
RGB	O
scene	O
crops	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
influence	O
of	O
different	O
input	O
augmentations	O
.	O
	
It	O
can	O
be	O
seen	O
that	O
the	O
effect	O
of	O
different	O
color	B-Method
augmentations	I-Method
is	O
cumulative	O
.	O
	
For	O
textureless	O
objects	O
,	O
even	O
the	O
inversion	O
of	O
color	O
channels	O
seems	O
to	O
be	O
beneficial	O
since	O
it	O
prevents	O
overfitting	O
to	O
synthetic	O
color	O
information	O
.	O
	
Furthermore	O
,	O
training	O
with	O
real	O
object	O
recordings	O
provided	O
in	O
T	B-Material
-	I-Material
LESS	I-Material
with	O
random	O
Pascal	O
VOC	O
background	O
and	O
augmentations	B-Method
yields	O
only	O
slightly	O
better	O
performance	O
than	O
the	O
training	O
with	O
synthetic	O
data	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
depicts	O
the	O
effect	O
of	O
different	O
latent	O
space	O
sizes	O
on	O
the	O
3D	O
pose	O
estimation	B-Task
accuracy	I-Metric
.	O
	
Performance	O
starts	O
to	O
saturate	O
at	O
.	O
	
In	O
Fig	O
.	O
	
[	O
reference	O
]	O
we	O
demonstrate	O
that	O
our	O
Domain	B-Method
Randomization	I-Method
strategy	I-Method
even	O
allows	O
the	O
generalization	B-Task
from	O
untextured	B-Method
CAD	I-Method
models	I-Method
.	O
	
subsection	O
:	O
6D	B-Task
Object	I-Task
Detection	I-Task
	
First	O
,	O
we	O
report	O
RGB	O
-	O
only	O
results	O
consisting	O
of	O
2D	B-Task
detection	I-Task
,	O
3D	B-Task
orientation	I-Task
estimation	I-Task
and	O
projective	O
distance	O
estimation	B-Task
.	O
	
Although	O
these	O
results	O
are	O
visually	O
appealing	O
,	O
the	O
distance	O
estimation	B-Task
is	O
refined	O
using	O
a	O
simple	O
cloud	O
-	O
based	O
ICP	B-Method
to	O
compete	O
with	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
depth	B-Method
-	I-Method
based	I-Method
methods	I-Method
.	O
	
Table	O
[	O
reference	O
]	O
presents	O
our	O
6D	B-Task
detection	I-Task
evaluation	I-Task
on	O
all	O
scenes	O
of	O
the	O
T	B-Material
-	I-Material
LESS	I-Material
dataset	I-Material
,	O
which	O
contains	O
a	O
lot	O
of	O
pose	O
ambiguities	O
.	O
	
Our	O
refined	O
results	O
outperform	O
the	O
recent	O
local	B-Method
patch	I-Method
descriptor	I-Method
approach	I-Method
from	O
Kehl	O
et	O
al	O
.	O
	
even	O
though	O
they	O
only	O
do	O
6D	B-Task
localization	I-Task
.	O
	
The	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
(	O
in	O
terms	O
of	O
average	O
accuracy	B-Metric
in	O
the	O
SIXD	O
challenge	O
)	O
from	O
Vidal	O
et	O
al	O
.	O
performs	O
a	O
time	O
consuming	O
search	O
through	O
pose	O
hypotheses	O
(	O
average	O
of	O
4.9	O
seconds	O
/	O
object	O
)	O
.	O
	
Our	O
approach	O
yields	O
comparable	O
accuracy	B-Metric
while	O
being	O
much	O
more	O
efficient	O
.	O
	
The	O
right	O
part	O
of	O
Table	O
[	O
reference	O
]	O
shows	O
results	O
with	O
ground	O
truth	O
bounding	O
boxes	O
yielding	O
an	O
upper	O
limit	O
on	O
the	O
pose	O
estimation	B-Task
performance	O
.	O
	
The	O
appendix	O
shows	O
some	O
failure	O
cases	O
,	O
mostly	O
stemming	O
from	O
missed	O
detections	O
or	O
strong	O
occlusions	O
.	O
	
In	O
Table	O
[	O
reference	O
]	O
we	O
compare	O
our	O
method	O
against	O
the	O
recently	O
introduced	O
SSD6D	B-Method
and	O
other	O
methods	O
on	O
the	O
LineMOD	O
dataset	O
.	O
	
SSD6D	B-Method
also	O
trains	O
on	O
synthetic	B-Task
views	I-Task
of	I-Task
3D	I-Task
models	I-Task
,	O
but	O
their	O
performance	O
seems	O
quite	O
dependent	O
on	O
a	O
sophisticated	O
occlusion	O
-	O
aware	O
,	O
projective	O
ICP	B-Method
refinement	O
step	O
.	O
	
Our	O
basic	O
ICP	B-Method
sometimes	O
converges	O
to	O
similarly	O
shaped	O
objects	O
in	O
the	O
vicinity	O
.	O
	
In	O
the	O
RGB	O
domain	O
our	O
method	O
outperforms	O
SSD6D.	O
justification	O
=	O
centering	O
,	O
width=0.8	O
max	O
width=	O
	
Test	O
dataRGB	O
+	O
Depth	O
	
(	O
ICP	B-Method
)	O
Train	O
dataRGB	O
w	O
/	O
o	O
Real	O
Pose	O
LabelsRGB	O
with	O
Real	O
Pose	O
Labels	O
+	O
DepthObjectSSD6D	O
[]	O
OURSBrachmann	O
[]	O
BB8	O
	
[	O
]	O
Tekin	O
[	O
]	O
OURSSSD6D	O
[]	O
Ape0.003.96	O
-	O
27.921.6220.5565Benchvise0.1820.92	O
-	O
62.081.8064.2580Cam0.4130.47	O
-	O
40.136.5763.2078Can1.3535.87	O
-	O
48.168.8076.0986Cat0.5117.90	O
	
-	O
45.241.8272.0170Driller2.5823.99	O
-	O
58.663.5141.5873Duck0.004.86	O
-	O
	
32.827.2332.3866Eggbox8.9081.01	O
-	O
40.069.5898.64100Glue0.0045.49	O
-	O
27.080.0296.39100Holepuncher0.3017.60	O
-	O
42.442.6349.8849Iron8.8632.03	O
-	O
67.074.9763.1178Lamp8.260.47	O
-	O
39.971.1191.6973Phone0.1833.79	O
-	O
35.247.7470.9679Mean2.4228.6532.343.655.9564.6779	O
	
section	O
:	O
Conclusion	O
	
We	O
have	O
proposed	O
a	O
new	O
self	B-Method
-	I-Method
supervised	I-Method
training	I-Method
strategy	I-Method
for	O
Autoencoder	B-Method
architectures	I-Method
that	O
enables	O
robust	O
3D	O
object	O
orientation	O
estimation	B-Task
on	O
various	O
RGB	O
sensors	O
while	O
training	O
only	O
on	O
synthetic	O
views	O
of	O
a	O
3D	B-Method
model	I-Method
.	O
	
By	O
demanding	O
the	O
Autoencoder	B-Method
to	O
revert	O
geometric	O
and	O
color	O
input	O
augmentations	O
,	O
we	O
learn	O
representations	O
that	O
(	O
1	O
)	O
specifically	O
encode	O
3D	O
object	O
orientations	O
,	O
(	O
2	O
)	O
are	O
invariant	O
to	O
a	O
significant	O
domain	O
gap	O
between	O
synthetic	O
and	O
real	O
RGB	O
images	O
,	O
(	O
3	O
)	O
inherently	O
regard	O
pose	O
ambiguities	O
from	O
symmetric	O
object	O
views	O
.	O
	
Around	O
this	O
approach	O
,	O
we	O
created	O
a	O
real	O
-	O
time	O
(	O
42	O
fps	O
)	O
,	O
RGB	B-Method
-	I-Method
based	I-Method
pipeline	I-Method
for	O
6D	B-Task
object	I-Task
detection	I-Task
which	O
is	O
especially	O
suitable	O
when	O
pose	O
-	O
annotated	O
RGB	O
sensor	O
data	O
is	O
not	O
available	O
.	O
	
section	O
:	O
Acknowledgement	O
	
We	O
would	O
like	O
to	O
thank	O
Dr.	O
Ingo	O
Kossyk	O
,	O
Dimitri	O
Henkel	O
and	O
Max	O
Denninger	O
for	O
helpful	O
discussions	O
.	O
	
We	O
also	O
thank	O
the	O
reviewers	O
for	O
their	O
useful	O
comments	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Quality	B-Method
Aware	I-Method
Network	I-Method
for	O
Set	B-Task
to	I-Task
Set	I-Task
Recognition	I-Task
	
This	O
paper	O
targets	O
on	O
the	O
problem	O
of	O
set	B-Task
to	I-Task
set	I-Task
recognition	I-Task
,	O
which	O
learns	O
the	O
metric	O
between	O
two	O
image	O
sets	O
.	O
	
Images	O
in	O
each	O
set	O
belong	O
to	O
the	O
same	O
identity	O
.	O
	
Since	O
images	O
in	O
a	O
set	O
can	O
be	O
complementary	O
,	O
they	O
hopefully	O
lead	O
to	O
higher	O
accuracy	B-Metric
in	O
practical	O
applications	O
.	O
	
However	O
,	O
the	O
quality	O
of	O
each	O
sample	O
can	O
not	O
be	O
guaranteed	O
,	O
and	O
samples	O
with	O
poor	O
quality	O
will	O
hurt	O
the	O
metric	O
.	O
	
In	O
this	O
paper	O
,	O
the	O
quality	B-Method
aware	I-Method
network	I-Method
(	O
QAN	B-Method
)	O
is	O
proposed	O
to	O
confront	O
this	O
problem	O
,	O
where	O
the	O
quality	O
of	O
each	O
sample	O
can	O
be	O
automatically	O
learned	O
although	O
such	O
information	O
is	O
not	O
explicitly	O
provided	O
in	O
the	O
training	O
stage	O
.	O
	
The	O
network	O
has	O
two	O
branches	O
,	O
where	O
the	O
first	O
branch	O
extracts	O
appearance	O
feature	O
embedding	O
for	O
each	O
sample	O
and	O
the	O
other	O
branch	O
predicts	O
quality	B-Metric
score	I-Metric
for	O
each	O
sample	O
.	O
	
Features	O
and	O
quality	O
scores	O
of	O
all	O
samples	O
in	O
a	O
set	O
are	O
then	O
aggregated	O
to	O
generate	O
the	O
final	O
feature	B-Method
embedding	I-Method
.	O
	
We	O
show	O
that	O
the	O
two	O
branches	O
can	O
be	O
trained	O
in	O
an	O
end	O
-	O
to	O
-	O
end	O
manner	O
given	O
only	O
the	O
set	O
-	O
level	O
identity	O
annotation	O
.	O
	
Analysis	O
on	O
gradient	O
spread	O
of	O
this	O
mechanism	O
indicates	O
that	O
the	O
quality	O
learned	O
by	O
the	O
network	O
is	O
beneficial	O
to	O
set	B-Task
-	I-Task
to	I-Task
-	I-Task
set	I-Task
recognition	I-Task
and	O
simplifies	O
the	O
distribution	O
that	O
the	O
network	O
needs	O
to	O
fit	O
.	O
	
Experiments	O
on	O
both	O
face	B-Task
verification	I-Task
and	O
person	B-Task
re	I-Task
-	I-Task
identification	I-Task
show	O
advantages	O
of	O
the	O
proposed	O
QAN	B-Method
.	O
	
The	O
source	O
code	O
and	O
network	O
structure	O
can	O
be	O
downloaded	O
at	O
GitHub	O
algorithmProcedure	O
	
section	O
:	O
Introduction	O
	
Face	B-Task
verification	I-Task
and	O
person	B-Task
re	I-Task
-	I-Task
identification	I-Task
have	O
been	O
well	O
studied	O
and	O
widely	O
used	O
in	O
computer	B-Task
vision	I-Task
applications	I-Task
such	O
as	O
financial	B-Task
identity	I-Task
authentication	I-Task
and	O
video	B-Task
surveillance	I-Task
.	O
	
Both	O
the	O
two	O
tasks	O
need	O
to	O
measure	O
the	O
distance	O
between	O
two	O
face	O
or	O
person	O
images	O
.	O
	
Such	O
tasks	O
can	O
be	O
naturally	O
formalized	O
as	O
a	O
metric	B-Task
learning	I-Task
problem	I-Task
,	O
where	O
the	O
distance	O
of	O
images	O
from	O
the	O
same	O
identity	O
should	O
be	O
smaller	O
than	O
that	O
from	O
different	O
identities	O
.	O
	
Built	O
on	O
large	O
scale	O
training	O
data	O
,	O
convolutional	B-Method
neural	I-Method
networks	I-Method
and	O
carefully	O
designed	O
optimization	B-Method
criterion	I-Method
,	O
current	O
methods	O
can	O
achieve	O
promising	O
performance	O
on	O
standard	O
benchmarks	O
,	O
but	O
may	O
still	O
fail	O
due	O
to	O
appearance	O
variations	O
caused	O
by	O
large	O
pose	O
or	O
illumination	O
.	O
	
In	O
practical	O
applications	O
,	O
instead	O
of	O
one	O
single	O
image	O
,	O
a	O
set	O
of	O
images	O
for	O
each	O
identity	O
can	O
always	O
be	O
collected	O
.	O
	
For	O
example	O
,	O
the	O
image	O
set	O
of	O
one	O
identity	O
can	O
be	O
sampled	O
from	O
the	O
trajectory	O
of	O
the	O
face	O
or	O
person	O
in	O
videos	O
.	O
	
Images	O
in	O
a	O
set	O
can	O
be	O
complementary	O
to	O
each	O
other	O
,	O
so	O
that	O
they	O
provide	O
more	O
information	O
than	O
a	O
single	O
image	O
,	O
such	O
as	O
images	O
from	O
different	O
poses	O
.	O
	
The	O
direct	O
way	O
to	O
aggregate	O
identity	O
information	O
from	O
all	O
images	O
in	O
a	O
set	O
can	O
be	O
simply	O
max	B-Method
/	I-Method
average	I-Method
pooling	I-Method
appearance	I-Method
features	I-Method
of	O
all	O
images	O
.	O
	
However	O
,	O
one	O
problem	O
in	O
this	O
pooling	O
is	O
that	O
some	O
images	O
in	O
the	O
set	O
may	O
be	O
not	O
suitable	O
for	O
recognition	B-Task
.	O
	
As	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
both	O
sets	O
from	O
left	O
-	O
top	O
and	O
left	O
-	O
bottom	O
hold	O
noisy	O
images	O
caused	O
by	O
shake	O
or	O
blur	O
.	O
	
If	O
the	O
noisy	O
images	O
are	O
treated	O
equally	O
and	O
max	B-Method
/	I-Method
average	I-Method
pooling	I-Method
is	O
used	O
to	O
aggregate	O
all	O
images	O
’	O
features	O
,	O
the	O
noisy	O
images	O
will	O
mislead	O
the	O
final	O
representation	O
.	O
	
In	O
this	O
paper	O
,	O
in	O
order	O
to	O
be	O
robust	O
to	O
images	O
with	O
poor	O
quality	O
as	O
described	O
above	O
and	O
simultaneously	O
use	O
the	O
rich	O
information	O
provided	O
by	O
the	O
other	O
images	O
,	O
our	O
basic	O
idea	O
is	O
that	O
each	O
image	O
can	O
have	O
a	O
quality	B-Metric
score	I-Metric
in	O
aggregation	B-Task
.	O
	
For	O
that	O
,	O
we	O
propose	O
a	O
quality	B-Method
aware	I-Method
network	I-Method
(	O
QAN	B-Method
)	O
,	O
which	O
has	O
two	O
branches	O
and	O
then	O
aggregated	O
together	O
.	O
	
The	O
first	O
branch	O
named	O
feature	B-Method
generation	I-Method
part	I-Method
extracts	O
the	O
feature	B-Method
embedding	I-Method
for	O
each	O
image	O
,	O
and	O
the	O
other	O
branch	O
named	O
quality	B-Method
generation	I-Method
part	I-Method
predicts	O
quality	B-Metric
score	I-Metric
for	O
each	O
image	O
.	O
	
Features	O
of	O
images	O
in	O
the	O
whole	O
set	O
are	O
then	O
aggregated	O
by	O
the	O
final	O
set	O
pooling	B-Method
unit	I-Method
according	O
to	O
their	O
quality	O
.	O
	
A	O
good	O
property	O
of	O
our	O
approach	O
is	O
that	O
we	O
do	O
not	O
supervise	O
the	O
model	O
by	O
any	O
explicit	O
annotations	O
of	O
the	O
quality	B-Metric
.	O
	
The	O
network	O
can	O
automatically	O
assign	O
low	O
quality	O
scores	O
to	O
images	O
with	O
poor	O
quality	O
in	O
order	O
to	O
keep	O
the	O
final	O
feature	O
embedding	O
useful	O
in	O
set	B-Task
-	I-Task
to	I-Task
-	I-Task
set	I-Task
recognition	I-Task
.	O
	
To	O
implement	O
that	O
,	O
an	O
elaborate	O
model	O
is	O
designed	O
in	O
which	O
embedding	O
branch	O
and	O
score	O
generation	O
branch	O
can	O
be	O
jointly	O
trained	O
through	O
optimization	O
of	O
the	O
final	O
embedding	O
.	O
	
Specially	O
in	O
this	O
paper	O
,	O
we	O
use	O
the	O
joint	O
triplet	O
and	O
softmax	O
loss	O
on	O
top	O
of	O
image	O
sets	O
.	O
	
The	O
designed	O
gradient	B-Method
of	I-Method
image	I-Method
set	I-Method
pooling	I-Method
unit	I-Method
ensures	O
the	O
correctness	O
of	O
this	O
automatic	B-Method
process	I-Method
.	O
	
Experiments	O
indicate	O
that	O
the	O
predicted	B-Metric
quality	I-Metric
score	I-Metric
is	O
correlated	O
with	O
the	O
quality	O
annotated	O
by	O
human	O
,	O
and	O
the	O
predicted	B-Metric
quality	I-Metric
score	I-Metric
performs	O
better	O
than	O
human	O
in	O
recognition	B-Task
.	O
	
In	O
this	O
paper	O
,	O
we	O
show	O
the	O
applications	O
of	O
the	O
proposed	O
method	O
on	O
both	O
person	B-Task
re	I-Task
-	I-Task
identification	I-Task
and	O
face	B-Task
verification	I-Task
.	O
	
For	O
person	B-Task
re	I-Task
-	I-Task
identification	I-Task
task	I-Task
,	O
the	O
proposed	O
quality	B-Method
aware	I-Method
network	I-Method
improves	O
top	B-Metric
-	I-Metric
1	I-Metric
matching	I-Metric
rates	I-Metric
over	O
the	O
baseline	O
by	O
14.6	O
%	O
on	O
iLIDS	O
-	O
VID	O
and	O
9.0	O
%	O
on	O
PRID2011	O
.	O
	
For	O
face	B-Task
verification	I-Task
,	O
the	O
proposed	O
method	O
reduces	O
15.6	O
%	O
and	O
29.32	O
%	O
miss	B-Metric
ratio	I-Metric
when	O
the	O
false	B-Metric
positive	I-Metric
rate	I-Metric
is	O
0.001	O
on	O
YouTube	B-Material
Face	I-Material
and	O
IJB	O
-	O
A	O
benchmarks	O
.	O
	
The	O
main	O
contributions	O
of	O
the	O
paper	O
are	O
summarized	O
as	O
follows	O
.	O
	
The	O
proposed	O
quality	B-Method
aware	I-Method
network	I-Method
automatically	O
generates	O
quality	B-Metric
scores	I-Metric
for	O
each	O
image	O
in	O
a	O
set	O
and	O
leads	O
to	O
better	O
representation	O
for	O
set	B-Task
-	I-Task
to	I-Task
-	I-Task
set	I-Task
recognition	I-Task
.	O
	
We	O
design	O
an	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
training	I-Method
strategy	I-Method
and	O
demonstrate	O
that	O
the	O
quality	B-Method
generation	I-Method
part	I-Method
and	O
feature	B-Method
generation	I-Method
part	I-Method
benefit	O
from	O
each	O
other	O
during	O
back	B-Method
propagation	I-Method
.	O
	
Quality	B-Metric
learnt	O
by	O
QAN	B-Method
is	O
better	O
than	O
quality	B-Metric
estimated	O
by	O
human	O
and	O
we	O
achieves	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
four	O
benchmarks	O
for	O
person	B-Task
re	I-Task
-	I-Task
identification	I-Task
and	O
face	B-Task
verification	I-Task
.	O
	
section	O
:	O
Related	O
work	O
	
Our	O
work	O
is	O
build	O
upon	O
recent	O
advances	O
in	O
deep	B-Task
learning	I-Task
based	O
person	B-Task
re	I-Task
-	I-Task
identification	I-Task
and	O
unconstrained	B-Task
face	I-Task
recognition	I-Task
.	O
	
In	O
person	B-Task
re	I-Task
-	I-Task
identification	I-Task
,	O
use	O
features	O
generated	O
by	O
deep	B-Method
convolutional	I-Method
network	I-Method
and	O
obtain	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
.	O
	
To	O
learn	O
face	B-Task
representations	I-Task
in	O
unconstrained	B-Task
face	I-Task
recognition	I-Task
,	O
Huang	O
et	O
al	O
.	O
uses	O
convolutional	B-Method
Restricted	I-Method
Boltzmann	I-Method
Machine	I-Method
while	O
deep	B-Method
convolutional	I-Method
neural	I-Method
network	I-Method
is	O
used	O
in	O
.	O
	
Furthermore	O
,	O
use	O
deeper	B-Method
convolutional	I-Method
network	I-Method
and	O
achieved	O
accuracy	B-Metric
that	O
even	O
surpasses	O
human	O
performance	O
.	O
	
The	O
accuracy	B-Metric
achieved	O
by	O
deep	B-Method
learning	I-Method
on	O
image	O
-	O
based	O
face	B-Task
verification	I-Task
benchmark	O
LFW	O
has	O
been	O
promoted	O
to	O
99.78	O
%	O
.	O
	
Although	O
deep	B-Method
neural	I-Method
network	I-Method
has	O
achieved	O
such	O
great	O
performance	O
on	O
these	O
two	O
problems	O
,	O
in	O
present	O
world	O
,	O
unconstrained	B-Task
set	I-Task
-	I-Task
to	I-Task
-	I-Task
set	I-Task
recognition	I-Task
is	O
more	O
challenging	O
and	O
useful	O
.	O
	
Looking	O
backward	O
,	O
there	O
are	O
two	O
different	O
approaches	O
handling	O
set	B-Task
-	I-Task
to	I-Task
-	I-Task
set	I-Task
recognition	I-Task
.	O
	
The	O
first	O
approach	O
takes	O
image	O
set	O
as	O
a	O
convex	O
hull	O
,	O
affine	O
hull	O
or	O
subspace	O
.	O
	
Under	O
these	O
settings	O
,	O
samples	O
in	O
a	O
set	O
distribute	O
in	O
a	O
Hilbert	O
space	O
or	O
Grassmann	O
mainfold	O
so	O
that	O
this	O
issue	O
can	O
be	O
formulated	O
as	O
a	O
metric	B-Task
learning	I-Task
problem	I-Task
.	O
	
Some	O
other	O
works	O
degrade	O
set	B-Task
-	I-Task
to	I-Task
-	I-Task
set	I-Task
recognition	I-Task
to	O
point	B-Task
-	I-Task
to	I-Task
-	I-Task
point	I-Task
recognition	I-Task
through	O
aggregating	O
images	O
in	O
a	O
set	O
to	O
a	O
single	O
representation	O
in	O
hyperspace	O
.	O
	
The	O
most	O
famous	O
approach	O
in	O
this	O
kind	O
is	O
the	O
Bag	O
of	O
features	O
,	O
which	O
uses	O
histogram	B-Method
to	O
represent	O
the	O
whole	O
set	O
for	O
feature	B-Task
aggregation	I-Task
.	O
	
Another	O
classical	O
work	O
is	O
vector	B-Method
of	I-Method
locally	I-Method
aggregated	I-Method
descriptors	I-Method
(	I-Method
VLAD	I-Method
)	I-Method
,	O
which	O
aggregates	O
all	O
local	O
descriptors	O
from	O
all	O
samples	O
.	O
	
Temporal	B-Method
max	I-Method
/	I-Method
average	I-Method
pooling	I-Method
is	O
used	O
in	O
to	O
integrate	O
all	O
frames	O
’	O
features	O
generated	O
by	O
recurrent	B-Method
convolutional	I-Method
network	I-Method
.	O
	
This	O
method	O
uses	O
the	O
1st	O
order	O
statistics	O
to	O
aggregate	O
the	O
set	O
.	O
	
The	O
2nd	O
order	O
statistics	O
is	O
used	O
in	O
in	O
assuming	O
that	O
samples	O
follow	O
Gaussian	O
distribution	O
.	O
	
In	O
,	O
original	O
faces	O
in	O
a	O
set	O
are	O
classified	O
into	O
20	O
bins	O
based	O
on	O
their	O
pose	O
and	O
quality	O
.	O
	
Then	O
faces	O
in	O
each	O
bin	O
are	O
pooled	O
to	O
generate	O
features	O
and	O
finally	O
feature	O
vectors	O
in	O
all	O
bins	O
are	O
merged	O
to	O
be	O
the	O
final	O
representation	O
.	O
	
uses	O
attention	B-Method
mechanism	I-Method
to	O
summarize	O
several	O
sample	O
points	O
to	O
a	O
single	O
aggregated	O
point	O
.	O
	
The	O
proposed	O
QAN	B-Method
belongs	O
to	O
the	O
second	O
approach	O
.	O
	
It	O
discards	O
the	O
dross	O
and	O
selects	O
the	O
essential	O
information	O
in	O
all	O
images	O
.	O
	
Different	O
from	O
recent	O
works	O
which	O
learn	O
aggregation	B-Method
based	O
on	O
fixed	O
feature	O
or	O
image	O
,	O
the	O
QAN	B-Method
learns	O
feature	B-Method
representation	I-Method
and	O
aggregation	B-Task
simultaneously	O
.	O
	
proposed	O
a	O
similar	B-Method
quality	I-Method
aware	I-Method
module	I-Method
named	O
“	O
memorability	B-Method
based	I-Method
frame	I-Method
selection	I-Method
”	O
which	O
takes	O
“	O
visual	O
entropy	O
”	O
to	O
be	O
the	O
score	O
of	O
a	O
frame	O
.	O
	
But	O
the	O
score	O
of	O
a	O
frame	O
is	O
defined	O
by	O
human	O
and	O
independent	O
with	O
feature	B-Method
generation	I-Method
unit	I-Method
.	O
	
In	O
QAN	B-Method
,	O
score	O
is	O
automatically	O
learned	O
and	O
quality	B-Method
generation	I-Method
unit	I-Method
is	O
joint	O
trained	O
with	O
feature	B-Method
generation	I-Method
unit	I-Method
.	O
	
Due	O
to	O
mutual	O
benefit	O
between	O
the	O
two	O
parts	O
during	O
training	O
,	O
performance	O
is	O
improved	O
significantly	O
by	O
jointly	O
optimizing	O
images	O
aggregation	O
parameter	O
and	O
images	B-Method
’	I-Method
feature	I-Method
generator	I-Method
.	O
	
section	O
:	O
Quality	B-Method
aware	I-Method
network	I-Method
(	O
QAN	B-Method
)	O
	
In	O
our	O
work	O
we	O
focus	O
on	O
improving	O
image	B-Method
set	I-Method
embedding	I-Method
model	I-Method
,	O
which	O
maps	O
an	O
image	O
set	O
to	O
an	O
representation	O
with	O
fixed	O
dimension	O
so	O
that	O
image	O
sets	O
with	O
different	O
number	O
of	O
images	O
are	O
comparable	O
with	O
each	O
other	O
.	O
	
Let	O
and	O
denote	O
representation	O
of	O
and	O
.	O
is	O
determined	O
by	O
all	O
elements	O
in	O
,	O
therefore	O
it	O
can	O
be	O
denoted	O
as	O
The	O
is	O
produced	O
by	O
a	O
feature	B-Method
extraction	I-Method
process	I-Method
,	O
containing	O
traditional	O
hand	B-Method
-	I-Method
craft	I-Method
feature	I-Method
extractors	I-Method
or	O
convolutional	B-Method
neural	I-Method
network	I-Method
.	O
	
is	O
an	O
aggregative	B-Method
function	I-Method
,	O
which	O
maps	O
a	O
variable	O
-	O
length	O
input	O
set	O
to	O
a	O
representation	O
of	O
fixed	O
dimension	O
.	O
	
The	O
challenge	O
is	O
to	O
find	O
an	O
optimized	O
,	O
which	O
aggregate	O
features	O
from	O
the	O
whole	O
image	O
set	O
to	O
obtain	O
the	O
most	O
discriminative	B-Method
representation	I-Method
.	O
	
Based	O
on	O
notion	O
that	O
images	O
with	O
higher	O
quality	O
are	O
easier	O
for	O
recognition	B-Task
while	O
images	O
with	O
lower	O
quality	O
containing	O
occlusion	O
and	O
large	O
pose	O
have	O
less	O
effect	O
on	O
set	B-Task
representation	I-Task
,	O
we	O
denote	O
as	O
where	O
predicts	O
a	O
quality	B-Metric
score	I-Metric
for	O
image	O
.	O
	
So	O
the	O
representation	O
of	O
a	O
set	O
is	O
a	O
fusion	O
of	O
each	O
images	O
’	O
features	O
,	O
weighted	O
by	O
their	O
quality	O
scores	O
.	O
	
subsection	O
:	O
QAN	B-Method
for	O
image	B-Task
set	I-Task
embedding	I-Task
	
In	O
this	O
paper	O
,	O
feature	B-Method
generation	I-Method
and	O
aggregation	B-Method
module	I-Method
is	O
implemented	O
through	O
an	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
convolutional	I-Method
neural	I-Method
network	I-Method
named	O
QAN	B-Method
as	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Two	O
branches	O
are	O
splited	O
from	O
the	O
middle	O
of	O
it	O
.	O
	
In	O
the	O
first	O
branch	O
,	O
quality	B-Method
generation	I-Method
part	I-Method
followed	O
by	O
a	O
set	B-Method
pooling	I-Method
unit	I-Method
composes	O
the	O
aggregation	B-Method
module	I-Method
.	O
	
And	O
in	O
the	O
second	O
branch	O
,	O
feature	B-Method
generation	I-Method
part	I-Method
generates	O
images	B-Task
’	I-Task
representation	I-Task
.	O
	
Now	O
we	O
introduce	O
how	O
an	O
image	O
set	O
flows	O
through	O
QAN	B-Method
.	O
	
At	O
the	O
beginning	O
of	O
the	O
process	O
,	O
all	O
images	O
are	O
sent	O
into	O
a	O
fully	B-Method
convolutional	I-Method
network	I-Method
to	O
generate	O
middle	B-Method
representations	I-Method
.	O
	
After	O
that	O
,	O
QAN	B-Method
is	O
divided	O
into	O
two	O
branches	O
.	O
	
The	O
first	O
one	O
(	O
upper	O
)	O
named	O
quality	B-Method
generation	I-Method
part	I-Method
is	O
a	O
tiny	B-Method
convolution	I-Method
neural	I-Method
network	I-Method
(	O
see	O
Sec	O
.	O
	
[	O
reference	O
]	O
for	O
details	O
)	O
which	O
is	O
employed	O
to	O
predict	O
quality	B-Metric
score	I-Metric
.	O
	
The	O
second	O
one	O
(	O
lower	O
)	O
,	O
called	O
feature	B-Method
generation	I-Method
part	I-Method
,	O
generates	O
image	B-Method
representations	I-Method
for	O
all	O
images	O
.	O
	
and	O
are	O
aggregated	O
at	O
set	O
pooling	B-Method
unit	I-Method
,	O
and	O
then	O
pass	O
through	O
a	O
fully	B-Method
connected	I-Method
layer	I-Method
to	O
get	O
the	O
final	O
representation	O
.	O
	
To	O
sum	O
up	O
,	O
this	O
structure	O
generates	O
quality	O
scores	O
for	O
images	O
,	O
uses	O
these	O
quality	O
scores	O
to	O
weight	O
images	O
’	O
representations	O
and	O
sums	O
them	O
up	O
to	O
produce	O
the	O
final	O
set	O
’s	O
representation	O
.	O
	
subsection	O
:	O
Training	O
QAN	B-Method
without	O
quality	B-Method
supervision	I-Method
	
We	O
train	O
the	O
QAN	B-Method
in	O
an	O
end	O
-	O
to	O
-	O
end	O
manner	O
.	O
	
The	O
data	O
flow	O
is	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
QAN	B-Method
is	O
supposed	O
to	O
generate	O
discriminative	B-Method
representations	I-Method
for	O
images	O
and	O
sets	O
belonging	O
to	O
different	O
identities	O
.	O
	
For	O
image	B-Task
level	I-Task
training	I-Task
,	O
a	O
fully	B-Method
connection	I-Method
layer	I-Method
is	O
established	O
after	O
feature	B-Method
generation	I-Method
part	I-Method
,	O
which	O
is	O
supervised	O
by	O
Softmax	O
loss	O
.	O
	
For	O
set	B-Task
level	I-Task
training	I-Task
,	O
a	O
set	O
’s	O
representation	O
is	O
supervised	O
by	O
which	O
is	O
formulated	O
as	O
:	O
The	O
loss	O
function	O
above	O
is	O
referred	O
as	O
Triplet	O
Loss	O
in	O
previous	O
works	O
.	O
	
We	O
define	O
as	O
anchor	O
set	O
,	O
as	O
positive	O
set	O
,	O
and	O
as	O
negative	O
set	O
.	O
	
This	O
function	O
minimizes	O
variances	O
of	O
intra	O
-	O
class	O
samples	O
while	O
Softmax	O
loss	O
can	O
not	O
guarantee	O
that	O
because	O
softmax	O
-	O
loss	O
directly	O
optimizes	O
the	O
probability	O
of	O
each	O
class	O
,	O
but	O
not	O
the	O
discrimination	B-Method
of	I-Method
representation	I-Method
.	O
	
Keeping	O
this	O
in	O
mind	O
,	O
we	O
consider	O
the	O
set	B-Method
pooling	I-Method
operation	I-Method
.	O
	
The	O
gradients	O
back	O
propagated	O
through	O
set	B-Method
pooling	I-Method
unit	I-Method
can	O
be	O
formulated	O
as	O
follows	O
,	O
So	O
we	O
can	O
formulate	O
propagation	B-Method
process	I-Method
of	O
the	O
final	O
loss	B-Metric
as	O
Where	O
is	O
the	O
dimension	O
of	O
images	O
’	O
representation	O
.	O
	
We	O
discuss	O
how	O
a	O
quality	B-Metric
score	I-Metric
is	O
automatically	O
learned	O
by	O
this	O
back	B-Method
propagation	I-Method
process	I-Method
.	O
	
subsection	O
:	O
Mechanism	O
for	O
learning	B-Metric
quality	I-Metric
score	I-Metric
	
Automatic	O
gradient	O
of	O
μ	O
.	O
	
After	O
back	B-Method
-	I-Method
propagation	I-Method
through	O
set	B-Method
pooling	I-Method
unit	I-Method
,	O
gradient	O
of	O
with	O
regard	O
to	O
can	O
be	O
calculated	O
according	O
to	O
the	O
Eq	O
.	O
	
[	O
reference	O
]	O
,	O
which	O
is	O
the	O
dot	O
product	O
of	O
gradient	O
from	O
and	O
.	O
	
So	O
if	O
angle	O
of	O
and	O
belongs	O
to	O
(	O
,	O
)	O
,	O
’s	O
gradient	O
will	O
be	O
positive	O
.	O
	
For	O
example	O
,	O
as	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
the	O
angle	O
of	O
and	O
is	O
less	O
than	O
,	O
so	O
the	O
quality	B-Metric
score	I-Metric
will	O
become	O
larger	O
after	O
this	O
back	B-Method
propagation	I-Method
process	I-Method
.	O
	
In	O
contrast	O
,	O
the	O
relative	O
direction	O
of	O
is	O
in	O
the	O
opposite	O
side	O
of	O
the	O
gradient	O
of	O
,	O
making	O
it	O
obviously	O
a	O
hard	O
sample	O
,	O
so	O
its	O
quality	B-Metric
score	I-Metric
will	O
tend	O
to	O
be	O
smaller	O
.	O
	
Obviously	O
,	O
samples	O
in	O
the	O
“	O
correct	O
”	O
directions	O
along	O
with	O
set	O
gradient	O
always	O
score	O
higher	O
in	O
quality	O
,	O
while	O
those	O
in	O
the	O
“	O
wrong	O
”	O
directions	O
gain	O
lower	O
weight	O
.	O
	
For	O
example	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
green	O
samples	O
in	O
the	O
upper	O
area	O
and	O
red	O
samples	O
in	O
the	O
lower	O
area	O
keep	O
improving	O
their	O
quality	O
consistently	O
while	O
in	O
the	O
middle	O
area	O
,	O
sample	O
’s	O
quality	O
reduces	O
.	O
	
To	O
this	O
end	O
,	O
represents	O
whether	O
image	O
is	O
a	O
good	O
sample	O
or	O
a	O
hard	O
sample	O
.	O
	
This	O
conclusion	O
will	O
be	O
further	O
demonstrated	O
by	O
experiments	O
.	O
	
regulates	O
the	O
attention	O
of	O
RIi	O
.	O
	
The	O
gradient	O
of	O
is	O
shown	O
in	O
Eq	O
.	O
	
[	O
reference	O
]	O
with	O
a	O
factor	O
,	O
together	O
with	O
the	O
gradient	O
propagated	O
from	O
Softmax	O
loss	O
.	O
	
Since	O
most	O
of	O
hard	O
samples	O
with	O
lower	O
are	O
always	O
poor	O
images	O
or	O
even	O
full	O
of	O
background	O
noises	O
,	O
the	O
factor	O
in	O
gradient	O
of	O
weaken	O
their	O
harmful	O
effect	O
on	O
the	O
whole	O
model	O
.	O
	
That	O
is	O
,	O
their	O
impact	O
on	O
parameters	O
in	O
feature	B-Task
generation	I-Task
part	I-Task
is	O
negligible	O
during	O
back	B-Method
propagation	I-Method
.	O
	
This	O
mechanism	O
helps	O
feature	B-Method
generation	I-Method
part	I-Method
to	O
focus	O
on	O
good	O
samples	O
and	O
neglect	O
ones	O
,	O
which	O
benefits	O
set	O
-	O
to	O
-	O
set	B-Task
recognition	I-Task
.	O
	
subsection	O
:	O
Details	O
of	O
quality	B-Method
generation	I-Method
part	I-Method
	
In	O
quality	B-Method
aware	I-Method
network	I-Method
(	O
QAN	B-Method
)	O
,	O
quality	B-Method
generation	I-Method
part	I-Method
is	O
a	O
convolution	B-Method
neural	I-Method
network	I-Method
.	O
	
We	O
design	O
different	O
score	B-Method
generation	I-Method
parts	I-Method
start	O
at	O
different	O
feature	O
maps	O
.	O
	
We	O
use	O
QAN	B-Method
split	O
at	O
Pool4	O
as	O
an	O
instance	O
.	O
	
As	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
the	O
output	O
spatial	O
of	O
Pool4	B-Method
layer	I-Method
is	O
.	O
	
In	O
order	O
to	O
generate	O
a	O
quality	B-Metric
score	I-Metric
,	O
the	O
convolution	B-Method
part	I-Method
contains	O
a	O
2	B-Method
-	I-Method
stride	I-Method
pooling	I-Method
layer	I-Method
and	O
a	O
final	O
pooling	B-Method
layer	I-Method
with	O
kernel	O
size	O
.	O
	
A	O
fully	B-Method
connected	I-Method
layer	I-Method
is	O
followed	O
by	O
the	O
final	O
pooling	B-Method
layer	I-Method
to	O
generate	O
the	O
original	O
quality	B-Metric
score	I-Metric
.	O
	
After	O
that	O
,	O
the	O
origin	O
scores	O
of	O
all	O
images	O
in	O
a	O
set	O
are	O
sent	O
to	O
sigmoid	B-Method
layer	I-Method
and	O
group	O
L1	B-Method
-	I-Method
normalization	I-Method
layer	I-Method
to	O
generate	O
the	O
final	O
scores	O
.	O
	
For	O
QAN	B-Method
split	O
at	O
Pool3	O
,	O
we	O
will	O
add	O
a	O
block	O
containing	O
three	O
1	B-Method
-	I-Method
stride	I-Method
convolution	I-Method
layer	I-Method
and	O
a	O
2	B-Method
-	I-Method
stride	I-Method
pooling	I-Method
layer	I-Method
at	O
the	O
beginning	O
of	O
quality	B-Method
generation	I-Method
unit	I-Method
.	O
	
section	O
:	O
Experiments	O
	
In	O
this	O
section	O
,	O
we	O
first	O
explore	O
the	O
meaning	O
of	O
the	O
quality	B-Metric
score	I-Metric
learned	O
by	O
QAN	B-Method
.	O
	
Then	O
QAN	B-Method
’s	O
sensitivity	O
to	O
level	O
of	O
feature	O
is	O
analysed	O
.	O
	
Based	O
on	O
above	O
knowledge	O
,	O
we	O
evaluate	O
QAN	B-Method
on	O
two	O
human	B-Task
re	I-Task
-	I-Task
identification	I-Task
benchmarks	I-Task
and	O
two	O
unconstrained	O
face	B-Task
verification	I-Task
benchmarks	O
.	O
	
Finally	O
,	O
we	O
analyse	O
the	O
concept	O
learned	O
by	O
QAN	B-Method
and	O
compare	O
it	O
with	O
score	O
labelled	O
by	O
human	O
.	O
	
subsection	O
:	O
What	O
is	O
learned	O
in	O
QAN	B-Method
?	O
	
Qualitative	B-Task
analysis	I-Task
We	O
visualize	O
images	O
with	O
their	O
generated	O
by	O
QAN	B-Method
to	O
explore	O
the	O
meaning	O
of	O
.	O
	
Instances	O
of	O
same	O
person	O
with	O
different	O
qualities	O
are	O
shown	O
in	O
the	O
first	O
two	O
rows	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
All	O
images	O
are	O
selected	O
from	O
test	O
set	O
.	O
	
The	O
two	O
images	O
in	O
the	O
same	O
column	O
belong	O
to	O
a	O
same	O
person	O
.	O
	
The	O
upper	O
images	O
are	O
random	O
selected	O
from	O
images	O
with	O
quality	O
scores	O
higher	O
than	O
0.8	O
and	O
the	O
lower	O
images	O
are	O
selected	O
from	O
images	O
with	O
quality	O
scores	O
lower	O
than	O
the	O
corresponding	O
higher	O
one	O
.	O
	
It	O
is	O
easy	O
to	O
find	O
that	O
images	O
with	O
deformity	O
,	O
superposition	O
,	O
blur	O
or	O
extreme	O
light	O
condition	O
tend	O
to	O
obtain	O
lower	O
quality	O
scores	O
than	O
normal	O
images	O
.	O
	
The	O
last	O
two	O
rows	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
give	O
some	O
examples	O
of	O
other	O
images	O
random	O
selected	O
from	O
test	O
set	O
.	O
	
They	O
are	O
sorted	O
by	O
their	O
quality	O
scores	O
from	O
left	O
to	O
right	O
.	O
	
We	O
can	O
observe	O
that	O
instances	O
with	O
quality	O
scores	O
larger	O
than	O
0.70	O
are	O
easy	O
to	O
recognize	O
by	O
human	O
while	O
the	O
others	O
are	O
hard	O
.	O
	
Especially	O
many	O
of	O
hard	O
images	O
include	O
two	O
or	O
more	O
bodies	O
in	O
the	O
center	O
and	O
we	O
can	O
hardly	O
discriminate	O
which	O
one	O
is	O
the	O
right	O
target	O
.	O
	
Quantitative	B-Task
analysis	I-Task
	
In	O
order	O
to	O
measure	O
the	O
relationship	O
between	O
the	O
quality	B-Metric
labelled	O
by	O
human	O
and	O
predicted	O
by	O
QAN	B-Method
,	O
1000	O
images	O
in	O
YouTube	B-Material
Face	I-Material
are	O
selected	O
randomly	O
and	O
the	O
quality	O
of	O
them	O
are	O
rated	O
subjectively	O
by	O
6	O
volunteers	O
,	O
where	O
each	O
volunteer	O
estimates	O
a	O
quality	B-Metric
score	I-Metric
for	O
each	O
image	O
,	O
ranging	O
from	O
0	O
to	O
1	O
.	O
	
All	O
the	O
ratings	O
of	O
each	O
volunteer	O
are	O
aligned	O
by	O
logistic	B-Method
regression	I-Method
.	O
	
Then	O
the	O
6	O
aligned	O
scores	O
of	O
each	O
image	O
are	O
averaged	O
and	O
finally	O
normalized	O
to	O
to	O
get	O
the	O
final	O
quality	B-Metric
score	I-Metric
from	O
human	O
.	O
	
We	O
divide	O
the	O
images	O
into	O
ten	O
partitions	O
based	O
on	O
human	O
’s	O
score	O
as	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
In	O
which	O
we	O
show	O
the	O
corresponding	O
quality	B-Metric
statistics	I-Metric
generated	O
by	O
QAN	B-Method
.	O
	
It	O
is	O
obvious	O
that	O
the	O
scores	O
given	O
by	O
the	O
QAN	B-Method
are	O
strongly	O
correlated	O
with	O
human	B-Metric
-	I-Metric
defined	I-Metric
quality	I-Metric
.	O
	
We	O
further	O
analyse	O
the	O
499	O
,	O
500	O
image	O
pairs	O
from	O
these	O
1000	O
images	O
and	O
ask	O
human	O
and	O
QAN	B-Method
to	O
select	O
the	O
better	O
one	O
in	O
each	O
pair	O
.	O
	
Result	O
shows	O
that	O
the	O
decision	O
made	O
by	O
QAN	B-Method
has	O
78.1	O
%	O
in	O
common	O
with	O
human	O
decision	O
.	O
	
subsection	O
:	O
Person	B-Task
re	I-Task
-	I-Task
identification	I-Task
	
Datasets	O
.	O
	
For	O
person	B-Task
re	I-Task
-	I-Task
identification	I-Task
,	O
we	O
collect	O
134	O
,	O
942	O
frames	O
with	O
16	O
,	O
133	O
people	O
and	O
212	O
,	O
726	O
bounding	O
boxes	O
as	O
the	O
training	O
data	O
.	O
	
Experiments	O
are	O
conducted	O
on	O
PRID2011	O
and	O
iLiDS	O
-	O
VID	O
datasets	O
.	O
	
PRID2011	O
contains	O
frames	O
in	O
two	O
views	O
captured	O
at	O
different	O
positions	O
of	O
a	O
street	O
.	O
	
CameraA	O
has	O
385	O
identities	O
while	O
CameraB	O
has	O
749	O
identities	O
,	O
and	O
the	O
two	O
videos	O
have	O
a	O
overlap	O
of	O
200	O
people	O
.	O
	
Each	O
person	O
has	O
5	O
to	O
675	O
images	O
,	O
and	O
the	O
average	O
number	O
is	O
100	O
.	O
	
iLIDS	O
-	O
VID	O
dataset	O
has	O
300	O
people	O
,	O
and	O
each	O
person	O
has	O
two	O
sets	O
also	O
captured	O
from	O
different	O
positions	O
.	O
	
Each	O
person	O
has	O
23	O
to	O
192	O
images	O
.	O
	
Evaluation	B-Task
procedure	I-Task
.	O
	
The	O
results	O
are	O
reported	O
in	O
terms	O
of	O
Cumulative	B-Metric
Matching	I-Metric
Characteristics	I-Metric
(	O
CMC	B-Metric
)	I-Metric
table	I-Metric
,	O
each	O
column	O
in	O
which	O
represents	O
matching	B-Metric
rate	I-Metric
in	O
a	O
certain	O
top	O
-	O
N	O
matching	O
.	O
	
Two	O
settings	O
are	O
used	O
for	O
comprehensive	O
evaluation	O
.	O
	
In	O
the	O
first	O
setting	O
,	O
we	O
follow	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
method	O
described	O
in	O
and	O
.	O
	
The	O
sets	O
whose	O
frame	O
number	O
is	O
larger	O
than	O
21	O
are	O
used	O
in	O
PRID2011	O
,	O
and	O
all	O
the	O
sets	O
in	O
iLIDS	O
-	O
VID	O
are	O
used	O
.	O
	
Each	O
dataset	O
is	O
divided	O
into	O
two	O
parts	O
for	O
fine	B-Task
-	I-Task
tuning	I-Task
and	O
testing	B-Task
,	O
respectively	O
.	O
	
For	O
the	O
testing	O
set	O
,	O
sets	O
form	O
CameraA	O
are	O
taken	O
as	O
probe	O
set	O
while	O
sets	O
from	O
CameraB	O
are	O
taken	O
as	O
the	O
gallery	O
.	O
	
The	O
final	O
number	O
is	O
reported	O
as	O
the	O
average	O
of	O
“	O
10	B-Metric
-	I-Metric
fold	I-Metric
cross	I-Metric
validation	I-Metric
”	O
.	O
	
In	O
the	O
second	O
setting	O
,	O
we	O
conduct	O
cross	B-Task
-	I-Task
dataset	I-Task
testing	I-Task
.	O
	
Different	O
from	O
the	O
first	O
setting	O
,	O
we	O
ignore	O
the	O
finetuning	B-Task
process	I-Task
and	O
use	O
all	O
data	O
to	O
test	O
our	O
model	O
.	O
	
That	O
is	O
,	O
in	O
PRID2011	O
,	O
the	O
first	O
200	O
people	O
from	O
CameraA	O
serve	O
as	O
probes	O
,	O
and	O
all	O
sets	O
from	O
CameraB	O
are	O
used	O
as	O
the	O
gallery	O
set	O
.	O
	
In	O
iLIDS	O
-	O
VID	O
,	O
CameraA	O
are	O
used	O
as	O
the	O
probe	O
set	O
,	O
and	O
Camera	O
B	O
serve	O
as	O
gallery	O
set	O
.	O
	
Baseline	O
.	O
	
We	O
implement	O
two	O
baseline	O
approaches	O
.	O
	
In	O
the	O
first	O
baseline	O
,	O
we	O
use	O
average	B-Method
pooling	I-Method
to	O
aggregate	O
all	O
images	O
’	O
representations	O
.	O
	
In	O
the	O
second	O
baseline	O
,	O
a	O
minimal	O
cosine	O
distance	O
between	O
two	O
closures	O
is	O
used	O
to	O
be	O
their	O
similarity	O
.	O
	
subsubsection	O
:	O
Evaluation	O
on	O
common	O
setting	O
	
Results	O
of	O
evaluation	B-Metric
obeying	O
“	O
10	B-Method
-	I-Method
fold	I-Method
cross	I-Method
validation	I-Method
”	O
on	O
PRID2011	O
and	O
iLIDS	O
-	O
VID	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
and	O
Table	O
[	O
reference	O
]	O
.	O
	
Benefiting	O
from	O
the	O
large	O
scale	O
training	O
dataset	O
,	O
our	O
CNN	B-Method
+	I-Method
AvePool	I-Method
and	O
CNN	B-Method
+	I-Method
Min	I-Method
(	I-Method
cos	I-Method
)	I-Method
baselines	O
are	O
close	O
to	O
or	O
even	O
better	O
than	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
.	O
	
Notice	O
that	O
most	O
of	O
the	O
leading	O
methods	O
listed	O
in	O
table	O
consider	O
both	O
appearance	O
and	O
spatio	O
-	O
temporal	O
information	O
while	O
our	O
method	O
only	O
considers	O
appearance	O
information	O
.	O
	
On	O
PRID2011	O
dataset	O
,	O
QAN	B-Method
increase	O
top	B-Metric
-	I-Metric
1	I-Metric
matching	I-Metric
rate	I-Metric
by	O
11.1	O
%	O
and	O
29.4	O
%	O
compared	O
with	O
CNN	B-Method
+	I-Method
AvePool	I-Method
and	O
CNN	B-Method
+	I-Method
Min	I-Method
(	I-Method
cos	I-Method
)	I-Method
.	O
	
On	O
iLIDS	O
-	O
VID	O
dataset	O
,	O
inherent	O
noise	O
is	O
much	O
more	O
than	O
that	O
in	O
PRID2011	O
,	O
which	O
significantly	O
influence	O
the	O
accuracy	B-Metric
of	O
CNN	B-Method
+	I-Method
Min	I-Method
(	I-Method
cos	I-Method
)	O
since	O
operator	O
“	O
Min	O
(	O
cos	O
)	O
”	O
is	O
more	O
sensitive	O
than	O
“	O
AvePool	B-Method
”	I-Method
to	O
noisy	O
samples	O
.	O
	
However	O
,	O
QAN	B-Method
achieves	O
more	O
gain	O
on	O
this	O
noisy	O
dataset	O
.	O
	
It	O
increase	O
top	B-Metric
-	I-Metric
1	I-Metric
matching	I-Metric
rate	I-Metric
by	O
12.21	O
%	O
and	O
37.9	O
%	O
.	O
	
Based	O
on	O
these	O
two	O
experiments	O
,	O
QAN	B-Method
significantly	O
outperforms	O
two	O
baselines	O
on	O
both	O
datasets	O
.	O
	
It	O
also	O
performs	O
better	O
than	O
many	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
approaches	O
and	O
pushes	O
top	B-Metric
-	I-Metric
1	I-Metric
matching	I-Metric
rate	I-Metric
20.3	O
%	O
higher	O
than	O
previous	O
best	O
CNN	B-Method
+	I-Method
RNN	I-Method
on	O
PRID2011	O
and	O
10	O
%	O
on	O
iLIDS	O
-	O
VID	O
.	O
	
The	O
performance	O
gain	O
is	O
more	O
significant	O
on	O
noisy	O
iLIDS	O
-	O
VID	O
dataset	O
,	O
which	O
meets	O
the	O
expectation	O
and	O
proves	O
QAN	B-Method
’s	O
ability	O
to	O
deal	O
with	O
images	O
of	O
poor	O
quality	O
.	O
	
subsubsection	O
:	O
Dataset	O
cross	O
evaluation	O
	
To	O
prevent	O
our	O
model	O
from	O
over	O
-	O
fitting	O
the	O
quality	O
distribution	O
of	O
test	O
set	O
,	O
we	O
conduct	O
dataset	B-Metric
cross	I-Metric
evaluation	I-Metric
.	O
	
We	O
extract	O
set	B-Method
representation	I-Method
of	O
iLIDS	O
-	O
VID	O
and	O
PRID2011	O
directly	O
using	O
trained	O
QAN	B-Method
without	O
fine	B-Method
-	I-Method
tuning	I-Method
.	O
	
The	O
QAN	B-Method
representation	O
is	O
then	O
evaluated	O
for	O
CMC	B-Metric
scores	I-Metric
.	O
	
Table	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
shows	O
the	O
results	O
of	O
QAN	B-Method
and	O
the	O
two	O
baselines	O
.	O
	
It	O
can	O
be	O
found	O
that	O
the	O
QAN	B-Method
is	O
robust	O
even	O
in	O
cross	O
-	O
dataset	O
setting	O
.	O
	
It	O
improves	O
top	B-Metric
-	I-Metric
1	I-Metric
matching	I-Metric
by	O
15.6	O
%	O
and	O
8.2	O
%	O
compared	O
to	O
the	O
baselines	O
.	O
	
This	O
result	O
shows	O
that	O
the	O
quality	O
distribution	O
learned	O
from	O
different	O
datasets	O
by	O
QAN	B-Method
is	O
able	O
to	O
generalize	O
to	O
other	O
datasets	O
.	O
	
subsection	O
:	O
Unconstrained	O
face	B-Task
verification	I-Task
	
Datasets	O
.	O
	
For	O
face	B-Task
verification	I-Task
,	O
we	O
train	O
our	O
base	O
model	O
on	O
extended	O
version	O
of	O
VGG	O
Face	O
dataset	O
,	O
in	O
which	O
we	O
extend	O
the	O
identity	O
number	O
from	O
2.6	O
K	O
to	O
90	O
K	O
and	O
image	O
number	O
from	O
2.6	O
M	O
to	O
5M.	O
The	O
model	O
is	O
evaluated	O
on	O
YouTube	B-Material
Face	I-Material
Database	I-Material
and	O
IARPA	O
Janus	O
Benchmark	O
A	O
(	O
IJB	O
-	O
A	O
)	O
dataset	O
.	O
	
YouTube	B-Material
Face	I-Material
contains	O
3425	O
videos	O
of	O
1595	O
identities	O
.	O
	
It	O
is	O
challenging	O
in	O
that	O
most	O
faces	O
are	O
blurred	O
or	O
has	O
low	O
resolution	O
.	O
	
IJB	O
-	O
A	O
dataset	O
contains	O
2042	O
videos	O
of	O
500	O
people	O
.	O
	
Faces	O
in	O
IJB	O
-	O
A	O
have	O
large	O
pose	O
variance	O
.	O
	
Evaluation	B-Task
procedure	I-Task
.	O
	
We	O
follow	O
the	O
1:1	O
protocol	O
in	O
both	O
two	O
benchmarks	O
and	O
evaluate	O
results	O
using	O
receiver	B-Metric
operating	I-Metric
characteristic	I-Metric
(	O
ROC	B-Metric
)	I-Metric
curves	I-Metric
.	O
	
Area	B-Metric
under	I-Metric
curve	I-Metric
(	O
AUC	B-Metric
)	O
and	O
accuracy	B-Metric
are	O
two	O
important	O
indicators	O
of	O
the	O
ROC	B-Metric
.	O
	
The	O
datasets	O
are	O
evaluated	O
using	O
10	B-Method
-	I-Method
fold	I-Method
cross	I-Method
-	I-Method
validation	I-Method
.	O
	
Training	O
details	O
.	O
	
All	O
faces	O
in	O
training	O
and	O
testing	O
sets	O
are	O
detected	O
and	O
aligned	O
by	O
a	O
multi	B-Method
-	I-Method
task	I-Method
region	I-Method
proposal	I-Method
network	I-Method
as	O
described	O
in	O
.	O
	
Then	O
we	O
crop	O
the	O
face	O
regions	O
and	O
resize	O
them	O
to	O
.	O
	
After	O
that	O
,	O
a	O
convolutional	B-Method
neural	I-Method
networks	I-Method
with	O
inputs	O
are	O
used	O
for	O
face	B-Task
verification	I-Task
.	O
	
It	O
begins	O
with	O
a	O
2	B-Method
-	I-Method
stride	I-Method
convolution	I-Method
layer	I-Method
,	O
followed	O
by	O
4	O
basic	O
blocks	O
,	O
while	O
each	O
block	O
has	O
three	O
1	B-Method
-	I-Method
stride	I-Method
convolution	I-Method
layers	I-Method
and	O
one	O
2	B-Method
-	I-Method
stride	I-Method
pooling	I-Method
layers	I-Method
.	O
	
After	O
that	O
,	O
a	O
fully	B-Method
connected	I-Method
layer	I-Method
is	O
used	O
to	O
get	O
the	O
final	O
feature	O
.	O
	
Quality	B-Metric
generation	I-Metric
branch	I-Metric
is	O
built	O
on	O
top	O
of	O
the	O
third	O
pooling	B-Method
layer	I-Method
,	O
where	O
the	O
spatial	O
size	O
of	O
middle	O
representation	O
response	O
is	O
.	O
	
We	O
pre	O
-	O
train	O
the	O
network	O
supervised	O
by	O
classification	O
signal	O
and	O
then	O
train	O
the	O
whole	O
QAN	B-Method
.	O
	
subsubsection	O
:	O
Results	O
on	O
YouTube	B-Material
Face	I-Material
and	O
IJB	O
-	O
A	O
benchmark	O
	
On	O
YouTube	B-Material
Face	I-Material
dataset	O
,	O
it	O
can	O
be	O
observed	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
and	O
Table	O
[	O
reference	O
]	O
that	O
the	O
accuracy	B-Metric
and	O
AUC	B-Metric
of	O
our	O
baselines	O
are	O
similar	O
with	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
such	O
as	O
FaceNet	B-Method
and	O
NAN	B-Method
.	O
	
Based	O
on	O
this	O
baseline	O
,	O
QAN	B-Method
further	O
reduces	O
15.6	O
%	O
error	B-Metric
ratio	I-Metric
.	O
	
Under	O
ROC	B-Metric
evaluation	I-Metric
metric	I-Metric
,	O
QAN	B-Method
surpasses	O
NAN	B-Method
by	O
8	O
%	O
and	O
DeepFace	B-Method
by	O
80	O
%	O
at	O
0.001	O
FPR	B-Metric
(	O
false	B-Metric
positive	I-Metric
rate	I-Metric
)	O
,	O
which	O
ensembles	O
25	O
models	O
.	O
	
On	O
IJB	O
-	O
A	O
dataset	O
,	O
QAN	B-Method
significantly	O
outperforms	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
algorithm	O
NAN	O
by	O
10.81	O
%	O
at	O
0.001	O
FPR	B-Metric
,	O
4.5	O
%	O
at	O
0.01	O
FPR	B-Metric
and	O
2.12	O
%	O
at	O
FPR=0.1	B-Metric
,	O
as	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Compared	O
with	O
average	B-Method
pooling	I-Method
baseline	I-Method
,	O
QAN	B-Method
reduces	O
false	B-Metric
negative	I-Metric
rate	I-Metric
at	O
above	O
three	O
FPRs	B-Metric
by	O
29.32	O
%	O
,	O
6.45	O
%	O
and	O
7.91	O
%	O
.	O
	
Our	O
experiments	O
on	O
the	O
two	O
tasks	O
show	O
that	O
QAN	B-Method
is	O
robust	O
for	O
set	B-Task
-	I-Task
to	I-Task
-	I-Task
set	I-Task
recognition	I-Task
.	O
	
Especially	O
on	O
the	O
point	O
of	O
low	O
FPR	B-Metric
,	O
QAN	B-Method
can	O
recall	O
more	O
matched	O
samples	O
with	O
less	O
errors	O
.	O
	
subsection	O
:	O
Quality	B-Metric
by	O
QAN	B-Method
VS	O
.	O
quality	B-Metric
by	O
human	O
	
There	O
is	O
no	O
explicit	O
supervision	O
signals	O
for	O
the	O
cascade	B-Method
score	I-Method
generation	I-Method
unit	I-Method
in	O
training	O
.	O
	
So	O
another	O
problem	O
arises	O
:	O
is	O
it	O
better	O
to	O
use	O
human	O
-	O
defined	O
scores	O
instead	O
of	O
letting	O
the	O
network	O
learn	O
itself	O
?	O
	
In	O
YouTube	B-Task
Face	I-Task
experiment	I-Task
,	O
we	O
replace	O
the	O
quality	B-Metric
score	I-Metric
with	O
volunteer	O
-	O
rated	O
score	O
and	O
get	O
the	O
following	O
result	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
which	O
is	O
better	O
than	O
the	O
two	O
baselines	O
but	O
inferior	O
to	O
the	O
result	O
of	O
original	O
QAN	B-Method
.	O
	
It	O
shows	O
that	O
is	O
similar	O
with	O
human	O
thoughts	O
,	O
but	O
more	O
suitable	O
for	O
recognition	B-Task
.	O
	
Quality	B-Metric
score	I-Metric
by	O
human	O
can	O
also	O
enhance	O
the	O
accuracy	B-Metric
but	O
is	O
still	O
worse	O
than	O
QAN	B-Method
’s	O
.	O
	
subsection	O
:	O
Diagnosis	B-Task
experiments	O
	
Level	O
of	O
middle	B-Method
representation	I-Method
may	O
affect	O
the	O
performance	O
of	O
QAN	B-Method
.	O
	
We	O
use	O
YouTube	B-Material
Face	I-Material
to	O
analyse	O
this	O
factor	O
by	O
comparing	O
different	O
configurations	O
.	O
	
In	O
the	O
first	O
configuration	O
,	O
the	O
weight	B-Method
generation	I-Method
part	I-Method
is	O
connected	O
to	O
the	O
image	O
.	O
	
In	O
the	O
second	O
to	O
fifth	O
configurations	O
,	O
weight	B-Method
generation	I-Method
part	I-Method
is	O
set	O
after	O
four	O
pooling	O
layers	O
in	O
each	O
block	O
,	O
respectively	O
.	O
	
In	O
the	O
sixth	O
configuration	O
,	O
we	O
connect	O
weight	B-Method
generation	I-Method
part	I-Method
to	O
a	O
fully	B-Method
connected	I-Method
layer	I-Method
.	O
	
For	O
the	O
final	O
configuration	O
,	O
we	O
fix	O
all	O
parameters	O
before	O
the	O
final	O
fully	O
connection	O
layer	O
in	O
the	O
sixth	O
configuration	O
and	O
only	O
update	O
parameters	O
in	O
weight	B-Method
generation	I-Method
part	I-Method
,	O
which	O
is	O
taken	O
as	O
the	O
seventh	O
structure	O
.	O
	
To	O
minimize	O
the	O
influence	O
by	O
parameters	O
’	O
number	O
,	O
the	O
total	O
size	O
of	O
different	O
models	O
is	O
restricted	O
to	O
the	O
same	O
by	O
changing	O
the	O
channel	O
number	O
.	O
	
Results	O
are	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
It	O
can	O
be	O
found	O
that	O
the	O
performance	O
of	O
QAN	B-Method
improves	O
at	O
the	O
beginning	O
and	O
reaches	O
the	O
top	O
accuracy	B-Metric
at	O
Pool3	O
.	O
	
The	O
end	O
-	O
to	O
-	O
end	O
training	O
version	O
of	O
feature	B-Method
generation	I-Method
part	I-Method
with	O
quality	B-Method
generation	I-Method
part	I-Method
performs	O
better	O
than	O
that	O
of	O
fixed	O
.	O
	
So	O
we	O
can	O
make	O
the	O
conclusion	O
that	O
1	O
)	O
the	O
middle	O
level	O
feature	O
is	O
better	O
for	O
QAN	B-Method
to	O
learn	O
and	O
2	O
)	O
significant	O
improvement	O
can	O
be	O
achieved	O
by	O
jointly	O
training	O
feature	B-Method
generation	I-Method
part	I-Method
and	O
quality	B-Method
generation	I-Method
part	I-Method
.	O
	
section	O
:	O
Conclusion	O
and	O
future	O
work	O
	
In	O
this	O
paper	O
we	O
propose	O
a	O
Quality	B-Method
Aware	I-Method
Network	I-Method
(	O
QAN	B-Method
)	O
for	O
set	B-Task
-	I-Task
to	I-Task
-	I-Task
set	I-Task
recognition	I-Task
.	O
	
It	O
automatically	O
learns	O
the	O
concept	O
of	O
quality	O
for	O
each	O
sample	O
in	O
a	O
set	O
without	O
supervised	O
signal	O
and	O
aggregates	O
the	O
most	O
discriminative	O
samples	O
to	O
generate	O
set	B-Method
representation	I-Method
.	O
	
We	O
theoretically	O
and	O
experimentally	O
demonstrate	O
that	O
the	O
quality	B-Metric
predicted	O
by	O
network	B-Method
is	O
beneficial	O
to	O
set	B-Task
representation	I-Task
and	O
better	O
than	O
human	O
labelled	O
.	O
	
QAN	B-Method
can	O
be	O
seen	O
as	O
an	O
attention	B-Method
model	I-Method
that	O
pay	O
attention	O
to	O
high	O
quality	O
elements	O
in	O
a	O
image	O
set	O
.	O
	
However	O
,	O
an	O
image	O
with	O
poor	O
quality	O
may	O
still	O
has	O
some	O
discriminative	O
regions	O
.	O
	
Considering	O
this	O
,	O
our	O
future	O
work	O
will	O
explore	O
a	O
fine	O
-	O
grained	O
quality	B-Method
aware	I-Method
network	I-Method
that	O
pay	O
attention	O
to	O
high	O
quality	O
regions	O
instead	O
of	O
high	O
quality	O
images	O
in	O
a	O
image	O
set	O
.	O
	
bibliography	O
:	O
References	O
	
Machine	B-Task
reading	I-Task
comprehension	I-Task
(	O
MRC	B-Task
)	O
on	O
real	O
web	O
data	O
usually	O
requires	O
the	O
machine	O
to	O
answer	B-Task
a	I-Task
question	I-Task
by	O
analyzing	O
multiple	O
passages	O
retrieved	O
by	O
search	B-Method
engine	I-Method
.	O
	
Compared	O
with	O
MRC	B-Task
on	O
a	O
single	O
passage	O
,	O
multi	B-Task
-	I-Task
passage	I-Task
MRC	I-Task
is	O
more	O
challenging	O
,	O
since	O
we	O
are	O
likely	O
to	O
get	O
multiple	O
confusing	O
answer	O
candidates	O
from	O
different	O
passages	O
.	O
	
To	O
address	O
this	O
problem	O
,	O
we	O
propose	O
an	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
neural	I-Method
model	I-Method
that	O
enables	O
those	O
answer	O
candidates	O
from	O
different	O
passages	O
to	O
verify	O
each	O
other	O
based	O
on	O
their	O
content	B-Method
representations	O
.	O
	
Specifically	O
,	O
we	O
jointly	O
train	O
three	O
modules	O
that	O
can	O
predict	O
the	O
final	O
answer	O
based	O
on	O
three	O
factors	O
:	O
the	O
answer	O
boundary	O
,	O
the	O
answer	O
content	B-Method
and	O
the	O
cross	B-Task
-	I-Task
passage	I-Task
answer	I-Task
verification	I-Task
.	O
	
The	O
experimental	O
results	O
show	O
that	O
our	O
method	O
outperforms	O
the	O
baseline	O
by	O
a	O
large	O
margin	O
and	O
achieves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
the	O
English	B-Material
MS	I-Material
-	I-Material
MARCO	I-Material
dataset	I-Material
and	O
the	O
Chinese	O
DuReader	O
dataset	O
,	O
both	O
of	O
which	O
are	O
designed	O
for	O
MRC	B-Task
in	O
real	B-Task
-	I-Task
world	I-Task
settings	I-Task
.	O
	
Multi	O
-	O
PassageMachineReadingComprehension	O
	
withCross	O
-	O
PassageAnswerVerification	O
[	O
1*	O
]	O
YizhongWang	O
*	O
ThisworkwasdonewhilethefirstauthorwasdoinginternshipatBaiduInc.	O
[	O
2	O
]	O
KaiLiu	O
[	O
2	O
]	O
JingLiu	O
[	O
2	O
]	O
WeiHe	O
[	O
2	O
]	O
	
YajuanLyu	O
[	O
2	O
]	O
HuaWu	O
[	O
1	O
]	O
SujianLi	O
[	O
2	O
]	O
HaifengWang	O
[	O
1	O
]	O
KeyLaboratoryofComputationalLinguistics	O
,	O
PekingUniversity	O
,	O
MOE	O
,	O
China	O
[	O
2	O
]	O
BaiduInc.	O
,	O
Beijing	O
,	O
China	O
[	O
]	O
{	O
yizhong	O
,	O
lisujian	O
}	O
@pku.edu.cn	O
,	O
{	O
liukai20	O
,	O
liujing46	O
,	O
[	O
]	O
hewei06	O
,	O
lvyajuan	O
,	O
wu_hua	O
,	O
wanghaifeng	O
}	O
	
@baidu.com	O
	
section	O
:	O
Introduction	O
	
Machine	B-Task
reading	I-Task
comprehension	I-Task
(	O
MRC	B-Task
)	O
,	O
empowering	O
computers	O
with	O
the	O
ability	O
to	O
acquire	O
knowledge	O
and	O
answer	O
questions	O
from	O
textual	O
data	O
,	O
is	O
believed	O
to	O
be	O
a	O
crucial	O
step	O
in	O
building	O
a	O
general	O
intelligent	B-Method
agent	I-Method
.	O
	
Recent	O
years	O
have	O
seen	O
rapid	O
growth	O
in	O
the	O
MRC	B-Task
community	I-Task
.	O
	
With	O
the	O
release	O
of	O
various	O
datasets	O
,	O
the	O
MRC	B-Task
task	I-Task
has	O
evolved	O
from	O
the	O
early	O
cloze	O
-	O
style	O
test	O
to	O
answer	B-Task
extraction	I-Task
from	O
a	O
single	O
passage	O
and	O
to	O
the	O
latest	O
more	O
complex	O
question	B-Task
answering	I-Task
on	O
web	O
data	O
.	O
	
Great	O
efforts	O
have	O
also	O
been	O
made	O
to	O
develop	O
models	O
for	O
these	O
MRC	B-Task
tasks	I-Task
,	O
especially	O
for	O
the	O
answer	B-Task
extraction	I-Task
on	O
single	O
passage	O
.	O
	
A	O
significant	O
milestone	O
is	O
that	O
several	O
MRC	B-Method
models	I-Method
have	O
exceeded	O
the	O
performance	O
of	O
human	O
annotators	O
on	O
the	O
SQuAD	O
dataset	O
.	O
	
However	O
,	O
this	O
success	O
on	O
single	O
Wikipedia	O
passage	O
is	O
still	O
not	O
adequate	O
,	O
considering	O
the	O
ultimate	O
goal	O
of	O
reading	O
the	O
whole	O
web	O
.	O
	
Therefore	O
,	O
several	O
latest	O
datasets	O
attempt	O
to	O
design	O
the	O
MRC	B-Task
tasks	I-Task
in	O
more	O
realistic	O
settings	O
by	O
involving	O
search	B-Method
engines	I-Method
.	O
	
For	O
each	O
question	O
,	O
they	O
use	O
the	O
search	B-Method
engine	I-Method
to	O
retrieve	O
multiple	O
passages	O
and	O
the	O
MRC	B-Method
models	I-Method
are	O
required	O
to	O
read	O
these	O
passages	O
in	O
order	O
to	O
give	O
the	O
final	O
answer	O
.	O
	
One	O
of	O
the	O
intrinsic	O
challenges	O
for	O
such	O
multi	B-Task
-	I-Task
passage	I-Task
MRC	I-Task
is	O
that	O
since	O
all	O
the	O
passages	O
are	O
question	O
-	O
related	O
but	O
usually	O
independently	O
written	O
,	O
it	O
’s	O
probable	O
that	O
multiple	O
confusing	O
answer	O
candidates	O
(	O
correct	O
or	O
incorrect	O
)	O
exist	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
an	O
example	O
from	O
MS	B-Material
-	I-Material
MARCO	I-Material
.	O
	
We	O
can	O
see	O
that	O
all	O
the	O
answer	O
candidates	O
have	O
semantic	O
matching	O
with	O
the	O
question	O
while	O
they	O
are	O
literally	O
different	O
and	O
some	O
of	O
them	O
are	O
even	O
incorrect	O
.	O
	
As	O
is	O
shown	O
by	O
adversarial	O
-	O
examples	O
,	O
these	O
confusing	O
answer	O
candidates	O
could	O
be	O
quite	O
difficult	O
for	O
MRC	B-Method
models	I-Method
to	O
distinguish	O
.	O
	
Therefore	O
,	O
special	O
consideration	O
is	O
required	O
for	O
such	O
multi	B-Task
-	I-Task
passage	I-Task
MRC	I-Task
problem	I-Task
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
to	O
leverage	O
the	O
answer	O
candidates	O
from	O
different	O
passages	O
to	O
verify	O
the	O
final	O
correct	O
answer	O
and	O
rule	O
out	O
the	O
noisy	O
incorrect	O
answers	O
.	O
	
Our	O
hypothesis	O
is	O
that	O
the	O
correct	O
answers	O
could	O
occur	O
more	O
frequently	O
in	O
those	O
passages	O
and	O
usually	O
share	O
some	O
commonalities	O
,	O
while	O
incorrect	O
answers	O
are	O
usually	O
different	O
from	O
one	O
another	O
.	O
	
The	O
example	O
in	O
Table	O
[	O
reference	O
]	O
demonstrates	O
this	O
phenomenon	O
.	O
	
We	O
can	O
see	O
that	O
the	O
answer	O
candidates	O
extracted	O
from	O
the	O
last	O
four	O
passages	O
are	O
all	O
valid	O
answers	O
to	O
the	O
question	O
and	O
they	O
are	O
semantically	O
similar	O
to	O
each	O
other	O
,	O
while	O
the	O
answer	O
candidates	O
from	O
the	O
other	O
two	O
passages	O
are	O
incorrect	O
and	O
there	O
is	O
no	O
supportive	O
information	O
from	O
other	O
passages	O
.	O
	
As	O
human	O
beings	O
usually	O
compare	O
the	O
answer	O
candidates	O
from	O
different	O
sources	O
to	O
deduce	O
the	O
final	O
answer	O
,	O
we	O
hope	O
that	O
MRC	B-Method
model	I-Method
can	O
also	O
benefit	O
from	O
the	O
cross	B-Task
-	I-Task
passage	I-Task
answer	I-Task
verification	I-Task
process	I-Task
.	O
	
The	O
overall	O
framework	O
of	O
our	O
model	O
is	O
demonstrated	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
which	O
consists	O
of	O
three	O
modules	O
.	O
	
First	O
,	O
we	O
follow	O
the	O
boundary	B-Method
-	I-Method
based	I-Method
MRC	I-Method
models	I-Method
to	O
find	O
an	O
answer	O
candidate	O
for	O
each	O
passage	O
by	O
identifying	O
the	O
start	O
and	O
end	O
position	O
of	O
the	O
answer	O
(	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
Second	O
,	O
we	O
model	O
the	O
meanings	O
of	O
the	O
answer	O
candidates	O
extracted	O
from	O
those	O
passages	O
and	O
use	O
the	O
content	B-Method
scores	O
to	O
measure	O
the	O
quality	O
of	O
the	O
candidates	O
from	O
a	O
second	O
perspective	O
.	O
	
Third	O
,	O
we	O
conduct	O
the	O
answer	B-Task
verification	I-Task
by	O
enabling	O
each	O
answer	O
candidate	O
to	O
attend	O
to	O
the	O
other	O
candidates	O
based	O
on	O
their	O
representations	O
.	O
	
We	O
hope	O
that	O
the	O
answer	O
candidates	O
can	O
collect	O
supportive	O
information	O
from	O
each	O
other	O
according	O
to	O
their	O
semantic	O
similarities	O
and	O
further	O
decide	O
whether	O
each	O
candidate	O
is	O
correct	O
or	O
not	O
.	O
	
Therefore	O
,	O
the	O
final	O
answer	O
is	O
determined	O
by	O
three	O
factors	O
:	O
the	O
boundary	O
,	O
the	O
content	B-Method
and	O
the	O
cross	B-Task
-	I-Task
passage	I-Task
answer	I-Task
verification	I-Task
.	O
	
The	O
three	O
steps	O
are	O
modeled	O
using	O
different	O
modules	O
,	O
which	O
can	O
be	O
jointly	O
trained	O
in	O
our	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
framework	I-Method
.	O
	
We	O
conduct	O
extensive	O
experiments	O
on	O
the	O
MS	B-Material
-	I-Material
MARCO	I-Material
and	O
DuReader	O
datasets	O
.	O
	
The	O
results	O
show	O
that	O
our	O
answer	B-Method
verification	I-Method
MRC	I-Method
model	I-Method
outperforms	O
the	O
baseline	O
models	O
by	O
a	O
large	O
margin	O
and	O
achieves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
both	O
datasets	O
.	O
	
section	O
:	O
Our	O
Approach	O
	
Figure	O
[	O
reference	O
]	O
gives	O
an	O
overview	O
of	O
our	O
multi	B-Method
-	I-Method
passage	I-Method
MRC	I-Method
model	I-Method
which	O
is	O
mainly	O
composed	O
of	O
three	O
modules	O
including	O
answer	B-Task
boundary	I-Task
prediction	I-Task
,	O
answer	O
content	B-Method
modeling	O
and	O
answer	B-Task
verification	I-Task
.	O
	
First	O
of	O
all	O
,	O
we	O
need	O
to	O
model	O
the	O
question	O
and	O
passages	O
.	O
	
Following	O
bidaf	B-Method
,	O
we	O
compute	O
the	O
question	B-Method
-	I-Method
aware	I-Method
representation	I-Method
for	O
each	O
passage	O
(	O
Section	O
[	O
reference	O
]	O
)	O
.	O
	
Based	O
on	O
this	O
representation	O
,	O
we	O
employ	O
a	O
Pointer	B-Method
Network	I-Method
to	O
predict	O
the	O
start	O
and	O
end	O
position	O
of	O
the	O
answer	O
in	O
the	O
module	O
of	O
answer	B-Task
boundary	I-Task
prediction	I-Task
(	O
Section	O
[	O
reference	O
]	O
)	O
.	O
	
At	O
the	O
same	O
time	O
,	O
with	O
the	O
answer	O
content	B-Method
model	O
(	O
Section	O
[	O
reference	O
]	O
)	O
,	O
we	O
estimate	O
whether	O
each	O
word	O
should	O
be	O
included	O
in	O
the	O
answer	O
and	O
thus	O
obtain	O
the	O
answer	B-Method
representations	I-Method
.	O
	
Next	O
,	O
in	O
the	O
answer	B-Method
verification	I-Method
module	I-Method
(	O
Section	O
[	O
reference	O
]	O
)	O
,	O
each	O
answer	O
candidate	O
can	O
attend	O
to	O
the	O
other	O
answer	O
candidates	O
to	O
collect	O
supportive	O
information	O
and	O
we	O
compute	O
one	O
score	O
for	O
each	O
candidate	O
to	O
indicate	O
whether	O
it	O
is	O
correct	O
or	O
not	O
according	O
to	O
the	O
verification	B-Task
.	O
	
The	O
final	O
answer	O
is	O
determined	O
by	O
not	O
only	O
the	O
boundary	O
but	O
also	O
the	O
answer	O
content	B-Method
and	O
its	O
verification	B-Metric
score	I-Metric
(	O
Section	O
[	O
reference	O
]	O
)	O
.	O
	
subsection	O
:	O
Question	B-Method
and	O
Passage	B-Method
Modeling	I-Method
	
Given	O
a	O
question	O
and	O
a	O
set	O
of	O
passages	O
retrieved	O
by	O
search	B-Method
engines	I-Method
,	O
our	O
task	O
is	O
to	O
find	O
the	O
best	O
concise	O
answer	O
to	O
the	O
question	O
.	O
	
First	O
,	O
we	O
formally	O
present	O
the	O
details	O
of	O
modeling	O
the	O
question	B-Method
and	O
passages	B-Method
.	O
	
paragraph	O
:	O
Encoding	B-Task
	
We	O
first	O
map	O
each	O
word	O
into	O
the	O
vector	O
space	O
by	O
concatenating	O
its	O
word	B-Method
embedding	I-Method
and	O
sum	O
of	O
its	O
character	B-Method
embeddings	I-Method
.	O
	
Then	O
we	O
employ	O
bi	B-Method
-	I-Method
directional	I-Method
LSTMs	I-Method
(	O
BiLSTM	B-Method
)	O
to	O
encode	O
the	O
question	O
and	O
passages	O
as	O
follows	O
:	O
where	O
,	O
,	O
,	O
are	O
the	O
word	O
-	O
level	O
and	O
character	O
-	O
level	O
embeddings	O
of	O
the	O
word	O
.	O
	
and	O
are	O
the	O
encoding	O
vectors	O
of	O
the	O
words	O
in	O
and	O
respectively	O
.	O
	
Unlike	O
previous	O
work	O
that	O
simply	O
concatenates	O
all	O
the	O
passages	O
,	O
we	O
process	O
the	O
passages	O
independently	O
at	O
the	O
encoding	B-Method
and	O
matching	B-Method
steps	I-Method
.	O
	
paragraph	O
:	O
Q	B-Method
-	I-Method
P	I-Method
Matching	I-Method
	
One	O
essential	O
step	O
in	O
MRC	B-Task
is	O
to	O
match	O
the	O
question	O
with	O
passages	O
so	O
that	O
important	O
information	O
can	O
be	O
highlighted	O
.	O
	
We	O
use	O
the	O
Attention	B-Method
Flow	I-Method
Layer	I-Method
to	O
conduct	O
the	O
Q	B-Task
-	I-Task
P	I-Task
matching	I-Task
in	O
two	O
directions	O
.	O
	
The	O
similarity	O
matrix	O
between	O
the	O
question	O
and	O
passage	O
is	O
changed	O
to	O
a	O
simpler	O
version	O
,	O
where	O
the	O
similarity	O
between	O
the	O
word	O
in	O
the	O
question	O
and	O
the	O
word	O
in	O
passage	O
is	O
computed	O
as	O
:	O
Then	O
the	O
context	O
-	O
to	O
-	O
question	O
attention	O
and	O
question	O
-	O
to	O
-	O
context	O
attention	O
is	O
applied	O
strictly	O
following	O
bidaf	O
to	O
obtain	O
the	O
question	B-Method
-	I-Method
aware	I-Method
passage	I-Method
representation	I-Method
.	O
	
We	O
do	O
not	O
give	O
the	O
details	O
here	O
due	O
to	O
space	O
limitation	O
.	O
	
Next	O
,	O
another	O
BiLSTM	B-Method
is	O
applied	O
in	O
order	O
to	O
fuse	O
the	O
contextual	O
information	O
and	O
get	O
the	O
new	O
representation	O
for	O
each	O
word	O
in	O
the	O
passage	O
,	O
which	O
is	O
regarded	O
as	O
the	O
match	O
output	O
:	O
	
Based	O
on	O
the	O
passage	B-Method
representations	I-Method
,	O
we	O
introduce	O
the	O
three	O
main	O
modules	O
of	O
our	O
model	O
.	O
	
subsection	O
:	O
Answer	B-Task
Boundary	I-Task
Prediction	I-Task
	
To	O
extract	O
the	O
answer	O
span	O
from	O
passages	O
,	O
mainstream	O
studies	O
try	O
to	O
locate	O
the	O
boundary	O
of	O
the	O
answer	O
,	O
which	O
is	O
called	O
boundary	B-Method
model	I-Method
.	O
	
Following	O
,	O
we	O
employ	O
Pointer	B-Method
Network	I-Method
to	O
compute	O
the	O
probability	O
of	O
each	O
word	O
to	O
be	O
the	O
start	O
or	O
end	O
position	O
of	O
the	O
span	O
:	O
	
By	O
utilizing	O
the	O
attention	O
weights	O
,	O
the	O
probability	O
of	O
the	O
word	O
in	O
the	O
passage	O
to	O
be	O
the	O
start	O
and	O
end	O
position	O
of	O
the	O
answer	O
is	O
obtained	O
as	O
and	O
.	O
	
It	O
should	O
be	O
noted	O
that	O
the	O
pointer	B-Method
network	I-Method
is	O
applied	O
to	O
the	O
concatenation	O
of	O
all	O
passages	O
,	O
which	O
is	O
denoted	O
as	O
P	O
so	O
that	O
the	O
probabilities	O
are	O
comparable	O
across	O
passages	O
.	O
	
This	O
boundary	B-Method
model	I-Method
can	O
be	O
trained	O
by	O
minimizing	O
the	O
negative	O
log	O
probabilities	O
of	O
the	O
true	O
start	O
and	O
end	O
indices	O
:	O
where	O
is	O
the	O
number	O
of	O
samples	O
in	O
the	O
dataset	O
and	O
,	O
are	O
the	O
gold	O
start	O
and	O
end	O
positions	O
.	O
	
subsection	O
:	O
Answer	B-Method
Content	I-Method
Modeling	I-Method
	
Previous	O
work	O
employs	O
the	O
boundary	B-Method
model	I-Method
to	O
find	O
the	O
text	O
span	O
with	O
the	O
maximum	O
boundary	O
score	O
as	O
the	O
final	O
answer	O
.	O
	
However	O
,	O
in	O
our	O
context	O
,	O
besides	O
locating	O
the	O
answer	O
candidates	O
,	O
we	O
also	O
need	O
to	O
model	O
their	O
meanings	O
in	O
order	O
to	O
conduct	O
the	O
verification	B-Task
.	O
	
An	O
intuitive	O
method	O
is	O
to	O
compute	O
the	O
representation	O
of	O
the	O
answer	O
candidates	O
separately	O
after	O
extracting	O
them	O
,	O
but	O
it	O
could	O
be	O
hard	O
to	O
train	O
such	O
model	O
end	O
-	O
to	O
-	O
end	O
.	O
	
Here	O
,	O
we	O
propose	O
a	O
novel	O
method	O
that	O
can	O
obtain	O
the	O
representation	O
of	O
the	O
answer	O
candidates	O
based	O
on	O
probabilities	O
.	O
	
Specifically	O
,	O
we	O
change	O
the	O
output	O
layer	O
of	O
the	O
classic	O
MRC	B-Method
model	I-Method
.	O
	
Besides	O
predicting	O
the	O
boundary	O
probabilities	O
for	O
the	O
words	O
in	O
the	O
passages	O
,	O
we	O
also	O
predict	O
whether	O
each	O
word	O
should	O
be	O
included	O
in	O
the	O
content	B-Method
of	O
the	O
answer	O
.	O
	
The	O
content	B-Method
probability	O
of	O
the	O
word	O
is	O
computed	O
as	O
:	O
Training	O
this	O
content	B-Method
model	O
is	O
also	O
quite	O
intuitive	O
.	O
	
We	O
transform	O
the	O
boundary	O
labels	O
into	O
a	O
continuous	O
segment	O
,	O
which	O
means	O
the	O
words	O
within	O
the	O
answer	O
span	O
will	O
be	O
labeled	O
as	O
1	O
and	O
other	O
words	O
will	O
be	O
labeled	O
as	O
0	O
.	O
	
In	O
this	O
way	O
,	O
we	O
define	O
the	O
loss	O
function	O
as	O
the	O
averaged	O
cross	O
entropy	O
:	O
The	O
content	B-Method
probabilities	O
provide	O
another	O
view	O
to	O
measure	O
the	O
quality	O
of	O
the	O
answer	O
in	O
addition	O
to	O
the	O
boundary	O
.	O
	
Moreover	O
,	O
with	O
these	O
probabilities	O
,	O
we	O
can	O
represent	O
the	O
answer	O
from	O
passage	O
as	O
a	O
weighted	O
sum	O
of	O
all	O
the	O
word	O
embeddings	O
in	O
this	O
passage	O
:	O
	
subsection	O
:	O
Cross	B-Task
-	I-Task
Passage	I-Task
Answer	I-Task
Verification	I-Task
	
The	O
boundary	B-Method
model	I-Method
and	O
the	O
content	B-Method
model	O
focus	O
on	O
extracting	O
and	O
modeling	O
the	O
answer	O
within	O
a	O
single	O
passage	O
respectively	O
,	O
with	O
little	O
consideration	O
of	O
the	O
cross	O
-	O
passage	O
information	O
.	O
	
However	O
,	O
as	O
is	O
discussed	O
in	O
Section	O
[	O
reference	O
]	O
,	O
there	O
could	O
be	O
multiple	O
answer	O
candidates	O
from	O
different	O
passages	O
and	O
some	O
of	O
them	O
may	O
mislead	O
the	O
MRC	B-Method
model	I-Method
to	O
make	O
an	O
incorrect	O
prediction	O
.	O
	
It	O
’s	O
necessary	O
to	O
aggregate	O
the	O
information	O
from	O
different	O
passages	O
and	O
choose	O
the	O
best	O
one	O
from	O
those	O
candidates	O
.	O
	
Therefore	O
,	O
we	O
propose	O
a	O
method	O
to	O
enable	O
the	O
answer	O
candidates	O
to	O
exchange	O
information	O
and	O
verify	O
each	O
other	O
through	O
the	O
cross	B-Task
-	I-Task
passage	I-Task
answer	I-Task
verification	I-Task
process	I-Task
.	O
	
Given	O
the	O
representation	O
of	O
the	O
answer	O
candidates	O
from	O
all	O
passages	O
,	O
each	O
answer	O
candidate	O
then	O
attends	O
to	O
other	O
candidates	O
to	O
collect	O
supportive	O
information	O
via	O
attention	B-Method
mechanism	I-Method
:	O
Here	O
is	O
the	O
collected	O
verification	O
information	O
from	O
other	O
passages	O
based	O
on	O
the	O
attention	O
weights	O
.	O
	
Then	O
we	O
pass	O
it	O
together	O
with	O
the	O
original	O
representation	O
to	O
a	O
fully	B-Method
connected	I-Method
layer	I-Method
:	O
We	O
further	O
normalize	O
these	O
scores	O
over	O
all	O
passages	O
to	O
get	O
the	O
verification	B-Metric
score	I-Metric
for	O
answer	O
candidate	O
:	O
In	O
order	O
to	O
train	O
this	O
verification	B-Method
model	I-Method
,	O
we	O
take	O
the	O
answer	O
from	O
the	O
gold	O
passage	O
as	O
the	O
gold	O
answer	O
.	O
	
And	O
the	O
loss	O
function	O
can	O
be	O
formulated	O
as	O
the	O
negative	O
log	O
probability	O
of	O
the	O
correct	O
answer	O
:	O
where	O
is	O
the	O
index	O
of	O
the	O
correct	O
answer	O
in	O
all	O
the	O
answer	O
candidates	O
of	O
the	O
instance	O
.	O
	
subsection	O
:	O
Joint	B-Task
Training	I-Task
and	O
Prediction	B-Task
	
As	O
is	O
described	O
above	O
,	O
we	O
define	O
three	O
objectives	O
for	O
the	O
reading	B-Method
comprehension	I-Method
model	I-Method
over	O
multiple	O
passages	O
:	O
	
1	O
.	O
finding	O
the	O
boundary	O
of	O
the	O
answer	O
;	O
2	O
.	O
predicting	O
whether	O
each	O
word	O
should	O
be	O
included	O
in	O
the	O
content	B-Method
;	O
3	O
.	O
selecting	O
the	O
best	O
answer	O
via	O
cross	B-Task
-	I-Task
passage	I-Task
answer	I-Task
verification	I-Task
.	O
	
According	O
to	O
our	O
design	O
,	O
these	O
three	O
tasks	O
can	O
share	O
the	O
same	O
embedding	O
,	O
encoding	O
and	O
matching	O
layers	O
.	O
	
Therefore	O
,	O
we	O
propose	O
to	O
train	O
them	O
together	O
as	O
multi	B-Task
-	I-Task
task	I-Task
learning	I-Task
.	O
	
The	O
joint	B-Metric
objective	I-Metric
function	I-Metric
is	O
formulated	O
as	O
follows	O
:	O
where	O
and	O
are	O
two	O
hyper	O
-	O
parameters	O
that	O
control	O
the	O
weights	O
of	O
those	O
tasks	O
.	O
	
When	O
predicting	O
the	O
final	O
answer	O
,	O
we	O
take	O
the	O
boundary	B-Metric
score	I-Metric
,	O
content	B-Method
score	O
and	O
verification	B-Metric
score	I-Metric
into	O
consideration	O
.	O
	
We	O
first	O
extract	O
the	O
answer	O
candidate	O
that	O
has	O
the	O
maximum	O
boundary	O
score	O
from	O
each	O
passage	O
.	O
	
This	O
boundary	B-Metric
score	I-Metric
is	O
computed	O
as	O
the	O
product	O
of	O
the	O
start	O
and	O
end	O
probability	O
of	O
the	O
answer	O
span	O
.	O
	
Then	O
for	O
each	O
answer	O
candidate	O
,	O
we	O
average	O
the	O
content	B-Method
probabilities	O
of	O
all	O
its	O
words	O
as	O
the	O
content	B-Method
score	O
of	O
.	O
	
And	O
we	O
can	O
also	O
predict	O
the	O
verification	B-Metric
score	I-Metric
for	O
using	O
the	O
verification	B-Method
model	I-Method
.	O
	
Therefore	O
,	O
the	O
final	O
answer	O
can	O
be	O
selected	O
from	O
all	O
the	O
answer	O
candidates	O
according	O
to	O
the	O
product	O
of	O
these	O
three	O
scores	O
.	O
	
section	O
:	O
Experiments	O
	
To	O
verify	O
the	O
effectiveness	O
of	O
our	O
model	O
on	O
multi	B-Task
-	I-Task
passage	I-Task
machine	I-Task
reading	I-Task
comprehension	I-Task
,	O
we	O
conduct	O
experiments	O
on	O
the	O
MS	B-Material
-	I-Material
MARCO	I-Material
and	O
DuReader	O
datasets	O
.	O
	
Our	O
method	O
achieves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
both	O
datasets	O
.	O
	
subsection	O
:	O
Datasets	O
	
We	O
choose	O
the	O
MS	B-Material
-	I-Material
MARCO	I-Material
and	O
DuReader	O
datasets	O
to	O
test	O
our	O
method	O
,	O
since	O
both	O
of	O
them	O
are	O
designed	O
from	O
real	B-Method
-	I-Method
world	I-Method
search	I-Method
engines	I-Method
and	O
involve	O
a	O
large	O
number	O
of	O
passages	O
retrieved	O
from	O
the	O
web	O
.	O
	
One	O
difference	O
of	O
these	O
two	O
datasets	O
is	O
that	O
MS	B-Material
-	I-Material
MARCO	I-Material
mainly	O
focuses	O
on	O
the	O
English	O
web	O
data	O
,	O
while	O
DuReader	O
is	O
designed	O
for	O
Chinese	O
MRC	O
.	O
	
This	O
diversity	O
is	O
expected	O
to	O
reflect	O
the	O
generality	O
of	O
our	O
method	O
.	O
	
In	O
terms	O
of	O
the	O
data	O
size	O
,	O
MS	B-Material
-	I-Material
MARCO	I-Material
contains	O
102023	O
questions	O
,	O
each	O
of	O
which	O
is	O
paired	O
up	O
with	O
approximately	O
10	O
passages	O
for	O
reading	B-Task
comprehension	I-Task
.	O
	
As	O
for	O
DuReader	O
,	O
it	O
keeps	O
the	O
top	O
-	O
5	O
search	O
results	O
for	O
each	O
question	O
and	O
there	O
are	O
totally	O
201574	O
questions	O
.	O
	
One	O
prerequisite	O
for	O
answer	B-Task
verification	I-Task
is	O
that	O
there	O
should	O
be	O
multiple	O
correct	O
answers	O
so	O
that	O
they	O
can	O
verify	O
each	O
other	O
.	O
	
Both	O
the	O
MS	B-Material
-	I-Material
MARCO	I-Material
and	O
DuReader	O
datasets	O
require	O
the	O
human	O
annotators	O
to	O
generate	O
multiple	O
answers	O
if	O
possible	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
proportion	O
of	O
questions	O
that	O
have	O
multiple	O
answers	O
.	O
	
However	O
,	O
the	O
same	O
answer	O
that	O
occurs	O
many	O
times	O
is	O
treated	O
as	O
one	O
single	O
answer	O
here	O
.	O
	
Therefore	O
,	O
we	O
also	O
report	O
the	O
proportion	O
of	O
questions	O
that	O
have	O
multiple	O
answer	O
spans	O
to	O
match	O
with	O
the	O
human	O
-	O
generated	O
answers	O
.	O
	
A	O
span	O
is	O
taken	O
as	O
valid	O
if	O
it	O
can	O
achieve	O
F1	B-Metric
score	I-Metric
larger	O
than	O
0.7	O
compared	O
with	O
any	O
reference	O
answer	O
.	O
	
From	O
these	O
statistics	O
,	O
we	O
can	O
see	O
that	O
the	O
phenomenon	O
of	O
multiple	O
answers	O
is	O
quite	O
common	O
for	O
both	O
MS	B-Material
-	I-Material
MARCO	I-Material
and	O
DuReader	O
.	O
	
These	O
answers	O
will	O
provide	O
strong	O
signals	O
for	O
answer	B-Task
verification	I-Task
if	O
we	O
can	O
leverage	O
them	O
properly	O
.	O
	
subsection	O
:	O
Implementation	O
Details	O
	
For	O
MS	B-Material
-	I-Material
MARCO	I-Material
,	O
we	O
preprocess	O
the	O
corpus	O
with	O
the	O
reversible	B-Method
tokenizer	I-Method
from	O
Stanford	O
CoreNLP	O
and	O
we	O
choose	O
the	O
span	O
that	O
achieves	O
the	O
highest	O
ROUGE	B-Metric
-	I-Metric
L	I-Metric
score	I-Metric
with	O
the	O
reference	O
answers	O
as	O
the	O
gold	O
span	O
for	O
training	O
.	O
	
We	O
employ	O
the	O
300	B-Method
-	I-Method
D	I-Method
pre	I-Method
-	I-Method
trained	I-Method
Glove	I-Method
embeddings	I-Method
and	O
keep	O
it	O
fixed	O
during	O
training	O
.	O
	
The	O
character	O
embeddings	O
are	O
randomly	O
initialized	O
with	O
its	O
dimension	O
as	O
30	O
.	O
	
For	O
DuReader	O
,	O
we	O
follow	O
the	O
preprocessing	O
described	O
in	O
dureader	B-Method
.	O
	
We	O
tune	O
the	O
hyper	O
-	O
parameters	O
according	O
to	O
the	O
validation	O
performance	O
on	O
the	O
MS	B-Material
-	I-Material
MARCO	I-Material
development	I-Material
set	I-Material
.	O
	
The	O
hidden	O
size	O
is	O
set	O
to	O
be	O
150	O
and	O
we	O
apply	O
regularization	B-Method
with	O
its	O
weight	O
as	O
0.0003	O
.	O
	
The	O
task	O
weights	O
,	O
are	O
both	O
set	O
to	O
be	O
0.5	O
.	O
	
To	O
train	O
our	O
model	O
,	O
we	O
employ	O
the	O
Adam	B-Method
algorithm	I-Method
with	O
the	O
initial	O
learning	B-Metric
rate	I-Metric
as	O
0.0004	O
and	O
the	O
mini	O
-	O
batch	O
size	O
as	O
32	O
.	O
	
Exponential	B-Method
moving	I-Method
average	I-Method
is	O
applied	O
on	O
all	O
trainable	O
variables	O
with	O
a	O
decay	B-Metric
rate	I-Metric
0.9999	O
.	O
	
Two	O
simple	O
yet	O
effective	O
technologies	O
are	O
employed	O
to	O
improve	O
the	O
final	O
performance	O
on	O
these	O
two	O
datasets	O
respectively	O
.	O
	
For	O
MS	B-Material
-	I-Material
MARCO	I-Material
,	O
approximately	O
8	O
%	O
questions	O
have	O
the	O
answers	O
as	O
Yes	O
	
or	O
No	O
,	O
which	O
usually	O
can	O
not	O
be	O
solved	O
by	O
extractive	B-Method
approach	I-Method
.	O
	
We	O
address	O
this	O
problem	O
by	O
training	O
a	O
simple	O
Yes	B-Method
/	I-Method
No	I-Method
classifier	I-Method
for	O
those	O
questions	O
with	O
certain	O
patterns	O
(	O
e.g.	O
,	O
starting	O
with	O
“	O
is	O
”	O
)	O
.	O
	
Concretely	O
,	O
we	O
simply	O
change	O
the	O
output	O
layer	O
of	O
the	O
basic	B-Method
boundary	I-Method
model	I-Method
so	O
that	O
it	O
can	O
predict	O
whether	O
the	O
answer	O
is	O
“	O
	
Yes	O
”	O
	
or	O
	
“	O
No	O
”	O
.	O
	
For	O
DuReader	O
,	O
the	O
retrieved	O
document	O
usually	O
contains	O
a	O
large	O
number	O
of	O
paragraphs	O
that	O
can	O
not	O
be	O
fed	O
into	O
MRC	B-Method
models	I-Method
directly	O
.	O
	
The	O
original	O
paper	O
employs	O
a	O
simple	O
a	O
simple	O
heuristic	B-Method
strategy	I-Method
to	O
select	O
a	O
representative	O
paragraph	O
for	O
each	O
document	O
,	O
while	O
we	O
train	O
a	O
paragraph	B-Method
ranking	I-Method
model	I-Method
for	O
this	O
.	O
	
We	O
will	O
demonstrate	O
the	O
effects	O
of	O
these	O
two	O
technologies	O
later	O
.	O
	
subsection	O
:	O
Results	O
on	O
MS	B-Material
-	I-Material
MARCO	I-Material
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
results	O
of	O
our	O
system	O
and	O
other	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
on	O
the	O
MS	B-Material
-	I-Material
MARCO	I-Material
test	I-Material
set	I-Material
.	O
	
We	O
adopt	O
the	O
official	B-Metric
evaluation	I-Metric
metrics	I-Metric
,	O
including	O
ROUGE	B-Metric
-	I-Metric
L	I-Metric
and	O
BLEU	B-Metric
-	I-Metric
1	I-Metric
.	O
	
As	O
we	O
can	O
see	O
,	O
for	O
both	O
metrics	O
,	O
our	O
single	O
model	O
outperforms	O
all	O
the	O
other	O
competing	O
models	O
with	O
an	O
evident	O
margin	O
,	O
which	O
is	O
extremely	O
hard	O
considering	O
the	O
near	O
-	O
human	O
performance	O
.	O
	
If	O
we	O
ensemble	O
the	O
models	O
trained	O
with	O
different	O
random	O
seeds	O
and	O
hyper	O
-	O
parameters	O
,	O
the	O
results	O
can	O
be	O
further	O
improved	O
and	O
outperform	O
the	O
ensemble	B-Method
model	I-Method
in	O
snet	B-Method
,	O
especially	O
in	O
terms	O
of	O
the	O
BLEU	B-Metric
-	I-Metric
1	I-Metric
.	O
	
subsection	O
:	O
Results	O
on	O
DuReader	O
	
The	O
results	O
of	O
our	O
model	O
and	O
several	O
baseline	O
systems	O
on	O
the	O
test	O
set	O
of	O
DuReader	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
The	O
BiDAF	B-Method
and	O
Match	B-Method
-	I-Method
LSTM	I-Method
models	I-Method
are	O
provided	O
as	O
two	O
baseline	O
systems	O
.	O
	
Based	O
on	O
BiDAF	B-Method
,	O
as	O
is	O
described	O
in	O
Section	O
[	O
reference	O
]	O
,	O
we	O
tried	O
a	O
new	O
paragraph	B-Method
selection	I-Method
strategy	I-Method
by	O
employing	O
a	O
paragraph	B-Method
ranking	I-Method
(	O
PR	B-Method
)	O
model	O
.	O
	
We	O
can	O
see	O
that	O
this	O
paragraph	B-Task
ranking	I-Task
can	O
boost	O
the	O
BiDAF	B-Metric
baseline	I-Metric
significantly	O
.	O
	
Finally	O
,	O
we	O
implement	O
our	O
system	O
based	O
on	O
this	O
new	O
strategy	O
,	O
and	O
our	O
system	O
(	O
single	O
model	O
)	O
achieves	O
further	O
improvement	O
by	O
a	O
large	O
margin	O
.	O
	
section	O
:	O
Analysis	O
and	O
Discussion	O
	
subsection	O
:	O
Ablation	B-Task
Study	I-Task
	
To	O
get	O
better	O
insight	O
into	O
our	O
system	O
,	O
we	O
conduct	O
in	O
-	O
depth	O
ablation	B-Task
study	I-Task
on	O
the	O
development	O
set	O
of	O
MS	B-Material
-	I-Material
MARCO	I-Material
,	O
which	O
is	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Following	O
snet	B-Method
,	O
we	O
mainly	O
focus	O
on	O
the	O
ROUGE	B-Metric
-	I-Metric
L	I-Metric
score	I-Metric
that	O
is	O
averaged	O
case	O
by	O
case	O
.	O
	
We	O
first	O
evaluate	O
the	O
answer	B-Task
verification	I-Task
by	O
ablating	O
the	O
cross	B-Method
-	I-Method
passage	I-Method
verification	I-Method
model	I-Method
so	O
that	O
the	O
verification	B-Metric
loss	I-Metric
and	O
verification	B-Metric
score	I-Metric
will	O
not	O
be	O
used	O
during	O
training	O
and	O
testing	O
.	O
	
Then	O
we	O
remove	O
the	O
content	B-Method
model	O
in	O
order	O
to	O
test	O
the	O
necessity	O
of	O
modeling	O
the	O
content	B-Method
of	O
the	O
answer	O
.	O
	
Since	O
we	O
do	O
n’t	O
have	O
the	O
content	B-Method
scores	O
,	O
we	O
use	O
the	O
boundary	O
probabilities	O
instead	O
to	O
compute	O
the	O
answer	B-Method
representation	I-Method
for	O
verification	B-Task
.	O
	
Next	O
,	O
to	O
show	O
the	O
benefits	O
of	O
joint	B-Task
training	I-Task
,	O
we	O
train	O
the	O
boundary	B-Method
model	I-Method
separately	O
from	O
the	O
other	O
two	O
models	O
.	O
	
Finally	O
,	O
we	O
remove	O
the	O
yes	B-Task
/	I-Task
no	I-Task
classification	I-Task
in	O
order	O
to	O
show	O
the	O
real	O
improvement	O
of	O
our	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
model	I-Method
compared	O
with	O
the	O
baseline	O
method	O
that	O
predicts	O
the	O
answer	O
with	O
only	O
the	O
boundary	B-Method
model	I-Method
.	O
	
From	O
Table	O
[	O
reference	O
]	O
,	O
we	O
can	O
see	O
that	O
the	O
answer	B-Task
verification	I-Task
makes	O
a	O
great	O
contribution	O
to	O
the	O
overall	O
improvement	O
,	O
which	O
confirms	O
our	O
hypothesis	O
that	O
cross	B-Task
-	I-Task
passage	I-Task
answer	I-Task
verification	I-Task
is	O
useful	O
for	O
the	O
multi	B-Task
-	I-Task
passage	I-Task
MRC	I-Task
.	O
	
For	O
the	O
ablation	O
of	O
the	O
content	B-Method
model	O
,	O
we	O
analyze	O
that	O
it	O
will	O
not	O
only	O
affect	O
the	O
content	B-Method
score	O
itself	O
,	O
but	O
also	O
violate	O
the	O
verification	B-Method
model	I-Method
since	O
the	O
content	B-Method
probabilities	O
are	O
necessary	O
for	O
the	O
answer	B-Task
representation	I-Task
,	O
which	O
will	O
be	O
further	O
analyzed	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Another	O
discovery	O
is	O
that	O
jointly	O
training	O
the	O
three	O
models	O
can	O
provide	O
great	O
benefits	O
,	O
which	O
shows	O
that	O
the	O
three	O
tasks	O
are	O
actually	O
closely	O
related	O
and	O
can	O
boost	O
each	O
other	O
with	O
shared	O
representations	O
at	O
bottom	O
layers	O
.	O
	
At	O
last	O
,	O
comparing	O
our	O
method	O
with	O
the	O
baseline	O
,	O
we	O
achieve	O
an	O
improvement	O
of	O
nearly	O
3	O
points	O
without	O
the	O
yes	B-Task
/	I-Task
no	I-Task
classification	I-Task
.	O
	
This	O
significant	O
improvement	O
proves	O
the	O
effectiveness	O
of	O
our	O
approach	O
.	O
	
subsection	O
:	O
Case	O
Study	O
	
To	O
demonstrate	O
how	O
each	O
module	O
of	O
our	O
model	O
takes	O
effect	O
when	O
predicting	O
the	O
final	O
answer	O
,	O
we	O
conduct	O
a	O
case	O
study	O
in	O
Table	O
[	O
reference	O
]	O
with	O
the	O
same	O
example	O
that	O
we	O
discussed	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
For	O
each	O
answer	O
candidate	O
,	O
we	O
list	O
three	O
scores	O
predicted	O
by	O
the	O
boundary	B-Method
model	I-Method
,	O
content	B-Method
model	O
and	O
verification	B-Method
model	I-Method
respectively	O
.	O
	
On	O
the	O
one	O
hand	O
,	O
we	O
can	O
see	O
that	O
these	O
three	O
scores	O
generally	O
have	O
some	O
relevance	O
.	O
	
For	O
example	O
,	O
the	O
second	O
candidate	O
is	O
given	O
lowest	O
scores	O
by	O
all	O
the	O
three	O
models	O
.	O
	
We	O
analyze	O
that	O
this	O
is	O
because	O
the	O
models	O
share	O
the	O
same	O
encoding	O
and	O
matching	O
layers	O
at	O
bottom	O
level	O
and	O
this	O
relevance	O
guarantees	O
that	O
the	O
content	B-Method
and	O
verification	B-Method
models	I-Method
will	O
not	O
violate	O
the	O
boundary	B-Method
model	I-Method
too	O
much	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
we	O
also	O
see	O
that	O
the	O
verification	B-Metric
score	I-Metric
can	O
really	O
make	O
a	O
difference	O
here	O
when	O
the	O
boundary	B-Method
model	I-Method
makes	O
an	O
incorrect	O
decision	O
among	O
the	O
confusing	O
answer	O
candidates	O
(	O
[	O
1	O
]	O
,	O
[	O
3	O
]	O
,	O
[	O
4	O
]	O
,	O
[	O
6	O
]	O
)	O
.	O
	
Besides	O
,	O
as	O
we	O
expected	O
,	O
the	O
verification	B-Method
model	I-Method
tends	O
to	O
give	O
higher	O
scores	O
for	O
those	O
answers	O
that	O
have	O
semantic	O
commonality	O
with	O
each	O
other	O
(	O
[	O
3	O
]	O
,	O
[	O
4	O
]	O
,	O
[	O
6	O
]	O
)	O
,	O
which	O
are	O
all	O
valid	O
answers	O
in	O
this	O
case	O
.	O
	
By	O
multiplying	O
the	O
three	O
scores	O
,	O
our	O
model	O
finally	O
predicts	O
the	O
answer	O
correctly	O
.	O
	
subsection	O
:	O
Necessity	O
of	O
the	O
Content	B-Method
Model	I-Method
	
In	O
our	O
model	O
,	O
we	O
compute	O
the	O
answer	B-Method
representation	I-Method
based	O
on	O
the	O
content	B-Method
probabilities	O
predicted	O
by	O
a	O
separate	O
content	B-Method
model	O
instead	O
of	O
directly	O
using	O
the	O
boundary	O
probabilities	O
.	O
	
We	O
argue	O
that	O
this	O
content	B-Method
model	O
is	O
necessary	O
for	O
our	O
answer	B-Task
verification	I-Task
process	I-Task
.	O
	
Figure	O
[	O
reference	O
]	O
plots	O
the	O
predicted	O
content	B-Method
probabilities	O
as	O
well	O
as	O
the	O
boundary	O
probabilities	O
for	O
a	O
passage	O
.	O
	
We	O
can	O
see	O
that	O
the	O
boundary	O
and	O
content	B-Method
probabilities	O
capture	O
different	O
aspects	O
of	O
the	O
answer	O
.	O
	
Since	O
answer	O
candidates	O
usually	O
have	O
similar	O
boundary	O
words	O
,	O
if	O
we	O
compute	O
the	O
answer	B-Method
representation	I-Method
based	O
on	O
the	O
boundary	O
probabilities	O
,	O
it	O
’s	O
difficult	O
to	O
model	O
the	O
real	O
difference	O
among	O
different	O
answer	O
candidates	O
.	O
	
On	O
the	O
contrary	O
,	O
with	O
the	O
content	B-Method
probabilities	O
,	O
we	O
pay	O
more	O
attention	O
to	O
the	O
content	B-Method
part	O
of	O
the	O
answer	O
,	O
which	O
can	O
provide	O
more	O
distinguishable	O
information	O
for	O
verifying	O
the	O
correct	O
answer	O
.	O
	
Furthermore	O
,	O
the	O
content	B-Method
probabilities	O
can	O
also	O
adjust	O
the	O
weights	O
of	O
the	O
words	O
within	O
the	O
answer	O
span	O
so	O
that	O
unimportant	O
words	O
(	O
e.g.	O
“	O
and	O
	
”	O
and	O
“	O
.	O
”	O
)	O
get	O
lower	O
weights	O
in	O
the	O
final	O
answer	B-Method
representation	I-Method
.	O
	
We	O
believe	O
that	O
this	O
refined	O
representation	O
is	O
also	O
good	O
for	O
the	O
answer	B-Task
verification	I-Task
process	I-Task
.	O
	
section	O
:	O
Related	O
Work	O
	
Machine	B-Task
reading	I-Task
comprehension	I-Task
made	O
rapid	O
progress	O
in	O
recent	O
years	O
,	O
especially	O
for	O
single	B-Task
-	I-Task
passage	I-Task
MRC	I-Task
task	I-Task
,	O
such	O
as	O
SQuAD	O
.	O
	
Mainstream	O
studies	O
treat	O
reading	B-Task
comprehension	I-Task
as	O
extracting	O
answer	O
span	O
from	O
the	O
given	O
passage	O
,	O
which	O
is	O
usually	O
achieved	O
by	O
predicting	O
the	O
start	O
and	O
end	O
position	O
of	O
the	O
answer	O
.	O
	
We	O
implement	O
our	O
boundary	B-Method
model	I-Method
similarly	O
by	O
employing	O
the	O
boundary	B-Method
-	I-Method
based	I-Method
pointer	I-Method
network	I-Method
.	O
	
Another	O
inspiring	O
work	O
is	O
from	O
rnet	B-Method
,	O
where	O
the	O
authors	O
propose	O
to	O
match	O
the	O
passage	O
against	O
itself	O
so	O
that	O
the	O
representation	O
can	O
aggregate	O
evidence	O
from	O
the	O
whole	O
passage	O
.	O
	
Our	O
verification	B-Method
model	I-Method
adopts	O
a	O
similar	O
idea	O
.	O
	
However	O
,	O
we	O
collect	O
information	O
across	O
passages	O
and	O
our	O
attention	B-Method
is	O
based	O
on	O
the	O
answer	B-Method
representation	I-Method
,	O
which	O
is	O
much	O
more	O
efficient	O
than	O
attention	B-Method
over	O
all	O
passages	O
.	O
	
For	O
the	O
model	B-Task
training	I-Task
,	O
dcn	B-Method
+	I-Method
argues	O
that	O
the	O
boundary	O
loss	O
encourages	O
exact	O
answers	O
at	O
the	O
cost	O
of	O
penalizing	O
overlapping	O
answers	O
.	O
	
Therefore	O
they	O
propose	O
a	O
mixed	B-Method
objective	I-Method
that	O
incorporates	O
rewards	O
derived	O
from	O
word	O
overlap	O
.	O
	
Our	O
joint	B-Method
training	I-Method
approach	I-Method
has	O
a	O
similar	O
function	O
.	O
	
By	O
taking	O
the	O
content	B-Method
and	O
verification	O
loss	O
into	O
consideration	O
,	O
our	O
model	O
will	O
give	O
less	O
loss	O
for	O
overlapping	O
answers	O
than	O
those	O
unmatched	O
answers	O
,	O
and	O
our	O
loss	O
function	O
is	O
totally	O
differentiable	O
.	O
	
Recently	O
,	O
we	O
also	O
see	O
emerging	O
interests	O
in	O
multi	O
-	O
passage	B-Task
MRC	I-Task
from	O
both	O
the	O
academic	O
and	O
industrial	O
community	O
.	O
	
Early	O
studies	O
usually	O
concat	O
those	O
passages	O
and	O
employ	O
the	O
same	O
models	O
designed	O
for	O
single	B-Task
-	I-Task
passage	I-Task
MRC	I-Task
.	O
	
However	O
,	O
more	O
and	O
more	O
latest	O
studies	O
start	O
to	O
design	O
specific	O
methods	O
that	O
can	O
read	O
multiple	O
passages	O
more	O
effectively	O
.	O
	
In	O
the	O
aspect	O
of	O
passage	B-Task
selection	I-Task
,	O
r3	B-Method
introduced	O
a	O
pipelined	B-Method
approach	I-Method
that	O
rank	O
the	O
passages	O
first	O
and	O
then	O
read	O
the	O
selected	O
passages	O
for	O
answering	O
questions	O
.	O
	
snet	B-Method
treats	O
the	O
passage	B-Task
ranking	I-Task
as	O
an	O
auxiliary	B-Task
task	I-Task
that	O
can	O
be	O
trained	O
jointly	O
with	O
the	O
reading	B-Method
comprehension	I-Method
model	I-Method
.	O
	
Actually	O
,	O
the	O
target	O
of	O
our	O
answer	B-Task
verification	I-Task
is	O
very	O
similar	O
to	O
that	O
of	O
the	O
passage	B-Task
selection	I-Task
,	O
while	O
we	O
pay	O
more	O
attention	O
to	O
the	O
answer	O
content	B-Method
and	O
the	O
answer	B-Task
verification	I-Task
process	I-Task
.	O
	
Speaking	O
of	O
the	O
answer	B-Task
verification	I-Task
,	O
evidence_aggregation	B-Task
has	O
a	O
similar	O
motivation	O
to	O
ours	O
.	O
	
They	O
attempt	O
to	O
aggregate	O
the	O
evidence	O
from	O
different	O
passages	O
and	O
choose	O
the	O
final	O
answer	O
from	O
n	O
-	O
best	O
candidates	O
.	O
	
However	O
,	O
they	O
implement	O
their	O
idea	O
as	O
a	O
separate	O
reranking	B-Task
step	I-Task
after	O
reading	B-Task
comprehension	I-Task
,	O
while	O
our	O
answer	B-Task
verification	I-Task
is	O
a	O
component	O
of	O
the	O
whole	O
model	O
that	O
can	O
be	O
trained	O
end	O
-	O
to	O
-	O
end	O
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
an	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
framework	I-Method
to	O
tackle	O
the	O
multi	B-Task
-	I-Task
passage	I-Task
MRC	I-Task
task	I-Task
.	O
	
We	O
creatively	O
design	O
three	O
different	O
modules	O
in	O
our	O
model	O
,	O
which	O
can	O
find	O
the	O
answer	O
boundary	O
,	O
model	O
the	O
answer	O
content	B-Method
and	O
conduct	O
cross	B-Task
-	I-Task
passage	I-Task
answer	I-Task
verification	I-Task
respectively	O
.	O
	
All	O
these	O
three	O
modules	O
can	O
be	O
trained	O
with	O
different	O
forms	O
of	O
the	O
answer	O
labels	O
and	O
training	O
them	O
jointly	O
can	O
provide	O
further	O
improvement	O
.	O
	
The	O
experimental	O
results	O
demonstrate	O
that	O
our	O
model	O
outperforms	O
the	O
baseline	O
models	O
by	O
a	O
large	O
margin	O
and	O
achieves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
two	O
challenging	O
datasets	O
,	O
both	O
of	O
which	O
are	O
designed	O
for	O
MRC	B-Task
on	O
real	O
web	O
data	O
.	O
	
section	O
:	O
Acknowledgments	O
	
This	O
work	O
is	O
supported	O
by	O
the	O
National	O
Basic	O
Research	O
Program	O
of	O
China	O
(	O
973	O
program	O
,	O
No	O
.	O
	
2014CB340505	O
)	O
and	O
Baidu	O
-	O
Peking	O
University	O
Joint	O
Project	O
.	O
	
We	O
thank	O
the	O
Microsoft	O
MSMARCO	O
team	O
for	O
evaluating	O
our	O
results	O
on	O
the	O
anonymous	O
test	O
set	O
.	O
	
We	O
also	O
thank	O
Ying	O
Chen	O
,	O
Xuan	O
Liu	O
and	O
the	O
anonymous	O
reviewers	O
for	O
their	O
constructive	O
criticism	O
of	O
the	O
manuscript	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Density	B-Task
estimation	I-Task
using	O
Real	B-Method
NVP	I-Method
	
Unsupervised	B-Method
learning	I-Method
of	O
probabilistic	B-Method
models	I-Method
is	O
a	O
central	O
yet	O
challenging	O
problem	O
in	O
machine	B-Task
learning	I-Task
.	O
	
Specifically	O
,	O
designing	O
models	O
with	O
tractable	B-Task
learning	I-Task
,	O
sampling	B-Task
,	O
inference	B-Task
and	O
evaluation	B-Task
is	O
crucial	O
in	O
solving	O
this	O
task	O
.	O
	
We	O
extend	O
the	O
space	O
of	O
such	O
models	O
using	O
real	B-Method
-	I-Method
valued	I-Method
non	I-Method
-	I-Method
volume	I-Method
preserving	I-Method
(	O
real	B-Method
NVP	I-Method
)	O
transformations	O
,	O
a	O
set	O
of	O
powerful	O
,	O
stably	O
invertible	O
,	O
and	O
learnable	O
transformations	O
,	O
resulting	O
in	O
an	O
unsupervised	B-Method
learning	I-Method
algorithm	I-Method
with	O
exact	B-Task
log	I-Task
-	I-Task
likelihood	I-Task
computation	I-Task
,	O
exact	O
and	O
efficient	O
sampling	B-Task
,	O
exact	O
and	O
efficient	O
inference	B-Task
of	I-Task
latent	I-Task
variables	I-Task
,	O
and	O
an	O
interpretable	O
latent	O
space	O
.	O
	
We	O
demonstrate	O
its	O
ability	O
to	O
model	O
natural	O
images	O
on	O
four	O
datasets	O
through	O
sampling	B-Method
,	O
log	B-Method
-	I-Method
likelihood	I-Method
evaluation	I-Method
,	O
and	O
latent	B-Method
variable	I-Method
manipulations	I-Method
.	O
	
[	O
]	O
,	O
	
n	O
,	O
,	O
	
section	O
:	O
Introduction	O
	
The	O
domain	O
of	O
representation	B-Task
learning	I-Task
has	O
undergone	O
tremendous	O
advances	O
due	O
to	O
improved	O
supervised	B-Method
learning	I-Method
techniques	I-Method
.	O
	
However	O
,	O
unsupervised	B-Method
learning	I-Method
has	O
the	O
potential	O
to	O
leverage	O
large	O
pools	O
of	O
unlabeled	O
data	O
,	O
and	O
extend	O
these	O
advances	O
to	O
modalities	O
that	O
are	O
otherwise	O
impractical	O
or	O
impossible	O
.	O
	
One	O
principled	O
approach	O
to	O
unsupervised	B-Method
learning	I-Method
is	O
generative	B-Method
probabilistic	I-Method
modeling	I-Method
.	O
	
Not	O
only	O
do	O
generative	B-Method
probabilistic	I-Method
models	I-Method
have	O
the	O
ability	O
to	O
create	O
novel	O
content	O
,	O
they	O
also	O
have	O
a	O
wide	O
range	O
of	O
reconstruction	B-Task
related	I-Task
applications	I-Task
including	O
inpainting	B-Task
theis2015generative	O
,	O
oord2016pixel	O
,	O
DBLP	O
:	O
conf	O
/	O
icml	O
/	O
Sohl	O
-	O
DicksteinW15	O
,	O
denoising	B-Task
balle2015density	O
,	O
colorization	B-Task
zhang2016colorful	O
,	O
and	O
super	B-Task
-	I-Task
resolution	I-Task
bruna2015super	O
.	O
	
As	O
data	O
of	O
interest	O
are	O
generally	O
high	O
-	O
dimensional	O
and	O
highly	O
structured	O
,	O
the	O
challenge	O
in	O
this	O
domain	O
is	O
building	O
models	O
that	O
are	O
powerful	O
enough	O
to	O
capture	O
its	O
complexity	O
yet	O
still	O
trainable	O
.	O
	
We	O
address	O
this	O
challenge	O
by	O
introducing	O
real	B-Method
-	I-Method
valued	I-Method
non	I-Method
-	I-Method
volume	I-Method
preserving	I-Method
(	O
real	B-Method
NVP	I-Method
)	O
transformations	O
,	O
a	O
tractable	O
yet	O
expressive	O
approach	O
to	O
modeling	B-Task
high	I-Task
-	I-Task
dimensional	I-Task
data	I-Task
.	O
	
This	O
model	O
can	O
perform	O
efficient	O
and	O
exact	B-Task
inference	I-Task
,	O
sampling	B-Task
and	O
log	B-Task
-	I-Task
density	I-Task
estimation	I-Task
of	O
data	O
points	O
.	O
	
Moreover	O
,	O
the	O
architecture	O
presented	O
in	O
this	O
paper	O
enables	O
exact	O
and	O
efficient	O
reconstruction	B-Task
of	O
input	O
images	O
from	O
the	O
hierarchical	O
features	O
extracted	O
by	O
this	O
model	O
.	O
	
section	O
:	O
Related	O
work	O
	
Inference	B-Task
Generation	I-Task
Substantial	O
work	O
on	O
probabilistic	B-Method
generative	I-Method
models	I-Method
has	O
focused	O
on	O
training	O
models	O
using	O
maximum	B-Method
likelihood	I-Method
.	O
	
One	O
class	O
of	O
maximum	B-Method
likelihood	I-Method
models	I-Method
are	O
those	O
described	O
by	O
probabilistic	B-Method
undirected	I-Method
graphs	I-Method
,	O
such	O
as	O
Restricted	B-Method
Boltzmann	I-Method
Machines	I-Method
smolensky1986information	O
and	O
Deep	B-Method
Boltzmann	I-Method
Machines	I-Method
salakhutdinov2009deep	O
.	O
	
These	O
models	O
are	O
trained	O
by	O
taking	O
advantage	O
of	O
the	O
conditional	O
independence	O
property	O
of	O
their	O
bipartite	O
structure	O
to	O
allow	O
efficient	O
exact	B-Task
or	I-Task
approximate	I-Task
posterior	I-Task
inference	I-Task
on	I-Task
latent	I-Task
variables	I-Task
.	O
	
However	O
,	O
because	O
of	O
the	O
intractability	O
of	O
the	O
associated	O
marginal	O
distribution	O
over	O
latent	O
variables	O
,	O
their	O
training	O
,	O
evaluation	B-Task
,	O
and	O
sampling	B-Method
procedures	I-Method
necessitate	O
the	O
use	O
of	O
approximations	B-Method
like	O
Mean	B-Method
Field	I-Method
inference	I-Method
and	O
Markov	B-Method
Chain	I-Method
Monte	I-Method
Carlo	I-Method
,	O
whose	O
convergence	B-Metric
time	I-Metric
for	O
such	O
complex	O
models	O
remains	O
undetermined	O
,	O
often	O
resulting	O
in	O
generation	O
of	O
highly	O
correlated	O
samples	O
.	O
	
Furthermore	O
,	O
these	O
approximations	O
can	O
often	O
hinder	O
their	O
performance	O
berglund2013stochastic	O
.	O
	
Directed	B-Method
graphical	I-Method
models	I-Method
are	O
instead	O
defined	O
in	O
terms	O
of	O
an	O
ancestral	B-Method
sampling	I-Method
procedure	I-Method
,	O
which	O
is	O
appealing	O
both	O
for	O
its	O
conceptual	O
and	O
computational	B-Metric
simplicity	O
.	O
	
They	O
lack	O
,	O
however	O
,	O
the	O
conditional	O
independence	O
structure	O
of	O
undirected	B-Method
models	I-Method
,	O
making	O
exact	B-Task
and	I-Task
approximate	I-Task
posterior	I-Task
inference	I-Task
on	O
latent	O
variables	O
cumbersome	O
saul1996mean	O
.	O
	
Recent	O
advances	O
in	O
stochastic	B-Method
variational	I-Method
inference	I-Method
hoffman2013stochastic	O
and	O
amortized	B-Task
inference	I-Task
dayan1995helmholtz	O
,	O
mnih2014neural	O
,	O
kingma2013auto	O
,	O
rezende2014stochastic	O
,	O
allowed	O
efficient	O
approximate	B-Task
inference	I-Task
and	I-Task
learning	I-Task
of	I-Task
deep	I-Task
directed	I-Task
graphical	I-Task
models	I-Task
by	O
maximizing	O
a	O
variational	B-Metric
lower	I-Metric
bound	I-Metric
on	O
the	O
log	O
-	O
likelihood	O
neal1998view	O
.	O
	
In	O
particular	O
,	O
the	O
variational	B-Method
autoencoder	I-Method
algorithm	I-Method
kingma2013auto	O
,	O
rezende2014stochastic	O
simultaneously	O
learns	O
a	O
generative	B-Method
network	I-Method
,	O
that	O
maps	O
gaussian	O
latent	O
variables	O
to	O
samples	O
,	O
and	O
a	O
matched	B-Method
approximate	I-Method
inference	I-Method
network	I-Method
that	O
maps	O
samples	O
to	O
a	O
semantically	O
meaningful	O
latent	O
representation	O
,	O
by	O
exploiting	O
the	O
reparametrization	B-Method
trick	I-Method
williams1992simple	O
.	O
	
Its	O
success	O
in	O
leveraging	O
recent	O
advances	O
in	O
backpropagation	B-Method
rumelhart1988learning	O
,	O
lecun2012efficient	O
in	O
deep	B-Method
neural	I-Method
networks	I-Method
resulted	O
in	O
its	O
adoption	O
for	O
several	O
applications	O
ranging	O
from	O
speech	B-Task
synthesis	I-Task
chung2015recurrent	O
to	O
language	B-Task
modeling	I-Task
bowman2015generating	O
.	O
	
Still	O
,	O
the	O
approximation	O
in	O
the	O
inference	B-Method
process	I-Method
limits	O
its	O
ability	O
to	O
learn	O
high	B-Task
dimensional	I-Task
deep	I-Task
representations	I-Task
,	O
motivating	O
recent	O
work	O
in	O
improving	O
approximate	B-Task
inference	I-Task
maaloe2016auxiliary	O
,	O
rezende2015variational	O
,	O
salimans2014markov	O
,	O
tran2015variational	O
,	O
burda2015importance	O
,	O
DBLP	O
:	O
conf	O
/	O
icml	O
/	O
Sohl	O
-	O
DicksteinW15	O
,	O
kingma2016improving	O
.	O
	
Such	O
approximations	O
can	O
be	O
avoided	O
altogether	O
by	O
abstaining	O
from	O
using	O
latent	O
variables	O
.	O
	
Auto	B-Method
-	I-Method
regressive	I-Method
models	I-Method
frey1998graphical	O
,	O
bengio1999modeling	O
,	O
larochelle2011neural	O
,	O
DBLP	O
:	O
journals	O
/	O
corr	O
/	O
GermainGML15	O
can	O
implement	O
this	O
strategy	O
while	O
typically	O
retaining	O
a	O
great	O
deal	O
of	O
flexibility	O
.	O
	
This	O
class	O
of	O
algorithms	O
tractably	O
models	O
the	O
joint	O
distribution	O
by	O
decomposing	O
it	O
into	O
a	O
product	O
of	O
conditionals	O
using	O
the	O
probability	B-Method
chain	I-Method
rule	I-Method
according	O
to	O
a	O
fixed	O
ordering	O
over	O
dimensions	O
,	O
simplifying	O
log	B-Method
-	I-Method
likelihood	I-Method
evaluation	I-Method
and	O
sampling	B-Task
.	O
	
Recent	O
work	O
in	O
this	O
line	O
of	O
research	O
has	O
taken	O
advantage	O
of	O
recent	O
advances	O
in	O
recurrent	B-Method
networks	I-Method
rumelhart1988learning	O
,	O
in	O
particular	O
long	B-Method
-	I-Method
short	I-Method
term	I-Method
memory	I-Method
DBLP	O
:	O
journals	O
/	O
neco	O
/	O
HochreiterS97	O
,	O
and	O
residual	B-Method
networks	I-Method
DBLP	O
:	O
journals	O
/	O
corr	O
/	O
HeZR016	O
,	O
DBLP	O
:	O
journals	O
/	O
corr	O
	
/	O
HeZRS15	O
in	O
order	O
to	O
learn	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
generative	B-Method
image	I-Method
models	I-Method
theis2015generative	O
,	O
oord2016pixel	O
and	O
language	B-Method
models	I-Method
	
DBLP	O
:	O
	
journals	O
/	O
corr	O
	
/	O
JozefowiczVSSW16	O
.	O
	
The	O
ordering	O
of	O
the	O
dimensions	O
,	O
although	O
often	O
arbitrary	O
,	O
can	O
be	O
critical	O
to	O
the	O
training	O
of	O
the	O
model	O
vinyals2015order	O
.	O
	
The	O
sequential	O
nature	O
of	O
this	O
model	O
limits	O
its	O
computational	B-Metric
efficiency	O
.	O
	
For	O
example	O
,	O
its	O
sampling	B-Method
procedure	I-Method
is	O
sequential	O
and	O
non	O
-	O
parallelizable	O
,	O
which	O
can	O
become	O
cumbersome	O
in	O
applications	O
like	O
speech	B-Task
and	I-Task
music	I-Task
synthesis	I-Task
,	O
or	O
real	B-Task
-	I-Task
time	I-Task
rendering	I-Task
..	O
	
Additionally	O
,	O
there	O
is	O
no	O
natural	B-Method
latent	I-Method
representation	I-Method
associated	O
with	O
autoregressive	B-Method
models	I-Method
,	O
and	O
they	O
have	O
not	O
yet	O
been	O
shown	O
to	O
be	O
useful	O
for	O
semi	B-Task
-	I-Task
supervised	I-Task
learning	I-Task
.	O
	
Generative	B-Method
Adversarial	I-Method
Networks	I-Method
(	O
GANs	B-Method
)	O
	
DBLP	O
:	O
conf	O
/	O
nips	O
/	O
GoodfellowPMXWOCB14	O
on	O
the	O
other	O
hand	O
can	O
train	O
any	O
differentiable	B-Method
generative	I-Method
network	I-Method
by	O
avoiding	O
the	O
maximum	B-Method
likelihood	I-Method
principle	I-Method
altogether	O
.	O
	
Instead	O
,	O
the	O
generative	B-Method
network	I-Method
is	O
associated	O
with	O
a	O
discriminator	B-Method
network	I-Method
whose	O
task	O
is	O
to	O
distinguish	O
between	O
samples	O
and	O
real	O
data	O
.	O
	
Rather	O
than	O
using	O
an	O
intractable	O
log	O
-	O
likelihood	O
,	O
this	O
discriminator	B-Method
network	I-Method
provides	O
the	O
training	O
signal	O
in	O
an	O
adversarial	B-Method
fashion	I-Method
.	O
	
Successfully	O
trained	O
GAN	B-Method
models	I-Method
DBLP	O
:	O
conf	O
/	O
nips	O
/	O
GoodfellowPMXWOCB14	O
,	O
DBLP	O
:	O
conf	O
/	O
nips	O
/	O
DentonCSF15	O
,	O
DBLP	O
:	O
journals	O
/	O
corr	O
	
/	O
RadfordMC15	O
can	O
consistently	O
generate	O
sharp	O
and	O
realistically	O
looking	O
samples	O
DBLP	O
:	O
journals	O
/	O
corr	O
	
/	O
LarsenSW15	O
.	O
	
However	O
,	O
metrics	O
that	O
measure	O
the	O
diversity	O
in	O
the	O
generated	O
samples	O
are	O
currently	O
intractable	O
DBLP	O
:	O
journals	O
/	O
corr	O
	
/	O
TheisOB15	O
,	O
gregor2016towards	O
,	O
im2016generating	O
.	O
	
Additionally	O
,	O
instability	O
in	O
their	O
training	O
process	O
DBLP	O
:	O
journals	O
/	O
corr	O
/	O
RadfordMC15	O
requires	O
careful	O
hyperparameter	B-Method
tuning	I-Method
to	O
avoid	O
diverging	O
behavior	O
.	O
	
Training	O
such	O
a	O
generative	B-Method
network	I-Method
that	O
maps	O
latent	O
variable	O
to	O
a	O
sample	O
does	O
not	O
in	O
theory	O
require	O
a	O
discriminator	B-Method
network	I-Method
as	O
in	O
GANs	B-Method
,	O
or	O
approximate	B-Method
inference	I-Method
as	O
in	O
variational	B-Method
autoencoders	I-Method
.	O
	
Indeed	O
,	O
if	O
is	O
bijective	O
,	O
it	O
can	O
be	O
trained	O
through	O
maximum	B-Method
likelihood	I-Method
using	O
the	O
change	B-Method
of	I-Method
variable	I-Method
formula	I-Method
:	O
This	O
formula	O
has	O
been	O
discussed	O
in	O
several	O
papers	O
including	O
the	O
maximum	B-Method
likelihood	I-Method
formulation	I-Method
of	O
independent	B-Method
components	I-Method
analysis	I-Method
(	O
ICA	B-Method
)	O
bell1995information	O
,	O
hyvarinen2004independent	O
,	O
gaussianization	O
NIPS1994_901	O
,	O
chen2000gaussianization	O
and	O
deep	B-Method
density	I-Method
models	I-Method
bengio1991artificial	O
,	O
rippel2013high	O
,	O
dinh2014nice	O
,	O
balle2015density	O
.	O
	
As	O
the	O
existence	O
proof	O
of	O
nonlinear	B-Method
ICA	I-Method
solutions	O
hyvarinen1999nonlinear	O
suggests	O
,	O
auto	B-Method
-	I-Method
regressive	I-Method
models	I-Method
can	O
be	O
seen	O
as	O
tractable	O
instance	O
of	O
maximum	B-Method
likelihood	I-Method
nonlinear	I-Method
ICA	I-Method
,	O
where	O
the	O
residual	O
corresponds	O
to	O
the	O
independent	O
components	O
.	O
	
However	O
,	O
naive	O
application	O
of	O
the	O
change	B-Method
of	I-Method
variable	I-Method
formula	I-Method
produces	O
models	O
which	O
are	O
computationally	O
expensive	O
and	O
poorly	O
conditioned	O
,	O
and	O
so	O
large	O
scale	O
models	O
of	O
this	O
type	O
have	O
not	O
entered	O
general	O
use	O
.	O
	
section	O
:	O
Model	B-Task
definition	I-Task
	
In	O
this	O
paper	O
,	O
we	O
will	O
tackle	O
the	O
problem	O
of	O
learning	B-Method
highly	I-Method
nonlinear	I-Method
models	I-Method
in	O
high	B-Task
-	I-Task
dimensional	I-Task
continuous	I-Task
spaces	I-Task
through	O
maximum	B-Method
likelihood	I-Method
.	O
	
In	O
order	O
to	O
optimize	O
the	O
log	O
-	O
likelihood	O
,	O
we	O
introduce	O
a	O
more	O
flexible	O
class	O
of	O
architectures	O
that	O
enables	O
the	O
computation	B-Task
of	I-Task
log	I-Task
-	I-Task
likelihood	I-Task
on	O
continuous	O
data	O
using	O
the	O
change	O
of	O
variable	O
formula	O
.	O
	
Building	O
on	O
our	O
previous	O
work	O
in	O
dinh2014nice	O
,	O
we	O
define	O
a	O
powerful	O
class	O
of	O
bijective	B-Method
functions	I-Method
which	O
enable	O
exact	B-Task
and	I-Task
tractable	I-Task
density	I-Task
evaluation	I-Task
and	O
exact	B-Task
and	I-Task
tractable	I-Task
inference	I-Task
.	O
	
Moreover	O
,	O
the	O
resulting	O
cost	B-Method
function	I-Method
does	O
not	O
to	O
rely	O
on	O
a	O
fixed	B-Metric
form	I-Metric
reconstruction	I-Metric
cost	I-Metric
such	O
as	O
square	B-Metric
error	I-Metric
DBLP	O
:	O
journals	O
/	O
corr	O
/	O
	
LarsenSW15	O
,	O
DBLP	O
:	O
journals	O
/	O
corr	O
/	O
RadfordMC15	O
,	O
and	O
generates	O
sharper	O
samples	O
as	O
a	O
result	O
.	O
	
Also	O
,	O
this	O
flexibility	O
helps	O
us	O
leverage	O
recent	O
advances	O
in	O
batch	B-Method
normalization	I-Method
ioffe2015batch	O
and	O
residual	B-Method
networks	I-Method
	
DBLP	O
:	O
	
journals	O
/	O
corr	O
/	O
HeZRS15	O
,	O
DBLP	O
:	O
journals	O
/	O
corr	O
/	O
HeZR016	O
to	O
define	O
a	O
very	O
deep	O
multi	B-Method
-	I-Method
scale	I-Method
architecture	I-Method
with	O
multiple	O
levels	O
of	O
abstraction	O
.	O
	
subsection	O
:	O
Change	O
of	O
variable	O
formula	O
	
Given	O
an	O
observed	O
data	O
variable	O
,	O
a	O
simple	O
prior	O
probability	O
distribution	O
on	O
a	O
latent	O
variable	O
,	O
and	O
a	O
bijection	O
(	O
with	O
)	O
,	O
the	O
change	O
of	O
variable	O
formula	O
defines	O
a	O
model	B-Method
distribution	I-Method
on	O
by	O
where	O
is	O
the	O
Jacobian	O
of	O
at	O
.	O
	
Exact	O
samples	O
from	O
the	O
resulting	O
distribution	O
can	O
be	O
generated	O
by	O
using	O
the	O
inverse	B-Method
transform	I-Method
sampling	I-Method
rule	I-Method
devroye1986sample	O
.	O
	
A	O
sample	O
is	O
drawn	O
in	O
the	O
latent	O
space	O
,	O
and	O
its	O
inverse	O
image	O
generates	O
a	O
sample	O
in	O
the	O
original	O
space	O
.	O
	
Computing	O
the	O
density	O
on	O
a	O
point	O
is	O
accomplished	O
by	O
computing	O
the	O
density	O
of	O
its	O
image	O
and	O
multiplying	O
by	O
the	O
associated	O
Jacobian	O
determinant	O
.	O
	
See	O
also	O
Figure	O
[	O
reference	O
]	O
.	O
	
Exact	O
and	O
efficient	O
inference	B-Task
enables	O
the	O
accurate	O
and	O
fast	O
evaluation	O
of	O
the	O
model	O
.	O
	
subsection	O
:	O
Coupling	O
layers	O
	
Computing	O
the	O
Jacobian	O
of	O
functions	O
with	O
high	O
-	O
dimensional	O
domain	O
and	O
codomain	O
and	O
computing	O
the	O
determinants	O
of	O
large	O
matrices	O
are	O
in	O
general	O
computationally	O
very	O
expensive	O
.	O
	
This	O
combined	O
with	O
the	O
restriction	O
to	O
bijective	O
functions	O
makes	O
Equation	O
[	O
reference	O
]	O
appear	O
impractical	O
for	O
modeling	O
arbitrary	O
distributions	O
.	O
	
As	O
shown	O
however	O
in	O
dinh2014nice	O
,	O
by	O
careful	O
design	O
of	O
the	O
function	O
,	O
a	O
bijective	B-Method
model	I-Method
can	O
be	O
learned	O
which	O
is	O
both	O
tractable	O
and	O
extremely	O
flexible	O
.	O
	
As	O
computing	O
the	O
Jacobian	O
determinant	O
of	O
the	O
transformation	O
is	O
crucial	O
to	O
effectively	O
train	O
using	O
this	O
principle	O
,	O
this	O
work	O
exploits	O
the	O
simple	O
observation	O
that	O
the	O
determinant	O
of	O
a	O
triangular	O
matrix	O
can	O
be	O
efficiently	O
computed	O
as	O
the	O
product	O
of	O
its	O
diagonal	O
terms	O
.	O
	
We	O
will	O
build	O
a	O
flexible	O
and	O
tractable	O
bijective	O
function	O
by	O
stacking	O
a	O
sequence	O
of	O
simple	O
bijections	O
.	O
	
In	O
each	O
simple	O
bijection	O
,	O
part	O
of	O
the	O
input	O
vector	O
is	O
updated	O
using	O
a	O
function	O
which	O
is	O
simple	O
to	O
invert	O
,	O
but	O
which	O
depends	O
on	O
the	O
remainder	O
of	O
the	O
input	O
vector	O
in	O
a	O
complex	O
way	O
.	O
	
We	O
refer	O
to	O
each	O
of	O
these	O
simple	O
bijections	O
as	O
an	O
affine	O
coupling	O
layer	O
.	O
	
Given	O
a	O
dimensional	O
input	O
and	O
,	O
the	O
output	O
of	O
an	O
affine	B-Method
coupling	I-Method
layer	I-Method
follows	O
the	O
equations	O
where	O
and	O
stand	O
for	O
scale	O
and	O
translation	O
,	O
and	O
are	O
functions	O
from	O
,	O
and	O
is	O
the	O
Hadamard	O
product	O
or	O
element	O
-	O
wise	O
product	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
subsection	O
:	O
Properties	O
	
The	O
Jacobian	O
of	O
this	O
transformation	O
is	O
where	O
is	O
the	O
diagonal	O
matrix	O
whose	O
diagonal	O
elements	O
correspond	O
to	O
the	O
vector	O
.	O
	
Given	O
the	O
observation	O
that	O
this	O
Jacobian	O
is	O
triangular	O
,	O
we	O
can	O
efficiently	O
compute	O
its	O
determinant	O
as	O
.	O
	
Since	O
computing	O
the	O
Jacobian	O
determinant	O
of	O
the	O
coupling	B-Method
layer	I-Method
operation	I-Method
does	O
not	O
involve	O
computing	O
the	O
Jacobian	O
of	O
or	O
,	O
those	O
functions	O
can	O
be	O
arbitrarily	O
complex	O
.	O
	
We	O
will	O
make	O
them	O
deep	B-Method
convolutional	I-Method
neural	I-Method
networks	I-Method
.	O
	
Note	O
that	O
the	O
hidden	O
layers	O
of	O
and	O
can	O
have	O
more	O
features	O
than	O
their	O
input	O
and	O
output	O
layers	O
.	O
	
Another	O
interesting	O
property	O
of	O
these	O
coupling	B-Method
layers	I-Method
in	O
the	O
context	O
of	O
defining	O
probabilistic	B-Method
models	I-Method
is	O
their	O
invertibility	B-Method
.	O
	
Indeed	O
,	O
computing	O
the	O
inverse	O
is	O
no	O
more	O
complex	O
than	O
the	O
forward	B-Method
propagation	I-Method
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
,	O
meaning	O
that	O
sampling	B-Method
is	O
as	O
efficient	O
as	O
inference	B-Task
for	O
this	O
model	O
.	O
	
Note	O
again	O
that	O
computing	O
the	O
inverse	O
of	O
the	O
coupling	O
layer	O
does	O
not	O
require	O
computing	O
the	O
inverse	O
of	O
or	O
,	O
so	O
these	O
functions	O
can	O
be	O
arbitrarily	O
complex	O
and	O
difficult	O
to	O
invert	O
.	O
	
subsection	O
:	O
Masked	B-Method
convolution	I-Method
	
Partitioning	B-Method
can	O
be	O
implemented	O
using	O
a	O
binary	O
mask	O
,	O
and	O
using	O
the	O
functional	O
form	O
for	O
,	O
We	O
use	O
two	O
partitionings	O
that	O
exploit	O
the	O
local	O
correlation	O
structure	O
of	O
images	O
:	O
spatial	O
checkerboard	O
patterns	O
,	O
and	O
channel	B-Method
-	I-Method
wise	I-Method
masking	I-Method
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
The	O
spatial	O
checkerboard	O
pattern	O
mask	O
has	O
value	O
where	O
the	O
sum	O
of	O
spatial	O
coordinates	O
is	O
odd	O
,	O
and	O
otherwise	O
.	O
	
The	O
channel	O
-	O
wise	O
mask	O
is	O
for	O
the	O
first	O
half	O
of	O
the	O
channel	O
dimensions	O
and	O
for	O
the	O
second	O
half	O
.	O
	
For	O
the	O
models	O
presented	O
here	O
,	O
both	O
and	O
are	O
rectified	B-Method
convolutional	I-Method
networks	I-Method
.	O
	
subsection	O
:	O
Combining	O
coupling	O
layers	O
	
Although	O
coupling	O
layers	O
can	O
be	O
powerful	O
,	O
their	O
forward	B-Method
transformation	I-Method
leaves	O
some	O
components	O
unchanged	O
.	O
	
This	O
difficulty	O
can	O
be	O
overcome	O
by	O
composing	O
coupling	O
layers	O
in	O
an	O
alternating	O
pattern	O
,	O
such	O
that	O
the	O
components	O
that	O
are	O
left	O
unchanged	O
in	O
one	O
coupling	O
layer	O
are	O
updated	O
in	O
the	O
next	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
The	O
Jacobian	O
determinant	O
of	O
the	O
resulting	O
function	O
remains	O
tractable	O
,	O
relying	O
on	O
the	O
fact	O
that	O
Similarly	O
,	O
its	O
inverse	O
can	O
be	O
computed	O
easily	O
as	O
	
subsection	O
:	O
Multi	B-Method
-	I-Method
scale	I-Method
architecture	I-Method
	
We	O
implement	O
a	O
multi	B-Method
-	I-Method
scale	I-Method
architecture	I-Method
using	O
a	O
squeezing	B-Method
operation	I-Method
:	O
for	O
each	O
channel	O
,	O
it	O
divides	O
the	O
image	O
into	O
subsquares	O
of	O
shape	O
,	O
then	O
reshapes	O
them	O
into	O
subsquares	O
of	O
shape	O
.	O
	
The	O
squeezing	B-Method
operation	I-Method
transforms	O
an	O
tensor	O
into	O
an	O
tensor	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
,	O
effectively	O
trading	O
spatial	O
size	O
for	O
number	O
of	O
channels	O
.	O
	
At	O
each	O
scale	O
,	O
we	O
combine	O
several	O
operations	O
into	O
a	O
sequence	O
:	O
we	O
first	O
apply	O
three	O
coupling	B-Method
layers	I-Method
with	O
alternating	O
checkerboard	O
masks	O
,	O
then	O
perform	O
a	O
squeezing	B-Method
operation	I-Method
,	O
and	O
finally	O
apply	O
three	O
more	O
coupling	B-Method
layers	I-Method
with	O
alternating	B-Method
channel	I-Method
-	I-Method
wise	I-Method
masking	I-Method
.	O
	
The	O
channel	B-Method
-	I-Method
wise	I-Method
masking	I-Method
is	O
chosen	O
so	O
that	O
the	O
resulting	O
partitioning	O
is	O
not	O
redundant	O
with	O
the	O
previous	O
checkerboard	O
masking	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
For	O
the	O
final	O
scale	O
,	O
we	O
only	O
apply	O
four	O
coupling	B-Method
layers	I-Method
with	O
alternating	O
checkerboard	O
masks	O
.	O
	
Propagating	O
a	O
dimensional	O
vector	O
through	O
all	O
the	O
coupling	B-Method
layers	I-Method
would	O
be	O
cumbersome	O
,	O
in	O
terms	O
of	O
computational	B-Metric
and	O
memory	B-Metric
cost	I-Metric
,	O
and	O
in	O
terms	O
of	O
the	O
number	O
of	O
parameters	O
that	O
would	O
need	O
to	O
be	O
trained	O
.	O
	
For	O
this	O
reason	O
we	O
follow	O
the	O
design	O
choice	O
of	O
simonyan2014very	O
and	O
factor	O
out	O
half	O
of	O
the	O
dimensions	O
at	O
regular	O
intervals	O
(	O
see	O
Equation	O
[	O
reference	O
]	O
)	O
.	O
	
We	O
can	O
define	O
this	O
operation	O
recursively	O
(	O
see	O
Figure	O
[	O
reference	O
]	O
)	O
,	O
In	O
our	O
experiments	O
,	O
we	O
use	O
this	O
operation	O
for	O
.	O
	
The	O
sequence	O
of	O
coupling	B-Method
-	I-Method
squeezing	I-Method
-	I-Method
coupling	I-Method
operations	I-Method
described	O
above	O
is	O
performed	O
per	O
layer	O
when	O
computing	O
(	O
Equation	O
[	O
reference	O
]	O
)	O
.	O
	
At	O
each	O
layer	O
,	O
as	O
the	O
spatial	O
resolution	O
is	O
reduced	O
,	O
the	O
number	O
of	O
hidden	O
layer	O
features	O
in	O
and	O
is	O
doubled	O
.	O
	
All	O
variables	O
which	O
have	O
been	O
factored	O
out	O
at	O
different	O
scales	O
are	O
concatenated	O
to	O
obtain	O
the	O
final	O
transformed	O
output	O
(	O
Equation	O
[	O
reference	O
]	O
)	O
.	O
	
As	O
a	O
consequence	O
,	O
the	O
model	O
must	O
Gaussianize	O
units	O
which	O
are	O
factored	O
out	O
at	O
a	O
finer	O
scale	O
(	O
in	O
an	O
earlier	O
layer	O
)	O
before	O
those	O
which	O
are	O
factored	O
out	O
at	O
a	O
coarser	O
scale	O
(	O
in	O
a	O
later	O
layer	O
)	O
.	O
	
This	O
results	O
in	O
the	O
definition	O
of	O
intermediary	O
levels	O
of	O
representation	O
salakhutdinov2009deep	O
,	O
rezende2014stochastic	O
corresponding	O
to	O
more	O
local	O
,	O
fine	O
-	O
grained	O
features	O
as	O
shown	O
in	O
Appendix	O
[	O
reference	O
]	O
.	O
	
Moreover	O
,	O
Gaussianizing	O
and	O
factoring	O
out	O
units	O
in	O
earlier	O
layers	O
has	O
the	O
practical	O
benefit	O
of	O
distributing	O
the	O
loss	O
function	O
throughout	O
the	O
network	O
,	O
following	O
the	O
philosophy	O
similar	O
to	O
guiding	O
intermediate	O
layers	O
using	O
intermediate	B-Method
classifiers	I-Method
lee2014deeply	O
.	O
	
It	O
also	O
reduces	O
significantly	O
the	O
amount	O
of	O
computation	O
and	O
memory	O
used	O
by	O
the	O
model	O
,	O
allowing	O
us	O
to	O
train	O
larger	O
models	O
.	O
	
subsection	O
:	O
Batch	B-Method
normalization	I-Method
	
To	O
further	O
improve	O
the	O
propagation	B-Task
of	I-Task
training	I-Task
signal	I-Task
,	O
we	O
use	O
deep	B-Method
residual	I-Method
networks	I-Method
DBLP	O
:	O
journals	O
/	O
corr	O
/	O
	
HeZRS15	O
,	O
DBLP	O
:	O
journals	O
/	O
corr	O
/	O
HeZR016	O
with	O
batch	B-Method
normalization	I-Method
ioffe2015batch	O
and	O
weight	B-Method
normalization	I-Method
badrinarayanan2015understanding	O
,	O
salimans2016weight	O
in	O
and	O
.	O
	
As	O
described	O
in	O
Appendix	O
[	O
reference	O
]	O
we	O
introduce	O
and	O
use	O
a	O
novel	O
variant	O
of	O
batch	B-Method
normalization	I-Method
which	O
is	O
based	O
on	O
a	O
running	B-Method
average	I-Method
over	O
recent	O
minibatches	O
,	O
and	O
is	O
thus	O
more	O
robust	O
when	O
training	O
with	O
very	O
small	O
minibatches	O
.	O
	
We	O
also	O
use	O
apply	O
batch	B-Method
normalization	I-Method
to	O
the	O
whole	O
coupling	O
layer	O
output	O
.	O
	
The	O
effects	O
of	O
batch	B-Method
normalization	I-Method
are	O
easily	O
included	O
in	O
the	O
Jacobian	B-Task
computation	I-Task
,	O
since	O
it	O
acts	O
as	O
a	O
linear	B-Method
rescaling	I-Method
on	O
each	O
dimension	O
.	O
	
That	O
is	O
,	O
given	O
the	O
estimated	O
batch	O
statistics	O
and	O
,	O
the	O
rescaling	O
function	O
has	O
a	O
Jacobian	O
determinant	O
	
This	O
form	O
of	O
batch	B-Method
normalization	I-Method
can	O
be	O
seen	O
as	O
similar	O
to	O
reward	B-Task
normalization	I-Task
in	O
deep	B-Method
reinforcement	I-Method
learning	I-Method
mnih2015human	O
,	O
van2016learning	O
.	O
	
We	O
found	O
that	O
the	O
use	O
of	O
this	O
technique	O
not	O
only	O
allowed	O
training	O
with	O
a	O
deeper	O
stack	O
of	O
coupling	O
layers	O
,	O
but	O
also	O
alleviated	O
the	O
instability	B-Task
problem	I-Task
that	O
practitioners	O
often	O
encounter	O
when	O
training	O
conditional	O
distributions	O
with	O
a	O
scale	O
parameter	O
through	O
a	O
gradient	B-Method
-	I-Method
based	I-Method
approach	I-Method
.	O
	
section	O
:	O
Experiments	O
	
subsection	O
:	O
Procedure	O
	
The	O
algorithm	O
described	O
in	O
Equation	O
[	O
reference	O
]	O
shows	O
how	O
to	O
learn	O
distributions	O
on	O
unbounded	O
space	O
.	O
	
In	O
general	O
,	O
the	O
data	O
of	O
interest	O
have	O
bounded	O
magnitude	O
.	O
	
For	O
examples	O
,	O
the	O
pixel	O
values	O
of	O
an	O
image	O
typically	O
lie	O
in	O
after	O
application	O
of	O
the	O
recommended	O
jittering	B-Method
procedure	I-Method
uria2013rnade	O
,	O
DBLP	O
:	O
journals	O
/	O
corr	O
/	O
TheisOB15	O
.	O
	
In	O
order	O
to	O
reduce	O
the	O
impact	O
of	O
boundary	O
effects	O
,	O
we	O
instead	O
model	O
the	O
density	O
of	O
,	O
where	O
is	O
picked	O
here	O
as	O
.	O
	
We	O
take	O
into	O
account	O
this	O
transformation	O
when	O
computing	O
log	O
-	O
likelihood	O
and	O
bits	O
per	O
dimension	O
.	O
	
We	O
also	O
augment	O
the	O
CIFAR	B-Material
-	I-Material
10	I-Material
,	O
CelebA	O
and	O
LSUN	O
datasets	O
during	O
training	O
to	O
also	O
include	O
horizontal	O
flips	O
of	O
the	O
training	O
examples	O
.	O
	
We	O
train	O
our	O
model	O
on	O
four	O
natural	O
image	O
datasets	O
:	O
CIFAR	B-Material
-	I-Material
10	I-Material
krizhevsky2009learning	O
,	O
Imagenet	O
russakovsky2015imagenet	O
,	O
Large	B-Task
-	I-Task
scale	I-Task
Scene	I-Task
Understanding	I-Task
	
(	O
LSUN	O
)	O
yu2015construction	O
,	O
CelebFaces	O
Attributes	O
(	O
CelebA	O
)	O
liu2015faceattributes	O
.	O
	
More	O
specifically	O
,	O
we	O
train	O
on	O
the	O
downsampled	O
to	O
and	O
versions	O
of	O
Imagenet	O
oord2016pixel	O
.	O
	
For	O
the	O
LSUN	O
dataset	O
,	O
we	O
train	O
on	O
the	O
bedroom	O
,	O
tower	O
and	O
church	O
outdoor	O
categories	O
.	O
	
The	O
procedure	O
for	O
LSUN	O
is	O
the	O
same	O
as	O
in	O
DBLP	O
:	O
	
journals	O
/	O
corr	O
/	O
RadfordMC15	O
	
:	O
we	O
downsample	O
the	O
image	O
so	O
that	O
the	O
smallest	O
side	O
is	O
pixels	O
and	O
take	O
random	O
crops	O
of	O
.	O
	
For	O
CelebA	O
,	O
we	O
use	O
the	O
same	O
procedure	O
as	O
in	O
DBLP	O
:	O
journals	O
/	O
corr	O
/	O
LarsenSW15	O
:	O
we	O
take	O
an	O
approximately	O
central	O
crop	O
of	O
then	O
resize	O
it	O
to	O
.	O
	
We	O
use	O
the	O
multi	B-Method
-	I-Method
scale	I-Method
architecture	I-Method
described	O
in	O
Section	O
[	O
reference	O
]	O
and	O
use	O
deep	B-Method
convolutional	I-Method
residual	I-Method
networks	I-Method
in	O
the	O
coupling	O
layers	O
with	O
rectifier	O
nonlinearity	O
and	O
skip	O
-	O
connections	O
as	O
suggested	O
by	O
oord2016pixel	O
.	O
	
To	O
compute	O
the	O
scaling	O
functions	O
,	O
we	O
use	O
a	O
hyperbolic	B-Method
tangent	I-Method
function	I-Method
multiplied	O
by	O
a	O
learned	O
scale	O
,	O
whereas	O
the	O
translation	O
function	O
has	O
an	O
affine	O
output	O
.	O
	
Our	O
multi	B-Method
-	I-Method
scale	I-Method
architecture	I-Method
is	O
repeated	O
recursively	O
until	O
the	O
input	O
of	O
the	O
last	O
recursion	O
is	O
a	O
tensor	O
.	O
	
For	O
datasets	O
of	O
images	O
of	O
size	O
,	O
we	O
use	O
residual	O
blocks	O
with	O
hidden	O
feature	O
maps	O
for	O
the	O
first	O
coupling	B-Method
layers	I-Method
with	O
checkerboard	O
masking	O
.	O
	
Only	O
residual	O
blocks	O
are	O
used	O
for	O
images	O
of	O
size	O
.	O
	
We	O
use	O
a	O
batch	O
size	O
of	O
.	O
	
For	O
CIFAR	B-Material
-	I-Material
10	I-Material
,	O
we	O
use	O
residual	O
blocks	O
,	O
feature	O
maps	O
,	O
and	O
downscale	O
only	O
once	O
.	O
	
We	O
optimize	O
with	O
ADAM	O
kingma2014adam	O
with	O
default	O
hyperparameters	O
and	O
use	O
an	O
regularization	B-Method
on	O
the	O
weight	O
scale	O
parameters	O
with	O
coefficient	O
.	O
	
We	O
set	O
the	O
prior	O
to	O
be	O
an	O
isotropic	B-Method
unit	I-Method
norm	I-Method
Gaussian	I-Method
.	O
	
However	O
,	O
any	O
distribution	O
could	O
be	O
used	O
for	O
,	O
including	O
distributions	O
that	O
are	O
also	O
learned	O
during	O
training	O
,	O
such	O
as	O
from	O
an	O
auto	B-Method
-	I-Method
regressive	I-Method
model	I-Method
,	O
or	O
(	O
with	O
slight	O
modifications	O
to	O
the	O
training	O
objective	O
)	O
a	O
variational	B-Method
autoencoder	I-Method
.	O
	
subsection	O
:	O
Results	O
	
We	O
show	O
in	O
Table	O
[	O
reference	O
]	O
that	O
the	O
number	O
of	O
bits	O
per	O
dimension	O
,	O
while	O
not	O
improving	O
over	O
the	O
Pixel	B-Method
RNN	I-Method
oord2016pixel	O
baseline	O
,	O
is	O
competitive	O
with	O
other	O
generative	B-Method
methods	I-Method
.	O
	
As	O
we	O
notice	O
that	O
our	O
performance	O
increases	O
with	O
the	O
number	O
of	O
parameters	O
,	O
larger	O
models	O
are	O
likely	O
to	O
further	O
improve	O
performance	O
.	O
	
For	O
CelebA	O
and	O
LSUN	O
,	O
the	O
bits	O
per	O
dimension	O
for	O
the	O
validation	O
set	O
was	O
decreasing	O
throughout	O
training	O
,	O
so	O
little	O
overfitting	O
is	O
expected	O
.	O
	
We	O
show	O
in	O
Figure	O
[	O
reference	O
]	O
samples	O
generated	O
from	O
the	O
model	O
with	O
training	O
examples	O
from	O
the	O
dataset	O
for	O
comparison	O
.	O
	
As	O
mentioned	O
in	O
DBLP	O
:	O
journals	O
/	O
corr	O
/	O
	
TheisOB15	O
,	O
gregor2016towards	O
,	O
maximum	B-Method
likelihood	I-Method
is	O
a	O
principle	O
that	O
values	O
diversity	O
over	O
sample	B-Metric
quality	I-Metric
in	O
a	O
limited	B-Task
capacity	I-Task
setting	I-Task
.	O
	
As	O
a	O
result	O
,	O
our	O
model	O
outputs	O
sometimes	O
highly	O
improbable	O
samples	O
as	O
we	O
can	O
notice	O
especially	O
on	O
CelebA.	O
As	O
opposed	O
to	O
variational	B-Method
autoencoders	I-Method
,	O
the	O
samples	O
generated	O
from	O
our	O
model	O
look	O
not	O
only	O
globally	O
coherent	O
but	O
also	O
sharp	O
.	O
	
Our	O
hypothesis	O
is	O
that	O
as	O
opposed	O
to	O
these	O
models	O
,	O
real	B-Method
NVP	I-Method
does	O
not	O
rely	O
on	O
fixed	O
form	O
reconstruction	O
cost	O
like	O
an	O
norm	O
which	O
tends	O
to	O
reward	O
capturing	O
low	O
frequency	O
components	O
more	O
heavily	O
than	O
high	O
frequency	O
components	O
.	O
	
Unlike	O
autoregressive	B-Method
models	I-Method
,	O
sampling	O
from	O
our	O
model	O
is	O
done	O
very	O
efficiently	O
as	O
it	O
is	O
parallelized	O
over	O
input	O
dimensions	O
.	O
	
On	O
Imagenet	O
and	O
LSUN	O
,	O
our	O
model	O
seems	O
to	O
have	O
captured	O
well	O
the	O
notion	O
of	O
background	O
/	O
foreground	O
and	O
lighting	O
interactions	O
such	O
as	O
luminosity	O
and	O
consistent	O
light	O
source	O
direction	O
for	O
reflectance	O
and	O
shadows	O
.	O
	
We	O
also	O
illustrate	O
the	O
smooth	O
semantically	O
consistent	O
meaning	O
of	O
our	O
latent	O
variables	O
.	O
	
In	O
the	O
latent	O
space	O
,	O
we	O
define	O
a	O
manifold	O
based	O
on	O
four	O
validation	O
examples	O
,	O
,	O
,	O
,	O
and	O
parametrized	O
by	O
two	O
parameters	O
and	O
by	O
,	O
We	O
project	O
the	O
resulting	O
manifold	O
back	O
into	O
the	O
data	O
space	O
by	O
computing	O
.	O
	
Results	O
are	O
shown	O
Figure	O
[	O
reference	O
]	O
.	O
	
We	O
observe	O
that	O
the	O
model	O
seems	O
to	O
have	O
organized	O
the	O
latent	O
space	O
with	O
a	O
notion	O
of	O
meaning	O
that	O
goes	O
well	O
beyond	O
pixel	B-Method
space	I-Method
interpolation	I-Method
.	O
	
More	O
visualization	O
are	O
shown	O
in	O
the	O
Appendix	O
.	O
	
To	O
further	O
test	O
whether	O
the	O
latent	O
space	O
has	O
a	O
consistent	O
semantic	O
interpretation	O
,	O
we	O
trained	O
a	O
class	B-Method
-	I-Method
conditional	I-Method
model	I-Method
on	O
CelebA	O
,	O
and	O
found	O
that	O
the	O
learned	O
representation	O
had	O
a	O
consistent	O
semantic	O
meaning	O
across	O
class	O
labels	O
(	O
see	O
Appendix	O
[	O
reference	O
]	O
)	O
.	O
	
section	O
:	O
Discussion	O
and	O
conclusion	O
	
In	O
this	O
paper	O
,	O
we	O
have	O
defined	O
a	O
class	O
of	O
invertible	B-Method
functions	I-Method
with	O
tractable	O
Jacobian	O
determinant	O
,	O
enabling	O
exact	B-Task
and	I-Task
tractable	I-Task
log	I-Task
-	I-Task
likelihood	I-Task
evaluation	I-Task
,	O
inference	B-Task
,	O
and	O
sampling	B-Task
.	O
	
We	O
have	O
shown	O
that	O
this	O
class	O
of	O
generative	B-Method
model	I-Method
achieves	O
competitive	O
performances	O
,	O
both	O
in	O
terms	O
of	O
sample	B-Metric
quality	I-Metric
and	O
log	B-Metric
-	I-Metric
likelihood	I-Metric
.	O
	
Many	O
avenues	O
exist	O
to	O
further	O
improve	O
the	O
functional	O
form	O
of	O
the	O
transformations	O
,	O
for	O
instance	O
by	O
exploiting	O
the	O
latest	O
advances	O
in	O
dilated	B-Method
convolutions	I-Method
yu2015multi	O
and	O
residual	B-Method
networks	I-Method
architectures	I-Method
DBLP	O
:	O
journals	O
/	O
corr	O
/	O
TargAL16	O
.	O
	
This	O
paper	O
presented	O
a	O
technique	O
bridging	O
the	O
gap	O
between	O
auto	B-Method
-	I-Method
regressive	I-Method
models	I-Method
,	O
variational	B-Method
autoencoders	I-Method
,	O
and	O
generative	B-Method
adversarial	I-Method
networks	I-Method
.	O
	
Like	O
auto	B-Method
-	I-Method
regressive	I-Method
models	I-Method
,	O
it	O
allows	O
tractable	O
and	O
exact	O
log	B-Task
-	I-Task
likelihood	I-Task
evaluation	I-Task
for	O
training	B-Task
.	O
	
It	O
allows	O
however	O
a	O
much	O
more	O
flexible	O
functional	O
form	O
,	O
similar	O
to	O
that	O
in	O
the	O
generative	B-Method
model	I-Method
of	I-Method
variational	I-Method
autoencoders	I-Method
.	O
	
This	O
allows	O
for	O
fast	O
and	O
exact	O
sampling	O
from	O
the	O
model	B-Method
distribution	I-Method
.	O
	
Like	O
GANs	B-Method
,	O
and	O
unlike	O
variational	B-Method
autoencoders	I-Method
,	O
our	O
technique	O
does	O
not	O
require	O
the	O
use	O
of	O
a	O
fixed	O
form	O
reconstruction	O
cost	O
,	O
and	O
instead	O
defines	O
a	O
cost	O
in	O
terms	O
of	O
higher	O
level	O
features	O
,	O
generating	O
sharper	O
images	O
.	O
	
Finally	O
,	O
unlike	O
both	O
variational	B-Method
autoencoders	I-Method
and	O
GANs	B-Method
,	O
our	O
technique	O
is	O
able	O
to	O
learn	O
a	O
semantically	O
meaningful	O
latent	O
space	O
which	O
is	O
as	O
high	O
dimensional	O
as	O
the	O
input	O
space	O
.	O
	
This	O
may	O
make	O
the	O
algorithm	O
particularly	O
well	O
suited	O
to	O
semi	B-Task
-	I-Task
supervised	I-Task
learning	I-Task
tasks	I-Task
,	O
as	O
we	O
hope	O
to	O
explore	O
in	O
future	O
work	O
.	O
	
Real	B-Method
NVP	I-Method
generative	I-Method
models	I-Method
can	O
additionally	O
be	O
conditioned	O
on	O
additional	O
variables	O
(	O
for	O
instance	O
class	O
labels	O
)	O
to	O
create	O
a	O
structured	B-Method
output	I-Method
algorithm	I-Method
.	O
	
More	O
so	O
,	O
as	O
the	O
resulting	O
class	O
of	O
invertible	O
transformations	O
can	O
be	O
treated	O
as	O
a	O
probability	O
distribution	O
in	O
a	O
modular	O
way	O
,	O
it	O
can	O
also	O
be	O
used	O
to	O
improve	O
upon	O
other	O
probabilistic	B-Method
models	I-Method
like	O
auto	B-Method
-	I-Method
regressive	I-Method
models	I-Method
and	O
variational	B-Method
autoencoders	I-Method
.	O
	
For	O
variational	B-Method
autoencoders	I-Method
,	O
these	O
transformations	O
could	O
be	O
used	O
both	O
to	O
enable	O
a	O
more	O
flexible	O
reconstruction	B-Metric
cost	I-Metric
DBLP	I-Metric
:	O
journals	O
/	O
corr	O
	
/	O
LarsenSW15	O
and	O
a	O
more	O
flexible	O
stochastic	B-Method
inference	I-Method
distribution	I-Method
rezende2015variational	O
.	O
	
Probabilistic	B-Method
models	I-Method
in	O
general	O
can	O
also	O
benefit	O
from	O
batch	B-Method
normalization	I-Method
techniques	I-Method
as	O
applied	O
in	O
this	O
paper	O
.	O
	
The	O
definition	O
of	O
powerful	O
and	O
trainable	O
invertible	B-Method
functions	I-Method
can	O
also	O
benefit	O
domains	O
other	O
than	O
generative	B-Method
unsupervised	I-Method
learning	I-Method
.	O
	
For	O
example	O
,	O
in	O
reinforcement	B-Task
learning	I-Task
,	O
these	O
invertible	O
functions	O
can	O
help	O
extend	O
the	O
set	O
of	O
functions	O
for	O
which	O
an	O
operation	O
is	O
tractable	O
for	O
continuous	B-Task
Q	I-Task
-	I-Task
learning	I-Task
gu2016continuous	O
or	O
find	O
representation	O
where	O
local	B-Method
linear	I-Method
Gaussian	I-Method
approximations	I-Method
are	O
more	O
appropriate	O
watter2015embed	O
.	O
	
section	O
:	O
Acknowledgments	O
	
The	O
authors	O
thank	O
the	O
developers	O
of	O
Tensorflow	B-Method
abadi2016tensorflow	O
.	O
	
We	O
thank	O
Sherry	O
Moore	O
,	O
David	O
Andersen	O
and	O
Jon	O
Shlens	O
for	O
their	O
help	O
in	O
implementing	O
the	O
model	O
.	O
	
We	O
thank	O
Aäron	O
van	O
den	O
Oord	O
,	O
Yann	O
Dauphin	O
,	O
Kyle	O
Kastner	O
,	O
Chelsea	O
Finn	O
,	O
Maithra	O
Raghu	O
,	O
David	O
Warde	O
-	O
Farley	O
,	O
Daniel	O
Jiwoong	O
	
I	O
m	O
and	O
Oriol	O
Vinyals	O
for	O
fruitful	O
discussions	O
.	O
	
Finally	O
,	O
we	O
thank	O
Ben	O
Poole	O
,	O
Rafal	O
Jozefowicz	O
and	O
George	O
Dahl	O
for	O
their	O
input	O
on	O
a	O
draft	O
of	O
the	O
paper	O
.	O
	
plus	O
0.12ex	O
	
bibliography	O
:	O
References	O
	
appendix	O
:	O
Samples	O
	
appendix	O
:	O
Manifold	O
	
appendix	O
:	O
Extrapolation	B-Task
	
Inspired	O
by	O
the	O
texture	B-Task
generation	I-Task
work	O
by	O
DBLP	O
:	O
conf	O
/	O
nips	O
/	O
GatysEB15	O
,	O
theis2015generative	O
and	O
extrapolation	B-Task
test	I-Task
with	O
DCGAN	B-Method
DBLP	I-Method
:	O
journals	O
/	O
corr	O
	
/	O
RadfordMC15	O
,	O
we	O
also	O
evaluate	O
the	O
statistics	B-Metric
captured	O
by	O
our	O
model	O
by	O
generating	O
images	O
twice	O
or	O
ten	O
times	O
as	O
large	O
as	O
present	O
in	O
the	O
dataset	O
.	O
	
As	O
we	O
can	O
observe	O
in	O
the	O
following	O
figures	O
,	O
our	O
model	O
seems	O
to	O
successfully	O
create	O
a	O
“	O
texture	B-Method
”	I-Method
representation	I-Method
of	O
the	O
dataset	O
while	O
maintaining	O
a	O
spatial	O
smoothness	O
through	O
the	O
image	O
.	O
	
Our	O
convolutional	B-Method
architecture	I-Method
is	O
only	O
aware	O
of	O
the	O
position	O
of	O
considered	O
pixel	O
through	O
edge	O
effects	O
in	O
convolutions	B-Method
,	O
therefore	O
our	O
model	O
is	O
similar	O
to	O
a	O
stationary	B-Method
process	I-Method
.	O
	
This	O
also	O
explains	O
why	O
these	O
samples	O
are	O
more	O
consistent	O
in	O
LSUN	O
,	O
where	O
the	O
training	O
data	O
was	O
obtained	O
using	O
random	O
crops	O
.	O
	
appendix	O
:	O
Latent	O
variables	O
semantic	O
	
As	O
in	O
gregor2016towards	O
,	O
we	O
further	O
try	O
to	O
grasp	O
the	O
semantic	O
of	O
our	O
learned	O
layers	O
latent	O
variables	O
by	O
doing	O
ablation	B-Method
tests	I-Method
.	O
	
We	O
infer	O
the	O
latent	O
variables	O
and	O
resample	O
the	O
lowest	O
levels	O
of	O
latent	O
variables	O
from	O
a	O
standard	O
gaussian	B-Method
,	O
increasing	O
the	O
highest	O
level	O
affected	O
by	O
this	O
resampling	O
.	O
	
As	O
we	O
can	O
see	O
in	O
the	O
following	O
figures	O
,	O
the	O
semantic	O
of	O
our	O
latent	O
space	O
seems	O
to	O
be	O
more	O
on	O
a	O
graphic	O
level	O
rather	O
than	O
higher	O
level	O
concept	O
.	O
	
Although	O
the	O
heavy	O
use	O
of	O
convolution	B-Method
improves	O
learning	B-Task
by	O
exploiting	O
image	O
prior	O
knowledge	O
,	O
it	O
is	O
also	O
likely	O
to	O
be	O
responsible	O
for	O
this	O
limitation	O
.	O
	
appendix	O
:	O
Batch	B-Method
normalization	I-Method
	
We	O
further	O
experimented	O
with	O
batch	B-Method
normalization	I-Method
by	O
using	O
a	O
weighted	B-Method
average	I-Method
of	O
a	O
moving	B-Method
average	I-Method
of	I-Method
the	I-Method
layer	I-Method
statistics	I-Method
and	O
the	O
current	O
batch	O
batch	O
statistics	O
,	O
where	O
is	O
the	O
momentum	O
.	O
	
When	O
using	O
,	O
we	O
only	O
propagate	O
gradient	O
through	O
the	O
current	O
batch	O
statistics	O
.	O
	
We	O
observe	O
that	O
using	O
this	O
lag	O
helps	O
the	O
model	O
train	O
with	O
very	O
small	O
minibatches	O
.	O
	
We	O
used	O
batch	B-Method
normalization	I-Method
with	O
a	O
moving	B-Method
average	I-Method
for	O
our	O
results	O
on	O
CIFAR	B-Material
-	I-Material
10	I-Material
.	O
	
appendix	O
:	O
Attribute	O
change	O
	
Additionally	O
,	O
we	O
exploit	O
the	O
attribute	O
information	O
in	O
CelebA	O
to	O
build	O
a	O
conditional	B-Method
model	I-Method
,	O
i.e.	O
the	O
invertible	O
function	O
from	O
image	O
to	O
latent	O
variable	O
uses	O
the	O
labels	O
in	O
to	O
define	O
its	O
parameters	O
.	O
	
In	O
order	O
to	O
observe	O
the	O
information	O
stored	O
in	O
the	O
latent	O
variables	O
,	O
we	O
choose	O
to	O
encode	O
a	O
batch	O
of	O
images	O
with	O
their	O
original	O
attribute	O
and	O
decode	O
them	O
using	O
a	O
new	O
set	O
of	O
attributes	O
,	O
build	O
by	O
shuffling	O
the	O
original	O
attributes	O
inside	O
the	O
batch	O
.	O
	
We	O
obtain	O
the	O
new	O
images	O
.	O
	
We	O
observe	O
that	O
,	O
although	O
the	O
faces	O
are	O
changed	O
as	O
to	O
respect	O
the	O
new	O
attributes	O
,	O
several	O
properties	O
remain	O
unchanged	O
like	O
position	O
and	O
background	O
.	O
	
document	O
:	O
Dual	B-Method
Path	I-Method
Networks	I-Method
	
In	O
this	O
work	O
,	O
we	O
present	O
a	O
simple	O
,	O
highly	O
efficient	O
and	O
modularized	O
Dual	O
Path	O
Network	O
(	O
DPN	B-Method
)	O
for	O
image	B-Task
classification	I-Task
which	O
presents	O
a	O
new	O
topology	O
of	O
connection	O
paths	O
internally	O
.	O
	
By	O
revealing	O
the	O
equivalence	O
of	O
the	O
state	O
-	O
of	O
-	B-Method
the	I-Method
-	I-Method
art	I-Method
Residual	I-Method
Network	I-Method
(	O
ResNet	B-Method
)	O
and	O
Densely	B-Method
Convolutional	I-Method
Network	I-Method
(	O
DenseNet	B-Method
)	O
within	O
the	O
HORNN	B-Method
framework	I-Method
,	O
we	O
find	O
that	O
ResNet	B-Method
enables	O
feature	B-Task
re	I-Task
-	I-Task
usage	I-Task
while	O
DenseNet	B-Method
enables	O
new	O
features	B-Task
exploration	I-Task
which	O
are	O
both	O
important	O
for	O
learning	O
good	O
representations	B-Task
.	O
	
To	O
enjoy	O
the	O
benefits	O
from	O
both	O
path	O
topologies	O
,	O
our	O
proposed	O
Dual	B-Method
Path	I-Method
Network	I-Method
shares	O
common	O
features	O
while	O
maintaining	O
the	O
flexibility	O
to	O
explore	O
new	O
features	O
through	O
dual	B-Method
path	I-Method
architectures	I-Method
.	O
	
Extensive	O
experiments	O
on	O
three	O
benchmark	O
datasets	O
,	O
ImagNet	B-Material
-	I-Material
1k	I-Material
,	O
Places365	O
and	O
PASCAL	O
VOC	O
,	O
clearly	O
demonstrate	O
superior	O
performance	O
of	O
the	O
proposed	O
DPN	B-Method
over	O
state	O
-	O
of	O
-	O
the	O
-	O
arts	O
.	O
	
In	O
particular	O
,	O
on	O
the	O
ImagNet	B-Material
-	I-Material
1k	I-Material
dataset	O
,	O
a	O
shallow	O
DPN	B-Method
surpasses	O
the	O
best	O
ResNeXt	B-Method
-	I-Method
101	I-Method
	
(	O
d	O
)	O
with	O
26	O
%	O
smaller	O
model	B-Metric
size	I-Metric
,	O
25	O
%	O
less	O
computational	B-Metric
cost	I-Metric
and	O
8	O
%	O
lower	O
memory	B-Metric
consumption	I-Metric
,	O
and	O
	
a	O
deeper	O
DPN	B-Method
(	O
DPN	B-Method
-	I-Method
131	I-Method
)	O
further	O
pushes	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
single	B-Method
model	I-Method
performance	O
with	O
about	O
2	O
times	O
faster	O
training	B-Metric
speed	I-Metric
.	O
	
Experiments	O
on	O
the	O
Places365	O
large	O
-	O
scale	O
scene	O
dataset	O
,	O
PASCAL	O
VOC	O
detection	O
dataset	O
,	O
and	O
PASCAL	O
VOC	O
segmentation	O
dataset	O
also	O
demonstrate	O
its	O
consistently	O
better	O
performance	O
than	O
DenseNet	B-Method
,	O
ResNet	B-Method
and	O
the	O
latest	O
ResNeXt	B-Method
model	I-Method
over	O
various	O
applications	O
.	O
	
figs	O
/	O
	
section	O
:	O
Introduction	O
	
‘	O
	
‘	O
Network	B-Method
engineering	I-Method
’	O
’	O
is	O
increasingly	O
more	O
important	O
for	O
visual	B-Task
recognition	I-Task
research	I-Task
.	O
	
In	O
this	O
paper	O
,	O
we	O
aim	O
to	O
develop	O
new	O
path	B-Method
topology	I-Method
of	I-Method
deep	I-Method
architectures	I-Method
to	O
further	O
push	O
the	O
frontier	O
of	O
representation	B-Task
learning	I-Task
.	O
	
In	O
particular	O
,	O
we	O
focus	O
on	O
analyzing	O
and	O
reforming	O
the	O
skip	O
connection	O
,	O
which	O
has	O
been	O
widely	O
used	O
in	O
designing	O
modern	O
deep	B-Method
neural	I-Method
networks	I-Method
and	O
offers	O
remarkable	O
success	O
in	O
many	O
applications	O
.	O
	
Skip	B-Method
connection	I-Method
creates	O
a	O
path	O
propagating	O
information	O
from	O
a	O
lower	O
layer	O
directly	O
to	O
a	O
higher	O
layer	O
.	O
	
During	O
the	O
forward	B-Method
propagation	I-Method
,	O
skip	O
connection	O
enables	O
a	O
very	O
top	O
layer	O
to	O
access	O
information	O
from	O
a	O
distant	O
bottom	O
layer	O
;	O
while	O
for	O
the	O
backward	B-Method
propagation	I-Method
,	O
it	O
facilitates	O
gradient	B-Method
back	I-Method
-	I-Method
propagation	I-Method
to	O
the	O
bottom	O
layer	O
without	O
diminishing	O
magnitude	O
,	O
which	O
effectively	O
alleviates	O
the	O
gradient	B-Task
vanishing	I-Task
problem	I-Task
and	O
eases	O
the	O
optimization	B-Task
.	O
	
Deep	B-Method
Residual	I-Method
Network	I-Method
(	O
ResNet	B-Method
)	O
is	O
one	O
of	O
the	O
first	O
works	O
that	O
successfully	O
adopt	O
skip	O
connections	O
,	O
where	O
each	O
mirco	O
-	O
block	O
,	O
a.k.a	O
.	O
residual	O
function	O
,	O
is	O
associated	O
with	O
a	O
skip	O
connection	O
,	O
called	O
residual	O
path	O
.	O
	
The	O
residual	O
path	O
element	O
-	O
wisely	O
adds	O
the	O
input	O
features	O
to	O
the	O
output	O
of	O
the	O
same	O
mirco	O
-	O
block	O
,	O
making	O
it	O
a	O
residual	B-Method
unit	I-Method
.	O
	
Depending	O
on	O
the	O
inner	B-Method
structure	I-Method
design	I-Method
of	O
the	O
mirco	B-Method
-	I-Method
block	I-Method
,	O
the	O
residual	B-Method
network	I-Method
has	O
developed	O
into	O
a	O
family	O
of	O
various	O
architectures	O
,	O
including	O
WRN	B-Method
,	O
Inception	B-Method
-	I-Method
resnet	I-Method
,	O
and	O
ResNeXt	B-Method
.	O
	
More	O
recently	O
,	O
proposed	O
a	O
different	O
network	B-Method
architecture	I-Method
that	O
achieves	O
comparable	O
accuracy	B-Metric
with	O
deep	B-Method
ResNet	I-Method
,	O
named	O
Dense	B-Method
Convolutional	I-Method
Network	I-Method
(	O
DenseNet	B-Method
)	O
.	O
	
Different	O
from	O
residual	B-Method
networks	I-Method
which	O
add	O
the	O
input	O
features	O
to	O
the	O
output	O
features	O
through	O
the	O
residual	O
path	O
,	O
the	O
DenseNet	B-Method
uses	O
a	O
densely	O
connected	O
path	O
to	O
concatenate	O
the	O
input	O
features	O
with	O
the	O
output	O
features	O
,	O
enabling	O
each	O
micro	O
-	O
block	O
to	O
receive	O
raw	O
information	O
from	O
all	O
previous	O
micro	O
-	O
blocks	O
.	O
	
Similar	O
with	O
residual	O
network	O
family	O
,	O
DenseNet	B-Method
can	O
be	O
categorized	O
to	O
the	O
densely	O
connected	O
network	O
family	O
.	O
	
Although	O
the	O
width	O
of	O
the	O
densely	O
connected	O
path	O
increases	O
linearly	O
as	O
it	O
goes	O
deeper	O
,	O
causing	O
the	O
number	O
of	O
parameters	O
to	O
grow	O
quadratically	O
,	O
DenseNet	B-Method
provides	O
higher	O
parameter	B-Metric
efficiency	I-Metric
compared	O
with	O
the	O
ResNet	B-Method
.	O
	
In	O
this	O
work	O
,	O
we	O
aim	O
to	O
study	O
the	O
advantages	O
and	O
limitations	O
of	O
both	O
topologies	O
and	O
further	O
enrich	O
the	O
path	B-Method
design	I-Method
by	O
proposing	O
a	O
dual	B-Method
path	I-Method
architecture	I-Method
.	O
	
In	O
particular	O
,	O
we	O
first	O
provide	O
a	O
new	O
understanding	O
of	O
the	O
densely	B-Method
connected	I-Method
networks	I-Method
from	O
the	O
lens	O
of	O
a	O
higher	B-Method
order	I-Method
recurrent	I-Method
neural	I-Method
network	I-Method
(	O
HORNN	B-Method
)	O
,	O
and	O
explore	O
the	O
relations	O
between	O
densely	B-Method
connected	I-Method
networks	I-Method
and	O
residual	B-Method
networks	I-Method
.	O
	
More	O
specifically	O
,	O
we	O
bridge	O
the	O
densely	B-Method
connected	I-Method
networks	I-Method
with	O
the	O
HORNNs	B-Method
,	O
showing	O
that	O
the	O
densely	B-Method
connected	I-Method
networks	I-Method
are	O
HORNNs	O
when	O
the	O
weights	O
are	O
shared	O
across	O
steps	O
.	O
	
Inspired	O
by	O
which	O
demonstrates	O
the	O
relations	O
between	O
the	O
residual	B-Method
networks	I-Method
and	O
RNNs	B-Method
,	O
we	O
prove	O
that	O
the	O
residual	B-Method
networks	I-Method
are	O
densely	B-Method
connected	I-Method
networks	I-Method
when	O
connections	O
are	O
shared	O
across	O
layers	O
.	O
	
With	O
this	O
unified	O
view	O
on	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
deep	B-Method
architecture	I-Method
,	O
we	O
find	O
that	O
the	O
deep	B-Method
residual	I-Method
networks	I-Method
implicitly	O
reuse	O
the	O
features	O
through	O
the	O
residual	O
path	O
,	O
while	O
densely	B-Method
connected	I-Method
networks	I-Method
keep	O
exploring	O
new	O
features	O
through	O
the	O
densely	O
connected	O
path	O
.	O
	
Based	O
on	O
this	O
new	O
view	O
,	O
we	O
propose	O
a	O
novel	O
dual	B-Method
path	I-Method
architecture	I-Method
,	O
called	O
the	O
Dual	B-Method
Path	I-Method
Network	I-Method
(	O
DPN	B-Method
)	O
.	O
	
This	O
new	O
architecture	O
inherits	O
both	O
advantages	O
of	O
residual	O
and	O
densely	O
connected	O
paths	O
,	O
enabling	O
effective	O
feature	B-Task
re	I-Task
-	I-Task
usage	I-Task
and	O
re	B-Task
-	I-Task
exploitation	I-Task
.	O
	
The	O
proposed	O
DPN	B-Method
also	O
enjoys	O
higher	O
parameter	B-Metric
efficiency	I-Metric
,	O
lower	O
computational	B-Metric
cost	I-Metric
and	O
lower	O
memory	B-Metric
consumption	I-Metric
,	O
and	O
being	O
friendly	O
for	O
optimization	B-Task
compared	O
with	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
classification	B-Method
networks	I-Method
.	O
	
Experimental	O
results	O
validate	O
the	O
outstanding	O
high	O
accuracy	B-Metric
of	O
DPN	B-Method
compared	O
with	O
other	O
well	O
-	O
established	O
baselines	O
for	O
image	B-Task
classification	I-Task
on	O
both	O
ImageNet	B-Material
-	I-Material
1k	I-Material
dataset	I-Material
and	O
Places365	O
-	O
Standard	O
dataset	O
.	O
	
Additional	O
experiments	O
on	O
object	B-Task
detection	I-Task
task	I-Task
and	O
semantic	B-Task
segmentation	I-Task
task	I-Task
also	O
demonstrate	O
that	O
the	O
proposed	O
dual	B-Method
path	I-Method
architecture	I-Method
can	O
be	O
broadly	O
applied	O
for	O
various	O
tasks	O
and	O
consistently	O
achieve	O
the	O
best	O
performance	O
.	O
	
section	O
:	O
Related	O
work	O
	
Designing	O
an	O
advanced	O
neural	B-Method
network	I-Method
architecture	I-Method
is	O
one	O
of	O
the	O
most	O
challenging	O
but	O
effective	O
ways	O
for	O
improving	O
the	O
image	B-Task
classification	I-Task
performance	O
,	O
which	O
can	O
also	O
directly	O
benefit	O
a	O
variety	O
of	O
other	O
tasks	O
.	O
	
AlexNet	B-Method
and	O
VGG	B-Method
are	O
two	O
most	O
important	O
works	O
that	O
show	O
the	O
power	O
of	O
deep	B-Method
convolutional	I-Method
neural	I-Method
networks	I-Method
.	O
	
They	O
demonstrate	O
that	O
building	O
deeper	B-Method
networks	I-Method
with	O
tiny	B-Method
convolutional	I-Method
kernels	I-Method
is	O
a	O
promising	O
way	O
to	O
increase	O
the	O
learning	B-Metric
capacity	I-Metric
of	O
the	O
neural	B-Method
network	I-Method
.	O
	
Residual	B-Method
Network	I-Method
was	O
first	O
proposed	O
by	O
,	O
which	O
greatly	O
alleviates	O
the	O
optimization	B-Metric
difficulty	I-Metric
and	O
further	O
pushes	O
the	O
depth	O
of	O
deep	B-Method
neural	I-Method
networks	I-Method
to	O
hundreds	O
of	O
layers	O
by	O
using	O
skipping	O
connections	O
.	O
	
Since	O
then	O
,	O
different	O
kinds	O
of	O
residual	B-Method
networks	I-Method
arose	O
,	O
concentrating	O
on	O
either	O
building	O
a	O
more	O
efficient	O
micro	O
-	O
block	O
inner	O
structure	O
or	O
exploring	O
how	O
to	O
use	O
residual	O
connections	O
.	O
	
Recently	O
,	O
proposed	O
a	O
different	O
network	O
,	O
called	O
Dense	B-Method
Convolutional	I-Method
Networks	I-Method
,	O
where	O
skip	O
connections	O
are	O
used	O
to	O
concatenate	O
the	O
input	O
to	O
the	O
output	O
instead	O
of	O
adding	O
.	O
	
However	O
,	O
the	O
width	O
of	O
the	O
densely	O
connected	O
path	O
linearly	O
increases	O
as	O
the	O
depth	O
rises	O
,	O
causing	O
the	O
number	O
of	O
parameters	O
to	O
grow	O
quadratically	O
and	O
costing	O
a	O
large	O
amount	O
of	O
GPU	O
memory	O
compared	O
with	O
the	O
residual	B-Method
networks	I-Method
if	O
the	O
implementation	O
is	O
not	O
specifically	O
optimized	O
.	O
	
This	O
limits	O
the	O
building	O
of	O
a	O
deeper	O
and	O
wider	O
densenet	O
that	O
may	O
further	O
improve	O
the	O
accuracy	B-Metric
.	O
	
Besides	O
designing	O
new	O
architectures	O
,	O
researchers	O
also	O
try	O
to	O
re	O
-	O
explore	O
the	O
existing	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
architectures	O
.	O
	
In	O
,	O
the	O
authors	O
showed	O
the	O
importance	O
of	O
the	O
residual	O
path	O
on	O
alleviating	O
the	O
optimization	B-Task
difficulty	I-Task
.	O
	
In	O
,	O
the	O
residual	B-Method
networks	I-Method
are	O
bridged	O
with	O
recurrent	B-Method
neural	I-Method
networks	I-Method
(	O
RNNs	B-Method
)	O
,	O
which	O
helps	O
people	O
better	O
understand	O
the	O
deep	B-Method
residual	I-Method
network	I-Method
from	O
the	O
perspective	O
of	O
RNNs	B-Method
.	O
	
In	O
,	O
several	O
different	O
residual	B-Method
functions	I-Method
are	O
unified	O
,	O
trying	O
to	O
provide	O
a	O
better	O
understanding	O
of	O
designing	O
a	O
better	O
mirco	B-Method
structure	I-Method
with	O
higher	O
learning	B-Metric
capacity	I-Metric
.	O
	
But	O
still	O
,	O
for	O
the	O
densely	B-Task
connected	I-Task
networks	I-Task
,	O
in	O
addition	O
to	O
several	O
intuitive	O
explanations	O
on	O
better	O
feature	O
reusage	O
and	O
efficient	O
gradient	B-Method
flow	I-Method
introduced	O
,	O
there	O
have	O
been	O
few	O
works	O
that	O
are	O
able	O
to	O
provide	O
a	O
really	O
deeper	O
understanding	O
.	O
	
In	O
this	O
work	O
,	O
we	O
aim	O
to	O
provide	O
a	O
deeper	O
understanding	O
of	O
the	O
densely	B-Task
connected	I-Task
network	I-Task
,	O
from	O
the	O
lens	B-Method
of	I-Method
Higher	I-Method
Order	I-Method
RNN	I-Method
,	O
and	O
explain	O
how	O
the	O
residual	B-Method
networks	I-Method
are	O
in	O
indeed	O
a	O
special	O
case	O
of	O
densely	B-Method
connected	I-Method
network	I-Method
.	O
	
Based	O
on	O
these	O
analysis	O
,	O
we	O
then	O
propose	O
a	O
novel	O
Dual	B-Method
Path	I-Method
Network	I-Method
architecture	I-Method
that	O
not	O
only	O
achieves	O
higher	O
accuracy	B-Metric
,	O
but	O
also	O
enjoys	O
high	O
parameter	O
and	O
computational	B-Metric
efficiency	I-Metric
.	O
	
section	O
:	O
Revisiting	O
ResNet	O
,	O
DenseNet	B-Method
and	O
Higher	B-Method
Order	I-Method
RNN	I-Method
	
In	O
this	O
section	O
,	O
we	O
first	O
bridge	O
the	O
densely	B-Method
connected	I-Method
network	I-Method
with	O
higher	B-Method
order	I-Method
recurrent	I-Method
neural	I-Method
networks	I-Method
to	O
provide	O
a	O
new	O
understanding	O
of	O
the	O
densely	B-Method
connected	I-Method
network	I-Method
.	O
	
We	O
prove	O
that	O
residual	O
networks	O
,	O
essentially	O
belong	O
to	O
the	O
family	O
of	O
densely	O
connected	O
networks	O
except	O
their	O
connections	O
are	O
shared	O
across	O
steps	O
.	O
	
Then	O
,	O
we	O
present	O
analysis	O
on	O
strengths	O
and	O
weaknesses	O
of	O
each	O
topology	B-Method
architecture	I-Method
,	O
which	O
motivates	O
us	O
to	O
develop	O
the	O
dual	B-Method
path	I-Method
network	I-Method
architecture	I-Method
.	O
	
For	O
exploring	O
the	O
above	O
relation	O
,	O
we	O
provide	O
a	O
new	O
view	O
on	O
the	O
densely	O
connected	O
networks	O
from	O
the	O
lens	O
of	O
Higher	B-Method
Order	I-Method
RNN	I-Method
,	O
explain	O
their	O
relations	O
and	O
then	O
specialize	O
the	O
analysis	O
to	O
residual	B-Task
networks	I-Task
.	O
	
Throughout	O
the	O
paper	O
,	O
we	O
formulate	O
the	O
HORNN	B-Method
in	O
a	O
more	O
generalized	O
form	O
.	O
	
We	O
use	O
to	O
denote	O
the	O
hidden	O
state	O
of	O
the	O
recurrent	B-Method
neural	I-Method
network	I-Method
at	O
the	O
-	O
th	O
step	O
and	O
use	O
as	O
the	O
index	O
of	O
the	O
current	O
step	O
.	O
	
Let	O
denotes	O
the	O
input	O
at	O
-	O
th	O
step	O
,	O
.	O
	
For	O
each	O
step	O
,	O
refers	O
to	O
the	O
feature	B-Method
extracting	I-Method
function	I-Method
which	O
takes	O
the	O
hidden	O
state	O
as	O
input	O
and	O
outputs	O
the	O
extracted	O
information	O
.	O
	
The	O
denotes	O
a	O
transformation	B-Method
function	I-Method
that	O
transforms	O
the	O
gathered	O
information	O
to	O
current	O
hidden	O
state	O
:	O
Eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
encapsulates	O
the	O
update	O
rule	O
of	O
various	O
network	B-Method
architectures	I-Method
in	O
a	O
generalized	O
way	O
.	O
	
For	O
HORNNs	O
,	O
weights	O
are	O
shared	O
across	O
steps	O
,	O
i.e.	O
and	O
.	O
	
For	O
the	O
densely	B-Task
connected	I-Task
networks	I-Task
,	O
each	O
step	O
(	O
micro	O
-	O
block	O
)	O
has	O
its	O
own	O
parameter	O
,	O
which	O
means	O
and	O
are	O
not	O
shared	O
.	O
	
Such	O
observation	O
shows	O
that	O
the	O
densely	O
connected	O
path	O
of	O
DenseNet	B-Method
is	O
essentially	O
a	O
higher	O
order	O
path	O
which	O
is	O
able	O
to	O
extract	O
new	O
information	O
from	O
previous	O
states	O
.	O
	
Figure	O
[	O
reference	O
]	O
	
(	O
c	O
)(	O
d	O
)	O
graphically	O
shows	O
the	O
relations	O
of	O
densely	B-Method
connected	I-Method
networks	I-Method
and	O
higher	B-Method
order	I-Method
recurrent	I-Method
networks	I-Method
.	O
	
We	O
then	O
explain	O
that	O
the	O
residual	B-Method
networks	I-Method
are	O
special	O
cases	O
of	O
densely	B-Method
connected	I-Method
networks	I-Method
if	O
taking	O
.	O
	
Here	O
,	O
for	O
succinctness	O
we	O
introduce	O
to	O
denote	O
the	O
intermediate	O
results	O
and	O
let	O
.	O
	
Then	O
Eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
can	O
be	O
rewritten	O
as	O
Thus	O
,	O
by	O
substituting	O
Eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
into	O
Eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
,	O
Eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
can	O
be	O
simplified	O
as	O
where	O
.	O
	
Obviously	O
,	O
Eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
has	O
the	O
same	O
form	O
as	O
the	O
residual	B-Method
network	I-Method
and	O
the	O
recurrent	B-Method
neural	I-Method
network	I-Method
.	O
	
Specifically	O
,	O
when	O
,	O
Eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
degenerates	O
to	O
an	O
RNN	B-Method
;	O
when	O
none	O
of	O
is	O
shared	O
and	O
,	O
Eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
produces	O
a	O
residual	B-Method
network	I-Method
.	O
	
Figure	O
[	O
reference	O
]	O
	
(	O
a	O
)(	O
b	O
)	O
graphically	O
shows	O
the	O
relation	O
.	O
	
Besides	O
,	O
recall	O
that	O
Eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
is	O
derived	O
under	O
the	O
condition	O
when	O
from	O
Eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
and	O
the	O
densely	O
connected	O
networks	O
are	O
in	O
forms	O
of	O
Eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
,	O
meaning	O
that	O
the	O
residual	O
network	O
family	O
essentially	O
belongs	O
to	O
the	O
densely	O
connected	O
network	O
family	O
.	O
	
Figure	O
[	O
reference	O
]	O
(	O
a	O
–	O
c	O
)	O
give	O
an	O
example	O
and	O
demonstrate	O
such	O
equivalence	O
,	O
where	O
corresponds	O
to	O
the	O
first	O
convolutional	B-Method
layer	I-Method
and	O
the	O
corresponds	O
to	O
the	O
other	O
layers	O
within	O
a	O
micro	O
-	O
block	O
in	O
Figure	O
[	O
reference	O
]	O
(	O
b	O
)	O
.	O
	
From	O
the	O
above	O
analysis	O
,	O
we	O
observe	O
:	O
1	O
)	O
both	O
residual	O
networks	O
and	O
densely	O
connected	O
networks	O
can	O
be	O
seen	O
as	O
a	O
HORNN	B-Method
when	O
and	O
are	O
shared	O
for	O
all	O
;	O
2	O
)	O
a	O
residual	B-Method
network	I-Method
is	O
a	O
densely	B-Method
connected	I-Method
network	I-Method
if	O
.	O
	
By	O
sharing	O
the	O
across	O
all	O
steps	O
,	O
receives	O
the	O
same	O
feature	O
from	O
a	O
given	O
output	O
state	O
,	O
which	O
encourages	O
the	O
feature	O
reusage	O
and	O
thus	O
reduces	O
the	O
feature	O
redundancy	O
.	O
	
However	O
,	O
such	O
an	O
information	B-Method
sharing	I-Method
strategy	I-Method
makes	O
it	O
difficult	O
for	O
residual	B-Method
networks	I-Method
to	O
explore	O
new	O
features	O
.	O
	
Comparatively	O
,	O
the	O
densely	B-Method
connected	I-Method
networks	I-Method
are	O
able	O
to	O
explore	O
new	O
information	O
from	O
previous	O
outputs	O
since	O
the	O
is	O
not	O
shared	O
across	O
steps	O
.	O
	
However	O
,	O
different	O
may	O
extract	O
the	O
same	O
type	O
of	O
features	O
multiple	O
times	O
,	O
leading	O
to	O
high	O
redundancy	O
.	O
	
In	O
the	O
following	O
section	O
,	O
we	O
present	O
the	O
dual	B-Method
path	I-Method
networks	I-Method
which	O
can	O
overcome	O
both	O
inherent	O
limitations	O
of	O
these	O
two	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
network	B-Method
architectures	I-Method
.	O
	
Their	O
relations	O
with	O
HORNN	B-Method
also	O
imply	O
that	O
our	O
proposed	O
architecture	O
can	O
be	O
used	O
for	O
improving	O
HORNN	B-Method
,	O
which	O
we	O
leave	O
for	O
future	O
works	O
.	O
	
section	O
:	O
Dual	B-Method
Path	I-Method
Networks	I-Method
	
Above	O
we	O
explain	O
the	O
relations	O
between	O
residual	B-Method
networks	I-Method
and	O
densely	B-Method
connected	I-Method
networks	I-Method
,	O
showing	O
that	O
the	O
residual	O
path	O
implicitly	O
reuses	O
features	O
,	O
but	O
it	O
is	O
not	O
good	O
at	O
exploring	O
new	O
features	O
.	O
	
In	O
contrast	O
the	O
densely	B-Method
connected	I-Method
network	I-Method
keeps	O
exploring	O
new	O
features	O
but	O
suffers	O
from	O
higher	O
redundancy	O
.	O
	
In	O
this	O
section	O
,	O
we	O
describe	O
the	O
details	O
of	O
our	O
proposed	O
novel	O
dual	B-Method
path	I-Method
architecture	I-Method
,	O
i.e.	O
the	O
Dual	B-Method
Path	I-Method
Network	I-Method
(	O
DPN	B-Method
)	I-Method
.	O
	
In	O
the	O
following	O
,	O
we	O
first	O
introduce	O
and	O
formulate	O
the	O
dual	B-Method
path	I-Method
architecture	I-Method
,	O
and	O
then	O
present	O
the	O
network	O
structure	O
in	O
details	O
with	O
complexity	B-Task
analysis	I-Task
.	O
	
subsection	O
:	O
Dual	B-Method
Path	I-Method
Architecture	I-Method
	
Sec	O
.	O
	
[	O
reference	O
]	O
discusses	O
the	O
advantage	O
and	O
limitations	O
of	O
both	O
residual	B-Method
networks	I-Method
and	O
densely	B-Method
connected	I-Method
networks	I-Method
.	O
	
Based	O
on	O
the	O
analysis	O
,	O
we	O
propose	O
a	O
simple	O
dual	B-Method
path	I-Method
architecture	I-Method
which	O
shares	O
the	O
across	O
all	O
blocks	O
to	O
enjoy	O
the	O
benefits	O
of	O
reusing	O
common	O
features	O
with	O
low	O
redundancy	O
,	O
while	O
still	O
remaining	O
a	O
densely	O
connected	O
path	O
to	O
give	O
the	O
network	O
more	O
flexibility	O
in	O
learning	O
new	O
features	O
.	O
	
We	O
formulate	O
such	O
a	O
dual	B-Method
path	I-Method
architecture	I-Method
as	O
follows	O
:	O
where	O
and	O
denote	O
the	O
extracted	O
information	O
at	O
-	O
th	O
step	O
from	O
individual	O
path	O
,	O
is	O
a	O
feature	B-Method
learning	I-Method
function	I-Method
as	O
.	O
	
Eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
refers	O
to	O
the	O
densely	O
connected	O
path	O
that	O
enables	O
exploring	O
new	O
features	O
,	O
Eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
refers	O
to	O
the	O
residual	O
path	O
that	O
enables	O
common	O
features	O
re	O
-	O
usage	O
,	O
and	O
	
Eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
defines	O
the	O
dual	O
path	O
that	O
integrates	O
them	O
and	O
feeds	O
them	O
to	O
the	O
last	O
transformation	O
function	O
in	O
Eqn	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
	
The	O
final	O
transformation	O
function	O
generates	O
current	O
state	O
,	O
which	O
is	O
used	O
for	O
making	O
next	B-Task
mapping	I-Task
or	I-Task
prediction	I-Task
.	O
	
Figure	O
[	O
reference	O
]	O
(	O
d	O
)(	O
e	O
)	O
show	O
an	O
example	O
of	O
the	O
dual	B-Method
path	I-Method
architecture	I-Method
that	O
is	O
being	O
used	O
in	O
our	O
experiments	O
.	O
	
More	O
generally	O
,	O
the	O
proposed	O
DPN	B-Method
is	O
a	O
family	O
of	O
convolutional	B-Method
neural	I-Method
networks	I-Method
which	O
contains	O
a	O
residual	O
alike	O
path	O
and	O
a	O
densely	O
connected	O
alike	O
path	O
,	O
as	O
explained	O
later	O
.	O
	
Similar	O
to	O
these	O
networks	O
,	O
one	O
can	O
customize	O
the	O
micro	O
-	O
block	O
function	O
of	O
DPN	B-Method
for	O
task	O
-	O
specific	O
usage	O
or	O
for	O
further	O
overall	O
performance	O
boosting	B-Task
.	O
	
subsection	O
:	O
Dual	B-Method
Path	I-Method
Networks	I-Method
	
The	O
proposed	O
network	O
is	O
built	O
by	O
stacking	O
multiple	O
modualized	O
mirco	O
-	O
blocks	O
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
In	O
this	O
work	O
,	O
the	O
structure	O
of	O
each	O
micro	O
-	O
block	O
is	O
designed	O
with	O
a	O
bottleneck	B-Method
style	I-Method
which	O
starts	O
with	O
a	O
convolutional	B-Method
layer	I-Method
followed	O
by	O
a	O
convolutional	B-Method
layer	I-Method
,	O
and	O
ends	O
with	O
a	O
convolutional	B-Method
layer	I-Method
.	O
	
The	O
output	O
of	O
the	O
last	O
convolutional	B-Method
layer	I-Method
is	O
split	O
into	O
two	O
parts	O
:	O
the	O
first	O
part	O
is	O
element	O
-	O
wisely	O
added	O
to	O
the	O
residual	O
path	O
,	O
and	O
the	O
second	O
part	O
is	O
concatenated	O
with	O
the	O
densly	O
connected	O
path	O
.	O
	
To	O
enhance	O
the	O
leaning	O
capacity	O
of	O
each	O
micro	O
-	O
block	O
,	O
we	O
use	O
the	O
grouped	B-Method
convolution	I-Method
layer	I-Method
in	O
the	O
second	O
layer	O
as	O
the	O
ResNeXt	O
.	O
	
Considering	O
that	O
the	O
residual	B-Method
networks	I-Method
are	O
more	O
wildly	O
used	O
than	O
the	O
densely	O
connected	O
networks	O
in	O
practice	O
,	O
we	O
choose	O
the	O
residual	B-Method
network	I-Method
as	O
the	O
backbone	O
and	O
add	O
a	O
thin	O
densely	O
connected	O
path	O
to	O
build	O
the	O
dual	B-Method
path	I-Method
network	I-Method
.	O
	
Such	O
design	O
also	O
helps	O
slow	O
the	O
width	O
increment	O
of	O
the	O
densely	O
connected	O
path	O
and	O
the	O
cost	O
of	O
GPU	O
memory	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
detailed	O
architecture	O
settings	O
.	O
	
In	O
the	O
table	O
,	O
refers	O
to	O
the	O
number	O
of	O
groups	O
,	O
and	O
refers	O
to	O
the	O
channels	O
increment	O
for	O
the	O
densely	O
connected	O
path	O
.	O
	
For	O
the	O
new	O
proposed	O
DPNs	B-Method
,	O
we	O
use	O
to	O
indicate	O
the	O
width	O
increment	O
of	O
the	O
densely	O
connected	O
path	O
.	O
	
The	O
overall	O
design	O
of	O
DPN	B-Method
inherits	O
backbone	B-Method
architecture	I-Method
of	O
the	O
vanilla	B-Method
ResNet	I-Method
/	I-Method
ResNeXt	I-Method
,	O
making	O
it	O
very	O
easy	O
to	O
implement	O
and	O
apply	O
to	O
other	O
tasks	O
.	O
	
One	O
can	O
simply	O
implement	O
a	O
DPN	B-Method
by	O
adding	O
one	O
more	O
‘	O
‘	O
slice	O
layer	O
’	O
’	O
and	O
‘	O
‘	O
concat	B-Method
layer	I-Method
’	O
’	O
upon	O
existing	O
residual	B-Method
networks	I-Method
.	O
	
Under	O
a	O
well	O
optimized	O
deep	B-Method
learning	I-Method
platform	I-Method
,	O
none	O
of	O
these	O
newly	O
added	O
operations	O
requires	O
extra	O
computational	B-Metric
cost	I-Metric
or	O
extra	O
memory	O
consumption	O
,	O
making	O
the	O
DPNs	B-Method
highly	O
efficient	O
.	O
	
In	O
order	O
to	O
demonstrate	O
the	O
appealing	O
effectiveness	O
of	O
the	O
dual	B-Method
path	I-Method
architecture	I-Method
,	O
we	O
intentionally	O
design	O
a	O
set	O
of	O
DPNs	B-Method
with	O
a	O
considerably	O
smaller	O
model	B-Metric
size	I-Metric
and	O
less	O
FLOPs	O
compared	O
with	O
the	O
sate	O
-	O
of	O
-	O
the	O
-	O
art	O
ResNeXts	B-Method
,	O
as	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Due	O
to	O
limited	O
computational	O
resources	O
,	O
we	O
set	O
these	O
hyper	O
-	O
parameters	O
based	O
on	O
our	O
previous	O
experience	O
instead	O
of	O
grid	B-Method
search	I-Method
experiments	O
.	O
	
paragraph	O
:	O
Model	B-Metric
complexity	I-Metric
	
We	O
measure	O
the	O
model	B-Metric
complexity	I-Metric
by	O
counting	O
the	O
total	O
number	O
of	O
learnable	O
parameters	O
within	O
each	O
neural	B-Method
network	I-Method
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
results	O
for	O
different	O
models	O
.	O
	
The	O
DPN	B-Method
-	I-Method
92	I-Method
costs	O
about	O
fewer	O
parameters	O
than	O
ResNeXt	O
-	O
101	O
	
(	O
d	O
)	O
,	O
while	O
the	O
DPN	B-Method
-	I-Method
98	I-Method
costs	O
about	O
fewer	O
parameters	O
than	O
ResNeXt	O
-	O
101	O
	
(	O
d	O
)	O
.	O
	
paragraph	O
:	O
Computational	B-Metric
complexity	I-Metric
	
We	O
measure	O
the	O
computational	B-Metric
cost	I-Metric
of	O
each	O
deep	B-Method
neural	I-Method
network	I-Method
using	O
the	O
floating	O
-	O
point	O
operations	O
(	O
FLOPs	O
)	O
with	O
input	O
size	O
of	O
,	O
in	O
the	O
number	O
of	O
multiply	O
-	O
adds	O
following	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
theoretical	B-Metric
computational	I-Metric
cost	I-Metric
.	O
	
Though	O
the	O
actual	O
time	B-Metric
cost	I-Metric
might	O
be	O
influenced	O
by	O
other	O
factors	O
,	O
e.g.	O
GPU	O
bandwidth	O
and	O
coding	B-Metric
quality	I-Metric
,	O
the	O
computational	B-Metric
cost	I-Metric
shows	O
the	O
speed	B-Metric
upper	I-Metric
bound	I-Metric
.	O
	
As	O
can	O
be	O
see	O
from	O
the	O
results	O
,	O
DPN	B-Method
-	I-Method
92	I-Method
consumes	O
about	O
less	O
FLOPs	O
than	O
ResNeXt	O
-	O
101	O
	
(	O
d	O
)	O
,	O
and	O
the	O
DPN	B-Method
-	I-Method
98	I-Method
consumes	O
about	O
less	O
FLOPs	O
than	O
ResNeXt	O
-	O
101	O
	
(	O
d	O
)	O
.	O
	
section	O
:	O
Experiments	O
	
Extensive	O
experiments	O
are	O
conducted	O
for	O
evaluating	O
the	O
proposed	O
Dual	B-Method
Path	I-Method
Networks	I-Method
.	O
	
Specifically	O
,	O
we	O
evaluate	O
the	O
proposed	O
architecture	O
on	O
three	O
tasks	O
:	O
image	B-Task
classification	I-Task
,	O
object	B-Task
detection	I-Task
and	O
semantic	B-Task
segmentation	I-Task
,	O
using	O
three	O
standard	O
benchmark	O
datasets	O
:	O
the	O
ImageNet	B-Material
-	I-Material
1k	I-Material
dataset	I-Material
,	O
Places365	O
-	O
Standard	O
dataset	O
and	O
the	O
PASCAL	O
VOC	O
datasets	O
.	O
	
Key	O
properties	O
of	O
the	O
proposed	O
DPNs	B-Method
are	O
studied	O
on	O
the	O
ImageNet	B-Material
-	I-Material
1k	I-Material
object	I-Material
classification	I-Material
dataset	I-Material
and	O
further	O
verified	O
on	O
the	O
Places365	O
-	O
Standard	O
scene	O
understanding	O
dataset	O
.	O
	
To	O
verify	O
whether	O
the	O
proposed	O
DPNs	B-Method
can	O
benefit	O
other	O
tasks	O
besides	O
image	B-Task
classification	I-Task
,	O
we	O
further	O
conduct	O
experiments	O
on	O
the	O
PASCAL	O
VOC	O
dataset	O
to	O
evaluate	O
its	O
performance	O
in	O
object	B-Task
detection	I-Task
and	O
semantic	B-Task
segmentation	I-Task
.	O
	
subsection	O
:	O
Experiments	O
on	O
image	B-Task
classification	I-Task
task	O
	
We	O
implement	O
the	O
DPNs	B-Method
using	O
MXNet	B-Method
on	O
a	O
cluster	O
with	O
40	O
K80	O
graphic	O
cards	O
.	O
	
Following	O
,	O
we	O
adopt	O
standard	O
data	B-Method
augmentation	I-Method
methods	I-Method
and	O
train	O
the	O
networks	O
using	O
SGD	B-Method
with	O
a	O
mini	O
-	O
batch	O
size	O
of	O
32	O
for	O
each	O
GPU	O
.	O
	
For	O
the	O
deepest	B-Method
network	I-Method
,	O
i.e.	O
DPN	B-Method
-	I-Method
131	I-Method
,	O
the	O
mini	O
-	O
batch	O
size	O
is	O
limited	O
to	O
24	O
because	O
of	O
the	O
12	O
GB	O
GPU	O
memory	O
constraint	O
.	O
	
The	O
learning	B-Metric
rate	I-Metric
starts	O
from	O
for	O
DPN	B-Method
-	I-Method
92	I-Method
and	O
DPN	B-Method
-	I-Method
131	I-Method
,	O
and	O
from	O
for	O
DPN	B-Method
-	I-Method
98	I-Method
.	O
	
It	O
drops	O
in	O
a	O
‘	O
‘	O
steps	O
’	O
’	O
manner	O
by	O
a	O
factor	O
of	O
.	O
	
Following	O
,	O
batch	B-Method
normalization	I-Method
layers	I-Method
are	O
refined	O
after	O
training	O
.	O
	
subsubsection	O
:	O
ImageNet	B-Material
-	I-Material
1k	I-Material
dataset	I-Material
	
Firstly	O
,	O
we	O
compare	O
the	O
image	B-Task
classification	I-Task
performance	O
of	O
DPNs	B-Method
with	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
.	O
	
As	O
can	O
be	O
seen	O
from	O
the	O
first	O
block	O
in	O
Table	O
[	O
reference	O
]	O
,	O
a	O
shallow	O
DPN	B-Method
with	O
only	O
the	O
depth	O
of	O
92	O
reduces	O
the	O
top	B-Metric
-	I-Metric
1	I-Metric
error	I-Metric
rate	I-Metric
by	O
an	O
absolute	O
value	O
of	O
compared	O
with	O
the	O
ResNeXt	B-Method
-	I-Method
101	I-Method
(	O
)	O
and	O
an	O
absolute	O
value	O
of	O
compared	O
with	O
the	O
DenseNet	B-Method
-	I-Method
161	I-Method
yet	O
provides	O
with	O
considerably	O
less	O
FLOPs	O
.	O
	
In	O
the	O
second	O
block	O
of	O
Table	O
[	O
reference	O
]	O
,	O
a	O
deeper	O
DPN	B-Method
(	O
DPN	B-Method
-	I-Method
98	I-Method
)	O
surpasses	O
the	O
best	O
residual	B-Method
network	I-Method
–	O
ResNeXt	O
-	O
101	O
	
(	O
d	O
)	O
,	O
and	O
still	O
enjoys	O
less	O
FLOPs	O
and	O
a	O
much	O
smaller	O
model	B-Metric
size	I-Metric
(	O
	
236	O
MB	O
v.s	O
.	O
320	O
MB	O
)	O
.	O
	
In	O
order	O
to	O
further	O
push	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
accuracy	B-Metric
,	O
we	O
slightly	O
increase	O
the	O
depth	O
of	O
the	O
DPN	B-Method
to	O
131	O
(	O
DPN	B-Method
-	I-Method
131	I-Method
)	O
.	O
	
The	O
results	O
are	O
shown	O
in	O
the	O
last	O
block	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Again	O
,	O
the	O
DPN	B-Method
shows	O
superior	O
accuracy	B-Metric
over	O
the	O
best	O
single	O
model	O
–	O
Very	O
Deep	B-Method
PolyNet	I-Method
,	O
with	O
a	O
much	O
smaller	O
model	O
size	O
(	O
304	O
MB	O
v.s	O
.	O
365	O
MB	O
)	O
.	O
	
Note	O
that	O
the	O
Very	O
Deep	B-Method
PolyNet	I-Method
adopts	O
numerous	O
tricks	O
,	O
e.g.	O
initialization	O
by	O
insertion	O
,	O
residual	O
scaling	O
,	O
stochastic	O
paths	O
,	O
to	O
assist	O
the	O
training	B-Task
process	I-Task
.	O
	
In	O
contrast	O
,	O
our	O
proposed	O
DPN	B-Method
-	I-Method
131	I-Method
is	O
simple	O
and	O
does	O
not	O
involve	O
these	O
tricks	O
,	O
DPN	B-Method
-	I-Method
131	I-Method
can	O
be	O
trained	O
using	O
a	O
standard	O
training	B-Method
strategy	I-Method
as	O
shallow	O
DPNs	B-Method
.	O
	
More	O
importantly	O
,	O
the	O
actual	O
training	B-Metric
speed	I-Metric
of	O
DPN	B-Method
-	I-Method
131	I-Method
is	O
about	O
2	O
times	O
faster	O
than	O
the	O
Very	O
Deep	B-Method
PolyNet	I-Method
,	O
as	O
discussed	O
in	O
the	O
following	O
paragraph	O
.	O
	
Secondly	O
,	O
we	O
compare	O
the	O
training	B-Metric
cost	I-Metric
between	O
the	O
best	O
performing	O
models	O
.	O
	
Here	O
,	O
we	O
focus	O
on	O
evaluating	O
two	O
key	O
properties	O
–	O
the	O
actual	O
GPU	B-Metric
memory	I-Metric
cost	I-Metric
and	O
the	O
actual	O
training	B-Metric
speed	I-Metric
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
the	O
results	O
.	O
	
As	O
can	O
be	O
seen	O
from	O
Figure	O
[	O
reference	O
]	O
	
(	O
a	O
)(	O
b	O
)	O
	
,	O
the	O
DPN	B-Method
-	I-Method
98	I-Method
is	O
faster	O
and	O
uses	O
less	O
memory	O
than	O
the	O
best	O
performing	O
ResNeXt	B-Method
with	O
a	O
considerably	O
lower	O
testing	B-Metric
error	I-Metric
rate	I-Metric
.	O
	
Note	O
that	O
theoretically	O
the	O
computational	B-Metric
cost	I-Metric
of	O
DPN	B-Method
-	I-Method
98	I-Method
shown	O
in	O
Table	O
[	O
reference	O
]	O
is	O
less	O
than	O
the	O
best	O
performing	O
ResNeXt	B-Method
,	O
indicating	O
there	O
is	O
still	O
room	O
for	O
code	B-Task
optimization	I-Task
.	O
	
Figure	O
[	O
reference	O
]	O
(	O
c	O
)	O
presents	O
the	O
same	O
result	O
in	O
a	O
more	O
clear	O
way	O
.	O
	
The	O
deeper	O
DPN	B-Method
-	O
131	O
only	O
costs	O
about	O
more	O
training	B-Metric
time	I-Metric
compared	O
with	O
the	O
best	O
performing	O
ResNeXt	B-Method
,	O
but	O
achieves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
single	O
model	O
performance	O
.	O
	
The	O
training	B-Metric
speed	I-Metric
of	O
the	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
single	O
model	O
,	O
i.e.	O
Very	O
Deep	B-Method
PolyNet	I-Method
	
(	O
537	O
layers	O
)	O
,	O
is	O
about	O
31	O
samples	O
per	O
second	O
based	O
on	O
our	O
implementation	O
using	O
MXNet	B-Method
,	O
showing	O
that	O
DPN	B-Method
-	I-Method
131	I-Method
runs	O
about	O
2	O
times	O
faster	O
than	O
the	O
Very	O
Deep	B-Method
PolyNet	I-Method
during	O
training	O
.	O
	
subsubsection	O
:	O
Place365	O
-	O
Standard	O
dataset	O
	
In	O
this	O
experiment	O
,	O
we	O
further	O
evaluate	O
the	O
accuracy	B-Metric
of	O
the	O
proposed	O
DPN	B-Method
on	O
the	O
scene	B-Task
classification	I-Task
task	I-Task
using	O
the	O
Places365	O
-	O
Standard	O
dataset	O
.	O
	
The	O
Places365	O
-	O
Standard	O
dataset	O
is	O
a	O
high	O
-	O
resolution	O
scene	O
understanding	O
dataset	O
with	O
more	O
than	O
1.8	O
million	O
images	O
of	O
365	O
scene	O
categories	O
.	O
	
Different	O
from	O
object	O
images	O
,	O
scene	O
images	O
do	O
not	O
have	O
very	O
clear	O
discriminative	O
patterns	O
and	O
require	O
a	O
higher	O
level	O
context	O
reasoning	O
ability	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
results	O
of	O
different	O
models	O
on	O
this	O
dataset	O
.	O
	
To	O
make	O
a	O
fair	O
comparison	O
,	O
we	O
perform	O
the	O
DPN	B-Method
-	I-Method
92	I-Method
on	O
this	O
dataset	O
instead	O
of	O
using	O
deeper	O
DPNs	B-Method
.	O
	
As	O
can	O
be	O
seen	O
from	O
the	O
results	O
,	O
DPN	B-Method
achieves	O
the	O
best	O
validation	O
accuracy	B-Metric
compared	O
with	O
other	O
methods	O
.	O
	
The	O
DPN	B-Method
-	I-Method
92	I-Method
requires	O
much	O
less	O
parameters	O
(	O
138	O
MB	O
v.s	O
.	O
163	O
MB	O
)	O
,	O
which	O
again	O
demonstrates	O
its	O
high	O
parameter	B-Metric
efficiency	I-Metric
and	O
high	O
generalization	B-Metric
ability	I-Metric
.	O
	
subsection	O
:	O
Experiments	O
on	O
the	O
object	B-Task
detection	I-Task
task	I-Task
	
We	O
further	O
evaluate	O
the	O
proposed	O
Dual	B-Method
Path	I-Method
Network	I-Method
on	O
the	O
object	B-Task
detection	I-Task
task	I-Task
.	O
	
Experiments	O
are	O
performed	O
on	O
the	O
PASCAL	O
VOC	O
2007	O
datasets	O
.	O
	
We	O
train	O
the	O
models	O
on	O
the	O
union	O
set	O
of	O
VOC	O
2007	O
trainval	O
and	O
VOC	O
2012	O
trainval	O
following	O
,	O
and	O
evaluate	O
them	O
on	O
VOC	O
2007	O
test	O
set	O
.	O
	
We	O
use	O
standard	O
evaluation	B-Metric
metrics	I-Metric
Average	I-Metric
Precision	I-Metric
(	O
AP	B-Metric
)	O
and	O
mean	B-Metric
of	I-Metric
AP	I-Metric
(	O
mAP	B-Metric
)	O
following	O
the	O
PASCAL	B-Method
challenge	I-Method
protocols	I-Method
for	O
evaluation	O
.	O
	
We	O
perform	O
all	O
experiments	O
based	O
on	O
the	O
ResNet	B-Method
-	I-Method
based	I-Method
Faster	I-Method
R	I-Method
-	I-Method
CNN	I-Method
framework	I-Method
,	O
following	O
and	O
make	O
comparisons	O
by	O
replacing	O
the	O
residual	B-Method
network	I-Method
,	O
while	O
keeping	O
other	O
parts	O
unchanged	O
.	O
	
Since	O
our	O
goal	O
is	O
to	O
evaluate	O
DPN	B-Method
,	O
rather	O
than	O
further	O
push	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
accuracy	B-Metric
on	O
this	O
dataset	O
,	O
we	O
adopt	O
the	O
shallowest	O
DPN	B-Method
-	O
92	O
and	O
baseline	O
networks	O
at	O
roughly	O
the	O
same	O
complexity	O
level	O
.	O
	
Table	O
[	O
reference	O
]	O
provides	O
the	O
detection	B-Task
performance	O
comparisons	O
of	O
the	O
proposed	O
DPN	B-Method
with	O
several	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	B-Method
models	I-Method
.	O
	
It	O
can	O
be	O
observed	O
that	O
the	O
DPN	B-Method
obtains	O
the	O
mAP	B-Metric
of	O
,	O
which	O
makes	O
large	O
improvements	O
,	O
i.e.	O
compared	O
with	O
ResNet	B-Method
-	I-Method
101	I-Method
and	O
compared	O
with	O
ResNeXt	O
-	O
101	O
(	O
d	O
)	O
.	O
	
The	O
better	O
results	O
shown	O
in	O
this	O
experiment	O
demonstrate	O
that	O
the	O
Dual	B-Method
Path	I-Method
Network	I-Method
is	O
also	O
capable	O
of	O
learning	O
better	O
feature	B-Method
representations	I-Method
for	O
detecting	B-Task
objects	I-Task
and	O
benefiting	O
the	O
object	B-Task
detection	I-Task
task	I-Task
.	O
	
subsection	O
:	O
Experiments	O
on	O
the	O
semantic	B-Task
segmentation	I-Task
task	I-Task
	
In	O
this	O
experiment	O
,	O
we	O
evaluate	O
the	O
performance	O
of	O
the	O
Dual	B-Method
Path	I-Method
Network	I-Method
for	O
dense	B-Task
prediction	I-Task
,	O
i.e.	O
semantic	B-Task
segmentation	I-Task
,	O
where	O
the	O
training	O
target	O
is	O
to	O
predict	O
the	O
semantic	O
label	O
for	O
each	O
pixel	O
in	O
the	O
input	O
image	O
.	O
	
We	O
conduct	O
experiments	O
on	O
the	O
PASCAL	O
VOC	O
2012	O
segmentation	O
benchmark	O
dataset	O
and	O
use	O
the	O
DeepLab	B-Method
-	I-Method
ASPP	I-Method
-	I-Method
L	I-Method
as	O
the	O
segmentation	B-Method
framework	I-Method
.	O
	
For	O
each	O
compared	O
method	O
in	O
Table	O
[	O
reference	O
]	O
,	O
we	O
replace	O
the	O
convolutional	B-Method
layers	I-Method
in	O
conv4	B-Method
and	O
conv5	B-Method
of	O
Table	O
[	O
reference	O
]	O
with	O
atrous	B-Method
convolution	I-Method
and	O
plug	O
in	O
a	O
head	O
of	O
Atrous	B-Method
Spatial	I-Method
Pyramid	I-Method
Pooling	I-Method
(	O
ASPP	B-Method
)	O
in	O
the	O
final	O
feature	O
maps	O
of	O
conv5	B-Method
.	O
	
We	O
adopt	O
the	O
same	O
training	B-Method
strategy	I-Method
for	O
all	O
networks	O
following	O
for	O
fair	O
comparison	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
results	O
of	O
different	O
convolutional	B-Method
neural	I-Method
networks	I-Method
.	O
	
It	O
can	O
be	O
observed	O
that	O
the	O
proposed	O
DPN	B-Method
-	I-Method
92	I-Method
has	O
the	O
highest	O
overall	O
mIoU	B-Metric
accuracy	I-Metric
.	O
	
Compared	O
with	O
the	O
ResNet	B-Method
-	I-Method
101	I-Method
which	O
has	O
a	O
larger	O
model	O
size	O
and	O
higher	O
computational	B-Metric
cost	I-Metric
,	O
the	O
proposed	O
DPN	B-Method
-	I-Method
92	I-Method
further	O
improves	O
the	O
IoU	B-Metric
for	O
most	O
categories	O
and	O
improves	O
the	O
overall	O
mIoU	B-Metric
by	O
an	O
absolute	O
value	O
.	O
	
Considering	O
the	O
ResNeXt	O
-	O
101	O
	
(	O
d	O
)	O
only	O
improves	O
the	O
overall	O
mIoU	B-Metric
by	O
an	O
absolute	O
value	O
compared	O
with	O
the	O
ResNet	B-Method
-	I-Method
101	I-Method
,	O
the	O
proposed	O
DPN	B-Method
-	I-Method
92	I-Method
gains	O
more	O
than	O
times	O
improvement	O
compared	O
with	O
the	O
ResNeXt	B-Method
-	I-Method
101	I-Method
(	O
d	O
)	O
.	O
	
The	O
better	O
results	O
once	O
again	O
demonstrate	O
the	O
proposed	O
Dual	B-Method
Path	I-Method
Network	I-Method
is	O
capable	O
of	O
learning	O
better	O
feature	B-Method
representation	I-Method
for	O
dense	B-Task
prediction	I-Task
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
paper	O
,	O
we	O
revisited	O
the	O
densely	B-Task
connected	I-Task
networks	I-Task
,	O
bridged	O
the	O
densely	B-Method
connected	I-Method
networks	I-Method
with	O
Higher	B-Method
Order	I-Method
RNNs	I-Method
and	O
proved	O
the	O
residual	B-Method
networks	I-Method
are	O
essentially	O
densely	B-Method
connected	I-Method
networks	I-Method
with	O
shared	O
connections	O
.	O
	
Based	O
on	O
this	O
new	O
explanation	O
,	O
we	O
proposed	O
a	O
dual	B-Method
path	I-Method
architecture	I-Method
that	O
enjoys	O
benefits	O
from	O
both	O
sides	O
.	O
	
The	O
novel	O
network	O
,	O
DPN	B-Method
,	O
is	O
then	O
developed	O
based	O
on	O
this	O
dual	B-Method
path	I-Method
architecture	I-Method
.	O
	
Experiments	O
on	O
the	O
image	B-Task
classification	I-Task
task	O
demonstrate	O
that	O
the	O
DPN	B-Method
enjoys	O
high	O
accuracy	B-Metric
,	O
small	O
model	B-Metric
size	I-Metric
,	O
low	B-Metric
computational	I-Metric
cost	I-Metric
and	O
low	B-Metric
GPU	I-Metric
memory	I-Metric
consumption	I-Metric
,	O
thus	O
is	O
extremely	O
useful	O
for	O
not	O
only	O
research	O
but	O
also	O
real	B-Task
-	I-Task
word	I-Task
application	I-Task
.	O
	
Experiments	O
on	O
the	O
object	B-Task
detection	I-Task
task	I-Task
and	O
semantic	B-Task
segmentation	I-Task
tasks	I-Task
show	O
that	O
the	O
proposed	O
DPN	B-Method
can	O
also	O
benefit	O
other	O
tasks	O
by	O
simply	O
replacing	O
the	O
base	B-Method
network	I-Method
.	O
	
bibliography	O
:	O
References	O
	
appendix	O
:	O
Testing	O
with	O
Mean	B-Method
-	I-Method
Max	I-Method
Pooling	I-Method
	
Here	O
,	O
we	O
introduce	O
a	O
new	O
testing	B-Method
technique	I-Method
by	O
using	O
Mean	B-Method
-	I-Method
Max	I-Method
Pooling	I-Method
which	O
can	O
further	O
improve	O
the	O
performance	O
of	O
a	O
well	O
trained	B-Method
CNN	I-Method
in	O
the	O
testing	O
phase	O
without	O
any	O
noticeable	O
computational	B-Metric
overhead	I-Metric
.	O
	
This	O
testing	O
technique	O
is	O
very	O
effective	O
for	O
testing	O
images	O
with	O
size	O
larger	O
than	O
training	O
crops	O
.	O
	
The	O
idea	O
is	O
to	O
first	O
convert	O
a	O
trained	O
CNN	B-Method
model	I-Method
into	O
a	O
convolutional	B-Method
network	I-Method
and	O
then	O
insert	O
the	O
following	O
Mean	B-Method
-	I-Method
Max	I-Method
Pooling	I-Method
layer	I-Method
	
(	O
a.k.a	O
.	O
	
Max	B-Method
-	I-Method
Avg	I-Method
Pooling	I-Method
)	O
	
,	O
i.e.	O
0.5	O
*	O
(	O
global	B-Method
average	I-Method
pooling	I-Method
+	O
global	B-Method
max	I-Method
pooling	I-Method
)	O
,	O
just	O
before	O
the	O
final	O
softmax	B-Method
layer	I-Method
.	O
	
Comparisons	O
between	O
the	O
models	O
with	O
and	O
without	O
	
Mean	B-Method
-	I-Method
Max	I-Method
Pooling	I-Method
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
As	O
can	O
be	O
seen	O
from	O
the	O
results	O
,	O
the	O
simple	O
Mean	B-Method
-	I-Method
Max	I-Method
Pooling	I-Method
testing	I-Method
strategy	I-Method
successfully	O
improves	O
the	O
testing	O
accuracy	B-Metric
for	O
all	O
models	O
.	O
	
document	O
:	O
Nonlinear	B-Method
3D	I-Method
Face	I-Method
Morphable	I-Method
Model	I-Method
	
As	O
a	O
classic	O
statistical	B-Method
model	I-Method
of	I-Method
3D	I-Method
facial	I-Method
shape	I-Method
and	I-Method
texture	I-Method
,	O
3D	B-Method
Morphable	I-Method
Model	I-Method
(	O
3DMM	B-Method
)	I-Method
is	O
widely	O
used	O
in	O
facial	B-Task
analysis	I-Task
,	O
e.g.	O
,	O
model	B-Task
fitting	I-Task
,	O
image	B-Task
synthesis	I-Task
.	O
	
Conventional	O
3DMM	B-Method
is	O
learned	O
from	O
a	O
set	O
of	O
well	O
-	O
controlled	O
2D	O
face	O
images	O
with	O
associated	O
3D	O
face	O
scans	O
,	O
and	O
represented	O
by	O
two	O
sets	O
of	O
PCA	B-Method
basis	I-Method
functions	I-Method
.	O
	
Due	O
to	O
the	O
type	O
and	O
amount	O
of	O
training	O
data	O
,	O
as	O
well	O
as	O
the	O
linear	O
bases	O
,	O
the	O
representation	O
power	O
of	O
3DMM	B-Method
can	O
be	O
limited	O
.	O
	
To	O
address	O
these	O
problems	O
,	O
this	O
paper	O
proposes	O
an	O
innovative	O
framework	O
to	O
learn	O
a	O
nonlinear	B-Method
3DMM	I-Method
model	O
from	O
a	O
large	O
set	O
of	O
unconstrained	O
face	O
images	O
,	O
without	O
collecting	O
3D	O
face	O
scans	O
.	O
	
Specifically	O
,	O
given	O
a	O
face	O
image	O
as	O
input	O
,	O
a	O
network	B-Method
encoder	I-Method
estimates	O
the	O
projection	O
,	O
shape	O
and	O
texture	O
parameters	O
.	O
	
Two	O
decoders	B-Method
serve	O
as	O
the	O
nonlinear	B-Method
3DMM	I-Method
to	O
map	O
from	O
the	O
shape	O
and	O
texture	O
parameters	O
to	O
the	O
3D	O
shape	O
and	O
texture	O
,	O
respectively	O
.	O
	
With	O
the	O
projection	O
parameter	O
,	O
3D	O
shape	O
,	O
and	O
texture	O
,	O
a	O
novel	O
analytically	B-Method
-	I-Method
differentiable	I-Method
rendering	I-Method
layer	I-Method
is	O
designed	O
to	O
reconstruct	O
the	O
original	O
input	O
face	O
.	O
	
The	O
entire	O
network	O
is	O
end	O
-	O
to	O
-	O
end	O
trainable	O
with	O
only	O
weak	O
supervision	O
.	O
	
We	O
demonstrate	O
the	O
superior	O
representation	B-Metric
power	I-Metric
of	O
our	O
nonlinear	B-Method
3DMM	I-Method
over	O
its	O
linear	B-Method
counterpart	I-Method
,	O
and	O
its	O
contribution	O
to	O
face	B-Task
alignment	I-Task
and	O
3D	B-Task
reconstruction	I-Task
.	O
	
⌊⌋	O
⌈⌉	O
	
section	O
:	O
Introduction	O
	
3D	B-Method
Morphable	I-Method
Model	I-Method
(	O
3DMM	B-Method
)	O
is	O
a	O
statistical	B-Method
model	I-Method
of	O
3D	O
facial	O
shape	O
and	O
texture	O
in	O
a	O
space	O
where	O
there	O
are	O
explicit	O
correspondences	O
.	O
	
The	O
morphable	B-Method
model	I-Method
framework	I-Method
provides	O
two	O
key	O
benefits	O
:	O
first	O
,	O
a	O
point	O
-	O
to	O
-	O
point	O
correspondence	O
between	O
the	O
reconstruction	B-Method
and	O
all	O
other	O
models	O
,	O
enabling	O
âmorphingâ	O
,	O
and	O
second	O
,	O
modeling	O
underlying	O
transformations	O
between	O
types	O
of	O
faces	O
(	O
male	O
to	O
female	O
,	O
neutral	O
to	O
smile	O
,	O
etc	O
.	O
)	O
.	O
	
3DMM	B-Method
has	O
been	O
widely	O
applied	O
in	O
numerous	O
areas	O
,	O
such	O
as	O
computer	B-Task
vision	I-Task
,	O
graphics	B-Task
,	O
human	B-Task
behavioral	I-Task
analysis	I-Task
and	O
craniofacial	B-Task
surgery	I-Task
.	O
	
3DMM	B-Method
is	O
learnt	O
through	O
supervision	B-Method
by	O
performing	O
dimension	B-Method
reduction	I-Method
,	O
normally	O
Principal	B-Method
Component	I-Method
Analysis	I-Method
(	O
PCA	B-Method
)	O
,	O
on	O
a	O
training	O
set	O
of	O
face	O
images	O
/	O
scans	O
.	O
	
To	O
model	O
highly	O
variable	O
3D	O
face	O
shapes	O
,	O
a	O
large	O
amount	O
of	O
high	O
-	O
quality	O
3D	O
face	O
scans	O
is	O
required	O
.	O
	
However	O
,	O
this	O
requirement	O
is	O
expensive	O
to	O
fulfill	O
.	O
	
The	O
first	O
3DMM	B-Method
was	O
built	O
from	O
scans	O
of	O
subjects	O
with	O
a	O
similar	O
ethnicity	O
/	O
age	O
group	O
.	O
	
They	O
were	O
also	O
captured	O
in	O
well	O
-	O
controlled	O
conditions	O
,	O
with	O
only	O
neutral	O
expressions	O
.	O
	
Hence	O
,	O
it	O
is	O
fragile	O
to	O
large	O
variances	O
in	O
the	O
face	O
identity	O
.	O
	
The	O
widely	O
used	O
Basel	B-Method
Face	I-Method
Model	I-Method
(	O
BFM	B-Method
)	I-Method
is	O
also	O
built	O
with	O
only	O
subjects	O
in	O
neutral	O
expressions	O
.	O
	
Lack	O
of	O
expression	O
can	O
be	O
compensated	O
using	O
expression	O
bases	O
from	O
FaceWarehouse	B-Method
or	O
BD	B-Method
-	I-Method
3FE	I-Method
.	O
	
After	O
more	O
than	O
a	O
decade	O
,	O
almost	O
all	O
models	O
use	O
less	O
than	O
training	O
scans	O
.	O
	
Such	O
a	O
small	O
training	O
set	O
is	O
far	O
from	O
adequate	O
to	O
describe	O
the	O
full	O
variability	O
of	O
human	O
faces	O
.	O
	
Only	O
recently	O
,	O
Booth	O
et	O
al	O
.	O
spent	O
a	O
significant	O
effort	O
to	O
build	O
3DMM	B-Method
from	O
scans	O
of	O
subjects	O
.	O
	
Second	O
,	O
the	O
texture	B-Method
model	I-Method
of	O
3DMM	B-Method
is	O
normally	O
built	O
with	O
a	O
small	O
number	O
of	O
2D	O
face	O
images	O
co	O
-	O
captured	O
with	O
3D	O
scans	O
,	O
under	O
well	O
-	O
controlled	O
conditions	O
.	O
	
Therefore	O
,	O
such	O
a	O
model	O
is	O
only	O
learnt	O
to	O
represent	O
the	O
facial	O
texture	O
in	O
similar	O
conditions	O
,	O
rather	O
than	O
in	O
-	O
the	O
-	O
wild	O
environments	O
.	O
	
This	O
substantially	O
limits	O
the	O
application	O
scenarios	O
of	O
3DMM	B-Method
.	O
	
Finally	O
,	O
the	O
representation	O
power	O
of	O
3DMM	B-Method
is	O
limited	O
by	O
not	O
only	O
the	O
size	O
of	O
training	O
set	O
but	O
also	O
its	O
formulation	O
.	O
	
The	O
facial	O
variations	O
are	O
nonlinear	B-Method
in	O
nature	O
.	O
	
E.g.	O
,	O
the	O
variations	O
in	O
different	O
facial	O
expressions	O
or	O
poses	O
are	O
nonlinear	B-Method
,	O
which	O
violates	O
the	O
linear	B-Method
assumption	I-Method
of	I-Method
PCA	I-Method
-	I-Method
based	I-Method
models	I-Method
.	O
	
Thus	O
,	O
a	O
PCA	B-Method
model	I-Method
is	O
unable	O
to	O
interpret	O
facial	O
variations	O
well	O
.	O
	
Given	O
the	O
barrier	O
of	O
3DMM	B-Method
in	O
its	O
data	O
,	O
supervision	B-Task
and	I-Task
linear	I-Task
bases	I-Task
,	O
this	O
paper	O
aims	O
to	O
revolutionize	O
the	O
paradigm	O
of	O
learning	O
3DMM	B-Method
by	O
answering	O
a	O
fundamental	O
question	O
:	O
Whether	O
and	O
how	O
can	O
we	O
learn	O
a	O
nonlinear	B-Method
3D	I-Method
Morphable	I-Method
Model	I-Method
of	O
face	O
shape	O
and	O
texture	O
from	O
a	O
set	O
of	O
unconstrained	O
2D	O
face	O
images	O
,	O
without	O
collecting	O
3D	O
face	O
scans	O
?	O
	
If	O
the	O
answer	O
were	O
yes	O
,	O
this	O
would	O
be	O
in	O
sharp	O
contrast	O
to	O
the	O
conventional	O
3DMM	B-Method
approach	O
,	O
and	O
remedy	O
all	O
aforementioned	O
limitations	O
.	O
	
Fortunately	O
,	O
we	O
have	O
developed	O
approaches	O
that	O
offer	O
positive	O
answers	O
to	O
this	O
question	O
.	O
	
Therefore	O
,	O
the	O
core	O
of	O
this	O
paper	O
is	O
regarding	O
how	O
to	O
learn	O
this	O
new	O
3DMM	B-Method
,	O
what	O
is	O
the	O
representation	O
power	O
of	O
the	O
model	O
,	O
and	O
what	O
is	O
the	O
benefit	O
of	O
the	O
model	O
to	O
facial	B-Task
analysis	I-Task
.	O
	
As	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
starting	O
with	O
an	O
observation	O
that	O
the	O
linear	O
3DMM	B-Method
formulation	O
is	O
equivalent	O
to	O
a	O
single	B-Method
layer	I-Method
network	I-Method
,	O
using	O
a	O
deep	B-Method
network	I-Method
architecture	I-Method
naturally	O
increases	O
the	O
model	O
capacity	O
.	O
	
Hence	O
,	O
we	O
utilize	O
two	O
network	B-Method
decoders	I-Method
,	O
instead	O
of	O
two	O
PCA	O
spaces	O
,	O
as	O
the	O
shape	B-Method
and	I-Method
texture	I-Method
model	I-Method
components	I-Method
,	O
respectively	O
.	O
	
With	O
careful	O
consideration	O
of	O
each	O
component	O
,	O
we	O
design	O
different	O
networks	O
for	O
shape	O
and	O
texture	O
:	O
the	O
multi	B-Method
-	I-Method
layer	I-Method
perceptron	I-Method
(	I-Method
MLP	I-Method
)	I-Method
for	O
shape	B-Method
and	O
convolutional	B-Method
neural	I-Method
network	I-Method
(	O
CNN	B-Method
)	O
for	O
texture	O
.	O
	
Each	O
decoder	O
will	O
take	O
a	O
shape	O
or	O
texture	O
representation	O
as	O
input	O
and	O
output	O
the	O
dense	O
3D	O
face	O
or	O
a	O
face	O
texture	O
.	O
	
These	O
two	O
decoders	O
are	O
essentially	O
the	O
nonlinear	B-Method
3DMM	I-Method
.	O
	
Further	O
,	O
we	O
learn	O
the	O
fitting	B-Method
algorithm	I-Method
to	O
our	O
nonlinear	B-Method
3DMM	I-Method
,	O
which	O
is	O
formulated	O
as	O
a	O
CNN	B-Method
encoder	I-Method
.	O
	
The	O
encoder	O
takes	O
a	O
2D	O
face	O
image	O
as	O
input	O
and	O
generates	O
the	O
shape	O
and	O
texture	O
parameters	O
,	O
from	O
which	O
two	O
decoders	B-Method
estimate	O
the	O
3D	O
face	O
and	O
texture	O
.	O
	
The	O
3D	O
face	O
and	O
texture	O
would	O
perfectly	O
reconstruct	O
the	O
input	O
face	O
,	O
if	O
the	O
fitting	B-Method
algorithm	I-Method
and	O
3DMM	B-Method
are	O
well	O
learnt	O
.	O
	
Therefore	O
,	O
we	O
design	O
a	O
differentiable	B-Method
rendering	I-Method
layer	I-Method
to	O
generate	O
a	O
reconstructed	O
face	O
by	O
fusing	O
the	O
3D	O
face	O
,	O
texture	O
,	O
and	O
the	O
camera	O
projection	O
parameters	O
estimated	O
by	O
the	O
encoder	B-Method
.	O
	
Finally	O
,	O
the	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
learning	I-Method
scheme	I-Method
is	O
constructed	O
where	O
the	O
encoder	B-Method
and	O
two	O
decoders	B-Method
are	O
learnt	O
jointly	O
to	O
minimize	O
the	O
difference	O
between	O
the	O
reconstructed	O
face	O
and	O
the	O
input	O
face	O
.	O
	
Jointly	O
learning	O
the	O
3DMM	B-Method
and	O
the	O
model	B-Method
fitting	I-Method
encoder	I-Method
allows	O
us	O
to	O
leverage	O
the	O
large	O
collection	O
of	O
unconstrained	O
2D	O
images	O
without	O
relying	O
on	O
3D	O
scans	O
.	O
	
We	O
show	O
significantly	O
improved	O
shape	O
and	O
texture	O
representation	O
power	O
over	O
the	O
linear	B-Method
3DMM	I-Method
.	O
	
Consequently	O
,	O
this	O
also	O
benefits	O
other	O
tasks	O
such	O
as	O
2D	O
face	B-Task
alignment	I-Task
and	O
3D	B-Task
reconstruction	I-Task
.	O
	
In	O
this	O
paper	O
,	O
we	O
make	O
the	O
following	O
contributions	O
:	O
1	O
)	O
We	O
learn	O
a	O
nonlinear	B-Method
3DMM	I-Method
model	O
that	O
has	O
greater	O
representation	O
power	O
than	O
its	O
traditional	O
linear	B-Method
counterpart	I-Method
.	O
	
2	O
)	O
	
We	O
jointly	O
learn	O
the	O
model	O
and	O
the	O
model	B-Method
fitting	I-Method
algorithm	I-Method
via	O
weak	B-Method
supervision	I-Method
,	O
by	O
leveraging	O
a	O
large	O
collection	O
of	O
2D	O
images	O
without	O
3D	O
scans	O
.	O
	
The	O
novel	O
rendering	B-Method
layer	I-Method
enables	O
the	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
training	I-Task
.	O
	
3	O
)	O
	
The	O
new	O
3DMM	B-Method
further	O
improves	O
performance	O
in	O
related	O
tasks	O
:	O
face	B-Task
alignment	I-Task
and	O
face	B-Task
reconstruction	I-Task
.	O
	
section	O
:	O
Prior	O
Work	O
	
Linear	B-Method
3DMM	I-Method
.	O
	
Since	O
the	O
original	O
work	O
by	O
Blanz	O
and	O
Vetter	O
,	O
there	O
has	O
been	O
a	O
large	O
amount	O
of	O
effort	O
trying	O
to	O
improve	O
3DMM	B-Method
modeling	O
mechanism	O
.	O
	
Paysan	O
et	O
al	O
.	O
use	O
a	O
Nonrigid	B-Method
Iterative	I-Method
Closest	I-Method
Point	I-Method
to	O
directly	O
align	O
3D	O
scans	O
as	O
an	O
alternative	O
to	O
the	O
UV	B-Method
space	I-Method
alignment	I-Method
method	I-Method
in	O
.	O
	
Vlasic	O
et	O
al	O
.	O
	
use	O
a	O
multilinear	B-Method
model	I-Method
to	O
model	O
the	O
combined	O
effect	O
of	O
identity	O
and	O
expression	O
variation	O
on	O
the	O
facial	O
shape	O
.	O
	
Later	O
,	O
Bolkart	O
and	O
Wuhrer	O
show	O
how	O
such	O
a	O
multilinear	B-Method
model	I-Method
can	O
be	O
estimated	O
directly	O
from	O
the	O
3D	O
scans	O
using	O
a	O
joint	B-Method
optimization	I-Method
over	O
the	O
model	O
parameters	O
and	O
groupwise	B-Method
registration	I-Method
of	O
3D	O
scans	O
.	O
	
Improving	O
Linear	B-Method
3DMM	I-Method
.	O
	
With	O
PCA	B-Method
bases	I-Method
,	O
the	O
statistical	B-Method
distribution	I-Method
underlying	O
3DMM	B-Method
is	O
Gaussian	B-Method
.	O
	
Koppen	O
et	O
al	O
.	O
argue	O
that	O
single	B-Method
-	I-Method
mode	I-Method
Gaussian	I-Method
ca	I-Method
n’t	I-Method
represent	O
real	O
-	O
world	O
distribution	O
.	O
	
They	O
introduce	O
the	O
Gaussian	O
Mixture	O
3DMM	B-Method
that	O
models	O
the	O
global	O
population	O
as	O
a	O
mixture	B-Method
of	I-Method
Gaussian	I-Method
subpopulations	I-Method
,	O
each	O
with	O
its	O
own	O
mean	O
,	O
but	O
shared	O
covariance	O
.	O
	
Booth	O
el	O
al	O
.	O
aim	O
to	O
improve	O
texture	O
of	O
3DMM	B-Method
to	O
go	O
beyond	O
controlled	O
settings	O
by	O
learning	O
âin	B-Method
-	I-Method
the	I-Method
-	I-Method
wildâ	I-Method
feature	I-Method
-	I-Method
based	I-Method
texture	I-Method
model	I-Method
.	O
	
However	O
,	O
both	O
works	O
are	O
still	O
based	O
on	O
statistical	B-Method
PCA	I-Method
bases	I-Method
.	O
	
Duong	O
et	O
al	O
.	O
address	O
the	O
problem	O
of	O
linearity	B-Task
in	I-Task
face	I-Task
modeling	I-Task
by	O
using	O
Deep	B-Method
Boltzmann	I-Method
Machines	I-Method
.	O
	
However	O
,	O
they	O
only	O
work	O
with	O
2D	O
face	O
and	O
sparse	O
landmarks	O
;	O
and	O
hence	O
can	O
not	O
handle	O
faces	O
with	O
large	O
-	O
pose	O
variations	O
or	O
occlusion	O
well	O
.	O
	
2D	B-Task
Face	I-Task
Alignment	I-Task
.	O
	
2D	B-Task
Face	I-Task
Alignment	I-Task
can	O
be	O
cast	O
as	O
a	O
regression	B-Task
problem	I-Task
where	O
2D	O
landmark	O
locations	O
are	O
regressed	O
directly	O
.	O
	
For	O
large	B-Task
-	I-Task
pose	I-Task
or	I-Task
occluded	I-Task
faces	I-Task
,	O
strong	O
priors	O
of	O
3DMM	B-Method
face	O
shape	O
have	O
been	O
shown	O
to	O
be	O
beneficial	O
.	O
	
Hence	O
,	O
there	O
is	O
increasing	O
attention	O
in	O
conducting	O
face	B-Task
alignment	I-Task
by	O
fitting	O
a	O
3D	B-Method
face	I-Method
model	I-Method
to	O
a	O
single	O
2D	O
image	O
.	O
	
Among	O
the	O
prior	O
works	O
,	O
iterative	B-Method
approaches	I-Method
with	O
cascades	O
of	O
regressors	O
tend	O
to	O
be	O
preferred	O
.	O
	
At	O
each	O
cascade	O
,	O
it	O
can	O
be	O
a	O
single	O
or	O
even	O
two	O
regressors	O
.	O
	
In	O
contrast	O
to	O
aforementioned	O
works	O
that	O
use	O
a	O
fixed	O
3DMM	B-Method
model	O
,	O
our	O
model	O
and	O
model	B-Method
fitting	I-Method
are	O
learned	O
jointly	O
.	O
	
This	O
results	O
in	O
a	O
more	O
powerful	O
model	O
:	O
a	O
single	B-Method
-	I-Method
pass	I-Method
encoder	I-Method
,	O
which	O
is	O
learnt	O
jointly	O
with	O
the	O
model	O
,	O
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
face	B-Task
alignment	I-Task
performance	I-Task
on	O
AFLW2000	B-Material
benchmark	I-Material
dataset	I-Material
.	O
	
3D	B-Task
Face	I-Task
Reconstruction	I-Task
.	O
	
3DMM	B-Method
also	O
demonstrates	O
its	O
strength	O
in	O
face	B-Task
reconstruction	I-Task
.	O
	
Since	O
with	O
a	O
single	O
image	O
,	O
present	O
information	O
about	O
the	O
surface	O
is	O
limited	O
;	O
3D	B-Task
face	I-Task
reconstruction	I-Task
must	O
rely	O
on	O
prior	O
knowledge	O
like	O
3DMM	B-Method
.	O
	
Besides	O
3DMM	B-Method
fitting	O
methods	O
,	O
recently	O
,	O
Richardson	O
et	O
al	O
.	O
design	O
a	O
refinement	B-Method
network	I-Method
that	O
adds	O
facial	O
details	O
on	O
top	O
of	O
the	O
3DMM	B-Method
-	O
based	O
geometry	O
.	O
	
However	O
,	O
this	O
approach	O
can	O
only	O
learn	O
2.5D	O
depth	O
map	O
,	O
which	O
loses	O
the	O
correspondence	O
property	O
of	O
3DMM	B-Method
.	O
	
The	O
recent	O
work	O
of	O
Tewari	O
et	O
al	O
.	O
reconstruct	O
a	O
3D	O
face	O
by	O
an	O
elegant	O
encoder	B-Method
-	I-Method
decoder	I-Method
network	I-Method
.	O
	
While	O
their	O
ability	O
to	O
decompose	O
lighting	O
with	O
reflectance	O
is	O
satisfactory	O
,	O
our	O
work	O
has	O
a	O
different	O
objective	O
of	O
learning	O
a	O
nonlinear	B-Method
3DMM	I-Method
.	O
	
section	O
:	O
Proposed	O
Method	O
	
subsection	O
:	O
Conventional	O
Linear	B-Method
3DMM	I-Method
	
The	O
3D	B-Method
Morphable	I-Method
Model	I-Method
(	O
3DMM	B-Method
)	O
and	O
its	O
2D	B-Method
counterpart	I-Method
,	O
Active	B-Method
Appearance	I-Method
Model	I-Method
,	O
provide	O
parametric	B-Method
models	I-Method
for	O
synthesizing	B-Task
faces	I-Task
,	O
where	O
faces	O
are	O
modeled	O
using	O
two	O
components	O
:	O
shape	O
and	O
texture	O
.	O
	
In	O
,	O
Blanz	O
et	O
al	O
.	O
propose	O
to	O
describe	O
the	O
3D	O
face	O
space	O
with	O
PCA	B-Method
:	O
where	O
is	O
a	O
3D	O
face	O
with	O
vertices	O
,	O
is	O
the	O
mean	O
shape	O
,	O
is	O
the	O
shape	O
parameter	O
corresponding	O
to	O
a	O
3D	O
shape	O
bases	O
.	O
	
The	O
shape	O
bases	O
can	O
be	O
further	O
split	O
into	O
,	O
where	O
is	O
trained	O
from	O
3D	O
scans	O
with	O
neutral	O
expression	O
,	O
and	O
is	O
from	O
the	O
offsets	O
between	O
expression	O
and	O
neutral	O
scans	O
.	O
	
The	O
texture	O
of	O
the	O
face	O
is	O
defined	O
within	O
the	O
mean	O
shape	O
,	O
which	O
describes	O
the	O
R	O
,	O
G	O
,	O
B	O
colors	O
of	O
corresponding	O
vertices	O
.	O
	
is	O
also	O
formulated	O
as	O
a	O
linear	B-Method
combination	I-Method
of	I-Method
texture	I-Method
basis	I-Method
functions	I-Method
:	O
where	O
is	O
the	O
mean	O
texture	O
,	O
is	O
the	O
texture	O
bases	O
,	O
and	O
is	O
the	O
texture	O
parameter	O
.	O
	
The	O
3DMM	B-Method
can	O
be	O
used	O
to	O
synthesize	O
novel	O
views	O
of	O
the	O
face	O
.	O
	
Firstly	O
,	O
a	O
3D	O
face	O
is	O
projected	O
onto	O
the	O
image	O
plane	O
with	O
the	O
weak	B-Method
perspective	I-Method
projection	I-Method
model	I-Method
:	O
where	O
is	O
the	O
model	B-Method
construction	I-Method
and	O
projection	O
function	O
leading	O
to	O
the	O
2D	O
positions	O
of	O
3D	O
vertices	O
,	O
is	O
the	O
scale	O
factor	O
,	O
is	O
the	O
orthographic	O
projection	O
matrix	O
,	O
is	O
the	O
rotation	O
matrix	O
constructed	O
from	O
three	O
rotation	O
angles	O
pitch	O
,	O
yaw	O
,	O
roll	O
,	O
and	O
is	O
the	O
translation	O
vector	O
.	O
	
While	O
the	O
projection	O
matrix	O
has	O
dimensions	O
,	O
it	O
has	O
six	O
degrees	O
of	O
freedom	O
,	O
which	O
is	O
parameterized	O
by	O
a	O
-	O
dim	O
vector	O
.	O
	
Then	O
,	O
the	O
2D	O
image	O
is	O
rendered	O
using	O
texture	B-Method
and	O
an	O
illumination	B-Method
model	I-Method
as	O
described	O
in	O
.	O
	
subsection	O
:	O
Nonlinear	O
3DMM	B-Method
	
As	O
mentioned	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
	
,	O
the	O
linear	B-Method
3DMM	I-Method
has	O
the	O
problems	O
such	O
as	O
requiring	O
3D	O
face	O
scans	O
for	O
supervised	B-Task
learning	I-Task
,	O
unable	O
to	O
leverage	O
massive	O
unconstrained	O
face	O
images	O
for	O
learning	B-Task
,	O
and	O
the	O
limited	O
representation	O
power	O
due	O
to	O
the	O
linear	B-Method
bases	I-Method
.	O
	
We	O
propose	O
to	O
learn	O
a	O
nonlinear	B-Method
3DMM	I-Method
model	O
using	O
only	O
large	O
-	O
scale	O
in	O
-	O
the	O
-	O
wild	O
2D	O
face	O
images	O
.	O
	
subsubsection	O
:	O
Problem	B-Task
Formulation	I-Task
	
In	O
linear	B-Method
3DMM	I-Method
,	O
the	O
factorization	O
of	O
each	O
components	O
(	O
texture	O
,	O
shape	O
)	O
can	O
be	O
seen	O
as	O
a	O
matrix	B-Method
multiplication	I-Method
between	O
coefficients	O
and	O
bases	O
.	O
	
From	O
a	O
neural	B-Method
network	I-Method
’s	O
perspective	O
,	O
this	O
can	O
be	O
viewed	O
as	O
a	O
shallow	B-Method
network	I-Method
with	O
only	O
one	O
fully	O
connected	O
layer	O
and	O
no	O
activation	O
function	O
.	O
	
Naturally	O
,	O
to	O
increase	O
the	O
model	O
’s	O
representative	O
power	O
,	O
the	O
shallow	B-Method
network	I-Method
can	O
be	O
extended	O
to	O
a	O
deep	B-Method
architecture	I-Method
.	O
	
In	O
this	O
work	O
,	O
we	O
design	O
a	O
novel	O
learning	B-Method
scheme	I-Method
to	O
learn	O
a	O
deep	O
3DMM	B-Method
and	O
its	O
inference	B-Method
(	I-Method
or	I-Method
fitting	I-Method
)	I-Method
algorithm	I-Method
.	O
	
Specifically	O
,	O
as	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
we	O
use	O
two	O
deep	B-Method
networks	I-Method
to	O
decode	O
the	O
shape	O
,	O
texture	O
parameters	O
into	O
the	O
3D	O
facial	O
shape	O
and	O
texture	O
respectively	O
.	O
	
To	O
make	O
the	O
framework	O
end	O
-	O
to	O
-	O
end	O
trainable	O
,	O
these	O
parameters	O
are	O
estimated	O
by	O
an	O
encoder	B-Method
network	I-Method
,	O
which	O
is	O
essentially	O
the	O
fitting	B-Method
algorithm	I-Method
of	O
our	O
3DMM	B-Method
.	O
	
Three	O
deep	B-Method
networks	I-Method
join	O
forces	O
for	O
the	O
ultimate	O
goal	O
of	O
reconstructing	O
the	O
input	O
face	O
image	O
,	O
with	O
the	O
assistance	O
of	O
a	O
geometry	B-Method
-	I-Method
based	I-Method
rendering	I-Method
layer	I-Method
.	O
	
Formally	O
,	O
given	O
a	O
set	O
of	O
2D	O
face	O
images	O
,	O
we	O
aim	O
to	O
learn	O
an	O
encoder	B-Method
:	O
that	O
estimates	O
the	O
projection	O
parameter	O
,	O
and	O
shape	O
and	O
texture	O
parameters	O
,	O
a	O
3D	B-Method
shape	I-Method
decoder	I-Method
:	O
that	O
decodes	O
the	O
shape	O
parameter	O
to	O
a	O
3D	O
shape	O
,	O
and	O
a	O
texture	B-Method
decoder	I-Method
:	O
that	O
decodes	O
the	O
texture	O
parameter	O
to	O
a	O
realistic	O
texture	O
,	O
with	O
the	O
objective	O
that	O
the	O
rendered	O
image	O
with	O
,	O
,	O
and	O
can	O
approximate	O
the	O
original	O
image	O
well	O
.	O
	
Mathematically	O
,	O
the	O
objective	B-Metric
function	I-Metric
is	O
:	O
where	O
is	O
the	O
rendering	O
layer	O
(	O
Sec	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
subsubsection	O
:	O
Shape	B-Method
&	I-Method
Texture	I-Method
Representation	I-Method
	
Our	O
shape	B-Method
representation	I-Method
is	O
the	O
same	O
as	O
that	O
of	O
the	O
linear	O
3DMM	B-Method
,	O
i.e.	O
,	O
is	O
a	O
set	O
of	O
vertices	O
on	O
the	O
face	O
surface	O
.	O
	
The	O
shape	B-Method
decoder	I-Method
is	O
a	O
MLP	B-Method
whose	O
input	O
is	O
the	O
shape	O
parameter	O
from	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
illustrates	O
three	O
possible	O
texture	B-Method
representations	I-Method
.	O
	
Texture	O
is	O
defined	O
per	O
vertex	O
in	O
the	O
linear	B-Method
3DMM	I-Method
and	O
recent	O
work	O
such	O
as	O
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
a	O
)	O
)	O
.	O
	
There	O
is	O
a	O
texture	O
intensity	O
value	O
corresponding	O
to	O
each	O
vertex	O
in	O
the	O
face	O
mesh	O
.	O
	
Since	O
3D	O
vertices	O
are	O
not	O
defined	O
on	O
a	O
2D	O
grid	O
,	O
this	O
representation	O
will	O
be	O
parameterized	O
as	O
a	O
vector	O
,	O
which	O
not	O
only	O
loses	O
the	O
spatial	O
relation	O
of	O
vertices	O
,	O
but	O
also	O
prevents	O
it	O
from	O
leveraging	O
the	O
convenience	O
of	O
deploying	O
CNN	B-Method
on	O
2D	O
imagery	O
.	O
	
In	O
contrast	O
,	O
given	O
the	O
rapid	O
progress	O
in	O
image	B-Task
synthesis	I-Task
,	O
it	O
is	O
desirable	O
to	O
choose	O
a	O
2D	O
image	O
,	O
e.g.	O
,	O
a	O
frontal	O
-	O
view	O
face	O
image	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
b	O
)	O
,	O
as	O
a	O
texture	B-Method
representation	I-Method
.	O
	
However	O
,	O
frontal	O
faces	O
contain	O
little	O
information	O
of	O
two	O
sides	O
,	O
which	O
would	O
lose	O
much	O
texture	O
information	O
for	O
side	O
-	O
view	O
faces	O
.	O
	
In	O
light	O
of	O
these	O
considerations	O
,	O
we	O
use	O
an	O
unwrapped	O
2D	O
texture	O
as	O
our	O
texture	B-Method
representation	I-Method
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
(	O
c	O
)	O
)	O
.	O
	
Specifically	O
,	O
each	O
3D	O
vertex	O
is	O
projected	O
onto	O
the	O
UV	O
space	O
using	O
cylindrical	O
unwarp	O
.	O
	
Assuming	O
that	O
the	O
face	O
mesh	O
has	O
the	O
top	O
pointing	O
up	O
the	O
axis	O
,	O
the	O
projection	O
of	O
onto	O
the	O
UV	O
space	O
is	O
computed	O
as	O
:	O
where	O
are	O
constant	O
scale	O
and	O
translation	O
scalars	O
to	O
place	O
the	O
unwrapped	O
face	O
into	O
the	O
image	O
boundaries	O
.	O
	
Also	O
,	O
the	O
texture	B-Method
decoder	I-Method
is	O
a	O
CNN	B-Method
constructed	O
by	O
fractionally	B-Method
-	I-Method
strided	I-Method
convolution	I-Method
layers	I-Method
.	O
	
subsubsection	O
:	O
In	B-Task
-	I-Task
Network	I-Task
Face	I-Task
Rendering	I-Task
	
To	O
reconstruct	O
a	O
face	O
image	O
from	O
the	O
texture	O
,	O
shape	O
,	O
and	O
projection	O
parameter	O
,	O
we	O
define	O
a	O
rendering	B-Method
layer	I-Method
.	O
	
This	O
is	O
accomplished	O
in	O
three	O
steps	O
.	O
	
Firstly	O
,	O
the	O
texture	O
value	O
of	O
each	O
vertex	O
in	O
is	O
determined	O
by	O
its	O
predefined	O
location	O
in	O
the	O
2D	O
texture	O
.	O
	
Usually	O
,	O
it	O
involves	O
sub	B-Method
-	I-Method
pixel	I-Method
sampling	I-Method
via	O
a	O
bilinear	B-Method
sampling	I-Method
kernel	I-Method
:	O
where	O
is	O
the	O
UV	O
space	O
projection	O
of	O
via	O
Eqn	O
.	O
	
[	O
reference	O
]	O
.	O
	
Secondly	O
,	O
the	O
3D	O
shape	O
/	O
mesh	O
is	O
projected	O
to	O
the	O
image	O
plane	O
via	O
Eqn	O
.	O
	
[	O
reference	O
]	O
.	O
	
Finally	O
,	O
the	O
3D	O
mesh	O
is	O
then	O
rendered	O
using	O
a	O
Z	B-Method
-	I-Method
buffer	I-Method
renderer	I-Method
,	O
where	O
each	O
pixel	O
is	O
associated	O
with	O
a	O
single	O
triangle	O
of	O
the	O
mesh	O
,	O
where	O
is	O
an	O
operation	O
returning	O
three	O
vertices	O
of	O
the	O
triangle	O
that	O
encloses	O
the	O
pixel	O
after	O
projection	O
.	O
	
In	O
order	O
to	O
handle	O
occlusions	O
,	O
when	O
a	O
single	O
pixel	O
resides	O
in	O
more	O
than	O
one	O
triangle	O
,	O
the	O
triangle	O
that	O
is	O
closest	O
to	O
the	O
image	O
plane	O
is	O
selected	O
.	O
	
The	O
value	O
of	O
each	O
pixel	O
is	O
determined	O
by	O
interpolating	O
the	O
intensity	O
of	O
the	O
mesh	O
vertices	O
via	O
barycentric	O
coordinates	O
.	O
	
There	O
are	O
alternative	O
designs	O
to	O
our	O
rendering	B-Method
layer	I-Method
.	O
	
If	O
the	O
texture	B-Method
representation	I-Method
is	O
defined	O
per	O
vertex	O
,	O
as	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
a	O
)	O
,	O
one	O
may	O
warp	O
the	O
input	O
image	O
onto	O
the	O
vertex	O
space	O
of	O
the	O
3D	O
shape	O
,	O
whose	O
distance	O
to	O
the	O
per	B-Method
-	I-Method
vertex	I-Method
texture	I-Method
representation	I-Method
can	O
form	O
a	O
reconstruction	O
loss	O
.	O
	
This	O
design	O
is	O
adopted	O
by	O
the	O
recent	O
work	O
of	O
.	O
	
In	O
comparison	O
,	O
our	O
rendered	O
image	O
is	O
defined	O
on	O
a	O
2D	O
grid	O
while	O
the	O
alternative	O
is	O
on	O
top	O
of	O
the	O
3D	O
mesh	O
.	O
	
As	O
a	O
result	O
,	O
our	O
rendered	O
image	O
can	O
enjoy	O
the	O
convenience	O
of	O
applying	O
the	O
adversarial	B-Method
loss	I-Method
,	O
which	O
is	O
shown	O
to	O
be	O
critical	O
in	O
improving	O
the	O
quality	B-Metric
of	I-Metric
synthetic	I-Metric
texture	I-Metric
.	O
	
Another	O
design	O
for	O
rendering	B-Task
layer	I-Task
is	O
image	B-Task
warping	I-Task
based	O
on	O
the	O
spline	B-Method
interpolation	I-Method
,	O
as	O
in	O
.	O
	
However	O
,	O
this	O
warping	O
is	O
continuous	O
:	O
every	O
pixel	O
in	O
the	O
input	O
will	O
map	O
to	O
the	O
output	O
.	O
	
Hence	O
this	O
warping	B-Method
operation	I-Method
fails	O
in	O
the	O
occlusion	O
part	O
.	O
	
As	O
a	O
result	O
,	O
Cole	O
et	O
al	O
.	O
limit	O
their	O
scope	O
to	O
only	O
synthesizing	O
frontal	O
faces	O
by	O
warping	O
from	O
normalized	O
faces	O
.	O
	
subsubsection	O
:	O
Network	B-Method
Architecture	I-Method
	
We	O
design	O
our	O
network	B-Method
architecture	I-Method
as	O
in	O
Tab	O
.	O
	
[	O
reference	O
]	O
.	O
	
Also	O
,	O
includes	O
two	O
fully	B-Method
connected	I-Method
layers	I-Method
with	O
-	B-Method
dim	I-Method
intermediate	I-Method
representation	I-Method
with	O
eLU	B-Method
activation	I-Method
.	O
	
The	O
entire	O
network	O
is	O
end	O
-	O
to	O
-	O
end	O
trained	O
to	O
reconstruct	O
the	O
input	O
images	O
,	O
with	O
the	O
loss	O
function	O
:	O
where	O
the	O
reconstruction	O
loss	O
enforces	O
the	O
rendered	O
image	O
to	O
be	O
similar	O
to	O
the	O
input	O
,	O
the	O
adversarial	B-Method
loss	I-Method
favors	O
realistic	B-Task
rendering	I-Task
,	O
and	O
the	O
landmark	O
loss	O
enforces	O
geometry	O
constraint	O
.	O
	
Adversarial	O
Loss	O
.	O
	
Based	O
on	O
the	O
principal	O
of	O
Generative	B-Method
Adversarial	I-Method
Network	I-Method
(	O
GAN	B-Method
)	O
,	O
the	O
adversarial	B-Method
loss	I-Method
is	O
widely	O
used	O
to	O
synthesize	O
photo	O
-	O
realistic	O
images	O
,	O
where	O
the	O
generator	B-Method
and	I-Method
discriminator	I-Method
are	O
trained	O
alternatively	O
.	O
	
In	O
our	O
case	O
,	O
networks	O
that	O
generate	O
the	O
rendered	O
image	O
is	O
the	O
generator	O
.	O
	
The	O
discriminator	O
includes	O
a	O
dedicated	B-Method
network	I-Method
,	O
which	O
aims	O
to	O
distinguish	O
between	O
the	O
real	O
face	O
image	O
and	O
rendered	O
image	O
.	O
	
During	O
the	O
training	O
of	O
the	O
generator	B-Method
,	O
the	O
texture	B-Method
model	I-Method
will	O
be	O
updated	O
with	O
the	O
objective	O
that	O
is	O
being	O
classified	O
as	O
real	O
faces	O
by	O
.	O
	
Since	O
our	O
face	B-Method
rendering	I-Method
already	O
creates	O
correct	O
global	O
structure	O
of	O
the	O
face	O
image	O
,	O
the	O
global	B-Method
image	I-Method
-	I-Method
based	I-Method
adversarial	I-Method
loss	I-Method
may	O
not	O
be	O
effective	O
in	O
producing	O
high	O
-	O
quality	O
textures	O
on	O
local	O
facial	O
regions	O
.	O
	
Therefore	O
,	O
we	O
employ	O
patchGAN	B-Method
in	O
our	O
discriminator	B-Method
.	O
	
Here	O
,	O
is	O
a	O
CNN	B-Method
consisting	O
of	O
four	O
conv	B-Method
layers	I-Method
with	O
stride	O
of	O
,	O
and	O
number	O
of	O
filters	O
are	O
,	O
,	O
and	O
,	O
respectively	O
.	O
	
Finally	O
,	O
one	O
of	O
key	O
reasons	O
we	O
are	O
able	O
to	O
employ	O
adversarial	B-Method
loss	I-Method
is	O
that	O
we	O
are	O
rendering	O
in	O
the	O
2D	O
image	O
space	O
,	O
rather	O
than	O
the	O
3D	O
vertices	O
space	O
or	O
unwrapped	O
texture	O
space	O
.	O
	
This	O
shows	O
the	O
necessity	O
and	O
importance	O
of	O
our	O
rendering	B-Method
layer	I-Method
.	O
	
Semi	B-Task
-	I-Task
Supervised	I-Task
Pre	I-Task
-	I-Task
Training	I-Task
.	O
	
Fully	O
unsupervised	B-Method
training	I-Method
using	O
only	O
the	O
mentioned	O
reconstruction	B-Method
and	I-Method
adversarial	I-Method
loss	I-Method
on	O
the	O
rendered	O
image	O
could	O
lead	O
to	O
a	O
degenerate	O
solution	O
,	O
since	O
the	O
initial	B-Method
estimation	I-Method
is	O
far	O
from	O
ideal	O
to	O
render	O
meaningful	O
images	O
.	O
	
Hence	O
,	O
we	O
introduce	O
pre	B-Method
-	I-Method
training	I-Method
loss	I-Method
functions	I-Method
to	O
guide	O
the	O
training	B-Task
in	O
the	O
early	O
iterations	O
.	O
	
With	O
face	B-Method
profiling	I-Method
technique	I-Method
,	O
Zhu	O
et	O
al	O
.	O
expands	O
the	O
300W	O
dataset	O
into	O
images	O
with	O
the	O
fitted	O
3DMM	B-Method
shape	O
and	O
projection	O
parameters	O
.	O
	
Given	O
and	O
,	O
we	O
create	O
the	O
pseudo	O
groundtruth	O
texture	O
by	O
referring	O
every	O
pixel	O
in	O
the	O
UV	O
space	O
back	O
to	O
the	O
input	O
image	O
,	O
i.e.	O
,	O
backward	O
of	O
our	O
rendering	B-Method
layer	I-Method
.	O
	
With	O
,	O
,	O
,	O
we	O
define	O
our	O
pre	B-Metric
-	I-Metric
training	I-Metric
loss	I-Metric
by	O
:	O
where	O
Due	O
to	O
the	O
pseudo	O
groundtruth	O
,	O
using	O
may	O
run	O
into	O
the	O
risk	O
that	O
our	O
solution	O
learns	O
to	O
mimic	O
the	O
linear	B-Method
model	I-Method
.	O
	
Thus	O
,	O
we	O
switch	O
to	O
the	O
loss	O
of	O
Eqn	O
.	O
	
[	O
reference	O
]	O
after	O
converges	O
.	O
	
Sparse	B-Task
Landmark	I-Task
Alignment	I-Task
.	O
	
To	O
help	O
to	O
better	O
learn	O
the	O
facial	O
shape	O
,	O
the	O
landmark	B-Task
loss	I-Task
can	O
be	O
an	O
auxiliary	B-Task
task	I-Task
.	O
	
where	O
is	O
the	O
manually	O
labeled	O
2D	O
landmark	O
locations	O
,	O
is	O
a	O
constant	O
-	O
dim	O
vector	O
storing	O
the	O
indexes	O
of	O
3D	O
vertices	O
corresponding	O
to	O
the	O
labeled	O
2D	O
landmarks	O
.	O
	
Unlike	O
the	O
three	O
losses	O
above	O
,	O
these	O
landmark	O
annotations	O
are	O
“	O
golden	O
”	O
groundtruth	O
,	O
and	O
hence	O
can	O
be	O
used	O
during	O
the	O
entire	O
training	B-Task
process	I-Task
.	O
	
Different	O
from	O
traditional	O
face	B-Task
alignment	I-Task
work	O
where	O
the	O
shape	O
bases	O
are	O
fixed	O
,	O
our	O
work	O
jointly	O
learns	O
the	O
bases	O
functions	O
(	O
i.e.	O
,	O
the	O
shape	B-Method
decoder	I-Method
)	O
as	O
well	O
.	O
	
Minimizing	B-Task
the	I-Task
landmark	I-Task
loss	I-Task
when	O
updating	O
only	O
moves	O
a	O
tiny	O
subset	O
of	O
vertices	O
,	O
since	O
our	O
is	O
a	O
MLP	B-Method
consisting	O
of	O
fully	B-Method
connected	I-Method
layers	I-Method
.	O
	
This	O
could	O
lead	O
to	O
unrealistic	O
shapes	O
.	O
	
Hence	O
,	O
when	O
optimizing	O
the	O
landmark	B-Task
loss	I-Task
,	O
we	O
fix	O
the	O
decoder	B-Method
and	O
only	O
update	O
the	O
encoder	B-Method
.	O
	
Note	O
that	O
the	O
estimated	O
groundtruth	O
in	O
and	O
the	O
landmarks	O
are	O
the	O
only	O
supervision	O
used	O
in	O
our	O
training	O
,	O
due	O
to	O
this	O
our	O
learning	O
is	O
considered	O
as	O
weakly	B-Task
supervised	I-Task
.	O
	
section	O
:	O
Experimental	O
Results	O
	
The	O
experiments	O
study	O
three	O
aspects	O
of	O
the	O
proposed	O
nonlinear	B-Method
3DMM	I-Method
,	O
in	O
terms	O
of	O
its	O
expressiveness	B-Metric
,	O
representation	B-Metric
power	I-Metric
,	O
and	O
applications	O
to	O
facial	B-Task
analysis	I-Task
.	O
	
Using	O
facial	O
mesh	O
triangle	O
definition	O
by	O
Basel	B-Method
Face	I-Method
Model	I-Method
(	O
BFM	B-Method
)	O
,	O
we	O
train	O
our	O
3DMM	B-Method
using	O
300W	O
-	O
LP	O
dataset	O
.	O
	
The	O
model	O
is	O
optimized	O
using	O
Adam	B-Method
optimizer	I-Method
with	O
an	O
initial	O
learning	B-Metric
rate	I-Metric
of	O
when	O
minimizing	O
,	O
and	O
when	O
minimizing	O
.	O
	
We	O
set	O
the	O
following	O
parameters	O
:	O
,	O
,	O
.	O
	
values	O
are	O
set	O
to	O
make	O
losses	O
to	O
have	O
similar	O
magnitudes	O
.	O
	
subsection	O
:	O
Expressiveness	O
	
Exploring	B-Task
feature	I-Task
space	I-Task
.	O
	
We	O
use	O
the	O
entire	O
CelebA	O
dataset	O
with	O
k	O
images	O
to	O
feed	O
to	O
our	O
network	O
to	O
obtain	O
the	O
empirical	O
distribution	O
of	O
our	O
shape	O
and	O
texture	O
parameters	O
.	O
	
By	O
varying	O
the	O
mean	O
parameter	O
along	O
each	O
dimension	O
proportional	O
to	O
their	O
standard	O
deviations	O
,	O
we	O
can	O
get	O
a	O
sense	O
how	O
each	O
element	O
contributes	O
to	O
the	O
final	O
shape	O
and	O
texture	O
.	O
	
We	O
sort	O
elements	O
in	O
the	O
shape	O
parameter	O
based	O
on	O
their	O
differences	O
to	O
the	O
mean	O
3D	O
shape	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
four	O
examples	O
of	O
shape	O
changes	O
,	O
whose	O
differences	O
rank	O
No	O
.	O
,	O
,	O
,	O
and	O
among	O
elements	O
.	O
	
Most	O
of	O
top	O
changes	O
are	O
expression	O
related	O
.	O
	
Similarly	O
,	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
we	O
visualize	O
different	O
texture	O
changes	O
by	O
adjusting	O
only	O
one	O
element	O
of	O
off	O
the	O
mean	O
parameter	O
.	O
	
The	O
elements	O
with	O
the	O
same	O
ranks	O
as	O
the	O
shape	O
counterpart	O
are	O
selected	O
.	O
	
Attribute	B-Method
Embedding	I-Method
.	O
	
To	O
better	O
understand	O
different	O
shape	O
and	O
texture	O
instances	O
embedded	O
in	O
our	O
two	O
decoders	O
,	O
we	O
dig	O
into	O
their	O
attribute	O
meaning	O
.	O
	
For	O
a	O
given	O
attribute	O
,	O
e.g.	O
,	O
male	O
,	O
we	O
feed	O
images	O
with	O
that	O
attribute	O
into	O
our	O
encoder	O
to	O
obtain	O
two	O
sets	O
of	O
parameters	O
and	O
.	O
	
These	O
sets	O
represent	O
corresponding	O
empirical	O
distributions	O
of	O
the	O
data	O
in	O
the	O
low	O
dimensional	O
spaces	O
.	O
	
By	O
computing	O
the	O
mean	O
parameters	O
,	O
and	O
feed	O
into	O
their	O
respective	O
decoders	B-Method
,	O
we	O
can	O
reconstruct	O
the	O
mean	O
shape	O
and	O
texture	O
with	O
that	O
attribute	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
visualizes	O
the	O
reconstructed	O
shape	O
and	O
texture	O
related	O
to	O
some	O
attributes	O
.	O
	
Differences	O
among	O
attributes	O
present	O
in	O
both	O
shape	O
and	O
texture	O
.	O
	
subsection	O
:	O
Representation	B-Method
Power	I-Method
	
Texture	O
.	O
	
Given	O
a	O
face	O
image	O
,	O
assuming	O
we	O
know	O
the	O
groundtruth	O
shape	O
and	O
projection	O
parameters	O
,	O
we	O
can	O
unwarp	O
the	O
texture	O
into	O
the	O
UV	O
space	O
,	O
as	O
we	O
generate	O
“	O
pseudo	O
groundtruth	O
”	O
texture	O
in	O
the	O
weakly	B-Task
supervised	I-Task
step	I-Task
.	O
	
With	O
the	O
groundtruth	O
texture	O
,	O
by	O
using	O
gradient	B-Method
descent	I-Method
,	O
we	O
can	O
estimate	O
a	O
texture	O
parameter	O
whose	O
decoded	O
texture	O
matches	O
with	O
the	O
groundtruth	O
.	O
	
Alternatively	O
,	O
we	O
can	O
minimize	O
the	O
reconstruction	B-Metric
error	I-Metric
in	O
the	O
image	O
space	O
,	O
through	O
the	O
rendering	B-Method
layer	I-Method
with	O
the	O
groundtruth	O
and	O
.	O
	
Empirically	O
,	O
the	O
two	O
methods	O
give	O
similar	O
performances	O
but	O
we	O
choose	O
the	O
first	O
option	O
as	O
it	O
involves	O
only	O
one	O
warping	O
step	O
,	O
instead	O
of	O
rendering	O
in	O
every	O
optimization	B-Task
iteration	I-Task
.	O
	
For	O
the	O
linear	B-Method
model	I-Method
,	O
we	O
use	O
the	O
fitting	O
results	O
of	O
Basel	B-Method
texture	I-Method
and	O
Phong	B-Method
illumination	I-Method
model	I-Method
given	O
by	O
.	O
	
As	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
our	O
nonlinear	B-Method
texture	I-Method
is	O
closer	O
to	O
the	O
groundtruth	O
than	O
the	O
linear	B-Method
model	I-Method
,	O
especially	O
for	O
in	O
-	O
the	O
-	O
wild	O
images	O
(	O
the	O
first	O
two	O
rows	O
)	O
.	O
	
This	O
is	O
expected	O
since	O
the	O
linear	B-Method
model	I-Method
is	O
trained	O
with	O
controlled	O
images	O
.	O
	
Quantitatively	O
,	O
our	O
nonlinear	B-Method
model	O
has	O
significantly	O
lower	O
reconstruction	B-Metric
error	I-Metric
than	O
the	O
linear	B-Method
model	I-Method
(	O
vs.	O
,	O
as	O
in	O
Tab	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
3D	O
Shape	O
.	O
	
We	O
also	O
compare	O
the	O
power	O
of	O
nonlinear	B-Method
and	O
linear	B-Method
3DMM	I-Method
in	O
representing	O
real	B-Task
-	I-Task
world	I-Task
3D	I-Task
scans	I-Task
.	O
	
We	O
compare	O
with	O
BFM	B-Method
,	O
the	O
most	O
commonly	O
used	O
3DMM	B-Method
at	O
present	O
.	O
	
We	O
use	O
ten	O
3D	O
face	O
scans	O
provided	O
by	O
,	O
which	O
are	O
not	O
included	O
in	O
the	O
training	O
set	O
of	O
BFM	B-Method
.	O
	
As	O
these	O
face	O
meshes	O
are	O
already	O
registered	O
using	O
the	O
same	O
triangle	O
definition	O
with	O
BFM	B-Method
,	O
no	O
registration	B-Task
is	O
necessary	O
.	O
	
Given	O
the	O
groundtruth	O
shape	O
,	O
by	O
using	O
gradient	B-Method
descent	I-Method
,	O
we	O
can	O
estimate	O
a	O
shape	O
parameter	O
whose	O
decoded	O
shape	O
matches	O
the	O
groundtruth	O
.	O
	
We	O
define	O
matching	B-Metric
criteria	I-Metric
on	O
both	O
vertex	O
distances	O
and	O
surface	O
normal	O
direction	O
.	O
	
This	O
empirically	O
improves	O
fidelity	O
of	O
final	O
results	O
compared	O
to	O
only	O
optimizing	O
vertex	O
distances	O
.	O
	
Also	O
,	O
to	O
emphasize	O
the	O
compactness	O
of	O
nonlinear	B-Method
models	O
,	O
we	O
train	O
different	O
models	O
with	O
different	O
latent	O
space	O
sizes	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
the	O
visual	B-Metric
quality	I-Metric
of	O
two	O
models	O
’	O
reconstructions	O
.	O
	
As	O
we	O
can	O
see	O
,	O
our	O
reconstructions	O
closely	O
match	O
the	O
face	O
shapes	O
.	O
	
Meanwhile	O
the	O
linear	B-Method
model	I-Method
struggles	O
with	O
face	O
shapes	O
outside	O
its	O
PCA	O
span	O
.	O
	
To	O
quantify	O
the	O
difference	O
,	O
we	O
use	O
NME	B-Method
,	O
averaged	B-Metric
per	I-Metric
-	I-Metric
vertex	I-Metric
errors	I-Metric
between	O
the	O
recovered	O
and	O
groundtruth	O
shapes	O
,	O
normalized	O
by	O
inter	O
-	O
ocular	O
distances	O
.	O
	
Our	O
nonlinear	B-Method
model	O
has	O
a	O
significantly	O
smaller	O
reconstruction	B-Metric
error	I-Metric
than	O
the	O
linear	B-Method
model	I-Method
,	O
vs.	O
(	O
Tab	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
Also	O
,	O
the	O
non	O
-	O
linear	B-Method
models	I-Method
are	O
more	O
compact	O
.	O
	
They	O
can	O
achieve	O
similar	O
performances	O
as	O
linear	B-Method
models	I-Method
whose	O
latent	O
spaceâs	O
sizes	O
doubled	O
.	O
	
subsection	O
:	O
Applications	O
	
Having	O
shown	O
the	O
capability	O
of	O
our	O
nonlinear	B-Method
3DMM	I-Method
(	O
i.e.	O
,	O
two	O
decoders	B-Method
)	O
,	O
now	O
we	O
demonstrate	O
the	O
applications	O
of	O
our	O
entire	O
network	O
,	O
which	O
has	O
the	O
additional	O
encoder	O
.	O
	
Many	O
applications	O
of	O
3DMM	B-Method
are	O
centered	O
on	O
its	O
ability	O
to	O
fit	O
to	O
2D	O
face	O
images	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
visualizes	O
our	O
3DMM	B-Method
fitting	O
results	O
on	O
CelebA	O
dataset	O
.	O
	
Our	O
encoder	B-Method
estimates	O
the	O
shape	O
,	O
texture	O
as	O
well	O
as	O
projection	O
parameter	O
.	O
	
We	O
can	O
recover	O
personal	O
facial	O
characteristic	O
in	O
both	O
shape	O
and	O
texture	O
.	O
	
Our	O
texture	O
can	O
have	O
variety	O
skin	O
color	O
or	O
facial	O
hair	O
,	O
which	O
is	O
normally	O
hard	O
to	O
be	O
recovered	O
by	O
linear	B-Method
3DMM	I-Method
.	O
	
2D	B-Task
Face	I-Task
Alignment	I-Task
.	O
	
Face	B-Task
alignment	I-Task
is	O
a	O
critical	O
step	O
for	O
any	O
facial	B-Task
analysis	I-Task
task	I-Task
such	O
as	O
face	B-Task
recognition	I-Task
.	O
	
With	O
enhancement	O
in	O
the	O
modeling	B-Task
,	O
we	O
hope	O
to	O
improve	O
this	O
task	O
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
We	O
compare	O
face	B-Task
alignment	I-Task
performance	O
with	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
,	O
SDM	B-Method
and	O
3DDFA	B-Method
,	O
on	O
the	O
AFLW2000	B-Material
dataset	I-Material
.	O
	
The	O
alignment	B-Metric
accuracy	I-Metric
is	O
evaluated	O
by	O
the	O
Normalized	B-Metric
Mean	I-Metric
Error	I-Metric
(	O
NME	B-Method
)	O
,	O
the	O
average	B-Metric
of	I-Metric
visible	I-Metric
landmark	I-Metric
error	I-Metric
normalized	O
by	O
the	O
bounding	O
box	O
size	O
.	O
	
Here	O
,	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
3DDFA	B-Method
is	O
a	O
cascade	B-Method
of	I-Method
CNNs	I-Method
that	O
iteratively	O
refines	O
its	O
estimation	O
in	O
multiple	O
steps	O
,	O
meanwhile	O
ours	O
is	O
a	O
single	O
-	O
pass	O
of	O
and	O
.	O
	
However	O
,	O
by	O
jointly	O
learning	O
model	B-Method
fitting	I-Method
with	O
3DMM	B-Method
,	O
our	O
network	O
can	O
surpass	O
’s	O
performance	O
,	O
as	O
in	O
Tab	O
.	O
	
[	O
reference	O
]	O
.	O
	
Another	O
perspective	O
is	O
that	O
in	O
conventional	O
3DMM	B-Method
fitting	O
,	O
the	O
texture	O
is	O
used	O
as	O
the	O
input	O
to	O
regress	O
the	O
shape	O
parameter	O
,	O
while	O
ours	O
adopts	O
an	O
analysis	B-Method
-	I-Method
by	I-Method
-	I-Method
synthesis	I-Method
scheme	I-Method
and	O
texture	O
is	O
the	O
output	O
of	O
the	O
synthesis	O
.	O
	
Further	O
,	O
for	O
a	O
more	O
fair	O
comparison	O
of	O
nonlinear	B-Method
vs.	O
linear	B-Method
models	I-Method
,	O
we	O
train	O
an	O
encoder	B-Method
with	O
the	O
same	O
architecture	O
as	O
our	O
,	O
whose	O
output	O
parameter	O
will	O
multiple	O
with	O
the	O
linear	O
shape	O
bases	O
,	O
and	O
train	O
with	O
the	O
landmark	O
loss	O
function	O
(	O
Eqn	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
Again	O
we	O
observe	O
the	O
higher	O
error	O
from	O
the	O
linear	B-Method
model	I-Method
-	O
based	O
fitting	O
.	O
	
3D	B-Task
Face	I-Task
Reconstruction	I-Task
.	O
	
We	O
compare	O
our	O
approach	O
to	O
recent	O
works	O
:	O
the	O
CNN	B-Method
-	I-Method
based	I-Method
iterative	I-Method
supervised	I-Method
regressor	I-Method
of	O
Richardson	O
et	O
al	O
.	O
and	O
unsupervised	B-Method
regressor	I-Method
method	I-Method
of	O
Tewari	O
et	O
al	O
.	O
.	O
	
The	O
work	O
by	O
Tewari	O
et	O
al	O
.	O
is	O
relevant	O
to	O
us	O
as	O
they	O
also	O
learn	O
to	O
fit	O
3DMM	B-Method
in	O
an	O
unsupervised	B-Method
fashion	I-Method
.	O
	
However	O
,	O
they	O
are	O
limited	O
to	O
linear	O
3DMM	B-Method
bases	O
,	O
which	O
of	O
course	O
are	O
not	O
jointly	O
trained	O
with	O
the	O
model	O
.	O
	
Also	O
,	O
we	O
only	O
compare	O
with	O
the	O
coarse	B-Method
network	I-Method
in	O
as	O
their	O
refinement	B-Method
network	I-Method
use	O
SfS	B-Method
,	O
which	O
leads	O
to	O
a	O
2.5D	B-Method
representation	I-Method
and	O
loses	O
correspondence	O
between	O
different	O
3D	O
shapes	O
.	O
	
This	O
is	O
orthogonal	O
to	O
our	O
approach	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
visual	O
comparison	O
.	O
	
Following	O
the	O
same	O
setting	O
in	O
,	O
we	O
also	O
quantitatively	O
compare	O
our	O
method	O
with	O
prior	O
works	O
on	O
subjects	O
of	O
FaceWarehouse	O
database	O
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
We	O
achieve	O
on	O
-	O
par	O
results	O
with	O
Garrido	O
et	O
al	O
.	O
,	O
an	O
offline	B-Method
optimization	I-Method
method	I-Method
,	O
while	O
surpassing	O
all	O
other	O
regression	B-Method
methods	I-Method
.	O
	
subsection	O
:	O
Ablation	O
on	O
Texture	B-Task
Learning	I-Task
	
With	O
great	O
representation	O
power	O
,	O
we	O
would	O
like	O
to	O
learn	O
a	O
realistic	O
texture	B-Method
model	I-Method
from	O
in	O
-	O
the	O
-	O
wild	O
images	O
.	O
	
The	O
rendering	B-Method
layer	I-Method
opens	O
a	O
possibility	O
to	O
apply	O
adversarial	O
loss	O
in	O
addition	O
to	O
global	O
loss	O
.	O
	
Using	O
a	O
global	B-Method
image	I-Method
-	I-Method
based	I-Method
discriminator	I-Method
is	O
redundant	O
as	O
the	O
global	O
structure	O
is	O
guaranteed	O
by	O
the	O
rendering	B-Method
layer	I-Method
.	O
	
Also	O
,	O
we	O
empirically	O
find	O
that	O
using	O
global	B-Method
image	I-Method
-	I-Method
based	I-Method
discriminator	I-Method
can	O
cause	O
severe	O
artifacts	O
in	O
the	O
resultant	O
texture	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
visualizes	O
outputs	O
of	O
our	O
network	O
with	O
different	O
options	O
of	O
adversarial	O
loss	O
.	O
	
Clearly	O
,	O
patchGAN	B-Method
offers	O
higher	O
realism	O
and	O
fewer	O
artifacts	O
.	O
	
section	O
:	O
Conclusions	O
	
Since	O
its	O
debut	O
in	O
1999	O
,	O
3DMM	B-Method
has	O
became	O
a	O
cornerstone	O
of	O
facial	B-Task
analysis	I-Task
research	I-Task
with	O
applications	O
to	O
many	O
problems	O
.	O
	
Despite	O
its	O
impact	O
,	O
it	O
has	O
drawbacks	O
in	O
requiring	O
training	O
data	O
of	O
3D	O
scans	O
,	O
learning	O
from	O
controlled	O
2D	O
images	O
,	O
and	O
limited	O
representation	O
power	O
due	O
to	O
linear	B-Method
bases	I-Method
.	O
	
These	O
drawbacks	O
could	O
be	O
formidable	O
when	O
fitting	O
3DMM	B-Method
to	O
unconstrained	B-Task
faces	I-Task
,	O
or	O
learning	O
3DMM	B-Method
for	O
generic	B-Task
objects	I-Task
such	O
as	O
shoes	O
.	O
	
This	O
paper	O
demonstrates	O
that	O
there	O
exists	O
an	O
alternative	O
approach	O
to	O
3DMM	B-Method
learning	O
,	O
where	O
a	O
nonlinear	B-Method
3DMM	I-Method
can	O
be	O
learned	O
from	O
a	O
large	O
set	O
of	O
unconstrained	O
face	O
images	O
without	O
collecting	O
3D	O
face	O
scans	O
.	O
	
Further	O
,	O
the	O
model	B-Method
fitting	I-Method
algorithm	I-Method
can	O
be	O
learnt	O
jointly	O
with	O
3DMM	B-Method
,	O
in	O
an	O
end	O
-	O
to	O
-	O
end	O
fashion	O
.	O
	
Our	O
experiments	O
cover	O
a	O
diverse	O
aspects	O
of	O
our	O
learnt	B-Method
model	I-Method
,	O
some	O
of	O
which	O
might	O
need	O
the	O
subjective	O
judgment	O
of	O
the	O
readers	O
.	O
	
We	O
hope	O
that	O
both	O
the	O
judgment	O
and	O
quantitative	O
results	O
could	O
be	O
viewed	O
under	O
the	O
context	O
that	O
,	O
unlike	O
linear	B-Method
3DMM	I-Method
,	O
no	O
genuine	O
3D	O
scans	O
are	O
used	O
in	O
our	O
learning	O
.	O
	
Finally	O
,	O
we	O
believe	O
that	O
unsupervisedly	B-Method
learning	I-Method
3D	I-Method
models	I-Method
from	O
large	B-Task
-	I-Task
scale	I-Task
in	I-Task
-	I-Task
the	I-Task
-	I-Task
wild	I-Task
2D	I-Task
images	I-Task
is	O
one	O
promising	O
research	O
direction	O
.	O
	
This	O
work	O
is	O
one	O
step	O
along	O
this	O
direction	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
M	B-Method
-	I-Method
Walk	I-Method
:	O
Learning	O
to	O
Walk	B-Task
over	I-Task
Graphs	I-Task
using	O
Monte	B-Method
Carlo	I-Method
Tree	I-Method
Search	I-Method
	
Learning	O
to	O
walk	O
over	O
a	O
graph	O
towards	O
a	O
target	O
node	O
for	O
a	O
given	O
query	O
and	O
a	O
source	O
node	O
is	O
an	O
important	O
problem	O
in	O
applications	O
such	O
as	O
knowledge	B-Task
base	I-Task
completion	I-Task
(	O
KBC	B-Task
)	I-Task
.	O
	
It	O
can	O
be	O
formulated	O
as	O
a	O
reinforcement	B-Method
learning	I-Method
(	I-Method
RL	I-Method
)	I-Method
problem	I-Method
with	O
a	O
known	B-Method
state	I-Method
transition	I-Method
model	I-Method
.	O
	
To	O
overcome	O
the	O
challenge	O
of	O
sparse	O
rewards	O
,	O
we	O
develop	O
a	O
graph	B-Method
-	I-Method
walking	I-Method
agent	I-Method
called	O
M	B-Method
-	I-Method
Walk	I-Method
,	O
which	O
consists	O
of	O
a	O
deep	B-Method
recurrent	I-Method
neural	I-Method
network	I-Method
(	O
RNN	B-Method
)	O
and	O
Monte	B-Method
Carlo	I-Method
Tree	I-Method
Search	I-Method
(	O
MCTS	B-Method
)	O
.	O
	
The	O
RNN	B-Method
encodes	O
the	O
state	O
(	O
i.e.	O
,	O
history	O
of	O
the	O
walked	O
path	O
)	O
and	O
maps	O
it	O
separately	O
to	O
a	O
policy	O
and	O
Q	O
-	O
values	O
.	O
	
In	O
order	O
to	O
effectively	O
train	O
the	O
agent	O
from	O
sparse	O
rewards	O
,	O
we	O
combine	O
MCTS	B-Method
with	O
the	O
neural	B-Method
policy	I-Method
to	O
generate	O
trajectories	O
yielding	O
more	O
positive	O
rewards	O
.	O
	
From	O
these	O
trajectories	O
,	O
the	O
network	O
is	O
improved	O
in	O
an	O
off	B-Method
-	I-Method
policy	I-Method
manner	I-Method
using	O
Q	B-Method
-	I-Method
learning	I-Method
,	O
which	O
modifies	O
the	O
RNN	B-Method
policy	I-Method
via	O
parameter	B-Method
sharing	I-Method
.	O
	
Our	O
proposed	O
RL	B-Method
algorithm	I-Method
repeatedly	O
applies	O
this	O
policy	B-Method
-	I-Method
improvement	I-Method
step	I-Method
to	O
learn	O
the	O
model	O
.	O
	
At	O
test	O
time	O
,	O
MCTS	B-Method
is	O
combined	O
with	O
the	O
neural	B-Method
policy	I-Method
to	O
predict	O
the	O
target	O
node	O
.	O
	
Experimental	O
results	O
on	O
several	O
graph	B-Method
-	I-Method
walking	I-Method
benchmarks	I-Method
show	O
that	O
M	B-Method
-	I-Method
Walk	I-Method
is	O
able	O
to	O
learn	O
better	O
policies	O
than	O
other	O
RL	B-Method
-	I-Method
based	I-Method
methods	I-Method
,	O
which	O
are	O
mainly	O
based	O
on	O
policy	O
gradients	O
.	O
	
M	B-Method
-	I-Method
Walk	I-Method
also	O
outperforms	O
traditional	O
KBC	B-Method
baselines	I-Method
.	O
	
section	O
:	O
Introduction	O
	
We	O
consider	O
the	O
problem	O
of	O
learning	B-Task
to	O
walk	O
over	O
a	O
graph	O
in	O
order	O
to	O
find	O
a	O
target	O
node	O
for	O
a	O
given	O
source	O
node	O
and	O
a	O
query	O
.	O
	
Such	O
problems	O
appear	O
in	O
,	O
for	O
example	O
,	O
knowledge	B-Task
base	I-Task
completion	I-Task
(	O
KBC	B-Task
)	O
.	O
	
A	O
knowledge	B-Method
graph	I-Method
is	O
a	O
structured	O
representation	O
of	O
world	O
knowledge	O
in	O
the	O
form	O
of	O
entities	O
and	O
their	O
relations	O
(	O
e.g.	O
,	O
Figure	O
[	O
reference	O
]	O
)	O
,	O
and	O
has	O
a	O
wide	O
range	O
of	O
downstream	B-Task
applications	I-Task
such	O
as	O
question	B-Task
answering	I-Task
.	O
	
Although	O
a	O
typical	O
knowledge	O
graph	O
may	O
contain	O
millions	O
of	O
entities	O
and	O
billions	O
of	O
relations	O
,	O
it	O
is	O
usually	O
far	O
from	O
complete	O
.	O
	
KBC	B-Method
aims	O
to	O
predict	O
the	O
missing	O
relations	O
between	O
entities	O
using	O
information	O
from	O
the	O
existing	O
knowledge	O
graph	O
.	O
	
More	O
formally	O
,	O
let	O
denote	O
a	O
graph	O
,	O
which	O
consists	O
of	O
a	O
set	O
of	O
nodes	O
,	O
,	O
and	O
a	O
set	O
of	O
edges	O
,	O
,	O
that	O
connect	O
the	O
nodes	O
,	O
and	O
let	O
denote	O
an	O
input	O
query	O
.	O
	
The	O
problem	O
is	O
stated	O
as	O
using	O
the	O
graph	O
,	O
the	O
source	O
node	O
and	O
the	O
query	O
as	O
inputs	O
to	O
predict	O
the	O
target	O
node	O
.	O
	
In	O
KBC	B-Task
tasks	I-Task
,	O
is	O
a	O
given	O
knowledge	O
graph	O
,	O
is	O
a	O
collection	O
of	O
entities	O
(	O
nodes	O
)	O
,	O
and	O
is	O
a	O
set	O
of	O
relations	O
(	O
edges	O
)	O
that	O
connect	O
the	O
entities	O
.	O
	
In	O
the	O
example	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
the	O
objective	O
of	O
KBC	B-Method
is	O
to	O
identify	O
the	O
target	O
node	O
=	O
	
USA	O
for	O
the	O
given	O
head	O
entity	O
=	O
	
Obama	O
and	O
the	O
given	O
query	O
=	O
	
Citizenship	O
.	O
	
The	O
problem	O
can	O
also	O
be	O
understood	O
as	O
constructing	O
a	O
function	O
to	O
predict	O
,	O
where	O
the	O
functional	O
form	O
of	O
is	O
generally	O
unknown	O
and	O
has	O
to	O
be	O
learned	O
from	O
a	O
training	O
dataset	O
consisting	O
of	O
samples	O
like	O
.	O
	
In	O
this	O
work	O
,	O
we	O
model	O
by	O
means	O
of	O
a	O
graph	B-Method
-	I-Method
walking	I-Method
agent	I-Method
that	O
intelligently	O
navigates	O
through	O
a	O
subset	O
of	O
nodes	O
in	O
the	O
graph	O
from	O
towards	O
.	O
	
Since	O
is	O
unknown	O
,	O
the	O
problem	O
can	O
not	O
be	O
solved	O
by	O
conventional	O
search	B-Method
algorithms	I-Method
such	O
as	O
-	B-Method
search	I-Method
,	O
which	O
seeks	O
to	O
find	O
paths	O
between	O
the	O
given	O
source	O
and	O
target	O
nodes	O
.	O
	
Instead	O
,	O
the	O
agent	O
needs	O
to	O
learn	O
its	O
search	B-Method
policy	I-Method
from	O
the	O
training	O
dataset	O
so	O
that	O
,	O
after	O
training	O
is	O
complete	O
,	O
the	O
agent	O
knows	O
how	O
to	O
walk	O
over	O
the	O
graph	O
to	O
reach	O
the	O
correct	O
target	O
node	O
for	O
an	O
unseen	O
pair	O
of	O
.	O
	
Moreover	O
,	O
each	O
training	O
sample	O
is	O
in	O
the	O
form	O
of	O
‘	O
	
‘	O
	
(	O
source	O
node	O
,	O
query	O
,	O
target	O
node	O
)	O
’	O
’	O
,	O
and	O
there	O
is	O
no	O
intermediate	O
supervision	O
for	O
the	O
correct	O
search	O
path	O
.	O
	
Instead	O
,	O
the	O
agent	O
receives	O
only	O
delayed	O
evaluative	O
feedback	O
:	O
when	O
the	O
agent	O
correctly	O
(	O
or	O
incorrectly	O
)	O
predicts	O
the	O
target	O
node	O
in	O
the	O
training	O
set	O
,	O
the	O
agent	O
will	O
receive	O
a	O
positive	O
(	O
or	O
zero	O
)	O
reward	O
.	O
	
For	O
this	O
reason	O
,	O
we	O
formulate	O
the	O
problem	O
as	O
a	O
Markov	B-Method
decision	I-Method
process	I-Method
(	O
MDP	B-Method
)	O
and	O
train	O
the	O
agent	O
by	O
reinforcement	B-Method
learning	I-Method
(	O
RL	B-Method
)	O
.	O
	
The	O
problem	O
poses	O
two	O
major	O
challenges	O
.	O
	
Firstly	O
,	O
since	O
the	O
state	O
of	O
the	O
MDP	B-Method
is	O
the	O
entire	O
trajectory	O
,	O
reaching	O
a	O
correct	O
decision	O
usually	O
requires	O
not	O
just	O
the	O
query	O
,	O
but	O
also	O
the	O
entire	O
history	O
of	O
traversed	O
nodes	O
.	O
	
For	O
the	O
KBC	O
example	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
having	O
access	O
to	O
the	O
current	O
node	O
=	O
Hawaii	O
alone	O
is	O
not	O
sufficient	O
to	O
know	O
that	O
the	O
best	O
action	O
is	O
moving	O
to	O
=	O
USA	O
.	O
	
Instead	O
,	O
the	O
agent	O
must	O
track	O
the	O
entire	O
history	O
,	O
including	O
the	O
input	O
query	O
=	O
	
Citizenship	O
,	O
to	O
reach	O
this	O
decision	O
.	O
	
Secondly	O
,	O
the	O
reward	O
is	O
sparse	O
,	O
being	O
received	O
only	O
at	O
the	O
end	O
of	O
a	O
search	O
path	O
,	O
for	O
instance	O
,	O
after	O
correctly	O
predicting	O
=	O
USA	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
develop	O
a	O
neural	B-Method
graph	I-Method
-	I-Method
walking	I-Method
agent	I-Method
,	O
named	O
M	B-Method
-	I-Method
Walk	I-Method
,	O
that	O
effectively	O
addresses	O
these	O
two	O
challenges	O
.	O
	
First	O
,	O
M	B-Method
-	I-Method
Walk	I-Method
uses	O
a	O
novel	O
recurrent	B-Method
neural	I-Method
network	I-Method
(	I-Method
RNN	I-Method
)	I-Method
architecture	I-Method
to	O
encode	O
the	O
entire	O
history	O
of	O
the	O
trajectory	O
into	O
a	O
vector	B-Method
representation	I-Method
,	O
which	O
is	O
further	O
used	O
to	O
model	O
the	O
policy	B-Method
and	O
the	O
Q	B-Method
-	I-Method
function	I-Method
.	O
	
Second	O
,	O
to	O
address	O
the	O
challenge	O
of	O
sparse	B-Task
rewards	I-Task
,	O
M	B-Method
-	I-Method
Walk	I-Method
exploits	O
the	O
fact	O
that	O
the	O
MDP	B-Method
transition	I-Method
model	I-Method
is	O
known	O
and	O
deterministic	O
.	O
	
Specifically	O
,	O
it	O
combines	O
Monte	B-Method
Carlo	I-Method
Tree	I-Method
Search	I-Method
(	O
MCTS	B-Method
)	O
with	O
the	O
RNN	B-Method
to	O
generate	O
trajectories	O
that	O
obtain	O
significantly	O
more	O
positive	O
rewards	O
than	O
using	O
the	O
RNN	B-Method
policy	I-Method
alone	O
.	O
	
These	O
trajectories	O
can	O
be	O
viewed	O
as	O
being	O
generated	O
from	O
an	O
improved	O
version	O
of	O
the	O
RNN	B-Method
policy	I-Method
.	O
	
But	O
while	O
these	O
trajectories	O
can	O
improve	O
the	O
RNN	B-Method
policy	I-Method
,	O
their	O
off	B-Method
-	I-Method
policy	I-Method
nature	I-Method
prevents	O
them	O
from	O
being	O
leveraged	O
by	O
policy	B-Method
gradient	I-Method
RL	I-Method
methods	I-Method
.	O
	
To	O
solve	O
this	O
problem	O
,	O
we	O
design	O
a	O
structure	O
for	O
sharing	O
parameters	O
between	O
the	O
Q	B-Method
-	I-Method
value	I-Method
network	I-Method
and	O
the	O
RNN	B-Method
’s	I-Method
policy	I-Method
network	I-Method
.	O
	
This	O
allows	O
the	O
policy	B-Method
network	I-Method
to	O
be	O
indirectly	O
improved	O
through	O
Q	B-Method
-	I-Method
learning	I-Method
over	O
the	O
off	O
-	O
policy	O
trajectories	O
.	O
	
Our	O
method	O
is	O
in	O
sharp	O
contrast	O
to	O
existing	O
RL	B-Method
-	I-Method
based	I-Method
methods	I-Method
for	O
KBC	B-Method
,	O
which	O
use	O
a	O
policy	B-Method
gradients	I-Method
(	I-Method
REINFORCE	I-Method
)	I-Method
method	I-Method
and	O
usually	O
require	O
a	O
large	O
number	O
of	O
rollouts	O
to	O
obtain	O
a	O
trajectory	O
with	O
a	O
positive	O
reward	O
,	O
especially	O
in	O
the	O
early	O
stages	O
of	O
learning	B-Task
.	O
	
Experimental	O
results	O
on	O
several	O
benchmarks	O
,	O
including	O
a	O
synthetic	B-Task
task	I-Task
and	O
several	O
real	B-Task
-	I-Task
world	I-Task
KBC	I-Task
tasks	I-Task
,	O
show	O
that	O
our	O
approach	O
learns	O
better	O
policies	O
than	O
previous	O
RL	B-Method
-	I-Method
based	I-Method
methods	I-Method
and	O
traditional	O
KBC	B-Method
methods	I-Method
.	O
	
The	O
rest	O
of	O
the	O
paper	O
is	O
organized	O
as	O
follows	O
:	O
Section	O
[	O
reference	O
]	O
develops	O
the	O
M	B-Method
-	I-Method
Walk	I-Method
agent	O
,	O
including	O
the	O
model	B-Method
architecture	I-Method
,	O
the	O
training	B-Method
and	I-Method
testing	I-Method
algorithms	I-Method
.	O
	
Experimental	O
results	O
are	O
presented	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Finally	O
,	O
we	O
discuss	O
related	O
work	O
in	O
Section	O
[	O
reference	O
]	O
and	O
conclude	O
the	O
paper	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
Graph	B-Task
Walking	I-Task
as	O
a	O
Markov	B-Method
Decision	I-Method
Process	I-Method
	
In	O
this	O
section	O
,	O
we	O
formulate	O
the	O
graph	B-Task
-	I-Task
walking	I-Task
problem	I-Task
as	O
a	O
Markov	B-Method
Decision	I-Method
Process	I-Method
(	O
MDP	B-Method
)	I-Method
,	O
which	O
is	O
defined	O
by	O
the	O
tuple	O
,	O
where	O
is	O
the	O
set	O
of	O
states	O
,	O
is	O
the	O
set	O
of	O
actions	O
,	O
is	O
the	O
reward	O
function	O
,	O
and	O
is	O
the	O
state	O
transition	O
probability	O
.	O
	
We	O
further	O
define	O
,	O
,	O
and	O
below	O
.	O
	
Figure	O
[	O
reference	O
]	O
illustrates	O
the	O
MDP	B-Method
corresponding	O
to	O
the	O
KBC	O
example	O
of	O
Figure	O
[	O
reference	O
]	O
.	O
	
Let	O
denote	O
the	O
state	O
at	O
time	O
.	O
	
Recalling	O
that	O
the	O
agent	O
needs	O
the	O
entire	O
history	O
of	O
traversed	O
nodes	O
and	O
the	O
query	O
to	O
make	O
a	O
correct	O
decision	O
,	O
we	O
define	O
by	O
the	O
following	O
recursion	O
:	O
where	O
denotes	O
the	O
action	O
selected	O
by	O
the	O
agent	O
at	O
time	O
,	O
denotes	O
the	O
currently	O
visited	O
node	O
at	O
time	O
,	O
is	O
the	O
set	O
of	O
all	O
edges	O
connected	O
to	O
,	O
and	O
is	O
the	O
set	O
of	O
all	O
nodes	O
connected	O
to	O
(	O
i.e.	O
,	O
the	O
neighborhood	O
)	O
.	O
	
Note	O
that	O
state	O
is	O
a	O
collection	O
of	O
(	O
i	O
)	O
all	O
the	O
traversed	O
nodes	O
(	O
along	O
with	O
their	O
edges	O
and	O
neighborhoods	O
)	O
up	O
to	O
time	O
,	O
(	O
ii	O
)	O
all	O
the	O
previously	O
selected	O
(	O
up	O
to	O
time	O
)	O
actions	O
,	O
and	O
(	O
iii	O
)	O
the	O
initial	O
query	O
.	O
	
The	O
set	O
consists	O
of	O
all	O
the	O
possible	O
values	O
of	O
.	O
	
Based	O
on	O
,	O
the	O
agent	O
takes	O
one	O
of	O
the	O
following	O
actions	O
at	O
each	O
time	O
:	O
(	O
i	O
)	O
choosing	O
an	O
edge	O
in	O
and	O
moving	O
to	O
the	O
next	O
node	O
,	O
or	O
(	O
ii	O
)	O
terminating	O
the	O
walk	O
(	O
denoted	O
as	O
the	O
‘	O
‘	O
STOP	O
’	O
’	O
action	O
)	O
.	O
	
Once	O
the	O
STOP	O
action	O
is	O
selected	O
,	O
the	O
MDP	B-Method
reaches	O
the	O
terminal	O
state	O
and	O
outputs	O
as	O
a	O
prediction	O
of	O
the	O
target	O
node	O
.	O
	
Therefore	O
,	O
we	O
define	O
the	O
set	O
of	O
feasible	O
actions	O
at	O
time	O
as	O
,	O
which	O
is	O
usually	O
time	O
-	O
varying	O
.	O
	
The	O
entire	O
action	O
space	O
is	O
the	O
union	O
of	O
all	O
,	O
i.e.	O
,	O
.	O
	
Recall	O
that	O
the	O
training	O
set	O
consists	O
of	O
samples	O
in	O
the	O
form	O
of	O
.	O
	
The	O
reward	O
is	O
defined	O
to	O
be	O
when	O
the	O
predicted	O
target	O
node	O
is	O
the	O
same	O
as	O
(	O
i.e.	O
,	O
)	O
,	O
and	O
zero	O
otherwise	O
.	O
	
In	O
the	O
example	O
of	O
Figure	O
[	O
reference	O
]	O
,	O
for	O
a	O
training	O
sample	O
(	O
Obama	O
,	O
Citizenship	O
,	O
USA	O
)	O
,	O
if	O
the	O
agent	O
successfully	O
navigates	O
from	O
Obama	O
to	O
USA	O
and	O
correctly	O
predicts	O
=	O
	
USA	O
,	O
the	O
reward	O
is	O
.	O
	
Otherwise	O
,	O
it	O
will	O
be	O
.	O
	
The	O
rewards	O
are	O
sparse	O
because	O
positive	O
reward	O
can	O
be	O
received	O
only	O
at	O
the	O
end	O
of	O
a	O
correct	O
path	O
.	O
	
Furthermore	O
,	O
since	O
the	O
graph	O
is	O
known	O
and	O
static	O
,	O
the	O
MDP	O
transition	O
probability	O
is	O
known	O
and	O
deterministic	O
,	O
and	O
is	O
defined	O
by	O
(	O
[	O
reference	O
]	O
)	O
.	O
	
To	O
see	O
this	O
,	O
we	O
observe	O
from	O
Figure	O
[	O
reference	O
]	O
that	O
once	O
an	O
action	O
(	O
i.e.	O
,	O
an	O
edge	O
in	O
or	O
‘	O
‘	O
STOP	O
’	O
’	O
)	O
is	O
selected	O
,	O
the	O
next	O
node	O
and	O
its	O
associated	O
and	O
are	O
known	O
.	O
	
By	O
(	O
[	O
reference	O
]	O
)	O
	
(	O
with	O
replaced	O
by	O
)	O
,	O
this	O
means	O
that	O
the	O
next	O
state	O
is	O
determined	O
.	O
	
This	O
important	O
(	O
model	O
-	O
based	O
)	O
knowledge	O
will	O
be	O
exploited	O
to	O
overcome	O
the	O
sparse	B-Task
-	I-Task
reward	I-Task
problem	I-Task
using	O
MCTS	B-Method
and	O
significantly	O
improve	O
the	O
performance	O
of	O
our	O
method	O
(	O
see	O
	
Sections	O
[	O
reference	O
]	O
	
–	O
[	O
reference	O
]	O
below	O
)	O
.	O
	
We	O
further	O
define	O
and	O
to	O
be	O
the	O
policy	O
and	O
the	O
Q	O
-	O
function	O
,	O
respectively	O
,	O
where	O
is	O
a	O
set	O
of	O
model	O
parameters	O
.	O
	
The	O
policy	B-Method
denotes	O
the	O
probability	O
of	O
taking	O
action	O
given	O
the	O
current	O
state	O
.	O
	
In	O
M	B-Method
-	I-Method
Walk	I-Method
,	O
it	O
is	O
used	O
as	O
a	O
prior	O
to	O
bias	O
the	O
MCTS	B-Method
search	I-Method
.	O
	
And	O
defines	O
the	O
long	O
-	O
term	O
reward	O
of	O
taking	O
action	O
at	O
state	O
and	O
then	O
following	O
the	O
optimal	B-Method
policy	I-Method
thereafter	O
.	O
	
The	O
objective	O
is	O
to	O
learn	O
a	O
policy	B-Method
that	O
maximizes	O
the	O
terminal	O
rewards	O
,	O
i.e.	O
,	O
correctly	O
identifies	O
the	O
target	O
node	O
with	O
high	O
probability	O
.	O
	
We	O
now	O
proceed	O
to	O
explain	O
how	O
to	O
model	O
and	O
jointly	O
learn	O
and	O
to	O
achieve	O
this	O
objective	O
.	O
	
section	O
:	O
The	O
M	B-Method
-	I-Method
Walk	I-Method
Agent	O
	
In	O
this	O
section	O
,	O
we	O
develop	O
a	O
neural	B-Method
graph	I-Method
-	I-Method
walking	I-Method
agent	I-Method
named	O
M	B-Method
-	I-Method
Walk	I-Method
(	O
i.e.	O
,	O
MCTS	B-Method
for	O
graph	B-Task
Walking	I-Task
)	O
,	O
which	O
consists	O
of	O
(	O
i	O
)	O
a	O
novel	O
neural	B-Method
architecture	I-Method
for	O
jointly	B-Task
modeling	I-Task
and	O
,	O
and	O
(	O
ii	O
)	O
	
Monte	B-Method
Carlo	I-Method
Tree	I-Method
Search	I-Method
(	O
MCTS	B-Method
)	O
.	O
	
We	O
first	O
introduce	O
the	O
overall	O
neural	B-Method
architecture	I-Method
and	O
then	O
explain	O
how	O
MCTS	B-Method
is	O
used	O
during	O
the	O
training	B-Task
and	I-Task
testing	I-Task
stages	I-Task
.	O
	
Finally	O
,	O
we	O
describe	O
some	O
further	O
details	O
of	O
the	O
neural	B-Method
architecture	I-Method
.	O
	
Our	O
discussion	O
focuses	O
on	O
addressing	O
the	O
two	O
challenges	O
described	O
earlier	O
:	O
history	O
-	O
dependent	O
state	O
and	O
sparse	O
rewards	O
.	O
	
subsection	O
:	O
The	O
neural	B-Method
architecture	I-Method
for	O
jointly	B-Task
modeling	I-Task
and	O
	
Recall	O
from	O
Section	O
[	O
reference	O
]	O
(	O
e.g.	O
,	O
(	O
[	O
reference	O
]	O
)	O
)	O
that	O
one	O
challenge	O
in	O
applying	O
RL	B-Method
to	O
the	O
graph	B-Task
-	I-Task
walking	I-Task
problem	I-Task
is	O
that	O
the	O
state	O
nominally	O
includes	O
the	O
entire	O
history	O
of	O
observations	O
.	O
	
To	O
address	O
this	O
problem	O
,	O
we	O
propose	O
a	O
special	O
RNN	B-Method
encoding	O
the	O
state	O
at	O
each	O
time	O
into	O
a	O
vector	B-Method
representation	I-Method
,	O
,	O
where	O
is	O
the	O
associated	O
model	O
parameter	O
.	O
	
We	O
defer	O
the	O
discussion	O
of	O
this	O
RNN	B-Method
state	I-Method
encoder	I-Method
to	O
Section	O
[	O
reference	O
]	O
,	O
and	O
focus	O
in	O
this	O
section	O
on	O
how	O
to	O
use	O
to	O
jointly	O
model	O
and	O
.	O
	
Specifically	O
,	O
the	O
vector	O
consists	O
of	O
several	O
sub	O
-	O
vectors	O
of	O
the	O
same	O
dimension	O
:	O
,	O
and	O
.	O
	
Each	O
sub	O
-	O
vector	O
encodes	O
part	O
of	O
the	O
state	O
in	O
(	O
[	O
reference	O
]	O
)	O
.	O
	
For	O
instance	O
,	O
the	O
vector	O
encodes	O
,	O
which	O
characterizes	O
the	O
history	O
in	O
the	O
state	O
.	O
	
The	O
vector	O
encodes	O
the	O
(	O
neighboring	O
)	O
node	O
and	O
the	O
edge	O
connected	O
to	O
,	O
which	O
can	O
be	O
viewed	O
as	O
a	O
vector	B-Method
representation	I-Method
of	O
the	O
-	O
th	O
candidate	O
action	O
(	O
excluding	O
the	O
STOP	O
action	O
)	O
.	O
	
And	O
the	O
vector	O
is	O
a	O
vector	B-Task
summarization	I-Task
of	O
and	O
,	O
which	O
is	O
used	O
to	O
model	O
the	O
STOP	O
action	O
probability	O
.	O
	
In	O
summary	O
,	O
we	O
use	O
the	O
sub	O
-	O
vectors	O
to	O
model	O
and	O
according	O
to	O
:	O
where	O
denotes	O
inner	O
product	O
,	O
is	O
a	O
fully	B-Method
-	I-Method
connected	I-Method
neural	I-Method
network	I-Method
with	O
model	O
parameter	O
,	O
denotes	O
the	O
element	B-Method
-	I-Method
wise	I-Method
sigmoid	I-Method
function	I-Method
,	O
and	O
is	O
the	O
softmax	O
function	O
with	O
temperature	O
parameter	O
.	O
	
Note	O
that	O
we	O
use	O
the	O
inner	O
product	O
between	O
the	O
vectors	O
and	O
to	O
compute	O
the	O
(	O
pre	O
-	O
softmax	O
)	O
score	O
for	O
choosing	O
the	O
-	O
th	O
candidate	O
action	O
,	O
where	O
.	O
	
The	O
inner	B-Method
product	I-Method
operation	I-Method
has	O
been	O
shown	O
to	O
be	O
useful	O
in	O
modeling	O
Q	B-Task
-	I-Task
functions	I-Task
when	O
the	O
candidate	O
actions	O
are	O
described	O
by	O
vector	B-Method
representations	I-Method
and	O
in	O
solving	O
other	O
problems	O
.	O
	
Moreover	O
,	O
the	O
value	O
of	O
is	O
computed	O
by	O
using	O
and	O
,	O
where	O
gives	O
the	O
(	O
pre	O
-	O
softmax	O
)	O
score	O
for	O
choosing	O
the	O
STOP	O
action	O
.	O
	
We	O
model	O
the	O
Q	O
-	O
function	O
by	O
applying	O
element	B-Method
-	I-Method
wise	I-Method
sigmoid	I-Method
to	O
,	O
and	O
we	O
model	O
the	O
policy	O
by	O
applying	O
the	O
softmax	B-Method
operation	I-Method
to	O
the	O
same	O
set	O
of	O
.	O
	
Note	O
that	O
the	O
policy	B-Method
network	I-Method
and	O
the	O
Q	B-Method
-	I-Method
network	I-Method
share	O
the	O
same	O
set	O
of	O
model	O
parameters	O
.	O
	
We	O
will	O
explain	O
in	O
Section	O
[	O
reference	O
]	O
how	O
such	O
parameter	B-Method
sharing	I-Method
enables	O
indirect	B-Task
updates	I-Task
to	O
the	O
policy	B-Method
via	O
Q	B-Method
-	I-Method
learning	I-Method
from	O
off	O
-	O
policy	O
data	O
.	O
	
subsection	O
:	O
The	O
training	B-Method
algorithm	I-Method
	
We	O
now	O
discuss	O
how	O
to	O
train	O
the	O
model	O
parameters	O
(	O
including	O
and	O
)	O
from	O
a	O
training	O
dataset	O
using	O
reinforcement	B-Method
learning	I-Method
.	O
	
One	O
approach	O
is	O
the	O
policy	B-Method
gradient	I-Method
method	I-Method
(	O
REINFORCE	B-Method
)	I-Method
,	O
which	O
uses	O
the	O
current	O
policy	O
to	O
roll	O
out	O
multiple	O
trajectories	O
to	O
estimate	O
a	O
stochastic	O
gradient	O
,	O
and	O
then	O
updates	O
the	O
policy	O
via	O
stochastic	B-Method
gradient	I-Method
ascent	I-Method
.	O
	
Previous	O
RL	B-Method
-	I-Method
based	I-Method
KBC	I-Method
methods	I-Method
typically	O
use	O
REINFORCE	B-Method
to	O
learn	O
the	O
policy	O
.	O
	
However	O
,	O
policy	B-Method
gradient	I-Method
methods	I-Method
generally	O
suffer	O
from	O
low	B-Metric
sample	I-Metric
efficiency	I-Metric
,	O
especially	O
when	O
the	O
reward	O
signal	O
is	O
sparse	O
,	O
because	O
large	O
numbers	O
of	O
Monte	B-Method
Carlo	I-Method
rollouts	I-Method
are	O
usually	O
needed	O
to	O
obtain	O
many	O
trajectories	O
with	O
positive	O
terminal	O
reward	O
,	O
particularly	O
in	O
the	O
early	O
stages	O
of	O
learning	B-Task
.	O
	
To	O
address	O
this	O
challenge	O
,	O
we	O
develop	O
a	O
novel	O
RL	B-Method
algorithm	I-Method
that	O
uses	O
MCTS	B-Method
to	O
exploit	O
the	O
deterministic	O
MDP	O
transition	O
defined	O
in	O
(	O
[	O
reference	O
]	O
)	O
.	O
	
Specifically	O
,	O
on	O
each	O
MCTS	B-Method
simulation	I-Method
,	O
a	O
trajectory	O
is	O
rolled	O
out	O
by	O
selecting	O
actions	O
according	O
to	O
a	O
variant	O
of	O
the	O
PUCT	B-Method
algorithm	I-Method
from	O
the	O
root	O
state	O
(	O
defined	O
in	O
(	O
[	O
reference	O
]	O
)	O
)	O
:	O
where	O
is	O
the	O
policy	O
defined	O
in	O
Section	O
[	O
reference	O
]	O
,	O
and	O
are	O
two	O
constants	O
that	O
control	O
the	O
level	O
of	O
exploration	O
,	O
and	O
and	O
are	O
the	O
visit	O
count	O
and	O
the	O
total	O
action	O
reward	O
accumulated	O
on	O
the	O
-	O
th	O
edge	O
on	O
the	O
MCTS	O
tree	O
.	O
	
Overall	O
,	O
PUCT	B-Method
treats	O
as	O
a	O
prior	O
probability	O
to	O
bias	O
the	O
MCTS	B-Method
search	I-Method
;	O
PUCT	B-Method
initially	O
prefers	O
actions	O
with	O
high	O
values	O
of	O
and	O
low	O
visit	O
count	O
(	O
because	O
the	O
first	O
term	O
in	O
(	O
[	O
reference	O
]	O
)	O
is	O
large	O
)	O
,	O
but	O
then	O
asympotically	O
prefers	O
actions	O
with	O
high	O
value	O
(	O
because	O
the	O
first	O
term	O
in	O
(	O
[	O
reference	O
]	O
)	O
vanishes	O
and	O
the	O
second	O
term	O
dominates	O
)	O
.	O
	
When	O
PUCT	O
selects	O
the	O
STOP	O
action	O
or	O
the	O
maximum	O
search	O
horizon	O
has	O
been	O
reached	O
,	O
MCTS	B-Method
completes	O
one	O
simulation	O
and	O
updates	O
and	O
using	O
.	O
	
(	O
See	O
Figure	O
[	O
reference	O
]	O
for	O
an	O
example	O
and	O
Appendix	O
[	O
reference	O
]	O
for	O
more	O
details	O
.	O
)	O
	
The	O
key	O
idea	O
of	O
our	O
method	O
is	O
that	O
running	O
multiple	O
MCTS	B-Method
simulations	I-Method
generates	O
a	O
set	O
of	O
trajectories	O
with	O
more	O
positive	O
rewards	O
(	O
see	O
Section	O
[	O
reference	O
]	O
for	O
more	O
analysis	O
)	O
,	O
which	O
can	O
also	O
be	O
viewed	O
as	O
being	O
generated	O
by	O
an	O
improved	O
policy	O
.	O
	
Therefore	O
,	O
learning	O
from	O
these	O
trajectories	O
can	O
further	O
improve	O
.	O
	
Our	O
RL	B-Method
algorithm	I-Method
repeatedly	O
applies	O
this	O
policy	B-Method
-	I-Method
improvement	I-Method
step	I-Method
to	O
refine	O
the	O
policy	O
.	O
	
However	O
,	O
since	O
these	O
trajectories	O
are	O
generated	O
by	O
a	O
policy	B-Method
that	O
is	O
different	O
from	O
,	O
they	O
are	O
off	O
-	O
policy	O
data	O
,	O
breaking	O
the	O
assumptions	O
inherent	O
in	O
policy	B-Method
gradient	I-Method
methods	I-Method
.	O
	
For	O
this	O
reason	O
,	O
we	O
instead	O
update	O
the	O
Q	B-Method
-	I-Method
network	I-Method
from	O
these	O
trajectories	O
in	O
an	O
off	B-Method
-	I-Method
policy	I-Method
manner	I-Method
using	O
Q	B-Method
-	I-Method
learning	I-Method
:	O
.	O
	
Recall	O
from	O
Section	O
[	O
reference	O
]	O
	
that	O
and	O
share	O
the	O
same	O
set	O
of	O
model	O
parameters	O
;	O
once	O
the	O
Q	B-Method
-	I-Method
network	I-Method
is	O
updated	O
,	O
the	O
policy	B-Method
network	I-Method
will	O
also	O
be	O
automatically	O
improved	O
.	O
	
Finally	O
,	O
the	O
new	O
is	O
used	O
to	O
control	O
the	O
MCTS	O
in	O
the	O
next	O
iteration	O
.	O
	
The	O
main	O
idea	O
of	O
the	O
training	B-Method
algorithm	I-Method
is	O
summarized	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
subsection	O
:	O
The	O
prediction	B-Method
algorithm	I-Method
	
At	O
test	O
time	O
,	O
we	O
want	O
to	O
infer	O
the	O
target	O
node	O
for	O
an	O
unseen	O
pair	O
of	O
.	O
	
One	O
approach	O
is	O
to	O
use	O
the	O
learned	O
policy	B-Method
to	O
walk	O
through	O
the	O
graph	O
to	O
find	O
.	O
	
However	O
,	O
this	O
would	O
not	O
exploit	O
the	O
known	O
MDP	B-Method
transition	I-Method
model	I-Method
(	O
[	O
reference	O
]	O
)	O
.	O
	
Instead	O
,	O
we	O
combine	O
the	O
learned	O
and	O
with	O
MCTS	B-Method
to	O
generate	O
an	O
MCTS	O
search	O
tree	O
,	O
as	O
in	O
the	O
training	O
stage	O
.	O
	
Note	O
that	O
there	O
could	O
be	O
multiple	O
paths	O
that	O
reach	O
the	O
same	O
terminal	O
node	O
,	O
meaning	O
that	O
there	O
could	O
be	O
multiple	O
leaf	O
states	O
in	O
MCTS	O
corresponding	O
to	O
that	O
node	O
.	O
	
Therefore	O
,	O
the	O
prediction	O
results	O
from	O
these	O
MCTS	O
leaf	O
states	O
need	O
to	O
be	O
merged	O
into	O
one	O
score	O
to	O
rank	O
the	O
node	O
.	O
	
Specifically	O
,	O
we	O
use	O
,	O
where	O
is	O
the	O
total	O
number	O
of	O
MCTS	O
simulations	O
,	O
and	O
the	O
summation	O
is	O
over	O
all	O
the	O
leaf	O
states	O
that	O
correspond	O
to	O
the	O
same	O
node	O
.	O
	
is	O
a	O
weighted	O
average	O
of	O
the	O
terminal	O
state	O
values	O
associated	O
with	O
the	O
same	O
candidate	O
node	O
.	O
	
Among	O
all	O
the	O
candidates	O
nodes	O
,	O
we	O
select	O
the	O
predicted	O
target	O
node	O
to	O
be	O
the	O
one	O
with	O
the	O
highest	O
score	O
:	O
.	O
	
subsection	O
:	O
The	O
RNN	B-Method
state	I-Method
encoder	I-Method
	
We	O
now	O
discuss	O
the	O
details	O
of	O
the	O
RNN	B-Method
state	I-Method
encoder	I-Method
,	O
where	O
,	O
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Specifically	O
,	O
we	O
explain	O
how	O
the	O
sub	O
-	O
vectors	O
of	O
are	O
computed	O
.	O
	
We	O
introduce	O
as	O
an	O
auxiliary	O
variable	O
.	O
	
Then	O
,	O
the	O
state	O
in	O
(	O
[	O
reference	O
]	O
)	O
can	O
be	O
written	O
as	O
.	O
	
Note	O
that	O
the	O
state	O
is	O
composed	O
of	O
two	O
parts	O
:	O
(	O
i	O
)	O
and	O
,	O
which	O
represent	O
the	O
candidate	O
actions	O
to	O
be	O
selected	O
(	O
excluding	O
the	O
STOP	O
action	O
)	O
,	O
and	O
(	O
ii	O
)	O
,	O
which	O
represents	O
the	O
history	O
.	O
	
We	O
use	O
two	O
different	O
neural	B-Method
networks	I-Method
to	O
encode	O
these	O
separately	O
.	O
	
For	O
the	O
-	O
th	O
candidate	O
action	O
(	O
)	O
,	O
we	O
concatenate	O
with	O
its	O
associated	O
and	O
input	O
them	O
into	O
a	O
fully	B-Method
connected	I-Method
network	I-Method
(	O
FCN	B-Method
)	O
to	O
compute	O
their	O
joint	B-Method
vector	I-Method
representation	I-Method
,	O
where	O
is	O
the	O
model	O
parameter	O
.	O
	
Recall	O
that	O
the	O
action	O
space	O
can	O
be	O
time	O
-	O
varying	O
when	O
the	O
size	O
of	O
changes	O
over	O
time	O
.	O
	
To	O
address	O
this	O
issue	O
,	O
we	O
apply	O
the	O
same	O
FCN	B-Method
to	O
different	O
to	O
obtain	O
their	O
respective	O
representations	O
.	O
	
Then	O
,	O
we	O
use	O
a	O
coordinate	B-Method
-	I-Method
wise	I-Method
max	I-Method
-	I-Method
pooling	I-Method
operation	I-Method
over	O
to	O
obtain	O
a	O
(	O
fixed	O
-	O
length	O
)	O
overall	B-Method
vector	I-Method
representation	I-Method
of	I-Method
.	O
	
To	O
encode	O
,	O
we	O
call	O
upon	O
the	O
following	O
recursion	O
for	O
(	O
see	O
Appendix	O
[	O
reference	O
]	O
for	O
the	O
derivation	O
)	O
:	O
.	O
	
Inspired	O
by	O
this	O
recursion	O
,	O
we	O
propose	O
using	O
the	O
GRU	B-Method
-	I-Method
RNN	I-Method
to	O
encode	O
into	O
a	O
vector	B-Method
representation	I-Method
:	O
with	O
initialization	O
,	O
where	O
is	O
the	O
model	O
parameter	O
,	O
and	O
denotes	O
the	O
vector	O
at	O
.	O
	
We	O
use	O
and	O
computed	O
by	O
the	O
FCNs	B-Method
to	O
represent	O
and	O
,	O
respectively	O
.	O
	
Then	O
,	O
we	O
map	O
to	O
using	O
another	O
FCN	B-Method
.	O
	
section	O
:	O
Experiments	O
	
We	O
evaluate	O
and	O
analyze	O
the	O
effectiveness	O
of	O
M	B-Method
-	I-Method
Walk	I-Method
on	O
a	O
synthetic	B-Task
Three	I-Task
Glass	I-Task
Puzzle	I-Task
task	I-Task
and	O
two	O
real	B-Task
-	I-Task
world	I-Task
KBC	I-Task
tasks	I-Task
.	O
	
We	O
briefly	O
describe	O
the	O
tasks	O
here	O
,	O
and	O
give	O
the	O
experiment	O
details	O
and	O
hyperparameters	O
in	O
Appendix	O
[	O
reference	O
]	O
.	O
	
paragraph	O
:	O
Three	O
Glass	O
Puzzle	O
	
The	O
Three	B-Task
Glass	I-Task
Puzzle	I-Task
is	O
a	O
problem	O
studied	O
in	O
math	B-Task
puzzles	I-Task
and	O
graph	B-Task
theory	I-Task
.	O
	
It	O
involves	O
three	O
milk	O
containers	O
,	O
,	O
and	O
,	O
with	O
capacities	O
,	O
and	O
liters	O
,	O
respectively	O
.	O
	
The	O
containers	O
display	O
no	O
intermediate	O
markings	O
.	O
	
There	O
are	O
three	O
feasible	O
actions	O
at	O
each	O
time	O
step	O
:	O
(	O
i	O
)	O
fill	O
a	O
container	O
(	O
to	O
its	O
capacity	O
)	O
,	O
(	O
ii	O
)	O
empty	O
all	O
of	O
its	O
liquid	O
,	O
and	O
(	O
iii	O
)	O
pour	O
its	O
liquid	O
into	O
another	O
container	O
(	O
up	O
to	O
its	O
capacity	O
)	O
.	O
	
The	O
objective	O
of	O
the	O
problem	O
is	O
,	O
given	O
a	O
desired	O
volume	O
,	O
to	O
take	O
a	O
sequence	O
of	O
actions	O
on	O
the	O
three	O
containers	O
after	O
which	O
one	O
of	O
them	O
contains	O
liters	O
of	O
liquid	O
.	O
	
We	O
formulate	O
this	O
as	O
a	O
graph	B-Task
-	I-Task
walking	I-Task
problem	I-Task
;	O
in	O
the	O
graph	O
,	O
each	O
node	O
denotes	O
the	O
amounts	O
of	O
remaining	O
liquid	O
in	O
the	O
three	O
containers	O
,	O
each	O
edge	O
denotes	O
one	O
of	O
the	O
three	O
feasible	O
actions	O
,	O
and	O
the	O
input	O
query	O
is	O
the	O
desired	O
volume	O
.	O
	
The	O
reward	O
is	O
when	O
the	O
agent	O
successfully	O
fills	O
one	O
of	O
the	O
containers	O
to	O
and	O
otherwise	O
(	O
see	O
Appendix	O
[	O
reference	O
]	O
for	O
the	O
details	O
)	O
.	O
	
We	O
use	O
vanilla	B-Method
policy	I-Method
gradient	I-Method
(	O
REINFORCE	O
)	O
as	O
the	O
baseline	O
,	O
with	O
task	B-Metric
success	I-Metric
rate	I-Metric
as	O
the	O
evaluation	B-Metric
metric	I-Metric
.	O
	
paragraph	O
:	O
Knowledge	B-Task
Base	I-Task
Completion	I-Task
	
We	O
use	O
WN18RR	B-Material
and	O
NELL995	O
knowledge	O
graph	O
datasets	O
for	O
evaluation	O
.	O
	
WN18RR	B-Material
is	O
created	O
from	O
the	O
original	O
WN18	O
by	O
removing	O
various	O
sources	O
of	O
test	O
leakage	O
,	O
making	O
the	O
dataset	O
more	O
challenging	O
.	O
	
The	O
NELL995	O
dataset	O
was	O
released	O
by	O
and	O
has	O
separate	O
graphs	O
for	O
each	O
query	O
relation	O
.	O
	
We	O
use	O
the	O
same	O
data	O
split	O
and	O
preprocessing	B-Method
protocol	I-Method
as	O
in	O
for	O
WN18RR	B-Material
and	O
in	O
for	O
NELL995	O
.	O
	
As	O
in	O
,	O
we	O
study	O
the	O
10	O
relation	B-Task
tasks	I-Task
of	O
NELL995	O
separately	O
.	O
	
We	O
use	O
HITS@1	B-Metric
,	O
3	B-Metric
and	O
mean	B-Metric
reciprocal	I-Metric
rank	I-Metric
(	O
MRR	B-Metric
)	O
as	O
the	O
evaluation	B-Metric
metrics	I-Metric
for	O
WN18RR	B-Material
,	O
and	O
use	O
mean	B-Metric
average	I-Metric
precision	I-Metric
(	O
MAP	B-Metric
)	O
for	O
NELL995	O
,	O
where	O
HITS@	B-Metric
computes	O
the	O
percentage	O
of	O
the	O
desired	O
entities	O
being	O
ranked	O
among	O
the	O
top	O
-	O
list	O
,	O
and	O
MRR	B-Metric
computes	O
an	O
average	O
of	O
the	O
reciprocal	O
rank	O
of	O
the	O
desired	O
entities	O
.	O
	
We	O
compare	O
against	O
RL	B-Method
-	I-Method
based	I-Method
methods	I-Method
,	O
embedding	B-Method
-	I-Method
based	I-Method
models	I-Method
(	O
including	O
DistMult	B-Method
,	O
ComplEx	B-Method
and	I-Method
ConvE	I-Method
)	O
and	O
recent	O
work	O
in	O
logical	O
rules	O
(	O
NeuralLP	B-Method
)	O
.	O
	
For	O
all	O
the	O
baseline	O
methods	O
,	O
we	O
used	O
the	O
implementation	O
released	O
by	O
the	O
corresponding	O
authors	O
with	O
their	O
best	O
-	O
reported	O
hyperparameter	O
settings	O
.	O
	
The	O
details	O
of	O
the	O
hyperparameters	O
for	O
M	B-Method
-	I-Method
Walk	I-Method
are	O
described	O
in	O
Appendix	O
[	O
reference	O
]	O
of	O
the	O
supplementary	O
material	O
.	O
	
subsection	O
:	O
Performance	O
of	O
M	B-Method
-	I-Method
Walk	I-Method
	
We	O
first	O
report	O
the	O
overall	O
performance	O
of	O
the	O
M	B-Method
-	I-Method
Walk	I-Method
algorithm	O
on	O
the	O
three	O
tasks	O
and	O
compare	O
it	O
with	O
other	O
baseline	O
methods	O
.	O
	
We	O
ran	O
the	O
experiments	O
three	O
times	O
and	O
report	O
the	O
means	O
and	O
standard	O
deviations	O
(	O
except	O
for	O
PRA	O
,	O
TransE	O
,	O
and	O
TransR	O
on	O
NELL995	O
,	O
whose	O
results	O
are	O
directly	O
quoted	O
from	O
)	O
.	O
	
On	O
the	O
Three	B-Task
Glass	I-Task
Puzzle	I-Task
task	I-Task
,	O
M	B-Method
-	I-Method
Walk	I-Method
significantly	O
outperforms	O
the	O
baseline	O
:	O
the	O
best	O
model	O
of	O
M	B-Method
-	I-Method
Walk	I-Method
achieves	O
an	O
accuracy	B-Metric
of	O
while	O
the	O
best	O
REINFORCE	B-Method
method	I-Method
achieves	O
(	O
see	O
Appendix	O
[	O
reference	O
]	O
for	O
more	O
experiments	O
with	O
different	O
settings	O
on	O
this	O
task	O
)	O
.	O
	
For	O
the	O
two	O
KBC	B-Task
tasks	I-Task
,	O
we	O
report	O
their	O
results	O
in	O
Tables	O
[	O
reference	O
]	O
-	O
[	O
reference	O
]	O
,	O
where	O
PG	B-Method
-	I-Method
Walk	I-Method
and	O
Q	B-Method
-	I-Method
Walk	I-Method
are	O
two	O
methods	O
we	O
created	O
just	O
for	O
the	O
ablation	O
study	O
in	O
the	O
next	O
section	O
.	O
	
The	O
proposed	O
method	O
outperforms	O
previous	O
works	O
in	O
most	O
of	O
the	O
metrics	O
on	O
NELL995	O
and	O
WN18RR	B-Material
datasets	O
.	O
	
Additional	O
experiments	O
on	O
the	O
FB15k	O
-	O
237	O
dataset	O
can	O
be	O
found	O
in	O
Appendix	O
[	O
reference	O
]	O
of	O
the	O
supplementary	O
material	O
.	O
	
subsection	O
:	O
Analysis	O
of	O
M	B-Method
-	I-Method
Walk	I-Method
	
We	O
performed	O
extensive	O
experimental	O
analysis	O
to	O
understand	O
the	O
proposed	O
M	B-Method
-	I-Method
Walk	I-Method
algorithm	O
,	O
including	O
(	O
i	O
)	O
the	O
contributions	O
of	O
different	O
components	O
,	O
(	O
ii	O
)	O
its	O
ability	O
to	O
overcome	O
sparse	O
rewards	O
,	O
(	O
iii	O
)	O
hyperparameter	B-Method
analysis	I-Method
,	O
(	O
iv	O
)	O
its	O
strengths	O
and	O
weaknesses	O
compared	O
to	O
traditional	O
KBC	B-Method
methods	I-Method
,	O
and	O
(	O
v	O
)	O
its	O
running	B-Metric
time	I-Metric
.	O
	
First	O
,	O
we	O
used	O
ablation	B-Task
studies	I-Task
to	O
analyze	O
the	O
contributions	O
of	O
different	O
components	O
in	O
M	B-Method
-	I-Method
Walk	I-Method
.	O
	
To	O
understand	O
the	O
contribution	O
of	O
the	O
proposed	O
neural	B-Method
architecture	I-Method
in	O
M	B-Method
-	I-Method
Walk	I-Method
,	O
we	O
created	O
a	O
method	O
,	O
	
PG	B-Method
-	I-Method
Walk	I-Method
,	O
which	O
uses	O
the	O
same	O
neural	B-Method
architecture	I-Method
as	O
M	B-Method
-	I-Method
Walk	I-Method
but	O
with	O
the	O
same	O
training	O
(	O
PG	B-Method
)	O
and	O
testing	O
(	O
beam	B-Method
search	I-Method
)	I-Method
algorithms	I-Method
as	O
MINERVA	B-Method
.	O
	
We	O
observed	O
that	O
the	O
novel	O
neural	B-Method
architecture	I-Method
of	O
M	B-Method
-	I-Method
Walk	I-Method
contributes	O
an	O
overall	O
gain	O
relative	O
to	O
MINERVA	B-Method
on	O
NELL995	O
,	O
and	O
it	O
is	O
still	O
worse	O
than	O
M	B-Method
-	I-Method
Walk	I-Method
,	O
which	O
uses	O
MCTS	B-Method
for	O
training	O
and	O
testing	B-Task
.	O
	
To	O
further	O
understand	O
the	O
contribution	O
of	O
MCTS	B-Method
,	O
we	O
created	O
another	O
method	O
,	O
Q	B-Method
-	I-Method
Walk	I-Method
,	O
which	O
uses	O
the	O
same	O
model	B-Method
architecture	I-Method
as	O
M	B-Method
-	I-Method
Walk	I-Method
except	O
that	O
it	O
is	O
trained	O
by	O
Q	B-Method
-	I-Method
learning	I-Method
only	O
without	O
MCTS	B-Method
.	O
	
Note	O
that	O
this	O
lost	O
about	O
in	O
overall	O
performance	O
on	O
NELL995	O
.	O
	
We	O
observed	O
similar	O
trends	O
on	O
WN18RR	B-Material
.	O
	
In	O
addition	O
,	O
we	O
also	O
analyze	O
the	O
importance	O
of	O
MCTS	O
in	O
the	O
testing	B-Task
stage	I-Task
in	O
Appendix	O
[	O
reference	O
]	O
.	O
	
Second	O
,	O
we	O
analyze	O
the	O
ability	O
of	O
M	B-Method
-	I-Method
Walk	I-Method
to	O
overcome	O
the	O
sparse	B-Task
-	I-Task
reward	I-Task
problem	I-Task
.	O
	
In	O
Figure	O
[	O
reference	O
]	O
,	O
we	O
show	O
the	O
positive	B-Metric
reward	I-Metric
rate	I-Metric
(	O
i.e.	O
,	O
the	O
percentage	O
of	O
trajectories	O
with	O
positive	O
reward	O
during	O
training	O
)	O
on	O
the	O
Three	O
Glass	B-Task
Puzzle	I-Task
task	I-Task
and	O
the	O
NELL995	O
tasks	O
.	O
	
Compared	O
to	O
the	O
policy	B-Method
gradient	I-Method
method	I-Method
(	O
PG	B-Method
-	I-Method
Walk	I-Method
)	O
,	O
and	O
Q	B-Method
-	I-Method
learning	I-Method
method	I-Method
(	O
Q	B-Method
-	I-Method
Walk	I-Method
)	I-Method
methods	I-Method
under	O
the	O
same	O
model	B-Method
architecture	I-Method
,	O
M	B-Method
-	I-Method
Walk	I-Method
with	O
MCTS	B-Method
is	O
able	O
to	O
generate	O
trajectories	O
with	O
more	O
positive	O
rewards	O
,	O
and	O
this	O
continues	O
to	O
improve	O
as	O
training	O
progresses	O
.	O
	
This	O
confirms	O
our	O
motivation	O
of	O
using	O
MCTS	B-Method
to	O
generate	O
higher	O
-	O
quality	O
trajectories	O
to	O
alleviate	O
the	O
sparse	B-Task
-	I-Task
reward	I-Task
problem	I-Task
in	O
graph	B-Task
walking	I-Task
.	O
	
Third	O
,	O
we	O
analyze	O
the	O
performance	O
of	O
M	B-Method
-	I-Method
Walk	I-Method
under	O
different	O
numbers	O
of	O
MCTS	B-Method
rollout	I-Method
simulations	I-Method
and	O
different	O
search	O
horizons	O
on	O
WN18RR	B-Material
dataset	O
,	O
with	O
results	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
We	O
observe	O
that	O
the	O
model	O
is	O
less	O
sensitive	O
to	O
search	O
horizon	O
and	O
more	O
sensitive	O
to	O
the	O
number	O
of	O
MCTS	O
rollouts	O
.	O
	
Finally	O
,	O
we	O
analyze	O
the	O
strengths	O
and	O
weaknesses	O
of	O
M	B-Method
-	I-Method
Walk	I-Method
relative	O
to	O
traditional	O
methods	O
on	O
the	O
WN18RR	B-Material
dataset	O
.	O
	
The	O
first	O
question	O
is	O
how	O
M	B-Method
-	I-Method
Walk	I-Method
performs	O
on	O
reasoning	O
paths	O
of	O
different	O
lengths	O
compared	O
to	O
baselines	O
.	O
	
To	O
answer	O
this	O
,	O
we	O
analyze	O
the	O
HITS@1	B-Metric
accuracy	I-Metric
against	O
ConvE	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
We	O
categorize	O
each	O
test	O
example	O
using	O
the	O
BFS	B-Method
(	I-Method
breadth	I-Method
-	I-Method
first	I-Method
search	I-Method
)	O
steps	O
from	O
the	O
query	O
entity	O
to	O
the	O
target	O
entity	O
(	O
-	O
1	O
means	O
not	O
reachable	O
)	O
.	O
	
We	O
observe	O
that	O
M	B-Method
-	I-Method
Walk	I-Method
outperforms	O
the	O
strong	O
baseline	O
ConvE	O
by	O
4.6–10.9	O
%	O
in	O
samples	O
that	O
require	O
2	O
or	O
3	B-Metric
steps	O
,	O
while	O
it	O
is	O
nearly	O
on	O
par	O
for	O
paths	O
of	O
length	O
one	O
.	O
	
Therefore	O
,	O
M	B-Method
-	I-Method
Walk	I-Method
does	O
better	O
at	O
reasoning	O
over	O
longer	O
paths	O
than	O
ConvE.	O
	
Another	O
question	O
is	O
what	O
are	O
the	O
major	O
types	O
of	O
errors	O
made	O
by	O
M	B-Method
-	I-Method
Walk	I-Method
.	O
	
Recall	O
that	O
M	B-Method
-	I-Method
Walk	I-Method
only	O
walks	O
through	O
a	O
subset	O
of	O
the	O
graph	O
and	O
ranks	O
a	O
subset	O
of	O
candidate	O
nodes	O
(	O
e.g.	O
,	O
MCTS	B-Method
produces	O
about	O
20–60	O
unique	O
candidates	O
on	O
WN18RR	B-Material
)	O
.	O
	
When	O
the	O
ground	O
truth	O
is	O
not	O
in	O
the	O
candidate	O
set	O
,	O
M	B-Method
-	I-Method
Walk	I-Method
always	O
makes	O
mistakes	O
and	O
we	O
define	O
this	O
type	O
of	O
error	O
as	O
out	B-Metric
-	I-Metric
of	I-Metric
-	I-Metric
candidate	I-Metric
-	I-Metric
set	I-Metric
error	I-Metric
.	O
	
To	O
examine	O
this	O
effect	O
,	O
we	O
show	O
in	O
Figure	O
[	O
reference	O
]	O
	
-	O
top	O
the	O
HITS@K	B-Metric
accuracies	I-Metric
when	O
the	O
ground	O
truth	O
is	O
in	O
the	O
candidate	O
set	O
.	O
	
It	O
shows	O
that	O
M	B-Method
-	I-Method
Walk	I-Method
has	O
very	O
high	O
accuracy	B-Metric
in	O
this	O
case	O
,	O
which	O
is	O
significantly	O
higher	O
than	O
ConvE	O
(	O
80	O
%	O
vs	O
39.6	O
%	O
in	O
HITS@1	B-Metric
)	O
.	O
	
We	O
further	O
examine	O
the	O
percentage	O
of	O
out	O
-	O
of	O
-	O
candidate	O
-	O
set	O
errors	O
among	O
all	O
errors	O
in	O
Figure	O
[	O
reference	O
]	O
-	O
bottom	O
.	O
	
It	O
shows	O
that	O
the	O
major	O
error	O
made	O
by	O
M	B-Method
-	I-Method
Walk	I-Method
is	O
the	O
out	O
-	O
of	O
-	O
candidate	B-Metric
-	I-Metric
set	I-Metric
error	I-Metric
.	O
	
These	O
observations	O
point	O
to	O
an	O
important	O
direction	O
for	O
improving	O
M	B-Method
-	I-Method
Walk	I-Method
in	O
future	O
work	O
:	O
increasing	O
the	O
chance	O
of	O
covering	O
the	O
target	O
by	O
the	O
candidate	O
set	O
.	O
	
In	O
Table	O
[	O
reference	O
]	O
,	O
we	O
show	O
the	O
running	B-Metric
time	I-Metric
of	O
M	B-Method
-	I-Method
Walk	I-Method
(	O
in	O
-	O
house	O
C	O
++	O
&	O
Cuda	B-Method
)	O
and	O
MINERVA	B-Method
	
(	O
TensorFlow	B-Method
-	I-Method
gpu	I-Method
)	O
for	O
both	O
training	B-Task
and	O
testing	B-Task
on	O
WN18RR	B-Material
with	O
different	O
values	O
of	O
search	O
horizon	O
and	O
number	O
of	O
rollouts	O
(	O
or	O
MCTS	O
simulation	O
number	O
)	O
.	O
	
Note	O
that	O
the	O
running	B-Metric
time	I-Metric
of	O
M	B-Method
-	I-Method
Walk	I-Method
is	O
comparable	O
to	O
that	O
of	O
MINERVA	B-Method
.	O
	
Additional	O
results	O
can	O
be	O
found	O
in	O
Figure	O
[	O
reference	O
]	O
of	O
the	O
supplementary	O
material	O
.	O
	
Finally	O
,	O
in	O
Table	O
[	O
reference	O
]	O
,	O
we	O
show	O
examples	O
of	O
reasoning	O
paths	O
found	O
by	O
M	B-Method
-	I-Method
Walk	I-Method
.	O
	
section	O
:	O
Related	O
Work	O
	
paragraph	O
:	O
Reinforcement	B-Method
Learning	I-Method
	
Recently	O
,	O
deep	B-Method
reinforcement	I-Method
learning	I-Method
has	O
achieved	O
great	O
success	O
in	O
many	O
artificial	B-Task
intelligence	I-Task
problems	I-Task
.	O
	
The	O
use	O
of	O
deep	B-Method
neural	I-Method
networks	I-Method
with	O
RL	B-Method
allows	O
policies	O
to	O
be	O
learned	O
from	O
raw	O
data	O
(	O
e.g.	O
,	O
images	O
)	O
in	O
an	O
end	O
-	O
to	O
-	O
end	O
manner	O
.	O
	
Our	O
work	O
also	O
aligns	O
with	O
this	O
direction	O
.	O
	
Furthermore	O
,	O
the	O
idea	O
of	O
using	O
an	O
RNN	B-Method
to	O
encode	O
the	O
history	O
of	O
observations	O
also	O
appeared	O
in	O
.	O
	
The	O
combination	O
of	O
model	B-Method
-	I-Method
based	I-Method
and	I-Method
model	I-Method
-	I-Method
free	I-Method
information	I-Method
in	O
our	O
work	O
shares	O
the	O
same	O
spirit	O
as	O
.	O
	
Among	O
them	O
,	O
the	O
most	O
relevant	O
are	O
,	O
which	O
combine	O
MCTS	B-Method
with	O
neural	B-Method
policy	I-Method
and	O
value	B-Method
functions	I-Method
to	O
achieve	O
superhuman	O
performance	O
on	O
Go	B-Task
.	O
	
Different	O
from	O
our	O
work	O
,	O
the	O
policy	B-Method
and	O
the	O
value	B-Method
networks	I-Method
in	O
are	O
trained	O
separately	O
without	O
the	O
help	O
of	O
MCTS	B-Method
,	O
and	O
are	O
only	O
used	O
to	O
help	O
MCTS	B-Method
after	O
being	O
trained	O
.	O
	
The	O
work	O
uses	O
a	O
new	O
policy	B-Method
iteration	I-Method
method	I-Method
that	O
combines	O
the	O
neural	B-Method
policy	I-Method
and	O
value	B-Method
functions	I-Method
with	O
MCTS	B-Method
during	O
training	O
.	O
	
However	O
,	O
the	O
method	O
in	O
improves	O
the	O
policy	B-Method
network	I-Method
from	O
the	O
MCTS	O
probabilities	O
of	O
the	O
moves	O
,	O
while	O
our	O
method	O
improves	O
the	O
policy	O
from	O
the	O
trajectories	O
generated	O
by	O
MCTS	B-Method
.	O
	
Note	O
that	O
the	O
former	O
is	O
constructed	O
from	O
the	O
visit	O
counts	O
of	O
all	O
the	O
edges	O
connected	O
to	O
the	O
MCTS	O
root	O
node	O
;	O
it	O
only	O
uses	O
information	O
near	O
the	O
root	O
node	O
to	O
improve	O
the	O
policy	O
.	O
	
By	O
contrast	O
,	O
we	O
improve	O
the	O
policy	O
by	O
learning	O
from	O
the	O
trajectories	O
generated	O
by	O
MCTS	B-Method
,	O
using	O
information	O
over	O
the	O
entire	O
MCTS	O
search	O
tree	O
.	O
	
paragraph	O
:	O
Knowledge	B-Task
Base	I-Task
Completion	I-Task
	
In	O
KBC	B-Task
tasks	I-Task
,	O
early	O
work	O
focused	O
on	O
learning	O
vector	B-Task
representations	I-Task
of	I-Task
entities	I-Task
and	I-Task
relations	I-Task
.	O
	
Recent	O
approaches	O
have	O
demonstrated	O
limitations	O
of	O
these	O
prior	O
approaches	O
:	O
they	O
suffer	O
from	O
cascading	O
errors	O
when	O
dealing	O
with	O
compositional	O
(	O
multi	O
-	O
step	O
)	O
relationships	O
.	O
	
Hence	O
,	O
recent	O
works	O
have	O
proposed	O
approaches	O
for	O
injecting	O
multi	B-Task
-	I-Task
step	I-Task
paths	I-Task
such	O
as	O
random	O
walks	O
through	O
sequences	O
of	O
triples	O
during	O
training	O
,	O
further	O
improving	O
performance	O
on	O
KBC	B-Task
tasks	I-Task
.	O
	
IRN	B-Method
and	O
Neural	B-Method
LP	I-Method
explore	O
multi	O
-	O
step	O
relations	O
by	O
using	O
an	O
RNN	B-Method
controller	I-Method
with	O
attention	O
over	O
an	O
external	O
memory	O
.	O
	
Compared	O
to	O
RL	B-Method
-	I-Method
based	I-Method
approaches	I-Method
,	O
it	O
is	O
hard	O
to	O
interpret	O
the	O
traversal	O
paths	O
,	O
and	O
these	O
models	O
can	O
be	O
computationally	O
expensive	O
to	O
access	O
the	O
entire	O
graph	O
in	O
memory	O
.	O
	
Two	O
recent	O
works	O
,	O
DeepPath	B-Method
and	O
MINERVA	B-Method
,	O
use	O
RL	B-Method
-	I-Method
based	I-Method
approaches	I-Method
to	O
explore	O
paths	B-Task
in	I-Task
knowledge	I-Task
graphs	I-Task
.	O
	
DeepPath	B-Method
requires	O
target	O
entity	O
information	O
to	O
be	O
in	O
the	O
state	O
of	O
the	O
RL	B-Method
agent	I-Method
,	O
and	O
can	O
not	O
be	O
applied	O
to	O
tasks	O
where	O
the	O
target	O
entity	O
is	O
unknown	O
.	O
	
MINERVA	B-Method
uses	O
a	O
policy	B-Method
gradient	I-Method
method	I-Method
to	O
explore	O
paths	O
during	O
training	O
and	O
test	O
.	O
	
Our	O
proposed	O
model	O
further	O
exploits	O
state	O
transition	O
information	O
by	O
integrating	O
the	O
MCTS	B-Method
algorithm	I-Method
.	O
	
Empirically	O
,	O
our	O
proposed	O
algorithm	O
outperforms	O
both	O
DeepPath	B-Method
and	I-Method
MINERVA	I-Method
in	O
the	O
KBC	O
benchmarks	O
.	O
	
section	O
:	O
Conclusion	O
and	O
Discussion	O
	
We	O
developed	O
an	O
RL	B-Method
-	I-Method
agent	I-Method
(	O
M	B-Method
-	I-Method
Walk	I-Method
)	O
that	O
learns	O
to	O
walk	O
over	O
a	O
graph	O
towards	O
a	O
desired	O
target	O
node	O
for	O
given	O
input	O
query	O
and	O
source	O
nodes	O
.	O
	
Specifically	O
,	O
we	O
proposed	O
a	O
novel	O
neural	B-Method
architecture	I-Method
that	O
encodes	O
the	O
state	O
into	O
a	O
vector	B-Method
representation	I-Method
,	O
and	O
maps	O
it	O
to	O
Q	O
-	O
values	O
and	O
a	O
policy	B-Method
.	O
	
To	O
learn	O
from	O
sparse	O
rewards	O
,	O
we	O
propose	O
a	O
new	O
reinforcement	B-Method
learning	I-Method
algorithm	I-Method
,	O
which	O
alternates	O
between	O
an	O
MCTS	B-Method
trajectory	I-Method
-	I-Method
generation	I-Method
step	I-Method
and	O
a	O
policy	B-Method
-	I-Method
improvement	I-Method
step	I-Method
,	O
to	O
iteratively	O
refine	O
the	O
policy	O
.	O
	
At	O
test	O
time	O
,	O
the	O
learned	O
networks	O
are	O
combined	O
with	O
MCTS	B-Method
to	O
search	O
for	O
the	O
target	O
node	O
.	O
	
Experimental	O
results	O
on	O
several	O
benchmarks	O
demonstrate	O
that	O
our	O
method	O
learns	O
better	O
policies	O
than	O
other	O
baseline	O
methods	O
,	O
including	O
RL	B-Method
-	I-Method
based	I-Method
and	O
traditional	O
methods	O
on	O
KBC	B-Task
tasks	I-Task
.	O
	
Furthermore	O
,	O
we	O
also	O
performed	O
extensive	O
experimental	O
analysis	O
to	O
understand	O
M	B-Method
-	I-Method
Walk	I-Method
.	O
	
We	O
found	O
that	O
our	O
method	O
is	O
more	O
accurate	O
when	O
the	O
ground	O
truth	O
is	O
in	O
the	O
candidate	O
set	O
.	O
	
We	O
also	O
found	O
that	O
the	O
out	O
-	O
of	O
-	O
candidate	O
-	O
set	O
error	O
is	O
the	O
main	O
type	O
of	O
error	O
made	O
by	O
M	B-Method
-	I-Method
Walk	I-Method
.	O
	
Therefore	O
,	O
in	O
future	O
work	O
,	O
we	O
intend	O
to	O
improve	O
this	O
method	O
by	O
reducing	O
such	O
out	O
-	O
of	O
-	O
candidate	O
-	O
set	O
errors	O
.	O
	
subsection	O
:	O
Acknowledgments	O
	
We	O
thank	O
Ricky	O
Loynd	O
,	O
Adith	O
Swaminathan	O
,	O
and	O
anonymous	O
reviewers	O
for	O
their	O
valuable	O
feedback	O
.	O
	
bibliography	O
:	O
References	O
	
appendix	O
:	O
Derivation	O
of	O
the	O
recursion	O
for	O
	
Recalling	O
the	O
definition	O
and	O
using	O
the	O
recursion	O
(	O
[	O
reference	O
]	O
)	O
,	O
we	O
have	O
where	O
step	O
(	O
a	O
)	O
uses	O
the	O
definition	O
of	O
,	O
step	O
(	O
b	O
)	O
substitutes	O
the	O
recursion	O
(	O
[	O
reference	O
]	O
)	O
,	O
and	O
step	O
(	O
c	O
)	O
uses	O
the	O
definition	O
of	O
.	O
	
appendix	O
:	O
Algorithm	O
Implementation	O
Details	O
	
The	O
detailed	O
algorithm	O
of	O
M	B-Method
-	I-Method
Walk	I-Method
is	O
described	O
in	O
Algorithm	O
[	O
reference	O
]	O
.	O
	
[	O
h	O
]	O
	
[	O
1	O
]	O
Input	O
:	O
Graph	O
;	O
Initial	O
node	O
;	O
Query	O
;	O
	
Target	O
node	O
;	O
Maximum	O
Path	O
Length	O
;	O
MCTS	O
Search	O
Number	O
;	O
episode	O
in	O
Set	O
current	O
node	O
;	O
Lookup	O
from	O
dictionary	O
to	O
obtain	O
and	O
Select	O
the	O
action	O
with	O
the	O
maximum	O
PUCT	O
value	O
:	O
	
Update	O
is	O
	
STOP	O
Compute	O
estimated	O
reward	O
value	O
Add	O
generated	O
path	O
into	O
a	O
path	O
list	O
Backup	O
along	O
the	O
path	O
to	O
update	O
the	O
visit	O
count	O
using	O
(	O
[	O
reference	O
]	O
)	O
and	O
the	O
total	O
action	O
reward	O
using	O
(	O
[	O
reference	O
]	O
)	O
on	O
the	O
-	O
th	O
edge	O
on	O
the	O
MCTS	B-Method
tree	I-Method
	
Break	O
each	O
path	O
in	O
the	O
path	O
list	O
Set	O
reward	O
if	O
the	O
end	O
of	O
the	O
path	O
otherwise	O
Repeatedly	O
update	O
the	O
model	B-Method
parameters	I-Method
with	O
Q	B-Method
-	I-Method
learning	I-Method
:	O
M	B-Method
-	I-Method
Walk	I-Method
Training	O
Algorithm	O
	
subsection	O
:	O
MCTS	B-Method
implementation	I-Method
	
In	O
the	O
MCTS	B-Method
implementation	I-Method
,	O
we	O
maintain	O
a	O
lookup	O
table	O
to	O
record	O
values	O
and	O
for	O
each	O
visited	O
state	O
-	O
action	O
pair	O
.	O
	
The	O
state	O
in	O
the	O
graph	B-Task
walk	I-Task
problem	I-Task
contains	O
all	O
the	O
information	O
along	O
the	O
traversal	O
path	O
,	O
and	O
is	O
the	O
node	O
at	O
the	O
current	O
step	O
.	O
	
We	O
assign	O
an	O
index	O
to	O
each	O
candidate	O
action	O
from	O
,	O
indicating	O
that	O
is	O
the	O
-	O
th	O
action	O
of	O
the	O
node	O
.	O
	
Thus	O
,	O
the	O
state	O
can	O
be	O
encoded	O
as	O
a	O
path	O
string	O
.	O
	
We	O
build	O
a	O
dictionary	O
using	O
the	O
path	O
string	O
as	O
a	O
key	O
,	O
and	O
we	O
record	O
and	O
as	O
values	O
in	O
.	O
	
In	O
the	O
backup	O
stage	O
,	O
the	O
and	O
values	O
are	O
updated	O
for	O
each	O
state	O
-	O
action	O
pair	O
along	O
with	O
the	O
traversal	O
path	O
in	O
MCTS	B-Method
:	O
where	O
is	O
the	O
length	O
of	O
the	O
traversal	O
path	O
,	O
is	O
the	O
discount	O
factor	O
of	O
the	O
MDP	B-Method
,	O
and	O
is	O
the	O
terminal	O
state	O
-	O
value	O
function	O
modeled	O
by	O
.	O
	
In	O
our	O
experiments	O
,	O
the	O
softmax	O
temperature	O
parameter	O
in	O
the	O
policy	B-Method
network	I-Method
(	O
see	O
(	O
[	O
reference	O
]	O
)	O
)	O
is	O
set	O
to	O
be	O
a	O
constant	O
.	O
	
An	O
alternative	O
choice	O
is	O
to	O
anneal	O
it	O
during	O
training	O
(	O
e.g.	O
,	O
)	O
.	O
	
However	O
,	O
we	O
did	O
not	O
observe	O
this	O
to	O
produce	O
any	O
significant	O
difference	O
in	O
performance	O
in	O
our	O
experiments	O
.	O
	
We	O
believe	O
the	O
main	O
reason	O
is	O
that	O
is	O
only	O
used	O
as	O
a	O
prior	O
to	O
bias	O
the	O
MCTS	B-Task
search	I-Task
,	O
while	O
the	O
exploration	O
of	O
MCTS	B-Method
is	O
controlled	O
by	O
the	O
parameters	O
and	O
of	O
(	O
[	O
reference	O
]	O
)	O
.	O
	
subsection	O
:	O
Experiment	O
details	O
	
subsubsection	O
:	O
Three	O
Glass	O
Puzzle	O
	
paragraph	O
:	O
An	O
example	O
	
Figure	O
[	O
reference	O
]	O
illustrates	O
one	O
step	O
in	O
solving	O
a	O
Three	B-Task
Glass	I-Task
Puzzle	I-Task
.	O
	
The	O
following	O
action	O
sequences	O
provide	O
one	O
solution	O
to	O
achieve	O
the	O
target	O
,	O
given	O
initially	O
empty	O
containers	O
with	O
capacities	O
,	O
where	O
denote	O
the	O
current	O
contents	O
of	O
the	O
containers	O
:	O
	
Initial	O
state	O
Fill	O
Pour	O
from	O
to	O
Empty	O
Pour	O
from	O
to	O
Fill	O
Pour	O
from	O
to	O
	
paragraph	O
:	O
Data	B-Task
generation	I-Task
	
In	O
the	O
Three	O
Glass	O
Puzzle	O
experiments	O
,	O
we	O
randomly	O
draw	O
four	O
integers	O
from	O
to	O
represent	O
the	O
capacities	O
,	O
and	O
the	O
desired	O
volume	O
.	O
	
We	O
further	O
restrict	O
the	O
values	O
so	O
that	O
and	O
,	O
to	O
avoid	O
data	O
duplication	O
.	O
	
We	O
discard	O
puzzles	O
for	O
which	O
there	O
is	O
no	O
solution	O
.	O
	
Finally	O
,	O
we	O
keep	O
600	O
unique	O
puzzles	O
as	O
the	O
experimental	O
dataset	O
,	O
where	O
500	O
puzzles	O
are	O
used	O
for	O
training	O
and	O
the	O
other	O
100	O
are	O
used	O
to	O
test	O
a	O
model	O
’s	O
generalization	B-Metric
capability	I-Metric
on	O
the	O
unseen	O
test	O
set	O
.	O
	
paragraph	O
:	O
Experiment	O
settings	O
and	O
hyperparameters	O
	
Let	O
be	O
the	O
current	O
status	O
of	O
each	O
container	O
,	O
and	O
define	O
the	O
puzzle	O
status	O
at	O
step	O
as	O
,	O
where	O
is	O
the	O
one	B-Method
-	I-Method
hot	I-Method
representation	I-Method
to	O
encode	O
the	O
value	O
of	O
.	O
	
Given	O
that	O
and	O
are	O
all	O
smaller	O
than	O
in	O
the	O
experiment	O
,	O
the	O
dimension	O
of	O
is	O
300	O
.	O
	
The	O
initial	O
query	O
is	O
obtained	O
by	O
,	O
where	O
is	O
a	O
query	O
embedding	O
lookup	O
table	O
and	O
indicates	O
the	O
-	O
th	O
column	O
.	O
	
The	O
query	O
embedding	O
dimension	O
is	O
set	O
to	O
.	O
	
In	O
the	O
Three	O
Glass	O
Puzzle	O
,	O
there	O
are	O
13	O
actions	O
in	O
total	O
:	O
fill	O
one	O
container	O
to	O
its	O
capacity	O
,	O
empty	O
one	O
container	O
,	O
pour	O
one	O
container	O
into	O
another	O
container	O
,	O
and	O
a	O
STOP	O
action	O
to	O
terminate	O
the	O
game	O
.	O
	
We	O
set	O
the	O
maximum	O
length	O
of	O
an	O
action	O
sequence	O
(	O
i.e.	O
,	O
the	O
search	O
horizon	O
)	O
to	O
be	O
,	O
where	O
only	O
the	O
STOP	O
action	O
can	O
be	O
taken	O
on	O
the	O
final	O
step	O
.	O
	
After	O
the	O
STOP	O
action	O
has	O
been	O
taken	O
,	O
the	O
system	O
evaluates	O
the	O
action	O
sequence	O
and	O
assigns	O
a	O
reward	O
if	O
the	O
final	O
status	O
is	O
a	O
success	O
,	O
otherwise	O
.	O
	
The	O
and	O
functions	O
are	O
modeled	O
by	O
two	O
different	O
DNNs	B-Method
with	O
the	O
same	O
architecture	O
:	O
two	O
fully	B-Method
-	I-Method
connected	I-Method
layers	I-Method
with	O
32	O
hidden	O
dimensions	O
and	O
ReLU	O
activation	O
function	O
.	O
	
is	O
two	O
fully	B-Method
-	I-Method
connected	I-Method
layers	I-Method
with	O
16	O
hidden	O
dimensions	O
,	O
where	O
the	O
first	O
hidden	B-Method
layer	I-Method
uses	O
a	O
ReLU	B-Method
activation	I-Method
function	I-Method
and	O
the	O
output	B-Method
layer	I-Method
uses	O
a	O
linear	O
activation	O
function	O
.	O
is	O
modeled	O
by	O
a	O
GRU	B-Method
with	O
hidden	O
size	O
64	O
.	O
	
The	O
hyperparameters	O
in	O
PUCT	B-Method
are	O
set	O
to	O
and	O
.	O
	
We	O
use	O
the	O
ADAM	B-Method
optimization	I-Method
algorithm	I-Method
with	O
learning	B-Method
rate	I-Method
during	O
training	O
,	O
and	O
we	O
set	O
the	O
mini	O
-	O
batch	O
size	O
to	O
.	O
	
subsubsection	O
:	O
Knowledge	B-Task
Base	I-Task
Completion	I-Task
	
paragraph	O
:	O
Statistics	O
of	O
the	O
three	O
datasets	O
	
The	O
NELL	O
-	O
995	O
knowledge	O
dataset	O
contains	O
unique	O
entities	O
and	O
relations	O
.	O
	
WN18RR	B-Material
contains	O
triples	O
with	O
entities	O
and	O
relations	O
.	O
	
And	O
FB15k	B-Method
-	I-Method
237	I-Method
,	O
a	O
subset	O
of	O
FB15k	O
where	O
inverse	O
relations	O
are	O
removed	O
,	O
contains	O
entities	O
and	O
relations	O
.	O
	
The	O
detailed	O
statstics	O
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
paragraph	O
:	O
Experiment	O
settings	O
and	O
hyperparameters	O
	
For	O
the	O
proposed	O
M	B-Method
-	I-Method
Walk	I-Method
,	O
we	O
set	O
the	O
entity	O
embedding	O
dimension	O
to	O
and	O
relation	O
embedding	O
dimension	O
to	O
.	O
	
The	O
maximum	O
length	O
of	O
the	O
graph	O
walking	O
path	O
(	O
i.e.	O
,	O
the	O
search	O
horizon	O
)	O
is	O
in	O
the	O
NELL	O
-	O
995	O
dataset	O
and	O
in	O
the	O
WN18RR	B-Material
dataset	O
.	O
	
After	O
the	O
STOP	O
action	O
has	O
been	O
taken	O
,	O
the	O
system	O
evaluates	O
the	O
action	O
sequence	O
and	O
assigns	O
a	O
reward	O
if	O
the	O
agent	O
reaches	O
the	O
target	O
node	O
,	O
otherwise	O
.	O
	
The	O
initial	O
query	O
is	O
the	O
concatenation	O
of	O
the	O
entity	O
embedding	O
vector	O
and	O
the	O
relation	O
embedding	O
vector	O
.	O
	
The	O
and	O
functions	O
are	O
modeled	O
by	O
two	O
different	O
DNNs	B-Method
with	O
the	O
same	O
architecture	O
:	O
two	O
fully	B-Method
-	I-Method
connected	I-Method
layers	I-Method
with	O
64	O
hidden	O
dimensions	O
and	O
the	O
ReLU	B-Method
activation	I-Method
function	I-Method
.	O
	
is	O
two	O
fully	B-Method
-	I-Method
connected	I-Method
layers	I-Method
with	O
16	O
hidden	O
dimensions	O
,	O
where	O
the	O
first	O
hidden	B-Method
layer	I-Method
uses	O
a	O
Tanh	B-Method
activation	I-Method
function	I-Method
and	O
the	O
output	B-Method
layer	I-Method
uses	O
a	O
linear	O
activation	O
function	O
.	O
is	O
modeled	O
by	O
a	O
GRU	B-Method
with	O
hidden	O
size	O
64	O
.	O
	
The	O
hyperparameters	O
in	O
PUCT	B-Method
are	O
set	O
to	O
and	O
.	O
	
We	O
roll	O
out	O
MCTS	O
paths	O
in	O
both	O
training	O
and	O
testing	O
in	O
the	O
NELL	O
-	O
995	O
dataset	O
and	O
MCTS	O
paths	O
in	O
the	O
WN18RR	B-Material
dataset	O
.	O
	
We	O
use	O
the	O
ADAM	B-Method
optimization	I-Method
algorithm	I-Method
for	O
model	B-Task
training	I-Task
with	O
learning	B-Metric
rate	I-Metric
,	O
and	O
we	O
set	O
the	O
mini	O
-	O
batch	O
size	O
to	O
.	O
	
appendix	O
:	O
Additional	O
Experiments	O
	
subsection	O
:	O
The	O
Three	O
Glass	B-Task
Puzzle	I-Task
task	I-Task
in	O
different	O
settings	O
	
We	O
now	O
present	O
more	O
experiments	O
on	O
the	O
Three	O
Glass	B-Task
Puzzle	I-Task
task	I-Task
under	O
different	O
settings	O
.	O
	
First	O
,	O
to	O
see	O
how	O
fast	O
M	B-Method
-	I-Method
Walk	I-Method
converges	O
,	O
we	O
show	O
in	O
Figure	O
[	O
reference	O
]	O
the	O
learning	O
curves	O
of	O
M	B-Method
-	I-Method
Walk	I-Method
and	O
PG	B-Method
.	O
	
It	O
shows	O
that	O
M	B-Method
-	I-Method
Walk	I-Method
converges	O
much	O
faster	O
than	O
PG	B-Method
and	O
achieves	O
better	O
results	O
on	O
this	O
task	O
.	O
	
In	O
Table	O
[	O
reference	O
]	O
,	O
we	O
report	O
the	O
test	O
accuracy	B-Metric
of	O
M	B-Method
-	I-Method
Walk	I-Method
and	O
vanilla	B-Method
policy	I-Method
gradient	I-Method
(	O
REINFORCE	B-Method
/	I-Method
PG	I-Method
)	O
with	O
different	O
beam	O
search	O
sizes	O
and	O
different	O
MCTS	O
rollouts	O
during	O
testing	O
.	O
	
The	O
number	O
of	O
MCTS	B-Method
simulations	I-Method
for	O
training	O
M	B-Method
-	I-Method
Walk	I-Method
is	O
fixed	O
to	O
be	O
.	O
	
We	O
observe	O
that	O
M	B-Method
-	I-Method
Walk	I-Method
with	O
MCTS	B-Method
achieves	O
the	O
best	O
test	B-Metric
accuracy	I-Metric
overall	O
.	O
	
In	O
addition	O
,	O
with	O
larger	O
beam	O
search	O
sizes	O
and	O
MCTS	O
rollouts	O
,	O
the	O
test	B-Metric
accuracy	I-Metric
improves	O
substantially	O
.	O
	
Furthermore	O
,	O
replacing	O
the	O
MCTS	B-Method
in	O
M	B-Method
-	I-Method
Walk	I-Method
by	O
beam	B-Method
search	I-Method
at	O
test	O
time	O
degrades	O
the	O
performance	O
greatly	O
,	O
which	O
shows	O
that	O
MCTS	B-Method
is	O
also	O
very	O
important	O
for	O
M	B-Method
-	I-Method
Walk	I-Method
at	O
test	O
time	O
.	O
	
As	O
mentioned	O
earlier	O
,	O
conventional	O
graph	B-Method
traversal	I-Method
algorithms	I-Method
such	O
as	O
Breadth	B-Method
-	I-Method
First	I-Method
Search	I-Method
(	I-Method
BFS	I-Method
)	I-Method
and	O
Depth	B-Method
-	I-Method
First	I-Method
Search	I-Method
(	O
DFS	B-Method
)	O
can	O
not	O
be	O
applied	O
to	O
the	O
graph	B-Task
walking	I-Task
problem	I-Task
,	O
because	O
the	O
ground	O
truth	O
target	O
node	O
is	O
not	O
known	O
at	O
test	O
time	O
.	O
	
However	O
,	O
to	O
understand	O
how	O
quickly	O
M	B-Method
-	I-Method
Walk	I-Method
with	O
MCTS	B-Method
can	O
find	O
the	O
correct	O
target	O
node	O
,	O
we	O
compare	O
it	O
with	O
BFS	B-Method
and	O
DFS	B-Method
in	O
the	O
following	O
cheating	O
setup	O
.	O
	
Specifically	O
,	O
we	O
apply	O
BFS	B-Method
and	O
DFS	B-Method
to	O
the	O
test	O
set	O
of	O
the	O
Three	O
Glass	B-Task
Puzzle	I-Task
task	I-Task
by	O
disclosing	O
the	O
target	O
node	O
to	O
them	O
.	O
	
In	O
Table	O
[	O
reference	O
]	O
,	O
we	O
report	O
the	O
average	O
traversal	O
steps	O
and	O
maximum	O
steps	O
to	O
reach	O
the	O
target	O
node	O
.	O
	
The	O
M	B-Method
-	I-Method
Walk	I-Method
with	O
MCTS	B-Method
algorithm	I-Method
is	O
able	O
to	O
find	O
the	O
target	O
node	O
more	O
efficiently	O
than	O
BFS	B-Method
or	O
DFS	B-Method
.	O
	
subsubsection	O
:	O
Knowledge	B-Task
Graph	I-Task
Link	I-Task
Prediction	I-Task
	
In	O
this	O
section	O
,	O
we	O
first	O
provide	O
additional	O
experimental	O
results	O
for	O
the	O
NELL995	B-Task
and	O
WN18RR	B-Material
tasks	O
to	O
support	O
our	O
analysis	O
.	O
	
In	O
Figure	O
[	O
reference	O
]	O
,	O
we	O
show	O
the	O
positive	B-Metric
reward	I-Metric
rate	I-Metric
during	O
training	B-Task
on	O
the	O
NELL995	B-Task
task	I-Task
.	O
	
And	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
we	O
provide	O
more	O
hyperparameter	B-Method
analysis	I-Method
(	O
search	O
horizon	O
and	O
MCTS	O
simulation	O
number	O
)	O
and	O
training	B-Method
-	I-Method
time	I-Method
analysis	I-Method
.	O
	
Furthermore	O
,	O
in	O
Table	O
[	O
reference	O
]	O
,	O
we	O
show	O
the	O
HITS@K	B-Metric
and	O
MRR	B-Metric
results	O
on	O
NELL995	O
.	O
	
In	O
addition	O
,	O
we	O
conduct	O
further	O
experiments	O
on	O
the	O
FB15k	O
-	O
237	O
dataset	O
,	O
which	O
is	O
a	O
subset	O
of	O
FB15k	O
with	O
inverse	O
relations	O
being	O
removed	O
.	O
	
We	O
use	O
the	O
same	O
data	O
split	O
and	O
preprocessing	B-Method
protocol	I-Method
as	O
in	O
for	O
FB15k	B-Method
-	I-Method
237	I-Method
.	O
	
The	O
results	O
are	O
reported	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
We	O
observe	O
that	O
M	B-Method
-	I-Method
Walk	I-Method
outperforms	O
the	O
other	O
RL	B-Method
-	I-Method
based	I-Method
method	I-Method
(	O
MINERVA	B-Method
)	O
.	O
	
However	O
,	O
it	O
is	O
still	O
worse	O
than	O
the	O
embedding	B-Method
-	I-Method
based	I-Method
methods	I-Method
.	O
	
In	O
future	O
work	O
,	O
we	O
intend	O
to	O
combine	O
the	O
strength	O
of	O
embedding	B-Method
-	I-Method
based	I-Method
methods	I-Method
and	O
our	O
method	O
to	O
further	O
improve	O
the	O
performance	O
of	O
M	B-Method
-	I-Method
Walk	I-Method
.	O
	
subsection	O
:	O
The	O
Reasoning	O
(	O
Traversal	O
)	O
Paths	O
	
In	O
Table	O
[	O
reference	O
]	O
,	O
we	O
show	O
the	O
reasoning	O
paths	O
of	O
M	B-Method
-	I-Method
Walk	I-Method
on	O
the	O
NELL995	O
dataset	O
.	O
	
Each	O
reasoning	O
path	O
is	O
generated	O
by	O
following	O
the	O
edges	O
on	O
the	O
MCTS	O
tree	O
with	O
the	O
highest	O
visiting	O
count	O
.	O
	
Image	B-Task
Super	I-Task
-	I-Task
Resolution	I-Task
Using	O
Deep	B-Method
Convolutional	I-Method
Networks	I-Method
	
section	O
:	O
	
Abstract	O
-	O
We	O
propose	O
a	O
deep	B-Method
learning	I-Method
method	I-Method
for	O
single	B-Task
image	I-Task
super	I-Task
-	I-Task
resolution	I-Task
(	O
SR	B-Task
)	O
.	O
	
Our	O
method	O
directly	O
learns	O
an	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
mapping	I-Task
between	O
the	O
low	O
/	O
high	O
-	O
resolution	O
images	O
.	O
	
The	O
mapping	B-Method
is	O
represented	O
as	O
a	O
deep	O
convolutional	O
neural	O
network	O
(	O
CNN	B-Method
)	O
that	O
takes	O
the	O
low	O
-	O
resolution	O
image	O
as	O
the	O
input	O
and	O
outputs	O
the	O
high	O
-	O
resolution	O
one	O
.	O
	
We	O
further	O
show	O
that	O
traditional	O
sparse	O
-	O
coding	O
-	O
based	O
SR	B-Task
methods	O
can	O
also	O
be	O
viewed	O
as	O
a	O
deep	B-Method
convolutional	I-Method
network	I-Method
.	O
	
But	O
unlike	O
traditional	O
methods	O
that	O
handle	O
each	O
component	O
separately	O
,	O
our	O
method	O
jointly	O
optimizes	O
all	O
layers	O
.	O
	
Our	O
deep	O
CNN	B-Method
has	O
a	O
lightweight	O
structure	O
,	O
yet	O
demonstrates	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
restoration	B-Metric
quality	I-Metric
,	O
and	O
achieves	O
fast	O
speed	B-Metric
for	O
practical	O
on	B-Task
-	I-Task
line	I-Task
usage	I-Task
.	O
	
We	O
explore	O
different	O
network	O
structures	O
and	O
parameter	O
settings	O
to	O
achieve	O
tradeoffs	O
between	O
performance	O
and	O
speed	B-Metric
.	O
	
Moreover	O
,	O
we	O
extend	O
our	O
network	O
to	O
cope	O
with	O
three	O
color	O
channels	O
simultaneously	O
,	O
and	O
show	O
better	O
overall	O
reconstruction	B-Metric
quality	I-Metric
.	O
	
section	O
:	O
INTRODUCTION	O
	
Single	B-Task
image	I-Task
super	I-Task
-	I-Task
resolution	I-Task
(	O
SR	B-Task
)	O
[	O
reference	O
]	O
,	O
which	O
aims	O
at	O
recovering	O
a	O
high	B-Task
-	I-Task
resolution	I-Task
image	I-Task
from	O
a	O
single	O
lowresolution	O
image	O
,	O
is	O
a	O
classical	O
problem	O
in	O
computer	B-Task
vision	I-Task
.	O
	
This	O
problem	O
is	O
inherently	O
ill	O
-	O
posed	O
since	O
a	O
multiplicity	O
of	O
solutions	O
exist	O
for	O
any	O
given	O
low	O
-	O
resolution	O
pixel	O
.	O
	
In	O
other	O
words	O
,	O
it	O
is	O
an	O
underdetermined	B-Task
inverse	I-Task
problem	I-Task
,	O
of	O
which	O
solution	O
is	O
not	O
unique	O
.	O
	
Such	O
a	O
problem	O
is	O
typically	O
mitigated	O
by	O
constraining	O
the	O
solution	O
space	O
by	O
strong	O
prior	O
information	O
.	O
	
To	O
learn	O
the	O
prior	O
,	O
recent	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
mostly	O
adopt	O
the	O
example	B-Method
-	I-Method
based	I-Method
[	O
reference	O
]	O
strategy	O
.	O
	
These	O
methods	O
either	O
exploit	O
internal	O
similarities	O
of	O
the	O
same	O
image	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
or	O
learn	O
mapping	O
functions	O
from	O
external	O
low	O
-	O
and	O
high	O
-	O
resolution	O
exemplar	O
pairs	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
	
[	O
reference	O
]	O
.	O
	
The	O
external	O
example	B-Method
-	I-Method
based	I-Method
methods	I-Method
can	O
be	O
formulated	O
for	O
generic	B-Task
image	I-Task
super	I-Task
-	I-Task
resolution	I-Task
,	O
or	O
can	O
be	O
designed	O
to	O
suit	O
domain	B-Task
specific	I-Task
tasks	I-Task
,	O
i.e.	O
,	O
face	B-Task
hallucination	I-Task
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
according	O
to	O
the	O
training	O
samples	O
provided	O
.	O
	
The	O
sparse	B-Method
-	I-Method
coding	I-Method
-	I-Method
based	I-Method
method	I-Method
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
is	O
one	O
of	O
the	O
representative	O
external	O
example	O
-	O
based	O
SR	B-Task
methods	O
.	O
	
This	O
method	O
involves	O
several	O
steps	O
in	O
its	O
solution	O
pipeline	O
.	O
	
First	O
,	O
overlapping	O
patches	O
are	O
densely	O
cropped	O
from	O
the	O
input	O
image	O
and	O
	
pre	O
-	O
processed	O
(	O
e.g.	O
,	O
subtracting	O
mean	O
and	O
normalization	B-Method
)	O
.	O
	
These	O
patches	O
are	O
then	O
encoded	O
by	O
a	O
low	B-Method
-	I-Method
resolution	I-Method
dictionary	I-Method
.	O
	
The	O
sparse	O
coefficients	O
are	O
passed	O
into	O
a	O
high	B-Method
-	I-Method
resolution	I-Method
dictionary	I-Method
for	O
reconstructing	B-Task
high	I-Task
-	I-Task
resolution	I-Task
patches	I-Task
.	O
	
The	O
overlapping	O
re	O
-	O
constructed	O
patches	O
are	O
aggregated	O
(	O
e.g.	O
,	O
by	O
weighted	B-Method
averaging	I-Method
)	O
to	O
produce	O
the	O
final	O
output	O
.	O
	
This	O
pipeline	O
is	O
shared	O
by	O
most	O
external	O
example	B-Method
-	I-Method
based	I-Method
methods	I-Method
,	O
which	O
pay	O
particular	O
attention	O
to	O
learning	O
and	O
optimizing	O
the	O
dictionaries	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
or	O
building	O
efficient	O
mapping	O
functions	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
	
reference	O
]	O
.	O
However	O
,	O
the	O
rest	O
of	O
the	O
steps	O
in	O
the	O
pipeline	O
have	O
been	O
rarely	O
optimized	O
or	O
considered	O
in	O
an	O
unified	B-Method
optimization	I-Method
framework	I-Method
.	O
	
In	O
this	O
paper	O
,	O
we	O
show	O
that	O
the	O
aforementioned	O
pipeline	O
is	O
equivalent	O
to	O
a	O
deep	B-Method
convolutional	I-Method
neural	I-Method
network	I-Method
[	O
reference	O
]	O
(	O
more	O
details	O
in	O
Section	O
3.2	O
)	O
.	O
	
Motivated	O
by	O
this	O
fact	O
,	O
we	O
consider	O
a	O
convolutional	B-Method
neural	I-Method
network	I-Method
that	O
directly	O
learns	O
an	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
mapping	I-Task
between	O
low	O
-	O
and	O
high	O
-	O
resolution	O
images	O
.	O
	
Our	O
method	O
differs	O
fundamentally	O
from	O
existing	O
external	B-Method
example	I-Method
-	I-Method
based	I-Method
approaches	I-Method
,	O
in	O
that	O
ours	O
does	O
not	O
explicitly	O
learn	O
the	O
dictionaries	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
or	O
manifolds	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
for	O
modeling	O
the	O
patch	O
space	O
.	O
	
These	O
are	O
implicitly	O
achieved	O
via	O
hidden	B-Method
layers	I-Method
.	O
	
Furthermore	O
,	O
the	O
patch	B-Task
extraction	I-Task
and	O
aggregation	B-Task
are	O
also	O
formulated	O
as	O
convolutional	B-Method
layers	I-Method
,	O
so	O
are	O
involved	O
in	O
the	O
optimization	B-Task
.	O
	
In	O
our	O
method	O
,	O
the	O
entire	O
SR	B-Task
pipeline	O
is	O
fully	O
obtained	O
through	O
learning	B-Method
,	O
with	O
little	O
pre	O
/	O
postprocessing	O
.	O
	
We	O
name	O
the	O
proposed	O
model	O
Super	B-Method
-	I-Method
Resolution	I-Method
Convolutional	I-Method
Neural	I-Method
Network	I-Method
(	O
SRCNN	B-Method
)	O
[	O
reference	O
]	O
.	O
	
The	O
proposed	O
SRCNN	B-Method
has	O
several	O
appealing	O
properties	O
.	O
	
First	O
,	O
its	O
structure	O
is	O
intentionally	O
designed	O
with	O
simplicity	O
in	O
mind	O
,	O
and	O
yet	O
provides	O
superior	O
accuracy	B-Metric
[	O
reference	O
]	O
compared	O
with	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
example	B-Method
-	I-Method
based	I-Method
methods	I-Method
.	O
	
numbers	O
of	O
filters	O
and	O
layers	O
,	O
our	O
method	O
achieves	O
fast	O
speed	B-Metric
for	O
practical	O
on	O
-	O
line	O
usage	O
even	O
on	O
a	O
CPU	O
.	O
	
Our	O
method	O
is	O
faster	O
than	O
a	O
number	O
of	O
example	B-Method
-	I-Method
based	I-Method
methods	I-Method
,	O
because	O
it	O
is	O
fully	O
feed	B-Method
-	I-Method
forward	I-Method
and	O
does	O
not	O
need	O
to	O
solve	O
any	O
optimization	B-Task
problem	I-Task
on	O
usage	O
.	O
	
Third	O
,	O
experiments	O
show	O
that	O
the	O
restoration	B-Metric
quality	I-Metric
of	O
the	O
network	O
can	O
be	O
further	O
improved	O
when	O
(	O
i	O
)	O
larger	O
and	O
more	O
diverse	O
datasets	O
are	O
available	O
,	O
and	O
/	O
or	O
(	O
ii	O
)	O
a	O
larger	O
and	O
deeper	O
model	O
is	O
used	O
.	O
	
On	O
the	O
contrary	O
,	O
larger	O
datasets	O
/	O
models	O
can	O
present	O
challenges	O
for	O
existing	O
example	B-Method
-	I-Method
based	I-Method
methods	I-Method
.	O
	
Furthermore	O
,	O
the	O
proposed	O
network	O
can	O
cope	O
with	O
three	O
channels	O
of	O
color	O
images	O
simultaneously	O
to	O
achieve	O
improved	O
super	B-Metric
-	I-Metric
resolution	I-Metric
performance	I-Metric
.	O
	
Overall	O
,	O
the	O
contributions	O
of	O
this	O
study	O
are	O
mainly	O
in	O
three	O
aspects	O
:	O
	
1	O
)	O
We	O
present	O
a	O
fully	B-Method
convolutional	I-Method
neural	I-Method
network	I-Method
for	O
image	B-Task
super	I-Task
-	I-Task
resolution	I-Task
.	O
	
The	O
network	O
directly	O
learns	O
an	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
mapping	I-Task
between	O
lowand	O
high	O
-	O
resolution	O
images	O
,	O
with	O
little	O
pre	O
/	O
postprocessing	O
beyond	O
the	O
optimization	B-Task
.	O
	
2	O
)	O
	
We	O
establish	O
a	O
relationship	O
between	O
our	O
deeplearning	O
-	O
based	O
SR	B-Task
method	O
and	O
the	O
traditional	O
sparse	O
-	O
coding	O
-	O
based	O
SR	B-Task
methods	O
.	O
	
This	O
relationship	O
provides	O
a	O
guidance	O
for	O
the	O
design	O
of	O
the	O
network	O
structure	O
.	O
	
3	O
)	O
	
We	O
demonstrate	O
that	O
deep	B-Method
learning	I-Method
is	O
useful	O
in	O
the	O
classical	O
computer	B-Task
vision	I-Task
problem	I-Task
of	I-Task
superresolution	I-Task
,	O
and	O
can	O
achieve	O
good	O
quality	B-Metric
and	O
speed	B-Metric
.	O
	
A	O
preliminary	O
version	O
of	O
this	O
work	O
was	O
presented	O
earlier	O
	
[	O
reference	O
]	O
.	O
	
The	O
present	O
work	O
adds	O
to	O
the	O
initial	O
version	O
in	O
significant	O
ways	O
.	O
	
Firstly	O
,	O
we	O
improve	O
the	O
SRCNN	B-Method
by	O
introducing	O
larger	O
filter	O
size	O
in	O
the	O
non	O
-	O
linear	O
mapping	O
layer	O
,	O
and	O
explore	O
deeper	O
structures	O
by	O
adding	O
nonlinear	B-Method
mapping	I-Method
layers	I-Method
.	O
	
Secondly	O
,	O
we	O
extend	O
the	O
SRCNN	B-Method
to	O
process	O
three	O
color	O
channels	O
(	O
either	O
in	O
YCbCr	O
or	O
RGB	O
color	O
space	O
)	O
simultaneously	O
.	O
	
Experimentally	O
,	O
we	O
demonstrate	O
that	O
performance	O
can	O
be	O
improved	O
in	O
comparison	O
to	O
the	O
single	B-Method
-	I-Method
channel	I-Method
network	I-Method
.	O
	
Thirdly	O
,	O
considerable	O
new	O
analyses	O
and	O
intuitive	O
explanations	O
are	O
added	O
to	O
the	O
initial	O
results	O
.	O
	
We	O
also	O
extend	O
the	O
original	O
experiments	O
from	O
Set5	B-Material
[	O
reference	O
]	O
and	O
Set14	B-Material
[	O
reference	O
]	O
test	O
images	O
to	O
BSD200	O
[	O
reference	O
]	O
(	O
200	O
test	O
images	O
)	O
.	O
	
In	O
addition	O
,	O
we	O
compare	O
with	O
a	O
number	O
of	O
recently	O
published	O
methods	O
and	O
confirm	O
that	O
our	O
model	O
still	O
outperforms	O
existing	O
approaches	O
using	O
different	O
evaluation	B-Metric
metrics	I-Metric
.	O
	
section	O
:	O
RELATED	O
WORK	O
	
section	O
:	O
Image	B-Task
Super	I-Task
-	I-Task
Resolution	I-Task
	
According	O
to	O
the	O
image	O
priors	O
,	O
single	B-Method
-	I-Method
image	I-Method
super	I-Method
resolution	I-Method
algorithms	I-Method
can	O
be	O
categorized	O
into	O
four	O
typesprediction	O
models	O
,	O
edge	B-Method
based	I-Method
methods	I-Method
,	O
image	B-Method
statistical	I-Method
methods	I-Method
and	O
patch	B-Method
based	I-Method
(	I-Method
or	I-Method
example	I-Method
-	I-Method
based	I-Method
)	I-Method
methods	I-Method
.	O
	
These	O
methods	O
have	O
been	O
thoroughly	O
investigated	O
and	O
evaluated	O
in	O
Yang	O
et	O
al	O
.	O
's	O
	
work	O
	
[	O
reference	O
]	O
.	O
Among	O
them	O
,	O
the	O
example	B-Method
-	I-Method
based	I-Method
methods	I-Method
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
achieve	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
.	O
	
The	O
internal	B-Method
example	I-Method
-	I-Method
based	I-Method
methods	I-Method
exploit	O
the	O
selfsimilarity	O
property	O
and	O
generate	O
exemplar	O
patches	O
from	O
the	O
input	O
image	O
.	O
	
It	O
is	O
first	O
proposed	O
in	O
Glasner	O
's	O
work	O
[	O
reference	O
]	O
,	O
and	O
several	O
improved	O
variants	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
are	O
proposed	O
to	O
accelerate	O
the	O
implementation	O
.	O
	
The	O
external	B-Method
example	I-Method
-	I-Method
based	I-Method
methods	I-Method
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
learn	O
a	O
mapping	O
between	O
low	O
/	O
highresolution	O
patches	O
from	O
external	O
datasets	O
.	O
	
These	O
studies	O
vary	O
on	O
how	O
to	O
learn	O
a	O
compact	O
dictionary	O
or	O
manifold	O
space	O
to	O
relate	O
low	O
/	O
high	O
-	O
resolution	O
patches	O
,	O
and	O
on	O
how	O
representation	B-Method
schemes	I-Method
can	O
be	O
conducted	O
in	O
such	O
spaces	O
.	O
	
In	O
the	O
pioneer	O
work	O
of	O
Freeman	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
,	O
the	O
dictionaries	B-Method
are	O
directly	O
presented	O
as	O
low	O
/	O
high	O
-	O
resolution	O
patch	O
pairs	O
,	O
and	O
the	O
nearest	B-Method
neighbour	I-Method
(	O
NN	B-Method
)	O
of	O
the	O
input	O
patch	O
is	O
found	O
in	O
the	O
low	O
-	O
resolution	O
space	O
,	O
with	O
its	O
corresponding	O
high	O
-	O
resolution	O
patch	O
used	O
for	O
reconstruction	B-Task
.	O
	
Chang	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
introduce	O
a	O
manifold	B-Method
embedding	I-Method
technique	I-Method
as	O
an	O
alternative	O
to	O
the	O
NN	B-Method
strategy	I-Method
.	O
	
In	O
Yang	O
et	O
al	O
.	O
's	O
work	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
the	O
above	O
NN	B-Method
correspondence	I-Method
advances	O
to	O
a	O
more	O
sophisticated	O
sparse	B-Method
coding	I-Method
formulation	I-Method
.	O
	
Other	O
mapping	B-Method
functions	I-Method
such	O
as	O
kernel	B-Method
regression	I-Method
[	O
reference	O
]	O
,	O
simple	B-Method
function	I-Method
[	O
reference	O
]	O
,	O
random	B-Method
forest	I-Method
[	O
reference	O
]	O
and	O
anchored	B-Method
neighborhood	I-Method
regression	I-Method
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
are	O
proposed	O
to	O
further	O
improve	O
the	O
mapping	B-Metric
accuracy	I-Metric
and	O
speed	B-Metric
.	O
	
The	O
sparsecoding	B-Method
-	I-Method
based	I-Method
method	I-Method
and	O
its	O
several	O
improvements	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
are	O
among	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
SR	B-Task
methods	O
nowadays	O
.	O
	
In	O
these	O
methods	O
,	O
the	O
patches	O
are	O
the	O
focus	O
of	O
the	O
optimization	B-Task
;	O
the	O
patch	B-Task
extraction	I-Task
and	O
aggregation	B-Task
steps	O
are	O
considered	O
as	O
pre	B-Task
/	I-Task
post	I-Task
-	I-Task
processing	I-Task
and	O
handled	O
separately	O
.	O
	
The	O
majority	O
of	O
SR	B-Task
algorithms	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
focus	O
on	O
gray	B-Task
-	I-Task
scale	I-Task
or	O
single	B-Task
-	I-Task
channel	I-Task
image	I-Task
super	I-Task
-	I-Task
resolution	I-Task
.	O
	
For	O
color	O
images	O
,	O
the	O
aforementioned	O
methods	O
first	O
transform	O
the	O
problem	O
to	O
a	O
different	O
color	O
space	O
(	O
YCbCr	O
or	O
YUV	O
)	O
,	O
and	O
SR	B-Task
is	O
applied	O
only	O
on	O
the	O
luminance	O
channel	O
.	O
	
There	O
are	O
also	O
works	O
attempting	O
to	O
super	O
-	O
resolve	O
all	O
channels	O
simultaneously	O
.	O
	
For	O
example	O
,	O
Kim	O
and	O
Kwon	O
[	O
reference	O
]	O
and	O
Dai	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
apply	O
their	O
model	O
to	O
each	O
RGB	O
channel	O
and	O
combined	O
them	O
to	O
produce	O
the	O
final	O
results	O
.	O
	
However	O
,	O
none	O
of	O
them	O
has	O
analyzed	O
the	O
SR	B-Task
performance	O
of	O
different	O
channels	O
,	O
and	O
the	O
necessity	O
of	O
recovering	O
all	O
three	O
channels	O
.	O
	
section	O
:	O
Convolutional	B-Method
Neural	I-Method
Networks	I-Method
	
Convolutional	B-Method
neural	I-Method
networks	I-Method
(	O
CNN	B-Method
)	O
date	O
back	O
decades	O
[	O
reference	O
]	O
and	O
deep	B-Method
CNNs	I-Method
have	O
recently	O
shown	O
an	O
explosive	O
popularity	O
partially	O
due	O
to	O
its	O
success	O
in	O
image	B-Task
classification	I-Task
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
.	O
	
They	O
have	O
also	O
been	O
successfully	O
applied	O
to	O
other	O
computer	B-Task
vision	I-Task
fields	I-Task
,	O
such	O
as	O
object	B-Task
detection	I-Task
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
face	B-Task
recognition	I-Task
[	O
reference	O
]	O
,	O
and	O
pedestrian	B-Task
detection	I-Task
	
[	O
reference	O
]	O
.	O
Several	O
factors	O
are	O
of	O
central	O
importance	O
in	O
this	O
progress	O
:	O
(	O
i	O
)	O
the	O
efficient	O
training	B-Method
implementation	I-Method
on	O
modern	O
powerful	O
GPUs	B-Method
[	O
reference	O
]	O
,	O
(	O
ii	O
)	O
the	O
proposal	O
of	O
the	O
Rectified	B-Method
Linear	I-Method
Unit	I-Method
(	O
ReLU	B-Method
)	O
[	O
reference	O
]	O
which	O
makes	O
convergence	B-Task
much	O
faster	O
while	O
still	O
presents	O
good	O
quality	O
[	O
reference	O
]	O
,	O
and	O
(	O
iii	O
)	O
the	O
easy	O
access	O
to	O
an	O
abundance	O
of	O
data	O
(	O
like	O
ImageNet	B-Method
[	O
reference	O
]	O
)	O
for	O
training	O
larger	B-Method
models	I-Method
.	O
	
Our	O
method	O
also	O
benefits	O
from	O
these	O
progresses	O
.	O
	
section	O
:	O
Deep	B-Method
Learning	I-Method
for	O
Image	B-Task
Restoration	I-Task
	
There	O
have	O
been	O
a	O
few	O
studies	O
of	O
using	O
deep	B-Method
learning	I-Method
techniques	I-Method
for	O
image	B-Task
restoration	I-Task
.	O
	
The	O
multi	B-Method
-	I-Method
layer	I-Method
perceptron	I-Method
(	I-Method
MLP	I-Method
)	I-Method
,	O
whose	O
all	O
layers	O
are	O
fully	O
-	O
connected	O
(	O
in	O
contrast	O
to	O
convolutional	B-Method
)	O
,	O
is	O
applied	O
for	O
natural	B-Task
image	I-Task
denoising	I-Task
[	O
reference	O
]	O
and	O
post	B-Task
-	I-Task
deblurring	I-Task
denoising	I-Task
[	O
reference	O
]	O
.	O
More	O
closely	O
related	O
to	O
our	O
work	O
,	O
the	O
convolutional	B-Method
neural	I-Method
network	I-Method
is	O
applied	O
for	O
natural	B-Task
image	I-Task
denoising	I-Task
[	O
reference	O
]	O
and	O
removing	O
noisy	O
patterns	O
(	O
dirt	O
/	O
rain	O
)	O
	
[	O
reference	O
]	O
.	O
These	O
restoration	B-Task
problems	I-Task
are	O
more	O
or	O
less	O
denoising	B-Task
-	I-Task
driven	I-Task
.	O
	
Cui	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
propose	O
to	O
embed	O
auto	B-Method
-	I-Method
encoder	I-Method
networks	I-Method
in	O
their	O
superresolution	B-Method
pipeline	I-Method
under	O
the	O
notion	O
internal	B-Method
examplebased	I-Method
approach	I-Method
[	O
reference	O
]	O
.	O
	
The	O
deep	B-Method
model	I-Method
is	O
not	O
specifically	O
designed	O
to	O
be	O
an	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
solution	I-Task
,	O
since	O
each	O
layer	O
of	O
the	O
cascade	B-Method
requires	O
independent	O
optimization	O
of	O
the	O
self	B-Method
-	I-Method
similarity	I-Method
search	I-Method
process	I-Method
and	O
the	O
auto	B-Method
-	I-Method
encoder	I-Method
.	O
	
On	O
the	O
contrary	O
,	O
the	O
proposed	O
SRCNN	B-Method
optimizes	O
an	O
end	B-Task
-	I-Task
toend	I-Task
mapping	I-Task
.	O
	
Further	O
,	O
the	O
SRCNN	B-Method
is	O
faster	O
at	O
speed	B-Metric
.	O
	
It	O
is	O
not	O
only	O
a	O
quantitatively	O
superior	O
method	O
,	O
but	O
also	O
a	O
practically	O
useful	O
one	O
.	O
	
section	O
:	O
CONVOLUTIONAL	B-Method
NEURAL	I-Method
NETWORKS	I-Method
FOR	O
SUPER	B-Task
-	I-Task
RESOLUTION	I-Task
	
section	O
:	O
Formulation	O
	
Consider	O
a	O
single	O
low	O
-	O
resolution	O
image	O
,	O
we	O
first	O
upscale	O
it	O
to	O
the	O
desired	O
size	O
using	O
bicubic	B-Method
interpolation	I-Method
,	O
which	O
is	O
the	O
only	O
pre	O
-	O
processing	O
we	O
perform	O
[	O
reference	O
]	O
.	O
	
Let	O
us	O
denote	O
the	O
interpolated	O
image	O
as	O
Y.	O
Our	O
goal	O
is	O
to	O
recover	O
from	O
Y	O
an	O
image	O
F	O
(	O
Y	O
)	O
that	O
is	O
as	O
similar	O
as	O
possible	O
to	O
the	O
ground	O
truth	O
high	O
-	O
resolution	O
image	O
X.	O
	
For	O
the	O
ease	O
of	O
presentation	O
,	O
we	O
still	O
call	O
Y	O
a	O
"	O
low	O
-	O
resolution	O
"	O
image	O
,	O
although	O
it	O
has	O
the	O
same	O
size	O
as	O
X.	O
	
We	O
wish	O
to	O
learn	O
a	O
mapping	B-Task
F	I-Task
,	O
which	O
conceptually	O
consists	O
of	O
three	O
operations	O
:	O
	
1	O
)	O
Patch	B-Method
extraction	I-Method
and	O
representation	B-Task
:	O
this	O
operation	O
extracts	O
	
(	O
overlapping	O
)	O
patches	O
from	O
the	O
lowresolution	O
image	O
Y	O
and	O
represents	O
each	O
patch	O
as	O
a	O
high	O
-	O
dimensional	O
vector	O
.	O
	
These	O
vectors	O
comprise	O
a	O
set	O
of	O
feature	O
maps	O
,	O
of	O
which	O
the	O
number	O
equals	O
to	O
the	O
dimensionality	O
of	O
the	O
vectors	O
.	O
	
2	O
)	O
	
Non	B-Method
-	I-Method
linear	I-Method
mapping	I-Method
:	O
this	O
operation	O
nonlinearly	O
maps	O
each	O
high	O
-	O
dimensional	O
vector	O
onto	O
another	O
high	O
-	O
dimensional	O
vector	O
.	O
	
Each	O
mapped	O
vector	O
is	O
conceptually	O
the	O
representation	O
of	O
a	O
high	B-Task
-	I-Task
resolution	I-Task
patch	I-Task
.	O
	
These	O
vectors	O
comprise	O
another	O
set	O
of	O
feature	B-Method
maps	I-Method
.	O
	
3	O
	
)	O
Reconstruction	B-Task
:	O
this	O
operation	O
aggregates	O
the	O
above	O
high	B-Method
-	I-Method
resolution	I-Method
patch	I-Method
-	I-Method
wise	I-Method
representations	I-Method
to	O
generate	O
the	O
final	O
high	O
-	O
resolution	O
image	O
.	O
	
This	O
image	O
is	O
expected	O
to	O
be	O
similar	O
to	O
the	O
ground	O
truth	O
X.	O
	
We	O
will	O
show	O
that	O
all	O
these	O
operations	O
form	O
a	O
convolutional	B-Method
neural	I-Method
network	I-Method
.	O
	
An	O
overview	O
of	O
the	O
network	O
is	O
depicted	O
in	O
Figure	O
2	O
.	O
	
Next	O
we	O
detail	O
our	O
definition	O
of	O
each	O
operation	O
.	O
	
section	O
:	O
Patch	B-Task
extraction	I-Task
and	O
representation	B-Task
	
A	O
popular	O
strategy	O
in	O
image	B-Task
restoration	I-Task
(	O
e.g.	O
,	O
[	O
reference	O
]	O
)	O
is	O
to	O
densely	O
extract	O
patches	O
and	O
then	O
represent	O
them	O
by	O
a	O
set	O
of	O
pre	O
-	O
trained	O
bases	O
such	O
as	O
PCA	B-Method
,	O
DCT	B-Method
,	O
Haar	B-Method
,	O
etc	O
.	O
	
This	O
is	O
equivalent	O
to	O
convolving	O
the	O
image	O
by	O
a	O
set	O
of	O
filters	B-Method
,	O
each	O
of	O
which	O
is	O
a	O
basis	O
.	O
	
In	O
our	O
formulation	O
,	O
we	O
involve	O
the	O
optimization	O
of	O
these	O
bases	O
into	O
the	O
optimization	B-Task
of	I-Task
the	I-Task
network	I-Task
.	O
	
Formally	O
,	O
our	O
first	O
layer	O
is	O
expressed	O
as	O
an	O
operation	O
F	O
1	O
:	O
	
where	O
W	O
1	O
and	O
B	O
1	O
represent	O
the	O
filters	O
and	O
biases	O
respectively	O
,	O
and	O
'	O
*	O
'	O
denotes	O
the	O
convolution	B-Method
operation	I-Method
.	O
	
Here	O
,	O
W	O
1	O
corresponds	O
to	O
n	O
1	O
filters	O
of	O
support	O
	
c	O
×	O
f	O
1	O
×	O
f	O
1	O
,	O
where	O
c	O
is	O
the	O
number	O
of	O
channels	O
in	O
the	O
input	O
image	O
,	O
f	O
1	O
is	O
the	O
spatial	O
size	O
of	O
a	O
filter	B-Method
.	O
	
Intuitively	O
,	O
W	O
1	O
applies	O
n	O
1	O
convolutions	B-Method
on	O
the	O
image	O
,	O
and	O
each	O
convolution	B-Method
has	O
[	O
reference	O
]	O
.	O
Bicubic	B-Method
interpolation	I-Method
is	O
also	O
a	O
convolutional	B-Method
operation	I-Method
,	O
so	O
it	O
can	O
be	O
formulated	O
as	O
a	O
convolutional	B-Method
layer	I-Method
.	O
	
However	O
,	O
the	O
output	O
size	O
of	O
this	O
layer	O
is	O
larger	O
than	O
the	O
input	O
size	O
,	O
so	O
there	O
is	O
a	O
fractional	O
stride	O
.	O
	
To	O
take	O
advantage	O
of	O
the	O
popular	O
well	B-Method
-	I-Method
optimized	I-Method
implementations	I-Method
such	O
as	O
cuda	B-Method
-	I-Method
convnet	I-Method
[	O
reference	O
]	O
,	O
we	O
exclude	O
this	O
"	O
layer	O
"	O
from	O
learning	B-Task
.	O
	
a	O
kernel	B-Method
size	I-Method
	
c	O
×	O
f	O
1	O
×	O
	
f	O
1	O
.	O
	
The	O
output	O
is	O
composed	O
of	O
n	O
1	O
feature	O
maps	O
.	O
	
B	O
1	O
is	O
an	O
n	O
1	O
-	O
dimensional	O
vector	O
,	O
whose	O
each	O
element	O
is	O
associated	O
with	O
a	O
filter	B-Method
.	O
	
We	O
apply	O
the	O
Rectified	B-Method
Linear	I-Method
Unit	I-Method
(	O
ReLU	B-Method
,	O
max	O
(	O
0	O
,	O
x	O
)	O
)	O
	
[	O
reference	O
]	O
on	O
the	O
filter	O
responses	O
4	O
.	O
	
section	O
:	O
Non	B-Task
-	I-Task
linear	I-Task
mapping	I-Task
	
The	O
first	O
layer	O
extracts	O
an	O
n	O
1	O
-	O
dimensional	O
feature	O
for	O
each	O
patch	O
.	O
	
In	O
the	O
second	O
operation	O
,	O
we	O
map	O
each	O
of	O
these	O
n	O
1	O
-	O
dimensional	O
vectors	O
into	O
an	O
n	O
2	O
-	O
dimensional	O
one	O
.	O
	
This	O
is	O
equivalent	O
to	O
applying	O
n	B-Method
2	I-Method
filters	I-Method
which	O
have	O
a	O
trivial	O
spatial	O
support	O
1	O
×	O
1	O
.	O
	
This	O
interpretation	O
is	O
only	O
valid	O
for	O
1	B-Method
×	I-Method
1	I-Method
filters	I-Method
.	O
	
But	O
it	O
is	O
easy	O
to	O
generalize	O
to	O
larger	O
filters	O
like	O
3	O
×	O
3	O
or	O
5	O
×	O
5	O
.	O
	
In	O
that	O
case	O
,	O
the	O
non	B-Method
-	I-Method
linear	I-Method
mapping	I-Method
is	O
not	O
on	O
a	O
patch	O
of	O
the	O
input	O
image	O
;	O
instead	O
,	O
it	O
is	O
on	O
a	O
3	O
×	O
3	O
or	O
5	O
×	O
5	O
"	O
patch	O
"	O
of	O
the	O
feature	O
map	O
.	O
	
The	O
operation	O
of	O
the	O
second	O
layer	O
is	O
:	O
	
Here	O
W	O
2	O
contains	O
n	O
2	O
filters	O
of	O
size	O
n	O
1	O
×	O
f	O
2	O
×	O
f	O
2	O
,	O
and	O
B	O
2	O
is	O
n	O
2	O
-	O
dimensional	O
.	O
	
Each	O
of	O
the	O
output	O
n	O
2	O
-	O
dimensional	O
vectors	O
is	O
conceptually	O
a	O
representation	O
of	O
a	O
high	B-Task
-	I-Task
resolution	I-Task
patch	I-Task
that	O
will	O
be	O
used	O
for	O
reconstruction	B-Task
.	O
	
It	O
is	O
possible	O
to	O
add	O
more	O
convolutional	O
layers	O
to	O
increase	O
the	O
non	O
-	O
linearity	O
.	O
	
But	O
this	O
can	O
increase	O
the	O
complexity	O
of	O
the	O
model	O
(	O
n	O
2	O
×	O
f	O
2	O
×	O
f	O
2	O
×	O
n	O
2	O
parameters	O
for	O
one	O
layer	O
)	O
,	O
and	O
thus	O
demands	O
more	O
training	O
time	O
.	O
	
We	O
will	O
explore	O
deeper	O
structures	O
by	O
introducing	O
additional	O
non	O
-	O
linear	O
mapping	O
layers	O
in	O
Section	O
4.3.3	O
.	O
	
section	O
:	O
Reconstruction	B-Task
	
In	O
the	O
traditional	O
methods	O
,	O
the	O
predicted	O
overlapping	O
high	O
-	O
resolution	O
patches	O
are	O
often	O
averaged	O
to	O
produce	O
the	O
final	O
full	O
image	O
.	O
	
The	O
averaging	B-Method
can	O
be	O
considered	O
as	O
a	O
pre	O
-	O
defined	B-Method
filter	I-Method
on	O
a	O
set	O
of	O
feature	O
maps	O
(	O
where	O
each	O
position	O
is	O
the	O
"	O
flattened	O
"	O
vector	O
form	O
of	O
a	O
highresolution	O
patch	O
)	O
.	O
	
Motivated	O
by	O
this	O
,	O
we	O
define	O
a	O
convolutional	B-Method
layer	I-Method
to	O
produce	O
the	O
final	O
high	O
-	O
resolution	O
image	O
:	O
	
4	O
.	O
	
The	O
ReLU	B-Method
can	O
be	O
equivalently	O
considered	O
as	O
a	O
part	O
of	O
the	O
second	O
operation	O
(	O
Non	B-Task
-	I-Task
linear	I-Task
mapping	I-Task
)	O
,	O
and	O
the	O
first	O
operation	O
(	O
Patch	B-Task
extraction	I-Task
and	I-Task
representation	I-Task
)	O
becomes	O
purely	O
linear	B-Method
convolution	I-Method
.	O
	
Here	O
W	O
3	O
corresponds	O
to	O
c	O
filters	O
of	O
a	O
size	O
n	O
2	O
×	O
f	O
3	O
×	O
f	O
3	O
,	O
and	O
B	O
3	O
is	O
a	O
c	O
-	O
dimensional	O
vector	O
.	O
	
If	O
the	O
representations	O
of	O
the	O
high	B-Task
-	I-Task
resolution	I-Task
patches	I-Task
are	O
in	O
the	O
image	O
domain	O
(	O
i.e.	O
,	O
we	O
can	O
simply	O
reshape	O
each	O
representation	O
to	O
form	O
the	O
patch	O
)	O
,	O
we	O
expect	O
that	O
the	O
filters	O
act	O
like	O
an	O
averaging	B-Method
filter	I-Method
;	O
if	O
the	O
representations	O
of	O
the	O
high	O
-	O
resolution	O
patches	O
are	O
in	O
some	O
other	O
domains	O
(	O
e.g.	O
,	O
coefficients	O
in	O
terms	O
of	O
some	O
bases	O
)	O
,	O
we	O
expect	O
that	O
W	O
3	O
behaves	O
like	O
first	O
projecting	O
the	O
coefficients	O
onto	O
the	O
image	O
domain	O
and	O
then	O
averaging	B-Method
.	O
	
In	O
either	O
way	O
,	O
W	O
3	O
is	O
a	O
set	O
of	O
linear	B-Method
filters	I-Method
.	O
	
Interestingly	O
,	O
although	O
the	O
above	O
three	O
operations	O
are	O
motivated	O
by	O
different	O
intuitions	O
,	O
they	O
all	O
lead	O
to	O
the	O
same	O
form	O
as	O
a	O
convolutional	B-Method
layer	I-Method
.	O
	
We	O
put	O
all	O
three	O
operations	O
together	O
and	O
form	O
a	O
convolutional	B-Method
neural	I-Method
network	I-Method
(	O
Figure	O
2	O
)	O
.	O
	
In	O
this	O
model	O
,	O
all	O
the	O
filtering	O
weights	O
and	O
biases	O
are	O
to	O
be	O
optimized	O
.	O
	
Despite	O
the	O
succinctness	O
of	O
the	O
overall	O
structure	O
,	O
our	O
SRCNN	B-Method
model	O
is	O
carefully	O
developed	O
by	O
drawing	O
extensive	O
experience	O
resulted	O
from	O
significant	O
progresses	O
in	O
super	B-Task
-	I-Task
resolution	I-Task
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
.	O
We	O
detail	O
the	O
relationship	O
in	O
the	O
next	O
section	O
.	O
	
section	O
:	O
Relationship	O
to	O
Sparse	B-Method
-	I-Method
Coding	I-Method
-	I-Method
Based	I-Method
Methods	I-Method
	
We	O
show	O
that	O
the	O
sparse	O
-	O
coding	O
-	O
based	O
SR	B-Task
methods	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
can	O
be	O
viewed	O
as	O
a	O
convolutional	B-Method
neural	I-Method
network	I-Method
.	O
	
Figure	O
3	O
shows	O
an	O
illustration	O
.	O
	
In	O
the	O
sparse	B-Method
-	I-Method
coding	I-Method
-	I-Method
based	I-Method
methods	I-Method
,	O
let	O
us	O
consider	O
that	O
an	O
f	O
1	O
×	O
f	O
1	O
low	O
-	O
resolution	O
patch	O
is	O
extracted	O
from	O
the	O
input	O
image	O
.	O
	
Then	O
the	O
sparse	B-Method
coding	I-Method
solver	I-Method
,	O
like	O
Feature	B-Method
-	I-Method
Sign	I-Method
[	O
reference	O
]	O
,	O
will	O
first	O
project	O
the	O
patch	O
onto	O
a	O
(	O
lowresolution	O
)	O
dictionary	O
.	O
	
If	O
the	O
dictionary	O
size	O
is	O
n	O
1	O
,	O
this	O
is	O
equivalent	O
to	O
applying	O
n	O
1	O
linear	B-Method
filters	I-Method
(	O
f	O
1	O
×	O
f	O
1	O
)	O
on	O
the	O
input	O
image	O
(	O
the	O
mean	B-Method
subtraction	I-Method
is	O
also	O
a	O
linear	O
operation	O
so	O
can	O
be	O
absorbed	O
)	O
.	O
	
This	O
is	O
illustrated	O
as	O
the	O
left	O
part	O
of	O
Figure	O
3	O
.	O
	
The	O
sparse	B-Method
coding	I-Method
solver	I-Method
will	O
then	O
iteratively	O
process	O
the	O
n	O
1	O
coefficients	O
.	O
	
The	O
outputs	O
of	O
this	O
solver	O
are	O
n	O
2	O
coefficients	O
,	O
and	O
usually	O
n	O
2	O
=	O
n	O
1	O
in	O
the	O
case	O
of	O
sparse	B-Task
coding	I-Task
.	O
	
These	O
n	O
2	O
coefficients	O
are	O
the	O
representation	O
of	O
the	O
high	B-Task
-	I-Task
resolution	I-Task
patch	I-Task
.	O
	
In	O
this	O
sense	O
,	O
the	O
sparse	B-Method
coding	I-Method
solver	I-Method
behaves	O
as	O
a	O
special	O
case	O
of	O
a	O
non	B-Method
-	I-Method
linear	I-Method
mapping	I-Method
operator	I-Method
,	O
whose	O
spatial	O
support	O
is	O
1	O
×	O
1	O
.	O
	
See	O
the	O
middle	O
part	O
of	O
Figure	O
3	O
.	O
	
However	O
,	O
the	O
sparse	B-Method
coding	I-Method
solver	I-Method
is	O
not	O
feed	B-Method
-	I-Method
forward	I-Method
,	O
i.e.	O
,	O
it	O
is	O
an	O
iterative	B-Method
algorithm	I-Method
.	O
	
On	O
the	O
contrary	O
,	O
our	O
non	B-Method
-	I-Method
linear	I-Method
operator	I-Method
is	O
fully	O
feed	O
-	O
forward	O
and	O
can	O
be	O
computed	O
efficiently	O
.	O
	
If	O
we	O
set	O
f	O
2	O
=	O
1	O
,	O
then	O
our	O
non	B-Method
-	I-Method
linear	I-Method
operator	I-Method
can	O
be	O
considered	O
as	O
a	O
pixel	B-Method
-	I-Method
wise	I-Method
fully	I-Method
-	I-Method
connected	I-Method
layer	I-Method
.	O
	
It	O
is	O
worth	O
noting	O
that	O
"	O
the	O
sparse	B-Method
coding	I-Method
solver	I-Method
"	O
in	O
SRCNN	B-Method
refers	O
to	O
the	O
first	O
two	O
layers	O
,	O
but	O
not	O
just	O
the	O
second	O
layer	O
or	O
the	O
activation	O
function	O
(	O
ReLU	B-Method
)	O
.	O
	
Thus	O
the	O
nonlinear	B-Method
operation	I-Method
in	O
SRCNN	B-Method
is	O
also	O
well	O
optimized	O
through	O
the	O
learning	B-Method
process	I-Method
.	O
	
The	O
above	O
n	O
2	O
coefficients	O
(	O
after	O
sparse	B-Method
coding	I-Method
)	O
are	O
then	O
projected	O
onto	O
another	O
(	O
high	O
-	O
resolution	O
)	O
dictionary	O
to	O
produce	O
a	O
high	B-Task
-	I-Task
resolution	I-Task
patch	I-Task
.	O
	
The	O
overlapping	O
high	O
-	O
resolution	O
patches	O
are	O
then	O
averaged	O
.	O
	
As	O
discussed	O
above	O
,	O
this	O
is	O
equivalent	O
to	O
linear	B-Method
convolutions	I-Method
on	O
the	O
n	O
2	O
feature	O
maps	O
.	O
	
If	O
the	O
high	O
-	O
resolution	O
patches	O
used	O
for	O
reconstruction	B-Task
are	O
of	O
size	O
f	O
3	O
×	O
f	O
3	O
,	O
then	O
the	O
linear	B-Method
filters	I-Method
have	O
an	O
equivalent	O
spatial	O
support	O
of	O
size	O
f	O
3	O
×	O
	
f	O
3	O
.	O
	
See	O
the	O
right	O
part	O
of	O
Figure	O
3	O
.	O
	
The	O
above	O
discussion	O
shows	O
that	O
the	O
sparse	O
-	O
codingbased	O
SR	B-Task
method	O
can	O
be	O
viewed	O
as	O
a	O
kind	O
of	O
convolutional	B-Method
neural	I-Method
network	I-Method
(	O
with	O
a	O
different	O
non	O
-	O
linear	O
mapping	O
)	O
.	O
	
But	O
not	O
all	O
operations	O
have	O
been	O
considered	O
in	O
the	O
optimization	B-Task
in	O
the	O
sparse	O
-	O
coding	O
-	O
based	O
SR	B-Task
methods	O
.	O
	
On	O
the	O
contrary	O
,	O
in	O
our	O
convolutional	B-Method
neural	I-Method
network	I-Method
,	O
the	O
low	O
-	O
resolution	O
dictionary	O
,	O
high	O
-	O
resolution	O
dictionary	O
,	O
non	B-Method
-	I-Method
linear	I-Method
mapping	I-Method
,	O
together	O
with	O
mean	B-Method
subtraction	I-Method
and	O
averaging	B-Method
,	O
are	O
all	O
involved	O
in	O
the	O
filters	O
to	O
be	O
optimized	O
.	O
	
So	O
our	O
method	O
optimizes	O
an	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
mapping	I-Task
that	O
consists	O
of	O
all	O
operations	O
.	O
	
The	O
above	O
analogy	O
can	O
also	O
help	O
us	O
to	O
design	O
hyperparameters	O
.	O
	
For	O
example	O
,	O
we	O
can	O
set	O
the	O
filter	O
size	O
of	O
the	O
last	O
layer	O
to	O
be	O
smaller	O
than	O
that	O
of	O
the	O
first	O
layer	O
,	O
and	O
thus	O
we	O
rely	O
more	O
on	O
the	O
central	O
part	O
of	O
the	O
highresolution	O
patch	O
(	O
to	O
the	O
extreme	O
,	O
if	O
f	O
3	O
=	O
1	O
,	O
we	O
are	O
using	O
the	O
center	O
pixel	O
with	O
no	O
averaging	O
)	O
.	O
	
We	O
can	O
also	O
set	O
n	O
2	O
<	O
n	O
1	O
because	O
it	O
is	O
expected	O
to	O
be	O
sparser	O
.	O
	
A	O
typical	O
and	O
basic	O
setting	O
is	O
f	O
1	O
=	O
9	O
,	O
f	O
2	O
=	O
1	O
,	O
f	O
3	O
=	O
5	O
,	O
n	O
1	O
=	O
64	O
,	O
and	O
n	O
2	O
=	O
32	O
(	O
we	O
evaluate	O
more	O
settings	O
in	O
the	O
experiment	O
section	O
)	O
.	O
	
On	O
the	O
whole	O
,	O
the	O
estimation	O
of	O
a	O
high	O
resolution	O
pixel	O
utilizes	O
the	O
information	O
of	O
(	O
9	O
+	O
5	O
−	O
1	O
)	O
2	O
=	O
169	O
pixels	O
.	O
	
Clearly	O
,	O
the	O
information	O
exploited	O
for	O
reconstruction	B-Task
is	O
comparatively	O
larger	O
than	O
that	O
used	O
in	O
existing	O
external	B-Method
example	I-Method
-	I-Method
based	I-Method
approaches	I-Method
,	O
e.g.	O
,	O
using	O
(	O
5	O
+	O
5−1	O
)	O
2	O
=	O
81	O
pixels	O
5	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
.	O
	
This	O
is	O
one	O
of	O
the	O
reasons	O
why	O
the	O
SRCNN	B-Method
gives	O
superior	O
performance	O
.	O
	
section	O
:	O
Training	O
	
Learning	O
the	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
mapping	I-Task
function	I-Task
F	I-Task
requires	O
the	O
estimation	O
of	O
network	O
parameters	O
Θ	O
=	O
{	O
W	O
1	O
,	O
W	O
2	O
,	O
W	O
3	O
,	O
B	O
1	O
,	O
B	O
2	O
,	O
B	O
3	O
}	O
.	O
	
This	O
is	O
achieved	O
through	O
minimizing	O
the	O
loss	O
between	O
the	O
reconstructed	O
images	O
F	O
(	O
Y	O
;	O
Θ	O
)	O
and	O
the	O
corresponding	O
ground	O
truth	O
highresolution	O
images	O
X.	O
	
Given	O
a	O
set	O
of	O
high	O
-	O
resolution	O
images	O
{	O
X	O
i	O
}	O
and	O
their	O
corresponding	O
low	O
-	O
resolution	O
images	O
{	O
Y	O
i	O
}	O
,	O
we	O
use	O
Mean	B-Metric
Squared	I-Metric
Error	I-Metric
(	O
MSE	B-Metric
)	O
as	O
the	O
loss	B-Metric
function	I-Metric
:	O
	
where	O
n	O
is	O
the	O
number	O
of	O
training	O
samples	O
.	O
	
Using	O
MSE	B-Metric
as	O
the	O
loss	O
function	O
favors	O
a	O
high	O
PSNR	B-Metric
.	O
	
The	O
PSNR	B-Metric
is	O
a	O
widely	O
-	O
used	O
metric	O
for	O
quantitatively	B-Task
evaluating	I-Task
image	I-Task
restoration	I-Task
quality	I-Task
,	O
and	O
is	O
at	O
least	O
partially	O
related	O
to	O
the	O
perceptual	B-Metric
quality	I-Metric
.	O
	
It	O
is	O
worth	O
noticing	O
that	O
the	O
convolutional	B-Method
neural	I-Method
networks	I-Method
do	O
not	O
preclude	O
the	O
usage	O
of	O
other	O
kinds	O
of	O
loss	O
functions	O
,	O
if	O
only	O
the	O
loss	O
functions	O
are	O
derivable	O
.	O
	
If	O
a	O
better	O
perceptually	B-Metric
motivated	I-Metric
metric	I-Metric
is	O
given	O
during	O
training	O
,	O
it	O
is	O
flexible	O
for	O
the	O
network	O
to	O
adapt	O
to	O
that	O
metric	O
.	O
	
On	O
the	O
contrary	O
,	O
such	O
a	O
flexibility	O
is	O
in	O
general	O
difficult	O
to	O
achieve	O
for	O
traditional	O
"	O
handcrafted	B-Method
"	I-Method
methods	I-Method
.	O
	
Despite	O
that	O
the	O
proposed	O
model	O
is	O
trained	O
favoring	O
a	O
high	O
PSNR	B-Metric
,	O
we	O
still	O
observe	O
satisfactory	O
performance	O
when	O
the	O
model	O
is	O
evaluated	O
using	O
alternative	O
evaluation	B-Metric
metrics	I-Metric
,	O
e.g.	O
,	O
SSIM	B-Metric
,	O
MSSIM	B-Metric
(	O
see	O
Section	O
4.4.1	O
)	O
.	O
	
The	O
loss	B-Task
is	O
minimized	O
using	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
with	O
the	O
standard	O
backpropagation	B-Method
[	O
reference	O
]	O
.	O
In	O
particular	O
,	O
the	O
weight	O
matrices	O
are	O
updated	O
as	O
	
5	O
.	O
	
The	O
patches	O
are	O
overlapped	O
with	O
4	O
pixels	O
at	O
each	O
direction	O
.	O
	
where	O
∈	O
{	O
1	O
,	O
2	O
,	O
3	O
}	O
and	O
i	O
are	O
the	O
indices	O
of	O
layers	O
and	O
iterations	O
,	O
η	O
is	O
the	O
learning	O
rate	O
,	O
and	O
	
is	O
the	O
derivative	O
.	O
	
The	O
filter	O
weights	O
of	O
each	O
layer	O
are	O
initialized	O
by	O
drawing	O
randomly	O
from	O
a	O
Gaussian	B-Method
distribution	I-Method
with	O
zero	O
mean	O
and	O
standard	O
deviation	O
0.001	O
(	O
and	O
0	O
for	O
biases	O
)	O
.	O
	
The	O
learning	B-Metric
rate	I-Metric
is	O
10	O
−4	O
for	O
the	O
first	O
two	O
layers	O
,	O
and	O
10	O
−5	O
for	O
the	O
last	O
layer	O
.	O
	
We	O
empirically	O
find	O
that	O
a	O
smaller	O
learning	B-Metric
rate	I-Metric
in	O
the	O
last	O
layer	O
is	O
important	O
for	O
the	O
network	O
to	O
converge	O
(	O
similar	O
to	O
the	O
denoising	B-Task
case	I-Task
[	O
reference	O
]	O
)	O
.	O
	
In	O
the	O
training	O
phase	O
,	O
the	O
ground	O
truth	O
images	O
{	O
X	O
i	O
}	O
are	O
prepared	O
as	O
f	O
sub	O
×f	O
sub	O
×c	O
-	O
pixel	O
sub	O
-	O
images	O
randomly	O
cropped	O
from	O
the	O
training	O
images	O
.	O
	
By	O
"	O
sub	O
-	O
images	O
"	O
we	O
mean	O
these	O
samples	O
are	O
treated	O
as	O
small	O
"	O
images	O
"	O
rather	O
than	O
"	O
patches	O
"	O
,	O
in	O
the	O
sense	O
that	O
"	O
patches	O
"	O
are	O
overlapping	O
and	O
require	O
some	O
averaging	O
as	O
post	B-Task
-	I-Task
processing	I-Task
but	O
"	O
sub	O
-	O
images	O
"	O
need	O
not	O
.	O
	
To	O
synthesize	O
the	O
low	O
-	O
resolution	O
samples	O
{	O
Y	O
i	O
}	O
,	O
we	O
blur	O
a	O
sub	O
-	O
image	O
by	O
a	O
Gaussian	B-Method
kernel	I-Method
,	O
sub	O
-	O
sample	O
it	O
by	O
the	O
upscaling	O
factor	O
,	O
and	O
upscale	O
it	O
by	O
the	O
same	O
factor	O
via	O
bicubic	B-Method
interpolation	I-Method
.	O
	
To	O
avoid	O
border	O
effects	O
during	O
training	O
,	O
all	O
the	O
convolutional	B-Method
layers	I-Method
have	O
no	O
padding	O
,	O
and	O
the	O
network	O
produces	O
a	O
smaller	O
output	O
(	O
(	O
	
2	O
×	O
c	O
)	O
.	O
	
The	O
MSE	B-Metric
loss	O
function	O
is	O
evaluated	O
only	O
by	O
the	O
difference	O
between	O
the	O
central	O
pixels	O
of	O
X	O
i	O
and	O
the	O
network	O
output	O
.	O
	
Although	O
we	O
use	O
a	O
fixed	O
image	O
size	O
in	O
training	O
,	O
the	O
convolutional	B-Method
neural	I-Method
network	I-Method
can	O
be	O
applied	O
on	O
images	O
of	O
arbitrary	O
sizes	O
during	O
testing	O
.	O
	
We	O
implement	O
our	O
model	O
using	O
the	O
cuda	B-Method
-	I-Method
convnet	I-Method
package	I-Method
[	O
reference	O
]	O
.	O
	
We	O
have	O
also	O
tried	O
the	O
Caffe	B-Method
package	I-Method
[	O
reference	O
]	O
and	O
observed	O
similar	O
performance	O
.	O
	
section	O
:	O
EXPERIMENTS	O
	
We	O
first	O
investigate	O
the	O
impact	O
of	O
using	O
different	O
datasets	O
on	O
the	O
model	O
performance	O
.	O
	
Next	O
,	O
we	O
examine	O
the	O
filters	B-Method
learned	O
by	O
our	O
approach	O
.	O
	
We	O
then	O
explore	O
different	O
architecture	O
designs	O
of	O
the	O
network	O
,	O
and	O
study	O
the	O
relations	O
between	O
super	B-Metric
-	I-Metric
resolution	I-Metric
performance	I-Metric
and	O
factors	O
like	O
depth	O
,	O
number	O
of	O
filters	O
,	O
and	O
filter	O
sizes	O
.	O
	
Subsequently	O
,	O
we	O
compare	O
our	O
method	O
with	O
recent	O
state	O
-	O
ofthe	O
-	O
arts	O
both	O
quantitatively	O
and	O
qualitatively	O
.	O
	
Following	O
[	O
reference	O
]	O
,	O
super	B-Task
-	I-Task
resolution	I-Task
is	O
only	O
applied	O
on	O
the	O
luminance	O
channel	O
(	O
Y	O
channel	O
in	O
YCbCr	O
color	O
space	O
)	O
in	O
Sections	O
4.1	O
-	O
4.4	O
,	O
so	O
c	O
=	O
1	O
in	O
the	O
first	O
/	O
last	O
layer	O
,	O
and	O
performance	O
(	O
e.g.	O
,	O
PSNR	B-Metric
and	O
SSIM	B-Metric
)	O
is	O
evaluated	O
on	O
the	O
Y	O
channel	O
.	O
	
At	O
last	O
,	O
we	O
extend	O
the	O
network	O
to	O
cope	O
with	O
color	O
images	O
and	O
evaluate	O
the	O
performance	O
on	O
different	O
channels	O
.	O
	
section	O
:	O
Training	O
Data	O
	
As	O
shown	O
in	O
the	O
literature	O
,	O
deep	B-Method
learning	I-Method
generally	O
benefits	O
from	O
big	B-Task
data	I-Task
training	I-Task
.	O
	
For	O
comparison	O
,	O
we	O
use	O
a	O
relatively	O
small	O
training	O
set	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
that	O
consists	O
of	O
91	O
images	O
,	O
and	O
a	O
large	O
training	O
set	O
that	O
consists	O
of	O
395	O
,	O
909	O
images	O
from	O
the	O
ILSVRC	O
2013	O
	
ImageNet	B-Method
detection	O
training	O
partition	O
.	O
	
The	O
size	O
of	O
training	O
sub	O
-	O
images	O
is	O
f	O
sub	O
=	O
33	O
.	O
	
Thus	O
the	O
91	O
-	O
image	O
dataset	O
can	O
be	O
decomposed	O
into	O
24	O
,	O
800	O
sub	O
-	O
images	O
,	O
which	O
are	O
extracted	O
from	O
original	O
images	O
with	O
a	O
stride	O
of	O
14	O
.	O
	
Whereas	O
the	O
ImageNet	B-Method
provides	O
over	O
5	O
million	O
sub	O
-	O
images	O
even	O
using	O
a	O
stride	O
of	O
33	O
.	O
	
We	O
use	O
the	O
basic	O
network	O
settings	O
,	O
i.e.	O
,	O
f	O
1	O
=	O
9	O
,	O
f	O
2	O
=	O
1	O
,	O
f	O
3	O
=	O
5	O
,	O
n	O
1	O
=	O
64	O
,	O
and	O
n	O
2	O
=	O
32	O
.	O
	
We	O
use	O
the	O
Set5	B-Material
[	O
reference	O
]	O
as	O
the	O
validation	O
set	O
.	O
	
We	O
observe	O
a	O
similar	O
trend	O
even	O
if	O
we	O
use	O
the	O
larger	O
Set14	B-Material
set	O
[	O
reference	O
]	O
.	O
	
The	O
upscaling	O
factor	O
is	O
3	O
.	O
	
We	O
use	O
the	O
sparse	B-Method
-	I-Method
coding	I-Method
-	I-Method
based	I-Method
method	I-Method
[	O
reference	O
]	O
as	O
our	O
baseline	O
,	O
which	O
achieves	O
an	O
average	B-Metric
PSNR	I-Metric
value	I-Metric
of	O
31.42	O
dB.	O
	
The	O
test	O
convergence	B-Metric
curves	I-Metric
of	O
using	O
different	O
training	O
sets	O
are	O
shown	O
in	O
Figure	O
4	O
.	O
	
The	O
training	B-Metric
time	I-Metric
on	O
ImageNet	B-Method
is	O
about	O
the	O
same	O
as	O
on	O
the	O
91	O
-	O
image	O
dataset	O
since	O
the	O
number	O
of	O
backpropagations	B-Method
is	O
the	O
same	O
.	O
	
As	O
can	O
be	O
observed	O
,	O
with	O
the	O
same	O
number	O
of	O
backpropagations	O
(	O
i.e.	O
,	O
8	O
×	O
10	O
8	O
)	O
,	O
the	O
SRCNN	B-Method
+	O
ImageNet	B-Method
achieves	O
32.52	O
dB	O
,	O
higher	O
than	O
32.39	O
dB	O
yielded	O
by	O
that	O
	
trained	O
on	O
91	O
images	O
.	O
	
The	O
results	O
positively	O
indicate	O
that	O
SRCNN	B-Method
performance	O
may	O
be	O
further	O
boosted	O
using	O
a	O
larger	O
training	O
set	O
,	O
but	O
the	O
effect	O
of	O
big	O
data	O
is	O
not	O
as	O
impressive	O
as	O
that	O
shown	O
in	O
high	B-Task
-	I-Task
level	I-Task
vision	I-Task
problems	I-Task
	
[	O
reference	O
]	O
.	O
This	O
is	O
mainly	O
because	O
that	O
the	O
91	O
images	O
have	O
already	O
captured	O
sufficient	O
variability	O
of	O
natural	O
images	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
our	O
SRCNN	B-Method
is	O
a	O
relatively	O
small	O
network	O
(	O
8	O
,	O
032	O
parameters	O
)	O
,	O
which	O
could	O
not	O
overfit	O
the	O
91	O
images	O
(	O
24	O
,	O
800	O
samples	O
)	O
.	O
	
Nevertheless	O
,	O
we	O
adopt	O
the	O
ImageNet	B-Method
,	O
which	O
contains	O
more	O
diverse	O
data	O
,	O
as	O
the	O
default	O
training	O
set	O
in	O
the	O
following	O
experiments	O
.	O
	
Figure	O
5	O
shows	O
examples	O
of	O
learned	O
first	B-Method
-	I-Method
layer	I-Method
filters	I-Method
trained	O
on	O
the	O
ImageNet	B-Method
by	O
an	O
upscaling	O
factor	O
3	O
.	O
	
Please	O
refer	O
to	O
our	O
published	O
implementation	O
for	O
upscaling	O
factors	O
2	O
and	O
4	O
.	O
	
Interestingly	O
,	O
each	O
learned	O
filter	O
has	O
its	O
specific	O
functionality	O
.	O
	
For	O
instance	O
,	O
the	O
filters	B-Method
g	I-Method
and	O
h	O
are	O
like	O
Laplacian	B-Method
/	I-Method
Gaussian	I-Method
filters	I-Method
,	O
the	O
filters	O
a	O
-	O
e	O
are	O
like	O
edge	B-Method
detectors	I-Method
at	O
different	O
directions	O
,	O
and	O
the	O
filter	B-Method
f	I-Method
is	O
like	O
a	O
texture	B-Method
extractor	I-Method
.	O
	
Example	O
feature	O
maps	O
of	O
different	O
layers	O
are	O
shown	O
in	O
figure	O
6	O
.	O
	
Obviously	O
,	O
feature	O
maps	O
of	O
the	O
first	O
layer	O
contain	O
different	O
structures	O
(	O
e.g.	O
,	O
edges	O
at	O
different	O
directions	O
)	O
,	O
while	O
that	O
of	O
the	O
second	O
layer	O
are	O
mainly	O
different	O
on	O
intensities	O
.	O
	
section	O
:	O
Learned	B-Method
Filters	I-Method
for	O
Super	B-Task
-	I-Task
Resolution	I-Task
	
section	O
:	O
Model	O
and	O
Performance	O
Trade	O
-	O
offs	O
	
Based	O
on	O
the	O
basic	O
network	O
settings	O
(	O
i.e.	O
,	O
f	O
1	O
=	O
9	O
,	O
f	O
2	O
=	O
1	O
,	O
f	O
3	O
=	O
5	O
,	O
n	O
1	O
=	O
64	O
,	O
and	O
n	O
2	O
=	O
32	O
)	O
,	O
we	O
will	O
progressively	O
modify	O
some	O
of	O
these	O
parameters	O
to	O
investigate	O
the	O
best	O
trade	O
-	O
off	O
between	O
performance	O
and	O
speed	B-Metric
,	O
and	O
study	O
the	O
relations	O
between	O
performance	O
and	O
parameters	O
.	O
	
section	O
:	O
Filter	O
number	O
	
In	O
general	O
,	O
the	O
performance	O
would	O
improve	O
if	O
we	O
increase	O
the	O
network	O
width	O
[	O
reference	O
]	O
,	O
i.e.	O
,	O
adding	O
more	O
filters	O
,	O
at	O
the	O
cost	O
of	O
running	B-Metric
time	I-Metric
.	O
	
Specifically	O
,	O
based	O
on	O
our	O
network	O
default	O
settings	O
of	O
n	O
1	O
=	O
64	O
and	O
n	O
2	O
=	O
32	O
,	O
we	O
conduct	O
two	O
experiments	O
:	O
(	O
i	O
)	O
one	O
is	O
with	O
a	O
larger	O
network	O
with	O
n	O
1	O
=	O
128	O
and	O
n	O
2	O
=	O
64	O
,	O
and	O
(	O
ii	O
)	O
the	O
other	O
is	O
with	O
a	O
smaller	O
network	O
with	O
n	O
1	O
=	O
32	O
and	O
n	O
2	O
=	O
16	O
.	O
	
Similar	O
to	O
Section	O
4.1	O
,	O
we	O
also	O
train	O
the	O
two	O
models	O
on	O
ImageNet	B-Method
and	O
test	O
on	O
Set5	B-Material
with	O
an	O
upscaling	O
factor	O
3	O
.	O
	
The	O
results	O
observed	O
at	O
8	O
×	O
10	O
8	O
backpropagations	O
are	O
shown	O
in	O
Table	O
1	O
.	O
	
It	O
is	O
clear	O
that	O
superior	O
performance	O
could	O
be	O
achieved	O
by	O
increasing	O
the	O
width	O
.	O
	
However	O
,	O
if	O
a	O
fast	O
restoration	O
speed	B-Metric
is	O
desired	O
,	O
a	O
small	O
network	O
width	O
is	O
preferred	O
,	O
which	O
could	O
still	O
achieve	O
better	O
performance	O
than	O
the	O
sparsecoding	B-Method
-	I-Method
based	I-Method
method	I-Method
(	O
31.42	O
dB	O
)	O
.	O
	
section	O
:	O
Filter	B-Method
size	I-Method
	
In	O
this	O
section	O
,	O
we	O
examine	O
the	O
network	O
sensitivity	O
to	O
different	O
filter	O
sizes	O
.	O
	
In	O
previous	O
experiments	O
,	O
we	O
set	O
filter	O
size	O
f	O
1	O
=	O
9	O
	
,	O
f	O
2	O
=	O
1	O
and	O
f	O
3	O
=	O
5	O
,	O
and	O
the	O
network	O
could	O
be	O
denoted	O
as	O
9	O
-	O
1	O
-	O
5	O
.	O
	
First	O
,	O
to	O
be	O
consistent	O
with	O
sparse	B-Method
-	I-Method
coding	I-Method
-	I-Method
based	I-Method
methods	I-Method
,	O
we	O
fix	O
the	O
filter	O
size	O
of	O
the	O
second	O
layer	O
to	O
be	O
f	O
2	O
=	O
1	O
,	O
and	O
enlarge	O
the	O
filter	O
size	O
of	O
other	O
layers	O
to	O
f	O
1	O
=	O
11	O
and	O
f	O
3	O
=	O
7	O
(	O
11	O
-	O
1	O
-	O
7	O
)	O
.	O
	
All	O
the	O
other	O
[	O
reference	O
]	O
.	O
	
We	O
use	O
'	O
width	O
'	O
to	O
term	O
the	O
number	O
of	O
filters	O
in	O
a	O
layer	O
,	O
following	O
[	O
reference	O
]	O
.	O
	
The	O
term	O
'	O
width	O
'	O
may	O
have	O
other	O
meanings	O
in	O
the	O
literature	O
.	O
	
settings	O
remain	O
the	O
same	O
with	O
Section	O
4.1	O
.	O
	
The	O
results	O
with	O
an	O
upscaling	O
factor	O
3	O
on	O
Set5	B-Material
are	O
32.57	O
dB	O
,	O
which	O
is	O
slightly	O
higher	O
than	O
the	O
32.52	O
dB	O
reported	O
in	O
Section	O
4.1	O
.	O
	
This	O
indicates	O
that	O
a	O
reasonably	O
larger	O
filter	O
size	O
could	O
grasp	O
richer	O
structural	O
information	O
,	O
which	O
in	O
turn	O
lead	O
to	O
better	O
results	O
.	O
	
Then	O
we	O
further	O
examine	O
networks	O
with	O
a	O
larger	O
filter	O
size	O
of	O
the	O
second	O
layer	O
.	O
	
Specifically	O
,	O
we	O
fix	O
the	O
filter	O
size	O
f	O
1	O
=	O
9	O
,	O
f	O
3	O
=	O
5	O
,	O
and	O
enlarge	O
the	O
filter	O
size	O
of	O
the	O
second	O
layer	O
to	O
be	O
(	O
i	O
)	O
f	O
2	O
=	O
3	O
(	O
9	O
-	O
3	O
-	O
5	O
)	O
and	O
(	O
ii	O
)	O
f	O
2	O
=	O
5	O
(	O
9	O
-	O
5	O
-	O
5	O
)	O
.	O
	
Convergence	O
curves	O
in	O
Figure	O
7	O
show	O
that	O
using	O
a	O
larger	O
filter	O
size	O
could	O
significantly	O
improve	O
the	O
performance	O
.	O
	
Specifically	O
,	O
the	O
average	O
PSNR	B-Metric
values	O
achieved	O
by	O
9	O
-	O
3	O
-	O
5	O
and	O
9	O
-	O
5	O
-	O
5	O
on	O
Set5	B-Material
with	O
8	O
×	O
10	O
8	O
backpropagations	O
are	O
32.66	O
dB	O
and	O
32.75	O
dB	O
,	O
respectively	O
.	O
	
The	O
results	O
suggest	O
that	O
utilizing	O
neighborhood	O
information	O
in	O
the	O
mapping	B-Task
stage	I-Task
is	O
beneficial	O
.	O
	
However	O
,	O
the	O
deployment	O
speed	B-Metric
will	O
also	O
decrease	O
with	O
a	O
larger	O
filter	O
size	O
.	O
	
For	O
example	O
,	O
the	O
number	O
of	O
parameters	O
of	O
9	O
-	O
1	O
-	O
5	O
,	O
9	O
-	O
3	O
-	O
5	O
,	O
and	O
9	O
-	O
5	O
-	O
5	O
is	O
8	O
,	O
032	O
,	O
24	O
,	O
416	O
,	O
and	O
57	O
,	O
184	O
respectively	O
.	O
	
The	O
complexity	B-Metric
of	O
9	O
-	O
5	O
-	O
5	O
is	O
almost	O
twice	O
of	O
9	O
-	O
3	O
-	O
5	O
,	O
but	O
the	O
performance	O
improvement	O
is	O
marginal	O
.	O
	
Therefore	O
,	O
the	O
choice	O
of	O
the	O
network	O
scale	O
should	O
always	O
be	O
a	O
trade	O
-	O
off	O
between	O
performance	O
and	O
speed	B-Metric
.	O
	
section	O
:	O
Number	O
of	O
layers	O
	
Recent	O
study	O
by	O
He	O
and	O
Sun	O
[	O
reference	O
]	O
suggests	O
that	O
CNN	B-Method
could	O
benefit	O
from	O
increasing	O
the	O
depth	O
of	O
network	O
moderately	O
.	O
	
Here	O
,	O
we	O
try	O
deeper	O
structures	O
by	O
adding	O
another	O
non	B-Method
-	I-Method
linear	I-Method
mapping	I-Method
layer	I-Method
,	O
which	O
has	O
n	O
22	O
=	O
16	O
filters	O
with	O
size	O
f	O
22	O
=	O
1	O
.	O
	
We	O
conduct	O
three	O
controlled	O
experiments	O
,	O
i.e.	O
,	O
9	O
-	O
1	O
-	O
1	O
-	O
5	O
,	O
9	O
-	O
3	O
-	O
1	O
-	O
5	O
,	O
9	O
-	O
5	O
-	O
1	O
-	O
5	O
,	O
which	O
add	O
an	O
additional	O
layer	O
on	O
9	O
-	O
1	O
-	O
5	O
,	O
9	O
-	O
3	O
-	O
5	O
,	O
and	O
9	O
-	O
5	O
-	O
5	O
,	O
respectively	O
.	O
	
The	O
initialization	B-Method
scheme	I-Method
and	O
learning	B-Metric
rate	I-Metric
of	O
the	O
additional	B-Method
layer	I-Method
are	O
the	O
same	O
as	O
the	O
second	O
layer	O
.	O
	
From	O
Figures	O
13	O
(	O
a	O
)	O
,	O
13	O
(	O
b	O
)	O
and	O
8	O
(	O
c	O
)	O
,	O
we	O
can	O
observe	O
that	O
the	O
four	B-Method
-	I-Method
layer	I-Method
networks	I-Method
converge	O
slower	O
than	O
the	O
three	B-Method
-	I-Method
layer	I-Method
network	I-Method
.	O
	
Nevertheless	O
,	O
given	O
enough	O
training	O
time	O
,	O
the	O
deeper	B-Method
networks	I-Method
will	O
finally	O
catch	O
up	O
and	O
converge	O
to	O
the	O
three	O
-	O
layer	O
ones	O
.	O
	
The	O
effectiveness	O
of	O
deeper	O
structures	O
for	O
super	B-Task
resolution	I-Task
is	O
found	O
not	O
as	O
apparent	O
as	O
that	O
shown	O
in	O
image	B-Task
classification	I-Task
	
[	O
reference	O
]	O
.	O
Furthermore	O
,	O
we	O
find	O
that	O
deeper	B-Method
networks	I-Method
do	O
not	O
always	O
result	O
in	O
better	O
performance	O
.	O
	
Specifically	O
,	O
if	O
we	O
add	O
an	O
additional	O
layer	O
with	O
n	O
22	O
=	O
32	O
filters	O
on	O
9	O
-	O
1	O
-	O
5	O
network	O
,	O
then	O
the	O
performance	O
degrades	O
and	O
fails	O
to	O
surpass	O
the	O
three	O
-	O
layer	B-Method
network	I-Method
(	O
see	O
Figure	O
9	O
(	O
a	O
)	O
)	O
.	O
	
If	O
we	O
go	O
deeper	O
by	O
adding	O
two	O
non	B-Method
-	I-Method
linear	I-Method
mapping	I-Method
layers	I-Method
with	O
	
n	O
22	O
=	O
32	O
and	O
n	O
23	O
=	O
16	O
filters	O
on	O
9	O
-	O
1	O
-	O
5	O
,	O
then	O
we	O
have	O
to	O
set	O
a	O
smaller	O
learning	B-Metric
rate	I-Metric
to	O
ensure	O
convergence	O
,	O
but	O
we	O
still	O
do	O
not	O
observe	O
superior	O
performance	O
after	O
a	O
week	O
of	O
training	O
(	O
see	O
Figure	O
9	O
(	O
a	O
)	O
)	O
.	O
	
We	O
also	O
tried	O
to	O
enlarge	O
the	O
filter	O
size	O
of	O
the	O
additional	O
layer	O
to	O
f	O
22	O
=	O
3	O
,	O
and	O
explore	O
two	O
deep	B-Method
structures	I-Method
-	O
9	O
-	O
3	O
-	O
3	O
-	O
5	O
and	O
9	O
-	O
3	O
-	O
3	O
-	O
3	O
.	O
	
However	O
,	O
from	O
the	O
convergence	O
curves	O
shown	O
in	O
Figure	O
9	O
(	O
b	O
)	O
,	O
these	O
two	O
networks	O
do	O
not	O
show	O
better	O
results	O
than	O
the	O
9	O
-	O
3	O
-	O
1	O
-	O
5	O
network	O
.	O
	
All	O
these	O
experiments	O
indicate	O
that	O
it	O
is	O
not	O
"	O
the	O
deeper	O
the	O
better	O
"	O
in	O
this	O
deep	B-Method
model	I-Method
for	O
super	B-Task
-	I-Task
resolution	I-Task
.	O
	
It	O
may	O
be	O
caused	O
by	O
the	O
difficulty	O
of	O
training	O
.	O
	
Our	O
CNN	B-Method
network	O
contains	O
no	O
pooling	B-Method
layer	I-Method
or	O
full	B-Method
-	I-Method
connected	I-Method
layer	I-Method
,	O
thus	O
it	O
is	O
sensitive	O
to	O
the	O
initialization	O
parameters	O
and	O
learning	B-Metric
rate	I-Metric
.	O
	
When	O
we	O
go	O
deeper	O
(	O
e.g.	O
,	O
4	O
or	O
5	O
layers	O
)	O
,	O
we	O
find	O
it	O
hard	O
to	O
set	O
appropriate	O
learning	B-Metric
rates	I-Metric
that	O
guarantee	O
convergence	B-Metric
.	O
	
Even	O
it	O
converges	O
,	O
the	O
network	O
may	O
fall	O
into	O
a	O
bad	O
local	O
minimum	O
,	O
and	O
the	O
learned	O
filters	O
are	O
of	O
less	O
diversity	O
even	O
given	O
enough	O
training	O
time	O
.	O
	
This	O
phenomenon	O
is	O
also	O
observed	O
in	O
[	O
reference	O
]	O
,	O
where	O
improper	O
increase	O
of	O
depth	O
leads	O
to	O
accuracy	B-Metric
saturation	I-Metric
or	O
degradation	B-Metric
for	O
image	B-Task
classification	I-Task
.	O
	
Why	O
"	O
deeper	O
is	O
not	O
better	O
"	O
is	O
still	O
an	O
open	O
question	O
,	O
which	O
requires	O
investigations	O
to	O
better	O
understand	O
gradients	O
and	O
training	O
dynamics	O
in	O
deep	B-Method
architectures	I-Method
.	O
	
Therefore	O
,	O
we	O
still	O
adopt	O
three	B-Method
-	I-Method
layer	I-Method
networks	I-Method
in	O
the	O
following	O
experiments	O
.	O
	
section	O
:	O
Comparisons	O
to	O
State	O
-	O
of	O
-	O
the	O
-	O
Arts	O
	
In	O
this	O
section	O
,	O
we	O
show	O
the	O
quantitative	O
and	O
qualitative	O
results	O
of	O
our	O
method	O
in	O
comparison	O
to	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
.	O
	
We	O
adopt	O
the	O
model	O
with	O
good	O
performancespeed	O
trade	O
-	O
off	O
:	O
a	O
three	B-Method
-	I-Method
layer	I-Method
network	I-Method
with	O
f	O
1	O
=	O
9	O
,	O
f	O
2	O
=	O
5	O
,	O
f	O
3	O
=	O
5	O
,	O
n	O
1	O
=	O
64	O
,	O
and	O
n	O
2	O
=	O
32	O
trained	O
on	O
the	O
ImageNet	B-Method
.	O
	
For	O
each	O
upscaling	O
factor	O
∈	O
{	O
2	O
,	O
3	O
,	O
4	O
}	O
,	O
we	O
train	O
a	O
specific	O
network	O
for	O
that	O
factor	O
[	O
reference	O
]	O
.	O
	
Comparisons	O
.	O
	
We	O
compare	O
our	O
SRCNN	B-Method
with	O
the	O
stateof	O
-	O
the	O
-	O
art	O
SR	B-Task
methods	O
:	O
	
•	O
	
SC	B-Method
-	I-Method
sparse	I-Method
coding	I-Method
-	I-Method
based	I-Method
method	I-Method
of	O
Yang	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
	
•	O
	
NE	O
+	O
LLE	O
	
-	B-Method
neighbour	I-Method
embedding	I-Method
+	O
locally	B-Method
linear	I-Method
embedding	I-Method
method	I-Method
[	O
reference	O
]	O
	
•	O
	
ANR	B-Method
-	I-Method
Anchored	I-Method
Neighbourhood	I-Method
Regression	I-Method
method	I-Method
[	O
reference	O
]	O
•	O
	
A	O
+	O
-	O
Adjusted	O
Anchored	B-Method
Neighbourhood	I-Method
Regression	I-Method
method	I-Method
[	O
reference	O
]	O
,	O
and	O
	
•	O
	
KK	B-Method
-	I-Method
the	I-Method
method	I-Method
described	O
in	O
[	O
reference	O
]	O
,	O
which	O
achieves	O
the	O
best	O
performance	O
among	O
external	O
examplebased	B-Method
methods	I-Method
,	O
according	O
to	O
the	O
comprehensive	O
evaluation	O
conducted	O
in	O
Yang	O
et	O
al	O
.	O
's	O
	
work	O
[	O
reference	O
]	O
	
The	O
implementations	O
are	O
all	O
from	O
the	O
publicly	O
available	O
codes	O
provided	O
by	O
the	O
authors	O
,	O
and	O
all	O
images	O
are	O
downsampled	O
using	O
the	O
same	O
bicubic	B-Method
kernel	I-Method
.	O
	
Test	O
set	O
.	O
	
The	O
Set5	B-Material
[	O
2	O
]	O
(	O
5	O
images	O
)	O
,	O
Set14	B-Material
[	O
51	O
]	O
(	O
14	O
images	O
)	O
and	O
BSD200	O
[	O
reference	O
]	O
(	O
200	O
images	O
)	O
	
[	O
reference	O
]	O
are	O
used	O
to	O
evaluate	O
the	O
performance	O
of	O
upscaling	O
factors	O
2	O
,	O
3	O
,	O
and	O
4	O
.	O
	
Evaluation	B-Metric
metrics	I-Metric
.	O
	
Apart	O
from	O
the	O
widely	O
used	O
PSNR	B-Metric
and	O
SSIM	B-Metric
[	O
reference	O
]	O
indices	O
,	O
we	O
also	O
adopt	O
another	O
four	O
evaluation	B-Metric
matrices	I-Metric
,	O
namely	O
information	B-Metric
fidelity	I-Metric
criterion	I-Metric
(	O
IFC	B-Metric
)	O
[	O
reference	O
]	O
,	O
noise	B-Metric
quality	I-Metric
measure	I-Metric
(	O
NQM	B-Metric
)	O
[	O
reference	O
]	O
,	O
weighted	B-Metric
peak	I-Metric
signal	I-Metric
-	I-Metric
to	I-Metric
-	I-Metric
noise	I-Metric
ratio	I-Metric
(	O
WPSNR	B-Metric
)	O
and	O
multiscale	B-Metric
structure	I-Metric
similarity	I-Metric
index	I-Metric
(	O
MSSSIM	B-Metric
)	O
[	O
reference	O
]	O
,	O
which	O
obtain	O
high	O
correlation	O
with	O
the	O
human	B-Metric
perceptual	I-Metric
scores	I-Metric
as	O
reported	O
in	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
Quantitative	B-Metric
and	I-Metric
qualitative	I-Metric
evaluation	I-Metric
	
As	O
shown	O
in	O
Tables	O
2	O
,	O
3	O
and	O
4	O
,	O
the	O
proposed	O
SRCNN	B-Method
yields	O
the	O
highest	O
scores	O
in	O
most	O
evaluation	B-Metric
matrices	I-Metric
[	O
reference	O
]	O
.	O
	
In	O
the	O
area	O
of	O
denoising	B-Task
[	O
reference	O
]	O
,	O
for	O
each	O
noise	O
level	O
a	O
specific	O
network	O
is	O
trained	O
.	O
	
8	O
.	O
	
We	O
use	O
the	O
same	O
200	O
images	O
as	O
in	O
[	O
reference	O
]	O
.	O
in	O
all	O
experiments	O
[	O
reference	O
]	O
.	O
	
Note	O
that	O
our	O
SRCNN	B-Method
results	O
are	O
based	O
on	O
the	O
checkpoint	O
of	O
8	O
×	O
10	O
8	O
backpropagations	B-Method
.	O
	
Specifically	O
,	O
for	O
the	O
upscaling	O
factor	O
3	O
,	O
the	O
average	O
gains	O
on	O
PSNR	B-Metric
achieved	O
by	O
SRCNN	B-Method
are	O
0.15	O
dB	O
,	O
0.17	O
dB	O
,	O
and	O
0.13	O
dB	O
,	O
higher	O
than	O
the	O
next	O
best	O
approach	O
,	O
A	O
+	O
[	O
reference	O
]	O
,	O
on	O
the	O
three	O
datasets	O
.	O
	
When	O
we	O
take	O
a	O
look	O
at	O
other	O
evaluation	B-Metric
metrics	I-Metric
,	O
we	O
observe	O
that	O
SC	B-Method
,	O
to	O
our	O
surprise	O
,	O
gets	O
even	O
lower	O
scores	O
than	O
the	O
bicubic	B-Method
interpolation	I-Method
on	O
IFC	B-Method
and	O
NQM	B-Method
.	O
	
It	O
is	O
clear	O
that	O
the	O
results	O
of	O
SC	B-Method
are	O
more	O
visually	O
pleasing	O
than	O
that	O
of	O
bicubic	B-Method
interpolation	I-Method
.	O
	
This	O
indicates	O
that	O
these	O
two	O
metrics	O
may	O
not	O
truthfully	O
reveal	O
the	O
image	B-Metric
quality	I-Metric
.	O
	
Thus	O
,	O
regardless	O
of	O
these	O
two	O
metrics	O
,	O
SRCNN	B-Method
achieves	O
the	O
best	O
performance	O
among	O
all	O
methods	O
and	O
scaling	O
factors	O
.	O
	
It	O
is	O
worth	O
pointing	O
out	O
that	O
SRCNN	B-Method
surpasses	O
the	O
bicubic	B-Method
baseline	I-Method
at	O
the	O
very	O
beginning	O
of	O
the	O
learning	O
stage	O
(	O
see	O
Figure	O
1	O
)	O
,	O
and	O
with	O
moderate	O
training	O
,	O
SR	B-Task
-	O
CNN	B-Method
outperforms	O
existing	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
(	O
see	O
Figure	O
4	O
)	O
.	O
	
Yet	O
,	O
the	O
performance	O
is	O
far	O
from	O
converge	O
.	O
	
We	O
conjecture	O
that	O
better	O
results	O
can	O
be	O
obtained	O
given	O
longer	O
training	O
time	O
(	O
see	O
Figure	O
10	O
)	O
.	O
	
Figures	O
14	O
,	O
15	O
and	O
16	O
show	O
the	O
super	B-Metric
-	I-Metric
resolution	I-Metric
results	O
of	O
different	O
approaches	O
by	O
an	O
upscaling	O
factor	O
3	O
.	O
	
As	O
can	O
be	O
observed	O
,	O
the	O
SRCNN	B-Method
produces	O
much	O
sharper	O
edges	O
than	O
other	O
approaches	O
without	O
any	O
obvious	O
artifacts	O
across	O
the	O
image	O
.	O
	
In	O
addition	O
,	O
we	O
report	O
to	O
another	O
recent	O
deep	B-Method
learning	I-Method
method	I-Method
for	O
image	B-Task
super	I-Task
-	I-Task
resolution	I-Task
(	O
DNC	B-Task
)	O
of	O
Cui	O
et	O
al	O
.	O
	
[	O
reference	O
]	O
.	O
	
As	O
they	O
employ	O
a	O
different	O
blur	O
kernel	O
(	O
a	O
Gaussian	B-Method
filter	I-Method
with	O
a	O
standard	O
deviation	O
of	O
0.55	O
)	O
,	O
we	O
train	O
a	O
specific	O
network	O
(	O
9	O
-	O
5	O
-	O
5	O
)	O
using	O
the	O
same	O
blur	O
kernel	O
as	O
DNC	B-Method
for	O
fair	O
quantitative	O
comparison	O
.	O
	
The	O
upscaling	O
factor	O
is	O
3	O
and	O
the	O
training	O
set	O
is	O
the	O
91	O
-	O
image	O
dataset	O
.	O
	
From	O
the	O
convergence	O
curve	O
shown	O
in	O
Figure	O
11	O
,	O
we	O
observe	O
that	O
our	O
SRCNN	B-Method
surpasses	O
DNC	B-Method
with	O
just	O
2.7	O
×	O
10	O
7	O
backprops	O
,	O
and	O
a	O
larger	O
margin	O
can	O
be	O
obtained	O
given	O
longer	O
training	O
time	O
.	O
	
This	O
also	O
demonstrates	O
that	O
the	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
learning	I-Method
is	O
superior	O
to	O
DNC	B-Method
,	O
even	O
if	O
that	O
model	O
is	O
already	O
"	O
deep	O
"	O
.	O
	
Figure	O
12	O
shows	O
the	O
running	B-Metric
time	I-Metric
comparisons	O
of	O
several	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
,	O
along	O
with	O
their	O
restoration	B-Method
performance	O
on	O
Set14	B-Material
.	O
	
All	O
baseline	O
methods	O
are	O
obtained	O
[	O
reference	O
]	O
.	O
The	O
PSNR	B-Metric
value	O
of	O
each	O
image	O
can	O
be	O
found	O
in	O
the	O
supplementary	O
file	O
.	O
	
section	O
:	O
Running	O
time	O
	
from	O
the	O
corresponding	O
authors	O
'	O
MATLAB	B-Method
+	I-Method
MEX	I-Method
implementation	I-Method
,	O
whereas	O
ours	O
are	O
in	O
pure	O
C	O
++	O
.	O
	
We	O
profile	O
the	O
running	O
time	O
of	O
all	O
the	O
algorithms	O
using	O
the	O
same	O
machine	O
(	O
Intel	O
CPU	O
3.10	O
GHz	O
and	O
16	O
GB	O
memory	O
)	O
.	O
	
Note	O
that	O
the	O
processing	B-Metric
time	I-Metric
of	O
our	O
approach	O
is	O
highly	O
linear	O
to	O
the	O
test	O
image	O
resolution	O
,	O
since	O
all	O
images	O
go	O
through	O
the	O
same	O
number	O
of	O
convolutions	O
.	O
	
Our	O
method	O
is	O
always	O
a	O
trade	O
-	O
off	O
between	O
performance	O
and	O
speed	B-Metric
.	O
	
To	O
show	O
this	O
,	O
we	O
train	O
three	O
networks	O
for	O
comparison	O
,	O
which	O
are	O
9	O
-	O
1	O
-	O
5	O
,	O
9	O
-	O
3	O
-	O
5	O
,	O
and	O
9	O
-	O
5	O
-	O
5	O
.	O
	
It	O
is	O
clear	O
that	O
the	O
9	B-Method
-	I-Method
1	I-Method
-	I-Method
5	I-Method
network	I-Method
is	O
the	O
fastest	O
,	O
while	O
it	O
still	O
achieves	O
better	O
performance	O
than	O
the	O
next	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
A	O
+	O
.	O
	
Other	O
methods	O
are	O
several	O
times	O
or	O
even	O
orders	O
of	O
magnitude	O
slower	O
in	O
comparison	O
to	O
9	O
-	O
1	O
-	O
5	O
network	O
.	O
	
Note	O
the	O
speed	B-Metric
gap	O
is	O
not	O
mainly	O
caused	O
by	O
the	O
different	O
MATLAB	B-Method
/	I-Method
C	I-Method
++	I-Method
implementations	I-Method
;	O
rather	O
,	O
the	O
other	O
methods	O
need	O
to	O
solve	O
complex	O
optimization	B-Task
problems	I-Task
on	O
usage	O
(	O
e.g.	O
,	O
sparse	B-Task
coding	I-Task
or	O
embedding	B-Task
)	O
,	O
whereas	O
our	O
method	O
is	O
completely	O
feed	B-Method
-	I-Method
forward	I-Method
.	O
	
The	O
9	O
-	O
5	O
-	O
5	O
network	O
achieves	O
the	O
best	O
performance	O
but	O
at	O
the	O
cost	O
of	O
the	O
running	B-Metric
time	I-Metric
.	O
	
The	O
test	O
-	O
time	O
speed	B-Metric
of	O
our	O
CNN	B-Method
can	O
be	O
further	O
accelerated	O
in	O
many	O
ways	O
,	O
e.g.	O
,	O
approximating	O
or	O
simplifying	O
the	O
trained	O
networks	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
with	O
possible	O
slight	O
degradation	O
in	O
performance	O
.	O
	
section	O
:	O
Experiments	O
on	O
Color	O
Channels	O
	
In	O
previous	O
experiments	O
,	O
we	O
follow	O
the	O
conventional	O
approach	O
to	O
super	B-Task
-	I-Task
resolve	I-Task
color	I-Task
images	I-Task
.	O
	
Specifically	O
,	O
we	O
first	O
transform	O
the	O
color	O
images	O
into	O
the	O
YCbCr	O
space	O
.	O
	
The	O
SR	B-Task
algorithms	O
are	O
only	O
applied	O
on	O
the	O
Y	O
channel	O
,	O
while	O
the	O
Cb	O
,	O
Cr	O
channels	O
are	O
upscaled	O
by	O
bicubic	B-Method
interpolation	I-Method
.	O
	
It	O
is	O
interesting	O
to	O
find	O
out	O
if	O
super	B-Metric
-	I-Metric
resolution	I-Metric
performance	I-Metric
can	O
be	O
improved	O
if	O
we	O
jointly	O
consider	O
all	O
three	O
channels	O
in	O
the	O
process	O
.	O
	
Our	O
method	O
is	O
flexible	O
to	O
accept	O
more	O
channels	O
without	O
altering	O
the	O
learning	B-Method
mechanism	I-Method
and	O
network	B-Method
design	I-Method
.	O
	
In	O
particular	O
,	O
it	O
can	O
readily	O
deal	O
with	O
three	O
channels	O
simultaneously	O
by	O
setting	O
the	O
input	O
channels	O
to	O
c	O
=	O
3	O
.	O
	
In	O
the	O
following	O
experiments	O
,	O
we	O
explore	O
different	O
training	B-Method
strategies	I-Method
for	O
color	B-Task
image	I-Task
super	I-Task
-	I-Task
resolution	I-Task
,	O
and	O
subsequently	O
evaluate	O
their	O
performance	O
on	O
different	O
channels	O
.	O
	
Implementation	O
details	O
.	O
	
Training	O
is	O
performed	O
on	O
the	O
91	O
-	O
image	O
dataset	O
,	O
and	O
testing	O
is	O
conducted	O
on	O
the	O
Set5	B-Material
	
[	O
reference	O
]	O
.	O
	
The	O
network	O
settings	O
are	O
:	O
c	O
=	O
3	O
,	O
f	O
1	O
=	O
9	O
,	O
f	O
2	O
=	O
1	O
,	O
f	O
3	O
=	O
5	O
,	O
n	O
1	O
=	O
64	O
,	O
and	O
n	O
2	O
=	O
32	O
.	O
	
As	O
we	O
have	O
proved	O
the	O
SRCNN	B-Method
(	O
9	O
-	O
3	O
-	O
5	O
)	O
SRCNN	B-Method
[	O
reference	O
]	O
--	O
>	O
	
Faster	O
Slower	O
<	O
--	O
Fig	O
.	O
12	O
.	O
	
The	O
proposed	O
SRCNN	B-Method
achieves	O
the	O
stateof	O
-	O
the	O
-	O
art	O
super	B-Metric
-	I-Metric
resolution	I-Metric
quality	I-Metric
,	O
whilst	O
maintains	O
high	O
and	O
competitive	O
speed	B-Metric
in	O
comparison	O
to	O
existing	O
external	B-Method
example	I-Method
-	I-Method
based	I-Method
methods	I-Method
.	O
	
The	O
chart	O
is	O
based	O
on	O
Set14	B-Material
results	O
summarized	O
in	O
Table	O
3	O
.	O
	
The	O
implementation	O
of	O
all	O
three	O
SRCNN	B-Method
networks	O
are	O
available	O
on	O
our	O
project	O
page	O
.	O
	
Comparisons	O
.	O
	
We	O
compare	O
our	O
method	O
with	O
the	O
stateof	O
-	O
art	O
color	O
SR	B-Task
method	O
-	O
KK	O
	
[	O
reference	O
]	O
.	O
	
We	O
also	O
try	O
different	O
learning	B-Method
strategies	I-Method
for	O
comparison	O
:	O
	
•	O
	
Y	O
only	O
:	O
this	O
is	O
our	O
baseline	O
method	O
,	O
which	O
is	O
a	O
single	O
-	O
channel	O
(	O
c	O
=	O
1	O
)	O
network	O
trained	O
only	O
on	O
the	O
luminance	O
channel	O
.	O
	
The	O
Cb	O
,	O
Cr	O
channels	O
are	O
upscaled	O
using	O
bicubic	B-Method
interpolation	I-Method
.	O
	
•	O
	
YCbCr	B-Method
:	O
training	B-Method
is	O
performed	O
on	O
the	O
three	O
channels	O
of	O
the	O
YCbCr	O
space	O
.	O
	
•	O
	
Y	O
pre	O
-	O
train	O
:	O
	
first	O
,	O
to	O
guarantee	O
the	O
performance	O
on	O
the	O
Y	O
channel	O
,	O
we	O
only	O
use	O
the	O
MSE	B-Metric
of	O
the	O
Y	O
channel	O
as	O
the	O
loss	O
to	O
pre	O
-	O
train	O
the	O
network	O
.	O
	
Then	O
we	O
employ	O
the	O
MSE	B-Metric
of	O
all	O
channels	O
to	O
fine	O
-	O
tune	O
the	O
parameters	O
.	O
	
•	O
	
CbCr	O
pre	O
-	O
train	O
	
:	O
we	O
use	O
the	O
MSE	B-Metric
of	O
the	O
Cb	O
,	O
Cr	O
channels	O
as	O
the	O
loss	O
to	O
pre	O
-	O
train	O
the	O
network	O
,	O
then	O
fine	O
-	O
tune	O
the	O
parameters	O
on	O
all	O
channels	O
.	O
	
•	O
	
RGB	O
:	O
	
training	B-Method
is	O
performed	O
on	O
the	O
three	O
channels	O
of	O
the	O
RGB	O
space	O
.	O
	
The	O
results	O
are	O
shown	O
in	O
Table	O
5	O
,	O
where	O
we	O
have	O
the	O
following	O
observations	O
.	O
	
(	O
i	O
)	O
	
If	O
we	O
directly	O
train	O
on	O
the	O
YCbCr	O
channels	O
,	O
the	O
results	O
are	O
even	O
worse	O
than	O
that	O
of	O
bicubic	B-Method
interpolation	I-Method
.	O
	
The	O
training	O
falls	O
into	O
a	O
bad	O
local	O
minimum	O
,	O
due	O
to	O
the	O
inherently	O
different	O
characteristics	O
of	O
the	O
Y	O
and	O
Cb	O
,	O
Cr	O
channels	O
.	O
	
(	O
ii	O
)	O
	
If	O
we	O
pre	O
-	O
train	O
on	O
the	O
Y	O
or	O
Cb	O
,	O
Cr	O
channels	O
,	O
the	O
performance	O
finally	O
improves	O
,	O
but	O
is	O
still	O
not	O
better	O
than	O
"	O
Y	O
only	O
"	O
on	O
the	O
color	O
image	O
(	O
see	O
the	O
last	O
column	O
of	O
Table	O
5	O
,	O
where	O
PSNR	B-Metric
is	O
computed	O
Fig	O
.	O
13	O
.	O
	
Chrominance	O
channels	O
of	O
the	O
first	B-Method
-	I-Method
layer	I-Method
filters	I-Method
using	O
the	O
"	O
Y	B-Method
pre	I-Method
-	I-Method
train	I-Method
"	I-Method
strategy	I-Method
.	O
	
in	O
RGB	O
color	O
space	O
)	O
.	O
	
This	O
suggests	O
that	O
the	O
Cb	O
,	O
Cr	O
channels	O
could	O
decrease	O
the	O
performance	O
of	O
the	O
Y	B-Method
channel	I-Method
when	O
training	B-Task
is	O
performed	O
in	O
a	O
unified	B-Method
network	I-Method
.	O
	
(	O
iii	O
)	O
	
We	O
observe	O
that	O
the	O
Cb	O
,	O
Cr	O
channels	O
have	O
higher	O
PSNR	B-Metric
values	O
for	O
"	O
Y	O
pre	O
-	O
train	O
"	O
than	O
for	O
"	O
CbCr	O
pre	O
-	O
train	O
"	O
.	O
	
The	O
reason	O
lies	O
on	O
the	O
differences	O
between	O
the	O
Cb	O
,	O
Cr	O
channels	O
and	O
the	O
Y	B-Method
channel	I-Method
.	O
	
Visually	O
,	O
the	O
Cb	O
,	O
Cr	O
channels	O
are	O
more	O
blurry	O
than	O
the	O
Y	O
channel	O
,	O
thus	O
are	O
less	O
affected	O
by	O
the	O
downsampling	B-Method
process	I-Method
.	O
	
When	O
we	O
pre	O
-	O
train	O
on	O
the	O
Cb	O
,	O
Cr	O
channels	O
,	O
there	O
are	O
only	O
a	O
few	O
filters	O
being	O
activated	O
.	O
	
Then	O
the	O
training	O
will	O
soon	O
fall	O
into	O
a	O
bad	O
local	O
minimum	O
during	O
fine	B-Method
-	I-Method
tuning	I-Method
.	O
	
On	O
the	O
other	O
hand	O
,	O
if	O
we	O
pre	O
-	O
train	O
on	O
the	O
Y	O
channel	O
,	O
more	O
filters	O
will	O
be	O
activated	O
,	O
and	O
the	O
performance	O
on	O
Cb	O
,	O
Cr	O
channels	O
will	O
be	O
pushed	O
much	O
higher	O
.	O
	
Figure	O
13	O
shows	O
the	O
Cb	O
,	O
Cr	O
channels	O
of	O
the	O
first	B-Method
-	I-Method
layer	I-Method
filters	I-Method
with	O
"	O
Y	O
pre	O
-	O
train	O
"	O
,	O
of	O
which	O
the	O
patterns	O
largely	O
differ	O
from	O
that	O
shown	O
in	O
Figure	O
5	O
.	O
	
(	O
iv	O
)	O
	
Training	O
on	O
the	O
RGB	O
channels	O
achieves	O
the	O
best	O
result	O
on	O
the	O
color	O
image	O
.	O
	
Different	O
from	O
the	O
YCbCr	O
channels	O
,	O
the	O
RGB	O
channels	O
exhibit	O
high	O
crosscorrelation	O
among	O
each	O
other	O
.	O
	
The	O
proposed	O
SRCNN	B-Method
is	O
capable	O
of	O
leveraging	O
such	O
natural	O
correspondences	O
between	O
the	O
channels	O
for	O
reconstruction	B-Task
.	O
	
Therefore	O
,	O
the	O
model	O
achieves	O
comparable	O
result	O
on	O
the	O
Y	O
channel	O
as	O
"	O
Y	O
only	O
"	O
,	O
and	O
better	O
results	O
on	O
Cb	O
,	O
Cr	O
channels	O
than	O
bicubic	B-Method
interpolation	I-Method
.	O
	
(	O
v	O
)	O
	
In	O
KK	O
[	O
reference	O
]	O
,	O
super	B-Task
-	I-Task
resolution	I-Task
is	O
applied	O
on	O
each	O
RGB	O
channel	O
separately	O
.	O
	
When	O
we	O
transform	O
its	O
results	O
to	O
YCbCr	O
space	O
,	O
the	O
PSNR	B-Metric
value	O
of	O
Y	O
channel	O
is	O
similar	O
as	O
"	O
Y	O
only	O
"	O
,	O
but	O
that	O
of	O
Cb	O
,	O
Cr	O
channels	O
are	O
poorer	O
than	O
bicubic	B-Method
interpolation	I-Method
.	O
	
The	O
result	O
suggests	O
that	O
the	O
algorithm	O
is	O
biased	O
to	O
the	O
Y	O
channel	O
.	O
	
On	O
the	O
whole	O
,	O
our	O
method	O
trained	O
on	O
RGB	O
channels	O
achieves	O
better	O
performance	O
than	O
KK	B-Method
and	O
the	O
singlechannel	B-Method
network	I-Method
(	O
	
"	O
Y	O
only	O
"	O
)	O
.	O
	
It	O
is	O
also	O
worth	O
noting	O
that	O
the	O
improvement	O
compared	O
with	O
the	O
single	B-Method
-	I-Method
channel	I-Method
network	I-Method
is	O
not	O
that	O
significant	O
(	O
i.e.	O
,	O
0.07	O
dB	O
)	O
.	O
	
This	O
indicates	O
that	O
the	O
Cb	O
,	O
Cr	O
channels	O
barely	O
help	O
in	O
improving	O
the	O
performance	O
.	O
	
section	O
:	O
CONCLUSION	O
	
We	O
have	O
presented	O
a	O
novel	O
deep	B-Method
learning	I-Method
approach	I-Method
for	O
single	B-Task
image	I-Task
super	I-Task
-	I-Task
resolution	I-Task
(	O
SR	B-Task
)	O
.	O
	
We	O
show	O
that	O
conventional	O
sparse	O
-	O
coding	O
-	O
based	O
SR	B-Task
methods	O
can	O
be	O
reformulated	O
into	O
a	O
deep	B-Method
convolutional	I-Method
neural	I-Method
network	I-Method
.	O
	
The	O
proposed	O
approach	O
,	O
SRCNN	B-Method
,	O
learns	O
an	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
mapping	I-Task
between	O
low	O
-	O
and	O
high	O
-	O
resolution	O
images	O
,	O
with	O
little	O
extra	O
pre	O
/	O
post	O
-	O
processing	O
beyond	O
the	O
optimization	B-Task
.	O
	
With	O
a	O
lightweight	B-Method
structure	I-Method
,	O
the	O
SRCNN	B-Method
has	O
achieved	O
superior	O
performance	O
than	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
.	O
	
We	O
conjecture	O
that	O
additional	O
performance	O
can	O
be	O
further	O
gained	O
by	O
exploring	O
more	O
filters	O
and	O
different	O
training	B-Method
strategies	I-Method
.	O
	
Besides	O
,	O
the	O
proposed	O
structure	O
,	O
with	O
its	O
advantages	O
of	O
simplicity	O
and	O
robustness	B-Metric
,	O
could	O
be	O
applied	O
to	O
other	O
low	B-Task
-	I-Task
level	I-Task
vision	I-Task
problems	I-Task
,	O
such	O
as	O
image	B-Task
deblurring	I-Task
or	O
simultaneous	O
SR	B-Task
+	O
denoising	O
.	O
	
One	O
could	O
also	O
investigate	O
a	O
network	O
to	O
cope	O
with	O
different	O
upscaling	O
factors	O
.	O
	
section	O
:	O
	
section	O
:	O
	
section	O
:	O
	
document	O
:	O
FacePoseNet	B-Method
:	O
Making	O
a	O
Case	O
for	O
Landmark	B-Task
-	I-Task
Free	I-Task
Face	I-Task
Alignment	I-Task
	
We	O
show	O
how	O
a	O
simple	O
convolutional	B-Method
neural	I-Method
network	I-Method
(	O
CNN	B-Method
)	O
can	O
be	O
trained	O
to	O
accurately	O
and	O
robustly	O
regress	O
6	O
degrees	O
of	O
freedom	O
(	O
6DoF	O
	
)	O
3D	O
head	O
pose	O
,	O
directly	O
from	O
image	O
intensities	O
.	O
	
We	O
further	O
explain	O
how	O
this	O
FacePoseNet	B-Method
(	O
FPN	B-Method
)	O
can	O
be	O
used	O
to	O
align	O
faces	O
in	O
2D	O
and	O
3D	O
as	O
an	O
alternative	O
to	O
explicit	B-Task
facial	I-Task
landmark	I-Task
detection	I-Task
for	O
these	O
tasks	O
.	O
	
We	O
claim	O
that	O
in	O
many	O
cases	O
the	O
standard	O
means	O
of	O
measuring	O
landmark	O
detector	O
accuracy	B-Metric
can	O
be	O
misleading	O
when	O
comparing	O
different	O
face	O
alignments	O
.	O
	
Instead	O
,	O
we	O
compare	O
our	O
FPN	B-Method
with	O
existing	O
methods	O
by	O
evaluating	O
how	O
they	O
affect	O
face	B-Metric
recognition	I-Metric
accuracy	I-Metric
on	O
the	O
IJB	B-Material
-	I-Material
A	I-Material
and	O
IJB	B-Material
-	I-Material
B	I-Material
benchmarks	I-Material
:	O
using	O
the	O
same	O
recognition	B-Method
pipeline	I-Method
,	O
but	O
varying	O
the	O
face	B-Method
alignment	I-Method
method	I-Method
.	O
	
Our	O
results	O
show	O
that	O
(	O
a	O
)	O
better	O
landmark	O
detection	O
accuracy	B-Metric
measured	O
on	O
the	O
300W	B-Material
benchmark	I-Material
does	O
not	O
necessarily	O
imply	O
better	O
face	B-Metric
recognition	I-Metric
accuracy	I-Metric
.	O
	
(	O
b	O
)	O
Our	O
FPN	B-Method
provides	O
superior	O
2D	B-Task
and	O
3D	B-Task
face	I-Task
alignment	I-Task
on	O
both	O
benchmarks	O
.	O
	
Finally	O
,	O
(	O
c	O
)	O
,	O
FPN	B-Method
aligns	O
faces	O
at	O
a	O
small	O
fraction	O
of	O
the	O
computational	B-Metric
cost	I-Metric
of	O
comparably	O
accurate	O
landmark	B-Method
detectors	I-Method
.	O
	
For	O
many	O
purposes	O
,	O
FPN	B-Method
is	O
thus	O
a	O
far	O
faster	O
and	O
far	O
more	O
accurate	O
face	B-Method
alignment	I-Method
method	I-Method
than	O
using	O
facial	B-Method
landmark	I-Method
detectors	I-Method
.	O
	
section	O
:	O
Introduction	O
	
Facial	B-Task
landmark	I-Task
detection	I-Task
is	O
rarely	O
,	O
if	O
ever	O
,	O
an	O
application	O
in	O
its	O
own	O
right	O
.	O
	
Instead	O
,	O
it	O
is	O
typically	O
a	O
means	O
to	O
an	O
end	O
:	O
It	O
is	O
one	O
component	O
out	O
of	O
many	O
in	O
pipelines	B-Method
designed	O
for	O
other	O
face	B-Task
understanding	I-Task
and	I-Task
processing	I-Task
tasks	I-Task
,	O
often	O
providing	O
effective	O
means	O
for	O
aligning	B-Task
face	I-Task
photos	I-Task
and	O
making	O
them	O
easier	O
to	O
process	O
.	O
	
Most	O
facial	B-Method
landmark	I-Method
detectors	I-Method
,	O
however	O
,	O
are	O
developed	O
without	O
measuring	O
their	O
impact	O
on	O
these	O
applications	O
but	O
rather	O
using	O
standard	O
facial	B-Method
landmark	I-Method
detection	I-Method
benchmarks	I-Method
such	O
as	O
the	O
popular	O
AFW	B-Method
,	O
LFPW	B-Method
,	O
HELEN	B-Method
,	O
and	O
IBUG	B-Method
.	O
	
These	O
benchmarks	O
contain	O
face	O
images	O
with	O
manually	O
labeled	O
ground	O
truth	O
landmarks	O
.	O
	
Better	O
detection	O
accuracy	B-Metric
on	O
these	O
benchmarks	O
equals	O
better	O
prediction	O
of	O
these	O
manual	O
positions	O
.	O
	
This	O
raises	O
an	O
important	O
question	O
:	O
Does	O
better	O
approximation	O
of	O
such	O
human	O
labeled	O
landmarks	O
imply	O
better	O
face	B-Task
alignment	I-Task
and	O
consequently	O
better	O
face	B-Task
understanding	I-Task
?	O
	
Images	O
one	O
,	O
three	O
,	O
and	O
five	O
are	O
ground	O
truth	O
.	O
	
Why	O
would	O
higher	O
accuracy	B-Metric
on	O
landmark	B-Task
detection	I-Task
benchmarks	O
not	O
imply	O
better	O
alignment	B-Task
?	O
	
The	O
many	O
landmark	B-Task
detection	I-Task
benchmarks	I-Task
used	O
by	O
the	O
community	O
to	O
measure	O
detection	O
accuracy	B-Metric
typically	O
offer	O
5	O
,	O
49	O
or	O
68	O
landmarks	O
painstakingly	O
labeled	O
on	O
hundreds	O
or	O
thousands	O
of	O
unconstrained	O
face	O
images	O
,	O
reflecting	O
wide	O
viewpoint	O
,	O
resolution	O
and	O
noise	O
variations	O
.	O
	
On	O
low	O
resolution	O
images	O
,	O
however	O
,	O
even	O
expert	O
human	O
operators	O
can	O
find	O
it	O
hard	O
to	O
accurately	O
pinpoint	O
landmark	O
positions	O
.	O
	
More	O
importantly	O
,	O
many	O
landmark	O
locations	O
are	O
not	O
well	O
defined	O
even	O
in	O
high	O
resolution	O
(	O
e.g.	O
,	O
points	O
along	O
the	O
jawline	O
or	O
behind	O
occlusions	O
)	O
.	O
	
Thus	O
,	O
improved	O
landmark	O
detection	O
accuracy	B-Metric
may	O
actually	O
reflect	O
better	O
estimation	O
of	O
uncertain	O
human	O
labels	O
rather	O
than	O
better	O
face	B-Task
alignment	I-Task
(	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
An	O
additional	O
concern	O
relates	O
to	O
how	O
landmarks	O
are	O
used	O
for	O
face	B-Task
alignment	I-Task
.	O
	
Face	B-Task
alignment	I-Task
often	O
implies	O
using	O
a	O
global	O
2D	O
or	O
3D	O
transformation	O
to	O
warp	O
faces	O
to	O
ideal	O
,	O
reference	O
frames	O
:	O
Detected	O
landmarks	O
are	O
matched	O
with	O
their	O
corresponding	O
landmarks	O
in	O
the	O
reference	O
coordinates	O
and	O
a	O
2D	O
or	O
3D	O
transformation	O
is	O
then	O
computed	O
by	O
robust	B-Method
estimation	I-Method
methods	I-Method
.	O
	
To	O
our	O
knowledge	O
,	O
the	O
effects	O
landmark	O
detection	O
noise	O
,	O
changing	O
expressions	O
or	O
face	O
shapes	O
have	O
on	O
these	O
estimated	O
transformations	O
were	O
never	O
fully	O
explored	O
.	O
	
Responding	O
to	O
these	O
concerns	O
,	O
we	O
offer	O
several	O
contributions	O
.	O
	
(	O
1	O
)	O
	
We	O
propose	O
comparing	O
landmark	B-Method
detection	I-Method
methods	I-Method
by	O
evaluating	O
bottom	O
line	O
face	O
recognition	O
accuracy	B-Metric
on	O
faces	O
aligned	O
with	O
these	O
methods	O
.	O
	
(	O
2	O
)	O
	
As	O
an	O
alternative	O
to	O
existing	O
facial	B-Method
landmark	I-Method
detectors	I-Method
,	O
we	O
further	O
present	O
a	O
robust	O
and	O
accurate	O
,	O
landmark	B-Method
-	I-Method
free	I-Method
method	I-Method
for	O
face	B-Task
alignment	I-Task
:	O
our	O
deep	B-Method
FacePoseNet	I-Method
(	O
FPN	B-Method
)	O
.	O
	
We	O
show	O
it	O
to	O
excel	O
at	O
global	B-Task
,	I-Task
3D	I-Task
face	I-Task
alignment	I-Task
even	O
under	O
the	O
most	O
challenging	O
viewing	O
conditions	O
.	O
	
Finally	O
,	O
(	O
3	O
)	O
,	O
we	O
test	O
our	O
FPN	B-Method
extensively	O
and	O
report	O
that	O
better	O
landmark	O
detection	O
accuracy	B-Metric
on	O
the	O
widely	O
used	O
300W	B-Material
benchmark	I-Material
does	O
not	O
imply	O
better	O
alignment	B-Task
and	O
recognition	B-Task
on	O
the	O
highly	O
challenging	O
IJB	B-Material
-	I-Material
A	I-Material
and	O
IJB	B-Material
-	I-Material
B	I-Material
benchmarks	I-Material
.	O
	
In	O
particular	O
,	O
recognition	B-Task
results	O
on	O
images	O
aligned	O
with	O
our	O
FPN	B-Method
surpass	O
those	O
on	O
images	O
aligned	O
with	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
detectors	O
.	O
	
Some	O
applications	O
require	O
landmark	B-Task
estimation	I-Task
.	O
	
Our	O
FPN	B-Method
provides	O
a	O
more	O
accurate	O
and	O
far	O
faster	O
face	B-Method
alignment	I-Method
technique	I-Method
in	O
the	O
many	O
cases	O
where	O
global	B-Task
alignment	I-Task
,	O
rather	O
than	O
specific	O
landmark	O
positions	O
,	O
is	O
needed	O
.	O
	
To	O
support	O
our	O
claims	O
,	O
we	O
make	O
our	O
code	O
publicly	O
available	O
.	O
	
section	O
:	O
Related	O
work	O
	
Applications	O
of	O
facial	B-Method
landmark	I-Method
detectors	I-Method
.	O
	
Facial	B-Task
landmark	I-Task
detection	I-Task
is	O
big	O
business	O
,	O
as	O
reflected	O
by	O
the	O
numerous	O
citation	O
to	O
relevant	O
papers	O
,	O
the	O
many	O
facial	B-Task
landmark	I-Task
detection	I-Task
benchmarks	I-Task
,	O
and	O
popular	O
international	O
events	O
dedicated	O
to	O
this	O
problem	O
.	O
	
With	O
all	O
this	O
effort	O
,	O
a	O
rigorous	O
survey	O
of	O
the	O
many	O
applications	O
of	O
facial	B-Task
landmarks	I-Task
is	O
outside	O
the	O
scope	O
of	O
this	O
paper	O
.	O
	
In	O
lieu	O
of	O
such	O
a	O
survey	O
,	O
and	O
to	O
get	O
some	O
idea	O
of	O
why	O
this	O
problem	O
attracts	O
so	O
much	O
attention	O
,	O
we	O
offer	O
the	O
following	O
cursory	O
study	O
.	O
	
We	O
consider	O
two	O
of	O
the	O
most	O
widely	O
cited	O
face	B-Task
landmark	I-Task
detector	I-Task
papers	O
of	O
the	O
last	O
decade	O
,	O
the	O
tree	B-Method
based	I-Method
approach	I-Method
and	O
supervised	B-Method
descent	I-Method
method	I-Method
.	O
	
At	O
the	O
time	O
of	O
writing	O
,	O
based	O
on	O
Google	O
Scholar	O
,	O
the	O
latter	O
accumulated	O
nearly	O
a	O
thousand	O
citations	O
and	O
the	O
former	O
well	O
over	O
a	O
thousand	O
.	O
	
We	O
found	O
23	O
application	O
names	O
appearing	O
frequently	O
(	O
more	O
than	O
ten	O
times	O
)	O
in	O
the	O
titles	O
of	O
the	O
papers	O
that	O
cite	O
these	O
two	O
and	O
counted	O
the	O
number	O
of	O
times	O
these	O
applications	O
were	O
mentioned	O
.	O
	
The	O
relative	O
frequencies	O
of	O
these	O
applications	O
are	O
reported	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Of	O
course	O
,	O
this	O
simple	O
survey	O
is	O
by	O
no	O
means	O
accurate	O
:	O
the	O
same	O
term	O
is	O
counted	O
twice	O
if	O
the	O
paper	O
using	O
it	O
in	O
its	O
title	O
	
cites	O
both	O
and	O
and	O
many	O
paper	O
titles	O
do	O
not	O
clearly	O
state	O
the	O
application	O
they	O
describe	O
	
(	O
e.g.	O
,	O
describes	O
a	O
method	O
for	O
face	B-Task
alignment	I-Task
in	O
3D	B-Task
but	O
does	O
not	O
mention	O
“	O
alignment	O
”	O
in	O
the	O
title	O
)	O
.	O
	
Nevertheless	O
,	O
with	O
around	O
two	O
thousand	O
papers	O
included	O
in	O
this	O
survey	O
,	O
the	O
result	O
is	O
quite	O
clear	O
:	O
Alignment	B-Task
,	O
face	B-Task
recognition	I-Task
and	O
pose	B-Task
estimation	I-Task
–	O
also	O
considered	O
alignment	B-Task
–	O
are	O
overwhelmingly	O
more	O
popular	O
than	O
any	O
other	O
application	O
.	O
	
This	O
,	O
of	O
course	O
,	O
excluding	O
other	O
landmark	B-Task
detection	I-Task
papers	I-Task
.	O
	
What	O
does	O
it	O
mean	O
to	O
align	O
a	O
face	O
?	O
	
The	O
term	O
alignment	O
almost	O
always	O
appears	O
in	O
the	O
titles	O
of	O
papers	O
which	O
present	O
facial	B-Method
landmark	I-Method
detection	I-Method
methods	I-Method
(	O
and	O
most	O
others	O
)	O
implying	O
that	O
the	O
two	O
terms	O
are	O
used	O
interchangeability	O
.	O
	
This	O
reflects	O
an	O
interpretation	O
of	O
alignment	B-Task
as	O
forming	O
correspondences	O
between	O
particular	O
spatial	O
locations	O
in	O
one	O
face	O
image	O
and	O
another	O
.	O
	
A	O
different	O
interpretation	O
of	O
alignment	B-Task
,	O
and	O
the	O
one	O
used	O
here	O
,	O
refers	O
not	O
only	O
to	O
establishing	O
these	O
correspondences	O
but	O
also	O
to	O
warping	O
the	O
two	O
face	O
images	O
,	O
thus	O
making	O
them	O
easier	O
to	O
compare	O
and	O
match	O
.	O
	
Face	B-Task
warping	I-Task
with	O
estimated	B-Task
2D	I-Task
(	I-Task
in	I-Task
-	I-Task
plane	I-Task
)	I-Task
or	I-Task
3D	I-Task
transformations	I-Task
is	O
well	O
known	O
to	O
have	O
a	O
profound	O
impact	O
on	O
the	O
performance	O
of	O
face	B-Task
recognition	I-Task
systems	I-Task
.	O
	
Although	O
sometimes	O
alignments	O
involve	O
non	B-Method
-	I-Method
parametric	I-Method
or	O
part	B-Method
-	I-Method
based	I-Method
warps	I-Method
,	O
often	O
,	O
global	O
2D	O
or	O
3D	O
(	O
parametric	O
)	O
transformation	O
are	O
all	O
that	O
is	O
required	O
for	O
this	O
purpose	O
.	O
	
Such	O
aligned	O
faces	O
are	O
then	O
further	O
processed	O
in	O
systems	O
for	O
face	B-Task
recognition	I-Task
,	O
emotion	B-Task
recognition	I-Task
,	O
age	B-Task
and	I-Task
gender	I-Task
estimation	I-Task
,	O
and	O
more	O
.	O
	
In	O
fact	O
,	O
it	O
was	O
recently	O
claimed	O
that	O
a	O
global	B-Method
alignment	I-Method
is	O
both	O
more	O
robust	O
and	O
far	O
faster	O
to	O
warp	O
than	O
non	B-Method
-	I-Method
parametric	I-Method
transformations	I-Method
.	O
	
This	O
paper	O
focuses	O
on	O
such	O
global	O
transformations	O
,	O
showing	O
how	O
they	O
can	O
be	O
estimated	O
quickly	O
and	O
accurately	O
using	O
a	O
deep	B-Method
neural	I-Method
network	I-Method
.	O
	
Deep	B-Task
pose	I-Task
estimation	I-Task
.	O
	
This	O
work	O
describes	O
a	O
deep	B-Method
network	I-Method
trained	O
to	O
estimate	O
the	O
6DoF	B-Task
of	O
3D	B-Task
faces	I-Task
viewed	O
in	O
single	O
images	O
.	O
	
Deep	B-Method
learning	I-Method
is	O
increasingly	O
used	O
for	O
similar	O
purposes	O
,	O
though	O
typically	O
focusing	O
on	O
general	O
object	O
classes	O
.	O
	
Some	O
recently	O
addressed	O
faces	O
in	O
particular	O
,	O
though	O
their	O
methods	O
are	O
designed	O
to	O
estimate	O
2D	O
landmarks	O
along	O
with	O
3D	O
face	O
shapes	O
.	O
	
Unlike	O
our	O
proposed	O
pose	B-Method
estimation	I-Method
,	O
they	O
regress	O
poses	O
by	O
using	O
iterative	B-Method
methods	I-Method
which	O
involve	O
computationally	O
costly	O
face	B-Task
rendering	I-Task
.	O
	
We	O
regress	O
6DoF	O
directly	O
from	O
image	O
intensities	O
without	O
such	O
rendering	B-Method
steps	I-Method
.	O
	
In	O
all	O
these	O
cases	O
,	O
absence	O
of	O
training	O
data	O
was	O
cited	O
as	O
a	O
major	O
obstacle	O
for	O
training	O
effective	O
models	O
.	O
	
In	O
response	O
,	O
some	O
turned	O
to	O
larger	O
3D	O
object	O
data	O
sets	O
or	O
using	O
synthetically	O
generated	O
examples	O
.	O
	
We	O
propose	O
a	O
far	O
simpler	O
alternative	O
and	O
show	O
it	O
to	O
result	O
in	O
robust	B-Task
and	I-Task
accurate	I-Task
face	I-Task
alignment	I-Task
.	O
	
section	O
:	O
A	O
critique	O
of	O
facial	B-Task
landmark	I-Task
detection	I-Task
	
Before	O
using	O
an	O
existing	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
facial	B-Method
landmark	I-Method
detector	I-Method
in	O
a	O
face	B-Task
processing	I-Task
system	I-Task
,	O
the	O
following	O
points	O
should	O
be	O
considered	O
.	O
	
Landmark	O
detection	O
accuracy	B-Metric
measures	O
.	O
	
Facial	B-Task
landmark	I-Task
detection	I-Task
accuracy	I-Metric
is	O
typically	O
measured	O
by	O
considering	O
the	O
distances	O
between	O
estimated	O
landmarks	O
and	O
ground	O
truth	O
(	O
reference	O
)	O
landmarks	O
,	O
normalized	O
by	O
the	O
reference	O
inter	O
-	O
ocular	O
distance	O
of	O
the	O
face	O
:	O
Here	O
,	O
is	O
the	O
set	O
of	O
2D	O
facial	O
landmark	O
coordinates	O
,	O
their	O
ground	O
truth	O
locations	O
,	O
and	O
the	O
reference	O
left	O
and	O
right	O
eye	O
outer	O
corner	O
positions	O
.	O
	
These	O
errors	O
are	O
then	O
translated	O
to	O
a	O
number	O
of	O
standard	O
quantities	O
,	O
including	O
the	O
mean	B-Metric
error	I-Metric
rate	I-Metric
(	O
MER	B-Metric
)	O
,	O
the	O
percentage	B-Metric
of	I-Metric
landmarks	I-Metric
detected	O
under	O
certain	O
error	O
thresholds	O
(	O
e.g.	O
,	O
below	O
5	O
%	O
or	O
10	O
%	O
error	B-Metric
rates	I-Metric
)	O
or	O
the	O
area	O
under	O
the	O
accumulative	B-Metric
error	I-Metric
curve	I-Metric
(	O
AUC	B-Metric
)	O
.	O
	
There	O
are	O
two	O
key	O
problems	O
with	O
this	O
method	O
of	O
evaluating	B-Task
landmark	I-Task
errors	I-Task
.	O
	
First	O
,	O
the	O
ground	O
truth	O
compared	O
against	O
is	O
manually	O
specified	O
,	O
often	O
by	O
mechanical	O
turk	O
workers	O
.	O
	
These	O
manual	O
annotations	O
can	O
be	O
noisy	O
,	O
they	O
are	O
ill	O
-	O
defined	O
when	O
images	O
are	O
low	O
resolution	O
,	O
the	O
landmarks	O
are	O
occluded	O
(	O
in	O
case	O
of	O
large	O
out	O
-	O
of	O
-	O
plane	O
head	O
rotations	O
,	O
facial	O
hair	O
and	O
other	O
obstructions	O
)	O
,	O
or	O
located	O
in	O
featureless	O
facial	O
regions	O
(	O
e.g.	O
,	O
along	O
the	O
jawline	O
)	O
.	O
	
Accurate	O
facial	B-Task
landmark	I-Task
detection	I-Task
,	O
as	O
measured	O
on	O
these	O
benchmarks	O
,	O
thus	O
implies	O
better	O
matching	O
human	O
labels	O
but	O
not	O
necessarily	O
better	O
detection	B-Task
.	O
	
These	O
problems	O
are	O
demonstrated	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
A	O
second	O
potential	O
problem	O
lies	O
in	O
the	O
error	B-Metric
measure	I-Metric
itself	O
:	O
	
Normalizing	B-Metric
detection	I-Metric
errors	I-Metric
by	O
inter	O
-	O
ocular	O
distances	O
biases	O
against	O
images	O
of	O
faces	O
appearing	O
at	O
non	O
-	O
frontal	O
views	O
.	O
	
When	O
faces	O
are	O
near	O
profile	O
,	O
perspective	O
projection	O
of	O
the	O
3D	O
face	O
onto	O
the	O
image	O
plane	O
shrinks	O
the	O
distances	O
between	O
the	O
eyes	O
thereby	O
naturally	O
inflating	O
the	O
errors	O
computed	O
for	O
such	O
images	O
.	O
	
Landmark	B-Task
detection	I-Task
speed	I-Task
.	O
	
Some	O
facial	B-Method
landmark	I-Method
detection	I-Method
methods	I-Method
emphasize	O
impressive	O
speeds	O
.	O
	
Measured	O
on	O
standard	O
landmark	B-Task
detection	I-Task
benchmarks	I-Task
,	O
however	O
,	O
these	O
methods	O
do	O
not	O
necessarily	O
claim	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
accuracy	B-Metric
,	O
falling	O
behind	O
more	O
sophisticated	O
,	O
yet	O
far	O
slower	O
detectors	O
.	O
	
Moreover	O
,	O
aside	O
from	O
,	O
no	O
existing	O
landmark	B-Method
detector	I-Method
is	O
designed	O
to	O
take	O
advantage	O
of	O
GPU	O
hardware	O
,	O
a	O
standard	O
feature	O
in	O
commodity	B-Method
computer	I-Method
systems	I-Method
and	O
most	O
,	O
including	O
,	O
apply	O
iterative	B-Method
optimizations	I-Method
which	O
may	O
be	O
hard	O
to	O
convert	O
to	O
parallel	B-Task
processing	I-Task
.	O
	
Effects	O
of	O
facial	O
expression	O
and	O
shape	O
on	O
alignment	B-Task
.	O
	
It	O
was	O
recently	O
shown	O
that	O
3D	B-Task
alignment	I-Task
and	O
warping	B-Task
of	I-Task
faces	I-Task
to	O
frontal	O
viewpoints	O
(	O
i.e.	O
frontalization	O
)	O
is	O
effective	O
regardless	O
of	O
the	O
precise	O
3D	O
face	O
shape	O
used	O
for	O
this	O
purpose	O
.	O
	
Facial	O
expressions	O
and	O
3D	O
shapes	O
in	O
particular	O
,	O
appear	O
to	O
have	O
little	O
impact	O
on	O
the	O
warped	O
result	O
as	O
evident	O
by	O
the	O
improved	O
face	B-Metric
recognition	I-Metric
accuracy	I-Metric
reported	O
by	O
that	O
method	O
.	O
	
Moreover	O
,	O
it	O
was	O
recently	O
demonstrated	O
that	O
by	O
using	O
such	O
a	O
generic	O
3D	O
face	O
shape	O
,	O
rendering	O
faces	O
from	O
new	O
viewpoints	O
can	O
be	O
accelerated	O
to	O
the	O
same	O
speed	O
as	O
simple	O
2D	B-Method
image	I-Method
warping	I-Method
.	O
	
Interestingly	O
,	O
they	O
and	O
many	O
others	O
used	O
facial	B-Method
landmark	I-Method
detectors	I-Method
to	O
compute	O
parametric	O
transformations	O
–	O
projection	O
matrix	O
or	O
2D	O
affine	O
or	O
similarity	O
transforms	O
–	O
by	O
applying	O
robust	B-Method
estimators	I-Method
to	O
corresponding	O
detected	O
facial	O
landmarks	O
.	O
	
Variations	O
in	O
landmark	O
locations	O
due	O
to	O
expressions	O
and	O
face	O
shapes	O
essentially	O
contribute	O
noise	O
to	O
this	O
estimation	B-Method
process	I-Method
.	O
	
The	O
effects	O
these	O
variations	O
have	O
on	O
the	O
quality	O
of	O
the	O
alignment	B-Task
were	O
,	O
as	O
far	O
as	O
we	O
know	O
,	O
never	O
truly	O
studied	O
.	O
	
section	O
:	O
Deep	B-Task
,	I-Task
direct	I-Task
head	I-Task
pose	I-Task
regression	I-Task
	
Rather	O
than	O
align	O
faces	O
using	O
landmark	B-Task
detection	I-Task
,	O
we	O
refer	O
to	O
alignment	B-Task
as	O
a	O
global	B-Task
,	I-Task
6DoF	I-Task
3D	I-Task
face	I-Task
pose	I-Task
,	O
and	O
propose	O
to	O
infer	O
it	O
directly	O
from	O
image	O
intensities	O
,	O
using	O
a	O
simple	O
deep	B-Method
network	I-Method
architecture	I-Method
.	O
	
We	O
next	O
describe	O
the	O
network	O
and	O
the	O
novel	O
method	O
used	O
to	O
train	O
it	O
.	O
	
subsection	O
:	O
Head	B-Method
pose	I-Method
representation	I-Method
	
We	O
define	O
face	B-Task
alignment	I-Task
as	O
the	O
3D	O
head	O
pose	O
,	O
expressed	O
using	O
6DoF	O
:	O
three	O
for	O
rotations	O
,	O
,	O
and	O
three	O
for	O
translations	O
,	O
:	O
where	O
are	O
represented	O
as	O
Euler	O
angles	O
(	O
pitch	O
,	O
yaw	O
,	O
and	O
roll	O
)	O
.	O
	
Given	O
2D	O
facial	O
landmark	O
coordinates	O
on	O
an	O
input	O
image	O
,	O
,	O
and	O
their	O
corresponding	O
,	O
reference	O
3D	O
coordinates	O
,	O
–	O
selected	O
on	O
a	O
fixed	O
,	O
generic	O
3D	B-Method
face	I-Method
model	I-Method
–	O
we	O
can	O
obtain	O
a	O
3D	O
to	O
2D	O
projection	O
of	O
the	O
3D	O
landmarks	O
onto	O
the	O
2D	O
image	O
by	O
solving	O
the	O
following	O
equation	O
for	O
the	O
standard	O
pinhole	B-Method
model	I-Method
:	O
where	O
and	O
are	O
the	O
camera	O
matrix	O
and	O
rotation	O
matrix	O
respectively	O
and	O
is	O
a	O
constant	O
vector	O
of	O
1	O
.	O
	
We	O
then	O
extract	O
a	O
rotation	O
vector	O
from	O
using	O
the	O
Rodrigues	B-Method
rotation	I-Method
formula	I-Method
:	O
where	O
we	O
define	O
.	O
	
Obtaining	O
enough	O
training	O
examples	O
.	O
	
Although	O
our	O
network	B-Method
architecture	I-Method
is	O
not	O
very	O
deep	O
compared	O
to	O
deep	B-Method
networks	I-Method
used	O
today	O
for	O
other	O
tasks	O
,	O
training	O
it	O
still	O
requires	O
large	O
quantities	O
of	O
labeled	O
training	O
data	O
.	O
	
We	O
found	O
the	O
numbers	O
of	O
facial	O
landmark	O
annotated	O
faces	O
in	O
standard	O
data	O
sets	O
to	O
be	O
too	O
small	O
for	O
this	O
purpose	O
.	O
	
A	O
key	O
problem	O
is	O
therefore	O
obtaining	O
a	O
large	O
enough	O
training	O
set	O
.	O
	
We	O
produce	O
our	O
training	O
set	O
by	O
synthesizing	O
6D	O
,	O
ground	O
truth	O
pose	O
labels	O
by	O
running	O
an	O
existing	O
facial	B-Method
landmark	I-Method
detector	I-Method
on	O
a	O
large	O
image	O
set	O
:	O
the	O
2.6	O
million	O
images	O
in	O
the	O
VGG	O
face	O
dataset	O
.	O
	
The	O
detected	O
landmarks	O
were	O
then	O
used	O
to	O
compute	O
the	O
6DoF	O
labels	O
for	O
the	O
images	O
in	O
this	O
set	O
.	O
	
A	O
potential	O
danger	O
in	O
using	O
an	O
existing	O
method	O
to	O
produce	O
our	O
training	O
labels	O
,	O
is	O
that	O
our	O
CNN	B-Method
will	O
not	O
improve	O
beyond	O
the	O
accuracy	B-Metric
of	O
its	O
training	O
labels	O
.	O
	
As	O
we	O
show	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
	
,	O
this	O
is	O
not	O
necessarily	O
the	O
case	O
.	O
	
To	O
further	O
improve	O
the	O
robustness	B-Metric
of	O
our	O
CNN	B-Method
,	O
we	O
apply	O
a	O
number	O
of	O
face	B-Method
augmentation	I-Method
techniques	I-Method
to	O
the	O
images	O
in	O
the	O
VGG	O
face	O
set	O
,	O
substantially	O
enriching	O
the	O
appearance	O
variations	O
it	O
provides	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
illustrates	O
this	O
augmentation	B-Method
process	I-Method
.	O
	
Specifically	O
,	O
following	O
face	B-Task
detection	I-Task
and	O
landmark	B-Task
detection	I-Task
,	O
we	O
transform	O
detected	O
bounding	O
boxes	O
and	O
their	O
detected	O
facial	O
landmarks	O
using	O
a	O
number	O
of	O
simple	O
in	B-Method
-	I-Method
plane	I-Method
transformations	I-Method
.	O
	
The	O
parameters	O
for	O
these	O
transformations	O
are	O
selected	O
randomly	O
from	O
fixed	O
distributions	O
(	O
Table	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
The	O
transformed	O
faces	O
are	O
then	O
used	O
for	O
training	O
,	O
along	O
with	O
their	O
horizontally	O
mirrored	O
versions	O
,	O
to	O
provide	O
yaw	O
rotation	O
invariance	O
.	O
	
Ground	O
truth	O
labels	O
are	O
,	O
of	O
course	O
,	O
computed	O
using	O
the	O
transformed	O
landmarks	O
.	O
	
Some	O
example	O
augmented	O
faces	O
are	O
provided	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Note	O
that	O
augmented	O
images	O
would	O
often	O
be	O
too	O
challenging	O
for	O
existing	O
landmark	B-Method
detectors	I-Method
,	O
due	O
to	O
extreme	O
rotations	O
or	O
scaling	O
.	O
	
This	O
,	O
of	O
course	O
,	O
does	O
not	O
affect	O
the	O
accuracy	B-Metric
of	O
the	O
ground	O
truth	O
labels	O
which	O
were	O
obtained	O
from	O
the	O
original	O
images	O
.	O
	
It	O
does	O
,	O
however	O
,	O
force	O
our	O
CNN	B-Method
to	O
learn	O
to	O
estimate	O
poses	O
even	O
on	O
such	O
challenging	O
images	O
.	O
	
FPN	B-Method
training	O
.	O
	
For	O
our	O
FPN	B-Method
we	O
use	O
an	O
AlexNet	B-Method
architecture	I-Method
with	O
its	O
initialized	O
weights	O
provided	O
by	O
.	O
	
The	O
only	O
difference	O
is	O
that	O
here	O
the	O
output	O
regresses	O
6D	O
floating	O
point	O
values	O
rather	O
than	O
predicts	O
one	O
-	O
hot	O
encoded	O
,	O
multi	O
class	O
labels	O
.	O
	
Note	O
that	O
during	O
training	O
each	O
dimension	O
of	O
the	O
head	O
pose	O
labels	O
is	O
normalized	O
by	O
the	O
corresponding	O
mean	O
and	O
standard	O
deviation	O
of	O
the	O
training	O
set	O
,	O
compensating	O
for	O
the	O
large	O
value	O
differences	O
among	O
dimensions	O
.	O
	
The	O
same	O
normalization	O
parameters	O
are	O
used	O
at	O
test	O
time	O
.	O
	
2D	B-Task
and	O
3D	B-Task
face	I-Task
alignment	I-Task
with	O
FPN	B-Method
.	O
	
Given	O
a	O
test	O
image	O
,	O
it	O
is	O
processed	O
by	O
applying	O
the	O
same	O
face	B-Method
detector	I-Method
,	O
cropping	O
the	O
face	O
and	O
scaling	O
it	O
to	O
the	O
dimension	O
of	O
the	O
network	O
’s	O
input	O
layer	O
.	O
	
The	O
6D	O
network	O
output	O
is	O
then	O
converted	O
to	O
a	O
projection	O
matrix	O
.	O
	
Specifically	O
,	O
the	O
projection	O
matrix	O
is	O
produced	O
by	O
the	O
camera	O
matrix	O
,	O
rotation	O
matrix	O
,	O
and	O
the	O
translation	O
vector	O
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
	
With	O
this	O
projection	O
matrix	O
we	O
can	O
render	O
new	O
views	O
of	O
the	O
face	O
,	O
aligning	O
it	O
across	O
3D	O
views	O
as	O
was	O
recently	O
proposed	O
by	O
others	O
.	O
	
For	O
2D	B-Task
alignment	I-Task
,	O
we	O
compute	O
the	O
2D	B-Method
similarity	I-Method
transform	I-Method
to	O
warp	O
the	O
2D	O
projected	O
landmarks	O
to	O
pre	O
-	O
defined	O
landmark	O
locations	O
.	O
	
With	O
frontal	O
images	O
(	O
absolute	O
yaw	O
angle	O
)	O
,	O
we	O
use	O
the	O
eye	O
centers	O
,	O
the	O
nose	O
tip	O
,	O
and	O
the	O
mouth	O
corners	O
for	O
alignment	B-Task
.	O
	
With	O
profile	O
images	O
(	O
absolute	O
yaw	O
angle	O
)	O
,	O
however	O
,	O
only	O
the	O
visible	O
eye	O
center	O
and	O
the	O
nose	O
tip	O
are	O
used	O
.	O
	
section	O
:	O
Results	O
	
We	O
provide	O
comparisons	O
of	O
our	O
FPN	B-Method
with	O
the	O
following	O
widely	O
used	O
,	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
,	O
facial	B-Method
landmark	I-Method
detection	I-Method
methods	I-Method
:	O
Dlib	B-Method
,	O
CLNF	B-Method
,	O
OpenFace	B-Method
,	O
DCLM	B-Method
,	O
RCPR	B-Method
,	O
and	O
3DDFA	B-Method
evaluating	O
them	O
for	O
their	O
effects	O
on	O
face	B-Task
recognition	I-Task
vs.	O
their	O
landmark	O
detection	O
accuracy	B-Metric
.	O
	
subsection	O
:	O
Effect	O
of	O
alignment	B-Task
on	O
recognition	B-Task
	
Sec	O
.	O
	
[	O
reference	O
]	O
discusses	O
the	O
various	O
potential	O
problems	O
of	O
comparing	O
face	B-Method
alignment	I-Method
methods	I-Method
by	O
measuring	O
their	O
landmark	O
detection	O
accuracy	B-Metric
.	O
	
As	O
an	O
alternative	O
,	O
we	O
propose	O
comparing	O
methods	O
for	O
face	B-Task
alignment	I-Task
and	I-Task
landmark	I-Task
detection	I-Task
by	O
evaluating	O
their	O
effect	O
on	O
the	O
bottom	O
line	O
accuracy	B-Metric
of	O
a	O
face	B-Method
processing	I-Method
pipeline	I-Method
.	O
	
Since	O
face	B-Task
recognition	I-Task
is	O
arguably	O
one	O
of	O
the	O
most	O
popular	O
applications	O
for	O
face	B-Task
alignment	I-Task
,	O
we	O
use	O
recognition	O
accuracy	B-Metric
as	O
a	O
performance	B-Metric
measure	I-Metric
.	O
	
To	O
our	O
knowledge	O
,	O
this	O
is	O
the	O
first	O
time	O
alignment	B-Method
methods	I-Method
are	O
compared	O
based	O
on	O
their	O
effect	O
on	O
recognition	O
accuracy	B-Metric
.	O
	
Specifically	O
,	O
we	O
use	O
two	O
of	O
the	O
most	O
recent	O
benchmarks	O
for	O
face	B-Task
recognition	I-Task
:	O
IARPA	B-Material
Janus	I-Material
Benchmark	I-Material
A	I-Material
and	O
B	B-Material
(	O
IJB	B-Material
-	I-Material
A	I-Material
and	O
IJB	B-Material
-	I-Material
B	I-Material
)	O
.	O
	
Importantly	O
,	O
these	O
benchmarks	O
were	O
designed	O
with	O
the	O
specific	O
intention	O
of	O
elevating	O
the	O
difficulty	O
of	O
face	B-Task
recognition	I-Task
.	O
	
This	O
heightened	O
challenge	O
is	O
reflected	O
by	O
,	O
among	O
other	O
factors	O
,	O
an	O
unprecedented	O
amount	O
of	O
extreme	O
out	O
of	O
plane	O
rotated	O
faces	O
including	O
many	O
appearing	O
in	O
near	O
-	O
profile	O
views	O
.	O
	
As	O
a	O
consequence	O
,	O
these	O
two	O
benchmarks	O
not	O
only	O
push	O
the	O
limits	O
of	O
face	B-Method
recognition	I-Method
systems	I-Method
,	O
but	O
also	O
the	O
alignment	B-Method
methods	I-Method
used	O
by	O
these	O
systems	O
,	O
possibly	O
more	O
so	O
than	O
the	O
faces	O
in	O
standard	O
facial	B-Task
landmark	I-Task
detection	I-Task
benchmarks	I-Task
.	O
	
Face	B-Task
recognition	I-Task
pipeline	I-Task
.	O
	
We	O
employ	O
a	O
system	O
similar	O
to	O
the	O
one	O
recently	O
proposed	O
by	O
,	O
building	O
on	O
their	O
publicly	O
available	O
ResFace101	B-Method
model	I-Method
and	O
related	O
code	O
.	O
	
We	O
chose	O
this	O
system	O
,	O
as	O
it	O
explicitly	O
aligns	O
faces	O
to	O
multiple	O
viewpoints	O
,	O
including	O
rendering	O
novel	O
views	O
.	O
	
These	O
steps	O
are	O
highly	O
dependent	O
on	O
the	O
quality	O
of	O
alignment	B-Metric
and	O
so	O
its	O
recognition	O
accuracy	B-Metric
should	O
reflect	O
alignment	O
accuracy	B-Metric
.	O
	
In	O
practice	O
,	O
we	O
used	O
their	O
2D	O
(	O
similarity	B-Method
transform	I-Method
)	O
and	O
3D	B-Method
(	I-Method
new	I-Method
view	I-Method
rendering	I-Method
)	O
code	O
directly	O
,	O
changing	O
how	O
the	O
transformations	O
are	O
computed	O
:	O
our	O
tests	O
compare	O
different	O
landmark	B-Method
detectors	I-Method
used	O
to	O
recover	O
the	O
6DoF	O
head	O
pose	O
required	O
by	O
their	O
warping	B-Method
and	I-Method
rendering	I-Method
method	I-Method
,	O
with	O
the	O
6DoF	B-Method
regressed	I-Method
using	O
our	O
FPN	B-Method
.	O
	
Their	O
system	O
uses	O
a	O
single	O
Convolutional	O
Neural	O
Network	O
(	O
CNN	B-Method
)	O
,	O
a	O
ResNet	B-Method
-	I-Method
101	I-Method
architecture	I-Method
,	O
trained	O
on	O
both	O
real	O
face	O
images	O
and	O
synthetic	O
,	O
rendered	O
views	O
.	O
	
We	O
fine	O
tune	O
the	O
ResFace101	O
CNN	B-Method
using	O
-	O
constrained	O
	
Softmax	O
Loss	O
instead	O
of	O
the	O
original	O
softmax	B-Method
used	O
by	O
Masi	O
et	O
al	O
.	O
for	O
their	O
publicly	O
released	O
model	O
.	O
	
This	O
fine	B-Task
tuning	I-Task
is	O
performed	O
using	O
the	O
MS	O
-	O
Celeb	O
face	O
set	O
as	O
an	O
example	O
set	O
.	O
	
Aside	O
from	O
this	O
change	O
,	O
we	O
use	O
the	O
same	O
recognition	B-Method
pipeline	I-Method
from	O
and	O
we	O
refer	O
to	O
that	O
paper	O
for	O
details	O
.	O
	
Bounding	B-Task
box	I-Task
detection	I-Task
.	O
	
We	O
emphasize	O
that	O
an	O
identical	O
pipeline	O
was	O
used	O
with	O
the	O
different	O
alignment	B-Method
methods	I-Method
;	O
different	O
results	O
vary	O
only	O
in	O
the	O
method	O
used	O
to	O
estimate	O
facial	O
pose	O
.	O
	
The	O
only	O
other	O
difference	O
between	O
recognition	B-Method
pipelines	I-Method
was	O
in	O
the	O
facial	B-Method
bounding	I-Method
box	I-Method
detector	I-Method
.	O
	
Facial	B-Method
landmark	I-Method
detectors	I-Method
are	O
sensitive	O
to	O
the	O
face	B-Method
detector	I-Method
they	O
are	O
used	O
with	O
.	O
	
We	O
therefore	O
report	O
results	O
obtained	O
when	O
running	O
landmark	B-Method
detectors	I-Method
with	O
the	O
best	O
bounding	O
boxes	O
we	O
were	O
able	O
to	O
determine	O
.	O
	
Specifically	O
,	O
FPN	B-Method
was	O
applied	O
to	O
the	O
bounding	O
boxes	O
returned	O
by	O
the	O
detector	B-Method
of	O
Yang	O
and	O
Nevatia	O
,	O
following	O
expansion	O
of	O
its	O
dimensions	O
by	O
25	O
%	O
.	O
	
Most	O
detectors	O
performed	O
best	O
when	O
applied	O
using	O
the	O
same	O
face	B-Method
detector	I-Method
,	O
without	O
the	O
25	O
%	O
increase	O
.	O
	
Finally	O
,	O
3DDFA	B-Method
was	O
tested	O
with	O
the	O
same	O
face	B-Method
detector	I-Method
followed	O
by	O
the	O
face	B-Method
box	I-Method
expansion	I-Method
code	I-Method
provided	O
by	O
its	O
authors	O
.	O
	
[	O
Quantitative	O
results	O
]	O
	
Method≤	O
5%≤	O
10%≤	O
20%≥	O
	
40%MERSec.	O
/	O
im	O
.	O
	
RCPR	B-Method
[	O
]	O
44.44	O
%	O
66.96	O
%	O
77.39	O
%	O
9.55	O
%	O
0.13860.19Dlib	O
	
[	O
]	O
60.03	O
%	O
82.65	O
%	O
90.94	O
%	O
2.83	O
%	O
0.07950.009CLNF	O
	
[	O
]	O
20.86	O
%	O
65.11	O
%	O
87.62	O
%	O
2.63	O
%	O
0.11060.38OpenFace	O
	
[	O
]	O
54.39	O
%	O
86.74	O
%	O
95.42	O
%	O
1.27	O
%	O
0.07020.31DCLM	O
[	O
]	O
64.91	O
%	O
91.91	O
%	O
96.00	O
%	O
1.17	O
%	O
0.061115.833DDFA	O
	
[	O
]	O
N	O
	
/	O
AN	O
/	O
AN	O
/	O
AN	O
/	O
AN	O
/	O
A0.6Our	O
FPN1.75	O
%	O
65.40	O
%	O
93.86	O
%	O
0.97	O
%	O
0.10430.005	O
	
[	O
Acumulative	B-Metric
error	I-Metric
curves	I-Metric
]	O
Face	B-Task
verification	I-Task
and	O
identification	B-Task
results	O
.	O
	
Face	B-Task
verification	I-Task
and	O
identification	B-Task
results	O
on	O
both	O
IJB	B-Material
-	I-Material
A	I-Material
and	O
IJB	B-Material
-	I-Material
B	I-Material
are	O
provided	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
We	O
report	O
multiple	O
recognition	B-Metric
metrics	I-Metric
for	O
both	O
verification	B-Task
and	O
identification	B-Task
:	O
For	O
verification	B-Task
,	O
these	O
measure	O
the	O
recall	B-Metric
(	O
True	B-Metric
Acceptance	I-Metric
Rate	I-Metric
)	O
at	O
three	O
cut	O
-	O
off	O
points	O
of	O
the	O
False	B-Metric
Alarm	I-Metric
Rate	I-Metric
(	O
TAR	B-Metric
-	I-Metric
{1%	I-Metric
,	I-Metric
0.1%	I-Metric
,	I-Metric
0.01	I-Metric
%	O
}	O
)	O
.	O
	
For	O
identification	B-Task
we	O
provide	O
recognition	B-Metric
rates	I-Metric
at	O
four	O
ranks	O
from	O
the	O
CMC	B-Method
(	O
Cumulative	B-Metric
Matching	I-Metric
Characteristic	I-Metric
)	O
.	O
	
The	O
overall	O
performances	O
in	O
terms	O
of	O
ROC	B-Metric
and	O
CMC	B-Metric
curves	O
are	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
The	O
table	O
also	O
provides	O
,	O
as	O
reference	O
,	O
three	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
IJB	B-Material
-	I-Material
A	I-Material
results	O
and	O
baseline	O
results	O
from	O
for	O
IJB	B-Material
-	I-Material
B	I-Material
(	O
to	O
our	O
knowledge	O
,	O
we	O
are	O
the	O
first	O
to	O
report	O
verification	B-Task
and	O
identification	B-Metric
accuracies	I-Metric
on	O
IJB	B-Material
-	I-Material
B	I-Material
)	O
.	O
	
Faces	O
aligned	O
with	O
our	O
FPN	B-Method
offer	O
higher	O
recognition	B-Metric
rates	I-Metric
,	O
even	O
compared	O
to	O
the	O
most	O
recent	O
,	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
facial	B-Method
landmark	I-Method
detection	I-Method
method	I-Method
of	O
.	O
	
In	O
addition	O
,	O
our	O
verification	B-Metric
scores	I-Metric
on	O
IJB	B-Material
-	I-Material
A	I-Material
outperform	O
the	O
scores	O
reported	O
for	O
the	O
system	O
used	O
here	O
as	O
the	O
basis	O
for	O
our	O
recognition	B-Method
system	I-Method
.	O
	
These	O
superior	O
results	O
are	O
likely	O
due	O
to	O
the	O
better	O
alignment	O
of	O
the	O
faces	O
provided	O
by	O
our	O
FPN	B-Method
.	O
	
subsection	O
:	O
Landmark	O
detection	O
accuracy	B-Metric
	
From	O
6DoF	O
pose	O
to	O
facial	O
landmarks	O
.	O
	
Given	O
a	O
6DoF	B-Task
head	I-Task
pose	I-Task
estimate	I-Task
,	O
facial	O
landmarks	O
can	O
then	O
be	O
estimated	O
and	O
compared	O
with	O
existing	O
landmark	B-Method
detection	I-Method
methods	I-Method
for	O
their	O
accuracy	B-Metric
on	O
standard	O
benchmarks	O
.	O
	
To	O
obtain	O
landmark	B-Task
predictions	I-Task
,	O
3D	O
reference	O
coordinates	O
of	O
facial	O
landmarks	O
are	O
selected	O
off	O
line	O
once	O
on	O
the	O
same	O
generic	O
,	O
	
3D	B-Method
face	I-Method
model	I-Method
used	O
in	O
.	O
	
Given	O
a	O
pose	B-Task
estimate	I-Task
,	O
we	O
convert	O
it	O
to	O
a	O
projection	O
matrix	O
and	O
project	O
these	O
3D	O
landmarks	O
down	O
to	O
the	O
input	O
image	O
.	O
	
Recently	O
,	O
a	O
similar	O
process	O
was	O
proposed	O
for	O
accurate	B-Task
landmark	I-Task
detection	I-Task
across	O
large	O
poses	O
.	O
	
In	O
their	O
work	O
,	O
an	O
iterative	B-Method
method	I-Method
was	O
used	O
to	O
simultaneously	O
estimate	O
a	O
3D	O
face	O
shape	O
,	O
including	O
facial	O
expression	O
,	O
and	O
project	O
its	O
landmarks	O
down	O
to	O
the	O
input	O
image	O
.	O
	
Unlike	O
them	O
,	O
our	O
tests	O
use	O
a	O
single	O
generic	B-Method
3D	I-Method
face	I-Method
model	I-Method
,	O
unmodified	O
.	O
	
By	O
not	O
iterating	O
over	O
the	O
face	O
shape	O
,	O
our	O
method	O
is	O
simpler	O
and	O
faster	O
,	O
but	O
of	O
course	O
,	O
our	O
predicted	O
landmarks	O
will	O
not	O
reflect	O
different	O
3D	O
shapes	O
and	O
facial	O
expressions	O
.	O
	
We	O
next	O
evaluate	O
the	O
effect	O
this	O
has	O
on	O
landmark	O
detection	O
accuracy	B-Metric
.	O
	
Detection	O
accuracy	B-Metric
on	O
the	O
300W	B-Material
benchmark	I-Material
.	O
	
We	O
evaluate	O
performance	O
on	O
the	O
300W	B-Material
data	I-Material
set	I-Material
,	O
the	O
most	O
challenging	O
benchmark	O
of	O
its	O
kind	O
,	O
using	O
68	O
landmarks	O
.	O
	
We	O
note	O
that	O
we	O
did	O
not	O
use	O
the	O
standard	O
training	O
sets	O
used	O
with	O
the	O
300W	B-Material
benchmark	I-Material
(	O
e.g.	O
,	O
the	O
HELEN	O
and	O
LFPW	O
training	O
sets	O
with	O
their	O
manual	O
annotations	O
)	O
.	O
	
Instead	O
we	O
trained	O
FPN	B-Method
with	O
the	O
estimated	O
landmarks	O
,	O
as	O
explained	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
.	O
	
As	O
a	O
test	O
set	O
,	O
we	O
used	O
the	O
standard	O
union	B-Method
consisting	O
of	O
the	O
LFPW	O
test	O
set	O
(	O
224	O
images	O
)	O
,	O
the	O
HELEN	O
test	O
set	O
(	O
330	O
)	O
,	O
AFW	O
(	O
337	O
)	O
,	O
and	O
IBUG	O
(	O
135	O
)	O
.	O
	
These	O
1026	O
images	O
,	O
collectively	O
,	O
form	O
the	O
300W	B-Material
test	I-Material
set	I-Material
.	O
	
Note	O
that	O
unlike	O
others	O
,	O
we	O
did	O
not	O
use	O
AFW	B-Method
to	O
train	O
our	O
method	O
,	O
allowing	O
us	O
to	O
use	O
it	O
for	O
testing	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
a	O
)	O
reports	O
five	O
measures	O
of	O
accuracy	B-Metric
for	O
the	O
various	O
methods	O
tested	O
:	O
	
The	O
percent	O
of	O
images	O
with	O
68	O
landmark	B-Metric
detection	I-Metric
errors	I-Metric
lower	O
than	O
5	O
%	O
,	O
10	O
%	O
,	O
and	O
20	O
%	O
inter	B-Metric
-	I-Metric
ocular	I-Metric
distances	I-Metric
,	O
and	O
the	O
mean	B-Metric
error	I-Metric
rate	I-Metric
(	O
MER	B-Metric
)	O
,	O
averaging	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
over	O
the	O
images	O
tested	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
	
(	O
b	O
)	O
additionally	O
provides	O
accumulative	B-Metric
error	I-Metric
curves	I-Metric
for	O
these	O
methods	O
.	O
	
Not	O
surprisingly	O
,	O
without	O
accounting	O
for	O
face	O
shapes	O
and	O
expressions	O
,	O
our	O
predicted	O
landmarks	O
are	O
not	O
as	O
accurate	O
as	O
those	O
predicted	O
by	O
methods	O
which	O
are	O
influenced	O
by	O
these	O
factors	O
.	O
	
Some	O
qualitative	O
detection	O
examples	O
are	O
provided	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
including	O
a	O
few	O
errors	O
larger	O
than	O
.	O
	
These	O
show	O
that	O
mistakes	O
can	O
often	O
be	O
attributed	O
to	O
FPN	B-Method
not	O
modeling	O
facial	O
expressions	O
and	O
shape	O
.	O
	
One	O
way	O
to	O
improve	O
this	O
would	O
be	O
to	O
use	O
a	O
single	B-Method
-	I-Method
view	I-Method
3D	I-Method
face	I-Method
shape	I-Method
estimation	I-Method
method	I-Method
to	O
better	O
approximate	O
landmark	O
positions	O
,	O
though	O
we	O
have	O
not	O
tested	O
this	O
here	O
.	O
	
Detection	B-Task
runtime	I-Task
.	O
	
In	O
one	O
tested	O
measure	O
FPN	B-Method
far	O
outperforms	O
its	O
alternatives	O
:	O
	
The	O
last	O
column	O
of	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
a	O
)	O
reports	O
the	O
mean	O
,	O
per	B-Metric
-	I-Metric
image	I-Metric
runtime	I-Metric
for	O
landmark	B-Task
detection	I-Task
.	O
	
Our	O
FPN	B-Method
is	O
an	O
order	O
of	O
magnitude	O
faster	O
than	O
nearly	O
all	O
other	O
face	B-Method
alignment	I-Method
methods	I-Method
.	O
	
Dlib	B-Method
was	O
slightly	O
slower	O
than	O
our	O
FPN	B-Method
,	O
but	O
is	O
far	O
less	O
accurate	O
in	O
the	O
face	B-Task
recognition	I-Task
tests	O
(	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
All	O
methods	O
were	O
tested	O
using	O
an	O
NVIDIA	O
,	O
GeForce	O
GTX	O
TITAN	O
X	O
,	O
12	O
GB	O
RAM	O
,	O
and	O
an	O
Intel	O
(	O
R	O
)	O
	
Xeon	O
(	O
R	O
)	O
	
CPU	O
E5	O
-	O
2640	O
v3	O
@	O
2.60GHz	O
,	O
132	O
GB	O
RAM	O
.	O
	
The	O
only	O
exception	O
was	O
3DDFA	O
,	O
which	O
required	O
a	O
Windows	O
system	O
and	O
was	O
tested	O
using	O
an	O
Intel	O
(	O
R	O
)	O
	
Core	B-Method
(	I-Method
TM	I-Method
)	O
	
i7	O
-	O
4820	O
	
K	O
CPU	O
@	O
3.70GHz	O
(	O
8	O
CPUs	O
)	O
	
,	O
16	O
GB	O
RAM	O
,	O
running	O
8	O
Pro	O
64	O
-	O
bit	O
.	O
	
subsection	O
:	O
Discussion	O
	
Landmarks	O
predicted	O
using	O
FPN	B-Method
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
were	O
less	O
accurate	O
than	O
those	O
estimated	O
by	O
other	O
methods	O
.	O
	
How	O
does	O
that	O
agree	O
with	O
the	O
better	O
face	B-Task
recognition	I-Task
results	O
obtained	O
with	O
images	O
aligned	O
using	O
FPN	B-Method
?	O
	
As	O
we	O
mentioned	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
better	O
accuracy	B-Metric
on	O
a	O
face	B-Task
landmark	I-Task
detection	I-Task
benchmark	I-Task
reflects	O
many	O
things	O
which	O
are	O
not	O
necessarily	O
important	O
when	O
aligning	O
faces	O
for	O
recognition	B-Task
.	O
	
These	O
include	O
,	O
in	O
particular	O
face	O
shapes	O
and	O
expressions	O
,	O
the	O
latter	O
can	O
actually	O
cause	O
misalignments	O
when	O
computing	O
face	O
pose	O
and	O
warping	O
the	O
face	O
accordingly	O
.	O
	
FPN	B-Method
,	O
on	O
the	O
other	O
hand	O
,	O
ignores	O
these	O
factors	O
,	O
instead	O
providing	O
a	O
6DoF	B-Task
pose	I-Task
estimates	I-Task
at	O
breakneck	O
speeds	O
,	O
directly	O
from	O
image	O
intensities	O
.	O
	
An	O
important	O
observation	O
is	O
that	O
despite	O
being	O
trained	O
with	O
labels	O
generated	O
by	O
OpenFace	O
,	O
recognition	B-Task
results	O
on	O
faces	O
aligned	O
with	O
FPN	B-Method
are	O
better	O
than	O
those	O
aligned	O
with	O
OpenFace	O
.	O
	
This	O
can	O
be	O
explained	O
in	O
a	O
number	O
of	O
ways	O
:	O
First	O
,	O
FPN	B-Method
was	O
trained	O
on	O
appearance	O
variations	O
introduced	O
by	O
augmentation	B-Method
,	O
which	O
OpenFace	O
was	O
not	O
necessarily	O
designed	O
to	O
handle	O
.	O
	
Second	O
,	O
poses	O
estimated	O
by	O
FPN	B-Method
were	O
less	O
corrupted	O
by	O
expressions	O
and	O
facial	O
shapes	O
,	O
making	O
the	O
warped	O
images	O
better	O
aligned	O
.	O
	
Third	O
,	O
as	O
was	O
recently	O
argued	O
by	O
others	O
,	O
CNNs	B-Method
are	O
remarkably	O
adapt	O
at	O
training	O
with	O
label	O
noise	O
such	O
as	O
any	O
errors	O
in	O
the	O
poses	O
predicted	O
by	O
OpenFace	O
for	O
the	O
ground	O
truth	O
labels	O
.	O
	
Finally	O
,	O
CNNs	B-Method
are	O
highly	O
capable	O
of	O
domain	B-Task
shifts	I-Task
to	O
new	O
data	O
,	O
such	O
as	O
the	O
extremely	O
challenging	O
views	O
of	O
the	O
faces	O
in	O
IJB	B-Material
-	I-Material
A	I-Material
and	O
IJB	B-Material
-	I-Material
B.	I-Material
	
section	O
:	O
Conclusions	O
	
For	O
many	O
practical	O
purposes	O
,	O
face	B-Task
alignment	I-Task
requires	O
only	O
global	B-Task
,	I-Task
parametric	I-Task
2D	I-Task
or	I-Task
3D	I-Task
transformations	I-Task
.	O
	
This	O
is	O
often	O
the	O
case	O
in	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
face	B-Method
recognition	I-Method
pipelines	I-Method
and	O
a	O
wide	O
variety	O
of	O
other	O
face	B-Task
understanding	I-Task
tasks	I-Task
.	O
	
In	O
such	O
circumstances	O
,	O
accurate	O
facial	B-Task
landmark	I-Task
detection	I-Task
is	O
superfluous	O
and	O
its	O
potential	O
for	O
introducing	O
errors	O
whenever	O
facial	O
expressions	O
and	O
shapes	O
are	O
not	O
explicitly	O
considered	O
was	O
never	O
fully	O
explored	O
.	O
	
In	O
this	O
paper	O
we	O
present	O
an	O
alternative	O
method	O
for	O
aligning	B-Task
faces	I-Task
:	O
using	O
a	O
simple	O
CNN	B-Method
,	O
uniquely	O
trained	O
to	O
regress	O
6DoF	O
face	O
pose	O
,	O
directly	O
from	O
image	O
intensities	O
.	O
	
We	O
show	O
that	O
by	O
using	O
a	O
GPU	B-Method
,	O
this	O
leads	O
to	O
staggering	O
alignment	B-Metric
speeds	I-Metric
.	O
	
Moreover	O
,	O
by	O
comparing	O
alignment	B-Method
methods	I-Method
by	O
considering	O
bottom	B-Metric
line	I-Metric
performance	I-Metric
of	O
a	O
face	B-Method
recognition	I-Method
system	I-Method
,	O
rather	O
than	O
landmark	O
detection	O
accuracy	B-Metric
,	O
we	O
show	O
that	O
this	O
simple	O
method	O
outperforms	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
alignment	B-Method
techniques	I-Method
in	O
the	O
face	B-Metric
recognition	I-Metric
accuracy	I-Metric
it	O
provides	O
.	O
	
section	O
:	O
Acknowledgments	O
	
This	O
research	O
is	O
based	O
upon	O
work	O
supported	O
in	O
part	O
by	O
the	O
Office	O
of	O
the	O
Director	O
of	O
National	O
Intelligence	O
(	O
ODNI	O
)	O
,	O
Intelligence	O
Advanced	O
Research	O
Projects	O
Activity	O
(	O
IARPA	O
)	O
,	O
via	O
IARPA	O
2014	O
-	O
14071600011	O
.	O
	
The	O
views	O
and	O
conclusions	O
contained	O
herein	O
are	O
those	O
of	O
the	O
authors	O
and	O
should	O
not	O
be	O
interpreted	O
as	O
necessarily	O
representing	O
the	O
official	O
policies	O
or	O
endorsements	O
,	O
either	O
expressed	O
or	O
implied	O
,	O
of	O
ODNI	O
,	O
IARPA	O
,	O
or	O
the	O
U.S.	O
Government	O
.	O
	
The	O
U.S.	O
Government	O
is	O
authorized	O
to	O
reproduce	O
and	O
distribute	O
reprints	O
for	O
Governmental	O
purpose	O
notwithstanding	O
any	O
copyright	O
annotation	O
thereon	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Meta	B-Method
-	I-Method
Transfer	I-Method
Learning	I-Method
for	O
Few	B-Task
-	I-Task
Shot	I-Task
Learning	I-Task
	
Meta	B-Method
-	I-Method
learning	I-Method
has	O
been	O
proposed	O
as	O
a	O
framework	O
to	O
address	O
the	O
challenging	O
few	O
-	B-Material
shot	I-Material
learning	O
setting	O
.	O
	
The	O
key	O
idea	O
is	O
to	O
leverage	O
a	O
large	O
number	O
of	O
similar	O
few	O
-	B-Material
shot	I-Material
tasks	O
in	O
order	O
to	O
learn	O
how	O
to	O
adapt	O
a	O
base	B-Method
-	I-Method
learner	I-Method
to	O
a	O
new	O
task	O
for	O
which	O
only	O
a	O
few	O
labeled	O
samples	O
are	O
available	O
.	O
	
As	O
deep	B-Method
neural	I-Method
networks	I-Method
(	O
DNNs	B-Method
)	O
tend	O
to	O
overfit	O
using	O
a	O
few	O
samples	O
only	O
,	O
meta	B-Method
-	I-Method
learning	I-Method
typically	O
uses	O
shallow	B-Method
neural	I-Method
networks	I-Method
(	O
SNNs	B-Method
)	O
,	O
thus	O
limiting	O
its	O
effectiveness	O
.	O
	
In	O
this	O
paper	O
we	O
propose	O
a	O
novel	O
few	O
-	B-Material
shot	I-Material
learning	O
method	O
called	O
meta	B-Method
-	I-Method
transfer	I-Method
learning	I-Method
(	O
MTL	B-Method
)	O
which	O
learns	O
to	O
adapt	O
a	O
deep	B-Method
NN	I-Method
for	O
few	B-Task
shot	I-Task
learning	I-Task
tasks	I-Task
.	O
	
Specifically	O
,	O
meta	B-Method
refers	O
to	O
training	O
multiple	O
tasks	O
,	O
and	O
transfer	B-Task
is	O
achieved	O
by	O
learning	O
scaling	B-Method
and	I-Method
shifting	I-Method
functions	I-Method
of	I-Method
DNN	I-Method
weights	I-Method
for	O
each	O
task	O
.	O
	
In	O
addition	O
,	O
we	O
introduce	O
the	O
hard	B-Method
task	I-Method
(	O
HT	B-Method
)	O
meta	B-Method
-	I-Method
batch	I-Method
scheme	I-Method
as	O
an	O
effective	O
learning	B-Method
curriculum	I-Method
for	O
MTL	B-Method
.	O
	
We	O
conduct	O
experiments	O
using	O
(	O
5	B-Task
-	I-Task
class	I-Task
,	O
1	O
-	B-Material
shot	I-Material
)	O
and	O
(	O
5	B-Task
-	I-Task
class	I-Task
,	O
5	O
-	B-Material
shot	I-Material
)	O
recognition	O
tasks	O
on	O
two	O
challenging	O
few	O
-	B-Material
shot	I-Material
learning	O
benchmarks	O
:	O
miniImageNet	B-Material
and	O
Fewshot	O
-	O
CIFAR100	O
.	O
	
Extensive	O
comparisons	O
to	O
related	O
works	O
validate	O
that	O
our	O
meta	B-Method
-	I-Method
transfer	I-Method
learning	I-Method
approach	O
trained	O
with	O
the	O
proposed	O
HT	B-Method
meta	I-Method
-	I-Method
batch	I-Method
scheme	I-Method
achieves	O
top	O
performance	O
.	O
	
An	O
ablation	O
study	O
also	O
shows	O
that	O
both	O
components	O
contribute	O
to	O
fast	O
convergence	B-Metric
and	O
high	O
accuracy	B-Metric
.	O
	
section	O
:	O
Introduction	O
	
While	O
deep	B-Method
learning	I-Method
systems	I-Method
have	O
achieved	O
great	O
performance	O
when	O
sufficient	O
amounts	O
of	O
labeled	O
data	O
are	O
available	O
,	O
there	O
has	O
been	O
growing	O
interest	O
in	O
reducing	O
the	O
required	O
amount	O
of	O
data	O
.	O
	
Few	O
-	B-Material
shot	I-Material
learning	O
tasks	O
have	O
been	O
defined	O
for	O
this	O
purpose	O
.	O
	
The	O
aim	O
is	O
to	O
learn	O
new	O
concepts	O
from	O
few	O
labeled	O
examples	O
,	O
e.g.	O
1	O
-	B-Material
shot	I-Material
learning	O
.	O
	
While	O
humans	O
tend	O
to	O
be	O
highly	O
effective	O
in	O
this	O
context	O
,	O
often	O
grasping	O
the	O
essential	O
connection	O
between	O
new	O
concepts	O
and	O
their	O
own	O
knowledge	O
and	O
experience	O
,	O
it	O
remains	O
challenging	O
for	O
machine	B-Method
learning	I-Method
approaches	I-Method
.	O
	
E.g.	O
,	O
on	O
the	O
CIFAR	O
-	O
100	O
dataset	O
,	O
a	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
method	O
achieves	O
only	O
accuracy	B-Metric
for	O
1	O
-	B-Material
shot	I-Material
learning	O
,	O
compared	O
to	O
for	O
the	O
all	B-Task
-	I-Task
class	I-Task
fully	I-Task
supervised	I-Task
case	I-Task
.	O
	
Few	O
-	B-Material
shot	I-Material
learning	O
methods	O
can	O
be	O
roughly	O
categorized	O
into	O
two	O
classes	O
:	O
data	B-Task
augmentation	I-Task
and	O
task	B-Method
-	I-Method
based	I-Method
meta	I-Method
-	I-Method
learning	I-Method
.	O
	
Data	B-Task
augmentation	I-Task
is	O
a	O
classic	O
technique	O
to	O
increase	O
the	O
amount	O
of	O
available	O
data	O
and	O
thus	O
also	O
useful	O
for	O
few	O
-	B-Material
shot	I-Material
learning	O
.	O
	
Several	O
methods	O
propose	O
to	O
learn	O
a	O
data	B-Method
generator	I-Method
e.g.	O
conditioned	O
on	O
Gaussian	O
noise	O
.	O
	
However	O
,	O
the	O
generation	B-Method
models	I-Method
often	O
underperform	O
when	O
trained	O
on	O
few	O
-	B-Material
shot	I-Material
data	O
.	O
	
An	O
alternative	O
is	O
to	O
merge	O
data	O
from	O
multiple	O
tasks	O
which	O
,	O
however	O
,	O
is	O
not	O
effective	O
due	O
to	O
variances	O
of	O
the	O
data	O
across	O
tasks	O
.	O
	
In	O
contrast	O
to	O
data	B-Method
-	I-Method
augmentation	I-Method
methods	I-Method
,	O
meta	B-Method
-	I-Method
learning	I-Method
is	O
a	O
task	B-Method
-	I-Method
level	I-Method
learning	I-Method
method	I-Method
.	O
	
Meta	B-Method
-	I-Method
learning	I-Method
aims	O
to	O
accumulate	O
experience	O
from	O
learning	O
multiple	O
tasks	O
,	O
while	O
base	B-Task
-	I-Task
learning	I-Task
focuses	O
on	O
modeling	O
the	O
data	B-Task
distribution	I-Task
of	O
a	O
single	O
task	O
.	O
	
A	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
representative	O
of	O
this	O
,	O
namely	O
Model	B-Method
-	I-Method
Agnostic	I-Method
Meta	I-Method
-	I-Method
Learning	I-Method
(	O
MAML	B-Method
)	I-Method
,	O
learns	O
to	O
search	O
for	O
the	O
optimal	O
initialization	O
state	O
to	O
fast	O
adapt	O
a	O
base	B-Method
-	I-Method
learner	I-Method
to	O
a	O
new	O
task	O
.	O
	
Its	O
task	O
-	O
agnostic	O
property	O
makes	O
it	O
possible	O
to	O
generalize	O
to	O
few	O
-	B-Material
shot	I-Material
supervised	O
learning	O
as	O
well	O
as	O
unsupervised	B-Method
reinforcement	I-Method
learning	I-Method
.	O
	
However	O
,	O
in	O
our	O
view	O
,	O
there	O
are	O
two	O
main	O
limitations	O
of	O
this	O
type	O
of	O
approaches	O
limiting	O
their	O
effectiveness	O
:	O
	
i	O
)	O
	
these	O
methods	O
usually	O
require	O
a	O
large	O
number	O
of	O
similar	O
tasks	O
for	O
meta	B-Method
-	I-Method
training	I-Method
which	O
is	O
costly	O
;	O
and	O
ii	O
)	O
each	O
task	O
is	O
typically	O
modeled	O
by	O
a	O
low	B-Method
-	I-Method
complexity	I-Method
base	I-Method
learner	I-Method
(	O
such	O
as	O
a	O
shallow	B-Method
neural	I-Method
network	I-Method
)	O
to	O
avoid	O
model	B-Task
overfitting	I-Task
,	O
thus	O
being	O
unable	O
to	O
use	O
deeper	O
and	O
more	O
powerful	O
architectures	O
.	O
	
For	O
example	O
,	O
for	O
the	O
miniImageNet	B-Material
dataset	I-Material
,	O
MAML	B-Method
uses	O
a	O
shallow	B-Method
CNN	I-Method
with	O
only	O
CONV	B-Method
layers	I-Method
and	O
its	O
optimal	O
performance	O
was	O
obtained	O
learning	O
on	O
tasks	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
novel	O
meta	B-Method
-	I-Method
learning	I-Method
method	I-Method
called	O
meta	B-Method
-	I-Method
transfer	I-Method
learning	I-Method
(	O
MTL	B-Method
)	O
leveraging	O
the	O
advantages	O
of	O
both	O
transfer	B-Method
and	O
meta	B-Method
learning	I-Method
(	O
see	O
conceptual	O
comparison	O
of	O
related	O
methods	O
in	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
In	O
a	O
nutshell	O
,	O
MTL	B-Method
is	O
a	O
novel	O
learning	B-Method
method	I-Method
that	O
helps	O
deep	B-Method
neural	I-Method
nets	I-Method
converge	O
faster	O
while	O
reducing	O
the	O
probability	O
to	O
overfit	O
when	O
using	O
few	O
labeled	O
training	O
data	O
only	O
.	O
	
In	O
particular	O
,	O
“	O
transfer	O
”	O
means	O
that	O
DNN	B-Method
weights	I-Method
trained	O
on	O
large	O
-	O
scale	O
data	O
can	O
be	O
used	O
in	O
other	O
tasks	O
by	O
two	O
light	B-Method
-	I-Method
weight	I-Method
neuron	I-Method
operations	I-Method
:	O
Scaling	O
and	O
Shifting	O
(	O
SS	B-Task
)	O
,	O
i.e.	O
.	O
	
“	O
	
Meta	O
”	O
means	O
that	O
the	O
parameters	O
of	O
these	O
operations	O
can	O
be	O
viewed	O
as	O
hyper	B-Method
-	I-Method
parameters	I-Method
trained	O
on	O
few	O
-	B-Material
shot	I-Material
learning	O
tasks	O
.	O
	
Large	O
-	O
scale	O
trained	O
DNN	B-Method
weights	I-Method
offer	O
a	O
good	O
initialization	O
,	O
enabling	O
fast	O
convergence	B-Metric
of	O
meta	B-Method
-	I-Method
transfer	I-Method
learning	I-Method
with	O
fewer	O
tasks	O
,	O
e.g.	O
only	O
tasks	O
for	O
miniImageNet	B-Material
,	O
times	O
fewer	O
than	O
MAML	B-Method
.	O
	
Light	B-Method
-	I-Method
weight	I-Method
operations	I-Method
on	O
DNN	O
neurons	O
have	O
less	O
parameters	O
to	O
learn	O
,	O
e.g.	O
less	O
than	O
if	O
considering	O
neurons	O
of	O
size	O
(	O
for	O
and	O
for	O
)	O
,	O
reducing	O
the	O
chance	O
of	O
overfitting	O
.	O
	
In	O
addition	O
,	O
these	O
operations	O
keep	O
those	O
trained	O
DNN	O
weights	O
unchanged	O
,	O
and	O
thus	O
avoid	O
the	O
problem	O
of	O
“	O
catastrophic	O
forgetting	O
”	O
which	O
means	O
forgetting	O
general	O
patterns	O
when	O
adapting	O
to	O
a	O
specific	O
task	O
.	O
	
The	O
second	O
main	O
contribution	O
of	O
this	O
paper	O
is	O
an	O
effective	O
meta	B-Method
-	I-Method
training	I-Method
curriculum	O
.	O
	
Curriculum	B-Task
learning	I-Task
and	O
hard	B-Task
negative	I-Task
mining	I-Task
both	O
suggest	O
that	O
faster	O
convergence	B-Metric
and	O
stronger	O
performance	O
can	O
be	O
achieved	O
by	O
a	O
better	O
arrangement	O
of	O
training	O
data	O
.	O
	
Inspired	O
by	O
these	O
ideas	O
,	O
we	O
design	O
our	O
hard	B-Method
task	I-Method
(	O
HT	B-Method
)	O
meta	B-Method
-	I-Method
batch	I-Method
strategy	I-Method
to	O
offer	O
a	O
challenging	O
but	O
effective	O
learning	B-Task
curriculum	I-Task
.	O
	
As	O
shown	O
in	O
the	O
bottom	O
rows	O
of	O
Figure	O
[	O
reference	O
]	O
,	O
a	O
conventional	O
meta	O
-	O
batch	O
contains	O
a	O
number	O
of	O
random	O
tasks	O
,	O
but	O
our	O
HT	B-Method
meta	I-Method
-	I-Method
batch	I-Method
online	O
re	O
-	O
samples	O
harder	O
ones	O
according	O
to	O
past	O
failure	O
tasks	O
with	O
lowest	O
validation	O
accuracy	B-Metric
.	O
	
Our	O
overall	O
contribution	O
is	O
thus	O
three	O
-	O
fold	O
:	O
i	O
)	O
	
we	O
propose	O
a	O
novel	O
MTL	B-Method
method	O
that	O
learns	O
to	O
transfer	O
large	O
-	O
scale	O
pre	B-Method
-	O
trained	O
DNN	O
weights	O
for	O
solving	O
few	O
-	B-Material
shot	I-Material
learning	O
tasks	O
;	O
ii	O
)	O
we	O
propose	O
a	O
novel	O
HT	B-Method
meta	I-Method
-	I-Method
batch	I-Method
learning	I-Method
strategy	I-Method
that	O
forces	O
meta	B-Method
-	I-Method
transfer	I-Method
to	O
“	O
grow	O
faster	O
and	O
stronger	O
through	O
hardship	O
”	O
;	O
and	O
iii	O
)	O
we	O
conduct	O
extensive	O
experiments	O
on	O
two	O
few	O
-	B-Material
shot	I-Material
learning	O
benchmarks	O
,	O
namely	O
miniImageNet	B-Material
and	O
Fewshot	O
-	O
CIFAR100	O
(	O
FC100	O
)	O
,	O
and	O
achieve	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
.	O
	
section	O
:	O
Related	O
work	O
	
Few	O
-	B-Material
shot	I-Material
learning	O
Research	O
literature	O
on	O
few	O
-	B-Material
shot	I-Material
learning	O
exhibits	O
great	O
diversity	O
.	O
	
In	O
this	O
section	O
,	O
we	O
focus	O
on	O
methods	O
using	O
the	O
supervised	O
meta	B-Method
-	I-Method
learning	I-Method
paradigm	O
most	O
relevant	O
to	O
ours	O
and	O
compared	O
to	O
in	O
the	O
experiments	O
.	O
	
We	O
can	O
divide	O
these	O
methods	O
into	O
three	O
categories	O
.	O
	
1	O
)	O
	
Metric	B-Method
learning	I-Method
methods	I-Method
learn	O
a	O
similarity	O
space	O
in	O
which	O
learning	B-Task
is	O
efficient	O
for	O
few	O
-	B-Material
shot	I-Material
examples	O
.	O
	
2	O
)	O
	
Memory	B-Method
network	I-Method
methods	I-Method
learn	O
to	O
store	O
“	O
experience	O
”	O
when	O
learning	O
seen	O
tasks	O
and	O
then	O
generalize	O
that	O
to	O
unseen	O
tasks	O
.	O
	
3	O
	
)	O
Gradient	B-Method
descent	I-Method
based	I-Method
methods	I-Method
have	O
a	O
specific	O
meta	B-Method
-	I-Method
learner	I-Method
that	O
learns	O
to	O
adapt	O
a	O
specific	O
base	B-Method
-	I-Method
learner	I-Method
(	O
to	O
few	O
-	B-Material
shot	I-Material
examples	O
)	O
through	O
different	O
tasks	O
.	O
	
E.g.	B-Method
MAML	I-Method
uses	O
a	O
meta	B-Method
-	I-Method
learner	I-Method
that	O
learns	O
to	O
effectively	O
initialize	O
a	O
base	B-Method
-	I-Method
learner	I-Method
for	O
a	O
new	O
learning	B-Task
task	I-Task
.	O
	
Meta	B-Method
-	I-Method
learner	I-Method
optimization	I-Method
is	O
done	O
by	O
gradient	B-Method
descent	I-Method
using	O
the	O
validation	B-Metric
loss	I-Metric
of	O
the	O
base	B-Method
-	I-Method
learner	I-Method
.	O
	
Our	O
method	O
is	O
closely	O
related	O
.	O
	
An	O
important	O
difference	O
is	O
that	O
our	O
MTL	B-Method
approach	O
leverages	O
transfer	B-Method
learning	I-Method
and	O
benefits	O
from	O
referencing	O
neuron	O
knowledge	O
in	O
pre	B-Method
-	O
trained	O
deep	B-Method
nets	I-Method
.	O
	
Although	O
MAML	B-Method
can	O
start	O
from	O
a	O
pre	B-Method
-	O
trained	O
network	O
,	O
its	O
element	B-Method
-	I-Method
wise	I-Method
fine	I-Method
-	I-Method
tuning	I-Method
makes	O
it	O
hard	O
to	O
learn	O
deep	B-Method
nets	I-Method
without	O
overfitting	O
(	O
validated	O
in	O
our	O
experiments	O
)	O
.	O
	
Transfer	B-Task
learning	I-Task
What	O
and	O
how	O
to	O
transfer	O
are	O
key	O
issues	O
to	O
be	O
addressed	O
in	O
transfer	B-Task
learning	I-Task
,	O
as	O
different	O
methods	O
are	O
applied	O
to	O
different	O
source	O
-	O
target	O
domains	O
and	O
bridge	O
different	O
transfer	O
knowledge	O
.	O
	
For	O
deep	B-Method
models	I-Method
,	O
a	O
powerful	O
transfer	B-Method
method	I-Method
is	O
adapting	O
a	O
pre	B-Method
-	O
trained	O
model	O
for	O
a	O
new	O
task	O
,	O
often	O
called	O
fine	B-Task
-	I-Task
tuning	I-Task
(	O
FT	B-Task
)	O
.	O
	
Models	O
pre	B-Method
-	O
trained	O
on	O
large	O
-	O
scale	O
datasets	O
have	O
proven	O
to	O
generalize	O
better	O
than	O
randomly	O
initialized	O
ones	O
.	O
	
Another	O
popular	O
transfer	B-Method
method	I-Method
is	O
taking	O
pre	B-Method
-	O
trained	O
networks	O
as	O
backbone	O
and	O
adding	O
high	O
-	O
level	O
functions	O
,	O
e.g.	O
for	O
object	B-Task
detection	I-Task
and	I-Task
recognition	I-Task
and	O
image	B-Task
segmentation	I-Task
.	O
	
Our	O
meta	B-Method
-	I-Method
transfer	I-Method
learning	I-Method
leverages	O
the	O
idea	O
of	O
transferring	O
pre	B-Method
-	O
trained	O
weights	O
and	O
aims	O
to	O
	
meta	O
-	O
learn	O
how	O
to	O
effectively	O
transfer	O
.	O
	
In	O
this	O
paper	O
,	O
large	O
-	O
scale	O
trained	O
DNN	O
weights	O
are	O
what	O
to	O
transfer	O
,	O
and	O
the	O
operations	O
of	O
Scaling	O
and	O
Shifting	B-Task
indicate	O
how	O
to	O
transfer	O
.	O
	
Similar	O
operations	O
have	O
been	O
used	O
to	O
modulating	O
the	O
per	O
-	O
feature	O
-	O
map	O
distribution	O
of	O
activations	O
for	O
visual	B-Task
reasoning	I-Task
.	O
	
Some	O
few	O
-	B-Material
shot	I-Material
learning	O
methods	O
have	O
been	O
proposed	O
to	O
use	O
pre	B-Method
-	O
trained	O
weights	O
as	O
initialization	O
.	O
	
Typically	O
,	O
weights	O
are	O
fine	O
-	O
tuned	O
for	O
each	O
task	O
,	O
while	O
we	O
learn	O
a	O
meta	B-Method
-	I-Method
transfer	I-Method
learner	I-Method
through	O
all	O
tasks	O
,	O
which	O
is	O
different	O
in	O
terms	O
of	O
the	O
underlying	O
learning	B-Method
paradigm	I-Method
.	O
	
Curriculum	B-Task
learning	I-Task
&	O
Hard	B-Task
sample	I-Task
mining	I-Task
Curriculum	I-Task
learning	I-Task
was	O
proposed	O
by	O
Bengio	O
et	O
al	O
.	O
and	O
is	O
popular	O
for	O
multi	B-Task
-	I-Task
task	I-Task
learning	I-Task
.	O
	
They	O
showed	O
that	O
instead	O
of	O
observing	O
samples	O
at	O
random	O
it	O
is	O
better	O
to	O
organize	O
samples	O
in	O
a	O
meaningful	O
way	O
so	O
that	O
fast	O
convergence	B-Metric
,	O
effective	O
learning	B-Task
and	O
better	O
generalization	B-Task
can	O
be	O
achieved	O
.	O
	
Pentina	O
et	O
al	O
.	O
	
use	O
adaptive	O
SVM	B-Method
classifiers	I-Method
to	O
evaluate	O
task	O
difficulty	O
for	O
later	B-Task
organization	I-Task
.	O
	
Differently	O
,	O
our	O
MTL	B-Method
method	O
does	O
task	B-Task
evaluation	I-Task
online	O
at	O
the	O
phase	O
of	O
episode	O
test	B-Task
,	O
without	O
needing	O
any	O
auxiliary	B-Method
model	I-Method
.	O
	
Hard	B-Method
sample	I-Method
mining	I-Method
was	O
proposed	O
by	O
Shrivastava	O
et	O
al	O
.	O
for	O
object	B-Task
detection	I-Task
.	O
	
It	O
treats	O
image	O
proposals	O
overlapped	O
with	O
ground	O
truth	O
as	O
hard	O
negative	O
samples	O
.	O
	
Training	O
on	O
more	O
confusing	O
data	O
enables	O
the	O
model	O
to	O
achieve	O
higher	O
robustness	B-Metric
and	O
better	O
performance	O
.	O
	
Inspired	O
by	O
this	O
,	O
we	O
sample	O
harder	O
tasks	O
online	O
and	O
make	O
our	O
MTL	B-Method
learner	O
“	O
grow	O
faster	O
and	O
stronger	O
through	O
more	O
hardness	O
”	O
.	O
	
In	O
our	O
experiments	O
,	O
we	O
show	O
that	O
this	O
can	O
be	O
generalized	O
to	O
enhance	O
other	O
meta	B-Method
-	I-Method
learning	I-Method
methods	I-Method
,	O
e.g.	O
MAML	B-Method
.	O
	
section	O
:	O
Preliminary	O
	
We	O
introduce	O
the	O
problem	O
setup	O
and	O
notations	O
of	O
meta	B-Method
-	I-Method
learning	I-Method
,	O
following	O
related	O
work	O
.	O
	
Meta	B-Method
-	I-Method
learning	I-Method
consists	O
of	O
two	O
phases	O
:	O
meta	B-Method
-	I-Method
train	I-Method
and	O
meta	O
-	O
test	B-Task
.	O
	
A	O
meta	B-Method
-	I-Method
training	I-Method
example	O
is	O
a	O
classification	B-Task
task	I-Task
sampled	O
from	O
a	O
distribution	O
.	O
	
is	O
called	O
episode	B-Method
,	O
including	O
a	O
training	O
split	O
to	O
optimize	O
the	O
base	B-Method
-	I-Method
learner	I-Method
,	O
and	O
a	O
test	B-Task
split	O
to	O
optimize	O
the	O
meta	B-Method
-	I-Method
learner	I-Method
.	O
	
In	O
particular	O
,	O
meta	B-Method
-	I-Method
training	I-Method
aims	O
to	O
learn	O
from	O
a	O
number	O
of	O
episodes	O
sampled	O
from	O
.	O
	
An	O
unseen	O
task	O
in	O
meta	O
-	O
test	B-Task
will	O
start	O
from	O
that	O
experience	O
of	O
the	O
meta	B-Method
-	I-Method
learner	I-Method
and	O
adapt	O
the	O
base	B-Method
-	I-Method
learner	I-Method
.	O
	
The	O
final	O
evaluation	O
is	O
done	O
by	O
testing	O
a	O
set	O
of	O
unseen	O
datapoints	O
.	O
	
Meta	B-Method
-	I-Method
training	I-Method
phase	I-Method
.	O
	
This	O
phase	O
aims	O
to	O
learn	O
a	O
meta	B-Method
-	I-Method
learner	I-Method
from	O
multiple	O
episodes	O
.	O
	
In	O
each	O
episode	O
,	O
meta	B-Method
-	I-Method
training	I-Method
has	O
a	O
two	O
-	O
stage	B-Method
optimization	I-Method
.	O
	
Stage	B-Method
-	I-Method
1	I-Method
is	O
called	O
base	B-Task
-	I-Task
learning	I-Task
,	O
where	O
the	O
cross	B-Method
-	I-Method
entropy	I-Method
loss	I-Method
is	O
used	O
to	O
optimize	O
the	O
parameters	O
of	O
the	O
base	B-Method
-	I-Method
learner	I-Method
.	O
	
Stage	B-Method
-	I-Method
2	I-Method
contains	O
a	O
feed	O
-	O
forward	O
test	B-Task
on	O
episode	O
test	B-Task
datapoints	O
.	O
	
The	O
test	B-Task
loss	O
is	O
used	O
to	O
optimize	O
the	O
parameters	O
of	O
the	O
meta	B-Method
-	I-Method
learner	I-Method
.	O
	
Specifically	O
,	O
given	O
an	O
episode	O
,	O
the	O
base	B-Method
-	I-Method
learner	I-Method
is	O
learned	O
from	O
episode	O
training	O
data	O
and	O
its	O
corresponding	O
loss	B-Metric
.	O
	
After	O
optimizing	O
this	O
loss	O
,	O
the	O
base	B-Method
-	I-Method
learner	I-Method
has	O
parameters	O
.	O
	
Then	O
,	O
the	O
meta	B-Method
-	I-Method
learner	I-Method
is	O
updated	O
using	O
test	B-Task
loss	O
.	O
	
After	O
meta	B-Method
-	I-Method
training	I-Method
on	O
all	O
episodes	O
,	O
the	O
meta	B-Method
-	I-Method
learner	I-Method
is	O
optimized	O
by	O
test	B-Task
losses	O
.	O
	
Therefore	O
,	O
the	O
number	O
of	O
meta	B-Method
-	I-Method
learner	I-Method
updates	I-Method
equals	O
to	O
the	O
number	O
of	O
episodes	O
.	O
	
Meta	O
-	O
test	B-Task
phase	O
.	O
	
This	O
phase	O
aims	O
to	O
test	B-Task
the	O
performance	O
of	O
the	O
trained	O
meta	B-Method
-	I-Method
learner	I-Method
for	O
fast	B-Task
adaptation	I-Task
to	O
unseen	B-Task
task	I-Task
.	O
	
Given	O
,	O
the	O
meta	B-Method
-	I-Method
learner	I-Method
teaches	O
the	O
base	B-Method
-	I-Method
learner	I-Method
to	O
adapt	O
to	O
the	O
objective	O
of	O
by	O
some	O
means	O
,	O
e.g.	O
through	O
initialization	B-Task
.	O
	
Then	O
,	O
the	O
test	B-Task
result	O
on	O
is	O
used	O
to	O
evaluate	O
the	O
meta	B-Method
-	I-Method
learning	I-Method
approach	I-Method
.	O
	
If	O
there	O
are	O
multiple	O
unseen	O
tasks	O
,	O
the	O
average	O
result	O
on	O
will	O
be	O
the	O
final	O
evaluation	O
.	O
	
section	O
:	O
Methodology	O
	
As	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
our	O
method	O
consists	O
of	O
three	O
phases	O
.	O
	
First	O
,	O
we	O
train	O
a	O
DNN	B-Method
on	O
large	O
-	O
scale	O
data	O
,	O
e.g.	O
on	O
miniImageNet	B-Material
(	O
-	O
class	O
,	O
-	B-Material
shot	I-Material
)	O
,	O
and	O
then	O
fix	O
the	O
low	B-Method
-	I-Method
level	I-Method
layers	I-Method
as	O
Feature	B-Method
Extractor	I-Method
(	O
Section	O
[	O
reference	O
]	O
)	O
.	O
	
Second	O
,	O
in	O
the	O
meta	B-Method
-	I-Method
transfer	I-Method
learning	I-Method
phase	O
,	O
MTL	B-Method
learns	O
the	O
Scaling	B-Method
and	I-Method
Shifting	I-Method
	
(	O
SS	B-Task
)	O
parameters	O
for	O
the	O
Feature	B-Method
Extractor	I-Method
neurons	I-Method
,	O
enabling	O
fast	O
adaptation	B-Task
to	O
few	O
-	B-Material
shot	I-Material
tasks	O
(	O
Section	O
[	O
reference	O
]	O
)	O
.	O
	
For	O
improved	O
overall	B-Task
learning	I-Task
,	O
we	O
use	O
our	O
HT	B-Method
meta	I-Method
-	I-Method
batch	I-Method
strategy	I-Method
(	O
Section	O
[	O
reference	O
]	O
)	O
.	O
	
The	O
training	O
steps	O
are	O
detailed	O
in	O
Algorithm	O
[	O
reference	O
]	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Finally	O
,	O
the	O
typical	O
meta	O
-	O
test	B-Task
phase	O
is	O
performed	O
,	O
as	O
introduced	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
subsection	O
:	O
DNN	B-Method
training	I-Method
on	O
large	O
-	O
scale	O
data	O
	
This	O
phase	O
is	O
similar	O
to	O
the	O
classic	O
pre	B-Method
-	O
training	O
stage	O
as	O
,	O
e.g.	O
,	O
pre	B-Method
-	O
training	O
on	O
Imagenet	B-Task
for	O
object	B-Task
recognition	I-Task
.	O
	
Here	O
,	O
we	O
do	O
not	O
consider	O
data	B-Task
/	I-Task
domain	I-Task
adaptation	I-Task
from	O
other	O
datasets	O
,	O
and	O
pre	B-Method
-	O
train	O
on	O
readily	O
available	O
data	O
of	O
few	O
-	B-Material
shot	I-Material
learning	O
benchmarks	O
,	O
allowing	O
for	O
fair	O
comparison	O
with	O
other	O
few	O
-	B-Material
shot	I-Material
learning	O
methods	O
.	O
	
Specifically	O
,	O
for	O
a	O
particular	O
few	O
-	B-Material
shot	I-Material
dataset	O
,	O
we	O
merge	O
all	O
-	O
class	O
data	O
for	O
pre	B-Method
-	O
training	O
.	O
	
For	O
instance	O
,	O
for	O
miniImageNet	B-Material
,	O
there	O
are	O
totally	O
classes	O
in	O
the	O
training	O
split	O
of	O
and	O
each	O
class	O
contains	O
samples	O
used	O
to	O
pre	B-Method
-	O
train	O
a	O
-	B-Method
class	I-Method
classifier	I-Method
.	O
	
We	O
first	O
randomly	O
initialize	O
a	O
feature	B-Method
extractor	I-Method
(	O
e.g.	O
CONV	B-Method
layers	I-Method
in	O
ResNets	B-Method
)	O
and	O
a	O
classifier	B-Method
(	O
e.g.	O
the	O
last	O
FC	O
layer	O
in	O
ResNets	O
)	O
,	O
and	O
then	O
optimize	O
them	O
by	O
gradient	B-Method
descent	I-Method
as	O
follows	O
,	O
where	O
denotes	O
the	O
following	O
empirical	B-Metric
loss	I-Metric
,	O
e.g.	O
cross	B-Metric
-	I-Metric
entropy	I-Metric
loss	I-Metric
,	O
and	O
denotes	O
the	O
learning	B-Metric
rate	I-Metric
.	O
	
In	O
this	O
phase	O
,	O
the	O
feature	B-Method
extractor	I-Method
is	O
learned	O
.	O
	
It	O
will	O
be	O
frozen	O
in	O
the	O
following	O
meta	B-Method
-	I-Method
training	I-Method
and	O
meta	B-Method
-	I-Method
test	I-Method
phases	I-Method
,	O
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
The	O
learned	O
classifier	B-Method
will	O
be	O
discarded	O
,	O
because	O
subsequent	O
few	O
-	B-Material
shot	I-Material
tasks	O
contain	O
different	O
classification	O
objectives	O
,	O
e.g.	O
-	O
class	O
instead	O
of	O
-	B-Method
class	I-Method
classification	I-Method
for	O
miniImageNet	B-Material
.	O
	
subsection	O
:	O
Meta	B-Method
-	I-Method
transfer	I-Method
learning	I-Method
(	O
MTL	B-Method
)	O
	
As	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
(	O
b	O
)	O
,	O
our	O
proposed	O
meta	B-Method
-	I-Method
transfer	I-Method
learning	I-Method
(	O
MTL	B-Method
)	O
method	O
optimizes	O
the	O
meta	B-Task
operations	I-Task
Scaling	I-Task
and	I-Task
Shifting	I-Task
(	O
SS	B-Task
)	O
through	O
HT	B-Method
meta	O
-	O
batch	O
training	O
(	O
Section	O
[	O
reference	O
]	O
)	O
.	O
	
Figure	O
[	O
reference	O
]	O
visualizes	O
the	O
difference	O
of	O
updating	O
through	O
SS	B-Task
and	O
FT	B-Task
.	O
	
SS	B-Task
operations	O
,	O
denoted	O
as	O
and	O
,	O
do	O
not	O
change	O
the	O
frozen	O
neuron	O
weights	O
of	O
during	O
learning	O
,	O
while	O
FT	B-Task
updates	O
the	O
complete	O
.	O
	
In	O
the	O
following	O
,	O
we	O
detail	O
the	O
SS	B-Task
operations	O
.	O
	
Given	O
a	O
task	O
,	O
the	O
loss	O
of	O
is	O
used	O
to	O
optimize	O
the	O
current	O
base	B-Method
-	I-Method
learner	I-Method
(	O
classifier	O
)	O
by	O
gradient	B-Method
descent	I-Method
:	O
which	O
is	O
different	O
to	O
Eq	O
.	O
	
[	O
reference	O
]	O
,	O
as	O
we	O
do	O
not	O
update	O
.	O
	
Note	O
that	O
here	O
is	O
different	O
to	O
the	O
one	O
from	O
the	O
previous	O
phase	O
,	O
the	O
large	B-Method
-	I-Method
scale	I-Method
classifier	I-Method
in	O
Eq	O
.	O
	
[	O
reference	O
]	O
.	O
	
This	O
concerns	O
only	O
a	O
few	O
of	O
classes	O
,	O
e.g.	O
5	O
classes	O
,	O
to	O
classify	O
each	O
time	O
in	O
a	O
novel	O
few	O
-	B-Material
shot	I-Material
setting	O
.	O
	
corresponds	O
to	O
a	O
temporal	B-Method
classifier	I-Method
only	O
working	O
in	O
the	O
current	O
task	O
,	O
initialized	O
by	O
the	O
optimized	O
for	O
the	O
previous	O
task	O
(	O
see	O
Eq	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
is	O
initialized	O
by	O
ones	O
and	O
by	O
zeros	O
.	O
	
Then	O
,	O
they	O
are	O
optimized	O
by	O
the	O
test	B-Task
loss	O
of	O
as	O
follows	O
,	O
	
In	O
this	O
step	O
,	O
is	O
updated	O
with	O
the	O
same	O
learning	B-Metric
rate	I-Metric
as	O
in	O
Eq	O
.	O
	
[	O
reference	O
]	O
,	O
Re	O
-	O
linking	O
to	O
Eq	O
.	O
	
[	O
reference	O
]	O
	
,	O
we	O
note	O
that	O
the	O
above	O
comes	O
from	O
the	O
last	O
epoch	O
of	O
base	B-Task
-	I-Task
learning	I-Task
on	O
.	O
	
Next	O
,	O
we	O
describe	O
how	O
we	O
apply	O
to	O
the	O
frozen	O
neurons	O
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
	
(	O
b	O
)	O
.	O
	
Given	O
the	O
trained	O
,	O
for	O
its	O
-	O
th	O
layer	O
containing	O
neurons	O
,	O
we	O
have	O
pairs	O
of	O
parameters	O
,	O
respectively	O
as	O
weight	O
and	O
bias	O
,	O
denoted	O
as	O
.	O
	
Note	O
that	O
the	O
neuron	O
location	O
will	O
be	O
omitted	O
for	O
readability	O
.	O
	
Based	O
on	O
MTL	B-Method
,	O
we	O
learn	O
pairs	O
of	O
scalars	O
.	O
	
Assuming	O
is	O
input	O
,	O
we	O
apply	O
to	O
as	O
where	O
denotes	O
the	O
element	B-Method
-	I-Method
wise	I-Method
multiplication	I-Method
.	O
	
Taking	O
Figure	O
[	O
reference	O
]	O
	
(	O
b	O
)	O
as	O
an	O
example	O
of	O
a	O
single	O
filter	B-Method
,	O
after	O
SS	B-Task
operations	O
,	O
this	O
filter	O
is	O
scaled	O
by	O
then	O
the	O
feature	O
maps	O
after	O
convolutions	O
are	O
shifted	O
by	O
in	O
addition	O
to	O
the	O
original	O
bias	O
.	O
	
Detailed	O
steps	O
of	O
SS	B-Task
are	O
given	O
in	O
Algorithm	O
[	O
reference	O
]	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Figure	O
[	O
reference	O
]	O
(	O
a	O
)	O
shows	O
a	O
typical	O
parameter	O
-	O
level	O
Fine	B-Method
-	I-Method
Tuning	I-Method
(	O
FT	B-Task
)	O
operation	O
,	O
which	O
is	O
in	O
the	O
meta	B-Task
optimization	I-Task
phase	I-Task
of	O
our	O
related	O
work	O
MAML	B-Method
.	O
	
It	O
is	O
obvious	O
that	O
FT	B-Task
updates	O
the	O
complete	O
values	O
of	O
and	O
,	O
and	O
has	O
a	O
large	O
number	O
of	O
parameters	O
,	O
and	O
our	O
SS	B-Task
reduces	O
this	O
number	O
to	O
below	O
in	O
the	O
example	O
of	O
the	O
figure	O
.	O
	
In	O
summary	O
,	O
SS	B-Task
can	O
benefit	O
MTL	B-Method
in	O
three	O
aspects	O
.	O
	
1	O
)	O
It	O
starts	O
from	O
a	O
strong	O
initialization	B-Method
based	O
on	O
a	O
large	B-Method
-	I-Method
scale	I-Method
trained	I-Method
DNN	I-Method
,	O
yielding	O
fast	B-Metric
convergence	I-Metric
for	O
MTL	B-Method
.	O
	
2	O
)	O
	
It	O
does	O
not	O
change	O
DNN	O
weights	O
,	O
thereby	O
avoiding	O
the	O
problem	O
of	O
“	O
catastrophic	O
forgetting	O
”	O
when	O
learning	B-Task
specific	I-Task
tasks	I-Task
in	O
MTL	B-Method
.	O
	
3	O
)	O
	
It	O
is	O
light	O
-	O
weight	O
,	O
reducing	O
the	O
chance	O
of	O
overfitting	O
of	O
MTL	B-Method
in	O
few	O
-	B-Material
shot	I-Material
scenarios	O
.	O
	
subsection	O
:	O
Hard	B-Task
task	I-Task
(	O
HT	B-Method
)	O
meta	O
-	O
batch	O
	
In	O
this	O
section	O
,	O
we	O
introduce	O
a	O
method	O
to	O
schedule	O
hard	B-Task
tasks	I-Task
in	O
meta	B-Method
-	I-Method
training	I-Method
batches	O
.	O
	
The	O
conventional	O
meta	B-Method
-	I-Method
batch	I-Method
is	O
composed	O
of	O
randomly	O
sampled	O
tasks	O
,	O
where	O
the	O
randomness	O
implies	O
random	O
difficulties	O
.	O
	
In	O
our	O
meta	B-Method
-	I-Method
training	I-Method
pipeline	I-Method
,	O
we	O
intentionally	O
pick	O
up	O
failure	O
cases	O
in	O
each	O
task	O
and	O
re	O
-	O
compose	O
their	O
data	O
to	O
be	O
harder	O
tasks	O
for	O
adverse	O
re	B-Task
-	I-Task
training	I-Task
.	O
	
We	O
aim	O
to	O
force	O
our	O
meta	B-Method
-	I-Method
learner	I-Method
to	O
“	O
grow	O
up	O
through	O
hardness	O
”	O
.	O
	
Pipeline	B-Method
.	O
	
Each	O
task	O
has	O
two	O
splits	O
,	O
and	O
,	O
for	O
base	B-Task
-	I-Task
learning	I-Task
and	O
test	B-Task
,	O
respectively	O
.	O
	
As	O
shown	O
in	O
Algorithm	O
[	O
reference	O
]	O
line	O
2	O
-	O
5	O
,	O
base	B-Method
-	I-Method
learner	I-Method
is	O
optimized	O
by	O
the	O
loss	O
of	O
(	O
in	O
multiple	O
epochs	O
)	O
.	O
	
SS	B-Task
parameters	O
are	O
then	O
optimized	O
by	O
the	O
loss	O
of	O
once	O
.	O
	
We	O
can	O
also	O
get	O
the	O
recognition	O
accuracy	B-Metric
of	O
for	O
classes	O
.	O
	
Then	O
,	O
we	O
choose	O
the	O
lowest	O
accuracy	B-Metric
to	O
determine	O
the	O
most	O
difficult	O
class	O
-	O
(	O
also	O
called	O
failure	O
class	O
)	O
in	O
the	O
current	O
task	O
.	O
	
After	O
obtaining	O
all	O
failure	O
classes	O
(	O
indexed	O
by	O
)	O
from	O
tasks	O
in	O
current	O
meta	O
-	O
batch	O
,	O
we	O
re	O
-	O
sample	O
tasks	O
from	O
their	O
data	O
.	O
	
Specifically	O
,	O
we	O
assume	O
is	O
the	O
task	O
distribution	O
,	O
we	O
sample	O
a	O
“	O
harder	O
”	O
task	O
.	O
	
Two	O
important	O
details	O
are	O
given	O
below	O
.	O
	
Choosing	O
hard	O
class	O
-	O
m	O
.	O
	
We	O
choose	O
the	O
failure	O
class	O
-	O
from	O
each	O
task	O
by	O
ranking	O
the	O
class	B-Metric
-	I-Metric
level	I-Metric
accuracies	I-Metric
instead	O
of	O
fixing	O
a	O
threshold	O
.	O
	
In	O
a	O
dynamic	B-Task
online	I-Task
setting	I-Task
as	O
ours	O
,	O
it	O
is	O
more	O
sensible	O
to	O
choose	O
the	O
hardest	O
cases	O
based	O
on	O
ranking	B-Task
rather	O
than	O
fixing	O
a	O
threshold	O
ahead	O
of	O
time	O
.	O
	
Two	O
methods	O
of	O
hard	B-Task
tasking	I-Task
using	O
{	O
m}.	O
Chosen	O
,	O
we	O
can	O
re	O
-	O
sample	O
tasks	O
by	O
(	O
1	O
)	O
directly	O
using	O
the	O
samples	O
of	O
class	O
-	O
in	O
the	O
current	O
task	O
,	O
or	O
(	O
2	O
)	O
indirectly	O
using	O
the	O
label	O
of	O
class	O
-	O
to	O
sample	O
new	O
samples	O
of	O
that	O
class	O
.	O
	
In	O
fact	O
,	O
setting	O
(	O
2	O
)	O
considers	O
to	O
include	O
more	O
data	O
variance	O
of	O
class	O
-	O
and	O
it	O
works	O
better	O
than	O
setting	O
(	O
1	O
)	O
in	O
general	O
.	O
	
subsection	O
:	O
Algorithm	O
	
Algorithm	O
[	O
reference	O
]	O
summarizes	O
the	O
training	O
process	O
of	O
two	O
main	O
stages	O
:	O
large	B-Task
-	I-Task
scale	I-Task
DNN	I-Task
training	I-Task
(	O
line	O
1	O
-	O
5	O
)	O
and	O
meta	B-Method
-	I-Method
transfer	I-Method
learning	I-Method
(	O
line	O
6	O
-	O
22	O
)	O
.	O
	
HT	B-Method
meta	I-Method
-	I-Method
batch	I-Method
re	I-Method
-	I-Method
sampling	I-Method
and	O
continuous	B-Method
training	I-Method
phases	I-Method
are	O
shown	O
in	O
lines	O
16	O
-	O
20	O
,	O
for	O
which	O
the	O
failure	O
classes	O
are	O
returned	O
by	O
Algorithm	O
[	O
reference	O
]	O
,	O
see	O
line	O
14	O
.	O
	
Algorithm	O
[	O
reference	O
]	O
presents	O
the	O
learning	B-Method
process	I-Method
on	O
a	O
single	O
task	O
that	O
includes	O
episode	B-Task
training	I-Task
(	O
lines	O
2	O
-	O
5	O
)	O
and	O
episode	O
test	B-Task
,	O
i.e.	O
meta	O
-	O
level	O
update	O
(	O
lines	O
6	O
)	O
.	O
	
In	O
lines	O
7	O
-	O
11	O
,	O
the	O
recognition	B-Metric
rates	I-Metric
of	O
all	O
test	B-Task
classes	O
are	O
computed	O
and	O
returned	O
to	O
Algorithm	O
[	O
reference	O
]	O
(	O
line	O
14	O
)	O
for	O
hard	B-Method
task	I-Method
sampling	O
.	O
	
Meta	B-Method
-	I-Method
transfer	I-Method
learning	I-Method
(	O
MTL	B-Method
)	O
KwDataInput	O
	
KwResultOutput	O
Task	O
distribution	O
and	O
corresponding	O
dataset	O
,	O
learning	B-Metric
rates	I-Metric
,	O
and	O
Feature	B-Method
extractor	I-Method
,	O
base	B-Method
learner	I-Method
,	O
SS	B-Task
parameters	O
Randomly	O
initialize	O
and	O
samples	O
in	O
Evaluate	O
by	O
Eq	O
.	O
	
[	O
reference	O
]	O
Optimize	O
and	O
by	O
Eq	O
.	O
	
[	O
reference	O
]	O
	
Initialize	O
by	O
ones	O
,	O
initialize	O
by	O
zeros	O
Reset	O
and	O
re	O
-	O
initialize	O
for	O
few	O
-	B-Material
shot	I-Material
tasks	O
meta	O
-	O
batches	O
Randomly	O
sample	O
tasks	O
from	O
not	O
done	O
Sample	O
task	O
}	O
Optimize	O
and	O
with	O
by	O
Algorithm	O
[	O
reference	O
]	O
	
Get	O
the	O
returned	O
class	O
-	O
then	O
add	O
it	O
to	O
Sample	O
hard	O
tasks	O
from	O
not	O
done	O
Sample	O
task	O
}	O
Optimize	O
and	O
with	O
by	O
Algorithm	O
[	O
reference	O
]	O
Empty	O
.	O
	
Detail	O
learning	O
steps	O
within	O
a	O
task	O
	
T	O
KwDataInput	O
KwResultOutput	O
,	O
learning	B-Metric
rates	I-Metric
and	O
,	O
feature	B-Method
extractor	I-Method
,	O
base	B-Method
learner	I-Method
,	O
SS	B-Task
parameters	O
Updated	O
and	O
,	O
the	O
worst	O
classified	O
class	O
-	O
in	O
Sample	O
and	O
from	O
samples	O
in	O
Evaluate	O
Optimize	O
by	O
Eq	O
.	O
	
[	O
reference	O
]	O
Optimize	O
and	O
by	O
Eq	O
.	O
	
[	O
reference	O
]	O
and	O
Eq	O
.	O
	
[	O
reference	O
]	O
not	O
done	O
Sample	O
class	O
-	O
in	O
Compute	O
for	O
Return	O
class	O
-	O
with	O
the	O
lowest	O
accuracy	B-Metric
.	O
	
section	O
:	O
Experiments	O
	
We	O
evaluate	O
the	O
proposed	O
MTL	B-Method
and	O
HT	B-Method
meta	I-Method
-	I-Method
batch	I-Method
in	O
terms	O
of	O
few	O
-	B-Material
shot	I-Material
recognition	O
accuracy	B-Metric
and	O
model	B-Metric
convergence	I-Metric
speed	I-Metric
.	O
	
Below	O
we	O
describe	O
the	O
datasets	O
and	O
detailed	O
settings	O
,	O
followed	O
by	O
an	O
ablation	O
study	O
and	O
a	O
comparison	O
to	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
.	O
	
subsection	O
:	O
Datasets	O
and	O
implementation	O
details	O
	
We	O
conduct	O
few	O
-	B-Material
shot	I-Material
learning	O
experiments	O
on	O
two	O
benchmarks	O
,	O
miniImageNet	B-Material
and	O
Fewshot	O
-	O
CIFAR100	O
(	O
FC100	O
)	O
.	O
	
miniImageNet	B-Material
is	O
widely	O
used	O
in	O
related	O
works	O
.	O
	
FC100	O
is	O
newly	O
proposed	O
in	O
and	O
is	O
more	O
challenging	O
in	O
terms	O
of	O
lower	O
image	B-Metric
resolution	I-Metric
and	O
stricter	O
training	O
-	O
test	B-Task
splits	O
than	O
miniImageNet	B-Material
.	O
	
miniImageNet	B-Material
was	O
proposed	O
by	O
Vinyals	O
et	O
al	O
.	O
for	O
few	O
-	B-Material
shot	I-Material
learning	O
evaluation	O
.	O
	
Its	O
complexity	B-Metric
is	O
high	O
due	O
to	O
the	O
use	O
of	O
ImageNet	O
images	O
,	O
but	O
requires	O
less	O
resource	O
and	O
infrastructure	O
than	O
running	O
on	O
the	O
full	O
ImageNet	O
dataset	O
.	O
	
In	O
total	O
,	O
there	O
are	O
classes	O
with	O
samples	O
of	O
color	O
images	O
per	O
class	O
.	O
	
These	O
classes	O
are	O
divided	O
into	O
,	O
,	O
and	O
classes	O
respectively	O
for	O
sampling	B-Task
tasks	I-Task
for	O
meta	B-Method
-	I-Method
training	I-Method
,	O
meta	B-Task
-	I-Task
validation	I-Task
and	O
meta	O
-	O
test	B-Task
,	O
following	O
related	O
works	O
.	O
	
Fewshot	O
-	O
CIFAR100	O
(	O
FC100	O
)	O
is	O
based	O
on	O
the	O
popular	O
object	O
classification	O
dataset	O
CIFAR100	O
.	O
	
The	O
splits	O
were	O
proposed	O
by	O
(	O
Please	O
check	O
details	O
in	O
the	O
supplementary	O
)	O
.	O
	
It	O
offers	O
a	O
more	O
challenging	O
scenario	O
with	O
lower	O
image	O
resolution	O
and	O
more	O
challenging	O
meta	B-Method
-	I-Method
training	I-Method
/	O
test	B-Task
splits	O
that	O
are	O
separated	O
according	O
to	O
object	O
super	O
-	O
classes	O
.	O
	
It	O
contains	O
object	O
classes	O
and	O
each	O
class	O
has	O
samples	O
of	O
color	O
images	O
.	O
	
The	O
classes	O
belong	O
to	O
super	O
-	O
classes	O
.	O
	
Meta	O
-	O
training	O
data	O
are	O
from	O
classes	O
belonging	O
to	O
super	O
-	O
classes	O
.	O
	
Meta	B-Method
-	I-Method
validation	I-Method
and	O
meta	O
-	O
test	B-Task
sets	O
contain	O
classes	O
belonging	O
to	O
super	O
-	O
classes	O
,	O
respectively	O
.	O
	
These	O
splits	O
accord	O
to	O
super	O
-	O
classes	O
,	O
thus	O
minimize	O
the	O
information	O
overlap	O
between	O
training	O
and	O
val	O
/	O
test	B-Task
tasks	O
.	O
	
The	O
following	O
settings	O
are	O
used	O
on	O
both	O
datasets	O
.	O
	
We	O
train	O
a	O
large	B-Method
-	I-Method
scale	I-Method
DNN	I-Method
with	O
all	O
training	O
datapoints	O
(	O
Section	O
[	O
reference	O
]	O
)	O
and	O
stop	O
this	O
training	O
after	O
iterations	O
.	O
	
We	O
use	O
the	O
same	O
task	B-Method
sampling	I-Method
method	I-Method
as	O
related	O
works	O
.	O
	
Specifically	O
,	O
1	O
)	O
we	O
consider	O
the	O
5	B-Task
-	I-Task
class	I-Task
classification	O
and	O
2	O
)	O
	
we	O
sample	O
5	B-Task
-	I-Task
class	I-Task
,	O
	
1	O
-	B-Material
shot	I-Material
(	O
5	O
-	B-Material
shot	I-Material
or	O
10	O
-	B-Material
shot	I-Material
)	O
episodes	O
to	O
contain	O
1	O
(	O
5	O
or	O
10	O
)	O
samples	O
for	O
train	O
episode	O
,	O
and	O
(	O
uniform	O
)	O
samples	O
for	O
episode	O
test	B-Task
.	O
	
Note	O
that	O
in	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
work	O
,	O
and	O
samples	O
are	O
respectively	O
used	O
in	O
5	B-Material
-	I-Material
shot	I-Material
and	O
10	B-Task
-	I-Task
shot	I-Task
settings	I-Task
for	O
episode	O
test	B-Task
.	O
	
In	O
total	O
,	O
we	O
sample	O
tasks	O
for	O
meta	B-Method
-	I-Method
training	I-Method
(	O
same	O
for	O
w	O
/	O
and	O
w	O
/	O
o	O
HT	B-Method
meta	O
-	O
batch	O
)	O
,	O
and	O
respectively	O
sample	O
random	B-Method
tasks	I-Method
for	O
meta	B-Task
-	I-Task
validation	I-Task
and	O
meta	O
-	O
test	B-Task
.	O
	
Please	O
check	O
the	O
supplementary	O
document	O
(	O
or	O
)	O
for	O
other	O
implementation	O
details	O
,	O
e.g.	O
learning	B-Metric
rate	I-Metric
and	O
dropout	B-Metric
rate	I-Metric
.	O
	
Network	B-Method
architecture	I-Method
.	O
	
We	O
present	O
the	O
details	O
for	O
the	O
Feature	B-Method
Extractor	I-Method
,	O
MTL	B-Method
meta	I-Method
-	I-Method
learner	I-Method
with	O
Scaling	B-Method
and	I-Method
Shifting	I-Method
,	O
and	O
MTL	B-Method
base	I-Method
-	I-Method
learner	I-Method
(	O
classifier	B-Method
)	O
.	O
	
The	O
architecture	O
of	O
Θ	B-Method
have	O
two	O
options	O
,	O
ResNet	B-Method
-	I-Method
12	I-Method
and	O
4CONV	B-Method
,	O
commonly	O
used	O
in	O
related	O
works	O
.	O
	
4CONV	B-Method
consists	O
of	O
layers	O
with	O
convolutions	B-Method
and	I-Method
filters	I-Method
,	O
followed	O
by	O
batch	B-Method
normalization	I-Method
(	O
BN	B-Method
)	I-Method
,	O
a	O
ReLU	B-Method
nonlinearity	I-Method
,	O
and	O
max	B-Method
-	I-Method
pooling	I-Method
.	O
	
ResNet	B-Method
-	I-Method
12	I-Method
is	O
more	O
popular	O
in	O
recent	O
works	O
.	O
	
It	O
contains	O
residual	O
blocks	O
and	O
each	O
block	O
has	O
CONV	B-Method
layers	I-Method
with	O
kernels	O
.	O
	
At	O
the	O
end	O
of	O
each	O
residual	O
block	O
,	O
a	O
max	B-Method
-	I-Method
pooling	I-Method
layer	I-Method
is	O
applied	O
.	O
	
The	O
number	O
of	O
filters	O
starts	O
from	O
and	O
is	O
doubled	O
every	O
next	O
block	O
.	O
	
Following	O
blocks	O
,	O
there	O
is	O
a	O
mean	B-Method
-	I-Method
pooling	I-Method
layer	I-Method
to	O
compress	O
the	O
output	O
feature	O
maps	O
to	O
a	O
feature	B-Method
embedding	I-Method
.	O
	
The	O
difference	O
between	O
using	O
4CONV	B-Method
and	O
using	O
ResNet	B-Method
-	I-Method
12	I-Method
in	O
our	O
methods	O
is	O
that	O
ResNet	B-Method
-	I-Method
12	I-Method
MTL	I-Method
sees	O
the	O
large	B-Task
-	I-Task
scale	I-Task
data	I-Task
training	I-Task
,	O
but	O
4CONV	B-Method
MTL	I-Method
is	O
learned	O
from	O
scratch	O
because	O
of	O
its	O
poor	O
performance	O
for	O
large	B-Task
-	I-Task
scale	I-Task
data	I-Task
training	I-Task
(	O
see	O
results	O
in	O
the	O
supplementary	O
)	O
.	O
	
Therefore	O
,	O
we	O
emphasize	O
the	O
experiments	O
of	O
using	O
ResNet	B-Method
-	I-Method
12	I-Method
MTL	I-Method
for	O
its	O
superior	O
performance	O
.	O
	
The	O
architectures	O
of	O
ΦS1	O
and	O
ΦS2	B-Method
are	O
generated	O
according	O
to	O
the	O
architecture	O
of	O
,	O
as	O
introduced	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
That	O
is	O
when	O
using	O
ResNet	B-Method
-	I-Method
12	I-Method
in	O
MTL	B-Method
,	O
and	O
also	O
have	O
12	O
layers	O
,	O
respectively	O
.	O
	
The	O
architecture	O
of	O
θ	B-Method
is	O
an	O
FC	B-Method
layer	I-Method
.	O
	
We	O
empirically	O
find	O
that	O
a	O
single	O
FC	B-Method
layer	I-Method
is	O
faster	O
to	O
train	O
and	O
more	O
effective	O
for	O
classification	B-Task
than	O
multiple	O
layers	O
.	O
	
(	O
see	O
comparisons	O
in	O
the	O
supplementary	O
)	O
.	O
	
subsection	O
:	O
Ablation	O
study	O
setting	O
	
In	O
order	O
to	O
show	O
the	O
effectiveness	O
of	O
our	O
approach	O
,	O
we	O
design	O
some	O
ablative	B-Method
settings	I-Method
:	O
two	O
baselines	O
without	O
meta	B-Method
-	I-Method
learning	I-Method
but	O
more	O
classic	B-Method
learning	I-Method
,	O
three	O
baselines	O
of	O
Fine	B-Method
-	I-Method
Tuning	I-Method
(	O
FT	B-Task
)	O
on	O
smaller	O
number	O
of	O
parameters	O
(	O
Table	O
[	O
reference	O
]	O
)	O
,	O
and	O
two	O
MAML	B-Method
variants	I-Method
using	O
our	O
deeper	O
pre	B-Method
-	O
trained	O
model	O
and	O
HT	B-Method
meta	I-Method
-	I-Method
batch	I-Method
(	O
Table	O
[	O
reference	O
]	O
and	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
Note	O
that	O
the	O
alternative	O
meta	B-Method
-	I-Method
learning	I-Method
operation	I-Method
to	O
SS	B-Task
is	O
the	O
FT	B-Task
used	O
in	O
MAML	B-Method
.	O
	
Some	O
bullet	O
names	O
are	O
explained	O
as	O
follows	O
.	O
	
update	O
[	O
Θ;θ	O
]	O
(	O
or	O
θ	O
)	O
.	O
	
There	O
is	O
no	O
meta	B-Method
-	I-Method
training	I-Method
phase	O
.	O
	
During	O
test	B-Task
phase	O
,	O
each	O
task	O
has	O
its	O
whole	O
model	O
(	O
or	O
the	O
classifier	B-Method
)	O
updated	O
on	O
,	O
and	O
then	O
tested	O
on	O
.	O
	
FT	B-Task
[	O
⁢Θ4;θ	O
]	O
(	O
or	O
θ	O
)	O
.	O
	
These	O
are	O
straight	O
-	O
forward	O
ways	O
to	O
define	O
a	O
smaller	O
set	O
of	O
meta	B-Method
-	I-Method
learner	I-Method
parameters	O
than	O
MAML	B-Method
.	O
	
We	O
can	O
freeze	O
low	O
-	O
level	O
pre	B-Method
-	O
trained	O
layers	O
and	O
meta	O
-	O
learn	O
the	O
classifier	B-Method
layer	I-Method
with	O
(	O
or	O
without	O
)	O
high	B-Method
-	I-Method
level	I-Method
CONV	I-Method
layer	I-Method
that	O
is	O
the	O
4th	O
residual	O
block	O
of	O
ResNet	B-Method
-	I-Method
12	I-Method
.	O
	
subsection	O
:	O
Results	O
and	O
analysis	O
	
Table	O
[	O
reference	O
]	O
,	O
Table	O
[	O
reference	O
]	O
and	O
Table	O
[	O
reference	O
]	O
	
present	O
the	O
overall	O
results	O
on	O
miniImageNet	B-Material
and	O
FC100	O
datasets	O
.	O
	
Extensive	O
comparisons	O
are	O
done	O
with	O
ablative	B-Method
methods	I-Method
and	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
arts	O
.	O
	
Note	O
that	O
tables	O
present	O
the	O
highest	O
accuracies	B-Metric
for	O
which	O
the	O
iterations	O
were	O
chosen	O
by	O
validation	O
.	O
	
For	O
the	O
miniImageNet	B-Material
,	O
iterations	O
for	O
1	B-Material
-	I-Material
shot	I-Material
and	O
5	B-Material
-	I-Material
shot	I-Material
are	O
at	O
and	O
,	O
respectively	O
.	O
	
For	O
the	O
FC100	O
,	O
iterations	O
are	O
all	O
at	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
the	O
performance	O
gap	O
between	O
with	O
and	O
without	O
HT	B-Method
meta	I-Method
-	I-Method
batch	I-Method
in	O
terms	O
of	O
accuracy	B-Metric
and	O
converging	B-Metric
speed	I-Metric
.	O
	
Result	O
overview	O
on	O
miniImageNet	B-Material
.	O
	
In	O
Table	O
[	O
reference	O
]	O
,	O
we	O
can	O
see	O
that	O
the	O
proposed	O
MTL	B-Method
with	O
SS	B-Task
,	O
HT	B-Method
meta	I-Method
-	I-Method
batch	I-Method
and	O
ResNet	B-Method
-	I-Method
12	I-Method
(	O
pre	B-Method
)	O
achieves	O
the	O
best	O
few	B-Metric
-	I-Metric
shot	I-Metric
classification	I-Metric
performance	I-Metric
with	O
for	O
(	O
5	B-Task
-	I-Task
class	I-Task
,	O
1	O
-	B-Material
shot	I-Material
)	O
.	O
	
Besides	O
,	O
it	O
tackles	O
the	O
(	O
5	B-Task
-	I-Task
class	I-Task
,	O
5	O
-	B-Material
shot	I-Material
)	O
tasks	O
with	O
an	O
accuracy	B-Metric
of	O
that	O
is	O
comparable	O
to	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
,	O
i.e.	O
,	O
reported	O
by	O
TADAM	O
whose	O
model	O
used	O
additional	O
FC	B-Method
layers	I-Method
in	O
the	O
ResNet	B-Method
-	I-Method
12	I-Method
arch	O
.	O
	
In	O
terms	O
of	O
the	O
network	B-Task
arch	I-Task
,	O
it	O
is	O
obvious	O
that	O
models	O
using	O
ResNet	B-Method
-	I-Method
12	I-Method
(	O
pre	B-Method
)	O
outperforms	O
those	O
using	O
4CONV	B-Method
by	O
large	O
margins	O
,	O
e.g.	O
4CONV	B-Method
models	O
have	O
the	O
best	O
1	O
-	B-Material
shot	I-Material
result	O
with	O
which	O
is	O
lower	O
than	O
our	O
best	O
.	O
	
Result	O
overview	O
on	O
FC100	O
.	O
	
In	O
Table	O
[	O
reference	O
]	O
,	O
we	O
give	O
the	O
results	O
of	O
TADAM	O
using	O
their	O
reported	O
numbers	O
in	O
the	O
paper	O
.	O
	
We	O
used	O
the	O
public	O
code	O
of	O
MAML	B-Method
to	O
get	O
its	O
results	O
for	O
this	O
new	O
dataset	O
.	O
	
Comparing	O
these	O
methods	O
,	O
we	O
can	O
see	O
that	O
MTL	B-Method
consistently	O
outperforms	O
MAML	B-Method
by	O
large	O
margins	O
,	O
i.e.	O
around	O
in	O
all	O
tasks	O
;	O
and	O
surpasses	O
TADAM	O
by	O
a	O
relatively	O
larger	O
number	O
of	O
for	O
1	B-Material
-	I-Material
shot	I-Material
,	O
and	O
with	O
and	O
respectively	O
for	O
5	B-Material
-	I-Material
shot	I-Material
and	O
10	O
-	B-Material
shot	I-Material
tasks	O
.	O
	
MTL	B-Method
vs.	O
	
No	O
meta	B-Method
-	I-Method
learning	I-Method
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
results	O
of	O
No	O
meta	B-Method
-	I-Method
learning	I-Method
on	O
the	O
top	O
block	O
.	O
	
Compared	O
to	O
these	O
,	O
our	O
approach	O
achieves	O
significantly	O
better	O
performance	O
even	O
without	O
HT	B-Method
meta	I-Method
-	I-Method
batch	I-Method
,	O
e.g.	O
the	O
largest	O
margins	O
are	O
for	O
1	B-Material
-	I-Material
shot	I-Material
and	O
for	O
5	B-Material
-	I-Material
shot	I-Material
on	O
miniImageNet	B-Material
.	O
	
This	O
validates	O
the	O
effectiveness	O
of	O
our	O
meta	B-Method
-	I-Method
learning	I-Method
method	I-Method
for	O
tackling	O
few	O
-	B-Material
shot	I-Material
learning	O
problems	O
.	O
	
Between	O
two	O
No	B-Method
meta	I-Method
-	I-Method
learning	I-Method
methods	I-Method
,	O
we	O
can	O
see	O
that	O
updating	O
both	O
feature	B-Method
extractor	I-Method
and	O
classifier	B-Method
is	O
inferior	O
to	O
updating	O
only	O
,	O
e.g.	O
around	O
reduction	B-Task
on	O
miniImageNet	B-Material
1	I-Material
-	I-Material
shot	I-Material
.	O
	
One	O
reason	O
is	O
that	O
in	O
few	O
-	B-Material
shot	I-Material
settings	O
,	O
there	O
are	O
too	O
many	O
parameters	O
to	O
optimize	O
with	O
little	O
data	O
.	O
	
This	O
supports	O
our	O
motivation	O
to	O
learn	O
only	O
during	O
base	B-Task
-	I-Task
learning	I-Task
.	O
	
Performance	O
effects	O
of	O
MTL	B-Method
components	O
.	O
	
MTL	B-Method
with	O
full	B-Method
components	I-Method
,	O
SS	B-Task
,	O
HT	B-Method
meta	I-Method
-	I-Method
batch	I-Method
and	O
ResNet	B-Method
-	I-Method
12	I-Method
(	O
pre	B-Method
)	O
,	O
achieves	O
the	O
best	O
performances	O
for	O
all	O
few	O
-	B-Material
shot	I-Material
settings	O
on	O
both	O
datasets	O
,	O
see	O
Table	O
[	O
reference	O
]	O
and	O
Table	O
[	O
reference	O
]	O
.	O
	
We	O
can	O
conclude	O
that	O
our	O
large	B-Method
-	I-Method
scale	I-Method
network	I-Method
training	I-Method
on	O
deep	B-Method
CNN	I-Method
significantly	O
boost	O
the	O
few	O
-	B-Material
shot	I-Material
learning	O
performance	O
.	O
	
This	O
is	O
an	O
important	O
gain	O
brought	O
by	O
the	O
transfer	B-Method
learning	I-Method
idea	I-Method
in	O
our	O
MTL	B-Method
approach	O
.	O
	
It	O
is	O
interesting	O
to	O
note	O
that	O
this	O
gain	O
on	O
FC100	O
is	O
not	O
as	O
large	O
as	O
for	O
miniImageNet	B-Material
:	O
only	O
,	O
and	O
.	O
	
The	O
possible	O
reason	O
is	O
that	O
FC100	B-Task
tasks	I-Task
for	O
meta	B-Task
-	I-Task
train	I-Task
and	O
meta	O
-	O
test	B-Task
are	O
clearly	O
split	O
according	O
to	O
super	O
-	O
classes	O
.	O
	
The	O
data	O
domain	O
gap	O
is	O
larger	O
than	O
that	O
for	O
miniImageNet	B-Material
,	O
which	O
makes	O
transfer	B-Task
more	O
difficult	O
.	O
	
HT	B-Method
meta	I-Method
-	I-Method
batch	I-Method
and	O
ResNet	B-Method
-	I-Method
12	I-Method
(	O
pre	B-Method
)	O
in	O
our	O
approach	O
can	O
be	O
generalized	O
to	O
other	O
meta	B-Method
-	I-Method
learning	I-Method
models	I-Method
.	O
	
MAML	O
4CONV	B-Method
with	O
HT	B-Method
meta	I-Method
-	I-Method
batch	I-Method
gains	O
averagely	O
on	O
two	O
datasets	O
.	O
	
When	O
changing	O
4CONV	B-Method
by	O
deep	O
ResNet	B-Method
-	I-Method
12	I-Method
(	O
pre	B-Method
)	O
it	O
achieves	O
significant	O
improvements	O
,	O
e.g.	O
and	O
on	O
miniImageNet	B-Material
.	O
	
Compared	O
to	O
MAML	B-Method
variants	I-Method
,	O
our	O
MTL	B-Method
results	O
are	O
consistently	O
higher	O
,	O
e.g.	O
on	O
FC100	O
.	O
	
People	O
may	O
argue	O
that	O
MAML	B-Method
fine	I-Method
-	I-Method
tuning	I-Method
(	O
FT	B-Task
)	O
	
all	O
network	B-Method
parameters	I-Method
is	O
likely	O
to	O
overfit	O
to	O
few	O
-	B-Material
shot	I-Material
data	O
.	O
	
In	O
the	O
middle	O
block	O
of	O
Table	O
[	O
reference	O
]	O
,	O
we	O
show	O
the	O
ablation	O
study	O
of	O
freezing	O
low	O
-	O
level	O
pre	B-Method
-	O
trained	O
layers	O
and	O
meta	O
-	O
learn	O
only	O
the	O
high	O
-	O
level	O
layers	O
(	O
e.g.	O
the	O
-	O
th	O
residual	O
block	O
of	O
ResNet	B-Method
-	I-Method
12	I-Method
)	O
by	O
the	O
FT	B-Task
operations	O
of	O
MAML	B-Method
.	O
	
These	O
all	O
yield	O
inferior	O
performances	O
than	O
using	O
our	O
SS	B-Task
.	O
	
An	O
additional	O
observation	O
is	O
that	O
SS	B-Task
*	O
performs	O
consistently	O
better	O
than	O
	
FT	B-Task
*	O
.	O
	
Speed	B-Metric
of	I-Metric
convergence	I-Metric
of	O
MTL	B-Method
.	O
	
MAML	B-Method
used	O
tasks	O
to	O
achieve	O
the	O
best	O
performance	O
on	O
miniImageNet	B-Material
.	O
	
Impressively	O
,	O
our	O
MTL	B-Method
methods	O
used	O
only	O
tasks	O
,	O
see	O
Figure	O
[	O
reference	O
]	O
	
(	O
a	O
)(	O
b	O
)	O
	
(	O
note	O
that	O
each	O
iteration	O
contains	O
2	O
tasks	O
)	O
.	O
	
This	O
advantage	O
is	O
more	O
obvious	O
for	O
FC100	O
on	O
which	O
MTL	B-Method
methods	O
need	O
at	O
most	O
tasks	O
,	O
Figure	O
[	O
reference	O
]	O
(	O
c	O
)(	O
d	O
)(	O
e	O
)	O
.	O
	
We	O
attest	O
this	O
to	O
two	O
reasons	O
.	O
	
First	O
,	O
MTL	B-Method
starts	O
from	O
the	O
pre	B-Method
-	O
trained	O
ResNet	B-Method
-	I-Method
12	I-Method
.	O
	
And	O
second	O
,	O
SS	B-Task
(	O
in	O
MTL	B-Method
)	O
needs	O
to	O
learn	O
only	O
parameters	O
of	O
the	O
number	O
of	O
FT	B-Task
(	O
in	O
MAML	B-Method
)	O
when	O
using	O
ResNet	B-Method
-	I-Method
12	I-Method
.	O
	
Speed	B-Metric
of	I-Metric
convergence	I-Metric
of	O
HT	B-Method
meta	I-Method
-	I-Method
batch	I-Method
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
1	O
)	O
MTL	B-Method
with	O
HT	B-Method
meta	I-Method
-	I-Method
batch	I-Method
consistently	O
achieves	O
higher	O
performances	O
than	O
MTL	B-Method
with	O
the	O
conventional	O
meta	B-Method
-	I-Method
batch	I-Method
,	O
in	O
terms	O
of	O
the	O
recognition	O
accuracy	B-Metric
in	O
all	O
settings	O
;	O
and	O
2	O
)	O
it	O
is	O
impressive	O
that	O
MTL	B-Method
with	O
HT	B-Method
meta	I-Method
-	I-Method
batch	I-Method
achieves	O
top	O
performances	O
early	O
,	O
after	O
about	O
iterations	O
for	O
1	B-Material
-	I-Material
shot	I-Material
,	O
for	O
5	B-Material
-	I-Material
shot	I-Material
and	O
for	O
	
10	O
-	B-Material
shot	I-Material
,	O
on	O
the	O
more	O
challenging	O
dataset	O
–	O
FC100	O
.	O
	
section	O
:	O
Conclusions	O
	
In	O
this	O
paper	O
,	O
we	O
show	O
that	O
our	O
novel	O
MTL	B-Method
trained	O
with	O
HT	B-Method
meta	I-Method
-	I-Method
batch	I-Method
learning	I-Method
curriculum	I-Method
achieves	O
the	O
top	O
performance	O
for	O
tackling	O
few	O
-	B-Material
shot	I-Material
learning	O
problems	O
.	O
	
The	O
key	O
operations	O
of	O
MTL	B-Method
on	O
pre	B-Method
-	O
trained	O
DNN	B-Method
neurons	I-Method
proved	O
highly	O
efficient	O
for	O
adapting	O
learning	O
experience	O
to	O
the	O
unseen	B-Task
task	I-Task
.	O
	
The	O
superiority	O
was	O
particularly	O
achieved	O
in	O
the	O
extreme	O
1	O
-	B-Material
shot	I-Material
cases	O
on	O
two	O
challenging	O
benchmarks	O
–	O
miniImageNet	B-Material
and	O
FC100	O
.	O
	
In	O
terms	O
of	O
learning	B-Method
scheme	I-Method
,	O
HT	B-Method
meta	I-Method
-	I-Method
batch	I-Method
showed	O
consistently	O
good	O
performance	O
for	O
all	O
baselines	O
and	O
ablative	B-Method
models	I-Method
.	O
	
On	O
the	O
more	O
challenging	O
FC100	O
benchmark	O
,	O
it	O
showed	O
to	O
be	O
particularly	O
helpful	O
for	O
boosting	B-Metric
convergence	I-Metric
speed	I-Metric
.	O
	
This	O
design	O
is	O
independent	O
from	O
any	O
specific	O
model	O
and	O
could	O
be	O
generalized	O
well	O
whenever	O
the	O
hardness	O
of	O
task	O
is	O
easy	O
to	O
evaluate	O
in	O
online	O
iterations	O
.	O
	
section	O
:	O
Acknowledgments	O
	
This	O
research	O
is	O
part	O
of	O
NExT	O
research	O
which	O
is	O
supported	O
by	O
the	O
National	O
Research	O
Foundation	O
,	O
Prime	O
Minister	O
’s	O
Office	O
,	O
Singapore	O
under	O
its	O
IRC@SG	O
Funding	O
Initiative	O
.	O
	
It	O
is	O
also	O
partially	O
supported	O
by	O
German	O
Research	O
Foundation	O
(	O
DFG	O
CRC	O
1223	O
)	O
,	O
and	O
National	O
Natural	O
Science	O
Foundation	O
of	O
China	O
(	O
61772359	O
)	O
.	O
	
bibliography	O
:	O
References	O
	
Supplementary	O
materials	O
	
These	O
materials	O
include	O
the	O
details	O
of	O
network	B-Method
architecture	I-Method
(	O
§	O
[	O
reference	O
]	O
)	O
,	O
implementation	O
(	O
§	O
[	O
reference	O
]	O
)	O
,	O
FC100	O
dataset	O
splits	O
(	O
§	O
[	O
reference	O
]	O
)	O
,	O
standard	O
variance	B-Method
analysis	I-Method
(	O
§	O
[	O
reference	O
]	O
)	O
,	O
additional	O
ablation	O
results	O
(	O
§	O
[	O
reference	O
]	O
)	O
,	O
and	O
some	O
interpretation	O
of	O
our	O
meta	B-Method
-	I-Method
learned	I-Method
model	I-Method
(	O
§	O
[	O
reference	O
]	O
)	O
.	O
	
In	O
addition	O
,	O
our	O
open	O
-	O
source	O
code	O
is	O
on	O
GitHub	O
.	O
	
section	O
:	O
Network	B-Method
architectures	I-Method
	
In	O
Figure	O
[	O
reference	O
]	O
,	O
we	O
present	O
the	O
4CONV	B-Method
architecture	O
for	O
feature	B-Task
extractor	I-Task
,	O
as	O
illustrated	O
in	O
Section	O
5.1	O
“	O
Network	B-Method
architecture	I-Method
”	O
of	O
the	O
main	O
paper	O
.	O
	
In	O
Figure	O
[	O
reference	O
]	O
,	O
we	O
present	O
the	O
other	O
architecture	O
–	O
ResNet	B-Method
-	I-Method
12	I-Method
.	O
	
Figure	O
[	O
reference	O
]	O
(	O
a	O
)	O
shows	O
the	O
details	O
of	O
a	O
single	O
residual	O
block	O
and	O
Figure	O
[	O
reference	O
]	O
	
(	O
b	O
)	O
shows	O
the	O
whole	O
network	O
consisting	O
of	O
four	O
residual	O
blocks	O
and	O
a	O
mean	B-Method
-	I-Method
pooling	I-Method
layer	I-Method
.	O
	
The	O
input	O
of	O
is	O
the	O
-	O
channel	O
RGB	O
image	O
,	O
and	O
the	O
output	O
is	O
the	O
-	O
dimensional	O
feature	O
vector	O
.	O
is	O
set	O
for	O
all	O
leakyReLU	B-Method
activation	I-Method
functions	I-Method
in	O
ResNet	B-Method
-	I-Method
12	I-Method
.	O
	
section	O
:	O
Implementation	O
details	O
	
For	O
the	O
phase	O
of	O
DNN	B-Task
training	I-Task
on	O
large	O
-	O
scale	O
data	O
,	O
the	O
model	O
is	O
trained	O
by	O
Adam	B-Method
optimizer	I-Method
.	O
	
Its	O
learning	B-Metric
rate	I-Metric
is	O
initialized	O
as	O
,	O
and	O
decays	O
to	O
its	O
half	O
every	O
iterations	O
until	O
it	O
is	O
lower	O
that	O
.	O
	
We	O
set	O
the	O
keep	O
probability	O
of	O
the	O
dropout	O
as	O
and	O
batch	O
-	O
size	O
as	O
.	O
	
The	O
pre	B-Method
-	O
training	O
stops	O
after	O
iterations	O
.	O
	
Note	O
that	O
for	O
the	O
hyperparameter	B-Task
selection	I-Task
,	O
we	O
randomly	O
choose	O
samples	O
each	O
class	O
as	O
the	O
training	O
set	O
,	O
and	O
the	O
rest	O
as	O
validation	O
.	O
	
After	O
the	O
grid	O
search	O
of	O
hyperparameters	O
,	O
we	O
fix	O
them	O
and	O
mix	O
up	O
all	O
samples	O
(	O
classes	O
,	O
samples	O
each	O
class	O
)	O
,	O
in	O
order	O
to	O
do	O
the	O
final	O
pre	B-Method
-	O
training	O
.	O
	
Besides	O
,	O
these	O
pre	B-Method
-	O
training	O
samples	O
are	O
augmented	O
with	O
horizontal	O
flip	O
.	O
	
For	O
the	O
meta	B-Task
-	I-Task
train	I-Task
phase	I-Task
,	O
we	O
sample	O
	
5	B-Task
-	I-Task
class	I-Task
,	O
1	B-Material
-	I-Material
shot	I-Material
(	O
5	B-Material
-	I-Material
shot	I-Material
or	O
10	O
-	B-Material
shot	I-Material
)	O
episodes	O
to	O
contain	O
(	O
or	O
)	O
sample	O
(	O
s	O
)	O
for	O
episode	B-Task
training	I-Task
,	O
and	O
samples	O
for	O
episode	O
test	B-Task
uniformly	O
,	O
	
following	O
the	O
setting	O
of	O
MAML	B-Method
.	O
	
The	O
base	B-Method
-	I-Method
learner	I-Method
is	O
optimized	O
by	O
batch	B-Method
gradient	I-Method
descent	I-Method
with	O
the	O
learning	B-Metric
rate	I-Metric
of	O
.	O
	
It	O
gets	O
updated	O
with	O
and	O
epochs	O
respectively	O
for	O
1	B-Material
-	I-Material
shot	I-Material
and	O
5	O
-	B-Material
shot	I-Material
tasks	O
on	O
the	O
miniImageNet	B-Material
dataset	I-Material
,	O
and	O
epochs	O
for	O
all	O
tasks	O
on	O
the	O
FC100	O
dataset	O
.	O
	
The	O
meta	B-Method
-	I-Method
learner	I-Method
,	O
,	O
the	O
parameters	O
of	O
the	O
SS	B-Task
operations	O
,	O
is	O
optimized	O
by	O
Adam	B-Method
optimizer	I-Method
.	O
	
Its	O
learning	B-Metric
rate	I-Metric
is	O
initialized	O
as	O
,	O
and	O
decays	O
to	O
the	O
half	O
every	O
iterations	O
until	O
.	O
	
The	O
size	O
of	O
meta	O
-	O
batch	O
is	O
set	O
to	O
(	O
tasks	O
)	O
due	O
to	O
the	O
memory	O
limit	O
.	O
	
Using	O
our	O
HT	B-Method
meta	I-Method
-	I-Method
batch	I-Method
strategy	I-Method
,	O
hard	O
tasks	O
are	O
sampled	O
every	O
time	O
after	O
running	O
meta	O
-	O
batches	O
,	O
,	O
the	O
failure	O
classes	O
used	O
for	O
sampling	O
hard	O
tasks	O
are	O
from	O
tasks	O
.	O
	
The	O
number	O
of	O
hard	B-Method
task	I-Method
is	O
selected	O
for	O
different	O
settings	O
by	O
validation	B-Task
:	O
and	O
hard	O
tasks	O
respectively	O
for	O
the	O
1	B-Material
-	I-Material
shot	I-Material
and	O
5	B-Material
-	I-Material
shot	I-Material
experiments	O
on	O
the	O
miniImageNet	B-Material
dataset	I-Material
;	O
and	O
respectively	O
,	O
and	O
hard	O
tasks	O
for	O
the	O
1	B-Material
-	I-Material
shot	I-Material
,	O
5	B-Material
-	I-Material
shot	I-Material
and	O
10	O
-	B-Material
shot	I-Material
experiments	O
on	O
the	O
FC100	O
dataset	O
.	O
	
For	O
the	O
meta	O
-	O
test	B-Task
phase	O
,	O
we	O
sample	O
	
5	B-Task
-	I-Task
class	I-Task
,	O
1	B-Material
-	I-Material
shot	I-Material
(	O
5	B-Material
-	I-Material
shot	I-Material
or	O
10	O
-	B-Material
shot	I-Material
)	O
episodes	O
and	O
each	O
episode	O
contains	O
(	O
or	O
)	O
sample	O
(	O
s	O
)	O
for	O
both	O
episode	B-Task
train	I-Task
and	O
episode	O
test	B-Task
.	O
	
On	O
each	O
dataset	O
,	O
we	O
sample	O
meta	O
-	O
test	B-Task
tasks	O
.	O
	
All	O
these	O
settings	O
are	O
exactly	O
the	O
same	O
as	O
MAML	B-Method
.	O
	
section	O
:	O
Super	O
-	O
class	O
splits	O
on	O
FC100	B-Method
	
In	O
this	O
section	O
,	O
we	O
show	O
the	O
details	O
of	O
the	O
FC100	O
splits	O
according	O
to	O
the	O
super	O
-	O
class	O
labels	O
,	O
same	O
with	O
TADAM	O
.	O
	
Training	O
split	O
super	O
-	O
class	O
indexes	O
:	O
1	O
,	O
2	O
,	O
3	O
,	O
4	O
,	O
5	O
,	O
6	O
,	O
9	O
,	O
10	O
,	O
15	O
,	O
17	O
,	O
18	O
,	O
19	O
;	O
and	O
corresponding	O
labels	O
:	O
fish	O
,	O
flowers	O
,	O
food_containers	O
,	O
fruit_and_vegetables	O
,	O
household_electrical_devices	O
,	O
household_furniture	O
,	O
large_man	O
-	O
made_outdoor_things	O
,	O
large_natural_outdoor_scenes	O
,	O
reptiles	O
,	O
trees	O
,	O
vehicles_1	O
,	O
	
vehicles_2	O
.	O
	
Validation	O
split	O
super	O
-	O
class	O
indexes	O
:	O
8	O
,	O
11	O
,	O
13	O
,	O
16	O
;	O
and	O
corresponding	O
labels	O
:	O
large_carnivores	O
,	O
large_omnivores_and_herbivores	O
,	O
non	O
-	O
insect_invertebrates	O
,	O
small_mammals	O
.	O
	
Test	O
split	O
super	O
-	O
class	O
indexes	O
:	O
0	O
,	O
7	O
,	O
12	O
,	O
14	O
;	O
and	O
corresponding	O
labels	O
:	O
	
aquatic_mammals	O
,	O
insects	O
,	O
medium_mammals	O
,	O
people	O
.	O
	
An	O
episode	O
(	O
task	O
)	O
is	O
independently	O
sampled	O
from	O
a	O
corresponding	O
split	O
,	O
a	O
meta	O
-	O
train	O
episode	O
contains	O
classes	O
that	O
can	O
only	O
be	O
belonging	O
to	O
the	O
super	O
-	O
classes	O
in	O
the	O
training	O
split	O
.	O
	
Therefore	O
,	O
there	O
is	O
no	O
fine	O
-	O
grained	O
information	O
overlap	O
between	O
meta	O
-	O
train	O
and	O
meta	O
-	O
test	B-Task
tasks	O
.	O
	
section	O
:	O
Standard	O
variance	B-Method
analysis	I-Method
	
The	O
final	O
accuracy	B-Metric
results	O
reported	O
in	O
our	O
main	O
paper	O
are	O
the	O
mean	O
values	O
and	O
standard	O
variances	O
of	O
the	O
results	O
of	O
meta	O
-	O
test	B-Task
tasks	O
.	O
	
The	O
standard	B-Metric
variance	I-Metric
is	O
affected	O
by	O
the	O
number	O
of	O
episode	O
test	B-Task
samples	O
.	O
	
As	O
introduced	O
in	O
§	O
[	O
reference	O
]	O
,	O
we	O
use	O
the	O
same	O
setting	O
as	O
MAML	B-Method
which	O
used	O
a	O
smaller	O
number	O
of	O
samples	O
for	O
episode	O
test	B-Task
(	O
sample	O
for	O
1	O
-	B-Material
shot	I-Material
episode	O
test	B-Task
and	O
samples	O
for	O
5	B-Material
-	I-Material
shot	I-Material
)	O
,	O
making	O
the	O
result	O
variance	O
higher	O
.	O
	
Other	O
works	O
that	O
used	O
more	O
samples	O
for	O
episode	O
test	B-Task
got	O
lower	O
variances	O
,	O
,	O
TADAM	O
used	O
samples	O
and	O
its	O
variances	O
are	O
about	O
and	O
of	O
MAML	B-Method
’s	I-Method
respectively	O
for	O
miniImageNet	B-Material
1	I-Material
-	I-Material
shot	I-Material
and	O
5	B-Material
-	I-Material
shot	I-Material
.	O
	
In	O
order	O
to	O
have	O
a	O
fair	O
comparison	O
with	O
TADAM	O
in	O
terms	O
of	O
this	O
issue	O
,	O
we	O
supplement	O
the	O
experiments	O
using	O
episode	O
test	B-Task
samples	O
at	O
the	O
meta	O
-	O
test	B-Task
.	O
	
We	O
get	O
the	O
new	O
confidence	O
intervals	O
(	O
using	O
our	O
method	O
:	O
MTL	B-Method
w	O
/	O
o	O
HT	B-Method
meta	I-Method
-	I-Method
batch	I-Method
)	O
as	O
(	O
for	O
TADAM	O
)	O
and	O
(	O
for	O
TADAM	O
)	O
respectively	O
for	O
1	B-Material
-	I-Material
shot	I-Material
and	O
5	B-Material
-	I-Material
shot	I-Material
on	O
the	O
miniImageNet	B-Material
dataset	I-Material
,	O
and	O
(	O
for	O
TADAM	O
)	O
,	O
(	O
for	O
TADAM	O
)	O
and	O
(	O
for	O
TADAM	O
)	O
respectively	O
for	O
1	B-Material
-	I-Material
shot	I-Material
,	O
5	B-Material
-	I-Material
shot	I-Material
and	O
10	O
-	B-Material
shot	I-Material
on	O
the	O
FC100	O
dataset	O
.	O
	
section	O
:	O
Additional	O
ablation	O
study	O
	
We	O
supplement	O
the	O
results	O
in	O
Table	O
[	O
reference	O
]	O
,	O
for	O
the	O
comparisons	O
mentioned	O
in	O
Section	O
5.1	O
of	O
main	O
paper	O
.	O
	
Red	O
numbers	O
on	O
the	O
bottom	O
row	O
are	O
copied	O
from	O
the	O
main	O
paper	O
(	O
corresponding	O
to	O
the	O
MTL	B-Method
setting	O
:	O
SS	B-Task
,	O
meta	O
-	O
batch	O
)	O
and	O
shown	O
here	O
for	O
the	O
convenience	O
of	O
comparison	O
.	O
	
To	O
get	O
the	O
first	O
row	O
,	O
we	O
train	O
4CONV	B-Method
net	O
by	O
large	O
-	O
scale	O
data	O
(	O
same	O
to	O
the	O
pre	B-Method
-	O
training	O
of	O
ResNet	B-Method
-	I-Method
12	I-Method
)	O
and	O
get	O
inferior	O
results	O
,	O
as	O
we	O
declared	O
in	O
the	O
main	O
paper	O
.	O
	
Results	O
on	O
the	O
second	O
and	O
third	O
rows	O
show	O
the	O
performance	O
drop	O
when	O
changing	O
the	O
single	O
FC	O
layer	O
to	O
multiple	O
layers	O
,	O
FC	O
layers	O
and	O
FC	B-Method
layers	I-Method
.	O
	
Results	O
on	O
the	O
fourth	O
row	O
show	O
the	O
performance	O
drop	O
when	O
updating	O
both	O
and	O
for	O
the	O
base	B-Task
-	I-Task
learning	I-Task
.	O
	
The	O
reason	O
is	O
that	O
has	O
too	O
many	O
parameters	O
to	O
update	O
with	O
too	O
little	O
data	O
.	O
	
section	O
:	O
Interpretation	O
of	O
meta	O
-	O
learned	O
SS	B-Task
	
In	O
Figure	O
[	O
reference	O
]	O
,	O
we	O
show	O
the	O
statistic	O
histograms	O
of	O
learned	O
SS	B-Task
parameters	O
,	O
taking	O
miniImageNet	B-Material
1	I-Material
-	I-Material
shot	I-Material
as	O
an	O
example	O
setting	O
.	O
	
Scaling	O
parameters	O
are	O
initialized	O
as	O
1	O
and	O
shifting	O
parameters	O
as	O
0	O
.	O
	
After	O
meta	B-Task
-	I-Task
train	I-Task
,	O
we	O
observe	O
that	O
these	O
statistics	O
are	O
close	O
to	O
Gaussian	O
distributions	O
respectively	O
with	O
(	O
,	O
)	O
and	O
(	O
,	O
)	O
as	O
(	O
mean	O
,	O
variance	O
)	O
values	O
,	O
which	O
shows	O
that	O
the	O
uniform	B-Method
initialization	I-Method
has	O
been	O
changed	O
to	O
Gaussian	B-Method
distribution	I-Method
through	O
few	O
-	B-Material
shot	I-Material
learning	O
.	O
	
Possible	O
interpretations	O
are	O
in	O
three	O
-	O
fold	O
:	O
1	O
)	O
majority	O
patterns	O
trained	O
by	O
a	O
large	O
number	O
of	O
few	O
-	B-Material
shot	I-Material
tasks	O
are	O
close	O
to	O
the	O
ones	O
trained	O
by	O
large	O
-	O
scale	O
data	O
;	O
2	O
)	O
tail	O
patterns	O
with	O
clear	O
scale	O
and	O
shift	O
values	O
are	O
the	O
ones	O
really	O
contributing	O
to	O
adapting	O
the	O
model	O
to	O
few	O
-	B-Material
shot	I-Material
tasks	O
;	O
3	O
)	O
tail	O
patterns	O
are	O
of	O
small	O
quantity	O
,	O
enabling	O
the	O
fast	O
learning	B-Task
convergence	I-Task
.	O
	
document	O
:	O
A	O
Character	B-Method
-	I-Method
Level	I-Method
Decoder	I-Method
without	O
Explicit	B-Method
Segmentation	I-Method
for	O
Neural	B-Task
Machine	I-Task
Translation	I-Task
	
The	O
existing	O
machine	B-Task
translation	I-Task
systems	O
,	O
whether	O
phrase	B-Method
-	I-Method
based	I-Method
or	I-Method
neural	I-Method
,	O
have	O
relied	O
almost	O
exclusively	O
on	O
word	B-Method
-	I-Method
level	I-Method
modelling	I-Method
with	O
explicit	B-Method
segmentation	I-Method
.	O
	
In	O
this	O
paper	O
,	O
we	O
ask	O
a	O
fundamental	O
question	O
:	O
can	O
neural	O
machine	B-Task
translation	I-Task
generate	O
a	O
character	O
sequence	O
without	O
any	O
explicit	B-Method
segmentation	I-Method
?	O
	
To	O
answer	O
this	O
question	O
,	O
we	O
evaluate	O
an	O
attention	B-Method
-	I-Method
based	I-Method
encoder	I-Method
–	I-Method
decoder	I-Method
with	O
a	O
subword	B-Method
-	I-Method
level	I-Method
encoder	O
and	O
a	O
character	B-Method
-	I-Method
level	I-Method
decoder	I-Method
on	O
four	O
language	O
pairs	O
	
–	O
	
En	O
-	O
Cs	O
,	O
En	O
-	O
De	O
,	O
En	O
-	O
Ru	O
and	O
En	O
-	O
Fi–	O
	
using	O
the	O
parallel	O
corpora	O
from	O
WMT’15	B-Material
.	O
	
Our	O
experiments	O
show	O
that	O
the	O
models	O
with	O
a	O
character	B-Method
-	I-Method
level	I-Method
decoder	I-Method
outperform	O
the	O
ones	O
with	O
a	O
subword	B-Method
-	I-Method
level	I-Method
decoder	O
on	O
all	O
of	O
the	O
four	O
language	O
pairs	O
.	O
	
Furthermore	O
,	O
the	O
ensembles	B-Method
of	I-Method
neural	I-Method
models	I-Method
with	O
a	O
character	B-Method
-	I-Method
level	I-Method
decoder	I-Method
outperform	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
non	O
-	O
neural	O
machine	B-Task
translation	I-Task
systems	O
on	O
En	O
-	O
Cs	O
,	O
En	O
-	O
De	O
and	O
En	O
-	O
Fi	O
and	O
perform	O
comparably	O
on	O
En	O
-	O
Ru	O
.	O
	
section	O
:	O
Introduction	O
	
The	O
existing	O
machine	B-Task
translation	I-Task
systems	O
have	O
relied	O
almost	O
exclusively	O
on	O
word	B-Method
-	I-Method
level	I-Method
modelling	I-Method
with	O
explicit	B-Method
segmentation	I-Method
.	O
	
This	O
is	O
mainly	O
due	O
to	O
the	O
issue	O
of	O
data	B-Task
sparsity	I-Task
which	O
becomes	O
much	O
more	O
severe	O
,	O
especially	O
for	O
-	O
grams	O
,	O
when	O
a	O
sentence	O
is	O
represented	O
as	O
a	O
sequence	O
of	O
characters	O
rather	O
than	O
words	O
,	O
as	O
the	O
length	O
of	O
the	O
sequence	O
grows	O
significantly	O
.	O
	
In	O
addition	O
to	O
data	O
sparsity	O
,	O
we	O
often	O
have	O
a	O
priori	O
belief	O
that	O
a	O
word	O
,	O
or	O
its	O
segmented	O
-	O
out	O
lexeme	O
,	O
is	O
a	O
basic	O
unit	O
of	O
meaning	O
,	O
making	O
it	O
natural	O
to	O
approach	O
translation	B-Task
as	O
mapping	B-Task
from	O
a	O
sequence	O
of	O
source	O
-	O
language	O
words	O
to	O
a	O
sequence	O
of	O
target	O
-	O
language	O
words	O
.	O
	
This	O
has	O
continued	O
with	O
the	O
more	O
recently	O
proposed	O
paradigm	O
of	O
neural	O
machine	B-Task
translation	I-Task
,	O
although	O
neural	B-Method
networks	I-Method
do	O
not	O
suffer	O
from	O
character	B-Method
-	I-Method
level	I-Method
modelling	I-Method
and	O
rather	O
suffer	O
from	O
the	O
issues	O
specific	O
to	O
word	B-Method
-	I-Method
level	I-Method
modelling	I-Method
,	O
such	O
as	O
the	O
increased	O
computational	B-Metric
complexity	I-Metric
from	O
a	O
very	O
large	O
target	O
vocabulary	O
.	O
	
Therefore	O
,	O
in	O
this	O
paper	O
,	O
we	O
address	O
a	O
question	O
of	O
whether	O
neural	O
machine	B-Task
translation	I-Task
can	O
be	O
done	O
directly	O
on	O
a	O
sequence	O
of	O
characters	O
without	O
any	O
explicit	O
word	B-Method
segmentation	I-Method
.	O
	
To	O
answer	O
this	O
question	O
,	O
we	O
focus	O
on	O
representing	O
the	O
target	O
side	O
as	O
a	O
character	O
sequence	O
.	O
	
We	O
evaluate	O
neural	O
machine	B-Task
translation	I-Task
models	O
with	O
a	O
character	B-Method
-	I-Method
level	I-Method
decoder	I-Method
on	O
four	O
language	O
pairs	O
from	O
WMT’15	B-Material
to	O
make	O
our	O
evaluation	O
as	O
convincing	O
as	O
possible	O
.	O
	
We	O
represent	O
the	O
source	O
side	O
as	O
a	O
sequence	O
of	O
subwords	O
extracted	O
using	O
byte	B-Method
-	I-Method
pair	I-Method
encoding	I-Method
from	O
sennrich2015neural	O
,	O
and	O
vary	O
the	O
target	O
side	O
to	O
be	O
either	O
a	O
sequence	O
of	O
subwords	O
or	O
characters	O
.	O
	
On	O
the	O
target	O
side	O
,	O
we	O
further	O
design	O
a	O
novel	O
recurrent	B-Method
neural	I-Method
network	I-Method
(	I-Method
RNN	I-Method
)	I-Method
,	O
called	O
bi	B-Method
-	I-Method
scale	I-Method
recurrent	O
network	O
,	O
that	O
better	O
handles	O
multiple	O
timescales	O
in	O
a	O
sequence	O
,	O
and	O
test	O
it	O
in	O
addition	O
to	O
a	O
naive	B-Method
,	I-Method
stacked	I-Method
recurrent	I-Method
neural	I-Method
network	I-Method
.	O
	
On	O
all	O
of	O
the	O
four	O
language	O
pairs	O
–	O
	
En	O
-	O
Cs	O
,	O
En	O
-	O
De	O
,	O
En	O
-	O
Ru	O
and	O
En	O
-	O
Fi–	O
,	O
the	O
models	O
with	O
a	O
character	B-Method
-	I-Method
level	I-Method
decoder	I-Method
outperformed	O
the	O
ones	O
with	O
a	O
subword	B-Method
-	I-Method
level	I-Method
decoder	O
.	O
	
We	O
observed	O
a	O
similar	O
trend	O
with	O
the	O
ensemble	O
of	O
each	O
of	O
these	O
configurations	O
,	O
outperforming	O
both	O
the	O
previous	O
best	O
neural	O
and	O
non	O
-	O
neural	O
translation	B-Task
systems	O
on	O
En	O
-	O
Cs	O
,	O
En	O
-	O
De	O
and	O
En	O
-	O
Fi	O
,	O
while	O
achieving	O
a	O
comparable	O
result	O
on	O
En	O
-	O
Ru	O
.	O
	
We	O
find	O
these	O
results	O
to	O
be	O
a	O
strong	O
evidence	O
that	O
neural	O
machine	B-Task
translation	I-Task
can	O
indeed	O
learn	O
to	O
translate	O
at	O
the	O
character	O
-	O
level	O
and	O
that	O
in	O
fact	O
,	O
it	O
benefits	O
from	O
doing	O
so	O
.	O
	
section	O
:	O
Neural	B-Task
Machine	I-Task
Translation	I-Task
	
Neural	O
machine	B-Task
translation	I-Task
refers	O
to	O
a	O
recently	O
proposed	O
approach	O
to	O
machine	B-Task
translation	I-Task
.	O
	
This	O
approach	O
aims	O
at	O
building	O
an	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
neural	I-Method
network	I-Method
that	O
takes	O
as	O
input	O
a	O
source	O
sentence	O
and	O
outputs	O
its	O
translation	B-Task
,	O
where	O
and	O
are	O
respectively	O
source	O
and	O
target	O
symbols	O
.	O
	
This	O
neural	B-Method
network	I-Method
is	O
constructed	O
as	O
a	O
composite	O
of	O
an	O
encoder	B-Method
network	I-Method
and	O
a	O
decoder	B-Method
network	I-Method
.	O
	
The	O
encoder	B-Method
network	I-Method
encodes	O
the	O
input	O
sentence	O
into	O
its	O
continuous	B-Method
representation	I-Method
.	O
	
In	O
this	O
paper	O
,	O
we	O
closely	O
follow	O
the	O
neural	O
translation	B-Task
model	O
proposed	O
in	O
bahdanau2014neural	O
and	O
use	O
a	O
bidirectional	B-Method
recurrent	I-Method
neural	I-Method
network	I-Method
,	O
which	O
consists	O
of	O
two	O
recurrent	B-Method
neural	I-Method
networks	I-Method
.	O
	
The	O
forward	B-Method
network	I-Method
reads	O
the	O
input	O
sentence	O
in	O
a	O
forward	O
direction	O
:	O
where	O
is	O
a	O
continuous	O
embedding	O
of	O
the	O
-	O
th	O
input	O
symbol	O
,	O
and	O
is	O
a	O
recurrent	O
activation	O
function	O
.	O
	
Similarly	O
,	O
the	O
reverse	B-Method
network	I-Method
reads	O
the	O
sentence	O
in	O
a	O
reverse	O
direction	O
(	O
right	O
to	O
left	O
)	O
:	O
At	O
each	O
location	O
in	O
the	O
input	O
sentence	O
,	O
we	O
concatenate	O
the	O
hidden	O
states	O
from	O
the	O
forward	B-Method
and	I-Method
reverse	I-Method
RNNs	I-Method
to	O
form	O
a	O
context	O
set	O
where	O
.	O
	
Then	O
the	O
decoder	B-Method
computes	O
the	O
conditional	O
distribution	O
over	O
all	O
possible	O
translations	O
based	O
on	O
this	O
context	O
set	O
.	O
	
This	O
is	O
done	O
by	O
first	O
rewriting	O
the	O
conditional	O
probability	O
of	O
a	O
translation	B-Task
:	O
For	O
each	O
conditional	O
term	O
in	O
the	O
summation	O
,	O
the	O
decoder	B-Method
RNN	I-Method
updates	O
its	O
hidden	O
state	O
by	O
where	O
is	O
the	O
continuous	O
embedding	O
of	O
a	O
target	O
symbol	O
.	O
	
is	O
a	O
context	O
vector	O
computed	O
by	O
a	O
soft	B-Method
-	I-Method
alignment	I-Method
mechanism	I-Method
:	O
The	O
soft	B-Method
-	I-Method
alignment	I-Method
mechanism	I-Method
weights	O
each	O
vector	O
in	O
the	O
context	O
set	O
according	O
to	O
its	O
relevance	O
given	O
what	O
has	O
been	O
translated	O
.	O
	
The	O
weight	O
of	O
each	O
vector	O
is	O
computed	O
by	O
where	O
is	O
a	O
parametric	B-Method
function	I-Method
returning	O
an	O
unnormalized	O
score	O
for	O
given	O
and	O
.	O
	
We	O
use	O
a	O
feedforward	B-Method
network	I-Method
with	O
a	O
single	O
hidden	O
layer	O
in	O
this	O
paper	O
.	O
	
is	O
a	O
normalization	O
constant	O
:	O
This	O
procedure	O
can	O
be	O
understood	O
as	O
computing	O
the	O
alignment	O
probability	O
between	O
the	O
-	O
th	O
target	O
symbol	O
and	O
-	O
th	O
source	O
symbol	O
.	O
	
The	O
hidden	O
state	O
,	O
together	O
with	O
the	O
previous	O
target	O
symbol	O
and	O
the	O
context	O
vector	O
,	O
is	O
fed	O
into	O
a	O
feedforward	B-Method
neural	I-Method
network	I-Method
to	O
result	O
in	O
the	O
conditional	O
distribution	O
:	O
	
The	O
whole	O
model	O
,	O
consisting	O
of	O
the	O
encoder	B-Method
,	I-Method
decoder	I-Method
and	O
soft	B-Method
-	I-Method
alignment	I-Method
mechanism	I-Method
,	O
is	O
then	O
tuned	O
end	O
-	O
to	O
-	O
end	O
to	O
minimize	O
the	O
negative	O
log	O
-	O
likelihood	O
using	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
.	O
	
section	O
:	O
Towards	O
Character	B-Task
-	I-Task
Level	I-Task
Translation	I-Task
	
subsection	O
:	O
Motivation	O
	
Let	O
us	O
revisit	O
how	O
the	O
source	O
and	O
target	O
sentences	O
(	O
and	O
)	O
are	O
represented	O
in	O
neural	O
machine	B-Task
translation	I-Task
.	O
	
For	O
the	O
source	O
side	O
of	O
any	O
given	O
training	O
corpus	O
,	O
we	O
scan	O
through	O
the	O
whole	O
corpus	O
to	O
build	O
a	O
vocabulary	O
of	O
unique	O
tokens	O
to	O
which	O
we	O
assign	O
integer	O
indices	O
.	O
	
A	O
source	O
sentence	O
is	O
then	O
built	O
as	O
a	O
sequence	O
of	O
the	O
indices	O
of	O
such	O
tokens	O
belonging	O
to	O
the	O
sentence	O
,	O
i.e.	O
,	O
,	O
where	O
.	O
	
The	O
target	O
sentence	O
is	O
similarly	O
transformed	O
into	O
a	O
target	O
sequence	O
of	O
integer	O
indices	O
.	O
	
Each	O
token	O
,	O
or	O
its	O
index	O
,	O
is	O
then	O
transformed	O
into	O
a	O
so	O
-	O
called	O
one	O
-	O
hot	O
vector	O
of	O
dimensionality	O
.	O
	
All	O
but	O
one	O
elements	O
of	O
this	O
vector	O
are	O
set	O
to	O
0	O
.	O
	
The	O
only	O
element	O
whose	O
index	O
corresponds	O
to	O
the	O
token	O
’s	O
index	O
is	O
set	O
to	O
1	O
.	O
	
This	O
one	O
-	O
hot	O
vector	O
is	O
the	O
one	O
which	O
any	O
neural	O
machine	B-Task
translation	I-Task
model	O
sees	O
.	O
	
The	O
embedding	O
function	O
,	O
or	O
,	O
is	O
simply	O
the	O
result	O
of	O
applying	O
a	O
linear	B-Method
transformation	I-Method
(	O
the	O
embedding	O
matrix	O
)	O
to	O
this	O
one	O
-	O
hot	O
vector	O
.	O
	
The	O
important	O
property	O
of	O
this	O
approach	O
based	O
on	O
one	B-Method
-	I-Method
hot	I-Method
vectors	I-Method
is	O
that	O
the	O
neural	B-Method
network	I-Method
is	O
oblivious	O
to	O
the	O
underlying	O
semantics	O
of	O
the	O
tokens	O
.	O
	
To	O
the	O
neural	B-Method
network	I-Method
,	O
each	O
and	O
every	O
token	O
in	O
the	O
vocabulary	O
is	O
equal	O
distance	O
away	O
from	O
every	O
other	O
token	O
.	O
	
The	O
semantics	O
of	O
those	O
tokens	O
are	O
simply	O
learned	O
(	O
into	O
the	O
embeddings	O
)	O
to	O
maximize	O
the	O
translation	B-Task
quality	O
,	O
or	O
the	O
log	O
-	O
likelihood	O
of	O
the	O
model	O
.	O
	
This	O
property	O
allows	O
us	O
great	O
freedom	O
in	O
the	O
choice	O
of	O
tokens	O
’	O
unit	O
.	O
	
Neural	B-Method
networks	I-Method
have	O
been	O
shown	O
to	O
work	O
well	O
with	O
word	O
tokens	O
but	O
also	O
with	O
finer	O
units	O
,	O
such	O
as	O
subwords	O
as	O
well	O
as	O
symbols	O
resulting	O
from	O
compression	B-Method
/	I-Method
encoding	I-Method
.	O
	
Although	O
there	O
have	O
been	O
a	O
number	O
of	O
previous	O
research	O
reporting	O
the	O
use	O
of	O
neural	B-Method
networks	I-Method
with	O
characters	O
(	O
see	O
,	O
e.g.	O
,	O
mikolov2012subword	O
and	O
santos2014learning	O
)	O
,	O
the	O
dominant	O
approach	O
has	O
been	O
to	O
preprocess	O
the	O
text	O
into	O
a	O
sequence	O
of	O
symbols	O
,	O
each	O
associated	O
with	O
a	O
sequence	O
of	O
characters	O
,	O
after	O
which	O
the	O
neural	B-Method
network	I-Method
is	O
presented	O
with	O
those	O
symbols	O
rather	O
than	O
with	O
characters	O
.	O
	
More	O
recently	O
in	O
the	O
context	O
of	O
neural	O
machine	B-Task
translation	I-Task
,	O
two	O
research	O
groups	O
have	O
proposed	O
to	O
directly	O
use	O
characters	O
.	O
	
kim2015character	O
proposed	O
to	O
represent	O
each	O
word	O
not	O
as	O
a	O
single	O
integer	O
index	O
as	O
before	O
,	O
but	O
as	O
a	O
sequence	O
of	O
characters	O
,	O
and	O
use	O
a	O
convolutional	B-Method
network	I-Method
followed	O
by	O
a	O
highway	B-Method
network	I-Method
to	O
extract	O
a	O
continuous	B-Method
representation	I-Method
of	O
the	O
word	O
.	O
	
This	O
approach	O
,	O
which	O
effectively	O
replaces	O
the	O
embedding	O
function	O
,	O
was	O
adopted	O
by	O
costa2016character	O
for	O
neural	O
machine	B-Task
translation	I-Task
.	O
	
Similarly	O
,	O
ling2015character	O
use	O
a	O
bidirectional	B-Method
recurrent	I-Method
neural	I-Method
network	I-Method
to	O
replace	O
the	O
embedding	O
functions	O
and	O
to	O
respectively	O
encode	O
a	O
character	O
sequence	O
to	O
and	O
from	O
the	O
corresponding	O
continuous	B-Method
word	I-Method
representation	I-Method
.	O
	
A	O
similar	O
,	O
but	O
slightly	O
different	O
approach	O
was	O
proposed	O
by	O
lee2015naver	O
,	O
where	O
they	O
explicitly	O
mark	O
each	O
character	O
with	O
its	O
relative	O
location	O
in	O
a	O
word	O
(	O
e.g.	O
,	O
“	O
B”eginning	O
and	O
“	O
I”ntermediate	O
)	O
.	O
	
Despite	O
the	O
fact	O
that	O
these	O
recent	O
approaches	O
work	O
at	O
the	O
level	O
of	O
characters	O
,	O
it	O
is	O
less	O
satisfying	O
that	O
they	O
all	O
rely	O
on	O
knowing	O
how	O
to	O
segment	O
characters	O
into	O
words	O
.	O
	
Although	O
it	O
is	O
generally	O
easy	O
for	O
languages	O
like	O
English	O
,	O
this	O
is	O
not	O
always	O
the	O
case	O
.	O
	
This	O
word	B-Method
segmentation	I-Method
procedure	I-Method
can	O
be	O
as	O
simple	O
as	O
tokenization	B-Task
followed	O
by	O
some	O
punctuation	B-Method
normalization	I-Method
,	O
but	O
also	O
can	O
be	O
as	O
complicated	O
as	O
morpheme	B-Task
segmentation	I-Task
requiring	O
a	O
separate	O
model	O
to	O
be	O
trained	O
in	O
advance	O
.	O
	
Furthermore	O
,	O
these	O
segmentation	B-Method
steps	I-Method
are	O
often	O
tuned	O
or	O
designed	O
separately	O
from	O
the	O
ultimate	O
objective	O
of	O
translation	B-Task
quality	O
,	O
potentially	O
contributing	O
to	O
a	O
suboptimal	B-Metric
quality	I-Metric
.	O
	
Based	O
on	O
this	O
observation	O
and	O
analysis	O
,	O
in	O
this	O
paper	O
,	O
we	O
ask	O
ourselves	O
and	O
the	O
readers	O
a	O
question	O
which	O
should	O
have	O
been	O
asked	O
much	O
earlier	O
:	O
Is	O
it	O
possible	O
to	O
do	O
character	O
-	O
level	O
translation	B-Task
without	O
any	O
explicit	B-Method
segmentation	I-Method
?	O
	
subsection	O
:	O
Why	O
Word	B-Task
-	I-Task
Level	I-Task
Translation	I-Task
?	O
	
paragraph	O
:	O
(	O
1	O
)	O
Word	O
as	O
a	O
Basic	O
Unit	O
of	O
Meaning	O
	
A	O
word	O
can	O
be	O
understood	O
in	O
two	O
different	O
senses	O
.	O
	
In	O
the	O
abstract	O
sense	O
,	O
a	O
word	O
is	O
a	O
basic	O
unit	O
of	O
meaning	O
(	O
lexeme	O
)	O
,	O
and	O
in	O
the	O
other	O
sense	O
,	O
can	O
be	O
understood	O
as	O
a	O
“	O
concrete	O
word	O
as	O
used	O
in	O
a	O
sentence	O
.	O
	
”	O
.	O
	
A	O
word	O
in	O
the	O
former	O
sense	O
turns	O
into	O
that	O
in	O
the	O
latter	O
sense	O
via	O
a	O
process	O
of	O
morphology	O
,	O
including	O
inflection	O
,	O
compounding	B-Task
and	O
derivation	B-Task
.	O
	
These	O
three	O
processes	O
do	O
alter	O
the	O
meaning	O
of	O
the	O
lexeme	O
,	O
but	O
often	O
it	O
stays	O
close	O
to	O
the	O
original	O
meaning	O
.	O
	
Because	O
of	O
this	O
view	O
of	O
words	O
as	O
basic	O
units	O
of	O
meaning	O
(	O
either	O
in	O
the	O
form	O
of	O
lexemes	O
or	O
derived	O
form	O
)	O
from	O
linguistics	B-Method
,	O
much	O
of	O
previous	O
work	O
in	O
natural	B-Task
language	I-Task
processing	I-Task
has	O
focused	O
on	O
using	O
words	O
as	O
basic	O
units	O
of	O
which	O
a	O
sentence	O
is	O
encoded	O
as	O
a	O
sequence	O
.	O
	
Also	O
,	O
the	O
potential	O
difficulty	O
in	O
finding	O
a	O
mapping	O
between	O
a	O
word	O
’s	O
character	O
sequence	O
and	O
meaning	O
has	O
likely	O
contributed	O
to	O
this	O
trend	O
toward	O
word	B-Method
-	I-Method
level	I-Method
modelling	I-Method
.	O
	
paragraph	O
:	O
(	O
2	O
)	O
Data	O
Sparsity	O
	
There	O
is	O
a	O
further	O
technical	O
reason	O
why	O
much	O
of	O
previous	O
research	O
on	O
machine	B-Task
translation	I-Task
has	O
considered	O
words	O
as	O
a	O
basic	O
unit	O
.	O
	
This	O
is	O
mainly	O
due	O
to	O
the	O
fact	O
that	O
major	O
components	O
in	O
the	O
existing	O
translation	B-Task
systems	O
,	O
such	O
as	O
language	B-Method
models	I-Method
and	O
phrase	B-Method
tables	I-Method
,	O
are	O
a	O
count	B-Method
-	I-Method
based	I-Method
estimator	I-Method
of	I-Method
probabilities	I-Method
.	O
	
In	O
other	O
words	O
,	O
a	O
probability	O
of	O
a	O
subsequence	O
of	O
symbols	O
,	O
or	O
pairs	O
of	O
symbols	O
,	O
is	O
estimated	O
by	O
counting	O
the	O
number	O
of	O
its	O
occurrences	O
in	O
a	O
training	O
corpus	O
.	O
	
This	O
approach	O
severely	O
suffers	O
from	O
the	O
issue	O
of	O
data	O
sparsity	O
,	O
which	O
is	O
due	O
to	O
a	O
large	O
state	O
space	O
which	O
grows	O
exponentially	O
w.r.t	O
.	O
	
the	O
length	O
of	O
subsequences	O
while	O
growing	O
only	O
linearly	O
w.r.t	O
.	O
	
the	O
corpus	O
size	O
.	O
	
This	O
poses	O
a	O
great	O
challenge	O
to	O
character	B-Method
-	I-Method
level	I-Method
modelling	I-Method
,	O
as	O
any	O
subsequence	O
will	O
be	O
on	O
average	O
4–5	O
times	O
longer	O
when	O
characters	O
,	O
instead	O
of	O
words	O
,	O
are	O
used	O
.	O
	
Indeed	O
,	O
vilar2007can	O
reported	O
worse	O
performance	O
when	O
the	O
character	O
sequence	O
was	O
directly	O
used	O
by	O
a	O
phrase	O
-	O
based	O
machine	B-Task
translation	I-Task
system	O
.	O
	
More	O
recently	O
,	O
neubig2013substring	O
proposed	O
a	O
method	O
to	O
improve	O
character	O
-	O
level	O
translation	B-Task
with	O
phrase	O
-	O
based	O
translation	B-Task
systems	O
,	O
however	O
,	O
with	O
only	O
a	O
limited	O
success	O
.	O
	
paragraph	O
:	O
(	O
3	O
)	O
Vanishing	O
Gradient	O
	
Specifically	O
to	O
neural	O
machine	B-Task
translation	I-Task
,	O
a	O
major	O
reason	O
behind	O
the	O
wide	O
adoption	O
of	O
word	B-Method
-	I-Method
level	I-Method
modelling	I-Method
is	O
due	O
to	O
the	O
difficulty	O
in	O
modelling	B-Task
long	I-Task
-	I-Task
term	I-Task
dependencies	I-Task
with	O
recurrent	B-Method
neural	I-Method
networks	I-Method
.	O
	
As	O
the	O
lengths	O
of	O
the	O
sentences	O
on	O
both	O
sides	O
grow	O
when	O
they	O
are	O
represented	O
in	O
characters	O
,	O
it	O
is	O
easy	O
to	O
believe	O
that	O
there	O
will	O
be	O
more	O
long	O
-	O
term	O
dependencies	O
that	O
must	O
be	O
captured	O
by	O
the	O
recurrent	B-Method
neural	I-Method
network	I-Method
for	O
successful	O
translation	B-Task
.	O
	
subsection	O
:	O
Why	O
Character	B-Task
-	I-Task
Level	I-Task
Translation	I-Task
?	O
	
paragraph	O
:	O
Why	O
not	O
Word	B-Task
-	I-Task
Level	I-Task
Translation	I-Task
?	O
	
The	O
most	O
pressing	O
issue	O
with	O
word	B-Task
-	I-Task
level	I-Task
processing	I-Task
is	O
that	O
we	O
do	O
not	O
have	O
a	O
perfect	O
word	B-Method
segmentation	I-Method
algorithm	I-Method
for	O
any	O
one	O
language	O
.	O
	
A	O
perfect	O
segmentation	B-Method
algorithm	I-Method
needs	O
to	O
be	O
able	O
to	O
segment	O
any	O
given	O
sentence	O
into	O
a	O
sequence	O
of	O
lexemes	O
and	O
morphemes	O
.	O
	
This	O
problem	O
is	O
however	O
a	O
difficult	O
problem	O
on	O
its	O
own	O
and	O
often	O
requires	O
decades	O
of	O
research	O
(	O
see	O
,	O
e.g.	O
,	O
creutz2005unsupervised	O
for	O
Finnish	O
and	O
other	O
morphologically	O
rich	O
languages	O
and	O
huang2007chinese	O
for	O
Chinese	O
)	O
.	O
	
Therefore	O
,	O
many	O
opt	O
to	O
using	O
either	O
a	O
rule	B-Method
-	I-Method
based	I-Method
tokenization	I-Method
approach	I-Method
or	O
a	O
suboptimal	O
,	O
but	O
still	O
available	O
,	O
learning	B-Method
based	I-Method
segmentation	I-Method
algorithm	I-Method
.	O
	
The	O
outcome	O
of	O
this	O
naive	O
,	O
sub	B-Task
-	I-Task
optimal	I-Task
segmentation	I-Task
is	O
that	O
the	O
vocabulary	O
is	O
often	O
filled	O
with	O
many	O
similar	O
words	O
that	O
share	O
a	O
lexeme	O
but	O
have	O
different	O
morphology	O
.	O
	
For	O
instance	O
,	O
if	O
we	O
apply	O
a	O
simple	O
tokenization	B-Method
script	I-Method
to	O
an	O
English	O
corpus	O
,	O
“	O
run	O
”	O
,	O
“	O
runs	O
”	O
,	O
“	O
ran	O
”	O
and	O
“	O
running	O
”	O
are	O
all	O
separate	O
entries	O
in	O
the	O
vocabulary	O
,	O
while	O
they	O
clearly	O
share	O
the	O
same	O
lexeme	O
	
“	O
run	O
”	O
.	O
	
This	O
prevents	O
any	O
machine	B-Task
translation	I-Task
system	O
,	O
in	O
particular	O
neural	O
machine	B-Task
translation	I-Task
,	O
from	O
modelling	O
these	O
morphological	O
variants	O
efficiently	O
.	O
	
More	O
specifically	O
in	O
the	O
case	O
of	O
neural	O
machine	B-Task
translation	I-Task
,	O
each	O
of	O
these	O
morphological	O
variants–“run	O
”	O
,	O
“	O
runs	O
”	O
,	O
	
“	O
ran	O
”	O
and	O
“	O
running”–	O
will	O
be	O
assigned	O
a	O
-	O
dimensional	O
word	O
vector	O
,	O
leading	O
to	O
four	O
independent	O
vectors	O
,	O
while	O
it	O
is	O
clear	O
that	O
if	O
we	O
can	O
segment	O
those	O
variants	O
into	O
a	O
lexeme	O
and	O
other	O
morphemes	O
,	O
we	O
can	O
model	O
them	O
more	O
efficiently	O
.	O
	
For	O
instance	O
,	O
we	O
can	O
have	O
a	O
-	O
dimensional	O
vector	O
for	O
the	O
lexeme	O
“	O
run	O
”	O
and	O
much	O
smaller	O
vectors	O
for	O
“	O
s	O
	
”	O
and“ing	O
”	O
.	O
	
Each	O
of	O
those	O
variants	O
will	O
be	O
then	O
a	O
composite	O
of	O
the	O
lexeme	O
vector	O
(	O
shared	O
across	O
these	O
variants	O
)	O
and	O
morpheme	O
vectors	O
(	O
shared	O
across	O
words	O
sharing	O
the	O
same	O
suffix	O
,	O
for	O
example	O
)	O
.	O
	
This	O
makes	O
use	O
of	O
distributed	B-Method
representation	I-Method
,	O
which	O
generally	O
yields	O
better	O
generalization	B-Task
,	O
but	O
seems	O
to	O
require	O
an	O
optimal	O
segmentation	O
,	O
which	O
is	O
unfortunately	O
almost	O
never	O
available	O
.	O
	
In	O
addition	O
to	O
inefficiency	O
in	O
modelling	B-Task
,	O
there	O
are	O
two	O
additional	O
negative	O
consequences	O
from	O
using	O
(	O
unsegmented	O
)	O
words	O
.	O
	
First	O
,	O
the	O
translation	B-Task
system	O
can	O
not	O
generalize	O
well	O
to	O
novel	O
words	O
,	O
which	O
are	O
often	O
mapped	O
to	O
a	O
token	O
reserved	O
for	O
an	O
unknown	O
word	O
.	O
	
This	O
effectively	O
ignores	O
any	O
meaning	O
or	O
structure	O
of	O
the	O
word	O
to	O
be	O
incorporated	O
when	O
translating	B-Task
.	O
	
Second	O
,	O
even	O
when	O
a	O
lexeme	O
is	O
common	O
and	O
frequently	O
observed	O
in	O
the	O
training	O
corpus	O
,	O
its	O
morphological	O
variant	O
may	O
not	O
be	O
.	O
	
This	O
implies	O
that	O
the	O
model	O
sees	O
this	O
specific	O
,	O
rare	O
morphological	O
variant	O
much	O
less	O
and	O
will	O
not	O
be	O
able	O
to	O
translate	O
it	O
well	O
.	O
	
However	O
,	O
if	O
this	O
rare	O
morphological	B-Method
variant	I-Method
shares	O
a	O
large	O
part	O
of	O
its	O
spelling	O
with	O
other	O
more	O
common	O
words	O
,	O
it	O
is	O
desirable	O
for	O
a	O
machine	B-Task
translation	I-Task
system	O
to	O
exploit	O
those	O
common	O
words	O
when	O
translating	O
those	O
rare	O
variants	O
.	O
	
paragraph	O
:	O
Why	O
Character	B-Task
-	I-Task
Level	I-Task
Translation	I-Task
?	O
	
All	O
of	O
these	O
issues	O
can	O
be	O
addressed	O
to	O
certain	O
extent	O
by	O
directly	O
modelling	O
characters	O
.	O
	
Although	O
the	O
issue	O
of	O
data	B-Task
sparsity	I-Task
arises	O
in	O
character	O
-	O
level	O
translation	B-Task
,	O
it	O
is	O
elegantly	O
addressed	O
by	O
using	O
a	O
parametric	B-Method
approach	I-Method
based	O
on	O
recurrent	B-Method
neural	I-Method
networks	I-Method
instead	O
of	O
a	O
non	B-Method
-	I-Method
parametric	I-Method
count	I-Method
-	I-Method
based	I-Method
approach	I-Method
.	O
	
Furthermore	O
,	O
in	O
recent	O
years	O
,	O
we	O
have	O
learned	O
how	O
to	O
build	O
and	O
train	O
a	O
recurrent	B-Method
neural	I-Method
network	I-Method
that	O
can	O
well	O
capture	O
long	O
-	O
term	O
dependencies	O
by	O
using	O
more	O
sophisticated	O
activation	O
functions	O
,	O
such	O
as	O
long	B-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
(	I-Method
LSTM	I-Method
)	I-Method
units	I-Method
and	O
gated	B-Method
recurrent	I-Method
units	I-Method
.	O
	
kim2015character	O
and	O
ling2015finding	O
recently	O
showed	O
that	O
by	O
having	O
a	O
neural	B-Method
network	I-Method
that	O
converts	O
a	O
character	O
sequence	O
into	O
a	O
word	O
vector	O
,	O
we	O
avoid	O
the	O
issues	O
from	O
having	O
many	O
morphological	O
variants	O
appearing	O
as	O
separate	O
entities	O
in	O
a	O
vocabulary	O
.	O
	
This	O
is	O
made	O
possible	O
by	O
sharing	O
the	O
character	B-Method
-	I-Method
to	I-Method
-	I-Method
word	I-Method
neural	I-Method
network	I-Method
across	O
all	O
the	O
unique	O
tokens	O
.	O
	
A	O
similar	O
approach	O
was	O
applied	O
to	O
machine	B-Task
translation	I-Task
by	O
ling2015character	O
.	O
	
These	O
recent	O
approaches	O
,	O
however	O
,	O
still	O
rely	O
on	O
the	O
availability	O
of	O
a	O
good	O
,	O
if	O
not	O
optimal	O
,	O
segmentation	B-Method
algorithm	I-Method
.	O
	
ling2015character	O
indeed	O
states	O
that	O
“	O
	
[	O
m	O
]	O
uch	O
of	O
the	O
prior	O
information	O
regarding	O
morphology	O
,	O
cognates	O
and	O
rare	O
word	O
translation	B-Task
among	O
others	O
,	O
should	O
be	O
incorporated	O
”	O
.	O
	
It	O
however	O
becomes	O
unnecessary	O
to	O
consider	O
these	O
prior	O
information	O
,	O
if	O
we	O
use	O
a	O
neural	B-Method
network	I-Method
,	O
be	O
it	O
recurrent	B-Method
,	O
convolution	B-Method
or	O
their	O
combination	O
,	O
directly	O
on	O
the	O
unsegmented	O
character	O
sequence	O
.	O
	
The	O
possibility	O
of	O
using	O
a	O
sequence	O
of	O
unsegmented	O
characters	O
has	O
been	O
studied	O
over	O
many	O
years	O
in	O
the	O
field	O
of	O
deep	B-Task
learning	I-Task
.	O
	
For	O
instance	O
,	O
mikolov2012subword	O
and	O
sutskever2011generating	O
trained	O
a	O
recurrent	B-Method
neural	I-Method
network	I-Method
language	I-Method
model	I-Method
(	O
RNN	B-Method
-	I-Method
LM	I-Method
)	O
on	O
character	O
sequences	O
.	O
	
The	O
latter	O
showed	O
that	O
it	O
is	O
possible	O
to	O
generate	O
sensible	O
text	O
sequences	O
by	O
simply	O
sampling	O
a	O
character	O
at	O
a	O
time	O
from	O
this	O
model	O
.	O
	
More	O
recently	O
,	O
zhang2015character	O
and	O
xiao2016efficient	O
successfully	O
applied	O
a	O
convolutional	B-Method
net	I-Method
and	O
a	O
convolutional	B-Method
-	I-Method
recurrent	I-Method
net	I-Method
respectively	O
to	O
character	B-Task
-	I-Task
level	I-Task
document	I-Task
classification	I-Task
without	O
any	O
explicit	B-Method
segmentation	I-Method
.	O
	
gillick2015multilingual	O
further	O
showed	O
that	O
it	O
is	O
possible	O
to	O
train	O
a	O
recurrent	B-Method
neural	I-Method
network	I-Method
on	O
unicode	O
bytes	O
,	O
instead	O
of	O
characters	O
or	O
words	O
,	O
to	O
perform	O
part	B-Task
-	I-Task
of	I-Task
-	I-Task
speech	I-Task
tagging	I-Task
and	O
named	B-Task
entity	I-Task
recognition	I-Task
.	O
	
These	O
previous	O
works	O
suggest	O
the	O
possibility	O
of	O
applying	O
neural	B-Method
networks	I-Method
for	O
the	O
task	O
of	O
machine	B-Task
translation	I-Task
,	O
which	O
is	O
often	O
considered	O
a	O
substantially	O
more	O
difficult	O
problem	O
compared	O
to	O
document	B-Task
classification	I-Task
and	O
language	B-Task
modelling	I-Task
.	O
	
subsection	O
:	O
Challenges	O
and	O
Questions	O
	
There	O
are	O
two	O
overlapping	O
sets	O
of	O
challenges	O
for	O
the	O
source	O
and	O
target	O
sides	O
.	O
	
On	O
the	O
source	O
side	O
,	O
it	O
is	O
unclear	O
how	O
to	O
build	O
a	O
neural	B-Method
network	I-Method
that	O
learns	O
a	O
highly	O
nonlinear	O
mapping	O
from	O
a	O
spelling	O
to	O
the	O
meaning	O
of	O
a	O
sentence	O
.	O
	
On	O
the	O
target	O
side	O
,	O
there	O
are	O
two	O
challenges	O
.	O
	
The	O
first	O
challenge	O
is	O
the	O
same	O
one	O
from	O
the	O
source	O
side	O
,	O
as	O
the	O
decoder	B-Method
neural	I-Method
network	I-Method
needs	O
to	O
summarize	O
what	O
has	O
been	O
translated	O
.	O
	
In	O
addition	O
to	O
this	O
,	O
the	O
character	B-Method
-	I-Method
level	I-Method
modelling	I-Method
on	O
the	O
target	O
side	O
is	O
more	O
challenging	O
,	O
as	O
the	O
decoder	B-Method
network	I-Method
must	O
be	O
able	O
to	O
generate	O
a	O
long	O
,	O
coherent	O
sequence	O
of	O
characters	O
.	O
	
This	O
is	O
a	O
great	O
challenge	O
,	O
as	O
the	O
size	O
of	O
the	O
state	O
space	O
grows	O
exponentially	O
w.r.t	O
.	O
	
the	O
number	O
of	O
symbols	O
,	O
and	O
in	O
the	O
case	O
of	O
characters	O
,	O
it	O
is	O
often	O
300	O
-	O
1000	O
symbols	O
long	O
.	O
	
All	O
these	O
challenges	O
should	O
first	O
be	O
framed	O
as	O
questions	O
;	O
whether	O
the	O
current	O
recurrent	B-Method
neural	I-Method
networks	I-Method
,	O
which	O
are	O
already	O
widely	O
used	O
in	O
neural	O
machine	B-Task
translation	I-Task
,	O
are	O
able	O
to	O
address	O
these	O
challenges	O
as	O
they	O
are	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
aim	O
at	O
answering	O
these	O
questions	O
empirically	O
and	O
focus	O
on	O
the	O
challenges	O
on	O
the	O
target	O
side	O
(	O
as	O
the	O
target	O
side	O
shows	O
both	O
of	O
the	O
challenges	O
)	O
.	O
	
section	O
:	O
Character	B-Task
-	I-Task
Level	I-Task
Translation	I-Task
	
In	O
this	O
paper	O
,	O
we	O
try	O
to	O
answer	O
the	O
questions	O
posed	O
earlier	O
by	O
testing	O
two	O
different	O
types	O
of	O
recurrent	B-Method
neural	I-Method
networks	I-Method
on	O
the	O
target	O
side	O
(	O
decoder	O
)	O
.	O
	
First	O
,	O
we	O
test	O
an	O
existing	O
recurrent	B-Method
neural	I-Method
network	I-Method
with	O
gated	B-Method
recurrent	I-Method
units	I-Method
(	O
GRUs	B-Method
)	O
.	O
	
We	O
call	O
this	O
decoder	O
a	O
base	B-Method
decoder	O
.	O
	
Second	O
,	O
we	O
build	O
a	O
novel	O
two	B-Method
-	I-Method
layer	I-Method
recurrent	I-Method
neural	I-Method
network	I-Method
,	O
inspired	O
by	O
the	O
gated	B-Method
-	I-Method
feedback	I-Method
network	I-Method
from	O
chung2015gated	O
,	O
called	O
a	O
bi	B-Method
-	I-Method
scale	I-Method
recurrent	O
neural	O
network	O
.	O
	
We	O
design	O
this	O
network	O
to	O
facilitate	O
capturing	O
two	O
timescales	O
,	O
motivated	O
by	O
the	O
fact	O
that	O
characters	O
and	O
words	O
may	O
work	O
at	O
two	O
separate	O
timescales	O
.	O
	
We	O
choose	O
to	O
test	O
these	O
two	O
alternatives	O
for	O
the	O
following	O
purposes	O
.	O
	
Experiments	O
with	O
the	O
base	B-Method
decoder	O
will	O
clearly	O
answer	O
whether	O
the	O
existing	O
neural	B-Method
network	I-Method
is	O
enough	O
to	O
handle	O
character	B-Method
-	I-Method
level	I-Method
decoding	I-Method
,	O
which	O
has	O
not	O
been	O
properly	O
answered	O
in	O
the	O
context	O
of	O
machine	B-Task
translation	I-Task
.	O
	
The	O
alternative	O
,	O
the	O
bi	B-Method
-	I-Method
scale	I-Method
decoder	O
,	O
is	O
tested	O
in	O
order	O
to	O
see	O
whether	O
it	O
is	O
possible	O
to	O
design	O
a	O
better	O
decoder	O
,	O
if	O
the	O
answer	O
to	O
the	O
first	O
question	O
is	O
positive	O
.	O
	
(	O
a	O
)	O
Gating	B-Method
units	I-Method
(	O
b	O
)	O
One	B-Method
-	I-Method
step	I-Method
processing	I-Method
	
subsection	O
:	O
Bi	B-Method
-	I-Method
Scale	I-Method
Recurrent	I-Method
Neural	I-Method
Network	I-Method
	
In	O
this	O
proposed	O
bi	B-Method
-	I-Method
scale	I-Method
recurrent	O
neural	O
network	O
,	O
there	O
are	O
two	O
sets	O
of	O
hidden	O
units	O
,	O
and	O
.	O
	
They	O
contain	O
the	O
same	O
number	O
of	O
units	O
,	O
i.e.	O
,	O
.	O
	
The	O
first	O
set	O
models	O
a	O
fast	O
-	O
changing	O
timescale	O
(	O
thereby	O
,	O
a	O
faster	O
layer	O
)	O
,	O
and	O
a	O
slower	O
timescale	O
(	O
thereby	O
,	O
a	O
slower	O
layer	O
)	O
.	O
	
For	O
each	O
hidden	O
unit	O
,	O
there	O
is	O
an	O
associated	O
gating	O
unit	O
,	O
to	O
which	O
we	O
refer	O
by	O
and	O
.	O
	
For	O
the	O
description	O
below	O
,	O
we	O
use	O
and	O
for	O
the	O
previous	O
target	O
symbol	O
and	O
the	O
context	O
vector	O
(	O
see	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
)	O
,	O
respectively	O
.	O
	
Let	O
us	O
start	O
with	O
the	O
faster	O
layer	O
.	O
	
The	O
faster	B-Method
layer	I-Method
outputs	O
two	O
sets	O
of	O
activations	O
,	O
a	O
normal	O
output	O
and	O
its	O
gated	B-Method
version	I-Method
.	O
	
The	O
activation	O
of	O
the	O
faster	O
layer	O
is	O
computed	O
by	O
where	O
and	O
are	O
the	O
gated	O
activations	O
of	O
the	O
faster	O
and	O
slower	O
layers	O
respectively	O
.	O
	
These	O
gated	O
activations	O
are	O
computed	O
by	O
In	O
other	O
words	O
,	O
the	O
faster	O
layer	O
’s	O
activation	O
is	O
based	O
on	O
the	O
adaptive	B-Method
combination	I-Method
of	O
the	O
faster	O
and	O
slower	O
layers	O
’	O
activations	O
from	O
the	O
previous	O
time	O
step	O
.	O
	
Whenever	O
the	O
faster	O
layer	O
determines	O
that	O
it	O
needs	O
to	O
reset	O
,	O
i.e.	O
,	O
,	O
the	O
next	O
activation	O
will	O
be	O
determined	O
based	O
more	O
on	O
the	O
slower	O
layer	O
’s	O
activation	O
.	O
	
The	O
faster	B-Method
layer	I-Method
’s	I-Method
gating	I-Method
unit	I-Method
is	O
computed	O
by	O
where	O
is	O
a	O
sigmoid	B-Method
function	I-Method
.	O
	
The	O
slower	B-Method
layer	I-Method
also	O
outputs	O
two	O
sets	O
of	O
activations	O
,	O
a	O
normal	O
output	O
and	O
its	O
gated	B-Method
version	I-Method
.	O
	
These	O
activations	O
are	O
computed	O
as	O
follows	O
:	O
where	O
is	O
a	O
candidate	O
activation	O
.	O
	
The	O
slower	O
layer	O
’s	O
gating	O
unit	O
is	O
computed	O
by	O
This	O
adaptive	B-Method
leaky	I-Method
integration	I-Method
based	O
on	O
the	O
gating	B-Method
unit	I-Method
from	O
the	O
faster	O
layer	O
has	O
a	O
consequence	O
that	O
the	O
slower	O
layer	O
updates	O
its	O
activation	O
only	O
when	O
the	O
faster	O
layer	O
resets	O
.	O
	
This	O
puts	O
a	O
soft	O
constraint	O
that	O
the	O
faster	B-Method
layer	I-Method
runs	O
at	O
a	O
faster	O
rate	O
by	O
preventing	O
the	O
slower	O
layer	O
from	O
updating	O
while	O
the	O
faster	B-Method
layer	I-Method
is	O
processing	O
a	O
current	O
chunk	O
.	O
	
The	O
candidate	O
activation	O
is	O
then	O
computed	O
by	O
indicates	O
the	O
reset	O
activation	O
from	O
the	O
previous	O
time	O
step	O
,	O
similarly	O
to	O
what	O
happened	O
in	O
the	O
faster	B-Method
layer	I-Method
,	O
and	O
is	O
the	O
input	O
from	O
the	O
context	O
.	O
	
According	O
to	O
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
	
,	O
the	O
faster	O
layer	O
influences	O
the	O
slower	O
layer	O
,	O
only	O
when	O
the	O
faster	O
layer	O
has	O
finished	O
processing	O
the	O
current	O
chunk	O
and	O
is	O
about	O
to	O
reset	O
itself	O
(	O
)	O
.	O
	
In	O
other	O
words	O
,	O
the	O
slower	B-Method
layer	I-Method
does	O
not	O
receive	O
any	O
input	O
from	O
the	O
faster	O
layer	O
,	O
until	O
the	O
faster	O
layer	O
has	O
quickly	O
processed	O
the	O
current	O
chunk	O
,	O
thereby	O
running	O
at	O
a	O
slower	O
rate	O
than	O
the	O
faster	B-Method
layer	I-Method
does	O
.	O
	
At	O
each	O
time	O
step	O
,	O
the	O
final	O
output	O
of	O
the	O
proposed	O
bi	B-Method
-	I-Method
scale	I-Method
recurrent	O
neural	O
network	O
is	O
the	O
concatenation	O
of	O
the	O
output	O
vectors	O
of	O
the	O
faster	O
and	O
slower	O
layers	O
,	O
i.e.	O
,	O
.	O
	
This	O
concatenated	O
vector	O
is	O
used	O
to	O
compute	O
the	O
probability	O
distribution	O
over	O
all	O
the	O
symbols	O
in	O
the	O
vocabulary	O
,	O
as	O
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
	
See	O
Fig	O
.	O
	
[	O
reference	O
]	O
for	O
graphical	O
illustration	O
.	O
	
Src	B-Method
Depth	I-Method
Model	I-Method
	
En	O
-	O
De	O
BPE	B-Method
En	O
-	O
Ru	O
	
BPE	B-Method
	
En	O
-	O
Fi	O
BPE	B-Method
	
section	O
:	O
Experiment	O
Settings	O
	
For	O
evaluation	O
,	O
we	O
represent	O
a	O
source	O
sentence	O
as	O
a	O
sequence	O
of	O
subword	O
symbols	O
extracted	O
by	O
byte	B-Method
-	I-Method
pair	I-Method
encoding	I-Method
(	O
BPE	B-Method
,	O
sennrich2015neural	O
)	O
and	O
a	O
target	O
sentence	O
either	O
as	O
a	O
sequence	O
of	O
BPE	B-Method
-	O
based	O
symbols	O
or	O
as	O
a	O
sequence	O
of	O
characters	O
.	O
	
paragraph	O
:	O
Corpora	O
and	O
Preprocessing	O
	
We	O
use	O
all	O
available	O
parallel	O
corpora	O
for	O
four	O
language	O
pairs	O
from	O
WMT’15	B-Material
:	O
	
En	O
-	O
Cs	O
,	O
En	O
-	O
De	O
,	O
En	O
-	O
Ru	O
and	O
En	O
-	O
Fi	O
.	O
	
They	O
consist	O
of	O
12.1	O
M	O
,	O
4.5	O
M	O
,	O
2.3	O
M	O
and	O
2	O
M	O
sentence	O
pairs	O
,	O
respectively	O
.	O
	
We	O
tokenize	O
each	O
corpus	O
using	O
a	O
tokenization	B-Method
script	I-Method
included	O
in	O
Moses	O
.	O
	
We	O
only	O
use	O
the	O
sentence	O
pairs	O
,	O
when	O
the	O
source	O
side	O
is	O
up	O
to	O
50	O
subword	O
symbols	O
long	O
and	O
the	O
target	O
side	O
is	O
either	O
up	O
to	O
100	O
subword	O
symbols	O
or	O
500	O
characters	O
.	O
	
We	O
do	O
not	O
use	O
any	O
monolingual	O
corpus	O
.	O
	
For	O
all	O
the	O
pairs	O
other	O
than	O
En	O
-	O
Fi	O
,	O
we	O
use	O
newstest	O
-	O
2013	O
as	O
a	O
development	O
set	O
,	O
and	O
newstest	O
-	O
2014	O
(	O
Test	O
)	O
and	O
newstest	O
-	O
2015	O
(	O
Test	O
)	O
as	O
test	O
sets	O
.	O
	
For	O
En	O
-	O
Fi	O
,	O
we	O
use	O
newsdev	O
-	O
2015	O
and	O
newstest	O
-	O
2015	O
as	O
development	O
and	O
test	O
sets	O
,	O
respectively	O
.	O
	
paragraph	O
:	O
Models	O
and	O
Training	O
	
We	O
test	O
three	O
models	O
settings	O
:	O
(	O
1	O
)	O
BPE	B-Method
BPE	I-Method
,	O
(	O
2	O
)	O
BPE	B-Method
Char	I-Method
(	O
base	B-Method
)	O
and	O
(	O
3	O
)	O
BPE	B-Method
Char	I-Method
(	O
bi	B-Method
-	I-Method
scale	I-Method
)	O
.	O
	
The	O
latter	O
two	O
differ	O
by	O
the	O
type	O
of	O
recurrent	B-Method
neural	I-Method
network	I-Method
we	O
use	O
.	O
	
We	O
use	O
GRUs	B-Method
for	O
the	O
encoder	O
in	O
all	O
the	O
settings	O
.	O
	
We	O
used	O
GRUs	B-Method
for	O
the	O
decoders	B-Method
in	O
the	O
first	O
two	O
settings	O
,	O
(	O
1	O
)	O
and	O
(	O
2	O
)	O
,	O
while	O
the	O
proposed	O
bi	B-Method
-	I-Method
scale	I-Method
recurrent	O
network	O
was	O
used	O
in	O
the	O
last	O
setting	O
,	O
(	O
3	O
)	O
.	O
	
The	O
encoder	B-Method
has	O
hidden	O
units	O
for	O
each	O
direction	O
(	O
forward	O
and	O
reverse	O
)	O
,	O
and	O
the	O
decoder	B-Method
has	O
hidden	O
units	O
per	O
layer	O
.	O
	
We	O
train	O
each	O
model	O
using	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
with	O
Adam	B-Method
.	O
	
Each	O
update	O
is	O
computed	O
using	O
a	O
minibatch	O
of	O
128	O
sentence	O
pairs	O
.	O
	
The	O
norm	O
of	O
the	O
gradient	O
is	O
clipped	O
with	O
a	O
threshold	O
.	O
	
paragraph	O
:	O
Decoding	B-Task
and	O
Evaluation	O
	
We	O
use	O
beamsearch	B-Method
to	O
approximately	O
find	O
the	O
most	O
likely	O
translation	B-Task
given	O
a	O
source	O
sentence	O
.	O
	
The	O
beam	O
widths	O
are	O
and	O
respectively	O
for	O
the	O
subword	B-Method
-	I-Method
level	I-Method
and	O
character	B-Method
-	I-Method
level	I-Method
decoders	I-Method
.	O
	
They	O
were	O
chosen	O
based	O
on	O
the	O
translation	B-Task
quality	O
on	O
the	O
development	O
set	O
.	O
	
The	O
translations	O
are	O
evaluated	O
using	O
BLEU	B-Metric
.	O
	
paragraph	O
:	O
Multilayer	B-Method
Decoder	I-Method
and	O
Soft	B-Method
-	I-Method
Alignment	I-Method
Mechanism	I-Method
	
When	O
the	O
decoder	B-Method
is	O
a	O
multilayer	B-Method
recurrent	I-Method
neural	I-Method
network	I-Method
(	O
including	O
a	O
stacked	B-Method
network	I-Method
as	O
well	O
as	O
the	O
proposed	O
bi	B-Method
-	I-Method
scale	I-Method
network	O
)	O
,	O
the	O
decoder	O
outputs	O
multiple	O
hidden	O
vectors–	O
for	O
layers	O
,	O
at	O
a	O
time	O
.	O
	
This	O
allows	O
an	O
extra	O
degree	O
of	O
freedom	O
in	O
the	O
soft	O
-	O
alignment	O
mechanism	O
(	O
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
)	O
.	O
	
We	O
evaluate	O
using	O
alternatives	O
,	O
including	O
(	O
1	O
)	O
using	O
only	O
(	O
slower	O
layer	O
)	O
and	O
(	O
2	O
)	O
using	O
all	O
of	O
them	O
(	O
concatenated	O
)	O
.	O
	
paragraph	O
:	O
Ensembles	O
	
We	O
also	O
evaluate	O
an	O
ensemble	O
of	O
neural	O
machine	B-Task
translation	I-Task
models	O
and	O
compare	O
its	O
performance	O
against	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
phrase	O
-	O
based	O
translation	B-Task
systems	O
on	O
all	O
four	O
language	O
pairs	O
.	O
	
We	O
decode	O
from	O
an	O
ensemble	O
by	O
taking	O
the	O
average	O
of	O
the	O
output	O
probabilities	O
at	O
each	O
step	O
.	O
	
section	O
:	O
Quantitative	B-Task
Analysis	I-Task
	
paragraph	O
:	O
Slower	B-Method
Layer	I-Method
for	O
Alignment	B-Task
	
On	O
En	O
-	O
De	O
,	O
we	O
test	O
which	O
layer	O
of	O
the	O
decoder	B-Method
should	O
be	O
used	O
for	O
computing	O
soft	B-Task
-	I-Task
alignments	I-Task
.	O
	
In	O
the	O
case	O
of	O
subword	B-Method
-	I-Method
level	I-Method
decoder	O
,	O
we	O
observed	O
no	O
difference	O
between	O
choosing	O
any	O
of	O
the	O
two	O
layers	O
of	O
the	O
decoder	O
against	O
using	O
the	O
concatenation	O
of	O
all	O
the	O
layers	O
(	O
Table	O
[	O
reference	O
]	O
(	O
a	O
–	O
b	O
)	O
)	O
	
On	O
the	O
other	O
hand	O
,	O
with	O
the	O
character	B-Method
-	I-Method
level	I-Method
decoder	I-Method
,	O
we	O
noticed	O
an	O
improvement	O
when	O
only	O
the	O
slower	O
layer	O
(	O
)	O
was	O
used	O
for	O
the	O
soft	B-Method
-	I-Method
alignment	I-Method
mechanism	I-Method
(	O
Table	O
[	O
reference	O
]	O
(	O
c	O
–	O
g	O
)	O
)	O
.	O
	
This	O
suggests	O
that	O
the	O
soft	B-Method
-	I-Method
alignment	I-Method
mechanism	I-Method
benefits	O
by	O
aligning	O
a	O
larger	O
chunk	O
in	O
the	O
target	O
with	O
a	O
subword	O
unit	O
in	O
the	O
source	O
,	O
and	O
we	O
use	O
only	O
the	O
slower	B-Method
layer	I-Method
for	O
all	O
the	O
other	O
language	O
pairs	O
.	O
	
paragraph	O
:	O
Single	O
Models	O
	
In	O
Table	O
[	O
reference	O
]	O
,	O
we	O
present	O
a	O
comprehensive	O
report	O
of	O
the	O
translation	B-Task
qualities	O
of	O
(	O
1	O
)	O
subword	B-Method
-	I-Method
level	I-Method
decoder	O
,	O
(	O
2	O
)	O
character	B-Method
-	I-Method
level	I-Method
base	I-Method
decoder	I-Method
and	O
(	O
3	O
)	O
character	B-Method
-	I-Method
level	I-Method
bi	I-Method
-	I-Method
scale	I-Method
decoder	I-Method
,	O
for	O
all	O
the	O
language	O
pairs	O
.	O
	
We	O
see	O
that	O
the	O
both	O
types	O
of	O
character	B-Method
-	I-Method
level	I-Method
decoder	I-Method
outperform	O
the	O
subword	B-Method
-	I-Method
level	I-Method
decoder	O
for	O
En	O
-	O
Cs	O
and	O
En	O
-	O
Fi	O
quite	O
significantly	O
.	O
	
On	O
En	O
-	O
De	O
,	O
the	O
character	B-Method
-	I-Method
level	I-Method
base	I-Method
decoder	I-Method
outperforms	O
both	O
the	O
subword	B-Method
-	I-Method
level	I-Method
decoder	O
and	O
the	O
character	B-Method
-	I-Method
level	I-Method
bi	I-Method
-	I-Method
scale	I-Method
decoder	I-Method
,	O
validating	O
the	O
effectiveness	O
of	O
the	O
character	B-Method
-	I-Method
level	I-Method
modelling	I-Method
.	O
	
On	O
En	O
-	O
Ru	O
,	O
among	O
the	O
single	O
models	O
,	O
the	O
character	B-Method
-	I-Method
level	I-Method
decoders	I-Method
outperform	O
the	O
subword	B-Method
-	I-Method
level	I-Method
decoder	O
,	O
but	O
in	O
general	O
,	O
we	O
observe	O
that	O
all	O
the	O
three	O
alternatives	O
work	O
comparable	O
to	O
each	O
other	O
.	O
	
These	O
results	O
clearly	O
suggest	O
that	O
it	O
is	O
indeed	O
possible	O
to	O
do	O
character	O
-	O
level	O
translation	B-Task
without	O
explicit	B-Method
segmentation	I-Method
.	O
	
In	O
fact	O
,	O
what	O
we	O
observed	O
is	O
that	O
character	O
-	O
level	O
translation	B-Task
often	O
surpasses	O
the	O
translation	B-Task
quality	O
of	O
word	O
-	O
level	O
translation	B-Task
.	O
	
Of	O
course	O
,	O
we	O
note	O
once	O
again	O
that	O
our	O
experiment	O
is	O
restricted	O
to	O
using	O
an	O
unsegmented	O
character	O
sequence	O
at	O
the	O
decoder	O
only	O
,	O
and	O
a	O
further	O
exploration	O
toward	O
replacing	O
the	O
source	O
sentence	O
with	O
an	O
unsegmented	O
character	O
sequence	O
is	O
needed	O
.	O
	
paragraph	O
:	O
Ensembles	O
	
Each	O
ensemble	O
was	O
built	O
using	O
eight	O
independent	B-Method
models	I-Method
.	O
	
The	O
first	O
observation	O
we	O
make	O
is	O
that	O
in	O
all	O
the	O
language	O
pairs	O
,	O
neural	O
machine	B-Task
translation	I-Task
performs	O
comparably	O
to	O
,	O
or	O
often	O
better	O
than	O
,	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
non	O
-	O
neural	O
translation	B-Task
system	O
.	O
	
Furthermore	O
,	O
the	O
character	B-Method
-	I-Method
level	I-Method
decoders	I-Method
outperform	O
the	O
subword	B-Method
-	I-Method
level	I-Method
decoder	O
in	O
all	O
the	O
cases	O
.	O
	
section	O
:	O
Qualitative	B-Task
Analysis	I-Task
	
paragraph	O
:	O
(	O
1	O
)	O
Can	O
the	O
character	B-Method
-	I-Method
level	I-Method
decoder	I-Method
generate	O
a	O
long	O
,	O
coherent	O
sentence	O
?	O
	
The	O
translation	B-Task
in	O
characters	O
is	O
dramatically	O
longer	O
than	O
that	O
in	O
words	O
,	O
likely	O
making	O
it	O
more	O
difficult	O
for	O
a	O
recurrent	B-Method
neural	I-Method
network	I-Method
to	O
generate	O
a	O
coherent	O
sentence	O
in	O
characters	O
.	O
	
This	O
belief	O
turned	O
out	O
to	O
be	O
false	O
.	O
	
As	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
left	O
)	O
	
,	O
there	O
is	O
no	O
significant	O
difference	O
between	O
the	O
subword	B-Method
-	I-Method
level	I-Method
and	O
character	B-Method
-	I-Method
level	I-Method
decoders	I-Method
,	O
even	O
though	O
the	O
lengths	O
of	O
the	O
generated	O
translations	O
are	O
generally	O
5–10	O
times	O
longer	O
in	O
characters	O
.	O
	
paragraph	O
:	O
(	O
2	O
)	O
Does	O
the	O
character	B-Method
-	I-Method
level	I-Method
decoder	I-Method
help	O
with	O
rare	O
words	O
?	O
	
One	O
advantage	O
of	O
character	B-Method
-	I-Method
level	I-Method
modelling	I-Method
is	O
that	O
it	O
can	O
model	O
the	O
composition	O
of	O
any	O
character	O
sequence	O
,	O
thereby	O
better	O
modelling	O
rare	O
morphological	O
variants	O
.	O
	
We	O
empirically	O
confirm	O
this	O
by	O
observing	O
the	O
growing	O
gap	O
in	O
the	O
average	B-Metric
negative	I-Metric
log	I-Metric
-	I-Metric
probability	I-Metric
of	I-Metric
words	I-Metric
between	O
the	O
subword	B-Method
-	I-Method
level	I-Method
and	O
character	B-Method
-	I-Method
level	I-Method
decoders	I-Method
as	O
the	O
frequency	O
of	O
the	O
words	O
decreases	O
.	O
	
This	O
is	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
right	O
)	O
and	O
explains	O
one	O
potential	O
cause	O
behind	O
the	O
success	O
of	O
character	B-Method
-	I-Method
level	I-Method
decoding	I-Method
in	O
our	O
experiments	O
(	O
we	O
define	O
)	O
.	O
	
paragraph	O
:	O
(	O
3	O
)	O
Can	O
the	O
character	B-Method
-	I-Method
level	I-Method
decoder	I-Method
soft	O
-	O
align	O
between	O
a	O
source	O
word	O
and	O
a	O
target	O
character	O
?	O
	
In	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
left	O
)	O
	
,	O
we	O
show	O
an	O
example	O
soft	B-Task
-	I-Task
alignment	I-Task
of	O
a	O
source	O
sentence	O
,	O
“	O
Two	O
sets	O
of	O
light	O
so	O
close	O
to	O
one	O
another	O
”	O
.	O
	
It	O
is	O
clear	O
that	O
the	O
character	B-Method
-	I-Method
level	I-Method
translation	I-Method
model	I-Method
well	O
captured	O
the	O
alignment	O
between	O
the	O
source	O
subwords	O
and	O
target	O
characters	O
.	O
	
We	O
observe	O
that	O
the	O
character	B-Method
-	I-Method
level	I-Method
decoder	I-Method
correctly	O
aligns	O
to	O
“	O
lights	O
”	O
and	O
“	O
sets	O
of	O
”	O
when	O
generating	O
a	O
German	O
compound	O
word	O
“	O
Lichtersets	O
”	O
(	O
see	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
(	O
right	O
)	O
for	O
the	O
zoomed	O
-	O
in	O
version	O
)	O
.	O
	
This	O
type	O
of	O
behaviour	O
happens	O
similarly	O
between	O
“	O
one	O
another	O
”	O
and	O
“	O
einander	O
”	O
.	O
	
Of	O
course	O
,	O
this	O
does	O
not	O
mean	O
that	O
there	O
exists	O
an	O
alignment	O
between	O
a	O
source	O
word	O
and	O
a	O
target	O
character	O
.	O
	
Rather	O
,	O
this	O
suggests	O
that	O
the	O
internal	O
state	O
of	O
the	O
character	B-Method
-	I-Method
level	I-Method
decoder	I-Method
,	O
the	O
base	B-Method
or	O
bi	B-Method
-	I-Method
scale	I-Method
,	O
well	O
captures	O
the	O
meaningful	O
chunk	O
of	O
characters	O
,	O
allowing	O
the	O
model	O
to	O
map	O
it	O
to	O
a	O
larger	O
chunk	O
(	O
subword	O
)	O
in	O
the	O
source	O
.	O
	
paragraph	O
:	O
(	O
4	O
)	O
How	O
fast	O
is	O
the	O
decoding	B-Metric
speed	I-Metric
of	O
the	O
character	B-Method
-	I-Method
level	I-Method
decoder	I-Method
?	O
	
We	O
evaluate	O
the	O
decoding	B-Metric
speed	I-Metric
of	O
subword	B-Method
-	I-Method
level	I-Method
base	I-Method
,	O
character	B-Method
-	I-Method
level	I-Method
base	I-Method
and	O
character	B-Method
-	I-Method
level	I-Method
bi	I-Method
-	I-Method
scale	I-Method
decoders	I-Method
on	O
newstest	O
-	O
2013	O
corpus	O
(	O
En	O
-	O
De	O
)	O
with	O
a	O
single	O
Titan	B-Method
X	I-Method
GPU	I-Method
.	O
	
The	O
subword	B-Method
-	I-Method
level	I-Method
base	I-Method
decoder	O
generates	O
31.9	O
words	O
per	O
second	O
,	O
and	O
the	O
character	B-Method
-	I-Method
level	I-Method
base	I-Method
decoder	I-Method
and	O
character	B-Method
-	I-Method
level	I-Method
bi	I-Method
-	I-Method
scale	I-Method
decoder	I-Method
generate	O
27.5	O
words	O
per	O
second	O
and	O
25.6	O
words	O
per	O
second	O
,	O
respectively	O
.	O
	
Note	O
that	O
this	O
is	O
evaluated	O
in	O
an	O
online	B-Task
setting	I-Task
,	O
performing	O
consecutive	B-Task
translation	I-Task
,	O
where	O
only	O
one	O
sentence	O
is	O
translated	O
at	O
a	O
time	O
.	O
	
Translating	O
in	O
a	O
batch	O
setting	O
could	O
differ	O
from	O
these	O
results	O
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
paper	O
,	O
we	O
addressed	O
a	O
fundamental	O
question	O
on	O
whether	O
a	O
recently	O
proposed	O
neural	O
machine	B-Task
translation	I-Task
system	O
can	O
directly	O
handle	O
translation	B-Task
at	O
the	O
level	O
of	O
characters	O
without	O
any	O
word	B-Method
segmentation	I-Method
.	O
	
We	O
focused	O
on	O
the	O
target	O
side	O
,	O
in	O
which	O
a	O
decoder	O
was	O
asked	O
to	O
generate	O
one	O
character	O
at	O
a	O
time	O
,	O
while	O
soft	O
-	O
aligning	O
between	O
a	O
target	O
character	O
and	O
a	O
source	O
subword	O
.	O
	
Our	O
extensive	O
experiments	O
,	O
on	O
four	O
language	O
pairs	O
–	O
	
En	O
-	O
Cs	O
,	O
En	O
-	O
De	O
,	O
	
En	O
-	O
Ru	O
and	O
En	O
-	O
Fi–	O
strongly	O
suggest	O
that	O
it	O
is	O
indeed	O
possible	O
for	O
neural	O
machine	B-Task
translation	I-Task
to	O
translate	O
at	O
the	O
level	O
of	O
characters	O
,	O
and	O
that	O
it	O
actually	O
benefits	O
from	O
doing	O
so	O
.	O
	
Our	O
result	O
has	O
one	O
limitation	O
that	O
we	O
used	O
subword	O
symbols	O
in	O
the	O
source	O
side	O
.	O
	
However	O
,	O
this	O
has	O
allowed	O
us	O
a	O
more	O
fine	B-Task
-	I-Task
grained	I-Task
analysis	I-Task
,	O
but	O
in	O
the	O
future	O
,	O
a	O
setting	O
where	O
the	O
source	O
side	O
is	O
also	O
represented	O
as	O
a	O
character	O
sequence	O
must	O
be	O
investigated	O
.	O
	
section	O
:	O
Acknowledgments	O
	
The	O
authors	O
would	O
like	O
to	O
thank	O
the	O
developers	O
of	O
Theano	O
.	O
	
We	O
acknowledge	O
the	O
support	O
of	O
the	O
following	O
agencies	O
for	O
research	O
funding	O
and	O
computing	O
support	O
:	O
NSERC	O
,	O
Calcul	O
Québec	O
,	O
Compute	O
Canada	O
,	O
the	O
Canada	O
Research	O
Chairs	O
,	O
CIFAR	O
and	O
Samsung	O
.	O
	
KC	O
thanks	O
the	O
support	O
by	O
Facebook	O
,	O
Google	O
(	O
Google	O
Faculty	O
Award	O
2016	O
)	O
and	O
NVIDIA	O
(	O
GPU	O
Center	O
of	O
Excellence	O
2015	O
-	O
2016	O
)	O
.	O
	
JC	O
thanks	O
Orhan	O
Firat	O
for	O
his	O
constructive	O
feedbacks	O
.	O
	
bibliography	O
:	O
References	O
	
In	O
statistical	B-Task
relational	I-Task
learning	I-Task
,	O
the	O
link	B-Task
prediction	I-Task
problem	I-Task
is	O
key	O
to	O
automatically	O
understand	O
the	O
structure	O
of	O
large	B-Method
knowledge	I-Method
bases	I-Method
.	O
	
As	O
in	O
previous	O
studies	O
,	O
we	O
propose	O
to	O
solve	O
this	O
problem	O
through	O
latent	B-Method
factorization	I-Method
.	O
	
However	O
,	O
here	O
we	O
make	O
use	O
of	O
complex	O
valued	O
embeddings	O
.	O
	
The	O
composition	B-Method
of	I-Method
complex	I-Method
embeddings	I-Method
can	O
handle	O
a	O
large	O
variety	O
of	O
binary	O
relations	O
,	O
among	O
them	O
symmetric	O
and	O
antisymmetric	O
relations	O
.	O
	
Compared	O
to	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
such	O
as	O
Neural	B-Method
Tensor	I-Method
Network	I-Method
and	O
Holographic	B-Method
Embeddings	I-Method
,	O
our	O
approach	O
based	O
on	O
complex	B-Method
embeddings	I-Method
is	O
arguably	O
simpler	O
,	O
as	O
it	O
only	O
uses	O
the	O
Hermitian	O
dot	O
product	O
,	O
the	O
complex	O
counterpart	O
of	O
the	O
standard	O
dot	O
product	O
between	O
real	O
vectors	O
.	O
	
Our	O
approach	O
is	O
scalable	O
to	O
large	O
datasets	O
as	O
it	O
remains	O
linear	O
in	O
both	O
space	O
and	O
time	O
,	O
while	O
consistently	O
outperforming	O
alternative	O
approaches	O
on	O
standard	O
link	B-Task
prediction	I-Task
benchmarks	I-Task
.	O
	
ruled	O
algothplop	O
algoAlgorithm	O
ComplexEmbeddingsforSimpleLinkPrediction	B-Method
	
section	O
:	O
Introduction	O
	
Web	O
-	O
scale	O
knowledge	O
bases	O
(	O
KBs	O
)	O
provide	O
a	O
structured	B-Method
representation	I-Method
of	I-Method
world	I-Method
knowledge	I-Method
,	O
with	O
projects	O
such	O
as	O
DBPedia	O
,	O
Freebase	O
or	O
the	O
Google	O
Knowledge	O
Vault	O
.	O
	
They	O
enable	O
a	O
wide	O
range	O
of	O
applications	O
such	O
as	O
recommender	B-Task
systems	I-Task
,	O
question	B-Task
answering	I-Task
or	O
automated	B-Task
personal	I-Task
agents	I-Task
.	O
	
The	O
incompleteness	O
of	O
these	O
KBs	O
has	O
stimulated	O
research	O
into	O
predicting	B-Task
missing	I-Task
entries	I-Task
,	O
a	O
task	O
known	O
as	O
link	B-Task
prediction	I-Task
that	O
is	O
one	O
of	O
the	O
main	O
problems	O
in	O
Statistical	B-Task
Relational	I-Task
Learning	I-Task
.	O
	
KBs	B-Method
express	O
data	O
as	O
a	O
directed	O
graph	O
with	O
labeled	O
edges	O
(	O
relations	O
)	O
between	O
nodes	O
(	O
entities	O
)	O
.	O
	
Natural	O
redundancies	O
among	O
the	O
recorded	O
relations	O
often	O
make	O
it	O
possible	O
to	O
fill	O
in	O
the	O
missing	O
entries	O
of	O
a	O
KB	O
.	O
	
As	O
an	O
example	O
,	O
the	O
relation	O
CountryOfBirth	O
is	O
not	O
recorded	O
for	O
all	O
entities	O
,	O
but	O
it	O
can	O
easily	O
be	O
inferred	O
if	O
the	O
relation	O
CityOfBirth	O
is	O
known	O
.	O
	
The	O
goal	O
of	O
link	B-Task
prediction	I-Task
is	O
the	O
automatic	B-Task
discovery	I-Task
of	I-Task
such	O
regularities	O
.	O
	
However	O
,	O
many	O
relations	O
are	O
non	O
-	O
deterministic	O
:	O
the	O
combination	O
of	O
the	O
two	O
facts	O
IsBornIn	O
(	O
John	O
,	O
Athens	O
)	O
and	O
IsLocatedIn	O
(	O
Athens	O
,	O
Greece	O
)	O
does	O
not	O
always	O
imply	O
the	O
fact	O
HasNationality	O
(	O
John	O
,	O
Greece	O
)	O
.	O
	
Hence	O
,	O
it	O
is	O
required	O
to	O
handle	O
other	O
facts	O
involving	O
these	O
relations	O
or	O
entities	O
in	O
a	O
probabilistic	O
fashion	O
.	O
	
To	O
do	O
so	O
,	O
an	O
increasingly	O
popular	O
method	O
is	O
to	O
state	O
the	O
link	B-Task
prediction	I-Task
task	I-Task
as	O
a	O
3D	B-Task
binary	I-Task
tensor	I-Task
completion	I-Task
problem	I-Task
,	O
where	O
each	O
slice	O
is	O
the	O
adjacency	O
matrix	O
of	O
one	O
relation	O
type	O
in	O
the	O
knowledge	O
graph	O
.	O
	
Completion	B-Task
based	O
on	O
low	B-Method
-	I-Method
rank	I-Method
factorization	I-Method
or	O
embeddings	B-Method
has	O
been	O
popularized	O
with	O
the	O
Netflix	O
challenge	O
.	O
	
A	O
partially	O
observed	O
matrix	O
or	O
tensor	O
is	O
decomposed	O
into	O
a	O
product	B-Method
of	I-Method
embedding	I-Method
matrices	I-Method
with	O
much	O
smaller	O
rank	O
,	O
resulting	O
in	O
fixed	O
-	O
dimensional	B-Method
vector	I-Method
representations	I-Method
for	O
each	O
entity	O
and	O
relation	O
in	O
the	O
database	O
.	O
	
For	O
a	O
given	O
fact	O
r	O
(	O
s	O
,	O
o	O
)	O
in	O
which	O
subject	O
is	O
linked	O
to	O
object	O
through	O
relation	O
,	O
the	O
score	O
can	O
then	O
be	O
recovered	O
as	O
a	O
multi	O
-	O
linear	O
product	O
between	O
the	O
embedding	O
vectors	O
of	O
,	O
and	O
.	O
	
Binary	O
relations	O
in	O
KBs	O
exhibit	O
various	O
types	O
of	O
patterns	O
:	O
hierarchies	O
and	O
compositions	O
like	O
FatherOf	O
,	O
OlderThan	O
or	O
IsPartOf	O
	
—with	O
partial	O
/	O
total	O
,	O
strict	O
/	O
non	O
-	O
strict	O
orders	O
—	O
and	O
equivalence	O
relations	O
like	O
IsSimilarTo	O
.	O
	
As	O
described	O
in	O
,	O
a	O
relational	B-Method
model	I-Method
should	O
(	O
a	O
)	O
be	O
able	O
to	O
learn	O
all	O
combinations	O
of	O
these	O
properties	O
,	O
namely	O
reflexivity	O
/	O
irreflexivity	O
,	O
symmetry	O
/	O
antisymmetry	O
and	O
transitivity	O
,	O
and	O
(	O
b	O
)	O
be	O
linear	O
in	O
both	O
time	O
and	O
memory	O
in	O
order	O
to	O
scale	O
to	O
the	O
size	O
of	O
present	O
day	O
KBs	O
,	O
and	O
keep	O
up	O
with	O
their	O
growth	O
.	O
	
Dot	B-Method
products	I-Method
of	I-Method
embeddings	I-Method
scale	O
well	O
and	O
can	O
naturally	O
handle	O
both	O
symmetry	O
and	O
(	O
ir	O
-)	O
reflexivity	O
of	O
relations	O
;	O
using	O
an	O
appropriate	O
loss	O
function	O
even	O
enables	O
transitivity	O
.	O
	
However	O
,	O
dealing	O
with	O
antisymmetric	O
relations	O
has	O
so	O
far	O
almost	O
always	O
implied	O
an	O
explosion	O
of	O
the	O
number	O
of	O
parameters	O
(	O
see	O
Table	O
[	O
reference	O
]	O
)	O
,	O
making	O
models	O
prone	O
to	O
overfitting	O
.	O
	
Finding	O
the	O
best	O
ratio	O
between	O
expressiveness	B-Metric
and	O
parameter	B-Metric
space	I-Metric
size	I-Metric
is	O
the	O
keystone	O
of	O
embedding	B-Method
models	I-Method
.	O
	
In	O
this	O
work	O
we	O
argue	O
that	O
the	O
standard	O
dot	B-Method
product	I-Method
between	I-Method
embeddings	I-Method
can	O
be	O
a	O
very	O
effective	O
composition	B-Method
function	I-Method
,	O
provided	O
that	O
one	O
uses	O
the	O
right	O
representation	O
.	O
	
Instead	O
of	O
using	O
embeddings	O
containing	O
real	O
numbers	O
we	O
discuss	O
and	O
demonstrate	O
the	O
capabilities	O
of	O
complex	B-Method
embeddings	I-Method
.	O
	
When	O
using	O
complex	O
vectors	O
,	O
i.e.	O
vectors	O
with	O
entries	O
in	O
,	O
the	O
dot	O
product	O
is	O
often	O
called	O
the	O
Hermitian	O
(	O
or	O
sesquilinear	O
)	O
dot	O
product	O
,	O
as	O
it	O
involves	O
the	O
conjugate	O
-	O
transpose	O
of	O
one	O
of	O
the	O
two	O
vectors	O
.	O
	
As	O
a	O
consequence	O
,	O
the	O
dot	O
product	O
is	O
not	O
symmetric	O
any	O
more	O
,	O
and	O
facts	O
about	O
antisymmetric	O
relations	O
can	O
receive	O
different	O
scores	O
depending	O
on	O
the	O
ordering	O
of	O
the	O
entities	O
involved	O
.	O
	
Thus	O
complex	O
vectors	O
can	O
effectively	O
capture	O
antisymmetric	O
relations	O
while	O
retaining	O
the	O
efficiency	O
benefits	O
of	O
the	O
dot	O
product	O
,	O
that	O
is	O
linearity	O
in	O
both	O
space	B-Metric
and	I-Metric
time	I-Metric
complexity	I-Metric
.	O
	
The	O
remainder	O
of	O
the	O
paper	O
is	O
organized	O
as	O
follows	O
.	O
	
We	O
first	O
justify	O
the	O
intuition	O
of	O
using	O
complex	O
embeddings	O
in	O
the	O
square	B-Task
matrix	I-Task
case	I-Task
in	O
which	O
there	O
is	O
only	O
a	O
single	O
relation	O
between	O
entities	O
.	O
	
The	O
formulation	O
is	O
then	O
extended	O
to	O
a	O
stacked	O
set	O
of	O
square	O
matrices	O
in	O
a	O
third	O
-	O
order	O
tensor	O
to	O
represent	O
multiple	O
relations	O
.	O
	
We	O
then	O
describe	O
experiments	O
on	O
large	O
scale	O
public	O
benchmark	O
KBs	O
in	O
which	O
we	O
empirically	O
show	O
that	O
this	O
representation	O
leads	O
not	O
only	O
to	O
simpler	O
and	O
faster	O
algorithms	O
,	O
but	O
also	O
gives	O
a	O
systematic	O
accuracy	B-Metric
improvement	O
over	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
alternatives	O
.	O
	
To	O
give	O
a	O
clear	O
comparison	O
with	O
respect	O
to	O
existing	O
approaches	O
using	O
only	O
real	O
numbers	O
,	O
we	O
also	O
present	O
an	O
equivalent	O
reformulation	O
of	O
our	O
model	O
that	O
involves	O
only	O
real	O
embeddings	O
.	O
	
This	O
should	O
help	O
practitioners	O
when	O
implementing	O
our	O
method	O
,	O
without	O
requiring	O
the	O
use	O
of	O
complex	O
numbers	O
in	O
their	O
software	O
implementation	O
.	O
	
section	O
:	O
Relations	O
as	O
Real	O
Part	O
of	O
Low	O
-	O
Rank	O
Normal	O
Matrices	O
	
In	O
this	O
section	O
we	O
discuss	O
the	O
use	O
of	O
complex	B-Method
embeddings	I-Method
for	O
low	B-Task
-	I-Task
rank	I-Task
matrix	I-Task
factorization	I-Task
and	O
illustrate	O
this	O
by	O
considering	O
a	O
simplified	O
link	B-Task
prediction	I-Task
task	I-Task
with	O
merely	O
a	O
single	O
relation	O
type	O
.	O
	
Understanding	O
the	O
factorization	B-Task
in	I-Task
complex	I-Task
space	I-Task
leads	O
to	O
a	O
better	O
theoretical	O
understanding	O
of	O
the	O
class	O
of	O
matrices	O
that	O
can	O
actually	O
be	O
approximated	O
by	O
dot	B-Method
products	I-Method
of	I-Method
embeddings	I-Method
.	O
	
These	O
are	O
the	O
so	O
-	O
called	O
normal	O
matrices	O
for	O
which	O
the	O
left	O
and	O
right	O
embeddings	O
share	O
the	O
same	O
unitary	O
basis	O
.	O
	
subsection	O
:	O
Modelling	B-Task
Relations	I-Task
	
Let	O
be	O
a	O
set	O
of	O
entities	O
with	O
.	O
	
A	O
relation	O
between	O
two	O
entities	O
is	O
represented	O
as	O
a	O
binary	O
value	O
,	O
where	O
is	O
the	O
subject	O
of	O
the	O
relation	O
and	O
its	O
object	O
.	O
	
Its	O
probability	O
is	O
given	O
by	O
the	O
logistic	O
inverse	O
link	O
function	O
:	O
where	O
is	O
a	O
latent	O
matrix	O
of	O
scores	O
,	O
and	O
the	O
partially	O
observed	O
sign	O
matrix	O
.	O
	
Our	O
goal	O
is	O
to	O
find	O
a	O
generic	O
structure	O
for	O
that	O
leads	O
to	O
a	O
flexible	O
approximation	O
of	O
common	O
relations	O
in	O
real	O
world	O
KBs	O
.	O
	
Standard	O
matrix	B-Method
factorization	I-Method
approximates	O
by	O
a	O
matrix	B-Method
product	I-Method
,	O
where	O
and	O
are	O
two	O
functionally	O
independent	O
matrices	O
,	O
being	O
the	O
rank	O
of	O
the	O
matrix	O
.	O
	
Within	O
this	O
formulation	O
it	O
is	O
assumed	O
that	O
entities	O
appearing	O
as	O
subjects	O
are	O
different	O
from	O
entities	O
appearing	O
as	O
objects	O
.	O
	
This	O
means	O
that	O
the	O
same	O
entity	O
will	O
have	O
two	O
different	O
embedding	O
vectors	O
,	O
depending	O
on	O
whether	O
it	O
appears	O
as	O
the	O
subject	O
or	O
the	O
object	O
of	O
a	O
relation	O
.	O
	
This	O
extensively	O
studied	O
type	O
of	O
model	O
is	O
closely	O
related	O
to	O
the	O
singular	B-Method
value	I-Method
decomposition	I-Method
(	O
SVD	B-Method
)	O
and	O
fits	O
well	O
to	O
the	O
case	O
where	O
the	O
matrix	O
is	O
rectangular	O
.	O
	
However	O
,	O
in	O
many	O
link	B-Task
prediction	I-Task
problems	I-Task
,	O
the	O
same	O
entity	O
can	O
appear	O
as	O
both	O
subject	O
and	O
object	O
.	O
	
It	O
then	O
seems	O
natural	O
to	O
learn	O
joint	O
embeddings	O
of	O
the	O
entities	O
,	O
which	O
entails	O
sharing	O
the	O
embeddings	O
of	O
the	O
left	O
and	O
right	O
factors	O
,	O
as	O
proposed	O
by	O
several	O
authors	O
to	O
solve	O
the	O
link	B-Task
prediction	I-Task
problem	I-Task
.	O
	
In	O
order	O
to	O
use	O
the	O
same	O
embedding	O
for	O
subjects	O
and	O
objects	O
,	O
researchers	O
have	O
generalised	O
the	O
notion	O
of	O
dot	O
products	O
to	O
scoring	B-Method
functions	I-Method
,	O
also	O
known	O
as	O
composition	O
functions	O
,	O
that	O
combine	O
embeddings	O
in	O
specific	O
ways	O
.	O
	
We	O
briefly	O
recall	O
several	O
examples	O
of	O
scoring	B-Metric
functions	I-Metric
in	O
Table	O
[	O
reference	O
]	O
,	O
as	O
well	O
as	O
the	O
extension	O
proposed	O
in	O
this	O
paper	O
.	O
	
Using	O
the	O
same	O
embeddings	O
for	O
right	O
and	O
left	O
factors	O
boils	O
down	O
to	O
Eigenvalue	B-Method
decomposition	I-Method
:	O
It	O
is	O
often	O
used	O
to	O
approximate	O
real	O
symmetric	O
matrices	O
such	O
as	O
covariance	O
matrices	O
,	O
kernel	O
functions	O
and	O
distance	O
or	O
similarity	O
matrices	O
.	O
	
In	O
these	O
cases	O
all	O
eigenvalues	O
and	O
eigenvectors	O
live	O
in	O
the	O
real	O
space	O
and	O
is	O
orthogonal	O
:	O
.	O
	
We	O
are	O
in	O
this	O
work	O
however	O
explicitly	O
interested	O
in	O
problems	O
where	O
matrices	O
—	O
and	O
thus	O
the	O
relations	O
they	O
represent	O
—	O
can	O
also	O
be	O
antisymmetric	O
.	O
	
In	O
that	O
case	O
eigenvalue	B-Method
decomposition	I-Method
is	O
not	O
possible	O
in	O
the	O
real	O
space	O
;	O
there	O
only	O
exists	O
a	O
decomposition	O
in	O
the	O
complex	O
space	O
where	O
embeddings	O
are	O
composed	O
of	O
a	O
real	O
vector	O
component	O
and	O
an	O
imaginary	O
vector	O
component	O
.	O
	
With	O
complex	O
numbers	O
,	O
the	O
dot	O
product	O
,	O
also	O
called	O
the	O
Hermitian	O
product	O
,	O
or	O
sesquilinear	O
form	O
,	O
is	O
defined	O
as	O
:	O
where	O
and	O
are	O
complex	O
-	O
valued	O
vectors	O
,	O
i.e.	O
with	O
and	O
corresponding	O
to	O
the	O
real	O
and	O
imaginary	O
parts	O
of	O
the	O
vector	O
,	O
and	O
denoting	O
the	O
square	O
root	O
of	O
.	O
	
We	O
see	O
here	O
that	O
one	O
crucial	O
operation	O
is	O
to	O
take	O
the	O
conjugate	O
of	O
the	O
first	O
vector	O
:	O
.	O
	
A	O
simple	O
way	O
to	O
justify	O
the	O
Hermitian	O
product	O
for	O
composing	O
complex	O
vectors	O
is	O
that	O
it	O
provides	O
a	O
valid	O
topological	O
norm	O
in	O
the	O
induced	O
vectorial	O
space	O
.	O
	
For	O
example	O
,	O
implies	O
while	O
this	O
is	O
not	O
the	O
case	O
for	O
the	O
bilinear	O
form	O
as	O
there	O
are	O
many	O
complex	O
vectors	O
for	O
which	O
.	O
	
Even	O
with	O
complex	O
eigenvectors	O
,	O
the	O
inversion	O
of	O
in	O
the	O
eigendecomposition	B-Method
of	I-Method
Equation	I-Method
(	O
[	O
reference	O
]	O
)	O
leads	O
to	O
computational	O
issues	O
.	O
	
Fortunately	O
,	O
mathematicians	O
defined	O
an	O
appropriate	O
class	O
of	O
matrices	O
that	O
prevents	O
us	O
from	O
inverting	O
the	O
eigenvector	O
matrix	O
:	O
we	O
consider	O
the	O
space	O
of	O
normal	O
matrices	O
,	O
i.e.	O
the	O
complex	O
matrices	O
,	O
such	O
that	O
=	O
.	O
	
The	O
spectral	B-Method
theorem	I-Method
for	O
normal	O
matrices	O
states	O
that	O
a	O
matrix	O
is	O
normal	O
if	O
and	O
only	O
if	O
it	O
is	O
unitarily	O
diagonalizable	O
:	O
where	O
is	O
the	O
diagonal	O
matrix	O
of	O
eigenvalues	O
(	O
with	O
decreasing	O
modulus	O
)	O
and	O
is	O
a	O
unitary	O
matrix	O
of	O
eigenvectors	O
,	O
with	O
representing	O
its	O
complex	O
conjugate	O
.	O
	
The	O
set	O
of	O
purely	O
real	O
normal	O
matrices	O
includes	O
all	O
symmetric	O
and	O
antisymmetric	O
sign	O
matrices	O
(	O
useful	O
to	O
model	O
hierarchical	O
relations	O
such	O
as	O
IsOlder	O
)	O
,	O
as	O
well	O
as	O
all	O
orthogonal	O
matrices	O
(	O
including	O
permutation	O
matrices	O
)	O
,	O
and	O
many	O
other	O
matrices	O
that	O
are	O
useful	O
to	O
represent	O
binary	O
relations	O
,	O
such	O
as	O
assignment	B-Method
matrices	I-Method
which	O
represent	O
bipartite	O
graphs	O
.	O
	
However	O
,	O
far	O
from	O
all	O
matrices	O
expressed	O
as	O
are	O
purely	O
real	O
,	O
and	O
equation	O
[	O
reference	O
]	O
requires	O
the	O
scores	O
to	O
be	O
purely	O
real	O
.	O
	
So	O
we	O
simply	O
keep	O
only	O
the	O
real	O
part	O
of	O
the	O
decomposition	O
:	O
In	O
fact	O
,	O
performing	O
this	O
projection	O
on	O
the	O
real	O
subspace	O
allows	O
the	O
exact	O
decomposition	O
of	O
any	O
real	O
square	O
matrix	O
and	O
not	O
only	O
normal	O
ones	O
,	O
as	O
shown	O
by	O
.	O
	
Compared	O
to	O
the	O
singular	B-Method
value	I-Method
decomposition	I-Method
,	O
the	O
eigenvalue	B-Method
decomposition	I-Method
has	O
two	O
key	O
differences	O
:	O
The	O
eigenvalues	O
are	O
not	O
necessarily	O
positive	O
or	O
real	O
;	O
The	O
factorization	B-Method
(	O
[	O
reference	O
]	O
)	O
is	O
useful	O
as	O
the	O
rows	O
of	O
can	O
be	O
used	O
as	O
vectorial	B-Method
representations	I-Method
of	O
the	O
entities	O
corresponding	O
to	O
rows	O
and	O
columns	O
of	O
the	O
relation	O
matrix	O
.	O
	
Indeed	O
,	O
for	O
a	O
given	O
entity	O
,	O
its	O
subject	O
embedding	O
vector	O
is	O
the	O
complex	O
conjugate	O
of	O
its	O
object	O
embedding	O
vector	O
.	O
	
subsection	O
:	O
Low	B-Method
-	I-Method
Rank	I-Method
Decomposition	I-Method
	
In	O
a	O
link	B-Task
prediction	I-Task
problem	I-Task
,	O
the	O
relation	O
matrix	O
is	O
unknown	O
and	O
the	O
goal	O
is	O
to	O
recover	O
it	O
entirely	O
from	O
noisy	O
observations	O
.	O
	
To	O
enable	O
the	O
model	O
to	O
be	O
learnable	O
,	O
i.e.	O
to	O
generalize	O
to	O
unobserved	O
links	O
,	O
some	O
regularity	O
assumptions	O
are	O
needed	O
.	O
	
Since	O
we	O
deal	O
with	O
binary	O
relations	O
,	O
we	O
assume	O
that	O
they	O
have	O
low	O
sign	O
-	O
rank	O
.	O
	
The	O
sign	O
-	O
rank	O
of	O
a	O
sign	O
matrix	O
is	O
the	O
smallest	O
rank	O
of	O
a	O
real	O
matrix	O
that	O
has	O
the	O
same	O
sign	O
-	O
pattern	O
as	O
:	O
This	O
is	O
theoretically	O
justified	O
by	O
the	O
fact	O
that	O
the	O
sign	B-Metric
-	I-Metric
rank	I-Metric
is	O
a	O
natural	B-Metric
complexity	I-Metric
measure	I-Metric
of	O
sign	O
matrices	O
and	O
is	O
linked	O
to	O
learnability	B-Task
,	O
and	O
empirically	O
confirmed	O
by	O
the	O
wide	O
success	O
of	O
factorization	B-Method
models	I-Method
.	O
	
If	O
the	O
observation	O
matrix	O
is	O
low	O
-	O
sign	O
-	O
rank	O
,	O
then	O
our	O
model	O
can	O
decompose	O
it	O
with	O
a	O
rank	O
at	O
most	O
the	O
double	O
of	O
the	O
sign	O
-	O
rank	O
of	O
.	O
	
That	O
is	O
,	O
for	O
any	O
,	O
there	O
always	O
exists	O
a	O
matrix	O
with	O
the	O
same	O
sign	O
pattern	O
,	O
where	O
the	O
rank	O
of	O
is	O
at	O
most	O
twice	O
the	O
sign	O
-	O
rank	O
of	O
.	O
	
Although	O
twice	O
sounds	O
bad	O
,	O
this	O
is	O
actually	O
a	O
good	O
upper	O
bound	O
.	O
	
Indeed	O
,	O
the	O
sign	B-Metric
-	I-Metric
rank	I-Metric
is	O
often	O
much	O
lower	O
than	O
the	O
rank	O
of	O
.	O
	
For	O
example	O
,	O
the	O
rank	O
of	O
the	O
identity	O
matrix	O
is	O
,	O
but	O
.	O
	
By	O
permutation	O
of	O
the	O
columns	O
and	O
,	O
the	O
matrix	O
corresponds	O
to	O
the	O
relation	O
marriedTo	O
,	O
a	O
relation	O
known	O
to	O
be	O
hard	O
to	O
factorize	O
.	O
	
Yet	O
our	O
model	O
can	O
express	O
it	O
in	O
rank	O
6	O
,	O
for	O
any	O
.	O
	
By	O
imposing	O
a	O
low	O
-	O
rank	O
on	O
,	O
only	O
the	O
first	O
values	O
of	O
are	O
non	O
-	O
zero	O
.	O
	
So	O
we	O
can	O
directly	O
have	O
and	O
.	O
	
Individual	O
relation	O
scores	O
between	O
entities	O
and	O
can	O
be	O
predicted	O
through	O
the	O
following	O
product	O
of	O
their	O
embeddings	O
	
:	O
We	O
summarize	O
the	O
above	O
discussion	O
in	O
three	O
points	O
:	O
Our	O
factorization	O
encompasses	O
all	O
possible	O
binary	O
relations	O
.	O
	
By	O
construction	O
,	O
it	O
accurately	O
describes	O
both	O
symmetric	O
and	O
antisymmetric	O
relations	O
.	O
	
Learnable	O
relations	O
can	O
be	O
efficiently	O
approximated	O
by	O
a	O
simple	O
low	B-Method
-	I-Method
rank	I-Method
factorization	I-Method
,	O
using	O
complex	O
numbers	O
to	O
represent	O
the	O
latent	O
factors	O
.	O
	
section	O
:	O
Application	O
to	O
Binary	O
Multi	O
-	O
Relational	O
Data	O
	
The	O
previous	O
section	O
focused	O
on	O
modeling	O
a	O
single	O
type	O
of	O
relation	O
;	O
we	O
now	O
extend	O
this	O
model	O
to	O
multiple	O
types	O
of	O
relations	O
.	O
	
We	O
do	O
so	O
by	O
allocating	O
an	O
embedding	O
to	O
each	O
relation	O
,	O
and	O
by	O
sharing	O
the	O
entity	O
embeddings	O
across	O
all	O
relations	O
.	O
	
Let	O
and	O
be	O
the	O
set	O
of	O
relations	O
and	O
entities	O
present	O
in	O
the	O
KB	O
.	O
	
We	O
want	O
to	O
recover	O
the	O
matrices	O
of	O
scores	O
for	O
all	O
the	O
relations	O
.	O
	
Given	O
two	O
entities	O
and	O
,	O
the	O
log	O
-	O
odd	O
of	O
the	O
probability	O
that	O
the	O
fact	O
r	O
(	O
s	O
,	O
o	O
)	O
is	O
true	O
is	O
:	O
where	O
is	O
a	O
scoring	B-Method
function	I-Method
that	O
is	O
typically	O
based	O
on	O
a	O
factorization	O
of	O
the	O
observed	O
relations	O
and	O
denotes	O
the	O
parameters	O
of	O
the	O
corresponding	O
model	O
.	O
	
While	O
as	O
a	O
whole	O
is	O
unknown	O
,	O
we	O
assume	O
that	O
we	O
observe	O
a	O
set	O
of	O
true	O
and	O
false	O
facts	O
,	O
corresponding	O
to	O
the	O
partially	O
observed	O
adjacency	O
matrices	O
of	O
different	O
relations	O
,	O
where	O
is	O
the	O
set	O
of	O
observed	O
triples	O
.	O
	
The	O
goal	O
is	O
to	O
find	O
the	O
probabilities	O
of	O
entries	O
being	O
true	O
or	O
false	O
for	O
a	O
set	O
of	O
targeted	O
unobserved	O
triples	O
.	O
	
Depending	O
on	O
the	O
scoring	O
function	O
used	O
to	O
predict	O
the	O
entries	O
of	O
the	O
tensor	O
,	O
we	O
obtain	O
different	O
models	O
.	O
	
Examples	O
of	O
scoring	O
functions	O
are	O
given	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Our	O
model	B-Method
scoring	I-Method
function	I-Method
is	O
:	O
where	O
is	O
a	O
complex	O
vector	O
.	O
	
These	O
equations	O
provide	O
two	O
interesting	O
views	O
of	O
the	O
model	O
:	O
Changing	O
the	O
representation	O
:	O
Equation	O
(	O
[	O
reference	O
]	O
)	O
would	O
correspond	O
to	O
DistMult	B-Method
with	O
real	O
embeddings	O
,	O
but	O
handles	O
asymmetry	O
thanks	O
to	O
the	O
complex	O
conjugate	O
of	O
one	O
of	O
the	O
embeddings	O
.	O
	
Changing	O
the	O
scoring	O
function	O
:	O
Equation	O
(	O
[	O
reference	O
]	O
)	O
only	O
involves	O
real	O
vectors	O
corresponding	O
to	O
the	O
real	O
and	O
imaginary	O
parts	O
of	O
the	O
embeddings	O
and	O
relations	O
.	O
	
One	O
can	O
easily	O
check	O
that	O
this	O
function	O
is	O
antisymmetric	O
when	O
is	O
purely	O
imaginary	O
(	O
i.e.	O
its	O
real	O
part	O
is	O
zero	O
)	O
,	O
and	O
symmetric	O
when	O
is	O
real	O
.	O
	
Interestingly	O
,	O
by	O
separating	O
the	O
real	O
and	O
imaginary	O
part	O
of	O
the	O
relation	O
embedding	O
,	O
we	O
obtain	O
a	O
decomposition	O
of	O
the	O
relation	O
matrix	O
as	O
the	O
sum	O
of	O
a	O
symmetric	O
matrix	O
and	O
a	O
antisymmetric	O
matrix	O
.	O
	
Relation	O
embeddings	O
naturally	O
act	O
as	O
weights	O
on	O
each	O
latent	O
dimension	O
:	O
over	O
the	O
symmetric	O
,	O
real	O
part	O
of	O
,	O
and	O
over	O
the	O
antisymmetric	O
,	O
imaginary	O
part	O
of	O
.	O
	
Indeed	O
,	O
one	O
has	O
,	O
meaning	O
that	O
is	O
symmetric	O
,	O
while	O
is	O
antisymmetric	O
.	O
	
This	O
enables	O
us	O
to	O
accurately	O
describe	O
both	O
symmetric	O
and	O
antisymmetric	O
relations	O
between	O
pairs	O
of	O
entities	O
,	O
while	O
still	O
using	O
joint	B-Method
representations	I-Method
of	O
entities	O
,	O
whether	O
they	O
appear	O
as	O
subject	O
or	O
object	O
of	O
relations	O
.	O
	
Geometrically	O
,	O
each	O
relation	B-Method
embedding	I-Method
is	O
an	O
anisotropic	O
scaling	O
of	O
the	O
basis	O
defined	O
by	O
the	O
entity	B-Method
embeddings	I-Method
,	O
followed	O
by	O
a	O
projection	O
onto	O
the	O
real	O
subspace	O
.	O
	
section	O
:	O
Experiments	O
	
In	O
order	O
to	O
evaluate	O
our	O
proposal	O
,	O
we	O
conducted	O
experiments	O
on	O
both	O
synthetic	O
and	O
real	O
datasets	O
.	O
	
The	O
synthetic	O
dataset	O
is	O
based	O
on	O
relations	O
that	O
are	O
either	O
symmetric	O
or	O
antisymmetric	O
,	O
whereas	O
the	O
real	O
datasets	O
comprise	O
different	O
types	O
of	O
relations	O
found	O
in	O
different	O
,	O
standard	O
KBs	O
.	O
	
We	O
refer	O
to	O
our	O
model	O
as	O
ComplEx	B-Method
,	O
for	O
Complex	B-Method
Embeddings	I-Method
.	O
	
subsection	O
:	O
Synthetic	B-Task
Task	I-Task
	
To	O
assess	O
the	O
ability	O
of	O
our	O
proposal	O
to	O
accurately	O
model	O
symmetry	O
and	O
antisymmetry	O
,	O
we	O
randomly	O
generated	O
a	O
KB	O
of	O
two	O
relations	O
and	O
30	O
entities	O
.	O
	
One	O
relation	O
is	O
entirely	O
symmetric	O
,	O
while	O
the	O
other	O
is	O
completely	O
antisymmetric	O
.	O
	
This	O
dataset	O
corresponds	O
to	O
a	O
tensor	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
a	O
part	O
of	O
this	O
randomly	O
generated	O
tensor	O
,	O
with	O
a	O
symmetric	O
slice	O
and	O
an	O
antisymmetric	O
slice	O
,	O
decomposed	O
into	O
training	O
,	O
validation	O
and	O
test	O
sets	O
.	O
	
The	O
diagonal	O
is	O
unobserved	O
as	O
it	O
is	O
not	O
relevant	O
in	O
this	O
experiment	O
.	O
	
The	O
train	O
set	O
contains	O
1392	O
observed	O
triples	O
,	O
whereas	O
the	O
validation	O
and	O
test	O
sets	O
contain	O
174	O
triples	O
each	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
the	O
best	O
cross	B-Metric
-	I-Metric
validated	I-Metric
Average	I-Metric
Precision	I-Metric
(	O
area	B-Metric
under	I-Metric
Precision	I-Metric
-	I-Metric
Recall	I-Metric
curve	I-Metric
)	O
for	O
different	O
factorization	B-Method
models	I-Method
of	O
ranks	O
ranging	O
up	O
to	O
50	O
.	O
	
Models	O
were	O
trained	O
using	O
Stochastic	B-Method
Gradient	I-Method
Descent	I-Method
with	O
mini	B-Method
-	I-Method
batches	I-Method
and	O
AdaGrad	B-Method
for	O
tuning	O
the	O
learning	B-Metric
rate	I-Metric
,	O
by	O
minimizing	O
the	O
negative	O
log	O
-	O
likelihood	O
of	O
the	O
logistic	B-Method
model	I-Method
with	O
regularization	O
on	O
the	O
parameters	O
of	O
the	O
considered	O
model	O
:	O
In	O
our	O
model	O
,	O
corresponds	O
to	O
the	O
embeddings	O
.	O
	
We	O
describe	O
the	O
full	O
algorithm	O
in	O
Appendix	O
[	O
reference	O
]	O
.	O
is	O
validated	O
in	O
.	O
	
As	O
expected	O
,	O
DistMult	B-Method
is	O
not	O
able	O
to	O
model	O
antisymmetry	O
and	O
only	O
predicts	O
the	O
symmetric	O
relations	O
correctly	O
.	O
	
Although	O
TransE	B-Method
is	O
not	O
a	O
symmetric	B-Method
model	I-Method
,	O
it	O
performs	O
poorly	O
in	O
practice	O
,	O
particularly	O
on	O
the	O
antisymmetric	O
relation	O
.	O
	
RESCAL	B-Method
,	O
with	O
its	O
large	O
number	O
of	O
parameters	O
,	O
quickly	O
overfits	O
as	O
the	O
rank	O
grows	O
.	O
	
Canonical	B-Method
Polyadic	I-Method
(	O
CP	B-Method
)	O
decomposition	O
fails	O
on	O
both	O
relations	O
as	O
it	O
has	O
to	O
push	O
symmetric	O
and	O
antisymmetric	O
patterns	O
through	O
the	O
entity	O
embeddings	O
.	O
	
Surprisingly	O
,	O
only	O
our	O
model	O
succeeds	O
on	O
such	O
simple	O
data	O
.	O
	
subsection	O
:	O
Datasets	O
:	O
FB15	O
K	O
and	O
WN18	B-Material
	
We	O
next	O
evaluate	O
the	O
performance	O
of	O
our	O
model	O
on	O
the	O
FB15	O
K	O
and	O
WN18	B-Material
datasets	I-Material
.	O
	
FB15	O
K	O
is	O
a	O
subset	O
of	O
Freebase	O
,	O
a	O
curated	O
KB	O
of	O
general	O
facts	O
,	O
whereas	O
WN18	B-Material
is	O
a	O
subset	O
of	O
Wordnet	B-Material
,	O
a	O
database	O
featuring	O
lexical	O
relations	O
between	O
words	O
.	O
	
We	O
use	O
original	O
training	O
,	O
validation	O
and	O
test	O
set	O
splits	O
as	O
provided	O
by	O
.	O
	
Table	O
[	O
reference	O
]	O
summarizes	O
the	O
metadata	O
of	O
the	O
two	O
datasets	O
.	O
	
Both	O
datasets	O
contain	O
only	O
positive	O
triples	O
.	O
	
As	O
in	O
,	O
we	O
generated	O
negatives	O
using	O
the	O
local	O
closed	O
world	O
assumption	O
.	O
	
That	O
is	O
,	O
for	O
a	O
triple	O
,	O
we	O
randomly	O
change	O
either	O
the	O
subject	O
or	O
the	O
object	O
at	O
random	O
,	O
to	O
form	O
a	O
negative	O
example	O
.	O
	
This	O
negative	B-Method
sampling	I-Method
is	O
performed	O
at	O
runtime	O
for	O
each	O
batch	O
of	O
training	O
positive	O
examples	O
.	O
	
For	O
evaluation	O
,	O
we	O
measure	O
the	O
quality	O
of	O
the	O
ranking	B-Metric
of	O
each	O
test	O
triple	O
among	O
all	O
possible	O
subject	O
and	O
object	O
substitutions	O
:	O
and	O
,	O
.	O
	
Mean	B-Metric
Reciprocal	I-Metric
Rank	I-Metric
(	O
MRR	B-Metric
)	O
and	O
Hits	B-Metric
	
at	O
are	O
the	O
standard	O
evaluation	B-Metric
measures	I-Metric
for	O
these	O
datasets	O
and	O
come	O
in	O
two	O
flavours	O
:	O
raw	O
and	O
filtered	O
.	O
	
The	O
filtered	B-Metric
metrics	I-Metric
are	O
computed	O
after	O
removing	O
all	O
the	O
other	O
positive	O
observed	O
triples	O
that	O
appear	O
in	O
either	O
training	O
,	O
validation	O
or	O
test	O
set	O
from	O
the	O
ranking	B-Task
,	O
whereas	O
the	O
raw	O
metrics	O
do	O
not	O
remove	O
these	O
.	O
	
Since	O
ranking	B-Metric
measures	I-Metric
are	O
used	O
,	O
previous	O
studies	O
generally	O
preferred	O
a	O
pairwise	B-Metric
ranking	I-Metric
loss	I-Metric
for	O
the	O
task	O
.	O
	
We	O
chose	O
to	O
use	O
the	O
negative	O
log	O
-	O
likelihood	O
of	O
the	O
logistic	B-Method
model	I-Method
,	O
as	O
it	O
is	O
a	O
continuous	O
surrogate	O
of	O
the	O
sign	O
-	O
rank	O
,	O
and	O
has	O
been	O
shown	O
to	O
learn	O
compact	B-Method
representations	I-Method
for	O
several	O
important	O
relations	O
,	O
especially	O
for	O
transitive	O
relations	O
.	O
	
In	O
preliminary	O
work	O
,	O
we	O
tried	O
both	O
losses	O
,	O
and	O
indeed	O
the	O
log	B-Method
-	I-Method
likelihood	I-Method
yielded	O
better	O
results	O
than	O
the	O
ranking	B-Metric
loss	I-Metric
(	O
except	O
with	O
TransE	B-Method
)	O
,	O
especially	O
on	O
	
FB15K.	O
	
We	O
report	O
both	O
filtered	B-Metric
and	O
raw	B-Metric
MRR	I-Metric
,	O
and	O
filtered	O
Hits	B-Metric
at	I-Metric
1	I-Metric
,	O
3	B-Metric
and	O
10	B-Metric
in	O
Table	O
[	O
reference	O
]	O
for	O
the	O
evaluated	O
models	O
.	O
	
Furthermore	O
,	O
we	O
chose	O
TransE	O
,	O
DistMult	B-Method
and	O
HolE	B-Method
as	O
baselines	O
since	O
they	O
are	O
the	O
best	O
performing	O
models	O
on	O
those	O
datasets	O
to	O
the	O
best	O
of	O
our	O
knowledge	O
.	O
	
We	O
also	O
compare	O
with	O
the	O
CP	B-Method
model	O
to	O
emphasize	O
empirically	O
the	O
importance	O
of	O
learning	O
unique	O
embeddings	O
for	O
entities	O
.	O
	
For	O
experimental	O
fairness	O
,	O
we	O
reimplemented	O
these	O
methods	O
within	O
the	O
same	O
framework	O
as	O
the	O
ComplEx	B-Method
model	I-Method
,	O
using	O
theano	O
.	O
	
However	O
,	O
due	O
to	O
time	O
constraints	O
and	O
the	O
complexity	O
of	O
an	O
efficient	O
implementation	O
of	O
HolE	B-Method
,	O
we	O
record	O
the	O
original	O
results	O
for	O
HolE	B-Method
as	O
reported	O
in	O
.	O
	
subsection	O
:	O
Results	O
	
WN18	B-Material
describes	O
lexical	O
and	O
semantic	O
hierarchies	O
between	O
concepts	O
and	O
contains	O
many	O
antisymmetric	O
relations	O
such	O
as	O
hypernymy	O
,	O
hyponymy	O
,	O
or	O
being	O
”	O
part	O
of	O
”	O
.	O
	
Indeed	O
,	O
the	O
DistMult	B-Method
and	O
TransE	B-Method
models	I-Method
are	O
outperformed	O
here	O
by	O
ComplEx	B-Method
and	O
HolE	B-Method
,	O
which	O
are	O
on	O
par	O
with	O
respective	O
filtered	B-Metric
MRR	I-Metric
scores	I-Metric
of	O
0.941	O
and	O
0.938	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
filtered	O
test	O
set	O
MRR	B-Metric
for	O
the	O
models	O
considered	O
and	O
each	O
relation	O
of	O
WN18	B-Material
,	O
confirming	O
the	O
advantage	O
of	O
our	O
model	O
on	O
antisymmetric	O
relations	O
while	O
losing	O
nothing	O
on	O
the	O
others	O
.	O
	
2D	O
projections	O
of	O
the	O
relation	O
embeddings	O
provided	O
in	O
Appendix	O
[	O
reference	O
]	O
visually	O
corroborate	O
the	O
results	O
.	O
	
On	O
FB15	O
K	O
,	O
the	O
gap	O
is	O
much	O
more	O
pronounced	O
and	O
the	O
ComplEx	B-Method
model	I-Method
largely	O
outperforms	O
HolE	B-Method
,	O
with	O
a	O
filtered	B-Metric
MRR	I-Metric
of	O
0.692	O
and	O
59.9	O
%	O
of	O
Hits	B-Metric
at	I-Metric
1	I-Metric
,	O
compared	O
to	O
0.524	O
and	O
40.2	O
%	O
for	O
HolE.	B-Method
	
We	O
attribute	O
this	O
to	O
the	O
simplicity	O
of	O
our	O
model	O
and	O
the	O
different	O
loss	O
function	O
.	O
	
This	O
is	O
supported	O
by	O
the	O
relatively	O
small	O
gap	O
in	O
MRR	B-Metric
compared	O
to	O
DistMult	B-Method
(	O
0.654	O
)	O
;	O
our	O
model	O
can	O
in	O
fact	O
be	O
interpreted	O
as	O
a	O
complex	O
number	O
version	O
of	O
DistMult	B-Method
.	O
	
On	O
both	O
datasets	O
,	O
TransE	B-Method
and	O
CP	B-Method
are	O
largely	O
left	O
behind	O
.	O
	
This	O
illustrates	O
the	O
power	O
of	O
the	O
simple	O
dot	B-Method
product	I-Method
in	O
the	O
first	O
case	O
,	O
and	O
the	O
importance	O
of	O
learning	O
unique	O
entity	O
embeddings	O
in	O
the	O
second	O
.	O
	
CP	B-Method
performs	O
poorly	O
on	O
WN18	B-Material
due	O
to	O
the	O
small	O
number	O
of	O
relations	O
,	O
which	O
magnifies	O
this	O
subject	O
/	O
object	O
difference	O
.	O
	
Reported	O
results	O
are	O
given	O
for	O
the	O
best	O
set	O
of	O
hyper	O
-	O
parameters	O
evaluated	O
on	O
the	O
validation	O
set	O
for	O
each	O
model	O
,	O
after	O
grid	B-Method
search	I-Method
on	O
the	O
following	O
values	O
:	O
,	O
,	O
,	O
with	O
the	O
regularization	O
parameter	O
,	O
the	O
initial	O
learning	B-Metric
rate	I-Metric
(	O
then	O
tuned	O
at	O
runtime	O
with	O
AdaGrad	B-Method
)	O
,	O
and	O
the	O
number	O
of	O
negatives	O
generated	O
per	O
positive	O
training	O
triple	O
.	O
	
We	O
also	O
tried	O
varying	O
the	O
batch	O
size	O
but	O
this	O
had	O
no	O
impact	O
and	O
we	O
settled	O
with	O
100	O
batches	O
per	O
epoch	O
.	O
	
Best	O
ranks	O
were	O
generally	O
150	O
or	O
200	O
,	O
in	O
both	O
cases	O
scores	O
were	O
always	O
very	O
close	O
for	O
all	O
models	O
.	O
	
The	O
number	O
of	O
negative	O
samples	O
per	O
positive	O
sample	O
also	O
had	O
a	O
large	O
influence	O
on	O
the	O
filtered	O
MRR	B-Metric
on	O
FB15	O
K	O
(	O
up	O
to	O
+	O
0.08	O
improvement	O
from	O
1	O
to	O
10	B-Metric
negatives	O
)	O
,	O
but	O
not	O
much	O
on	O
WN18	B-Material
.	O
	
On	O
both	O
datasets	O
regularization	B-Task
was	O
important	O
(	O
up	O
to	O
+	O
0.05	O
on	O
filtered	B-Metric
MRR	I-Metric
between	O
and	O
optimal	O
one	O
)	O
.	O
	
We	O
found	O
the	O
initial	O
learning	B-Metric
rate	I-Metric
to	O
be	O
very	O
important	O
on	O
FB15	O
K	O
,	O
while	O
not	O
so	O
much	O
on	O
WN18	B-Material
.	O
	
We	O
think	O
this	O
may	O
also	O
explain	O
the	O
large	O
gap	O
of	O
improvement	O
our	O
model	O
provides	O
on	O
this	O
dataset	O
compared	O
to	O
previously	O
published	O
results	O
–	O
as	O
DistMult	B-Method
results	O
are	O
also	O
better	O
than	O
those	O
previously	O
reported	O
–	O
along	O
with	O
the	O
use	O
of	O
the	O
log	B-Method
-	I-Method
likelihood	I-Method
objective	I-Method
.	O
	
It	O
seems	O
that	O
in	O
general	O
AdaGrad	B-Method
is	O
relatively	O
insensitive	O
to	O
the	O
initial	O
learning	B-Metric
rate	I-Metric
,	O
perhaps	O
causing	O
some	O
overconfidence	O
in	O
its	O
ability	O
to	O
tune	O
the	O
step	O
size	O
online	O
and	O
consequently	O
leading	O
to	O
less	O
efforts	O
when	O
selecting	O
the	O
initial	O
step	O
size	O
.	O
	
Training	B-Task
was	O
stopped	O
using	O
early	O
stopping	O
on	O
the	O
validation	O
set	O
filtered	O
MRR	B-Metric
,	O
computed	O
every	O
50	O
epochs	O
with	O
a	O
maximum	O
of	O
1000	O
epochs	O
.	O
	
subsection	O
:	O
Influence	O
of	O
Negative	O
Samples	O
	
We	O
further	O
investigated	O
the	O
influence	O
of	O
the	O
number	O
of	O
negatives	O
generated	O
per	O
positive	O
training	O
sample	O
.	O
	
In	O
the	O
previous	O
experiment	O
,	O
due	O
to	O
computational	O
limitations	O
,	O
the	O
number	O
of	O
negatives	O
per	O
training	O
sample	O
,	O
,	O
was	O
validated	O
among	O
the	O
possible	O
numbers	O
.	O
	
We	O
want	O
to	O
explore	O
here	O
whether	O
increasing	O
these	O
numbers	O
could	O
lead	O
to	O
better	O
results	O
.	O
	
To	O
do	O
so	O
,	O
we	O
focused	O
on	O
FB15	O
K	O
,	O
with	O
the	O
best	O
validated	O
,	O
obtained	O
from	O
the	O
previous	O
experiment	O
.	O
	
We	O
then	O
let	O
vary	O
in	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
the	O
influence	O
of	O
the	O
number	O
of	O
generated	O
negatives	O
per	O
positive	O
training	O
triple	O
on	O
the	O
performance	O
of	O
our	O
model	O
on	O
FB15K.	O
Generating	O
more	O
negatives	O
clearly	O
improves	O
the	O
results	O
,	O
with	O
a	O
filtered	B-Metric
MRR	I-Metric
of	O
0.737	O
with	O
100	O
negative	O
triples	O
(	O
and	O
64.8	O
%	O
of	O
Hits@1	B-Metric
)	O
,	O
before	O
decreasing	O
again	O
with	O
200	O
negatives	O
.	O
	
The	O
model	O
also	O
converges	O
with	O
fewer	O
epochs	O
,	O
which	O
compensates	O
partially	O
for	O
the	O
additional	O
training	O
time	O
per	O
epoch	O
,	O
up	O
to	O
50	O
negatives	O
.	O
	
It	O
then	O
grows	O
linearly	O
as	O
the	O
number	O
of	O
negatives	O
increases	O
,	O
making	O
50	O
a	O
good	O
trade	O
-	O
off	O
between	O
accuracy	B-Metric
and	O
training	B-Metric
time	I-Metric
.	O
	
section	O
:	O
Related	O
Work	O
	
In	O
the	O
early	O
age	O
of	O
spectral	B-Method
theory	I-Method
in	O
linear	B-Task
algebra	I-Task
,	O
complex	O
numbers	O
were	O
not	O
used	O
for	O
matrix	B-Task
factorization	I-Task
and	O
mathematicians	O
mostly	O
focused	O
on	O
bi	O
-	O
linear	O
forms	O
.	O
	
The	O
eigen	B-Method
-	I-Method
decomposition	I-Method
in	O
the	O
complex	O
domain	O
as	O
taught	O
today	O
in	O
linear	B-Task
algebra	I-Task
courses	I-Task
came	O
40	O
years	O
later	O
.	O
	
Similarly	O
,	O
most	O
of	O
the	O
existing	O
approaches	O
for	O
tensor	B-Task
factorization	I-Task
were	O
based	O
on	O
decompositions	O
in	O
the	O
real	O
domain	O
,	O
such	O
as	O
the	O
Canonical	B-Method
Polyadic	I-Method
(	O
CP	B-Method
)	O
decomposition	O
.	O
	
These	O
methods	O
are	O
very	O
effective	O
in	O
many	O
applications	O
that	O
use	O
different	O
modes	O
of	O
the	O
tensor	O
for	O
different	O
types	O
of	O
entities	O
.	O
	
But	O
in	O
the	O
link	B-Task
prediction	I-Task
problem	I-Task
,	O
antisymmetry	B-Task
of	I-Task
relations	I-Task
was	O
quickly	O
seen	O
as	O
a	O
problem	O
and	O
asymmetric	O
extensions	O
of	O
tensors	O
were	O
studied	O
,	O
mostly	O
by	O
either	O
considering	O
independent	B-Method
embeddings	I-Method
or	O
considering	O
relations	O
as	O
matrices	O
instead	O
of	O
vectors	O
in	O
the	O
RESCAL	B-Method
model	I-Method
.	O
	
Direct	O
extensions	O
were	O
based	O
on	O
uni	O
-,	O
bi	O
-	O
and	O
trigram	O
latent	O
factors	O
for	O
triple	O
data	O
,	O
as	O
well	O
as	O
a	O
low	O
-	O
rank	O
relation	O
matrix	O
.	O
	
Pairwise	B-Method
interaction	I-Method
models	I-Method
were	O
also	O
considered	O
to	O
improve	O
prediction	B-Task
performances	O
.	O
	
For	O
example	O
,	O
the	O
Universal	B-Method
Schema	I-Method
approach	I-Method
factorizes	O
a	O
2D	B-Method
unfolding	I-Method
of	I-Method
the	I-Method
tensor	I-Method
(	O
a	O
matrix	O
of	O
entity	O
pairs	O
vs.	O
relations	O
)	O
while	O
extend	O
this	O
also	O
to	O
other	O
pairs	O
.	O
	
In	O
the	O
Neural	B-Method
Tensor	I-Method
Network	I-Method
(	O
NTN	B-Method
)	O
model	O
,	O
combine	O
linear	O
transformations	O
and	O
multiple	O
bilinear	O
forms	O
of	O
subject	O
and	O
object	O
embeddings	O
to	O
jointly	O
feed	O
them	O
into	O
a	O
nonlinear	B-Method
neural	I-Method
layer	I-Method
.	O
	
Its	O
non	O
-	O
linearity	O
and	O
multiple	O
ways	O
of	O
including	O
interactions	O
between	O
embeddings	O
gives	O
it	O
an	O
advantage	O
in	O
expressiveness	O
over	O
models	O
with	O
simpler	O
scoring	O
function	O
like	O
DistMult	B-Method
or	O
RESCAL	B-Method
.	O
	
As	O
a	O
downside	O
,	O
its	O
very	O
large	O
number	O
of	O
parameters	O
can	O
make	O
the	O
NTN	B-Method
model	O
harder	O
to	O
train	O
and	O
overfit	O
more	O
easily	O
.	O
	
The	O
original	O
multi	O
-	O
linear	O
DistMult	B-Method
model	O
is	O
symmetric	O
in	O
subject	O
and	O
object	O
for	O
every	O
relation	O
and	O
achieves	O
good	O
performance	O
,	O
presumably	O
due	O
to	O
its	O
simplicity	O
.	O
	
The	O
TransE	B-Method
model	I-Method
from	O
also	O
embeds	O
entities	O
and	O
relations	O
in	O
the	O
same	O
space	O
and	O
imposes	O
a	O
geometrical	O
structural	O
bias	O
into	O
the	O
model	O
:	O
the	O
subject	O
entity	O
vector	O
should	O
be	O
close	O
to	O
the	O
object	O
entity	O
vector	O
once	O
translated	O
by	O
the	O
relation	O
vector	O
.	O
	
A	O
recent	O
novel	O
way	O
to	O
handle	O
antisymmetry	O
is	O
via	O
the	O
Holographic	B-Method
Embeddings	I-Method
(	O
HolE	B-Method
)	O
model	O
by	O
.	O
	
In	O
HolE	B-Method
the	O
circular	O
correlation	O
is	O
used	O
for	O
combining	O
entity	O
embeddings	O
,	O
measuring	O
the	O
covariance	O
between	O
embeddings	O
at	O
different	O
dimension	O
shifts	O
.	O
	
This	O
generally	O
suggests	O
that	O
other	O
composition	O
functions	O
than	O
the	O
classical	O
tensor	B-Method
product	I-Method
can	O
be	O
helpful	O
as	O
they	O
allow	O
for	O
a	O
richer	O
interaction	O
of	O
embeddings	O
.	O
	
However	O
,	O
the	O
asymmetry	O
in	O
the	O
composition	O
function	O
in	O
HolE	B-Method
stems	O
from	O
the	O
asymmetry	O
of	O
circular	O
correlation	O
,	O
an	O
operation	O
,	O
whereas	O
ours	O
is	O
inherited	O
from	O
the	O
complex	O
inner	O
product	O
,	O
in	O
.	O
	
section	O
:	O
Conclusion	O
	
We	O
described	O
a	O
simple	O
approach	O
to	O
matrix	B-Task
and	I-Task
tensor	I-Task
factorization	I-Task
for	O
link	B-Task
prediction	I-Task
data	I-Task
that	O
uses	O
vectors	O
with	O
complex	O
values	O
and	O
retains	O
the	O
mathematical	O
definition	O
of	O
the	O
dot	O
product	O
.	O
	
The	O
class	B-Method
of	I-Method
normal	I-Method
matrices	I-Method
is	O
a	O
natural	O
fit	O
for	O
binary	O
relations	O
,	O
and	O
using	O
the	O
real	O
part	O
allows	O
for	O
efficient	O
approximation	O
of	O
any	O
learnable	O
relation	O
.	O
	
Results	O
on	O
standard	O
benchmarks	O
show	O
that	O
no	O
more	O
modifications	O
are	O
needed	O
to	O
improve	O
over	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
.	O
	
There	O
are	O
several	O
directions	O
in	O
which	O
this	O
work	O
can	O
be	O
extended	O
.	O
	
An	O
obvious	O
one	O
is	O
to	O
merge	O
our	O
approach	O
with	O
known	O
extensions	O
to	O
tensor	B-Method
factorization	I-Method
in	O
order	O
to	O
further	O
improve	O
predictive	B-Task
performance	O
.	O
	
For	O
example	O
,	O
the	O
use	O
of	O
pairwise	O
embeddings	O
together	O
with	O
complex	O
numbers	O
might	O
lead	O
to	O
improved	O
results	O
in	O
many	O
situations	O
that	O
involve	O
non	O
-	O
compositionality	O
.	O
	
Another	O
direction	O
would	O
be	O
to	O
develop	O
a	O
more	O
intelligent	O
negative	B-Method
sampling	I-Method
procedure	I-Method
,	O
to	O
generate	O
more	O
informative	O
negatives	O
with	O
respect	O
to	O
the	O
positive	O
sample	O
from	O
which	O
they	O
have	O
been	O
sampled	O
.	O
	
It	O
would	O
reduce	O
the	O
number	O
of	O
negatives	O
required	O
to	O
reach	O
good	O
performance	O
,	O
thus	O
accelerating	O
training	B-Metric
time	I-Metric
.	O
	
Also	O
,	O
if	O
we	O
were	O
to	O
use	O
complex	O
embeddings	O
every	O
time	O
a	O
model	O
includes	O
a	O
dot	O
product	O
,	O
e.g.	O
in	O
deep	B-Method
neural	I-Method
networks	I-Method
,	O
would	O
it	O
lead	O
to	O
a	O
similar	O
systematic	O
improvement	O
?	O
	
section	O
:	O
Acknowledgements	O
	
This	O
work	O
was	O
supported	O
in	O
part	O
by	O
the	O
Paul	O
Allen	O
Foundation	O
through	O
an	O
Allen	O
Distinguished	O
Investigator	O
grant	O
and	O
in	O
part	O
by	O
a	O
Google	O
Focused	O
Research	O
Award	O
.	O
	
bibliography	O
:	O
References	O
	
appendix	O
:	O
SGD	B-Method
algorithm	I-Method
	
We	O
describe	O
the	O
algorithm	O
to	O
learn	O
the	O
ComplEx	B-Method
model	I-Method
with	O
Stochastic	B-Method
Gradient	I-Method
Descent	I-Method
using	O
only	O
real	O
-	O
valued	O
vectors	O
.	O
	
Let	O
us	O
rewrite	O
equation	O
[	O
reference	O
]	O
,	O
by	O
denoting	O
the	O
real	O
part	O
of	O
embeddings	O
with	O
primes	O
and	O
the	O
imaginary	O
part	O
with	O
double	O
primes	O
:	O
,	O
,	O
,	O
.	O
	
The	O
set	O
of	O
parameters	O
is	O
,	O
and	O
the	O
scoring	B-Method
function	I-Method
involves	O
only	O
real	O
vectors	O
:	O
where	O
each	O
entity	O
and	O
each	O
relation	O
has	O
two	O
real	O
embeddings	O
.	O
	
Gradients	O
are	O
now	O
easy	O
to	O
write	O
:	O
where	O
is	O
the	O
element	O
-	O
wise	O
(	O
Hadamard	O
)	O
product	O
.	O
	
As	O
stated	O
in	O
equation	O
[	O
reference	O
]	O
we	O
use	O
the	O
sigmoid	O
link	O
function	O
,	O
and	O
minimize	O
the	O
-	O
regularized	O
negative	O
log	O
-	O
likelihood	O
:	O
To	O
handle	O
regularization	B-Task
,	O
note	O
that	O
the	O
squared	O
-	O
norm	O
of	O
a	O
complex	O
vector	O
is	O
the	O
sum	O
of	O
the	O
squared	O
modulus	O
of	O
each	O
entry	O
:	O
which	O
is	O
actually	O
the	O
sum	O
of	O
the	O
-	O
norms	O
of	O
the	O
vectors	O
of	O
the	O
real	O
and	O
imaginary	O
parts	O
.	O
	
We	O
can	O
finally	O
write	O
the	O
gradient	O
of	O
with	O
respect	O
to	O
a	O
real	O
embedding	O
for	O
one	O
triple	O
:	O
where	O
is	O
the	O
sigmoid	O
function	O
.	O
	
Algorithm	O
[	O
reference	O
]	O
describes	O
SGD	B-Method
for	O
this	O
formulation	O
of	O
the	O
scoring	O
function	O
.	O
	
When	O
contains	O
only	O
positive	O
triples	O
,	O
we	O
generate	O
negatives	O
per	O
positive	O
train	O
triple	O
,	O
by	O
corrupting	O
either	O
the	O
subject	O
or	O
the	O
object	O
of	O
the	O
positive	O
triple	O
,	O
as	O
described	O
in	O
.	O
	
[	O
t	O
]	O
SGD	B-Method
for	O
the	O
ComplEx	B-Method
model	I-Method
	
Training	O
set	O
,	O
Validation	O
set	O
,	O
learning	B-Metric
rate	I-Metric
,	O
embedding	O
dim	O
.	O
,	O
regularization	O
factor	O
,	O
negative	O
ratio	O
,	O
batch	O
size	O
,	O
max	O
iter	O
,	O
early	O
stopping	O
.	O
	
,	O
for	O
each	O
,	O
for	O
each	O
sample	O
Update	O
embeddings	O
w.r.t	O
.	O
	
:	O
Update	O
learning	B-Metric
rate	I-Metric
using	O
Adagrad	B-Method
break	O
if	O
filteredMRR	O
or	O
AP	O
on	O
decreased	O
	
appendix	O
:	O
WN18	B-Task
embeddings	I-Task
visualization	I-Task
	
We	O
used	O
principal	B-Method
component	I-Method
analysis	I-Method
(	O
PCA	B-Method
)	O
to	O
visualize	O
embeddings	O
of	O
the	O
relations	O
of	O
the	O
wordnet	B-Material
dataset	I-Material
(	O
WN18	B-Material
)	O
.	O
	
We	O
plotted	O
the	O
four	O
first	O
components	O
of	O
the	O
best	O
DistMult	B-Method
and	O
ComplEx	B-Method
model	I-Method
	
’s	O
embeddings	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
For	O
the	O
ComplEx	B-Method
model	I-Method
,	O
we	O
simply	O
concatenated	O
the	O
real	O
and	O
imaginary	O
parts	O
of	O
each	O
embedding	O
.	O
	
Most	O
of	O
WN18	B-Material
relations	O
describe	O
hierarchies	O
,	O
and	O
are	O
thus	O
antisymmetric	O
.	O
	
Each	O
of	O
these	O
hierarchic	O
relations	O
has	O
its	O
inverse	O
relation	O
in	O
the	O
dataset	O
.	O
	
For	O
example	O
:	O
hypernym	O
/	O
hyponym	O
,	O
part_of	O
/	O
has_part	O
,	O
synset_domain_topic_of	O
/	O
member_of_domain_topic	O
.	O
	
Since	O
DistMult	B-Method
is	O
unable	O
to	O
model	O
antisymmetry	O
,	O
it	O
will	O
correctly	O
represent	O
the	O
nature	O
of	O
each	O
pair	O
of	O
opposite	O
relations	O
,	O
but	O
not	O
the	O
direction	O
of	O
the	O
relations	O
.	O
	
Loosely	O
speaking	O
,	O
in	O
the	O
hypernym	O
/	O
hyponym	O
pair	O
the	O
nature	O
is	O
sharing	O
semantics	O
,	O
and	O
the	O
direction	O
is	O
that	O
one	O
entity	O
generalizes	O
the	O
semantics	O
of	O
the	O
other	O
.	O
	
This	O
makes	O
DistMult	B-Method
reprensenting	O
the	O
opposite	O
relations	O
with	O
very	O
close	O
embeddings	O
,	O
as	O
Figure	O
[	O
reference	O
]	O
shows	O
.	O
	
It	O
is	O
especially	O
striking	O
for	O
the	O
third	O
and	O
fourth	O
principal	O
component	O
(	O
bottom	O
-	O
left	O
)	O
.	O
	
Conversely	O
,	O
ComplEx	B-Method
manages	O
to	O
oppose	O
spatially	O
the	O
opposite	O
relations	O
.	O
	
document	O
:	O
A	O
Corpus	O
with	O
Multi	O
-	O
Level	O
Annotations	O
of	O
Patients	O
,	O
Interventions	O
and	O
Outcomes	O
to	O
Support	O
Language	B-Task
Processing	I-Task
for	O
Medical	O
Literature	O
	
We	O
present	O
a	O
corpus	O
of	O
5	O
,	O
000	O
richly	O
annotated	O
abstracts	O
of	O
medical	O
articles	O
describing	O
clinical	O
randomized	O
controlled	O
trials	O
.	O
	
Annotations	O
include	O
demarcations	O
of	O
text	O
spans	O
that	O
describe	O
the	O
Patient	O
population	O
enrolled	O
,	O
the	O
Interventions	O
studied	O
and	O
to	O
what	O
they	O
were	O
Compared	O
,	O
and	O
the	O
Outcomes	O
measured	O
(	O
the	O
‘	O
PICO	O
’	O
elements	O
)	O
.	O
	
These	O
spans	O
are	O
further	O
annotated	O
at	O
a	O
more	O
granular	O
level	O
,	O
e.g.	O
,	O
individual	O
interventions	O
within	O
them	O
are	O
marked	O
and	O
mapped	O
onto	O
a	O
structured	O
medical	O
vocabulary	O
.	O
	
We	O
acquired	O
annotations	O
from	O
a	O
diverse	O
set	O
of	O
workers	O
with	O
varying	O
levels	O
of	O
expertise	O
and	O
cost	O
.	O
	
We	O
describe	O
our	O
data	O
collection	O
process	O
and	O
the	O
corpus	O
itself	O
in	O
detail	O
.	O
	
We	O
then	O
outline	O
a	O
set	O
of	O
challenging	O
NLP	B-Task
tasks	I-Task
that	O
would	O
aid	O
searching	O
of	O
the	O
medical	O
literature	O
and	O
the	O
practice	O
of	O
evidence	B-Task
-	I-Task
based	I-Task
medicine	I-Task
.	O
	
section	O
:	O
Introduction	O
	
In	O
2015	O
alone	O
,	O
about	O
100	O
manuscripts	O
describing	O
randomized	O
controlled	O
trials	O
(	O
RCTs	O
)	O
for	O
medical	B-Task
interventions	I-Task
were	O
published	O
every	O
day	O
.	O
	
It	O
is	O
thus	O
practically	O
impossible	O
for	O
physicians	O
to	O
know	O
which	O
is	O
the	O
best	O
medical	O
intervention	O
for	O
a	O
given	O
patient	O
group	O
and	O
condition	O
.	O
	
This	O
inability	O
to	O
easily	O
search	O
and	O
organize	O
the	O
published	O
literature	O
impedes	O
the	O
aims	O
of	O
evidence	B-Task
based	I-Task
medicine	I-Task
(	O
EBM	B-Task
)	I-Task
,	O
which	O
aspires	O
to	O
inform	O
patient	B-Task
care	I-Task
using	O
the	O
totality	O
of	O
relevant	O
evidence	O
.	O
	
Computational	B-Method
methods	I-Method
could	O
expedite	O
biomedical	B-Task
evidence	I-Task
synthesis	I-Task
and	O
natural	B-Task
language	I-Task
processing	I-Task
(	O
NLP	B-Task
)	O
in	O
particular	O
can	O
play	O
a	O
key	O
role	O
in	O
the	O
task	O
.	O
	
Prior	O
work	O
has	O
explored	O
the	O
use	O
of	O
NLP	B-Method
methods	I-Method
to	O
automate	O
biomedical	B-Task
evidence	I-Task
extraction	I-Task
and	I-Task
synthesis	I-Task
.	O
	
But	O
the	O
area	O
has	O
attracted	O
less	O
attention	O
than	O
it	O
might	O
from	O
the	O
NLP	B-Task
community	I-Task
,	O
due	O
primarily	O
to	O
a	O
dearth	O
of	O
publicly	O
available	O
,	O
annotated	O
corpora	O
with	O
which	O
to	O
train	O
and	O
evaluate	O
models	O
.	O
	
Here	O
we	O
address	O
this	O
gap	O
by	O
introducing	O
EBM	B-Material
-	I-Material
NLP	I-Material
,	O
a	O
new	O
corpus	O
to	O
power	O
NLP	B-Method
models	I-Method
in	O
support	O
of	O
EBM	B-Task
.	O
	
The	O
corpus	O
,	O
accompanying	O
documentation	O
,	O
baseline	O
model	B-Method
implementations	I-Method
for	O
the	O
proposed	O
tasks	O
,	O
and	O
all	O
code	O
are	O
publicly	O
available	O
.	O
	
EBM	B-Material
-	I-Material
NLP	I-Material
comprises	O
5	O
,	O
000	O
medical	O
abstracts	O
describing	O
clinical	O
trials	O
,	O
multiply	O
annotated	O
in	O
detail	O
with	O
respect	O
to	O
characteristics	O
of	O
the	O
underlying	O
trial	O
Populations	O
(	O
e.g.	O
,	O
diabetics	O
)	O
,	O
Interventions	O
(	O
insulin	O
)	O
,	O
Comparators	O
(	O
placebo	O
)	O
and	O
Outcomes	O
(	O
blood	O
glucose	O
levels	O
)	O
.	O
	
Collectively	O
,	O
these	O
key	O
informational	O
pieces	O
are	O
referred	O
to	O
as	O
PICO	O
elements	O
;	O
they	O
form	O
the	O
basis	O
for	O
well	B-Task
-	I-Task
formed	I-Task
clinical	I-Task
questions	I-Task
.	O
	
We	O
adopt	O
a	O
hybrid	B-Method
crowdsourced	I-Method
labeling	I-Method
strategy	I-Method
using	O
heterogeneous	O
annotators	O
with	O
varying	O
expertise	O
and	O
cost	O
,	O
from	O
laypersons	O
to	O
MDs	O
.	O
	
Annotators	B-Method
were	O
first	O
tasked	O
with	O
marking	O
text	O
spans	O
that	O
described	O
the	O
respective	O
PICO	O
elements	O
.	O
	
Identified	O
spans	O
were	O
subsequently	O
annotated	O
in	O
greater	O
detail	O
:	O
this	O
entailed	O
finer	O
-	O
grained	O
labeling	O
of	O
PICO	O
elements	O
and	O
mapping	O
these	O
onto	O
a	O
normalized	O
vocabulary	O
,	O
and	O
indicating	O
redundancy	O
in	O
the	O
mentions	O
of	O
PICO	O
elements	O
.	O
	
In	O
addition	O
,	O
we	O
outline	O
several	O
NLP	B-Task
tasks	I-Task
that	O
would	O
directly	O
support	O
the	O
practice	O
of	O
EBM	B-Task
and	O
that	O
may	O
be	O
explored	O
using	O
the	O
introduced	O
resource	O
.	O
	
We	O
present	O
baseline	O
models	O
and	O
associated	O
results	O
for	O
these	O
tasks	O
.	O
	
section	O
:	O
Related	O
Work	O
	
We	O
briefly	O
review	O
two	O
lines	O
of	O
research	O
relevant	O
to	O
the	O
current	O
effort	O
:	O
work	O
on	O
NLP	B-Method
to	O
facilitate	O
EBM	B-Task
,	O
and	O
research	O
in	O
crowdsourcing	B-Method
for	O
NLP	B-Task
.	O
	
subsection	O
:	O
NLP	B-Method
for	O
EBM	B-Task
	
Prior	O
work	O
on	O
NLP	B-Method
for	O
EBM	B-Task
has	O
been	O
limited	O
by	O
the	O
availability	O
of	O
only	O
small	O
corpora	O
,	O
which	O
have	O
typically	O
provided	O
on	O
the	O
order	O
of	O
a	O
couple	O
hundred	O
annotated	O
abstracts	O
or	O
articles	O
for	O
very	O
complex	O
information	B-Task
extraction	I-Task
tasks	I-Task
.	O
	
For	O
example	O
,	O
the	O
ExaCT	O
system	O
applies	O
rules	O
to	O
extract	O
21	O
aspects	O
of	O
the	O
reported	O
trial	O
.	O
	
It	O
was	O
developed	O
and	O
validated	O
on	O
a	O
dataset	O
of	O
182	O
marked	O
full	O
-	O
text	O
articles	O
.	O
	
The	O
ACRES	B-Method
system	I-Method
produces	O
summaries	O
of	O
several	O
trial	O
characteristic	O
,	O
and	O
was	O
trained	O
on	O
263	O
annotated	O
abstracts	O
.	O
	
Hinting	O
at	O
more	O
challenging	O
tasks	O
that	O
can	O
build	O
upon	O
foundational	B-Method
information	I-Method
extraction	I-Method
,	O
Alamri	O
and	O
Stevenson	O
alamri2015automatic	O
developed	O
methods	O
for	O
detecting	B-Task
contradictory	I-Task
claims	I-Task
in	O
biomedical	O
papers	O
.	O
	
Their	O
corpus	O
of	O
annotated	O
claims	O
contains	O
259	O
sentences	O
.	O
	
Larger	O
corpora	O
for	O
EBM	B-Task
tasks	I-Task
have	O
been	O
derived	O
using	O
(	O
noisy	O
)	O
automated	O
annotation	B-Task
approaches	O
.	O
	
This	O
approach	O
has	O
been	O
used	O
to	O
build	O
,	O
e.g.	O
,	O
datasets	O
to	O
facilitate	O
work	O
on	O
Information	B-Method
Retrieval	I-Method
(	I-Method
IR	I-Method
)	I-Method
models	I-Method
for	O
biomedical	B-Task
texts	I-Task
.	O
	
Similar	O
approaches	O
have	O
been	O
used	O
to	O
‘	O
distantly	O
supervise	O
’	O
annotation	B-Task
of	O
full	B-Task
-	I-Task
text	I-Task
articles	I-Task
describing	O
clinical	O
trials	O
.	O
	
In	O
contrast	O
to	O
the	O
corpora	O
discussed	O
above	O
,	O
these	O
automatically	O
derived	O
datasets	O
tend	O
to	O
be	O
relatively	O
large	O
,	O
but	O
they	O
include	O
only	O
shallow	O
annotations	O
.	O
	
Other	O
work	O
attempts	O
to	O
bypass	O
basic	O
extraction	B-Task
tasks	I-Task
and	O
address	O
more	O
complex	O
biomedical	B-Task
QA	I-Task
and	O
	
(	O
multi	B-Task
-	I-Task
document	I-Task
)	I-Task
summarization	I-Task
problems	I-Task
to	O
support	O
EBM	B-Task
.	O
	
Such	O
systems	O
would	O
directly	O
benefit	O
from	O
more	O
accurate	O
extraction	O
of	O
the	O
types	O
codified	O
in	O
the	O
corpus	O
we	O
present	O
here	O
.	O
	
subsection	O
:	O
Crowdsourcing	O
	
Crowdsourcing	B-Method
,	O
which	O
we	O
here	O
define	O
operationally	O
as	O
the	O
use	O
of	O
distributed	O
lay	O
annotators	O
,	O
has	O
shown	O
encouraging	O
results	O
in	O
NLP	B-Method
.	O
	
Such	O
annotations	O
are	O
typically	O
imperfect	O
,	O
but	O
methods	O
that	O
aggregate	O
redundant	O
annotations	O
can	O
mitigate	O
this	O
problem	O
.	O
	
Medical	O
articles	O
contain	O
relatively	O
technical	O
content	O
,	O
which	O
intuitively	O
may	O
be	O
difficult	O
for	O
persons	O
without	O
domain	O
expertise	O
to	O
annotate	O
.	O
	
However	O
,	O
recent	O
promising	O
preliminary	O
work	O
has	O
found	O
that	O
crowdsourced	B-Method
approaches	I-Method
can	O
yield	O
surprisingly	O
high	O
-	O
quality	O
annotations	O
in	O
the	O
domain	O
of	O
EBM	B-Task
specifically	I-Task
.	O
	
section	O
:	O
Data	O
Collection	O
	
PubMed	O
provides	O
access	O
to	O
the	O
MEDLINE	O
database	O
which	O
indexes	O
titles	O
,	O
abstracts	O
and	O
meta	O
-	O
data	O
for	O
articles	O
from	O
selected	O
medical	O
journals	O
dating	O
back	O
to	O
the	O
1970s	O
.	O
	
MEDLINE	O
indexes	O
over	O
24	O
million	O
abstracts	O
;	O
the	O
majority	O
of	O
these	O
	
have	O
been	O
manually	O
assigned	O
metadata	O
which	O
we	O
used	O
to	O
retrieved	O
a	O
set	O
of	O
5	O
,	O
000	O
articles	O
describing	O
RCTs	O
with	O
an	O
emphasis	O
on	O
cardiovascular	O
diseases	O
,	O
cancer	O
,	O
and	O
autism	O
.	O
	
These	O
particular	O
topics	O
were	O
selected	O
to	O
cover	O
a	O
range	O
of	O
common	O
conditions	O
.	O
	
We	O
decomposed	O
the	O
annotation	B-Task
process	O
into	O
two	O
steps	O
,	O
performed	O
in	O
sequence	O
.	O
	
First	O
,	O
we	O
acquired	O
labels	O
demarcating	O
spans	O
in	O
the	O
text	O
describing	O
the	O
clinically	O
salient	O
abstract	O
elements	O
mentioned	O
above	O
:	O
the	O
trial	O
Population	O
,	O
the	O
Interventions	O
and	O
Comparators	O
studied	O
,	O
and	O
the	O
Outcomes	O
measured	O
.	O
	
We	O
collapse	O
Interventions	O
and	O
Comparators	O
into	O
a	O
single	O
category	O
(	O
I	O
)	O
.	O
	
In	O
the	O
second	O
annotation	B-Task
step	O
,	O
we	O
tasked	O
workers	O
with	O
providing	O
more	O
granular	O
(	O
sub	O
-	O
span	O
)	O
annotations	O
on	O
these	O
spans	O
.	O
	
For	O
each	O
PIO	O
element	O
,	O
all	O
abstracts	O
were	O
annotated	O
with	O
the	O
following	O
four	O
types	O
of	O
information	O
.	O
	
Spans	O
exhaustive	O
marking	O
of	O
text	O
spans	O
containing	O
information	O
relevant	O
to	O
the	O
respective	O
PIO	O
categories	O
(	O
Stage	O
1	O
annotation	B-Task
)	O
.	O
	
Hierarchical	B-Task
labels	I-Task
assignment	I-Task
of	O
more	O
specific	O
labels	O
to	O
subsequences	O
comprising	O
the	O
marked	O
relevant	O
spans	O
(	O
Stage	O
2	O
annotation	B-Task
)	O
.	O
	
Repetition	B-Method
grouping	I-Method
of	O
labeled	O
tokens	O
to	O
indicate	O
repeated	O
occurrences	O
of	O
the	O
same	O
information	O
(	O
Stage	O
2	O
annotation	B-Task
)	O
.	O
	
MeSH	O
terms	O
assignment	O
of	O
the	O
metadata	O
MeSH	O
terms	O
associated	O
with	O
the	O
abstract	O
to	O
labeled	O
subsequences	O
(	O
Stage	O
2	O
annotation	B-Task
)	O
.	O
	
We	O
collected	O
annotations	O
for	O
each	O
P	O
,	O
I	O
and	O
O	O
element	O
individually	O
to	O
avoid	O
the	O
cognitive	O
load	O
imposed	O
by	O
switching	O
between	O
label	O
sets	O
,	O
and	O
to	O
reduce	O
the	O
amount	O
of	O
instruction	O
required	O
to	O
begin	O
the	O
task	O
.	O
	
All	O
annotation	B-Task
was	O
performed	O
using	O
a	O
modified	O
version	O
of	O
the	O
Brat	B-Method
Rapid	I-Method
Annotation	I-Method
Tool	O
(	O
BRAT	B-Method
)	O
stenetorp2012brat	O
.	O
	
We	O
include	O
all	O
annotation	B-Task
instructions	O
provided	O
to	O
workers	O
for	O
all	O
tasks	O
in	O
the	O
Appendix	O
.	O
	
subsection	O
:	O
Non	O
-	O
Expert	O
(	O
Layperson	O
)	O
Workers	O
	
For	O
large	B-Task
scale	I-Task
crowdsourcing	I-Task
via	O
recruitment	B-Task
of	I-Task
layperson	I-Task
annotators	I-Task
,	O
we	O
used	O
Amazon	B-Method
Mechanical	I-Method
Turk	I-Method
(	O
AMT	B-Method
)	O
.	O
	
All	O
workers	O
were	O
required	O
to	O
have	O
an	O
overall	O
job	B-Metric
approval	I-Metric
rate	I-Metric
of	O
at	O
least	O
90	O
%	O
.	O
	
Each	O
job	O
presented	O
to	O
the	O
workers	O
required	O
the	O
annotation	B-Task
of	O
three	O
randomly	O
selected	O
abstracts	O
from	O
our	O
pool	O
of	O
documents	O
.	O
	
As	O
we	O
received	O
initial	O
results	O
,	O
we	O
blocked	O
workers	O
who	O
were	O
clearly	O
not	O
following	O
instructions	O
,	O
and	O
we	O
actively	O
recruited	O
the	O
best	O
workers	O
to	O
continue	O
working	O
on	O
our	O
task	O
at	O
a	O
higher	O
pay	O
rate	O
.	O
	
We	O
began	O
by	O
collecting	O
the	O
least	O
technical	O
annotations	O
,	O
moving	O
on	O
to	O
more	O
difficult	O
tasks	O
only	O
after	O
restricting	O
our	O
pool	O
of	O
workers	O
to	O
those	O
with	O
a	O
demonstrated	O
aptitude	O
for	O
the	O
jobs	O
.	O
	
We	O
obtained	O
annotations	O
from	O
different	O
workers	O
for	O
each	O
of	O
the	O
5	O
,	O
000	O
abstracts	O
to	O
enable	O
robust	O
inference	O
of	O
reliable	O
labels	O
from	O
noisy	O
data	O
.	O
	
After	O
performing	O
filtering	B-Method
passes	I-Method
to	O
remove	O
non	O
-	O
RCT	O
documents	O
or	O
those	O
missing	O
relevant	O
data	O
for	O
the	O
second	O
annotation	B-Task
task	O
,	O
we	O
are	O
left	O
with	O
between	O
4	O
,	O
000	O
and	O
5	O
,	O
000	O
sets	O
of	O
annotations	O
for	O
each	O
PIO	O
element	O
after	O
the	O
second	O
phase	O
of	O
annotation	B-Task
.	O
	
subsection	O
:	O
Expert	O
Workers	O
	
To	O
supplement	O
our	O
larger	O
-	O
scale	O
data	O
collection	O
via	O
AMT	B-Method
,	O
we	O
collected	O
annotations	O
for	O
200	O
abstracts	O
for	O
each	O
PIO	O
element	O
from	O
workers	O
with	O
advanced	O
medical	O
training	O
.	O
	
The	O
idea	O
is	O
for	O
these	O
to	O
serve	O
as	O
reference	O
annotations	O
,	O
i.e.	O
,	O
a	O
test	O
set	O
with	O
which	O
to	O
evaluate	O
developed	O
NLP	B-Method
systems	I-Method
.	O
	
We	O
plan	O
to	O
enlarge	O
this	O
test	O
set	O
in	O
the	O
near	O
future	O
,	O
at	O
which	O
point	O
we	O
will	O
update	O
the	O
website	O
accordingly	O
.	O
	
For	O
the	O
initial	O
span	B-Task
labeling	I-Task
task	I-Task
,	O
two	O
medical	O
students	O
from	O
the	O
University	O
of	O
Pennsylvania	O
and	O
Drexel	O
University	O
provided	O
the	O
reference	O
labels	O
.	O
	
In	O
addition	O
,	O
for	O
both	O
stages	O
of	O
annotation	B-Task
and	O
for	O
the	O
detailed	O
subspan	O
annotation	B-Task
in	O
Stage	O
2	O
,	O
we	O
hired	O
three	O
medical	O
professionals	O
via	O
Upwork	B-Method
,	O
an	O
online	B-Method
platform	I-Method
for	O
hiring	O
skilled	O
freelancers	O
.	O
	
After	O
reviewing	O
several	O
dozen	O
suggested	O
profiles	O
,	O
we	O
selected	O
three	O
workers	O
that	O
had	O
the	O
following	O
characteristics	O
:	O
Advanced	O
medical	O
training	O
(	O
the	O
majority	O
of	O
hired	O
workers	O
were	O
Medical	O
Doctors	O
,	O
the	O
one	O
exception	O
being	O
a	O
fourth	O
-	O
year	O
medical	O
student	O
)	O
;	O
Strong	O
technical	O
reading	O
and	O
writing	O
skills	O
;	O
And	O
an	O
interest	O
in	O
medical	B-Task
research	I-Task
.	O
	
In	O
addition	O
to	O
providing	O
high	O
-	O
quality	O
annotations	O
,	O
individuals	O
hired	O
via	O
Upwork	O
also	O
provided	O
feedback	O
regarding	O
the	O
instructions	O
to	O
help	O
make	O
the	O
task	O
as	O
clear	O
as	O
possible	O
for	O
the	O
AMT	B-Method
workers	I-Method
.	O
	
section	O
:	O
The	O
Corpus	O
	
We	O
now	O
present	O
corpus	O
details	O
,	O
paying	O
special	O
attention	O
to	O
worker	O
performance	O
and	O
agreement	B-Metric
.	O
	
We	O
discuss	O
and	O
present	O
statistics	O
for	O
acquired	O
annotations	O
on	O
spans	O
,	O
tokens	O
,	O
repetition	O
and	O
MeSH	O
terms	O
in	O
Sections	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
,	O
and	O
[	O
reference	O
]	O
,	O
respectively	O
.	O
	
subsection	O
:	O
Spans	O
	
For	O
each	O
P	O
,	O
I	O
and	O
O	O
element	O
,	O
workers	O
were	O
asked	O
to	O
read	O
the	O
abstract	O
and	O
highlight	O
all	O
spans	O
of	O
text	O
including	O
any	O
pertinent	O
information	O
.	O
	
Annotations	O
for	O
5	O
,	O
000	O
articles	O
were	O
collected	O
from	O
a	O
total	O
of	O
579	O
AMT	O
workers	O
across	O
the	O
three	O
annotation	B-Task
types	O
,	O
and	O
expert	O
annotations	O
were	O
collected	O
for	O
200	O
articles	O
from	O
two	O
medical	O
students	O
.	O
	
We	O
first	O
evaluate	O
the	O
quality	O
of	O
the	O
annotations	O
by	O
calculating	O
token	B-Metric
-	I-Metric
wise	I-Metric
label	I-Metric
agreement	I-Metric
between	O
the	O
expert	O
annotators	O
;	O
this	O
is	O
reported	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Due	O
to	O
the	O
difficulty	O
and	O
technicality	O
of	O
the	O
material	O
,	O
agreement	O
between	O
even	O
well	O
-	O
trained	O
domain	B-Method
experts	I-Method
is	O
imperfect	O
.	O
	
The	O
effect	O
is	O
magnified	O
by	O
the	O
unreliability	O
of	O
AMT	B-Method
workers	I-Method
,	O
motivating	O
our	O
strategy	O
of	O
collecting	O
several	O
noisy	O
annotations	O
and	O
aggregating	O
over	O
them	O
to	O
produce	O
a	O
single	O
cleaner	O
annotation	B-Task
.	O
	
We	O
tested	O
three	O
different	O
aggregation	B-Method
strategies	I-Method
:	O
a	O
simple	O
majority	B-Method
vote	I-Method
,	O
the	O
Dawid	B-Method
-	I-Method
Skene	I-Method
model	I-Method
which	O
estimates	O
worker	B-Task
reliability	I-Task
,	O
and	O
HMMCrowd	B-Method
,	O
a	O
recent	O
extension	O
to	O
Dawid	O
-	O
Skene	O
that	O
includes	O
a	O
HMM	B-Method
component	I-Method
,	O
thus	O
explicitly	O
leveraging	O
the	O
sequential	O
structure	O
of	O
contiguous	O
spans	O
of	O
words	O
nguyen2017aggregating	O
.	O
	
For	O
each	O
aggregation	B-Method
strategy	I-Method
,	O
we	O
compute	O
the	O
token	B-Metric
-	I-Metric
wise	I-Metric
precision	I-Metric
and	I-Metric
recall	I-Metric
of	O
the	O
output	O
labels	O
against	O
the	O
unioned	O
expert	O
labels	O
.	O
	
As	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
,	O
the	O
HMMCrowd	B-Method
model	I-Method
afforded	O
modest	O
improvement	O
in	O
F	B-Metric
-	I-Metric
1	I-Metric
scores	I-Metric
over	O
the	O
standard	O
Dawid	B-Method
-	I-Method
Skene	I-Method
model	I-Method
,	O
and	O
was	O
thus	O
used	O
to	O
generate	O
the	O
inputs	O
for	O
the	O
second	O
annotation	B-Task
phase	O
.	O
	
The	O
limited	O
overlap	O
in	O
the	O
document	O
subsets	O
annotated	O
by	O
any	O
given	O
pair	O
of	O
workers	O
,	O
and	O
wide	O
variation	O
in	O
the	O
number	O
of	O
annotations	O
per	O
worker	O
make	O
interpretation	O
of	O
standard	O
agreement	B-Metric
statistics	I-Metric
tricky	O
.	O
	
We	O
quantify	O
the	O
centrality	O
of	O
the	O
AMT	O
span	O
annotations	O
by	O
calculating	O
token	B-Metric
-	I-Metric
wise	I-Metric
precision	I-Metric
and	O
recall	B-Metric
for	O
each	O
annotation	B-Task
against	O
the	O
aggregated	O
version	O
of	O
the	O
labels	O
(	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
When	O
comparing	O
the	O
average	B-Metric
precision	I-Metric
and	O
recall	B-Metric
for	O
individual	O
crowdworkers	O
against	O
the	O
aggregated	O
labels	O
in	O
Table	O
[	O
reference	O
]	O
,	O
scores	O
are	O
poor	O
showing	O
very	O
low	O
agreement	O
between	O
the	O
workers	O
.	O
	
Despite	O
this	O
,	O
the	O
aggregated	O
labels	O
compare	O
favorably	O
against	O
the	O
expert	O
labels	O
.	O
	
This	O
further	O
supports	O
the	O
intuition	O
that	O
it	O
is	O
feasible	O
to	O
collect	O
multiple	O
low	O
-	O
quality	O
annotations	O
for	O
a	O
document	O
and	O
synthesize	O
them	O
to	O
extract	O
the	O
signal	O
from	O
the	O
noise	O
.	O
	
On	O
the	O
dataset	O
website	O
,	O
we	O
provide	O
a	O
variant	O
of	O
the	O
corpus	O
that	O
includes	O
all	O
individual	O
worker	O
span	O
annotations	O
(	O
e.g.	O
,	O
for	O
researchers	O
interested	O
in	O
crowd	O
annotation	B-Task
aggregated	O
methods	O
)	O
,	O
and	O
also	O
a	O
version	O
with	O
pre	O
-	O
aggregated	O
annotations	O
for	O
convenience	O
.	O
	
subsection	O
:	O
Hierarchical	O
Labels	O
	
Outcomes	O
Physical	O
Health	O
Pain	O
Adverse	O
Effects	O
Mortality	O
Mental	O
/	O
Behavioral	O
Impact	O
Mental	O
Health	O
Participant	O
Behavior	O
Satisfaction	O
	
With	O
Care	O
Non	O
-	O
health	O
Outcome	O
Quality	O
of	O
Intervention	O
Resource	O
Use	O
Withdrawals	O
from	O
Study	O
For	O
each	O
P	O
,	O
I	O
,	O
and	O
	
O	O
category	O
we	O
developed	O
a	O
hierarchy	O
of	O
labels	O
intended	O
to	O
capture	O
important	O
sub	O
categories	O
within	O
these	O
.	O
	
Our	O
labels	O
are	O
aligned	O
to	O
(	O
and	O
thus	O
compatible	O
with	O
)	O
the	O
concepts	O
codified	O
by	O
the	O
Medical	O
Subject	O
Headings	O
(	O
MeSH	O
)	O
vocabulary	O
of	O
medical	O
terms	O
maintained	O
by	O
the	O
National	O
Library	O
of	O
Medicine	O
(	O
NLM	O
)	O
.	O
	
In	O
consultation	O
with	O
domain	O
experts	O
,	O
we	O
selected	O
subsets	O
of	O
MeSH	O
terms	O
for	O
each	O
PIO	O
category	O
that	O
captured	O
relatively	O
precise	O
information	O
without	O
being	O
overwhelming	O
.	O
	
For	O
illustration	O
,	O
we	O
show	O
the	O
outcomes	O
label	O
hierarchy	O
we	O
used	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
We	O
reproduce	O
the	O
label	O
hierarchies	O
used	O
for	O
all	O
PIO	O
categories	O
in	O
the	O
Appendix	O
.	O
	
At	O
this	O
stage	O
,	O
workers	O
were	O
presented	O
with	O
abstracts	O
in	O
which	O
relevant	O
spans	O
were	O
highlighted	O
,	O
based	O
on	O
the	O
annotations	O
collected	O
in	O
the	O
first	O
annotation	B-Task
phase	O
(	O
and	O
aggregated	O
via	O
the	O
HMMCrowd	B-Method
model	I-Method
)	O
.	O
	
This	O
two	O
-	O
step	O
approach	O
served	O
dual	O
purposes	O
:	O
(	O
i	O
)	O
increasing	O
the	O
rate	O
at	O
which	O
workers	O
could	O
complete	O
tasks	O
,	O
and	O
(	O
ii	O
)	O
improving	O
recall	B-Metric
by	O
directing	O
workers	O
to	O
all	O
areas	O
in	O
abstracts	O
where	O
they	O
might	O
find	O
the	O
structured	O
information	O
of	O
interest	O
.	O
	
Our	O
choice	O
of	O
a	O
high	B-Method
recall	I-Method
aggregation	I-Method
strategy	I-Method
for	O
the	O
starting	O
spans	O
ensured	O
that	O
the	O
large	O
majority	O
of	O
relevant	O
sections	O
of	O
the	O
article	O
were	O
available	O
as	O
inputs	O
to	O
this	O
task	O
.	O
	
The	O
three	O
trained	O
medical	O
personnel	O
hired	O
via	O
Upwork	O
each	O
annotated	O
200	O
documents	O
and	O
reported	O
that	O
spans	O
sufficiently	O
captured	O
the	O
target	O
information	O
.	O
	
These	O
domain	O
experts	O
received	O
feedback	O
and	O
additional	O
training	O
after	O
labeling	O
an	O
initial	O
round	O
of	O
documents	O
,	O
and	O
all	O
annotations	O
were	O
reviewed	O
for	O
compliance	O
.	O
	
The	O
average	O
inter	B-Metric
-	I-Metric
annotator	I-Metric
agreement	I-Metric
is	O
reported	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
With	O
respect	O
to	O
crowdsourcing	B-Task
on	O
AMT	B-Method
,	O
the	O
task	O
for	O
Participants	O
was	O
published	O
first	O
,	O
allowing	O
us	O
to	O
target	O
higher	O
quality	O
workers	O
for	O
the	O
more	O
technical	O
Interventions	O
and	O
Outcomes	O
annotations	O
.	O
	
We	O
retained	O
labels	O
from	O
118	O
workers	O
for	O
Participants	O
,	O
the	O
top	O
67	O
of	O
whom	O
were	O
invited	O
to	O
continue	O
on	O
to	O
the	O
following	O
tasks	O
.	O
	
Of	O
these	O
,	O
37	O
continued	O
to	O
contribute	O
to	O
the	O
project	O
.	O
	
Several	O
workers	O
provided	O
1	O
,	O
000	O
annotations	O
and	O
continued	O
to	O
work	O
on	O
the	O
task	O
over	O
a	O
period	O
of	O
several	O
months	O
.	O
	
To	O
produce	O
final	O
per	O
-	O
token	O
labels	O
,	O
we	O
again	O
turned	O
to	O
aggregation	B-Task
.	O
	
The	O
subspans	O
annotated	O
in	O
this	O
second	O
pass	O
were	O
by	O
construction	O
shorter	O
than	O
the	O
starting	O
spans	O
,	O
and	O
(	O
perhaps	O
as	O
a	O
result	O
)	O
informal	O
experiments	O
revealed	O
little	O
benefit	O
from	O
HMMCrowd	B-Method
’s	I-Method
sequential	I-Method
modeling	I-Method
aspect	I-Method
.	O
	
The	O
introduction	O
of	O
many	O
label	O
types	O
significantly	O
increased	O
the	O
complexity	B-Metric
of	O
the	O
task	O
,	O
resulting	O
in	O
both	O
lower	O
expert	B-Metric
inter	I-Metric
-	I-Metric
annotator	I-Metric
agreement	I-Metric
(	O
Table	O
[	O
reference	O
]	O
and	O
decreased	O
performance	O
when	O
comparing	O
the	O
crowdsourced	O
labels	O
against	O
those	O
of	O
the	O
experts	O
(	O
Table	O
[	O
reference	O
]	O
.	O
	
Most	O
observed	O
token	O
-	O
level	O
disagreements	O
(	O
and	O
errors	O
,	O
with	O
respect	O
to	O
reference	O
annotations	O
)	O
involve	O
differences	O
in	O
the	O
span	O
lengths	O
demarcated	O
by	O
individuals	O
.	O
	
For	O
example	O
,	O
many	O
abstracts	O
contain	O
an	O
information	O
-	O
dense	O
description	O
of	O
the	O
patient	O
population	O
,	O
focusing	O
on	O
their	O
medical	O
condition	O
but	O
also	O
including	O
information	O
about	O
their	O
sex	O
and	O
/	O
or	O
age	O
.	O
	
Workers	O
would	O
also	O
sometimes	O
fail	O
to	O
capture	O
repeated	O
mentions	O
of	O
the	O
same	O
information	O
,	O
producing	O
Type	O
2	O
errors	O
more	O
frequently	O
than	O
Type	O
1	O
.	O
	
This	O
tendency	O
can	O
be	O
seen	O
in	O
the	O
overall	O
token	B-Metric
-	I-Metric
level	I-Metric
confusion	I-Metric
matrix	I-Metric
for	O
AMT	B-Method
workers	I-Method
on	O
the	O
Participants	B-Task
task	I-Task
,	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
In	O
a	O
similar	O
though	O
more	O
benign	O
category	O
of	O
error	O
,	O
workers	O
differed	O
in	O
the	O
amount	O
of	O
context	O
they	O
included	O
surrounding	O
each	O
subspan	O
.	O
	
Although	O
the	O
instructions	O
asked	O
workers	O
to	O
highlight	O
minimal	O
subspans	O
,	O
there	O
was	O
variance	O
in	O
what	O
workers	O
considered	O
relevant	O
.	O
	
For	O
the	O
same	O
reasons	O
mentioned	O
above	O
(	O
little	O
pairwise	O
overlap	O
in	O
annotations	O
,	O
high	O
variance	O
with	O
respect	O
to	O
annotations	O
per	O
worker	O
)	O
,	O
quantifying	O
agreement	B-Metric
between	O
AMT	B-Method
workers	I-Method
is	O
again	O
difficult	O
using	O
traditional	O
measures	O
.	O
	
We	O
thus	O
again	O
take	O
as	O
a	O
measure	O
of	O
agreement	B-Metric
the	O
precision	B-Metric
,	O
recall	B-Metric
,	O
and	O
F	B-Metric
-	I-Metric
1	I-Metric
of	O
the	O
individual	O
annotations	O
against	O
the	O
aggregated	O
labels	O
and	O
present	O
the	O
results	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
subsection	O
:	O
Repetition	O
	
Medical	O
abstracts	O
often	O
mention	O
the	O
same	O
information	O
in	O
multiple	O
places	O
.	O
	
In	O
particular	O
,	O
interventions	O
and	O
outcomes	O
are	O
typically	O
described	O
at	O
the	O
beginning	O
of	O
an	O
abstract	O
when	O
introducing	O
the	O
purpose	O
of	O
the	O
underlying	O
study	O
,	O
and	O
then	O
again	O
when	O
discussing	O
methods	O
and	O
results	O
.	O
	
It	O
is	O
important	O
to	O
be	O
able	O
to	O
differentiate	O
between	O
novel	O
and	O
reiterated	O
information	O
,	O
especially	O
in	O
cases	O
such	O
as	O
complex	O
interventions	O
,	O
distinct	O
measured	O
outcomes	O
,	O
or	O
multi	O
-	O
armed	O
trials	O
.	O
	
Merely	O
identifying	O
all	O
occurrences	O
of	O
,	O
for	O
example	O
,	O
a	O
pharmacological	O
intervention	O
leaves	O
ambiguity	O
as	O
to	O
how	O
many	O
distinct	O
interventions	O
were	O
applied	O
.	O
	
Workers	O
identified	O
repeated	O
information	O
as	O
follows	O
.	O
	
After	O
completing	O
detailed	O
labeling	B-Task
of	I-Task
abstract	I-Task
spans	I-Task
,	O
they	O
were	O
asked	O
to	O
group	O
together	O
subspans	O
that	O
were	O
instances	O
of	O
the	O
same	O
information	O
(	O
for	O
example	O
,	O
redundant	O
mentions	O
of	O
a	O
particular	O
drug	O
evaluated	O
as	O
one	O
of	O
the	O
interventions	O
in	O
the	O
trial	O
)	O
.	O
	
This	O
process	O
produces	O
labels	O
for	O
repetition	O
between	O
short	O
spans	O
of	O
tokens	O
.	O
	
Due	O
to	O
the	O
differences	O
in	O
the	O
lengths	O
of	O
annotated	O
subspans	O
discussed	O
in	O
the	O
preceding	O
section	O
,	O
the	O
labels	O
are	O
not	O
naturally	O
comparable	O
between	O
workers	O
without	O
directly	O
modeling	O
the	O
entities	O
contained	O
in	O
each	O
subspan	O
.	O
	
The	O
labels	O
assigned	O
by	O
workers	O
produce	O
repetition	O
labels	O
between	O
sets	O
of	O
tokens	O
but	O
a	O
more	O
sophisticated	O
notion	O
of	O
co	O
-	O
reference	O
is	O
required	O
to	O
identify	O
which	O
tokens	O
correctly	O
represent	O
the	O
entity	O
contained	O
in	O
the	O
span	O
,	O
and	O
which	O
tokens	O
are	O
superfluous	O
noise	O
.	O
	
As	O
a	O
proxy	O
for	O
formally	O
enumerating	O
these	O
entities	O
,	O
we	O
observe	O
that	O
a	O
large	O
majority	O
of	O
starting	O
spans	O
only	O
contain	O
a	O
single	O
target	O
relevant	O
to	O
the	O
subspan	B-Task
labeling	I-Task
task	I-Task
,	O
and	O
so	O
identifying	O
repetition	O
between	O
the	O
starting	O
spans	O
is	O
sufficient	O
.	O
	
For	O
example	O
,	O
consider	O
the	O
starting	O
intervention	O
span	O
”	O
underwent	O
conventional	O
total	O
knee	O
arthroplasty	O
”	O
;	O
there	O
is	O
only	O
one	O
intervention	O
in	O
the	O
span	O
but	O
some	O
annotators	O
assigned	O
the	O
surgical	O
label	O
to	O
all	O
five	O
tokens	O
while	O
others	O
opted	O
for	O
only	O
”	O
total	B-Method
knee	I-Method
arthroplasty	I-Method
.	O
	
”	O
	
By	O
analyzing	O
repetition	O
at	O
the	O
level	O
of	O
the	O
starting	O
spans	O
,	O
we	O
can	O
compute	O
agreement	O
without	O
concern	O
for	O
the	O
confounds	O
of	O
slight	O
misalignments	O
or	O
differences	O
in	O
length	O
of	O
the	O
subspans	O
.	O
	
Overall	O
agreement	O
between	O
AMT	B-Method
workers	I-Method
for	O
span	O
-	O
level	O
repetition	O
,	O
measured	O
by	O
computing	O
precision	B-Metric
and	O
recall	B-Metric
against	O
the	O
majority	O
vote	O
for	O
each	O
pair	O
of	O
spans	O
,	O
is	O
reported	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
subsection	O
:	O
MeSH	O
Terms	O
	
The	O
National	O
Library	O
of	O
Medicine	O
maintains	O
an	O
extensive	O
hierarchical	O
ontology	O
of	O
medical	O
concepts	O
called	O
Medical	O
Subject	O
Headings	O
(	O
MeSH	O
terms	O
)	O
;	O
this	O
is	O
part	O
of	O
the	O
overarching	O
Metathesaurus	O
of	O
the	O
Unified	B-Method
Medical	I-Method
Language	I-Method
System	I-Method
(	O
UMLS	B-Method
)	O
.	O
	
Personnel	O
at	O
the	O
NLM	B-Task
manually	O
assign	O
citations	O
(	O
article	O
titles	O
,	O
abstracts	O
and	O
meta	O
-	O
data	O
)	O
indexed	O
in	O
MEDLINE	O
relevant	O
MeSH	O
terms	O
.	O
	
These	O
terms	O
have	O
been	O
used	O
extensively	O
to	O
evaluate	O
the	O
content	O
of	O
articles	O
,	O
and	O
are	O
frequently	O
used	O
to	O
facilitate	O
document	B-Task
retrieval	I-Task
.	O
	
In	O
the	O
case	O
of	O
randomized	B-Task
controlled	I-Task
trials	I-Task
,	O
MeSH	O
terms	O
provide	O
structured	O
information	O
regarding	O
key	O
aspects	O
of	O
the	O
underlying	O
studies	O
,	O
ranging	O
from	O
participant	O
demographics	O
to	O
methodologies	O
to	O
co	O
-	O
morbidities	O
.	O
	
A	O
drawback	O
to	O
these	O
annotations	O
,	O
however	O
,	O
is	O
that	O
they	O
are	O
applied	O
at	O
the	O
document	O
(	O
rather	O
than	O
snippet	O
or	O
token	O
)	O
level	O
.	O
	
To	O
capture	O
where	O
MeSH	O
terms	O
are	O
instantiated	O
within	O
a	O
given	O
abstract	O
text	O
,	O
we	O
provided	O
a	O
list	O
of	O
all	O
terms	O
associated	O
with	O
said	O
article	O
and	O
instructed	O
workers	O
to	O
select	O
the	O
subset	O
of	O
these	O
that	O
applied	O
to	O
each	O
set	O
of	O
token	O
labels	O
that	O
they	O
annotated	O
.	O
	
MeSH	O
terms	O
are	O
domain	O
specific	O
and	O
many	O
require	O
a	O
medical	O
background	O
to	O
understand	O
,	O
thus	O
rendering	O
this	O
facet	O
of	O
the	O
annotation	B-Task
process	O
particularly	O
difficult	O
for	O
untrained	O
(	O
lay	O
)	O
workers	O
.	O
	
Perhaps	O
surprisingly	O
,	O
several	O
AMT	O
workers	O
voluntarily	O
mentioned	O
relevant	O
background	O
training	O
;	O
our	O
pool	O
of	O
workers	O
included	O
(	O
self	O
-	O
identified	O
)	O
nurses	O
and	O
other	O
trained	O
medical	O
professionals	O
.	O
	
A	O
few	O
workers	O
with	O
such	O
training	O
stated	O
this	O
background	O
as	O
a	O
reason	O
for	O
their	O
interest	O
in	O
our	O
tasks	O
.	O
	
The	O
technical	O
specificity	O
of	O
the	O
more	O
obscure	O
MeSH	O
terms	O
is	O
also	O
exacerbated	O
by	O
their	O
sparsity	O
.	O
	
Of	O
the	O
6	O
,	O
963	O
unique	O
MeSH	O
terms	O
occurring	O
in	O
our	O
set	O
of	O
abstracts	O
,	O
87	O
%	O
of	O
them	O
are	O
only	O
found	O
in	O
10	O
documents	O
or	O
fewer	O
and	O
only	O
2.0	O
%	O
occur	O
in	O
at	O
least	O
1	O
%	O
of	O
the	O
total	O
documents	O
.	O
	
The	O
full	O
distribution	O
of	O
document	O
frequency	O
for	O
MeSH	O
terms	O
is	O
show	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
To	O
evaluate	O
how	O
often	O
salient	O
MeSH	O
terms	O
were	O
instantiated	O
in	O
the	O
text	O
by	O
annotators	O
we	O
consider	O
only	O
the	O
135	O
MeSH	O
terms	O
that	O
occur	O
in	O
at	O
least	O
1	O
%	O
of	O
abstracts	O
(	O
we	O
list	O
these	O
in	O
the	O
supplementary	O
material	O
)	O
.	O
	
For	O
each	O
term	O
,	O
we	O
calculate	O
its	O
”	O
instantiation	B-Metric
frequency	I-Metric
”	I-Metric
as	O
the	O
percentage	O
of	O
abstracts	O
containing	O
the	O
term	O
in	O
which	O
at	O
least	O
one	O
annotator	O
assigned	O
it	O
to	O
a	O
span	O
of	O
text	O
.	O
	
The	O
total	O
numbers	O
of	O
MeSH	O
terms	O
with	O
an	O
instantiation	B-Metric
rate	I-Metric
above	O
different	O
thresholds	O
for	O
the	O
respective	O
PIO	B-Method
elements	I-Method
are	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
section	O
:	O
Tasks	O
&	O
Baselines	O
	
We	O
outline	O
a	O
few	O
NLP	B-Task
tasks	I-Task
that	O
are	O
central	O
to	O
the	O
aim	O
of	O
processing	O
medical	O
literature	O
generally	O
and	O
to	O
aiding	O
practitioners	O
of	O
EBM	B-Task
specifically	O
.	O
	
First	O
,	O
we	O
consider	O
the	O
task	O
of	O
identifying	O
spans	O
in	O
abstracts	O
that	O
describe	O
the	O
respective	O
PICO	O
elements	O
(	O
Section	O
[	O
reference	O
]	O
)	O
.	O
	
This	O
would	O
,	O
e.g.	O
,	O
improve	O
medical	B-Task
literature	I-Task
search	I-Task
and	I-Task
retrieval	I-Task
systems	I-Task
.	O
	
Next	O
,	O
we	O
outline	O
the	O
problem	O
of	O
extracting	B-Task
structured	I-Task
information	I-Task
from	O
abstracts	O
(	O
Section	O
[	O
reference	O
]	O
)	O
.	O
	
Such	O
models	O
would	O
further	O
aid	O
search	B-Task
,	O
and	O
might	O
eventually	O
facilitate	O
automated	B-Task
knowledge	I-Task
-	I-Task
base	I-Task
construction	I-Task
for	O
the	O
clinical	O
trials	O
literature	O
.	O
	
Furthermore	O
,	O
automatic	B-Task
extraction	I-Task
of	I-Task
structured	I-Task
data	I-Task
would	O
enable	O
automation	O
of	O
the	O
manual	B-Task
evidence	I-Task
synthesis	I-Task
process	I-Task
.	O
	
Finally	O
,	O
we	O
consider	O
the	O
challenging	O
task	O
of	O
identifying	O
redundant	O
mentions	O
of	O
the	O
same	O
PICO	O
element	O
(	O
Section	O
[	O
reference	O
]	O
)	O
.	O
	
This	O
happens	O
,	O
e.g.	O
,	O
when	O
an	O
intervention	O
is	O
mentioned	O
by	O
the	O
authors	O
repeatedly	O
in	O
an	O
abstract	O
,	O
potentially	O
with	O
different	O
terms	O
.	O
	
Achieving	O
such	O
disambiguation	B-Task
is	O
important	O
for	O
systems	O
aiming	O
to	O
induce	O
structured	O
representations	O
of	O
trials	O
and	O
their	O
results	O
,	O
as	O
this	O
would	O
require	O
recognizing	O
and	O
normalizing	O
the	O
unique	O
interventions	O
and	O
outcomes	O
studied	O
in	O
a	O
trial	O
.	O
	
For	O
each	O
of	O
these	O
tasks	O
we	O
present	O
baseline	O
models	O
and	O
corresponding	O
results	O
.	O
	
Note	O
that	O
we	O
have	O
pre	O
-	O
defined	O
train	O
,	O
development	O
and	O
test	O
sets	O
across	O
PIO	O
elements	O
for	O
this	O
corpus	O
,	O
comprising	O
4300	O
,	O
500	O
and	O
200	O
abstracts	O
,	O
respectively	O
.	O
	
The	O
latter	O
set	O
is	O
annotated	O
by	O
domain	O
experts	O
(	O
i.e.	O
,	O
persons	O
with	O
medical	O
training	O
)	O
.	O
	
These	O
splits	O
will	O
,	O
of	O
course	O
,	O
be	O
distributed	O
along	O
with	O
the	O
dataset	O
to	O
facilitate	O
model	O
comparisons	O
.	O
	
subsection	O
:	O
Identifying	B-Task
P	I-Task
,	O
I	O
and	O
O	O
Spans	O
	
We	O
consider	O
two	O
baseline	O
models	O
:	O
a	O
linear	O
Conditional	B-Method
Random	I-Method
Field	I-Method
(	O
CRF	B-Method
)	O
and	O
a	O
Long	B-Method
Short	I-Method
-	I-Method
Term	I-Method
Memory	I-Method
(	O
LSTM	B-Method
)	O
neural	B-Method
tagging	I-Method
model	I-Method
,	O
an	O
LSTM	B-Method
-	I-Method
CRF	I-Method
.	O
	
In	O
both	O
models	O
,	O
we	O
treat	O
tokens	O
as	O
being	O
either	O
Inside	O
(	O
I	O
)	O
or	O
Outside	O
(	O
O	O
)	O
of	O
spans	O
.	O
	
For	O
the	O
CRF	B-Method
,	O
features	O
include	O
:	O
indicators	O
for	O
the	O
current	O
,	O
previous	O
and	O
next	O
words	O
;	O
part	O
of	O
speech	O
tags	O
inferred	O
using	O
the	O
Stanford	B-Method
CoreNLP	I-Method
tagger	I-Method
;	O
and	O
character	O
information	O
,	O
e.g.	O
,	O
whether	O
a	O
token	O
contains	O
digits	O
,	O
uppercase	O
letters	O
,	O
symbols	O
and	O
so	O
on	O
.	O
	
For	O
the	O
neural	B-Method
model	I-Method
,	O
the	O
model	O
induces	O
features	O
via	O
a	O
bi	B-Method
-	I-Method
directional	I-Method
LSTM	I-Method
that	O
consumes	O
distributed	B-Method
vector	I-Method
representations	I-Method
of	O
input	O
tokens	O
sequentially	O
.	O
	
The	O
bi	B-Method
-	I-Method
LSTM	I-Method
yields	O
a	O
hidden	O
vector	O
at	O
each	O
token	O
index	O
,	O
which	O
is	O
then	O
passed	O
to	O
a	O
CRF	B-Method
layer	O
for	O
prediction	B-Task
.	O
	
We	O
also	O
exploit	O
character	O
-	O
level	O
information	O
by	O
passing	O
a	O
bi	B-Method
-	I-Method
LSTM	I-Method
over	O
the	O
characters	O
comprising	O
each	O
word	O
;	O
these	O
are	O
appended	O
to	O
the	O
word	B-Method
embedding	I-Method
representations	I-Method
before	O
being	O
passed	O
through	O
the	O
bi	B-Method
-	I-Method
LSTM	I-Method
.	O
	
subsection	O
:	O
Extracting	B-Task
Structured	I-Task
Information	I-Task
	
Beyond	O
identifying	O
the	O
spans	O
of	O
text	O
containing	O
information	O
pertinent	O
to	O
each	O
of	O
the	O
PIO	O
elements	O
,	O
we	O
consider	O
the	O
task	O
of	O
predicting	O
which	O
of	O
the	O
detailed	O
labels	O
occur	O
in	O
each	O
span	O
,	O
and	O
where	O
they	O
are	O
located	O
.	O
	
Specifically	O
,	O
we	O
begin	O
with	O
the	O
starting	O
spans	O
and	O
predict	O
a	O
single	O
label	O
from	O
the	O
corresponding	O
PIO	O
hierarchy	O
for	O
each	O
token	O
,	O
evaluating	O
against	O
the	O
test	O
set	O
of	O
200	O
documents	O
.	O
	
Initial	O
experiments	O
with	O
neural	B-Method
models	I-Method
proved	O
unfruitful	O
but	O
bear	O
further	O
investigation	O
.	O
	
For	O
the	O
CRF	B-Method
model	O
we	O
include	O
the	O
same	O
features	O
as	O
in	O
the	O
previous	O
model	O
,	O
supplemented	O
with	O
additional	O
features	O
encoding	O
if	O
the	O
adjacent	O
tokens	O
include	O
any	O
parenthesis	O
or	O
mathematical	O
operators	O
(	O
specifically	O
:	O
)	O
.	O
	
For	O
the	O
logistic	B-Method
regression	I-Method
model	I-Method
,	O
we	O
use	O
a	O
one	B-Method
-	I-Method
vs	I-Method
-	I-Method
rest	I-Method
approach	I-Method
.	O
	
Features	O
include	O
token	O
-	O
grams	O
,	O
part	O
of	O
speech	O
indicators	O
,	O
and	O
the	O
same	O
character	O
-	O
level	O
information	O
as	O
in	O
the	O
CRF	B-Method
model	O
.	O
	
subsection	O
:	O
Detecting	B-Task
Repetition	I-Task
	
To	O
formalize	O
repetition	O
,	O
we	O
consider	O
every	O
pair	O
of	O
starting	O
PIO	O
spans	O
from	O
each	O
abstract	O
,	O
and	O
assign	O
binary	O
labels	O
that	O
indicate	O
whether	O
they	O
share	O
at	O
least	O
one	O
instance	O
of	O
the	O
same	O
information	O
.	O
	
Although	O
this	O
makes	O
prediction	B-Task
easier	O
for	O
long	B-Task
and	I-Task
information	I-Task
-	I-Task
dense	I-Task
spans	I-Task
,	O
a	O
large	O
enough	O
majority	O
of	O
the	O
spans	O
contain	O
only	O
a	O
single	O
instance	O
of	O
relevant	O
information	O
that	O
the	O
task	O
serves	O
as	O
a	O
reasonable	O
baseline	O
.	O
	
Again	O
,	O
the	O
model	O
is	O
trained	O
on	O
the	O
aggregated	O
labels	O
collected	O
from	O
AMT	B-Method
and	O
evaluated	O
against	O
the	O
high	O
-	O
quality	O
test	O
set	O
.	O
	
We	O
train	O
a	O
logistic	B-Method
regression	I-Method
model	I-Method
that	O
operates	O
over	O
standard	O
features	O
,	O
including	O
bag	B-Method
-	I-Method
of	I-Method
-	I-Method
words	I-Method
representations	I-Method
and	O
sentence	O
-	O
level	O
features	O
such	O
as	O
length	O
and	O
position	O
in	O
the	O
document	O
.	O
	
All	O
baseline	O
model	O
implementations	O
are	O
available	O
on	O
the	O
corpus	O
website	O
.	O
	
section	O
:	O
Conclusions	O
	
We	O
have	O
presented	O
EBM	B-Material
-	I-Material
NLP	I-Material
:	O
a	O
new	O
,	O
publicly	O
available	O
corpus	O
comprising	O
5	O
,	O
000	O
richly	O
annotated	O
abstracts	O
of	O
articles	O
describing	O
clinical	O
randomized	O
controlled	O
trials	O
.	O
	
This	O
dataset	O
fills	O
a	O
need	O
for	O
larger	O
scale	O
corpora	O
to	O
facilitate	O
research	O
on	O
NLP	B-Method
methods	I-Method
for	O
processing	O
the	O
biomedical	O
literature	O
,	O
which	O
have	O
the	O
potential	O
to	O
aid	O
the	O
conduct	O
of	O
EBM	B-Task
.	O
	
The	O
need	O
for	O
such	O
technologies	O
will	O
only	O
become	O
more	O
pressing	O
as	O
the	O
literature	O
continues	O
its	O
torrential	O
growth	O
.	O
	
The	O
EBM	B-Material
-	I-Material
NLP	I-Material
corpus	I-Material
,	O
accompanying	O
documentation	O
,	O
code	O
for	O
working	O
with	O
the	O
data	O
,	O
and	O
baseline	O
models	O
presented	O
in	O
this	O
work	O
are	O
all	O
publicly	O
available	O
at	O
:	O
.	O
	
section	O
:	O
Acknowledgements	O
	
This	O
work	O
was	O
supported	O
in	O
part	O
by	O
the	O
National	O
Cancer	O
Institute	O
(	O
NCI	O
)	O
of	O
the	O
National	O
Institutes	O
of	O
Health	O
(	O
NIH	O
)	O
,	O
award	O
number	O
UH2CA203711	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Stochastic	B-Method
Pooling	I-Method
for	O
Regularization	B-Task
of	O
Deep	B-Method
Convolutional	I-Method
Neural	I-Method
Networks	I-Method
	
We	O
introduce	O
a	O
simple	O
and	O
effective	O
method	O
for	O
regularizing	B-Method
large	I-Method
convolutional	I-Method
neural	I-Method
networks	I-Method
.	O
	
We	O
replace	O
the	O
conventional	O
deterministic	O
pooling	B-Method
operations	O
with	O
a	O
stochastic	B-Method
procedure	I-Method
,	O
randomly	O
picking	O
the	O
activation	O
within	O
each	O
pooling	B-Method
region	O
according	O
to	O
a	O
multinomial	O
distribution	O
,	O
given	O
by	O
the	O
activities	O
within	O
the	O
pooling	B-Method
region	O
.	O
	
The	O
approach	O
is	O
hyper	O
-	O
parameter	O
free	O
and	O
can	O
be	O
combined	O
with	O
other	O
regularization	B-Method
approaches	I-Method
,	O
such	O
as	O
dropout	B-Method
and	O
data	B-Method
augmentation	I-Method
.	O
	
We	O
achieve	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
four	O
image	O
datasets	O
,	O
relative	O
to	O
other	O
approaches	O
that	O
do	O
not	O
utilize	O
data	B-Method
augmentation	I-Method
.	O
	
section	O
:	O
Introduction	O
	
Neural	B-Method
network	I-Method
models	I-Method
are	O
prone	O
to	O
over	O
-	O
fitting	O
due	O
to	O
their	O
high	O
capacity	O
.	O
	
A	O
range	O
of	O
regularization	B-Method
techniques	I-Method
are	O
used	O
to	O
prevent	O
this	O
,	O
such	O
as	O
weight	B-Method
decay	I-Method
,	O
weight	B-Method
tying	I-Method
and	O
the	O
augmentation	O
of	O
the	O
training	O
set	O
with	O
transformed	O
copies	O
.	O
	
These	O
allow	O
the	O
training	O
of	O
larger	O
capacity	B-Method
models	I-Method
than	O
would	O
otherwise	O
be	O
possible	O
,	O
which	O
yield	O
superior	O
test	O
performance	O
compared	O
to	O
smaller	O
un	B-Method
-	I-Method
regularized	I-Method
models	I-Method
.	O
	
Dropout	B-Method
,	O
recently	O
proposed	O
by	O
Hinton	O
et	O
al	O
.	O
	
[	O
]	O
,	O
is	O
another	O
regularization	B-Method
approach	I-Method
that	O
stochastically	O
sets	O
half	O
the	O
activations	O
within	O
a	O
layer	O
to	O
zero	O
for	O
each	O
training	O
sample	O
during	O
training	O
.	O
	
It	O
has	O
been	O
shown	O
to	O
deliver	O
significant	O
gains	O
in	O
performance	O
across	O
a	O
wide	O
range	O
of	O
problems	O
,	O
although	O
the	O
reasons	O
for	O
its	O
efficacy	O
are	O
not	O
yet	O
fully	O
understood	O
.	O
	
A	O
drawback	O
to	O
dropout	B-Method
is	O
that	O
it	O
does	O
not	O
seem	O
to	O
have	O
the	O
same	O
benefits	O
for	O
convolutional	B-Method
layers	I-Method
,	O
which	O
are	O
common	O
in	O
many	O
networks	O
designed	O
for	O
vision	B-Task
tasks	I-Task
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
novel	O
type	O
of	O
regularization	B-Method
for	O
convolutional	B-Method
layers	I-Method
that	O
enables	O
the	O
training	O
of	O
larger	B-Method
models	I-Method
without	O
over	B-Task
-	I-Task
fitting	I-Task
,	O
and	O
produces	O
superior	O
performance	O
on	O
recognition	B-Task
tasks	I-Task
.	O
	
The	O
key	O
idea	O
is	O
to	O
make	O
the	O
pooling	B-Method
that	O
occurs	O
in	O
each	O
convolutional	B-Method
layer	I-Method
a	O
stochastic	B-Method
process	I-Method
.	O
	
Conventional	O
forms	O
of	O
pooling	B-Method
such	O
as	O
average	B-Method
and	O
max	B-Method
are	O
deterministic	O
,	O
the	O
latter	O
selecting	O
the	O
largest	O
activation	O
in	O
each	O
pooling	B-Method
region	O
.	O
	
In	O
our	O
stochastic	B-Method
pooling	I-Method
,	O
the	O
selected	O
activation	O
is	O
drawn	O
from	O
a	O
multinomial	O
distribution	O
formed	O
by	O
the	O
activations	O
within	O
the	O
pooling	B-Method
region	O
.	O
	
An	O
alternate	O
view	O
of	O
stochastic	B-Method
pooling	I-Method
is	O
that	O
it	O
is	O
equivalent	O
to	O
standard	O
max	B-Method
pooling	I-Method
but	O
with	O
many	O
copies	O
of	O
an	O
input	O
image	O
,	O
each	O
having	O
small	O
local	O
deformations	O
.	O
	
This	O
is	O
similar	O
to	O
explicit	O
elastic	O
deformations	O
of	O
the	O
input	O
images	O
,	O
which	O
delivers	O
excellent	O
MNIST	B-Metric
performance	I-Metric
.	O
	
Other	O
types	O
of	O
data	B-Task
augmentation	I-Task
,	O
such	O
as	O
flipping	O
and	O
cropping	B-Task
differ	O
in	O
that	O
they	O
are	O
global	B-Task
image	I-Task
transformations	I-Task
.	O
	
Furthermore	O
,	O
using	O
stochastic	B-Method
pooling	I-Method
in	O
a	O
multi	B-Method
-	I-Method
layer	I-Method
model	I-Method
gives	O
an	O
exponential	O
number	O
of	O
deformations	O
since	O
the	O
selections	O
in	O
higher	O
layers	O
are	O
independent	O
of	O
those	O
below	O
.	O
	
section	O
:	O
Review	O
of	O
Convolutional	B-Method
Networks	I-Method
	
Our	O
stochastic	O
pooling	B-Method
scheme	O
is	O
designed	O
for	O
use	O
in	O
a	O
standard	O
convolutional	B-Method
neural	I-Method
network	I-Method
architecture	I-Method
.	O
	
We	O
first	O
review	O
this	O
model	O
,	O
along	O
with	O
conventional	O
pooling	B-Method
schemes	O
,	O
before	O
introducing	O
our	O
novel	O
stochastic	O
pooling	B-Method
approach	O
.	O
	
A	O
classical	O
convolutional	B-Method
network	I-Method
is	O
composed	O
of	O
alternating	O
layers	O
of	O
convolution	O
and	O
pooling	B-Method
(	O
i.e.	O
subsampling	B-Method
)	O
.	O
	
The	O
aim	O
of	O
the	O
first	O
convolutional	B-Method
layer	I-Method
is	O
to	O
extract	O
patterns	O
found	O
within	O
local	O
regions	O
of	O
the	O
input	O
images	O
that	O
are	O
common	O
throughout	O
the	O
dataset	O
.	O
	
This	O
is	O
done	O
by	O
convolving	O
a	O
template	B-Method
or	I-Method
filter	I-Method
over	O
the	O
input	O
image	O
pixels	O
,	O
computing	O
the	O
inner	O
product	O
of	O
the	O
template	O
at	O
every	O
location	O
in	O
the	O
image	O
and	O
outputting	O
this	O
as	O
a	O
feature	O
map	O
,	O
for	O
each	O
filter	O
in	O
the	O
layer	O
.	O
	
This	O
output	O
is	O
a	O
measure	O
of	O
how	O
well	O
the	O
template	O
matches	O
each	O
portion	O
of	O
the	O
image	O
.	O
	
A	O
non	O
-	O
linear	O
function	O
is	O
then	O
applied	O
element	O
-	O
wise	O
to	O
each	O
feature	O
map	O
:	O
.	O
	
The	O
resulting	O
activations	O
are	O
then	O
passed	O
to	O
the	O
pooling	B-Method
layer	O
.	O
	
This	O
aggregates	O
the	O
information	O
within	O
a	O
set	O
of	O
small	O
local	O
regions	O
,	O
,	O
producing	O
a	O
pooled	B-Method
feature	I-Method
map	I-Method
(	O
of	O
smaller	O
size	O
)	O
as	O
output	O
.	O
	
Denoting	O
the	O
aggregation	O
function	O
as	O
,	O
for	O
each	O
feature	O
map	O
we	O
have	O
:	O
where	O
is	O
pooling	B-Method
region	O
in	O
feature	O
map	O
and	O
is	O
the	O
index	O
of	O
each	O
element	O
within	O
it	O
.	O
	
The	O
motivation	O
behind	O
pooling	B-Method
is	O
that	O
the	O
activations	O
in	O
the	O
pooled	B-Method
map	I-Method
are	O
less	O
sensitive	O
to	O
the	O
precise	O
locations	O
of	O
structures	O
within	O
the	O
image	O
than	O
the	O
original	O
feature	O
map	O
.	O
	
In	O
a	O
multi	B-Method
-	I-Method
layer	I-Method
model	I-Method
,	O
the	O
convolutional	B-Method
layers	I-Method
,	O
which	O
take	O
the	O
pooled	O
maps	O
as	O
input	O
,	O
can	O
thus	O
extract	O
features	O
that	O
are	O
increasingly	O
invariant	O
to	O
local	O
transformations	O
of	O
the	O
input	O
image	O
.	O
	
This	O
is	O
important	O
for	O
classification	B-Task
tasks	I-Task
,	O
since	O
these	O
transformations	O
obfuscate	O
the	O
object	O
identity	O
.	O
	
A	O
range	O
of	O
functions	O
can	O
be	O
used	O
for	O
,	O
with	O
and	O
logistic	B-Method
functions	I-Method
being	O
popular	O
choices	O
.	O
	
In	O
this	O
is	O
paper	O
we	O
use	O
a	O
linear	B-Method
rectification	I-Method
function	I-Method
as	O
the	O
non	O
-	O
linearity	O
.	O
	
In	O
general	O
,	O
this	O
has	O
been	O
shown	O
to	O
have	O
significant	O
benefits	O
over	O
or	O
logistic	O
functions	O
.	O
	
However	O
,	O
it	O
is	O
especially	O
suited	O
to	O
our	O
pooling	B-Method
mechanism	I-Method
since	O
:	O
(	O
i	O
)	O
our	O
formulation	O
involves	O
the	O
non	O
-	O
negativity	O
of	O
elements	O
in	O
the	O
pooling	B-Method
regions	O
and	O
(	O
ii	O
)	O
	
the	O
clipping	O
of	O
negative	O
responses	O
introduces	O
zeros	O
into	O
the	O
pooling	B-Method
regions	O
,	O
ensuring	O
that	O
the	O
stochastic	B-Method
sampling	I-Method
is	O
selecting	O
from	O
a	O
few	O
specific	O
locations	O
(	O
those	O
with	O
strong	O
responses	O
)	O
,	O
rather	O
than	O
all	O
possible	O
locations	O
in	O
the	O
region	O
.	O
	
There	O
are	O
two	O
conventional	O
choices	O
for	O
:	O
average	B-Method
and	O
max	B-Method
.	O
	
The	O
former	O
takes	O
the	O
arithmetic	O
mean	O
of	O
the	O
elements	O
in	O
each	O
pooling	B-Method
region	O
:	O
while	O
the	O
max	B-Method
operation	O
selects	O
the	O
largest	O
element	O
:	O
Both	O
types	O
of	O
pooling	B-Method
have	O
drawbacks	O
when	O
training	O
deep	B-Method
convolutional	I-Method
networks	I-Method
.	O
	
In	O
average	B-Method
pooling	I-Method
,	O
all	O
elements	O
in	O
a	O
pooling	B-Method
region	O
are	O
considered	O
,	O
even	O
if	O
many	O
have	O
low	O
magnitude	O
.	O
	
When	O
combined	O
with	O
linear	B-Method
rectification	I-Method
non	I-Method
-	I-Method
linearities	I-Method
,	O
this	O
has	O
the	O
effect	O
of	O
down	O
-	O
weighting	O
strong	O
activations	O
since	O
many	O
zero	O
elements	O
are	O
included	O
in	O
the	O
average	B-Method
.	O
	
Even	O
worse	O
,	O
with	O
non	O
-	O
linearities	O
,	O
strong	O
positive	O
and	O
negative	O
activations	O
can	O
cancel	O
each	O
other	O
out	O
,	O
leading	O
to	O
small	O
pooled	O
responses	O
.	O
	
While	O
max	B-Method
pooling	I-Method
does	O
not	O
suffer	O
from	O
these	O
drawbacks	O
,	O
we	O
find	O
it	O
easily	O
overfits	O
the	O
training	O
set	O
in	O
practice	O
,	O
making	O
it	O
hard	O
to	O
generalize	O
well	O
to	O
test	O
examples	O
.	O
	
Our	O
proposed	O
pooling	B-Method
scheme	O
has	O
the	O
advantages	O
of	O
max	B-Method
pooling	I-Method
but	O
its	O
stochastic	O
nature	O
helps	O
prevent	O
over	B-Task
-	I-Task
fitting	I-Task
.	O
	
section	O
:	O
Stochastic	B-Method
Pooling	I-Method
	
In	O
stochastic	B-Method
pooling	I-Method
,	O
we	O
select	O
the	O
pooled	O
map	O
response	O
by	O
sampling	O
from	O
a	O
multinomial	O
distribution	O
formed	O
from	O
the	O
activations	O
of	O
each	O
pooling	B-Method
region	O
.	O
	
More	O
precisely	O
,	O
we	O
first	O
compute	O
the	O
probabilities	O
for	O
each	O
region	O
by	O
normalizing	O
the	O
activations	O
within	O
the	O
region	O
:	O
We	O
then	O
sample	O
from	O
the	O
multinomial	B-Method
distribution	I-Method
based	O
on	O
to	O
pick	O
a	O
location	O
within	O
the	O
region	O
.	O
	
The	O
pooled	B-Method
activation	I-Method
is	O
then	O
simply	O
:	O
The	O
procedure	O
is	O
illustrated	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
The	O
samples	O
for	O
each	O
pooling	B-Method
region	O
in	O
each	O
layer	O
for	O
each	O
training	O
example	O
are	O
drawn	O
independently	O
to	O
one	O
another	O
.	O
	
When	O
back	O
-	O
propagating	O
through	O
the	O
network	O
this	O
same	O
selected	O
location	O
is	O
used	O
to	O
direct	O
the	O
gradient	O
back	O
through	O
the	O
pooling	B-Method
region	O
,	O
analogous	O
to	O
back	B-Method
-	I-Method
propagation	I-Method
with	O
max	B-Method
pooling	I-Method
.	O
	
Max	B-Method
pooling	I-Method
only	O
captures	O
the	O
strongest	O
activation	O
of	O
the	O
filter	O
template	O
with	O
the	O
input	O
for	O
each	O
region	O
.	O
	
However	O
,	O
there	O
may	O
be	O
additional	O
activations	O
in	O
the	O
same	O
pooling	B-Method
region	O
that	O
should	O
be	O
taken	O
into	O
account	O
when	O
passing	O
information	O
up	O
the	O
network	O
and	O
stochastic	B-Method
pooling	I-Method
ensures	O
that	O
these	O
non	O
-	O
maximal	O
activations	O
will	O
also	O
be	O
utilized	O
.	O
	
subsection	O
:	O
Probabilistic	B-Method
Weighting	I-Method
at	O
Test	O
Time	O
	
Using	O
stochastic	B-Method
pooling	I-Method
at	O
test	O
time	O
introduces	O
noise	O
into	O
the	O
network	O
	
’s	O
predictions	O
which	O
we	O
found	O
to	O
degrade	O
performance	O
(	O
see	O
Section	O
[	O
reference	O
]	O
)	O
.	O
	
Instead	O
,	O
we	O
use	O
a	O
probabilistic	B-Method
form	I-Method
of	I-Method
averaging	I-Method
.	O
	
In	O
this	O
,	O
the	O
activations	O
in	O
each	O
region	O
are	O
weighted	O
by	O
the	O
probability	O
(	O
see	O
Eqn	O
.	O
	
[	O
reference	O
]	O
)	O
and	O
summed	O
:	O
	
This	O
differs	O
from	O
standard	O
average	B-Method
pooling	I-Method
because	O
each	O
element	O
has	O
a	O
potentially	O
different	O
weighting	O
and	O
the	O
denominator	O
is	O
the	O
sum	O
of	O
activations	O
,	O
rather	O
than	O
the	O
pooling	B-Method
region	O
size	O
.	O
	
In	O
practice	O
,	O
using	O
conventional	O
average	B-Method
(	O
or	O
sum	O
)	O
pooling	B-Method
results	O
in	O
a	O
huge	O
performance	O
drop	O
(	O
see	O
Section	O
[	O
reference	O
]	O
)	O
.	O
	
Our	O
probabilistic	B-Method
weighting	I-Method
can	O
be	O
viewed	O
as	O
a	O
form	O
of	O
model	B-Method
averaging	I-Method
in	O
which	O
each	O
setting	O
of	O
the	O
locations	O
in	O
the	O
pooling	B-Method
regions	O
defines	O
a	O
new	O
model	O
.	O
	
At	O
training	O
time	O
,	O
sampling	O
to	O
get	O
new	O
locations	O
produces	O
a	O
new	O
model	O
since	O
the	O
connection	O
structure	O
throughout	O
the	O
network	O
is	O
modified	O
.	O
	
At	O
test	O
time	O
,	O
using	O
the	O
probabilities	O
instead	O
of	O
sampling	B-Method
,	O
we	O
effectively	O
get	O
an	O
estimate	O
of	O
averaging	O
over	O
all	O
of	O
these	O
possible	O
models	O
without	O
having	O
to	O
instantiate	O
them	O
.	O
	
Given	O
a	O
network	B-Method
architecture	I-Method
with	O
different	O
pooling	B-Method
regions	O
,	O
each	O
of	O
size	O
,	O
the	O
number	O
of	O
possible	O
models	O
is	O
where	O
can	O
be	O
in	O
the	O
-	O
range	O
and	O
is	O
typically	O
4	O
,	O
9	O
,	O
or	O
16	O
for	O
example	O
(	O
corresponding	O
to	O
,	O
or	O
pooling	B-Method
regions	O
)	O
.	O
	
This	O
is	O
a	O
significantly	O
larger	O
number	O
than	O
the	O
model	B-Method
averaging	I-Method
that	O
occurs	O
in	O
dropout	B-Task
,	O
where	O
always	O
(	O
since	O
an	O
activation	O
is	O
either	O
present	O
or	O
not	O
)	O
.	O
	
In	O
Section	O
[	O
reference	O
]	O
we	O
confirm	O
that	O
using	O
this	O
probability	B-Method
weighting	I-Method
achieves	O
similar	O
performance	O
compared	O
to	O
using	O
a	O
large	O
number	O
of	O
model	O
instantiations	O
,	O
while	O
requiring	O
only	O
one	O
pass	O
through	O
the	O
network	O
.	O
	
Using	O
the	O
probabilities	O
for	O
sampling	O
at	O
training	O
time	O
and	O
for	O
weighting	O
the	O
activations	O
at	O
test	O
time	O
leads	O
to	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
many	O
common	O
benchmarks	O
,	O
as	O
we	O
now	O
demonstrate	O
.	O
	
section	O
:	O
Experiments	O
	
subsection	O
:	O
Overview	O
	
We	O
compare	O
our	O
method	O
to	O
average	B-Method
and	O
max	B-Method
pooling	I-Method
on	O
a	O
variety	O
of	O
image	B-Task
classification	I-Task
tasks	I-Task
.	O
	
In	O
all	O
experiments	O
we	O
use	O
mini	B-Method
-	I-Method
batch	I-Method
gradient	I-Method
descent	I-Method
with	O
momentum	B-Method
to	O
optimize	O
the	O
cross	O
entropy	O
between	O
our	O
network	O
	
’s	O
prediction	O
of	O
the	O
class	O
and	O
the	O
ground	O
truth	O
labels	O
.	O
	
For	O
a	O
given	O
parameter	O
at	O
time	O
the	O
weight	O
updates	O
added	O
to	O
the	O
parameters	O
,	O
are	O
where	O
is	O
the	O
gradient	O
of	O
the	O
cost	O
function	O
with	O
respect	O
to	O
that	O
parameter	O
at	O
time	O
averaged	O
over	O
the	O
batch	O
and	O
is	O
a	O
learning	O
rate	O
set	O
by	O
hand	O
.	O
	
All	O
experiments	O
were	O
conducted	O
using	O
an	O
extremely	O
efficient	O
C	B-Method
++	I-Method
GPU	I-Method
convolution	I-Method
library	I-Method
wrapped	O
in	O
MATLAB	B-Method
using	O
GPUmat	B-Method
,	O
which	O
allowed	O
for	O
rapid	O
development	O
and	O
experimentation	O
.	O
	
We	O
begin	O
with	O
the	O
same	O
network	O
layout	O
as	O
in	O
Hinton	O
et	O
al	O
.	O
	
’s	O
dropout	O
work	O
,	O
which	O
has	O
convolutional	B-Method
layers	I-Method
with	O
5x5	O
filters	O
and	O
feature	B-Method
maps	I-Method
per	O
layer	O
with	O
rectified	B-Method
linear	I-Method
units	I-Method
as	O
their	O
outputs	O
.	O
	
We	O
use	O
this	O
same	O
model	O
and	O
train	O
for	O
280	O
epochs	O
in	O
all	O
experiments	O
aside	O
from	O
one	O
additional	O
model	O
in	O
Section	O
[	O
reference	O
]	O
that	O
has	O
128	O
feature	O
maps	O
in	O
layer	O
3	O
and	O
is	O
trained	O
for	O
500	O
epochs	O
.	O
	
Unless	O
otherwise	O
specified	O
we	O
use	O
pooling	B-Method
with	O
stride	O
(	O
i.e.	O
neighboring	O
pooling	B-Method
regions	O
overlap	O
by	O
element	O
along	O
the	O
borders	O
)	O
for	O
each	O
of	O
the	O
pooling	B-Method
layers	O
.	O
	
Additionally	O
,	O
after	O
each	O
pooling	B-Method
layer	O
there	O
is	O
a	O
response	B-Method
normalization	I-Method
layer	I-Method
(	O
as	O
in	O
)	O
,	O
which	O
normalizes	O
the	O
pooling	B-Method
outputs	O
at	O
each	O
location	O
over	O
a	O
subset	O
of	O
neighboring	O
feature	O
maps	O
.	O
	
This	O
typically	O
helps	O
training	O
by	O
suppressing	O
extremely	O
large	O
outputs	O
allowed	O
by	O
the	O
rectified	O
linear	O
units	O
as	O
well	O
as	O
helps	O
neighboring	O
features	O
communicate	O
.	O
	
Finally	O
,	O
we	O
use	O
a	O
single	O
fully	B-Method
-	I-Method
connected	I-Method
layer	I-Method
with	O
soft	O
-	O
max	B-Method
outputs	O
to	O
produce	O
the	O
network	O
’s	O
class	O
predictions	O
.	O
	
We	O
applied	O
this	O
model	O
to	O
four	O
different	O
datasets	O
:	O
MNIST	O
,	O
CIFAR	B-Material
-	I-Material
10	I-Material
,	O
CIFAR	B-Material
-	I-Material
100	I-Material
and	O
Street	B-Material
View	I-Material
House	I-Material
Numbers	I-Material
(	O
SVHN	B-Material
)	O
,	O
see	O
Fig	O
.	O
	
[	O
reference	O
]	O
for	O
examples	O
images	O
.	O
	
subsection	O
:	O
CIFAR	B-Material
-	I-Material
10	I-Material
	
We	O
begin	O
our	O
experiments	O
with	O
the	O
CIFAR	B-Material
-	I-Material
10	I-Material
dataset	O
where	O
convolutional	B-Method
networks	I-Method
and	O
methods	O
such	O
as	O
dropout	B-Method
are	O
known	O
to	O
work	O
well	O
.	O
	
This	O
dataset	O
is	O
composed	O
of	O
10	O
classes	O
of	O
natural	O
images	O
with	O
50	O
,	O
000	O
training	O
examples	O
in	O
total	O
,	O
5	O
,	O
000	O
per	O
class	O
.	O
	
Each	O
image	O
is	O
an	O
RGB	O
image	O
of	O
size	O
32x32	O
taken	O
from	O
the	O
tiny	O
images	O
dataset	O
and	O
labeled	O
by	O
hand	O
.	O
	
For	O
this	O
dataset	O
we	O
scale	O
to	O
[	O
0	O
,	O
1	O
]	O
and	O
follow	O
Hinton	O
et	O
al	O
.	O
	
’s	O
approach	O
of	O
subtracting	O
the	O
per	O
-	O
pixel	O
mean	O
computed	O
over	O
the	O
dataset	O
from	O
each	O
image	O
as	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
f	O
)	O
.	O
	
Cross	O
-	O
validating	O
with	O
a	O
set	O
of	O
5	O
,	O
000	O
CIFAR	B-Material
-	I-Material
10	I-Material
training	O
images	O
,	O
we	O
found	O
a	O
good	O
value	O
for	O
the	O
learning	B-Metric
rate	I-Metric
to	O
be	O
for	O
convolutional	B-Method
layers	I-Method
and	O
for	O
the	O
final	O
softmax	B-Method
output	I-Method
layer	I-Method
.	O
	
These	O
rates	O
were	O
annealed	O
linearly	O
throughout	O
training	O
to	O
of	O
their	O
original	O
values	O
.	O
	
Additionally	O
,	O
we	O
found	O
a	O
small	O
weight	O
decay	O
of	O
to	O
be	O
optimal	O
and	O
was	O
applied	O
to	O
all	O
layers	O
.	O
	
These	O
hyper	O
-	O
parameter	O
settings	O
found	O
through	O
cross	B-Metric
-	I-Metric
validation	I-Metric
were	O
used	O
for	O
all	O
other	O
datasets	O
in	O
our	O
experiments	O
.	O
	
Using	O
the	O
same	O
network	B-Method
architecture	I-Method
described	O
above	O
,	O
we	O
trained	O
three	O
models	O
using	O
average	B-Method
,	O
max	B-Method
and	O
stochastic	B-Method
pooling	I-Method
respectively	O
and	O
compare	O
their	O
performance	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
the	O
progression	O
of	O
train	O
and	O
test	O
errors	O
over	O
280	O
training	O
epochs	O
.	O
	
Stochastic	O
pooling	B-Method
avoids	O
over	B-Task
-	I-Task
fitting	I-Task
,	O
unlike	O
average	B-Method
and	O
max	B-Method
pooling	I-Method
,	O
and	O
produces	O
less	O
test	O
errors	O
.	O
	
Table	O
[	O
reference	O
]	O
compares	O
the	O
test	O
performance	O
of	O
the	O
three	O
pooling	B-Method
approaches	O
to	O
the	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
result	O
on	O
CIFAR	B-Material
-	I-Material
10	I-Material
which	O
uses	O
no	O
data	B-Method
augmentation	I-Method
but	O
adds	O
dropout	B-Method
on	O
an	O
additional	O
locally	B-Method
connected	I-Method
layer	I-Method
.	O
	
Stochastic	O
pooling	B-Method
surpasses	O
this	O
result	O
by	O
0.47	O
%	O
using	O
the	O
same	O
architecture	O
but	O
without	O
requiring	O
the	O
locally	O
connected	O
layer	O
.	O
	
To	O
determine	O
the	O
effect	O
of	O
the	O
pooling	B-Method
region	O
size	O
on	O
the	O
behavior	O
of	O
the	O
system	O
with	O
stochastic	B-Method
pooling	I-Method
,	O
we	O
compare	O
the	O
CIFAR	B-Metric
-	I-Metric
10	I-Metric
train	I-Metric
and	O
test	B-Metric
set	I-Metric
performance	I-Metric
for	O
5x5	O
,	O
4x4	O
,	O
3x3	O
,	O
and	O
2x2	O
pooling	B-Method
sizes	O
throughout	O
the	O
network	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
The	O
optimal	O
size	O
appears	O
to	O
be	O
3x3	O
,	O
with	O
smaller	O
regions	O
over	O
-	O
fitting	O
and	O
larger	O
regions	O
possibly	O
being	O
too	O
noisy	O
during	O
training	O
.	O
	
At	O
all	O
sizes	O
the	O
stochastic	B-Method
pooling	I-Method
	
outperforms	O
both	O
max	B-Method
and	O
average	B-Method
pooling	I-Method
.	O
	
subsection	O
:	O
MNIST	O
	
The	O
MNIST	B-Task
digit	I-Task
classification	I-Task
task	I-Task
is	O
composed	O
of	O
28x28	O
images	O
of	O
the	O
10	O
handwritten	O
digits	O
.	O
	
There	O
are	O
60	O
,	O
000	O
training	O
images	O
with	O
10	O
,	O
000	O
test	O
images	O
in	O
this	O
benchmark	O
.	O
	
The	O
images	O
are	O
scaled	O
to	O
[	O
0	O
,	O
1	O
]	O
and	O
we	O
do	O
not	O
perform	O
any	O
other	O
pre	B-Method
-	I-Method
processing	I-Method
.	O
	
During	O
training	B-Task
,	O
the	O
error	B-Metric
using	O
both	O
stochastic	B-Method
pooling	I-Method
and	O
max	B-Method
pooling	I-Method
dropped	O
quickly	O
,	O
but	O
the	O
latter	O
completely	O
overfit	O
the	O
training	O
data	O
.	O
	
Weight	B-Method
decay	I-Method
prevented	O
average	B-Method
pooling	I-Method
from	O
over	B-Task
-	I-Task
fitting	I-Task
,	O
but	O
had	O
an	O
inferior	O
performance	O
to	O
the	O
other	O
two	O
methods	O
.	O
	
Table	O
[	O
reference	O
]	O
compares	O
the	O
three	O
pooling	B-Method
approaches	O
to	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
on	O
MNIST	O
,	O
which	O
also	O
utilize	O
convolutional	B-Method
networks	I-Method
.	O
	
Stochastic	O
pooling	B-Method
outperforms	O
all	O
other	O
methods	O
that	O
do	O
not	O
use	O
data	B-Method
augmentation	I-Method
methods	I-Method
such	O
as	O
jittering	O
or	O
elastic	O
distortions	O
.	O
	
The	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
single	B-Method
model	I-Method
approach	I-Method
by	O
CiresÌ§an	O
et	O
al	O
.	O
	
[	O
]	O
uses	O
elastic	O
distortions	O
to	O
augment	O
the	O
original	O
training	O
set	O
.	O
	
As	O
stochastic	B-Method
pooling	I-Method
is	O
a	O
different	O
type	O
of	O
regularization	B-Method
,	O
it	O
could	O
be	O
combined	O
with	O
data	B-Task
augmentation	I-Task
to	O
further	O
improve	O
performance	O
.	O
	
subsection	O
:	O
CIFAR	B-Material
-	I-Material
100	I-Material
	
The	O
CIFAR	B-Material
-	I-Material
100	I-Material
dataset	O
is	O
another	O
subset	O
of	O
the	O
tiny	O
images	O
dataset	O
,	O
but	O
with	O
100	O
classes	O
.	O
	
There	O
are	O
50	O
,	O
000	O
training	O
examples	O
in	O
total	O
(	O
500	O
per	O
class	O
)	O
and	O
10	O
,	O
000	O
test	O
examples	O
.	O
	
As	O
with	O
the	O
CIFAR	B-Material
-	I-Material
10	I-Material
,	O
we	O
scale	O
to	O
[	O
0	O
,	O
1	O
]	O
and	O
subtract	O
the	O
per	O
-	O
pixel	O
mean	O
from	O
each	O
image	O
as	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
(	O
h	O
)	O
.	O
	
Due	O
to	O
the	O
limited	O
number	O
of	O
training	O
examples	O
per	O
class	O
,	O
typical	O
pooling	B-Method
methods	O
used	O
in	O
convolutional	B-Method
networks	I-Method
do	O
not	O
perform	O
well	O
,	O
as	O
shown	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Stochastic	O
pooling	B-Method
outperforms	O
these	O
methods	O
by	O
preventing	O
over	B-Task
-	I-Task
fitting	I-Task
and	O
surpasses	O
what	O
we	O
believe	O
to	O
be	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
method	O
by	O
%	O
.	O
	
subsection	O
:	O
Street	B-Material
View	I-Material
House	I-Material
Numbers	I-Material
	
The	O
Street	B-Material
View	I-Material
House	I-Material
Numbers	I-Material
(	O
SVHN	B-Material
)	O
dataset	O
is	O
composed	O
of	O
604	O
,	O
388	O
images	O
(	O
using	O
both	O
the	O
difficult	O
training	O
set	O
and	O
simpler	O
extra	O
set	O
)	O
and	O
26	O
,	O
032	O
test	O
images	O
.	O
	
The	O
goal	O
of	O
this	O
task	O
is	O
to	O
classify	O
the	O
digit	O
in	O
the	O
center	O
of	O
each	O
cropped	O
32x32	O
color	O
image	O
.	O
	
This	O
is	O
a	O
difficult	O
real	B-Task
world	I-Task
problem	I-Task
since	O
multiple	O
digits	O
may	O
be	O
visible	O
within	O
each	O
image	O
.	O
	
The	O
practical	O
application	O
of	O
this	O
is	O
to	O
classify	B-Task
house	I-Task
numbers	I-Task
throughout	O
Google	O
’s	O
street	O
view	O
database	O
of	O
images	O
.	O
	
We	O
found	O
that	O
subtracting	O
the	O
per	O
-	O
pixel	O
mean	O
from	O
each	O
image	O
did	O
not	O
really	O
modify	O
the	O
statistics	O
of	O
the	O
images	O
(	O
see	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
b	O
)	O
)	O
and	O
left	O
large	O
variations	O
of	O
brightness	O
and	O
color	O
that	O
could	O
make	O
classification	B-Task
more	O
difficult	O
.	O
	
Instead	O
,	O
we	O
utilized	O
local	B-Method
contrast	I-Method
normalization	I-Method
(	O
as	O
in	O
)	O
on	O
each	O
of	O
the	O
three	O
RGB	O
channels	O
to	O
pre	O
-	O
process	O
the	O
images	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
(	O
c	O
)	O
.	O
	
This	O
normalized	O
the	O
brightness	O
and	O
color	O
variations	O
and	O
helped	O
training	O
proceed	O
quickly	O
on	O
this	O
relatively	O
large	O
dataset	O
.	O
	
Despite	O
having	O
significant	O
amounts	O
of	O
training	O
data	O
,	O
a	O
large	O
convolutional	B-Method
network	I-Method
can	O
still	O
overfit	O
.	O
	
For	O
this	O
dataset	O
,	O
we	O
train	O
an	O
additional	O
model	O
for	O
500	O
epochs	O
with	O
64	O
,	O
64	O
and	O
128	O
feature	O
maps	O
in	O
layers	O
1	O
,	O
2	O
and	O
3	O
respectively	O
.	O
	
Our	O
stochastic	B-Method
pooling	I-Method
helps	O
to	O
prevent	O
overfitting	O
even	O
in	O
this	O
large	O
model	O
(	O
denoted	O
64	O
-	O
64	O
-	O
128	O
in	O
Table	O
[	O
reference	O
]	O
)	O
,	O
despite	O
training	O
for	O
a	O
long	O
time	O
.	O
	
The	O
existing	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
on	O
this	O
dataset	O
is	O
the	O
multi	B-Method
-	I-Method
stage	I-Method
convolutional	I-Method
network	I-Method
of	O
Sermanet	O
et	O
al	O
.	O
	
[	O
]	O
,	O
	
but	O
stochastic	B-Method
pooling	I-Method
beats	O
this	O
by	O
%	O
(	O
relative	O
gain	O
of	O
)	O
.	O
	
subsection	O
:	O
Reduced	O
Training	B-Metric
Set	I-Metric
Size	I-Metric
	
To	O
further	O
illustrate	O
the	O
ability	O
of	O
stochastic	B-Method
pooling	I-Method
to	O
prevent	O
over	B-Task
-	I-Task
fitting	I-Task
,	O
we	O
reduced	O
the	O
training	B-Metric
set	I-Metric
size	I-Metric
on	O
MINST	O
and	O
CIFAR	B-Material
-	I-Material
10	I-Material
datasets	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
test	O
performance	O
when	O
training	O
on	O
a	O
random	O
selection	O
of	O
only	O
1000	O
,	O
2000	O
,	O
3000	O
,	O
5000	O
,	O
10000	O
,	O
half	O
,	O
or	O
the	O
full	O
training	O
set	O
.	O
	
In	O
most	O
cases	O
,	O
stochastic	B-Method
pooling	I-Method
overfits	O
less	O
than	O
the	O
other	O
pooling	B-Method
approaches	O
.	O
	
subsection	O
:	O
Importance	O
of	O
Model	B-Method
Averaging	I-Method
	
To	O
analyze	O
the	O
importance	O
of	O
stochastic	B-Method
sampling	I-Method
at	O
training	O
time	O
and	O
probability	B-Method
weighting	I-Method
at	O
test	O
time	O
,	O
we	O
use	O
different	O
methods	O
of	O
pooling	B-Method
when	O
training	O
and	O
testing	O
on	O
CIFAR	B-Material
-	I-Material
10	I-Material
(	O
see	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
Choosing	O
the	O
locations	O
stochastically	O
at	O
test	O
time	O
degrades	O
performance	O
slightly	O
as	O
could	O
be	O
expected	O
,	O
however	O
it	O
still	O
outperforms	O
models	O
where	O
max	B-Method
or	O
average	B-Method
pooling	I-Method
are	O
used	O
at	O
test	O
time	O
.	O
	
To	O
confirm	O
that	O
probability	B-Method
weighting	I-Method
is	O
a	O
valid	O
approximation	O
to	O
averaging	O
many	O
models	O
,	O
we	O
draw	O
samples	O
of	O
the	O
pooling	B-Method
locations	O
throughout	O
the	O
network	O
and	O
average	B-Method
the	O
output	O
probabilities	O
from	O
those	O
models	O
(	O
denoted	O
Stochastic	O
-	O
in	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
As	O
increases	O
,	O
the	O
results	O
approach	O
the	O
probability	B-Method
weighting	I-Method
method	I-Method
,	O
but	O
have	O
the	O
obvious	O
downside	O
of	O
an	O
-	O
fold	O
increase	O
in	O
computations	B-Metric
.	O
	
Using	O
a	O
model	O
trained	O
with	O
max	B-Method
or	O
average	B-Method
pooling	I-Method
and	O
using	O
stochastic	B-Method
pooling	I-Method
at	O
test	O
time	O
performs	O
poorly	O
.	O
	
This	O
suggests	O
that	O
training	O
with	O
stochastic	B-Method
pooling	I-Method
,	O
which	O
incorporates	O
non	O
-	O
maximal	O
elements	O
and	O
sampling	O
noise	O
,	O
makes	O
the	O
model	O
more	O
robust	O
at	O
test	O
time	O
.	O
	
Furthermore	O
,	O
if	O
these	O
non	O
-	O
maximal	O
elements	O
are	O
not	O
utilized	O
correctly	O
or	O
the	O
scale	O
produced	O
by	O
the	O
pooling	B-Method
function	O
is	O
not	O
correct	O
,	O
such	O
as	O
if	O
average	B-Method
pooling	I-Method
is	O
used	O
at	O
test	O
time	O
,	O
a	O
drastic	O
performance	O
hit	O
is	O
seen	O
.	O
	
When	O
using	O
probability	B-Method
weighting	I-Method
during	O
training	O
,	O
the	O
network	O
easily	O
over	O
-	O
fits	O
and	O
performs	O
sub	O
-	O
optimally	O
at	O
test	O
time	O
using	O
any	O
of	O
the	O
pooling	B-Method
methods	O
.	O
	
However	O
,	O
the	O
benefits	O
of	O
probability	B-Method
weighting	I-Method
at	O
test	O
time	O
are	O
seen	O
when	O
the	O
model	O
has	O
specifically	O
been	O
trained	O
to	O
utilize	O
it	O
through	O
either	O
probability	B-Method
weighting	I-Method
or	O
stochastic	B-Method
pooling	I-Method
at	O
training	O
time	O
.	O
	
subsection	O
:	O
Visualizations	B-Task
	
Some	O
insight	O
into	O
the	O
mechanism	O
of	O
stochastic	B-Method
pooling	I-Method
can	O
be	O
gained	O
by	O
using	O
a	O
deconvolutional	B-Method
network	I-Method
of	O
Zeiler	O
et	O
al	O
.	O
	
[	O
]	O
to	O
provide	O
a	O
novel	O
visualization	O
of	O
our	O
trained	B-Method
convolutional	I-Method
network	I-Method
.	O
	
The	O
deconvolutional	B-Method
network	I-Method
has	O
the	O
same	O
components	O
(	O
pooling	B-Method
,	O
filtering	B-Method
)	O
as	O
a	O
convolutional	B-Method
network	I-Method
but	O
are	O
inverted	O
to	O
act	O
as	O
a	O
top	B-Method
-	I-Method
down	I-Method
decoder	I-Method
that	O
maps	O
the	O
top	O
-	O
layer	O
feature	O
maps	O
back	O
to	O
the	O
input	O
pixels	O
.	O
	
The	O
unpooling	B-Method
operation	I-Method
uses	O
the	O
stochastically	O
chosen	O
locations	O
selected	O
during	O
the	O
forward	O
pass	O
.	O
	
The	O
deconvolution	B-Method
network	I-Method
filters	I-Method
(	O
now	O
applied	O
to	O
the	O
feature	O
maps	O
,	O
rather	O
than	O
the	O
input	O
)	O
are	O
the	O
transpose	O
of	O
the	O
feed	B-Method
-	I-Method
forward	I-Method
filters	I-Method
,	O
as	O
in	O
an	O
auto	B-Method
-	I-Method
encoder	I-Method
with	O
tied	B-Method
encoder	I-Method
/	O
decoder	B-Method
weights	I-Method
.	O
	
We	O
repeat	O
this	O
top	O
-	O
down	O
process	O
until	O
the	O
input	O
pixel	O
level	O
is	O
reached	O
,	O
producing	O
the	O
visualizations	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
With	O
max	B-Method
pooling	I-Method
,	O
many	O
of	O
the	O
input	O
image	O
edges	O
are	O
present	O
,	O
but	O
average	B-Method
pooling	I-Method
produces	O
a	O
reconstruction	B-Method
with	O
no	O
discernible	O
structure	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
	
(	O
a	O
)	O
shows	O
16	O
examples	O
of	O
pixel	B-Method
-	I-Method
space	I-Method
reconstructions	I-Method
for	O
different	O
location	O
samples	O
throughout	O
the	O
network	O
.	O
	
The	O
reconstructions	O
are	O
similar	O
to	O
the	O
max	B-Method
pooling	I-Method
case	I-Method
,	O
but	O
as	O
the	O
pooling	B-Method
locations	O
change	O
they	O
result	O
in	O
small	O
local	O
deformations	O
of	O
the	O
visualized	O
image	O
.	O
	
Despite	O
the	O
stochastic	O
nature	O
of	O
the	O
model	O
,	O
the	O
multinomial	B-Method
distributions	I-Method
effectively	O
capture	O
the	O
regularities	O
of	O
the	O
data	O
.	O
	
To	O
demonstrate	O
this	O
,	O
we	O
compare	O
the	O
outputs	O
produced	O
by	O
a	O
deconvolutional	B-Method
network	I-Method
when	O
sampling	O
using	O
the	O
feedforward	B-Method
(	O
FF	B-Method
)	O
proabilities	O
versus	O
sampling	O
from	O
uniform	B-Method
(	O
UN	B-Method
)	O
distributions	O
.	O
	
In	O
contrast	O
to	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
a	O
)	O
which	O
uses	O
only	O
feedforward	B-Method
proabilities	O
,	O
Fig	O
.	O
	
[	O
reference	O
]	O
(	O
	
b	O
-	O
h	O
)	O
replace	O
one	O
or	O
more	O
of	O
the	O
pooling	B-Method
layers	O
’	O
distributions	O
with	O
uniform	B-Method
distributions	O
.	O
	
The	O
feed	O
forward	O
probabilities	O
encode	O
significant	O
structural	O
information	O
,	O
especially	O
in	O
the	O
lower	O
layers	O
of	O
the	O
model	O
.	O
	
Additional	O
visualizations	O
and	O
videos	O
of	O
the	O
sampling	B-Method
process	I-Method
are	O
provided	O
as	O
supplementary	O
material	O
at	O
.	O
	
section	O
:	O
Discussion	O
	
We	O
propose	O
a	O
simple	O
and	O
effective	O
stochastic	O
pooling	B-Method
strategy	O
that	O
can	O
be	O
combined	O
with	O
any	O
other	O
forms	O
of	O
regularization	B-Method
such	O
as	O
weight	O
decay	O
,	O
dropout	B-Method
,	O
data	B-Task
augmentation	I-Task
,	O
etc	O
.	O
to	O
prevent	O
over	B-Task
-	I-Task
fitting	I-Task
when	O
training	O
deep	B-Method
convolutional	I-Method
networks	I-Method
.	O
	
The	O
method	O
is	O
also	O
intuitive	O
,	O
selecting	O
from	O
information	O
the	O
network	O
is	O
already	O
providing	O
,	O
as	O
opposed	O
to	O
methods	O
such	O
as	O
dropout	B-Method
which	O
throw	O
information	O
away	O
.	O
	
We	O
show	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
numerous	O
datasets	O
,	O
when	O
comparing	O
to	O
other	O
approaches	O
that	O
do	O
not	O
employ	O
data	B-Method
augmentation	I-Method
.	O
	
Furthermore	O
,	O
our	O
method	O
has	O
negligible	O
computational	B-Metric
overhead	I-Metric
and	O
no	O
hyper	O
-	O
parameters	O
to	O
tune	O
,	O
thus	O
can	O
be	O
swapped	O
into	O
to	O
any	O
existing	O
convolutional	B-Method
network	I-Method
architecture	I-Method
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Attention	O
Is	O
All	O
You	O
Need	O
	
The	O
dominant	B-Method
sequence	I-Method
transduction	I-Method
models	I-Method
are	O
based	O
on	O
complex	O
recurrent	B-Method
or	O
convolutional	O
neural	O
networks	O
that	O
include	O
an	O
encoder	B-Method
and	O
a	O
decoder	B-Method
.	O
	
The	O
best	O
performing	O
models	O
also	O
connect	O
the	O
encoder	B-Method
and	O
decoder	B-Method
through	O
an	O
attention	B-Method
mechanism	I-Method
.	O
	
We	O
propose	O
a	O
new	O
simple	O
network	B-Method
architecture	I-Method
,	O
the	O
Transformer	B-Method
,	O
based	O
solely	O
on	O
attention	B-Method
mechanisms	I-Method
,	O
dispensing	O
with	O
recurrence	B-Method
and	I-Method
convolutions	I-Method
entirely	O
.	O
	
Experiments	O
on	O
two	O
machine	B-Task
translation	I-Task
tasks	I-Task
show	O
these	O
models	O
to	O
be	O
superior	O
in	O
quality	O
while	O
being	O
more	O
parallelizable	O
and	O
requiring	O
significantly	O
less	O
time	O
to	O
train	O
.	O
	
Our	O
model	O
achieves	O
28.4	O
BLEU	B-Metric
on	O
the	O
WMT	B-Task
2014	I-Task
English	I-Task
-	I-Task
to	I-Task
-	I-Task
German	I-Task
translation	I-Task
task	I-Task
,	O
improving	O
over	O
the	O
existing	O
best	O
results	O
,	O
including	O
ensembles	B-Method
,	O
by	O
over	O
2	O
BLEU	B-Metric
.	O
	
On	O
the	O
WMT	B-Task
2014	I-Task
English	I-Task
-	I-Task
to	I-Task
-	I-Task
French	I-Task
translation	I-Task
task	I-Task
,	O
our	O
model	O
establishes	O
a	O
new	O
single	O
-	O
model	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
BLEU	B-Metric
score	I-Metric
of	O
41.8	O
after	O
training	O
for	O
3.5	O
days	O
on	O
eight	O
GPUs	B-Method
,	O
a	O
small	O
fraction	O
of	O
the	O
training	B-Metric
costs	I-Metric
of	O
the	O
best	O
models	O
from	O
the	O
literature	O
.	O
	
We	O
show	O
that	O
the	O
Transformer	B-Method
generalizes	O
well	O
to	O
other	O
tasks	O
by	O
applying	O
it	O
successfully	O
to	O
English	B-Task
constituency	I-Task
parsing	I-Task
both	O
with	O
large	O
and	O
limited	O
training	O
data	O
.	O
	
section	O
:	O
Introduction	O
	
Recurrent	B-Method
neural	I-Method
networks	I-Method
,	O
long	B-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
hochreiter1997	O
and	O
gated	O
recurrent	B-Method
gruEval14	O
neural	O
networks	O
in	O
particular	O
,	O
have	O
been	O
firmly	O
established	O
as	O
state	O
of	O
the	O
art	O
approaches	O
in	O
sequence	B-Task
modeling	I-Task
and	O
transduction	B-Task
problems	I-Task
such	O
as	O
language	B-Task
modeling	I-Task
and	O
machine	B-Task
translation	I-Task
	
sutskever14	O
,	O
	
bahdanau2014neural	O
,	O
cho2014learning	O
.	O
	
Numerous	O
efforts	O
have	O
since	O
continued	O
to	O
push	O
the	O
boundaries	O
of	O
recurrent	B-Method
language	O
models	O
and	O
encoder	B-Method
-	I-Method
decoder	I-Method
architectures	I-Method
	
wu2016google	O
,	O
luong2015effective	O
,	O
jozefowicz2016exploring	O
.	O
	
Recurrent	B-Method
models	I-Method
typically	O
factor	O
computation	O
along	O
the	O
symbol	O
positions	O
of	O
the	O
input	O
and	O
output	O
sequences	O
.	O
	
Aligning	O
the	O
positions	O
to	O
steps	O
in	O
computation	O
time	O
,	O
they	O
generate	O
a	O
sequence	O
of	O
hidden	O
states	O
,	O
as	O
a	O
function	O
of	O
the	O
previous	O
hidden	O
state	O
and	O
the	O
input	O
for	O
position	O
.	O
	
This	O
inherently	O
sequential	O
nature	O
precludes	O
parallelization	O
within	O
training	O
examples	O
,	O
which	O
becomes	O
critical	O
at	O
longer	O
sequence	O
lengths	O
,	O
as	O
memory	O
constraints	O
limit	O
batching	O
across	O
examples	O
.	O
	
Recent	O
work	O
has	O
achieved	O
significant	O
improvements	O
in	O
computational	B-Metric
efficiency	I-Metric
through	O
factorization	B-Method
tricks	I-Method
Kuchaiev2017Factorization	O
and	O
conditional	B-Method
computation	I-Method
shazeer2017outrageously	O
,	O
while	O
also	O
improving	O
model	O
performance	O
in	O
case	O
of	O
the	O
latter	O
.	O
	
The	O
fundamental	O
constraint	O
of	O
sequential	B-Task
computation	I-Task
,	O
however	O
,	O
remains	O
.	O
	
Attention	B-Method
mechanisms	I-Method
have	O
become	O
an	O
integral	O
part	O
of	O
compelling	O
sequence	B-Method
modeling	I-Method
and	O
transduction	B-Method
models	I-Method
in	O
various	O
tasks	O
,	O
allowing	O
modeling	B-Task
of	I-Task
dependencies	I-Task
without	O
regard	O
to	O
their	O
distance	O
in	O
the	O
input	O
or	O
output	O
sequences	O
bahdanau2014neural	O
,	O
structuredAttentionNetworks	O
.	O
	
In	O
all	O
but	O
a	O
few	O
cases	O
decomposableAttnModel	O
,	O
however	O
,	O
such	O
attention	B-Method
mechanisms	I-Method
are	O
used	O
in	O
conjunction	O
with	O
a	O
recurrent	B-Method
network	O
.	O
	
In	O
this	O
work	O
we	O
propose	O
the	O
Transformer	B-Method
,	O
a	O
model	B-Method
architecture	I-Method
eschewing	O
recurrence	B-Method
and	O
instead	O
relying	O
entirely	O
on	O
an	O
attention	B-Method
mechanism	I-Method
to	O
draw	O
global	O
dependencies	O
between	O
input	O
and	O
output	O
.	O
	
The	O
Transformer	B-Method
allows	O
for	O
significantly	O
more	O
parallelization	B-Task
and	O
can	O
reach	O
a	O
new	O
state	O
of	O
the	O
art	O
in	O
translation	B-Metric
quality	I-Metric
after	O
being	O
trained	O
for	O
as	O
little	O
as	O
twelve	O
hours	O
on	O
eight	O
P100	B-Method
GPUs	I-Method
.	O
	
section	O
:	O
Background	O
	
The	O
goal	O
of	O
reducing	O
sequential	B-Task
computation	I-Task
also	O
forms	O
the	O
foundation	O
of	O
the	O
Extended	B-Method
Neural	I-Method
GPU	I-Method
extendedngpu	O
,	O
ByteNet	B-Method
NalBytenet2017	O
and	O
ConvS2S	B-Method
JonasFaceNet2017	O
,	O
all	O
of	O
which	O
use	O
convolutional	B-Method
neural	I-Method
networks	I-Method
as	O
basic	O
building	O
block	O
,	O
computing	O
hidden	O
representations	O
in	O
parallel	O
for	O
all	O
input	O
and	O
output	O
positions	O
.	O
	
In	O
these	O
models	O
,	O
the	O
number	O
of	O
operations	O
required	O
to	O
relate	O
signals	O
from	O
two	O
arbitrary	O
input	O
or	O
output	O
positions	O
grows	O
in	O
the	O
distance	O
between	O
positions	O
,	O
linearly	O
for	O
ConvS2S	B-Method
and	O
logarithmically	O
for	O
ByteNet	B-Method
.	O
	
This	O
makes	O
it	O
more	O
difficult	O
to	O
learn	O
dependencies	O
between	O
distant	O
positions	O
hochreiter2001gradient	O
.	O
	
In	O
the	O
Transformer	B-Method
this	O
is	O
reduced	O
to	O
a	O
constant	O
number	O
of	O
operations	O
,	O
albeit	O
at	O
the	O
cost	O
of	O
reduced	O
effective	B-Metric
resolution	I-Metric
due	O
to	O
averaging	O
attention	O
-	O
weighted	O
positions	O
,	O
an	O
effect	O
we	O
counteract	O
with	O
Multi	O
-	O
Head	O
Attention	O
as	O
described	O
in	O
section	O
[	O
reference	O
]	O
.	O
	
Self	B-Method
-	I-Method
attention	I-Method
,	O
sometimes	O
called	O
intra	B-Method
-	I-Method
attention	I-Method
is	O
an	O
attention	B-Method
mechanism	I-Method
relating	O
different	O
positions	O
of	O
a	O
single	O
sequence	O
in	O
order	O
to	O
compute	O
a	O
representation	O
of	O
the	O
sequence	O
.	O
	
Self	B-Method
-	I-Method
attention	I-Method
has	O
been	O
used	O
successfully	O
in	O
a	O
variety	O
of	O
tasks	O
including	O
reading	B-Task
comprehension	I-Task
,	O
abstractive	B-Task
summarization	I-Task
,	O
textual	B-Task
entailment	I-Task
and	O
learning	B-Task
task	I-Task
-	I-Task
independent	I-Task
sentence	I-Task
representations	I-Task
cheng2016long	O
,	O
decomposableAttnModel	B-Method
,	O
paulus2017deep	O
,	O
lin2017structured	O
.	O
	
End	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
memory	I-Method
networks	I-Method
are	O
based	O
on	O
a	O
recurrent	B-Method
attention	O
mechanism	O
instead	O
of	O
sequence	B-Method
-	I-Method
aligned	I-Method
recurrence	I-Method
and	O
have	O
been	O
shown	O
to	O
perform	O
well	O
on	O
simple	B-Task
-	I-Task
language	I-Task
question	I-Task
answering	I-Task
and	I-Task
language	I-Task
modeling	I-Task
tasks	I-Task
sukhbaatar2015	O
.	O
	
To	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
however	O
,	O
the	O
Transformer	B-Method
is	O
the	O
first	O
transduction	B-Method
model	I-Method
relying	O
entirely	O
on	O
self	O
-	O
attention	O
to	O
compute	O
representations	O
of	O
its	O
input	O
and	O
output	O
without	O
using	O
sequence	B-Method
-	I-Method
aligned	I-Method
RNNs	I-Method
or	O
convolution	B-Method
.	O
	
In	O
the	O
following	O
sections	O
,	O
we	O
will	O
describe	O
the	O
Transformer	B-Method
,	O
motivate	O
self	B-Task
-	I-Task
attention	I-Task
and	O
discuss	O
its	O
advantages	O
over	O
models	O
such	O
as	O
neural_gpu	B-Method
,	O
NalBytenet2017	B-Method
and	O
JonasFaceNet2017	B-Method
.	O
	
section	O
:	O
Model	O
Architecture	O
	
Most	O
competitive	O
neural	B-Method
sequence	I-Method
transduction	I-Method
models	I-Method
have	O
an	O
encoder	B-Method
-	I-Method
decoder	I-Method
structure	I-Method
cho2014learning	O
,	O
bahdanau2014neural	O
,	O
sutskever14	O
.	O
	
Here	O
,	O
the	O
encoder	B-Method
maps	O
an	O
input	O
sequence	O
of	O
symbol	B-Method
representations	I-Method
to	O
a	O
sequence	O
of	O
continuous	B-Method
representations	I-Method
.	O
	
Given	O
,	O
the	O
decoder	B-Method
then	O
generates	O
an	O
output	O
sequence	O
of	O
symbols	O
one	O
element	O
at	O
a	O
time	O
.	O
	
At	O
each	O
step	O
the	O
model	O
is	O
auto	B-Method
-	I-Method
regressive	I-Method
graves2013generating	O
,	O
consuming	O
the	O
previously	O
generated	O
symbols	O
as	O
additional	O
input	O
when	O
generating	O
the	O
next	O
.	O
	
The	O
Transformer	B-Method
follows	O
this	O
overall	O
architecture	O
using	O
stacked	B-Method
self	I-Method
-	I-Method
attention	I-Method
and	O
point	B-Method
-	I-Method
wise	I-Method
,	I-Method
fully	I-Method
connected	I-Method
layers	I-Method
for	O
both	O
the	O
encoder	O
and	O
decoder	B-Method
,	O
shown	O
in	O
the	O
left	O
and	O
right	O
halves	O
of	O
Figure	O
[	O
reference	O
]	O
,	O
respectively	O
.	O
	
subsection	O
:	O
Encoder	B-Method
and	O
Decoder	B-Method
Stacks	I-Method
	
paragraph	O
:	O
Encoder	B-Method
:	O
	
The	O
encoder	B-Method
is	O
composed	O
of	O
a	O
stack	B-Method
of	I-Method
identical	I-Method
layers	I-Method
.	O
	
Each	O
layer	O
has	O
two	O
sub	O
-	O
layers	O
.	O
	
The	O
first	O
is	O
a	O
multi	B-Method
-	I-Method
head	I-Method
self	I-Method
-	I-Method
attention	I-Method
mechanism	I-Method
,	O
and	O
the	O
second	O
is	O
a	O
simple	O
,	O
position	B-Method
-	I-Method
wise	I-Method
fully	I-Method
connected	I-Method
feed	I-Method
-	I-Method
forward	I-Method
network	I-Method
.	O
	
We	O
employ	O
a	O
residual	B-Method
connection	I-Method
	
he2016deep	O
around	O
each	O
of	O
the	O
two	O
sub	O
-	O
layers	O
,	O
followed	O
by	O
layer	B-Method
normalization	I-Method
.	O
	
That	O
is	O
,	O
the	O
output	O
of	O
each	O
sub	O
-	O
layer	O
is	O
,	O
where	O
is	O
the	O
function	O
implemented	O
by	O
the	O
sub	O
-	O
layer	O
itself	O
.	O
	
To	O
facilitate	O
these	O
residual	O
connections	O
,	O
all	O
sub	O
-	O
layers	O
in	O
the	O
model	O
,	O
as	O
well	O
as	O
the	O
embedding	O
layers	O
,	O
produce	O
outputs	O
of	O
dimension	O
.	O
	
paragraph	O
:	O
Decoder	O
:	O
	
The	O
decoder	B-Method
is	O
also	O
composed	O
of	O
a	O
stack	B-Method
of	I-Method
identical	I-Method
layers	I-Method
.	O
	
In	O
addition	O
to	O
the	O
two	O
sub	O
-	O
layers	O
in	O
each	O
encoder	B-Method
layer	I-Method
,	O
the	O
decoder	B-Method
inserts	O
a	O
third	O
sub	O
-	O
layer	O
,	O
which	O
performs	O
multi	O
-	O
head	O
attention	O
over	O
the	O
output	O
of	O
the	O
encoder	O
stack	O
.	O
	
Similar	O
to	O
the	O
encoder	B-Method
,	O
we	O
employ	O
residual	O
connections	O
around	O
each	O
of	O
the	O
sub	O
-	O
layers	O
,	O
followed	O
by	O
layer	B-Method
normalization	I-Method
.	O
	
We	O
also	O
modify	O
the	O
self	B-Method
-	I-Method
attention	I-Method
sub	I-Method
-	I-Method
layer	I-Method
in	O
the	O
decoder	O
stack	O
to	O
prevent	O
positions	O
from	O
attending	O
to	O
subsequent	O
positions	O
.	O
	
This	O
masking	O
,	O
combined	O
with	O
fact	O
that	O
the	O
output	O
embeddings	O
are	O
offset	O
by	O
one	O
position	O
,	O
ensures	O
that	O
the	O
predictions	O
for	O
position	O
can	O
depend	O
only	O
on	O
the	O
known	O
outputs	O
at	O
positions	O
less	O
than	O
.	O
	
subsection	O
:	O
Attention	O
	
An	O
attention	B-Method
function	I-Method
can	O
be	O
described	O
as	O
mapping	O
a	O
query	O
and	O
a	O
set	O
of	O
key	O
-	O
value	O
pairs	O
to	O
an	O
output	O
,	O
where	O
the	O
query	O
,	O
keys	O
,	O
values	O
,	O
and	O
output	O
are	O
all	O
vectors	O
.	O
	
The	O
output	O
is	O
computed	O
as	O
a	O
weighted	O
sum	O
of	O
the	O
values	O
,	O
where	O
the	O
weight	O
assigned	O
to	O
each	O
value	O
is	O
computed	O
by	O
a	O
compatibility	O
function	O
of	O
the	O
query	O
with	O
the	O
corresponding	O
key	O
.	O
	
subsubsection	B-Method
:	O
Scaled	B-Method
Dot	I-Method
-	I-Method
Product	I-Method
Attention	I-Method
	
We	O
call	O
our	O
particular	O
attention	O
"	O
Scaled	B-Method
Dot	I-Method
-	I-Method
Product	I-Method
Attention	I-Method
"	O
(	O
Figure	O
[	O
reference	O
]	O
)	O
.	O
	
The	O
input	O
consists	O
of	O
queries	O
and	O
keys	O
of	O
dimension	O
,	O
and	O
values	O
of	O
dimension	O
.	O
	
We	O
compute	O
the	O
dot	O
products	O
of	O
the	O
query	O
with	O
all	O
keys	O
,	O
divide	O
each	O
by	O
,	O
and	O
apply	O
a	O
softmax	B-Method
function	I-Method
to	O
obtain	O
the	O
weights	O
on	O
the	O
values	O
.	O
	
In	O
practice	O
,	O
we	O
compute	O
the	O
attention	O
function	O
on	O
a	O
set	O
of	O
queries	O
simultaneously	O
,	O
packed	O
together	O
into	O
a	O
matrix	O
.	O
	
The	O
keys	O
and	O
values	O
are	O
also	O
packed	O
together	O
into	O
matrices	O
and	O
.	O
	
We	O
compute	O
the	O
matrix	O
of	O
outputs	O
as	O
:	O
The	O
two	O
most	O
commonly	O
used	O
attention	B-Method
functions	I-Method
are	O
additive	B-Method
attention	I-Method
bahdanau2014neural	O
,	O
and	O
dot	B-Method
-	I-Method
product	I-Method
(	I-Method
multiplicative	I-Method
)	I-Method
attention	I-Method
.	O
	
Dot	B-Method
-	I-Method
product	I-Method
attention	I-Method
is	O
identical	O
to	O
our	O
algorithm	O
,	O
except	O
for	O
the	O
scaling	O
factor	O
of	O
.	O
	
Additive	B-Method
attention	I-Method
computes	O
the	O
compatibility	O
function	O
using	O
a	O
feed	B-Method
-	I-Method
forward	I-Method
network	I-Method
with	O
a	O
single	O
hidden	B-Method
layer	I-Method
.	O
	
While	O
the	O
two	O
are	O
similar	O
in	O
theoretical	B-Metric
complexity	I-Metric
,	O
dot	B-Method
-	I-Method
product	I-Method
attention	I-Method
is	O
much	O
faster	O
and	O
more	O
space	O
-	O
efficient	O
in	O
practice	O
,	O
since	O
it	O
can	O
be	O
implemented	O
using	O
highly	O
optimized	O
matrix	B-Method
multiplication	I-Method
code	I-Method
.	O
	
While	O
for	O
small	O
values	O
of	O
the	O
two	O
mechanisms	O
perform	O
similarly	O
,	O
additive	B-Method
attention	I-Method
outperforms	O
dot	B-Method
product	I-Method
attention	I-Method
without	O
scaling	B-Method
for	O
larger	O
values	O
of	O
DBLP	O
:	O
journals	O
/	O
corr	O
/	O
BritzGLL17	O
.	O
	
We	O
suspect	O
that	O
for	O
large	O
values	O
of	O
,	O
the	O
dot	O
products	O
grow	O
large	O
in	O
magnitude	O
,	O
pushing	O
the	O
softmax	O
function	O
into	O
regions	O
where	O
it	O
has	O
extremely	O
small	O
gradients	O
.	O
	
To	O
counteract	O
this	O
effect	O
,	O
we	O
scale	O
the	O
dot	O
products	O
by	O
.	O
	
subsubsection	O
:	O
Multi	B-Task
-	I-Task
Head	I-Task
Attention	I-Task
	
Scaled	B-Task
Dot	I-Task
-	I-Task
Product	I-Task
Attention	I-Task
Multi	I-Task
-	I-Task
Head	I-Task
Attention	I-Task
	
Instead	O
of	O
performing	O
a	O
single	O
attention	B-Method
function	I-Method
with	O
-	O
dimensional	O
keys	O
,	O
values	O
and	O
queries	O
,	O
we	O
found	O
it	O
beneficial	O
to	O
linearly	O
project	O
the	O
queries	O
,	O
keys	O
and	O
values	O
times	O
with	O
different	O
,	O
learned	O
linear	O
projections	O
to	O
,	O
and	O
dimensions	O
,	O
respectively	O
.	O
	
On	O
each	O
of	O
these	O
projected	O
versions	O
of	O
queries	O
,	O
keys	O
and	O
values	O
we	O
then	O
perform	O
the	O
attention	B-Method
function	I-Method
in	O
parallel	O
,	O
yielding	O
-	O
dimensional	O
output	O
values	O
.	O
	
These	O
are	O
concatenated	O
and	O
once	O
again	O
projected	O
,	O
resulting	O
in	O
the	O
final	O
values	O
,	O
as	O
depicted	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Multi	B-Task
-	I-Task
head	I-Task
attention	I-Task
allows	O
the	O
model	O
to	O
jointly	O
attend	O
to	O
information	O
from	O
different	O
representation	O
subspaces	O
at	O
different	O
positions	O
.	O
	
With	O
a	O
single	O
attention	O
head	O
,	O
averaging	O
inhibits	O
this	O
.	O
	
Where	O
the	O
projections	O
are	O
parameter	O
matrices	O
,	O
,	O
and	O
.	O
	
In	O
this	O
work	O
we	O
employ	O
parallel	O
attention	O
layers	O
,	O
or	O
heads	O
.	O
	
For	O
each	O
of	O
these	O
we	O
use	O
.	O
	
Due	O
to	O
the	O
reduced	O
dimension	O
of	O
each	O
head	O
,	O
the	O
total	O
computational	B-Metric
cost	I-Metric
is	O
similar	O
to	O
that	O
of	O
single	B-Method
-	I-Method
head	I-Method
attention	I-Method
with	O
full	O
dimensionality	O
.	O
	
subsubsection	O
:	O
Applications	O
of	O
Attention	O
in	O
our	O
Model	O
	
The	O
Transformer	B-Method
uses	O
multi	O
-	O
head	O
attention	O
in	O
three	O
different	O
ways	O
:	O
In	O
"	O
encoder	B-Method
-	I-Method
decoder	I-Method
attention	I-Method
"	I-Method
layers	I-Method
,	O
the	O
queries	O
come	O
from	O
the	O
previous	O
decoder	B-Method
layer	I-Method
,	O
and	O
the	O
memory	O
keys	O
and	O
values	O
come	O
from	O
the	O
output	O
of	O
the	O
encoder	B-Method
.	O
	
This	O
allows	O
every	O
position	O
in	O
the	O
decoder	O
to	O
attend	O
over	O
all	O
positions	O
in	O
the	O
input	O
sequence	O
.	O
	
This	O
mimics	O
the	O
typical	O
encoder	B-Method
-	I-Method
decoder	I-Method
attention	I-Method
mechanisms	I-Method
in	O
sequence	B-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
models	I-Method
such	O
as	O
wu2016google	B-Method
,	O
bahdanau2014neural	B-Method
,	O
JonasFaceNet2017	B-Method
.	O
	
The	O
encoder	B-Method
contains	O
self	B-Method
-	I-Method
attention	I-Method
layers	I-Method
.	O
	
In	O
a	O
self	B-Method
-	I-Method
attention	I-Method
layer	I-Method
all	O
of	O
the	O
keys	O
,	O
values	O
and	O
queries	O
come	O
from	O
the	O
same	O
place	O
,	O
in	O
this	O
case	O
,	O
the	O
output	O
of	O
the	O
previous	O
layer	O
in	O
the	O
encoder	B-Method
.	O
	
Each	O
position	O
in	O
the	O
encoder	O
can	O
attend	O
to	O
all	O
positions	O
in	O
the	O
previous	O
layer	O
of	O
the	O
encoder	O
.	O
	
Similarly	O
,	O
self	O
-	O
attention	O
layers	O
in	O
the	O
decoder	O
allow	O
each	O
position	O
in	O
the	O
decoder	O
to	O
attend	O
to	O
all	O
positions	O
in	O
the	O
decoder	O
up	O
to	O
and	O
including	O
that	O
position	O
.	O
	
We	O
need	O
to	O
prevent	O
leftward	O
information	O
flow	O
in	O
the	O
decoder	O
to	O
preserve	O
the	O
auto	O
-	O
regressive	O
property	O
.	O
	
We	O
implement	O
this	O
inside	O
of	O
scaled	B-Method
dot	I-Method
-	I-Method
product	I-Method
attention	I-Method
by	O
masking	O
out	O
(	O
setting	O
to	O
)	O
all	O
values	O
in	O
the	O
input	O
of	O
the	O
softmax	O
which	O
correspond	O
to	O
illegal	O
connections	O
.	O
	
See	O
Figure	O
[	O
reference	O
]	O
.	O
	
subsection	O
:	O
Position	B-Method
-	I-Method
wise	I-Method
Feed	I-Method
-	I-Method
Forward	I-Method
Networks	I-Method
	
In	O
addition	O
to	O
attention	O
sub	O
-	O
layers	O
,	O
each	O
of	O
the	O
layers	O
in	O
our	O
encoder	B-Method
and	I-Method
decoder	I-Method
contains	O
a	O
fully	B-Method
connected	I-Method
feed	I-Method
-	I-Method
forward	I-Method
network	I-Method
,	O
which	O
is	O
applied	O
to	O
each	O
position	O
separately	O
and	O
identically	O
.	O
	
This	O
consists	O
of	O
two	O
linear	B-Method
transformations	I-Method
with	O
a	O
ReLU	O
activation	O
in	O
between	O
.	O
	
While	O
the	O
linear	B-Method
transformations	I-Method
are	O
the	O
same	O
across	O
different	O
positions	O
,	O
they	O
use	O
different	O
parameters	O
from	O
layer	O
to	O
layer	O
.	O
	
Another	O
way	O
of	O
describing	O
this	O
is	O
as	O
two	O
convolutions	B-Method
with	O
kernel	O
size	O
1	O
.	O
	
The	O
dimensionality	O
of	O
input	O
and	O
output	O
is	O
,	O
and	O
the	O
inner	B-Method
-	I-Method
layer	I-Method
has	O
dimensionality	O
.	O
	
subsection	O
:	O
Embeddings	B-Task
and	O
Softmax	B-Task
	
Similarly	O
to	O
other	O
sequence	B-Method
transduction	I-Method
models	I-Method
,	O
we	O
use	O
learned	O
embeddings	O
to	O
convert	O
the	O
input	O
tokens	O
and	O
output	O
tokens	O
to	O
vectors	O
of	O
dimension	O
.	O
	
We	O
also	O
use	O
the	O
usual	O
learned	O
linear	O
transformation	O
and	O
softmax	O
function	O
to	O
convert	O
the	O
decoder	O
output	O
to	O
predicted	O
next	O
-	O
token	O
probabilities	O
.	O
	
In	O
our	O
model	O
,	O
we	O
share	O
the	O
same	O
weight	O
matrix	O
between	O
the	O
two	O
embedding	O
layers	O
and	O
the	O
pre	B-Method
-	I-Method
softmax	I-Method
linear	I-Method
transformation	I-Method
,	O
similar	O
to	O
press2016using	O
.	O
	
In	O
the	O
embedding	O
layers	O
,	O
we	O
multiply	O
those	O
weights	O
by	O
.	O
	
subsection	O
:	O
Positional	B-Method
Encoding	I-Method
	
Since	O
our	O
model	O
contains	O
no	O
recurrence	O
and	O
no	O
convolution	B-Method
,	O
in	O
order	O
for	O
the	O
model	O
to	O
make	O
use	O
of	O
the	O
order	O
of	O
the	O
sequence	O
,	O
we	O
must	O
inject	O
some	O
information	O
about	O
the	O
relative	O
or	O
absolute	O
position	O
of	O
the	O
tokens	O
in	O
the	O
sequence	O
.	O
	
To	O
this	O
end	O
,	O
we	O
add	O
"	O
positional	O
encodings	O
"	O
to	O
the	O
input	O
embeddings	O
at	O
the	O
bottoms	O
of	O
the	O
encoder	O
and	O
decoder	O
stacks	O
.	O
	
The	O
positional	B-Method
encodings	I-Method
have	O
the	O
same	O
dimension	O
as	O
the	O
embeddings	O
,	O
so	O
that	O
the	O
two	O
can	O
be	O
summed	O
.	O
	
There	O
are	O
many	O
choices	O
of	O
positional	B-Method
encodings	I-Method
,	O
learned	O
and	O
fixed	O
JonasFaceNet2017	O
.	O
	
In	O
this	O
work	O
,	O
we	O
use	O
sine	O
and	O
cosine	O
functions	O
of	O
different	O
frequencies	O
:	O
where	O
is	O
the	O
position	O
and	O
is	O
the	O
dimension	O
.	O
	
That	O
is	O
,	O
each	O
dimension	O
of	O
the	O
positional	B-Method
encoding	I-Method
corresponds	O
to	O
a	O
sinusoid	O
.	O
	
The	O
wavelengths	O
form	O
a	O
geometric	O
progression	O
from	O
to	O
.	O
	
We	O
chose	O
this	O
function	O
because	O
we	O
hypothesized	O
it	O
would	O
allow	O
the	O
model	O
to	O
easily	O
learn	O
to	O
attend	O
by	O
relative	O
positions	O
,	O
since	O
for	O
any	O
fixed	O
offset	O
,	O
can	O
be	O
represented	O
as	O
a	O
linear	O
function	O
of	O
.	O
	
We	O
also	O
experimented	O
with	O
using	O
learned	O
positional	O
embeddings	O
JonasFaceNet2017	O
instead	O
,	O
and	O
found	O
that	O
the	O
two	O
versions	O
produced	O
nearly	O
identical	O
results	O
(	O
see	O
Table	O
[	O
reference	O
]	O
row	O
(	O
E	O
)	O
)	O
.	O
	
We	O
chose	O
the	O
sinusoidal	B-Method
version	I-Method
because	O
it	O
may	O
allow	O
the	O
model	O
to	O
extrapolate	O
to	O
sequence	O
lengths	O
longer	O
than	O
the	O
ones	O
encountered	O
during	O
training	O
.	O
	
section	O
:	O
Why	O
Self	O
-	O
Attention	O
	
In	O
this	O
section	O
we	O
compare	O
various	O
aspects	O
of	O
self	B-Method
-	I-Method
attention	I-Method
layers	I-Method
to	O
the	O
recurrent	B-Method
and	O
convolutional	B-Method
layers	I-Method
commonly	O
used	O
for	O
mapping	O
one	O
variable	O
-	O
length	O
sequence	O
of	O
symbol	O
representations	O
to	O
another	O
sequence	O
of	O
equal	O
length	O
,	O
with	O
,	O
such	O
as	O
a	O
hidden	B-Method
layer	I-Method
in	O
a	O
typical	O
sequence	B-Method
transduction	I-Method
encoder	I-Method
or	I-Method
decoder	I-Method
.	O
	
Motivating	O
our	O
use	O
of	O
self	B-Method
-	I-Method
attention	I-Method
we	O
consider	O
three	O
desiderata	O
.	O
	
One	O
is	O
the	O
total	O
computational	B-Metric
complexity	I-Metric
per	O
layer	O
.	O
	
Another	O
is	O
the	O
amount	O
of	O
computation	O
that	O
can	O
be	O
parallelized	O
,	O
as	O
measured	O
by	O
the	O
minimum	O
number	O
of	O
sequential	O
operations	O
required	O
.	O
	
The	O
third	O
is	O
the	O
path	O
length	O
between	O
long	O
-	O
range	O
dependencies	O
in	O
the	O
network	O
.	O
	
Learning	B-Task
long	I-Task
-	I-Task
range	I-Task
dependencies	I-Task
is	O
a	O
key	O
challenge	O
in	O
many	O
sequence	B-Task
transduction	I-Task
tasks	I-Task
.	O
	
One	O
key	O
factor	O
affecting	O
the	O
ability	O
to	O
learn	O
such	O
dependencies	O
is	O
the	O
length	O
of	O
the	O
paths	O
forward	O
and	O
backward	O
signals	O
have	O
to	O
traverse	O
in	O
the	O
network	O
.	O
	
The	O
shorter	O
these	O
paths	O
between	O
any	O
combination	O
of	O
positions	O
in	O
the	O
input	O
and	O
output	O
sequences	O
,	O
the	O
easier	O
it	O
is	O
to	O
learn	O
long	O
-	O
range	O
dependencies	O
hochreiter2001gradient	O
.	O
	
Hence	O
we	O
also	O
compare	O
the	O
maximum	O
path	O
length	O
between	O
any	O
two	O
input	O
and	O
output	O
positions	O
in	O
networks	O
composed	O
of	O
the	O
different	O
layer	O
types	O
.	O
	
As	O
noted	O
in	O
Table	O
[	O
reference	O
]	O
,	O
a	O
self	B-Method
-	I-Method
attention	I-Method
layer	I-Method
connects	O
all	O
positions	O
with	O
a	O
constant	O
number	O
of	O
sequentially	O
executed	O
operations	O
,	O
whereas	O
a	O
recurrent	B-Method
layer	O
requires	O
sequential	O
operations	O
.	O
	
In	O
terms	O
of	O
computational	B-Metric
complexity	I-Metric
,	O
self	B-Method
-	I-Method
attention	I-Method
layers	I-Method
are	O
faster	O
than	O
recurrent	B-Method
layers	O
when	O
the	O
sequence	O
length	O
is	O
smaller	O
than	O
the	O
representation	O
dimensionality	O
,	O
which	O
is	O
most	O
often	O
the	O
case	O
with	O
sentence	B-Method
representations	I-Method
used	O
by	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
in	O
machine	B-Task
translations	I-Task
,	O
such	O
as	O
word	B-Method
-	I-Method
piece	I-Method
wu2016google	O
and	O
byte	B-Method
-	I-Method
pair	I-Method
sennrich2015neural	O
representations	O
.	O
	
To	O
improve	O
computational	B-Task
performance	O
for	O
tasks	O
involving	O
very	O
long	O
sequences	O
,	O
self	B-Task
-	I-Task
attention	I-Task
could	O
be	O
restricted	O
to	O
considering	O
only	O
a	O
neighborhood	O
of	O
size	O
in	O
the	O
input	O
sequence	O
centered	O
around	O
the	O
respective	O
output	O
position	O
.	O
	
This	O
would	O
increase	O
the	O
maximum	O
path	O
length	O
to	O
.	O
	
We	O
plan	O
to	O
investigate	O
this	O
approach	O
further	O
in	O
future	O
work	O
.	O
	
A	O
single	O
convolutional	B-Method
layer	I-Method
with	O
kernel	O
width	O
does	O
not	O
connect	O
all	O
pairs	O
of	O
input	O
and	O
output	O
positions	O
.	O
	
Doing	O
so	O
requires	O
a	O
stack	O
of	O
convolutional	B-Method
layers	I-Method
in	O
the	O
case	O
of	O
contiguous	O
kernels	O
,	O
or	O
in	O
the	O
case	O
of	O
dilated	O
convolutions	O
NalBytenet2017	O
,	O
increasing	O
the	O
length	O
of	O
the	O
longest	O
paths	O
between	O
any	O
two	O
positions	O
in	O
the	O
network	O
.	O
	
Convolutional	B-Method
layers	I-Method
are	O
generally	O
more	O
expensive	O
than	O
recurrent	B-Method
layers	O
,	O
by	O
a	O
factor	O
of	O
.	O
	
Separable	B-Method
convolutions	I-Method
xception2016	O
,	O
however	O
,	O
decrease	O
the	O
complexity	B-Metric
considerably	O
,	O
to	O
.	O
	
Even	O
with	O
,	O
however	O
,	O
the	O
complexity	B-Metric
of	O
a	O
separable	B-Method
convolution	I-Method
is	O
equal	O
to	O
the	O
combination	O
of	O
a	O
self	B-Method
-	I-Method
attention	I-Method
layer	I-Method
and	O
a	O
point	B-Method
-	I-Method
wise	I-Method
feed	I-Method
-	I-Method
forward	I-Method
layer	I-Method
,	O
the	O
approach	O
we	O
take	O
in	O
our	O
model	O
.	O
	
As	O
side	O
benefit	O
,	O
self	O
-	O
attention	O
could	O
yield	O
more	O
interpretable	O
models	O
.	O
	
We	O
inspect	O
attention	O
distributions	O
from	O
our	O
models	O
and	O
present	O
and	O
discuss	O
examples	O
in	O
the	O
appendix	O
.	O
	
Not	O
only	O
do	O
individual	O
attention	O
heads	O
clearly	O
learn	O
to	O
perform	O
different	O
tasks	O
,	O
many	O
appear	O
to	O
exhibit	O
behavior	O
related	O
to	O
the	O
syntactic	O
and	O
semantic	O
structure	O
of	O
the	O
sentences	O
.	O
	
section	O
:	O
Training	O
	
This	O
section	O
describes	O
the	O
training	O
regime	O
for	O
our	O
models	O
.	O
	
subsection	O
:	O
Training	O
Data	O
and	O
Batching	O
	
We	O
trained	O
on	O
the	O
standard	O
WMT	B-Material
2014	I-Material
English	I-Material
-	I-Material
German	I-Material
dataset	I-Material
consisting	O
of	O
about	O
4.5	O
million	O
sentence	O
pairs	O
.	O
	
Sentences	O
were	O
encoded	O
using	O
byte	B-Method
-	I-Method
pair	I-Method
encoding	O
DBLP	O
:	O
journals	O
/	O
corr	O
/	O
BritzGLL17	O
,	O
which	O
has	O
a	O
shared	O
source	O
-	O
target	O
vocabulary	O
of	O
about	O
37000	O
tokens	O
.	O
	
For	O
English	B-Material
-	I-Material
French	I-Material
,	O
we	O
used	O
the	O
significantly	O
larger	O
WMT	B-Material
2014	I-Material
English	I-Material
-	I-Material
French	I-Material
dataset	I-Material
consisting	O
of	O
36	O
M	O
sentences	O
and	O
split	O
tokens	O
into	O
a	O
32000	O
word	O
-	O
piece	O
vocabulary	O
wu2016google	O
.	O
	
Sentence	O
pairs	O
were	O
batched	O
together	O
by	O
approximate	O
sequence	O
length	O
.	O
	
Each	O
training	O
batch	O
contained	O
a	O
set	O
of	O
sentence	O
pairs	O
containing	O
approximately	O
25000	O
source	O
tokens	O
and	O
25000	O
target	O
tokens	O
.	O
	
subsection	O
:	O
Hardware	O
and	O
Schedule	O
	
We	O
trained	O
our	O
models	O
on	O
one	O
machine	O
with	O
8	O
NVIDIA	B-Method
P100	I-Method
GPUs	I-Method
.	O
	
For	O
our	O
base	B-Method
models	I-Method
using	O
the	O
hyperparameters	O
described	O
throughout	O
the	O
paper	O
,	O
each	O
training	O
step	O
took	O
about	O
0.4	O
seconds	O
.	O
	
We	O
trained	O
the	O
base	B-Method
models	I-Method
for	O
a	O
total	O
of	O
100	O
,	O
000	O
steps	O
or	O
12	O
hours	O
.	O
	
For	O
our	O
big	B-Method
models	I-Method
,(	O
described	O
on	O
the	O
bottom	O
line	O
of	O
table	O
[	O
reference	O
]	O
)	O
,	O
step	O
time	O
was	O
1.0	O
seconds	O
.	O
	
The	O
big	B-Method
models	I-Method
were	O
trained	O
for	O
300	O
,	O
000	O
steps	O
(	O
3.5	O
days	O
)	O
.	O
	
subsection	O
:	O
Optimizer	O
	
We	O
used	O
the	O
Adam	B-Method
optimizer	I-Method
kingma2014adam	O
with	O
,	O
and	O
.	O
	
We	O
varied	O
the	O
learning	B-Metric
rate	I-Metric
over	O
the	O
course	O
of	O
training	O
,	O
according	O
to	O
the	O
formula	O
:	O
This	O
corresponds	O
to	O
increasing	O
the	O
learning	B-Metric
rate	I-Metric
linearly	O
for	O
the	O
first	O
training	O
steps	O
,	O
and	O
decreasing	O
it	O
thereafter	O
proportionally	O
to	O
the	O
inverse	O
square	O
root	O
of	O
the	O
step	O
number	O
.	O
	
We	O
used	O
.	O
	
subsection	O
:	O
Regularization	B-Task
	
We	O
employ	O
three	O
types	O
of	O
regularization	B-Method
during	O
training	B-Task
:	O
	
paragraph	O
:	O
Residual	O
Dropout	O
	
We	O
apply	O
dropout	B-Method
srivastava2014dropout	O
to	O
the	O
output	O
of	O
each	O
sub	O
-	O
layer	O
,	O
before	O
it	O
is	O
added	O
to	O
the	O
sub	O
-	O
layer	O
input	O
and	O
normalized	O
.	O
	
In	O
addition	O
,	O
we	O
apply	O
dropout	B-Method
to	O
the	O
sums	O
of	O
the	O
embeddings	O
and	O
the	O
positional	B-Method
encodings	I-Method
in	O
both	O
the	O
encoder	O
and	O
decoder	O
stacks	O
.	O
	
For	O
the	O
base	B-Method
model	I-Method
,	O
we	O
use	O
a	O
rate	O
of	O
.	O
	
paragraph	O
:	O
Label	B-Method
Smoothing	I-Method
	
During	O
training	B-Task
,	O
we	O
employed	O
label	B-Method
smoothing	I-Method
of	I-Method
value	I-Method
DBLP	I-Method
:	O
journals	O
/	O
corr	O
/	O
SzegedyVISW15	O
.	O
	
This	O
hurts	O
perplexity	O
,	O
as	O
the	O
model	O
learns	O
to	O
be	O
more	O
unsure	O
,	O
but	O
improves	O
accuracy	B-Metric
and	O
BLEU	B-Metric
score	I-Metric
.	O
	
section	O
:	O
Results	O
	
subsection	O
:	O
Machine	B-Task
Translation	I-Task
	
On	O
the	O
WMT	B-Task
2014	I-Task
English	I-Task
-	I-Task
to	I-Task
-	I-Task
German	I-Task
translation	I-Task
task	I-Task
,	O
the	O
big	B-Method
transformer	I-Method
model	I-Method
(	O
Transformer	B-Method
(	O
big	O
)	O
in	O
Table	O
[	O
reference	O
]	O
)	O
outperforms	O
the	O
best	O
previously	O
reported	O
models	O
(	O
including	O
ensembles	B-Method
)	O
by	O
more	O
than	O
BLEU	B-Metric
,	O
establishing	O
a	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
BLEU	B-Metric
score	I-Metric
of	O
.	O
	
The	O
configuration	O
of	O
this	O
model	O
is	O
listed	O
in	O
the	O
bottom	O
line	O
of	O
Table	O
[	O
reference	O
]	O
.	O
	
Training	O
took	O
days	O
on	O
P100	B-Method
GPUs	I-Method
.	O
	
Even	O
our	O
base	B-Method
model	I-Method
surpasses	O
all	O
previously	O
published	O
models	O
and	O
ensembles	O
,	O
at	O
a	O
fraction	O
of	O
the	O
training	B-Metric
cost	I-Metric
of	O
any	O
of	O
the	O
competitive	B-Method
models	I-Method
.	O
	
On	O
the	O
WMT	B-Task
2014	I-Task
English	I-Task
-	I-Task
to	I-Task
-	I-Task
French	I-Task
translation	I-Task
task	I-Task
,	O
our	O
big	B-Method
model	I-Method
achieves	O
a	O
BLEU	B-Metric
score	I-Metric
of	O
,	O
outperforming	O
all	O
of	O
the	O
previously	O
published	O
single	O
models	O
,	O
at	O
less	O
than	O
the	O
training	B-Metric
cost	I-Metric
of	O
the	O
previous	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
model	O
.	O
	
The	O
Transformer	B-Method
(	O
big	O
)	O
model	O
trained	O
for	O
English	B-Material
-	I-Material
to	I-Material
-	I-Material
French	I-Material
used	O
dropout	B-Method
rate	O
,	O
instead	O
of	O
.	O
	
For	O
the	O
base	B-Method
models	I-Method
,	O
we	O
used	O
a	O
single	O
model	O
obtained	O
by	O
averaging	O
the	O
last	O
5	O
checkpoints	O
,	O
which	O
were	O
written	O
at	O
10	O
-	O
minute	O
intervals	O
.	O
	
For	O
the	O
big	B-Method
models	I-Method
,	O
we	O
averaged	O
the	O
last	O
20	O
checkpoints	O
.	O
	
We	O
used	O
beam	B-Method
search	I-Method
with	O
a	O
beam	O
size	O
of	O
and	O
length	O
penalty	O
wu2016google	O
.	O
	
These	O
hyperparameters	O
were	O
chosen	O
after	O
experimentation	O
on	O
the	O
development	O
set	O
.	O
	
We	O
set	O
the	O
maximum	O
output	O
length	O
during	O
inference	B-Task
to	O
input	O
length	O
+	O
,	O
but	O
terminate	O
early	O
when	O
possible	O
wu2016google	O
.	O
	
Table	O
[	O
reference	O
]	O
summarizes	O
our	O
results	O
and	O
compares	O
our	O
translation	B-Metric
quality	I-Metric
and	O
training	B-Metric
costs	I-Metric
to	O
other	O
model	O
architectures	O
from	O
the	O
literature	O
.	O
	
We	O
estimate	O
the	O
number	O
of	O
floating	O
point	O
operations	O
used	O
to	O
train	O
a	O
model	O
by	O
multiplying	O
the	O
training	B-Metric
time	I-Metric
,	O
the	O
number	O
of	O
GPUs	O
used	O
,	O
and	O
an	O
estimate	O
of	O
the	O
sustained	O
single	O
-	O
precision	O
floating	O
-	O
point	O
capacity	O
of	O
each	O
GPU	O
.	O
	
subsection	O
:	O
Model	O
Variations	O
	
To	O
evaluate	O
the	O
importance	O
of	O
different	O
components	O
of	O
the	O
Transformer	B-Method
,	O
we	O
varied	O
our	O
base	B-Method
model	I-Method
in	O
different	O
ways	O
,	O
measuring	O
the	O
change	O
in	O
performance	O
on	O
English	B-Task
-	I-Task
to	I-Task
-	I-Task
German	I-Task
translation	I-Task
on	O
the	O
development	O
set	O
,	O
newstest2013	O
.	O
	
We	O
used	O
beam	B-Method
search	I-Method
as	O
described	O
in	O
the	O
previous	O
section	O
,	O
but	O
no	O
checkpoint	B-Method
averaging	I-Method
.	O
	
We	O
present	O
these	O
results	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
In	O
Table	O
[	O
reference	O
]	O
rows	O
(	O
A	O
)	O
,	O
we	O
vary	O
the	O
number	O
of	O
attention	O
heads	O
and	O
the	O
attention	O
key	O
and	O
value	O
dimensions	O
,	O
keeping	O
the	O
amount	O
of	O
computation	O
constant	O
,	O
as	O
described	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
While	O
single	B-Method
-	I-Method
head	I-Method
attention	I-Method
is	O
0.9	O
BLEU	B-Metric
worse	O
than	O
the	O
best	O
setting	O
,	O
quality	B-Metric
also	O
drops	O
off	O
with	O
too	O
many	O
heads	O
.	O
	
In	O
Table	O
[	O
reference	O
]	O
rows	O
(	O
B	O
)	O
,	O
we	O
observe	O
that	O
reducing	O
the	O
attention	B-Metric
key	I-Metric
size	I-Metric
hurts	O
model	B-Metric
quality	I-Metric
.	O
	
This	O
suggests	O
that	O
determining	O
compatibility	O
is	O
not	O
easy	O
and	O
that	O
a	O
more	O
sophisticated	O
compatibility	O
function	O
than	O
dot	B-Method
product	I-Method
may	O
be	O
beneficial	O
.	O
	
We	O
further	O
observe	O
in	O
rows	O
(	O
C	O
)	O
and	O
(	O
D	O
)	O
that	O
,	O
as	O
expected	O
,	O
bigger	O
models	O
are	O
better	O
,	O
and	O
dropout	B-Method
is	O
very	O
helpful	O
in	O
avoiding	O
over	B-Task
-	I-Task
fitting	I-Task
.	O
	
In	O
row	O
(	O
E	O
)	O
we	O
replace	O
our	O
sinusoidal	B-Method
positional	I-Method
encoding	I-Method
with	O
learned	O
positional	B-Method
embeddings	I-Method
JonasFaceNet2017	O
,	O
and	O
observe	O
nearly	O
identical	O
results	O
to	O
the	O
base	B-Method
model	I-Method
.	O
	
subsection	O
:	O
English	B-Task
Constituency	I-Task
Parsing	I-Task
	
To	O
evaluate	O
if	O
the	O
Transformer	B-Method
can	O
generalize	O
to	O
other	O
tasks	O
we	O
performed	O
experiments	O
on	O
English	B-Task
constituency	I-Task
parsing	I-Task
.	O
	
This	O
task	O
presents	O
specific	O
challenges	O
:	O
the	O
output	O
is	O
subject	O
to	O
strong	O
structural	O
constraints	O
and	O
is	O
significantly	O
longer	O
than	O
the	O
input	O
.	O
	
Furthermore	O
,	O
RNN	B-Method
sequence	I-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
models	I-Method
have	O
not	O
been	O
able	O
to	O
attain	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
in	O
small	B-Task
-	I-Task
data	I-Task
regimes	I-Task
.	O
	
We	O
trained	O
a	O
4	B-Method
-	I-Method
layer	I-Method
transformer	I-Method
with	O
on	O
the	O
Wall	O
Street	O
Journal	O
(	O
WSJ	O
)	O
portion	O
of	O
the	O
Penn	B-Material
Treebank	I-Material
marcus1993building	O
,	O
about	O
40	O
K	O
training	O
sentences	O
.	O
	
We	O
also	O
trained	O
it	O
in	O
a	O
semi	B-Task
-	I-Task
supervised	I-Task
setting	I-Task
,	O
using	O
the	O
larger	O
high	O
-	O
confidence	O
and	O
BerkleyParser	O
corpora	O
from	O
with	O
approximately	O
17	O
M	O
sentences	O
KVparse15	O
.	O
	
We	O
used	O
a	O
vocabulary	O
of	O
16	O
K	O
tokens	O
for	O
the	O
WSJ	B-Task
only	I-Task
setting	I-Task
and	O
a	O
vocabulary	O
of	O
32	O
K	O
tokens	O
for	O
the	O
semi	B-Task
-	I-Task
supervised	I-Task
setting	I-Task
.	O
	
We	O
performed	O
only	O
a	O
small	O
number	O
of	O
experiments	O
to	O
select	O
the	O
dropout	B-Method
,	O
both	O
attention	O
and	O
residual	O
(	O
section	O
[	O
reference	O
]	O
)	O
,	O
learning	B-Metric
rates	I-Metric
and	O
beam	B-Metric
size	I-Metric
on	O
the	O
Section	O
22	O
development	O
set	O
,	O
all	O
other	O
parameters	O
remained	O
unchanged	O
from	O
the	O
English	B-Method
-	I-Method
to	I-Method
-	I-Method
German	I-Method
base	I-Method
translation	I-Method
model	I-Method
.	O
	
During	O
inference	B-Task
,	O
we	O
increased	O
the	O
maximum	O
output	O
length	O
to	O
input	O
length	O
+	O
.	O
	
We	O
used	O
a	O
beam	O
size	O
of	O
and	O
for	O
both	O
WSJ	B-Task
only	I-Task
and	O
the	O
semi	B-Task
-	I-Task
supervised	I-Task
setting	I-Task
.	O
	
Our	O
results	O
in	O
Table	O
[	O
reference	O
]	O
show	O
that	O
despite	O
the	O
lack	O
of	O
task	O
-	O
specific	O
tuning	O
our	O
model	O
performs	O
surprisingly	O
well	O
,	O
yielding	O
better	O
results	O
than	O
all	O
previously	O
reported	O
models	O
with	O
the	O
exception	O
of	O
the	O
Recurrent	B-Method
Neural	I-Method
Network	I-Method
Grammar	I-Method
.	O
	
In	O
contrast	O
to	O
RNN	B-Method
sequence	I-Method
-	I-Method
to	I-Method
-	I-Method
sequence	I-Method
models	I-Method
KVparse15	O
,	O
the	O
Transformer	B-Method
outperforms	O
the	O
BerkeleyParser	B-Method
even	O
when	O
training	O
only	O
on	O
the	O
WSJ	O
training	O
set	O
of	O
40	O
K	O
sentences	O
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
work	O
,	O
we	O
presented	O
the	O
Transformer	B-Method
,	O
the	O
first	O
sequence	B-Method
transduction	I-Method
model	I-Method
based	O
entirely	O
on	O
attention	B-Method
,	O
replacing	O
the	O
recurrent	B-Method
layers	O
most	O
commonly	O
used	O
in	O
encoder	B-Method
-	I-Method
decoder	I-Method
architectures	I-Method
with	O
multi	O
-	O
headed	O
self	O
-	O
attention	O
.	O
	
For	O
translation	B-Task
tasks	I-Task
,	O
the	O
Transformer	B-Method
can	O
be	O
trained	O
significantly	O
faster	O
than	O
architectures	O
based	O
on	O
recurrent	B-Method
or	O
convolutional	B-Method
layers	I-Method
.	O
	
On	O
both	O
WMT	B-Task
2014	I-Task
English	I-Task
-	I-Task
to	I-Task
-	I-Task
German	I-Task
and	O
WMT	B-Task
2014	I-Task
English	I-Task
-	I-Task
to	I-Task
-	I-Task
French	I-Task
translation	I-Task
tasks	I-Task
,	O
we	O
achieve	O
a	O
new	O
state	O
of	O
the	O
art	O
.	O
	
In	O
the	O
former	O
task	O
our	O
best	O
model	O
outperforms	O
even	O
all	O
previously	O
reported	O
ensembles	O
.	O
	
We	O
are	O
excited	O
about	O
the	O
future	O
of	O
attention	B-Method
-	I-Method
based	I-Method
models	I-Method
and	O
plan	O
to	O
apply	O
them	O
to	O
other	O
tasks	O
.	O
	
We	O
plan	O
to	O
extend	O
the	O
Transformer	B-Method
to	O
problems	O
involving	O
input	O
and	O
output	O
modalities	O
other	O
than	O
text	O
and	O
to	O
investigate	O
local	B-Method
,	I-Method
restricted	I-Method
attention	I-Method
mechanisms	I-Method
to	O
efficiently	O
handle	O
large	O
inputs	O
and	O
outputs	O
such	O
as	O
images	O
,	O
audio	O
and	O
video	O
.	O
	
Making	O
generation	B-Task
less	O
sequential	O
is	O
another	O
research	O
goals	O
of	O
ours	O
.	O
	
The	O
code	O
we	O
used	O
to	O
train	O
and	O
evaluate	O
our	O
models	O
is	O
available	O
at	O
.	O
	
paragraph	O
:	O
Acknowledgements	O
	
We	O
are	O
grateful	O
to	O
Nal	O
Kalchbrenner	O
and	O
Stephan	O
Gouws	O
for	O
their	O
fruitful	O
comments	O
,	O
corrections	O
and	O
inspiration	O
.	O
	
bibliography	O
:	O
References	O
	
appendix	O
:	O
Attention	B-Method
Visualizations	I-Method
	
document	O
:	O
Learning	O
Phrase	B-Method
Representations	I-Method
using	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
for	O
Statistical	B-Task
Machine	I-Task
Translation	I-Task
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
novel	O
neural	B-Method
network	I-Method
model	I-Method
called	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
that	O
consists	O
of	O
two	O
recurrent	B-Method
neural	I-Method
networks	I-Method
(	O
RNN	B-Method
)	O
.	O
	
One	O
RNN	B-Method
encodes	O
a	O
sequence	O
of	O
symbols	O
into	O
a	O
fixed	B-Method
-	I-Method
length	I-Method
vector	I-Method
representation	I-Method
,	O
and	O
the	O
other	O
decodes	O
the	O
representation	O
into	O
another	O
sequence	O
of	O
symbols	O
.	O
	
The	O
encoder	B-Method
and	O
decoder	B-Method
of	O
the	O
proposed	O
model	O
are	O
jointly	O
trained	O
to	O
maximize	O
the	O
conditional	O
probability	O
of	O
a	O
target	O
sequence	O
given	O
a	O
source	O
sequence	O
.	O
	
The	O
performance	O
of	O
a	O
statistical	B-Task
machine	I-Task
translation	I-Task
system	I-Task
is	O
empirically	O
found	O
to	O
improve	O
by	O
using	O
the	O
conditional	O
probabilities	O
of	O
phrase	O
pairs	O
computed	O
by	O
the	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
as	O
an	O
additional	O
feature	O
in	O
the	O
existing	O
log	B-Method
-	I-Method
linear	I-Method
model	I-Method
.	O
	
Qualitatively	O
,	O
we	O
show	O
that	O
the	O
proposed	O
model	O
learns	O
a	O
semantically	B-Method
and	O
syntactically	B-Method
meaningful	I-Method
representation	I-Method
of	O
linguistic	O
phrases	O
.	O
	
arxiv	O
arxiv.	O
/	O
figures	O
/	O
	
section	O
:	O
Introduction	O
	
Deep	B-Method
neural	I-Method
networks	I-Method
have	O
shown	O
great	O
success	O
in	O
various	O
applications	O
such	O
as	O
objection	B-Task
recognition	I-Task
(	O
see	O
,	O
e.g.	O
,	O
)	O
and	O
speech	B-Task
recognition	I-Task
(	O
see	O
,	O
e.g.	O
,	O
)	O
.	O
	
Furthermore	O
,	O
many	O
recent	O
works	O
showed	O
that	O
neural	B-Method
networks	I-Method
can	O
be	O
successfully	O
used	O
in	O
a	O
number	O
of	O
tasks	O
in	O
natural	B-Task
language	I-Task
processing	I-Task
(	O
NLP	B-Task
)	I-Task
.	O
	
These	O
include	O
,	O
but	O
are	O
not	O
limited	O
to	O
,	O
language	B-Task
modeling	I-Task
,	O
paraphrase	B-Task
detection	I-Task
and	O
word	B-Task
embedding	I-Task
extraction	I-Task
.	O
	
In	O
the	O
field	O
of	O
statistical	B-Task
machine	I-Task
translation	I-Task
(	O
SMT	B-Task
)	I-Task
,	O
deep	B-Method
neural	I-Method
networks	I-Method
have	O
begun	O
to	O
show	O
promising	O
results	O
.	O
	
summarizes	O
a	O
successful	O
usage	O
of	O
feedforward	B-Method
neural	I-Method
networks	I-Method
in	O
the	O
framework	O
of	O
phrase	B-Method
-	I-Method
based	I-Method
SMT	I-Method
system	I-Method
.	O
	
Along	O
this	O
line	O
of	O
research	O
on	O
using	O
neural	B-Method
networks	I-Method
for	O
SMT	B-Task
,	O
this	O
paper	O
focuses	O
on	O
a	O
novel	O
neural	B-Method
network	I-Method
architecture	I-Method
that	O
can	O
be	O
used	O
as	O
a	O
part	O
of	O
the	O
conventional	O
phrase	B-Method
-	I-Method
based	I-Method
SMT	I-Method
system	I-Method
.	O
	
The	O
proposed	O
neural	B-Method
network	I-Method
architecture	I-Method
,	O
which	O
we	O
will	O
refer	O
to	O
as	O
an	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
,	O
consists	O
of	O
two	O
recurrent	B-Method
neural	I-Method
networks	I-Method
(	O
RNN	B-Method
)	O
that	O
act	O
as	O
an	O
encoder	B-Method
and	O
a	O
decoder	O
pair	O
.	O
	
The	O
encoder	B-Method
maps	O
a	O
variable	O
-	O
length	O
source	O
sequence	O
to	O
a	O
fixed	O
-	O
length	O
vector	O
,	O
and	O
the	O
decoder	B-Method
maps	O
the	O
vector	B-Method
representation	I-Method
back	O
to	O
a	O
variable	O
-	O
length	O
target	O
sequence	O
.	O
	
The	O
two	O
networks	O
are	O
trained	O
jointly	O
to	O
maximize	O
the	O
conditional	O
probability	O
of	O
the	O
target	O
sequence	O
given	O
a	O
source	O
sequence	O
.	O
	
Additionally	O
,	O
we	O
propose	O
to	O
use	O
a	O
rather	O
sophisticated	O
hidden	O
unit	O
in	O
order	O
to	O
improve	O
both	O
the	O
memory	B-Metric
capacity	I-Metric
and	O
the	O
ease	O
of	O
training	B-Task
.	O
	
The	O
proposed	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
with	O
a	O
novel	O
hidden	B-Method
unit	I-Method
is	O
empirically	O
evaluated	O
on	O
the	O
task	O
of	O
translating	B-Task
from	O
English	B-Material
to	I-Material
French	I-Material
.	O
	
We	O
train	O
the	O
model	O
to	O
learn	O
the	O
translation	O
probability	O
of	O
an	O
English	O
phrase	O
to	O
a	O
corresponding	O
French	O
phrase	O
.	O
	
The	O
model	O
is	O
then	O
used	O
as	O
a	O
part	O
of	O
a	O
standard	O
phrase	B-Method
-	I-Method
based	I-Method
SMT	I-Method
system	I-Method
by	O
scoring	O
each	O
phrase	O
pair	O
in	O
the	O
phrase	O
table	O
.	O
	
The	O
empirical	O
evaluation	O
reveals	O
that	O
this	O
approach	O
of	O
scoring	B-Task
phrase	I-Task
pairs	I-Task
with	O
an	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
improves	O
the	O
translation	B-Task
performance	O
.	O
	
We	O
qualitatively	O
analyze	O
the	O
trained	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
by	O
comparing	O
its	O
phrase	O
scores	O
with	O
those	O
given	O
by	O
the	O
existing	O
translation	B-Method
model	I-Method
.	O
	
The	O
qualitative	O
analysis	O
shows	O
that	O
the	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
is	O
better	O
at	O
capturing	O
the	O
linguistic	O
regularities	O
in	O
the	O
phrase	O
table	O
,	O
indirectly	O
explaining	O
the	O
quantitative	O
improvements	O
in	O
the	O
overall	O
translation	B-Metric
performance	I-Metric
.	O
	
The	O
further	O
analysis	O
of	O
the	O
model	O
reveals	O
that	O
the	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
learns	O
a	O
continuous	B-Method
space	I-Method
representation	I-Method
of	O
a	O
phrase	O
that	O
preserves	O
both	O
the	O
semantic	O
and	O
syntactic	O
structure	O
of	O
the	O
phrase	O
.	O
	
section	O
:	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
	
subsection	O
:	O
Preliminary	O
:	O
Recurrent	B-Method
Neural	I-Method
Networks	I-Method
	
A	O
recurrent	B-Method
neural	I-Method
network	I-Method
(	O
RNN	B-Method
)	O
is	O
a	O
neural	B-Method
network	I-Method
that	O
consists	O
of	O
a	O
hidden	O
state	O
and	O
an	O
optional	O
output	O
which	O
operates	O
on	O
a	O
variable	O
-	O
length	O
sequence	O
.	O
	
At	O
each	O
time	O
step	O
,	O
the	O
hidden	O
state	O
of	O
the	O
RNN	B-Method
is	O
updated	O
by	O
where	O
is	O
a	O
non	B-Method
-	I-Method
linear	I-Method
activation	I-Method
function	I-Method
.	O
	
may	O
be	O
as	O
simple	O
as	O
an	O
element	B-Method
-	I-Method
wise	I-Method
logistic	I-Method
sigmoid	I-Method
function	I-Method
and	O
as	O
complex	O
as	O
a	O
long	B-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
(	I-Method
LSTM	I-Method
)	I-Method
unit	I-Method
.	O
	
An	O
RNN	B-Method
can	O
learn	O
a	O
probability	O
distribution	O
over	O
a	O
sequence	O
by	O
being	O
trained	O
to	O
predict	O
the	O
next	O
symbol	O
in	O
a	O
sequence	O
.	O
	
In	O
that	O
case	O
,	O
the	O
output	O
at	O
each	O
timestep	O
is	O
the	O
conditional	O
distribution	O
.	O
	
For	O
example	O
,	O
a	O
multinomial	B-Method
distribution	I-Method
(	I-Method
-	I-Method
of	I-Method
-	I-Method
coding	I-Method
)	O
can	O
be	O
output	O
using	O
a	O
softmax	B-Method
activation	I-Method
function	I-Method
for	O
all	O
possible	O
symbols	O
,	O
where	O
are	O
the	O
rows	O
of	O
a	O
weight	O
matrix	O
.	O
	
By	O
combining	O
these	O
probabilities	O
,	O
we	O
can	O
compute	O
the	O
probability	O
of	O
the	O
sequence	O
using	O
From	O
this	O
learned	B-Method
distribution	I-Method
,	O
it	O
is	O
straightforward	O
to	O
sample	O
a	O
new	O
sequence	O
by	O
iteratively	O
sampling	O
a	O
symbol	O
at	O
each	O
time	O
step	O
.	O
	
subsection	O
:	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
novel	O
neural	B-Method
network	I-Method
architecture	I-Method
that	O
learns	O
to	O
encode	O
a	O
variable	O
-	O
length	O
sequence	O
into	O
a	O
fixed	B-Method
-	I-Method
length	I-Method
vector	I-Method
representation	I-Method
and	O
to	O
decode	O
a	O
given	O
fixed	B-Method
-	I-Method
length	I-Method
vector	I-Method
representation	I-Method
back	O
into	O
a	O
variable	O
-	O
length	O
sequence	O
.	O
	
From	O
a	O
probabilistic	O
perspective	O
,	O
this	O
new	O
model	O
is	O
a	O
general	O
method	O
to	O
learn	O
the	O
conditional	O
distribution	O
over	O
a	O
variable	O
-	O
length	O
sequence	O
conditioned	O
on	O
yet	O
another	O
variable	O
-	O
length	O
sequence	O
,	O
e.g.	O
,	O
where	O
one	O
should	O
note	O
that	O
the	O
input	O
and	O
output	O
sequence	O
lengths	O
and	O
may	O
differ	O
.	O
	
The	O
encoder	B-Method
is	O
an	O
RNN	B-Method
that	O
reads	O
each	O
symbol	O
of	O
an	O
input	O
sequence	O
sequentially	O
.	O
	
As	O
it	O
reads	O
each	O
symbol	O
,	O
the	O
hidden	O
state	O
of	O
the	O
RNN	B-Method
changes	O
according	O
to	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
	
After	O
reading	O
the	O
end	O
of	O
the	O
sequence	O
(	O
marked	O
by	O
an	O
end	O
-	O
of	O
-	O
sequence	O
symbol	O
)	O
,	O
the	O
hidden	O
state	O
of	O
the	O
RNN	B-Method
is	O
a	O
summary	O
of	O
the	O
whole	O
input	O
sequence	O
.	O
	
The	O
decoder	O
of	O
the	O
proposed	O
model	O
is	O
another	O
RNN	B-Method
which	O
is	O
trained	O
to	O
generate	O
the	O
output	O
sequence	O
by	O
predicting	O
the	O
next	O
symbol	O
given	O
the	O
hidden	O
state	O
.	O
	
However	O
,	O
unlike	O
the	O
RNN	B-Method
described	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
,	O
both	O
and	O
are	O
also	O
conditioned	O
on	O
and	O
on	O
the	O
summary	O
of	O
the	O
input	O
sequence	O
.	O
	
Hence	O
,	O
the	O
hidden	O
state	O
of	O
the	O
decoder	O
at	O
time	O
is	O
computed	O
by	O
,	O
and	O
similarly	O
,	O
the	O
conditional	O
distribution	O
of	O
the	O
next	O
symbol	O
is	O
for	O
given	O
activation	O
functions	O
and	O
(	O
the	O
latter	O
must	O
produce	O
valid	O
probabilities	O
,	O
e.g.	O
with	O
a	O
softmax	B-Method
)	O
.	O
	
See	O
Fig	O
.	O
	
[	O
reference	O
]	O
for	O
a	O
graphical	O
depiction	O
of	O
the	O
proposed	O
model	B-Method
architecture	I-Method
.	O
	
The	O
two	O
components	O
of	O
the	O
proposed	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
are	O
jointly	O
trained	O
to	O
maximize	O
the	O
conditional	O
log	O
-	O
likelihood	O
where	O
is	O
the	O
set	O
of	O
the	O
model	O
parameters	O
and	O
each	O
is	O
an	O
(	O
input	O
sequence	O
,	O
output	O
sequence	O
)	O
pair	O
from	O
the	O
training	O
set	O
.	O
	
In	O
our	O
case	O
,	O
as	O
the	O
output	O
of	O
the	O
decoder	B-Method
,	O
starting	O
from	O
the	O
input	O
,	O
is	O
differentiable	O
,	O
we	O
can	O
use	O
a	O
gradient	B-Method
-	I-Method
based	I-Method
algorithm	I-Method
to	O
estimate	O
the	O
model	O
parameters	O
.	O
	
Once	O
the	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
is	O
trained	O
,	O
the	O
model	O
can	O
be	O
used	O
in	O
two	O
ways	O
.	O
	
One	O
way	O
is	O
to	O
use	O
the	O
model	O
to	O
generate	O
a	O
target	O
sequence	O
given	O
an	O
input	O
sequence	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
the	O
model	O
can	O
be	O
used	O
to	O
score	O
a	O
given	O
pair	O
of	O
input	O
and	O
output	O
sequences	O
,	O
where	O
the	O
score	O
is	O
simply	O
a	O
probability	O
from	O
Eqs	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
and	O
(	O
[	O
reference	O
]	O
)	O
.	O
	
subsection	O
:	O
Hidden	B-Method
Unit	I-Method
that	O
Adaptively	O
Remembers	O
and	O
Forgets	O
	
In	O
addition	O
to	O
a	O
novel	O
model	B-Method
architecture	I-Method
,	O
we	O
also	O
propose	O
a	O
new	O
type	O
of	O
hidden	O
unit	O
(	O
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
)	O
that	O
has	O
been	O
motivated	O
by	O
the	O
LSTM	B-Method
unit	I-Method
but	O
is	O
much	O
simpler	O
to	O
compute	O
and	O
implement	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
the	O
graphical	O
depiction	O
of	O
the	O
proposed	O
hidden	B-Method
unit	I-Method
.	O
	
Let	O
us	O
describe	O
how	O
the	O
activation	O
of	O
the	O
-	O
th	O
hidden	B-Method
unit	I-Method
is	O
computed	O
.	O
	
First	O
,	O
the	O
reset	O
gate	O
is	O
computed	O
by	O
where	O
is	O
the	O
logistic	B-Method
sigmoid	I-Method
function	I-Method
,	O
and	O
denotes	O
the	O
-	O
th	O
element	O
of	O
a	O
vector	O
.	O
	
and	O
are	O
the	O
input	O
and	O
the	O
previous	O
hidden	O
state	O
,	O
respectively	O
.	O
	
and	O
are	O
weight	O
matrices	O
which	O
are	O
learned	O
.	O
	
Similarly	O
,	O
the	O
update	O
gate	O
is	O
computed	O
by	O
The	O
actual	O
activation	O
of	O
the	O
proposed	O
unit	O
is	O
then	O
computed	O
by	O
where	O
In	O
this	O
formulation	O
,	O
when	O
the	O
reset	O
gate	O
is	O
close	O
to	O
0	O
,	O
the	O
hidden	O
state	O
is	O
forced	O
to	O
ignore	O
the	O
previous	O
hidden	O
state	O
and	O
reset	O
with	O
the	O
current	O
input	O
only	O
.	O
	
This	O
effectively	O
allows	O
the	O
hidden	O
state	O
to	O
drop	O
any	O
information	O
that	O
is	O
found	O
to	O
be	O
irrelevant	O
later	O
in	O
the	O
future	O
,	O
thus	O
,	O
allowing	O
a	O
more	O
compact	O
representation	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
the	O
update	O
gate	O
controls	O
how	O
much	O
information	O
from	O
the	O
previous	O
hidden	O
state	O
will	O
carry	O
over	O
to	O
the	O
current	O
hidden	O
state	O
.	O
	
This	O
acts	O
similarly	O
to	O
the	O
memory	O
cell	O
in	O
the	O
LSTM	B-Method
network	I-Method
and	O
helps	O
the	O
RNN	B-Method
to	O
remember	O
long	O
-	O
term	O
information	O
.	O
	
Furthermore	O
,	O
this	O
may	O
be	O
considered	O
an	O
adaptive	B-Method
variant	I-Method
of	O
a	O
leaky	B-Method
-	I-Method
integration	I-Method
unit	I-Method
.	O
	
As	O
each	O
hidden	B-Method
unit	I-Method
has	O
separate	O
reset	O
and	O
update	O
gates	O
,	O
each	O
hidden	B-Method
unit	I-Method
will	O
learn	O
to	O
capture	O
dependencies	O
over	O
different	O
time	O
scales	O
.	O
	
Those	O
units	O
that	O
learn	O
to	O
capture	O
short	O
-	O
term	O
dependencies	O
will	O
tend	O
to	O
have	O
reset	O
gates	O
that	O
are	O
frequently	O
active	O
,	O
but	O
those	O
that	O
capture	O
longer	O
-	O
term	O
dependencies	O
will	O
have	O
update	O
gates	O
that	O
are	O
mostly	O
active	O
.	O
	
In	O
our	O
preliminary	O
experiments	O
,	O
we	O
found	O
that	O
it	O
is	O
crucial	O
to	O
use	O
this	O
new	O
unit	O
with	O
gating	B-Method
units	I-Method
.	O
	
We	O
were	O
not	O
able	O
to	O
get	O
meaningful	O
result	O
with	O
an	O
oft	O
-	O
used	O
unit	O
without	O
any	O
gating	O
.	O
	
section	O
:	O
Statistical	B-Task
Machine	I-Task
Translation	I-Task
	
In	O
a	O
commonly	O
used	O
statistical	B-Task
machine	I-Task
translation	I-Task
system	I-Task
(	O
SMT	B-Task
)	I-Task
,	O
the	O
goal	O
of	O
the	O
system	O
(	O
decoder	B-Method
,	O
specifically	O
)	O
is	O
to	O
find	O
a	O
translation	O
given	O
a	O
source	O
sentence	O
,	O
which	O
maximizes	O
where	O
the	O
first	O
term	O
at	O
the	O
right	O
hand	O
side	O
is	O
called	O
translation	B-Method
model	I-Method
and	O
the	O
latter	O
language	B-Method
model	I-Method
(	O
see	O
,	O
e.g.	O
,	O
)	O
.	O
	
In	O
practice	O
,	O
however	O
,	O
most	O
SMT	B-Task
systems	O
model	O
as	O
a	O
log	B-Method
-	I-Method
linear	I-Method
model	I-Method
with	O
additional	O
features	O
and	O
corresponding	O
weights	O
:	O
where	O
and	O
are	O
the	O
-	O
th	O
feature	O
and	O
weight	O
,	O
respectively	O
.	O
	
is	O
a	O
normalization	O
constant	O
that	O
does	O
not	O
depend	O
on	O
the	O
weights	O
.	O
	
The	O
weights	O
are	O
often	O
optimized	O
to	O
maximize	O
the	O
BLEU	B-Metric
score	I-Metric
on	O
a	O
development	O
set	O
.	O
	
In	O
the	O
phrase	O
-	O
based	O
SMT	B-Task
framework	O
introduced	O
in	O
and	O
,	O
the	O
translation	B-Method
model	I-Method
is	O
factorized	O
into	O
the	O
translation	O
probabilities	O
of	O
matching	O
phrases	O
in	O
the	O
source	O
and	O
target	O
sentences	O
.	O
	
These	O
probabilities	O
are	O
once	O
again	O
considered	O
additional	O
features	O
in	O
the	O
log	B-Method
-	I-Method
linear	I-Method
model	I-Method
(	O
see	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
)	O
and	O
are	O
weighted	O
accordingly	O
to	O
maximize	O
the	O
BLEU	B-Metric
score	I-Metric
.	O
	
Since	O
the	O
neural	B-Method
net	I-Method
language	I-Method
model	I-Method
was	O
proposed	O
in	O
,	O
neural	B-Method
networks	I-Method
have	O
been	O
used	O
widely	O
in	O
SMT	B-Method
systems	I-Method
.	O
	
In	O
many	O
cases	O
,	O
neural	B-Method
networks	I-Method
have	O
been	O
used	O
to	O
rescore	B-Task
translation	I-Task
hypotheses	I-Task
	
(	O
-	O
best	O
lists	O
)	O
	
(	O
see	O
,	O
e.g.	O
,	O
)	O
.	O
	
Recently	O
,	O
however	O
,	O
there	O
has	O
been	O
interest	O
in	O
training	O
neural	B-Method
networks	I-Method
to	O
score	O
the	O
translated	O
sentence	O
(	O
or	O
phrase	O
pairs	O
)	O
using	O
a	O
representation	O
of	O
the	O
source	O
sentence	O
as	O
an	O
additional	O
input	O
.	O
	
See	O
,	O
e.g.	O
,	O
,	O
and	O
.	O
	
subsection	O
:	O
Scoring	O
Phrase	O
Pairs	O
with	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
	
Here	O
we	O
propose	O
to	O
train	O
the	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
(	O
see	O
Sec	O
.	O
	
[	O
reference	O
]	O
)	O
on	O
a	O
table	O
of	O
phrase	O
pairs	O
and	O
use	O
its	O
scores	O
as	O
additional	O
features	O
in	O
the	O
log	B-Method
-	I-Method
linear	I-Method
model	I-Method
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
	
when	O
tuning	O
the	O
SMT	B-Task
decoder	O
.	O
	
When	O
we	O
train	O
the	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
,	O
we	O
ignore	O
the	O
(	O
normalized	O
)	O
frequencies	O
of	O
each	O
phrase	O
pair	O
in	O
the	O
original	O
corpora	O
.	O
	
This	O
measure	O
was	O
taken	O
in	O
order	O
(	O
1	O
)	O
to	O
reduce	O
the	O
computational	B-Metric
expense	I-Metric
of	O
randomly	O
selecting	O
phrase	O
pairs	O
from	O
a	O
large	O
phrase	O
table	O
according	O
to	O
the	O
normalized	O
frequencies	O
and	O
(	O
2	O
)	O
to	O
ensure	O
that	O
the	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
does	O
not	O
simply	O
learn	O
to	O
rank	O
the	O
phrase	O
pairs	O
according	O
to	O
their	O
numbers	O
of	O
occurrences	O
.	O
	
One	O
underlying	O
reason	O
for	O
this	O
choice	O
was	O
that	O
the	O
existing	O
translation	O
probability	O
in	O
the	O
phrase	O
table	O
already	O
reflects	O
the	O
frequencies	O
of	O
the	O
phrase	O
pairs	O
in	O
the	O
original	O
corpus	O
.	O
	
With	O
a	O
fixed	O
capacity	O
of	O
the	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
,	O
we	O
try	O
to	O
ensure	O
that	O
most	O
of	O
the	O
capacity	O
of	O
the	O
model	O
is	O
focused	O
toward	O
learning	O
linguistic	O
regularities	O
,	O
i.e.	O
,	O
distinguishing	O
between	O
plausible	O
and	O
implausible	O
translations	O
,	O
or	O
learning	O
the	O
“	O
manifold	O
”	O
(	O
region	O
of	O
probability	O
concentration	O
)	O
of	O
plausible	O
translations	O
.	O
	
Once	O
the	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
is	O
trained	O
,	O
we	O
add	O
a	O
new	O
score	O
for	O
each	O
phrase	O
pair	O
to	O
the	O
existing	O
phrase	O
table	O
.	O
	
This	O
allows	O
the	O
new	O
scores	O
to	O
enter	O
into	O
the	O
existing	O
tuning	B-Method
algorithm	I-Method
with	O
minimal	O
additional	O
overhead	O
in	O
computation	B-Metric
.	O
	
As	O
Schwenk	O
pointed	O
out	O
in	O
,	O
it	O
is	O
possible	O
to	O
completely	O
replace	O
the	O
existing	O
phrase	O
table	O
with	O
the	O
proposed	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
.	O
	
In	O
that	O
case	O
,	O
for	O
a	O
given	O
source	O
phrase	O
,	O
the	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
will	O
need	O
to	O
generate	O
a	O
list	O
of	O
(	O
good	O
)	O
target	O
phrases	O
.	O
	
This	O
requires	O
,	O
however	O
,	O
an	O
expensive	O
sampling	B-Method
procedure	I-Method
to	O
be	O
performed	O
repeatedly	O
.	O
	
In	O
this	O
paper	O
,	O
thus	O
,	O
we	O
only	O
consider	O
rescoring	O
the	O
phrase	O
pairs	O
in	O
the	O
phrase	O
table	O
.	O
	
subsection	O
:	O
Related	O
Approaches	O
:	O
Neural	B-Method
Networks	I-Method
in	O
Machine	B-Task
Translation	I-Task
	
Before	O
presenting	O
the	O
empirical	O
results	O
,	O
we	O
discuss	O
a	O
number	O
of	O
recent	O
works	O
that	O
have	O
proposed	O
to	O
use	O
neural	B-Method
networks	I-Method
in	O
the	O
context	O
of	O
SMT	B-Task
.	O
	
Schwenk	O
in	O
proposed	O
a	O
similar	O
approach	O
of	O
scoring	B-Task
phrase	I-Task
pairs	I-Task
.	O
	
Instead	O
of	O
the	O
RNN	B-Method
-	O
based	O
neural	O
network	O
,	O
he	O
used	O
a	O
feedforward	B-Method
neural	I-Method
network	I-Method
that	O
has	O
fixed	O
-	O
size	O
inputs	O
(	O
7	O
words	O
in	O
his	O
case	O
,	O
with	O
zero	O
-	O
padding	O
for	O
shorter	O
phrases	O
)	O
and	O
fixed	O
-	O
size	O
outputs	O
(	O
7	O
words	O
in	O
the	O
target	O
language	O
)	O
.	O
	
When	O
it	O
is	O
used	O
specifically	O
for	O
scoring	B-Task
phrases	I-Task
for	O
the	O
SMT	B-Method
system	I-Method
,	O
the	O
maximum	O
phrase	O
length	O
is	O
often	O
chosen	O
to	O
be	O
small	O
.	O
	
However	O
,	O
as	O
the	O
length	O
of	O
phrases	O
increases	O
or	O
as	O
we	O
apply	O
neural	B-Method
networks	I-Method
to	O
other	O
variable	O
-	O
length	O
sequence	O
data	O
,	O
it	O
is	O
important	O
that	O
the	O
neural	B-Method
network	I-Method
can	O
handle	O
variable	O
-	O
length	O
input	O
and	O
output	O
.	O
	
The	O
proposed	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
is	O
well	O
-	O
suited	O
for	O
these	O
applications	O
.	O
	
Similar	O
to	O
,	O
Devlin	O
et	O
al	O
.	O
proposed	O
to	O
use	O
a	O
feedforward	B-Method
neural	I-Method
network	I-Method
to	O
model	O
a	O
translation	B-Method
model	I-Method
,	O
however	O
,	O
by	O
predicting	O
one	O
word	O
in	O
a	O
target	O
phrase	O
at	O
a	O
time	O
.	O
	
They	O
reported	O
an	O
impressive	O
improvement	O
,	O
but	O
their	O
approach	O
still	O
requires	O
the	O
maximum	O
length	O
of	O
the	O
input	O
phrase	O
(	O
or	O
context	O
words	O
)	O
to	O
be	O
fixed	O
a	O
priori	O
.	O
	
Although	O
it	O
is	O
not	O
exactly	O
a	O
neural	B-Method
network	I-Method
they	O
train	O
,	O
the	O
authors	O
of	O
proposed	O
to	O
learn	O
a	O
bilingual	O
embedding	O
of	O
words	O
/	O
phrases	O
.	O
	
They	O
use	O
the	O
learned	O
embedding	B-Method
to	O
compute	O
the	O
distance	O
between	O
a	O
pair	O
of	O
phrases	O
which	O
is	O
used	O
as	O
an	O
additional	O
score	O
of	O
the	O
phrase	O
pair	O
in	O
an	O
SMT	B-Method
system	I-Method
.	O
	
In	O
,	O
a	O
feedforward	B-Method
neural	I-Method
network	I-Method
was	O
trained	O
to	O
learn	O
a	O
mapping	O
from	O
a	O
bag	B-Method
-	I-Method
of	I-Method
-	I-Method
words	I-Method
representation	I-Method
of	O
an	O
input	O
phrase	O
to	O
an	O
output	O
phrase	O
.	O
	
This	O
is	O
closely	O
related	O
to	O
both	O
the	O
proposed	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
and	O
the	O
model	O
proposed	O
in	O
,	O
except	O
that	O
their	O
input	O
representation	O
of	O
a	O
phrase	O
is	O
a	O
bag	O
-	O
of	O
-	O
words	O
.	O
	
A	O
similar	O
approach	O
of	O
using	O
bag	B-Method
-	I-Method
of	I-Method
-	I-Method
words	I-Method
representations	I-Method
was	O
proposed	O
in	O
as	O
well	O
.	O
	
Earlier	O
,	O
a	O
similar	O
encoder	B-Method
–	I-Method
decoder	I-Method
model	I-Method
using	O
two	O
recursive	B-Method
neural	I-Method
networks	I-Method
was	O
proposed	O
in	O
,	O
but	O
their	O
model	O
was	O
restricted	O
to	O
a	O
monolingual	B-Task
setting	I-Task
,	O
i.e.	O
the	O
model	O
reconstructs	O
an	O
input	O
sentence	O
.	O
	
More	O
recently	O
,	O
another	O
encoder	B-Method
–	I-Method
decoder	I-Method
model	I-Method
using	O
an	O
RNN	B-Method
was	O
proposed	O
in	O
,	O
where	O
the	O
decoder	B-Method
is	O
conditioned	O
on	O
a	O
representation	O
of	O
either	O
a	O
source	O
sentence	O
or	O
a	O
source	O
context	O
.	O
	
One	O
important	O
difference	O
between	O
the	O
proposed	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
and	O
the	O
approaches	O
in	O
and	O
is	O
that	O
the	O
order	O
of	O
the	O
words	O
in	O
source	O
and	O
target	O
phrases	O
is	O
taken	O
into	O
account	O
.	O
	
The	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
naturally	O
distinguishes	O
between	O
sequences	O
that	O
have	O
the	O
same	O
words	O
but	O
in	O
a	O
different	O
order	O
,	O
whereas	O
the	O
aforementioned	O
approaches	O
effectively	O
ignore	O
order	O
information	O
.	O
	
The	O
closest	O
approach	O
related	O
to	O
the	O
proposed	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
is	O
the	O
Recurrent	B-Method
Continuous	I-Method
Translation	I-Method
Model	I-Method
(	O
Model	O
2	O
)	O
proposed	O
in	O
.	O
	
In	O
their	O
paper	O
,	O
they	O
proposed	O
a	O
similar	O
model	O
that	O
consists	O
of	O
an	O
encoder	B-Method
and	I-Method
decoder	I-Method
.	O
	
The	O
difference	O
with	O
our	O
model	O
is	O
that	O
they	O
used	O
a	O
convolutional	B-Method
-	I-Method
gram	I-Method
model	I-Method
(	O
CGM	B-Method
)	I-Method
for	O
the	O
encoder	B-Method
and	O
the	O
hybrid	O
of	O
an	O
inverse	B-Method
CGM	I-Method
and	O
a	O
recurrent	B-Method
neural	I-Method
network	I-Method
for	O
the	O
decoder	B-Method
.	O
	
They	O
,	O
however	O
,	O
evaluated	O
their	O
model	O
on	O
rescoring	B-Task
the	I-Task
-	I-Task
best	I-Task
list	I-Task
proposed	O
by	O
the	O
conventional	O
SMT	B-Method
system	I-Method
and	O
computing	O
the	O
perplexity	B-Metric
of	O
the	O
gold	O
standard	O
translations	O
.	O
	
section	O
:	O
Experiments	O
	
We	O
evaluate	O
our	O
approach	O
on	O
the	O
English	B-Task
/	I-Task
French	I-Task
translation	I-Task
task	I-Task
of	O
the	O
WMT’14	B-Material
workshop	I-Material
.	O
	
subsection	O
:	O
Data	O
and	O
Baseline	B-Method
System	O
	
Large	O
amounts	O
of	O
resources	O
are	O
available	O
to	O
build	O
an	O
English	O
/	O
French	O
SMT	B-Task
system	O
in	O
the	O
framework	O
of	O
the	O
WMT’14	B-Task
translation	I-Task
task	I-Task
.	O
	
The	O
bilingual	O
corpora	O
include	O
Europarl	O
(	O
61	O
M	O
words	O
)	O
,	O
news	O
commentary	O
(	O
5.5	O
M	O
)	O
,	O
UN	O
(	O
421	O
M	O
)	O
,	O
and	O
two	O
crawled	O
corpora	O
of	O
90	O
M	O
and	O
780	O
M	O
words	O
respectively	O
.	O
	
The	O
last	O
two	O
corpora	O
are	O
quite	O
noisy	O
.	O
	
To	O
train	O
the	O
French	B-Method
language	I-Method
model	I-Method
,	O
about	O
712	O
M	O
words	O
of	O
crawled	O
newspaper	O
material	O
is	O
available	O
in	O
addition	O
to	O
the	O
target	O
side	O
of	O
the	O
bitexts	O
.	O
	
All	O
the	O
word	O
counts	O
refer	O
to	O
French	B-Material
words	I-Material
after	O
tokenization	O
.	O
	
It	O
is	O
commonly	O
acknowledged	O
that	O
training	O
statistical	B-Method
models	I-Method
on	O
the	O
concatenation	O
of	O
all	O
this	O
data	O
does	O
not	O
necessarily	O
lead	O
to	O
optimal	O
performance	O
,	O
and	O
results	O
in	O
extremely	O
large	O
models	O
which	O
are	O
difficult	O
to	O
handle	O
.	O
	
Instead	O
,	O
one	O
should	O
focus	O
on	O
the	O
most	O
relevant	O
subset	O
of	O
the	O
data	O
for	O
a	O
given	O
task	O
.	O
	
We	O
have	O
done	O
so	O
by	O
applying	O
the	O
data	B-Method
selection	I-Method
method	I-Method
proposed	O
in	O
,	O
and	O
its	O
extension	O
to	O
bitexts	O
.	O
	
By	O
these	O
means	O
we	O
selected	O
a	O
subset	O
of	O
418	O
M	O
words	O
out	O
of	O
more	O
than	O
2	O
G	O
words	O
for	O
language	B-Task
modeling	I-Task
and	O
a	O
subset	O
of	O
348	O
M	O
out	O
of	O
850	O
M	O
words	O
for	O
training	O
the	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
.	O
	
We	O
used	O
the	O
test	O
set	O
newstest2012	O
and	O
2013	O
for	O
data	B-Task
selection	I-Task
and	O
weight	B-Task
tuning	I-Task
with	O
MERT	B-Method
,	O
and	O
newstest2014	O
as	O
our	O
test	O
set	O
.	O
	
Each	O
set	O
has	O
more	O
than	O
70	O
thousand	O
words	O
and	O
a	O
single	O
reference	O
translation	O
.	O
	
For	O
training	O
the	O
neural	B-Method
networks	I-Method
,	O
including	O
the	O
proposed	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
,	O
we	O
limited	O
the	O
source	O
and	O
target	O
vocabulary	O
to	O
the	O
most	O
frequent	O
15	O
,	O
000	O
words	O
for	O
both	O
English	B-Material
and	I-Material
French	I-Material
.	O
	
This	O
covers	O
approximately	O
93	O
%	O
of	O
the	O
dataset	O
.	O
	
All	O
the	O
out	O
-	O
of	O
-	O
vocabulary	O
words	O
were	O
mapped	O
to	O
a	O
special	O
token	O
(	O
)	O
.	O
	
The	O
baseline	O
phrase	B-Method
-	I-Method
based	I-Method
SMT	I-Method
system	I-Method
was	O
built	O
using	O
Moses	B-Method
with	O
default	O
settings	O
.	O
	
This	O
system	O
achieves	O
a	O
BLEU	B-Metric
score	I-Metric
of	O
30.64	O
and	O
33.3	O
on	O
the	O
development	O
and	O
test	O
sets	O
,	O
respectively	O
(	O
see	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
subsubsection	O
:	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
	
The	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
used	O
in	O
the	O
experiment	O
had	O
1000	O
hidden	O
units	O
with	O
the	O
proposed	O
gates	O
at	O
the	O
encoder	B-Method
and	O
at	O
the	O
decoder	B-Method
.	O
	
The	O
input	O
matrix	O
between	O
each	O
input	O
symbol	O
and	O
the	O
hidden	O
unit	O
is	O
approximated	O
with	O
two	O
lower	O
-	O
rank	O
matrices	O
,	O
and	O
the	O
output	O
matrix	O
is	O
approximated	O
similarly	O
.	O
	
We	O
used	O
rank	O
-	O
100	O
matrices	O
,	O
equivalent	O
to	O
learning	O
an	O
embedding	O
of	O
dimension	O
100	O
for	O
each	O
word	O
.	O
	
The	O
activation	O
function	O
used	O
for	O
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
is	O
a	O
hyperbolic	O
tangent	O
function	O
.	O
	
The	O
computation	O
from	O
the	O
hidden	O
state	O
in	O
the	O
decoder	O
to	O
the	O
output	O
is	O
implemented	O
as	O
a	O
deep	B-Method
neural	I-Method
network	I-Method
with	O
a	O
single	O
intermediate	B-Method
layer	I-Method
having	O
500	O
maxout	B-Method
units	I-Method
each	O
pooling	O
2	O
inputs	O
.	O
	
All	O
the	O
weight	O
parameters	O
in	O
the	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
were	O
initialized	O
by	O
sampling	O
from	O
an	O
isotropic	B-Method
zero	I-Method
-	I-Method
mean	I-Method
(	I-Method
white	I-Method
)	I-Method
Gaussian	I-Method
distribution	I-Method
with	O
its	O
standard	O
deviation	O
fixed	O
to	O
,	O
except	O
for	O
the	O
recurrent	O
weight	O
parameters	O
.	O
	
For	O
the	O
recurrent	O
weight	O
matrices	O
,	O
we	O
first	O
sampled	O
from	O
a	O
white	B-Method
Gaussian	I-Method
distribution	I-Method
and	O
used	O
its	O
left	O
singular	O
vectors	O
matrix	O
,	O
following	O
.	O
	
We	O
used	O
Adadelta	B-Method
and	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
to	O
train	O
the	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
with	O
hyperparameters	B-Method
and	O
.	O
	
At	O
each	O
update	O
,	O
we	O
used	O
64	O
randomly	O
selected	O
phrase	O
pairs	O
from	O
a	O
phrase	O
table	O
(	O
which	O
was	O
created	O
from	O
348	O
M	O
words	O
)	O
.	O
	
The	O
model	O
was	O
trained	O
for	O
approximately	O
three	O
days	O
.	O
	
Details	O
of	O
the	O
architecture	O
used	O
in	O
the	O
experiments	O
are	O
explained	O
in	O
more	O
depth	O
in	O
the	O
supplementary	O
material	O
.	O
	
subsubsection	O
:	O
Neural	B-Method
Language	I-Method
Model	I-Method
	
In	O
order	O
to	O
assess	O
the	O
effectiveness	O
of	O
scoring	O
phrase	O
pairs	O
with	O
the	O
proposed	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
,	O
we	O
also	O
tried	O
a	O
more	O
traditional	O
approach	O
of	O
using	O
a	O
neural	B-Method
network	I-Method
for	O
learning	O
a	O
target	B-Method
language	I-Method
model	I-Method
(	O
CSLM	B-Method
)	O
.	O
	
Especially	O
,	O
the	O
comparison	O
between	O
the	O
SMT	B-Method
system	I-Method
using	O
CSLM	B-Method
and	O
that	O
using	O
the	O
proposed	O
approach	O
of	O
phrase	B-Method
scoring	I-Method
by	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
will	O
clarify	O
whether	O
the	O
contributions	O
from	O
multiple	O
neural	B-Method
networks	I-Method
in	O
different	O
parts	O
of	O
the	O
SMT	B-Method
system	I-Method
add	O
up	O
or	O
are	O
redundant	O
.	O
	
We	O
trained	O
the	O
CSLM	B-Method
model	O
on	O
7	O
-	O
grams	O
from	O
the	O
target	O
corpus	O
.	O
	
Each	O
input	O
word	O
was	O
projected	O
into	O
the	O
embedding	O
space	O
,	O
and	O
they	O
were	O
concatenated	O
to	O
form	O
a	O
3072	O
-	O
dimensional	O
vector	O
.	O
	
The	O
concatenated	O
vector	O
was	O
fed	O
through	O
two	O
rectified	B-Method
layers	I-Method
(	O
of	O
size	O
1536	O
and	O
1024	O
)	O
.	O
	
The	O
output	O
layer	O
was	O
a	O
simple	O
softmax	B-Method
layer	I-Method
(	O
see	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
)	O
.	O
	
All	O
the	O
weight	O
parameters	O
were	O
initialized	O
uniformly	O
between	O
and	O
,	O
and	O
the	O
model	O
was	O
trained	O
until	O
the	O
validation	B-Metric
perplexity	I-Metric
did	O
not	O
improve	O
for	O
10	O
epochs	O
.	O
	
After	O
training	O
,	O
the	O
language	B-Method
model	I-Method
achieved	O
a	O
perplexity	B-Metric
of	O
45.80	O
.	O
	
The	O
validation	O
set	O
was	O
a	O
random	O
selection	O
of	O
0.1	O
%	O
of	O
the	O
corpus	O
.	O
	
The	O
model	O
was	O
used	O
to	O
score	O
partial	O
translations	O
during	O
the	O
decoding	B-Task
process	I-Task
,	O
which	O
generally	O
leads	O
to	O
higher	O
gains	O
in	O
BLEU	B-Metric
score	I-Metric
than	O
n	B-Method
-	I-Method
best	I-Method
list	I-Method
rescoring	I-Method
.	O
	
To	O
address	O
the	O
computational	B-Metric
complexity	I-Metric
of	O
using	O
a	O
CSLM	B-Method
in	O
the	O
decoder	O
a	O
buffer	O
was	O
used	O
to	O
aggregate	O
n	O
-	O
grams	O
during	O
the	O
stack	B-Task
-	I-Task
search	I-Task
performed	O
by	O
the	O
decoder	O
.	O
	
Only	O
when	O
the	O
buffer	O
is	O
full	O
,	O
or	O
a	O
stack	O
is	O
about	O
to	O
be	O
pruned	O
,	O
the	O
n	O
-	O
grams	O
are	O
scored	O
by	O
the	O
CSLM	B-Method
.	O
	
This	O
allows	O
us	O
to	O
perform	O
fast	O
matrix	B-Task
-	I-Task
matrix	I-Task
multiplication	I-Task
on	O
GPU	O
using	O
Theano	O
.	O
	
subsection	O
:	O
Quantitative	B-Task
Analysis	I-Task
	
We	O
tried	O
the	O
following	O
combinations	O
:	O
Baseline	B-Method
configuration	O
Baseline	B-Method
+	O
RNN	B-Method
Baseline	I-Method
+	O
CSLM	B-Method
+	O
RNN	B-Method
Baseline	I-Method
+	O
CSLM	B-Method
+	O
RNN	B-Method
+	O
Word	B-Method
penalty	I-Method
	
The	O
results	O
are	O
presented	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
As	O
expected	O
,	O
adding	O
features	O
computed	O
by	O
neural	B-Method
networks	I-Method
consistently	O
improves	O
the	O
performance	O
over	O
the	O
baseline	O
performance	O
.	O
	
The	O
best	O
performance	O
was	O
achieved	O
when	O
we	O
used	O
both	O
CSLM	B-Method
and	O
the	O
phrase	O
scores	O
from	O
the	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
.	O
	
This	O
suggests	O
that	O
the	O
contributions	O
of	O
the	O
CSLM	B-Method
and	O
the	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
are	O
not	O
too	O
correlated	O
and	O
that	O
one	O
can	O
expect	O
better	O
results	O
by	O
improving	O
each	O
method	O
independently	O
.	O
	
Furthermore	O
,	O
we	O
tried	O
penalizing	O
the	O
number	O
of	O
words	O
that	O
are	O
unknown	O
to	O
the	O
neural	B-Method
networks	I-Method
(	O
i.e.	O
words	O
which	O
are	O
not	O
in	O
the	O
shortlist	O
)	O
.	O
	
We	O
do	O
so	O
by	O
simply	O
adding	O
the	O
number	O
of	O
unknown	O
words	O
as	O
an	O
additional	O
feature	O
the	O
log	B-Method
-	I-Method
linear	I-Method
model	I-Method
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
.	O
	
However	O
,	O
in	O
this	O
case	O
we	O
were	O
not	O
able	O
to	O
achieve	O
better	O
performance	O
on	O
the	O
test	O
set	O
,	O
but	O
only	O
on	O
the	O
development	O
set	O
.	O
	
subsection	O
:	O
Qualitative	B-Method
Analysis	I-Method
	
In	O
order	O
to	O
understand	O
where	O
the	O
performance	O
improvement	O
comes	O
from	O
,	O
we	O
analyze	O
the	O
phrase	O
pair	O
scores	O
computed	O
by	O
the	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
against	O
the	O
corresponding	O
from	O
the	O
translation	B-Method
model	I-Method
.	O
	
Since	O
the	O
existing	O
translation	B-Method
model	I-Method
relies	O
solely	O
on	O
the	O
statistics	O
of	O
the	O
phrase	O
pairs	O
in	O
the	O
corpus	O
,	O
we	O
expect	O
its	O
scores	O
to	O
be	O
better	O
estimated	O
for	O
the	O
frequent	O
phrases	O
but	O
badly	O
estimated	O
for	O
rare	O
phrases	O
.	O
	
Also	O
,	O
as	O
we	O
mentioned	O
earlier	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
,	O
we	O
further	O
expect	O
the	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
which	O
was	O
trained	O
without	O
any	O
frequency	O
information	O
to	O
score	O
the	O
phrase	O
pairs	O
based	O
rather	O
on	O
the	O
linguistic	O
regularities	O
than	O
on	O
the	O
statistics	O
of	O
their	O
occurrences	O
in	O
the	O
corpus	O
.	O
	
We	O
focus	O
on	O
those	O
pairs	O
whose	O
source	O
phrase	O
is	O
long	O
(	O
more	O
than	O
3	O
words	O
per	O
source	O
phrase	O
)	O
and	O
frequent	O
.	O
	
For	O
each	O
such	O
source	O
phrase	O
,	O
we	O
look	O
at	O
the	O
target	O
phrases	O
that	O
have	O
been	O
scored	O
high	O
either	O
by	O
the	O
translation	O
probability	O
or	O
by	O
the	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
.	O
	
Similarly	O
,	O
we	O
perform	O
the	O
same	O
procedure	O
with	O
those	O
pairs	O
whose	O
source	O
phrase	O
is	O
long	O
but	O
rare	O
in	O
the	O
corpus	O
.	O
	
Table	O
[	O
reference	O
]	O
lists	O
the	O
top	O
-	O
target	O
phrases	O
per	O
source	O
phrase	O
favored	O
either	O
by	O
the	O
translation	B-Method
model	I-Method
or	O
by	O
the	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
.	O
	
The	O
source	O
phrases	O
were	O
randomly	O
chosen	O
among	O
long	O
ones	O
having	O
more	O
than	O
4	O
or	O
5	O
words	O
.	O
	
In	O
most	O
cases	O
,	O
the	O
choices	O
of	O
the	O
target	O
phrases	O
by	O
the	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
are	O
closer	O
to	O
actual	O
or	O
literal	O
translations	O
.	O
	
We	O
can	O
observe	O
that	O
the	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
prefers	O
shorter	O
phrases	O
in	O
general	O
.	O
	
Interestingly	O
,	O
many	O
phrase	O
pairs	O
were	O
scored	O
similarly	O
by	O
both	O
the	O
translation	B-Method
model	I-Method
and	O
the	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
,	O
but	O
there	O
were	O
as	O
many	O
other	O
phrase	O
pairs	O
that	O
were	O
scored	O
radically	O
different	O
(	O
see	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
This	O
could	O
arise	O
from	O
the	O
proposed	O
approach	O
of	O
training	O
the	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
on	O
a	O
set	O
of	O
unique	O
phrase	O
pairs	O
,	O
discouraging	O
the	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
from	O
learning	O
simply	O
the	O
frequencies	O
of	O
the	O
phrase	O
pairs	O
from	O
the	O
corpus	O
,	O
as	O
explained	O
earlier	O
.	O
	
Furthermore	O
,	O
in	O
Table	O
[	O
reference	O
]	O
,	O
we	O
show	O
for	O
each	O
of	O
the	O
source	O
phrases	O
in	O
Table	O
[	O
reference	O
]	O
,	O
the	O
generated	O
samples	O
from	O
the	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
.	O
	
For	O
each	O
source	O
phrase	O
,	O
we	O
generated	O
50	O
samples	O
and	O
show	O
the	O
top	O
-	O
five	O
phrases	O
accordingly	O
to	O
their	O
scores	O
.	O
	
We	O
can	O
see	O
that	O
the	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
is	O
able	O
to	O
propose	O
well	O
-	O
formed	O
target	O
phrases	O
without	O
looking	O
at	O
the	O
actual	O
phrase	O
table	O
.	O
	
Importantly	O
,	O
the	O
generated	O
phrases	O
do	O
not	O
overlap	O
completely	O
with	O
the	O
target	O
phrases	O
from	O
the	O
phrase	O
table	O
.	O
	
This	O
encourages	O
us	O
to	O
further	O
investigate	O
the	O
possibility	O
of	O
replacing	O
the	O
whole	O
or	O
a	O
part	O
of	O
the	O
phrase	O
table	O
with	O
the	O
proposed	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
in	O
the	O
future	O
.	O
	
subsection	O
:	O
Word	B-Method
and	I-Method
Phrase	I-Method
Representations	I-Method
	
Since	O
the	O
proposed	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
is	O
not	O
specifically	O
designed	O
only	O
for	O
the	O
task	O
of	O
machine	B-Task
translation	I-Task
,	O
here	O
we	O
briefly	O
look	O
at	O
the	O
properties	O
of	O
the	O
trained	O
model	O
.	O
	
It	O
has	O
been	O
known	O
for	O
some	O
time	O
that	O
continuous	B-Method
space	I-Method
language	I-Method
models	I-Method
using	O
neural	B-Method
networks	I-Method
are	O
able	O
to	O
learn	O
semantically	B-Method
meaningful	O
embeddings	O
(	O
See	O
,	O
e.g.	O
,	O
)	O
.	O
	
Since	O
the	O
proposed	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
also	O
projects	O
to	O
and	O
maps	O
back	O
from	O
a	O
sequence	O
of	O
words	O
into	O
a	O
continuous	O
space	O
vector	O
,	O
we	O
expect	O
to	O
see	O
a	O
similar	O
property	O
with	O
the	O
proposed	O
model	O
as	O
well	O
.	O
	
The	O
left	O
plot	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
the	O
2–D	O
embedding	O
of	O
the	O
words	O
using	O
the	O
word	B-Method
embedding	I-Method
matrix	I-Method
learned	O
by	O
the	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
.	O
	
The	O
projection	O
was	O
done	O
by	O
the	O
recently	O
proposed	O
Barnes	B-Method
-	I-Method
Hut	I-Method
-	I-Method
SNE	I-Method
.	O
	
We	O
can	O
clearly	O
see	O
that	O
semantically	B-Method
similar	O
words	O
are	O
clustered	O
with	O
each	O
other	O
(	O
see	O
the	O
zoomed	O
-	O
in	O
plots	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
The	O
proposed	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
naturally	O
generates	O
a	O
continuous	B-Method
-	I-Method
space	I-Method
representation	I-Method
of	I-Method
a	I-Method
phrase	I-Method
.	O
	
The	O
representation	O
(	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
in	O
this	O
case	O
is	O
a	O
1000	O
-	O
dimensional	O
vector	O
.	O
	
Similarly	O
to	O
the	O
word	B-Method
representations	I-Method
,	O
we	O
visualize	O
the	O
representations	O
of	O
the	O
phrases	O
that	O
consists	O
of	O
four	O
or	O
more	O
words	O
using	O
the	O
Barnes	B-Method
-	I-Method
Hut	I-Method
-	I-Method
SNE	I-Method
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
From	O
the	O
visualization	O
,	O
it	O
is	O
clear	O
that	O
the	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
captures	O
both	O
semantic	O
and	O
syntactic	O
structures	O
of	O
the	O
phrases	O
.	O
	
For	O
instance	O
,	O
in	O
the	O
bottom	O
-	O
left	O
plot	O
,	O
most	O
of	O
the	O
phrases	O
are	O
about	O
the	O
duration	O
of	O
time	O
,	O
while	O
those	O
phrases	O
that	O
are	O
syntactically	O
similar	O
are	O
clustered	O
together	O
.	O
	
The	O
bottom	O
-	O
right	O
plot	O
shows	O
the	O
cluster	O
of	O
phrases	O
that	O
are	O
semantically	B-Method
similar	O
(	O
countries	O
or	O
regions	O
)	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
the	O
top	O
-	O
right	O
plot	O
shows	O
the	O
phrases	O
that	O
are	O
syntactically	O
similar	O
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
paper	O
,	O
we	O
proposed	O
a	O
new	O
neural	B-Method
network	I-Method
architecture	I-Method
,	O
called	O
an	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
that	O
is	O
able	O
to	O
learn	O
the	O
mapping	O
from	O
a	O
sequence	O
of	O
an	O
arbitrary	O
length	O
to	O
another	O
sequence	O
,	O
possibly	O
from	O
a	O
different	O
set	O
,	O
of	O
an	O
arbitrary	O
length	O
.	O
	
The	O
proposed	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
is	O
able	O
to	O
either	O
score	O
a	O
pair	O
of	O
sequences	O
(	O
in	O
terms	O
of	O
a	O
conditional	O
probability	O
)	O
or	O
generate	O
a	O
target	O
sequence	O
given	O
a	O
source	O
sequence	O
.	O
	
Along	O
with	O
the	O
new	O
architecture	O
,	O
we	O
proposed	O
a	O
novel	O
hidden	B-Method
unit	I-Method
that	O
includes	O
a	O
reset	O
gate	O
and	O
an	O
update	O
gate	O
that	O
adaptively	O
control	O
how	O
much	O
each	O
hidden	B-Method
unit	I-Method
remembers	O
or	O
forgets	O
while	O
reading	O
/	O
generating	O
a	O
sequence	O
.	O
	
We	O
evaluated	O
the	O
proposed	O
model	O
with	O
the	O
task	O
of	O
statistical	B-Task
machine	I-Task
translation	I-Task
,	O
where	O
we	O
used	O
the	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
to	O
score	O
each	O
phrase	O
pair	O
in	O
the	O
phrase	O
table	O
.	O
	
Qualitatively	O
,	O
we	O
were	O
able	O
to	O
show	O
that	O
the	O
new	O
model	O
is	O
able	O
to	O
capture	O
linguistic	O
regularities	O
in	O
the	O
phrase	O
pairs	O
well	O
and	O
also	O
that	O
the	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
is	O
able	O
to	O
propose	O
well	O
-	O
formed	O
target	O
phrases	O
.	O
	
The	O
scores	O
by	O
the	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
were	O
found	O
to	O
improve	O
the	O
overall	O
translation	B-Metric
performance	I-Metric
in	O
terms	O
of	O
BLEU	B-Metric
scores	I-Metric
.	O
	
Also	O
,	O
we	O
found	O
that	O
the	O
contribution	O
by	O
the	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
is	O
rather	O
orthogonal	O
to	O
the	O
existing	O
approach	O
of	O
using	O
neural	B-Method
networks	I-Method
in	O
the	O
SMT	B-Method
system	I-Method
,	O
so	O
that	O
we	O
can	O
improve	O
further	O
the	O
performance	O
by	O
using	O
,	O
for	O
instance	O
,	O
the	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
and	O
the	O
neural	B-Method
net	I-Method
language	I-Method
model	I-Method
together	O
.	O
	
Our	O
qualitative	O
analysis	O
of	O
the	O
trained	O
model	O
shows	O
that	O
it	O
indeed	O
captures	O
the	O
linguistic	O
regularities	O
in	O
multiple	O
levels	O
i.e.	O
at	O
the	O
word	O
level	O
as	O
well	O
as	O
phrase	O
level	O
.	O
	
This	O
suggests	O
that	O
there	O
may	O
be	O
more	O
natural	B-Task
language	I-Task
related	I-Task
applications	I-Task
that	O
may	O
benefit	O
from	O
the	O
proposed	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
.	O
	
The	O
proposed	O
architecture	O
has	O
large	O
potential	O
for	O
further	O
improvement	O
and	O
analysis	O
.	O
	
One	O
approach	O
that	O
was	O
not	O
investigated	O
here	O
is	O
to	O
replace	O
the	O
whole	O
,	O
or	O
a	O
part	O
of	O
the	O
phrase	O
table	O
by	O
letting	O
the	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
propose	O
target	O
phrases	O
.	O
	
Also	O
,	O
noting	O
that	O
the	O
proposed	O
model	O
is	O
not	O
limited	O
to	O
being	O
used	O
with	O
written	O
language	O
,	O
it	O
will	O
be	O
an	O
important	O
future	O
research	O
to	O
apply	O
the	O
proposed	O
architecture	O
to	O
other	O
applications	O
such	O
as	O
speech	B-Task
transcription	I-Task
.	O
	
section	O
:	O
Acknowledgments	O
	
KC	O
,	O
BM	O
,	O
CG	O
,	O
DB	O
and	O
YB	O
would	O
like	O
to	O
thank	O
NSERC	O
,	O
Calcul	O
Québec	O
,	O
Compute	O
Canada	O
,	O
the	O
Canada	O
Research	O
Chairs	O
and	O
CIFAR	O
.	O
	
FB	O
and	O
HS	O
were	O
partially	O
funded	O
by	O
the	O
European	O
Commission	O
under	O
the	O
project	O
MateCat	O
,	O
and	O
by	O
DARPA	O
under	O
the	O
BOLT	O
project	O
.	O
	
bibliography	O
:	O
References	O
	
appendix	O
:	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
	
In	O
this	O
document	O
,	O
we	O
describe	O
in	O
detail	O
the	O
architecture	O
of	O
the	O
RNN	B-Method
Encoder	O
–	O
Decoder	O
used	O
in	O
the	O
experiments	O
.	O
	
Let	O
us	O
denote	O
an	O
source	O
phrase	O
by	O
and	O
a	O
target	O
phrase	O
by	O
.	O
	
Each	O
phrase	O
is	O
a	O
sequence	O
of	O
-	O
dimensional	O
one	O
-	O
hot	O
vectors	O
,	O
such	O
that	O
only	O
one	O
element	O
of	O
the	O
vector	O
is	O
and	O
all	O
the	O
others	O
are	O
.	O
	
The	O
index	O
of	O
the	O
active	O
(	O
)	O
element	O
indicates	O
the	O
word	O
represented	O
by	O
the	O
vector	O
.	O
	
subsection	O
:	O
Encoder	O
	
Each	O
word	O
of	O
the	O
source	O
phrase	O
is	O
embedded	O
in	O
a	O
-	O
dimensional	O
vector	O
space	O
:	O
.	O
is	O
used	O
in	O
Sec	O
.	O
	
[	O
reference	O
]	O
to	O
visualize	O
the	O
words	O
.	O
	
The	O
hidden	O
state	O
of	O
an	O
encoder	B-Method
consists	O
of	O
hidden	O
units	O
,	O
and	O
each	O
one	O
of	O
them	O
at	O
time	O
is	O
computed	O
by	O
where	O
and	O
are	O
a	O
logistic	B-Method
sigmoid	I-Method
function	I-Method
and	O
an	O
element	B-Method
-	I-Method
wise	I-Method
multiplication	I-Method
,	O
respectively	O
.	O
	
To	O
make	O
the	O
equations	O
uncluttered	O
,	O
we	O
omit	O
biases	O
.	O
	
The	O
initial	O
hidden	O
state	O
is	O
fixed	O
to	O
.	O
	
Once	O
the	O
hidden	O
state	O
at	O
the	O
step	O
(	O
the	O
end	O
of	O
the	O
source	O
phrase	O
)	O
is	O
computed	O
,	O
the	O
representation	O
of	O
the	O
source	O
phrase	O
is	O
	
subsubsection	O
:	O
Decoder	B-Method
	
The	O
decoder	O
starts	O
by	O
initializing	O
the	O
hidden	O
state	O
with	O
where	O
we	O
will	O
use	O
to	O
distinguish	O
parameters	O
of	O
the	O
decoder	O
from	O
those	O
of	O
the	O
encoder	B-Method
.	O
	
The	O
hidden	O
state	O
at	O
time	O
of	O
the	O
decoder	O
is	O
computed	O
by	O
where	O
and	O
is	O
an	O
all	O
-	O
zero	O
vector	O
.	O
	
Similarly	O
to	O
the	O
case	O
of	O
the	O
encoder	B-Method
,	O
is	O
an	O
embedding	O
of	O
a	O
target	O
word	O
.	O
	
Unlike	O
the	O
encoder	B-Method
which	O
simply	O
encodes	O
the	O
source	O
phrase	O
,	O
the	O
decoder	B-Method
is	O
learned	O
to	O
generate	O
a	O
target	O
phrase	O
.	O
	
At	O
each	O
time	O
,	O
the	O
decoder	B-Method
computes	O
the	O
probability	O
of	O
generating	O
-	O
th	O
word	O
by	O
where	O
the	O
-	O
element	O
of	O
is	O
and	O
In	O
short	O
,	O
the	O
is	O
a	O
so	O
-	O
called	O
maxout	O
unit	O
.	O
	
For	O
the	O
computational	B-Metric
efficiency	I-Metric
,	O
instead	O
of	O
a	O
single	O
-	O
matrix	O
output	O
weight	O
,	O
we	O
use	O
a	O
product	O
of	O
two	O
matrices	O
such	O
that	O
where	O
and	O
.	O
	
appendix	O
:	O
Word	B-Method
and	I-Method
Phrase	I-Method
Representations	I-Method
	
Here	O
,	O
we	O
show	O
enlarged	O
plots	O
of	O
the	O
word	B-Method
and	I-Method
phrase	I-Method
representations	I-Method
in	O
Figs	O
.	O
	
[	O
reference	O
]	O
	
–	O
[	O
reference	O
]	O
.	O
	
arxiv	O
arxiv	O
	
document	O
:	O
Image	B-Task
Reconstruction	I-Task
with	O
Predictive	B-Method
Filter	I-Method
Flow	I-Method
	
We	O
propose	O
a	O
simple	O
,	O
interpretable	B-Method
framework	I-Method
for	O
solving	O
a	O
wide	O
range	O
of	O
image	B-Task
reconstruction	I-Task
problems	I-Task
such	O
as	O
denoising	B-Task
and	I-Task
deconvolution	I-Task
.	O
	
Given	O
a	O
corrupted	O
input	O
image	O
,	O
the	O
model	O
synthesizes	O
a	O
spatially	B-Method
varying	I-Method
linear	I-Method
filter	I-Method
which	O
,	O
when	O
applied	O
to	O
the	O
input	O
image	O
,	O
reconstructs	O
the	O
desired	O
output	O
.	O
	
The	O
model	O
parameters	O
are	O
learned	O
using	O
supervised	B-Method
or	I-Method
self	I-Method
-	I-Method
supervised	I-Method
training	I-Method
.	O
	
We	O
test	O
this	O
model	O
on	O
three	O
tasks	O
:	O
non	B-Task
-	I-Task
uniform	I-Task
motion	I-Task
blur	I-Task
removal	I-Task
,	O
lossy	B-Task
-	I-Task
compression	I-Task
artifact	I-Task
reduction	I-Task
and	O
single	B-Task
image	I-Task
super	I-Task
resolution	I-Task
.	O
	
We	O
demonstrate	O
that	O
our	O
model	O
substantially	O
outperforms	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
on	O
all	O
these	O
tasks	O
and	O
is	O
significantly	O
faster	O
than	O
optimization	B-Method
-	I-Method
based	I-Method
approaches	I-Method
to	O
deconvolution	B-Task
.	O
	
Unlike	O
models	O
that	O
directly	O
predict	O
output	O
pixel	O
values	O
,	O
the	O
predicted	O
filter	O
flow	O
is	O
controllable	O
and	O
interpretable	O
,	O
which	O
we	O
demonstrate	O
by	O
visualizing	O
the	O
space	O
of	O
predicted	O
filters	O
for	O
different	O
tasks	O
.	O
	
section	O
:	O
Introduction	O
	
Real	O
-	O
world	O
images	O
are	O
seldom	O
perfect	O
.	O
	
Practical	O
engineering	O
trade	O
-	O
offs	O
entail	O
that	O
consumer	O
photos	O
are	O
often	O
blurry	O
due	O
to	O
low	O
-	O
light	O
,	O
camera	O
shake	O
or	O
object	O
motion	O
,	O
limited	O
in	O
resolution	O
and	O
further	O
degraded	O
by	O
image	O
compression	O
artifacts	O
introduced	O
for	O
the	O
sake	O
of	O
affordable	O
transmission	B-Task
and	I-Task
storage	I-Task
.	O
	
Scientific	B-Task
applications	I-Task
such	O
as	O
microscopy	B-Task
or	O
astronomy	B-Task
,	O
which	O
push	O
the	O
fundamental	O
physical	O
limitations	O
of	O
light	O
,	O
lenses	O
and	O
sensors	O
,	O
face	O
similar	O
challenges	O
.	O
	
Recovering	B-Task
high	I-Task
-	I-Task
quality	I-Task
images	I-Task
from	O
degraded	O
measurements	O
has	O
been	O
a	O
long	O
-	O
standing	O
problem	O
for	O
image	B-Task
analysis	I-Task
and	O
spans	O
a	O
range	O
of	O
tasks	O
such	O
as	O
blind	B-Task
-	I-Task
image	I-Task
deblurring	I-Task
,	O
compression	B-Task
artifact	I-Task
reduction	I-Task
,	O
and	O
single	B-Task
image	I-Task
super	I-Task
-	I-Task
resolution	I-Task
.	O
	
Such	O
image	B-Task
reconstruction	I-Task
tasks	I-Task
can	O
be	O
viewed	O
mathematically	O
as	O
inverse	B-Task
problems	I-Task
,	O
which	O
are	O
typically	O
ill	O
-	O
posed	O
and	O
massively	O
under	O
-	O
constrained	O
.	O
	
Many	O
contemporary	O
techniques	O
to	O
inverse	B-Task
problems	I-Task
have	O
focused	O
on	O
regularization	B-Method
techniques	I-Method
which	O
are	O
amenable	O
to	O
computational	B-Task
optimization	I-Task
.	O
	
While	O
such	O
approaches	O
are	O
interpretable	O
as	O
Bayesian	B-Method
estimators	I-Method
with	O
particular	O
choice	O
of	O
priors	O
,	O
they	O
are	O
often	O
computationally	O
expensive	O
in	O
practice	O
.	O
	
Alternately	O
,	O
data	B-Method
-	I-Method
driven	I-Method
methods	I-Method
based	O
on	O
training	O
deep	B-Method
convolutional	I-Method
neural	I-Method
networks	I-Method
yield	O
fast	O
inference	B-Task
but	O
lack	O
interpretability	O
and	O
guarantees	O
of	O
robustness	B-Metric
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
new	O
framework	O
called	O
Predictive	B-Method
Filter	I-Method
Flow	I-Method
that	O
retains	O
interpretability	O
and	O
control	O
over	O
the	O
resulting	O
reconstruction	B-Task
while	O
allowing	O
fast	B-Task
inference	I-Task
.	O
	
The	O
proposed	O
framework	O
is	O
directly	O
applicable	O
to	O
a	O
variety	O
of	O
low	B-Task
-	I-Task
level	I-Task
computer	I-Task
vision	I-Task
problems	I-Task
involving	O
local	B-Task
pixel	I-Task
transformations	I-Task
.	O
	
As	O
the	O
name	O
suggests	O
,	O
our	O
approach	O
is	O
built	O
on	O
the	O
notion	O
of	O
filter	B-Method
flow	I-Method
introduced	O
by	O
Seitz	O
and	O
Baker	O
.	O
	
In	O
filter	B-Method
flow	I-Method
pixels	O
in	O
a	O
local	O
neighborhood	O
of	O
the	O
input	O
image	O
are	O
linearly	O
combined	O
to	O
reconstruct	O
the	O
pixel	O
centered	O
at	O
the	O
same	O
location	O
in	O
the	O
output	O
image	O
.	O
	
However	O
,	O
unlike	O
convolution	B-Method
,	O
the	O
filter	O
weights	O
are	O
allowed	O
to	O
vary	O
from	O
one	O
spatial	O
location	O
to	O
the	O
next	O
.	O
	
Filter	B-Method
flows	I-Method
are	O
a	O
flexible	O
class	O
of	O
image	B-Method
transformations	I-Method
that	O
can	O
model	O
a	O
wide	O
range	O
of	O
imaging	O
effects	O
(	O
including	O
optical	O
flow	O
,	O
lighting	O
changes	O
,	O
non	O
-	O
uniform	O
blur	O
,	O
non	O
-	O
parametric	O
distortion	O
)	O
.	O
	
The	O
original	O
work	O
on	O
filter	B-Method
flow	I-Method
focused	O
on	O
the	O
problem	O
of	O
estimating	O
an	O
appropriately	O
regularized	B-Task
/	I-Task
constrained	I-Task
flow	I-Task
between	O
a	O
given	O
pair	O
of	O
images	O
.	O
	
This	O
yielded	O
convex	O
but	O
impractically	O
large	O
optimization	B-Task
problems	I-Task
(	O
e.g.	O
,	O
hours	O
of	O
computation	O
to	O
compute	O
a	O
single	O
flow	O
)	O
.	O
	
Instead	O
of	O
solving	O
for	O
an	O
optimal	B-Method
filter	I-Method
flow	I-Method
,	O
we	O
propose	O
to	O
directly	O
predict	O
a	O
filter	B-Method
flow	I-Method
given	O
an	O
input	O
image	O
using	O
a	O
convolutional	B-Method
neural	I-Method
net	I-Method
(	O
CNN	B-Method
)	O
to	O
regress	O
the	O
filter	O
weights	O
.	O
	
Using	O
a	O
CNN	B-Method
to	O
directly	O
predict	O
a	O
well	B-Method
regularized	I-Method
solution	I-Method
is	O
orders	O
of	O
magnitude	O
faster	O
than	O
expensive	O
iterative	B-Method
optimization	I-Method
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
provides	O
an	O
illustration	O
of	O
our	O
overall	O
framework	O
.	O
	
Instead	O
of	O
estimating	O
the	O
flow	O
between	O
a	O
pair	O
of	O
input	O
images	O
,	O
we	O
focus	O
on	O
applications	O
where	O
the	O
model	O
predicts	O
both	O
the	O
flow	O
and	O
the	O
transformed	O
image	O
.	O
	
This	O
can	O
be	O
viewed	O
as	O
“	O
blind	B-Task
”	I-Task
filter	I-Task
flow	I-Task
estimation	I-Task
,	O
in	O
analogy	O
with	O
blind	B-Task
deconvolution	I-Task
.	O
	
During	O
training	B-Task
,	O
we	O
use	O
a	O
loss	O
defined	O
over	O
the	O
transformed	O
image	O
(	O
rather	O
than	O
the	O
predicted	O
flow	O
)	O
.	O
	
This	O
is	O
closely	O
related	O
to	O
so	O
-	O
called	O
self	B-Method
-	I-Method
supervised	I-Method
techniques	I-Method
that	O
learn	O
to	O
predict	O
optical	B-Method
flow	I-Method
and	O
depth	B-Method
from	O
unlabeled	O
video	O
data	O
.	O
	
Specifically	O
,	O
for	O
the	O
reconstruction	B-Task
tasks	I-Task
we	O
consider	O
such	O
as	O
image	B-Task
super	I-Task
-	I-Task
resolution	I-Task
,	O
the	O
forward	B-Method
degradation	I-Method
process	I-Method
can	O
be	O
easily	O
simulated	O
to	O
generate	O
a	O
large	O
quantity	O
of	O
training	O
data	O
without	O
manual	O
collection	O
or	O
annotation	O
.	O
	
The	O
lack	O
of	O
interpretability	O
in	O
deep	B-Method
image	I-Method
-	I-Method
to	I-Method
-	I-Method
image	I-Method
regression	I-Method
models	I-Method
makes	O
it	O
hard	O
to	O
provide	O
guarantees	O
of	O
robustness	B-Metric
in	O
the	O
presence	O
of	O
adversarial	O
input	O
,	O
and	O
confer	O
reliability	B-Metric
needed	O
for	O
researchers	O
in	O
biology	B-Task
and	O
medical	O
science	O
.	O
	
Predictive	B-Method
filter	I-Method
flow	I-Method
differs	O
from	O
other	O
CNN	B-Method
-	I-Method
based	I-Method
approaches	I-Method
in	O
this	O
regard	O
since	O
the	O
intermediate	B-Method
filter	I-Method
flows	I-Method
are	O
interpretable	O
and	O
transparent	O
,	O
providing	O
an	O
explicit	O
description	O
of	O
how	O
the	O
input	O
is	O
transformed	O
into	O
output	O
.	O
	
It	O
is	O
also	O
straightforward	O
to	O
inject	O
constraints	O
on	O
the	O
reconstruction	B-Task
(	O
e.g.	O
,	O
local	O
brightness	O
conservation	O
)	O
which	O
would	O
be	O
nearly	O
impossible	O
to	O
guarantee	O
for	O
deep	O
image	B-Method
-	I-Method
to	I-Method
-	I-Method
image	I-Method
regression	I-Method
models	I-Method
.	O
	
To	O
evaluate	O
our	O
model	O
,	O
we	O
carry	O
out	O
extensive	O
experiments	O
on	O
three	O
different	O
low	B-Task
-	I-Task
level	I-Task
vision	I-Task
tasks	I-Task
,	O
non	B-Task
-	I-Task
uniform	I-Task
motion	I-Task
blur	I-Task
removal	I-Task
,	O
JPEG	B-Task
compression	I-Task
artifact	I-Task
reduction	I-Task
and	O
single	B-Task
image	I-Task
super	I-Task
-	I-Task
resolution	I-Task
.	O
	
We	O
show	O
that	O
our	O
model	O
surpasses	O
all	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
on	O
all	O
the	O
three	O
tasks	O
.	O
	
We	O
also	O
visualize	O
the	O
predicted	B-Method
filters	I-Method
which	O
reveals	O
filtering	B-Method
operators	I-Method
reminiscent	O
of	O
classic	O
unsharp	B-Method
masking	I-Method
filters	I-Method
and	O
anisotropic	B-Method
diffusion	I-Method
along	O
boundaries	O
.	O
	
To	O
summarize	O
our	O
contribution	O
:	O
(	O
1	O
)	O
we	O
propose	O
a	O
novel	O
,	O
end	B-Method
-	I-Method
to	I-Method
-	I-Method
end	I-Method
trainable	I-Method
,	I-Method
learning	I-Method
framework	I-Method
for	O
solving	O
various	O
low	B-Task
-	I-Task
level	I-Task
image	I-Task
reconstruction	I-Task
tasks	I-Task
;	O
(	O
2	O
)	O
we	O
show	O
this	O
framework	O
is	O
highly	O
interpretable	O
and	O
controllable	O
,	O
enabling	O
direct	O
post	B-Task
-	I-Task
hoc	I-Task
analysis	I-Task
of	O
how	O
the	O
reconstructed	O
image	O
is	O
generated	O
from	O
the	O
degraded	O
input	O
;	O
(	O
3	O
)	O
we	O
show	O
experimentally	O
that	O
predictive	B-Method
filter	I-Method
flow	I-Method
outperforms	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
remarkably	O
on	O
the	O
three	O
different	O
tasks	O
,	O
non	B-Task
-	I-Task
uniform	I-Task
motion	I-Task
blur	I-Task
removal	I-Task
,	O
compression	B-Task
artifact	I-Task
reduction	I-Task
and	O
single	B-Task
image	I-Task
super	I-Task
-	I-Task
resolution	I-Task
.	O
	
section	O
:	O
Related	O
Work	O
	
Our	O
work	O
is	O
inspired	O
by	O
filter	B-Method
flow	I-Method
,	O
which	O
is	O
an	O
optimization	B-Method
based	I-Method
method	I-Method
for	O
finding	O
a	O
linear	O
transformation	O
relating	O
nearby	O
pixel	O
values	O
in	O
a	O
pair	O
of	O
images	O
.	O
	
By	O
imposing	O
additional	O
constraints	O
on	O
certain	O
structural	O
properties	O
of	O
these	O
filters	O
,	O
it	O
serves	O
as	O
a	O
general	O
framework	O
for	O
understanding	O
a	O
wide	O
variety	O
of	O
low	B-Task
-	I-Task
level	I-Task
vision	I-Task
problems	I-Task
.	O
	
However	O
,	O
filter	B-Method
flow	I-Method
as	O
originally	O
formulated	O
has	O
some	O
obvious	O
shortcomings	O
.	O
	
First	O
,	O
it	O
requires	O
prior	O
knowledge	O
to	O
specify	O
a	O
set	O
of	O
constraints	O
needed	O
to	O
produce	O
good	O
results	O
.	O
	
It	O
is	O
not	O
always	O
straightforward	O
to	O
model	O
or	O
even	O
come	O
up	O
with	O
such	O
knowledge	O
-	O
based	O
constraints	O
.	O
	
Second	O
,	O
solving	O
for	O
an	O
optimal	B-Method
filter	I-Method
flow	I-Method
is	O
compute	O
intensive	O
;	O
it	O
may	O
take	O
up	O
to	O
20	O
hours	O
to	O
compute	O
over	O
a	O
pair	O
of	O
500	O
500	O
images	O
.	O
	
We	O
address	O
these	O
by	O
directly	O
predicting	B-Task
flows	I-Task
from	O
image	O
data	O
.	O
	
We	O
leverage	O
predictive	B-Method
filter	I-Method
flow	I-Method
for	O
targeting	O
three	O
specific	O
image	B-Task
reconstruction	I-Task
tasks	I-Task
which	O
can	O
be	O
framed	O
as	O
performing	O
spatially	B-Method
variant	I-Method
filtering	I-Method
over	O
local	O
image	O
patches	O
.	O
	
Non	B-Task
-	I-Task
Uniform	I-Task
Blind	I-Task
Motion	I-Task
Blur	I-Task
Removal	I-Task
is	O
an	O
extremely	O
challenging	O
yet	O
practically	O
significant	O
task	O
of	O
removing	B-Task
blur	I-Task
caused	O
by	O
object	O
motion	O
or	O
camera	O
shake	O
on	O
a	O
blurry	O
photo	O
.	O
	
The	O
blur	O
kernel	O
is	O
unknown	O
and	O
may	O
vary	O
over	O
the	O
image	O
.	O
	
Recent	O
methods	O
estimate	O
blur	O
kernels	O
locally	O
at	O
patch	O
level	O
,	O
and	O
adopt	O
an	O
optimization	B-Method
method	I-Method
for	O
deblurring	O
the	O
patches	O
.	O
	
leverage	O
prior	O
information	O
about	O
smooth	O
motion	O
by	O
selecting	O
from	O
a	O
predefine	O
discretized	O
set	O
of	O
linear	O
blur	O
kernels	O
.	O
	
These	O
methods	O
are	O
computationally	O
expensive	O
as	O
an	O
iterative	B-Method
solver	I-Method
is	O
required	O
for	O
deconvolution	B-Task
after	O
estimating	O
the	O
blur	B-Method
kernel	I-Method
;	O
and	O
the	O
deep	B-Method
learning	I-Method
approach	I-Method
can	O
not	O
generalize	O
well	O
to	O
novel	O
motion	O
kernels	O
.	O
	
Compression	B-Task
Artifact	I-Task
Reduction	I-Task
is	O
of	O
significance	O
as	O
lossy	B-Task
image	I-Task
compression	I-Task
is	O
ubiquitous	O
for	O
reducing	O
the	O
size	O
of	O
images	O
transmitted	O
over	O
the	O
web	O
and	O
recorded	O
on	O
data	O
storage	O
media	O
.	O
	
However	O
,	O
high	O
compression	B-Metric
rates	I-Metric
come	O
with	O
visual	O
artifacts	O
that	O
degrade	O
the	O
image	B-Metric
quality	I-Metric
and	O
thus	O
user	O
experience	O
.	O
	
Among	O
various	O
compression	B-Method
algorithms	I-Method
,	O
JPEG	B-Method
has	O
become	O
the	O
most	O
widely	O
accepted	O
standard	O
in	O
lossy	B-Task
image	I-Task
compression	I-Task
with	O
several	O
(	O
non	O
-	O
invertible	O
)	O
transforms	O
,	O
i.e.	O
,	O
downsampling	O
and	O
DCT	B-Method
quantization	I-Method
.	O
	
Removing	B-Task
artifacts	I-Task
from	O
jpeg	B-Task
compression	I-Task
can	O
be	O
viewed	O
as	O
a	O
practical	O
variant	O
of	O
natural	B-Task
image	I-Task
denoising	I-Task
problems	I-Task
.	O
	
Recent	O
methods	O
based	O
on	O
deep	B-Method
convolutional	I-Method
neural	I-Method
networks	I-Method
trained	O
to	O
take	O
as	O
input	O
the	O
compressed	O
image	O
and	O
output	O
the	O
denoised	O
image	O
directly	O
achieve	O
good	O
performance	O
.	O
	
Single	B-Task
Image	I-Task
Super	I-Task
-	I-Task
Resolution	I-Task
aims	O
at	O
recovering	O
a	O
high	O
-	O
resolution	O
image	O
from	O
a	O
single	O
low	O
-	O
resolution	O
image	O
.	O
	
This	O
problem	O
is	O
inherently	O
ill	O
-	O
posed	O
as	O
a	O
multiplicity	O
of	O
solutions	O
exists	O
for	O
any	O
given	O
low	O
-	O
resolution	O
input	O
.	O
	
Many	O
methods	O
adopt	O
an	O
example	B-Method
-	I-Method
based	I-Method
strategy	I-Method
requiring	O
an	O
optimization	B-Method
solver	I-Method
,	O
others	O
are	O
based	O
on	O
deep	B-Method
convolutional	I-Method
neural	I-Method
nets	I-Method
which	O
achieve	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
and	O
real	B-Metric
-	I-Metric
time	I-Metric
performance	I-Metric
.	O
	
The	O
deep	B-Method
learning	I-Method
methods	I-Method
take	O
as	O
input	O
the	O
low	O
-	O
resolution	O
image	O
(	O
usually	O
4	O
upsampled	O
one	O
using	O
bicubic	B-Method
interpolation	I-Method
)	O
,	O
and	O
output	O
the	O
high	O
-	O
resolution	O
image	O
directly	O
.	O
	
section	O
:	O
Predictive	B-Method
Filter	I-Method
Flow	I-Method
	
Filter	B-Method
flow	I-Method
models	O
image	B-Task
transformations	I-Task
as	O
a	O
linear	B-Method
mapping	I-Method
where	O
each	O
output	O
pixel	O
only	O
depends	O
on	O
a	O
local	O
neighborhood	O
of	O
the	O
input	O
.	O
	
Find	O
such	O
a	O
flow	O
can	O
be	O
framed	O
as	O
solving	O
a	O
constrained	B-Method
linear	I-Method
system	I-Method
where	O
is	O
a	O
matrix	O
whose	O
rows	O
act	O
separately	O
on	O
a	O
vectorized	B-Method
version	I-Method
of	O
the	O
source	O
image	O
.	O
	
For	O
the	O
model	O
[	O
reference	O
]	O
to	O
make	O
sense	O
,	O
must	O
serve	O
as	O
a	O
placeholder	O
for	O
the	O
entire	O
set	O
of	O
additional	O
constraints	O
on	O
the	O
operator	O
which	O
enables	O
a	O
unique	O
solution	O
that	O
satisfies	O
our	O
expectations	O
for	O
particular	O
problems	O
of	O
interest	O
.	O
	
For	O
example	O
,	O
standard	O
convolution	B-Method
corresponds	O
to	O
being	O
a	O
circulant	B-Method
matrix	I-Method
whose	O
rows	O
are	O
cyclic	O
permutations	O
of	O
a	O
single	O
set	O
of	O
filter	O
weights	O
which	O
are	O
typically	O
constrained	O
to	O
have	O
compact	O
localized	O
non	O
-	O
zero	O
support	O
.	O
	
For	O
a	O
theoretical	O
perspective	O
,	O
Filter	B-Method
Flow	I-Method
model	I-Method
[	O
reference	O
]	O
is	O
simple	O
and	O
elegant	O
,	O
but	O
directly	O
solving	O
Eq	O
.	O
	
[	O
reference	O
]	O
is	O
intractable	O
for	O
image	O
sizes	O
we	O
typically	O
encounter	O
in	O
practice	O
,	O
particularly	O
when	O
the	O
filters	B-Method
are	O
allowed	O
to	O
vary	O
spatially	O
.	O
	
subsection	O
:	O
Learning	O
to	O
predict	B-Task
flows	I-Task
	
Instead	O
of	O
optimizing	O
over	O
directly	O
,	O
we	O
seek	O
for	O
a	O
learnable	O
function	O
parameterized	O
by	O
that	O
	
predicts	O
the	O
transformation	O
specific	O
to	O
image	O
taken	O
as	O
input	O
	
:	O
We	O
call	O
this	O
model	O
Predictive	B-Method
Filter	I-Method
Flow	I-Method
.	O
	
Manually	O
designing	O
such	O
a	O
function	O
is	O
n’t	O
feasible	O
in	O
general	O
,	O
therefore	O
we	O
learn	O
a	O
specific	O
under	O
the	O
assumption	O
that	O
are	O
drawn	O
from	O
some	O
fixed	O
joint	O
distribution	O
.	O
	
Given	O
sampled	O
image	O
pairs	O
,	O
,	O
where	O
,	O
we	O
seek	O
parameters	O
that	O
minimize	O
the	O
difference	O
between	O
a	O
recovered	O
image	O
and	O
the	O
real	O
one	O
measured	O
by	O
some	O
loss	O
.	O
	
Note	O
that	O
constraints	O
on	O
are	O
different	O
from	O
constraints	O
used	O
in	O
Filter	B-Method
Flow	I-Method
.	O
	
In	O
practice	O
,	O
we	O
enforce	O
hard	O
constraints	O
via	O
our	O
choice	O
of	O
the	O
architecture	O
/	O
functional	O
form	O
of	O
along	O
with	O
soft	O
-	O
constraints	O
via	O
additional	O
regularization	O
term	O
.	O
	
We	O
also	O
adopt	O
commonly	O
used	O
regularization	O
on	O
to	O
reduce	O
overfitting	O
.	O
	
There	O
are	O
a	O
range	O
of	O
possible	O
choices	O
for	O
measuring	O
the	O
difference	O
between	O
two	O
images	O
.	O
	
In	O
our	O
experiments	O
,	O
we	O
simply	O
use	O
the	O
robust	B-Method
norm	I-Method
to	O
measure	O
the	O
pixel	O
-	O
level	O
difference	O
.	O
	
paragraph	O
:	O
Filter	B-Method
locality	I-Method
	
In	O
principle	O
,	O
each	O
pixel	O
output	O
in	O
Eq	O
.	O
	
[	O
reference	O
]	O
can	O
depend	O
on	O
all	O
input	O
pixels	O
.	O
	
We	O
introduce	O
the	O
structural	O
constraint	O
that	O
each	O
output	O
pixel	O
only	O
depends	O
on	O
a	O
corresponding	O
local	O
neighborhood	O
of	O
the	O
input	O
.	O
	
The	O
size	O
of	O
this	O
neighborhood	O
is	O
thus	O
a	O
hyper	O
-	O
parameter	O
of	O
the	O
model	O
.	O
	
We	O
note	O
that	O
while	O
the	O
predicted	O
filter	O
flow	O
acts	O
locally	O
,	O
the	O
estimation	O
of	O
the	O
correct	O
local	O
flow	O
within	O
a	O
patch	O
can	O
depend	O
on	O
global	O
context	O
captured	O
by	O
large	O
receptive	O
fields	O
in	O
the	O
predictor	O
.	O
	
In	O
practice	O
,	O
this	O
constraint	O
is	O
implemented	O
by	O
using	O
the	O
“	O
im2col	B-Method
”	I-Method
operation	I-Method
to	O
vectorize	O
the	O
local	O
neighborhood	O
patch	O
centered	O
at	O
each	O
pixel	O
and	O
compute	O
the	O
inner	O
product	O
of	O
this	O
vector	O
with	O
the	O
corresponding	O
predicted	B-Method
filter	I-Method
.	O
	
This	O
operation	O
is	O
highly	O
optimized	O
for	O
available	O
hardware	O
architectures	O
in	O
most	O
deep	B-Method
learning	I-Method
libraries	I-Method
and	O
has	O
time	B-Metric
and	O
space	B-Metric
cost	I-Metric
similar	O
to	O
computing	O
a	O
single	O
convolution	B-Method
.	O
	
For	O
example	O
,	O
if	O
the	O
filter	O
size	O
is	O
20	O
20	O
,	O
the	O
last	O
layer	O
of	O
the	O
CNN	B-Method
model	I-Method
outputs	O
a	O
three	O
-	O
dimensional	O
array	O
with	O
a	O
channel	O
dimension	O
of	O
,	O
which	O
is	O
comparable	O
to	O
feature	O
activations	O
at	O
a	O
single	O
layer	O
of	O
typical	O
CNN	B-Method
architectures	I-Method
.	O
	
paragraph	O
:	O
Other	O
filter	O
constraints	O
	
Various	O
priori	O
constraints	O
on	O
the	O
filter	B-Method
flow	I-Method
can	O
be	O
added	O
easily	O
to	O
enable	O
better	O
model	B-Task
training	I-Task
.	O
	
For	O
example	O
,	O
if	O
smoothness	O
is	O
desired	O
,	O
an	O
regularization	B-Method
on	O
the	O
(	O
1st	O
order	O
or	O
2nd	O
order	O
)	O
derivative	O
of	O
the	O
filter	O
flow	O
maps	O
can	O
be	O
inserted	O
during	O
training	B-Task
;	O
if	O
sparsity	O
is	O
desired	O
,	O
an	O
regularization	B-Method
on	O
the	O
filter	B-Method
flows	I-Method
can	O
be	O
added	O
easily	O
.	O
	
In	O
our	O
work	O
,	O
we	O
add	O
sum	O
-	O
to	O
-	O
one	O
and	O
non	O
-	O
negative	O
constraints	O
on	O
the	O
filters	O
for	O
the	O
task	O
of	O
non	B-Task
-	I-Task
uniform	I-Task
motion	I-Task
blur	I-Task
removal	I-Task
,	O
meaning	O
that	O
the	O
values	O
in	O
each	O
filter	O
should	O
be	O
non	O
-	O
negative	O
and	O
sum	O
-	O
to	O
-	O
one	O
by	O
assuming	O
there	O
is	O
no	O
lighting	O
change	O
.	O
	
This	O
can	O
be	O
easily	O
done	O
by	O
inserting	O
a	O
softmax	B-Method
transform	I-Method
across	O
channels	O
of	O
the	O
predicted	O
filter	O
weights	O
.	O
	
For	O
other	O
tasks	O
,	O
we	O
simply	O
let	O
the	O
model	B-Method
output	I-Method
free	I-Method
-	I-Method
form	I-Method
filters	I-Method
with	O
no	O
further	O
constraints	O
on	O
the	O
weights	O
.	O
	
paragraph	O
:	O
Self	O
-	O
Supervision	O
	
Though	O
the	O
proposed	O
framework	O
for	O
training	O
Predictive	B-Method
Filter	I-Method
Flow	I-Method
requires	O
paired	O
inputs	O
and	O
target	O
outputs	O
,	O
we	O
note	O
that	O
generating	O
training	O
data	O
for	O
many	O
reconstruction	B-Task
tasks	I-Task
can	O
be	O
accomplished	O
automatically	O
without	O
manual	B-Task
labeling	I-Task
.	O
	
Given	O
a	O
pool	O
of	O
high	O
quality	O
images	O
,	O
we	O
can	O
automatically	O
generate	O
low	O
-	O
resolution	O
,	O
blurred	O
or	O
JPEG	O
degraded	O
counterparts	O
to	O
use	O
in	O
training	O
(	O
see	O
Section	O
[	O
reference	O
]	O
)	O
.	O
	
This	O
can	O
also	O
be	O
generalized	O
to	O
so	O
-	O
called	O
self	B-Method
-	I-Method
supervised	I-Method
training	I-Method
for	O
predicting	B-Task
flows	I-Task
between	I-Task
video	I-Task
frames	I-Task
or	O
stereo	O
pairs	O
.	O
	
subsection	O
:	O
Model	B-Method
Architecture	I-Method
and	O
Training	O
	
Our	O
basic	O
framework	O
is	O
largely	O
agnostic	O
to	O
the	O
choice	O
of	O
architectures	O
,	O
learning	B-Method
method	I-Method
,	O
and	O
loss	O
functions	O
.	O
	
In	O
our	O
experiments	O
,	O
we	O
utilize	O
to	O
a	O
two	B-Method
-	I-Method
stream	I-Method
architecture	I-Method
as	O
shown	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
The	O
first	O
stream	O
is	O
a	O
simple	O
18	B-Method
-	I-Method
layer	I-Method
network	I-Method
with	O
3	O
3	B-Method
convolutional	I-Method
layers	I-Method
,	O
skip	O
connections	O
,	O
pooling	B-Method
layers	I-Method
and	O
upsampling	B-Method
layers	I-Method
;	O
the	O
second	O
stream	O
is	O
a	O
shallow	B-Method
but	I-Method
full	I-Method
-	I-Method
resolution	I-Method
network	I-Method
with	O
no	O
pooling	B-Method
.	O
	
The	O
first	O
stream	O
has	O
larger	O
receptive	O
fields	O
for	O
estimating	O
per	B-Task
-	I-Task
pixel	I-Task
filters	I-Task
by	O
considering	O
long	O
-	O
range	O
contextual	O
information	O
,	O
while	O
the	O
second	O
stream	O
keeps	O
original	O
resolution	O
as	O
input	O
image	O
without	O
inducing	O
spatial	O
information	O
loss	O
.	O
	
Batch	B-Method
normalization	I-Method
is	O
also	O
inserted	O
between	O
a	O
convolution	B-Method
layer	I-Method
and	O
ReLU	B-Method
layer	I-Method
.	O
	
The	O
Predictive	B-Method
Filter	I-Method
Flow	I-Method
is	O
self	O
-	O
supervised	O
so	O
we	O
could	O
generate	O
an	O
unlimited	O
amount	O
of	O
image	O
pairs	O
for	O
training	O
very	O
large	O
models	O
.	O
	
However	O
,	O
we	O
find	O
a	O
light	B-Method
-	I-Method
weight	I-Method
architecture	I-Method
trained	O
over	O
moderate	O
-	O
scale	O
training	O
set	O
performs	O
quite	O
well	O
.	O
	
Since	O
our	O
architecture	O
is	O
different	O
from	O
other	O
feed	B-Method
-	I-Method
forward	I-Method
image	I-Method
-	I-Method
to	I-Method
-	I-Method
image	I-Method
regression	I-Method
CNNs	I-Method
,	O
we	O
also	O
report	O
the	O
baseline	O
performance	O
of	O
the	O
two	B-Method
-	I-Method
stream	I-Method
architecture	I-Method
trained	O
to	O
directly	O
predict	O
the	O
reconstructed	O
image	O
rather	O
than	O
the	O
filter	O
coefficients	O
.	O
	
For	O
training	O
,	O
we	O
crop	O
64	O
64	O
-	O
resolution	O
patches	O
to	O
form	O
a	O
batch	O
of	O
size	O
56	O
.	O
	
Since	O
the	O
model	O
adapts	O
to	O
patch	O
boundary	O
effects	O
seen	O
during	O
training	O
,	O
at	O
test	O
time	O
we	O
apply	O
it	O
to	O
non	O
-	O
overlapping	O
tiles	O
of	O
the	O
input	O
image	O
.	O
	
However	O
,	O
we	O
note	O
that	O
the	O
model	O
is	O
fully	O
convolutional	B-Method
so	O
it	O
could	O
be	O
trained	O
over	O
larger	O
patches	O
to	O
avoid	O
boundary	O
effects	O
and	O
applied	O
to	O
arbitrary	O
size	O
inputs	O
.	O
	
We	O
use	O
ADAM	B-Method
optimization	I-Method
method	I-Method
during	O
training	O
,	O
with	O
initial	O
learning	O
0.0005	O
and	O
coefficients	O
0.9	O
and	O
0.999	O
for	O
computing	O
running	B-Metric
averages	I-Metric
of	I-Metric
gradient	I-Metric
and	O
its	O
square	O
.	O
	
As	O
for	O
the	O
training	B-Task
loss	I-Task
,	O
we	O
simply	O
use	O
the	O
-	B-Method
norm	I-Method
loss	I-Method
measuring	O
absolute	B-Metric
difference	I-Metric
over	I-Metric
pixel	I-Metric
intensities	I-Metric
.	O
	
We	O
train	O
our	O
model	O
from	O
scratch	O
on	O
a	O
single	O
NVIDIA	B-Method
TITAN	I-Method
X	I-Method
GPU	I-Method
,	O
and	O
terminate	O
after	O
several	O
hundred	O
epochs	O
.	O
	
section	O
:	O
Experiments	O
	
We	O
evaluate	O
the	O
proposed	O
Predictive	B-Method
Filter	I-Method
Flow	I-Method
framework	O
(	O
PFF	B-Method
)	O
on	O
three	O
low	B-Task
-	I-Task
level	I-Task
vision	I-Task
tasks	I-Task
:	O
non	B-Task
-	I-Task
uniform	I-Task
motion	I-Task
blur	I-Task
removal	I-Task
,	O
JPEG	B-Task
compression	I-Task
artifact	I-Task
reduction	I-Task
and	O
single	B-Task
image	I-Task
super	I-Task
-	I-Task
resolution	I-Task
.	O
	
We	O
first	O
describe	O
the	O
datasets	O
and	O
evaluation	B-Metric
metrics	I-Metric
,	O
and	O
then	O
compare	O
with	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
on	O
the	O
three	O
tasks	O
in	O
separate	O
subsections	O
,	O
respectively	O
.	O
	
subsection	O
:	O
Datasets	O
and	O
Metrics	O
	
We	O
use	O
the	O
high	O
-	O
resolution	O
images	O
in	O
DIV2	O
K	O
dataset	O
and	O
BSDS500	O
training	O
set	O
for	O
training	O
all	O
our	O
models	O
on	O
the	O
three	O
tasks	O
.	O
	
This	O
results	O
into	O
a	O
total	O
of	O
1	O
,	O
200	O
training	O
images	O
.	O
	
We	O
evaluate	O
each	O
model	O
over	O
different	O
datasets	O
specific	O
to	O
the	O
task	O
.	O
	
Concretely	O
,	O
we	O
test	O
our	O
model	O
for	O
non	B-Task
-	I-Task
uniform	I-Task
motion	I-Task
blur	I-Task
removal	I-Task
over	O
the	O
dataset	O
introduced	O
in	O
,	O
which	O
contains	O
large	O
motion	O
blur	O
up	O
to	O
38	O
pixels	O
.	O
	
We	O
evaluate	O
over	O
the	O
classic	O
LIVE1	O
dataset	O
for	O
JPEG	B-Task
compression	I-Task
artifacts	I-Task
reduction	I-Task
,	O
and	O
Set5	B-Material
and	O
Set14	B-Material
for	O
single	B-Task
image	I-Task
super	I-Task
-	I-Task
resolution	I-Task
.	O
	
To	O
quantitatively	O
measure	O
performance	O
,	O
we	O
use	O
Peak	B-Metric
-	I-Metric
Signal	I-Metric
-	I-Metric
to	I-Metric
-	I-Metric
Noise	I-Metric
-	I-Metric
Ratio	I-Metric
(	O
PSNR	B-Metric
)	O
and	O
Structural	B-Metric
Similarity	I-Metric
Index	I-Metric
(	O
SSIM	B-Metric
)	O
over	O
the	O
Y	O
channel	O
in	O
YCbCr	O
color	O
space	O
between	O
the	O
output	O
quality	O
image	O
and	O
the	O
original	O
image	O
.	O
	
This	O
is	O
a	O
standard	O
practice	O
in	O
literature	O
for	O
quantitatively	O
measuring	O
the	O
recovered	B-Metric
image	I-Metric
quality	I-Metric
.	O
	
subsection	O
:	O
Non	B-Task
-	I-Task
Uniform	I-Task
Motion	I-Task
Blur	I-Task
Removal	I-Task
	
To	O
train	O
models	O
for	O
non	B-Task
-	I-Task
uniform	I-Task
motion	I-Task
blur	I-Task
removal	I-Task
,	O
we	O
generate	O
the	O
64	O
64	O
-	O
resolution	O
blurry	O
patches	O
from	O
clear	O
ones	O
using	O
random	B-Method
linear	I-Method
kernels	I-Method
,	O
which	O
are	O
of	O
size	O
30	O
30	O
and	O
have	O
motion	O
vector	O
with	O
random	O
orientation	O
in	O
degrees	O
and	O
random	O
length	O
in	O
pixels	O
.	O
	
We	O
set	O
the	O
predicted	O
filter	O
size	O
to	O
be	O
17	O
17	O
so	O
the	O
model	O
outputs	O
17	O
17	O
289	O
filter	O
weights	O
at	O
each	O
image	O
location	O
.	O
	
Note	O
that	O
we	O
generate	O
training	O
pairs	O
on	O
the	O
fly	O
during	O
training	O
,	O
so	O
our	O
model	O
can	O
deal	O
with	O
a	O
wide	O
range	O
of	O
motion	O
blurs	O
.	O
	
This	O
is	O
advantageous	O
over	O
methods	O
in	O
which	O
require	O
a	O
predefined	O
set	O
of	O
blur	O
kernels	O
used	O
for	O
deconvolution	B-Task
through	O
some	O
offline	B-Method
algorithm	I-Method
.	O
	
In	O
Table	O
[	O
reference	O
]	O
,	O
we	O
list	O
the	O
comparison	O
with	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
over	O
the	O
released	O
test	O
set	O
by	O
.	O
	
There	O
are	O
two	O
subsets	O
in	O
the	O
dataset	O
,	O
one	O
with	O
moderate	O
motion	O
blur	O
and	O
the	O
other	O
with	O
large	O
blur	O
.	O
	
We	O
also	O
report	O
our	O
CNN	B-Method
models	I-Method
based	O
on	O
the	O
proposed	O
two	B-Method
-	I-Method
stream	I-Method
architecture	I-Method
that	O
outputs	O
the	O
quality	O
images	O
directly	O
by	O
taking	O
as	O
input	O
the	O
blurry	O
ones	O
.	O
	
Our	O
CNN	B-Method
model	I-Method
outperforms	O
the	O
one	O
in	O
which	O
trains	O
a	O
CNN	B-Method
for	O
predicting	O
the	O
blur	O
kernel	O
over	O
a	O
patch	O
,	O
but	O
carries	O
out	O
non	B-Method
-	I-Method
blind	I-Method
deconvolution	I-Method
with	O
the	O
estimated	B-Method
kernel	I-Method
for	O
the	O
final	O
quality	O
image	O
.	O
	
We	O
attribute	O
our	O
better	O
performance	O
to	O
two	O
reasons	O
.	O
	
First	O
,	O
our	O
CNN	B-Method
model	I-Method
learns	O
a	O
direct	O
inverse	B-Method
mapping	I-Method
from	O
blurry	O
patch	O
to	O
its	O
clear	O
counterpart	O
based	O
on	O
the	O
learned	O
image	O
distribution	O
,	O
whereas	O
only	O
estimates	O
the	O
blur	O
kernel	O
for	O
the	O
patch	O
and	O
uses	O
an	O
offline	B-Method
optimization	I-Method
for	O
non	B-Task
-	I-Task
blind	I-Task
deblurring	I-Task
,	O
resulting	O
in	O
some	O
artifacts	O
such	O
as	O
ringing	O
.	O
	
Second	O
,	O
our	O
CNN	B-Method
architecture	I-Method
is	O
higher	O
fidelity	O
than	O
the	O
one	O
used	O
in	O
,	O
as	O
ours	O
outputs	O
full	O
-	O
resolution	O
result	O
and	O
learns	O
internally	O
to	O
minimize	O
artifacts	O
,	O
e.g.	O
,	O
aliasing	O
and	O
ringing	O
effect	O
.	O
	
From	O
the	O
table	O
,	O
we	O
can	O
see	O
our	O
PFF	B-Method
model	I-Method
outperforms	O
all	O
the	O
other	O
methods	O
by	O
a	O
fair	O
margin	O
.	O
	
To	O
understand	O
where	O
our	O
model	O
performs	O
better	O
,	O
we	O
visualize	O
the	O
qualitative	O
results	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
along	O
with	O
the	O
filter	B-Method
flow	I-Method
maps	I-Method
as	O
output	O
from	O
PFF	B-Method
.	O
	
We	O
ca	O
n’t	O
easily	O
visualize	O
the	O
289	B-Method
dimensional	I-Method
filters	I-Method
.	O
	
However	O
,	O
since	O
the	O
predicted	O
weights	O
are	O
positive	O
and	O
normalized	O
,	O
we	O
can	O
treat	O
them	O
as	O
a	O
distribution	O
which	O
we	O
summarize	O
by	O
computing	O
the	O
expected	O
flow	O
vector	O
where	O
is	O
a	O
particular	O
output	O
pixel	O
and	O
indexes	O
the	O
input	O
pixels	O
.	O
	
This	O
can	O
be	O
interpreted	O
as	O
the	O
optical	O
flow	O
(	O
delta	B-Method
filter	I-Method
)	O
which	O
most	O
closely	O
approximates	O
the	O
predicted	O
filter	O
flow	O
.	O
	
We	O
use	O
the	O
the	O
color	O
legend	O
shown	O
in	O
top	O
-	O
left	O
of	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
The	O
last	O
two	O
rows	O
of	O
Fig	O
.	O
	
[	O
reference	O
]	O
show	O
the	O
results	O
over	O
real	O
-	O
world	O
blurry	O
images	O
for	O
which	O
there	O
is	O
no	O
“	O
blur	O
-	O
free	O
”	O
ground	O
-	O
truth	O
.	O
	
We	O
can	O
clearly	O
see	O
that	O
images	O
produced	O
by	O
PFF	B-Method
have	O
less	O
artifacts	O
such	O
as	O
ringing	O
artifacts	O
around	O
sharp	O
edges	O
.	O
	
Interestingly	O
,	O
from	O
the	O
filter	B-Method
flow	I-Method
maps	I-Method
,	O
we	O
can	O
see	O
that	O
the	O
expected	O
flow	O
vectors	O
are	O
large	O
near	O
high	O
contrast	O
boundaries	O
and	O
smaller	O
in	O
regions	O
that	O
are	O
already	O
in	O
sharp	O
focus	O
or	O
which	O
are	O
uniform	O
in	O
color	O
.	O
	
Although	O
we	O
define	O
the	O
filter	O
size	O
as	O
17	O
17	O
,	O
which	O
is	O
much	O
smaller	O
than	O
the	O
maximum	O
shift	O
in	O
the	O
largest	O
blur	O
(	O
up	O
to	O
30	O
pixels	O
)	O
,	O
our	O
model	O
still	O
handles	O
large	O
motion	O
blur	O
and	O
performs	O
better	O
than	O
.	O
	
We	O
assume	O
it	O
should	O
be	O
possible	O
to	O
utilize	O
larger	O
filter	O
sizes	O
but	O
we	O
did	O
not	O
observe	O
further	O
improvements	O
when	O
training	O
models	O
to	O
synthesize	O
larger	O
per	O
-	O
pixel	O
kernels	O
.	O
	
This	O
suggests	O
that	O
a	O
larger	O
blurry	O
dataset	O
is	O
needed	O
to	O
validate	O
this	O
point	O
in	O
future	O
work	O
.	O
	
We	O
also	O
considered	O
an	O
iterative	B-Method
variant	I-Method
of	O
our	O
model	O
in	O
which	O
we	O
feed	O
the	O
resulting	O
deblurred	O
image	O
back	O
as	O
input	O
to	O
the	O
model	O
.	O
	
However	O
,	O
we	O
found	O
relatively	O
little	O
improvement	O
with	O
additional	O
iterations	O
(	O
results	O
shown	O
in	O
the	O
appendix	O
)	O
.	O
	
We	O
conjecture	O
that	O
,	O
although	O
the	O
model	O
was	O
trained	O
with	O
a	O
wide	O
range	O
of	O
blurred	O
examples	O
,	O
the	O
statistics	O
of	O
the	O
transformed	O
image	O
from	O
the	O
first	O
iteration	O
are	O
sufficiently	O
different	O
than	O
the	O
blurred	O
training	O
inputs	O
.	O
	
One	O
solution	O
could	O
be	O
inserting	O
adversarial	O
loss	O
to	O
push	O
the	O
model	O
to	O
generate	O
more	O
fine	O
-	O
grained	O
textures	O
(	O
as	O
done	O
in	O
for	O
image	B-Task
super	I-Task
-	I-Task
resolution	I-Task
)	O
.	O
	
subsection	O
:	O
JPEG	B-Task
Compression	I-Task
Artifact	I-Task
Reduction	I-Task
	
Similar	O
to	O
training	O
for	O
image	B-Task
deblurring	I-Task
,	O
we	O
generate	O
JPEG	O
compressed	O
image	O
patches	O
from	O
original	O
non	O
-	O
compressed	O
ones	O
on	O
the	O
fly	O
during	O
training	O
.	O
	
This	O
can	O
be	O
easily	O
done	O
using	O
JPEG	B-Method
compression	I-Method
function	I-Method
by	O
varying	O
the	O
quality	O
factor	O
(	O
QF	O
)	O
of	O
interest	O
.	O
	
In	O
Table	O
[	O
reference	O
]	O
,	O
we	O
list	O
the	O
performance	O
of	O
our	O
model	O
and	O
compare	O
to	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
.	O
	
We	O
note	O
that	O
our	O
final	O
PFF	B-Method
achieves	O
the	O
best	O
among	O
all	O
the	O
methods	O
.	O
	
Our	O
CNN	B-Method
baseline	I-Method
model	I-Method
also	O
achieves	O
on	O
-	O
par	O
performance	O
with	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
,	O
though	O
we	O
do	O
not	O
show	O
in	O
the	O
table	O
,	O
we	O
draw	O
the	O
performance	O
under	O
the	O
ablation	O
study	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Specifically	O
,	O
we	O
study	O
how	O
our	O
model	O
trained	O
with	O
single	O
or	O
a	O
mixed	O
QFs	O
affect	O
the	O
performance	O
when	O
tested	O
on	O
image	O
compressed	O
with	O
a	O
range	O
of	O
different	O
QFs	O
.	O
	
We	O
plot	O
the	O
detailed	O
performances	O
of	O
our	O
CNN	B-Method
and	O
PFF	B-Method
in	O
terms	O
of	O
absolute	B-Metric
measurements	I-Metric
by	O
PSNR	B-Metric
and	O
SSIM	B-Metric
,	O
and	O
the	O
increase	O
in	O
PSNR	B-Metric
between	O
the	O
reconstructed	O
and	O
JPEG	O
compressed	O
image	O
.	O
	
We	O
can	O
see	O
that	O
,	O
though	O
a	O
model	O
trained	O
with	O
QF=10	B-Method
overfits	O
the	O
dataset	O
,	O
all	O
the	O
other	O
models	O
achieve	O
generalizable	O
and	O
stable	O
performance	O
.	O
	
Basically	O
,	O
a	O
model	O
trained	O
on	O
a	O
single	O
QF	B-Method
brings	O
the	O
largest	O
performance	O
gain	O
over	O
images	O
compressed	O
with	O
the	O
same	O
QF	O
.	O
	
Moreover	O
,	O
when	O
our	O
model	O
is	O
trained	O
with	O
mixed	O
quality	O
factors	O
,	O
its	O
performance	O
is	O
quite	O
stable	O
and	O
competitive	O
with	O
quality	B-Method
-	I-Method
specific	I-Method
models	I-Method
across	O
different	O
compression	B-Metric
quality	I-Metric
factors	I-Metric
.	O
	
This	O
indicates	O
that	O
our	O
model	O
is	O
of	O
practical	O
value	O
in	O
real	B-Task
-	I-Task
world	I-Task
applications	I-Task
.	O
	
In	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
,	O
we	O
demonstrate	O
qualitative	O
comparison	O
between	O
CNN	B-Method
and	O
PFF	B-Method
.	O
	
The	O
output	O
filter	B-Method
flow	I-Method
maps	I-Method
indicate	O
from	O
the	O
colorful	O
edges	O
how	O
the	O
pixels	O
are	O
warped	O
from	O
the	O
neighborhood	O
in	O
the	O
input	O
image	O
.	O
	
This	O
also	O
clearly	O
shows	O
where	O
the	O
JPEG	O
image	O
degrades	O
most	O
,	O
e.g.	O
,	O
the	O
large	O
sky	O
region	O
is	O
quantized	O
by	O
JPEG	B-Method
compression	I-Method
.	O
	
Though	O
CNN	B-Method
makes	O
the	O
block	O
effect	O
smooth	O
to	O
some	O
extent	O
,	O
our	O
PFF	B-Method
produces	O
the	O
best	O
visual	B-Metric
quality	I-Metric
,	O
smoothing	O
the	O
block	O
artifact	O
while	O
maintaining	O
both	O
high	O
-	O
and	O
low	O
-	O
frequency	O
details	O
.	O
	
PSNR	B-Metric
improvements	O
.	O
	
SSIM	B-Metric
improvements	I-Metric
.	O
	
subsection	O
:	O
Single	B-Task
Image	I-Task
Super	I-Task
-	I-Task
Resolution	I-Task
	
In	O
this	O
work	O
,	O
we	O
only	O
generate	O
pairs	O
to	O
super	O
-	O
resolve	O
images	O
4	O
larger	O
.	O
	
To	O
generate	O
training	O
pairs	O
,	O
for	O
each	O
original	O
image	O
,	O
we	O
downsample	O
and	O
upsample	O
	
4	O
again	O
using	O
bicubic	B-Method
interpolation	I-Method
(	O
with	O
anti	O
-	O
aliasing	O
)	O
.	O
	
The	O
4	O
upsampled	O
image	O
from	O
the	O
low	O
-	O
resolution	O
is	O
the	O
input	O
to	O
our	O
model	O
.	O
	
Therefore	O
,	O
a	O
super	B-Method
-	I-Method
resolution	I-Method
model	I-Method
is	O
expected	O
to	O
be	O
learned	O
for	O
sharpening	O
the	O
input	O
image	O
.	O
	
In	O
Table	O
[	O
reference	O
]	O
,	O
we	O
compare	O
our	O
PFF	B-Method
model	I-Method
quantitatively	O
with	O
other	O
methods	O
.	O
	
We	O
can	O
see	O
that	O
our	O
model	O
outperforms	O
the	O
others	O
on	O
both	O
test	O
sets	O
.	O
	
In	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
,	O
we	O
compare	O
visually	O
over	O
bicubic	B-Method
interpolation	I-Method
,	O
CNN	B-Method
and	O
PFF	B-Method
.	O
	
We	O
can	O
see	O
from	O
the	O
zoom	O
-	O
in	O
regions	O
that	O
our	O
PFF	B-Method
generates	O
sharper	O
boundaries	O
and	O
delivers	O
an	O
anti	O
-	O
aliasing	O
functionality	O
.	O
	
The	O
filter	B-Method
flow	I-Method
maps	I-Method
once	O
again	O
act	O
as	O
a	O
guide	O
,	O
illustrating	O
where	O
the	O
smoothing	B-Task
happens	O
and	O
where	O
sharpening	O
happens	O
.	O
	
Especially	O
,	O
the	O
filter	B-Method
maps	I-Method
demonstrate	O
from	O
the	O
strong	O
colorful	O
edges	O
where	O
the	O
pixels	O
undergo	O
larger	O
transforms	O
.	O
	
In	O
next	O
section	O
,	O
we	O
visualize	O
the	O
per	O
-	O
pixel	O
kernels	O
to	O
have	O
an	O
in	O
-	O
depth	O
understanding	O
.	O
	
Set5	B-Material
	
Set14	B-Material
	
section	O
:	O
Visualization	B-Task
and	O
Analysis	O
	
We	O
explored	O
a	O
number	O
of	O
techniques	O
to	O
visualize	O
the	O
predicted	O
filter	O
flows	O
for	O
different	O
tasks	O
.	O
	
First	O
,	O
we	O
ran	O
k	B-Method
-	I-Method
means	I-Method
on	O
predicted	B-Method
filters	I-Method
from	O
the	O
set	O
of	O
test	O
images	O
for	O
each	O
the	O
three	O
tasks	O
,	O
respectively	O
,	O
to	O
cluster	O
the	O
kernels	O
into	O
=	O
400	O
groups	O
.	O
	
Then	O
we	O
run	O
t	B-Method
-	I-Method
SNE	I-Method
over	O
the	O
400	O
mean	B-Method
filters	I-Method
to	O
display	O
them	O
in	O
the	O
image	O
plane	O
,	O
shown	O
by	O
the	O
scatter	O
plots	O
in	O
top	O
row	O
of	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
Qualitative	O
inspection	O
shows	O
filters	O
that	O
can	O
be	O
interpreted	O
as	O
performing	O
translation	O
or	O
integration	O
along	O
lines	O
of	O
different	O
orientation	O
(	O
non	O
-	O
uniform	O
blur	O
)	O
,	O
filling	O
in	O
high	O
-	O
frequency	O
detail	O
(	O
jpeg	B-Task
artifact	I-Task
reduction	I-Task
)	O
and	O
deformed	B-Method
Laplacian	I-Method
-	I-Method
like	I-Method
filters	I-Method
(	O
super	B-Method
-	I-Method
resolution	I-Method
)	O
.	O
	
We	O
also	O
examined	O
the	O
top	O
10	O
principal	O
components	O
of	O
the	O
predicted	O
filters	O
(	O
shown	O
in	O
the	O
second	O
row	O
grid	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
The	O
10D	B-Method
principal	I-Method
subspace	I-Method
capture	O
99.65	O
%	O
,	O
99.99	O
%	O
and	O
99.99	O
%	O
of	O
the	O
filter	O
energy	O
for	O
non	B-Task
-	I-Task
uniform	I-Task
blur	I-Task
,	O
artifact	B-Task
removal	I-Task
and	O
super	B-Task
resolution	I-Task
respectively	O
.	O
	
PCA	B-Method
reveals	O
smooth	O
,	O
symmetric	O
harmonic	O
structure	O
for	O
super	B-Task
-	I-Task
resolution	I-Task
with	O
some	O
intriguing	O
vertical	O
and	O
horizontal	O
features	O
.	O
	
Finally	O
,	O
in	O
order	O
to	O
summarize	O
the	O
spatially	O
varying	O
structure	O
of	O
the	O
filters	O
,	O
we	O
use	O
the	O
2D	B-Method
t	I-Method
-	I-Method
SNE	I-Method
embedding	I-Method
to	O
assign	O
a	O
color	O
to	O
each	O
centroid	O
(	O
as	O
given	O
by	O
the	O
reference	O
color	O
chart	O
shown	O
top	O
-	O
left	O
)	O
,	O
and	O
visualize	O
the	O
nearest	O
centroid	O
for	O
the	O
filter	O
at	O
each	O
filter	O
location	O
in	O
the	O
third	O
row	O
grid	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
.	O
	
This	O
visualization	O
demonstrates	O
the	O
filters	O
as	O
output	O
by	O
our	O
model	O
generally	O
vary	O
smoothly	O
over	O
the	O
image	O
with	O
discontinuities	O
along	O
salient	O
edges	O
and	O
textured	O
regions	O
reminiscent	O
of	O
anisotropic	B-Method
diffusion	I-Method
or	O
bilateral	B-Method
filtering	I-Method
.	O
	
In	O
summary	O
,	O
these	O
visualizations	O
provide	O
a	O
transparent	O
view	O
of	O
how	O
each	O
reconstructed	O
pixel	O
is	O
assembled	O
from	O
the	O
degraded	O
input	O
image	O
.	O
	
We	O
view	O
this	O
as	O
a	O
notable	O
advantage	O
over	O
other	O
CNN	B-Method
-	I-Method
based	I-Method
models	I-Method
which	O
simply	O
perform	O
image	B-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
regression	I-Task
.	O
	
Unlike	O
activations	O
of	O
intermediate	O
layers	O
of	O
a	O
CNN	B-Method
,	O
linear	B-Method
filter	I-Method
weights	I-Method
have	O
a	O
well	O
defined	O
semantics	O
that	O
can	O
be	O
visualized	O
and	O
analyzed	O
using	O
well	O
developed	O
tools	O
of	O
linear	B-Method
signal	I-Method
processing	I-Method
.	O
	
section	O
:	O
Conclusion	O
and	O
Future	O
Work	O
	
We	O
propose	O
a	O
general	O
,	O
elegant	O
and	O
simple	O
framework	O
called	O
Predictive	B-Method
Filter	I-Method
Flow	I-Method
,	O
which	O
has	O
direct	O
applications	O
to	O
a	O
broad	O
range	O
of	O
image	B-Task
reconstruction	I-Task
tasks	I-Task
.	O
	
Our	O
framework	O
generates	O
space	B-Method
-	I-Method
variant	I-Method
per	I-Method
-	I-Method
pixel	I-Method
filters	I-Method
which	O
are	O
easy	O
to	O
interpret	O
and	O
fast	O
to	O
compute	O
at	O
test	O
time	O
.	O
	
Through	O
extensive	O
experiments	O
over	O
three	O
different	O
low	B-Task
-	I-Task
level	I-Task
vision	I-Task
tasks	I-Task
,	O
we	O
demonstrate	O
this	O
approach	O
outperforms	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
.	O
	
In	O
our	O
experiments	O
here	O
,	O
we	O
only	O
train	O
light	B-Method
-	I-Method
weight	I-Method
models	I-Method
over	O
patches	O
,	O
However	O
,	O
we	O
believe	O
global	O
image	O
context	O
is	O
also	O
important	O
for	O
these	O
tasks	O
and	O
is	O
an	O
obvious	O
direction	O
for	O
future	O
work	O
.	O
	
For	O
example	O
,	O
the	O
global	O
blur	O
structure	O
conveys	O
information	O
about	O
camera	O
shake	O
;	O
super	B-Task
-	I-Task
resolution	I-Task
and	O
compression	B-Task
reduction	I-Task
can	O
benefit	O
from	O
long	O
-	O
range	O
interactions	O
to	O
reconstruct	O
high	O
-	O
frequency	O
detail	O
(	O
as	O
in	O
non	O
-	O
local	O
means	O
)	O
.	O
	
Moreover	O
,	O
we	O
expect	O
that	O
the	O
interpretability	O
of	O
the	O
output	O
will	O
be	O
particularly	O
appealing	O
for	O
interactive	B-Task
and	I-Task
scientific	I-Task
applications	I-Task
such	O
as	O
medical	B-Task
imaging	I-Task
and	O
biological	B-Task
microscopy	I-Task
where	O
predicted	B-Task
filters	I-Task
could	O
be	O
directly	O
compared	O
to	O
physical	B-Method
models	I-Method
of	I-Method
the	I-Method
imaging	I-Method
process	I-Method
.	O
	
section	O
:	O
Acknowledgement	O
	
This	O
project	O
is	O
supported	O
by	O
NSF	O
grants	O
IIS	O
-	O
1618806	O
,	O
IIS	O
-	O
1253538	O
,	O
DBI	O
-	O
1262547	O
and	O
a	O
hardware	O
donation	O
from	O
NVIDIA	O
.	O
	
bibliography	O
:	O
References	O
	
Appendix	O
	
In	O
the	O
supplementary	O
material	O
,	O
we	O
first	O
show	O
more	O
visualizations	O
to	O
understand	O
the	O
predicted	O
filter	O
flows	O
,	O
then	O
show	O
if	O
it	O
is	O
possible	O
to	O
refine	O
the	O
results	O
by	O
iteratively	O
feeding	O
deblurred	O
image	O
to	O
the	O
same	O
model	O
for	O
the	O
task	O
of	O
non	B-Task
-	I-Task
uniform	I-Task
motion	I-Task
blur	I-Task
removal	I-Task
.	O
	
We	O
finally	O
present	O
more	O
qualitative	O
results	O
for	O
all	O
the	O
three	O
tasks	O
studied	O
in	O
this	O
paper	O
.	O
	
section	O
:	O
Visualization	O
of	O
Per	O
-	O
Pixel	O
Loading	O
Factors	O
	
As	O
a	O
supplementary	O
visualization	O
to	O
the	O
principal	B-Method
components	I-Method
by	O
PCA	B-Method
shown	O
in	O
the	O
main	O
paper	O
,	O
we	O
can	O
also	O
visualize	O
the	O
per	O
-	O
pixel	O
loading	O
factors	O
corresponding	O
to	O
each	O
principal	B-Method
component	I-Method
.	O
	
We	O
run	O
PCA	B-Method
over	O
testing	O
set	O
and	O
show	O
the	O
first	O
six	O
principal	O
components	O
and	O
the	O
corresponding	O
per	O
-	O
pixel	O
loading	O
factors	O
as	O
a	O
heatmap	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
With	O
this	O
visualization	B-Method
technique	I-Method
,	O
we	O
can	O
know	O
what	O
region	O
has	O
higher	O
response	O
to	O
which	O
component	O
kernels	O
.	O
	
Moreover	O
,	O
given	O
that	O
the	O
first	O
ten	O
principal	B-Method
components	I-Method
capture	O
filter	O
energy	O
(	O
stated	O
in	O
the	O
main	O
paper	O
)	O
,	O
we	O
expect	O
future	O
work	O
to	O
predict	O
compact	O
per	B-Method
-	I-Method
pixel	I-Method
filters	I-Method
using	O
low	B-Method
-	I-Method
rank	I-Method
technique	I-Method
,	O
which	O
allows	O
for	O
incorporating	O
long	O
-	O
range	O
pixels	O
through	O
large	O
predictive	B-Method
filters	I-Method
while	O
with	O
compact	O
features	O
(	O
thus	O
memory	O
consumption	O
is	O
reduced	O
largely	O
)	O
.	O
	
section	O
:	O
Iteratively	B-Task
Removing	I-Task
Motion	I-Task
Blur	I-Task
	
As	O
the	O
deblurred	O
images	O
are	O
still	O
not	O
perfect	O
,	O
we	O
are	O
interested	O
in	O
studying	O
if	O
we	O
can	O
improve	O
performance	O
by	O
iteratively	O
running	O
the	O
model	O
,	O
i.e.	O
,	O
feeding	O
the	O
deblurred	O
image	O
as	O
input	O
to	O
the	O
same	O
model	O
one	O
more	O
time	O
to	O
get	O
the	O
result	O
.	O
	
We	O
denote	O
this	O
method	O
as	O
PFF	B-Method
+	I-Method
1	I-Method
.	O
	
Not	O
much	O
surprisingly	O
,	O
we	O
do	O
not	O
observe	O
further	O
improvement	O
as	O
listed	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
instead	O
,	O
such	O
a	O
practice	O
even	O
hurts	O
performance	O
slightly	O
.	O
	
The	O
qualitative	O
results	O
are	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
from	O
which	O
we	O
can	O
see	O
the	O
second	O
run	O
does	O
not	O
generate	O
much	O
change	O
through	O
the	O
filter	B-Method
flow	I-Method
maps	I-Method
.	O
	
We	O
believe	O
the	O
reason	O
is	O
that	O
,	O
the	O
deblurred	O
images	O
have	O
different	O
statistics	O
from	O
the	O
original	O
blurry	O
input	O
,	O
and	O
the	O
model	O
is	O
not	O
trained	O
with	O
such	O
deblurred	O
images	O
.	O
	
Therefore	O
,	O
it	O
suggests	O
two	O
natural	O
directions	O
as	O
future	O
work	O
for	O
improving	O
the	O
results	O
,	O
1	O
)	O
training	O
explicitly	O
with	O
recurrent	B-Method
loops	I-Method
with	O
multiple	O
losses	O
to	O
improve	O
the	O
performance	O
,	O
similar	O
to	O
,	O
or	O
2	O
)	O
simultaneously	O
inserting	O
an	O
adversarial	O
loss	O
to	O
force	O
the	O
model	O
to	O
hallucinate	O
details	O
for	O
realistic	O
output	O
,	O
which	O
can	O
be	O
useful	O
in	O
practice	O
as	O
done	O
in	O
.	O
	
section	O
:	O
More	O
Qualitative	O
Results	O
	
In	O
Figure	O
[	O
reference	O
]	O
,	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
	
,	O
we	O
show	O
more	O
qualitative	O
results	O
for	O
non	B-Task
-	I-Task
uniform	I-Task
motion	I-Task
blur	I-Task
removal	I-Task
,	O
JPEG	B-Task
compression	I-Task
artifact	I-Task
reduction	I-Task
and	O
single	B-Task
image	I-Task
super	I-Task
-	I-Task
resolution	I-Task
,	O
respectively	O
.	O
	
From	O
these	O
comparisons	O
and	O
with	O
the	O
guide	O
of	O
filter	O
flow	O
maps	O
,	O
we	O
can	O
see	O
at	O
what	O
regions	O
our	O
PFF	B-Method
pays	O
attention	O
to	O
and	O
how	O
it	O
outperforms	O
the	O
other	O
methods	O
.	O
	
document	O
:	O
Multimodal	B-Task
Sentiment	I-Task
Analysis	I-Task
using	O
Hierarchical	B-Method
Fusion	I-Method
with	O
Context	B-Method
Modeling	I-Method
	
Multimodal	B-Task
sentiment	I-Task
analysis	I-Task
is	O
a	O
very	O
actively	O
growing	O
field	O
of	O
research	O
.	O
	
A	O
promising	O
area	O
of	O
opportunity	O
in	O
this	O
field	O
is	O
to	O
improve	O
the	O
multimodal	B-Method
fusion	I-Method
mechanism	I-Method
.	O
	
We	O
present	O
a	O
novel	O
feature	O
fusion	B-Method
strategy	I-Method
that	O
proceeds	O
in	O
a	O
hierarchical	O
fashion	O
,	O
first	O
fusing	O
the	O
modalities	O
two	O
in	O
two	O
and	O
only	O
then	O
fusing	O
all	O
three	O
modalities	O
.	O
	
On	O
multimodal	B-Task
sentiment	I-Task
analysis	I-Task
of	O
individual	O
utterances	O
,	O
our	O
strategy	O
outperforms	O
conventional	O
concatenation	B-Method
of	I-Method
features	I-Method
by	O
1	O
%	O
,	O
which	O
amounts	O
to	O
5	O
%	O
reduction	O
in	O
error	B-Metric
rate	I-Metric
.	O
	
On	O
utterance	B-Task
-	I-Task
level	I-Task
multimodal	I-Task
sentiment	I-Task
analysis	I-Task
of	O
multi	O
-	O
utterance	O
video	O
clips	O
,	O
for	O
which	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
techniques	O
incorporate	O
contextual	O
information	O
from	O
other	O
utterances	O
of	O
the	O
same	O
clip	O
,	O
our	O
hierarchical	B-Method
fusion	I-Method
gives	O
up	O
to	O
2.4	O
%	O
(	O
almost	O
10	O
%	O
error	B-Metric
rate	I-Metric
reduction	I-Metric
)	O
over	O
currently	O
used	O
concatenation	B-Method
.	O
	
The	O
implementation	O
of	O
our	O
method	O
is	O
publicly	O
available	O
in	O
the	O
form	O
of	O
open	O
-	O
source	O
code	O
.	O
	
section	O
:	O
Introduction	O
	
On	O
numerous	O
social	O
media	O
platforms	O
,	O
such	O
as	O
YouTube	O
,	O
Facebook	O
,	O
or	O
Instagram	O
,	O
people	O
share	O
their	O
opinions	O
on	O
all	O
kinds	O
of	O
topics	O
in	O
the	O
form	O
of	O
posts	O
,	O
images	O
,	O
and	O
video	O
clips	O
.	O
	
With	O
the	O
proliferation	O
of	O
smartphones	O
and	O
tablets	O
,	O
which	O
has	O
greatly	O
boosted	O
content	B-Task
sharing	I-Task
,	O
people	O
increasingly	O
share	O
their	O
opinions	O
on	O
newly	O
released	O
products	O
or	O
on	O
other	O
topics	O
in	O
form	O
of	O
video	O
reviews	O
or	O
comments	O
.	O
	
This	O
is	O
an	O
excellent	O
opportunity	O
for	O
large	O
companies	O
to	O
capitalize	O
on	O
,	O
by	O
extracting	O
user	O
sentiment	O
,	O
suggestions	O
,	O
and	O
complaints	O
on	O
their	O
products	O
from	O
these	O
video	O
reviews	O
.	O
	
This	O
information	O
also	O
opens	O
new	O
horizons	O
to	O
improving	O
our	O
quality	O
of	O
life	O
by	O
making	O
informed	O
decisions	O
on	O
the	O
choice	O
of	O
products	O
we	O
buy	O
,	O
services	O
we	O
use	O
,	O
places	O
we	O
visit	O
,	O
or	O
movies	O
we	O
watch	O
basing	O
on	O
the	O
experience	O
and	O
opinions	O
of	O
other	O
users	O
.	O
	
Videos	O
convey	O
information	O
through	O
three	O
channels	O
:	O
audio	O
,	O
video	O
,	O
and	O
text	O
(	O
in	O
the	O
form	O
of	O
speech	O
)	O
.	O
	
Mining	B-Task
opinions	I-Task
from	O
this	O
plethora	O
of	O
multimodal	O
data	O
calls	O
for	O
a	O
solid	O
multimodal	B-Task
sentiment	I-Task
analysis	I-Task
technology	I-Task
.	O
	
One	O
of	O
the	O
major	O
problems	O
faced	O
in	O
multimodal	B-Task
sentiment	I-Task
analysis	I-Task
is	O
the	O
fusion	B-Task
of	I-Task
features	I-Task
pertaining	O
to	O
different	O
modalities	O
.	O
	
For	O
this	O
,	O
the	O
majority	O
of	O
the	O
recent	O
works	O
in	O
multimodal	B-Task
sentiment	I-Task
analysis	I-Task
have	O
simply	O
concatenated	O
the	O
feature	O
vectors	O
of	O
different	O
modalities	O
.	O
	
However	O
,	O
this	O
does	O
not	O
take	O
into	O
account	O
that	O
different	O
modalities	O
may	O
carry	O
conflicting	O
information	O
.	O
	
We	O
hypothesize	O
that	O
the	O
fusion	B-Method
method	I-Method
we	O
present	O
in	O
this	O
paper	O
deals	O
with	O
this	O
issue	O
better	O
,	O
and	O
present	O
experimental	O
evidence	O
showing	O
improvement	O
over	O
simple	O
concatenation	B-Method
of	I-Method
feature	I-Method
vectors	I-Method
.	O
	
Also	O
,	O
following	O
the	O
state	O
of	O
the	O
art	O
,	O
we	O
employ	O
recurrent	B-Method
neural	I-Method
network	I-Method
(	O
RNN	B-Method
)	O
to	O
propagate	O
contextual	O
information	O
between	O
utterances	O
in	O
a	O
video	O
clip	O
,	O
which	O
significantly	O
improves	O
the	O
classification	B-Task
results	O
and	O
outperforms	O
the	O
state	O
of	O
the	O
art	O
by	O
a	O
significant	O
margin	O
of	O
1–2	O
%	O
for	O
all	O
the	O
modality	O
combinations	O
.	O
	
In	O
our	O
method	O
,	O
we	O
first	O
obtain	O
unimodal	O
features	O
for	O
each	O
utterance	O
for	O
all	O
three	O
modalities	O
.	O
	
Then	O
,	O
using	O
RNN	B-Method
we	O
extract	O
context	O
-	O
aware	O
utterance	O
features	O
.	O
	
Thus	O
,	O
we	O
transform	O
the	O
context	O
-	O
aware	O
utterance	O
vectors	O
to	O
the	O
vectors	O
of	O
the	O
same	O
dimensionality	O
.	O
	
We	O
assume	O
that	O
these	O
transformed	O
vectors	O
contain	O
abstract	O
features	O
representing	O
the	O
attributes	O
relevant	O
to	O
sentiment	B-Task
classification	I-Task
.	O
	
Next	O
,	O
we	O
compare	O
and	O
combine	O
each	O
bimodal	B-Method
combination	I-Method
of	O
these	O
abstract	O
features	O
using	O
fully	B-Method
-	I-Method
connected	I-Method
layers	I-Method
.	O
	
This	O
yields	O
fused	O
bimodal	O
feature	O
vectors	O
.	O
	
Similarly	O
to	O
the	O
unimodal	B-Task
case	I-Task
,	O
we	O
use	O
RNN	B-Method
to	O
generate	O
context	O
-	O
aware	O
features	O
.	O
	
Finally	O
,	O
we	O
combine	O
these	O
bimodal	O
vectors	O
into	O
a	O
trimodal	B-Method
vector	I-Method
using	O
,	O
again	O
,	O
fully	B-Method
-	I-Method
connected	I-Method
layers	I-Method
and	O
use	O
a	O
RNN	B-Method
to	O
pass	O
contextual	O
information	O
between	O
them	O
.	O
	
We	O
empirically	O
show	O
that	O
the	O
feature	O
vectors	O
obtained	O
in	O
this	O
manner	O
are	O
more	O
useful	O
for	O
the	O
sentiment	B-Task
classification	I-Task
task	I-Task
.	O
	
The	O
implementation	O
of	O
our	O
method	O
is	O
publicly	O
available	O
in	O
the	O
form	O
of	O
open	O
-	O
source	O
code	O
.	O
	
This	O
paper	O
is	O
structured	O
as	O
follows	O
:	O
	
sec	O
:	O
related	O
-	O
work	O
-	O
1	O
briefly	O
discusses	O
important	O
previous	O
work	O
in	O
multimodal	B-Task
feature	I-Task
fusion	I-Task
;	O
sec	O
:	O
model	O
describes	O
our	O
method	O
in	O
details	O
;	O
sec	O
:	O
experiments	O
reports	O
the	O
results	O
of	O
our	O
experiments	O
and	O
discuss	O
their	O
implications	O
;	O
finally	O
,	O
sec	O
:	O
conclusions	O
concludes	O
the	O
paper	O
and	O
discusses	O
future	O
work	O
.	O
	
section	O
:	O
Related	O
Work	O
	
In	O
recent	O
years	O
,	O
sentiment	B-Task
analysis	I-Task
has	O
become	O
increasingly	O
popular	O
for	O
processing	O
social	O
media	O
data	O
on	O
online	O
communities	O
,	O
blogs	O
,	O
wikis	O
,	O
microblogging	O
platforms	O
,	O
and	O
other	O
online	O
collaborative	O
media	O
.	O
	
Sentiment	B-Task
analysis	I-Task
is	O
a	O
branch	O
of	O
affective	B-Task
computing	I-Task
research	I-Task
that	O
aims	O
to	O
classify	O
text	O
–	O
but	O
sometimes	O
also	O
audio	O
and	O
video	O
–	O
into	O
either	O
positive	O
or	O
negative	O
–	O
but	O
sometimes	O
also	O
neutral	O
.	O
	
Most	O
of	O
the	O
literature	O
is	O
on	O
English	O
language	O
but	O
recently	O
an	O
increasing	O
number	O
of	O
works	O
are	O
tackling	O
the	O
multilinguality	B-Task
issue	I-Task
,	O
especially	O
in	O
booming	O
online	O
languages	O
such	O
as	O
Chinese	O
.	O
	
Sentiment	B-Method
analysis	I-Method
techniques	I-Method
can	O
be	O
broadly	O
categorized	O
into	O
symbolic	B-Method
and	I-Method
sub	I-Method
-	I-Method
symbolic	I-Method
approaches	I-Method
:	O
the	O
former	O
include	O
the	O
use	O
of	O
lexicons	O
,	O
ontologies	O
,	O
and	O
semantic	B-Method
networks	I-Method
to	O
encode	O
the	O
polarity	O
associated	O
with	O
words	O
and	O
multiword	O
expressions	O
;	O
the	O
latter	O
consist	O
of	O
supervised	B-Method
,	I-Method
semi	I-Method
-	I-Method
supervised	I-Method
and	I-Method
unsupervised	I-Method
machine	I-Method
learning	I-Method
techniques	I-Method
that	O
perform	O
sentiment	B-Task
classification	I-Task
based	O
on	O
word	O
co	O
-	O
occurrence	O
frequencies	O
.	O
	
Among	O
these	O
,	O
the	O
most	O
popular	O
recently	O
are	O
algorithms	O
based	O
on	O
deep	B-Method
neural	I-Method
networks	I-Method
and	O
generative	B-Method
adversarial	I-Method
networks	I-Method
.	O
	
While	O
most	O
works	O
approach	O
it	O
as	O
a	O
simple	O
categorization	B-Task
problem	I-Task
,	O
sentiment	B-Task
analysis	I-Task
is	O
actually	O
a	O
suitcase	O
research	O
problem	O
that	O
requires	O
tackling	O
many	O
NLP	B-Task
tasks	I-Task
,	O
including	O
word	B-Task
polarity	I-Task
disambiguation	I-Task
,	O
subjectivity	B-Task
detection	I-Task
,	O
personality	B-Task
recognition	I-Task
,	O
microtext	B-Task
normalization	I-Task
,	O
concept	B-Task
extraction	I-Task
,	O
time	B-Task
tagging	I-Task
,	O
and	O
aspect	B-Task
extraction	I-Task
.	O
	
Sentiment	B-Task
analysis	I-Task
has	O
raised	O
growing	O
interest	O
both	O
within	O
the	O
scientific	O
community	O
,	O
leading	O
to	O
many	O
exciting	O
open	O
challenges	O
,	O
as	O
well	O
as	O
in	O
the	O
business	B-Task
world	I-Task
,	O
due	O
to	O
the	O
remarkable	O
benefits	O
to	O
be	O
had	O
from	O
financial	B-Task
and	I-Task
political	I-Task
forecasting	I-Task
,	O
e	B-Task
-	I-Task
health	I-Task
and	O
e	B-Task
-	I-Task
tourism	I-Task
,	O
user	B-Task
profiling	I-Task
and	O
community	B-Task
detection	I-Task
,	O
manufacturing	B-Task
and	I-Task
supply	I-Task
chain	I-Task
applications	I-Task
,	O
human	B-Task
communication	I-Task
comprehension	I-Task
and	O
dialogue	B-Task
systems	I-Task
,	O
etc	O
.	O
	
In	O
the	O
field	O
of	O
emotion	B-Task
recognition	I-Task
,	O
early	O
works	O
by	O
and	O
showed	O
that	O
fusion	B-Method
of	I-Method
audio	I-Method
and	I-Method
visual	I-Method
systems	I-Method
,	O
creating	O
a	O
bimodal	O
signal	O
,	O
yielded	O
a	O
higher	O
accuracy	B-Metric
than	O
any	O
unimodal	B-Method
system	I-Method
.	O
	
Such	O
fusion	O
has	O
been	O
analyzed	O
at	O
both	O
feature	B-Metric
level	I-Metric
and	O
decision	B-Metric
level	I-Metric
.	O
	
Although	O
there	O
is	O
much	O
work	O
done	O
on	O
audio	B-Task
-	I-Task
visual	I-Task
fusion	I-Task
for	O
emotion	B-Task
recognition	I-Task
,	O
exploring	O
contribution	O
of	O
text	O
along	O
with	O
audio	O
and	O
visual	O
modalities	O
in	O
multimodal	B-Task
emotion	I-Task
detection	I-Task
has	O
been	O
little	O
explored	O
.	O
and	O
fused	O
information	O
from	O
audio	O
,	O
visual	O
and	O
textual	O
modalities	O
to	O
extract	O
emotion	O
and	O
sentiment	O
.	O
and	O
fused	O
audio	O
and	O
textual	O
modalities	O
for	O
emotion	B-Task
recognition	I-Task
.	O
	
Both	O
approaches	O
relied	O
on	O
a	O
feature	B-Method
-	I-Method
level	I-Method
fusion	I-Method
.	O
	
fused	O
audio	O
and	O
textual	O
clues	O
at	O
decision	O
level	O
.	O
	
uses	O
convolutional	B-Method
neural	I-Method
network	I-Method
(	O
CNN	B-Method
)	O
to	O
extract	O
features	O
from	O
the	O
modalities	O
and	O
then	O
employs	O
multiple	B-Method
-	I-Method
kernel	I-Method
learning	I-Method
(	O
MKL	B-Method
)	I-Method
for	O
sentiment	B-Task
analysis	I-Task
.	O
	
The	O
current	O
state	O
of	O
the	O
art	O
,	O
set	O
forth	O
by	O
,	O
extracts	O
contextual	O
information	O
from	O
the	O
surrounding	O
utterances	O
using	O
long	B-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
(	O
LSTM	B-Method
)	O
.	O
	
fuses	O
different	O
modalities	O
with	O
deep	B-Method
learning	I-Method
-	I-Method
based	I-Method
tools	I-Method
.	O
	
uses	O
tensor	B-Method
fusion	I-Method
.	O
	
further	O
extends	O
upon	O
the	O
ensemble	B-Method
of	I-Method
CNN	I-Method
and	O
MKL	B-Method
.	O
	
Unlike	O
existing	O
approaches	O
,	O
which	O
use	O
simple	O
concatenation	O
based	O
early	B-Method
fusion	I-Method
and	O
non	B-Method
-	I-Method
trainable	I-Method
tensors	I-Method
based	I-Method
fusion	I-Method
,	O
this	O
work	O
proposes	O
a	O
hierarchical	B-Method
fusion	I-Method
capable	O
of	O
learning	O
the	O
bimodal	O
and	O
trimodal	O
correlations	O
for	O
data	B-Task
fusion	I-Task
using	O
deep	B-Method
neural	I-Method
networks	I-Method
.	O
	
The	O
method	O
is	O
end	O
-	O
to	O
-	O
end	O
and	O
,	O
in	O
order	O
to	O
accomplish	O
the	O
fusion	B-Task
,	O
it	O
can	O
be	O
plugged	O
into	O
any	O
deep	B-Method
neural	I-Method
network	I-Method
based	I-Method
multimodal	I-Method
sentiment	I-Method
analysis	I-Method
framework	I-Method
.	O
	
section	O
:	O
Our	O
Method	O
	
In	O
this	O
section	O
,	O
we	O
discuss	O
our	O
novel	O
methodology	O
behind	O
solving	O
the	O
sentiment	B-Task
classification	I-Task
problem	I-Task
.	O
	
First	O
we	O
discuss	O
the	O
overview	O
of	O
our	O
method	O
and	O
then	O
we	O
discuss	O
the	O
whole	O
method	O
in	O
details	O
,	O
step	O
by	O
step	O
.	O
	
subsection	O
:	O
Overview	O
	
subsubsection	O
:	O
Unimodal	B-Method
Feature	I-Method
Extraction	I-Method
	
We	O
extract	O
utterance	O
-	O
level	O
features	O
for	O
three	O
modalities	O
.	O
	
This	O
step	O
is	O
discussed	O
in	O
UFE	O
.	O
	
subsubsection	O
:	O
Multimodal	B-Task
Fusion	I-Task
	
paragraph	O
:	O
Problems	O
of	O
early	B-Method
fusion	I-Method
	
The	O
majority	O
of	O
the	O
work	O
on	O
multimodal	O
data	O
use	O
concatenation	B-Method
,	O
or	O
early	B-Method
fusion	I-Method
(	O
fig	O
:	O
early_fusion	B-Method
)	O
,	O
as	O
their	O
fusion	B-Method
strategy	I-Method
.	O
	
The	O
problem	O
with	O
this	O
simplistic	O
approach	O
is	O
that	O
it	O
can	O
not	O
filter	O
out	O
and	O
conflicting	O
or	O
redundant	O
information	O
obtained	O
from	O
different	O
modalities	O
.	O
	
To	O
address	O
this	O
major	O
issue	O
,	O
we	O
devise	O
an	O
hierarchical	B-Method
approach	I-Method
which	O
proceeds	O
from	O
unimodal	O
to	O
bimodal	O
vectors	O
and	O
then	O
bimodal	O
to	O
trimodal	O
vectors	O
.	O
	
paragraph	O
:	O
Bimodal	B-Method
fusion	I-Method
	
We	O
fuse	O
the	O
utterance	O
feature	O
vectors	O
for	O
each	O
bimodal	O
combination	O
,	O
i.e.	O
,	O
T	O
+	O
V	O
,	O
T	O
+	O
A	O
,	O
and	O
A	O
+	O
V.	O
This	O
step	O
is	O
depicted	O
in	O
fig	O
:	O
	
hfusion	B-Method
-	O
bimodal	O
and	O
discussed	O
in	O
details	O
in	O
sec	O
:	O
bimodal	O
.	O
	
We	O
use	O
the	O
penultimate	O
layer	O
for	O
fig	O
:	O
hfusion	B-Method
-	O
bimodal	O
as	O
bimodal	O
features	O
.	O
	
paragraph	O
:	O
Trimodal	B-Method
fusion	I-Method
	
We	O
fuse	O
the	O
three	O
bimodal	O
features	O
to	O
obtain	O
trimodal	O
feature	O
as	O
depicted	O
in	O
fig	O
:	O
hfusion	B-Method
-	O
trimodal	O
.	O
	
This	O
step	O
is	O
discussed	O
in	O
details	O
in	O
sec	O
:	O
trimodal	B-Method
.	O
	
paragraph	O
:	O
Addition	O
of	O
context	O
	
We	O
also	O
improve	O
the	O
quality	O
of	O
feature	O
vectors	O
(	O
both	O
unimodal	O
and	O
multimodal	O
)	O
by	O
incorporating	O
information	O
from	O
surrounding	O
utterances	O
using	O
RNN	B-Method
.	O
	
We	O
model	O
the	O
context	O
using	O
gated	B-Method
recurrent	I-Method
unit	I-Method
(	O
GRU	B-Method
)	O
as	O
depicted	O
in	O
fig	O
:	O
architecture	O
.	O
	
The	O
details	O
of	O
context	B-Method
modeling	I-Method
is	O
discussed	O
in	O
sec	O
:	O
context	O
and	O
the	O
following	O
subsections	O
.	O
	
paragraph	O
:	O
Classification	B-Task
	
We	O
classify	O
the	O
feature	O
vectors	O
using	O
a	O
softmax	B-Method
layer	I-Method
.	O
	
subsection	O
:	O
Unimodal	B-Task
Feature	I-Task
Extraction	I-Task
	
In	O
this	O
section	O
,	O
we	O
discuss	O
the	O
method	O
of	O
feature	B-Task
extraction	I-Task
for	O
three	O
different	O
modalities	O
:	O
audio	O
,	O
video	O
,	O
and	O
text	O
.	O
	
subsubsection	O
:	O
Textual	B-Method
Feature	I-Method
Extraction	I-Method
	
The	O
textual	O
data	O
is	O
obtained	O
from	O
the	O
transcripts	O
of	O
the	O
videos	O
.	O
	
We	O
apply	O
a	O
deep	B-Method
Convolutional	I-Method
Neural	I-Method
Networks	I-Method
(	O
CNN	B-Method
)	O
on	O
each	O
utterance	O
to	O
extract	O
textual	O
features	O
.	O
	
Each	O
utterance	O
in	O
the	O
text	O
is	O
represented	O
as	O
an	O
array	O
of	O
pre	O
-	O
trained	O
300	O
-	O
dimensional	O
word2vec	O
vectors	O
.	O
	
Further	O
,	O
the	O
utterances	O
are	O
truncated	O
or	O
padded	O
with	O
null	O
vectors	O
to	O
have	O
exactly	O
50	O
words	O
.	O
	
Next	O
,	O
these	O
utterances	O
as	O
array	O
of	O
vectors	O
are	O
passed	O
through	O
two	O
different	O
convolutional	B-Method
layers	I-Method
;	O
first	O
layer	O
having	O
two	O
filters	O
of	O
size	O
3	O
and	O
4	O
respectively	O
with	O
50	O
feature	O
maps	O
each	O
and	O
the	O
second	O
layer	O
has	O
a	O
filter	B-Method
of	O
size	O
2	O
with	O
100	O
feature	O
maps	O
.	O
	
Each	O
convolutional	B-Method
layer	I-Method
is	O
followed	O
by	O
a	O
max	B-Method
-	I-Method
pooling	I-Method
layer	I-Method
with	O
window	O
.	O
	
The	O
output	O
of	O
the	O
second	O
max	B-Method
-	I-Method
pooling	I-Method
layer	I-Method
is	O
fed	O
to	O
a	O
fully	B-Method
-	I-Method
connected	I-Method
layer	I-Method
with	O
500	O
neurons	O
with	O
a	O
rectified	O
linear	O
unit	O
(	O
ReLU	B-Method
)	I-Method
activation	I-Method
,	O
followed	O
by	O
softmax	O
output	O
.	O
	
The	O
output	O
of	O
the	O
penultimate	B-Method
fully	I-Method
-	I-Method
connected	I-Method
layer	I-Method
is	O
used	O
as	O
the	O
textual	O
feature	O
.	O
	
The	O
translation	B-Method
of	I-Method
convolution	I-Method
filter	I-Method
over	O
makes	O
the	O
CNN	B-Method
learn	O
abstract	O
features	O
and	O
with	O
each	O
subsequent	O
layer	O
the	O
context	O
of	O
the	O
features	O
expands	O
further	O
.	O
	
subsubsection	B-Method
:	O
Audio	B-Method
Feature	I-Method
Extraction	I-Method
	
The	O
audio	B-Method
feature	I-Method
extraction	I-Method
process	I-Method
is	O
performed	O
at	O
30	O
Hz	O
frame	O
rate	O
with	O
100	O
ms	O
sliding	O
window	O
.	O
	
We	O
use	O
openSMILE	B-Method
,	O
which	O
is	O
capable	O
of	O
automatic	B-Task
pitch	I-Task
and	I-Task
voice	I-Task
intensity	I-Task
extraction	I-Task
,	O
for	O
audio	B-Task
feature	I-Task
extraction	I-Task
.	O
	
Prior	O
to	O
feature	B-Task
extraction	I-Task
audio	I-Task
signals	I-Task
are	O
processed	O
with	O
voice	B-Method
intensity	I-Method
thresholding	I-Method
and	O
voice	B-Method
normalization	I-Method
.	O
	
Specifically	O
,	O
we	O
use	O
Z	B-Method
-	I-Method
standardization	I-Method
for	O
voice	B-Task
normalization	I-Task
.	O
	
In	O
order	O
to	O
filter	O
out	O
audio	O
segments	O
without	O
voice	O
,	O
we	O
threshold	O
voice	O
intensity	O
.	O
	
OpenSMILE	B-Method
is	O
used	O
to	O
perform	O
both	O
these	O
steps	O
.	O
	
Using	O
openSMILE	B-Method
we	O
extract	O
several	O
Low	B-Method
Level	I-Method
Descriptors	I-Method
(	O
LLD	B-Method
)	O
(	O
e.g.	O
,	O
pitch	O
,	O
voice	O
intensity	O
)	O
and	O
various	O
statistical	B-Method
functionals	I-Method
of	O
them	O
(	O
e.g.	O
,	O
amplitude	B-Metric
mean	I-Metric
,	O
arithmetic	B-Metric
mean	I-Metric
,	O
root	B-Metric
quadratic	I-Metric
mean	I-Metric
,	O
standard	B-Metric
deviation	I-Metric
,	O
flatness	O
,	O
skewness	O
,	O
kurtosis	O
,	O
quartiles	O
,	O
inter	O
-	O
quartile	O
ranges	O
,	O
and	O
linear	O
regression	O
slope	O
)	O
.	O
	
“	O
	
IS13	O
-	O
ComParE	O
”	O
configuration	O
file	O
of	O
openSMILE	O
is	O
used	O
to	O
for	O
our	O
purposes	O
.	O
	
Finally	O
,	O
we	O
extracted	O
total	O
6392	O
features	O
from	O
each	O
input	O
audio	O
segment	O
.	O
	
subsubsection	O
:	O
Visual	B-Task
Feature	I-Task
Extraction	I-Task
	
To	O
extract	O
visual	O
features	O
,	O
we	O
focus	O
not	O
only	O
on	O
feature	B-Task
extraction	I-Task
from	O
each	O
video	O
frame	O
but	O
also	O
try	O
to	O
model	O
temporal	O
features	O
across	O
frames	O
.	O
	
To	O
achieve	O
this	O
,	O
we	O
use	O
3D	B-Method
-	I-Method
CNN	I-Method
on	O
the	O
video	O
.	O
	
3D	B-Method
-	I-Method
CNNs	I-Method
have	O
been	O
successful	O
in	O
the	O
past	O
,	O
specially	O
in	O
the	O
field	O
of	O
object	B-Task
classification	I-Task
on	O
3D	O
data	O
.	O
	
Its	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
such	O
tasks	O
motivates	O
its	O
use	O
in	O
this	O
paper	O
.	O
	
Let	O
the	O
video	O
be	O
called	O
,	O
where	O
represents	O
the	O
three	O
RGB	O
channels	O
of	O
an	O
image	O
and	O
denote	O
the	O
cardinality	O
,	O
height	O
,	O
and	O
width	O
of	O
the	O
frames	O
,	O
respectively	O
.	O
	
A	O
3D	B-Method
convolutional	I-Method
filter	I-Method
,	O
named	O
,	O
is	O
applied	O
to	O
this	O
video	O
,	O
where	O
,	O
similar	O
to	O
a	O
2D	B-Method
-	I-Method
CNN	I-Method
,	O
the	O
filter	O
translates	O
across	O
the	O
video	O
and	O
generates	O
the	O
convolution	O
output	O
.	O
	
Here	O
,	O
denote	O
number	O
of	O
feature	O
maps	O
,	O
depth	O
of	O
filter	O
,	O
height	O
of	O
filter	O
,	O
and	O
width	O
of	O
filter	O
,	O
respectively	O
.	O
	
Finally	O
,	O
we	O
apply	O
max	B-Method
-	I-Method
pooling	I-Method
operation	I-Method
to	O
the	O
,	O
which	O
selects	O
the	O
most	O
relevant	O
features	O
.	O
	
This	O
operation	O
is	O
applied	O
only	O
to	O
the	O
last	O
three	O
dimensions	O
of	O
.	O
	
This	O
is	O
followed	O
by	O
a	O
dense	B-Method
layer	I-Method
and	O
softmax	B-Method
computation	I-Method
.	O
	
The	O
activations	O
of	O
this	O
layer	O
is	O
used	O
as	O
the	O
overall	O
video	O
features	O
for	O
each	O
utterance	O
video	O
.	O
	
In	O
our	O
experiments	O
,	O
we	O
receive	O
the	O
best	O
results	O
with	O
filter	O
dimensions	O
and	O
.	O
	
Also	O
,	O
for	O
the	O
max	B-Task
-	I-Task
pooling	I-Task
,	O
we	O
set	O
the	O
window	O
size	O
as	O
and	O
the	O
succeeding	O
dense	O
layer	O
with	O
neurons	O
.	O
	
subsection	O
:	O
Context	B-Method
Modeling	I-Method
	
Utterances	O
in	O
the	O
videos	O
are	O
semantically	O
dependent	O
on	O
each	O
other	O
.	O
	
In	O
other	O
words	O
,	O
complete	O
meaning	O
of	O
an	O
utterance	O
may	O
be	O
determined	O
by	O
taking	O
preceding	O
utterances	O
into	O
consideration	O
.	O
	
We	O
call	O
this	O
the	O
context	O
of	O
an	O
utterance	O
.	O
	
Following	O
,	O
we	O
use	O
RNN	B-Method
,	O
specifically	O
GRU	B-Method
to	O
model	O
semantic	O
dependency	O
among	O
the	O
utterances	O
in	O
a	O
video	O
.	O
	
Let	O
the	O
following	O
items	O
represent	O
unimodal	O
features	O
:	O
where	O
maximum	O
number	O
of	O
utterances	O
in	O
a	O
video	O
.	O
	
We	O
pad	O
the	O
shorter	O
videos	O
with	O
dummy	O
utterances	O
represented	O
by	O
null	O
vectors	O
of	O
corresponding	O
length	O
.	O
	
For	O
each	O
modality	O
,	O
we	O
feed	O
the	O
unimodal	O
utterance	O
features	O
(	O
where	O
)	O
(	O
discussed	O
in	O
UFE	B-Method
)	O
of	O
a	O
video	O
to	O
with	O
output	O
size	O
,	O
which	O
is	O
defined	O
as	O
where	O
,	O
,	O
,	O
,	O
,	O
,	O
,	O
,	O
,	O
,	O
,	O
,	O
and	O
.	O
	
This	O
yields	O
hidden	O
outputs	O
as	O
context	O
-	O
aware	O
unimodal	O
features	O
for	O
each	O
modality	O
.	O
	
Hence	O
,	O
we	O
define	O
,	O
where	O
.	O
	
Thus	O
,	O
the	O
context	O
-	O
aware	O
multimodal	O
features	O
can	O
be	O
defined	O
as	O
	
subsection	O
:	O
Multimodal	B-Task
Fusion	I-Task
	
In	O
this	O
section	O
,	O
we	O
use	O
context	O
-	O
aware	O
unimodal	O
features	O
and	O
to	O
a	O
unified	O
feature	O
space	O
.	O
	
The	O
unimodal	O
features	O
may	O
have	O
different	O
dimensions	O
,	O
i.e.	O
,	O
.	O
	
Thus	O
,	O
we	O
map	O
them	O
to	O
the	O
same	O
dimension	O
,	O
say	O
(	O
we	O
obtained	O
best	O
results	O
with	O
)	O
,	O
using	O
fully	B-Method
-	I-Method
connected	I-Method
layer	I-Method
as	O
follows	O
:	O
where	O
,	O
,	O
,	O
,	O
,	O
and	O
.	O
	
We	O
can	O
represent	O
the	O
mapping	O
for	O
each	O
dimension	O
as	O
where	O
and	O
are	O
scalars	O
for	O
all	O
and	O
.	O
	
Also	O
,	O
in	O
the	O
rows	O
represent	O
the	O
utterances	O
and	O
the	O
columns	O
the	O
feature	O
values	O
.	O
	
We	O
can	O
see	O
these	O
values	O
as	O
more	O
abstract	O
feature	O
values	O
derived	O
from	O
fundamental	O
feature	O
values	O
(	O
which	O
are	O
the	O
components	O
of	O
,	O
,	O
and	O
)	O
.	O
	
For	O
example	O
,	O
an	O
abstract	O
feature	O
can	O
be	O
the	O
angriness	O
of	O
a	O
speaker	O
in	O
a	O
video	O
.	O
	
We	O
can	O
infer	O
the	O
degree	O
of	O
angriness	O
from	O
visual	O
features	O
(	O
;	O
facial	O
muscle	O
movements	O
)	O
,	O
acoustic	O
features	O
(	O
,	O
such	O
as	O
pitch	O
and	O
raised	O
voice	O
)	O
,	O
or	O
textual	O
features	O
(	O
,	O
such	O
as	O
the	O
language	O
and	O
choice	O
of	O
words	O
)	O
.	O
	
Therefore	O
,	O
the	O
degree	O
of	O
angriness	O
can	O
be	O
represented	O
by	O
,	O
where	O
is	O
,	O
,	O
or	O
,	O
is	O
some	O
fixed	O
integer	O
between	O
and	O
,	O
and	O
is	O
some	O
fixed	O
integer	O
between	O
and	O
.	O
	
Now	O
,	O
the	O
evaluation	O
of	O
abstract	O
feature	O
values	O
from	O
all	O
the	O
modalities	O
may	O
not	O
have	O
the	O
same	O
merit	O
or	O
may	O
even	O
contradict	O
each	O
other	O
.	O
	
Hence	O
,	O
we	O
need	O
the	O
network	O
to	O
make	O
comparison	O
among	O
the	O
feature	O
values	O
derived	O
from	O
different	O
modalities	O
to	O
make	O
a	O
more	O
refined	O
evaluation	O
of	O
the	O
degree	B-Metric
of	I-Metric
anger	I-Metric
.	O
	
To	O
this	O
end	O
,	O
we	O
take	O
each	O
bimodal	B-Method
combination	I-Method
(	O
which	O
are	O
audio	O
–	O
video	O
,	O
audio	O
–	O
text	O
,	O
and	O
video	O
–	O
text	O
)	O
at	O
a	O
time	O
and	O
compare	O
and	O
combine	O
each	O
of	O
their	O
respective	O
abstract	O
feature	O
values	O
(	O
i.e.	O
with	O
,	O
with	O
,	O
and	O
with	O
)	O
using	O
fully	B-Method
-	I-Method
connected	I-Method
layers	I-Method
as	O
follows	O
:	O
where	O
,	O
is	O
scalar	O
,	O
,	O
is	O
scalar	O
,	O
,	O
and	O
is	O
scalar	O
,	O
for	O
all	O
	
and	O
.	O
	
We	O
hypothesize	O
that	O
it	O
will	O
enable	O
the	O
network	O
to	O
compare	O
the	O
decisions	O
from	O
each	O
modality	O
against	O
the	O
others	O
and	O
help	O
achieve	O
a	O
better	O
fusion	O
of	O
modalities	O
.	O
	
paragraph	O
:	O
Bimodal	B-Method
fusion	I-Method
	
bimodal:1bimodal:3	B-Method
are	O
used	O
for	O
bimodal	B-Method
fusion	I-Method
.	O
	
The	O
bimodal	O
fused	O
features	O
for	O
video	O
–	O
audio	O
,	O
audio	O
–	O
text	O
,	O
video	O
–	O
text	O
are	O
defined	O
as	O
We	O
further	O
employ	O
(	O
sec	O
:	O
context	O
)	O
(	O
)	O
,	O
to	O
incorporate	O
contextual	O
information	O
among	O
the	O
utterances	O
in	O
a	O
video	O
with	O
where	O
,	O
,	O
and	O
are	O
context	O
-	O
aware	O
bimodal	O
features	O
represented	O
as	O
vectors	O
and	O
is	O
scalar	O
for	O
,	O
,	O
,	O
and	O
.	O
	
paragraph	O
:	O
Trimodal	B-Method
fusion	I-Method
	
We	O
combine	O
all	O
three	O
modalities	O
using	O
fully	B-Method
-	I-Method
connected	I-Method
layers	I-Method
as	O
follows	O
:	O
where	O
and	O
is	O
a	O
scalar	O
for	O
all	O
	
and	O
.	O
	
So	O
,	O
we	O
define	O
the	O
fused	O
features	O
as	O
where	O
,	O
is	O
scalar	O
for	O
and	O
.	O
	
Similarly	O
to	O
bimodal	B-Method
fusion	I-Method
(	O
sec	O
:	O
bimodal	B-Method
)	O
,	O
after	O
trimodal	B-Method
fusion	I-Method
we	O
pass	O
the	O
fused	O
features	O
through	O
to	O
incorporate	O
contextual	O
information	O
in	O
them	O
,	O
which	O
yields	O
where	O
,	O
is	O
scalar	O
for	O
,	O
,	O
,	O
and	O
is	O
the	O
context	O
-	O
aware	O
trimodal	O
feature	O
vector	O
.	O
	
subsection	O
:	O
Classification	B-Task
	
In	O
order	O
to	O
perform	O
classification	B-Task
,	O
we	O
feed	O
the	O
fused	O
features	O
(	O
where	O
and	O
)	O
to	O
a	O
softmax	B-Method
layer	I-Method
with	O
outputs	O
.	O
	
The	O
classifier	B-Method
can	O
be	O
described	O
as	O
follows	O
:	O
where	O
,	O
,	O
,	O
class	O
value	O
(	O
or	O
)	O
,	O
and	O
estimated	O
class	O
value	O
.	O
	
subsection	O
:	O
Training	O
	
We	O
employ	O
categorical	B-Metric
cross	I-Metric
-	I-Metric
entropy	I-Metric
as	O
loss	O
function	O
(	O
)	O
for	O
training	O
,	O
where	O
number	O
of	O
samples	O
,	O
index	O
of	O
a	O
sample	O
,	O
class	O
value	O
,	O
and	O
Adam	B-Method
is	O
used	O
as	O
optimizer	O
due	O
to	O
its	O
ability	O
to	O
adapt	O
learning	O
rate	O
for	O
each	O
parameter	O
individually	O
.	O
	
We	O
train	O
the	O
network	O
for	O
200	O
epochs	O
with	O
early	O
stopping	O
,	O
where	O
we	O
optimize	O
the	O
parameter	O
set	O
where	O
,	O
,	O
and	O
.	O
	
algorithm	O
summarizes	O
our	O
method	O
.	O
	
[	O
!	O
ht	O
]	O
{	O
algorithmic}	O
[	O
1	O
]	O
	
TrainAndTestModelU	O
,	O
V	O
=	O
train	O
set	O
,	O
V	O
=	O
test	O
set	O
feature	B-Method
extraction	I-Method
:	O
baseline	O
features	O
	
∈{A	O
,	O
V	O
,	O
T	O
}	O
=	O
	
⁢GRUm	O
(	O
fm	O
)	O
equalization	O
bimodal	B-Method
fusion	I-Method
∈{⁢VA	O
,	O
⁢AT	O
,	O
⁢VT	O
}	O
=	O
	
⁢GRUm	O
(	O
fm	O
)	O
fusion	O
=	O
⁢GRU⁢AVT	O
(	O
f⁢AVT	O
)	O
	
i:	O
[	O
1	O
,	O
N	O
]	O
softmax	B-Method
classification	I-Method
MapToSpacexz	I-Method
modality	I-Method
z	O
gz	O
BimodalFusiongz1	O
,	O
gz2	O
modality	O
z1	O
and	O
z2	O
,	O
where	O
≠z1z2	O
f⁢z1z2	O
TrimodalFusionfz1	O
,	O
	
fz2	O
,	O
fz3	O
modality	O
combination	O
z1	O
,	O
z2	O
,	O
and	O
z3	O
,	O
where	O
z1≠z2≠z3	O
f⁢z1z2z3	O
TestModelV	O
to	O
training	O
phase	O
,	O
V	O
is	O
passed	O
through	O
the	O
learnt	O
models	O
to	O
get	O
the	O
features	O
and	O
classification	O
outputs	O
.	O
	
mentions	O
the	O
trainable	O
parameters	O
(	O
θ	O
)	O
.	O
	
section	O
:	O
Experiments	O
	
subsection	O
:	O
Dataset	O
Details	O
	
Most	O
research	O
works	O
in	O
multimodal	B-Task
sentiment	I-Task
analysis	I-Task
are	O
performed	O
on	O
datasets	O
where	O
train	O
and	O
test	O
splits	O
may	O
share	O
certain	O
speakers	O
.	O
	
Since	O
,	O
each	O
individual	O
has	O
an	O
unique	O
way	O
of	O
expressing	O
emotions	O
and	O
sentiments	O
,	O
finding	O
generic	O
and	O
person	O
-	O
independent	O
features	O
for	O
sentiment	B-Task
analysis	I-Task
is	O
crucial	O
.	O
	
tab	O
:	O
dataset	O
shows	O
the	O
train	O
and	O
test	O
split	O
for	O
the	O
datasets	O
used	O
.	O
	
subsubsection	O
:	O
CMU	B-Material
-	I-Material
MOSI	I-Material
	
CMU	B-Material
-	I-Material
MOSI	I-Material
dataset	I-Material
is	O
rich	O
in	O
sentimental	O
expressions	O
,	O
where	O
89	O
people	O
review	O
various	O
topics	O
in	O
English	O
.	O
	
The	O
videos	O
are	O
segmented	O
into	O
utterances	O
where	O
each	O
utterance	O
is	O
annotated	O
with	O
scores	O
between	O
(	O
strongly	O
negative	O
)	O
and	O
(	O
strongly	O
positive	O
)	O
by	O
five	O
annotators	O
.	O
	
We	O
took	O
the	O
average	O
of	O
these	O
five	O
annotations	O
as	O
the	O
sentiment	O
polarity	O
and	O
considered	O
only	O
two	O
classes	O
(	O
positive	O
and	O
negative	O
)	O
.	O
	
Given	O
every	O
individual	O
’s	O
unique	O
way	O
of	O
expressing	O
sentiments	O
,	O
real	O
world	O
applications	O
should	O
be	O
able	O
to	O
model	O
generic	O
person	O
independent	O
features	O
and	O
be	O
robust	O
to	O
person	O
variance	O
.	O
	
To	O
this	O
end	O
,	O
we	O
perform	O
person	O
-	O
independent	O
experiments	O
to	O
emulate	O
unseen	O
conditions	O
.	O
	
Our	O
train	O
/	O
test	O
splits	O
of	O
the	O
dataset	O
are	O
completely	O
disjoint	O
with	O
respect	O
to	O
speakers	O
.	O
	
The	O
train	O
/	O
validation	O
set	O
consists	O
of	O
the	O
first	O
62	O
individuals	O
in	O
the	O
dataset	O
.	O
	
The	O
test	O
set	O
contains	O
opinionated	O
videos	O
by	O
rest	O
of	O
the	O
31	O
speakers	O
.	O
	
In	O
particular	O
,	O
1447	O
and	O
752	O
utterances	O
are	O
used	O
for	O
training	O
and	O
test	O
respectively	O
.	O
	
subsubsection	O
:	O
IEMOCAP	B-Material
	
IEMOCAP	B-Material
contains	O
two	O
way	O
conversations	O
among	O
ten	O
speakers	O
,	O
segmented	O
into	O
utterances	O
.	O
	
The	O
utterances	O
are	O
tagged	O
with	O
the	O
labels	O
anger	O
,	O
happiness	O
,	O
sadness	O
,	O
neutral	O
,	O
excitement	O
,	O
frustration	O
,	O
fear	O
,	O
surprise	O
,	O
and	O
other	O
.	O
	
We	O
consider	O
the	O
first	O
four	O
ones	O
to	O
compare	O
with	O
the	O
state	O
of	O
the	O
art	O
and	O
other	O
works	O
.	O
	
It	O
contains	O
1083	O
angry	O
,	O
1630	O
happy	O
,	O
1083	O
sad	O
,	O
and	O
1683	O
neutral	O
videos	O
.	O
	
Only	O
the	O
videos	O
by	O
the	O
first	O
eight	O
speakers	O
are	O
considered	O
for	O
training	O
.	O
	
subsection	O
:	O
Baselines	O
	
We	O
compare	O
our	O
method	O
with	O
the	O
following	O
strong	O
baselines	O
.	O
	
paragraph	O
:	O
Early	B-Task
fusion	I-Task
	
We	O
extract	O
unimodal	O
features	O
(	O
UFE	O
)	O
and	O
simply	O
concatenate	O
them	O
to	O
produce	O
multimodal	O
features	O
.	O
	
Followed	O
by	O
support	B-Method
vector	I-Method
machine	I-Method
(	O
SVM	B-Method
)	O
being	O
applied	O
on	O
this	O
feature	O
vector	O
for	O
the	O
final	O
sentiment	B-Task
classification	I-Task
.	O
	
paragraph	O
:	O
Method	O
from	O
	
We	O
have	O
implemented	O
and	O
compared	O
our	O
method	O
with	O
the	O
approach	O
proposed	O
by	O
.	O
	
In	O
their	O
approach	O
,	O
they	O
extracted	O
visual	O
features	O
using	O
CLM	B-Method
-	I-Method
Z	I-Method
,	O
audio	O
features	O
using	O
openSMILE	B-Method
,	O
and	O
textual	O
features	O
using	O
CNN	B-Method
.	O
	
MKL	B-Method
was	O
then	O
applied	O
to	O
the	O
features	O
obtained	O
from	O
concatenation	O
of	O
the	O
unimodal	O
features	O
.	O
	
However	O
,	O
they	O
did	O
not	O
conduct	O
speaker	O
independent	O
experiments	O
.	O
	
In	O
order	O
to	O
perform	O
a	O
fair	O
comparison	O
with	O
,	O
we	O
employ	O
our	O
fusion	B-Method
method	I-Method
on	O
the	O
features	O
extracted	O
by	O
.	O
	
paragraph	O
:	O
Method	O
from	O
	
We	O
have	O
compared	O
our	O
method	O
with	O
,	O
which	O
takes	O
advantage	O
of	O
contextual	O
information	O
obtained	O
from	O
the	O
surrounding	O
utterances	O
.	O
	
This	O
context	B-Method
modeling	I-Method
is	O
achieved	O
using	O
LSTM	B-Method
.	O
	
We	O
reran	O
the	O
experiments	O
of	O
without	O
using	O
SVM	B-Method
for	O
classification	B-Task
since	O
using	O
SVM	B-Method
with	I-Method
neural	I-Method
networks	I-Method
is	O
usually	O
discouraged	O
.	O
	
This	O
provides	O
a	O
fair	O
comparison	O
with	O
our	O
model	O
which	O
does	O
not	O
use	O
SVM	B-Method
.	O
	
paragraph	O
:	O
Method	O
from	O
	
In	O
,	O
they	O
proposed	O
a	O
trimodal	B-Method
fusion	I-Method
method	O
based	O
on	O
the	O
tensors	O
.	O
	
We	O
have	O
also	O
compared	O
our	O
method	O
with	O
their	O
.	O
	
In	O
particular	O
,	O
their	O
dataset	O
configuration	O
was	O
different	O
than	O
us	O
so	O
we	O
have	O
adapted	O
their	O
publicly	O
available	O
code	O
and	O
employed	O
that	O
on	O
our	O
dataset	O
.	O
	
subsection	O
:	O
Experimental	O
Setting	O
	
We	O
considered	O
two	O
variants	O
of	O
experimental	O
setup	O
while	O
evaluating	O
our	O
model	O
.	O
	
paragraph	O
:	O
HFusion	B-Method
	
In	O
this	O
setup	O
,	O
we	O
evaluated	O
hierarchical	B-Method
fusion	I-Method
without	O
context	O
-	O
aware	O
features	O
with	O
CMU	B-Material
-	I-Material
MOSI	I-Material
dataset	I-Material
.	O
	
We	O
removed	O
all	O
the	O
GRUs	O
from	O
the	O
model	O
described	O
in	O
sec	O
:	O
	
mul_fusion	B-Method
,	O
sec	O
:	O
context	O
forwarded	O
utterance	O
specific	O
features	O
directly	O
to	O
the	O
next	O
layer	O
.	O
	
This	O
setup	O
is	O
depicted	O
in	O
fig	O
:	O
hfusion	B-Method
-	O
trimodal	O
.	O
	
paragraph	O
:	O
CHFusion	B-Method
	
This	O
setup	O
is	O
exactly	O
as	O
the	O
model	O
described	O
in	O
sec	O
:	O
model	O
.	O
	
subsection	O
:	O
Results	O
and	O
Discussion	O
	
We	O
discuss	O
the	O
results	O
for	O
the	O
different	O
experimental	O
settings	O
discussed	O
in	O
sec	O
:	O
exp_set	O
.	O
	
subsubsection	O
:	O
Hierarchical	B-Method
Fusion	I-Method
(	O
HFusion	B-Method
)	O
	
The	O
results	O
of	O
our	O
experiments	O
are	O
presented	O
in	O
table	O
:	O
hfusion	B-Method
.	O
	
We	O
evaluated	O
this	O
setup	O
with	O
CMU	B-Material
-	I-Material
MOSI	I-Material
dataset	I-Material
(	O
sec	O
:	O
mosi	B-Material
)	O
and	O
two	O
feature	O
sets	O
:	O
the	O
feature	O
set	O
used	O
in	O
and	O
the	O
set	O
of	O
unimodal	O
features	O
discussed	O
in	O
UFE	B-Method
.	O
	
Our	O
model	O
outperformed	O
,	O
which	O
employed	O
MKL	B-Method
,	O
for	O
all	O
bimodal	O
and	O
trimodal	O
scenarios	O
by	O
a	O
margin	O
of	O
1–1.8	O
%	O
.	O
	
This	O
leads	O
us	O
to	O
present	O
two	O
observations	O
.	O
	
Firstly	O
,	O
the	O
features	O
used	O
in	O
are	O
inferior	O
to	O
the	O
features	O
extracted	O
in	O
our	O
approach	O
.	O
	
Second	O
,	O
our	O
hierarchical	B-Method
fusion	I-Method
method	I-Method
is	O
better	O
than	O
their	O
fusion	B-Method
method	I-Method
.	O
	
It	O
is	O
already	O
established	O
in	O
the	O
literature	O
that	O
multimodal	B-Method
analysis	I-Method
outperforms	O
unimodal	B-Method
analysis	I-Method
.	O
	
We	O
also	O
observe	O
the	O
same	O
trend	O
in	O
our	O
experiments	O
where	O
trimodal	B-Method
and	I-Method
bimodal	I-Method
classifiers	I-Method
outperform	O
unimodal	B-Method
classifiers	I-Method
.	O
	
The	O
textual	B-Method
modality	I-Method
performed	O
best	O
among	O
others	O
with	O
a	O
higher	O
unimodal	O
classification	O
accuracy	B-Metric
of	O
75	O
%	O
.	O
	
Although	O
other	O
modalities	O
contribute	O
to	O
improve	O
the	O
performance	O
of	O
multimodal	B-Method
classifiers	I-Method
,	O
that	O
contribution	O
is	O
little	O
in	O
compare	O
to	O
the	O
textual	O
modality	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
we	O
compared	O
our	O
model	O
with	O
early	B-Method
fusion	I-Method
(	O
early	B-Method
-	I-Method
fusion	I-Method
)	O
for	O
aforementioned	O
feature	O
sets	O
(	O
UFE	O
)	O
.	O
	
Our	O
fusion	B-Method
mechanism	I-Method
consistently	O
outperforms	O
early	B-Method
fusion	I-Method
for	O
all	O
combination	O
of	O
modalities	O
.	O
	
This	O
supports	O
our	O
hypothesis	O
that	O
our	O
hierarchical	B-Method
fusion	I-Method
method	I-Method
captures	O
the	O
inter	O
-	O
relation	O
among	O
the	O
modalities	O
and	O
produce	O
better	O
performance	O
vector	O
than	O
early	B-Method
fusion	I-Method
.	O
	
Text	O
is	O
the	O
strongest	O
individual	O
modality	O
,	O
and	O
we	O
observe	O
that	O
the	O
text	O
modality	O
paired	O
with	O
remaining	O
two	O
modalities	O
results	O
in	O
consistent	O
performance	O
improvement	O
.	O
	
Overall	O
,	O
the	O
results	O
give	O
a	O
strong	O
indication	O
that	O
the	O
comparison	O
among	O
the	O
abstract	O
feature	O
values	O
dampens	O
the	O
effect	O
of	O
less	O
important	O
modalities	O
,	O
which	O
was	O
our	O
hypothesis	O
.	O
	
For	O
example	O
,	O
we	O
can	O
notice	O
that	O
for	O
early	B-Method
fusion	I-Method
T	O
+	O
V	O
and	O
T	B-Method
+	I-Method
A	I-Method
both	O
yield	O
the	O
same	O
performance	O
.	O
	
However	O
,	O
with	O
our	O
method	O
text	O
with	O
video	O
performs	O
better	O
than	O
text	O
with	O
audio	O
,	O
which	O
is	O
more	O
aligned	O
with	O
our	O
expectations	O
,	O
since	O
facial	O
muscle	O
movements	O
usually	O
carry	O
more	O
emotional	O
nuances	O
than	O
voice	O
.	O
	
In	O
particular	O
,	O
we	O
observe	O
that	O
our	O
model	O
outperformed	O
all	O
the	O
strong	O
baselines	O
mentioned	O
above	O
.	O
	
The	O
method	O
by	O
is	O
only	O
able	O
to	O
fuse	O
using	O
concatenation	B-Method
.	O
	
Our	O
proposed	O
method	O
outperformed	O
their	O
approach	O
by	O
a	O
significant	O
margin	O
;	O
thanks	O
to	O
the	O
power	O
of	O
hierarchical	B-Method
fusion	I-Method
which	O
proves	O
the	O
capability	O
of	O
our	O
method	O
in	O
modeling	O
bimodal	B-Task
and	I-Task
trimodal	I-Task
correlations	I-Task
.	O
	
However	O
on	O
the	O
other	O
hand	O
,	O
the	O
method	O
by	O
is	O
capable	O
of	O
fusing	O
the	O
modalities	O
using	O
a	O
tensor	O
.	O
	
Interestingly	O
our	O
method	O
also	O
outperformed	O
them	O
and	O
we	O
think	O
the	O
reason	O
is	O
the	O
capability	O
of	O
bimodal	B-Method
fusion	I-Method
and	O
use	O
that	O
for	O
trimodal	B-Method
fusion	I-Method
.	O
	
Tensor	B-Method
fusion	I-Method
network	I-Method
is	O
incapable	O
to	O
learn	O
the	O
weights	O
of	O
the	O
bimodal	O
and	O
trimodal	O
correlations	O
in	O
the	O
fusion	B-Task
.	O
	
Tensor	B-Task
Fusion	I-Task
is	O
mathematically	O
formed	O
by	O
an	O
outer	B-Method
product	I-Method
,	O
it	O
has	O
no	O
learn	O
-	O
able	O
parameters	O
.	O
	
Wherein	O
our	O
method	O
learns	O
the	O
weights	O
automatically	O
using	O
a	O
neural	B-Method
network	I-Method
(	O
Equation	O
1	O
,	O
2	O
and	O
3	O
)	O
.	O
	
subsubsection	O
:	O
Context	B-Method
-	I-Method
Aware	I-Method
Hierarchical	I-Method
Fusion	I-Method
(	O
CHFusion	B-Method
)	O
	
The	O
results	O
of	O
this	O
experiment	O
are	O
shown	O
in	O
table	O
:	O
chfusion	B-Method
.	O
	
This	O
setting	O
fully	O
utilizes	O
the	O
model	O
described	O
in	O
sec	O
:	O
model	O
.	O
	
We	O
applied	O
this	O
experimental	O
setting	O
for	O
two	O
datasets	O
,	O
namely	O
CMU	B-Material
-	I-Material
MOSI	I-Material
	
(	O
sec	O
:	O
mosi	B-Material
)	O
and	O
IEMOCAP	B-Material
(	O
sec	O
:	O
iemocap	B-Material
)	O
.	O
	
We	O
used	O
the	O
feature	O
set	O
discussed	O
in	O
UFE	B-Method
,	O
which	O
was	O
also	O
used	O
by	O
.	O
	
As	O
expected	O
our	O
method	O
outperformed	O
the	O
simple	O
early	B-Method
fusion	I-Method
based	I-Method
fusion	I-Method
by	O
,	O
tensor	B-Method
fusion	I-Method
by	O
.	O
	
The	O
method	O
by	O
used	O
a	O
scheme	O
to	O
learn	O
contextual	O
features	O
from	O
the	O
surrounding	O
features	O
.	O
	
However	O
,	O
as	O
a	O
method	O
of	O
fusion	B-Task
they	O
adapted	O
simple	O
concatenation	O
based	O
fusion	B-Method
method	I-Method
by	O
.	O
	
As	O
discussed	O
in	O
Section	O
[	O
reference	O
]	O
,	O
we	O
employed	O
their	O
contextual	B-Method
feature	I-Method
extraction	I-Method
framework	I-Method
and	O
integrated	O
our	O
proposed	O
fusion	B-Method
method	I-Method
to	O
that	O
.	O
	
This	O
has	O
helped	O
us	O
to	O
outperform	O
by	O
significant	O
margin	O
thanks	O
to	O
the	O
hierarchical	B-Method
fusion	I-Method
(	O
HFusion	B-Method
)	O
.	O
	
paragraph	O
:	O
CMU	B-Material
-	I-Material
MOSI	I-Material
	
We	O
achieve	O
1–2	O
%	O
performance	O
improvement	O
over	O
the	O
state	O
of	O
the	O
art	O
for	O
all	O
the	O
modality	O
combinations	O
having	O
textual	B-Method
component	I-Method
.	O
	
For	O
A	O
+	O
V	O
modality	B-Task
combination	I-Task
we	O
achieve	O
better	O
but	O
similar	O
performance	O
to	O
the	O
state	O
of	O
the	O
art	O
.	O
	
We	O
suspect	O
that	O
it	O
is	O
due	O
to	O
both	O
audio	O
and	O
video	O
modality	O
being	O
significantly	O
less	O
informative	O
than	O
textual	O
modality	O
.	O
	
It	O
is	O
evident	O
from	O
the	O
unimodal	O
performance	O
where	O
we	O
observe	O
that	O
textual	O
modality	O
on	O
its	O
own	O
performs	O
around	O
21	O
%	O
better	O
than	O
both	O
audio	O
and	O
video	O
modality	O
.	O
	
Also	O
,	O
audio	O
and	O
video	O
modality	O
performs	O
close	O
to	O
majority	O
baseline	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
it	O
is	O
important	O
to	O
notice	O
that	O
with	O
all	O
modalities	O
combined	O
we	O
achieve	O
about	O
3.5	O
%	O
higher	O
accuracy	B-Metric
than	O
text	O
alone	O
.	O
	
For	O
example	O
,	O
consider	O
the	O
following	O
utterance	O
:	O
so	O
overall	O
new	O
moon	O
even	O
with	O
the	O
bigger	O
better	O
budgets	O
	
huh	O
it	O
was	O
still	O
too	O
long	O
.	O
	
The	O
speaker	O
discusses	O
her	O
opinion	O
on	O
the	O
movie	O
Twilight	O
New	O
Moon	O
.	O
	
Textually	O
the	O
utterance	O
is	O
abundant	O
with	O
positive	O
words	O
however	O
audio	O
and	O
video	O
comprises	O
of	O
a	O
frown	O
which	O
is	O
observed	O
by	O
the	O
hierarchical	B-Method
fusion	I-Method
based	O
model	O
.	O
	
paragraph	O
:	O
IEMOCAP	B-Material
	
As	O
the	O
IEMOCAP	B-Material
dataset	I-Material
contains	O
four	O
distinct	O
emotion	O
categories	O
,	O
in	O
the	O
last	O
layer	O
of	O
the	O
network	O
we	O
used	O
a	O
softmax	B-Method
classifier	I-Method
whose	O
output	O
dimension	O
is	O
set	O
to	O
4	O
.	O
	
In	O
order	O
to	O
perform	O
classification	B-Task
on	O
IEMOCAP	B-Material
dataset	I-Material
we	O
feed	O
the	O
fused	O
features	O
(	O
where	O
and	O
)	O
to	O
a	O
softmax	B-Method
layer	I-Method
with	O
outputs	O
.	O
	
The	O
classifier	B-Method
can	O
be	O
described	O
as	O
follows	O
:	O
where	O
,	O
,	O
,	O
class	O
value	O
(	O
or	O
or	O
or	O
)	O
,	O
and	O
estimated	O
class	O
value	O
.	O
	
Here	O
as	O
well	O
,	O
we	O
achieve	O
performance	O
improvement	O
consistent	O
with	O
CMU	B-Material
-	I-Material
MOSI	I-Material
.	O
	
This	O
method	O
performs	O
1–2.4	O
%	O
better	O
than	O
the	O
state	O
of	O
the	O
art	O
for	O
all	O
the	O
modality	O
combinations	O
.	O
	
Also	O
,	O
trimodal	O
accuracy	B-Metric
is	O
3	O
%	O
higher	O
than	O
the	O
same	O
for	O
textual	O
modality	O
.	O
	
Since	O
,	O
IEMOCAP	B-Material
dataset	O
imbalanced	O
,	O
we	O
also	O
present	O
the	O
f	B-Metric
-	I-Metric
score	I-Metric
for	O
each	O
modality	O
combination	O
for	O
a	O
better	O
evaluation	O
.	O
	
One	O
key	O
observation	O
for	O
IEMOCAP	B-Material
dataset	I-Material
is	O
that	O
its	O
A	B-Method
+	I-Method
V	I-Method
modality	I-Method
combination	I-Method
performs	O
significantly	O
better	O
than	O
the	O
same	O
of	O
CMU	B-Material
-	I-Material
MOSI	I-Material
dataset	I-Material
.	O
	
We	O
think	O
that	O
this	O
is	O
due	O
to	O
the	O
audio	O
and	O
video	O
modality	O
of	O
IEMOCAP	B-Material
being	O
richer	O
than	O
the	O
same	O
of	O
CMU	B-Material
-	I-Material
MOSI	I-Material
.	O
	
The	O
performance	O
difference	O
with	O
another	O
strong	O
baseline	O
is	O
even	O
more	O
ranging	O
from	O
2.1	O
%	O
to	O
3	O
%	O
on	O
CMU	B-Material
-	I-Material
MOSI	I-Material
dataset	I-Material
and	O
2.2	O
%	O
to	O
5	O
%	O
on	O
IEMOCAP	B-Material
dataset	I-Material
.	O
	
This	O
again	O
confirms	O
the	O
superiority	O
of	O
the	O
hierarchical	B-Method
fusion	I-Method
in	O
compare	O
to	O
.	O
	
We	O
think	O
this	O
is	O
mainly	O
because	O
of	O
learning	O
the	O
weights	O
of	O
bimodal	O
and	O
trimodal	O
correlation	O
(	O
representing	O
the	O
degree	O
of	O
correlations	O
)	O
calculations	O
at	O
the	O
time	O
of	O
fusion	B-Task
while	O
Tensor	B-Method
Fusion	I-Method
Network	I-Method
(	O
TFN	B-Method
)	O
just	O
relies	O
on	O
the	O
non	O
-	O
trainable	O
outer	B-Method
product	I-Method
of	I-Method
tensors	I-Method
to	O
model	O
such	O
correlations	O
for	O
fusion	B-Task
.	O
	
Additionally	O
,	O
we	O
present	O
class	O
-	O
wise	O
accuracy	B-Metric
and	O
f	B-Metric
-	I-Metric
score	I-Metric
for	O
IEMOCAP	B-Material
for	O
trimodal	B-Task
(	O
A	O
+	O
V	O
+	O
T	O
)	O
scenario	O
in	O
table	O
:	O
iemocap	O
-	O
classwise	O
.	O
	
subsubsection	B-Method
:	O
HFusion	B-Method
vs.	O
CHFusion	B-Method
	
We	O
compare	O
HFusion	B-Method
and	O
CHFusion	B-Method
models	I-Method
over	O
CMU	B-Material
-	I-Material
MOSI	I-Material
dataset	I-Material
.	O
	
We	O
observe	O
that	O
CHFusion	B-Method
performs	O
1–2	O
%	O
better	O
than	O
HFusion	B-Method
model	I-Method
for	O
all	O
the	O
modality	O
combinations	O
.	O
	
This	O
performance	O
boost	O
is	O
achieved	O
by	O
the	O
inclusion	O
of	O
utterance	O
-	O
level	O
contextual	O
information	O
in	O
HFusion	B-Method
model	I-Method
by	O
adding	O
GRUs	B-Method
in	O
different	O
levels	O
of	O
fusion	O
hierarchy	O
.	O
	
section	O
:	O
Conclusion	O
	
Multimodal	O
fusion	B-Method
strategy	I-Method
is	O
an	O
important	O
issue	O
in	O
multimodal	B-Task
sentiment	I-Task
analysis	I-Task
.	O
	
However	O
,	O
little	O
work	O
has	O
been	O
done	O
so	O
far	O
in	O
this	O
direction	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
have	O
presented	O
a	O
novel	O
and	O
comprehensive	O
fusion	B-Method
strategy	I-Method
.	O
	
Our	O
method	O
outperforms	O
the	O
widely	O
used	O
early	B-Method
fusion	I-Method
on	O
both	O
datasets	O
typically	O
used	O
to	O
test	O
multimodal	B-Method
sentiment	I-Method
analysis	I-Method
methods	I-Method
.	O
	
Moreover	O
,	O
with	O
the	O
addition	O
of	O
context	B-Method
modeling	I-Method
with	O
GRU	B-Method
,	O
our	O
method	O
outperforms	O
the	O
state	O
of	O
the	O
art	O
in	O
multimodal	B-Task
sentiment	I-Task
analysis	I-Task
and	O
emotion	B-Task
detection	I-Task
by	O
significant	O
margin	O
.	O
	
In	O
our	O
future	O
work	O
,	O
we	O
plan	O
to	O
improve	O
the	O
quality	O
of	O
unimodal	O
features	O
,	O
especially	O
textual	O
features	O
,	O
which	O
will	O
further	O
improve	O
the	O
accuracy	B-Metric
of	O
classification	B-Task
.	O
	
We	O
will	O
also	O
experiment	O
with	O
more	O
sophisticated	O
network	B-Method
architectures	I-Method
.	O
	
section	O
:	O
Acknowledgement	O
	
The	O
work	O
was	O
partially	O
supported	O
by	O
the	O
Instituto	O
Politécnico	O
Nacional	O
via	O
grant	O
SIP	O
20172008	O
to	O
A.	O
Gelbukh	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Fast	O
and	O
Accurate	O
Deep	B-Method
Network	I-Method
Learning	I-Method
by	O
Exponential	B-Method
Linear	I-Method
Units	I-Method
(	O
ELUs	B-Method
)	O
	
We	O
introduce	O
the	O
“	O
exponential	B-Method
linear	I-Method
unit	I-Method
”	I-Method
(	O
ELU	B-Method
)	O
which	O
speeds	O
up	O
learning	B-Task
in	O
deep	B-Method
neural	I-Method
networks	I-Method
and	O
leads	O
to	O
higher	O
classification	B-Metric
accuracies	I-Metric
.	O
	
Like	O
rectified	B-Method
linear	I-Method
units	I-Method
(	O
ReLUs	B-Method
)	O
,	O
leaky	B-Method
ReLUs	I-Method
(	O
LReLUs	B-Method
)	O
and	O
parametrized	B-Method
ReLUs	I-Method
(	O
PReLUs	B-Method
)	O
,	O
ELUs	B-Method
alleviate	O
the	O
vanishing	B-Task
gradient	I-Task
problem	I-Task
via	O
the	O
identity	O
for	O
positive	O
values	O
.	O
	
However	O
ELUs	B-Method
have	O
improved	O
learning	B-Metric
characteristics	I-Metric
compared	O
to	O
the	O
units	O
with	O
other	O
activation	O
functions	O
.	O
	
In	O
contrast	O
to	O
ReLUs	B-Method
,	O
ELUs	B-Method
have	O
negative	O
values	O
which	O
allows	O
them	O
to	O
push	O
mean	O
unit	O
activations	O
closer	O
to	O
zero	O
like	O
batch	B-Method
normalization	I-Method
but	O
with	O
lower	O
computational	B-Metric
complexity	I-Metric
.	O
	
Mean	O
shifts	O
toward	O
zero	O
speed	O
up	O
learning	B-Task
by	O
bringing	O
the	O
normal	O
gradient	O
closer	O
to	O
the	O
unit	O
natural	O
gradient	O
because	O
of	O
a	O
reduced	O
bias	O
shift	O
effect	O
.	O
	
While	O
LReLUs	B-Method
and	O
PReLUs	B-Method
have	O
negative	O
values	O
,	O
too	O
,	O
they	O
do	O
not	O
ensure	O
a	O
noise	O
-	O
robust	O
deactivation	O
state	O
.	O
	
ELUs	B-Method
saturate	O
to	O
a	O
negative	O
value	O
with	O
smaller	O
inputs	O
and	O
thereby	O
decrease	O
the	O
forward	O
propagated	O
variation	O
and	O
information	O
.	O
	
Therefore	O
ELUs	B-Method
code	O
the	O
degree	O
of	O
presence	O
of	O
particular	O
phenomena	O
in	O
the	O
input	O
,	O
while	O
they	O
do	O
not	O
quantitatively	O
model	O
the	O
degree	O
of	O
their	O
absence	O
.	O
	
In	O
experiments	O
,	O
ELUs	B-Method
lead	O
not	O
only	O
to	O
faster	O
learning	B-Task
,	O
but	O
also	O
to	O
significantly	O
better	O
generalization	B-Metric
performance	I-Metric
than	O
ReLUs	B-Method
and	O
LReLUs	B-Method
on	O
networks	O
with	O
more	O
than	O
5	O
layers	O
.	O
	
On	O
CIFAR	B-Method
-	I-Method
100	I-Method
ELUs	I-Method
networks	I-Method
significantly	O
outperform	O
ReLU	B-Method
networks	O
with	O
batch	B-Method
normalization	I-Method
while	O
batch	B-Method
normalization	I-Method
does	O
not	O
improve	O
ELU	B-Method
networks	I-Method
.	O
	
ELU	B-Method
networks	I-Method
are	O
among	O
the	O
top	O
10	O
reported	O
CIFAR	B-Material
-	I-Material
10	I-Material
results	O
and	O
yield	O
the	O
best	O
published	O
result	O
on	O
CIFAR	B-Material
-	I-Material
100	I-Material
,	O
without	O
resorting	O
to	O
multi	B-Method
-	I-Method
view	I-Method
evaluation	I-Method
or	O
model	B-Method
averaging	I-Method
.	O
	
On	O
ImageNet	O
,	O
ELU	B-Method
networks	I-Method
considerably	O
speed	O
up	O
learning	B-Task
compared	O
to	O
a	O
ReLU	B-Method
network	O
with	O
the	O
same	O
architecture	O
,	O
obtaining	O
less	O
than	O
10	O
%	O
classification	B-Metric
error	I-Metric
for	O
a	O
single	O
crop	B-Method
,	I-Method
single	I-Method
model	I-Method
network	I-Method
.	O
	
section	O
:	O
Introduction	O
	
Currently	O
the	O
most	O
popular	O
activation	B-Method
function	I-Method
for	O
neural	B-Method
networks	I-Method
is	O
the	O
rectified	B-Method
linear	I-Method
unit	I-Method
(	O
ReLU	B-Method
)	O
,	O
which	O
was	O
first	O
proposed	O
for	O
restricted	B-Method
Boltzmann	I-Method
machines	I-Method
and	O
then	O
successfully	O
used	O
for	O
neural	B-Task
networks	I-Task
.	O
	
The	O
ReLU	B-Method
activation	O
function	O
is	O
the	O
identity	O
for	O
positive	O
arguments	O
and	O
zero	O
otherwise	O
.	O
	
Besides	O
producing	O
sparse	B-Method
codes	I-Method
,	O
the	O
main	O
advantage	O
of	O
ReLUs	B-Method
is	O
that	O
they	O
alleviate	O
the	O
vanishing	B-Task
gradient	I-Task
problem	I-Task
since	O
the	O
derivative	O
of	O
1	O
for	O
positive	O
values	O
is	O
not	O
contractive	O
.	O
	
However	O
ReLUs	O
are	O
non	O
-	O
negative	O
and	O
,	O
therefore	O
,	O
have	O
a	O
mean	O
activation	O
larger	O
than	O
zero	O
.	O
	
Units	O
that	O
have	O
a	O
non	O
-	O
zero	O
mean	O
activation	O
act	O
as	O
bias	O
for	O
the	O
next	O
layer	O
.	O
	
If	O
such	O
units	O
do	O
not	O
cancel	O
each	O
other	O
out	O
,	O
learning	O
causes	O
a	O
bias	O
shift	O
for	O
units	O
in	O
next	O
layer	O
.	O
	
The	O
more	O
the	O
units	O
are	O
correlated	O
,	O
the	O
higher	O
their	O
bias	O
shift	O
.	O
	
We	O
will	O
see	O
that	O
Fisher	B-Method
optimal	I-Method
learning	I-Method
,	O
i.e.	O
,	O
the	O
natural	O
gradient	O
,	O
would	O
correct	O
for	O
the	O
bias	O
shift	O
by	O
adjusting	O
the	O
weight	O
updates	O
.	O
	
Thus	O
,	O
less	O
bias	O
shift	O
brings	O
the	O
standard	O
gradient	O
closer	O
to	O
the	O
natural	O
gradient	O
and	O
speeds	O
up	O
learning	B-Task
.	O
	
We	O
aim	O
at	O
activation	O
functions	O
that	O
push	O
activation	O
means	O
closer	O
to	O
zero	O
to	O
decrease	O
the	O
bias	O
shift	O
effect	O
.	O
	
Centering	O
the	O
activations	O
at	O
zero	O
has	O
been	O
proposed	O
in	O
order	O
to	O
keep	O
the	O
off	O
-	O
diagonal	O
entries	O
of	O
the	O
Fisher	O
information	O
matrix	O
small	O
.	O
	
For	O
neural	B-Method
network	I-Method
it	O
is	O
known	O
that	O
centering	O
the	O
activations	O
speeds	O
up	O
learning	B-Task
.	O
	
“	O
	
Batch	B-Method
normalization	I-Method
”	O
also	O
centers	O
activations	O
with	O
the	O
goal	O
to	O
counter	O
the	O
internal	O
covariate	O
shift	O
.	O
	
Also	O
the	O
Projected	B-Method
Natural	I-Method
Gradient	I-Method
Descent	I-Method
algorithm	I-Method
(	O
PRONG	B-Method
)	O
centers	O
the	O
activations	O
by	O
implicitly	O
whitening	O
them	O
.	O
	
An	O
alternative	O
to	O
centering	O
is	O
to	O
push	O
the	O
mean	O
activation	O
toward	O
zero	O
by	O
an	O
appropriate	O
activation	B-Method
function	I-Method
.	O
	
Therefore	O
has	O
been	O
preferred	O
over	O
logistic	B-Method
functions	I-Method
.	O
	
Recently	O
“	O
Leaky	B-Method
ReLUs	I-Method
”	I-Method
(	O
LReLUs	B-Method
)	O
that	O
replace	O
the	O
negative	O
part	O
of	O
the	O
ReLU	B-Method
with	O
a	O
linear	O
function	O
have	O
been	O
shown	O
to	O
be	O
superior	O
to	O
ReLUs	B-Method
.	O
	
Parametric	B-Method
Rectified	I-Method
Linear	I-Method
Units	I-Method
(	O
PReLUs	B-Method
)	O
generalize	O
LReLUs	B-Method
by	O
learning	O
the	O
slope	O
of	O
the	O
negative	O
part	O
which	O
yielded	O
improved	O
learning	O
behavior	O
on	O
large	O
image	O
benchmark	O
data	O
sets	O
.	O
	
Another	O
variant	O
are	O
Randomized	B-Method
Leaky	I-Method
Rectified	I-Method
Linear	I-Method
Units	I-Method
(	O
RReLUs	B-Method
)	O
which	O
randomly	O
sample	O
the	O
slope	O
of	O
the	O
negative	O
part	O
which	O
raised	O
the	O
performance	O
on	O
image	O
benchmark	O
datasets	O
and	O
convolutional	B-Method
networks	I-Method
.	O
	
In	O
contrast	O
to	O
ReLUs	O
,	O
activation	O
functions	O
like	O
LReLUs	B-Method
,	O
PReLUs	O
,	O
and	O
	
RReLUs	B-Method
do	O
not	O
ensure	O
a	O
noise	O
-	O
robust	O
deactivation	O
state	O
.	O
	
We	O
propose	O
an	O
activation	B-Method
function	I-Method
that	O
has	O
negative	O
values	O
to	O
allow	O
for	O
mean	O
activations	O
close	O
to	O
zero	O
,	O
but	O
which	O
saturates	O
to	O
a	O
negative	O
value	O
with	O
smaller	O
arguments	O
.	O
	
The	O
saturation	O
decreases	O
the	O
variation	O
of	O
the	O
units	O
if	O
deactivated	O
,	O
so	O
the	O
precise	O
deactivation	O
argument	O
is	O
less	O
relevant	O
.	O
	
Such	O
an	O
activation	B-Method
function	I-Method
can	O
code	O
the	O
degree	O
of	O
presence	O
of	O
particular	O
phenomena	O
in	O
the	O
input	O
,	O
but	O
does	O
not	O
quantitatively	O
model	O
the	O
degree	O
of	O
their	O
absence	O
.	O
	
Therefore	O
,	O
such	O
an	O
activation	B-Method
function	I-Method
is	O
more	O
robust	O
to	O
noise	O
.	O
	
Consequently	O
,	O
dependencies	O
between	O
coding	O
units	O
are	O
much	O
easier	O
to	O
model	O
and	O
much	O
easier	O
to	O
interpret	O
since	O
only	O
activated	O
code	O
units	O
carry	O
much	O
information	O
.	O
	
Furthermore	O
,	O
distinct	O
concepts	O
are	O
much	O
less	O
likely	O
to	O
interfere	O
with	O
such	O
activation	O
functions	O
since	O
the	O
deactivation	O
state	O
is	O
non	O
-	O
informative	O
,	O
i.e.	O
variance	O
decreasing	O
.	O
	
section	O
:	O
Bias	B-Method
Shift	I-Method
Correction	I-Method
Speeds	O
Up	O
Learning	B-Task
	
To	O
derive	O
and	O
analyze	O
the	O
bias	O
shift	O
effect	O
mentioned	O
in	O
the	O
introduction	O
,	O
we	O
utilize	O
the	O
natural	O
gradient	O
.	O
	
The	O
natural	O
gradient	O
corrects	O
the	O
gradient	O
direction	O
with	O
the	O
inverse	O
Fisher	O
information	O
matrix	O
and	O
,	O
thereby	O
,	O
enables	O
Fisher	B-Method
optimal	I-Method
learning	I-Method
,	O
which	O
ensures	O
the	O
steepest	O
descent	O
in	O
the	O
Riemannian	O
parameter	O
manifold	O
and	O
Fisher	B-Metric
efficiency	I-Metric
for	O
online	B-Task
learning	I-Task
.	O
	
The	O
recently	O
introduced	O
Hessian	B-Method
-	I-Method
Free	I-Method
Optimization	I-Method
technique	I-Method
and	O
the	O
Krylov	B-Method
Subspace	I-Method
Descent	I-Method
methods	I-Method
use	O
an	O
extended	B-Method
Gauss	I-Method
-	I-Method
Newton	I-Method
approximation	I-Method
of	O
the	O
Hessian	O
,	O
therefore	O
they	O
can	O
be	O
interpreted	O
as	O
versions	O
of	O
natural	B-Method
gradient	I-Method
descent	I-Method
.	O
	
Since	O
for	O
neural	B-Method
networks	I-Method
the	O
Fisher	O
information	O
matrix	O
is	O
typically	O
too	O
expensive	O
to	O
compute	O
,	O
different	O
approximations	O
of	O
the	O
natural	O
gradient	O
have	O
been	O
proposed	O
.	O
	
Topmoumoute	B-Method
Online	I-Method
natural	I-Method
Gradient	I-Method
Algorithm	I-Method
(	O
TONGA	B-Method
)	O
uses	O
a	O
low	B-Method
-	I-Method
rank	I-Method
approximation	I-Method
of	I-Method
natural	I-Method
gradient	I-Method
descent	I-Method
.	O
	
FActorized	B-Method
Natural	I-Method
Gradient	I-Method
(	O
FANG	B-Method
)	O
estimates	O
the	O
natural	O
gradient	O
via	O
an	O
approximation	B-Method
of	I-Method
the	I-Method
Fisher	I-Method
information	I-Method
matrix	I-Method
by	O
a	O
Gaussian	B-Method
graphical	I-Method
model	I-Method
.	O
	
The	O
Fisher	O
information	O
matrix	O
can	O
be	O
approximated	O
by	O
a	O
block	B-Method
-	I-Method
diagonal	I-Method
matrix	I-Method
,	O
where	O
unit	O
or	O
quasi	O
-	O
diagonal	O
natural	O
gradients	O
are	O
used	O
.	O
	
Unit	O
natural	O
gradients	O
or	O
“	O
	
Unitwise	B-Method
Fisher	I-Method
’s	I-Method
scoring	I-Method
”	I-Method
are	O
based	O
on	O
natural	O
gradients	O
for	O
perceptrons	B-Method
.	O
	
We	O
will	O
base	O
our	O
analysis	O
on	O
the	O
unit	O
natural	O
gradient	O
.	O
	
We	O
assume	O
a	O
parameterized	B-Method
probabilistic	I-Method
model	I-Method
with	O
parameter	O
vector	O
and	O
data	O
.	O
	
The	O
training	O
data	O
are	O
with	O
,	O
where	O
is	O
the	O
input	O
for	O
example	O
and	O
is	O
its	O
label	O
.	O
	
is	O
the	O
loss	O
of	O
example	O
using	O
model	O
.	O
	
The	O
average	B-Metric
loss	I-Metric
on	O
the	O
training	O
data	O
is	O
the	O
empirical	O
risk	O
.	O
	
Gradient	B-Method
descent	I-Method
updates	O
the	O
weight	O
vector	O
by	O
where	O
is	O
the	O
learning	B-Metric
rate	I-Metric
.	O
	
The	O
natural	O
gradient	O
is	O
the	O
inverse	O
Fisher	O
information	O
matrix	O
multiplied	O
by	O
the	O
gradient	O
of	O
the	O
empirical	O
risk	O
:	O
.	O
	
For	O
a	O
multi	B-Method
-	I-Method
layer	I-Method
perceptron	I-Method
is	O
the	O
unit	O
activation	O
vector	O
and	O
is	O
the	O
bias	O
unit	O
activation	O
.	O
	
We	O
consider	O
the	O
ingoing	O
weights	O
to	O
unit	O
,	O
therefore	O
we	O
drop	O
the	O
index	O
:	O
for	O
the	O
weight	O
from	O
unit	O
to	O
unit	O
,	O
for	O
the	O
activation	O
,	O
and	O
for	O
the	O
bias	O
weight	O
of	O
unit	O
.	O
	
The	O
activation	B-Method
function	I-Method
maps	O
the	O
net	O
input	O
of	O
unit	O
to	O
its	O
activation	O
.	O
	
For	O
computing	O
the	O
Fisher	O
information	O
matrix	O
,	O
the	O
derivative	O
of	O
the	O
log	O
-	O
output	O
probability	O
is	O
required	O
.	O
	
Therefore	O
we	O
define	O
the	O
at	O
unit	O
as	O
,	O
which	O
can	O
be	O
computed	O
via	O
backpropagation	B-Method
,	O
but	O
using	O
the	O
log	O
-	O
output	O
probability	O
instead	O
of	O
the	O
conventional	O
loss	O
function	O
.	O
	
The	O
derivative	O
is	O
.	O
	
We	O
restrict	O
the	O
Fisher	O
information	O
matrix	O
to	O
weights	O
leading	O
to	O
unit	O
which	O
is	O
the	O
unit	O
Fisher	O
information	O
matrix	O
.	O
	
captures	O
only	O
the	O
interactions	O
of	O
weights	O
to	O
unit	O
.	O
	
Consequently	O
,	O
the	O
unit	O
natural	O
gradient	O
only	O
corrects	O
the	O
interactions	O
of	O
weights	O
to	O
unit	O
,	O
i.e.	O
considers	O
the	O
Riemannian	O
parameter	O
manifold	O
only	O
in	O
a	O
subspace	O
.	O
	
The	O
unit	O
Fisher	O
information	O
matrix	O
is	O
Weighting	O
the	O
activations	O
by	O
is	O
equivalent	O
to	O
adjusting	O
the	O
probability	O
of	O
drawing	O
inputs	O
.	O
	
Inputs	O
with	O
large	O
are	O
drawn	O
with	O
higher	O
probability	O
.	O
	
Since	O
,	O
we	O
can	O
define	O
a	O
distribution	O
:	O
Using	O
,	O
the	O
entries	O
of	O
can	O
be	O
expressed	O
as	O
second	O
moments	O
:	O
If	O
the	O
bias	O
unit	O
is	O
with	O
weight	O
then	O
the	O
weight	O
vector	O
can	O
be	O
divided	O
into	O
a	O
bias	O
part	O
and	O
the	O
rest	O
:	O
.	O
	
For	O
the	O
row	O
that	O
corresponds	O
to	O
the	O
bias	O
weight	O
,	O
we	O
have	O
:	O
	
The	O
next	O
Theorem	O
[	O
reference	O
]	O
gives	O
the	O
correction	O
of	O
the	O
standard	O
gradient	O
by	O
the	O
unit	O
natural	O
gradient	O
where	O
the	O
bias	O
weight	O
is	O
treated	O
separately	O
(	O
see	O
also	O
)	O
.	O
	
theorem	O
:	O
.	O
	
The	O
unit	O
natural	O
gradient	O
corrects	O
the	O
weight	O
update	O
(	O
⁢ΔwT	O
,	O
⁢Δw0	O
)	O
T	O
to	O
a	O
unit	O
i	O
by	O
following	O
affine	O
transformation	O
of	O
the	O
gradient	O
=	O
	
∇	O
(	O
wT	O
,	O
w0	O
)	O
TRemp	O
(	O
gT	O
,	O
g0	O
)	O
T	O
:	O
where	O
A=	O
[	O
⁢F	O
(	O
w	O
)]	O
⁢¬0	O
,	O
⁢¬0=⁢E⁢p	O
(	O
z	O
)(	O
δ2	O
)	O
E⁢q	O
(	O
z	O
)(	O
⁢aaT	O
)	O
is	O
the	O
unit	O
Fisher	O
information	O
matrix	O
without	O
row	O
0	O
and	O
	
column	O
0	O
corresponding	O
to	O
the	O
bias	O
weight	O
.	O
	
The	O
vector	O
=	O
b	O
[	O
⁢F	O
(	O
w	O
)]	O
0	O
is	O
the	O
zeroth	O
column	O
of	O
F	O
corresponding	O
to	O
the	O
bias	O
weight	O
,	O
and	O
the	O
positive	O
scalar	O
s	O
	
is	O
where	O
a	O
is	O
the	O
vector	O
of	O
activations	O
of	O
units	O
with	O
weights	O
to	O
unit	O
i	O
and	O
	
=	O
⁢q	O
(	O
z	O
)	O
⁢δ2	O
(	O
z	O
)	O
p	O
(	O
z	O
)	O
E⁢p	O
(	O
z	O
)-	O
1	O
(	O
δ2	O
)	O
.	O
	
proof	O
:	O
Proof	O
.	O
	
Multiplying	O
the	O
inverse	O
Fisher	O
matrix	O
with	O
the	O
separated	O
gradient	O
gives	O
the	O
weight	B-Method
update	I-Method
:	O
where	O
The	O
previous	O
formula	O
is	O
derived	O
in	O
Lemma	O
[	O
reference	O
]	O
in	O
the	O
appendix	O
.	O
	
Using	O
in	O
the	O
update	O
gives	O
The	O
right	O
hand	O
side	O
is	O
obtained	O
by	O
inserting	O
in	O
the	O
left	O
hand	O
side	O
update	O
.	O
	
Since	O
,	O
,	O
and	O
,	O
we	O
obtain	O
Applying	O
Lemma	O
[	O
reference	O
]	O
in	O
the	O
appendix	O
gives	O
the	O
formula	O
for	O
.	O
	
∎	O
	
The	O
bias	O
shift	O
(	O
mean	O
shift	O
)	O
of	O
unit	O
is	O
the	O
change	O
of	O
unit	O
’s	O
mean	O
value	O
due	O
to	O
the	O
weight	B-Method
update	I-Method
.	O
	
Bias	O
shifts	O
of	O
unit	O
lead	O
to	O
oscillations	O
and	O
impede	O
learning	B-Task
.	O
	
See	O
Section	O
4.4	O
in	O
for	O
demonstrating	O
this	O
effect	O
at	O
the	O
inputs	O
and	O
in	O
for	O
explaining	O
this	O
effect	O
using	O
the	O
input	O
covariance	O
matrix	O
.	O
	
Such	O
bias	O
shifts	O
are	O
mitigated	O
or	O
even	O
prevented	O
by	O
the	O
unit	O
natural	O
gradient	O
.	O
	
The	O
bias	B-Task
shift	I-Task
correction	I-Task
of	O
the	O
unit	O
natural	O
gradient	O
is	O
the	O
effect	O
on	O
the	O
bias	O
shift	O
due	O
to	O
which	O
captures	O
the	O
interaction	O
between	O
the	O
bias	O
unit	O
and	O
the	O
incoming	O
units	O
.	O
	
Without	O
bias	B-Method
shift	I-Method
correction	I-Method
,	O
i.e.	O
,	O
and	O
,	O
the	O
weight	O
updates	O
are	O
and	O
.	O
	
As	O
only	O
the	O
activations	O
depend	O
on	O
the	O
input	O
,	O
the	O
bias	O
shift	O
can	O
be	O
computed	O
by	O
multiplying	O
the	O
weight	O
update	O
by	O
the	O
mean	O
of	O
the	O
activation	O
vector	O
.	O
	
Thus	O
we	O
obtain	O
the	O
bias	O
shift	O
.	O
	
The	O
bias	O
shift	O
strongly	O
depends	O
on	O
the	O
correlation	O
of	O
the	O
incoming	O
units	O
which	O
is	O
captured	O
by	O
.	O
	
Next	O
,	O
Theorem	O
[	O
reference	O
]	O
states	O
that	O
the	O
bias	B-Method
shift	I-Method
correction	I-Method
by	O
the	O
unit	O
natural	O
gradient	O
can	O
be	O
considered	O
to	O
correct	O
the	O
incoming	O
mean	O
proportional	O
to	O
toward	O
zero	O
.	O
	
theorem	O
:	O
.	O
	
The	O
bias	O
shift	O
correction	O
by	O
the	O
unit	O
natural	O
gradient	O
is	O
equivalent	O
to	O
an	O
additive	B-Method
correction	I-Method
of	O
the	O
incoming	O
mean	O
by	O
-	O
⁢kE⁢q	O
(	O
z	O
)(	O
a	O
)	O
and	O
a	O
multiplicative	B-Method
correction	I-Method
of	O
the	O
bias	O
unit	O
by	O
k	O
,	O
where	O
	
proof	O
:	O
Proof	O
.	O
	
Using	O
,	O
the	O
bias	O
shift	O
is	O
:	O
The	O
mean	O
correction	O
term	O
,	O
indicated	O
by	O
an	O
underbrace	O
in	O
previous	O
formula	O
,	O
is	O
The	O
expression	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
for	O
follows	O
from	O
Lemma	O
[	O
reference	O
]	O
in	O
the	O
appendix	O
.	O
	
The	O
bias	O
unit	O
correction	O
term	O
is	O
.	O
	
∎	O
In	O
Theorem	O
[	O
reference	O
]	O
we	O
can	O
reformulate	O
.	O
	
Therefore	O
increases	O
with	O
the	O
length	O
of	O
for	O
given	O
variances	O
and	O
covariances	O
.	O
	
Consequently	O
the	O
bias	B-Task
shift	I-Task
correction	I-Task
through	O
the	O
unit	O
natural	O
gradient	O
is	O
governed	O
by	O
the	O
length	O
of	O
.	O
	
The	O
bias	B-Method
shift	I-Method
correction	I-Method
is	O
zero	O
for	O
since	O
does	O
not	O
correct	O
the	O
bias	O
unit	O
multiplicatively	O
.	O
	
Using	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
,	O
is	O
split	O
into	O
an	O
offset	O
and	O
an	O
information	O
containing	O
term	O
:	O
In	O
general	O
,	O
smaller	O
positive	O
⁢E⁢p	O
(	O
z	O
)(	O
a	O
)	O
lead	O
to	O
smaller	O
positive	O
⁢E⁢q	O
(	O
z	O
)(	O
a	O
)	O
,	O
therefore	O
to	O
smaller	O
corrections	O
.	O
	
The	O
reason	O
is	O
that	O
in	O
general	O
the	O
largest	O
absolute	O
components	O
of	O
are	O
positive	O
,	O
since	O
activated	O
inputs	O
will	O
activate	O
the	O
unit	O
which	O
in	O
turn	O
will	O
have	O
large	O
impact	O
on	O
the	O
output	O
.	O
	
To	O
summarize	O
,	O
the	O
unit	O
natural	O
gradient	O
corrects	O
the	O
bias	O
shift	O
of	O
unit	O
via	O
the	O
interactions	O
of	O
incoming	O
units	O
with	O
the	O
bias	O
unit	O
to	O
ensure	O
efficient	O
learning	B-Task
.	O
	
This	O
correction	O
is	O
equivalent	O
to	O
shifting	O
the	O
mean	O
activations	O
of	O
the	O
incoming	O
units	O
toward	O
zero	O
and	O
scaling	O
up	O
the	O
bias	O
unit	O
.	O
	
To	O
reduce	O
the	O
undesired	O
bias	O
shift	O
effect	O
without	O
the	O
natural	O
gradient	O
,	O
either	O
the	O
(	O
i	O
)	O
activation	O
of	O
incoming	O
units	O
can	O
be	O
centered	O
at	O
zero	O
or	O
(	O
ii	O
)	O
activation	O
functions	O
with	O
negative	O
values	O
can	O
be	O
used	O
.	O
	
We	O
introduce	O
a	O
new	O
activation	B-Method
function	I-Method
with	O
negative	O
values	O
while	O
keeping	O
the	O
identity	O
for	O
positive	O
arguments	O
where	O
it	O
is	O
not	O
contradicting	O
.	O
	
section	O
:	O
Exponential	B-Method
Linear	I-Method
Units	I-Method
(	O
ELUs	B-Method
)	O
	
The	O
exponential	B-Method
linear	I-Method
unit	I-Method
(	O
ELU	B-Method
)	O
with	O
is	O
The	O
ELU	B-Method
hyperparameter	O
controls	O
the	O
value	O
to	O
which	O
an	O
ELU	B-Method
saturates	O
for	O
negative	O
net	O
inputs	O
(	O
see	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
ELUs	B-Method
diminish	O
the	O
vanishing	O
gradient	O
effect	O
as	O
rectified	O
linear	O
units	O
(	O
ReLUs	B-Method
)	O
and	O
leaky	B-Method
ReLUs	I-Method
(	O
LReLUs	B-Method
)	O
do	O
.	O
	
The	O
vanishing	B-Task
gradient	I-Task
problem	I-Task
is	O
alleviated	O
because	O
the	O
positive	O
part	O
of	O
these	O
functions	O
is	O
the	O
identity	O
,	O
therefore	O
their	O
derivative	O
is	O
one	O
and	O
not	O
contractive	O
.	O
	
In	O
contrast	O
,	O
and	O
sigmoid	B-Method
activation	I-Method
functions	I-Method
are	O
contractive	O
almost	O
everywhere	O
.	O
	
In	O
contrast	O
to	O
ReLUs	O
,	O
ELUs	B-Method
have	O
negative	O
values	O
which	O
pushes	O
the	O
mean	O
of	O
the	O
activations	O
closer	O
to	O
zero	O
.	O
	
Mean	O
activations	O
that	O
are	O
closer	O
to	O
	
zero	O
enable	O
faster	O
learning	B-Task
as	O
they	O
bring	O
the	O
gradient	O
closer	O
to	O
the	O
natural	O
gradient	O
(	O
see	O
Theorem	O
[	O
reference	O
]	O
and	O
text	O
thereafter	O
)	O
.	O
	
ELUs	B-Method
saturate	O
to	O
a	O
negative	O
value	O
when	O
the	O
argument	O
gets	O
smaller	O
.	O
	
Saturation	O
means	O
a	O
small	O
derivative	O
which	O
decreases	O
the	O
variation	O
and	O
the	O
information	O
that	O
is	O
propagated	O
to	O
the	O
next	O
layer	O
.	O
	
Therefore	O
the	O
representation	O
is	O
both	O
noise	O
-	O
robust	O
and	O
low	O
-	O
complex	O
.	O
	
ELUs	B-Method
code	O
the	O
degree	O
of	O
presence	O
of	O
input	O
concepts	O
,	O
while	O
they	O
neither	O
quantify	O
the	O
degree	O
of	O
their	O
absence	O
nor	O
distinguish	O
the	O
causes	O
of	O
their	O
absence	O
.	O
	
This	O
property	O
of	O
non	O
-	O
informative	O
deactivation	O
states	O
is	O
also	O
present	O
at	O
ReLUs	B-Method
and	O
allowed	O
to	O
detect	O
biclusters	O
corresponding	O
to	O
biological	O
modules	O
in	O
gene	O
expression	O
datasets	O
and	O
to	O
identify	O
toxicophores	B-Task
in	I-Task
toxicity	I-Task
prediction	I-Task
.	O
	
The	O
enabling	O
features	O
for	O
these	O
interpretations	O
is	O
that	O
activation	B-Task
can	O
be	O
clearly	O
distinguished	O
from	O
deactivation	B-Method
and	O
that	O
only	O
active	O
units	O
carry	O
relevant	O
information	O
and	O
can	O
crosstalk	O
.	O
	
section	O
:	O
Experiments	O
Using	O
ELUs	B-Method
	
In	O
this	O
section	O
,	O
we	O
assess	O
the	O
performance	O
of	O
exponential	B-Method
linear	I-Method
units	I-Method
(	O
ELUs	B-Method
)	O
if	O
used	O
for	O
unsupervised	B-Task
and	O
supervised	B-Task
learning	I-Task
of	I-Task
deep	I-Task
autoencoders	I-Task
and	O
deep	B-Method
convolutional	I-Method
networks	I-Method
.	O
	
ELUs	B-Method
with	O
are	O
compared	O
to	O
(	O
i	O
)	O
Rectified	B-Method
Linear	I-Method
Units	I-Method
(	O
ReLUs	B-Method
)	O
with	O
activation	O
,	O
(	O
ii	O
)	O
Leaky	B-Method
ReLUs	I-Method
(	O
LReLUs	B-Method
)	O
with	O
activation	O
(	O
)	O
,	O
and	O
(	O
iii	O
)	O
Shifted	B-Method
ReLUs	I-Method
(	O
SReLUs	B-Method
)	O
with	O
activation	O
.	O
	
Comparisons	O
are	O
done	O
with	O
and	O
without	O
batch	B-Method
normalization	I-Method
.	O
	
The	O
following	O
benchmark	O
datasets	O
are	O
used	O
:	O
(	O
i	O
)	O
MNIST	O
(	O
gray	O
images	O
in	O
10	O
classes	O
,	O
60k	O
train	O
and	O
10k	O
test	O
)	O
,	O
(	O
ii	O
)	O
CIFAR	B-Material
-	I-Material
10	I-Material
(	O
color	O
images	O
in	O
10	O
classes	O
,	O
50k	O
train	O
and	O
10k	O
test	O
)	O
,	O
(	O
iii	O
)	O
CIFAR	B-Material
-	I-Material
100	I-Material
(	O
color	O
images	O
in	O
100	O
classes	O
,	O
50k	O
train	O
and	O
10k	O
test	O
)	O
,	O
and	O
(	O
iv	O
)	O
	
ImageNet	O
(	O
color	O
images	O
in	O
1	O
,	O
000	O
classes	O
,	O
1.3	O
M	O
train	O
and	O
100k	O
tests	O
)	O
.	O
	
subsection	O
:	O
MNIST	O
	
subsubsection	O
:	O
Learning	B-Task
Behavior	I-Task
	
We	O
first	O
want	O
to	O
verify	O
that	O
ELUs	B-Method
keep	O
the	O
mean	O
activations	O
closer	O
to	O
zero	O
than	O
other	O
units	O
.	O
	
Fully	B-Method
connected	I-Method
deep	I-Method
neural	I-Method
networks	I-Method
with	O
ELUs	B-Method
(	I-Method
)	I-Method
,	O
ReLUs	B-Method
,	O
and	O
LReLUs	B-Method
(	O
)	O
were	O
trained	O
on	O
the	O
MNIST	O
digit	O
classification	O
dataset	O
while	O
each	O
hidden	O
unit	O
’s	O
activation	O
was	O
tracked	O
.	O
	
Each	O
network	O
had	O
eight	O
hidden	O
layers	O
of	O
128	O
units	O
each	O
,	O
and	O
was	O
trained	O
for	O
300	O
epochs	O
by	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
with	O
learning	B-Method
rate	I-Method
and	O
mini	O
-	O
batches	O
of	O
size	O
64	O
.	O
	
The	O
weights	O
have	O
been	O
initialized	O
according	O
to	O
.	O
	
After	O
each	O
epoch	O
we	O
calculated	O
the	O
units	O
’	O
average	O
activations	O
on	O
a	O
fixed	O
subset	O
of	O
the	O
training	O
data	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
the	O
median	O
over	O
all	O
units	O
along	O
learning	O
.	O
	
ELUs	B-Method
stay	O
have	O
smaller	O
median	O
throughout	O
the	O
training	O
process	O
.	O
	
The	O
training	B-Metric
error	I-Metric
of	O
ELU	B-Method
networks	I-Method
decreases	O
much	O
more	O
rapidly	O
than	O
for	O
the	O
other	O
networks	O
.	O
	
Section	O
[	O
reference	O
]	O
in	O
the	O
appendix	O
compares	O
the	O
variance	O
of	O
median	O
activation	O
in	O
ReLU	B-Method
and	O
ELU	B-Method
networks	I-Method
.	O
	
The	O
median	O
varies	O
much	O
more	O
in	O
ReLU	B-Method
networks	O
.	O
	
This	O
indicates	O
that	O
ReLU	B-Method
networks	O
continuously	O
try	O
to	O
correct	O
the	O
bias	O
shift	O
introduced	O
by	O
previous	O
weight	O
updates	O
while	O
this	O
effect	O
is	O
much	O
less	O
prominent	O
in	O
ELU	B-Method
networks	I-Method
.	O
	
subsubsection	O
:	O
Autoencoder	B-Method
Learning	I-Method
	
To	O
evaluate	O
ELU	B-Method
networks	I-Method
at	O
unsupervised	B-Task
settings	O
,	O
we	O
followed	O
and	O
and	O
trained	O
a	O
deep	B-Method
autoencoder	I-Method
on	O
the	O
MNIST	O
dataset	O
.	O
	
The	O
encoder	B-Method
part	I-Method
consisted	O
of	O
four	O
fully	B-Method
connected	I-Method
hidden	I-Method
layers	I-Method
with	O
sizes	O
1000	O
,	O
500	O
,	O
250	O
and	O
30	O
,	O
respectively	O
.	O
	
The	O
decoder	O
part	O
was	O
symmetrical	O
to	O
the	O
encoder	O
.	O
	
For	O
learning	B-Task
we	O
applied	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
with	O
mini	O
-	O
batches	O
of	O
64	O
samples	O
for	O
500	O
epochs	O
using	O
the	O
fixed	O
learning	B-Metric
rates	I-Metric
(	O
)	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
,	O
that	O
ELUs	B-Method
outperform	O
the	O
competing	O
activation	B-Method
functions	I-Method
in	O
terms	O
of	O
training	B-Metric
/	I-Metric
test	I-Metric
set	I-Metric
reconstruction	I-Metric
error	I-Metric
for	O
all	O
learning	B-Metric
rates	I-Metric
.	O
	
As	O
already	O
noted	O
by	O
,	O
higher	O
learning	B-Metric
rates	I-Metric
seem	O
to	O
perform	O
better	O
.	O
	
subsection	O
:	O
Comparison	O
of	O
Activation	B-Method
Functions	I-Method
	
In	O
this	O
subsection	O
we	O
show	O
that	O
ELUs	B-Method
indeed	O
possess	O
a	O
superior	O
learning	B-Metric
behavior	I-Metric
compared	O
to	O
other	O
activation	B-Method
functions	I-Method
as	O
postulated	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Furthermore	O
we	O
show	O
that	O
ELU	B-Method
networks	I-Method
perform	O
better	O
than	O
ReLU	B-Method
networks	O
with	O
batch	B-Method
normalization	I-Method
.	O
	
We	O
use	O
as	O
benchmark	O
dataset	O
CIFAR	B-Material
-	I-Material
100	I-Material
and	O
use	O
a	O
relatively	O
simple	O
convolutional	B-Method
neural	I-Method
network	I-Method
(	O
CNN	B-Method
)	O
architecture	O
to	O
keep	O
the	O
computational	B-Metric
complexity	I-Metric
reasonable	O
for	O
comparisons	O
.	O
	
[	O
-	O
2.0ex	O
]	O
	
[	O
-	O
2.0ex	O
]	O
	
[	O
-	O
2.0ex	O
]	O
The	O
CNN	B-Method
for	O
these	O
CIFAR	B-Material
-	I-Material
100	I-Material
experiments	O
consists	O
of	O
11	O
convolutional	B-Method
layers	I-Method
arranged	O
in	O
stacks	O
of	O
(	O
)	O
layers	O
units	O
receptive	O
fields	O
.	O
	
2	O
2	O
max	B-Method
-	I-Method
pooling	I-Method
with	O
a	O
stride	O
of	O
2	O
was	O
applied	O
after	O
each	O
stack	O
.	O
	
For	O
network	B-Task
regularization	I-Task
we	O
used	O
the	O
following	O
drop	B-Metric
-	I-Metric
out	I-Metric
rate	I-Metric
for	O
the	O
last	O
layer	O
of	O
each	O
stack	O
(	O
)	O
.	O
	
The	O
-	O
weight	O
decay	O
regularization	O
term	O
was	O
set	O
to	O
.	O
	
The	O
following	O
learning	B-Metric
rate	I-Metric
schedule	I-Metric
was	O
applied	O
(	O
)	O
(	O
iterations	O
[	O
learning	O
rate	O
]	O
)	O
.	O
	
For	O
fair	O
comparisons	O
,	O
we	O
used	O
this	O
learning	B-Method
rate	I-Method
schedule	I-Method
for	O
all	O
networks	O
.	O
	
During	O
previous	O
experiments	O
,	O
this	O
schedule	O
was	O
optimized	O
for	O
ReLU	B-Method
networks	O
,	O
however	O
as	O
ELUs	B-Method
converge	O
faster	O
they	O
would	O
benefit	O
from	O
an	O
adjusted	O
schedule	O
.	O
	
The	O
momentum	B-Metric
term	I-Metric
learning	I-Metric
rate	I-Metric
was	O
fixed	O
to	O
0.9	O
.	O
	
The	O
dataset	O
was	O
preprocessed	O
as	O
described	O
in	O
with	O
global	B-Method
contrast	I-Method
normalization	I-Method
and	O
ZCA	B-Method
whitening	I-Method
.	O
	
Additionally	O
,	O
the	O
images	O
were	O
padded	O
with	O
four	O
zero	O
pixels	O
at	O
all	O
borders	O
.	O
	
The	O
model	O
was	O
trained	O
on	O
random	O
crops	O
with	O
random	O
horizontal	O
flipping	O
.	O
	
Besides	O
that	O
,	O
we	O
no	O
further	O
augmented	O
the	O
dataset	O
during	O
training	O
.	O
	
Each	O
network	O
was	O
run	O
10	O
times	O
with	O
different	O
weight	B-Method
initialization	I-Method
.	O
	
Across	O
networks	O
with	O
different	O
activation	O
functions	O
the	O
same	O
run	O
number	O
had	O
the	O
same	O
initial	O
weights	O
.	O
	
Mean	B-Metric
test	I-Metric
error	I-Metric
results	O
of	O
networks	O
with	O
different	O
activation	O
functions	O
are	O
compared	O
in	O
Fig	O
.	O
	
[	O
reference	O
]	O
,	O
which	O
also	O
shows	O
the	O
standard	O
deviation	O
.	O
	
ELUs	B-Method
yield	O
on	O
average	O
a	O
test	B-Metric
error	I-Metric
of	O
28.75	O
(	O
0.24	O
)	O
%	O
,	O
while	O
SReLUs	O
,	O
ReLUs	O
and	O
LReLUs	B-Method
yield	O
29.35	O
(	O
0.29	O
)	O
%	O
,	O
31.56	O
(	O
0.37	O
)	O
%	O
and	O
30.59	O
(	O
0.29	O
)	O
%	O
,	O
respectively	O
.	O
	
ELUs	B-Method
achieve	O
both	O
lower	O
training	B-Metric
loss	I-Metric
and	O
lower	O
test	B-Metric
error	I-Metric
than	O
ReLUs	B-Method
,	O
LReLUs	B-Method
,	O
and	O
SReLUs	B-Method
.	O
	
Both	O
the	O
ELU	B-Method
training	I-Method
and	O
test	O
performance	O
is	O
significantly	O
better	O
than	O
for	O
other	O
activation	B-Method
functions	I-Method
(	O
Wilcoxon	O
signed	O
-	O
rank	O
test	O
with	O
-	O
value	O
0.001	O
)	O
.	O
	
Batch	B-Method
normalization	I-Method
improved	O
ReLU	B-Method
and	O
LReLU	B-Method
networks	I-Method
,	O
but	O
did	O
not	O
improve	O
ELU	B-Method
and	O
	
SReLU	B-Method
networks	I-Method
(	O
see	O
Fig	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
ELU	B-Method
networks	I-Method
significantly	O
outperform	O
ReLU	B-Method
networks	O
with	O
batch	B-Method
normalization	I-Method
(	O
Wilcoxon	B-Metric
signed	I-Metric
-	I-Metric
rank	I-Metric
test	I-Metric
with	O
-	O
value	O
0.001	O
)	O
.	O
	
subsection	O
:	O
Classification	B-Metric
Performance	I-Metric
on	O
CIFAR	B-Material
-	I-Material
100	I-Material
and	O
CIFAR	B-Material
-	I-Material
10	I-Material
	
The	O
following	O
experiments	O
should	O
highlight	O
the	O
generalization	B-Method
capabilities	I-Method
of	O
ELU	B-Method
networks	I-Method
.	O
	
The	O
CNN	B-Method
architecture	O
is	O
more	O
sophisticated	O
than	O
in	O
the	O
previous	O
subsection	O
and	O
consists	O
of	O
18	O
convolutional	B-Method
layers	I-Method
arranged	O
in	O
stacks	O
of	O
(	O
)	O
.	O
	
Initial	O
drop	B-Metric
-	I-Metric
out	I-Metric
rate	I-Metric
,	O
Max	B-Method
-	I-Method
pooling	I-Method
after	O
each	O
stack	O
,	O
-	O
weight	O
decay	O
,	O
momentum	O
term	O
,	O
data	B-Method
preprocessing	I-Method
,	O
padding	O
,	O
and	O
cropping	O
were	O
as	O
in	O
previous	O
section	O
.	O
	
The	O
initial	O
learning	B-Metric
rate	I-Metric
was	O
set	O
to	O
0.01	O
and	O
decreased	O
by	O
a	O
factor	O
of	O
10	O
after	O
35k	O
iterations	O
.	O
	
The	O
mini	O
-	O
batch	O
size	O
was	O
100	O
.	O
	
For	O
the	O
final	O
50k	O
iterations	O
fine	O
-	O
tuning	O
we	O
increased	O
the	O
drop	B-Metric
-	I-Metric
out	I-Metric
rate	I-Metric
for	O
all	O
layers	O
in	O
a	O
stack	O
to	O
(	O
)	O
,	O
thereafter	O
increased	O
the	O
drop	B-Metric
-	I-Metric
out	I-Metric
rate	I-Metric
by	O
a	O
factor	O
of	O
1.5	O
for	O
40k	O
additional	O
iterations	O
.	O
	
ELU	B-Method
networks	I-Method
are	O
compared	O
to	O
following	O
recent	O
successful	O
CNN	B-Method
architectures	O
:	O
AlexNet	B-Method
,	O
DSN	B-Method
,	O
NiN	B-Method
,	O
Maxout	B-Method
,	O
All	O
-	O
CNN	B-Method
,	O
Highway	B-Method
Network	I-Method
and	O
Fractional	B-Method
Max	I-Method
-	I-Method
Pooling	I-Method
.	O
	
The	O
test	B-Metric
error	I-Metric
in	O
percent	B-Metric
misclassification	I-Metric
are	O
given	O
in	O
Tab	O
.	O
	
[	O
reference	O
]	O
.	O
	
ELU	B-Method
-	I-Method
networks	I-Method
are	O
the	O
second	O
best	O
on	O
CIFAR	B-Material
-	I-Material
10	I-Material
with	O
a	O
test	B-Metric
error	I-Metric
of	O
6.55	O
%	O
but	O
still	O
they	O
are	O
among	O
the	O
top	O
10	O
best	O
results	O
reported	O
for	O
CIFAR	B-Material
-	I-Material
10	I-Material
.	O
	
ELU	B-Method
networks	I-Method
performed	O
best	O
on	O
CIFAR	B-Material
-	I-Material
100	I-Material
with	O
a	O
test	B-Metric
error	I-Metric
of	O
24.28	O
%	O
.	O
	
This	O
is	O
the	O
best	O
published	O
result	O
on	O
CIFAR	B-Material
-	I-Material
100	I-Material
,	O
without	O
even	O
resorting	O
to	O
multi	B-Method
-	I-Method
view	I-Method
evaluation	I-Method
or	O
model	B-Method
averaging	I-Method
.	O
	
subsection	O
:	O
ImageNet	O
Challenge	O
Dataset	O
	
Finally	O
,	O
we	O
evaluated	O
ELU	B-Method
-	I-Method
networks	I-Method
on	O
the	O
1000	O
-	O
class	O
ImageNet	O
dataset	O
.	O
	
It	O
contains	O
about	O
1.3	O
M	O
training	O
color	O
images	O
as	O
well	O
as	O
additional	O
50k	O
images	O
and	O
100k	O
images	O
for	O
validation	O
and	O
testing	O
,	O
respectively	O
.	O
	
For	O
this	O
task	O
,	O
we	O
designed	O
a	O
15	O
layer	O
CNN	B-Method
,	O
which	O
was	O
arranged	O
in	O
stacks	O
of	O
(	O
)	O
layers	O
units	O
receptive	O
fields	O
or	O
fully	B-Method
-	I-Method
connected	I-Method
(	O
FC	B-Method
)	O
.	O
	
2	O
2	O
max	B-Method
-	I-Method
pooling	I-Method
with	O
a	O
stride	O
of	O
2	O
was	O
applied	O
after	O
each	O
stack	O
and	O
spatial	B-Method
pyramid	I-Method
pooling	I-Method
(	O
SPP	B-Method
)	O
with	O
3	O
levels	O
before	O
the	O
first	O
FC	B-Method
layer	O
.	O
	
For	O
network	B-Task
regularization	I-Task
we	O
set	O
the	O
-	O
weight	O
decay	O
term	O
to	O
and	O
used	O
50	O
%	O
drop	O
-	O
out	O
in	O
the	O
two	O
penultimate	O
FC	B-Method
layers	O
.	O
	
Images	O
were	O
re	O
-	O
sized	O
to	O
256	O
256	O
pixels	O
and	O
per	O
-	O
pixel	O
mean	O
subtracted	O
.	O
	
Trained	O
was	O
on	O
random	O
crops	O
with	O
random	O
horizontal	O
flipping	O
.	O
	
Besides	O
that	O
,	O
we	O
did	O
not	O
augment	O
the	O
dataset	O
during	O
training	O
.	O
	
Fig	O
.	O
	
[	O
reference	O
]	O
shows	O
the	O
learning	O
behavior	O
of	O
ELU	B-Method
vs.	O
ReLU	B-Method
networks	O
.	O
	
Panel	O
(	O
b	O
)	O
shows	O
that	O
ELUs	B-Method
start	O
reducing	O
the	O
error	B-Metric
earlier	O
.	O
	
The	O
ELU	B-Method
-	I-Method
network	I-Method
already	O
reaches	O
the	O
20	O
%	O
top	B-Metric
-	I-Metric
5	I-Metric
error	I-Metric
after	O
160k	O
iterations	O
,	O
while	O
the	O
ReLU	B-Method
network	O
needs	O
200k	O
iterations	O
to	O
reach	O
the	O
same	O
error	B-Metric
rate	I-Metric
.	O
	
The	O
single	O
-	O
model	O
performance	O
was	O
evaluated	O
on	O
the	O
single	O
center	B-Task
crop	I-Task
with	O
no	O
further	O
augmentation	O
and	O
yielded	O
a	O
top	B-Metric
-	I-Metric
5	I-Metric
validation	I-Metric
error	I-Metric
below	O
10	O
%	O
.	O
	
Currently	O
ELU	B-Method
nets	I-Method
are	O
5	O
%	O
slower	O
on	O
ImageNet	B-Method
than	O
ReLU	B-Method
nets	O
.	O
	
The	O
difference	O
is	O
small	O
because	O
activation	O
functions	O
generally	O
have	O
only	O
minor	O
influence	O
on	O
the	O
overall	O
training	B-Metric
time	I-Metric
.	O
	
In	O
terms	O
of	O
wall	B-Metric
clock	I-Metric
time	I-Metric
,	O
ELUs	B-Method
require	O
12.15h	O
vs.	O
ReLUs	B-Method
with	O
11.48h	O
for	O
10k	O
iterations	O
.	O
	
We	O
expect	O
that	O
ELU	B-Method
implementations	I-Method
can	O
be	O
improved	O
,	O
e.g.	O
by	O
faster	O
exponential	B-Method
functions	I-Method
.	O
	
section	O
:	O
Conclusion	O
	
We	O
have	O
introduced	O
the	O
exponential	B-Method
linear	I-Method
units	I-Method
(	O
ELUs	B-Method
)	O
for	O
faster	O
and	O
more	O
precise	O
learning	B-Task
in	O
deep	B-Task
neural	I-Task
networks	I-Task
.	O
	
ELUs	B-Method
have	O
negative	O
values	O
,	O
which	O
allows	O
the	O
network	O
to	O
push	O
the	O
mean	O
activations	O
closer	O
to	O
zero	O
.	O
	
Therefore	O
ELUs	B-Method
decrease	O
the	O
gap	O
between	O
the	O
normal	O
gradient	O
and	O
the	O
unit	O
natural	O
gradient	O
and	O
,	O
thereby	O
speed	O
up	O
learning	B-Task
.	O
	
We	O
believe	O
that	O
this	O
property	O
is	O
also	O
the	O
reason	O
for	O
the	O
success	O
of	O
activation	O
functions	O
like	O
LReLUs	B-Method
and	O
PReLUs	B-Method
and	O
of	O
batch	B-Method
normalization	I-Method
.	O
	
In	O
contrast	O
to	O
LReLUs	B-Method
and	O
PReLUs	B-Method
,	O
ELUs	B-Method
have	O
a	O
clear	O
saturation	O
plateau	O
in	O
its	O
negative	O
regime	O
,	O
allowing	O
them	O
to	O
learn	O
a	O
more	O
robust	O
and	O
stable	O
representation	O
.	O
	
Experimental	O
results	O
show	O
that	O
ELUs	B-Method
significantly	O
outperform	O
other	O
activation	B-Method
functions	I-Method
on	O
different	O
vision	O
datasets	O
.	O
	
Further	O
ELU	B-Method
networks	I-Method
perform	O
significantly	O
better	O
than	O
ReLU	B-Method
networks	O
trained	O
with	O
batch	B-Method
normalization	I-Method
.	O
	
ELU	B-Method
networks	I-Method
achieved	O
one	O
of	O
the	O
top	O
10	O
best	O
reported	O
results	O
on	O
CIFAR	B-Material
-	I-Material
10	I-Material
and	O
set	O
a	O
new	O
state	O
of	O
the	O
art	O
in	O
CIFAR	B-Material
-	I-Material
100	I-Material
without	O
the	O
need	O
for	O
multi	B-Method
-	I-Method
view	I-Method
test	I-Method
evaluation	I-Method
or	O
model	B-Method
averaging	I-Method
.	O
	
Furthermore	O
,	O
ELU	B-Method
networks	I-Method
produced	O
competitive	O
results	O
on	O
the	O
ImageNet	O
in	O
much	O
fewer	O
epochs	O
than	O
a	O
corresponding	O
ReLU	B-Method
network	O
.	O
	
Given	O
their	O
outstanding	O
performance	O
,	O
we	O
expect	O
ELU	B-Method
networks	I-Method
to	O
become	O
a	O
real	O
time	O
saver	O
in	O
convolutional	B-Method
networks	I-Method
,	O
which	O
are	O
notably	O
time	O
-	O
intensive	O
to	O
train	O
from	O
scratch	O
otherwise	O
.	O
	
paragraph	O
:	O
Acknowledgment	O
.	O
	
We	O
thank	O
the	O
NVIDIA	O
Corporation	O
for	O
supporting	O
this	O
research	O
with	O
several	O
Titan	O
X	O
GPUs	O
and	O
Roland	O
Vollgraf	O
and	O
Martin	O
Heusel	O
for	O
helpful	O
discussions	O
and	O
comments	O
on	O
this	O
work	O
.	O
	
bibliography	O
:	O
References	O
	
appendix	O
:	O
Inverse	B-Method
of	I-Method
Block	I-Method
Matrices	I-Method
	
theorem	O
:	O
.	O
	
The	O
positive	O
definite	O
matrix	O
M	O
is	O
in	O
block	O
format	O
with	O
matrix	O
A	O
,	O
vector	O
b	O
,	O
and	O
scalar	O
c.	O
	
The	O
inverse	O
of	O
M	O
is	O
where	O
	
proof	O
:	O
Proof	O
.	O
	
For	O
block	O
matrices	O
the	O
inverse	O
is	O
where	O
the	O
matrices	O
on	O
the	O
right	O
hand	O
side	O
are	O
:	O
Further	O
if	O
follows	O
that	O
We	O
now	O
use	O
this	O
formula	O
for	O
being	O
a	O
vector	O
and	O
a	O
scalar	O
.	O
	
We	O
obtain	O
where	O
the	O
right	O
hand	O
side	O
matrices	O
,	O
vectors	O
,	O
and	O
the	O
scalar	O
are	O
:	O
	
Again	O
it	O
follows	O
that	O
A	O
reformulation	O
using	O
gives	O
∎	O
	
appendix	O
:	O
Quadratic	O
Form	O
of	O
Mean	O
and	O
Inverse	B-Method
Second	I-Method
Moment	I-Method
	
theorem	O
:	O
.	O
	
For	O
a	O
random	O
variable	O
a	O
holds	O
and	O
Furthermore	O
holds	O
	
proof	O
:	O
Proof	O
.	O
	
The	O
Sherman	B-Method
-	I-Method
Morrison	I-Method
Theorem	I-Method
states	O
	
Therefore	O
we	O
have	O
Using	O
the	O
identity	O
for	O
the	O
second	O
moment	O
and	O
	
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
	
,	O
we	O
get	O
The	O
last	O
inequality	O
follows	O
from	O
the	O
fact	O
that	O
is	O
positive	O
definite	O
.	O
	
From	O
last	O
equation	O
,	O
we	O
obtain	O
further	O
For	O
the	O
mixed	O
quadratic	O
form	O
we	O
get	O
from	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
	
From	O
this	O
equation	O
follows	O
Therefore	O
we	O
get	O
∎	O
	
appendix	O
:	O
Variance	O
of	O
Mean	O
Activations	O
in	O
ELU	B-Method
and	O
ReLU	B-Method
Networks	O
	
To	O
compare	O
the	O
variance	O
of	O
median	O
activation	O
in	O
ReLU	B-Method
and	O
ELU	B-Method
networks	I-Method
,	O
we	O
trained	O
a	O
neural	B-Method
network	I-Method
with	O
5	O
hidden	O
layers	O
of	O
256	O
hidden	O
units	O
for	O
200	O
epochs	O
using	O
a	O
learning	O
rate	O
of	O
0.01	O
,	O
once	O
using	O
ReLU	B-Method
and	O
once	O
using	O
ELU	B-Method
activation	I-Method
functions	I-Method
on	O
the	O
MNIST	O
dataset	O
.	O
	
After	O
each	O
epoch	O
,	O
we	O
calculated	O
the	O
median	O
activation	O
of	O
each	O
hidden	B-Method
unit	I-Method
on	O
the	O
whole	O
training	O
set	O
.	O
	
We	O
then	O
calculated	O
the	O
variance	O
of	O
these	O
changes	O
,	O
which	O
is	O
depicted	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
The	O
median	O
varies	O
much	O
more	O
in	O
ReLU	B-Method
networks	O
.	O
	
This	O
indicates	O
that	O
ReLU	B-Method
networks	O
continuously	O
try	O
to	O
correct	O
the	O
bias	O
shift	O
introduced	O
by	O
previous	O
weight	O
updates	O
while	O
this	O
effect	O
is	O
much	O
less	O
prominent	O
in	O
ELU	B-Method
networks	I-Method
.	O
	
document	O
:	O
Direct	B-Method
Output	I-Method
Connection	I-Method
for	O
a	O
High	B-Method
-	I-Method
Rank	I-Method
Language	I-Method
Model	I-Method
	
This	O
paper	O
proposes	O
a	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
recurrent	B-Method
neural	I-Method
network	I-Method
(	I-Method
RNN	I-Method
)	I-Method
language	I-Method
model	I-Method
that	O
combines	O
probability	O
distributions	O
computed	O
not	O
only	O
from	O
a	O
final	O
RNN	B-Method
layer	I-Method
but	O
also	O
from	O
middle	B-Method
layers	I-Method
.	O
	
Our	O
proposed	O
method	O
raises	O
the	O
expressive	O
power	O
of	O
a	O
language	B-Method
model	I-Method
based	O
on	O
the	O
matrix	O
factorization	O
interpretation	O
of	O
language	B-Task
modeling	I-Task
introduced	O
by	O
DBLP	O
:	O
journals	O
/	O
corr	O
/	O
abs	O
-	O
1711	O
-	O
03953	O
.	O
	
The	O
proposed	O
method	O
improves	O
the	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
language	B-Method
model	I-Method
and	O
achieves	O
the	O
best	O
score	O
on	O
the	O
Penn	B-Material
Treebank	I-Material
and	O
WikiText	B-Material
-	I-Material
2	I-Material
,	O
which	O
are	O
the	O
standard	O
benchmark	O
datasets	O
.	O
	
Moreover	O
,	O
we	O
indicate	O
our	O
proposed	O
method	O
contributes	O
to	O
two	O
application	O
tasks	O
:	O
machine	B-Task
translation	I-Task
and	O
headline	B-Task
generation	I-Task
.	O
	
Our	O
code	O
is	O
publicly	O
available	O
at	O
:	O
https:	O
//	O
github.com	O
/	O
nttcslab	O
-	O
nlp	O
/	O
doc_lmhttps:	O
//	O
github.com	O
/	O
nttcslab	O
-	O
nlp	O
/	O
doc_lm	O
.	O
	
section	O
:	O
Introduction	O
	
Neural	B-Method
network	I-Method
language	I-Method
models	I-Method
have	O
played	O
a	O
central	O
role	O
in	O
recent	O
natural	B-Task
language	I-Task
processing	I-Task
(	O
NLP	B-Task
)	O
advances	O
.	O
	
For	O
example	O
,	O
neural	B-Method
encoder	I-Method
-	I-Method
decoder	I-Method
models	I-Method
,	O
which	O
were	O
successfully	O
applied	O
to	O
various	O
natural	B-Task
language	I-Task
generation	I-Task
tasks	I-Task
including	O
machine	B-Task
translation	I-Task
,	O
summarization	B-Task
,	O
and	O
dialogue	B-Task
,	O
can	O
be	O
interpreted	O
as	O
conditional	B-Method
neural	I-Method
language	I-Method
models	I-Method
.	O
	
Neural	B-Method
language	I-Method
models	I-Method
also	O
positively	O
influence	O
syntactic	B-Task
parsing	I-Task
.	O
	
Moreover	O
,	O
such	O
word	B-Method
embedding	I-Method
methods	I-Method
as	O
Skip	B-Method
-	I-Method
gram	I-Method
and	O
vLBL	B-Method
originated	O
from	O
neural	B-Method
language	I-Method
models	I-Method
designed	O
to	O
handle	O
much	O
larger	O
vocabulary	O
and	O
data	O
sizes	O
.	O
	
Neural	B-Method
language	I-Method
models	I-Method
can	O
also	O
be	O
used	O
as	O
contextualized	B-Method
word	I-Method
representations	I-Method
.	O
	
Thus	O
,	O
language	B-Task
modeling	I-Task
is	O
a	O
good	O
benchmark	O
task	O
for	O
investigating	O
the	O
general	O
frameworks	O
of	O
neural	B-Method
methods	I-Method
in	O
NLP	B-Task
field	O
.	O
	
In	O
language	B-Task
modeling	I-Task
,	O
we	O
compute	O
joint	O
probability	O
using	O
the	O
product	O
of	O
conditional	O
probabilities	O
.	O
	
Let	O
be	O
a	O
word	O
sequence	O
with	O
length	O
:	O
.	O
	
We	O
obtain	O
the	O
joint	O
probability	O
of	O
word	O
sequence	O
as	O
follows	O
:	O
is	O
generally	O
assumed	O
to	O
be	O
in	O
this	O
literature	O
,	O
that	O
is	O
,	O
,	O
and	O
thus	O
we	O
can	O
ignore	O
its	O
calculation	O
.	O
	
See	O
the	O
implementation	O
of	O
DBLP	O
:	O
journals	O
/	O
corr	O
/	O
ZarembaSV14	O
,	O
for	O
an	O
example	O
.	O
	
RNN	B-Method
language	I-Method
models	I-Method
obtain	O
conditional	O
probability	O
from	O
the	O
probability	O
distribution	O
of	O
each	O
word	O
.	O
	
To	O
compute	O
the	O
probability	O
distribution	O
,	O
RNN	B-Method
language	I-Method
models	I-Method
encode	O
sequence	O
into	O
a	O
fixed	O
-	O
length	O
vector	O
and	O
apply	O
a	O
transformation	O
matrix	O
and	O
the	O
softmax	B-Method
function	I-Method
.	O
	
Previous	O
researches	O
demonstrated	O
that	O
RNN	B-Method
language	I-Method
models	I-Method
achieve	O
high	O
performance	O
by	O
using	O
several	O
regularizations	B-Method
and	O
selecting	O
appropriate	O
hyperparameters	O
.	O
	
However	O
,	O
DBLP	O
:	O
journals	O
/	O
corr	O
/	O
abs	O
-	O
1711	O
-	O
03953	O
proved	O
that	O
existing	O
RNN	B-Method
language	I-Method
models	I-Method
have	O
low	O
expressive	B-Metric
power	I-Metric
due	O
to	O
the	O
Softmax	O
bottleneck	O
,	O
which	O
means	O
the	O
output	O
matrix	O
of	O
RNN	B-Method
language	I-Method
models	I-Method
is	O
low	O
rank	O
when	O
we	O
interpret	O
the	O
training	O
of	O
RNN	B-Method
language	I-Method
models	I-Method
as	O
a	O
matrix	B-Task
factorization	I-Task
problem	I-Task
.	O
	
To	O
solve	O
the	O
Softmax	B-Task
bottleneck	I-Task
,	O
DBLP	O
:	O
journals	O
/	O
corr	O
	
/	O
abs	O
-	O
1711	O
-	O
03953	O
proposed	O
Mixture	B-Method
of	I-Method
Softmaxes	I-Method
(	O
MoS	B-Method
)	O
,	O
which	O
increases	O
the	O
rank	O
of	O
the	O
matrix	O
by	O
combining	O
multiple	O
probability	O
distributions	O
computed	O
from	O
the	O
encoded	O
fixed	O
-	O
length	O
vector	O
.	O
	
In	O
this	O
study	O
,	O
we	O
propose	O
Direct	B-Method
Output	I-Method
Connection	I-Method
(	O
DOC	B-Method
)	O
as	O
a	O
generalization	B-Method
of	I-Method
MoS.	I-Method
For	O
stacked	B-Method
RNNs	I-Method
,	O
DOC	B-Method
computes	O
the	O
probability	O
distributions	O
from	O
the	O
middle	O
layers	O
including	O
input	O
embeddings	O
.	O
	
In	O
addition	O
to	O
raising	O
the	O
rank	O
,	O
the	O
proposed	O
method	O
helps	O
weaken	O
the	O
vanishing	B-Task
gradient	I-Task
problem	I-Task
in	O
backpropagation	B-Method
because	O
DOC	B-Method
provides	O
a	O
shortcut	O
connection	O
to	O
the	O
output	O
.	O
	
We	O
conduct	O
experiments	O
on	O
standard	O
benchmark	O
datasets	O
for	O
language	B-Task
modeling	I-Task
:	O
the	O
Penn	B-Material
Treebank	I-Material
and	O
WikiText	B-Material
-	I-Material
2	I-Material
.	O
	
Our	O
experiments	O
demonstrate	O
that	O
DOC	B-Method
outperforms	O
MoS	B-Method
and	O
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
perplexities	B-Metric
on	O
each	O
dataset	O
.	O
	
Moreover	O
,	O
we	O
investigate	O
the	O
effect	O
of	O
DOC	B-Method
on	O
two	O
applications	O
:	O
machine	B-Task
translation	I-Task
and	O
headline	B-Task
generation	I-Task
.	O
	
We	O
indicate	O
that	O
DOC	B-Method
can	O
improve	O
the	O
performance	O
of	O
an	O
encoder	B-Method
-	I-Method
decoder	I-Method
with	O
an	O
attention	B-Method
mechanism	I-Method
,	O
which	O
is	O
a	O
strong	O
baseline	O
for	O
such	O
applications	O
.	O
	
In	O
addition	O
,	O
we	O
conduct	O
an	O
experiment	O
on	O
the	O
Penn	B-Material
Treebank	I-Material
constituency	O
parsing	O
task	O
to	O
investigate	O
the	O
effectiveness	O
of	O
DOC	B-Method
.	O
	
section	O
:	O
RNN	B-Method
Language	I-Method
Model	I-Method
	
In	O
this	O
section	O
,	O
we	O
briefly	O
overview	O
RNN	B-Method
language	I-Method
models	I-Method
.	O
	
Let	O
be	O
the	O
vocabulary	O
size	O
and	O
let	O
be	O
the	O
probability	O
distribution	O
of	O
the	O
vocabulary	O
at	O
timestep	O
.	O
	
Moreover	O
,	O
let	O
be	O
the	O
dimension	O
of	O
the	O
hidden	O
state	O
of	O
the	O
-	O
th	O
RNN	B-Method
,	O
and	O
let	O
be	O
the	O
dimensions	O
of	O
the	O
embedding	O
vectors	O
.	O
	
Then	O
the	O
RNN	B-Method
language	I-Method
models	I-Method
predict	O
probability	B-Method
distribution	I-Method
by	O
the	O
following	O
equation	O
:	O
where	O
is	O
a	O
weight	O
matrix	O
,	O
is	O
a	O
word	B-Method
embedding	I-Method
matrix	I-Method
,	O
is	O
a	O
one	O
-	O
hot	O
vector	O
of	O
input	O
word	O
at	O
timestep	O
,	O
and	O
is	O
the	O
hidden	O
state	O
of	O
the	O
-	O
th	O
RNN	B-Method
at	O
timestep	O
.	O
	
We	O
define	O
at	O
timestep	O
as	O
a	O
zero	O
vector	O
:	O
.	O
	
Let	O
represent	O
an	O
abstract	O
function	O
of	O
an	O
RNN	B-Method
,	O
which	O
might	O
be	O
the	O
Elman	B-Method
network	I-Method
,	O
the	O
Long	B-Method
Short	I-Method
-	I-Method
Term	I-Method
Memory	I-Method
(	O
LSTM	B-Method
)	O
,	O
the	O
Recurrent	B-Method
Highway	I-Method
Network	I-Method
(	O
RHN	B-Method
)	I-Method
,	O
or	O
any	O
other	O
RNN	B-Method
variant	I-Method
.	O
	
In	O
this	O
research	O
,	O
we	O
stack	O
three	O
LSTM	B-Method
layers	O
based	O
on	O
merityRegOpt	O
because	O
they	O
achieved	O
high	O
performance	O
.	O
	
section	O
:	O
Language	B-Task
Modeling	I-Task
as	O
Matrix	B-Task
Factorization	I-Task
	
DBLP	O
:	O
	
journals	O
/	O
corr	O
/	O
abs	O
-	O
1711	O
-	O
03953	O
indicated	O
that	O
the	O
training	O
of	O
language	B-Method
models	I-Method
can	O
be	O
interpreted	O
as	O
a	O
matrix	B-Task
factorization	I-Task
problem	I-Task
.	O
	
In	O
this	O
section	O
,	O
we	O
briefly	O
introduce	O
their	O
description	O
.	O
	
Let	O
word	O
sequence	O
be	O
context	O
.	O
	
Then	O
we	O
can	O
regard	O
a	O
natural	O
language	O
as	O
a	O
finite	O
set	O
of	O
the	O
pairs	O
of	O
a	O
context	O
and	O
its	O
conditional	O
probability	O
distribution	O
:	O
,	O
where	O
is	O
the	O
number	O
of	O
possible	O
contexts	O
and	O
is	O
a	O
variable	O
representing	O
a	O
one	O
-	O
hot	O
vector	O
of	O
a	O
word	O
.	O
	
Here	O
,	O
we	O
consider	O
matrix	O
that	O
represents	O
the	O
true	O
log	O
probability	O
distributions	O
and	O
matrix	O
that	O
contains	O
the	O
hidden	O
states	O
of	O
the	O
final	O
RNN	B-Method
layer	I-Method
for	O
each	O
context	O
:	O
	
Then	O
we	O
obtain	O
set	O
of	O
matrices	O
,	O
where	O
is	O
an	O
all	O
-	O
ones	O
matrix	O
,	O
and	O
is	O
a	O
diagonal	O
matrix	O
.	O
	
contains	O
matrices	O
that	O
shifted	O
each	O
row	O
of	O
by	O
an	O
arbitrary	O
real	O
number	O
.	O
	
In	O
other	O
words	O
,	O
if	O
we	O
take	O
a	O
matrix	O
from	O
and	O
apply	O
the	O
softmax	B-Method
function	I-Method
to	O
each	O
of	O
its	O
rows	O
,	O
we	O
obtain	O
a	O
matrix	O
that	O
consists	O
of	O
true	O
probability	O
distributions	O
.	O
	
Therefore	O
,	O
for	O
some	O
,	O
training	O
RNN	B-Method
language	I-Method
models	I-Method
is	O
to	O
find	O
the	O
parameters	O
satisfying	O
the	O
following	O
equation	O
:	O
Equation	O
[	O
reference	O
]	O
indicates	O
that	O
training	O
RNN	B-Method
language	I-Method
models	I-Method
can	O
also	O
be	O
interpreted	O
as	O
a	O
matrix	B-Task
factorization	I-Task
problem	I-Task
.	O
	
In	O
most	O
cases	O
,	O
the	O
rank	O
of	O
matrix	O
is	O
because	O
is	O
smaller	O
than	O
and	O
in	O
common	O
RNN	B-Method
language	I-Method
models	I-Method
.	O
	
Thus	O
,	O
an	O
RNN	B-Method
language	I-Method
model	I-Method
can	O
not	O
express	O
true	O
distributions	O
if	O
is	O
much	O
smaller	O
than	O
.	O
	
DBLP	O
:	O
	
journals	O
/	O
corr	O
/	O
abs	O
-	O
1711	O
-	O
03953	O
also	O
argued	O
that	O
is	O
as	O
high	O
as	O
vocabulary	B-Metric
size	I-Metric
based	O
on	O
the	O
following	O
two	O
assumptions	O
:	O
Natural	O
language	O
is	O
highly	O
context	O
-	O
dependent	O
.	O
	
In	O
addition	O
,	O
since	O
we	O
can	O
imagine	O
many	O
kinds	O
of	O
contexts	O
,	O
it	O
is	O
difficult	O
to	O
assume	O
a	O
basis	O
that	O
represents	O
a	O
conditional	O
probability	O
distribution	O
for	O
any	O
contexts	O
.	O
	
In	O
other	O
words	O
,	O
compressing	B-Task
is	O
difficult	O
.	O
	
Since	O
we	O
also	O
have	O
many	O
kinds	O
of	O
semantic	O
meanings	O
,	O
it	O
is	O
difficult	O
to	O
assume	O
basic	O
meanings	O
that	O
can	O
create	O
all	O
other	O
semantic	O
meanings	O
by	O
such	O
simple	O
operations	O
as	O
addition	O
and	O
subtraction	O
;	O
compressing	B-Task
is	O
difficult	O
.	O
	
In	O
summary	O
,	O
DBLP	O
:	O
journals	O
/	O
corr	O
	
/	O
abs	O
-	O
1711	O
-	O
03953	O
indicated	O
that	O
is	O
much	O
smaller	O
than	O
because	O
its	O
scale	O
is	O
usually	O
and	O
vocabulary	O
size	O
is	O
at	O
least	O
.	O
	
section	O
:	O
Proposed	O
Method	O
:	O
Direct	B-Method
Output	I-Method
Connection	I-Method
	
To	O
construct	O
a	O
high	O
-	O
rank	O
matrix	O
,	O
DBLP	O
:	O
journals	O
/	O
corr	O
	
/	O
abs	O
-	O
1711	O
-	O
03953	O
proposed	O
Mixture	B-Method
of	I-Method
Softmaxes	I-Method
(	O
MoS	B-Method
)	O
.	O
	
MoS	B-Method
computes	O
multiple	O
probability	O
distributions	O
from	O
the	O
hidden	O
state	O
of	O
final	O
RNN	B-Method
layer	I-Method
and	O
regards	O
the	O
weighted	O
average	O
of	O
the	O
probability	B-Method
distributions	I-Method
as	O
the	O
final	O
distribution	O
.	O
	
In	O
this	O
study	O
,	O
we	O
propose	O
Direct	B-Method
Output	I-Method
Connection	I-Method
(	O
DOC	B-Method
)	O
,	O
which	O
is	O
a	O
generalization	B-Method
method	I-Method
of	O
MoS.	O
DOC	B-Method
computes	O
probability	O
distributions	O
from	O
the	O
middle	O
layers	O
in	O
addition	O
to	O
the	O
final	O
layer	O
.	O
	
In	O
other	O
words	O
,	O
DOC	B-Method
directly	O
connects	O
the	O
middle	O
layers	O
to	O
the	O
output	O
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
an	O
overview	O
of	O
DOC	B-Method
,	O
that	O
uses	O
the	O
middle	O
layers	O
(	O
including	O
word	O
embeddings	O
)	O
to	O
compute	O
the	O
probability	O
distributions	O
.	O
	
Figure	O
[	O
reference	O
]	O
computes	O
three	O
probability	O
distributions	O
from	O
all	O
the	O
layers	O
,	O
but	O
we	O
can	O
vary	O
the	O
number	O
of	O
probability	O
distributions	O
for	O
each	O
layer	O
and	O
select	O
some	O
layers	O
to	O
avoid	O
.	O
	
In	O
our	O
experiments	O
,	O
we	O
search	O
for	O
the	O
appropriate	O
number	O
of	O
probability	O
distributions	O
for	O
each	O
layer	O
.	O
	
Formally	O
,	O
instead	O
of	O
Equation	O
[	O
reference	O
]	O
	
,	O
DOC	B-Method
computes	O
the	O
output	O
probability	O
distribution	O
at	O
timestep	O
by	O
the	O
following	O
equation	O
:	O
where	O
is	O
a	O
weight	O
for	O
each	O
probability	O
distribution	O
,	O
is	O
a	O
vector	O
computed	O
from	O
each	O
hidden	O
state	O
,	O
and	O
is	O
a	O
weight	B-Method
matrix	I-Method
.	O
	
Thus	O
,	O
is	O
the	O
weighted	B-Method
average	I-Method
of	I-Method
probability	I-Method
distributions	I-Method
.	O
	
We	O
define	O
the	O
diagonal	O
matrix	O
whose	O
elements	O
are	O
weight	O
for	O
each	O
context	O
as	O
.	O
	
Then	O
we	O
obtain	O
matrix	O
:	O
where	O
is	O
a	O
matrix	O
whose	O
rows	O
are	O
vector	O
.	O
	
can	O
be	O
an	O
arbitrary	O
high	O
rank	O
because	O
the	O
righthand	O
side	O
of	O
Equation	O
[	O
reference	O
]	O
computes	O
not	O
only	O
the	O
matrix	B-Method
multiplication	I-Method
but	O
also	O
a	O
nonlinear	O
function	O
.	O
	
Therefore	O
,	O
an	O
RNN	B-Method
language	I-Method
model	I-Method
with	O
DOC	B-Method
can	O
output	O
a	O
distribution	O
matrix	O
whose	O
rank	O
is	O
identical	O
to	O
one	O
of	O
the	O
true	O
distributions	O
.	O
	
In	O
other	O
words	O
,	O
is	O
a	O
better	O
approximation	O
of	O
than	O
the	O
output	O
of	O
a	O
standard	O
RNN	B-Method
language	I-Method
model	I-Method
.	O
	
Next	O
we	O
describe	O
how	O
to	O
acquire	O
weight	O
and	O
vector	O
.	O
	
Let	O
be	O
a	O
vector	O
whose	O
elements	O
are	O
weight	O
.	O
	
Then	O
we	O
compute	O
from	O
the	O
hidden	O
state	O
of	O
the	O
final	O
RNN	B-Method
layer	I-Method
:	O
where	O
is	O
a	O
weight	O
matrix	O
.	O
	
We	O
next	O
compute	O
from	O
the	O
hidden	O
state	O
of	O
the	O
-	B-Method
th	I-Method
RNN	I-Method
layer	I-Method
:	O
where	O
is	O
a	O
weight	O
matrix	O
.	O
	
In	O
addition	O
,	O
let	O
be	O
the	O
number	O
of	O
from	O
.	O
	
Then	O
we	O
define	O
the	O
sum	O
of	O
for	O
all	O
as	O
	
;	O
that	O
is	O
,	O
.	O
	
In	O
short	O
,	O
DOC	B-Method
computes	O
probability	O
distributions	O
from	O
all	O
the	O
layers	O
,	O
including	O
the	O
input	O
embedding	O
(	O
)	O
.	O
	
For	O
,	O
DOC	B-Method
becomes	O
identical	O
to	O
MoS.	O
	
In	O
addition	O
to	O
increasing	O
the	O
rank	O
,	O
we	O
expect	O
that	O
DOC	B-Method
weakens	O
the	O
vanishing	B-Task
gradient	I-Task
problem	I-Task
during	O
backpropagation	B-Method
because	O
a	O
middle	B-Method
layer	I-Method
is	O
directly	O
connected	O
to	O
the	O
output	O
,	O
such	O
as	O
with	O
the	O
auxiliary	B-Method
classifiers	I-Method
described	O
in	O
43022	O
.	O
	
For	O
a	O
network	O
that	O
computes	O
the	O
weights	O
for	O
several	O
vectors	O
,	O
such	O
as	O
Equation	O
[	O
reference	O
]	O
,	O
DBLP	O
:	O
journals	O
/	O
corr	O
/	O
ShazeerMMDLHD17	O
indicated	O
that	O
it	O
often	O
converges	O
to	O
a	O
state	O
where	O
it	O
always	O
produces	O
large	O
weights	O
for	O
few	O
vectors	O
.	O
	
In	O
fact	O
,	O
we	O
observed	O
that	O
DOC	B-Method
tends	O
to	O
assign	O
large	O
weights	O
to	O
shallow	O
layers	O
.	O
	
To	O
prevent	O
this	O
phenomenon	O
,	O
we	O
compute	O
the	O
coefficient	O
of	O
variation	O
of	O
Equation	O
[	O
reference	O
]	O
in	O
each	O
mini	O
-	O
batch	O
as	O
a	O
regularization	B-Method
term	I-Method
following	O
DBLP	B-Method
:	O
journals	O
/	O
corr	O
/	O
ShazeerMMDLHD17	O
.	O
	
In	O
other	O
words	O
,	O
we	O
try	O
to	O
adjust	O
the	O
sum	O
of	O
the	O
weights	O
for	O
each	O
probability	O
distribution	O
with	O
identical	O
values	O
in	O
each	O
mini	O
-	O
batch	O
.	O
	
Formally	O
,	O
we	O
compute	O
the	O
following	O
equation	O
for	O
a	O
mini	B-Task
-	I-Task
batch	I-Task
consisting	O
of	O
:	O
where	O
functions	O
and	O
are	O
functions	O
that	O
respectively	O
return	O
an	O
input	O
’s	O
standard	O
deviation	O
and	O
its	O
average	O
.	O
	
In	O
the	O
training	O
step	O
,	O
we	O
add	O
multiplied	O
by	O
weight	O
coefficient	O
to	O
the	O
loss	O
function	O
.	O
	
section	O
:	O
Experiments	O
on	O
Language	B-Task
Modeling	I-Task
	
We	O
investigate	O
the	O
effect	O
of	O
DOC	B-Method
on	O
the	O
language	B-Task
modeling	I-Task
task	O
.	O
	
In	O
detail	O
,	O
we	O
conduct	O
word	B-Task
-	I-Task
level	I-Task
prediction	I-Task
experiments	O
and	O
show	O
that	O
DOC	B-Method
improves	O
the	O
performance	O
of	O
MoS	B-Method
,	O
which	O
only	O
uses	O
the	O
final	O
layer	O
to	O
compute	O
the	O
probability	O
distributions	O
.	O
	
Moreover	O
,	O
we	O
evaluate	O
various	O
combinations	O
of	O
layers	O
to	O
explore	O
which	O
combination	O
achieves	O
the	O
best	O
score	O
.	O
	
subsection	O
:	O
Datasets	O
	
We	O
used	O
the	O
Penn	B-Material
Treebank	I-Material
(	O
PTB	B-Material
)	O
and	O
WikiText	B-Material
-	I-Material
2	I-Material
datasets	O
,	O
which	O
are	O
the	O
standard	O
benchmark	O
datasets	O
for	O
the	O
word	O
-	O
level	O
language	B-Task
modeling	I-Task
task	O
.	O
	
DBLP	O
:	O
conf	O
/	O
interspeech	O
/	O
MikolovKBCK10	O
and	O
DBLP	O
:	O
	
journals	O
/	O
corr	O
	
/	O
MerityXBS16	O
respectively	O
published	O
preprocessed	B-Material
PTB	I-Material
and	O
WikiText	B-Material
-	I-Material
2	I-Material
datasets	O
.	O
	
Table	O
[	O
reference	O
]	O
describes	O
their	O
statistics	O
.	O
	
We	O
used	O
these	O
preprocessed	O
datasets	O
for	O
fair	O
comparisons	O
with	O
previous	O
studies	O
.	O
	
subsection	O
:	O
Hyperparameters	O
	
Our	O
implementation	O
is	O
based	O
on	O
the	O
averaged	B-Method
stochastic	I-Method
gradient	I-Method
descent	I-Method
Weight	I-Method
-	I-Method
Dropped	I-Method
LSTM	I-Method
(	O
AWD	B-Method
-	I-Method
LSTM	I-Method
)	O
proposed	O
by	O
merityRegOpt	O
.	O
	
AWD	B-Method
-	I-Method
LSTM	I-Method
consists	O
of	O
three	O
LSTMs	B-Method
with	O
various	O
regularizations	B-Method
.	O
	
For	O
the	O
hyperparameters	O
,	O
we	O
used	O
the	O
same	O
values	O
as	O
DBLP	O
:	O
	
journals	O
/	O
corr	O
/	O
abs	O
-	O
1711	O
-	O
03953	O
except	O
for	O
the	O
dropout	B-Metric
rate	I-Metric
for	O
vector	O
and	O
the	O
non	O
-	O
monotone	O
interval	O
.	O
	
Since	O
we	O
found	O
that	O
the	O
dropout	B-Metric
rate	I-Metric
for	O
vector	O
greatly	O
influences	O
in	O
Equation	O
[	O
reference	O
]	O
,	O
we	O
varied	O
it	O
from	O
to	O
with	O
intervals	O
.	O
	
We	O
selected	O
because	O
this	O
value	O
achieved	O
the	O
best	O
score	O
on	O
the	O
PTB	B-Material
validation	I-Material
dataset	I-Material
.	O
	
For	O
the	O
non	O
-	O
monotone	O
interval	O
,	O
we	O
adopted	O
the	O
same	O
value	O
as	O
fraternal	O
.	O
	
Table	O
[	O
reference	O
]	O
summarizes	O
the	O
hyperparameters	O
of	O
our	O
experiments	O
.	O
	
subsection	O
:	O
Results	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
perplexities	B-Metric
of	O
AWD	O
-	O
LSTM	B-Method
with	O
DOC	B-Method
on	O
the	O
PTB	B-Material
dataset	I-Material
.	O
	
Each	O
value	O
of	O
columns	O
represents	O
the	O
number	O
of	O
probability	O
distributions	O
from	O
hidden	O
state	O
.	O
	
To	O
find	O
the	O
best	O
combination	O
,	O
we	O
varied	O
the	O
number	O
of	O
probability	O
distributions	O
from	O
each	O
layer	O
by	O
fixing	O
their	O
total	O
to	O
20	O
:	O
.	O
	
Moreover	O
,	O
the	O
top	O
row	O
of	O
Table	O
[	O
reference	O
]	O
shows	O
the	O
perplexity	B-Metric
of	O
AWD	B-Method
-	I-Method
LSTM	I-Method
with	I-Method
MoS	I-Method
reported	O
in	O
DBLP	O
:	O
journals	O
/	O
corr	O
/	O
abs	O
-	O
1711	O
-	O
03953	O
for	O
comparison	O
.	O
	
Table	O
[	O
reference	O
]	O
indicates	O
that	O
language	B-Method
models	I-Method
using	O
middle	B-Method
layers	I-Method
outperformed	O
one	O
using	O
only	O
the	O
final	O
layer	O
.	O
	
In	O
addition	O
,	O
Table	O
[	O
reference	O
]	O
shows	O
that	O
increasing	O
the	O
distributions	O
from	O
the	O
final	O
layer	O
(	O
)	O
degraded	O
the	O
score	O
from	O
the	O
language	B-Method
model	I-Method
with	O
(	O
the	O
top	O
row	O
of	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
Thus	O
,	O
to	O
obtain	O
a	O
superior	O
language	B-Method
model	I-Method
,	O
we	O
should	O
not	O
increase	O
the	O
number	O
of	O
distributions	O
from	O
the	O
final	O
layer	O
;	O
we	O
should	O
instead	O
use	O
the	O
middle	O
layers	O
,	O
as	O
with	O
our	O
proposed	O
DOC	B-Method
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
that	O
the	O
setting	O
achieved	O
the	O
best	O
performance	O
and	O
the	O
other	O
settings	O
with	O
shallow	O
layers	O
have	O
a	O
little	O
effect	O
.	O
	
This	O
result	O
implies	O
that	O
we	O
need	O
some	O
layers	O
to	O
output	O
accurate	O
distributions	O
.	O
	
In	O
fact	O
,	O
most	O
previous	O
studies	O
adopted	O
two	O
LSTM	B-Method
layers	O
for	O
language	B-Task
modeling	I-Task
.	O
	
This	O
suggests	O
that	O
we	O
need	O
at	O
least	O
two	O
layers	O
to	O
obtain	O
high	O
-	O
quality	O
distributions	O
.	O
	
For	O
the	O
setting	O
,	O
we	O
explored	O
the	O
effect	O
of	O
in	O
.	O
	
Although	O
Table	O
[	O
reference	O
]	O
shows	O
that	O
achieved	O
the	O
best	O
perplexity	B-Metric
,	O
the	O
effect	O
is	O
not	O
consistent	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
coefficient	O
of	O
variation	O
of	O
Equation	O
[	O
reference	O
]	O
,	O
i.e.	O
,	O
in	O
the	O
PTB	B-Material
dataset	I-Material
.	O
	
This	O
table	O
demonstrates	O
that	O
the	O
coefficient	O
of	O
variation	O
decreases	O
with	O
growth	O
in	O
.	O
	
In	O
other	O
words	O
,	O
the	O
model	O
trained	O
with	O
a	O
large	O
assigns	O
balanced	O
weights	O
to	O
each	O
probability	O
distribution	O
.	O
	
These	O
results	O
indicate	O
that	O
it	O
is	O
not	O
always	O
necessary	O
to	O
equally	O
use	O
each	O
probability	O
distribution	O
,	O
but	O
we	O
can	O
acquire	O
a	O
better	O
model	O
in	O
some	O
.	O
	
Hereafter	O
,	O
we	O
refer	O
to	O
the	O
setting	O
that	O
achieved	O
the	O
best	O
score	O
(	O
)	O
as	O
AWD	B-Method
-	I-Method
LSTM	I-Method
-	I-Method
DOC	I-Method
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
ranks	O
of	O
matrices	O
containing	O
log	O
probability	O
distributions	O
from	O
each	O
method	O
.	O
	
In	O
other	O
words	O
,	O
Table	O
[	O
reference	O
]	O
describes	O
in	O
Equation	O
[	O
reference	O
]	O
for	O
each	O
method	O
.	O
	
As	O
shown	O
by	O
this	O
table	O
,	O
the	O
output	O
of	O
AWD	B-Method
-	I-Method
LSTM	I-Method
is	O
restricted	O
to	O
.	O
	
In	O
contrast	O
,	O
AWD	B-Method
-	I-Method
LSTM	I-Method
-	I-Method
MoS	I-Method
and	O
AWD	B-Method
-	I-Method
LSTM	I-Method
-	I-Method
DOC	I-Method
outputted	O
matrices	O
whose	O
ranks	O
equal	O
the	O
vocabulary	O
size	O
.	O
	
This	O
fact	O
indicates	O
that	O
DOC	B-Method
(	O
including	O
MoS	B-Method
)	O
can	O
output	O
the	O
same	O
matrix	O
as	O
the	O
true	O
distributions	O
in	O
view	O
of	O
a	O
rank	O
.	O
	
Figure	O
[	O
reference	O
]	O
illustrates	O
the	O
learning	O
curves	O
of	O
each	O
method	O
on	O
PTB	B-Material
.	O
	
This	O
figure	O
contains	O
the	O
validation	B-Metric
scores	I-Metric
of	O
AWD	B-Method
-	I-Method
LSTM	I-Method
,	O
AWD	B-Method
-	I-Method
LSTM	I-Method
-	I-Method
MoS	I-Method
,	O
and	O
AWD	B-Method
-	I-Method
LSTM	I-Method
-	I-Method
DOC	I-Method
at	O
each	O
training	O
epoch	O
.	O
	
We	O
trained	O
AWD	B-Method
-	I-Method
LSTM	I-Method
and	O
AWD	B-Method
-	I-Method
LSTM	I-Method
-	I-Method
MoS	I-Method
by	O
setting	O
the	O
non	O
-	O
monotone	O
interval	O
to	O
60	O
,	O
as	O
with	O
AWD	B-Method
-	I-Method
LSTM	I-Method
-	I-Method
DOC	I-Method
.	O
	
In	O
other	O
words	O
,	O
we	O
used	O
hyperparameters	O
identical	O
to	O
the	O
original	O
ones	O
to	O
train	O
AWD	B-Method
-	I-Method
LSTM	I-Method
and	O
AWD	B-Method
-	I-Method
LSTM	I-Method
-	I-Method
MoS	I-Method
,	O
except	O
for	O
the	O
non	O
-	O
monotone	O
interval	O
.	O
	
We	O
note	O
that	O
the	O
optimization	B-Method
method	I-Method
converts	O
the	O
ordinary	B-Method
stochastic	I-Method
gradient	I-Method
descent	I-Method
(	O
SGD	B-Method
)	O
into	O
the	O
averaged	O
SGD	B-Method
at	O
the	O
point	O
where	O
convergence	O
almost	O
occurs	O
.	O
	
In	O
Figure	O
[	O
reference	O
]	O
,	O
the	O
turning	O
point	O
is	O
the	O
epoch	O
when	O
each	O
method	O
drastically	O
decreases	O
the	O
perplexity	B-Metric
.	O
	
Figure	O
[	O
reference	O
]	O
shows	O
that	O
each	O
method	O
similarly	O
reduces	O
the	O
perplexity	B-Metric
at	O
the	O
beginning	O
.	O
	
AWD	B-Method
-	I-Method
LSTM	I-Method
and	O
AWD	B-Method
-	I-Method
LSTM	I-Method
-	I-Method
MoS	I-Method
were	O
slow	O
to	O
decrease	O
the	O
perplexity	B-Metric
from	O
50	O
epochs	O
.	O
	
In	O
contrast	O
,	O
AWD	B-Method
-	I-Method
LSTM	I-Method
-	I-Method
DOC	I-Method
constantly	O
decreased	O
the	O
perplexity	B-Metric
and	O
achieved	O
a	O
lower	O
value	O
than	O
the	O
other	O
methods	O
with	O
ordinary	O
SGD	B-Method
.	O
	
Therefore	O
,	O
we	O
conclude	O
that	O
DOC	B-Method
positively	O
affects	O
the	O
training	O
of	O
language	B-Task
modeling	I-Task
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
AWD	B-Method
-	I-Method
LSTM	I-Method
,	O
AWD	B-Method
-	I-Method
LSTM	I-Method
-	I-Method
MoS	I-Method
,	O
and	O
AWD	B-Method
-	I-Method
LSTM	I-Method
-	I-Method
DOC	I-Method
results	O
in	O
our	O
configurations	O
.	O
	
For	O
AWD	B-Method
-	I-Method
LSTM	I-Method
-	I-Method
MoS	I-Method
,	O
we	O
trained	O
our	O
implementation	O
with	O
the	O
same	O
dropout	B-Metric
rates	I-Metric
as	O
AWD	B-Method
-	I-Method
LSTM	I-Method
-	I-Method
DOC	I-Method
for	O
a	O
fair	O
comparison	O
.	O
	
AWD	B-Method
-	I-Method
LSTM	I-Method
-	I-Method
DOC	I-Method
outperformed	O
both	O
the	O
original	O
AWD	B-Method
-	I-Method
LSTM	I-Method
-	I-Method
MoS	I-Method
and	O
our	O
implementation	O
.	O
	
In	O
other	O
words	O
,	O
DOC	B-Method
outperformed	O
MoS.	B-Method
	
Since	O
the	O
averaged	O
SGD	B-Method
uses	O
the	O
averaged	O
parameters	O
from	O
each	O
update	O
step	O
,	O
the	O
parameters	O
of	O
the	O
early	O
steps	O
are	O
harmful	O
to	O
the	O
final	O
parameters	O
.	O
	
Therefore	O
,	O
when	O
the	O
model	O
converges	O
,	O
recent	O
studies	O
and	O
ours	O
eliminate	O
the	O
history	O
of	O
and	O
then	O
retrains	O
the	O
model	O
.	O
	
merityRegOpt	O
referred	O
to	O
this	O
retraining	B-Method
process	I-Method
as	O
fine	B-Task
-	I-Task
tuning	I-Task
.	O
	
Although	O
most	O
previous	O
studies	O
only	O
conducted	O
fine	O
-	O
tuning	O
once	O
,	O
fraternal	O
argued	O
that	O
two	O
fine	B-Method
-	I-Method
tunings	I-Method
provided	O
additional	O
improvement	O
.	O
	
Thus	O
,	O
we	O
repeated	O
fine	O
-	O
tuning	O
until	O
we	O
achieved	O
no	O
more	O
improvements	O
in	O
the	O
validation	O
data	O
.	O
	
We	O
refer	O
to	O
the	O
model	O
as	O
AWD	O
-	O
LSTM	B-Method
-	O
DOC	B-Method
(	O
fin	O
)	O
in	O
Table	O
[	O
reference	O
]	O
,	O
which	O
shows	O
that	O
repeated	O
fine	O
-	O
tunings	O
improved	O
the	O
perplexity	B-Metric
by	O
about	O
0.5	O
.	O
	
Tables	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
respectively	O
show	O
the	O
perplexities	B-Metric
of	O
AWD	B-Method
-	I-Method
LSTM	I-Method
-	I-Method
DOC	I-Method
and	O
previous	O
studies	O
on	O
PTB	B-Material
and	O
WikiText	B-Material
-	I-Material
2	I-Material
.	O
	
These	O
tables	O
show	O
that	O
AWD	B-Method
-	I-Method
LSTM	I-Method
-	I-Method
DOC	I-Method
achieved	O
the	O
best	O
perplexity	B-Metric
.	O
	
AWD	B-Method
-	I-Method
LSTM	I-Method
-	I-Method
DOC	I-Method
improved	O
the	O
perplexity	B-Metric
by	O
almost	O
2.0	O
on	O
PTB	B-Material
and	O
3.5	O
on	O
WikiText	B-Material
-	I-Material
2	I-Material
from	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
scores	O
.	O
	
The	O
ensemble	B-Method
technique	I-Method
provided	O
further	O
improvement	O
,	O
as	O
described	O
in	O
previous	O
studies	O
,	O
and	O
improved	O
the	O
perplexity	B-Metric
by	O
at	O
least	O
4	O
points	O
on	O
both	O
datasets	O
.	O
	
Finally	O
,	O
the	O
ensemble	O
of	O
the	O
repeated	B-Method
finetuning	I-Method
models	I-Method
achieved	O
47.17	O
on	O
the	O
PTB	B-Material
test	O
and	O
53.09	O
on	O
the	O
WikiText	B-Material
-	I-Material
2	I-Material
test	O
.	O
	
section	O
:	O
Experiments	O
on	O
Application	B-Task
Tasks	I-Task
	
As	O
described	O
in	O
Section	O
[	O
reference	O
]	O
,	O
a	O
neural	B-Method
encoder	I-Method
-	I-Method
decoder	I-Method
model	I-Method
can	O
be	O
interpreted	O
as	O
a	O
conditional	B-Method
language	I-Method
model	I-Method
.	O
	
To	O
investigate	O
the	O
effect	O
of	O
DOC	B-Method
on	O
an	O
encoder	B-Method
-	I-Method
decoder	I-Method
model	I-Method
,	O
we	O
incorporate	O
DOC	B-Method
into	O
the	O
decoder	B-Method
and	O
examine	O
its	O
performance	O
.	O
	
subsection	O
:	O
Dataset	O
	
We	O
conducted	O
experiments	O
on	O
machine	B-Task
translation	I-Task
and	I-Task
headline	I-Task
generation	I-Task
tasks	I-Task
.	O
	
For	O
machine	B-Task
translation	I-Task
,	O
we	O
used	O
two	O
kinds	O
of	O
sentence	O
pairs	O
(	O
English	O
-	O
German	O
and	O
English	O
-	O
French	O
)	O
in	O
the	O
IWSLT	O
2016	O
dataset	O
.	O
	
The	O
training	O
set	O
respectively	O
contains	O
about	O
189	O
K	O
and	O
208	O
K	O
sentence	O
pairs	O
of	O
English	O
-	O
German	O
and	O
English	O
-	O
French	O
.	O
	
We	O
experimented	O
in	O
four	O
settings	O
:	O
from	O
English	O
to	O
German	O
(	O
En	O
-	O
De	O
)	O
,	O
its	O
reverse	O
(	O
De	O
-	O
En	O
)	O
,	O
from	O
English	O
to	O
French	O
(	O
En	O
-	O
Fr	O
)	O
,	O
and	O
its	O
reverse	O
(	O
Fr	O
-	O
En	O
)	O
.	O
	
Headline	B-Task
generation	I-Task
is	O
a	O
task	O
that	O
creates	O
a	O
short	B-Task
summarization	I-Task
of	O
an	O
input	O
sentence	O
.	O
	
rush	O
-	O
chopra	O
-	O
weston:2015:EMNLP	O
constructed	O
a	O
headline	B-Method
generation	I-Method
dataset	I-Method
by	O
extracting	O
pairs	O
of	O
first	O
sentences	O
of	O
news	O
articles	O
and	O
their	O
headlines	O
from	O
the	O
annotated	O
English	O
Gigaword	O
corpus	O
.	O
	
They	O
also	O
divided	O
the	O
extracted	O
sentence	O
-	O
headline	O
pairs	O
into	O
three	O
parts	O
:	O
training	O
,	O
validation	O
,	O
and	O
test	O
sets	O
.	O
	
The	O
training	O
set	O
contains	O
about	O
3.8	O
M	O
sentence	O
-	O
headline	O
pairs	O
.	O
	
For	O
our	O
evaluation	O
,	O
we	O
used	O
the	O
test	O
set	O
constructed	O
by	O
zhou	O
-	O
EtAl:2017:Long	O
because	O
the	O
one	O
constructed	O
by	O
rush	O
-	O
chopra	O
-	O
weston:2015:EMNLP	O
contains	O
some	O
invalid	O
instances	O
,	O
as	O
reported	O
in	O
zhou	O
-	O
EtAl:2017:Long	O
.	O
	
subsection	O
:	O
Encoder	B-Method
-	I-Method
Decoder	I-Method
Model	I-Method
	
For	O
the	O
base	O
model	O
,	O
we	O
adopted	O
an	O
encoder	B-Method
-	I-Method
decoder	I-Method
with	O
an	O
attention	B-Method
mechanism	I-Method
described	O
in	O
kiyono	B-Method
.	O
	
The	O
encoder	O
consists	O
of	O
a	O
2	O
-	O
layer	O
bidirectional	O
LSTM	B-Method
,	O
and	O
the	O
decoder	B-Method
consists	O
of	O
a	O
2	O
-	O
layer	O
LSTM	B-Method
with	O
attention	B-Method
proposed	O
by	O
luong	O
-	O
pham	O
-	O
manning:2015:EMNLP	O
.	O
	
We	O
interpreted	O
the	O
layer	O
after	O
computing	O
the	O
attention	O
as	O
the	O
3rd	O
layer	O
of	O
the	O
decoder	B-Method
.	O
	
We	O
refer	O
to	O
this	O
encoder	B-Method
-	I-Method
decoder	I-Method
as	O
EncDec	B-Method
.	O
	
For	O
the	O
hyperparameters	O
,	O
we	O
followed	O
the	O
setting	O
of	O
kiyono	B-Method
except	O
for	O
the	O
sizes	O
of	O
hidden	O
states	O
and	O
embeddings	O
.	O
	
We	O
used	O
500	O
for	O
machine	B-Task
translation	I-Task
and	O
400	O
for	O
headline	B-Task
generation	I-Task
.	O
	
We	O
constructed	O
a	O
vocabulary	O
set	O
by	O
using	O
Byte	B-Method
-	I-Method
Pair	I-Method
-	I-Method
Encoding	I-Method
(	O
BPE	B-Method
)	O
.	O
	
We	O
set	O
the	O
number	O
of	O
BPE	B-Method
merge	O
operations	O
at	O
16	O
K	O
for	O
the	O
machine	B-Task
translation	I-Task
and	O
5	O
K	O
for	O
the	O
headline	B-Task
generation	I-Task
.	O
	
In	O
this	O
experiment	O
,	O
we	O
compare	O
DOC	B-Method
to	O
the	O
base	O
EncDec	B-Method
.	O
	
We	O
prepared	O
two	O
DOC	B-Method
settings	O
:	O
using	O
only	O
the	O
final	O
layer	O
,	O
that	O
is	O
,	O
a	O
setting	O
that	O
is	O
identical	O
to	O
MoS	B-Method
,	O
and	O
using	O
both	O
the	O
final	O
and	O
middle	O
layers	O
.	O
	
We	O
used	O
the	O
2nd	O
and	O
3rd	O
layers	O
in	O
the	O
latter	O
setting	O
because	O
this	O
case	O
achieved	O
the	O
best	O
performance	O
on	O
the	O
language	B-Task
modeling	I-Task
task	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
We	O
set	O
and	O
.	O
	
For	O
this	O
experiment	O
,	O
we	O
modified	O
a	O
publicly	O
available	O
encode	B-Method
-	I-Method
decoder	I-Method
implementation	I-Method
.	O
	
subsection	O
:	O
Results	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
BLEU	B-Metric
scores	I-Metric
of	O
each	O
method	O
.	O
	
Since	O
an	O
initial	O
value	O
often	O
drastically	O
varies	O
the	O
result	O
of	O
a	O
neural	B-Method
encoder	I-Method
-	I-Method
decoder	I-Method
,	O
we	O
reported	O
the	O
average	O
of	O
three	O
models	O
trained	O
from	O
different	O
initial	O
values	O
and	O
random	O
seeds	O
.	O
	
Table	O
[	O
reference	O
]	O
indicates	O
that	O
EncDec	O
+	O
DOC	B-Method
outperformed	O
EncDec	B-Method
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
ROUGE	O
F1	B-Metric
scores	I-Metric
of	O
each	O
method	O
.	O
	
In	O
addition	O
to	O
the	O
results	O
of	O
our	O
implementations	O
(	O
the	O
upper	O
part	O
)	O
,	O
the	O
lower	O
part	O
represents	O
the	O
published	O
scores	O
reported	O
in	O
previous	O
studies	O
.	O
	
For	O
the	O
upper	O
part	O
,	O
we	O
reported	O
the	O
average	O
of	O
three	O
models	O
(	O
as	O
in	O
Table	O
[	O
reference	O
]	O
)	O
.	O
	
EncDec	O
+	O
DOC	B-Method
	
outperformed	O
EncDec	B-Method
on	O
all	O
scores	O
.	O
	
Moreover	O
,	O
EncDec	B-Method
outperformed	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
method	O
on	O
the	O
ROUGE	B-Metric
-	I-Metric
2	I-Metric
and	O
ROUGE	B-Metric
-	I-Metric
L	I-Metric
F1	I-Metric
scores	I-Metric
.	O
	
In	O
other	O
words	O
,	O
our	O
baseline	O
is	O
already	O
very	O
strong	O
.	O
	
We	O
believe	O
that	O
this	O
is	O
because	O
we	O
adopted	O
a	O
larger	O
embedding	O
size	O
than	O
zhou	O
-	O
EtAl:2017:Long	O
.	O
	
It	O
is	O
noteworthy	O
that	O
DOC	B-Method
improved	O
the	O
performance	O
of	O
EncDec	B-Method
even	O
though	O
EncDec	B-Method
is	O
very	O
strong	O
.	O
	
These	O
results	O
indicate	O
that	O
DOC	B-Method
positively	O
influences	O
a	O
neural	B-Method
encoder	I-Method
-	I-Method
decoder	I-Method
model	I-Method
.	O
	
Using	O
the	O
middle	O
layer	O
also	O
yields	O
further	O
improvement	O
because	O
EncDec	O
+	O
DOC	B-Method
	
(	O
)	O
outperformed	O
EncDec	O
+	O
DOC	B-Method
(	O
)	O
.	O
	
section	O
:	O
Experiments	O
on	O
Constituency	B-Task
Parsing	I-Task
	
choe	O
-	O
charniak:2016:EMNLP2016	O
achieved	O
high	O
F1	B-Metric
scores	I-Metric
on	O
the	O
Penn	B-Material
Treebank	I-Material
constituency	O
parsing	O
task	O
by	O
transforming	O
candidate	O
trees	O
into	O
a	O
symbol	O
sequence	O
(	O
S	O
-	O
expression	O
)	O
and	O
reranking	O
them	O
based	O
on	O
the	O
perplexity	B-Metric
obtained	O
by	O
a	O
neural	B-Method
language	I-Method
model	I-Method
.	O
	
To	O
investigate	O
the	O
effectiveness	O
of	O
DOC	B-Method
,	O
we	O
evaluate	O
our	O
language	B-Method
models	I-Method
following	O
their	O
configurations	O
.	O
	
subsection	O
:	O
Dataset	O
	
We	O
used	O
the	O
Wall	O
Street	O
Journal	O
of	O
the	O
Penn	B-Material
Treebank	I-Material
dataset	O
.	O
	
We	O
used	O
the	O
section	O
2	O
-	O
21	O
for	O
training	O
,	O
22	O
for	O
validation	B-Task
,	O
and	O
23	O
for	O
testing	O
.	O
	
We	O
applied	O
the	O
preprocessing	B-Method
codes	I-Method
of	O
choe	O
-	O
charniak:2016:EMNLP2016	O
to	O
the	O
dataset	O
and	O
converted	O
a	O
token	O
that	O
appears	O
fewer	O
than	O
ten	O
times	O
in	O
the	O
training	O
dataset	O
into	O
a	O
special	O
token	O
unk	O
.	O
	
For	O
reranking	B-Task
,	O
we	O
prepared	O
500	O
candidates	O
obtained	O
by	O
the	O
Charniak	B-Method
parser	I-Method
.	O
	
subsection	O
:	O
Models	O
	
We	O
compare	O
AWD	B-Method
-	I-Method
LSTM	I-Method
-	I-Method
DOC	I-Method
with	O
AWD	B-Method
-	I-Method
LSTM	I-Method
and	O
AWD	B-Method
-	I-Method
LSTM	I-Method
-	I-Method
MoS	I-Method
.	O
	
We	O
trained	O
each	O
model	O
with	O
the	O
same	O
hyperparameters	O
from	O
our	O
language	B-Task
modeling	I-Task
experiments	O
(	O
Section	O
[	O
reference	O
]	O
)	O
.	O
	
We	O
selected	O
the	O
model	O
that	O
achieved	O
the	O
best	O
perplexity	B-Metric
on	O
the	O
validation	O
set	O
during	O
the	O
training	O
.	O
	
subsection	O
:	O
Results	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
bracketing	O
F1	B-Metric
scores	I-Metric
on	O
the	O
PTB	B-Material
test	I-Material
set	I-Material
.	O
	
This	O
table	O
is	O
divided	O
into	O
three	O
parts	O
by	O
horizontal	O
lines	O
;	O
the	O
upper	O
part	O
describes	O
the	O
scores	O
by	O
single	O
language	B-Task
modeling	I-Task
based	O
rerankers	O
,	O
the	O
middle	O
part	O
shows	O
the	O
results	O
by	O
ensembling	O
five	O
rerankers	O
,	O
and	O
the	O
lower	O
part	O
represents	O
the	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
scores	O
in	O
the	O
setting	O
without	O
external	O
data	O
.	O
	
The	O
upper	O
part	O
also	O
contains	O
the	O
score	O
reported	O
in	O
choe	O
-	O
charniak:2016:EMNLP2016	O
that	O
reranked	O
candidates	O
by	O
the	O
simple	O
LSTM	B-Method
language	I-Method
model	I-Method
.	O
	
This	O
part	O
indicates	O
that	O
our	O
implemented	O
rerankers	B-Method
outperformed	O
the	O
simple	O
LSTM	B-Method
language	I-Method
model	I-Method
based	I-Method
reranker	I-Method
,	O
which	O
achieved	O
92.6	O
F1	B-Metric
score	I-Metric
.	O
	
Moreover	O
,	O
AWD	B-Method
-	I-Method
LSTM	I-Method
-	I-Method
DOC	I-Method
outperformed	O
AWD	B-Method
-	I-Method
LSTM	I-Method
and	O
AWD	B-Method
-	I-Method
LSTM	I-Method
-	I-Method
MoS.	I-Method
	
These	O
results	O
correspond	O
to	O
the	O
performance	O
on	O
the	O
language	B-Task
modeling	I-Task
task	O
(	O
Section	O
[	O
reference	O
]	O
)	O
.	O
	
The	O
middle	O
part	O
shows	O
that	O
AWD	B-Method
-	I-Method
LSTM	I-Method
-	I-Method
DOC	I-Method
also	O
outperformed	O
AWD	B-Method
-	I-Method
LSTM	I-Method
and	O
AWD	B-Method
-	I-Method
LSTM	I-Method
-	I-Method
MoS	I-Method
in	O
the	O
ensemble	B-Task
setting	I-Task
.	O
	
In	O
addition	O
,	O
we	O
can	O
improve	O
the	O
performance	O
by	O
exchanging	O
the	O
base	B-Method
parser	I-Method
with	O
a	O
stronger	O
one	O
.	O
	
In	O
fact	O
,	O
we	O
achieved	O
94.29	O
F1	B-Metric
score	I-Metric
by	O
reranking	O
the	O
candidates	O
from	O
retrained	B-Method
Recurrent	I-Method
Neural	I-Method
Network	I-Method
Grammars	I-Method
(	O
RNNG	B-Method
)	O
,	O
that	O
achieved	O
91.2	O
F1	B-Metric
score	I-Metric
in	O
our	O
configuration	O
.	O
	
Moreover	O
,	O
the	O
lowest	O
row	O
of	O
the	O
middle	O
part	O
indicates	O
the	O
result	O
by	O
reranking	O
the	O
candidates	O
from	O
the	O
retrained	B-Method
neural	I-Method
encoder	I-Method
-	I-Method
decoder	I-Method
based	I-Method
parser	I-Method
.	O
	
Our	O
base	O
parser	B-Method
has	O
two	O
different	O
parts	O
from	O
P18	O
-	O
2097	O
.	O
	
First	O
,	O
we	O
used	O
the	O
sum	O
of	O
the	O
hidden	O
states	O
of	O
the	O
forward	B-Method
and	I-Method
backward	I-Method
RNNs	I-Method
as	O
the	O
hidden	O
layer	O
for	O
each	O
RNN	B-Method
.	O
	
Second	O
,	O
we	O
tied	O
the	O
embedding	O
matrix	O
to	O
the	O
weight	O
matrix	O
to	O
compute	O
the	O
probability	O
distributions	O
in	O
the	O
decoder	B-Method
.	O
	
The	O
retrained	B-Method
parser	I-Method
achieved	O
93.12	O
F1	B-Metric
score	I-Metric
.	O
	
Finally	O
,	O
we	O
achieved	O
94.47	O
F1	B-Metric
score	I-Metric
by	O
reranking	O
its	O
candidates	O
with	O
AWD	B-Method
-	I-Method
LSTM	I-Method
-	I-Method
DOC	I-Method
.	O
	
We	O
expect	O
that	O
we	O
can	O
achieve	O
even	O
better	O
score	O
by	O
replacing	O
the	O
base	B-Method
parser	I-Method
with	O
the	O
current	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
one	O
.	O
	
section	O
:	O
Related	O
Work	O
	
Bengio:2003:NPL:944919.944966	O
are	O
pioneers	O
of	O
neural	B-Method
language	I-Method
models	I-Method
.	O
	
To	O
address	O
the	O
curse	O
of	O
dimensionality	B-Task
in	O
language	B-Task
modeling	I-Task
,	O
they	O
proposed	O
a	O
method	O
using	O
word	B-Method
embeddings	I-Method
and	O
a	O
feed	B-Method
-	I-Method
forward	I-Method
neural	I-Method
network	I-Method
(	O
FFNN	B-Method
)	O
.	O
	
They	O
demonstrated	O
that	O
their	O
approach	O
outperformed	O
n	B-Method
-	I-Method
gram	I-Method
language	I-Method
models	I-Method
,	O
but	O
FFNN	B-Method
can	O
only	O
handle	O
fixed	O
-	O
length	O
contexts	O
.	O
	
Instead	O
of	O
FFNN	B-Method
,	O
DBLP	B-Method
:	O
	
conf	O
/	O
interspeech	O
/	O
MikolovKBCK10	O
applied	O
RNN	B-Method
to	O
language	B-Task
modeling	I-Task
to	O
address	O
the	O
entire	O
given	O
sequence	O
as	O
a	O
context	O
.	O
	
Their	O
method	O
outperformed	O
the	O
Kneser	B-Method
-	I-Method
Ney	I-Method
smoothed	I-Method
5	I-Method
-	I-Method
gram	I-Method
language	I-Method
model	I-Method
.	O
	
Researchers	O
continue	O
to	O
try	O
to	O
improve	O
the	O
performance	O
of	O
RNN	B-Method
language	I-Method
models	I-Method
.	O
	
DBLP	O
:	O
	
journals	O
/	O
corr	O
	
/	O
ZarembaSV14	O
used	O
LSTM	B-Method
instead	O
of	O
a	O
simple	O
RNN	B-Method
for	O
language	B-Task
modeling	I-Task
and	O
significantly	O
improved	O
an	O
RNN	B-Method
language	I-Method
model	I-Method
by	O
applying	O
dropout	B-Method
to	O
all	O
the	O
connections	O
except	O
for	O
the	O
recurrent	O
connections	O
.	O
	
To	O
regularize	O
the	O
recurrent	O
connections	O
,	O
Gal2016Theoretically	O
proposed	O
variational	B-Method
inference	I-Method
-	I-Method
based	I-Method
dropout	I-Method
.	O
	
Their	O
method	O
uses	O
the	O
same	O
dropout	O
mask	O
at	O
each	O
timestep	O
.	O
	
fraternal	B-Method
proposed	O
fraternal	B-Method
dropout	I-Method
,	O
which	O
minimizes	O
the	O
differences	O
between	O
outputs	O
from	O
different	O
dropout	O
masks	O
to	O
be	O
invariant	O
to	O
the	O
dropout	O
mask	O
.	O
	
DBLP	O
:	O
	
journals	O
/	O
corr	O
/	O
MelisDB17	O
used	O
black	B-Method
-	I-Method
box	I-Method
optimization	I-Method
to	O
find	O
appropriate	O
hyperparameters	B-Method
for	O
RNN	B-Method
language	I-Method
models	I-Method
and	O
demonstrated	O
that	O
the	O
standard	O
LSTM	B-Method
with	O
proper	O
regularizations	B-Method
can	O
outperform	O
other	O
architectures	O
.	O
	
Apart	O
from	O
dropout	B-Method
techniques	I-Method
,	O
DBLP	O
:	O
journals	O
/	O
corr	O
/	O
InanKS16	O
and	O
press	O
-	O
wolf:2017:EACLshort	O
proposed	O
the	O
word	B-Method
tying	I-Method
method	I-Method
(	O
WT	B-Method
)	O
,	O
which	O
unifies	O
word	O
embeddings	O
(	O
in	O
Equation	O
[	O
reference	O
]	O
)	O
with	O
the	O
weight	O
matrix	O
to	O
compute	O
probability	O
distributions	O
(	O
in	O
Equation	O
[	O
reference	O
]	O
)	O
.	O
	
In	O
addition	O
to	O
quantitative	B-Metric
evaluation	I-Metric
,	O
DBLP	B-Method
:	O
journals	O
/	O
corr	O
/	O
InanKS16	O
provided	O
a	O
theoretical	O
justification	O
for	O
WT	B-Method
and	O
proposed	O
the	O
augmented	B-Method
loss	I-Method
technique	I-Method
(	O
AL	B-Method
)	O
,	O
which	O
computes	O
an	O
objective	O
probability	O
based	O
on	O
word	O
embeddings	O
.	O
	
In	O
addition	O
to	O
these	O
regularization	B-Method
techniques	I-Method
,	O
merityRegOpt	B-Method
used	O
DropConnect	O
and	O
averaged	O
SGD	B-Method
for	O
an	O
LSTM	B-Method
language	I-Method
model	I-Method
.	O
	
Their	O
AWD	B-Method
-	I-Method
LSTM	I-Method
achieved	O
lower	O
perplexity	B-Metric
than	O
DBLP	O
:	O
journals	O
/	O
corr	O
/	O
MelisDB17	O
on	O
PTB	B-Material
and	O
WikiText	B-Material
-	I-Material
2	I-Material
.	O
	
Previous	O
studies	O
also	O
explored	O
superior	O
architecture	O
for	O
language	B-Task
modeling	I-Task
.	O
	
zilly2016recurrent	O
proposed	O
recurrent	B-Method
highway	I-Method
networks	I-Method
that	O
use	O
highway	B-Method
layers	I-Method
to	O
deepen	O
recurrent	O
connections	O
.	O
	
45826	O
adopted	O
reinforcement	B-Method
learning	I-Method
to	O
construct	O
the	O
best	O
RNN	B-Method
structure	I-Method
.	O
	
However	O
,	O
as	O
mentioned	O
,	O
DBLP	O
:	O
journals	O
/	O
corr	O
/	O
MelisDB17	O
established	O
that	O
the	O
standard	O
LSTM	B-Method
is	O
superior	O
to	O
these	O
architectures	O
.	O
	
Apart	O
from	O
RNN	B-Method
architecture	I-Method
,	O
takase	O
-	O
suzuki	O
-	O
nagata:2017:I17	O
-	O
2	O
proposed	O
the	O
input	O
-	O
to	O
-	O
output	O
gate	O
(	O
IOG	B-Method
)	O
,	O
which	O
boosts	O
the	O
performance	O
of	O
trained	O
language	B-Method
models	I-Method
.	O
	
As	O
described	O
in	O
Section	O
[	O
reference	O
]	O
,	O
DBLP	O
:	O
journals	O
/	O
corr	O
/	O
	
abs	O
-	O
1711	O
-	O
03953	O
interpreted	O
training	O
language	B-Task
modeling	I-Task
as	O
matrix	B-Method
factorization	I-Method
and	O
improved	O
performance	O
by	O
computing	O
multiple	O
probability	O
distributions	O
.	O
	
In	O
this	O
study	O
,	O
we	O
generalized	O
their	O
approach	O
to	O
use	O
the	O
middle	O
layers	O
of	O
RNNs	B-Method
.	O
	
Finally	O
,	O
our	O
proposed	O
method	O
,	O
DOC	B-Method
,	O
achieved	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
score	O
on	O
the	O
standard	O
benchmark	O
datasets	O
.	O
	
Some	O
studies	O
provided	O
methods	O
that	O
boost	O
performance	O
by	O
using	O
statistics	O
obtained	O
from	O
test	O
data	O
.	O
	
DBLP	O
:	O
	
journals	O
/	O
corr	O
/	O
GraveJU16	O
extended	O
a	O
cache	B-Method
model	I-Method
for	O
RNN	B-Method
language	I-Method
models	I-Method
.	O
	
DBLP	O
:	O
	
journals	O
/	O
corr	O
/	O
abs	O
-	O
1709	O
-	O
07432	O
proposed	O
dynamic	B-Method
evaluation	I-Method
that	O
updates	O
parameters	O
based	O
on	O
a	O
recent	O
sequence	O
during	O
testing	O
.	O
	
Although	O
these	O
methods	O
might	O
also	O
improve	O
the	O
performance	O
of	O
DOC	B-Method
,	O
we	O
omitted	O
such	O
investigation	O
to	O
focus	O
on	O
comparisons	O
among	O
methods	O
trained	O
only	O
on	O
the	O
training	O
set	O
.	O
	
section	O
:	O
Conclusion	O
	
We	O
proposed	O
Direct	B-Method
Output	I-Method
Connection	I-Method
(	O
DOC	B-Method
)	O
,	O
a	O
generalization	B-Method
method	I-Method
of	O
MoS	B-Method
introduced	O
by	O
DBLP	O
:	O
journals	O
/	O
corr	O
/	O
abs	O
-	O
1711	O
-	O
03953	O
.	O
	
DOC	B-Method
raises	O
the	O
expressive	O
power	O
of	O
RNN	B-Method
language	I-Method
models	I-Method
and	O
improves	O
quality	O
of	O
the	O
model	O
.	O
	
DOC	B-Method
outperformed	O
MoS	B-Method
and	O
achieved	O
the	O
best	O
perplexities	B-Metric
on	O
the	O
standard	O
benchmark	O
datasets	O
of	O
language	B-Task
modeling	I-Task
:	O
PTB	B-Material
and	O
WikiText	B-Material
-	I-Material
2	I-Material
.	O
	
Moreover	O
,	O
we	O
investigated	O
its	O
effectiveness	O
on	O
machine	B-Task
translation	I-Task
and	O
headline	B-Task
generation	I-Task
.	O
	
Our	O
results	O
show	O
that	O
DOC	B-Method
also	O
improved	O
the	O
performance	O
of	O
EncDec	B-Method
and	O
using	O
a	O
middle	B-Method
layer	I-Method
positively	O
affected	O
such	O
application	O
tasks	O
.	O
	
bibliography	O
:	O
References	O
	
In	O
this	O
paper	O
we	O
introduce	O
a	O
simple	O
approach	O
for	O
exploration	B-Task
in	I-Task
reinforcement	I-Task
learning	I-Task
(	I-Task
RL	I-Task
)	O
that	O
allows	O
us	O
to	O
develop	O
theoretically	O
justified	B-Method
algorithms	I-Method
in	O
the	O
tabular	B-Task
case	I-Task
but	O
that	O
is	O
also	O
extendable	O
to	O
settings	O
where	O
function	B-Method
approximation	I-Method
is	O
required	O
.	O
	
Our	O
approach	O
is	O
based	O
on	O
the	O
successor	B-Method
representation	I-Method
(	O
SR	B-Method
)	O
,	O
which	O
was	O
originally	O
introduced	O
as	O
a	O
representation	O
defining	O
state	B-Task
generalization	I-Task
by	O
the	O
similarity	O
of	O
successor	O
states	O
.	O
	
Here	O
we	O
show	O
that	O
the	O
norm	O
of	O
the	O
SR	B-Method
,	O
while	O
it	O
is	O
being	O
learned	O
,	O
can	O
be	O
used	O
as	O
a	O
reward	O
bonus	O
to	O
incentivize	O
exploration	B-Task
.	O
	
In	O
order	O
to	O
better	O
understand	O
this	O
transient	O
behavior	O
of	O
the	O
norm	O
of	O
the	O
SR	B-Method
we	O
introduce	O
the	O
substochastic	B-Method
successor	I-Method
representation	I-Method
(	O
SSR	B-Method
)	O
and	O
we	O
show	O
that	O
it	O
implicitly	O
counts	O
the	O
number	O
of	O
times	O
each	O
state	O
(	O
or	O
feature	O
)	O
has	O
been	O
observed	O
.	O
	
We	O
use	O
this	O
result	O
to	O
introduce	O
an	O
algorithm	O
that	O
performs	O
as	O
well	O
as	O
some	O
theoretically	B-Method
sample	I-Method
-	I-Method
efficient	I-Method
approaches	I-Method
.	O
	
Finally	O
,	O
we	O
extend	O
these	O
ideas	O
to	O
a	O
deep	B-Method
RL	I-Method
algorithm	I-Method
and	O
show	O
that	O
it	O
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
in	O
Atari	B-Material
2600	I-Material
games	I-Material
.	O
	
Count	O
-	O
BasedExplorationwiththeSuccessorRepresentation	O
	
section	O
:	O
Introduction	O
	
Reinforcement	B-Method
learning	I-Method
(	O
RL	B-Method
)	O
tackles	O
sequential	B-Task
decision	I-Task
making	I-Task
problems	I-Task
by	O
formulating	O
them	O
as	O
tasks	O
where	O
an	O
agent	O
must	O
learn	O
how	O
to	O
act	O
optimally	O
through	O
trial	O
and	O
error	O
interactions	O
with	O
the	O
environment	O
.	O
	
The	O
goal	O
in	O
these	O
problems	O
is	O
to	O
maximize	O
the	O
discounted	O
sum	O
of	O
the	O
numerical	O
reward	O
signal	O
observed	O
at	O
each	O
time	O
step	O
.	O
	
Because	O
the	O
actions	O
taken	O
by	O
the	O
agent	O
influence	O
not	O
just	O
the	O
immediate	O
reward	O
but	O
also	O
the	O
states	O
and	O
associated	O
rewards	O
in	O
the	O
future	O
,	O
sequential	B-Task
decision	I-Task
making	I-Task
problems	I-Task
require	O
agents	O
to	O
deal	O
with	O
the	O
trade	O
-	O
off	O
between	O
immediate	O
and	O
delayed	O
rewards	O
.	O
	
Here	O
we	O
focus	O
on	O
the	O
problem	O
of	O
exploration	B-Task
in	I-Task
RL	I-Task
,	O
which	O
aims	O
to	O
reduce	O
the	O
number	O
of	O
samples	O
(	O
i.e.	O
,	O
interactions	O
)	O
an	O
agent	O
needs	O
in	O
order	O
to	O
learn	O
to	O
perform	O
well	O
in	O
these	O
tasks	O
when	O
the	O
environment	O
is	O
initially	O
unknown	O
.	O
	
Surprisingly	O
,	O
the	O
most	O
common	O
approach	O
in	O
the	O
field	O
is	O
to	O
select	O
exploratory	O
actions	O
uniformly	O
at	O
random	O
,	O
with	O
even	O
high	O
-	O
profile	O
success	O
stories	O
being	O
obtained	O
with	O
this	O
strategy	O
[	O
e.g.	O
,][]	O
Tesauro95	O
,	O
Mnih15	O
.	O
	
However	O
,	O
random	B-Method
exploration	I-Method
often	O
fails	O
in	O
environments	O
with	O
sparse	O
rewards	O
,	O
that	O
is	O
,	O
environments	O
where	O
the	O
agent	O
observes	O
a	O
reward	O
signal	O
of	O
value	O
zero	O
for	O
the	O
majority	O
of	O
states	O
.	O
	
In	O
this	O
paper	O
we	O
introduce	O
a	O
novel	O
approach	O
for	O
exploration	B-Task
in	I-Task
RL	I-Task
based	O
on	O
the	O
successor	B-Method
representation	I-Method
[	O
SR;	O
][]	O
Dayan93	O
.	O
	
The	O
SR	B-Method
is	O
a	O
representation	O
that	O
generalizes	O
between	O
states	O
using	O
the	O
similarity	O
between	O
their	O
successors	O
,	O
that	O
is	O
,	O
the	O
states	O
that	O
follow	O
the	O
current	O
state	O
given	O
the	O
agent	O
’s	O
policy	O
.	O
	
The	O
SR	B-Method
is	O
defined	O
for	O
any	O
problem	O
,	O
it	O
can	O
be	O
learned	O
with	O
temporal	B-Method
-	I-Method
difference	I-Method
(	O
TD	B-Method
)	O
learning	O
Sutton88	O
and	O
,	O
as	O
we	O
discuss	O
below	O
,	O
it	O
can	O
be	O
seen	O
as	O
implicitly	O
estimating	O
the	O
transition	O
dynamics	O
of	O
the	O
environment	O
.	O
	
The	O
main	O
contribution	O
of	O
this	O
paper	O
is	O
to	O
show	O
that	O
the	O
norm	O
of	O
the	O
SR	B-Method
can	O
be	O
used	O
as	O
an	O
exploration	O
bonus	O
.	O
	
We	O
perform	O
an	O
extensive	O
empirical	O
evaluation	O
to	O
demonstrate	O
this	O
and	O
we	O
introduce	O
the	O
substochastic	B-Method
successor	I-Method
representation	I-Method
(	O
SSR	B-Method
)	O
to	O
also	O
understand	O
,	O
theoretically	O
,	O
the	O
behavior	O
of	O
such	O
bonus	O
.	O
	
The	O
SSR	B-Method
behaves	O
similarly	O
to	O
the	O
SR	B-Method
but	O
it	O
is	O
more	O
amenable	O
to	O
theoretical	O
analyses	O
.	O
	
We	O
show	O
that	O
the	O
SSR	B-Method
implicitly	O
counts	O
state	O
visitation	O
,	O
suggesting	O
that	O
the	O
exploration	O
bonus	O
obtained	O
from	O
the	O
SR	B-Method
,	O
while	O
it	O
is	O
being	O
learned	O
,	O
might	O
also	O
be	O
incorporating	O
some	O
notion	O
of	O
state	O
visitation	O
counts	O
.	O
	
Finally	O
,	O
we	O
extend	O
the	O
idea	O
of	O
using	O
the	O
norm	O
of	O
the	O
SR	B-Method
as	O
an	O
exploration	O
bonus	O
to	O
the	O
function	B-Task
approximation	I-Task
case	I-Task
,	O
designing	O
a	O
deep	B-Method
RL	I-Method
algorithm	I-Method
that	O
achieves	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
in	O
hard	B-Task
exploration	I-Task
Atari	I-Task
2600	I-Task
games	I-Task
when	O
in	O
a	O
low	O
sample	B-Metric
-	I-Metric
complexity	I-Metric
regime	I-Metric
.	O
	
Importantly	O
,	O
the	O
proposed	O
algorithm	O
is	O
also	O
simpler	O
than	O
traditional	O
baselines	O
such	O
as	O
pseudo	B-Method
-	I-Method
count	I-Method
-	I-Method
based	I-Method
methods	I-Method
as	O
it	O
does	O
not	O
require	O
domain	B-Method
-	I-Method
specific	I-Method
density	I-Method
models	I-Method
Bellemare16	O
,	O
Ostrovski17	O
.	O
	
section	O
:	O
Preliminaries	O
	
We	O
consider	O
an	O
agent	O
interacting	O
with	O
its	O
environment	O
in	O
a	O
sequential	O
manner	O
.	O
	
Starting	O
from	O
a	O
state	O
,	O
at	O
each	O
step	O
the	O
agent	O
takes	O
an	O
action	O
,	O
to	O
which	O
the	O
environment	O
responds	O
with	O
a	O
state	O
according	O
to	O
a	O
transition	O
probability	O
function	O
,	O
and	O
with	O
a	O
reward	O
signal	O
,	O
where	O
indicates	O
the	O
expected	O
reward	O
for	O
a	O
transition	O
from	O
state	O
under	O
action	O
,	O
i.e.	O
,	O
.	O
	
The	O
value	O
of	O
a	O
state	O
when	O
following	O
a	O
policy	O
,	O
,	O
is	O
defined	O
to	O
be	O
the	O
expected	O
sum	O
of	O
discounted	O
rewards	O
from	O
that	O
state	O
:	O
,	O
with	O
being	O
the	O
discount	O
factor	O
.	O
	
When	O
the	O
transition	O
probability	O
function	O
and	O
the	O
reward	O
function	O
are	O
known	O
,	O
we	O
can	O
compute	O
recursively	O
by	O
solving	O
the	O
system	O
of	O
equations	O
below	O
Bellman57	O
:	O
These	O
equations	O
can	O
also	O
be	O
written	O
in	O
matrix	O
form	O
with	O
,	O
and	O
:	O
where	O
is	O
the	O
state	O
to	O
state	O
transition	O
probability	O
function	O
induced	O
by	O
,	O
that	O
is	O
,	O
.	O
	
Traditional	O
model	B-Method
-	I-Method
based	I-Method
algorithms	I-Method
work	O
by	O
learning	O
estimates	O
of	O
the	O
matrix	O
and	O
of	O
the	O
vector	O
and	O
using	O
them	O
to	O
estimate	O
,	O
for	O
example	O
by	O
solving	O
Equation	O
[	O
reference	O
]	O
.	O
	
We	O
use	O
and	O
to	O
denote	O
empirical	O
estimates	O
of	O
and	O
.	O
	
Formally	O
,	O
where	O
denotes	O
the	O
-	O
th	O
entry	O
in	O
the	O
vector	O
,	O
is	O
the	O
number	O
of	O
times	O
the	O
transition	O
was	O
observed	O
,	O
,	O
and	O
is	O
the	O
sum	O
of	O
the	O
rewards	O
associated	O
with	O
the	O
transitions	O
	
(	O
we	O
drop	O
the	O
action	O
to	O
simplify	O
notation	O
)	O
.	O
	
However	O
,	O
model	B-Method
-	I-Method
based	I-Method
approaches	I-Method
are	O
rarely	O
successful	O
in	O
problems	O
with	O
large	O
state	O
spaces	O
due	O
to	O
the	O
difficulty	O
in	O
learning	B-Task
accurate	I-Task
models	I-Task
.	O
	
Because	O
of	O
the	O
challenges	O
in	O
model	B-Task
learning	I-Task
,	O
model	B-Method
-	I-Method
free	I-Method
solutions	I-Method
largely	O
dominate	O
the	O
literature	O
.	O
	
In	O
model	B-Task
-	I-Task
free	I-Task
RL	I-Task
,	O
instead	O
of	O
estimating	O
and	O
we	O
estimate	O
directly	O
from	O
samples	O
.	O
	
We	O
often	O
use	O
TD	B-Method
learning	I-Method
Sutton88	O
to	O
update	O
our	O
estimates	O
of	O
,	O
,	O
online	O
:	O
where	O
is	O
the	O
step	O
-	O
size	O
parameter	O
.	O
	
Generalization	B-Task
is	O
required	O
in	O
problems	O
with	O
large	O
state	O
spaces	O
,	O
where	O
it	O
is	O
unfeasible	O
to	O
learn	O
an	O
individual	O
value	O
for	O
each	O
state	O
.	O
	
We	O
do	O
so	O
by	O
parametrizing	O
with	O
a	O
set	O
of	O
weights	O
.	O
	
We	O
write	O
,	O
given	O
the	O
weights	O
,	O
and	O
,	O
where	O
.	O
	
Model	B-Method
-	I-Method
free	I-Method
methods	I-Method
have	O
performed	O
well	O
in	O
problems	O
with	O
large	O
state	O
spaces	O
,	O
mainly	O
due	O
to	O
the	O
use	O
of	O
neural	B-Method
networks	I-Method
as	O
function	B-Method
approximators	I-Method
[	O
e.g.	O
,][]	O
Mnih15	O
.	O
	
The	O
ideas	O
presented	O
here	O
are	O
based	O
on	O
the	O
successor	B-Method
representation	I-Method
[	O
SR;	O
][]	O
Dayan93	O
.	O
	
The	O
successor	B-Method
representation	I-Method
with	O
respect	O
to	O
a	O
policy	O
,	O
,	O
is	O
defined	O
as	O
where	O
we	O
assume	O
the	O
sum	O
is	O
convergent	O
with	O
denoting	O
the	O
indicator	O
function	O
.	O
	
This	O
expectation	O
can	O
actually	O
be	O
estimated	O
from	O
samples	O
with	O
TD	B-Method
learning	I-Method
:	O
for	O
all	O
and	O
denoting	O
the	O
step	O
-	O
size	O
.	O
	
The	O
SR	B-Method
also	O
corresponds	O
to	O
the	O
Neumann	O
series	O
of	O
:	O
Notice	O
that	O
the	O
SR	B-Method
is	O
part	O
of	O
the	O
solution	O
when	O
computing	O
a	O
value	O
function	O
:	O
(	O
Eq	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
We	O
use	O
to	O
denote	O
the	O
SR	B-Method
computed	O
through	O
,	O
the	O
approximation	B-Method
of	I-Method
.	O
	
The	O
definition	O
of	O
the	O
SR	B-Method
can	O
also	O
be	O
extended	O
to	O
features	O
.	O
	
Successor	B-Method
features	I-Method
Barreto17	O
generalize	O
the	O
successor	B-Method
representation	I-Method
to	O
the	O
function	B-Task
approximation	I-Task
setting	I-Task
.	O
	
We	O
use	O
the	O
definition	O
for	O
the	O
uncontrolled	B-Task
case	I-Task
in	O
this	O
paper	O
.	O
	
Successor	B-Method
features	I-Method
can	O
also	O
be	O
learned	O
with	O
TD	B-Method
learning	I-Method
.	O
	
theorem	O
:	O
(	O
Successor	O
Features	O
)	O
.	O
	
For	O
a	O
given	O
0≤γ<1	O
,	O
policy	O
π	O
,	O
and	O
for	O
a	O
feature	B-Method
representation	I-Method
∈⁢ϕ	O
(	O
s	O
)	O
Rd	O
,	O
the	O
successor	O
features	O
for	O
a	O
state	O
s	O
are	O
:	O
Alternatively	O
,	O
in	O
matrix	O
form	O
,	O
we	O
can	O
write	O
the	O
successor	O
features	O
as	O
,	O
where	O
is	O
a	O
matrix	O
encoding	O
the	O
feature	B-Method
representation	I-Method
of	O
each	O
state	O
such	O
that	O
.	O
	
This	O
definition	O
reduces	O
to	O
the	O
SR	B-Method
in	O
the	O
tabular	O
case	O
,	O
where	O
.	O
	
section	O
:	O
as	O
an	O
Exploration	O
Bonus	O
	
It	O
is	O
now	O
well	O
-	O
known	O
that	O
the	O
SR	B-Method
incorporates	O
diffusion	O
properties	O
of	O
the	O
environment	O
[	O
e.g.	O
,][]	O
Machado18b	O
,	O
Wu19	O
.	O
	
These	O
properties	O
can	O
be	O
used	O
to	O
accelerate	O
learning	B-Task
,	O
for	O
example	O
,	O
with	O
options	O
that	O
promote	O
exploration	B-Task
Machado18b	O
.	O
	
Inspired	O
by	O
these	O
results	O
,	O
in	O
this	O
section	O
we	O
argue	O
that	O
the	O
SR	B-Method
can	O
be	O
used	O
in	O
a	O
more	O
direct	O
way	O
to	O
promote	O
exploration	B-Task
.	O
	
We	O
show	O
that	O
the	O
norm	O
of	O
the	O
SR	B-Method
,	O
while	O
it	O
is	O
being	O
learned	O
,	O
behaves	O
as	O
an	O
exploration	O
bonus	O
that	O
rewards	O
agents	O
for	O
visiting	O
states	O
it	O
has	O
visited	O
less	O
often	O
.	O
	
We	O
first	O
demonstrate	O
this	O
behavior	O
empirically	O
,	O
in	O
the	O
tabular	O
case	O
,	O
to	O
clearly	O
present	O
the	O
idea	O
behind	O
the	O
introduced	O
algorithm	O
.	O
	
We	O
then	O
introduce	O
the	O
substochastic	B-Method
successor	I-Method
representation	I-Method
in	O
order	O
to	O
provide	O
some	O
theoretical	O
intuition	O
that	O
justifies	O
this	O
idea	O
.	O
	
Later	O
we	O
show	O
how	O
these	O
ideas	O
carry	O
over	O
to	O
the	O
function	B-Task
approximation	I-Task
setting	I-Task
.	O
	
subsection	O
:	O
Empirical	O
Demonstration	O
	
To	O
demonstrate	O
the	O
usefulness	O
of	O
the	O
norm	O
of	O
the	O
SR	B-Method
as	O
an	O
exploration	O
bonus	O
we	O
compare	O
the	O
performance	O
of	O
traditional	O
Sarsa	B-Method
Rummery94	I-Method
to	O
Sarsa	B-Method
+	O
SR	B-Method
,	O
which	O
incorporates	O
the	O
norm	O
of	O
the	O
SR	B-Method
as	O
an	O
exploration	O
bonus	O
in	O
the	O
Sarsa	B-Method
update	I-Method
.	O
	
The	O
update	B-Method
equation	I-Method
for	O
Sarsa	B-Method
+	O
SR	B-Method
is	O
where	O
is	O
a	O
scaling	O
factor	O
and	O
,	O
at	O
each	O
time	O
step	O
,	O
is	O
updated	O
before	O
as	O
per	O
Equation	O
4	O
.	O
	
We	O
evaluted	O
this	O
algorithm	O
in	O
RiverSwim	O
and	O
SixArms	O
Strehl08	O
,	O
traditional	O
domains	O
in	O
the	O
PAC	O
-	O
MDP	O
literature	O
that	O
are	O
used	O
to	O
evaluate	O
provably	B-Method
sample	I-Method
-	I-Method
efficient	I-Method
algorithms	I-Method
.	O
	
In	O
these	O
domains	O
it	O
is	O
very	O
likely	O
that	O
an	O
agent	O
will	O
first	O
observe	O
a	O
small	O
reward	O
generated	O
in	O
a	O
state	O
that	O
is	O
easy	O
to	O
get	O
to	O
.	O
	
If	O
the	O
agent	O
does	O
not	O
have	O
a	O
good	O
exploration	B-Method
policy	I-Method
it	O
is	O
likely	O
to	O
converge	O
to	O
a	O
suboptimal	O
behavior	O
,	O
never	O
observing	O
larger	O
rewards	O
available	O
in	O
states	O
that	O
are	O
difficult	O
to	O
get	O
to	O
.	O
	
Our	O
results	O
suggest	O
that	O
the	O
proposed	O
exploration	B-Method
bonus	I-Method
has	O
a	O
profound	O
impact	O
in	O
the	O
algorithm	O
	
’s	O
performance	O
.	O
	
When	O
evaluating	O
the	O
agent	O
for	O
time	O
steps	O
,	O
Sarsa	B-Method
obtains	O
an	O
average	O
return	O
of	O
approximately	O
,	O
while	O
Sarsa	B-Method
+	O
SR	B-Method
obtains	O
an	O
approximate	O
average	B-Metric
return	I-Metric
of	O
million	O
!	O
	
Notice	O
that	O
,	O
in	O
RiverSwim	O
,	O
the	O
reward	O
that	O
is	O
“	O
easy	O
to	O
get	O
”	O
has	O
value	O
,	O
implying	O
that	O
,	O
different	O
from	O
Sarsa	B-Method
+	O
SR	B-Method
,	O
Sarsa	B-Method
almost	O
never	O
explores	O
the	O
state	O
space	O
well	O
enough	O
.	O
	
In	O
SixArms	O
the	O
trend	O
is	O
the	O
same	O
.	O
	
Sarsa	B-Method
obtains	O
an	O
approximate	O
average	B-Metric
return	I-Metric
of	O
while	O
Sarsa	B-Method
+	O
SR	B-Method
achieves	O
approximately	O
millon	O
.	O
	
The	O
actual	O
numbers	O
,	O
which	O
were	O
averaged	O
over	O
runs	O
,	O
are	O
available	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Details	O
about	O
parameters	O
as	O
well	O
as	O
the	O
empirical	O
methodology	O
are	O
available	O
in	O
the	O
Appendix	O
.	O
	
subsection	O
:	O
Theoretical	O
Justification	O
	
It	O
is	O
difficult	O
to	O
characterize	O
the	O
behavior	O
of	O
our	O
proposed	O
exploration	B-Method
bonus	I-Method
because	O
it	O
is	O
updated	O
at	O
each	O
time	O
step	O
with	O
TD	B-Method
learning	I-Method
.	O
	
It	O
is	O
hard	O
to	O
analyze	O
the	O
behavior	O
of	O
estimates	O
obtained	O
with	O
TD	B-Method
learning	I-Method
in	O
the	O
interim	O
.	O
	
Also	O
,	O
at	O
its	O
fixed	O
point	O
,	O
the	O
-	O
norm	O
of	O
the	O
SR	B-Method
is	O
for	O
all	O
states	O
,	O
making	O
it	O
hard	O
for	O
us	O
to	O
use	O
the	O
fixed	O
point	O
of	O
the	O
SR	B-Method
to	O
theoretically	O
analyze	O
the	O
behavior	O
of	O
this	O
exploration	O
bonus	O
.	O
	
In	O
this	O
section	O
we	O
introduce	O
the	O
substochastic	B-Method
successor	I-Method
representation	I-Method
(	O
SSR	B-Method
)	O
to	O
provide	O
some	O
theoretical	O
intuition	O
of	O
why	O
the	O
norm	O
of	O
the	O
SR	B-Method
is	O
a	O
good	O
exploration	O
bonus	O
.	O
	
The	O
SSR	B-Method
behaves	O
similarly	O
to	O
the	O
SR	B-Method
	
but	O
it	O
is	O
simpler	O
to	O
analyze	O
.	O
	
theorem	O
:	O
(	O
Substochastic	B-Method
Successor	I-Method
Representation	I-Method
)	O
.	O
	
Let	O
~Pπ	O
denote	O
the	O
substochastic	O
matrix	O
induced	O
by	O
the	O
environment	O
	
’s	O
dynamics	O
and	O
by	O
the	O
policy	B-Method
π	I-Method
	
such	O
that	O
~Pπ	O
(	O
s′|s	O
)	O
=⁢n	O
(	O
s	O
,	O
s′	O
)+	O
⁢n	O
(	O
s	O
)	O
1	O
.	O
	
For	O
a	O
given	O
0≤γ<1	O
,	O
the	O
substochastic	B-Method
successor	I-Method
representation	I-Method
,	O
~Ψπ	O
,	O
is	O
defined	O
as	O
:	O
The	O
SSR	B-Method
only	O
differs	O
from	O
the	O
empirical	O
SR	B-Method
in	O
its	O
incorporation	O
of	O
an	O
additional	O
“	O
phantom	O
”	O
transition	O
from	O
each	O
state	O
,	O
making	O
it	O
underestimate	O
the	O
real	O
SR	B-Method
.	O
	
Through	O
algebraic	O
manipulation	O
we	O
show	O
that	O
the	O
SSR	B-Method
allows	O
us	O
to	O
recover	O
an	O
estimate	O
of	O
the	O
visit	O
counts	O
,	O
.	O
	
This	O
result	O
provides	O
some	O
intuition	O
of	O
why	O
the	O
exploration	O
bonus	O
we	O
propose	O
in	O
this	O
paper	O
performs	O
so	O
well	O
,	O
as	O
exploration	O
bonuses	O
based	O
on	O
state	O
visitation	O
counts	O
are	O
known	O
to	O
generate	O
proper	O
exploration	B-Task
.	O
	
As	O
aforementioned	O
,	O
the	O
SSR	B-Method
behaves	O
similarly	O
to	O
the	O
SR	B-Method
.	O
	
When	O
computing	O
the	O
norm	O
of	O
the	O
SR	B-Method
,	O
while	O
it	O
is	O
being	O
learned	O
with	O
TD	B-Method
learning	I-Method
,	O
it	O
is	O
as	O
if	O
a	O
reward	O
of	O
1	O
was	O
observed	O
at	O
each	O
time	O
step	O
.	O
	
Thus	O
,	O
there	O
is	O
little	O
variance	O
in	O
the	O
target	O
,	O
with	O
the	O
predictions	O
slowly	O
approaching	O
the	O
true	O
value	O
of	O
the	O
SR	B-Method
.	O
	
If	O
pessimistically	O
initialized	O
,	O
as	O
traditionally	O
done	O
,	O
the	O
estimates	O
of	O
the	O
SR	B-Method
approach	O
the	O
target	O
from	O
below	O
.	O
	
In	O
this	O
sense	O
,	O
the	O
number	O
of	O
times	O
a	O
prediction	O
has	O
been	O
updated	O
in	O
a	O
given	O
state	O
is	O
a	O
good	O
proxy	O
to	O
estimate	O
how	O
far	O
this	O
prediction	O
is	O
from	O
its	O
final	O
target	O
.	O
	
From	O
the	O
definition	O
above	O
we	O
can	O
see	O
that	O
the	O
SSR	B-Method
have	O
similar	O
properties	O
.	O
	
It	O
underestimates	O
the	O
true	O
target	O
but	O
slowly	O
approaches	O
it	O
,	O
converging	O
to	O
the	O
true	O
SR	B-Method
in	O
the	O
limit	O
.	O
	
The	O
SSR	B-Method
simplifies	O
the	O
analysis	O
by	O
not	O
taking	O
bootstrapping	O
into	O
consideration	O
.	O
	
The	O
theorem	O
below	O
formalizes	O
the	O
idea	O
that	O
the	O
norm	O
of	O
the	O
SSR	B-Method
implicitly	O
counts	O
state	O
visitation	O
,	O
shedding	O
some	O
light	O
on	O
why	O
the	O
exploration	O
bonus	O
we	O
propose	O
works	O
so	O
well	O
.	O
	
theorem	O
:	O
.	O
	
Let	O
⁢n	O
(	O
s	O
)	O
denote	O
the	O
number	O
of	O
times	O
state	O
s	O
has	O
been	O
visited	O
and	O
let	O
~Ψπ	O
denote	O
the	O
substochastic	B-Method
successor	I-Method
representation	I-Method
as	O
in	O
Definition	O
.	O
	
For	O
a	O
given	O
0≤γ<1	O
,	O
	
proof	O
:	O
Proof	O
of	O
Theorem	O
[	O
reference	O
]	O
.	O
	
Let	O
be	O
the	O
empirical	O
transition	O
matrix	O
.	O
	
We	O
first	O
rewrite	O
in	O
terms	O
of	O
:	O
This	O
expression	O
can	O
also	O
be	O
written	O
in	O
matrix	O
form	O
:	O
,	O
where	O
denotes	O
the	O
diagonal	O
matrix	O
of	O
augmented	O
inverse	O
counts	O
.	O
	
Expanding	O
we	O
have	O
:	O
The	O
top	O
eigenvector	O
of	O
a	O
stochastic	O
matrix	O
is	O
the	O
all	O
-	O
ones	O
vector	O
,	O
meyn12markov	O
,	O
and	O
it	O
corresponds	O
to	O
the	O
eigenvalue	O
1	O
.	O
	
Using	O
this	O
fact	O
and	O
the	O
definition	O
of	O
with	O
respect	O
to	O
we	O
have	O
:	O
We	O
can	O
now	O
bound	O
the	O
term	O
using	O
the	O
fact	O
that	O
is	O
also	O
the	O
top	O
eigenvector	O
of	O
the	O
successor	B-Method
representation	I-Method
and	O
has	O
eigenvalue	O
Machado18b	O
:	O
Plugging	O
(	O
[	O
reference	O
]	O
)	O
into	O
the	O
definition	O
of	O
the	O
SR	B-Method
we	O
have	O
	
(	O
notice	O
that	O
)	O
:	O
	
When	O
we	O
also	O
use	O
the	O
other	O
bound	O
on	O
the	O
quadratic	O
term	O
we	O
conclude	O
that	O
,	O
for	O
any	O
state	O
,	O
∎	O
	
In	O
other	O
words	O
,	O
the	O
SSR	B-Method
,	O
obtained	O
after	O
a	O
slight	O
change	O
to	O
the	O
SR	B-Method
,	O
can	O
be	O
used	O
to	O
recover	O
state	O
visitation	O
counts	O
.	O
	
The	O
intuition	O
behind	O
this	O
result	O
is	O
that	O
the	O
phantom	O
transition	O
,	O
represented	O
by	O
the	O
in	O
the	O
denominator	O
of	O
the	O
SSR	B-Method
,	O
serves	O
as	O
a	O
proxy	O
for	O
the	O
uncertainty	O
about	O
that	O
state	O
by	O
underestimating	O
the	O
SR	B-Method
.	O
	
This	O
is	O
due	O
to	O
the	O
fact	O
that	O
gets	O
closer	O
to	O
each	O
time	O
state	O
is	O
visited	O
.	O
	
As	O
a	O
sanity	O
check	O
,	O
we	O
used	O
this	O
result	O
to	O
implement	O
a	O
simple	O
model	B-Method
-	I-Method
based	I-Method
algorithm	I-Method
that	O
penalizes	O
the	O
agent	O
for	O
visiting	O
commonly	O
visited	O
states	O
with	O
the	O
exploration	O
bonus	O
.	O
	
Thus	O
,	O
our	O
agent	O
actually	O
maximizes	O
,	O
with	O
being	O
a	O
scaling	O
parameter	O
.	O
	
The	O
shift	O
in	O
the	O
theorem	O
has	O
no	O
effect	O
in	O
the	O
agent	O
’s	O
policy	O
because	O
it	O
is	O
the	O
same	O
across	O
all	O
states	O
.	O
	
In	O
this	O
algorithm	O
the	O
agent	O
updates	O
its	O
transition	B-Method
probability	I-Method
model	I-Method
and	O
reward	B-Method
model	I-Method
through	O
Equation	O
[	O
reference	O
]	O
and	O
its	O
SSR	B-Method
estimate	O
as	O
in	O
Definition	O
[	O
reference	O
]	O
.	O
	
Table	O
[	O
reference	O
]	O
depicts	O
the	O
performance	O
of	O
this	O
algorithm	O
,	O
dubbed	O
ESSR	B-Method
,	O
as	O
well	O
as	O
the	O
performance	O
of	O
some	O
algorithms	O
with	O
polynomial	B-Metric
sample	I-Metric
-	I-Metric
complexity	I-Metric
bounds	I-Metric
.	O
	
The	O
goal	O
with	O
this	O
evaluation	O
is	O
not	O
to	O
outperform	O
these	O
algorithms	O
,	O
but	O
to	O
evaluate	O
how	O
well	O
ESSR	B-Method
performs	O
when	O
compared	O
to	O
algorithms	O
that	O
explicitly	O
keep	O
visitation	O
counts	O
to	O
promote	O
exploration	B-Task
.	O
	
ESSR	B-Method
performs	O
as	O
well	O
as	O
R	B-Method
-	I-Method
Max	I-Method
Brafman02	O
and	O
E	O
Kearns02	O
on	O
RiverSwim	O
and	O
it	O
outperforms	O
these	O
algorithms	O
on	O
SixArms	O
;	O
while	O
MBIE	B-Method
Strehl08	O
,	O
which	O
explicitly	O
estimates	O
confidence	O
intervals	O
over	O
the	O
expected	O
return	O
in	O
each	O
state	O
,	O
outperforms	O
ESSR	B-Method
in	O
these	O
domains	O
.	O
	
These	O
results	O
clearly	O
show	O
that	O
ESSR	B-Method
performs	O
,	O
on	O
average	O
,	O
similarly	O
to	O
other	O
algorithms	O
with	O
PAC	B-Method
-	I-Method
MDP	I-Method
guarantees	I-Method
,	O
suggesting	O
that	O
the	O
norm	O
of	O
the	O
SSR	B-Method
is	O
a	O
promising	O
exploration	O
bonus	O
.	O
	
Additional	O
details	O
about	O
the	O
algorithm	O
and	O
the	O
experimental	O
methodology	O
are	O
available	O
in	O
the	O
Appendix	O
.	O
	
section	O
:	O
Counting	O
Feature	O
Activations	O
with	O
the	O
SR	B-Method
	
In	O
large	O
environments	O
,	O
where	O
enumerating	O
all	O
states	O
is	O
not	O
an	O
option	O
,	O
directly	O
using	O
Sarsa	B-Method
+	O
SR	B-Method
as	O
described	O
in	O
the	O
previous	O
section	O
is	O
not	O
viable	O
.	O
	
Learning	O
the	O
SR	B-Method
becomes	O
even	O
more	O
challenging	O
when	O
the	O
representation	B-Task
,	O
,	O
is	O
also	O
being	O
learned	O
.	O
	
Using	O
neural	B-Method
networks	I-Method
to	O
learn	O
a	O
representation	O
while	O
learning	O
to	O
estimate	O
state	B-Method
-	I-Method
action	I-Method
value	I-Method
function	I-Method
is	O
the	O
approach	O
that	O
currently	O
often	O
leads	O
to	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
in	O
the	O
field	O
.	O
	
In	O
this	O
section	O
we	O
describe	O
an	O
algorithm	O
that	O
uses	O
the	O
same	O
ideas	O
described	O
so	O
far	O
but	O
in	O
the	O
function	B-Task
approximation	I-Task
setting	I-Task
.	O
	
Our	O
algorithm	O
was	O
inspired	O
by	O
recent	O
work	O
that	O
have	O
shown	O
that	O
successor	O
features	O
can	O
be	O
learned	O
jointly	O
with	O
the	O
feature	B-Method
representation	I-Method
itself	O
Kulkarni16	O
,	O
Machado18b	O
.	O
	
An	O
overview	O
of	O
the	O
neural	B-Method
network	I-Method
we	O
used	O
to	O
learn	O
the	O
agent	O
’s	O
value	O
function	O
while	O
also	O
learning	O
the	O
feature	B-Method
representation	I-Method
and	O
the	O
SR	B-Method
is	O
depicted	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
The	O
layers	O
used	O
to	O
compute	O
the	O
state	O
-	O
action	O
value	O
function	O
,	O
,	O
are	O
structured	O
as	O
in	O
DQN	B-Method
Mnih15	O
,	O
but	O
with	O
different	O
numbers	O
of	O
parameters	O
(	O
i	O
..	O
	
e	O
,	O
filter	O
sizes	O
,	O
stride	O
,	O
and	O
number	O
of	O
nodes	O
)	O
.	O
	
This	O
was	O
done	O
to	O
match	O
Oh15	B-Method
’s	I-Method
(	O
Oh15	B-Method
)	O
architecture	O
,	O
which	O
is	O
known	O
to	O
succeed	O
in	O
the	O
auxiliary	B-Task
task	I-Task
of	O
predicting	O
the	O
agent	O
’s	O
next	O
observation	O
,	O
which	O
we	O
detail	O
below	O
.	O
	
From	O
here	O
on	O
,	O
we	O
call	O
the	O
part	O
of	O
our	O
architecture	O
that	O
predicts	O
DQN	B-Method
to	O
distinguish	O
between	O
the	O
parameters	O
of	O
this	O
network	O
and	O
DQN	B-Method
.	O
	
It	O
is	O
trained	O
to	O
minimize	O
with	O
and	O
being	O
defined	O
as	O
This	O
loss	O
is	O
known	O
as	O
the	O
mixed	B-Method
Monte	I-Method
-	I-Method
Carlo	I-Method
return	I-Method
(	O
MMC	B-Method
)	O
and	O
it	O
has	O
been	O
used	O
in	O
the	O
past	O
by	O
the	O
algorithms	O
that	O
achieved	O
succesful	O
exploration	O
in	O
deep	B-Task
reinforcement	I-Task
learning	I-Task
Bellemare16	O
,	O
Ostrovski17	O
.	O
	
The	O
distinction	O
between	O
and	O
is	O
standard	O
in	O
the	O
field	O
,	O
with	O
denoting	O
the	O
parameters	O
of	O
the	O
target	O
network	O
,	O
which	O
is	O
updated	O
less	O
often	O
for	O
stability	B-Task
purposes	I-Task
Mnih15	I-Task
.	O
	
As	O
before	O
,	O
we	O
use	O
to	O
denote	O
the	O
exploration	O
bonus	O
obtained	O
from	O
the	O
successor	O
features	O
of	O
the	O
internal	B-Method
representation	I-Method
,	O
,	O
which	O
will	O
be	O
defined	O
below	O
.	O
	
Moreover	O
,	O
to	O
ensure	O
all	O
features	O
are	O
in	O
the	O
same	O
range	O
,	O
we	O
normalize	O
the	O
feature	O
vector	O
so	O
that	O
.	O
	
In	O
Fig	O
.	O
	
[	O
reference	O
]	O
	
we	O
highlight	O
with	O
the	O
layer	O
in	O
which	O
we	O
normalize	O
its	O
output	O
.	O
	
Notice	O
that	O
the	O
features	O
are	O
always	O
non	O
-	O
negative	O
due	O
to	O
the	O
use	O
of	O
ReLU	O
gates	O
.	O
	
The	O
successor	O
features	O
,	O
,	O
at	O
the	O
bottom	O
of	O
the	O
diagram	O
,	O
are	O
obtained	O
by	O
minimizing	O
the	O
loss	O
Zero	O
is	O
a	O
fixed	O
point	O
for	O
the	O
SR	B-Method
,	O
which	O
is	O
particularly	O
concerning	O
in	O
settings	O
with	O
sparse	O
rewards	O
.	O
	
The	O
agent	O
might	O
end	O
up	O
learning	O
to	O
set	O
to	O
achieve	O
zero	O
loss	O
.	O
	
We	O
address	O
this	O
problem	O
by	O
not	O
propagating	O
to	O
(	O
this	O
is	O
depicted	O
in	O
Figure	O
[	O
reference	O
]	O
as	O
an	O
open	O
circle	O
stopping	O
the	O
gradient	O
)	O
;	O
and	O
by	O
creating	O
an	O
auxiliary	B-Task
task	I-Task
Jaderberg17	O
to	O
encourage	O
a	O
representation	O
to	O
be	O
learned	O
before	O
a	O
non	O
-	O
zero	O
reward	O
is	O
observed	O
.	O
	
As	O
Machado18b	O
,	O
we	O
use	O
the	O
auxiliary	B-Task
task	I-Task
of	O
predicting	O
the	O
next	O
observation	O
,	O
learned	O
through	O
the	O
architecture	O
proposed	O
by	O
Oh15	B-Method
,	O
which	O
is	O
depicted	O
as	O
the	O
top	O
layers	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
The	O
loss	O
we	O
minimize	O
for	O
this	O
last	O
part	O
of	O
the	O
network	O
is	O
The	O
overall	O
loss	O
minimized	O
by	O
the	O
network	O
is	O
The	O
last	O
step	O
in	O
describing	O
our	O
algorithm	O
is	O
to	O
define	O
,	O
the	O
intrinsic	O
reward	O
we	O
use	O
to	O
encourage	O
exploration	B-Task
.	O
	
We	O
choose	O
the	O
exploration	O
bonus	O
to	O
be	O
the	O
inverse	O
of	O
the	O
-	O
norm	O
of	O
the	O
vector	O
of	O
successor	O
features	O
of	O
the	O
current	O
state	O
,	O
as	O
in	O
Sarsa	B-Method
+	O
SR	B-Method
.	O
	
That	O
is	O
,	O
where	O
denotes	O
the	O
successor	O
features	O
of	O
state	O
parametrized	O
by	O
.	O
	
The	O
exploration	O
bonus	O
comes	O
from	O
the	O
same	O
intuition	O
presented	O
in	O
the	O
previous	O
section	O
(	O
we	O
observed	O
in	O
preliminary	O
experiments	O
not	O
discussed	O
here	O
that	O
DQN	B-Method
performs	O
better	O
when	O
dealing	O
with	O
positive	O
rewards	O
)	O
.	O
	
Moreover	O
,	O
we	O
use	O
the	O
-	O
norm	O
of	O
the	O
SR	B-Method
instead	O
of	O
the	O
-	O
norm	O
,	O
which	O
was	O
used	O
so	O
far	O
.	O
	
This	O
mismatch	O
is	O
further	O
discussed	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
It	O
was	O
driven	O
by	O
the	O
-	O
norm	O
leading	O
to	O
slightly	O
better	O
performance	O
.	O
	
A	O
complete	O
description	O
of	O
the	O
network	B-Method
architecture	I-Method
is	O
available	O
in	O
the	O
Appendix	O
.	O
	
section	O
:	O
Evaluation	O
of	O
Exploration	B-Task
in	O
Deep	B-Task
RL	I-Task
	
We	O
evaluated	O
our	O
algorithm	O
on	O
the	O
Arcade	O
Learning	O
Environment	O
Bellemare13	O
.	O
	
Following	O
Bellemare16	O
’s	O
(	O
Bellemare16	O
)	O
taxonomy	O
,	O
we	O
focused	O
on	O
the	O
Atari	B-Material
2600	I-Material
games	I-Material
with	O
sparse	O
rewards	O
that	O
pose	O
hard	B-Task
exploration	I-Task
problems	I-Task
.	O
	
They	O
are	O
:	O
Freeway	O
,	O
Gravitar	O
,	O
Montezuma	B-Material
’s	I-Material
Revenge	I-Material
,	O
Private	O
Eye	O
,	O
Solaris	O
,	O
and	O
Venture	O
.	O
	
We	O
used	O
the	O
evaluation	O
protocol	O
proposed	O
by	O
Machado18a	O
.	O
	
We	O
used	O
Montezuma	B-Material
’s	I-Material
Revenge	I-Material
to	O
tune	O
our	O
parameters	O
.	O
	
The	O
reported	O
results	O
are	O
the	O
average	O
over	O
10	O
seeds	O
after	O
100	O
million	O
frames	O
.	O
	
We	O
evaluated	O
our	O
agents	O
in	O
the	O
stochastic	B-Task
setting	I-Task
(	O
sticky	O
actions	O
,	O
)	O
using	O
a	O
frame	O
skip	O
of	O
with	O
the	O
full	O
action	O
set	O
(	O
)	O
.	O
	
The	O
agent	O
learns	O
from	O
raw	O
pixels	O
i.e.	O
,	O
it	O
uses	O
the	O
game	O
screen	O
as	O
input	O
.	O
	
Our	O
results	O
were	O
obtained	O
with	O
the	O
algorithm	O
described	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
We	O
set	O
after	O
a	O
rough	O
sweep	O
over	O
values	O
in	O
the	O
game	O
Montezuma	B-Material
’s	I-Material
Revenge	I-Material
.	O
	
We	O
annealed	O
in	O
DQN	B-Method
’s	O
-	O
greedy	O
exploration	O
over	O
the	O
first	O
million	O
steps	O
,	O
starting	O
at	O
and	O
stopping	O
at	O
as	O
done	O
by	O
Bellemare16	O
.	O
	
We	O
trained	O
the	O
network	O
with	O
RMSprop	B-Method
with	O
a	O
step	O
-	O
size	O
of	O
,	O
an	O
value	O
of	O
,	O
and	O
a	O
decay	O
of	O
,	O
which	O
are	O
the	O
standard	O
parameters	O
for	O
training	O
DQN	B-Method
Mnih15	O
.	O
	
The	O
discount	O
factor	O
,	O
,	O
is	O
set	O
to	O
and	O
,	O
,	O
.	O
	
The	O
weights	O
,	O
,	O
and	O
were	O
set	O
so	O
that	O
the	O
loss	O
functions	O
would	O
be	O
roughly	O
the	O
same	O
scale	O
.	O
	
All	O
other	O
parameters	O
are	O
the	O
same	O
as	O
those	O
used	O
by	O
Mnih15	O
.	O
	
subsection	O
:	O
Overall	O
Performance	O
and	O
Baselines	O
	
Table	O
[	O
reference	O
]	O
summarizes	O
the	O
results	O
after	O
100	O
million	O
frames	O
.	O
	
The	O
performance	O
of	O
other	O
algorithms	O
is	O
also	O
provided	O
for	O
reference	O
.	O
	
Notice	O
we	O
are	O
reporting	O
learning	B-Task
performance	O
for	O
all	O
algorithms	O
instead	O
of	O
the	O
maximum	O
scores	O
achieved	O
by	O
the	O
algorithm	O
.	O
	
We	O
use	O
the	O
superscript	O
to	O
distinguish	O
between	O
the	O
algorithms	O
that	O
use	O
MMC	B-Method
from	O
those	O
that	O
do	O
not	O
.	O
	
When	O
comparing	O
our	O
algorithm	O
,	O
DQN	B-Method
+	O
SR	B-Method
,	O
to	O
DQN	B-Method
we	O
can	O
see	O
how	O
much	O
our	O
approach	O
improves	O
over	O
the	O
most	O
traditional	O
baseline	O
.	O
	
By	O
comparing	O
our	O
algorithm	O
’s	O
performance	O
to	O
DQN	B-Method
+	O
CTS	B-Method
Bellemare16	O
and	O
DQN	B-Method
	
+	O
PixelCNN	B-Method
Ostrovski17	O
	
we	O
compare	O
our	O
algorithm	O
to	O
established	O
baselines	O
for	O
exploration	B-Task
that	O
are	O
closer	O
to	O
our	O
method	O
.	O
	
By	O
comparing	O
our	O
algorithm	O
’s	O
performance	O
to	O
Random	B-Method
Network	I-Method
Distillation	I-Method
[	O
	
RND;	O
][]	O
Burda19	O
we	O
compare	O
our	O
algorithm	O
to	O
the	O
most	O
recent	O
paper	O
in	O
the	O
field	O
with	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
.	O
	
As	O
mentioned	O
in	O
Section	O
[	O
reference	O
]	O
,	O
the	O
parameters	O
of	O
the	O
network	O
we	O
used	O
are	O
different	O
from	O
those	O
used	O
in	O
the	O
traditional	O
DQN	B-Method
network	O
,	O
so	O
we	O
also	O
compared	O
the	O
performance	O
of	O
our	O
algorithm	O
to	O
the	O
performance	O
of	O
the	O
same	O
network	O
our	O
algorithm	O
uses	O
but	O
without	O
the	O
additional	O
modules	O
(	O
next	B-Method
state	I-Method
prediction	I-Method
and	O
successor	B-Method
representation	I-Method
)	O
by	O
setting	O
and	O
without	O
the	O
intrinsic	O
reward	O
bonus	O
by	O
setting	O
.	O
	
The	O
column	O
labeled	O
DQN	B-Method
contains	O
the	O
results	O
for	O
this	O
baseline	O
.	O
	
This	O
comparison	O
allows	O
us	O
to	O
explicitly	O
quantify	O
the	O
improvement	O
provided	O
by	O
the	O
proposed	O
exploration	B-Method
bonus	I-Method
.	O
	
The	O
learning	O
curves	O
of	O
these	O
algorithms	O
and	O
their	O
performance	O
after	O
different	O
amounts	O
of	O
experience	O
are	O
available	O
in	O
the	O
Appendix	O
.	O
	
We	O
can	O
clearly	O
see	O
that	O
our	O
algorithm	O
achieves	O
scores	O
much	O
higher	O
than	O
those	O
achieved	O
by	O
DQN	B-Method
,	O
which	O
struggles	O
in	O
games	B-Task
that	O
pose	O
hard	B-Task
exploration	I-Task
problems	I-Task
.	O
	
Moreover	O
,	O
by	O
comparing	O
DQN	B-Method
+	O
SR	B-Method
to	O
DQN	B-Method
we	O
can	O
see	O
that	O
the	O
provided	O
exploration	O
bonus	O
has	O
a	O
big	O
impact	O
in	O
the	O
game	O
Montezuma	B-Material
’s	I-Material
Revenge	I-Material
,	O
which	O
is	O
probably	O
known	O
as	O
the	O
hardest	O
game	O
among	O
those	O
we	O
used	O
in	O
our	O
evaluation	O
,	O
and	O
the	O
only	O
game	O
where	O
agents	O
do	O
not	O
learn	O
how	O
to	O
achieve	O
scores	O
greater	O
than	O
zero	O
with	O
random	B-Method
exploration	I-Method
.	O
	
Interestingly	O
,	O
the	O
change	O
in	O
architecture	O
and	O
the	O
use	O
of	O
MMC	B-Method
leads	O
to	O
a	O
big	O
improvement	O
in	O
games	B-Task
such	O
as	O
Gravitar	B-Task
and	O
Venture	B-Task
,	O
which	O
we	O
can	O
not	O
fully	O
explain	O
.	O
	
However	O
,	O
notice	O
that	O
the	O
change	O
in	O
architecture	O
does	O
not	O
have	O
any	O
effect	O
in	O
Montezuma	B-Material
’s	I-Material
Revenge	I-Material
.	O
	
The	O
proposed	O
exploration	O
bonus	O
seems	O
to	O
be	O
essential	O
in	O
games	O
with	O
very	O
sparse	O
rewards	O
.	O
	
We	O
also	O
compared	O
our	O
algorithm	O
to	O
DQN	B-Method
+	O
CTS	B-Method
and	O
DQN	B-Method
+	O
PixelCNN	B-Method
.	O
	
We	O
can	O
observe	O
that	O
,	O
on	O
average	O
,	O
DQN	B-Method
+	O
SR	B-Method
outperforms	O
these	O
algorithms	O
while	O
being	O
simpler	O
since	O
it	O
does	O
not	O
require	O
a	O
density	B-Method
model	I-Method
.	O
	
Instead	O
,	O
our	O
algorithm	O
requires	O
the	O
SR	B-Method
,	O
which	O
is	O
domain	O
-	O
independent	O
as	O
it	O
is	O
already	O
defined	O
for	O
every	O
problem	O
since	O
it	O
is	O
a	O
component	O
of	O
the	O
value	B-Method
function	I-Method
estimates	I-Method
,	O
as	O
discussed	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Finally	O
,	O
DQN	B-Method
+	O
SR	B-Method
also	O
outperforms	O
RND	B-Method
Burda19	O
when	O
it	O
is	O
trained	O
for	O
100	O
million	O
frames	O
.	O
	
Importantly	O
,	O
RND	B-Method
is	O
currently	O
considered	O
to	O
be	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
approach	O
for	O
exploration	B-Task
in	O
Atari	B-Material
2600	I-Material
games	I-Material
.	O
	
Burda19	O
did	O
not	O
evaluate	O
RND	B-Method
in	O
Freeway	O
.	O
	
Details	O
about	O
how	O
the	O
RND	B-Method
performance	O
was	O
obtained	O
are	O
avaiable	O
in	O
the	O
Appendix	O
.	O
	
subsection	O
:	O
Evaluating	O
the	O
Impact	O
of	O
the	O
Auxiliary	B-Task
Task	I-Task
	
While	O
the	O
results	O
depicted	O
in	O
Table	O
3	O
allow	O
us	O
to	O
clearly	O
see	O
the	O
benefit	O
of	O
using	O
an	O
exploration	O
bonus	O
derived	O
from	O
the	O
SR	B-Method
,	O
they	O
do	O
not	O
inform	O
us	O
about	O
the	O
impact	O
of	O
the	O
auxiliary	B-Task
task	I-Task
in	O
the	O
results	O
.	O
	
The	O
experiments	O
in	O
this	O
section	O
aim	O
at	O
addressing	O
this	O
issue	O
.	O
	
We	O
focus	O
on	O
Montezuma	B-Material
’s	I-Material
Revenge	I-Material
because	O
it	O
is	O
the	O
game	O
where	O
the	O
problem	O
of	O
exploration	B-Task
is	O
maximized	O
,	O
with	O
most	O
algorithms	O
not	O
being	O
able	O
to	O
do	O
anything	O
without	O
an	O
exploration	O
bonus	O
.	O
	
The	O
first	O
question	O
we	O
asked	O
was	O
whether	O
the	O
auxiliary	B-Task
task	I-Task
was	O
necessary	O
in	O
our	O
algorithm	O
.	O
	
We	O
evaluated	O
this	O
by	O
dropping	O
the	O
reconstruction	B-Method
module	I-Method
from	O
the	O
network	O
to	O
test	O
whether	O
the	O
initial	O
random	O
noise	O
generated	O
by	O
the	O
SR	B-Method
is	O
enough	O
to	O
drive	O
representation	B-Task
learning	I-Task
.	O
	
It	O
is	O
not	O
.	O
	
When	O
dropping	O
the	O
auxiliary	B-Task
task	I-Task
,	O
the	O
average	O
performance	O
of	O
this	O
baseline	O
over	O
4	O
seeds	O
in	O
Montezuma	B-Material
’s	I-Material
Revenge	I-Material
after	O
million	O
frames	O
was	O
points	O
(	O
=	O
;	O
min	O
:	O
,	O
	
max	O
:	O
)	O
.	O
	
As	O
comparison	O
,	O
our	O
algorithm	O
obtains	O
points	O
(	O
=	O
,	O
min	O
:	O
,	O
max	O
:	O
)	O
.	O
	
These	O
results	O
suggest	O
that	O
auxiliary	B-Task
tasks	I-Task
seem	O
to	O
be	O
necessary	O
for	O
our	O
method	O
to	O
perform	O
well	O
.	O
	
We	O
also	O
evaluated	O
whether	O
the	O
auxiliary	B-Task
task	I-Task
was	O
sufficient	O
to	O
generate	O
the	O
results	O
we	O
observed	O
.	O
	
To	O
do	O
so	O
we	O
dropped	O
the	O
SR	B-Method
module	O
and	O
set	O
to	O
evaluate	O
whether	O
our	O
exploration	O
bonus	O
was	O
actually	O
improving	O
the	O
agent	O
’s	O
performance	O
or	O
whether	O
the	O
auxiliary	O
task	O
was	O
doing	O
it	O
.	O
	
The	O
exploration	O
bonus	O
seems	O
to	O
be	O
essential	O
.	O
	
When	O
dropping	O
the	O
exploration	O
bonus	O
and	O
the	O
SR	B-Method
module	O
,	O
the	O
average	O
performance	O
of	O
this	O
baseline	O
over	O
4	O
seeds	O
in	O
Montezuma	B-Material
’s	I-Material
Revenge	I-Material
after	O
million	O
frames	O
was	O
points	O
(	O
=	O
;	O
min	O
:	O
,	O
	
max	O
:	O
)	O
.	O
	
Again	O
,	O
clearly	O
,	O
the	O
auxiliary	B-Task
task	I-Task
is	O
not	O
a	O
sufficient	O
condition	O
for	O
the	O
performance	O
we	O
report	O
.	O
	
The	O
reported	O
results	O
use	O
the	O
same	O
parameters	O
as	O
before	O
.	O
	
Learning	O
curves	O
for	O
each	O
run	O
are	O
available	O
in	O
the	O
Appendix	O
.	O
	
subsection	O
:	O
On	O
the	O
Mismatch	O
between	O
the	O
Used	O
Norms	O
	
As	O
aforementioned	O
,	O
there	O
is	O
a	O
mismatch	O
between	O
theory	O
and	O
practice	O
when	O
looking	O
at	O
the	O
deep	B-Method
RL	I-Method
algorithm	I-Method
we	O
introduced	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
While	O
DQN	B-Method
+	O
SR	B-Method
uses	O
the	O
-	O
norm	O
of	O
the	O
SR	B-Method
to	O
generate	O
the	O
exploration	O
bonus	O
,	O
our	O
theoretical	O
result	O
is	O
stated	O
with	O
respect	O
to	O
the	O
-	O
norm	O
of	O
the	O
SR	B-Method
.	O
	
This	O
mismatch	O
was	O
driven	O
by	O
the	O
fact	O
that	O
,	O
empirically	O
,	O
DQN	B-Method
+	O
SR	B-Method
exhibits	O
a	O
slightly	O
better	O
performance	O
when	O
using	O
the	O
-	O
norm	O
of	O
the	O
SR	B-Method
instead	O
of	O
the	O
-	O
norm	O
.	O
	
We	O
conjecture	O
this	O
might	O
be	O
due	O
to	O
the	O
fact	O
that	O
the	O
-	O
norm	O
is	O
smoother	O
than	O
the	O
-	O
norm	O
,	O
a	O
property	O
that	O
is	O
particularly	O
important	O
when	O
training	O
neural	B-Method
networks	I-Method
.	O
	
Table	O
[	O
reference	O
]	O
depicts	O
a	O
comparison	O
between	O
the	O
performance	O
of	O
DQN	B-Method
+	O
SR	B-Method
when	O
using	O
the	O
-	O
norm	O
and	O
the	O
-	O
norm	O
of	O
the	O
SR	B-Method
to	O
generate	O
its	O
exploration	O
bonus	O
(	O
is	O
normalized	O
with	O
the	O
respective	O
norm	O
)	O
.	O
	
We	O
followed	O
the	O
same	O
evaluation	O
protocol	O
described	O
before	O
,	O
averaging	O
the	O
performance	O
of	O
DQN	B-Method
+	O
SR	B-Method
with	O
the	O
-	O
norm	O
over	O
10	O
runs	O
.	O
	
The	O
parameter	O
is	O
the	O
only	O
parameter	O
not	O
shared	O
by	O
both	O
algorithms	O
.	O
	
While	O
when	O
using	O
the	O
-	O
norm	O
of	O
the	O
SR	B-Method
,	O
when	O
using	O
the	O
-	O
norm	O
of	O
the	O
SR	B-Method
.	O
	
These	O
results	O
also	O
support	O
the	O
claim	O
that	O
the	O
norm	O
of	O
the	O
SR	B-Method
can	O
be	O
used	O
to	O
generate	O
exploration	O
bonuses	O
.	O
	
DQN	B-Method
+	O
SR	B-Method
,	O
when	O
using	O
the	O
-	O
norm	O
of	O
the	O
SR	B-Method
,	O
exhibits	O
performance	O
comparable	O
to	O
pseudo	B-Method
-	I-Method
count	I-Method
based	I-Method
methods	I-Method
,	O
despite	O
not	O
being	O
the	O
best	O
results	O
we	O
obtained	O
.	O
	
We	O
also	O
revisited	O
the	O
results	O
presented	O
in	O
Section	O
[	O
reference	O
]	O
to	O
evaluate	O
the	O
impact	O
of	O
the	O
different	O
norms	O
in	O
Sarsa	B-Method
+	O
SR	B-Method
.	O
	
We	O
swept	O
over	O
all	O
the	O
parameters	O
,	O
as	O
previously	O
described	O
.	O
	
The	O
results	O
reported	O
for	O
Sarsa	B-Method
+	O
SR	B-Method
when	O
using	O
the	O
-	O
norm	O
of	O
the	O
SR	B-Method
are	O
the	O
average	O
over	O
100	O
runs	O
.	O
	
The	O
actual	O
numbers	O
are	O
available	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
The	O
used	O
parameters	O
are	O
discussed	O
in	O
the	O
Appendix	O
.	O
	
Interestingly	O
,	O
we	O
observe	O
the	O
same	O
trend	O
we	O
observed	O
in	O
the	O
deep	B-Task
RL	I-Task
case	I-Task
.	O
	
The	O
-	O
norm	O
of	O
the	O
SR	B-Method
leads	O
to	O
even	O
better	O
results	O
.	O
	
The	O
fact	O
that	O
the	O
algorithms	O
proposed	O
in	O
this	O
paper	O
perform	O
better	O
when	O
using	O
the	O
-	O
norm	O
of	O
the	O
SR	B-Method
instead	O
of	O
the	O
-	O
norm	O
deserves	O
further	O
investigation	O
,	O
either	O
empirically	O
or	O
theoretically	O
.	O
	
We	O
conjecture	O
it	O
might	O
be	O
possible	O
to	O
derive	O
theoretical	O
guarantees	O
for	O
the	O
-	O
norm	O
of	O
the	O
SR	B-Method
that	O
are	O
similar	O
to	O
those	O
derived	O
here	O
.	O
	
Nevertheless	O
,	O
these	O
results	O
suggest	O
that	O
the	O
idea	O
of	O
using	O
the	O
norm	O
of	O
the	O
SR	B-Method
for	O
exploration	B-Task
is	O
quite	O
general	O
,	O
with	O
the	O
-	O
norm	O
of	O
the	O
SR	B-Method
being	O
effective	O
for	O
more	O
than	O
one	O
value	O
of	O
.	O
	
section	O
:	O
Related	O
Work	O
	
There	O
are	O
multiple	O
algorithms	O
in	O
the	O
tabular	B-Task
,	I-Task
model	I-Task
-	I-Task
based	I-Task
case	I-Task
with	O
guarantees	O
about	O
their	O
performance	O
in	O
terms	O
of	O
regret	B-Metric
bounds	I-Metric
[	O
e.g.	O
,][]	O
Osband16b	O
or	O
sample	B-Metric
-	I-Metric
complexity	I-Metric
[	O
e.g.	O
,][]	O
Brafman02	O
,	O
Kearns02	O
,	O
Strehl08	O
.	O
	
RiverSwim	O
and	O
SixArms	O
are	O
domains	O
traditionally	O
used	O
when	O
evaluating	O
these	O
algorithms	O
.	O
	
In	O
this	O
paper	O
we	O
have	O
introduced	O
a	O
model	B-Method
-	I-Method
free	I-Method
algorithm	I-Method
that	O
performs	O
particularly	O
well	O
in	O
these	O
domains	O
.	O
	
We	O
have	O
also	O
introduced	O
a	O
model	B-Method
-	I-Method
based	I-Method
algorithm	I-Method
that	O
performs	O
as	O
well	O
as	O
some	O
of	O
these	O
algorithms	O
with	O
theoretical	O
guarantees	O
.	O
	
Among	O
these	O
algorithms	O
,	O
R	B-Method
-	I-Method
Max	I-Method
seems	O
the	O
closest	O
approach	O
to	O
ours	O
.	O
	
As	O
with	O
R	B-Method
-	I-Method
Max	I-Method
,	O
the	O
algorithm	O
we	O
presented	O
in	O
Section	O
[	O
reference	O
]	O
augments	O
the	O
state	O
-	O
space	O
with	O
an	O
imaginary	O
state	O
and	O
encourages	O
the	O
agent	O
to	O
visit	O
that	O
state	O
,	O
implicitly	O
reducing	O
the	O
algorithm	O
	
’s	O
uncertainty	O
in	O
the	O
state	O
-	O
space	O
.	O
	
However	O
,	O
R	B-Method
-	I-Method
Max	I-Method
deletes	O
the	O
transition	O
to	O
this	O
imaginary	O
state	O
once	O
a	O
state	O
has	O
been	O
visited	O
a	O
given	O
number	O
of	O
times	O
.	O
	
Ours	O
,	O
on	O
the	O
other	O
hand	O
,	O
lets	O
the	O
probability	O
of	O
visiting	O
this	O
imaginary	O
state	O
vanish	O
with	O
additional	O
visitations	O
.	O
	
Importantly	O
,	O
notice	O
that	O
it	O
is	O
not	O
clear	O
how	O
to	O
apply	O
these	O
traditional	O
algorithms	O
such	O
as	O
R	B-Method
-	I-Method
Max	I-Method
and	O
E	B-Method
to	O
large	O
domains	O
where	O
function	B-Task
approximation	I-Task
is	O
required	O
.	O
	
Conversely	O
,	O
there	O
are	O
not	O
many	O
model	B-Method
-	I-Method
free	I-Method
approaches	I-Method
with	O
proven	O
sample	B-Metric
-	I-Metric
complexity	I-Metric
bounds	I-Metric
[	O
e.g.	O
,][]	O
Strehl06	O
,	O
but	O
there	O
are	O
multiple	O
model	B-Method
-	I-Method
free	I-Method
algorithms	I-Method
for	O
exploration	B-Task
that	O
actually	O
work	O
in	O
large	O
domains	O
[	O
e.g.	O
,][]	O
Stadie15	O
,	O
Bellemare16	O
,	O
Ostrovski17	O
,	O
Plappert18	O
,	O
Burda19	O
.	O
	
Among	O
these	O
algorithms	O
,	O
the	O
use	O
of	O
pseudo	B-Method
-	I-Method
counts	I-Method
through	O
density	B-Method
models	I-Method
is	O
the	O
closest	O
to	O
ours	O
Bellemare16	O
,	O
Ostrovski17	O
.	O
	
Inspired	O
by	O
those	O
papers	O
we	O
used	O
the	O
mixed	O
Monte	O
-	O
Carlo	O
return	O
as	O
a	O
target	O
in	O
the	O
update	B-Method
rule	I-Method
.	O
	
In	O
Section	O
[	O
reference	O
]	O
we	O
have	O
shown	O
that	O
our	O
algorithm	O
outperforms	O
these	O
approaches	O
while	O
being	O
simpler	O
by	O
not	O
requiring	O
a	O
density	B-Method
model	I-Method
.	O
	
Importantly	O
,	O
Martin17	O
had	O
already	O
shown	O
that	O
counting	O
activations	O
of	O
fixed	O
,	O
handcrafted	O
features	O
in	O
Atari	B-Material
2600	I-Material
games	I-Material
leads	O
to	O
good	O
exploration	O
behavior	O
.	O
	
Nevertheless	O
,	O
by	O
using	O
the	O
SR	B-Method
we	O
are	O
not	O
only	O
counting	O
learned	O
features	O
but	O
we	O
are	O
also	O
implicitly	O
capturing	O
the	O
induced	O
transition	O
dynamics	O
.	O
	
Finally	O
,	O
the	O
SR	B-Method
has	O
already	O
been	O
used	O
in	O
the	O
context	O
of	O
exploration	B-Task
.	O
	
However	O
,	O
it	O
was	O
used	O
to	O
help	O
the	O
agent	O
learn	O
how	O
to	O
act	O
in	O
a	O
higher	O
level	O
of	O
abstraction	O
in	O
order	O
to	O
navigate	O
through	O
the	O
state	O
space	O
faster	O
Machado18b	O
.	O
	
Such	O
an	O
approach	O
has	O
led	O
to	O
promising	O
results	O
in	O
the	O
tabular	O
case	O
but	O
only	O
anecdotal	O
evidence	O
about	O
its	O
scalability	O
has	O
been	O
provided	O
when	O
the	O
idea	O
was	O
applied	O
to	O
large	O
domains	O
such	O
as	O
Atari	B-Material
2600	I-Material
games	I-Material
.	O
	
Importantly	O
,	O
the	O
work	O
developed	O
by	O
Machado18b	O
,	O
Kulkarni16	O
and	O
Oh15	B-Method
are	O
the	O
main	O
motivation	O
for	O
the	O
neural	B-Method
network	I-Method
architecture	I-Method
presented	O
here	O
.	O
	
Oh15	B-Method
have	O
shown	O
how	O
one	O
can	O
predict	O
the	O
next	O
screen	O
given	O
the	O
current	O
observation	O
and	O
action	O
(	O
our	O
auxiliary	O
task	O
)	O
,	O
while	O
Machado18b	O
	
and	O
Kulkarni16	O
have	O
proposed	O
different	O
architectures	O
for	O
learning	O
the	O
SR	B-Method
from	O
raw	O
pixels	O
.	O
	
section	O
:	O
Conclusion	O
	
RL	B-Method
algorithms	I-Method
tend	O
to	O
have	O
high	O
sample	B-Metric
complexity	I-Metric
,	O
which	O
often	O
prevents	O
them	O
from	O
being	O
used	O
in	O
the	O
real	O
-	O
world	O
.	O
	
Poor	O
exploration	B-Method
strategies	I-Method
is	O
one	O
of	O
the	O
main	O
reasons	O
for	O
this	O
high	O
sample	B-Metric
-	I-Metric
complexity	I-Metric
.	O
	
Despite	O
all	O
of	O
its	O
shortcomings	O
,	O
uniform	B-Method
random	I-Method
exploration	I-Method
is	O
,	O
to	O
date	O
,	O
the	O
most	O
commonly	O
used	O
approach	O
for	O
exploration	B-Task
.	O
	
This	O
is	O
mainly	O
due	O
to	O
the	O
fact	O
that	O
most	O
approaches	O
for	O
tackling	O
the	O
exploration	B-Task
problem	I-Task
still	O
rely	O
on	O
domain	O
-	O
specific	O
knowledge	O
(	O
e.g.	O
,	O
density	B-Method
models	I-Method
,	O
handcrafted	O
features	O
)	O
,	O
or	O
on	O
having	O
an	O
agent	O
learn	O
a	O
perfect	O
model	O
of	O
the	O
environment	O
.	O
	
In	O
this	O
paper	O
we	O
introduced	O
a	O
general	O
method	O
for	O
exploration	B-Task
in	O
RL	B-Task
that	O
implicitly	O
counts	O
state	O
(	O
or	O
feature	O
)	O
visitation	O
in	O
order	O
to	O
guide	O
the	O
exploration	B-Task
process	I-Task
.	O
	
It	O
is	O
compatible	O
to	O
representation	B-Task
learning	I-Task
and	O
the	O
idea	O
can	O
also	O
be	O
adapted	O
to	O
be	O
applied	O
to	O
large	O
domains	O
.	O
	
This	O
result	O
opens	O
up	O
multiple	O
possibilities	O
for	O
future	O
work	O
.	O
	
Based	O
on	O
the	O
results	O
presented	O
in	O
Section	O
[	O
reference	O
]	O
,	O
for	O
example	O
,	O
we	O
conjecture	O
that	O
the	O
substochastic	B-Method
successor	I-Method
representation	I-Method
can	O
be	O
actually	O
used	O
to	O
generate	O
algorithms	O
with	O
PAC	B-Method
-	I-Method
MDP	I-Method
bounds	I-Method
.	O
	
Investigating	O
to	O
what	O
extent	O
different	O
auxiliary	O
tasks	O
impact	O
the	O
algorithm	O
	
’s	O
performance	O
,	O
and	O
whether	O
simpler	O
tasks	O
such	O
as	O
predicting	O
feature	O
activations	O
or	O
parts	O
of	O
the	O
input	O
Jaderberg17	O
are	O
effective	O
is	O
also	O
worth	O
studying	O
.	O
	
Finally	O
,	O
it	O
might	O
be	O
interesting	O
to	O
further	O
investigate	O
the	O
connection	O
between	O
representation	B-Task
learning	I-Task
and	O
exploration	B-Task
,	O
since	O
it	O
is	O
also	O
known	O
that	O
better	O
representations	O
can	O
lead	O
to	O
faster	O
exploration	B-Task
Jiang17	O
.	O
	
section	O
:	O
Acknowledgements	O
	
The	O
authors	O
would	O
like	O
to	O
thank	O
Jesse	O
Farebrother	O
for	O
the	O
initial	O
implementation	O
of	O
DQN	B-Method
used	O
in	O
this	O
paper	O
,	O
Georg	O
Ostrovski	O
for	O
the	O
discussions	O
and	O
for	O
kindly	O
providing	O
us	O
the	O
exact	O
results	O
we	O
report	O
for	O
DQNMMC	B-Method
+	O
CTS	B-Method
and	O
DQNMMC	B-Method
+	O
PixelCNN	B-Method
,	O
and	O
Yuri	O
Burda	O
for	O
kindly	O
providing	O
us	O
the	O
data	O
we	O
used	O
to	O
compute	O
the	O
performance	O
we	O
report	O
for	O
RND	B-Method
in	O
Atari	B-Material
2600	I-Material
games	I-Material
.	O
	
We	O
would	O
also	O
like	O
to	O
thank	O
Carles	O
Gelada	O
,	O
George	O
Tucker	O
and	O
Or	O
Sheffet	O
for	O
useful	O
discussions	O
,	O
as	O
well	O
as	O
the	O
anonymous	O
reviewers	O
for	O
their	O
feedback	O
.	O
	
This	O
work	O
was	O
supported	O
by	O
grants	O
from	O
Alberta	O
Innovates	O
Technology	O
Futures	O
and	O
the	O
Alberta	O
Machine	O
Intelligence	O
Institute	O
(	O
Amii	O
)	O
.	O
	
Computing	O
resources	O
were	O
provided	O
by	O
Compute	O
Canada	O
through	O
CalculQuébec	O
.	O
	
bibliography	O
:	O
References	O
	
Supplemental	O
Material	O
:	O
Count	B-Method
-	I-Method
Based	I-Method
Exploration	I-Method
with	O
the	O
Successor	B-Method
Representation	I-Method
	
This	O
document	O
contains	O
details	O
omitted	O
from	O
the	O
main	O
text	O
due	O
to	O
space	O
constraints	O
.	O
	
The	O
list	O
of	O
contents	O
is	O
below	O
:	O
Description	O
of	O
RiverSwim	O
and	O
SixArms	O
,	O
the	O
tabular	O
domains	O
we	O
used	O
in	O
our	O
evaluation	O
;	O
Details	O
about	O
the	O
methodology	O
we	O
used	O
to	O
evaluate	O
Sarsa	B-Method
and	O
Sarsa	B-Method
+	O
SR	B-Method
;	O
Pseudo	O
-	O
code	O
for	O
the	O
model	B-Method
-	I-Method
based	I-Method
algorithm	I-Method
discussed	O
in	O
Section	O
3.2	O
;	O
Detailed	O
description	O
of	O
the	O
neural	B-Method
network	I-Method
implemented	O
with	O
DQN	B-Method
+	O
SR	B-Method
;	O
Learning	B-Method
curves	I-Method
for	O
the	O
experiments	O
with	O
DQN	B-Method
and	O
DQN	B-Method
+	O
SR	B-Method
and	O
the	O
performance	O
of	O
these	O
algorithms	O
after	O
different	O
amounts	O
of	O
experience	O
in	O
the	O
Atari	B-Material
2600	I-Material
games	I-Material
used	O
in	O
our	O
evaluation	O
;	O
Learning	O
curves	O
for	O
the	O
experiments	O
designed	O
to	O
evaluate	O
the	O
role	O
of	O
the	O
auxiliary	B-Task
task	I-Task
in	O
DQN	B-Method
+	O
SR	B-Method
;	O
Details	O
about	O
how	O
we	O
computed	O
the	O
performance	O
of	O
Random	B-Method
Network	I-Method
Distillation	I-Method
(	O
RND	B-Method
)	O
;	O
Learning	B-Method
curves	I-Method
and	O
the	O
performance	O
after	O
different	O
amounts	O
of	O
experience	O
of	O
DQN	B-Method
+	O
SR	B-Method
when	O
using	O
the	O
-	O
norm	O
of	O
the	O
SR	B-Method
to	O
generate	O
the	O
exploration	O
bonus	O
.	O
	
section	O
:	O
Description	O
of	O
RiverSwim	O
and	O
SixArms	O
	
The	O
two	O
domains	O
we	O
used	O
as	O
testbed	O
to	O
evaluate	O
our	O
ideas	O
in	O
the	O
tabular	O
case	O
are	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
These	O
domains	O
are	O
the	O
same	O
used	O
by	O
Strehl08	O
.	O
	
For	O
SixArms	O
,	O
the	O
agent	O
starts	O
in	O
state	O
.	O
	
For	O
RiverSwim	B-Task
,	O
the	O
agent	O
starts	O
in	O
either	O
state	O
or	O
with	O
equal	O
probability	O
.	O
	
[	O
b	O
]	O
0.55	O
	
[	O
b	O
]	O
0.42	O
	
section	O
:	O
Methodology	O
used	O
to	O
Evaluate	O
Sarsa	B-Method
and	O
Sarsa	B-Method
+	O
SR	B-Method
	
Both	O
Sarsa	B-Method
and	O
Sarsa	B-Method
+	O
SR	B-Method
acted	O
-	O
greedily	O
,	O
maximizing	O
the	O
discounted	O
return	O
using	O
.	O
	
For	O
Sarsa	B-Method
+	O
SR	B-Method
,	O
we	O
swept	O
over	O
different	O
values	O
of	O
,	O
,	O
,	O
and	O
,	O
with	O
,	O
,	O
,	O
and	O
.	O
	
For	O
Sarsa	B-Method
,	O
we	O
swept	O
over	O
the	O
parameters	O
and	O
.	O
	
For	O
fairness	O
,	O
we	O
looked	O
at	O
a	O
finer	O
granularity	O
for	O
these	O
parameters	O
,	O
with	O
for	O
ranging	O
from	O
to	O
,	O
and	O
with	O
for	O
ranging	O
from	O
to	O
.	O
	
Table	O
[	O
reference	O
]	O
summarizes	O
the	O
parameter	O
settings	O
that	O
led	O
to	O
the	O
best	O
results	O
for	O
each	O
algorithm	O
in	O
RiverSwim	O
and	O
SixArms	O
.	O
	
section	O
:	O
Exploration	O
through	O
the	O
Substochastic	B-Method
Successor	I-Method
Representation	I-Method
	
In	O
the	O
main	O
paper	O
we	O
described	O
ESSR	B-Method
as	O
a	O
standard	O
model	B-Method
-	I-Method
based	I-Method
algorithm	I-Method
where	O
the	O
agent	O
updates	O
its	O
transition	B-Method
probability	I-Method
model	I-Method
and	O
reward	B-Method
model	I-Method
through	O
Equation	O
2	O
and	O
its	O
substochastic	B-Method
successor	I-Method
representation	I-Method
estimate	I-Method
as	O
in	O
Definition	O
3.1	O
.	O
	
The	O
pseudo	O
-	O
code	O
with	O
details	O
about	O
the	O
implementation	O
is	O
presented	O
below	O
.	O
	
[	O
h	O
]	O
Exploration	O
through	O
the	O
Substochastic	B-Method
Successor	I-Method
Representation	I-Method
(	O
ESSR	B-Method
)	O
episode	O
is	O
not	O
over	O
Observe	O
,	O
take	O
action	O
selected	O
according	O
to	O
,	O
and	O
observe	O
a	O
reward	O
and	O
a	O
next	O
state	O
each	O
state	O
PolicyIteration	O
(	O
^P	O
,+	O
^r⁢βrint	O
)	O
	
section	O
:	O
Detailed	O
Neural	B-Method
Network	I-Method
Architecture	I-Method
of	O
DQN	B-Method
+	O
SR	B-Method
	
In	O
order	O
to	O
allow	O
the	O
reader	O
to	O
focus	O
on	O
the	O
general	O
idea	O
proposed	O
in	O
the	O
paper	O
,	O
we	O
decided	O
to	O
not	O
present	O
,	O
in	O
the	O
main	O
text	O
,	O
the	O
detailed	O
description	O
of	O
the	O
architecture	O
we	O
used	O
in	O
DQN	B-Method
+	O
SR	B-Method
.	O
	
The	O
detailed	O
architecture	O
is	O
depicted	O
in	O
Figure	O
[	O
reference	O
]	O
,	O
where	O
we	O
explicitly	O
represent	O
each	O
layer	O
and	O
their	O
parameters	O
.	O
	
The	O
loss	B-Method
functions	I-Method
and	O
the	O
optimizer	B-Method
used	O
were	O
described	O
in	O
the	O
main	O
paper	O
.	O
	
The	O
only	O
other	O
important	O
information	O
is	O
regarding	O
the	O
network	O
’s	O
initialization	O
.	O
	
We	O
initialize	O
our	O
network	O
the	O
same	O
way	O
Oh15	B-Method
does	O
.	O
	
We	O
use	O
Xavier	B-Method
initialization	I-Method
Glorot10	O
in	O
all	O
layers	O
except	O
the	O
fully	O
connected	O
layers	O
around	O
the	O
element	O
-	O
wise	O
multiplication	O
denoted	O
by	O
,	O
which	O
are	O
initialized	O
uniformly	O
with	O
values	O
between	O
and	O
.	O
	
section	O
:	O
Additional	O
Results	O
for	O
DQN	B-Method
+	O
SR	B-Method
and	O
DQN	B-Method
in	O
the	O
Atari	B-Material
2600	I-Material
Games	I-Material
	
As	O
recommended	O
by	O
Machado18a	O
,	O
we	O
report	O
the	O
performance	O
of	O
DQN	B-Method
+	O
SR	B-Method
and	O
DQN	B-Method
after	O
different	O
amounts	O
of	O
experience	O
(	O
,	O
,	O
and	O
million	O
frames	O
)	O
in	O
Tables	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
.	O
	
Finally	O
,	O
Figure	O
[	O
reference	O
]	O
depicts	O
the	O
learning	O
curves	O
obtained	O
with	O
the	O
evaluated	O
algorithms	O
in	O
each	O
game	O
.	O
	
Lighter	O
lines	O
represent	O
individual	O
runs	O
while	O
the	O
solid	O
lines	O
encode	O
the	O
average	O
over	O
the	O
multiple	O
runs	O
.	O
	
[	O
b	O
]	O
0.32	O
	
[	O
b	O
]	O
0.32	O
	
[	O
b	O
]	O
0.32	O
	
[	O
b	O
]	O
0.32	O
	
[	O
b	O
]	O
0.32	O
[	O
b	O
]	O
0.32	O
	
section	O
:	O
Evaluation	O
of	O
the	O
Impact	O
of	O
the	O
Auxiliary	B-Task
Task	I-Task
in	O
DQN	B-Method
+	O
SR	B-Method
	
In	O
the	O
main	O
paper	O
we	O
also	O
evaluated	O
whether	O
the	O
introduced	O
auxiliary	B-Task
task	I-Task
was	O
necessary	O
and	O
whether	O
this	O
auxiliary	O
task	O
was	O
sufficient	O
to	O
obtain	O
the	O
performance	O
reported	O
for	O
DQN	B-Method
+	O
SR	B-Method
.	O
	
The	O
results	O
suggest	O
that	O
while	O
an	O
auxiliary	B-Task
task	I-Task
is	O
necessary	O
for	O
DQN	B-Method
+	O
SR	B-Method
,	O
it	O
is	O
definitely	O
not	O
sufficient	O
to	O
explain	O
the	O
obtained	O
performance	O
.	O
	
This	O
discussion	O
is	O
available	O
in	O
the	O
main	O
paper	O
.	O
	
Figure	O
[	O
reference	O
]	O
depicts	O
the	O
learning	O
curves	O
for	O
each	O
individual	O
run	O
.	O
	
[	O
b	O
]	O
0.31	O
[	O
b	O
]	O
0.31	O
	
section	O
:	O
On	O
the	O
Reported	O
Performance	O
of	O
Random	B-Method
Network	I-Method
Distillation	I-Method
(	O
RND	B-Method
)	O
in	O
the	O
ALE	B-Task
	
We	O
calculated	O
the	O
performance	O
of	O
RND	B-Method
from	O
the	O
data	O
used	O
by	O
Burda19	O
to	O
plot	O
Figure	O
7	O
of	O
their	O
paper	O
.	O
	
The	O
authors	O
shared	O
this	O
data	O
with	O
us	O
.	O
	
The	O
performance	O
we	O
report	O
is	O
the	O
average	O
performance	O
after	O
rollouts	O
.	O
	
Each	O
rollout	O
consists	O
of	O
128	O
time	O
steps	O
with	O
4	O
frames	O
per	O
time	O
step	O
(	O
128	O
environments	O
were	O
executed	O
in	O
parallel	O
)	O
,	O
leading	O
to	O
frames	O
.	O
	
We	O
averaged	O
the	O
performance	O
over	O
seeds	O
in	O
the	O
games	O
Gravitar	O
,	O
Private	O
Eye	O
,	O
Solaris	O
,	O
and	O
Venture	O
.	O
	
The	O
performance	O
reported	O
for	O
Montezuma	B-Material
’s	I-Material
Revenge	I-Material
is	O
the	O
average	O
over	O
seeds	O
.	O
	
section	O
:	O
The	O
Impact	O
of	O
Using	O
the	O
and	O
-	O
norm	O
of	O
the	O
SR	B-Method
in	O
DQN	B-Method
+	O
SR	B-Method
	
In	O
the	O
main	O
paper	O
we	O
evaluated	O
DQN	B-Method
+	O
SR	B-Method
using	O
both	O
the	O
-	O
and	O
-	O
norm	O
of	O
the	O
SR	B-Method
.	O
	
In	O
this	O
section	O
we	O
provide	O
additional	O
data	O
related	O
to	O
DQN	B-Method
+	O
SR	B-Method
when	O
using	O
the	O
-	O
norm	O
of	O
the	O
SR	B-Method
.	O
	
More	O
specifically	O
,	O
Table	O
[	O
reference	O
]	O
depicts	O
the	O
agent	O
	
’s	O
performance	O
after	O
different	O
amounts	O
of	O
experience	O
while	O
Figure	O
[	O
reference	O
]	O
depicts	O
the	O
full	O
learning	O
curves	O
.	O
	
Finally	O
,	O
for	O
completeness	O
,	O
Table	O
[	O
reference	O
]	O
depicts	O
the	O
agent	O
	
’s	O
performance	O
after	O
different	O
amounts	O
of	O
experience	O
for	O
DQN	B-Method
when	O
the	O
feature	B-Method
representation	I-Method
is	O
normalized	O
with	O
the	O
-	O
norm	O
instead	O
of	O
the	O
-	O
norm	O
of	O
the	O
SR	B-Method
.	O
	
[	O
b	O
]	O
0.32	O
	
[	O
b	O
]	O
0.32	O
	
[	O
b	O
]	O
0.32	O
	
[	O
b	O
]	O
0.32	O
	
[	O
b	O
]	O
0.32	O
[	O
b	O
]	O
0.32	O
	
Face	B-Task
Detection	I-Task
Using	O
Improved	O
Faster	B-Method
RCNN	I-Method
	
section	O
:	O
Abstract	O
	
Faster	O
RCNN	B-Method
has	O
achieved	O
great	O
success	O
for	O
generic	B-Task
object	I-Task
detection	I-Task
including	O
PASCAL	B-Task
object	I-Task
detection	I-Task
and	O
MS	B-Task
COCO	I-Task
object	I-Task
detection	I-Task
.	O
	
In	O
this	O
report	O
,	O
we	O
propose	O
a	O
detailed	O
designed	O
Faster	B-Method
RCNN	I-Method
method	I-Method
named	O
FDNet1.0	B-Method
for	O
face	B-Task
detection	I-Task
.	O
	
Several	O
techniques	O
were	O
employed	O
including	O
multi	B-Method
-	I-Method
scale	I-Method
training	I-Method
,	O
multi	B-Method
-	I-Method
scale	I-Method
testing	I-Method
,	O
light	B-Method
-	I-Method
designed	I-Method
RCNN	I-Method
,	O
some	O
tricks	O
for	O
inference	B-Task
and	O
a	O
vote	B-Method
-	I-Method
based	I-Method
ensemble	I-Method
method	I-Method
.	O
	
Our	O
method	O
achieves	O
two	O
1th	O
places	O
and	O
one	O
2nd	O
place	O
in	O
three	O
tasks	O
over	O
WIDER	B-Material
FACE	I-Material
validation	I-Material
dataset	I-Material
(	O
easy	B-Material
set	I-Material
,	O
medium	B-Material
set	I-Material
,	O
hard	B-Material
set	I-Material
)	O
.	O
	
section	O
:	O
	
object	B-Method
detectors	I-Method
including	O
one	O
stage	O
methods	O
(	O
e.g.	O
,	O
YOLO	O
[	O
reference	O
][	O
reference	O
],	O
SSD	O
[	O
reference	O
][	O
reference	O
]	O
)	O
and	O
two	O
stage	O
methods	O
(	O
e.g	O
.	O
,	O
Faster	O
RCNN	B-Method
[	O
reference	O
][	O
reference	O
],	O
RFCN	O
[	O
reference	O
][	O
reference	O
]	O
)	O
.	O
	
One	B-Method
stage	I-Method
methods	I-Method
refer	O
broadly	O
to	O
architectures	O
that	O
use	O
a	O
single	O
feed	B-Method
-	I-Method
forward	I-Method
full	I-Method
convolutional	I-Method
neural	I-Method
network	I-Method
to	O
directly	O
predict	O
each	O
proposal	O
's	O
class	O
and	O
corresponding	O
bounding	O
box	O
without	O
requiring	O
a	O
second	O
stage	O
per	B-Method
-	I-Method
proposal	I-Method
classification	I-Method
operation	I-Method
and	O
box	B-Method
refinement	I-Method
.	O
	
Two	O
stage	B-Method
methods	I-Method
,	O
especially	O
Faster	O
RCNN	B-Method
achieves	O
better	O
performance	O
than	O
one	O
stage	B-Method
methods	I-Method
over	O
many	O
object	B-Task
detection	I-Task
benchmarks	O
	
[	O
reference	O
][	O
reference	O
]	O
.	O
	
In	O
the	O
Faster	O
R	B-Task
-	I-Task
CNN	I-Task
setting	I-Task
,	O
object	B-Task
detection	I-Task
happens	O
over	O
two	O
pipes	O
.	O
	
In	O
the	O
first	O
pipe	O
,	O
input	O
image	O
is	O
directly	O
processed	O
by	O
a	O
feature	B-Method
extractor	I-Method
(	O
e.g.	O
,	O
Vgg16	O
[	O
reference	O
]	O
,	O
Inception	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
,	O
ResNet101	O
[	O
reference	O
]	O
)	O
without	O
any	O
hand	O
engineering	O
,	O
and	O
features	O
at	O
the	O
selected	O
intermediate	O
layer	O
(	O
e.g.	O
,	O
"conv5_3	O
	
"	O
[	O
reference	O
],	O
"res4f	O
"	O
[	O
reference	O
]	O
)	O
will	O
be	O
fed	O
to	O
a	O
convolutional	B-Method
layer	I-Method
,	O
which	O
simultaneously	O
predict	O
objectiveness	O
scores	O
and	O
region	O
bounds	O
at	O
each	O
location	O
on	O
a	O
regular	O
grid	O
according	O
to	O
predefined	O
stride	O
.	O
	
The	O
first	O
pipe	O
is	O
also	O
called	O
region	B-Method
proposal	I-Method
network	I-Method
(	O
RPN	B-Method
)	O
.	O
	
In	O
the	O
second	O
pipe	O
,	O
these	O
proposals	O
with	O
higher	O
scores	O
in	O
the	O
RPN	B-Method
are	O
used	O
to	O
crop	O
features	O
from	O
the	O
same	O
intermediate	O
feature	O
map	O
which	O
are	O
subsequently	O
fed	O
to	O
the	O
remainder	O
of	O
the	O
feature	B-Method
extractor	I-Method
(	O
e.g.	O
,	O
two	O
full	B-Method
connected	I-Method
layer	I-Method
[	O
reference	O
]	O
,	O
5th	O
block	O
[	O
reference	O
]	O
)	O
in	O
order	O
to	O
predict	O
a	O
class	O
and	O
class	O
-	O
specific	O
box	O
refinement	O
for	O
each	O
proposal	O
.	O
	
Face	B-Task
detection	I-Task
[	O
reference	O
][	O
reference	O
]	O
has	O
achieved	O
great	O
success	O
thanks	O
to	O
the	O
appearance	O
of	O
one	O
stage	B-Method
method	I-Method
and	O
two	O
stage	B-Method
methods	I-Method
.	O
	
However	O
,	O
there	O
are	O
still	O
some	O
issues	O
with	O
these	O
methods	O
that	O
can	O
be	O
improved	O
with	O
elaborate	O
design	O
of	O
the	O
details	O
.	O
	
In	O
this	O
report	O
,	O
we	O
propose	O
a	O
detailed	O
design	B-Method
Faster	I-Method
RCNN	I-Method
method	I-Method
named	O
FDNet1.0	B-Method
for	O
face	B-Task
detection	I-Task
,	O
which	O
achieves	O
more	O
decent	O
performance	O
than	O
previous	O
methods	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
	
A	O
deformable	B-Method
layer	I-Method
with	O
fewer	O
channels	O
is	O
attached	O
to	O
the	O
backbone	B-Method
network	I-Method
to	O
produce	O
a	O
"	O
thin	O
"	O
feature	O
map	O
,	O
which	O
is	O
subsequently	O
fed	O
to	O
a	O
full	B-Method
connected	I-Method
layer	I-Method
,	O
building	O
an	O
efficient	O
yet	O
accurate	O
two	O
-	O
stage	B-Method
detector	I-Method
[	O
reference	O
]	O
.	O
At	O
testing	O
time	O
,	O
we	O
also	O
find	O
a	O
comparable	O
mean	B-Metric
average	I-Metric
precision	I-Metric
(	O
mAP	B-Metric
)	O
be	O
achieved	O
when	O
the	O
top	O
-	O
ranked	O
proposals	O
(	O
e.g.	O
,	O
6000	O
)	O
are	O
directly	O
selected	O
[	O
reference	O
]	O
without	O
NMS	B-Method
in	O
the	O
RPN	B-Method
stage	I-Method
over	O
WIDER	B-Material
FACE	I-Material
dataset	I-Material
.	O
	
It	O
is	O
also	O
beneficial	O
for	O
hard	B-Material
set	I-Material
to	O
keep	O
the	O
small	O
proposals	O
(	O
<	O
16	O
pixels	O
width	O
/	O
height	O
)	O
at	O
training	O
and	O
testing	O
stage	O
as	O
there	O
are	O
many	O
tinny	O
faces	O
of	O
WIDER	B-Material
FACE	I-Material
dataset	I-Material
.	O
	
Furthermore	O
,	O
the	O
multi	B-Method
-	I-Method
scale	I-Method
training	I-Method
and	I-Method
testing	I-Method
strategy	I-Method
are	O
also	O
applied	O
in	O
our	O
work	O
.	O
	
Our	O
key	O
contributions	O
are	O
summarized	O
as	O
follows	O
:	O
(	O
1	O
)	O
A	O
light	B-Method
head	I-Method
based	I-Method
two	I-Method
-	I-Method
stage	I-Method
framework	I-Method
named	O
FDNet1.0	B-Method
is	O
developed	O
for	O
face	B-Task
detection	I-Task
.	O
	
(	O
2	O
)	O
Some	O
useful	O
tricks	O
are	O
found	O
to	O
improve	O
final	O
face	B-Task
detection	I-Task
performance	O
including	O
multi	B-Method
-	I-Method
scale	I-Method
training	I-Method
,	O
multi	B-Method
-	I-Method
scale	I-Method
testing	I-Method
,	O
keep	O
the	O
small	O
proposals	O
at	O
training	O
and	O
testing	O
stage	O
,	O
directly	O
select	O
top	O
-	O
ranked	O
proposals	O
(	O
e.g.	O
,	O
6000	O
)	O
without	O
NMS	B-Method
in	O
the	O
RPN	B-Method
stage	I-Method
for	O
R	B-Method
-	I-Method
CNN	I-Method
,	O
a	O
vote	B-Method
-	I-Method
based	I-Method
NMS	I-Method
ensemble	I-Method
strategy	I-Method
.	O
	
(	O
3	B-Method
)	I-Method
Our	I-Method
framework	I-Method
achieves	O
two	O
1st	O
places	O
and	O
one	O
2nd	O
place	O
in	O
three	O
tasks	O
over	O
WIDER	B-Material
FACE	I-Material
validation	I-Material
dataset	I-Material
(	O
easy	B-Material
,	O
medium	B-Material
,	O
hard	B-Material
)	O
,	O
one	O
illustrative	O
example	O
of	O
our	O
results	O
in	O
the	O
crowd	O
case	O
can	O
be	O
found	O
in	O
Figure	O
1	O
.	O
	
Face	B-Task
detection	I-Task
is	O
one	O
of	O
the	O
most	O
fundamental	O
and	O
challenging	O
problems	O
in	O
computer	B-Task
vision	I-Task
,	O
and	O
has	O
been	O
extensively	O
studied	O
for	O
decades	O
.	O
	
Compared	O
against	O
these	O
hand	O
-	O
engineered	O
features	O
,	O
a	O
lot	O
of	O
progress	O
for	O
face	B-Task
detection	I-Task
has	O
been	O
made	O
in	O
recent	O
years	O
due	O
to	O
utilizing	O
of	O
modern	O
object	B-Method
detectors	I-Method
,	O
including	O
Faster	B-Method
R	I-Method
-	I-Method
CNN	I-Method
,	O
R	B-Method
-	I-Method
FCN	I-Method
,	O
SSD	B-Method
,	O
YOLO	B-Method
and	O
their	O
extensions	O
.	O
	
section	O
:	O
Hand	B-Method
-	I-Method
engineered	I-Method
approaches	I-Method
:	O
	
A	O
cascaded	B-Method
AdaBoost	I-Method
face	I-Method
detector	I-Method
[	O
reference	O
]	O
is	O
proposed	O
to	O
detect	O
face	O
by	O
using	O
Haar	O
-	O
like	O
features	O
.	O
	
Based	O
on	O
this	O
groundbreaking	O
work	O
,	O
more	O
advanced	O
hand	O
-	O
engineered	O
features	O
and	O
more	O
powerful	O
machine	B-Method
learning	I-Method
algorithms	I-Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
are	O
developed	O
to	O
improve	O
face	B-Task
detection	I-Task
performance	O
.	O
	
Additionally	O
,	O
deformable	B-Method
part	I-Method
models	I-Method
(	O
DPM	B-Method
)	I-Method
is	O
also	O
employed	O
for	O
face	B-Task
detection	I-Task
by	O
several	O
research	O
groups	O
,	O
which	O
achieve	O
remarkable	O
performance	O
	
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
Single	B-Method
-	I-Method
stage	I-Method
approaches	I-Method
:	O
CascadeCNN	B-Method
[	O
reference	O
]	O
proposes	O
a	O
strategy	O
to	O
detect	O
face	B-Task
coarse	I-Task
to	I-Task
fine	I-Task
.	O
	
A	O
mutli	B-Method
-	I-Method
task	I-Method
learning	I-Method
method	I-Method
[	O
reference	O
]	O
named	O
MTCNN	B-Method
is	O
present	O
to	O
predict	O
face	B-Task
and	I-Task
landmark	I-Task
location	I-Task
simultaneously	O
.	O
	
Dense	B-Method
-	I-Method
Box	I-Method
[	O
reference	O
]	O
employs	O
a	O
fully	B-Method
deep	I-Method
convolutional	I-Method
neural	I-Method
network	I-Method
to	O
directly	O
predict	O
face	O
confidence	O
and	O
corresponding	O
bounding	O
box	O
.	O
	
UnitBox	B-Method
[	O
reference	O
]	O
introduces	O
a	O
novel	O
intersection	B-Method
-	I-Method
over	I-Method
-	I-Method
union	I-Method
(	I-Method
IoU	I-Method
)	I-Method
loss	I-Method
to	O
predict	B-Task
bounding	I-Task
box	I-Task
,	O
which	O
regresses	O
the	O
four	O
bounds	O
of	O
a	O
predicted	O
box	O
as	O
a	O
whole	O
unit	O
.	O
	
SAFD	B-Method
[	O
reference	O
]	O
and	O
RSA	O
unit	O
[	O
reference	O
]	O
	
[	O
reference	O
]	O
introduces	O
an	O
end	O
-	O
to	O
-	O
end	B-Method
multi	I-Method
-	I-Method
task	I-Method
discriminative	I-Method
learning	I-Method
framework	I-Method
to	O
increase	O
occlusion	B-Metric
robustness	I-Metric
.	O
	
Based	O
on	O
R	B-Method
-	I-Method
FCN	I-Method
[	O
reference	O
]	O
,	O
Face	B-Method
R	I-Method
-	I-Method
FCN	I-Method
[	O
reference	O
]	O
re	O
-	O
weights	O
embedding	O
responses	O
on	O
score	O
maps	O
and	O
eliminates	O
the	O
effect	O
of	O
non	O
-	O
uniformed	O
contribution	O
in	O
each	O
facial	O
part	O
using	O
a	O
position	B-Method
-	I-Method
sensitive	I-Method
average	I-Method
pooling	I-Method
.	O
	
section	O
:	O
Proposed	O
Approach	O
	
Faster	O
RCNN	B-Method
,	O
with	O
two	O
fully	B-Method
connected	I-Method
layers	I-Method
or	O
all	O
the	O
convolution	B-Method
layers	I-Method
in	O
ResNet	B-Method
5	I-Method
-	I-Method
th	I-Method
stage	I-Method
to	O
predict	O
RoI	B-Task
classification	I-Task
and	I-Task
regression	I-Task
,	O
consumes	O
a	O
large	O
memory	O
and	O
computing	O
resource	O
.	O
	
RFCN	B-Method
is	O
fully	O
convolutional	B-Method
with	O
almost	O
all	O
computation	O
shared	O
on	O
the	O
entire	O
image	O
,	O
but	O
it	O
has	O
poor	O
performance	O
compared	O
to	O
Faster	O
RCNN	B-Method
.	O
	
Inspired	O
by	O
[	O
reference	O
]	O
,	O
we	O
develop	O
a	O
light	B-Method
-	I-Method
head	I-Method
Faster	I-Method
RCNN	I-Method
for	O
face	B-Task
detection	I-Task
with	O
good	O
performance	O
and	O
inference	B-Metric
speed	I-Metric
.	O
	
In	O
this	O
section	O
,	O
we	O
will	O
present	O
our	O
method	O
in	O
detail	O
.	O
	
section	O
:	O
Light	O
-	O
Head	O
Faster	O
RCNN	B-Method
	
Based	O
on	O
Faster	O
RCNN	B-Method
,	O
we	O
make	O
several	O
effective	O
modifications	O
for	O
improving	O
detection	B-Task
performance	O
.	O
	
The	O
architecture	O
of	O
our	O
framework	O
is	O
depicted	O
in	O
Figure	O
2	O
.	O
	
ResNet	B-Method
architecture	I-Method
plays	O
the	O
role	O
of	O
feature	B-Method
extractor	I-Method
,	O
the	O
"	O
thin	O
"	O
feature	O
maps	O
is	O
built	O
by	O
a	O
deformable	B-Method
layer	I-Method
before	O
Region	B-Method
-	I-Method
of	I-Method
-	I-Method
Interest	I-Method
(	O
RoI	B-Method
)	I-Method
warping	I-Method
,	O
which	O
will	O
exploit	O
image	O
context	O
and	O
be	O
robust	O
to	O
variations	O
.	O
	
And	O
a	O
single	O
fully	B-Method
-	I-Method
connected	I-Method
layer	I-Method
is	O
used	O
in	O
the	O
R	B-Method
-	I-Method
CNN	I-Method
subnet	I-Method
.	O
	
We	O
use	O
ResNet	B-Method
-	I-Method
v1	I-Method
-	I-Method
101	I-Method
as	O
backbone	B-Method
network	I-Method
to	O
extract	O
high	O
-	O
level	O
feature	O
.	O
	
The	O
stride	B-Method
of	I-Method
ResNet	I-Method
-	I-Method
v1	I-Method
-	I-Method
101	I-Method
is	O
fixed	O
to	O
16	O
pixels	O
,	O
which	O
is	O
not	O
good	O
enough	O
for	O
detecting	O
different	O
scale	O
faces	O
.	O
	
Therefore	O
a	O
large	O
kernel	B-Method
-	I-Method
based	I-Method
deformable	I-Method
layer	I-Method
is	O
attached	O
on	O
backbone	B-Method
network	I-Method
to	O
exploit	O
image	O
context	O
and	O
be	O
robust	O
to	O
variations	O
,	O
where	O
"	O
D	O
"	O
stand	O
for	O
deformable	O
.	O
	
The	O
output	O
channel	O
size	O
of	O
the	O
deformable	B-Method
layer	I-Method
is	O
512	O
,	O
and	O
each	O
ROI	O
will	O
be	O
resized	O
to	O
512×7×7	O
,	O
which	O
will	O
be	O
fed	O
to	O
the	O
following	O
fully	B-Method
connected	I-Method
layer	I-Method
with	O
2048	O
channels	O
.	O
	
Figure2	O
.	O
	
Overview	O
of	O
our	O
approach	O
.	O
	
A	O
deformable	B-Method
layer	I-Method
with	O
512	O
channels	O
was	O
employed	O
to	O
build	O
"	O
thin	O
"	O
feature	O
maps	O
with	O
exploiting	O
image	O
context	O
simultaneously	O
before	O
RoI	O
warping	O
.	O
	
Hence	O
,	O
RCNN	B-Method
can	O
be	O
designed	O
with	O
light	O
-	O
head	O
to	O
improve	O
inference	B-Metric
speed	I-Metric
.	O
	
Additionally	O
,	O
anchors	O
are	O
carefully	O
designed	O
to	O
obtain	O
better	O
location	O
samples	O
.	O
	
The	O
aspect	O
ratio	O
is	O
set	O
to	O
1	O
,	O
1	O
.	O
based	O
on	O
statistical	B-Method
analysis	I-Method
on	O
the	O
training	O
dataset	O
.	O
	
These	O
smaller	O
anchors	O
are	O
very	O
helpful	O
for	O
sufficiently	O
capturing	O
tiny	O
face	O
.	O
	
As	O
WIDER	B-Material
FACE	I-Material
dataset	I-Material
contain	O
many	O
extremely	O
tinny	O
faces	O
(	O
<	O
16	O
pixels	O
width	O
/	O
height	O
)	O
,	O
we	O
keep	O
these	O
small	O
proposals	O
(	O
<	O
16	O
pixels	O
width	O
/	O
height	O
)	O
valid	O
in	O
the	O
training	O
and	O
testing	O
time	O
	
[	O
reference	O
]	O
.	O
The	O
experiments	O
show	O
that	O
our	O
method	O
can	O
achieve	O
better	O
performance	O
.	O
	
section	O
:	O
Multi	B-Task
-	I-Task
Scale	I-Task
Training	I-Task
and	I-Task
Testing	I-Task
	
The	O
trained	O
model	O
can	O
also	O
be	O
robust	O
on	O
different	O
scale	O
faces	O
when	O
both	O
multi	B-Method
-	I-Method
scale	I-Method
training	I-Method
and	I-Method
testing	I-Method
strategy	I-Method
are	O
used	O
.	O
	
In	O
our	O
method	O
,	O
the	O
shorter	O
side	O
is	O
resized	O
to	O
600	O
,	O
800	O
,	O
1000	O
,	O
1200	O
,	O
1400	O
pixels	O
according	O
to	O
the	O
statistical	B-Method
analysis	I-Method
on	O
the	O
training	O
dataset	O
.	O
	
Unlike	O
[	O
reference	O
]	O
,	O
we	O
only	O
use	O
horizontal	B-Method
image	I-Method
flipping	I-Method
augmentation	I-Method
,	O
and	O
no	O
other	O
hard	B-Material
example	O
mining	O
method	O
is	O
used	O
in	O
the	O
training	O
stage	O
.	O
	
In	O
the	O
testing	O
phase	O
,	O
the	O
shorter	O
side	O
of	O
each	O
image	O
is	O
also	O
resized	O
to	O
600	O
,	O
800	O
,	O
1000	O
,	O
1200	O
,	O
1400	O
pixels	O
and	O
tested	O
independently	O
.	O
	
Then	O
all	O
of	O
the	O
output	O
results	O
are	O
merged	O
.	O
	
Next	O
,	O
a	O
voted	B-Method
-	I-Method
based	I-Method
NMS	I-Method
strategy	I-Method
is	O
adapted	O
.	O
	
We	O
firstly	O
delete	O
the	O
output	O
bounding	O
box	O
whose	O
IOU	O
is	O
lower	O
than	O
0.3	O
with	O
any	O
other	O
bounding	O
boxes	O
to	O
suppress	O
false	O
positive	O
samples	O
,	O
and	O
then	O
NMS	B-Method
is	O
used	O
to	O
get	O
the	O
best	O
bounding	O
boxes	O
.	O
	
section	O
:	O
Experiments	O
	
We	O
perform	O
evaluation	O
on	O
WIDER	B-Material
FACE	I-Material
dataset	I-Material
[	O
reference	O
]	O
which	O
contains	O
more	O
challenges	O
,	O
including	O
small	O
scale	O
,	O
illumination	O
,	O
occlusion	O
,	O
background	O
clutter	O
and	O
extreme	O
poses	O
when	O
compared	O
with	O
other	O
benchmarks	O
.	O
	
A	O
total	O
of	O
393	O
,	O
703	O
labeled	O
faces	O
in	O
32	O
,	O
203	O
images	O
from	O
61	O
different	O
scenes	O
are	O
collected	O
,	O
of	O
which	O
40	O
%	O
are	O
chosen	O
as	O
train	O
set	O
,	O
10	O
%	O
as	O
validation	O
set	O
and	O
other	O
50	O
%	O
as	O
test	O
set	O
.	O
	
The	O
validation	O
set	O
and	O
the	O
testing	O
set	O
are	O
also	O
divided	O
into	O
easy	B-Material
set	I-Material
,	O
medium	B-Material
set	I-Material
and	O
hard	B-Material
set	I-Material
according	O
to	O
the	O
detection	O
difficulties	O
.	O
	
It	O
is	O
noticed	O
that	O
our	O
method	O
is	O
trained	O
only	O
on	O
the	O
train	O
set	O
and	O
evaluate	O
on	O
both	O
validation	B-Metric
set	I-Metric
and	O
test	O
set	O
.	O
	
Better	O
performance	O
might	O
be	O
achieved	O
by	O
merging	O
the	O
train	O
set	O
and	O
the	O
validation	O
set	O
for	O
training	O
.	O
	
More	O
detailed	O
results	O
of	O
WIDER	B-Material
FACE	I-Material
are	O
shown	O
in	O
Figure	O
4	O
.	O
	
section	O
:	O
Implementation	O
Details	O
	
Single	O
NVIDIA	B-Method
Tesla	I-Method
K80	I-Method
is	O
used	O
for	O
training	O
and	O
testing	O
.	O
	
Mini	O
batch	O
size	O
is	O
set	O
to	O
1	O
considering	O
memory	O
consumption	O
.	O
	
Specifically	O
,	O
ResNet_v1_101	B-Method
trained	O
on	O
ImageNet	O
-	O
128w	O
is	O
used	O
for	O
Faster	O
RCNN	B-Task
feature	I-Task
extraction	I-Task
.	O
	
It	O
is	O
helpful	O
to	O
freeze	O
the	O
first	O
two	O
blocks	O
in	O
the	O
training	O
stage	O
as	O
data	O
size	O
of	O
WIDER	B-Material
FACE	I-Material
is	O
not	O
so	O
large	O
.	O
	
A	O
deformable	B-Method
layer	I-Method
is	O
used	O
to	O
output	O
a	O
"	O
thin	O
"	O
feature	O
map	O
with	O
exploiting	O
image	O
context	O
.	O
	
Aspect	O
ratios	O
(	O
1	O
,	O
1.5	O
,	O
2	O
)	O
and	O
scales	O
(	O
16	O
2	O
,	O
32	O
2	O
,	O
64	O
2	O
,	O
128	O
2	O
,	O
256	O
2	O
,	O
512	O
2	O
)	O
are	O
carefully	O
designed	O
to	O
capture	O
better	O
locations	O
of	O
faces	O
in	O
the	O
RPN	B-Method
stage	I-Method
,	O
and	O
the	O
number	O
of	O
filters	O
for	O
the	O
RPN	B-Method
layer	I-Method
is	O
set	O
as	O
512	O
.	O
	
The	O
anchors	O
with	O
highest	O
IoU	B-Metric
score	I-Metric
or	O
IoU	B-Metric
score	I-Metric
with	O
the	O
ground	O
truth	O
above	O
0.7	O
are	O
defined	O
as	O
positive	O
.	O
	
The	O
anchors	O
whose	O
IoU	O
score	O
with	O
the	O
ground	O
truth	O
that	O
is	O
lower	O
than	O
0.3	O
are	O
defined	O
as	O
negative	O
,	O
while	O
whose	O
IoU	O
score	O
above	O
0.3	O
but	O
lower	O
than	O
0.7	O
will	O
be	O
ignored	O
.	O
	
The	O
similar	O
settings	O
of	O
anchors	O
are	O
used	O
in	O
the	O
R	B-Method
-	I-Method
CNN	I-Method
stage	I-Method
.	O
	
The	O
anchors	O
with	O
IoU	O
score	O
with	O
the	O
ground	O
truth	O
above	O
0.5	O
are	O
assigned	O
as	O
positive	O
,	O
IoU	B-Metric
score	I-Metric
that	O
is	O
lower	O
than	O
0.3	O
is	O
defined	O
as	O
negative	O
,	O
IoU	O
score	O
above	O
0.3	O
but	O
lower	O
than	O
0.5	O
will	O
be	O
ignored	O
.	O
	
By	O
the	O
way	O
,	O
the	O
batch	O
size	O
of	O
RPN	B-Method
and	I-Method
R	I-Method
-	I-Method
CNN	I-Method
is	O
respectively	O
assigned	O
as	O
256	O
and	O
128	O
.	O
	
The	O
initial	O
learning	B-Metric
rate	I-Metric
is	O
set	O
to	O
1e	O
-	O
3	O
,	O
and	O
decrease	O
to	O
1e	O
-	O
4	O
after	O
20w	O
iterations	O
.	O
	
Weight	O
decay	O
is	O
and	O
momentum	O
is	O
set	O
to	O
1e	O
-	O
4	O
and	O
0.9	O
respectively	O
.	O
	
In	O
testing	B-Task
stage	I-Task
,	O
multi	B-Method
-	I-Method
scale	I-Method
testing	I-Method
strategy	I-Method
is	O
adapted	O
to	O
be	O
robust	O
to	O
different	O
scale	O
faces	O
.	O
	
Specifically	O
,	O
the	O
shorter	O
side	O
of	O
each	O
image	O
is	O
also	O
resized	O
to	O
600	O
,	O
800	O
,	O
1000	O
,	O
1200	O
,	O
1400	O
pixels	O
and	O
tested	O
independently	O
.	O
	
And	O
a	O
voted	B-Method
-	I-Method
based	I-Method
NMS	I-Method
strategy	I-Method
is	O
used	O
to	O
get	O
the	O
final	O
result	O
.	O
	
We	O
also	O
find	O
top	O
-	O
ranked	O
6000	O
proposals	O
are	O
directly	O
selected	O
without	O
NMS	B-Method
during	O
testing	O
can	O
boost	O
0.1	O
%	O
,	O
0.3	O
%	O
and	O
0.6	O
%	O
on	O
easy	B-Material
set	I-Material
,	O
medium	B-Material
set	I-Material
and	O
hard	B-Material
set	I-Material
respectively	O
.	O
	
section	O
:	O
Comparison	O
on	O
Benchmarks	O
	
Our	O
model	O
is	O
trained	O
on	O
the	O
train	O
set	O
and	O
evaluated	O
on	O
WIDER	B-Material
FACE	I-Material
validation	I-Material
set	I-Material
.	O
	
Compared	O
with	O
the	O
recently	O
published	O
top	O
approaches	O
,	O
FDNet1.0	B-Method
wins	O
two	O
1st	O
places	O
(	O
easy	B-Material
set	I-Material
=	O
95.9	O
%	O
,	O
medium	B-Material
set	I-Material
=	O
94.5	O
%	O
)	O
and	O
one	O
2nd	O
place	O
(	O
hard	B-Material
set	I-Material
=	O
87.9	O
%	O
)	O
on	O
the	O
validation	O
set	O
,	O
as	O
illustrated	O
in	O
Figure	O
3	O
.	O
	
We	O
believe	O
that	O
more	O
kinds	O
of	O
data	B-Task
augmentation	I-Task
and	O
hard	B-Material
example	O
mining	O
[	O
reference	O
]	O
would	O
further	O
boost	O
detection	B-Task
performance	O
.	O
	
(	O
a	O
)	O
Easy	B-Material
set	I-Material
:	O
validation	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
novel	O
framework	O
named	O
FDNet1.0	B-Method
for	O
face	B-Task
detection	I-Task
.	O
	
FDNet1.0	B-Method
improves	O
Faster	O
RCNN	B-Method
by	O
integrating	O
several	O
efficient	O
techniques	O
for	O
better	O
performance	O
.	O
	
Experimental	O
results	O
on	O
challenging	O
WIDER	B-Material
FACE	I-Material
dataset	I-Material
validate	O
the	O
effectiveness	O
of	O
our	O
proposed	O
algorithm	O
.	O
	
In	O
the	O
future	O
,	O
we	O
will	O
try	O
more	O
kinds	O
of	O
data	B-Task
augmentation	I-Task
and	O
hard	B-Material
example	O
mining	O
which	O
may	O
further	O
boost	O
detection	B-Task
performance	O
.	O
	
We	O
will	O
also	O
consider	O
some	O
ideas	O
for	O
faster	O
inference	B-Metric
speed	I-Metric
,	O
e.g.	O
designing	O
light	O
backbone	O
.	O
	
section	O
:	O
	
document	O
:	O
Joint	B-Task
Detection	I-Task
and	I-Task
Identification	I-Task
Feature	I-Task
Learning	I-Task
for	O
Person	B-Task
Search	I-Task
	
Existing	O
person	B-Task
re	I-Task
-	I-Task
identification	I-Task
benchmarks	O
and	O
methods	O
mainly	O
focus	O
on	O
matching	O
cropped	O
pedestrian	O
images	O
between	O
queries	O
and	O
candidates	O
.	O
	
However	O
,	O
it	O
is	O
different	O
from	O
real	O
-	O
world	O
scenarios	O
where	O
the	O
annotations	O
of	O
pedestrian	O
bounding	O
boxes	O
are	O
unavailable	O
and	O
the	O
target	O
person	O
needs	O
to	O
be	O
searched	O
from	O
a	O
gallery	O
of	O
whole	O
scene	O
images	O
.	O
	
To	O
close	O
the	O
gap	O
,	O
we	O
propose	O
a	O
new	O
deep	B-Method
learning	I-Method
framework	I-Method
for	O
person	B-Task
search	I-Task
.	O
	
Instead	O
of	O
breaking	O
it	O
down	O
into	O
two	O
separate	O
tasks	O
—	O
pedestrian	O
detection	B-Task
and	O
person	B-Task
re	I-Task
-	I-Task
identification	I-Task
,	O
we	O
jointly	O
handle	O
both	O
aspects	O
in	O
a	O
single	O
convolutional	B-Method
neural	I-Method
network	I-Method
.	O
	
An	O
Online	B-Method
Instance	I-Method
Matching	I-Method
(	O
OIM	B-Method
)	O
loss	O
function	O
is	O
proposed	O
to	O
train	O
the	O
network	O
effectively	O
,	O
which	O
is	O
scalable	O
to	O
datasets	O
with	O
numerous	O
identities	O
.	O
	
To	O
validate	O
our	O
approach	O
,	O
we	O
collect	O
and	O
annotate	O
a	O
large	O
-	O
scale	O
benchmark	O
dataset	O
for	O
person	B-Task
search	I-Task
.	O
	
It	O
contains	O
images	O
,	O
identities	O
,	O
and	O
pedestrian	O
bounding	O
boxes	O
.	O
	
Experiments	O
show	O
that	O
our	O
framework	O
outperforms	O
other	O
separate	O
approaches	O
,	O
and	O
the	O
proposed	O
OIM	B-Method
loss	O
function	O
converges	O
much	O
faster	O
and	O
better	O
than	O
the	O
conventional	O
Softmax	B-Method
loss	I-Method
.	O
	
section	O
:	O
Introduction	O
	
Person	B-Task
re	I-Task
-	I-Task
identification	I-Task
(	O
re	B-Task
-	I-Task
i	I-Task
d	I-Task
)	O
aims	O
at	O
matching	O
a	O
target	O
person	O
with	O
a	O
gallery	O
of	O
pedestrian	O
images	O
.	O
	
It	O
has	O
many	O
video	B-Task
surveillance	I-Task
applications	I-Task
,	O
such	O
as	O
finding	B-Task
criminals	I-Task
,	O
cross	B-Task
-	I-Task
camera	I-Task
person	I-Task
tracking	I-Task
,	O
and	O
person	B-Task
activity	I-Task
analysis	I-Task
.	O
	
The	O
problem	O
is	O
challenging	O
because	O
of	O
complex	O
variations	O
of	O
human	O
poses	O
,	O
camera	O
viewpoints	O
,	O
lighting	O
,	O
occlusion	O
,	O
resolution	O
,	O
background	O
clutter	O
,	O
,	O
and	O
thus	O
draws	O
much	O
research	O
attention	O
in	O
recent	O
years	O
.	O
	
[	O
b	O
]	O
[	O
1em	O
]	O
[	O
b	O
]	O
	
Although	O
numerous	O
person	B-Task
re	I-Task
-	I-Task
i	I-Task
d	I-Task
datasets	O
and	O
methods	O
have	O
been	O
proposed	O
,	O
there	O
is	O
still	O
a	O
big	O
gap	O
between	O
the	O
problem	O
setting	O
itself	O
and	O
real	O
-	O
world	O
applications	O
.	O
	
In	O
most	O
benchmarks	O
,	O
the	O
gallery	O
only	O
contains	O
manually	O
cropped	O
pedestrian	O
images	O
(	O
Figure	O
[	O
reference	O
]	O
)	O
,	O
while	O
in	O
real	O
applications	O
,	O
the	O
goal	O
is	O
to	O
find	O
a	O
target	O
person	O
in	O
a	O
gallery	O
of	O
whole	O
scene	O
images	O
,	O
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Following	O
the	O
protocols	O
of	O
these	O
benchmarks	O
,	O
most	O
of	O
the	O
existing	O
person	O
re	B-Task
-	I-Task
i	I-Task
d	I-Task
methods	O
assume	O
perfect	O
pedestrian	O
detections	O
.	O
	
However	O
,	O
these	O
manually	O
cropped	O
bounding	O
boxes	O
are	O
unavailable	O
in	O
practical	O
applications	O
.	O
	
Off	O
-	O
the	O
-	O
shelf	O
pedestrian	B-Method
detectors	I-Method
would	O
inevitably	O
produce	O
false	O
alarms	O
,	O
misdetections	O
,	O
and	O
misalignments	O
,	O
which	O
could	O
harm	O
the	O
final	O
searching	B-Task
performance	O
significantly	O
.	O
	
In	O
2014	O
,	O
Xu	O
made	O
the	O
first	O
step	O
towards	O
closing	O
this	O
gap	O
.	O
	
They	O
introduced	O
the	O
person	B-Task
search	I-Task
problem	I-Task
to	O
the	O
community	O
,	O
and	O
proposed	O
a	O
sliding	B-Method
window	I-Method
searching	I-Method
strategy	I-Method
based	O
on	O
a	O
combination	O
of	O
pedestrian	O
detection	B-Task
and	O
person	O
matching	O
scores	O
.	O
	
However	O
,	O
the	O
performance	O
is	O
limited	O
by	O
the	O
handcrafted	O
features	O
,	O
and	O
the	O
sliding	B-Method
window	I-Method
framework	I-Method
is	O
not	O
scalable	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
new	O
deep	B-Method
learning	I-Method
framework	I-Method
for	O
person	B-Task
search	I-Task
.	O
	
Different	O
from	O
conventional	O
approaches	O
that	O
break	O
down	O
the	O
problem	O
into	O
two	O
separate	O
tasks	O
—	O
pedestrian	O
detection	B-Task
and	O
person	B-Task
re	I-Task
-	I-Task
identification	I-Task
,	O
we	O
jointly	O
handle	O
both	O
aspects	O
in	O
a	O
single	O
Convolutional	B-Method
Neural	I-Method
Network	I-Method
(	O
CNN	B-Method
)	O
.	O
	
Our	O
CNN	B-Method
consists	O
of	O
two	O
parts	O
,	O
given	O
a	O
whole	O
input	O
gallery	O
image	O
,	O
a	O
pedestrian	B-Method
proposal	I-Method
net	I-Method
is	O
used	O
to	O
produce	O
bounding	O
boxes	O
of	O
candidate	O
people	O
,	O
which	O
are	O
fed	O
into	O
an	O
identification	B-Method
net	I-Method
to	O
extract	O
features	O
for	O
comparing	O
with	O
the	O
target	O
person	O
.	O
	
The	O
pedestrian	B-Method
proposal	I-Method
net	I-Method
and	O
the	O
identification	B-Method
net	I-Method
adapt	O
with	O
each	O
other	O
during	O
the	O
joint	B-Task
optimization	I-Task
.	O
	
For	O
example	O
,	O
the	O
proposal	B-Method
net	I-Method
can	O
focus	O
more	O
on	O
the	O
recall	B-Metric
rather	O
than	O
the	O
precision	B-Metric
,	O
as	O
false	O
alarms	O
could	O
be	O
eliminated	O
through	O
the	O
latter	O
features	B-Method
matching	I-Method
process	I-Method
.	O
	
Meanwhile	O
,	O
misalignments	O
of	O
proposals	O
are	O
also	O
acceptable	O
,	O
as	O
they	O
can	O
be	O
further	O
adjusted	O
by	O
the	O
identification	O
net	O
.	O
	
To	O
improve	O
the	O
scalability	O
of	O
the	O
whole	O
system	O
,	O
inspired	O
by	O
recent	O
advances	O
in	O
object	O
detection	B-Task
,	O
we	O
encourage	O
both	O
parts	O
to	O
share	O
underlying	O
convolutional	O
feature	O
maps	O
,	O
which	O
significantly	O
accelerates	O
the	O
inference	B-Method
procedure	I-Method
.	O
	
Traditional	O
re	B-Task
-	I-Task
i	I-Task
d	I-Task
feature	I-Task
learning	I-Task
mainly	O
employs	O
pairwise	O
or	O
triplet	O
distance	O
loss	O
functions	O
.	O
	
However	O
,	O
they	O
are	O
not	O
efficient	O
as	O
only	O
several	O
data	O
samples	O
are	O
compared	O
at	O
each	O
time	O
,	O
and	O
there	O
are	O
potential	O
input	O
combinations	O
,	O
where	O
is	O
the	O
number	O
of	O
images	O
.	O
	
Different	O
sampling	B-Method
strategies	I-Method
could	O
significantly	O
impact	O
the	O
convergence	B-Metric
rate	I-Metric
and	I-Metric
quality	I-Metric
,	O
but	O
finding	O
efficient	O
sampling	B-Method
strategies	I-Method
becomes	O
much	O
more	O
difficult	O
as	O
increases	O
.	O
	
Another	O
approach	O
is	O
learning	O
to	O
classify	O
identities	O
with	O
the	O
Softmax	O
loss	O
function	O
,	O
which	O
effectively	O
compares	O
all	O
the	O
samples	O
at	O
the	O
same	O
time	O
.	O
	
But	O
as	O
the	O
number	O
of	O
classes	O
increases	O
,	O
training	O
the	O
big	O
Softmax	B-Method
classifier	I-Method
matrix	I-Method
becomes	O
much	O
slower	O
or	O
even	O
can	O
not	O
converge	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
novel	O
Online	B-Method
Instance	I-Method
Matching	I-Method
(	O
OIM	B-Method
)	O
loss	O
function	O
to	O
cope	O
with	O
the	O
problems	O
.	O
	
We	O
maintain	O
a	O
lookup	O
table	O
of	O
features	O
from	O
all	O
the	O
labeled	O
identities	O
,	O
and	O
compare	O
distances	O
between	O
mini	O
-	O
batch	O
samples	O
and	O
all	O
the	O
registered	O
entries	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
many	O
unlabeled	O
identities	O
could	O
appear	O
in	O
scene	O
images	O
,	O
which	O
can	O
be	O
served	O
as	O
negatives	O
for	O
labeled	O
identities	O
.	O
	
We	O
thus	O
exploit	O
a	O
circular	O
queue	O
to	O
store	O
their	O
features	O
also	O
for	O
comparison	O
.	O
	
This	O
is	O
another	O
advantage	O
brought	O
by	O
the	O
person	B-Task
search	I-Task
problem	I-Task
setting	I-Task
.	O
	
The	O
proposed	O
parameter	O
-	O
free	O
OIM	B-Method
loss	O
converges	O
much	O
faster	O
and	O
better	O
than	O
the	O
Softmax	B-Method
loss	I-Method
in	O
our	O
experiments	O
.	O
	
The	O
contribution	O
of	O
our	O
work	O
is	O
three	O
-	O
fold	O
.	O
	
First	O
,	O
we	O
propose	O
a	O
new	O
deep	B-Method
learning	I-Method
framework	I-Method
to	O
search	O
a	O
target	O
person	O
from	O
a	O
gallery	O
of	O
whole	O
scene	O
images	O
.	O
	
Instead	O
of	O
simply	O
combining	O
the	O
pedestrian	B-Method
detectors	I-Method
and	O
person	O
re	B-Task
-	I-Task
i	I-Task
d	I-Task
methods	O
,	O
we	O
jointly	O
optimize	O
both	O
objectives	O
in	O
a	O
single	O
CNN	B-Method
and	O
they	O
better	O
adapt	O
with	O
each	O
other	O
.	O
	
Second	O
,	O
we	O
propose	O
an	O
Online	B-Method
Instance	I-Method
Matching	I-Method
loss	O
function	O
to	O
learn	O
identification	O
features	O
more	O
effectively	O
,	O
which	O
enables	O
our	O
framework	O
to	O
be	O
scalable	O
to	O
large	O
datasets	O
with	O
numerous	O
identities	O
.	O
	
Together	O
with	O
the	O
fast	O
inference	B-Metric
speed	I-Metric
,	O
our	O
framework	O
is	O
much	O
closer	O
to	O
the	O
real	O
-	O
world	O
application	O
requirements	O
.	O
	
At	O
last	O
,	O
we	O
collect	O
and	O
annotate	O
a	O
large	O
-	O
scale	O
benchmark	O
dataset	O
for	O
person	B-Task
search	I-Task
,	O
covering	O
hundreds	O
of	O
scenes	O
from	O
street	O
and	O
movie	O
snapshots	O
.	O
	
The	O
dataset	O
contains	O
images	O
,	O
identities	O
,	O
and	O
pedestrian	O
bounding	O
boxes	O
.	O
	
We	O
validate	O
the	O
effectiveness	O
of	O
our	O
approach	O
comparing	O
against	O
other	O
baselines	O
on	O
this	O
dataset	O
.	O
	
The	O
dataset	O
and	O
code	O
are	O
made	O
public	O
to	O
facilitate	O
further	O
research	O
.	O
	
section	O
:	O
Related	O
Work	O
	
Person	B-Task
re	I-Task
-	I-Task
identification	I-Task
.	O
	
Early	O
person	B-Task
re	I-Task
-	I-Task
identification	I-Task
methods	O
addressed	O
the	O
problem	O
by	O
manually	O
designing	O
discriminative	O
features	O
,	O
learning	O
feature	O
transforms	O
across	O
camera	O
views	O
,	O
and	O
learning	B-Metric
distance	I-Metric
metrics	I-Metric
.	O
	
Recent	O
years	O
,	O
many	O
researchers	O
have	O
proposed	O
various	O
deep	B-Method
learning	I-Method
based	I-Method
methods	I-Method
that	O
jointly	O
handle	O
all	O
these	O
aspects	O
.	O
	
Li	O
and	O
Ahmed	O
designed	O
specific	O
CNN	B-Method
models	O
for	O
person	B-Task
re	I-Task
-	I-Task
i	I-Task
d	I-Task
.	O
	
Both	O
the	O
networks	O
utilize	O
as	O
input	O
a	O
pair	O
of	O
cropped	O
pedestrian	O
images	O
and	O
employ	O
a	O
binary	B-Method
verification	I-Method
loss	I-Method
function	I-Method
to	O
train	O
the	O
parameters	O
.	O
	
Ding	O
and	O
Cheng	O
exploited	O
triplet	O
samples	O
for	O
training	O
CNNs	B-Method
to	O
minimize	O
the	O
feature	O
distance	O
between	O
the	O
same	O
person	O
and	O
maximize	O
the	O
distance	O
between	O
different	O
people	O
.	O
	
Apart	O
from	O
using	O
pairwise	O
or	O
triplet	O
loss	O
functions	O
,	O
Xiao	O
proposed	O
to	O
learn	O
features	O
by	O
classifying	O
identities	O
.	O
	
Multiple	O
datasets	O
are	O
combined	O
together	O
and	O
a	O
domain	B-Method
guided	I-Method
dropout	I-Method
technique	I-Method
is	O
proposed	O
to	O
improve	O
the	O
feature	B-Method
learning	I-Method
.	O
	
Several	O
recent	O
works	O
addressed	O
on	O
solving	O
person	B-Task
re	I-Task
-	I-Task
i	I-Task
d	I-Task
on	O
abnormal	O
images	O
,	O
such	O
as	O
low	O
-	O
resolution	O
images	O
,	O
or	O
partially	O
occluded	O
images	O
.	O
	
Concurrent	O
with	O
our	O
prior	O
arXiv	O
submission	O
,	O
Zheng	O
also	O
contributed	O
a	O
benchmark	O
dataset	O
for	O
person	B-Task
search	I-Task
.	O
	
They	O
exploited	O
separate	O
detection	B-Task
and	O
re	B-Task
-	I-Task
i	I-Task
d	I-Task
methods	I-Task
with	O
scores	O
re	O
-	O
weighting	O
to	O
solve	O
the	O
problem	O
,	O
while	O
in	O
this	O
work	O
we	O
propose	O
a	O
deep	B-Method
learning	I-Method
framework	I-Method
that	O
jointly	O
handles	O
both	O
aspects	O
.	O
	
Pedestrian	O
detection	B-Task
.	O
	
DPM	B-Method
,	O
ACF	B-Method
,	O
and	O
Checkerboards	B-Method
are	O
the	O
most	O
commonly	O
used	O
off	O
-	O
the	O
-	O
shelf	O
pedestrian	B-Method
detectors	I-Method
.	O
	
They	O
rely	O
on	O
hand	O
-	O
crafted	O
features	O
and	O
linear	B-Method
classifiers	I-Method
to	O
detect	O
pedestrians	O
.	O
	
Recent	O
years	O
,	O
CNN	B-Method
-	O
based	O
pedestrian	O
detectors	O
have	O
also	O
been	O
developed	O
.	O
	
Various	O
factors	O
,	O
including	O
CNN	B-Method
model	O
structures	O
,	O
training	O
data	O
,	O
and	O
different	O
training	B-Method
strategies	I-Method
are	O
studied	O
empirically	O
in	O
.	O
	
Tian	O
exploited	O
pedestrian	O
and	O
scene	O
attribute	O
labels	O
to	O
train	O
CNN	B-Method
pedestrian	O
detectors	O
in	O
a	O
multi	O
-	O
task	O
manner	O
.	O
	
Cai	O
proposed	O
a	O
complexity	B-Method
-	I-Method
aware	I-Method
boosting	I-Method
algorithm	I-Method
for	O
learning	O
CNN	B-Method
detector	O
cascades	O
.	O
	
section	O
:	O
Method	O
	
We	O
propose	O
a	O
new	O
deep	B-Method
learning	I-Method
framework	I-Method
that	O
jointly	O
handles	O
the	O
pedestrian	O
detection	B-Task
and	O
person	B-Task
re	I-Task
-	I-Task
identification	I-Task
in	O
a	O
single	O
convolutional	B-Method
neural	I-Method
network	I-Method
(	O
CNN	B-Method
)	O
,	O
as	O
shown	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Given	O
as	O
input	O
a	O
whole	O
scene	O
image	O
,	O
we	O
first	O
use	O
a	O
stem	O
CNN	B-Method
to	O
transform	O
from	O
raw	O
pixels	O
to	O
convolutional	O
feature	O
maps	O
.	O
	
A	O
pedestrian	B-Method
proposal	I-Method
net	I-Method
is	O
built	O
upon	O
these	O
feature	O
maps	O
to	O
predict	O
bounding	O
boxes	O
of	O
candidate	O
people	O
,	O
which	O
are	O
then	O
fed	O
into	O
an	O
identification	B-Method
net	I-Method
with	O
RoI	B-Method
-	I-Method
Pooling	I-Method
to	O
extract	O
L2	O
-	O
normalized	O
-	O
d	O
features	O
for	O
each	O
of	O
them	O
.	O
	
At	O
inference	B-Task
stage	I-Task
,	O
we	O
rank	O
the	O
gallery	O
people	O
according	O
to	O
their	O
feature	O
distances	O
to	O
the	O
target	O
person	O
.	O
	
At	O
training	O
stage	O
,	O
we	O
propose	O
an	O
Online	B-Method
Instance	I-Method
Matching	I-Method
(	O
OIM	B-Method
)	O
loss	O
function	O
on	O
top	O
of	O
the	O
feature	O
vectors	O
to	O
supervise	O
the	O
identification	B-Task
net	I-Task
,	O
together	O
with	O
several	O
other	O
loss	B-Method
functions	I-Method
for	O
training	O
the	O
proposal	B-Method
net	I-Method
in	O
a	O
multi	B-Task
-	I-Task
task	I-Task
manner	I-Task
.	O
	
Below	O
we	O
will	O
first	O
detail	O
the	O
CNN	B-Method
model	O
structure	O
,	O
and	O
then	O
elaborate	O
on	O
the	O
OIM	B-Method
loss	O
function	O
.	O
	
subsection	O
:	O
Model	O
Structure	O
	
We	O
adopt	O
the	O
ResNet	B-Method
-	I-Method
50	I-Method
as	O
our	O
base	O
CNN	B-Method
model	O
.	O
	
It	O
has	O
a	O
convolution	B-Method
layer	I-Method
in	O
front	O
(	O
named	O
conv1	O
)	O
,	O
followed	O
by	O
four	O
blocks	O
(	O
named	O
conv2_x	O
to	O
conv5_x	O
)	O
each	O
containing	O
residual	O
units	O
,	O
respectively	O
.	O
	
We	O
exploit	O
conv1	B-Method
to	O
conv4_3	O
as	O
the	O
stem	O
part	O
.	O
	
Given	O
an	O
input	O
image	O
,	O
the	O
stem	O
will	O
produce	O
channels	O
of	O
features	O
maps	O
,	O
which	O
have	O
resolutions	O
of	O
the	O
original	O
image	O
.	O
	
On	O
top	O
of	O
these	O
feature	O
maps	O
,	O
we	O
build	O
a	O
pedestrian	B-Method
proposal	I-Method
network	I-Method
to	O
detect	O
person	O
candidates	O
.	O
	
A	O
convolutional	B-Method
layer	I-Method
is	O
first	O
added	O
to	O
transform	O
the	O
features	O
specifically	O
for	O
pedestrians	O
.	O
	
Then	O
we	O
follow	O
to	O
associate	O
anchors	O
at	O
each	O
feature	O
map	O
location	O
,	O
and	O
use	O
a	O
Softmax	B-Method
classifier	I-Method
to	O
predict	O
whether	O
each	O
anchor	O
is	O
a	O
pedestrian	O
or	O
not	O
,	O
as	O
well	O
as	O
a	O
linear	B-Method
regression	I-Method
to	O
adjust	O
their	O
locations	O
.	O
	
We	O
will	O
keep	O
the	O
top	O
adjusted	O
bounding	O
boxes	O
after	O
non	O
-	O
maximum	O
suppression	O
as	O
our	O
final	O
proposals	O
.	O
	
To	O
find	O
the	O
target	O
person	O
among	O
all	O
these	O
proposals	O
,	O
we	O
build	O
an	O
identification	B-Method
net	I-Method
to	O
extract	O
the	O
features	O
of	O
each	O
proposal	O
,	O
and	O
compare	O
against	O
the	O
target	O
ones	O
.	O
	
We	O
first	O
exploit	O
an	O
RoI	B-Method
-	I-Method
Pooling	I-Method
layer	I-Method
to	O
pool	O
a	O
region	O
from	O
the	O
stem	O
feature	O
maps	O
for	O
each	O
proposal	O
.	O
	
Then	O
they	O
are	O
passed	O
through	O
the	O
rest	O
conv4_4	B-Method
to	O
conv5_3	O
of	O
the	O
ResNet	B-Method
-	I-Method
50	I-Method
,	O
followed	O
by	O
a	O
global	B-Method
average	I-Method
pooling	I-Method
layer	I-Method
to	O
summarize	O
into	O
a	O
dimensional	O
feature	O
vector	O
.	O
	
On	O
one	O
hand	O
,	O
as	O
the	O
pedestrian	O
proposals	O
would	O
inevitably	O
contain	O
some	O
false	O
alarms	O
and	O
misalignments	O
,	O
we	O
use	O
again	O
a	O
Softmax	B-Method
classifier	I-Method
and	O
a	O
linear	B-Method
regression	I-Method
to	O
reject	O
non	O
-	O
persons	O
and	O
refine	O
the	O
locations	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
we	O
project	O
the	O
features	O
into	O
a	O
L2	O
-	O
normalized	O
dimensional	O
subspace	O
(	O
i	O
d	O
-	O
feat	O
)	O
,	O
and	O
use	O
them	O
to	O
compute	O
cosine	O
similarities	O
with	O
the	O
target	O
person	O
when	O
doing	O
inference	B-Task
.	O
	
During	O
the	O
training	O
stage	O
,	O
we	O
supervise	O
the	O
i	B-Method
d	I-Method
-	I-Method
feat	I-Method
with	O
the	O
proposed	O
OIM	B-Method
loss	O
function	O
.	O
	
Together	O
with	O
other	O
loss	B-Method
functions	I-Method
for	O
detection	B-Task
,	O
the	O
whole	O
net	O
is	O
jointly	O
trained	O
in	O
a	O
multi	B-Task
-	I-Task
task	I-Task
learning	I-Task
manner	I-Task
,	O
rather	O
than	O
using	O
the	O
alternative	O
optimizations	O
in	O
.	O
	
subsection	O
:	O
Online	B-Method
Instance	I-Method
Matching	I-Method
Loss	O
	
There	O
are	O
three	O
different	O
types	O
of	O
proposals	O
,	O
labeled	O
identities	O
,	O
unlabeled	O
identities	O
,	O
and	O
background	O
clutter	O
.	O
	
Suppose	O
there	O
are	O
different	O
target	O
people	O
in	O
the	O
training	O
set	O
,	O
when	O
a	O
proposal	O
matches	O
a	O
target	O
person	O
,	O
we	O
call	O
it	O
an	O
instance	O
of	O
the	O
labeled	O
identity	O
,	O
and	O
assign	O
a	O
class	O
-	O
i	O
d	O
(	O
from	O
to	O
)	O
to	O
it	O
accordingly	O
.	O
	
There	O
are	O
also	O
lots	O
of	O
proposals	O
predicting	O
pedestrians	O
correctly	O
,	O
but	O
do	O
not	O
belong	O
to	O
anyone	O
of	O
our	O
target	O
people	O
.	O
	
We	O
call	O
them	O
unlabeled	O
identities	O
in	O
such	O
cases	O
.	O
	
We	O
demonstrate	O
some	O
examples	O
of	O
labeled	O
and	O
unlabeled	O
identities	O
in	O
Figure	O
[	O
reference	O
]	O
with	O
blue	O
and	O
orange	O
bounding	O
boxes	O
,	O
respectively	O
.	O
	
Other	O
proposals	O
are	O
just	O
false	O
alarms	O
on	O
other	O
objects	O
or	O
background	O
regions	O
.	O
	
In	O
the	O
proposed	O
loss	B-Method
function	I-Method
,	O
we	O
only	O
consider	O
the	O
labeled	O
and	O
unlabeled	O
identities	O
,	O
while	O
leave	O
the	O
other	O
proposals	O
untouched	O
.	O
	
As	O
our	O
goal	O
is	O
to	O
distinguish	O
different	O
people	O
,	O
a	O
natural	O
objective	O
is	O
to	O
minimize	O
the	O
features	O
discrepancy	O
among	O
the	O
instances	O
of	O
the	O
same	O
person	O
,	O
while	O
maximize	O
the	O
discrepancy	O
among	O
different	O
people	O
.	O
	
To	O
fulfill	O
this	O
goal	O
,	O
we	O
need	O
to	O
memorize	O
the	O
features	O
of	O
all	O
the	O
people	O
.	O
	
This	O
could	O
be	O
done	O
offline	O
by	O
doing	O
network	B-Method
forward	I-Method
on	O
all	O
the	O
training	O
images	O
,	O
but	O
it	O
is	O
not	O
practical	O
when	O
using	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
(	O
SGD	B-Method
)	I-Method
for	O
optimization	B-Task
.	O
	
Thus	O
in	O
our	O
approach	O
,	O
we	O
choose	O
an	O
online	B-Method
approximation	I-Method
instead	O
.	O
	
Denote	O
the	O
features	O
of	O
a	O
labeled	O
identity	O
inside	O
a	O
mini	O
-	O
batch	O
by	O
,	O
where	O
is	O
the	O
feature	O
dimension	O
,	O
we	O
maintain	O
a	O
lookup	O
table	O
(	O
LUT	O
)	O
to	O
store	O
the	O
features	O
of	O
all	O
the	O
labeled	O
identities	O
,	O
as	O
demonstrated	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
During	O
the	O
forward	B-Method
propagation	I-Method
,	O
we	O
compute	O
cosine	O
similarities	O
between	O
the	O
mini	O
-	O
batch	O
sample	O
and	O
all	O
the	O
labeled	O
identities	O
by	O
.	O
	
During	O
backward	O
,	O
if	O
the	O
target	O
class	O
-	O
i	O
d	O
is	O
,	O
then	O
we	O
will	O
update	O
the	O
-	O
th	O
column	O
of	O
the	O
LUT	O
by	O
,	O
where	O
,	O
and	O
then	O
scale	O
to	O
have	O
unit	O
L2	O
-	O
norm	O
.	O
	
Apart	O
from	O
labeled	O
identities	O
,	O
many	O
unlabeled	O
identities	O
are	O
also	O
valuable	O
for	O
learning	O
feature	B-Method
representations	I-Method
.	O
	
They	O
can	O
be	O
safely	O
used	O
as	O
negative	O
classes	O
for	O
all	O
the	O
labeled	O
identities	O
.	O
	
We	O
use	O
a	O
circular	O
queue	O
to	O
store	O
the	O
features	O
of	O
these	O
unlabeled	O
identities	O
that	O
appear	O
in	O
recent	O
mini	O
-	O
batches	O
.	O
	
Denote	O
the	O
features	O
in	O
this	O
circular	O
queue	O
by	O
,	O
where	O
is	O
the	O
queue	O
size	O
,	O
we	O
can	O
also	O
compute	O
their	O
cosine	O
similarities	O
with	O
the	O
mini	O
-	O
batch	O
sample	O
by	O
.	O
	
After	O
each	O
iteration	O
,	O
we	O
push	O
the	O
new	O
feature	O
vectors	O
into	O
the	O
queue	O
,	O
while	O
pop	O
the	O
out	O
-	O
of	O
-	O
date	O
ones	O
to	O
keep	O
the	O
queue	O
size	O
unchanged	O
.	O
	
Based	O
on	O
these	O
two	O
data	O
structures	O
,	O
we	O
define	O
the	O
probability	O
of	O
being	O
recognized	O
as	O
the	O
identity	O
with	O
class	O
-	O
i	O
d	O
by	O
a	O
Softmax	B-Method
function	I-Method
where	O
higher	O
temperature	O
leads	O
to	O
softer	O
probability	O
distribution	O
.	O
	
Similarly	O
,	O
the	O
probability	O
of	O
being	O
recognized	O
as	O
the	O
-	O
th	O
unlabeled	O
identity	O
in	O
the	O
circular	O
queue	O
is	O
OIM	B-Method
objective	O
is	O
to	O
maximize	O
the	O
expected	O
log	O
-	O
likelihood	O
and	O
its	O
gradient	O
with	O
respect	O
to	O
can	O
be	O
derived	O
as	O
It	O
can	O
be	O
seen	O
that	O
our	O
OIM	B-Method
loss	O
effectively	O
compares	O
the	O
mini	O
-	O
batch	O
sample	O
with	O
all	O
the	O
labeled	O
and	O
unlabeled	O
identities	O
,	O
driving	O
the	O
underlying	O
feature	O
vector	O
to	O
be	O
similar	O
with	O
the	O
target	O
one	O
,	O
while	O
pushing	O
it	O
away	O
from	O
the	O
others	O
.	O
	
Why	O
not	O
Softmax	O
loss	O
?	O
	
A	O
natural	O
question	O
here	O
is	O
that	O
why	O
not	O
learning	O
a	O
classifier	B-Method
matrix	I-Method
with	O
a	O
conventional	O
Softmax	O
loss	O
to	O
predict	O
the	O
class	O
-	O
i	O
d	O
.	O
	
There	O
are	O
mainly	O
two	O
drawbacks	O
.	O
	
First	O
,	O
large	O
-	O
scale	O
person	O
search	O
datasets	O
would	O
have	O
a	O
large	O
number	O
of	O
identities	O
(	O
more	O
than	O
in	O
our	O
training	O
set	O
)	O
,	O
while	O
each	O
identity	O
only	O
has	O
several	O
instances	O
and	O
each	O
image	O
only	O
contains	O
a	O
few	O
identities	O
.	O
	
We	O
need	O
to	O
learn	O
more	O
than	O
discriminant	O
functions	O
simultaneously	O
,	O
but	O
during	O
each	O
SGD	B-Method
iteration	I-Method
we	O
only	O
have	O
positive	O
samples	O
from	O
tens	O
of	O
classes	O
.	O
	
The	O
classifier	B-Method
matrix	I-Method
suffers	O
from	O
large	O
variance	O
of	O
gradients	O
and	O
thus	O
can	O
not	O
be	O
learned	O
effectively	O
,	O
even	O
with	O
proper	O
pre	B-Method
-	I-Method
training	I-Method
and	O
high	O
momentum	O
.	O
	
Second	O
,	O
we	O
can	O
not	O
exploit	O
the	O
unlabeled	O
identities	O
with	O
Softmax	O
loss	O
,	O
as	O
they	O
have	O
no	O
specific	O
class	O
-	O
ids	O
.	O
	
Although	O
our	O
OIM	B-Method
loss	O
formulation	O
is	O
similar	O
to	O
the	O
Softmax	B-Method
one	I-Method
,	O
the	O
major	O
difference	O
is	O
that	O
the	O
OIM	B-Method
loss	O
is	O
non	O
-	O
parametric	O
.	O
	
The	O
LUT	O
and	O
circular	O
queue	O
are	O
considered	O
as	O
external	O
buffer	O
,	O
rather	O
than	O
the	O
network	O
parameters	O
.	O
	
The	O
gradients	O
directly	O
operate	O
on	O
the	O
features	O
without	O
the	O
transformation	O
by	O
a	O
classifier	B-Method
matrix	I-Method
.	O
	
The	O
potential	O
drawback	O
of	O
this	O
non	B-Method
-	I-Method
parametric	I-Method
loss	I-Method
is	O
that	O
it	O
could	O
overfit	O
more	O
easily	O
.	O
	
We	O
find	O
that	O
projecting	O
the	O
features	O
into	O
a	O
L2	O
-	O
normalized	O
low	O
-	O
dimensional	O
subspace	O
helps	O
reduce	O
overfitting	O
.	O
	
Scalability	O
.	O
	
Computing	O
the	O
partition	O
function	O
in	O
Eq	O
(	O
[	O
reference	O
]	O
)	O
and	O
Eq	O
(	O
[	O
reference	O
]	O
)	O
could	O
be	O
time	O
consuming	O
when	O
the	O
number	O
of	O
identities	O
increases	O
.	O
	
To	O
overcome	O
this	O
problem	O
,	O
we	O
can	O
approximate	O
the	O
denominators	O
by	O
sub	O
-	O
sampling	O
the	O
labeled	O
and	O
unlabeled	O
identities	O
,	O
which	O
results	O
in	O
optimizing	O
a	O
lower	B-Metric
-	I-Metric
bound	I-Metric
of	O
Eq	O
(	O
[	O
reference	O
]	O
)	O
.	O
	
section	O
:	O
Dataset	O
	
We	O
collect	O
and	O
annotate	O
a	O
large	O
-	O
scale	O
person	O
search	O
dataset	O
to	O
evaluate	O
of	O
our	O
proposed	O
method	O
.	O
	
We	O
exploit	O
two	O
data	O
sources	O
to	O
diversify	O
the	O
scenes	O
.	O
	
On	O
one	O
hand	O
,	O
we	O
use	O
hand	B-Method
-	I-Method
held	I-Method
cameras	I-Method
to	O
shoot	O
street	O
snaps	O
around	O
an	O
urban	O
city	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
we	O
collect	O
from	O
movie	O
snapshots	O
that	O
contain	O
pedestrians	O
,	O
as	O
they	O
could	O
enrich	O
the	O
variations	O
of	O
viewpoints	O
,	O
lighting	O
,	O
and	O
background	O
conditions	O
.	O
	
In	O
this	O
section	O
,	O
we	O
will	O
show	O
the	O
basic	O
statistics	O
of	O
our	O
dataset	O
,	O
as	O
well	O
as	O
define	O
the	O
evaluation	B-Metric
protocols	I-Metric
and	O
metrics	O
.	O
	
subsection	O
:	O
Statistics	O
	
After	O
collecting	O
all	O
the	O
images	O
,	O
we	O
first	O
densely	O
annotate	O
all	O
the	O
pedestrians	O
bounding	O
boxes	O
in	O
these	O
scenes	O
,	O
and	O
then	O
associate	O
the	O
person	O
that	O
appears	O
across	O
different	O
images	O
,	O
resulting	O
in	O
labeled	O
identities	O
.	O
	
The	O
statistics	O
of	O
two	O
data	O
sources	O
are	O
listed	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
We	O
did	O
not	O
annotate	O
those	O
people	O
who	O
appear	O
with	O
half	O
bodies	O
or	O
abnormal	O
poses	O
such	O
as	O
sitting	O
or	O
squatting	O
.	O
	
Moreover	O
,	O
people	O
who	O
change	O
clothes	O
and	O
decorations	O
in	O
different	O
video	O
frames	O
are	O
not	O
associated	O
in	O
our	O
dataset	O
,	O
since	O
person	B-Task
search	I-Task
problem	I-Task
requires	O
to	O
recognize	O
identities	O
mainly	O
according	O
to	O
their	O
clothes	O
and	O
body	O
shapes	O
rather	O
than	O
faces	O
.	O
	
We	O
ensure	O
that	O
the	O
background	O
pedestrians	O
do	O
not	O
contain	O
labeled	O
identities	O
,	O
and	O
thus	O
they	O
can	O
be	O
safely	O
served	O
as	O
negative	O
samples	O
for	O
identification	B-Task
.	O
	
Note	O
that	O
we	O
also	O
ignore	O
the	O
background	O
pedestrians	O
whose	O
heights	O
are	O
smaller	O
than	O
pixels	O
,	O
as	O
they	O
would	O
be	O
hard	O
to	O
recognize	O
even	O
for	O
human	B-Task
labelers	I-Task
.	O
	
The	O
height	O
distributions	O
of	O
labeled	O
and	O
unlabeled	O
identities	O
are	O
demonstrated	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
It	O
can	O
be	O
seen	O
that	O
our	O
dataset	O
has	O
rich	O
variations	O
of	O
pedestrian	O
scales	O
.	O
	
subsection	O
:	O
Evaluation	B-Metric
Protocols	I-Metric
and	O
Metrics	O
	
We	O
split	O
the	O
dataset	O
into	O
a	O
training	O
and	O
a	O
test	O
subset	O
,	O
ensuring	O
no	O
overlapped	O
images	O
or	O
labeled	O
identities	O
between	O
them	O
.	O
	
Table	O
[	O
reference	O
]	O
shows	O
the	O
statistics	O
of	O
these	O
two	O
subsets	O
.	O
	
We	O
divide	O
the	O
test	O
identity	O
instances	O
into	O
queries	O
and	O
galleries	O
.	O
	
For	O
each	O
of	O
the	O
test	O
identities	O
,	O
we	O
randomly	O
choose	O
one	O
of	O
his	O
/	O
her	O
instances	O
as	O
the	O
query	O
,	O
while	O
the	O
corresponding	O
gallery	O
set	O
consists	O
of	O
two	O
parts	O
	
—	O
all	O
the	O
images	O
containing	O
the	O
other	O
instances	O
and	O
some	O
randomly	O
sampled	O
images	O
not	O
containing	O
this	O
person	O
.	O
	
Different	O
queries	O
have	O
different	O
galleries	O
,	O
and	O
jointly	O
they	O
cover	O
all	O
the	O
test	O
images	O
.	O
	
To	O
better	O
understand	O
how	O
gallery	O
size	O
would	O
affect	O
the	O
person	B-Task
search	I-Task
performance	O
,	O
we	O
define	O
a	O
set	O
of	O
protocols	O
with	O
gallery	O
size	O
ranging	O
from	O
to	O
.	O
	
Taking	O
gallery	O
size	O
of	O
as	O
an	O
example	O
,	O
as	O
each	O
image	O
approximately	O
contains	O
pedestrians	O
,	O
then	O
our	O
task	O
is	O
to	O
find	O
the	O
target	O
person	O
among	O
about	O
people	O
.	O
	
This	O
setting	O
is	O
comparable	O
with	O
existing	O
person	B-Task
re	I-Task
-	I-Task
i	I-Task
d	I-Task
datasets	I-Task
(	O
,	O
CUHK	O
-	O
03	O
,	O
VIPeR	O
)	O
in	O
terms	O
of	O
the	O
number	O
of	O
gallery	O
pedestrians	O
,	O
and	O
is	O
even	O
more	O
challenging	O
as	O
there	O
could	O
be	O
thousands	O
of	O
background	O
clutter	O
bounding	O
boxes	O
distracting	O
our	O
attentions	O
.	O
	
We	O
employ	O
two	O
kinds	O
of	O
evaluation	B-Metric
metrics	I-Metric
	
—	O
cumulative	B-Metric
matching	I-Metric
characteristics	I-Metric
(	O
CMC	B-Metric
top	I-Metric
-	I-Metric
K	I-Metric
)	O
and	O
mean	B-Metric
averaged	I-Metric
precision	I-Metric
(	O
mAP	B-Metric
)	O
.	O
	
The	O
first	O
one	O
is	O
inherited	O
from	O
the	O
person	B-Task
re	I-Task
-	I-Task
i	I-Task
d	I-Task
problem	I-Task
,	O
where	O
a	O
matching	B-Task
is	O
counted	O
if	O
there	O
is	O
at	O
least	O
one	O
of	O
the	O
top	O
-	O
K	O
predicted	O
bounding	O
boxes	O
overlaps	O
with	O
the	O
ground	O
truths	O
with	O
intersection	B-Metric
-	I-Metric
over	I-Metric
-	I-Metric
union	I-Metric
(	O
IoU	B-Metric
)	O
greater	O
or	O
equal	O
to	O
.	O
	
The	O
second	O
one	O
is	O
inspired	O
from	O
the	O
object	O
detection	B-Task
tasks	O
.	O
	
We	O
follow	O
the	O
ILSVRC	O
object	O
detection	B-Task
criterion	O
to	O
judge	O
the	O
correctness	O
of	O
predicted	O
bounding	O
boxes	O
.	O
	
An	O
averaged	B-Metric
precision	I-Metric
(	O
AP	B-Metric
)	O
is	O
calculated	O
for	O
each	O
query	O
based	O
on	O
the	O
precision	B-Metric
-	I-Metric
recall	I-Metric
curve	I-Metric
,	O
and	O
then	O
we	O
average	O
the	O
APs	O
across	O
all	O
the	O
queries	O
to	O
get	O
the	O
final	O
result	O
.	O
	
section	O
:	O
Experiments	O
	
To	O
evaluate	O
the	O
effectiveness	O
of	O
our	O
approach	O
and	O
study	O
the	O
impact	O
of	O
various	O
factors	O
on	O
person	B-Task
search	I-Task
performance	O
,	O
we	O
conduct	O
several	O
groups	O
of	O
experiments	O
on	O
the	O
new	O
dataset	O
.	O
	
In	O
this	O
section	O
,	O
we	O
first	O
detail	O
the	O
baseline	O
methods	O
and	O
experiment	O
settings	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Then	O
we	O
compare	O
our	O
joint	B-Method
framework	I-Method
with	O
the	O
baselines	O
of	O
using	O
separate	O
pedestrian	O
detection	B-Task
and	O
person	B-Task
re	I-Task
-	I-Task
identification	I-Task
in	O
Section	O
[	O
reference	O
]	O
.	O
	
Section	O
[	O
reference	O
]	O
shows	O
the	O
effectiveness	O
of	O
our	O
proposed	O
Online	B-Method
Instance	I-Method
Matching	I-Method
(	O
OIM	B-Method
)	O
loss	O
.	O
	
At	O
last	O
,	O
we	O
present	O
the	O
influence	O
of	O
various	O
factors	O
,	O
including	O
detection	B-Task
recall	O
and	O
gallery	B-Metric
size	I-Metric
.	O
	
subsection	O
:	O
Experiment	O
Settings	O
	
We	O
implement	O
our	O
framework	O
based	O
on	O
Caffe	B-Method
and	O
py	B-Method
-	I-Method
faster	I-Method
-	I-Method
rcnn	I-Method
.	O
	
ImageNet	B-Method
-	I-Method
pretrained	I-Method
ResNet	I-Method
-	I-Method
50	I-Method
are	O
exploited	O
for	O
parameters	B-Task
initialization	I-Task
.	O
	
We	O
fix	O
the	O
first	O
convolution	B-Method
layer	I-Method
and	O
the	O
batch	B-Method
normalization	I-Method
(	O
BN	B-Method
)	O
layers	O
as	O
constant	O
affine	O
transformations	O
in	O
the	O
stem	O
part	O
,	O
while	O
keep	O
the	O
other	O
BN	B-Method
layers	O
as	O
normal	O
in	O
the	O
identification	O
part	O
.	O
	
The	O
temperature	O
scalar	O
in	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
and	O
	
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
is	O
set	O
to	O
,	O
the	O
size	O
of	O
the	O
circular	O
queue	O
is	O
set	O
to	O
.	O
	
All	O
the	O
losses	O
have	O
the	O
same	O
loss	O
weight	O
.	O
	
Each	O
mini	O
-	O
batch	O
consists	O
of	O
two	O
scene	O
images	O
.	O
	
The	O
learning	B-Metric
rate	I-Metric
is	O
initialized	O
to	O
,	O
dropped	O
to	O
after	O
K	O
iterations	O
,	O
and	O
kept	O
unchanged	O
until	O
the	O
model	O
converges	O
at	O
K	O
iterations	O
.	O
	
We	O
compare	O
our	O
framework	O
with	O
conventional	O
methods	O
that	O
break	O
down	O
the	O
problem	O
into	O
two	O
separate	O
tasks	O
—	O
pedestrian	O
detection	B-Task
and	O
person	B-Task
re	I-Task
-	I-Task
identification	I-Task
.	O
	
Three	O
pedestrian	O
detection	B-Task
and	O
five	O
person	O
re	B-Task
-	I-Task
i	I-Task
d	I-Task
methods	O
are	O
used	O
in	O
our	O
experiments	O
,	O
resulting	O
in	O
baseline	O
combinations	O
.	O
	
For	O
pedestrian	O
detection	B-Task
,	O
we	O
directly	O
use	O
the	O
off	B-Method
-	I-Method
the	I-Method
-	I-Method
shelf	I-Method
deep	I-Method
learning	I-Method
CCF	I-Method
detector	I-Method
,	O
as	O
well	O
as	O
two	O
other	O
detectors	O
specifically	O
fine	O
-	O
tuned	O
on	O
our	O
dataset	O
.	O
	
One	O
is	O
the	O
ACF	B-Method
,	O
and	O
the	O
other	O
is	O
Faster	B-Method
-	I-Method
RCNN	I-Method
(	O
CNN	B-Method
)	O
with	O
ResNet	B-Method
-	I-Method
50	I-Method
,	O
which	O
is	O
equivalent	O
to	O
our	O
framework	O
but	O
without	O
the	O
identification	B-Task
task	I-Task
.	O
	
The	O
recall	B-Metric
-	I-Metric
precision	I-Metric
curve	I-Metric
of	O
each	O
detector	O
on	O
our	O
dataset	O
are	O
plotted	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
We	O
also	O
use	O
the	O
ground	O
truth	O
(	O
GT	O
)	O
bounding	O
boxes	O
as	O
the	O
results	O
of	O
a	O
perfect	B-Method
detector	I-Method
.	O
	
For	O
person	B-Task
re	I-Task
-	I-Task
identification	I-Task
,	O
we	O
use	O
several	O
popular	O
re	B-Task
-	I-Task
i	I-Task
d	I-Task
feature	O
representations	O
,	O
including	O
DenseSIFT	B-Method
-	I-Method
ColorHist	I-Method
(	I-Method
DSIFT	I-Method
)	O
,	O
Bag	B-Method
of	I-Method
Words	I-Method
(	O
BoW	B-Method
)	O
,	O
and	O
Local	B-Method
Maximal	I-Method
Occurrence	I-Method
(	O
LOMO	B-Method
)	O
.	O
	
Each	O
feature	B-Method
representation	I-Method
is	O
used	O
in	O
conjunction	O
with	O
a	O
specific	O
distance	B-Metric
metric	I-Metric
,	O
including	O
Euclidean	O
,	O
Cosine	O
similarity	O
,	O
KISSME	B-Method
,	O
and	O
XQDA	B-Method
,	O
where	O
KISSME	B-Method
and	O
XQDA	B-Method
are	O
trained	O
on	O
our	O
dataset	O
.	O
	
Moreover	O
,	O
by	O
discarding	O
the	O
pedestrian	B-Method
proposal	I-Method
network	I-Method
in	O
our	O
framework	O
and	O
training	O
the	O
remaining	O
net	O
to	O
classify	O
identities	O
with	O
Softmax	O
loss	O
from	O
cropped	O
pedestrian	O
images	O
,	O
we	O
get	O
another	O
baseline	O
re	B-Task
-	I-Task
i	I-Task
d	I-Task
method	O
(	O
IDNet	B-Method
)	O
.	O
	
This	O
training	O
scheme	O
has	O
been	O
exploited	O
in	O
to	O
learn	O
discriminative	O
re	B-Task
-	I-Task
i	I-Task
d	I-Task
feature	O
representations	O
.	O
	
In	O
our	O
experiments	O
,	O
when	O
training	O
IDNet	B-Task
with	O
detector	O
boxes	O
,	O
we	O
found	O
that	O
adding	O
background	O
clutter	O
as	O
a	O
unique	O
class	O
improves	O
the	O
result	O
,	O
while	O
adding	O
unlabeled	O
identities	O
does	O
not	O
.	O
	
The	O
following	O
results	O
are	O
reported	O
using	O
the	O
protocol	O
with	O
gallery	O
size	O
equal	O
to	O
if	O
not	O
specified	O
.	O
	
subsection	O
:	O
Comparison	O
with	O
Detection	B-Task
and	O
Re	B-Task
-	I-Task
ID	I-Task
	
We	O
first	O
compare	O
our	O
proposed	O
person	B-Method
search	I-Method
framework	I-Method
(	O
with	O
or	O
without	O
using	O
unlabeled	O
identities	O
)	O
with	O
other	O
baseline	O
combinations	O
that	O
break	O
down	O
the	O
problem	O
into	O
separate	O
detection	B-Task
and	O
re	B-Task
-	I-Task
identification	I-Task
tasks	I-Task
.	O
	
The	O
results	O
are	O
summarized	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
Our	O
method	O
outperforms	O
the	O
others	O
by	O
large	O
margin	O
.	O
	
Comparing	O
with	O
CNN	B-Method
+	O
IDNet	O
,	O
the	O
gain	O
comes	O
from	O
the	O
joint	O
optimization	O
of	O
the	O
detection	B-Task
and	O
identification	O
parts	O
,	O
as	O
well	O
as	O
the	O
effective	O
use	O
of	O
unlabeled	O
identities	O
in	O
the	O
OIM	B-Method
loss	O
.	O
	
From	O
Table	O
[	O
reference	O
]	O
we	O
can	O
also	O
see	O
that	O
different	O
detectors	O
affect	O
the	O
person	B-Task
search	I-Task
performance	O
significantly	O
for	O
each	O
re	B-Task
-	I-Task
i	I-Task
d	I-Task
method	O
.	O
	
Directly	O
using	O
an	O
off	B-Method
-	I-Method
the	I-Method
-	I-Method
shelf	I-Method
detector	I-Method
may	O
not	O
be	O
a	O
good	O
choice	O
when	O
applying	O
existing	O
re	B-Task
-	I-Task
i	I-Task
d	I-Task
methods	I-Task
in	O
the	O
real	B-Task
-	I-Task
world	I-Task
person	I-Task
search	I-Task
applications	I-Task
.	O
	
Otherwise	O
the	O
detector	B-Method
could	O
become	O
a	O
bottleneck	O
that	O
diminishes	O
the	O
returns	O
of	O
better	O
re	B-Task
-	I-Task
i	I-Task
d	I-Task
methods	I-Task
.	O
	
On	O
the	O
other	O
hand	O
,	O
the	O
relative	O
performance	O
of	O
different	O
re	B-Task
-	I-Task
i	I-Task
d	I-Task
methods	I-Task
are	O
consistent	O
across	O
all	O
the	O
detectors	O
.	O
	
It	O
implies	O
that	O
existing	O
person	O
re	B-Task
-	I-Task
i	I-Task
d	I-Task
datasets	O
could	O
still	O
guide	O
us	O
to	O
design	O
better	O
feature	B-Method
representations	I-Method
,	O
but	O
it	O
may	O
lose	O
some	O
valuable	O
data	O
,	O
such	O
as	O
unlabeled	O
identities	O
and	O
background	O
clutter	O
,	O
which	O
come	O
with	O
the	O
person	O
search	O
datasets	O
.	O
	
Another	O
interesting	O
phenomenon	O
is	O
that	O
although	O
IDNet	B-Method
and	O
LOMO	B-Method
+	I-Method
XQDA	I-Method
have	O
similar	O
performance	O
when	O
using	O
GT	O
or	O
fine	O
-	O
tuned	O
ACF	O
and	O
CNN	B-Method
detectors	O
,	O
IDNet	B-Method
is	O
significantly	O
better	O
when	O
using	O
off	B-Method
-	I-Method
the	I-Method
-	I-Method
shelf	I-Method
CCF	I-Method
detector	I-Method
.	O
	
We	O
observe	O
that	O
the	O
CCF	O
detection	B-Task
results	O
contain	O
many	O
misalignments	O
.	O
	
Hand	O
-	O
crafted	O
features	O
in	O
such	O
cases	O
are	O
not	O
as	O
robust	O
as	O
the	O
IDNet	B-Method
counterpart	I-Method
.	O
	
subsection	O
:	O
Effectiveness	O
of	O
Online	B-Method
Instance	I-Method
Matching	I-Method
	
We	O
validate	O
the	O
effectiveness	O
of	O
the	O
proposed	O
Online	B-Method
Instance	I-Method
Matching	I-Method
(	O
OIM	B-Method
)	O
loss	O
by	O
comparing	O
it	O
against	O
Softmax	B-Method
baselines	I-Method
with	O
or	O
without	O
pretraining	O
the	O
classifier	O
matrix	O
.	O
	
The	O
training	B-Metric
identification	I-Metric
accuracy	I-Metric
and	O
test	O
person	B-Metric
search	I-Metric
mAP	I-Metric
curves	I-Metric
are	O
demonstrated	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
First	O
,	O
we	O
can	O
see	O
that	O
using	O
Softmax	B-Method
loss	I-Method
without	O
pretraining	B-Method
classifier	I-Method
remains	O
at	O
low	O
accuracy	B-Metric
during	O
the	O
whole	O
process	O
.	O
	
This	O
phenomenon	O
verifies	O
our	O
analysis	O
in	O
Section	O
[	O
reference	O
]	O
that	O
learning	O
a	O
large	O
classifier	O
matrix	O
is	O
difficult	O
.	O
	
Even	O
with	O
proper	O
pretraining	B-Method
,	O
the	O
training	B-Metric
accuracy	I-Metric
still	O
improves	O
slowly	O
,	O
and	O
the	O
test	O
mAP	B-Metric
keeps	O
at	O
around	O
.	O
	
On	O
the	O
contrary	O
,	O
the	O
proposed	O
OIM	B-Method
loss	O
starts	O
with	O
a	O
low	O
training	B-Metric
accuracy	I-Metric
but	O
converges	O
much	O
faster	O
and	O
also	O
consistently	O
improves	O
the	O
test	O
performance	O
.	O
	
The	O
parameter	O
-	O
free	O
OIM	B-Method
loss	O
learns	O
features	O
directly	O
without	O
needing	O
to	O
learn	O
a	O
big	O
classifier	O
matrix	O
.	O
	
Moreover	O
,	O
the	O
mismatch	O
between	O
training	O
and	O
test	O
criterion	O
no	O
longer	O
exists	O
,	O
as	O
both	O
are	O
computed	O
based	O
on	O
the	O
inner	O
product	O
of	O
L2	O
-	O
normalized	O
feature	O
vectors	O
,	O
which	O
represents	O
the	O
cosine	O
similarity	O
.	O
	
We	O
further	O
evaluate	O
the	O
impact	O
of	O
OIM	B-Method
loss	O
on	O
the	O
standard	O
person	B-Task
re	I-Task
-	I-Task
identification	I-Task
task	O
.	O
	
We	O
train	O
two	O
different	O
base	B-Method
CNNs	I-Method
,	O
Inception	B-Method
(	O
from	O
scratch	O
)	O
and	O
	
ResNet	B-Method
-	I-Method
50	I-Method
(	O
ImageNet	O
pretrained	O
)	O
,	O
with	O
either	O
Softmax	O
loss	O
or	O
OIM	B-Method
loss	O
,	O
on	O
three	O
large	O
-	O
scale	O
person	O
re	B-Task
-	I-Task
i	I-Task
d	I-Task
datasets	O
,	O
CUHK03	O
,	O
Market1501	O
,	O
and	O
Duke	B-Material
.	O
	
Following	O
their	O
own	O
protocols	O
,	O
we	O
evaluate	O
the	O
CMC	B-Metric
top	I-Metric
-	I-Metric
1	I-Metric
accuracy	I-Metric
of	O
using	O
different	O
loss	O
functions	O
,	O
as	O
listed	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
OIM	B-Method
loss	O
consistently	O
outperforms	O
Softmax	O
loss	O
,	O
regardless	O
of	O
which	O
base	O
CNN	B-Method
is	O
used	O
.	O
	
We	O
refer	O
readers	O
to	O
Open	O
-	O
ReID	O
benchmarks	O
for	O
more	O
details	O
.	O
	
[	O
t	O
]	O
0.32	O
[	O
t	O
]	O
0.32	O
[	O
t	O
]	O
0.32	O
	
Sub	O
-	O
sampling	O
the	O
identities	O
.	O
	
As	O
the	O
number	O
of	O
identities	O
increases	O
,	O
the	O
computation	B-Metric
time	I-Metric
of	O
the	O
OIM	B-Method
loss	O
could	O
become	O
the	O
bottleneck	O
of	O
the	O
whole	O
system	O
.	O
	
Thus	O
we	O
proposed	O
in	O
Section	O
[	O
reference	O
]	O
to	O
approximate	O
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
and	O
	
Eq	O
.	O
	
(	O
[	O
reference	O
]	O
)	O
by	O
sub	O
-	O
sampling	O
both	O
the	O
labeled	O
and	O
unlabeled	O
identities	O
in	O
the	O
denominators	O
.	O
	
We	O
validate	O
this	O
approach	O
here	O
by	O
training	O
the	O
framework	O
with	O
sub	O
-	O
sampling	O
size	O
of	O
,	O
,	O
and	O
.	O
	
The	O
test	O
mAP	B-Metric
curves	O
are	O
demonstrated	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
In	O
general	O
,	O
sub	O
-	O
sampling	O
a	O
small	O
number	O
of	O
identities	O
relaxes	O
the	O
training	B-Metric
objective	I-Metric
,	O
which	O
leads	O
to	O
slightly	O
inferior	O
performance	O
but	O
much	O
faster	O
convergence	B-Metric
rate	I-Metric
.	O
	
This	O
indicates	O
that	O
our	O
framework	O
is	O
scalable	O
to	O
larger	O
datasets	O
with	O
even	O
more	O
identities	O
by	O
using	O
proper	O
sub	B-Metric
-	I-Metric
sampling	I-Metric
rate	I-Metric
.	O
	
Low	B-Method
-	I-Method
dimensional	I-Method
subspace	I-Method
.	O
	
We	O
further	O
investigate	O
how	O
the	O
dimension	O
of	O
the	O
L2	O
-	O
normalized	O
feature	O
vector	O
affects	O
the	O
person	B-Task
search	I-Task
performance	O
.	O
	
The	O
results	O
are	O
summarized	O
in	O
Table	O
[	O
reference	O
]	O
.	O
	
We	O
observe	O
that	O
using	O
the	O
-	O
d	O
global	O
pooled	O
feature	O
vector	O
directly	O
with	O
L2	B-Method
-	I-Method
normalization	I-Method
leads	O
to	O
lower	O
training	B-Metric
error	I-Metric
,	O
but	O
its	O
test	O
performance	O
is	O
worse	O
.	O
	
This	O
suggests	O
that	O
projecting	O
the	O
features	O
into	O
a	O
proper	O
low	O
-	O
rank	O
subspace	O
is	O
very	O
important	O
to	O
regularize	O
the	O
network	B-Task
training	I-Task
.	O
	
In	O
our	O
experiments	O
,	O
to	O
dimensions	O
have	O
similar	O
test	O
performance	O
,	O
and	O
we	O
choose	O
-	O
d	O
to	O
accelerate	O
the	O
computation	O
of	O
feature	O
distances	O
.	O
	
subsection	O
:	O
Factors	O
for	O
Person	B-Task
Search	I-Task
	
Detection	B-Metric
Recall	I-Metric
.	O
	
We	O
investigate	O
how	O
detection	B-Task
recalls	O
would	O
affect	O
the	O
person	B-Task
search	I-Task
performance	O
by	O
using	O
LOMO	B-Method
+	I-Method
XQDA	I-Method
as	O
the	O
re	B-Task
-	I-Task
i	I-Task
d	I-Task
method	I-Task
and	O
setting	O
different	O
thresholds	O
on	O
detection	B-Task
scores	O
.	O
	
A	O
lower	O
threshold	O
reduces	O
misdetections	O
(	O
increases	O
the	O
recall	B-Metric
)	O
but	O
results	O
in	O
more	O
false	O
alarms	O
.	O
	
We	O
choose	O
the	O
recall	B-Metric
rates	I-Metric
ranging	O
from	O
to	O
the	O
maximum	O
value	O
of	O
each	O
detector	O
.	O
	
The	O
final	O
person	B-Metric
search	I-Metric
mAP	I-Metric
under	O
each	O
setting	O
is	O
demonstrated	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
An	O
interesting	O
observation	O
is	O
that	O
higher	O
recall	B-Metric
does	O
not	O
necessarily	O
lead	O
to	O
higher	O
person	B-Task
search	I-Task
performance	O
,	O
which	O
means	O
re	B-Task
-	I-Task
i	I-Task
d	I-Task
method	I-Task
could	O
still	O
get	O
confused	O
on	O
some	O
false	O
alarms	O
.	O
	
This	O
again	O
indicates	O
that	O
we	O
should	O
not	O
focus	O
solely	O
on	O
training	O
re	B-Task
-	I-Task
i	I-Task
d	I-Task
methods	I-Task
with	O
manually	O
cropped	O
pedestrians	O
,	O
but	O
should	O
consider	O
the	O
detections	O
jointly	O
under	O
the	O
person	B-Task
search	I-Task
problem	I-Task
setting	I-Task
.	O
	
Gallery	B-Metric
size	I-Metric
.	O
	
Person	B-Task
search	I-Task
could	O
be	O
more	O
challenging	O
as	O
the	O
gallery	O
size	O
increases	O
.	O
	
We	O
evaluate	O
several	O
methods	O
under	O
different	O
test	O
gallery	O
sizes	O
from	O
to	O
full	O
set	O
of	O
images	O
,	O
following	O
the	O
protocols	O
defined	O
in	O
Section	O
[	O
reference	O
]	O
.	O
	
The	O
test	O
mAPs	O
are	O
demonstrated	O
in	O
Figure	O
[	O
reference	O
]	O
.	O
	
Note	O
that	O
for	O
each	O
test	O
query	O
,	O
the	O
corresponding	O
gallery	O
images	O
are	O
randomly	O
sampled	O
from	O
the	O
whole	O
set	O
.	O
	
All	O
test	O
images	O
are	O
covered	O
even	O
with	O
small	O
gallery	O
sizes	O
.	O
	
The	O
performance	O
gaps	O
among	O
different	O
methods	O
are	O
reduced	O
as	O
the	O
gallery	O
size	O
increases	O
,	O
indicating	O
all	O
the	O
methods	O
may	O
suffer	O
from	O
some	O
common	O
hard	O
samples	O
,	O
and	O
we	O
could	O
further	O
improve	O
the	O
performance	O
with	O
hard	B-Task
example	I-Task
minings	I-Task
.	O
	
section	O
:	O
Conclusion	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
new	O
deep	B-Method
learning	I-Method
framework	I-Method
for	O
person	B-Task
search	I-Task
.	O
	
It	O
jointly	O
handles	O
detection	B-Task
and	O
identification	B-Task
in	O
a	O
single	O
CNN	B-Method
.	O
	
An	O
Online	B-Method
Instance	I-Method
Matching	I-Method
loss	O
function	O
is	O
proposed	O
to	O
train	O
the	O
network	O
effectively	O
.	O
	
Its	O
non	B-Method
-	I-Method
parametric	I-Method
nature	I-Method
enables	O
faster	O
yet	O
better	O
convergence	B-Metric
,	O
which	O
is	O
validated	O
through	O
series	O
of	O
experiments	O
.	O
	
Acknowledgements	O
.	O
	
This	O
work	O
is	O
supported	O
in	O
part	O
by	O
SenseTime	O
Group	O
Limited	O
,	O
in	O
part	O
by	O
the	O
General	O
Research	O
Fund	O
through	O
the	O
Research	O
Grants	O
Council	O
of	O
Hong	O
Kong	O
under	O
Grants	O
CUHK14213616	O
,	O
CUHK14206114	O
,	O
CUHK14205615	O
,	O
CUHK14207814	O
,	O
CUHK14203015	O
,	O
CUHK14239816	O
,	O
and	O
CUHK419412	O
,	O
in	O
part	O
by	O
the	O
Hong	O
Kong	O
Innovation	O
and	O
Technology	O
Support	O
Programme	O
Grant	O
ITS	O
/	O
121	O
/	O
15FX	O
,	O
in	O
part	O
by	O
the	O
State	O
Key	O
Development	O
Program	O
under	O
Grant	O
2016YFB1001004	O
,	O
in	O
part	O
by	O
the	O
Guangdong	O
Natural	O
Science	O
Foundation	O
under	O
Grant	O
No	O
.	O
2014A030313201	O
,	O
and	O
in	O
part	O
by	O
National	O
Natural	O
Science	O
Foundation	O
of	O
China	O
under	O
Grant	O
61371192	O
.	O
	
bibliography	O
:	O
References	O
	
document	O
:	O
Invariant	B-Method
Information	I-Method
Clustering	I-Method
for	O
Unsupervised	B-Task
Image	I-Task
Classification	I-Task
and	O
Segmentation	B-Task
	
We	O
present	O
a	O
novel	O
clustering	B-Method
objective	I-Method
that	O
learns	O
a	O
neural	B-Method
network	I-Method
classifier	I-Method
from	O
scratch	O
,	O
given	O
only	O
unlabelled	O
data	O
samples	O
.	O
	
The	O
model	O
discovers	O
clusters	O
that	O
accurately	O
match	O
semantic	O
classes	O
,	O
achieving	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
in	O
eight	O
unsupervised	B-Task
clustering	O
benchmarks	O
spanning	O
image	B-Task
classification	I-Task
and	I-Task
segmentation	I-Task
.	O
	
These	O
include	O
STL10	O
,	O
an	O
unsupervised	B-Task
variant	O
of	O
ImageNet	O
,	O
and	O
CIFAR10	O
,	O
where	O
we	O
significantly	O
beat	O
the	O
accuracy	B-Metric
of	O
our	O
closest	O
competitors	O
by	O
8	O
and	O
9.5	O
absolute	O
percentage	O
points	O
respectively	O
.	O
	
The	O
method	O
is	O
not	O
specialised	O
to	O
computer	B-Task
vision	I-Task
and	O
operates	O
on	O
any	O
paired	O
dataset	O
samples	O
;	O
in	O
our	O
experiments	O
we	O
use	O
random	B-Method
transforms	I-Method
to	O
obtain	O
a	O
pair	O
from	O
each	O
image	O
.	O
	
The	O
trained	O
network	O
directly	O
outputs	O
semantic	O
labels	O
,	O
rather	O
than	O
high	B-Method
dimensional	I-Method
representations	I-Method
that	O
need	O
external	O
processing	O
to	O
be	O
usable	O
for	O
semantic	B-Task
clustering	I-Task
.	O
	
The	O
objective	O
is	O
simply	O
to	O
maximise	O
mutual	O
information	O
between	O
the	O
class	O
assignments	O
of	O
each	O
pair	O
.	O
	
It	O
is	O
easy	O
to	O
implement	O
and	O
rigorously	O
grounded	O
in	O
information	B-Method
theory	I-Method
,	O
meaning	O
we	O
effortlessly	O
avoid	O
degenerate	O
solutions	O
that	O
other	O
clustering	B-Method
methods	I-Method
are	O
susceptible	O
to	O
.	O
	
In	O
addition	O
to	O
the	O
fully	O
unsupervised	B-Task
mode	O
,	O
we	O
also	O
test	O
two	O
semi	O
-	O
supervised	B-Task
settings	O
.	O
	
The	O
first	O
achieves	O
88.8	O
%	O
accuracy	B-Metric
on	O
STL10	B-Task
classification	I-Task
,	O
setting	O
a	O
new	O
global	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
over	O
all	O
existing	O
methods	O
(	O
whether	O
supervised	B-Task
,	O
semi	B-Task
-	I-Task
supervised	I-Task
or	O
unsupervised	B-Task
)	O
.	O
	
The	O
second	O
shows	O
robustness	O
to	O
90	O
%	O
reductions	O
in	O
label	B-Metric
coverage	I-Metric
,	O
of	O
relevance	O
to	O
applications	O
that	O
wish	O
to	O
make	O
use	O
of	O
small	O
amounts	O
of	O
labels	O
.	O
	
capbtabboxtable	O
[	O
]	O
	
[	O
]	O
[	O
table	O
]	O
capposition	O
=	O
bottom	O
	
,	O
captionskip=0.2em	O
[	O
figure	O
]	O
capposition	O
=	O
bottom	O
,	O
captionskip=0.2em	O
	
section	O
:	O
Introduction	O
	
Most	O
supervised	B-Task
deep	O
learning	O
methods	O
require	O
large	O
quantities	O
of	O
manually	O
labelled	O
data	O
,	O
limiting	O
their	O
applicability	O
in	O
many	O
scenarios	O
.	O
	
This	O
is	O
true	O
for	O
large	B-Task
-	I-Task
scale	I-Task
image	I-Task
classification	I-Task
and	O
even	O
more	O
for	O
segmentation	B-Task
(	O
pixel	B-Task
-	I-Task
wise	I-Task
classification	I-Task
)	O
where	O
the	O
annotation	B-Metric
cost	I-Metric
per	O
image	O
is	O
very	O
high	O
.	O
	
Unsupervised	B-Method
clustering	I-Method
,	O
on	O
the	O
other	O
hand	O
,	O
aims	O
to	O
group	O
data	O
points	O
into	O
classes	O
entirely	O
without	O
labels	O
.	O
	
Many	O
authors	O
have	O
sought	O
to	O
combine	O
mature	O
clustering	B-Method
algorithms	I-Method
with	O
deep	B-Method
learning	I-Method
,	O
for	O
example	O
by	O
bootstrapping	B-Method
network	I-Method
training	I-Method
with	O
k	B-Method
-	I-Method
means	I-Method
style	I-Method
objectives	I-Method
.	O
	
However	O
,	O
trivially	O
combining	O
clustering	B-Method
and	I-Method
representation	I-Method
learning	I-Method
methods	I-Method
often	O
leads	O
to	O
degenerate	O
solutions	O
.	O
	
It	O
is	O
precisely	O
to	O
prevent	O
such	O
degeneracy	O
that	O
cumbersome	O
pipelines	O
—	O
involving	O
pre	B-Method
-	I-Method
training	I-Method
,	O
feature	B-Method
post	I-Method
-	I-Method
processing	I-Method
(	O
whitening	B-Method
or	O
PCA	B-Method
)	O
,	O
clustering	B-Method
mechanisms	I-Method
external	O
to	O
the	O
network	O
—	O
have	O
evolved	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
introduce	O
Invariant	B-Method
Information	I-Method
Clustering	I-Method
(	O
IIC	B-Method
)	O
,	O
a	O
method	O
that	O
addresses	O
this	O
issue	O
in	O
a	O
more	O
principled	O
manner	O
.	O
	
IIC	B-Method
is	O
a	O
generic	O
clustering	B-Method
algorithm	I-Method
that	O
directly	O
trains	O
a	O
randomly	B-Method
initialised	I-Method
neural	I-Method
network	I-Method
into	O
a	O
classification	B-Method
function	I-Method
,	O
end	O
-	O
to	O
-	O
end	O
and	O
without	O
any	O
labels	O
.	O
	
It	O
involves	O
a	O
simple	O
objective	B-Method
function	I-Method
,	O
which	O
is	O
the	O
mutual	O
information	O
between	O
the	O
function	O
’s	O
classifications	O
for	O
paired	O
data	O
samples	O
.	O
	
The	O
input	O
data	O
can	O
be	O
of	O
any	O
modality	O
and	O
,	O
since	O
the	O
clustering	O
space	O
is	O
discrete	O
,	O
mutual	O
information	O
can	O
be	O
computed	O
exactly	O
.	O
	
Despite	O
its	O
simplicity	O
,	O
IIC	B-Method
is	O
intrinsically	O
robust	O
to	O
two	O
issues	O
that	O
affect	O
other	O
methods	O
.	O
	
The	O
first	O
is	O
clustering	B-Metric
degeneracy	I-Metric
,	O
which	O
is	O
the	O
tendency	O
for	O
a	O
single	O
cluster	O
to	O
dominate	O
the	O
predictions	O
or	O
for	O
clusters	O
to	O
disappear	O
(	O
which	O
can	O
be	O
observed	O
with	O
k	B-Method
-	I-Method
means	I-Method
,	O
especially	O
when	O
combined	O
with	O
representation	B-Method
learning	I-Method
)	O
.	O
	
Due	O
to	O
the	O
entropy	B-Method
maximisation	I-Method
component	I-Method
within	O
mutual	O
information	O
,	O
the	O
loss	O
is	O
not	O
minimised	O
if	O
all	O
images	O
are	O
assigned	O
to	O
the	O
same	O
class	O
.	O
	
At	O
the	O
same	O
time	O
,	O
it	O
is	O
optimal	O
for	O
the	O
model	O
to	O
predict	O
for	O
each	O
image	O
a	O
single	O
class	O
with	O
certainty	O
(	O
i.e.	O
one	O
-	O
hot	O
)	O
due	O
to	O
the	O
conditional	B-Method
entropy	I-Method
minimisation	I-Method
(	O
f	O
:	O
mnist_dots	B-Method
)	O
.	O
	
The	O
second	O
issue	O
is	O
noisy	O
data	O
with	O
unknown	O
or	O
distractor	O
classes	O
(	O
present	O
in	O
STL10	O
for	O
example	O
)	O
.	O
	
IIC	B-Method
addresses	O
this	O
issue	O
by	O
employing	O
an	O
auxiliary	B-Method
output	I-Method
layer	I-Method
that	O
is	O
parallel	O
to	O
the	O
main	O
output	B-Method
layer	I-Method
,	O
trained	O
to	O
produce	O
an	O
overclustering	O
(	O
i.e.	O
same	O
loss	O
function	O
but	O
greater	O
number	O
of	O
clusters	O
than	O
the	O
ground	O
truth	O
)	O
that	O
is	O
ignored	O
at	O
test	O
time	O
.	O
	
Auxiliary	B-Method
overclustering	I-Method
is	O
a	O
general	O
technique	O
that	O
could	O
be	O
useful	O
for	O
other	O
algorithms	O
.	O
	
These	O
two	O
features	O
of	O
IIC	B-Method
contribute	O
to	O
making	O
it	O
the	O
only	O
method	O
amongst	O
our	O
unsupervised	B-Task
baselines	O
that	O
is	O
robust	O
enough	O
to	O
make	O
use	O
of	O
the	O
noisy	O
unlabelled	O
subset	O
of	O
STL10	O
,	O
a	O
version	O
of	O
ImageNet	O
specifically	O
designed	O
as	O
a	O
benchmark	O
for	O
unsupervised	B-Task
clustering	O
.	O
	
In	O
the	O
rest	O
of	O
the	O
paper	O
,	O
we	O
begin	O
by	O
explaining	O
the	O
difference	O
between	O
semantic	B-Method
clustering	I-Method
and	O
intermediate	B-Method
representation	I-Method
learning	I-Method
(	O
s	O
:	O
related	O
)	O
,	O
which	O
separates	O
our	O
method	O
from	O
the	O
majority	O
of	O
work	O
in	O
unsupervised	B-Task
deep	O
learning	O
.	O
	
We	O
then	O
describe	O
the	O
theoretical	O
foundations	O
of	O
IIC	B-Method
in	O
statistical	B-Method
learning	I-Method
(	O
s	B-Method
:	I-Method
method	I-Method
)	O
,	O
demonstrating	O
that	O
maximising	O
mutual	O
information	O
between	O
pairs	O
of	O
samples	O
under	O
a	O
bottleneck	O
is	O
a	O
principled	B-Method
clustering	I-Method
objective	I-Method
which	O
is	O
equivalent	O
to	O
distilling	O
their	O
shared	O
abstract	O
content	O
(	O
co	B-Method
-	I-Method
clustering	I-Method
)	O
.	O
	
We	O
propose	O
that	O
for	O
static	O
images	O
,	O
an	O
easy	O
way	O
to	O
generate	O
pairs	O
with	O
shared	O
abstract	O
content	O
from	O
unlabelled	O
data	O
is	O
to	O
take	O
each	O
image	O
and	O
its	O
random	O
transformation	O
,	O
or	O
each	O
patch	O
and	O
a	O
neighbour	O
.	O
	
We	O
show	O
that	O
maximising	B-Task
MI	I-Task
automatically	O
avoids	O
degenerate	O
solutions	O
and	O
can	O
be	O
written	O
as	O
a	O
convolution	B-Method
in	O
the	O
case	O
of	O
segmentation	B-Task
,	O
allowing	O
for	O
efficient	O
implementation	O
with	O
any	O
deep	B-Method
learning	I-Method
library	I-Method
.	O
	
We	O
perform	O
experiments	O
on	O
a	O
large	O
number	O
of	O
datasets	O
(	O
s	O
:	O
experiments	O
)	O
including	O
STL	O
,	O
CIFAR	O
,	O
MNIST	B-Material
,	O
COCO	O
-	O
Stuff	O
and	O
Potsdam	O
,	O
setting	O
a	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
on	O
unsupervised	B-Task
clustering	O
and	O
segmentation	B-Task
in	O
all	O
cases	O
,	O
with	O
results	O
of	O
61.0	O
%	O
,	O
61.7	O
%	O
and	O
72.3	O
%	O
on	O
STL10	O
,	O
CIFAR10	O
and	O
COCO	O
-	O
Stuff	O
-	O
3	O
beating	O
the	O
closest	O
competitors	O
(	O
53.0	O
%	O
,	O
52.2	O
%	O
,	O
54.0	O
%	O
)	O
with	O
significant	O
margins	O
.	O
	
Note	O
that	O
training	O
deep	B-Method
neural	I-Method
networks	I-Method
to	O
perform	O
large	B-Task
scale	I-Task
,	I-Task
real	I-Task
-	I-Task
world	I-Task
segmentations	I-Task
from	O
scratch	O
,	O
without	O
labels	O
or	O
heuristics	O
,	O
is	O
a	O
highly	O
challenging	O
task	O
with	O
negligible	O
precedent	O
.	O
	
We	O
also	O
perform	O
an	O
ablation	O
study	O
and	O
additionally	O
test	O
two	O
semi	O
-	O
supervised	B-Task
modes	O
,	O
setting	O
a	O
new	O
global	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
of	O
88.8	O
%	O
on	O
STL10	O
over	O
all	O
supervised	B-Task
,	O
semi	B-Task
-	I-Task
supervised	I-Task
and	O
unsupervised	B-Task
methods	O
,	O
and	O
demonstrating	O
the	O
robustness	B-Metric
in	O
semi	O
-	O
supervised	B-Task
accuracy	I-Metric
when	O
90	O
%	O
of	O
labels	O
are	O
removed	O
.	O
	
section	O
:	O
Related	O
work	O
	
paragraph	O
:	O
Co	B-Method
-	I-Method
clustering	I-Method
and	O
mutual	O
information	O
.	O
	
The	O
use	O
of	O
information	O
as	O
a	O
criterion	O
to	O
learn	O
representations	B-Task
is	O
not	O
new	O
.	O
	
One	O
of	O
the	O
earliest	O
works	O
to	O
do	O
so	O
is	O
by	O
Becker	O
and	O
Hinton	O
.	O
	
More	O
generally	O
,	O
learning	B-Task
from	O
paired	O
data	O
has	O
also	O
been	O
explored	O
in	O
co	B-Task
-	I-Task
clustering	I-Task
and	O
in	O
other	O
works	O
that	O
build	O
on	O
the	O
information	B-Method
bottleneck	I-Method
principle	I-Method
.	O
	
Several	O
recent	O
papers	O
have	O
used	O
information	O
as	O
a	O
tool	O
to	O
train	O
deep	B-Method
networks	I-Method
in	O
particular	O
,	O
albeit	O
not	O
for	O
discrete	B-Task
clustering	I-Task
.	O
	
IMSAT	B-Method
maximises	O
mutual	O
information	O
between	O
data	O
and	O
its	O
representation	O
and	O
DeepINFOMAX	B-Method
maximizes	O
information	O
between	O
spatially	O
-	O
preserved	O
features	O
and	O
compact	O
features	O
.	O
	
However	O
,	O
IMSAT	B-Method
and	O
DeepINFOMAX	B-Method
combine	O
information	O
with	O
other	O
criteria	O
,	O
whereas	O
in	O
our	O
method	O
information	O
is	O
the	O
only	O
criterion	O
used	O
.	O
	
Furthermore	O
,	O
both	O
IMSAT	B-Method
and	O
DeepINFOMAX	B-Method
compute	O
mutual	O
information	O
over	O
continuous	O
random	O
variables	O
,	O
which	O
requires	O
complex	O
estimators	O
,	O
whereas	O
IIC	B-Method
does	O
so	O
for	O
discrete	O
variables	O
with	O
simple	O
and	O
exact	O
computations	O
.	O
	
Finally	O
,	O
DeepINFOMAX	B-Method
considers	O
the	O
information	O
between	O
the	O
features	O
and	O
a	O
deterministic	O
function	O
of	O
it	O
,	O
which	O
is	O
in	O
principle	O
the	O
same	O
as	O
the	O
entropy	O
;	O
in	O
contrast	O
,	O
in	O
IIC	B-Method
information	O
does	O
not	O
trivially	O
reduce	O
to	O
entropy	O
.	O
	
paragraph	O
:	O
Semantic	B-Method
clustering	I-Method
versus	O
intermediate	B-Method
representation	I-Method
learning	I-Method
.	O
	
In	O
semantic	B-Task
clustering	I-Task
,	O
the	O
learned	O
function	O
directly	O
outputs	O
discrete	O
assignments	O
for	O
high	O
level	O
(	O
i.e.	O
semantic	O
)	O
clusters	O
.	O
	
Intermediate	B-Method
representation	I-Method
learners	I-Method
,	O
on	O
the	O
other	O
hand	O
,	O
produce	O
continuous	B-Task
,	I-Task
distributed	I-Task
,	I-Task
high	I-Task
-	I-Task
dimensional	I-Task
representations	I-Task
that	O
must	O
be	O
post	O
-	O
processed	O
,	O
for	O
example	O
by	O
k	B-Method
-	I-Method
means	I-Method
,	O
to	O
obtain	O
the	O
discrete	O
low	O
-	O
cardinality	O
assignments	O
required	O
for	O
unsupervised	B-Task
semantic	O
clustering	O
.	O
	
The	O
latter	O
includes	O
objectives	O
such	O
as	O
generative	B-Task
autoencoder	I-Task
image	I-Task
reconstruction	I-Task
,	O
triplets	B-Task
and	O
spatial	B-Task
-	I-Task
temporal	I-Task
order	I-Task
or	O
context	B-Task
prediction	I-Task
,	O
for	O
example	O
predicting	B-Task
patch	I-Task
proximity	I-Task
,	O
solving	O
jigsaw	B-Task
puzzles	I-Task
and	O
inpainting	B-Task
.	O
	
Note	O
it	O
also	O
includes	O
a	O
number	O
of	O
clustering	B-Method
methods	I-Method
(	O
DeepCluster	B-Method
,	O
exemplars	B-Method
)	O
where	O
the	O
clustering	B-Method
is	O
only	O
auxiliary	O
;	O
a	O
clustering	B-Method
-	I-Method
style	I-Method
objective	I-Method
is	O
used	O
but	O
does	O
not	O
produce	O
groups	O
with	O
semantic	O
correspondence	O
.	O
	
For	O
example	O
,	O
DeepCluster	B-Method
is	O
a	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
method	O
for	O
learning	B-Task
highly	I-Task
-	I-Task
transferable	I-Task
intermediate	I-Task
features	I-Task
using	O
overclustering	B-Method
as	O
a	O
proxy	B-Task
task	I-Task
,	O
but	O
does	O
not	O
automatically	O
find	O
semantically	O
meaningful	O
clusters	O
.	O
	
As	O
these	O
methods	O
use	O
auxiliary	O
objectives	O
divorced	O
from	O
the	O
semantic	B-Method
clustering	I-Method
objective	I-Method
,	O
it	O
is	O
unsurprising	O
that	O
they	O
perform	O
worse	O
than	O
IIC	B-Method
(	O
s	O
:	O
experiments	O
)	O
,	O
which	O
directly	O
optimises	O
for	O
it	O
,	O
training	O
the	O
network	O
end	O
-	O
to	O
-	O
end	O
with	O
the	O
final	O
clusterer	O
implicitly	O
wrapped	O
inside	O
.	O
	
paragraph	O
:	O
Optimising	B-Task
image	I-Task
-	I-Task
to	I-Task
-	I-Task
image	I-Task
distance	I-Task
.	O
	
Many	O
approaches	O
to	O
deep	B-Task
clustering	I-Task
,	O
whether	O
semantic	O
or	O
auxiliary	O
,	O
utilise	O
a	O
distance	O
function	O
between	O
input	O
images	O
that	O
approximates	O
a	O
given	O
grouping	B-Metric
criterion	I-Metric
.	O
	
Agglomerative	B-Method
clustering	I-Method
and	O
partially	O
ordered	O
sets	O
of	O
HOG	O
features	O
have	O
been	O
used	O
to	O
group	O
images	O
,	O
and	O
exemplars	O
define	O
a	O
group	O
as	O
a	O
set	O
of	O
random	O
transformations	O
applied	O
to	O
a	O
single	O
image	O
.	O
	
Note	O
the	O
latter	O
does	O
not	O
scale	O
easily	O
,	O
in	O
particular	O
to	O
image	B-Task
segmentation	I-Task
where	O
a	O
single	O
image	O
would	O
call	O
for	O
40k	O
classes	O
.	O
	
DAC	B-Method
,	O
JULE	B-Method
,	O
DeepCluster	B-Method
,	O
ADC	B-Method
and	O
DEC	B-Method
rely	O
on	O
the	O
inherent	O
visual	O
consistency	O
and	O
disentangling	O
properties	O
of	O
CNNs	B-Method
to	O
produce	O
cluster	O
assignments	O
,	O
which	O
are	O
processed	O
and	O
reinforced	O
in	O
each	O
iteration	O
.	O
	
The	O
latter	O
three	O
are	O
based	O
on	O
k	B-Method
-	I-Method
means	I-Method
style	I-Method
mechanisms	I-Method
to	O
refine	O
feature	O
centroids	O
,	O
which	O
is	O
prone	O
to	O
degenerate	O
solutions	O
and	O
thus	O
needs	O
explicit	O
prevention	B-Method
mechanisms	I-Method
such	O
as	O
pre	B-Method
-	I-Method
training	I-Method
,	O
cluster	B-Method
-	I-Method
reassignment	I-Method
or	O
feature	B-Method
cleaning	I-Method
via	O
PCA	B-Method
and	O
whitening	B-Method
.	O
	
paragraph	O
:	O
Invariance	O
as	O
a	O
training	O
objective	O
.	O
	
Optimising	O
for	O
function	O
outputs	O
to	O
be	O
persistent	O
through	O
spatio	O
-	O
temporal	O
or	O
non	O
-	O
material	O
distortion	O
is	O
an	O
idea	O
shared	O
by	O
IIC	B-Method
with	O
several	O
works	O
,	O
including	O
exemplars	B-Method
,	O
IMSAT	B-Method
,	O
proximity	B-Method
prediction	I-Method
,	O
the	O
denoising	B-Metric
objective	I-Metric
of	O
Tagger	B-Method
,	O
temporal	O
slowness	O
constraints	O
,	O
and	O
optimising	O
for	O
features	O
to	O
be	O
invariant	O
to	O
local	O
image	O
transformations	O
.	O
	
More	O
broadly	O
,	O
the	O
problem	O
of	O
modelling	B-Task
data	I-Task
transformation	I-Task
has	O
received	O
significant	O
attention	O
in	O
deep	B-Task
learning	I-Task
,	O
one	O
example	O
being	O
the	O
transforming	B-Method
autoencoder	I-Method
.	O
	
section	O
:	O
Method	O
	
First	O
we	O
introduce	O
a	O
generic	O
objective	O
,	O
Invariant	B-Method
Information	I-Method
Clustering	I-Method
,	O
which	O
can	O
be	O
used	O
to	O
cluster	O
any	O
kind	O
of	O
unlabelled	O
paired	O
data	O
by	O
training	O
a	O
network	O
to	O
predict	O
cluster	O
identities	O
(	O
s	O
:	O
generic_clustering	O
)	O
.	O
	
We	O
then	O
apply	O
it	O
to	O
image	B-Task
clustering	I-Task
(	O
s	O
:	O
	
image_clustering	O
,	O
f	O
:	O
overview	O
and	O
f	O
:	O
mnist_dots	B-Method
)	O
and	O
segmentation	B-Task
(	O
s	O
:	O
	
image_segmentation	B-Task
)	I-Task
,	O
by	O
generating	O
the	O
required	O
paired	O
data	O
using	O
random	O
transformations	O
and	O
spatial	O
proximity	O
.	O
	
subsection	O
:	O
Invariant	B-Method
Information	I-Method
Clustering	I-Method
	
Let	O
be	O
a	O
paired	O
data	O
sample	O
from	O
a	O
joint	O
probability	O
distribution	O
.	O
	
For	O
example	O
,	O
and	O
could	O
be	O
different	O
images	O
containing	O
the	O
same	O
object	O
.	O
	
The	O
goal	O
of	O
Invariant	B-Method
Information	I-Method
Clustering	I-Method
(	O
IIC	B-Method
)	O
is	O
to	O
learn	O
a	O
representation	O
that	O
preserves	O
what	O
is	O
in	O
common	O
between	O
and	O
while	O
discarding	O
instance	O
-	O
specific	O
details	O
.	O
	
The	O
former	O
can	O
be	O
achieved	O
by	O
maximizing	O
the	O
mutual	O
information	O
between	O
encoded	O
variables	O
:	O
which	O
is	O
equivalent	O
to	O
maximising	O
the	O
predictability	O
of	O
from	O
and	O
vice	O
versa	O
.	O
	
An	O
effect	O
of	O
equation	O
e	O
:	O
	
info_orig	B-Method
,	O
in	O
general	O
,	O
is	O
to	O
make	O
representations	O
of	O
paired	O
samples	O
the	O
same	O
.	O
	
However	O
,	O
it	O
is	O
not	O
the	O
same	O
as	O
merely	O
minimising	O
representation	O
distance	O
,	O
as	O
done	O
for	O
example	O
in	O
methods	O
based	O
on	O
k	B-Method
-	I-Method
means	I-Method
:	O
the	O
presence	O
of	O
entropy	O
within	O
allows	O
us	O
to	O
avoid	O
degeneracy	O
,	O
as	O
discussed	O
in	O
detail	O
below	O
.	O
	
If	O
is	O
a	O
neural	B-Method
network	I-Method
with	O
a	O
small	O
output	O
capacity	O
(	O
often	O
called	O
a	O
	
‘	O
‘	O
bottleneck	O
’	O
’	O
)	O
,	O
e	O
:	O
	
info_orig	B-Method
also	O
has	O
the	O
effect	O
of	O
discarding	O
instance	O
-	O
specific	O
details	O
from	O
the	O
data	O
.	O
	
Clustering	B-Method
imposes	O
a	O
natural	O
bottleneck	O
,	O
since	O
the	O
representation	O
space	O
is	O
,	O
a	O
finite	O
set	O
of	O
class	O
indices	O
(	O
as	O
opposed	O
to	O
an	O
infinite	O
vector	O
space	O
)	O
.	O
	
Without	O
a	O
bottleneck	O
,	O
i.e.	O
assuming	O
unbounded	O
capacity	O
,	O
e	O
:	O
info_orig	O
is	O
trivially	O
solved	O
by	O
setting	O
to	O
the	O
identity	O
function	O
because	O
of	O
the	O
data	O
processing	O
inequality	O
,	O
i.e.	O
.	O
	
Since	O
our	O
goal	O
is	O
to	O
learn	O
the	O
representation	O
with	O
a	O
deep	B-Method
neural	I-Method
network	I-Method
,	O
we	O
consider	O
soft	O
rather	O
than	O
hard	B-Task
clustering	I-Task
,	O
meaning	O
the	O
neural	B-Method
network	I-Method
is	O
terminated	O
by	O
a	O
(	O
differentiable	B-Method
)	I-Method
softmax	I-Method
layer	I-Method
.	O
	
Then	O
the	O
output	O
can	O
be	O
interpreted	O
as	O
the	O
distribution	O
of	O
a	O
discrete	O
random	O
variable	O
over	O
classes	O
,	O
formally	O
given	O
by	O
.	O
	
Making	O
the	O
output	O
probabilistic	O
amounts	O
to	O
allowing	O
for	O
uncertainty	O
in	O
the	O
cluster	O
assigned	O
to	O
an	O
input	O
.	O
	
Consider	O
now	O
a	O
pair	O
of	O
such	O
cluster	O
assignment	O
variables	O
and	O
for	O
two	O
inputs	O
and	O
respectively	O
.	O
	
Their	O
conditional	O
joint	O
distribution	O
is	O
given	O
by	O
This	O
equation	O
states	O
that	O
and	O
are	O
independent	O
when	O
conditioned	O
on	O
specific	O
inputs	O
and	O
;	O
however	O
,	O
in	O
general	O
they	O
are	O
not	O
independent	O
after	O
marginalization	O
over	O
a	O
dataset	O
of	O
input	O
pairs	O
,	O
.	O
	
For	O
example	O
,	O
for	O
a	O
trained	O
classification	B-Method
network	I-Method
and	O
a	O
dataset	O
of	O
image	O
pairs	O
where	O
each	O
image	O
contains	O
the	O
same	O
object	O
of	O
its	O
pair	O
but	O
in	O
a	O
randomly	O
different	O
position	O
,	O
the	O
random	O
variable	O
constituted	O
by	O
the	O
class	O
of	O
the	O
first	O
of	O
each	O
pair	O
,	O
,	O
will	O
have	O
a	O
strong	O
statistical	O
relationship	O
with	O
the	O
random	O
variable	O
for	O
the	O
class	O
of	O
the	O
second	O
of	O
each	O
pair	O
,	O
;	O
one	O
is	O
predictive	O
of	O
the	O
other	O
(	O
in	O
fact	O
identical	O
to	O
it	O
,	O
in	O
this	O
case	O
)	O
so	O
they	O
are	O
highly	O
dependent	O
.	O
	
After	O
marginalization	O
over	O
the	O
dataset	O
(	O
or	O
batch	O
,	O
in	O
practice	O
)	O
,	O
the	O
joint	O
probability	O
distribution	O
is	O
given	O
by	O
the	O
matrix	O
,	O
where	O
each	O
element	O
at	O
row	O
and	O
column	O
constitutes	O
:	O
	
The	O
marginals	O
and	O
can	O
be	O
obtained	O
by	O
summing	O
over	O
the	O
rows	O
and	O
columns	O
of	O
this	O
matrix	O
.	O
	
As	O
we	O
generally	O
consider	O
symmetric	B-Task
problems	I-Task
,	O
where	O
for	O
each	O
we	O
also	O
have	O
,	O
is	O
symmetrized	O
using	O
.	O
	
Now	O
the	O
objective	B-Metric
function	I-Metric
e	O
:	O
info_orig	O
can	O
be	O
computed	O
by	O
plugging	O
the	O
matrix	O
into	O
the	O
expression	O
for	O
mutual	O
information	O
,	O
which	O
results	O
in	O
the	O
formula	O
:	O
	
paragraph	O
:	O
Why	O
degenerate	O
solutions	O
are	O
avoided	O
.	O
	
Mutual	O
information	O
(	O
[	O
reference	O
]	O
)	O
expands	O
to	O
.	O
	
Hence	O
,	O
maximizing	O
this	O
quantity	O
trades	O
-	O
off	O
minimizing	O
the	O
conditional	O
cluster	O
assignment	O
entropy	O
and	O
maximising	O
individual	O
cluster	O
assignments	O
entropy	O
.	O
	
The	O
smallest	O
value	O
of	O
is	O
0	O
,	O
obtained	O
when	O
the	O
cluster	O
assignments	O
are	O
exactly	O
predictable	O
from	O
each	O
other	O
.	O
	
The	O
largest	O
value	O
of	O
is	O
,	O
obtained	O
when	O
all	O
clusters	O
are	O
equally	O
likely	O
to	O
be	O
picked	O
.	O
	
This	O
occurs	O
when	O
the	O
data	O
is	O
assigned	O
evenly	O
between	O
the	O
clusters	O
,	O
equalizing	O
their	O
mass	O
.	O
	
Therefore	O
the	O
loss	O
is	O
not	O
minimised	O
if	O
all	O
samples	O
are	O
assigned	O
to	O
a	O
single	O
cluster	O
(	O
i.e.	O
output	O
class	O
is	O
identical	O
for	O
all	O
samples	O
)	O
.	O
	
Thus	O
as	O
maximising	O
mutual	O
information	O
naturally	O
balances	O
reinforcement	B-Task
of	I-Task
predictions	I-Task
with	O
mass	B-Method
equalization	I-Method
,	O
it	O
avoids	O
the	O
tendency	O
for	O
degenerate	O
solutions	O
that	O
algorithms	O
which	O
combine	O
k	B-Method
-	I-Method
means	I-Method
with	O
representation	B-Method
learning	I-Method
are	O
susceptible	O
to	O
.	O
	
For	O
further	O
discussion	O
of	O
entropy	B-Task
maximisation	I-Task
,	O
and	O
optionally	O
how	O
to	O
prioritise	O
it	O
with	O
an	O
entropy	O
coefficient	O
,	O
see	O
supplementary	O
material	O
.	O
	
paragraph	O
:	O
Meaning	O
of	O
mutual	O
information	O
.	O
	
The	O
reader	O
may	O
now	O
wonder	O
what	O
are	O
the	O
benefits	O
of	O
maximising	O
mutual	O
information	O
,	O
as	O
opposed	O
to	O
merely	O
maximising	O
entropy	O
.	O
	
Firstly	O
,	O
due	O
to	O
the	O
soft	B-Method
clustering	I-Method
,	O
entropy	O
alone	O
could	O
be	O
maximised	O
trivially	O
by	O
setting	O
all	O
prediction	O
vectors	O
to	O
uniform	O
distributions	O
,	O
resulting	O
in	O
no	O
clustering	B-Method
.	O
	
This	O
is	O
corrected	O
by	O
the	O
conditional	B-Method
entropy	I-Method
component	I-Method
,	O
which	O
encourages	O
deterministic	B-Task
one	I-Task
-	I-Task
hot	I-Task
predictions	I-Task
.	O
	
For	O
example	O
,	O
even	O
for	O
the	O
degenerate	O
case	O
of	O
identical	O
pairs	O
,	O
the	O
IIC	B-Method
objective	O
encourages	O
a	O
deterministic	B-Method
clustering	I-Method
function	I-Method
(	O
i.e.	O
is	O
a	O
one	O
-	O
hot	O
vector	O
)	O
as	O
this	O
results	O
in	O
null	O
conditional	O
entropy	O
.	O
	
Secondly	O
,	O
the	O
objective	O
of	O
IIC	B-Method
is	O
to	O
find	O
what	O
is	O
common	O
between	O
two	O
data	O
points	O
that	O
share	O
redundancy	O
,	O
such	O
as	O
different	O
images	O
of	O
the	O
same	O
object	O
,	O
explicitly	O
encouraging	O
distillation	O
of	O
the	O
common	O
part	O
while	O
ignoring	O
the	O
rest	O
,	O
i.e.	O
instance	O
details	O
specific	O
to	O
one	O
of	O
the	O
samples	O
.	O
	
This	O
would	O
not	O
be	O
possible	O
without	O
pairing	O
samples	O
.	O
	
subsection	O
:	O
Image	B-Task
clustering	I-Task
	
IIC	B-Method
requires	O
a	O
source	O
of	O
paired	O
samples	O
,	O
which	O
are	O
often	O
unavailable	O
in	O
unsupervised	B-Task
image	O
clustering	O
applications	O
.	O
	
In	O
this	O
case	O
,	O
we	O
propose	O
to	O
use	O
generated	O
image	O
pairs	O
,	O
consisting	O
of	O
image	O
and	O
its	O
randomly	O
perturbed	O
version	O
.	O
	
The	O
objective	O
e	O
:	O
	
info_orig	O
can	O
thus	O
be	O
written	O
as	O
:	O
where	O
both	O
image	O
and	O
transformation	O
are	O
random	O
variables	O
.	O
	
Useful	O
could	O
include	O
scaling	O
,	O
skewing	O
,	O
rotation	O
or	O
flipping	O
(	O
geometric	O
)	O
,	O
changing	O
contrast	O
and	O
colour	O
saturation	O
(	O
photometric	O
)	O
,	O
or	O
any	O
other	O
perturbation	O
that	O
is	O
likely	O
to	O
leave	O
the	O
content	O
of	O
the	O
image	O
intact	O
.	O
	
IIC	B-Method
can	O
then	O
be	O
used	O
to	O
recover	O
the	O
factor	O
which	O
is	O
invariant	O
to	O
which	O
of	O
the	O
pair	O
is	O
picked	O
.	O
	
The	O
effect	O
is	O
to	O
learn	O
a	O
function	O
that	O
partitions	O
the	O
data	O
such	O
that	O
clusters	O
are	O
closed	O
to	O
the	O
perturbations	O
,	O
without	O
dropping	O
clusters	O
.	O
	
The	O
objective	O
is	O
simple	O
enough	O
to	O
be	O
written	O
in	O
six	O
lines	O
of	O
PyTorch	O
code	O
(	O
f	O
:	O
code	O
)	O
.	O
	
paragraph	O
:	O
Auxiliary	B-Method
overclustering	I-Method
.	O
	
For	O
certain	O
datasets	O
(	O
e.g.	O
STL10	O
)	O
,	O
training	O
data	O
comes	O
in	O
two	O
types	O
:	O
one	O
known	O
to	O
contain	O
only	O
relevant	O
classes	O
and	O
the	O
other	O
known	O
to	O
contain	O
irrelevant	O
or	O
distractor	O
classes	O
.	O
	
It	O
is	O
desirable	O
to	O
train	O
a	O
clusterer	B-Method
specialised	O
for	O
the	O
relevant	O
classes	O
,	O
that	O
still	O
benefits	O
from	O
the	O
context	O
provided	O
by	O
the	O
distractor	O
classes	O
,	O
since	O
the	O
latter	O
is	O
often	O
much	O
larger	O
(	O
for	O
example	O
100	O
K	O
compared	O
to	O
13	O
K	O
for	O
STL10	O
)	O
.	O
	
Our	O
solution	O
is	O
to	O
add	O
an	O
auxiliary	B-Method
overclustering	I-Method
head	I-Method
to	O
the	O
network	O
(	O
f	O
:	O
overview	B-Method
)	O
that	O
is	O
trained	O
with	O
the	O
full	O
dataset	O
,	O
whilst	O
the	O
main	O
output	O
head	O
is	O
trained	O
with	O
the	O
subset	O
containing	O
only	O
relevant	O
classes	O
.	O
	
This	O
allows	O
us	O
to	O
make	O
use	O
of	O
the	O
noisy	O
unlabelled	O
subset	O
despite	O
being	O
an	O
unsupervised	B-Task
clustering	O
method	O
.	O
	
Other	O
methods	O
are	O
generally	O
not	O
robust	O
enough	O
to	O
do	O
so	O
and	O
thus	O
avoid	O
the	O
100k	O
-	O
samples	O
unlabelled	O
subset	O
of	O
STL10	O
when	O
training	O
for	O
unsupervised	B-Task
clustering	O
(	O
)	O
.	O
	
Since	O
the	O
auxiliary	B-Method
overclustering	I-Method
head	I-Method
outputs	O
predictions	O
over	O
a	O
larger	O
number	O
of	O
clusters	O
than	O
the	O
ground	O
truth	O
,	O
whilst	O
still	O
maintaining	O
a	O
predictor	O
that	O
is	O
matched	O
to	O
ground	O
truth	O
number	O
of	O
clusters	O
(	O
the	O
main	O
head	O
)	O
,	O
it	O
can	O
be	O
useful	O
in	O
general	O
for	O
increasing	O
expressivity	O
in	O
the	O
learned	O
feature	B-Method
representation	I-Method
,	O
even	O
for	O
datasets	O
where	O
there	O
are	O
no	O
distractor	O
classes	O
.	O
	
subsection	O
:	O
Image	B-Task
segmentation	I-Task
	
IIC	B-Method
can	O
be	O
applied	O
to	O
image	B-Task
segmentation	I-Task
identically	O
to	O
image	B-Task
clustering	I-Task
,	O
except	O
for	O
two	O
modifications	O
.	O
	
Firstly	O
,	O
since	O
predictions	O
are	O
made	O
for	O
each	O
pixel	O
densely	O
,	O
clustering	B-Method
is	O
applied	O
to	O
image	O
patches	O
(	O
defined	O
by	O
the	O
receptive	O
field	O
of	O
the	O
neural	B-Method
network	I-Method
for	O
each	O
output	O
pixel	O
)	O
rather	O
than	O
whole	O
images	O
.	O
	
Secondly	O
,	O
unlike	O
with	O
whole	O
images	O
,	O
one	O
has	O
access	O
to	O
the	O
spatial	O
relationships	O
between	O
patches	O
.	O
	
Thus	O
,	O
we	O
can	O
add	O
local	O
spatial	O
invariance	O
to	O
the	O
list	O
of	O
geometric	O
and	O
photometric	O
invariances	O
in	O
s	O
:	O
	
image_clustering	O
,	O
meaning	O
we	O
form	O
pairs	O
of	O
patches	O
not	O
only	O
via	O
synthetic	O
perturbations	O
,	O
but	O
also	O
by	O
extracting	O
pairs	O
of	O
adjacent	O
patches	O
in	O
the	O
image	O
.	O
	
In	O
detail	O
,	O
let	O
the	O
RGB	O
image	O
be	O
a	O
tensor	O
,	O
a	O
pixel	O
location	O
,	O
and	O
a	O
patch	O
centered	O
at	O
.	O
	
We	O
can	O
form	O
a	O
pair	O
of	O
patches	O
by	O
looking	O
at	O
location	O
and	O
its	O
neighbour	O
at	O
some	O
small	O
displacement	O
.	O
	
The	O
cluster	O
probability	O
vectors	O
for	O
all	O
patches	O
can	O
be	O
read	O
off	O
as	O
the	O
column	O
vectors	O
of	O
the	O
tensor	O
,	O
computed	O
by	O
a	O
single	O
application	O
of	O
the	O
convolutional	B-Method
network	I-Method
.	O
	
Then	O
,	O
to	O
apply	O
IIC	B-Method
,	O
one	O
simply	O
substitutes	O
pairs	O
,	O
in	O
the	O
calculation	O
of	O
the	O
joint	O
probability	O
matrix	O
(	O
[	O
reference	O
]	O
)	O
.	O
	
The	O
geometric	O
and	O
photometric	O
perturbations	O
used	O
before	O
for	O
whole	B-Task
image	I-Task
clustering	I-Task
can	O
be	O
applied	O
to	O
individual	O
patches	O
too	O
.	O
	
Rather	O
than	O
transforming	O
patches	O
individually	O
,	O
however	O
,	O
it	O
is	O
much	O
more	O
efficient	O
to	O
transform	O
all	O
of	O
them	O
in	O
parallel	O
by	O
perturbing	O
the	O
entire	O
image	O
.	O
	
Any	O
number	O
or	O
combination	O
of	O
these	O
invariances	O
can	O
be	O
chained	O
and	O
learned	O
simultaneously	O
;	O
the	O
only	O
detail	O
is	O
to	O
ensure	O
indices	O
of	O
the	O
original	O
image	O
and	O
transformed	O
image	O
class	O
probability	O
tensors	O
line	O
up	O
,	O
meaning	O
that	O
predictions	O
from	O
patches	O
which	O
are	O
intended	O
to	O
be	O
paired	O
together	O
do	O
so	O
.	O
	
Formally	O
,	O
if	O
the	O
image	B-Task
transformation	I-Task
is	O
a	O
geometric	O
transformation	O
,	O
the	O
vector	O
of	O
cluster	O
probabilities	O
will	O
not	O
correspond	O
to	O
;	O
rather	O
,	O
it	O
will	O
correspond	O
to	O
because	O
patch	O
is	O
sent	O
to	O
patch	O
by	O
the	O
transformation	O
.	O
	
All	O
vectors	O
can	O
be	O
paired	O
at	O
once	O
by	O
applying	O
the	O
reverse	B-Method
transformation	I-Method
to	O
the	O
tensor	O
,	O
as	O
For	O
example	O
,	O
flipping	O
the	O
input	O
image	O
will	O
require	O
flipping	O
the	O
resulting	O
probability	O
tensor	O
back	O
.	O
	
In	O
general	O
,	O
the	O
perturbation	O
can	O
incorporate	O
geometric	O
and	O
photometric	O
transformations	O
,	O
and	O
only	O
needs	O
to	O
undo	O
geometric	O
ones	O
.	O
	
The	O
segmentation	B-Task
objective	I-Task
is	O
thus	O
:	O
Hence	O
the	O
goal	O
is	O
to	O
maximize	O
the	O
information	O
between	O
each	O
patch	O
label	O
and	O
the	O
patch	O
label	O
of	O
its	O
transformed	O
neighbour	O
patch	O
,	O
in	O
expectation	O
over	O
images	O
,	O
patches	O
within	O
each	O
image	O
,	O
and	O
perturbations	O
.	O
	
Information	O
is	O
in	O
turn	O
averaged	O
over	O
all	O
neighbour	O
displacements	O
(	O
which	O
was	O
found	O
to	O
perform	O
slightly	O
better	O
than	O
averaging	O
over	O
before	O
computing	O
information	O
;	O
see	O
supplementary	O
material	O
)	O
.	O
	
paragraph	O
:	O
Implementation	O
.	O
	
The	O
joint	O
distribution	O
of	O
e	O
:	O
info_seg	O
for	O
all	O
displacements	O
can	O
be	O
computed	O
in	O
a	O
simple	O
and	O
highly	O
efficient	O
way	O
.	O
	
Given	O
two	O
network	O
outputs	O
for	O
one	O
batch	O
of	O
image	O
pairs	O
where	O
,	O
we	O
first	O
bring	O
back	O
into	O
the	O
coordinate	O
-	O
space	O
of	O
by	O
using	O
a	O
bilinear	B-Method
resampler	I-Method
,	O
which	O
inverts	O
any	O
geometrical	O
transforms	O
in	O
,	O
.	O
	
Then	O
,	O
the	O
inner	O
summation	O
in	O
e	O
:	O
info_seg	O
reduces	O
to	O
the	O
convolution	O
of	O
the	O
two	O
tensors	O
.	O
	
Using	O
any	O
standard	O
deep	B-Method
learning	I-Method
framework	I-Method
,	O
this	O
can	O
be	O
achieved	O
by	O
swapping	O
the	O
first	O
two	O
dimensions	O
of	O
each	O
of	O
and	O
,	O
computing	O
(	O
a	O
2D	B-Method
convolution	I-Method
with	O
padding	O
in	O
both	O
dimensions	O
)	O
,	O
and	O
normalising	O
the	O
result	O
to	O
produce	O
.	O
	
section	O
:	O
Experiments	O
	
We	O
apply	O
IIC	B-Method
to	O
fully	O
unsupervised	B-Task
image	O
clustering	O
and	O
segmentation	O
,	O
as	O
well	O
as	O
two	O
semi	O
-	O
supervised	B-Task
settings	O
.	O
	
Existing	O
baselines	O
are	O
outperformed	O
in	O
all	O
cases	O
.	O
	
We	O
also	O
conduct	O
an	O
analysis	O
of	O
our	O
method	O
via	O
ablation	B-Task
studies	I-Task
.	O
	
For	O
minor	O
details	O
see	O
supplementary	O
material	O
.	O
	
subsection	O
:	O
Image	B-Task
clustering	I-Task
	
[	O
]	O
table	O
[	O
0.27	O
]	O
	
[	O
]	O
figure	O
[	O
0.68	O
]	O
	
paragraph	O
:	O
Datasets	O
.	O
	
We	O
test	O
on	O
STL10	O
,	O
which	O
is	O
ImageNet	O
adapted	O
for	O
unsupervised	B-Task
classification	O
,	O
as	O
well	O
as	O
CIFAR10	O
,	O
CIFAR100	O
-	O
20	O
and	O
MNIST	B-Material
.	O
	
The	O
main	O
setting	O
is	O
pure	O
unsupervised	B-Task
clustering	O
(	O
IIC	B-Method
)	O
but	O
we	O
also	O
test	O
two	O
semi	O
-	O
supervised	B-Task
settings	O
:	O
finetuning	B-Method
and	O
overclustering	B-Method
.	O
	
For	O
unsupervised	B-Task
clustering	O
,	O
following	O
previous	O
work	O
,	O
we	O
train	O
on	O
the	O
full	O
dataset	O
and	O
test	O
on	O
the	O
labelled	O
part	O
;	O
for	O
the	O
semi	O
-	O
supervised	B-Task
settings	O
,	O
train	O
and	O
test	O
sets	O
are	O
separate	O
.	O
	
As	O
for	O
DeepCluster	B-Method
,	O
we	O
found	O
Sobel	B-Method
filtering	I-Method
to	O
be	O
beneficial	O
,	O
as	O
it	O
discourages	O
clustering	B-Task
based	O
on	O
trivial	O
cues	O
such	O
as	O
colour	O
and	O
encourages	O
using	O
more	O
meaningful	O
cues	O
such	O
as	O
shape	O
.	O
	
Additionally	O
,	O
for	O
data	B-Task
augmentation	I-Task
,	O
we	O
repeat	O
images	O
within	O
each	O
batch	O
times	O
;	O
this	O
means	O
that	O
multiple	O
image	O
pairs	O
within	O
a	O
batch	O
contain	O
the	O
same	O
original	O
image	O
,	O
each	O
paired	O
with	O
a	O
different	O
transformation	O
,	O
which	O
encourages	O
greater	O
distillation	O
since	O
there	O
are	O
more	O
examples	O
of	O
which	O
visual	O
details	O
to	O
ignore	O
(	O
s	O
:	O
equalization	O
)	O
.	O
	
We	O
set	O
for	O
all	O
experiments	O
.	O
	
Images	O
are	O
rescaled	O
and	O
cropped	O
for	O
training	O
(	O
prior	O
to	O
applying	O
transforms	O
,	O
consisting	O
of	O
random	O
additive	O
and	O
multiplicative	O
colour	O
transformations	O
and	O
horizontal	O
flipping	O
)	O
and	O
a	O
single	O
center	O
crop	O
is	O
used	O
at	O
test	O
time	O
for	O
all	O
experiments	O
except	O
semi	O
-	O
supervised	B-Task
finetuning	O
,	O
where	O
10	O
crops	O
are	O
used	O
.	O
	
paragraph	O
:	O
Architecture	O
.	O
	
All	O
networks	O
are	O
randomly	O
initialised	O
and	O
consist	O
of	O
a	O
ResNet	B-Method
or	O
	
VGG11	O
-	O
like	O
base	O
(	O
see	O
sup	O
.	O
	
mat	O
.	O
)	O
,	O
followed	O
by	O
one	O
or	O
more	O
heads	O
(	O
linear	O
predictors	O
)	O
.	O
	
Let	O
the	O
number	O
of	O
ground	O
truth	O
clusters	O
be	O
and	O
the	O
output	O
channels	O
of	O
a	O
head	O
be	O
.	O
	
For	O
IIC	B-Method
,	O
there	O
is	O
a	O
main	O
output	O
head	O
with	O
and	O
an	O
auxiliary	B-Method
overclustering	I-Method
head	I-Method
(	O
f	O
:	O
overview	O
)	O
with	O
.	O
	
For	O
semi	B-Method
-	I-Method
supervised	I-Method
overclustering	I-Method
there	O
is	O
one	O
output	O
head	O
with	O
.	O
	
For	O
increased	O
robustness	O
,	O
each	O
head	O
is	O
duplicated	O
times	O
with	O
a	O
different	O
random	O
initialisation	O
,	O
and	O
we	O
call	O
these	O
concrete	O
instantiations	O
sub	O
-	O
heads	O
.	O
	
Each	O
sub	O
-	O
head	O
takes	O
features	O
from	O
and	O
outputs	O
a	O
probability	B-Method
distribution	I-Method
for	O
each	O
batch	O
element	O
over	O
the	O
relevant	O
number	O
of	O
clusters	O
.	O
	
For	O
semi	O
-	O
supervised	B-Task
finetuning	O
(	O
t	O
:	O
iid_imgclus_semisup	O
)	O
,	O
the	O
base	O
is	O
copied	O
from	O
a	O
semi	O
-	O
supervised	B-Task
overclustering	O
network	O
and	O
combined	O
with	O
a	O
single	O
randomly	B-Method
initialised	I-Method
linear	I-Method
layer	I-Method
where	O
.	O
	
paragraph	O
:	O
Training	O
.	O
	
We	O
use	O
the	O
Adam	B-Method
optimiser	I-Method
with	O
learning	B-Method
rate	I-Method
.	O
	
For	O
IIC	B-Method
,	O
the	O
main	O
and	O
auxiliary	O
heads	O
are	O
trained	O
by	O
maximising	O
e	O
:	O
	
loss_expanded	O
in	O
alternate	O
epochs	O
.	O
	
For	O
semi	B-Method
-	I-Method
supervised	I-Method
overclustering	I-Method
,	O
the	O
single	O
head	O
is	O
trained	O
by	O
maximising	O
e	O
:	O
loss_expanded	B-Metric
.	O
	
Semi	O
-	O
supervised	B-Task
finetuning	O
uses	O
a	O
standard	O
logistic	B-Method
loss	I-Method
.	O
	
paragraph	O
:	O
Evaluation	O
.	O
	
We	O
evaluate	O
based	O
on	O
accuracy	B-Metric
(	O
true	B-Metric
positives	I-Metric
divided	O
by	O
sample	O
size	O
)	O
.	O
	
For	O
IIC	B-Method
we	O
follow	O
the	O
standard	O
protocol	O
of	O
finding	O
the	O
best	O
one	O
-	O
to	O
-	O
one	O
permutation	O
mapping	O
between	O
learned	O
and	O
ground	O
-	O
truth	O
clusters	O
(	O
from	O
the	O
main	O
output	O
head	O
;	O
auxiliary	B-Method
overclustering	I-Method
head	I-Method
is	O
ignored	O
)	O
using	O
linear	B-Method
assignment	I-Method
.	O
	
While	O
this	O
step	O
uses	O
labels	O
,	O
it	O
does	O
not	O
constitute	O
learning	B-Task
as	O
it	O
merely	O
makes	O
the	O
metric	O
invariant	O
to	O
the	O
order	O
of	O
the	O
clusters	O
.	O
	
For	O
semi	B-Method
-	I-Method
supervised	I-Method
overclustering	I-Method
,	O
each	O
ground	O
-	O
truth	O
cluster	O
may	O
correspond	O
to	O
the	O
union	O
of	O
several	O
predicted	O
clusters	O
.	O
	
Evaluation	B-Task
thus	O
requires	O
a	O
many	O
-	O
to	O
-	O
one	O
discrete	O
map	O
from	O
to	O
,	O
since	O
.	O
	
This	O
extracts	O
some	O
information	O
from	O
the	O
labels	O
and	O
thus	O
requires	O
separated	O
training	O
and	O
test	O
set	O
.	O
	
Note	O
this	O
mapping	O
is	O
found	O
using	O
the	O
training	O
set	O
(	O
accuracy	B-Metric
is	O
computed	O
on	O
the	O
test	O
set	O
)	O
and	O
does	O
not	O
affect	O
the	O
network	O
parameters	O
as	O
it	O
is	O
used	O
for	O
evaluation	B-Task
only	O
.	O
	
For	O
semi	O
-	O
supervised	B-Task
finetuning	O
,	O
output	O
channel	O
order	O
matches	O
ground	O
truth	O
so	O
no	O
mapping	O
is	O
required	O
.	O
	
The	O
performance	O
of	O
each	O
sub	O
-	O
head	O
is	O
assessed	O
independently	O
,	O
and	O
best	O
and	O
average	O
performances	O
are	O
reported	O
.	O
	
paragraph	O
:	O
Unsupervised	B-Method
learning	I-Method
analysis	I-Method
.	O
	
IIC	B-Method
is	O
highly	O
capable	O
of	O
discovering	O
clusters	O
in	O
unlabelled	O
data	O
that	O
accurately	O
correspond	O
to	O
the	O
underlying	O
semantic	O
classes	O
,	O
and	O
outperforms	O
all	O
competing	O
baselines	O
at	O
this	O
task	O
(	O
t	O
:	O
img_clus_iid	O
)	O
,	O
with	O
significant	O
margins	O
of	O
and	O
in	O
the	O
case	O
of	O
STL10	O
and	O
CIFAR10	O
.	O
	
As	O
mentioned	O
in	O
s	O
:	O
related	O
,	O
this	O
underlines	O
the	O
advantages	O
of	O
end	B-Task
-	I-Task
to	I-Task
-	I-Task
end	I-Task
optimisation	I-Task
instead	O
of	O
using	O
a	O
fixed	O
external	B-Method
procedure	I-Method
like	O
k	B-Method
-	I-Method
means	I-Method
as	O
with	O
many	O
baselines	O
.	O
	
The	O
clusters	O
found	O
by	O
IIC	B-Method
are	O
highly	O
discriminative	O
(	O
f	O
:	O
images_img_clus	O
)	O
,	O
although	O
note	O
some	O
failure	O
cases	O
;	O
as	O
IIC	B-Method
distills	O
purely	O
visual	O
correspondences	O
within	O
images	O
,	O
it	O
can	O
be	O
confused	O
by	O
instances	O
that	O
combine	O
classes	O
,	O
such	O
as	O
a	O
deer	O
with	O
the	O
coat	O
pattern	O
of	O
a	O
cat	O
.	O
	
Our	O
ablations	B-Method
(	O
t	O
:	O
iid_imgclus_ablation	B-Method
)	O
illustrate	O
the	O
contributions	O
of	O
various	O
implementation	O
details	O
,	O
and	O
in	O
particular	O
the	O
accuracy	B-Metric
gain	O
from	O
using	O
auxiliary	B-Method
overclustering	I-Method
.	O
	
paragraph	O
:	O
Semi	O
-	O
supervised	B-Task
learning	O
analysis	O
.	O
	
For	O
semi	O
-	O
supervised	B-Task
learning	O
,	O
we	O
establish	O
a	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
on	O
STL10	O
out	O
of	O
all	O
reported	O
methods	O
by	O
finetuning	O
a	O
network	O
trained	O
in	O
an	O
entirely	O
unsupervised	B-Task
fashion	O
with	O
the	O
IIC	B-Method
objective	O
(	O
recall	O
labels	O
in	O
semi	B-Method
-	I-Method
supervised	I-Method
overclustering	I-Method
are	O
used	O
for	O
evaluation	O
and	O
do	O
not	O
influence	O
the	O
network	O
parameters	O
)	O
.	O
	
This	O
explicitly	O
validates	O
the	O
quality	O
of	O
our	O
unsupervised	B-Task
learning	O
method	O
,	O
as	O
we	O
beat	O
even	O
the	O
supervised	B-Task
state	O
-	O
of	O
-	O
the	O
-	O
art	O
(	O
t	O
:	O
iid_imgclus_semisup	B-Method
)	O
.	O
	
Given	O
that	O
the	O
bulk	O
of	O
parameters	O
within	O
semi	B-Method
-	I-Method
supervised	I-Method
overclustering	I-Method
are	O
trained	O
unsupervised	B-Task
(	O
i.e.	O
all	O
network	O
parameters	O
)	O
,	O
it	O
is	O
unsurprising	O
that	O
f	O
:	O
imgclus_variation	B-Method
shows	O
a	O
90	O
%	O
drop	O
in	O
the	O
number	O
of	O
available	O
labels	O
for	O
STL10	O
(	O
decreasing	O
the	O
amount	O
of	O
labelled	O
data	O
available	O
from	O
5000	O
to	O
500	O
over	O
10	O
classes	O
)	O
barely	O
impacts	O
performance	O
,	O
costing	O
just	O
10	O
%	O
drop	O
in	O
accuracy	B-Metric
.	O
	
This	O
setting	O
has	O
lower	O
label	O
requirements	O
than	O
finetuning	O
because	O
whereas	O
the	O
latter	O
learns	O
all	O
network	O
parameters	O
,	O
the	O
former	O
only	O
needs	O
to	O
learn	O
a	O
discrete	O
map	O
between	O
and	O
,	O
making	O
it	O
an	O
important	O
practical	O
setting	O
for	O
applications	O
with	O
small	O
amounts	O
of	O
labelled	O
data	O
.	O
	
subsection	O
:	O
Segmentation	B-Task
	
1pt	O
40	O
	
paragraph	O
:	O
Datasets	O
.	O
	
Large	B-Task
scale	I-Task
segmentation	I-Task
on	O
real	O
-	O
world	O
data	O
using	O
deep	B-Method
neural	I-Method
networks	I-Method
is	O
extremely	O
difficult	O
without	O
labels	O
or	O
heuristics	O
,	O
and	O
has	O
negligible	O
precedent	O
.	O
	
We	O
establish	O
new	O
baselines	O
on	O
scene	O
and	O
satellite	O
images	O
to	O
highlight	O
performance	O
on	O
textural	B-Task
classes	I-Task
,	O
where	O
the	O
assumption	O
of	O
spatially	O
proximal	O
invariance	O
(	O
s	O
:	O
image_segmentation	O
)	O
is	O
most	O
valid	O
.	O
	
COCO	O
-	O
Stuff	O
is	O
a	O
challenging	O
and	O
diverse	O
segmentation	O
dataset	O
containing	O
‘	O
‘	O
stuff	O
’	O
’	O
classes	O
ranging	O
from	O
buildings	O
to	O
bodies	O
of	O
water	O
.	O
	
We	O
use	O
the	O
15	O
coarse	O
labels	O
and	O
164k	O
images	O
variant	O
,	O
reduced	O
to	O
52k	O
by	O
taking	O
only	O
images	O
with	O
at	O
least	O
75	O
%	O
stuff	O
pixels	O
.	O
	
COCO	O
-	O
Stuff	O
-	O
3	O
is	O
a	O
subset	O
of	O
COCO	O
-	O
Stuff	O
with	O
only	O
sky	O
,	O
ground	O
and	O
plants	O
labelled	O
.	O
	
For	O
both	O
COCO	O
datasets	O
,	O
input	O
images	O
are	O
shrunk	O
by	O
two	O
thirds	O
and	O
cropped	O
to	O
pixels	O
,	O
Sobel	B-Method
preprocessing	I-Method
is	O
applied	O
for	O
data	B-Task
augmentation	I-Task
,	O
and	O
predictions	O
for	O
non	O
-	O
stuff	O
pixels	O
are	O
ignored	O
.	O
	
Potsdam	O
is	O
divided	O
into	O
8550	O
RGBIR	O
px	O
satellite	O
images	O
,	O
of	O
which	O
3150	O
are	O
unlabelled	O
.	O
	
We	O
test	O
both	O
the	O
6	B-Method
-	I-Method
label	I-Method
variant	I-Method
(	O
roads	O
and	O
cars	O
,	O
vegetation	O
and	O
trees	O
,	O
buildings	O
and	O
clutter	O
)	O
and	O
a	O
3	B-Method
-	I-Method
label	I-Method
variant	I-Method
(	O
Potsdam	O
-	O
3	O
)	O
formed	O
by	O
merging	O
each	O
of	O
the	O
3	O
pairs	O
.	O
	
All	O
segmentation	O
training	O
and	O
testing	O
sets	O
will	O
be	O
released	O
with	O
our	O
code	O
.	O
	
paragraph	O
:	O
Architecture	O
.	O
	
All	O
networks	O
are	O
randomly	O
initialised	O
and	O
consist	O
of	O
a	O
base	O
CNN	B-Method
(	O
see	O
sup	O
.	O
	
mat	O
.	O
)	O
	
followed	O
by	O
head	O
(	O
s	O
)	O
,	O
which	O
are	O
convolution	B-Method
layers	I-Method
.	O
	
Similar	O
to	O
s	O
:	O
exp_img_clus	B-Method
,	O
overclustering	B-Method
uses	O
3	O
-	O
5	O
times	O
higher	O
than	O
.	O
	
Since	O
segmentation	B-Task
is	O
much	O
more	O
expensive	O
than	O
image	B-Task
clustering	I-Task
(	O
e.g.	O
a	O
single	O
Potsdam	O
image	O
contains	O
40	O
,	O
000	O
predictions	O
)	O
,	O
all	O
segmentation	B-Task
experiments	O
were	O
run	O
with	O
and	O
(	O
sec	O
.	O
	
[	O
reference	O
]	O
)	O
.	O
	
paragraph	O
:	O
Training	O
.	O
	
The	O
convolutional	B-Method
implementation	I-Method
of	O
IIC	B-Method
(	O
e	O
:	O
info_seg	B-Method
)	O
was	O
used	O
with	O
.	O
	
For	O
Potsdam	O
-	O
3	O
and	O
COCO	O
-	O
Stuff	O
-	O
3	O
,	O
the	O
optional	B-Metric
entropy	I-Metric
coefficient	I-Metric
(	O
s	O
:	O
equalization	O
and	O
sup	O
.	O
	
mat	O
.	O
)	O
was	O
used	O
and	O
set	O
to	O
1.5	O
.	O
	
Using	O
the	O
coefficient	O
made	O
slight	O
improvements	O
of	O
1.2%	O
-	O
3.2	O
%	O
on	O
performance	O
.	O
	
These	O
two	O
datasets	O
are	O
balanced	O
in	O
nature	O
with	O
very	O
large	O
sample	O
volume	O
(	O
e.g.	O
predictions	O
per	O
batch	O
for	O
Potsdam	O
-	O
3	O
)	O
resulting	O
in	O
stable	O
and	O
balanced	O
batches	O
,	O
justifying	O
prioritisation	O
of	O
equalisation	B-Method
.	O
	
Other	O
training	O
details	O
are	O
the	O
same	O
as	O
s	O
:	O
exp_img_clus	O
.	O
	
paragraph	O
:	O
Evaluation	O
.	O
	
Evaluation	B-Metric
uses	O
accuracy	B-Metric
as	O
in	O
s	O
:	O
exp_img_clus	O
,	O
computed	O
per	O
-	O
pixel	O
.	O
	
For	O
the	O
baselines	O
,	O
the	O
original	O
authors	O
’	O
code	O
was	O
adapted	O
from	O
image	B-Method
clustering	I-Method
where	O
available	O
,	O
and	O
the	O
architectures	O
are	O
shared	O
with	O
IIC	B-Method
for	O
fairness	O
.	O
	
For	O
baselines	O
that	O
required	O
application	O
of	O
k	B-Method
-	I-Method
means	I-Method
to	O
produce	O
per	B-Task
-	I-Task
pixel	I-Task
predictions	I-Task
(	O
t	O
:	O
iid_seg	O
)	O
,	O
k	B-Method
-	I-Method
means	I-Method
was	O
trained	O
with	O
randomly	O
sampled	O
pixel	O
features	O
from	O
the	O
training	O
set	O
(	O
10	O
M	O
for	O
Potsdam	O
,	O
Potsdam	O
-	O
3	O
;	O
50	O
M	O
for	O
COCO	O
-	O
Stuff	O
,	O
COCO	O
-	O
Stuff	O
-	O
3	O
)	O
and	O
tested	O
on	O
the	O
full	O
test	O
set	O
to	O
obtain	O
accuracy	B-Metric
.	O
	
paragraph	O
:	O
Analysis	O
.	O
	
Without	O
labels	O
or	O
heuristics	O
to	O
learn	O
from	O
,	O
and	O
given	O
just	O
the	O
cluster	O
cardinality	O
(	O
3	O
)	O
,	O
IIC	B-Method
automatically	O
partitions	O
COCO	O
-	O
Stuff	O
-	O
3	O
into	O
clusters	O
that	O
are	O
recognisable	O
as	O
sky	O
,	O
vegetation	O
and	O
ground	O
,	O
and	O
learns	O
to	O
classify	O
vegetation	O
,	O
roads	O
and	O
buildings	O
for	O
Potsdam	O
-	O
3	O
(	O
f	O
:	O
images_img_seg	O
)	O
.	O
	
The	O
segmentations	B-Method
are	O
notably	O
intricate	O
,	O
capturing	O
fine	O
detail	O
,	O
but	O
are	O
at	O
the	O
same	O
time	O
locally	O
consistent	O
and	O
coherent	O
across	O
all	O
images	O
.	O
	
Since	O
spatial	O
smoothness	O
is	O
built	O
into	O
the	O
loss	O
(	O
s	O
:	O
image_segmentation	O
)	O
,	O
all	O
our	O
results	O
are	O
able	O
to	O
use	O
raw	O
network	O
outputs	O
without	O
post	O
-	O
processing	O
(	O
avoiding	O
e.g.	O
CRF	B-Method
smoothing	I-Method
)	O
.	O
	
Quantitatively	O
,	O
we	O
outperform	O
all	O
baselines	O
(	O
t	O
:	O
iid_seg	B-Method
)	O
,	O
notably	O
by	O
in	O
the	O
case	O
of	O
COCO	O
-	O
Stuff	O
-	O
3	O
.	O
	
The	O
efficient	O
convolutional	B-Method
formulation	I-Method
of	O
the	O
loss	O
(	O
e	O
:	O
info_seg	O
)	O
allows	O
us	O
to	O
optimise	O
over	O
all	O
pixels	O
in	O
all	O
batch	O
images	O
in	O
parallel	O
,	O
converging	O
in	O
fewer	O
epochs	O
(	O
passes	O
of	O
the	O
dataset	O
)	O
without	O
paying	O
the	O
price	O
of	O
reduced	O
computational	B-Metric
speed	I-Metric
for	O
dense	B-Method
sampling	I-Method
.	O
	
This	O
is	O
in	O
contrast	O
to	O
our	O
baselines	O
which	O
,	O
being	O
not	O
natively	O
adapted	O
for	O
segmentation	B-Task
,	O
required	O
sampling	O
a	O
subset	O
of	O
pixels	O
within	O
each	O
batch	O
,	O
resulting	O
in	O
increased	O
loss	B-Metric
volatility	I-Metric
and	O
training	B-Metric
speeds	I-Metric
that	O
were	O
up	O
to	O
3.3	O
slower	O
than	O
IIC	B-Method
.	O
	
section	O
:	O
Conclusions	O
	
We	O
have	O
shown	O
that	O
it	O
is	O
possible	O
to	O
train	O
neural	B-Method
networks	I-Method
into	O
semantic	B-Method
clusterers	I-Method
without	O
using	O
labels	O
or	O
heuristics	O
.	O
	
The	O
novel	O
objective	O
presented	O
relies	O
on	O
statistical	B-Method
learning	I-Method
,	O
by	O
optimising	O
mutual	O
information	O
between	O
related	O
pairs	O
-	O
a	O
relationship	O
that	O
can	O
be	O
generated	O
by	O
random	B-Method
transforms	I-Method
-	O
and	O
naturally	O
avoids	O
degenerate	O
solutions	O
.	O
	
The	O
resulting	O
models	O
classify	O
and	O
segment	O
images	O
with	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
levels	O
of	O
semantic	O
accuracy	B-Metric
.	O
	
Being	O
not	O
specific	O
to	O
vision	B-Task
,	O
the	O
method	O
opens	O
up	O
many	O
interesting	O
research	O
directions	O
,	O
including	O
optimising	O
information	O
in	O
datastreams	O
over	O
time	O
.	O
	
bibliography	O
:	O
References	O
	
HIERARCHICAL	B-Method
MULTISCALE	I-Method
RECURRENT	I-Method
NEURAL	I-Method
NETWORKS	I-Method
	
section	O
:	O
ABSTRACT	O
	
Learning	O
both	O
hierarchical	B-Task
and	I-Task
temporal	I-Task
representation	I-Task
has	O
been	O
among	O
the	O
longstanding	O
challenges	O
of	O
recurrent	B-Method
neural	I-Method
networks	I-Method
.	O
	
Multiscale	B-Method
recurrent	I-Method
neural	I-Method
networks	I-Method
have	O
been	O
considered	O
as	O
a	O
promising	O
approach	O
to	O
resolve	O
this	O
issue	O
,	O
yet	O
there	O
has	O
been	O
a	O
lack	O
of	O
empirical	O
evidence	O
showing	O
that	O
this	O
type	O
of	O
models	O
can	O
actually	O
capture	O
the	O
temporal	O
dependencies	O
by	O
discovering	O
the	O
latent	O
hierarchical	O
structure	O
of	O
the	O
sequence	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
novel	O
multiscale	B-Method
approach	I-Method
,	O
called	O
the	O
hierarchical	B-Method
multiscale	I-Method
recurrent	I-Method
neural	I-Method
network	I-Method
,	O
that	O
can	O
capture	O
the	O
latent	O
hierarchical	O
structure	O
in	O
the	O
sequence	O
by	O
encoding	O
the	O
temporal	O
dependencies	O
with	O
different	O
timescales	O
using	O
a	O
novel	O
update	B-Method
mechanism	I-Method
.	O
	
We	O
show	O
some	O
evidence	O
that	O
the	O
proposed	O
model	O
can	O
discover	O
underlying	O
hierarchical	O
structure	O
in	O
the	O
sequences	O
without	O
using	O
explicit	O
boundary	O
information	O
.	O
	
We	O
evaluate	O
our	O
proposed	O
model	O
on	O
character	B-Task
-	I-Task
level	I-Task
language	I-Task
modelling	I-Task
and	O
handwriting	B-Task
sequence	I-Task
generation	I-Task
.	O
	
section	O
:	O
INTRODUCTION	O
	
One	O
of	O
the	O
key	O
principles	O
of	O
learning	B-Task
in	O
deep	B-Method
neural	I-Method
networks	I-Method
as	O
well	O
as	O
in	O
the	O
human	O
brain	O
is	O
to	O
obtain	O
a	O
hierarchical	B-Method
representation	I-Method
with	O
increasing	O
levels	O
of	O
abstraction	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
A	O
stack	O
of	O
representation	O
layers	O
,	O
learned	O
from	O
the	O
data	O
in	O
a	O
way	O
to	O
optimize	O
the	O
target	O
task	O
,	O
make	O
deep	B-Method
neural	I-Method
networks	I-Method
entertain	O
advantages	O
such	O
as	O
generalization	O
to	O
unseen	O
examples	O
[	O
reference	O
]	O
,	O
sharing	O
learned	O
knowledge	O
among	O
multiple	O
tasks	O
,	O
and	O
discovering	O
disentangling	O
factors	O
of	O
variation	O
	
[	O
reference	O
]	O
.	O
	
The	O
remarkable	O
recent	O
successes	O
of	O
the	O
deep	B-Method
convolutional	I-Method
neural	I-Method
networks	I-Method
are	O
particularly	O
based	O
on	O
this	O
ability	O
to	O
learn	O
hierarchical	B-Method
representation	I-Method
for	O
spatial	O
data	O
	
[	O
reference	O
]	O
.	O
For	O
modelling	B-Task
temporal	I-Task
data	I-Task
,	O
	
the	O
recent	O
resurgence	O
of	O
recurrent	B-Method
neural	I-Method
networks	I-Method
(	O
RNN	B-Method
)	O
has	O
led	O
to	O
remarkable	O
advances	O
	
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
	
However	O
,	O
unlike	O
the	O
spatial	O
data	O
,	O
learning	O
both	O
hierarchical	B-Method
and	I-Method
temporal	I-Method
representation	I-Method
has	O
been	O
among	O
the	O
long	O
-	O
standing	O
challenges	O
of	O
RNNs	B-Method
in	O
spite	O
of	O
the	O
fact	O
that	O
hierarchical	O
multiscale	O
structures	O
naturally	O
exist	O
in	O
many	O
temporal	O
data	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
	
A	O
promising	O
approach	O
to	O
model	O
such	O
hierarchical	B-Method
and	I-Method
temporal	I-Method
representation	I-Method
is	O
the	O
multiscale	B-Method
RNNs	I-Method
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
Based	O
on	O
the	O
observation	O
that	O
high	O
-	O
level	O
abstraction	O
changes	O
slowly	O
with	O
temporal	O
coherency	O
while	O
low	O
-	O
level	O
abstraction	O
has	O
quickly	O
changing	O
features	O
sensitive	O
to	O
the	O
precise	O
local	O
timing	O
[	O
reference	O
]	O
,	O
the	O
multiscale	B-Method
RNNs	I-Method
group	O
hidden	O
units	O
into	O
multiple	O
modules	O
of	O
different	O
timescales	O
.	O
	
In	O
addition	O
to	O
the	O
fact	O
that	O
the	O
architecture	O
fits	O
naturally	O
to	O
the	O
latent	O
hierarchical	O
structures	O
in	O
many	O
temporal	O
data	O
,	O
the	O
multiscale	B-Method
approach	I-Method
provides	O
the	O
following	O
advantages	O
that	O
resolve	O
some	O
inherent	O
problems	O
of	O
standard	O
RNNs	B-Method
:	O
(	O
a	O
)	O
computational	B-Metric
efficiency	O
obtained	O
by	O
updating	O
the	O
high	O
-	O
level	O
layers	O
less	O
frequently	O
,	O
(	O
b	O
)	O
efficiently	O
delivering	O
long	O
-	O
term	O
dependencies	O
with	O
fewer	O
updates	O
at	O
the	O
high	O
-	O
level	O
layers	O
,	O
which	O
mitigates	O
the	O
vanishing	B-Task
gradient	I-Task
problem	I-Task
,	O
(	O
c	O
)	O
flexible	O
resource	B-Task
allocation	I-Task
(	O
e.g.	O
,	O
more	O
hidden	O
units	O
to	O
the	O
higher	O
layers	O
that	O
focus	O
on	O
modelling	O
long	O
-	O
term	O
dependencies	O
and	O
less	O
hidden	O
units	O
to	O
the	O
lower	O
layers	O
which	O
are	O
in	O
charge	O
of	O
learning	O
short	O
-	O
term	O
dependencies	O
)	O
.	O
	
In	O
addition	O
,	O
the	O
learned	O
latent	O
hierarchical	O
structures	O
can	O
provide	O
useful	O
information	O
to	O
other	O
downstream	B-Task
tasks	I-Task
such	O
Published	O
as	O
a	O
conference	O
paper	O
at	O
ICLR	O
2017	O
as	O
module	O
structures	O
in	O
computer	B-Task
program	I-Task
learning	I-Task
,	O
sub	B-Task
-	I-Task
task	I-Task
structures	I-Task
in	O
hierarchical	B-Task
reinforcement	I-Task
learning	I-Task
,	O
and	O
story	B-Task
segments	I-Task
in	O
video	B-Task
understanding	I-Task
.	O
	
There	O
have	O
been	O
various	O
approaches	O
to	O
implementing	O
the	O
multiscale	B-Method
RNNs	I-Method
.	O
	
The	O
most	O
popular	O
approach	O
is	O
to	O
set	O
the	O
timescales	O
as	O
hyperparameters	O
[	O
reference	O
][	O
reference	O
]	O
instead	O
of	O
treating	O
them	O
as	O
dynamic	O
variables	O
that	O
can	O
be	O
learned	O
from	O
the	O
data	O
[	O
reference	O
][	O
reference	O
][	O
reference	O
]	O
.	O
However	O
,	O
considering	O
the	O
fact	O
that	O
non	O
-	O
stationarity	O
is	O
prevalent	O
in	O
temporal	O
data	O
,	O
and	O
that	O
many	O
entities	O
of	O
abstraction	O
such	O
as	O
words	O
and	O
sentences	O
are	O
in	O
variable	O
length	O
,	O
we	O
claim	O
that	O
it	O
is	O
important	O
for	O
an	O
RNN	B-Method
to	O
dynamically	O
adapt	O
its	O
timescales	O
to	O
the	O
particulars	O
of	O
the	O
input	O
entities	O
of	O
various	O
length	O
.	O
	
While	O
this	O
is	O
trivial	O
if	O
the	O
hierarchical	O
boundary	O
structure	O
is	O
provided	O
[	O
reference	O
]	O
,	O
it	O
has	O
been	O
a	O
challenge	O
for	O
an	O
RNN	B-Method
to	O
discover	O
the	O
latent	O
hierarchical	O
structure	O
in	O
temporal	O
data	O
without	O
explicit	O
boundary	O
information	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
novel	O
multiscale	B-Method
RNN	I-Method
model	I-Method
,	O
which	O
can	O
learn	O
the	O
hierarchical	O
multiscale	O
structure	O
from	O
temporal	O
data	O
without	O
explicit	O
boundary	O
information	O
.	O
	
This	O
model	O
,	O
called	O
a	O
hierarchical	B-Method
multiscale	I-Method
recurrent	I-Method
neural	I-Method
network	I-Method
(	I-Method
HM	I-Method
-	I-Method
RNN	I-Method
)	I-Method
,	O
does	O
not	O
assign	O
fixed	O
update	O
rates	O
,	O
but	O
adaptively	O
determines	O
proper	O
update	O
times	O
corresponding	O
to	O
different	O
abstraction	O
levels	O
of	O
the	O
layers	O
.	O
	
We	O
find	O
that	O
this	O
model	O
tends	O
to	O
learn	O
fine	O
timescales	O
for	O
low	O
-	O
level	O
layers	O
and	O
coarse	O
timescales	O
for	O
high	O
-	O
level	O
layers	O
.	O
	
To	O
do	O
this	O
,	O
we	O
introduce	O
a	O
binary	B-Method
boundary	I-Method
detector	I-Method
at	O
each	O
layer	O
.	O
	
The	O
boundary	B-Method
detector	I-Method
is	O
turned	O
on	O
only	O
at	O
the	O
time	O
steps	O
where	O
a	O
segment	O
of	O
the	O
corresponding	O
abstraction	O
level	O
is	O
completely	O
processed	O
.	O
	
Otherwise	O
,	O
i.e.	O
,	O
during	O
the	O
within	B-Task
segment	I-Task
processing	I-Task
,	O
it	O
stays	O
turned	O
off	O
.	O
	
Using	O
the	O
hierarchical	O
boundary	O
states	O
,	O
we	O
implement	O
three	O
operations	O
,	O
UPDATE	O
,	O
COPY	O
and	O
FLUSH	O
,	O
and	O
choose	O
one	O
of	O
them	O
at	O
each	O
time	O
step	O
.	O
	
The	O
UPDATE	B-Method
operation	I-Method
is	O
similar	O
to	O
the	O
usual	O
update	B-Method
rule	I-Method
of	O
the	O
long	B-Method
short	I-Method
-	I-Method
term	I-Method
memory	I-Method
(	O
LSTM	B-Method
)	O
[	O
reference	O
]	O
,	O
except	O
that	O
it	O
is	O
executed	O
sparsely	O
according	O
to	O
the	O
detected	O
boundaries	O
.	O
	
The	O
COPY	B-Method
operation	I-Method
simply	O
copies	O
the	O
cell	O
and	O
hidden	O
states	O
of	O
the	O
previous	O
time	O
step	O
.	O
	
Unlike	O
the	O
leaky	O
integration	O
of	O
the	O
LSTM	B-Method
or	O
the	O
Gated	B-Method
Recurrent	I-Method
Unit	I-Method
(	O
GRU	B-Method
)	O
[	O
reference	O
]	O
,	O
the	O
COPY	B-Method
operation	I-Method
retains	O
the	O
whole	O
states	O
without	O
any	O
loss	O
of	O
information	O
.	O
	
The	O
FLUSH	B-Method
operation	I-Method
is	O
executed	O
when	O
a	O
boundary	O
is	O
detected	O
,	O
where	O
it	O
first	O
ejects	O
the	O
summarized	B-Method
representation	I-Method
of	O
the	O
current	O
segment	O
to	O
the	O
upper	O
layer	O
and	O
then	O
reinitializes	O
the	O
states	O
to	O
start	O
processing	O
the	O
next	O
segment	O
.	O
	
Learning	O
to	O
select	O
a	O
proper	O
operation	O
at	O
each	O
time	O
step	O
and	O
to	O
detect	O
the	O
boundaries	O
,	O
the	O
HM	B-Method
-	I-Method
RNN	I-Method
discovers	O
the	O
latent	O
hierarchical	O
structure	O
of	O
the	O
sequences	O
.	O
	
We	O
find	O
that	O
the	O
straight	B-Method
-	I-Method
through	I-Method
estimator	I-Method
[	O
reference	B-Method
][	I-Method
reference	I-Method
][	I-Method
reference	I-Method
]	O
is	O
efficient	O
for	O
training	O
this	O
model	O
containing	O
discrete	O
variables	O
.	O
	
We	O
evaluate	O
our	O
model	O
on	O
two	O
tasks	O
:	O
character	B-Task
-	I-Task
level	I-Task
language	I-Task
modelling	I-Task
and	O
handwriting	B-Task
sequence	I-Task
generation	I-Task
.	O
	
For	O
the	O
character	B-Task
-	I-Task
level	I-Task
language	I-Task
modelling	I-Task
,	O
the	O
HM	B-Method
-	I-Method
RNN	I-Method
achieves	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
the	O
Text8	B-Material
dataset	I-Material
,	O
and	O
comparable	O
results	O
to	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
on	O
the	O
Penn	O
Treebank	O
and	O
Hutter	B-Material
Prize	I-Material
Wikipedia	I-Material
datasets	I-Material
.	O
	
The	O
HM	B-Method
-	I-Method
RNN	I-Method
also	O
outperforms	O
the	O
standard	O
RNN	B-Method
on	O
the	O
handwriting	B-Task
sequence	I-Task
generation	I-Task
using	O
the	O
IAM	O
-	O
OnDB	O
dataset	O
.	O
	
In	O
addition	O
,	O
we	O
demonstrate	O
that	O
the	O
hierarchical	O
structure	O
found	O
by	O
the	O
HM	B-Method
-	I-Method
RNN	I-Method
is	O
indeed	O
very	O
similar	O
to	O
the	O
intrinsic	O
structure	O
observed	O
in	O
the	O
data	O
.	O
	
The	O
contributions	O
of	O
this	O
paper	O
are	O
:	O
	
•	O
	
We	O
propose	O
for	O
the	O
first	O
time	O
an	O
RNN	B-Method
model	I-Method
that	O
can	O
learn	O
a	O
latent	O
hierarchical	O
structure	O
of	O
a	O
sequence	O
without	O
using	O
explicit	O
boundary	O
information	O
.	O
	
•	O
	
We	O
show	O
that	O
it	O
is	O
beneficial	O
to	O
utilize	O
the	O
above	O
structure	O
through	O
empirical	O
evaluation	O
.	O
	
•	O
	
We	O
show	O
that	O
the	O
straight	B-Method
-	I-Method
through	I-Method
estimator	I-Method
is	O
an	O
efficient	O
way	O
of	O
training	O
a	O
model	O
containing	O
discrete	O
variables	O
.	O
	
•	O
	
We	O
propose	O
the	O
slope	B-Method
annealing	I-Method
trick	I-Method
to	O
improve	O
the	O
training	B-Method
procedure	I-Method
based	O
on	O
the	O
straight	B-Method
-	I-Method
through	I-Method
estimator	I-Method
.	O
	
section	O
:	O
RELATED	O
WORK	O
	
Two	O
notable	O
early	O
attempts	O
inspiring	O
our	O
model	O
are	O
[	O
reference	O
]	O
and	O
El	B-Method
	
[	O
reference	O
]	O
.	O
	
In	O
these	O
works	O
,	O
it	O
is	O
advocated	O
to	O
stack	O
multiple	O
layers	O
of	O
RNNs	B-Method
in	O
a	O
decreasing	O
order	O
of	O
update	O
frequency	O
for	O
computational	B-Metric
and	O
learning	B-Metric
efficiency	I-Metric
.	O
	
In	O
[	O
reference	O
]	O
,	O
the	O
author	O
shows	O
a	O
model	O
that	O
can	O
self	O
-	O
organize	O
a	O
hierarchical	O
multiscale	O
structure	O
.	O
	
Particularly	O
in	O
El	B-Method
[	O
reference	O
]	O
,	O
the	O
advantages	O
of	O
incorporating	O
a	O
priori	O
knowledge	O
,	O
"	O
temporal	O
dependencies	O
are	O
structured	O
hierarchically	O
"	O
,	O
into	O
the	O
RNN	B-Method
architecture	I-Method
is	O
studied	O
.	O
	
The	O
authors	O
propose	O
an	O
RNN	B-Method
architecture	I-Method
that	O
updates	O
each	O
layer	O
with	O
a	O
fixed	O
but	O
different	O
rate	O
,	O
called	O
a	O
hierarchical	B-Method
RNN	I-Method
.	O
	
LSTMs	B-Method
[	O
reference	O
]	O
employ	O
the	O
multiscale	B-Method
update	I-Method
concept	I-Method
,	O
where	O
the	O
hidden	O
units	O
have	O
different	O
forget	O
and	O
update	O
rates	O
and	O
thus	O
can	O
operate	O
with	O
different	O
timescales	O
.	O
	
However	O
,	O
unlike	O
our	O
model	O
,	O
these	O
timescales	O
are	O
not	O
organized	O
hierarchically	O
.	O
	
Although	O
the	O
LSTM	B-Method
has	O
a	O
selfloop	O
for	O
the	O
gradients	O
that	O
helps	O
to	O
capture	O
the	O
long	O
-	O
term	O
dependencies	O
by	O
mitigating	O
the	O
vanishing	B-Task
gradient	I-Task
problem	I-Task
,	O
in	O
practice	O
,	O
it	O
is	O
still	O
limited	O
to	O
a	O
few	O
hundred	O
time	O
steps	O
due	O
to	O
the	O
leaky	O
integration	O
by	O
which	O
the	O
contents	O
to	O
memorize	O
for	O
a	O
long	O
-	O
term	O
is	O
gradually	O
diluted	O
at	O
every	O
time	O
step	O
.	O
	
Also	O
,	O
the	O
model	O
remains	O
computationally	O
expensive	O
because	O
it	O
has	O
to	O
perform	O
the	O
update	O
at	O
every	O
time	O
step	O
for	O
each	O
unit	O
.	O
	
However	O
,	O
our	O
model	O
is	O
less	O
prone	O
to	O
these	O
problems	O
because	O
it	O
learns	O
a	O
hierarchical	O
structure	O
such	O
that	O
,	O
by	O
design	O
,	O
high	O
-	O
level	O
layers	O
learn	O
to	O
perform	O
less	O
frequent	O
updates	O
than	O
low	O
-	O
level	O
layers	O
.	O
	
We	O
hypothesize	O
that	O
this	O
property	O
mitigates	O
the	O
vanishing	B-Task
gradient	I-Task
problem	I-Task
more	O
efficiently	O
while	O
also	O
being	O
computationally	O
more	O
efficient	O
.	O
	
A	O
more	O
recent	O
model	O
,	O
the	O
clockwork	B-Method
RNN	I-Method
(	I-Method
CW	I-Method
-	I-Method
RNN	I-Method
)	O
	
[	O
reference	O
]	O
extends	O
the	O
hierarchical	O
RNN	O
(	O
El	B-Method
[	O
reference	O
]	O
and	O
the	O
NARX	B-Method
RNN	I-Method
[	O
reference	O
]	O
1	O
.	O
	
The	O
CW	B-Method
-	I-Method
RNN	I-Method
tries	O
to	O
solve	O
the	O
issue	O
of	O
using	O
soft	O
timescales	O
in	O
the	O
LSTM	B-Method
,	O
by	O
explicitly	O
assigning	O
hard	O
timescales	O
.	O
	
In	O
the	O
CW	B-Method
-	I-Method
RNN	I-Method
,	O
hidden	O
units	O
are	O
partitioned	O
into	O
several	O
modules	O
,	O
and	O
different	O
timescales	O
are	O
assigned	O
to	O
the	O
modules	O
such	O
that	O
a	O
module	O
i	O
updates	O
its	O
hidden	O
units	O
at	O
every	O
2	O
(	O
i−1	O
)	O
-	O
th	O
time	O
step	O
.	O
	
The	O
CW	B-Method
-	I-Method
RNN	I-Method
is	O
computationally	O
more	O
efficient	O
than	O
the	O
standard	O
RNN	B-Method
including	O
the	O
LSTM	B-Method
since	O
hidden	B-Method
units	I-Method
are	O
updated	O
only	O
at	O
the	O
assigned	O
clock	O
rates	O
.	O
	
However	O
,	O
finding	O
proper	O
timescales	O
in	O
the	O
CW	B-Method
-	I-Method
RNN	I-Method
remains	O
as	O
a	O
challenge	O
whereas	O
our	O
model	O
learns	O
the	O
intrinsic	O
timescales	O
from	O
the	O
data	O
.	O
	
In	O
the	O
biscale	B-Method
RNNs	I-Method
[	O
reference	O
]	O
,	O
the	O
authors	O
proposed	O
to	O
model	O
layer	O
-	O
wise	O
timescales	O
adaptively	O
by	O
having	O
additional	O
gating	O
units	O
,	O
however	O
this	O
approach	O
still	O
relies	O
on	O
the	O
soft	B-Method
gating	I-Method
mechanism	I-Method
like	O
LSTMs	B-Method
.	O
	
Other	O
forms	O
of	O
Hierarchical	B-Method
RNN	I-Method
(	I-Method
HRNN	I-Method
)	I-Method
architectures	I-Method
have	O
been	O
proposed	O
in	O
the	O
cases	O
where	O
the	O
explicit	O
hierarchical	O
boundary	O
structure	O
is	O
provided	O
.	O
	
In	O
[	O
reference	O
]	O
,	O
after	O
obtaining	O
the	O
word	O
boundary	O
via	O
tokenization	B-Method
,	O
the	O
HRNN	B-Method
architecture	I-Method
is	O
used	O
for	O
neural	B-Task
machine	I-Task
translation	I-Task
by	O
modelling	O
the	O
characters	O
and	O
words	O
using	O
the	O
first	B-Method
and	I-Method
second	I-Method
RNN	I-Method
layers	I-Method
,	O
respectively	O
.	O
	
A	O
similar	O
HRNN	B-Method
architecture	I-Method
is	O
also	O
adopted	O
in	O
[	O
reference	O
]	O
to	O
model	O
dialogue	O
utterances	O
.	O
	
However	O
,	O
in	O
many	O
cases	O
,	O
hierarchical	O
boundary	O
information	O
is	O
not	O
explicitly	O
observed	O
or	O
expensive	O
to	O
obtain	O
.	O
	
Also	O
,	O
it	O
is	O
unclear	O
how	O
to	O
deploy	O
more	O
layers	O
than	O
the	O
number	O
of	O
boundary	O
levels	O
that	O
is	O
explicitly	O
observed	O
in	O
the	O
data	O
.	O
	
While	O
the	O
above	O
models	O
focus	O
on	O
online	B-Task
prediction	I-Task
problems	I-Task
,	O
where	O
a	O
prediction	B-Task
needs	O
to	O
be	O
made	O
by	O
using	O
only	O
the	O
past	O
data	O
,	O
in	O
some	O
cases	O
,	O
predictions	O
are	O
made	O
after	O
observing	O
the	O
whole	O
sequence	O
.	O
	
In	O
this	O
setting	O
,	O
the	O
input	O
sequence	O
can	O
be	O
regarded	O
as	O
1	O
-	O
D	O
spatial	O
data	O
,	O
convolutional	B-Method
neural	I-Method
networks	I-Method
with	O
1	B-Method
-	I-Method
D	I-Method
kernels	I-Method
are	O
proposed	O
in	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
for	O
language	B-Task
modelling	I-Task
and	O
sentence	B-Task
classification	I-Task
.	O
	
Also	O
,	O
in	O
[	O
reference	O
]	O
and	O
,	O
the	O
authors	O
proposed	O
to	O
obtain	O
high	O
-	O
level	B-Method
representation	I-Method
of	O
the	O
sequences	O
of	O
reduced	O
length	O
by	O
repeatedly	O
merging	O
or	O
pooling	O
the	O
lower	B-Method
-	I-Method
level	I-Method
representation	I-Method
of	O
the	O
sequences	O
.	O
	
Hierarchical	B-Method
RNN	I-Method
architectures	I-Method
have	O
also	O
been	O
used	O
to	O
discover	O
the	O
segmentation	O
structure	O
in	O
sequences	O
	
[	O
reference	O
][	O
reference	O
]	O
.	O
	
It	O
is	O
however	O
different	O
to	O
our	O
model	O
in	O
the	O
sense	O
that	O
they	O
optimize	O
the	O
objective	O
with	O
explicit	O
labels	O
on	O
the	O
hierarchical	O
segments	O
while	O
our	O
model	O
discovers	O
the	O
intrinsic	O
structure	O
only	O
from	O
the	O
sequences	O
without	O
segment	O
label	O
information	O
.	O
	
The	O
COPY	B-Method
operation	I-Method
used	O
in	O
our	O
model	O
can	O
be	O
related	O
to	O
Zoneout	B-Method
[	O
reference	O
]	O
which	O
is	O
a	O
recurrent	B-Method
generalization	I-Method
of	I-Method
stochastic	I-Method
depth	I-Method
[	O
reference	O
]	O
.	O
In	O
Zoneout	B-Method
,	O
an	O
identity	B-Method
transformation	I-Method
is	O
randomly	O
applied	O
to	O
each	O
hidden	O
unit	O
at	O
each	O
time	O
step	O
according	O
to	O
a	O
Bernoulli	B-Method
distribution	I-Method
.	O
	
This	O
results	O
in	O
occasional	O
copy	O
operations	O
of	O
the	O
previous	O
hidden	O
states	O
.	O
	
While	O
the	O
focus	O
of	O
Zoneout	B-Task
is	O
to	O
propose	O
a	O
regularization	B-Method
technique	I-Method
similar	O
to	O
dropout	B-Method
[	O
reference	O
]	O
(	O
where	O
the	O
regularization	O
strength	O
is	O
controlled	O
by	O
a	O
hyperparameter	O
)	O
,	O
our	O
model	O
learns	O
(	O
a	O
)	O
to	O
dynamically	O
determine	O
when	O
to	O
copy	O
from	O
the	O
context	O
inputs	O
and	O
(	O
b	O
)	O
to	O
discover	O
the	O
hierarchical	O
multiscale	O
structure	O
and	O
representation	O
.	O
	
Although	O
the	O
main	O
goal	O
of	O
our	O
proposed	O
model	O
is	O
not	O
regularization	O
,	O
we	O
found	O
that	O
our	O
model	O
also	O
shows	O
very	O
good	O
generalization	B-Metric
performance	O
.	O
	
3	O
HIERARCHICAL	B-Method
MULTISCALE	I-Method
RECURRENT	I-Method
NEURAL	I-Method
NETWORKS	I-Method
	
section	O
:	O
MOTIVATION	O
	
To	O
begin	O
with	O
,	O
we	O
provide	O
an	O
example	O
of	O
how	O
a	O
stacked	B-Method
RNN	I-Method
can	O
model	O
temporal	O
data	O
in	O
an	O
ideal	O
setting	O
,	O
i.e.	O
,	O
when	O
the	O
hierarchy	O
of	O
segments	O
is	O
provided	O
[	O
reference	O
][	O
reference	O
]	O
.	O
	
In	O
Figure	O
1	O
(	O
a	O
)	O
,	O
we	O
depict	O
a	O
hierarchical	B-Method
RNN	I-Method
(	I-Method
HRNN	I-Method
)	I-Method
for	O
language	B-Task
modelling	I-Task
with	O
two	O
layers	O
:	O
the	O
first	O
layer	O
receives	O
characters	O
as	O
inputs	O
and	O
generates	O
word	B-Method
-	I-Method
level	I-Method
representations	I-Method
(	O
C2W	B-Method
-	I-Method
RNN	I-Method
)	O
,	O
and	O
the	O
second	O
layer	O
takes	O
the	O
word	B-Method
-	I-Method
level	I-Method
representations	I-Method
as	O
inputs	O
and	O
yields	O
phrase	B-Method
-	I-Method
level	I-Method
representations	I-Method
(	O
W2P	B-Method
-	I-Method
RNN	I-Method
)	O
.	O
	
As	O
shown	O
,	O
by	O
means	O
of	O
the	O
provided	O
end	O
-	O
of	O
-	O
word	O
labels	O
,	O
the	O
C2W	B-Method
-	I-Method
RNN	I-Method
obtains	O
word	B-Method
-	I-Method
level	I-Method
representation	I-Method
after	O
processing	O
the	O
last	O
character	O
of	O
each	O
word	O
and	O
passes	O
the	O
word	B-Method
-	I-Method
level	I-Method
representation	I-Method
to	O
the	O
W2P	B-Method
-	I-Method
RNN	I-Method
.	O
	
Then	O
,	O
the	O
W2P	B-Method
-	I-Method
RNN	I-Method
performs	O
an	O
update	O
of	O
the	O
phrase	B-Method
-	I-Method
level	I-Method
representation	I-Method
.	O
	
Note	O
that	O
the	O
hidden	O
states	O
of	O
the	O
W2P	B-Method
-	I-Method
RNN	I-Method
remains	O
unchanged	O
while	O
all	O
the	O
characters	O
of	O
a	O
word	O
are	O
processed	O
by	O
the	O
C2W	B-Method
-	I-Method
RNN	I-Method
.	O
	
When	O
the	O
C2W	B-Method
-	I-Method
RNN	I-Method
starts	O
to	O
process	O
the	O
next	O
word	O
,	O
its	O
hidden	O
states	O
are	O
reinitialized	O
using	O
the	O
latest	O
hidden	O
states	O
of	O
the	O
W2P	B-Method
-	I-Method
RNN	I-Method
,	O
which	O
contain	O
summarized	O
representation	O
of	O
all	O
the	O
words	O
that	O
have	O
been	O
processed	O
by	O
that	O
time	O
step	O
,	O
in	O
that	O
phrase	O
.	O
	
From	O
this	O
simple	O
example	O
,	O
we	O
can	O
see	O
the	O
advantages	O
of	O
having	O
a	O
hierarchical	O
multiscale	O
structure	O
:	O
(	O
1	O
)	O
as	O
the	O
W2P	B-Method
-	I-Method
RNN	I-Method
is	O
updated	O
at	O
a	O
much	O
slower	O
update	B-Metric
rate	I-Metric
than	O
the	O
C2W	B-Method
-	I-Method
RNN	I-Method
,	O
a	O
considerable	O
amount	O
of	O
computation	O
can	O
be	O
saved	O
,	O
(	O
2	O
)	O
gradients	O
are	O
backpropagated	O
through	O
a	O
much	O
smaller	O
number	O
of	O
time	O
steps	O
,	O
and	O
	
(	O
3	O
)	O
layer	B-Method
-	I-Method
wise	I-Method
capacity	I-Method
control	I-Method
becomes	O
possible	O
(	O
e.g.	O
,	O
use	O
a	O
smaller	O
number	O
of	O
hidden	O
units	O
in	O
the	O
first	O
layer	O
which	O
models	O
short	O
-	O
term	O
dependencies	O
but	O
whose	O
updates	O
are	O
invoked	O
much	O
more	O
often	O
)	O
.	O
	
Can	O
an	O
RNN	B-Method
discover	O
such	O
hierarchical	O
multiscale	O
structure	O
without	O
explicit	O
hierarchical	O
boundary	O
information	O
?	O
	
Considering	O
the	O
fact	O
that	O
the	O
boundary	O
information	O
is	O
difficult	O
to	O
obtain	O
(	O
for	O
example	O
,	O
consider	O
languages	O
where	O
words	O
are	O
not	O
always	O
cleanly	O
separated	O
by	O
spaces	O
or	O
punctuation	O
symbols	O
,	O
and	O
imperfect	O
rules	O
are	O
used	O
to	O
separately	O
perform	O
segmentation	B-Task
)	O
or	O
usually	O
not	O
provided	O
at	O
all	O
,	O
this	O
is	O
a	O
legitimate	O
problem	O
.	O
	
It	O
gets	O
worse	O
when	O
we	O
consider	O
higher	O
-	O
level	O
concepts	O
which	O
we	O
would	O
like	O
the	O
RNN	B-Method
to	O
discover	O
autonomously	O
.	O
	
In	O
Section	O
2	O
,	O
we	O
discussed	O
the	O
limitations	O
of	O
the	O
existing	O
RNN	B-Method
models	I-Method
under	O
this	O
setting	O
,	O
which	O
either	O
have	O
to	O
update	O
all	O
units	O
at	O
every	O
time	O
step	O
or	O
use	O
fixed	O
update	O
frequencies	O
	
[	O
reference	O
][	O
reference	O
]	O
.	O
	
Unfortunately	O
,	O
this	O
kind	O
of	O
approach	O
is	O
not	O
well	O
suited	O
to	O
the	O
case	O
where	O
different	O
segments	O
in	O
the	O
hierarchical	B-Method
decomposition	I-Method
have	O
different	O
lengths	O
:	O
for	O
example	O
,	O
different	O
words	O
have	O
different	O
lengths	O
,	O
so	O
a	O
fixed	O
hierarchy	O
would	O
not	O
update	O
its	O
upper	O
-	O
level	O
units	O
in	O
synchrony	O
with	O
the	O
natural	O
boundaries	O
in	O
the	O
data	O
.	O
	
section	O
:	O
THE	O
PROPOSED	O
MODEL	O
	
A	O
key	O
element	O
of	O
our	O
model	O
is	O
the	O
introduction	O
of	O
a	O
parametrized	B-Method
boundary	I-Method
detector	I-Method
,	O
which	O
outputs	O
a	O
binary	O
value	O
,	O
in	O
each	O
layer	O
of	O
a	O
stacked	B-Method
RNN	I-Method
,	O
and	O
learns	O
when	O
a	O
segment	O
should	O
end	O
in	O
such	O
a	O
way	O
to	O
optimize	O
the	O
overall	O
target	O
objective	B-Metric
.	O
	
Whenever	O
the	O
boundary	B-Method
detector	I-Method
is	O
turned	O
on	O
at	O
a	O
time	O
step	O
of	O
layer	O
(	O
i.e.	O
,	O
when	O
the	O
boundary	O
state	O
is	O
1	O
)	O
,	O
the	O
model	O
considers	O
this	O
to	O
be	O
the	O
end	O
of	O
a	O
segment	O
corresponding	O
to	O
the	O
latent	O
abstraction	O
level	O
of	O
that	O
layer	O
(	O
e.g.	O
,	O
word	O
or	O
phrase	O
)	O
and	O
feeds	O
the	O
summarized	B-Method
representation	I-Method
of	O
the	O
detected	O
segment	O
into	O
the	O
upper	O
layer	O
(	O
+	O
1	O
)	O
.	O
	
Using	O
the	O
boundary	O
states	O
,	O
at	O
each	O
time	O
step	O
,	O
each	O
layer	O
selects	O
one	O
of	O
the	O
following	O
operations	O
:	O
UPDATE	O
,	O
COPY	O
or	O
FLUSH	O
.	O
	
The	O
selection	O
is	O
determined	O
by	O
(	O
1	O
)	O
the	O
boundary	O
state	O
of	O
the	O
current	O
time	O
step	O
in	O
the	O
layer	O
below	O
z	O
−1	O
t	O
and	O
(	O
2	O
)	O
the	O
boundary	O
state	O
of	O
the	O
previous	O
time	O
step	O
in	O
the	O
same	O
layer	O
z	O
t−1	O
.	O
	
In	O
the	O
following	O
,	O
we	O
describe	O
an	O
HM	B-Method
-	I-Method
RNN	I-Method
based	O
on	O
the	O
LSTM	B-Method
update	O
rule	O
.	O
	
We	O
call	O
this	O
model	O
a	O
hierarchical	B-Method
multiscale	I-Method
LSTM	I-Method
(	O
HM	B-Method
-	I-Method
LSTM	I-Method
)	O
.	O
	
Consider	O
an	O
HM	B-Method
-	I-Method
LSTM	I-Method
model	I-Method
of	I-Method
L	I-Method
layers	I-Method
(	O
=	O
1	O
,	O
.	O
.	O
	
.	O
	
,	O
L	O
)	O
which	O
,	O
at	O
each	O
layer	O
,	O
performs	O
the	O
following	O
update	O
at	O
time	O
step	O
t	O
:	O
	
(	O
	
Here	O
,	O
h	O
and	O
c	O
denote	O
the	O
hidden	O
and	O
cell	O
states	O
,	O
respectively	O
.	O
	
The	O
function	O
f	O
HM	O
-	O
LSTM	B-Method
is	O
implemented	O
as	O
follows	O
.	O
	
First	O
,	O
using	O
the	O
two	O
boundary	O
states	O
z	O
t−1	O
and	O
z	O
−1	O
t	O
,	O
the	O
cell	O
state	O
is	O
updated	O
by	O
:	O
	
and	O
then	O
the	O
hidden	O
state	O
is	O
obtained	O
by	O
:	O
	
Here	O
,	O
(	O
f	O
,	O
i	O
,	O
o	O
)	O
are	O
forget	O
,	O
input	O
,	O
output	O
gates	O
,	O
and	O
g	O
is	O
a	O
cell	O
proposal	O
vector	O
.	O
	
Note	O
that	O
unlike	O
the	O
LSTM	B-Method
,	O
it	O
is	O
not	O
necessary	O
to	O
compute	O
these	O
gates	O
and	O
cell	O
proposal	O
values	O
at	O
every	O
time	O
step	O
.	O
	
For	O
example	O
,	O
in	O
the	O
case	O
of	O
the	O
COPY	O
operation	O
,	O
we	O
do	O
not	O
need	O
to	O
compute	O
any	O
of	O
these	O
values	O
and	O
thus	O
can	O
save	O
computations	O
.	O
	
The	O
COPY	B-Method
operation	I-Method
,	O
which	O
simply	O
performs	O
(	O
c	O
t	O
,	O
	
h	O
t	O
)	O
←	O
(	O
c	O
t−1	O
,	O
h	O
t−1	O
)	O
,	O
implements	O
the	O
observation	O
that	O
an	O
upper	O
layer	O
should	O
keep	O
its	O
state	O
unchanged	O
until	O
it	O
receives	O
the	O
summarized	O
input	O
from	O
the	O
lower	O
layer	O
.	O
	
The	O
UPDATE	B-Method
operation	I-Method
is	O
performed	O
to	O
update	O
the	O
summary	B-Task
representation	I-Task
of	I-Task
the	I-Task
layer	I-Task
if	O
the	O
boundary	O
z	O
−1	O
t	O
is	O
detected	O
from	O
the	O
layer	O
below	O
but	O
the	O
boundary	O
z	O
t−1	O
was	O
not	O
found	O
at	O
the	O
previous	O
time	O
step	O
.	O
	
Hence	O
,	O
the	O
UPDATE	B-Method
operation	I-Method
is	O
executed	O
sparsely	O
unlike	O
the	O
standard	O
RNNs	B-Method
where	O
it	O
is	O
executed	O
at	O
every	O
time	O
step	O
,	O
making	O
it	O
computationally	O
inefficient	O
.	O
	
If	O
a	O
boundary	O
is	O
detected	O
,	O
the	O
FLUSH	B-Method
operation	I-Method
is	O
executed	O
.	O
	
The	O
FLUSH	B-Method
operation	I-Method
consists	O
of	O
two	O
sub	O
-	O
operations	O
:	O
(	O
a	O
)	O
EJECT	O
to	O
pass	O
the	O
current	O
state	O
to	O
the	O
upper	O
layer	O
and	O
then	O
(	O
b	O
)	O
RESET	O
to	O
reinitialize	O
the	O
state	O
before	O
starting	O
to	O
read	O
a	O
new	O
segment	O
.	O
	
This	O
operation	O
implicitly	O
forces	O
the	O
upper	O
layer	O
to	O
absorb	O
the	O
summary	O
information	O
of	O
the	O
lower	O
layer	O
segment	O
,	O
because	O
otherwise	O
it	O
will	O
be	O
lost	O
.	O
	
Note	O
that	O
the	O
FLUSH	B-Method
operation	I-Method
is	O
a	O
hard	O
reset	O
in	O
the	O
sense	O
that	O
it	O
completely	O
erases	O
all	O
the	O
previous	O
states	O
of	O
the	O
same	O
layer	O
,	O
which	O
is	O
different	O
from	O
the	O
soft	O
reset	O
or	O
soft	O
forget	O
operation	O
in	O
the	O
GRU	B-Method
or	O
LSTM	B-Method
.	O
	
Whenever	O
needed	O
(	O
depending	O
on	O
the	O
chosen	O
operation	O
)	O
,	O
the	O
gate	O
values	O
(	O
f	O
t	O
,	O
i	O
t	O
,	O
o	O
t	O
)	O
,	O
the	O
cell	O
proposal	O
g	O
t	O
,	O
and	O
the	O
pre	O
-	O
activation	O
of	O
the	O
boundary	O
detectorz	O
t	O
2	O
are	O
then	O
obtained	O
by	O
:	O
	
where	O
	
Here	O
,	O
we	O
use	O
W	O
	
)	O
	
×dim	O
(	O
h	O
)	O
to	O
denote	O
state	O
transition	O
parameters	O
from	O
layer	O
i	O
to	O
layer	O
j	O
,	O
and	O
b	O
∈	O
R	O
4dim	O
(	O
h	O
)	O
	
+	O
1	O
is	O
a	O
bias	O
term	O
.	O
	
In	O
the	O
last	O
layer	O
L	O
,	O
the	O
2z	O
t	O
can	O
also	O
be	O
implemented	O
as	O
a	O
function	O
of	O
h	O
t	O
,	O
e.g.	O
,	O
z	O
t	O
=	O
hard	O
sigm	O
(	O
U	O
h	O
t	O
)	O
.	O
	
top	O
-	O
down	O
connection	O
is	O
ignored	O
,	O
and	O
we	O
use	O
h	O
0	O
t	O
=	O
x	O
t	O
.	O
	
Since	O
the	O
input	O
should	O
not	O
be	O
omitted	O
,	O
we	O
set	O
z	O
0	O
t	O
	
=	O
1	O
for	O
all	O
	
t.	O
	
Also	O
,	O
we	O
do	O
not	O
use	O
the	O
boundary	B-Method
detector	I-Method
for	O
the	O
last	O
layer	O
.	O
	
The	O
hard	O
sigm	O
is	O
defined	O
by	O
hard	B-Method
sigm	I-Method
(	I-Method
x	I-Method
)	O
=	O
max	O
0	O
,	O
min	O
1	O
,	O
	
with	O
a	O
being	O
the	O
slope	O
variable	O
.	O
	
Unlike	O
the	O
standard	O
LSTM	B-Method
,	O
the	O
HM	B-Method
-	I-Method
LSTM	I-Method
has	O
a	O
top	O
-	O
down	O
connection	O
from	O
(	O
+	O
1	O
)	O
to	O
,	O
which	O
is	O
allowed	O
to	O
be	O
activated	O
only	O
if	O
a	O
boundary	O
is	O
detected	O
at	O
the	O
previous	O
time	O
step	O
of	O
the	O
layer	O
(	O
see	O
Eq	O
.	O
6	O
)	O
.	O
	
This	O
makes	O
the	O
layer	O
to	O
be	O
initialized	O
with	O
more	O
long	O
-	O
term	O
information	O
after	O
the	O
boundary	O
is	O
detected	O
and	O
execute	O
the	O
FLUSH	O
operation	O
.	O
	
In	O
addition	O
,	O
the	O
input	O
from	O
the	O
lower	O
layer	O
(	O
−	O
1	O
)	O
becomes	O
effective	O
only	O
when	O
a	O
boundary	O
is	O
detected	O
at	O
the	O
current	O
time	O
step	O
in	O
the	O
layer	O
(	O
−	O
1	O
)	O
due	O
to	O
the	O
binary	O
gate	O
z	O
	
−1	O
t	O
.	O
	
Figure	O
2	O
(	O
left	O
)	O
shows	O
the	O
gating	B-Method
mechanism	I-Method
of	O
the	O
HM	B-Method
-	I-Method
LSTM	I-Method
at	O
time	O
step	O
	
t.	O
	
Finally	O
,	O
the	O
binary	O
boundary	O
state	O
z	O
t	O
is	O
obtained	O
by	O
:	O
	
For	O
the	O
binarization	O
function	O
f	O
bound	O
:	O
	
R	O
→	O
{	O
0	O
,	O
1	O
}	O
,	O
we	O
can	O
either	O
use	O
a	O
deterministic	B-Method
step	I-Method
function	I-Method
:	O
	
or	O
sample	O
from	O
a	O
Bernoulli	B-Method
distribution	I-Method
z	O
t	O
∼	O
Bernoulli	B-Method
(	I-Method
z	I-Method
t	I-Method
)	O
.	O
	
Although	O
this	O
binary	O
decision	O
is	O
a	O
key	O
to	O
our	O
model	O
,	O
it	O
is	O
usually	O
difficult	O
to	O
use	O
stochastic	B-Method
gradient	I-Method
descent	I-Method
to	O
train	O
such	O
model	O
with	O
discrete	O
decisions	O
as	O
it	O
is	O
not	O
differentiable	O
.	O
	
section	O
:	O
COMPUTING	B-Task
GRADIENT	I-Task
OF	I-Task
BOUNDARY	I-Task
DETECTOR	I-Task
	
Training	O
neural	B-Method
networks	I-Method
with	O
discrete	O
variables	O
requires	O
more	O
efforts	O
since	O
the	O
standard	O
backpropagation	B-Method
is	O
no	O
longer	O
applicable	O
due	O
to	O
the	O
non	O
-	O
differentiability	O
.	O
	
Among	O
a	O
few	O
methods	O
for	O
training	O
a	O
neural	B-Method
network	I-Method
with	O
discrete	O
variables	O
such	O
as	O
the	O
REINFORCE	B-Method
[	O
reference	O
][	O
reference	O
]	O
and	O
the	O
straight	B-Method
-	I-Method
through	I-Method
estimator	I-Method
[	O
reference	O
][	O
reference	O
]	O
,	O
we	O
use	O
the	O
straightthrough	B-Method
estimator	I-Method
to	O
train	O
our	O
model	O
.	O
	
The	O
straight	B-Method
-	I-Method
through	I-Method
estimator	I-Method
is	O
a	O
biased	B-Method
estimator	I-Method
because	O
the	O
non	O
-	O
differentiable	O
function	O
used	O
in	O
the	O
forward	O
pass	O
(	O
i.e.	O
,	O
the	O
step	O
function	O
in	O
our	O
case	O
)	O
is	O
replaced	O
by	O
a	O
differentiable	O
function	O
during	O
the	O
backward	O
pass	O
(	O
i.e.	O
,	O
the	O
hard	O
sigmoid	O
function	O
in	O
our	O
case	O
)	O
.	O
	
The	O
straight	B-Method
-	I-Method
through	I-Method
estimator	I-Method
,	O
however	O
,	O
is	O
much	O
simpler	O
and	O
often	O
works	O
more	O
efficiently	O
in	O
practice	O
than	O
other	O
unbiased	B-Method
but	I-Method
high	I-Method
-	I-Method
variance	I-Method
estimators	I-Method
such	O
as	O
the	O
REINFORCE	B-Method
.	O
	
The	O
straight	B-Method
-	I-Method
through	I-Method
estimator	I-Method
has	O
also	O
been	O
used	O
in	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
.	O
	
The	O
Slope	B-Method
Annealing	I-Method
Trick	I-Method
.	O
	
In	O
our	O
experiment	O
,	O
we	O
use	O
the	O
slope	B-Method
annealing	I-Method
trick	I-Method
to	O
reduce	O
the	O
bias	O
of	O
the	O
straight	B-Method
-	I-Method
through	I-Method
estimator	I-Method
.	O
	
The	O
idea	O
is	O
to	O
reduce	O
the	O
discrepancy	O
between	O
the	O
two	O
functions	O
used	O
during	O
the	O
forward	O
pass	O
and	O
the	O
backward	O
pass	O
.	O
	
That	O
is	O
,	O
by	O
gradually	O
increasing	O
the	O
slope	O
a	O
of	O
the	O
hard	O
sigmoid	O
function	O
,	O
we	O
make	O
the	O
hard	O
sigmoid	O
be	O
close	O
to	O
the	O
step	O
function	O
.	O
	
Note	O
that	O
starting	O
with	O
a	O
high	O
slope	O
value	O
from	O
the	O
beginning	O
can	O
make	O
the	O
training	O
difficult	O
while	O
it	O
is	O
more	O
applicable	O
later	O
when	O
the	O
model	O
parameters	O
become	O
more	O
stable	O
.	O
	
In	O
our	O
experiments	O
,	O
starting	O
from	O
slope	O
a	O
=	O
1	O
,	O
we	O
slowly	O
increase	O
the	O
slope	O
until	O
it	O
reaches	O
a	O
threshold	O
with	O
an	O
appropriate	O
scheduling	O
.	O
	
section	O
:	O
EXPERIMENTS	O
	
We	O
evaluate	O
the	O
proposed	O
model	O
on	O
two	O
tasks	O
,	O
character	B-Task
-	I-Task
level	I-Task
language	I-Task
modelling	I-Task
and	O
handwriting	B-Task
sequence	I-Task
generation	I-Task
.	O
	
Character	B-Method
-	I-Method
level	I-Method
language	I-Method
modelling	I-Method
is	O
a	O
representative	O
example	O
of	O
discrete	O
[	O
reference	O
]	O
1.67	O
MRNN	O
[	O
reference	O
]	O
	
1.60	O
GF	B-Method
-	I-Method
LSTM	I-Method
[	O
reference	O
]	O
1.58	O
Grid	B-Method
-	I-Method
LSTM	I-Method
[	O
reference	O
]	O
1.47	O
MI	B-Method
-	I-Method
LSTM	I-Method
1.44	O
Recurrent	B-Method
Memory	I-Method
Array	I-Method
Structures	I-Method
(	O
Rocki	O
,	O
2016a	O
)	O
	
1.40	O
SF	B-Method
-	I-Method
LSTM	I-Method
	
(	O
Rocki	O
,	O
2016b	O
)	O
‡	O
	
1.37	O
HyperNetworks	B-Method
[	O
reference	O
]	O
	
1.35	O
LayerNorm	B-Method
HyperNetworks	I-Method
[	O
reference	O
]	O
	
1.34	O
Recurrent	B-Method
Highway	I-Method
Networks	I-Method
[	O
reference	O
]	O
1	O
sequence	B-Method
modelling	I-Method
,	O
where	O
the	O
discrete	O
symbols	O
form	O
a	O
distinct	O
hierarchical	O
multiscale	O
structure	O
.	O
	
The	O
performance	O
on	O
real	O
-	O
valued	O
sequences	O
is	O
tested	O
on	O
the	O
handwriting	B-Task
sequence	I-Task
generation	I-Task
in	O
which	O
a	O
relatively	O
clear	O
hierarchical	O
multiscale	O
structure	O
exists	O
compared	O
to	O
other	O
data	O
such	O
as	O
speech	O
signals	O
.	O
	
section	O
:	O
CHARACTER	B-Task
-	I-Task
LEVEL	I-Task
LANGUAGE	I-Task
MODELLING	I-Task
	
A	O
sequence	B-Task
modelling	I-Task
task	I-Task
aims	O
at	O
learning	O
the	O
probability	O
distribution	O
over	O
sequences	O
by	O
minimizing	O
the	O
negative	O
log	O
-	O
likelihood	O
of	O
the	O
training	O
sequences	O
:	O
	
where	O
θ	O
is	O
the	O
model	O
parameter	O
,	O
N	O
is	O
the	O
number	O
of	O
training	O
sequences	O
,	O
and	O
T	O
n	O
is	O
the	O
length	O
of	O
the	O
n	O
-	O
th	O
sequence	O
.	O
	
A	O
symbol	O
at	O
time	O
t	O
of	O
sequence	O
n	O
is	O
denoted	O
by	O
x	O
n	O
t	O
,	O
and	O
x	O
n	O
<	O
t	O
denotes	O
all	O
previous	O
symbols	O
at	O
time	O
	
t.	O
	
We	O
evaluate	O
our	O
model	O
on	O
three	O
benchmark	O
text	O
corpora	O
:	O
(	O
1	O
)	O
Penn	O
Treebank	O
,	O
(	O
2	O
)	O
Text8	B-Material
and	O
(	O
3	O
)	O
Hutter	B-Material
Prize	I-Material
Wikipedia	I-Material
.	O
	
We	O
use	O
the	O
bits	B-Metric
-	I-Metric
per	I-Metric
-	I-Metric
character	I-Metric
(	O
BPC	B-Metric
)	O
,	O
E	O
[	O
−	O
log	O
2	O
p	O
(	O
x	O
t	O
+	O
1	O
|	O
x	O
≤t	O
)	O
]	O
,	O
as	O
the	O
evaluation	B-Metric
metric	I-Metric
.	O
	
Model	O
	
We	O
use	O
a	O
model	O
consisting	O
of	O
an	O
input	B-Method
embedding	I-Method
layer	I-Method
,	O
an	O
RNN	B-Method
module	I-Method
and	O
an	O
output	B-Method
module	I-Method
.	O
	
The	O
input	B-Method
embedding	I-Method
layer	I-Method
maps	O
each	O
input	O
symbol	O
into	O
128	O
-	O
dimensional	O
continuous	O
vector	O
without	O
using	O
any	O
non	O
-	O
linearity	O
.	O
	
The	O
RNN	B-Method
module	I-Method
is	O
the	O
HM	B-Method
-	I-Method
LSTM	I-Method
,	O
described	O
in	O
Section	O
3	O
,	O
with	O
three	O
layers	O
.	O
	
The	O
output	B-Method
module	I-Method
is	O
a	O
feedforward	B-Method
neural	I-Method
network	I-Method
with	O
two	O
layers	O
,	O
an	O
output	B-Method
embedding	I-Method
layer	I-Method
and	O
a	O
softmax	B-Method
layer	I-Method
.	O
	
Figure	O
2	O
(	O
right	O
)	O
shows	O
a	O
diagram	O
of	O
the	O
output	O
module	O
.	O
	
At	O
each	O
time	O
step	O
,	O
the	O
output	B-Method
embedding	I-Method
layer	I-Method
receives	O
the	O
hidden	O
states	O
of	O
the	O
three	O
RNN	B-Method
layers	I-Method
as	O
input	O
.	O
	
In	O
order	O
to	O
adaptively	O
control	O
the	O
importance	O
of	O
each	O
layer	O
at	O
each	O
time	O
step	O
,	O
we	O
also	O
introduce	O
three	O
scalar	O
gating	O
units	O
g	O
t	O
∈	O
R	O
to	O
each	O
of	O
the	O
layer	O
outputs	O
:	O
	
where	O
w	O
∈	O
R	O
L	O
=	O
1	O
dim	O
(	O
h	O
)	O
is	O
the	O
weight	O
parameter	O
.	O
	
The	O
output	O
embedding	O
h	O
e	O
t	O
is	O
computed	O
by	O
:	O
	
where	O
L	O
=	O
3	O
and	O
ReLU	O
(	O
x	O
)	O
=	O
	
max	O
(	O
0	O
,	O
x	O
)	O
	
[	O
reference	O
]	O
.	O
Finally	O
,	O
the	O
probability	O
distribution	O
for	O
the	O
next	O
target	O
character	O
is	O
computed	O
by	O
the	O
softmax	O
function	O
,	O
softmax	O
(	O
xj	O
)	O
=	O
,	O
where	O
each	O
output	O
class	O
is	O
a	O
character	O
.	O
	
section	O
:	O
Text8	B-Material
	
Model	O
BPC	B-Metric
td	O
-	O
LSTM	B-Method
1.63	O
HF	O
-	O
MRNN	O
1.54	O
	
MI	B-Method
-	I-Method
RNN	I-Method
1.52	I-Method
Skipping	I-Method
-	I-Method
RNN	I-Method
[	O
reference	O
]	O
Table	O
2	O
:	O
BPC	B-Metric
on	O
the	O
Text8	B-Material
test	I-Material
set	I-Material
.	O
	
Penn	O
Treebank	O
	
We	O
process	O
the	O
Penn	O
Treebank	O
dataset	O
[	O
reference	O
]	O
by	O
following	O
the	O
procedure	O
introduced	O
in	O
.	O
	
Each	O
update	O
is	O
done	O
by	O
using	O
a	O
mini	O
-	O
batch	O
of	O
64	O
examples	O
of	O
length	O
100	O
to	O
prevent	O
the	O
memory	O
overflow	O
problem	O
when	O
unfolding	O
the	O
RNN	B-Method
in	O
time	O
for	O
backpropagation	B-Method
.	O
	
The	O
last	O
hidden	O
state	O
of	O
a	O
sequence	O
is	O
used	O
to	O
initialize	O
the	O
hidden	O
state	O
of	O
the	O
next	O
sequence	O
to	O
approximate	O
the	O
full	B-Method
backpropagation	I-Method
.	O
	
We	O
train	O
the	O
model	O
using	O
Adam	B-Method
[	O
reference	O
]	O
with	O
an	O
initial	O
learning	B-Metric
rate	I-Metric
of	O
0.002	O
.	O
	
We	O
divide	O
the	O
learning	B-Metric
rate	I-Metric
by	O
a	O
factor	O
of	O
50	O
when	O
the	O
validation	O
negative	O
log	O
-	O
likelihood	O
stopped	O
decreasing	O
.	O
	
The	O
norm	O
of	O
the	O
gradient	O
is	O
clipped	O
with	O
a	O
threshold	O
of	O
1	O
	
[	O
reference	O
][	O
reference	O
]	O
.	O
	
We	O
also	O
apply	O
layer	B-Method
normalization	I-Method
[	O
reference	O
]	O
)	O
to	O
our	O
models	O
.	O
	
For	O
all	O
of	O
the	O
character	B-Task
-	I-Task
level	I-Task
language	I-Task
modelling	I-Task
experiments	O
,	O
we	O
apply	O
the	O
same	O
procedure	O
,	O
but	O
only	O
change	O
the	O
number	O
of	O
hidden	O
units	O
,	O
mini	O
-	O
batch	O
size	O
and	O
the	O
initial	O
learning	B-Metric
rate	I-Metric
.	O
	
For	O
the	O
Penn	O
Treebank	O
dataset	O
,	O
we	O
use	O
512	O
units	O
in	O
each	O
layer	O
of	O
the	O
HM	B-Method
-	I-Method
LSTM	I-Method
and	O
for	O
the	O
output	B-Method
embedding	I-Method
layer	I-Method
.	O
	
In	O
Table	O
1	O
(	O
left	O
)	O
,	O
we	O
compare	O
the	O
test	O
BPCs	B-Metric
of	O
four	O
variants	O
of	O
our	O
model	O
to	O
other	O
baseline	O
models	O
.	O
	
Note	O
that	O
the	O
HM	B-Method
-	I-Method
LSTM	I-Method
using	O
the	O
step	O
function	O
for	O
the	O
hard	O
boundary	O
decision	O
outperforms	O
the	O
others	O
using	O
either	O
sampling	O
or	O
soft	O
boundary	O
decision	O
(	O
i.e.	O
,	O
hard	O
sigmoid	O
)	O
.	O
	
The	O
test	O
BPC	B-Metric
is	O
further	O
improved	O
with	O
the	O
slope	B-Method
annealing	I-Method
trick	I-Method
,	O
which	O
reduces	O
the	O
bias	O
of	O
the	O
straight	B-Method
-	I-Method
through	I-Method
estimator	I-Method
.	O
	
We	O
increased	O
the	O
slope	O
a	O
with	O
the	O
following	O
schedule	O
a	O
=	O
min	O
(	O
5	O
,	O
1	O
+	O
0.04	O
·	O
N	O
epoch	O
)	O
,	O
where	O
N	O
epoch	O
is	O
the	O
maximum	O
number	O
of	O
epochs	O
.	O
	
The	O
HM	B-Method
-	I-Method
LSTM	I-Method
achieves	O
test	B-Metric
BPC	I-Metric
score	I-Metric
of	O
1.24	O
.	O
	
For	O
the	O
remaining	O
tasks	O
,	O
we	O
fixed	O
the	O
hard	O
boundary	O
decision	O
using	O
the	O
step	O
function	O
without	O
slope	B-Method
annealing	I-Method
due	O
to	O
the	O
difficulty	O
of	O
finding	O
a	O
good	O
annealing	B-Method
schedule	I-Method
on	O
large	O
-	O
scale	O
datasets	O
.	O
	
section	O
:	O
Text8	B-Material
	
The	O
Text8	B-Material
dataset	I-Material
(	O
Mahoney	O
,	O
2009	O
)	O
consists	O
of	O
100	O
M	O
characters	O
extracted	O
from	O
the	O
Wikipedia	O
corpus	O
.	O
	
Text8	B-Material
contains	O
only	O
alphabets	O
and	O
spaces	O
,	O
and	O
thus	O
we	O
have	O
total	O
27	O
symbols	O
.	O
	
In	O
order	O
to	O
compare	O
with	O
other	O
previous	O
works	O
,	O
we	O
follow	O
the	O
data	O
splits	O
used	O
in	O
.	O
	
We	O
use	O
1024	O
units	O
for	O
each	O
HM	B-Method
-	I-Method
LSTM	I-Method
layer	I-Method
and	O
2048	B-Method
units	I-Method
for	O
the	O
output	B-Method
embedding	I-Method
layer	I-Method
.	O
	
The	O
mini	O
-	O
batch	O
size	O
and	O
the	O
initial	O
learning	B-Metric
rate	I-Metric
are	O
set	O
to	O
128	O
and	O
0.001	O
,	O
respectively	O
.	O
	
The	O
results	O
are	O
shown	O
in	O
Table	O
2	O
.	O
	
The	O
HM	B-Method
-	I-Method
LSTM	I-Method
obtains	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
test	O
BPC	B-Metric
1.29	O
.	O
	
Hutter	B-Material
Prize	I-Material
Wikipedia	I-Material
	
The	O
Hutter	B-Material
Prize	I-Material
Wikipedia	I-Material
(	O
enwik8	B-Material
)	O
dataset	O
[	O
reference	O
]	O
contains	O
205	O
symbols	O
including	O
XML	O
markups	O
and	O
special	O
characters	O
.	O
	
We	O
follow	O
the	O
data	O
splits	O
used	O
in	O
[	O
reference	O
]	O
where	O
the	O
first	O
90	O
M	O
characters	O
are	O
used	O
to	O
train	O
the	O
model	O
,	O
the	O
next	O
5	O
M	O
characters	O
for	O
validation	O
,	O
and	O
the	O
remainders	O
for	O
the	O
test	O
set	O
.	O
	
We	O
use	O
the	O
same	O
model	O
size	O
,	O
mini	O
-	O
batch	O
size	O
and	O
the	O
initial	O
learning	B-Metric
rate	I-Metric
as	O
in	O
the	O
Text8	B-Material
.	O
	
In	O
Table	O
1	O
(	O
right	O
)	O
,	O
we	O
show	O
the	O
HM	B-Method
-	I-Method
LSTM	I-Method
achieving	O
the	O
test	O
BPC	B-Metric
1.32	O
,	O
which	O
is	O
a	O
tie	O
with	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
result	O
among	O
the	O
neural	B-Method
models	I-Method
.	O
	
Although	O
the	O
neural	B-Method
models	I-Method
,	O
show	O
remarkable	O
performances	O
,	O
their	O
compression	B-Task
performance	O
is	O
still	O
behind	O
the	O
best	O
models	O
such	O
as	O
PAQ8hp12	B-Method
[	O
reference	O
]	O
and	O
decomp8	B-Method
[	O
reference	O
]	O
.	O
	
Visualizing	O
Learned	O
Hierarchical	O
Multiscale	O
Structure	O
	
In	O
Figure	O
3	O
and	O
4	O
,	O
we	O
visualize	O
the	O
boundaries	O
detected	O
by	O
the	O
boundary	B-Method
detectors	I-Method
of	O
the	O
HM	B-Method
-	I-Method
LSTM	I-Method
while	O
reading	O
a	O
character	O
sequence	O
of	O
total	O
length	O
270	O
taken	O
from	O
the	O
validation	O
set	O
of	O
either	O
the	O
Penn	O
Treebank	O
or	O
Hutter	B-Material
Prize	I-Material
Wikipedia	I-Material
dataset	I-Material
.	O
	
Due	O
to	O
the	O
page	O
width	O
limit	O
,	O
the	O
figure	O
contains	O
the	O
sequence	O
partitioned	O
into	O
three	O
segments	O
of	O
length	O
90	O
.	O
	
The	O
white	O
blocks	O
indicate	O
boundaries	O
z	O
t	O
=	O
1	O
while	O
the	O
black	O
blocks	O
indicate	O
the	O
non	O
-	O
boundaries	O
z	O
t	O
=	O
0	O
.	O
	
Interestingly	O
in	O
both	O
figures	O
,	O
we	O
can	O
observe	O
that	O
the	O
boundary	O
detector	O
of	O
the	O
first	O
layer	O
,	O
z	O
1	O
,	O
tends	O
to	O
be	O
turned	O
on	O
when	O
it	O
sees	O
a	O
space	O
or	O
after	O
it	O
sees	O
a	O
space	O
,	O
which	O
is	O
a	O
reasonable	O
breakpoint	O
to	O
separate	O
between	O
words	O
.	O
	
This	O
is	O
somewhat	O
surprising	O
because	O
the	O
model	O
self	O
-	O
organizes	O
this	O
structure	O
without	O
any	O
explicit	O
boundary	O
information	O
.	O
	
In	O
Figure	O
3	O
,	O
we	O
observe	O
that	O
the	O
z	O
1	O
tends	O
to	O
detect	O
the	O
boundaries	O
of	O
the	O
words	O
but	O
also	O
fires	O
within	O
the	O
words	O
,	O
where	O
the	O
z	O
2	O
tends	O
to	O
fire	O
when	O
it	O
sees	O
either	O
an	O
end	O
of	O
a	O
word	O
or	O
2	O
,	O
	
3	B-Method
-	I-Method
grams	I-Method
.	O
	
In	O
Figure	O
4	O
,	O
we	O
also	O
see	O
flushing	O
in	O
the	O
middle	O
of	O
a	O
word	O
,	O
e.g.	O
,	O
"	O
tele	O
-	O
FLUSH	O
-	O
phone	O
"	O
.	O
	
Note	O
that	O
"	O
tele	O
"	O
is	O
a	O
prefix	O
after	O
which	O
a	O
various	O
number	O
of	O
postfixes	O
can	O
follow	O
.	O
	
From	O
these	O
,	O
it	O
seems	O
that	O
the	O
model	O
uses	O
to	O
some	O
extent	O
the	O
concept	O
of	O
surprise	O
to	O
learn	O
the	O
boundary	O
.	O
	
Although	O
interpretation	O
of	O
the	O
second	O
layer	O
boundaries	O
is	O
not	O
as	O
apparent	O
as	O
the	O
first	O
layer	O
boundaries	O
,	O
it	O
seems	O
to	O
segment	O
at	O
reasonable	O
semantic	O
/	O
syntactic	O
boundaries	O
,	O
	
e.g.	O
,	O
"	O
consumers	O
may	O
"	O
-	O
"want	O
to	O
move	O
their	O
telephones	O
a	O
"	O
-	O
"little	O
closer	O
to	O
the	O
tv	O
set	O
<	O
unk	O
>	O
"	O
,	O
and	O
so	O
on	O
.	O
	
Another	O
remarkable	O
point	O
is	O
the	O
fact	O
that	O
we	O
do	O
not	O
pose	O
any	O
constraint	O
on	O
the	O
number	O
of	O
boundaries	O
that	O
the	O
model	O
can	O
fire	O
up	O
.	O
	
The	O
model	O
,	O
however	O
,	O
learns	O
that	O
it	O
is	O
more	O
beneficial	O
to	O
delay	O
the	O
information	O
ejection	O
to	O
some	O
extent	O
.	O
	
This	O
is	O
somewhat	O
counterintuitive	O
because	O
it	O
might	O
look	O
more	O
beneficial	O
to	O
feed	O
the	O
fresh	O
update	O
to	O
the	O
upper	O
layers	O
at	O
every	O
time	O
step	O
without	O
any	O
delay	O
.	O
	
We	O
conjecture	O
the	O
reason	O
that	O
the	O
model	O
works	O
in	O
this	O
way	O
is	O
due	O
to	O
the	O
FLUSH	B-Method
operation	I-Method
that	O
poses	O
an	O
implicit	O
constraint	O
on	O
the	O
frequency	B-Task
of	I-Task
boundary	I-Task
detection	I-Task
,	O
because	O
it	O
contains	O
both	O
a	O
reward	O
(	O
feeding	O
fresh	O
information	O
to	O
upper	O
layers	O
)	O
and	O
a	O
penalty	O
(	O
erasing	O
accumulated	O
information	O
)	O
.	O
	
The	O
model	O
finds	O
an	O
optimal	O
balance	O
between	O
the	O
reward	O
and	O
the	O
penalty	O
.	O
	
To	O
understand	O
the	O
update	B-Method
mechanism	I-Method
more	O
intuitively	O
,	O
in	O
Figure	O
4	O
,	O
we	O
also	O
depict	O
the	O
heatmap	O
of	O
the	O
2	O
-	O
norm	O
of	O
the	O
hidden	O
states	O
along	O
with	O
the	O
states	O
of	O
the	O
boundary	B-Method
detectors	I-Method
.	O
	
As	O
we	O
expect	O
,	O
we	O
can	O
see	O
that	O
there	O
is	O
no	O
change	O
in	O
the	O
norm	O
value	O
within	O
segments	O
due	O
to	O
the	O
COPY	B-Method
operation	I-Method
.	O
	
Also	O
,	O
the	O
color	O
of	O
h	O
1	O
changes	O
quickly	O
(	O
at	O
every	O
time	O
step	O
)	O
because	O
there	O
is	O
no	O
COPY	O
operation	O
in	O
the	O
first	O
layer	O
.	O
	
The	O
color	O
of	O
h	O
2	O
changes	O
less	O
frequently	O
based	O
on	O
the	O
states	O
of	O
z	O
1	O
t	O
and	O
z	O
2	O
t−1	O
.	O
	
The	O
color	O
of	O
h	O
3	O
changes	O
even	O
slowly	O
,	O
i.e.	O
,	O
only	O
when	O
z	O
2	O
t	O
=	O
1	O
.	O
	
A	O
notable	O
advantage	O
of	O
the	O
proposed	O
architecture	O
is	O
that	O
the	O
internal	O
process	O
of	O
the	O
RNN	B-Method
becomes	O
more	O
interpretable	O
.	O
	
For	O
example	O
,	O
we	O
can	O
substitute	O
the	O
states	O
of	O
z	O
1	O
t	O
and	O
z	O
2	O
t−1	O
into	O
Eq	O
.	O
2	O
and	O
infer	O
which	O
operation	O
among	O
the	O
UPDATE	O
,	O
COPY	O
and	O
FLUSH	O
was	O
applied	O
to	O
the	O
second	O
layer	O
at	O
time	O
step	O
	
t.	O
	
We	O
can	O
also	O
inspect	O
the	O
update	O
frequencies	O
of	O
the	O
layers	O
simply	O
by	O
counting	O
how	O
many	O
UPDATE	O
and	O
FLUSH	O
operations	O
were	O
made	O
in	O
each	O
layer	O
.	O
	
For	O
example	O
in	O
Figure	O
4	O
,	O
we	O
see	O
that	O
the	O
first	O
layer	O
updates	O
at	O
every	O
time	O
step	O
(	O
which	O
is	O
270	O
UPDATE	O
operations	O
)	O
	
,	O
the	O
second	O
layer	O
updates	O
56	O
times	O
,	O
Figure	O
5	O
:	O
	
The	O
visualization	O
by	O
segments	O
based	O
on	O
either	O
the	O
given	O
pen	O
-	O
tip	O
location	O
or	O
states	O
of	O
the	O
z	O
2	O
.	O
	
and	O
only	O
9	O
updates	O
has	O
made	O
in	O
the	O
third	O
layer	O
.	O
	
Note	O
that	O
,	O
by	O
design	O
,	O
the	O
first	O
layer	O
performs	O
UPDATE	O
operation	O
at	O
every	O
time	O
step	O
and	O
then	O
the	O
number	O
of	O
UPDATE	O
operations	O
decreases	O
as	O
the	O
layer	O
level	O
increases	O
.	O
	
In	O
this	O
example	O
,	O
the	O
total	O
number	O
of	O
updates	O
is	O
335	O
for	O
the	O
HM	B-Method
-	I-Method
LSTM	I-Method
which	O
is	O
60	O
%	O
of	O
reduction	O
from	O
the	O
810	O
updates	O
of	O
the	O
standard	O
RNN	B-Method
architecture	I-Method
.	O
	
section	O
:	O
HANDWRITING	B-Task
SEQUENCE	I-Task
GENERATION	I-Task
	
We	O
extend	O
the	O
evaluation	O
of	O
the	O
HM	B-Method
-	I-Method
LSTM	I-Method
to	O
a	O
real	B-Task
-	I-Task
valued	I-Task
sequence	I-Task
modelling	I-Task
task	I-Task
using	O
IAMOnDB	O
[	O
reference	O
]	O
dataset	O
.	O
	
The	O
IAM	O
-	O
OnDB	O
dataset	O
consists	O
of	O
12	O
,	O
179	O
handwriting	O
examples	O
,	O
each	O
of	O
which	O
is	O
a	O
sequence	O
of	O
(	O
x	O
,	O
y	O
)	O
coordinate	O
and	O
a	O
binary	O
indicator	O
p	O
for	O
pen	O
-	O
tip	O
location	O
,	O
giving	O
us	O
(	O
x	O
1:T	O
n	O
,	O
y	O
1:T	O
n	O
,	O
p	O
1:T	O
n	O
)	O
,	O
where	O
n	O
is	O
an	O
index	O
of	O
a	O
sequence	O
.	O
	
At	O
each	O
time	O
step	O
,	O
the	O
model	O
receives	O
(	O
x	O
t	O
,	O
y	O
t	O
,	O
p	O
t	O
)	O
,	O
and	O
the	O
goal	O
is	O
to	O
predict	O
(	O
x	O
t	O
+	O
1	O
,	O
y	O
t	O
+	O
1	O
,	O
p	O
t	O
+	O
1	O
)	O
.	O
	
The	O
pen	O
-	O
up	O
(	O
p	O
t	O
=	O
1	O
)	O
indicates	O
an	O
end	O
of	O
a	O
stroke	O
,	O
and	O
the	O
pen	O
-	O
down	O
(	O
p	O
t	O
=	O
0	O
)	O
indicates	O
that	O
a	O
stroke	O
is	O
in	O
progress	O
.	O
	
There	O
is	O
usually	O
a	O
large	O
shift	O
in	O
the	O
(	O
x	O
,	O
y	O
)	O
coordinate	O
to	O
start	O
a	O
new	O
stroke	O
after	O
the	O
pen	O
-	O
up	O
happens	O
.	O
	
We	O
remove	O
all	O
sequences	O
whose	O
length	O
is	O
shorter	O
than	O
300	O
.	O
	
This	O
leaves	O
us	O
10	O
,	O
465	O
sequences	O
for	O
training	O
,	O
581	O
for	O
validation	B-Task
,	O
582	O
for	O
test	O
.	O
	
The	O
average	O
length	O
of	O
the	O
sequences	O
is	O
648	O
.	O
	
We	O
normalize	O
the	O
range	O
of	O
the	O
(	O
x	O
,	O
y	O
)	O
coordinates	O
separately	O
with	O
the	O
mean	O
and	O
standard	O
deviation	O
obtained	O
from	O
the	O
training	O
set	O
.	O
	
We	O
use	O
the	O
mini	O
-	O
batch	O
size	O
of	O
32	O
,	O
and	O
the	O
initial	O
learning	B-Metric
rate	I-Metric
is	O
set	O
to	O
0.0003	O
.	O
	
We	O
use	O
the	O
same	O
model	B-Method
architecture	I-Method
as	O
used	O
in	O
the	O
character	B-Method
-	I-Method
level	I-Method
language	I-Method
model	I-Method
,	O
except	O
that	O
the	O
output	B-Method
layer	I-Method
is	O
modified	O
to	O
predict	O
real	O
-	O
valued	O
outputs	O
.	O
	
We	O
use	O
the	O
mixture	B-Method
density	I-Method
network	I-Method
as	O
the	O
output	O
layer	O
following	O
[	O
reference	O
]	O
,	O
and	O
use	O
400	O
units	O
for	O
each	O
HM	B-Method
-	I-Method
LSTM	I-Method
layer	I-Method
and	O
for	O
the	O
output	B-Method
embedding	I-Method
layer	I-Method
.	O
	
In	O
Table	O
3	O
,	O
we	O
compare	O
the	O
log	B-Metric
-	I-Metric
likelihood	I-Metric
averaged	O
over	O
the	O
test	O
sequences	O
of	O
the	O
IAM	O
-	O
OnDB	O
dataset	O
.	O
	
We	O
observe	O
that	O
the	O
HM	B-Method
-	I-Method
LSTM	I-Method
outperforms	O
the	O
standard	O
LSTM	B-Method
.	O
	
The	O
slope	B-Method
annealing	I-Method
trick	I-Method
further	O
improves	O
the	O
test	B-Metric
log	I-Metric
-	I-Metric
likelihood	I-Metric
of	O
the	O
HM	B-Method
-	I-Method
LSTM	I-Method
into	O
1167	O
in	O
our	O
setting	O
.	O
	
In	O
this	O
experiment	O
,	O
we	O
increased	O
the	O
slope	O
a	O
with	O
the	O
following	O
schedule	O
a	O
=	O
min	O
(	O
3	O
,	O
1	O
+	O
0.004	O
	
·	O
N	O
epoch	O
)	O
.	O
	
In	O
Figure	O
5	O
,	O
we	O
let	O
the	O
HM	B-Method
-	I-Method
LSTM	I-Method
to	O
read	O
a	O
randomly	O
picked	O
validation	O
sequence	O
and	O
present	O
the	O
visualization	O
of	O
handwriting	O
examples	O
by	O
segments	O
based	O
on	O
either	O
the	O
states	O
of	O
z	O
2	O
or	O
the	O
states	O
of	O
pen	O
-	O
tip	O
location	O
3	O
.	O
	
section	O
:	O
CONCLUSION	O
	
In	O
this	O
paper	O
,	O
we	O
proposed	O
the	O
HM	B-Method
-	I-Method
RNN	I-Method
that	O
can	O
capture	O
the	O
latent	O
hierarchical	O
structure	O
of	O
the	O
sequences	O
.	O
	
We	O
introduced	O
three	O
types	O
of	O
operations	O
to	O
the	O
RNN	B-Method
,	O
which	O
are	O
the	O
COPY	O
,	O
UPDATE	O
and	O
FLUSH	O
operations	O
.	O
	
In	O
order	O
to	O
implement	O
these	O
operations	O
,	O
we	O
introduced	O
a	O
set	O
of	O
binary	O
variables	O
and	O
a	O
novel	O
update	B-Method
rule	I-Method
that	O
is	O
dependent	O
on	O
the	O
states	O
of	O
these	O
binary	O
variables	O
.	O
	
Each	O
binary	O
variable	O
is	O
learned	O
to	O
find	O
segments	O
at	O
its	O
level	O
,	O
therefore	O
,	O
we	O
call	O
this	O
binary	O
variable	O
,	O
a	O
boundary	B-Method
detector	I-Method
.	O
	
On	O
the	O
character	B-Task
-	I-Task
level	I-Task
language	I-Task
modelling	I-Task
,	O
the	O
HM	B-Method
-	I-Method
LSTM	I-Method
achieved	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
result	O
on	O
the	O
Text8	B-Material
dataset	I-Material
and	O
comparable	O
results	O
to	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
the	O
Penn	O
Treebank	O
and	O
Hutter	B-Material
Prize	I-Material
Wikipedia	I-Material
datasets	I-Material
.	O
	
Also	O
,	O
the	O
HM	B-Method
-	I-Method
LSTM	I-Method
outperformed	O
the	O
standard	O
LSTM	B-Method
on	O
the	O
handwriting	B-Task
sequence	I-Task
generation	I-Task
.	O
	
Our	O
results	O
and	O
analysis	O
suggest	O
that	O
the	O
proposed	O
HM	B-Method
-	I-Method
RNN	I-Method
can	O
discover	O
the	O
latent	O
hierarchical	O
structure	O
of	O
the	O
sequences	O
and	O
can	O
learn	O
efficient	O
hierarchical	B-Method
multiscale	I-Method
representation	I-Method
that	O
leads	O
to	O
better	O
generalization	B-Task
performance	O
.	O
	
section	O
:	O
	
section	O
:	O
ACKNOWLEDGMENTS	O
	
The	O
authors	O
would	O
like	O
to	O
thank	O
Alex	O
Graves	O
,	O
Tom	O
Schaul	O
and	O
Hado	O
van	O
Hasselt	O
for	O
their	O
fruitful	O
comments	O
and	O
discussion	O
.	O
	
We	O
acknowledge	O
the	O
support	O
of	O
the	O
following	O
agencies	O
for	O
research	O
funding	O
and	O
computing	O
support	O
:	O
Ubisoft	O
,	O
Samsung	O
,	O
IBM	O
,	O
Facebook	O
,	O
Google	O
,	O
Microsoft	O
,	O
NSERC	O
,	O
Calcul	O
Québec	O
,	O
Compute	O
Canada	O
,	O
the	O
Canada	O
Research	O
Chairs	O
and	O
CIFAR	O
.	O
	
The	O
authors	O
thank	O
the	O
developers	O
of	O
Theano	O
[	O
reference	O
]	O
.	O
JC	O
would	O
like	O
to	O
thank	O
Arnaud	O
Bergenon	O
and	O
Frédéric	O
Bastien	O
for	O
their	O
technical	O
support	O
.	O
	
JC	O
would	O
also	O
like	O
to	O
thank	O
Guillaume	O
Alain	O
,	O
Kyle	O
Kastner	O
and	O
David	O
Ha	O
for	O
providing	O
us	O
useful	O
pieces	O
of	O
code	O
.	O
	
section	O
:	O
	
Supervised	B-Method
learning	I-Method
on	O
molecules	O
has	O
incredible	O
potential	O
to	O
be	O
useful	O
in	O
chemistry	B-Task
,	O
drug	B-Task
discovery	I-Task
,	O
and	O
materials	B-Task
science	I-Task
.	O
	
Luckily	O
,	O
several	O
promising	O
and	O
closely	O
related	O
neural	B-Method
network	I-Method
models	I-Method
invariant	O
to	O
molecular	O
symmetries	O
have	O
already	O
been	O
described	O
in	O
the	O
literature	O
.	O
	
These	O
models	O
learn	O
a	O
message	B-Method
passing	I-Method
algorithm	I-Method
and	O
aggregation	B-Method
procedure	I-Method
to	O
compute	O
a	O
function	O
of	O
their	O
entire	O
input	O
graph	O
.	O
	
At	O
this	O
point	O
,	O
the	O
next	O
step	O
is	O
to	O
find	O
a	O
particularly	O
effective	O
variant	O
of	O
this	O
general	O
approach	O
and	O
apply	O
it	O
to	O
chemical	B-Task
prediction	I-Task
benchmarks	I-Task
until	O
we	O
either	O
solve	O
them	O
or	O
reach	O
the	O
limits	O
of	O
the	O
approach	O
.	O
	
In	O
this	O
paper	O
,	O
we	O
reformulate	O
existing	O
models	O
into	O
a	O
single	O
common	O
framework	O
we	O
call	O
Message	B-Method
Passing	I-Method
Neural	I-Method
Networks	I-Method
(	O
MPNNs	B-Method
)	O
and	O
explore	O
additional	O
novel	O
variations	O
within	O
this	O
framework	O
.	O
	
Using	O
MPNNs	B-Method
we	O
demonstrate	O
state	O
of	O
the	O
art	O
results	O
on	O
an	O
important	O
molecular	B-Task
property	I-Task
prediction	I-Task
benchmark	I-Task
;	O
these	O
results	O
are	O
strong	O
enough	O
that	O
we	O
believe	O
future	O
work	O
should	O
focus	O
on	O
datasets	O
with	O
larger	O
molecules	O
or	O
more	O
accurate	O
ground	O
truth	O
labels	O
.	O
	
NeuralMessagePassingforQuantumChemistry	O
	
section	O
:	O
Introduction	O
	
The	O
past	O
decade	O
has	O
seen	O
remarkable	O
success	O
in	O
the	O
use	O
of	O
deep	B-Method
neural	I-Method
networks	I-Method
to	O
understand	O
and	O
translate	O
natural	O
language	O
,	O
generate	O
and	O
decode	O
complex	O
audio	O
signals	O
,	O
and	O
infer	O
features	O
from	O
real	O
-	O
world	O
images	O
and	O
videos	O
.	O
	
Although	O
chemists	O
have	O
applied	O
machine	B-Method
learning	I-Method
to	O
many	O
problems	O
over	O
the	O
years	O
,	O
predicting	O
the	O
properties	B-Task
of	I-Task
molecules	I-Task
and	I-Task
materials	I-Task
using	O
machine	B-Method
learning	I-Method
(	O
and	O
especially	O
deep	B-Method
learning	I-Method
)	O
is	O
still	O
in	O
its	O
infancy	O
.	O
	
To	O
date	O
,	O
most	O
research	O
applying	O
machine	B-Method
learning	I-Method
to	O
chemistry	B-Task
tasks	I-Task
has	O
revolved	O
around	O
feature	B-Method
engineering	I-Method
.	O
	
While	O
neural	B-Method
networks	I-Method
have	O
been	O
applied	O
in	O
a	O
variety	O
of	O
situations	O
,	O
they	O
have	O
yet	O
to	O
become	O
widely	O
adopted	O
.	O
	
This	O
situation	O
is	O
reminiscent	O
of	O
the	O
state	O
of	O
image	B-Method
models	I-Method
before	O
the	O
broad	O
adoption	O
of	O
convolutional	B-Method
neural	I-Method
networks	I-Method
and	O
is	O
due	O
,	O
in	O
part	O
,	O
to	O
a	O
dearth	O
of	O
empirical	O
evidence	O
that	O
neural	B-Method
architectures	I-Method
with	O
the	O
appropriate	O
inductive	O
bias	O
can	O
be	O
successful	O
in	O
this	O
domain	O
.	O
	
Recently	O
,	O
large	B-Task
scale	I-Task
quantum	I-Task
chemistry	I-Task
calculation	I-Task
and	O
molecular	B-Method
dynamics	I-Method
simulations	I-Method
coupled	O
with	O
advances	O
in	O
high	O
throughput	O
experiments	O
have	O
begun	O
to	O
generate	O
data	O
at	O
an	O
unprecedented	O
rate	O
.	O
	
Most	O
classical	O
techniques	O
do	O
not	O
make	O
effective	O
use	O
of	O
the	O
larger	O
amounts	O
of	O
data	O
that	O
are	O
now	O
available	O
.	O
	
The	O
time	O
is	O
ripe	O
to	O
apply	O
more	O
powerful	O
and	O
flexible	O
machine	B-Method
learning	I-Method
methods	I-Method
to	O
these	O
problems	O
,	O
assuming	O
we	O
can	O
find	O
models	O
with	O
suitable	O
inductive	O
biases	O
.	O
	
The	O
symmetries	O
of	O
atomic	B-Method
systems	I-Method
suggest	O
neural	B-Method
networks	I-Method
that	O
operate	O
on	O
graph	O
structured	O
data	O
and	O
are	O
invariant	O
to	O
graph	O
isomorphism	O
might	O
also	O
be	O
appropriate	O
for	O
molecules	O
.	O
	
Sufficiently	O
successful	O
models	O
could	O
someday	O
help	O
automate	O
challenging	O
chemical	B-Task
search	I-Task
problems	I-Task
in	O
drug	B-Task
discovery	I-Task
or	O
materials	B-Task
science	I-Task
.	O
	
In	O
this	O
paper	O
,	O
our	O
goal	O
is	O
to	O
demonstrate	O
effective	O
machine	B-Method
learning	I-Method
models	I-Method
for	O
chemical	B-Task
prediction	I-Task
problems	I-Task
that	O
are	O
capable	O
of	O
learning	O
their	O
own	O
features	O
from	O
molecular	O
graphs	O
directly	O
and	O
are	O
invariant	O
to	O
graph	O
isomorphism	O
.	O
	
To	O
that	O
end	O
,	O
we	O
describe	O
a	O
general	O
framework	O
for	O
supervised	B-Task
learning	I-Task
on	I-Task
graphs	I-Task
called	O
Message	B-Method
Passing	I-Method
Neural	I-Method
Networks	I-Method
(	O
MPNNs	B-Method
)	O
that	O
simply	O
abstracts	O
the	O
commonalities	O
between	O
several	O
of	O
the	O
most	O
promising	O
existing	O
neural	B-Method
models	I-Method
for	O
graph	O
structured	O
data	O
,	O
in	O
order	O
to	O
make	O
it	O
easier	O
to	O
understand	O
the	O
relationships	O
between	O
them	O
and	O
come	O
up	O
with	O
novel	O
variations	O
.	O
	
Given	O
how	O
many	O
researchers	O
have	O
published	O
models	O
that	O
fit	O
into	O
the	O
MPNN	B-Method
framework	I-Method
,	O
we	O
believe	O
that	O
the	O
community	O
should	O
push	O
this	O
general	O
approach	O
as	O
far	O
as	O
possible	O
on	O
practically	O
important	O
graph	B-Task
problems	I-Task
and	O
only	O
suggest	O
new	O
variations	O
that	O
are	O
well	O
motivated	O
by	O
applications	O
,	O
such	O
as	O
the	O
application	O
we	O
consider	O
here	O
:	O
predicting	O
the	O
quantum	B-Task
mechanical	I-Task
properties	I-Task
of	I-Task
small	I-Task
organic	I-Task
molecules	I-Task
(	O
see	O
task	O
schematic	O
in	O
figure	O
[	O
reference	O
]	O
)	O
.	O
	
In	O
general	O
,	O
the	O
search	O
for	O
practically	O
effective	O
machine	B-Method
learning	I-Method
(	I-Method
ML	I-Method
)	I-Method
models	I-Method
in	O
a	O
given	O
domain	O
proceeds	O
through	O
a	O
sequence	O
of	O
increasingly	O
realistic	O
and	O
interesting	O
benchmarks	O
.	O
	
Here	O
we	O
focus	O
on	O
the	O
QM9	B-Material
dataset	I-Material
as	O
such	O
a	O
benchmark	O
.	O
	
QM9	B-Material
consists	O
of	O
130k	O
molecules	O
with	O
13	O
properties	O
for	O
each	O
molecule	O
which	O
are	O
approximated	O
by	O
an	O
expensive	O
quantum	B-Method
mechanical	I-Method
simulation	I-Method
method	I-Method
(	O
DFT	B-Method
)	O
,	O
to	O
yield	O
13	O
corresponding	O
regression	B-Task
tasks	I-Task
.	O
	
These	O
tasks	O
are	O
plausibly	O
representative	O
of	O
many	O
important	O
chemical	B-Task
prediction	I-Task
problems	I-Task
and	O
are	O
(	O
currently	O
)	O
difficult	O
for	O
many	O
existing	O
methods	O
.	O
	
Additionally	O
,	O
QM9	B-Material
also	O
includes	O
complete	O
spatial	O
information	O
for	O
the	O
single	O
low	O
energy	O
conformation	O
of	O
the	O
atoms	O
in	O
the	O
molecule	O
that	O
was	O
used	O
in	O
calculating	O
the	O
chemical	O
properties	O
.	O
	
QM9	B-Material
therefore	O
lets	O
us	O
consider	O
both	O
the	O
setting	O
where	O
the	O
complete	O
molecular	O
geometry	O
is	O
known	O
(	O
atomic	O
distances	O
,	O
bond	O
angles	O
,	O
etc	O
.	O
)	O
and	O
the	O
setting	O
where	O
we	O
need	O
to	O
compute	O
properties	O
that	O
might	O
still	O
be	O
defined	O
in	O
terms	O
of	O
the	O
spatial	O
positions	O
of	O
atoms	O
,	O
but	O
where	O
only	O
the	O
atom	O
and	O
bond	O
information	O
(	O
i.e.	O
graph	O
)	O
is	O
available	O
as	O
input	O
.	O
	
In	O
the	O
latter	O
case	O
,	O
the	O
model	O
must	O
implicitly	O
fit	O
something	O
about	O
the	O
computation	O
used	O
to	O
determine	O
a	O
low	O
energy	O
3D	O
conformation	O
and	O
hopefully	O
would	O
still	O
work	O
on	O
problems	O
where	O
it	O
is	O
not	O
clear	O
how	O
to	O
compute	O
a	O
reasonable	O
3D	O
conformation	O
.	O
	
When	O
measuring	O
the	O
performance	O
of	O
our	O
models	O
on	O
QM9	B-Material
,	O
there	O
are	O
two	O
important	O
benchmark	B-Metric
error	I-Metric
levels	I-Metric
.	O
	
The	O
first	O
is	O
the	O
estimated	O
average	B-Metric
error	I-Metric
of	O
the	O
DFT	B-Method
approximation	I-Method
to	O
nature	O
,	O
which	O
we	O
refer	O
to	O
as	O
“	O
DFT	B-Metric
error	I-Metric
.	O
	
”	O
	
The	O
second	O
,	O
known	O
as	O
“	O
chemical	B-Metric
accuracy	I-Metric
,	O
”	O
is	O
a	O
target	B-Metric
error	I-Metric
that	O
has	O
been	O
established	O
by	O
the	O
chemistry	O
community	O
.	O
	
Estimates	O
of	O
DFT	B-Metric
error	I-Metric
and	O
chemical	B-Metric
accuracy	I-Metric
are	O
provided	O
for	O
each	O
of	O
the	O
13	O
targets	O
in	O
.	O
	
One	O
important	O
goal	O
of	O
this	O
line	O
of	O
research	O
is	O
to	O
produce	O
a	O
model	O
which	O
can	O
achieve	O
chemical	B-Metric
accuracy	I-Metric
with	O
respect	O
to	O
the	O
true	O
targets	O
as	O
measured	O
by	O
an	O
extremely	O
precise	O
experiment	O
.	O
	
The	O
dataset	O
containing	O
the	O
true	O
targets	O
on	O
all	O
134k	O
molecules	O
does	O
not	O
currently	O
exist	O
.	O
	
However	O
,	O
the	O
ability	O
to	O
fit	O
the	O
DFT	B-Method
approximation	I-Method
to	O
within	O
chemical	B-Metric
accuracy	I-Metric
would	O
be	O
an	O
encouraging	O
step	O
in	O
this	O
direction	O
.	O
	
For	O
all	O
13	O
targets	O
,	O
achieving	O
chemical	B-Metric
accuracy	I-Metric
is	O
at	O
least	O
as	O
hard	O
as	O
achieving	O
DFT	B-Metric
error	I-Metric
.	O
	
In	O
the	O
rest	O
of	O
this	O
paper	O
when	O
we	O
talk	O
about	O
chemical	B-Metric
accuracy	I-Metric
we	O
generally	O
mean	O
with	O
respect	O
to	O
our	O
available	O
ground	O
truth	O
labels	O
.	O
	
In	O
this	O
paper	O
,	O
by	O
exploring	O
novel	O
variations	O
of	O
models	O
in	O
the	O
MPNN	B-Method
family	I-Method
,	O
we	O
are	O
able	O
to	O
both	O
achieve	O
a	O
new	O
state	O
of	O
the	O
art	O
on	O
the	O
QM9	B-Material
dataset	I-Material
and	O
to	O
predict	O
the	O
DFT	B-Task
calculation	I-Task
to	O
within	O
chemical	B-Metric
accuracy	I-Metric
on	O
all	O
but	O
two	O
targets	O
.	O
	
In	O
particular	O
,	O
we	O
provide	O
the	O
following	O
key	O
contributions	O
:	O
We	O
develop	O
an	O
MPNN	B-Method
which	O
achieves	O
state	O
of	O
the	O
art	O
results	O
on	O
all	O
13	O
targets	O
and	O
predicts	O
DFT	B-Task
to	O
within	O
chemical	B-Metric
accuracy	I-Metric
on	O
11	O
out	O
of	O
13	O
targets	O
.	O
	
We	O
develop	O
several	O
different	O
MPNNs	B-Method
which	O
predict	O
DFT	B-Method
to	O
within	O
chemical	B-Metric
accuracy	I-Metric
on	O
5	O
out	O
of	O
13	O
targets	O
while	O
operating	O
on	O
the	O
topology	O
of	O
the	O
molecule	O
alone	O
(	O
with	O
no	O
spatial	O
information	O
as	O
input	O
)	O
.	O
	
We	O
develop	O
a	O
general	O
method	O
to	O
train	O
MPNNs	B-Method
with	O
larger	O
node	B-Method
representations	I-Method
without	O
a	O
corresponding	O
increase	O
in	O
computation	B-Metric
time	I-Metric
or	O
memory	B-Metric
,	O
yielding	O
a	O
substantial	O
savings	O
over	O
previous	O
MPNNs	B-Method
for	O
high	B-Method
dimensional	I-Method
node	I-Method
representations	I-Method
.	O
	
We	O
believe	O
our	O
work	O
is	O
an	O
important	O
step	O
towards	O
making	O
well	O
-	O
designed	O
MPNNâs	B-Method
the	O
default	O
for	O
supervised	B-Task
learning	I-Task
on	O
modestly	B-Task
sized	I-Task
molecules	I-Task
.	O
	
In	O
order	O
for	O
this	O
to	O
happen	O
,	O
researchers	O
need	O
to	O
perform	O
careful	O
empirical	O
studies	O
to	O
find	O
the	O
proper	O
way	O
to	O
use	O
these	O
types	O
of	O
models	O
and	O
to	O
make	O
any	O
necessary	O
improvements	O
to	O
them	O
,	O
it	O
is	O
not	O
sufficient	O
for	O
these	O
models	O
to	O
have	O
been	O
described	O
in	O
the	O
literature	O
if	O
there	O
is	O
only	O
limited	O
accompanying	O
empirical	O
work	O
in	O
the	O
chemical	O
domain	O
.	O
	
Indeed	O
convolutional	B-Method
neural	I-Method
networks	I-Method
existed	O
for	O
decades	O
before	O
careful	O
empirical	O
work	O
applying	O
them	O
to	O
image	B-Task
classification	I-Task
helped	O
them	O
displace	O
SVMs	B-Method
on	O
top	O
of	O
hand	O
-	O
engineered	O
features	O
for	O
a	O
host	O
of	O
computer	B-Task
vision	I-Task
problems	I-Task
.	O
	
section	O
:	O
Message	B-Method
Passing	I-Method
Neural	I-Method
Networks	I-Method
	
There	O
are	O
at	O
least	O
eight	O
notable	O
examples	O
of	O
models	O
from	O
the	O
literature	O
that	O
we	O
can	O
describe	O
using	O
our	O
Message	B-Method
Passing	I-Method
Neural	I-Method
Networks	I-Method
(	O
MPNN	B-Method
)	I-Method
framework	I-Method
.	O
	
For	O
simplicity	O
we	O
describe	O
MPNNs	B-Method
which	O
operate	O
on	O
undirected	O
graphs	O
with	O
node	O
features	O
and	O
edge	O
features	O
.	O
	
It	O
is	O
trivial	O
to	O
extend	O
the	O
formalism	O
to	O
directed	B-Task
multigraphs	I-Task
.	O
	
The	O
forward	B-Method
pass	I-Method
has	O
two	O
phases	O
,	O
a	O
message	B-Method
passing	I-Method
phase	I-Method
and	O
a	O
readout	B-Method
phase	I-Method
.	O
	
The	O
message	B-Method
passing	I-Method
phase	I-Method
runs	O
for	O
time	O
steps	O
and	O
is	O
defined	O
in	O
terms	O
of	O
message	O
functions	O
and	O
vertex	B-Method
update	I-Method
functions	I-Method
.	O
	
During	O
the	O
message	B-Task
passing	I-Task
phase	I-Task
,	O
hidden	O
states	O
at	O
each	O
node	O
in	O
the	O
graph	O
are	O
updated	O
based	O
on	O
messages	O
according	O
to	O
where	O
in	O
the	O
sum	O
,	O
denotes	O
the	O
neighbors	O
of	O
in	O
graph	O
.	O
	
The	O
readout	B-Method
phase	I-Method
computes	O
a	O
feature	O
vector	O
for	O
the	O
whole	O
graph	O
using	O
some	O
readout	O
function	O
according	O
to	O
The	O
message	O
functions	O
,	O
vertex	O
update	O
functions	O
,	O
and	O
readout	O
function	O
are	O
all	O
learned	O
differentiable	O
functions	O
.	O
	
operates	O
on	O
the	O
set	O
of	O
node	O
states	O
and	O
must	O
be	O
invariant	O
to	O
permutations	O
of	O
the	O
node	O
states	O
in	O
order	O
for	O
the	O
MPNN	B-Method
to	O
be	O
invariant	O
to	O
graph	B-Method
isomorphism	I-Method
.	O
	
In	O
what	O
follows	O
,	O
we	O
define	O
previous	O
models	O
in	O
the	O
literature	O
by	O
specifying	O
the	O
message	O
function	O
,	O
vertex	O
update	O
function	O
,	O
and	O
readout	O
function	O
used	O
.	O
	
Note	O
one	O
could	O
also	O
learn	O
edge	O
features	O
in	O
an	O
MPNN	B-Method
by	O
introducing	O
hidden	O
states	O
for	O
all	O
edges	O
in	O
the	O
graph	O
and	O
updating	O
them	O
analogously	O
to	O
equations	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
.	O
	
Of	O
the	O
existing	O
MPNNs	B-Method
,	O
only	O
has	O
used	O
this	O
idea	O
.	O
	
Convolutional	B-Method
Networks	I-Method
for	O
Learning	B-Task
Molecular	I-Task
Fingerprints	I-Task
,	O
(	O
)	O
	
The	O
message	O
function	O
used	O
is	O
where	O
denotes	O
concatenation	O
.	O
	
The	O
vertex	O
update	O
function	O
used	O
is	O
,	O
where	O
is	O
the	O
sigmoid	O
function	O
,	O
deg	O
is	O
the	O
degree	O
of	O
vertex	O
and	O
is	O
a	O
learned	O
matrix	O
for	O
each	O
time	O
step	O
and	O
vertex	O
degree	O
.	O
	
has	O
skip	O
connections	O
to	O
all	O
previous	O
hidden	O
states	O
and	O
is	O
equal	O
to	O
,	O
where	O
is	O
a	O
neural	B-Method
network	I-Method
and	O
are	O
learned	O
readout	O
matrices	O
,	O
one	O
for	O
each	O
time	O
step	O
.	O
	
This	O
message	B-Method
passing	I-Method
scheme	I-Method
may	O
be	O
problematic	O
since	O
the	O
resulting	O
message	O
vector	O
is	O
which	O
separately	O
sums	O
over	O
connected	O
nodes	O
and	O
connected	O
edges	O
.	O
	
It	O
follows	O
that	O
the	O
message	B-Method
passing	I-Method
implemented	O
in	O
is	O
unable	O
to	O
identify	O
correlations	O
between	O
edge	O
states	O
and	O
node	O
states	O
.	O
	
Gated	B-Method
Graph	I-Method
Neural	I-Method
Networks	I-Method
(	O
GG	B-Method
-	I-Method
NN	I-Method
)	O
,	O
(	O
)	O
	
The	O
message	O
function	O
used	O
is	O
,	O
where	O
is	O
a	O
learned	O
matrix	O
,	O
one	O
for	O
each	O
edge	O
label	O
(	O
the	O
model	O
assumes	O
discrete	O
edge	O
types	O
)	O
.	O
	
The	O
update	O
function	O
is	O
,	O
where	O
GRU	B-Method
is	O
the	O
Gated	B-Method
Recurrent	I-Method
Unit	I-Method
introduced	O
in	O
.	O
	
This	O
work	O
used	O
weight	B-Method
tying	I-Method
,	O
so	O
the	O
same	O
update	O
function	O
is	O
used	O
at	O
each	O
time	O
step	O
.	O
	
Finally	O
,	O
where	O
and	O
are	O
neural	B-Method
networks	I-Method
,	O
and	O
denotes	O
element	B-Method
-	I-Method
wise	I-Method
multiplication	I-Method
.	O
	
Interaction	O
Networks	O
,	O
(	O
)	O
	
This	O
work	O
considered	O
both	O
the	O
case	O
where	O
there	O
is	O
a	O
target	O
at	O
each	O
node	O
in	O
the	O
graph	O
,	O
and	O
where	O
there	O
is	O
a	O
graph	O
level	O
target	O
.	O
	
It	O
also	O
considered	O
the	O
case	O
where	O
there	O
are	O
node	O
level	O
effects	O
applied	O
at	O
each	O
time	O
step	O
,	O
in	O
such	O
a	O
case	O
the	O
update	B-Method
function	I-Method
takes	O
as	O
input	O
the	O
concatenation	O
where	O
is	O
an	O
external	O
vector	O
representing	O
some	O
outside	O
influence	O
on	O
the	O
vertex	O
.	O
	
The	O
message	B-Method
function	I-Method
is	O
a	O
neural	B-Method
network	I-Method
which	O
takes	O
the	O
concatenation	O
.	O
	
The	O
vertex	B-Method
update	I-Method
function	I-Method
is	O
a	O
neural	B-Method
network	I-Method
which	O
takes	O
as	O
input	O
the	O
concatenation	O
.	O
	
Finally	O
,	O
in	O
the	O
case	O
where	O
there	O
is	O
a	O
graph	O
level	O
output	O
,	O
where	O
is	O
a	O
neural	B-Method
network	I-Method
which	O
takes	O
the	O
sum	O
of	O
the	O
final	O
hidden	O
states	O
.	O
	
Note	O
the	O
original	O
work	O
only	O
defined	O
the	O
model	O
for	O
.	O
	
Molecular	B-Method
Graph	I-Method
Convolutions	I-Method
,	O
(	O
)	O
	
This	O
work	O
deviates	O
slightly	O
from	O
other	O
MPNNs	B-Method
in	O
that	O
it	O
introduces	O
edge	B-Method
representations	I-Method
which	O
are	O
updated	O
during	O
the	O
message	B-Method
passing	I-Method
phase	I-Method
.	O
	
The	O
message	O
function	O
used	O
for	O
node	O
messages	O
is	O
.	O
	
The	O
vertex	O
update	O
function	O
is	O
where	O
denotes	O
concatenation	O
,	O
is	O
the	O
ReLU	O
activation	O
and	O
are	O
learned	O
weight	O
matrices	O
.	O
	
The	O
edge	O
state	O
update	O
is	O
defined	O
by	O
where	O
the	O
are	O
also	O
learned	O
weight	O
matrices	O
.	O
	
Deep	B-Method
Tensor	I-Method
Neural	I-Method
Networks	I-Method
,	O
(	O
)	O
	
The	O
message	O
from	O
to	O
is	O
computed	O
by	O
where	O
,	O
,	O
are	O
matrices	O
and	O
,	O
are	O
bias	O
vectors	O
.	O
	
The	O
update	O
function	O
used	O
is	O
.	O
	
The	O
readout	B-Method
function	I-Method
passes	O
each	O
node	O
independently	O
through	O
a	O
single	O
hidden	B-Method
layer	I-Method
neural	I-Method
network	I-Method
and	O
sums	O
the	O
outputs	O
,	O
in	O
particular	O
Laplacian	B-Method
Based	I-Method
Methods	I-Method
,	O
(	O
)	O
	
These	O
methods	O
generalize	O
the	O
notion	O
of	O
the	O
convolution	O
operation	O
typically	O
applied	O
to	O
image	O
datasets	O
to	O
an	O
operation	O
that	O
operates	O
on	O
an	O
arbitrary	O
graph	O
with	O
a	O
real	O
valued	O
adjacency	O
matrix	O
.	O
	
The	O
operations	O
defined	O
in	O
result	O
in	O
message	O
functions	O
of	O
the	O
form	O
,	O
where	O
the	O
matrices	O
are	O
parameterized	O
by	O
the	O
eigenvectors	O
of	O
the	O
graph	O
laplacian	O
,	O
and	O
the	O
learned	O
parameters	O
of	O
the	O
model	O
.	O
	
The	O
vertex	O
update	O
function	O
used	O
is	O
where	O
is	O
some	O
pointwise	O
non	O
-	O
linearity	O
(	O
such	O
as	O
ReLU	B-Method
)	O
.	O
	
The	O
model	O
results	O
in	O
a	O
message	O
function	O
where	O
.	O
	
The	O
vertex	O
update	O
function	O
is	O
.	O
	
For	O
the	O
exact	O
expressions	O
for	O
the	O
and	O
the	O
derivation	O
of	O
the	O
reformulation	O
of	O
these	O
models	O
as	O
MPNNs	B-Method
,	O
see	O
the	O
supplementary	O
material	O
.	O
	
subsection	O
:	O
Moving	O
Forward	O
	
Given	O
how	O
many	O
instances	O
of	O
MPNNâs	B-Method
have	O
appeared	O
in	O
the	O
literature	O
,	O
we	O
should	O
focus	O
on	O
pushing	O
this	O
general	O
family	O
as	O
far	O
as	O
possible	O
in	O
a	O
specific	O
application	O
of	O
substantial	O
practical	O
importance	O
.	O
	
This	O
way	O
we	O
can	O
determine	O
the	O
most	O
crucial	O
implementation	O
details	O
and	O
potentially	O
reach	O
the	O
limits	O
of	O
these	O
models	O
to	O
guide	O
us	O
towards	O
future	O
modeling	O
improvements	O
.	O
	
One	O
downside	O
of	O
all	O
of	O
these	O
approaches	O
is	O
computation	B-Metric
time	I-Metric
.	O
	
Recent	O
work	O
has	O
adapted	O
the	O
GG	B-Method
-	I-Method
NN	I-Method
architecture	I-Method
to	O
larger	O
graphs	O
by	O
passing	O
messages	O
on	O
only	O
subsets	O
of	O
the	O
graph	O
at	O
each	O
time	O
step	O
.	O
	
In	O
this	O
work	O
we	O
also	O
present	O
a	O
MPNN	B-Method
modification	I-Method
that	O
can	O
improve	O
the	O
computational	B-Metric
costs	I-Metric
.	O
	
section	O
:	O
Related	O
Work	O
	
Although	O
in	O
principle	O
quantum	O
mechanics	O
lets	O
us	O
compute	O
the	O
properties	O
of	O
molecules	O
,	O
the	O
laws	O
of	O
physics	O
lead	O
to	O
equations	O
that	O
are	O
far	O
too	O
difficult	O
to	O
solve	O
exactly	O
.	O
	
Therefore	O
scientists	O
have	O
developed	O
a	O
hierarchy	O
of	O
approximations	O
to	O
quantum	B-Task
mechanics	I-Task
with	O
varying	O
tradeoffs	O
of	O
speed	B-Metric
and	O
accuracy	B-Metric
,	O
such	O
as	O
Density	B-Method
Functional	I-Method
Theory	I-Method
(	O
DFT	B-Method
)	O
with	O
a	O
variety	O
of	O
functionals	O
,	O
the	O
GW	B-Method
approximation	I-Method
,	O
and	O
Quantum	B-Method
Monte	I-Method
-	I-Method
Carlo	I-Method
.	O
	
Despite	O
being	O
widely	O
used	O
,	O
DFT	B-Method
is	O
simultaneously	O
still	O
too	O
slow	O
to	O
be	O
applied	O
to	O
large	O
systems	O
(	O
scaling	O
as	O
where	O
is	O
the	O
number	O
of	O
electrons	O
)	O
and	O
exhibits	O
systematic	O
as	O
well	O
as	O
random	O
errors	O
relative	O
to	O
exact	B-Method
solutions	I-Method
to	O
Schrödinger	B-Task
’s	I-Task
equation	I-Task
.	O
	
For	O
example	O
,	O
to	O
run	O
the	O
DFT	B-Task
calculation	I-Task
on	O
a	O
single	O
9	O
heavy	O
atom	O
molecule	O
in	O
QM9	B-Material
takes	O
around	O
an	O
hour	O
on	O
a	O
single	O
core	O
of	O
a	O
Xeon	O
E5	O
-	O
2660	O
(	O
2.2	O
GHz	O
)	O
using	O
a	O
version	O
of	O
Gaussian	B-Method
G09	I-Method
(	O
ES64L	B-Method
-	I-Method
G09RevD.01	I-Method
)	O
.	O
	
For	O
a	O
17	O
heavy	O
atom	O
molecule	O
,	O
computation	B-Metric
time	I-Metric
is	O
up	O
to	O
8	O
hours	O
.	O
	
Empirical	B-Method
potentials	I-Method
have	O
been	O
developed	O
,	O
such	O
as	O
the	O
Stillinger	B-Method
-	I-Method
Weber	I-Method
potential	I-Method
,	O
that	O
are	O
fast	O
and	O
accurate	O
but	O
must	O
be	O
created	O
from	O
scratch	O
,	O
from	O
first	O
principles	O
,	O
for	O
every	O
new	O
composition	O
of	O
atoms	O
.	O
	
used	O
neural	B-Method
networks	I-Method
to	O
approximate	O
a	O
particularly	O
troublesome	O
term	O
in	O
DFT	B-Task
called	O
the	O
exchange	O
correlation	O
potential	O
to	O
improve	O
the	O
accuracy	B-Metric
of	O
DFT	B-Task
.	O
	
However	O
,	O
their	O
method	O
fails	O
to	O
improve	O
upon	O
the	O
efficiency	O
of	O
DFT	B-Method
and	O
relies	O
on	O
a	O
large	O
set	O
of	O
ad	B-Method
hoc	I-Method
atomic	I-Method
descriptors	I-Method
.	O
	
Two	O
more	O
recent	O
approaches	O
by	O
and	O
attempt	O
to	O
approximate	O
solutions	O
to	O
quantum	B-Task
mechanics	I-Task
directly	O
without	O
appealing	O
to	O
DFT	B-Method
.	O
	
In	O
the	O
first	O
case	O
single	B-Method
-	I-Method
hidden	I-Method
-	I-Method
layer	I-Method
neural	I-Method
networks	I-Method
were	O
used	O
to	O
approximate	O
the	O
energy	O
and	O
forces	O
for	O
configurations	O
of	O
a	O
Silicon	O
melt	O
with	O
the	O
goal	O
of	O
speeding	O
up	O
molecular	B-Task
dynamics	I-Task
simulations	I-Task
.	O
	
The	O
second	O
paper	O
used	O
Kernel	B-Method
Ridge	I-Method
Regression	I-Method
(	O
KRR	B-Method
)	O
to	O
infer	O
atomization	O
energies	O
over	O
a	O
wide	O
range	O
of	O
molecules	O
.	O
	
In	O
both	O
cases	O
hand	O
engineered	O
features	O
were	O
used	O
(	O
symmetry	O
functions	O
and	O
the	O
Coulomb	O
matrix	O
,	O
respectively	O
)	O
that	O
built	O
physical	O
symmetries	O
into	O
the	O
input	O
representation	O
.	O
	
Subsequent	O
papers	O
have	O
replaced	O
KRR	B-Method
by	O
a	O
neural	B-Method
network	I-Method
.	O
	
Both	O
of	O
these	O
lines	O
of	O
research	O
used	O
hand	O
engineered	O
features	O
that	O
have	O
intrinsic	O
limitations	O
.	O
	
The	O
work	O
of	O
used	O
a	O
representation	O
that	O
was	O
manifestly	O
invariant	O
to	O
graph	B-Method
isomorphism	I-Method
,	O
but	O
has	O
difficulty	O
when	O
applied	O
to	O
systems	O
with	O
more	O
than	O
three	O
species	O
of	O
atoms	O
and	O
fails	O
to	O
generalize	O
to	O
novel	O
compositions	O
.	O
	
The	O
representation	O
used	O
in	O
is	O
not	O
invariant	O
to	O
graph	B-Method
isomorphism	I-Method
.	O
	
Instead	O
,	O
this	O
invariance	O
must	O
be	O
learned	O
by	O
the	O
downstream	B-Method
model	I-Method
through	O
dataset	B-Task
augmentation	I-Task
.	O
	
In	O
addition	O
to	O
the	O
eight	O
MPNNâs	B-Method
discussed	O
in	O
Section	O
[	O
reference	O
]	O
there	O
have	O
been	O
a	O
number	O
of	O
other	O
approaches	O
to	O
machine	B-Task
learning	I-Task
on	O
graphical	O
data	O
which	O
take	O
advantage	O
of	O
the	O
symmetries	O
in	O
a	O
number	O
of	O
ways	O
.	O
	
One	O
such	O
family	O
of	O
approaches	O
define	O
a	O
preprocessing	B-Method
step	I-Method
which	O
constructs	O
a	O
canonical	B-Method
graph	I-Method
representation	I-Method
which	O
can	O
then	O
be	O
fed	O
into	O
into	O
a	O
standard	O
classifier	B-Method
.	O
	
Examples	O
in	O
this	O
family	O
include	O
and	O
.	O
	
Finally	O
define	O
a	O
message	B-Method
passing	I-Method
process	I-Method
on	O
graphs	B-Method
which	O
is	O
run	O
until	O
convergence	O
,	O
instead	O
of	O
for	O
a	O
finite	O
number	O
of	O
time	O
steps	O
as	O
in	O
MPNNs	B-Method
.	O
	
section	O
:	O
QM9	B-Material
Dataset	I-Material
	
To	O
investigate	O
the	O
success	O
of	O
MPNNs	B-Method
on	O
predicting	B-Task
chemical	I-Task
properties	I-Task
,	O
we	O
use	O
the	O
publicly	O
available	O
QM9	B-Material
dataset	I-Material
.	O
	
Molecules	O
in	O
the	O
dataset	O
consist	O
of	O
Hydrogen	O
(	O
H	O
)	O
,	O
Carbon	O
(	O
C	O
)	O
,	O
Oxygen	O
(	O
O	O
)	O
,	O
Nitrogen	O
(	O
N	O
)	O
,	O
and	O
Flourine	O
(	O
F	O
)	O
atoms	O
and	O
contain	O
up	O
to	O
9	O
heavy	O
(	O
non	O
Hydrogen	O
)	O
atoms	O
.	O
	
In	O
all	O
,	O
this	O
results	O
in	O
about	O
134k	O
drug	O
-	O
like	O
organic	O
molecules	O
that	O
span	O
a	O
wide	O
range	O
of	O
chemistry	O
.	O
	
For	O
each	O
molecule	O
DFT	B-Method
is	O
used	O
to	O
find	O
a	O
reasonable	O
low	O
energy	O
structure	O
and	O
hence	O
atom	O
“	O
positions	O
”	O
are	O
available	O
.	O
	
Additionally	O
a	O
wide	O
range	O
of	O
interesting	O
and	O
fundamental	O
chemical	O
properties	O
are	O
computed	O
.	O
	
Given	O
how	O
fundamental	O
some	O
of	O
the	O
QM9	B-Material
properties	O
are	O
,	O
it	O
is	O
hard	O
to	O
believe	O
success	O
on	O
more	O
challenging	O
chemical	B-Task
tasks	I-Task
will	O
be	O
possible	O
if	O
we	O
ca	O
	
n’t	O
make	O
accurate	O
statistical	O
predictions	O
for	O
the	O
properties	O
computed	O
in	O
QM9	B-Material
.	O
	
We	O
can	O
group	O
the	O
different	O
properties	O
we	O
try	O
to	O
predict	O
into	O
four	O
broad	O
categories	O
.	O
	
First	O
,	O
we	O
have	O
four	O
properties	O
related	O
to	O
how	O
tightly	O
bound	O
together	O
the	O
atoms	O
in	O
a	O
molecule	O
are	O
.	O
	
These	O
measure	O
the	O
energy	O
required	O
to	O
break	O
up	O
the	O
molecule	O
at	O
different	O
temperatures	O
and	O
pressures	O
.	O
	
These	O
include	O
the	O
atomization	O
energy	O
at	O
,	O
(	O
eV	O
)	O
,	O
atomization	O
energy	O
at	O
room	O
temperature	O
,	O
(	O
eV	O
)	O
,	O
enthalpy	O
of	O
atomization	O
at	O
room	O
temperature	O
,	O
(	O
eV	O
)	O
,	O
and	O
free	O
energy	O
of	O
atomization	O
,	O
(	O
eV	O
)	O
.	O
	
Next	O
there	O
are	O
properties	O
related	O
to	O
fundamental	O
vibrations	O
of	O
the	O
molecule	O
,	O
including	O
the	O
highest	O
fundamental	O
vibrational	O
frequency	O
(	O
)	O
and	O
the	O
zero	O
point	O
vibrational	O
energy	O
(	O
ZPVE	O
)	O
(	O
eV	O
)	O
.	O
	
Additionally	O
,	O
there	O
are	O
a	O
number	O
of	O
properties	O
that	O
concern	O
the	O
states	O
of	O
the	O
electrons	O
in	O
the	O
molecule	O
.	O
	
They	O
include	O
the	O
energy	O
of	O
the	O
electron	O
in	O
the	O
highest	O
occupied	O
molecular	O
orbital	O
(	O
HOMO	O
)	O
(	O
eV	O
)	O
,	O
the	O
energy	O
of	O
the	O
lowest	O
unoccupied	O
molecular	O
orbital	O
(	O
LUMO	O
)	O
	
(	O
eV	O
)	O
,	O
and	O
the	O
electron	O
energy	O
gap	O
(	O
(	O
eV	O
)	O
)	O
.	O
	
The	O
electron	O
energy	O
gap	O
is	O
simply	O
the	O
difference	O
.	O
	
Finally	O
,	O
there	O
are	O
several	O
measures	O
of	O
the	O
spatial	O
distribution	O
of	O
electrons	O
in	O
the	O
molecule	O
.	O
	
These	O
include	O
the	O
electronic	O
spatial	O
extent	O
(	O
Bohr	O
)	O
,	O
the	O
norm	O
of	O
the	O
dipole	O
moment	O
(	O
Debye	O
)	O
,	O
and	O
the	O
norm	O
of	O
static	O
polarizability	O
(	O
Bohr	O
)	O
.	O
	
For	O
a	O
more	O
detailed	O
description	O
of	O
these	O
properties	O
,	O
see	O
the	O
supplementary	O
material	O
.	O
	
section	O
:	O
MPNN	B-Method
Variants	I-Method
	
We	O
began	O
our	O
exploration	O
of	O
MPNNs	B-Method
around	O
the	O
GG	B-Method
-	I-Method
NN	I-Method
model	I-Method
which	O
we	O
believe	O
to	O
be	O
a	O
strong	O
baseline	O
.	O
	
We	O
focused	O
on	O
trying	O
different	O
message	O
functions	O
,	O
output	O
functions	O
,	O
finding	O
the	O
appropriate	O
input	O
representation	O
,	O
and	O
properly	O
tuning	O
hyperparameters	O
.	O
	
For	O
the	O
rest	O
of	O
the	O
paper	O
we	O
use	O
to	O
denote	O
the	O
dimension	O
of	O
the	O
internal	B-Method
hidden	I-Method
representation	I-Method
of	O
each	O
node	O
in	O
the	O
graph	O
,	O
and	O
to	O
denote	O
the	O
number	O
of	O
nodes	O
in	O
the	O
graph	O
.	O
	
Our	O
implementation	O
of	O
MPNNs	B-Method
in	O
general	O
operates	O
on	O
directed	O
graphs	O
with	O
a	O
separate	O
message	O
channel	O
for	O
incoming	O
and	O
outgoing	O
edges	O
,	O
in	O
which	O
case	O
the	O
incoming	O
message	O
is	O
the	O
concatenation	O
of	O
and	O
,	O
this	O
was	O
also	O
used	O
in	O
.	O
	
When	O
we	O
apply	O
this	O
to	O
undirected	B-Task
chemical	I-Task
graphs	I-Task
we	O
treat	O
the	O
graph	O
as	O
directed	O
,	O
where	O
each	O
original	O
edge	O
becomes	O
both	O
an	O
incoming	O
and	O
outgoing	O
edge	O
with	O
the	O
same	O
label	O
.	O
	
Note	O
there	O
is	O
nothing	O
special	O
about	O
the	O
direction	O
of	O
the	O
edge	O
,	O
it	O
is	O
only	O
relevant	O
for	O
parameter	B-Task
tying	I-Task
.	O
	
Treating	O
undirected	O
graphs	O
as	O
directed	O
means	O
that	O
the	O
size	O
of	O
the	O
message	O
channel	O
is	O
instead	O
of	O
.	O
	
The	O
input	O
to	O
our	O
MPNN	B-Method
model	I-Method
is	O
a	O
set	O
of	O
feature	O
vectors	O
for	O
the	O
nodes	O
of	O
the	O
graph	O
,	O
,	O
and	O
an	O
adjacency	O
matrix	O
with	O
vector	O
valued	O
entries	O
to	O
indicate	O
different	O
bonds	O
in	O
the	O
molecule	O
as	O
well	O
as	O
pairwise	O
spatial	O
distance	O
between	O
two	O
atoms	O
.	O
	
We	O
experimented	O
as	O
well	O
with	O
the	O
message	B-Method
function	I-Method
used	O
in	O
the	O
GG	B-Method
-	I-Method
NN	I-Method
family	I-Method
,	O
which	O
assumes	O
discrete	O
edge	O
labels	O
,	O
in	O
which	O
case	O
the	O
matrix	O
has	O
entries	O
in	O
a	O
discrete	O
alphabet	O
of	O
size	O
.	O
	
The	O
initial	O
hidden	O
states	O
are	O
set	O
to	O
be	O
the	O
atom	O
input	O
feature	O
vectors	O
and	O
are	O
padded	O
up	O
to	O
some	O
larger	O
dimension	O
.	O
	
All	O
of	O
our	O
experiments	O
used	O
weight	B-Method
tying	I-Method
at	O
each	O
time	O
step	O
,	O
and	O
a	O
GRU	B-Method
for	O
the	O
update	B-Method
function	I-Method
as	O
in	O
the	O
GG	B-Method
-	I-Method
NN	I-Method
family	I-Method
.	O
	
subsection	O
:	O
Message	B-Method
Functions	I-Method
	
Matrix	B-Method
Multiplication	I-Method
:	O
We	O
started	O
with	O
the	O
message	B-Method
function	I-Method
used	O
in	O
GG	B-Method
-	I-Method
NN	I-Method
which	O
is	O
defined	O
by	O
the	O
equation	O
.	O
	
Edge	B-Method
Network	I-Method
:	O
To	O
allow	O
vector	O
valued	O
edge	O
features	O
we	O
propose	O
the	O
message	B-Method
function	I-Method
where	O
is	O
a	O
neural	B-Method
network	I-Method
which	O
maps	O
the	O
edge	O
vector	O
to	O
a	O
matrix	O
.	O
	
Pair	O
Message	O
:	O
	
One	O
property	O
that	O
the	O
matrix	B-Method
multiplication	I-Method
rule	I-Method
has	O
is	O
that	O
the	O
message	O
from	O
node	O
to	O
node	O
is	O
a	O
function	O
only	O
of	O
the	O
hidden	O
state	O
and	O
the	O
edge	O
.	O
	
In	O
particular	O
,	O
it	O
does	O
not	O
depend	O
on	O
the	O
hidden	O
state	O
.	O
	
In	O
theory	O
,	O
a	O
network	O
may	O
be	O
able	O
to	O
use	O
the	O
message	O
channel	O
more	O
efficiently	O
if	O
the	O
node	O
messages	O
are	O
allowed	O
to	O
depend	O
on	O
both	O
the	O
source	O
and	O
destination	O
node	O
.	O
	
Thus	O
we	O
also	O
tried	O
using	O
a	O
variant	O
on	O
the	O
message	O
function	O
as	O
described	O
in	O
.	O
	
Here	O
the	O
message	O
from	O
to	O
along	O
edge	O
is	O
where	O
is	O
a	O
neural	B-Method
network	I-Method
.	O
	
When	O
we	O
apply	O
the	O
above	O
message	B-Method
functions	I-Method
to	O
directed	O
graphs	O
,	O
there	O
are	O
two	O
separate	O
functions	O
used	O
,	O
and	O
an	O
.	O
	
Which	O
function	O
is	O
applied	O
to	O
a	O
particular	O
edge	O
depends	O
on	O
the	O
direction	O
of	O
that	O
edge	O
.	O
	
subsection	O
:	O
Virtual	O
Graph	O
Elements	O
	
We	O
explored	O
two	O
different	O
ways	O
to	O
change	O
how	O
the	O
messages	O
are	O
passed	O
throughout	O
the	O
model	O
.	O
	
The	O
simplest	O
modification	O
involves	O
adding	O
a	O
separate	O
“	O
virtual	O
”	O
edge	O
type	O
for	O
pairs	O
of	O
nodes	O
that	O
are	O
not	O
connected	O
.	O
	
This	O
can	O
be	O
implemented	O
as	O
a	O
data	B-Task
preprocessing	I-Task
step	I-Task
and	O
allows	O
information	O
to	O
travel	O
long	O
distances	O
during	O
the	O
propagation	O
phase	O
.	O
	
We	O
also	O
experimented	O
with	O
using	O
a	O
latent	O
“	O
master	O
”	O
node	O
,	O
which	O
is	O
connected	O
to	O
every	O
input	O
node	O
in	O
the	O
graph	O
with	O
a	O
special	O
edge	O
type	O
.	O
	
The	O
master	O
node	O
serves	O
as	O
a	O
global	O
scratch	O
space	O
that	O
each	O
node	O
both	O
reads	O
from	O
and	O
writes	O
to	O
in	O
every	O
step	O
of	O
message	B-Task
passing	I-Task
.	O
	
We	O
allow	O
the	O
master	O
node	O
to	O
have	O
a	O
separate	O
node	O
dimension	O
,	O
as	O
well	O
as	O
separate	O
weights	O
for	O
the	O
internal	O
update	O
function	O
(	O
in	O
our	O
case	O
a	O
GRU	B-Method
)	O
.	O
	
This	O
allows	O
information	O
to	O
travel	O
long	O
distances	O
during	O
the	O
propagation	O
phase	O
.	O
	
It	O
also	O
,	O
in	O
theory	O
,	O
allows	O
additional	O
model	O
capacity	O
(	O
e.g.	O
large	O
values	O
of	O
)	O
without	O
a	O
substantial	O
hit	O
in	O
performance	O
,	O
as	O
the	O
complexity	B-Metric
of	O
the	O
master	B-Method
node	I-Method
model	I-Method
is	O
.	O
	
subsection	O
:	O
Readout	B-Method
Functions	I-Method
	
We	O
experimented	O
with	O
two	O
readout	B-Method
functions	I-Method
.	O
	
First	O
is	O
the	O
readout	B-Method
function	I-Method
used	O
in	O
GG	B-Method
-	I-Method
NN	I-Method
,	O
which	O
is	O
defined	O
by	O
equation	O
[	O
reference	O
]	O
.	O
	
Second	O
is	O
a	O
set2set	B-Method
model	I-Method
from	O
.	O
	
The	O
set2set	B-Method
model	I-Method
is	O
specifically	O
designed	O
to	O
operate	O
on	O
sets	O
and	O
should	O
have	O
more	O
expressive	O
power	O
than	O
simply	O
summing	O
the	O
final	O
node	O
states	O
.	O
	
This	O
model	O
first	O
applies	O
a	O
linear	B-Method
projection	I-Method
to	O
each	O
tuple	O
(	O
)	O
and	O
then	O
takes	O
as	O
input	O
the	O
set	O
of	O
projected	O
tuples	O
.	O
	
Then	O
,	O
after	O
steps	O
of	O
computation	O
,	O
the	O
set2set	B-Method
model	I-Method
produces	O
a	O
graph	B-Method
level	I-Method
embedding	I-Method
which	O
is	O
invariant	O
to	O
the	O
order	O
of	O
the	O
of	O
the	O
tuples	O
.	O
	
We	O
feed	O
this	O
embedding	O
through	O
a	O
neural	B-Method
network	I-Method
to	O
produce	O
the	O
output	O
.	O
	
subsection	O
:	O
Multiple	O
Towers	O
	
One	O
issue	O
with	O
MPNNâs	B-Method
is	O
scalability	O
.	O
	
In	O
particular	O
,	O
a	O
single	O
step	O
of	O
the	O
message	B-Method
passing	I-Method
phase	I-Method
for	O
a	O
dense	B-Task
graph	I-Task
requires	O
floating	B-Task
point	I-Task
multiplications	I-Task
.	O
	
As	O
or	O
get	O
large	O
this	O
can	O
be	O
computationally	O
expensive	O
.	O
	
To	O
address	O
this	O
issue	O
we	O
break	O
the	O
dimensional	O
node	O
embeddings	O
into	O
different	O
dimensional	O
embeddings	O
and	O
run	O
a	O
propagation	B-Method
step	I-Method
on	O
each	O
of	O
the	O
copies	O
separately	O
to	O
get	O
temporary	O
embeddings	O
,	O
using	O
separate	O
message	B-Method
and	I-Method
update	I-Method
functions	I-Method
for	O
each	O
copy	O
.	O
	
The	O
temporary	O
embeddings	O
of	O
each	O
node	O
are	O
then	O
mixed	O
together	O
according	O
to	O
the	O
equation	O
where	O
denotes	O
a	O
neural	B-Method
network	I-Method
and	O
denotes	O
concatenation	B-Method
,	O
with	O
shared	O
across	O
all	O
nodes	O
in	O
the	O
graph	O
.	O
	
This	O
mixing	O
preserves	O
the	O
invariance	O
to	O
permutations	O
of	O
the	O
nodes	O
,	O
while	O
allowing	O
the	O
different	O
copies	O
of	O
the	O
graph	O
to	O
communicate	O
with	O
each	O
other	O
during	O
the	O
propagation	O
phase	O
.	O
	
This	O
can	O
be	O
advantageous	O
in	O
that	O
it	O
allows	O
larger	O
hidden	O
states	O
for	O
the	O
same	O
number	O
of	O
parameters	O
,	O
which	O
yields	O
a	O
computational	O
speedup	O
in	O
practice	O
.	O
	
For	O
example	O
,	O
when	O
the	O
message	O
function	O
is	O
matrix	B-Method
multiplication	I-Method
(	O
as	O
in	O
GG	B-Method
-	I-Method
NN	I-Method
)	O
a	O
propagation	B-Method
step	I-Method
of	O
a	O
single	O
copy	O
takes	O
time	O
,	O
and	O
there	O
are	O
copies	O
,	O
therefore	O
the	O
overall	O
time	B-Metric
complexity	I-Metric
is	O
,	O
with	O
some	O
additional	O
overhead	O
due	O
to	O
the	O
mixing	B-Method
network	I-Method
.	O
	
For	O
,	O
and	O
we	O
see	O
a	O
factor	O
of	O
2	O
speedup	O
in	O
inference	B-Metric
time	I-Metric
over	O
a	O
,	O
,	O
and	O
architecture	O
.	O
	
This	O
variation	O
would	O
be	O
most	O
useful	O
for	O
larger	O
molecules	O
,	O
for	O
instance	O
molecules	O
from	O
GDB	O
-	O
17	O
.	O
	
section	O
:	O
Input	B-Method
Representation	I-Method
	
There	O
are	O
a	O
number	O
of	O
features	O
available	O
for	O
each	O
atom	O
in	O
a	O
molecule	O
which	O
capture	O
both	O
properties	O
of	O
the	O
electrons	O
in	O
the	O
atom	O
as	O
well	O
as	O
the	O
bonds	O
that	O
the	O
atom	O
participates	O
in	O
.	O
	
For	O
a	O
list	O
of	O
all	O
of	O
the	O
features	O
see	O
table	O
[	O
reference	O
]	O
.	O
	
We	O
experimented	O
with	O
making	O
the	O
hydrogen	O
atoms	O
explicit	O
nodes	O
in	O
the	O
graph	O
(	O
as	O
opposed	O
to	O
simply	O
including	O
the	O
count	O
as	O
a	O
node	O
feature	O
)	O
,	O
in	O
which	O
case	O
graphs	O
have	O
up	O
to	O
29	O
nodes	O
.	O
	
Note	O
that	O
having	O
larger	O
graphs	O
significantly	O
slows	O
training	B-Metric
time	I-Metric
,	O
in	O
this	O
case	O
by	O
a	O
factor	O
of	O
roughly	O
10	O
.	O
	
For	O
the	O
adjacency	O
matrix	O
there	O
are	O
three	O
edge	B-Method
representations	I-Method
used	O
depending	O
on	O
the	O
model	O
.	O
	
Chemical	B-Method
Graph	I-Method
:	O
	
In	O
the	O
abscence	O
of	O
distance	O
information	O
,	O
adjacency	O
matrix	O
entries	O
are	O
discrete	O
bond	O
types	O
:	O
single	O
,	O
double	O
,	O
triple	O
,	O
or	O
aromatic	O
.	O
	
Distance	O
bins	O
:	O
The	O
matrix	B-Method
multiply	I-Method
message	I-Method
function	I-Method
assumes	O
discrete	O
edge	O
types	O
,	O
so	O
to	O
include	O
distance	O
information	O
we	O
bin	O
bond	O
distances	O
into	O
10	O
bins	O
,	O
the	O
bins	O
are	O
obtained	O
by	O
uniformly	O
partitioning	O
the	O
interval	O
into	O
8	O
bins	O
,	O
followed	O
by	O
adding	O
a	O
bin	O
	
and	O
.	O
	
These	O
bins	O
were	O
hand	O
chosen	O
by	O
looking	O
at	O
a	O
histogram	O
of	O
all	O
distances	O
.	O
	
The	O
adjacency	O
matrix	O
then	O
has	O
entries	O
in	O
an	O
alphabet	O
of	O
size	O
14	O
,	O
indicating	O
bond	O
type	O
for	O
bonded	O
atoms	O
and	O
distance	O
bin	O
for	O
atoms	O
that	O
are	O
not	O
bonded	O
.	O
	
We	O
found	O
the	O
distance	O
for	O
bonded	O
atoms	O
to	O
be	O
almost	O
completely	O
determined	O
by	O
bond	O
type	O
.	O
	
Raw	O
distance	O
feature	O
:	O
When	O
using	O
a	O
message	B-Method
function	I-Method
which	O
operates	O
on	O
vector	O
valued	O
edges	O
,	O
the	O
entries	O
of	O
the	O
adjacency	O
matrix	O
are	O
then	O
5	O
dimensional	O
,	O
where	O
the	O
first	O
dimension	O
indicates	O
the	O
euclidean	O
distance	O
between	O
the	O
pair	O
of	O
atoms	O
,	O
and	O
the	O
remaining	O
four	O
are	O
a	O
one	O
-	O
hot	O
encoding	O
of	O
the	O
bond	O
type	O
.	O
	
section	O
:	O
Training	O
	
Each	O
model	O
and	O
target	O
combination	O
was	O
trained	O
using	O
a	O
uniform	B-Method
random	I-Method
hyper	I-Method
parameter	I-Method
search	I-Method
with	O
50	O
trials	O
.	O
was	O
constrained	O
to	O
be	O
in	O
the	O
range	O
(	O
in	O
practice	O
,	O
any	O
works	O
)	O
.	O
	
The	O
number	O
of	O
set2set	O
computations	O
was	O
chosen	O
from	O
the	O
range	O
.	O
	
All	O
models	O
were	O
trained	O
using	O
SGD	B-Method
with	O
the	O
ADAM	B-Method
optimizer	I-Method
(	O
)	O
,	O
with	O
batch	O
size	O
20	O
for	O
3	O
million	O
steps	O
(	O
540	O
epochs	O
)	O
.	O
	
The	O
initial	O
learning	B-Metric
rate	I-Metric
was	O
chosen	O
uniformly	O
between	O
and	O
.	O
	
We	O
used	O
a	O
linear	B-Method
learning	I-Method
rate	I-Method
decay	I-Method
that	O
began	O
between	O
10	O
%	O
and	O
90	O
%	O
of	O
the	O
way	O
through	O
training	O
and	O
the	O
initial	O
learning	B-Metric
rate	I-Metric
decayed	O
to	O
a	O
final	O
learning	B-Metric
rate	I-Metric
,	O
using	O
a	O
decay	O
factor	O
in	O
the	O
range	O
.	O
	
The	O
QM	B-Material
-	I-Material
9	I-Material
dataset	I-Material
has	O
130462	O
molecules	O
in	O
it	O
.	O
	
We	O
randomly	O
chose	O
10000	O
samples	O
for	O
validation	O
,	O
10000	O
samples	O
for	O
testing	O
,	O
and	O
used	O
the	O
rest	O
for	O
training	O
.	O
	
We	O
use	O
the	O
validation	O
set	O
to	O
do	O
early	B-Method
stopping	I-Method
and	O
model	B-Method
selection	I-Method
and	O
we	O
report	O
scores	O
on	O
the	O
test	O
set	O
.	O
	
All	O
targets	O
were	O
normalized	O
to	O
have	O
mean	O
0	O
and	O
variance	O
1	O
.	O
	
We	O
minimize	O
the	O
mean	B-Metric
squared	I-Metric
error	I-Metric
between	O
the	O
model	O
output	O
and	O
the	O
target	O
,	O
although	O
we	O
evaluate	O
mean	B-Metric
absolute	I-Metric
error	I-Metric
.	O
	
section	O
:	O
Results	O
	
In	O
all	O
of	O
our	O
tables	O
we	O
report	O
the	O
ratio	O
of	O
the	O
mean	B-Metric
absolute	I-Metric
error	I-Metric
(	O
MAE	B-Metric
)	O
of	O
our	O
models	O
with	O
the	O
provided	O
estimate	O
of	O
chemical	B-Metric
accuracy	I-Metric
for	O
that	O
target	O
.	O
	
Thus	O
any	O
model	O
with	O
error	B-Metric
ratio	I-Metric
less	O
than	O
1	O
has	O
achieved	O
chemical	B-Metric
accuracy	I-Metric
for	O
that	O
target	O
.	O
	
In	O
the	O
supplementary	O
material	O
we	O
list	O
the	O
chemical	B-Metric
accuracy	I-Metric
estimates	I-Metric
for	O
each	O
target	O
,	O
these	O
are	O
the	O
same	O
estimates	O
that	O
were	O
given	O
in	O
.	O
	
In	O
this	O
way	O
,	O
the	O
MAE	B-Metric
of	O
our	O
models	O
can	O
be	O
calculated	O
as	O
.	O
	
Note	O
,	O
unless	O
otherwise	O
indicated	O
,	O
all	O
tables	O
display	O
result	O
of	O
models	O
trained	O
individually	O
on	O
each	O
target	O
(	O
as	O
opposed	O
to	O
training	O
one	O
model	O
to	O
predict	O
all	O
13	O
)	O
.	O
	
We	O
performed	O
numerous	O
experiments	O
in	O
order	O
to	O
find	O
the	O
best	O
possible	O
MPNN	B-Method
on	O
this	O
dataset	O
as	O
well	O
as	O
the	O
proper	O
input	O
representation	O
.	O
	
In	O
our	O
experiments	O
,	O
we	O
found	O
that	O
including	O
the	O
complete	O
edge	O
feature	O
vector	O
(	O
bond	O
type	O
,	O
spatial	O
distance	O
)	O
and	O
treating	O
hydrogen	O
atoms	O
as	O
explicit	O
nodes	O
in	O
the	O
graph	O
to	O
be	O
very	O
important	O
for	O
a	O
number	O
of	O
targets	O
.	O
	
We	O
also	O
found	O
that	O
training	O
one	O
model	O
per	O
target	O
consistently	O
outperformed	O
jointly	O
training	O
on	O
all	O
13	O
targets	O
.	O
	
In	O
some	O
cases	O
the	O
improvement	O
was	O
up	O
to	O
40	O
%	O
.	O
	
Our	O
best	O
MPNN	B-Method
variant	I-Method
used	O
the	O
edge	O
network	O
message	O
function	O
,	O
set2set	O
output	O
,	O
and	O
operated	O
on	O
graphs	O
with	O
explicit	O
hydrogens	O
.	O
	
We	O
were	O
able	O
to	O
further	O
improve	O
performance	O
on	O
the	O
test	O
set	O
by	O
ensembling	O
the	O
predictions	O
of	O
the	O
five	O
models	O
with	O
lowest	O
validation	B-Metric
error	I-Metric
.	O
	
In	O
table	O
[	O
reference	O
]	O
we	O
compare	O
the	O
performance	O
of	O
our	O
best	O
MPNN	B-Method
variant	I-Method
(	O
denoted	O
with	O
enn	B-Method
-	I-Method
s2s	I-Method
)	O
and	O
the	O
corresponding	O
ensemble	B-Method
(	O
denoted	O
with	O
enn	B-Method
-	I-Method
s2s	I-Method
-	I-Method
ens5	I-Method
)	O
with	O
the	O
previous	O
state	O
of	O
the	O
art	O
on	O
this	O
dataset	O
as	O
reported	O
in	O
.	O
	
For	O
clarity	O
the	O
error	B-Metric
ratios	I-Metric
of	O
the	O
best	O
non	B-Method
-	I-Method
ensemble	I-Method
models	I-Method
are	O
shown	O
in	O
bold	O
.	O
	
This	O
previous	O
work	O
performed	O
a	O
comparison	O
study	O
of	O
several	O
existing	O
ML	B-Method
models	I-Method
for	O
QM9	B-Material
and	O
we	O
have	O
taken	O
care	O
to	O
use	O
the	O
same	O
train	O
,	O
validation	O
,	O
and	O
test	O
split	O
.	O
	
These	O
baselines	O
include	O
5	O
different	O
hand	B-Method
engineered	I-Method
molecular	I-Method
representations	I-Method
,	O
which	O
then	O
get	O
fed	O
through	O
a	O
standard	O
,	O
off	B-Method
-	I-Method
the	I-Method
-	I-Method
shelf	I-Method
classifier	I-Method
.	O
	
These	O
input	O
representations	O
include	O
the	O
Coulomb	O
Matrix	O
(	O
CM	B-Method
,	O
)	O
,	O
Bag	O
of	O
Bonds	O
(	O
BoB	B-Method
,	O
)	O
,	O
Bonds	O
Angles	O
,	O
Machine	B-Method
Learning	I-Method
(	O
BAML	B-Method
,	O
)	O
,	O
Extended	O
Connectivity	O
Fingerprints	O
(	O
ECPF4	B-Method
,	O
)	O
,	O
and	O
“	O
Projected	B-Method
Histograms	I-Method
”	O
(	O
HDAD	B-Method
,	O
)	O
representations	O
.	O
	
In	O
addition	O
to	O
these	O
hand	O
engineered	O
features	O
we	O
include	O
two	O
existing	O
baseline	O
MPNNs	B-Method
,	O
the	O
Molecular	B-Method
Graph	I-Method
Convolutions	I-Method
model	I-Method
(	O
GC	B-Method
)	I-Method
from	O
,	O
and	O
the	O
original	O
GG	B-Method
-	I-Method
NN	I-Method
model	I-Method
trained	O
with	O
distance	O
bins	O
.	O
	
Overall	O
,	O
our	O
new	O
MPNN	B-Method
achieves	O
chemical	B-Metric
accuracy	I-Metric
on	O
11	O
out	O
of	O
13	O
targets	O
and	O
state	O
of	O
the	O
art	O
on	O
all	O
13	O
targets	O
.	O
	
Training	O
Without	O
Spatial	O
Information	O
:	O
We	O
also	O
experimented	O
in	O
the	O
setting	O
where	O
spatial	O
information	O
is	O
not	O
included	O
in	O
the	O
input	O
.	O
	
In	O
general	O
,	O
we	O
find	O
that	O
augmenting	O
the	O
MPNN	B-Method
with	O
some	O
means	O
of	O
capturing	O
long	O
range	O
interactions	O
between	O
nodes	O
in	O
the	O
graph	O
greatly	O
improves	O
performance	O
in	O
this	O
setting	O
.	O
	
To	O
demonstrate	O
this	O
we	O
performed	O
4	O
experiments	O
,	O
one	O
where	O
we	O
train	O
the	O
GG	B-Method
-	I-Method
NN	I-Method
model	I-Method
on	O
the	O
sparse	O
graph	O
,	O
one	O
where	O
we	O
add	O
virtual	O
edges	O
,	O
one	O
where	O
we	O
add	O
a	O
master	O
node	O
,	O
and	O
one	O
where	O
we	O
change	O
the	O
graph	O
level	O
output	O
to	O
a	O
set2set	O
output	O
.	O
	
The	O
error	B-Metric
ratios	I-Metric
averaged	O
across	O
the	O
13	O
targets	O
are	O
shown	O
in	O
table	O
[	O
reference	O
]	O
.	O
	
Overall	O
,	O
these	O
three	O
modifications	O
help	O
on	O
all	O
13	O
targets	O
,	O
and	O
the	O
Set2Set	O
output	O
achieves	O
chemical	O
accuracy	B-Metric
on	O
5	O
out	O
of	O
13	O
targets	O
.	O
	
For	O
more	O
details	O
,	O
consult	O
the	O
supplementary	O
material	O
.	O
	
The	O
experiments	O
shown	O
tables	O
[	O
reference	O
]	O
and	O
[	O
reference	O
]	O
were	O
run	O
with	O
a	O
partial	O
charge	O
feature	O
as	O
a	O
node	O
input	O
.	O
	
This	O
feature	O
is	O
an	O
output	O
of	O
the	O
DFT	B-Method
calculation	I-Method
and	O
thus	O
could	O
not	O
be	O
used	O
in	O
an	O
applied	O
setting	O
.	O
	
The	O
state	O
of	O
art	O
numbers	O
we	O
report	O
in	O
table	O
[	O
reference	O
]	O
do	O
not	O
use	O
this	O
feature	O
.	O
	
Towers	O
:	O
	
Our	O
original	O
intent	O
in	O
developing	O
the	O
towers	B-Method
variant	I-Method
was	O
to	O
improve	O
training	B-Metric
time	I-Metric
,	O
as	O
well	O
as	O
to	O
allow	O
the	O
model	O
to	O
be	O
trained	O
on	O
larger	O
graphs	O
.	O
	
However	O
,	O
we	O
also	O
found	O
some	O
evidence	O
that	O
the	O
multi	O
-	O
tower	O
structure	O
improves	O
generalization	B-Task
performance	O
.	O
	
In	O
table	O
[	O
reference	O
]	O
we	O
compare	O
GG	B-Method
-	I-Method
NN	I-Method
+	I-Method
towers	I-Method
+	I-Method
set2set	I-Method
output	I-Method
vs	O
a	O
baseline	B-Method
GG	I-Method
-	I-Method
NN	I-Method
+	O
set2set	O
output	O
when	O
distance	O
bins	O
are	O
used	O
.	O
	
We	O
do	O
this	O
comparison	O
in	O
both	O
the	O
joint	B-Task
training	I-Task
regime	I-Task
and	O
when	O
training	O
one	O
model	O
per	O
target	O
.	O
	
The	O
towers	B-Method
model	I-Method
outperforms	O
the	O
baseline	O
model	O
on	O
12	O
out	O
of	O
13	O
targets	O
in	O
both	O
individual	B-Task
and	I-Task
joint	I-Task
target	I-Task
training	I-Task
.	O
	
We	O
believe	O
the	O
benefit	O
of	O
towers	O
is	O
that	O
it	O
resembles	O
training	O
an	O
ensemble	B-Method
of	I-Method
models	I-Method
.	O
	
Unfortunately	O
,	O
our	O
attempts	O
so	O
far	O
at	O
combining	O
the	O
towers	O
and	O
edge	B-Method
network	I-Method
message	I-Method
function	I-Method
have	O
failed	O
to	O
further	O
improve	O
performance	O
,	O
possibly	O
because	O
the	O
combination	O
makes	O
training	B-Task
more	O
difficult	O
.	O
	
Further	O
training	O
details	O
,	O
and	O
error	B-Metric
ratios	I-Metric
on	O
all	O
targets	O
can	O
be	O
found	O
in	O
the	O
supplementary	O
material	O
.	O
	
Additional	O
Experiments	O
:	O
	
In	O
preliminary	O
experiments	O
,	O
we	O
tried	O
disabling	O
weight	B-Method
tying	I-Method
across	O
different	O
time	O
steps	O
.	O
	
However	O
,	O
we	O
found	O
that	O
the	O
most	O
effective	O
way	O
to	O
increase	O
performance	O
was	O
to	O
tie	O
the	O
weights	O
and	O
use	O
a	O
larger	O
hidden	O
dimension	O
.	O
	
We	O
also	O
early	O
on	O
found	O
the	O
pair	B-Method
message	I-Method
function	I-Method
to	O
perform	O
worse	O
than	O
the	O
edge	B-Method
network	I-Method
function	I-Method
.	O
	
This	O
included	O
a	O
toy	B-Task
pathfinding	I-Task
problem	I-Task
which	O
was	O
originally	O
designed	O
to	O
benefit	O
from	O
using	O
pair	O
messages	O
.	O
	
Also	O
,	O
when	O
trained	O
jointly	O
on	O
the	O
13	O
targets	O
the	O
edge	B-Method
network	I-Method
function	I-Method
outperforms	O
pair	O
message	O
on	O
11	O
out	O
of	O
13	O
targets	O
,	O
and	O
has	O
an	O
average	O
error	B-Metric
ratio	I-Metric
of	O
1.53	O
compared	O
to	O
3.98	O
for	O
pair	B-Task
message	I-Task
.	O
	
Given	O
the	O
difficulties	O
with	O
training	O
this	O
function	O
we	O
did	O
not	O
pursue	O
it	O
further	O
.	O
	
For	O
performance	O
on	O
smaller	O
sized	O
training	O
sets	O
,	O
consult	O
the	O
supplementary	O
material	O
.	O
	
section	O
:	O
Conclusions	O
and	O
Future	O
Work	O
	
Our	O
results	O
show	O
that	O
MPNNâs	B-Method
with	O
the	O
appropriate	O
message	O
,	O
update	O
,	O
and	O
output	O
functions	O
have	O
a	O
useful	O
inductive	B-Metric
bias	I-Metric
for	O
predicting	B-Task
molecular	I-Task
properties	I-Task
,	O
outperforming	O
several	O
strong	O
baselines	O
and	O
eliminating	O
the	O
need	O
for	O
complicated	O
feature	B-Method
engineering	I-Method
.	O
	
Moreover	O
,	O
our	O
results	O
also	O
reveal	O
the	O
importance	O
of	O
allowing	O
long	O
range	O
interactions	O
between	O
nodes	O
in	O
the	O
graph	O
with	O
either	O
the	O
master	O
node	O
or	O
the	O
set2set	O
output	O
.	O
	
The	O
towers	O
variation	O
makes	O
these	O
models	O
more	O
scalable	O
,	O
but	O
additional	O
improvements	O
will	O
be	O
needed	O
to	O
scale	O
to	O
much	O
larger	O
graphs	O
.	O
	
An	O
important	O
future	O
direction	O
is	O
to	O
design	O
MPNNs	B-Method
that	O
can	O
generalize	O
effectively	O
to	O
larger	O
graphs	O
than	O
those	O
appearing	O
in	O
the	O
training	O
set	O
or	O
at	O
least	O
work	O
with	O
benchmarks	O
designed	O
to	O
expose	O
issues	O
with	O
generalization	B-Task
across	O
graph	O
sizes	O
.	O
	
Generalizing	O
to	O
larger	O
molecule	O
sizes	O
seems	O
particularly	O
challenging	O
when	O
using	O
spatial	O
information	O
.	O
	
First	O
of	O
all	O
,	O
the	O
pairwise	O
distance	O
distribution	O
depends	O
heavily	O
on	O
the	O
number	O
of	O
atoms	O
.	O
	
Second	O
,	O
our	O
most	O
successful	O
ways	O
of	O
using	O
spatial	O
information	O
create	O
a	O
fully	O
connected	O
graph	O
where	O
the	O
number	O
of	O
incoming	O
messages	O
also	O
depends	O
on	O
the	O
number	O
of	O
nodes	O
.	O
	
To	O
address	O
the	O
second	O
issue	O
,	O
we	O
believe	O
that	O
adding	O
an	O
attention	B-Method
mechanism	I-Method
over	O
the	O
incoming	O
message	O
vectors	O
could	O
be	O
an	O
interesting	O
direction	O
to	O
explore	O
.	O
	
section	O
:	O
Acknowledgements	O
	
We	O
would	O
like	O
to	O
thank	O
Lukasz	O
Kaiser	O
,	O
Geoffrey	O
Irving	O
,	O
Alex	O
Graves	O
,	O
and	O
Yujia	O
Li	O
for	O
helpful	O
discussions	O
.	O
	
Thank	O
you	O
to	O
Adrian	O
Roitberg	O
for	O
pointing	O
out	O
an	O
issue	O
with	O
the	O
use	O
of	O
partial	O
charges	O
in	O
an	O
earlier	O
version	O
of	O
this	O
paper	O
.	O
	
bibliography	O
:	O
References	O
	
section	O
:	O
Appendix	O
	
subsection	O
:	O
Interpretation	O
of	O
Laplacian	B-Method
based	I-Method
models	I-Method
as	O
MPNNs	B-Method
	
Another	O
family	O
of	O
models	O
defined	O
in	O
,	O
,	O
can	O
be	O
interpreted	O
as	O
MPNNs	B-Method
.	O
	
These	O
models	O
generalize	O
the	O
notion	O
of	O
convolutions	B-Method
a	O
general	O
graph	O
with	O
nodes	O
.	O
	
In	O
the	O
language	O
of	O
MPNNs	B-Method
,	O
these	O
models	O
tend	O
to	O
have	O
very	O
simple	O
message	B-Method
functions	I-Method
and	O
are	O
typically	O
applied	O
to	O
much	O
larger	O
graphs	O
such	O
as	O
social	O
network	O
data	O
.	O
	
We	O
closely	O
follow	O
the	O
notation	O
defined	O
in	O
equation	O
(	O
3.2	O
)	O
.	O
	
The	O
model	O
discussed	O
in	O
(	O
equation	O
5	O
)	O
and	O
can	O
be	O
viewed	O
as	O
special	O
cases	O
.	O
	
Given	O
an	O
adjacency	O
matrix	O
we	O
define	O
the	O
graph	O
Laplacian	O
to	O
be	O
where	O
is	O
the	O
diagonal	O
degree	O
matrix	O
with	O
.	O
	
Let	O
denote	O
the	O
eigenvectors	O
of	O
,	O
ordered	O
by	O
eigenvalue	O
.	O
	
Let	O
be	O
a	O
real	O
valued	O
nonlinearity	O
(	O
such	O
as	O
ReLU	B-Method
)	O
.	O
	
We	O
now	O
define	O
an	O
operation	O
which	O
transforms	O
an	O
input	O
vector	O
of	O
size	O
to	O
a	O
vector	O
of	O
size	O
(	O
the	O
full	B-Method
model	I-Method
can	O
defined	O
as	O
stacking	O
these	O
operations	O
)	O
.	O
	
Here	O
and	O
are	O
all	O
dimensional	O
vectors	O
corresponding	O
to	O
a	O
scalar	O
feature	O
at	O
each	O
node	O
.	O
	
The	O
matrices	O
are	O
all	O
diagonal	O
matrices	O
and	O
contain	O
all	O
of	O
the	O
learned	O
parameters	O
in	O
the	O
layer	O
.	O
	
We	O
now	O
expand	O
equation	O
[	O
reference	O
]	O
in	O
terms	O
of	O
the	O
full	O
vector	O
and	O
vector	O
,	O
using	O
and	O
to	O
index	O
nodes	O
in	O
the	O
graph	O
and	O
,	O
to	O
index	O
the	O
dimensions	O
of	O
the	O
node	O
states	O
.	O
	
In	O
this	O
way	O
denotes	O
the	O
’	O
th	O
dimension	O
of	O
node	O
,	O
and	O
denotes	O
the	O
’	O
th	O
dimension	O
of	O
node	O
,	O
furthermore	O
we	O
use	O
to	O
denote	O
the	O
dimensional	O
vector	O
for	O
node	O
state	O
,	O
and	O
to	O
denote	O
the	O
dimensional	O
vector	O
for	O
node	O
.	O
	
Define	O
the	O
rank	O
4	O
tensor	O
of	O
dimension	O
where	O
.	O
	
We	O
will	O
use	O
to	O
denote	O
the	O
dimensional	O
matrix	O
where	O
and	O
to	O
denote	O
the	O
dimensional	O
matrix	O
where	O
.	O
	
Writing	O
equation	O
[	O
reference	O
]	O
in	O
this	O
notation	O
we	O
have	O
Relabelling	O
as	O
and	O
as	O
this	O
last	O
line	O
can	O
be	O
interpreted	O
as	O
the	O
message	B-Task
passing	I-Task
update	I-Task
in	O
an	O
MPNN	B-Method
where	O
and	O
.	O
	
subsubsection	O
:	O
The	O
special	O
case	O
of	O
Kipf	O
and	O
Welling	O
(	O
2016	O
)	O
	
Motivated	O
as	O
a	O
first	B-Method
order	I-Method
approximation	I-Method
of	O
the	O
graph	B-Method
laplacian	I-Method
methods	I-Method
,	O
propose	O
the	O
following	O
layer	B-Method
-	I-Method
wise	I-Method
propagation	I-Method
rule	I-Method
:	O
Here	O
where	O
is	O
the	O
real	O
valued	O
adjacency	O
matrix	O
for	O
an	O
undirected	O
graph	O
.	O
	
Adding	O
the	O
identity	O
matrix	O
corresponds	O
to	O
adding	O
self	O
loops	O
to	O
the	O
graph	O
.	O
	
Also	O
denotes	O
the	O
degree	O
matrix	O
for	O
the	O
graph	O
with	O
self	O
loops	O
,	O
is	O
a	O
layer	O
-	O
specific	O
trainable	O
weight	O
matrix	O
,	O
and	O
denotes	O
a	O
real	O
valued	O
nonlinearity	O
.	O
	
Each	O
is	O
a	O
dimensional	O
matrix	O
indicating	O
the	O
dimensional	O
node	O
states	O
for	O
the	O
nodes	O
in	O
the	O
graph	O
.	O
	
In	O
what	O
follows	O
,	O
given	O
a	O
matrix	O
we	O
use	O
to	O
denote	O
the	O
row	O
in	O
indexed	O
by	O
(	O
will	O
always	O
correspond	O
to	O
a	O
node	O
in	O
the	O
graph	O
)	O
.	O
	
Let	O
.	O
	
To	O
get	O
the	O
updated	O
node	O
state	O
for	O
node	O
we	O
have	O
Relabelling	O
the	O
row	O
vector	O
as	O
an	O
dimensional	O
column	O
vector	O
the	O
above	O
equation	O
is	O
equivalent	O
to	O
which	O
is	O
equivalent	O
to	O
a	O
message	O
function	O
and	O
update	B-Method
function	I-Method
Note	O
that	O
the	O
are	O
all	O
scalar	O
valued	O
,	O
so	O
this	O
model	O
corresponds	O
to	O
taking	O
a	O
certain	O
weighted	O
average	O
of	O
neighboring	O
nodes	O
at	O
each	O
time	O
step	O
.	O
	
subsection	O
:	O
A	O
More	O
Detailed	O
Description	O
of	O
the	O
Quantum	B-Metric
Properties	I-Metric
	
First	O
there	O
the	O
four	O
atomization	O
energies	O
.	O
	
Atomization	O
energy	O
at	O
(	O
eV	O
)	O
	
:	O
This	O
is	O
the	O
energy	O
required	O
to	O
break	O
up	O
the	O
molecule	O
into	O
all	O
of	O
its	O
constituent	O
atoms	O
if	O
the	O
molecule	O
is	O
at	O
absolute	O
zero	O
.	O
	
This	O
calculation	O
assumes	O
that	O
the	O
molecules	O
are	O
held	O
at	O
fixed	O
volume	O
.	O
	
Atomization	O
energy	O
at	O
room	O
temperature	O
(	O
eV	O
)	O
:	O
	
Like	O
,	O
this	O
is	O
the	O
energy	O
required	O
to	O
break	O
up	O
the	O
molecule	O
if	O
it	O
is	O
at	O
room	O
temperature	O
.	O
	
Enthalpy	O
of	O
atomization	O
at	O
room	O
temperature	O
(	O
eV	O
)	O
:	O
The	O
enthalpy	O
of	O
atomization	B-Task
is	O
similar	O
in	O
spirit	O
to	O
the	O
energy	O
of	O
atomization	O
,	O
.	O
	
However	O
,	O
unlike	O
the	O
energy	O
this	O
calculation	O
assumes	O
that	O
the	O
constituent	O
molecules	O
are	O
held	O
at	O
fixed	O
pressure	O
.	O
	
Free	B-Metric
energy	I-Metric
of	I-Metric
atomization	I-Metric
(	O
eV	O
)	O
:	O
Once	O
again	O
this	O
is	O
similar	O
to	O
and	O
,	O
but	O
assumes	O
that	O
the	O
system	O
is	O
held	O
at	O
fixed	O
temperature	O
and	O
pressure	O
during	O
the	O
dissociation	B-Task
.	O
	
Next	O
there	O
are	O
properties	O
related	O
to	O
fundamental	O
vibrations	O
of	O
the	O
molecule	O
:	O
	
Highest	O
fundamental	O
vibrational	O
frequency	O
	
(	O
)	O
:	O
Every	O
molecule	O
has	O
fundamental	O
vibrational	O
modes	O
that	O
it	O
can	O
naturally	O
oscillate	O
at	O
.	O
	
is	O
the	O
mode	O
that	O
requires	O
the	O
most	O
energy	O
.	O
	
Zero	O
Point	O
Vibrational	O
Energy	O
(	O
ZPVE	O
)	O
(	O
eV	O
)	O
:	O
	
Even	O
at	O
zero	O
temperature	O
quantum	O
mechanical	O
uncertainty	O
implies	O
that	O
atoms	O
vibrate	O
.	O
	
This	O
is	O
known	O
as	O
the	O
zero	O
point	O
vibrational	O
energy	O
and	O
can	O
be	O
calculated	O
once	O
the	O
allowed	O
vibrational	O
modes	O
of	O
a	O
molecule	O
are	O
known	O
.	O
	
Additionally	O
,	O
there	O
are	O
a	O
number	O
of	O
properties	O
that	O
concern	O
the	O
states	O
of	O
the	O
electrons	O
in	O
the	O
molecule	O
:	O
Highest	O
Occupied	O
Molecular	O
Orbital	O
(	O
HOMO	O
)	O
(	O
eV	O
)	O
:	O
	
Quantum	O
mechanics	O
dictates	O
that	O
the	O
allowed	O
states	O
that	O
electrons	O
can	O
occupy	O
in	O
a	O
molecule	O
are	O
discrete	O
.	O
	
The	O
Pauli	O
exclusion	O
principle	O
states	O
that	O
no	O
two	O
electrons	O
may	O
occupy	O
the	O
same	O
state	O
.	O
	
At	O
zero	O
temperature	O
,	O
therefore	O
,	O
electrons	O
stack	O
in	O
states	O
from	O
lowest	O
energy	O
to	O
highest	O
energy	O
.	O
	
HOMO	O
is	O
the	O
energy	O
of	O
the	O
highest	O
occupied	O
electronic	O
state	O
.	O
	
Lowest	O
Unoccupied	O
Molecular	O
Orbital	O
(	O
LUMO	O
)	O
	
(	O
eV	O
)	O
:	O
Like	O
HOMO	O
,	O
LUMO	O
is	O
the	O
lowest	O
energy	O
electronic	O
state	O
that	O
is	O
unoccupied	O
.	O
	
Electron	O
energy	O
gap	O
(	O
eV	O
)	O
	
:	O
This	O
is	O
the	O
difference	O
in	O
energy	O
between	O
LUMO	O
and	O
HOMO	O
.	O
	
It	O
is	O
the	O
lowest	O
energy	O
transition	O
that	O
can	O
occur	O
when	O
an	O
electron	O
is	O
excited	O
from	O
an	O
occupied	O
state	O
to	O
an	O
unoccupied	O
state	O
.	O
	
also	O
dictates	O
the	O
longest	O
wavelength	O
of	O
light	O
that	O
the	O
molecule	O
can	O
absorb	O
.	O
	
Finally	O
,	O
there	O
are	O
several	O
measures	O
of	O
the	O
spatial	O
distribution	O
of	O
electrons	O
in	O
the	O
molecule	O
:	O
Electronic	O
Spatial	O
Extent	O
(	O
Bohr	O
)	O
:	O
	
The	O
electronic	O
spatial	O
extent	O
is	O
the	O
second	O
moment	O
of	O
the	O
charge	O
distribution	O
,	O
,	O
or	O
in	O
other	O
words	O
.	O
	
Norm	O
of	O
the	O
dipole	O
moment	O
(	O
Debye	O
)	O
:	O
	
The	O
dipole	O
moment	O
,	O
,	O
approximates	O
the	O
electric	O
field	O
far	O
from	O
a	O
molecule	O
.	O
	
The	O
norm	O
of	O
the	O
dipole	O
moment	O
is	O
related	O
to	O
how	O
anisotropically	O
the	O
charge	O
is	O
distributed	O
(	O
and	O
hence	O
the	O
strength	O
of	O
the	O
field	O
far	O
from	O
the	O
molecule	O
)	O
.	O
	
This	O
degree	O
of	O
anisotropy	O
is	O
in	O
turn	O
related	O
to	O
a	O
number	O
of	O
material	O
properties	O
(	O
for	O
example	O
hydrogen	O
bonding	O
in	O
water	O
causes	O
the	O
dipole	O
moment	O
to	O
be	O
large	O
which	O
has	O
a	O
large	O
effect	O
on	O
dynamics	B-Task
and	O
surface	B-Task
tension	I-Task
)	O
.	O
	
Norm	O
of	O
the	O
static	O
polarizability	O
(	O
Bohr	B-Metric
)	O
:	O
measures	O
the	O
extent	O
to	O
which	O
a	O
molecule	O
can	O
spontaneously	O
incur	O
a	O
dipole	O
moment	O
in	O
response	O
to	O
an	O
external	O
field	O
.	O
	
This	O
is	O
in	O
turn	O
related	O
to	O
the	O
degree	O
to	O
which	O
i.e.	O
Van	O
der	O
Waals	O
interactions	O
play	O
a	O
role	O
in	O
the	O
dynamics	O
of	O
the	O
medium	O
.	O
	
subsection	O
:	O
Chemical	B-Metric
Accuracy	I-Metric
and	O
DFT	B-Metric
Error	I-Metric
	
In	O
Table	O
[	O
reference	O
]	O
we	O
list	O
the	O
mean	B-Metric
absolute	I-Metric
error	I-Metric
numbers	O
for	O
chemical	B-Metric
accuracy	I-Metric
.	O
	
These	O
are	O
the	O
numbers	O
used	O
to	O
compute	O
the	O
error	B-Metric
ratios	I-Metric
of	O
all	O
models	O
in	O
the	O
tables	O
.	O
	
The	O
mean	B-Metric
absolute	I-Metric
errors	I-Metric
of	O
our	O
models	O
can	O
thus	O
be	O
calculated	O
as	O
.	O
	
We	O
also	O
include	O
some	O
estimates	O
of	O
the	O
mean	B-Metric
absolute	I-Metric
error	I-Metric
for	O
the	O
DFT	B-Task
calculation	I-Task
to	O
the	O
ground	O
truth	O
.	O
	
Both	O
the	O
estimates	O
of	O
chemical	B-Metric
accruacy	I-Metric
and	O
DFT	B-Metric
error	I-Metric
were	O
provided	O
in	O
.	O
	
subsection	O
:	O
Additional	O
Results	O
	
In	O
Table	O
[	O
reference	O
]	O
we	O
compare	O
the	O
performance	O
of	O
the	O
best	O
architecture	O
(	O
edge	B-Method
network	I-Method
+	O
set2set	O
output	O
)	O
on	O
different	O
sized	O
training	O
sets	O
.	O
	
It	O
is	O
surprising	O
how	O
data	O
efficient	O
this	O
model	O
is	O
on	O
some	O
targets	O
.	O
	
For	O
example	O
,	O
on	O
both	O
R2	O
and	O
Omega	O
our	O
models	O
are	O
equal	O
or	O
better	O
with	O
11k	O
samples	O
than	O
the	O
best	O
baseline	O
is	O
with	O
110k	O
samples	O
.	O
	
In	O
Table	O
[	O
reference	O
]	O
we	O
compare	O
the	O
performance	O
of	O
several	O
models	O
trained	O
without	O
spatial	O
information	O
.	O
	
The	O
left	O
4	O
columns	O
show	O
the	O
results	O
of	O
4	O
experiments	O
,	O
one	O
where	O
we	O
train	O
the	O
GG	B-Method
-	I-Method
NN	I-Method
model	I-Method
on	O
the	O
sparse	O
graph	O
,	O
one	O
where	O
we	O
add	O
virtual	O
edges	O
(	O
ve	O
)	O
,	O
one	O
where	O
we	O
add	O
a	O
master	O
node	O
(	O
mn	O
)	O
,	O
and	O
one	O
where	O
we	O
change	O
the	O
graph	O
level	O
output	O
to	O
a	O
set2set	O
output	O
(	O
s2s	O
)	O
.	O
	
In	O
general	O
,	O
we	O
find	O
that	O
it	O
’s	O
important	O
to	O
allow	O
the	O
model	O
to	O
capture	O
long	O
range	O
interactions	O
in	O
these	O
graphs	O
.	O
	
In	O
Table	O
[	O
reference	O
]	O
we	O
compare	O
GG	B-Method
-	I-Method
NN	I-Method
+	I-Method
towers	I-Method
+	I-Method
set2set	I-Method
output	I-Method
(	O
tow8	B-Method
)	O
vs	O
a	O
baseline	B-Method
GG	I-Method
-	I-Method
NN	I-Method
+	I-Method
set2set	I-Method
output	I-Method
(	O
GG	B-Method
-	I-Method
NN	I-Method
)	O
when	O
distance	O
bins	O
are	O
used	O
.	O
	
We	O
do	O
this	O
comparison	O
in	O
both	O
the	O
joint	B-Task
training	I-Task
regime	I-Task
(	O
j	O
)	O
and	O
when	O
training	O
one	O
model	O
per	O
target	O
(	O
i	O
)	O
.	O
	
For	O
joint	B-Task
training	I-Task
of	O
the	O
baseline	O
we	O
used	O
100	O
trials	O
with	O
as	O
well	O
as	O
200	O
trials	O
where	O
was	O
chosen	O
randomly	O
in	O
the	O
set	O
,	O
we	O
report	O
the	O
minimum	O
test	O
error	O
across	O
all	O
300	O
trials	O
.	O
	
For	O
individual	B-Task
training	I-Task
of	O
the	O
baseline	O
we	O
used	O
100	O
trials	O
where	O
was	O
chosen	O
uniformly	O
in	O
the	O
range	O
.	O
	
The	O
towers	B-Method
model	I-Method
was	O
always	O
trained	O
with	O
and	O
,	O
with	O
100	O
tuning	O
trials	O
for	O
joint	B-Method
training	I-Method
and	O
50	O
trials	O
for	O
individual	B-Task
training	I-Task
.	O
	
The	O
towers	B-Method
model	I-Method
outperforms	O
the	O
baseline	O
model	O
on	O
12	O
out	O
of	O
13	O
targets	O
in	O
both	O
individual	B-Task
and	I-Task
joint	I-Task
target	I-Task
training	I-Task
.	O
	
In	O
Table	O
[	O
reference	O
]	O
	
right	O
2	O
columns	O
compare	O
the	O
edge	B-Method
network	I-Method
(	O
enn	B-Method
)	O
with	O
the	O
pair	B-Method
message	I-Method
network	I-Method
(	O
pm	B-Method
)	O
in	O
the	O
joint	O
training	O
regime	O
(	O
j	O
)	O
.	O
	
The	O
edge	B-Method
network	I-Method
consistently	O
outperforms	O
the	O
pair	B-Method
message	I-Method
function	I-Method
across	O
most	O
targets	O
.	O
	
In	O
Table	O
[	O
reference	O
]	O
we	O
compare	O
our	O
MPNNs	B-Method
with	O
different	O
input	O
featurizations	O
.	O
	
All	O
models	O
use	O
the	O
Set2Set	O
output	O
and	O
GRU	B-Method
update	I-Method
functions	I-Method
.	O
	
The	O
no	B-Method
distance	I-Method
model	I-Method
uses	O
the	O
matrix	B-Method
multiply	I-Method
message	I-Method
function	I-Method
,	O
the	O
distance	B-Method
models	I-Method
use	O
the	O
edge	B-Method
neural	I-Method
network	I-Method
message	I-Method
function	I-Method
.	O
	
document	O
:	O
Learning	O
a	O
Discriminative	B-Method
Feature	I-Method
Network	I-Method
for	O
Semantic	B-Task
Segmentation	I-Task
	
Most	O
existing	O
methods	O
of	O
semantic	B-Task
segmentation	I-Task
still	O
suffer	O
from	O
two	O
aspects	O
of	O
challenges	O
:	O
intra	B-Metric
-	I-Metric
class	I-Metric
inconsistency	I-Metric
and	O
inter	O
-	O
class	O
indistinction	O
.	O
	
To	O
tackle	O
these	O
two	O
problems	O
,	O
we	O
propose	O
a	O
Discriminative	B-Method
Feature	I-Method
Network	I-Method
(	O
DFN	B-Method
)	O
,	O
which	O
contains	O
two	O
sub	B-Method
-	I-Method
networks	I-Method
:	O
Smooth	B-Method
Network	I-Method
and	O
Border	B-Method
Network	I-Method
.	O
	
Specifically	O
,	O
to	O
handle	O
the	O
intra	B-Task
-	I-Task
class	I-Task
inconsistency	I-Task
problem	I-Task
,	O
we	O
specially	O
design	O
a	O
Smooth	O
Network	O
with	O
Channel	B-Method
Attention	I-Method
Block	I-Method
and	O
global	B-Method
average	I-Method
pooling	I-Method
to	O
select	O
the	O
more	O
discriminative	O
features	O
.	O
	
Furthermore	O
,	O
we	O
propose	O
a	O
Border	B-Method
Network	I-Method
to	O
make	O
the	O
bilateral	O
features	O
of	O
boundary	O
distinguishable	O
with	O
deep	B-Method
semantic	I-Method
boundary	I-Method
supervision	I-Method
.	O
	
Based	O
on	O
our	O
proposed	O
DFN	B-Method
,	O
we	O
achieve	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
86.2	O
%	O
mean	B-Metric
IOU	I-Metric
on	O
PASCAL	B-Material
VOC	I-Material
2012	I-Material
and	O
80.3	O
%	O
	
mean	B-Metric
	
IOU	B-Metric
on	O
Cityscapes	B-Material
dataset	I-Material
.	O
	
figures	O
/	O
	
section	O
:	O
Introduction	O
	
Semantic	B-Task
segmentation	I-Task
is	O
a	O
fundamental	O
technique	O
for	O
numerous	O
computer	B-Task
vision	I-Task
applications	I-Task
like	O
scene	B-Task
understanding	I-Task
,	O
human	B-Task
parsing	I-Task
and	O
autonomous	B-Task
driving	I-Task
.	O
	
With	O
the	O
recent	O
development	O
of	O
the	O
convolutional	B-Method
neural	I-Method
network	I-Method
,	O
especially	O
the	O
Fully	B-Method
Convolutional	I-Method
Network	I-Method
(	O
FCN	B-Method
)	O
,	O
a	O
lot	O
of	O
great	O
work	O
such	O
as	O
have	O
obtained	O
promising	O
results	O
on	O
the	O
benchmarks	O
.	O
	
However	O
,	O
the	O
features	O
learned	O
by	O
these	O
methods	O
are	O
usually	O
not	O
discriminative	O
to	O
differentiate	O
1	O
)	O
the	O
patches	O
which	O
share	O
the	O
same	O
semantic	O
label	O
but	O
different	O
appearances	O
,	O
named	O
intra	O
-	O
class	O
inconsistency	O
as	O
shown	O
in	O
the	O
first	O
row	O
of	O
Figure	O
[	O
reference	O
]	O
;	O
2	O
)	O
the	O
two	O
adjacent	O
patches	O
which	O
have	O
different	O
semantic	O
labels	O
but	O
with	O
similar	O
appearances	O
,	O
named	O
inter	O
-	O
class	O
indistinction	O
as	O
shown	O
in	O
the	O
second	O
row	O
of	O
Figure	O
[	O
reference	O
]	O
.	O
	
To	O
address	O
these	O
two	O
challenges	O
,	O
we	O
rethink	O
the	O
semantic	B-Task
segmentation	I-Task
task	I-Task
from	O
a	O
more	O
macroscopic	O
point	O
of	O
view	O
.	O
	
In	O
this	O
way	O
,	O
we	O
regard	O
the	O
semantic	B-Task
segmentation	I-Task
as	O
a	O
task	O
to	O
assign	O
a	O
consistent	O
semantic	O
label	O
to	O
a	O
category	O
of	O
things	O
,	O
rather	O
than	O
to	O
each	O
single	O
pixel	O
.	O
	
From	O
a	O
macroscopic	O
perspective	O
,	O
regarding	O
each	O
category	O
of	O
pixels	O
as	O
a	O
whole	O
,	O
inherently	O
considers	O
both	O
intra	O
-	O
class	O
consistency	O
and	O
inter	O
-	O
class	O
variation	O
.	O
	
It	O
means	O
that	O
the	O
task	O
demands	O
discriminative	O
features	O
.	O
	
To	O
this	O
end	O
,	O
we	O
present	O
a	O
novel	O
Discriminative	B-Method
Feature	I-Method
Network	I-Method
(	O
DFN	B-Method
)	O
to	O
learn	O
the	O
feature	B-Method
representation	I-Method
which	O
considers	O
both	O
the	O
“	O
intra	B-Metric
-	I-Metric
class	I-Metric
consistency	I-Metric
”	O
and	O
the	O
“	O
inter	O
-	O
class	O
distinction	O
”	O
.	O
	
Our	O
DFN	B-Method
involves	O
two	O
components	O
:	O
Smooth	B-Method
Network	I-Method
and	O
Border	B-Method
Network	I-Method
,	O
as	O
Figure	O
[	O
reference	O
]	O
illustrates	O
.	O
	
The	O
Smooth	B-Method
Network	I-Method
is	O
designed	O
to	O
address	O
the	O
intra	B-Task
-	I-Task
class	I-Task
inconsistency	I-Task
issue	I-Task
.	O
	
To	O
learn	O
a	O
robust	B-Method
feature	I-Method
representation	I-Method
for	O
intra	B-Task
-	I-Task
class	I-Task
consistency	I-Task
,	O
we	O
usually	O
consider	O
two	O
crucial	O
factors	O
.	O
	
On	O
the	O
one	O
hand	O
,	O
we	O
need	O
multi	O
-	O
scale	O
and	O
global	O
context	O
features	O
to	O
encode	O
the	O
local	O
and	O
global	O
information	O
.	O
	
For	O
example	O
,	O
the	O
small	O
white	O
patch	O
only	O
in	O
Figure	O
[	O
reference	O
]	O
(	O
a	O
)	O
usually	O
can	O
not	O
predict	O
the	O
correct	O
category	O
due	O
to	O
the	O
lack	O
of	O
sufficient	O
context	O
information	O
.	O
	
On	O
the	O
other	O
hand	O
,	O
as	O
multi	O
-	O
scale	O
context	O
is	O
introduced	O
,	O
for	O
a	O
certain	O
scale	O
of	O
thing	O
,	O
the	O
features	O
have	O
different	O
extent	O
of	O
discrimination	O
,	O
some	O
of	O
which	O
may	O
predict	O
a	O
false	O
label	O
.	O
	
Therefore	O
,	O
it	O
is	O
necessary	O
to	O
select	O
the	O
discriminative	O
and	O
effective	O
features	O
.	O
	
Motivated	O
by	O
these	O
two	O
aspects	O
,	O
our	O
Smooth	B-Method
Network	I-Method
is	O
presented	O
based	O
on	O
the	O
U	O
-	O
shape	O
structure	O
to	O
capture	O
the	O
multi	O
-	O
scale	O
context	O
information	O
,	O
with	O
the	O
global	B-Method
average	I-Method
pooling	I-Method
to	O
capture	O
the	O
global	O
context	O
.	O
	
Also	O
,	O
we	O
propose	O
a	O
Channel	B-Method
Attention	I-Method
Block	I-Method
(	O
CAB	B-Method
)	O
,	O
which	O
utilizes	O
the	O
high	O
-	O
level	O
features	O
to	O
guide	O
the	O
selection	O
of	O
low	O
-	O
level	O
features	O
stage	O
-	O
by	O
-	O
stage	O
.	O
	
Border	B-Method
Network	I-Method
,	O
on	O
the	O
other	O
hand	O
,	O
tries	O
to	O
differentiate	O
the	O
adjacent	O
patches	O
with	O
similar	O
appearances	O
but	O
different	O
semantic	O
labels	O
.	O
	
Most	O
of	O
the	O
existing	O
approaches	O
consider	O
the	O
semantic	B-Task
segmentation	I-Task
task	I-Task
as	O
a	O
dense	B-Task
recognition	I-Task
problem	I-Task
,	O
which	O
usually	O
ignores	O
explicitly	O
modeling	O
the	O
inter	O
-	O
class	O
relationship	O
.	O
	
Consider	O
the	O
example	O
in	O
Figure	O
[	O
reference	O
]	O
	
(	O
d	O
)	O
,	O
if	O
more	O
and	O
more	O
global	O
context	O
is	O
integrated	O
into	O
the	O
classificiation	B-Method
process	I-Method
,	O
the	O
computer	O
case	O
next	O
to	O
the	O
monitor	O
can	O
be	O
easily	O
misclassified	O
as	O
a	O
monitor	O
due	O
to	O
the	O
similar	O
appearance	O
.	O
	
Thus	O
,	O
it	O
is	O
significant	O
to	O
explicitly	O
involve	O
the	O
semantic	O
boundary	O
to	O
guide	O
the	O
learning	B-Task
of	I-Task
the	I-Task
features	I-Task
.	O
	
It	O
can	O
amplify	O
the	O
variation	O
of	O
features	O
on	O
both	O
sides	O
.	O
	
In	O
our	O
Border	B-Method
Network	I-Method
,	O
we	O
integrate	O
semantic	O
boundary	O
loss	O
during	O
the	O
training	O
process	O
to	O
learn	O
the	O
discriminative	O
features	O
to	O
enlarge	O
the	O
“	O
inter	O
-	O
class	O
distinction	O
”	O
.	O
	
In	O
summary	O
,	O
there	O
are	O
four	O
contributions	O
in	O
our	O
paper	O
:	O
We	O
rethink	O
the	O
semantic	B-Task
segmentation	I-Task
task	I-Task
from	O
a	O
new	O
macroscopic	O
point	O
of	O
view	O
.	O
	
We	O
regard	O
the	O
semantic	B-Task
segmentation	I-Task
as	O
a	O
task	O
to	O
assign	O
a	O
consistent	O
semantic	O
label	O
to	O
one	O
category	O
of	O
things	O
,	O
not	O
just	O
at	O
the	O
pixel	O
level	O
.	O
	
We	O
propose	O
a	O
Discriminative	B-Method
Feature	I-Method
Network	I-Method
to	O
simultaneously	O
address	O
the	O
“	O
intra	B-Metric
-	I-Metric
class	I-Metric
consistency	I-Metric
”	I-Metric
and	O
“	O
inter	O
-	O
class	O
variation	O
”	O
issues	O
.	O
	
Experiments	O
on	O
PASCAL	B-Material
VOC	I-Material
2012	I-Material
and	O
Cityscapes	B-Material
datasets	O
validate	O
the	O
effectiveness	O
of	O
our	O
proposed	O
algorithm	O
.	O
	
We	O
present	O
a	O
Smooth	B-Method
Network	I-Method
to	O
enhance	O
the	O
intra	O
-	O
class	O
consistency	O
with	O
the	O
global	O
context	O
and	O
the	O
Channel	B-Method
Attention	I-Method
Block	I-Method
.	O
	
We	O
design	O
a	O
bottom	B-Method
-	I-Method
up	I-Method
Border	I-Method
Network	I-Method
with	O
deep	O
supervision	O
to	O
enlarge	O
the	O
variation	O
of	O
features	O
on	O
both	O
sides	O
of	O
the	O
semantic	O
boundary	O
.	O
	
This	O
can	O
also	O
refine	O
the	O
semantic	O
boundary	O
of	O
prediction	B-Task
.	O
	
section	O
:	O
Related	O
Work	O
	
Recently	O
,	O
lots	O
of	O
approaches	O
based	O
on	O
FCN	B-Method
have	O
achieved	O
high	O
performance	O
on	O
different	O
benchmarks	O
.	O
	
Most	O
of	O
them	O
are	O
still	O
constrained	O
by	O
intra	O
-	O
class	O
inconsistency	O
and	O
inter	O
-	O
class	O
indistinction	O
issues	O
.	O
	
paragraph	O
:	O
Encoder	B-Method
-	I-Method
Decoder	I-Method
:	O
	
The	O
FCN	B-Method
model	I-Method
has	O
inherently	O
encoded	O
different	O
levels	O
of	O
feature	O
.	O
	
Naturally	O
,	O
some	O
methods	O
integrate	O
them	O
to	O
refine	O
the	O
final	O
prediction	B-Task
.	O
	
This	O
branch	O
of	O
methods	O
mainly	O
consider	O
how	O
to	O
recover	O
the	O
reduced	O
spatial	O
information	O
caused	O
by	O
consecutive	O
pooling	O
operator	O
or	O
convolution	O
with	O
stride	O
.	O
	
For	O
example	O
,	O
SegNet	B-Method
utilizes	O
the	O
saved	O
pool	O
indices	O
to	O
recover	O
the	O
reduced	O
spatial	O
information	O
.	O
	
U	B-Method
-	I-Method
net	I-Method
uses	O
the	O
skip	O
connection	O
,	O
while	O
the	O
Global	B-Method
Convolutional	I-Method
Network	I-Method
adapts	O
the	O
large	O
kernel	O
size	O
.	O
	
