{"title": [{"text": "Retrieving Meaning-equivalent Sentences for Example-based Rough Translation", "labels": [], "entities": [{"text": "Retrieving Meaning-equivalent Sentences", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.9094293514887491}, {"text": "Example-based Rough Translation", "start_pos": 44, "end_pos": 75, "type": "TASK", "confidence": 0.6682480672995249}]}], "abstractContent": [{"text": "Example-based machine translation (EBMT) is a promising translation method for speech-to-speech translation because of its robust-ness.", "labels": [], "entities": [{"text": "Example-based machine translation (EBMT)", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.7755240499973297}, {"text": "speech-to-speech translation", "start_pos": 79, "end_pos": 107, "type": "TASK", "confidence": 0.7320511043071747}]}, {"text": "It retrieves example sentences similar to the input and adjusts their translations to obtain the output.", "labels": [], "entities": []}, {"text": "However, it has problems in that the performance degrades when input sentences are long and when the style of inputs and that of the example corpus are different.", "labels": [], "entities": []}, {"text": "This paper proposes a method for retrieving \"meaning-equivalent sentences\" to overcome these two problems.", "labels": [], "entities": []}, {"text": "A meaning-equivalent sentence shares the main meaning with an input despite lacking some unimportant information.", "labels": [], "entities": []}, {"text": "The translations of meaning-equivalent sentences correspond to \"rough translations.\"", "labels": [], "entities": []}, {"text": "The retrieval is based on content words, modality , and tense.", "labels": [], "entities": []}], "introductionContent": [{"text": "Speech-to-speech translation (S2ST) technologies consist of speech recognition, machine translation (MT), and speech synthesis).", "labels": [], "entities": [{"text": "Speech-to-speech translation (S2ST)", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.8328781425952911}, {"text": "speech recognition", "start_pos": 60, "end_pos": 78, "type": "TASK", "confidence": 0.7162472456693649}, {"text": "machine translation (MT)", "start_pos": 80, "end_pos": 104, "type": "TASK", "confidence": 0.8398183584213257}, {"text": "speech synthesis", "start_pos": 110, "end_pos": 126, "type": "TASK", "confidence": 0.732414186000824}]}, {"text": "The MT part receives speech texts recognized by a speech recognizer.", "labels": [], "entities": [{"text": "MT", "start_pos": 4, "end_pos": 6, "type": "TASK", "confidence": 0.9783002734184265}]}, {"text": "The nature of speech causes difficulty in translation since the styles of speech are different from those of written text and are sometimes ungrammatical).", "labels": [], "entities": [{"text": "translation", "start_pos": 42, "end_pos": 53, "type": "TASK", "confidence": 0.9796008467674255}]}, {"text": "Therefore, rule-based MT cannot translate speech accurately compared with its performance for written-style text . Example-based MT (EBMT) is one of the corpusbased machine translation methods.", "labels": [], "entities": [{"text": "MT", "start_pos": 129, "end_pos": 131, "type": "TASK", "confidence": 0.6798635125160217}, {"text": "corpusbased machine translation", "start_pos": 153, "end_pos": 184, "type": "TASK", "confidence": 0.6282230118910471}]}, {"text": "It retrieves examples similar to inputs and adjusts their translations to obtain the output.", "labels": [], "entities": []}, {"text": "EBMT is a promising method for S2ST in that it performs robust translation of ungrammatical sentences and requires far less manual work than rule-based MT.", "labels": [], "entities": [{"text": "EBMT", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8087782263755798}, {"text": "S2ST", "start_pos": 31, "end_pos": 35, "type": "TASK", "confidence": 0.9561598300933838}, {"text": "translation of ungrammatical sentences", "start_pos": 63, "end_pos": 101, "type": "TASK", "confidence": 0.8338784724473953}]}, {"text": "However, there are two problems in applying EBMT to S2ST.", "labels": [], "entities": []}, {"text": "One is that the translation accuracy drastically drops as input sentences become long.", "labels": [], "entities": [{"text": "translation", "start_pos": 16, "end_pos": 27, "type": "TASK", "confidence": 0.9392051100730896}, {"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9587365388870239}]}, {"text": "As the length of a sentence becomes long, the number of retrieved similar sentences greatly decreases.", "labels": [], "entities": []}, {"text": "This often results in no output when translating long sentences.", "labels": [], "entities": [{"text": "translating long sentences", "start_pos": 37, "end_pos": 63, "type": "TASK", "confidence": 0.8519004583358765}]}, {"text": "The other problem arises due to the differences in style between input sentences and the example corpus.", "labels": [], "entities": []}, {"text": "It is difficult to acquire a large volume of natural speech data since it requires much time and cost.", "labels": [], "entities": []}, {"text": "Therefore, we cannot avoid using a corpus with written-style text, which is different from that of natural speech.", "labels": [], "entities": []}, {"text": "This style difference makes retrieval of similar sentences difficult and degrades the performance of EBMT.", "labels": [], "entities": []}, {"text": "This paper proposes a method of retrieving sentences whose meaning is equivalent to input sentences to overcome the two problems.", "labels": [], "entities": []}, {"text": "A meaning-equivalent sentence means a sentence having the main meaning of an input sentence despite lacking some unimportant information.", "labels": [], "entities": []}, {"text": "Such a sentence can be more easily retrieved than a similar sentence, and its translation is useful enough in S2ST.", "labels": [], "entities": []}, {"text": "We call this translation strategy example-based \"rough translation.\"", "labels": [], "entities": [{"text": "rough translation", "start_pos": 49, "end_pos": 66, "type": "TASK", "confidence": 0.6837121546268463}]}, {"text": "Retrieval of meaning-equivalent sentences is based on content words, modality, and tense.", "labels": [], "entities": [{"text": "Retrieval of meaning-equivalent sentences", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.8406565338373184}]}, {"text": "This provides robustness against long inputs and in the differences in style between the input and the example corpus.", "labels": [], "entities": []}, {"text": "This advantage distinguishes our method from other translation methods.", "labels": [], "entities": []}, {"text": "We describe the difficulties in S2ST in Section 2.", "labels": [], "entities": [{"text": "S2ST", "start_pos": 32, "end_pos": 36, "type": "TASK", "confidence": 0.911830484867096}]}, {"text": "Then, we describe our purpose, features for retrieval, and retrieval method for meaning-equivalent sentences in Section 3.", "labels": [], "entities": []}, {"text": "We report an experiment comparing our method with two other methods in Section 4.", "labels": [], "entities": []}, {"text": "The experiment demonstrates the robustness of our method to length of input and the style differences between inputs and the example corpus.", "labels": [], "entities": []}], "datasetContent": [{"text": "Evaluation was carried out by judging whether retrieved sentences are meaning-equivalent to inputs.", "labels": [], "entities": []}, {"text": "It must be noted that inputs and retrieved sentences are both in Japanese.", "labels": [], "entities": []}, {"text": "We did not compare inputs and translations of retrieved sentences, since translation accuracy is a matter of the example corpus and does not concern our method.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.9695277214050293}]}, {"text": "The sentence with the highest score among retrieved sentences was taken and evaluated.", "labels": [], "entities": []}, {"text": "The sentences are marked manually as meaning-equivalent or not by a Japanese native.", "labels": [], "entities": []}, {"text": "A meaning-equivalent sentence includes all important information in the input but may lack some unimportant information.", "labels": [], "entities": []}, {"text": "shows the accuracy of the three methods with the concise and conversational style data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9993026256561279}]}, {"text": "Accuracy is defined as the ratio of the number of correctly equivalent sentences to that of total inputs.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9885850548744202}]}, {"text": "Inputs are classified into four types by their word length.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Number of Words by Sentences", "labels": [], "entities": []}, {"text": " Table 4: Statistics of the Corpora", "labels": [], "entities": [{"text": "Corpora", "start_pos": 28, "end_pos": 35, "type": "TASK", "confidence": 0.40704816579818726}]}]}