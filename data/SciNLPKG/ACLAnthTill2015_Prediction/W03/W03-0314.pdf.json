{"title": [{"text": "Learning Sequence-to-Sequence Correspondences from Parallel Corpora via Sequential Pattern Mining", "labels": [], "entities": []}], "abstractContent": [{"text": "We present an unsupervised extraction of sequence-to-sequence correspondences from parallel corpora by sequential pattern mining.", "labels": [], "entities": [{"text": "sequential pattern mining", "start_pos": 103, "end_pos": 128, "type": "TASK", "confidence": 0.6322201093037924}]}, {"text": "The main characteristics of our method are twofold.", "labels": [], "entities": []}, {"text": "First, we propose a systematic way to enumerate all possible translation pair candidates of rigid and gapped sequences without falling into combinatorial explosion.", "labels": [], "entities": []}, {"text": "Second, our method uses an efficient data structure and algorithm for calculating frequencies in a contingency table for each translation pair candidate.", "labels": [], "entities": []}, {"text": "Our method is empirically evaluated using English-Japanese parallel corpora of 6 million words.", "labels": [], "entities": []}, {"text": "Results indicate that it works well for multi-word translations, giving 56-84% accuracy at 19% token coverage and 11% type coverage.", "labels": [], "entities": [{"text": "multi-word translations", "start_pos": 40, "end_pos": 63, "type": "TASK", "confidence": 0.6359470635652542}, {"text": "accuracy", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.9992884397506714}]}], "introductionContent": [{"text": "This paper addresses the problem of identifying \"multiword\" (sequence-to-sequence) translation correspondences from parallel corpora.", "labels": [], "entities": [{"text": "identifying \"multiword\" (sequence-to-sequence) translation correspondences from parallel corpora", "start_pos": 36, "end_pos": 132, "type": "TASK", "confidence": 0.6986702183882395}]}, {"text": "It is well-known that translation does not always proceed by word-for-word.", "labels": [], "entities": [{"text": "translation", "start_pos": 22, "end_pos": 33, "type": "TASK", "confidence": 0.9748511910438538}]}, {"text": "This highlights the need for finding multi-word translation correspondences.", "labels": [], "entities": [{"text": "multi-word translation correspondences", "start_pos": 37, "end_pos": 75, "type": "TASK", "confidence": 0.7404133578141531}]}, {"text": "Previous works that focus on multi-word translation correspondences from parallel corpora include noun phrase correspondences, fixed/flexible collocations (, n-gram word sequences of arbitrary length, non-compositional compounds), captoids, and named entities . In all of these approaches, a common problem seems to bean identification of meaningful multi-word translation units.", "labels": [], "entities": [{"text": "multi-word translation correspondences", "start_pos": 29, "end_pos": 67, "type": "TASK", "confidence": 0.758254865805308}, {"text": "noun phrase correspondences", "start_pos": 98, "end_pos": 125, "type": "TASK", "confidence": 0.6433306634426117}, {"text": "identification of meaningful multi-word translation", "start_pos": 321, "end_pos": 372, "type": "TASK", "confidence": 0.7396674275398254}]}, {"text": "There area number of factors which make handling of multi-word units more complicated than it appears.", "labels": [], "entities": []}, {"text": "First, it is a many-to-many mapping which potentially leads to a combinatorial explosion.", "labels": [], "entities": []}, {"text": "Second, multiword translation units are not necessarily contiguous, so an algorithm should not be hampered by the word adjacency constraint.", "labels": [], "entities": [{"text": "multiword translation", "start_pos": 8, "end_pos": 29, "type": "TASK", "confidence": 0.7967643737792969}]}, {"text": "Third, word segmentation itself is ambiguous for non-segmented languages such as Chinese or Japanese.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 7, "end_pos": 24, "type": "TASK", "confidence": 0.7638100981712341}]}, {"text": "We need to resolve such ambiguity as well.", "labels": [], "entities": []}, {"text": "In this paper, we apply sequential pattern mining to solve the problem.", "labels": [], "entities": [{"text": "sequential pattern mining", "start_pos": 24, "end_pos": 49, "type": "TASK", "confidence": 0.6032960017522176}]}, {"text": "First, the method effectively avoids an inherent combinatorial explosion by concatenating pairs of parallel sentences into single bilingual sequences and applying a pattern mining algorithm on those sequences.", "labels": [], "entities": []}, {"text": "Second, it covers both rigid (gap-less) and gapped sequences.", "labels": [], "entities": []}, {"text": "Third, it achieves a systematic way of enumerating all possible translation pair candidates, single-or multi-word.", "labels": [], "entities": []}, {"text": "Note that some are overlapped to account for word segmentation ambiguity.", "labels": [], "entities": [{"text": "word segmentation ambiguity", "start_pos": 45, "end_pos": 72, "type": "TASK", "confidence": 0.787556787331899}]}, {"text": "Our method is balanced by a conservative discovery of translation correspondences with the rationale that direct associations will win over indirect ones, thereby resolving the ambiguity.", "labels": [], "entities": [{"text": "translation correspondences", "start_pos": 54, "end_pos": 81, "type": "TASK", "confidence": 0.9032501876354218}]}], "datasetContent": [{"text": "We evaluate our sequence-to-sequence correspondence by accuracy and coverage, which we believe, similar criteria to and 2 . Let C seq be the set of correct bilingual sequences by a human judge, S seq be the set of bilingual sequences identified by our system, C token be the multiset of items covered by C seq , T token be the multiset of items in the bilingual sequence database, C type be the set of items covered by C seq , and T type be the set of items in the bilingual sequence database.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9996114373207092}, {"text": "coverage", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9830264449119568}]}, {"text": "Then, our evaluation metrics are given by: We would like to examine how many distinct translation pairs are correctly identified (accuracy) and how well the identified subsequences can be used for partial sequence alignment in the original parallel corpora (coverage).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 130, "end_pos": 138, "type": "METRIC", "confidence": 0.9988490343093872}, {"text": "partial sequence alignment", "start_pos": 197, "end_pos": 223, "type": "TASK", "confidence": 0.6153206626574198}]}, {"text": "Since all the correct translation pairs in our parallel corpora are not annotated, the sum of true positives and false negatives remain unknown.", "labels": [], "entities": []}, {"text": "For this reason, we avoid to use evaluation terms precision and recall to emphasize the difference.", "labels": [], "entities": [{"text": "precision", "start_pos": 50, "end_pos": 59, "type": "METRIC", "confidence": 0.9991944432258606}, {"text": "recall", "start_pos": 64, "end_pos": 70, "type": "METRIC", "confidence": 0.998239278793335}]}, {"text": "There are many variations of evaluation criteria used in the literature.", "labels": [], "entities": []}, {"text": "At first, we try to use Moore's criteria to present a direct comparison.", "labels": [], "entities": []}, {"text": "Unfortunately, we are unclear about frequency for multi-words in the parallel corpora, which seems to require for the denominator of his coverage formula.", "labels": [], "entities": [{"text": "frequency", "start_pos": 36, "end_pos": 45, "type": "METRIC", "confidence": 0.973904550075531}]}, {"text": "Further, we also did not split train/test corpus for cross-validation.", "labels": [], "entities": []}, {"text": "Our method is an unsupervised learning, and the learning does not involve tuning parameters of a probabilistic model for unseen events.", "labels": [], "entities": []}, {"text": "So we believe results using entire parallel corpora give indicative material for evaluation.", "labels": [], "entities": []}, {"text": "In order to calculate accuracy, each translation pair is compared against the EDR.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9989603757858276}, {"text": "EDR", "start_pos": 78, "end_pos": 81, "type": "METRIC", "confidence": 0.7453143000602722}]}, {"text": "All the entries appeared in the dictionary were assumed to be correct.", "labels": [], "entities": []}, {"text": "The remaining list was checked by hand.", "labels": [], "entities": []}, {"text": "A human judge was asked to decide \"correct\", \"nearmiss\", or \"incorrect\" for each proposed translation pair without any reference to the surrounding context.", "labels": [], "entities": []}, {"text": "Distinction between \"nearmiss\" and \"incorrect\" is that the former includes translation pairs that are partially correct 3 . In, and 5, accuracy is given as a range from a combination of \"correct\" and \"nearmiss\" to a combination of \"nearmiss\" and \"incorrect\".", "labels": [], "entities": [{"text": "accuracy", "start_pos": 135, "end_pos": 143, "type": "METRIC", "confidence": 0.9993115663528442}]}, {"text": "Having calculated the total accuracy, accuracies for single-word translation pairs only and for multi-word translation pairs only are calculated accordingly.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.999203622341156}, {"text": "accuracies", "start_pos": 38, "end_pos": 48, "type": "METRIC", "confidence": 0.9949625730514526}]}], "tableCaptions": [{"text": " Table 2: Statistics of 150,000 parallel sentences  Japanese  English  content (token)  2,039,656 2,257,806  content (type)  47,316  57,666  functional (token) 2,660,855 1,704,189  functional (type)  1,811  386", "labels": [], "entities": []}, {"text": " Table 3: Result of Rigid Sequence Only with minsup = 3, maxpat = 3. Accuracy is given as a range from a combination  of \"correct\" and \"nearmiss\" to a combination of \"nearmiss\" and \"incorrect\". The left side of slash gives a tigher  evaluation and the right side of slash gives a looser evaluation.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.9990401864051819}]}, {"text": " Table 4: Result of Rigid Sequences Only with minsup = 10 and minsup = 5.", "labels": [], "entities": []}, {"text": " Table 5: Result of Rigid and Gapped Sequences with minsup = 10. A default projectable constraint in Figure 3 is used.", "labels": [], "entities": []}, {"text": " Table 6: Comparison between Table 4 and Table 5 with minsup = 10, maxpat = 3", "labels": [], "entities": [{"text": "minsup", "start_pos": 54, "end_pos": 60, "type": "METRIC", "confidence": 0.9717388153076172}, {"text": "maxpat", "start_pos": 67, "end_pos": 73, "type": "METRIC", "confidence": 0.9654432535171509}]}, {"text": " Table 7: Length Distribution of 171 correct Rigid multi-word Sequences Only (left) vs. Length Distribution of 112  wrong Rigid multi-word Sequences Only (right)  H H H H", "labels": [], "entities": [{"text": "Length", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9933254718780518}, {"text": "Length", "start_pos": 88, "end_pos": 94, "type": "METRIC", "confidence": 0.976496160030365}]}, {"text": " Table 8: Length Distribution of 710 correct Rigid and Gapped multi-word Sequences (left) vs. Length Distribution of  937 wrong Rigid and Gapped multi-word Sequences (right)  H H H H", "labels": [], "entities": [{"text": "Length", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9960861206054688}, {"text": "Length", "start_pos": 94, "end_pos": 100, "type": "METRIC", "confidence": 0.9783581495285034}]}]}