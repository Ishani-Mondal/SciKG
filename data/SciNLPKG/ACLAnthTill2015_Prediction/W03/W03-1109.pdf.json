{"title": [{"text": "BRIDJE over a Language Barrier: Cross-Language Information Access by Integrating Translation and Retrieval", "labels": [], "entities": [{"text": "BRIDJE", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9352812767028809}, {"text": "Integrating Translation and Retrieval", "start_pos": 69, "end_pos": 106, "type": "TASK", "confidence": 0.6797445714473724}]}], "abstractContent": [{"text": "This paper describes two new features of the BRIDJE system for cross-language information access.", "labels": [], "entities": [{"text": "cross-language information access", "start_pos": 63, "end_pos": 96, "type": "TASK", "confidence": 0.6813264787197113}]}, {"text": "The first feature is the partial disambiguation function of the Bi-directional Retriever, which can be used for search request translation in cross-language IR.", "labels": [], "entities": [{"text": "Bi-directional Retriever", "start_pos": 64, "end_pos": 88, "type": "METRIC", "confidence": 0.8314347565174103}, {"text": "search request translation", "start_pos": 112, "end_pos": 138, "type": "TASK", "confidence": 0.6528352598349253}]}, {"text": "Its advantage over a \"black-box\" machine translation approach is consistent across five test collections and across two language permutations: English-Japanese and Japanese-English.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 33, "end_pos": 52, "type": "TASK", "confidence": 0.7444186210632324}]}, {"text": "The second new feature is the Information Distiller, which performs interactive summarisation of retrieved documents based on Semantic Role Analysis.", "labels": [], "entities": [{"text": "Information Distiller", "start_pos": 30, "end_pos": 51, "type": "TASK", "confidence": 0.6635970324277878}, {"text": "summarisation of retrieved documents", "start_pos": 80, "end_pos": 116, "type": "TASK", "confidence": 0.8338769972324371}, {"text": "Semantic Role Analysis", "start_pos": 126, "end_pos": 148, "type": "TASK", "confidence": 0.7165868481000265}]}, {"text": "Our examples illustrate the usefulness of this feature, and our evaluation results show that the precision of Semantic Role Analysis is very high.", "labels": [], "entities": [{"text": "precision", "start_pos": 97, "end_pos": 106, "type": "METRIC", "confidence": 0.9995253086090088}, {"text": "Semantic Role Analysis", "start_pos": 110, "end_pos": 132, "type": "TASK", "confidence": 0.8651571472485861}]}], "introductionContent": [{"text": "Cross-Language Information Retrieval (CLIR) has received a lot of attention recently.", "labels": [], "entities": [{"text": "Cross-Language Information Retrieval (CLIR)", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.853932778040568}]}, {"text": "TREC currently studies English-Arabic IR, CLEF studies CLIR across European languages, and NTCIR studies CLIR across Asian languages.", "labels": [], "entities": [{"text": "TREC", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.792033314704895}, {"text": "English-Arabic IR", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.44335174560546875}, {"text": "NTCIR", "start_pos": 91, "end_pos": 96, "type": "DATASET", "confidence": 0.7909964919090271}]}, {"text": "As with monolingual IR, CLIR evaluations usually rely on the use of static test collections: The system accepts a source language search request and outputs a ranked list of target language documents, and this list is evaluated using metrics such as Average Precision.", "labels": [], "entities": [{"text": "Average Precision", "start_pos": 250, "end_pos": 267, "type": "METRIC", "confidence": 0.8916884064674377}]}, {"text": "However, CLIR solves only part of the Language Barrier Problem: if the user cannot express his information need in target language, then he probably cannot make much use of the retrieved documents written in the same language.", "labels": [], "entities": []}, {"text": "(If the source and target languages are reasonably similar, then the user may find such plain CLIR useful.", "labels": [], "entities": []}, {"text": "However, this is certainly not the case for pairs of disparate languages such as English and Japanese.)", "labels": [], "entities": []}, {"text": "Thus, what deserves more attention is Cross-Language Information Access (CLIA), which subsumes CLIR and provides useful information to the user in source language (e.g. ().", "labels": [], "entities": [{"text": "Cross-Language Information Access (CLIA)", "start_pos": 38, "end_pos": 78, "type": "TASK", "confidence": 0.6506075213352839}]}, {"text": "This paper describes two new features of the BRIDJE (Bi-directional Retriever/Information Distiller for Japanese and English) system) which integrates machine translation (MT) with information retrieval (IR) to support both English-Japanese (E-J) and Japanese-English (J-E) CLIA.", "labels": [], "entities": [{"text": "BRIDJE", "start_pos": 45, "end_pos": 51, "type": "METRIC", "confidence": 0.9969303011894226}, {"text": "machine translation (MT)", "start_pos": 151, "end_pos": 175, "type": "TASK", "confidence": 0.8226336121559144}]}, {"text": "The first feature is the partial disambiguation function of the Bidirectional Retriever part of BRIDJE for enhancing retrieval performance in the traditional sense.", "labels": [], "entities": [{"text": "BRIDJE", "start_pos": 96, "end_pos": 102, "type": "DATASET", "confidence": 0.5536559224128723}]}, {"text": "While most of the traditional MT-based CLIR systems use MT as a \"black box\", partial disambiguation accesses the internal data structures of a commercial MT system for search request translation so that multiple translation candidates can be used as search terms.", "labels": [], "entities": [{"text": "MT-based CLIR", "start_pos": 30, "end_pos": 43, "type": "TASK", "confidence": 0.8553969264030457}, {"text": "search request translation", "start_pos": 168, "end_pos": 194, "type": "TASK", "confidence": 0.6835233171780905}]}, {"text": "We present positive results that are consistent across five test collections (or six topic sets), and across two language permutations: English-Japanese and Japanese-English.", "labels": [], "entities": []}, {"text": "To our knowledge, BRIDJE is the first system that truly integrates MT with IR and performs well in terms of standard measures.", "labels": [], "entities": [{"text": "BRIDJE", "start_pos": 18, "end_pos": 24, "type": "METRIC", "confidence": 0.9449031352996826}, {"text": "MT", "start_pos": 67, "end_pos": 69, "type": "TASK", "confidence": 0.9818000793457031}]}, {"text": "The second new feature is the entire Information Distiller part of BRIDJE, which can provide generic or query-specific summaries of the retrieved documents, as well as their translations in source language.", "labels": [], "entities": [{"text": "BRIDJE", "start_pos": 67, "end_pos": 73, "type": "METRIC", "confidence": 0.6383938193321228}]}, {"text": "Based on Semantic Role Analysis (SRA) originally designed for enhancing retrieval performance), the Information Distiller extracts important text fragments from a retrieved document on the fly.", "labels": [], "entities": [{"text": "Semantic Role Analysis (SRA", "start_pos": 9, "end_pos": 36, "type": "TASK", "confidence": 0.7367924392223358}, {"text": "Information Distiller extracts important text fragments from a retrieved document", "start_pos": 100, "end_pos": 181, "type": "TASK", "confidence": 0.8453593343496323}]}, {"text": "Preliminary evaluations suggest that SRA can classify text fragments with very high precision, and that it is useful for efficient information access.", "labels": [], "entities": [{"text": "SRA", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.9531330466270447}, {"text": "precision", "start_pos": 84, "end_pos": 93, "type": "METRIC", "confidence": 0.9980794191360474}, {"text": "information access", "start_pos": 131, "end_pos": 149, "type": "TASK", "confidence": 0.756545901298523}]}, {"text": "We regard our Information Distiller feature as one step towards Cross-Language Question Answering.", "labels": [], "entities": [{"text": "Cross-Language Question Answering", "start_pos": 64, "end_pos": 97, "type": "TASK", "confidence": 0.7739550272623698}]}, {"text": "BRIDJE is an enhanced, fully bilingual version of the KIDS Japanese retrieval system that recently achieved the highest performances in the EnglishJapanese and Japanese monolingual IR tasks at NTCIR-3.", "labels": [], "entities": [{"text": "BRIDJE", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9749112129211426}, {"text": "NTCIR-3", "start_pos": 193, "end_pos": 200, "type": "DATASET", "confidence": 0.8473489284515381}]}, {"text": "The remainder of this paper is organised as follows: Section 2 compares some of the previous work on CLIR/CLIA with our present study.", "labels": [], "entities": [{"text": "CLIR/CLIA", "start_pos": 101, "end_pos": 110, "type": "DATASET", "confidence": 0.6578910946846008}]}, {"text": "Section 3 provides an overview of the BRIDJE system.", "labels": [], "entities": [{"text": "BRIDJE", "start_pos": 38, "end_pos": 44, "type": "DATASET", "confidence": 0.39468124508857727}]}, {"text": "Section 4 describes an extensive set of retrieval experiments that compares partial disambiguation with the black-box MT approach.", "labels": [], "entities": [{"text": "MT", "start_pos": 118, "end_pos": 120, "type": "TASK", "confidence": 0.9307653307914734}]}, {"text": "Section 5 provides examples to illustrate the advantages of the Information Distiller for efficient information access, as well as some evaluation results of SRA.", "labels": [], "entities": [{"text": "SRA", "start_pos": 158, "end_pos": 161, "type": "TASK", "confidence": 0.6937452554702759}]}, {"text": "Finally, Section 6 provides conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "This section compares partial disambiguation with traditional full disambiguation for search request translation in CLIR.", "labels": [], "entities": [{"text": "search request translation", "start_pos": 86, "end_pos": 112, "type": "TASK", "confidence": 0.6480405926704407}]}, {"text": "We used three English-Japanese test collections: NTCIR-3 E-J (, NTCIR-2 E-J () and BMIR-J2 E-J ( 1 . As BMIR-J2 E-J has two English topic sets X and Y translated from a single Japanese topic set), we Data in BMIR-J2 is taken from the Mainichi Shimbun CD-ROM 1994 data collection.", "labels": [], "entities": [{"text": "NTCIR-3 E-J", "start_pos": 49, "end_pos": 60, "type": "DATASET", "confidence": 0.7823864817619324}, {"text": "BMIR-J2", "start_pos": 83, "end_pos": 90, "type": "METRIC", "confidence": 0.8929885029792786}, {"text": "Mainichi Shimbun CD-ROM 1994 data collection", "start_pos": 234, "end_pos": 278, "type": "DATASET", "confidence": 0.9722260336081187}]}, {"text": "BMIR-J2 was constructed by the SIG Database Systems of the Information Processing Society of Japan, in collaboration with the Real World Computing Partnership.", "labels": [], "entities": [{"text": "BMIR-J2", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.52231365442276}]}, {"text": "performed four sets of E-J CLIR experiments in total.", "labels": [], "entities": []}, {"text": "On the other hand, we used two Japanese-English test collections: NTCIR-3 J-E ( and NTCIR-2 J-E (.", "labels": [], "entities": [{"text": "NTCIR-3", "start_pos": 66, "end_pos": 73, "type": "DATASET", "confidence": 0.8998205661773682}, {"text": "NTCIR-2 J-E", "start_pos": 84, "end_pos": 95, "type": "DATASET", "confidence": 0.8268015682697296}]}, {"text": "summarises the features of these five test collections.", "labels": [], "entities": []}, {"text": "As they provide multiple relevance levels, the number of relevant documents summed across topics are shown for each relevance level: S-relevant (highly relevant), A-relevant (relevant), and B-relevant (partially relevant).", "labels": [], "entities": []}, {"text": "There are no S-relevant documents for BMIR-J2.", "labels": [], "entities": [{"text": "BMIR-J2", "start_pos": 38, "end_pos": 45, "type": "DATASET", "confidence": 0.8398112058639526}]}, {"text": "Following the practice at NTCIR, we computed Mean Average Precision (MAP) based on \"relaxed\" relevance (which treats S,A and B-relevant documents as relevant) and on \"rigid\" relevance (which treats Sand A-relevant documents as relevant)).", "labels": [], "entities": [{"text": "NTCIR", "start_pos": 26, "end_pos": 31, "type": "DATASET", "confidence": 0.9194273948669434}, {"text": "Mean Average Precision (MAP)", "start_pos": 45, "end_pos": 73, "type": "METRIC", "confidence": 0.9768376251061758}]}, {"text": "In addition, for unified evaluation with multiple relevance levels, we used Average Gain Ratio (AGR).", "labels": [], "entities": [{"text": "Average Gain Ratio (AGR)", "start_pos": 76, "end_pos": 100, "type": "METRIC", "confidence": 0.9796649714310964}]}, {"text": "For testing statistical significance, we used the sign test.", "labels": [], "entities": []}, {"text": "For each test collection, full disambiguation and partial disambiguation queries were generated using the topic descriptions.", "labels": [], "entities": []}, {"text": "Although our MT system has several domain-specific dictionaries, we used the general dictionary only.", "labels": [], "entities": [{"text": "MT", "start_pos": 13, "end_pos": 15, "type": "TASK", "confidence": 0.9085298776626587}]}, {"text": "For the NTCIR-3 E-J experiment, the BM25 and PRF parameters were tuned using the dryrun topics.", "labels": [], "entities": [{"text": "NTCIR-3 E-J experiment", "start_pos": 8, "end_pos": 30, "type": "DATASET", "confidence": 0.8649536569913229}, {"text": "BM25", "start_pos": 36, "end_pos": 40, "type": "METRIC", "confidence": 0.9116206169128418}, {"text": "PRF", "start_pos": 45, "end_pos": 48, "type": "METRIC", "confidence": 0.660681426525116}]}, {"text": "For all other experiments, Okapi/BM25 defaults were used, and the number of pseudo-relevant documents and that of expansion terms were fixed to 10 and 30, respectively).", "labels": [], "entities": [{"text": "Okapi/BM25", "start_pos": 27, "end_pos": 37, "type": "DATASET", "confidence": 0.7123600641886393}]}, {"text": "summarises the results of our CLIR experiments.", "labels": [], "entities": []}, {"text": "Full disambiguation runs with and without PRF are denoted by FD+PRF and FD, while the corresponding partial disambiguation runs are denoted by PD+PRF and PD, respectively.", "labels": [], "entities": [{"text": "FD+PRF", "start_pos": 61, "end_pos": 67, "type": "METRIC", "confidence": 0.8718814253807068}, {"text": "FD", "start_pos": 72, "end_pos": 74, "type": "METRIC", "confidence": 0.9739011526107788}, {"text": "PD", "start_pos": 154, "end_pos": 156, "type": "METRIC", "confidence": 0.8951886892318726}]}, {"text": "The monolingual performances with and without PRF, denoted by ML+PRF and ML, are also shown.", "labels": [], "entities": [{"text": "ML", "start_pos": 73, "end_pos": 75, "type": "METRIC", "confidence": 0.8048356771469116}]}, {"text": "Columns (i), (ii) and (iii) show performances in MAP with relaxed relevance, MAP with rigid relevance, and Mean AGR (MAGR), respectively.", "labels": [], "entities": [{"text": "Mean AGR (MAGR)", "start_pos": 107, "end_pos": 122, "type": "METRIC", "confidence": 0.9308789253234864}]}, {"text": "Runs that significantly outperform FD are indicated by \"\ud97b\udf59\"s, while those that significantly outperform PD are indicated by \"y\"s.", "labels": [], "entities": [{"text": "FD", "start_pos": 35, "end_pos": 37, "type": "METRIC", "confidence": 0.8021498322486877}, {"text": "PD", "start_pos": 103, "end_pos": 105, "type": "METRIC", "confidence": 0.9877380132675171}]}, {"text": "For example, Table 2A Column (i) include the following information in terms of relaxed MAP: (a) PD+PRF is 8% better than FD+PRF, and significantly better than FD (\ud97b\udf59 = 0 :01)and PD (\ud97b\udf59 = 0 :05);", "labels": [], "entities": [{"text": "MAP", "start_pos": 87, "end_pos": 90, "type": "METRIC", "confidence": 0.6483348608016968}, {"text": "FD", "start_pos": 159, "end_pos": 161, "type": "METRIC", "confidence": 0.7269845604896545}, {"text": "PD", "start_pos": 177, "end_pos": 179, "type": "METRIC", "confidence": 0.8255161046981812}]}], "tableCaptions": [{"text": " Table 2: Partial disambiguation vs full disambiguation.", "labels": [], "entities": [{"text": "Partial disambiguation", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.7859151661396027}]}, {"text": " Table 3: (a)#terms per topic / (b)#out-of-vocabulary words.", "labels": [], "entities": []}, {"text": " Table 4: Per-topic comparison of Average Precision: FD vs.PD.", "labels": [], "entities": [{"text": "Average Precision", "start_pos": 34, "end_pos": 51, "type": "METRIC", "confidence": 0.7808352410793304}, {"text": "FD", "start_pos": 53, "end_pos": 55, "type": "METRIC", "confidence": 0.936951756477356}]}]}