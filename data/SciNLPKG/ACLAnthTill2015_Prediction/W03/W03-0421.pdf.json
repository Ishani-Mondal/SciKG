{"title": [{"text": "A Simple Named Entity Extractor using AdaBoost", "labels": [], "entities": [{"text": "AdaBoost", "start_pos": 38, "end_pos": 46, "type": "DATASET", "confidence": 0.8589622378349304}]}], "abstractContent": [], "introductionContent": [{"text": "This paper presents a Named Entity Extraction (NEE) system for the CoNLL-2003 shared task competition.", "labels": [], "entities": [{"text": "Named Entity Extraction (NEE)", "start_pos": 22, "end_pos": 51, "type": "TASK", "confidence": 0.7454040994246801}, {"text": "CoNLL-2003 shared task competition", "start_pos": 67, "end_pos": 101, "type": "TASK", "confidence": 0.6248623430728912}]}, {"text": "As in the past year edition), we have approached the task by treating the two main sub-tasks of the problem, recognition (NER) and classification (NEC), sequentially and independently with separate modules.", "labels": [], "entities": [{"text": "recognition (NER) and classification (NEC)", "start_pos": 109, "end_pos": 151, "type": "TASK", "confidence": 0.6850307186444601}]}, {"text": "Both modules are machine learning based systems, which make use of binary and multiclass AdaBoost classifiers.", "labels": [], "entities": []}, {"text": "Named Entity recognition is performed as a greedy sequence tagging procedure under the well-known BIO labelling scheme.", "labels": [], "entities": [{"text": "Named Entity recognition", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.6323177417119344}]}, {"text": "This tagging process makes use of three binary classifiers trained to be experts on the recognition of B, I, and O labels, respectively.", "labels": [], "entities": []}, {"text": "Named Entity classification is viewed as a 4-class classification problem (with LOC, PER, ORG, and MISC class labels), which is straightforwardly addressed by the use of a multiclass learning algorithm.", "labels": [], "entities": [{"text": "Entity classification", "start_pos": 6, "end_pos": 27, "type": "TASK", "confidence": 0.7253275662660599}, {"text": "LOC", "start_pos": 80, "end_pos": 83, "type": "METRIC", "confidence": 0.9372628927230835}, {"text": "PER", "start_pos": 85, "end_pos": 88, "type": "METRIC", "confidence": 0.9311650395393372}, {"text": "ORG", "start_pos": 90, "end_pos": 93, "type": "METRIC", "confidence": 0.8302244544029236}]}, {"text": "The system presented here consists of a replication, with some minor changes, of the system that obtained the best results in the CoNLL-2002 NEE task.", "labels": [], "entities": [{"text": "CoNLL-2002 NEE task", "start_pos": 130, "end_pos": 149, "type": "DATASET", "confidence": 0.7418995300928751}]}, {"text": "Therefore, it can be considered as a benchmark of the state-of-theart technology for the current edition, and will allow also to make comparisons about the training corpora of both editions.", "labels": [], "entities": []}], "datasetContent": [{"text": "The list of functional words for the task has been automatically constructed using the training set.", "labels": [], "entities": []}, {"text": "The lowercased words inside a NE that appeared more than 3 times were selected as functional words for the language.", "labels": [], "entities": []}, {"text": "Similarly, a gazetteer was constructed with the NEs in the training set.", "labels": [], "entities": [{"text": "NEs", "start_pos": 48, "end_pos": 51, "type": "TASK", "confidence": 0.8591158390045166}]}, {"text": "When training, only a random 40% of the entries in the gazetteer were considered.", "labels": [], "entities": []}, {"text": "Moreover, we used external knowledge in the form of a list of trigger words for NEs and an external gazetteer.", "labels": [], "entities": []}, {"text": "These knowledge sources are the same that we used in the last year competition for Spanish NEE.", "labels": [], "entities": [{"text": "Spanish NEE", "start_pos": 83, "end_pos": 94, "type": "DATASET", "confidence": 0.9180189371109009}]}, {"text": "The entries of the triggerword list were linked to the Spanish WordNet, so they have been directly translated by picking the corresponding synsets of the English WordNet.", "labels": [], "entities": [{"text": "Spanish WordNet", "start_pos": 55, "end_pos": 70, "type": "DATASET", "confidence": 0.7986040711402893}]}, {"text": "The gazetteer has been left unchanged, assuming interlinguality of most of the entries.", "labels": [], "entities": []}, {"text": "The gazetteer provided by the CoNLL-2003 organization has not been used in the work reported in this paper.", "labels": [], "entities": [{"text": "CoNLL-2003 organization", "start_pos": 30, "end_pos": 53, "type": "DATASET", "confidence": 0.9125384092330933}]}, {"text": "In all cases, a preprocess of attribute filtering was performed in order to avoid overfitting and to speed-up learning.", "labels": [], "entities": [{"text": "attribute filtering", "start_pos": 30, "end_pos": 49, "type": "TASK", "confidence": 0.7046166956424713}]}, {"text": "All features that occur less than 3 times in the training corpus were discarded.", "labels": [], "entities": []}, {"text": "For each classification problem we trained the corresponding AdaBoost classifiers, learning up to 4,000 base decision trees per classifier, with depths ranging from 1 (decision stumps) to 4.", "labels": [], "entities": []}, {"text": "The depth of the base rules and the number of rounds were directly optimized on the development set.", "labels": [], "entities": []}, {"text": "The set of unlabelled examples provided by the organization was not used in this work.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results of the BIO recognizer for the NER task", "labels": [], "entities": [{"text": "BIO recognizer", "start_pos": 25, "end_pos": 39, "type": "TASK", "confidence": 0.834994912147522}, {"text": "NER task", "start_pos": 48, "end_pos": 56, "type": "TASK", "confidence": 0.9213472008705139}]}, {"text": " Table 2: NEC accuracy on the development set assuming  a perfect recognition of named entities", "labels": [], "entities": [{"text": "NEC", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.9654759168624878}, {"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9405686259269714}]}, {"text": " Table 3: Overall results using no external knowledge", "labels": [], "entities": []}]}