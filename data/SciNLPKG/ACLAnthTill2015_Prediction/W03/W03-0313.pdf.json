{"title": [], "abstractContent": [{"text": "The term translation spotting (TS) refers to the task of identifying the target-language (TL) words that correspond to a given set of source-language (SL) words in a pair of text segments known to be mutual translations.", "labels": [], "entities": [{"text": "translation spotting (TS)", "start_pos": 9, "end_pos": 34, "type": "TASK", "confidence": 0.9314825534820557}, {"text": "identifying the target-language (TL) words that correspond to a given set of source-language (SL) words in a pair of text segments known to be mutual translations", "start_pos": 57, "end_pos": 219, "type": "Description", "confidence": 0.5761038561662039}]}, {"text": "This article examines this task within the context of a sub-sentential translation-memory system, i.e. a translation support tool capable of proposing translations for portions of a SL sentence, extracted from an archive of existing translations.", "labels": [], "entities": []}, {"text": "Different methods are proposed, based on a statistical translation model.", "labels": [], "entities": [{"text": "statistical translation", "start_pos": 43, "end_pos": 66, "type": "TASK", "confidence": 0.5867193937301636}]}, {"text": "These methods take advantage of certain characteristics of the application , to produce TL segments submitted to constraints of contiguity and composition-ality.", "labels": [], "entities": []}, {"text": "Experiments show that imposing these constraints allows important gains inaccuracy, with regard to the most probable alignments predicted by the model.", "labels": [], "entities": []}], "introductionContent": [{"text": "Translation spotting is the term coined by for the task of identifying the wordtokens in a target-language (TL) translation that correspond to some given word-tokens in a source-language (SL) text.", "labels": [], "entities": [{"text": "Translation spotting", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9208426475524902}]}, {"text": "Translation spotting (TS) takes as input a couple, i.e. a pair of SL and TL text segments, which are known to be translations of one another, and a SL query, i.e. a subset of the tokens of the SL segment, on which the TS will focus its attention.", "labels": [], "entities": [{"text": "Translation spotting (TS)", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.9357386469841004}]}, {"text": "The result of the TS process consists of two sets of tokens, i.e. one for each language.", "labels": [], "entities": [{"text": "TS process", "start_pos": 18, "end_pos": 28, "type": "TASK", "confidence": 0.8764086663722992}]}, {"text": "We call these sets the SL and TL answers to the query.", "labels": [], "entities": [{"text": "TL", "start_pos": 30, "end_pos": 32, "type": "METRIC", "confidence": 0.8677265644073486}]}, {"text": "In more formal terms: \u2022 The input to the TS process is a pair of SL and TL text segments S, T , and a contiguous, non-empty sequence of word-tokens in S, q = s i1 ...s i2 (the query).", "labels": [], "entities": []}, {"text": "\u2022 The output is a pair of sets of tokens r q (S), r q (T ), the SL answer and TL answer respectively.", "labels": [], "entities": []}, {"text": "shows some examples of TS, where the words in italics represent the SL query, and the words in bold are the SL and TL answers.", "labels": [], "entities": [{"text": "TS", "start_pos": 23, "end_pos": 25, "type": "TASK", "confidence": 0.9028034806251526}]}, {"text": "As can be seen in these examples, the tokens in the query q and answers r q (S) and r q (T ) mayor may not be contiguous (examples 2 and 3), and the TL answer may possibly be empty (example 4) when there is no satisfying way of linking TL tokens to the query.", "labels": [], "entities": []}, {"text": "Translation spotting finds different applications, for example in bilingual concordancers, such as the TransSearch system (), and example-based machine translation.", "labels": [], "entities": [{"text": "Translation spotting", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9696807265281677}, {"text": "machine translation", "start_pos": 144, "end_pos": 163, "type": "TASK", "confidence": 0.6989946067333221}]}, {"text": "In this article, we focus on a different application: a subsentential translation memory.", "labels": [], "entities": [{"text": "subsentential translation memory", "start_pos": 56, "end_pos": 88, "type": "TASK", "confidence": 0.6482077836990356}]}, {"text": "We describe this application context in section 2, and discuss how TS fits in to this type of system.", "labels": [], "entities": [{"text": "TS", "start_pos": 67, "end_pos": 69, "type": "TASK", "confidence": 0.9058807492256165}]}, {"text": "We then propose in section 3 a series of TS methods, specifically adapted to this application context.", "labels": [], "entities": [{"text": "TS", "start_pos": 41, "end_pos": 43, "type": "TASK", "confidence": 0.9474949836730957}]}, {"text": "In section 4, we present an empirical evaluation of the proposed methods.", "labels": [], "entities": []}], "datasetContent": [{"text": "We describe here a series of experiments that were carried out to evaluate the performance of the TS methods described in section 3.", "labels": [], "entities": [{"text": "TS", "start_pos": 98, "end_pos": 100, "type": "TASK", "confidence": 0.8267338275909424}]}, {"text": "We essentially identified a number of SL queries, looked up these segments in a TM to extract matching pairs of SL-TL sentences, and manually identified the TL tokens corresponding to the SL queries in each of these pairs, hence producing manual TS's.", "labels": [], "entities": []}, {"text": "We then submitted the same sentence-pairs and SL queries to each of the proposed TS methods, and measured how the TL answers produced automatically compared with those produced manually.", "labels": [], "entities": []}, {"text": "We describe this process and the results we obtained in more details below.", "labels": [], "entities": []}, {"text": "The results of our TS methods on the test corpus were compared to the reference TS, and performance was measured under different metrics.", "labels": [], "entities": []}, {"text": "Given each pair S, T from the test corpus, and the corresponding reference and evaluated TL answers r * and r, represented as sets of tokens, we computed: exactness : equal to 1 if r * = r, 0 otherwise; In all the above computations, we considered that \"empty\" TL answers (r = \u2205) actually contained a single \"null\" word.", "labels": [], "entities": [{"text": "exactness", "start_pos": 155, "end_pos": 164, "type": "METRIC", "confidence": 0.9937881827354431}]}, {"text": "These metrics were then averaged overall pairs of the test corpus (and not over SL queries, which means that more \"productive\" queries weight more heavily in the reported results).", "labels": [], "entities": []}, {"text": "We tested all three methods presented in section 3, as well as the three \"post-processings\" on Viterbi TS proposed in section 3.2.", "labels": [], "entities": [{"text": "Viterbi TS", "start_pos": 95, "end_pos": 105, "type": "DATASET", "confidence": 0.9413112103939056}]}, {"text": "All of these methods are based on IBM Model 2.", "labels": [], "entities": []}, {"text": "The same model parameters were used for all the experiments reported here, which were computed with the GIZA program of the Egypt toolkit ( The Zero-tolerance post-processing produces empty TL answers whenever the TL tokens are not contiguous.", "labels": [], "entities": [{"text": "GIZA", "start_pos": 104, "end_pos": 108, "type": "METRIC", "confidence": 0.7592934370040894}]}, {"text": "On our test corpus, over 70% of all Viterbi alignments turned out to be non-contiguous.", "labels": [], "entities": []}, {"text": "These empty TL answers were counted in the statistics above (Viterbi + Zero-tolerance row), which explains the low performance obtained with this method.", "labels": [], "entities": [{"text": "Viterbi + Zero-tolerance row)", "start_pos": 61, "end_pos": 90, "type": "METRIC", "confidence": 0.6397266268730164}]}, {"text": "In practice, the intention of Zero-tolerance post-processing is to filter out non-contiguous answers, under the hypotheses that they probably would not be usable in a TM application.: Performance of zero-tolerance filter on nonempty TL answers", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results of experiments", "labels": [], "entities": []}, {"text": " Table 2: Performance of zero-tolerance filter on non- empty TL answers", "labels": [], "entities": []}]}