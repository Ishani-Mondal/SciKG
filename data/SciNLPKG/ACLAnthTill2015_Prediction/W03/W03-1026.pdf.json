{"title": [{"text": "HowtogetaChineseName(Entity): Segmentation and Combination Issues", "labels": [], "entities": [{"text": "HowtogetaChineseName", "start_pos": 0, "end_pos": 20, "type": "DATASET", "confidence": 0.9113057851791382}]}], "abstractContent": [{"text": "When building a Chinese named entity recognition system, one must deal with certain language-specific issues such as whether the model should be based on characters or words.", "labels": [], "entities": [{"text": "Chinese named entity recognition", "start_pos": 16, "end_pos": 48, "type": "TASK", "confidence": 0.6149053275585175}]}, {"text": "While there is no unique answer to this question, we discuss in detail advantages and disadvantages of each model, identify problems in segmen-tation and suggest possible solutions, presenting our observations, analysis, and experimental results.", "labels": [], "entities": []}, {"text": "The second topic of this paper is classifier combination.", "labels": [], "entities": [{"text": "classifier combination", "start_pos": 34, "end_pos": 56, "type": "TASK", "confidence": 0.9309647977352142}]}, {"text": "We present and describe four classifiers for Chinese named entity recognition and describe various methods for combining their outputs.", "labels": [], "entities": [{"text": "Chinese named entity recognition", "start_pos": 45, "end_pos": 77, "type": "TASK", "confidence": 0.6102847754955292}]}, {"text": "The results demonstrate that classifier combination is an effective technique of improving system performance: experiments over a large annotated corpus of fine-grained entity types exhibit a 10% relative reduction in F-measure error.", "labels": [], "entities": [{"text": "F-measure error", "start_pos": 218, "end_pos": 233, "type": "METRIC", "confidence": 0.9702147543430328}]}], "introductionContent": [{"text": "Named entity (NE) recognition has drawn much attention in recent years.", "labels": [], "entities": [{"text": "Named entity (NE) recognition", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.6904364575942358}]}, {"text": "It was a designated task in a number of conferences, including the Message Understanding Conferences), the Information Retrieval and Extraction Conference, the Conferences on Natural Language Learning, and the recent Automatic Content Extraction Conference.", "labels": [], "entities": [{"text": "Information Retrieval and Extraction Conference", "start_pos": 107, "end_pos": 154, "type": "TASK", "confidence": 0.8959291815757752}, {"text": "Automatic Content Extraction Conference", "start_pos": 217, "end_pos": 256, "type": "TASK", "confidence": 0.7409040480852127}]}, {"text": "A variety of algorithms have been proposed for NE recognition.", "labels": [], "entities": [{"text": "NE recognition", "start_pos": 47, "end_pos": 61, "type": "TASK", "confidence": 0.9801405370235443}]}, {"text": "Many of these algorithms are, in principle, language-independent.", "labels": [], "entities": []}, {"text": "However, when applying these algorithms to languages such as Chinese and Japanese, we must deal with certain language-specific issues: for example, should we build a character-based model or a word-based model?", "labels": [], "entities": []}, {"text": "how do word segmentation errors affect NE recognition?", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 7, "end_pos": 24, "type": "TASK", "confidence": 0.7013402283191681}, {"text": "NE recognition", "start_pos": 39, "end_pos": 53, "type": "TASK", "confidence": 0.9235153794288635}]}, {"text": "how should word segmentation and NE recognition interact with each other?", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 11, "end_pos": 28, "type": "TASK", "confidence": 0.7579477429389954}, {"text": "NE recognition", "start_pos": 33, "end_pos": 47, "type": "TASK", "confidence": 0.9571420848369598}]}, {"text": "Besides word segmentation related issues, Chinese does not have capitalization, which is a very useful feature in identifying NEs in languages such as English, Spanish, or Dutch.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 8, "end_pos": 25, "type": "TASK", "confidence": 0.7309333384037018}, {"text": "identifying NEs", "start_pos": 114, "end_pos": 129, "type": "TASK", "confidence": 0.7267129123210907}]}, {"text": "How does the lack of features such as capitalization affect the performance?", "labels": [], "entities": []}, {"text": "In the first part of this paper, we discuss these language-specific issues in Chinese NE recognition.", "labels": [], "entities": [{"text": "Chinese NE recognition", "start_pos": 78, "end_pos": 100, "type": "TASK", "confidence": 0.6574538250764211}]}, {"text": "In particular, we use a hidden Markov model (HMM) system as an example, and discuss various issues related to applying the HMM classifier to Chinese.", "labels": [], "entities": []}, {"text": "The HMM classifier is similar to the one described in ().", "labels": [], "entities": []}, {"text": "In the second part of this paper, we investigate the combination of a set of diverse NE recognition classifiers.", "labels": [], "entities": [{"text": "NE recognition classifiers", "start_pos": 85, "end_pos": 111, "type": "TASK", "confidence": 0.8890429139137268}]}, {"text": "Four statistical classifiers are combined in the experiments, including the above-mentioned hidden Markov model classifier, a transformationbased learning classifier), a maximum entropy classifier), and a robust risk minimization classifier ( ).", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows: Section 2 describes the experiment data, Section 3 discusses specific issues related to Chinese NE recognition, Section 4 presents the four classifiers and approaches to combining these classifiers.", "labels": [], "entities": [{"text": "Chinese NE recognition", "start_pos": 141, "end_pos": 163, "type": "TASK", "confidence": 0.6507031718889872}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Performance of the character-based HMM  model, the word-based HMM model, and the class- based HMM model. (The precision, recall, and F- measure presented in this table and throughout this  paper are based on correct identification of all the  attributes of an NE, including boundary, content,  and type.)", "labels": [], "entities": [{"text": "precision", "start_pos": 120, "end_pos": 129, "type": "METRIC", "confidence": 0.9993984699249268}, {"text": "recall", "start_pos": 131, "end_pos": 137, "type": "METRIC", "confidence": 0.9964902997016907}, {"text": "F- measure", "start_pos": 143, "end_pos": 153, "type": "METRIC", "confidence": 0.9963497320810953}]}, {"text": " Table 1. The  two corpora used in the evaluation, the IBM-FBIS  corpus and the IEER corpus, differ greatly in data  size and the number of NE types. The IBM-FBIS  training data consists of 3.1 million characters and  the corresponding test data has 270,000 characters.  As we can see from the table, for both corpora, the  character-based model outperforms the word-based  model, with a lead of 3 to 5.5 in F-measure. The per- formance gap between two models is larger for the  IEER data than for the IBM-FBIS data.", "labels": [], "entities": [{"text": "IBM-FBIS  corpus", "start_pos": 55, "end_pos": 71, "type": "DATASET", "confidence": 0.8095040619373322}, {"text": "IEER corpus", "start_pos": 80, "end_pos": 91, "type": "DATASET", "confidence": 0.8592474460601807}, {"text": "F-measure", "start_pos": 408, "end_pos": 417, "type": "METRIC", "confidence": 0.9956179857254028}, {"text": "IEER data", "start_pos": 479, "end_pos": 488, "type": "DATASET", "confidence": 0.8866902887821198}]}, {"text": " Table 2: Baselines and performance of the four classifiers.", "labels": [], "entities": []}, {"text": " Table 3: Classifier combination results.", "labels": [], "entities": []}]}