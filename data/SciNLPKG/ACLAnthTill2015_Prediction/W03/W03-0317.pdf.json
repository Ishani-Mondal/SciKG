{"title": [{"text": "Acquisition of English-Chinese Transliterated Word Pairs from Parallel- Aligned Texts using a Statistical Machine Transliteration Model", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents a framework for extracting English and Chinese transliterated word pairs from parallel texts.", "labels": [], "entities": [{"text": "extracting English and Chinese transliterated word pairs from parallel texts", "start_pos": 36, "end_pos": 112, "type": "TASK", "confidence": 0.8654085516929626}]}, {"text": "The approach is based on the statistical machine transliteration model to exploit the phonetic similarities between English words and corresponding Chi-nese transliterations.", "labels": [], "entities": []}, {"text": "For a given proper noun in English, the proposed method extracts the corresponding transliterated word from the aligned text in Chinese.", "labels": [], "entities": []}, {"text": "Under the proposed approach, the parameters of the model are automatically learned from a bilingual proper name list.", "labels": [], "entities": []}, {"text": "Experimental results show that the average rates of word and character precision are 86.0% and 94.4%, respectively.", "labels": [], "entities": [{"text": "precision", "start_pos": 71, "end_pos": 80, "type": "METRIC", "confidence": 0.9468638896942139}]}, {"text": "The rates can be further improved with the addition of simple linguistic processing.", "labels": [], "entities": []}], "introductionContent": [{"text": "Automatic bilingual lexicon construction based on bilingual corpora has become an important first step for many studies and applications of natural language processing (NLP), such as machine translation (MT), crosslanguage information retrieval (CLIR), and bilingual text alignment.", "labels": [], "entities": [{"text": "Automatic bilingual lexicon construction", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.6553102061152458}, {"text": "natural language processing (NLP)", "start_pos": 140, "end_pos": 173, "type": "TASK", "confidence": 0.806853731473287}, {"text": "machine translation (MT)", "start_pos": 183, "end_pos": 207, "type": "TASK", "confidence": 0.8520429134368896}, {"text": "crosslanguage information retrieval (CLIR)", "start_pos": 209, "end_pos": 251, "type": "TASK", "confidence": 0.7951869964599609}, {"text": "bilingual text alignment", "start_pos": 257, "end_pos": 281, "type": "TASK", "confidence": 0.6438777347405752}]}, {"text": "As noted in, many previous methods () deal with this problem based on frequency of words appearing in the corpora, which cannot be effectively applied to lowfrequency words, such as transliterated words.", "labels": [], "entities": []}, {"text": "These transliterated words are often domain-specific and created frequently.", "labels": [], "entities": []}, {"text": "Many of them are not found in existing bilingual dictionaries.", "labels": [], "entities": []}, {"text": "Thus, it is difficult to handle transliteration only via simple dictionary lookup.", "labels": [], "entities": []}, {"text": "For CLIR, the accuracy of transliteration highly affects the performance of retrieval.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9982978701591492}]}, {"text": "In this paper, we present a framework of acquisition for English and Chinese transliterated word pairs based on the proposed statistical machine transliteration model.", "labels": [], "entities": []}, {"text": "Recently, much research has been done on machine transliteration for many language pairs, such as English/Arabic), English/Chinese (;), English/Japanese (, and English/Korean ().", "labels": [], "entities": []}, {"text": "Most previous approaches to machine transliteration have focused on the use of a pronunciation dictionary for converting source words into phonetic symbols, a manually assigned scoring matrix for measuring phonetic similarities between source and target words, or a method based on heuristic rules for source-to-target word transliteration.", "labels": [], "entities": []}, {"text": "However, words with unknown pronunciations may cause problems for transliteration.", "labels": [], "entities": []}, {"text": "In addition, using either a language-dependent penalty function to measure the similarity between bilingual word pairs, or handcrafted heuristic mapping rules for transliteration may lead to problems when porting to other language pairs.", "labels": [], "entities": []}, {"text": "The proposed method in this paper requires no conversion of source words into phonetic symbols.", "labels": [], "entities": []}, {"text": "The model is trained automatically on a bilingual proper name list via unsupervised learning.", "labels": [], "entities": []}, {"text": "The remainder of the paper is organized as follows: Section 2 gives an overview of machine transliteration and describes the proposed model.", "labels": [], "entities": [{"text": "machine transliteration", "start_pos": 83, "end_pos": 106, "type": "TASK", "confidence": 0.7379975914955139}]}, {"text": "Section 3 describes how to apply the model for extraction of transliterated target words from parallel texts.", "labels": [], "entities": [{"text": "extraction of transliterated target words from parallel texts", "start_pos": 47, "end_pos": 108, "type": "TASK", "confidence": 0.7711417526006699}]}, {"text": "Experimental setup and quantitative assessment of performance are presented in Section 4.", "labels": [], "entities": []}, {"text": "Concluding remarks are made in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "The corpus T0 for training consists of 2,430 pairs of English names together with their Chinese transliterations.", "labels": [], "entities": []}, {"text": "In the first experiment, we analyze the convergence characteristics of this model training based on a similarity-based framework (.", "labels": [], "entities": []}, {"text": "A validation set T1, consisting of 150 unseen person name pairs, was collected from Sinorama Magazine).", "labels": [], "entities": [{"text": "Sinorama Magazine", "start_pos": 84, "end_pos": 101, "type": "DATASET", "confidence": 0.9468023180961609}]}, {"text": "For each transliterated word in T1, a set of 1,557 proper names is used as potential answers.", "labels": [], "entities": []}, {"text": "In the second experiment, a parallel corpus T2 was prepared to evaluate the performance of proposed methods.", "labels": [], "entities": []}, {"text": "T2 consists of 500 bilingual examples from the English-Chinese version of the Longman Dictionary of Contempory English (LDOCE)).", "labels": [], "entities": [{"text": "Longman Dictionary of Contempory English (LDOCE))", "start_pos": 78, "end_pos": 127, "type": "DATASET", "confidence": 0.9347620755434036}]}, {"text": "In the first experiment, a set of source words was compared with a given target word, and then was ranked by similarity scores.", "labels": [], "entities": []}, {"text": "The source word with the highest similarity score is chosen as the answer to the backtransliteration problem.", "labels": [], "entities": []}, {"text": "The performance is evaluated by rates of the Average Rank (AR) and the Average Reciprocal Rank (ARR) following.", "labels": [], "entities": [{"text": "Average Rank (AR)", "start_pos": 45, "end_pos": 62, "type": "METRIC", "confidence": 0.9773258090019226}, {"text": "Average Reciprocal Rank (ARR)", "start_pos": 71, "end_pos": 100, "type": "METRIC", "confidence": 0.964860717455546}]}, {"text": "where N is the number of testing data, and R(i) is the rank of the i-th testing data.", "labels": [], "entities": [{"text": "R(i)", "start_pos": 43, "end_pos": 47, "type": "METRIC", "confidence": 0.9167494475841522}]}, {"text": "Higher values of ARR indicate better performance.", "labels": [], "entities": [{"text": "ARR", "start_pos": 17, "end_pos": 20, "type": "METRIC", "confidence": 0.9981532692909241}]}, {"text": "In, we show the rates of AR and ARR for the validation set T1 by varying the number of iterations of the EM training algorithm from 1 to 6.", "labels": [], "entities": [{"text": "AR", "start_pos": 25, "end_pos": 27, "type": "METRIC", "confidence": 0.9973942041397095}, {"text": "ARR", "start_pos": 32, "end_pos": 35, "type": "METRIC", "confidence": 0.9724889397621155}]}, {"text": "We note that the rates become saturated at the 2nd iteration, which indicates the efficiency of the proposed training approach.", "labels": [], "entities": []}, {"text": "As for the second experiment, performance on the extraction of transliterations is evaluated based on precision and recall rates on the word and character level.", "labels": [], "entities": [{"text": "extraction of transliterations", "start_pos": 49, "end_pos": 79, "type": "TASK", "confidence": 0.8108820915222168}, {"text": "precision", "start_pos": 102, "end_pos": 111, "type": "METRIC", "confidence": 0.9994139671325684}, {"text": "recall", "start_pos": 116, "end_pos": 122, "type": "METRIC", "confidence": 0.9981918931007385}]}, {"text": "Since we consider exact one proper name in the source language and one transliteration in the target language at a time.", "labels": [], "entities": []}, {"text": "The word recall rates are same as word precision rates: For the purpose of easier evaluation, T2 was designed to contain exact one proper name in the source language and one transliteration in the target language for each bilingual example.", "labels": [], "entities": [{"text": "recall", "start_pos": 9, "end_pos": 15, "type": "METRIC", "confidence": 0.8566634654998779}, {"text": "precision", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.7925401329994202}]}, {"text": "Therefore, if more than one proper name occurs in a bilingual example, we separate them into several testing examples.", "labels": [], "entities": []}, {"text": "We also separate a compound proper name in one example into individual names to form multiple examples.", "labels": [], "entities": []}, {"text": "For example, in the first case, two proper names \"Tchaikovsky\" and \"Stravinsky\" were found in the testing sample \"Tchaikovsky and Stravinsky each wrote several famous ballets\".", "labels": [], "entities": []}, {"text": "In the second case, a compound proper name \"Cyril Tourneur\" was found in \"No one knows who wrote that play, but it is usually ascribed to Cyril Tourneur\".", "labels": [], "entities": []}, {"text": "However, in the third case, \"New York\" is transliterated as a whole Chinese word \"\u7d10\u7d04\", so it cannot be separated into two words.", "labels": [], "entities": []}, {"text": "Therefore, the testing data for the above examples will be semi-automatically constructed.", "labels": [], "entities": []}, {"text": "For simplicity, we considered each proper name in the source sentence in turn and determined its corresponding transliteration independently.", "labels": [], "entities": []}, {"text": "shows some examples of the testing set T2.", "labels": [], "entities": []}, {"text": "In the experiment of transliterated word extraction, the proposed method achieves on average 86.0% word accuracy rate, 94.4% character precision rate, and 96.3% character recall rate, as shown in row 1 of.", "labels": [], "entities": [{"text": "word extraction", "start_pos": 36, "end_pos": 51, "type": "TASK", "confidence": 0.7081460207700729}, {"text": "accuracy rate", "start_pos": 104, "end_pos": 117, "type": "METRIC", "confidence": 0.9387194514274597}, {"text": "precision rate", "start_pos": 135, "end_pos": 149, "type": "METRIC", "confidence": 0.9266771972179413}, {"text": "recall rate", "start_pos": 171, "end_pos": 182, "type": "METRIC", "confidence": 0.9619453847408295}]}, {"text": "The performance can be further improved with a simple statistical and linguistic processing, as shown in..", "labels": [], "entities": []}, {"text": "The experimental results of transliterated word extraction for T2.", "labels": [], "entities": [{"text": "transliterated word extraction", "start_pos": 28, "end_pos": 58, "type": "TASK", "confidence": 0.6332758863766988}]}], "tableCaptions": [{"text": " Table  2. The performance can be further improved with a sim- ple statistical and linguistic processing, as shown in", "labels": [], "entities": []}, {"text": " Table 2. The experimental results of transliter- ated word extraction for T2.", "labels": [], "entities": [{"text": "transliter- ated word extraction", "start_pos": 38, "end_pos": 70, "type": "TASK", "confidence": 0.5744841396808624}]}]}