{"title": [{"text": "TREQ-AL: A word alignment system with limited language resources", "labels": [], "entities": [{"text": "TREQ-AL", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.5043618679046631}, {"text": "word alignment", "start_pos": 11, "end_pos": 25, "type": "TASK", "confidence": 0.7716086506843567}]}], "abstractContent": [{"text": "We provide a rather informal presentation of a prototype system for word alignment based on our previous translation equivalence approach, discuss the problems encountered in the shared-task on word-aligning of a parallel Romanian-English text, present the preliminary evaluation results and suggest further ways of improving the alignment accuracy.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 68, "end_pos": 82, "type": "TASK", "confidence": 0.8170822262763977}, {"text": "accuracy", "start_pos": 340, "end_pos": 348, "type": "METRIC", "confidence": 0.985687792301178}]}], "introductionContent": [{"text": "In () we largely described our extractor of translation equivalents, called TREQ.", "labels": [], "entities": [{"text": "TREQ", "start_pos": 76, "end_pos": 80, "type": "METRIC", "confidence": 0.8136935234069824}]}, {"text": "It was aimed at building translation dictionaries from parallel corpora.", "labels": [], "entities": []}, {"text": "We described in ( how this program is used in word clustering and in checking out the validity of the cross-lingual links between the monolingual wordnets of the multilingual Balkanet lexical ontology (.", "labels": [], "entities": [{"text": "word clustering", "start_pos": 46, "end_pos": 61, "type": "TASK", "confidence": 0.7690993547439575}]}, {"text": "In this paper we describe the TREQ-AL system, which builds on TREQ and aims at generating a word-alignment map fora parallel text (a bitext).", "labels": [], "entities": []}, {"text": "TREQ-AL was builtin less than two weeks for the Shared Task proposed by the organizers of the workshop on \"Building and Using Parallel Texts:Data Driven Machine Translation and Beyond\" at the HLT-NAACL 2003 conference.", "labels": [], "entities": [{"text": "Data Driven Machine Translation", "start_pos": 141, "end_pos": 172, "type": "TASK", "confidence": 0.62616266310215}, {"text": "HLT-NAACL 2003 conference", "start_pos": 192, "end_pos": 217, "type": "DATASET", "confidence": 0.8380353450775146}]}, {"text": "It can be improved in several ways that became conspicuous when we analyzed the evaluation results.", "labels": [], "entities": []}, {"text": "TREQ-AL has no need for an a priori bilingual dictionary, as this will be automatically extracted by TREQ.", "labels": [], "entities": [{"text": "TREQ-AL", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.914792537689209}, {"text": "TREQ", "start_pos": 101, "end_pos": 105, "type": "DATASET", "confidence": 0.7984654903411865}]}, {"text": "However, if such a dictionary is available, both TREQ and TREQ-AL know to make best use of it.", "labels": [], "entities": [{"text": "TREQ", "start_pos": 49, "end_pos": 53, "type": "METRIC", "confidence": 0.852356493473053}, {"text": "TREQ-AL", "start_pos": 58, "end_pos": 65, "type": "METRIC", "confidence": 0.7679758667945862}]}, {"text": "This ability allows both systems to work in a bootstrapping mode and to produce larger dictionaries and better alignments as they are used.", "labels": [], "entities": []}, {"text": "The word alignment, as it was defined in the shared task is different and harder than the problem of translation equivalence as previously addressed.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.7429549396038055}, {"text": "translation equivalence", "start_pos": 101, "end_pos": 124, "type": "TASK", "confidence": 0.9125775396823883}]}, {"text": "Ina dictionary extraction task one translation pair is considered correct, if there is at least one context in which it has been rightly observed.", "labels": [], "entities": [{"text": "dictionary extraction", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.6985166072845459}]}, {"text": "A multiply occurring pair would count only once for the final 1 http://www.cs.unt.edu/~rada/wpt/index.html#shared dictionary.", "labels": [], "entities": []}, {"text": "This is in sharp contrast with the alignment task where each occurrence of the same pair equally counts.", "labels": [], "entities": [{"text": "alignment task", "start_pos": 35, "end_pos": 49, "type": "TASK", "confidence": 0.869645893573761}]}, {"text": "Another differentiating feature between the two tasks is the status of functional word links.", "labels": [], "entities": []}, {"text": "In extracting translation equivalents one is usually interested only in the major categories (open classes).", "labels": [], "entities": [{"text": "extracting translation equivalents", "start_pos": 3, "end_pos": 37, "type": "TASK", "confidence": 0.9230859676996866}]}, {"text": "In our case (because of the WordNet centered approach of our current projects) we were especially interested in POSpreserving translation equivalents.", "labels": [], "entities": [{"text": "POSpreserving translation equivalents", "start_pos": 112, "end_pos": 149, "type": "TASK", "confidence": 0.8979538281758627}]}, {"text": "However, since in EuroWordNet and Balkanet one can define cross-POS links, the different POS translation equivalents became of interest (provided these categories are major ones).", "labels": [], "entities": [{"text": "EuroWordNet", "start_pos": 18, "end_pos": 29, "type": "DATASET", "confidence": 0.9751825332641602}, {"text": "Balkanet", "start_pos": 34, "end_pos": 42, "type": "DATASET", "confidence": 0.8754523396492004}]}, {"text": "The word alignment task requires each word (irrespective of its POS) or punctuation mark in both parts of the bitext be assigned a translation in the other part (or the null translation if the case).", "labels": [], "entities": [{"text": "word alignment task", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.8241312702496847}]}, {"text": "Finally, the evaluations of the two tasks, even if both use the same measures as precision or recall, have to be differently judged.", "labels": [], "entities": [{"text": "precision", "start_pos": 81, "end_pos": 90, "type": "METRIC", "confidence": 0.9992357492446899}, {"text": "recall", "start_pos": 94, "end_pos": 100, "type": "METRIC", "confidence": 0.9794229865074158}]}, {"text": "The null alignments in a dictionary extraction task have no significance, while in a word alignment task they play an important role (in the Romanian-English gold standard data the null alignments represent 13,35% of the total number of links).", "labels": [], "entities": [{"text": "dictionary extraction task", "start_pos": 25, "end_pos": 51, "type": "TASK", "confidence": 0.785043478012085}, {"text": "word alignment task", "start_pos": 85, "end_pos": 104, "type": "TASK", "confidence": 0.7936182121435801}, {"text": "Romanian-English gold standard data", "start_pos": 141, "end_pos": 176, "type": "DATASET", "confidence": 0.7371287122368813}]}], "datasetContent": [{"text": "The results of the evaluation of TREQ-AL performance are shown in the Table 1.", "labels": [], "entities": [{"text": "TREQ-AL", "start_pos": 33, "end_pos": 40, "type": "METRIC", "confidence": 0.9285274744033813}]}, {"text": "In our submission file the sentence no.", "labels": [], "entities": []}, {"text": "221 was left out by (our) mistake.", "labels": [], "entities": []}, {"text": "We used the official evaluation program to re-evaluate our submission with the omitted sentence included and the precision improved with 0,09%, recall with 0,45%, Fmeasure and AER with 0,33%.).", "labels": [], "entities": [{"text": "precision", "start_pos": 113, "end_pos": 122, "type": "METRIC", "confidence": 0.9997699856758118}, {"text": "recall", "start_pos": 144, "end_pos": 150, "type": "METRIC", "confidence": 0.999774158000946}, {"text": "Fmeasure", "start_pos": 163, "end_pos": 171, "type": "METRIC", "confidence": 0.9960619807243347}, {"text": "AER", "start_pos": 176, "end_pos": 179, "type": "METRIC", "confidence": 0.9988508224487305}]}, {"text": "The figures in the first and second columns of the are those considered by the official evaluation.", "labels": [], "entities": []}, {"text": "The last column contains the evaluation of the result that was our main target.", "labels": [], "entities": []}, {"text": "Since TREQ-AL produces only \"sure\" links, AER (alignment error rate -see the Shared Task web-page for further details) reduces to 1 -F-measure.", "labels": [], "entities": [{"text": "TREQ-AL", "start_pos": 6, "end_pos": 13, "type": "METRIC", "confidence": 0.7400674819946289}, {"text": "AER", "start_pos": 42, "end_pos": 45, "type": "METRIC", "confidence": 0.9995181560516357}, {"text": "alignment error rate -", "start_pos": 47, "end_pos": 69, "type": "METRIC", "confidence": 0.9387708753347397}, {"text": "F-measure", "start_pos": 133, "end_pos": 142, "type": "METRIC", "confidence": 0.7667333483695984}]}, {"text": "TREQ-AL uses no external bilingual-resources.", "labels": [], "entities": [{"text": "TREQ-AL", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.777140736579895}]}, {"text": "A machine-readable bilingual dictionary would certainly improve the overall performance.", "labels": [], "entities": []}, {"text": "The present version of the system (which is far from being finalized) seems to work pretty well on the non-null assignments and this is not surprising, because these links are supposed to be relevant fora translation dictionary extraction system and this was the very reason we developed TREQ.", "labels": [], "entities": [{"text": "translation dictionary extraction", "start_pos": 205, "end_pos": 238, "type": "TASK", "confidence": 0.7743200659751892}]}, {"text": "Moreover if we consider only the content words (main categories: noun, verbs, adjectives and general adverbs), which are the most relevant with respect to our immediate goals (multilingual wordnets interlinking and word sense disambiguation), we think TREQ-AL performs reasonably well and is worth further improving it.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 215, "end_pos": 240, "type": "TASK", "confidence": 0.625364770491918}, {"text": "TREQ-AL", "start_pos": 252, "end_pos": 259, "type": "METRIC", "confidence": 0.5544785857200623}]}], "tableCaptions": []}