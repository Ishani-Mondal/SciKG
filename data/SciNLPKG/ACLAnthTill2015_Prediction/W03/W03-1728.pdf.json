{"title": [{"text": "Chinese Word Segmentation as LMR Tagging", "labels": [], "entities": [{"text": "Chinese Word Segmentation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.575731893380483}, {"text": "LMR Tagging", "start_pos": 29, "end_pos": 40, "type": "TASK", "confidence": 0.6194807887077332}]}], "abstractContent": [{"text": "In this paper we present Chinese word segmentation algorithms based on the so-called LMR tagging.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 25, "end_pos": 50, "type": "TASK", "confidence": 0.5857559343179067}, {"text": "LMR tagging", "start_pos": 85, "end_pos": 96, "type": "TASK", "confidence": 0.6977296620607376}]}, {"text": "Our LMR taggers are implemented with the Maximum En-tropy Markov Model and we then use Transformation-Based Learning to combine the results of the two LMR taggers that scan the input in opposite directions.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "We conducted closed track experiments on three data sources: the Academia Sinica (AS) corpus, the Beijing University (PKU) corpus and the Hong Kong City University (CityU) corpus.", "labels": [], "entities": [{"text": "Academia Sinica (AS) corpus", "start_pos": 65, "end_pos": 92, "type": "DATASET", "confidence": 0.5444679210583369}, {"text": "Beijing University (PKU) corpus", "start_pos": 98, "end_pos": 129, "type": "DATASET", "confidence": 0.6345771799484888}, {"text": "Hong Kong City University (CityU) corpus", "start_pos": 138, "end_pos": 178, "type": "DATASET", "confidence": 0.6618418991565704}]}, {"text": "We first split the training data from each of the three sources into two portions.", "labels": [], "entities": []}, {"text": "\u00a7 \u0087 \u00a4 \u00a8 c of the official training data is used to train the MEMM taggers, and the other\u00a8d other\u00a8 other\u00a8d \u0087 \u00a4 \u00a8 c is held out as the development test data (the development set).", "labels": [], "entities": [{"text": "MEMM taggers", "start_pos": 61, "end_pos": 73, "type": "TASK", "confidence": 0.7077440023422241}]}, {"text": "The development set is used to estimate the optimal number of iterations in the MEMM training., and show the curves of F-scores on the development set with respect to the number of iterations in MEMM training.", "labels": [], "entities": [{"text": "MEMM training.", "start_pos": 80, "end_pos": 94, "type": "TASK", "confidence": 0.6919609308242798}, {"text": "F-scores", "start_pos": 119, "end_pos": 127, "type": "METRIC", "confidence": 0.979357123374939}]}, {"text": "achieve the best results after 500 and 400 rounds (iterations) of training on the AS data and the PKU data respectively.", "labels": [], "entities": [{"text": "AS", "start_pos": 82, "end_pos": 84, "type": "METRIC", "confidence": 0.9648140072822571}, {"text": "PKU data", "start_pos": 98, "end_pos": 106, "type": "DATASET", "confidence": 0.9467355906963348}]}, {"text": "However, the results on the CityU data is not very clear.", "labels": [], "entities": [{"text": "CityU data", "start_pos": 28, "end_pos": 38, "type": "DATASET", "confidence": 0.9875960052013397}]}, {"text": "From Round 100 through 200, the F-score on the development set almost stays unchanged.", "labels": [], "entities": [{"text": "F-score", "start_pos": 32, "end_pos": 39, "type": "METRIC", "confidence": 0.9985681772232056}]}, {"text": "We think this is because the CityU data is from three different sources, which differ in the optimal number of iterations.", "labels": [], "entities": [{"text": "CityU data", "start_pos": 29, "end_pos": 39, "type": "DATASET", "confidence": 0.9735599160194397}]}, {"text": "We decided to train the MEMM taggers for 160 iterations the HK City University data.", "labels": [], "entities": [{"text": "MEMM taggers", "start_pos": 24, "end_pos": 36, "type": "TASK", "confidence": 0.6597631275653839}, {"text": "HK City University data", "start_pos": 60, "end_pos": 83, "type": "DATASET", "confidence": 0.9894829094409943}]}, {"text": "We implemented two MEMM taggers, one scans the input from left to right and one from right to left.", "labels": [], "entities": [{"text": "MEMM taggers", "start_pos": 19, "end_pos": 31, "type": "TASK", "confidence": 0.7540838122367859}]}, {"text": "We then used these two MEMM taggers to tag both the training and the development data.", "labels": [], "entities": [{"text": "MEMM taggers", "start_pos": 23, "end_pos": 35, "type": "TASK", "confidence": 0.689542829990387}]}, {"text": "We use the LMR tagging output to train a TransformationBased learner, using fast TBL).", "labels": [], "entities": [{"text": "LMR tagging", "start_pos": 11, "end_pos": 22, "type": "TASK", "confidence": 0.6329723298549652}]}, {"text": "The middle in shows the F-score on the development set achieved by the MEMM tagger that scans the input from left to right and the last column is the results after the TransformationBased Learner is applied.", "labels": [], "entities": [{"text": "F-score", "start_pos": 24, "end_pos": 31, "type": "METRIC", "confidence": 0.9982900023460388}]}, {"text": "The results show that using Transformation-Based learning only give rise to slight improvements.", "labels": [], "entities": []}, {"text": "It seems that the bidirectional approach does not help much for the LMR tagging.", "labels": [], "entities": [{"text": "LMR tagging", "start_pos": 68, "end_pos": 79, "type": "TASK", "confidence": 0.9216130971908569}]}, {"text": "Therefore, we only submitted the results of our leftto-right MEMM tagger, retrained on the entire training sets, as our official results.", "labels": [], "entities": [{"text": "MEMM tagger", "start_pos": 61, "end_pos": 72, "type": "TASK", "confidence": 0.6162800043821335}]}, {"text": "The results on the official test data is similar to what we have got on our development set, except that the F-score on the Beijing Univ. corpus is over 2 \u00a6 lower in absolute accuracy than what we expected.", "labels": [], "entities": [{"text": "F-score", "start_pos": 109, "end_pos": 116, "type": "METRIC", "confidence": 0.9970952272415161}, {"text": "Beijing Univ. corpus", "start_pos": 124, "end_pos": 144, "type": "DATASET", "confidence": 0.9797128438949585}, {"text": "accuracy", "start_pos": 175, "end_pos": 183, "type": "METRIC", "confidence": 0.9214147925376892}]}, {"text": "The reason is that in the training data of Beijing University corpus, all the numbers are encoded in GBK, while in the test data many numbers are encoded in ASCII, which are unknown to our tagger.", "labels": [], "entities": [{"text": "Beijing University corpus", "start_pos": 43, "end_pos": 68, "type": "DATASET", "confidence": 0.9599851767222086}, {"text": "GBK", "start_pos": 101, "end_pos": 104, "type": "DATASET", "confidence": 0.5712438225746155}]}, {"text": "With this problem fixed, the results of the official test data are compatible with the results on our development set.", "labels": [], "entities": []}, {"text": "However, we have withdrawn our segmentation results on the Beijing University corpus.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 31, "end_pos": 43, "type": "TASK", "confidence": 0.9627451300621033}, {"text": "Beijing University corpus", "start_pos": 59, "end_pos": 84, "type": "DATASET", "confidence": 0.9833027323087057}]}], "tableCaptions": [{"text": " Table 2: F-score on development data", "labels": [], "entities": [{"text": "F-score", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.998649537563324}]}]}