{"title": [{"text": "Extracting Multiword Expressions with A Semantic Tagger", "labels": [], "entities": [{"text": "Extracting Multiword Expressions", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8266041080156962}, {"text": "Semantic Tagger", "start_pos": 40, "end_pos": 55, "type": "TASK", "confidence": 0.7336814105510712}]}], "abstractContent": [{"text": "Automatic extraction of multiword expressions (MWE) presents a tough challenge for the NLP community and corpus linguistics.", "labels": [], "entities": [{"text": "Automatic extraction of multiword expressions (MWE)", "start_pos": 0, "end_pos": 51, "type": "TASK", "confidence": 0.8625539280474186}]}, {"text": "Although various statistically driven or knowledge based approaches have been proposed and tested, efficient MWE extraction still remains an unsolved issue.", "labels": [], "entities": [{"text": "MWE extraction", "start_pos": 109, "end_pos": 123, "type": "TASK", "confidence": 0.9949617683887482}]}, {"text": "In this paper, we present our research work in which we tested approaching the MWE issue using a semantic field annotator.", "labels": [], "entities": [{"text": "approaching the MWE issue", "start_pos": 63, "end_pos": 88, "type": "TASK", "confidence": 0.6564674153923988}]}, {"text": "We use an English semantic tagger (USAS) developed at Lancaster University to identify multiword units which depict single semantic concepts.", "labels": [], "entities": [{"text": "English semantic tagger (USAS)", "start_pos": 10, "end_pos": 40, "type": "TASK", "confidence": 0.6305510103702545}]}, {"text": "The Meter Corpus (Gaizauskas et al., 2001; Clough et al., 2002) builtin Sheffield was used to evaluate our approach.", "labels": [], "entities": [{"text": "Meter Corpus (Gaizauskas et al., 2001; Clough et al., 2002) builtin Sheffield", "start_pos": 4, "end_pos": 81, "type": "DATASET", "confidence": 0.8812509512200075}]}, {"text": "In our evaluation, this approach extracted a total of 4,195 MWE candidates, of which, after manual checking, 3,792 were accepted as valid MWEs, producing a precision of 90.39% and an estimated recall of 39.38%.", "labels": [], "entities": [{"text": "precision", "start_pos": 156, "end_pos": 165, "type": "METRIC", "confidence": 0.9991816878318787}, {"text": "recall", "start_pos": 193, "end_pos": 199, "type": "METRIC", "confidence": 0.9996606111526489}]}, {"text": "Of the accepted MWEs, 68.22% or 2,587 are low frequency terms, occurring only once or twice in the corpus.", "labels": [], "entities": []}, {"text": "These results show that our approach provides a practical solution to MWE extraction.", "labels": [], "entities": [{"text": "MWE extraction", "start_pos": 70, "end_pos": 84, "type": "TASK", "confidence": 0.9933133125305176}]}], "introductionContent": [], "datasetContent": [{"text": "In order to test our approach of extracting MWEs using semantic information, we first tagged the newspaper part of the METER Corpus with the USAS tagger.", "labels": [], "entities": [{"text": "extracting MWEs", "start_pos": 33, "end_pos": 48, "type": "TASK", "confidence": 0.750946044921875}, {"text": "newspaper part of the METER Corpus", "start_pos": 97, "end_pos": 131, "type": "DATASET", "confidence": 0.762492169936498}, {"text": "USAS tagger", "start_pos": 141, "end_pos": 152, "type": "DATASET", "confidence": 0.9545753300189972}]}, {"text": "We then collected the multiword units assigned as a single semantic unit.", "labels": [], "entities": []}, {"text": "Finally, we manually checked the results.", "labels": [], "entities": []}, {"text": "The Meter Corpus chosen as the test data is a collection of court reports from the British Press Association (PA) and some leading British newspapers).", "labels": [], "entities": [{"text": "Meter Corpus", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.7131275683641434}, {"text": "British Press Association (PA)", "start_pos": 83, "end_pos": 113, "type": "DATASET", "confidence": 0.9575583835442861}]}, {"text": "In our experiment, we used the newspaper part of the corpus containing 774 articles with more than 250,000 words.", "labels": [], "entities": []}, {"text": "It provides a homogeneous corpus (in the sense that the reports come from a restricted domain of court events) and is thus a good source from which to extract domain-specific MWEs.", "labels": [], "entities": []}, {"text": "Another reason for choosing this corpus is that it has not been used in training the USAS system.", "labels": [], "entities": [{"text": "USAS system", "start_pos": 85, "end_pos": 96, "type": "DATASET", "confidence": 0.9566476345062256}]}, {"text": "As an open test, we assume the results of the experiment should reflect true capability of our approach for real-life applications.", "labels": [], "entities": []}, {"text": "The current USAS tagger may assign multiple possible semantic tags fora term when it fails to disambiguate between them.", "labels": [], "entities": [{"text": "USAS tagger", "start_pos": 12, "end_pos": 23, "type": "DATASET", "confidence": 0.8472854793071747}]}, {"text": "As mentioned previously, the first one denotes the most likely semantic field of the term.", "labels": [], "entities": []}, {"text": "Therefore, in our experiment we chose the first tag when such situations arose.", "labels": [], "entities": []}, {"text": "A major problem we faced in our experiment is the definition of a MWE.", "labels": [], "entities": []}, {"text": "Although it has been several years since people started to work on MWE extraction, we found that there is, as yet, no available \"clear-cut\" definition for MWEs.", "labels": [], "entities": [{"text": "MWE extraction", "start_pos": 67, "end_pos": 81, "type": "TASK", "confidence": 0.9736440777778625}]}, {"text": "We noticed various possible definitions have been suggested for MWE/MWU.", "labels": [], "entities": [{"text": "MWE/MWU", "start_pos": 64, "end_pos": 71, "type": "TASK", "confidence": 0.5504477024078369}]}, {"text": "For example, Smadja (1993) suggests a basic characteristic of collocations and multiword units is recurrent, domain-dependent and cohesive lexical clusters.", "labels": [], "entities": []}, {"text": "(2001b) suggest that MWEs can roughly be defined as \"idiosyncratic interpretations that crossword boundaries (or spaces)\".", "labels": [], "entities": []}, {"text": "describe MWEs as lexical bundles, which they goon to define as combinations of words that can be repeated frequently and tend to be used frequently by many different speakers/writers within a register.", "labels": [], "entities": []}, {"text": "Although it is not difficult to interpret these deifications in theory, things became much more complicated when we undertook our practical checking of the MWE candidates.", "labels": [], "entities": []}, {"text": "Quite often, we experienced disagreement between us about whether or not to accept a MWE candidate as a good one.", "labels": [], "entities": []}, {"text": "In practice, we generally followed Biber et al.'s definition, i.e. accept a candidate MWE as a good one if it can repeatedly co-occur in the corpus.", "labels": [], "entities": []}, {"text": "Another difficulty we experienced relates to estimating recall.", "labels": [], "entities": [{"text": "estimating", "start_pos": 45, "end_pos": 55, "type": "TASK", "confidence": 0.9520626664161682}, {"text": "recall", "start_pos": 56, "end_pos": 62, "type": "METRIC", "confidence": 0.9250013828277588}]}, {"text": "Because the MWEs in the METER Corpus are not marked-up, we could not automatically calculate the number of MWEs contained in the corpus.", "labels": [], "entities": [{"text": "METER Corpus", "start_pos": 24, "end_pos": 36, "type": "DATASET", "confidence": 0.9308169186115265}]}, {"text": "Consequently, we had to manually estimate this figure.", "labels": [], "entities": []}, {"text": "Obviously it is not practical to manually check though the whole corpus within the limited time allowed.", "labels": [], "entities": []}, {"text": "Therefore, we had to estimate the recall on a sample of the corpus, as will be described in the following section.", "labels": [], "entities": [{"text": "recall", "start_pos": 34, "end_pos": 40, "type": "METRIC", "confidence": 0.9994609951972961}]}, {"text": "In this section, we analyze the results of the MWE extraction in detail fora full evaluation of our approach to MWE extraction.", "labels": [], "entities": [{"text": "MWE extraction", "start_pos": 47, "end_pos": 61, "type": "TASK", "confidence": 0.9237855076789856}, {"text": "MWE extraction", "start_pos": 112, "end_pos": 126, "type": "TASK", "confidence": 0.9694555103778839}]}, {"text": "Overall, after we processed the test corpus, the USAS tagger extracted 4,195 MWE candidates from the test corpus.", "labels": [], "entities": [{"text": "USAS tagger extracted 4,195 MWE candidates from the test corpus", "start_pos": 49, "end_pos": 112, "type": "DATASET", "confidence": 0.8483133673667907}]}, {"text": "After manually checking through the candidates, we selected 3,792 as good MWEs, resulting in overall precision of 90.39%.", "labels": [], "entities": [{"text": "precision", "start_pos": 101, "end_pos": 110, "type": "METRIC", "confidence": 0.9994729161262512}]}, {"text": "As we explained earlier, due to the difficulty of obtaining the total number of true MWEs in the entire test corpus, we had to estimate recall of the MWE extraction on a sample corpus.", "labels": [], "entities": [{"text": "recall", "start_pos": 136, "end_pos": 142, "type": "METRIC", "confidence": 0.9991402626037598}, {"text": "MWE extraction", "start_pos": 150, "end_pos": 164, "type": "TASK", "confidence": 0.9201188087463379}]}, {"text": "In detail, we first randomly selected fifty texts containing 14,711 words from the test corpus, then manually markedup good MWEs in the sample texts, finally counted the number of the marked-up MWUs.", "labels": [], "entities": []}, {"text": "As a result, 1,511 good MWEs were found in the sample.", "labels": [], "entities": []}, {"text": "Since the number of automatically extracted good MWEs in the sample is 595, the recall on the sample is calculated as follows: Recall=(595\u00f71511)\u00d7100%=39.38%.", "labels": [], "entities": [{"text": "recall", "start_pos": 80, "end_pos": 86, "type": "METRIC", "confidence": 0.9992006421089172}, {"text": "Recall", "start_pos": 127, "end_pos": 133, "type": "METRIC", "confidence": 0.9991503953933716}]}, {"text": "Considering the homogenous feature of the test data, we assume this local recall is roughly approximate to the global recall of the test corpus.", "labels": [], "entities": [{"text": "recall", "start_pos": 74, "end_pos": 80, "type": "METRIC", "confidence": 0.9819289445877075}, {"text": "recall", "start_pos": 118, "end_pos": 124, "type": "METRIC", "confidence": 0.8587979078292847}]}, {"text": "To analyze the performance of USAS in respect to the different semantic field categories, we divided candidates according to the assigned semantic tag, and calculated the precision for each of them.", "labels": [], "entities": [{"text": "USAS", "start_pos": 30, "end_pos": 34, "type": "DATASET", "confidence": 0.9249841570854187}, {"text": "precision", "start_pos": 171, "end_pos": 180, "type": "METRIC", "confidence": 0.9994956254959106}]}, {"text": "lists these precisions, sorting the semantic fields by the number of MWE candidates (refer to section 3 for definitions of the twenty-one main semantic field categories).", "labels": [], "entities": [{"text": "precisions", "start_pos": 12, "end_pos": 22, "type": "METRIC", "confidence": 0.9866177439689636}]}, {"text": "As shown in this table, the USAS semantic tagger obtained precisions between 91.23% to 100.00% for each semantic field except for the field of \"names and grammatical words\" denoted by Z. As Z was the biggest field (containing 45.39% of the total MWEs and 43.12% of the accepted MWEs), we examined these MWEs more closely.", "labels": [], "entities": [{"text": "USAS semantic tagger", "start_pos": 28, "end_pos": 48, "type": "TASK", "confidence": 0.7743189136187235}, {"text": "precisions", "start_pos": 58, "end_pos": 68, "type": "METRIC", "confidence": 0.9984419941902161}]}, {"text": "We discovered that numerous pairs of words are tagged as person names (Z1) and geographical names (Z2) by mistake, e.g. Blackfriars crown (tagged as Z1), stabbed Constance (tagged as Z2) etc.: Precisions for different semantic categories Another possible factor that affects the performance of the USAS tagger is the length of the MWEs.", "labels": [], "entities": [{"text": "Blackfriars crown", "start_pos": 120, "end_pos": 137, "type": "DATASET", "confidence": 0.9799354374408722}, {"text": "Precisions", "start_pos": 193, "end_pos": 203, "type": "METRIC", "confidence": 0.9259592294692993}, {"text": "USAS tagger", "start_pos": 298, "end_pos": 309, "type": "DATASET", "confidence": 0.8184355199337006}]}, {"text": "To observe the performance of our approach from this perspective, we grouped the MWEs by their lengths, and then checked precision for each of the categories.", "labels": [], "entities": [{"text": "precision", "start_pos": 121, "end_pos": 130, "type": "METRIC", "confidence": 0.9996230602264404}]}, {"text": "shows the results (once again, they are sorted in descending order by MWE lengths).", "labels": [], "entities": [{"text": "MWE lengths", "start_pos": 70, "end_pos": 81, "type": "METRIC", "confidence": 0.6797538250684738}]}, {"text": "As we might expect, the number of MWEs decreases as the length increases.", "labels": [], "entities": []}, {"text": "In fact, bi-grams alone constitute 80.52% and 81.88% of the candidate and accepted MWEs respectively.", "labels": [], "entities": []}, {"text": "The precision also showed a generally increasing trend as the MWE length increases, but with a major divergence of trigrams.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9988131523132324}, {"text": "MWE length", "start_pos": 62, "end_pos": 72, "type": "METRIC", "confidence": 0.7131105065345764}]}, {"text": "One main type of error occurred on trigrams is that those with the structure of CIW(capital-initial word) + conjunction + CIW tend to be tagged as Z2 (geographical name).", "labels": [], "entities": []}, {"text": "The  As discussed earlier, purely statistical algorithms of MWE extraction generally filter out candidates of low frequencies.", "labels": [], "entities": [{"text": "MWE extraction", "start_pos": 60, "end_pos": 74, "type": "TASK", "confidence": 0.994379997253418}]}, {"text": "However, such low-frequency terms in fact form major part of MWEs inmost corpora.", "labels": [], "entities": []}, {"text": "In our study, we attempted to investigate the possibility of extracting low frequency MWEs by using semantic field annotation.", "labels": [], "entities": [{"text": "extracting low frequency MWEs", "start_pos": 61, "end_pos": 90, "type": "TASK", "confidence": 0.7364629358053207}]}, {"text": "We divided MWEs into different frequency groups, then checked precision for each of the categories.", "labels": [], "entities": [{"text": "precision", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9996935129165649}]}, {"text": "shows the results, which are sorted by the candidate MWE frequencies.", "labels": [], "entities": []}, {"text": "As we expected, 69.46% of the candidate MWEs and 68.22% of the accepted MWEs occur in the corpus only once or twice.", "labels": [], "entities": []}, {"text": "This means that, with a frequency filter of Min(f)=3, a purely statistical algorithm would exclude more than half of the candidates from the process.", "labels": [], "entities": []}, {"text": "also displays an interesting relationship between the precisions and the frequencies.", "labels": [], "entities": [{"text": "precisions", "start_pos": 54, "end_pos": 64, "type": "METRIC", "confidence": 0.9990566372871399}]}, {"text": "Generally, we would expect better precisions for MWEs of higher frequencies, as higher co-occurrence frequencies are expected to reflect stronger affinity between the words within the MWEs.", "labels": [], "entities": [{"text": "precisions", "start_pos": 34, "end_pos": 44, "type": "METRIC", "confidence": 0.9960655570030212}]}, {"text": "By and large, slightly higher precisions were obtained for the latter groups of higher frequencies than those for the preceding lower frequency groups, i.e. 94.07%-96.64% versus 87.43%-92.67%.", "labels": [], "entities": [{"text": "precisions", "start_pos": 30, "end_pos": 40, "type": "METRIC", "confidence": 0.998195469379425}]}, {"text": "Nevertheless, for the latter three groups of the higher frequencies) the precision did not increase as the frequency increases, as we initially expected.", "labels": [], "entities": [{"text": "precision", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.9996923208236694}]}], "tableCaptions": [{"text": " Table 1: Precisions for different semantic catego- ries", "labels": [], "entities": [{"text": "Precisions", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9579837918281555}]}, {"text": " Table 2: Precisions for MWEs of different lengths", "labels": [], "entities": [{"text": "Precisions", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9123375415802002}]}, {"text": " Table 3: Precisions for MWEs with different fre- quencies", "labels": [], "entities": [{"text": "Precisions", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9400339126586914}]}]}