{"title": [{"text": "Very Low-Dimensional Latent Semantic Indexing for Local Query Regions", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we focus on performing LSI on very low SVD dimensions.", "labels": [], "entities": [{"text": "LSI", "start_pos": 38, "end_pos": 41, "type": "TASK", "confidence": 0.9173786640167236}]}, {"text": "The results show that there is a nearly linear surface in the local query region.", "labels": [], "entities": []}, {"text": "Using low-dimensional LSI on local query region we can capture such a linear surface, obtain much better performance than VSM and come comparably to global LSI.", "labels": [], "entities": []}, {"text": "The surprisingly small requirements of the SVD dimension resolve the computation restrictions.", "labels": [], "entities": []}, {"text": "Moreover, on the condition that several relevant sample documents are available, application of low-dimensional LSI to these documents yielded comparable IR performance to local RF but in a different manner.", "labels": [], "entities": []}], "introductionContent": [{"text": "The increasing size of searchable text collection poses a great challenge to performing the information retrieval (IR) task.", "labels": [], "entities": [{"text": "information retrieval (IR)", "start_pos": 92, "end_pos": 118, "type": "TASK", "confidence": 0.8471232652664185}]}, {"text": "Latent Semantic Indexing (LSI) is an enhancement of the familiar Vector Model of IR.", "labels": [], "entities": [{"text": "Latent Semantic Indexing (LSI)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.6927498976389567}]}, {"text": "It satisfies the IR task through discovering corpus-wide word relationship based on cooccurrence analysis of a whole collection.", "labels": [], "entities": [{"text": "IR task", "start_pos": 17, "end_pos": 24, "type": "TASK", "confidence": 0.90338134765625}]}, {"text": "LSI has been successfully applied to various document collections and has achieved favorable results, sometimes outperforming VSM.", "labels": [], "entities": [{"text": "VSM", "start_pos": 126, "end_pos": 129, "type": "DATASET", "confidence": 0.7570503354072571}]}, {"text": "However, the principal challenges to applying LSI to large data collections are the cost of computing and storing SVD.", "labels": [], "entities": []}, {"text": "Local analysis of the information in a set of topranked documents for the query is one promising way to solve the computationally demanding IR task fora large collection.", "labels": [], "entities": [{"text": "IR task", "start_pos": 140, "end_pos": 147, "type": "TASK", "confidence": 0.9210630655288696}]}, {"text": "To solve the computational complexity of LSI, David Hull introduced one interesting method, local LSI, for routing problems.", "labels": [], "entities": [{"text": "routing problems", "start_pos": 107, "end_pos": 123, "type": "TASK", "confidence": 0.9394975304603577}]}, {"text": "The basic idea is: apply the SVD to a set of documents known to be relevant to the query; then all the documents in the collection can be folded into the reduced space of those relevant documents.", "labels": [], "entities": []}, {"text": "By concentrating on the local space around the query results, we maybe able to compute using flexible and efficient LSI algorithms.", "labels": [], "entities": []}, {"text": "In this paper we put much emphasis on local dimensionality analysis of the local query regions filled with relevant documents.", "labels": [], "entities": [{"text": "local dimensionality analysis", "start_pos": 38, "end_pos": 67, "type": "TASK", "confidence": 0.7051490942637125}]}, {"text": "In ideal experimental cases, local LSI involves only the documents known to be relevant to the query.", "labels": [], "entities": []}, {"text": "To our surprise, inmost of our experiments, local LSI obtains its best IR performance using just one or two SVD dimensions.", "labels": [], "entities": [{"text": "IR", "start_pos": 71, "end_pos": 73, "type": "TASK", "confidence": 0.9401671886444092}]}, {"text": "These interesting results moved us to try performing local LSI with one or two SVD dimensions on the top return sets of VSM in ad-hoc IR experiments.", "labels": [], "entities": []}, {"text": "We found that this worked surprisingly well.", "labels": [], "entities": []}, {"text": "Ina practical setting, local LSI maybe regarded as a variation of pseudo relevance feedback (RF).", "labels": [], "entities": [{"text": "pseudo relevance feedback (RF)", "start_pos": 66, "end_pos": 96, "type": "TASK", "confidence": 0.5440769443909327}]}, {"text": "Therefore, the comparative results with local RF are provided in this paper as well.", "labels": [], "entities": []}, {"text": "The experiments show that local LSI with one or two SVD dimensions can contribute to expanding the query information in a manner different from traditional local RF.", "labels": [], "entities": []}, {"text": "This paper is organized as follows: Section 2 reviews existing related techniques.", "labels": [], "entities": []}, {"text": "Section 3 describes the implementation architecture of the experiments and gives the experiment results.", "labels": [], "entities": []}, {"text": "Section 4 explains the result and points out characteristic of the local LSI.", "labels": [], "entities": []}, {"text": "Section 5 draws the conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "We first present the experimental results on the ideal condition.", "labels": [], "entities": []}, {"text": "The document vectors already judged to be relevant to the query were used.", "labels": [], "entities": []}, {"text": "SVD calculation are performed on the local region organized by To clarify how the local LSI space influences IR performance, we projected the document vectors onto the extracted local routine LSI space and figured out the distribution in.", "labels": [], "entities": [{"text": "IR", "start_pos": 109, "end_pos": 111, "type": "TASK", "confidence": 0.9769168496131897}]}, {"text": "The data of plots are based on one query from the Medlars collection.", "labels": [], "entities": [{"text": "Medlars collection", "start_pos": 50, "end_pos": 68, "type": "DATASET", "confidence": 0.9763266444206238}]}, {"text": "Only the largest singular vector was used for the left plot, and the two largest were used for the right.", "labels": [], "entities": []}, {"text": "Based on the plots, we find that these dimensions do not vary significantly for the non-relevant documents, Thus, they tend to cluster around the origin.", "labels": [], "entities": []}, {"text": "On the other hand, the relevant document space illustrates that local SVD factors are designed to capture their structure.", "labels": [], "entities": []}, {"text": "Since the pre-judged set of documents is generally not available for the ad-hoc query, In this paper, to investigate the efficiency of local LSI using very low dimensions, we continue to do some experiments using different numbers of relevant documents, which were selected from the relevant judgment file.", "labels": [], "entities": []}, {"text": "The comparative results based on four cases in which the SVD factors equal 1, 2 and 3, respectively, were shown in.", "labels": [], "entities": []}, {"text": "The second column is the condition, which means that the number of relevant documents belonging to the analyzing object (query) should exceed the value in table.", "labels": [], "entities": []}, {"text": "Column 3 \"#qry\" indicates the numbers of queries in the test collection which satisfy the condition appearing in the second column.", "labels": [], "entities": []}, {"text": "The fourth column gives the parameter indicating the number of relevant documents to be used for creating the local space of the correspondent query.", "labels": [], "entities": []}, {"text": "As we expected, local LSI using one or two SVD dimensions built from the first two singular vectors resulted in the best IR performance in the partially ideal experiments.", "labels": [], "entities": [{"text": "IR", "start_pos": 121, "end_pos": 123, "type": "TASK", "confidence": 0.945544958114624}]}, {"text": "The comparison of the results was shown in the.", "labels": [], "entities": []}, {"text": "We know that the most important step in LSI is the phase of SVD.", "labels": [], "entities": [{"text": "LSI", "start_pos": 40, "end_pos": 43, "type": "TASK", "confidence": 0.9294971823692322}, {"text": "SVD", "start_pos": 60, "end_pos": 63, "type": "TASK", "confidence": 0.867982029914856}]}, {"text": "It requires O(k \u00d7 nz 2 ) to find the k leading eigenvectors.", "labels": [], "entities": []}, {"text": "The parameter nz is the non-zero entries of the term-by-document matrix.", "labels": [], "entities": []}, {"text": "These requirements are unacceptably high for document data sets as the non-zero entries number tens of thousands.", "labels": [], "entities": []}, {"text": "According to the LSI analyzing procedure, it includes the SVD phase and the subsequent projecting treatment.", "labels": [], "entities": [{"text": "LSI analyzing", "start_pos": 17, "end_pos": 30, "type": "TASK", "confidence": 0.7156046330928802}, {"text": "SVD", "start_pos": 58, "end_pos": 61, "type": "TASK", "confidence": 0.7793847918510437}]}, {"text": "For global LSI, the computation complexity can be evaluated by: O(nz 2 k + #qry \u00d7 k 2 \u00d7 nz 2 \u00d7 qnz 2 ) k = (100 \u223c 300) While our approach can be estimated by: O(#qry \u00d7 [(nz 2 lock loc ) + (k 2 loc \u00d7 nz 2 \u00d7 qnz 2 )]) k = 1 or 2 In the above equation, \"nz loc \" represents the nonzero entries of the local query region.", "labels": [], "entities": []}, {"text": "\"qnz\" are non-zero entities in the query vector.", "labels": [], "entities": []}, {"text": "The value of \"nz loc \" varies with the number of known relevant documents.", "labels": [], "entities": []}, {"text": "Note that the difference between these two equations shows clearly that local LSI on small SVD dimensions is much easier to compute than global LSI.", "labels": [], "entities": []}, {"text": "According to our observation, it is particularly fast when computing only the largest singular value.", "labels": [], "entities": []}, {"text": "Based on the above experiments, the interesting results and the power of the two largest singular vectors prompted us to try putting the local LSI with one or two singular dimensions into the practical experiments.", "labels": [], "entities": []}, {"text": "In this paper, we used the simplest and most efficient VSM method as the initial retrieval step for extracting the relevant information around the query.", "labels": [], "entities": [{"text": "VSM", "start_pos": 55, "end_pos": 58, "type": "TASK", "confidence": 0.7249516248703003}]}, {"text": "We assume that the top-ranked documents obtained by VSM are relevant documents.", "labels": [], "entities": [{"text": "VSM", "start_pos": 52, "end_pos": 55, "type": "DATASET", "confidence": 0.8187015056610107}]}, {"text": "The details are introduced in section 3.4.", "labels": [], "entities": []}, {"text": "In this experiment, we note that using the top returned items from VSM is sometimes called blind feedback or pseudo RF.", "labels": [], "entities": [{"text": "VSM", "start_pos": 67, "end_pos": 70, "type": "DATASET", "confidence": 0.713395357131958}]}, {"text": "Hence, we borrow the idea of local RF.", "labels": [], "entities": []}, {"text": "The expanded query representation was obtained by combining the original query vector with its projecting result on the local SVD dimensions.", "labels": [], "entities": []}, {"text": "The equation for expanding the scheme is as follows: \ud97b\udf59 q new = \ud97b\udf59 q ori + A lock (A lock ) T \ud97b\udf59 q ori In the equation: As for the parameter k, representing the SVD dimensionality of the local region, we set its value equal to 1 or 2 in this experiment.", "labels": [], "entities": []}, {"text": "At first, to show that local LSI on small dimensions works well is a practical case clearly, we gave the comparable plots between local LSI with the baseline VSM and global LSI.", "labels": [], "entities": []}, {"text": "average precision recall plots of local LSI were figured out for the three test collections in.", "labels": [], "entities": [{"text": "precision", "start_pos": 8, "end_pos": 17, "type": "METRIC", "confidence": 0.9911167621612549}, {"text": "recall", "start_pos": 18, "end_pos": 24, "type": "METRIC", "confidence": 0.6489484906196594}]}, {"text": "The symbol sin the figure represents the sample size and k represents the SVD dimension.", "labels": [], "entities": []}, {"text": "To our satisfactions, local LSI based query expansion method does much better than VSM and more closely approaches the global LSI.", "labels": [], "entities": [{"text": "query expansion", "start_pos": 38, "end_pos": 53, "type": "TASK", "confidence": 0.7067019045352936}]}, {"text": "Next, to investigate the effectiveness of low dimensional LSI on local query region in restructuring the user cared information space, local RF with Rocchio's weights \u03b1 : \u03b2 : \u03b3 = 1 : 1 : 0, as in Xu and Croft), was used for comparison.", "labels": [], "entities": []}, {"text": "Both of them were used on the same sample documents.", "labels": [], "entities": []}, {"text": "The difference between them is a twofold one.", "labels": [], "entities": []}, {"text": "First, the standard RF formula shown in section 2.2 make use of weighting parameters for query expansion, while our approach does not.", "labels": [], "entities": [{"text": "RF", "start_pos": 20, "end_pos": 22, "type": "TASK", "confidence": 0.5834631323814392}, {"text": "query expansion", "start_pos": 89, "end_pos": 104, "type": "TASK", "confidence": 0.8496696054935455}]}, {"text": "Secondly, different combination object was used.", "labels": [], "entities": []}, {"text": "The local RF experiment performed in this paper makes use of the centroid of the top s returned document vectors.", "labels": [], "entities": []}, {"text": "In our approach, we combine the original query vector with its projecting results on the low local SVD space.", "labels": [], "entities": []}, {"text": "shows these results in terms of varying feedback size with one or two SVD dimensions.", "labels": [], "entities": []}, {"text": "The first column \"sample size\" in the table is the value of s according to which we would select the top rank documents . We see that local LSI outperforms local RF for most combinations of sample size and one or two SVD dimensions in the experiment on Medlars.", "labels": [], "entities": []}, {"text": "The best run on Medlars using local LSI is 8.4% better than the best in local RF.", "labels": [], "entities": [{"text": "Medlars", "start_pos": 16, "end_pos": 23, "type": "DATASET", "confidence": 0.9344832897186279}]}, {"text": "As for the best run on Cranfield and on NTCIR, local LSI got comparable results with the local RF.", "labels": [], "entities": [{"text": "Cranfield", "start_pos": 23, "end_pos": 32, "type": "DATASET", "confidence": 0.9940550327301025}, {"text": "NTCIR", "start_pos": 40, "end_pos": 45, "type": "DATASET", "confidence": 0.9851404428482056}]}, {"text": "In the experiments, we note that with the increasing of sample size, the precision of local LSI decreased more than that of local RF.", "labels": [], "entities": [{"text": "precision", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.9995662569999695}]}, {"text": "Based on our analysis, there are two reasons for this.", "labels": [], "entities": []}, {"text": "First, In the VSM based local LSI experiments, we assume that the top s documents from the initial retrieval by VSM are relevant, although that assumption does not always hold.", "labels": [], "entities": [{"text": "VSM", "start_pos": 112, "end_pos": 115, "type": "DATASET", "confidence": 0.9147118926048279}]}, {"text": "In the case where the dominant components of the top s return sets are non-relevant, the maintained SVD dimensions would deviate from the orientation that we preferred.", "labels": [], "entities": []}, {"text": "This will influence the following projection procedure greatly.", "labels": [], "entities": [{"text": "projection", "start_pos": 34, "end_pos": 44, "type": "TASK", "confidence": 0.9679338932037354}]}, {"text": "The average precision-recall results of VSM on Cranfield and NTCIR is 0.38 and 0.21, respectively.", "labels": [], "entities": [{"text": "precision-recall", "start_pos": 12, "end_pos": 28, "type": "METRIC", "confidence": 0.9987037181854248}, {"text": "Cranfield", "start_pos": 47, "end_pos": 56, "type": "DATASET", "confidence": 0.9368619918823242}, {"text": "NTCIR", "start_pos": 61, "end_pos": 66, "type": "DATASET", "confidence": 0.9149217009544373}]}, {"text": "The second factor is the characteristic of the test collection.", "labels": [], "entities": []}, {"text": "The number of relevant documents for query sets ranges from 2 to 40 and from 3 to 170 for the Cranfield and NTCIR, respectively.", "labels": [], "entities": [{"text": "Cranfield", "start_pos": 94, "end_pos": 103, "type": "DATASET", "confidence": 0.9757376909255981}, {"text": "NTCIR", "start_pos": 108, "end_pos": 113, "type": "DATASET", "confidence": 0.7002919316291809}]}, {"text": "With such wide range of query sets, some queries don't have enough relevant documents for this strategy to be feasible.", "labels": [], "entities": []}, {"text": "Therefore, from the experiment results, it is still reasonable for us to believe that if several relevant sample documents of a query are available, low-dimensional local LSI will be able to achieve comparable performance to local RF.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results on the Cran., Med. and NTCIR are shown in terms of ave. precision, precision at document  cutoff of 10. Results of the local LSI experiment based on three different SVD dimensions were provided.", "labels": [], "entities": [{"text": "Cran.", "start_pos": 25, "end_pos": 30, "type": "DATASET", "confidence": 0.9637907147407532}, {"text": "Med.", "start_pos": 32, "end_pos": 36, "type": "DATASET", "confidence": 0.5416205525398254}, {"text": "NTCIR", "start_pos": 41, "end_pos": 46, "type": "DATASET", "confidence": 0.7629020810127258}, {"text": "ave.", "start_pos": 69, "end_pos": 73, "type": "METRIC", "confidence": 0.9422225952148438}, {"text": "precision", "start_pos": 74, "end_pos": 83, "type": "METRIC", "confidence": 0.5210698843002319}, {"text": "precision", "start_pos": 85, "end_pos": 94, "type": "METRIC", "confidence": 0.9993597865104675}]}, {"text": " Table 2. The second column is the condi- tion, which means that the number of relevant doc- uments belonging to the analyzing object (query)  should exceed the value in table. Column 3 \"#qry\"", "labels": [], "entities": []}, {"text": " Table 2.  We know that the most important step in LSI is  the phase of SVD. It requires O(k \u00d7 nz 2 ) to find  the k leading eigenvectors. The parameter nz is the  non-zero entries of the term-by-document matrix.  These requirements are unacceptably high for doc- ument data sets as the non-zero entries number tens  of thousands. According to the LSI analyzing proce- dure, it includes the SVD phase and the subsequent", "labels": [], "entities": [{"text": "SVD", "start_pos": 72, "end_pos": 75, "type": "TASK", "confidence": 0.9237101078033447}]}, {"text": " Table 2: Ave. precision-recall comparing results  based on different SVD factors.  Coll.  Cond. #qry #sel. SVD  Ave.  Rel. fact.  P-R  1  0.6857  10  2  0.6667  Cran. >15  27  3  0.6654  (#rel)  1  0.5749  5  2  0.5692  3  0.5641  1  0.7945  10  2  0.8007  Med.  >15  25  3  0.7952  (#rel)  1  0.7160  5  2  0.7142  3  0.7137  1  0.3899  10  2  0.3987  NTCIR >15  23  3  0.3967  (#rel)  1  0.2917  5  2  0.2913  3  0.2883", "labels": [], "entities": [{"text": "precision-recall", "start_pos": 15, "end_pos": 31, "type": "METRIC", "confidence": 0.9880350232124329}]}, {"text": " Table 3: comparative results of Local LSI and Local  relevance feedback on the local region organized by  the return sets of VSM on Med., Cran. and NTCIR,  respectively. The SVD dimension value for the local  LSI is the one from which the best IR performance  was obtained at the specific sample size.", "labels": [], "entities": [{"text": "Med.", "start_pos": 133, "end_pos": 137, "type": "DATASET", "confidence": 0.9187378883361816}, {"text": "Cran.", "start_pos": 139, "end_pos": 144, "type": "DATASET", "confidence": 0.8304302096366882}, {"text": "NTCIR", "start_pos": 149, "end_pos": 154, "type": "DATASET", "confidence": 0.8825081586837769}]}]}