{"title": [{"text": "Automatic Evaluation of Students' Answers using Syntactically Enhanced LSA", "labels": [], "entities": [{"text": "Automatic Evaluation of Students' Answers", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.5120643019676209}]}], "abstractContent": [{"text": "Latent semantic analysis (LSA) has been used in several intelligent tutoring systems(ITS's) for assessing students' learning by evaluating their answers to questions in the tutoring domain.", "labels": [], "entities": [{"text": "Latent semantic analysis (LSA)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7902380178372065}]}, {"text": "It is based on word-document co-occurrence statistics in the training corpus and a dimensionality reduction technique.", "labels": [], "entities": []}, {"text": "However , it doesn't consider the word-order or syntactic information, which can improve the knowledge representation and therefore lead to better performance of an ITS.", "labels": [], "entities": []}, {"text": "We present here an approach called Syntactically Enhanced LSA (SELSA) which generalizes LSA by considering a word along with its syntactic neighborhood given by the part-of-speech tag of its preceding word, as a unit of knowledge representation.", "labels": [], "entities": []}, {"text": "The experimental results on Auto-Tutor task to evaluate students' answers to basic computer science questions by SELSA and its comparison with LSA are presented in terms of several cognitive measures.", "labels": [], "entities": []}, {"text": "SELSA is able to correctly evaluate a few more answers than LSA but is having less correlation with human evaluators than LSA has.", "labels": [], "entities": []}, {"text": "It also provides better discrimination of syntactic-semantic knowledge representation than LSA.", "labels": [], "entities": []}], "introductionContent": [{"text": "Computer based education systems are useful in distance learning as well as for class-room learning environment.", "labels": [], "entities": []}, {"text": "These systems are based on intelligent tutoring systems(ITS's) which provide an interactive learning environment to students.", "labels": [], "entities": []}, {"text": "These systems first familiarize a student with a topic and then ask questions to assess her knowledge.", "labels": [], "entities": []}, {"text": "Automatic evaluation of students' answers is thus central to design of an ITS that can function without the need of continuous monitoring by a human.", "labels": [], "entities": []}, {"text": "Examples of ITS's that use natural language processing to understand students' contribution are CIRC-SIM), Atlas (), PACT () etc.", "labels": [], "entities": []}, {"text": "These systems use a parser to derive various levels of syntactic and semantic information and rules to determine the next dialog move.", "labels": [], "entities": []}, {"text": "They perform quite well with short answers in a limited domain, but are limited to take arbitrarily long free-text input and are difficult to port across domains.", "labels": [], "entities": []}, {"text": "These limitations can be alleviated by using latent semantic analysis(LSA), a recently developed technique for information retrieval), knowledge representation (), natural language understanding and cognitive modeling) etc.", "labels": [], "entities": [{"text": "latent semantic analysis(LSA)", "start_pos": 45, "end_pos": 74, "type": "TASK", "confidence": 0.7120813677708308}, {"text": "information retrieval", "start_pos": 111, "end_pos": 132, "type": "TASK", "confidence": 0.7206560522317886}, {"text": "knowledge representation", "start_pos": 135, "end_pos": 159, "type": "TASK", "confidence": 0.7273966521024704}, {"text": "natural language understanding", "start_pos": 164, "end_pos": 194, "type": "TASK", "confidence": 0.6491734584172567}]}, {"text": "LSA has been used in various ITS's like AutoTutor), Intelligent Essay Assessor (), Summary Street (), Apex ( etc.", "labels": [], "entities": []}, {"text": "LSA is a statistical corpus-based natural language understanding technique that supports semantic similarity measurement between texts.", "labels": [], "entities": [{"text": "statistical corpus-based natural language understanding", "start_pos": 9, "end_pos": 64, "type": "TASK", "confidence": 0.6158395290374756}, {"text": "semantic similarity measurement between texts", "start_pos": 89, "end_pos": 134, "type": "TASK", "confidence": 0.7849550485610962}]}, {"text": "Given a set of documents in the tutoring domain, LSA uses the frequency of occurrence of each word in each document to construct a word-document co-occurrence matrix.", "labels": [], "entities": []}, {"text": "After preprocessing, singular value decomposition is performed to represent the domain knowledge into a 200 to 400 dimensional space.", "labels": [], "entities": [{"text": "singular value decomposition", "start_pos": 21, "end_pos": 49, "type": "TASK", "confidence": 0.6318065424760183}]}, {"text": "This space is then used for evaluating the semantic similarity between any two text units.", "labels": [], "entities": []}, {"text": "In an ITS, LSA is used to evaluate students' answers with respect to the ideal answers to questions in the domain ().", "labels": [], "entities": [{"text": "LSA", "start_pos": 11, "end_pos": 14, "type": "METRIC", "confidence": 0.9526639580726624}]}, {"text": "This is done by finding the match between a student's answer and the ideal answer by calculating the cosine similarity measure between their projections in LSA space.", "labels": [], "entities": [{"text": "cosine similarity measure", "start_pos": 101, "end_pos": 126, "type": "METRIC", "confidence": 0.7266197204589844}]}, {"text": "This information is used to provide interactive response to the student in terms of hint, prompt,question etc.", "labels": [], "entities": []}, {"text": "It has been found that LSA performs as good as an intermediate expert human evaluator but not so well as an accomplished expert of the domain.", "labels": [], "entities": []}, {"text": "This maybe because LSA is a 'bag-of-words' approach and so lacks the wordorder or syntactic information in a text document.", "labels": [], "entities": []}, {"text": "But for correct automatic evaluation of students' answers, a model should consider both syntax and semantics in the answer.", "labels": [], "entities": []}, {"text": "So, one obvious way to improve the performance of LSA is to incorporate some syntactic information in it.", "labels": [], "entities": [{"text": "LSA", "start_pos": 50, "end_pos": 53, "type": "TASK", "confidence": 0.8523849844932556}]}, {"text": "In order to add syntactic information to LSA, recently there has been an effort in, where a word along with its part-of-speech (POS) tag was used to construct the LSA matrix, thus capturing multiple syntactic senses of a word.", "labels": [], "entities": []}, {"text": "But this approach, called tagged LSA, deteriorated the performance.", "labels": [], "entities": []}, {"text": "In another attempt, similarity between two sentences was calculated by averaging the LSA based similarity of sub-sentence structures like noun phrase, verb phrase, object phrase etc.", "labels": [], "entities": [{"text": "similarity", "start_pos": 20, "end_pos": 30, "type": "METRIC", "confidence": 0.9677531123161316}, {"text": "LSA", "start_pos": 85, "end_pos": 88, "type": "METRIC", "confidence": 0.8903431296348572}]}, {"text": "This approach, called as structured LSA (SLSA), could improve the performance in terms of sentence-pair similarity judgment.", "labels": [], "entities": [{"text": "sentence-pair similarity judgment", "start_pos": 90, "end_pos": 123, "type": "TASK", "confidence": 0.6510988473892212}]}, {"text": "But its performance in terms of evaluating students' answers was poorer than that of LSA).", "labels": [], "entities": []}, {"text": "We propose here a model called Syntactically Enhanced LSA (SELSA), where we augment each word with the part-of-speech (POS) tag of the preceding word.", "labels": [], "entities": [{"text": "Syntactically Enhanced LSA", "start_pos": 31, "end_pos": 57, "type": "TASK", "confidence": 0.6885359088579813}]}, {"text": "Thus instead of word-document co-occurence matrix, we generate a matrix in which rows correspond to all possible word -POS tag combinations and columns correspond to documents.", "labels": [], "entities": []}, {"text": "A preceding tag indicates some kind of syntactic neighbourhood around the focus word.", "labels": [], "entities": []}, {"text": "Depending on the preceding tag, the syntactic-semantic sense of a word can vary.", "labels": [], "entities": []}, {"text": "Thus SELSA captures finer resolution of syntactic-semantic information compared to mere semantics of LSA.", "labels": [], "entities": [{"text": "SELSA", "start_pos": 5, "end_pos": 10, "type": "TASK", "confidence": 0.9338416457176208}]}, {"text": "This finer information can therefore be used to evaluate a student's answer more accurately than LSA.", "labels": [], "entities": [{"text": "LSA", "start_pos": 97, "end_pos": 100, "type": "METRIC", "confidence": 0.6433192491531372}]}, {"text": "We compare the performance of SELSA with LSA for the AutoTutor cognitive modeling task ().", "labels": [], "entities": [{"text": "SELSA", "start_pos": 30, "end_pos": 35, "type": "TASK", "confidence": 0.8347796201705933}, {"text": "AutoTutor cognitive modeling task", "start_pos": 53, "end_pos": 86, "type": "TASK", "confidence": 0.5845807865262032}]}, {"text": "This involves evaluating students' answers to questions in three areas of computer science viz.", "labels": [], "entities": []}, {"text": "hardware, operating system and networking.", "labels": [], "entities": []}, {"text": "The performance is measured in terms of various criteria like correlation, mean absolute difference and number of correct /emphvs false evaluations by humans and by computer.", "labels": [], "entities": [{"text": "correlation", "start_pos": 62, "end_pos": 73, "type": "METRIC", "confidence": 0.9940055012702942}, {"text": "mean absolute difference", "start_pos": 75, "end_pos": 99, "type": "METRIC", "confidence": 0.9001724720001221}]}, {"text": "SELSA is found better than LSA in terms of robustness across thresholds as well as in terms of evaluating more answers correctly, but it is having less correlation measure with human than LSA.", "labels": [], "entities": [{"text": "SELSA", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.6431680917739868}]}, {"text": "The organization of this paper is as follows.", "labels": [], "entities": []}, {"text": "The next section describes LSA and its applications in ITS's.", "labels": [], "entities": []}, {"text": "In section 3, we describe the proposed SELSA model.", "labels": [], "entities": [{"text": "SELSA", "start_pos": 39, "end_pos": 44, "type": "TASK", "confidence": 0.939612865447998}]}, {"text": "The experimental details are given in section 4 followed by discussion on results in section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have studied the performance of SELSA and compared it with LSA in the AutoTutor task (section 2.2.1) for natural language understanding and cognitive modeling performance.", "labels": [], "entities": [{"text": "SELSA", "start_pos": 35, "end_pos": 40, "type": "TASK", "confidence": 0.9520455002784729}, {"text": "natural language understanding", "start_pos": 108, "end_pos": 138, "type": "TASK", "confidence": 0.6303734878698984}]}, {"text": "The details of the experiment are presented below.", "labels": [], "entities": []}, {"text": "For comparing the performance of SELSA and LSA with humans, we selected four human evaluators from computer related areas.", "labels": [], "entities": [{"text": "SELSA", "start_pos": 33, "end_pos": 38, "type": "TASK", "confidence": 0.9561008214950562}]}, {"text": "Three of them were doctorate candidates and one had completed it, thus they were expert human evaluators.", "labels": [], "entities": []}, {"text": "Each of them were given the 192 studentanswers and a set of good answers to each of the question.", "labels": [], "entities": []}, {"text": "They were asked to evaluate the answers on the basis of compatibility score i.e. the fraction of the number of sentences in a student-answer that matches any of the good answers.", "labels": [], "entities": [{"text": "compatibility score", "start_pos": 56, "end_pos": 75, "type": "METRIC", "confidence": 0.9844494462013245}]}, {"text": "Thus, the score for each answer ranged between 0 to 1.", "labels": [], "entities": []}, {"text": "They were not told what constitutes a \"match\", but were to decide themselves.", "labels": [], "entities": []}, {"text": "In order to evaluate the performance of SELSA and LSA on AutoTutor task, we need to define an appropriate measure.", "labels": [], "entities": [{"text": "SELSA", "start_pos": 40, "end_pos": 45, "type": "TASK", "confidence": 0.4524063467979431}]}, {"text": "The earlier studies on this task used a correlation coefficient measure between the LSA's rating and human rating of the 192 answers.", "labels": [], "entities": [{"text": "LSA's rating", "start_pos": 84, "end_pos": 96, "type": "METRIC", "confidence": 0.6577825446923574}]}, {"text": "We have also used this as one of the three measures for comparison.", "labels": [], "entities": []}, {"text": "But fora task having small sample size, the correlation coefficient is not reliably estimated, so we defined two new performance measures.", "labels": [], "entities": [{"text": "correlation coefficient", "start_pos": 44, "end_pos": 67, "type": "METRIC", "confidence": 0.969581663608551}]}, {"text": "The first one was the mean absolute difference between the human and SELSA (correspondingly LSA) evaluations.", "labels": [], "entities": [{"text": "mean absolute difference", "start_pos": 22, "end_pos": 46, "type": "METRIC", "confidence": 0.7313008904457092}, {"text": "SELSA", "start_pos": 69, "end_pos": 74, "type": "METRIC", "confidence": 0.8547849059104919}]}, {"text": "In the other measure we used the comparison of how many answers were correctly evaluated versus how many were falsely evaluated by SELSA (LSA) as compared to human evaluations.", "labels": [], "entities": [{"text": "SELSA (LSA)", "start_pos": 131, "end_pos": 142, "type": "METRIC", "confidence": 0.8750521242618561}]}, {"text": "A detailed explanation of these measures is given in the following section.", "labels": [], "entities": []}, {"text": "We define an evaluation l i by SELSA (LSA) to be corrector false as below: T where CT and F T are correctness and falsehood thresholds which were set to 0.05 and 0.95 respectively for strict measures.", "labels": [], "entities": [{"text": "CT and F T", "start_pos": 83, "end_pos": 93, "type": "METRIC", "confidence": 0.7677210718393326}]}, {"text": "Number of such correct as well as false evaluations were then averaged across the four human evaluators.", "labels": [], "entities": []}, {"text": "They are plotted in figs. (6) and for SELSA and LSA respectively (the upper curves corresponding to correct and the lower ones to false evaluations).", "labels": [], "entities": [{"text": "SELSA", "start_pos": 38, "end_pos": 43, "type": "METRIC", "confidence": 0.9577248096466064}, {"text": "LSA", "start_pos": 48, "end_pos": 51, "type": "METRIC", "confidence": 0.9500749707221985}]}, {"text": "The maximum number of correct (maxCorrect) and the minimum number of false (minF alse) evaluations across the thresholds for each value of SVD dimensions are calculated and shown in tables (3) and (4).", "labels": [], "entities": [{"text": "correct (maxCorrect)", "start_pos": 22, "end_pos": 42, "type": "METRIC", "confidence": 0.8872184157371521}, {"text": "minimum number of false (minF alse) evaluations", "start_pos": 51, "end_pos": 98, "type": "METRIC", "confidence": 0.7704237765736051}]}, {"text": "We observe that the best performance for SELSA is achieved at 300 dimensions with 126 correct and 30 false evaluations, while for LSA it is at 400 dimensions with 123 correct and 30 false evaluations.", "labels": [], "entities": [{"text": "SELSA", "start_pos": 41, "end_pos": 46, "type": "TASK", "confidence": 0.9063537120819092}, {"text": "LSA", "start_pos": 130, "end_pos": 133, "type": "DATASET", "confidence": 0.649781346321106}]}, {"text": "The average correct and false evaluations among all human-human evaluator pairs were 132 and 23 respectively.", "labels": [], "entities": [{"text": "correct", "start_pos": 12, "end_pos": 19, "type": "METRIC", "confidence": 0.98470139503479}]}, {"text": "Thus here also SELSA is closer to human evaluators than LSA.", "labels": [], "entities": [{"text": "SELSA", "start_pos": 15, "end_pos": 20, "type": "TASK", "confidence": 0.8585107326507568}]}, {"text": "In fact, for the cognitive task like AutoTutor, this is a more appealing and explicit measure than the previous two.", "labels": [], "entities": []}, {"text": "Apart from these three measures, one can also calculate precision, recall and F-measure ( to evaluate the performance.", "labels": [], "entities": [{"text": "precision", "start_pos": 56, "end_pos": 65, "type": "METRIC", "confidence": 0.9996433258056641}, {"text": "recall", "start_pos": 67, "end_pos": 73, "type": "METRIC", "confidence": 0.9995075464248657}, {"text": "F-measure", "start_pos": 78, "end_pos": 87, "type": "METRIC", "confidence": 0.9989532232284546}]}], "tableCaptions": [{"text": " Table 1: Threshold Width of SELSA", "labels": [], "entities": [{"text": "Threshold", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9908238649368286}, {"text": "Width", "start_pos": 20, "end_pos": 25, "type": "METRIC", "confidence": 0.5760255455970764}, {"text": "SELSA", "start_pos": 29, "end_pos": 34, "type": "TASK", "confidence": 0.7606195211410522}]}, {"text": " Table 2: Threshold Width of LSA", "labels": [], "entities": [{"text": "Threshold", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9934908747673035}, {"text": "Width", "start_pos": 20, "end_pos": 25, "type": "METRIC", "confidence": 0.7409541010856628}, {"text": "LSA", "start_pos": 29, "end_pos": 32, "type": "TASK", "confidence": 0.4451214671134949}]}, {"text": " Table 3: SELSA -M AD, correct and false evaluation", "labels": [], "entities": [{"text": "SELSA -M AD", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.902280405163765}]}, {"text": " Table 4: LSA -M AD, correct and false evaluation", "labels": [], "entities": [{"text": "LSA -M AD", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9210697412490845}]}]}