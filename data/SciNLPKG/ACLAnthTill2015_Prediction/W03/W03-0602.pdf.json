{"title": [{"text": "Words and Pictures in the News", "labels": [], "entities": []}], "abstractContent": [{"text": "We discuss the properties of a collection of news photos and captions, collected from the Associated Press and Reuters.", "labels": [], "entities": []}, {"text": "Captions have a vocabulary dominated by proper names.", "labels": [], "entities": []}, {"text": "We have implemented various text clustering algorithms to organize these items by topic, as well as an iconic matcher that identifies articles that share a picture.", "labels": [], "entities": [{"text": "text clustering", "start_pos": 28, "end_pos": 43, "type": "TASK", "confidence": 0.6990674138069153}]}, {"text": "We have found that the special structure of captions allows us to extract some names of people actually portrayed in the image quite reliably, using a simple syntactic analysis.", "labels": [], "entities": []}, {"text": "We have been able to build a directory of face images of individuals from this collection .", "labels": [], "entities": []}], "introductionContent": [{"text": "For the past year we have been building a collection of captioned news photos and illustrated news articles.", "labels": [], "entities": []}, {"text": "We believe that, for many applications, words and pictures together provide very rich information on document content.", "labels": [], "entities": []}, {"text": "Photographs can link articles in ways that pure textual analysis may overlook or underestimate, and text provides high level descriptions of image contents that current vision techniques cannot obtain.", "labels": [], "entities": []}, {"text": "Our analysis of image captions has revealed various journalistic conventions that we believe make this dataset particularly appealing fora number of applications.", "labels": [], "entities": [{"text": "image captions", "start_pos": 16, "end_pos": 30, "type": "TASK", "confidence": 0.7284247875213623}]}, {"text": "Captions act as concise summaries of events, and we believe we can use them to isolate the most pertinent words for different topics.", "labels": [], "entities": []}, {"text": "We have implemented various clustering methods to explore this idea.", "labels": [], "entities": []}, {"text": "Captions are also tightly tied to the actual content of the image.", "labels": [], "entities": [{"text": "Captions", "start_pos": 0, "end_pos": 8, "type": "TASK", "confidence": 0.9352478981018066}]}, {"text": "The difficulty hereon the text side, is in identifying those portions of a caption that refer to tangible objects, physically present in the image.", "labels": [], "entities": []}, {"text": "On the image side, we need to isolate objects of interest and solve the correspondence problem between caption extracts and image regions.", "labels": [], "entities": []}, {"text": "We are exploring these issues in the context of trying to build an automated celebrity directory and face classifier.", "labels": [], "entities": []}], "datasetContent": [{"text": "Quantitatively our models appear to fit well, but an analysis of their usefulness for interacting with these collections is more difficult.", "labels": [], "entities": []}, {"text": "Our collection has no canonical topical structure against which we can compare our results.", "labels": [], "entities": []}, {"text": "However, we have built various tools to aid in the qualitative evaluation of our results.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Iconic Matches  Iconic Matches  Collection Stats  Collection Total Docs  BBC CNN  BBC  16990  BBC 3793  223  CNN  8397 CNN  1233", "labels": [], "entities": [{"text": "Iconic Matches  Iconic Matches  Collection Stats  Collection Total Docs  BBC CNN  BBC  16990  BBC 3793  223  CNN  8397 CNN  1233", "start_pos": 10, "end_pos": 138, "type": "DATASET", "confidence": 0.7777895495295525}]}]}