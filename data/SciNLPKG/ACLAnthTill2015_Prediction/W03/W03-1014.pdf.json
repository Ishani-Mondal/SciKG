{"title": [{"text": "Learning Extraction Patterns for Subjective Expressions *", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents a bootstrapping process that learns linguistically rich extraction patterns for subjective (opinionated) expressions.", "labels": [], "entities": []}, {"text": "High-precision classifiers label unannotated data to automatically create a large training set, which is then given to an extraction pattern learning algorithm.", "labels": [], "entities": []}, {"text": "The learned patterns are then used to identify more subjective sentences.", "labels": [], "entities": []}, {"text": "The bootstrapping process learns many subjective patterns and increases recall while maintaining high precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 72, "end_pos": 78, "type": "METRIC", "confidence": 0.9995099306106567}, {"text": "precision", "start_pos": 102, "end_pos": 111, "type": "METRIC", "confidence": 0.9974868297576904}]}], "introductionContent": [{"text": "Many natural language processing applications could benefit from being able to distinguish between factual and subjective information.", "labels": [], "entities": []}, {"text": "Subjective remarks come in a variety of forms, including opinions, rants, allegations, accusations, suspicions, and speculations.", "labels": [], "entities": []}, {"text": "Ideally, information extraction systems should be able to distinguish between factual information (which should be extracted) and non-factual information (which should be discarded or labeled as uncertain).", "labels": [], "entities": [{"text": "information extraction", "start_pos": 9, "end_pos": 31, "type": "TASK", "confidence": 0.739993155002594}]}, {"text": "Question answering systems should distinguish between factual and speculative answers.", "labels": [], "entities": [{"text": "Question answering", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8895097076892853}]}, {"text": "Multi-perspective question answering aims to present multiple answers to the user based upon speculation or opinions derived from different sources.", "labels": [], "entities": [{"text": "Multi-perspective question answering", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.6914861599604288}]}, {"text": "Multidocument summarization systems need to summarize different opinions and perspectives.", "labels": [], "entities": [{"text": "Multidocument summarization", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6653343141078949}]}, {"text": "Spam filtering systems * This work was supported by the National Science Foundation under grants IIS-0208798, IIS-0208985, and IRI-9704240.", "labels": [], "entities": [{"text": "Spam filtering", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.855927437543869}, {"text": "IIS-0208798", "start_pos": 97, "end_pos": 108, "type": "DATASET", "confidence": 0.7931629419326782}, {"text": "IIS-0208985", "start_pos": 110, "end_pos": 121, "type": "DATASET", "confidence": 0.8142951726913452}, {"text": "IRI-9704240", "start_pos": 127, "end_pos": 138, "type": "DATASET", "confidence": 0.8470084071159363}]}, {"text": "The data preparation was performed in support of the Northeast Regional Research Center (NRRC) which is sponsored by the Advanced Research and Development Activity (ARDA), a U.S. Government entity which sponsors and promotes research of import to the Intelligence Community which includes but is not limited to the CIA, DIA, NSA, NIMA, and NRO.", "labels": [], "entities": [{"text": "Northeast Regional Research Center (NRRC)", "start_pos": 53, "end_pos": 94, "type": "DATASET", "confidence": 0.8239406602723258}]}, {"text": "must recognize rants and emotional tirades, among other things.", "labels": [], "entities": []}, {"text": "In general, nearly any system that seeks to identify information could benefit from being able to separate factual and subjective information.", "labels": [], "entities": []}, {"text": "Some existing resources contain lists of subjective words (e.g.,), and some empirical methods in NLP have automatically identified adjectives, verbs, and N-grams that are statistically associated with subjective language (e.g.,).", "labels": [], "entities": []}, {"text": "However, subjective language can be exhibited by a staggering variety of words and phrases.", "labels": [], "entities": []}, {"text": "In addition, many subjective terms occur infrequently, such as strongly subjective adjectives (e.g., preposterous, unseemly) and metaphorical or idiomatic phrases (e.g., dealt a blow, swept off one's feet).", "labels": [], "entities": []}, {"text": "Consequently, we believe that subjectivity learning systems must be trained on extremely large text collections before they will acquire a subjective vocabulary that is truly broad and comprehensive in scope.", "labels": [], "entities": []}, {"text": "To address this issue, we have been exploring the use of bootstrapping methods to allow subjectivity classifiers to learn from a collection of unannotated texts.", "labels": [], "entities": []}, {"text": "Our research uses high-precision subjectivity classifiers to automatically identify subjective and objective sentences in unannotated texts.", "labels": [], "entities": []}, {"text": "This process allows us to generate a large set of labeled sentences automatically.", "labels": [], "entities": []}, {"text": "The second emphasis of our research is using extraction patterns to represent subjective expressions.", "labels": [], "entities": []}, {"text": "These patterns are linguistically richer and more flexible than single words or N-grams.", "labels": [], "entities": []}, {"text": "Using the (automatically) labeled sentences as training data, we apply an extraction pattern learning algorithm to automatically generate patterns representing subjective expressions.", "labels": [], "entities": []}, {"text": "The learned patterns can be used to automatically identify more subjective sentences, which grows the training set, and the entire process can then be bootstrapped.", "labels": [], "entities": []}, {"text": "Our experimental results show that this bootstrapping process increases the recall of the highprecision subjective sentence classifier with little loss in precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 76, "end_pos": 82, "type": "METRIC", "confidence": 0.9989612102508545}, {"text": "precision", "start_pos": 155, "end_pos": 164, "type": "METRIC", "confidence": 0.9979268312454224}]}, {"text": "We also find that the learned extraction patterns capture subtle connotations that are more expressive than the individual words by themselves.", "labels": [], "entities": []}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 discusses previous work on subjectivity analysis and extraction pattern learning.", "labels": [], "entities": [{"text": "subjectivity analysis", "start_pos": 37, "end_pos": 58, "type": "TASK", "confidence": 0.7286376059055328}, {"text": "extraction pattern learning", "start_pos": 63, "end_pos": 90, "type": "TASK", "confidence": 0.8175307909647623}]}, {"text": "Section 3 overviews our general approach, describes the high-precision subjectivity classifiers, and explains the algorithm for learning extraction patterns associated with subjectivity.", "labels": [], "entities": []}, {"text": "Section 4 describes the data that we use, presents our experimental results, and shows examples of patterns that are learned.", "labels": [], "entities": []}, {"text": "Finally, Section 5 summarizes our findings and conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our pool of unannotated texts consists of 302,163 individual sentences.", "labels": [], "entities": []}, {"text": "The HP-Subj classifier initially labeled roughly 44,300 of these sentences as subjective, and the HP-Obj classifier initially labeled roughly 17,000 sentences as objective.", "labels": [], "entities": []}, {"text": "In order to keep the training set relatively balanced, we used all 17,000 objective sentences and 17,000 of the subjective sentences as training data for the extraction pattern learner.", "labels": [], "entities": []}, {"text": "17,073 extraction patterns were learned that have frequency \u2265 2 and P r(subjective | pattern i ) \u2265 .60 on the training data.", "labels": [], "entities": []}, {"text": "We then wanted to determine whether the extraction patterns are, in fact, good indicators of subjectivity.", "labels": [], "entities": []}, {"text": "To evaluate the patterns, we applied different subsets of them to a test set to see if they consistently occur in subjective sentences.", "labels": [], "entities": []}, {"text": "This test set consists of 3947 sentences, 54% of which are subjective.", "labels": [], "entities": []}, {"text": "shows sentence recall and pattern (instancelevel) precision for the learned extraction patterns on the test set.", "labels": [], "entities": [{"text": "recall", "start_pos": 15, "end_pos": 21, "type": "METRIC", "confidence": 0.9545735120773315}, {"text": "precision", "start_pos": 50, "end_pos": 59, "type": "METRIC", "confidence": 0.7744402885437012}]}, {"text": "In this figure, precision is the proportion of pattern instances found in the test set that are in subjective sentences, and recall is the proportion of subjective sentences that contain at least one pattern instance.", "labels": [], "entities": [{"text": "precision", "start_pos": 16, "end_pos": 25, "type": "METRIC", "confidence": 0.9995672106742859}, {"text": "recall", "start_pos": 125, "end_pos": 131, "type": "METRIC", "confidence": 0.999382734298706}]}, {"text": "We evaluated 18 different subsets of the patterns, by selecting the patterns that pass certain thresholds in the training data.", "labels": [], "entities": []}, {"text": "We tried all combinations of \u03b8 1 = {2,10} and \u03b8 2 = {.60,.65,.70,.75,.80,.85,.90,.95,1.0}.", "labels": [], "entities": []}, {"text": "The data points corresponding to \u03b8 1 =2 are shown on the upper line in, and those corresponding to \u03b8 1 =10 are shown on the lower line.", "labels": [], "entities": []}, {"text": "For example, the data point corresponding to \u03b8 1 =10 and \u03b8 2 =.90 evaluates only the extraction patterns that occur at least 10 times in the training data and with a probability \u2265 .90 (i.e., at least 90% of its occurrences are in subjective training sentences).", "labels": [], "entities": []}, {"text": "Overall, the extraction patterns perform quite well.", "labels": [], "entities": []}, {"text": "The precision ranges from 71% to 85%, with the expected tradeoff between precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9997072815895081}, {"text": "precision", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.9997124075889587}, {"text": "recall", "start_pos": 87, "end_pos": 93, "type": "METRIC", "confidence": 0.997637152671814}]}, {"text": "This experiment confirms that the extraction patterns are effective at recognizing subjective expressions.", "labels": [], "entities": []}, {"text": "In our second experiment, we used the learned extraction patterns to classify previously unlabeled sentences from the unannotated text collection.", "labels": [], "entities": []}, {"text": "The new subjective sentences were then fed back into the Extraction Pattern Learner to complete the bootstrapping cycle depicted by the rightmost dashed line in.", "labels": [], "entities": []}, {"text": "The Patternbased Subjective Sentence Classifier classifies a sentence as subjective if it contains at least one extraction pattern with \u03b8 1 \u22655 and \u03b8 2 \u22651.0 on the training data.", "labels": [], "entities": [{"text": "Patternbased Subjective Sentence Classifier classifies a sentence", "start_pos": 4, "end_pos": 69, "type": "TASK", "confidence": 0.7641541106360299}]}, {"text": "This process produced approximately 9,500 new subjective sentences that were previously unlabeled.", "labels": [], "entities": []}, {"text": "Since our bootstrapping process does not learn new objective sentences, we did not want to simply add the new subjective sentences to the training set, or it would become increasingly skewed toward subjective sentences.", "labels": [], "entities": []}, {"text": "Since HP-Obj had produced roughly 17,000 objective sentences used for training, we used the 9,500 new subjective sentences along with 7,500 of the previously identified subjective sentences as our new training set.", "labels": [], "entities": [{"text": "HP-Obj", "start_pos": 6, "end_pos": 12, "type": "DATASET", "confidence": 0.9336325526237488}]}, {"text": "In other words, the training set that we used during the second bootstrapping cycle contained exactly the same objective sentences as the first cycle, half of the same subjective sentences as the first cycle, and 9,500 brand new subjective sentences.", "labels": [], "entities": []}, {"text": "On this second cycle of bootstrapping, the extraction pattern learner generated many new patterns that were not discovered during the first cycle.", "labels": [], "entities": []}, {"text": "4,248 new patterns were found that have \u03b8 1 \u22652 and \u03b8 2 \u2265.60.", "labels": [], "entities": []}, {"text": "If we consider only the strongest (most subjective) extraction patterns, 308 new patterns were found that had \u03b8 1 \u226510 and \u03b8 2 \u22651.0.", "labels": [], "entities": []}, {"text": "This is a substantial set of new extraction patterns that seem to be very highly correlated with subjectivity.", "labels": [], "entities": []}, {"text": "An open question was whether the new patterns provide additional coverage.", "labels": [], "entities": []}, {"text": "To assess this, we did a simple test: we added the 4,248 new patterns to the original set of patterns learned during the first bootstrapping cycle.", "labels": [], "entities": []}, {"text": "Then we repeated the same analysis that we depict in.", "labels": [], "entities": []}, {"text": "In general, the recall numbers increased by about 2-4% while the precision numbers decreased by less, from 0.5-2%.", "labels": [], "entities": [{"text": "recall", "start_pos": 16, "end_pos": 22, "type": "METRIC", "confidence": 0.9995566010475159}, {"text": "precision", "start_pos": 65, "end_pos": 74, "type": "METRIC", "confidence": 0.9993711113929749}]}, {"text": "In our third experiment, we evaluated whether the learned patterns can improve the coverage of the highprecision subjectivity classifier (HP-Subj), to complete the bootstrapping loop depicted in the top-most dashed line of.", "labels": [], "entities": []}, {"text": "Our hope was that the patterns would allow more sentences from the unannotated text collection to be labeled as subjective, without a substantial drop in precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 154, "end_pos": 163, "type": "METRIC", "confidence": 0.9955452680587769}]}, {"text": "For this experiment, we selected the learned extraction patterns that had \u03b8 1 \u2265 10 and \u03b8 2 \u2265 1.0 on the training set, since these seemed likely to be the most reliable (high precision) indicators of subjectivity.", "labels": [], "entities": []}, {"text": "We modified the HP-Subj classifier to use extraction patterns as follows.", "labels": [], "entities": []}, {"text": "All sentences labeled as subjective by the original HP-Subj classifier are also labeled as subjective by the new version.", "labels": [], "entities": []}, {"text": "For previously unlabeled sentences, the new version classifies a sentence as subjective if (1) it contains two or more of the learned patterns, or (2) it contains one of the clues used by the original HPSubj classifier and at least one learned pattern.", "labels": [], "entities": []}, {"text": "shows the performance results on the test set mentioned in Section 3.1 (2197 sentences) for both the original HPSubj classifier and the new version that uses the learned extraction patterns.", "labels": [], "entities": []}, {"text": "The extraction patterns produce a 7.2 percentage point gain in coverage, and only a 1.1 percentage point drop in precision.", "labels": [], "entities": [{"text": "coverage", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9987075328826904}, {"text": "precision", "start_pos": 113, "end_pos": 122, "type": "METRIC", "confidence": 0.9992007613182068}]}, {"text": "This result shows that the learned extraction patterns do improve the performance of the high-precision subjective sentence classifier, allowing it to classify more sentences as subjective with nearly the same high reliability.", "labels": [], "entities": []}, {"text": "gives examples of patterns used to augment the HP-Subj classifier which do not overlap in non-function words with any of the clues already known by the original system.", "labels": [], "entities": []}, {"text": "For each pattern, we show an example sentence from our corpus that matches the pattern.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Bootstrapping the Learned Patterns into the  High-Precision Sentence Classifier", "labels": [], "entities": []}]}