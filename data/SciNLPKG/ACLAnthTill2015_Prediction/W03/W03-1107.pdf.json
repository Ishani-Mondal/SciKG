{"title": [{"text": "Feature Selection in Categorizing Procedural Expressions", "labels": [], "entities": [{"text": "Feature Selection", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.6996610164642334}]}], "abstractContent": [{"text": "Text categorization, as an essential component of applications for user navigation on the World Wide Web using Question-Answering in Japanese, requires more effective features for the categorization of documents and the efficient acquisition of knowledge.", "labels": [], "entities": [{"text": "Text categorization", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7356974184513092}]}, {"text": "In the questions addressed by such navigation, we focus on those questions for procedures and intend to clarify specification of the answers.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recent methodologies of text categorization as applied to Question-Answering(QA) and user navigation on the Web address new types of problems, such as the categorization of texts based on the question type in addition to one based on domain and genre.", "labels": [], "entities": [{"text": "text categorization", "start_pos": 24, "end_pos": 43, "type": "TASK", "confidence": 0.7267061769962311}, {"text": "Question-Answering(QA)", "start_pos": 58, "end_pos": 80, "type": "TASK", "confidence": 0.6214239224791527}]}, {"text": "For good performance in a shallow approach, which exploits the shallow specification of texts to categorize them, requires a great deal of knowledge of the expressions in the answers corresponding to the questions.", "labels": [], "entities": []}, {"text": "In most past QA research, the types of question have been primarily restricted to fact-based questions.", "labels": [], "entities": [{"text": "QA", "start_pos": 13, "end_pos": 15, "type": "TASK", "confidence": 0.9719298481941223}]}, {"text": "However, in user navigation on the Web, other types of questions should be supported.", "labels": [], "entities": []}, {"text": "In this paper, we focus on questions requiring a procedure asking for such navigation and intend to study the features necessary for its extraction by illustrating the specification of its answer.", "labels": [], "entities": []}, {"text": "In the above type of QA, very few studies have aimed at answering questions by extracting procedural expressions from web pages.", "labels": [], "entities": []}, {"text": "Accordingly, a) representations in a web text to indicate a procedure, b) the method of extracting those representations, and c) the way to combine related texts as an answer, are issues that have not been sufficiently clarified.", "labels": [], "entities": []}, {"text": "Consequently, past studies do not provide a general approach for solving this task.", "labels": [], "entities": []}, {"text": "In contrast, it has been reported that the texts related to QA in web pages contain many lists in the descriptions.", "labels": [], "entities": []}, {"text": "We decided to focus on lists including procedural expressions and employed an approach of extracting lists from web pages as answers.", "labels": [], "entities": []}, {"text": "This results in difficulty in extracting the answers written in a different style.", "labels": [], "entities": []}, {"text": "However, compared to seeking answer candidates from a document set including various web pages, it is expected that they will be found relatively more often from the gathered lists.", "labels": [], "entities": []}, {"text": "In this study, our motivation is to provide users with the means to navigate accurately and credibly to information on the Web, but not to give a complete relevant document set with respect to user queries.", "labels": [], "entities": []}, {"text": "In addition, a list is a summarization made by humans, and thus it is edited to make it easy to understand.", "labels": [], "entities": []}, {"text": "Therefore, the restriction to itemized answers doesn't lose its effectiveness in our study.", "labels": [], "entities": []}, {"text": "In the initial step of our work for this type of QA, we discuss a text categorization task that divides a set of lists into two groups: procedural and non-procedural.", "labels": [], "entities": []}, {"text": "First, we gathered web pages from a search engine and extracted lists including the procedural expressions tagged with any HTML(Hyper Text Markup Language) list tags found, and observed their characteristics.", "labels": [], "entities": []}, {"text": "Then we examined Support Vector Machines (SVMs) and sequential pattern mining relative to the set of lists, and observed the obtained model to find useful features for extraction of answers to explain a relevant procedure.", "labels": [], "entities": [{"text": "sequential pattern mining", "start_pos": 52, "end_pos": 77, "type": "TASK", "confidence": 0.6500881711641947}]}, {"text": "In the following section, we introduce some related work.", "labels": [], "entities": []}, {"text": "Section 3 presents the list features including procedural expressions in the web pages.", "labels": [], "entities": []}, {"text": "Subsequently, we will apply our machine learning and sequential pattern mining techniques to learn these features, which are briefly illustrated in Section 4.", "labels": [], "entities": [{"text": "sequential pattern mining", "start_pos": 53, "end_pos": 78, "type": "TASK", "confidence": 0.603743980328242}]}, {"text": "Section 5 shows the results of our categorization experiments.", "labels": [], "entities": []}, {"text": "Finally, Section 6 presents our conclusions and Section 7 gives our plans for future study.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the first experiment, to determine the categorization capability of a domain, we employed a set of lists in the Computer domain and conducted a crossvalidation procedure.", "labels": [], "entities": []}, {"text": "The document set was divided into five subsets of nearly equal size, and five different SVMs, the training sets of four of the subsets, and the remaining one classified for testing.", "labels": [], "entities": []}, {"text": "In the second experiment, to determine the categorization capability of an open domain, we employed a set of lists from the Others domain with the document set in the first experiment.", "labels": [], "entities": []}, {"text": "Then, the set of the lists from the Others domain was used in the test and the one from the Computer domain was used in the training, and their training and testing roles were also switched.", "labels": [], "entities": []}, {"text": "In both experiments, recall, precision, and, occasionally, F-measure value were calculated to evaluate categorization performance.", "labels": [], "entities": [{"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9996767044067383}, {"text": "precision", "start_pos": 29, "end_pos": 38, "type": "METRIC", "confidence": 0.9995036125183105}, {"text": "F-measure value", "start_pos": 59, "end_pos": 74, "type": "METRIC", "confidence": 0.9816108345985413}]}, {"text": "Fmeasure is calculated with precision (P) and recall (R) in formula 1.", "labels": [], "entities": [{"text": "Fmeasure", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9496989250183105}, {"text": "precision (P)", "start_pos": 28, "end_pos": 41, "type": "METRIC", "confidence": 0.936942458152771}, {"text": "recall (R)", "start_pos": 46, "end_pos": 56, "type": "METRIC", "confidence": 0.9568642973899841}]}, {"text": "The lists in the experiment were gathered from those marked by the list tags in the pages.", "labels": [], "entities": []}, {"text": "To focus on the feasibility of the features in the lists for the categorization task, the contexts before and after each list are not targeted.  with word N-gram and patterns; polynomial kernel degree d for the SVM was equal to one.", "labels": [], "entities": []}, {"text": "Support values for PrefixSpan were determined in an ad hoc manner to produce a sufficient number of patterns in our experimental conditions.", "labels": [], "entities": []}, {"text": "To investigate the effective features for list categorization, feature sets of the lists were divided into five groups (see) with consideration given to the difference of content word and function words according to our observations (described in Section 3.3).", "labels": [], "entities": [{"text": "list categorization", "start_pos": 42, "end_pos": 61, "type": "TASK", "confidence": 0.71437007188797}]}, {"text": "The values in indicate the numbers of differences between words in each domain data set.", "labels": [], "entities": []}, {"text": "The notation of tags above, such as 'snp', follows the categories in.", "labels": [], "entities": []}, {"text": "F2 and F3 consist of content words and F4 and F5 consist of function words.", "labels": [], "entities": []}, {"text": "F6 was a feature group, which added verbal nouns based on our observations (described in Section 3.3).", "labels": [], "entities": [{"text": "F6", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.7798054218292236}]}, {"text": "To observe the performances of SVM, we compared the results of categorizations in the conditions of F3 and F5 with a decision tree.", "labels": [], "entities": [{"text": "SVM", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.8777346014976501}]}, {"text": "For decision tree learning, j48.j48, which is an implementation of the C4.5 algorithm by Weka 3 , was chosen.", "labels": [], "entities": [{"text": "decision tree learning", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.8159908652305603}]}, {"text": "In these experiments, only the first sentence in each list item was used because in our preliminary experiments, we obtained the best results when only the first sentence was used in categorization.", "labels": [], "entities": []}, {"text": "As many as a thousand patterns from the top in the ranking of frequencies were selected and used in conditions from F1 to F6.", "labels": [], "entities": [{"text": "F1", "start_pos": 116, "end_pos": 118, "type": "METRIC", "confidence": 0.9975993037223816}]}, {"text": "For pattern selection, we examined the method based on frequency.", "labels": [], "entities": [{"text": "pattern selection", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.9006379842758179}]}, {"text": "In addition, mutual information filtering was conducted in some conditions for comparison with performances based only on pattern frequency.", "labels": [], "entities": [{"text": "mutual information filtering", "start_pos": 13, "end_pos": 41, "type": "TASK", "confidence": 0.8140294949213663}]}, {"text": "By ranking these with the mutual information filtering, we selected 100, 300,    and 500 patterns from 1000 patterns.", "labels": [], "entities": []}, {"text": "Furthermore, the features of N-grams were varied to N=1, 1+2, and 1+2+3 by incrementing N and adding new Ngrams to the features in the experiments.", "labels": [], "entities": []}, {"text": "lists the results of a 5-fold cross-validation evaluation of the Computer domain lists.", "labels": [], "entities": [{"text": "Computer domain lists", "start_pos": 65, "end_pos": 86, "type": "DATASET", "confidence": 0.8814656535784403}]}, {"text": "Gradually, N-grams and patterns were added to input feature vectors, thus N=1, 2, 3, and patterns.", "labels": [], "entities": []}, {"text": "The feature group primarily constructed of content words slightly overtook the function group, with the exception of recall, while trigram and patterns were added.", "labels": [], "entities": [{"text": "recall", "start_pos": 117, "end_pos": 123, "type": "METRIC", "confidence": 0.997116208076477}]}, {"text": "In the comparison of F2 and F4, differences in performance are not as salient as differences in numbers of features.", "labels": [], "entities": [{"text": "F4", "start_pos": 28, "end_pos": 30, "type": "DATASET", "confidence": 0.7754554748535156}]}, {"text": "Incorporating verbal nouns into the categorization slightly improved the results.", "labels": [], "entities": []}, {"text": "However, the patterns didn't work in this task.", "labels": [], "entities": []}, {"text": "The same experiment-switching the roles of the two list sets, the Computer and the Others domain, was then performed (see.", "labels": [], "entities": []}, {"text": "Along with adding N-grams, the recall became worse for the group of content words.", "labels": [], "entities": [{"text": "recall", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.9994314312934875}]}, {"text": "In contrast, the group of function words showed better perfor-  From another perspective, when trigram was added as a feature, performance took decreased in recall.", "labels": [], "entities": [{"text": "perfor-", "start_pos": 55, "end_pos": 62, "type": "METRIC", "confidence": 0.9609181582927704}, {"text": "recall", "start_pos": 157, "end_pos": 163, "type": "METRIC", "confidence": 0.997649610042572}]}, {"text": "Adding the patterns, however, improved performance.", "labels": [], "entities": []}, {"text": "It is assumed that there are dependencies between words at a distance greater than three words, which is beneficial in their categorization.", "labels": [], "entities": []}, {"text": "compares the results of SVM and j48.j48 decision tree.", "labels": [], "entities": []}, {"text": "lists the effectiveness of mutual information filtering.", "labels": [], "entities": [{"text": "mutual information filtering", "start_pos": 27, "end_pos": 55, "type": "TASK", "confidence": 0.7543442646662394}]}, {"text": "In both tables, values show the F-measure calculated with formula 1.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9952176809310913}]}, {"text": "According to, SVM overtook j48.j48 overall.", "labels": [], "entities": [{"text": "SVM", "start_pos": 14, "end_pos": 17, "type": "DATASET", "confidence": 0.8873662948608398}]}, {"text": "j48.j48 scarcely changes with an increase in the number of features, however, SVM gradually improves performance.", "labels": [], "entities": []}, {"text": "For mutual information filtering, SVM marked the best results with no-filter in the Computer domain.", "labels": [], "entities": [{"text": "mutual information filtering", "start_pos": 4, "end_pos": 32, "type": "TASK", "confidence": 0.7807846268018087}, {"text": "SVM", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.8030894994735718}]}, {"text": "However, in the case of learning from the Others domain, the mutual information filtering appears effective.", "labels": [], "entities": [{"text": "mutual information filtering", "start_pos": 61, "end_pos": 89, "type": "TASK", "confidence": 0.6300923724969228}]}], "tableCaptions": [{"text": " Table 1: Result from a Search Engine.", "labels": [], "entities": []}, {"text": " Table 2: Domain and Type of List.", "labels": [], "entities": []}, {"text": " Table 4: Statistics of Data Sets.  Proc. Non-Proc. Comp.  Others  Lists  721  3399  2224  1896  Items 4.6 / 2.8 4.9 / 5.7 4.8 / 6.1 4.9 / 4.4  Sen. 1.8 / 1.7 1.3 / 0.9 1.5 / 1.1 1.3 / 1.1  Char. 40.3 / 48.6 32.6 / 42.4 35.6 / 40.1 32.6 / 48.2", "labels": [], "entities": [{"text": "Statistics of Data Sets.  Proc. Non-Proc. Comp.  Others  Lists  721  3399  2224  1896  Items 4.6 / 2.8 4.9 / 5.7 4.8 / 6.1 4.9 / 4.4  Sen. 1.8 / 1.7 1.3 / 0.9 1.5 / 1.1 1.3 / 1.1  Char. 40.3", "start_pos": 10, "end_pos": 200, "type": "DATASET", "confidence": 0.784034882454162}]}, {"text": " Table 6: Result of Close-Domain.  Computer domain  1  1+2  1+2+3  pattern", "labels": [], "entities": []}, {"text": " Table 7: Results when Learning from Computer Do- main.  Computer Domain -Others Domain  1  1+2  1+2+3  pattern", "labels": [], "entities": []}, {"text": " Table 8: Results when Learning from Others Do- main.  Others Domain -Computer Domain  1  1+2  1+2+3  pattern", "labels": [], "entities": []}, {"text": " Table 9: Comparison of SVM and Decision Tree.", "labels": [], "entities": []}, {"text": " Table 10: Results of Pattern Selection with Mutual  Information Filtering.", "labels": [], "entities": [{"text": "Pattern Selection", "start_pos": 22, "end_pos": 39, "type": "TASK", "confidence": 0.9766218960285187}]}]}