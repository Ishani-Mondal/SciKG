{"title": [{"text": "Abductive Explanation-based Learning Improves Parsing Accuracy and Efficiency", "labels": [], "entities": [{"text": "Abductive Explanation-based Learning Improves Parsing", "start_pos": 0, "end_pos": 53, "type": "TASK", "confidence": 0.7951266705989838}, {"text": "Accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.666158139705658}]}], "abstractContent": [{"text": "Natural language parsing has to be accurate and quick.", "labels": [], "entities": [{"text": "Natural language parsing", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.6958940426508585}]}, {"text": "Explanation-based Learning (EBL) is a technique to speed-up parsing.", "labels": [], "entities": [{"text": "Explanation-based Learning (EBL)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.5733770489692688}]}, {"text": "The accuracy however often declines with EBL.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9996405839920044}, {"text": "EBL", "start_pos": 41, "end_pos": 44, "type": "METRIC", "confidence": 0.7424049973487854}]}, {"text": "The paper shows that this accuracy loss is not due to the EBL framework as such, but to deductive parsing.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9990897178649902}, {"text": "EBL framework", "start_pos": 58, "end_pos": 71, "type": "DATASET", "confidence": 0.8700505793094635}]}, {"text": "Abduc-tive EBL allows extending the deductive closure of the parser.", "labels": [], "entities": []}, {"text": "We present a Chi-nese parser based on abduction.", "labels": [], "entities": []}, {"text": "Experiments show improvements inaccuracy and efficiency.", "labels": [], "entities": []}], "introductionContent": [{"text": "The difficulties of natural language parsing, in general, and of parsing Chinese, in particular, are due to local ambiguities of words and phrases.", "labels": [], "entities": [{"text": "natural language parsing", "start_pos": 20, "end_pos": 44, "type": "TASK", "confidence": 0.6777333815892538}, {"text": "parsing Chinese", "start_pos": 65, "end_pos": 80, "type": "TASK", "confidence": 0.9074547290802002}]}, {"text": "Extensive linguistic and non-linguistic knowledge is required for their resolution.", "labels": [], "entities": [{"text": "their resolution", "start_pos": 66, "end_pos": 82, "type": "TASK", "confidence": 0.6314670443534851}]}, {"text": "Different parsing approaches provide different types of knowledge.", "labels": [], "entities": []}, {"text": "Example-based parsing approaches offer rich syntagmatic contexts for disambiguation, richer than rule-based approaches do (.", "labels": [], "entities": []}, {"text": "Statistical approaches to parsing acquire mainly paradigmatic knowledge and require larger corpora, c.f..", "labels": [], "entities": [{"text": "parsing", "start_pos": 26, "end_pos": 33, "type": "TASK", "confidence": 0.9756543636322021}]}, {"text": "Statistical approaches handle unseen events via smoothing.", "labels": [], "entities": []}, {"text": "Rule-based approaches use abstract category labels.", "labels": [], "entities": []}, {"text": "Example-based parsing generalizes examples during compilation time, e.g. (, or performs a similarity-based fuzzy match during runtime.", "labels": [], "entities": []}, {"text": "Both techniques maybe computationally demanding, their effect on parsing however is quite different, c.f.).", "labels": [], "entities": [{"text": "parsing", "start_pos": 65, "end_pos": 72, "type": "TASK", "confidence": 0.9756895303726196}]}, {"text": "Explanation-based learning (EBL) is a method to speed-up rule-based parsing via the caching of examples.", "labels": [], "entities": [{"text": "Explanation-based learning (EBL)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.6733953654766083}]}, {"text": "EBL however trades speed for accuracy.", "labels": [], "entities": [{"text": "EBL", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9527547359466553}, {"text": "speed", "start_pos": 19, "end_pos": 24, "type": "METRIC", "confidence": 0.9968103766441345}, {"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.998233437538147}]}, {"text": "For many systems, a small loss inaccuracy is acceptable if an order of magnitude less computing time is required.", "labels": [], "entities": []}, {"text": "Apart from speed, one generally recognizes that EBL acquires some kind of knowledge from texts.", "labels": [], "entities": [{"text": "speed", "start_pos": 11, "end_pos": 16, "type": "METRIC", "confidence": 0.9893039464950562}]}, {"text": "However, what is this knowledge like if it does not help with parsing?", "labels": [], "entities": [{"text": "parsing", "start_pos": 62, "end_pos": 69, "type": "TASK", "confidence": 0.974634051322937}]}, {"text": "Couldn't a system improve by learning its own output?", "labels": [], "entities": []}, {"text": "Can a system learn to parse Chinese by parsing Chinese?", "labels": [], "entities": []}, {"text": "The paper sets out to tackle these questions in theory and practice.", "labels": [], "entities": []}], "datasetContent": [{"text": "The aim of the experiments is to verify whether new knowledge is acquired in A-EBL and D-EBL.", "labels": [], "entities": [{"text": "A-EBL", "start_pos": 77, "end_pos": 82, "type": "METRIC", "confidence": 0.918023943901062}]}, {"text": "Secondly, we want to test the influence of new knowledge on parsing accuracy and speed.", "labels": [], "entities": [{"text": "parsing", "start_pos": 60, "end_pos": 67, "type": "TASK", "confidence": 0.9802195429801941}, {"text": "accuracy", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.973251223564148}, {"text": "speed", "start_pos": 81, "end_pos": 86, "type": "METRIC", "confidence": 0.987287163734436}]}, {"text": "The general setup of the experiment is the following.", "labels": [], "entities": []}, {"text": "We use a section of a treebank as seed-corpus ( ) . We train the seed-corpus to a corpus-based parser.", "labels": [], "entities": []}, {"text": "Using a test-corpus we establish the parsing # 4a deductive recursive parsing with lexeme, # 4b compared to abductive parsing accuracy and speed of the parser (q . A filter criterion that works on the explanation applies.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 126, "end_pos": 134, "type": "METRIC", "confidence": 0.9400292634963989}]}, {"text": "We train those trees which pass the filter to the parser (s ).", "labels": [], "entities": []}, {"text": "Then the parsing accuracy and speed is tested against the same training corpus (q (recall,precision,f-score,time)).", "labels": [], "entities": [{"text": "parsing", "start_pos": 9, "end_pos": 16, "type": "TASK", "confidence": 0.9705545902252197}, {"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9735312461853027}, {"text": "speed", "start_pos": 30, "end_pos": 35, "type": "METRIC", "confidence": 0.9829219579696655}, {"text": "recall,precision,f-score,time", "start_pos": 83, "end_pos": 112, "type": "METRIC", "confidence": 0.9913854598999023}]}, {"text": "Sections of the Chinese Sinica Treebank () are used as seed-treebank and gold standard for parsing evaluation.", "labels": [], "entities": [{"text": "Chinese Sinica Treebank", "start_pos": 16, "end_pos": 39, "type": "DATASET", "confidence": 0.9464653929074606}, {"text": "parsing evaluation", "start_pos": 91, "end_pos": 109, "type": "TASK", "confidence": 0.9188180565834045}]}, {"text": "Seed-corpora range between 1.000 and 20.000 trees.", "labels": [], "entities": []}, {"text": "We train them to the parser OCTOPUS.", "labels": [], "entities": [{"text": "OCTOPUS", "start_pos": 28, "end_pos": 35, "type": "DATASET", "confidence": 0.5460067987442017}]}, {"text": "This parser integrates memory-deduction-and abduction-based parsing in a hierarchy of preferences, starting from 1 memory-based parsing, 2 non-recursive deductive parsing, 3 recursive deductive parsing and 5 finally abductive parsing.", "labels": [], "entities": []}, {"text": "Learning the seed corpora (s The corpus used is a subset of the 5 Million word Sinica Corpus (.", "labels": [], "entities": [{"text": "5 Million word Sinica Corpus", "start_pos": 64, "end_pos": 92, "type": "DATASET", "confidence": 0.706447696685791}]}, {"text": "For every ( \u0087 C \u0086 the parser produces one parsetree \u0090 \u0088 \u00a8 ( r 2 a ! and an explanation.", "labels": [], "entities": [{"text": "parsetree \u0090 \u0088 \u00a8", "start_pos": 42, "end_pos": 57, "type": "METRIC", "confidence": 0.7331406027078629}]}, {"text": "The explanation has the form of a derivation tree in TAGs, c.f.", "labels": [], "entities": []}, {"text": "The deduction and abduction steps are visible in the explanation.", "labels": [], "entities": []}, {"text": "Filters apply on the explanation and create sub-corpora that belong to one inference type.", "labels": [], "entities": []}, {"text": "The first filter requires the explanation to contain only one non-recursive deduction, i.e. only parsing step 2.", "labels": [], "entities": []}, {"text": "As deductive parsing is attempted after memory-based parsing", "labels": [], "entities": [{"text": "deductive parsing", "start_pos": 3, "end_pos": 20, "type": "TASK", "confidence": 0.7081640064716339}, {"text": "parsing", "start_pos": 53, "end_pos": 60, "type": "TASK", "confidence": 0.7174474000930786}]}], "tableCaptions": []}