{"title": [{"text": "ProAlign: Shared Task System Description", "labels": [], "entities": [{"text": "ProAlign", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.8734608292579651}, {"text": "Shared Task System Description", "start_pos": 10, "end_pos": 40, "type": "TASK", "confidence": 0.5020084977149963}]}], "abstractContent": [{"text": "ProAlign combines several different approaches in order to produce high quality word word alignments.", "labels": [], "entities": [{"text": "ProAlign", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.8747596144676208}, {"text": "word word alignments", "start_pos": 80, "end_pos": 100, "type": "TASK", "confidence": 0.6446471114953359}]}, {"text": "Like competitive linking, ProAlign uses a constrained search to find high scoring alignments.", "labels": [], "entities": [{"text": "ProAlign", "start_pos": 26, "end_pos": 34, "type": "DATASET", "confidence": 0.858707070350647}]}, {"text": "Like EM-based methods, a probability model is used to rank possible alignments.", "labels": [], "entities": []}, {"text": "The goal of this paper is to give a bird's eye view of the ProAlign system to encourage discussion and comparison.", "labels": [], "entities": [{"text": "ProAlign system", "start_pos": 59, "end_pos": 74, "type": "DATASET", "confidence": 0.9365521967411041}]}, {"text": "1 Alignment Algorithm at a Glance We have submitted the ProAlign alignment system to the WPT'03 shared task.", "labels": [], "entities": [{"text": "ProAlign alignment", "start_pos": 56, "end_pos": 74, "type": "DATASET", "confidence": 0.7796216011047363}, {"text": "WPT'03 shared task", "start_pos": 89, "end_pos": 107, "type": "DATASET", "confidence": 0.7457656264305115}]}, {"text": "It received a 5.71% AER on the English-French task and 29.36% on the Romanian-English task.", "labels": [], "entities": [{"text": "AER", "start_pos": 20, "end_pos": 23, "type": "METRIC", "confidence": 0.9996135830879211}]}, {"text": "These results are with the no-null data; our output was not formatted to work with explicit nulls.", "labels": [], "entities": []}, {"text": "ProAlign works by iteratively improving an alignment.", "labels": [], "entities": [{"text": "ProAlign", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9386420249938965}]}, {"text": "The algorithm creates an initial alignment using search, constraints, and summed \u03c6 2 correlation-based scores (Gale and Church, 1991).", "labels": [], "entities": [{"text": "summed \u03c6 2 correlation-based scores", "start_pos": 74, "end_pos": 109, "type": "METRIC", "confidence": 0.766110897064209}]}, {"text": "This is similar to the competitive linking process (Melamed, 2000).", "labels": [], "entities": []}, {"text": "It then learns a probability model from the current alignment, and conducts a constrained search again, this time scoring alignments according to the probability model.", "labels": [], "entities": []}, {"text": "The process continues until results on a validation set begin to indicate over-fitting.", "labels": [], "entities": []}, {"text": "For the purposes of our algorithm, we view an alignment as a set of links between the words in a sentence pair.", "labels": [], "entities": []}, {"text": "Before describing the algorithm, we will define the following notation.", "labels": [], "entities": []}, {"text": "Let E bean English sentence e 1 , e 2 ,.", "labels": [], "entities": []}, {"text": ".. , em and let F be a French sentence f 1 , f 2 ,.", "labels": [], "entities": [{"text": "em", "start_pos": 5, "end_pos": 7, "type": "METRIC", "confidence": 0.9653618931770325}, {"text": "F", "start_pos": 16, "end_pos": 17, "type": "METRIC", "confidence": 0.9840548634529114}]}, {"text": "We define a link l(e i , f j) to exist if e i and f j area translation (or part of a translation) of one another.", "labels": [], "entities": []}, {"text": "We define the null link l(e i , f 0) to exist if e i does not correspond to a translation for any French word in F.", "labels": [], "entities": []}, {"text": "The null link l(e 0 , f j) is defined similarly.", "labels": [], "entities": []}, {"text": "An alignment A for two sentences E and F is a set of links such that every word in E and F participates in at least one link, and a word linked toe 0 or f 0 participates in no other links.", "labels": [], "entities": []}, {"text": "If e occurs in E x times and f occurs in F y times, we say that e and f co-occur xy times in this sentence pair.", "labels": [], "entities": []}, {"text": "ProAlign conducts a best-first search (with constant beam and agenda size) to search a constrained space of possible alignments.", "labels": [], "entities": [{"text": "ProAlign", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9520766139030457}]}, {"text": "A state in this space is a partial alignment, and a transition is defined as the addition of a single link to the current state.", "labels": [], "entities": []}, {"text": "Any link which would create a state that does not violate any constraint is considered to be a valid transition.", "labels": [], "entities": []}, {"text": "Our start state is the empty alignment, where all words in E and F are implicitly linked to null.", "labels": [], "entities": []}, {"text": "A terminal state is a state in which no more links can be added without violating a constraint.", "labels": [], "entities": []}, {"text": "Our goal is to find the terminal state with the highest probability.", "labels": [], "entities": []}, {"text": "To complete this algorithm, one requires a set of constraints and a method for determining which alignment is most likely.", "labels": [], "entities": []}, {"text": "These are presented in the next two sections.", "labels": [], "entities": []}, {"text": "The algorithm takes as input a set of English-French sentence pairs, along with dependency trees for the English sentences.", "labels": [], "entities": []}, {"text": "The presence of the English dependency tree allows us to incorporate linguistic features into our model and linguistic intuitions into our constraints.", "labels": [], "entities": []}, {"text": "2 Constraints The model used for scoring alignments has no mechanism to prevent certain types of undesirable alignments, such as having all French words align to the same En-glish word.", "labels": [], "entities": []}, {"text": "To guide the search to correct alignments, we employ two constraints to limit our search for the most probable alignment.", "labels": [], "entities": []}, {"text": "The first constraint is the one-to-one constraint (Melamed, 2000): every word (except the null words e 0 and f 0) participates in exactly one link.", "labels": [], "entities": []}, {"text": "The second constraint, known as the cohesion constraint (Fox, 2002), uses the dependency tree (Mel'\u02c7 cuk, 1987) of the English sentence to restrict possible link", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}