{"title": [{"text": "Word Selection for EBMT based on Monolingual Similarity and Translation Confidence", "labels": [], "entities": [{"text": "Word Selection", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7383176684379578}]}], "abstractContent": [{"text": "We propose a method of constructing an example-based machine translation (EBMT) system that exploits a content-aligned bilingual corpus.", "labels": [], "entities": [{"text": "example-based machine translation (EBMT)", "start_pos": 39, "end_pos": 79, "type": "TASK", "confidence": 0.8229849139849345}]}, {"text": "First, the sentences and phrases in the corpus are aligned across the two languages, and the pairs with high translation confidence are selected and stored in the translation memory.", "labels": [], "entities": []}, {"text": "Then, fora given input sentences, the system searches for fitting examples based on both the monolingual similarity and the translation confidence of the pair, and the obtained results are then combined to generate the translation.", "labels": [], "entities": []}, {"text": "Our experiments on translation selection showed the accuracy of 85% demonstrating the basic feasibility of our approach.", "labels": [], "entities": [{"text": "translation selection", "start_pos": 19, "end_pos": 40, "type": "TASK", "confidence": 0.9779132902622223}, {"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9996963739395142}]}], "introductionContent": [{"text": "The basic idea of example-based machine translation, or EBMT, is that translation examples similar to apart of an input sentence are retrieved and combined to produce a translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 32, "end_pos": 51, "type": "TASK", "confidence": 0.7478803098201752}]}, {"text": "In order to make a practical MT system based on this approach, a large number of translation examples with structural correspondences are required.", "labels": [], "entities": [{"text": "MT", "start_pos": 29, "end_pos": 31, "type": "TASK", "confidence": 0.995721697807312}]}, {"text": "This naturally presupposes high-accuracy parsers and well-aligned large bilingual corpora.", "labels": [], "entities": []}, {"text": "Over the last decade, the accuracy of the parsers improved significantly.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9995982050895691}]}, {"text": "The availability of well-aligned bilingual corpora, however, has not increased despite our expectations.", "labels": [], "entities": []}, {"text": "In reality, the number of bilingual corpora that share the same content, such as newspapers and broadcast news, has increased steadily.", "labels": [], "entities": []}, {"text": "We call this type of corpus a content-aligned corpus.", "labels": [], "entities": []}, {"text": "With these observations, we started a research project that covered all aspects of constructing EBMT systems starting from using First, the sentences and phrases in the corpus are aligned across the two languages, and the pairs with high translation confidence are selected and stored in the translation memory.", "labels": [], "entities": []}, {"text": "Then, translation examples are retrieved based on both the monolingual similarity and the translation confidence of the pair.", "labels": [], "entities": []}, {"text": "Finally, these examples are combined to generate the translation.", "labels": [], "entities": []}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "The next section presents how to build the translation memory from a content-aligned corpus.", "labels": [], "entities": []}, {"text": "Section 3 describes our EBMT system, paying special attention to the selection of translation examples.", "labels": [], "entities": []}, {"text": "Section 4 reports experimental results of word selection, Section 5 describes related works, and Section 6 gives our conclusions.", "labels": [], "entities": [{"text": "word selection", "start_pos": 42, "end_pos": 56, "type": "TASK", "confidence": 0.875062495470047}]}, {"text": "* Underlined phrases and sentences have no parallel expressions in the other language.", "labels": [], "entities": []}], "datasetContent": [{"text": "For evaluation, we selected 50 sentence pairs from the NHK News Corpus that were not used for the translation memory.", "labels": [], "entities": [{"text": "NHK News Corpus", "start_pos": 55, "end_pos": 70, "type": "DATASET", "confidence": 0.9691458940505981}, {"text": "translation memory", "start_pos": 98, "end_pos": 116, "type": "TASK", "confidence": 0.8975918889045715}]}, {"text": "Their source (Japanese) sentences were translated by our EBMT system, and the selected FTEs were evaluated by hand, referring to the target (English) sentences.", "labels": [], "entities": [{"text": "EBMT", "start_pos": 57, "end_pos": 61, "type": "DATASET", "confidence": 0.8550940155982971}, {"text": "FTEs", "start_pos": 87, "end_pos": 91, "type": "METRIC", "confidence": 0.979885995388031}]}, {"text": "A phrase by phrase evaluation was done to judge whether the English expression of the selected FTE was good or bad.", "labels": [], "entities": []}, {"text": "The accuracy was 85.0%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9997550845146179}]}, {"text": "In order to investigate the effectiveness of each component of FTE selection, we compared the following four methods: 4.", "labels": [], "entities": [{"text": "FTE selection", "start_pos": 63, "end_pos": 76, "type": "TASK", "confidence": 0.9740297496318817}]}, {"text": "DICONLY: Word selection is based only on dictionaries and frequency in the corpus.", "labels": [], "entities": [{"text": "DICONLY", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.582572877407074}, {"text": "Word selection", "start_pos": 9, "end_pos": 23, "type": "TASK", "confidence": 0.7936903834342957}]}, {"text": "The accuracy of each method is shown in, and the results indicate that the proposed method, EQ-CONTEXTALIGN, is the best, that is, using context similarity and align confidence works effectively.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9994731545448303}, {"text": "EQ-CONTEXTALIGN", "start_pos": 92, "end_pos": 107, "type": "METRIC", "confidence": 0.778178870677948}]}, {"text": "When there are no plausible translation examples in the translation memory, the system selects a low-similarity or low-confidence FTE.", "labels": [], "entities": [{"text": "FTE", "start_pos": 130, "end_pos": 133, "type": "METRIC", "confidence": 0.9914163947105408}]}, {"text": "However we believe this problem will be resolved as the number of translation examples increases, since the News Corpus is increasing day by day.", "labels": [], "entities": [{"text": "News Corpus", "start_pos": 108, "end_pos": 119, "type": "DATASET", "confidence": 0.9837757349014282}]}], "tableCaptions": [{"text": " Table 1: Number of TEs.  Corpus  WCR  # of TEs  0.3-0.4  18290  NHK News  0.4-0.5  6975  0.5- 2314  White Paper  - 2225  SENSEVAL  - 6920", "labels": [], "entities": [{"text": "Corpus  WCR  # of TEs  0.3-0.4  18290  NHK News  0.4-0.5  6975  0.5- 2314  White Paper  - 2225  SENSEVAL  - 6920", "start_pos": 26, "end_pos": 138, "type": "DATASET", "confidence": 0.8905651086852664}]}, {"text": " Table 2: Parameters for Similarity and Confidence Calculation.", "labels": [], "entities": [{"text": "Similarity and Confidence Calculation", "start_pos": 25, "end_pos": 62, "type": "TASK", "confidence": 0.6648808643221855}]}]}