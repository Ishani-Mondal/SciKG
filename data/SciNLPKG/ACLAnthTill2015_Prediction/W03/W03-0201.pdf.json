{"title": [], "abstractContent": [{"text": "This paper describes classification of typed student utterances within AutoTutor, an intelligent tutoring system.", "labels": [], "entities": [{"text": "classification of typed student utterances", "start_pos": 21, "end_pos": 63, "type": "TASK", "confidence": 0.840336000919342}]}, {"text": "Utterances are classified to one of 18 categories, including 16 question categories.", "labels": [], "entities": [{"text": "Utterances", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.9563850164413452}]}, {"text": "The classifier presented uses part of speech tagging, cascaded finite state transducers, and simple disambiguation rules.", "labels": [], "entities": [{"text": "speech tagging", "start_pos": 38, "end_pos": 52, "type": "TASK", "confidence": 0.7230691015720367}]}, {"text": "Shallow NLP is well suited to the task: session log file analysis reveals significant classification of eleven question categories, frozen expressions, and assertions.", "labels": [], "entities": []}], "introductionContent": [{"text": "AutoTutor is a domain-portable intelligent tutoring system (ITS) with current versions in the domains of physics and computer literacy (.", "labels": [], "entities": []}, {"text": "AutoTutor, like many other ITSs, is an intersection of applications, including tutoring, mixed-initiative dialogue, and question answering.", "labels": [], "entities": [{"text": "question answering", "start_pos": 120, "end_pos": 138, "type": "TASK", "confidence": 0.8749031126499176}]}, {"text": "In each of these, utterance classification, particularly question classification, plays a critical role.", "labels": [], "entities": [{"text": "utterance classification", "start_pos": 18, "end_pos": 42, "type": "TASK", "confidence": 0.9196978807449341}, {"text": "question classification", "start_pos": 57, "end_pos": 80, "type": "TASK", "confidence": 0.7827518284320831}]}, {"text": "In tutoring, utterance classification can be used to track the student's level of understanding.", "labels": [], "entities": [{"text": "utterance classification", "start_pos": 13, "end_pos": 37, "type": "TASK", "confidence": 0.9287894666194916}]}, {"text": "Contribution and question classifications can both play a role: contributions maybe compared to an expected answer () and questions maybe scored by how \"deep\" they are.", "labels": [], "entities": []}, {"text": "For example, The PREG model ( predicts under what circumstances students will ask \"deep\" questions, i.e. those that reveal a greater level of cognitive processing than who, what, when, or where questions.", "labels": [], "entities": []}, {"text": "A student who is only asking shallow questions, or no questions at all, is predicted by PREG to not have a situation-level understanding and thus to learn less and forget faster.", "labels": [], "entities": []}, {"text": "The key point is that different metrics for tracking student understanding are applicable to questions and contributions.", "labels": [], "entities": [{"text": "tracking student understanding", "start_pos": 44, "end_pos": 74, "type": "TASK", "confidence": 0.5946110486984253}]}, {"text": "Distinguishing them via classification is a first step to applying a metric.", "labels": [], "entities": []}, {"text": "In mixed-initiative dialog systems, utterance classification can be used to detect shifts in initiative.", "labels": [], "entities": [{"text": "utterance classification", "start_pos": 36, "end_pos": 60, "type": "TASK", "confidence": 0.877575159072876}]}, {"text": "For example, a mixed-initiative system that asks, \"Where would you like to travel\", could respond to the question, \"Where can I travel for $200?\") by giving a list of cities.", "labels": [], "entities": []}, {"text": "In this example, the user is taking the initiative by requesting more information.", "labels": [], "entities": []}, {"text": "In order to respond properly, the system must detect that the user has taken initiative before it can respond appropriately; otherwise it might try to interpret the user's utterance as a travel destination.", "labels": [], "entities": []}, {"text": "In this sense, questions mark redirection of the dialogue, whereas contributions are continuations of the dialogue.", "labels": [], "entities": []}, {"text": "In order fora user to redirect the dialogue and thus exercise initiative, a mixed-initiative system must be able to distinguish questions and contributions.", "labels": [], "entities": []}, {"text": "Question classification as early as has been used as a basis for answering questions, a trend that continues today.", "labels": [], "entities": [{"text": "Question classification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8016136586666107}]}, {"text": "A common feature of these question-answering systems is that they first determine the expected answer type implicit in the question.", "labels": [], "entities": []}, {"text": "For example, \"How much does a pretzel cost\" might be classified according to the answer type of MONEY or QUANTITY.", "labels": [], "entities": [{"text": "MONEY", "start_pos": 96, "end_pos": 101, "type": "METRIC", "confidence": 0.9237163662910461}, {"text": "QUANTITY", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.9226544499397278}]}, {"text": "Knowledge of the expected answer type can be used to narrow the search space for the answer, either online () or in a database (.", "labels": [], "entities": []}, {"text": "Accordingly, question answering calls fora finer discrimination of question types as opposed to only distinguishing questions from contributions.", "labels": [], "entities": [{"text": "question answering", "start_pos": 13, "end_pos": 31, "type": "TASK", "confidence": 0.9461190104484558}]}, {"text": "AutoTutor uses utterance classification to track student progress, to determine initiative, and to answer questions.", "labels": [], "entities": [{"text": "AutoTutor", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.8521558046340942}, {"text": "utterance classification", "start_pos": 15, "end_pos": 39, "type": "TASK", "confidence": 0.8622328341007233}]}, {"text": "By virtue of being embedded in AutoTutor, the utterance classifier presented here has an unusual set of constraints, both practical and theoretical.", "labels": [], "entities": []}, {"text": "On the practical side, AutoTutor is a web-based application that performs in real time; thus utterance classification must also proceed in real time.", "labels": [], "entities": [{"text": "utterance classification", "start_pos": 93, "end_pos": 117, "type": "TASK", "confidence": 0.9275084137916565}]}, {"text": "For that reason, the classifier uses a minimum of resources, including part of speech tagging and cascaded finite state transducers defining the categories.", "labels": [], "entities": [{"text": "speech tagging", "start_pos": 79, "end_pos": 93, "type": "TASK", "confidence": 0.7283609509468079}]}, {"text": "Theoretically speaking, AutoTutor must also recognize questions in a meaningful way to both question answering and tutoring.", "labels": [], "entities": [{"text": "question answering", "start_pos": 92, "end_pos": 110, "type": "TASK", "confidence": 0.8110169768333435}]}, {"text": "The question taxonomy utilized, that of, is an extension of taxonomy for question answering and has been applied to human tutoring (.", "labels": [], "entities": [{"text": "question answering", "start_pos": 73, "end_pos": 91, "type": "TASK", "confidence": 0.8116305470466614}]}, {"text": "This paper outlines the utterance classifier and quantifies its performance.", "labels": [], "entities": [{"text": "utterance classifier", "start_pos": 24, "end_pos": 44, "type": "TASK", "confidence": 0.791260153055191}]}, {"text": "In particular, Section 2 presents AutoTutor.", "labels": [], "entities": []}, {"text": "Section 3 presents the utterance taxonomy.", "labels": [], "entities": []}, {"text": "Section 4 describes the classifier algorithm.", "labels": [], "entities": []}, {"text": "Section 5 delineates the training process and results.", "labels": [], "entities": []}, {"text": "Section 6 presents evaluation of the classifier on real AutoTutor sessions.", "labels": [], "entities": []}, {"text": "Section 7 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "The classifier was used in AutoTutor sessions throughout the year of 2002.", "labels": [], "entities": []}, {"text": "The log files from these sessions contained 9094 student utterances, each of which was classified by an expert.", "labels": [], "entities": []}, {"text": "The expert ratings were compared to the classifier's ratings, forming a 2 x 2 contingency table for each category as in.", "labels": [], "entities": []}, {"text": "To expedite ratings, utterances extracted from the log files were split into two groups, contributions and non-contributions, according to their logged classification.", "labels": [], "entities": []}, {"text": "Expert judges were assigned to a group and instructed to classify a set of utterances to one of the 18 categories.", "labels": [], "entities": []}, {"text": "Though inter-rater reliability using the kappa statistic (Carletta 1996) maybe calculated for each group, the distribution of categories in the contribution group was highly skewed and warrants further discussion.", "labels": [], "entities": []}, {"text": "Skewed categories bias the kappa statistic to low values even when the proportion of rater agreement is very high).", "labels": [], "entities": []}, {"text": "In the contribution group, judges can expect to see mostly one category, contribution, whereas judges in the non-contribution group can expect to seethe other 17 categories.", "labels": [], "entities": []}, {"text": "Expected agreement by chance for the contribution group was 98%.", "labels": [], "entities": [{"text": "Expected", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9884912967681885}, {"text": "agreement", "start_pos": 9, "end_pos": 18, "type": "METRIC", "confidence": 0.5697318911552429}]}, {"text": "Correspondingly, inter-rater reliability using the kappa statistic was low for the contribution group, .5 despite 99% proportion agreement, and high for non-contribution group, .93.", "labels": [], "entities": [{"text": "reliability", "start_pos": 29, "end_pos": 40, "type": "METRIC", "confidence": 0.7919368147850037}]}, {"text": "However, the .93 inter-rater agreement can be extended to all of the utterance categories.", "labels": [], "entities": []}, {"text": "Due to classifier error, the non-contribution group consisted of 38% contributions.", "labels": [], "entities": []}, {"text": "Thus the .93 agreement applies to contributions in this group.", "labels": [], "entities": []}, {"text": "Equal proportion of agreement for contribution classifications in both groups, 99%, suggests that the differences in kappa solely reflect differences in category skew across groups.", "labels": [], "entities": [{"text": "agreement", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.9454658627510071}]}, {"text": "Under this analysis, dividing the utterances into two groups improved the distribution of categories for the calculation of kappa.", "labels": [], "entities": []}, {"text": "Expert judges classified questions with a .93 kappa, which supports a monothetic classification scheme for this application.", "labels": [], "entities": []}, {"text": "In Section 3 the possibility was raised of a polythetic scheme for question classification, i.e. one in which two categories could be assigned to a given question.", "labels": [], "entities": [{"text": "question classification", "start_pos": 67, "end_pos": 90, "type": "TASK", "confidence": 0.8165057003498077}]}, {"text": "If a polythetic scheme were truly necessary, one would expect inter-rater reliability to suffer in a monothetic classification task.", "labels": [], "entities": [{"text": "reliability", "start_pos": 74, "end_pos": 85, "type": "METRIC", "confidence": 0.8719791173934937}]}, {"text": "High inter-rater reliability on the monothetic classification task renders polythetic schemes superfluous for this application.", "labels": [], "entities": [{"text": "monothetic classification task", "start_pos": 36, "end_pos": 66, "type": "TASK", "confidence": 0.7872056365013123}]}, {"text": "The recall column for evaluation in is generally much higher than corresponding cells in the precision column.", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.998943030834198}, {"text": "precision", "start_pos": 93, "end_pos": 102, "type": "METRIC", "confidence": 0.9984371066093445}]}, {"text": "The disparity implies a high rate of false positives for each of the categories.", "labels": [], "entities": []}, {"text": "One possible explanation is the reconstruction algorithm applied during classification.", "labels": [], "entities": [{"text": "classification", "start_pos": 72, "end_pos": 86, "type": "TASK", "confidence": 0.9722755551338196}]}, {"text": "It was observed that, particularly in the language of physics, student used question stems in utterances that were not questions, e.g. \"The ball will land when \u2026\" Such falsely reconstructed questions account for 40% of the questions detected by the classifier.", "labels": [], "entities": []}, {"text": "Whether modifying the reconstruction algorithm would improve F-measure, i.e. improve precision without sacrificing recall, is a question for future research.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 61, "end_pos": 70, "type": "METRIC", "confidence": 0.9908487796783447}, {"text": "precision", "start_pos": 85, "end_pos": 94, "type": "METRIC", "confidence": 0.9987953901290894}, {"text": "recall", "start_pos": 115, "end_pos": 121, "type": "METRIC", "confidence": 0.993107795715332}]}, {"text": "The distribution of categories is highly skewed: 97% of the utterances were contributions, and example questions never occurred at all.", "labels": [], "entities": []}, {"text": "In addition to recall, fallout, precision, and F-measure, significance tests were calcu-  Though not appropriate for hypothesis testing in this instance, likelihood ratios provide a comparison of classifier performance across categories.", "labels": [], "entities": [{"text": "recall", "start_pos": 15, "end_pos": 21, "type": "METRIC", "confidence": 0.998807430267334}, {"text": "precision", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9994540810585022}, {"text": "F-measure", "start_pos": 47, "end_pos": 56, "type": "METRIC", "confidence": 0.9969105124473572}]}, {"text": "Likelihood ratios are particularly useful when comparing common and rare events, making them natural here given the rareness of most question categories and the frequency of contributions.", "labels": [], "entities": []}, {"text": "The likelihood ratios in the rightmost column of are on a natural logarithmic scale, -2ln\u03bb, so procedural ate . 5 x 20.23 = 24711 is more likely than goal orientation, ate . 5 x 14.49 = 1401, with respect to the base rate, or null hypothesis.", "labels": [], "entities": []}, {"text": "To judge overall performance on the AutoTutor sessions, an average weighted F-measure maybe calculated by summing the products of all category Fmeasures with their frequencies: The average weighted F-measure reflects real world performance since accuracy on frequently occurring classes is weighted more.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 76, "end_pos": 85, "type": "METRIC", "confidence": 0.9602714776992798}, {"text": "accuracy", "start_pos": 246, "end_pos": 254, "type": "METRIC", "confidence": 0.9946462512016296}]}, {"text": "The average weighted Fmeasure for the evaluation data is .98, mostly due to the great frequency of contributions (.97 of all utterances) and the high associated F-measure.", "labels": [], "entities": [{"text": "Fmeasure", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9841070175170898}, {"text": "F-measure", "start_pos": 161, "end_pos": 170, "type": "METRIC", "confidence": 0.9870665669441223}]}, {"text": "Without weighting, the average F-measure for the significant cells is .54.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 31, "end_pos": 40, "type": "METRIC", "confidence": 0.9990143775939941}]}, {"text": "With respect to the three applications mentioned, i) tracking student understanding, ii) mixed-initiative dialogue, and iii) questions answering, the classifier is doing extremely well on the first two and adequately on the last.", "labels": [], "entities": [{"text": "tracking student understanding", "start_pos": 53, "end_pos": 83, "type": "TASK", "confidence": 0.6479840477307638}, {"text": "questions answering", "start_pos": 125, "end_pos": 144, "type": "TASK", "confidence": 0.7370306551456451}]}, {"text": "The first two applications for the most part require distinguishing questions from contributions, which the classifier does extremely well, F-measure = .99.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 140, "end_pos": 149, "type": "METRIC", "confidence": 0.9976736903190613}]}, {"text": "Question answering, on the other hand, can benefit from more precise identification of the question type, and the average unweighted F-measure for the significant questions is .48.", "labels": [], "entities": [{"text": "Question answering", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9281759262084961}, {"text": "F-measure", "start_pos": 133, "end_pos": 142, "type": "METRIC", "confidence": 0.964522659778595}]}], "tableCaptions": [{"text": " Table 4. Training data and AutoTutor results.", "labels": [], "entities": [{"text": "Training data", "start_pos": 10, "end_pos": 23, "type": "DATASET", "confidence": 0.6566317677497864}, {"text": "AutoTutor", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.9181007146835327}]}]}