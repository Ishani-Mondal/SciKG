{"title": [{"text": "Preferential Presentation of Japanese Near-Synonyms Using Definition Statements", "labels": [], "entities": [{"text": "Preferential Presentation of Japanese Near-Synonyms", "start_pos": 0, "end_pos": 51, "type": "TASK", "confidence": 0.8768028974533081}]}], "abstractContent": [{"text": "This paper proposes anew method of ranking near-synonyms ordered by their suitability of nuances in a particular context.", "labels": [], "entities": []}, {"text": "Our method distincts near-synonyms by semantic features extracted from their definition statements in an ordinary dictionary , and ranks them by the types of features and a particular context.", "labels": [], "entities": []}, {"text": "Our method is an initial step to achieve a semantic paraphrase system for authoring support.", "labels": [], "entities": []}], "introductionContent": [{"text": "Most researches on automatic paraphrasing aim either at document modification fora wide range of NLP applications), at reading comprehension support), or at transformation based on external constraints.", "labels": [], "entities": [{"text": "document modification", "start_pos": 56, "end_pos": 77, "type": "TASK", "confidence": 0.7273234724998474}]}, {"text": "On the other hand, authoring / revision support is known as another type of paraphrasing which targets at texts in preparation.", "labels": [], "entities": [{"text": "authoring / revision support", "start_pos": 19, "end_pos": 47, "type": "TASK", "confidence": 0.830757662653923}]}, {"text": "However, there are not so many researches of such paraphrasing.", "labels": [], "entities": []}, {"text": "Paraphrase systems which aim at revising documents can be classified into three types: \u2022 Syntactic suitability This type of systems points out spelling or grammatical mistakes and corrects them, such as a grammar checker).", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate our ranking method, we randomly extracted 40 sentences from corpora and applied our method to a certain word in each sentence.", "labels": [], "entities": []}, {"text": "Also, for each case, we manually selected all near-synonyms which can be paraphrased . We evaluated the ranking results of our method by the measure of noninterpolated average precision (NAP): where R is the number of near-synonyms which can be paraphrased, n is the number of presented nearsynonyms, and 1 if a near synonym in rank i can be paraphrased 0 otherwize shows the result.", "labels": [], "entities": [{"text": "noninterpolated average precision (NAP)", "start_pos": 152, "end_pos": 191, "type": "METRIC", "confidence": 0.8392219841480255}]}, {"text": "shows that our method is remarkably effective for the judgement of semantic suitability of near-synonyms if a target word is not ambiguous.", "labels": [], "entities": []}, {"text": "However, the average precision is worse for ambiguous words, thus it is important to disambiguate those target words before applying to our method.", "labels": [], "entities": [{"text": "precision", "start_pos": 21, "end_pos": 30, "type": "METRIC", "confidence": 0.9972338080406189}]}, {"text": "For the criterion if a word can paraphrase to another or not, we dissemble any addition / deletion informations.", "labels": [], "entities": []}, {"text": "That is, we assume that a word can paraphrase if the paraphrased sentence has the same meaning as the original with some changes to their context.", "labels": [], "entities": []}, {"text": "Most of failure results are caused by the following cases; incorrect core meanings or fine-grained meanings were extracted in Section 3; adequate relations between a near-synonym and an input context could not be identified because of the ambiguity of neighbor words in the input sentence; or the semantic range of the label of a denotation or a lexical restriction is too wide to express the fine-grained meaning of the near-synonym clearly.", "labels": [], "entities": []}, {"text": "In addition, shows that the average precision by only S v is worse than the one by only S d . It could be caused by the low precision of classification into lexical restrictions and by the inadequacy in the measure of similarity described in Section 4.2.", "labels": [], "entities": [{"text": "precision", "start_pos": 36, "end_pos": 45, "type": "METRIC", "confidence": 0.9886666536331177}, {"text": "precision", "start_pos": 124, "end_pos": 133, "type": "METRIC", "confidence": 0.9983288645744324}]}, {"text": "To improve those problems, another measure such as semantical similarities without using a structure of a thesaurus is needed.", "labels": [], "entities": []}, {"text": "Also, we would learn from a method of lexical choice with knowledge about collocational behavior).", "labels": [], "entities": []}, {"text": "Though we have not discussed the evaluation of the propriety of arrangements to an input sentence, it seems that the information of addition often occurs imprecisely, against that the information of deletion appears infrequently but almost correctly, because, in our method, all denotations of a target word are given as the information of addition when they do not match with any denotation of a near-synonym.", "labels": [], "entities": []}, {"text": "Therefore, we must define the importance of each addition information and to present selected ones.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Result of extracting core meanings", "labels": [], "entities": []}, {"text": " Table 3: Average precision of ranking", "labels": [], "entities": [{"text": "Average", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9710552096366882}, {"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9519516229629517}]}]}