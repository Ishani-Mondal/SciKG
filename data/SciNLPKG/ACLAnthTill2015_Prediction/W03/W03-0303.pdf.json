{"title": [{"text": "Word Alignment Based on Bilingual Bracketing", "labels": [], "entities": [{"text": "Word Alignment", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7099576145410538}]}], "abstractContent": [{"text": "In this paper, an improved word alignment based on bilingual bracketing is described.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 27, "end_pos": 41, "type": "TASK", "confidence": 0.7039168179035187}, {"text": "bilingual bracketing", "start_pos": 51, "end_pos": 71, "type": "TASK", "confidence": 0.6886140704154968}]}, {"text": "The explored approaches include using Model-1 conditional probability, a boosting strategy for lexicon probabilities based on importance sampling , applying Parts of Speech to discriminate English words and incorporating information of English base noun phrase.", "labels": [], "entities": []}, {"text": "The results of the shared task on French-English, Romanian-English and Chinese-English word alignments are presented and discussed.", "labels": [], "entities": [{"text": "Chinese-English word alignments", "start_pos": 71, "end_pos": 102, "type": "TASK", "confidence": 0.6385509173075358}]}], "introductionContent": [{"text": "Bilingual parsing based word alignment is promising but still difficult.", "labels": [], "entities": [{"text": "Bilingual parsing based word alignment", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.8161390423774719}]}, {"text": "The goal is to extract structure information from parallel sentences, and thereby improve word/phrase alignment via bilingual constraint transfer.", "labels": [], "entities": [{"text": "word/phrase alignment", "start_pos": 90, "end_pos": 111, "type": "TASK", "confidence": 0.6361686661839485}, {"text": "bilingual constraint transfer", "start_pos": 116, "end_pos": 145, "type": "TASK", "confidence": 0.6644482811292013}]}, {"text": "This approach can be generalized to the automatic acquisition of a translation lexicon and phrase translations esp.", "labels": [], "entities": [{"text": "automatic acquisition of a translation lexicon", "start_pos": 40, "end_pos": 86, "type": "TASK", "confidence": 0.6963916023572286}]}, {"text": "for languages for which resources are relatively scarce compared with English.", "labels": [], "entities": []}, {"text": "The parallel sentences in building Statistical Machine Translation (SMT) systems are mostly unrestricted text where full parsing often fails, and robustness with respect to the inherent noise of the parallel data is important.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 35, "end_pos": 72, "type": "TASK", "confidence": 0.8201135396957397}]}, {"text": "Bilingual Bracketing] is one of the bilingual shallow parsing approaches studied for Chinese-English word alignment.", "labels": [], "entities": [{"text": "Bilingual Bracketing", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.6670064181089401}, {"text": "Chinese-English word alignment", "start_pos": 85, "end_pos": 115, "type": "TASK", "confidence": 0.6198815902074178}]}, {"text": "It uses a translation lexicon within a probabilistic context free grammar (PCFG) as a generative model to analyze the parallel sentences with weak order constraints.", "labels": [], "entities": []}, {"text": "This provides a framework to incorporate knowledge from the English side such as POS, phrase structure and potentially more detailed parsing results.", "labels": [], "entities": [{"text": "phrase structure", "start_pos": 86, "end_pos": 102, "type": "TASK", "confidence": 0.7362421452999115}]}, {"text": "In this paper, we use a simplified bilingual bracketing grammar together with a statistical translation lexicon such as the Model-1 lexicon] to do the bilingual bracketing.", "labels": [], "entities": [{"text": "bilingual bracketing", "start_pos": 151, "end_pos": 171, "type": "TASK", "confidence": 0.6703011691570282}]}, {"text": "A boosting strategy is studied and applied to the statistical lexicon training.", "labels": [], "entities": []}, {"text": "English POS and Base Noun Phrase (NP) detection are used to further improve the alignment performance.", "labels": [], "entities": [{"text": "Base Noun Phrase (NP) detection", "start_pos": 16, "end_pos": 47, "type": "TASK", "confidence": 0.5428105507578168}]}, {"text": "Word alignments and phrase alignments are extracted from the parsing results as post processing.", "labels": [], "entities": [{"text": "Word alignments", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.6808275282382965}, {"text": "phrase alignments", "start_pos": 20, "end_pos": 37, "type": "TASK", "confidence": 0.7077459990978241}]}, {"text": "The settings of different translation lexicons within the bilingual bracketing framework are studied and experiments on word-alignment are carried out on Chinese-English, French-English, and RomanianEnglish language pairs.", "labels": [], "entities": []}, {"text": "The paper is structured as follows: in section 2, the simplified bilingual bracketing used in our system is described; in section 3, the boosting strategy based on importance sampling for IBM Model-1 lexicon is introduced; in section 4, English POS and English Base Noun Phrase are used to constrain the alignments ; in section 5, the experimental results are shown; summary and conclusions are given in section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "All the settings described so far are based on our previous experiments on Chinese-English (CE) alignment.", "labels": [], "entities": [{"text": "Chinese-English (CE) alignment", "start_pos": 75, "end_pos": 105, "type": "TASK", "confidence": 0.5745272278785706}]}, {"text": "These settings are then used directly without any adjustment of the parameters for the French-English (FE) and Romanian-English (RE) word alignment tasks.", "labels": [], "entities": [{"text": "French-English (FE) and Romanian-English (RE) word alignment tasks", "start_pos": 87, "end_pos": 153, "type": "TASK", "confidence": 0.5832429056366285}]}, {"text": "In this section, we will first describe our experiments on Chinese-English alignment, and then the results for the shared task on French-English and Romanian-English.", "labels": [], "entities": [{"text": "Chinese-English alignment", "start_pos": 59, "end_pos": 84, "type": "TASK", "confidence": 0.6604504436254501}]}, {"text": "For Chinese-English alignment, 365 sentence-pairs are randomly sampled from the Chinese Tree-bank provided by the Linguistic Data Consortium.", "labels": [], "entities": [{"text": "Chinese-English alignment", "start_pos": 4, "end_pos": 29, "type": "TASK", "confidence": 0.6744361072778702}, {"text": "Chinese Tree-bank", "start_pos": 80, "end_pos": 97, "type": "DATASET", "confidence": 0.9125479161739349}, {"text": "Linguistic Data Consortium", "start_pos": 114, "end_pos": 140, "type": "DATASET", "confidence": 0.7649605472882589}]}, {"text": "Three persons manually aligned the word-pairs independently, and the consistent alignments from all of them were used as the reference alignments.", "labels": [], "entities": []}, {"text": "There are totally 4094 word-pairs in the reference set.", "labels": [], "entities": []}, {"text": "Our way of alignment is very similar to the \"SURE\" (S) alignment defined in the shared task.", "labels": [], "entities": [{"text": "alignment", "start_pos": 11, "end_pos": 20, "type": "TASK", "confidence": 0.9486968517303467}]}, {"text": "The training data we used is 16K parallel sentence-pairs from Hong-Kong news data.", "labels": [], "entities": [{"text": "Hong-Kong news data", "start_pos": 62, "end_pos": 81, "type": "DATASET", "confidence": 0.7823824683825175}]}, {"text": "The English POS tagger we used is Brill's POS tagger.", "labels": [], "entities": [{"text": "Brill's POS tagger", "start_pos": 34, "end_pos": 52, "type": "DATASET", "confidence": 0.901615709066391}]}, {"text": "The base noun detector is.", "labels": [], "entities": []}, {"text": "The alignment is evaluated in terms of precision, recall, F-measure and alignment error rate (AER) defined in the shared task.", "labels": [], "entities": [{"text": "precision", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.9996299743652344}, {"text": "recall", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.9995123147964478}, {"text": "F-measure", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9978475570678711}, {"text": "alignment error rate (AER)", "start_pos": 72, "end_pos": 98, "type": "METRIC", "confidence": 0.9492100179195404}]}, {"text": "The results are shown in shows the effectiveness of using each setting on this small size training data.", "labels": [], "entities": []}, {"text": "Here the boosted model gives a noticeable improvement over the baseline.", "labels": [], "entities": []}, {"text": "However, our observations on the trial/test data showed very similar results for boosted and non-boosted models, so we present only the non-boosted results(standard Model-1) for the shared task of EF and RE word alignment.", "labels": [], "entities": [{"text": "RE word alignment", "start_pos": 204, "end_pos": 221, "type": "TASK", "confidence": 0.6941717763741811}]}, {"text": "Adding POS further improved the performance significantly.", "labels": [], "entities": []}, {"text": "The AER drops from 44.04 to 41.29.", "labels": [], "entities": [{"text": "AER", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.9991347193717957}]}, {"text": "Adding additional base noun phrase boundaries did not give as much improvement as we hoped.", "labels": [], "entities": []}, {"text": "There is only slight improvement in terms of AER and F-measure.", "labels": [], "entities": [{"text": "AER", "start_pos": 45, "end_pos": 48, "type": "METRIC", "confidence": 0.9997518658638}, {"text": "F-measure", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9975898265838623}]}, {"text": "One reason is that noun phrase boundaries is more directly related to phrase alignment than word-alignment.", "labels": [], "entities": [{"text": "phrase alignment", "start_pos": 70, "end_pos": 86, "type": "TASK", "confidence": 0.7344410866498947}]}, {"text": "A close examination showed that with wrong phrase-alignment, word-alignment can still be correct.", "labels": [], "entities": []}, {"text": "Another reason is that using the noun phrase boundaries this way may not be powerful enough to leverage the English structure information in Bilingual Bracketing.", "labels": [], "entities": [{"text": "Bilingual Bracketing", "start_pos": 141, "end_pos": 161, "type": "TASK", "confidence": 0.5201671272516251}]}, {"text": "More suitable ways could be bilingual chunk parsing, and refining the bracketing grammar as described in].", "labels": [], "entities": [{"text": "bilingual chunk parsing", "start_pos": 28, "end_pos": 51, "type": "TASK", "confidence": 0.7003263036410013}]}, {"text": "In the shared task experiments, we restricted the training data to sentences upto 60 words.", "labels": [], "entities": []}, {"text": "The statistics for the training sets are shown in  There are 447 test sentence pairs for English-French and 248 test sentence pairs for Romanian-English.", "labels": [], "entities": []}, {"text": "After the bilingual bracketing, we extracted only the explicit word alignment from lexical rules: A \u2192 e/f , where neither e nor f is the null(empty) word.", "labels": [], "entities": []}, {"text": "These explicit word alignments are more directly related to the translation quality in our SMT system than the null-word alignments.", "labels": [], "entities": [{"text": "SMT", "start_pos": 91, "end_pos": 94, "type": "TASK", "confidence": 0.9784693717956543}]}, {"text": "Also the explicit word alignments is in accordance with the \"SURE\" (S) alignment defined in the shared tasks.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 18, "end_pos": 33, "type": "TASK", "confidence": 0.6665069609880447}, {"text": "SURE\" (S) alignment", "start_pos": 61, "end_pos": 80, "type": "METRIC", "confidence": 0.7207830448945364}]}, {"text": "However the Bilingual Bracketing system is not adapted to the \"PROBABLE\" (P) alignment because of the inherent one-to-one mapping.", "labels": [], "entities": [{"text": "Bilingual Bracketing", "start_pos": 12, "end_pos": 32, "type": "TASK", "confidence": 0.5266945213079453}]}, {"text": "All the AERs in the following tables are calculated based solely on S alignment without any null alignments collected from the bracketing results.", "labels": [], "entities": [{"text": "AERs", "start_pos": 8, "end_pos": 12, "type": "METRIC", "confidence": 0.9964801669120789}]}, {"text": "For the limited resource task, we trained Model-1 lexicons in both directions: from source to target denoted as p(f |e) and from target to source denoted as p(e|f ).", "labels": [], "entities": []}, {"text": "These two lexicons are then plugged into the Bilingual Bracketing algorithm separately to get two sets of bilingual bracketing word alignments.", "labels": [], "entities": [{"text": "Bilingual Bracketing algorithm", "start_pos": 45, "end_pos": 75, "type": "DATASET", "confidence": 0.7845628062884012}, {"text": "bilingual bracketing word alignments", "start_pos": 106, "end_pos": 142, "type": "TASK", "confidence": 0.7147640436887741}]}, {"text": "The intersection of these two sets of word alignments is then collected.", "labels": [], "entities": []}, {"text": "The resulting AERs are shown in respectively.", "labels": [], "entities": [{"text": "AERs", "start_pos": 14, "end_pos": 18, "type": "METRIC", "confidence": 0.998076319694519}]}, {"text": "For the unlimited resource task, we again tagged the English sentences and base noun phrase boundaries as mentioned before.", "labels": [], "entities": []}, {"text": "Then corresponding Model-1 lexicon was trained and Bilingual Bracketing carried out.", "labels": [], "entities": [{"text": "Bilingual Bracketing", "start_pos": 51, "end_pos": 71, "type": "TASK", "confidence": 0.45915985107421875}]}, {"text": "Using the same strategies as in the limited resource task, we got the results shown in.", "labels": [], "entities": []}, {"text": "The table above show that adding English POS and base noun detection gave a consistent improvement for all conditions in the French-to-English alignment.", "labels": [], "entities": [{"text": "POS", "start_pos": 41, "end_pos": 44, "type": "METRIC", "confidence": 0.7874014973640442}, {"text": "noun detection", "start_pos": 54, "end_pos": 68, "type": "TASK", "confidence": 0.7164797186851501}]}, {"text": "The intersection of the two alignments greatly improves the precision, paired with a reduction in recall, still resulting in an overall improvement in F-measure and AER.", "labels": [], "entities": [{"text": "precision", "start_pos": 60, "end_pos": 69, "type": "METRIC", "confidence": 0.9997597336769104}, {"text": "recall", "start_pos": 98, "end_pos": 104, "type": "METRIC", "confidence": 0.9997816681861877}, {"text": "F-measure", "start_pos": 151, "end_pos": 160, "type": "METRIC", "confidence": 0.9987818598747253}, {"text": "AER", "start_pos": 165, "end_pos": 168, "type": "METRIC", "confidence": 0.9969457983970642}]}, {"text": "For the Romanian-English alignment the POS tagging and noun phrase boundaries did not help.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 39, "end_pos": 50, "type": "TASK", "confidence": 0.7834218442440033}]}, {"text": "On the small corpus the increase in vocabulary resulted in addition unknown words in the test sentences which introduces additional alignment errors.", "labels": [], "entities": []}, {"text": "Comparing the results of the French-English and Romanian-English alignment tasks we see a striking difference in precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 113, "end_pos": 122, "type": "METRIC", "confidence": 0.9995304346084595}, {"text": "recall", "start_pos": 127, "end_pos": 133, "type": "METRIC", "confidence": 0.9974243640899658}]}, {"text": "Whereas the FrenchEnglish alignment has a low precision and a high recall its the opposite for the Romanian-English alignment.", "labels": [], "entities": [{"text": "FrenchEnglish alignment", "start_pos": 12, "end_pos": 35, "type": "DATASET", "confidence": 0.9706369340419769}, {"text": "precision", "start_pos": 46, "end_pos": 55, "type": "METRIC", "confidence": 0.9989892840385437}, {"text": "recall", "start_pos": 67, "end_pos": 73, "type": "METRIC", "confidence": 0.9995884299278259}]}, {"text": "The cause lays in different styles for the manual alignments.", "labels": [], "entities": []}, {"text": "The French-English reference set contains both Sand P alignments, whereas the Romanian-English reference set was annotated with only S alignments.", "labels": [], "entities": [{"text": "French-English reference set", "start_pos": 4, "end_pos": 32, "type": "DATASET", "confidence": 0.7971573571364085}, {"text": "Romanian-English reference set", "start_pos": 78, "end_pos": 108, "type": "DATASET", "confidence": 0.7573519249757131}]}, {"text": "As a result, there are on average only 0.5 S alignments per word in the FE reference set, but 1.5 S alignments per word in the RE test set.", "labels": [], "entities": [{"text": "FE reference set", "start_pos": 72, "end_pos": 88, "type": "DATASET", "confidence": 0.8098031083742777}, {"text": "RE test set", "start_pos": 127, "end_pos": 138, "type": "DATASET", "confidence": 0.7974341909090678}]}], "tableCaptions": []}