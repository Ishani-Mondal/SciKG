{"title": [{"text": "Combining Semantic and Temporal Constraints for Multimodal Integra- tion in Conversation Systems", "labels": [], "entities": []}], "abstractContent": [{"text": "Ina multimodal conversation, user referring patterns could be complex, involving multiple referring expressions from speech utterances and multiple gestures.", "labels": [], "entities": []}, {"text": "To resolve those references, multimodal integration based on semantic constraints is insufficient.", "labels": [], "entities": []}, {"text": "In this paper, we describe a graph-based probabilistic approach that simultaneously combines both semantic and temporal constraints to achieve a high performance.", "labels": [], "entities": []}], "introductionContent": [{"text": "Multimodal conversation systems allow users to converse with systems through multiple modalities such as speech, gesture and gaze.", "labels": [], "entities": []}, {"text": "In such an environment, not only are more interaction modalities available, but also richer contexts are established during the interaction.", "labels": [], "entities": []}, {"text": "Understanding user inputs, for example, what users refer to is important.", "labels": [], "entities": []}, {"text": "Previous work on multimodal reference resolution includes the use of a focus space model (), the centering framework (), context factors (, and rules.", "labels": [], "entities": [{"text": "multimodal reference resolution", "start_pos": 17, "end_pos": 48, "type": "TASK", "confidence": 0.6655208269755045}]}, {"text": "These previous approaches focus on semantics constraints without fully addressing temporal constraints.", "labels": [], "entities": []}, {"text": "Ina user study , we found that the majority of user referring behavior involved one referring expression and one gesture (as in in).", "labels": [], "entities": []}, {"text": "The earlier approaches worked well for these types of references.", "labels": [], "entities": []}, {"text": "However, we found that 14.1% of the inputs were complex, which involved multiple referring expressions from speech utterances and multiple gestures (S3 in).", "labels": [], "entities": []}, {"text": "To resolve those complex references, we have to not only apply semantic constraints, but also apply temporal constraints at the same time.", "labels": [], "entities": []}, {"text": "For example, shows three inputs where the number of referring expressions is the same and the number of gestures is the same.", "labels": [], "entities": []}, {"text": "The speech utterances and gestures are aligned along the time axis.", "labels": [], "entities": []}, {"text": "The first case) and the second case have the same speech utterance but different temporal alignment between the gestures and the speech input.", "labels": [], "entities": []}, {"text": "The second case and the third case () have a similar alignment, but the third case provides an additional constraint on the number of referents (from the word \"two\").", "labels": [], "entities": []}, {"text": "Although all three cases are similar, but the objects they refer to are quite different in each case.", "labels": [], "entities": []}, {"text": "In the first case, most likely \"this\" refers to the house selected by the first point gesture and \"these houses\" refers to two houses selected by the other two gestures.", "labels": [], "entities": []}, {"text": "In the second case, \"this\" most likely refers to the highlighted house on the display and \"these houses\" refer to three houses selected by the gestures.", "labels": [], "entities": []}, {"text": "In the third case, \"this\" most likely refers to the house selected by the first point gesture and \"these two houses\" refers to two houses selected by the other two point gestures.", "labels": [], "entities": []}, {"text": "Referring patterns from the user study We are developing a system that helps users find real estate properties.", "labels": [], "entities": []}, {"text": "So here we use real estate as the testing domain.", "labels": [], "entities": []}, {"text": "Resolving these complex cases requires simultaneously satisfying semantic constraints from inputs and the interaction contexts, and the temporal constraints between speech and gesture.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}