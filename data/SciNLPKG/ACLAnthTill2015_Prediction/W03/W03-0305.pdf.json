{"title": [{"text": "Reducing Parameter Space for Word Alignment", "labels": [], "entities": [{"text": "Word Alignment", "start_pos": 29, "end_pos": 43, "type": "TASK", "confidence": 0.7543828785419464}]}], "abstractContent": [{"text": "This paper presents the experimental results of our attemps to reduce the size of the parameter space in word alignment algorithm.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 105, "end_pos": 119, "type": "TASK", "confidence": 0.8216534852981567}]}, {"text": "We use IBM Model 4 as a baseline.", "labels": [], "entities": [{"text": "IBM Model 4", "start_pos": 7, "end_pos": 18, "type": "DATASET", "confidence": 0.9444546699523926}]}, {"text": "In order to reduce the parameter space, we pre-processed the training corpus using a word lemmatizer and a bilingual term extraction algorithm.", "labels": [], "entities": [{"text": "term extraction", "start_pos": 117, "end_pos": 132, "type": "TASK", "confidence": 0.7054163217544556}]}, {"text": "Using these additional components, we obtained an improvement in the alignment error rate.", "labels": [], "entities": [{"text": "alignment error rate", "start_pos": 69, "end_pos": 89, "type": "METRIC", "confidence": 0.8150692184766134}]}], "introductionContent": [{"text": "We participated the workshop shared task for EnglishFrench and Romanian-English word alignment.", "labels": [], "entities": [{"text": "EnglishFrench", "start_pos": 45, "end_pos": 58, "type": "DATASET", "confidence": 0.889064610004425}, {"text": "Romanian-English word alignment", "start_pos": 63, "end_pos": 94, "type": "TASK", "confidence": 0.5510927041371664}]}, {"text": "We use IBM Model 4 as a baseline.", "labels": [], "entities": [{"text": "IBM Model 4", "start_pos": 7, "end_pos": 18, "type": "DATASET", "confidence": 0.9444546699523926}]}, {"text": "The number of parameters in this model roughly scales as the product of the vocabulary sizes (ie number of types) in the source and target languages.", "labels": [], "entities": []}, {"text": "In order to obtain better alignment performance, we wish to investigate techniques that may reduce the number of parameters, therefore increasing the datato-parameter ratio.", "labels": [], "entities": [{"text": "alignment", "start_pos": 26, "end_pos": 35, "type": "TASK", "confidence": 0.9592105746269226}]}, {"text": "For that purpose, we preprocessed the training corpus using a word lemmatizer and a bilingual lexicon extraction algorithm.", "labels": [], "entities": [{"text": "bilingual lexicon extraction", "start_pos": 84, "end_pos": 112, "type": "TASK", "confidence": 0.721454401810964}]}, {"text": "Section 2 briefly describes the base alignment algorithm, Section 3 describes our additional components, and Section 4 shows our experimental results, followed by Discussion and Conclusion in Section 5 and 6, respectively.", "labels": [], "entities": [{"text": "base alignment", "start_pos": 32, "end_pos": 46, "type": "TASK", "confidence": 0.6652514934539795}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: English-French shared task", "labels": [], "entities": []}, {"text": " Table 2: Romanian-English shared task", "labels": [], "entities": []}]}