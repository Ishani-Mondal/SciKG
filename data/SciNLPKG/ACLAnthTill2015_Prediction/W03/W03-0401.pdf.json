{"title": [{"text": "A model of syntactic disambiguation based on lexicalized grammars", "labels": [], "entities": [{"text": "syntactic disambiguation", "start_pos": 11, "end_pos": 35, "type": "TASK", "confidence": 0.7630729973316193}]}], "abstractContent": [{"text": "This paper presents anew approach to syntactic disambiguation based on lexicalized grammars.", "labels": [], "entities": [{"text": "syntactic disambiguation", "start_pos": 37, "end_pos": 61, "type": "TASK", "confidence": 0.8335578441619873}]}, {"text": "While existing disambiguation models decompose the probability of parsing results into that of primitive dependencies of two words, our model selects the most probable parsing result from a set of candidates allowed by a lexicalized grammar.", "labels": [], "entities": []}, {"text": "Since parsing results given by the lexicalized grammar cannot be decomposed into independent sub-events, we apply a maximum entropy model for feature forests, which allows probabilistic model-ing without the independence assumption.", "labels": [], "entities": []}, {"text": "Our approach provides a general method of producing a consistent probabilistic model of parsing results given by lexicalized grammars.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recent studies on the automatic extraction of lexicalized grammars) allow the modeling of syntactic disambiguation based on linguistically motivated grammar theories including LTAG) and CCG).", "labels": [], "entities": [{"text": "automatic extraction of lexicalized grammars", "start_pos": 22, "end_pos": 66, "type": "TASK", "confidence": 0.7857542037963867}, {"text": "syntactic disambiguation", "start_pos": 90, "end_pos": 114, "type": "TASK", "confidence": 0.7128704935312271}]}, {"text": "However, existing models of disambiguation with lexicalized grammars area mere extension of lexicalized probabilistic context-free grammars (LPCFG), which are based on the decomposition of parsing results into the syntactic/semantic dependencies of two words in a sentence under the assumption of independence of the dependencies.", "labels": [], "entities": []}, {"text": "While LPCFG models have proved that the incorporation of lexical associations (i.e., dependencies of words) significantly improves the accuracy of parsing, this idea has been naively inherited in the recent studies on disambiguation models of lexicalized grammars.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 135, "end_pos": 143, "type": "METRIC", "confidence": 0.9975146055221558}]}, {"text": "However, the disambiguation models of lexicalized grammars should be totally different from that of LPCFG, because the grammars define the relation of syntax and semantics, and can restrict the possible structure of parsing results.", "labels": [], "entities": []}, {"text": "Parsing results cannot simply be decomposed into primitive dependencies, because the complete structure is determined by solving the syntactic constraints of a complete sentence.", "labels": [], "entities": [{"text": "Parsing", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.9550643563270569}]}, {"text": "For example, when we apply a unification-based grammar, LPCFG-like modeling results in an inconsistent probability model because the model assigns probabilities to parsing results not allowed by the grammar.", "labels": [], "entities": []}, {"text": "We have only two ways of adhering to LPCFG models: preserve the consistency of probability models by abandoning improvements to the lexicalized grammars using complex constraints), or ignore the inconsistency in probability models).", "labels": [], "entities": []}, {"text": "This paper provides anew model of syntactic disambiguation in which lexicalized grammars can restrict the possible structures of parsing results.", "labels": [], "entities": [{"text": "syntactic disambiguation", "start_pos": 34, "end_pos": 58, "type": "TASK", "confidence": 0.787915974855423}]}, {"text": "Our modeling aims at providing grounds for i) producing a consistent probabilistic model of lexicalized grammars, as well as ii) evaluating the contributions of syntactic and semantic preferences to syntactic disambiguation.", "labels": [], "entities": [{"text": "syntactic disambiguation", "start_pos": 199, "end_pos": 223, "type": "TASK", "confidence": 0.8048148155212402}]}, {"text": "The model is composed of the syntax and semantics probabilities, which represent syntactic and semantic preferences respectively.", "labels": [], "entities": []}, {"text": "The syntax probability is responsible for determining the syntactic categories chosen by words in a sentence, and the semantics probability selects the most plausible dependencies of words from candidates allowed by the syntactic categories yielded by the syntax probability.", "labels": [], "entities": []}, {"text": "Since the sequence of syntactic categories restricts the possible structure of parsing results, the semantics probability is a conditional probability without decomposition into the primitive dependencies of words.", "labels": [], "entities": []}, {"text": "Recently used machine learning methods including maximum entropy models and support vector machines provide grounds for this type of modeling, because it allows various dependent features to be incorporated into the model without the independence assumption.", "labels": [], "entities": []}, {"text": "The above approach, however, has a serious deficiency: a lexicalized grammar assigns exponentially many parsing results because of local ambiguities in a sentence, which is problematic in estimating the parameters of a probability model.", "labels": [], "entities": []}, {"text": "To cope with this, we adopted an algorithm of maximum entropy estimation for feature forests, which allows parameters to be efficiently estimated.", "labels": [], "entities": []}, {"text": "The algorithm enables probabilistic modeling of complete structures, such as transition sequences in Markov models and parse trees, without dividing them into independent sub-events.", "labels": [], "entities": []}, {"text": "The algorithm avoids exponential explosion by representing a probabilistic event by a packed representation of a feature space.", "labels": [], "entities": []}, {"text": "If a complete structure is represented with a feature forest of a tractable size, the parameters can be efficiently estimated by dynamic programming.", "labels": [], "entities": []}, {"text": "A series of studies on parsing with wide-coverage LFG () have had a similar motivation to ours.", "labels": [], "entities": [{"text": "parsing", "start_pos": 23, "end_pos": 30, "type": "TASK", "confidence": 0.9860053062438965}]}, {"text": "Their models have also been based on a discriminative model to select a parsing result from all candidates given by the grammar.", "labels": [], "entities": []}, {"text": "A significant difference is that we apply maximum entropy estimation for feature forests to avoid the inherent problem with estimation: the exponential explosion of parsing results given by the grammar.", "labels": [], "entities": []}, {"text": "They assumed that parsing results would be suppressed to a reasonable number through using heuristic rules, or by carefully implementing a fully restrictive and wide-coverage grammar, which requires a considerable amount of effort to develop.", "labels": [], "entities": [{"text": "parsing", "start_pos": 18, "end_pos": 25, "type": "TASK", "confidence": 0.9678859114646912}]}, {"text": "Our contention is that this problem can be solved in a more sophisticated way as is discussed in this paper.", "labels": [], "entities": []}, {"text": "Another difference is that our model is separated into syntax and semantics probabilities, which will benefit computational/linguistic investigations into the relation between syntax and semantics, and allow separate improvements to both models.", "labels": [], "entities": []}, {"text": "Overall, the approach taken in this paper is different from existing models in the following respects.", "labels": [], "entities": []}, {"text": "\u2022 Since it does not require the assumption of independence, the probability model is consistent with lexicalized grammars with complex constraints including unification-based grammar formalism.", "labels": [], "entities": []}, {"text": "Our model can assign consistent probabilities to parsing results of lexicalized grammars, while the traditional models assign probabilities to parsing results not allowed by the grammar.", "labels": [], "entities": []}, {"text": "\u2022 Since the syntax and semantics probabilities are separate, we can improve them individually.", "labels": [], "entities": []}, {"text": "For example, the syntax model can be improved by smoothing using the syntactic classes of words, while the semantics model should be able to be improved by using semantic classes.", "labels": [], "entities": []}, {"text": "In addition, the model can be a starting point that allows the theory of syntax and semantics to be evaluated through consulting an extensive corpus.", "labels": [], "entities": []}, {"text": "We evaluated the validity of our model through experiments on a disambiguation task of parsing the Penn Treebank) with an automatically acquired LTAG grammar.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 99, "end_pos": 112, "type": "DATASET", "confidence": 0.9700779914855957}]}, {"text": "To assess the contribution of the syntax and semantics probabilities to the accuracy of parsing and to evaluate the validity of applying maximum entropy estimation for feature forests, we compared three models trained with the same training set and the same set of features.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9988534450531006}, {"text": "validity", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.955729603767395}]}, {"text": "Following the experimental results, we concluded that i) a parser with the syntax probability only achieved high accuracy with the lexicalized grammar, ii) the incorporation of preferences for lexical association through the semantics probability resulted in significant improvements, and iii) our model recorded an accuracy that was quite close to the traditional model, which indicated the validity of applying maximum entropy estimation for feature forests.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 113, "end_pos": 121, "type": "METRIC", "confidence": 0.9929131865501404}, {"text": "accuracy", "start_pos": 316, "end_pos": 324, "type": "METRIC", "confidence": 0.9989535808563232}]}, {"text": "In what follows, we first describe the existing models for syntactic disambiguation, and discuss problems with them in Section 2.", "labels": [], "entities": [{"text": "syntactic disambiguation", "start_pos": 59, "end_pos": 83, "type": "TASK", "confidence": 0.879100501537323}]}, {"text": "We then define the general form for parsing results of lexicalized grammars, and introduce our model in Section 3.", "labels": [], "entities": [{"text": "parsing results of lexicalized grammars", "start_pos": 36, "end_pos": 75, "type": "TASK", "confidence": 0.7981410026550293}]}, {"text": "We prove the validity of our approach through a series of experiments in Section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "The model proposed in Section 3 is generally applicable to any lexicalized grammars, and this section reports the evaluation of our model with a wide-coverage LTAG grammar, which is automatically acquired from the Penn Treebank () Sections 02-21.", "labels": [], "entities": [{"text": "Penn Treebank () Sections 02-21", "start_pos": 214, "end_pos": 245, "type": "DATASET", "confidence": 0.9698015093803406}]}, {"text": "The grammar was acquired by an algorithm similar to, and consisted of 2,105 elementary trees, where 1,010 were initial trees and 1,095 were auxiliary ones.", "labels": [], "entities": []}, {"text": "The coverage of the grammar against Section 22 (1,700 sentences) was 92.6% (1,575 sentences) in a weak sense (i.e., the grammar could output a structure consistent with the bracketing in the test corpus), and 68.0% (1,156 sentences) in a strong sense (i.e., the grammar could output exactly the correct derivation).", "labels": [], "entities": [{"text": "Section 22", "start_pos": 36, "end_pos": 46, "type": "DATASET", "confidence": 0.9376021027565002}]}, {"text": "Since the grammar acquisition algorithm could output derivation trees for the sentences in the training corpus (Section 02-21), we used them as a training set of the probability model.", "labels": [], "entities": [{"text": "grammar acquisition", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.7212013751268387}]}, {"text": "The model of syntax probability was estimated with syntactic categories appearing in the training set.", "labels": [], "entities": []}, {"text": "For estimating the semantics probability, a parser produced all possible derivation trees for each sequence of syntactic categories (corresponding to each sentence) in the training set, and the obtained derivation trees, i.e., A(c), are passed to a maximum entropy estimator.", "labels": [], "entities": [{"text": "A", "start_pos": 227, "end_pos": 228, "type": "METRIC", "confidence": 0.9470475316047668}]}, {"text": "By applying the grammar acquisition algorithm to Section 22, we obtained the derivation trees of the sentences in this section, and from this set we prepared a test set by eliminating non-sententials, long sentences (including more than 40 words), sentences not covered by the grammar, and sentences that caused time-outs in parsing.", "labels": [], "entities": [{"text": "grammar acquisition", "start_pos": 16, "end_pos": 35, "type": "TASK", "confidence": 0.7001357078552246}]}, {"text": "The resulting set consisted of 917 derivation trees.", "labels": [], "entities": []}, {"text": "The following three disambiguation models were prepared using the training set.", "labels": [], "entities": []}, {"text": "syntax Only composed of the syntax probability, i.e., p(c|w) traditional Similar to our model, but semantics probability p(A|c) was decomposed into the probabilities of the primitive dependencies of two words as in the traditional modeling, i.e., this model is an inconsistent probability model our model The model by maximum entropy estimation for feature forests The syntax probability was a unigram model, and contexts around the word such as previous words/categories were not used.", "labels": [], "entities": []}, {"text": "Hence, it includes only syntactic preferences of words.", "labels": [], "entities": []}, {"text": "The semantics parts of traditional and our model were maximum entropy models, where exactly the same set of features were used, i.e., the difference between the two models was only in an event representation: derivation trees were decomposed into primitive dependencies in traditional, while in our model they were represented by a feature forest without decomposition.", "labels": [], "entities": []}, {"text": "Hence, we can evaluate the effects of applying maximum entropy estimation for feature forests by comparing our model with traditional.", "labels": [], "entities": []}, {"text": "While our model allowed features to be incorporated that were not limited to the dependencies of two words (Section 3), the models used throughout the experiments only included features of the dependencies of two words.", "labels": [], "entities": []}, {"text": "The semantics probabilities were developed with two sets of features includ-: Accuracy of dependencies ing surface forms/POSs of words, the labels of dependencies (substitution/adjunction), and the distance between two words.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.970449686050415}]}, {"text": "The first feature set had 283,755 features and the other had 150,156 features excluding fine-grained features of the first set.", "labels": [], "entities": []}, {"text": "There were 701,819 events for traditional, and 32,371 for our model.", "labels": [], "entities": []}, {"text": "The difference in the number of events was caused by the difference in the units of events, i.e., an event corresponded to a dependency in traditional, while it corresponded to a sentence in our model.", "labels": [], "entities": []}, {"text": "The parameters of the models were estimated by the limited-memory BFGS algorithm) with a Gaussian distribution as the prior probability distribution for smoothing) implemented in a maximum entropy estimator for feature forests).", "labels": [], "entities": []}, {"text": "The estimation for traditional was converged in 67 iterations in 127 seconds, and our model in 29 iterations in 111 seconds on a Pentium III 1.26-GHz CPU with 4 GB of memory.", "labels": [], "entities": [{"text": "estimation", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9961453676223755}]}, {"text": "These results reveal that the estimation with our model is comparatively efficient with traditional.", "labels": [], "entities": []}, {"text": "The parsing algorithm was CKY-style parsing with beam thresholding, which was similar to ones used in).", "labels": [], "entities": [{"text": "parsing", "start_pos": 4, "end_pos": 11, "type": "TASK", "confidence": 0.987000048160553}, {"text": "CKY-style parsing", "start_pos": 26, "end_pos": 43, "type": "TASK", "confidence": 0.5895194709300995}]}, {"text": "Although we needed to compute normalizing factor Z c to obtain probability values, we used unnormalized products as the preference score for beam thresholding, following).", "labels": [], "entities": [{"text": "beam thresholding", "start_pos": 141, "end_pos": 158, "type": "TASK", "confidence": 0.8434944152832031}]}, {"text": "We did not use any preprocessing such as supertagging and the parser searched for the most plausible derivation tree from the derivation forest in terms of the probability given by the combination of syntax and semantics probabilities.", "labels": [], "entities": []}, {"text": "list the accuracy of dependencies, i.e., edges in derivation trees, for each model with two sets of features for the semantics model . Since in derivation trees each word in a sentence depends on one and only one word (see, the accuracy is the number of correct edges divided by the number of all edges in the tree.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9987561702728271}, {"text": "accuracy", "start_pos": 228, "end_pos": 236, "type": "METRIC", "confidence": 0.9980395436286926}]}, {"text": "The exact column indicates the ratio of dependencies where the syntactic category, the argument position, and the dependee headword of the argument word are correctly output.", "labels": [], "entities": []}, {"text": "The partial column shows the ratio of dependencies where the words are related regardless of the label.", "labels": [], "entities": []}, {"text": "We should note that the exact measure is a very stringent because the model must select the correct syntactic category from 2,105 categories.", "labels": [], "entities": [{"text": "exact measure", "start_pos": 24, "end_pos": 37, "type": "METRIC", "confidence": 0.9520530700683594}]}, {"text": "First, we can see that syntax achieved a high level of accuracy although it was not quite sufficient yet.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9988604784011841}]}, {"text": "We think this was because the grammar could adequately restrict the possible structure of parsing results, and the disambiguation model tried to search for the most probable structure from the candidates allowed by the grammar.", "labels": [], "entities": []}, {"text": "Second, traditional and our model recorded significantly higher accuracy than syntax.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.999005138874054}]}, {"text": "The accuracy of our model was almost matched traditional, which proved the validity of probabilistic modeling with maximum entropy estimation for feature forests.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9995681643486023}]}, {"text": "The differences between traditional and our model were insignificant and the results proved that a consistent probability model of parsing can be built without the independence assumption, and attains performance that rivals the traditional models in terms of parsing accuracy.", "labels": [], "entities": [{"text": "parsing", "start_pos": 131, "end_pos": 138, "type": "TASK", "confidence": 0.9743525981903076}, {"text": "parsing", "start_pos": 260, "end_pos": 267, "type": "TASK", "confidence": 0.964931845664978}, {"text": "accuracy", "start_pos": 268, "end_pos": 276, "type": "METRIC", "confidence": 0.8936118483543396}]}, {"text": "We should note that accuracy can further be improved with our model because it allows other features to be incorporated that were not used in these experiments because the model is not rely on the decomposition into the dependencies of two words.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.9994112253189087}]}, {"text": "Another possibility to increase the accuracy is to refine the LTAG grammar.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.999554455280304}, {"text": "LTAG grammar", "start_pos": 62, "end_pos": 74, "type": "DATASET", "confidence": 0.7072218656539917}]}, {"text": "Although we assumed that all syntactic constraints were expressed with syntactic categories (Section 3), i.e., elementary trees, the grammar used in the experiments were not augmented with feature structures and not sufficiently restrictive to eliminate syntactically invalid structures.", "labels": [], "entities": []}, {"text": "Since our model did not include the preferences of syntactic relations of words, we expect the refinement of the grammar will greatly improve the accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 146, "end_pos": 154, "type": "METRIC", "confidence": 0.9983329176902771}]}], "tableCaptions": [{"text": " Table 1: Accuracy of dependencies (1)", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9937230944633484}]}, {"text": " Table 2: Accuracy of dependencies", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9980377554893494}]}]}