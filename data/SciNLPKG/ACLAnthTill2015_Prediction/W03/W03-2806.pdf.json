{"title": [{"text": "Intrinsic versus Extrinsic Evaluations of Parsing Systems", "labels": [], "entities": []}], "abstractContent": [{"text": "A wide range of parser and/or grammar evaluation methods have been reported in the literature.", "labels": [], "entities": []}, {"text": "However, inmost cases these evaluations take the parsers independently (intrinsic evaluations), and only in a few cases has the effect of different parsers in real applications been measured (extrinsic evaluations).", "labels": [], "entities": []}, {"text": "This paper compares two evaluations of the Link Grammar parser and the Conexor Functional Dependency Grammar parser.", "labels": [], "entities": []}, {"text": "The parsing systems, despite both being dependency-based, return different types of dependencies, making a direct comparison impossible.", "labels": [], "entities": [{"text": "parsing", "start_pos": 4, "end_pos": 11, "type": "TASK", "confidence": 0.9681450724601746}]}, {"text": "In the intrinsic evaluation, the accuracy of the parsers is compared independently by converting the dependencies into grammatical relations and using the methodology of Carroll et al.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9984392523765564}]}, {"text": "(1998) for parser comparison.", "labels": [], "entities": [{"text": "parser comparison", "start_pos": 11, "end_pos": 28, "type": "TASK", "confidence": 0.842580258846283}]}, {"text": "In the extrinsic evaluation , the parsers' impact in a practical application is compared within the context of answer extraction.", "labels": [], "entities": [{"text": "answer extraction", "start_pos": 111, "end_pos": 128, "type": "TASK", "confidence": 0.7954564094543457}]}, {"text": "The differences in the results are significant.", "labels": [], "entities": []}], "introductionContent": [{"text": "Parsing is a principal stage in many natural language processing (NLP) systems.", "labels": [], "entities": [{"text": "Parsing", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.908703088760376}]}, {"text": "A good parser is expected to return an accurate syntactic structure of a sentence.", "labels": [], "entities": []}, {"text": "This structure is typically forwarded to other modules so that they can work with unambiguous and well-defined structures representing the sentences.", "labels": [], "entities": []}, {"text": "It is to be expected that the performance of an NLP system quickly degrades if the parsing system returns incorrect syntactic structures, and therefore an evaluation of parsing coverage and accuracy is important.", "labels": [], "entities": [{"text": "parsing", "start_pos": 169, "end_pos": 176, "type": "TASK", "confidence": 0.9597336053848267}, {"text": "accuracy", "start_pos": 190, "end_pos": 198, "type": "METRIC", "confidence": 0.9968984127044678}]}, {"text": "According to, there are two main criteria in performance evaluation: \"Intrinsic criteria are those relating to a system's objective, extrinsic criteria those relating to its function i.e. to its role in relation to its setup's purpose.\").", "labels": [], "entities": [{"text": "Intrinsic", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.9844223260879517}]}, {"text": "Thus, an intrinsic evaluation of a parser would analyse the accuracy of the results returned by the parser as a stand-alone system, whereas an extrinsic evaluation would analyse the impact of the parser within the context of a broader NLP application.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9973451495170593}]}, {"text": "There are currently several parsing systems that attempt to achieve a wide coverage of the English language (such as those developed by, , and).", "labels": [], "entities": []}, {"text": "There is also substantial literature on parsing evaluation (see, for example, work by,,, and) Recently there has been a shift from constituency-based (e.g. counting crossing brackets () to dependency-based evaluation).", "labels": [], "entities": [{"text": "parsing evaluation", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.9617554247379303}]}, {"text": "Those evaluation methodologies typically focus on comparisons of stand-alone parsers (intrinsic evaluations).", "labels": [], "entities": []}, {"text": "In this paper we report on the comparison between an intrinsic evaluation and an evaluation of the impact of the parser in areal application (an extrinsic evaluation).", "labels": [], "entities": []}, {"text": "We have chosen answer extraction as an example of a practical application within which to test the parsing systems.", "labels": [], "entities": [{"text": "answer extraction", "start_pos": 15, "end_pos": 32, "type": "TASK", "confidence": 0.9259394109249115}]}, {"text": "In particular, the extrinsic evaluation uses ExtrAns, an answer extraction system that operates over Unix manual pages ().", "labels": [], "entities": [{"text": "extrinsic evaluation", "start_pos": 19, "end_pos": 39, "type": "TASK", "confidence": 0.8526802062988281}, {"text": "answer extraction", "start_pos": 57, "end_pos": 74, "type": "TASK", "confidence": 0.7555236518383026}]}, {"text": "The two grammar systems to compare are Link Grammar and the Conexor Functional Dependency Grammar parser ) (henceforth referred to as Conexor FDG).", "labels": [], "entities": [{"text": "Conexor FDG", "start_pos": 134, "end_pos": 145, "type": "DATASET", "confidence": 0.7834444940090179}]}, {"text": "These parsing systems were chosen because both include a dependency-based parser and a comprehensive grammar of English.", "labels": [], "entities": []}, {"text": "However, the structures returned are so different that a direct comparison between them is not straightforward.", "labels": [], "entities": []}, {"text": "In Section 2 we review the main differences between Link Grammar and Conexor FDG.", "labels": [], "entities": [{"text": "Conexor FDG", "start_pos": 69, "end_pos": 80, "type": "DATASET", "confidence": 0.8133848011493683}]}, {"text": "In Section 3 we present the intrinsic comparison of parsers, and in Section 4 we comment on the extrinsic comparison within the context of answer extraction.", "labels": [], "entities": [{"text": "answer extraction", "start_pos": 139, "end_pos": 156, "type": "TASK", "confidence": 0.8293343186378479}]}, {"text": "The results of the evaluations are discussed in Section 5.) is a grammar theory that is strongly dependencybased.", "labels": [], "entities": []}, {"text": "A freely available parsing system that implements the Link Grammar theory has been developed at Carnegie Mellon University.", "labels": [], "entities": [{"text": "Link Grammar theory", "start_pos": 54, "end_pos": 73, "type": "TASK", "confidence": 0.7475149432818095}]}, {"text": "The parsing system includes an extensive grammar and lexicon and has a wide coverage of the English language.", "labels": [], "entities": []}, {"text": "Conexor FDG ) is a commercial parser and grammar, based on the theory of Functional Dependency Grammar, and was originally developed at the University of Helsinki.", "labels": [], "entities": [{"text": "Conexor FDG )", "start_pos": 0, "end_pos": 13, "type": "DATASET", "confidence": 0.8375049829483032}, {"text": "Functional Dependency Grammar", "start_pos": 73, "end_pos": 102, "type": "TASK", "confidence": 0.5682389040788015}]}], "datasetContent": [{"text": "Given that both parses are dependency-based, intrinsic evaluations that are based on constituency structures (e.g. () are hard to perform.", "labels": [], "entities": []}, {"text": "Dependency-based evaluations are not easy either: directly comparing dependency graphs (as suggested by, for example) becomes difficult given the differences between the structures returned by the Link Grammar parser and Conexor FDG.", "labels": [], "entities": [{"text": "Conexor FDG", "start_pos": 221, "end_pos": 232, "type": "DATASET", "confidence": 0.7993209958076477}]}, {"text": "We therefore need an approach that is independent from the format of the parser output.", "labels": [], "entities": []}, {"text": "Following we use grammatical relations to compare the accuracy of Link Grammar and Conexor FDG.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9994532465934753}, {"text": "Conexor FDG", "start_pos": 83, "end_pos": 94, "type": "DATASET", "confidence": 0.8050240576267242}]}, {"text": "propose a set of twenty parser-independent grammatical relations arranged in a hierarchy representing different degrees of specificity.", "labels": [], "entities": []}, {"text": "Four relations from the hierarchy are shown in.", "labels": [], "entities": []}, {"text": "The arguments to each relation specify ahead, a dependent, and possibly an initial grammatical relation (in the case of SUBJ in passive sentences, for example) or the 'type', which specifies the word introducing the dependent (in the case of XCOMP).", "labels": [], "entities": []}, {"text": "For example, the grammatical relations of the sentence the man that came ate bananas and apples with a fork without asking has the following relations: SUBJ(eat,man, ), OBJ(eat,banana), OBJ(eat,apple), MOD(fork,eat,with), SUBJ(come,man, ), MOD(that,man,come), XCOMP(without,eat,ask) The terms 'head' and 'dependent' used by to refer to the arguments of grammatical relations should not be confused with the similar terms in the theory of dependency grammar.", "labels": [], "entities": [{"text": "MOD", "start_pos": 240, "end_pos": 243, "type": "METRIC", "confidence": 0.9082211852073669}, {"text": "XCOMP", "start_pos": 260, "end_pos": 265, "type": "METRIC", "confidence": 0.9038616418838501}]}, {"text": "Grammatical relations and dependency arcs represent different phenomena.", "labels": [], "entities": []}, {"text": "An example should suffice to illustrate the difference; consider The man that came ate bananas and apples with a fork.", "labels": [], "entities": []}, {"text": "In dependency grammar a unique head is assigned to each word, for example the head of man is ate.", "labels": [], "entities": []}, {"text": "However man is the dependent of more than one grammatical relation, namely SUBJ(eat,man, ) and SUBJ(come,man, ).", "labels": [], "entities": []}, {"text": "Furthermore, in dependency grammar a word can have at most one dependent of each argument type, and so ate can have at most one object, for example.", "labels": [], "entities": []}, {"text": "But Clausal complement without an overt subject MOD(type, head, dependent) Modifier: Grammatical relations used in the intrinsic evaluation.", "labels": [], "entities": [{"text": "MOD", "start_pos": 48, "end_pos": 51, "type": "METRIC", "confidence": 0.9901686906814575}]}, {"text": "the same is not true for grammatical relations, and we get both OBJ(eat,banana) and OBJ(eat,apple).", "labels": [], "entities": [{"text": "OBJ", "start_pos": 64, "end_pos": 67, "type": "METRIC", "confidence": 0.9859654903411865}, {"text": "OBJ", "start_pos": 84, "end_pos": 87, "type": "METRIC", "confidence": 0.9807558655738831}]}, {"text": "It is important to know not only the accuracy of a parser but how possible parsing errors affect the success of an NLP application.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9990668892860413}]}, {"text": "This is the goal of an extrinsic evaluation, where the system is evaluated in relation to the embedding setup.", "labels": [], "entities": []}, {"text": "Using answer extraction as an example of an NLP application, we compared the performance of the Link Grammar system and Conexor FDG.", "labels": [], "entities": [{"text": "answer extraction", "start_pos": 6, "end_pos": 23, "type": "TASK", "confidence": 0.8829126954078674}, {"text": "Conexor FDG", "start_pos": 120, "end_pos": 131, "type": "DATASET", "confidence": 0.8419064879417419}]}], "tableCaptions": [{"text": " Table 3: Accuracy of identification of grammatical  relations.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9787079691886902}, {"text": "identification of grammatical  relations", "start_pos": 22, "end_pos": 62, "type": "TASK", "confidence": 0.8564188629388809}]}, {"text": " Table 4: Averages per query in synonym mode.", "labels": [], "entities": []}, {"text": " Table 5: Averages per query in approximate mode.", "labels": [], "entities": []}, {"text": " Table 6: Numbers of times no relevant answers  were found.", "labels": [], "entities": [{"text": "Numbers", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9817330837249756}]}]}