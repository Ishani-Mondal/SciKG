{"title": [{"text": "Learning Bilingual Translations from Comparable Corpora to Cross-Language Information Retrieval: Hybrid Statistics-based and Linguistics-based Approach", "labels": [], "entities": [{"text": "Learning Bilingual Translations from Comparable Corpora to Cross-Language Information Retrieval", "start_pos": 0, "end_pos": 95, "type": "TASK", "confidence": 0.7170661181211472}]}], "abstractContent": [{"text": "Recent years saw an increased interest in the use and the construction of large corpora.", "labels": [], "entities": []}, {"text": "With this increased interest and awareness has come an expansion in the application to knowledge acquisition and bilingual terminology extraction.", "labels": [], "entities": [{"text": "knowledge acquisition", "start_pos": 87, "end_pos": 108, "type": "TASK", "confidence": 0.8167688846588135}, {"text": "bilingual terminology extraction", "start_pos": 113, "end_pos": 145, "type": "TASK", "confidence": 0.6726849377155304}]}, {"text": "The present paper will seek to present an approach to bilingual lexicon extraction from non-aligned comparable corpora, combination to linguistics-based pruning and evaluations on Cross-Language Information Retrieval.", "labels": [], "entities": [{"text": "bilingual lexicon extraction from non-aligned comparable corpora", "start_pos": 54, "end_pos": 118, "type": "TASK", "confidence": 0.7751282751560211}, {"text": "Cross-Language Information Retrieval", "start_pos": 180, "end_pos": 216, "type": "TASK", "confidence": 0.773532509803772}]}, {"text": "We propose and explore a two-stages translation model for the acquisition of bilingual terminology from comparable corpora, dis-ambiguation and selection of best translation alternatives on the basis of their morphological knowledge.", "labels": [], "entities": []}, {"text": "Evaluations using a large-scale test collection on Japanese-English and different weighting schemes of SMART retrieval system confirmed the effectiveness of the proposed combination of two-stages comparable corpora and linguistics-based pruning on Cross-Language Information Retrieval.", "labels": [], "entities": [{"text": "SMART retrieval", "start_pos": 103, "end_pos": 118, "type": "TASK", "confidence": 0.6226658523082733}, {"text": "Cross-Language Information Retrieval", "start_pos": 248, "end_pos": 284, "type": "TASK", "confidence": 0.7538376053174337}]}], "introductionContent": [{"text": "Researches on corpus-based approaches to machine translation (MT) have been on the rise, particularly because of their promise to provide bilingual terminology and enrich lexical resources such as bilingual dictionaries and thesauri.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 41, "end_pos": 65, "type": "TASK", "confidence": 0.8800036787986756}]}, {"text": "These approaches generally rely on large text corpora, which play an important role in Natural Language Processing (NLP) and Information Retrieval (IR).", "labels": [], "entities": [{"text": "Information Retrieval (IR)", "start_pos": 125, "end_pos": 151, "type": "TASK", "confidence": 0.8667134642601013}]}, {"text": "Moreover, non-aligned comparable corpora have been given a special interest in bilingual terminology acquisition and lexical resources enrichment.", "labels": [], "entities": [{"text": "bilingual terminology acquisition", "start_pos": 79, "end_pos": 112, "type": "TASK", "confidence": 0.6413339873154958}, {"text": "lexical resources enrichment", "start_pos": 117, "end_pos": 145, "type": "TASK", "confidence": 0.6874696214993795}]}, {"text": "Unlike parallel corpora, comparable corpora are collections of texts from pairs or multiples of languages, which can be contrasted because of their common features, in the topic, the domain, the authors or the time period.", "labels": [], "entities": []}, {"text": "This property made comparable corpora more abundant, less expensive and more accessible through the World Wide Web.", "labels": [], "entities": []}, {"text": "In the present paper, we are concerned by exploiting scarce resources for bilingual terminology acquisition, then evaluations on Cross-Language Information Retrieval (CLIR).", "labels": [], "entities": [{"text": "bilingual terminology acquisition", "start_pos": 74, "end_pos": 107, "type": "TASK", "confidence": 0.66757732629776}, {"text": "Cross-Language Information Retrieval (CLIR)", "start_pos": 129, "end_pos": 172, "type": "TASK", "confidence": 0.7678923656543096}]}, {"text": "CLIR consists of retrieving documents written in one language using queries written in another language.", "labels": [], "entities": []}, {"text": "An application is conducted on NTCIR, a large-scale data collection for (Japanese, English) language pair.", "labels": [], "entities": [{"text": "NTCIR", "start_pos": 31, "end_pos": 36, "type": "DATASET", "confidence": 0.922538161277771}]}, {"text": "The remainder of the present paper is organized as follows: Section 2 presents the proposed twostages approach for bilingual terminology acquisition from comparable corpora.", "labels": [], "entities": [{"text": "bilingual terminology acquisition", "start_pos": 115, "end_pos": 148, "type": "TASK", "confidence": 0.6289942065874735}]}, {"text": "Section 3 describes the integration of linguistic knowledge for pruning the translation candidates.", "labels": [], "entities": []}, {"text": "Experiments and evaluations in CLIR are discussed in Sections 4.", "labels": [], "entities": [{"text": "CLIR", "start_pos": 31, "end_pos": 35, "type": "DATASET", "confidence": 0.7665160894393921}]}, {"text": "Section 5 concludes the present paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "Experiments have been carried out to measure the improvement of our proposal on bilingual terminology acquisition from comparable corpora on Japanese-English tasks in CLIR, i.e. Japanese queries to retrieve English documents.", "labels": [], "entities": [{"text": "bilingual terminology acquisition", "start_pos": 80, "end_pos": 113, "type": "TASK", "confidence": 0.606294979651769}]}, {"text": "We considered the set of news articles as well as the abstracts of NTCIR-2 test collection as comparable corpora for Japanese-English language pairs.", "labels": [], "entities": [{"text": "NTCIR-2 test collection", "start_pos": 67, "end_pos": 90, "type": "DATASET", "confidence": 0.9459804892539978}]}, {"text": "The abstracts of NTCIR-2 test collection are partially aligned (more than half are Japanese-English paired documents) but the alignment was not considered in the present research to treat the set of documents as comparable.", "labels": [], "entities": [{"text": "NTCIR-2 test collection", "start_pos": 17, "end_pos": 40, "type": "DATASET", "confidence": 0.9344578782717387}]}, {"text": "Content words (nouns, verbs, adjectives, adverbs) were extracted from English and Japanese corpora.", "labels": [], "entities": []}, {"text": "In addition, foreign words (mostly represented in katakana) were extracted from Japanese texts.", "labels": [], "entities": []}, {"text": "Thus, context vectors were constructed for 13,552,481 Japanese terms and 1,517,281 English terms.", "labels": [], "entities": []}, {"text": "Similarity vectors were constructed for 96,895,255 (Japanese, English) pairs of terms and 92,765,129 (English, Japanese) pairs of terms.", "labels": [], "entities": []}, {"text": "Bi-directional similarity vectors (after merging and disambiguation) resulted in 58,254,841 (Japanese, English) pairs of terms.", "labels": [], "entities": []}, {"text": "illustrates some situations with the extracted English translation alternatives for Japanese terms \u00a2 \u00a1 (eiga), using the two-stages comparable corpora approach and combination to linguisticsbased pruning.", "labels": [], "entities": []}, {"text": "Using the two-stages comparable corpora-based approach, correct translations of the Japanese term \u00a3 \u00a1 (eiga) were ranked in top 3 (movie) and top 5 (f ilm).", "labels": [], "entities": []}, {"text": "We notice that top ranked translations, which are considered as wrong translations, are related mostly to the context of the source Japanese term and could help the query expansion in CLIR.", "labels": [], "entities": [{"text": "CLIR", "start_pos": 184, "end_pos": 188, "type": "DATASET", "confidence": 0.904137134552002}]}, {"text": "Combined two-stages comparable corpora with the linguistics-based pruning shows better results with ranks 2 (movie) and 4 (f ilm).", "labels": [], "entities": []}, {"text": "Japanese vocabulary is frequently imported from other languages, primarily (but not exclusively) from English.", "labels": [], "entities": []}, {"text": "The special phonetic alphabet (here Japanese katakana) is used to write down foreign words and loanwords, example names of persons and others.", "labels": [], "entities": []}, {"text": "Katakana terms could be treated via transliteration or possible romanization, i.e., conversion of Japanese katakana to their English equivalence or the alphabetical description of their pronunciation.", "labels": [], "entities": []}, {"text": "Transliteration is the phonetic or spelling representation of one language using the alphabet of another language).", "labels": [], "entities": []}, {"text": "Conducted experiments and evaluations were completed on NTCIR test collection using the monolin- gual English runs, i.e., English queries to retrieve English documents and the bilingual JapaneseEnglish runs, i.e., Japanese queries to retrieve English document.", "labels": [], "entities": [{"text": "NTCIR test collection", "start_pos": 56, "end_pos": 77, "type": "DATASET", "confidence": 0.9185310204823812}]}, {"text": "Topics 0101 to 0149 were considered and key terms contained in the fields, title <T IT LE>, description <DESCRIP T ION > and concept <CON CEP T > were used to generate 49 queries in Japanese and English.", "labels": [], "entities": [{"text": "title <T IT LE>", "start_pos": 75, "end_pos": 90, "type": "METRIC", "confidence": 0.8293062845865885}, {"text": "DESCRIP T ION >", "start_pos": 105, "end_pos": 120, "type": "METRIC", "confidence": 0.9040201306343079}, {"text": "CON CEP T", "start_pos": 134, "end_pos": 143, "type": "METRIC", "confidence": 0.6621729930241903}]}, {"text": "There is a variety of techniques implemented in SMART to calculate weights for individual terms in both documents and queries.", "labels": [], "entities": [{"text": "SMART", "start_pos": 48, "end_pos": 53, "type": "TASK", "confidence": 0.9363889694213867}]}, {"text": "These weighting techniques are formulated by combining three parameters: Term Frequency component, Inverted Document Frequency component and Vector Normalization component.", "labels": [], "entities": [{"text": "Term Frequency component", "start_pos": 73, "end_pos": 97, "type": "METRIC", "confidence": 0.8505626916885376}, {"text": "Inverted Document Frequency component", "start_pos": 99, "end_pos": 136, "type": "METRIC", "confidence": 0.8280594497919083}]}, {"text": "The standard SMART notation to describe the combined schemes is \"XXX.YYY\".", "labels": [], "entities": [{"text": "SMART", "start_pos": 13, "end_pos": 18, "type": "TASK", "confidence": 0.9127475023269653}]}, {"text": "The three characters to the left (XXX) and right (YYY) of the period refer to the document and query vector components, respectively.", "labels": [], "entities": []}, {"text": "For example, ATC.ATN applies augmented normalized term frequency, tf \u00d7idf document frequency (term frequency times inverse document frequency components) to weigh terms in the collection of documents.", "labels": [], "entities": []}, {"text": "Similarly ATN refers to the weighting scheme applied to the query.", "labels": [], "entities": [{"text": "ATN", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.8612695932388306}]}, {"text": "First experiments were conducted on several combinations of weighting parameters and schemes of SMART retrieval system for documents terms and query terms, such as ATN, ATC, LTN, LTC, NNN, NTC, etc.", "labels": [], "entities": []}, {"text": "Best performances in terms of average precision were realized by the following combined weighting schemes: ATN.NTC, LTN.NTC, LTC.NTC, ATC.NTC and NTC.NTC, respectively.", "labels": [], "entities": [{"text": "precision", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9653928279876709}, {"text": "ATN.NTC", "start_pos": 107, "end_pos": 114, "type": "DATASET", "confidence": 0.7700083255767822}]}, {"text": "The best weighting scheme for the monolingual runs turned out to be the ATN.NTC.", "labels": [], "entities": [{"text": "ATN.NTC", "start_pos": 72, "end_pos": 79, "type": "DATASET", "confidence": 0.9679955840110779}]}, {"text": "This finding is somewhat different from previous results where ANN, LTC ( weighting schemes on query terms, LNC.LTC  and LNC.LTN () combined weighting schemes on document terms and query terms showed the best results.", "labels": [], "entities": []}, {"text": "On the other hand, our findings were quite similar to the result presented by Savoy, where the ATN.NTC showed the best performance among the existing weighting schemes in SMART for English monolingual runs.", "labels": [], "entities": [{"text": "ATN.NTC", "start_pos": 95, "end_pos": 102, "type": "DATASET", "confidence": 0.9536756277084351}, {"text": "SMART", "start_pos": 171, "end_pos": 176, "type": "TASK", "confidence": 0.7061782479286194}]}, {"text": "shows some weighting schemes of SMART retrieval system, among others.", "labels": [], "entities": [{"text": "SMART retrieval", "start_pos": 32, "end_pos": 47, "type": "TASK", "confidence": 0.4675317108631134}]}, {"text": "To assign an indexing weight w ij that reflects the importance of each single-term T j in a document Di , different factors should be considered, as follows: \u2022 within-document term frequency tf ij , which represents the first letter of the SMART label.", "labels": [], "entities": [{"text": "SMART label", "start_pos": 240, "end_pos": 251, "type": "TASK", "confidence": 0.5121500343084335}]}, {"text": "\u2022 collection-wide term frequency df j , which represents the second letter of the SMART label.", "labels": [], "entities": [{"text": "SMART label", "start_pos": 82, "end_pos": 93, "type": "TASK", "confidence": 0.5354229062795639}]}, {"text": "In, idf j = log NF j ; where, N represents the number of documents and F j represents the document frequency of term T j . \u2022 normalization scheme, which represents the third letter of the SMART label.", "labels": [], "entities": [{"text": "SMART label", "start_pos": 188, "end_pos": 199, "type": "TASK", "confidence": 0.6365466415882111}]}, {"text": "Bilingual translations were extracted from comparable corpora using the proposed two-stages model.", "labels": [], "entities": []}, {"text": "A fixed number (set to five) of top-ranked translation alternatives was retained for evaluations in CLIR.", "labels": [], "entities": [{"text": "CLIR", "start_pos": 100, "end_pos": 104, "type": "DATASET", "confidence": 0.8666762709617615}]}, {"text": "Results and performances on the monolingual and bilingual runs for the proposed translation models and the combination to linguistics-based pruning are described in.", "labels": [], "entities": []}, {"text": "Evaluations were based on the average precision, differences in term of average precision of the monolingual counterpart and the improvement over the monolingual counterpart.", "labels": [], "entities": [{"text": "precision", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9799113869667053}, {"text": "precision", "start_pos": 80, "end_pos": 89, "type": "METRIC", "confidence": 0.8097785711288452}]}, {"text": "As well, evaluations using R-precision are illustrated in. represents the recall/precision curves of the proposed two-stages comparable corpora-based translation model and combination to linguisticsbased pruning, in the case of ATN.NTC weighting scheme.", "labels": [], "entities": [{"text": "recall/precision", "start_pos": 74, "end_pos": 90, "type": "METRIC", "confidence": 0.7832765777905782}]}, {"text": "The proposed two-stages model using comparable corpora 'BCC' showed a better improvement in terms of average precision compared to the simple model 'SCC' (one stage, i.e., simple comparable corpora-based translation) with +27.1%.", "labels": [], "entities": [{"text": "precision", "start_pos": 109, "end_pos": 118, "type": "METRIC", "confidence": 0.972881555557251}]}, {"text": "Combination to Linguistics-based pruning showed the best performance in terms of average precision with +41.7% and +11.5% compared to the simple comparable corpora-based model 'SCC' and the two-stages comparable corpora-based model 'BCC', respectively, in the case of ATN.NTC weighting scheme.", "labels": [], "entities": [{"text": "precision", "start_pos": 89, "end_pos": 98, "type": "METRIC", "confidence": 0.9694027900695801}]}, {"text": "Different weighting schemes of SMART retrieval system showed an improvement in term of average precision for the proposed translation models 'BCC' and 'BCC+Morph'.", "labels": [], "entities": [{"text": "SMART retrieval", "start_pos": 31, "end_pos": 46, "type": "TASK", "confidence": 0.6950580179691315}, {"text": "precision", "start_pos": 95, "end_pos": 104, "type": "METRIC", "confidence": 0.9452376365661621}]}, {"text": "The approach based on comparable corpora largely affected the translation because related words could be added as translation alternatives or expansion terms.", "labels": [], "entities": []}, {"text": "The acquisition of bilingual terminology from bi-directional comparable corpora yields a significantly better result than using the simple model.", "labels": [], "entities": []}, {"text": "Moreover, the linguistics-based pruning technique has allowed an improvement in the effectiveness of CLIR.", "labels": [], "entities": []}, {"text": "Finally, statistical t-test) was carried out in order to measure significant differences between paired retrieval models.", "labels": [], "entities": []}, {"text": "The improvement by using the proposed two-stages comparable corporabased method 'BCC' was statistically significant (p-value=0.0011).", "labels": [], "entities": []}, {"text": "The combined statistics-based and linguistics-based pruning 'BCC+Morph' was found statistically significant (p-value= 0.05) over the monolingual retrieval 'ME'.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: An example for the two-stages comparable corpora translation model and linguistics-based pruning", "labels": [], "entities": []}, {"text": " Table 3: Best results on different weighting schemes for the proposed translation models and the linguistics- based pruning", "labels": [], "entities": []}]}