{"title": [{"text": "Learning Word Meanings and Descriptive Parameter Spaces from Music", "labels": [], "entities": []}], "abstractContent": [{"text": "The audio bitstream in music encodes a high amount of statistical, acoustic, emotional and cultural information.", "labels": [], "entities": []}, {"text": "But music also has an important linguistic accessory; most musical artists are described in great detail in record reviews, fan sites and news items.", "labels": [], "entities": []}, {"text": "We highlight current and ongoing research into extracting relevant features from audio and simultaneously learning language features linked to the music.", "labels": [], "entities": []}, {"text": "We show results in a \"query-by-description\" task in which we learn the perceptual meaning of automatically-discovered single-term descriptive components, as well as a method of automatically uncovering 'seman-tically attached' terms (terms that have perceptual grounding.)", "labels": [], "entities": []}, {"text": "We then show recent work in 'semantic basis functions'-parameter spaces of description (such as fast ...", "labels": [], "entities": []}, {"text": "female) that encode the highest descriptive variance in a semantic space.", "labels": [], "entities": []}], "introductionContent": [{"text": "What can you learn by listening to the radio all day?", "labels": [], "entities": []}, {"text": "If the DJ was wordy enough, we argue that you can gain enough knowledge of the language of perception, as well as the grammar of description and the grammar of music.", "labels": [], "entities": []}, {"text": "Here we develop a system that uncovers descriptive parameters of perception completely autonomously.", "labels": [], "entities": []}, {"text": "Relations between English adjectives and audio features are learned using anew 'severe multi-class' algorithm based on the support vector machine.", "labels": [], "entities": []}, {"text": "Training data consists of music reviews from the Internet correlated echnology and Entertainment Media: Rights and Responsibilities with acoustic recordings of the reviewed music.", "labels": [], "entities": []}, {"text": "Once trained, we obtain a perceptually-grounded lexicon of adjectives that maybe used to automatically label new music.", "labels": [], "entities": []}, {"text": "The predictive accuracy of the perceptual models are evaluated on unseen test music-review data samples.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9433562755584717}]}, {"text": "We consider terms with high predictive accuracy (i.e., that agree with word usage of musical reviews not used during training) to be well grounded.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.7845338582992554}]}, {"text": "We extend our prior work by introducing a 'linguistic expert,' in the form of a lexical knowledge base that provides human-encoded symbolic knowledge about lexical relations.", "labels": [], "entities": []}, {"text": "We apply lexical relations to well grounded adjectives to determine the perceptual correlates of opposition.", "labels": [], "entities": []}, {"text": "This enables us to move from isolated word groundings to a gradation system by discovering the perceptual basis underlying lexical opposition of adjective pairs (fast ...", "labels": [], "entities": []}, {"text": "Once we have uncovered these gradations, we effectively obtain a set of \"semantic basis functions\" which can be used to characterize music samples based on their perceptual projections onto these lexically determined basis functions.: Selected adjective terms and their weighted precision in predicting a description of as-yet 'unheard' music in the frame-based single term attachment system.", "labels": [], "entities": [{"text": "precision", "start_pos": 279, "end_pos": 288, "type": "METRIC", "confidence": 0.9667356610298157}]}, {"text": "The very low baseline and noisy ground truth contribute to low overall scores, but the difference between 'ungroundable' and high-scoring terms are significant-for example, the system cannot find a spectral definition of 'sexy.'", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate our connection-finding system, we compute the weighted precision P (a t ) of predicting the label t for audio derived features of artist a.", "labels": [], "entities": [{"text": "weighted precision P (a t )", "start_pos": 58, "end_pos": 85, "type": "METRIC", "confidence": 0.8144604052816119}]}, {"text": "We train anew ct for each term t against the training set.", "labels": [], "entities": []}, {"text": "ft (x) for the test set is computed over each audio-derived observation frame x and term t.", "labels": [], "entities": []}, {"text": "If the sign off t (x) is the same as our supposed 'ground truth' for that {artist, t}, (i.e. did the audio frame for an artist correctly resolve to a known descriptive term?) we consider the prediction successful.", "labels": [], "entities": []}, {"text": "Due to the bias problem mentioned earlier, the evaluation is then computed on the test set by computing a 'weighted precision': where P (a p ) indicates overall positive accuracy (given an audio-derived observation, the probability that a positive association to a term is predicted) and Perception LexicallKnowledgeeBase DescriptionnbyyObservation: Overview of our parameter grounding method.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 170, "end_pos": 178, "type": "METRIC", "confidence": 0.9890539646148682}]}, {"text": "Semantically attached terms are discovered by finding strong connections to perception.", "labels": [], "entities": []}, {"text": "We then ask a 'professional' in the form of a lexical knowledge base about antonymial relations.", "labels": [], "entities": []}, {"text": "We use those relations to infer gradations in perception.", "labels": [], "entities": []}, {"text": "P (a n ) indicates overall negative accuracy, P (a) is defined as P (a p )P (a n ), which should remain significant even in the face of extreme negative output class bias.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9777387976646423}]}, {"text": "Now we sort the list of P (a t ) and set an arbitrary threshold \u03b5.", "labels": [], "entities": []}, {"text": "In our implementation, we use \u03b5 = 0.1.", "labels": [], "entities": []}, {"text": "Any P (a t ) greater than \u03b5 is considered 'grounded.'", "labels": [], "entities": []}, {"text": "In this manner we can use training accuracy to throwaway badly scoring classes and then figure out which were incorrect or unimportant.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9843232035636902}]}, {"text": "In the following section we describe our experiments using the aforementioned models and show how we can automatically uncover the perceptual parameter spaces underlying adjective oppositions.", "labels": [], "entities": []}, {"text": "We use audio from the NECI Minnowmatch testbed ().", "labels": [], "entities": [{"text": "NECI Minnowmatch testbed", "start_pos": 22, "end_pos": 46, "type": "DATASET", "confidence": 0.921221395333608}]}, {"text": "The testbed includes on average ten songs from each of 1,000 albums from roughly 500 artists.", "labels": [], "entities": []}, {"text": "The album list was chosen from the most popular songs on OpenNap, a popular peer-to-peer music sharing service, in August of 2001.", "labels": [], "entities": []}, {"text": "We do not separate audioderived features among separate songs since our connections in language are at the artist level (community metadata refers to an artist, not an album or song.)", "labels": [], "entities": []}, {"text": "Therefore, each artist a is represented as a concatenated matrix of F a computed from each song performed by that artist.", "labels": [], "entities": []}, {"text": "F a contains N rows of 40-dimensional data.", "labels": [], "entities": []}, {"text": "Each observation represents 10 seconds of audio data.", "labels": [], "entities": []}, {"text": "We choose a random sampling of artists for both training and testing (25 artists each, 5 songs fora total of N observations for testing and training) from the Minnowmatch testbed.", "labels": [], "entities": [{"text": "Minnowmatch testbed", "start_pos": 159, "end_pos": 178, "type": "DATASET", "confidence": 0.9778938591480255}]}], "tableCaptions": [{"text": " Table 1: Selected adjective terms and their weighted pre- cision in predicting a description of as-yet 'unheard' mu- sic in the frame-based single term attachment system.  The very low baseline and noisy ground truth contribute  to low overall scores, but the difference between 'un- groundable' and high-scoring terms are significant-for  example, the system cannot find a spectral definition of  'sexy.'", "labels": [], "entities": []}, {"text": " Table 2: Top 10 terms (noun phrase and adjective sets) for  the musical group 'Portishead' from community meta- data.", "labels": [], "entities": [{"text": "Portishead' from community meta- data", "start_pos": 80, "end_pos": 117, "type": "DATASET", "confidence": 0.7792408381189618}]}, {"text": " Table 4: Select adjective terms discovered by the time- aware adjective grounding system. Overall, the attached  term list is more musical due to the increased time-aware  information in the representation.", "labels": [], "entities": []}, {"text": " Table 5: Select automatically discovered parameter  spaces and their weighted precision. The top are the most  semantically significant description spaces for music un- derstanding uncovered autonomously by our system.", "labels": [], "entities": [{"text": "precision", "start_pos": 79, "end_pos": 88, "type": "METRIC", "confidence": 0.9730851650238037}]}]}