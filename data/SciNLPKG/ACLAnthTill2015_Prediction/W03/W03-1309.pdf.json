{"title": [{"text": "Protein Name Tagging for Biomedical Annotation in Text", "labels": [], "entities": [{"text": "Protein Name Tagging", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7182008028030396}, {"text": "Biomedical Annotation", "start_pos": 25, "end_pos": 46, "type": "TASK", "confidence": 0.6774327456951141}]}], "abstractContent": [{"text": "We explore the use of morphological analysis as preprocessing for protein name tagging.", "labels": [], "entities": [{"text": "protein name tagging", "start_pos": 66, "end_pos": 86, "type": "TASK", "confidence": 0.6073077023029327}]}, {"text": "Our method finds protein names by chunking based on a morpheme, the smallest unit determined by the morphological analysis.", "labels": [], "entities": []}, {"text": "This helps to recognize the exact boundaries of protein names.", "labels": [], "entities": []}, {"text": "Moreover, our morphological analyzer can deal with compounds.", "labels": [], "entities": []}, {"text": "This offers a simple way to adapt name descriptions from biomedical resources for language processing.", "labels": [], "entities": []}, {"text": "Using GENIA corpus 3.01, our method attains f-score of 70 points for protein molecule names, and 75 points for protein names including molecules, families and domains.", "labels": [], "entities": [{"text": "GENIA corpus 3.01", "start_pos": 6, "end_pos": 23, "type": "DATASET", "confidence": 0.9254404306411743}, {"text": "f-score", "start_pos": 44, "end_pos": 51, "type": "METRIC", "confidence": 0.9986076951026917}]}], "introductionContent": [{"text": "This paper describes a protein name tagging method which is a fundamental precursor to information extraction of protein-protein interactions (PPIs) from MEDLINE abstracts.", "labels": [], "entities": [{"text": "protein name tagging", "start_pos": 23, "end_pos": 43, "type": "TASK", "confidence": 0.6387463410695394}, {"text": "information extraction of protein-protein interactions (PPIs) from MEDLINE abstracts", "start_pos": 87, "end_pos": 171, "type": "TASK", "confidence": 0.802619375965812}]}, {"text": "Previous work in bio-entity (including protein) recognition can be categorized into three approaches: (a) exact and approximate string matching (, (b) handcrafted rule-based approaches () (), and (c) machine learning), ().", "labels": [], "entities": [{"text": "bio-entity (including protein) recognition", "start_pos": 17, "end_pos": 59, "type": "TASK", "confidence": 0.7570235133171082}, {"text": "approximate string matching", "start_pos": 116, "end_pos": 143, "type": "TASK", "confidence": 0.5982526739438375}]}, {"text": "Previous approaches in (b) and (c) ignore the fact that bio-entities have boundary ambiguities.", "labels": [], "entities": []}, {"text": "Unlike general English, a space character is not a sufficient token delimiter.", "labels": [], "entities": []}, {"text": "Moreover, name descriptions in biomedical resources are mostly compounds.", "labels": [], "entities": []}, {"text": "A conventional English preprocessing undergoes a pipeline of simple tokenization and partof-speech tagging.", "labels": [], "entities": [{"text": "partof-speech tagging", "start_pos": 85, "end_pos": 106, "type": "TASK", "confidence": 0.7251940965652466}]}, {"text": "The tokenization is based on a graphic word 1 for the subsequent part-of-speech tagging to work.", "labels": [], "entities": []}, {"text": "The conventional paradigm does not properly handle peculiarities of biomedical English.", "labels": [], "entities": []}, {"text": "To remedy the problem, we propose morphological analysis which achieves sophisticated tokenization and adapts biomedical resources effectively.", "labels": [], "entities": []}, {"text": "Our method identifies protein names by chunking based on morphemes, the smallest units determined by morphological analysis.", "labels": [], "entities": []}, {"text": "We do not use graphic words as a unit of chunking to avoid the under-segmentation problem.", "labels": [], "entities": []}, {"text": "Suppose that a protein name appears as a substring of a graphic word.", "labels": [], "entities": []}, {"text": "Chunking based on graphic words fails, because graphic words are too coarsely segmented.", "labels": [], "entities": []}, {"text": "Instead, chunking based on morpheme overcomes the problem, and the exact boundaries of protein names are better recognized.", "labels": [], "entities": []}, {"text": "Below, we describe our method of protein name tagging, including preprocessing, feature extraction (Section 2), and experimental results (Section 3).", "labels": [], "entities": [{"text": "protein name tagging", "start_pos": 33, "end_pos": 53, "type": "TASK", "confidence": 0.6116570929686228}, {"text": "preprocessing", "start_pos": 65, "end_pos": 78, "type": "METRIC", "confidence": 0.9143370389938354}, {"text": "feature extraction", "start_pos": 80, "end_pos": 98, "type": "TASK", "confidence": 0.654367133975029}]}, {"text": "We mention related work in bio-entity recognition (Section 4) and give concluding remarks (Section 5).", "labels": [], "entities": [{"text": "bio-entity recognition", "start_pos": 27, "end_pos": 49, "type": "TASK", "confidence": 0.7648374140262604}]}], "datasetContent": [{"text": "We first conduct experiments with Yapex corpus 5 , the same corpus used in to get a direct comparison with the good-performing rulebased approach . There are 99 abstracts for training  and 101 abstracts for testing.", "labels": [], "entities": [{"text": "Yapex corpus 5", "start_pos": 34, "end_pos": 48, "type": "DATASET", "confidence": 0.9518255194028219}]}, {"text": "Each sentence undergoes preprocessing, feature extraction and SVM-based chunking to obtain a protein name tagged sentence.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.6923042386770248}, {"text": "SVM-based chunking", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.8095259666442871}]}, {"text": "We also use YamCha for this task.", "labels": [], "entities": []}, {"text": "Parameters for YamCha are summarized in.", "labels": [], "entities": [{"text": "Parameters", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9324240684509277}]}, {"text": "Our evaluation criteria follow that of.", "labels": [], "entities": []}, {"text": "We calculate the standard measures of precision, recall and f-score for each boundary condition of strict, left, right and sloppy described in.", "labels": [], "entities": [{"text": "precision", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9996658563613892}, {"text": "recall", "start_pos": 49, "end_pos": 55, "type": "METRIC", "confidence": 0.9996588230133057}, {"text": "f-score", "start_pos": 60, "end_pos": 67, "type": "METRIC", "confidence": 0.9810749888420105}]}, {"text": "The performance of our method on Yapex corpus is summarized in, along with that of Yapex protein tagger.", "labels": [], "entities": [{"text": "Yapex corpus", "start_pos": 33, "end_pos": 45, "type": "DATASET", "confidence": 0.9778686761856079}, {"text": "Yapex protein tagger", "start_pos": 83, "end_pos": 103, "type": "DATASET", "confidence": 0.8148541251818339}]}, {"text": "Our method achieves as good result as a hand-crafted rule-based approach, despite the small set of training data (99 abstracts) which works unfavorable to machine learning approaches.", "labels": [], "entities": []}, {"text": "The better performance in strict could be attributed to chunking based on morphemes instead of words.", "labels": [], "entities": []}, {"text": "Yapex has a good recall rate while our method enjoys a good precision in all boundary conditions.", "labels": [], "entities": [{"text": "Yapex", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9472190737724304}, {"text": "recall rate", "start_pos": 17, "end_pos": 28, "type": "METRIC", "confidence": 0.9831022620201111}, {"text": "precision", "start_pos": 60, "end_pos": 69, "type": "METRIC", "confidence": 0.9987245202064514}]}, {"text": "A possible explanation for the low recall is that the training data was small (99 abstracts) for SVM to generalize the characteristics of protein names.", "labels": [], "entities": [{"text": "recall", "start_pos": 35, "end_pos": 41, "type": "METRIC", "confidence": 0.9993845224380493}, {"text": "generalize the characteristics of protein names", "start_pos": 104, "end_pos": 151, "type": "TASK", "confidence": 0.7291613419850668}]}, {"text": "As: Results on Yapex corpus (99 abstracts for training and 101 abstracts for testing).", "labels": [], "entities": [{"text": "Yapex corpus", "start_pos": 15, "end_pos": 27, "type": "DATASET", "confidence": 0.9755603969097137}]}, {"text": "P(precision), R(recall) and F(f-score) are shown.", "labels": [], "entities": [{"text": "precision", "start_pos": 2, "end_pos": 11, "type": "METRIC", "confidence": 0.9807302951812744}, {"text": "recall", "start_pos": 16, "end_pos": 22, "type": "METRIC", "confidence": 0.8939244747161865}, {"text": "F(f-score)", "start_pos": 28, "end_pos": 38, "type": "METRIC", "confidence": 0.7411093637347221}]}, {"text": "The table shows the protein tagger with an IOB2 chunking with forward parsing.", "labels": [], "entities": []}, {"text": "we will shortly report in the next subsection, we no longer observe a low recall when training with the medium-sized (590 abstracts) and the large-sized (1600 abstracts) data.", "labels": [], "entities": [{"text": "recall", "start_pos": 74, "end_pos": 80, "type": "METRIC", "confidence": 0.9989380240440369}]}, {"text": "IOB2 chunking with forward parsing gives better results in left, while IOE2 chunking with backward parsing gives better results in right.", "labels": [], "entities": [{"text": "IOB2 chunking", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.6052121967077255}, {"text": "IOE2 chunking", "start_pos": 71, "end_pos": 84, "type": "TASK", "confidence": 0.688385009765625}]}, {"text": "The result follows our intuition that IOB2 chunking with a forward parsing intensively learns the left boundary between B(egin) and O(utside), while IOE2 chunking with a backward parsing intensively learns the right boundary between E(nd) and O(utside).", "labels": [], "entities": [{"text": "IOB2 chunking", "start_pos": 38, "end_pos": 51, "type": "TASK", "confidence": 0.542773649096489}, {"text": "IOE2 chunking", "start_pos": 149, "end_pos": 162, "type": "TASK", "confidence": 0.5974490940570831}]}, {"text": "Use of a weighted voting of multiple system outputs, as discussed in (, is left for future research.", "labels": [], "entities": []}, {"text": "Effects of each feature in IOB2 chunking with forward parsing are summarized in.", "labels": [], "entities": [{"text": "IOB2 chunking", "start_pos": 27, "end_pos": 40, "type": "TASK", "confidence": 0.6434288322925568}]}, {"text": "Each feature is assessed by subtracting the focused feature from the maximal model in.", "labels": [], "entities": []}, {"text": "Since the test dataset is only 101 abstracts, it is difficult to observe any statistical significance.", "labels": [], "entities": []}, {"text": "Based on the offsets, the result suggests that an incorporation of biomedical features (sequence and ontology) is crucial in protein name tagging.", "labels": [], "entities": [{"text": "protein name tagging", "start_pos": 125, "end_pos": 145, "type": "TASK", "confidence": 0.6275021433830261}]}, {"text": "The contribution of syntactic features is not as significant as we originally expect.", "labels": [], "entities": []}, {"text": "Considering syntactic features we use are approximate features obtained from BaseNP boundaries, the outcome maybe inevitable.", "labels": [], "entities": []}, {"text": "We plan to investigate further into effective syntactic features such as word dependency from a word dependency parser.", "labels": [], "entities": []}, {"text": "In order to experiment our method with a larger dataset, we use GENIA corpus 3.01 released recently.", "labels": [], "entities": [{"text": "GENIA corpus 3.01", "start_pos": 64, "end_pos": 81, "type": "DATASET", "confidence": 0.9664677580197653}]}, {"text": "Unlike Yapex corpus, GENIA corpus contains 2000 abstracts and uses a hierarchical tagset.", "labels": [], "entities": [{"text": "Yapex corpus", "start_pos": 7, "end_pos": 19, "type": "DATASET", "confidence": 0.9356105923652649}, {"text": "GENIA corpus", "start_pos": 21, "end_pos": 33, "type": "DATASET", "confidence": 0.9080053269863129}]}, {"text": "For our experiment, we use two definitions fora protein: one to identify G#protein molecule and the other to identify G#protein X.", "labels": [], "entities": []}, {"text": "The former is a narrower sense of protein names, and more close to a protein name in Yapex corpus where the protein name is defined as something that denotes a single biological entity composed of one or more amino acid chain.", "labels": [], "entities": [{"text": "Yapex corpus", "start_pos": 85, "end_pos": 97, "type": "DATASET", "confidence": 0.9881298542022705}]}, {"text": "The latter covers a broader sense of protein, including families and domains.", "labels": [], "entities": []}, {"text": "We evaluate our method with the two versions of protein names since the desired granularity of a protein name depends on the application.", "labels": [], "entities": []}, {"text": "Two datasets are prepared in this experiment.", "labels": [], "entities": []}, {"text": "One is GENIA 1.1 subset and the other is GENIA 3.01 set.", "labels": [], "entities": [{"text": "GENIA 1.1 subset", "start_pos": 7, "end_pos": 23, "type": "DATASET", "confidence": 0.8265318075815836}, {"text": "GENIA 3.01 set", "start_pos": 41, "end_pos": 55, "type": "DATASET", "confidence": 0.889052152633667}]}, {"text": "The GENIA 1.1 subset contains 670 abstracts from GENIA 3.01 where the same Medline IDs are also found in GENIA corpus 1.1.", "labels": [], "entities": [{"text": "GENIA 1.1 subset", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.9271317720413208}, {"text": "GENIA 3.01", "start_pos": 49, "end_pos": 59, "type": "DATASET", "confidence": 0.9223780632019043}, {"text": "GENIA corpus 1.1", "start_pos": 105, "end_pos": 121, "type": "DATASET", "confidence": 0.9583300153414408}]}, {"text": "In addition, we split the GENIA 1.1 subset into the test dataset of 80 abstracts used in and the training dataset of the remaining 590 abstracts.", "labels": [], "entities": [{"text": "GENIA 1.1 subset", "start_pos": 26, "end_pos": 42, "type": "DATASET", "confidence": 0.8633697430292765}]}, {"text": "The  GENIA 3.01 set is an entire set of GENIA corpus 3.01.", "labels": [], "entities": [{"text": "GENIA 3.01 set", "start_pos": 5, "end_pos": 19, "type": "DATASET", "confidence": 0.9332024653752645}, {"text": "GENIA corpus 3.01", "start_pos": 40, "end_pos": 57, "type": "DATASET", "confidence": 0.958433190981547}]}, {"text": "We randomly split the entire set so that 4/5 of which is used for training the remaining 1/5 is used for testing.", "labels": [], "entities": []}, {"text": "Results in show that the broader class G#protein X is easier to learn than the narrower class G#protein molecule.", "labels": [], "entities": []}, {"text": "Results of protein name recognition in using GENIA 1.1 are 0.492, 0.664 and 0.565 for precision, recall, f-score respectively.", "labels": [], "entities": [{"text": "protein name recognition", "start_pos": 11, "end_pos": 35, "type": "TASK", "confidence": 0.6669903000195821}, {"text": "GENIA 1.1", "start_pos": 45, "end_pos": 54, "type": "DATASET", "confidence": 0.8527126610279083}, {"text": "precision", "start_pos": 86, "end_pos": 95, "type": "METRIC", "confidence": 0.9996218681335449}, {"text": "recall", "start_pos": 97, "end_pos": 103, "type": "METRIC", "confidence": 0.9992383718490601}, {"text": "f-score", "start_pos": 105, "end_pos": 112, "type": "METRIC", "confidence": 0.9937844276428223}]}, {"text": "GENIA 1.1 has only one class for protein name (GENIA#protein), while GENIA 3.01 has hierarchically organized tags fora protein name class.", "labels": [], "entities": [{"text": "GENIA 1.1", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9608445167541504}, {"text": "GENIA#protein", "start_pos": 47, "end_pos": 60, "type": "DATASET", "confidence": 0.8483566244443258}, {"text": "GENIA 3.01", "start_pos": 69, "end_pos": 79, "type": "DATASET", "confidence": 0.9163168966770172}]}, {"text": "Assuming that GENIA#protein in GENIA 1.1 corresponds to G#protein X in GENIA 3.01, we could claim that our method gives better results to their SVM approach.", "labels": [], "entities": [{"text": "GENIA 1.1", "start_pos": 31, "end_pos": 40, "type": "DATASET", "confidence": 0.8983072340488434}, {"text": "GENIA 3.01", "start_pos": 71, "end_pos": 81, "type": "DATASET", "confidence": 0.9084730446338654}]}, {"text": "The better performance could be attributed to chunking based on morpheme instead of graphic words and better adaptation of biomedical resources.", "labels": [], "entities": []}, {"text": "Next, we compare Yapex performance with G#protein molecule trained with 1600 abstracts (cf.), though tagging policy and corpus are different.", "labels": [], "entities": []}, {"text": "Our method significantly outperforms in strict, better in left and right, slightly lost in sloppy.", "labels": [], "entities": [{"text": "strict", "start_pos": 40, "end_pos": 46, "type": "METRIC", "confidence": 0.9574970006942749}]}, {"text": "With a large dataset of training data (1600 abstracts), we obtain 70 points of f-score for G#protein molecule and 75 points of f-score for G#protein X, which are comparable to approaches reported in the literature.", "labels": [], "entities": [{"text": "f-score", "start_pos": 79, "end_pos": 86, "type": "METRIC", "confidence": 0.9644392728805542}, {"text": "f-score", "start_pos": 127, "end_pos": 134, "type": "METRIC", "confidence": 0.9629600644111633}]}, {"text": "An increase of training data from 590 abstracts to 1600 abstracts helps the overall performance improve, given the corpus error is minimized.", "labels": [], "entities": []}, {"text": "Our internal experiments with GENIA 3.0 (the version was corrected to GENIA 3.01) reveal that the corpus error is critical in our method.", "labels": [], "entities": [{"text": "GENIA 3.0", "start_pos": 30, "end_pos": 39, "type": "DATASET", "confidence": 0.9167761504650116}, {"text": "GENIA 3.01", "start_pos": 70, "end_pos": 80, "type": "DATASET", "confidence": 0.9313499629497528}]}, {"text": "Even corpus errors have been successfully removed, it would not be practical to increase the size of labor-intensive annotated corpus.", "labels": [], "entities": []}, {"text": "Use of unlabeled data in conjunction with a small but quality set of labeled data.", "labels": [], "entities": []}, {"text": "e.g., would have to be explored.", "labels": [], "entities": []}, {"text": "use a hybrid approach of transformation-based learning (Brill Tagger) with rule-based post processing.", "labels": [], "entities": []}, {"text": "An obvious drawback in their approach as with other rule-based approaches including is that the approaches cannot handle many correlated features.", "labels": [], "entities": []}, {"text": "As pointed out in their paper, errors in the early stage of rule application are often propagated to the later stage, damaging the overall performance.", "labels": [], "entities": [{"text": "rule application", "start_pos": 60, "end_pos": 76, "type": "TASK", "confidence": 0.910306304693222}]}, {"text": "In contrast, our method can deal with correlated features owing to the generalization characteristic of SVM.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 5: Results on Yapex corpus (99 abstracts for  training and 101 abstracts for testing). P(precision),  R(recall) and F(f-score) are shown. The table shows  the protein tagger with an IOB2 chunking with for- ward parsing.", "labels": [], "entities": [{"text": "Yapex corpus", "start_pos": 21, "end_pos": 33, "type": "DATASET", "confidence": 0.9818100929260254}, {"text": "precision),  R(recall) and F(f-score)", "start_pos": 96, "end_pos": 133, "type": "METRIC", "confidence": 0.717400461435318}]}, {"text": " Table 6: The table shows the protein tagger with an  IOE2 chunking with backward parsing.", "labels": [], "entities": []}, {"text": " Table 7: Effects of each feature contribution on strict  boundary condition. The F-score is subtracted from  the maximal model in IOB2 chuking with forward  parsing (Table 5). The upper rows show effects of a  single feature removed. The lower rows show effects  of multiple features with the same class removed.  See Section 2.3 for description of each feature.", "labels": [], "entities": [{"text": "F-score", "start_pos": 82, "end_pos": 89, "type": "METRIC", "confidence": 0.9982513785362244}]}, {"text": " Table 8: Results on GENIA 1.1 subset of 670 ab- stracts (590 abstracts for training and 80 abstracts  for testing).", "labels": [], "entities": [{"text": "GENIA 1.1 subset of 670 ab- stracts", "start_pos": 21, "end_pos": 56, "type": "DATASET", "confidence": 0.832399345934391}]}, {"text": " Table 9: Results on GENIA 3.01 set of 2000 ab- stracts (1600 abstracts for training and 400 abstracts  for testing).", "labels": [], "entities": [{"text": "GENIA 3.01 set of 2000 ab- stracts", "start_pos": 21, "end_pos": 55, "type": "DATASET", "confidence": 0.8999985381960869}]}]}