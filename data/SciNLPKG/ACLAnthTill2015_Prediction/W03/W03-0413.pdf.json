{"title": [], "abstractContent": [{"text": "The purpose of this work is to investigate the use of machine learning approaches for confidence estimation within a statistical machine translation application.", "labels": [], "entities": [{"text": "confidence estimation", "start_pos": 86, "end_pos": 107, "type": "TASK", "confidence": 0.6549655050039291}, {"text": "statistical machine translation", "start_pos": 117, "end_pos": 148, "type": "TASK", "confidence": 0.6087559660275778}]}, {"text": "Specifically, we attempt to learn probabilities of correctness for various model predictions, based on the native probabilites (i.e. the probabilites given by the original model) and on features of the current context.", "labels": [], "entities": []}, {"text": "Our experiments were conducted using three original translation models and two types of neural nets (single-layer and multi-layer perceptrons) for the confidence estimation task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Most statistical models used in natural language applications are capable in principle of generating probability estimates for their outputs.", "labels": [], "entities": []}, {"text": "However, in practice, these estimates are often quite poor and are usually interpreted simply as scores that are monotonic with probabilities.", "labels": [], "entities": []}, {"text": "There are many contexts where good estimates of true probabilities are desirable: \u2022 in a decision-theoretic setting, posterior probabilities are required in order to choose the lowest-cost output fora given input.", "labels": [], "entities": []}, {"text": "\u2022 when a collection of different models is available for some problem, output probabilities provide a principled and convenient way of combining them; and \u2022 when multiplying conditional probabilities to compute joint distributions, the accuracy of the result is crucially dependent on the stability of the conditional estimates across different contexts-this is important for applications like speech recognition and machine translation that perform searches over a large space of output sentences, represented as sequences of words.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 236, "end_pos": 244, "type": "METRIC", "confidence": 0.9970054030418396}, {"text": "speech recognition", "start_pos": 394, "end_pos": 412, "type": "TASK", "confidence": 0.753495842218399}, {"text": "machine translation", "start_pos": 417, "end_pos": 436, "type": "TASK", "confidence": 0.7809078991413116}]}, {"text": "Given a statistical model that produces a probabilistic score, a straightforward way of obtaining a true probability is to use the score as input to another model whose output is interpreted as the desired probability.", "labels": [], "entities": []}, {"text": "The idea is that the second model can learn how to transform the base model's score by observing its performance on new text, possibly in conjunction with other features.", "labels": [], "entities": []}, {"text": "This approach, which is known as confidence estimation (CE), is widely used in speech recognition () but is virtually unknown in other areas of natural language progessing (NLP).", "labels": [], "entities": [{"text": "confidence estimation (CE)", "start_pos": 33, "end_pos": 59, "type": "METRIC", "confidence": 0.8825631380081177}, {"text": "speech recognition", "start_pos": 79, "end_pos": 97, "type": "TASK", "confidence": 0.782734751701355}, {"text": "natural language progessing (NLP)", "start_pos": 144, "end_pos": 177, "type": "TASK", "confidence": 0.7206063369909922}]}, {"text": "The alternatives to confidence estimation are traditional smoothing techniques such as backing off to simpler models and cross validation, along with careful marginalization and scaling where applicable to obtain the desired posterior probabilities.", "labels": [], "entities": [{"text": "confidence estimation", "start_pos": 20, "end_pos": 41, "type": "TASK", "confidence": 0.5766133069992065}]}, {"text": "There is some evidence () that this approach can give results that are at least as good as those obtainable with an external CE model.", "labels": [], "entities": []}, {"text": "However, CE as we present it here is not incompatible with traditional techniques, and has several practical advantages.", "labels": [], "entities": [{"text": "CE", "start_pos": 9, "end_pos": 11, "type": "METRIC", "confidence": 0.872612476348877}]}, {"text": "First, it can easily incorporate specialized features that are highly indicative of how well the base model will perform on a given input, but that maybe of little use for the task of choosing the output.", "labels": [], "entities": []}, {"text": "Since such features maybe inconvenient to include in the base model, CE represents a kind of modularization, particularly as it maybe possible to reuse some features for many different problems.", "labels": [], "entities": [{"text": "CE", "start_pos": 69, "end_pos": 71, "type": "METRIC", "confidence": 0.7802324295043945}]}, {"text": "Another advantage is that a CE layer is usually much smaller and easier to train than the baseline model; this means that it can be used to rapidly adapt a system's performance to new domains.", "labels": [], "entities": []}, {"text": "Finally, CE typically concentrates on only the top few hy-potheses output by the baseline model, which is an easier task than estimating a complete distribution.", "labels": [], "entities": [{"text": "CE", "start_pos": 9, "end_pos": 11, "type": "TASK", "confidence": 0.9610132575035095}]}, {"text": "This is especially true when the hypotheses of interest are drawn from a joint distribution that maybe impossible in practice to enumerate.", "labels": [], "entities": []}, {"text": "In this paper we describe an application of confidence estimation to an interactive target-text prediction task in a translation setting, using two different types of neural nets: single-layer perceptron (SLPs) and multi-layer perceptrons (MLPs) with 20 hidden units.", "labels": [], "entities": [{"text": "target-text prediction task", "start_pos": 84, "end_pos": 111, "type": "TASK", "confidence": 0.8150358001391093}]}, {"text": "The main issues that we investigate here are: \u2022 the benefit that can be gained by using confidence estimates, in discrimination power and/or over-all application quality as computed by a simulation that estimates the benefit to the user; \u2022 the use of different machine learning (ML) techniques for CE; \u2022 the relevance of various confidence features; and \u2022 model combinations: we experiment with various model combination schemes based on the CE layer in order to improve the over-all prediction accuracy of the application.", "labels": [], "entities": []}, {"text": "Among the more interesting results we will present are the comparisons between the discrimination capacity of the native probabilities and the probabilities of correctness produced by the CE layer.", "labels": [], "entities": []}, {"text": "Depending on the underlying SMT model, we obtained a relative improvement incorrect rejection rate (CR) ranging from 3.90% to 33.09% at a fixed 0.80 correct acceptance rate (CA) for prediction lengths of up to four words.", "labels": [], "entities": [{"text": "SMT", "start_pos": 28, "end_pos": 31, "type": "TASK", "confidence": 0.9902641773223877}, {"text": "incorrect rejection rate (CR)", "start_pos": 74, "end_pos": 103, "type": "METRIC", "confidence": 0.9542975922425588}, {"text": "correct acceptance rate (CA)", "start_pos": 149, "end_pos": 177, "type": "METRIC", "confidence": 0.9057940344015757}]}, {"text": "We also measured relative improvements of approximately 10% in estimated benefit to the user with our application.", "labels": [], "entities": []}, {"text": "In the following section we briefly describe the text prediction application we are aiming to improve.", "labels": [], "entities": [{"text": "text prediction", "start_pos": 49, "end_pos": 64, "type": "TASK", "confidence": 0.8227005898952484}]}, {"text": "Next we outline the CE approach and the evaluation methods we applied.", "labels": [], "entities": []}, {"text": "Finally, we report the results obtained in our experiments and conclude with suggestions for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Evaluation is performed using test sets of translation predictions, each tagged as corrector incorrect.", "labels": [], "entities": []}, {"text": "A translation prediction w m is tagged as correct if and only if an identical word sequence is found in the reference translation, properly aligned.", "labels": [], "entities": []}, {"text": "This reflects our application, where we attempt to match what a particular translator has in mind, not simply produce any correct translation.", "labels": [], "entities": []}, {"text": "We use two types of evaluation methods: ROC curves and a user simulation as described above.", "labels": [], "entities": [{"text": "ROC", "start_pos": 40, "end_pos": 43, "type": "METRIC", "confidence": 0.6068295240402222}]}, {"text": "The data for our experiments originates from the Hansard English-French parallel corpus.", "labels": [], "entities": [{"text": "Hansard English-French parallel corpus", "start_pos": 49, "end_pos": 87, "type": "DATASET", "confidence": 0.9552018195390701}]}, {"text": "In this section we report the ROC evaluation results.", "labels": [], "entities": [{"text": "ROC evaluation", "start_pos": 30, "end_pos": 44, "type": "TASK", "confidence": 0.5676266998052597}]}, {"text": "The user-model evaluation results are presented in the following section.", "labels": [], "entities": []}, {"text": "As described in section 2, we evaluated the prediction system as a whole by simulating the actions of a translator on a given source text and measuring the gain  with a user model.", "labels": [], "entities": []}, {"text": "In order to abstract away from approximations made in deriving character-based probabilities p(k|x, h, s) used in the benefit calculation from word-based probabilities, we employed a specialized user model.", "labels": [], "entities": []}, {"text": "In contrast to the realistic model described in), this assumes that users accept predictions only at the beginnings of words, and only when they are correct in their entirety.", "labels": [], "entities": []}, {"text": "To reduce variation further, it also assumes that the user always accepts a correct prediction as soon as it is suggested.", "labels": [], "entities": [{"text": "variation", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9454613924026489}]}, {"text": "Thus the model's estimates of benefit to the user maybe slightly overoptimistic: the limited opportunities for accepting and editing must be balanced against the user's inhumanly perfect decision-making.", "labels": [], "entities": []}, {"text": "However, its main purpose is not realism but simply to allow fora fair comparison between the base and the CE models.", "labels": [], "entities": [{"text": "realism", "start_pos": 33, "end_pos": 40, "type": "METRIC", "confidence": 0.9647191166877747}]}, {"text": "Simulations with all three translation models were performed using a 500-sentence test text.", "labels": [], "entities": []}, {"text": "At each prediction point, the benefits associated with best predictions of 1-4 words in length were compared to decide which (if any) to propose.", "labels": [], "entities": []}, {"text": "The results, in terms of percentages of typing time saved, are shown in table 8: base corresponds to the base model; mults to length-specific probability multipliers tuned to optimize benefit on a held-out corpus; SLP and MLP to CE estimates; and best to using an oracle to pick the length that maximizes benefit.", "labels": [], "entities": []}, {"text": "Although the CE layer provides no gain over the much simpler probability-multiplier approach for the Bayes model, the gain for both maxent models is substantial, around 10% in relative terms and 25% of the theoretical maximum gain (over the base model) with the MLP and slightly lower with the SLP.", "labels": [], "entities": [{"text": "MLP", "start_pos": 262, "end_pos": 265, "type": "DATASET", "confidence": 0.7531659603118896}]}], "tableCaptions": [{"text": " Table 1: Comparison of discrimination capacity between  the Bayes prediction model probability and the CE of the  corresponding SLP and MLP on predictions of up to four  words", "labels": [], "entities": [{"text": "CE", "start_pos": 104, "end_pos": 106, "type": "METRIC", "confidence": 0.9968119263648987}]}, {"text": " Table 3: Comparison of discrimination capacity between  the Maxent1 prediction model probability and the CE of  the corresponding SLP and MLP on predictions of up to  four words", "labels": [], "entities": [{"text": "Maxent1 prediction model probability", "start_pos": 61, "end_pos": 97, "type": "DATASET", "confidence": 0.8217809498310089}, {"text": "CE", "start_pos": 106, "end_pos": 108, "type": "METRIC", "confidence": 0.9968425035476685}]}, {"text": " Table 4: Comparison of discrimination capacity between  the Maxent2 prediction model probability and the CE of  the corresponding SLP and MLP on predictions of up to  four words", "labels": [], "entities": [{"text": "Maxent2 prediction model probability", "start_pos": 61, "end_pos": 97, "type": "DATASET", "confidence": 0.8323824852705002}, {"text": "CE", "start_pos": 106, "end_pos": 108, "type": "METRIC", "confidence": 0.9967160224914551}]}, {"text": " Table 5: Impact of prediction length on discrimination  capacity and accuracy for the Maxent2 prediction model", "labels": [], "entities": [{"text": "accuracy", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.999218225479126}]}, {"text": " Table 6: Prediction accuracy of the Bayes and Maxent2  model compared with combined model accuracy", "labels": [], "entities": [{"text": "Prediction", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.8708236813545227}, {"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.613474428653717}]}, {"text": " Table 7: Percentage of typing time saved for various CE  configurations.", "labels": [], "entities": [{"text": "Percentage", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9536855816841125}]}]}