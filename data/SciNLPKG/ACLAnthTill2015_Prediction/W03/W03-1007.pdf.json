{"title": [{"text": "Maximum Entropy Models for FrameNet Classification", "labels": [], "entities": [{"text": "FrameNet Classification", "start_pos": 27, "end_pos": 50, "type": "TASK", "confidence": 0.8373472690582275}]}], "abstractContent": [{"text": "The development of FrameNet, a large database of semantically annotated sentences , has primed research into statistical methods for semantic tagging.", "labels": [], "entities": [{"text": "semantic tagging", "start_pos": 133, "end_pos": 149, "type": "TASK", "confidence": 0.7534395456314087}]}, {"text": "We advance previous work by adopting a Maximum Entropy approach and by using previous tag information to find the highest probability tag sequence fora given sentence.", "labels": [], "entities": []}, {"text": "Further we examine the use of sentence level syntactic pattern features to increase performance.", "labels": [], "entities": []}, {"text": "We analyze our strategy on both human annotated and automatically identified frame elements, and compare performance to previous work on identical test data.", "labels": [], "entities": []}, {"text": "Experiments indicate a statistically significant improvement (p<0.01) of over 6%.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recent work in the development of FrameNet, a large database of semantically annotated sentences, has laid the foundation for statistical approaches to the task of automatic semantic classification.", "labels": [], "entities": [{"text": "automatic semantic classification", "start_pos": 164, "end_pos": 197, "type": "TASK", "confidence": 0.6245918373266856}]}, {"text": "The FrameNet project seeks to annotate a large subset of the British National Corpus with semantic information.", "labels": [], "entities": [{"text": "British National Corpus", "start_pos": 61, "end_pos": 84, "type": "DATASET", "confidence": 0.9468052387237549}]}, {"text": "Annotations are based on Frame Semantics, in which frames are defined as schematic representations of situations involving various frame elements such as participants, props, and other conceptual roles.", "labels": [], "entities": []}, {"text": "In each FrameNet sentence, a single target predicate is identified and all of its relevant frame elements are tagged with their semantic role (e.g., Agent, Judge), their syntactic phrase type (e.g., NP, PP), and their grammatical function (e.g., external argument, object argument).", "labels": [], "entities": []}, {"text": "shows an example of an annotated sentence and its appropriate semantic frame.", "labels": [], "entities": []}, {"text": "She clapped her hands in inspiration.", "labels": [], "entities": []}], "datasetContent": [{"text": "We present three experiments in which different feature sets are used to train the ME classifier.", "labels": [], "entities": []}, {"text": "The first experiment uses only those feature combinations described in (feature sets 0-7 from).", "labels": [], "entities": []}, {"text": "The second experiment uses a super set of the first and incorporates the syntactic pattern features described above (feature sets 0-9).", "labels": [], "entities": []}, {"text": "The final experiment uses the previous tags and implements Viterbi search to find the best tag sequence (feature sets 0-11).", "labels": [], "entities": []}, {"text": "Here Z x is a normalization constant, f i (r,x) is a feature function which maps each role and vector element (or combination of elements) to a binary value, n is the total number of feature functions, and \u03bb i is the weight fora given feature function.", "labels": [], "entities": []}, {"text": "The final classification is just the role with highest probability given its feature vector and the model.", "labels": [], "entities": []}, {"text": "We further investigate the effect of varying two aspects of classifier training: the standard deviation of the Gaussian priors used for smoothing, and the number of sentences used for training.", "labels": [], "entities": []}, {"text": "To examine the effect of optimizing the standard deviation, a range of values was chosen and a classifier was trained using each value until performance on a development set ceased to improve.", "labels": [], "entities": []}, {"text": "The feature functions that we employ can be divided into feature sets based upon the types and combinations of features on which they operate.", "labels": [], "entities": []}, {"text": "lists the feature sets that we use, as well as the number of individual feature functions they contain.", "labels": [], "entities": []}, {"text": "The feature combinations were chosen based both on previous work and trial and error.", "labels": [], "entities": []}, {"text": "In future work we will examine more principled feature selection techniques.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 47, "end_pos": 64, "type": "TASK", "confidence": 0.7729887962341309}]}, {"text": "To examine the effect of training set size on performance, five data sets were generated from the original set with 36, 367, 3674, 7349, and 24496 sentences, respectively.", "labels": [], "entities": []}, {"text": "These data sets were created by going through the original set and selecting every thousandth, hundredth, tenth, fifth, and every second and third sentence, respectively.", "labels": [], "entities": []}, {"text": "It is important to note that the feature functions described here are not equivalent to the subset conditional distributions that are used in the Gildea and Jurafsky model.", "labels": [], "entities": []}, {"text": "ME models are log-linear models in which feature functions map specific instances of syntactic features and classes to binary values (e.g., if a training element has head=\"in\" and role=CAUSE, then, for that element, the feature function f(CAUSE, \"in\") will equal 1).", "labels": [], "entities": []}, {"text": "Thus, ME is not here being used as another way to find weights for an interpolated model.", "labels": [], "entities": [{"text": "ME", "start_pos": 6, "end_pos": 8, "type": "METRIC", "confidence": 0.5580461025238037}]}, {"text": "Rather, the ME approach provides an overarching framework in which the full distribution of semantic roles given syntactic features can be modeled.", "labels": [], "entities": []}, {"text": "We train the ME models using the GIS algorithm ( as implemented in the YASMET ME package).", "labels": [], "entities": [{"text": "YASMET ME package", "start_pos": 71, "end_pos": 88, "type": "DATASET", "confidence": 0.7934770186742147}]}, {"text": "We use the YASMET MEtagger ( to perform the Viterbi search.", "labels": [], "entities": [{"text": "YASMET", "start_pos": 11, "end_pos": 17, "type": "METRIC", "confidence": 0.9295642375946045}, {"text": "MEtagger", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.4796814024448395}]}, {"text": "The classifier was trained until performance on the development set ceased to improve.", "labels": [], "entities": []}, {"text": "Feature weights were smoothed using Gaussian priors with mean 0 ().", "labels": [], "entities": []}, {"text": "The standard deviation of this distribution was optimized on the development set for each experiment..", "labels": [], "entities": []}, {"text": "Performance of models on test data using hand annotated frame element boundaries.", "labels": [], "entities": []}, {"text": "G&J refers to the results of.", "labels": [], "entities": [{"text": "G&J", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.9025076230367025}]}, {"text": "Exp 1 incorporates feature sets 0-7 from; Exp 2 feature sets 0-9; Exp 3 features 0-11.", "labels": [], "entities": [{"text": "Exp", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9412562251091003}]}, {"text": "shows the results of our experiments alongside those of (Gildea and Jurafsky, 2002) on identical held out test sets.", "labels": [], "entities": []}, {"text": "The difference in performance between each classifier is statistically significant at (p<0.01), with the exception of Exp 2 and Exp 3, whose difference is statistically significant at (p<0.05).", "labels": [], "entities": []}, {"text": "shows the effect of varying the standard deviation of the Gaussian priors used for smoothing in Experiment 1.", "labels": [], "entities": []}, {"text": "The difference in performance between the classifiers trained using standard deviation 1 and 2 is statistically significant at (p<0.01)..", "labels": [], "entities": []}, {"text": "Effect of training set size on semantic role classification.", "labels": [], "entities": [{"text": "semantic role classification", "start_pos": 31, "end_pos": 59, "type": "TASK", "confidence": 0.8381068507830302}]}, {"text": "shows the change in performance as a function of training set size.", "labels": [], "entities": []}, {"text": "Classifiers were trained using the full set of features described for Experiment 3.", "labels": [], "entities": []}, {"text": "shows the confusion matrix fora subset of semantic roles.", "labels": [], "entities": []}, {"text": "Five roles were chosen for presentation based upon their high contribution to classifier error.", "labels": [], "entities": [{"text": "presentation", "start_pos": 27, "end_pos": 39, "type": "TASK", "confidence": 0.9694089889526367}]}, {"text": "Confusion between these five account for 27% of all errors made amongst the 120 possible roles.", "labels": [], "entities": []}, {"text": "The tenth role, other, represents the sum of the remaining 115 roles.", "labels": [], "entities": []}, {"text": "presents example errors for five of the most confused roles.", "labels": [], "entities": []}, {"text": "We use the ME formulation described in Section 3.2 to build a binary classifier.", "labels": [], "entities": []}, {"text": "The classifier features follow closely those used in Gildea and Jurafsky.", "labels": [], "entities": []}, {"text": "We model the data using the feature sets: f(fe, path), f(fe, path, tar), and f(fe, head, tar), where fe represents the binary classification of the constituent.", "labels": [], "entities": []}, {"text": "While this experiment only uses three feature sets, the heterogeneity of the path feature is so great that the classifier itself uses 1,119,331 unique binary features.", "labels": [], "entities": []}, {"text": "With the constituents having been labeled, we apply the ME frame element classifier described above.", "labels": [], "entities": []}, {"text": "Results are presented using the classifier of Experiment 1, described in section 3.3.", "labels": [], "entities": []}, {"text": "We then investigate the effect of varying the number of constituents used for training on identification performance.", "labels": [], "entities": []}, {"text": "Five data sets of approximately 100,000 10,000, 1,000, and 100 constituents were generated from the original set by random selection and used to train ME models as described above.", "labels": [], "entities": []}, {"text": "compares the results of Gildea and Jurafsky (2002) and the ME frame element identifier on both the task of frame element identification alone, and the combined task of frame element identification and classification.", "labels": [], "entities": [{"text": "ME frame element identifier", "start_pos": 59, "end_pos": 86, "type": "DATASET", "confidence": 0.7265267223119736}, {"text": "frame element identification", "start_pos": 107, "end_pos": 135, "type": "TASK", "confidence": 0.6079429984092712}, {"text": "frame element identification and classification", "start_pos": 168, "end_pos": 215, "type": "TASK", "confidence": 0.6426147103309632}]}, {"text": "In order to be counted correct on the combined task, the constituent must have been correctly identified as a frame element, and then must have been correctly classified into one of the 120 semantic categories.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. Feature sets used in ME frame element classifier. Shows individual feature sets, example feature  function from that set, and total number of feature functions in the set. Examples taken from frame element  \"in inspiration,\" shown in", "labels": [], "entities": [{"text": "ME frame element classifier", "start_pos": 31, "end_pos": 58, "type": "TASK", "confidence": 0.5781492739915848}]}, {"text": " Table 2. Effect of different smoothing parameter (std.  dev.) values on classification performance.  Std. Dev.  % Correct  1  79.9  2  82.1  4  81.9", "labels": [], "entities": [{"text": "Std. Dev", "start_pos": 102, "end_pos": 110, "type": "DATASET", "confidence": 0.9004030028978983}]}, {"text": " Table 3. Confusion matrix for five roles which contrib- ute most to overall system error. Columns refer to ac- tual role. Rows refer to the model's hypothesis. Other  refers to combination of all other roles.", "labels": [], "entities": []}, {"text": " Table 5. Results of frame element identification. G&J represents results reported in (", "labels": [], "entities": [{"text": "frame element identification", "start_pos": 21, "end_pos": 49, "type": "TASK", "confidence": 0.6604479054609934}, {"text": "G&J", "start_pos": 51, "end_pos": 54, "type": "METRIC", "confidence": 0.9348171949386597}]}]}