{"title": [{"text": "Transliteration of Proper Names in Cross-Lingual Information Retrieval", "labels": [], "entities": [{"text": "Cross-Lingual Information Retrieval", "start_pos": 35, "end_pos": 70, "type": "TASK", "confidence": 0.6123285988966624}]}], "abstractContent": [{"text": "We address the problem of transliterating English names using Chinese orthogra-phy in support of cross-lingual speech and text processing applications.", "labels": [], "entities": [{"text": "transliterating English names", "start_pos": 26, "end_pos": 55, "type": "TASK", "confidence": 0.8351247509320577}]}, {"text": "We demonstrate the application of statistical machine translation techniques to \"translate\" the phonemic representation of an En-glish name, obtained by using an automatic text-to-speech system, to a sequence of initials and finals, commonly used sub-word units of pronunciation for Chinese.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 34, "end_pos": 65, "type": "TASK", "confidence": 0.6683755815029144}]}, {"text": "We then use another statistical translation model to map the initial/final sequence to Chinese characters.", "labels": [], "entities": []}, {"text": "We also present an evaluation of this module in retrieval of Mandarin spoken documents from the TDT corpus using English text queries.", "labels": [], "entities": [{"text": "TDT corpus", "start_pos": 96, "end_pos": 106, "type": "DATASET", "confidence": 0.9143804013729095}]}], "introductionContent": [{"text": "Translation of proper names is generally recognized as a significant problem in many multi-lingual text and speech processing applications.", "labels": [], "entities": [{"text": "Translation of proper names", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.9273743629455566}]}, {"text": "Even when hand-crafted translation lexicons used for machine translation (MT) and cross-lingual information retrieval (CLIR) provide significant coverage of the words encountered in the text, a significant portion of the tokens not covered by the lexicon are proper names and domain-specific terminology (cf., e.g.,).", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 53, "end_pos": 77, "type": "TASK", "confidence": 0.852460503578186}, {"text": "cross-lingual information retrieval (CLIR)", "start_pos": 82, "end_pos": 124, "type": "TASK", "confidence": 0.7537417411804199}]}, {"text": "This lack of translations adversely affects performance.", "labels": [], "entities": []}, {"text": "For CLIR applications in particular, proper names and technical terms are especially important, as they carry the most distinctive information in a query as corroborated by their relatively low document frequency.", "labels": [], "entities": []}, {"text": "Finally, in interactive IR systems where users provide very short queries (e.g. 2-5 words), their importance grows even further.", "labels": [], "entities": []}, {"text": "Unlike specialized terminology, however, proper names are amenable to a speech-inspired translation approach.", "labels": [], "entities": []}, {"text": "One tries, when writing foreign names in ones own language, to preserve the way it sounds.", "labels": [], "entities": []}, {"text": "i.e. one uses an orthographic representation which, when \"read aloud\" by a speaker of ones language sounds as much like it would when spoken by a speaker of the foreign language -a process referred to as transliteration.", "labels": [], "entities": []}, {"text": "Therefore, if a mechanism were available to render, say, an English name in its phonemic form, and another mechanism were available to convert this phonemic string into the orthography of, say, Chinese, then one would have a mechanism for transliterating English names using Chinese characters.", "labels": [], "entities": [{"text": "transliterating English names", "start_pos": 239, "end_pos": 268, "type": "TASK", "confidence": 0.8822396993637085}]}, {"text": "The first step has been addressed extensively, for other obvious reasons, in the automatic speech synthesis literature.", "labels": [], "entities": [{"text": "automatic speech synthesis", "start_pos": 81, "end_pos": 107, "type": "TASK", "confidence": 0.6145333548386892}]}, {"text": "This paper describes a statistical approach for the second step.", "labels": [], "entities": []}, {"text": "Several techniques have been proposed in the recent past for name transliteration.", "labels": [], "entities": [{"text": "name transliteration", "start_pos": 61, "end_pos": 81, "type": "TASK", "confidence": 0.9004941582679749}]}, {"text": "Rather than providing a comprehensive survey we highlight a few representative approaches here.", "labels": [], "entities": []}, {"text": "Finite state transducers that implement transformation rules for back-transliteration from Japanese to English have been described by, and extended to Arabic by.", "labels": [], "entities": []}, {"text": "In both cases, the goal is to recognize words in Japanese or Arabic text which hap- pen to be transliterations of English names.", "labels": [], "entities": []}, {"text": "If the orthography of a language is strongly phonetic, as is the case for Korean, then one may use relatively simple hidden Markov models to transform English pronunciations, as shown by.", "labels": [], "entities": []}, {"text": "The work closest to our application scenario, and the one with which we will be making several direct comparisons, is that of Meng et al.", "labels": [], "entities": []}, {"text": "In their work, a set of hand-crafted transformations for locally editing the phonemic spelling of an English word to conform to rules of Mandarin syllabification are used to seed a transformation-based learning algorithm.", "labels": [], "entities": []}, {"text": "The algorithm examines some data and learns the proper sequence of application of the transformations to convert an English phoneme sequence to a Mandarin syllable sequence.", "labels": [], "entities": []}, {"text": "Our paper describes a data driven counterpart to this technique, in which a cascade of two source-channel translation models is used to go from English names to their Chinese transliteration.", "labels": [], "entities": []}, {"text": "Thus even the initial requirement of creating candidate transformation rules, which may require knowledge of the phonology of the target language, is eliminated.", "labels": [], "entities": []}, {"text": "We also investigate incorporation of this transliteration system in a cross-lingual spoken document retrieval application, in which English text queries are used to index and retrieve Mandarin audio from the TDT corpus.", "labels": [], "entities": [{"text": "cross-lingual spoken document retrieval", "start_pos": 70, "end_pos": 109, "type": "TASK", "confidence": 0.6337072476744652}, {"text": "TDT corpus", "start_pos": 208, "end_pos": 218, "type": "DATASET", "confidence": 0.8719773292541504}]}], "datasetContent": [{"text": "We evaluate the efficacy of our transliteration at two levels.", "labels": [], "entities": []}, {"text": "For comparison with the very comparable set-up of, we measure the accuracy of the pin-yin output produced by our system after Step 3.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.999528169631958}]}, {"text": "The results are shown in, where pin-yin error rate is the edit distance between the \"correct\" pin-yin representation of the correct transliteration and the pin-yin sequence output by the system.: Pin-yin and character error rates in automatic transliteration.", "labels": [], "entities": [{"text": "pin-yin error rate", "start_pos": 32, "end_pos": 50, "type": "METRIC", "confidence": 0.8089103897412618}]}, {"text": "Note that the pin-yin error performance of our fully statistical method is quite competitive with previous results.", "labels": [], "entities": []}, {"text": "We further note that increasing the training data results in further reduction of the syllable error rate.", "labels": [], "entities": [{"text": "syllable error rate", "start_pos": 86, "end_pos": 105, "type": "METRIC", "confidence": 0.7676021655400594}]}, {"text": "We concede that this performance, while comparable to other systems, is not satisfactory and merits further investigation.", "labels": [], "entities": []}, {"text": "We also evaluate the efficacy of our second translation system which maps the pin-yin sequence produced by the previous stages to a sequence of Chinese characters, and obtain character error rates of 12.6%.", "labels": [], "entities": [{"text": "character error rates", "start_pos": 175, "end_pos": 196, "type": "METRIC", "confidence": 0.7562743425369263}]}, {"text": "Thus every correctly recognized pin-yin symbol has a chance of being transformed with some error, resulting in higher character error rate than the pin-yin error rate.", "labels": [], "entities": [{"text": "character error rate", "start_pos": 118, "end_pos": 138, "type": "METRIC", "confidence": 0.7497695684432983}]}, {"text": "Note that while significantly lower error rates have been reported for converting pin-yin to characters in generic Chinese text, ours is a highly specialized subset of transliterated foreign names, where the choice between several characters sharing the same pin-yin symbol is somewhat arbitrary.", "labels": [], "entities": [{"text": "error", "start_pos": 36, "end_pos": 41, "type": "METRIC", "confidence": 0.9665470719337463}]}], "tableCaptions": [{"text": " Table 1: Pin-yin and character error rates in auto- matic transliteration.", "labels": [], "entities": []}, {"text": " Table 3: Pin-yin error rates for MT systems with  varying amounts of training data and different data  selection procedures.", "labels": [], "entities": [{"text": "Pin-yin error rates", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.6644911170005798}, {"text": "MT", "start_pos": 34, "end_pos": 36, "type": "TASK", "confidence": 0.9876107573509216}]}]}