{"title": [], "abstractContent": [{"text": "We evaluate the English-French word alignment data of the shared tasks from a phrase alignment perspective.", "labels": [], "entities": [{"text": "English-French word alignment", "start_pos": 16, "end_pos": 45, "type": "TASK", "confidence": 0.6307198802630106}, {"text": "phrase alignment", "start_pos": 78, "end_pos": 94, "type": "TASK", "confidence": 0.70927394926548}]}, {"text": "We discuss peculiarities of the submitted data and the test data.", "labels": [], "entities": []}, {"text": "We show that phrase-based evaluation is closely related to word-based evaluation.", "labels": [], "entities": []}, {"text": "We show examples of phrases which are easy to align and also phrases which are difficult to align.", "labels": [], "entities": []}], "introductionContent": [{"text": "We describe a phrase-based evaluation of the 16 English-French alignment submissions for the shared task on Parallel Texts.", "labels": [], "entities": []}, {"text": "The task was to indicate which word token in an English alignment sample corresponds to which word token in the French alignment sample.", "labels": [], "entities": [{"text": "French alignment sample", "start_pos": 112, "end_pos": 135, "type": "DATASET", "confidence": 0.802039643128713}]}, {"text": "Two types of submission were permitted: for restricted submissions were allowed a \"sentence\" aligned segment of the Canadian Hansards to train the systems while unrestricted submission would be allowed to use additional resources.", "labels": [], "entities": [{"text": "Canadian Hansards", "start_pos": 116, "end_pos": 133, "type": "DATASET", "confidence": 0.8545011579990387}]}, {"text": "The performance of the systems was compared fora set of 447 English-French hand-aligned test samples which were also taken from the Canadian Hansards.", "labels": [], "entities": [{"text": "Canadian Hansards", "start_pos": 132, "end_pos": 149, "type": "DATASET", "confidence": 0.7570937275886536}]}, {"text": "Five institutes participated in the English-French alignment task, submitting a total of 16 sets of alignment data.", "labels": [], "entities": [{"text": "alignment task", "start_pos": 51, "end_pos": 65, "type": "TASK", "confidence": 0.7665915191173553}]}, {"text": "To evaluate the submitted data, we extracted bilingual phrase dictionaries from the word-alignment data.", "labels": [], "entities": []}, {"text": "The extracted dictionaries of the submitted data were compared with the extracted dictionary of the test data.", "labels": [], "entities": []}, {"text": "We first discuss word-to-word and phrase-to-phrase alignment format.", "labels": [], "entities": [{"text": "phrase-to-phrase alignment format", "start_pos": 34, "end_pos": 67, "type": "TASK", "confidence": 0.7785560091336569}]}, {"text": "We present two different methods for extracting bilingual dictionaries from the word alignment data: a minimal dictionary contains the least number of unambiguous phrase-to-phrase translations while an exhaustive dictionary contains all possible unambiguous translations.", "labels": [], "entities": [{"text": "extracting bilingual dictionaries from the word alignment", "start_pos": 37, "end_pos": 94, "type": "TASK", "confidence": 0.6539372163159507}]}, {"text": "We examine the test data (i.e. the \"golden standard\") and the submitted alignment data.", "labels": [], "entities": []}, {"text": "We discuss their peculiarities and give examples of phrases easy and difficult to align.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}