{"title": [{"text": "Selecting Text Features for Gene Name Classification: from Documents to Terms", "labels": [], "entities": [{"text": "Gene Name Classification", "start_pos": 28, "end_pos": 52, "type": "TASK", "confidence": 0.8369217316309611}]}], "abstractContent": [{"text": "In this paper we discuss the performance of a text-based classification approach by comparing different types of features.", "labels": [], "entities": [{"text": "text-based classification", "start_pos": 46, "end_pos": 71, "type": "TASK", "confidence": 0.6018258482217789}]}, {"text": "We consider the automatic classification of gene names from the molecular biology literature, by using a support-vector machine method.", "labels": [], "entities": [{"text": "automatic classification of gene names", "start_pos": 16, "end_pos": 54, "type": "TASK", "confidence": 0.7663436770439148}]}, {"text": "Classification features range from words, lemmas and stems, to automatically extracted terms.", "labels": [], "entities": []}, {"text": "Also, simple co-occurrences of genes within documents are considered.", "labels": [], "entities": []}, {"text": "The preliminary experiments performed on a set of 3,000 S. cerevisiae gene names and 53,000 Medline abstracts have shown that using domain-specific terms can improve the performance compared to the standard bag-of-words approach, in particular for genes classified with higher confidence, and for under-represented classes.", "labels": [], "entities": []}], "introductionContent": [{"text": "Dynamic development and new discoveries in the domain of biomedicine have resulted in the huge volume of the domain literature, which is constantly expanding both in the size and thematic coverage ().", "labels": [], "entities": []}, {"text": "The literature, which is still the most relevant and the most useful knowledge source, is swamped by newly coined terms and relationships representing and linking newly identified or created compounds, genes, drugs, reactions, etc., which makes the existing terminological resources rarely up-to-date.", "labels": [], "entities": []}, {"text": "Therefore, domain knowledge sources need to frequently adapt to the advent of such terms by assorting them into appropriate classes, in order to allow biologists to rapidly acquire, analyse and visualise entities or group of entities ().", "labels": [], "entities": []}, {"text": "Naming conventions solely cannot be used as reliable classification criteria, since they typically do not systematically reflect any particular functional property or relatedness between biological entities.", "labels": [], "entities": []}, {"text": "On the other hand, it has proved surprisingly difficult to automatically predict classes for some types of biological entities based solely on experimental data (e.g. the prediction of protein cellular locations from sequences ( or the amino acid composition of proteins ().", "labels": [], "entities": [{"text": "prediction of protein cellular locations", "start_pos": 171, "end_pos": 211, "type": "TASK", "confidence": 0.809426486492157}]}, {"text": "In order to overcome this problem, several literature-based classification methods have been developed).", "labels": [], "entities": []}, {"text": "Classification methods typically rely on supervised machine learning techniques that examine the wider context in which terms are used.", "labels": [], "entities": [{"text": "Classification", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.9462031126022339}]}, {"text": "For example, used document-based word counts and naive Bayesian classification, maximum entropy modelling and nearest-neighbour classification to assign the GO ontology codes to a set of genes.", "labels": [], "entities": []}, {"text": "Recently, support-vector machines) have been widely used as fast, effective and reliable means for text-based classification, both for document classification and classification of specific named entities ().", "labels": [], "entities": [{"text": "text-based classification", "start_pos": 99, "end_pos": 124, "type": "TASK", "confidence": 0.6561747640371323}, {"text": "document classification", "start_pos": 135, "end_pos": 158, "type": "TASK", "confidence": 0.7908259928226471}, {"text": "classification of specific named entities", "start_pos": 163, "end_pos": 204, "type": "TASK", "confidence": 0.8458974599838257}]}, {"text": "Regardless of the learning approach and target entities (documents or terms), different types of text features have been employed for the classification task.", "labels": [], "entities": []}, {"text": "For example, a bag-of-words approach was used by to classify proteins, while used orthographic features to classify different biological entities.", "labels": [], "entities": []}, {"text": "On the other hand, experimented with morphological, distributional and shallow-syntactic information to discriminate between proteins, genes and RNAs.", "labels": [], "entities": []}, {"text": "In this paper we analyse the impact of different types of features on the performance of an SVMbased classifier.", "labels": [], "entities": []}, {"text": "More precisely, we discuss the multi-class SVM performance with respect to the type of features used, ranging from document identifiers, through words, lemmas and stems, to automatically extracted terms.", "labels": [], "entities": []}, {"text": "The paper is organised as follows.", "labels": [], "entities": []}, {"text": "After presenting the related work on feature selection in Section 2, the methods used for engineering features in our approach are explained in Section 3.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 37, "end_pos": 54, "type": "TASK", "confidence": 0.775949090719223}]}, {"text": "Section 4 discusses the experiments and results.", "labels": [], "entities": []}], "datasetContent": [{"text": "An experimental environment was setup by using the following resources: a) corpus: a set of documents has been obtained by collecting Medline abstracts related to the baker's yeast (S. cerevisiae), resulting in 52,845 abstracts; this set, containing almost 5 million word occurrences, was used as both training and testing corpus.", "labels": [], "entities": []}, {"text": "b) classification entities: a set of 5007 S. cerevisiae gene names has been retrieved from the SGD (Saccharomyces Genome Database) gene registry 1 , which also provided synonyms and aliases of genes; 2975 gene names appearing in the corpus have been used for the classification task.", "labels": [], "entities": [{"text": "SGD (Saccharomyces Genome Database) gene registry 1", "start_pos": 95, "end_pos": 146, "type": "DATASET", "confidence": 0.7976049184799194}]}, {"text": "c) classification scheme: each gene name has been classified according to a classification scheme based on eleven categories (see) of the up-per part of the GO ontology () . d) training and testing sets: positive examples for each class were split evenly between the training and testing sets, and, also, the number of negative examples in the training set was set equal to the number of positive examples within each class.", "labels": [], "entities": []}, {"text": "The only exception was the metabolism class, which had far more positive than negatives examples.", "labels": [], "entities": []}, {"text": "Therefore, in this case, we have evenly split negative examples between the training and testing sets.", "labels": [], "entities": []}, {"text": "The January 2003 release of the GO ontology was used.", "labels": [], "entities": [{"text": "GO ontology", "start_pos": 32, "end_pos": 43, "type": "DATASET", "confidence": 0.8362475335597992}]}, {"text": "A similar classification scheme was used in ().", "labels": [], "entities": []}, {"text": "Features have been generated according to the methods explained in Section 3 ( shows the number of features generated).", "labels": [], "entities": []}, {"text": "As indicated earlier, the experiments have been performed by using either all features or by selecting only those that appeared in at least two documents.", "labels": [], "entities": []}, {"text": "As a rule, there were no significant differences in the classification performance between the two.", "labels": [], "entities": []}, {"text": "To evaluate the classification performance we have firstly generated precision/recall plots for each class.", "labels": [], "entities": [{"text": "precision", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.9987239241600037}, {"text": "recall", "start_pos": 79, "end_pos": 85, "type": "METRIC", "confidence": 0.8629024624824524}]}, {"text": "In the majority of classes, terms have demonstrated the best performance (cf..", "labels": [], "entities": []}, {"text": "However, the results have shown a wide disparity in performance across the classes, depending on the size of the training set.", "labels": [], "entities": []}, {"text": "The classes with fairly large number of training entities (e.g. metabolism) have been predicted quite accurately (regardless of the features used), while, on the other hand, under-represented classes (e.g. sporulation) performed quite modestly (cf.)..", "labels": [], "entities": []}, {"text": "Precision/recall plots for some classes using words and terms Comparison between performances on different classes is difficult if the classes contain fairly different ratios of positive/negative examples in the testing sets, as it was the casein our experiments (see, column testing 1).", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9050653576850891}, {"text": "recall", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.859180748462677}]}, {"text": "Therefore, we reevaluated the results by selecting -for each classthe same number of positive and negative examples (see, column testing 2), so that we could compare relative performance across classes.", "labels": [], "entities": []}, {"text": "The results shown in actually indicate which classes are \"easier\" to learn (only the performance of single-words and terms are presented).", "labels": [], "entities": []}, {"text": "To assess the global performance of classification methods, we employed micro-averaging of the precision/recall data presented in.", "labels": [], "entities": [{"text": "precision", "start_pos": 95, "end_pos": 104, "type": "METRIC", "confidence": 0.9990056157112122}, {"text": "recall", "start_pos": 105, "end_pos": 111, "type": "METRIC", "confidence": 0.8943438529968262}]}, {"text": "In micro-averaging, the precision and recall are averaged over the number of entities that are classified (giving, thus, an equal weight to the performance on each gene).", "labels": [], "entities": [{"text": "precision", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.9996471405029297}, {"text": "recall", "start_pos": 38, "end_pos": 44, "type": "METRIC", "confidence": 0.9994168281555176}]}, {"text": "In other words, microaverage shows the performance of the classification system on a gene selected randomly from the testing set.", "labels": [], "entities": []}, {"text": "The comparison of micro-averaging results for words, lemmas and stems has shown that there was no significant difference among them.", "labels": [], "entities": []}, {"text": "This outcome matches the results previously reported for the document classification task (), which means that there is no need to pre-process documents.", "labels": [], "entities": [{"text": "document classification task", "start_pos": 61, "end_pos": 89, "type": "TASK", "confidence": 0.852986752986908}]}, {"text": "shows the comparison of microaveraging plots for terms and lemmas.", "labels": [], "entities": []}, {"text": "Terms perform generally much better at lower recall points, while there is just marginal difference between the two at the higher recall points.", "labels": [], "entities": [{"text": "recall", "start_pos": 45, "end_pos": 51, "type": "METRIC", "confidence": 0.9984110593795776}, {"text": "recall", "start_pos": 130, "end_pos": 136, "type": "METRIC", "confidence": 0.9961202144622803}]}, {"text": "Very high precision points at lower recall mean that terms maybe useful classification features for precise predictions for genes classified with the highest confidence.", "labels": [], "entities": [{"text": "recall", "start_pos": 36, "end_pos": 42, "type": "METRIC", "confidence": 0.9992786049842834}]}, {"text": "The results obtained by combining terms and words have not shown any improvements over using only terms as classification features.", "labels": [], "entities": []}, {"text": "We believe that adding more features has introduced additional noise that derogated the overall performance of terms.", "labels": [], "entities": []}, {"text": "Finally, presents the comparison of classification results using terms and abstract identifiers.", "labels": [], "entities": []}, {"text": "Although PMIDs outperformed terms, we reiterate that -while other features allow learning more general properties that can be applied on other corpora -PMIDs can be only used to classify new terms that appear in a closed training/testing corpus..", "labels": [], "entities": []}, {"text": "Micro-averaging plot for 11 classes using PMIDs and terms", "labels": [], "entities": [{"text": "PMIDs", "start_pos": 42, "end_pos": 47, "type": "METRIC", "confidence": 0.9660738110542297}]}], "tableCaptions": [{"text": " Table 1. Classification categories and the number  of examples in the training and the testing sets", "labels": [], "entities": []}]}