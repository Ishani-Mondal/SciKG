{"title": [{"text": "HITIQA: An Interactive Question Answering System A Preliminary Report", "labels": [], "entities": [{"text": "Question Answering", "start_pos": 23, "end_pos": 41, "type": "TASK", "confidence": 0.6903740018606186}]}], "abstractContent": [{"text": "HITIQA is an interactive question answering technology designed to allow intelligence analysts and other users of information systems to pose questions in natural language and obtain relevant answers, or the assistance they require in order to perform their tasks.", "labels": [], "entities": [{"text": "HITIQA", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8605073094367981}, {"text": "question answering", "start_pos": 25, "end_pos": 43, "type": "TASK", "confidence": 0.7246772646903992}]}, {"text": "Our objective in HITIQA is to allow the user to submit exploratory, analytical, non-factual questions, such as \"What has been Russia's reaction to U.S. bombing of Kosovo?\"", "labels": [], "entities": []}, {"text": "The distinguishing property of such questions is that one cannot generally anticipate what might constitute the answer.", "labels": [], "entities": []}, {"text": "While certain types of things maybe expected (e.g., diplomatic statements), the answer is heavily conditioned by what information is in fact available on the topic.", "labels": [], "entities": []}, {"text": "From a practical viewpoint, analytical questions are often under-specified, thus casting abroad net on a space of possible answers.", "labels": [], "entities": []}, {"text": "Therefore, clarification dialogue is often needed to negotiate with the user the exact scope and intent of the question.", "labels": [], "entities": []}], "introductionContent": [{"text": "HITIQA project is part of the ARDA AQUAINT program that aims to make significant advances in the state of the art of automated question answering.", "labels": [], "entities": [{"text": "HITIQA", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8066749572753906}, {"text": "question answering", "start_pos": 127, "end_pos": 145, "type": "TASK", "confidence": 0.7970460653305054}]}, {"text": "In this paper we focus on two aspects of our work: 1.", "labels": [], "entities": []}, {"text": "Question Semantics: how the system \"understands\" user requests.", "labels": [], "entities": []}, {"text": "2. Human-Computer Dialogue: how the user and the system negotiate this understanding.", "labels": [], "entities": []}, {"text": "We will also discuss very preliminary evaluation results from a series of pilot tests of the system conducted by intelligence analysts via a remote internet link.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have just completed the first round of a pilot evaluation for testing the interactive dialogue component of HITIQA.", "labels": [], "entities": [{"text": "HITIQA", "start_pos": 111, "end_pos": 117, "type": "DATASET", "confidence": 0.8373447060585022}]}, {"text": "The purpose of this first stage of evaluation is to determine what kind of dialogue is acceptable/tolerable to the user and whether an efficient navigation though the answer space is possible.", "labels": [], "entities": []}, {"text": "HITIQA was blindly tested by two different analysts on eleven different topics.", "labels": [], "entities": [{"text": "HITIQA", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.7896599173545837}]}, {"text": "Five different groups participated, but no analyst tested more than one system, as system comparison was not a goal.", "labels": [], "entities": [{"text": "system comparison", "start_pos": 83, "end_pos": 100, "type": "TASK", "confidence": 0.7024834156036377}]}, {"text": "The analysts were given complete freedom in forming their queries and responses to HITIQA's questions.", "labels": [], "entities": [{"text": "HITIQA's questions", "start_pos": 83, "end_pos": 101, "type": "DATASET", "confidence": 0.8370291193326315}]}, {"text": "They were only provided with descriptions of the eleven topics the systems would be tested on.", "labels": [], "entities": []}, {"text": "The analysts were given 15 minutes for each topic to arrive at what they believed to bean acceptable answer.", "labels": [], "entities": []}, {"text": "During testing a Wizard (human) was allowed to intervene if HITIQA generated a dialogue question/response that was felt inappropriate.", "labels": [], "entities": []}, {"text": "The Wizard was able to override the system and send a Wizard generated question/response to the analyst.", "labels": [], "entities": []}, {"text": "The HITIQA Wizard intervened an average of 13% of the time.", "labels": [], "entities": [{"text": "HITIQA Wizard", "start_pos": 4, "end_pos": 17, "type": "DATASET", "confidence": 0.6455935537815094}]}, {"text": "These results are for information purposes only as it was not a formal evaluation.", "labels": [], "entities": []}, {"text": "HITIQA earned an average score of 5.8 from both Analysts for dialogue, where 1 was \"extremely dissatisfied\" and 7 was \"completely satisfied\".", "labels": [], "entities": [{"text": "HITIQA", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8210102319717407}]}, {"text": "The highest score possible was a 7 for each dialogue.", "labels": [], "entities": []}, {"text": "The Analysts were asked to grade each scenario for successor failure.", "labels": [], "entities": []}, {"text": "We divide the failures from both analysts into three categories: 1) the user gives upon the system for the given scenario(9%) 2) the 15 minute time limit was up(13%) 3) the data was not in the database(9%) HITIQA had a 63% success rate for Analyst 1 and a 73% success rate for Analyst 2.", "labels": [], "entities": [{"text": "HITIQA", "start_pos": 206, "end_pos": 212, "type": "DATASET", "confidence": 0.669254720211029}]}, {"text": "It is unclear how these results should be interpreted, if at all, as the evaluation was a mere pilot, mostly to test the mechanics of the setup.", "labels": [], "entities": []}, {"text": "We know only that a human Wizard equipped with all necessary information can easily achieve 100% success in this test.", "labels": [], "entities": []}, {"text": "What is still needed is a baseline performance, perhaps based on using an ordinary keyword-based search engine.", "labels": [], "entities": []}], "tableCaptions": []}