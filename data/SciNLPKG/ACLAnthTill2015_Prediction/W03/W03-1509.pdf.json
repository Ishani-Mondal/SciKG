{"title": [{"text": "Chinese Named Entity Recognition Combining a Statistical Model with Human Knowledge", "labels": [], "entities": [{"text": "Chinese Named Entity Recognition", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.6616774499416351}]}], "abstractContent": [{"text": "Named Entity Recognition is one of the key techniques in the fields of natural language processing, information retrieval, question answering and soon.", "labels": [], "entities": [{"text": "Named Entity Recognition", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7218161424001058}, {"text": "natural language processing", "start_pos": 71, "end_pos": 98, "type": "TASK", "confidence": 0.6539278030395508}, {"text": "information retrieval", "start_pos": 100, "end_pos": 121, "type": "TASK", "confidence": 0.8235583901405334}, {"text": "question answering", "start_pos": 123, "end_pos": 141, "type": "TASK", "confidence": 0.9188331961631775}]}, {"text": "Unfortunately, Chinese Named Entity Recognition (NER) is more difficult for the lack of capitalization information and the uncertainty in word segmentation.", "labels": [], "entities": [{"text": "Chinese Named Entity Recognition (NER)", "start_pos": 15, "end_pos": 53, "type": "TASK", "confidence": 0.7141242495604924}, {"text": "word segmentation", "start_pos": 138, "end_pos": 155, "type": "TASK", "confidence": 0.6990694850683212}]}, {"text": "In this paper, we present a hybrid algorithm which can combine a class-based statistical model with various types of human knowledge very well.", "labels": [], "entities": []}, {"text": "In order to avoid data sparseness problem, we employ a back-off model and\u00a1 \u00b6 \u00cd \u00ac \u00d2 \u00e5 \u00b4 \u00ca \u00b4 \u00ca \u00c1 \u00d6 /TONG YI CI CI LIN \u00a1 \u00b7 , a Chinese thesaurus, to smooth the parameters in the model.", "labels": [], "entities": [{"text": "\u00cd \u00ac \u00d2 \u00e5 \u00b4 \u00ca \u00b4 \u00ca \u00c1 \u00d6 /TONG YI CI CI LIN", "start_pos": 77, "end_pos": 115, "type": "METRIC", "confidence": 0.8463985808193684}]}, {"text": "The F-measure of person names, location names, and organization names on the newswire test data for the 1999 IEER evaluation in Mandarin is 86.84%, 84.40% and 76.22% respectively.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9988314509391785}, {"text": "newswire test data for the 1999 IEER evaluation", "start_pos": 77, "end_pos": 124, "type": "DATASET", "confidence": 0.6900081299245358}]}], "introductionContent": [{"text": "The NER task was first introduced as Message Understanding Conference (MUC) subtask in 1995 (MUC-6).", "labels": [], "entities": [{"text": "NER task", "start_pos": 4, "end_pos": 12, "type": "TASK", "confidence": 0.9189018309116364}, {"text": "Message Understanding Conference (MUC) subtask in 1995 (MUC-6)", "start_pos": 37, "end_pos": 99, "type": "TASK", "confidence": 0.7516437595089277}]}, {"text": "Named Entities were defined as entity names (organizations, persons and locations), temporal expressions (dates and times) and number expressions (monetary values and percentages).", "labels": [], "entities": []}, {"text": "Compared with the entity name recognition, the recognition of temporal and number expressions is simpler.", "labels": [], "entities": [{"text": "entity name recognition", "start_pos": 18, "end_pos": 41, "type": "TASK", "confidence": 0.6655299862225851}]}, {"text": "So, our research focuses on the recognition of person, location and organization names.", "labels": [], "entities": [{"text": "recognition of person, location and organization names", "start_pos": 32, "end_pos": 86, "type": "TASK", "confidence": 0.8455894663929939}]}, {"text": "The Multilingual NE task first started in 1995(MET-1), including Chinese, Japanese, and Spanish in that year, and continued for Chinese, Japanese in 1998(MET-2).", "labels": [], "entities": [{"text": "Multilingual NE task", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.7509743571281433}]}, {"text": "Compared with English NER, Chinese NER is more difficult.", "labels": [], "entities": [{"text": "Chinese NER", "start_pos": 27, "end_pos": 38, "type": "TASK", "confidence": 0.5080533027648926}]}, {"text": "We think the main differences between Chinese NER and English NER lie in: First, unlike English, Chinese lacks the capitalization information that plays an important role in signaling named entities.", "labels": [], "entities": []}, {"text": "Second, there is no space between words in Chinese, and we have to segment the text before NER.", "labels": [], "entities": [{"text": "NER", "start_pos": 91, "end_pos": 94, "type": "DATASET", "confidence": 0.685154914855957}]}, {"text": "However, the errors in word segmentation will affect the result of NER.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.7083294540643692}, {"text": "NER", "start_pos": 67, "end_pos": 70, "type": "TASK", "confidence": 0.8318663835525513}]}, {"text": "Third, Different types of named entities have different structures, especially for abbreviative entities.", "labels": [], "entities": []}, {"text": "Therefore, a single unified model can't capture all the types of entities.", "labels": [], "entities": []}, {"text": "Here <>* means repeating one or several times.", "labels": [], "entities": []}, {"text": "{}* means selecting at least one of items.", "labels": [], "entities": []}, {"text": "Fourth, there are few openly available resources for Chinese NER.", "labels": [], "entities": [{"text": "Chinese NER", "start_pos": 53, "end_pos": 64, "type": "TASK", "confidence": 0.5516423285007477}]}, {"text": "Thus we have to resort to the algorithm that doesn't rely on large NER-tagged text corpus.", "labels": [], "entities": []}, {"text": "Based on the above analysis, we present a hybrid algorithm that incorporating various types of human knowledge into a statistical model.", "labels": [], "entities": []}, {"text": "The innovative points of our paper are as follows.", "labels": [], "entities": []}, {"text": "First, the hybrid algorithm can make the best use of existing limited resources to develop an effective NER system.", "labels": [], "entities": []}, {"text": "These resources include one-month's Chinese People's Daily tagged with NER tags by Peking University (which contains about two-million Chinese characters) and various types of human knowledge.", "labels": [], "entities": [{"text": "Chinese People's Daily tagged with NER tags", "start_pos": 36, "end_pos": 79, "type": "DATASET", "confidence": 0.8773849010467529}]}, {"text": "Second, in order to compensate for the lack of labeled corpus, we use several types of human knowledge, such as\u00a1 \u00b6 \u00cd \u00ac \u00d2 \u00e5 \u00b4 \u00ca \u00b4 \u00ca \u00c1 \u00d6 /TONG YI CI CI LIN\u00a1 \u00b7, a general location names list, the list of the salient words in location name, the list of the salient words in organization names, a Chinese surnames list, the list of Chinese characters that could be included in transliterated person names, and soon.", "labels": [], "entities": [{"text": "\u00cd \u00ac \u00d2 \u00e5 \u00b4 \u00ca \u00b4 \u00ca \u00c1 \u00d6 /TONG YI CI CI LIN", "start_pos": 115, "end_pos": 153, "type": "METRIC", "confidence": 0.734697911888361}]}, {"text": "Third, we emphasize that human knowledge and statistical information should be combined very well.", "labels": [], "entities": []}, {"text": "For example, a general LN list and a general famous ON list are used in our system.", "labels": [], "entities": []}, {"text": "However, we only accept words in the lists as entity candidates with a probability.", "labels": [], "entities": []}, {"text": "Whether it is a LN or ON depends on the context.", "labels": [], "entities": [{"text": "ON", "start_pos": 22, "end_pos": 24, "type": "METRIC", "confidence": 0.9710540771484375}]}, {"text": "This is different from other systems which accept them as a LN or ON once the system meets them.", "labels": [], "entities": []}, {"text": "More details refer to section 4.", "labels": [], "entities": []}, {"text": "This paper will be organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 is the background of NER.", "labels": [], "entities": [{"text": "NER", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.6209259033203125}]}, {"text": "Section 3 describes the class-based statistical baseline Chinese NER model.", "labels": [], "entities": [{"text": "NER", "start_pos": 65, "end_pos": 68, "type": "TASK", "confidence": 0.9134502410888672}]}, {"text": "Section 4 describes different types of human knowledge for different named entities recognitions and how to combine them with a statistical model organically in details.", "labels": [], "entities": []}, {"text": "Section 5 is the evaluation and section 6 is the conclusion.", "labels": [], "entities": []}], "datasetContent": [{"text": "The baseline model was evaluated in terms of precision (P), recall (R) and F-measure (F) metrics.", "labels": [], "entities": [{"text": "precision (P)", "start_pos": 45, "end_pos": 58, "type": "METRIC", "confidence": 0.9413395673036575}, {"text": "recall (R)", "start_pos": 60, "end_pos": 70, "type": "METRIC", "confidence": 0.9530965685844421}, {"text": "F-measure (F) metrics", "start_pos": 75, "end_pos": 96, "type": "METRIC", "confidence": 0.95325927734375}]}, {"text": "The Performance of The Baseline  We also test our hybrid model on IEER-99 neswire test data.", "labels": [], "entities": [{"text": "IEER-99 neswire test data", "start_pos": 66, "end_pos": 91, "type": "DATASET", "confidence": 0.9299495220184326}]}, {"text": "The performance is shown in.", "labels": [], "entities": []}, {"text": "The Performance of the Hybrid Model", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2 The Performance of The Baseline", "labels": [], "entities": []}, {"text": " Table 4 The Performance of the Hybrid Model", "labels": [], "entities": []}, {"text": " Table 4 Statistic of Multi-field Test Data", "labels": [], "entities": []}, {"text": " Table 5 Results on different domain", "labels": [], "entities": []}]}