{"title": [{"text": "A Maximum Entropy Chinese Character-Based Parser", "labels": [], "entities": []}], "abstractContent": [{"text": "The paper presents a maximum entropy Chinese character-based parser trained on the Chinese Treebank (\"CTB\" henceforth).", "labels": [], "entities": [{"text": "Chinese Treebank (\"CTB\"", "start_pos": 83, "end_pos": 106, "type": "DATASET", "confidence": 0.9408298254013061}]}, {"text": "Word-based parse trees in CTB are first converted into character-based trees, where word-level part-of-speech (POS) tags become constituent labels and character-level tags are derived from word-level POS tags.", "labels": [], "entities": []}, {"text": "A maximum entropy parser is then trained on the character-based corpus.", "labels": [], "entities": []}, {"text": "The parser does word-segmentation, POS-tagging and parsing in a unified framework.", "labels": [], "entities": []}, {"text": "An average label F-measure \u00a2 \u00a1 \u00a4 \u00a3 \u00a6 \u00a5 \u00a8 \u00a7 and word-segmentation F-measure \u00a9 \u00a3 \u00a7 are achieved by the parser.", "labels": [], "entities": []}, {"text": "Our results show that word-level POS tags can improve significantly word-segmentation, but higher-level syntactic strutures are of little use to word segmentation in the maximum entropy parser.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 145, "end_pos": 162, "type": "TASK", "confidence": 0.7065907716751099}]}, {"text": "A word-dictionary helps to improve both word-segmentation and parsing accuracy.", "labels": [], "entities": [{"text": "parsing", "start_pos": 62, "end_pos": 69, "type": "TASK", "confidence": 0.9466086030006409}, {"text": "accuracy", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.8536709547042847}]}], "introductionContent": [], "datasetContent": [{"text": "All experiments reported here are conducted on the latest LDC release of the Chinese Treebank, which consists of about l \u00a3 words.", "labels": [], "entities": [{"text": "LDC release of the Chinese Treebank", "start_pos": 58, "end_pos": 93, "type": "DATASET", "confidence": 0.9037238657474518}]}, {"text": "Word parse trees are converted to character trees using the procedure described in Section 2.", "labels": [], "entities": [{"text": "Word parse trees", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7270618577798208}]}, {"text": "All traces and functional tags are stripped in training and testing.", "labels": [], "entities": []}, {"text": "Two results are reported for the character-based parsers: the F-measure of word segmentation and F-measure of constituent labels.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9759669899940491}, {"text": "word segmentation", "start_pos": 75, "end_pos": 92, "type": "TASK", "confidence": 0.6489572077989578}, {"text": "F-measure", "start_pos": 97, "end_pos": 106, "type": "METRIC", "confidence": 0.9535437822341919}]}, {"text": "Formally, let be the number of words of the \u0099 rt reference sentence and its parser output, respectively, and\u00a8\u00a9 be the number of common words in the \u0099 gr t sentence of test set, then the word segmentation F-measure is The F-measure of constituent labels is computed similarly: is the number of common constituents.", "labels": [], "entities": [{"text": "\u00a8\u00a9", "start_pos": 108, "end_pos": 110, "type": "METRIC", "confidence": 0.9744937419891357}, {"text": "word segmentation F-measure", "start_pos": 186, "end_pos": 213, "type": "TASK", "confidence": 0.6359745462735494}]}, {"text": "Chunk-level labels converted from POS tags (e.g., \"NR\", \"NN\" and \"VV\" etc in (1)) are included in computing label F-measures for character-based parsers.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 5. Intuitively, these questions  would help the model to identify word boundaries,  which in turn ought to improve the parser. This is  confirmed by results shown in", "labels": [], "entities": []}]}