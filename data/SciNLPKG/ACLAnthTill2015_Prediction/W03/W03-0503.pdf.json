{"title": [{"text": "Multi-document summarization using off the shelf compression software", "labels": [], "entities": [{"text": "Multi-document summarization", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8219718337059021}]}], "abstractContent": [{"text": "This study examines the usefulness of common off the shelf compression software such as gzip in enhancing already existing summaries and producing summaries from scratch.", "labels": [], "entities": []}, {"text": "Since the gzip algorithm works by removing repetitive data from a file in order to compress it, we should be able to determine which sentences in a summary contain the least repetitive data by judging the gzipped size of the summary with the sentence compared to the gzipped size of the summary without the sentence.", "labels": [], "entities": []}, {"text": "By picking the sentence that increased the size of the summary the most, we hypothesized that the summary will gain the sentence with the most new information.", "labels": [], "entities": []}, {"text": "This hypothesis was found to be true in many cases and to varying degrees in this study.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "To test the benefit of gzip in the summarization process, extracts were created using a combination of MEAD and gzip.", "labels": [], "entities": [{"text": "summarization", "start_pos": 35, "end_pos": 48, "type": "TASK", "confidence": 0.985887348651886}, {"text": "MEAD", "start_pos": 103, "end_pos": 107, "type": "METRIC", "confidence": 0.940593421459198}]}, {"text": "These extracts contained pointers to the actual sentences that would be included in the summary, but not the sentences themselves.", "labels": [], "entities": []}, {"text": "extracts, the number of sentences contributed by MEAD was incremented by ten starting at zero and the number of sentences contributed by gzip was incremented from one to ten, on top of the MEAD sentences.", "labels": [], "entities": [{"text": "MEAD", "start_pos": 49, "end_pos": 53, "type": "DATASET", "confidence": 0.8614426851272583}, {"text": "MEAD sentences", "start_pos": 189, "end_pos": 203, "type": "DATASET", "confidence": 0.9224536418914795}]}, {"text": "So for any randomly chosens extract of siz\u00eb , \u00a7\u00a8\u00a9 \u00a7\u00a8\u00a9 \u00a7 3 2 5 4 7 6 8 9 A @ CB indicates the number of sentence contributed by gzip.", "labels": [], "entities": [{"text": "CB", "start_pos": 76, "end_pos": 78, "type": "METRIC", "confidence": 0.5305814146995544}]}, {"text": "So an extract of fifty-six sentences contains fifty sentences from MEAD and six from gzip.", "labels": [], "entities": [{"text": "MEAD", "start_pos": 67, "end_pos": 71, "type": "DATASET", "confidence": 0.5795137882232666}]}, {"text": "In this way, a total of 110 extracts were created for all clusters except Cluster 323, for which only 80 extracts were created because there were only 91 sentences total in that cluster.", "labels": [], "entities": []}, {"text": "For clarification, the 110 sentence extract for each cluster contained 100 MEAD sentences and 10 sentences from the chosen gzip policy.", "labels": [], "entities": [{"text": "MEAD", "start_pos": 75, "end_pos": 79, "type": "METRIC", "confidence": 0.9028024077415466}]}, {"text": "The 10 sentence extract for each cluster contained 0 MEAD sentences and 10 sentences from the chosen gzip policy.", "labels": [], "entities": [{"text": "MEAD", "start_pos": 53, "end_pos": 57, "type": "METRIC", "confidence": 0.9645865559577942}]}, {"text": "In order to have a benchmark to compare the gzip modified extracts to, extracts containing an identical number of sentences were created using only MEAD, so a 110 MEAD extract has all of its sentences chosen by MEAD.", "labels": [], "entities": [{"text": "MEAD", "start_pos": 148, "end_pos": 152, "type": "METRIC", "confidence": 0.6758601069450378}, {"text": "MEAD", "start_pos": 211, "end_pos": 215, "type": "DATASET", "confidence": 0.8733589053153992}]}, {"text": "Relative utility was run on all types of gzip extracts, as well as only MEAD extracts.", "labels": [], "entities": [{"text": "MEAD", "start_pos": 72, "end_pos": 76, "type": "METRIC", "confidence": 0.6122896075248718}]}, {"text": "We use the Relative Utility (RU) method () to compare our various summaries.", "labels": [], "entities": [{"text": "Relative Utility (RU)", "start_pos": 11, "end_pos": 32, "type": "TASK", "confidence": 0.5835754871368408}]}, {"text": "To calculate RU, human judges read through all sentences in a document cluster and then give scores, from 1 (totally irrelevant) to 10 (central to the topic) to each sentence based on their impression of the importance of each sentence fora summary of the documents.", "labels": [], "entities": [{"text": "RU", "start_pos": 13, "end_pos": 15, "type": "METRIC", "confidence": 0.9120778441429138}]}, {"text": "Each judge's score is then normalized by his or her other scores.", "labels": [], "entities": []}, {"text": "Finally, for each sentence, the judges' scores are summed and normalized again by the number of judges.", "labels": [], "entities": []}, {"text": "Then a final score is given fora summary by summing the utility score for each sentence which was in the summary and then factoring in the  upper bound (highest utility scores given by the judges) and lower bound (utility scores from randomly chosen sentences).", "labels": [], "entities": []}, {"text": "We use this method because, as) find, Precision, Recall, and Kappa measures as well as content-based evaluation methods are unreliable for short summaries (5%-30%) and especially in the task of multi-document summarization, where there are likely to be several sentences which would contribute the same information to a summary.", "labels": [], "entities": [{"text": "find", "start_pos": 32, "end_pos": 36, "type": "METRIC", "confidence": 0.9508123993873596}, {"text": "Precision", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9801099300384521}, {"text": "Recall", "start_pos": 49, "end_pos": 55, "type": "METRIC", "confidence": 0.8471766114234924}, {"text": "Kappa", "start_pos": 61, "end_pos": 66, "type": "METRIC", "confidence": 0.9471449255943298}, {"text": "multi-document summarization", "start_pos": 194, "end_pos": 222, "type": "TASK", "confidence": 0.6197383105754852}]}], "tableCaptions": []}