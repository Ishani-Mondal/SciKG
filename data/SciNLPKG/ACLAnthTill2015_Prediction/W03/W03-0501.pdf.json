{"title": [{"text": "Hedge Trimmer: A Parse-and-Trim Approach to Headline Generation", "labels": [], "entities": [{"text": "Hedge Trimmer", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.6953019797801971}, {"text": "Headline Generation", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.7000681757926941}]}], "abstractContent": [{"text": "This paper presents Hedge Trimmer, a HEaDline GEneration system that creates a headline fora newspaper story using linguistically-motivated heuristics to guide the choice of a potential headline.", "labels": [], "entities": [{"text": "Hedge Trimmer", "start_pos": 20, "end_pos": 33, "type": "TASK", "confidence": 0.5763800144195557}]}, {"text": "We present feasibility tests used to establish the validity of an approach that constructs a headline by selecting words in order from a story.", "labels": [], "entities": []}, {"text": "In addition, we describe experimental results that demonstrate the effectiveness of our linguistically motivated approach over a HMM-based model, using both human evaluation and automatic met-rics for comparing the two approaches.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this paper we present Hedge Trimmer, a HEaDline GEneration system that creates a headline fora newspaper story by removing constituents from a parse tree of the first sentence until a length threshold has been reached.", "labels": [], "entities": [{"text": "Hedge Trimmer", "start_pos": 25, "end_pos": 38, "type": "DATASET", "confidence": 0.6617579162120819}]}, {"text": "Linguistically-motivated heuristics guide the choice of which constituents of a story should be preserved, and which ones should be deleted.", "labels": [], "entities": []}, {"text": "Our focus is on headline generation for English newspaper texts, with an eye toward the production of document surrogates-for cross-language information retrieval-and the eventual generation of readable headlines from speech broadcasts.", "labels": [], "entities": [{"text": "headline generation", "start_pos": 16, "end_pos": 35, "type": "TASK", "confidence": 0.8159548342227936}, {"text": "cross-language information retrieval-and", "start_pos": 126, "end_pos": 166, "type": "TASK", "confidence": 0.6500989298025767}, {"text": "generation of readable headlines from speech broadcasts", "start_pos": 180, "end_pos": 235, "type": "TASK", "confidence": 0.6676712845052991}]}, {"text": "In contrast to original newspaper headlines, which are often intended only to catch the eye, our approach produces informative abstracts describing the main theme or event of the newspaper article.", "labels": [], "entities": []}, {"text": "We claim that the construction of informative abstracts requires access to deeper linguistic knowledge, in order to make substantial improvements over purely statistical approaches.", "labels": [], "entities": []}, {"text": "In this paper, we present our technique for producing headlines using a parse-and-trim approach based on the BBN Parser.", "labels": [], "entities": [{"text": "BBN Parser", "start_pos": 109, "end_pos": 119, "type": "DATASET", "confidence": 0.9719308018684387}]}, {"text": "As described in, the BBN parser builds augmented parse trees according to a process similar to that described in.", "labels": [], "entities": []}, {"text": "The BBN parser has been used successfully for the task of information extraction in the SIFT system ().", "labels": [], "entities": [{"text": "BBN", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.623680055141449}, {"text": "information extraction", "start_pos": 58, "end_pos": 80, "type": "TASK", "confidence": 0.8078504800796509}]}, {"text": "The next section presents previous work in the area of automatic generation of abstracts.", "labels": [], "entities": [{"text": "automatic generation of abstracts", "start_pos": 55, "end_pos": 88, "type": "TASK", "confidence": 0.8179992064833641}]}, {"text": "Following this, we present feasibility tests used to establish the validity of an approach that constructs headlines from words in a story, taken in order and focusing on the earlier part of the story.", "labels": [], "entities": []}, {"text": "Next, we describe the application of the parse-and-trim approach to the problem of headline generation.", "labels": [], "entities": [{"text": "headline generation", "start_pos": 83, "end_pos": 102, "type": "TASK", "confidence": 0.896237850189209}]}, {"text": "We discuss the linguistically-motivated heuristics we use to produce results that are headlinelike.", "labels": [], "entities": []}, {"text": "Finally, we evaluate Hedge Trimmer by comparing it to our earlier work on headline generation, a probabilistic model for automatic headline generation ().", "labels": [], "entities": [{"text": "Hedge Trimmer", "start_pos": 21, "end_pos": 34, "type": "TASK", "confidence": 0.5447443425655365}, {"text": "headline generation", "start_pos": 74, "end_pos": 93, "type": "TASK", "confidence": 0.8491979837417603}, {"text": "headline generation", "start_pos": 131, "end_pos": 150, "type": "TASK", "confidence": 0.8156462609767914}]}, {"text": "In this paper we will refer to this statistical system as HMM Hedge We demonstrate the effectiveness of our linguistically-motivated approach, Hedge Trimmer, over the probabilistic model, HMM Hedge, using both human evaluation and automatic metrics.", "labels": [], "entities": []}], "datasetContent": [{"text": "One was an informal human assessment and one was a formal automatic evaluation.", "labels": [], "entities": []}, {"text": "BLEU () is a system for automatic evaluation of machine translation.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9771338105201721}, {"text": "machine translation", "start_pos": 48, "end_pos": 67, "type": "TASK", "confidence": 0.7525916397571564}]}, {"text": "BLEU uses a modified n-gram precision measure to compare machine translations to reference human translations.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.945670485496521}, {"text": "precision measure", "start_pos": 28, "end_pos": 45, "type": "METRIC", "confidence": 0.9314260184764862}]}, {"text": "We treat summarization as a type of translation from a verbose language to a concise one, and compare automatically generated headlines to human generated headlines.", "labels": [], "entities": [{"text": "summarization", "start_pos": 9, "end_pos": 22, "type": "TASK", "confidence": 0.988650918006897}]}, {"text": "For this evaluation we used 100 headlines created for 100 AP stories from the TIPSTER collection for August 6, 1990 as reference summarizations for those stories.", "labels": [], "entities": [{"text": "AP stories from the TIPSTER collection for August 6, 1990", "start_pos": 58, "end_pos": 115, "type": "DATASET", "confidence": 0.8739851496436379}]}, {"text": "These 100 stories had never been run through either system or evaluated by the authors prior to this evaluation.", "labels": [], "entities": []}, {"text": "We also used the 2496 manual abstracts for the DUC2003 10-word summarization task as reference translations for the 624 test documents of that task.", "labels": [], "entities": [{"text": "DUC2003 10-word summarization task", "start_pos": 47, "end_pos": 81, "type": "TASK", "confidence": 0.7294184267520905}]}, {"text": "We used two variants of HMM Hedge, one which selects headline words from the first 60 words of the story, and one which selects words from the first sentence of the story.", "labels": [], "entities": [{"text": "HMM Hedge", "start_pos": 24, "end_pos": 33, "type": "DATASET", "confidence": 0.8598843216896057}]}, {"text": "shows the BLEU score using trigrams, and the 95% confidence interval for the score.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9988433122634888}, {"text": "confidence interval", "start_pos": 49, "end_pos": 68, "type": "METRIC", "confidence": 0.9049792289733887}]}, {"text": "0.1341 \u00b1 0.0181 avg len: 8.50 These results show that although Hedge Trimmer scores slightly higher than HMM Hedge on both data sets, the results are not statistically significant.", "labels": [], "entities": [{"text": "HMM Hedge", "start_pos": 105, "end_pos": 114, "type": "DATASET", "confidence": 0.8590031862258911}]}, {"text": "However, we believe that the difference in the quality of the systems is not adequately reflected by this automatic evaluation.", "labels": [], "entities": []}, {"text": "Human evaluation indicates significantly higher scores than might be guessed from the automatic evaluation.", "labels": [], "entities": []}, {"text": "For the 100 AP stories from the TIPSTER corpus for August 6, 1990, the output of Hedge Trimmer and HMM Hedge was evaluated by one human.", "labels": [], "entities": [{"text": "TIPSTER corpus for August 6", "start_pos": 32, "end_pos": 59, "type": "DATASET", "confidence": 0.8948161721229553}, {"text": "HMM Hedge", "start_pos": 99, "end_pos": 108, "type": "DATASET", "confidence": 0.8017574548721313}]}, {"text": "Each headline was given a subjective score from 1 to 5, with 1 being the worst and 5 being the best.", "labels": [], "entities": []}, {"text": "The average score of HMM Hedge was 3.01 with standard deviation of 1.11.", "labels": [], "entities": [{"text": "HMM Hedge", "start_pos": 21, "end_pos": 30, "type": "DATASET", "confidence": 0.8951134383678436}]}, {"text": "The average score of Hedge Trimmer was 3.72 with standard deviation of 1.26.", "labels": [], "entities": [{"text": "Hedge Trimmer", "start_pos": 21, "end_pos": 34, "type": "TASK", "confidence": 0.5850649774074554}]}, {"text": "Using a t-score, the difference is significant with greater than 99.9% confidence.", "labels": [], "entities": [{"text": "difference", "start_pos": 21, "end_pos": 31, "type": "METRIC", "confidence": 0.9644836187362671}]}, {"text": "The types of problems exhibited by the two systems are qualitatively different.", "labels": [], "entities": []}, {"text": "The probabilistic system is more likely to produce an ungrammatical result or omit a necessary argument, as in the examples below.", "labels": [], "entities": []}, {"text": "(15) HMM60: Nearly drowns in satisfactory condition satisfactory condition.", "labels": [], "entities": [{"text": "HMM60", "start_pos": 5, "end_pos": 10, "type": "DATASET", "confidence": 0.9417177438735962}]}, {"text": "(16) HMM60: A county jail inmate who noticed.", "labels": [], "entities": [{"text": "HMM60", "start_pos": 5, "end_pos": 10, "type": "DATASET", "confidence": 0.6900278329849243}]}, {"text": "In contrast, the parser-based system is more likely to fail by producing a grammatical but semantically useless headline.", "labels": [], "entities": []}, {"text": "(17) HedgeTr: It may not be everyone's idea especially coming on heels.", "labels": [], "entities": []}, {"text": "Finally, even when both systems produce acceptable output, Hedge Trimmer usually produces headlines which are more fluent or include more useful information.", "labels": [], "entities": [{"text": "Hedge Trimmer", "start_pos": 59, "end_pos": 72, "type": "TASK", "confidence": 0.6001835763454437}]}], "tableCaptions": [{"text": " Table 1  These results show that although Hedge Trimmer  scores slightly higher than HMM Hedge on both data  sets, the results are not statistically significant. How- ever, we believe that the difference in the quality of the  systems is not adequately reflected by this automatic  evaluation.", "labels": [], "entities": [{"text": "HMM Hedge", "start_pos": 86, "end_pos": 95, "type": "DATASET", "confidence": 0.8308207988739014}]}]}