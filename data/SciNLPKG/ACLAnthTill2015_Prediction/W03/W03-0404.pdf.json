{"title": [{"text": "Learning Subjective Nouns using Extraction Pattern Bootstrapping *", "labels": [], "entities": []}], "abstractContent": [{"text": "We explore the idea of creating a subjectiv-ity classifier that uses lists of subjective nouns learned by bootstrapping algorithms.", "labels": [], "entities": []}, {"text": "The goal of our research is to develop a system that can distinguish subjective sentences from objective sentences.", "labels": [], "entities": []}, {"text": "First, we use two bootstrap-ping algorithms that exploit extraction patterns to learn sets of subjective nouns.", "labels": [], "entities": []}, {"text": "Then we train a Naive Bayes classifier using the subjective nouns, discourse features, and subjectivity clues identified in prior research.", "labels": [], "entities": [{"text": "Naive Bayes classifier", "start_pos": 16, "end_pos": 38, "type": "TASK", "confidence": 0.7045710285504659}]}, {"text": "The boot-strapping algorithms learned over 1000 subjective nouns, and the subjectivity classifier performed well, achieving 77% recall with 81% precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 128, "end_pos": 134, "type": "METRIC", "confidence": 0.9982120990753174}, {"text": "precision", "start_pos": 144, "end_pos": 153, "type": "METRIC", "confidence": 0.9981749057769775}]}], "introductionContent": [{"text": "Many natural language processing applications could benefit from being able to distinguish between factual and subjective information.", "labels": [], "entities": []}, {"text": "Subjective remarks come in a variety of forms, including opinions, rants, allegations, accusations, suspicions, and speculation.", "labels": [], "entities": []}, {"text": "Ideally, information extraction systems should be able to distinguish between factual information (which should be extracted) and non-factual information (which should be discarded or labeled as uncertain).", "labels": [], "entities": [{"text": "information extraction", "start_pos": 9, "end_pos": 31, "type": "TASK", "confidence": 0.739993155002594}]}, {"text": "Question answering systems should distinguish between factual and speculative answers.", "labels": [], "entities": [{"text": "Question answering", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8895097076892853}]}, {"text": "Multi-perspective question answering aims to present multiple answers to the user based upon speculation or opinions derived from different sources.", "labels": [], "entities": [{"text": "Multi-perspective question answering", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.6914861599604288}]}, {"text": "Multi- * This work was supported in part by the National Science Foundation under grants IIS-0208798 and IRI-9704240.", "labels": [], "entities": [{"text": "National Science Foundation", "start_pos": 48, "end_pos": 75, "type": "DATASET", "confidence": 0.9309422572453817}, {"text": "IIS-0208798", "start_pos": 89, "end_pos": 100, "type": "DATASET", "confidence": 0.7892058491706848}, {"text": "IRI-9704240", "start_pos": 105, "end_pos": 116, "type": "DATASET", "confidence": 0.7552341818809509}]}, {"text": "The data preparation was performed in support of the Northeast Regional Reseach Center (NRRC) which is sponsored by the Advanced Research and Development Activity (ARDA), a U.S. Government entity which sponsors and promotes research of import to the Intelligence Community which includes but is not limited to the CIA, DIA, NSA, NIMA, and NRO.", "labels": [], "entities": [{"text": "Northeast Regional Reseach Center (NRRC)", "start_pos": 53, "end_pos": 93, "type": "DATASET", "confidence": 0.7123454553740365}]}, {"text": "document summarization systems need to summarize different opinions and perspectives.", "labels": [], "entities": [{"text": "document summarization", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.6193410307168961}]}, {"text": "Spam filtering systems must recognize rants and emotional tirades, among other things.", "labels": [], "entities": [{"text": "Spam filtering", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.8878866136074066}]}, {"text": "In general, nearly any system that seeks to identify information could benefit from being able to separate factual and subjective information.", "labels": [], "entities": []}, {"text": "Subjective language has been previously studied in fields such as linguistics, literary theory, psychology, and content analysis.", "labels": [], "entities": [{"text": "Subjective language", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8651970028877258}, {"text": "content analysis", "start_pos": 112, "end_pos": 128, "type": "TASK", "confidence": 0.7720475196838379}]}, {"text": "Some manually-developed knowledge resources exist, but there is no comprehensive dictionary of subjective language.", "labels": [], "entities": []}, {"text": "Meta-Bootstrapping () and Basilisk ( are bootstrapping algorithms that use automatically generated extraction patterns to identify words belonging to a semantic category.", "labels": [], "entities": []}, {"text": "We hypothesized that extraction patterns could also identify subjective words.", "labels": [], "entities": []}, {"text": "For example, the pattern \"expressed <direct object>\" often extracts subjective nouns, such as \"concern\", \"hope\", and \"support\".", "labels": [], "entities": []}, {"text": "Furthermore, these bootstrapping algorithms require only a handful of seed words and unannotated texts for training; no annotated data is needed at all.", "labels": [], "entities": []}, {"text": "In this paper, we use the Meta-Bootstrapping and Basilisk algorithms to learn lists of subjective nouns from a large collection of unannotated texts.", "labels": [], "entities": []}, {"text": "Then we train a subjectivity classifier on a small set of annotated data, using the subjective nouns as features along with some other previously identified subjectivity features.", "labels": [], "entities": []}, {"text": "Our experimental results show that the subjectivity classifier performs well (77% recall with 81% precision) and that the learned nouns improve upon previous state-of-the-art subjectivity results ().", "labels": [], "entities": [{"text": "recall", "start_pos": 82, "end_pos": 88, "type": "METRIC", "confidence": 0.9957020878791809}, {"text": "precision", "start_pos": 98, "end_pos": 107, "type": "METRIC", "confidence": 0.9938763976097107}]}], "datasetContent": [{"text": "The Meta-Bootstrapping and Basilisk algorithms need seed words and an unannotated text corpus as input.", "labels": [], "entities": []}, {"text": "Since we did not need annotated texts, we created a much larger training corpus, the bootstrapping corpus, by gathering 950 new texts from the FBIS source mentioned in Section 2.2.", "labels": [], "entities": [{"text": "FBIS source", "start_pos": 143, "end_pos": 154, "type": "DATASET", "confidence": 0.9095574617385864}]}, {"text": "To find candidate seed words, we automatically identified 850 nouns that were positively correlated with subjective sentences in another data set.", "labels": [], "entities": []}, {"text": "However, it is crucial that the seed words occur frequently in our FBIS texts or the bootstrapping process will not get off the ground.", "labels": [], "entities": [{"text": "FBIS texts", "start_pos": 67, "end_pos": 77, "type": "DATASET", "confidence": 0.7400925159454346}]}, {"text": "So we searched for each of the 850 nouns in the bootstrapping corpus, sorted them by frequency, and manually selected 20 high-frequency words that we judged to be strongly subjective.", "labels": [], "entities": []}, {"text": "shows the 20 seed words used for both Meta-Bootstrapping and Basilisk.", "labels": [], "entities": []}, {"text": "We ran each bootstrapping algorithm for 400 iterations, generating 5 words per iteration.", "labels": [], "entities": []}, {"text": "Basilisk generated 2000 nouns and Meta-Bootstrapping generated 1996 nouns.: Extraction Pattern Examples terns that were discovered to be associated with subjective nouns.", "labels": [], "entities": []}, {"text": "Meta-Bootstrapping and Basilisk are semi-automatic lexicon generation tools because, although the bootstrapping process is 100% automatic, the resulting lexicons need to be reviewed by a human.", "labels": [], "entities": []}, {"text": "So we manually reviewed the 3996 words proposed by the algorithms.", "labels": [], "entities": []}, {"text": "This process is very fast; it takes only a few seconds to classify each word.", "labels": [], "entities": []}, {"text": "The entire review process took approximately 3-4 hours.", "labels": [], "entities": []}, {"text": "One author did this labeling; this person did not look at or run tests on the experiment corpus.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 6: Subjective Word Lexicons after Manual Review  (B=Basilisk, M=MetaBootstrapping)", "labels": [], "entities": []}, {"text": " Table 7: Baselines for Comparison", "labels": [], "entities": [{"text": "Comparison", "start_pos": 24, "end_pos": 34, "type": "TASK", "confidence": 0.7817840576171875}]}, {"text": " Table 8: Results with New Features", "labels": [], "entities": []}]}