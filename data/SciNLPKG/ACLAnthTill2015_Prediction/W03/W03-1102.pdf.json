{"title": [{"text": "A Practical Text Summarizer by Paragraph Extraction for Thai", "labels": [], "entities": [{"text": "Practical Text Summarizer", "start_pos": 2, "end_pos": 27, "type": "TASK", "confidence": 0.6171010235945383}, {"text": "Paragraph Extraction", "start_pos": 31, "end_pos": 51, "type": "TASK", "confidence": 0.6718076020479202}]}], "abstractContent": [{"text": "In this paper, we propose a practical approach for extracting the most relevant paragraphs from the original document to form a summary for Thai text.", "labels": [], "entities": []}, {"text": "The idea of our approach is to exploit both the local and global properties of paragraphs.", "labels": [], "entities": []}, {"text": "The local property can be considered as clusters of significant words within each paragraph, while the global property can be though of as relations of all paragraphs in a document.", "labels": [], "entities": []}, {"text": "These two properties are combined for ranking and extracting summaries.", "labels": [], "entities": [{"text": "extracting summaries", "start_pos": 50, "end_pos": 70, "type": "TASK", "confidence": 0.7212027907371521}]}, {"text": "Experimental results on real-world data sets are encouraging.", "labels": [], "entities": []}], "introductionContent": [{"text": "The growth of electronic texts is becoming increasingly common.", "labels": [], "entities": []}, {"text": "Newspapers or magazines tend to be available on the World-Wide Web.", "labels": [], "entities": []}, {"text": "Summarizing these texts can help users access to the information content more quickly.", "labels": [], "entities": []}, {"text": "However, doing this task by humans is costly and time-consuming.", "labels": [], "entities": []}, {"text": "Automatic text summarization is a solution for dealing with this problem.", "labels": [], "entities": [{"text": "Automatic text summarization", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.5880071222782135}]}, {"text": "Automatic text summarization can be broadly classified into two approaches: abstraction and extraction.", "labels": [], "entities": [{"text": "Automatic text summarization", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.6982487837473551}]}, {"text": "In contrast to abstraction that requires using heavy machinery from natural language processing (NLP), including grammars and lexicons for parsing and generation), extraction can be easily viewed as the process of selecting relevant excerpts (sentences, paragraphs, etc.) from the original document and concatenating them into a shorter form.", "labels": [], "entities": [{"text": "parsing and generation", "start_pos": 139, "end_pos": 161, "type": "TASK", "confidence": 0.8029478192329407}]}, {"text": "Thus, most of recent works in this research area are based on extraction ().", "labels": [], "entities": []}, {"text": "Although one may argue that extraction approach makes the text hard to read due to the lack of coherence, it also depends on the objective of summarization.", "labels": [], "entities": []}, {"text": "If we need to generate summaries that can be used to indicative what topics are addressed in the original document, and thus can be used to alert the uses as the source content, i.e., the indicative function ( ), extraction approach is capable of handling this kind of tasks.", "labels": [], "entities": []}, {"text": "There have been many researches on text summarization problem.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 35, "end_pos": 53, "type": "TASK", "confidence": 0.8079399764537811}]}, {"text": "However, in Thai, we are in the initial stage of developing mechanisms for automatically summarizing documents.", "labels": [], "entities": [{"text": "summarizing documents", "start_pos": 89, "end_pos": 110, "type": "TASK", "confidence": 0.8543536067008972}]}, {"text": "It is a challenge to summarize these documents, since they are extremely different from documents written in English.", "labels": [], "entities": [{"text": "summarize", "start_pos": 21, "end_pos": 30, "type": "TASK", "confidence": 0.9855700135231018}]}, {"text": "Similar to Chinese or Japanese, for the Thai writing system, there are no boundaries between adjoining words, and also there are no explicit sentences boundaries within the document.", "labels": [], "entities": []}, {"text": "Fortunately, there is the use of the paragraph structure in the Thai writing system, which is indicated by indentations and blank lines.", "labels": [], "entities": []}, {"text": "Therefore, extracting text spans from Thai documents at the paragraph level is a more practical way.", "labels": [], "entities": [{"text": "extracting text spans from Thai documents", "start_pos": 11, "end_pos": 52, "type": "TASK", "confidence": 0.8697022895018259}]}, {"text": "In this paper, we propose a practical approach to Thai text summarization by extracting the most relevant paragraphs from the original document.", "labels": [], "entities": [{"text": "Thai text summarization", "start_pos": 50, "end_pos": 73, "type": "TASK", "confidence": 0.7477030754089355}]}, {"text": "Our approach considers both the local and global properties of these paragraphs, which their meaning will become clear later.", "labels": [], "entities": []}, {"text": "We also present an efficient approach for solving Thai word segmentation problem, which can enhance a basic word segmentation algorithm yielding more useful output.", "labels": [], "entities": [{"text": "Thai word segmentation problem", "start_pos": 50, "end_pos": 80, "type": "TASK", "confidence": 0.7169225513935089}, {"text": "word segmentation", "start_pos": 108, "end_pos": 125, "type": "TASK", "confidence": 0.7277703732252121}]}, {"text": "We provide experimental evidence that our approach achieves acceptable performance.", "labels": [], "entities": []}, {"text": "Furthermore, our approach does not require the external knowledge other than the document itself, and be able to summarize general text documents.", "labels": [], "entities": [{"text": "summarize general text documents", "start_pos": 113, "end_pos": 145, "type": "TASK", "confidence": 0.8848077356815338}]}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we review some related work and contrast it with our work.", "labels": [], "entities": []}, {"text": "Section 3 describes the preprocessing for Thai text, particularly on word segmentation.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 69, "end_pos": 86, "type": "TASK", "confidence": 0.7248800098896027}]}, {"text": "In Section 4, we present our approach for extracting relevant paragraphs in detail, including how to find clusters of significant words, how to discover relations of paragraphs, and an algorithm for combining these two approaches.", "labels": [], "entities": []}, {"text": "Section 5 describes our experiments.", "labels": [], "entities": []}, {"text": "Finally, we conclude in Section 6 with some directions of future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate results of summarization by using the standard precision, recall, and F 1 . Let J be the number of extracts in the summary, K be the number of selected paragraphs in the summary, and M be the number of extracts in the test document.", "labels": [], "entities": [{"text": "summarization", "start_pos": 23, "end_pos": 36, "type": "TASK", "confidence": 0.9865259528160095}, {"text": "precision", "start_pos": 59, "end_pos": 68, "type": "METRIC", "confidence": 0.9993423819541931}, {"text": "recall", "start_pos": 70, "end_pos": 76, "type": "METRIC", "confidence": 0.9996771812438965}, {"text": "F", "start_pos": 82, "end_pos": 83, "type": "METRIC", "confidence": 0.9993120431900024}]}, {"text": "We then refer to precision of the algorithm as the fraction between the number of extracts in the summary and the number of selected paragraphs in the summary: recall as the fraction between the number of extracts in the summary and the number of extracts in the test document: Finally, F 1 , a combination of precision and recall, can be calculated as follows:  In this section, we provide experimental evidence that our algorithm gives acceptable performance.", "labels": [], "entities": [{"text": "precision", "start_pos": 17, "end_pos": 26, "type": "METRIC", "confidence": 0.9984715580940247}, {"text": "recall", "start_pos": 160, "end_pos": 166, "type": "METRIC", "confidence": 0.9989323019981384}, {"text": "F 1", "start_pos": 287, "end_pos": 290, "type": "METRIC", "confidence": 0.9919437766075134}, {"text": "precision", "start_pos": 310, "end_pos": 319, "type": "METRIC", "confidence": 0.9976922273635864}, {"text": "recall", "start_pos": 324, "end_pos": 330, "type": "METRIC", "confidence": 0.9916531443595886}]}, {"text": "The compression rate of paragraph extraction to form a summary is 20% and 30%.", "labels": [], "entities": [{"text": "paragraph extraction", "start_pos": 24, "end_pos": 44, "type": "TASK", "confidence": 0.787491112947464}]}, {"text": "These rates yield the number of extracts in the summary comparable to the number of actual extracts in a given test document.", "labels": [], "entities": []}, {"text": "The threshold \u03b1 of the cosine similarity is 0.2.", "labels": [], "entities": []}, {"text": "The parameter \u03bb for combining the local and global properties is 0.5.", "labels": [], "entities": []}, {"text": "For the distance between significant words in a cluster, we set that significant words are separated by not more than three insignificant words. and 2 show a summary of precision, recall, and F 1 for each compression rate, respectively.", "labels": [], "entities": [{"text": "precision", "start_pos": 169, "end_pos": 178, "type": "METRIC", "confidence": 0.9996597766876221}, {"text": "recall", "start_pos": 180, "end_pos": 186, "type": "METRIC", "confidence": 0.9993115663528442}, {"text": "F 1", "start_pos": 192, "end_pos": 195, "type": "METRIC", "confidence": 0.9953745603561401}]}, {"text": "We can see that average precision values of our algorithm slightly decrease, but average recall values increase when we increase the compression rate.", "labels": [], "entities": [{"text": "precision", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.9954674243927002}, {"text": "recall", "start_pos": 89, "end_pos": 95, "type": "METRIC", "confidence": 0.9988139867782593}]}, {"text": "Since using higher compression rate tends to select more paragraphs from the document, it increases the chance that the selected paragraphs will be matched with the target extracts.", "labels": [], "entities": []}, {"text": "On the other hand, it also selects irrelevant paragraphs to be included in the summary, so precision can decrease.", "labels": [], "entities": [{"text": "precision", "start_pos": 91, "end_pos": 100, "type": "METRIC", "confidence": 0.9994798302650452}]}, {"text": "Further experiments on larger text corpora are needed to determine the performance of our summarizer.", "labels": [], "entities": []}, {"text": "However, these preliminary results are very encouraging.", "labels": [], "entities": []}, {"text": "illustrates an example of keywords and extracted summaries fora Thai document using compression rate 20% . The implementation of our algorithm is now available for user testing at http://mickey.", "labels": [], "entities": []}, {"text": "sci.ku.ac.th/\u02dcTextSumm/index.html.", "labels": [], "entities": []}, {"text": "The computation time to summarize moderately-sized documents, such as newspaper articles, is less one second.", "labels": [], "entities": [{"text": "summarize moderately-sized documents, such as newspaper articles", "start_pos": 24, "end_pos": 88, "type": "TASK", "confidence": 0.7789183929562569}]}], "tableCaptions": [{"text": " Table 2: Evaluation results obtained by using com- pression rate 30%.", "labels": [], "entities": [{"text": "com- pression rate", "start_pos": 47, "end_pos": 65, "type": "METRIC", "confidence": 0.9245414733886719}]}]}