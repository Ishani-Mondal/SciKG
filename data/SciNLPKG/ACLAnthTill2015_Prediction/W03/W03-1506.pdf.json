{"title": [{"text": "Multi-Language Named-Entity Recognition System based on HMM", "labels": [], "entities": [{"text": "Multi-Language Named-Entity Recognition", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.6156061490376791}, {"text": "HMM", "start_pos": 56, "end_pos": 59, "type": "TASK", "confidence": 0.4265606701374054}]}], "abstractContent": [{"text": "We introduce a multi-language named-entity recognition system based on HMM.", "labels": [], "entities": [{"text": "named-entity recognition", "start_pos": 30, "end_pos": 54, "type": "TASK", "confidence": 0.7112843543291092}]}, {"text": "Japanese, Chinese, Korean and English versions have already been implemented.", "labels": [], "entities": []}, {"text": "In principle, it can analyze any other language if we have training data of the target language.", "labels": [], "entities": []}, {"text": "This system has a common analytical engine and it can handle any language simply by changing the lexical analysis rules and statistical language model.", "labels": [], "entities": []}, {"text": "In this paper, we describe the architecture and accuracy of the named-entity system, and report preliminary experiments on automatic bilingual named-entity dictionary construction using the Japanese and English named-entity recognizer.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9992223978042603}, {"text": "automatic bilingual named-entity dictionary construction", "start_pos": 123, "end_pos": 179, "type": "TASK", "confidence": 0.6594266891479492}]}], "introductionContent": [{"text": "There is increasing demand for cross-language information retrieval.", "labels": [], "entities": [{"text": "cross-language information retrieval", "start_pos": 31, "end_pos": 67, "type": "TASK", "confidence": 0.7405608693758646}]}, {"text": "Due to the development of the World Wide Web, we can access information written in not only our mother language but also foreign languages.", "labels": [], "entities": []}, {"text": "One report has English as the dominant language of web pages (76.6 %), followed by Japanese (2.77 %), German (2.28 %), Chinese (1.69 %), French (1.09 %), Spanish (0.81 %), and Korean (0.65 %).", "labels": [], "entities": []}, {"text": "Internet users who are not fluent in English finds this situation far from satisfactory; the many useful information sources in English are not open to them.", "labels": [], "entities": []}, {"text": "To implement a multi-language information retrieval system, it is indispensable to develop multi-language text analysis techniques such as morphological analysis and named-entity recognition.", "labels": [], "entities": [{"text": "multi-language information retrieval", "start_pos": 15, "end_pos": 51, "type": "TASK", "confidence": 0.6225399772326151}, {"text": "named-entity recognition", "start_pos": 166, "end_pos": 190, "type": "TASK", "confidence": 0.7200167179107666}]}, {"text": "They are needed in many natural language processing applications such as machine translation, information retrieval, and information extraction.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 73, "end_pos": 92, "type": "TASK", "confidence": 0.811492532491684}, {"text": "information retrieval", "start_pos": 94, "end_pos": 115, "type": "TASK", "confidence": 0.8226045966148376}, {"text": "information extraction", "start_pos": 121, "end_pos": 143, "type": "TASK", "confidence": 0.8768309950828552}]}, {"text": "We developed a multi-language named-entity recognition system based on HMM.", "labels": [], "entities": [{"text": "named-entity recognition", "start_pos": 30, "end_pos": 54, "type": "TASK", "confidence": 0.6967886090278625}]}, {"text": "This system is mainly for Japanese, Chinese, Korean and English, but it can handle any other language if we have training data of the target language.", "labels": [], "entities": []}, {"text": "This system has a common analytical engine and only the lexical analysis rules and statistical language model need be changed to handle any other language.", "labels": [], "entities": []}, {"text": "Previous works on multi-language named-entity recognition are mainly for European languages.", "labels": [], "entities": [{"text": "multi-language named-entity recognition", "start_pos": 18, "end_pos": 57, "type": "TASK", "confidence": 0.6230078538258871}]}, {"text": "Our system is the first one that can handle Asian languages, as far as we know.", "labels": [], "entities": []}, {"text": "In the following sections, we first describe the system architecture and language model of our named-entity recognition system.", "labels": [], "entities": [{"text": "named-entity recognition", "start_pos": 95, "end_pos": 119, "type": "TASK", "confidence": 0.7289620041847229}]}, {"text": "We then describe the evaluation results of our system.", "labels": [], "entities": []}, {"text": "Finally, we report preliminary experiments on the automatic construction of a bilingual named-entity dictionary.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate our system, we prepared original corpora for Japanese, Chinese, Korean and English.", "labels": [], "entities": []}, {"text": "The material was mainly taken from newspapers and Web texts.", "labels": [], "entities": []}, {"text": "We used the morpheme analysis definition of Pen Tree Bank for English, Jtag for Japanese, Beijing Univ. for Chinese and MATEC99 for Korean.", "labels": [], "entities": [{"text": "Pen Tree Bank", "start_pos": 44, "end_pos": 57, "type": "DATASET", "confidence": 0.976457397143046}, {"text": "Jtag", "start_pos": 71, "end_pos": 75, "type": "DATASET", "confidence": 0.8208091259002686}, {"text": "Beijing Univ.", "start_pos": 90, "end_pos": 103, "type": "DATASET", "confidence": 0.9440838098526001}, {"text": "MATEC99", "start_pos": 120, "end_pos": 127, "type": "DATASET", "confidence": 0.8171703815460205}]}, {"text": "The named-entity tag definitions were based on MUC for English and IREX for Japanese.", "labels": [], "entities": [{"text": "IREX", "start_pos": 67, "end_pos": 71, "type": "METRIC", "confidence": 0.9021838307380676}]}, {"text": "We defined Chinese and Korean named-entity tags following the Japanese IREX specifications.", "labels": [], "entities": []}, {"text": "shows dictionary and corpus size.", "labels": [], "entities": []}, {"text": "Dictionary words means the size of the dictionary for morphological analysis.", "labels": [], "entities": []}, {"text": "Total words and sentences represent the size of the corpus for named-entity recognition.", "labels": [], "entities": [{"text": "named-entity recognition", "start_pos": 63, "end_pos": 87, "type": "TASK", "confidence": 0.7194633483886719}]}, {"text": "Named-entity accuracy is expressed in terms of recall and precision.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.99069744348526}, {"text": "recall", "start_pos": 47, "end_pos": 53, "type": "METRIC", "confidence": 0.9995689988136292}, {"text": "precision", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9981958270072937}]}, {"text": "We also use the F-measure to indicate the overall performance.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 16, "end_pos": 25, "type": "METRIC", "confidence": 0.9984955787658691}]}, {"text": "It is calculated as follows; shows the F-measure for all languages.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.9945387244224548}]}, {"text": "Since we used our original corpora in this evaluation, we cannot compare our results to those of previous works.", "labels": [], "entities": []}, {"text": "Accordingly, we also evaluated SVM using our original corpora (see).", "labels": [], "entities": []}, {"text": "The accuracy of HMM and SVM were approximately equivalent.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9998032450675964}]}, {"text": "But the analysis speed of HMM was ten times faster than that of SVM.", "labels": [], "entities": []}, {"text": "This means that our system is very fast and has state-of-the-art accuracy in four languages.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9990081191062927}]}, {"text": "We noted that the accuracy of SVM is unusually lower than that of HMM for Japanese.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9998072981834412}, {"text": "SVM", "start_pos": 30, "end_pos": 33, "type": "TASK", "confidence": 0.658997654914856}]}, {"text": "We have not yet confirmed the cause of this, but a plausible argument is as follows.", "labels": [], "entities": []}, {"text": "First, the word segmentation ambiguity has a worse affect on accuracy than expected.", "labels": [], "entities": [{"text": "word segmentation ambiguity", "start_pos": 11, "end_pos": 38, "type": "TASK", "confidence": 0.7547789613405863}, {"text": "accuracy", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.9988059997558594}]}], "tableCaptions": [{"text": " Table 2. The Japanese and English inputs  are parallel sentences. It is apparent that the  efficiency of word candidate generation  improves dramatically compared to the case  of generating all character strings as", "labels": [], "entities": [{"text": "word candidate generation", "start_pos": 106, "end_pos": 131, "type": "TASK", "confidence": 0.6571680208047231}]}, {"text": " Table 5. Dictionary and Corpus Size", "labels": [], "entities": [{"text": "Dictionary", "start_pos": 10, "end_pos": 20, "type": "DATASET", "confidence": 0.9496694803237915}, {"text": "Corpus Size", "start_pos": 25, "end_pos": 36, "type": "TASK", "confidence": 0.606971025466919}]}, {"text": " Table 4. Linear Interpolation Scheme", "labels": [], "entities": []}, {"text": " Table 7. List of Bilingual Lexicons", "labels": [], "entities": []}]}