{"title": [{"text": "EBLA: A Perceptually Grounded Model of Language Acquisition", "labels": [], "entities": [{"text": "Perceptually Grounded Model of Language Acquisition", "start_pos": 8, "end_pos": 59, "type": "TASK", "confidence": 0.6980120738347372}]}], "abstractContent": [{"text": "This paper introduces an open computational framework for visual perception and grounded language acquisition called Experience-Based Language Acquisition (EBLA).", "labels": [], "entities": [{"text": "grounded language acquisition", "start_pos": 80, "end_pos": 109, "type": "TASK", "confidence": 0.6797613501548767}]}, {"text": "EBLA can \"watch\" a series of short videos and acquire a simple language of nouns and verbs corresponding to the objects and object-object relations in those videos.", "labels": [], "entities": []}, {"text": "Upon acquiring this protolanguage, EBLA can perform basic scene analysis to generate descriptions of novel videos.", "labels": [], "entities": []}, {"text": "The performance of EBLA has been evaluated based on accuracy and speed of protolanguage acquisition as well as on accuracy of generated scene descriptions.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9991689920425415}, {"text": "protolanguage acquisition", "start_pos": 74, "end_pos": 99, "type": "TASK", "confidence": 0.7179580330848694}, {"text": "accuracy", "start_pos": 114, "end_pos": 122, "type": "METRIC", "confidence": 0.9984482526779175}]}, {"text": "For a test set of simple animations, EBLA had average acquisition success rates as high as 100% and average description success rates as high as 96.7%.", "labels": [], "entities": [{"text": "acquisition success", "start_pos": 54, "end_pos": 73, "type": "METRIC", "confidence": 0.8912434577941895}]}, {"text": "For a larger set of real videos, EBLA had average acquisition success rates as high as 95.8% and average description success rates as high as 65.3%.", "labels": [], "entities": []}, {"text": "The lower description success rate for the videos is attributed to the wide variance in the appearance of objects across the test set.", "labels": [], "entities": []}, {"text": "While there have been several systems capable of learning objector event labels for videos , EBLA is the first known system to acquire both nouns and verbs using a grounded computer vision system.", "labels": [], "entities": []}], "introductionContent": [{"text": "While traditional, top-down research fields such as natural language processing (NLP), computational linguistics, and speech recognition and synthesis have made great progress in allowing computers to process natural language, they typically do not address perceptual understanding.", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 52, "end_pos": 85, "type": "TASK", "confidence": 0.8276476462682089}, {"text": "speech recognition and synthesis", "start_pos": 118, "end_pos": 150, "type": "TASK", "confidence": 0.818227045238018}]}, {"text": "In these fields, meaning and context fora given word are based solely on other words and the logical relationships among them.", "labels": [], "entities": []}, {"text": "To make this clearer, consider the following Webster's definition of apple: \"The fleshy usually rounded and red or yellow edible pome fruit of a tree of the rose family.\"", "labels": [], "entities": []}, {"text": "Using traditional approaches, a computer might be able to determine from such a definition that an apple is \"edible,\" that it is a \"fruit,\" and that it is usually \"rounded and red or yellow.\"", "labels": [], "entities": []}, {"text": "But what does is mean to be \"rounded and red\"?", "labels": [], "entities": []}, {"text": "People understand these words because their conceptual representations are grounded in their perceptual experiences.", "labels": [], "entities": []}, {"text": "As for more abstract words, many have perceptual analogs or can be defined in terms of grounded words.", "labels": [], "entities": []}, {"text": "Although it is unlikely that any two people share identical representations of a given word, there are generally enough similarities for that word to convey meaning.", "labels": [], "entities": []}, {"text": "If computers can be enabled to ground language in perception, ultimately communication between man and machine maybe facilitated.", "labels": [], "entities": []}, {"text": "This paper details anew software framework, Experience-Based Language Acquisition (EBLA), that acquires a childlike language known as protolanguage in a bottom-up fashion based on visually perceived experiences.", "labels": [], "entities": [{"text": "Experience-Based Language Acquisition (EBLA)", "start_pos": 44, "end_pos": 88, "type": "TASK", "confidence": 0.7242260376612345}]}, {"text": "EBLA uses an integrated computer vision system to watch short videos and to generate internal representations of both the objects and the object-object relations in those videos.", "labels": [], "entities": [{"text": "EBLA", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9461130499839783}]}, {"text": "It then performs language acquisition by resolving these internal representations to the individual words in protolanguage descriptions of each video.", "labels": [], "entities": [{"text": "language acquisition", "start_pos": 17, "end_pos": 37, "type": "TASK", "confidence": 0.7112910002470016}]}, {"text": "Upon acquiring this grounded protolanguage, EBLA can perform basic scene analysis to generate simplistic descriptions of what it \"sees.\"", "labels": [], "entities": []}, {"text": "EBLA operates in three primary stages: vision processing, entity extraction, and lexical resolution.", "labels": [], "entities": [{"text": "vision processing", "start_pos": 39, "end_pos": 56, "type": "TASK", "confidence": 0.7054602801799774}, {"text": "entity extraction", "start_pos": 58, "end_pos": 75, "type": "TASK", "confidence": 0.8248821198940277}, {"text": "lexical resolution", "start_pos": 81, "end_pos": 99, "type": "TASK", "confidence": 0.7546095550060272}]}, {"text": "In the vision processing stage, EBLA is presented with experiences in the form of short videos, each containing a simple event such as a hand picking up a ball.", "labels": [], "entities": []}, {"text": "EBLA processes the individual frames in the videos to identify and store information about significant objects.", "labels": [], "entities": []}, {"text": "In the entity extraction stage, EBLA aggregates the information from the video processing stage into internal representations called entities.", "labels": [], "entities": [{"text": "entity extraction", "start_pos": 7, "end_pos": 24, "type": "TASK", "confidence": 0.7672892212867737}]}, {"text": "Entities are defined for both the significant objects in each experience and for the relationships among those objects.", "labels": [], "entities": []}, {"text": "Finally, in the lexical acquisition stage, EBLA attempts to acquire language for the entities extracted in the second stage using protolanguage descriptions of each event.", "labels": [], "entities": []}, {"text": "It extracts the individual lexemes (words) from each description and then attempts to generate entity-lexeme mappings using an inference technique called cross-situational learning.", "labels": [], "entities": []}, {"text": "EBLA is not primed with abase lexicon, so it faces the task of bootstrapping its lexicon from scratch.", "labels": [], "entities": [{"text": "EBLA", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9074681401252747}]}, {"text": "While, to date, EBLA has only been evaluated using short descriptions comprised of nouns and verbs, one of the primary goals of this research has been to develop an open system that can potentially learn any perceptually grounded lexeme using a unified approach.", "labels": [], "entities": []}, {"text": "The entities recognized EBLA are generic in nature and are comprised of clusters of perceptual attributes linked in a database system.", "labels": [], "entities": []}, {"text": "Although only twelve basic attributes have been programmed into the current system, both the EBLA software and database support the addition of other attributes.", "labels": [], "entities": []}, {"text": "There are even mechanisms in the database to support dynamic loading/unloading of custom attribute calculators.", "labels": [], "entities": []}], "datasetContent": [{"text": "EBLA was evaluated using three criteria.", "labels": [], "entities": [{"text": "EBLA", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.7117864489555359}]}, {"text": "First, overall success was measured by comparing the number of correct entity-lexeme mappings to the total number of entities detected.", "labels": [], "entities": []}, {"text": "Second, acquisition speed was measured by comparing the average number of experiences needed to resolve a word in comparison to the total number of experiences processed.", "labels": [], "entities": []}, {"text": "Third, descriptive accuracy was measured by presenting EBLA with new, unlabeled experiences, and determining its ability to generate protolanguage descriptions based on prior experiences.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9902708530426025}]}, {"text": "The test sets for EBLA were comprised of eight simple animations created using Macromedia Flash, and 319 short digital videos.", "labels": [], "entities": [{"text": "EBLA", "start_pos": 18, "end_pos": 22, "type": "DATASET", "confidence": 0.7428156137466431}]}, {"text": "While the results for the animations were somewhat better than those for the videos, only the results for the larger and more complex video test set will be presented here.", "labels": [], "entities": []}, {"text": "Of the 319 videos, 226 were delivered to EBLA for evaluating lexical acquisition accuracy and speed and 167 were delivered to EBLA for evaluating descriptive accuracy.", "labels": [], "entities": [{"text": "EBLA", "start_pos": 41, "end_pos": 45, "type": "DATASET", "confidence": 0.9742830395698547}, {"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9287456274032593}, {"text": "speed", "start_pos": 94, "end_pos": 99, "type": "METRIC", "confidence": 0.9834592938423157}, {"text": "EBLA", "start_pos": 126, "end_pos": 130, "type": "DATASET", "confidence": 0.9768530130386353}, {"text": "accuracy", "start_pos": 158, "end_pos": 166, "type": "METRIC", "confidence": 0.9013383388519287}]}, {"text": "Videos were removed from the full set of 319 because of problems with over and undersegmentation in the vision processing system.", "labels": [], "entities": []}, {"text": "demonstrates the types of problems encountered by EBLA's vision system.", "labels": [], "entities": []}, {"text": "It shows the polygon tracings for three frames from a single video shot with the Garfield toy.", "labels": [], "entities": []}, {"text": "The frame on the left was correctly segmented, the frame in the middle was undersegmented where the hand has been merged into the background and essentially disappeared, and the frame on the right was oversegmented where the Garfield toy has been split into two objects.", "labels": [], "entities": []}, {"text": "To measure acquisition speed and accuracy, the 226 videos were delivered to EBLA at random, ten times for each of nineteen different minimum standard deviation (\u03c3 min ) values.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9985485672950745}, {"text": "EBLA", "start_pos": 76, "end_pos": 80, "type": "DATASET", "confidence": 0.9575294256210327}, {"text": "minimum standard deviation (\u03c3 min )", "start_pos": 133, "end_pos": 168, "type": "METRIC", "confidence": 0.7426847645214626}]}, {"text": "The value of \u03c3 min used to match the attribute values to existing entities was varied from 5% to 95% in increments of 5%.", "labels": [], "entities": []}, {"text": "shows the success rates for lexeme mappings for each of the nineteen \u03c3 min values.", "labels": [], "entities": []}, {"text": "For \u03c3 min values of 5% and 10%, the acquisition success was only 76% and 85% respectively.", "labels": [], "entities": []}, {"text": "This can be attributed to the amount of variation in the entities for the videos.", "labels": [], "entities": []}, {"text": "A stricter matching criteria results in more unmatched entities.", "labels": [], "entities": []}, {"text": "For all of the other \u03c3 min values the acquisition success rate was better than 90% and as high as 95.8% fora \u03c3 min value of 45%.", "labels": [], "entities": [{"text": "acquisition success rate", "start_pos": 38, "end_pos": 62, "type": "METRIC", "confidence": 0.8857082724571228}]}, {"text": "For the lower values of \u03c3 min , there were very few incorrect descriptions, but many entities did not map to a known lexeme.", "labels": [], "entities": []}, {"text": "As \u03c3 min was increased, the situation reversed with almost every entity mapping to some lexeme, but many to the wrong lexeme.", "labels": [], "entities": []}, {"text": "The most accurate descriptions were produced fora \u03c3 min value of 15% where just over 65% of the entities were described correctly.", "labels": [], "entities": []}, {"text": "These are reasonably good results considering the amount that any given entity varied from video to video, especially the object-object relation entities.", "labels": [], "entities": []}, {"text": "For a full discussion of both the animation and video results for EBLA see chapter 6 of Pangburn (2002).", "labels": [], "entities": [{"text": "EBLA", "start_pos": 66, "end_pos": 70, "type": "DATASET", "confidence": 0.8180825710296631}, {"text": "Pangburn (2002)", "start_pos": 88, "end_pos": 103, "type": "DATASET", "confidence": 0.9297873228788376}]}, {"text": "displays the average acquisition speed for the videos.", "labels": [], "entities": []}, {"text": "It indicates that for the first few videos, it took an average of over twenty experiences to resolve all of the entity-lexeme mappings.", "labels": [], "entities": []}, {"text": "After about seventyfive experiences had been processed, this average dropped to about five experiences, and after about 150 experiences, the average fell below one.", "labels": [], "entities": []}, {"text": "To evaluate the descriptive accuracy of EBLA, 157 of the 167 best videos were randomly processed in acquisition mode and the remaining ten were processed in description mode.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9833890795707703}]}, {"text": "This scenario was run ten times for each of the same nineteen \u03c3 min values used to evaluate acquisition success.", "labels": [], "entities": []}, {"text": "The results are shown in table 2.", "labels": [], "entities": []}, {"text": "It is important to note that fora given \u03c3 min value, EBLA often returned multiple \"matching\" lexemes.", "labels": [], "entities": []}, {"text": "When this happened, both the correct and incorrect lexemes were scored pro-rata.", "labels": [], "entities": []}], "tableCaptions": []}