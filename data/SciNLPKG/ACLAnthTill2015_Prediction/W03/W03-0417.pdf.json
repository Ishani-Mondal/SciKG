{"title": [{"text": "Training a Naive Bayes Classifier via the EM Algorithm with a Class Distribution Constraint", "labels": [], "entities": []}], "abstractContent": [{"text": "Combining a naive Bayes classifier with the EM algorithm is one of the promising approaches for making use of unlabeled data for disambiguation tasks when using local context features including word sense disambigua-tion and spelling correction.", "labels": [], "entities": [{"text": "word sense disambigua-tion", "start_pos": 194, "end_pos": 220, "type": "TASK", "confidence": 0.6508910258611044}, {"text": "spelling correction", "start_pos": 225, "end_pos": 244, "type": "TASK", "confidence": 0.8523541986942291}]}, {"text": "However, the use of unlabeled data via the basic EM algorithm often causes disastrous performance degradation instead of improving classification performance , resulting in poor classification performance on average.", "labels": [], "entities": []}, {"text": "In this study, we introduce a class distribution constraint into the iteration process of the EM algorithm.", "labels": [], "entities": []}, {"text": "This constraint keeps the class distribution of unlabeled data consistent with the class distribution estimated from labeled data, preventing the EM algorithm from converging into an undesirable state.", "labels": [], "entities": []}, {"text": "Experimental results from using 26 confusion sets and a large amount of unlabeled data show that our proposed method for using unlabeled data considerably improves classification performance when the amount of labeled data is small.", "labels": [], "entities": []}], "introductionContent": [{"text": "Many of the tasks in natural language processing can be addressed as classification problems.", "labels": [], "entities": []}, {"text": "State-of-theart machine learning techniques including Support Vector Machines, AdaBoost) and Maximum Entropy Models) provide high performance classifiers if one has abundant correctly labeled examples.", "labels": [], "entities": []}, {"text": "However, annotating a large set of examples generally requires a huge amount of human labor and time.", "labels": [], "entities": []}, {"text": "This annotation cost is one of the major obstacles to applying machine learning techniques to real-world NLP applications.", "labels": [], "entities": []}, {"text": "Recently, learning algorithms called minimally supervised learning or unsupervised learning that can make use of unlabeled data have received much attention.", "labels": [], "entities": []}, {"text": "Since collecting unlabeled data is generally much easier than annotating data, such techniques have potential for solving the problem of annotation cost.", "labels": [], "entities": []}, {"text": "Those approaches include a naive Bayes classifier combined with the EM algorithm,, and Transductive Support Vector Machines).", "labels": [], "entities": []}, {"text": "These algorithms have been applied to some tasks including text classification and word sense disambiguation and their effectiveness has been demonstrated to some extent.", "labels": [], "entities": [{"text": "text classification", "start_pos": 59, "end_pos": 78, "type": "TASK", "confidence": 0.8350881338119507}, {"text": "word sense disambiguation", "start_pos": 83, "end_pos": 108, "type": "TASK", "confidence": 0.7280148863792419}]}, {"text": "Combining a naive Bayes classifier with the EM algorithm is one of the promising minimally supervised approaches because its computational cost is low (linear to the size of unlabeled data), and it does not require the features to be split into two independent sets unlike cotraining.", "labels": [], "entities": []}, {"text": "However, the use of unlabeled data via the basic EM algorithm does not always improve classification performance.", "labels": [], "entities": []}, {"text": "In fact, this often causes disastrous performance degradation resulting in poor classification performance on average.", "labels": [], "entities": []}, {"text": "To alleviate this problem, we introduce a class distribution constraint into the iteration process of the EM algorithm.", "labels": [], "entities": []}, {"text": "This constraint keeps the class distribution of unlabeled data consistent with the class distribution estimated from labeled data, preventing the EM algorithm from converging into an undesirable state.", "labels": [], "entities": []}, {"text": "In order to assess the effectiveness of the proposed method, we applied it to the problem of semantic disambiguation using local context features.", "labels": [], "entities": [{"text": "semantic disambiguation", "start_pos": 93, "end_pos": 116, "type": "TASK", "confidence": 0.815683513879776}]}, {"text": "Experiments were conducted with 26 confusion sets and a large number of unlabeled examples collected from a corpus of one hundred million words.", "labels": [], "entities": []}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 briefly reviews the naive Bayes classifier and the EM algorithm as means of using unlabeled data.", "labels": [], "entities": []}, {"text": "Section 3 presents the idea of using a class distribution constraint and how to impose this constraint on the learning process.", "labels": [], "entities": []}, {"text": "Section 4 describes the problem of confusion set disambiguation and the features used in the experiments.", "labels": [], "entities": [{"text": "confusion set disambiguation", "start_pos": 35, "end_pos": 63, "type": "TASK", "confidence": 0.634028563896815}]}, {"text": "Experimental results are presented in Section 5.", "labels": [], "entities": []}, {"text": "Related work is discussed in Section 6.", "labels": [], "entities": []}, {"text": "Section 7 offers some concluding remarks.", "labels": [], "entities": []}], "datasetContent": [{"text": "To conduct large scale experiments, we used the British National Corpus 1 that is currently one of the largest corpora available.", "labels": [], "entities": [{"text": "British National Corpus 1", "start_pos": 48, "end_pos": 73, "type": "DATASET", "confidence": 0.920133963227272}]}, {"text": "The corpus contains roughly one hundred million words collected from various sources.", "labels": [], "entities": []}, {"text": "The confusion sets used in our experiments are the same as in Golding's experiment (1999).", "labels": [], "entities": []}, {"text": "Since our algorithm requires the classification to be binary, we decomposed three-class confusion sets into pairwise binary classifications.", "labels": [], "entities": []}, {"text": "shows the resulting confusion sets used in the following experiments.", "labels": [], "entities": []}, {"text": "The baseline performances, achieved by simply selecting the majority class, are shown in the second column.", "labels": [], "entities": []}, {"text": "The number of unlabeled data are shown in the rightmost column.", "labels": [], "entities": []}, {"text": "The 1,000 test sets were randomly selected from the corpus for each confusion set.", "labels": [], "entities": []}, {"text": "They do not overlap the labeled data or the unlabeled data used in the learning process.", "labels": [], "entities": []}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "These four tables correspond to the cases in which the number of labeled examples is 32, 64, 128 and 256 as indicated by the table captions.", "labels": [], "entities": []}, {"text": "The first column shows the confusion sets.", "labels": [], "entities": []}, {"text": "The second column shows the classification performance of the naive Bayes classifier with which only labeled data was used for training.", "labels": [], "entities": []}, {"text": "The third column shows the performance of the naive Bayes classifier with which unlabeled data was used via the basic EM algorithm.", "labels": [], "entities": []}, {"text": "The rightmost column shows the performance of the EM algorithm that was extended with our proposed calibration process.", "labels": [], "entities": []}, {"text": "Notice that the effect of unlabeled data were very different for each confusion set.", "labels": [], "entities": []}, {"text": "As shown in, the precision was significantly improved for some confusion sets including {I, me}, {accept, except} and {affect, effect} . However, disastrous performance deterioration can be observed, especially that of the basic EM algorithm, in some confusion sets including {among, between}, {country, county}, and {site, cite}.", "labels": [], "entities": [{"text": "precision", "start_pos": 17, "end_pos": 26, "type": "METRIC", "confidence": 0.9996315240859985}]}, {"text": "On average, precision was degraded by the use of un- labeled data via the basic EM algorithm (from 83.3% to 82.9%).", "labels": [], "entities": [{"text": "precision", "start_pos": 12, "end_pos": 21, "type": "METRIC", "confidence": 0.9996678829193115}]}, {"text": "On the other hand, the EM algorithm with the class distribution constraint improved average classification performance (from 83.3% to 85.4%).", "labels": [], "entities": []}, {"text": "This improved precision nearly reached the performance achieved by twice the size of labeled data without unlabeled data (see the average precision of NB in).", "labels": [], "entities": [{"text": "precision", "start_pos": 14, "end_pos": 23, "type": "METRIC", "confidence": 0.9988824725151062}, {"text": "precision", "start_pos": 138, "end_pos": 147, "type": "METRIC", "confidence": 0.7864439487457275}]}, {"text": "This performance gain indicates that the use of unlabeled data effectively doubles the labeled training data.", "labels": [], "entities": []}, {"text": "In, the tendency of performance improvement (or degradation) in the use of unlabeled data is almost the same as in.", "labels": [], "entities": []}, {"text": "The basic EM algorithm degraded the performance on average, while our method improved average performance (from 85.7% to 87.7%).", "labels": [], "entities": []}, {"text": "This performance gain effectively doubled the size of labeled data.", "labels": [], "entities": []}, {"text": "The results with 128 labeled examples are shown in Table 4.", "labels": [], "entities": []}, {"text": "Although the use of unlabeled examples by means of our proposed method still improved average performance (from 87.6% to 88.6%), the gain is smaller than that fora smaller amount of labeled data.", "labels": [], "entities": []}, {"text": "With 256 labeled examples, the average per- formance gain was negligible (from 89.2% to 89.3%).", "labels": [], "entities": []}, {"text": "summarizes the average precisions for different number of labeled examples.", "labels": [], "entities": [{"text": "precisions", "start_pos": 23, "end_pos": 33, "type": "METRIC", "confidence": 0.949354887008667}]}, {"text": "Average peformance was improved by the use of unlabeled data with our proposed method when the amount of labeled data was small (from 32 to 256) as shown in.", "labels": [], "entities": [{"text": "peformance", "start_pos": 8, "end_pos": 18, "type": "METRIC", "confidence": 0.9562387466430664}]}, {"text": "However, when the number of labeled examples was large (more than 512), the use of unlabeled data degraded average performance.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Confusion Sets used in the Experiments", "labels": [], "entities": []}]}