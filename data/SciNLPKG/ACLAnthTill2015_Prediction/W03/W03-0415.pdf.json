{"title": [{"text": "Using LSA and Noun Coordination Information to Improve the Precision and Recall of Automatic Hyponymy Extraction", "labels": [], "entities": [{"text": "Precision", "start_pos": 59, "end_pos": 68, "type": "METRIC", "confidence": 0.8897119164466858}, {"text": "Recall of Automatic Hyponymy Extraction", "start_pos": 73, "end_pos": 112, "type": "TASK", "confidence": 0.5709780156612396}]}], "abstractContent": [{"text": "In this paper we demonstrate methods of improving both the recall and the precision of automatic methods for extraction of hyponymy (IS A) relations from free text.", "labels": [], "entities": [{"text": "recall", "start_pos": 59, "end_pos": 65, "type": "METRIC", "confidence": 0.9994799494743347}, {"text": "precision", "start_pos": 74, "end_pos": 83, "type": "METRIC", "confidence": 0.9995977282524109}, {"text": "extraction of hyponymy (IS A) relations from free text", "start_pos": 109, "end_pos": 163, "type": "TASK", "confidence": 0.8267806985161521}]}, {"text": "By applying latent semantic analysis (LSA) to filter extracted hyponymy relations we reduce the rate of error of our initial pattern-based hyponymy extraction by 30%, achieving precision of 58%.", "labels": [], "entities": [{"text": "precision", "start_pos": 177, "end_pos": 186, "type": "METRIC", "confidence": 0.9993855953216553}]}, {"text": "Applying a graph-based model of noun-noun similarity learned automatically from coordination patterns to previously extracted correct hyponymy relations, we achieve roughly a five-fold increase in the number of correct hy-ponymy relations extracted.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper demonstrates that mathematical models for measuring semantic similarity between concepts can be used to improve the learning of hyponymy relationships between concepts from free text.", "labels": [], "entities": [{"text": "learning of hyponymy relationships between concepts from free text", "start_pos": 127, "end_pos": 193, "type": "TASK", "confidence": 0.6530797349082099}]}, {"text": "In particular, we show that latent semantic analysis can be used to filter results, giving an increase in precision, and that neighbors in a graph built from coordination information can be used to improve recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 106, "end_pos": 115, "type": "METRIC", "confidence": 0.9993157386779785}, {"text": "recall", "start_pos": 206, "end_pos": 212, "type": "METRIC", "confidence": 0.9891680479049683}]}, {"text": "The goal of extracting semantic information from text is well-established, and has encouraged work on lexical acquisition, information extraction, and ontology engineering.", "labels": [], "entities": [{"text": "lexical acquisition", "start_pos": 102, "end_pos": 121, "type": "TASK", "confidence": 0.7629552781581879}, {"text": "information extraction", "start_pos": 123, "end_pos": 145, "type": "TASK", "confidence": 0.848503828048706}, {"text": "ontology engineering", "start_pos": 151, "end_pos": 171, "type": "TASK", "confidence": 0.8312148153781891}]}, {"text": "The purpose of this kind of work is to collect information about the meanings of lexical items or phrases, and the relationships between them, so that the process of building semantic resources (such as ontologies and dictionaries) by hand can be automated or at least helped.", "labels": [], "entities": []}, {"text": "One of the standard ways of arranging concepts is in a concept hierarchy or taxonomy such as the WordNet noun taxonomy.", "labels": [], "entities": [{"text": "WordNet noun taxonomy", "start_pos": 97, "end_pos": 118, "type": "DATASET", "confidence": 0.9370537996292114}]}, {"text": "The fundamental relationship between objects in a taxonomy is called hyponymy, where y is a hyponym of x if every y is also an x.", "labels": [], "entities": []}, {"text": "For example, every trout is also a fish, so we say that trout is a hyponym (\"below name\") offish and conversely, fish is a hypernym (\"above name\") of trout.", "labels": [], "entities": []}, {"text": "Other names exist for variants of the hyponymy relationship, such as an IS A relationship, a parent-node / child-node relationship, and a broader term / narrower term relationship.", "labels": [], "entities": []}, {"text": "It is also noted that the genus of an object, in traditional lexicographic terms, is often a hypernym of that object.", "labels": [], "entities": []}, {"text": "Throughout this paper we will write y < x for the relationship \"y is a hyponym of x\".", "labels": [], "entities": []}, {"text": "In this paper, we use the hyponymy relationship to describe subset relationships, so we regard y < x to be true if the set of y's can reasonably be said to be a subset of the set of x's.", "labels": [], "entities": []}, {"text": "Because hyponymy relationships are so central to knowledge engineering, there have been numerous attempts to learn them from text, beginning with those of.", "labels": [], "entities": []}, {"text": "We review this work in Section 2, where we reproduce similar experiments as a baseline from which to expand.", "labels": [], "entities": []}, {"text": "The rest of the paper demonstrates ways in which other mathematical models built from text corpora can be used to improve hyponymy extraction.", "labels": [], "entities": [{"text": "hyponymy extraction", "start_pos": 122, "end_pos": 141, "type": "TASK", "confidence": 0.8657878339290619}]}, {"text": "In Section 3, we show how latent semantic analysis can be used to filter potential relationships according to their \"semantic plausibility\".", "labels": [], "entities": [{"text": "latent semantic analysis", "start_pos": 26, "end_pos": 50, "type": "TASK", "confidence": 0.6311136484146118}]}, {"text": "In Section 4, we show how correctly extracted relationships can be used as \"seed-cases\" to extract several more relationships, thus improving recall; this work shares some similarities with that of.", "labels": [], "entities": [{"text": "recall", "start_pos": 142, "end_pos": 148, "type": "METRIC", "confidence": 0.9980925917625427}]}, {"text": "In Section 5 we show that combining the techniques of Section 3 and Section 4 improves both precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 92, "end_pos": 101, "type": "METRIC", "confidence": 0.9996168613433838}, {"text": "recall", "start_pos": 106, "end_pos": 112, "type": "METRIC", "confidence": 0.9990371465682983}]}, {"text": "Section 6 demonstrates that Another possible view is that \"hyponymy\" should only refer to core relationships, not contingent ones (so pheasant < bird might be accepted but pheasant < food might not be, because it depends on context and culture).", "labels": [], "entities": []}, {"text": "We use the broader \"subset\" definition because contingent relationships are an important part of world-knowledge (and are therefore worth learning), and because in practice we found the distinction difficult to enforce.", "labels": [], "entities": []}, {"text": "Another definition is given by Caraballo (1999): \".", "labels": [], "entities": []}, {"text": "a word A is said to be a hypernym of a word B if native speakers of English accept the sentence 'B is a (kind of) A.'", "labels": [], "entities": []}, {"text": "\" linguistic tools such as lemmatization can be used to reliably put the extracted relationships into a normalized or \"canonical\" form for addition to a semantic resource.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Number of the 100 randomly selected hyponymy  relations (of 513 extracted) to which each of the authors  assigned the five available scores.", "labels": [], "entities": []}, {"text": " Table 3: Number of the 100 top-ranked hyponymy re- lations (of 513 extracted) to which each of the authors  assigned the five available scores.", "labels": [], "entities": []}]}