{"title": [{"text": "Using LTAG Based Features in Parse Reranking *", "labels": [], "entities": [{"text": "Parse Reranking", "start_pos": 29, "end_pos": 44, "type": "TASK", "confidence": 0.6540925800800323}]}], "abstractContent": [{"text": "We propose the use of Lexicalized Tree Adjoining Grammar (LTAG) as a source of features that are useful for reranking the output of a statistical parser.", "labels": [], "entities": [{"text": "Lexicalized Tree Adjoining Grammar (LTAG)", "start_pos": 22, "end_pos": 63, "type": "TASK", "confidence": 0.7244832686015538}]}, {"text": "In this paper, we extend the notion of a tree kernel over arbitrary sub-trees of the parse to the derivation trees and derived trees provided by the LTAG formalism, and in addition , we extend the original definition of the tree kernel, making it more lexi-calized and more compact.", "labels": [], "entities": []}, {"text": "We use LTAG based features for the parse reranking task and obtain labeled recall and precision of 89.7%/90.0% on WSJ section 23 of Penn Treebank for sentences of length \u2264 100 words.", "labels": [], "entities": [{"text": "parse reranking", "start_pos": 35, "end_pos": 50, "type": "TASK", "confidence": 0.9609967172145844}, {"text": "recall", "start_pos": 75, "end_pos": 81, "type": "METRIC", "confidence": 0.9333105087280273}, {"text": "precision", "start_pos": 86, "end_pos": 95, "type": "METRIC", "confidence": 0.9940229058265686}, {"text": "WSJ section 23 of Penn Treebank", "start_pos": 114, "end_pos": 145, "type": "DATASET", "confidence": 0.9251017769177755}]}, {"text": "Our results show that the use of LTAG based tree kernel gives rise to a 17% relative difference in f-score improvement over the use of a linear kernel without LTAG based features.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recent work in statistical parsing has explored alternatives to the use of (smoothed) maximum likelihood estimation for parameters of the model.", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 15, "end_pos": 34, "type": "TASK", "confidence": 0.8468450009822845}]}, {"text": "These alternatives are distribution-free, providing a discriminative method for resolving parse ambiguity.", "labels": [], "entities": []}, {"text": "Discriminative methods provide a ranking between multiple choices for the most plausible parse tree fora sentence, without assuming that a particular distribution or stochastic process generated the alternative parses.", "labels": [], "entities": []}, {"text": "* We would like to thank Michael Collins for providing the original n-best parsed data on which we ran our experiments and the anonymous reviewers for their comments.", "labels": [], "entities": [{"text": "Michael Collins", "start_pos": 25, "end_pos": 40, "type": "DATASET", "confidence": 0.7764143943786621}]}, {"text": "The second author is partially supported by NSERC,.", "labels": [], "entities": [{"text": "NSERC", "start_pos": 44, "end_pos": 49, "type": "DATASET", "confidence": 0.9372358918190002}]}, {"text": "Discriminative methods permit the use of feature functions that can be used to condition on arbitrary aspects of the input.", "labels": [], "entities": []}, {"text": "This flexibility makes it possible to incorporate features of various of kinds.", "labels": [], "entities": []}, {"text": "Features can be defined on characters, words, part of speech (POS) tags and context-free grammar (CFG) rules, depending on the application to which the model is applied.", "labels": [], "entities": []}, {"text": "Features defined on n-grams from the input are the most commonly used for NLP applications.", "labels": [], "entities": []}, {"text": "Such n-grams can either be defined explicitly using some linguistic insight into the problem, or the model can be used to search the entire space of ngram features using a kernel representation.", "labels": [], "entities": []}, {"text": "One example is the use of a polynomial kernel over sequences.", "labels": [], "entities": []}, {"text": "However, to use all possible n-gram features typically introduces too many noisy features, which can result in lower accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 117, "end_pos": 125, "type": "METRIC", "confidence": 0.9968385696411133}]}, {"text": "One way to solve this problem is to use a kernel function that is tailored for particular NLP applications, such as the tree kernel) for statistical parsing.", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 137, "end_pos": 156, "type": "TASK", "confidence": 0.8577064871788025}]}, {"text": "In addition to n-gram features, more complex high-level features are often exploited to obtain higher accuracy, especially when discriminative models are used for statistical parsing.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 102, "end_pos": 110, "type": "METRIC", "confidence": 0.9983305335044861}, {"text": "statistical parsing", "start_pos": 163, "end_pos": 182, "type": "TASK", "confidence": 0.7752311527729034}]}, {"text": "For example, all possible sub-trees can be used as features (.", "labels": [], "entities": []}, {"text": "However, most of the sub-trees are linguistically meaningless, and area source of noisy features thus limiting efficiency and accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 126, "end_pos": 134, "type": "METRIC", "confidence": 0.9934189915657043}]}, {"text": "An alternative to the use of arbitrary sets of sub-trees is to use the set of elementary trees as defined in Lexicalized Tree Adjoining Grammar (LTAG).", "labels": [], "entities": [{"text": "Lexicalized Tree Adjoining Grammar (LTAG)", "start_pos": 109, "end_pos": 150, "type": "TASK", "confidence": 0.7322738255773272}]}, {"text": "LTAG based features not only allow a more limited and a linguistically more valid set of features over sub-trees, they also provide the use of features that use discontinuous sub-trees which are outside the scope of previous tree kernel definitions using arbitrary sub-trees.", "labels": [], "entities": []}, {"text": "In this paper, we use the LTAG based features in the parse reranking problem).", "labels": [], "entities": []}, {"text": "We use the Support Vector Machine (SVM)) based algorithm proposed in as the reranker in this paper.", "labels": [], "entities": []}, {"text": "We apply the tree kernel to derivation trees of LTAG, and extract features from derivation trees.", "labels": [], "entities": [{"text": "LTAG", "start_pos": 48, "end_pos": 52, "type": "DATASET", "confidence": 0.8815217614173889}]}, {"text": "Both the tree kernel and the linear kernel on the richer feature set are used.", "labels": [], "entities": []}, {"text": "Our experiments show that the use of tree kernel on derivation trees makes the notion of a tree kernel more powerful and more applicable.", "labels": [], "entities": []}], "datasetContent": [{"text": "As described above, we use the SVM based voting algorithm) in our reranking experiments.", "labels": [], "entities": []}, {"text": "We use preference kernels and pairwise parse trees in our reranking models.", "labels": [], "entities": []}, {"text": "We use the same data set as described in.", "labels": [], "entities": []}, {"text": "Section 2-21 of the Penn WSJ Treebank are used as training data, and section 23 is used for final test.", "labels": [], "entities": [{"text": "Penn WSJ Treebank", "start_pos": 20, "end_pos": 37, "type": "DATASET", "confidence": 0.9456902543703715}]}, {"text": "The training data contains around 40,000 sentences, each of which has 27 distinct parses on average.", "labels": [], "entities": []}, {"text": "Of the 40,000 training sentences, the first 36,000 are used to train SVMs.", "labels": [], "entities": [{"text": "SVMs", "start_pos": 69, "end_pos": 73, "type": "TASK", "confidence": 0.6264760494232178}]}, {"text": "The remaining 4,000 sentences are used as development data.", "labels": [], "entities": []}, {"text": "Due to the computational complexity of SVM, we have to divide training data into slices to speedup training.", "labels": [], "entities": []}, {"text": "Each slice contain two pairs of parses from every sentence.", "labels": [], "entities": []}, {"text": "Specifically, slice i contains positive samples ((\u02dc pk , p ki ), +1) and negative samples ((p ki , \u02dc pk ), \u22121), where\u02dcpwhere\u02dc where\u02dcp k is the best parse for sentence k, p ki is the parse with the ith highest loglikelihood in all the parses for sentence k and it is not the best parse.", "labels": [], "entities": []}, {"text": "There are about 60000 samples in each slice in average.", "labels": [], "entities": []}, {"text": "For the tree kernel SVMs of Model 1, we take 3 slices as a chunk, and train an SVM for each chunk.", "labels": [], "entities": []}, {"text": "Due to the limitation of computing resource, we have only trained on 3 chunks.", "labels": [], "entities": []}, {"text": "The results of tree kernel SVMs are combined with simple combination.", "labels": [], "entities": []}, {"text": "Then the outcome is combined with the result of the linear kernel SVMs trained on features extracted from the derived trees which are reported in.", "labels": [], "entities": []}, {"text": "For each parse, the number of the brackets in it and the log-likelihood given by Collins' parser Model 2 are also used in the computation of the score of a parse.", "labels": [], "entities": []}, {"text": "For each parse p, its score Sco(p) is defined as follows: where MT (p) is the output of the tree kernel SVMs, M L (p) is the output of linear kernel SVMs, l(p) is the log-likelihood of parse p, and b(p) is the number of brackets in parse p.", "labels": [], "entities": []}, {"text": "We noticed that the SVM systems prefers to give higher scores to the parses with less brackets.", "labels": [], "entities": []}, {"text": "As a result, the system has a high precision but a low recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 35, "end_pos": 44, "type": "METRIC", "confidence": 0.9994034767150879}, {"text": "recall", "start_pos": 55, "end_pos": 61, "type": "METRIC", "confidence": 0.9991758465766907}]}, {"text": "Therefore, we take the number of brackets, b(p), as a feature to make the recall and precision balanced.", "labels": [], "entities": [{"text": "recall", "start_pos": 74, "end_pos": 80, "type": "METRIC", "confidence": 0.9992478489875793}, {"text": "precision", "start_pos": 85, "end_pos": 94, "type": "METRIC", "confidence": 0.9989323019981384}]}, {"text": "The three weight parameters are tuned on the development data.", "labels": [], "entities": []}, {"text": "The results are shown in with \u2264 100 words.", "labels": [], "entities": []}, {"text": "Our results show a 17% relative difference inf -score improvement over the use of a linear kernel without LTAG based features.", "labels": [], "entities": []}, {"text": "In addition, we also get non-trivial improvement on the number of crossing brackets.", "labels": [], "entities": []}, {"text": "These results verify the benefit of using LTAG based features and confirm the hypothesis that LTAG based features provide a novel set of abstract features that complement the hand selected features from).", "labels": [], "entities": []}, {"text": "Our results on Model 1 show a 1% error reduction on the previous best reranking result using the dataset reported in).", "labels": [], "entities": [{"text": "error", "start_pos": 33, "end_pos": 38, "type": "METRIC", "confidence": 0.987159252166748}]}, {"text": "Also, Model 1 provides a 10% reduction in error over () where the features from tree kernel were over arbitrary sub-trees.", "labels": [], "entities": [{"text": "error", "start_pos": 42, "end_pos": 47, "type": "METRIC", "confidence": 0.9607921242713928}]}, {"text": "For Model 2, we first train 22 SVMs on 22 distinct slices.", "labels": [], "entities": []}, {"text": "Then we combine the results of individual SVMs with simple combination.", "labels": [], "entities": []}, {"text": "However, the overall performance does not improve.", "labels": [], "entities": []}, {"text": "But we notice that the use of LTAG based features gives rise to improvement on most of the single SVMs, as shown in.", "labels": [], "entities": []}, {"text": "We think there are several reasons to account for why our Model 2 doesn't work as well for the full task when compared with Model 1.", "labels": [], "entities": []}, {"text": "Firstly, the training slice is not large enough.", "labels": [], "entities": []}, {"text": "Local optimization on each slice does not result in global optimization (as seen in.", "labels": [], "entities": []}, {"text": "Secondly, the LTAG based features that we have used in the linear kernel in Model 2 are not as useful as the tree kernel in Model 1.", "labels": [], "entities": []}, {"text": "The last reason is that we do not set the importance of LTAG based features.", "labels": [], "entities": []}, {"text": "One shortcoming of kernel methods is that the coefficient of each feature must beset before the training).", "labels": [], "entities": []}, {"text": "In our case, we do not tune the coefficients for the LTAG based features in Model 2.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. With Model  1, we achieve LR/LP of 89.7%/90.0% on sentences", "labels": [], "entities": [{"text": "LR/LP", "start_pos": 36, "end_pos": 41, "type": "METRIC", "confidence": 0.9088371992111206}]}]}