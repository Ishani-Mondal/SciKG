{"title": [{"text": "Named Entity Recognition through Classifier Combination", "labels": [], "entities": [{"text": "Named Entity Recognition", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.6004058420658112}]}], "abstractContent": [{"text": "This paper presents a classifier-combination experimental framework for named entity recognition in which four diverse classi-fiers (robust linear classifier, maximum en-tropy, transformation-based learning, and hidden Markov model) are combined under different conditions.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 72, "end_pos": 96, "type": "TASK", "confidence": 0.6254169940948486}]}, {"text": "When no gazetteer or other additional training resources are used, the combined system attains a performance of 91.6F on the English development data; integrating name, location and person gazetteers, and named entity systems trained on additional, more general, data reduces the F-measure error by a factor of 15 to 21% on the English data.", "labels": [], "entities": [{"text": "English development data", "start_pos": 125, "end_pos": 149, "type": "DATASET", "confidence": 0.6460701823234558}, {"text": "F-measure error", "start_pos": 280, "end_pos": 295, "type": "METRIC", "confidence": 0.963156521320343}, {"text": "English data", "start_pos": 328, "end_pos": 340, "type": "DATASET", "confidence": 0.7829384803771973}]}], "introductionContent": [{"text": "This paper investigates the combination of a set of diverse statistical named entity classifiers, including a rule-based classifier -the transformation-based learning classifier, henceforth fnTBL) with the forward-backward extension, a hidden Markov model classifier (henceforth HMM), similar to the one described in, a robust risk minimization classifier, based on a regularized winnow method () (henceforth RRM) and a maximum entropy classifier () (henceforth MaxEnt).", "labels": [], "entities": []}, {"text": "This particular set of classifiers is diverse across multiple dimensions, making it suitable for combination: \u2022 fnTBL is a discriminant classifier -it bases its classification decision only on the few most discriminant features active on an example -while HMM, RRM and MaxEnt are agglomerative classifiers -their decision is based on the combination of all features active for the particular example.", "labels": [], "entities": []}, {"text": "\u2022 In dealing with the data sparseness problem, fnTBL, MaxEnt and RRM investigate and integrate in their decision arbitrary feature types, while HMM is dependent on a prespecified back-off path.", "labels": [], "entities": [{"text": "fnTBL", "start_pos": 47, "end_pos": 52, "type": "DATASET", "confidence": 0.9128023386001587}]}, {"text": "\u2022 The search methods employed by each classifier are different: the HMM, MaxEnt and RRM classifiers construct a model for each example and then rely on a sequence search such as the Viterbi algorithm to identify the best overall sequence, while fnTBL starts with most frequent classification (usually per token), and then dynamically models the interaction between classifications, effectively performing the search at training time.", "labels": [], "entities": []}, {"text": "\u2022 The classifiers also differ in their output: fnTBL and RRM return a single classification per example 1 , while the MaxEnt and HMM classifiers return a probability distribution.", "labels": [], "entities": []}, {"text": "The remainder of the paper is organized as follows: Section 2 describes the features used by the classifiers, Section 3 briefly describes the algorithms used by each classifier, and Section 4 analyzes in detail the results obtained by each classifier and their combination.", "labels": [], "entities": []}], "datasetContent": [{"text": "The results obtained by each individual classifier, broken down by entity type, are presented in.", "labels": [], "entities": []}, {"text": "Out of the four classifiers, the MaxEnt and RRM classifiers are the best performers, followed by the modified fnTBL classifier and the HMM classifier.", "labels": [], "entities": []}, {"text": "The error-based classifiers (RRM and fnTBL) tend to obtain balanced precision/recall numbers, while the other two tend to be more precise at the expense of recall.", "labels": [], "entities": [{"text": "RRM", "start_pos": 29, "end_pos": 32, "type": "METRIC", "confidence": 0.7618812322616577}, {"text": "fnTBL", "start_pos": 37, "end_pos": 42, "type": "DATASET", "confidence": 0.735954225063324}, {"text": "precision", "start_pos": 68, "end_pos": 77, "type": "METRIC", "confidence": 0.9952795505523682}, {"text": "recall", "start_pos": 78, "end_pos": 84, "type": "METRIC", "confidence": 0.8961774706840515}, {"text": "recall", "start_pos": 156, "end_pos": 162, "type": "METRIC", "confidence": 0.9981549382209778}]}, {"text": "To facilitate comparison with other classifiers for this task, most reported results are obtained by using features exclusively extracted from the training data.", "labels": [], "entities": []}, {"text": "In general, given n classifiers, one can interpret the classifier combination framework as combining probability distributions: where Ci is the classifier i's classification output, f is a combination function.", "labels": [], "entities": []}, {"text": "This way, the entire training data can be used to estimate the weight parameters \u03bb i (w) and P i (C|w, Ci ) but, at decoding time, the individual classifier outputs Ci are computed by using the entire training data.", "labels": [], "entities": []}, {"text": "presents the combination results, for different ways of estimating the interpolation parameters.", "labels": [], "entities": []}, {"text": "A simple combination method is the equal voting method, where the parameters are computed as \u03bb i (w) = 1 n and P i (C|w, Ci ) = \u03b4 (C, Ci ), where \u03b4 is the Kronecker operator (\u03b4 (x, y) := (x = y?1 : 0)) -each of the classifiers votes with equal weight for the class that is most likely under its model, and the class receiving the largest number of votes wins.", "labels": [], "entities": []}, {"text": "However, this procedure may lead to ties, where some classes receive the same number of votes -one usually resorts to randomly selecting one of the tied candidates in this case - presents the average results obtained by this method, together with the variance obtained over 30 trials.", "labels": [], "entities": []}, {"text": "To make the decision deterministically, the weights associated with the classifiers can be chosen as \u03bb i (w) = P i (error).", "labels": [], "entities": []}, {"text": "In this method, presented in as weighted voting, better performing classifiers will have a higher impact in the final classification.", "labels": [], "entities": []}, {"text": "In the voting methods, each classifier gave its entire vote to one class -its own output.", "labels": [], "entities": []}, {"text": "However, Equation (2) allows for classifiers to give partial credit to alternative classifications, through the probability P i (C|w, Ci ).", "labels": [], "entities": []}, {"text": "3: Word statistics (percent unknown words) In our experiments, this value is computed through 5-fold cross-validation on the training data.", "labels": [], "entities": []}, {"text": "The space of possible choices for C, wand Ci is large enough to make the estimation unreliable, so we use two approximations, named Model 1 and Model 2 in: respectively.", "labels": [], "entities": []}, {"text": "On the development data, the former estimation type obtains a lower performance than the latter.", "labels": [], "entities": []}, {"text": "Ina last experiment using only features extracted from the training data, we use the RRM method to compute the function fin Equation (1), allowing the system to select a good performing combination of features.", "labels": [], "entities": [{"text": "RRM", "start_pos": 85, "end_pos": 88, "type": "METRIC", "confidence": 0.8616341948509216}, {"text": "fin Equation (1", "start_pos": 120, "end_pos": 135, "type": "METRIC", "confidence": 0.8903656452894211}]}, {"text": "At training time, the system was fed the output of each classifier on the cross-classified data, the part-of-speech and chunk boundary tags.", "labels": [], "entities": []}, {"text": "At test time, the system was fed the classifications of each system trained on the entire training data, and the corresponding POS and chunk boundary tags.", "labels": [], "entities": []}, {"text": "The result obtained rivals the one obtained by model 2, both displaying a 17% reduction in F-measure error 4 , indicating that maybe all sources of information have been explored and incorporated.", "labels": [], "entities": [{"text": "F-measure error 4", "start_pos": 91, "end_pos": 108, "type": "METRIC", "confidence": 0.9879140456517538}]}, {"text": "The RRM method is showing its combining power when additional information sources are used.", "labels": [], "entities": []}, {"text": "Specifically, the system was fed additional feature streams from a list of gazetteers and the output of two other named entity systems trained on 1.7M words annotated with 32 name categories.", "labels": [], "entities": []}, {"text": "The RRM system alone obtains an Fmeasure of 92.1, and can effectively integrate these information streams with the output of the four classifiers, gazetteers and the two additional classifiers into obtaining 93.9 F-measure, as detailed in, a 21% reduction in F-measure error.", "labels": [], "entities": [{"text": "Fmeasure", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9948392510414124}, {"text": "F-measure error", "start_pos": 259, "end_pos": 274, "type": "METRIC", "confidence": 0.9308932423591614}]}, {"text": "In contrast, combination model 2 obtains only a performance of 92.4, showing its limitations in combining diverse sources of information.", "labels": [], "entities": []}, {"text": "German poses a completely different problem for named entity recognition: the data is considerably sparser.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 48, "end_pos": 72, "type": "TASK", "confidence": 0.6960959235827128}]}, {"text": "shows the relative distribution of unknown words in the development and test corpora.", "labels": [], "entities": []}, {"text": "We note that the numbers are roughly twice as large for the development data in German as they are for English.", "labels": [], "entities": []}, {"text": "Since the unknown words are classed by most classifiers, this results in few data points to estimate classifier combinations.", "labels": [], "entities": []}, {"text": "Also, specifically for the German data, traditional approaches which utilize capitalization do notwork as well as in English, because all nouns are capitalized in German.", "labels": [], "entities": []}, {"text": "For German, in addition to the entity lists provided, we also used a small gazetteer of names (4500 first and last names, 4800 locations in Germany and 190 countries), which was collected by browsing web pages in about two person-hours.", "labels": [], "entities": []}, {"text": "The average classifier performance gain by using these features is about 1.5F for the testa data and about .6F for the testb data.", "labels": [], "entities": []}], "tableCaptions": []}