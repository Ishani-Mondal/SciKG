{"title": [{"text": "PhraseNet: Towards Context Sensitive Lexical Semantics *", "labels": [], "entities": [{"text": "Context Sensitive Lexical Semantics", "start_pos": 19, "end_pos": 54, "type": "TASK", "confidence": 0.72310870885849}]}], "abstractContent": [{"text": "This paper introduces PhraseNet, a context-sensitive lexical semantic knowledge base system.", "labels": [], "entities": []}, {"text": "Based on the supposition that semantic proximity is not simply a relation between two words in isolation, but rather a relation between them in their context, English nouns and verbs, along with contexts they appear in, are organized in PhraseNet into Consets; Con-sets capture the underlying lexical concept, and are connected with several semantic relations that respect contextually sensitive lexical information.", "labels": [], "entities": []}, {"text": "PhraseNet makes use of WordNet as an important knowledge source.", "labels": [], "entities": [{"text": "PhraseNet", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.8786337375640869}, {"text": "WordNet", "start_pos": 23, "end_pos": 30, "type": "DATASET", "confidence": 0.9653340578079224}]}, {"text": "It enhances a WordNet synset with its contextual information and refines its relational structure by maintaining only those relations that respect con-textual constraints.", "labels": [], "entities": []}, {"text": "The contextual information allows for supporting more functionali-ties compared with those of WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 94, "end_pos": 101, "type": "DATASET", "confidence": 0.9588356018066406}]}, {"text": "Natural language researchers as well as linguists and language learners can gain from accessing PhraseNet with a word token and its context, to retrieve relevant semantic information.", "labels": [], "entities": []}, {"text": "We describe the design and construction of PhraseNet and give preliminary experimental evidence to its usefulness for NLP researches.", "labels": [], "entities": [{"text": "NLP researches", "start_pos": 118, "end_pos": 132, "type": "TASK", "confidence": 0.8942976295948029}]}], "introductionContent": [{"text": "Progress in natural language understanding research necessitates significant progress in lexical semantics and the development of lexical semantics resources.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 12, "end_pos": 42, "type": "TASK", "confidence": 0.6413667500019073}]}, {"text": "Ina broad range of natural language applications, from * Research supported by NSF grants IIS-99-84168, ITR-IIS-00-85836 and an ONR MURI award.", "labels": [], "entities": [{"text": "NSF grants IIS-99-84168", "start_pos": 79, "end_pos": 102, "type": "DATASET", "confidence": 0.7020746072133383}, {"text": "ONR", "start_pos": 128, "end_pos": 131, "type": "DATASET", "confidence": 0.5036801695823669}, {"text": "MURI", "start_pos": 132, "end_pos": 136, "type": "METRIC", "confidence": 0.7626475691795349}]}, {"text": "Names of authors are listed alphabetically.", "labels": [], "entities": []}, {"text": "prepositional phrase attachment), co-reference resolution) to text summarization), semantic information is a necessary component in the inference, by providing a level of abstraction that is necessary for robust decisions.", "labels": [], "entities": [{"text": "prepositional phrase attachment", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.5997144281864166}, {"text": "co-reference resolution", "start_pos": 34, "end_pos": 57, "type": "TASK", "confidence": 0.7251778244972229}, {"text": "text summarization", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.6261696517467499}]}, {"text": "Inducing that the prepositional phrase in \"They ate a cake with a fork\" has the same grammatical function as that in \"They ate a cake with a spoon\", for example, depends on the knowledge that \"cutlery\" and \"tableware\" are the hypernyms of both \"fork\" and \"spoon\".", "labels": [], "entities": []}, {"text": "However, the noun \"fork\" has five senses listed in WordNet and each of them has several different hypernyms.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 51, "end_pos": 58, "type": "DATASET", "confidence": 0.972687840461731}]}, {"text": "Choosing the correct one is a context sensitive decision.", "labels": [], "entities": []}, {"text": "WordNet, a manually constructed lexical reference system provides a lexical database along with semantic relations among the lexemes of English and is widely used in NLP tasks today.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9559948444366455}]}, {"text": "However, WordNet is organized at the word level, and at this level, English suffers ambiguities.", "labels": [], "entities": []}, {"text": "Stand-alone words may have several meanings and take on relations (e.g., hypernyms, hyponyms) that depend on their meanings.", "labels": [], "entities": []}, {"text": "Consequently, there are very few success stories of automatically using WordNet in natural language applications.", "labels": [], "entities": []}, {"text": "In many cases, reported (and unreported) problems are due to the fact that WordNet enumerates all the senses of polysemous words; attempts to use this resource automatically often result in noisy and non-uniform information).", "labels": [], "entities": []}, {"text": "PhraseNet is designed based on the assumption that, by and large, semantic ambiguity in English disappears when local context of words is taken into account.", "labels": [], "entities": []}, {"text": "It makes use of WordNet as an important knowledge source and is generated automatically using WordNet and machine learning based processing of large English corpora.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 16, "end_pos": 23, "type": "DATASET", "confidence": 0.9590446352958679}, {"text": "WordNet", "start_pos": 94, "end_pos": 101, "type": "DATASET", "confidence": 0.9663496613502502}]}, {"text": "It enhances a WordNet synset with its contextual information and refines its relational structure, including relations such as hypernym, hyponym, antonym and synonym, by maintaining only those links that respect contextual constraints.", "labels": [], "entities": []}, {"text": "However, PhraseNet is not just a functional extension of WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 57, "end_pos": 64, "type": "DATASET", "confidence": 0.9604299068450928}]}, {"text": "It is an independent lexical semantic system allied with proper user interfaces and access functions that will allow researchers and practitioners to use it in applications.", "labels": [], "entities": []}, {"text": "As stated before, PhraseNet, is built on the assumption that linguistic context is an indispensable factor affecting the perception of a semantic proximity between words.", "labels": [], "entities": []}, {"text": "PhraseNet captures such constraints from the contextual structures extracted automatically from natural language corpora and enumerates word lists with their hierarchical contextual information.", "labels": [], "entities": []}, {"text": "Several abstractions are made in the process of extracting the context in order to prevent superfluous information and support generalization.", "labels": [], "entities": []}, {"text": "The basic unit in PhraseNet is a conset, a word in its context, together with all relations associated with it.", "labels": [], "entities": []}, {"text": "In the lexical database, consets are chained together via their similar or hierarchical contexts.", "labels": [], "entities": []}, {"text": "By listing every context extracted from large corpora and all the generalized contexts based on those attested sentences, PhraseNet will have much more consets than synsets in WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 176, "end_pos": 183, "type": "DATASET", "confidence": 0.953405499458313}]}, {"text": "However, the organization of PhraseNet respects the syntactic structure together with the distinction of senses of each word in its corresponding contexts.", "labels": [], "entities": []}, {"text": "For example, rather than linking all hypernyms of a polysemous word to a single word token, PhraseNet connects the hypernym of each sense to the target word in every context that instantiates that sense.", "labels": [], "entities": []}, {"text": "While in WordNet every word has an average of 5.4 hypernyms, in PhraseNet, the average number of hypernyms of a word in a conset is 1.5 1 . In addition to querying WordNet semantic relations to disambiguate consets, PhraseNet also maintains fre-quency records of each word in its context to help differentiate consets and makes use of defined similarity between contexts in this process 2 . Several access functions are built into PhraseNet that allow retrieving information relevant to a word and its context.", "labels": [], "entities": []}, {"text": "When accessed with words and their contextual information, the system tends to output more relevant semantic information due to the constraint set by their syntactic contexts.", "labels": [], "entities": []}, {"text": "While still in preliminary stages of development and experimentation and with a lot of functionalities still missing, we believe that PhraseNet is an important effort towards building a contextually sensitive lexical semantic resource, that will be of much value to NLP researchers as well as linguists and language learners.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "2 presents the design principles of PhraseNet.", "labels": [], "entities": [{"text": "PhraseNet", "start_pos": 36, "end_pos": 45, "type": "DATASET", "confidence": 0.7828885912895203}]}, {"text": "3 describes the construction of PhraseNet and the current stage of the implementation.", "labels": [], "entities": []}, {"text": "An application that provides a preliminary experimental evaluation is described in Sec.", "labels": [], "entities": []}, {"text": "5 discuses some related work on lexical semantics resources and Sec.", "labels": [], "entities": []}, {"text": "6 discusses future directions within PhraseNet.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we provide a first evaluation of PhraseNet.", "labels": [], "entities": [{"text": "PhraseNet", "start_pos": 49, "end_pos": 58, "type": "DATASET", "confidence": 0.5909175872802734}]}, {"text": "We do that in the context of a learning task.", "labels": [], "entities": []}, {"text": "Learning tasks in NLP are typically modelled as classification tasks, where one seeks a mapping g : X \u2192 c 1 , ..., ck , that maps an instance x \u2208 X (e.g., a sentence) to one of c 1 , ..., ck -representing some properties of the instance (e.g., a part-of-speech tag of a word in the context of the sentence).", "labels": [], "entities": []}, {"text": "Typically, the raw representation -sentence or document -are first mapped to some feature based representation, and then a learning algorithm is applied to learn a mapping from this representation to the desired property.", "labels": [], "entities": []}, {"text": "It is clear that inmost cases representing the mapping gin terms of the raw representation of the input instance -words and their order -is very complex.", "labels": [], "entities": []}, {"text": "Functionally simple representations of this mapping can only be formed if we augment the information that is readily available in the input instance with additional, more abstract information.", "labels": [], "entities": []}, {"text": "For example, it is common to augment sentence representations with syntactic categories -part-of-speech (POS), under the assumption that the sought-after property, for which we seek the classifier, depends on the syntactic role of a word in the sentence rather than the specific word.", "labels": [], "entities": []}, {"text": "Similar logic can be applied to semantic categories.", "labels": [], "entities": []}, {"text": "In many cases, the property seems not to depend on the specific word used in the sentence -that could be replaced without affecting this property -but rather on its 'meaning'.", "labels": [], "entities": []}, {"text": "In this section we show the benefit of using PhraseNet in doing that in the context of Question Classification.", "labels": [], "entities": [{"text": "Question Classification", "start_pos": 87, "end_pos": 110, "type": "TASK", "confidence": 0.7029498815536499}]}, {"text": "Question classification (QC) is the task of determining the semantic class of the answer of a given question.", "labels": [], "entities": [{"text": "Question classification (QC)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8904412984848022}]}, {"text": "For example, given the question: \"What Cuban dictator did Fidel Castro force out of power in 1958?\" we would like to determine that its answer should be a name of a person.", "labels": [], "entities": []}, {"text": "Our approach to QC follows that of ().", "labels": [], "entities": []}, {"text": "The question classifier used is a multi-class classifier which can classify a question into one of 50 fine-grained classes.", "labels": [], "entities": []}, {"text": "The baseline classifier makes use of syntactic features like the standard POS information and information extracted by a shallow parser in addition to the words in the sentence.", "labels": [], "entities": []}, {"text": "The classifier is then augmented with standard WordNet or with PhraseNet information as follows.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 47, "end_pos": 54, "type": "DATASET", "confidence": 0.9600499272346497}]}, {"text": "In all cases, words in the sentence are augmented with additional words that are supposed to be semantically related to them.", "labels": [], "entities": []}, {"text": "The intuition, as described above, is that this provides a level of abstract -we could have potentially seen an equivalent question, where other \"equivalent\" words occur.", "labels": [], "entities": []}, {"text": "For WordNet, for each word in a question, all its hypernyms are added to its feature based representation (in addition to the syntactic features).", "labels": [], "entities": [{"text": "WordNet", "start_pos": 4, "end_pos": 11, "type": "DATASET", "confidence": 0.9211936593055725}]}, {"text": "For PhraseNet, for each word in a question, all the words in the corresponding conset wordlist are added (where the context is supplied by the question).", "labels": [], "entities": []}, {"text": "Our experiments compare the three pruning operations described above.", "labels": [], "entities": []}, {"text": "Training is done on a data set of 21,500 questions.", "labels": [], "entities": []}, {"text": "Performance is evaluated by the precision of classifying 1,000 test questions, defined as follows: presents the classification precision before and after incorporating WordNet and PhraseNet information into the classifier.", "labels": [], "entities": [{"text": "precision", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9988834261894226}, {"text": "WordNet", "start_pos": 168, "end_pos": 175, "type": "DATASET", "confidence": 0.9360644221305847}]}, {"text": "By augmenting the question classifier with PhraseNet information, even in this preliminary stage, the error rate of the classifier can be reduced by 12%, while an equivalent use of WordNet information reduces the error by only 5.7%.", "labels": [], "entities": [{"text": "error rate", "start_pos": 102, "end_pos": 112, "type": "METRIC", "confidence": 0.9814707338809967}]}], "tableCaptions": [{"text": " Table 2: Question Classification with PhraseNet Informa-", "labels": [], "entities": [{"text": "Question Classification", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.831457793712616}]}]}