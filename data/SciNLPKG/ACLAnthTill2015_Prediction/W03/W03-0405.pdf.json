{"title": [], "abstractContent": [{"text": "This paper presents a set of algorithms for distinguishing personal names with multiple real referents in text, based on little or no supervision.", "labels": [], "entities": [{"text": "distinguishing personal names with multiple real referents in text", "start_pos": 44, "end_pos": 110, "type": "TASK", "confidence": 0.78289266427358}]}, {"text": "The approach utilizes an unsupervised clustering technique over a rich feature space of biographic facts, which are automatically extracted via a language-independent bootstrapping process.", "labels": [], "entities": []}, {"text": "The induced clustering of named entities are then partitioned and linked to their real referents via the automatically extracted biographic data.", "labels": [], "entities": []}, {"text": "Performance is evaluated based on both a test set of hand-labeled multi-referent personal names and via automatically generated pseudonames.", "labels": [], "entities": []}], "introductionContent": [{"text": "One open problem in natural language ambiguity resolution is the task of proper noun disambiguation . While word senses and translation ambiguities may typically have 2-20 alternative meanings that must be resolved through context, a personal name such as \"Jim Clark\" may potentially refer to hundreds or thousands of distinct individuals.", "labels": [], "entities": [{"text": "natural language ambiguity resolution", "start_pos": 20, "end_pos": 57, "type": "TASK", "confidence": 0.7159458100795746}, {"text": "proper noun disambiguation", "start_pos": 73, "end_pos": 99, "type": "TASK", "confidence": 0.6213067770004272}]}, {"text": "Each different referent typically has some distinct contextual characteristics.", "labels": [], "entities": []}, {"text": "These characteristics can help distinguish, resolve and trace the referents when the surface names appear in online documents.", "labels": [], "entities": []}, {"text": "A search of Google shows 76,000 web pages mentioning Jim Clark, of which the first 10 unique referents are:.", "labels": [], "entities": [{"text": "Jim Clark", "start_pos": 53, "end_pos": 62, "type": "DATASET", "confidence": 0.821511298418045}]}, {"text": "Jim Clark -Race car driver from Scotland 2.", "labels": [], "entities": [{"text": "Scotland 2", "start_pos": 32, "end_pos": 42, "type": "DATASET", "confidence": 0.9530057609081268}]}, {"text": "Jim Clark -Clockmaker from Colorado 3.", "labels": [], "entities": [{"text": "Clockmaker from Colorado 3", "start_pos": 11, "end_pos": 37, "type": "DATASET", "confidence": 0.7613979279994965}]}, {"text": "Jim Clark -Film Editor 4.", "labels": [], "entities": [{"text": "Film Editor", "start_pos": 11, "end_pos": 22, "type": "DATASET", "confidence": 0.8397587537765503}]}, {"text": "Jim Clark -Netscape Founder 5.", "labels": [], "entities": [{"text": "Netscape Founder 5", "start_pos": 11, "end_pos": 29, "type": "DATASET", "confidence": 0.8639724651972452}]}, {"text": "Jim Clark -Disaster Survivor 6.", "labels": [], "entities": [{"text": "Disaster Survivor 6", "start_pos": 11, "end_pos": 30, "type": "TASK", "confidence": 0.6452112793922424}]}, {"text": "Jim Clark -Car Salesman in Kansas 7.", "labels": [], "entities": [{"text": "Car Salesman", "start_pos": 11, "end_pos": 23, "type": "TASK", "confidence": 0.7193374335765839}, {"text": "Kansas 7", "start_pos": 27, "end_pos": 35, "type": "DATASET", "confidence": 0.8277525305747986}]}, {"text": "Jim Clark -Fishing Instructor in Canada 8.", "labels": [], "entities": []}, {"text": "Jim Clark -Computer Science student in Hong Kong 9.", "labels": [], "entities": [{"text": "Computer Science student in Hong Kong 9", "start_pos": 11, "end_pos": 50, "type": "DATASET", "confidence": 0.6577692968504769}]}, {"text": "Jim Clark -Professor at McGill 10.", "labels": [], "entities": [{"text": "McGill 10", "start_pos": 24, "end_pos": 33, "type": "DATASET", "confidence": 0.9594709873199463}]}, {"text": "Jim In this paper, we present a method for distinguishing the real world referent of a given name in context.", "labels": [], "entities": [{"text": "distinguishing the real world referent of a given name in context", "start_pos": 43, "end_pos": 108, "type": "TASK", "confidence": 0.7863291285254739}]}, {"text": "Approaches to this problem include, focusing on the variation of surface name fora given referent, and, resolving geographic name ambiguity.", "labels": [], "entities": []}, {"text": "We present preliminary evaluation on pseudonames: conflations of multiple personal names, constructed in the same way pseudowords are used for word sense disambiguation (.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 143, "end_pos": 168, "type": "TASK", "confidence": 0.6327198147773743}]}, {"text": "We then present corroborating evidence from real personal name polysemy to show that this technique works in practice.", "labels": [], "entities": []}, {"text": "Another topic of recent interest is in producing biographical summaries from corpora ().", "labels": [], "entities": []}, {"text": "Along with disambiguation, our system simultaneously collects biographic information (Table 1).", "labels": [], "entities": []}, {"text": "The relevant biographical attributes are depicted along with a clustering which shows the distinct referents (Section 4.1).", "labels": [], "entities": []}], "datasetContent": [{"text": "For automated pseudoname evaluation purposes, we selected a set of 8 different people for conflation, who we presumed had one vastly predominant sense.", "labels": [], "entities": [{"text": "pseudoname evaluation", "start_pos": 14, "end_pos": 35, "type": "TASK", "confidence": 0.734031468629837}]}, {"text": "We selected these people giving room for historical figures, figures from pop culture and modern media culture, as well as \"ordinary\" people.", "labels": [], "entities": []}, {"text": "We added people with similar backgrounds (born close to each other, or having the same profession).", "labels": [], "entities": []}, {"text": "The full list was composed of these 8 individuals: Haifa Al-Faisal, William Blake, Tom Cruise, Woody Harrelson, Hermann Hesse, Wolfgang Amadeus Mozart, Anna Shusterman, Bryon Tosoff For each, we submitted Google queries, and retrieved up to 1000 pages each.", "labels": [], "entities": []}, {"text": "We then took these hit returns, and subsampled to a maximum of 100 pages per person.", "labels": [], "entities": []}, {"text": "The person with the smallest representation was Anna Shusterman with 26 pages.", "labels": [], "entities": []}, {"text": "We subsampled by taking the first 100 as ordered lexically.", "labels": [], "entities": []}, {"text": "This may have biased the results somewhat towards unreliable web pages, since pages with numeric addresses tend to be newer and more transient.", "labels": [], "entities": []}, {"text": "We evaluated two guanularities of feature extraction.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 34, "end_pos": 52, "type": "TASK", "confidence": 0.7642624378204346}]}, {"text": "The small feature set uses high precision rules to extract occupation (occ), birthday (brthyr), spouse, birth location (brthloc), and school.", "labels": [], "entities": [{"text": "birthday (brthyr)", "start_pos": 77, "end_pos": 94, "type": "METRIC", "confidence": 0.868509829044342}]}, {"text": "The large feature set adds higher recall (and therefore noisier) patterns for the previous relationships and as well as parent/child relationships.", "labels": [], "entities": [{"text": "recall", "start_pos": 34, "end_pos": 40, "type": "METRIC", "confidence": 0.9991169571876526}]}, {"text": "As can be seen from the table, the highest performing system combines proper nouns, relevant words, and the high precision extracted features (nnp+feat+mi and nnp+feat+tfidf).", "labels": [], "entities": []}, {"text": "The extended features (nnp+feat+extfeat+mi) do not give additional benefit to this combination.", "labels": [], "entities": []}, {"text": "As can be seen from the table, the large feature set yields better overall performance than the smaller feature set.", "labels": [], "entities": []}, {"text": "For the feat+tfidf system, accuracy at the twoclass disambiguation was above 80% for 25 out of the 28 pairs.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.99967360496521}]}, {"text": "Without these pairs, the average twoclass disambiguation performance over the remaining pairs is 90%.", "labels": [], "entities": []}, {"text": "In two of the problematic cases, the contexts of the names are easily confusable, as the individuals share the same profession and many of the same keywords.", "labels": [], "entities": []}, {"text": "More complete biographic profiles and different clustering biases would be helpful in fully partitioning these cases.", "labels": [], "entities": []}, {"text": "However, in practice these pseudoname pair situations maybe more difficult than expected for naturally occurring name pairs.", "labels": [], "entities": []}, {"text": "In many occupations that are typically newsworthy (such as actors, authors, musicians, politicians, etc.), there maybe a tendency for individuals to avoid using identical names (or entering the field entirely) to minimize confusion.", "labels": [], "entities": []}, {"text": "When people with identical names do indeed share the same field one would expect a greater effort to providing disambiguating contextual features to distinguish them.", "labels": [], "entities": []}, {"text": "The above results have utilized pseudoname test sets where high accuracy ground truth is automatically available in large quantities [O(1000) examples per name] to better distinguish model performance.", "labels": [], "entities": [{"text": "O", "start_pos": 134, "end_pos": 135, "type": "METRIC", "confidence": 0.97333163022995}]}, {"text": "Table 6 shows the performance on the four O(60) example hand-labeled test sets for naturally occurring polysemous person names.", "labels": [], "entities": [{"text": "O", "start_pos": 42, "end_pos": 43, "type": "METRIC", "confidence": 0.9606525301933289}]}, {"text": "Given that this is an n-ary classification task, for consistency with the above experiments the data were assigned to one of 3 clusters, corresponding to the 2 automatically derived first-pass majority seed sets and the residual \"other-use\" classification, but evaluated strictly on performance for the two major senses.", "labels": [], "entities": []}, {"text": "While additional analyses could be accomplished on the residual sets, this is difficult given their small size (remaining personal exemplars were mostly singletons) and lack of evidence on many single-mention web pages.", "labels": [], "entities": []}, {"text": "Thus the task of accurately partitioning the two most common uses and clustering the residual examples for visual exploration maybe a natural and practical use for these classification and visualization technologies.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Highest Precision Patterns Extracted for English and Spanish using Suffix Tree Methodology", "labels": [], "entities": [{"text": "Highest Precision Patterns Extracted", "start_pos": 10, "end_pos": 46, "type": "TASK", "confidence": 0.6489522010087967}]}, {"text": " Table 3: The 10 words with highest mutual infor- mation with the document collection and all of ex- tended feature words for DAVIS/HARRELSON pseudon- ame", "labels": [], "entities": [{"text": "document collection", "start_pos": 66, "end_pos": 85, "type": "DATASET", "confidence": 0.7941182851791382}, {"text": "HARRELSON pseudon- ame", "start_pos": 132, "end_pos": 154, "type": "METRIC", "confidence": 0.5458426848053932}]}, {"text": " Table 5: Disambiguation Accuracy of different  Clustering Methods over 28 pseudonames", "labels": [], "entities": [{"text": "Disambiguation", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.9575884342193604}, {"text": "Accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9314597249031067}]}]}