{"title": [{"text": "Sentence Alignment for Monolingual Comparable Corpora", "labels": [], "entities": [{"text": "Sentence Alignment", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9762167632579803}]}], "abstractContent": [{"text": "We address the problem of sentence alignment for monolingual corpora, a phenomenon distinct from alignment in parallel corpora.", "labels": [], "entities": [{"text": "sentence alignment", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.7208350151777267}]}, {"text": "Aligning large comparable corpora automatically would provide a valuable resource for learning of text-to-text rewriting rules.", "labels": [], "entities": []}, {"text": "We incorporate context into the search for an optimal alignment in two complementary ways: learning rules for matching paragraphs using topic structure and further refining the matching through local alignment to find good sentence pairs.", "labels": [], "entities": []}, {"text": "Evaluation shows that our alignment method outperforms state-of-the-art systems developed for the same task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Text-to-text generation is an emerging area of research in NLP).", "labels": [], "entities": [{"text": "Text-to-text generation", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.7689415812492371}]}, {"text": "Unlike in traditional conceptto-text generation, text-to-text generation applications take a text as input and transform it into anew text satisfying specific constraints, such as length in summarization or style in text simplification.", "labels": [], "entities": [{"text": "conceptto-text generation", "start_pos": 22, "end_pos": 47, "type": "TASK", "confidence": 0.7567372620105743}, {"text": "text-to-text generation", "start_pos": 49, "end_pos": 72, "type": "TASK", "confidence": 0.7600626349449158}, {"text": "summarization", "start_pos": 190, "end_pos": 203, "type": "TASK", "confidence": 0.9634206891059875}]}, {"text": "One exciting new research direction is the automatic induction of such transformation rules.", "labels": [], "entities": []}, {"text": "This is a particularly promising direction given that there are naturally occurring examples of comparable texts that convey the same information yet are written in different styles.", "labels": [], "entities": []}, {"text": "Presented with two such texts, one can pair sentences that convey the same information, thereby building a training set of rewriting examples for the domain to which the texts belong.", "labels": [], "entities": []}, {"text": "We believe that automating this process will provide researchers in text-to-text generation with valuable training and testing resources, just as techniques to align multilingual parallel corpora boosted research in Machine Translation.", "labels": [], "entities": [{"text": "text-to-text generation", "start_pos": 68, "end_pos": 91, "type": "TASK", "confidence": 0.7332680970430374}, {"text": "Machine Translation", "start_pos": 216, "end_pos": 235, "type": "TASK", "confidence": 0.8125977218151093}]}, {"text": "In this paper, we address the task of aligning sentences in text pairs.", "labels": [], "entities": []}, {"text": "We focus on monolingual comparable corpora, that is, texts in the same language (e.g., English) that overlap in the information they convey.", "labels": [], "entities": []}, {"text": "Stories about the same events from different press agencies and texts presenting the same information to experts and laypeople are two examples.", "labels": [], "entities": []}, {"text": "In MT, the task of sentence alignment was extensively studied for parallel corpora.", "labels": [], "entities": [{"text": "MT", "start_pos": 3, "end_pos": 5, "type": "TASK", "confidence": 0.9843283891677856}, {"text": "sentence alignment", "start_pos": 19, "end_pos": 37, "type": "TASK", "confidence": 0.7397526800632477}]}, {"text": "1 A typical sentence alignment algorithm can be roughly described as a two-step process: (1) for each sentence pair compute a local similarity value, independently of the other sentences; (2) find an overall sequence of mapped sentences, using both the local similarity values and additional features.", "labels": [], "entities": [{"text": "sentence alignment", "start_pos": 12, "end_pos": 30, "type": "TASK", "confidence": 0.736465722322464}]}, {"text": "In the case of monolingual corpora, step (2) might seem unnecessary.", "labels": [], "entities": []}, {"text": "Since the texts share the same language, it would be enough to choose for local similarity a function based on lexical cues only and select sentence pairs with high lexical similarity.", "labels": [], "entities": []}, {"text": "Even a simple lexical function (e.g., one that counts word overlap) could produce an accurate alignment.", "labels": [], "entities": []}, {"text": "After all, two sentences which share most of their words are likely to paraphrase each other.", "labels": [], "entities": []}, {"text": "The problem is that there are many sentences that convey the same information but have little surface resemblance.", "labels": [], "entities": []}, {"text": "As a result, simple word counts cannot distinguish the matching pair (A) in from the unrelated pair (B).", "labels": [], "entities": []}, {"text": "An accurate local similarity measure would have to account for many complex paraphrasing phenomena.", "labels": [], "entities": []}, {"text": "A simple, weak lexical similarity function alone is not sufficient.", "labels": [], "entities": []}], "datasetContent": [{"text": "We compiled two collections from the Encyclopedia Britannica and Britannica Elementary.", "labels": [], "entities": [{"text": "Encyclopedia Britannica", "start_pos": 37, "end_pos": 60, "type": "DATASET", "confidence": 0.8051165044307709}, {"text": "Britannica Elementary", "start_pos": 65, "end_pos": 86, "type": "DATASET", "confidence": 0.9357879161834717}]}, {"text": "In contrast to the long (up to 15-page) detailed articles of the Encyclopedia Britannica, Britannica Elementary contains one-to two-page entries targeted towards children.", "labels": [], "entities": [{"text": "Britannica Elementary", "start_pos": 90, "end_pos": 111, "type": "DATASET", "confidence": 0.926185131072998}]}, {"text": "The elementary version generally contains a subset of the information presented in the comprehensive version, but there are numerous cases when the elementary entry contains additional or more up-to-date pieces of information.", "labels": [], "entities": []}, {"text": "The two collections together exhibit many instances of complex rewriting.", "labels": [], "entities": []}, {"text": "We collected 103 pairs of comprehensive/elementary city descriptions.", "labels": [], "entities": []}, {"text": "We set aside a testing set of 11 text pairs.", "labels": [], "entities": []}, {"text": "The rest (92 pairs) was used for the Vertical Clustering.", "labels": [], "entities": [{"text": "Vertical Clustering", "start_pos": 37, "end_pos": 56, "type": "TASK", "confidence": 0.6492374539375305}]}, {"text": "Nine text pairs were used for training (see for statistics).", "labels": [], "entities": []}, {"text": "Each text pair in the training and testing sets was annotated by two annotators.", "labels": [], "entities": []}, {"text": "In our guidelines to them, we defined two sentences as aligned if they contain at least one clause  that expresses the same information.", "labels": [], "entities": []}, {"text": "On average, each annotator spent 50 minutes per text pair.", "labels": [], "entities": []}, {"text": "While the annotators agreed for most of the sentence pairs they identified, there were some cases of disagreement.", "labels": [], "entities": []}, {"text": "Alignment is a tedious task, and sentence pairs can easily be missed even by a careful human annotator.", "labels": [], "entities": [{"text": "Alignment", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.9771885871887207}]}, {"text": "For each text pair, a third annotator went through contested sentence pairs, deciding on a case-by-case basis whether to include it in the alignment.", "labels": [], "entities": []}, {"text": "Overall, 320 sentence pairs were aligned in the training set and 281 in the testing set.", "labels": [], "entities": []}, {"text": "The other sentence pairs which were not aligned served as negative examples, yielding a total of 4192 training instances and 3884 testing instances.", "labels": [], "entities": []}, {"text": "As a confirmation that there is no order preservation in comparable corpora, there were up to nine order shifts in each of the annotated text pairs.", "labels": [], "entities": []}, {"text": "shows that a large fraction of manually aligned sentence pairs have low lexical similarity.", "labels": [], "entities": []}, {"text": "Similarity is measured hereby the number of words in common, normalized by the number of types in the shorter sentence.", "labels": [], "entities": []}, {"text": "We tuned all the parameters on our training set, obtaining the following values: the skip penalty is 0.001, and the cosine threshold for selecting pairs with high lexical similarity is 0.5.", "labels": [], "entities": [{"text": "skip penalty", "start_pos": 85, "end_pos": 97, "type": "METRIC", "confidence": 0.9844105243682861}]}, {"text": "BoosTexter was trained in 200 iterations.", "labels": [], "entities": [{"text": "BoosTexter", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.9360728859901428}]}, {"text": "To find the optimal number of clusters for each collection, Vertical Clustering was performed with different numbers of clusters, ranging from 10 to 40; we selected Our corpus is available at http://www.cs. columbia.edu/\u02dcnoemie/alignment.", "labels": [], "entities": []}, {"text": "the alternatives with the best performance on the training set: 20 for both collections.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics for the training and testing sets for  the comprehensive and elementary versions.", "labels": [], "entities": []}, {"text": " Table 2: Distribution of manually aligned sentence  pairs among different similarity ranges.", "labels": [], "entities": []}, {"text": " Table 3: Precision at 55.8% Recall.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9344671368598938}, {"text": "Recall", "start_pos": 29, "end_pos": 35, "type": "METRIC", "confidence": 0.9970622658729553}]}]}