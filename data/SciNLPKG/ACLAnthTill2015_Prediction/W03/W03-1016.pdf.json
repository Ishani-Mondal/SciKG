{"title": [{"text": "Statistical Acquisition of Content Selection Rules for Natural Language Generation", "labels": [], "entities": [{"text": "Statistical Acquisition of Content Selection", "start_pos": 0, "end_pos": 44, "type": "TASK", "confidence": 0.6614935398101807}]}], "abstractContent": [{"text": "A Natural Language Generation system produces text using as input semantic data.", "labels": [], "entities": [{"text": "Natural Language Generation", "start_pos": 2, "end_pos": 29, "type": "TASK", "confidence": 0.6744265258312225}]}, {"text": "One of its very first tasks is to decide which pieces of information to convey in the output.", "labels": [], "entities": []}, {"text": "This task, called Content Selection , is quite domain dependent, requiring considerable re-engineering to transport the system from one scenario to another.", "labels": [], "entities": [{"text": "Content Selection", "start_pos": 18, "end_pos": 35, "type": "TASK", "confidence": 0.8520017564296722}]}, {"text": "In this paper, we present a method to acquire content selection rules automatically from a corpus of text and associated semantics.", "labels": [], "entities": [{"text": "acquire content selection", "start_pos": 38, "end_pos": 63, "type": "TASK", "confidence": 0.5901649792989095}]}, {"text": "Our proposed technique was evaluated by comparing its output with information selected by human authors in unseen texts, where we were able to filter half the input data set without loss of recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 190, "end_pos": 196, "type": "METRIC", "confidence": 0.9957354068756104}]}], "introductionContent": [{"text": "CONTENT SELECTION is the task of choosing the right information to communicate in the output of a Natural Language Generation (NLG) system, given semantic input and a communicative goal.", "labels": [], "entities": [{"text": "CONTENT SELECTION", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.6573081910610199}]}, {"text": "In general, Content Selection is a highly domain dependent task; new rules must be developed for each new domain, and typically this is done manually.", "labels": [], "entities": [{"text": "Content Selection", "start_pos": 12, "end_pos": 29, "type": "TASK", "confidence": 0.8276691734790802}]}, {"text": "Morevoer, it has been argued () that Content Selection is the most important task from a user's standpoint (i.e., users may tolerate errors in wording, as long as the information being sought is present in the text).", "labels": [], "entities": [{"text": "Content Selection", "start_pos": 37, "end_pos": 54, "type": "TASK", "confidence": 0.8017149567604065}]}, {"text": "Designing content selection rules manually is a tedious task.", "labels": [], "entities": [{"text": "Designing content selection", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.8880326151847839}]}, {"text": "A realistic knowledge base contains a large amount of information that could potentially be included in a text and a designer must examine a sizable number of texts, produced in different situations, to determine the specific constraints for the selection of each piece of information.", "labels": [], "entities": []}, {"text": "Our goal is to develop a system that can automatically acquire constraints for the content selection task.", "labels": [], "entities": [{"text": "content selection task", "start_pos": 83, "end_pos": 105, "type": "TASK", "confidence": 0.7806819578011831}]}, {"text": "Our algorithm uses the information we learned from a corpus of desired outputs for the system (i.e., human-produced text) aligned against related semantic data (i.e., the type of data the system will use as input).", "labels": [], "entities": []}, {"text": "It produces constraints on every piece of the input where constraints dictate if it should appear in the output at all and if so, under what conditions.", "labels": [], "entities": []}, {"text": "This process provides a filter on the information to be included in a text, identifying all information that is potentially relevant (previously termed global focus or viewpoints).", "labels": [], "entities": []}, {"text": "The resulting information can be later either further filtered, ordered and augmented by later stages in the generation pipeline (e.g., seethe spreading activation algorithm used in ILEX ().", "labels": [], "entities": []}, {"text": "We focus on descriptive texts which realize a single, purely informative, communicative goal, as opposed to cases where more knowledge about speaker intentions are needed.", "labels": [], "entities": []}, {"text": "In particular, we present experiments on biographical descriptions, where the planned system will generate short paragraph length texts summarizing important facts about famous people.", "labels": [], "entities": [{"text": "biographical descriptions", "start_pos": 41, "end_pos": 66, "type": "TASK", "confidence": 0.7159766852855682}]}, {"text": "The kind of text that we aim to generate is shown in.", "labels": [], "entities": []}, {"text": "The rules that we aim to acquire will specify the kind of information that is typically included in any biography.", "labels": [], "entities": []}, {"text": "In some cases, whether Actor, born Thomas Connery on bridge, Edinburgh, Scotland, the son of a truck driver and charwoman.", "labels": [], "entities": []}, {"text": "He has a brother, Neil, born in 1938.", "labels": [], "entities": [{"text": "Neil", "start_pos": 18, "end_pos": 22, "type": "METRIC", "confidence": 0.9858625531196594}]}, {"text": "Connery dropped out of school at age fifteen to join the British Navy.", "labels": [], "entities": [{"text": "British Navy", "start_pos": 57, "end_pos": 69, "type": "DATASET", "confidence": 0.9368390142917633}]}, {"text": "Connery is best known for his portrayal of the suave, sophisticated British spy, James Bond, in the 1960s.", "labels": [], "entities": []}, {"text": "the information is included or not maybe conditioned on the particular values of known facts (e.g., the occupation of the person being described -we may need different content selection rules for artists than politicians).", "labels": [], "entities": []}, {"text": "To proceed with the experiments described here, we acquired a set of semantic information and related biographies from the Internet and used this corpus to learn Content Selection rules.", "labels": [], "entities": []}, {"text": "Our main contribution is to analyze how variations in the data influence changes in the text.", "labels": [], "entities": []}, {"text": "We perform such analysis by splitting the semantic input into clusters and then comparing the language models of the associated clusters induced in the text side (given the alignment between semantics and text in the corpus).", "labels": [], "entities": []}, {"text": "By doing so, we gain insights on the relative importance of the different pieces of data and, thus, find out which data to include in the generated text.", "labels": [], "entities": []}, {"text": "The rest of this paper is divided as follows: in the next section, we present the biographical domain we are working with, together with the corpus we have gathered to perform the described experiments.", "labels": [], "entities": []}, {"text": "Section 3 describes our algorithm in detail.", "labels": [], "entities": []}, {"text": "The experiments we perform to validate it, together with their results, are discussed in Section 4.", "labels": [], "entities": []}, {"text": "Section 5 summarizes related work in the field.", "labels": [], "entities": []}, {"text": "Our final remarks, together with proposed future work conclude the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used the following experimental setting: 102 frames were separated from the full set together with their associated 102 biographies from the biography.com site.", "labels": [], "entities": []}, {"text": "This constituted our development corpus.", "labels": [], "entities": []}, {"text": "We further split that corpus into development training (91 people) and development test and hand-tagged the 11 document-data pairs.", "labels": [], "entities": []}, {"text": "The annotation was done by one of the authors, by reading the biographies and checking which triples (in the RDF sense, \u00a5 frame, slot, value\u00a9 ) were actually mentioned in the text (going back and forth to the biography as needed).", "labels": [], "entities": []}, {"text": "Two cases required special attention.", "labels": [], "entities": []}, {"text": "The first one was aggregated information, e.g., the text may say \"he received three Grammys\" while in the semantic input each award was itemized, together with the year it was received, the reason and the type (Best Song of the Year, etc.).", "labels": [], "entities": []}, {"text": "In that case, only the name of award was selected, for each of the three awards.", "labels": [], "entities": []}, {"text": "The second case was factual errors.", "labels": [], "entities": []}, {"text": "For example, the biography may say the person was born in MA and raised in WA, but the fact-sheet may say he was born in WA.", "labels": [], "entities": [{"text": "MA", "start_pos": 58, "end_pos": 60, "type": "DATASET", "confidence": 0.9488118886947632}, {"text": "WA", "start_pos": 75, "end_pos": 77, "type": "DATASET", "confidence": 0.8166207671165466}, {"text": "WA", "start_pos": 121, "end_pos": 123, "type": "DATASET", "confidence": 0.9455261826515198}]}, {"text": "In those cases, the intention of the human writer was given priority and the place of birth was marked as selected, even though one of the two sources were wrong.", "labels": [], "entities": []}, {"text": "The annotated data total 1,129 triples.", "labels": [], "entities": []}, {"text": "From them, only 293 triples (or a 26%) were verbalized in the associated text and thus, considered selected.", "labels": [], "entities": []}, {"text": "That implies that the \"select all\" tactic (\"select all\" is the only trivial content selection tactic, \"select none\" is of no practical value) will achieve an F-measure of 0.41 (26% prec. at 100% rec.).", "labels": [], "entities": [{"text": "F-measure", "start_pos": 158, "end_pos": 167, "type": "METRIC", "confidence": 0.9991872906684875}]}, {"text": "Following the methods outlined in Section 3, we utilized the training part of the development corpus to mine Content Selection rules.", "labels": [], "entities": []}, {"text": "We then used the development test to run different trials and fit the different parameters for the algorithm.", "labels": [], "entities": []}, {"text": "Namely, we determined that filtering the bottom 1,000 TF*IDF weighted words from the text before building the -gram model was important for the task (we compared against other filtering schemes and the use of lists of stop-words).", "labels": [], "entities": []}, {"text": "The best parameters found and the fitting methodology are described in.", "labels": [], "entities": []}, {"text": "We then evaluated on the rest of the semantic input (998 people) aligned with one other textual corpus (imdb.com).", "labels": [], "entities": []}, {"text": "As the average length-perbiography are different in each of the corpora we worked with (450 and 250, respectively), the content selection rules to be learned in each case were different (and thus, ensure us an interesting evaluation of the learning capabilities).", "labels": [], "entities": []}, {"text": "In each case, we split the data into training and test sets, and hand-tagged the test set, following the same guidelines explained for the development corpus.", "labels": [], "entities": []}, {"text": "The linkage step also required some work to be done.", "labels": [], "entities": []}, {"text": "We were able to link 205 people in imdb.com and separated 14 of them as the test set.", "labels": [], "entities": [{"text": "imdb.com", "start_pos": 35, "end_pos": 43, "type": "DATASET", "confidence": 0.9371777772903442}]}, {"text": "The results are shown in 9 . Several We disturbed the dataset to obtain some cross-validation over these figures, obtaining a std dev. of 0.02 for the F*, the full details are given in.: Example rule, from the ripper output.", "labels": [], "entities": []}, {"text": "It says that the subtitle of the award (e.g., \"Best Director\", for an award with title \"Oscar\") should be selected if the person is a director who studied in the US and the award is not of Festival-type.", "labels": [], "entities": []}], "tableCaptions": []}