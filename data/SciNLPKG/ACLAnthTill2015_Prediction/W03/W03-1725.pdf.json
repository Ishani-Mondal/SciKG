{"title": [], "abstractContent": [{"text": "This paper presents a Unicode based Chinese word segmentor.", "labels": [], "entities": [{"text": "Unicode based Chinese word segmentor", "start_pos": 22, "end_pos": 58, "type": "TASK", "confidence": 0.5634204626083374}]}, {"text": "It can handle Chinese text in Simplified, Traditional, or mixed mode.", "labels": [], "entities": []}, {"text": "The system uses the strategy of divide-and-conquer to handle the recognition of personal names, numbers, time and numerical values, etc in the pre-processing stage.", "labels": [], "entities": [{"text": "recognition of personal names", "start_pos": 65, "end_pos": 94, "type": "TASK", "confidence": 0.8581359088420868}]}, {"text": "The segmentor further uses tagging information to work on disambiguation.", "labels": [], "entities": []}, {"text": "Adopting a modular design approach, different functional parts are separately implemented using different modules and each module tackles one problem at a time providing more flexibility and extensibility.", "labels": [], "entities": []}, {"text": "Results show that with added pre-processing modules and accessorial modules, the accuracy of the segmentor is increased and the system is easily adaptive to different applications.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9995622038841248}]}], "introductionContent": [{"text": "The most difficult problem in Chinese word segmentation is due to overlapping ambiguities.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 30, "end_pos": 55, "type": "TASK", "confidence": 0.6199232935905457}]}, {"text": "The recognition of names, foreign names, and organizations are quite unique for Chinese.", "labels": [], "entities": [{"text": "recognition of names", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.8674934109052023}]}, {"text": "Some systems can already achieve very high accuracy, but they heavily rely on manual work in getting the system to be trained to work certain language environment.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.9985197186470032}]}, {"text": "However, for many applications, we need to look at the cost to achieve high accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9948699474334717}]}, {"text": "Ina competitive environment, we also need to have systems that are quickly adaptive to new requirements with limited resources available.", "labels": [], "entities": []}, {"text": "In this paper, we report a Unicode based Chinese word segmentor.", "labels": [], "entities": [{"text": "Unicode based Chinese word segmentor", "start_pos": 27, "end_pos": 63, "type": "TASK", "confidence": 0.5329793870449067}]}, {"text": "The segmentor can handle Chinese text in Simplified, Traditional, or mixed mode where internally only one dictionary is needed.", "labels": [], "entities": []}, {"text": "The system uses the strategy of divideand-conquer to handle the recognition of personal names, numbers, time and numerical values.", "labels": [], "entities": [{"text": "recognition of personal names", "start_pos": 64, "end_pos": 93, "type": "TASK", "confidence": 0.8662292808294296}]}, {"text": "The system has a built-in new word extractor that can extract new words from running text, thus save time on training and getting the system quickly adaptive to new language environment.", "labels": [], "entities": [{"text": "word extractor", "start_pos": 30, "end_pos": 44, "type": "TASK", "confidence": 0.7092401683330536}]}, {"text": "The Bakeoff results in the open text for our system in all categories have shown that it works reasonably good for all different corpora.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 presents our system design objectives and components.", "labels": [], "entities": []}, {"text": "Section 3 discusses more implementation details.", "labels": [], "entities": []}, {"text": "Section 4 gives some performance evaluations.", "labels": [], "entities": []}, {"text": "Section 5 is the conclusion.", "labels": [], "entities": []}], "datasetContent": [{"text": "The valuation metrics used in were adopted here.", "labels": [], "entities": []}, {"text": "where N 1 denotes the number of words in the annotated corpus, N 2 denotes the number of words identified by the segmentation algorithm , and N 3 is the number of words correctly identified.", "labels": [], "entities": []}, {"text": "We participated in the open tests for all four corpora.", "labels": [], "entities": []}, {"text": "The results are shown in the following table.", "labels": [], "entities": []}, {"text": "The worst performance in the 4 tests were for the CTB(UPenn) data.", "labels": [], "entities": [{"text": "CTB(UPenn) data", "start_pos": 50, "end_pos": 65, "type": "DATASET", "confidence": 0.8620867013931275}]}, {"text": "From the observation from the testing data, we found that the main problem with have with CTB data is the difference in word granularity.", "labels": [], "entities": [{"text": "CTB data", "start_pos": 90, "end_pos": 98, "type": "DATASET", "confidence": 0.9061906039714813}]}, {"text": "To confirm our observation, we have done an analysis of combining errors and overlapping errors.", "labels": [], "entities": []}, {"text": "The results show that the ratios of combining errors in all the error types are 0.8425(AS), 0.87684(CTB), 0.82085(HK), and 0.77102(PK).", "labels": [], "entities": [{"text": "AS)", "start_pos": 87, "end_pos": 90, "type": "METRIC", "confidence": 0.9773607552051544}, {"text": "HK)", "start_pos": 114, "end_pos": 117, "type": "METRIC", "confidence": 0.9760535359382629}]}, {"text": "The biggest problem we have with AS data, on the other hand is due to out of vocabulary mistakes.", "labels": [], "entities": [{"text": "AS", "start_pos": 33, "end_pos": 35, "type": "TASK", "confidence": 0.9553650617599487}]}, {"text": "Even though our new word extractor can help us to reduce this problem, but we have not trained our system using data from Taiwan.", "labels": [], "entities": [{"text": "word extractor", "start_pos": 20, "end_pos": 34, "type": "TASK", "confidence": 0.7112534195184708}]}, {"text": "Our best performance was on PK data because we used a very similar dictionary.", "labels": [], "entities": [{"text": "PK data", "start_pos": 28, "end_pos": 35, "type": "DATASET", "confidence": 0.7022987306118011}]}, {"text": "The additional training of data for HK was done using one year Commercial Daily( The program initialization needs around 2.25 seconds mainly to load the dictionaries and other data into the memory before the segmentation can start.", "labels": [], "entities": [{"text": "HK", "start_pos": 36, "end_pos": 38, "type": "TASK", "confidence": 0.9313462972640991}]}, {"text": "If we only count the segmentation time, the rate of segmentation on the average is around 7,500 characters for the first three corpora.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 21, "end_pos": 33, "type": "TASK", "confidence": 0.956419050693512}]}, {"text": "It seems that the processing speed for Peking U. data is faster.", "labels": [], "entities": [{"text": "Peking U. data", "start_pos": 39, "end_pos": 53, "type": "DATASET", "confidence": 0.9158174395561218}]}, {"text": "This maybe because the dictionaries we used are closer to the PK system, thus it would take less time to work on disambiguation.", "labels": [], "entities": [{"text": "PK system", "start_pos": 62, "end_pos": 71, "type": "DATASET", "confidence": 0.8587734997272491}]}], "tableCaptions": []}