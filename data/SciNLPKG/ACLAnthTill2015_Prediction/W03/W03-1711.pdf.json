{"title": [{"text": "A Chinese Efficient Analyser Integrating Word Segmentation, Part-Of-Speech Tagging, Partial Parsing and Full Parsing", "labels": [], "entities": [{"text": "Word Segmentation", "start_pos": 41, "end_pos": 58, "type": "TASK", "confidence": 0.6820429414510727}, {"text": "Part-Of-Speech Tagging", "start_pos": 60, "end_pos": 82, "type": "TASK", "confidence": 0.7078191190958023}]}], "abstractContent": [{"text": "This paper introduces an efficient analyser for the Chinese language, which efficiently and effectively integrates word segmentation, part-of-speech tagging, partial parsing and full parsing.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 115, "end_pos": 132, "type": "TASK", "confidence": 0.7540031969547272}, {"text": "part-of-speech tagging", "start_pos": 134, "end_pos": 156, "type": "TASK", "confidence": 0.6833194643259048}, {"text": "partial parsing", "start_pos": 158, "end_pos": 173, "type": "TASK", "confidence": 0.6101897656917572}, {"text": "full parsing", "start_pos": 178, "end_pos": 190, "type": "TASK", "confidence": 0.6720151007175446}]}, {"text": "The Chinese efficient analyser is based on a Hidden Markov Model (HMM) and an HMM-based tagger.", "labels": [], "entities": []}, {"text": "That is, all the components are based on the same HMM-based tagging engine.", "labels": [], "entities": [{"text": "HMM-based tagging", "start_pos": 50, "end_pos": 67, "type": "TASK", "confidence": 0.5889364331960678}]}, {"text": "One advantage of using the same single engine is that it largely decreases the code size and makes the maintenance easy.", "labels": [], "entities": []}, {"text": "Another advantage is that it is easy to optimise the code and thus improve the speed while speed plays a critical important role in many applications.", "labels": [], "entities": [{"text": "speed", "start_pos": 79, "end_pos": 84, "type": "METRIC", "confidence": 0.9863790273666382}, {"text": "speed", "start_pos": 91, "end_pos": 96, "type": "METRIC", "confidence": 0.9682117700576782}]}, {"text": "Finally, the performances of all the components can benefit from the optimisation of existing algorithms and/or adoption of better algorithms to a single engine.", "labels": [], "entities": []}, {"text": "Experiments show that all the components can achieve state-of-art performances with high efficiency for the Chinese language.", "labels": [], "entities": []}, {"text": "The layout of this paper is as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the Chinese efficient analyser.", "labels": [], "entities": [{"text": "Chinese efficient analyser", "start_pos": 24, "end_pos": 50, "type": "TASK", "confidence": 0.6020701130231222}]}, {"text": "Section 3 presents the HMM and the HMM-based tagger.", "labels": [], "entities": []}, {"text": "Sections 4 and 5 describe the applications of the HMM-based tagger in integrated word segmentation and part-of-speech tagging, partial parsing, and full parsing respectively.", "labels": [], "entities": [{"text": "HMM-based tagger", "start_pos": 50, "end_pos": 66, "type": "TASK", "confidence": 0.7776682376861572}, {"text": "word segmentation", "start_pos": 81, "end_pos": 98, "type": "TASK", "confidence": 0.6812389194965363}, {"text": "part-of-speech tagging", "start_pos": 103, "end_pos": 125, "type": "TASK", "confidence": 0.7084351927042007}, {"text": "partial parsing", "start_pos": 127, "end_pos": 142, "type": "TASK", "confidence": 0.6810579746961594}, {"text": "full parsing", "start_pos": 148, "end_pos": 160, "type": "TASK", "confidence": 0.7631338238716125}]}, {"text": "Section 6 gives the experimental results.", "labels": [], "entities": []}, {"text": "Finally, some conclusions are drawn with possible extensions of future work in section 7.", "labels": [], "entities": []}], "introductionContent": [{"text": "Traditionally, a text parser outputs a complete parse tree for each input sentence, achieving a speed in the order of 10 words per second (wps) (Abney 1997).", "labels": [], "entities": []}, {"text": "However, for many applications like text mining, a parse tree is not necessary and a speed of 10 wps is unacceptable when we have to process millions of words in thousands of documents in a reasonable time.", "labels": [], "entities": [{"text": "text mining", "start_pos": 36, "end_pos": 47, "type": "TASK", "confidence": 0.8214463889598846}]}, {"text": "Therefore, there is a compromise between speed and performance in many applications.", "labels": [], "entities": [{"text": "speed", "start_pos": 41, "end_pos": 46, "type": "METRIC", "confidence": 0.9620257616043091}]}, {"text": "5) In this way, full parsing is completed with a fully parsed tree after several levels (3 in the example of) of cascaded partial parsing.", "labels": [], "entities": [{"text": "full parsing", "start_pos": 16, "end_pos": 28, "type": "TASK", "confidence": 0.5701837241649628}]}], "datasetContent": [{"text": "The Chinese efficient analyser is implemented in C++, providing a rapid and easy code-compile-train-test development cycle.", "labels": [], "entities": []}, {"text": "In fact, many NLP systems suffer from alack of software and computer-science engineering effort: running efficiency is key to performing numerous experiments, which, in turn, is key to improving performance.", "labels": [], "entities": []}, {"text": "A system may have excellent performance on a given task, but if it takes long to compile and/or run on test data, the rate of improvement of that system will be contrained compared to that which can run very efficiently.", "labels": [], "entities": []}, {"text": "Moreover, speed plays a critical role in many applications such as text mining.", "labels": [], "entities": [{"text": "speed", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9924044013023376}, {"text": "text mining", "start_pos": 67, "end_pos": 78, "type": "TASK", "confidence": 0.8610734641551971}]}, {"text": "All the experiments are implemented on a Pentium II/450MHZ PC.", "labels": [], "entities": []}, {"text": "All the performances are measured in precisions, recalls and F-measures.", "labels": [], "entities": [{"text": "precisions", "start_pos": 37, "end_pos": 47, "type": "METRIC", "confidence": 0.9995531439781189}, {"text": "recalls", "start_pos": 49, "end_pos": 56, "type": "METRIC", "confidence": 0.9944215416908264}, {"text": "F-measures", "start_pos": 61, "end_pos": 71, "type": "METRIC", "confidence": 0.9942195415496826}]}, {"text": "Here, the precision (P) measures the number of correct units in the answer file over the total number of units in the answer file and the recall (R) measures the number of correct units in the answer file over the total number of units in the key file   The word segmentation corresponds to bracketing of the chunking model while POS tagging corresponds to bracketing and labelling.", "labels": [], "entities": [{"text": "precision (P)", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.9467561542987823}, {"text": "recall (R)", "start_pos": 138, "end_pos": 148, "type": "METRIC", "confidence": 0.9760321378707886}, {"text": "word segmentation", "start_pos": 258, "end_pos": 275, "type": "TASK", "confidence": 0.7119259387254715}, {"text": "POS tagging", "start_pos": 330, "end_pos": 341, "type": "TASK", "confidence": 0.7443288862705231}]}, {"text": "shows that recall (P) is higher than precision (P).", "labels": [], "entities": [{"text": "recall (P)", "start_pos": 11, "end_pos": 21, "type": "METRIC", "confidence": 0.9587986320257187}, {"text": "precision (P)", "start_pos": 37, "end_pos": 50, "type": "METRIC", "confidence": 0.9462301880121231}]}, {"text": "The main reason maybe the existence of unknown words.", "labels": [], "entities": []}, {"text": "In the Chinese efficient analyser, unknown words are segmented into individual Chinese characters.", "labels": [], "entities": []}, {"text": "This makes the number of segmented words/POS tagged words in the system output higher than that in the correct answer.", "labels": [], "entities": []}, {"text": "shows that the performances of partial parsing and full parsing are quite low, compared to those of state-of-art partial parsing and full parsing for the English language (Zhou et al 2000a; Collins 1997).", "labels": [], "entities": [{"text": "partial parsing", "start_pos": 31, "end_pos": 46, "type": "TASK", "confidence": 0.5749741196632385}, {"text": "full parsing", "start_pos": 51, "end_pos": 63, "type": "TASK", "confidence": 0.5692648887634277}]}, {"text": "The main reason behind is the small size of the training corpus used in our experiments.", "labels": [], "entities": []}, {"text": "However, the Chinese PENN Tree Bank is the largest corpus we can find for partial parsing and full parsing.", "labels": [], "entities": [{"text": "Chinese PENN Tree Bank", "start_pos": 13, "end_pos": 35, "type": "DATASET", "confidence": 0.875799298286438}, {"text": "full parsing", "start_pos": 94, "end_pos": 106, "type": "TASK", "confidence": 0.5878961682319641}]}, {"text": "Therefore, developing a much larger Chinese tree bank (comparable to UPENN English Tree Bank) becomes an urgent task for the Chinese language processing community.", "labels": [], "entities": [{"text": "UPENN English Tree Bank", "start_pos": 69, "end_pos": 92, "type": "DATASET", "confidence": 0.9043642431497574}]}, {"text": "Actually, the best individual system (Zhou et al 2000b) in CoNLL'2000 chunking shared task for the English language used the same HMM-based tagging engine.", "labels": [], "entities": [{"text": "CoNLL'2000 chunking shared task", "start_pos": 59, "end_pos": 90, "type": "TASK", "confidence": 0.7268693298101425}]}], "tableCaptions": [{"text": " Table 1: Constraints between t and t", "labels": [], "entities": []}, {"text": " Table 2: Performances of Word Segmentation  and POS Tagging (wps: words per second)", "labels": [], "entities": [{"text": "Word Segmentation", "start_pos": 26, "end_pos": 43, "type": "TASK", "confidence": 0.7165083587169647}, {"text": "POS Tagging", "start_pos": 49, "end_pos": 60, "type": "TASK", "confidence": 0.746025562286377}]}, {"text": " Table 3: Performances of 1 st -level Partial Parsing  and Full Parsing (wps: words per second)", "labels": [], "entities": [{"text": "Partial Parsing", "start_pos": 38, "end_pos": 53, "type": "TASK", "confidence": 0.7859281897544861}]}]}