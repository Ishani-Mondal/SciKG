{"title": [{"text": "Conversational Robots: Building Blocks for Grounding Word Meaning", "labels": [], "entities": [{"text": "Conversational Robots", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8065220713615417}, {"text": "Grounding Word Meaning", "start_pos": 43, "end_pos": 65, "type": "TASK", "confidence": 0.6648954252401987}]}], "abstractContent": [{"text": "How can we build robots that engage in fluid spoken conversations with people, moving beyond canned responses to words and towards actually understanding?", "labels": [], "entities": []}, {"text": "As a step towards addressing this question, we introduce a robotic architecture that provides a basis for grounding word meanings.", "labels": [], "entities": []}, {"text": "The architecture provides perceptual , procedural, and affordance representations for grounding words.", "labels": [], "entities": []}, {"text": "A perceptually-coupled on-line simulator enables sensory-motor representations that can shift points of view.", "labels": [], "entities": []}, {"text": "Held together, we show that this architecture provides a rich set of data structures and procedures that provide the foundations for grounding the meaning of certain classes of words.", "labels": [], "entities": []}], "introductionContent": [{"text": "Language enables people to talk about the world, past, present, and future, real and imagined.", "labels": [], "entities": []}, {"text": "For a robot to do the same, it must ground language in its world as mediated by its perceptual, motor, and cognitive capacities.", "labels": [], "entities": []}, {"text": "Many words that refer to entities in the world can be grounded through sensory-motor associations.", "labels": [], "entities": []}, {"text": "For instance, the meaning of ball includes perceptual associations that encode how balls look and predictive models of how balls behave.", "labels": [], "entities": []}, {"text": "The representation of touch must include procedural associations that encode how to perform the action, and perceptual encodings to recognize the action in others.", "labels": [], "entities": []}, {"text": "In this view, words serve as labels for perceptual or action concepts.", "labels": [], "entities": []}, {"text": "When a word is uttered, the underlying concept is communicated since the speaker and listener maintain similar associations.", "labels": [], "entities": []}, {"text": "This basic approach underlies most work to date in building machines that ground language.", "labels": [], "entities": []}, {"text": "Not all words, however, can be grounded in terms of perceptual and procedural representations, even when used in concrete situations.", "labels": [], "entities": []}, {"text": "In fact, in even the simplest conversations about everyday objects, events, and relations, we run into problems.", "labels": [], "entities": []}, {"text": "Consider a person and a robot sitting across a table from each other, engaged in coordinated activity involving manipulation of objects.", "labels": [], "entities": []}, {"text": "After some interaction, the person says to the robot: Touch the heavy blue thing that was on my left.", "labels": [], "entities": []}, {"text": "To understand and act on this command in context, consider the range of knowledge representations that the robot must bind words of this utterance to.", "labels": [], "entities": []}, {"text": "Touch can be grounded in a visually-guided motor program that enables the robot to move towards and touch objects.", "labels": [], "entities": []}, {"text": "This is an example of a procedural association which also critically depends on perception to guide the action.", "labels": [], "entities": []}, {"text": "Heavy specifies a property of objects which involves affordances that intertwine procedural representations with perceptual expectations.", "labels": [], "entities": []}, {"text": "Blue and left specify visual properties.", "labels": [], "entities": []}, {"text": "Thing must be grounded in terms of both perception and affordances (one can see an object, and expect to reach out and touch it).", "labels": [], "entities": []}, {"text": "Was triggers a reference to the past.", "labels": [], "entities": []}, {"text": "My triggers a shift of perspective in space.", "labels": [], "entities": []}, {"text": "We have developed an architecture in which a physical robot is coupled with a physical simulator to provide the basis for grounding each of these classes of lexical semantics . This workshop paper provides an abbreviated version of a forthcoming paper (.", "labels": [], "entities": []}, {"text": "The robot, called Ripley, is driven by compliant actuators and is able to manipulate small objects.", "labels": [], "entities": []}, {"text": "Ripley has cameras, touch, and various other sensors on its \"head\".", "labels": [], "entities": []}, {"text": "Force sensors in each actuated joint combined with position sensors provide the robot with a sense of proprioception.", "labels": [], "entities": []}, {"text": "Ripley's visual and proprioceptive systems drive a physical simulator that keeps a constructed version of the world (that includes Ripley's own physical body) in synchronization with Ripley's noisy perceptual input.", "labels": [], "entities": []}, {"text": "An object permanence module determines when to instantiate and destroy objects in the model based on perceptual evidence.", "labels": [], "entities": []}, {"text": "Once instantiated, perception can continue to influence the properties of an object in the model, but knowledge of physical world dynamics is built into the simulator and counteracts 'unreasonable' percepts.", "labels": [], "entities": []}, {"text": "Language is grounded in terms of associations with elements of this perceptually driven world model, as well as direct groundings in terms of sensory and motor representations.", "labels": [], "entities": []}, {"text": "Although the world model directly reflects reality, the state of the model is the result of an interpretation process that compiles perceptual input into a stable registration of the environment.", "labels": [], "entities": []}, {"text": "As opposed to direct perception, the world model affords the ability to assume arbitrary points of view through the use of synthetic vision which operates within the physical model, enabling a limited form of \"out of body experience\".", "labels": [], "entities": []}, {"text": "This ability is essential to successfully differentiate the semantics of my left versus your left.", "labels": [], "entities": []}, {"text": "Non-linguistic cues such as the visual location of the communication partners can be integrated with linguistic input to context-appropriate perspective shifts.", "labels": [], "entities": []}, {"text": "Shifts of perspective in time and space maybe thought of as semantic modulation functions.", "labels": [], "entities": []}, {"text": "Although the meaning of \"left\" in one sense remains constant across usages, the words \"my\" and \"your\" modulate the meaning by swapping frames of reference.", "labels": [], "entities": []}, {"text": "We suspect that successful use of language requires constant modulations of meanings of this and related kinds.", "labels": [], "entities": []}, {"text": "We describe the robot and simulator, and mechanisms for real-time coupling.", "labels": [], "entities": []}, {"text": "We then discuss mechanisms within this architecture designed for the purposes of grounding the semantics of situated, natural spoken conversation.", "labels": [], "entities": []}, {"text": "Although no language understanding system has yet been constructed, we conclude by sketching how the semantics of each of the words and the whole utterance discussed above can be grounded in the data structures and processes provided by this architecture.", "labels": [], "entities": []}, {"text": "This work represents steps towards our long term goal of developing robots and other machines that use language in the utterance and context that we have described, the groundings listed above play essential roles.", "labels": [], "entities": []}, {"text": "It maybe argued that other senses of words are often metaphoric extensions of these embodied representations (.", "labels": [], "entities": []}, {"text": "human-like ways by leveraging deep, grounded representations of meaning that \"hook\" into the world through machine perception, action, and higher layers of cognitive processes.", "labels": [], "entities": []}, {"text": "The work has theoretical implications on how language is represented and processed by machine, and also has practical applications where natural humanrobot interaction is needed such as deep-sea robot control, remote handling of hazardous materials by robots, and astronaut-robot communication in space.", "labels": [], "entities": [{"text": "astronaut-robot communication", "start_pos": 264, "end_pos": 293, "type": "TASK", "confidence": 0.7181897163391113}]}], "datasetContent": [], "tableCaptions": []}