{"title": [{"text": "The Web as a Parallel Corpus", "labels": [], "entities": []}], "abstractContent": [{"text": "Parallel corpora have become an essential resource for work in multilingual natural language processing.", "labels": [], "entities": [{"text": "multilingual natural language processing", "start_pos": 63, "end_pos": 103, "type": "TASK", "confidence": 0.6326849535107613}]}, {"text": "In this article, we report on our work using the STRAND system for mining parallel text on the World Wide Web, first reviewing the original algorithm and results and then presenting a set of significant enhancements.", "labels": [], "entities": []}, {"text": "These enhancements include the use of supervised learning based on structural features of documents to improve classification performance, anew content-based measure of translational equivalence, and adaptation of the system to take advantage of the Internet Archive for mining parallel text from the Web on a large scale.", "labels": [], "entities": [{"text": "translational equivalence", "start_pos": 169, "end_pos": 194, "type": "TASK", "confidence": 0.8930005133152008}]}, {"text": "Finally, the value of these techniques is demonstrated in the construction of a significant parallel corpus fora low-density language pair.", "labels": [], "entities": []}], "introductionContent": [{"text": "Parallel corpora-bodies of text in parallel translation, also known as bitexts-have taken on an important role in machine translation and multilingual natural language processing.", "labels": [], "entities": [{"text": "Parallel corpora-bodies of text in parallel translation", "start_pos": 0, "end_pos": 55, "type": "TASK", "confidence": 0.571565466267722}, {"text": "machine translation", "start_pos": 114, "end_pos": 133, "type": "TASK", "confidence": 0.7903884053230286}, {"text": "multilingual natural language processing", "start_pos": 138, "end_pos": 178, "type": "TASK", "confidence": 0.6209810078144073}]}, {"text": "They represent resources for automatic lexical acquisition (e.g.,, they provide indispensable training data for statistical translation models (e.g.,, and they can provide the connection between vocabularies in cross-language information retrieval (e.g.,; see also.", "labels": [], "entities": [{"text": "automatic lexical acquisition", "start_pos": 29, "end_pos": 58, "type": "TASK", "confidence": 0.6648511489232382}, {"text": "statistical translation", "start_pos": 112, "end_pos": 135, "type": "TASK", "confidence": 0.6939481794834137}, {"text": "cross-language information retrieval", "start_pos": 211, "end_pos": 247, "type": "TASK", "confidence": 0.7051361997922262}]}, {"text": "More recently, researchers at Johns Hopkins University and the University of Maryland have been exploring new ways to exploit parallel corpora in order to develop monolingual resources and tools, using a process of annotation, projection, and training: Given a parallel corpus in English and a less resource-rich language, we project English annotations across the parallel corpus to the second language, using word-level alignments as the bridge, and then use robust statistical techniques in learning from the resulting noisy annotations.", "labels": [], "entities": []}, {"text": "For these reasons, parallel corpora can bethought of as a critical resource.", "labels": [], "entities": []}, {"text": "Unfortunately, they are not readily available in the necessary quantities.", "labels": [], "entities": []}, {"text": "Until very recently, for example, statistical work in machine translation focused heavily on French-English translation because the Canadian parliamentary proceedings (Hansards) in English and French were the only large bitext available.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 54, "end_pos": 73, "type": "TASK", "confidence": 0.7723943591117859}, {"text": "French-English translation", "start_pos": 93, "end_pos": 119, "type": "TASK", "confidence": 0.7333149015903473}, {"text": "Canadian parliamentary proceedings (Hansards)", "start_pos": 132, "end_pos": 177, "type": "DATASET", "confidence": 0.6816397358973821}]}, {"text": "Things have improved somewhat, but it is still fair to say that for all but a relatively few language pairs, parallel corpora tend to be accessible only in specialized forms such as United Nations proceedings (e.g., via the Linguistic Data Consortium, \ud97b\udf59http://www.ldc.upenn.edu\ud97b\udf59), religious texts, localized versions of software manuals, and the like.", "labels": [], "entities": []}, {"text": "Even for the top handful of majority languages, the available parallel corpora tend to be unbalanced, representing primarily governmental or newswire-style texts.", "labels": [], "entities": []}, {"text": "In addition, like other language resources, parallel corpora are often encumbered by fees or licensing restrictions.", "labels": [], "entities": []}, {"text": "For all these reasons, it is difficult to follow the \"more data are better data\" advice of, abandoning balance in favor of volume, with respect to parallel text.", "labels": [], "entities": []}, {"text": "Then there is the World Wide Web.", "labels": [], "entities": [{"text": "World Wide Web", "start_pos": 18, "end_pos": 32, "type": "DATASET", "confidence": 0.8919185598691305}]}, {"text": "People tend to seethe Web as a reflection of their own way of viewing the world-as a huge semantic network, or an enormous historical archive, or a grand social experiment.", "labels": [], "entities": []}, {"text": "We are no different: As computational linguists working on multilingual issues, we view the Web as a great big body of text waiting to be mined, a huge fabric of linguistic data often interwoven with parallel threads.", "labels": [], "entities": []}, {"text": "This article describes our techniques for mining the Web in order to extract the parallel text it contains.", "labels": [], "entities": []}, {"text": "It presents, in revised and considerably extended form, our early work on mining the Web for bilingual text (STRAND)), incorporating new work on content-based detection of translations), and efficient exploitation of the Internet Archive.", "labels": [], "entities": [{"text": "STRAND", "start_pos": 109, "end_pos": 115, "type": "METRIC", "confidence": 0.9170377254486084}, {"text": "content-based detection of translations", "start_pos": 145, "end_pos": 184, "type": "TASK", "confidence": 0.7792907804250717}]}, {"text": "In Section 2 we layout the STRAND architecture, which is based on the insight that translated Web pages tend quite strongly to exhibit parallel structure, permitting them to be identified even without looking at content; we also show how we have improved STRAND's performance by training a supervised classifier using structural parameters rather than relying on manually tuned thresholds.", "labels": [], "entities": []}, {"text": "In Section 3 we present an approach to detecting translations that relies entirely on content rather than structure, demonstrating performance comparable to STRAND's using this orthogonal source of information.", "labels": [], "entities": [{"text": "detecting translations", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.8529537618160248}]}, {"text": "In Section 4 we describe how we have adapted the STRAND approach to the Internet Archive, dramatically improving our ability to identify parallel Web pages on a large scale.", "labels": [], "entities": []}, {"text": "Section 5 puts all the pieces together, using structural and combined content-structure matching of pages on the Internet Archive in order to obtain a sizable corpus of English-Arabic Web document pairs.", "labels": [], "entities": []}, {"text": "Finally we present our thoughts on future work and conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "We now apply our content-based similarity measure to the candidate pair classification task presented by STRAND.", "labels": [], "entities": [{"text": "candidate pair classification task", "start_pos": 57, "end_pos": 91, "type": "TASK", "confidence": 0.691072590649128}, {"text": "STRAND", "start_pos": 105, "end_pos": 111, "type": "DATASET", "confidence": 0.8856707215309143}]}, {"text": "Recall that both the original STRAND classifier and those learned using decision tree methods, described in Section 2.2.3, employ only structural features of the documents to determine whether they are translations.", "labels": [], "entities": [{"text": "STRAND classifier", "start_pos": 30, "end_pos": 47, "type": "TASK", "confidence": 0.4202083796262741}]}, {"text": "Here we apply the tsim score to the same task and compare the results with those of the original STRAND classifier.", "labels": [], "entities": [{"text": "STRAND", "start_pos": 97, "end_pos": 103, "type": "METRIC", "confidence": 0.6816655397415161}]}], "tableCaptions": [{"text": " Table 1  Effects of parameter tuning.", "labels": [], "entities": [{"text": "parameter tuning", "start_pos": 21, "end_pos": 37, "type": "TASK", "confidence": 0.709943026304245}]}, {"text": " Table 3  Comparison with STRAND. The test set contains 293 of the 326 pairs in Resnik's (1999) test  set. The 32 development pairs were used to select manually the 0.44 threshold. N is the  number of examples for which judgment comparison was possible in each case (human judges  were sometimes undecided; those cases are ignored in computing \u03ba).", "labels": [], "entities": [{"text": "STRAND", "start_pos": 26, "end_pos": 32, "type": "METRIC", "confidence": 0.8849940299987793}, {"text": "Resnik's (1999) test  set", "start_pos": 80, "end_pos": 105, "type": "DATASET", "confidence": 0.7383810111454555}, {"text": "judgment comparison", "start_pos": 220, "end_pos": 239, "type": "TASK", "confidence": 0.6830713450908661}]}, {"text": " Table 4  Effects of parameter tuning with the additional tsim feature.", "labels": [], "entities": []}, {"text": " Table 5  English-Arabic structural classification results.", "labels": [], "entities": [{"text": "English-Arabic structural classification", "start_pos": 10, "end_pos": 50, "type": "TASK", "confidence": 0.6307333906491598}]}, {"text": " Table 6  English-Arabic combined structural/content-based classification results. The baseline and  content-only classifiers are on the full set, and the structure-only classifier is repeated for  reference.", "labels": [], "entities": []}, {"text": " Table 7  Yield: The English-Arabic Internet Archive corpus, tokenized several ways.", "labels": [], "entities": [{"text": "English-Arabic Internet Archive corpus", "start_pos": 21, "end_pos": 59, "type": "DATASET", "confidence": 0.7398177087306976}]}]}