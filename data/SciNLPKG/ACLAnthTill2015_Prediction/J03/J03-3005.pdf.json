{"title": [{"text": "Using the Web to Obtain Frequencies for Unseen Bigrams", "labels": [], "entities": []}], "abstractContent": [{"text": "This article shows that the Web can be employed to obtain frequencies for bigrams that are unseen in a given corpus.", "labels": [], "entities": []}, {"text": "We describe a method for retrieving counts for adjective-noun, noun-noun, and verb-object bigrams from the Web by querying a search engine.", "labels": [], "entities": []}, {"text": "We evaluate this method by demonstrating: (a) a high correlation between Web frequencies and corpus frequencies; (b) a reliable correlation between Web frequencies and plausibility judgments; (c) a reliable correlation between Web frequencies and frequencies recreated using class-based smoothing; (d) a good performance of Web frequencies in a pseudodisambiguation task.", "labels": [], "entities": []}], "introductionContent": [{"text": "In two recent papers,) criticize the fact that current NLP algorithms are typically optimized, tested, and compared on fairly small data sets (corpora with millions of words), even though data sets several orders of magnitude larger are available, at least for some NLP tasks.) experiment with context-sensitive spelling correction, a task for which large amounts of data can be obtained straightforwardly, as no manual annotation is required.", "labels": [], "entities": [{"text": "context-sensitive spelling correction", "start_pos": 294, "end_pos": 331, "type": "TASK", "confidence": 0.6391967932383219}]}, {"text": "They demonstrate that the learning algorithms typically used for spelling correction benefit significantly from larger training sets, and that their performance shows no sign of reaching an asymptote as the size of the training set increases.", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 65, "end_pos": 84, "type": "TASK", "confidence": 0.9792391359806061}]}, {"text": "Arguably, the largest data set that is available for NLP is the Web, 1 which currently consists of at least 3,033 million pages.", "labels": [], "entities": []}, {"text": "Data retrieved from the Web therefore provide enormous potential for training NLP algorithms, if findings for spelling corrections generalize; potential applications include tasks that involve word n-grams and simple surface syntax.", "labels": [], "entities": [{"text": "spelling corrections", "start_pos": 110, "end_pos": 130, "type": "TASK", "confidence": 0.8878056108951569}]}, {"text": "There is a small body of existing research that tries to harness the potential of the Web for NLP. and use the Web to generate corpora for languages for which electronic resources are scarce, and Resnik (1999) describes a method for mining the Web in order to obtain bilingual texts. and use the Web for word sense disambiguation, proposes a method for resolving PP attachment ambiguities based on Web data, Markert, use the Web for the resolution of nominal anaphora, Example of patterns used for the extraction of adjective-noun bigrams.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 304, "end_pos": 329, "type": "TASK", "confidence": 0.7250279188156128}, {"text": "PP attachment ambiguities", "start_pos": 363, "end_pos": 388, "type": "TASK", "confidence": 0.7997797926266988}, {"text": "resolution of nominal anaphora", "start_pos": 437, "end_pos": 467, "type": "TASK", "confidence": 0.8261837363243103}]}], "datasetContent": [{"text": "Since Web counts can be relatively noisy, as discussed in the previous section, it is crucial to determine whether there is a reliable relationship between Web counts and corpus counts.", "labels": [], "entities": []}, {"text": "Once this is assured, we can explore the usefulness of Web counts for overcoming data sparseness.", "labels": [], "entities": []}, {"text": "We carried out a correlation analysis to determine whether there is a linear relationship between BNC and NANTC counts and AltaVista and Google counts.", "labels": [], "entities": [{"text": "BNC and NANTC counts", "start_pos": 98, "end_pos": 118, "type": "DATASET", "confidence": 0.4709712564945221}]}, {"text": "All correlation coefficients reported in this article refer to Pearson's r.", "labels": [], "entities": [{"text": "correlation", "start_pos": 4, "end_pos": 15, "type": "METRIC", "confidence": 0.968388557434082}, {"text": "Pearson's r", "start_pos": 63, "end_pos": 74, "type": "METRIC", "confidence": 0.6608434418837229}]}, {"text": "All results were obtained on log-transformed counts.", "labels": [], "entities": []}, {"text": "7 shows the results of correlating Web counts with corpus counts from the BNC, the corpus from which our bigrams were sampled (see Section 2.1).", "labels": [], "entities": [{"text": "BNC", "start_pos": 74, "end_pos": 77, "type": "DATASET", "confidence": 0.9362453818321228}]}, {"text": "A high correlation coefficient was obtained across the board, ranging from .720 to .847 for AltaVista counts and from .720 to .850 for Google counts.", "labels": [], "entities": [{"text": "correlation", "start_pos": 7, "end_pos": 18, "type": "METRIC", "confidence": 0.9593735933303833}]}, {"text": "This indicates that Web counts approximate BNC counts for the three types of bigrams under investigation.", "labels": [], "entities": [{"text": "BNC", "start_pos": 43, "end_pos": 46, "type": "METRIC", "confidence": 0.8908694982528687}]}, {"text": "Note that there is almost no difference between the correlations achieved using Google and AltaVista counts.", "labels": [], "entities": []}, {"text": "It is important to check that these results are also valid for counts obtained from other corpora.", "labels": [], "entities": []}, {"text": "We therefore correlated our Web counts with the counts obtained from NANTC, a corpus that is larger than the BNC but is drawn from a single genre, namely, news text (see Section 2.2).", "labels": [], "entities": [{"text": "NANTC", "start_pos": 69, "end_pos": 74, "type": "DATASET", "confidence": 0.9444923400878906}, {"text": "BNC", "start_pos": 109, "end_pos": 112, "type": "DATASET", "confidence": 0.8970447182655334}]}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "We find that 6 Correlation analysis is away of measuring the degree of linear association between two variables.", "labels": [], "entities": []}, {"text": "Effectively, we are fitting a linear equation y = ax + b to the data; this means that the two variables x and y (which in our case represent frequencies or judgments) can still differ by a multiplicative constant a and an additive constant b, even if they are highly correlated.", "labels": [], "entities": []}, {"text": "7 It is well-known that corpus frequencies have a Zipfian distribution.", "labels": [], "entities": []}, {"text": "Log-transforming them is away of normalizing the counts before applying statistical tests.", "labels": [], "entities": []}, {"text": "We apply correlation analysis on the log-transformed data, which is equivalent to computing a log-linear regression coefficient on the untransformed data.", "labels": [], "entities": []}, {"text": "Google and AltaVista counts also correlate significantly with NANTC counts.", "labels": [], "entities": [{"text": "NANTC counts", "start_pos": 62, "end_pos": 74, "type": "DATASET", "confidence": 0.6678451895713806}]}, {"text": "The correlation coefficients range from .667 to .788 for AltaVista and from .662 to .787 for Google.", "labels": [], "entities": [{"text": "correlation", "start_pos": 4, "end_pos": 15, "type": "METRIC", "confidence": 0.9776790142059326}]}, {"text": "Again, there is virtually no difference between the correlations for the two search engines.", "labels": [], "entities": []}, {"text": "We also observe that the correlation between Web counts and BNC is generally slightly higher than the correlation between Web counts and NANTC counts.", "labels": [], "entities": [{"text": "BNC", "start_pos": 60, "end_pos": 63, "type": "METRIC", "confidence": 0.6641494631767273}]}, {"text": "We carried out one-tailed t-tests to determine whether the differences in the correlation coefficients were significant.", "labels": [], "entities": [{"text": "correlation", "start_pos": 78, "end_pos": 89, "type": "METRIC", "confidence": 0.9703457355499268}]}, {"text": "We found that both AltaVista counts (t(87) = 3.11, p < .01) and Google counts (t(87) = 3.21, p < .01) were significantly better correlated with BNC counts than with NANTC counts for adjective-noun bigrams.", "labels": [], "entities": []}, {"text": "The difference in correlation coefficients was not significant for noun-noun and verb-object bigrams, for either search engine.", "labels": [], "entities": [{"text": "correlation", "start_pos": 18, "end_pos": 29, "type": "METRIC", "confidence": 0.969959557056427}]}, {"text": "also shows the correlations between BNC counts and NANTC counts.", "labels": [], "entities": [{"text": "BNC counts", "start_pos": 36, "end_pos": 46, "type": "METRIC", "confidence": 0.8941251635551453}, {"text": "NANTC counts", "start_pos": 51, "end_pos": 63, "type": "METRIC", "confidence": 0.7445838451385498}]}, {"text": "The intercorpus correlation can be regarded as an upper limit for the correlations we can expect between counts from two corpora that differ in size and genre and that have been obtained using different extraction methods.", "labels": [], "entities": []}, {"text": "The correlation between AltaVista and Google counts and NANTC counts reached the upper limit for all three bigram types (one-tailed t-tests found no significant differences between the correlation coefficients).", "labels": [], "entities": [{"text": "NANTC", "start_pos": 56, "end_pos": 61, "type": "DATASET", "confidence": 0.775605320930481}]}, {"text": "The correlation between BNC counts and Web counts reached the upper limit for noun-noun and verb-object bigrams (no significant differences for either search engine) and significantly exceeded it for adjective-noun bigrams for AltaVista (t(87) = 3.16, p < .01) and Google (t(87) = 3.26, p < .01).", "labels": [], "entities": []}, {"text": "We conclude that simple heuristics (see Section 2.3) are sufficient to obtain useful frequencies from the Web; it seems that the large amount of data available for Web counts outweighs the associated problems (noisy, unbalanced, etc.).", "labels": [], "entities": []}, {"text": "We found that Web counts were highly correlated with frequencies from two different corpora.", "labels": [], "entities": []}, {"text": "Furthermore, Web counts and corpus counts are as highly correlated as counts from two different corpora (which can be regarded as an upper bound).", "labels": [], "entities": []}, {"text": "Note that also provide the correlation coefficients obtained when corpus frequencies are compared with frequencies that were re-created through class-based smoothing, using the BNC as a training corpus (after removing the seen bigrams).", "labels": [], "entities": [{"text": "BNC", "start_pos": 177, "end_pos": 180, "type": "DATASET", "confidence": 0.9122458696365356}]}, {"text": "This will be discussed in more detail in Section 3.3.", "labels": [], "entities": []}, {"text": "Previous work has demonstrated that corpus counts correlate with human plausibility judgments for adjective-noun bigrams.", "labels": [], "entities": []}, {"text": "This result holds both for seen bigrams) and for unseen bigrams whose counts have been re-created using smoothing techniques.", "labels": [], "entities": []}, {"text": "Based on these findings, we decided to evaluate our Web counts on the task of predicting plausibility ratings.", "labels": [], "entities": [{"text": "predicting plausibility ratings", "start_pos": 78, "end_pos": 109, "type": "TASK", "confidence": 0.8532781600952148}]}, {"text": "If the Web counts for bigrams correlate with plausibility judgments, then this indicates that the counts are valid, in the sense of being useful for predicting the intuitive plausibility of predicate-argument pairs.", "labels": [], "entities": []}, {"text": "The degree of correlation between Web counts and plausibility judgments is an indicator of the quality of the Web counts (compared to corpus counts or counts re-created using smoothing techniques).", "labels": [], "entities": []}, {"text": "The evaluation in the last two sections established that Web counts are useful for approximating corpus counts and for predicting plausibility judgments.", "labels": [], "entities": [{"text": "predicting plausibility judgments", "start_pos": 119, "end_pos": 152, "type": "TASK", "confidence": 0.9199394583702087}]}, {"text": "As a further step in our evaluation, we correlated Web counts with counts re-created by applying a class-based smoothing method to the BNC.", "labels": [], "entities": [{"text": "BNC", "start_pos": 135, "end_pos": 138, "type": "DATASET", "confidence": 0.9573450684547424}]}, {"text": "We re-created co-occurrence frequencies for predicate-argument bigrams using a simplified version of Resnik's (1993) selectional association measure proposed by Lapata,.", "labels": [], "entities": []}, {"text": "Ina nutshell, this measure replaces information-theoretic approach with a simpler measure that makes no assumptions with respect to the contribution of a semantic class to the total quantity of information provided by the predicate about the semantic classes of its argument.", "labels": [], "entities": []}, {"text": "It simply substitutes the argument occurring in the predicate-argument bigram with the concept by which it is represented in the WordNet taxonomy.", "labels": [], "entities": [{"text": "WordNet taxonomy", "start_pos": 129, "end_pos": 145, "type": "DATASET", "confidence": 0.9421712756156921}]}, {"text": "Predicate-argument co-occurrence frequency is estimated by counting the number of times the concept corresponding to the argument is observed to co-occur with the predicate in the corpus.", "labels": [], "entities": []}, {"text": "Because a given word is not always represented by a single class in the taxonomy (i.e., the argument co-occurring with a predicate can generally be the realization of one of several conceptual classes), constructed the frequency counts fora predicate-argument bigram for each conceptual class by dividing the contribution from the argument by the number of classes to which it belongs.", "labels": [], "entities": []}, {"text": "They demonstrate that the counts re-created using this smoothing technique correlate significantly with plausibility judgments for adjective-noun bigrams.", "labels": [], "entities": []}, {"text": "They also show that this class-based approach outperforms distance-weighted averaging (Dagan, Lee, and Pereira 1999), a smoothing method that re-creates unseen word co-occurrences on the basis of distributional similarity (without relying on a predefined taxonomy), in predicting plausibility.", "labels": [], "entities": [{"text": "predicting plausibility", "start_pos": 269, "end_pos": 292, "type": "TASK", "confidence": 0.8616724610328674}]}, {"text": "In the current study, we used the smoothing technique of Lapata, to re-create not only adjective-noun bigrams, but also noun-noun and verb-object bigrams.", "labels": [], "entities": []}, {"text": "As already mentioned in Section 2.1, it was assumed that the noun is the predicate in adjective-noun bigrams; for noun-noun bigrams, we treated the right noun as the predicate, and for verb-object bigrams, we treated the verb as the predicate.", "labels": [], "entities": []}, {"text": "We applied technique to the unseen bigrams for all three bigram types.", "labels": [], "entities": []}, {"text": "We also used it on the seen bigrams, which we were able to treat as unseen by removing all instances of the bigrams from the training corpus.", "labels": [], "entities": []}, {"text": "To test the claim that Web frequencies can be used to overcome data sparseness, we correlated the frequencies re-created using class-based smoothing on the BNC with the frequencies obtained from the Web.", "labels": [], "entities": [{"text": "BNC", "start_pos": 156, "end_pos": 159, "type": "DATASET", "confidence": 0.9019791483879089}]}, {"text": "The correlation coefficients for both seen and unseen bigrams are shown in.", "labels": [], "entities": [{"text": "correlation", "start_pos": 4, "end_pos": 15, "type": "METRIC", "confidence": 0.9548320174217224}]}, {"text": "In all cases, a significant correlation between Web counts and re-created counts is obtained.", "labels": [], "entities": []}, {"text": "For seen bigrams, the correlation coefficient ranged from .344 to .362 for AltaVista counts and from .330 to .349 for Google counts.", "labels": [], "entities": [{"text": "correlation", "start_pos": 22, "end_pos": 33, "type": "METRIC", "confidence": 0.9824674725532532}]}, {"text": "For unseen bigrams, the correlations were somewhat higher, ranging from .386 to .439 for AltaVista counts and from .397 to .444 for Google counts.", "labels": [], "entities": []}, {"text": "For both seen and unseen bigrams, there was only a very small difference between the correlation coefficients obtained with the two search engines.", "labels": [], "entities": []}, {"text": "It is also interesting to compare the performance of class-based smoothing and Web counts on the task of predicting plausibility judgments.", "labels": [], "entities": [{"text": "predicting plausibility judgments", "start_pos": 105, "end_pos": 138, "type": "TASK", "confidence": 0.8973568677902222}]}, {"text": "The correlation coefficients are listed in.", "labels": [], "entities": [{"text": "correlation", "start_pos": 4, "end_pos": 15, "type": "METRIC", "confidence": 0.9836512207984924}]}, {"text": "The re-created frequencies are correlated significantly with all three types of bigrams, both for seen and unseen bigrams.", "labels": [], "entities": []}, {"text": "For the seen bigrams, we found that the correlation coefficients obtained using smoothed counts were significantly lower than the upper bound for all three types of bigrams (t(87) = 3.01, p < .01; t(87) = 3.23, p < .01; t(87) = 3.43, p < .01).", "labels": [], "entities": []}, {"text": "This result also held for the unseen bigrams: The correlations obtained using smoothing were significantly lower than the upper bound for all three types of bigrams (t(87) = 1.86, p < .05; t(87) = 1.97, p < .05; t(87) = 3.36, p < .01).", "labels": [], "entities": []}, {"text": "Recall that the correlation coefficients obtained using the Web counts were not found to be significantly different from the upper bound, which indicates that Web counts are better predictors of plausibility than smoothed counts.", "labels": [], "entities": []}, {"text": "This fact was confirmed by further significance testing: For seen bigrams, we found that the AltaVista correlation coefficients were significantly higher than correlation coefficients obtained using smoothing, for all three types of bigrams (t(87) = 3.31, p < .01; t(87) = 4.11, p < .01; t(87) = 4.32, p < .01).", "labels": [], "entities": []}, {"text": "This also held for Google counts (t(87) = 3.16, p < .01; t(87) = 4.02, p < .01; t(87) = 4.03, p < .01).", "labels": [], "entities": []}, {"text": "For unseen bigrams, the AltaVista coefficients and the coefficients obtained using smoothing were not significantly different for adjective-noun bigrams, but the difference reached significance for noun-noun and verb-object bigrams (t(87) = 2.08, p < .05; t(87) = 2.53, p < .01).", "labels": [], "entities": []}, {"text": "For Google counts, the difference was again not significant for adjective-noun bigrams, but it reached significance for noun-noun and verb-object bigrams (t(87) = 2.34, p < .05; t(87) = 2.15, p < .05).", "labels": [], "entities": []}, {"text": "Finally, we conducted a small study to investigate the validity of the counts that were re-created using class-based smoothing.", "labels": [], "entities": [{"text": "validity", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9439160227775574}]}, {"text": "We correlated the re-created counts for the seen bigrams with their actual BNC and NANTC frequencies.", "labels": [], "entities": [{"text": "BNC", "start_pos": 75, "end_pos": 78, "type": "DATASET", "confidence": 0.616997241973877}, {"text": "NANTC", "start_pos": 83, "end_pos": 88, "type": "DATASET", "confidence": 0.44259342551231384}]}, {"text": "The correlation coefficients are reported in.", "labels": [], "entities": [{"text": "correlation", "start_pos": 4, "end_pos": 15, "type": "METRIC", "confidence": 0.9845210909843445}]}, {"text": "We found that the correlation between recreated counts and corpus counts was significant for all three types of bigrams, for both corpora.", "labels": [], "entities": []}, {"text": "This demonstrates that the smoothing technique we employed generates realistic corpus counts, in the sense that the re-created counts are correlated with the actual counts.", "labels": [], "entities": []}, {"text": "However, the correlation coefficients obtained using Web counts were always substantially higher than those obtained using smoothed counts.", "labels": [], "entities": [{"text": "correlation", "start_pos": 13, "end_pos": 24, "type": "METRIC", "confidence": 0.9651475548744202}]}, {"text": "These differences were significant for the BNC counts for AltaVista (t(87) = 8.38, p < .01; t(87) = 5.00, p < .01; t(87) = 5.03, p < .01) and Google (t(87) = 8.35, p < .01; t(87) = 5.00, p < .01; t(87) = 5.03, p < .01).", "labels": [], "entities": [{"text": "BNC counts", "start_pos": 43, "end_pos": 53, "type": "DATASET", "confidence": 0.8226324021816254}, {"text": "Google", "start_pos": 142, "end_pos": 148, "type": "DATASET", "confidence": 0.9606184363365173}]}, {"text": "They were also significant for the NANTC counts for AltaVista (t(87) = 4.12, p < .01; t(87) = 3.72, p < .01; t(87) = 6.58, p < .01) and Google (t(87) = 4.08, p < .01; t(87) = 3.06, p < .01; t(87) = 6.47, p < .01).", "labels": [], "entities": [{"text": "NANTC", "start_pos": 35, "end_pos": 40, "type": "DATASET", "confidence": 0.8039795756340027}, {"text": "AltaVista", "start_pos": 52, "end_pos": 61, "type": "DATASET", "confidence": 0.8637930750846863}, {"text": "Google", "start_pos": 136, "end_pos": 142, "type": "DATASET", "confidence": 0.9635142087936401}]}, {"text": "To summarize, the results presented in this section indicate that Web counts are indeed a valid way of obtaining counts for bigrams that are unseen in a given corpus: They correlate reliably with counts re-created using class-based smoothing.", "labels": [], "entities": []}, {"text": "For seen bigrams, we found that Web counts correlate with counts that were re-created using smoothing techniques (after removing the seen bigrams from the training corpus).", "labels": [], "entities": []}, {"text": "For the task of predicting plausibility judgments, we were able to show that Web counts outperform re-created counts, both for seen and for unseen bigrams.", "labels": [], "entities": [{"text": "predicting plausibility judgments", "start_pos": 16, "end_pos": 49, "type": "TASK", "confidence": 0.9219350616137186}]}, {"text": "Finally, we found that Web counts for seen bigrams correlate better than re-created counts with the real corpus counts.", "labels": [], "entities": []}, {"text": "It is beyond the scope of the present study to undertake a full comparison between Web counts and frequencies re-created using all available smoothing techniques (and all available taxonomies that might be used for class-based smoothing).", "labels": [], "entities": []}, {"text": "The smoothing method discussed above is simply one type of class-based smoothing.", "labels": [], "entities": []}, {"text": "Other, more sophisticated class-based methods do away with the simplifying assumption that the argument co-occurring with a given predicate (adjective, noun, verb) is distributed evenly across its conceptual classes and attempt to find the right level of generalization in a concept hierarchy, by discounting, for example, the contribution of very general classes.", "labels": [], "entities": []}, {"text": "Other smoothing approaches such as discounting and distance-weighted averaging) re-create counts of unseen word combinations by exploiting only corpus-internal evidence, without relying on taxonomic information.", "labels": [], "entities": []}, {"text": "Our goal was to demonstrate that frequencies retrieved from the Web area viable alternative to conventional smoothing methods when data are sparse; we do not claim that our Web-based method is necessarily superior to smoothing or that it should be generally preferred over smoothing methods.", "labels": [], "entities": []}, {"text": "However, the next section will present a small-scale study that compares the performance of several smoothing techniques with the performance of Web counts on a standard task from the literature.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4  Log-transformed NANTC counts for seen adjective-noun, noun-noun, and verb-object bigrams.", "labels": [], "entities": []}, {"text": " Table 5  Number of zero counts returned by queries to search engines and in the NANTC (for bigrams  unseen in BNC).", "labels": [], "entities": [{"text": "NANTC", "start_pos": 81, "end_pos": 86, "type": "DATASET", "confidence": 0.9519168138504028}]}, {"text": " Table 7  Average factor by which Web counts are larger than BNC counts (seen bigrams).", "labels": [], "entities": []}, {"text": " Table 10  Descriptive statistics for plausibility judgments (log-transformed). N is the number of subjects  used in each experiment.", "labels": [], "entities": []}, {"text": " Table 13  Percentage of correct disambiguations on the pseudodisambiguation task using Web counts  and counts re-created using EM-based clustering (", "labels": [], "entities": []}, {"text": " Table 14  Percentage of correct disambiguations on the pseudodisambiguation task using Web counts  and counts re-created using EM-based clustering (Prescher, Riezler, and Rooth 2000).", "labels": [], "entities": []}, {"text": " Table 15  Percentage of correct disambiguations on the pseudodisambiguation task using Web counts  and counts re-created using class-based smoothing", "labels": [], "entities": []}]}