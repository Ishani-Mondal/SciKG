{"title": [{"text": "Disambiguating Nouns, Verbs, and Adjectives Using Automatically Acquired Selectional Preferences", "labels": [], "entities": []}], "abstractContent": [{"text": "Selectional preferences have been used byword sense disambiguation (WSD) systems as one source of disambiguating information.", "labels": [], "entities": [{"text": "sense disambiguation (WSD)", "start_pos": 46, "end_pos": 72, "type": "TASK", "confidence": 0.7065489530563355}]}, {"text": "We evaluate WSD using selectional preferences acquired for English adjective-noun, subject, and direct object grammatical relationships with respect to a standard test corpus.", "labels": [], "entities": [{"text": "WSD", "start_pos": 12, "end_pos": 15, "type": "TASK", "confidence": 0.9617857933044434}]}, {"text": "The selectional preferences are specific to verb or adjective classes, rather than individual word forms, so they can be used to disambiguate the co-occurring adjectives and verbs, rather than just the nominal argument heads.", "labels": [], "entities": []}, {"text": "We also investigate use of the one-sense-per-discourse heuristic to propagate a sense tag fora word to other occurrences of the same word within the current document in order to increase coverage.", "labels": [], "entities": []}, {"text": "Although the preferences perform well in comparison with other unsupervised WSD systems on the same corpus, the results show that for many applications, further knowledge sources would be required to achieve an adequate level of accuracy and coverage.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 229, "end_pos": 237, "type": "METRIC", "confidence": 0.9979376792907715}]}, {"text": "In addition to quantifying performance, we analyze the results to investigate the situations in which the selectional preferences achieve the best precision and in which the one-sense-per-discourse heuristic increases performance.", "labels": [], "entities": [{"text": "precision", "start_pos": 147, "end_pos": 156, "type": "METRIC", "confidence": 0.9969666600227356}]}], "introductionContent": [{"text": "Although selectional preferences area possible knowledge source in an automatic word sense disambiguation (WDS) system, they are not a panacea.", "labels": [], "entities": [{"text": "word sense disambiguation (WDS)", "start_pos": 80, "end_pos": 111, "type": "TASK", "confidence": 0.7988986968994141}]}, {"text": "One problem is coverage: Most previous work has focused on acquiring selectional preferences for verbs and applying them to disambiguate nouns occurring at subject and direct object slots.", "labels": [], "entities": [{"text": "coverage", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9358541369438171}]}, {"text": "In normal running text, however, a large proportion of word tokens do not fall at these slots.", "labels": [], "entities": []}, {"text": "There has been some work looking at other slots, and on using nominal arguments as disambiguators for verbs, but the problem of coverage remains.", "labels": [], "entities": [{"text": "coverage", "start_pos": 128, "end_pos": 136, "type": "METRIC", "confidence": 0.8920925855636597}]}, {"text": "Selectional preferences can be used for WSD in combination with other knowledge sources, but there is a need to ascertain when they work well so that they can be utilized to their full advantage.", "labels": [], "entities": [{"text": "WSD", "start_pos": 40, "end_pos": 43, "type": "TASK", "confidence": 0.9815046191215515}]}, {"text": "This article is aimed at quantifying the disambiguation performance of automatically acquired selectional preferences in regard to nouns, verbs, and adjectives with respect to a standard test corpus and evaluation setup (SENSEVAL-2) and to identify strengths and weaknesses.", "labels": [], "entities": []}, {"text": "Although there is clearly a limit to coverage using preferences alone, because preferences are acquired only with respect to specific grammatical roles, we show that when dealing with running text, rather than isolated examples, coverage can be increased at little cost inaccuracy by using the one-sense-per-discourse heuristic.", "labels": [], "entities": []}, {"text": "We acquire selectional preferences as probability distributions over the WordNet) noun hyponym hierarchy.", "labels": [], "entities": [{"text": "WordNet) noun hyponym hierarchy", "start_pos": 73, "end_pos": 104, "type": "DATASET", "confidence": 0.8582346081733704}]}, {"text": "The probability distributions are conditioned on a verb or adjective class and a grammatical relationship.", "labels": [], "entities": []}, {"text": "A noun is disambiguated by using the preferences to give probability estimates for each of its senses in WordNet, that is, for WordNet synsets.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 105, "end_pos": 112, "type": "DATASET", "confidence": 0.9630269408226013}]}, {"text": "Verbs and adjectives are disambiguated by using the probability distributions and Bayes' rule to obtain an estimate of the probability of the adjective or verb class, given the noun and the grammatical relationship.", "labels": [], "entities": []}, {"text": "Previously, we evaluated noun and verb disambiguation on the English all-words task in the SENSEVAL-2 exercise (.", "labels": [], "entities": [{"text": "noun and verb disambiguation", "start_pos": 25, "end_pos": 53, "type": "TASK", "confidence": 0.6175854876637459}]}, {"text": "We now present results also using preferences for adjectives, again evaluated on the SENSEVAL-2 test corpus (but carried out after the formal evaluation deadline).", "labels": [], "entities": [{"text": "SENSEVAL-2 test corpus", "start_pos": 85, "end_pos": 107, "type": "DATASET", "confidence": 0.7761799693107605}]}, {"text": "The results are encouraging, given that this method does not rely for training on any hand-tagged data or frequency distributions derived from such data.", "labels": [], "entities": []}, {"text": "Although a modest amount of English sense-tagged data is available, we nevertheless believe it is important to investigate methods that do not require such data, because there will be languages or texts for which sense-tagged data fora given word is not available or relevant.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated our system using the SENSEVAL-2 test corpus on the English allwords task ().", "labels": [], "entities": [{"text": "SENSEVAL-2 test corpus", "start_pos": 34, "end_pos": 56, "type": "DATASET", "confidence": 0.7276241083939871}]}, {"text": "We entered a previous version of this system for the SENSEVAL-2 exercise, in three variants, under the names \"sussex-sel\" (selectional preferences), \"sussex-sel-ospd\" (with the OSPD heuristic), and \"sussex-sel-ospd-ana\" (with anaphora resolution).", "labels": [], "entities": [{"text": "SENSEVAL-2 exercise", "start_pos": 53, "end_pos": 72, "type": "TASK", "confidence": 0.8578000962734222}]}, {"text": "8 For SENSEVAL-2 we used only the direct object and subject slots, since we had not yet dealt with adjectives.", "labels": [], "entities": [{"text": "SENSEVAL-2", "start_pos": 6, "end_pos": 16, "type": "TASK", "confidence": 0.8777612447738647}]}, {"text": "In we show how our system fared at the time of SENSEVAL-2 compared to other unsupervised systems.", "labels": [], "entities": [{"text": "SENSEVAL-2", "start_pos": 47, "end_pos": 57, "type": "TASK", "confidence": 0.5517033338546753}]}, {"text": "We have also plotted the results of the supervised systems and the precision and recall achieved by using the most frequent sense (as listed in WordNet).", "labels": [], "entities": [{"text": "precision", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.9995326995849609}, {"text": "recall", "start_pos": 81, "end_pos": 87, "type": "METRIC", "confidence": 0.999000608921051}, {"text": "WordNet", "start_pos": 144, "end_pos": 151, "type": "DATASET", "confidence": 0.9778119921684265}]}, {"text": "In the work reported here, we attempted disambiguation for head nouns and verbs in subject and direct object relationships, and for adjectives and nouns in adjectivenoun relationships.", "labels": [], "entities": []}, {"text": "For each test instance, we applied subject preferences before direct object preferences, and direct object preferences before adjective-noun preferences.", "labels": [], "entities": []}, {"text": "We also propagated sense tags to test instances not in these relationships by applying the one-sense-per-discourse heuristic.", "labels": [], "entities": []}, {"text": "We did not use the SENSEVAL-2 coarse-grained classification, as this was not available at the time when we were acquiring the selectional preferences.", "labels": [], "entities": []}, {"text": "We therefore  do not include in the following the coarse-grained results; they are just slightly better than the fine-grained results, which seems to be typical of other systems.", "labels": [], "entities": [{"text": "coarse-grained", "start_pos": 50, "end_pos": 64, "type": "METRIC", "confidence": 0.976796567440033}]}, {"text": "Our latest overall results are shown in show the results both with and without the OSPD heuristic.", "labels": [], "entities": [{"text": "OSPD heuristic", "start_pos": 83, "end_pos": 97, "type": "DATASET", "confidence": 0.8928746283054352}]}, {"text": "The results for the English SENSEVAL-2 tasks were generally much lower than those for the original SENSEVAL competition.", "labels": [], "entities": [{"text": "SENSEVAL-2 tasks", "start_pos": 28, "end_pos": 44, "type": "TASK", "confidence": 0.6825169026851654}, {"text": "SENSEVAL competition", "start_pos": 99, "end_pos": 119, "type": "TASK", "confidence": 0.8062851428985596}]}, {"text": "At the time of the SENSEVAL-2 workshop, this was assumed to be due largely to the use of WordNet as the inventory, as opposed to HECTOR (Atkins 1993), but Palmer, Trang Dang, and Fellbaum (forthcoming) have subsequently shown that, at least for the lexical sample tasks, this was due to a harder selection of words, with a higher average level of polysemy.", "labels": [], "entities": [{"text": "SENSEVAL-2 workshop", "start_pos": 19, "end_pos": 38, "type": "TASK", "confidence": 0.8999755084514618}, {"text": "WordNet", "start_pos": 89, "end_pos": 96, "type": "DATASET", "confidence": 0.9408466219902039}]}, {"text": "For three of the most polysemous verbs that overlapped between the English lexical sample for SENSEVAL and SENSEVAL-2, the performance was comparable.", "labels": [], "entities": []}, {"text": "shows our precision results including use of the OSPD heuristic, broken down by part of speech.", "labels": [], "entities": [{"text": "precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9992591738700867}, {"text": "OSPD heuristic", "start_pos": 49, "end_pos": 63, "type": "DATASET", "confidence": 0.7200023233890533}]}, {"text": "Although the precision for nouns is greater than that for verbs, the difference is much less when we remove the trivial monosemous cases.", "labels": [], "entities": [{"text": "precision", "start_pos": 13, "end_pos": 22, "type": "METRIC", "confidence": 0.999464213848114}]}, {"text": "Nouns, verbs, and adjectives all outperform their random baseline for precision, and the difference is more marked when monosemous instances are dropped.", "labels": [], "entities": [{"text": "precision", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.9985219836235046}]}, {"text": "shows the precision results for polysemous words given the slot and the disambiguation source.", "labels": [], "entities": [{"text": "precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9994792342185974}]}, {"text": "Overall, once at least one word token has been disambiguated by the preferences, the OSPD heuristic seems to perform better than the selectional preferences.", "labels": [], "entities": []}, {"text": "We can see, however, that although this is certainly true for the nouns, the difference for the adjectives (1.3%) is less marked, and the preferences outperform OSPD for the verbs.", "labels": [], "entities": [{"text": "OSPD", "start_pos": 161, "end_pos": 165, "type": "DATASET", "confidence": 0.787804365158081}]}, {"text": "It seems that verbs obey the OSPD principle much less than nouns.", "labels": [], "entities": []}, {"text": "Also, verbs are best disambiguated by their direct objects, whereas nouns appear to be better disambiguated as subjects and when modified by adjectives.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2  Precision results by part of speech.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.8195275068283081}]}, {"text": " Table 3  Precision results for polysemous words by part of speech and slot or disambiguation source.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9623567461967468}, {"text": "slot", "start_pos": 71, "end_pos": 75, "type": "METRIC", "confidence": 0.9509462714195251}]}, {"text": " Table 4  Percentages of words with a different predominant sense in SemCor, across files and genres.", "labels": [], "entities": []}, {"text": " Table 5  Lemma/file combinations in SemCor with more than one sense evident.", "labels": [], "entities": []}]}