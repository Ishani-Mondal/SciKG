{"title": [], "abstractContent": [{"text": "In this article, we present a language-independent, unsupervised approach to sentence boundary detection.", "labels": [], "entities": [{"text": "sentence boundary detection", "start_pos": 77, "end_pos": 104, "type": "TASK", "confidence": 0.7314527928829193}]}, {"text": "It is based on the assumption that a large number of ambiguities in the determination of sentence boundaries can be eliminated once abbreviations have been identified.", "labels": [], "entities": []}, {"text": "Instead of relying on orthographic clues, the proposed system is able to detect abbreviations with high accuracy using three criteria that only require information about the candidate type itself and are independent of context: Abbreviations can be defined as a very tight collocation consisting of a truncated word and a final period, abbreviations are usually short, and abbreviations sometimes contain internal periods.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 104, "end_pos": 112, "type": "METRIC", "confidence": 0.985802412033081}]}, {"text": "We also show the potential of collocational evidence for two other important subtasks of sentence boundary disambiguation, namely, the detection of initials and ordinal numbers.", "labels": [], "entities": [{"text": "sentence boundary disambiguation", "start_pos": 89, "end_pos": 121, "type": "TASK", "confidence": 0.6486409505208334}]}, {"text": "The proposed system has been tested extensively on eleven different languages and on different text genres.", "labels": [], "entities": []}, {"text": "It achieves good results without any further amendments or language-specific resources.", "labels": [], "entities": []}, {"text": "We evaluate its performance against three different baselines and compare it to other systems for sentence boundary detection proposed in the literature.", "labels": [], "entities": [{"text": "sentence boundary detection", "start_pos": 98, "end_pos": 125, "type": "TASK", "confidence": 0.7450411518414816}]}], "introductionContent": [{"text": "The sentence is a fundamental and relatively well understood unit in theoretical and computational linguistics.", "labels": [], "entities": []}, {"text": "Many linguistic phenomena-such as collocations, idioms, and variable binding, to name a few-are constrained by the abstract concept 'sentence' in that they are confined by sentence boundaries.", "labels": [], "entities": []}, {"text": "The successful determination of these boundaries is thus a prerequisite for proper sentence processing.", "labels": [], "entities": [{"text": "sentence processing", "start_pos": 83, "end_pos": 102, "type": "TASK", "confidence": 0.7212930619716644}]}, {"text": "Sentence boundary detection is not a trivial task, though.", "labels": [], "entities": [{"text": "Sentence boundary detection", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.9381459951400757}]}, {"text": "Graphemes often serve more than one purpose in writing systems.", "labels": [], "entities": []}, {"text": "The period, which is employed as sentence boundary marker, is no exception.", "labels": [], "entities": [{"text": "sentence boundary marker", "start_pos": 33, "end_pos": 57, "type": "TASK", "confidence": 0.6965973873933157}]}, {"text": "It is also used to mark abbreviations, initials, ordinal numbers, and ellipses.", "labels": [], "entities": []}, {"text": "Moreover, a period can be used to mark an abbreviation and a sentence boundary at the same time.", "labels": [], "entities": []}, {"text": "In such cases, the second period is haplologically omitted and only one period is used as end-of-sentence and abbreviation marker.", "labels": [], "entities": []}, {"text": "Sentence boundary detection thus has to be considered as an instance of ambiguity resolution.", "labels": [], "entities": [{"text": "Sentence boundary detection", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.8954381148020426}]}, {"text": "The ambiguity of the period is illustrated by example (1).", "labels": [], "entities": []}], "datasetContent": [{"text": "We have tested our system extensively fora number of different languages and under different circumstances.", "labels": [], "entities": []}, {"text": "We report the results that we obtained from our experiments in Section 6.4, after giving a short characterization of the test corpora on which we did our evaluation in Section 6.1, defining the performance measures we use in Section 6.2 and proposing three baselines as lower bounds and standards of comparison in Section 6.3.", "labels": [], "entities": []}, {"text": "We compare our approach to other systems for sentence boundary detection proposed in the literature in Section 7.", "labels": [], "entities": [{"text": "sentence boundary detection", "start_pos": 45, "end_pos": 72, "type": "TASK", "confidence": 0.7583674192428589}]}, {"text": "We have tested Punkt on the various corpora introduced in Section 6.1.", "labels": [], "entities": []}, {"text": "In all cases, it was only provided with the unannotated test corpus as input and no further data whatsoever, most importantly, no lexicon and no list of abbreviations.", "labels": [], "entities": []}, {"text": "Its main classification task was to decide for all token-final periods whether they indicated the end of a sentence or not.", "labels": [], "entities": []}, {"text": "8 In addition, it had to decide for all token-final periods whether they were used as an abbreviation marker or were part of an ellipsis.", "labels": [], "entities": []}, {"text": "The results Punkt achieved on the newspaper corpora are presented in Section 6.4.1.", "labels": [], "entities": [{"text": "newspaper corpora", "start_pos": 34, "end_pos": 51, "type": "DATASET", "confidence": 0.9514381587505341}]}, {"text": "Those obtained for the remaining corpora are given in Section 6.4.2.", "labels": [], "entities": [{"text": "Section 6.4.2", "start_pos": 54, "end_pos": 67, "type": "DATASET", "confidence": 0.8713949918746948}]}, {"text": "In Section 6.4.3, we provide the results of an experiment in which we evaluated our system on all-uppercase and all-lowercase corpora.", "labels": [], "entities": []}, {"text": "As many competing systems require a list of abbreviations, we have carried out an experiment to determine the usefulness of abbreviation lists derived from general-purpose dictionaries.", "labels": [], "entities": []}, {"text": "The results are reported in Section 6.4.4.", "labels": [], "entities": []}, {"text": "Last but not least, we take a closer look at the architecture of Punkt in Section 6.4.5 by examining the contributions of its individual parts, look at remaining errors and problems in Section 6.4.6, and discuss the hypothesis that the methods and heuristics we use can be called language independent in Section 6.4.7.", "labels": [], "entities": [{"text": "Punkt in Section 6.4.5", "start_pos": 65, "end_pos": 87, "type": "DATASET", "confidence": 0.7943489849567413}]}, {"text": "shows the results that we obtained for the tasks of sentence boundary detection and abbreviation detection on the eleven newspaper corpora.", "labels": [], "entities": [{"text": "sentence boundary detection", "start_pos": 52, "end_pos": 79, "type": "TASK", "confidence": 0.7165498733520508}, {"text": "abbreviation detection", "start_pos": 84, "end_pos": 106, "type": "TASK", "confidence": 0.9061965346336365}]}, {"text": "We performed two test runs for each language: one with detection of ordinal numbers and one without a special treatment of numbers.", "labels": [], "entities": []}, {"text": "For languages such as English, which do not usually mark ordinal numbers with a final period, it is obviously preferable not to try to detect them.", "labels": [], "entities": []}, {"text": "In, we only report the best result from the two test runs for each language.", "labels": [], "entities": []}, {"text": "Those languages in which the period is not usually used to mark ordinal numbers and for which the test without special treatment of numbers achieved better results are italicized in the following tables.", "labels": [], "entities": []}, {"text": "However, even if the special treatment of numbers was not turned off for such languages, the resulting increase in the error rate was not very high, maximally 0.03%; see also Section 6.4.5.", "labels": [], "entities": [{"text": "error rate", "start_pos": 119, "end_pos": 129, "type": "METRIC", "confidence": 0.9857777059078217}]}, {"text": "For the sentence boundary detection task, the error rates Punkt achieved on the eleven newspaper corpora range from 2.12% on the Estonian corpus to only 0.35% on the German corpus with an average error rate of 1.26%.", "labels": [], "entities": [{"text": "sentence boundary detection", "start_pos": 8, "end_pos": 35, "type": "TASK", "confidence": 0.8161282738049825}, {"text": "error", "start_pos": 46, "end_pos": 51, "type": "METRIC", "confidence": 0.9879195690155029}, {"text": "Estonian corpus", "start_pos": 129, "end_pos": 144, "type": "DATASET", "confidence": 0.8951537013053894}, {"text": "German corpus", "start_pos": 166, "end_pos": 179, "type": "DATASET", "confidence": 0.8693434000015259}, {"text": "error rate", "start_pos": 196, "end_pos": 206, "type": "METRIC", "confidence": 0.9521332383155823}]}, {"text": "The error rates for abbreviation detection are slightly lower, lying between 1.75% on the Estonian corpus and 0.26% on the German corpus with an average of 0.80% for all eleven corpora.", "labels": [], "entities": [{"text": "error", "start_pos": 4, "end_pos": 9, "type": "METRIC", "confidence": 0.9873966574668884}, {"text": "abbreviation detection", "start_pos": 20, "end_pos": 42, "type": "TASK", "confidence": 0.9785401225090027}, {"text": "Estonian corpus", "start_pos": 90, "end_pos": 105, "type": "DATASET", "confidence": 0.9111188054084778}, {"text": "German corpus", "start_pos": 123, "end_pos": 136, "type": "DATASET", "confidence": 0.9080676138401031}]}, {"text": "compares Punkt's performance to that of the three baseline algorithms.", "labels": [], "entities": []}, {"text": "The error rates achieved by Punkt for the sentence boundary task are reduced by about 83% on average compared to the absolute baseline, by about 73% compared to the token-based baseline, and by almost 80% compared to the type-based baseline.", "labels": [], "entities": [{"text": "error", "start_pos": 4, "end_pos": 9, "type": "METRIC", "confidence": 0.9774847626686096}]}, {"text": "The error rates for the abbreviation detection task have decreased even more considerably, namely, by approximately 89% in comparison to the absolute baseline, by about 83% in comparison to the token-based baseline, and by almost 86% in comparison to the typebased baseline.", "labels": [], "entities": [{"text": "error", "start_pos": 4, "end_pos": 9, "type": "METRIC", "confidence": 0.963356614112854}, {"text": "abbreviation detection task", "start_pos": 24, "end_pos": 51, "type": "TASK", "confidence": 0.9335639874140421}]}, {"text": "Table 9 also shows that whereas the good performance of our system is quite stable across the eleven corpora with a standard deviation of only 0.49% for 9 One exception is the French corpus.", "labels": [], "entities": [{"text": "French corpus", "start_pos": 176, "end_pos": 189, "type": "DATASET", "confidence": 0.9627737402915955}]}, {"text": "It contains rankings from sports events in which ranks are indicated using digits and a following period.", "labels": [], "entities": []}, {"text": "Using the special detection of ordinal numbers on this corpus results in a lower error rate of 1.33% for the task of sentence boundary detection and 0.50% for abbreviation detection.", "labels": [], "entities": [{"text": "error rate", "start_pos": 81, "end_pos": 91, "type": "METRIC", "confidence": 0.9900678396224976}, {"text": "sentence boundary detection", "start_pos": 117, "end_pos": 144, "type": "TASK", "confidence": 0.7127203842004141}, {"text": "abbreviation detection", "start_pos": 159, "end_pos": 181, "type": "TASK", "confidence": 0.933055967092514}]}, {"text": "However, as ordinal numbers in French are not usually indicated with final periods, we have given the results of the system without special treatment of ordinal numbers for French in.", "labels": [], "entities": []}, {"text": "We have also tested the applicability of Punkt to single-case text.", "labels": [], "entities": []}, {"text": "The newspaper test corpora have been converted to all-uppercase and all-lowercase versions in order to determine how much Punkt is affected by the loss of capitalization information.", "labels": [], "entities": [{"text": "newspaper test corpora", "start_pos": 4, "end_pos": 26, "type": "DATASET", "confidence": 0.950971762339274}]}, {"text": "In fact, one should keep in mind, the performance of our system is only minimally affected by the loss of capitalization information, slightly more soon the all-lowercase corpora.", "labels": [], "entities": []}, {"text": "The error rate our system produces for the task of sentence boundary detection is 0.41% higher on average on the lowercase corpora than on the mixed-case corpora.", "labels": [], "entities": [{"text": "error rate", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.972519040107727}, {"text": "sentence boundary detection", "start_pos": 51, "end_pos": 78, "type": "TASK", "confidence": 0.7500417629877726}]}, {"text": "The increase in the error rate on the uppercase corpora is slightly lower: 0.29%.", "labels": [], "entities": [{"text": "error rate", "start_pos": 20, "end_pos": 30, "type": "METRIC", "confidence": 0.9840043783187866}]}, {"text": "For the task of abbreviation detection, the increase in the error rates is even lower: 0.14% on the lowercase corpora and 0.13% on the uppercase corpora.", "labels": [], "entities": [{"text": "abbreviation detection", "start_pos": 16, "end_pos": 38, "type": "TASK", "confidence": 0.9877810478210449}, {"text": "error rates", "start_pos": 60, "end_pos": 71, "type": "METRIC", "confidence": 0.9767886996269226}]}, {"text": "This is expected because Punkt only uses capitalization information as evidence during the token-based correction and reclassification stage and not as primary evidence for the detection of abbreviations.", "labels": [], "entities": [{"text": "token-based correction", "start_pos": 91, "end_pos": 113, "type": "TASK", "confidence": 0.6604381799697876}]}, {"text": "The experiments on the single-case corpora show that Punkt is quite robust and well suited also to process single-case text.", "labels": [], "entities": []}, {"text": "Punkt is able to dynamically detect abbreviations in the test corpus itself.", "labels": [], "entities": []}, {"text": "It therefore does not depend on precompiled abbreviation lists like some of its competitors; compare Section 7.", "labels": [], "entities": []}, {"text": "But even though an abbreviation list is not necessary for Punkt to perform well, such a list can easily be integrated into its architecture.", "labels": [], "entities": []}, {"text": "The abbreviations read from such a list are simply added to those the system has detected in the test corpus after the type-based stage.", "labels": [], "entities": []}, {"text": "Ideally, one would use a domain-specific abbreviation list if the domain of the test corpus is known beforehand.", "labels": [], "entities": []}, {"text": "However, we wanted to determine the usefulness of general-purpose abbreviation lists derived from general-purpose dictionaries.", "labels": [], "entities": []}, {"text": "We have therefore built such abbreviation lists by extracting by hand all abbreviations from a German spelling dictionary-the Rechtschreibduden (Dudenredaktion 2004)-and all English abbreviations from a bilingual dictionary-the small Muret-Sanders English-German dictionary by Langenscheidt (.", "labels": [], "entities": [{"text": "German spelling dictionary-the Rechtschreibduden (Dudenredaktion 2004)-", "start_pos": 95, "end_pos": 166, "type": "DATASET", "confidence": 0.6889451965689659}]}, {"text": "This yielded a total number of 769 abbreviations for German and 1,537 for English; compare.", "labels": [], "entities": []}, {"text": "We then made three additional versions of these lists from which we deleted potentially harmful entries: one from which we removed all abbreviations that had obvious non-abbreviation homographs, one from which we removed all single-character abbreviations, and one from which we removed both.", "labels": [], "entities": []}, {"text": "gives the number of remaining abbreviations for these different versions.", "labels": [], "entities": []}, {"text": "We produced these additional versions to test how much care is needed when preparing abbreviation lists fora system like Punkt.", "labels": [], "entities": [{"text": "Punkt", "start_pos": 121, "end_pos": 126, "type": "DATASET", "confidence": 0.9728221893310547}]}, {"text": "We then carried out two experiments on the German and English newspaper corpora and the Brown corpus.", "labels": [], "entities": [{"text": "German and English newspaper corpora", "start_pos": 43, "end_pos": 79, "type": "DATASET", "confidence": 0.6528508186340332}, {"text": "Brown corpus", "start_pos": 88, "end_pos": 100, "type": "DATASET", "confidence": 0.961432695388794}]}, {"text": "In the first experiment, we tested how well Punkt performed when it was provided with the different abbreviation lists in addition to the abbreviations it was able to detect on the fly; see for the results.", "labels": [], "entities": []}, {"text": "The results show that Punkt can indeed benefit from additional abbreviation lists, but only if these are prepared with care.", "labels": [], "entities": [{"text": "Punkt", "start_pos": 22, "end_pos": 27, "type": "DATASET", "confidence": 0.9299800395965576}]}, {"text": "Providing such a carefully prepared  abbreviation list reduced the error rate of our system on the WSJ corpus from 1.65% to 1.58%, the error rate on the Brown corpus from 1.02% to 0.92%, and the error rate on the German NZZ corpus from 0.35% to 0.32%.", "labels": [], "entities": [{"text": "error rate", "start_pos": 67, "end_pos": 77, "type": "METRIC", "confidence": 0.9908938705921173}, {"text": "WSJ corpus", "start_pos": 99, "end_pos": 109, "type": "DATASET", "confidence": 0.9860051572322845}, {"text": "error rate", "start_pos": 135, "end_pos": 145, "type": "METRIC", "confidence": 0.983704537153244}, {"text": "Brown corpus", "start_pos": 153, "end_pos": 165, "type": "DATASET", "confidence": 0.9844781160354614}, {"text": "error rate", "start_pos": 195, "end_pos": 205, "type": "METRIC", "confidence": 0.9746235013008118}, {"text": "German NZZ corpus", "start_pos": 213, "end_pos": 230, "type": "DATASET", "confidence": 0.8773676554361979}]}, {"text": "Additional general-purpose abbreviation lists thus do improve the performance of our system, but the decrease of the error rate is not very great.", "labels": [], "entities": [{"text": "error rate", "start_pos": 117, "end_pos": 127, "type": "METRIC", "confidence": 0.9826689958572388}]}, {"text": "Table 14 also shows that abbreviation lists from which abbreviations homographic to ordinary words and single-character abbreviations have not been removed are not helpful at all and instead lead to an increased error rate on all of the three corpora.", "labels": [], "entities": [{"text": "error rate", "start_pos": 212, "end_pos": 222, "type": "METRIC", "confidence": 0.9746718108654022}]}, {"text": "In the second experiment, Punkt could only use the abbreviations on the different lists and was not allowed to add any additional abbreviations on the fly.", "labels": [], "entities": []}, {"text": "This experiment thus really tests the coverage of general-purpose abbreviation lists and also the productivity of abbreviation use in the test corpora.", "labels": [], "entities": []}, {"text": "contains the results from this experiment.", "labels": [], "entities": []}, {"text": "The column On the fly gives the error rates that Punkt achieved in its normal configuration detecting abbreviations on the fly without being provided with an additional abbreviation list.", "labels": [], "entities": [{"text": "error rates", "start_pos": 32, "end_pos": 43, "type": "METRIC", "confidence": 0.9700862765312195}]}, {"text": "The remaining columns show the results it produced when it could use a fixed list of abbreviations only.", "labels": [], "entities": []}, {"text": "A comparison between the first column and the other columns makes clear that abbreviation use in the corpora is quite productive and that fixed general-purpose abbreviation lists are clearly not sufficient for sentence boundary detection.", "labels": [], "entities": [{"text": "sentence boundary detection", "start_pos": 210, "end_pos": 237, "type": "TASK", "confidence": 0.7330057422320048}]}, {"text": "A versatile sentence boundary detection system should therefore always be able to detect unknown abbreviations on the fly.", "labels": [], "entities": [{"text": "sentence boundary detection", "start_pos": 12, "end_pos": 39, "type": "TASK", "confidence": 0.7403554121653239}]}], "tableCaptions": [{"text": " Table 1  Correct and incorrect frequent sentence starters.", "labels": [], "entities": [{"text": "sentence starters", "start_pos": 41, "end_pos": 58, "type": "TASK", "confidence": 0.6645784974098206}]}, {"text": " Table 2  Candidate list from an English test corpus.", "labels": [], "entities": [{"text": "English test corpus", "start_pos": 33, "end_pos": 52, "type": "DATASET", "confidence": 0.9074802001317342}]}, {"text": " Table 3  Example data for the orthographic heuristic.", "labels": [], "entities": []}, {"text": " Table 7  Statistical properties of the test corpora.", "labels": [], "entities": []}, {"text": " Table 8  Results of classification-newspaper corpora (mixed case).", "labels": [], "entities": [{"text": "classification-newspaper corpora", "start_pos": 21, "end_pos": 53, "type": "TASK", "confidence": 0.8209279179573059}]}, {"text": " Table 9  Comparison with the baselines-newspaper corpora (mixed case).", "labels": [], "entities": []}, {"text": " Table 10  Results of classification-other corpora (mixed case).", "labels": [], "entities": []}, {"text": " Table 11  Comparison with the baselines-other corpora (mixed case).", "labels": [], "entities": []}, {"text": " Table 12  Results of classification-newspaper corpora (single case).", "labels": [], "entities": [{"text": "classification-newspaper corpora", "start_pos": 22, "end_pos": 54, "type": "TASK", "confidence": 0.8428147733211517}]}, {"text": " Table 14  Results of classification-using an additional abbreviation list.", "labels": [], "entities": []}, {"text": " Table 15  Results of classification-using only a fixed abbreviation list.", "labels": [], "entities": []}, {"text": " Table 16  Configurations for testing the effectiveness of separate reclassification in the token-based stage.", "labels": [], "entities": []}, {"text": " Table 17  Contributions of separate reclassifications-newspaper corpora (mixed case).", "labels": [], "entities": []}, {"text": " Table 19  Contributions of the heuristics-newspaper corpora (mixed case).", "labels": [], "entities": []}, {"text": " Table 20  Difference between lowest error rate and error rate achieved with a threshold of 0.3.", "labels": [], "entities": [{"text": "error rate", "start_pos": 37, "end_pos": 47, "type": "METRIC", "confidence": 0.9103807508945465}, {"text": "error rate", "start_pos": 52, "end_pos": 62, "type": "METRIC", "confidence": 0.9904663860797882}]}, {"text": " Table 21  Comparison between MxTerminator (Reynar and Ratnaparkhi 1997) and the Punkt System.", "labels": [], "entities": [{"text": "MxTerminator (Reynar and Ratnaparkhi 1997)", "start_pos": 30, "end_pos": 72, "type": "DATASET", "confidence": 0.8234189833913531}, {"text": "Punkt System", "start_pos": 81, "end_pos": 93, "type": "DATASET", "confidence": 0.9682384133338928}]}, {"text": " Table 22  Direct comparison between Punkt and other systems for sentence boundary detection.", "labels": [], "entities": [{"text": "sentence boundary detection", "start_pos": 65, "end_pos": 92, "type": "TASK", "confidence": 0.7474632759888967}]}]}