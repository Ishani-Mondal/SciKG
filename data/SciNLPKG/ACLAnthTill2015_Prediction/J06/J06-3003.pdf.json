{"title": [], "abstractContent": [{"text": "There are at least two kinds of similarity.", "labels": [], "entities": [{"text": "similarity", "start_pos": 32, "end_pos": 42, "type": "METRIC", "confidence": 0.9580373764038086}]}, {"text": "Relational similarity is correspondence between relations , in contrast with attributional similarity, which is correspondence between attributes.", "labels": [], "entities": []}, {"text": "When two words have a high degree of attributional similarity, we call them synonyms.", "labels": [], "entities": []}, {"text": "When two pairs of words have a high degree of relational similarity, we say that their relations are analogous.", "labels": [], "entities": []}, {"text": "For example, the word pair mason:stone is analogous to the pair carpenter:wood.", "labels": [], "entities": []}, {"text": "This article introduces Latent Relational Analysis (LRA), a method for measuring relational similarity.", "labels": [], "entities": [{"text": "Latent Relational Analysis (LRA)", "start_pos": 24, "end_pos": 56, "type": "TASK", "confidence": 0.7543921172618866}]}, {"text": "LRA has potential applications in many areas, including information extraction, word sense disambiguation, and information retrieval.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 56, "end_pos": 78, "type": "TASK", "confidence": 0.8431583046913147}, {"text": "word sense disambiguation", "start_pos": 80, "end_pos": 105, "type": "TASK", "confidence": 0.7315841714541117}, {"text": "information retrieval", "start_pos": 111, "end_pos": 132, "type": "TASK", "confidence": 0.8457051217556}]}, {"text": "Recently the Vector Space Model (VSM) of information retrieval has been adapted to measuring relational similarity, achieving a score of 47% on a collection of 374 college-level multiple-choice word analogy questions.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 41, "end_pos": 62, "type": "TASK", "confidence": 0.7183731496334076}]}, {"text": "In the VSM approach, the relation between a pair of words is characterized by a vector of frequencies of predefined patterns in a large corpus.", "labels": [], "entities": [{"text": "VSM", "start_pos": 7, "end_pos": 10, "type": "TASK", "confidence": 0.8818082809448242}]}, {"text": "LRA extends the VSM approach in three ways: (1) The patterns are derived automatically from the corpus, (2) the Singular Value Decomposition (SVD) is used to smooth the frequency data, and (3) automatically generated synonyms are used to explore variations of the word pairs.", "labels": [], "entities": [{"text": "VSM", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.9297770857810974}, {"text": "Singular Value Decomposition (SVD)", "start_pos": 112, "end_pos": 146, "type": "METRIC", "confidence": 0.7056685288747152}]}, {"text": "LRA achieves 56% on the 374 analogy questions, statistically equivalent to the average human score of 57%.", "labels": [], "entities": [{"text": "LRA", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.6557746529579163}]}, {"text": "On the related problem of classifying semantic relations, LRA achieves similar gains over the VSM.", "labels": [], "entities": [{"text": "classifying semantic relations", "start_pos": 26, "end_pos": 56, "type": "TASK", "confidence": 0.8573499719301859}, {"text": "LRA", "start_pos": 58, "end_pos": 61, "type": "METRIC", "confidence": 0.7491879463195801}, {"text": "VSM", "start_pos": 94, "end_pos": 97, "type": "DATASET", "confidence": 0.8331040740013123}]}], "introductionContent": [{"text": "There are at least two kinds of similarity.", "labels": [], "entities": [{"text": "similarity", "start_pos": 32, "end_pos": 42, "type": "METRIC", "confidence": 0.9580373764038086}]}, {"text": "Attributional similarity is correspondence between attributes and relational similarity is correspondence between relations.", "labels": [], "entities": []}, {"text": "When two words have a high degree of attributional similarity, we call them synonyms.", "labels": [], "entities": []}, {"text": "When two word pairs have a high degree of relational similarity, we say they are analogous.", "labels": [], "entities": []}, {"text": "Verbal analogies are often written in the form A:B::C:D, meaning A is to B as C is to D; for example, traffic:street::water:riverbed.", "labels": [], "entities": []}, {"text": "Traffic flows over a street; water flows over a riverbed.", "labels": [], "entities": []}, {"text": "A street carries traffic; a riverbed carries water.", "labels": [], "entities": []}, {"text": "There is a high degree of relational similarity between the word pair traffic:street and the word pair water:riverbed.", "labels": [], "entities": []}, {"text": "In fact, this analogy is the basis of several mathematical theories of traffic flow.", "labels": [], "entities": [{"text": "traffic flow", "start_pos": 71, "end_pos": 83, "type": "TASK", "confidence": 0.8244534730911255}]}, {"text": "In Section 2, we look more closely at the connections between attributional and relational similarity.", "labels": [], "entities": []}, {"text": "In analogies such as mason:stone::carpenter:wood, it seems that relational similarity can be reduced to attributional similarity, since mason and carpenter are attributionally similar, as are stone and wood.", "labels": [], "entities": []}, {"text": "In general, this reduction fails.", "labels": [], "entities": []}, {"text": "Consider the analogy traffic:street::water:riverbed.", "labels": [], "entities": []}, {"text": "Traffic and water are not attributionally similar.", "labels": [], "entities": []}, {"text": "Street and riverbed are only moderately attributionally similar.", "labels": [], "entities": []}, {"text": "Many algorithms have been proposed for measuring the attributional similarity between two words.", "labels": [], "entities": []}, {"text": "Measures of attributional similarity have been studied extensively, due to their applications in problems such as recognizing synonyms, information retrieval), determining semantic orientation, grading student essays (), measuring textual cohesion, and word sense disambiguation).", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 136, "end_pos": 157, "type": "TASK", "confidence": 0.7220193445682526}, {"text": "determining semantic orientation", "start_pos": 160, "end_pos": 192, "type": "TASK", "confidence": 0.6306881407896677}, {"text": "word sense disambiguation", "start_pos": 253, "end_pos": 278, "type": "TASK", "confidence": 0.6902992129325867}]}, {"text": "On the other hand, since measures of relational similarity are not as well developed as measures of attributional similarity, the potential applications of relational similarity are not as well known.", "labels": [], "entities": []}, {"text": "Many problems that involve semantic relations would benefit from an algorithm for measuring relational similarity.", "labels": [], "entities": []}, {"text": "We discuss related problems in natural language processing, information retrieval, and information extraction in more detail in Section 3.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 31, "end_pos": 58, "type": "TASK", "confidence": 0.630945066610972}, {"text": "information retrieval", "start_pos": 60, "end_pos": 81, "type": "TASK", "confidence": 0.8369661867618561}, {"text": "information extraction", "start_pos": 87, "end_pos": 109, "type": "TASK", "confidence": 0.839729368686676}]}, {"text": "This article builds on the Vector Space Model (VSM) of information retrieval.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 55, "end_pos": 76, "type": "TASK", "confidence": 0.8372491598129272}]}, {"text": "Given a query, a search engine produces a ranked list of documents.", "labels": [], "entities": []}, {"text": "The documents are ranked in order of decreasing attributional similarity between the query and each document.", "labels": [], "entities": []}, {"text": "Almost all modern search engines measure attributional similarity using the VSM (Baeza-Yates and.", "labels": [], "entities": [{"text": "VSM", "start_pos": 76, "end_pos": 79, "type": "DATASET", "confidence": 0.5919651389122009}]}, {"text": "adapt the VSM approach to measuring relational similarity.", "labels": [], "entities": []}, {"text": "They used a vector of frequencies of patterns in a corpus to represent the relation between a pair of words.", "labels": [], "entities": []}, {"text": "Section 4 presents the VSM approach to measuring similarity.", "labels": [], "entities": [{"text": "VSM", "start_pos": 23, "end_pos": 26, "type": "TASK", "confidence": 0.8355642557144165}]}, {"text": "In Section 5, we present an algorithm for measuring relational similarity, which we call Latent Relational Analysis (LRA).", "labels": [], "entities": [{"text": "Latent Relational Analysis (LRA)", "start_pos": 89, "end_pos": 121, "type": "TASK", "confidence": 0.5644324570894241}]}, {"text": "The algorithm learns from a large corpus of unlabeled, unstructured text, without supervision.", "labels": [], "entities": []}, {"text": "LRA extends the VSM approach of in three ways: (1) The connecting patterns are derived automatically from the corpus, instead of using a fixed set of patterns.", "labels": [], "entities": [{"text": "VSM", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.8989530205726624}]}, {"text": "(2) Singular Value Decomposition (SVD) is used to smooth the frequency data.", "labels": [], "entities": [{"text": "Singular Value Decomposition (SVD)", "start_pos": 4, "end_pos": 38, "type": "TASK", "confidence": 0.5344481766223907}]}, {"text": "(3) Given a word pair such as traffic:street, LRA considers transformations of the word pair, generated by replacing one of the words by synonyms, such as traffic:road or traffic:highway.", "labels": [], "entities": []}, {"text": "Section 6 presents our experimental evaluation of LRA with a collection of 374 multiple-choice word analogy questions from the SAT college entrance exam.", "labels": [], "entities": [{"text": "LRA", "start_pos": 50, "end_pos": 53, "type": "TASK", "confidence": 0.6742265224456787}]}, {"text": "An example of atypical SAT question appears in.", "labels": [], "entities": [{"text": "SAT", "start_pos": 23, "end_pos": 26, "type": "METRIC", "confidence": 0.6746160387992859}]}, {"text": "In the educational testing literature, the first pair (mason:stone) is called the stem of the analogy.", "labels": [], "entities": []}, {"text": "The correct choice is called the solution and the incorrect choices are distractors.", "labels": [], "entities": []}, {"text": "We evaluate LRA by testing its ability to select the solution and avoid the distractors.", "labels": [], "entities": []}, {"text": "The average performance of collegebound senior high school students on verbal SAT questions corresponds to an accuracy of about 57%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 110, "end_pos": 118, "type": "METRIC", "confidence": 0.9996472597122192}]}, {"text": "LRA achieves an accuracy of about 56%.", "labels": [], "entities": [{"text": "LRA", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.785250186920166}, {"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.999653697013855}]}, {"text": "On these same questions, the VSM attained 47%.", "labels": [], "entities": [{"text": "VSM", "start_pos": 29, "end_pos": 32, "type": "DATASET", "confidence": 0.6134869456291199}]}, {"text": "One application for relational similarity is classifying semantic relations in nounmodifier pairs.", "labels": [], "entities": [{"text": "classifying semantic relations in nounmodifier pairs", "start_pos": 45, "end_pos": 97, "type": "TASK", "confidence": 0.7699142793814341}]}, {"text": "In Section 7, we evaluate the performance of LRA with a set of 600 noun-modifier pairs from.", "labels": [], "entities": []}, {"text": "The problem is to classify a noun-modifier pair, such as \"laser printer,\" according to the semantic relation between the head noun (printer) and the modifier (laser).", "labels": [], "entities": []}, {"text": "The 600 pairs have been manually labeled with 30 classes of semantic relations.", "labels": [], "entities": []}, {"text": "For example, \"laser printer\" is classified as instrument; the printer uses the laser as an instrument for printing.", "labels": [], "entities": []}], "datasetContent": [{"text": "This section presents various experiments with 374 multiple-choice SAT word analogy questions.", "labels": [], "entities": [{"text": "multiple-choice SAT word analogy", "start_pos": 51, "end_pos": 83, "type": "TASK", "confidence": 0.6320925131440163}]}, {"text": "shows the performance of the baseline LRA system on the 374 SAT questions, using the parameter settings and configuration described in Section 5.", "labels": [], "entities": []}, {"text": "LRA correctly answered 210 of the 374 questions; 160 questions were answered incorrectly and 4 questions were skipped, because the stem pair and its alternates were represented by zero vectors.", "labels": [], "entities": []}, {"text": "The performance of LRA is significantly better than the lexicon-based approach of Veale (2004) (see Section 3.1) and the best performance using attributional similarity (see Section 2.3), with 95% confidence, according to the Fisher Exact Test).", "labels": [], "entities": [{"text": "LRA", "start_pos": 19, "end_pos": 22, "type": "METRIC", "confidence": 0.7660484910011292}]}, {"text": "As mentioned in the introduction, LRA extends the VSM approach of by exploring variations on the analogies by replacing words with synonyms (step 1), (2) automatically generating connecting patterns (step 4), and (3) smoothing the data with SVD (step 9).", "labels": [], "entities": []}, {"text": "In this subsection, we ablate each of these three components to assess their contribution to the performance of LRA.", "labels": [], "entities": [{"text": "LRA", "start_pos": 112, "end_pos": 115, "type": "TASK", "confidence": 0.744896650314331}]}, {"text": "This section describes experiments with 600 noun-modifier pairs, hand-labeled with 30 classes of semantic relations.", "labels": [], "entities": []}, {"text": "In the following experiments, LRA is used with the baseline parameter values, exactly as described in Section 5.5.", "labels": [], "entities": [{"text": "LRA", "start_pos": 30, "end_pos": 33, "type": "METRIC", "confidence": 0.9975340366363525}]}, {"text": "No adjustments were made to tune LRA to the noun-modifier pairs.", "labels": [], "entities": [{"text": "LRA", "start_pos": 33, "end_pos": 36, "type": "METRIC", "confidence": 0.9677916765213013}]}, {"text": "LRA is used as a distance (nearness) measure in a single nearest neighbor supervised learning algorithm.", "labels": [], "entities": [{"text": "LRA", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.9598578810691833}, {"text": "distance (nearness) measure", "start_pos": 17, "end_pos": 44, "type": "METRIC", "confidence": 0.7700165510177612}]}], "tableCaptions": [{"text": " Table 4  Performance of attributional similarity measures on the 374 SAT questions. Precision, recall, and  F are reported as percentages. (The bottom two rows are not attributional similarity measures.  They are included for comparison.)", "labels": [], "entities": [{"text": "Precision", "start_pos": 85, "end_pos": 94, "type": "METRIC", "confidence": 0.998976469039917}, {"text": "recall", "start_pos": 96, "end_pos": 102, "type": "METRIC", "confidence": 0.9904871582984924}, {"text": "F", "start_pos": 109, "end_pos": 110, "type": "METRIC", "confidence": 0.9027593731880188}]}, {"text": " Table 7  Alternate forms of the original pair quart:volume. The first column shows the original pair and  the alternate pairs. The second column shows Lin's similarity score for the alternate word  compared to the original word. For example, the similarity between quart and pint is 0.210. The  third column shows the frequency of the pair in the WMTS corpus. The fourth column shows the  pairs that pass the filtering step (i.e., step 2).", "labels": [], "entities": [{"text": "Lin's similarity score", "start_pos": 152, "end_pos": 174, "type": "METRIC", "confidence": 0.7522246241569519}, {"text": "WMTS corpus", "start_pos": 348, "end_pos": 359, "type": "DATASET", "confidence": 0.9385841190814972}]}, {"text": " Table 9  Frequencies of various patterns for quart:volume. The asterisk \"*\" represents the wildcard.  Suffixes are ignored, so quart matches quarts. For example, quarts in volume is one  of the four phrases that match quart P volume when P is in.", "labels": [], "entities": []}, {"text": " Table 10  The 16 combinations and their cosines. A:B::C:D expresses the analogy A is to B as C is to D. The  third column indicates those combinations for which the cosine is greater than or equal  to the cosine of the original analogy, quart:volume::mile:distance.", "labels": [], "entities": []}, {"text": " Table 6. Column 1 gives the averages of the cosines  that are greater than or equal to the original cosines (e.g., the average of the cosines that are  marked Yes in", "labels": [], "entities": []}, {"text": " Table 12  Performance of LRA on the 374 SAT questions. Precision, recall, and F are reported as  percentages. (The bottom five rows are included for comparison.)", "labels": [], "entities": [{"text": "LRA", "start_pos": 26, "end_pos": 29, "type": "METRIC", "confidence": 0.9501917362213135}, {"text": "Precision", "start_pos": 56, "end_pos": 65, "type": "METRIC", "confidence": 0.999548614025116}, {"text": "recall", "start_pos": 67, "end_pos": 73, "type": "METRIC", "confidence": 0.995499312877655}, {"text": "F", "start_pos": 79, "end_pos": 80, "type": "METRIC", "confidence": 0.9702252149581909}]}, {"text": " Table 13  LRA elapsed run time.", "labels": [], "entities": [{"text": "LRA elapsed run time", "start_pos": 11, "end_pos": 31, "type": "METRIC", "confidence": 0.8615464866161346}]}, {"text": " Table 14  LRA versus VSM with 374 SAT analogy questions.", "labels": [], "entities": [{"text": "LRA", "start_pos": 11, "end_pos": 14, "type": "METRIC", "confidence": 0.7169798016548157}, {"text": "VSM", "start_pos": 22, "end_pos": 25, "type": "DATASET", "confidence": 0.6316068768501282}]}, {"text": " Table 16  Variation in performance with different parameter values. The Baseline column marks the  baseline parameter values. The Step column gives the step number in Section 5.5 where each  parameter is discussed.", "labels": [], "entities": []}, {"text": " Table 17  Results of ablation experiments.", "labels": [], "entities": []}, {"text": " Table 18  Performance as a function of N.", "labels": [], "entities": []}, {"text": " Table 20  Comparison of LRA and VSM on the 30 class problem.", "labels": [], "entities": [{"text": "LRA", "start_pos": 25, "end_pos": 28, "type": "DATASET", "confidence": 0.6396276950836182}, {"text": "VSM", "start_pos": 33, "end_pos": 36, "type": "DATASET", "confidence": 0.818514347076416}]}, {"text": " Table 21  Comparison of LRA and VSM on the 5 class problem.", "labels": [], "entities": [{"text": "LRA", "start_pos": 25, "end_pos": 28, "type": "DATASET", "confidence": 0.5160709619522095}, {"text": "VSM", "start_pos": 33, "end_pos": 36, "type": "DATASET", "confidence": 0.7512384653091431}]}]}