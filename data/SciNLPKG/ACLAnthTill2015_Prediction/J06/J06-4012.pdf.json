{"title": [{"text": "Last Words Mark-up Barking Up the Wrong Tree", "labels": [], "entities": [{"text": "Last Words Mark-up Barking Up the Wrong Tree", "start_pos": 0, "end_pos": 44, "type": "DATASET", "confidence": 0.5682207643985748}]}], "abstractContent": [{"text": "PARC The interest in machine-learning methods to solve natural-language-understanding problems has led to the use of textual annotation as an important auxiliary technique.", "labels": [], "entities": [{"text": "PARC", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9051049947738647}]}, {"text": "Grammar induction based on annotation has been very successful for the Penn Treebank, where a corpus of English text was annotated with syntactic information.", "labels": [], "entities": [{"text": "Grammar induction", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8439378440380096}, {"text": "Penn Treebank", "start_pos": 71, "end_pos": 84, "type": "DATASET", "confidence": 0.9944810569286346}]}, {"text": "This shining example has inspired a plethora of annotation efforts: corpora are annotated for 'coreference', for animacy, for expressions of opinions, for temporal dependencies, for the estimated duration of the activities that the expressions refer to, and soon.", "labels": [], "entities": []}, {"text": "It is not clear though that these efforts are bound to repeat the success of the Penn Treebank.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 81, "end_pos": 94, "type": "DATASET", "confidence": 0.9930438995361328}]}, {"text": "The circumstances in which the Penn Treebank project was executed are vastly different from those in which most annotation tasks take place.", "labels": [], "entities": [{"text": "Penn Treebank project", "start_pos": 31, "end_pos": 52, "type": "DATASET", "confidence": 0.9880240758260092}]}, {"text": "First, the annotation was a linguistic task and one about which there is reasonable agreement.", "labels": [], "entities": []}, {"text": "People might quibble about the way to represent certain constituent structure distinctions in English, but they do, in general, not disagree about the distinctions themselves; and if you don't like the Treebank as is, you can translate it into your favorite format.", "labels": [], "entities": []}, {"text": "Second, the work was done by advanced students who understood the task and were supervised by specialists in the field.", "labels": [], "entities": []}, {"text": "Third, this was not done in a hurry.", "labels": [], "entities": []}, {"text": "The project started in 1989 and the corpora are still maintained and the annotations improved.", "labels": [], "entities": []}, {"text": "About the only thing that this project has in common with the bulk of annotation tasks is that the annotators were not very well paid.", "labels": [], "entities": []}, {"text": "Currently, we see annotation schemas being developed for phenomena that are much less well understood than constituent structure.", "labels": [], "entities": []}, {"text": "In workshops and conferences we hear lively discussions about interannotator agreement, about tools to make the annotation task easier, about how to cope with multiple annotations of the same text, about the development of international standards for annotation schemes in specific subdomains, and, most importantly, about the statistical models that can be built once the annotations are in place.", "labels": [], "entities": []}, {"text": "One thing that is much less discussed is whether the annotation indeed helps isolate the property that motivated it in the first place.", "labels": [], "entities": []}, {"text": "This is not the same as interannotator agreement.", "labels": [], "entities": []}, {"text": "For interannotator agreement, it suffices that all annotators do the same thing.", "labels": [], "entities": [{"text": "interannotator agreement", "start_pos": 4, "end_pos": 28, "type": "TASK", "confidence": 0.8215938210487366}]}, {"text": "But even with full annotator agreement it is not sure that the task captures what was initially intended.", "labels": [], "entities": []}, {"text": "Assume that I want to mark all the entities in a text that refer to the same entity with the same number and I tell my annotators \"Whenever you seethe word Chicago, give it the same number\": I'll get great interannotator agreement with that guideline but it is debatable whether I will realize my proclaimed aim of classifying references to one and the same entity in the outside world.", "labels": [], "entities": []}, {"text": "Presumably, I would like to catchall the references to the city of Chicago, but Chicago pizza is made and sold allover the United States, and the relation", "labels": [], "entities": [{"text": "catchall", "start_pos": 28, "end_pos": 36, "type": "TASK", "confidence": 0.9323099851608276}]}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}