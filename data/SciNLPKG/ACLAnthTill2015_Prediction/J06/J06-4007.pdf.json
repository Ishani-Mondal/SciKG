{"title": [], "abstractContent": [{"text": "Machine learning has become the predominant problem-solving strategy for computational linguistics problems in the last decade.", "labels": [], "entities": [{"text": "Machine learning", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7990555763244629}]}, {"text": "Many researchers work on improving algorithms, developing new ones, testing feature representation issues, and so forth.", "labels": [], "entities": []}, {"text": "Other researchers, however, apply machine-learning techniques as off-the-shelf implementation, often with little knowledge about the algorithms and intricacies of data representation issues.", "labels": [], "entities": []}, {"text": "In this book, Daelemans and van den Bosch provide an in-depth introduction to Memory-Based Language Processing (MBLP) that shows for different problems in NLP how the technique is successfully applied.", "labels": [], "entities": [{"text": "Memory-Based Language Processing (MBLP)", "start_pos": 78, "end_pos": 117, "type": "TASK", "confidence": 0.7128909329573313}]}, {"text": "Apart from the more practical issues, the book also explores the suitability of the chosen learning paradigm, memory-based learning (Stanfill and Waltz 1986), for NLP problems.", "labels": [], "entities": []}, {"text": "Thus the book is a valuable source of information fora wide range of readers from the linguist interested in applying machine-learning techniques or the machine-learning specialist with no prior experience in NLP to the expert in machine learning wanting to learn more about the appropriateness of the MBLP bias for NLP problems.", "labels": [], "entities": []}, {"text": "Memory-based learning is a machine-learning method based on the idea that examples can be re-used directly in processing natural language problems.", "labels": [], "entities": []}, {"text": "Training examples are stored without modification or abstraction.", "labels": [], "entities": []}, {"text": "During the classification process, the most similar examples from the training data are located, and their class is used to classify the new example.", "labels": [], "entities": []}, {"text": "The book addresses different levels of understanding and working with MBLP: On one level, it explains the theoretical concepts of memory-based learning; on another, it provides more practical information: The implementation of memory-based learning, TiMBL, is described as well as different extensions such as FamBL and MBT.", "labels": [], "entities": [{"text": "FamBL", "start_pos": 310, "end_pos": 315, "type": "METRIC", "confidence": 0.5586494207382202}, {"text": "MBT", "start_pos": 320, "end_pos": 323, "type": "DATASET", "confidence": 0.835491955280304}]}, {"text": "On a different level, the application of these techniques is described for typical problems in natural language processing.", "labels": [], "entities": []}, {"text": "The reader learns how to model standard classification problems such as POS tagging, as well as sequence-learning problems, which are more difficult to model as classification problems.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 72, "end_pos": 83, "type": "TASK", "confidence": 0.7231644541025162}]}, {"text": "Daelemans and van den Bosch also cover critical issues, such as problems that arise in the evaluation of such experiments and the automation of searching for suitable system parameter settings.", "labels": [], "entities": []}, {"text": "On a more abstract level, they approach the question of how suitable the bias of MBLP is.", "labels": [], "entities": [{"text": "MBLP", "start_pos": 81, "end_pos": 85, "type": "DATASET", "confidence": 0.5184445381164551}]}, {"text": "In chapter 6, they compare memory-based learning as an instance of lazy learning to an instance of eager learning, rule induction, with regard to their classification accuracy if, for example, more abstraction is introduced.", "labels": [], "entities": [{"text": "rule induction", "start_pos": 115, "end_pos": 129, "type": "TASK", "confidence": 0.6851391643285751}, {"text": "accuracy", "start_pos": 167, "end_pos": 175, "type": "METRIC", "confidence": 0.896805465221405}]}, {"text": "Since MBLP does not abstract over the training data, it is called a lazy learning approach.", "labels": [], "entities": [{"text": "MBLP", "start_pos": 6, "end_pos": 10, "type": "DATASET", "confidence": 0.46812599897384644}]}, {"text": "Rule induction, in contrast, learns rules and does not go back to the actual training data during classification.", "labels": [], "entities": [{"text": "Rule induction", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.8533391356468201}]}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}