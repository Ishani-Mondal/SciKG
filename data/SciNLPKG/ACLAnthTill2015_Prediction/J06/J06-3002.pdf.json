{"title": [{"text": "The Notion of Argument in Prepositional Phrase Attachment", "labels": [], "entities": [{"text": "Notion of Argument in Prepositional Phrase Attachment", "start_pos": 4, "end_pos": 57, "type": "TASK", "confidence": 0.7525479538100106}]}], "abstractContent": [{"text": "In this article we refine the formulation of the problem of prepositional phrase (PP) attachment as a four-way disambiguation problem.", "labels": [], "entities": [{"text": "prepositional phrase (PP) attachment", "start_pos": 60, "end_pos": 96, "type": "TASK", "confidence": 0.660312349597613}]}, {"text": "We argue that, in interpreting PPs, both knowledge about the site of the attachment (the traditional noun-verb attachment distinction) and the nature of the attachment (the distinction of arguments from adjuncts) are needed.", "labels": [], "entities": [{"text": "interpreting PPs", "start_pos": 18, "end_pos": 34, "type": "TASK", "confidence": 0.9072501957416534}]}, {"text": "We introduce a method to learn arguments and adjuncts based on a definition of arguments as a vector of features.", "labels": [], "entities": []}, {"text": "Ina series of supervised classification experiments, first we explore the features that enable us to learn the distinction between arguments and adjuncts.", "labels": [], "entities": []}, {"text": "We find that both linguistic diagnostics of argumenthood and lexical semantic classes are useful.", "labels": [], "entities": []}, {"text": "Second, we investigate the best method to reach the four-way classification of potentially ambiguous prepositional phrases.", "labels": [], "entities": [{"text": "classification of potentially ambiguous prepositional phrases", "start_pos": 61, "end_pos": 122, "type": "TASK", "confidence": 0.7298017144203186}]}, {"text": "We find that whereas it is overall better to solve the problem as a single four-way classification task, verb arguments are sometimes more precisely identified if the classification is done as a two-step process, first choosing the attachment site and then labeling it as argument or adjunct.", "labels": [], "entities": []}, {"text": "1. Motivation Incorrect attachment of prepositional phrases (PPs) often constitutes the largest single source of errors in current parsing systems.", "labels": [], "entities": [{"text": "Motivation Incorrect attachment of prepositional phrases (PPs)", "start_pos": 3, "end_pos": 65, "type": "TASK", "confidence": 0.8519872029622396}]}, {"text": "Correct attachment of PPs is necessary to construct a parse tree that will support the proper interpretation of constituents in the sentence.", "labels": [], "entities": []}, {"text": "Consider the timeworn example (1) I saw the man with the telescope.", "labels": [], "entities": []}, {"text": "It is important to determine if the PP with the telescope is to be attached as a sister to the noun the man, restricting its interpretation, or if it is to be attached to the verb, thereby indicating the instrument of the main action described by the sentence.", "labels": [], "entities": []}, {"text": "Based on examples of this sort, recent approaches have formalized the problem of disambiguating PP attachments as a binary choice, distinguishing between attachment of a PP to a given verb or to the verb's direct object (Hindle and Rooth 1993; Ratnaparkhi, Reynar, and", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "reports the accuracy in the argument-adjunct distinction of experiments that use only the most useful lexical and class features, the preposition and the verb class, and the diagnostic-based features, using combinations of diagnostic features.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9997192025184631}]}, {"text": "The combinations of features shown are those that yielded the best results over a development set of tuples extracted from Section 24 of the Penn Treebank.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 141, "end_pos": 154, "type": "DATASET", "confidence": 0.8825680315494537}]}, {"text": "The results reported are calculated over a test corresponding to the tuples in Section 23 of the Penn Treebank.", "labels": [], "entities": [{"text": "Section 23 of the Penn Treebank", "start_pos": 79, "end_pos": 110, "type": "DATASET", "confidence": 0.8849458495775858}]}, {"text": "The best combination, line 2, yields a 37% reduction of the error rate over the baseline.", "labels": [], "entities": [{"text": "error rate", "start_pos": 60, "end_pos": 70, "type": "METRIC", "confidence": 0.9849647283554077}]}, {"text": "All the differences in performance among these configurations are significant.", "labels": [], "entities": []}, {"text": "What all these combinations have in common is that they are combinations of three levels of granularity, mixing lexical information, class information, and higher level syntactic-semantic information, encoded indirectly in the diagnostics.", "labels": [], "entities": []}, {"text": "All the combinations that are not shown here have lower accuracies.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 56, "end_pos": 66, "type": "METRIC", "confidence": 0.9932996034622192}]}, {"text": "shows the confusion matrix for the combination of features with the best accuracy listed above.", "labels": [], "entities": [{"text": "confusion", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9526116847991943}, {"text": "accuracy", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9982806444168091}]}, {"text": "These figures yield a precision and recall for arguments of 80% and 85%, respectively (F measure = 82%); and a precision and recall for adjuncts of 80% and 73%, respectively (F measure = 76%).", "labels": [], "entities": [{"text": "precision", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.9994762539863586}, {"text": "recall", "start_pos": 36, "end_pos": 42, "type": "METRIC", "confidence": 0.9968833327293396}, {"text": "F measure", "start_pos": 87, "end_pos": 96, "type": "METRIC", "confidence": 0.9909710586071014}, {"text": "precision", "start_pos": 111, "end_pos": 120, "type": "METRIC", "confidence": 0.9994182586669922}, {"text": "recall", "start_pos": 125, "end_pos": 131, "type": "METRIC", "confidence": 0.9976657629013062}, {"text": "F measure", "start_pos": 175, "end_pos": 184, "type": "METRIC", "confidence": 0.9840995371341705}]}, {"text": "Clearly, although both kinds of PPs are well identified, arguments are better identified than adjuncts, an observation already made by several other authors, especially Hindle and Rooth in their detailed discussion of the errors in a noun or verb PP-attachment task.", "labels": [], "entities": []}, {"text": "In particular, we notice that more adjuncts are misclassified as arguments than vice versa.", "labels": [], "entities": []}, {"text": "The results of these experiments confirm that corpus information is conducive to learning the distinction under discussion without explicitly represented complex semantic knowledge.", "labels": [], "entities": []}, {"text": "They also confirm that this distinction is essentially a word class phenomenon-and not an individual lexical-item phenomenon-as would be expected undercurrent theories of the syntax-semantics interface.", "labels": [], "entities": []}, {"text": "Finally, the combination of lexical items, classes, and linguistic diagnostics yields the best results.", "labels": [], "entities": []}, {"text": "This indicates that using features of different levels of granularity is beneficial, probably because the algorithm has the option of using more specific information when reliable, while abstracting to coarser-grained information when lexical features suffer from sparse data.", "labels": [], "entities": []}, {"text": "This interpretation of the results is supported by observing which features are at the top of the tree.", "labels": [], "entities": []}, {"text": "Interestingly, here the topmost feature is head dependence (the lexical variant, hdepv1), on one side of which we find preposition as the second most discriminative feature, followed by head dependence (hdepv2) again, and optionality (class variants).", "labels": [], "entities": []}, {"text": "On the other side of the tree, we find preposition as the second most informative feature and verb class as the third most discriminative feature.", "labels": [], "entities": []}, {"text": "Results on Partly Manually Labeled Set.", "labels": [], "entities": []}, {"text": "report the results obtained by training the classifier on the automatically labeled training set and testing on the manually labeled test set.", "labels": [], "entities": []}, {"text": "They illustrate the effect of training the decision tree classifier on a training set that has different properties from the test set.", "labels": [], "entities": []}, {"text": "This experiment provides a lower bound of performance across different samples and shows which are the features with the greatest generalization ability.", "labels": [], "entities": []}, {"text": "We can draw several conclusions.", "labels": [], "entities": []}, {"text": "First, the lexical features do better than chance, but do not do better than the baseline established by using only the preposition as a feature (lines 1, 2, and 3 of).", "labels": [], "entities": []}, {"text": "Secondly, classes do better than the baseline (line 7 of) and so do the diagnostic features).", "labels": [], "entities": [{"text": "diagnostic", "start_pos": 72, "end_pos": 82, "type": "METRIC", "confidence": 0.9155233502388}]}, {"text": "Since we are using a training and a test set with different properties, these results indicate that classes and diagnostics capture a level of generality that the lexical features do not have and will be more useful across domains and corpora.", "labels": [], "entities": []}, {"text": "Finally, the rank of performance for different feature combinations holds across training and testing methods, whether established automatically or manually, as can be confirmed by a comparison of and also 2 and 5.", "labels": [], "entities": []}, {"text": "The difference in performance with diagnostics (line 3 of) and without, using only classes (line 7 of), is only marginally significant, indicating that diagnostics are not useless.", "labels": [], "entities": []}, {"text": "Results on Test Set without Bare PPs.", "labels": [], "entities": [{"text": "Test Set", "start_pos": 11, "end_pos": 19, "type": "DATASET", "confidence": 0.894940048456192}]}, {"text": "The biggest discrepancy in validating the automatic labeling was found for PPs without functional tags.", "labels": [], "entities": []}, {"text": "The automatic labeling had classified bare PPs as argument but the manual gold standard assigns more than half of them to the adjunct class.", "labels": [], "entities": []}, {"text": "They are therefore a source of noise in establishing reliable results.", "labels": [], "entities": []}, {"text": "If we remove these PPs from the training and test set, results improve and become almost identical across the manually and automatically labeled sets, as illustrated in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1  Accuracy of the argument-adjunct distinction for VP-attached PPs, using combinations of lexical  features. The training and test sets are automatically annotated.", "labels": [], "entities": []}, {"text": " Table 2  Best results using preposition and combination of diagnostic-based features, in different  variants. The training and test sets are automatically annotated.", "labels": [], "entities": []}, {"text": " Table 3  Confusion matrix of the best classification of PPs attached to the verb. Training and test set  established automatically.", "labels": [], "entities": []}, {"text": " Table 4  Accuracy of the argument-adjunct distinction for VP-attached PPs, using combinations  of lexical features. The training set is automatically annotated while the test set is in part  annotated by hand.", "labels": [], "entities": []}, {"text": " Table 5  Best results using prepositions and combination of diagnostic-based features in different  variants. The training set is automatically annotated, whereas the test set is in part annotated  by hand.", "labels": [], "entities": []}, {"text": " Table 6  Best results using preposition and combination of diagnostic-based features, in different  variants, taking out PP examples.", "labels": [], "entities": []}, {"text": " Table 7  Baselines and performances using lexical heads and classes for N-attached PPs.", "labels": [], "entities": []}, {"text": " Table 8  Performances using some combinations of features for N-attached PPs.", "labels": [], "entities": []}, {"text": " Table 11  Percent precision, recall, and F score for the best two-step and one-step four-way classification  of PPs, including and not including the preposition of.", "labels": [], "entities": [{"text": "precision", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.9955543875694275}, {"text": "recall", "start_pos": 30, "end_pos": 36, "type": "METRIC", "confidence": 0.999275267124176}, {"text": "F", "start_pos": 42, "end_pos": 43, "type": "METRIC", "confidence": 0.9997037053108215}]}, {"text": " Table 12  Confusion matrix of the best one-step four-way classification of PPs without the preposition of .", "labels": [], "entities": []}, {"text": " Table 13  Percent accuracy using combinations of features for a one-step four-way classification of PPs.  Best combination = (v cl , n1 cl , p, opt1, opt2, hdepv1, hdepv2, hdepn1, para).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.996921718120575}]}, {"text": " Table 14  Percent precision, recall, and F-score for the best four-way classification of PPs, including  and not including the preposition of using SVMs.", "labels": [], "entities": [{"text": "precision", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.9963556528091431}, {"text": "recall", "start_pos": 30, "end_pos": 36, "type": "METRIC", "confidence": 0.9993854761123657}, {"text": "F-score", "start_pos": 42, "end_pos": 49, "type": "METRIC", "confidence": 0.9995471835136414}]}]}