{"title": [{"text": "Part-of-Speech Tagging for Chinese-English Mixed Texts with Dynamic Features", "labels": [], "entities": [{"text": "Part-of-Speech Tagging", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7863345742225647}]}], "abstractContent": [{"text": "In modern Chinese articles or conversations, it is very popular to involve a few English words, especially in emails and Internet literature.", "labels": [], "entities": []}, {"text": "Therefore, it becomes an important and challenging topic to analyze Chinese-English mixed texts.", "labels": [], "entities": []}, {"text": "The underlying problem is how to tag part-of-speech (POS) for the English words involved.", "labels": [], "entities": []}, {"text": "Due to the lack of specially annotated corpus, most of the English words are tagged as the oversimplified type, \"foreign words\".", "labels": [], "entities": []}, {"text": "In this paper, we present a method using dynamic features to tag POS of mixed texts.", "labels": [], "entities": []}, {"text": "Experiments show that our method achieves higher performance than traditional sequence labeling methods.", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 78, "end_pos": 95, "type": "TASK", "confidence": 0.6275838911533356}]}, {"text": "Meanwhile, our method also boosts the performance of POS tagging for pure Chinese texts.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 53, "end_pos": 64, "type": "TASK", "confidence": 0.854773759841919}]}], "introductionContent": [{"text": "Nowadays, Chinese-English mixed texts are prevalent in modern articles or emails.", "labels": [], "entities": []}, {"text": "More and more English words are used in Chinese texts as names of organizations, products, terms and abbreviations, such as \"eBay\", \"iPhone\", \"GDP\", \"Android\" etc.", "labels": [], "entities": []}, {"text": "On the other hand, it is also a common phenomenon to use Chinese-English mixed texts in daily conversation, especially in communication among employers in large international corporations.", "labels": [], "entities": []}, {"text": "There are some challenges for analyzing ChineseEnglish mixed texts: 1.", "labels": [], "entities": [{"text": "ChineseEnglish mixed texts", "start_pos": 40, "end_pos": 66, "type": "DATASET", "confidence": 0.6943347652753195}]}, {"text": "How to define the POS tags for English words in these mixed texts.", "labels": [], "entities": []}, {"text": "Since the standard of POS tags for English and Chinese are different, we cannot use English POS to tag the English words in mixed texts.", "labels": [], "entities": []}, {"text": "2. Due to lack of annotated corpus for mixed texts, most of the English words are tagged as \"foreign words\", which is oversimplified.", "labels": [], "entities": []}, {"text": "So we cannot use them in further processing for the syntactic and semantic analysis.", "labels": [], "entities": [{"text": "syntactic and semantic analysis", "start_pos": 52, "end_pos": 83, "type": "TASK", "confidence": 0.6615658402442932}]}, {"text": "3. Most English words used in mixed texts are often out-of-vocabulary (OOV), which thus increases the difficulties to tag them.", "labels": [], "entities": []}, {"text": "Currently, the mainstream method of Chinese POS tagging is joint segmentation & tagging with cross-labels, which can avoid the problem of error propagation and achieve higher performance on both subtasks().", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 44, "end_pos": 55, "type": "TASK", "confidence": 0.7559612691402435}, {"text": "error propagation", "start_pos": 138, "end_pos": 155, "type": "TASK", "confidence": 0.6980884075164795}]}, {"text": "Each label is the crossproduct of a segmentation label and a tagging label, e.g. {B-NN, I-NN, E-NN, S-NN, ...}.", "labels": [], "entities": []}, {"text": "The features are generated by position-based templates on character-level.", "labels": [], "entities": []}, {"text": "Since the main part of mixed texts is in Chinese and the role of English word is more like Chinese, we use Chinese POS tags) to tag English words.", "labels": [], "entities": []}, {"text": "Since the categories of the most commonly used English words are nouns, verbs and adjectives, we can use \"NN\", \"NR\", \"VV\", \"VA\", \"JJ\" to label their POS tags.", "labels": [], "entities": [{"text": "VA", "start_pos": 124, "end_pos": 126, "type": "METRIC", "confidence": 0.9755556583404541}]}, {"text": "For the English proper nouns and verbs, there are no significant differences in Chinese and English POS tags except that English features plural and tense forms.", "labels": [], "entities": []}, {"text": "For the English nouns, these are some English nouns used as verbs, such as \"\u6211\u5f88 [fan/VV] \u4ed6\u3002(I adore him very much.)\" where \"fan\" means \"adore\" and is used as a verb.", "labels": [], "entities": []}, {"text": "For the English adjectives, there are two corresponding Chinese POS tags \"VA\" and \"JJ\".", "labels": [], "entities": [{"text": "VA", "start_pos": 74, "end_pos": 76, "type": "METRIC", "confidence": 0.9207803010940552}]}, {"text": "For example, the roles of some English words in, such as \"professional\" and \"high\", are different with their original ones.", "labels": [], "entities": []}, {"text": "Therefore, the POS tagging for mixed texts cannot be settled with simple methods, such as looking up in a dictionary.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 15, "end_pos": 26, "type": "TASK", "confidence": 0.8302355110645294}]}, {"text": "One of the main differences between Chinese and English in POS tagging is that the two languages have character-based features and word-based features respectively.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 59, "end_pos": 70, "type": "TASK", "confidence": 0.6838651150465012}]}, {"text": "To ensure the consistency of tagging models, we prefer to use word-level information in Chinese, which is both useful for ChineseEnglish mixed texts and Chinese-only texts.", "labels": [], "entities": []}, {"text": "For instance, in a sentence \"X \u6216\u8005 Y ...", "labels": [], "entities": []}, {"text": "(X or Y ...)\", the word Y ought to have the same POS tag as the word X.", "labels": [], "entities": [{"text": "POS tag", "start_pos": 49, "end_pos": 56, "type": "METRIC", "confidence": 0.933604508638382}]}, {"text": "Another example is that the word following a pronoun is usually a verb, and adjectives often describe nouns.", "labels": [], "entities": []}, {"text": "Some related works show that word-level features can improve the performance of Chinese POS tagging ( In this paper, we propose a method to tag mixed texts with dynamic features.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 88, "end_pos": 99, "type": "TASK", "confidence": 0.6460839509963989}]}, {"text": "Our method combines these dynamic features, which are dynamically generated at the decoding stage, with traditional static features.", "labels": [], "entities": []}, {"text": "For Chinese-English mixed texts, the traditional features cannot yield a satisfied result due to lack of training data.", "labels": [], "entities": []}, {"text": "The proposed dynamic features can improve the performance by using the information of a word, such as POS tag or length of the whole word, which is proven effective by experiments.", "labels": [], "entities": [{"text": "POS tag", "start_pos": 102, "end_pos": 109, "type": "METRIC", "confidence": 0.9338527023792267}]}, {"text": "The rest of the paper is organized as follows: In section 2, we introduce the sequence labeling models, then we describe our method of dynamic features in section 3 and analyze its complexity in section 4.", "labels": [], "entities": []}, {"text": "Section 5 describes the training method.", "labels": [], "entities": []}, {"text": "The experimental results are manifested in section 6.", "labels": [], "entities": []}, {"text": "Finally, We review the relevant research works in section 7 and conclude our work in section 8.", "labels": [], "entities": []}], "datasetContent": [{"text": "We implement our system based on FudanNLP 1 . We employ the commonly used label set {B, I, E, S} for the segmentation part of cross-labels.", "labels": [], "entities": [{"text": "FudanNLP 1", "start_pos": 33, "end_pos": 43, "type": "DATASET", "confidence": 0.9315581023693085}]}, {"text": "{B, I, E} represent Begin, Inside, End of a multi-node segmentation respectively, and S represents a Single node segmentation.", "labels": [], "entities": [{"text": "Single node segmentation", "start_pos": 101, "end_pos": 125, "type": "TASK", "confidence": 0.7072216471036276}]}, {"text": "The F 1 score is used for evaluation, which is the harmonic mean of precision P (percentage of predict phrases that exactly match the reference phrases) and recall R (percentage of reference phrases that returned by system).", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9788195292154948}, {"text": "precision P", "start_pos": 68, "end_pos": 79, "type": "METRIC", "confidence": 0.9787546098232269}, {"text": "recall R", "start_pos": 157, "end_pos": 165, "type": "METRIC", "confidence": 0.9769836068153381}]}, {"text": "The feature templates, which are used to extract features, are listed in.", "labels": [], "entities": []}, {"text": "We set traditional method (static features) as the baseline.", "labels": [], "entities": []}, {"text": "The detailed experimental settings and results are reported in the following subsections.", "labels": [], "entities": []}, {"text": "To investigate the actual performance, we collect areal dataset from Web, which consists of 142 representative Chinese-English mixed sentences.", "labels": [], "entities": []}, {"text": "This dataset contains 4, 238 Chinese characters and 275 English words.", "labels": [], "entities": []}, {"text": "Since we focus on the performance for English words, we only label the POS tags of the English words.", "labels": [], "entities": []}, {"text": "shows some examples in the real dataset of mixed texts.", "labels": [], "entities": []}, {"text": "The information of the real dataset is shown in Table.", "labels": [], "entities": []}, {"text": "If all involved English words are tagging as \"NN\", the precision is just 56%.", "labels": [], "entities": [{"text": "precision", "start_pos": 55, "end_pos": 64, "type": "METRIC", "confidence": 0.9997288584709167}]}, {"text": "Since there is no noun-modifier \"JJ\" in our collected data.", "labels": [], "entities": []}, {"text": "We use the models trained on dataset B and C to tag the real data.", "labels": [], "entities": []}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "The difference between model B and C is that model B regards all words with tag \"NR\" as \"NN\".", "labels": [], "entities": []}, {"text": "Since it is difficult to distinguish between \"NR\" and \"NN\" merely according to the context, model B performs better than model C.", "labels": [], "entities": []}, {"text": "The detail results of model B and C are shown in and 22.", "labels": [], "entities": [{"text": "detail", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9899341464042664}]}], "tableCaptions": [{"text": " Table 6: POS Tagging Dataset in SIGHAN Bakeoff 2008", "labels": [], "entities": [{"text": "POS Tagging Dataset in SIGHAN Bakeoff 2008", "start_pos": 10, "end_pos": 52, "type": "DATASET", "confidence": 0.7044194638729095}]}, {"text": " Table 7: Performances of POS Tagging on Chinese-only  Texts with Static and Dynamic Features", "labels": [], "entities": [{"text": "POS Tagging", "start_pos": 26, "end_pos": 37, "type": "TASK", "confidence": 0.8175468146800995}]}, {"text": " Table 8: The Synthetic Chinese-English Mixed Dataset  H", "labels": [], "entities": [{"text": "Synthetic Chinese-English Mixed Dataset", "start_pos": 14, "end_pos": 53, "type": "DATASET", "confidence": 0.685685470700264}]}, {"text": " Table 9: Performances of POS Tagging on Dataset H 1  and H 2", "labels": [], "entities": [{"text": "POS Tagging", "start_pos": 26, "end_pos": 37, "type": "TASK", "confidence": 0.8568077683448792}]}, {"text": " Table 10: The Synthetic Chinese-English Mixed Dataset", "labels": [], "entities": [{"text": "Synthetic Chinese-English Mixed Dataset", "start_pos": 15, "end_pos": 54, "type": "DATASET", "confidence": 0.6752137243747711}]}, {"text": " Table 11. On dataset E,  our method achieves 6.78% higher performance on  tagging EN G labels than traditional static features.  This result is reasonable because our model can use  more flexible feature templates to extract features  and reduce the problem of being dependent on spe- cific English words.  Tables 12/13/14/15/16/17 show the detailed re- sults on datasets A/B/C/D 1 /D 2 /E.", "labels": [], "entities": [{"text": "tagging EN G labels", "start_pos": 75, "end_pos": 94, "type": "TASK", "confidence": 0.8293401896953583}]}, {"text": " Table 11: Performances of POS Tagging on Datasets  A/B/C/D 1 /D 2 /E", "labels": [], "entities": [{"text": "POS Tagging on Datasets  A/B/C/D 1 /D 2 /E", "start_pos": 27, "end_pos": 69, "type": "TASK", "confidence": 0.7805101626059588}]}, {"text": " Table 12: Performances on Dataset A", "labels": [], "entities": []}, {"text": " Table 13: Performances on Dataset B", "labels": [], "entities": []}, {"text": " Table 14: Performances on Dataset C", "labels": [], "entities": []}, {"text": " Table 15: Performances on Dataset D 1", "labels": [], "entities": []}, {"text": " Table 16: Performances on Dataset D 2", "labels": [], "entities": []}, {"text": " Table 17: Performances on Dataset E", "labels": [], "entities": []}, {"text": " Table 18: Examples in Real Dataset of Mixed Texts", "labels": [], "entities": []}, {"text": " Table 20: Performances of POS Tagging on R", "labels": [], "entities": [{"text": "POS Tagging on R", "start_pos": 27, "end_pos": 43, "type": "TASK", "confidence": 0.7334889322519302}]}, {"text": " Table 21: Performances of Model B on Dataset R", "labels": [], "entities": []}, {"text": " Table 22: Performances of Model C on Dataset R", "labels": [], "entities": []}]}