{"title": [{"text": "Minimal Dependency Length in Realization Ranking", "labels": [], "entities": []}], "abstractContent": [{"text": "Comprehension and corpus studies have found that the tendency to minimize dependency length has a strong influence on constituent ordering choices.", "labels": [], "entities": []}, {"text": "In this paper, we investigate dependency length minimization in the context of discriminative realization ranking, fo-cusing on its potential to eliminate egregious ordering errors as well as better match the dis-tributional characteristics of sentence order-ings in news text.", "labels": [], "entities": [{"text": "dependency length minimization", "start_pos": 30, "end_pos": 60, "type": "TASK", "confidence": 0.6840274532636007}]}, {"text": "We find that with a state-of-the-art, comprehensive realization ranking model, dependency length minimization yields statistically significant improvements in BLEU scores and significantly reduces the number of heavy/light ordering errors.", "labels": [], "entities": [{"text": "dependency length minimization", "start_pos": 79, "end_pos": 109, "type": "TASK", "confidence": 0.5760231713453928}, {"text": "BLEU", "start_pos": 159, "end_pos": 163, "type": "METRIC", "confidence": 0.9981006979942322}]}, {"text": "Through distributional analyses, we also show that with simpler ranking models, dependency length minimization can go overboard, too often sacrificing canonical word order to shorten dependencies, while richer models manage to better counterbalance the dependency length minimization preference against (sometimes) competing canonical word order preferences.", "labels": [], "entities": [{"text": "dependency length minimization", "start_pos": 80, "end_pos": 110, "type": "TASK", "confidence": 0.6355522274971008}]}], "introductionContent": [{"text": "In this paper, we show that for the constituent ordering problem in surface realization, incorporating insights from the minimal dependency length theory of language production into a discriminative realization ranking model yields significant improvements upon a state-of-the-art baseline.", "labels": [], "entities": [{"text": "surface realization", "start_pos": 68, "end_pos": 87, "type": "TASK", "confidence": 0.7124329954385757}]}, {"text": "We demonstrate empirically using OpenCCG, our CCG-based) surface realization system, the utility of a global feature encoding the total dependency length of a given derivation.", "labels": [], "entities": []}, {"text": "Although other works in the realization literature have used phrase length or head-dependent distances in their models (, to the best of our knowledge, this paper is the first to use insights from the minimal dependency length theory directly and study their effects, both qualitatively and quantitatively.", "labels": [], "entities": []}, {"text": "The impetus for this paper was the discovery that despite incorporating a sophisticated syntactic model borrowed from the parsing literatureincluding features with head-dependent distances at various scales-  realization ranking model still often performed poorly on weight-related decisions such as when to employ heavy-NP shift.", "labels": [], "entities": []}, {"text": "In wsj 0034.9, the full model (incorporating numerous syntactic features) succeeds in reproducing the reference sentence, which is clearly preferable to the rather awkward variant selected by the baseline model (using various n-gram models).", "labels": [], "entities": []}, {"text": "However, in wsj 0013.16, the full model fails to shift the temporal modifier for now next to the phrasal verb turned down, leaving it at the end of its very long verb phrase where it is highly ambiguous (with multiple intervening attachment sites).", "labels": [], "entities": [{"text": "wsj 0013.16", "start_pos": 12, "end_pos": 23, "type": "DATASET", "confidence": 0.8496436476707458}]}, {"text": "Conversely, in wsj 0044.3, the full model shifts before next to the verb, despite the NP cheating being very light, yielding a very confusing ordering given that before is meant to be intransitive.", "labels": [], "entities": [{"text": "wsj 0044.3", "start_pos": 15, "end_pos": 25, "type": "DATASET", "confidence": 0.8268606066703796}]}, {"text": "The syntactic features in realization ranking model are taken from  wsj 0044.3 she had seen cheating before , but these notes were uncanny .", "labels": [], "entities": []}], "datasetContent": [{"text": "We followed the averaged perceptron training procedure of White and Rajkumar (2009) with a couple of updates.", "labels": [], "entities": []}, {"text": "First, as noted earlier, we used a reimplementation of generative syntactic model as an extra component of our generative baseline; and second, only five epochs of training were used, which was found to work as well as using additional epochs on the development set.", "labels": [], "entities": []}, {"text": "As in the earlier work, the models were trained on the standard training sections (02-21) of an enhanced version of the CCGbank, using a lexico-grammar extracted from these sections.", "labels": [], "entities": [{"text": "CCGbank", "start_pos": 120, "end_pos": 127, "type": "DATASET", "confidence": 0.9680588245391846}]}, {"text": "The models tested in the experiments reported below are summarized in.", "labels": [], "entities": []}, {"text": "The three groups of models are designed to test the impact of the dependency length feature when added to feature sets of increasing complexity.", "labels": [], "entities": []}, {"text": "In more detail, the GLOBAL and DEPLEN-GLOBAL models contain dense features on entire derivations; their values are the log probabilities of the three n-gram mod- Note that the learned weight of the total dependency length feature was negative in each case, as expected.", "labels": [], "entities": []}, {"text": "shows the sizes of the various models.", "labels": [], "entities": []}, {"text": "For each model, the alphabet-whose size increases to over a million features-is the set of applicable features found to have discriminative value in at least 5 training examples; from these, a subset are made active (i.e., take on a non-zero weight) through perceptron updates when the feature value differs between the model-best and oracle-best realization.", "labels": [], "entities": []}, {"text": "To determine whether heavy-light ordering differences often represent ordering errors (including egregious ones), rather than simply representing acceptable variation, we conducted a targeted human evaluation on examples of this kind.", "labels": [], "entities": []}, {"text": "Specifically, for each of the DEPLEN* models and their corresponding models without the dependency length feature, we chose the 25 sentences from the development section whose realizations exhibited the greatest difference in dependency length between sibling constituents appearing in opposite orders, and asked two judges (not the authors) to choose which of the two realizations best expressed the meaning of the reference sentence in a grammatical and fluent way, with the choice forced (2AFC).  with only one disagreement on the realizations from the DEPLEN and DEPORD-NF models (involving an acceptable paraphrase in our judgment), and only four disagreements on the DEPLEN-GLOBAL and GLOBAL realizations.", "labels": [], "entities": [{"text": "2AFC", "start_pos": 492, "end_pos": 496, "type": "METRIC", "confidence": 0.9436900615692139}]}, {"text": "Pooling the judgments, the preference for the DEPLEN* models was well above the chance level of 50% according to a binomial test (p < 0.001 in each case).", "labels": [], "entities": [{"text": "DEPLEN", "start_pos": 46, "end_pos": 52, "type": "METRIC", "confidence": 0.732715904712677}]}, {"text": "Inspecting the data ourselves, we found that many of the items did indeed involve egregious ordering errors that the DEPLEN* models managed to avoid.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 6: Model sizes-number of features in alphabet for  each model (satisfying count cutoff of 5) along with num- ber active in model after 5 training epochs", "labels": [], "entities": []}, {"text": " Table 5: Legend for experimental conditions", "labels": [], "entities": []}, {"text": " Table 8: Dependency length compared to corpus- percentage of realizations with dependency length less  than and greater than gold standard, along with mean  dependency length, whose significance is tested against  gold; 1671 development set (Section 00) complete real- izations analyzed", "labels": [], "entities": [{"text": "1671 development set", "start_pos": 221, "end_pos": 241, "type": "DATASET", "confidence": 0.8202061454455057}]}, {"text": " Table 8. The table shows the mean of the total de- pendency length of each realized derivation com-Model  % Short % Long % Eq % Single  / Long  / Short  Constit", "labels": [], "entities": [{"text": "de- pendency length", "start_pos": 48, "end_pos": 67, "type": "METRIC", "confidence": 0.6099566146731377}]}, {"text": " Table 10: Distribution of heavy unequal constituents  (length difference > 5) in Section 00; 4692 gold cases  considered and significance tested against the gold stan- dard using a \u03c7-square test", "labels": [], "entities": [{"text": "Section 00", "start_pos": 82, "end_pos": 92, "type": "DATASET", "confidence": 0.8347918689250946}]}, {"text": " Table 13: PTB Section 23 BLEU scores and exact match  percentages in the NLG literature (Nakanishi et al.'s re- sults are for sentences of length 20 or less)", "labels": [], "entities": [{"text": "PTB", "start_pos": 11, "end_pos": 14, "type": "DATASET", "confidence": 0.7730658650398254}, {"text": "BLEU", "start_pos": 26, "end_pos": 30, "type": "METRIC", "confidence": 0.9849254488945007}, {"text": "exact match  percentages", "start_pos": 42, "end_pos": 66, "type": "METRIC", "confidence": 0.9046912789344788}, {"text": "NLG literature", "start_pos": 74, "end_pos": 88, "type": "DATASET", "confidence": 0.9245863258838654}]}]}