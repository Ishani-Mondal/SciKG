{"title": [], "abstractContent": [{"text": "We propose the subtree ranking approach to parse forest reranking which is a generalization of current perceptron-based reranking methods.", "labels": [], "entities": [{"text": "parse forest reranking", "start_pos": 43, "end_pos": 65, "type": "TASK", "confidence": 0.8613030711809794}]}, {"text": "For the training of the reranker, we extract competing local subtrees, hence the training instances (candidate subtree sets) are very similar to those used during beam-search parsing.", "labels": [], "entities": [{"text": "beam-search parsing", "start_pos": 163, "end_pos": 182, "type": "TASK", "confidence": 0.706172525882721}]}, {"text": "This leads to better parameter optimization.", "labels": [], "entities": []}, {"text": "Another chief advantage of the framework is that arbitrary learning to rank methods can be applied.", "labels": [], "entities": []}, {"text": "We evaluated our reranking approach on German and En-glish phrase structure parsing tasks and compared it to various state-of-the-art reranking approaches such as the perceptron-based forest reranker.", "labels": [], "entities": [{"text": "En-glish phrase structure parsing tasks", "start_pos": 50, "end_pos": 89, "type": "TASK", "confidence": 0.6480948805809021}]}, {"text": "The subtree ranking approach with a Maximum Entropy model significantly outperformed the other approaches.", "labels": [], "entities": []}], "introductionContent": [{"text": "Reranking has become a popular technique for solving various structured prediction tasks, such as phrase-structure) and dependency parsing, semantic role labeling () and machine translation).", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 120, "end_pos": 138, "type": "TASK", "confidence": 0.7820072174072266}, {"text": "semantic role labeling", "start_pos": 140, "end_pos": 162, "type": "TASK", "confidence": 0.6656552255153656}, {"text": "machine translation", "start_pos": 170, "end_pos": 189, "type": "TASK", "confidence": 0.7996000051498413}]}, {"text": "The idea is to (re)rank candidates extracted by abase system exploiting a rich feature set and operating at a global (usually sentence) level.", "labels": [], "entities": []}, {"text": "Reranking achieved significant gains over the base system in many tasks because it has access to information/features which are not computable in the base system.", "labels": [], "entities": []}, {"text": "Reranking also outperforms discriminative approaches which try to handle the entire candidate universe (cf.) because the base system effectively and efficiently filters out many bad candidates and makes the problem tractable.", "labels": [], "entities": [{"text": "Reranking", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.7876585125923157}]}, {"text": "The standard approach for reranking is the n-best list ranking procedure, where the base system extracts its top n global-level candidates with associated goodness scores that define an initial ranking.", "labels": [], "entities": [{"text": "reranking", "start_pos": 26, "end_pos": 35, "type": "TASK", "confidence": 0.9844605326652527}]}, {"text": "Then the task is to rerank these candidates by using a rich feature set.", "labels": [], "entities": []}, {"text": "The bottleneck of this approach is the small number of candidates considered.", "labels": [], "entities": []}, {"text": "Compared to n-best lists, packed parse forests encode more candidates in a compact way.", "labels": [], "entities": []}, {"text": "Forest reranking methods have been proposed, which can exploit the richer set of candidates and they have been successfully applied for phrase-structure, dependency) parsing and machine translation ( as well.", "labels": [], "entities": [{"text": "dependency) parsing", "start_pos": 154, "end_pos": 173, "type": "TASK", "confidence": 0.6198342243830363}, {"text": "machine translation", "start_pos": 178, "end_pos": 197, "type": "TASK", "confidence": 0.803625762462616}]}, {"text": "introduced the perceptron-based forest reranking approach.", "labels": [], "entities": []}, {"text": "The core of the algorithm is a beam-search based decoder operating on the packed forest in a bottom-up manner.", "labels": [], "entities": []}, {"text": "It follows the assumption that the feature values of the whole structure are the sum of the feature values of the local elements and they are designed to the usage of the perceptron update.", "labels": [], "entities": []}, {"text": "Under these assumptions a 1-best Viterbi or beam-search decoder can be efficiently employed at parsing and training time.", "labels": [], "entities": [{"text": "parsing", "start_pos": 95, "end_pos": 102, "type": "TASK", "confidence": 0.9624940156936646}]}, {"text": "During training, it decodes the 1-best complete parse then it makes the perceptron update against the oracle parse, i.e. the perceptron is trained at the global (sentence) level.", "labels": [], "entities": []}, {"text": "We propose here a subtree ranker approach which can be regarded as a generalization of this for-est reranking procedure.", "labels": [], "entities": []}, {"text": "In contrast to updating on a single (sub)tree per sentence using only the 1-best parse (perceptron-based forest reranking), the subtree ranker exploits subtrees of all sizes from a sentence and trains a (re)ranker utilising several derivations of the constituent in question.", "labels": [], "entities": []}, {"text": "During parsing we conduct a beam-search extraction by asking the ranker to select the k best subtrees among the possible candidates of each forest node.", "labels": [], "entities": [{"text": "parsing", "start_pos": 7, "end_pos": 14, "type": "TASK", "confidence": 0.9772059917449951}, {"text": "beam-search extraction", "start_pos": 28, "end_pos": 50, "type": "TASK", "confidence": 0.7024754583835602}]}, {"text": "The chief motivation for this approach is that in this way, training and prediction are carried out on similar local candidate lists which we expect to be favorable to the learning mechanism.", "labels": [], "entities": []}, {"text": "We empirically prove that the trained discriminative rankers benefit from having access to a larger amount of subtree candidates.", "labels": [], "entities": []}, {"text": "Moreover, in this framework any kind of learning to rank methods can be chosen as ranker, including pair-wise and list-wise classifiers.", "labels": [], "entities": []}, {"text": "The contributions of this paper are the following: \u2022 We extend the perceptron-based forest rerankers to the subtree ranker forest reranking framework which allows to replace the perceptron update by any kind of learning to rank procedure.", "labels": [], "entities": []}, {"text": "\u2022 We report experimental results on German and English phrase-structure parsing comparing subtree rerankers to various other rerankers showing a significant improvement over the perceptron-based forest reranker approach.", "labels": [], "entities": [{"text": "phrase-structure parsing", "start_pos": 55, "end_pos": 79, "type": "TASK", "confidence": 0.6552892178297043}]}], "datasetContent": [{"text": "We carried out experiments on English and German phrase-structure reranking.", "labels": [], "entities": [{"text": "phrase-structure reranking", "start_pos": 49, "end_pos": 75, "type": "TASK", "confidence": 0.6611457318067551}]}, {"text": "As evaluation metric, we used the standard evalb implementation of PAR-SEVAL on every sentence without length limitation and we start from raw sentences without gold standard POS tagging.", "labels": [], "entities": [{"text": "PAR-SEVAL", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.6892482042312622}]}, {"text": "As the grammatical functions of constituents are important from a downstream application point of view -especially in German -we also report PARSEVAL scores on the conflation of constituent labels and grammatical functions.", "labels": [], "entities": [{"text": "PARSEVAL", "start_pos": 141, "end_pos": 149, "type": "METRIC", "confidence": 0.9979693293571472}]}, {"text": "These scores are shown in brackets in.", "labels": [], "entities": []}, {"text": "We used the Wall Street Journal subcorpus of the Ontonotes v4.0 corpus (Weischedel et al., 2011) 1 for English.", "labels": [], "entities": [{"text": "Wall Street Journal subcorpus of the Ontonotes v4.0 corpus (Weischedel et al., 2011) 1", "start_pos": 12, "end_pos": 98, "type": "DATASET", "confidence": 0.9077289840754341}]}, {"text": "As usual sections 2-21, 23 and 24 served as training set (30,060 sentences), test set (1,640 sentences), and development set (1,336 sentences), respectively.", "labels": [], "entities": []}, {"text": "Using the Ontonotes version enables us to assess parser robustness.", "labels": [], "entities": []}, {"text": "To this end, we evaluated our models also on the weblog subcorpus of the Ontonotes v4.0 corpus which consists of 15,103 sentences.", "labels": [], "entities": [{"text": "Ontonotes v4.0 corpus", "start_pos": 73, "end_pos": 94, "type": "DATASET", "confidence": 0.8831239740053812}]}, {"text": "For German we used the Tiger treebank ().", "labels": [], "entities": [{"text": "Tiger treebank", "start_pos": 23, "end_pos": 37, "type": "DATASET", "confidence": 0.9778445363044739}]}, {"text": "We take the first 40,474 sentences of the Tiger treebank as training data, the next 5,000 sentences as development data, and the last 5,000 sentences as test data.", "labels": [], "entities": [{"text": "Tiger treebank", "start_pos": 42, "end_pos": 56, "type": "DATASET", "confidence": 0.8997942805290222}]}], "tableCaptions": [{"text": " Table 1: The lower and upper bounds for rerankers on the four evaluation datasets. The numbers in brackets refers to  evaluation with grammatical function labels on the German dataset.", "labels": [], "entities": [{"text": "German dataset", "start_pos": 170, "end_pos": 184, "type": "DATASET", "confidence": 0.9511565566062927}]}, {"text": " Table 2: The results achieved by various forest rerankers. The difference between the scores marked by  \u2020 and the  'perceptron with global training' were not statistically significant with p < 0.005 according to the the McNemar test.  All other results are statistically different from this baseline.", "labels": [], "entities": [{"text": "\u2020", "start_pos": 105, "end_pos": 106, "type": "METRIC", "confidence": 0.9869948029518127}, {"text": "McNemar test", "start_pos": 221, "end_pos": 233, "type": "DATASET", "confidence": 0.91974738240242}]}, {"text": " Table 3: The sizes of the subtree ranker training datasets  at k = 3.", "labels": [], "entities": []}, {"text": " Table 4: The results of the two selection strategies. Using  the oracle trees proved to be better on each of the datasets.", "labels": [], "entities": []}]}