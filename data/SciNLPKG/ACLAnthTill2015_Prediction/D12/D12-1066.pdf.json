{"title": [{"text": "Generalizing Sub-sentential Paraphrase Acquisition across Original Signal Type of Text Pairs", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes a study on the impact of the original signal (text, speech, visual scene, event) of a text pair on the task of both manual and automatic sub-sentential paraphrase acquisition.", "labels": [], "entities": [{"text": "sub-sentential paraphrase acquisition", "start_pos": 158, "end_pos": 195, "type": "TASK", "confidence": 0.6411849955717722}]}, {"text": "A corpus of 2,500 annotated sentences in English and French is described, and performance on this corpus is reported for an efficient system combination exploiting a large set of features for paraphrase recognition.", "labels": [], "entities": [{"text": "paraphrase recognition", "start_pos": 192, "end_pos": 214, "type": "TASK", "confidence": 0.9153020977973938}]}, {"text": "A detailed quantified typology of sub-sentential paraphrases found in our corpus types is given.", "labels": [], "entities": []}], "introductionContent": [{"text": "Sub-sentential paraphrases can be acquired from text pairs expressing the same meaning.", "labels": [], "entities": []}, {"text": "If the semantic similarity of a text pair has a direct impact on the quality of the acquired paraphrases, it has, to our knowledge, never been shown what impact the type of original signal has on paraphrase acquisition.", "labels": [], "entities": [{"text": "paraphrase acquisition", "start_pos": 196, "end_pos": 218, "type": "TASK", "confidence": 0.9232973456382751}]}, {"text": "In this work, we consider four types of corpora, which we think are representative of the main types of original semantic signals: text pairs (roughly, sentences) originating a) from independent translations of a text (TEXT), b) from independent translations of a speech (SPEECH), c) from independent descriptions of a visual scene (SCENE), and d) from independent descriptions of some event (EVENT).", "labels": [], "entities": [{"text": "TEXT", "start_pos": 219, "end_pos": 223, "type": "METRIC", "confidence": 0.9150157570838928}, {"text": "EVENT", "start_pos": 393, "end_pos": 398, "type": "METRIC", "confidence": 0.9675258994102478}]}, {"text": "We will report the results of experiments on sub-sentential paraphrase acquisition on all these corpus types in two languages, English and French, and provide some answers to the following questions: What types of paraphrases can be found by human annotators, with what confidence and in which quantities?", "labels": [], "entities": [{"text": "sub-sentential paraphrase acquisition", "start_pos": 45, "end_pos": 82, "type": "TASK", "confidence": 0.6196344097455343}]}, {"text": "How well can representative paraphrase acquisition systems perform on each corpus type, and how performance can be improved through combination?", "labels": [], "entities": [{"text": "paraphrase acquisition", "start_pos": 28, "end_pos": 50, "type": "TASK", "confidence": 0.7208032310009003}]}, {"text": "On what corpus types can performance be improved by using training material from other corpus types?", "labels": [], "entities": []}, {"text": "Our experimental results will provide several indications of the differences and complementarities of the corpus types understudy, and will notably show that performance on the most readily available corpus type can be improved by using training data from the set of all other corpus types.", "labels": [], "entities": []}, {"text": "We will first describe the building procedures and characteristics of our corpora (section 2), and then describe our experimental settings for evaluating paraphrase acquisition (section 3.1).", "labels": [], "entities": [{"text": "paraphrase acquisition", "start_pos": 154, "end_pos": 176, "type": "TASK", "confidence": 0.8448239266872406}]}, {"text": "Our experiments will first consist of the description (section 3.2) and evaluation (section 3.3) of a system combination on each corpus type and then of our system provided with additional training data from the other corpus types (section 3.4).", "labels": [], "entities": []}, {"text": "We will finally briefly review related work (section 4) and discuss our main findings and future work (section 5).", "labels": [], "entities": []}], "datasetContent": [{"text": "Results for individual systems, their union and our validation system trained on each corpus type are given on.", "labels": [], "entities": []}, {"text": "First, we find that all individual systems fare better on TEXT, for which more training data were available and where semantic equiv- Using the implementation at: http://homepages.", "labels": [], "entities": [{"text": "TEXT", "start_pos": 58, "end_pos": 62, "type": "DATASET", "confidence": 0.5140756964683533}]}, {"text": "inf.ed.ac.uk/lzhang10/maxent_toolkit.html alence of sentence pairs is most likely.", "labels": [], "entities": []}, {"text": "EVENT appears to be the most difficult corpus type, whereas one could say that being the most readily data source this is a disapointing result: we will return to this in section 3.4.", "labels": [], "entities": []}, {"text": "In terms of performance on F-measure per corpus type, GIZA performs best for TEXT and SPEECH, containing long sentences with possible repetitions, while TER p performs on par with GIZA for SCENE and best for EVENT, where equivalences that are rare at the corpus level are more present.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 27, "end_pos": 36, "type": "METRIC", "confidence": 0.9095256924629211}, {"text": "TEXT", "start_pos": 77, "end_pos": 81, "type": "METRIC", "confidence": 0.8992506861686707}, {"text": "SPEECH", "start_pos": 86, "end_pos": 92, "type": "METRIC", "confidence": 0.7922202348709106}, {"text": "TER p", "start_pos": 153, "end_pos": 158, "type": "METRIC", "confidence": 0.9493324756622314}, {"text": "EVENT", "start_pos": 208, "end_pos": 213, "type": "METRIC", "confidence": 0.549317479133606}]}, {"text": "FASTR achieves a very low recall, showing that the encoded definitions of term variants do not coverall types of paraphrases, and also possibly that the lexical resource that it uses has incomplete coverage.", "labels": [], "entities": [{"text": "FASTR", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.40724146366119385}, {"text": "recall", "start_pos": 26, "end_pos": 32, "type": "METRIC", "confidence": 0.9995065927505493}]}, {"text": "It nonetheless obtains high precision values, most notably on TEXT.", "labels": [], "entities": [{"text": "precision", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.9973917007446289}, {"text": "TEXT", "start_pos": 62, "end_pos": 66, "type": "DATASET", "confidence": 0.5435799956321716}]}, {"text": "One last comment regarding individual systems is that PIVOT is by far the most precise of all the techniques used, but with a recall much lower than those of GIZA and TER p : as is the case for FASTR, which makes use of manuallyencoded lexical resources, PIVOT encodes in some sense some kind of semantic knowledge.", "labels": [], "entities": [{"text": "recall", "start_pos": 126, "end_pos": 132, "type": "METRIC", "confidence": 0.9992662072181702}, {"text": "TER p", "start_pos": 167, "end_pos": 172, "type": "METRIC", "confidence": 0.9693648219108582}]}, {"text": "In all cases, our combination system manages to increase F-measure substantially over the best individual system fora corpus type and the simple union.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 57, "end_pos": 66, "type": "METRIC", "confidence": 0.9985059499740601}]}, {"text": "Improvements are strong on TEXT (resp.", "labels": [], "entities": [{"text": "TEXT", "start_pos": 27, "end_pos": 31, "type": "METRIC", "confidence": 0.8573232293128967}]}, {"text": "+12.5 and +11.6 on English and French) and on SPEECH (+11.7 and +11.1) and quite good on SCENE (+3.2 and +6.4) and on EVENT (+5.4: Evaluation results for individual systems (left) and combination systems (right) on all corpus types for English (top) and French (bottom).", "labels": [], "entities": [{"text": "SPEECH", "start_pos": 46, "end_pos": 52, "type": "METRIC", "confidence": 0.8933367133140564}, {"text": "EVENT", "start_pos": 118, "end_pos": 123, "type": "METRIC", "confidence": 0.8311592936515808}]}, {"text": "Values in bold are for highest values fora given metric for each corpus type and language. and +6.1).", "labels": [], "entities": []}, {"text": "Recall from that TEXT and SPEECH were the two corpus types with the highest number of sure paraphrase examples for both languages: results show that our classifier was able to efficiently use them.", "labels": [], "entities": [{"text": "TEXT", "start_pos": 17, "end_pos": 21, "type": "METRIC", "confidence": 0.9419536590576172}, {"text": "SPEECH", "start_pos": 26, "end_pos": 32, "type": "METRIC", "confidence": 0.9404746890068054}]}, {"text": "Recall values for the union are quite strong for all corpus types, ranging from 71.4 (SPEECH in English) to.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9905666708946228}, {"text": "SPEECH", "start_pos": 86, "end_pos": 92, "type": "METRIC", "confidence": 0.9566528797149658}]}, {"text": "There is, however, a substantial decrease between the unions and the results of our combination systems, although recall values for our systems are roughly between 56 and 67, which maybe considered an acceptable range on such a task.", "labels": [], "entities": [{"text": "recall", "start_pos": 114, "end_pos": 120, "type": "METRIC", "confidence": 0.9987455606460571}]}, {"text": "Further study of false negatives should help with engineering new features to improve paraphrase recognition.", "labels": [], "entities": [{"text": "paraphrase recognition", "start_pos": 86, "end_pos": 108, "type": "TASK", "confidence": 0.9209827184677124}]}, {"text": "Lastly, we note that precision is in general highest fora specific system (PIVOT), and reaches high values for our validation system on TEXT, where we have the most examples (resp. 68.4 and 74.7 for English and French).", "labels": [], "entities": [{"text": "precision", "start_pos": 21, "end_pos": 30, "type": "METRIC", "confidence": 0.9995114803314209}, {"text": "TEXT", "start_pos": 136, "end_pos": 140, "type": "DATASET", "confidence": 0.8120822906494141}]}, {"text": "As seen in, synonymy is the most present phenomenon in all our corpora; it is also probably one of the most useful type of knowledge for many applications.", "labels": [], "entities": []}, {"text": "We now therefore focus on this class, for which all the sure paraphrases in our corpora falling in this class have been annotated.", "labels": [], "entities": []}, {"text": "Table 5 shows F-measure values for the individual techniques and our combination systems on all corpus types.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 14, "end_pos": 23, "type": "METRIC", "confidence": 0.9893564581871033}]}, {"text": "We first observe that our combination system also always improves here over the best individual system, albeit not by a large margin on EVENT.: F-measure values for test instances in the synonymy class (see) for all individual systems and our validation system for English (top) and French (bottom).", "labels": [], "entities": [{"text": "EVENT.", "start_pos": 136, "end_pos": 142, "type": "METRIC", "confidence": 0.993381142616272}, {"text": "F-measure", "start_pos": 144, "end_pos": 153, "type": "METRIC", "confidence": 0.9977208971977234}]}, {"text": "Also, we find that PIVOT performs relatively closer to GIZA and TER p on TEXT and SPEECH than for the full set of classes, confirming the intuition that translational equivalence maybe appropriate to recognize synonymy.", "labels": [], "entities": [{"text": "GIZA", "start_pos": 55, "end_pos": 59, "type": "METRIC", "confidence": 0.8481316566467285}, {"text": "TER p", "start_pos": 64, "end_pos": 69, "type": "METRIC", "confidence": 0.9818429350852966}, {"text": "TEXT", "start_pos": 73, "end_pos": 77, "type": "METRIC", "confidence": 0.7280163168907166}]}, {"text": "To test how different the corpora understudy are as regards paraphrase identification, we now consider using as additional training data for our classifiers corpora of the other types, both individually and collectively.", "labels": [], "entities": [{"text": "paraphrase identification", "start_pos": 60, "end_pos": 85, "type": "TASK", "confidence": 0.9610770046710968}]}, {"text": "Results are given on  The most notable observation is that EVENT is substantially improved by using all available additional training data for English (+10.2), and to a lesser extent for French (+2.5) . It should be noted that no individual corpus type, save TEXT, individually improves results on EVENT, and that results are yet substantially improved over the use of training data from TEXT when using all available data, revealing a collective contribution of all corpus types.", "labels": [], "entities": [{"text": "EVENT", "start_pos": 59, "end_pos": 64, "type": "METRIC", "confidence": 0.8630686402320862}]}, {"text": "The second major observation is that all other corpus types seem to be quite specific in nature, as no addition of training data from other types yields any improvement (with the exception of SPEECH on English), but they often in fact decrease performance.", "labels": [], "entities": []}, {"text": "For instance, SCENE in English is substantially negatively impacted by the use of the numerous examples of TEXT (-4 in F-measure) and even more when using all other training data.", "labels": [], "entities": [{"text": "SCENE", "start_pos": 14, "end_pos": 19, "type": "TASK", "confidence": 0.8617100715637207}, {"text": "TEXT", "start_pos": 107, "end_pos": 111, "type": "METRIC", "confidence": 0.9986104965209961}, {"text": "F-measure", "start_pos": 119, "end_pos": 128, "type": "METRIC", "confidence": 0.9384130835533142}]}, {"text": "This underlines the specific nature of this corpus type: independent descriptions of the same scene in a video maybe worded with much variation that mostly differ from that present in other corpus types.", "labels": [], "entities": []}, {"text": "Our main conclusion here is therefore that all our corpora understudy are quite specific in nature, but that EVENT can benefit from all training data from the other corpus types.", "labels": [], "entities": [{"text": "EVENT", "start_pos": 109, "end_pos": 114, "type": "METRIC", "confidence": 0.4756113290786743}]}, {"text": "We can further note that the fact that TEXT is almost not impacted by additional data may also be explained by the fact that this corpus type contains more than half of the total number of examples for the two languages.", "labels": [], "entities": []}, {"text": "Finally, there are substantially more positive paraphrase examples for French (19,427) than for English (12,593).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Description of all corpora and paraphrase reference sets for English (top) and French (bottom). Note that  SCENE for French appears within parentheses as we do not consider it of the same quality as the other corpora.", "labels": [], "entities": [{"text": "SCENE", "start_pos": 117, "end_pos": 122, "type": "METRIC", "confidence": 0.9819971919059753}]}, {"text": " Table 2: Percentages of paraphrase classes in 50 randomly selected sentence pairs for reference paraphrases for English  (top) and French (bottom). Classes are illustrated by the following examples:", "labels": [], "entities": []}, {"text": " Table 4: Evaluation results for individual systems (left) and combination systems (right) on all corpus types for English  (top) and French (bottom). Values in bold are for highest values for a given metric for each corpus type and language.", "labels": [], "entities": []}, {"text": " Table 5: F-measure values for test instances in the syn- onymy class (see", "labels": [], "entities": [{"text": "F-measure", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9826383590698242}]}, {"text": " Table 6: Evaluation results (F 1 scores) for all corpus  types for English (top) and French (bottom) when adding  training material from other corpus types (values with  gray background on the diagonal are when no additional  training data are used). \"#ex+\" rows indicate numbers of  positive paraphrase examples for each additional corpus  type.", "labels": [], "entities": [{"text": "F 1 scores)", "start_pos": 30, "end_pos": 41, "type": "METRIC", "confidence": 0.971013143658638}]}]}