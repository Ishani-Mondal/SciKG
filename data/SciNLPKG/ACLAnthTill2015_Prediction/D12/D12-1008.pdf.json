{"title": [{"text": "Optimising Incremental Dialogue Decisions Using Information Density for Interactive Systems", "labels": [], "entities": [{"text": "Optimising Incremental Dialogue Decisions", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.7681999355554581}]}], "abstractContent": [{"text": "Incremental processing allows system designers to address several discourse phenomena that have previously been somewhat neglected in interactive systems, such as backchannels or barge-ins, but that can enhance the responsiveness and naturalness of systems.", "labels": [], "entities": []}, {"text": "Unfortunately , prior work has focused largely on deterministic incremental decision making , rendering system behaviour less flexible and adaptive than is desirable.", "labels": [], "entities": []}, {"text": "We present a novel approach to incremental decision making that is based on Hierarchical Reinforcement Learning to achieve an interactive op-timisation of Information Presentation (IP) strategies, allowing the system to generate and comprehend backchannels and barge-ins, by employing the recent psycholinguistic hypothesis of information density (ID) (Jaeger, 2010).", "labels": [], "entities": []}, {"text": "Results in terms of average rewards and a human rating study show that our learnt strategy outperforms several baselines that are not sensitive to ID by more than 23%.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recent work on incremental systems has shown that adapting a system's turn-taking behaviour to be more human-like can improve the user's experience significantly, based on incremental models of automatic speech recognition (ASR) (), dialogue management (, and speech generation).", "labels": [], "entities": [{"text": "automatic speech recognition (ASR)", "start_pos": 194, "end_pos": 228, "type": "TASK", "confidence": 0.8024764855702718}, {"text": "dialogue management", "start_pos": 233, "end_pos": 252, "type": "TASK", "confidence": 0.8797605335712433}, {"text": "speech generation", "start_pos": 260, "end_pos": 277, "type": "TASK", "confidence": 0.7614571154117584}]}, {"text": "All of these approaches are based on the same general abstract architecture of incremental processing (.", "labels": [], "entities": []}, {"text": "While this architecture offers inherently incremental mechanisms to update and revise input hypotheses, it is affected by a number of drawbacks, shared by deterministic models of decision making in general: they rely on hand-crafted rules which can be time-consuming and expensive to produce, they do not provide a mechanism to deal with uncertainty introduced by varying user behaviour, they are unable to generalise and adapt flexibly to unseen situations, and they do not use automatic optimisation.", "labels": [], "entities": []}, {"text": "Statistical approaches to incremental processing that address some of these problems have been suggested by, who use a cost matrix and decision theoretic principles to optimise turntaking in a dialogue system under the constraint that users prefer no gaps and no overlap at turn boundaries.", "labels": [], "entities": []}, {"text": "use maximum entropy classification to support responsive overlap in an incremental system by predicting the completions of user utterances.", "labels": [], "entities": []}, {"text": "use logistic regression models to predict the stability and accuracy of incremental speech recognition results to enhance performance without causing delay.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9968602657318115}, {"text": "speech recognition", "start_pos": 84, "end_pos": 102, "type": "TASK", "confidence": 0.6751861423254013}]}, {"text": "For related work on (deterministic) incremental language generation, please see (.", "labels": [], "entities": [{"text": "deterministic) incremental language generation", "start_pos": 21, "end_pos": 67, "type": "TASK", "confidence": 0.6724140346050262}]}, {"text": "Recent years have seen a number of data-driven approaches to interactive systems that automatically adapt their decisions to the dialogue context using Reinforcement Learning (;.", "labels": [], "entities": []}, {"text": "While these approaches have been shown to enhance the performance and adaptivity of interactive systems, unfortunately none of them has yet been combined with incremental processing.", "labels": [], "entities": []}, {"text": "In this paper, we present a novel approach to incremental decision making for output planning that is based on Hierarchical Reinforcement Learning (HRL).", "labels": [], "entities": []}, {"text": "In particular, we address the problem of optimising IP strategies while allowing the system to generate and comprehend backchannels and bargeins based on a partially data-driven reward function.", "labels": [], "entities": []}, {"text": "Generating backchannels can be beneficial for grounding in interaction.", "labels": [], "entities": []}, {"text": "Similarly, barge-ins can lead to more efficient interactions, e.g. when a system can clarify a bad recognition result immediately before acting based on a misrecognition.", "labels": [], "entities": []}, {"text": "A central concept to our approach is Information Density (ID), a psycholinguistic hypothesis that human utterance production is sensitive to a uniform distribution of information across the utterance.", "labels": [], "entities": [{"text": "Information Density (ID)", "start_pos": 37, "end_pos": 61, "type": "TASK", "confidence": 0.8561345100402832}]}, {"text": "This hypothesis has also been adopted for low level output planning recently, see e.g. Rajkumar and White (2011).", "labels": [], "entities": []}, {"text": "Our results in terms of average rewards and a human rating study show that a learning agent that is sensitive to ID can learn when it is most beneficial to generate feedback to a user, and outperforms several other agents that are not sensitive to ID.", "labels": [], "entities": []}], "datasetContent": [{"text": "The agent learns to barge-in or generate backchannels to users at points where the ID is low but rising.", "labels": [], "entities": [{"text": "ID", "start_pos": 83, "end_pos": 85, "type": "METRIC", "confidence": 0.9781728386878967}]}, {"text": "In particular, the agent learns to barge-in right before information density peaks in an incoming user utterance to clarify or request slots that are still open from the previous information density peak.", "labels": [], "entities": []}, {"text": "If a user has specified their desired cuisine type but the system has received a low ASR confidence score for it, it may barge-in to clarify the slot.", "labels": [], "entities": [{"text": "ASR confidence score", "start_pos": 85, "end_pos": 105, "type": "METRIC", "confidence": 0.9508954882621765}]}, {"text": "This case was illustrated in the last example in, where the system clarified the previous (cuisine) slot (which is associated with a high ID) just before the user specifies the location slot (which again would have a high ID).", "labels": [], "entities": []}, {"text": "The main benefit the system can gain through clarification barge-ins is to avoid self-corrections when having acted based on a low ASR confidence, leading to more efficient interactions.", "labels": [], "entities": [{"text": "ASR", "start_pos": 131, "end_pos": 134, "type": "TASK", "confidence": 0.5873393416404724}]}, {"text": "The system learns to generate backchannels after information peaks to confirm newly acquired slots that have a high confidence.", "labels": [], "entities": []}, {"text": "An example is shown in the first dialogue fragment in.", "labels": [], "entities": []}, {"text": "In addition, the system learns to yield its current turn to a user that is barging-in if its own ID is low, falling or rising, or if the ID of the incoming user utterance is high.", "labels": [], "entities": []}, {"text": "If the system's own ID is high, but the user's is not, it will try to keep the turn.", "labels": [], "entities": []}, {"text": "6 This is exemplified in the third dialogue fragment in.", "labels": [], "entities": []}, {"text": "We compare our learnt policy against two baselines.", "labels": [], "entities": []}, {"text": "Baseline 1 was designed to always generate barge-ins after an information peak in a user utterance, i.e. when ID has just switched from high to falling.", "labels": [], "entities": []}, {"text": "We chose this baseline to confirm that users indeed prefer barge-ins before information peaks rather than at any point of low ID.", "labels": [], "entities": [{"text": "ID", "start_pos": 126, "end_pos": 128, "type": "METRIC", "confidence": 0.9584549069404602}]}, {"text": "Baseline 1 yields a turn to a user barge-in if its own ID is low and tries to keep it otherwise.", "labels": [], "entities": []}, {"text": "Baseline 2 generates barge-ins and backchannels randomly and at any point during a user utterance.", "labels": [], "entities": []}, {"text": "The decision of yielding or keeping a turn in case of a user barge-in is also random.", "labels": [], "entities": []}, {"text": "Both baselines also use HRL to optimise their IP strategy.", "labels": [], "entities": []}, {"text": "We do not compare different IP strategies, which has been done in detail by.", "labels": [], "entities": []}, {"text": "All re-6 Incidentally, this also helps to prevent the system yielding its turn to a user backchannel; cf. Example 2 in. sults are summarised in. shows the performance of all systems in terms of average rewards in simulation.", "labels": [], "entities": []}, {"text": "The learnt policy outperforms both baselines.", "labels": [], "entities": []}, {"text": "While the learnt policy and Baseline 1 appear to achieve similar performance, an absolute comparison of the last 1000 episodes of each behaviour shows that the improvement of the HRL agent over Baseline 1 corresponds to 23.42%.", "labels": [], "entities": []}, {"text": "The difference between the learnt policy and its baselines is significant at p < 0.0001 according to a paired t-test and has a high effect size of r = 0.85.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Comparison of policies in terms of average re- wards and user ratings.  *  indicates a significant improve- ment over Baseline 1 and  *  *  over Baseline 2.", "labels": [], "entities": [{"text": "improve- ment", "start_pos": 109, "end_pos": 122, "type": "METRIC", "confidence": 0.8468941847483317}]}]}