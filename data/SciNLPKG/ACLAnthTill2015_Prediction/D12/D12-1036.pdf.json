{"title": [{"text": "Answering Opinion Questions on Products by Exploiting Hierarchical Organization of Consumer Reviews", "labels": [], "entities": [{"text": "Answering Opinion Questions on Products by Exploiting Hierarchical Organization of Consumer Reviews", "start_pos": 0, "end_pos": 99, "type": "TASK", "confidence": 0.723034086326758}]}], "abstractContent": [{"text": "This paper proposes to generate appropriate answers for opinion questions about products by exploiting the hierarchical organization of consumer reviews.", "labels": [], "entities": []}, {"text": "The hierarchy organizes product aspects as nodes following their parent-child relations.", "labels": [], "entities": []}, {"text": "For each aspect, the reviews and corresponding opinions on this aspect are stored.", "labels": [], "entities": []}, {"text": "We develop anew framework for opinion Questions Answering, which enables accurate question analysis and effective answer generation by making use the hierarchy.", "labels": [], "entities": [{"text": "opinion Questions Answering", "start_pos": 30, "end_pos": 57, "type": "TASK", "confidence": 0.6727846165498098}, {"text": "question analysis", "start_pos": 82, "end_pos": 99, "type": "TASK", "confidence": 0.7154436260461807}, {"text": "answer generation", "start_pos": 114, "end_pos": 131, "type": "TASK", "confidence": 0.7526539266109467}]}, {"text": "In particular, we first identify the (ex-plicit/implicit) product aspects asked in the questions and their sub-aspects by referring to the hierarchy.", "labels": [], "entities": []}, {"text": "We then retrieve the corresponding review fragments relevant to the aspects from the hierarchy.", "labels": [], "entities": []}, {"text": "In order to generate appropriate answers from the review fragments , we develop a multi-criteria optimization approach for answer generation by simultaneously taking into account review salience, coherence, diversity, and parent-child relations among the aspects.", "labels": [], "entities": [{"text": "answer generation", "start_pos": 123, "end_pos": 140, "type": "TASK", "confidence": 0.8972656726837158}]}, {"text": "We conduct evaluations on 11 popular products in four domains.", "labels": [], "entities": []}, {"text": "The evaluated corpus contains 70,359 consumer reviews and 220 questions on these products.", "labels": [], "entities": []}, {"text": "Experimental results demonstrate the effectiveness of our approach.", "labels": [], "entities": []}], "introductionContent": [{"text": "With the rapid development of E-commerce, most retail websites encourage consumers to post reviews to express their opinions on the products.", "labels": [], "entities": []}, {"text": "For example, the review \"The battery of Nokia N95 is amazing.\" reveals positive opinion on the aspect \"bat- tery\" of product Nokia N95.", "labels": [], "entities": [{"text": "Nokia N95", "start_pos": 40, "end_pos": 49, "type": "DATASET", "confidence": 0.9117051661014557}]}, {"text": "An aspect here refers to a component or an attribute of a certain product.", "labels": [], "entities": []}, {"text": "Numerous consumer reviews are now available online, and these reviews contain rich opinionated information on various aspects of products.", "labels": [], "entities": []}, {"text": "They are naturally a valuable resource for answering opinion questions about products, such as \"How do people think about the battery of Nokia N95?\"", "labels": [], "entities": []}, {"text": "Opinion Question Answering (opinion-QA) on products seeks to uncover consumers' thinking and feeling about the products or aspects of products.", "labels": [], "entities": [{"text": "Opinion Question Answering (opinion-QA)", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.7752807041009268}]}, {"text": "It is different from traditional factual QA, where the questions ask for the fact, such as \"Where is the capital of United States?\" and the answer is \"Washington, D.C.\" For a product opinionated question, the answer should not be just a best answer.", "labels": [], "entities": []}, {"text": "It should reflect the opinions of various segments of users, and incorpo-rate both positive and negative viewpoints.", "labels": [], "entities": []}, {"text": "Hence the answer should be a summarization of public opinions and comments on the product or specific aspect asked in the question (.", "labels": [], "entities": []}, {"text": "In addition, it should also include public opinions and comments on the sub-aspects.", "labels": [], "entities": []}, {"text": "Such answers would help users to understand the inherent reasons of the opinions on the asked aspect.", "labels": [], "entities": []}, {"text": "For example, the question \"What do people think the camera of Nokia 5800?\" asks for public positive and negative opinions on the aspect \"camera\" of product \"Nokia 5800.\"", "labels": [], "entities": []}, {"text": "The summarization of opinions on the sub-aspects such as \"lens\" and \"resolution\" would help users better understand that the public complaints on the aspect \"camera\" are due to the poor \"lens\" and/or low \"resolution.\"", "labels": [], "entities": [{"text": "resolution", "start_pos": 69, "end_pos": 79, "type": "METRIC", "confidence": 0.958834707736969}]}, {"text": "Moreover, the answer should be presented following the generalto-specific logic, i.e., from general aspects to specific sub-aspects.", "labels": [], "entities": []}, {"text": "This makes the answer easier to understand by the users (.", "labels": [], "entities": []}, {"text": "Current Opinion-QA methods mainly include three components, including question analysis that identifies aspects and opinions asked in the questions, answer fragment retrieval, and answer generation which summarizes the retrieved fragments).", "labels": [], "entities": [{"text": "question analysis", "start_pos": 70, "end_pos": 87, "type": "TASK", "confidence": 0.674992710351944}, {"text": "answer fragment retrieval", "start_pos": 149, "end_pos": 174, "type": "TASK", "confidence": 0.71128777662913}, {"text": "answer generation", "start_pos": 180, "end_pos": 197, "type": "TASK", "confidence": 0.7290215194225311}]}, {"text": "Although existing methods show encouraging performance, they are usually notable to generate satisfactory answers due to the following drawbacks.", "labels": [], "entities": []}, {"text": "First, current methods often identify aspects as the noun phrases in the questions.", "labels": [], "entities": []}, {"text": "However, noun phrases contain noises that are not aspects.", "labels": [], "entities": []}, {"text": "This gives rise to imprecise aspect identification.", "labels": [], "entities": [{"text": "aspect identification", "start_pos": 29, "end_pos": 50, "type": "TASK", "confidence": 0.7936292588710785}]}, {"text": "For example, in the question \"What reasons can I persuade my wife that people prefer the battery of Nokia N95?\" noun phrases \"wife\" and \"people\" are not aspects.", "labels": [], "entities": []}, {"text": "Moreover, current methods relied on noun phrases are notable to reveal the implicit aspects, which are not explicitly asked in the questions.", "labels": [], "entities": []}, {"text": "For example, the question \"Is iPhone 4 expensive?\" asks about the aspect \"price\", but the term \"price\" does not appear in the question.", "labels": [], "entities": []}, {"text": "Second, current methods cannot discover sub-aspects of the asked aspect due to its ignorance of parent-child relations among aspects.", "labels": [], "entities": []}, {"text": "Third, the answers generated by the existing methods do not follow the general-tospecific logic, leading to difficulty in understanding the answers.", "labels": [], "entities": []}, {"text": "To overcome these problems, we can resort to the hierarchical organization of consumer reviews on products.", "labels": [], "entities": []}, {"text": "As illustrated in, the hierarchy organizes product aspects as nodes, following their parent-child relations.", "labels": [], "entities": []}, {"text": "For each aspect, the reviews and corresponding opinions on this aspect are stored.", "labels": [], "entities": []}, {"text": "Such hierarchy can naturally facilitate to identify aspects asked in questions.", "labels": [], "entities": []}, {"text": "While explicit aspects can be recognized by referring to the hierarchy, implicit aspects can be inferred based on the associations between sentiment terms and aspects in the hierarchy ().", "labels": [], "entities": []}, {"text": "The sentiment terms are discovered from the reviews on corresponding aspects.", "labels": [], "entities": []}, {"text": "Moreover, by following the parent-child relations in the hierarchy, sub-aspects of the asked aspect can be directly acquired, and the answers can present aspects from general to specific.", "labels": [], "entities": []}, {"text": "Motivated by the above observations, we propose to exploit the hierarchical organization of consumer reviews for product opinion-QA.", "labels": [], "entities": []}, {"text": "As illustrated in, our framework first organizes consumer reviews of a certain product into a hierarchical organization.", "labels": [], "entities": []}, {"text": "The resulting hierarchy is in turn used to help question analysis and relevant review fragments retrieval.", "labels": [], "entities": [{"text": "question analysis", "start_pos": 48, "end_pos": 65, "type": "TASK", "confidence": 0.8435583710670471}, {"text": "relevant review fragments retrieval", "start_pos": 70, "end_pos": 105, "type": "TASK", "confidence": 0.5768329426646233}]}, {"text": "In order to generate appropriate answers from the retrieved fragments, we develop a multi-criteria optimization approach by simultaneously taking into account review salience, coherence, and diversity.", "labels": [], "entities": []}, {"text": "The parent-child relations among aspects are also incorporated into the approach to ensure the answers be general-to-specific.", "labels": [], "entities": []}, {"text": "We conduct evaluations on 11 popular products in four domains.", "labels": [], "entities": []}, {"text": "The evaluated corpus contains 70,359 consumer reviews and 220 questions on these products.", "labels": [], "entities": []}, {"text": "More details of the dataset are discussed in Section 4.", "labels": [], "entities": []}, {"text": "Experimental results to demonstrate the effectiveness of our approach.", "labels": [], "entities": []}, {"text": "The main contributions of this paper include, \u2022 We propose to exploit the hierarchical organization of consumer reviews for answering opinion questions on products.", "labels": [], "entities": []}, {"text": "\u2022 With the help of the hierarchy, our proposed framework can accurately identify (explicit/implicit) aspects asked in the questions, and the corresponding sub-aspects.", "labels": [], "entities": []}, {"text": "\u2022 We develop a multi-criteria optimization approach to generate informative, coherent, diverse and general-to-specific answers.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 introduces the components of hierarchical organization of reviews, question analysis, and answer fragment retrieval.", "labels": [], "entities": [{"text": "question analysis", "start_pos": 77, "end_pos": 94, "type": "TASK", "confidence": 0.8461858034133911}, {"text": "answer fragment retrieval", "start_pos": 100, "end_pos": 125, "type": "TASK", "confidence": 0.7504291733105978}]}, {"text": "Section 3 elaborates the multicriteria optimization approach for answer generation . Section 4 presents experimental details, while Section 5 reviews related works.", "labels": [], "entities": [{"text": "answer generation", "start_pos": 65, "end_pos": 82, "type": "TASK", "confidence": 0.9547963440418243}]}, {"text": "Finally, Section 6 concludes this paper with future works.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we evaluate the effectiveness of the proposed approach, in terms of question analysis and answer generation.", "labels": [], "entities": [{"text": "question analysis", "start_pos": 85, "end_pos": 102, "type": "TASK", "confidence": 0.8121425807476044}, {"text": "answer generation", "start_pos": 107, "end_pos": 124, "type": "TASK", "confidence": 0.835445910692215}]}, {"text": "We employed the product review dataset used in as corpus.", "labels": [], "entities": [{"text": "product review dataset", "start_pos": 16, "end_pos": 38, "type": "DATASET", "confidence": 0.6025750736395518}]}, {"text": "As illustrated in, the dataset contained 70,359 reviews about 11 popular products in four domains.", "labels": [], "entities": []}, {"text": "In addition, we created 220 questions for these products by referring to real questions in Yahoo!Anwser service.", "labels": [], "entities": [{"text": "Yahoo!Anwser service", "start_pos": 91, "end_pos": 111, "type": "DATASET", "confidence": 0.9146487861871719}]}, {"text": "We corrected the typos and grammar errors for these real questions.", "labels": [], "entities": []}, {"text": "Each product contains 15 opinion questions and 5 factual questions, respectively.", "labels": [], "entities": []}, {"text": "All questions were shown in Appendix C in supplementary material.", "labels": [], "entities": [{"text": "Appendix", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.7754212617874146}]}, {"text": "Three annotators were invited to generate the gold standard.", "labels": [], "entities": [{"text": "gold standard", "start_pos": 46, "end_pos": 59, "type": "DATASET", "confidence": 0.8997530937194824}]}, {"text": "Each question was labeled by two annotators.", "labels": [], "entities": []}, {"text": "The labels include product name, product aspect, opinion, question type and question form.", "labels": [], "entities": []}, {"text": "The average inter-rater agreement in terms of Kappa statistics is 89%.", "labels": [], "entities": [{"text": "agreement", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.8066165447235107}, {"text": "Kappa statistics", "start_pos": 46, "end_pos": 62, "type": "DATASET", "confidence": 0.86801677942276}]}, {"text": "These annotators were then invited to read the reviews, and create the ground truth answers by selecting and ordering some review sentences.", "labels": [], "entities": []}, {"text": "Such process is time consuming and laborintensive.", "labels": [], "entities": []}, {"text": "We speedup the annotation process as follows.", "labels": [], "entities": []}, {"text": "We first collected all the review sentences in the answers generated by three evaluated methods to be discussed in Section 4.3.1.", "labels": [], "entities": []}, {"text": "In addition, we sampled the top-N (N=20) sentences on each asked aspect and its sub-aspects respectively, where the sentences were ranked based on their salient weights in Section 3.2.", "labels": [], "entities": []}, {"text": "We then provided such subset of review sentences to the three annotators, and let them individually create an answer of up to 100 words (i.e. K=100) for each question.", "labels": [], "entities": []}, {"text": "We employed precision (P), recall (R) and F 1 -measure (F 1 ) as the evaluation metric for question analysis, and utilized ROUGE ( as the metric to evaluate the quality of answer generation.", "labels": [], "entities": [{"text": "precision (P)", "start_pos": 12, "end_pos": 25, "type": "METRIC", "confidence": 0.9491012841463089}, {"text": "recall (R)", "start_pos": 27, "end_pos": 37, "type": "METRIC", "confidence": 0.9478503167629242}, {"text": "F 1 -measure (F 1 )", "start_pos": 42, "end_pos": 61, "type": "METRIC", "confidence": 0.9691016748547554}, {"text": "question analysis", "start_pos": 91, "end_pos": 108, "type": "TASK", "confidence": 0.7666425704956055}, {"text": "ROUGE", "start_pos": 123, "end_pos": 128, "type": "METRIC", "confidence": 0.9928667545318604}, {"text": "answer generation", "start_pos": 172, "end_pos": 189, "type": "TASK", "confidence": 0.7221967130899429}]}, {"text": "ROUGE is a widely accepted standard for summarization, which measures the quality of the summarized answers by counting the overlapping Ngrams between the answers generated by machine and human, respectively.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9498775601387024}, {"text": "summarization", "start_pos": 40, "end_pos": 53, "type": "TASK", "confidence": 0.9909379482269287}]}, {"text": "In the experiment, we reported the F 1 -measure of ROUGE-1, ROUGE-2 and ROUGE-SU4, which count the overlapping unigrams, bigrams and skip-4 bigrams respectively.", "labels": [], "entities": [{"text": "F 1 -measure", "start_pos": 35, "end_pos": 47, "type": "METRIC", "confidence": 0.9843509644269943}, {"text": "ROUGE-1", "start_pos": 51, "end_pos": 58, "type": "METRIC", "confidence": 0.8773598074913025}, {"text": "ROUGE-2", "start_pos": 60, "end_pos": 67, "type": "METRIC", "confidence": 0.8816162943840027}, {"text": "ROUGE-SU4", "start_pos": 72, "end_pos": 81, "type": "METRIC", "confidence": 0.8599883913993835}]}, {"text": "ROUGE-1 can measure informativeness of the answers, while higher order ROUGE-N (N=2,4) captures the matching of subsequences, which can measure the fluency and readability of the answers.", "labels": [], "entities": [{"text": "ROUGE-1", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.910697340965271}, {"text": "ROUGE-N", "start_pos": 71, "end_pos": 78, "type": "METRIC", "confidence": 0.942838728427887}]}, {"text": "For the trade-off parameters, we empirically set \u03bb 1 = 0.4, \u03bb 2 = 0.3 and \u03bb 3 = 0.3.", "labels": [], "entities": []}, {"text": "We first evaluated the performance of product recognition, opinion/factual question classification, opinion classification, question type and question form identification.", "labels": [], "entities": [{"text": "product recognition", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.7281963378190994}, {"text": "opinion/factual question classification", "start_pos": 59, "end_pos": 98, "type": "TASK", "confidence": 0.6303565680980683}, {"text": "opinion classification", "start_pos": 100, "end_pos": 122, "type": "TASK", "confidence": 0.7298150360584259}, {"text": "question form identification", "start_pos": 142, "end_pos": 170, "type": "TASK", "confidence": 0.6268840730190277}]}, {"text": "The experimental results are shown in.", "labels": [], "entities": []}, {"text": "The results show that traditional methods achieve encouraging performance on the aforementioned tasks.", "labels": [], "entities": []}, {"text": "We next examined the performance of our approach on aspect identification.", "labels": [], "entities": [{"text": "aspect identification", "start_pos": 52, "end_pos": 73, "type": "TASK", "confidence": 0.9534904956817627}]}, {"text": "The method proposed by was reimplemented as the baseline, which identifies aspects based on noun phrase extraction.", "labels": [], "entities": [{"text": "noun phrase extraction", "start_pos": 92, "end_pos": 114, "type": "TASK", "confidence": 0.6572996973991394}]}, {"text": "This method achieved good performance on the opinion QA task in TAC 2008 and was employed in subsequent works.", "labels": [], "entities": [{"text": "opinion QA task in TAC 2008", "start_pos": 45, "end_pos": 72, "type": "DATASET", "confidence": 0.6072211861610413}]}, {"text": "As demonstrated in, our approach significantly outperforms Balahur's method by over 49.4% in terms of average F 1 -measure.", "labels": [], "entities": [{"text": "F 1 -measure", "start_pos": 110, "end_pos": 122, "type": "METRIC", "confidence": 0.9655119180679321}]}, {"text": "A probable reason is that Balahur's method relies on noun phrases, which may mis-identify some noise noun phrases as aspects, while our approach performs hierarchical classification based on the hierarchy, which can leverage the prior knowledge encoded in the hierarchy to filter out the noise and obtain accurate aspects.", "labels": [], "entities": []}, {"text": "Moreover, we evaluated the effectiveness of our approach on implicit aspect identification.", "labels": [], "entities": [{"text": "implicit aspect identification", "start_pos": 60, "end_pos": 90, "type": "TASK", "confidence": 0.5863090554873148}]}, {"text": "The 70 implicit aspect questions in our question corpus were used here.", "labels": [], "entities": []}, {"text": "The method proposed by was reimplemented as the baseline.", "labels": [], "entities": []}, {"text": "It identifies implicit aspects by mutual clustering, and it was, our approach significantly outperforms Su's method by over 9.1% in terms of average F 1 -measure.", "labels": [], "entities": [{"text": "F 1 -measure", "start_pos": 149, "end_pos": 161, "type": "METRIC", "confidence": 0.9494462609291077}]}, {"text": "The results show that the hierarchy can help to identify implicit aspects by exploiting the underlying associations among sentiment terms and aspects.", "labels": [], "entities": []}, {"text": "We further evaluated the effectiveness of each optimization criterion by tuning the trade-off parameters (i.e. \u03bb 1 , \u03bb 2 , and \u03bb 3 ).", "labels": [], "entities": []}, {"text": "We fixed \u03bb 1 as a constant in with 0.1 as an interval, and updated \u03bb 2 from 0 to 1 \u2212 \u03bb 1 , \u03bb 3 = 1 \u2212 \u03bb 1 \u2212 \u03bb 2 , correspondingly.", "labels": [], "entities": []}, {"text": "The performance change is shown in in terms of ROUGE-1, ROUGE-2, and ROUGE-SU4, respectively.", "labels": [], "entities": [{"text": "ROUGE-1", "start_pos": 47, "end_pos": 54, "type": "METRIC", "confidence": 0.9394798278808594}, {"text": "ROUGE-2", "start_pos": 56, "end_pos": 63, "type": "METRIC", "confidence": 0.8660265803337097}, {"text": "ROUGE-SU4", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.9137396812438965}]}, {"text": "The best performance is achieved at \u03bb 1 = 0.4, \u03bb 2 = 0.3, \u03bb 3 = 0.3.", "labels": [], "entities": []}, {"text": "We observe the performance drops dramatically when any parameter (i.e. \u03bb 1 , \u03bb 2 , \u03bb 3 ) is close to 0 (i.e. remove any of the corresponding criterion).", "labels": [], "entities": []}, {"text": "Thus, we can conclude that all the criteria are useful in answer generation.", "labels": [], "entities": [{"text": "answer generation", "start_pos": 58, "end_pos": 75, "type": "TASK", "confidence": 0.9493424892425537}]}, {"text": "We also find that the performance change is sharp when \u03bb 1 changes.", "labels": [], "entities": []}, {"text": "This indicates that the salience criterion is crucial for answer generation.", "labels": [], "entities": [{"text": "answer generation", "start_pos": 58, "end_pos": 75, "type": "TASK", "confidence": 0.9531504511833191}]}, {"text": "shows the exemplar answers generated by our approach.", "labels": [], "entities": []}, {"text": "Each answer first gives the statistic of positive and negative reviews.", "labels": [], "entities": []}, {"text": "This helps user to quickly get an overview of public opinions.", "labels": [], "entities": []}, {"text": "The summary of relevant review sentences is then presented in the answer.", "labels": [], "entities": []}, {"text": "The answer diversely comments the asked aspect and all its available sub-aspects following the general-to-specific logic.", "labels": [], "entities": []}, {"text": "Moreover, we feel that the answers are informative and readable.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of the product review dataset, # denotes  the number of the reviews/sentences.", "labels": [], "entities": [{"text": "product review dataset", "start_pos": 28, "end_pos": 50, "type": "DATASET", "confidence": 0.6323204139868418}]}, {"text": " Table 2. The results show that traditional methods  achieve encouraging performance on the aforemen- tioned tasks.", "labels": [], "entities": []}, {"text": " Table 2: Performance of question analysis.", "labels": [], "entities": [{"text": "question analysis", "start_pos": 25, "end_pos": 42, "type": "TASK", "confidence": 0.8165607750415802}]}, {"text": " Table 3: Performance of aspect identification for question  analysis. * denotes the results (i.e. P , R, F 1 ) are tested  for statistical significance using T-Test, p-values<0.05.", "labels": [], "entities": [{"text": "aspect identification", "start_pos": 25, "end_pos": 46, "type": "TASK", "confidence": 0.8183476626873016}, {"text": "question  analysis", "start_pos": 51, "end_pos": 69, "type": "TASK", "confidence": 0.7755109071731567}, {"text": "T-Test", "start_pos": 159, "end_pos": 165, "type": "METRIC", "confidence": 0.9606124758720398}]}, {"text": " Table 4: Performance of implicit aspect identification for  question analysis. T-Test, p-values<0.05", "labels": [], "entities": [{"text": "implicit aspect identification", "start_pos": 25, "end_pos": 55, "type": "TASK", "confidence": 0.6566843191782633}, {"text": "question analysis", "start_pos": 61, "end_pos": 78, "type": "TASK", "confidence": 0.7742171883583069}, {"text": "T-Test", "start_pos": 80, "end_pos": 86, "type": "METRIC", "confidence": 0.990107536315918}]}, {"text": " Table 5: Performance of answer generation. T-Test, p- values<0.05.", "labels": [], "entities": [{"text": "answer generation", "start_pos": 25, "end_pos": 42, "type": "TASK", "confidence": 0.8875544369220734}, {"text": "T-Test", "start_pos": 44, "end_pos": 50, "type": "METRIC", "confidence": 0.992634117603302}]}]}