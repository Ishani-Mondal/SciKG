{"title": [{"text": "Local and Global Context for Supervised and Unsupervised Metonymy Resolution", "labels": [], "entities": [{"text": "Supervised and Unsupervised Metonymy Resolution", "start_pos": 29, "end_pos": 76, "type": "TASK", "confidence": 0.599710899591446}]}], "abstractContent": [{"text": "Computational approaches to metonymy resolution have focused almost exclusively on the local context, especially the constraints placed on a potentially metonymic word by its grammatical collocates.", "labels": [], "entities": [{"text": "metonymy resolution", "start_pos": 28, "end_pos": 47, "type": "TASK", "confidence": 0.9678573608398438}]}, {"text": "We expand such approaches by taking into account the larger context.", "labels": [], "entities": []}, {"text": "Our algorithm is tested on the data from the metonymy resolution task (Task 8) at SemEval 2007.", "labels": [], "entities": [{"text": "metonymy resolution task", "start_pos": 45, "end_pos": 69, "type": "TASK", "confidence": 0.8852560122807821}, {"text": "SemEval 2007", "start_pos": 82, "end_pos": 94, "type": "DATASET", "confidence": 0.6689718514680862}]}, {"text": "The results show that incorporation of the global context can improve over the use of the local context alone, depending on the types of metonymies addressed.", "labels": [], "entities": []}, {"text": "As a second contribution, we move towards unsu-pervised resolution of metonymies, made feasible by considering ontological relations as possible readings.", "labels": [], "entities": []}, {"text": "We show that such an unsu-pervised approach delivers promising results: it beats the supervised most frequent sense baseline and performs close to a supervised approach using only standard lexico-syntactic features.", "labels": [], "entities": []}], "introductionContent": [{"text": "With the exception of explicit tasks in metonymy and metaphor analysis, computational treatment of language relies on the assumption that the texts to be processed have a literal interpretation.", "labels": [], "entities": [{"text": "metaphor analysis", "start_pos": 53, "end_pos": 70, "type": "TASK", "confidence": 0.8711322247982025}]}, {"text": "This contrasts with the fact that figurative expressions are common in language, as exemplified by the metonymy in the excerpt from a Wikipedia article in Example 1 and another in Example 2 from the SemEval 2007 metonymy resolution task).", "labels": [], "entities": [{"text": "SemEval 2007 metonymy resolution task", "start_pos": 199, "end_pos": 236, "type": "TASK", "confidence": 0.7533453941345215}]}, {"text": "(1) In the gold medal game, Canada defeated the American team 2-0 to win their third consecutive gold.", "labels": [], "entities": []}, {"text": "(2) This keyword is only required when your relational database is Oracle.", "labels": [], "entities": []}, {"text": "The defeating in Example 1 will not be done by the country as such, but by a team representing the country in a sporting event.", "labels": [], "entities": []}, {"text": "Hence, in a metonymy a potentially metonymic expression or word (here Canada) stands fora conceptually related entity (here, people of Canada).", "labels": [], "entities": []}, {"text": "In the second Example, a company name (Oracle) stands fora product (database) developed by the company.", "labels": [], "entities": []}, {"text": "Metonymy resolution can be important fora variety of tasks.", "labels": [], "entities": [{"text": "Metonymy resolution", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9278211891651154}]}, {"text": "Textual entailment may need metonymy resolution (: for example, we would like to be able to induce from Example 1 the hypothesis The Canadian team won . .", "labels": [], "entities": [{"text": "Textual entailment", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7693439722061157}, {"text": "metonymy resolution", "start_pos": 28, "end_pos": 47, "type": "TASK", "confidence": 0.7166471183300018}]}, {"text": "show that metonymy recognition on location proper names helps geographical information retrieval by excluding metonymically used place names from consideration (such as Example 1 or the use of Vietnam for the Vietnam war).", "labels": [], "entities": [{"text": "metonymy recognition on location proper names", "start_pos": 10, "end_pos": 55, "type": "TASK", "confidence": 0.7898185004790624}, {"text": "geographical information retrieval", "start_pos": 62, "end_pos": 96, "type": "TASK", "confidence": 0.700830360253652}]}, {"text": "Metonymies also frequently interact with anaphora resolution), as in Example 1 where the metonymic use of Canada is referred to by a plural pronoun afterward (their).", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 41, "end_pos": 60, "type": "TASK", "confidence": 0.7405828833580017}]}, {"text": "Metonymies can be quite regular: company names can be used for their management or their products, country names can be used for associated sports teams.", "labels": [], "entities": []}, {"text": "Following from this, the currently prevalent set-up for metonymy resolution -as in the SemEval 2007 task -provides a manually compiled list of frequent readings or metonymic patterns such as organization-for-product for prespecified semantic classes (such as organizations) as well as annotated examples for these patterns so that systems can then treat metonymy resolution as a (supervised) word sense disambiguation task.", "labels": [], "entities": [{"text": "metonymy resolution", "start_pos": 56, "end_pos": 75, "type": "TASK", "confidence": 0.8306346833705902}, {"text": "SemEval 2007 task", "start_pos": 87, "end_pos": 104, "type": "TASK", "confidence": 0.692440946896871}, {"text": "metonymy resolution", "start_pos": 354, "end_pos": 373, "type": "TASK", "confidence": 0.7265377789735794}, {"text": "word sense disambiguation task", "start_pos": 392, "end_pos": 422, "type": "TASK", "confidence": 0.7537694871425629}]}, {"text": "However, this approach needs novel, manual provision of readings as well as annotated examples for each new semantic class.", "labels": [], "entities": []}, {"text": "In contrast, we will see readings as relations between the potentially metonymic word (PMW) and other concepts in a large concept network, a priori allowing all possible relations as readings.", "labels": [], "entities": []}, {"text": "We base this approach on the observation that metonymic words stand in for concepts that they are related with -e.g. the part for the whole, the company for the product.", "labels": [], "entities": []}, {"text": "These readings are obtained on the fly and are therefore independent of manually provided, preclassified interpretations or semantic classes, leading eventually to the possibility of unsupervised metonymy resolution.", "labels": [], "entities": [{"text": "metonymy resolution", "start_pos": 196, "end_pos": 215, "type": "TASK", "confidence": 0.7601653337478638}]}, {"text": "We achieve this by first linking a PMW to an article in Wikipedia.", "labels": [], "entities": []}, {"text": "Then we extract from a large concept network derived from Wikipedia the relations surrounding the PMW.", "labels": [], "entities": [{"text": "PMW", "start_pos": 98, "end_pos": 101, "type": "DATASET", "confidence": 0.7939058542251587}]}, {"text": "As there will be (many) more than one such relation, these need to be ranked or scored.", "labels": [], "entities": []}, {"text": "We achieve this in a probabilistic framework where we condition the probability of a relation on the context of the PMW.", "labels": [], "entities": [{"text": "PMW", "start_pos": 116, "end_pos": 119, "type": "DATASET", "confidence": 0.8733943104743958}]}, {"text": "This ranking showcases our second major innovation in that the flexibility of our framework allows us to incorporate a wider context than inmost prior approaches.", "labels": [], "entities": []}, {"text": "Let us consider the indications for metonymic readings and its interpretation in Example 1, on the one hand, and Example 2, on the other hand.", "labels": [], "entities": [{"text": "Example", "start_pos": 81, "end_pos": 88, "type": "DATASET", "confidence": 0.887210488319397}]}, {"text": "In Example 1, the grammatical relation to the verb defeat and the verb's selectional preferences indicate the metonymy.", "labels": [], "entities": []}, {"text": "We will call all such grammatically related words and the grammatical relations the local context of the PMW.", "labels": [], "entities": [{"text": "PMW", "start_pos": 105, "end_pos": 108, "type": "DATASET", "confidence": 0.9170030355453491}]}, {"text": "Such types of local context have been used by most prior approaches, among others).", "labels": [], "entities": []}, {"text": "However, Example 2 shows that the local context can be ambiguous or often weak, such as the verb to be.", "labels": [], "entities": []}, {"text": "In these examples, the wider context (database, keyword) is a better indication fora metonymy but has not been satisfactorily integrated in prior approaches (see Section 2).", "labels": [], "entities": []}, {"text": "We here call all words surrounding the PMW but not grammatically related to it the global context.", "labels": [], "entities": [{"text": "PMW", "start_pos": 39, "end_pos": 42, "type": "DATASET", "confidence": 0.866008996963501}]}, {"text": "In our approach we integrate both the local and the global context in our probabilistic framework.", "labels": [], "entities": []}, {"text": "For the local context, we compute the selectional preferences for the words related to the PMW from a corpus of English Wikipedia articles and generalize them in the Wikipedia concept network, thus (automatically) providing a set of abstractions -general concepts in the network that capture the semantic classes required by the local context.", "labels": [], "entities": []}, {"text": "In the next step we compute probabilities of the global context surrounding the PMWs under each (locally required) abstraction, and combine this with the selectional preferences of the grammatically related words.", "labels": [], "entities": []}, {"text": "That we can integrate local and global context in one probabilistic but also knowledge-based framework is possible because we combine two descriptions of meaning -ontological and distributional -by exploiting different sources of information in Wikipedia (category-article hierarchy and article texts).", "labels": [], "entities": []}, {"text": "We compute the probabilities of the relations (= readings) between the concept corresponding to the PMW and its directly related concepts.", "labels": [], "entities": []}, {"text": "These can be used either (i) as additional features in a supervised approach or (ii) directly for unsupervised resolution.", "labels": [], "entities": []}, {"text": "We do both in this paper and show that (i) the supervised approach using both local and global context can outperform one using just local context, dependent on the semantic class studied and (ii) that an unsupervised approach -although lower than the supervised one -outperforms the supervised most frequent reading baseline and performs close to a standard supervised model with the basic set of lexico-syntactic features).", "labels": [], "entities": []}], "datasetContent": [{"text": "The computed probabilities for each conceptual relation (= potential readings) of the PMW in the concept network can be used as features in a supervised framework or directly as an unsupervised prediction, returning the most likely conceptual relation given the context as the required reading.", "labels": [], "entities": []}, {"text": "Although the latter is our ultimate goal, to allow comparison with related work from the metonymy resolution task (Task 8) at SemEval 2007, we first investigate the supervised set-up.", "labels": [], "entities": [{"text": "metonymy resolution task (Task 8) at SemEval 2007", "start_pos": 89, "end_pos": 138, "type": "TASK", "confidence": 0.7775935351848602}]}, {"text": "We then simulate the unsupervised setting in Section 4.3.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Statistics for the Task 8 data", "labels": [], "entities": [{"text": "Task 8 data", "start_pos": 29, "end_pos": 40, "type": "DATASET", "confidence": 0.8007660110791525}]}, {"text": " Table 4: Fine-grained results for each classification task  for countries (F-scores)", "labels": [], "entities": [{"text": "F-scores", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9747538566589355}]}, {"text": " Table 5: Fine-grained results for each classification task  for companies (F-scores)", "labels": [], "entities": [{"text": "F-scores", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9737437963485718}]}]}