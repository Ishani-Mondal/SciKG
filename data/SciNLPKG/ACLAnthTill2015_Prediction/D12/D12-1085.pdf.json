{"title": [{"text": "Generating Non-Projective Word Order in Statistical Linearization", "labels": [], "entities": [{"text": "Generating Non-Projective Word Order", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.6953072547912598}, {"text": "Statistical Linearization", "start_pos": 40, "end_pos": 65, "type": "TASK", "confidence": 0.7336415946483612}]}], "abstractContent": [{"text": "We propose a technique to generate non-projective word orders in an efficient statistical linearization system.", "labels": [], "entities": []}, {"text": "Our approach predicts liftings of edges in an unordered syntactic tree by means of a classifier, and uses a projective algorithm for tree linearization.", "labels": [], "entities": [{"text": "predicts liftings of edges", "start_pos": 13, "end_pos": 39, "type": "TASK", "confidence": 0.8124505579471588}]}, {"text": "We obtain statistically significant improvements on six typologically different languages: En-glish, German, Dutch, Danish, Hungarian, and Czech.", "labels": [], "entities": []}], "introductionContent": [{"text": "There is a growing interest in language-independent data-driven approaches to natural language generation (NLG).", "labels": [], "entities": [{"text": "natural language generation (NLG)", "start_pos": 78, "end_pos": 111, "type": "TASK", "confidence": 0.8190482556819916}]}, {"text": "An important subtask of NLG is surface realization, which was recently addressed in the 2011 Shared Task on Surface Realisation ).", "labels": [], "entities": [{"text": "surface realization", "start_pos": 31, "end_pos": 50, "type": "TASK", "confidence": 0.7801849544048309}, {"text": "Shared Task on Surface Realisation", "start_pos": 93, "end_pos": 127, "type": "TASK", "confidence": 0.572251808643341}]}, {"text": "Here, the input is a linguistic representation, such as a syntactic dependency tree lacking all precedence information, and the task is to determine a natural, coherent linearization of the words.", "labels": [], "entities": []}, {"text": "The standard data-driven approach is to traverse the dependency tree deciding locally at each node on the relative order of the head and its children.", "labels": [], "entities": []}, {"text": "The shared task results have proven this approach to be both effective and efficient when applied to English.", "labels": [], "entities": []}, {"text": "It is what federal support should try to achieve However, the approach can only generate projective word orders (which can be drawn without any crossing edges).", "labels": [], "entities": []}, {"text": "shows a nonprojective word order: the edge connecting the extracted wh-pronoun with its head crosses another edge.", "labels": [], "entities": []}, {"text": "Once what has been ordered relative to achieve, there are no ways of inserting intervening material.", "labels": [], "entities": []}, {"text": "In this case, only ungrammatical linearizations can be produced from the unordered input tree: Although rather infrequent in English, nonprojective word orders are quite common in languages with a less restrictive word order.", "labels": [], "entities": []}, {"text": "In these languages, it is often possible to find a grammatically correct projective linearization fora given input tree, but discourse coherence, information structure, and stylistic factors will often make speakers prefer some non-projective word order.", "labels": [], "entities": []}, {"text": "1 shows an object fronting example from German where the edge between the subject and the finite verb crosses the edge between the object and the full verb.", "labels": [], "entities": []}, {"text": "Various other constructions, such as extraposition of (relative) clauses or scrambling, can lead to non-projectivity.", "labels": [], "entities": []}, {"text": "In languages where word order is driven to an even larger degree by information structure, such as Czech and Hungarian, non-projectivity can likewise result from various ordering decisions.", "labels": [], "entities": []}, {"text": "These phenomena have been studied extensively in the linguistic literature, and for certain languages, work on rule-based generation has addressed certain aspects of the problem.", "labels": [], "entities": [{"text": "rule-based generation", "start_pos": 111, "end_pos": 132, "type": "TASK", "confidence": 0.7249838560819626}]}, {"text": "In this paper, we aim fora general data-driven approach that can deal with various causes for nonprojectivity and will work for typologically different languages.", "labels": [], "entities": []}, {"text": "Our technique is inspired by work in data-driven multilingual parsing, where non-projectivity has received considerable attention.", "labels": [], "entities": [{"text": "multilingual parsing", "start_pos": 49, "end_pos": 69, "type": "TASK", "confidence": 0.6674589961767197}]}, {"text": "In pseudo-projective parsing (), the parsing algorithm is restricted to projective structures, but the issue is side-stepped by converting non-projective structures to projective ones prior to training and application, and then restoring the original structure afterwards.", "labels": [], "entities": [{"text": "pseudo-projective parsing", "start_pos": 3, "end_pos": 28, "type": "TASK", "confidence": 0.6276946067810059}]}, {"text": "Similarly, we split the linearization task in two stages: initially, the input tree is modified by lifting certain edges in such away that new orderings become possible even under a projectivity constraint; the second stage is the original, projective linearization step.", "labels": [], "entities": []}, {"text": "In parsing, projectivization is a deterministic process that lifts edges based on the linear order of a sentence.", "labels": [], "entities": []}, {"text": "Since the linear order is exactly what we aim to produce, this deterministic conversion cannot be applied before linearization.", "labels": [], "entities": []}, {"text": "Therefore, we use a statistical classifier as our initial lifting component.", "labels": [], "entities": []}, {"text": "This classifier has to be trained on suitable data, and it is an empirical question whether the projective linearizer can take advantage of this preceding lifting step.", "labels": [], "entities": []}, {"text": "We present experiments on six languages with varying degrees of non-projective structures: English, German, Dutch, Danish, Czech and Hungarian, which exhibit substantially different word order properties.", "labels": [], "entities": []}, {"text": "Our approach achieves significant improvements on all six languages.", "labels": [], "entities": []}, {"text": "On German, we also report results of a pilot human evaluation.", "labels": [], "entities": [{"text": "German", "start_pos": 3, "end_pos": 9, "type": "DATASET", "confidence": 0.9835814237594604}]}], "datasetContent": [{"text": "We conduct experiments on six European languages with varying degrees of word order restrictions: While English word order is very restrictive, Czech and Hungarian exhibit few word order constraints.", "labels": [], "entities": []}, {"text": "Danish, Dutch, and German (so-called V2, i. e. verb-second, languages) show a relatively free word order that is however more restrictive than in Hungarian or Czech.", "labels": [], "entities": []}, {"text": "The English and the Czech data are from the CoNLL 2009 Shared Task data sets).", "labels": [], "entities": [{"text": "CoNLL 2009 Shared Task data sets", "start_pos": 44, "end_pos": 76, "type": "DATASET", "confidence": 0.9596489369869232}]}, {"text": "The Danish and the Dutch data are from the CoNLL 2006 Shared Task data sets).", "labels": [], "entities": [{"text": "CoNLL 2006 Shared Task data sets", "start_pos": 43, "end_pos": 75, "type": "DATASET", "confidence": 0.9597611129283905}]}, {"text": "For Hungarian, we use the Hungarian Dependency Treebank (, and for German, we use a dependency conversion by shows the sizes of the training corpora and the percentage of non-projective sentences and edges in the data.", "labels": [], "entities": [{"text": "Hungarian Dependency Treebank", "start_pos": 26, "end_pos": 55, "type": "DATASET", "confidence": 0.8526190320650736}]}, {"text": "Note that the data sets for Danish and Dutch are quite small.", "labels": [], "entities": []}, {"text": "English has the least percentage of non-projective edges.", "labels": [], "entities": []}, {"text": "Czech, German, and Dutch show the highest percentage of nonprojective edges.", "labels": [], "entities": []}, {"text": "The last column shows the percentage of non-projective edges that can be made projective by at most 3 lifting steps.", "labels": [], "entities": []}, {"text": "We have carried out a pilot human evaluation on the German data in order to see whether human judges prefer word orders obtained from the lifting-based linearizer.", "labels": [], "entities": [{"text": "German data", "start_pos": 52, "end_pos": 63, "type": "DATASET", "confidence": 0.93740513920784}]}, {"text": "In particular, we wanted to check whether the lifting-based linearizer produces more natural word orders for sentences that had a non-projective tree in the corpus, and maybe less natural word orders on originally projective sentences.", "labels": [], "entities": []}, {"text": "Therefore, we divided the evaluated items into originally projective and non-projective sentences.", "labels": [], "entities": []}, {"text": "We asked four annotators to judge 60 sentence pairs comparing the lifting-based against the nonlifted linearizer using the toolkit by.", "labels": [], "entities": []}, {"text": "All annotators are students, two of them have a background in linguistics.", "labels": [], "entities": []}, {"text": "The items were randomly sampled from the subset of the development set containing those sentences where the linearizers produced different surface realizations.", "labels": [], "entities": []}, {"text": "The items are subdivided into 30 originally projective and 30 originally non-projective sentences.", "labels": [], "entities": []}, {"text": "For each item, we presented the original context sentence from the corpus and the pair of automatically produced linearizations for the current sentence.", "labels": [], "entities": []}, {"text": "The annotators had to decide on two criteria: (i) which sentence do they prefer?", "labels": [], "entities": []}, {"text": "(ii) how fluent is that sentence?", "labels": [], "entities": []}, {"text": "In both cases, we used continuous sliders as rating tools, since humans seem to prefer them ( ).", "labels": [], "entities": []}, {"text": "For the first criterion, the slider positions were mapped to values from -50 (preference for left sentence) to 50 (preference for right sentence).", "labels": [], "entities": []}, {"text": "If the slider position is zero, both sentences are equally preferred.", "labels": [], "entities": []}, {"text": "For the second criterion, the slider positions were mapped to values from 0 (absolutely broken sentence) to 100 (perfectly fluent sentence).: Results from human evaluation.", "labels": [], "entities": []}, {"text": "presents the results averaged overall sentences, as well as for the subsets of non-projective and projective sentences.", "labels": [], "entities": []}, {"text": "We report the percentage of items where the judges selected both, the lifted, or non-lifted sentence, alongside with the average fluency score (0-100) and preference strength (0-50).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Size of training sets, percentage of non- projective (np) sentences and edges, percentage of np  edges covered by 3 lifting steps.", "labels": [], "entities": []}, {"text": " Table 4: Precision, recall, F-measure and perfect projec- tivization results for the lifting classifier.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9975027441978455}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9991857409477234}, {"text": "F-measure", "start_pos": 29, "end_pos": 38, "type": "METRIC", "confidence": 0.9968631267547607}, {"text": "perfect projec- tivization", "start_pos": 43, "end_pos": 69, "type": "METRIC", "confidence": 0.8440524488687515}]}, {"text": " Table 5: Performance of linearizers using different lift- ings, Exact lif t is the exact match for words with an in- coming lifted edge, N lif t is the total number of lifted  edges.", "labels": [], "entities": []}, {"text": " Table 6: Results on the development set of the 2011  Shared Task on Surface Realisation data, (the test set was  not officially released).", "labels": [], "entities": [{"text": "2011  Shared Task on Surface Realisation data", "start_pos": 48, "end_pos": 93, "type": "DATASET", "confidence": 0.6899452124323163}]}, {"text": " Table 7: Results from human evaluation.", "labels": [], "entities": []}]}