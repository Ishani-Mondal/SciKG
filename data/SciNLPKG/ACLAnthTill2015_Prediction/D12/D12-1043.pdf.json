{"title": [{"text": "An \"AI readability\" formula for French as a foreign language", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper present anew readability formula for French as a foreign language (FFL), which relies on 46 textual features representative of the lexical, syntactic, and semantic levels as well as some of the specificities of the FFL context.", "labels": [], "entities": [{"text": "French as a foreign language (FFL)", "start_pos": 48, "end_pos": 82, "type": "TASK", "confidence": 0.6429221108555794}]}, {"text": "We report comparisons between several techniques for feature selection and various learning algorithms.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 53, "end_pos": 70, "type": "TASK", "confidence": 0.7531594336032867}]}, {"text": "Our best model, based on support vector machines (SVM), significantly outperforms previous FFL formulas.", "labels": [], "entities": []}, {"text": "We also found that semantic features behave poorly in our case, in contrast with some previous readability studies on English as a first language.", "labels": [], "entities": []}], "introductionContent": [{"text": "Whether in a first language (L1) or a second and foreign language (L2), learning to read has been and remains one of the major concerns of education.", "labels": [], "entities": []}, {"text": "When a teacher wants to improve his/her students' reading skills, he/she uses reading exercises, whether there are guided or independent.", "labels": [], "entities": []}, {"text": "For this practice to be efficient, it is necessary that the texts suit the level of students (O').", "labels": [], "entities": [{"text": "O')", "start_pos": 94, "end_pos": 97, "type": "METRIC", "confidence": 0.9823262393474579}]}, {"text": "This condition is sometimes difficult to meet for teachers wishing to get off the beaten tracks by not using texts from levelled textbooks or readers.", "labels": [], "entities": []}, {"text": "In this context, readability formulas have long been used to help teachers faster select texts for their students.", "labels": [], "entities": []}, {"text": "These formulas are reproducible methods that aim at matching readers and texts relative to their reading difficulty level.", "labels": [], "entities": []}, {"text": "The and formulas are probably the best-known examples of those.", "labels": [], "entities": []}, {"text": "They are typical of classic formulas, the first major methodological paradigm developed in the field during the 40's and 50's.", "labels": [], "entities": []}, {"text": "They were kept as parsimonious as possible, using linear regression to combined two, or sometimes, three surface features, such as word mean length, sentence mean length, or proportion of outof-simple-vocabulary words.", "labels": [], "entities": [{"text": "sentence mean length", "start_pos": 149, "end_pos": 169, "type": "METRIC", "confidence": 0.6745561063289642}]}, {"text": "Later, some scholars ( argued that the classic formulas suffer from several shortcomings.", "labels": [], "entities": []}, {"text": "These formulas only take into account superficial features, ignoring other important aspects contributing to text difficulty, such as coherence, content density, inference load, etc.", "labels": [], "entities": []}, {"text": "They also omit the interactive aspect of the reading process.", "labels": [], "entities": []}, {"text": "In the 80's, a second paradigm, inspired by structuro-cognitivist theories, intended to overcome these issues.", "labels": [], "entities": []}, {"text": "It focused on higher textual dimensions, such as inference load, density of concepts, or macrostructure.", "labels": [], "entities": []}, {"text": "However, these attempts did not achieve better results than the classic approach, even though they used more principled and more complex features.", "labels": [], "entities": []}, {"text": "Recently, a third paradigm, referred to as the \"AI readability\" by Fran\u00e7ois (2011a), has emerged in the field.", "labels": [], "entities": []}, {"text": "Studies that are part of this current share three key features: the use of a large number of texts assessed by experts (coming from textbooks, simplified newspapers or web resources) as training data ; the use of NPL-enable features able to capture a wider range of readability factors, and the combination of those features through a machine learning algorithm.", "labels": [], "entities": []}, {"text": "Since the work of, this paradigm have spawn several studies for English.", "labels": [], "entities": []}, {"text": "However, for French, the field is far from being so thriving.", "labels": [], "entities": [{"text": "French", "start_pos": 13, "end_pos": 19, "type": "TASK", "confidence": 0.8401990532875061}]}, {"text": "To our knowledge, only two \"AI readability\" have been designed so far for French L1 and only one for French as a foreign language (FFL) (see Section 2).", "labels": [], "entities": [{"text": "French L1", "start_pos": 74, "end_pos": 83, "type": "DATASET", "confidence": 0.9000261723995209}, {"text": "French as a foreign language (FFL)", "start_pos": 101, "end_pos": 135, "type": "TASK", "confidence": 0.5337062887847424}]}, {"text": "This paper reports some experiments aimed at designing a more efficient readability model for FFL.", "labels": [], "entities": [{"text": "FFL", "start_pos": 94, "end_pos": 97, "type": "TASK", "confidence": 0.9558853507041931}]}, {"text": "In Section 2, it is further argue why anew formula was necessary for FFL.", "labels": [], "entities": [{"text": "FFL", "start_pos": 69, "end_pos": 72, "type": "TASK", "confidence": 0.9137585759162903}]}, {"text": "Section 3 covers the various methodological steps required to devise the model, whose results are reported in Section 4.", "labels": [], "entities": []}, {"text": "Finally, Section 5 discusses some interesting insights gained by this work.", "labels": [], "entities": []}], "datasetContent": [{"text": "The next step then consisted in training logistic and SVM models for each of the above subsets.", "labels": [], "entities": []}, {"text": "Their performances, reported in, were assessed using five measures: the multiple correlation ratio (R), the accuracy (acc), the adjacent accuracy 7 (adjacc), the root mean square error (rmse) and the mean absolute error (mae).", "labels": [], "entities": [{"text": "multiple correlation ratio (R)", "start_pos": 72, "end_pos": 102, "type": "METRIC", "confidence": 0.8642479677995046}, {"text": "accuracy (acc)", "start_pos": 108, "end_pos": 122, "type": "METRIC", "confidence": 0.9439077526330948}, {"text": "adjacent accuracy 7 (adjacc)", "start_pos": 128, "end_pos": 156, "type": "METRIC", "confidence": 0.878689040740331}, {"text": "root mean square error (rmse)", "start_pos": 162, "end_pos": 191, "type": "METRIC", "confidence": 0.8519785233906337}, {"text": "mean absolute error (mae)", "start_pos": 200, "end_pos": 225, "type": "METRIC", "confidence": 0.9042907257874807}]}, {"text": "It should be noted that each of these measures was estimated through a tenfold cross-validation procedure, which allowed us to compare performances of different models with a Ttest.", "labels": [], "entities": [{"text": "Ttest", "start_pos": 175, "end_pos": 180, "type": "METRIC", "confidence": 0.9754285216331482}]}, {"text": "The comparison between the models was performed in two steps.", "labels": [], "entities": []}, {"text": "First, we computed T-tests based on adjacc to compare the models based on a same set of features (either Exp1, Exp2, or Auto).", "labels": [], "entities": []}, {"text": "This allowed us to pickup the best classifier for each set.", "labels": [], "entities": []}, {"text": "Ina second step, these three best models were compared the same way, which resulted in the selection of the very best classifier.", "labels": [], "entities": []}, {"text": "The decision of adopting the adjacent accuracy as a criterion instead of the accuracy was motivated by our conviction that our system should rather avoid serious errors (i.e. larger than one level) than be more accurate, while sometimes generating terrible mistakes.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.8855077624320984}, {"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.999446451663971}]}, {"text": "However, it appeared that both metrics were mostly consistent.", "labels": [], "entities": []}, {"text": "The performance of the different models are displayed in.", "labels": [], "entities": []}, {"text": "It is first interesting to note that the baseline (based on SVM) already gives interesting results.", "labels": [], "entities": []}, {"text": "It reaches a classification accuracy of 34%, which is about twice the random.", "labels": [], "entities": [{"text": "classification", "start_pos": 13, "end_pos": 27, "type": "TASK", "confidence": 0.8034537434577942}, {"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9348049759864807}]}, {"text": "As regards the first model (Exp1), based on RLM and including four predictors, it outperforms the baseline by 5%, a difference close to significance (t(9) = 1.77; p = 0.055).", "labels": [], "entities": [{"text": "RLM", "start_pos": 44, "end_pos": 47, "type": "METRIC", "confidence": 0.609827995300293}, {"text": "significance", "start_pos": 136, "end_pos": 148, "type": "METRIC", "confidence": 0.9681873917579651}]}, {"text": "Therefore, combining variables from several families seems to improve performance over the \"classic\" baseline, limited to lexico-syntactic features.", "labels": [], "entities": []}, {"text": "This finding is reinforced by the SVM model from Exp2, which includes eight features.", "labels": [], "entities": [{"text": "Exp2", "start_pos": 49, "end_pos": 53, "type": "DATASET", "confidence": 0.8892467617988586}]}, {"text": "It performs significantly better than the baseline (t(9) =: Evaluation measures for the best difficulty model from each feature set (Exp1, Exp2 and Auto), along with values fora random classification, and the \"classic\" baseline. 2.36; p = 0.02), with an accuracy gain of 7%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 254, "end_pos": 262, "type": "METRIC", "confidence": 0.9994459748268127}]}, {"text": "However, to that point, it was not clear whether this superiority was indeed a consequence of maximizing the kind of information brought to the model or merely the result of the increased number of predictor.", "labels": [], "entities": []}, {"text": "We thus performed another experiment to address this issue.", "labels": [], "entities": []}, {"text": "The model Exp1 was compared with Auto-OLR, the best ordinal logistic model obtained through the stepwise selection (see), and previously discarded as a result of the Ttest comparisons.", "labels": [], "entities": [{"text": "Exp1", "start_pos": 10, "end_pos": 14, "type": "DATASET", "confidence": 0.6752740740776062}]}, {"text": "Like Exp1, it also contains four predictors, but they are all lexical or syntactic features.", "labels": [], "entities": [{"text": "Exp1", "start_pos": 5, "end_pos": 9, "type": "DATASET", "confidence": 0.9007565379142761}]}, {"text": "Therefore, this model does not maximize the type of information.", "labels": [], "entities": []}, {"text": "Surprisingly, we observed that Auto-OLR obtained similar and even slightly better performance than Exp1 (+2% for both acc and adjacc).", "labels": [], "entities": [{"text": "Exp1", "start_pos": 99, "end_pos": 103, "type": "DATASET", "confidence": 0.7564563751220703}]}, {"text": "Thus, the claim that maximizing the source of information should yield better models did not stand on our data.", "labels": [], "entities": []}, {"text": "Finally, our best performing model was based on the Auto feature set and SVM.", "labels": [], "entities": [{"text": "Auto feature set", "start_pos": 52, "end_pos": 68, "type": "DATASET", "confidence": 0.9161121646563212}]}, {"text": "Its accuracy was increased by 8% in comparison with the Exp2 model, which is clearly a significant improvement (t(9) = 2.61; p = 0.01), and outperformed the baseline by 15%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9997186064720154}, {"text": "Exp2", "start_pos": 56, "end_pos": 60, "type": "DATASET", "confidence": 0.9476099610328674}]}, {"text": "As mentioned previously, this model includes 46 features coming from our four families.", "labels": [], "entities": []}, {"text": "It is worth mentioning that the quality of the predictions is not the same across the levels, as shown in Table 5.", "labels": [], "entities": []}, {"text": "They are more accurate for classes situated at both ends of the difficulty scale, namely A1, C1 and C2.", "labels": [], "entities": []}, {"text": "For A1, this is explained because texts for beginners are more typical, having very short sentences and simple words.", "labels": [], "entities": []}, {"text": "However, the case of C1 and C2 classes is more surprising and might be due to some specificities of the learning algorithm.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Spearman correlation for some predictors in our set with difficulty. A positive correlation means that the  difficulty of texts increases with the value of the predictor. Signification levels are the following 1 : < 0.05; 2 : < 0.01;  and 3 : < 0.001.", "labels": [], "entities": []}, {"text": " Table 3: Results from the two selection process: expert and automatic. Description of the features can be found in  Table 2.", "labels": [], "entities": []}, {"text": " Table 4: Evaluation measures for the best difficulty model from each feature set (Exp1, Exp2 and Auto), along with  values for a random classification, and the \"classic\" baseline.", "labels": [], "entities": []}, {"text": " Table 6: Accuracy and adjacent accuracy (in percentage)  for models either using only one family of predictors, or  including all 46 features except those of one family.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9991015195846558}, {"text": "adjacent", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9732016324996948}, {"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.8163860440254211}]}]}