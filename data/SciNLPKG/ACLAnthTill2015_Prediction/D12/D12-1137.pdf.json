{"title": [{"text": "Supervised Text-based Geolocation Using Language Models on an Adaptive Grid", "labels": [], "entities": []}], "abstractContent": [{"text": "The geographical properties of words have recently begun to be exploited for geolocating documents based solely on their text, often in the context of social media and online content.", "labels": [], "entities": []}, {"text": "One common approach for geolocating texts is rooted in information retrieval.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 55, "end_pos": 76, "type": "TASK", "confidence": 0.7310312986373901}]}, {"text": "Given training documents labeled with latitude/longitude coordinates , a grid is overlaid on the Earth and pseudo-documents constructed by concatenat-ing the documents within a given grid cell; then a location fora test document is chosen based on the most similar pseudo-document.", "labels": [], "entities": []}, {"text": "Uniform grids are normally used, but they are sensitive to the dispersion of documents over the earth.", "labels": [], "entities": []}, {"text": "We define an alternative grid construction using k-d trees that more robustly adapts to data, especially with larger training sets.", "labels": [], "entities": []}, {"text": "We also provide a better way of choosing the locations for pseudo-documents.", "labels": [], "entities": []}, {"text": "We evaluate these strategies on existing Wikipedia and Twitter corpora, as well as anew, larger Twit-ter corpus.", "labels": [], "entities": [{"text": "Twit-ter corpus", "start_pos": 96, "end_pos": 111, "type": "DATASET", "confidence": 0.911381721496582}]}, {"text": "The adaptive grid achieves competitive results with a uniform grid on small training sets and outperforms it on the large Twitter corpus.", "labels": [], "entities": []}, {"text": "The two grid constructions can also be combined to produce consistently strong results across all training sets.", "labels": [], "entities": []}], "introductionContent": [{"text": "The growth of the Internet in recent years has provided unparalleled access to informational resources.", "labels": [], "entities": []}, {"text": "It is often desirable to extract summary metadata from such resources, such as the date of writing or the location of the author -yet only a small portion of available documents are explicitly annotated in this fashion.", "labels": [], "entities": []}, {"text": "With sufficient training data, however, it is often possible to infer this information directly from a document's text.", "labels": [], "entities": []}, {"text": "For example, clues to the geographic location of a document may come from a variety of word features, e.g. toponyms (Toronto), geographic features (mountain), culturally local features (hockey), and stylistic or dialectical differences (cool vs. kewl vs. kool).", "labels": [], "entities": []}, {"text": "This article focuses on text-based document geolocation, the prediction of the latitude and longitude of a document.", "labels": [], "entities": []}, {"text": "Among the uses for this are region-based search engines; tracing the sources of historical documents; location attribution while summarizing large documents; tailoring of ads while browsing; phishing detection when a user account is accessed from an unexpected location; and \"activist mapping\", as in the Ushahidi project.", "labels": [], "entities": [{"text": "summarizing large documents", "start_pos": 129, "end_pos": 156, "type": "TASK", "confidence": 0.7944480975468954}, {"text": "phishing detection when a user account is accessed from an unexpected location", "start_pos": 191, "end_pos": 269, "type": "TASK", "confidence": 0.7874835580587387}]}, {"text": "Geolocation has also been used as a feature in automatic news story identification systems (.", "labels": [], "entities": [{"text": "automatic news story identification", "start_pos": 47, "end_pos": 82, "type": "TASK", "confidence": 0.6165474951267242}]}, {"text": "One of the first works on document geolocation is, who attempt to automatically determine the geographic scope of web pages.", "labels": [], "entities": []}, {"text": "They focus on named locations, e.g. cities and states, found in gazetteers.", "labels": [], "entities": []}, {"text": "Locations are predicted based on toponym detection and heuristic resolution algorithms.", "labels": [], "entities": [{"text": "toponym detection", "start_pos": 33, "end_pos": 50, "type": "TASK", "confidence": 0.7271963655948639}]}, {"text": "A related, recent effort is, who geolocate Twitter users by resolving their profile locations against a gazetteer of U.S. cities and training a classifier to identify geographically local words.", "labels": [], "entities": []}, {"text": "An alternative to using a discrete set of locations from a gazetteer is to use information retrieval (IR) techniques on a set of geolocated training documents.", "labels": [], "entities": [{"text": "information retrieval (IR)", "start_pos": 79, "end_pos": 105, "type": "TASK", "confidence": 0.8032040119171142}]}, {"text": "A new test document is compared with each training document and a location chosen based on the location(s) of the most similar training document(s).", "labels": [], "entities": []}, {"text": "For image geolocation, Chen and Grauman (2011) perform mean-shift clustering over training images to discretize locations, then estimate a test image's location with weighted voting from the k most similar documents.", "labels": [], "entities": []}, {"text": "For text, both and use a similar approach, but compute document similarity based on language models rather than image features.", "labels": [], "entities": []}, {"text": "Additionally, they group documents via a uniform geodesic grid rather than a clustered set of locations.", "labels": [], "entities": []}, {"text": "This reduces the number of similarity computations and removes the need to perform location clustering altogether, but introduces anew parameter controlling the granularity of the grid.", "labels": [], "entities": []}, {"text": "predict the locations of tweets and users by comparing text in tweets to language models associated with zip codes and broader geopolitical enclosures.", "labels": [], "entities": []}, {"text": "discretize by simply clustering data points within a small distance threshold, but only perform geolocation within fixed city limits.", "labels": [], "entities": []}, {"text": "While the above approaches discretize the continuous surface of the earth, predict locations based on Gaussian distributions over the earth's surface as part of a hierarchical Bayesian model.", "labels": [], "entities": []}, {"text": "This model has many advantages (e.g. the ability to compute a complete probability distribution over locations), but we suspect it will be difficult to scale up to the large document collections needed for high accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 211, "end_pos": 219, "type": "METRIC", "confidence": 0.9686117768287659}]}, {"text": "We build on the IR approach with grids while addressing some of the shortcomings of a uniform grid.", "labels": [], "entities": [{"text": "IR", "start_pos": 16, "end_pos": 18, "type": "TASK", "confidence": 0.9302113652229309}]}, {"text": "Uniform grids are problematic in that they ignore the geographic dispersion of documents and forgo the possibility of greater-granularity geographic resolution in document-rich areas.", "labels": [], "entities": []}, {"text": "Instead, we construct a grid using a k-d tree, which adapts to the size of the training set and the geographic dispersion of the documents it contains.", "labels": [], "entities": []}, {"text": "This can better benefit from more data, since it enables the training set to support more pseudo-documents when there is sufficient evidence to do so, while still ensuring that all pseudodocuments contain comparable amounts of data.", "labels": [], "entities": []}, {"text": "It also has the desirable property of generally requiring fewer active cells than a uniform grid, drastically reducing the computation time required to label a test document.", "labels": [], "entities": []}, {"text": "We show that consistently strong results, robust across both Wikipedia and Twitter datasets, are obtained from the union of the pseudo-documents from a uniform and adaptive grid.", "labels": [], "entities": [{"text": "Wikipedia and Twitter datasets", "start_pos": 61, "end_pos": 91, "type": "DATASET", "confidence": 0.722626082599163}]}, {"text": "In addition, a simple difference in the choice of location fora given grid cell -the centroid of the training documents in the cell, rather than the cell midpoint -results in across-the-board improvements.", "labels": [], "entities": []}, {"text": "We also construct and evaluate on a much larger dataset of geolocated tweets than has been used in previous papers, demonstrating the scalability and robustness of our methods and confirming the ability of the adaptive grid to more effectively use larger datasets.", "labels": [], "entities": []}], "datasetContent": [{"text": "We experiment with several configurations of grids and representative locations.", "labels": [], "entities": []}, {"text": "W&B refers to a uniform grid and geographiccenter location selection, UNIFCENTROID to a uniform grid with centroid location selection, KDCENTROID to a k-d tree grid with centroid location selection, and UNIFKDCENTROID to the union of pseudo-documents constructed by UNIFCENTROID and KDCENTROID.", "labels": [], "entities": [{"text": "W&B", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8492931723594666}]}, {"text": "We also provide two baselines, both of which are based on a uniform grid with centroid location selection.", "labels": [], "entities": []}, {"text": "RANDOM predicts a grid cell chosen at random uniformly; MOSTCOMMONCELL always predicts the grid cell containing the most training documents.", "labels": [], "entities": [{"text": "MOSTCOMMONCELL", "start_pos": 56, "end_pos": 70, "type": "METRIC", "confidence": 0.9129751324653625}]}, {"text": "Note that a most-common k-d leaf baseline does not make sense, as all k-d leaves contain approximately the same number of documents.", "labels": [], "entities": []}, {"text": "We use three metrics to measure geolocation performance.", "labels": [], "entities": []}, {"text": "The output of each experiment is a predicted coordinate for each test document.", "labels": [], "entities": []}, {"text": "For each prediction, we compute the error distance along the surface of the earth to the gold coordinate.", "labels": [], "entities": [{"text": "error distance", "start_pos": 36, "end_pos": 50, "type": "METRIC", "confidence": 0.9687959253787994}]}, {"text": "We report the mean and median of all such distances as in.", "labels": [], "entities": [{"text": "mean and median", "start_pos": 14, "end_pos": 29, "type": "METRIC", "confidence": 0.7488878269990286}]}, {"text": "We also report the fraction of error distances less than 161 km, corresponding to's measure of predictions within 100 miles of the true location.", "labels": [], "entities": []}, {"text": "This third measure can reveal differences between models not obvious from just mean and median.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance on the held-out test sets of GEOWIKI and GEOTEXT, comparing to the results of Wing and  Baldridge (2011) and Eisenstein et al. (2011).", "labels": [], "entities": [{"text": "GEOWIKI", "start_pos": 51, "end_pos": 58, "type": "DATASET", "confidence": 0.8468385934829712}, {"text": "GEOTEXT", "start_pos": 63, "end_pos": 70, "type": "DATASET", "confidence": 0.8478555083274841}]}, {"text": " Table 2: Performance on the held-out test set of UTGEO2011 for different configurations trained on  UTGEO2011-SMALL (comparable in size to GEOTEXT) and UTGEO2011-LARGE. The numbers given for W&B  were produced from their implementation, and correspond to uniform grid partitioning with locations from centers  rather than centroids.", "labels": [], "entities": [{"text": "UTGEO2011", "start_pos": 50, "end_pos": 59, "type": "DATASET", "confidence": 0.9279412031173706}, {"text": "UTGEO2011-SMALL", "start_pos": 101, "end_pos": 116, "type": "DATASET", "confidence": 0.9151318073272705}, {"text": "GEOTEXT", "start_pos": 140, "end_pos": 147, "type": "DATASET", "confidence": 0.8097197413444519}, {"text": "UTGEO2011-LARGE", "start_pos": 153, "end_pos": 168, "type": "DATASET", "confidence": 0.9281936883926392}]}, {"text": " Table 3: The 20 words with least average error  (km) in the UTGEO2011 development set, trained  on the UTGEO2011-SMALL training set, using the  KDCENTROID approach with our best parameters. Only  words that occur in at least 10 documents are shown.", "labels": [], "entities": [{"text": "least average error  (km)", "start_pos": 28, "end_pos": 53, "type": "METRIC", "confidence": 0.7899162967999777}, {"text": "UTGEO2011 development set", "start_pos": 61, "end_pos": 86, "type": "DATASET", "confidence": 0.9523543318112692}, {"text": "UTGEO2011-SMALL training set", "start_pos": 104, "end_pos": 132, "type": "DATASET", "confidence": 0.9818202058474222}]}, {"text": " Table 4: Top 20 words with the least average er- ror (km) in the GEOWIKI development set, using the  UNIFKDCENTROID approach with our best parameters.  Only words occurring in at least 10 documents are shown.", "labels": [], "entities": [{"text": "er- ror (km)", "start_pos": 46, "end_pos": 58, "type": "METRIC", "confidence": 0.9620613952477773}, {"text": "GEOWIKI development set", "start_pos": 66, "end_pos": 89, "type": "DATASET", "confidence": 0.9031612873077393}]}]}