{"title": [{"text": "Generative Goal-Driven User Simulation for Dialog Management", "labels": [], "entities": [{"text": "Generative Goal-Driven User Simulation", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.6043574139475822}, {"text": "Dialog Management", "start_pos": 43, "end_pos": 60, "type": "TASK", "confidence": 0.9122793972492218}]}], "abstractContent": [{"text": "User simulation is frequently used to train statistical dialog managers for task-oriented domains.", "labels": [], "entities": []}, {"text": "At present, goal-driven simula-tors (those that have a persistent notion of what they wish to achieve in the dialog) require some task-specific engineering, making them impossible to evaluate intrinsically.", "labels": [], "entities": []}, {"text": "Instead , they have been evaluated extrinsically by means of the dialog managers they are intended to train, leading to circularity of argument.", "labels": [], "entities": []}, {"text": "In this paper, we propose the first fully generative goal-driven simulator that is fully induced from data, without hand-crafting or goal annotation.", "labels": [], "entities": [{"text": "generative goal-driven simulator", "start_pos": 42, "end_pos": 74, "type": "TASK", "confidence": 0.8373678723971049}]}, {"text": "Our goals are latent, and take the form of topics in a topic model, clustering together semantically equivalent and phoneti-cally confusable strings, implicitly modelling synonymy and speech recognition noise.", "labels": [], "entities": []}, {"text": "We evaluate on two standard dialog resources, the Communicator and Let's Go datasets, and demonstrate that our model has substantially better fit to held out data than competing approaches.", "labels": [], "entities": []}, {"text": "We also show that features derived from our model allow significantly greater improvement over a baseline at distinguishing real from randomly permuted dialogs.", "labels": [], "entities": []}], "introductionContent": [{"text": "Automatically simulating user behaviour in humanmachine dialogs has become vital for training statistical dialog managers in task-oriented domains.", "labels": [], "entities": []}, {"text": "These managers are often trained with some variant of reinforcement learning, where optimal behaviour is sought or learnt through the exploration of the space of possible dialogs.", "labels": [], "entities": []}, {"text": "Although learning by interacting with human subjects is a possibility (, it has been argued that user simulation avoids the expensive, labour intensive, and error-prone experience of exposing real humans to fledgling dialog systems (.", "labels": [], "entities": []}, {"text": "Training effective dialog managers should benefit from exposure to properties exhibited by real users.", "labels": [], "entities": []}, {"text": "shows an example dialog in a domain such as we consider, where the objective is to simulate at the semantic level.", "labels": [], "entities": []}, {"text": "In such task oriented domains, the user has a goal (in this case, to book a flight from New York to Osaka), and the machine is tasked with fulfilling it.", "labels": [], "entities": []}, {"text": "Notice that the user is consistent with this goal throughout the dialog, in that they do not provide contradictory information (although an ASR error is present), but that every mention of their destination city uses a different string.", "labels": [], "entities": [{"text": "ASR error", "start_pos": 140, "end_pos": 149, "type": "METRIC", "confidence": 0.8616094887256622}]}, {"text": "This motivates our first desideratum: that simulation be consistent over the course of a dialog.", "labels": [], "entities": []}, {"text": "Furthermore, one can imagine users not always responding identically in identical situations: we thus additionally require variability.", "labels": [], "entities": []}, {"text": "In this paper we demonstrate a fully generative, latent variable probability model exhibiting both of these properties.", "labels": [], "entities": []}, {"text": "Thus far, consistent simulators have been partially deterministic and have required some handengineering.", "labels": [], "entities": []}, {"text": "As a result, it has only been possible to evaluate them extrinsically using dialog managers.", "labels": [], "entities": []}, {"text": "This is circular because we need simulators to train managers, but need managers to evaluate simulators.", "labels": [], "entities": []}, {"text": "The issue is that judgements of quality of each depend on the specifics of the other and that a proper evaluation of one depends on the correct functioning of the other.", "labels": [], "entities": []}, {"text": "Furthermore, there is little reason to assume that because a simulator performs well with a certain dialog manager, it would perform similarly: An example of a dialog in speech and its semantic equivalent.", "labels": [], "entities": []}, {"text": "M and U denote machine and user utterances respectively.", "labels": [], "entities": []}, {"text": "Note how a single speech utterance is split by the semantic parser into multiple logical utterances, each of which is broken down to an ACT, slot, and value.", "labels": [], "entities": [{"text": "ACT", "start_pos": 136, "end_pos": 139, "type": "METRIC", "confidence": 0.9848393797874451}]}, {"text": "We consider resources where gold standard transcriptions are not available; thus there will be speech recognition noise, e.g. Osaka rendered as Salt Lake City, something our model is able to capture.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 95, "end_pos": 113, "type": "TASK", "confidence": 0.7284705936908722}]}, {"text": "In contrast, a probabilistic formulation such as we propose allows us to evaluate our models intrinsically using standard machine learning metrics, and without reference to a specific manager, thus breaking the circularity, and guarding against such experimental biases.", "labels": [], "entities": []}, {"text": "We demonstrate the efficacy of our model on two tasks, and compare it to two other approaches.", "labels": [], "entities": []}, {"text": "Firstly we use a standard bigram model as conceived by and ; secondly we compare to a probabilistic goalbased simulator where the goals are string literals, as envisaged by and.", "labels": [], "entities": []}, {"text": "We demonstrate substantial improvement over these models in terms of predicting heldout data on two standard dialog resources: DARPA Communicator () and).", "labels": [], "entities": [{"text": "DARPA Communicator", "start_pos": 127, "end_pos": 145, "type": "DATASET", "confidence": 0.8750823140144348}]}], "datasetContent": [{"text": "No standardised metric of evaluation has been established for user simulators largely because they have been so inextricably linked to dialog managers.", "labels": [], "entities": []}, {"text": "The most popular method of evaluation relies on generating synthetic dialogs through the interaction of the user simulator with some dialog manager.", "labels": [], "entities": []}, {"text": "hand-craft a simple deterministic dialog manager based on finite automata, and compute similarity measures between these synthetically produced dialogs and real dialogs.", "labels": [], "entities": []}, {"text": "use a scoring function to evaluate synthetic dialogs using accuracy, precision, recall, and perplexity, while rely on dialog completion rates.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9993736147880554}, {"text": "precision", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.9983077049255371}, {"text": "recall", "start_pos": 80, "end_pos": 86, "type": "METRIC", "confidence": 0.9984506368637085}]}, {"text": "Williams (2008) use a Cramer-von Mises test, a hypothesis test to determine whether simulated and real dialogs are significantly different, while use Kullback Leibler Divergence between the empirical distributions over acts in real and simulated dialogs. and judge the consistency of human quality ranked synthetic dialogs generated by different simulators interacting with the IT-SPOKE dialog system.", "labels": [], "entities": []}, {"text": "use a simulator to train a statistical dialog manager and then evaluate the learned policy.", "labels": [], "entities": []}, {"text": "Because this only indirectly evaluates the simulator, it is inappropriate as a sole measure of quality.", "labels": [], "entities": []}, {"text": "There has been far less evaluation of simulators without a dialog manager.", "labels": [], "entities": []}, {"text": "The main approach is to compute precision and recall on an utterance basis, which is intended to measure the similarity between real user responses in the corpora and simulated user responses produced under similar circumstances ().", "labels": [], "entities": [{"text": "precision", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9985600113868713}, {"text": "recall", "start_pos": 46, "end_pos": 52, "type": "METRIC", "confidence": 0.9987756609916687}]}, {"text": "However, this is a harsh evaluation as it assumes a corrector \"best\" answer, and penalises valid variability in user behaviour.", "labels": [], "entities": []}, {"text": "Our experiments use two standard corpora, the first of which is DARPA Communicator (DC), a flight booking domain collected between 2000-2001 through the interaction of real users with 10 different systems ().", "labels": [], "entities": [{"text": "DARPA Communicator (DC)", "start_pos": 64, "end_pos": 87, "type": "DATASET", "confidence": 0.7212137460708619}]}, {"text": "Let's Go is a bus routing domain in Pittsburgh collected by having the general public interact with the CMU dialog system to find their way through the city.", "labels": [], "entities": []}, {"text": "The dialogs in both corpora are of mixed-initiative, having a free number of contiguous system and user responses.", "labels": [], "entities": []}, {"text": "We preprocessed the corpora, converting Communicator XML-tagged files and Let's Go system log files into sequences of ACT, slot, and value utterances.", "labels": [], "entities": []}, {"text": "Let's Go is a noisy corpus that contains far more speech recognition errors than Communicator.", "labels": [], "entities": []}, {"text": "In addition, users tend to be more flexible with their bus routes than they are with their flight destinations, and so values area lot more varied throughout the course of Let's Go dialogs than Communicator ones.", "labels": [], "entities": []}, {"text": "Furthermore, Let's Go semantic parses contain ambiguity not present in Communicator; the parser fails to distinguish departure from arrival places over 90% of the time, and instead assigns them a generic Single Place property.", "labels": [], "entities": [{"text": "Let's Go semantic parses", "start_pos": 13, "end_pos": 37, "type": "TASK", "confidence": 0.6763729929924012}]}, {"text": "Our current model assumes the decisions made by the semantic parser are correct.", "labels": [], "entities": []}, {"text": "In reality however, a better model would incorporate potential noise in the semantic parse in a joint model.", "labels": [], "entities": []}, {"text": "We defer this more complex treatment for future work.", "labels": [], "entities": []}, {"text": "Free model parameters are set by a simple search on the development set, where the objective is likelihood-for the bigram model the parameters are the interpolation weights, and for the topic model we search for the number of topics and smoothing constant for the topic distributions.", "labels": [], "entities": []}, {"text": "For Let's Go, since we can have multiple places provided in a single act, we treat each utterance as containing a set of values and build the count vector for the topic model as the union of these sets over the whole dialog.", "labels": [], "entities": []}, {"text": "The slots over which the topic model is defined for Communicator are dest city and orig city (this takes into account PROVIDE and REPROVIDE acts).", "labels": [], "entities": [{"text": "REPROVIDE", "start_pos": 130, "end_pos": 139, "type": "METRIC", "confidence": 0.9433486461639404}]}, {"text": "For Let's Go we derive the model over the three properties: single place, arrival place and departure place, as opposed to the less informative slot place.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: The mean per-utterance perplexity on heldout  data. DC-A is all acts for Communicator, while DC-P is  the calculated on PROVIDE acts alone (the acts on which  our model is designed to improve prediction).", "labels": [], "entities": []}, {"text": " Table 4: Examples of sampling from the topic goal model. Left: top 5 strings (with probabilities) sampled from topics  for three different dialogs d. Right: top 6 utterances (plus fraction of samples in 10,000) generated in response to the  machine utterance \"REQUEST INFO dest city\" and conditioned on the topic z dest city .", "labels": [], "entities": [{"text": "REQUEST", "start_pos": 261, "end_pos": 268, "type": "METRIC", "confidence": 0.987335205078125}, {"text": "INFO", "start_pos": 269, "end_pos": 273, "type": "METRIC", "confidence": 0.6959666013717651}]}]}