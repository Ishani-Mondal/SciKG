{"title": [{"text": "Joint Learning for Coreference Resolution with Markov Logic", "labels": [], "entities": [{"text": "Coreference Resolution", "start_pos": 19, "end_pos": 41, "type": "TASK", "confidence": 0.9604634046554565}]}], "abstractContent": [{"text": "Pairwise coreference resolution models must merge pairwise coreference decisions to generate final outputs.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 9, "end_pos": 31, "type": "TASK", "confidence": 0.8404980301856995}]}, {"text": "Traditional merging methods adopt different strategies such as the best-first method and enforcing the transitivity constraint , but most of these methods are used independently of the pairwise learning methods as an isolated inference procedure at the end.", "labels": [], "entities": []}, {"text": "We propose a joint learning model which combines pairwise classification and mention clustering with Markov logic.", "labels": [], "entities": []}, {"text": "Experimental results show that our joint learning system outperforms independent learning systems.", "labels": [], "entities": []}, {"text": "Our system gives a better performance than all the learning-based systems from the CoNLL-2011 shared task on the same dataset.", "labels": [], "entities": [{"text": "CoNLL-2011 shared task", "start_pos": 83, "end_pos": 105, "type": "DATASET", "confidence": 0.8291844924290975}]}, {"text": "Compared with the best system from CoNLL-2011, which employs a rule-based method, our system shows competitive performance.", "labels": [], "entities": [{"text": "CoNLL-2011", "start_pos": 35, "end_pos": 45, "type": "DATASET", "confidence": 0.9242780208587646}]}], "introductionContent": [{"text": "The task of noun phrase coreference resolution is to determine which mentions in a text refer to the same real-world entity.", "labels": [], "entities": [{"text": "noun phrase coreference resolution", "start_pos": 12, "end_pos": 46, "type": "TASK", "confidence": 0.7585219442844391}]}, {"text": "Many methods have been proposed for this problem.", "labels": [], "entities": []}, {"text": "Among them the mentionpair model) is one of the most influential ones and can achieve the stateof-the-art performance.", "labels": [], "entities": []}, {"text": "The mention-pair model splits the task into three parts: mention detection, pairwise classification and mention clustering.", "labels": [], "entities": [{"text": "mention detection", "start_pos": 57, "end_pos": 74, "type": "TASK", "confidence": 0.7506822049617767}, {"text": "pairwise classification", "start_pos": 76, "end_pos": 99, "type": "TASK", "confidence": 0.6792200952768326}, {"text": "mention clustering", "start_pos": 104, "end_pos": 122, "type": "TASK", "confidence": 0.6599240452051163}]}, {"text": "Mention detection aims to identify anaphoric noun phrases, including proper nouns, common noun phrases and pronouns.", "labels": [], "entities": [{"text": "Mention detection", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8689000904560089}]}, {"text": "Pairwise classification takes a pair of detected anaphoric noun phrase candidates and determines whether they refer to the same entity.", "labels": [], "entities": [{"text": "Pairwise classification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8113572895526886}]}, {"text": "Because these classification decisions are local, they do not guarantee that candidate mentions are partitioned into clusters.", "labels": [], "entities": []}, {"text": "Therefore a mention clustering step is needed to resolve conflicts and generate the final mention clusters.", "labels": [], "entities": []}, {"text": "Much work has been done following the mentionpair model ().", "labels": [], "entities": []}, {"text": "In most work, pairwise classification and mention clustering are done sequentially.", "labels": [], "entities": [{"text": "pairwise classification", "start_pos": 14, "end_pos": 37, "type": "TASK", "confidence": 0.7733159363269806}, {"text": "mention clustering", "start_pos": 42, "end_pos": 60, "type": "TASK", "confidence": 0.6307350844144821}]}, {"text": "A major weakness of this approach is that pairwise classification considers only local information, which may not be sufficient to make correct decisions.", "labels": [], "entities": [{"text": "pairwise classification", "start_pos": 42, "end_pos": 65, "type": "TASK", "confidence": 0.6978243887424469}]}, {"text": "One way to address this weakness is to jointly learn the pairwise classification model and the mention clustering model.", "labels": [], "entities": []}, {"text": "This idea has been explored to some extent by using conditional undirected graphical models and by using an SVM-based supervised clustering method.", "labels": [], "entities": [{"text": "SVM-based supervised clustering", "start_pos": 108, "end_pos": 139, "type": "TASK", "confidence": 0.7113045851389567}]}, {"text": "In this paper, we study how to use a different learning framework, Markov logic (), to learn a joint model for both pairwise classification and mention clustering under the mention-pair model.", "labels": [], "entities": [{"text": "pairwise classification", "start_pos": 116, "end_pos": 139, "type": "TASK", "confidence": 0.6168394982814789}, {"text": "mention clustering", "start_pos": 144, "end_pos": 162, "type": "TASK", "confidence": 0.6943515241146088}]}, {"text": "We choose Markov logic because of its appealing properties.", "labels": [], "entities": []}, {"text": "Markov logic is based on first-order logic, which makes the learned models readily interpretable by humans.", "labels": [], "entities": [{"text": "Markov logic", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.8210678100585938}]}, {"text": "Moreover, joint learning is natural under the Markov logic framework, with local pairwise classification and global mention clustering both formulated as weighted first-order clauses.", "labels": [], "entities": [{"text": "joint learning", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.7902707755565643}, {"text": "global mention clustering", "start_pos": 109, "end_pos": 134, "type": "TASK", "confidence": 0.6553526719411215}]}, {"text": "In fact, Markov logic has been previously used by for coreference resolution and achieved good results, but it was used for unsupervised coreference resolution and the method was based on a different model, the entity-mention model.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 54, "end_pos": 76, "type": "TASK", "confidence": 0.9561292231082916}, {"text": "coreference resolution", "start_pos": 137, "end_pos": 159, "type": "TASK", "confidence": 0.8449656665325165}]}, {"text": "More specifically, to combine mention clustering with pairwise classification, we adopt the commonly used strategies (such as best-first clustering and transitivity constraint), and formulate them as first-order logic formulas under the Markov logic framework.", "labels": [], "entities": [{"text": "pairwise classification", "start_pos": 54, "end_pos": 77, "type": "TASK", "confidence": 0.6666928678750992}]}, {"text": "Best-first clustering has been previously studied by and and found to be effective.", "labels": [], "entities": [{"text": "Best-first clustering", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.5560551434755325}]}, {"text": "Transitivity constraint has been applied to coreference resolution by and, and also achieved good performance.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 44, "end_pos": 66, "type": "TASK", "confidence": 0.9656965136528015}]}, {"text": "We evaluate Markov logic-based method on the dataset from CoNLL-2011 shared task.", "labels": [], "entities": [{"text": "CoNLL-2011 shared task", "start_pos": 58, "end_pos": 80, "type": "DATASET", "confidence": 0.8684627811113993}]}, {"text": "Our experiment results demonstrate the advantage of joint learning of pairwise classification and mention clustering over independent learning.", "labels": [], "entities": []}, {"text": "We examine best-first clustering and transitivity constraint in our methods, and find that both are very useful for coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 116, "end_pos": 138, "type": "TASK", "confidence": 0.9741061329841614}]}, {"text": "Compared with the state of the art, our method outperforms a baseline that represents atypical system using the mention-pair model.", "labels": [], "entities": []}, {"text": "Our method is also better than all learning systems from the CoNLL-2011 shared task based on the reported performance.", "labels": [], "entities": [{"text": "CoNLL-2011 shared task", "start_pos": 61, "end_pos": 83, "type": "DATASET", "confidence": 0.8509812951087952}]}, {"text": "Even with the top system from CoNLL-2011, our performance is still competitive.", "labels": [], "entities": [{"text": "CoNLL-2011", "start_pos": 30, "end_pos": 40, "type": "DATASET", "confidence": 0.9078342318534851}]}, {"text": "In the rest of this paper, we first describe a standard pairwise coreference resolution system in Section 2.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 65, "end_pos": 87, "type": "TASK", "confidence": 0.8306003212928772}]}, {"text": "We then present our Markov logic model for pairwise coreference resolution in Section 3.", "labels": [], "entities": [{"text": "pairwise coreference resolution", "start_pos": 43, "end_pos": 74, "type": "TASK", "confidence": 0.6729098757108053}]}, {"text": "Experimental results are given in Section 4.", "labels": [], "entities": []}, {"text": "Finally we discuss related work in Section 5 and conclude in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we will first describe the dataset and evaluation metrics we use.", "labels": [], "entities": []}, {"text": "We will then present the effect of our joint learning method, and finally discuss the comparison with the state of the art.", "labels": [], "entities": []}, {"text": "We use the same evaluation metrics as used in CoNLL-2011.", "labels": [], "entities": [{"text": "CoNLL-2011", "start_pos": 46, "end_pos": 56, "type": "DATASET", "confidence": 0.9269787669181824}]}, {"text": "Specifically, for mention detection, we use precision, recall and the F-measure.", "labels": [], "entities": [{"text": "precision", "start_pos": 44, "end_pos": 53, "type": "METRIC", "confidence": 0.999602735042572}, {"text": "recall", "start_pos": 55, "end_pos": 61, "type": "METRIC", "confidence": 0.9993966817855835}, {"text": "F-measure", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.9934183359146118}]}, {"text": "A mention is considered to be correct only if it matches the exact same span of characters in the annotation key.", "labels": [], "entities": []}, {"text": "For coreference resolution, MUC (, B-CUBED ( and CEAF-E () are used for evaluation.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.9676716029644012}, {"text": "MUC", "start_pos": 28, "end_pos": 31, "type": "METRIC", "confidence": 0.5475641489028931}, {"text": "B-CUBED", "start_pos": 35, "end_pos": 42, "type": "METRIC", "confidence": 0.9728373289108276}, {"text": "CEAF-E", "start_pos": 49, "end_pos": 55, "type": "DATASET", "confidence": 0.6775485873222351}]}, {"text": "The unweighted average F score of them is used to compare different systems.", "labels": [], "entities": [{"text": "F score", "start_pos": 23, "end_pos": 30, "type": "METRIC", "confidence": 0.8703816533088684}]}], "tableCaptions": [{"text": " Table 3: Comparison between different MLN-based systems, using 10-fold cross validation on the training dataset.", "labels": [], "entities": []}, {"text": " Table 4: Comparisons with state-of-the-art systems on the development dataset.", "labels": [], "entities": []}]}