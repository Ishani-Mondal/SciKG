{"title": [{"text": "Regularized Interlingual Projections: Evaluation on Multilingual Transliteration", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we address the problem of building a multilingual transliteration system using an interlingual representation.", "labels": [], "entities": []}, {"text": "Our approach uses international phonetic alphabet (IPA) to learn the interlingual representation and thus allows us to use any word and its IPA representation as a training example.", "labels": [], "entities": []}, {"text": "Thus, our approach requires only monolingual resources: a phoneme dictionary that lists words and their IPA representations.", "labels": [], "entities": []}, {"text": "1 By adding a phoneme dictionary of anew language, we can readily build a transliteration system into any of the existing previous languages, without the expense of all-pairs data or computation.", "labels": [], "entities": []}, {"text": "We also propose a regularization framework for learning the interlingual representation, which accounts for language specific phonemic variability , and thus it can find better mappings between languages.", "labels": [], "entities": []}, {"text": "Experimental results on the name transliteration task in five diverse languages show a maximum improvement of 29% accuracy and an average improvement of 17% accuracy compared to a state-of-the-art baseline system.", "labels": [], "entities": [{"text": "name transliteration task", "start_pos": 28, "end_pos": 53, "type": "TASK", "confidence": 0.8532153367996216}, {"text": "accuracy", "start_pos": 114, "end_pos": 122, "type": "METRIC", "confidence": 0.9992185831069946}, {"text": "accuracy", "start_pos": 157, "end_pos": 165, "type": "METRIC", "confidence": 0.998591959476471}]}], "introductionContent": [{"text": "Because of the wide usage of English, many natural language processing (NLP) tasks have bilingual resources from English into other languages.", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 43, "end_pos": 76, "type": "TASK", "confidence": 0.7578025062878927}]}, {"text": "For example, significantly larger parallel texts are available between English and other languages.", "labels": [], "entities": []}, {"text": "Similarly, bilingual dictionaries and transliteration data sets are more accessible from a language into English than into a different language.", "labels": [], "entities": []}, {"text": "This situation has caused the NLP community to develop approaches which use a resource rich language (Q say English) as pivot to build resources/applications between anew language pair P and R.", "labels": [], "entities": []}, {"text": "Previous studies in machine translation (), transliteration ( , and dictionary mining ( show that these bridge language approaches perform competitively with approaches that use resources between P and R.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 20, "end_pos": 39, "type": "TASK", "confidence": 0.813419908285141}, {"text": "dictionary mining", "start_pos": 68, "end_pos": 85, "type": "TASK", "confidence": 0.7986443042755127}]}, {"text": "In this paper, we propose a regularization framework for bridge language approaches and show its effectiveness for name transliteration task.", "labels": [], "entities": [{"text": "name transliteration task", "start_pos": 115, "end_pos": 140, "type": "TASK", "confidence": 0.8692958752314249}]}, {"text": "The key idea of our approach is that it accounts for language specific variation in the bridge language resources (i.e. between P \u2194 Q and Q \u2194 R) and aims to minimize this variation as much as possible.", "labels": [], "entities": []}, {"text": "Though our technique is general, for clarity we describe it in the context of named entity (NE) transliteration.", "labels": [], "entities": []}, {"text": "Named entity (NE) transliteration involves transliterating a name in one language into another language and is shown to be crucial for machine translation (MT)) and cross-lingual information retrieval (CLIR) ().", "labels": [], "entities": [{"text": "Named entity (NE) transliteration", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.5852680951356888}, {"text": "machine translation (MT))", "start_pos": 135, "end_pos": 160, "type": "TASK", "confidence": 0.8254784405231476}, {"text": "cross-lingual information retrieval (CLIR)", "start_pos": 165, "end_pos": 207, "type": "TASK", "confidence": 0.7572940985361735}]}, {"text": "There exists a large body of literature in transliteration, especially in the bilingual setting, well summarized by.", "labels": [], "entities": []}, {"text": "We summarize the approaches that are most relevant to us in Sec.", "labels": [], "entities": [{"text": "Sec.", "start_pos": 60, "end_pos": 64, "type": "TASK", "confidence": 0.8651759624481201}]}, {"text": "5. In this paper, we operate in the context of transliteration mining () where we assume that we are given a source language name and a list of target language candidate transliterations and the task is to identify the correct transliteration.", "labels": [], "entities": [{"text": "transliteration mining", "start_pos": 47, "end_pos": 69, "type": "TASK", "confidence": 0.9189228117465973}]}, {"text": "Given a set of l languages, we address the problem of building a transliteration system between every pair of languages.", "labels": [], "entities": []}, {"text": "A straightforward supervised learning approach would require training data of name pairs between every pair of languages) or a set of common names transliterated from every language into a pivot language.", "labels": [], "entities": []}, {"text": "Though it is relatively easy to obtain names transliterated into a pivot language (such as English), it is unlikely that such data sets contain the same names.", "labels": [], "entities": []}, {"text": "Bridge language approaches overcome the need for common names and build transliteration systems for resource poor languages ( . However, such approaches still require training data consisting of bilingual name transliterations (orthographic name-to-name mappings).", "labels": [], "entities": []}, {"text": "In this paper, we relax the need for name transliterations by using international phonetic alphabet (IPA) in a manner akin to a \"bridge language.\"", "labels": [], "entities": [{"text": "name transliterations", "start_pos": 37, "end_pos": 58, "type": "TASK", "confidence": 0.7612313330173492}]}], "datasetContent": [{"text": "Our experiments are designed to evaluate the following three aspects of our model, and of our approach to transliteration in general: IPA as bridge: Unlike other phonemic based approaches (Sec.", "labels": [], "entities": []}, {"text": "5), we do not explicitly model the phoneme modifications between pairs of languages.", "labels": [], "entities": []}, {"text": "Moreover, the phoneme dictionary in each language is crawled from Wiktionary (Sec. 6.1), which is likely to be noisy.", "labels": [], "entities": [{"text": "Wiktionary (Sec. 6.1)", "start_pos": 66, "end_pos": 87, "type": "DATASET", "confidence": 0.8517654657363891}]}, {"text": "So, the first aspect we want to evaluate is the effectiveness of using IPA as the bridge language.", "labels": [], "entities": []}, {"text": "Here, we also compare our method with other bridge language approaches and establish the importance of modeling language specific variance.", "labels": [], "entities": []}, {"text": "Multilinguality: In our method, simply adding a phoneme dictionary of anew language allows us to extend our transliteration system into any of the existing languages.", "labels": [], "entities": []}, {"text": "We evaluate the effect of data from a different, but related, languages on a transliteration system between a given pair.", "labels": [], "entities": []}, {"text": "Complementarity: Using IPA as bridge language allows us to build transliteration system into resource poor languages.", "labels": [], "entities": []}, {"text": "But we also want to evaluate whether such an approach can help improving a transliteration system trained directly on bilingual name-pairs.", "labels": [], "entities": []}, {"text": "We convert the phoneme dictionaries of each language into feature vectors.", "labels": [], "entities": []}, {"text": "We use unigram and bigram features in the phonemic space and unigram, bigram and trigram features in the character space.", "labels": [], "entities": []}, {"text": "An example for feature generation is shown in Sec.", "labels": [], "entities": [{"text": "feature generation", "start_pos": 15, "end_pos": 33, "type": "TASK", "confidence": 0.7672480642795563}]}, {"text": "3. After converting the data into feature vectors, we retain the most frequent 5000 features.", "labels": [], "entities": []}, {"text": "We only keep the frequent 5000 features since we observed, elsewhere, that including infrequent features leads CCA based methods to learn projection directions with perfect correlations which are not effective for downstream applications.", "labels": [], "entities": []}, {"text": "The last row of shows the number of features in the character space of each of the languages.", "labels": [], "entities": []}, {"text": "The phonemic space is common to all the languages and has 3777 features.", "labels": [], "entities": []}, {"text": "Though the phonemic features are common to all the languages, as discussed in Sec.", "labels": [], "entities": []}, {"text": "2, only a subset of features will be observed in a given language.", "labels": [], "entities": []}, {"text": "For example, in our data sets, of the total 3777 common phonetic features only 3312, 882, and 1009 features are observed in English, Bulgarian, and Russian languages respectively.", "labels": [], "entities": []}, {"text": "This indicates the diversity in the phonemic inventory of different languages.", "labels": [], "entities": []}, {"text": "We compare our approach against Bridge-CCA, a state-of-the-art bridge language transliteration system which is known to perform competitively with other discriminative approaches ( . We use the phoneme dictionaries in each language to train our approach, as well as the baseline system.", "labels": [], "entities": []}, {"text": "The projection directions learnt during the training are used to find the transliteration fora test name as described in Sec.", "labels": [], "entities": []}, {"text": "We report the performance in terms of the accuracy (exact match) of the top ranked transliteration and the mean reciprocal rank (MRR) of the correct transliteration.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9994292855262756}, {"text": "exact match)", "start_pos": 52, "end_pos": 64, "type": "METRIC", "confidence": 0.9347065687179565}, {"text": "mean reciprocal rank (MRR)", "start_pos": 107, "end_pos": 133, "type": "METRIC", "confidence": 0.8099046349525452}]}, {"text": "We find transliterations in both the directions (i.e. target language transliterations given a source name and vice versa) and report average accuracies.", "labels": [], "entities": []}, {"text": "The regularization parameter (\u03c4 ) and the size of the interlingual representation (k) in both our approach and Bridge-CCA are tuned on the development set.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Statistics of different data sets. Training  data is monolingual phoneme dictionaries while develop- ment/test sets are bilingual name pairs between English  and the respective language.", "labels": [], "entities": []}, {"text": " Table 4: Results of our approach and the baseline system on the test set. The second block shows the results when our  approach is trained only on phoneme dictionaries of the language pair, the third block shows results when we include  other language data as well.", "labels": [], "entities": []}, {"text": " Table 5: Comparison with a system trained on bilingual  name pairs. The (t) in the third row indicates parame- ters are tuned for test set. We also show the percentage  error reduction achieved by a linear combination of our  approach and CCA.", "labels": [], "entities": [{"text": "percentage  error reduction", "start_pos": 158, "end_pos": 185, "type": "METRIC", "confidence": 0.7369624475638071}]}]}