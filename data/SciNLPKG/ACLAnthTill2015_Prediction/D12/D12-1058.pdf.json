{"title": [{"text": "Enlarging Paraphrase Collections through Generalization and Instantiation", "labels": [], "entities": [{"text": "Enlarging Paraphrase Collections", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7552676697572073}, {"text": "Generalization", "start_pos": 41, "end_pos": 55, "type": "TASK", "confidence": 0.9576809406280518}]}], "abstractContent": [{"text": "This paper presents a paraphrase acquisition method that uncovers and exploits generalities underlying paraphrases: paraphrase patterns are first induced and then used to collect novel instances.", "labels": [], "entities": [{"text": "paraphrase acquisition", "start_pos": 22, "end_pos": 44, "type": "TASK", "confidence": 0.8720665574073792}]}, {"text": "Unlike existing methods, ours uses both bilingual parallel and monolin-gual corpora.", "labels": [], "entities": []}, {"text": "While the former are regarded as a source of high-quality seed paraphrases, the latter are searched for paraphrases that match patterns learned from the seed paraphrases.", "labels": [], "entities": []}, {"text": "We show how one can use monolingual corpora , which are far more numerous and larger than bilingual corpora, to obtain paraphrases that rival in quality those derived directly from bilingual corpora.", "labels": [], "entities": []}, {"text": "In our experiments, the number of paraphrase pairs obtained in this way from monolingual corpora was a large multiple of the number of seed paraphrases.", "labels": [], "entities": []}, {"text": "Human evaluation through a paraphrase substitution test demonstrated that the newly acquired paraphrase pairs are of reasonable quality.", "labels": [], "entities": [{"text": "paraphrase substitution", "start_pos": 27, "end_pos": 50, "type": "TASK", "confidence": 0.8212959170341492}]}, {"text": "Remaining noise can be further reduced by filtering seed paraphrases.", "labels": [], "entities": []}], "introductionContent": [{"text": "Paraphrases are semantically equivalent expressions in the same language.", "labels": [], "entities": []}, {"text": "Because \"equivalence\" is the most fundamental semantic relationship, techniques for generating and recognizing paraphrases play an important role in a wide range of natural language processing tasks.", "labels": [], "entities": []}, {"text": "In the last decade, automatic acquisition of knowledge about paraphrases from corpora has been drawing the attention of many researchers.", "labels": [], "entities": [{"text": "automatic acquisition of knowledge about paraphrases from corpora", "start_pos": 20, "end_pos": 85, "type": "TASK", "confidence": 0.8268130868673325}]}, {"text": "Typically, the acquired knowledge is simply represented as pairs of semantically equivalent sub-sentential expressions as in (1).", "labels": [], "entities": []}, {"text": "(1) a. look like \u21d4 resemble b. control system \u21d4 controller The challenge in acquiring paraphrases is to ensure good coverage of the targeted classes of paraphrases along with a low proportion of incorrect pairs.", "labels": [], "entities": []}, {"text": "However, no matter what type of resource has been used, it has proven difficult to acquire paraphrase pairs with both high recall and high precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 123, "end_pos": 129, "type": "METRIC", "confidence": 0.9992296695709229}, {"text": "precision", "start_pos": 139, "end_pos": 148, "type": "METRIC", "confidence": 0.9958099126815796}]}, {"text": "Among various types of corpora, monolingual corpora can be considered the best source for highcoverage paraphrase acquisition, because there is far more monolingual than bilingual text available.", "labels": [], "entities": [{"text": "highcoverage paraphrase acquisition", "start_pos": 90, "end_pos": 125, "type": "TASK", "confidence": 0.6785449584325155}]}, {"text": "Most methods that exploit monolingual corpora rely on the Distributional Hypothesis: expressions that appear in similar contexts are expected to have similar meaning.", "labels": [], "entities": []}, {"text": "However, if one uses purely distributional criteria, it is difficult to distinguish real paraphrases from pairs of expressions that are related in other ways, such as antonyms and cousin words.", "labels": [], "entities": []}, {"text": "In contrast, since the work in), bilingual parallel corpora have been acknowledged as a good source of highquality paraphrases: paraphrases are obtained by putting together expressions that receive the same translation in the other language (pivot language).", "labels": [], "entities": []}, {"text": "Because translation expresses a specific meaning more directly than context in the aforementioned approach, pairs of expressions acquired in this manner tend to be correct paraphrases.", "labels": [], "entities": []}, {"text": "However, the coverage problem remains: there is much less bilingual parallel than monolingual text available.", "labels": [], "entities": [{"text": "coverage", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.8496866822242737}]}, {"text": "Our objective in this paper is to obtain paraphrases that have high quality (like those extracted from bilingual parallel corpora via pivoting) but can be generated in large quantity (like those extracted from monolingual corpora via contextual similarity).", "labels": [], "entities": []}, {"text": "To achieve this, we propose a method that exploits general patterns underlying paraphrases and uses both bilingual parallel and monolingual sources of information.", "labels": [], "entities": []}, {"text": "Given a relatively high-quality set of paraphrases obtained from a bilingual parallel corpus, a set of paraphrase patterns is first induced.", "labels": [], "entities": []}, {"text": "Then, appropriate instances of such patterns, i.e., potential paraphrases, are harvested from a monolingual corpus.", "labels": [], "entities": []}, {"text": "After reviewing existing methods in Section 2, our method is presented in Section 3.", "labels": [], "entities": []}, {"text": "Section 4 describes our experiments in acquiring paraphrases and presents statistics summarizing the coverage of our method.", "labels": [], "entities": []}, {"text": "Section 5 describes a human evaluation of the quality of the acquired paraphrases.", "labels": [], "entities": []}, {"text": "Finally, Section 6 concludes this paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "To confirm that the quality of P Hvst is sufficiently high, we carried out a substitution test.", "labels": [], "entities": []}, {"text": "First, by substituting sub-sentential paraphrases to existing sentences in a given test corpus, pairs of slightly different sentences were automatically generated.", "labels": [], "entities": []}, {"text": "For instance, by applying \"looks like\" \u21d2 \"resembles\" to (5), (6) was generated.", "labels": [], "entities": []}, {"text": "(5) The roof looks like a prehistoric lizard's spine.", "labels": [], "entities": []}, {"text": "(6) The roof resembles a prehistoric lizard's spine.", "labels": [], "entities": []}, {"text": "Human evaluators were then asked to score each pair of an original sentence and a paraphrased sentence with the following two 5-point scale grades proposed by: Grammaticality: whether the paraphrased sentence is grammatical (1: horrible, 5: perfect) Meaning: whether the meaning of the original sentence is properly retained by the paraphrased sentence (1: totally different, 5: equivalent) To make results more consistent and reduce the human labor, evaluators were asked to rate at the same time several paraphrases for the same source phrase.", "labels": [], "entities": []}, {"text": "For instance, given a source sentence (5), the evaluators might be given the following sentences in addition to a paraphrased sentence (6).", "labels": [], "entities": []}, {"text": "The roof seems like a prehistoric lizard's spine.", "labels": [], "entities": []}, {"text": "(8) The roof would look like a prehistoric lizard's spine.", "labels": [], "entities": []}, {"text": "In this experiment, we showed five paraphrases per source phrase, assuming that evaluators would get confused if too large a number of paraphrase candidates were presented at the same time.", "labels": [], "entities": []}, {"text": "As in previous work), we evaluated paraphrases acquired from the Europarl corpus on news sentences.", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 65, "end_pos": 80, "type": "DATASET", "confidence": 0.9835082590579987}]}, {"text": "Paraphrase examples were automatically generated from the English part of WMT 2008-2011 \"newstest\" data (10,050 unique sentences) by applying the union of P Seed and P Hvst of the Europarl setting (19.3M paraphrases for 5.95M phrases).", "labels": [], "entities": [{"text": "WMT 2008-2011 \"newstest\" data", "start_pos": 74, "end_pos": 103, "type": "DATASET", "confidence": 0.9150426983833313}, {"text": "Europarl setting", "start_pos": 180, "end_pos": 196, "type": "DATASET", "confidence": 0.9839973449707031}]}, {"text": "On the other hand, paraphrases acquired from patent documents are much more difficult to evaluate due to the following reasons.", "labels": [], "entities": [{"text": "paraphrases acquired from patent documents", "start_pos": 19, "end_pos": 61, "type": "TASK", "confidence": 0.8692588806152344}]}, {"text": "First, they maybe too domain-specific to be of any use in general areas such as news sentences.", "labels": [], "entities": []}, {"text": "However, conducting an in-domain evaluation would be difficult without enrolling domain experts.", "labels": [], "entities": []}, {"text": "We expect that paraphrases from a domain can be used safely in that domain.", "labels": [], "entities": []}, {"text": "Nevertheless, deciding under what circumstances they can be used safely in another domain is an interesting research question.", "labels": [], "entities": []}, {"text": "To reduce the human labor for the evaluation, sentences were restricted to those with moderate length: 10-30 words, which are expected to provide sufficient but succinct context.", "labels": [], "entities": []}, {"text": "To propose multiple paraphrase candidates at the same time, we also restricted phrases to be paraphrased (LHS phrases) to those having at least five paraphrases including ones from P Hvst . This resulted in 60,421 paraphrases for 988 phrase tokens (353 unique phrases).", "labels": [], "entities": []}, {"text": "Finally, we randomly sampled 80 unique phrase tokens and five unique paraphrases for each phrase token (400 examples in total), and asked six people having a high level of English proficiency to evaluate them.", "labels": [], "entities": []}, {"text": "Inter-evaluator agreement was calculated from five different pairs of evaluators, each judging the same 10 examples.", "labels": [], "entities": []}, {"text": "The remaining 350 examples were divided into six chunks of slightly unequal length, with each chunk being judged by one of the six evaluators.", "labels": [], "entities": []}, {"text": "shows the average of the original 5-point scale scores and the percentage of examples that are judged correct based on a binary judgment: an example is considered to be correct iff the grammaticality score is 4 or above and/or the meaning score is 3 or above.", "labels": [], "entities": []}, {"text": "Paraphrases based on P Seed achieved a quite high performance in both grammaticality (\"G\") and meaning (\"M\") in part because of the effectiveness of our filtering techniques.", "labels": [], "entities": [{"text": "P Seed", "start_pos": 21, "end_pos": 27, "type": "DATASET", "confidence": 0.8067227602005005}]}, {"text": "The performance of paraphrases drawn from P Hvst was reasonably high and similar to the scores 0.68 for grammaticality, 0.61 for meaning, and 0.55 for both, of the best model reported in), although it was inferior to P Seed . Despite the fact that all of our evaluators had a high-level command of English, the agreement was not very high.", "labels": [], "entities": [{"text": "agreement", "start_pos": 311, "end_pos": 320, "type": "METRIC", "confidence": 0.9898161888122559}]}, {"text": "This was true even when the collected scores were mapped into binary classes.", "labels": [], "entities": []}, {"text": "In this case, the \u03ba values for each criterion were 0.45 and 0.45, respectively, which indicate the agreement was \"fair\".", "labels": [], "entities": []}, {"text": "To obtain a better \u03ba value, the criteria for grading will need to be improved.", "labels": [], "entities": []}, {"text": "However, we think that was not too low either 8 .", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Avg. score and precision of binary classification.", "labels": [], "entities": [{"text": "Avg. score", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9224420587221781}, {"text": "precision", "start_pos": 25, "end_pos": 34, "type": "METRIC", "confidence": 0.9986853003501892}, {"text": "binary classification", "start_pos": 38, "end_pos": 59, "type": "TASK", "confidence": 0.6174538880586624}]}]}