{"title": [{"text": "Using Discourse Information for Paraphrase Extraction", "labels": [], "entities": [{"text": "Paraphrase Extraction", "start_pos": 32, "end_pos": 53, "type": "TASK", "confidence": 0.9150724709033966}]}], "abstractContent": [{"text": "Previous work on paraphrase extraction using parallel or comparable corpora has generally not considered the documents' discourse structure as a useful information source.", "labels": [], "entities": [{"text": "paraphrase extraction", "start_pos": 17, "end_pos": 38, "type": "TASK", "confidence": 0.9437311589717865}]}, {"text": "We propose a novel method for collecting paraphrases relying on the sequential event order in the discourse, using multiple sequence alignment with a semantic similarity measure.", "labels": [], "entities": []}, {"text": "We show that adding discourse information boosts the performance of sentence-level paraphrase acquisition, which consequently gives a tremendous advantage for extracting phrase-level paraphrase fragments from matched sentences.", "labels": [], "entities": [{"text": "sentence-level paraphrase acquisition", "start_pos": 68, "end_pos": 105, "type": "TASK", "confidence": 0.5852920810381571}, {"text": "extracting phrase-level paraphrase fragments from matched sentences", "start_pos": 159, "end_pos": 226, "type": "TASK", "confidence": 0.7763660337243762}]}, {"text": "Our system beats an informed baseline by a margin of 50%.", "labels": [], "entities": []}], "introductionContent": [{"text": "It is widely agreed that identifying paraphrases is a core task for natural language processing, including applications like document summarization (), Recognizing Textual Entailment (), natural language generation (, and machine translation (.", "labels": [], "entities": [{"text": "document summarization", "start_pos": 125, "end_pos": 147, "type": "TASK", "confidence": 0.7506588101387024}, {"text": "Recognizing Textual Entailment", "start_pos": 152, "end_pos": 182, "type": "TASK", "confidence": 0.797739843527476}, {"text": "natural language generation", "start_pos": 187, "end_pos": 214, "type": "TASK", "confidence": 0.6478282610575358}, {"text": "machine translation", "start_pos": 222, "end_pos": 241, "type": "TASK", "confidence": 0.8009440898895264}]}, {"text": "As a consequence, many methods have been proposed for generating large paraphrase resources ().", "labels": [], "entities": []}, {"text": "One of the intuitively appropriate data sources for such collections are parallel or comparable corpora: if two texts are translations of the same foreign document, or if they describe the same underlying scenario, they should contain a reasonable number of sentence pairs that convey the same meaning.", "labels": [], "entities": []}, {"text": "Most approaches that extract paraphrases from parallel texts employ some type of pattern matching: sentences with the same meaning are assumed to share many n-grams (, among others), many words in their context () or certain slots in a dependency path).", "labels": [], "entities": []}, {"text": "Discourse structure has only marginally been considered for this task: For example,  extract the first sentences from comparable articles and take them as paraphrases.", "labels": [], "entities": [{"text": "Discourse structure", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8070321679115295}]}, {"text": "Another approach) matches similar paragraphs in comparable texts, creating smaller comparable documents for paraphrase extraction.", "labels": [], "entities": [{"text": "paraphrase extraction", "start_pos": 108, "end_pos": 129, "type": "TASK", "confidence": 0.920634925365448}]}, {"text": "We believe that discourse structure delivers important information for the extraction of paraphrases.", "labels": [], "entities": []}, {"text": "Sentences that play the same role in a certain discourse and have a similar discourse context can be paraphrases, even if a semantic similarity model does not consider them very similar.", "labels": [], "entities": []}, {"text": "This extends the widely applied distributional hypothesis to the discourse level: According to the distributional hypothesis, entities are similar if they share similar contexts.", "labels": [], "entities": []}, {"text": "In our case, entities are whole sentences, and contexts are discourse units.", "labels": [], "entities": []}, {"text": "Based on this assumption, we propose a novel method for collecting paraphrases from parallel texts using discourse information.", "labels": [], "entities": [{"text": "collecting paraphrases from parallel texts", "start_pos": 56, "end_pos": 98, "type": "TASK", "confidence": 0.7735198140144348}]}, {"text": "We create anew type of parallel corpus by collecting multiple summaries for several TV show episodes.", "labels": [], "entities": []}, {"text": "The discourse structures of those summaries are easy to compare: they all contain the events in the same order as they have appeared on the screen.", "labels": [], "entities": []}, {"text": "This allows us to take sentence order as event-based discourse structure, which is highly parallel for recaps of the same episode.", "labels": [], "entities": []}, {"text": "In its first step, our system uses a sequence align-ment algorithm combined with a state-of-the-art similarity measure.", "labels": [], "entities": []}, {"text": "The approach outperforms informed baselines on the task of sentential paraphrase identification.", "labels": [], "entities": [{"text": "sentential paraphrase identification", "start_pos": 59, "end_pos": 95, "type": "TASK", "confidence": 0.7021101514498392}]}, {"text": "The usage of discourse information even contributes more to the final performance than the sentence similarity measure.", "labels": [], "entities": []}, {"text": "As second step, we extract phrase-level paraphrase fragments from the matched sentences.", "labels": [], "entities": []}, {"text": "This step relies on the alignment algorithm's output, and we show that discourse information makes a big difference for the precision of the extraction.", "labels": [], "entities": [{"text": "precision", "start_pos": 124, "end_pos": 133, "type": "METRIC", "confidence": 0.9984939098358154}]}, {"text": "We then add more discourse-based information by preprocessing the text with a coreference resolution system, which results in additional performance improvement.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 78, "end_pos": 100, "type": "TASK", "confidence": 0.7927634418010712}]}, {"text": "The paper is structured as follows: first we summarize related work (Sec.", "labels": [], "entities": [{"text": "summarize related work", "start_pos": 45, "end_pos": 67, "type": "TASK", "confidence": 0.8679145574569702}]}, {"text": "2), and then we give an overview over our perspective on the task and sketch our system pipeline (Sec. 3).", "labels": [], "entities": []}, {"text": "The following two sections describe the details of the sentence matching step (Sec.", "labels": [], "entities": [{"text": "sentence matching", "start_pos": 55, "end_pos": 72, "type": "TASK", "confidence": 0.7350872159004211}]}, {"text": "4) and the subsequent paraphrase fragment extraction (Sec. 5).", "labels": [], "entities": [{"text": "paraphrase fragment extraction", "start_pos": 22, "end_pos": 52, "type": "TASK", "confidence": 0.7286168734232584}]}, {"text": "We present both automatic and manual evaluation of the two system components (Sec. 6).", "labels": [], "entities": []}, {"text": "Finally, we conclude the paper and give some hints for future work (Sec. 7).", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate both sentential paraphrase matching and paraphrase fragment extraction using manually labelled gold standards (provided in the supplementary material).", "labels": [], "entities": [{"text": "sentential paraphrase matching", "start_pos": 17, "end_pos": 47, "type": "TASK", "confidence": 0.7081267337004343}, {"text": "paraphrase fragment extraction", "start_pos": 52, "end_pos": 82, "type": "TASK", "confidence": 0.7903305888175964}]}, {"text": "We collect recaps for all 20 episodes of season 6 of House M.D., taking 8 summaries per episode (the supplementary material contains a list of all URLs).", "labels": [], "entities": []}, {"text": "This results in 160 documents containing 14735 sentences.", "labels": [], "entities": []}, {"text": "For evaluation, we use all episodes except no.", "labels": [], "entities": []}, {"text": "2, which is held out for parameter optimizations and other development purposes.", "labels": [], "entities": [{"text": "parameter optimizations", "start_pos": 25, "end_pos": 48, "type": "TASK", "confidence": 0.7313102334737778}]}, {"text": "To evaluate sentence matching, we adapt the baselines from our earlier work ( and create anew gold standard.", "labels": [], "entities": [{"text": "sentence matching", "start_pos": 12, "end_pos": 29, "type": "TASK", "confidence": 0.7653044164180756}]}, {"text": "We compute precision, recall and accuracy of our main system and suggest baselines that separately show the influence of both the MSA and the semantic scoring function.", "labels": [], "entities": [{"text": "precision", "start_pos": 11, "end_pos": 20, "type": "METRIC", "confidence": 0.9993671774864197}, {"text": "recall", "start_pos": 22, "end_pos": 28, "type": "METRIC", "confidence": 0.9991582632064819}, {"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9984776377677917}]}, {"text": "We compute precision, recall and f-score with respect to the gold standard (paraphrases are members of paraphrase coll ), taking f-score as follows: We also compute accuracy as the overall fraction of correct labels (negative and positive ones).", "labels": [], "entities": [{"text": "precision", "start_pos": 11, "end_pos": 20, "type": "METRIC", "confidence": 0.9994413256645203}, {"text": "recall", "start_pos": 22, "end_pos": 28, "type": "METRIC", "confidence": 0.9995324611663818}, {"text": "f-score", "start_pos": 33, "end_pos": 40, "type": "METRIC", "confidence": 0.9427171945571899}, {"text": "accuracy", "start_pos": 165, "end_pos": 173, "type": "METRIC", "confidence": 0.9979534149169922}]}, {"text": "Our main system uses MSA (denoted by MSA afterwards) with vector-based similarities (VEC) as a scoring function.", "labels": [], "entities": [{"text": "vector-based similarities (VEC)", "start_pos": 58, "end_pos": 89, "type": "METRIC", "confidence": 0.6413454353809357}]}, {"text": "The gap costs are optimized for f-score, resulting inc gap = 0.", "labels": [], "entities": []}, {"text": "To show the contribution of MSA's structural component and compare it to the vector model's contribution, we create a second MSA-based system that uses MSA with BLEU scores () as scoring function (MSA+BLEU).", "labels": [], "entities": [{"text": "BLEU scores", "start_pos": 161, "end_pos": 172, "type": "METRIC", "confidence": 0.9716296494007111}, {"text": "BLEU", "start_pos": 201, "end_pos": 205, "type": "METRIC", "confidence": 0.9889612793922424}]}, {"text": "BLEU establishes the average 1-to-4-gram overlap of two sentences.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9583587646484375}]}, {"text": "The gap costs for this baseline were optimized separately, ending up with c gap = 1.", "labels": [], "entities": []}, {"text": "In order to quantify the contribution of the alignment, we create a discourse-unaware baseline by dropping the MSA and using a state-of-the-art clustering algorithm fed with the vector space model scores (CLUSTER+VEC).", "labels": [], "entities": []}, {"text": "The algorithm partitions the set of sentences into paraphrase clusters such that the most similar sentences end up in one cluster.", "labels": [], "entities": []}, {"text": "This does not require any parameter tuning.", "labels": [], "entities": []}, {"text": "We also show a baseline that uses the clustering algorithm with BLEU scores (CLUSTER+BLEU).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 64, "end_pos": 68, "type": "METRIC", "confidence": 0.9983409643173218}, {"text": "BLEU", "start_pos": 85, "end_pos": 89, "type": "METRIC", "confidence": 0.8895882368087769}]}, {"text": "The comparison of this baseline with the other clustering-baseline that uses vector similarities helps to underline the sentence similarities' advantage compared to pure word overlap.", "labels": [], "entities": []}, {"text": "Note that the CLUS-TER+BLEU system resembles popular n-gram overlap measures for paraphrase classification.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 23, "end_pos": 27, "type": "METRIC", "confidence": 0.8738240003585815}, {"text": "paraphrase classification", "start_pos": 81, "end_pos": 106, "type": "TASK", "confidence": 0.8933602273464203}]}, {"text": "We also show the results completely random label assignment, which constitutes a lower bound for the baselines and the system.", "labels": [], "entities": [{"text": "random label assignment", "start_pos": 36, "end_pos": 59, "type": "TASK", "confidence": 0.6465526123841604}]}, {"text": "We also manually evaluate precision on paraphrase fragments, and additionally describe the productivity of the different setups, providing some intuition about the methods' recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.9991280436515808}, {"text": "recall", "start_pos": 173, "end_pos": 179, "type": "METRIC", "confidence": 0.9943716526031494}]}], "tableCaptions": [{"text": " Table 1: Results for sentence matching.", "labels": [], "entities": [{"text": "sentence matching", "start_pos": 22, "end_pos": 39, "type": "TASK", "confidence": 0.7891905009746552}]}, {"text": " Table 2: Results of paraphrase fragment extraction.", "labels": [], "entities": [{"text": "paraphrase fragment extraction", "start_pos": 21, "end_pos": 51, "type": "TASK", "confidence": 0.872346043586731}]}, {"text": " Table 3: Impact of MSA on fragment extraction", "labels": [], "entities": [{"text": "fragment extraction", "start_pos": 27, "end_pos": 46, "type": "TASK", "confidence": 0.8832882642745972}]}]}