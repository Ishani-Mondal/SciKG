{"title": [{"text": "Iterative Annotation Transformation with Predict-Self Reestimation for Chinese Word Segmentation", "labels": [], "entities": [{"text": "Iterative Annotation Transformation", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.6445357302824656}, {"text": "Chinese Word Segmentation", "start_pos": 71, "end_pos": 96, "type": "TASK", "confidence": 0.5420416494210561}]}], "abstractContent": [{"text": "In this paper we first describe the technology of automatic annotation transformation, which is based on the annotation adaptation algorithm (Jiang et al., 2009).", "labels": [], "entities": [{"text": "automatic annotation transformation", "start_pos": 50, "end_pos": 85, "type": "TASK", "confidence": 0.596431722243627}]}, {"text": "It can automatically transform a human-annotated corpus from one annotation guideline to another.", "labels": [], "entities": []}, {"text": "We then propose two optimization strategies, iterative training and predict-self reestimation, to further improve the accuracy of annotation guideline transformation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 118, "end_pos": 126, "type": "METRIC", "confidence": 0.998803973197937}]}, {"text": "Experiments on Chinese word segmentation show that, the iterative training strategy together with predict-self reestimation brings significant improvement over the simple annotation transformation baseline, and leads to classifiers with significantly higher accuracy and several times faster processing than annotation adaptation does.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 15, "end_pos": 40, "type": "TASK", "confidence": 0.5815168023109436}, {"text": "accuracy", "start_pos": 258, "end_pos": 266, "type": "METRIC", "confidence": 0.9958821535110474}]}, {"text": "On the Penn Chinese Treebank 5.0, it achieves an F-measure of 98.43%, significantly outperforms previous works although using a single classifier with only local features .", "labels": [], "entities": [{"text": "Penn Chinese Treebank 5.0", "start_pos": 7, "end_pos": 32, "type": "DATASET", "confidence": 0.9830971658229828}, {"text": "F-measure", "start_pos": 49, "end_pos": 58, "type": "METRIC", "confidence": 0.999645471572876}]}], "introductionContent": [{"text": "Annotation guideline adaptation depicts a general pipeline to integrate the knowledge of corpora with different underling annotation guidelines ().", "labels": [], "entities": [{"text": "Annotation guideline adaptation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.6713079810142517}]}, {"text": "In annotation adaptation two classifiers are cascaded together, where the classification results of the lower classifier are used as guiding features of the upper classifier, in order to achieve more accurate classification.", "labels": [], "entities": []}, {"text": "This method can automatically adapt the divergence between different annotation guidelines and bring improvement to Chinese word segmentation.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 116, "end_pos": 141, "type": "TASK", "confidence": 0.5736080408096313}]}, {"text": "However, the need of cascaded classification decisions makes it less practical for tasks of high computational complexity such as parsing, and less efficient to incorporate more than two annotated corpora.", "labels": [], "entities": [{"text": "parsing", "start_pos": 130, "end_pos": 137, "type": "TASK", "confidence": 0.9748271703720093}]}, {"text": "In this paper, we first describe the algorithm of automatic annotation transformation.", "labels": [], "entities": [{"text": "automatic annotation transformation", "start_pos": 50, "end_pos": 85, "type": "TASK", "confidence": 0.5842265089352926}]}, {"text": "It is based on the annotation adaptation algorithm, and it focuses on the automatic transformation (rather than adaptation) of a human-annotated corpus from one annotation guideline to another.", "labels": [], "entities": []}, {"text": "First, a classifier is trained on the corpus with an annotation guideline not desired, it is used to classify the corpus with the annotation guideline we want, so as to obtain a corpus with parallel annotation guidelines.", "labels": [], "entities": []}, {"text": "Then a second classifier is trained on the parallelly annotated corpus to learn the statistical regularity of annotation transformation, and it is used to process the previous corpus to transform its annotation guideline to that of the target corpus.", "labels": [], "entities": []}, {"text": "Instead of the online knowledge integration methodology of annotation adaptation, annotation transformation can lead to improved classification accuracy in an offline manner by using the transformed corpora as additional training data for the classifier.", "labels": [], "entities": [{"text": "annotation adaptation", "start_pos": 59, "end_pos": 80, "type": "TASK", "confidence": 0.7158491015434265}, {"text": "annotation transformation", "start_pos": 82, "end_pos": 107, "type": "TASK", "confidence": 0.6995322853326797}, {"text": "accuracy", "start_pos": 144, "end_pos": 152, "type": "METRIC", "confidence": 0.8749871850013733}]}, {"text": "This method leads to an enhanced classifier with much faster processing than the cascaded classifiers in annotation adaptation.", "labels": [], "entities": []}, {"text": "We then propose two optimization strategies, iterative training and predict-self reestimation, to further improve the accuracy of annotation transformation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 118, "end_pos": 126, "type": "METRIC", "confidence": 0.9987322688102722}, {"text": "annotation transformation", "start_pos": 130, "end_pos": 155, "type": "TASK", "confidence": 0.7146119624376297}]}, {"text": "Although the transformation classifiers can only be trained on corpora with autogenerated (rather than gold) parallel annotations, an iterative training procedure can gradually improve the trans-formation accuracy by iteratively optimizing the parallelly annotated corpora.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 205, "end_pos": 213, "type": "METRIC", "confidence": 0.9895046949386597}]}, {"text": "Both source-to-target and target-to-source annotation transformations are performed in each training iteration, and the transformed corpora are used to provide better annotations for the parallelly annotated corpora of the next iteration; then the better parallelly annotated corpora will result in more accurate transformation classifiers, which will generate better transformed corpora in the new iteration.", "labels": [], "entities": []}, {"text": "The predict-self reestimation is based on the following hypothesis, a better transformation result should be easier to be transformed back to the original form.", "labels": [], "entities": []}, {"text": "The predict-self heuristic is also validated by in unsupervised dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 64, "end_pos": 82, "type": "TASK", "confidence": 0.7008764445781708}]}, {"text": "Experiments in Chinese word segmentation show that, the iterative training strategy together with predict-self reestimation brings significant improvement over the simple annotation transformation baseline.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 15, "end_pos": 40, "type": "TASK", "confidence": 0.5923940042654673}]}, {"text": "We perform optimized annotation transformation from the People's Daily () to the Penn Chinese Treebank 5.0 (CTB), in order to improve the word segmenter with CTB annotation guideline.", "labels": [], "entities": [{"text": "People's Daily", "start_pos": 56, "end_pos": 70, "type": "DATASET", "confidence": 0.9627149303754171}, {"text": "Penn Chinese Treebank 5.0 (CTB)", "start_pos": 81, "end_pos": 112, "type": "DATASET", "confidence": 0.9710016080311367}, {"text": "word segmenter", "start_pos": 138, "end_pos": 152, "type": "TASK", "confidence": 0.6882888674736023}]}, {"text": "Compared to annotation adaptation, the optimized annotation transformation strategy leads to classifiers with significantly higher accuracy and several times faster processing on the same data sets.", "labels": [], "entities": [{"text": "annotation adaptation", "start_pos": 12, "end_pos": 33, "type": "TASK", "confidence": 0.81263267993927}, {"text": "accuracy", "start_pos": 131, "end_pos": 139, "type": "METRIC", "confidence": 0.9949299693107605}]}, {"text": "On CTB 5.0, it achieves an Fmeasure of 98.43%, significantly outperforms previous works although using a single classifier with only local features.", "labels": [], "entities": [{"text": "CTB 5.0", "start_pos": 3, "end_pos": 10, "type": "DATASET", "confidence": 0.9766916036605835}, {"text": "Fmeasure", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9982433319091797}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the classification-based Chinese word segmentation method.", "labels": [], "entities": [{"text": "classification-based Chinese word segmentation", "start_pos": 24, "end_pos": 70, "type": "TASK", "confidence": 0.6791654899716377}]}, {"text": "Section 3 details the simple annotation transformation algorithm and the two optimization methods.", "labels": [], "entities": [{"text": "annotation transformation", "start_pos": 29, "end_pos": 54, "type": "TASK", "confidence": 0.6677679717540741}]}, {"text": "After the introduction of related works in section 4, we give the experimental results on Chinese word segmentation in section 5.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 90, "end_pos": 115, "type": "TASK", "confidence": 0.5876259704430898}]}], "datasetContent": [{"text": "We perform annotation transformation from People's Daily (PD) () to Penn Chinese Treebank 5.0 (CTB) (), following the same experimental setting as the annotation adaptation work () for convenience of comparison.", "labels": [], "entities": [{"text": "People's Daily (PD)", "start_pos": 42, "end_pos": 61, "type": "DATASET", "confidence": 0.9550106525421143}, {"text": "Penn Chinese Treebank 5.0 (CTB)", "start_pos": 68, "end_pos": 99, "type": "DATASET", "confidence": 0.9667448060853141}]}, {"text": "The two corpora are segmented following different segmentation guidelines and differ largely in quantity of data.", "labels": [], "entities": []}, {"text": "CTB is smaller in size with about 0.5M words, while PD is much larger, containing nearly 6M words.", "labels": [], "entities": [{"text": "CTB", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8192632794380188}, {"text": "PD", "start_pos": 52, "end_pos": 54, "type": "METRIC", "confidence": 0.9290609359741211}]}, {"text": "To approximate more general scenarios of annotation adaptation problems, we extract from PD a subset which is comparable to CTB in size.", "labels": [], "entities": [{"text": "annotation adaptation", "start_pos": 41, "end_pos": 62, "type": "TASK", "confidence": 0.7617139518260956}]}, {"text": "We randomly select 20, 000 sentences (0.45M words) from the PD training data as the new training set, and 1000/1000 sentences from the PD test data as the new test/developing set.", "labels": [], "entities": [{"text": "PD training data", "start_pos": 60, "end_pos": 76, "type": "DATASET", "confidence": 0.7532877524693807}, {"text": "PD test data", "start_pos": 135, "end_pos": 147, "type": "DATASET", "confidence": 0.8076749444007874}]}, {"text": "We name the smaller version of PD as SPD.", "labels": [], "entities": []}, {"text": "The balanced source corpus and target corpus also facilitate the investigation of annotation transformation.", "labels": [], "entities": [{"text": "annotation transformation", "start_pos": 82, "end_pos": 107, "type": "TASK", "confidence": 0.696547195315361}]}], "tableCaptions": [{"text": " Table 3: Data partitioning for CTB and PD.", "labels": [], "entities": [{"text": "Data partitioning", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.6578493565320969}]}, {"text": " Table 4: Performance of the perceptron classifiers for  Chinese word segmentation.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 57, "end_pos": 82, "type": "TASK", "confidence": 0.5910244186719259}]}, {"text": " Table 5: Comparison of the baseline annotation transfor- mation, annotation adaptation and a simple corpus merg- ing strategy.", "labels": [], "entities": []}]}