{"title": [{"text": "Automatically Constructing a Normalisation Dictionary for Microblogs", "labels": [], "entities": [{"text": "Automatically Constructing a Normalisation", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.5902751982212067}, {"text": "Microblogs", "start_pos": 58, "end_pos": 68, "type": "DATASET", "confidence": 0.4722982943058014}]}], "abstractContent": [{"text": "Microblog normalisation methods often utilise complex models and struggle to differentiate between correctly-spelled unknown words and lexical variants of known words.", "labels": [], "entities": [{"text": "Microblog normalisation", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.6988141983747482}]}, {"text": "In this paper, we propose a method for constructing a dictionary of lexical variants of known words that facilitates lexical normalisation via simple string substitution (e.g. tomorrow for tmrw).", "labels": [], "entities": [{"text": "lexical normalisation", "start_pos": 117, "end_pos": 138, "type": "TASK", "confidence": 0.6640104204416275}]}, {"text": "We use context information to generate possible variant and normalisation pairs and then rank these by string similarity.", "labels": [], "entities": []}, {"text": "Highly-ranked pairs are selected to populate the dictionary.", "labels": [], "entities": []}, {"text": "We show that a dictionary-based approach achieves state-of-the-art performance for both F-score and word error rate on a standard dataset.", "labels": [], "entities": [{"text": "F-score", "start_pos": 88, "end_pos": 95, "type": "METRIC", "confidence": 0.9889715313911438}, {"text": "word error rate", "start_pos": 100, "end_pos": 115, "type": "METRIC", "confidence": 0.7054303884506226}]}, {"text": "Compared with other methods, this approach offers a fast, lightweight and easy-to-use solution, and is thus suitable for high-volume microblog pre-processing.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "Given the re-ranked pairs from Section 5, here we apply them to a token-level normalisation task using the normalisation dataset of Han and Baldwin (2011).", "labels": [], "entities": [{"text": "token-level normalisation task", "start_pos": 66, "end_pos": 96, "type": "TASK", "confidence": 0.7331649859746298}]}], "tableCaptions": [{"text": " Table 1: The five best parameter combinations in the exhaustive search of parameter combinations", "labels": [], "entities": []}, {"text": " Table 2: Parameter sensitivity analysis measured as log(CG) for correctly-generated pairs. We tune one parameter at  a time, using the default (underlined) setting for other parameters; the non-exhaustive best-performing setting in each  case is indicated in bold.", "labels": [], "entities": []}, {"text": " Table 3: Normalisation results using our derived dictionaries (contextual similarity (C-dict); double metaphone ren- dering (DM-dict); string subsequence kernel scores (S-dict)), the dictionary of Gouws et al.", "labels": [], "entities": [{"text": "double metaphone ren- dering (DM-dict)", "start_pos": 96, "end_pos": 134, "type": "METRIC", "confidence": 0.8251738846302032}]}, {"text": " Table 5: S-dict normalisation results broken down according to OOV token length. Recall is presented both over the  subset of instances of length \u2265 N in the data (\"Recall (\u2265 N )\"), and over the entirety of the dataset (\"Recall (all)\");  \"#Variants\" is the number of token instances of the indicated length in the test dataset.", "labels": [], "entities": [{"text": "S-dict normalisation", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.827447921037674}]}]}