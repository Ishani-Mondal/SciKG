{"title": [{"text": "A Sequence Labelling Approach to Quote Attribution", "labels": [], "entities": [{"text": "Sequence Labelling Approach", "start_pos": 2, "end_pos": 29, "type": "TASK", "confidence": 0.7176586190859476}, {"text": "Quote Attribution", "start_pos": 33, "end_pos": 50, "type": "TASK", "confidence": 0.7790832817554474}]}], "abstractContent": [{"text": "Quote extraction and attribution is the task of automatically extracting quotes from text and attributing each quote to its correct speaker.", "labels": [], "entities": [{"text": "Quote extraction", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.862275093793869}]}, {"text": "The present state-of-the-art system uses gold standard information from previous decisions in its features, which, when removed, results in a large drop in performance.", "labels": [], "entities": []}, {"text": "We treat the problem as a sequence labelling task, which allows us to incorporate sequence features without using gold standard information.", "labels": [], "entities": [{"text": "sequence labelling task", "start_pos": 26, "end_pos": 49, "type": "TASK", "confidence": 0.7315221627553304}]}, {"text": "We present results on two new corpora and an augmented version of a third, achieving anew state-of-the-art for systems using only realistic features.", "labels": [], "entities": []}], "introductionContent": [{"text": "News stories are often driven by the quotes made by politicians, sports stars, musicians, and celebrities.", "labels": [], "entities": []}, {"text": "When these stories exit the news cycle, the quotes they contain are often forgotten by both readers and journalists.", "labels": [], "entities": []}, {"text": "A system that automatically extracts quotes and attributes those quotes to the correct speaker would enable readers and journalists to place news in the context of all comments made by a person on a given topic.", "labels": [], "entities": []}, {"text": "Though quote attribution may appear to be a straightforward task, the simple rule-based approaches proposed thus far have produced disappointing results.", "labels": [], "entities": [{"text": "quote attribution", "start_pos": 7, "end_pos": 24, "type": "TASK", "confidence": 0.8094808459281921}]}, {"text": "Going beyond these to machine learning approaches presents several problems that make quote attribution surprisingly difficult.", "labels": [], "entities": [{"text": "quote attribution", "start_pos": 86, "end_pos": 103, "type": "TASK", "confidence": 0.877579540014267}]}, {"text": "The main challenge is that while a large portion of quotes can be attributed to a speaker based on simple rules, the remainder have few or no contextual clues as to who the correct speaker is.", "labels": [], "entities": []}, {"text": "Additionally, many quote sequences, such as dialogues, rely on the reader understanding that there is an alternating sequence of speakers, which creates dependencies between attribution decisions made by a classifier. is the only study that directly uses machine learning in quote attribution, treating the task as a classification task, where each quote is attributed independently of other quotes.", "labels": [], "entities": [{"text": "quote attribution", "start_pos": 275, "end_pos": 292, "type": "TASK", "confidence": 0.7156943082809448}]}, {"text": "To handle conversations and similar constructs they use gold standard information about speakers of previous quotes as features for their model.", "labels": [], "entities": []}, {"text": "This is an unrealistic assumption, since gold standard information is not available in practice.", "labels": [], "entities": []}, {"text": "The primary contribution of this paper is that we reformulate quote attribution as a sequence labelling task.", "labels": [], "entities": [{"text": "reformulate quote attribution", "start_pos": 50, "end_pos": 79, "type": "TASK", "confidence": 0.7231009403864542}]}, {"text": "This allows us to use sequence features without having to use the unrealistic gold standard features that were used in.", "labels": [], "entities": []}, {"text": "We experiment with three sequence decoding models including greedy, Viterbi and a linear chain Conditional Random Field (CRF).", "labels": [], "entities": []}, {"text": "Furthermore we present results on two new corpora and an augmented version of a third.", "labels": [], "entities": []}, {"text": "The two new corpora are from news articles from the Wall Street Journal and the Sydney Morning Herald respectively, while the third corpus is an extension to the classic literature corpus from.", "labels": [], "entities": [{"text": "Wall Street Journal and the Sydney Morning Herald", "start_pos": 52, "end_pos": 101, "type": "DATASET", "confidence": 0.8267811834812164}]}, {"text": "Our results show that a quote attribution system using only realistic features is highly feasible for the news domain, with accuracies of 92.4% on the SMH corpus and 84.1% on the WSJ corpus.", "labels": [], "entities": [{"text": "quote attribution", "start_pos": 24, "end_pos": 41, "type": "TASK", "confidence": 0.7409436702728271}, {"text": "accuracies", "start_pos": 124, "end_pos": 134, "type": "METRIC", "confidence": 0.9871538281440735}, {"text": "SMH corpus", "start_pos": 151, "end_pos": 161, "type": "DATASET", "confidence": 0.861748456954956}, {"text": "WSJ corpus", "start_pos": 179, "end_pos": 189, "type": "DATASET", "confidence": 0.9859231412410736}]}], "datasetContent": [{"text": "We use two classifiers: a logistic regression implementation available in LIBLINEAR, and a Conditional Random Field (CRF) from CRFSuite.", "labels": [], "entities": [{"text": "Conditional Random Field (CRF)", "start_pos": 91, "end_pos": 121, "type": "METRIC", "confidence": 0.7147784580787023}, {"text": "CRFSuite", "start_pos": 127, "end_pos": 135, "type": "DATASET", "confidence": 0.9227100610733032}]}, {"text": "Both packages use maximum likelihood estimation with L2 regularisation.", "labels": [], "entities": []}, {"text": "We experimented with several values for the coefficient on a development set, but found that it had little impact, so stuck with the default value.", "labels": [], "entities": []}, {"text": "All of our machine learning experiments use the same text encoding, which is explained below, and all use the category predictions when they are available.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The proportion of quotes in each category and the accuracy of the speaker prediction based on the category.  The two categories marked with an asterisk (*) depend on previous decisions.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9994009733200073}]}, {"text": " Table 2: Accuracy results comparing the E&M approach  with gold standard, predicted or no sequence features.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9988569021224976}]}, {"text": " Table 3: Accuracy on test set with the binary class model. Italicised results indicate gold standard information is used.  Bold results show the best realistic result for each corpus.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9823563694953918}]}, {"text": " Table 4: Accuracy on test set with the n-way class model. Italicised results indicate gold standard information is used.  Bold results show the best realistic result for each corpus.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.986949622631073}]}]}