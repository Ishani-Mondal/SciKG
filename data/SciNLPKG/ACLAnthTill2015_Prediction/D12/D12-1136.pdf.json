{"title": [{"text": "Revisiting the Predictability of Language: Response Completion in Social Media", "labels": [], "entities": []}], "abstractContent": [{"text": "The question \"how predictable is English?\" has long fascinated researchers.", "labels": [], "entities": []}, {"text": "While prior work has focused on formal English typically used in news articles, we turn to texts generated by users in online settings that are more informal in nature.", "labels": [], "entities": []}, {"text": "We are motivated by a novel application scenario: given the difficulty of typing on mobile devices, can we help reduce typing effort with message completion, especially in conversational settings?", "labels": [], "entities": [{"text": "message completion", "start_pos": 138, "end_pos": 156, "type": "TASK", "confidence": 0.7157879620790482}]}, {"text": "We propose a method for automatic response completion.", "labels": [], "entities": [{"text": "automatic response completion", "start_pos": 24, "end_pos": 53, "type": "TASK", "confidence": 0.607155313094457}]}, {"text": "Our approach models both the language used in responses and the specific context provided by the original message.", "labels": [], "entities": []}, {"text": "Our experimental results on a large-scale dataset show that both components help reduce typing effort.", "labels": [], "entities": [{"text": "typing", "start_pos": 88, "end_pos": 94, "type": "TASK", "confidence": 0.9511865377426147}]}, {"text": "We also perform an information-theoretic study in this setting and examine the entropy of user-generated content, especially in conversational scenarios, to better understand predictability of user generated English.", "labels": [], "entities": []}], "introductionContent": [{"text": "As early as 1951, long before large quantities of texts (or the means to process them) were easily available, Shannon had raised this question and proceeded to answer it with a set of clever analytical estimations.", "labels": [], "entities": []}, {"text": "He studied the predictability of printed English, or \"how well can the next letter of a text be predicted when the preceding N letters are known\".", "labels": [], "entities": []}, {"text": "This was quantified as the conditional entropy, which measures the amount of information conveyed from statistics over the preceding context.", "labels": [], "entities": []}, {"text": "In this paper, we discuss a novel application setting which mirrors the predictability study as defined by Shannon.", "labels": [], "entities": []}, {"text": "Text completion for user-generated texts: Consider a user who is chatting with her contact or posting to asocial media site using a mobile device.", "labels": [], "entities": [{"text": "Text completion", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.8113581836223602}]}, {"text": "If we can predict the next word given the preceding words that were already typed in, we can help reduce the typing cost by offering users suggestions of possible completions of their partially typed messages (e.g., in a drop-down list).", "labels": [], "entities": []}, {"text": "If the intended word is ranked reasonably high, the user can select the word instead of typing it.", "labels": [], "entities": []}, {"text": "Assuming a lower cost associated with selections, this could lead to less typing effort for the user.", "labels": [], "entities": []}, {"text": "An interface like this would be quite familiar to Web users today.", "labels": [], "entities": []}, {"text": "Providing suggestions of possible completions to partially typed queries, which we will refer to as query completion, 1 is a common feature of search boxes).", "labels": [], "entities": []}, {"text": "In spite of the similarity in the interface, the underlying technical challenge can be quite different.", "labels": [], "entities": []}, {"text": "Query completion does not necessarily rely on language models: can-didate completions can be limited to popular queries that were previously submitted to the site or entries in a closed database of available objects, and ranking can be done by overall popularity.", "labels": [], "entities": [{"text": "Query completion", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.9213269650936127}]}, {"text": "In contrast, our scenario requires generation of unseen texts.", "labels": [], "entities": []}, {"text": "Given the difficulty of generating full-length text, we consider a more realistic setting, where we perform completion on a word-by-word basis.", "labels": [], "entities": []}, {"text": "Each time, we propose candidate completions at the wordlevel when the user is about to start anew word, or has partially entered the first few letters; once this word is successfully completed, we move onto the next one.", "labels": [], "entities": []}, {"text": "This predict-verify-predict process exactly mirrors the human experiment described by, except we do this at the word-level rather than the letter-level: having the user examine and verify predictions at the letter level would not be a practical solution for the intended application.", "labels": [], "entities": []}, {"text": "The response completion task: In addition, our task has another interesting difference from Shannon's human experiment.", "labels": [], "entities": [{"text": "response completion", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.7592473924160004}]}, {"text": "Consider the mobiledevice user mentioned previously.", "labels": [], "entities": []}, {"text": "If the user is replying to apiece of text (e.g., an instant message sent by a contact), we have an additional source of contextual information in the stimulus, or the text which triggered the response that the user is trying to type.", "labels": [], "entities": []}, {"text": "Can we learn from previously observed stimulus-response pairs (which we will refer to as exchanges)?", "labels": [], "entities": []}, {"text": "That is, can we take advantage of this conversational setting and effectively use the information provided by stimulus to better predict the next word in the response?", "labels": [], "entities": []}, {"text": "We refer to this task as the response completion task.", "labels": [], "entities": [{"text": "response completion task", "start_pos": 29, "end_pos": 53, "type": "TASK", "confidence": 0.7784262299537659}]}, {"text": "Our task is different from \"chatter-bots\", where the goal is to generate a response to an input that would resemble a human conversation partner.", "labels": [], "entities": []}, {"text": "Instead, we want to complete a response as the replier intends to.", "labels": [], "entities": []}, {"text": "Recently, Ritter et. al (2011) experimented with automatic response generation in social media.", "labels": [], "entities": [{"text": "automatic response generation", "start_pos": 49, "end_pos": 78, "type": "TASK", "confidence": 0.6247903108596802}]}, {"text": "They had a similar conversational setting, but instead of completion based on partial input, they attempted to generate a response in its entirety given only the stimulus.", "labels": [], "entities": []}, {"text": "While many of the generated responses are deemed possible replies to the stimulus, they have a low chance of actually matching the real response given by the user: they reported BLEU scores between 0 and 2 for various systems.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 178, "end_pos": 182, "type": "METRIC", "confidence": 0.9993491768836975}]}, {"text": "This clearly shows the difficulty of the task.", "labels": [], "entities": []}, {"text": "While we are addressing a more modest setting, would the problem prove to be too difficult even in this case?", "labels": [], "entities": []}, {"text": "In this paper, we propose a method for automatic response completion.", "labels": [], "entities": [{"text": "automatic response completion", "start_pos": 39, "end_pos": 68, "type": "TASK", "confidence": 0.5857217311859131}]}, {"text": "Our approach models the generic language used in responses, as well as the contextual information provided by the stimulus.", "labels": [], "entities": []}, {"text": "We construct a large-scale dataset of usergenerated textual exchanges, and our experimental results show that both components help reduce typing effort.", "labels": [], "entities": []}, {"text": "In addition, to better understand predictability of user generated English, we perform an information-theoretic study in this conversational setting to investigate the entropy of user-generated content.", "labels": [], "entities": []}], "datasetContent": [{"text": "Recall@k : Here, we follow a standard evaluation strategy used to assess ranking quality in information retrieval applications.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 92, "end_pos": 113, "type": "TASK", "confidence": 0.7656073272228241}]}, {"text": "For each word, we check if the correct answer is one of the top-k tokens being suggested.", "labels": [], "entities": []}, {"text": "We then compute the recall at different values of k.", "labels": [], "entities": [{"text": "recall", "start_pos": 20, "end_pos": 26, "type": "METRIC", "confidence": 0.9992151260375977}]}, {"text": "While this is a straight-forward measure to assess the overall quality of different top-k lists, it is not tailored to suit our specific task of response completion.", "labels": [], "entities": [{"text": "response completion", "start_pos": 145, "end_pos": 164, "type": "TASK", "confidence": 0.7876278758049011}]}, {"text": "In particular, this measure (a) does not distinguish between (typing) savings fora short word versus along one, and (b) does not distinguish between the correct answer being higher up in the list versus lower as long as the word is present in the top-k list.", "labels": [], "entities": []}, {"text": "TypRed : Our main evaluation measure is based on \"reduction in typing effort fora user of the system\", which is a more informative measure for our task.", "labels": [], "entities": [{"text": "TypRed", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9381940960884094}]}, {"text": "We estimate the typing reduction via a hypothetical typing model 3 in the following manner: Suppose we show top k predictions fora given setting.", "labels": [], "entities": []}, {"text": "Now, there are two possible scenarios: 1.", "labels": [], "entities": []}, {"text": "if the user does not find the correct answer in the top-k list, he/she gives upon this word and will have to type the entire word.", "labels": [], "entities": []}, {"text": "The typing cost is then estimated to be the number of characters in the word l w ; 2.", "labels": [], "entities": []}, {"text": "if the user spots the correct answer in the list, the cost for choosing the word is proportional to the rank of the word rank w , with a fixed cost ratio c 0 . Suppose the user scrolls down the list using the down-arrow (\u2193) to reach the intended word (instead of typing), then rank w \u00b7 c 0 reflects the scrolling effort required, where c 0 is the relative cost of scrolling down versus typing a character.", "labels": [], "entities": []}, {"text": "In general, pressing a fixed key can have a lower cost than typing anew one, in addition, we can imagine a virtual keyboard where navigational keys occupy bigger real-estate, and thus incur less cost to press.", "labels": [], "entities": []}, {"text": "As a result, it's reasonable to assume c 0 value that is smaller than 1.", "labels": [], "entities": []}, {"text": "In all our experiments, c 0 = 0.5 unless otherwise noted.", "labels": [], "entities": []}, {"text": "Note that if the typing model assumes a user selects the intended word using an interface that is similar to a mousing device, the cost may increase with rank w at a sublinear rate; in that case, our measure will be overestimating the cost.", "labels": [], "entities": []}, {"text": "In order to have a consistent measure that always improves as the ranking improves, we assume a clever user who will choose to finish the word by typing or by selecting, depending on which cost is lower.", "labels": [], "entities": []}, {"text": "Combining these two cases under the cleveruser model, we estimate the reduction in typing cost for every word as follows: where w is the correct word, l w is the length of w, and rank w is the rank of win the top-k list.", "labels": [], "entities": []}, {"text": "A higher value of TypRed implies higher savings achieved in typing cost and thereby better prediction performance.", "labels": [], "entities": [{"text": "TypRed", "start_pos": 18, "end_pos": 24, "type": "DATASET", "confidence": 0.7437257170677185}]}, {"text": "We run experiments using the models described in Section 3 under two different settings: (1) previous words from the response are provided, and (2) previous words from response + first c characters of the current word are provided.", "labels": [], "entities": []}, {"text": "During the candidate generation phase, for every position in the response message we present the top 1,000 candidates (as scored by the generic response language model or mixture models).", "labels": [], "entities": [{"text": "candidate generation", "start_pos": 11, "end_pos": 31, "type": "TASK", "confidence": 0.755225419998169}]}, {"text": "We reserve a small subset of (\u223c1,000) exchanges as development data for tuning parameters from our models.", "labels": [], "entities": []}, {"text": "For the generic response language models, we set the interpolation weight \u03bb 1 = 0.9.", "labels": [], "entities": [{"text": "interpolation weight \u03bb 1", "start_pos": 53, "end_pos": 77, "type": "METRIC", "confidence": 0.8825763314962387}]}, {"text": "For the selection-based mixture model, we estimate the mixture weights on the training data and set \u03bb select (0.09).", "labels": [], "entities": []}, {"text": "For the topic-based mixture model, we ran a grid search with different parameter settings for \u03bb topic on the held-out development set and chose the value (0.01) that gave the best performance (in terms of TypRed).", "labels": [], "entities": [{"text": "TypRed", "start_pos": 205, "end_pos": 211, "type": "METRIC", "confidence": 0.5423710346221924}]}], "tableCaptions": [{"text": " Table 1: Comparison of various prediction models (in terms of TypRed score @ rank 5) on all (stimulus,response)  pairs from a large test collection (218,263 exchanges) when the first c characters of each word are typed in by the user.  A higher score indicates better performance.  *  indicates statistical significance (p < 0.05) over the baseline score.", "labels": [], "entities": [{"text": "TypRed score", "start_pos": 63, "end_pos": 75, "type": "METRIC", "confidence": 0.7569896578788757}]}, {"text": " Table 2: Comparison of typing reductions achieved over  the entire test data when top k list is provided to the user.", "labels": [], "entities": []}]}