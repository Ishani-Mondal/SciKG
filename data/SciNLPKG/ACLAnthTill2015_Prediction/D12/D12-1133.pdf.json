{"title": [{"text": "A Transition-Based System for Joint Part-of-Speech Tagging and Labeled Non-Projective Dependency Parsing", "labels": [], "entities": [{"text": "Joint Part-of-Speech Tagging", "start_pos": 30, "end_pos": 58, "type": "TASK", "confidence": 0.6897404591242472}, {"text": "Labeled Non-Projective Dependency Parsing", "start_pos": 63, "end_pos": 104, "type": "TASK", "confidence": 0.6245951503515244}]}], "abstractContent": [{"text": "Most current dependency parsers presuppose that input words have been morphologically disambiguated using a part-of-speech tagger before parsing begins.", "labels": [], "entities": [{"text": "dependency parsers presuppose", "start_pos": 13, "end_pos": 42, "type": "TASK", "confidence": 0.7960634231567383}]}, {"text": "We present a transition-based system for joint part-of-speech tagging and labeled dependency parsing with non-projective trees.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 47, "end_pos": 69, "type": "TASK", "confidence": 0.7151008546352386}, {"text": "labeled dependency parsing", "start_pos": 74, "end_pos": 100, "type": "TASK", "confidence": 0.628805677096049}]}, {"text": "Experimental evaluation on Chinese, Czech, English and German shows consistent improvements in both tagging and parsing accuracy when compared to a pipeline system, which lead to improved state-of-the-art results for all languages.", "labels": [], "entities": [{"text": "parsing", "start_pos": 112, "end_pos": 119, "type": "TASK", "confidence": 0.9417316317558289}, {"text": "accuracy", "start_pos": 120, "end_pos": 128, "type": "METRIC", "confidence": 0.9555872082710266}]}], "introductionContent": [{"text": "Dependency-based syntactic parsing has been the focus of intense research efforts during the last decade, and the state of the art today is represented by globally normalized discriminative models that are induced using structured learning.", "labels": [], "entities": [{"text": "Dependency-based syntactic parsing", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.7423087358474731}]}, {"text": "Graphbased models parameterize the parsing problem by the structure of the dependency graph and normally use dynamic programming for inference, but other inference methods have been explored especially for non-projective parsing (.", "labels": [], "entities": [{"text": "parsing problem", "start_pos": 35, "end_pos": 50, "type": "TASK", "confidence": 0.9176110625267029}]}, {"text": "Transitionbased models parameterize the problem by elementary parsing actions and typically use incremental beam search.", "labels": [], "entities": []}, {"text": "Despite notable differences in model structure, graph-based and transition-based parsers both give state-of-theart accuracy with proper feature selection and optimization (.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 115, "end_pos": 123, "type": "METRIC", "confidence": 0.9945423603057861}]}, {"text": "It is noteworthy, however, that almost all dependency parsers presuppose that the words of an input sentence have been morphologically disambiguated using (at least) a part-of-speech tagger.", "labels": [], "entities": []}, {"text": "This is in stark contrast to the best parsers based on PCFG models, such as the Brown parser) and the Berkeley parser (, which not only can perform their own part-of-speech tagging but normally give better parsing accuracy when they are allowed to do so.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 158, "end_pos": 180, "type": "TASK", "confidence": 0.6967580318450928}, {"text": "accuracy", "start_pos": 214, "end_pos": 222, "type": "METRIC", "confidence": 0.9166578054428101}]}, {"text": "This suggests that joint models for tagging and parsing might improve accuracy also in the case of dependency parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 48, "end_pos": 55, "type": "TASK", "confidence": 0.9296900033950806}, {"text": "accuracy", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.9988111257553101}, {"text": "dependency parsing", "start_pos": 99, "end_pos": 117, "type": "TASK", "confidence": 0.7954193651676178}]}, {"text": "It has been argued that joint morphological and syntactic disambiguation is especially important for richly inflected languages, where there is considerable interaction between morphology and syntax such that neither can be fully disambiguated without considering the other.", "labels": [], "entities": [{"text": "syntactic disambiguation", "start_pos": 48, "end_pos": 72, "type": "TASK", "confidence": 0.7270674705505371}]}, {"text": "Thus, show that a discriminative model for joint morphological disambiguation and dependency parsing outperforms a pipeline model in experiments on Latin, Ancient Greek, Czech and Hungarian.", "labels": [], "entities": [{"text": "joint morphological disambiguation", "start_pos": 43, "end_pos": 77, "type": "TASK", "confidence": 0.6135572691758474}, {"text": "dependency parsing", "start_pos": 82, "end_pos": 100, "type": "TASK", "confidence": 0.7273023724555969}]}, {"text": "However, and report improvements with a joint model also for Chinese, which is not a richly inflected language but is nevertheless rich in part-of-speech ambiguities.", "labels": [], "entities": []}, {"text": "In this paper, we present a transition-based model for joint part-of-speech tagging and labeled dependency parsing with non-projective trees.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 61, "end_pos": 83, "type": "TASK", "confidence": 0.6664299815893173}, {"text": "labeled dependency parsing", "start_pos": 88, "end_pos": 114, "type": "TASK", "confidence": 0.621849000453949}]}, {"text": "Exper-iments show that joint modeling improves both tagging and parsing accuracy, leading to state-of-the-art accuracy for richly inflected languages like Czech and German as well as more configurational languages like Chinese and English.", "labels": [], "entities": [{"text": "tagging", "start_pos": 52, "end_pos": 59, "type": "TASK", "confidence": 0.9599219560623169}, {"text": "parsing", "start_pos": 64, "end_pos": 71, "type": "TASK", "confidence": 0.8976469039916992}, {"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9300358295440674}, {"text": "accuracy", "start_pos": 110, "end_pos": 118, "type": "METRIC", "confidence": 0.9968710541725159}]}, {"text": "To our knowledge, this is the first joint system that performs labeled dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 71, "end_pos": 89, "type": "TASK", "confidence": 0.668849304318428}]}, {"text": "It is also the first joint system that achieves state-of-the-art accuracy for non-projective dependency parsing.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9980827569961548}, {"text": "non-projective dependency parsing", "start_pos": 78, "end_pos": 111, "type": "TASK", "confidence": 0.6543035308519999}]}], "datasetContent": [{"text": "We have evaluated the model for joint tagging and dependency parsing on four typologically diverse languages: Chinese, Czech, English, and German.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 50, "end_pos": 68, "type": "TASK", "confidence": 0.7622380256652832}]}], "tableCaptions": [{"text": " Table 1: Accuracy scores for the CoNLL 2009 shared task development sets as a function of the number of tags k and  the score threshold \u03b1. Beam parameters fixed at b 1 = 40, b 2 = 4.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9991229176521301}, {"text": "CoNLL 2009 shared task development sets", "start_pos": 34, "end_pos": 73, "type": "DATASET", "confidence": 0.9131823976834615}]}, {"text": " Table 2: Accuracy scores for the CoNLL 2009 shared task test sets. Rows 1-2: Top performing systems in the shared  CoNLL Shared Task 2009; Gesmundo et al. (2009) was placed first in the shared task; for Bohnet", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9990567564964294}, {"text": "CoNLL 2009 shared task test sets", "start_pos": 34, "end_pos": 66, "type": "DATASET", "confidence": 0.9023316701253256}, {"text": "CoNLL Shared Task 2009", "start_pos": 116, "end_pos": 138, "type": "DATASET", "confidence": 0.7745285183191299}, {"text": "Bohnet", "start_pos": 204, "end_pos": 210, "type": "DATASET", "confidence": 0.6524051427841187}]}, {"text": " Table 3: Accuracy scores for WSJ-PTB converted with  head rules of Yamada and Matsumoto (2003) and labeling  rules of Nivre (2006). Best dev setting: k = 3, \u03b1 = 0.4.  Results marked with  \u2020 use additional information sources  and are not directly comparable to the others.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9993483424186707}, {"text": "WSJ-PTB", "start_pos": 30, "end_pos": 37, "type": "DATASET", "confidence": 0.7927289009094238}]}, {"text": " Table 4: Accuracy scores for Penn Chinese Treebank  converted with the head rules of Zhang and Clark (2008).  Best dev setting: k = 3, \u03b1 = 0.1. MSTParser results from  Li et al. (2011). UAS scores from Li et al. (2011) and Ha- tori et al. (2011) recalculated from the separate accuracy  scores for root words and non-root words reported in the  original papers.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9982938170433044}, {"text": "Penn Chinese Treebank", "start_pos": 30, "end_pos": 51, "type": "DATASET", "confidence": 0.9802101850509644}, {"text": "MSTParser", "start_pos": 145, "end_pos": 154, "type": "DATASET", "confidence": 0.6649582982063293}, {"text": "UAS", "start_pos": 187, "end_pos": 190, "type": "METRIC", "confidence": 0.8470228910446167}, {"text": "accuracy", "start_pos": 278, "end_pos": 286, "type": "METRIC", "confidence": 0.9973662495613098}]}]}