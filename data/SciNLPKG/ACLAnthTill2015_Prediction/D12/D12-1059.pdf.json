{"title": [{"text": "Concurrent Acquisition of Word Meaning and Lexical Categories", "labels": [], "entities": [{"text": "Concurrent Acquisition of Word Meaning", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.5505482196807862}]}], "abstractContent": [{"text": "Learning the meaning of words from ambiguous and noisy context is a challenging task for language learners.", "labels": [], "entities": [{"text": "Learning the meaning of words from ambiguous and noisy context", "start_pos": 0, "end_pos": 62, "type": "TASK", "confidence": 0.8438748896121979}]}, {"text": "It has been suggested that children draw on syntactic cues such as lexical categories of words to constrain potential ref-erents of words in a complex scene.", "labels": [], "entities": []}, {"text": "Although the acquisition of lexical categories should be interleaved with learning word meanings, it has not previously been modeled in that fashion.", "labels": [], "entities": []}, {"text": "In this paper, we investigate the interplay of word learning and category induction by integrating an LDA-based word class learning module with a probabilistic word learning model.", "labels": [], "entities": [{"text": "word learning", "start_pos": 47, "end_pos": 60, "type": "TASK", "confidence": 0.775642454624176}, {"text": "category induction", "start_pos": 65, "end_pos": 83, "type": "TASK", "confidence": 0.7050539553165436}]}, {"text": "Our results show that the incremen-tally induced word classes significantly improve word learning, and their contribution is comparable to that of manually assigned part of speech categories.", "labels": [], "entities": [{"text": "word learning", "start_pos": 84, "end_pos": 97, "type": "TASK", "confidence": 0.7736179828643799}]}], "introductionContent": [], "datasetContent": [{"text": "As training data, we extract utterances from the Manchester corpus () in the CHILDES database (MacWhinney 1995), a corpus that contains transcripts of conversations with children between the ages of 1 year, 8 months and 3 years.", "labels": [], "entities": [{"text": "Manchester corpus", "start_pos": 49, "end_pos": 66, "type": "DATASET", "confidence": 0.9923126101493835}, {"text": "CHILDES database (MacWhinney 1995)", "start_pos": 77, "end_pos": 111, "type": "DATASET", "confidence": 0.9442993303140005}]}, {"text": "We use the mother's speech from transcripts of 12 children (henceforth referred to by children's names).", "labels": [], "entities": []}, {"text": "We run word class induction while simultaneously outputting the highest scoring word-class label for each word: fora new sentence, we sample class assignments for each feature (doing J passes), update the counts, and then for each word d ti output the highest scoring class label according to argmax z n z,dt it (where n z,dt it stands for the number of times class z co-occurred with word type d ti up to step t).", "labels": [], "entities": [{"text": "word class induction", "start_pos": 7, "end_pos": 27, "type": "TASK", "confidence": 0.6756502588589987}]}, {"text": "During development we ran the online word class induction module on data for Aran, Becky, Carl and Anne and then started the word learning module for the Anne portion while continuing inducing categories.", "labels": [], "entities": [{"text": "word class induction", "start_pos": 37, "end_pos": 57, "type": "TASK", "confidence": 0.6874227523803711}]}, {"text": "We then evaluated word learning on Anne.", "labels": [], "entities": [{"text": "word learning", "start_pos": 18, "end_pos": 31, "type": "TASK", "confidence": 0.8612667918205261}]}, {"text": "We chose the parameters of the word class induction module based on those development results: K 1=1 \u03b1 = 10, \u03b2 = 0.1, K = 10 and J = 20.", "labels": [], "entities": []}, {"text": "We used cross-validation for the final evaluation.", "labels": [], "entities": []}, {"text": "For each of six data files (Anne, Aran, Becky, Carl, Dominic and Gail), we ran word-class induction on the whole corpus with the chosen file last, and then started applying the word-learning algorithm on this last chosen file (while continuing with category induction).", "labels": [], "entities": [{"text": "category induction", "start_pos": 249, "end_pos": 267, "type": "TASK", "confidence": 0.7039360404014587}]}, {"text": "We evaluated how well word meanings were learned in those six cases.", "labels": [], "entities": []}, {"text": "We follow in the construction of the input.", "labels": [], "entities": []}, {"text": "We need a semantic representation paired with each utterance.", "labels": [], "entities": []}, {"text": "Such a representation is not available from the corpus and has to be constructed.", "labels": [], "entities": []}, {"text": "We automatically construct a gold lexicon for all nouns and verbs in this corpus as follows.", "labels": [], "entities": []}, {"text": "For each word, we extract all hypernyms for its first sense in the appropriate (verb or noun) hierarchy in WordNet, and add the first word in the synset of each hypernym to the set of semantic features for the target word.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 107, "end_pos": 114, "type": "DATASET", "confidence": 0.9506956934928894}]}, {"text": "For verbs, we also extract features from VerbNet ().", "labels": [], "entities": [{"text": "VerbNet", "start_pos": 41, "end_pos": 48, "type": "DATASET", "confidence": 0.9234251976013184}]}, {"text": "A small subset of words (pronouns and frequent quantifiers) are also manually added.", "labels": [], "entities": []}, {"text": "This lexicon represents the true meaning of each word, and is used in generating the scene representations in the input and in evaluation.", "labels": [], "entities": []}, {"text": "For each utterance in the input corpus, we form the union of the feature representations of all its words.", "labels": [], "entities": []}, {"text": "Words not found in the lexicon (i.e. for which we could not extract a semantic representation from WordNet and VerbNet) are removed from the utterance (only for the word learning module).", "labels": [], "entities": [{"text": "WordNet", "start_pos": 99, "end_pos": 106, "type": "DATASET", "confidence": 0.9429623484611511}]}, {"text": "In order to simulate the high level of noise that children receive from their environment, we follow and pair each utterance with a combination of its own scene representation and the scene representation for the following utterance.", "labels": [], "entities": []}, {"text": "This decision was based on the intuition that consequent utterances are more likely to be about re-Utterance: { mommy, ate, broccoli } Scene: { ANIMATE, HUMAN, ..., CONSUMPTION, ACTION, ...", "labels": [], "entities": [{"text": "ANIMATE", "start_pos": 144, "end_pos": 151, "type": "METRIC", "confidence": 0.9809936285018921}, {"text": "HUMAN", "start_pos": 153, "end_pos": 158, "type": "METRIC", "confidence": 0.8666818141937256}, {"text": "CONSUMPTION", "start_pos": 165, "end_pos": 176, "type": "METRIC", "confidence": 0.7757280468940735}]}, {"text": "}: A sample input item to the word learning model lated topics and scenes.", "labels": [], "entities": []}, {"text": "This results in a (roughly) 200% ambiguity.", "labels": [], "entities": []}, {"text": "In addition, we remove the meaning of one random word from the scene representation of every second utterance in an attempt to simulate cases where the referent of an uttered word is not within the perception field (such as 'daddy is not home yet').", "labels": [], "entities": []}, {"text": "A sample utterance and its corresponding scene are shown in.", "labels": [], "entities": []}, {"text": "As mentioned before, many words in our input corpus are polysemous.", "labels": [], "entities": []}, {"text": "For such words, we extract different sets of features depending on their manually tagged part of speech and keep them in the lexicon (e.g. the lexicon contains two different entries for set:N and set:V).", "labels": [], "entities": []}, {"text": "When constructing a scene representation for an utterance which contains an ambiguous word, we choose the correct sense from our lexicon according to the word's part of speech tag in Manchester corpus.", "labels": [], "entities": [{"text": "Manchester corpus", "start_pos": 183, "end_pos": 200, "type": "DATASET", "confidence": 0.9863927364349365}]}, {"text": "In the experiments reported in the next section, we assess the performance of our model on learning words at each point in time: for each target word, we compare its set of features in the lexicon with its probability distribution over the semantic features that the model has learned.", "labels": [], "entities": []}, {"text": "We use mean average precision (MAP) to measure how well p (t) (\u00b7|w) ranks the features of w.", "labels": [], "entities": [{"text": "mean average precision (MAP)", "start_pos": 7, "end_pos": 35, "type": "METRIC", "confidence": 0.9151501456896464}]}], "tableCaptions": [{"text": " Table 3: Final Mean Average Precision scores", "labels": [], "entities": [{"text": "Mean Average Precision", "start_pos": 16, "end_pos": 38, "type": "METRIC", "confidence": 0.7807850241661072}]}]}