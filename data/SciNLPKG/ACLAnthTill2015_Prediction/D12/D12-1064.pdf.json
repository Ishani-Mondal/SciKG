{"title": [{"text": "Exploring Adaptor Grammars for Native Language Identification", "labels": [], "entities": [{"text": "Native Language Identification", "start_pos": 31, "end_pos": 61, "type": "TASK", "confidence": 0.6837132175763448}]}], "abstractContent": [{"text": "The task of inferring the native language of an author based on texts written in a second language has generally been tackled as a classification problem, typically using as features a mix of n-grams over characters and part of speech tags (for small and fixed n) and un-igram function words.", "labels": [], "entities": []}, {"text": "To capture arbitrarily long n-grams that syntax-based approaches have suggested are useful, adaptor grammars have some promise.", "labels": [], "entities": []}, {"text": "In this work we investigate their extension to identifying n-gram col-locations of arbitrary length over a mix of PoS tags and words, using both maxent and induced syntactic language model approaches to classification.", "labels": [], "entities": []}, {"text": "After presenting anew, simple baseline, we show that learned collocations used as features in a maxent model perform better still, but that the story is more mixed for the syntactic language model.", "labels": [], "entities": []}], "introductionContent": [{"text": "The task of inferring the native language of an author based on texts written in a second language -native language identification (NLI) -has, since the seminal work of, been primarily tackled as a text classification task using supervised machine learning techniques.", "labels": [], "entities": [{"text": "inferring the native language of an author based on texts written in a second language -native language identification (NLI)", "start_pos": 12, "end_pos": 136, "type": "TASK", "confidence": 0.7897003157572313}, {"text": "text classification task", "start_pos": 198, "end_pos": 222, "type": "TASK", "confidence": 0.7704736292362213}]}, {"text": "Lexical features, such as function words, character n-grams, and part-ofspeech (PoS) n-grams, have been proven to be useful in NLI (.", "labels": [], "entities": []}, {"text": "The recent work of , motivated by ideas from Second Language Acquisition (SLA), has shown that syntactic features -potentially capturing syntactic errors characteristic of a particular native languageimprove performance over purely lexical ones.", "labels": [], "entities": [{"text": "Second Language Acquisition (SLA)", "start_pos": 45, "end_pos": 78, "type": "TASK", "confidence": 0.7791201770305634}]}, {"text": "PoS n-grams can be leveraged to characterise surface syntactic structures: in, for example, ungrammatical structures were approximated by rare PoS bigrams.", "labels": [], "entities": []}, {"text": "For the purpose of NLI, small n-gram sizes like bigram or trigram might not suffice to capture sequences that are characteristic of a particular native language.", "labels": [], "entities": []}, {"text": "On the other hand, an attempt to represent these with larger n-grams would not just lead to feature sparsity problems, but also computational efficiency issues.", "labels": [], "entities": []}, {"text": "Some form of feature selection should then come into play.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 13, "end_pos": 30, "type": "TASK", "confidence": 0.6533174067735672}]}, {"text": "Adaptor grammars, a hierarchical non-parametric extension of PCFGs (and also interpretable as an extension of LDA-based topic models), holdout some promise here.", "labels": [], "entities": []}, {"text": "In that initial work, Johnson's model learnt collocations of arbitrary length such as gradient descent and cost function, under a topic associated with machine learning.", "labels": [], "entities": []}, {"text": "applied this idea to perspective classification, learning collocations such as palestinian violence and palestinian freedom, the use of which as features was demonstrated to help the classification of texts from the Bitter Lemons corpus as either Palestinian or Israeli perspective.", "labels": [], "entities": [{"text": "perspective classification", "start_pos": 21, "end_pos": 47, "type": "TASK", "confidence": 0.7841703295707703}]}, {"text": "Typically in NLI and other authorship attribution tasks, the feature sets exclude content words, to avoid unfair cues due to potentially different domains of discourse.", "labels": [], "entities": []}, {"text": "In our context, then, what we are interested in are 'quasi-syntactic collocations' of either pure PoS (e.g. NN IN NN) or a mixture of PoS with function words (e.g. NN of NN).", "labels": [], "entities": []}, {"text": "The particular question of interest for this paper, then, is to investigate whether the power of adaptor grammars to discover collocations -specifically, ones of arbitrary length that are useful for classification -extends to features beyond the purely lexical.", "labels": [], "entities": []}, {"text": "We examine two different approaches in this paper.", "labels": [], "entities": []}, {"text": "We first utilise adaptor grammars for discovery of high performing 'quasi-syntactic collocations' of arbitrary length as mentioned above and use them as classification features in a conventional maximum entropy (maxent) model for identifying the author's native language.", "labels": [], "entities": []}, {"text": "In the second approach, we adopt a grammar induction technique to learn a grammarbased language model in a Bayesian setting.", "labels": [], "entities": [{"text": "grammar induction", "start_pos": 35, "end_pos": 52, "type": "TASK", "confidence": 0.7063217908143997}]}, {"text": "The grammar learned can then be used to infer the most probable native language that a given text written in a second language is associated with.", "labels": [], "entities": []}, {"text": "The latter approach is actually closer to the work of using adaptor grammars for perspective modeling, which inspired our general approach.", "labels": [], "entities": [{"text": "perspective modeling", "start_pos": 81, "end_pos": 101, "type": "TASK", "confidence": 0.7742744088172913}]}, {"text": "This alternative approach is also similar in nature to the in which grounded learning of semantic parsers was reduced to a grammatical inference task.", "labels": [], "entities": []}, {"text": "The structure of the paper is as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we review the existing work of NLI as well as the mechanics of adaptor grammars along with their applications to classification.", "labels": [], "entities": []}, {"text": "Section 3 details the supervised maxent classification of NLI with collocation (n-gram) features discovered by adaptor grammars.", "labels": [], "entities": []}, {"text": "The language model-based classifier is described in Section 4.", "labels": [], "entities": []}, {"text": "Finally, we present a discussion in Section 5 and follow with concluding remarks.", "labels": [], "entities": []}], "datasetContent": [{"text": "The classification experiments are conducted on the second version of ICLE ().", "labels": [], "entities": [{"text": "ICLE", "start_pos": 70, "end_pos": 74, "type": "DATASET", "confidence": 0.822218656539917}]}, {"text": "Following our earlier NLI work in , our data set consists of 490 texts written in English by authors of seven different native language groups: Bulgarian, Czech, French, Russian, Spanish, Chinese, and Japanese.", "labels": [], "entities": []}, {"text": "Each native language contributes 70 out of the 490 texts.", "labels": [], "entities": []}, {"text": "As we are using a relative small data set, we perform k-fold cross-validation, choosing k = 5.", "labels": [], "entities": []}, {"text": "As we are using the same data set as per the previous approach, we perform 5-fold cross validation as well.", "labels": [], "entities": []}, {"text": "However, the training for each fold is conducted with a different grammar consisting of only the vocabulary that occur in each training fold.", "labels": [], "entities": []}, {"text": "The reason is that we are now having a form of supervised topic models where the learning process is guided by the native languages.", "labels": [], "entities": []}, {"text": "Hence, each of the training sentences are prefixed with the (native) language identifiers lang, as seen in the Root rules of the grammar presented above.", "labels": [], "entities": []}, {"text": "To evaluate the grammars learned, as in B\u00f6rschinger et al.", "labels": [], "entities": []}, {"text": "(2011) we need to slightly modify the grammars above by removing the language identifiers ( lang) from the Root rules and then parse the unlabeled sentences using a publicly available CKY parser.", "labels": [], "entities": []}, {"text": "The predicted native language is inferred from the parse output by reading off the langT opics that the Root is rewritten to.", "labels": [], "entities": []}, {"text": "We take that as the most probable native language fora particular test sentence.", "labels": [], "entities": []}, {"text": "At the document level, we select as the class the language predicted for the largest number of sentences in that document.", "labels": [], "entities": []}, {"text": "present the parsing results at the sentence level and the document level, respectively.", "labels": [], "entities": []}, {"text": "On the whole, the results at the sentence level are much poorer as compared to those at the document level.", "labels": [], "entities": []}, {"text": "In light of the results of Section 3.2, it is surprising   that bigram models appear to perform better than ngram models for both types of vocabulary, with the exception of AG-POS+FW at the document level.", "labels": [], "entities": []}, {"text": "In fact, one would expect n-gram models to perform better in general as it is a generalisation that would contain all the potential bigrams.", "labels": [], "entities": []}, {"text": "Nonetheless, the language models over the mixture of PoS and function words appear to be a more suitable representative of our learner corpus as compared to those over purely PoS, confirming the usefulness of integrated function words for the NLI classification task.", "labels": [], "entities": [{"text": "NLI classification task", "start_pos": 243, "end_pos": 266, "type": "TASK", "confidence": 0.8992555936177572}]}, {"text": "It should also be noted that sparse priors generally appear to be more appriopriate; except that for AG-POS+FW n-grams, uniform priors are indeed better and resulted in the highest parsing result of 50.15.", "labels": [], "entities": []}, {"text": "(Although all the parsing results are much weaker as compared to the results presented in Section 3.2, they are all higher than the majority baseline of 14.29% i.e. 70/490).", "labels": [], "entities": [{"text": "parsing", "start_pos": 18, "end_pos": 25, "type": "TASK", "confidence": 0.9672311544418335}, {"text": "490", "start_pos": 168, "end_pos": 171, "type": "METRIC", "confidence": 0.8775424957275391}]}], "tableCaptions": [{"text": " Table 1: Maxent classification results for individual fea- ture sets (with 5-fold cross validation).", "labels": [], "entities": [{"text": "Maxent classification", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.8550617396831512}]}, {"text": " Table 3: Language modeling-based classification results  based on parsing (at the sentence level).", "labels": [], "entities": [{"text": "Language modeling-based classification", "start_pos": 10, "end_pos": 48, "type": "TASK", "confidence": 0.7735418180624644}]}, {"text": " Table 4: Language modeling-based classification results  based on parsing (at the document level).", "labels": [], "entities": [{"text": "Language modeling-based classification", "start_pos": 10, "end_pos": 48, "type": "TASK", "confidence": 0.7586882611115774}]}, {"text": " Table 5: Confusion matrix based on the best performing  model under maxent setting (BL:Bulgarian, CZ:Czech,  RU:Russian, FR:French, SP:Spanish, CN:Chinese,  JP:Japanese).", "labels": [], "entities": [{"text": "BL", "start_pos": 85, "end_pos": 87, "type": "METRIC", "confidence": 0.971342921257019}]}, {"text": " Table 6:  Confusion matrix based on the best  performing model under language modeling setting  (BL:Bulgarian, CZ:Czech, RU:Russian, FR:French,  SP:Spanish, CN:Chinese, JP:Japanese).", "labels": [], "entities": [{"text": "BL", "start_pos": 98, "end_pos": 100, "type": "METRIC", "confidence": 0.9557910561561584}]}, {"text": " Table 8: Distribution of n-grams (collocations) for each topic under language modeling setting. (a) subcolumns are  for n-grams of pure PoS and (b) subcolumns are for n-grams of mixtures of PoS and function words.", "labels": [], "entities": []}, {"text": " Table 9: Distribution of n-grams (collocations) for each topic under maxent setting. (a) subcolumns are for n-grams  of pure PoS and (b) subcolumns are for n-grams of mixtures of PoS and function words.", "labels": [], "entities": []}]}