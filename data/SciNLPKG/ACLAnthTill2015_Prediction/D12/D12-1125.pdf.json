{"title": [{"text": "Learning to Map into a Universal POS Tagset", "labels": [], "entities": [{"text": "POS Tagset", "start_pos": 33, "end_pos": 43, "type": "DATASET", "confidence": 0.6141226440668106}]}], "abstractContent": [{"text": "We present an automatic method for mapping language-specific part-of-speech tags to a set of universal tags.", "labels": [], "entities": []}, {"text": "This unified representation plays a crucial role in cross-lingual syntactic transfer of multilingual dependency parsers.", "labels": [], "entities": [{"text": "cross-lingual syntactic transfer of multilingual dependency parsers", "start_pos": 52, "end_pos": 119, "type": "TASK", "confidence": 0.6187276286738259}]}, {"text": "Until now, however, such conversion schemes have been created manually.", "labels": [], "entities": []}, {"text": "Our central hypothesis is that a valid mapping yields POS annotations with coherent linguistic properties which are consistent across source and target languages.", "labels": [], "entities": []}, {"text": "We encode this intuition in an objective function that captures a range of distributional and typological characteristics of the derived mapping.", "labels": [], "entities": []}, {"text": "Given the exponential size of the mapping space, we propose a novel method for optimizing over soft mappings, and use entropy regularization to drive those towards hard mappings.", "labels": [], "entities": []}, {"text": "Our results demonstrate that automatically induced mappings rival the quality of their manually designed counterparts when evaluated in the context of multilingual parsing.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this paper, we explore an automatic method for mapping language-specific part-of-speech tags to a universal tagset.", "labels": [], "entities": []}, {"text": "In multilingual parsing, this unified input representation is required for cross-lingual syntactic transfer.", "labels": [], "entities": [{"text": "multilingual parsing", "start_pos": 3, "end_pos": 23, "type": "TASK", "confidence": 0.6217129230499268}, {"text": "cross-lingual syntactic transfer", "start_pos": 75, "end_pos": 107, "type": "TASK", "confidence": 0.6981196304162344}]}, {"text": "Specifically, the universal tagset annotations enable an unlexicalized parser to capitalize on annotations from one language when learning a model for another.", "labels": [], "entities": []}, {"text": "While the notion of a universal POS tagset is widely accepted, in practice it is hardly ever used for annotation of monolingual resources.", "labels": [], "entities": []}, {"text": "In fact, available POS annotations are designed to capture language-specific idiosyncrasies and therefore are substantially more detailed than a coarse universal tagset.", "labels": [], "entities": []}, {"text": "To reconcile these cross-lingual annotation differences, a number of mapping schemes have been proposed in the parsing community.", "labels": [], "entities": [{"text": "parsing", "start_pos": 111, "end_pos": 118, "type": "TASK", "confidence": 0.9638269543647766}]}, {"text": "In all of these cases, the conversion is performed manually and has to be repeated for each language and annotation scheme anew.", "labels": [], "entities": []}, {"text": "Despite the apparent simplicity, deriving a mapping is by no means easy, even for humans.", "labels": [], "entities": []}, {"text": "In fact, the universal tagsets manually induced by  and by disagree on 10% of the tags.", "labels": [], "entities": []}, {"text": "An example of such discrepancy is the mapping of the Japanese tag \"PVfin\" to the universal tag \"particle\" according to one scheme, and to \"verb\" according to another.", "labels": [], "entities": []}, {"text": "Moreover, the quality of this conversion has a direct implication on the parsing performance.", "labels": [], "entities": [{"text": "parsing", "start_pos": 73, "end_pos": 80, "type": "TASK", "confidence": 0.9719335436820984}]}, {"text": "In the Japanese example above, this difference in mapping yields a 6.7% difference in parsing accuracy.", "labels": [], "entities": [{"text": "parsing", "start_pos": 86, "end_pos": 93, "type": "TASK", "confidence": 0.9662588238716125}, {"text": "accuracy", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.9510338306427002}]}, {"text": "The goal of our work is to induce the mapping fora new language, utilizing existing manuallyconstructed mappings as training data.", "labels": [], "entities": []}, {"text": "The existing mappings developed in the parsing community rely on gold POS tags for the target language.", "labels": [], "entities": []}, {"text": "A more realistic scenario is to employ the mapping technique to resource-poor languages where gold POS annotations are lacking.", "labels": [], "entities": []}, {"text": "In such cases, a mapping algorithm has to operate over automatically in-duced clusters on the target language (e.g., using the Brown algorithm) and convert them to universal tags.", "labels": [], "entities": []}, {"text": "We are interested in a mapping approach that can effectively handle both gold tags and induced clusters.", "labels": [], "entities": []}, {"text": "Our central hypothesis is that a valid mapping yields POS annotations with coherent linguistic properties which are consistent across languages.", "labels": [], "entities": []}, {"text": "Since universal tags play the same linguistic role in source and target languages, we expect similarity in their global distributional statistics.", "labels": [], "entities": [{"text": "similarity", "start_pos": 93, "end_pos": 103, "type": "METRIC", "confidence": 0.9826186895370483}]}, {"text": "shows statistics for two close languages, English and German.", "labels": [], "entities": []}, {"text": "We can see that their unigram frequencies on the five most common tags are very close.", "labels": [], "entities": []}, {"text": "Other properties concern POS tag per sentence statisticse.g., every sentence has to have at least one verb.", "labels": [], "entities": [{"text": "POS tag", "start_pos": 25, "end_pos": 32, "type": "METRIC", "confidence": 0.7749759554862976}]}, {"text": "Finally, the mappings can be further constrained by typological properties of the target language that specify likely tag sequences.", "labels": [], "entities": []}, {"text": "This information is readily available even for resource poor language).", "labels": [], "entities": []}, {"text": "For instance, since English and German are prepositional languages, we expect to observe adposition-noun sequences but not the reverse (see for sample sentences).", "labels": [], "entities": []}, {"text": "We encode these heterogeneous properties into an objective function that guides the search for the optimal mapping.", "labels": [], "entities": []}, {"text": "Having defined a quality measure for mappings, our goal is to find the optimal mapping.", "labels": [], "entities": []}, {"text": "However, such partition optimization problems 2 are NP hard (.", "labels": [], "entities": [{"text": "partition optimization", "start_pos": 14, "end_pos": 36, "type": "TASK", "confidence": 0.7330960929393768}]}, {"text": "A naive approach to the problem is to greedily improve the map, but it turns out that this approach yields poor quality mappings.", "labels": [], "entities": []}, {"text": "We therefore develop a method for optimizing over soft mappings, and use entropy regularization to drive those towards hard mappings.", "labels": [], "entities": []}, {"text": "We construct the objective in away that facilitates simple monotonically improving updates corresponding to solving convex optimization problems.", "labels": [], "entities": []}, {"text": "We evaluate our mapping approach on 19 languages that include representatives of IndoEuropean, Semitic, Basque, Japonic and Turkic families.", "labels": [], "entities": []}, {"text": "We measure mapping quality based on the target language parsing accuracy.", "labels": [], "entities": [{"text": "language parsing", "start_pos": 47, "end_pos": 63, "type": "TASK", "confidence": 0.6747931838035583}, {"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.5895641446113586}]}, {"text": "In addition to considering gold POS tags for the target language, we also evaluate the mapping algorithm on automatically induced POS tags.", "labels": [], "entities": []}, {"text": "In all evaluation scenarios, our model consistently rivals the quality of manually induced mappings.", "labels": [], "entities": []}, {"text": "We also demonstrate that the proposed inference procedure outperforms greedy methods by a large margin, highlighting the importance of good optimization techniques.", "labels": [], "entities": []}, {"text": "We further show that while all characteristics of the mapping contribute to the objective, our largest gain comes from distributional features that capture global statistics.", "labels": [], "entities": []}, {"text": "Finally, we establish that the mapping quality has a significant impact on the accuracy of syntactic transfer, which motivates further study of this topic.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.9988480806350708}, {"text": "syntactic transfer", "start_pos": 91, "end_pos": 109, "type": "TASK", "confidence": 0.826936811208725}]}], "datasetContent": [{"text": "Datasets We test our model on 19 languages: Arabic, Basque, Bulgarian, Catalan, Chinese, Czech, Danish, Dutch, English, German, Greek, Hungarian, Italian, Japanese, Portuguese, Slovene, Spanish, Swedish, and Turkish.", "labels": [], "entities": []}, {"text": "Our data is taken from the CoNLL 2006 and 2007 shared tasks).", "labels": [], "entities": [{"text": "CoNLL 2006 and 2007 shared tasks", "start_pos": 27, "end_pos": 59, "type": "DATASET", "confidence": 0.9206700623035431}]}, {"text": "The CoNLL datasets consist of manually created dependency trees and language-specific POS tags.", "labels": [], "entities": [{"text": "CoNLL datasets", "start_pos": 4, "end_pos": 18, "type": "DATASET", "confidence": 0.9290154278278351}]}, {"text": "Following , our model maps these language-specific tags to a set of 12 universal tags: noun, verb, adjective, adverb, pronoun, determiner, adposition, numeral, conjunction, particle, punctuation mark and X (a general tag).", "labels": [], "entities": [{"text": "X", "start_pos": 204, "end_pos": 205, "type": "METRIC", "confidence": 0.9608858227729797}]}, {"text": "Ties are broken using the F (A) objective.", "labels": [], "entities": [{"text": "F (A) objective", "start_pos": 26, "end_pos": 41, "type": "METRIC", "confidence": 0.8849797368049621}]}, {"text": "Evaluation Procedure We perform a separate experiment for each of the 19 languages as the target and a source language chosen from the rest (using the method from Section 5.3).", "labels": [], "entities": []}, {"text": "For the selected source language, we assume access to the mapping of .  We evaluate the quality of the derived mapping in the context of the target language parsing accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 165, "end_pos": 173, "type": "METRIC", "confidence": 0.8306096196174622}]}, {"text": "In both the training and test data, the language-specific tags are replaced with universal tags: Petrov's tags for the source languages and learned tags for the target language.", "labels": [], "entities": []}, {"text": "We train two non-lexicalized parsers using source annotations and apply them to the target language.", "labels": [], "entities": []}, {"text": "The first parser is a non-lexicalized version of the MST parser ( ) successfully used in the multilingual context ).", "labels": [], "entities": []}, {"text": "In the second parser, parameters of the target language are estimated as a weighted mixture of parameters learned from supervised source languages).", "labels": [], "entities": []}, {"text": "For the parser of, we trained the model on the four languages used in the original paper -English, German, Czech and Italian.", "labels": [], "entities": []}, {"text": "When measuring the performance on each of these four languages, we selected another set of four languages with a similar level of diversity.", "labels": [], "entities": []}, {"text": "Following the standard evaluation practice in parsing, we use directed dependency accuracy as our measure of performance.", "labels": [], "entities": [{"text": "parsing", "start_pos": 46, "end_pos": 53, "type": "TASK", "confidence": 0.983995258808136}, {"text": "accuracy", "start_pos": 82, "end_pos": 90, "type": "METRIC", "confidence": 0.862621545791626}]}, {"text": "Baselines We compare mappings induced by our model against three baselines: the manually constructed mapping of , a randomly constructed mapping and a greedy mapping.", "labels": [], "entities": []}, {"text": "The greedy mapping uses the same objective as our full model, but optimizes it using a greedy method.", "labels": [], "entities": []}, {"text": "In each iteration, this method makes |L T | passes over the language-specific tags, selecting a substitution that contributes the most to the objective.", "labels": [], "entities": []}, {"text": "Initialization To reduce the dimension of our algorithm's search space and speedup our method, we start by clustering the language-specific POS tags of the target into |K| = 12 clusters using an unsuper- We also experimented with aversion of the Cohen et al.", "labels": [], "entities": []}, {"text": "(2011) model trained on all the source languages.", "labels": [], "entities": []}, {"text": "This set-up resulted in decreased performance.", "labels": [], "entities": []}, {"text": "For this reason, we chose to train the model on the four languages.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Directed dependency accuracy of our model and the baselines using gold POS tags for the target language.  The first section of the table is for the direct transfer of the MST parser (McDonald et al., 2011). The second section  is for the weighted mixture parsing model (Cohen et al., 2011). The first two columns (Random and Greedy) of each  section present the parsing performance with a random or a greedy mapping. The third column (Petrov) shows the  results when the mapping of Petrov et al. (2011) is used. The fourth column (Model) shows the results when our  mapping is used and the fifth column in the first section (Best Pair) shows the performance of our model when the best  source language is selected for every target language. The last column (Tag Diff.) presents the difference between our  mapping and the mapping of Petrov et al. (2011) by showing the percentage of target language tokens for which the  two mappings select a different universal tag.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9605309963226318}]}]}