{"title": [{"text": "Improving Transition-Based Dependency Parsing with Buffer Transitions", "labels": [], "entities": [{"text": "Improving Transition-Based Dependency Parsing", "start_pos": 0, "end_pos": 45, "type": "TASK", "confidence": 0.9012753665447235}]}], "abstractContent": [{"text": "In this paper, we show that significant improvements in the accuracy of well-known transition-based parsers can be obtained, without sacrificing efficiency, by enriching the parsers with simple transitions that act on buffer nodes.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.998909592628479}]}, {"text": "First, we show how adding a specific transition to create either a left or right arc of length one between the first two buffer nodes produces improvements in the accuracy of Nivre's arc-eager projective parser on a number of datasets from the CoNLL-X shared task.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 163, "end_pos": 171, "type": "METRIC", "confidence": 0.9993818998336792}, {"text": "CoNLL-X shared task", "start_pos": 244, "end_pos": 263, "type": "DATASET", "confidence": 0.6923774282137553}]}, {"text": "Then, we show that accuracy can also be improved by adding transitions involving the topmost stack node and the second buffer node (allowing a limited form of non-projectivity).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9990893602371216}]}, {"text": "None of these transitions has a negative impact on the computational complexity of the algorithm.", "labels": [], "entities": []}, {"text": "Although the experiments in this paper use the arc-eager parser, the approach is generic enough to be applicable to any stack-based dependency parser.", "labels": [], "entities": []}], "introductionContent": [{"text": "Dependency parsing has become a very active research area in natural language processing in recent years.", "labels": [], "entities": [{"text": "Dependency parsing", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9124486148357391}, {"text": "natural language processing", "start_pos": 61, "end_pos": 88, "type": "TASK", "confidence": 0.6463242967923483}]}, {"text": "The dependency representation of syntax simplifies the syntactic parsing task, since no non-lexical nodes need to be postulated by the parsers; while being convenient in practice, since dependency representations directly show the headmodifier and head-complement relationships which form the basis of predicate-argument structure.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 55, "end_pos": 72, "type": "TASK", "confidence": 0.7006900012493134}]}, {"text": "This has led to the development of various data-driven dependency parsers, such as those by,,,, or, which can be trained directly from annotated data and produce accurate analyses very efficiently.", "labels": [], "entities": []}, {"text": "Most current data-driven dependency parsers can be classified into two families, commonly called graph-based and transition-based parsers).", "labels": [], "entities": []}, {"text": "Graph-based parsers) are based on global optimization of models that work by scoring subtrees.", "labels": [], "entities": []}, {"text": "On the other hand, transition-based parsers), which are the focus of this work, use local training to make greedy decisions that deterministically select the next parser state.", "labels": [], "entities": []}, {"text": "Among the advantages of transition-based parsers are the linear time complexity of many of them and the possibility of using rich feature models ().", "labels": [], "entities": []}, {"text": "In particular, many transition-based parsers ( are stack-based, meaning that they keep a stack of partially processed tokens and an input buffer of unread tokens.", "labels": [], "entities": []}, {"text": "In this paper, we show how the accuracy of this kind of parsers can be improved, without compromising efficiency, by extending their set of available transitions with buffer transitions.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9993392825126648}]}, {"text": "These are transitions that create a dependency arc involving some node in the buffer, which would typically be considered unavailable for linking by these algo-rithms.", "labels": [], "entities": []}, {"text": "The rationale is that buffer transitions construct some \"easy\" dependency arcs in advance, before the involved nodes reach the stack, so that the classifier's job when choosing among standard transitions is simplified.", "labels": [], "entities": []}, {"text": "To test the approach, we use the well-known arceager parser by) as a baseline, showing improvements inaccuracy on most datasets of the CoNLL-X shared task).", "labels": [], "entities": []}, {"text": "However, the techniques discussed in this paper are generic and can also be applied to other stack-based dependency parsers.", "labels": [], "entities": []}, {"text": "The rest of this paper is structured as follows: Section 2 is an introduction to transition-based parsers and the arc-eager parsing algorithm.", "labels": [], "entities": []}, {"text": "Section 3 presents the first novel contribution of this paper, projective buffer transitions, and discusses their empirical results on CoNLL-X datasets.", "labels": [], "entities": [{"text": "CoNLL-X datasets", "start_pos": 135, "end_pos": 151, "type": "DATASET", "confidence": 0.9083570241928101}]}, {"text": "Section 4 does the same fora more complex set of transitions, non-projective buffer transitions.", "labels": [], "entities": []}, {"text": "Finally, Section 5 discusses related work and Section 6 sums up the conclusions and points out avenues for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate the impact of non-projective buffer transitions on parsing accuracy by using the same baseticular subset of non-projective structures captured by each such parser.", "labels": [], "entities": [{"text": "parsing", "start_pos": 63, "end_pos": 70, "type": "TASK", "confidence": 0.9700718522071838}, {"text": "accuracy", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.9593271613121033}]}, {"text": "line parser, datasets and experimental settings as for projective buffer transitions in Section 3.2.", "labels": [], "entities": [{"text": "line parser", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.7001583725214005}]}, {"text": "As can be seen in, adding a non-projective buffer transition to the arc-eager parser improves its performance on all eight datasets.", "labels": [], "entities": []}, {"text": "The improvements in LAS are statistically significant at the .01 level (Dan Bikel's comparator) for Chinese, Czech and Turkish.", "labels": [], "entities": [{"text": "LAS", "start_pos": 20, "end_pos": 23, "type": "METRIC", "confidence": 0.9375859498977661}, {"text": "Dan Bikel's comparator", "start_pos": 72, "end_pos": 94, "type": "DATASET", "confidence": 0.7077816128730774}]}, {"text": "Note that the Chinese treebank is fully projective, this means that non-projective buffer transitions are also beneficial when creating projective arcs.", "labels": [], "entities": [{"text": "Chinese treebank", "start_pos": 14, "end_pos": 30, "type": "DATASET", "confidence": 0.8081607520580292}]}, {"text": "While with projective buffer transitions we observed that each of them was beneficial for about half of the treebanks, and we related this to the amount of leftward and rightward links of length 1 in each; in the case of non-projective buffer transitions we do not observe this tendency.", "labels": [], "entities": []}, {"text": "In this case, LEFT-NONPROJ-BUFFER-ARC works better than RIGHT-NONPROJ-BUFFER-ARC in all datasets except for Turkish and Arabic.", "labels": [], "entities": [{"text": "LEFT-NONPROJ-BUFFER-ARC", "start_pos": 14, "end_pos": 37, "type": "METRIC", "confidence": 0.9961532950401306}, {"text": "RIGHT-NONPROJ-BUFFER-ARC", "start_pos": 56, "end_pos": 80, "type": "METRIC", "confidence": 0.9280813336372375}]}, {"text": "As with the projective transitions, we gathered data about the individual precision of each of the transitions.", "labels": [], "entities": [{"text": "precision", "start_pos": 74, "end_pos": 83, "type": "METRIC", "confidence": 0.9809650778770447}]}, {"text": "The results were similar to those for the projective transitions, and show that adding a non-projective buffer transition improves the precision of the standard transitions.", "labels": [], "entities": [{"text": "precision", "start_pos": 135, "end_pos": 144, "type": "METRIC", "confidence": 0.9990836381912231}]}, {"text": "We also experimentally checked that adding both non-projective buffer transitions at the same time (NE+LNBA+RNBA) achieved worse performance than adding only the most suitable transition for each dataset.", "labels": [], "entities": [{"text": "RNBA", "start_pos": 108, "end_pos": 112, "type": "METRIC", "confidence": 0.8629231452941895}]}, {"text": "compares the performance of the arceager parser with the best non-projective buffer transition for each dataset with the results obtained by   the parser with the pseudo-projective transformation by in the CoNLL-X shared task.", "labels": [], "entities": []}, {"text": "Note that, like the one in, this should not be interpreted as a homogeneous comparison.", "labels": [], "entities": []}, {"text": "We can see that the algorithm with non-projective buffer transitions obtains better LAS in five out of the eight treebanks.", "labels": [], "entities": [{"text": "LAS", "start_pos": 84, "end_pos": 87, "type": "METRIC", "confidence": 0.9711138606071472}]}, {"text": "Precision and recall data on projective and non-projective arcs show that, while our parser does not capture as many non-projective arcs as the pseudo-projective transformation (unsurprisingly, as it can only build non-projective arcs in one direction: that of the particular non-projective buffer transition used for each dataset); it does so with greater precision and is more accurate than that algorithm in projective arcs.", "labels": [], "entities": [{"text": "recall", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9988627433776855}, {"text": "precision", "start_pos": 357, "end_pos": 366, "type": "METRIC", "confidence": 0.9984569549560547}]}, {"text": "Like projective buffer transitions, non-projective transitions do not increase the computational complexity of stack-based parsers.", "labels": [], "entities": []}, {"text": "The observed training and parsing times for the arc-eager parser with non-projective buffer transitions showed a small overhead with respect to the original arc-eager (7.1% average increase in training time, 17.0% in parsing time).", "labels": [], "entities": [{"text": "parsing", "start_pos": 26, "end_pos": 33, "type": "TASK", "confidence": 0.9696439504623413}]}, {"text": "For comparison, running the arceager parser with the pseudo-projective transformation () on the same machine produced a 23.5% increase in training time and a 87.5% increase in parsing time.", "labels": [], "entities": [{"text": "parsing", "start_pos": 176, "end_pos": 183, "type": "TASK", "confidence": 0.9732224345207214}]}], "tableCaptions": [{"text": " Table 1: Parsing accuracy (LAS and UAS, excluding punctuation) of Nivre's arc-eager parser without modification  (NE), with the LEFT-BUFFER-ARC transition added (NE+LBA) and with the RIGHT-BUFFER-ARC transition added  (NE+RBA). Best results for each language are shown in boldface.", "labels": [], "entities": [{"text": "Parsing", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.8601646423339844}, {"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9429425001144409}, {"text": "LEFT-BUFFER-ARC", "start_pos": 129, "end_pos": 144, "type": "METRIC", "confidence": 0.97735995054245}, {"text": "RBA", "start_pos": 223, "end_pos": 226, "type": "METRIC", "confidence": 0.7792671918869019}]}, {"text": " Table 2: Analysis of the datasets used in the experiments  in terms of: percentage of leftward and rightward links  (L%, R%), percentage of leftward and rightward links  of length 1 (L1%, R1%), and which projective buffer  transition works better for each dataset according to the  results in Table 1 (LBA = LEFT-BUFFER-ARC, RBA  = RIGHT-BUFFER-ARC). Languages where both tran- sitions are beneficial (Czech) or harmful (Swedish) are  marked with an asterisk.", "labels": [], "entities": [{"text": "RBA  = RIGHT-BUFFER-ARC", "start_pos": 326, "end_pos": 349, "type": "METRIC", "confidence": 0.8038631280263265}]}, {"text": " Table 3: Labelled precision of the arcs built by each transition of Nivre's arc-eager parser without modification (NE),  with a projective buffer transition added (NE+LBA, NE+RBA) and with both projective buffer transitions added  (NE+LBA+RBA). We mark a standard LEFT-ARC (LA) or RIGHT-ARC (LA) transition with an asterisk (LA*, RA*)  when it is acting only on a \"hard\" subset of leftward (rightward) arcs, and thus its precision is not directly comparable  to that of (LA, RA). Best results for each language and transition are shown in boldface.", "labels": [], "entities": [{"text": "precision", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.9760105609893799}, {"text": "precision", "start_pos": 422, "end_pos": 431, "type": "METRIC", "confidence": 0.9983372688293457}]}, {"text": " Table 3. As we can see, projec- tive buffer transitions achieve better precision than  standard transitions, but this is not surprising since  they act only on \"easy\" arcs of length 1. There- fore, this high precision does not mean that they ac- tually build arcs more accurately than the standard  transitions, since it is not measured on the same set  of arcs. Similarly, adding a projective buffer tran- sition decreases the precision of its corresponding  standard transition, but this is because the standard  transition is then dealing only with \"harder\" arcs of  length greather than 1, not because it is making more  errors. A more interesting insight comes from com- paring transitions that are acting on the same tar- get set of arcs: we see that, in the languages where  LEFT-BUFFER-ARC is beneficial, the addition of  this transition always improves the precision of the  standard RIGHT-ARC transition; and the converse  happens with RIGHT-BUFFER-ARC with respect to  LEFT-ARC. This further backs the hypothesis that  the filtering of \"easy\" links achieved by projective  buffer transitions makes it easier for the classifier to  decide among standard transitions.", "labels": [], "entities": [{"text": "precision", "start_pos": 72, "end_pos": 81, "type": "METRIC", "confidence": 0.9934394955635071}, {"text": "precision", "start_pos": 429, "end_pos": 438, "type": "METRIC", "confidence": 0.9985847473144531}, {"text": "precision", "start_pos": 867, "end_pos": 876, "type": "METRIC", "confidence": 0.9916261434555054}]}, {"text": " Table 5: Comparison of the Arabic and Danish LAS ob- tained by the arc-eager parser with projective buffer tran- sitions in comparison to other parsers in the literature that  report results on these datasets.", "labels": [], "entities": []}, {"text": " Table 7: Comparison of the parsing accuracy (LAS  and UAS, excluding punctuation) of Nivre's arc- eager parser with non-projective buffer transitions  (NE+LNBA/RNBA) and the parser with the pseudo- projective transformation (Nivre et al., 2006).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.7386195063591003}, {"text": "LAS", "start_pos": 46, "end_pos": 49, "type": "METRIC", "confidence": 0.9767792820930481}, {"text": "UAS", "start_pos": 55, "end_pos": 58, "type": "METRIC", "confidence": 0.9599692821502686}]}, {"text": " Table 8: Comparison of the precision and recall for pro- jective (PP, PR) and non-projective (NP, NR) arcs, av- eraged over all datasets, obtained by Nivre's arc-eager  parser with and without non-projective buffer transitions  (NE+LNBA/RNBA, NE) and the parser with the pseudo- projective transformation (Nivre et al., 2006).", "labels": [], "entities": [{"text": "precision", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.998980700969696}, {"text": "recall", "start_pos": 42, "end_pos": 48, "type": "METRIC", "confidence": 0.9986912608146667}]}]}