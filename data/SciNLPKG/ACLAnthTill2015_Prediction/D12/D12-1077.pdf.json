{"title": [{"text": "Inducing a Discriminative Parser to Optimize Machine Translation Reordering", "labels": [], "entities": [{"text": "Machine Translation Reordering", "start_pos": 45, "end_pos": 75, "type": "TASK", "confidence": 0.7954466541608175}]}], "abstractContent": [{"text": "This paper proposes a method for learning a discriminative parser for machine translation reordering using only aligned parallel text.", "labels": [], "entities": [{"text": "machine translation reordering", "start_pos": 70, "end_pos": 100, "type": "TASK", "confidence": 0.827226479848226}]}, {"text": "This is done by treating the parser's derivation tree as a latent variable in a model that is trained to maximize reordering accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 125, "end_pos": 133, "type": "METRIC", "confidence": 0.9595852494239807}]}, {"text": "We demonstrate that efficient large-margin training is possible by showing that two measures of reordering accuracy can be factored over the parse tree.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 107, "end_pos": 115, "type": "METRIC", "confidence": 0.9574552178382874}]}, {"text": "Using this model in the pre-ordering framework results in significant gains in translation accuracy over standard phrase-based SMT and previously proposed unsu-pervised syntax induction methods.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.9131837487220764}, {"text": "SMT", "start_pos": 127, "end_pos": 130, "type": "TASK", "confidence": 0.7739847302436829}]}], "introductionContent": [{"text": "Finding the appropriate word ordering in the target language is one of the most difficult problems for statistical machine translation (SMT), particularly for language pairs with widely divergent syntax.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 103, "end_pos": 140, "type": "TASK", "confidence": 0.8039268602927526}]}, {"text": "As a result, there is a large amount of previous research that handles the problem of reordering through the use of improved reordering models for phrase-based SMT ( ), hierarchical phrase-based translation, syntax-based translation (), or preordering ().", "labels": [], "entities": [{"text": "SMT", "start_pos": 160, "end_pos": 163, "type": "TASK", "confidence": 0.6912256479263306}, {"text": "phrase-based translation", "start_pos": 182, "end_pos": 206, "type": "TASK", "confidence": 0.6671113967895508}]}, {"text": "In particular, systems that use sourcelanguage syntax allow for the handling of longdistance reordering without large increases in The first author is now affiliated with the Nara Institute of decoding time.", "labels": [], "entities": [{"text": "Nara Institute", "start_pos": 175, "end_pos": 189, "type": "DATASET", "confidence": 0.8468165099620819}]}, {"text": "However, these require a good syntactic parser, which is not available for many languages.", "labels": [], "entities": []}, {"text": "In recent work, DeNero and Uszkoreit (2011) suggest that unsupervised grammar induction can be used to create source-sentence parse structure for use in translation as apart of a pre-ordering based translation system.", "labels": [], "entities": [{"text": "source-sentence parse structure", "start_pos": 110, "end_pos": 141, "type": "TASK", "confidence": 0.7974435488382975}]}, {"text": "In this work, we present a method for inducing a parser for SMT by training a discriminative model to maximize reordering accuracy while treating the parse tree as a latent variable.", "labels": [], "entities": [{"text": "SMT", "start_pos": 60, "end_pos": 63, "type": "TASK", "confidence": 0.9934492707252502}, {"text": "accuracy", "start_pos": 122, "end_pos": 130, "type": "METRIC", "confidence": 0.9602859616279602}]}, {"text": "As a learning framework, we use online large-margin methods to train the model to directly minimize two measures of reordering accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 127, "end_pos": 135, "type": "METRIC", "confidence": 0.8846370577812195}]}, {"text": "We propose a variety of features, and demonstrate that learning can succeed when no linguistic information (POS tags or parse structure) is available in the source language, but also show that this linguistic information can be simply incorporated when it is available.", "labels": [], "entities": []}, {"text": "Experiments find that the proposed model improves both reordering and translation accuracy, leading to average gains of 1.2 BLEU points on English-Japanese and Japanese-English translation without linguistic analysis tools, or up to 1.5 BLEU points when these tools are incorporated.", "labels": [], "entities": [{"text": "translation", "start_pos": 70, "end_pos": 81, "type": "TASK", "confidence": 0.9485151171684265}, {"text": "accuracy", "start_pos": 82, "end_pos": 90, "type": "METRIC", "confidence": 0.9590451717376709}, {"text": "BLEU", "start_pos": 124, "end_pos": 128, "type": "METRIC", "confidence": 0.9985028505325317}, {"text": "BLEU", "start_pos": 237, "end_pos": 241, "type": "METRIC", "confidence": 0.9984984397888184}]}, {"text": "In addition, we show that our model is able to effectively maximize various measures of reordering accuracy, and that the reordering measure that we choose has a direct effect on translation results.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 99, "end_pos": 107, "type": "METRIC", "confidence": 0.8979151248931885}]}], "datasetContent": [{"text": "Our experiments test the reordering and translation accuracy of translation systems using the proposed method.", "labels": [], "entities": [{"text": "translation", "start_pos": 40, "end_pos": 51, "type": "TASK", "confidence": 0.9222971200942993}, {"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.8690851330757141}]}, {"text": "As reordering metrics, we use Kendall's \u03c4 and chunk fragmentation (Talbot et al., 2011) comparing the system F and oracle F calculated with manually created alignments.", "labels": [], "entities": []}, {"text": "As translation metrics, we use BLEU (), as well as RIBES (, which is similar to Kendall's \u03c4 , but evaluated on the target sentence E instead of the reordered sentence F . All scores are the average of three training runs to control for randomness in training).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 31, "end_pos": 35, "type": "METRIC", "confidence": 0.9990503191947937}, {"text": "RIBES", "start_pos": 51, "end_pos": 56, "type": "METRIC", "confidence": 0.9969210624694824}]}, {"text": "For translation, we use Moses () with lexicalized reordering ( ) in all experiments.", "labels": [], "entities": [{"text": "translation", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.9869639277458191}]}, {"text": "We test three types  of pre-ordering: original order with F \u2190 F (orig), pre-orderings learned using the 3-step process of DeNero and Uszkoreit (2011), and the proposed model with latent derivations (lader).", "labels": [], "entities": []}, {"text": "7 Except when stated otherwise, lader was trained to minimize chunk fragmentation loss with a cube pruning stack pop limit of 50, and the regularization constant of 10 \u22123 (chosen through cross-validation).", "labels": [], "entities": []}, {"text": "We test our systems on Japanese-English and English-Japanese translation using data from the Kyoto Free Translation Task.", "labels": [], "entities": [{"text": "English-Japanese translation", "start_pos": 44, "end_pos": 72, "type": "TASK", "confidence": 0.7232109308242798}, {"text": "Kyoto Free Translation Task", "start_pos": 93, "end_pos": 120, "type": "DATASET", "confidence": 0.848323330283165}]}, {"text": "We use the training set for training translation and language models, the development set for weight tuning, and the test set for testing.", "labels": [], "entities": [{"text": "training translation and language models", "start_pos": 28, "end_pos": 68, "type": "TASK", "confidence": 0.7936872005462646}, {"text": "weight tuning", "start_pos": 94, "end_pos": 107, "type": "TASK", "confidence": 0.6284357905387878}]}, {"text": "We use the designated development and test sets of manually created alignments as training data for the reordering models, removing sentences of more than 60 words.", "labels": [], "entities": []}, {"text": "As default features for lader and the monolingual parsing and reordering models in 3-step, we use all the features described in Section 5. 7 Available open-source: http://phontron.com/lader except \u03c6 pos and \u03c6 cf g . In addition, we test systems with \u03c6 pos and \u03c6 cf gadded.", "labels": [], "entities": []}, {"text": "For English, we use the Stanford parser ( for both POS tagging and CFG parsing.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 51, "end_pos": 62, "type": "TASK", "confidence": 0.6918235570192337}, {"text": "CFG parsing", "start_pos": 67, "end_pos": 78, "type": "TASK", "confidence": 0.7993302941322327}]}, {"text": "For Japanese, we use the KyTea tagger (Neubig et al., 2011) for POS tagging, 8 and the EDA word-based dependency parser) with simple manual head-rules to convert a dependency parse to a CFG parse.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 64, "end_pos": 75, "type": "TASK", "confidence": 0.764165848493576}, {"text": "EDA word-based dependency parser", "start_pos": 87, "end_pos": 119, "type": "TASK", "confidence": 0.7149075120687485}]}, {"text": "shows reordering and translation results for orig, 3-step, and lader.", "labels": [], "entities": [{"text": "translation", "start_pos": 21, "end_pos": 32, "type": "TASK", "confidence": 0.9481179118156433}]}, {"text": "It can be seen that the proposed lader outperforms the baselines in both reordering and translation.", "labels": [], "entities": [{"text": "lader", "start_pos": 33, "end_pos": 38, "type": "DATASET", "confidence": 0.7437546849250793}, {"text": "translation", "start_pos": 88, "end_pos": 99, "type": "TASK", "confidence": 0.9289239645004272}]}, {"text": "There area number of reasons why lader outperforms 3-step.", "labels": [], "entities": []}, {"text": "First, the pipeline of 3-step suffers from error propogation, with errors in monolingual parsing and reordering resulting in low overall accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 137, "end_pos": 145, "type": "METRIC", "confidence": 0.9971827268600464}]}, {"text": "10 Second, as Section 5.1 describes, lader breaks ties between oracle parses based on model score, allowing easyto-reproduce model parses to be chosen during training.", "labels": [], "entities": []}, {"text": "In fact, lader generally found trees that followed from syntactic constituency, while 3-step more often used terminal nodes In addition, following the example of's reordering rules, we lexicalize all particles.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Reordering (chunk, \u03c4 ) and translation (BLEU, RIBES) results for each system. Bold numbers  indicate no significant difference from the best system (bootstrap resampling with p > 0.05) (Koehn, 2004).", "labels": [], "entities": [{"text": "Reordering", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9835804104804993}, {"text": "BLEU", "start_pos": 50, "end_pos": 54, "type": "METRIC", "confidence": 0.9871172308921814}, {"text": "RIBES", "start_pos": 56, "end_pos": 61, "type": "METRIC", "confidence": 0.8740643262863159}]}, {"text": " Table 1: The number of sentences and words for  training and testing the reordering model (RM),  translation model (TM), and language model (LM).", "labels": [], "entities": []}, {"text": " Table 3: Results for systems trained to optimize chunk fragmentation (L c ) or Kendall's \u03c4 (L t ).", "labels": [], "entities": [{"text": "Kendall's \u03c4 (L t )", "start_pos": 80, "end_pos": 98, "type": "METRIC", "confidence": 0.7997964450291225}]}]}