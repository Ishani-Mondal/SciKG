{"title": [{"text": "A Unified Approach to Transliteration-based Text Input with Online Spelling Correction", "labels": [], "entities": [{"text": "Transliteration-based Text Input", "start_pos": 22, "end_pos": 54, "type": "TASK", "confidence": 0.7490675250689188}]}], "abstractContent": [{"text": "This paper presents an integrated, end-to-end approach to online spelling correction for text input.", "labels": [], "entities": [{"text": "online spelling correction", "start_pos": 58, "end_pos": 84, "type": "TASK", "confidence": 0.6542708476384481}]}, {"text": "Online spelling correction refers to the spelling correction as you type, as opposed to post-editing.", "labels": [], "entities": [{"text": "Online spelling correction", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.623063882191976}, {"text": "spelling correction", "start_pos": 41, "end_pos": 60, "type": "TASK", "confidence": 0.5850956439971924}]}, {"text": "The online scenario is particularly important for languages that routinely use transliteration-based text input methods, such as Chinese and Japanese, because the desired target characters cannot be input at all unless they are in the list of candidates provided by an input method, and spelling errors prevent them from appearing in the list.", "labels": [], "entities": []}, {"text": "For example, a user might type suesheng by mistake to mean xuesheng \u5b66\u751f 'student' in Chinese; existing input methods fail to convert this misspelled input to the desired target Chinese characters.", "labels": [], "entities": []}, {"text": "In this paper, we propose a unified approach to the problem of spelling correction and transliteration-based character conversion using an approach inspired by the phrase-based statistical machine translation framework.", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 63, "end_pos": 82, "type": "TASK", "confidence": 0.9237561225891113}, {"text": "transliteration-based character conversion", "start_pos": 87, "end_pos": 129, "type": "TASK", "confidence": 0.5888013740380605}, {"text": "phrase-based statistical machine translation", "start_pos": 164, "end_pos": 208, "type": "TASK", "confidence": 0.598598413169384}]}, {"text": "At the phrase (substring) level, k most probable pinyin (Romanized Chinese) corrections are generated using a monotone decoder; at the sentence level, input pinyin strings are directly transliterated into target Chinese characters by a decoder using a log-linear model that refer to the features of both levels.", "labels": [], "entities": []}, {"text": "A new method of automatically deriving parallel training data from user keystroke logs is also presented.", "labels": [], "entities": []}, {"text": "Experiments on Chinese pinyin conversion show that our integrated method reduces the character error rate by 20% (from 8.9% to 7.12%) over the previous state-of-the art based on a noisy channel model.", "labels": [], "entities": [{"text": "Chinese pinyin conversion", "start_pos": 15, "end_pos": 40, "type": "TASK", "confidence": 0.5906979441642761}, {"text": "character error rate", "start_pos": 85, "end_pos": 105, "type": "METRIC", "confidence": 0.6112219194571177}]}], "introductionContent": [{"text": "This paper addresses the problem of online spelling correction, which tries to correct users' misspellings as they type, rather than post-editing them after they have already been input.", "labels": [], "entities": [{"text": "online spelling correction", "start_pos": 36, "end_pos": 62, "type": "TASK", "confidence": 0.6477100352446238}]}, {"text": "This online scenario is particularly important for languages that routinely use transliteration-based text input methods, including Chinese and Japanese: in these languages, characters (called hanzi in Chinese and kanji/kana in Japanese) are typically input by typing how they are pronounced in Roman alphabet (called pinyin in Chinese, romaji in Japanese), and selecting a conversion candidate among those that are offered by an input method system, often referred to as IMEs or input method editors.", "labels": [], "entities": []}, {"text": "One big challenge posed by spelling mistakes is that they prevent the desired candidates from appearing as conversion candidates, as in: suesheng is likely to be a spelling error of xuesheng \u5b66\u751f 'student', but it is not included as one of the candidates.", "labels": [], "entities": []}, {"text": "This severely limits the utility of an IME, as spelling errors are extremely common.", "labels": [], "entities": [{"text": "IME", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.957913339138031}]}, {"text": "Speakers of a non-standard dialect and non-native speakers have a particularly hard time, because they may not know the standard pronunciation of the word to begin with, preventing them from inputting the word altogether.", "labels": [], "entities": []}, {"text": "Error-tolerant word completion and next word prediction are also highly desirable features for text input on software (onscreen) keyboards for any language, making the current work relevant beyond Chinese and Japanese.", "labels": [], "entities": [{"text": "word completion", "start_pos": 15, "end_pos": 30, "type": "TASK", "confidence": 0.6295083314180374}, {"text": "next word prediction", "start_pos": 35, "end_pos": 55, "type": "TASK", "confidence": 0.5967747072378794}]}, {"text": "In this paper, we propose a novel, unified system of text input with spelling correction, using Chinese pinyin-to-hanzi conversion as an example.", "labels": [], "entities": []}, {"text": "We first formulate the task of pinyin spelling correction as a substring-based monotone translation problem, inspired by phrase-based statistical machine translation (SMT) systems (): we consider the pinyin input (potentially with errors) as the source language and the error-corrected pinyin as the target, and build a log-linear model for spelling correction.", "labels": [], "entities": [{"text": "pinyin spelling correction", "start_pos": 31, "end_pos": 57, "type": "TASK", "confidence": 0.738014300664266}, {"text": "substring-based monotone translation", "start_pos": 63, "end_pos": 99, "type": "TASK", "confidence": 0.7571951150894165}, {"text": "phrase-based statistical machine translation (SMT)", "start_pos": 121, "end_pos": 171, "type": "TASK", "confidence": 0.7418132722377777}, {"text": "spelling correction", "start_pos": 341, "end_pos": 360, "type": "TASK", "confidence": 0.9078523814678192}]}, {"text": "In doing so, we also propose a novel, unsupervised method of collecting parallel training data from user input logs.", "labels": [], "entities": []}, {"text": "We then build an integrated end-to-end text input system that directly converts a potentially erroneous input pinyin sequence into a desired hanzi sequence, also formulated as a monotone phrase-based SMT problem, in which the feature functions of the substring-based error correction component are integrated and jointly optimized with the sentence-level feature functions for character conversion Our method generalizes and improves over the previous state-of-the-art methods for the task of error correction and text input in several crucial respects.", "labels": [], "entities": [{"text": "SMT", "start_pos": 200, "end_pos": 203, "type": "TASK", "confidence": 0.8643126487731934}, {"text": "character conversion", "start_pos": 377, "end_pos": 397, "type": "TASK", "confidence": 0.7755427062511444}, {"text": "error correction", "start_pos": 493, "end_pos": 509, "type": "TASK", "confidence": 0.7600528597831726}]}, {"text": "First, our error correction model is designed and implemented as a substring-based, fully trainable system based on a log-linear model, which has been shown effective for related tasks such as transliteration and letter-to-phone conversion, but has not been attempted for the task of spelling correction.", "labels": [], "entities": [{"text": "error correction", "start_pos": 11, "end_pos": 27, "type": "TASK", "confidence": 0.6934987306594849}, {"text": "letter-to-phone conversion", "start_pos": 213, "end_pos": 239, "type": "TASK", "confidence": 0.7238600254058838}, {"text": "spelling correction", "start_pos": 284, "end_pos": 303, "type": "TASK", "confidence": 0.9570200741291046}]}, {"text": "Second, we build an end-toend pinyin-to-hanzi conversion system by combining all the feature functions used in the error correction and character conversion components in an SMT-style log-linear model, where the feature weights are trained discriminatively for the end-to-end task.", "labels": [], "entities": [{"text": "error correction and character conversion", "start_pos": 115, "end_pos": 156, "type": "TASK", "confidence": 0.6836881220340729}, {"text": "SMT-style", "start_pos": 174, "end_pos": 183, "type": "TASK", "confidence": 0.9661971926689148}]}, {"text": "This integration method generalizes the previous approach based on a noisy channel model), in which only the error model and the conversion model probabilities are used and combined with equal weights.", "labels": [], "entities": []}, {"text": "Finally, like other statistical systems, the amount and quality of training data control the quality of the outcome; we thus propose anew, language-independent method of deriving parallel data for spelling correction from user keystroke logs.", "labels": [], "entities": [{"text": "spelling correction from user keystroke logs", "start_pos": 197, "end_pos": 241, "type": "TASK", "confidence": 0.876394788424174}]}, {"text": "We performed experiments on various methods of integrating the error correction and character conversion sub-components.", "labels": [], "entities": [{"text": "error correction", "start_pos": 63, "end_pos": 79, "type": "TASK", "confidence": 0.7457164824008942}, {"text": "character conversion", "start_pos": 84, "end_pos": 104, "type": "TASK", "confidence": 0.8541081845760345}]}, {"text": "Our best system, a fully integrated SMT-based approach, reduces the character error rate by 35% on test data that is completely independent of the creation of error correction and character conversion models.", "labels": [], "entities": [{"text": "SMT-based", "start_pos": 36, "end_pos": 45, "type": "TASK", "confidence": 0.9938686490058899}, {"text": "character error rate", "start_pos": 68, "end_pos": 88, "type": "METRIC", "confidence": 0.7235637704531351}, {"text": "character conversion", "start_pos": 180, "end_pos": 200, "type": "TASK", "confidence": 0.7119504809379578}]}, {"text": "In what follows, we first give the background of this research in Section 2.", "labels": [], "entities": []}, {"text": "We then describe our approach to the spelling correction task (Section 3) and the end-to-end conversion task (Section 4).", "labels": [], "entities": [{"text": "spelling correction task", "start_pos": 37, "end_pos": 61, "type": "TASK", "confidence": 0.9410418073336283}, {"text": "end-to-end conversion task", "start_pos": 82, "end_pos": 108, "type": "TASK", "confidence": 0.7392891844113668}]}, {"text": "We summarize our contribution and conclude with remarks for future directions in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "For the evaluation of the end-to-end conversion task, we used the CHIME corpus mentioned above.", "labels": [], "entities": [{"text": "end-to-end conversion task", "start_pos": 26, "end_pos": 52, "type": "TASK", "confidence": 0.6508383651574453}, {"text": "CHIME corpus", "start_pos": 66, "end_pos": 78, "type": "DATASET", "confidence": 0.8950394690036774}]}, {"text": "In order to use the word trigram language model that is built in-house, we re-segmented the CHIME corpus using our word-breaker, resulting in 12,102 words in 2,000 sentences.", "labels": [], "entities": [{"text": "CHIME corpus", "start_pos": 92, "end_pos": 104, "type": "DATASET", "confidence": 0.8824516832828522}]}, {"text": "We then divided the sentences in the corpus randomly into two halves, and performed a two-fold cross validation evaluation.", "labels": [], "entities": []}, {"text": "The development portion of the data is used to tune the weights of the feature functions in MERT-style training.", "labels": [], "entities": [{"text": "MERT-style training", "start_pos": 92, "end_pos": 111, "type": "TASK", "confidence": 0.7500459253787994}]}, {"text": "We measured our results using character error rate (CER), which is based on the longest common subsequence match in characters between the reference and the best system output.", "labels": [], "entities": [{"text": "character error rate (CER)", "start_pos": 30, "end_pos": 56, "type": "METRIC", "confidence": 0.8717223505179087}]}, {"text": "This is a standard metric used in evaluating IME systems (e.g.,).", "labels": [], "entities": [{"text": "IME", "start_pos": 45, "end_pos": 48, "type": "TASK", "confidence": 0.9499363899230957}]}, {"text": "Let N REF be the number of characters in a reference sentence, N SYS be the character length of a system output, and N LCS be the length of the longest common subsequence between them.", "labels": [], "entities": [{"text": "REF", "start_pos": 6, "end_pos": 9, "type": "METRIC", "confidence": 0.9455801248550415}]}, {"text": "Then the character-level recall is defined as N LCS /N REF , and the precision as N LCS /N SYS . The CER based on recall and on precision are then defined as 1 -recall and 1 -precision, respectively.", "labels": [], "entities": [{"text": "recall", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.9130999445915222}, {"text": "precision", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.9993292093276978}, {"text": "CER", "start_pos": 101, "end_pos": 104, "type": "METRIC", "confidence": 0.9932286739349365}, {"text": "recall", "start_pos": 114, "end_pos": 120, "type": "METRIC", "confidence": 0.9945344924926758}, {"text": "precision", "start_pos": 128, "end_pos": 137, "type": "METRIC", "confidence": 0.9953880906105042}, {"text": "1 -recall", "start_pos": 158, "end_pos": 167, "type": "METRIC", "confidence": 0.6433607141176859}, {"text": "1 -precision", "start_pos": 172, "end_pos": 184, "type": "METRIC", "confidence": 0.6037643154462179}]}, {"text": "We report the harmonic mean of these values, similarly to the widely used F1-measure.", "labels": [], "entities": [{"text": "F1-measure", "start_pos": 74, "end_pos": 84, "type": "METRIC", "confidence": 0.9849531650543213}]}, {"text": "As our goal is to show the effectiveness of the unified approach, we used simpler methods of integrating pinyin error correction with character conversion to create baselines.", "labels": [], "entities": [{"text": "character conversion", "start_pos": 134, "end_pos": 154, "type": "TASK", "confidence": 0.7113183438777924}]}, {"text": "The simplest From, we observe that the accuracy of the 20-best output of the spelling correction component is over 99%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.9995915293693542}, {"text": "spelling correction", "start_pos": 77, "end_pos": 96, "type": "TASK", "confidence": 0.9020405113697052}]}, {"text": "An offline run with the IME system on an independent data set also showed that the accuracy of the 20-best IME output is over 99%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.9996315240859985}]}, {"text": "baseline is a pre-processing approach: we use the pinyin error correction model to convert A into a single best candidate C, and run an IME system on C.", "labels": [], "entities": []}, {"text": "Another more realistic baseline is the noisy channel integration discussed in Section 4.1.", "labels": [], "entities": [{"text": "noisy channel integration", "start_pos": 39, "end_pos": 64, "type": "TASK", "confidence": 0.6486576298872629}]}, {"text": "We approximated this integration method by reranking all the candidates generated by the proposed log-linear model with only the channel and language model probabilities, equally weighted.", "labels": [], "entities": []}, {"text": "5-best results as well as the 1-best results are shown, because in an IME application, providing the correct candidate in the candidate list is particularly important even if it is not the best candidate.", "labels": [], "entities": []}, {"text": "Let us first discuss the 1-best results.", "labels": [], "entities": []}, {"text": "The CER of this test corpus using the in-house IME system without correcting any errors is 10.91.", "labels": [], "entities": [{"text": "CER", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.9974203109741211}]}, {"text": "The oracle CER, which is the result of applying the IME on the gold standard pinyin input derived from the reference text using a hanzi-topinyin converter (as mentioned in Section 3.3), is 4.08, which is the upper-bound imposed by the IME conversion accuracy.", "labels": [], "entities": [{"text": "CER", "start_pos": 11, "end_pos": 14, "type": "METRIC", "confidence": 0.9601637721061707}]}, {"text": "The simple pipeline approach of concatenating the pinyin correction component with the character conversion component improves the CER by 1% to 9.93.", "labels": [], "entities": [{"text": "pinyin correction", "start_pos": 50, "end_pos": 67, "type": "TASK", "confidence": 0.575838252902031}, {"text": "CER", "start_pos": 131, "end_pos": 134, "type": "METRIC", "confidence": 0.9756882190704346}]}, {"text": "Assuming that there are on average 20 words in a sentence, and each word consists of 2 characters, 1% CER reduction means one improvement every 2.5 sentences.", "labels": [], "entities": [{"text": "CER reduction", "start_pos": 102, "end_pos": 115, "type": "METRIC", "confidence": 0.9392099976539612}]}, {"text": "Noisy channel integration improves over this quite substantially, achieving a CER of 7.92, demonstrating the power of the word language model in character conversion.", "labels": [], "entities": [{"text": "Noisy channel integration", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.7170683542887369}, {"text": "CER", "start_pos": 78, "end_pos": 81, "type": "METRIC", "confidence": 0.9965599179267883}, {"text": "character conversion", "start_pos": 145, "end_pos": 165, "type": "TASK", "confidence": 0.8183670938014984}]}, {"text": "Incidentally, the CER of the output by  proposed method outperforms all these baselines to reduce the CER to 7.12, a 35% relative error rate reduction compared with the no correction baseline, a 20% reduction against Zheng et al (2011b) and a 10% reduction from our noisy channel baseline.", "labels": [], "entities": [{"text": "CER", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.9979244470596313}, {"text": "CER", "start_pos": 102, "end_pos": 105, "type": "METRIC", "confidence": 0.9967781901359558}, {"text": "relative error rate", "start_pos": 121, "end_pos": 140, "type": "METRIC", "confidence": 0.7344783544540405}]}, {"text": "The 5-best results follow the same trend of steady improvement as we use a more integrated system.", "labels": [], "entities": []}, {"text": "In order to understand the characteristics of the errors and remaining issues, we ran an error analysis on the 1-best results of the proposed system.", "labels": [], "entities": []}, {"text": "For each word in the test data (all 2,000 sentences) for which the system output had an error, we classified the reasons of failure into one of the four categories: (1) character conversion error: correct pinyin was input to the IME but the conversion failed; (2) over-correction of pinyin input: the system corrected the pinyin input when it should not have; (3) under-correction of pinyin input: the system did not correct an error in the input pinyin when it should have; (4) wrong correction: input pinyin string had a spelling error but it was corrected incorrectly.", "labels": [], "entities": [{"text": "character conversion", "start_pos": 169, "end_pos": 189, "type": "TASK", "confidence": 0.6897624135017395}, {"text": "IME", "start_pos": 229, "end_pos": 232, "type": "DATASET", "confidence": 0.8748500943183899}, {"text": "wrong correction", "start_pos": 479, "end_pos": 495, "type": "METRIC", "confidence": 0.8979493379592896}]}, {"text": "shows the results of the error analysis.", "labels": [], "entities": []}, {"text": "We find that somewhat contrary to our expectation, over-correction of the spelling mistakes was not a conspicuous problem, even though the pinyin correction rate of the training data is much higher than that of the test data.", "labels": [], "entities": [{"text": "pinyin correction rate", "start_pos": 139, "end_pos": 161, "type": "METRIC", "confidence": 0.9151774843533834}]}, {"text": "We therefore conclude that the error correction model adapts very well to the characteristics of the test data in our integrated SMT-based approach, which trains the unified feature weights to optimize the end goal.", "labels": [], "entities": [{"text": "error correction", "start_pos": 31, "end_pos": 47, "type": "TASK", "confidence": 0.7230301648378372}, {"text": "SMT-based", "start_pos": 129, "end_pos": 138, "type": "TASK", "confidence": 0.993733823299408}]}], "tableCaptions": [{"text": " Table 3. 5-best results as  well as the 1-best results are shown, because in an  IME application, providing the correct candidate in  the candidate list is particularly important even if it  is not the best candidate. Let us first discuss the 1- best results. The CER of this test corpus using the  in-house IME system without correcting any errors  is 10.91. The oracle CER, which is the result of  applying the IME on the gold standard pinyin input  derived from the reference text using a hanzi-to- pinyin converter (as mentioned in Section 3.3), is  4.08, which is the upper-bound imposed by the  IME conversion accuracy. The simple pipeline  approach of concatenating the pinyin correction  component with the character conversion  component improves the CER by 1% to 9.93.  Assuming that there are on average 20 words in a  sentence, and each word consists of 2 characters,  1% CER reduction means one improvement every  2.5 sentences. Noisy channel integration improves  over this quite substantially, achieving a CER of  7.92, demonstrating the power of the word  language model in character conversion.  Incidentally, the CER of the output by", "labels": [], "entities": [{"text": "CER", "start_pos": 265, "end_pos": 268, "type": "METRIC", "confidence": 0.9963079690933228}, {"text": "CER", "start_pos": 761, "end_pos": 764, "type": "METRIC", "confidence": 0.9876603484153748}, {"text": "CER reduction", "start_pos": 885, "end_pos": 898, "type": "METRIC", "confidence": 0.9545332789421082}, {"text": "CER", "start_pos": 1022, "end_pos": 1025, "type": "METRIC", "confidence": 0.9774270057678223}, {"text": "character conversion", "start_pos": 1091, "end_pos": 1111, "type": "TASK", "confidence": 0.7267848700284958}, {"text": "CER", "start_pos": 1132, "end_pos": 1135, "type": "METRIC", "confidence": 0.9923330545425415}]}, {"text": " Table 3: CER results for the conversion task (%)", "labels": [], "entities": [{"text": "CER", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9601253867149353}, {"text": "conversion task", "start_pos": 30, "end_pos": 45, "type": "TASK", "confidence": 0.8982426822185516}]}]}