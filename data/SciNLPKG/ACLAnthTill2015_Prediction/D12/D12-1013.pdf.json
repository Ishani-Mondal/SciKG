{"title": [{"text": "Active Learning for Imbalanced Sentiment Classification", "labels": [], "entities": [{"text": "Imbalanced Sentiment Classification", "start_pos": 20, "end_pos": 55, "type": "TASK", "confidence": 0.8141756653785706}]}], "abstractContent": [{"text": "Active learning is a promising way for sentiment classification to reduce the annotation cost.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 39, "end_pos": 63, "type": "TASK", "confidence": 0.9728786945343018}]}, {"text": "In this paper, we focus on the imbalanced class distribution scenario for sentiment classification, wherein the number of positive samples is quite different from that of negative samples.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 74, "end_pos": 98, "type": "TASK", "confidence": 0.9641102850437164}]}, {"text": "This scenario posits new challenges to active learning.", "labels": [], "entities": []}, {"text": "To address these challenges, we propose a novel active learning approach, named co-selecting, by taking both the imbalanced class distribution issue and uncertainty into account.", "labels": [], "entities": []}, {"text": "Specifically, our co-selecting approach employs two feature subspace classifiers to collectively select most informative minority-class samples for manual annotation by leveraging a certainty measurement and an uncertainty measurement, and in the meanwhile, automatically label most informative majority-class samples, to reduce human-annotation efforts.", "labels": [], "entities": [{"text": "certainty measurement", "start_pos": 182, "end_pos": 203, "type": "METRIC", "confidence": 0.9678609669208527}]}, {"text": "Extensive experiments across four domains demonstrate great potential and effectiveness of our proposed co-selecting approach to active learning for imbalanced sentiment classification.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 160, "end_pos": 184, "type": "TASK", "confidence": 0.7901544570922852}]}], "introductionContent": [{"text": "Sentiment classification is the task of identifying the sentiment polarity (e.g., positive or negative) of * 1 Corresponding author a natural language text towards a given topic) and has become the core component of many important applications in opinion analysis (.", "labels": [], "entities": [{"text": "Sentiment classification", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.934905469417572}, {"text": "opinion analysis", "start_pos": 247, "end_pos": 263, "type": "TASK", "confidence": 0.8793781995773315}]}, {"text": "Most of previous studies in sentiment classification focus on learning models from a large number of labeled data.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 28, "end_pos": 52, "type": "TASK", "confidence": 0.973312109708786}]}, {"text": "However, in many real-world applications, manual annotation is expensive and time-consuming.", "labels": [], "entities": []}, {"text": "In these situations, active learning approaches could be helpful by actively selecting most informative samples for manual annotation.", "labels": [], "entities": []}, {"text": "Compared to traditional active learning for sentiment classification, active learning for imbalanced sentiment classification faces some unique challenges.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 44, "end_pos": 68, "type": "TASK", "confidence": 0.9738986790180206}, {"text": "sentiment classification", "start_pos": 101, "end_pos": 125, "type": "TASK", "confidence": 0.7466188371181488}]}, {"text": "As a specific type of sentiment classification, imbalanced sentiment classification deals with the situation in which there are many more samples of one class (called majority class) than the other class (called minority class), and has attracted much attention due to its high realistic value in real-world applications ().", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 22, "end_pos": 46, "type": "TASK", "confidence": 0.9382592737674713}, {"text": "imbalanced sentiment classification", "start_pos": 48, "end_pos": 83, "type": "TASK", "confidence": 0.7210004528363546}]}, {"text": "In imbalanced sentiment classification, since the minority-class samples (denoted as MI samples) are normally much sparse and thus more precious and informative for learning compared to the majority-class ones (denoted as MA samples), it is worthwhile to spend more on manually annotating MI samples to guarantee both the quality and quantity of MI samples.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 14, "end_pos": 38, "type": "TASK", "confidence": 0.8067958950996399}]}, {"text": "Traditionally, uncertainty has been popularly used as a basic measurement in active learning ().", "labels": [], "entities": []}, {"text": "Therefore, how to select most informative MI samples for manual annotation without violating the basic uncertainty requirement in active learning is challenging in imbalanced sentiment classification.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 175, "end_pos": 199, "type": "TASK", "confidence": 0.8521495163440704}]}, {"text": "In this paper, we address above challenges in active learning for imbalanced sentiment classification.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 77, "end_pos": 101, "type": "TASK", "confidence": 0.7719879746437073}]}, {"text": "The basic idea of our active learning approach is to use two complementary classifiers for collectively selecting most informative MI samples: one to adopt a certainty measurement for selecting most possible MI samples and the other to adopt an uncertainty measurement for selecting most uncertain MI samples from the most possible MI samples returned from the first classifier.", "labels": [], "entities": []}, {"text": "Specifically, the two classifiers are trained with two disjoint feature subspaces to guarantee their complementariness.", "labels": [], "entities": []}, {"text": "This also applies to selecting most informative MA samples.", "labels": [], "entities": []}, {"text": "We call our novel active learning approach co-selecting due to its collectively selecting informative samples through two disjoint feature subspace classifiers.", "labels": [], "entities": []}, {"text": "To further reduce the annotation efforts, we only manually annotate those most informative MI samples while those most informative MA samples are automatically labeled using the predicted labels provided by the first classifier.", "labels": [], "entities": []}, {"text": "In principle, our active learning approach differs from existing ones in two main aspects.", "labels": [], "entities": []}, {"text": "First, a certainty measurement and an uncertainty measurement are employed in two complementary subspace classifiers respectively to collectively select most informative MI samples for manual annotation.", "labels": [], "entities": [{"text": "certainty measurement", "start_pos": 9, "end_pos": 30, "type": "METRIC", "confidence": 0.9619764089584351}]}, {"text": "Second, most informative MA samples are automatically labeled to further reduce the annotation cost.", "labels": [], "entities": []}, {"text": "Evaluation across four domains shows that our active learning approach is effective for imbalanced sentiment classification and significantly outperforms the state-of-the-art active learning alternatives, such as uncertainty sampling () and co-testing ().", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 99, "end_pos": 123, "type": "TASK", "confidence": 0.8492920696735382}]}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 overviews the related work on sentiment classification and active learning.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 40, "end_pos": 64, "type": "TASK", "confidence": 0.9727780818939209}]}, {"text": "Section 3 proposes our active learning approach for imbalanced sentiment classification.", "labels": [], "entities": [{"text": "imbalanced sentiment classification", "start_pos": 52, "end_pos": 87, "type": "TASK", "confidence": 0.6771750251452128}]}, {"text": "Section 4 reports the experimental results.", "labels": [], "entities": []}, {"text": "Finally, Section 5 draws the conclusion and outlines the future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we will systematically evaluate our active learning approach for imbalanced sentiment classification and compare it with the state-of-theart active learning alternatives.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 93, "end_pos": 117, "type": "TASK", "confidence": 0.74433733522892}]}, {"text": "We use the same data as used by).", "labels": [], "entities": []}, {"text": "For thorough comparison, various kinds of active learning approaches are implemented including: \uf0d8 Random: randomly select the samples from the unlabeled data for manual annotation; \uf0d8 Margin-based: iteratively select samples closest to the hyperplane provided by the SVM classifier, which is suggested by and.", "labels": [], "entities": []}, {"text": "One sample is selected in each iteration; \uf0d8 Uncertainty: iteratively select samples using the uncertainty measurement according to the output of ME classifier.", "labels": [], "entities": []}, {"text": "One sample is selected in each iteration; \uf0d8 Certainty: iteratively select class-balanced samples using the certainty measurement according to the output of ME classifier.", "labels": [], "entities": []}, {"text": "One positive and negative sample (the positive and negative label is provided by the ME classifier) are selected in each iteration; \uf0d8 Co-testing: first get contention samples (i.e., unlabeled examples on which the member classifiers predict different labels) and then select the least confidence one among the hypotheses of different member classifiers, i.e., the aggressive strategy as described.", "labels": [], "entities": []}, {"text": "Specifically, the member classifiers are two subspace classifiers trained by splitting the whole feature space into two disjoint subspaces of same size; \uf0d8 Self-selecting: first select k uncertainty samples and then randomly select a positive and negative sample from the uncertainty-sample set, which is suggested by.", "labels": [], "entities": []}, {"text": "We call it self-selecting since only one classifier is involved to measure uncertainty and predict class labels.", "labels": [], "entities": []}, {"text": "For those approaches involving random selection of features, we run 5 times for them and report the average results.", "labels": [], "entities": []}, {"text": "Note that the samples selected by these approaches are imbalanced.", "labels": [], "entities": []}, {"text": "To address the problem of classification on imbalanced data, we adopt the under-sampling strategy which has been shown effective for supervised imbalanced sentiment classification ().", "labels": [], "entities": [{"text": "supervised imbalanced sentiment classification", "start_pos": 133, "end_pos": 179, "type": "TASK", "confidence": 0.6498421803116798}]}, {"text": "Our active learning approach includes two versions: the co-selecting algorithm as described in Section 3.2 and the co-selecting with selected MA samples automatically labeled as described in Section 3.3.", "labels": [], "entities": []}, {"text": "For clarity, we refer the former as co-selecting-basic and the latter as coselecting-plus in the following.", "labels": [], "entities": []}, {"text": "compares different active learning approaches to imbalanced sentiment classification when 600 unlabeled samples are selected for annotation.", "labels": [], "entities": [{"text": "imbalanced sentiment classification", "start_pos": 49, "end_pos": 84, "type": "TASK", "confidence": 0.6964215238889059}]}, {"text": "Specifically, the parameters \uf071 and k is set to be 1/16 and 50 respectively.", "labels": [], "entities": []}, {"text": "justifies that it is challenging to perform active learning in imbalanced sentiment classification: the approaches of margin-based, uncertainty-based and self-selecting perform no better than random selection while co-testing only outperforms random selection in two domains: DVD and Electronic with only a small improvement (about 1%).", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 74, "end_pos": 98, "type": "TASK", "confidence": 0.8621364235877991}, {"text": "DVD", "start_pos": 276, "end_pos": 279, "type": "DATASET", "confidence": 0.9033715724945068}]}, {"text": "In comparison, our approaches, both coselecting-basic and co-selecting-plus significantly outperform the random selection approach on all the four domains.", "labels": [], "entities": []}, {"text": "It also shows that co-selectingplus is preferable over co-selecting-basic.", "labels": [], "entities": []}, {"text": "This verifies the effectiveness of automatically labeling those selected MA samples in imbalanced sentiment classification.", "labels": [], "entities": [{"text": "imbalanced sentiment classification", "start_pos": 87, "end_pos": 122, "type": "TASK", "confidence": 0.6624508202075958}]}], "tableCaptions": [{"text": " Table 1: The number of MI samples selected for  manual annotation when 600 samples are  annotated on the whole.", "labels": [], "entities": []}]}