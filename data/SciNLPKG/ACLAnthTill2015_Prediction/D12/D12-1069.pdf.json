{"title": [{"text": "Weakly Supervised Training of Semantic Parsers", "labels": [], "entities": []}], "abstractContent": [{"text": "We present a method for training a semantic parser using only a knowledge base and an un-labeled text corpus, without any individually annotated sentences.", "labels": [], "entities": []}, {"text": "Our key observation is that multiple forms of weak supervision can be combined to train an accurate semantic parser: semantic supervision from a knowledge base, and syntactic supervision from dependency-parsed sentences.", "labels": [], "entities": []}, {"text": "We apply our approach to train a semantic parser that uses 77 relations from Freebase in its knowledge representation.", "labels": [], "entities": []}, {"text": "This semantic parser extracts instances of binary relations with state-of-the-art accuracy, while simultaneously recovering much richer semantic structures, such as conjunctions of multiple relations with partially shared arguments.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 82, "end_pos": 90, "type": "METRIC", "confidence": 0.9970756769180298}]}, {"text": "We demonstrate recovery of this richer structure by extracting logical forms from natural language queries against Freebase.", "labels": [], "entities": []}, {"text": "On this task, the trained semantic parser achieves 80% precision and 56% recall, despite never having seen an annotated logical form.", "labels": [], "entities": [{"text": "precision", "start_pos": 55, "end_pos": 64, "type": "METRIC", "confidence": 0.9994810223579407}, {"text": "recall", "start_pos": 73, "end_pos": 79, "type": "METRIC", "confidence": 0.9996365308761597}]}], "introductionContent": [{"text": "Semantic parsing converts natural language statements into logical forms in a meaning representation language.", "labels": [], "entities": [{"text": "Semantic parsing", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7765199542045593}]}, {"text": "For example, the phrase \"town in California\" might be represented as \u03bbx.CITY(x) \u2227 LOCATEDIN(x, CALIFORNIA), where CITY, LOCATEDIN and CALIFORNIA are predicates and entities from a knowledge base.", "labels": [], "entities": []}, {"text": "The expressivity and utility of semantic parsing is derived from this meaning representation, which is essentially a program that is directly executable by a computer.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 32, "end_pos": 48, "type": "TASK", "confidence": 0.7414968311786652}]}, {"text": "In this sense, broad coverage semantic parsing is the goal of natural language understanding.", "labels": [], "entities": [{"text": "broad coverage semantic parsing", "start_pos": 15, "end_pos": 46, "type": "TASK", "confidence": 0.733367845416069}, {"text": "natural language understanding", "start_pos": 62, "end_pos": 92, "type": "TASK", "confidence": 0.6622206072012583}]}, {"text": "Unfortunately, due to data annotation constraints, modern semantic parsers only operate in narrow domains.", "labels": [], "entities": [{"text": "semantic parsers", "start_pos": 58, "end_pos": 74, "type": "TASK", "confidence": 0.720761239528656}]}, {"text": "The best performing semantic parsers are trained using extensive manual annotation: typically, a number of sentences must be annotated with their desired logical form.", "labels": [], "entities": []}, {"text": "Although other forms of supervision exist), these methods similarly require annotations for individual sentences.", "labels": [], "entities": []}, {"text": "More automated training methods are required to produce semantic parsers with richer meaning representations.", "labels": [], "entities": []}, {"text": "This paper presents an algorithm for training a semantic parser without per-sentence annotations.", "labels": [], "entities": []}, {"text": "Instead, our approach exploits two easily-obtainable sources of supervision: a large knowledge base and (automatically) dependency-parsed sentences.", "labels": [], "entities": []}, {"text": "The semantic parser is trained to identify relation instances from the knowledge base while simultaneously producing parses that syntactically agree with the dependency parses.", "labels": [], "entities": []}, {"text": "Combining these two sources of supervision allows us to train an accurate semantic parser for any knowledge base without annotated training data.", "labels": [], "entities": []}, {"text": "We demonstrate our approach by training a Combinatory Categorial Grammar (CCG)) that parses sentences into logical forms containing any of 77 relations from Freebase.", "labels": [], "entities": []}, {"text": "Our training data consists of relation instances from Freebase and automatically dependency-parsed sentences from a web corpus.", "labels": [], "entities": []}, {"text": "The trained semantic parser extracts binary relations with state-of-the-art performance, while recovering considerably richer semantic structure.", "labels": [], "entities": []}, {"text": "We demonstrate recovery of this semantic structure using natural language queries : An example parse of \"town in California\" using the example CCG lexicon.", "labels": [], "entities": []}, {"text": "The first stage in parsing retrieves a category from each word from the lexicon, represented by the \"Lex\" entries.", "labels": [], "entities": []}, {"text": "The second stage applies CCG combination rules, in this case both forms of function application, to combine these categories into a semantic parse.", "labels": [], "entities": []}, {"text": "Our weakly-supervised semantic parser predicts the correct logical form for 56% of queries, despite never seeing a labeled logical form.", "labels": [], "entities": []}, {"text": "This paper is structured as follows.", "labels": [], "entities": []}, {"text": "We first provide some background information on CCG and the structure of a knowledge base in Section 2.", "labels": [], "entities": [{"text": "CCG", "start_pos": 48, "end_pos": 51, "type": "TASK", "confidence": 0.5193168520927429}]}, {"text": "Section 3 formulates the weakly supervised training problem for semantic parsers and presents our algorithm.", "labels": [], "entities": []}, {"text": "Section 4 describes how we applied our algorithm to construct a semantic parser for Freebase, and Section 5 presents our results.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 84, "end_pos": 92, "type": "DATASET", "confidence": 0.9152002334594727}]}, {"text": "We conclude with related work and discussion.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we evaluate the performance of a semantic parser for Freebase, trained using our weakly-supervised algorithm.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 70, "end_pos": 78, "type": "DATASET", "confidence": 0.9388687014579773}]}, {"text": "Empirical comparison is somewhat difficult because the most comparable previous work -weakly-supervised relation extraction -uses a shallower semantic representation.", "labels": [], "entities": [{"text": "Empirical comparison", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7894352674484253}, {"text": "relation extraction", "start_pos": 104, "end_pos": 123, "type": "TASK", "confidence": 0.7415504157543182}]}, {"text": "Our evaluation therefore has two components: (1) a binary relation extraction task, to demonstrate that the trained semantic parser extracts instances of binary relations with performance comparable to other state-of-the-art systems, and (2) a natural language database query task, to demonstrate the parser's ability to extract more complex logical forms than binary relation instances, such as logical expressions involving conjunctions of multiple categories and relations with partially shared arguments.", "labels": [], "entities": [{"text": "binary relation extraction", "start_pos": 51, "end_pos": 77, "type": "TASK", "confidence": 0.6723999579747518}]}], "tableCaptions": [{"text": " Table 3: Example natural language queries and their cor- rect annotated logical form.", "labels": [], "entities": []}, {"text": " Table 4: Precision and recall for predicting logical forms  of natural language queries against Freebase. The table  compares PARSE, trained with syntactic supervision to  PARSE-DEP, trained without syntactic supervision.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9925181865692139}, {"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9990560412406921}, {"text": "predicting logical forms  of natural language queries", "start_pos": 35, "end_pos": 88, "type": "TASK", "confidence": 0.8873225961412702}, {"text": "PARSE", "start_pos": 127, "end_pos": 132, "type": "METRIC", "confidence": 0.6773884892463684}]}]}