{"title": [{"text": "Do Neighbours Help? An Exploration of Graph-based Algorithms for Cross-domain Sentiment Classification", "labels": [], "entities": [{"text": "Cross-domain Sentiment Classification", "start_pos": 65, "end_pos": 102, "type": "TASK", "confidence": 0.680829385916392}]}], "abstractContent": [{"text": "This paper presents a comparative study of graph-based approaches for cross-domain sentiment classification.", "labels": [], "entities": [{"text": "cross-domain sentiment classification", "start_pos": 70, "end_pos": 107, "type": "TASK", "confidence": 0.8067289590835571}]}, {"text": "In particular, the paper analyses two existing methods: an optimisation problem and a ranking algorithm.", "labels": [], "entities": []}, {"text": "We compare these graph-based methods with each other and with the other state-of-the-art approaches and conclude that graph domain representations offer a competitive solution to the domain adaptation problem.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 183, "end_pos": 200, "type": "TASK", "confidence": 0.7253776788711548}]}, {"text": "Analysis of the best parameters for graph-based algorithms reveals that there are no optimal values valid for all domain pairs and that these values are dependent on the characteristics of corresponding domains.", "labels": [], "entities": []}], "introductionContent": [{"text": "The sentiment classification (SC) is an active area of research concerned automatic identification of sentiment strength or valence of texts.", "labels": [], "entities": [{"text": "sentiment classification (SC)", "start_pos": 4, "end_pos": 33, "type": "TASK", "confidence": 0.9168673634529114}, {"text": "automatic identification of sentiment strength or valence of texts", "start_pos": 74, "end_pos": 140, "type": "TASK", "confidence": 0.7455308338006338}]}, {"text": "SC of product reviews is commercially important and widely researched but it typically needs to be optimised separately for each type of product (i.e. domain).", "labels": [], "entities": [{"text": "SC of product reviews", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8949657678604126}]}, {"text": "When domain-specific data are absent or insufficient the researchers usually seek solution in semi-supervised, unsupervised or cross-domain approaches.", "labels": [], "entities": []}, {"text": "In this paper, we focus on cross-domain methods in order to take advantage of the huge amount of annotated sentiment data available on the Internet.", "labels": [], "entities": []}, {"text": "Our aim is to find out to what extent it is possible to learn sentiment phenomena from these data and transfer them to new domains rather than induce them from scratch for each new domain.", "labels": [], "entities": []}, {"text": "Previous research has shown that models trained on one data usually give much worse results on another, especially when both data sets belong to completely different domains.", "labels": [], "entities": []}, {"text": "This is largely because the sentiment words and their valences depend a lot on the domain where they are expressed.", "labels": [], "entities": []}, {"text": "The first problem concerns the words that can convey opposite sentiments with respect to the context or domain.", "labels": [], "entities": []}, {"text": "For example, a word \"ridiculous\" in book reviews may express a negative meaning when talking about a book content, however for reviews on electronics this word can bear a positive meaning when talking about prices.", "labels": [], "entities": []}, {"text": "Another and more common problem is related to sentiment words that are specific for each domain.", "labels": [], "entities": []}, {"text": "For instance, words like \"boring\", \"inspiring\", \"engaging\" are very common in book reviews but it is almost impossible to find them in reviews on electronics.", "labels": [], "entities": []}, {"text": "At the same time, the electronics domain can contain words like \"defective\", \"refund\", \"return\", \"customer service\", which are very unusual for book reviews.", "labels": [], "entities": []}, {"text": "Several cross-domain approaches have been suggested recently to solve the problem of accuracy loss in cross-domain sentiment classification, namely Structural Correspondence Learning (SCL), the graph-based approach () and Spectral Feature Alignment (SFA) (.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.9947311878204346}, {"text": "cross-domain sentiment classification", "start_pos": 102, "end_pos": 139, "type": "TASK", "confidence": 0.6666664580504099}, {"text": "Spectral Feature Alignment (SFA)", "start_pos": 222, "end_pos": 254, "type": "TASK", "confidence": 0.7942923009395599}]}, {"text": "In this paper, we explore graph-based algorithms which refer to a group of techniques that model data as a graph of documents.", "labels": [], "entities": []}, {"text": "This data representation takes into account not only document contents but also document connectivity which is modeled as document sentiment similarity rather than content similarity.", "labels": [], "entities": []}, {"text": "Our interest in graph algorithms is two-fold.", "labels": [], "entities": []}, {"text": "First, graph-based domain representations can benefit from two independent sources of information: scores given by a machine learning technique which indicate the probability of a document to belong to a sentiment class and similarity relations between documents.", "labels": [], "entities": []}, {"text": "Second, unlike other suggested methods, this approach can be easily adapted to multiple classes, which makes it possible to classify documents using finer-grained sentiment scales.", "labels": [], "entities": []}, {"text": "Different graph-based algorithms have been applied to several SA tasks), but no comparison has been made to find the most appropriate one for SC.", "labels": [], "entities": [{"text": "SC", "start_pos": 142, "end_pos": 144, "type": "TASK", "confidence": 0.9754701256752014}]}, {"text": "Moreover, in the framework of the domain adaption task, we come across the problem of choosing the best set of parameters, which, as we further demonstrate, depends on the characteristics of a corresponding domain pair.", "labels": [], "entities": [{"text": "domain adaption task", "start_pos": 34, "end_pos": 54, "type": "TASK", "confidence": 0.7842661440372467}]}, {"text": "Unfortunately, no study has investigated this problem.", "labels": [], "entities": []}, {"text": "() exploited the graph-based approach fora semi-supervised task and experimented with data belonging to one domain and, therefore did not come across this issue.", "labels": [], "entities": []}, {"text": "The work of () lacks any discussion about the choice of the parameter values; the authors set some values equal for all domains without mentioning how they obtained these numbers.", "labels": [], "entities": []}, {"text": "The present research brings several contributions.", "labels": [], "entities": []}, {"text": "First, we compare two graph-based algorithms in cross-domain SC settings: the algorithm exploited in), which seeks document sentiments as an output of an optimisation problem (OPTIM) and the algorithm adopted by (, that uses ranking to assign sentiment scores (RANK).", "labels": [], "entities": [{"text": "sentiment scores (RANK)", "start_pos": 243, "end_pos": 266, "type": "METRIC", "confidence": 0.5877318024635315}]}, {"text": "Second, as document similarity is a crucial factor for satisfactory performance of graph-based algorithms, we suggest and evaluate various sentiment similarity measures.", "labels": [], "entities": []}, {"text": "Sentiment similarity is different from topic similarity as it compares documents with respect to the sentiment they convey rather than their topic.", "labels": [], "entities": [{"text": "Sentiment similarity", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9571509063243866}, {"text": "topic similarity", "start_pos": 39, "end_pos": 55, "type": "TASK", "confidence": 0.6881930083036423}]}, {"text": "Finally, we discover the dependency of algorithm parameter values on domain properties and, subsequently, the impossibility to find universal parameter values suitable for all domain pairs.", "labels": [], "entities": []}, {"text": "We discuss a possible strategy for choosing the best set of parameters based on our previous study, where we introduced two domain characteristics: domain similarity and domain complexity and demonstrated their strong correlation with cross-domain accuracy loss.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 248, "end_pos": 256, "type": "METRIC", "confidence": 0.9212834239006042}]}, {"text": "The rest of the paper is structured as follows.", "labels": [], "entities": []}, {"text": "In Section 2 we give a short overview of related works on cross-domain SC.", "labels": [], "entities": [{"text": "cross-domain SC", "start_pos": 58, "end_pos": 73, "type": "TASK", "confidence": 0.7580589652061462}]}, {"text": "Section 3 describes and compares the OPTIM and RANK algorithms.", "labels": [], "entities": []}, {"text": "In Section 4 we discuss an issue of document similarity and select document representation that correlates best with document sentiments.", "labels": [], "entities": [{"text": "select document representation", "start_pos": 60, "end_pos": 90, "type": "TASK", "confidence": 0.6081761519114176}]}, {"text": "Experimental results are described in Section 5 followed by a discussion on the strategy for choosing the best parameter values of the algorithms (Section 6).", "labels": [], "entities": []}, {"text": "Finally, in Section 7 we summarise our contributions and discuss further research.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our data comprises Amazon product reviews on 4 topics: books (BO), electronics (EL), kitchen (KI) and DVDs (DV), initially collected and described by.", "labels": [], "entities": []}, {"text": "Reviews are rated using a binary scale, 1-2 star reviews are considered as negative and 4-5 star reviews as positive.", "labels": [], "entities": []}, {"text": "The data within each domain are balanced: they contain 1000 positive and 1000 negative reviews.", "labels": [], "entities": []}, {"text": "First, we compute a baseline for each domain pair by training a Support Vector Machines (SVMs) classifier using one domain as training data and another as test data.", "labels": [], "entities": []}, {"text": "We choose SVMs as our main learning technique because they have proved to be the best supervised algorithm for SC.", "labels": [], "entities": [{"text": "SC", "start_pos": 111, "end_pos": 113, "type": "TASK", "confidence": 0.9866535067558289}]}, {"text": "In particular, we use the LIBSVM library () and a linear kernel function to train the classifier.", "labels": [], "entities": []}, {"text": "For the feature set we experiment with different features and feature weights and conclude that unigrams and bigrams weighted with binary values yield the best performance.", "labels": [], "entities": []}, {"text": "on the y-axis represent target domains.", "labels": [], "entities": []}, {"text": "The isolines image of the baseline accuracy delivers a good representation of domain relations.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9186268448829651}]}, {"text": "In particular, we can observe two regions with the highest accuracy (EL-KI, KI-EL) and (BO-DV, DV-BO) and two regions with a big performance drop (EL-BO, EL-DV, KI-BO, KI-DV) and (BO-EL, BO-KI, DV-EL, DV-KI).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.998251736164093}, {"text": "BO-DV", "start_pos": 88, "end_pos": 93, "type": "METRIC", "confidence": 0.9520306587219238}]}, {"text": "As shown in our previous study) the first two regions conform with the most similar domain pairs BO, DV and EL, KI.", "labels": [], "entities": [{"text": "BO", "start_pos": 97, "end_pos": 99, "type": "METRIC", "confidence": 0.99431312084198}]}, {"text": "OPTIM and RANK require the setting of several parameters: (k, k , \u03b1, \u03b2) for OPTIM and (k, k , \u03b3) for RANK.", "labels": [], "entities": [{"text": "OPTIM", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8583670258522034}]}, {"text": "As it is computationally expensive to iterate overall possible values of parameters we first run the algorithms on a small matrix of parameters and then apply the gradient descent method which takes the values with highest accuracy as its starting points.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 223, "end_pos": 231, "type": "METRIC", "confidence": 0.9686097502708435}]}, {"text": "We execute both algorithms with different similarity measures, F idf and F idf +SOCAL . In OPTIM and RANK run with F idf , while OPTIM+SOCAL and RANK+SOCAL run with F idf +SOCAL . We give the best accuracies achieved by these algorithms for each domain pair.", "labels": [], "entities": [{"text": "OPTIM", "start_pos": 91, "end_pos": 96, "type": "DATASET", "confidence": 0.6433835029602051}, {"text": "accuracies", "start_pos": 197, "end_pos": 207, "type": "METRIC", "confidence": 0.9680938720703125}]}, {"text": "Unlike the correlations, the accuracies increase significantly with the integration of SO-CAL-dictionaries, the average improvement is about 3% for RANK and 1.5% for OPTIM.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 29, "end_pos": 39, "type": "METRIC", "confidence": 0.9969359636306763}, {"text": "RANK", "start_pos": 148, "end_pos": 152, "type": "METRIC", "confidence": 0.4124753177165985}]}, {"text": "In general, RANK consistently outperforms OPTIM for all domain pairs, OPTIM shows competitive performance only for the pairs of similar domains BO-DV, KI-EL and EL-KI.", "labels": [], "entities": []}, {"text": "We should also point out that OPTIM is more time-consuming as it requires expensive matrix operations.", "labels": [], "entities": []}, {"text": "Due to these advantages of the RANK algorithm, we mostly focus on its analysis in the rest of the paper.", "labels": [], "entities": []}, {"text": "It is interesting to examine the performance of RANK on the basis of the 3D isolines image ().", "labels": [], "entities": [{"text": "RANK", "start_pos": 48, "end_pos": 52, "type": "DATASET", "confidence": 0.5248057842254639}]}, {"text": "The isolines stretch from left to right indicating that accuracy is almost independent of the source domain.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.9994309544563293}]}, {"text": "Such behaviour for RANK suggests a positive answer to our question stated in the title: even if domains are quite different, neighbours from the same domain will fix these discrepancies.", "labels": [], "entities": [{"text": "RANK", "start_pos": 19, "end_pos": 23, "type": "DATASET", "confidence": 0.7135673761367798}]}, {"text": "This property is definitely a big advantage of the RANK algorithm in the context of the cross-domain task as it minimises the importance of the source domain.", "labels": [], "entities": []}, {"text": "Obviously more experiments with different data must be accomplished to prove this conclusion with a higher level of confidence.", "labels": [], "entities": []}, {"text": "We also compare graph-based algorithms with other state-of-the-art approaches, such as SCL and SFA (Table 2,.", "labels": [], "entities": []}, {"text": "The best results in are highlighted and if the difference is statistically significant with \u03b1 = 0.05 the corresponding accuracy is underlined.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 119, "end_pos": 127, "type": "METRIC", "confidence": 0.9996936321258545}]}, {"text": "Note that we compare graph-based approaches against the others but not each other, therefore, if the result given by RANK is underlined it means that it is statistically significant only in comparison with SCL and SFA and not with OPTIM.", "labels": [], "entities": []}, {"text": "According to, RANK surpasses SCL for almost all domain pairs with an average difference equal to 2%.", "labels": [], "entities": []}, {"text": "Interestingly, without using SO-CAL-dictionaries RANK loses to both SCL and SFA for almost all domain pairs.", "labels": [], "entities": []}, {"text": "The advantage of RANK over SFA is disputable as there is not much consistency about when one algorithm outperforms another, except that SFA is better overall for close domains.", "labels": [], "entities": [{"text": "consistency", "start_pos": 66, "end_pos": 77, "type": "METRIC", "confidence": 0.9564666152000427}]}, {"text": "However suggests an interesting finding: that for domains with different complexities swapping source and target also changes the method that produces the best performance.", "labels": [], "entities": []}, {"text": "A comparison of RANK and SCL on the Chinese texts given by ( shows the same phenomenon.", "labels": [], "entities": [{"text": "RANK", "start_pos": 16, "end_pos": 20, "type": "METRIC", "confidence": 0.5098382234573364}]}, {"text": "It seems that RANK works better when the target domain is simpler, maybe because it can benefit more from in-domain neighbours of the less rich and ambiguous domain.", "labels": [], "entities": [{"text": "RANK", "start_pos": 14, "end_pos": 18, "type": "TASK", "confidence": 0.9115551114082336}]}, {"text": "In the future, we plan to increase the impact of lexically different but reliably labeled source data by implementing the SFA algorithm and measuring document similarity between feature clusters rather than separate features.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Correlation for various similarity measures with sentiment scores of documents across different domains.", "labels": [], "entities": []}, {"text": " Table 2: Comparison of different cross-domain algorithms", "labels": [], "entities": []}, {"text": " Table 3: Best number of labeled and unlabeled neighbours for the RANK algorithm over various domain pairs", "labels": [], "entities": []}]}