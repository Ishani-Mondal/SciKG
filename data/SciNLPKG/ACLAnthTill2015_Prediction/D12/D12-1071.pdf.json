{"title": [{"text": "Resolving Complex Cases of Definite Pronouns: The Winograd Schema Challenge", "labels": [], "entities": [{"text": "Resolving Complex Cases of Definite Pronouns", "start_pos": 0, "end_pos": 44, "type": "TASK", "confidence": 0.9033661981423696}]}], "abstractContent": [{"text": "We examine the task of resolving complex cases of definite pronouns, specifically those for which traditional linguistic constraints on coreference (e.g., Binding Constraints, gender and number agreement) as well as commonly-used resolution heuristics (e.g., string-matching facilities, syntactic salience) are not useful.", "labels": [], "entities": []}, {"text": "Being able to solve this task has broader implications in artificial intelligence: a restricted version of it, sometimes referred to as the Winograd Schema Challenge, has been suggested as a conceptually and practically appealing alternative to the Turing Test.", "labels": [], "entities": []}, {"text": "We employ a knowledge-rich approach to this task, which yields a pronoun resolver that out-performs state-of-the-art resolvers by nearly 18 points inaccuracy on our dataset.", "labels": [], "entities": []}], "introductionContent": [{"text": "Despite the significant amount of work on pronoun resolution in the natural language processing community in the past forty years, the problem is still far from being solved.", "labels": [], "entities": [{"text": "pronoun resolution", "start_pos": 42, "end_pos": 60, "type": "TASK", "confidence": 0.786944568157196}]}, {"text": "Its difficulty stems in part from its reliance on sophisticated knowledge sources and inference mechanisms.", "labels": [], "entities": []}, {"text": "The sentence pair below, which we will subsequently refer to as the shout example, illustrates how difficult the problem can be: (1a) Ed shouted at Tim because he crashed the car.", "labels": [], "entities": []}, {"text": "(1b) Ed shouted at Tim because he was angry.", "labels": [], "entities": []}, {"text": "The pronoun he refers to Tim in 1a and Ed in 1b.", "labels": [], "entities": []}, {"text": "Humans can resolve the pronoun easily, but stateof-the-art coreference resolvers cannot.", "labels": [], "entities": [{"text": "coreference resolvers", "start_pos": 59, "end_pos": 80, "type": "TASK", "confidence": 0.6724397242069244}]}, {"text": "The reason is that humans have the kind of world knowledge needed to resolve the pronouns that machines do not.", "labels": [], "entities": []}, {"text": "Our world knowledge tells us that if someone is angry, he may shout at other people.", "labels": [], "entities": []}, {"text": "Since Ed shouted, he should be the one who was angry.", "labels": [], "entities": []}, {"text": "Our world knowledge also tells us that we may shout at someone who made a mistake and that crashing a car is a mistake.", "labels": [], "entities": []}, {"text": "Combining these two pieces of evidence, we can easily infer that Tim crashed the car.", "labels": [], "entities": []}, {"text": "Our goal in this paper is to examine the resolution of complex cases of definite pronouns that appear in sentences exemplified by the shout example.", "labels": [], "entities": [{"text": "resolution of complex cases of definite pronouns", "start_pos": 41, "end_pos": 89, "type": "TASK", "confidence": 0.7869347248758588}]}, {"text": "Specifically, each sentence (1) has two clauses separated by a discourse connective (i.e., the connective appears between the two clauses, just like because in the shout example), where the first clause contains two or more candidate antecedents (e.g.,, and the second clause contains the target pronoun (e.g., he); and (2) the target pronoun agrees in gender, number, and semantic class with each candidate antecedent, but does not have any overlap in content words with any of them.", "labels": [], "entities": []}, {"text": "For convenience, we will refer to the target pronoun that appears in this kind of sentences as a difficult pronoun.", "labels": [], "entities": []}, {"text": "Note that many traditional linguistic constraints on coreference are no longer useful for resolving difficult pronouns.", "labels": [], "entities": [{"text": "coreference", "start_pos": 53, "end_pos": 64, "type": "TASK", "confidence": 0.9692884683609009}]}, {"text": "For instance, syntactic constraints such as the Binding Constraints will not be useful, since the pronoun and the candidate antecedents appear in different clauses separated by a discourse connective; and constraints concerning agreement in gender, number, and semantic class will not be useful, since the pronoun and the candidate antecedents are compatible with respect to all these attributes.", "labels": [], "entities": []}, {"text": "Traditionally important clues provided by various I(a) The city councilmen refused the demonstrators a permit because they feared violence.", "labels": [], "entities": []}, {"text": "I(b) The city councilmen refused the demonstrators a permit because they advocated violence.", "labels": [], "entities": []}, {"text": "II(a) James asked Robert fora favor, but he refused.", "labels": [], "entities": []}, {"text": "II(b) James asked Robert fora favor, but he was refused.", "labels": [], "entities": []}, {"text": "III(a) Keith fired Blaine but he did not regret.", "labels": [], "entities": []}, {"text": "III(b) Keith fired Blaine although he is diligent.", "labels": [], "entities": []}, {"text": "IV(a) Emma did not pass the ball to Janie, although she was open.", "labels": [], "entities": []}, {"text": "IV(b) Emma did not pass the ball to Janie, although she should have.", "labels": [], "entities": [{"text": "Emma", "start_pos": 6, "end_pos": 10, "type": "METRIC", "confidence": 0.9444866180419922}]}, {"text": "V(a) Medvedev will cede the presidency to Putin because he is more popular.", "labels": [], "entities": []}, {"text": "V(b) Medvedev will cede the presidency to Putin because he is less popular.: Sample twin sentences.", "labels": [], "entities": []}, {"text": "The target pronoun in each sentence is italicized, and its antecedent is boldfaced.", "labels": [], "entities": []}, {"text": "string-matching facilities will not be useful either, since the pronoun and its candidate antecedents do not have any words in common.", "labels": [], "entities": []}, {"text": "As in the shout example, we ensure that each sentence has a twin.", "labels": [], "entities": []}, {"text": "Twin sentences were used extensively by researchers in the 1970s to illustrate the difficulty of pronoun resolution.", "labels": [], "entities": [{"text": "pronoun resolution", "start_pos": 97, "end_pos": 115, "type": "TASK", "confidence": 0.7548225224018097}]}, {"text": "We consider two sentences as twins if (1) they are identical up to and possibly including the discourse connective; and (2) the difficult pronouns in them are lexically identical but have different antecedents.", "labels": [], "entities": []}, {"text": "The presence of twins implies that syntactic salience, a commonly-used heuristic in pronoun resolution that prefers the selection of syntactically salient candidate antecedents, may no longer be useful, since the candidate in the subject position is not more likely to be the correct antecedent than the other candidates.", "labels": [], "entities": [{"text": "syntactic salience", "start_pos": 35, "end_pos": 53, "type": "TASK", "confidence": 0.7910931706428528}, {"text": "pronoun resolution", "start_pos": 84, "end_pos": 102, "type": "TASK", "confidence": 0.7391959726810455}]}, {"text": "To enable the reader to get a sense of how hard it is to resolve difficult pronouns, shows sample twin sentences from our dataset.", "labels": [], "entities": []}, {"text": "Note that state-ofthe-art pronoun resolvers (e.g., JavaRAP (), GuiTaR (), as well as those designed by and) and coreference resolvers (e.g.,,), Reconcile (, the Stanford resolver () cannot accurately resolve the difficult pronouns in these structurally simple sentences, as they do not have the mechanism to capture the fine distinctions between twin sentences.", "labels": [], "entities": [{"text": "coreference resolvers", "start_pos": 112, "end_pos": 133, "type": "TASK", "confidence": 0.9014979600906372}]}, {"text": "In other words, when given these sentences, the best that the existing resolvers can do to resolve the pronouns is guessing.", "labels": [], "entities": []}, {"text": "This could be surprising to a non-coreference researcher, but it is indeed the state of the art.", "labels": [], "entities": []}, {"text": "A natural question is: why do existing resolvers not attempt to handle difficult pronouns?", "labels": [], "entities": []}, {"text": "One reason could be that these difficult pronouns do not appear frequently in standard evaluation corpora such as.", "labels": [], "entities": []}, {"text": "In fact, the Stanford coreference resolver (, which won the CoNLL-2011 shared task on coreference resolution, adopts the once-popular rule-based approach, resolving pronouns simply with rules that encode the aforementioned traditional linguistic constraints on coreference, such as the Binding constraints and gender and number agreement.", "labels": [], "entities": [{"text": "coreference resolver", "start_pos": 22, "end_pos": 42, "type": "TASK", "confidence": 0.6680734157562256}, {"text": "coreference resolution", "start_pos": 86, "end_pos": 108, "type": "TASK", "confidence": 0.843146413564682}]}, {"text": "The infrequency of occurrences of difficult pronouns in these standard evaluation corpora by no means undermines their significance, however.", "labels": [], "entities": []}, {"text": "In fact, being able to automatically resolve difficult pronouns has broader implications in artificial intelligence.", "labels": [], "entities": []}, {"text": "Recently, has argued that the problem of resolving the difficult pronouns in a carefully chosen set of twin sentences, which he refers to as the Winograd Schema Challenge 1 , could serve as a conceptually and practically appealing alternative to the well-known Turing Test (Turing, 1 Levesque (2011) defines a Winograd Schema as a small reading comprehension test involving the question of which of the two candidate antecedents for the definite pronoun in a given sentence is its correct antecedent.", "labels": [], "entities": []}, {"text": "Levesque names this challenge after Winograd because of his pioneering attempt to use a well-known pair of twin sentences -specifically the first pair in -to illustrate the difficulty of natural language understanding.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 187, "end_pos": 217, "type": "TASK", "confidence": 0.6729258497556051}]}, {"text": "Strictly speaking, we are addressing a relaxed version of the Challenge: while Levesque focuses solely on definite pronouns whose resolution requires background knowledge not expressed in the words of a sentence, we do not impose such a condition on a sentence.", "labels": [], "entities": []}, {"text": "The reason should perhaps be clear given the above discussion: this is an easy task fora subject who can \"understand\" natural language but a challenging task for one who can only make intelligent guesses.", "labels": [], "entities": []}, {"text": "Levesque believes that \"with a very high probability\", anything that can resolve correctly a series of difficult pronouns \"is thinking in the fullbodied sense we usually reserve for people\".", "labels": [], "entities": []}, {"text": "Hence, being able to make progress on this task enables us to move one step closer to building an intelligent machine that can truly understand natural language.", "labels": [], "entities": []}, {"text": "To sum up, an important contribution of our work is that it opens up anew line of research involving a problem whose solution requires a deeper understanding of a text.", "labels": [], "entities": []}, {"text": "With recent advances in knowledge extraction from text, we believe that time is ripe to tackle this problem.", "labels": [], "entities": [{"text": "knowledge extraction from text", "start_pos": 24, "end_pos": 54, "type": "TASK", "confidence": 0.8127822354435921}]}, {"text": "It is worth noting that some researchers have focused on other kinds of anaphors that are hard to resolve, including bridging anaphors (e.g., ) and anaphors referring to abstract entities, such as those realized by verb phrases in dialogs (e.g.,,,).", "labels": [], "entities": []}, {"text": "Nevertheless, to our knowledge, there has been little work that specifically targets difficult pronouns.", "labels": [], "entities": []}, {"text": "Given the complexity of our task, we investigate a variety of sophisticated knowledge sources for resolving difficult pronouns, and combine them via a machine learning approach.", "labels": [], "entities": []}, {"text": "Note that there has been a recent surge of interest in extracting world knowledge from online encyclopedias such as Wikipedia (e.g.,,), YAGO (e.g.,, Rahman and Ng (2011),), and Freebase (e.g.,).", "labels": [], "entities": [{"text": "YAGO", "start_pos": 136, "end_pos": 140, "type": "DATASET", "confidence": 0.8294103145599365}, {"text": "Freebase", "start_pos": 177, "end_pos": 185, "type": "DATASET", "confidence": 0.9371044039726257}]}, {"text": "However, the resulting extractions are primarily IS-A relations (e.g., Barack Obama IS-A U.", "labels": [], "entities": []}, {"text": "S. president), which would not be useful for resolving definite pronouns.", "labels": [], "entities": []}], "datasetContent": [{"text": "We asked 30 undergraduate students who are not affiliated with this research to compose sentence pairs (i.e., twin sentences) that conform to the constraints specified in the introduction.", "labels": [], "entities": []}, {"text": "Each student was also asked to annotate the candidate antecedents, the target pronoun, and the correct antecedent for each sentence she composed.", "labels": [], "entities": []}, {"text": "Note that a sentence may contain multiple pronouns, but exactly one of them -the one explicitly annotated by its author -is the target pronoun.", "labels": [], "entities": []}, {"text": "Each sentence pair was crosschecked by one other student to ensure that it (1) conforms to the desired constraints and (2) does not contain pronouns with ambiguous antecedents (in other words, a human should not be confused as to which candidate antecedent is the correct one).", "labels": [], "entities": []}, {"text": "At the end of the process, 941 sentence pairs were considered acceptable, and they formed our dataset.", "labels": [], "entities": []}, {"text": "These sentences cover a variety of topics, ranging from real events (e.g., Iran's plan to attack the Saudi ambassador to the U.S.), to events and characters in movies (e.g., Batman and Robin), to purely imaginary situations (e.g., the shout example).", "labels": [], "entities": []}, {"text": "We partition these sentence pairs into a training set and a test set following a 70/30 ratio.", "labels": [], "entities": []}, {"text": "While not requested by us, the students annotated exactly two candidate antecedents for each sentence.", "labels": [], "entities": []}, {"text": "For ease of exposition, we will assume below that there are two candidate antecedents per sentence.", "labels": [], "entities": []}, {"text": "We report results on the test set, which comprises 30% of our hand-annotated sentence pairs (see Section 2 for details).", "labels": [], "entities": []}, {"text": "Results are expressed in terms of accuracy, which is the percentage of correctly resolved target pronouns.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9994812607765198}]}, {"text": "We also report the percentages of these pronouns that are (1) not resolved and (2) incorrectly resolved.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Results of the Stanford resolver, the Baseline Ranker, the Combined resolver, and our system.", "labels": [], "entities": [{"text": "resolver", "start_pos": 34, "end_pos": 42, "type": "TASK", "confidence": 0.46826156973838806}]}, {"text": " Table 4: Results of feature ablation experiments.", "labels": [], "entities": []}, {"text": " Table 5: Results of single-feature coreference models.", "labels": [], "entities": []}]}