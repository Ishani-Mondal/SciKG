{"title": [], "abstractContent": [{"text": "Decoding algorithms for syntax based machine translation suffer from high computational complexity, a consequence of intersecting a language model with a context free grammar.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 37, "end_pos": 56, "type": "TASK", "confidence": 0.7100450545549393}]}, {"text": "Left-to-right decoding, which generates the target string in order, can improve decoding efficiency by simplifying the language model evaluation.", "labels": [], "entities": []}, {"text": "This paper presents a novel left to right decoding algorithm for tree-to-string translation, using a bottom-up parsing strategy and dynamic future cost estimation for each partial translation.", "labels": [], "entities": [{"text": "tree-to-string translation", "start_pos": 65, "end_pos": 91, "type": "TASK", "confidence": 0.7281555235385895}]}, {"text": "Our method outperforms previously published tree-to-string decoders, including a competing left-to-right method.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years there has been rapid progress in the development of tree-to-string models for statistical machine translation.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 94, "end_pos": 125, "type": "TASK", "confidence": 0.7495604356129965}]}, {"text": "These models use the syntactic parse tree of the source language to inform its translation, which allows the models to capture consistent syntactic transformations between the source and target languages, e.g., from subject-verb-object to subject-object-verb word orderings.", "labels": [], "entities": []}, {"text": "Decoding algorithms for grammar-based translation seek to find the best string in the intersection between a weighted context free grammar (the translation mode, given a source string/tree) and a weighted finite state acceptor (an n-gram language model).", "labels": [], "entities": []}, {"text": "This intersection is problematic, as it results in an intractably large grammar, and makes exact search impossible.", "labels": [], "entities": []}, {"text": "Most researchers have resorted to approximate search, typically beam search.", "labels": [], "entities": []}, {"text": "The decoder parses the source sentence, recording the target translations for each span.", "labels": [], "entities": []}, {"text": "As the partial translation hypothesis grows, its component ngrams are scored and the hypothesis score is updated.", "labels": [], "entities": []}, {"text": "This decoding method though is inefficient as it requires recording the language model context (n \u2212 1 words) on the left and right edges of each chart cell.", "labels": [], "entities": []}, {"text": "These contexts allow for boundary ngrams to be evaluated when the cell is used in another grammar production.", "labels": [], "entities": []}, {"text": "In contrast, if the target string is generated in left-to-right order, then only one language model context is required, and the problem of language model evaluation is vastly simplified.", "labels": [], "entities": [{"text": "language model evaluation", "start_pos": 140, "end_pos": 165, "type": "TASK", "confidence": 0.6331720650196075}]}, {"text": "In this paper, we develop a novel method of leftto-right decoding for tree-to-string translation using a shift-reduce parsing strategy.", "labels": [], "entities": [{"text": "tree-to-string translation", "start_pos": 70, "end_pos": 96, "type": "TASK", "confidence": 0.7302983105182648}]}, {"text": "A central issue in any decoding algorithm is the technique used for pruning the search space.", "labels": [], "entities": []}, {"text": "Our left-to-right decoding algorithm groups hypotheses, which cover the same number of source words, into a bin.", "labels": [], "entities": []}, {"text": "Pruning requires the evaluation of different hypotheses in the same bin, and elimating the least promising options.", "labels": [], "entities": []}, {"text": "As each hypotheses may cover different sets of tree nodes, it is necessary to consider the cost of uncovered nodes, i.e., the future cost.", "labels": [], "entities": []}, {"text": "We show that a good future cost estimate is essential for accurate and efficient search, leading to high quality translation output.", "labels": [], "entities": []}, {"text": "Other researchers have also considered the leftto-right decoding algorithm for tree-to-string models.", "labels": [], "entities": []}, {"text": "developed an Earleystyle parsing algorithm.", "labels": [], "entities": [{"text": "Earleystyle parsing", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.5939285010099411}]}, {"text": "In their approach, hypotheses covering the same number of tree nodes were binned together.", "labels": [], "entities": []}, {"text": "Their method uses a top-down depth-first search, with a mechanism for early elimation of some rules which lead to deadends in the search.'s method was shown to outperform the traditional post-ordertraversal decoding algorithm, considering fewer hypotheses and thus decoding much faster at the same level of performance.", "labels": [], "entities": []}, {"text": "However their algorithm used a very rough estimate of future cost, resulting in more search errors than our approach.", "labels": [], "entities": []}, {"text": "Our experiments show that compared with the Earley-style left-to-right decoding and the traditional post-order-traversal decoding () algorithms, our algorithm achieves a significant improvement on search capacity and better translation performance at the same level of speed.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the experiments, we use two baseline systems: our in-house tree-to-string decoder implemented according to (denoted as traditional) and the Earley-style top-down decoder implemented according to (denoted as topdown), respectively.", "labels": [], "entities": []}, {"text": "We compare our bottom-up left-to-right decoder (denoted as bottom-up) with the baseline in terms of performance, translation quality and decoding speed with different beam sizes, and search capacity.", "labels": [], "entities": []}, {"text": "Lastly, we show the influence of future cost.", "labels": [], "entities": []}, {"text": "All systems are implemented in C++.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Search capacity comparison. The first column is  beam size, the following three columns denote the num- ber of test sentences, on which the translation scores of  the bottom-up decoder are greater, equal to, lower than  that of the traditional decoder.", "labels": [], "entities": []}, {"text": " Table 5. From  the result, we can conclude that future cost plays a  significant role in decoding. If the bottom-up de- coder does not employ future cost, its performance", "labels": [], "entities": []}]}