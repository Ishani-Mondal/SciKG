{"title": [{"text": "Cross-Lingual Language Modeling with Syntactic Reordering for Low-Resource Speech Recognition", "labels": [], "entities": [{"text": "Cross-Lingual Language Modeling", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7270536621411642}, {"text": "Syntactic Reordering", "start_pos": 37, "end_pos": 57, "type": "TASK", "confidence": 0.7560263276100159}, {"text": "Low-Resource Speech Recognition", "start_pos": 62, "end_pos": 93, "type": "TASK", "confidence": 0.6460340718428293}]}], "abstractContent": [{"text": "This paper proposes cross-lingual language modeling for transcribing source resource-poor languages and translating them into target resource-rich languages if necessary.", "labels": [], "entities": [{"text": "cross-lingual language modeling", "start_pos": 20, "end_pos": 51, "type": "TASK", "confidence": 0.677180012067159}, {"text": "transcribing source resource-poor languages", "start_pos": 56, "end_pos": 99, "type": "TASK", "confidence": 0.8338039070367813}]}, {"text": "Our focus is to improve the speech recognition performance of low-resource languages by leveraging the language model statistics from resource-rich languages.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 28, "end_pos": 46, "type": "TASK", "confidence": 0.7696218490600586}]}, {"text": "The most challenging work of cross-lingual language modeling is to solve the syntactic discrepancies between the source and target languages.", "labels": [], "entities": [{"text": "cross-lingual language modeling", "start_pos": 29, "end_pos": 60, "type": "TASK", "confidence": 0.7171589732170105}]}, {"text": "We therefore propose syntactic reordering for cross-lingual language modeling, and present a first result that compares inversion transduction grammar (ITG) reordering constraints to IBM and local constraints in an integrated speech transcription and translation system.", "labels": [], "entities": [{"text": "cross-lingual language modeling", "start_pos": 46, "end_pos": 77, "type": "TASK", "confidence": 0.7153903245925903}, {"text": "speech transcription and translation", "start_pos": 226, "end_pos": 262, "type": "TASK", "confidence": 0.718300387263298}]}, {"text": "Evaluations on resource-poor Cantonese speech transcription and Cantonese to resource-rich Mandarin translation tasks show that our proposed approach improves the system performance significantly , up to 3.4% relative WER reduction in Cantonese transcription and 13.3% relative bilingual evaluation understudy (BLEU) score improvement in Mandarin transcription compared with the system without reordering.", "labels": [], "entities": [{"text": "Cantonese to resource-rich Mandarin translation tasks", "start_pos": 64, "end_pos": 117, "type": "TASK", "confidence": 0.7056782891352972}, {"text": "WER reduction", "start_pos": 218, "end_pos": 231, "type": "METRIC", "confidence": 0.9655766189098358}, {"text": "relative bilingual evaluation understudy (BLEU) score", "start_pos": 269, "end_pos": 322, "type": "METRIC", "confidence": 0.726270467042923}]}], "introductionContent": [{"text": "Statistical language modeling techniques have achieved remarkable success in speech and language processing).", "labels": [], "entities": [{"text": "Statistical language modeling", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.7797398567199707}]}, {"text": "However, this success largely depends on the availability of a large amount of suitable text data in a language.", "labels": [], "entities": []}, {"text": "Without sufficient text data for training, it is very difficult to build a practical and usable statistical language model.", "labels": [], "entities": []}, {"text": "Therefore, most of the advances have been reported in so called resource-rich language such as English, Mandarin and Japanese, after creating linguistic resources of these languages at considerable cost.", "labels": [], "entities": []}, {"text": "Today there are more than 6000 living languages spoken in the world (, and most of them have little transcribed texts and are considered as resource-poor languages).", "labels": [], "entities": []}, {"text": "Many of these languages are actually spoken by a huge number of speakers (e.g. some Chinese and Indian languages), and thus there is still a great demand to build speech and language processing systems for these languages.", "labels": [], "entities": []}, {"text": "Owing to data scarcity, most often an interpolation) of language models between a resource-poor language and a resource-rich language is used inmost low-resource ASR systems.", "labels": [], "entities": [{"text": "ASR", "start_pos": 162, "end_pos": 165, "type": "TASK", "confidence": 0.9629811644554138}]}, {"text": "Some researchers have proposed transforming resource-rich language models to resource-poor language models by word-level transduction, either in a context-independent or context-dependent manner (.", "labels": [], "entities": []}, {"text": "In), a simple dictionary based contextindependent transduction from a resource-rich language to a resource-poor language is exploited to improve speech recognition of the resource-poor language.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 145, "end_pos": 163, "type": "TASK", "confidence": 0.7032605707645416}]}, {"text": "In (, context-dependent transduction is exploited.", "labels": [], "entities": []}, {"text": "In their case, the resource-poor language is a spoken language, and the resource-rich language is a written language.", "labels": [], "entities": []}, {"text": "They carried out language model transformation since the input speech is in speaking-style and the output text is in writtenstyle.", "labels": [], "entities": [{"text": "language model transformation", "start_pos": 17, "end_pos": 46, "type": "TASK", "confidence": 0.651074230670929}]}, {"text": "Others have investigated cross-lingual information between a resource-poor language and a resource-rich language.", "labels": [], "entities": []}, {"text": "In (), cross-language cues are used to improve a language model of a resource-poor language.", "labels": [], "entities": []}, {"text": "They used cross-lingual unigram probabilities trained from a story-specific parallel corpus of the resourcepoor and resource-rich languages.", "labels": [], "entities": []}, {"text": "They interpolate the language model of the resource-poor language with those unigram probabilities.", "labels": [], "entities": []}, {"text": "In, an n-gram language model in a resource-poor language is interpolated with crosslingual unigram trigger probabilities.", "labels": [], "entities": []}, {"text": "These triggers are word pairs of the resource-poor and resourcerich languages with the highest mutual information across these two languages.", "labels": [], "entities": []}, {"text": "Another way of estimating those unigram probabilities is using latent semantic analysis by measuring cosine similarities from a document-aligned corpus for any given word pair (.", "labels": [], "entities": []}, {"text": "Both interpolation and word-level transduction approaches fail to meet the challenge of syntactic discrepancies between the resource-poor and resource-rich languages.", "labels": [], "entities": [{"text": "word-level transduction", "start_pos": 23, "end_pos": 46, "type": "TASK", "confidence": 0.6860858052968979}]}, {"text": "This syntactic discrepancies exist, for example, even between the Sinitic languages and Indian languages 1 of the same family.", "labels": [], "entities": []}, {"text": "Sinitic languages such as Cantonese/Yue, Shanghai/Wu, etc. are officially considered as \"dialects\" of the standard Chinese Mandarin (or Putonghua) 2 . However, they differ greatly from Mandarin in all aspects and are not mutually comprehensible.", "labels": [], "entities": []}, {"text": "For instance, in addition to lexical and pronunciation differences, Cantonese Chinese (Lee, 2011) differs syntactically from Mandarin as well -we found that there are approximately 10% syntactic inversions between sentences of the two forms of Chinese.", "labels": [], "entities": []}, {"text": "We suggest that a better approach than interpolation and word-level transduction is to use crosslingual language modeling with syntactic reorder-1 For example,).", "labels": [], "entities": [{"text": "word-level transduction", "start_pos": 57, "end_pos": 80, "type": "TASK", "confidence": 0.6931374967098236}]}, {"text": "Since Cantonese does not have an official written form, there are very few written texts available for training language models.", "labels": [], "entities": []}, {"text": "In this paper, we treat Cantonese as atypical resourcepoor language and Mandarin as atypical resource-rich language.", "labels": [], "entities": []}, {"text": "This language pair will be used for illustration purposes throughout this paper. ing.", "labels": [], "entities": []}, {"text": "A reordering model with reordering constraints, such as ITG constraints (Wu, 1997), IBM constraints (, and local constraints () can account for the syntactic differences.", "labels": [], "entities": []}, {"text": "It has been shown in) that ITG constraints perform better than other constraints when tackling the reordering between many language pairs.", "labels": [], "entities": []}, {"text": "Previous work on weighted finitestate transducer (WFST) based speech translation such as only train the reordering model using IBM constraints, local constraints or ad hoc rules.", "labels": [], "entities": [{"text": "speech translation", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.7627851963043213}]}, {"text": "We will use ITG constraints, which have only been applied to text translation tasks before, to model the syntactic differences in cross-lingual language modeling for speech recognition.", "labels": [], "entities": [{"text": "text translation tasks", "start_pos": 61, "end_pos": 83, "type": "TASK", "confidence": 0.800002912680308}, {"text": "speech recognition", "start_pos": 166, "end_pos": 184, "type": "TASK", "confidence": 0.773173451423645}]}, {"text": "We will implement a cross-lingual language model using WFSTs, and integrate it into a WFSTbased speech recognition search space to give both resource-poor language and resource-rich language transcriptions.", "labels": [], "entities": [{"text": "WFSTs", "start_pos": 55, "end_pos": 60, "type": "DATASET", "confidence": 0.9445377588272095}, {"text": "WFSTbased speech recognition search", "start_pos": 86, "end_pos": 121, "type": "TASK", "confidence": 0.7061841487884521}]}, {"text": "This creates an integrated speech transcription and translation framework.", "labels": [], "entities": [{"text": "speech transcription and translation", "start_pos": 27, "end_pos": 63, "type": "TASK", "confidence": 0.6743813157081604}]}, {"text": "This paper is organized as follows: Section 2 presents our proposed cross-lingual language modeling with syntactic reordering.", "labels": [], "entities": [{"text": "cross-lingual language modeling", "start_pos": 68, "end_pos": 99, "type": "TASK", "confidence": 0.687595804532369}]}, {"text": "In Section 3, we discuss speech recognition with cross-lingual language models.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 25, "end_pos": 43, "type": "TASK", "confidence": 0.8264565765857697}]}, {"text": "Section 4 and 5 give the experimental setup and results.", "labels": [], "entities": []}, {"text": "We conclude our work at the end of this paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "Decoding of the speech recognition search space ASR is performed by T 3 Decoder (, which is a state-of-the-art WFST-based LVCSR speech decoder.", "labels": [], "entities": [{"text": "speech recognition search space ASR", "start_pos": 16, "end_pos": 51, "type": "TASK", "confidence": 0.8564313411712646}, {"text": "WFST-based LVCSR speech decoder", "start_pos": 111, "end_pos": 142, "type": "DATASET", "confidence": 0.8020936846733093}]}, {"text": "Decoding of ASR in Eq. gives Mandarin outputs.", "labels": [], "entities": [{"text": "ASR", "start_pos": 12, "end_pos": 15, "type": "TASK", "confidence": 0.7878199815750122}, {"text": "Eq.", "start_pos": 19, "end_pos": 22, "type": "DATASET", "confidence": 0.8990800380706787}]}, {"text": "Decoding of ASR in Eq. gives Cantonese outputs.", "labels": [], "entities": [{"text": "ASR", "start_pos": 12, "end_pos": 15, "type": "TASK", "confidence": 0.6698784232139587}, {"text": "Eq.", "start_pos": 19, "end_pos": 22, "type": "DATASET", "confidence": 0.9074872732162476}]}, {"text": "In our experiments, we use the following evaluation criteria: WER (word error rate).", "labels": [], "entities": [{"text": "WER", "start_pos": 62, "end_pos": 65, "type": "METRIC", "confidence": 0.9988309741020203}, {"text": "word error rate)", "start_pos": 67, "end_pos": 83, "type": "METRIC", "confidence": 0.8119215369224548}]}, {"text": "The WER is computed as the minimum number of substitution, insertion and deletion operations that have to be performed to convert the generated sentence into the reference sentence ().", "labels": [], "entities": [{"text": "WER", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.9944497346878052}]}, {"text": "The WER relates the speech recognition accuracy.", "labels": [], "entities": [{"text": "WER", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.8172457814216614}, {"text": "speech recognition", "start_pos": 20, "end_pos": 38, "type": "TASK", "confidence": 0.7546440958976746}, {"text": "accuracy", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.9405235648155212}]}, {"text": "The lower WER, the better.", "labels": [], "entities": [{"text": "WER", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9994595646858215}]}, {"text": "BLEU (bilingual evaluation understudy) score.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9744892120361328}]}, {"text": "The BLEU score measures the precision of n-grams (unigrams, bigrams, trigrams and fourgrams) with respect to a reference translation with a penalty for too short sentences ().", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9779424667358398}, {"text": "precision", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.9991160035133362}]}, {"text": "The BLEU score reflects the translation accuracy.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9631757438182831}, {"text": "translation", "start_pos": 28, "end_pos": 39, "type": "TASK", "confidence": 0.9437706470489502}, {"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.9717645645141602}]}, {"text": "The larger BLEU score, the better.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 11, "end_pos": 21, "type": "METRIC", "confidence": 0.9511131346225739}]}, {"text": "We perform WER evaluation of decoding outputs of Eq.", "labels": [], "entities": [{"text": "WER", "start_pos": 11, "end_pos": 14, "type": "TASK", "confidence": 0.5616379976272583}, {"text": "Eq", "start_pos": 49, "end_pos": 51, "type": "DATASET", "confidence": 0.9136906862258911}]}, {"text": "(10) and BLEU score evaluation of decoding outputs of Eq.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 9, "end_pos": 13, "type": "METRIC", "confidence": 0.9987963438034058}, {"text": "Eq", "start_pos": 54, "end_pos": 56, "type": "DATASET", "confidence": 0.8989348411560059}]}, {"text": "(9) using the evaluation set.", "labels": [], "entities": []}, {"text": "The WER evaluation is on the Cantonese output against the Cantonese reference transcription (manual transcription).", "labels": [], "entities": [{"text": "WER", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.8365366458892822}]}, {"text": "The BLEU score evaluation is on the Mandarin output against the Mandarin reference transcription (Hansard transcription).", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.970113068819046}, {"text": "Hansard transcription", "start_pos": 98, "end_pos": 119, "type": "DATASET", "confidence": 0.9273316264152527}]}, {"text": "The evaluation results of the proposed cross-lingual language models G cl with reordering under various constraints are presented in, where In general, reordering has a significant effect on enhancing the performance of recognition and translation in the sense of WER reduction and BLEU improvement.", "labels": [], "entities": [{"text": "WER reduction", "start_pos": 264, "end_pos": 277, "type": "METRIC", "confidence": 0.9109808206558228}, {"text": "BLEU", "start_pos": 282, "end_pos": 286, "type": "METRIC", "confidence": 0.9986691474914551}]}, {"text": "Compared with the cross-lingual language model without reordering, the cross-lingual language model with reordering under local constraints gives 0.70% absolute WER reduction and 3.06 absolute BLEU improvement.", "labels": [], "entities": [{"text": "WER reduction", "start_pos": 161, "end_pos": 174, "type": "METRIC", "confidence": 0.9546914994716644}, {"text": "BLEU", "start_pos": 193, "end_pos": 197, "type": "METRIC", "confidence": 0.981240451335907}]}, {"text": "The cross-lingual language model with reordering under IBM constraints gives 0.85% absolute WER reduction and 3.58 absolute BLEU improvement.", "labels": [], "entities": [{"text": "WER reduction", "start_pos": 92, "end_pos": 105, "type": "METRIC", "confidence": 0.9017190635204315}, {"text": "BLEU", "start_pos": 124, "end_pos": 128, "type": "METRIC", "confidence": 0.9809978604316711}]}, {"text": "The cross-lingual language model with reordering under ITG constraints yields the best performance, with 0.92% absolute WER reduction and 3.89 absolute BLEU improvement.", "labels": [], "entities": [{"text": "ITG", "start_pos": 55, "end_pos": 58, "type": "DATASET", "confidence": 0.8766606450080872}, {"text": "WER reduction", "start_pos": 120, "end_pos": 133, "type": "METRIC", "confidence": 0.9066708981990814}, {"text": "BLEU", "start_pos": 152, "end_pos": 156, "type": "METRIC", "confidence": 0.9706300497055054}]}, {"text": "All WER improvements pointed out here are statistically significant at 99% confidence according to a two-proportional z-test, and all BLEU improvements are statistically significant at 95% confidence according to a paired student t-test using bootstrap resampling.", "labels": [], "entities": [{"text": "WER", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.8718379139900208}, {"text": "BLEU", "start_pos": 134, "end_pos": 138, "type": "METRIC", "confidence": 0.9982530474662781}]}, {"text": "We have chosen segmentation order s = 3 because it works the best in our system.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 15, "end_pos": 27, "type": "TASK", "confidence": 0.9694282412528992}]}], "tableCaptions": [{"text": " Table 1: Comparison of permutation number under local constraints (N Local ), IBM constraints (N IBM(4) ) and ITG  constraints (N IT G ). The comparison is constrained by the phrase number K and the reordering distance L.  K=2 K=3 K=4 K=5 K=6 K=7  K=8  K=9  K=10", "labels": [], "entities": []}, {"text": " Table 2: No. of substitutions, insertions, deletions and  inversions identified in the parallel corpus with different  segmentation order s.", "labels": [], "entities": []}]}