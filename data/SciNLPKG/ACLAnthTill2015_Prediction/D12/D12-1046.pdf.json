{"title": [{"text": "Joint Chinese Word Segmentation, POS Tagging and Parsing", "labels": [], "entities": [{"text": "Chinese Word Segmentation", "start_pos": 6, "end_pos": 31, "type": "TASK", "confidence": 0.6482490499814352}, {"text": "POS Tagging", "start_pos": 33, "end_pos": 44, "type": "TASK", "confidence": 0.7658083438873291}, {"text": "Parsing", "start_pos": 49, "end_pos": 56, "type": "TASK", "confidence": 0.3821091055870056}]}], "abstractContent": [{"text": "In this paper, we propose a novel decoding algorithm for discriminative joint Chinese word segmentation, part-of-speech (POS) tagging, and parsing.", "labels": [], "entities": [{"text": "discriminative joint Chinese word segmentation", "start_pos": 57, "end_pos": 103, "type": "TASK", "confidence": 0.5662836074829102}, {"text": "part-of-speech (POS) tagging", "start_pos": 105, "end_pos": 133, "type": "TASK", "confidence": 0.6413511991500854}, {"text": "parsing", "start_pos": 139, "end_pos": 146, "type": "TASK", "confidence": 0.9673183560371399}]}, {"text": "Previous work often used a pipeline method-Chinese word segmentation followed by POS tagging and parsing, which suffers from error propagation and is unable to leverage information in later modules for earlier components.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 51, "end_pos": 68, "type": "TASK", "confidence": 0.72354556620121}, {"text": "POS tagging", "start_pos": 81, "end_pos": 92, "type": "TASK", "confidence": 0.7052864879369736}]}, {"text": "In our approach, we train the three individual models separately during training, and incorporate them together in a unified framework during decoding.", "labels": [], "entities": []}, {"text": "We extend the CYK parsing algorithm so that it can deal with word segmentation and POS tagging features.", "labels": [], "entities": [{"text": "CYK parsing", "start_pos": 14, "end_pos": 25, "type": "TASK", "confidence": 0.8000072240829468}, {"text": "word segmentation", "start_pos": 61, "end_pos": 78, "type": "TASK", "confidence": 0.7566213011741638}, {"text": "POS tagging", "start_pos": 83, "end_pos": 94, "type": "TASK", "confidence": 0.7726821601390839}]}, {"text": "As far as we know, this is the first work on joint Chinese word segmentation, POS tagging and parsing.", "labels": [], "entities": [{"text": "joint Chinese word segmentation", "start_pos": 45, "end_pos": 76, "type": "TASK", "confidence": 0.5506993234157562}, {"text": "POS tagging and parsing", "start_pos": 78, "end_pos": 101, "type": "TASK", "confidence": 0.7184545993804932}]}, {"text": "Our experimental results on Chinese Tree Bank 5 corpus show that our approach outperforms the state-of-the-art pipeline system.", "labels": [], "entities": [{"text": "Chinese Tree Bank 5 corpus", "start_pos": 28, "end_pos": 54, "type": "DATASET", "confidence": 0.9900811791419983}]}], "introductionContent": [{"text": "For Asian languages such as Japanese and Chinese that do not contain explicitly marked word boundaries, word segmentation is an important first step for many subsequent language processing tasks, such as POS tagging, parsing, semantic role labeling, and various applications.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 104, "end_pos": 121, "type": "TASK", "confidence": 0.7189465165138245}, {"text": "POS tagging", "start_pos": 204, "end_pos": 215, "type": "TASK", "confidence": 0.885157436132431}, {"text": "parsing", "start_pos": 217, "end_pos": 224, "type": "TASK", "confidence": 0.9672959446907043}, {"text": "semantic role labeling", "start_pos": 226, "end_pos": 248, "type": "TASK", "confidence": 0.6248335937658945}]}, {"text": "Previous studies for POS tagging and syntax parsing on these languages sometimes assume that gold standard word segmentation information is provided, which is not the real scenario.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 21, "end_pos": 32, "type": "TASK", "confidence": 0.8716279864311218}, {"text": "syntax parsing", "start_pos": 37, "end_pos": 51, "type": "TASK", "confidence": 0.7291510999202728}, {"text": "word segmentation", "start_pos": 107, "end_pos": 124, "type": "TASK", "confidence": 0.72016441822052}]}, {"text": "Ina fully automatic system, a pipeline approach is often adopted, where raw sentences are first segmented into word sequences, then POS tagging and parsing are performed.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 132, "end_pos": 143, "type": "TASK", "confidence": 0.7781422734260559}]}, {"text": "This kind of approach suffers from error propagation.", "labels": [], "entities": [{"text": "error propagation", "start_pos": 35, "end_pos": 52, "type": "TASK", "confidence": 0.6814699470996857}]}, {"text": "For example, word segmentation errors will result in tagging and parsing errors.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 13, "end_pos": 30, "type": "TASK", "confidence": 0.7850648760795593}]}, {"text": "Additionally, early modules cannot use information from subsequent modules.", "labels": [], "entities": []}, {"text": "Intuitively a joint model that performs the three tasks together should help the system make the best decisions.", "labels": [], "entities": []}, {"text": "In this paper, we propose a unified model for joint Chinese word segmentation, POS tagging, and parsing.", "labels": [], "entities": [{"text": "joint Chinese word segmentation", "start_pos": 46, "end_pos": 77, "type": "TASK", "confidence": 0.534376323223114}, {"text": "POS tagging", "start_pos": 79, "end_pos": 90, "type": "TASK", "confidence": 0.8645396530628204}]}, {"text": "Three sub-models are independently trained using the state-of-the-art methods.", "labels": [], "entities": []}, {"text": "We do not use the joint inference algorithm for training because of the high complexity caused by the large amount of parameters.", "labels": [], "entities": []}, {"text": "We use linear chain Conditional Random Fields (CRFs) () to train the word segmentation model and POS tagging model, and averaged perceptron to learn the parsing model.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 69, "end_pos": 86, "type": "TASK", "confidence": 0.7367033213376999}, {"text": "POS tagging", "start_pos": 97, "end_pos": 108, "type": "TASK", "confidence": 0.7058453410863876}]}, {"text": "During decoding, parameters of each sub-model are scaled to represent its importance in the joint model.", "labels": [], "entities": []}, {"text": "Our decoding algorithm is an extension of CYK parsing.", "labels": [], "entities": [{"text": "CYK parsing", "start_pos": 42, "end_pos": 53, "type": "TASK", "confidence": 0.7556794583797455}]}, {"text": "Initially, weights of all possible words together with their POS tags are calculated.", "labels": [], "entities": []}, {"text": "When searching the parse tree, the word and POS tagging features are dynamically generated and the transition information of POS tagging is considered in the span merge operation.", "labels": [], "entities": []}, {"text": "Experiments are conducted on Chinese Tree Bank (CTB) 5 dataset, which is widely used for Chinese word segmentation, POS tagging and parsing.", "labels": [], "entities": [{"text": "Chinese Tree Bank (CTB) 5 dataset", "start_pos": 29, "end_pos": 62, "type": "DATASET", "confidence": 0.9760648310184479}, {"text": "Chinese word segmentation", "start_pos": 89, "end_pos": 114, "type": "TASK", "confidence": 0.5905109643936157}, {"text": "POS tagging", "start_pos": 116, "end_pos": 127, "type": "TASK", "confidence": 0.8649930059909821}]}, {"text": "We compare our proposed joint model with the pipeline system, both built using the state-of-the-art submodels.", "labels": [], "entities": []}, {"text": "We also propose an evaluation metric to calculate the bracket scores for parsing in the face of word segmentation errors.", "labels": [], "entities": [{"text": "parsing", "start_pos": 73, "end_pos": 80, "type": "TASK", "confidence": 0.9675267934799194}, {"text": "word segmentation", "start_pos": 96, "end_pos": 113, "type": "TASK", "confidence": 0.6929308921098709}]}, {"text": "Our experimental results show that the joint model significantly outperforms the pipeline method based on the state-of-the-art sub-models.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate system performance on the individual tasks, as well as the joint tasks.", "labels": [], "entities": []}, {"text": "1 For word segmentation, three metrics are used for evaluation: precision (P), recall (R), and F-score (F) defined by 2PR/(P+R).", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 6, "end_pos": 23, "type": "TASK", "confidence": 0.7559100687503815}, {"text": "precision (P)", "start_pos": 64, "end_pos": 77, "type": "METRIC", "confidence": 0.9396961182355881}, {"text": "recall (R)", "start_pos": 79, "end_pos": 89, "type": "METRIC", "confidence": 0.9492284804582596}, {"text": "F-score (F)", "start_pos": 95, "end_pos": 106, "type": "METRIC", "confidence": 0.9648839831352234}]}, {"text": "Precision is the percentage of correct words in the system output.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9917067289352417}]}, {"text": "Recall is the percentage of words in gold standard annotations that are correctly predicted.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9818984866142273}]}, {"text": "For parsing, we use the standard parseval evaluation metrics: bracketing precision, recall and F-score.", "labels": [], "entities": [{"text": "parsing", "start_pos": 4, "end_pos": 11, "type": "TASK", "confidence": 0.986911416053772}, {"text": "precision", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.7377820014953613}, {"text": "recall", "start_pos": 84, "end_pos": 90, "type": "METRIC", "confidence": 0.9993966817855835}, {"text": "F-score", "start_pos": 95, "end_pos": 102, "type": "METRIC", "confidence": 0.9970666766166687}]}, {"text": "For joint word segmentation and POS tagging, a word is correctly predicted if both the boundaries and the POS tag are correctly identified.", "labels": [], "entities": [{"text": "joint word segmentation", "start_pos": 4, "end_pos": 27, "type": "TASK", "confidence": 0.6128811836242676}, {"text": "POS tagging", "start_pos": 32, "end_pos": 43, "type": "TASK", "confidence": 0.8659699857234955}]}, {"text": "For joint segmentation, POS tagging, and parsing task, when calculating the bracket scores using existing parseval tools, we need to consider possible word segmentation errors.", "labels": [], "entities": [{"text": "joint segmentation", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.7130269706249237}, {"text": "POS tagging", "start_pos": 24, "end_pos": 35, "type": "TASK", "confidence": 0.8907244205474854}, {"text": "parsing task", "start_pos": 41, "end_pos": 53, "type": "TASK", "confidence": 0.9181727170944214}, {"text": "word segmentation", "start_pos": 151, "end_pos": 168, "type": "TASK", "confidence": 0.6830993443727493}]}, {"text": "To do this, we add the word boundary information in states -a bracket is correct only if its boundaries, label and word segmentation are all correct.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 115, "end_pos": 132, "type": "TASK", "confidence": 0.6706202626228333}]}, {"text": "One example is shown in.", "labels": [], "entities": []}, {"text": "Notice that identity unary rules are removed during evaluation.", "labels": [], "entities": []}, {"text": "The basic spans are characters, not words, because the number of words in reference and prediction maybe different.", "labels": [], "entities": []}, {"text": "POS tags are removed since they do not affect the bracket scores.", "labels": [], "entities": [{"text": "POS tags", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.6048324704170227}]}, {"text": "If the segmentation is perfect, then the bracket scores of the modified tree are exactly the same as the original tree.", "labels": [], "entities": []}, {"text": "This is similar to evaluating parsing performance on speech transcripts with automatic sentence segmentation ().", "labels": [], "entities": [{"text": "sentence segmentation", "start_pos": 87, "end_pos": 108, "type": "TASK", "confidence": 0.7515551745891571}]}, {"text": "In this section we first show that our sub-models are better than or comparable to state-of-the-art systems, and then the joint model is superior to the pipeline approach.", "labels": [], "entities": []}, {"text": "shows word segmentation results using our word segmentation submodel, in comparison to a few state-of-the-art systems.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 6, "end_pos": 23, "type": "TASK", "confidence": 0.742728054523468}, {"text": "word segmentation", "start_pos": 42, "end_pos": 59, "type": "TASK", "confidence": 0.6957896798849106}]}, {"text": "For our segmentor, we show results for two variants: one removes transition features as described in Section 3.1, the other uses CRFs to learn the weights of transition features.", "labels": [], "entities": []}, {"text": "We can see that our system is competitive with all the others except Sun's that used additional idiom resources.", "labels": [], "entities": []}, {"text": "Our two word segmentors have similar performance.", "labels": [], "entities": []}, {"text": "Since the one without transition features can be naturally integrated into the joint system, we use it in the following joint tasks.", "labels": [], "entities": []}, {"text": "For the POS tagging only task that takes gold standard word segmentation as input, we have two systems.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 8, "end_pos": 19, "type": "TASK", "confidence": 0.8671788573265076}, {"text": "word segmentation", "start_pos": 55, "end_pos": 72, "type": "TASK", "confidence": 0.7256723642349243}]}, {"text": "One uses the linear chain CRFs as described in Section 3.2, the other is obtained using the parser described in Section 3.3 -the parser generates POS tag hypotheses when POS tag features are not used.", "labels": [], "entities": []}, {"text": "The POS tagging accuracy is 95.53% and 95.10% using these two methods respectively.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.6741058528423309}, {"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9736232161521912}]}, {"text": "The better performance from the former system maybe because the local label dependency is more helpful for POS tagging than the long distance dependencies that might be noisy.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 107, "end_pos": 118, "type": "TASK", "confidence": 0.8234880864620209}]}, {"text": "This result also confirms our choice of using an independent POS tagger for the sub-model, rather than relying on a parser for POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 127, "end_pos": 138, "type": "TASK", "confidence": 0.75013867020607}]}, {"text": "However, since there are no reported results for this setup, we demonstrate the competence of our POS tagger using the joint word segmentation and POS tagging task.", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 98, "end_pos": 108, "type": "TASK", "confidence": 0.7087675780057907}, {"text": "word segmentation", "start_pos": 125, "end_pos": 142, "type": "TASK", "confidence": 0.69202920794487}, {"text": "POS tagging", "start_pos": 147, "end_pos": 158, "type": "TASK", "confidence": 0.7493214011192322}]}, {"text": "shows the performance of a few systems along with ours, all using the pipeline approach where automatic segmentation is followed by POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 132, "end_pos": 143, "type": "TASK", "confidence": 0.6804976612329483}]}, {"text": "We can see that our POS tagger is comparable to the others.", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 20, "end_pos": 30, "type": "TASK", "confidence": 0.6539556086063385}]}, {"text": "For parsing, presents the parsing result on gold standard segmented sentence.", "labels": [], "entities": [{"text": "parsing", "start_pos": 4, "end_pos": 11, "type": "TASK", "confidence": 0.9716448187828064}]}, {"text": "Notice that the result of are not directly comparable to ours, as they used a different data split.", "labels": [], "entities": []}, {"text": "The best published system result on CTB5 is Petrov and Klein's, which used PCFG with latent Variables.", "labels": [], "entities": [{"text": "CTB5", "start_pos": 36, "end_pos": 40, "type": "DATASET", "confidence": 0.8824381828308105}]}, {"text": "Our system performs better mainly because it benefits from a large amount of features.", "labels": [], "entities": []}, {"text": "For our parser, besides the model described in Section 3.3, we tried two variations: one does not use the automatic POS tag features, the other one is learned on the parent annotated training data.", "labels": [], "entities": []}, {"text": "The results in show that there is a performance degradation when using parent annotation.", "labels": [], "entities": []}, {"text": "This maybe due to the introduction of a large number of states, resulting in sparse features.", "labels": [], "entities": []}, {"text": "We also notice that with the help of the POS tag information, even automatically generated, the parser gained 0.9% improvement in F-score.", "labels": [], "entities": [{"text": "F-score", "start_pos": 130, "end_pos": 137, "type": "METRIC", "confidence": 0.9975185394287109}]}, {"text": "This demonstrates the advantage of using a better independent POS tagger and incorporating it in parsing.", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 62, "end_pos": 72, "type": "TASK", "confidence": 0.6384506672620773}]}], "tableCaptions": [{"text": " Table 4: Complexity Analysis of Algorithm 1.", "labels": [], "entities": [{"text": "Complexity Analysis of Algorithm 1", "start_pos": 10, "end_pos": 44, "type": "TASK", "confidence": 0.8238910436630249}]}, {"text": " Table 5: Training, development, and test data of CTB 5.", "labels": [], "entities": []}, {"text": " Table 6: Parameters used in our system.", "labels": [], "entities": []}, {"text": " Table 7: Word segmentation results.", "labels": [], "entities": [{"text": "Word segmentation", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.7148773521184921}]}, {"text": " Table 8: Results for the joint word segmentation and POS  tagging task.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 32, "end_pos": 49, "type": "TASK", "confidence": 0.711961567401886}, {"text": "POS  tagging task", "start_pos": 54, "end_pos": 71, "type": "TASK", "confidence": 0.8711754282315572}]}, {"text": " Table 9: Parsing results using gold standard word seg- mentation.", "labels": [], "entities": [{"text": "Parsing", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9437150955200195}]}, {"text": " Table 10: Results for the joint segmentation, tagging, and  parsing task using pipeline and joint models.", "labels": [], "entities": [{"text": "joint segmentation, tagging", "start_pos": 27, "end_pos": 54, "type": "TASK", "confidence": 0.5876132845878601}, {"text": "parsing", "start_pos": 61, "end_pos": 68, "type": "TASK", "confidence": 0.8914899230003357}]}, {"text": " Table 11: POS tagging error patterns. # means the error  number of the corresponding pattern made by the pipeline  tagging model. \u2193 and \u2191 mean the error number reduced  or increased by the joint model.", "labels": [], "entities": [{"text": "POS tagging error patterns", "start_pos": 11, "end_pos": 37, "type": "TASK", "confidence": 0.7697554379701614}, {"text": "error  number", "start_pos": 51, "end_pos": 64, "type": "METRIC", "confidence": 0.9398821890354156}]}]}