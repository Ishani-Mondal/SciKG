{"title": [{"text": "Learning Syntactic Categories Using Paradigmatic Representations of Word Context", "labels": [], "entities": []}], "abstractContent": [{"text": "We investigate paradigmatic representations of word context in the domain of unsupervised syntactic category acquisition.", "labels": [], "entities": [{"text": "syntactic category acquisition", "start_pos": 90, "end_pos": 120, "type": "TASK", "confidence": 0.6909193992614746}]}, {"text": "Paradigmatic representations of word context are based on potential substitutes of a word in contrast to syntagmatic representations based on properties of neighboring words.", "labels": [], "entities": []}, {"text": "We compare a bigram based baseline model with several paradigmatic models and demonstrate significant gains inaccuracy.", "labels": [], "entities": []}, {"text": "Our best model based on Euclidean co-occurrence embedding combines the paradigmatic context representation with morphological and orthographic features and achieves 80% many-to-one accuracy on a 45-tag 1M word corpus.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 181, "end_pos": 189, "type": "METRIC", "confidence": 0.996063768863678}]}], "introductionContent": [{"text": "Grammar rules apply not to individual words (e.g. dog, eat) but to syntactic categories of words (e.g. noun, verb).", "labels": [], "entities": []}, {"text": "Thus constructing syntactic categories (also known as lexical or part-of-speech categories) is one of the fundamental problems in language acquisition.", "labels": [], "entities": [{"text": "language acquisition", "start_pos": 130, "end_pos": 150, "type": "TASK", "confidence": 0.7254464030265808}]}, {"text": "Syntactic categories represent groups of words that can be substituted for one another without altering the grammaticality of a sentence.", "labels": [], "entities": []}, {"text": "Linguists identify syntactic categories based on semantic, syntactic, and morphological properties of words.", "labels": [], "entities": []}, {"text": "There is also evidence that children use prosodic and phonological features to bootstrap syntactic category acquisition ().", "labels": [], "entities": [{"text": "bootstrap syntactic category acquisition", "start_pos": 79, "end_pos": 119, "type": "TASK", "confidence": 0.577786922454834}]}, {"text": "However there is as yet no satisfactory computational model that can match human performance.", "labels": [], "entities": []}, {"text": "Thus identifying the best set of features and best learning algorithms for syntactic category acquisition is still an open problem.", "labels": [], "entities": [{"text": "syntactic category acquisition", "start_pos": 75, "end_pos": 105, "type": "TASK", "confidence": 0.7318570415178934}]}, {"text": "Relationships between linguistic units can be classified into two types: syntagmatic (concerning positioning), and paradigmatic (concerning substitution).", "labels": [], "entities": []}, {"text": "Syntagmatic relations determine which units can combine to create larger groups and paradigmatic relations determine which units can be substituted for one another.", "labels": [], "entities": []}, {"text": "illustrates the paradigmatic vs syntagmatic axes for words in a simple sentence and their possible substitutes.", "labels": [], "entities": []}, {"text": "In this study, we represent the paradigmatic axis directly by building substitute vectors for each word position in the text.", "labels": [], "entities": []}, {"text": "The dimensions of a substitute vector represent words in the vocabulary, and the magnitudes represent the probability of occurrence in the given position.", "labels": [], "entities": []}, {"text": "Note that the substitute vector fora word position (e.g. the second word in) is a function of the context only (i.e. \"the cried\"), and does not depend on the word that does actually appear there (i.e. \"man\").", "labels": [], "entities": []}, {"text": "Thus substi-: Syntagmatic vs. paradigmatic axes for words in a simple sentence tute vectors represent individual word contexts, not word types.", "labels": [], "entities": []}, {"text": "We refer to the use of features based on substitute vectors as paradigmatic representations of word context.", "labels": [], "entities": []}, {"text": "Our preliminary experiments indicated that using context information alone without the identity or the features of the target word (e.g. using dimensionality reduction and clustering on substitute vectors) has limited success and modeling the co-occurrence of word and context types is essential for inducing syntactic categories.", "labels": [], "entities": []}, {"text": "In the models presented in this paper, we combine paradigmatic representations of word context with features of co-occurring words within the co-occurrence data embedding (CODE) framework ().", "labels": [], "entities": []}, {"text": "The resulting embeddings for word types are split into 45 clusters using k-means and the clusters are compared to the 45 gold tags in the 1M word Penn Treebank Wall Street Journal corpus).", "labels": [], "entities": [{"text": "1M word Penn Treebank Wall Street Journal corpus", "start_pos": 138, "end_pos": 186, "type": "DATASET", "confidence": 0.822992168366909}]}, {"text": "We obtain many-to-one accuracies up to .7680 using only distributional information (the identity of the word and a representation of its context) and .8023 using morphological and orthographic features of words improving the state-ofthe-art in unsupervised part-of-speech tagging performance.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 257, "end_pos": 279, "type": "TASK", "confidence": 0.596872866153717}]}, {"text": "The high probability substitutes reflect both semantic and syntactic properties of the context as seen in the example below (the numbers in parentheses give substitute probabilities): \"Pierre Vinken, 61 years old, will join the board as a nonexecutive director Nov. 29.\" the: its (.9011), the (.0981), a (.0006), . .", "labels": [], "entities": []}, {"text": "board: board (.4288), company (.2584), firm (.2024), bank (.0731), . .", "labels": [], "entities": []}, {"text": "Top substitutes for the word \"the\" consist of words that can act as determiners.", "labels": [], "entities": []}, {"text": "Top substitutes for \"board\" are not only nouns, but specifically nouns compatible with the semantic context.", "labels": [], "entities": []}, {"text": "This example illustrates two concerns inherent in all distributional methods: (i) words that are generally substitutable like \"the\" and \"its\" are placed in separate categories (DT and PRP$) by the gold standard, (ii) words that are generally not substitutable like \"do\" and \"put\" are placed in the same category (VB).", "labels": [], "entities": []}, {"text": "point out that categories with unsubstitutable words fail the standard linguistic definition of a syntactic category and children do not seem to make errors of substituting such words in utterances (e.g. \"What do you want?\" vs. *\"What put you want?\").", "labels": [], "entities": []}, {"text": "Whether gold standard part-of-speech tags or distributional categories are better suited to applications like parsing or machine translation can be best decided using extrinsic evaluation.", "labels": [], "entities": [{"text": "parsing", "start_pos": 110, "end_pos": 117, "type": "TASK", "confidence": 0.9694867134094238}, {"text": "machine translation", "start_pos": 121, "end_pos": 140, "type": "TASK", "confidence": 0.6935928612947464}]}, {"text": "However in this study we follow previous work and evaluate our results by comparing them to gold standard part-of-speech tags.", "labels": [], "entities": []}, {"text": "Section 2 gives a detailed review of related work.", "labels": [], "entities": []}, {"text": "Section 3 describes the dataset and the construction of the substitute vectors.", "labels": [], "entities": []}, {"text": "Section 4 describes cooccurrence data embedding, the learning algorithm used in our experiments.", "labels": [], "entities": []}, {"text": "Section 5 describes our experiments and compares our results with previous work.", "labels": [], "entities": []}, {"text": "Section 6 gives a brief error analysis and Section 7 summarizes our contributions.", "labels": [], "entities": []}, {"text": "All the data and the code to replicate the results given in this paper is available from the authors' website at http://goo.gl/RoqEh.", "labels": [], "entities": []}], "datasetContent": [{"text": "We report many-to-one and V-measure scores for our experiments as suggested in.", "labels": [], "entities": [{"text": "V-measure scores", "start_pos": 26, "end_pos": 42, "type": "METRIC", "confidence": 0.9564407169818878}]}, {"text": "The many-to-one (MTO) evaluation maps each cluster to its most frequent gold tag and reports the percentage of correctly tagged instances.", "labels": [], "entities": []}, {"text": "The MTO score naturally gets higher with increasing number of clusters but it is an intuitive metric when comparing results with the same number of clusters.", "labels": [], "entities": [{"text": "MTO score", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.7932531535625458}]}, {"text": "The V-measure (VM)) is an information theoretic metric that reports the harmonic mean of homogeneity (each cluster should contain only instances of a single class) and completeness (all instances of a class should be members of the same cluster).", "labels": [], "entities": []}, {"text": "In Section 6 we argue that homogeneity is perhaps more important in part-of-speech induction and suggest MTO with a fixed number of clusters as a more intuitive metric.", "labels": [], "entities": [{"text": "part-of-speech induction", "start_pos": 68, "end_pos": 92, "type": "TASK", "confidence": 0.7043721973896027}]}, {"text": "In this section we present experiments that evaluate substitute vectors as representations of word context within the S-CODE framework.", "labels": [], "entities": []}, {"text": "Section 5.1 replicates the bigram based S-CODE results from) as a baseline.", "labels": [], "entities": []}, {"text": "The S-CODE algorithm works with discrete inputs.", "labels": [], "entities": []}, {"text": "The substitute vectors as described in Section 3 are high dimensional and continuous.", "labels": [], "entities": []}, {"text": "We experimented with two approaches to use substitute vectors in a discrete setting.", "labels": [], "entities": []}, {"text": "Section 5.2 presents an algorithm that partitions the high dimensional space of substitute vectors into small neighborhoods and uses the partition id as a discrete context representation.", "labels": [], "entities": []}, {"text": "Section 5.3 presents an even simpler model which pairs each word with a random substitute.", "labels": [], "entities": []}, {"text": "When the leftword -right-word pairs used in the bigram model are replaced with word -partition-id or word -substitute pairs we see significant gains inaccuracy.", "labels": [], "entities": []}, {"text": "These results support our running hypothesis that paradigmatic features, i.e. potential substitutes of a word, are better determiners of syntactic category compared to left and right neighbors.", "labels": [], "entities": []}, {"text": "Section 5.4 explores morphologic and orthographic features as additional sources of information and its results improve the state-of-the-art in the field of unsupervised syntactic category acquisition.", "labels": [], "entities": [{"text": "syntactic category acquisition", "start_pos": 170, "end_pos": 200, "type": "TASK", "confidence": 0.6476044754187266}]}, {"text": "Each experiment was repeated 10 times with different random seeds and the results are reported with standard errors in parentheses or error bars in graphs.", "labels": [], "entities": []}, {"text": "summarizes all the results reported in this paper and the ones we cite from the literature.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Summary of results in terms of the MTO and VM scores. Standard errors are given in parentheses when  available. Starred entries have been reported in the review paper (", "labels": [], "entities": [{"text": "MTO", "start_pos": 45, "end_pos": 48, "type": "METRIC", "confidence": 0.6870948076248169}, {"text": "VM", "start_pos": 53, "end_pos": 55, "type": "METRIC", "confidence": 0.7717531323432922}, {"text": "Standard errors", "start_pos": 64, "end_pos": 79, "type": "METRIC", "confidence": 0.8954842984676361}]}]}