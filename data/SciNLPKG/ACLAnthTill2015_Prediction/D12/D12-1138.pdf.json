{"title": [{"text": "A Discriminative Model for Query Spelling Correction with Latent Structural SVM", "labels": [], "entities": [{"text": "Query Spelling Correction", "start_pos": 27, "end_pos": 52, "type": "TASK", "confidence": 0.8553689320882162}]}], "abstractContent": [{"text": "Discriminative training in query spelling correction is difficult due to the complex internal structures of the data.", "labels": [], "entities": [{"text": "query spelling correction", "start_pos": 27, "end_pos": 52, "type": "TASK", "confidence": 0.8596192995707194}]}, {"text": "Recent work on query spelling correction suggests a two stage approach a noisy channel model that is used to retrieve a number of candidate corrections, followed by discriminatively trained ranker applied to these candidates.", "labels": [], "entities": [{"text": "query spelling correction", "start_pos": 15, "end_pos": 40, "type": "TASK", "confidence": 0.8819675048192342}]}, {"text": "The ranker, however , suffers from the fact the low recall of the first, suboptimal, search stage.", "labels": [], "entities": [{"text": "recall", "start_pos": 52, "end_pos": 58, "type": "METRIC", "confidence": 0.9990875720977783}]}, {"text": "This paper proposes to directly optimize the search stage with a discriminative model based on latent structural SVM.", "labels": [], "entities": []}, {"text": "In this model, we treat query spelling correction as a multi-class classification problem with structured input and output.", "labels": [], "entities": [{"text": "query spelling correction", "start_pos": 24, "end_pos": 49, "type": "TASK", "confidence": 0.8414086898167928}]}, {"text": "The latent structural information is used to model the alignment of words in the spelling correction process.", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 81, "end_pos": 100, "type": "TASK", "confidence": 0.9210459291934967}]}, {"text": "Experiment results show that as a standalone speller, our model outperforms all the baseline systems.", "labels": [], "entities": []}, {"text": "It also attains a higher recall compared with the noisy channel model, and can therefore serve as a better filtering stage when combined with a ranker.", "labels": [], "entities": [{"text": "recall", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.9995347261428833}]}], "introductionContent": [{"text": "Query spelling correction has become a crucial component in modern information systems.", "labels": [], "entities": [{"text": "Query spelling correction", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.8475173115730286}]}, {"text": "Particularly, search engine users rely heavily on the query correction mechanism to formulate effective queries.", "labels": [], "entities": [{"text": "query correction", "start_pos": 54, "end_pos": 70, "type": "TASK", "confidence": 0.7088783979415894}]}, {"text": "Given a user query q, which is potentially misspelled, the goal of query spelling correction is to find a correction of the query c that could lead to a better search experience.", "labels": [], "entities": [{"text": "query spelling correction", "start_pos": 67, "end_pos": 92, "type": "TASK", "confidence": 0.7613742550214132}]}, {"text": "A typical query spelling correction system employs a noisy channel model ().", "labels": [], "entities": [{"text": "query spelling correction", "start_pos": 10, "end_pos": 35, "type": "TASK", "confidence": 0.8609227140744528}]}, {"text": "The model assumes that the correct query c is formed in the user's mind before entering the noisy channels, e.g., typing, and get misspelled.", "labels": [], "entities": []}, {"text": "Formally, the model maximizes the posterior probability p(c|q): Applying Bayes rule, the formulation can be rewritten as: The model uses two probabilities.", "labels": [], "entities": []}, {"text": "The prior probability p(c) represents how likely it is that c is the original correct query in the user's mind.", "labels": [], "entities": []}, {"text": "The probability is usually modeled by a language model estimated from a sizable corpus.", "labels": [], "entities": []}, {"text": "The transformation probability p(q|c) measures how likely it is that q is the output given that c has been formed by the user.", "labels": [], "entities": []}, {"text": "This probability can be either heuristic-based (edit distance) or learned from samples of well aligned corrections.", "labels": [], "entities": []}, {"text": "One problem with the noisy channel model is that there is no weighting for the two kinds of probabilities, and since they are estimated from different sources, there are usually issues regarding their scale and comparability, resulting in suboptimal performance ( . Another limitation of this generative model is that it is notable to take advantage of additional useful features.", "labels": [], "entities": []}, {"text": "A discriminative model may solve these problems by adding the flexibility of using features and applying weights.", "labels": [], "entities": []}, {"text": "But training such a model is not easy.", "labels": [], "entities": []}, {"text": "The difficulty is that the output space of query correction is enormous, as the candidate corrections for each a query term could be the entire vocabulary.", "labels": [], "entities": [{"text": "query correction", "start_pos": 43, "end_pos": 59, "type": "TASK", "confidence": 0.7903100848197937}]}, {"text": "This is even worse when word boundary errors (i.e. merging and splitting of words) exist.", "labels": [], "entities": []}, {"text": "The problem is intractable with standard discriminative models as we cannot enumerate every candidate correction.", "labels": [], "entities": []}, {"text": "To solve the problem, ( ) proposed a two stage approach.", "labels": [], "entities": []}, {"text": "In this approach, a ranker is trained to score each candidate correction of a query.", "labels": [], "entities": []}, {"text": "When a query is issued, the system first uses the noisy channel model with a standard search algorithm to find the 20 best candidates.", "labels": [], "entities": []}, {"text": "Then the ranker is used to re-rank these candidates and find the best correction for the query.", "labels": [], "entities": []}, {"text": "This ranker based system has one critical limitation, though.", "labels": [], "entities": []}, {"text": "Since the ranking stage is decoupled from the search, it relies on the outsourced search algorithm to find the candidates.", "labels": [], "entities": []}, {"text": "Because query spelling correction is an online operation, only a small number of candidates can enter the ranker due to efficiency concerns, thus limiting the ability of the ranker to the ceiling of recall set by the suboptimal search phase.", "labels": [], "entities": [{"text": "query spelling correction", "start_pos": 8, "end_pos": 33, "type": "TASK", "confidence": 0.8706003228823344}, {"text": "recall", "start_pos": 199, "end_pos": 205, "type": "METRIC", "confidence": 0.993909478187561}]}, {"text": "The research question we address here is whether we can directly optimize the search phase of query spelling correction using a discriminative model without loss of efficiency.", "labels": [], "entities": [{"text": "query spelling correction", "start_pos": 94, "end_pos": 119, "type": "TASK", "confidence": 0.7770979205767313}]}, {"text": "More specifically, we want 1) a learning process that is aware of the search phase and interacts with its result; 2) an efficient search algorithm that is able to incorporate the learned model and guide the search to the target spelling correction.", "labels": [], "entities": []}, {"text": "In this paper, we propose anew discriminative model for query correction that maintains the advantage of a discriminative model in accommodating flexible combination of features and naturally incorporates an efficient search algorithm in learning and inference.", "labels": [], "entities": [{"text": "query correction", "start_pos": 56, "end_pos": 72, "type": "TASK", "confidence": 0.7944613099098206}]}, {"text": "Similarly to ( we collapse a two stage process into a single discriminatively trained process, by considering the output of the first stage as an intermediate latent representation for the joint learning process.", "labels": [], "entities": []}, {"text": "Specifically, we make use of the latent structural SVM (LS-SVM) () formulation.", "labels": [], "entities": []}, {"text": "We formulate the problem query spelling correction as a multiclass classification problem on structured inputs and outputs.", "labels": [], "entities": [{"text": "query spelling correction", "start_pos": 25, "end_pos": 50, "type": "TASK", "confidence": 0.7078808546066284}, {"text": "multiclass classification", "start_pos": 56, "end_pos": 81, "type": "TASK", "confidence": 0.7298679947853088}]}, {"text": "The advantage of the structural SVM model is that it allows task specific, customizable solutions for the inference problem.", "labels": [], "entities": []}, {"text": "This allows us to adapt the model to make it work directly with the search algorithm we use for finding the best correction of the query.", "labels": [], "entities": []}, {"text": "To account for word boundary errors, we model the word alignment between the query and the correction as a latent structural variable.", "labels": [], "entities": []}, {"text": "The LS-SVM model allows us to jointly search over the output space and the latent structure space.", "labels": [], "entities": []}, {"text": "As the inference algorithm in the proposed discriminative model we use an algorithm that resembles a traditional noisy channel model.", "labels": [], "entities": []}, {"text": "To adapt the LS-SVM model to enable the efficient search of query spelling correction, we study how features can be designed.", "labels": [], "entities": [{"text": "query spelling correction", "start_pos": 60, "end_pos": 85, "type": "TASK", "confidence": 0.6583900650342306}]}, {"text": "We analyze the properties of features that can be used in the search algorithm and propose a criteria for selecting and designing new features.", "labels": [], "entities": []}, {"text": "We demonstrate the use of the criteria by designing separate features for different types of spelling errors (e.g. splitting, merging).", "labels": [], "entities": []}, {"text": "With the proposed discriminative model, we can directly optimize the search phase of query spelling correction without loss of efficiency.", "labels": [], "entities": [{"text": "query spelling correction", "start_pos": 85, "end_pos": 110, "type": "TASK", "confidence": 0.7743696570396423}]}, {"text": "Our model can be used not only as a standalone speller with high accuracy, but also as a high recall candidate generation stage fora ranker based system.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9985830783843994}, {"text": "recall", "start_pos": 94, "end_pos": 100, "type": "METRIC", "confidence": 0.9872651100158691}]}, {"text": "Experiments verify the effectiveness of the discriminative model, as the accuracy of correction can be improved significantly over baseline systems including an award winning query spelling system.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9996179342269897}]}, {"text": "Even though the optimization is primarily based on the top correction, the weights trained by LS-SVM can be used to search for more candidate corrections.", "labels": [], "entities": []}, {"text": "The improvement in recall at different levels over the noisy channel model demonstrates that our model is superior even when used in the two-stage approach..", "labels": [], "entities": [{"text": "recall", "start_pos": 19, "end_pos": 25, "type": "METRIC", "confidence": 0.9994427561759949}]}], "datasetContent": [{"text": "In order to test the effectiveness and efficiency of our proposed discriminative training method, in this section we conduct extensive experiments on two web query spelling datasets.", "labels": [], "entities": []}, {"text": "Below we first present the dataset and evaluation metrics, followed by the experiment results on query spelling correction.", "labels": [], "entities": [{"text": "query spelling correction", "start_pos": 97, "end_pos": 122, "type": "TASK", "confidence": 0.6831940412521362}]}, {"text": "The experiments are conducted on two query spelling correction datasets.", "labels": [], "entities": [{"text": "query spelling correction", "start_pos": 37, "end_pos": 62, "type": "TASK", "confidence": 0.6248413920402527}]}, {"text": "One is the TREC dataset based on the publicly available TREC queries.", "labels": [], "entities": [{"text": "TREC dataset", "start_pos": 11, "end_pos": 23, "type": "DATASET", "confidence": 0.8812390863895416}]}, {"text": "This dataset contains 5892 queries and the corresponding corrections annotated by the MSR Speller Challenge 3 organizers.", "labels": [], "entities": [{"text": "MSR Speller Challenge 3 organizers", "start_pos": 86, "end_pos": 120, "type": "DATASET", "confidence": 0.6982142806053162}]}, {"text": "There could be more than one plausible corrections fora query.", "labels": [], "entities": []}, {"text": "In this dataset only 5.3% of queries are judged as misspelled.", "labels": [], "entities": []}, {"text": "We have also annotated another dataset that contains 4926 MSN queries, where for each query there is at most one correction.", "labels": [], "entities": []}, {"text": "Three experts are involved in the annotation process.", "labels": [], "entities": []}, {"text": "For each query, we consult the speller from two major search engines (i.e. Google and Bing).", "labels": [], "entities": []}, {"text": "If they agree on the returned results (including the case if the query is just unchanged), we take it as the corrected form of the input query.", "labels": [], "entities": []}, {"text": "If the results are not the same from the two, as least one human expert will manually annotate the most likely corrected form of the query.", "labels": [], "entities": []}, {"text": "Finally, about 13% of queries are judged as misspelled http://web-ngram.research.microsoft.com/spellerchallenge/ in this dataset, which is close to the error rate of real web queries.", "labels": [], "entities": []}, {"text": "We've made this dataset publicly available to all researchers 4 . Both the two datasets are split randomly into two equal subsets for training and testing.", "labels": [], "entities": []}, {"text": "We evaluate our system based on the evaluation metrics proposed in Microsoft Speller Challenge, including expected precision, expected recall and expected F1 measure.", "labels": [], "entities": [{"text": "Microsoft Speller Challenge", "start_pos": 67, "end_pos": 94, "type": "DATASET", "confidence": 0.8557390968004862}, {"text": "precision", "start_pos": 115, "end_pos": 124, "type": "METRIC", "confidence": 0.8865824937820435}, {"text": "recall", "start_pos": 135, "end_pos": 141, "type": "METRIC", "confidence": 0.9742883443832397}, {"text": "F1 measure", "start_pos": 155, "end_pos": 165, "type": "METRIC", "confidence": 0.9770685136318207}]}, {"text": "Let q be a user query and C(q) = (c 1 , c 2 , , ck ) be the set of system output with posterior probabilities P (c i |q).", "labels": [], "entities": []}, {"text": "Let S(q) denote the set of plausible spelling variations annotated by the human experts for q.", "labels": [], "entities": []}, {"text": "Expected Precision is computed as: where I p (c, q) = 1 if c \u2208 S(q), and 0 otherwise.", "labels": [], "entities": [{"text": "Precision", "start_pos": 9, "end_pos": 18, "type": "METRIC", "confidence": 0.9132221937179565}]}, {"text": "And expected recall is defined as: where Ir (C(q), a) = 1 if a \u2208 C(q) fora \u2208 S(q), and 0 otherwise.", "labels": [], "entities": [{"text": "recall", "start_pos": 13, "end_pos": 19, "type": "METRIC", "confidence": 0.9878963232040405}, {"text": "Ir", "start_pos": 41, "end_pos": 43, "type": "METRIC", "confidence": 0.9979795813560486}]}, {"text": "We use R@N to denote recall for systems limited to output top N corrections.", "labels": [], "entities": [{"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9991130232810974}]}, {"text": "Expected F1 measure can be computed as: compares the performance of our LS-SVM based model with two strong baseline systems.", "labels": [], "entities": [{"text": "F1 measure", "start_pos": 9, "end_pos": 19, "type": "METRIC", "confidence": 0.95658078789711}]}, {"text": "The first baseline system is an Echo system which simply echos the input.", "labels": [], "entities": []}, {"text": "The echo system is usually considered as a strong baseline in query spelling correction as the majority of the queries are correctly spelled queries.", "labels": [], "entities": [{"text": "query spelling correction", "start_pos": 62, "end_pos": 87, "type": "TASK", "confidence": 0.8072565197944641}]}, {"text": "The second baseline Lueck-2011 we use is a award winning speller system 5 (Luec, 2011), which was ranked at the first place in Microsoft Spelling Challenge 2011.", "labels": [], "entities": []}, {"text": "We show performances for the entire query sets as well as the query sets consisting only the misspelled queries.", "labels": [], "entities": []}, {"text": "As we can see, our system outperforms both baseline systems on almost all metrics, except the precision of Lueck-2011 is better than ours on TREC dataset.", "labels": [], "entities": [{"text": "precision", "start_pos": 94, "end_pos": 103, "type": "METRIC", "confidence": 0.998198926448822}, {"text": "TREC dataset", "start_pos": 141, "end_pos": 153, "type": "DATASET", "confidence": 0.941297858953476}]}, {"text": "We perform statistical test and measures where our system shows statistical significant improvement over both baseline systems are noted by \u2020 . It is theoretically impossible to achieve statistical significance in the entire query set as majority queries have almost identical performance in different systems due to the large amount of correct queries.", "labels": [], "entities": []}, {"text": "But our method shows significant improvement in the dealing with the misspelled queries.", "labels": [], "entities": [{"text": "dealing with the misspelled queries", "start_pos": 52, "end_pos": 87, "type": "TASK", "confidence": 0.8794678449630737}]}, {"text": "This experiment verified the effectiveness of our proposed discriminative model.", "labels": [], "entities": []}, {"text": "As a standalone speller, our system achieves very high accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9976004958152771}]}, {"text": "Despite we are primarily focused on optimizing the top correction in our discriminative model, we can also use the trained system to output multiple candidate corrections.", "labels": [], "entities": []}, {"text": "Table 2 compare our system with the noisy channel model (N-C) in terms of recall at different levels of cutoff.", "labels": [], "entities": [{"text": "recall", "start_pos": 74, "end_pos": 80, "type": "METRIC", "confidence": 0.9991459846496582}]}, {"text": "For all levels, we see that our system achieves higher recall than the noisy channel model.", "labels": [], "entities": [{"text": "recall", "start_pos": 55, "end_pos": 61, "type": "METRIC", "confidence": 0.9995822310447693}]}, {"text": "This indicates that when used together with a secondary ranker, our system serves as a better filtering method than the unoptimized noisy channel model.", "labels": [], "entities": []}, {"text": "Since the ranker makes use of arbitrary features, it has the potential of further improving the accuracy of query spelling correction.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 96, "end_pos": 104, "type": "METRIC", "confidence": 0.9988942742347717}, {"text": "query spelling correction", "start_pos": 108, "end_pos": 133, "type": "TASK", "confidence": 0.7539705038070679}]}, {"text": "We plan to further explore this idea as a future work.", "labels": [], "entities": []}, {"text": "In we study the effect of treating the transformation probability of merging and splitting errors as separate features and including the local and global heuristic features (rich features).", "labels": [], "entities": []}, {"text": "We see that  the precision of query spelling correction can benefits from the use of rich features.", "labels": [], "entities": [{"text": "precision", "start_pos": 17, "end_pos": 26, "type": "METRIC", "confidence": 0.9976493716239929}, {"text": "query spelling correction", "start_pos": 30, "end_pos": 55, "type": "TASK", "confidence": 0.7837154865264893}]}, {"text": "However, it does not result in much improvement in recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 51, "end_pos": 57, "type": "METRIC", "confidence": 0.9985650181770325}]}, {"text": "This is reasonable as the additional features are primarily designed to improve the accuracy of the top correction generated by the system.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.9993318915367126}]}, {"text": "In doing so, it actually regularizes the ability of the system in retrieving diversified results.", "labels": [], "entities": []}, {"text": "For instance, the global heuristic feature on the number of word change tries to prevent the system from returning candidates having more than a certain number of changed words.", "labels": [], "entities": []}, {"text": "For the TREC collection where more than one corrections can be labeled fora query, this phenomena is aggravated.", "labels": [], "entities": [{"text": "TREC collection", "start_pos": 8, "end_pos": 23, "type": "DATASET", "confidence": 0.6769063621759415}]}], "tableCaptions": [{"text": " Table 1: LSSVM vs Baselines Serving as Standalone Speller", "labels": [], "entities": []}, {"text": " Table 3: LSSVM w/ and w/o Rich Features", "labels": [], "entities": []}]}