{"title": [{"text": "Linking Named Entities to Any Database", "labels": [], "entities": [{"text": "Linking Named Entities to Any Database", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.8745000859101614}]}], "abstractContent": [{"text": "Existing techniques for disambiguating named entities in text mostly focus on Wikipedia as a target catalog of entities.", "labels": [], "entities": [{"text": "disambiguating named entities in text", "start_pos": 24, "end_pos": 61, "type": "TASK", "confidence": 0.8444754600524902}]}, {"text": "Yet for many types of entities, such as restaurants and cult movies, relational databases exist that contain far more extensive information than Wikipedia.", "labels": [], "entities": []}, {"text": "This paper introduces anew task, called Open-Database Named-Entity Disam-biguation (Open-DB NED), in which a system must be able to resolve named entities to symbols in an arbitrary database, without requiring labeled data for each new database.", "labels": [], "entities": []}, {"text": "We introduce two techniques for Open-DB NED, one based on distant supervision and the other based on domain adaptation.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 101, "end_pos": 118, "type": "TASK", "confidence": 0.7055181264877319}]}, {"text": "In experiments on two domains, one with poor coverage by Wikipedia and the other with near-perfect coverage , our Open-DB NED strategies outper-form a state-of-the-art Wikipedia NED system by over 25% inaccuracy.", "labels": [], "entities": []}], "introductionContent": [{"text": "Named-entity disambiguation (NED) is the task of linking names mentioned in text with an established catalog of entities ().", "labels": [], "entities": [{"text": "Named-entity disambiguation (NED)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8442244052886962}]}, {"text": "It is a vital first step for semantic understanding of text, such as in grounded semantic parsing), as well as for information retrieval tasks like person name search.", "labels": [], "entities": [{"text": "semantic understanding of text", "start_pos": 29, "end_pos": 59, "type": "TASK", "confidence": 0.8745847195386887}, {"text": "grounded semantic parsing", "start_pos": 72, "end_pos": 97, "type": "TASK", "confidence": 0.768349846204122}, {"text": "information retrieval", "start_pos": 115, "end_pos": 136, "type": "TASK", "confidence": 0.7491676509380341}, {"text": "person name search", "start_pos": 148, "end_pos": 166, "type": "TASK", "confidence": 0.7024790048599243}]}, {"text": "NED requires a catalog of symbols, called referents, to which named-entities will be resolved.", "labels": [], "entities": [{"text": "NED", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.639021098613739}]}, {"text": "Most NED systems today use Wikipedia as the catalog of referents, but exclusive focus on Wikipedia as a target for NED systems has significant drawbacks: despite its breadth, Wikipedia still does not contain all or even most real-world entities mentioned in text.", "labels": [], "entities": []}, {"text": "As one example, it has poor coverage of entities that are mostly important in a small geographical region, such as hotels and restaurants, which are widely discussed on the Web.", "labels": [], "entities": []}, {"text": "57% of the named-entities in the Text Analysis Conference's (TAC) 2009 entity linking task refer to an entity that does not appear in.", "labels": [], "entities": [{"text": "Text Analysis Conference's (TAC) 2009 entity linking task", "start_pos": 33, "end_pos": 90, "type": "TASK", "confidence": 0.8830079111185941}]}, {"text": "Wikipedia is clearly a highly valuable resource, but it should not bethought of as the only one.", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9367703795433044}]}, {"text": "Instead of relying solely on Wikipedia, we propose a novel approach to NED, which we refer to as Open-DB NED: the task is to resolve an entity to Wikipedia or to any relational database that meets mild conditions about the format of the data, described below.", "labels": [], "entities": []}, {"text": "Leveraging structured, relational data should allow systems to achieve strong accuracy, as with domain-specific or database-specific NED techniques like Hoffart et al.'s NED system for YAGO).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.9971765279769897}]}, {"text": "And because of the availability of huge numbers of databases on the Web, many for specialized domains, a successful system for this task will cover entities that a Wikipedia NED or database-specific system cannot.", "labels": [], "entities": []}, {"text": "We investigate two complementary learning strategies for Open-DB NED, both of which significantly relax the assumptions of traditional NED systems.", "labels": [], "entities": []}, {"text": "The first strategy, a distant supervision approach, uses the relational information in a given database and a large corpus of unlabeled text to learn a database-specific model.", "labels": [], "entities": []}, {"text": "The second strat-egy, a domain adaptation approach, assumes a single source database that has accompanying labeled data.", "labels": [], "entities": []}, {"text": "Classifiers in this setting must learn a model that transfers from the source database to any new database, without requiring new training data for the new database.", "labels": [], "entities": []}, {"text": "Experiments show that both strategies outperform a state-of-the-art Wikipedia NED system by wide margins without requiring any labeled data from the test domain, highlighting the significant advantage of having domain-specific relational data.", "labels": [], "entities": []}, {"text": "The next section contrasts Open-DB NED with previous work.", "labels": [], "entities": []}, {"text": "Section 3 formalizes the task.", "labels": [], "entities": []}, {"text": "Sections 4 and 5 present our distant supervision strategy and domain-adaptation strategy, respectively.", "labels": [], "entities": []}, {"text": "Section 6 introduces a technique that is a hybrid of the two learning strategies.", "labels": [], "entities": []}, {"text": "Section 7 describes our experiments, and Section 8 concludes.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our experiments compare our strategies for Open-DB NED against one another, as well as against a Wikipedia NED system from previous work, on two domains: sports and movies.", "labels": [], "entities": []}, {"text": "We report on aversion of exact-match accuracy.", "labels": [], "entities": [{"text": "aversion", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9899042248725891}, {"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9203601479530334}]}, {"text": "The system chooses the most likely labe\u00ee s for each m.", "labels": [], "entities": []}, {"text": "This is judged correct if\u02c6sif\u02c6 if\u02c6s matches the correct label s exactly, or (in cases where both a Wikipedia and a database entity are considered correct) if one of the labels matches\u02c6smatches\u02c6 matches\u02c6s exactly.", "labels": [], "entities": []}, {"text": "This metric allows systems to resolve against either reference, Wikipedia or another database, without requiring it to match both if the same entity appears in both references.", "labels": [], "entities": []}], "tableCaptions": []}