{"title": [{"text": "Opinion Target Extraction Using Word-Based Translation Model", "labels": [], "entities": [{"text": "Opinion Target Extraction", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.7899958690007528}, {"text": "Word-Based Translation", "start_pos": 32, "end_pos": 54, "type": "TASK", "confidence": 0.6706981062889099}]}], "abstractContent": [{"text": "This paper proposes a novel approach to extract opinion targets based on word-based translation model (WTM).", "labels": [], "entities": [{"text": "word-based translation", "start_pos": 73, "end_pos": 95, "type": "TASK", "confidence": 0.6636342406272888}]}, {"text": "At first, we apply WTM in a monolingual scenario to mine the associations between opinion targets and opinion words.", "labels": [], "entities": [{"text": "WTM", "start_pos": 19, "end_pos": 22, "type": "TASK", "confidence": 0.8158800601959229}]}, {"text": "Then, a graph-based algorithm is exploited to extract opinion targets, where candidate opinion relevance estimated from the mined associations, is incorporated with candidate importance to generate a global measure.", "labels": [], "entities": []}, {"text": "By using WTM, our method can capture opinion relations more precisely, especially for long-span relations.", "labels": [], "entities": []}, {"text": "In particular, compared with previous syntax-based methods, our method can effectively avoid noises from parsing errors when dealing with informal texts in large Web corpora.", "labels": [], "entities": []}, {"text": "By using graph-based algorithm, opinion targets are extracted in a global process, which can effectively alleviate the problem of error propagation in traditional bootstrap-based methods, such as Double Propagation.", "labels": [], "entities": [{"text": "error propagation", "start_pos": 130, "end_pos": 147, "type": "TASK", "confidence": 0.7006491869688034}]}, {"text": "The experimental results on three real world datasets in different sizes and languages show that our approach is more effective and robust than state-of-art methods.", "labels": [], "entities": []}], "introductionContent": [{"text": "With the rapid development of e-commerce, most customers express their opinions on various kinds of entities, such as products and services.", "labels": [], "entities": []}, {"text": "These reviews not only provide customers with useful information for reference, but also are valuable for merchants to get the feedback from customers and enhance the qualities of their products or services.", "labels": [], "entities": []}, {"text": "Therefore, mining opinions from these vast amounts of reviews becomes urgent, and has attracted a lot of attentions from many researchers.", "labels": [], "entities": []}, {"text": "In opinion mining, one fundamental problem is opinion target extraction.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 3, "end_pos": 17, "type": "TASK", "confidence": 0.8643081486225128}, {"text": "opinion target extraction", "start_pos": 46, "end_pos": 71, "type": "TASK", "confidence": 0.6481953859329224}]}, {"text": "This task is to extract items which opinions are expressed on.", "labels": [], "entities": []}, {"text": "In reviews, opinion targets are usually nouns/noun phrases.", "labels": [], "entities": []}, {"text": "For example, in the sentence of \"The phone has a colorful and even amazing screen\", \"screen\" is an opinion target.", "labels": [], "entities": []}, {"text": "In online product reviews, opinion targets often are products or product features, so this task is also named as product feature extraction in previous work (.", "labels": [], "entities": [{"text": "product feature extraction", "start_pos": 113, "end_pos": 139, "type": "TASK", "confidence": 0.6658327281475067}]}, {"text": "To extract opinion targets, many studies regarded opinion words as strong indicators (;, which is based on the observation that opinion words are usually located around opinion targets, and there are associations between them.", "labels": [], "entities": []}, {"text": "Therefore, most pervious methods iteratively extracted opinion targets depending upon the associations between opinion words and opinion targets (.", "labels": [], "entities": []}, {"text": "For example, \"colorful\" and \"amazing\" is usually used to modify \"screen\" in reviews about cellphone, so there are strong associations between them.", "labels": [], "entities": []}, {"text": "If \"colorful\" and \"amazing\" had been known to be opinion words, \"screen\" is likely to bean opinion target in this domain.", "labels": [], "entities": []}, {"text": "In addition, the extracted opinion targets can be used to expand more opinion words according to their associations.", "labels": [], "entities": []}, {"text": "It's a mutual reinforcement procedure.", "labels": [], "entities": []}, {"text": "Therefore, mining associations between opinion targets and opinion words is a key for opinion target extraction ( . To this end, most previous methods (;, named as adjacent methods, employed the adjacent rule, where an opinion target was regarded to have opinion relations with the surrounding opinion words in a given window.", "labels": [], "entities": [{"text": "opinion target extraction", "start_pos": 86, "end_pos": 111, "type": "TASK", "confidence": 0.6385462284088135}]}, {"text": "However, because of the limitation of window size, opinion relations cannot be captured precisely, especially for long-span relations, which would hurt estimating associations between opinion targets and opinion words.", "labels": [], "entities": []}, {"text": "To resolve this problem, several studies exploited syntactic information such as dependency trees (.", "labels": [], "entities": []}, {"text": "If the syntactic relation between an opinion word and an opinion target satisfied a designed pattern, then there was an opinion relation between them.", "labels": [], "entities": []}, {"text": "Experiments consistently reported that syntaxbased methods could yield better performance than adjacent methods for small or medium corpora (.", "labels": [], "entities": []}, {"text": "The performance of syntaxbased methods heavily depends on the parsing performance.", "labels": [], "entities": []}, {"text": "However, online reviews are often informal texts (including grammar mistakes, typos, improper punctuations etc.).", "labels": [], "entities": []}, {"text": "As a result, parsing may generate many mistakes.", "labels": [], "entities": [{"text": "parsing", "start_pos": 13, "end_pos": 20, "type": "TASK", "confidence": 0.985988199710846}]}, {"text": "Thus, for large corpora from Web including a great deal of informal texts, these syntax-based methods may suffer from parsing errors and introduce many noises.", "labels": [], "entities": []}, {"text": "Furthermore, this problem maybe more serious on non-English language reviews, such as Chinese reviews, because that the performances of parsing on these languages are often worse than that on English.", "labels": [], "entities": []}, {"text": "To overcome the weakness of the two kinds of methods mentioned above, we propose a novel unsupervised approach to extract opinion targets by using word-based translation model (WTM).", "labels": [], "entities": [{"text": "word-based translation", "start_pos": 147, "end_pos": 169, "type": "TASK", "confidence": 0.6581762284040451}]}, {"text": "We formulate identifying opinion relations between opinion targets and opinion words as a word alignment task.", "labels": [], "entities": [{"text": "formulate identifying opinion relations between opinion targets", "start_pos": 3, "end_pos": 66, "type": "TASK", "confidence": 0.8430840798786708}, {"text": "word alignment", "start_pos": 90, "end_pos": 104, "type": "TASK", "confidence": 0.7059187293052673}]}, {"text": "We argue that an opinion target can find its corresponding modifier through monolingual word alignment.", "labels": [], "entities": [{"text": "monolingual word alignment", "start_pos": 76, "end_pos": 102, "type": "TASK", "confidence": 0.687835693359375}]}, {"text": "For example in, the opinion words \"colorful\" and \"amazing\" are aligned with the target \"screen\" through word alignment.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 104, "end_pos": 118, "type": "TASK", "confidence": 0.7244230210781097}]}, {"text": "To this end, we use WTM to perform monolingual word alignment for mining associations between opinion targets and opinion words.", "labels": [], "entities": [{"text": "WTM", "start_pos": 20, "end_pos": 23, "type": "DATASET", "confidence": 0.8085448741912842}, {"text": "monolingual word alignment", "start_pos": 35, "end_pos": 61, "type": "TASK", "confidence": 0.6743652721246084}]}, {"text": "In this process, several factors, such as word co-occurrence frequencies, word positions etc., can be considered globally.", "labels": [], "entities": []}, {"text": "Compared with adjacent methods, WTM doesn't identify opinion relations between words in a given window, so long-span relations can be effectively captured ( ).", "labels": [], "entities": []}, {"text": "Compared with syntax-based methods, without using parsing, WTM can effectively avoid errors from parsing informal texts.", "labels": [], "entities": [{"text": "parsing informal texts", "start_pos": 97, "end_pos": 119, "type": "TASK", "confidence": 0.8763030767440796}]}, {"text": "So it will be more robust.", "labels": [], "entities": []}, {"text": "In addition, by using WTM, our method can capture the \"one-to-many\" or \"many-to-one\" relations (\"one-to-many\" means that, in a sentence one opinion word modifies several opinion targets, and \"many-to-one\" means several opinion words modify one opinion target).", "labels": [], "entities": [{"text": "WTM", "start_pos": 22, "end_pos": 25, "type": "DATASET", "confidence": 0.7331572771072388}]}, {"text": "Thus, it's reasonable to expect that WTM is likely to yield better performance than traditional methods for mining associations between opinion targets and opinion words.", "labels": [], "entities": [{"text": "WTM", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.8083944320678711}]}, {"text": "Based on the mined associations, we extract opinion targets in a ranking framework.", "labels": [], "entities": []}, {"text": "All nouns/noun phrases are regarded as opinion target candidates.", "labels": [], "entities": []}, {"text": "Then a graph-based algorithm is exploited to assign confidences to each candidate, in which candidate opinion relevance and importance are incorporated to generate a global measure.", "labels": [], "entities": []}, {"text": "At last, the candidates with higher ranks are extracted as opinion targets.", "labels": [], "entities": []}, {"text": "Compared with most traditional methods (, we don't extract opinion targets iteratively based on the bootstrapping strategy, such as Double Propagation (Qiu et al., 2011), instead all candidates are dynamically ranked in a global process.", "labels": [], "entities": []}, {"text": "Therefore, error propagation can be effectively avoided and the performance can be improved.", "labels": [], "entities": [{"text": "error propagation", "start_pos": 11, "end_pos": 28, "type": "TASK", "confidence": 0.6714594513177872}]}, {"text": "The main contributions of this paper are as follows.", "labels": [], "entities": []}, {"text": "1) We formulate the opinion relation identification between opinion targets and opinion words as a word alignment task.", "labels": [], "entities": [{"text": "opinion relation identification", "start_pos": 20, "end_pos": 51, "type": "TASK", "confidence": 0.649091104666392}, {"text": "word alignment", "start_pos": 99, "end_pos": 113, "type": "TASK", "confidence": 0.7010922580957413}]}, {"text": "To our best knowledge, none of previous methods deal with this task using monolingual word alignment model (in Section 3.1).", "labels": [], "entities": [{"text": "word alignment", "start_pos": 86, "end_pos": 100, "type": "TASK", "confidence": 0.6902209222316742}]}], "datasetContent": [{"text": "In our experiments, we select three real world datasets to evaluate our approach.", "labels": [], "entities": []}, {"text": "The first dataset is COAE2008 dataset2 2 , which contains Chinese reviews of four different products.", "labels": [], "entities": [{"text": "COAE2008 dataset2 2", "start_pos": 21, "end_pos": 40, "type": "DATASET", "confidence": 0.9565856655438741}]}, {"text": "The detailed 2 http://ir-china.org.cn/coae2008.html information can be seen in.", "labels": [], "entities": []}, {"text": "Moreover, to evaluate our method comprehensively, we collect a larger collection named by Large, which includes three corpora from three different domains and different languages.", "labels": [], "entities": []}, {"text": "The detailed statistical information of this dataset is also shown in.", "labels": [], "entities": []}, {"text": "Restaurant is crawled from the Chinese Web site: www.dianping.com.", "labels": [], "entities": []}, {"text": "The Hotel and MP3 3 were used in (), which are respectively clawed from www.tripadvisor.com and www.amazon.com.", "labels": [], "entities": [{"text": "Hotel", "start_pos": 4, "end_pos": 9, "type": "DATASET", "confidence": 0.9685583114624023}]}, {"text": "For each collection, we perform random sampling to generate testing dataset, which include 6,000 sentences for each domain.", "labels": [], "entities": []}, {"text": "Then the opinion targets in Large were manually annotated as the gold standard for evaluations.", "labels": [], "entities": []}, {"text": "Three annotators are involved in the annotation process as follows.", "labels": [], "entities": []}, {"text": "First, every noun/noun phrase and its contexts in review sentences are extracted.", "labels": [], "entities": []}, {"text": "Then two annotators were required to judge whether every noun/noun phrase is opinion target or not.", "labels": [], "entities": []}, {"text": "If a conflict happens, a third annotator will make judgment for finial results.", "labels": [], "entities": []}, {"text": "In total, we respectively obtain 1,112, 1,241 and 1,850 opinion targets in Hotel, MP3 and Restaurant.", "labels": [], "entities": []}, {"text": "The third dataset is Customer Review Datasets 4 (English reviews of five products), which was also used in ().", "labels": [], "entities": [{"text": "Customer Review Datasets 4", "start_pos": 21, "end_pos": 47, "type": "DATASET", "confidence": 0.6993176117539406}]}, {"text": "They have labeled opinion targets.", "labels": [], "entities": []}, {"text": "The detailed information can be found in () is used to identify noun phrases.", "labels": [], "entities": []}, {"text": "We select precision, recall and Fmeasure as the evaluation metrics.", "labels": [], "entities": [{"text": "precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9995564818382263}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9995059967041016}, {"text": "Fmeasure", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9991286396980286}]}, {"text": "We also perform a significant test, i.e., a t-test with a default significant level of 0.05.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Examples of associations between opinion  targets and opinion words.", "labels": [], "entities": []}, {"text": " Table 2: Experimental Data Sets, # denotes the size  of the reviews/sentences", "labels": [], "entities": []}, {"text": " Table 3: Experiments on COAE2008 dataset2", "labels": [], "entities": [{"text": "COAE2008 dataset2", "start_pos": 25, "end_pos": 42, "type": "DATASET", "confidence": 0.9511217474937439}]}, {"text": " Table 4: Experiments on Large", "labels": [], "entities": []}]}