{"title": [], "abstractContent": [{"text": "We propose a general method for reranker construction which targets choosing the candidate with the least expected loss, rather than the most probable candidate.", "labels": [], "entities": [{"text": "reranker construction", "start_pos": 32, "end_pos": 53, "type": "TASK", "confidence": 0.9573045670986176}]}, {"text": "Different approaches to expected loss approximation are considered, including estimating from the probabilistic model used to generate the candidates, estimating from a discriminative model trained to rerank the candidates, and learning to approximate the expected loss.", "labels": [], "entities": [{"text": "expected loss approximation", "start_pos": 24, "end_pos": 51, "type": "TASK", "confidence": 0.6309186021486918}]}, {"text": "The proposed methods are applied to the parse reranking task, with various baseline models , achieving significant improvement both over the probabilistic models and the discriminative rerankers.", "labels": [], "entities": [{"text": "parse reranking task", "start_pos": 40, "end_pos": 60, "type": "TASK", "confidence": 0.9491185347239176}]}, {"text": "When a neural network parser is used as the probabilistic model and the Voted Perceptron algorithm with data-defined kernels as the learning algorithm, the loss minimization model achieves 90.0% labeled constituents F 1 score on the standard WSJ parsing task.", "labels": [], "entities": [{"text": "labeled constituents F 1 score", "start_pos": 195, "end_pos": 225, "type": "METRIC", "confidence": 0.7089293420314788}, {"text": "WSJ parsing task", "start_pos": 242, "end_pos": 258, "type": "TASK", "confidence": 0.7989949385325114}]}], "introductionContent": [{"text": "The reranking approach is widely used in parsing as well as in other structured classification problems.", "labels": [], "entities": [{"text": "parsing", "start_pos": 41, "end_pos": 48, "type": "TASK", "confidence": 0.9835535287857056}]}, {"text": "For structured classification tasks, where labels are complex and have an internal structure of interdependency, the 0-1 loss considered in classical formulation of classification algorithms is not a natural choice and different loss functions are normally employed.", "labels": [], "entities": [{"text": "structured classification tasks", "start_pos": 4, "end_pos": 35, "type": "TASK", "confidence": 0.68656325340271}]}, {"text": "To tackle this problem, several approaches have been proposed to accommodate loss functions in learning algorithms (.", "labels": [], "entities": []}, {"text": "Avery different use of loss functions was considered in the areas of signal processing and machine translation, where direct minimization of expected loss (Minimum Bayes Risk decoding) on word sequences was considered (.", "labels": [], "entities": [{"text": "signal processing", "start_pos": 69, "end_pos": 86, "type": "TASK", "confidence": 0.7069417983293533}, {"text": "machine translation", "start_pos": 91, "end_pos": 110, "type": "TASK", "confidence": 0.8342534899711609}]}, {"text": "The only attempt to use Minimum Bayes Risk (MBR) decoding in parsing was made in, where a parsing algorithm for constituent recall minimization was constructed.", "labels": [], "entities": [{"text": "Minimum Bayes Risk (MBR)", "start_pos": 24, "end_pos": 48, "type": "METRIC", "confidence": 0.7082479993502299}, {"text": "parsing", "start_pos": 61, "end_pos": 68, "type": "TASK", "confidence": 0.9748304486274719}, {"text": "constituent recall minimization", "start_pos": 112, "end_pos": 143, "type": "TASK", "confidence": 0.708441694577535}]}, {"text": "However, their approach is limited to binarized PCFG models and, consequently, is not applicable to state-of-the-art parsing methods.", "labels": [], "entities": []}, {"text": "In this paper we consider several approaches to loss approximation on the basis of a candidate list provided by a baseline probabilistic model.", "labels": [], "entities": [{"text": "loss approximation", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.7371334135532379}]}, {"text": "The intuitive motivation for expected loss minimization can be seen from the following example.", "labels": [], "entities": [{"text": "expected loss minimization", "start_pos": 29, "end_pos": 55, "type": "TASK", "confidence": 0.6199420392513275}]}, {"text": "Consider the situation where there area group of several very similar candidates and one very different candidate whose probability is just slightly larger than the probability of any individual candidate in the group, but much smaller than their total probability.", "labels": [], "entities": []}, {"text": "A method which chooses the maximum probability candidate will choose this outlier candidate, which is correct if you are only interested in getting the label exactly correct (i.e. 0-1 loss), and you think the estimates are accurate.", "labels": [], "entities": []}, {"text": "But if you are interested in a loss function where the loss is small when you choose a candidate which is similar to the correct candidate, then it is better to choose one of the candidates in the group.", "labels": [], "entities": []}, {"text": "With this choice the loss will only be large if the outlier turns out to be correct, while if the outlier is chosen then the loss will be large if any of the group are correct.", "labels": [], "entities": []}, {"text": "In other words, the expected loss of choosing a member of the group will be smaller than that for the outlier.", "labels": [], "entities": []}, {"text": "More formally, the Bayes risk of a model y = h(x) is defined as where the expectation is taken overall the possible inputs x and labels y and \u2206(y, y \ud97b\udf59 ) denotes a loss incurred by assigning x toy \ud97b\udf59 when the correct label is y.", "labels": [], "entities": []}, {"text": "We assume that the loss function possesses values within the range from 0 to 1, which is equivalent to the requirement that the loss function is bounded in ().", "labels": [], "entities": []}, {"text": "It follows that an optimal reranker h \ud97b\udf59 is one which chooses the label y that minimizes the expected loss: where G(x) denotes a candidate list provided by a baseline probabilistic model for the input x.", "labels": [], "entities": []}, {"text": "In this paper we propose different approaches to loss approximation.", "labels": [], "entities": [{"text": "loss approximation", "start_pos": 49, "end_pos": 67, "type": "TASK", "confidence": 0.7373519092798233}]}, {"text": "We apply them to the parse reranking problem where the baseline probabilistic model is a neural network parser, and to parse reranking of candidates provided by the (Collins, 1999) model.", "labels": [], "entities": [{"text": "parse reranking", "start_pos": 21, "end_pos": 36, "type": "TASK", "confidence": 0.9693944454193115}, {"text": "parse reranking", "start_pos": 119, "end_pos": 134, "type": "TASK", "confidence": 0.9198075234889984}]}, {"text": "The resulting reranking method achieves very significant improvement in the considered loss function and improvement inmost other standard measures of accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 151, "end_pos": 159, "type": "METRIC", "confidence": 0.9978712797164917}]}, {"text": "In the following three sections we will discuss three approaches to learning such a classifier.", "labels": [], "entities": []}, {"text": "The first two derive a classification criteria for use with a predefined probability model (the first generative, the second discriminative).", "labels": [], "entities": []}, {"text": "The third defines a kernel for use with a classification method for minimizing loss.", "labels": [], "entities": []}, {"text": "All use previously proposed learning algorithms and optimization criteria.", "labels": [], "entities": []}], "datasetContent": [{"text": "To perform empirical evaluations of the proposed methods, we considered the task of parsing the Penn Treebank Wall Street Journal corpus).", "labels": [], "entities": [{"text": "parsing", "start_pos": 84, "end_pos": 91, "type": "TASK", "confidence": 0.9721636772155762}, {"text": "Penn Treebank Wall Street Journal corpus", "start_pos": 96, "end_pos": 136, "type": "DATASET", "confidence": 0.9582859575748444}]}, {"text": "First, we perform experiments with SVM Struct () as the learner.", "labels": [], "entities": []}, {"text": "Since SVM Struct already uses the loss function during training to rescale the margin or slack variables, this learner allows us to test the hypothesis that loss functions are useful in parsing not only to define the optimization criteria but also to define the classifier and to define the feature space.", "labels": [], "entities": []}, {"text": "However, SVM Struct training for large scale parsing experiments is computationally expensive 2 , so here we use only a small portion of the available training data to perform evaluations of the different approaches.", "labels": [], "entities": []}, {"text": "In the other two sets of experiments, described below, we test our best model on the standard Wall Street Journal parsing benchmark) with the Voted Perceptron algorithm as the learner.", "labels": [], "entities": [{"text": "Wall Street Journal parsing benchmark", "start_pos": 94, "end_pos": 131, "type": "DATASET", "confidence": 0.9246773242950439}]}, {"text": "Both the neural network probabilistic model and the kernel based classifiers were trained on section 0 (1,921 sentences, 40,930 words).", "labels": [], "entities": []}, {"text": "Section 24 (1,346 sentences, 29,125 words) was used as the validation set during the neural network learning and for choosing parameters of the models.", "labels": [], "entities": []}, {"text": "Section 23 (2,416 sentences, 54,268 words) was used for the final testing of the models.", "labels": [], "entities": []}, {"text": "We used a publicly available tagger) to provide the part-of-speech tags for each word in the sentence.", "labels": [], "entities": []}, {"text": "For each tag, there is an unknown-word vocabulary item which is used for all those words which are not sufficiently frequent with that tag to be included individually in the vocabulary.", "labels": [], "entities": []}, {"text": "For these experiments, we only included a specific tag-word pair in the vocabu- lary if it occurred at least 20 time in the training set, which (with tag-unknown-word pairs) led to the very small vocabulary of 271 tag-word pairs.", "labels": [], "entities": []}, {"text": "The same model was used both for choosing the list of candidate parses and for the probabilistic model used for loss estimation and kernel feature extraction.", "labels": [], "entities": [{"text": "loss estimation", "start_pos": 112, "end_pos": 127, "type": "TASK", "confidence": 0.6186189949512482}, {"text": "kernel feature extraction", "start_pos": 132, "end_pos": 157, "type": "TASK", "confidence": 0.7475455005963644}]}, {"text": "For training and testing of the kernel models, we provided a candidate list consisting of the top 20 parses found by the probabilistic model.", "labels": [], "entities": []}, {"text": "For the testing set, selecting the candidate with an oracle results in an F 1 score of 89.1%.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 74, "end_pos": 83, "type": "METRIC", "confidence": 0.9928354819615682}]}, {"text": "We used the SVM Struct software package () to train the SVM for all the approaches based on discriminative classifier learning, with slack rescaling and linear slack penalty.", "labels": [], "entities": []}, {"text": "The loss function is defined as \u2206(y, y \ud97b\udf59 ) = 1 \u2212 F 1 (y, y \ud97b\udf59 ), where F 1 denotes F 1 measure on bracketed constituents.", "labels": [], "entities": [{"text": "F", "start_pos": 70, "end_pos": 71, "type": "METRIC", "confidence": 0.9528968334197998}, {"text": "F 1 measure", "start_pos": 82, "end_pos": 93, "type": "METRIC", "confidence": 0.9088091452916464}]}, {"text": "This loss was used both for rescaling the slacks in the SVM and for defining our classification models and kernels.", "labels": [], "entities": []}, {"text": "We performed initial testing of the models on the validation set and preselected the best model for each of the approaches before testing it on the final testing set.", "labels": [], "entities": []}, {"text": "Standard measures of parsing accuracy, plus complete match accuracy, are shown in table 1.", "labels": [], "entities": [{"text": "parsing", "start_pos": 21, "end_pos": 28, "type": "TASK", "confidence": 0.9825016856193542}, {"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.969426691532135}, {"text": "accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.7394904494285583}]}, {"text": "As the baselines, the table includes the results of the standard TOP reranking kernel (TRK)  and the baseline probabilistic model (SSN).", "labels": [], "entities": []}, {"text": "SSN-Estim is the model using loss estimation on the basic probabilistic model, as explained in section 2.", "labels": [], "entities": [{"text": "SSN-Estim", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.7806409597396851}]}, {"text": "LLK-Learn and LK-Learn are the models which define the kernel based on loss, using the Loss Logit Kernel (equation) and the Loss Kernel (equation), respectively.", "labels": [], "entities": []}, {"text": "FKEstim and TRK-Estim are the models which esti-mate the loss with data-defined kernels, using the Fisher Kernel (equation) and the TOP Reranking kernel (equation), respectively.", "labels": [], "entities": [{"text": "FKEstim", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9325354695320129}, {"text": "TRK-Estim", "start_pos": 12, "end_pos": 21, "type": "METRIC", "confidence": 0.5598557591438293}]}, {"text": "All our proposed models show better F 1 accuracy than the baseline probabilistic model SSN, and all these differences are statistically significant.", "labels": [], "entities": [{"text": "F 1", "start_pos": 36, "end_pos": 39, "type": "METRIC", "confidence": 0.964264839887619}, {"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.7341141104698181}]}, {"text": "The difference in F 1 between TRK-Estim and FK-Estim is not statistically significant, but otherwise TRK-Estim demonstrates a statistically significant improvement overall other models.", "labels": [], "entities": [{"text": "F 1", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.9951130151748657}]}, {"text": "It should also be noted that exact match measures for TRK-Estim and SSN-Estim are not negatively affected, even though the F 1 loss function was optimized.", "labels": [], "entities": [{"text": "TRK-Estim", "start_pos": 54, "end_pos": 63, "type": "METRIC", "confidence": 0.757531464099884}, {"text": "F 1 loss", "start_pos": 123, "end_pos": 131, "type": "METRIC", "confidence": 0.9505195617675781}]}, {"text": "It is important to point out that SSN-Estim, which improves significantly over SSN, does not require the learning of a discriminative classifier, and differs from the SSN only by use of the different classification model (equation), which means that it is extremely easy to apply in practice.", "labels": [], "entities": []}, {"text": "One surprising aspect of these results is the failure of LLK-Learn and LK-Learn to achieve improvement over SSN-Estim.", "labels": [], "entities": [{"text": "LLK-Learn", "start_pos": 57, "end_pos": 66, "type": "DATASET", "confidence": 0.8717769384384155}]}, {"text": "This might be explained by the difficulty of learning a linear approximation to (4).", "labels": [], "entities": []}, {"text": "Under this explanation, the performance of LLK-Learn and LK-Learn could be explained by the fact that the first component of their kernels is a monotonic function of the SSNEstim estimation.", "labels": [], "entities": []}, {"text": "To test this hypothesis, we did an additional experiment where we removed the first component of Loss Logit Kernel (13) from the feature vector and performed learning.", "labels": [], "entities": []}, {"text": "Surprisingly, the model achieved virtually the same results, rather than the predicted worse performance.", "labels": [], "entities": []}, {"text": "This result might indicate that the LLKLearn model still can be useful for different problems where discriminative learning gives more advantage over generative approaches.", "labels": [], "entities": []}, {"text": "These experimental results demonstrate that the loss approximation reranking approaches proposed in this paper demonstrate significant improvement over the baseline models, achieving about the same relative error reduction as previously achieved with data-defined kernels).", "labels": [], "entities": []}, {"text": "This improvement is despite the fact that the loss function is already used in the definition of the training criteria for all the models except SSN.", "labels": [], "entities": []}, {"text": "It is also interesting to note that the best result on the validation set for estimation We measured significance of all the experiments in this paper with the randomized significance test of the loss with data-defined kernels (12) and was achieved when the parameter A is close to the inverse of the first component of the learned decision vector, which confirms the motivation for these kernels.", "labels": [], "entities": [{"text": "estimation", "start_pos": 78, "end_pos": 88, "type": "TASK", "confidence": 0.9808818101882935}, {"text": "significance", "start_pos": 101, "end_pos": 113, "type": "METRIC", "confidence": 0.9888023734092712}]}, {"text": "The above experiments with the SVM Struct demonstrate empirically the viability of our approaches.", "labels": [], "entities": [{"text": "SVM Struct", "start_pos": 31, "end_pos": 41, "type": "DATASET", "confidence": 0.7142235338687897}]}, {"text": "The aim of experiments on the entire WSJ is to test whether our approaches still achieve significant improvement when more accurate generative models are used, and also to show that they generalize well to learning methods different from SVMs.", "labels": [], "entities": [{"text": "WSJ", "start_pos": 37, "end_pos": 40, "type": "DATASET", "confidence": 0.8276724815368652}]}, {"text": "We perform experiments on the standard WSJ parsing data using the standard split into training, validation and testing sets.", "labels": [], "entities": [{"text": "WSJ parsing data", "start_pos": 39, "end_pos": 55, "type": "DATASET", "confidence": 0.8201250433921814}]}, {"text": "We replicate completely the setup of experiments in).", "labels": [], "entities": []}, {"text": "For a detailed description of the experiment setup, we refer the reader to).", "labels": [], "entities": []}, {"text": "We only note here that the candidate list has 20 candidates, and, for the testing set, selecting the candidate with an oracle results in an F 1 score of 95.4%.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 140, "end_pos": 149, "type": "METRIC", "confidence": 0.9910904367764791}]}, {"text": "We selected the TRK-Estim approach for these experiments because it demonstrated the best results in the previous set of experiments (5.2).", "labels": [], "entities": [{"text": "TRK-Estim", "start_pos": 16, "end_pos": 25, "type": "METRIC", "confidence": 0.8368075489997864}]}, {"text": "We trained the Voted Perceptron (VP) modification described in ) with the TOP Reranking kernel.", "labels": [], "entities": [{"text": "TOP Reranking kernel", "start_pos": 74, "end_pos": 94, "type": "DATASET", "confidence": 0.6137125094731649}]}, {"text": "VP is not a linear classifier, so we were notable to use a classifier in the form (11).", "labels": [], "entities": []}, {"text": "Instead the normalized counts of votes given to the candidate parses were used as probability estimates, as discussed in section 3.3.", "labels": [], "entities": []}, {"text": "The resulting accuracies of this model are presented in table 2, together with results of the TOP Reranking kernel VP  and the SSN probabilistic model.", "labels": [], "entities": [{"text": "TOP Reranking kernel VP", "start_pos": 94, "end_pos": 117, "type": "DATASET", "confidence": 0.5661971867084503}]}, {"text": "Model TRK-Estim achieves significantly better results than the previously proposed models, which were evaluated in the same experimental setup.", "labels": [], "entities": []}, {"text": "Again, the relative error reduction is about the same as that of TRK.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 20, "end_pos": 35, "type": "METRIC", "confidence": 0.8944116830825806}, {"text": "TRK", "start_pos": 65, "end_pos": 68, "type": "METRIC", "confidence": 0.5277569890022278}]}, {"text": "The resulting system, consisting of the generative model and the reranker, achieves results at the state-of-the-art level.", "labels": [], "entities": []}, {"text": "We believe that this method can be applied to most parsing models to achieve a significant improvement.: Percentage labeled constituent recall (R), precision (P), combination of both (F 1 ) on the testing set.", "labels": [], "entities": [{"text": "parsing", "start_pos": 51, "end_pos": 58, "type": "TASK", "confidence": 0.9635242819786072}, {"text": "Percentage labeled constituent recall (R)", "start_pos": 105, "end_pos": 146, "type": "METRIC", "confidence": 0.7812112527234214}, {"text": "precision (P)", "start_pos": 148, "end_pos": 161, "type": "METRIC", "confidence": 0.9666336327791214}]}, {"text": "In this series of experiments we validate the statement in section 3.3, where we suggested that loss approximation from a discriminative classifier is not limited only to models with data-defined kernels.", "labels": [], "entities": []}, {"text": "We apply the same method as used in the TRK-Estim model above to the Tree Kernel (), which we call the TK-Estim model.", "labels": [], "entities": []}, {"text": "We replicated the parse reranking experimental setup used for the evaluation of the Tree Kernel in, where the candidate list was provided by the generative probabilistic model) (model 2).", "labels": [], "entities": []}, {"text": "A list of on average 29 candidates was used, with an oracle F 1 score on the testing set of 95.0%.", "labels": [], "entities": [{"text": "oracle F 1 score", "start_pos": 53, "end_pos": 69, "type": "METRIC", "confidence": 0.7046142220497131}]}, {"text": "We trained VP using the same parameters for the Tree Kernel and probability feature weighting as described in).", "labels": [], "entities": []}, {"text": "A publicly available efficient implementation of the Tree Kernel was utilized to speedup computations.", "labels": [], "entities": []}, {"text": "As in the previous section, votes of the perceptron were used to define the probability estimate used in the classifier.", "labels": [], "entities": []}, {"text": "The results for the MBR decoding method (TKEstim), defined in section 3.3, along with the standard Tree) (TK) and the probabilistic baseline) (CO99) are presented in table 3.", "labels": [], "entities": []}, {"text": "The proposed model improves in F 1 score over the standard VP results.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 31, "end_pos": 40, "type": "METRIC", "confidence": 0.9901026487350464}]}, {"text": "Differences between all the models are statistically significant.", "labels": [], "entities": []}, {"text": "The error reduction of TK-Estim is again about the same as the error reduction of TK.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 4, "end_pos": 19, "type": "METRIC", "confidence": 0.9679480493068695}, {"text": "error reduction", "start_pos": 63, "end_pos": 78, "type": "METRIC", "confidence": 0.9366927146911621}]}, {"text": "This improvement is achieved without adding any additional linguistic features.", "labels": [], "entities": []}, {"text": "It is important to note that the model improves in other accuracy measures as well.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.998854398727417}]}, {"text": "We would expect even better results with MBR-decoding if larger n-best lists are used.", "labels": [], "entities": [{"text": "MBR-decoding", "start_pos": 41, "end_pos": 53, "type": "DATASET", "confidence": 0.7433017492294312}]}, {"text": "The n-best parsing algorithm can be used to efficiently produce candidate lists as large as 10 6: Result on the testing set.", "labels": [], "entities": []}, {"text": "Percentage labeled constituent recall (R), precision (P), combination of both (F 1 ), an average number of crossing brackets per sentence (CB), percentage of sentences with 0 and \u2264 2 crossing brackets (0C and 2C, respectively).", "labels": [], "entities": [{"text": "recall (R)", "start_pos": 31, "end_pos": 41, "type": "METRIC", "confidence": 0.9126108139753342}, {"text": "precision (P)", "start_pos": 43, "end_pos": 56, "type": "METRIC", "confidence": 0.9600434750318527}, {"text": "average number of crossing brackets per sentence (CB)", "start_pos": 89, "end_pos": 142, "type": "METRIC", "confidence": 0.6149469584226608}]}, {"text": "parse trees with the model of).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Percentage labeled constituent recall (R),  precision (P), combination of both (F 1 ) and per- centage complete match (CM) on the testing set.", "labels": [], "entities": [{"text": "Percentage labeled constituent recall (R)", "start_pos": 10, "end_pos": 51, "type": "METRIC", "confidence": 0.7945363947323391}, {"text": "precision (P)", "start_pos": 54, "end_pos": 67, "type": "METRIC", "confidence": 0.9731392711400986}, {"text": "F 1 )", "start_pos": 90, "end_pos": 95, "type": "METRIC", "confidence": 0.9573815663655599}, {"text": "per- centage complete match (CM)", "start_pos": 100, "end_pos": 132, "type": "METRIC", "confidence": 0.7615886144340038}]}, {"text": " Table 2: Percentage labeled constituent recall (R),  precision (P), combination of both (F 1 ) on the test- ing set.", "labels": [], "entities": [{"text": "Percentage labeled constituent recall (R)", "start_pos": 10, "end_pos": 51, "type": "METRIC", "confidence": 0.7315857538155147}, {"text": "precision (P)", "start_pos": 54, "end_pos": 67, "type": "METRIC", "confidence": 0.9705313742160797}]}, {"text": " Table 3: Result on the testing set. Percentage la- beled constituent recall (R), precision (P), combi- nation of both (F 1 ), an average number of cross- ing brackets per sentence (CB), percentage of sen- tences with 0 and \u2264 2 crossing brackets (0C and  2C, respectively).", "labels": [], "entities": [{"text": "Percentage la- beled constituent recall (R)", "start_pos": 37, "end_pos": 80, "type": "METRIC", "confidence": 0.9035789900355868}, {"text": "precision (P)", "start_pos": 82, "end_pos": 95, "type": "METRIC", "confidence": 0.9669944196939468}, {"text": "combi- nation of both (F 1 )", "start_pos": 97, "end_pos": 125, "type": "METRIC", "confidence": 0.8429820272657607}, {"text": "average number of cross- ing brackets per sentence (CB)", "start_pos": 130, "end_pos": 185, "type": "METRIC", "confidence": 0.6508268366257349}]}]}