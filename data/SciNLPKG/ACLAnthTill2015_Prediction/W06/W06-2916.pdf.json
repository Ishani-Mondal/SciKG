{"title": [{"text": "Unsupervised Grammar Induction by Distribution and Attachment", "labels": [], "entities": [{"text": "Unsupervised Grammar Induction", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.5948481659094492}]}], "abstractContent": [{"text": "Distributional approaches to grammar induction are typically inefficient, enumerating large numbers of candidate constituents.", "labels": [], "entities": [{"text": "grammar induction", "start_pos": 29, "end_pos": 46, "type": "TASK", "confidence": 0.8179807364940643}]}, {"text": "In this paper, we describe a simplified model of distributional analysis which uses heuristics to reduce the number of candidate constituents under consideration.", "labels": [], "entities": [{"text": "distributional analysis", "start_pos": 49, "end_pos": 72, "type": "TASK", "confidence": 0.7517196834087372}]}, {"text": "We apply this model to a large corpus of over 400000 words of written English, and evaluate the results using EVALB.", "labels": [], "entities": [{"text": "EVALB", "start_pos": 110, "end_pos": 115, "type": "DATASET", "confidence": 0.7761373519897461}]}, {"text": "We show that the performance of this approach is limited, providing a detailed analysis of learned structure and a comparison with actual constituent-context distributions.", "labels": [], "entities": []}, {"text": "This motivates a more structured approach, using a process of attachment to form constituents from their distributional components.", "labels": [], "entities": []}, {"text": "Our findings suggest that distributional methods do not generalize enough to learn syntax effectively from raw text, but that attachment methods are more successful.", "labels": [], "entities": []}], "introductionContent": [{"text": "Distributional approaches to grammar induction exploit the principle of substitutability: constituents of the same type maybe exchanged with one another without affecting the syntax of the surrounding context.", "labels": [], "entities": [{"text": "grammar induction", "start_pos": 29, "end_pos": 46, "type": "TASK", "confidence": 0.7515716850757599}]}, {"text": "Reversing this notion, if we can identify \"surrounding context\" by observation, we can hypothesize that word sequences occurring in that context will be constituents of the same type.", "labels": [], "entities": []}, {"text": "Thus, distributional methods can be used to segment text into constituents and classify the results.", "labels": [], "entities": []}, {"text": "This work focuses on distributional learning from raw text.", "labels": [], "entities": [{"text": "distributional learning from raw text", "start_pos": 21, "end_pos": 58, "type": "TASK", "confidence": 0.850962245464325}]}, {"text": "Various models of distributional analysis have been used to induce syntactic structure, but most use probabilistic metrics to decide between candidate constituents.", "labels": [], "entities": [{"text": "distributional analysis", "start_pos": 18, "end_pos": 41, "type": "TASK", "confidence": 0.7430554330348969}, {"text": "syntactic structure", "start_pos": 67, "end_pos": 86, "type": "TASK", "confidence": 0.7589036226272583}]}, {"text": "We show that the efficiency of these systems can be improved by exploiting some properties of probable constituents, but also that this reliance on probability is problematic for learning from text.", "labels": [], "entities": []}, {"text": "As a consequence, we propose an extension to strict distributional learning that incorporates more information about constituent boundaries.", "labels": [], "entities": []}, {"text": "The remainder of this paper describes our experiences with a heuristic system for grammar induction.", "labels": [], "entities": [{"text": "grammar induction", "start_pos": 82, "end_pos": 99, "type": "TASK", "confidence": 0.7714294791221619}]}, {"text": "We begin with a discussion of previous distributional approaches to grammar induction in Section 2 and describe their implications in Section 3.", "labels": [], "entities": [{"text": "grammar induction", "start_pos": 68, "end_pos": 85, "type": "TASK", "confidence": 0.8019305765628815}]}, {"text": "We then introduce a heuristic distributional system in Section 4, which we analyze empirically against a treebank.", "labels": [], "entities": []}, {"text": "Poor system performance leads us to examine actual constituent-context distributions (Section 5), the implications of which motivate a more structured extension to our learning system, which we describe and analyze in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate our algorithm, we follow the standard approach of comparing the output of our system with that of a treebank.", "labels": [], "entities": []}, {"text": "We use the EVALB algorithm, originally designed for evaluating supervised parsing systems, with identical configuration to that of (van of our algorithm, which chunks text into expressions between function words, which we refer to as Function-Word Bracketing (FWB).", "labels": [], "entities": []}, {"text": "summarizes the EVALB scores for two 500-iteration runs of Directed Alignment over ICE-GB: DA is the standard context-sensitive version of the algorithm; DA cluster is the version with context clustering.", "labels": [], "entities": []}, {"text": "F W B precision is relatively low, with only 30% of proposed structures appearing in the treebank.", "labels": [], "entities": [{"text": "F W B precision", "start_pos": 0, "end_pos": 15, "type": "METRIC", "confidence": 0.8995940834283829}]}, {"text": "Recall is even lower, with only 11% of structure retrieved.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9773651957511902}]}, {"text": "This is unsurprising, as no nested constructions are considered.", "labels": [], "entities": []}, {"text": "In comparison, both versions of Directed Alignment perform significantly worse, with DA cluster being only fractionally better than standard DA.", "labels": [], "entities": [{"text": "DA cluster", "start_pos": 85, "end_pos": 95, "type": "METRIC", "confidence": 0.8156167566776276}]}, {"text": "Experiments over more learning iterations suggest that the performance of DA converges on F W B, with few nested constituents discovered.", "labels": [], "entities": []}, {"text": "Both variants of the system produce very poor performance, with very little nested structure recovered.", "labels": [], "entities": []}, {"text": "While these results seem discouraging, it is worth investigating system performance further., summarizes the success of the algorithm at discovering different types of constituent.", "labels": [], "entities": []}, {"text": "Note that these results are unlabeled, so we are examining the proportion of each type of constituent in ICE-GB that has been identified.", "labels": [], "entities": []}, {"text": "Here, Directed Alignment exhibits the most success at identifying nonclauses, of which the primary source of success is short sentence fragments.", "labels": [], "entities": [{"text": "Directed Alignment", "start_pos": 6, "end_pos": 24, "type": "TASK", "confidence": 0.6219348311424255}]}, {"text": "Around 10% of nounphrases (NP), verb-phrases (VP) and subordinatephrases (SUBP) were recovered, this limited success reflects the nature of the constituents: all three have relatively simple constructions, whereby a single word represents the constituent.", "labels": [], "entities": []}, {"text": "In contrast, con-: The top five expression classes to match N (noun) in ICE-GB, ranked by recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 90, "end_pos": 96, "type": "METRIC", "confidence": 0.9981901049613953}]}, {"text": "stituent types that comprise multiple units, such as prepositional-phrases (PP), are seldom recovered.", "labels": [], "entities": []}, {"text": "We applied Directed Alignment with attachment based on STOP arguments (DA ST OP ) to ICE-GB as before, running for 500 iterations.", "labels": [], "entities": [{"text": "DA ST OP )", "start_pos": 71, "end_pos": 81, "type": "METRIC", "confidence": 0.7394517213106155}]}, {"text": "These results are shown in.", "labels": [], "entities": []}, {"text": "Unlabeled precision increased by almost 50%, from 23.6% for DA cluster to 33.6%.", "labels": [], "entities": [{"text": "precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9889035820960999}]}, {"text": "Likewise, system recall increased dramatically, from 8.1% to 14.1%, up some 75%.", "labels": [], "entities": [{"text": "recall", "start_pos": 17, "end_pos": 23, "type": "METRIC", "confidence": 0.9980437755584717}]}, {"text": "Crossing-brackets increased slightly, but remained relatively low at 0.42.", "labels": [], "entities": []}, {"text": "shows the breakdown of EVALB scores for the major non-terminal types, as before.", "labels": [], "entities": [{"text": "EVALB", "start_pos": 23, "end_pos": 28, "type": "METRIC", "confidence": 0.930367648601532}]}, {"text": "The improvement in EVALB scores is attributable to a marked increase in success at identifying prepositional-phrases, with a lesser increase in noun-phrase identification.", "labels": [], "entities": [{"text": "EVALB", "start_pos": 19, "end_pos": 24, "type": "METRIC", "confidence": 0.9476038217544556}, {"text": "noun-phrase identification", "start_pos": 144, "end_pos": 170, "type": "TASK", "confidence": 0.7394655048847198}]}], "tableCaptions": [{"text": " Table 1: EVALB results after 500 iterations of Di- rected Alignment applied to ICE-GB, showing both  context-sensitive (DA) and clustered (DA cluster )  alignment. The columns represent Unlabeled Preci- sion, Unlabeled Recall, Unlabeled F-Score and the  proportion of sentence with crossing brackets re- spectively.", "labels": [], "entities": [{"text": "EVALB", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.7054049372673035}, {"text": "ICE-GB", "start_pos": 80, "end_pos": 86, "type": "DATASET", "confidence": 0.7684996724128723}, {"text": "Unlabeled Recall", "start_pos": 210, "end_pos": 226, "type": "METRIC", "confidence": 0.6211313605308533}, {"text": "F-Score", "start_pos": 238, "end_pos": 245, "type": "METRIC", "confidence": 0.6164028644561768}]}, {"text": " Table 2: Constituent retrieval results for Function- Word Bracketing (FWB) and Directed Alignment  (DA and DA cluster ), categorized by gold-type", "labels": [], "entities": []}, {"text": " Table 3: The top five expression classes to match N  (noun) in ICE-GB, ranked by recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 82, "end_pos": 88, "type": "METRIC", "confidence": 0.9987469911575317}]}, {"text": " Table 4: The five most frequent left/start/end/right  POS contexts for NP, VP and PP constituents.", "labels": [], "entities": []}, {"text": " Table 5: EVALB results after 500 iterations of Di- rected Alignment with STOP attachment applied to  ICE-GB (DA ST OP ).", "labels": [], "entities": [{"text": "EVALB", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.7846745252609253}, {"text": "STOP attachment", "start_pos": 74, "end_pos": 89, "type": "METRIC", "confidence": 0.9308664500713348}]}, {"text": " Table 6: Constituent retrieval results for DA ST OP ,  categorized by gold-type", "labels": [], "entities": [{"text": "DA ST OP", "start_pos": 44, "end_pos": 52, "type": "TASK", "confidence": 0.6641334692637125}]}]}