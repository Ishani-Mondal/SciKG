{"title": [{"text": "Morpho-syntactic Arabic Preprocessing for Arabic-to-English Statistical Machine Translation", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 60, "end_pos": 91, "type": "TASK", "confidence": 0.7459202607472738}]}], "abstractContent": [{"text": "The Arabic language has far richer systems of inflection and derivation than En-glish which has very little morphology.", "labels": [], "entities": []}, {"text": "This morphology difference causes a large gap between the vocabulary sizes in any given parallel training corpus.", "labels": [], "entities": []}, {"text": "Segmen-tation of inflected Arabic words is away to smooth its highly morphological nature.", "labels": [], "entities": [{"text": "Segmen-tation of inflected Arabic words", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.7330271959304809}]}, {"text": "In this paper, we describe some statistically and linguistically motivated methods for Arabic word segmentation.", "labels": [], "entities": [{"text": "Arabic word segmentation", "start_pos": 87, "end_pos": 111, "type": "TASK", "confidence": 0.5835036933422089}]}, {"text": "Then, we show the efficiency of proposed methods on the Arabic-English BTEC and NIST tasks.", "labels": [], "entities": [{"text": "NIST", "start_pos": 80, "end_pos": 84, "type": "DATASET", "confidence": 0.5903666019439697}]}], "introductionContent": [{"text": "Arabic is a highly inflected language compared to English which has very little morphology.", "labels": [], "entities": []}, {"text": "This morphological richness makes statistical machine translation from Arabic to English a challenging task.", "labels": [], "entities": [{"text": "statistical machine translation from Arabic", "start_pos": 34, "end_pos": 77, "type": "TASK", "confidence": 0.8207668423652649}]}, {"text": "A usual phenomenon in Arabic is the attachment of a group of words which are semantically dependent on each other.", "labels": [], "entities": []}, {"text": "For instance, prepositions like \"and\" and \"then\" are usually attached to the next word.", "labels": [], "entities": []}, {"text": "This applies also to the definite article \"the\".", "labels": [], "entities": []}, {"text": "In addition, personal pronouns are attached to the end of verbs, whereas possessive pronouns are attached to the end of the previous word, which constitutes the possessed object.", "labels": [], "entities": []}, {"text": "Hence, an Arabic word can be decomposed into \"prefixes, stem and suffixes\".", "labels": [], "entities": []}, {"text": "We restrict the set of prefixes and suffixes to those showed in and 2, where each of the prefixes and suffixes has at least one meaning which can be represented by a single word in the target language.", "labels": [], "entities": []}, {"text": "Some prefixes can be combined.", "labels": [], "entities": []}, {"text": "For example the word wbAlqlm ( which means \"and with the pen\") has a prefix which is a combination of three prefixes, namely w, band Al.", "labels": [], "entities": []}, {"text": "The suffixes we handle in this paper cannot be combined with each other.", "labels": [], "entities": []}, {"text": "Thus, the compound word pattern handled here is \"prefixes-stem-suffix\".", "labels": [], "entities": []}, {"text": "All possible prefix combinations that do not contain Al allow the stem to have a suffix.", "labels": [], "entities": []}, {"text": "Note that there are other suffixes that are not handled here, such as At ( ), An ( ) and wn ( ) which make the plural form of a word.", "labels": [], "entities": [{"text": "At", "start_pos": 70, "end_pos": 72, "type": "METRIC", "confidence": 0.9438509345054626}, {"text": "An", "start_pos": 78, "end_pos": 80, "type": "METRIC", "confidence": 0.9868685603141785}]}, {"text": "The reason why we omit them is that they do not have their own meaning.", "labels": [], "entities": []}, {"text": "The impact of Arabic morphology is that the vocabulary size and the number of singletons can be dramatically high, i.e. the Arabic words are not seen often enough to be learned by statistical machine translation models.", "labels": [], "entities": []}, {"text": "This can lead to an inefficient alignment.", "labels": [], "entities": []}, {"text": "In order to deal with this problem and to improve the performance of statistical machine translation, each word must be decomposed into its parts.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 69, "end_pos": 100, "type": "TASK", "confidence": 0.713348388671875}]}, {"text": "In () it was already shown that word segmentation for Arabic improves information retrieval.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 32, "end_pos": 49, "type": "TASK", "confidence": 0.7254458069801331}, {"text": "information retrieval", "start_pos": 70, "end_pos": 91, "type": "TASK", "confidence": 0.7908968031406403}]}, {"text": "In () a statistical approach for Arabic word segmentation was presented.", "labels": [], "entities": [{"text": "Arabic word segmentation", "start_pos": 33, "end_pos": 57, "type": "TASK", "confidence": 0.5981200238068899}]}, {"text": "It decomposes each word into a sequence of morphemes (prefixes-stem-suffixes), where all possible prefixes and suffixes (not only those we described in and 2) are split from the original word.", "labels": [], "entities": []}, {"text": "A comparable work was done by), where a POS tagging method for Arabic is also discussed.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 40, "end_pos": 51, "type": "TASK", "confidence": 0.7205437421798706}]}, {"text": "As we have access to this tool, we test its impact on the performance of our translation system.", "labels": [], "entities": []}, {"text": "In) a morphology analyzer was used for the segementation and POS tagging.", "labels": [], "entities": [{"text": "segementation", "start_pos": 43, "end_pos": 56, "type": "TASK", "confidence": 0.9648297429084778}, {"text": "POS tagging", "start_pos": 61, "end_pos": 72, "type": "TASK", "confidence": 0.7653426826000214}]}, {"text": "In contrast to the methods mentioned above, our segmentation method is unsupervised and rule based.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 48, "end_pos": 60, "type": "TASK", "confidence": 0.9812255501747131}]}, {"text": "In this paper we first explain our statistical machine translation (SMT) system used for testing the impact of the different segmentation methods, then we introduce some preprocessing and normalization tools for Arabic and explain the linguistic motivation beyond them.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 35, "end_pos": 72, "type": "TASK", "confidence": 0.7752838631470998}]}, {"text": "Afterwards, we present three word segmentation methods, a supervised learning approach, a finite state automaton-based segmentation, and a frequency-based method.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 29, "end_pos": 46, "type": "TASK", "confidence": 0.7105168402194977}, {"text": "finite state automaton-based segmentation", "start_pos": 90, "end_pos": 131, "type": "TASK", "confidence": 0.6851463913917542}]}, {"text": "In Section 5, the experimental results are presented.", "labels": [], "entities": []}, {"text": "Finally, the paper is summarized in Section 6 .", "labels": [], "entities": []}], "datasetContent": [{"text": "The commonly used criteria to evaluate the translation results in the machine translation community are: WER (word error rate), PER (positionindependent word error rate), BLEU (), and NIST).", "labels": [], "entities": [{"text": "machine translation community", "start_pos": 70, "end_pos": 99, "type": "TASK", "confidence": 0.7763007680575053}, {"text": "WER (word error rate)", "start_pos": 105, "end_pos": 126, "type": "METRIC", "confidence": 0.836238756775856}, {"text": "PER (positionindependent word error rate)", "start_pos": 128, "end_pos": 169, "type": "METRIC", "confidence": 0.8720498340470451}, {"text": "BLEU", "start_pos": 171, "end_pos": 175, "type": "METRIC", "confidence": 0.9932696223258972}, {"text": "NIST", "start_pos": 184, "end_pos": 188, "type": "DATASET", "confidence": 0.6834008097648621}]}, {"text": "The four criteria are computed with respect to multiple references.", "labels": [], "entities": []}, {"text": "The number of reference translations per source sentence varies from 4 to 16 references.", "labels": [], "entities": []}, {"text": "The evaluation is case-insensitive for BTEC and casesensitive for NIST task.", "labels": [], "entities": [{"text": "BTEC", "start_pos": 39, "end_pos": 43, "type": "DATASET", "confidence": 0.8880138993263245}, {"text": "NIST", "start_pos": 66, "end_pos": 70, "type": "DATASET", "confidence": 0.8349440693855286}]}, {"text": "As the BLEU and NIST scores measure accuracy, higher scores are better.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 7, "end_pos": 11, "type": "METRIC", "confidence": 0.9977830052375793}, {"text": "NIST", "start_pos": 16, "end_pos": 20, "type": "DATASET", "confidence": 0.8132908344268799}, {"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9996398687362671}]}], "tableCaptions": [{"text": " Table 3: BTEC corpus statistics, where the Arabic part is tokenized and segmented with the SL, FB, FSA  and the IFSA methods.  ARABIC  ENGLISH", "labels": [], "entities": [{"text": "BTEC corpus statistics", "start_pos": 10, "end_pos": 32, "type": "DATASET", "confidence": 0.9055078625679016}, {"text": "FB", "start_pos": 96, "end_pos": 98, "type": "METRIC", "confidence": 0.8252419233322144}, {"text": "FSA", "start_pos": 100, "end_pos": 103, "type": "METRIC", "confidence": 0.9132310748100281}, {"text": "IFSA", "start_pos": 113, "end_pos": 117, "type": "METRIC", "confidence": 0.6251227855682373}, {"text": "ARABIC  ENGLISH", "start_pos": 128, "end_pos": 143, "type": "METRIC", "confidence": 0.6884806156158447}]}, {"text": " Table 4: Corpus statistics for the news part of the NIST task, where the Arabic part is tokenized and seg- mented with SL, FB, FSA and IFSA methods.  ARABIC  ENGLISH", "labels": [], "entities": [{"text": "NIST task", "start_pos": 53, "end_pos": 62, "type": "TASK", "confidence": 0.6587779223918915}, {"text": "SL", "start_pos": 120, "end_pos": 122, "type": "METRIC", "confidence": 0.976478099822998}, {"text": "FB", "start_pos": 124, "end_pos": 126, "type": "METRIC", "confidence": 0.847893238067627}, {"text": "FSA", "start_pos": 128, "end_pos": 131, "type": "METRIC", "confidence": 0.8800566792488098}, {"text": "IFSA", "start_pos": 136, "end_pos": 140, "type": "METRIC", "confidence": 0.9102513790130615}, {"text": "ARABIC  ENGLISH", "start_pos": 151, "end_pos": 166, "type": "METRIC", "confidence": 0.7483694553375244}]}, {"text": " Table 5: NIST task corpus statistics, where the Arabic part is tokenized and segmented with the IFSA  method.  ARABIC  ENGLISH", "labels": [], "entities": [{"text": "NIST task corpus statistics", "start_pos": 10, "end_pos": 37, "type": "DATASET", "confidence": 0.7637382596731186}, {"text": "ARABIC  ENGLISH", "start_pos": 112, "end_pos": 127, "type": "METRIC", "confidence": 0.7667126655578613}]}, {"text": " Table 6: Case insensitive evaluation results for translating the development and test data of BTEC task after  performing divers preprocessing.  Dev  Test  mPER mWER BLEU NIST mPER mWER BLEU NIST  [%]  [%]  [%]  [%]  [%]  [%]  Non-Segmented Data  21.4  24.6  63.9  10.0  23.5  27.2  58.1  9.6  SL Segmenter  21.2  24.4  62.5  9.7  23.4  27.4  59.2  9.7  FB Segmenter  20.9  24.4  65.3  10.1  22.1  25.8  59.8  9.7  FSA Segmenter  20.1  23.4  64.8  10.2  21.1  25.2  61.3  10.2  IFSA Segmenter  20.0  23.3  65.0  10.4  21.2  25.3  61.3  10.2", "labels": [], "entities": [{"text": "Dev  Test  mPER mWER BLEU NIST mPER mWER BLEU NIST", "start_pos": 146, "end_pos": 196, "type": "METRIC", "confidence": 0.6798901051282883}, {"text": "FB Segmenter  20.9  24.4  65.3  10.1  22.1  25.8  59.8  9.7  FSA Segmenter  20.1  23.4  64.8  10.2  21.1  25.2  61.3  10.2  IFSA Segmenter  20.0", "start_pos": 355, "end_pos": 499, "type": "DATASET", "confidence": 0.8940043786297673}]}, {"text": " Table 7: Case sensitive evaluation results for translating the development and test data of the news part of  the NIST task after performing divers preprocessing.  Dev  Test  mPER mWER BLEU NIST mPER mWER BLEU NIST  [%]  [%]  [%]  [%]  [%]  [%]  Non-Segmented Data  43.7  56.4  43.6  9.9  46.1  58.0  37.4  9.1  SL Segmenter  42.0  54.7  45.1  10.2  44.3  56.3  39.9  9.6  FB Segmenter  43.4  56.1  43.2  9.8  45.6  57.8  37.2  9.2  FSA Segmenter  42.9  55.7  43.7  9.9  44.8  56.9  38.7  9.4  IFSA Segmenter  42.6  55.0  44.6  9.9  44.5  56.6  38.8  9.4", "labels": [], "entities": [{"text": "Dev  Test  mPER mWER BLEU NIST mPER mWER BLEU NIST", "start_pos": 165, "end_pos": 215, "type": "METRIC", "confidence": 0.5604085922241211}]}]}