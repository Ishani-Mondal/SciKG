{"title": [{"text": "Vine Parsing and Minimum Risk Reranking for Speed and Precision *", "labels": [], "entities": [{"text": "Vine Parsing", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.7062899768352509}, {"text": "Minimum Risk", "start_pos": 17, "end_pos": 29, "type": "METRIC", "confidence": 0.934883326292038}, {"text": "Speed", "start_pos": 44, "end_pos": 49, "type": "METRIC", "confidence": 0.9636211395263672}]}], "abstractContent": [{"text": "We describe our entry in the CoNLL-X shared task.", "labels": [], "entities": [{"text": "CoNLL-X shared task", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.6521194775899252}]}, {"text": "The system consists of three phases: a probabilistic vine parser (Eisner and N. Smith, 2005) that produces unlabeled dependency trees, a probabilistic relation-labeling model, and a discriminative minimum risk reranker (D. Smith and Eisner, 2006).", "labels": [], "entities": []}, {"text": "The system is designed for fast training and decoding and for high precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.9962037205696106}]}, {"text": "We describe sources of cross-lingual error and ways to ameliorate them.", "labels": [], "entities": []}, {"text": "We then provide a detailed error analysis of parses produced for sentences in German (much training data) and Arabic (little training data).", "labels": [], "entities": []}], "introductionContent": [{"text": "Standard state-of-the-art parsing systems (e.g.,) typically involve two passes.", "labels": [], "entities": []}, {"text": "First, a parser produces a list of the most likely n parse trees under a generative, probabilistic model (usually some flavor of PCFG).", "labels": [], "entities": []}, {"text": "A discriminative reranker then chooses among trees in this list by using an extended feature set.", "labels": [], "entities": []}, {"text": "This paradigm has many advantages: PCFGs are fast to train, can be very robust, and perform better as more data is made available; and rerankers train quickly (compared to discriminative models), require few parameters, and permit arbitrary features.", "labels": [], "entities": []}, {"text": "We describe such a system for dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 30, "end_pos": 48, "type": "TASK", "confidence": 0.8748585283756256}]}, {"text": "Our shared task entry is a preliminary system developed in only 3 person-weeks, and its accuracy is typically one s.d. below the average across systems and 10-20 points below the best system.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.9996286630630493}]}, {"text": "On the positive side, its decoding algorithms have guaranteed O(n) runtime, and training takes only a couple of hours.", "labels": [], "entities": [{"text": "O", "start_pos": 62, "end_pos": 63, "type": "METRIC", "confidence": 0.9859105348587036}]}, {"text": "Having designed primarily for speed and robustness, we sacrifice accuracy.", "labels": [], "entities": [{"text": "speed", "start_pos": 30, "end_pos": 35, "type": "METRIC", "confidence": 0.9655468463897705}, {"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9988781809806824}]}, {"text": "Better estimation, reranking on larger datasets, and more finegrained parsing constraints are expected to boost accuracy while maintaining speed.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 112, "end_pos": 120, "type": "METRIC", "confidence": 0.998837411403656}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Parameters and performance on test data. B and B r were chosen to retain 90% of dependencies  in training data. We show oracle, 1-best, and reranked performance on the test set at different stages of the  system. Boldface marks oracle performance that, given perfect downstream modules, would supercede the  best system. Italics mark the few cases where the reranker increased error rate. Columns 8-10 show labeled  accuracy; column 10 gives the final shared task evaluation scores.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 426, "end_pos": 434, "type": "METRIC", "confidence": 0.904147207736969}]}]}