{"title": [{"text": "Is it Really that Difficult to Parse German?", "labels": [], "entities": [{"text": "Parse German", "start_pos": 31, "end_pos": 43, "type": "TASK", "confidence": 0.6301576495170593}]}], "abstractContent": [{"text": "This paper presents a comparative study of probabilistic treebank parsing of Ger-man, using the Negra and T\u00fcBa-D/Z tree-banks.", "labels": [], "entities": [{"text": "Negra and T\u00fcBa-D/Z tree-banks", "start_pos": 96, "end_pos": 125, "type": "DATASET", "confidence": 0.8255874117215475}]}, {"text": "Experiments with the Stanford parser, which uses a factored PCFG and dependency model, show that, contrary to previous claims for other parsers, lexical-ization of PCFG models boosts parsing performance for both treebanks.", "labels": [], "entities": []}, {"text": "The experiments also show that there is a big difference in parsing performance, when trained on the Negra and on the T\u00fcBa-D/Z treebanks.", "labels": [], "entities": [{"text": "parsing", "start_pos": 60, "end_pos": 67, "type": "TASK", "confidence": 0.9824181199073792}, {"text": "Negra", "start_pos": 101, "end_pos": 106, "type": "DATASET", "confidence": 0.979759156703949}, {"text": "T\u00fcBa-D/Z treebanks", "start_pos": 118, "end_pos": 136, "type": "DATASET", "confidence": 0.9190763980150223}]}, {"text": "Parser performance for the models trained on T\u00fcBa-D/Z are comparable to parsing results for English with the Stanford parser, when trained on the Penn treebank.", "labels": [], "entities": [{"text": "Parser", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9886136054992676}, {"text": "T\u00fcBa-D/Z", "start_pos": 45, "end_pos": 53, "type": "DATASET", "confidence": 0.8990146319071451}, {"text": "Penn treebank", "start_pos": 146, "end_pos": 159, "type": "DATASET", "confidence": 0.9813606142997742}]}, {"text": "This comparison at least suggests that German is not harder to parse than its West-Germanic neighbor language English.", "labels": [], "entities": []}], "introductionContent": [{"text": "There have been a number of recent studies on probabilistic treebank parsing of German (, using the Negra treebank () as their underlying data source.", "labels": [], "entities": [{"text": "probabilistic treebank parsing", "start_pos": 46, "end_pos": 76, "type": "TASK", "confidence": 0.6097689867019653}, {"text": "Negra treebank", "start_pos": 100, "end_pos": 114, "type": "DATASET", "confidence": 0.9767152070999146}]}, {"text": "A common theme that has emerged from this research is the claim that lexicalization of PCFGs, which has been proven highly beneficial for other languages 1 , is detrimental for parsing accuracy of German.", "labels": [], "entities": [{"text": "parsing", "start_pos": 177, "end_pos": 184, "type": "TASK", "confidence": 0.956183910369873}, {"text": "accuracy", "start_pos": 185, "end_pos": 193, "type": "METRIC", "confidence": 0.8812375664710999}]}, {"text": "In fact, this assumption is by now so widely held that does not even consider lexicalization as a possible For English, see parameter and concentrates instead only on treebank transformations of various sorts in his experiments.", "labels": [], "entities": []}, {"text": "Another striking feature of all studies mentioned above are the relatively low parsing Fscores achieved for German by comparison to the scores reported for English, its West-Germanic neighbor, using similar parsers.", "labels": [], "entities": [{"text": "Fscores", "start_pos": 87, "end_pos": 94, "type": "METRIC", "confidence": 0.9540974497795105}]}, {"text": "This naturally raises the question whether German is just harder to parse or whether it is just hard to parse the Negra treebank.", "labels": [], "entities": [{"text": "Negra treebank", "start_pos": 114, "end_pos": 128, "type": "DATASET", "confidence": 0.9788200557231903}]}, {"text": "The purpose of this paper is to address precisely this question by training the Stanford parser () and the LoPar parser) on the two major treebanks available for German, Negra and T\u00fcBa-D/Z, the T\u00fcbingen treebank of written German (.", "labels": [], "entities": [{"text": "T\u00fcbingen treebank", "start_pos": 194, "end_pos": 211, "type": "DATASET", "confidence": 0.8196480572223663}]}, {"text": "A series of comparative parsing experiments that utilize different parameter settings of the parsers is conducted, including lexicalization and markovization.", "labels": [], "entities": [{"text": "comparative parsing", "start_pos": 12, "end_pos": 31, "type": "TASK", "confidence": 0.5275614857673645}]}, {"text": "These experiments show striking differences in performance between the two treebanks.", "labels": [], "entities": []}, {"text": "What makes this comparison interesting is that the treebanks are of comparable size and are both based on a newspaper corpus.", "labels": [], "entities": [{"text": "newspaper corpus", "start_pos": 108, "end_pos": 124, "type": "DATASET", "confidence": 0.795553982257843}]}, {"text": "However, both treebanks differ significantly in their syntactic annotation scheme.", "labels": [], "entities": []}, {"text": "Note, however, that our experiments concentrate on the original (context-free) annotations of the treebank.", "labels": [], "entities": []}, {"text": "The structure of this paper is as follows: section 2 discusses three characteristic grammatical features of German that need to betaken into account in syntactic annotation and in choosing an appropriate parsing model for German.", "labels": [], "entities": []}, {"text": "Section 3 introduces the Negra and T\u00fcBa-D/Z treebanks and discusses the main differences between their annotation schemes.", "labels": [], "entities": [{"text": "Negra and T\u00fcBa-D/Z treebanks", "start_pos": 25, "end_pos": 53, "type": "DATASET", "confidence": 0.8179284433523814}]}, {"text": "Section 4 explains the experimental setup, sections 5-7 the experiments, and section 8 discusses the results.", "labels": [], "entities": []}], "datasetContent": [{"text": "The main goals behind our experiments were twofold: (1) to re-investigate the claim that lexicalization is detrimental for treebank parsing of German, and (2) to compare the parsing results for the two German treebanks.", "labels": [], "entities": [{"text": "treebank parsing", "start_pos": 123, "end_pos": 139, "type": "TASK", "confidence": 0.6290048807859421}]}, {"text": "To investigate the first issue, the Stanford Parser (), a state-of-the-art probabilistic parser, was trained with both lexicalized and unlexicalized versions of the two treebanks (Experiment I).", "labels": [], "entities": []}, {"text": "For lexicalized parsing, the Stanford Parser provides a factored probabilistic model that combines a PCFG model with a dependency model.", "labels": [], "entities": [{"text": "Stanford Parser", "start_pos": 29, "end_pos": 44, "type": "DATASET", "confidence": 0.8480322360992432}]}, {"text": "For the comparison between the two treebanks, two types of experiments were performed: a purely constituent-based comparison using both the Stanford parser and the pure PCFG parser LoPar () (Experiment II), and an indepth evaluation of the three major grammatical functions subject, accusative object, and dative object, using the Stanford parser (Experiment III).", "labels": [], "entities": [{"text": "PCFG parser LoPar", "start_pos": 169, "end_pos": 186, "type": "DATASET", "confidence": 0.7935414512952169}]}, {"text": "All three experiments use gold POS tags extracted from the treebanks as parser input.", "labels": [], "entities": []}, {"text": "All parsing results shown below are averaged over a ten-fold cross-validation of the test data.", "labels": [], "entities": []}, {"text": "Experiments I and II used versions of the treebanks that excluded grammatical information, thus only contained constituent labeling.", "labels": [], "entities": []}, {"text": "For Experiment III, all syntactic labels were extended by their grammatical function (e.g NX-ON fora subject NP in T\u00fcBa-D/Z or NP-SB fora Negra subject).", "labels": [], "entities": []}, {"text": "Experiments I and II included all sentences of a maximal length of 40 words.", "labels": [], "entities": []}, {"text": "Due to memory limitations (7 GB), Experiment III had to be restricted to sentences of a maximal length of 35 words.", "labels": [], "entities": []}, {"text": "parsers and parameters, should not be generalized to claims about probabilistic parsing of German in general.", "labels": [], "entities": []}, {"text": "Experiment I also shows considerable differences in the overall scores between the two treebanks, with the F-scores for T\u00fcBa-D/Z parsing approximating scores reported for English, but with Negra scores lagging behind by an average margin of appr.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 107, "end_pos": 115, "type": "METRIC", "confidence": 0.9803237915039062}, {"text": "T\u00fcBa-D/Z parsing", "start_pos": 120, "end_pos": 136, "type": "TASK", "confidence": 0.6623389720916748}]}, {"text": "Of course, it is important to note that such direct comparisons with English are hardly possible due to different annotation schemes, different underlying text corpora, etc.", "labels": [], "entities": []}, {"text": "Nevertheless, the striking difference in parser performance between the two German treebanks warrants further attention.", "labels": [], "entities": [{"text": "parser", "start_pos": 41, "end_pos": 47, "type": "TASK", "confidence": 0.9450444579124451}]}, {"text": "Experiments II and III will investigate this matter in more depth.", "labels": [], "entities": []}, {"text": "The purpose of Experiment II is to rule out the possibility that the differences in parser performance for the two German treebanks produced by Experiment I may just be due to using a particular parser -in this particular case the hybrid PCFG and dependency model of the Stanford parser.", "labels": [], "entities": []}, {"text": "After all, Experiment I also yielded different results concerning the received wisdom about the utility of lexicalization from previously reported results.", "labels": [], "entities": []}, {"text": "In order to obtain a broader experimental base, unlexicalized models of the Stanford parser and the pure PCFG parser LoPar were trained on both treebanks.", "labels": [], "entities": [{"text": "PCFG parser LoPar", "start_pos": 105, "end_pos": 122, "type": "DATASET", "confidence": 0.8057492971420288}]}, {"text": "In addition we experimented with two different parameter settings of the Stanford parser, one with and one without markovization.", "labels": [], "entities": []}, {"text": "The experiment with markovization used parent information (v=1) and a second order Markov model for horizontal markovization (h=2).", "labels": [], "entities": []}, {"text": "The results, summarized in, show that parsing results for all unlexicalized experiments show roughly the same 20 point difference in F-score that were obtained for the lexicalized models in Experiment I. We can therefore conclude that the difference in parsing performance is robust across two parsers with different parameter settings, such as lexicalization and markovization.", "labels": [], "entities": [{"text": "parsing", "start_pos": 38, "end_pos": 45, "type": "TASK", "confidence": 0.9653594493865967}, {"text": "F-score", "start_pos": 133, "end_pos": 140, "type": "METRIC", "confidence": 0.9989192485809326}]}, {"text": "Experiment II also confirms the finding of Klein and Manning (2003a) and of that horizontal and vertical markovization has a positive effect on parser performance.", "labels": [], "entities": []}, {"text": "Notice also that markovization with unlexicalized grammars yields almost the same improvement as lexicalization does in Experiment I.  In Experiments I and II, only constituent structure was evaluated, which is highly annotation dependent.", "labels": [], "entities": []}, {"text": "It could simply be the case that the T\u00fcBa-D/Z annotation scheme contains many local structures that can be easily parsed by a PCFG model or the hybrid Stanford model.", "labels": [], "entities": []}, {"text": "Moreover, such easy to parse structures may not be of great importance when it comes to determining the correct macrostructure of a sentence.", "labels": [], "entities": []}, {"text": "To empirically verify such a conjecture, a separate evaluation of: A comparison of unlexicalized, markovized parsing of constituent structure and grammatical functions in Negra and T\u00fcBa-D/Z. parser performance for different constituent types would be necessary.", "labels": [], "entities": []}, {"text": "However, even such an evaluation would only be meaningful if the annotation schemes agree on the defining characteristics of such constituent types.", "labels": [], "entities": []}, {"text": "Unfortunately, this is not the case for the two treebanks under consideration.", "labels": [], "entities": []}, {"text": "Even for arguably theory-neutral constituents such as NPs, the two treebanks differ considerably.", "labels": [], "entities": []}, {"text": "In the Negra annotation scheme, single word NPs directly project from the POS level to the clausal level, while in T\u00fcBa-D/Z, they project by a unary rule first to an NP.", "labels": [], "entities": []}, {"text": "An extreme case of this Negra annotation is shown in for sentence (9).", "labels": [], "entities": []}, {"text": "Here, all the phrases are one word phrases and are thus projected directly to the clause level.", "labels": [], "entities": []}, {"text": "There is an even more important motivation for not focusing on the standard constituent-based parseval measures -at least when parsing German.", "labels": [], "entities": [{"text": "parsing German", "start_pos": 127, "end_pos": 141, "type": "TASK", "confidence": 0.8610977232456207}]}, {"text": "As discussed earlier in section 2.2, obtaining the correct constituent structure fora German sentence will often not be sufficient for determining its intended meaning.", "labels": [], "entities": []}, {"text": "Due to the word order freeness of phrases, a given NP in anyone position may in principle fulfill different grammatical functions in the sentence as a whole.", "labels": [], "entities": []}, {"text": "Therefore grammatical functions need to be explicitly marked in the treebank and correctly assigned during parsing.", "labels": [], "entities": []}, {"text": "Since both treebanks encode grammatical functions, this information is available for parsing and can ultimately lead to a more meaningful comparison of the two treebanks when used for parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 85, "end_pos": 92, "type": "TASK", "confidence": 0.9729753136634827}]}, {"text": "The purpose of Experiment III is to investigate parser performance on the treebanks when grammatical functions are included in the trees.", "labels": [], "entities": []}, {"text": "For these experiments, the unlexicalized, markovized PCFG version of the Stanford parser was used, with markovization parameters v=1 and h=2, as in Experiment II.", "labels": [], "entities": []}, {"text": "The results of this experiment are shown in.", "labels": [], "entities": []}, {"text": "The comparison of the experiments with (line 2) and without grammatical functions (line 1) confirms the findings of that the task of assigning correct grammatical functions is harder than mere constituent-based parsing.", "labels": [], "entities": []}, {"text": "When evaluating on all grammatical functions, the results for Negra decrease from 69.95 to 51.41, and for T\u00fcBa-D/Z from 89.18 to 75.33.", "labels": [], "entities": []}, {"text": "Notice however, that the relative differences between Negra and T\u00fcBa-D/Z that were true for Experiments I and II remain more or less constant for this experiment as well.", "labels": [], "entities": []}, {"text": "In order to get a clearer picture of the quality of the parser output for each treebank, it is important to consider individual grammatical functions.", "labels": [], "entities": []}, {"text": "As discussed in section 3, the overall inventory of grammatical functions is different for the two treebanks.", "labels": [], "entities": []}, {"text": "We therefore evaluated those grammatical functions separately that are crucial for determining function-argument structure and that are at the same time the most comparable for the two treebanks.", "labels": [], "entities": []}, {"text": "These are the functions of subject (encoded as SB in Negra and as ON in T\u00fcBa-D/Z), accusative object (OA ), and dative object (DA in Negra and OD in T\u00fcBa-D/Z).", "labels": [], "entities": []}, {"text": "Once again, the results are consistently better for T\u00fcBa-D/Z (cf. lines 3-5 in), with subjects yielding the highest results (71.08 vs. 55.12 F-score) and dative objects the lowest results (14.07 vs. 5.00).", "labels": [], "entities": [{"text": "F-score", "start_pos": 141, "end_pos": 148, "type": "METRIC", "confidence": 0.9932712912559509}]}, {"text": "The latter results must be attributed to data sparseness, dative object occur only appr.", "labels": [], "entities": []}, {"text": "1 000 times in each treebank while subjects occur more than 15 000 times.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The results of lexicalizing German.", "labels": [], "entities": []}, {"text": " Table 2: A comparison of unlexicalized parsing of Negra and T\u00fcBa-D/Z.", "labels": [], "entities": [{"text": "Negra", "start_pos": 51, "end_pos": 56, "type": "DATASET", "confidence": 0.9351270794868469}]}, {"text": " Table 3: A comparison of unlexicalized, markovized parsing of constituent structure and grammatical  functions in Negra and T\u00fcBa-D/Z.", "labels": [], "entities": [{"text": "Negra and T\u00fcBa-D/Z", "start_pos": 115, "end_pos": 133, "type": "DATASET", "confidence": 0.7809617638587951}]}]}