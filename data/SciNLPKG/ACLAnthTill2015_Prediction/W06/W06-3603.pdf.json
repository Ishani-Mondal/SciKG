{"title": [{"text": "Computational Challenges in Parsing by Classification", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents a discriminative parser that does not use a generative model in anyway, yet whose accuracy still surpasses a generative base-line.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 102, "end_pos": 110, "type": "METRIC", "confidence": 0.9990453124046326}]}, {"text": "The parser performs feature selection incrementally during training, as opposed to a priori, which enables it to work well with minimal linguistic clever-ness.", "labels": [], "entities": []}, {"text": "The main challenge in building this parser was fitting the training data into memory.", "labels": [], "entities": []}, {"text": "We introduce gradient sampling, which increased training speed 100-fold.", "labels": [], "entities": []}, {"text": "Our implementation is freely available at", "labels": [], "entities": []}], "introductionContent": [{"text": "Discriminative machine learning methods have improved accuracy on many NLP tasks, including POS-tagging, shallow parsing, relation extraction, and machine translation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9982491731643677}, {"text": "shallow parsing", "start_pos": 105, "end_pos": 120, "type": "TASK", "confidence": 0.5905523300170898}, {"text": "relation extraction", "start_pos": 122, "end_pos": 141, "type": "TASK", "confidence": 0.8881397545337677}, {"text": "machine translation", "start_pos": 147, "end_pos": 166, "type": "TASK", "confidence": 0.8156847953796387}]}, {"text": "However, only limited advances have been made on full syntactic constituent parsing.", "labels": [], "entities": [{"text": "syntactic constituent parsing", "start_pos": 54, "end_pos": 83, "type": "TASK", "confidence": 0.633137176434199}]}, {"text": "Successful discriminative parsers have used generative models to reduce training time and raise accuracy above generative baselines).", "labels": [], "entities": [{"text": "generative", "start_pos": 44, "end_pos": 54, "type": "TASK", "confidence": 0.9709293246269226}, {"text": "accuracy", "start_pos": 96, "end_pos": 104, "type": "METRIC", "confidence": 0.9989020824432373}]}, {"text": "However, relying upon information from a generative model might limit the potential of these approaches to realize the accuracy gains achieved by discriminative methods on other NLP tasks.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 119, "end_pos": 127, "type": "METRIC", "confidence": 0.9970441460609436}]}, {"text": "Another difficulty is that discriminative parsing approaches can be very task-specific and require quite a bit of trial and error with different hyper-parameter values and types of features.", "labels": [], "entities": [{"text": "discriminative parsing", "start_pos": 27, "end_pos": 49, "type": "TASK", "confidence": 0.5156247913837433}]}, {"text": "In the present work, we make progress towards overcoming these obstacles.", "labels": [], "entities": []}, {"text": "We propose a flexible, well-integrated method for training discriminative parsers, demonstrating techniques that might also be useful for other structured learning problems.", "labels": [], "entities": []}, {"text": "The learning algorithm projects the hand-provided atomic features into a compound feature space and performs incremental feature selection from this large feature space.", "labels": [], "entities": []}, {"text": "We achieve higher accuracy than a generative baseline, despite not using the standard trick of including an underlying generative model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9989481568336487}, {"text": "generative", "start_pos": 34, "end_pos": 44, "type": "TASK", "confidence": 0.963130533695221}]}, {"text": "Our training regime does model selection without ad-hoc smoothing or frequency-based feature cutoffs, and requires no heuristics to optimize the single hyper-parameter.", "labels": [], "entities": []}, {"text": "We discuss the computational challenges we overcame to build this parser.", "labels": [], "entities": []}, {"text": "The main difficulty is that the training data fit in memory only using an indirect representation, 1 so the most costly operation during training is accessing the features of a particular example.", "labels": [], "entities": []}, {"text": "We show how to train a parser effectively under these conditions.", "labels": [], "entities": []}, {"text": "We also show how to speedup training by using a principled sampling method to estimate the loss gradients used in feature selection.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 114, "end_pos": 131, "type": "TASK", "confidence": 0.7874531745910645}]}, {"text": "\u00a72 describes the parsing algorithm.", "labels": [], "entities": [{"text": "parsing", "start_pos": 17, "end_pos": 24, "type": "TASK", "confidence": 0.9789463877677917}]}, {"text": "\u00a73 presents the learning method and techniques used to reduce training time.", "labels": [], "entities": []}, {"text": "\u00a74 presents experiments with discriminative parsers built using these methods.", "labels": [], "entities": []}, {"text": "\u00a75 dis-cusses possible issues in scaling to larger example sets.", "labels": [], "entities": []}], "datasetContent": [{"text": "We follow and in training and testing on \u2264 15 word sentences in the English Penn Treebank.", "labels": [], "entities": [{"text": "English Penn Treebank", "start_pos": 68, "end_pos": 89, "type": "DATASET", "confidence": 0.7963115175565084}]}, {"text": "We used sections 02-21 for training, section 22 for development, and section 23, for testing.", "labels": [], "entities": []}, {"text": "We use the same preprocessing steps as: during both training and testing, the parser is given text POS-tagged by the tagger of, with capitalization stripped and outermost punctuation removed.", "labels": [], "entities": []}, {"text": "For reasons given in, items are inferred bottom-up right-to-left.", "labels": [], "entities": []}, {"text": "As mentioned in \u00a72, the parser cannot infer any item that crosses an item already in the state.", "labels": [], "entities": []}, {"text": "To ensure the parser does not enter an infinite loop, no two items in a state can have both the same span and the same label.", "labels": [], "entities": []}, {"text": "Given these restrictions, there were roughly 40 million training examples.", "labels": [], "entities": []}, {"text": "These were partitioned among the constituent label classifiers.", "labels": [], "entities": []}, {"text": "Our atomic feature set A contains features of the form \"is there an item in group J whose label/headword/headtag/headtagclass 9 is 'X'?\".", "labels": [], "entities": []}, {"text": "Possible values of 'X' for each predicate are collected from the training data.", "labels": [], "entities": []}, {"text": "Some examples of possible values for J include the last n child items, the first n left context items, all right context items, and the terminal items dominated by the non-head child items.", "labels": [], "entities": []}, {"text": "Space constraints prevent enumeration of the headtagclasses and atomic feature templates, which are Figure 1 F 1 score of our parser on the development set of the Penn Treebank, using only \u2264 15 word sentences.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 163, "end_pos": 176, "type": "DATASET", "confidence": 0.9788033962249756}]}, {"text": "The dashed line indicates the percent of NP example weight lost due to sampling.", "labels": [], "entities": []}, {"text": "The bottom x-axis shows the number of non-zero parameters in each parser, summed overall label classifiers.", "labels": [], "entities": []}, {"text": "instead provided at the URL given in the abstract.", "labels": [], "entities": []}, {"text": "These templates gave 1.1 million different atomic features.", "labels": [], "entities": []}, {"text": "We experimented with smaller feature sets, but found that accuracy was lower.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 58, "end_pos": 66, "type": "METRIC", "confidence": 0.9995088577270508}]}, {"text": "use linguistically more sophisticated features, and and use sub-tree features, all of which we plan to try in future work.", "labels": [], "entities": []}, {"text": "We evaluated our parser using the standard PAR-SEVAL measures: labelled precision, labelled recall, and labelled F-measure (Prec., Rec., and F 1 , respectively), which are based on the number of non-terminal items in the parser's output that match those in the gold-standard parse.", "labels": [], "entities": [{"text": "PAR-SEVAL", "start_pos": 43, "end_pos": 52, "type": "METRIC", "confidence": 0.7540117502212524}, {"text": "precision", "start_pos": 72, "end_pos": 81, "type": "METRIC", "confidence": 0.7891084551811218}, {"text": "recall", "start_pos": 92, "end_pos": 98, "type": "METRIC", "confidence": 0.9192739129066467}, {"text": "F-measure", "start_pos": 113, "end_pos": 122, "type": "METRIC", "confidence": 0.8161255717277527}, {"text": "F 1", "start_pos": 141, "end_pos": 144, "type": "METRIC", "confidence": 0.9908901751041412}]}, {"text": "The solid curve shows the accuracy of the parser over the development set as training progressed.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9995135068893433}]}, {"text": "The parser exceeded 89% F-measure after 2.5 days of training.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.9986512064933777}]}, {"text": "The peak F-measure was 90.55%, achieved at 5.4 days using 6.3K active parameters.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 9, "end_pos": 18, "type": "METRIC", "confidence": 0.9994951486587524}]}, {"text": "We omit details given by in favor of a longer discussion in \u00a74.2.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1 PARSEVAL results of parsers on the test  set, using only \u2264 15 word sentences.  F 1 % Rec. % Prec. %  Turian and Melamed (2005) 87.13 86.47 87.80  Bikel (2004)  88.30 87.85 88.75  Taskar et al. (2004)  89.12 89.10 89.14  our parser  89.40 89.26 89.55", "labels": [], "entities": [{"text": "PARSEVAL", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.8825119733810425}, {"text": "F", "start_pos": 88, "end_pos": 89, "type": "METRIC", "confidence": 0.9686157703399658}, {"text": "Rec", "start_pos": 94, "end_pos": 97, "type": "METRIC", "confidence": 0.7834253907203674}]}, {"text": " Table 2 Profile of an NP training iteration, given  in seconds, using an AMD Opteron 242 (64-bit,  1.6Ghz). Steps refer to Listing 1.", "labels": [], "entities": [{"text": "AMD Opteron 242", "start_pos": 74, "end_pos": 89, "type": "DATASET", "confidence": 0.7047581275304159}]}]}