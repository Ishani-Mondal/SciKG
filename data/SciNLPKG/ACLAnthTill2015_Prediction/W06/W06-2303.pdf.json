{"title": [{"text": "Robust Parsing of the Proposition Bank", "labels": [], "entities": [{"text": "Robust Parsing", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.8621430993080139}]}], "abstractContent": [{"text": "In this paper, we extend an existing statistical parsing model to produce richer output parse trees, annotated with PropBank semantic role labels.", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 37, "end_pos": 56, "type": "TASK", "confidence": 0.6199935674667358}, {"text": "PropBank semantic role labels", "start_pos": 116, "end_pos": 145, "type": "DATASET", "confidence": 0.8428461253643036}]}, {"text": "Our results show that the model can be robustly extended to produce more complex output parse trees without any loss in performance and suggest that joint inference of syntactic and semantic representations is a viable alternative to approaches based on a pipeline of local processing steps.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recent successes in statistical syntactic parsing based on supervised learning techniques trained on a large corpus of syntactic trees have brought forth the hope that the same approaches could be applied to the more ambitious goal of recovering the propositional content and the frame semantics of a sentence.", "labels": [], "entities": [{"text": "statistical syntactic parsing", "start_pos": 20, "end_pos": 49, "type": "TASK", "confidence": 0.6287249128023783}]}, {"text": "Moving towards a shallow semantic level of representation is a first initial step towards the distant goal of natural language understanding and has immediate applications in question-answering and information extraction.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 110, "end_pos": 140, "type": "TASK", "confidence": 0.6525633831818899}, {"text": "information extraction", "start_pos": 198, "end_pos": 220, "type": "TASK", "confidence": 0.8247310221195221}]}, {"text": "For example, an automatic flight reservation system processing the sentence I want to book a flight from Geneva to Trento will need to know that from Geneva denotes the origin of the flight and to Trento denotes its destination.", "labels": [], "entities": []}, {"text": "Knowing that these two phrases are prepositional phrases, the information provided by a syntactic parser, is only moderately useful.", "labels": [], "entities": []}, {"text": "The growing interest in learning deeper information is to a large extent supported and due to the recent development of semantically annotated databases such as FrameNet ( or the Proposition Bank ( , that can be used as training resources fora number of supervised learning paradigms.", "labels": [], "entities": []}, {"text": "We focus hereon the Proposition Bank (PropBank).", "labels": [], "entities": [{"text": "Proposition Bank (PropBank)", "start_pos": 20, "end_pos": 47, "type": "DATASET", "confidence": 0.8580382823944092}]}, {"text": "PropBank encodes propositional information by adding a layer of argument structure annotation to the syntactic structures of the Penn Treebank (.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 129, "end_pos": 142, "type": "DATASET", "confidence": 0.9945983588695526}]}, {"text": "Verbal predicates in the Penn Treebank (PTB) receive a label REL and their arguments are annotated with abstract semantic role labels A0-A5 or AA for those complements of the predicative verb that are considered arguments while those complements of the verb labelled with a semantic functional label in the original PTB receive the composite semantic role label AM-X, where X stands for labels such as LOC, TMP or ADV, for locative, temporal and adverbial modifiers respectively.", "labels": [], "entities": [{"text": "Penn Treebank (PTB)", "start_pos": 25, "end_pos": 44, "type": "DATASET", "confidence": 0.9795671939849854}, {"text": "REL", "start_pos": 61, "end_pos": 64, "type": "METRIC", "confidence": 0.9126279950141907}, {"text": "AA", "start_pos": 143, "end_pos": 145, "type": "METRIC", "confidence": 0.8393415808677673}]}, {"text": "A tree structure with PropBank labels fora sentence from the PTB (section 00) is shown in below.", "labels": [], "entities": [{"text": "PTB (section 00", "start_pos": 61, "end_pos": 76, "type": "DATASET", "confidence": 0.9148911088705063}]}, {"text": "PropBank uses two levels of granularity in its annotation, at least conceptually.", "labels": [], "entities": [{"text": "PropBank", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.972711443901062}]}, {"text": "Arguments receiving labels A0-A5 or AA do not express consistent semantic roles and are specific to a verb, while arguments receiving an AM-X label are supposed to be adjuncts and the respective roles they express are consistent across all verbs.", "labels": [], "entities": [{"text": "AA", "start_pos": 36, "end_pos": 38, "type": "METRIC", "confidence": 0.9345842003822327}]}, {"text": "Recent approaches to learning semantic role labels are based on two-stage architectures.", "labels": [], "entities": [{"text": "learning semantic role labels", "start_pos": 21, "end_pos": 50, "type": "TASK", "confidence": 0.6589533239603043}]}, {"text": "The first stage selects the elements to be labelled, while the second determines the labels to be assigned to the selected elements.", "labels": [], "entities": []}, {"text": "While some of these models are based on full parse trees (), other methods have been proposed that eschew the need fora full parse).", "labels": [], "entities": []}, {"text": "Because of the way the problem has been formulated -as a pipeline of parsing (or chunking) feeding into labelling -specific investigations of integrated approaches that solve both the parsing and the semantic role labelling problems at the same time have not been studied.", "labels": [], "entities": [{"text": "parsing (or chunking)", "start_pos": 69, "end_pos": 90, "type": "TASK", "confidence": 0.8142039895057678}]}, {"text": "We present work to test the hypothesis that a current statistical parser can output richer information robustly, that is without any significant degradation of the parser's accuracy on the original parsing task, by explicitly modelling semantic role labels as the interface between syntax and semantics.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 173, "end_pos": 181, "type": "METRIC", "confidence": 0.9976404905319214}]}, {"text": "We achieve promising results both on the simple parsing task, where the accuracy of the parser is measured on the standard Parseval measures, and also on the parsing task where the more complex labels of PropBank are taken into account.", "labels": [], "entities": [{"text": "parsing task", "start_pos": 48, "end_pos": 60, "type": "TASK", "confidence": 0.8288219273090363}, {"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9993011951446533}, {"text": "parsing task", "start_pos": 158, "end_pos": 170, "type": "TASK", "confidence": 0.8982880413532257}, {"text": "PropBank", "start_pos": 204, "end_pos": 212, "type": "DATASET", "confidence": 0.9485366940498352}]}, {"text": "We will call the former task Penn Treebank parsing (PTB parsing) and the latter task PropBank parsing below.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 29, "end_pos": 42, "type": "DATASET", "confidence": 0.9833310544490814}, {"text": "parsing (PTB parsing", "start_pos": 43, "end_pos": 63, "type": "TASK", "confidence": 0.6881224811077118}, {"text": "PropBank parsing", "start_pos": 85, "end_pos": 101, "type": "TASK", "confidence": 0.7648693919181824}]}, {"text": "These results have several consequences.", "labels": [], "entities": []}, {"text": "On the one hand, we show that it is possible to build a single integrated robust system successfully.", "labels": [], "entities": []}, {"text": "This is a meaningful achievement, as a task combining semantic role labelling and parsing is more complex than simple syntactic parsing.", "labels": [], "entities": [{"text": "semantic role labelling", "start_pos": 54, "end_pos": 77, "type": "TASK", "confidence": 0.6270702183246613}, {"text": "syntactic parsing", "start_pos": 118, "end_pos": 135, "type": "TASK", "confidence": 0.7782970666885376}]}, {"text": "While the shallow semantics of a constituent and its structural position are often correlated, they sometimes diverge.", "labels": [], "entities": []}, {"text": "For example, some nominal temporal modifiers occupy an object position without being objects, like Tuesday in below.", "labels": [], "entities": []}, {"text": "On the other hand, our results indicate that the proposed models are robust.", "labels": [], "entities": []}, {"text": "To model our task accurately, additional parameters must be estimated.", "labels": [], "entities": []}, {"text": "However, given the current limited availability of annotated treebanks, this more complex task will have to be solved with the same overall amount of data, aggravating the difficulty of estimating the model's parameters due to sparse data.", "labels": [], "entities": []}, {"text": "The limited availability of data is increased further by the high variability of the argumental labels A0-A5 whose semantics is specific to a given verb or a given verb sense.", "labels": [], "entities": []}, {"text": "Solving this more complex problem successfully, then, indicates that the models used are robust.", "labels": [], "entities": []}, {"text": "Finally, we achieve robustness without simplifying the parsing architecture.", "labels": [], "entities": [{"text": "parsing", "start_pos": 55, "end_pos": 62, "type": "TASK", "confidence": 0.9681462645530701}]}, {"text": "Specifically, robustness is achieved without resorting to the stipulation of strong independence assumptions to compensate for the limited availability and high variability of data.", "labels": [], "entities": []}, {"text": "Consequently, such an achievement demonstrates not only that the robustness of the parsing model, but also its scalability and portability.", "labels": [], "entities": [{"text": "parsing", "start_pos": 83, "end_pos": 90, "type": "TASK", "confidence": 0.9651991128921509}]}], "datasetContent": [{"text": "Our extended semantic role SSN parser was trained on sections 2-21 and validated on section 24 from the PropBank.", "labels": [], "entities": [{"text": "SSN parser", "start_pos": 27, "end_pos": 37, "type": "TASK", "confidence": 0.8988625407218933}, {"text": "PropBank", "start_pos": 104, "end_pos": 112, "type": "DATASET", "confidence": 0.9769574403762817}]}, {"text": "Training, validating and testing data sets consist of the PTB data annotated with PropBank semantic roles labels, as provided in the CoNLL-2005 shared task (Carreras and ).", "labels": [], "entities": [{"text": "PTB data", "start_pos": 58, "end_pos": 66, "type": "DATASET", "confidence": 0.9098100066184998}]}, {"text": "Our augmented model has a total 613 of nonterminals to represents both the PTB and PropBank labels of constituents, instead of the 33 of the original SSN parser.", "labels": [], "entities": [{"text": "PTB", "start_pos": 75, "end_pos": 78, "type": "DATASET", "confidence": 0.9309177398681641}]}, {"text": "The 580 newly introduced labels consist of a standard PTB label followed by a set of one or more PropBank semantic role such as PP-AM-TMP or NP-A0-A1.", "labels": [], "entities": []}, {"text": "As a result of lowering the six AM-X semantic role labels, 240 new part-of-speech tags were introduced to partition the original tag set which consisted of 45 tags.", "labels": [], "entities": []}, {"text": "SSN parsers do not tag their input sentences.", "labels": [], "entities": [{"text": "SSN parsers", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.7937372624874115}]}, {"text": "To provide the augmented model with tagged input sentences, we trained an SVM tagger whose features and parameters are described in detail in ().", "labels": [], "entities": []}, {"text": "Trained on section 2-21, the tagger reaches a performance of 95.45% on the test set (section 23) using our new tag set.", "labels": [], "entities": [{"text": "tagger", "start_pos": 29, "end_pos": 35, "type": "TASK", "confidence": 0.9622238874435425}]}, {"text": "As already mentioned, argumental labels A0-A5 are specific to a given verb or a given verb sense, thus their distribution is highly variable.", "labels": [], "entities": []}, {"text": "To reduce variability, we add some of the tag-verb pairs licensing these argumental labels to the vocabu-F RP PropBank training and PropBank parsing task 82.3 82.1 82.4 PropBank training and PTB parsing task 88.8 88.6 88.9 PTB training and PTB parsing task 88.6 88.3 88.9: Percentage F-measure (F), recall (R), and precision (P) of our SSN parser on two different tasks and the original SSN parser.", "labels": [], "entities": [{"text": "PropBank parsing task 82.3 82.1 82.4 PropBank", "start_pos": 132, "end_pos": 177, "type": "TASK", "confidence": 0.5655110776424408}, {"text": "PTB parsing task 88.8 88.6 88.9 PTB", "start_pos": 191, "end_pos": 226, "type": "TASK", "confidence": 0.7912767444338117}, {"text": "PTB parsing task 88.6 88.3 88.9", "start_pos": 240, "end_pos": 271, "type": "TASK", "confidence": 0.7806393802165985}, {"text": "Percentage F-measure (F)", "start_pos": 273, "end_pos": 297, "type": "METRIC", "confidence": 0.8629488229751587}, {"text": "recall (R)", "start_pos": 299, "end_pos": 309, "type": "METRIC", "confidence": 0.9458889812231064}, {"text": "precision (P)", "start_pos": 315, "end_pos": 328, "type": "METRIC", "confidence": 0.9721954613924026}]}, {"text": "We reach a total of 4970 tagword pairs.", "labels": [], "entities": []}, {"text": "3 This vocabulary comprises the original 512 pairs of the original SSN model, and our added pairs which must occur at least 10 times in the training data.", "labels": [], "entities": []}, {"text": "Our vocabulary as well as the new 240 POS tags and the new 580 non-terminal labels are included in the set f of features input to the history representations as described in section 2.", "labels": [], "entities": []}, {"text": "We perform two different evaluations on our model trained on PropBank data.", "labels": [], "entities": [{"text": "PropBank data", "start_pos": 61, "end_pos": 74, "type": "DATASET", "confidence": 0.974309891462326}]}, {"text": "Recall that we distinguish between two parsing tasks: the PropBank parsing task and the PTB parsing task.", "labels": [], "entities": [{"text": "parsing", "start_pos": 39, "end_pos": 46, "type": "TASK", "confidence": 0.9623140692710876}, {"text": "PropBank parsing task", "start_pos": 58, "end_pos": 79, "type": "TASK", "confidence": 0.7610165476799011}, {"text": "PTB parsing task", "start_pos": 88, "end_pos": 104, "type": "TASK", "confidence": 0.7694044510523478}]}, {"text": "To evaluate the first parsing task, we compute the standard Parseval measures of labelled recall and precision of constituents, taking into account not only the 33 original labels but also the 580 newly introduced PropBank labels.", "labels": [], "entities": [{"text": "parsing task", "start_pos": 22, "end_pos": 34, "type": "TASK", "confidence": 0.8897930979728699}, {"text": "Parseval", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.8335709571838379}, {"text": "recall", "start_pos": 90, "end_pos": 96, "type": "METRIC", "confidence": 0.8826155066490173}, {"text": "precision", "start_pos": 101, "end_pos": 110, "type": "METRIC", "confidence": 0.9988601207733154}, {"text": "PropBank labels", "start_pos": 214, "end_pos": 229, "type": "DATASET", "confidence": 0.9088788032531738}]}, {"text": "This evaluation gives us an indication of how accurately and exhaustively we can recover this richer set of nonterminal labels.", "labels": [], "entities": []}, {"text": "The results, computed on the testing data set from the PropBank, are shown on the first line of.", "labels": [], "entities": [{"text": "testing data set", "start_pos": 29, "end_pos": 45, "type": "DATASET", "confidence": 0.770855704943339}, {"text": "PropBank", "start_pos": 55, "end_pos": 63, "type": "DATASET", "confidence": 0.5725718140602112}]}, {"text": "To evaluate the PTB task, we compute the labelled recall and precision of constituents, ignoring the set of PropBank semantic role labels that our model assigns to constituents.", "labels": [], "entities": [{"text": "recall", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.9444584250450134}, {"text": "precision", "start_pos": 61, "end_pos": 70, "type": "METRIC", "confidence": 0.9975734353065491}]}, {"text": "This evaluation indicates how well we perform on the standard PTB parsing task alone, and its results on the testing data set from the PTB are shown on the second line of.", "labels": [], "entities": [{"text": "PTB parsing task", "start_pos": 62, "end_pos": 78, "type": "TASK", "confidence": 0.75135471423467}, {"text": "PTB", "start_pos": 135, "end_pos": 138, "type": "DATASET", "confidence": 0.755031943321228}]}, {"text": "The third line of gives the performance on the simpler PTB parsing task of the original SSN parser, that was trained on the PTB data sets contrary to our SSN model trained on the PropBank data sets.", "labels": [], "entities": [{"text": "PTB parsing", "start_pos": 55, "end_pos": 66, "type": "TASK", "confidence": 0.6951424479484558}, {"text": "SSN parser", "start_pos": 88, "end_pos": 98, "type": "TASK", "confidence": 0.8225964605808258}, {"text": "PTB data sets", "start_pos": 124, "end_pos": 137, "type": "DATASET", "confidence": 0.971151610215505}, {"text": "PropBank data sets", "start_pos": 179, "end_pos": 197, "type": "DATASET", "confidence": 0.9827849070231119}]}], "tableCaptions": [{"text": " Table 2: Percentage F-measure (F), recall (R), and precision (P) of our Propbank SSN parser and state- of-the-art semantic role labelling systems on the PropBank parsing task (1267 sentences from PropBank  validating data sets; Propbank data sets are available at http://www.lsi.upc.edu/ srlconll/st05/st05.html).", "labels": [], "entities": [{"text": "Percentage F-measure (F)", "start_pos": 10, "end_pos": 34, "type": "METRIC", "confidence": 0.8868509769439697}, {"text": "recall (R)", "start_pos": 36, "end_pos": 46, "type": "METRIC", "confidence": 0.9407946318387985}, {"text": "precision (P)", "start_pos": 52, "end_pos": 65, "type": "METRIC", "confidence": 0.9464257955551147}, {"text": "PropBank parsing task", "start_pos": 154, "end_pos": 175, "type": "TASK", "confidence": 0.7288613716761271}, {"text": "PropBank  validating data sets", "start_pos": 197, "end_pos": 227, "type": "DATASET", "confidence": 0.7574018910527229}, {"text": "Propbank data sets", "start_pos": 229, "end_pos": 247, "type": "DATASET", "confidence": 0.7553339302539825}]}]}