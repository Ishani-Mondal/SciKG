{"title": [{"text": "Measuring annotator agreement in a complex hierarchical dialogue act annotation scheme", "labels": [], "entities": []}], "abstractContent": [{"text": "We present a first analysis of inter-annotator agreement for the DIT ++ tagset of dialogue acts, a comprehensive, lay-ered, multidimensional set of 86 tags.", "labels": [], "entities": [{"text": "DIT ++ tagset of dialogue acts", "start_pos": 65, "end_pos": 95, "type": "DATASET", "confidence": 0.8870382010936737}]}, {"text": "Within a dimension or a layer, subsets of tags are often hierarchically organised.", "labels": [], "entities": []}, {"text": "We argue that especially for such highly struc-tured annotation schemes the well-known kappa statistic is not an adequate measure of inter-annotator agreement.", "labels": [], "entities": []}, {"text": "Instead, we propose a statistic that takes the structural properties of the tagset into account, and we discuss the application of this statistic in an annotation experiment.", "labels": [], "entities": []}, {"text": "The experiment shows promising agreement scores for most dimensions in the tagset and provides useful insights into the usability of the annotation scheme, but also indicates that several additional factors influence annotator agreement.", "labels": [], "entities": []}, {"text": "We finally suggest that the proposed approach for measuring agreement per dimension can be a good basis for measuring annotator agreement over the dimensions of a multidimensional annotation scheme.", "labels": [], "entities": []}], "introductionContent": [{"text": "The DIT ++ tagset ) was designed to combine in one comprehensive annotation scheme the communicative functions of dialogue acts distinguished in Dynamic Interpretation Theory), and many of those in DAMSL ) and in other annotation schemes.", "labels": [], "entities": []}, {"text": "An important difference between the DIT ++ and DAMSL schemes is the more elaborate and fine-grained set of functions for feedback and other aspects of dialogue control that is available in DIT, partly inspired by the work of Allwood (.", "labels": [], "entities": []}, {"text": "As it is often thought that more elaborate and fine-grained annotation schemes are difficult for annotators to apply consistently, we decided to address this issue in an annotation experiment on which we report in this paper.", "labels": [], "entities": []}, {"text": "A frequently used way of evaluating human dialogue act classification is inter-annotator agreement.", "labels": [], "entities": [{"text": "human dialogue act classification", "start_pos": 36, "end_pos": 69, "type": "TASK", "confidence": 0.7657998949289322}]}, {"text": "Agreement is sometimes measured as percentage of the cases on which the annotators agree, but more often expected agreement is taken into account in using the kappa statistic, which is given by: where p o is the observed proportion of agreement and p e is the proportion of agreement expected by chance.", "labels": [], "entities": [{"text": "Agreement", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9570429921150208}]}, {"text": "Ever since its introduction in general and in computational linguistics), many researchers have pointed out that there are quite some problems in using \u03ba (e.g.), one of which is the discrepancy between p 0 and \u03ba for skewed class distribution.", "labels": [], "entities": []}, {"text": "Another is that the degree of disagreement is not taken into account, which is relevant for any non-nominal scale.", "labels": [], "entities": []}, {"text": "To address this problem, a weighted \u03ba has been proposed) that penalizes disagreement according to their degree rather than treating all disagreements equally.", "labels": [], "entities": []}, {"text": "It would be arguable that in a similar way, characteristics of dialogue acts in a particular taxonomy and possible pragmatic similarity between them should betaken into account to express annotator agreement.", "labels": [], "entities": []}, {"text": "For dialogue act taxonomies which are structured in a meaningful way, such as those that express hierarchical relations between concepts in the taxonomy, the taxonomic structure can be exploited to express how much annotators disagree when they choose different concepts that are directly or indirectly related.", "labels": [], "entities": []}, {"text": "Recent work that accounts for some of these aspects is a metric for automatic dialogue act classification () that uses distance in a hierarchical structure of multidimensional labels.", "labels": [], "entities": [{"text": "automatic dialogue act classification", "start_pos": 68, "end_pos": 105, "type": "TASK", "confidence": 0.6349455788731575}]}, {"text": "In the following sections of this paper, we will first briefly consider the dimensions in the DIT ++ scheme and highlight the taxonomic characteristics that will turnout to be relevant in later stage.", "labels": [], "entities": [{"text": "DIT ++ scheme", "start_pos": 94, "end_pos": 107, "type": "DATASET", "confidence": 0.8118122021357218}]}, {"text": "We will then introduce a variant of weighted \u03ba for inter-annotator agreement called \u03ba tw that adopts a taxonomy-dependent weighting, and discuss its use.", "labels": [], "entities": []}], "datasetContent": [{"text": "As noted, existing work on annotator agreement analysis has mostly involved only two annotators.", "labels": [], "entities": [{"text": "annotator agreement analysis", "start_pos": 27, "end_pos": 55, "type": "TASK", "confidence": 0.7672162055969238}]}, {"text": "It maybe argued that especially for annotation of concepts that are rather complex, an odd number of annotators is desirable.", "labels": [], "entities": []}, {"text": "First, it allows having majority agreement unless all annotators choose entirely different.", "labels": [], "entities": []}, {"text": "Second, it allows to deal better with the undesirable situation that one annotator chooses quite differently from the others.", "labels": [], "entities": []}, {"text": "The 2 Drawn from the OVIS corpus (): OVIS2:104/001/001:008-011 agreement scores reported in this paper are all calculated on the basis of the annotations of three annotators, using the method proposed in.", "labels": [], "entities": [{"text": "OVIS corpus", "start_pos": 21, "end_pos": 32, "type": "DATASET", "confidence": 0.9530612528324127}, {"text": "OVIS2:104", "start_pos": 37, "end_pos": 46, "type": "DATASET", "confidence": 0.8594212532043457}]}, {"text": "The dialogues that were annotated are taskoriented and are all in Dutch.", "labels": [], "entities": []}, {"text": "To account for different complexities of interaction, both humanmachine and human-human dialogues are considered.", "labels": [], "entities": []}, {"text": "Moreover, the dialogues analyzed are drawn from different corpora: OVIS (), DIAMOND), and a collection of Map Task dialogues; see Six undergraduate students annotated the selected dialogue material.", "labels": [], "entities": [{"text": "OVIS", "start_pos": 67, "end_pos": 71, "type": "METRIC", "confidence": 0.7101110219955444}, {"text": "DIAMOND", "start_pos": 76, "end_pos": 83, "type": "METRIC", "confidence": 0.9538769721984863}]}, {"text": "They had been introduced to the DIT ++ annotation scheme and the underlying theory while participating in a course on pragmatics.", "labels": [], "entities": [{"text": "DIT ++ annotation scheme", "start_pos": 32, "end_pos": 56, "type": "DATASET", "confidence": 0.7476518750190735}]}, {"text": "During this course they were exposed to approximately four hours of lecturing and few small annotation exercises.", "labels": [], "entities": []}, {"text": "For all dialogues, the audio recordings were transcribed and the annotators annotated presegmented utterances for which full agreement was established on segmentation level beforehand.", "labels": [], "entities": []}, {"text": "During the annotation sessions the annotators had -apart from the transcribed speech -access to the audio recordings, to the on-line definitions of the communicative functions in the scheme and to a very brief, 1-page set of annotation guidelines . The task was facilitated by the use of an annotation tool that had been built for this occasion; this tool allowed the subjects to assign each utterance one DIT ++ tag for each dimension without any further constraints.", "labels": [], "entities": []}, {"text": "In total 1,674 utterances were annotated.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Scores for corrected \u03ba and \u03ba tw per DIT  dimension.", "labels": [], "entities": []}]}