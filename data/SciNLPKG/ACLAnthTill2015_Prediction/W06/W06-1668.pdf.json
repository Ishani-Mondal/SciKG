{"title": [{"text": "Competitive generative models with structure learning for NLP classification tasks", "labels": [], "entities": [{"text": "NLP classification", "start_pos": 58, "end_pos": 76, "type": "TASK", "confidence": 0.895018994808197}]}], "abstractContent": [{"text": "In this paper we show that generative models are competitive with and sometimes superior to discriminative models, when both kinds of models are allowed to learn structures that are optimal for discrimination.", "labels": [], "entities": []}, {"text": "In particular, we compare Bayesian Networks and Conditional log-linear models on two NLP tasks.", "labels": [], "entities": []}, {"text": "We observe that when the structure of the gen-erative model encodes very strong independence assumptions (a la Naive Bayes), a discriminative model is superior, but when the generative model is allowed to weaken these independence assumptions via learning a more complex structure, it can achieve very similar or better performance than a corresponding discrimina-tive model.", "labels": [], "entities": []}, {"text": "In addition, as structure learning for generative models is far more efficient , they maybe preferable for some tasks.", "labels": [], "entities": [{"text": "generative models", "start_pos": 39, "end_pos": 56, "type": "TASK", "confidence": 0.8958315253257751}]}], "introductionContent": [{"text": "Discriminative models have become the models of choice for NLP tasks, because of their ability to easily incorporate non-independent features and to more directly optimize classification accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 187, "end_pos": 195, "type": "METRIC", "confidence": 0.7956534624099731}]}, {"text": "State of the art models for many NLP tasks are either fully discriminative or trained using discriminative reranking).", "labels": [], "entities": []}, {"text": "These include models for part-of-speech tagging (, semantic-role labeling) and Penn Treebank parsing).", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 25, "end_pos": 47, "type": "TASK", "confidence": 0.6991234421730042}, {"text": "semantic-role labeling", "start_pos": 51, "end_pos": 73, "type": "TASK", "confidence": 0.6990894079208374}, {"text": "Penn Treebank parsing", "start_pos": 79, "end_pos": 100, "type": "DATASET", "confidence": 0.8301463723182678}]}, {"text": "The superiority of discriminative models has been shown on many tasks when the discriminative and generative models use exactly the same model structure ().", "labels": [], "entities": []}, {"text": "However, the advantage of the discriminative models can be very slight) and for small training set sizes generative models can be better because they need fewer training samples to converge to the optimal parameter setting ().", "labels": [], "entities": []}, {"text": "Additionally, many discriminative models use a generative model as abase model and add discriminative features with reranking), or train discriminatively a small set of weights for features which are generatively estimated probabilities ().", "labels": [], "entities": []}, {"text": "Therefore it is important to study generative models and to find ways of making them better even when they are used only as components of discriminative models.", "labels": [], "entities": [{"text": "generative", "start_pos": 35, "end_pos": 45, "type": "TASK", "confidence": 0.9688524007797241}]}, {"text": "Generative models may often perform poorly due to making strong independence assumptions about the joint distribution of features and classes.", "labels": [], "entities": []}, {"text": "To avoid this problem, generative models for NLP tasks have often been manually designed to achieve an appropriate representation of the joint distribution, such as in the parsing models of).", "labels": [], "entities": []}, {"text": "This shows that when the generative models have a good model structure, they can perform quite well.", "labels": [], "entities": []}, {"text": "In this paper, we look differently at comparing generative and discriminative models.", "labels": [], "entities": [{"text": "generative", "start_pos": 48, "end_pos": 58, "type": "TASK", "confidence": 0.9725514054298401}]}, {"text": "We ask the question: given the same set of input features, what is the best a generative model can do if it is allowed to learn an optimal structure for the joint distribution, and what is the best a discriminative model can do if it is also allowed to learn an optimal structure.", "labels": [], "entities": []}, {"text": "That is, we do not impose any independence assumptions on the generative or discriminative models and let them learn the best representation of the data they can.", "labels": [], "entities": []}, {"text": "Structure learning is very efficient for generative models in the form of directed graphical models (Bayesian Networks), since the optimal parameters for such models can be estimated in closed form.", "labels": [], "entities": [{"text": "Structure learning", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8892516791820526}]}, {"text": "We compare Bayesian Net-works with structure learning to their closely related discriminative counterpart -conditional loglinear models with structure learning.", "labels": [], "entities": []}, {"text": "Our conditional log-linear models can also be seen as Conditional Random Fields (), except we do not have a structure on the labels, but want to learn a structure on the features.", "labels": [], "entities": []}, {"text": "We compare the two kinds of models on two NLP classification tasks -prepositional phrase attachment and semantic role labelling.", "labels": [], "entities": [{"text": "NLP classification", "start_pos": 42, "end_pos": 60, "type": "TASK", "confidence": 0.8161494135856628}, {"text": "prepositional phrase attachment", "start_pos": 68, "end_pos": 99, "type": "TASK", "confidence": 0.5929469267527262}, {"text": "semantic role labelling", "start_pos": 104, "end_pos": 127, "type": "TASK", "confidence": 0.656745711962382}]}, {"text": "Our results show that the generative models are competitive with or better than the discriminative models.", "labels": [], "entities": [{"text": "generative", "start_pos": 26, "end_pos": 36, "type": "TASK", "confidence": 0.965360164642334}]}, {"text": "When a small set of interpolation parameters for the conditional probability tables are fit discriminatively, the resulting hybrid generativediscriminative models perform better than the generative only models and sometimes better than the discriminative models.", "labels": [], "entities": []}, {"text": "In Section 2, we describe in detail the form of the generative and discriminative models we study and our structure search methodology.", "labels": [], "entities": []}, {"text": "In Section 3 we present the results of our empirical study.", "labels": [], "entities": []}], "datasetContent": [{"text": "We study two classification problems -prepositional phrase (PP) attachment, and semantic role labeling.", "labels": [], "entities": [{"text": "prepositional phrase (PP) attachment", "start_pos": 38, "end_pos": 74, "type": "TASK", "confidence": 0.6377079983552297}, {"text": "semantic role labeling", "start_pos": 80, "end_pos": 102, "type": "TASK", "confidence": 0.6395822564760844}]}, {"text": "Following most of the literature on prepositional phrase attachment (e.g.,), we focus on the most common configuration that leads to ambiguities: V NP PP.", "labels": [], "entities": [{"text": "prepositional phrase attachment", "start_pos": 36, "end_pos": 67, "type": "TASK", "confidence": 0.6717766722043356}]}, {"text": "Here, we are given a verb phrase with a following noun phrase and a prepositional phrase.", "labels": [], "entities": []}, {"text": "The goal is to determine if the PP should be attached to the verb or to the object noun phrase.", "labels": [], "entities": []}, {"text": "For example, in the sentence: [with a peg] PP , the prepositional phrase with a peg can either modify the verb hang or the object noun phrase a painting.", "labels": [], "entities": []}, {"text": "Here, clearly, with a peg modifies the verb hang.", "labels": [], "entities": []}, {"text": "We follow the common practice in representing the problem using only the head words of these constituents and of the NP inside the PP.", "labels": [], "entities": []}, {"text": "Thus the example sentence is represented as the following quadruple: [v:hang n 1 :painting p:with n 2 :peg].", "labels": [], "entities": []}, {"text": "Thus for the PP attachment task we have binary labels Att, and four input variables -v, n 1 , p, n 2 . We work with the standard dataset previously used for this task by other researchers (Ratna-.", "labels": [], "entities": [{"text": "PP attachment task", "start_pos": 13, "end_pos": 31, "type": "TASK", "confidence": 0.9525126814842224}, {"text": "Att", "start_pos": 54, "end_pos": 57, "type": "METRIC", "confidence": 0.9505693316459656}]}, {"text": "It is extracted from the the Penn Treebank Wall Street Journal data (.", "labels": [], "entities": [{"text": "Penn Treebank Wall Street Journal data", "start_pos": 29, "end_pos": 67, "type": "DATASET", "confidence": 0.9701610108216604}]}, {"text": "shows summary statistics for the dataset.", "labels": [], "entities": []}, {"text": "The second task we concentrate on is semantic role labeling in the context of).", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 37, "end_pos": 59, "type": "TASK", "confidence": 0.7098773916562399}]}, {"text": "The PropBank corpus annotates phrases which fill semantic roles for verbs on top of Penn Treebank parse trees.", "labels": [], "entities": [{"text": "PropBank corpus annotates phrases", "start_pos": 4, "end_pos": 37, "type": "DATASET", "confidence": 0.9283097833395004}, {"text": "Penn Treebank parse trees", "start_pos": 84, "end_pos": 109, "type": "DATASET", "confidence": 0.9652939438819885}]}, {"text": "The annotated roles specify agent, patient, direction, etc.", "labels": [], "entities": []}, {"text": "The labels for semantic roles are grouped into two groups, core argument labels and modifier argument labels, which correspond approximately to the traditional distinction between arguments and adjuncts.", "labels": [], "entities": []}, {"text": "There has been plenty of work on machine learning models for semantic role labeling, starting with the work of, and including CoNLL shared tasks).", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 61, "end_pos": 83, "type": "TASK", "confidence": 0.7072814106941223}]}, {"text": "The most successful formulation has been as learning to classify nodes in a syntactic parse tree.", "labels": [], "entities": []}, {"text": "The possible labels are NONE, meaning that the corresponding phrase has no semantic role and the set of core and modifier labels.", "labels": [], "entities": [{"text": "NONE", "start_pos": 24, "end_pos": 28, "type": "METRIC", "confidence": 0.9814403057098389}]}, {"text": "We concentrate on the subproblem of classification for core argument nodes.", "labels": [], "entities": []}, {"text": "The problem is, given that anode has a core argument label, decide what the correct label is.", "labels": [], "entities": []}, {"text": "Other researchers have also looked at this subproblem ().", "labels": [], "entities": []}, {"text": "Many features have been proposed for building models for semantic role labeling.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 57, "end_pos": 79, "type": "TASK", "confidence": 0.7380033532778422}]}, {"text": "Initially, 7 features were proposed by), and all following research has used these features and some additional ones.", "labels": [], "entities": []}, {"text": "These are the features we use as well.", "labels": [], "entities": []}, {"text": "State-of-the-art models for the subproblem of classification of core arguments additionally use other features of individual nodes (, as well as global features including the labels of other nodes in parse tree.", "labels": [], "entities": []}, {"text": "Nevertheless it is interesting to see how well we can do with these 7 features only.", "labels": [], "entities": []}, {"text": "We use the standard training, development, and.", "labels": [], "entities": []}, {"text": "As we can see, the training set size is much larger compared to the PP attachment training set.", "labels": [], "entities": [{"text": "PP attachment training set", "start_pos": 68, "end_pos": 94, "type": "DATASET", "confidence": 0.5894257053732872}]}], "tableCaptions": [{"text": " Table 1: Data sizes for the PP attachment and SRL  tasks.", "labels": [], "entities": [{"text": "PP attachment", "start_pos": 29, "end_pos": 42, "type": "TASK", "confidence": 0.826251745223999}, {"text": "SRL  tasks", "start_pos": 47, "end_pos": 57, "type": "TASK", "confidence": 0.8675258457660675}]}, {"text": " Table 3: Naive Bayes and Logistic regression PP  attachment results.", "labels": [], "entities": []}, {"text": " Table 4: Bayesian Network and Conditional log- linear model PP attachment results.", "labels": [], "entities": [{"text": "PP attachment", "start_pos": 61, "end_pos": 74, "type": "TASK", "confidence": 0.9178716242313385}]}, {"text": " Table 5: Naive Bayes and Logistic regression SRL  classificaion results.", "labels": [], "entities": [{"text": "SRL  classificaion", "start_pos": 46, "end_pos": 64, "type": "TASK", "confidence": 0.7227577865123749}]}, {"text": " Table 6: Bayesian Network and Conditional log- linear model SRL classification results.", "labels": [], "entities": [{"text": "SRL classification", "start_pos": 61, "end_pos": 79, "type": "TASK", "confidence": 0.9511926472187042}]}, {"text": " Table 8: Bayesian Network and Conditional log- linear model: PP & SRL classification results us- ing minimal smoothing and no backoff to lower  order distributions.", "labels": [], "entities": [{"text": "PP & SRL classification", "start_pos": 62, "end_pos": 85, "type": "TASK", "confidence": 0.51459701359272}]}]}