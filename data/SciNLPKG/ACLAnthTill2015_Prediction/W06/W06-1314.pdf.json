{"title": [{"text": "Automatically Detecting Action Items in Audio Meeting Recordings", "labels": [], "entities": [{"text": "Automatically Detecting Action Items in Audio Meeting", "start_pos": 0, "end_pos": 53, "type": "TASK", "confidence": 0.8188531143324715}]}], "abstractContent": [{"text": "Identification of action items in meeting recordings can provide immediate access to salient information in a medium notoriously difficult to search and summarize.", "labels": [], "entities": []}, {"text": "To this end, we use a maximum entropy model to automatically detect action item-related utterances from multi-party audio meeting recordings.", "labels": [], "entities": []}, {"text": "We compare the effect of lexical, temporal, syntactic, semantic , and prosodic features on system performance.", "labels": [], "entities": []}, {"text": "We show that on a corpus of action item annotations on the ICSI meeting recordings, characterized by high imbalance and low inter-annotator agreement, the system performs at an F measure of 31.92%.", "labels": [], "entities": [{"text": "ICSI meeting recordings", "start_pos": 59, "end_pos": 82, "type": "DATASET", "confidence": 0.9659053484598795}, {"text": "F measure", "start_pos": 177, "end_pos": 186, "type": "METRIC", "confidence": 0.9884561896324158}]}, {"text": "While this is low compared to better-studied tasks on more mature corpora , the relative usefulness of the features towards this task is indicative of their usefulness on more consistent annotations, as well as to related tasks.", "labels": [], "entities": []}], "introductionContent": [{"text": "Meetings area ubiquitous feature of workplace environments, and recordings of meetings provide obvious benefit in that they can be replayed or searched through at a later date.", "labels": [], "entities": []}, {"text": "As recording technology becomes more easily available and storage space becomes less costly, the feasibility of producing and storing these recordings increases.", "labels": [], "entities": []}, {"text": "This is particularly true for audio recordings, which are cheaper to produce and store than full audio-video recordings.", "labels": [], "entities": []}, {"text": "However, audio recordings are notoriously difficult to search or to summarize.", "labels": [], "entities": [{"text": "summarize", "start_pos": 68, "end_pos": 77, "type": "TASK", "confidence": 0.9699810743331909}]}, {"text": "This is doubly true of multi-party recordings, which, in addition to the difficulties presented by single-party recordings, typically contain backchannels, elaborations, and side topics, all of which further confound search and summarization processes.", "labels": [], "entities": [{"text": "summarization", "start_pos": 228, "end_pos": 241, "type": "TASK", "confidence": 0.9701959490776062}]}, {"text": "Making efficient use of large meeting corpora thus requires intelligent summary and review techniques.", "labels": [], "entities": []}, {"text": "One possible user goal given a corpus of meeting recordings is to discover the action items decided within the meetings.", "labels": [], "entities": []}, {"text": "Action items are decisions made within the meeting that require postmeeting attention or labor.", "labels": [], "entities": []}, {"text": "Rapid identification of action items can provide immediate access to salient portions of the meetings.", "labels": [], "entities": []}, {"text": "A review of action items can also function as (part of) a summary of the meeting content.", "labels": [], "entities": []}, {"text": "To this end, we explore the task of applying maximum entropy classifiers to the task of automatically detecting action item utterances in audio recordings of multi-party meetings.", "labels": [], "entities": [{"text": "automatically detecting action item utterances in audio recordings of multi-party meetings", "start_pos": 88, "end_pos": 178, "type": "TASK", "confidence": 0.7650047432292592}]}, {"text": "Although available corpora for action items are not ideal, it is hoped that the feature analysis presented here will be of use to later work on other corpora.", "labels": [], "entities": []}], "datasetContent": [{"text": "We formulate the action item detection task as one of binary classification of utterances.", "labels": [], "entities": [{"text": "action item detection task", "start_pos": 17, "end_pos": 43, "type": "TASK", "confidence": 0.7322438508272171}]}, {"text": "We apply a maximum entropy (maxent) model to this task.", "labels": [], "entities": []}, {"text": "Maxent models seek to maximize the conditional probability of a class c given the observations X using the exponential form where f i,c (X) is the ith feature of the data X in class c, \u03bb i,c is the corresponding weight, and Z(X) is a normalization term.", "labels": [], "entities": []}, {"text": "Maxent models choose the weights \u03bb i,c so as to maximize the entropy of the induced distribution while remaining consistent with the data and labels; the intuition is that such a distribution makes the fewest assumptions about the underlying data.", "labels": [], "entities": []}, {"text": "Our maxent model is regularized by a quadratic prior and uses quasi-Newton parameter optimization.", "labels": [], "entities": []}, {"text": "Due to the limited amount of training data (see Section 3) and to avoid overfitting, we employ 10-fold cross validation in each experiment.", "labels": [], "entities": []}, {"text": "To evaluate system performance, we calculate the F measure (F ) of precision (P ) and recall (R), defined as: where A is the set of utterances marked as action items by the system, and C is the set of (all) correct action item utterances.", "labels": [], "entities": [{"text": "F measure (F )", "start_pos": 49, "end_pos": 63, "type": "METRIC", "confidence": 0.9790568828582764}, {"text": "precision (P )", "start_pos": 67, "end_pos": 81, "type": "METRIC", "confidence": 0.9328068196773529}, {"text": "recall (R)", "start_pos": 86, "end_pos": 96, "type": "METRIC", "confidence": 0.9694912135601044}]}, {"text": "The use of precision and recall is motivated by the fact that the large imbalance between positive and negative examples in the corpus (Section 3) means that simpler metrics like accuracy are insufficient-a system that simply classifies every utterance as negative will achieve an accuracy of 97.5%, which clearly is not a good reflection of desired behavior.", "labels": [], "entities": [{"text": "precision", "start_pos": 11, "end_pos": 20, "type": "METRIC", "confidence": 0.9993298053741455}, {"text": "recall", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.9984796643257141}, {"text": "accuracy", "start_pos": 179, "end_pos": 187, "type": "METRIC", "confidence": 0.9967697858810425}, {"text": "accuracy", "start_pos": 281, "end_pos": 289, "type": "METRIC", "confidence": 0.9953834414482117}]}, {"text": "Recall and F measure for such a system, however, will be zero.", "labels": [], "entities": [{"text": "F measure", "start_pos": 11, "end_pos": 20, "type": "METRIC", "confidence": 0.9870710968971252}]}, {"text": "Likewise, a system that flips a coin weighted in proportion to the number of positive examples in the entire corpus will have an accuracy of 95.25%, but will only achieve P = R = F = 2.4%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 129, "end_pos": 137, "type": "METRIC", "confidence": 0.9994671940803528}, {"text": "P = R", "start_pos": 171, "end_pos": 176, "type": "METRIC", "confidence": 0.8067672252655029}, {"text": "F", "start_pos": 179, "end_pos": 180, "type": "METRIC", "confidence": 0.5567595958709717}]}], "tableCaptions": [{"text": " Table 1: Performance of the maxent classifier as measured by F measure, the relative improvement from  the preceding feature set, and the number of features, across all feature sets tried. Italicized lines denote  the addition of features which do not improve performance; these are omitted from succeeding systems.", "labels": [], "entities": [{"text": "F measure", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9878309071063995}]}]}