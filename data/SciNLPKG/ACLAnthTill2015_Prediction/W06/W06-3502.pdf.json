{"title": [{"text": "Backbone Extraction and Pruning for Speeding Up a Deep Parser for Dialogue Systems", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper we discuss issues related to speeding up parsing with wide-coverage unification grammars.", "labels": [], "entities": []}, {"text": "We demonstrate that state-of-the-art optimisation techniques based on backbone parsing before unification do not provide a general solution , because they depend on specific properties of the grammar formalism that do not hold for all unification based grammars.", "labels": [], "entities": [{"text": "backbone parsing before unification", "start_pos": 70, "end_pos": 105, "type": "TASK", "confidence": 0.7698926329612732}]}, {"text": "As an alternative, we describe an optimisation technique that combines ambiguity packing at the constituent structure level with pruning based on local features.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this paper we investigate the problem of scaling up a deep unification-based parser developed specifically for the purpose of robust interpretation in dialogue systems by improving its speed and coverage for longer utterances.", "labels": [], "entities": [{"text": "speed", "start_pos": 188, "end_pos": 193, "type": "METRIC", "confidence": 0.9627190232276917}, {"text": "coverage", "start_pos": 198, "end_pos": 206, "type": "METRIC", "confidence": 0.9614205956459045}]}, {"text": "While typical sentences in dialogue contexts are shorter than in expository text domains, longer utterances are important in discussion oriented domains.", "labels": [], "entities": []}, {"text": "For example, in educational applications of dialogue it is important to elicit deep explanation from students and then offer focused feedback based on the details of what students say.", "labels": [], "entities": []}, {"text": "The choice of instructional dialogue as a target application influenced the choice of parser we needed to use for interpretation in a dialogue system.", "labels": [], "entities": []}, {"text": "Several deep, wide-coverage parsers are currently available, but many of these have not been designed with issues related to interpretation in a dialogue context in mind.", "labels": [], "entities": []}, {"text": "The TRIPS grammar () is a wide-coverage unification grammar that has been used very successfully in several task-oriented dialogue systems.", "labels": [], "entities": []}, {"text": "It supports interpretation of fragments and lexical semantic features (see Section 2 fora more detailed discussion), and provides additional robustness through \"robust\" rules that cover common grammar mistakes found in dialogue such as missing articles or incorrect agreement.", "labels": [], "entities": []}, {"text": "These enhancements help parsing dialogue (both spoken and typed), but they significantly increase grammar ambiguity, a common concern in building grammars for robust parsing.", "labels": [], "entities": [{"text": "parsing dialogue", "start_pos": 24, "end_pos": 40, "type": "TASK", "confidence": 0.9176694750785828}]}, {"text": "It is specifically these robustness-efficiency trade-offs that we address in this paper.", "labels": [], "entities": []}, {"text": "Much work has been done related to enhancing the efficiency of deep interpretation systems, which forms the foundation that we build on in this work.", "labels": [], "entities": []}, {"text": "For example, techniques for speeding up unification in HPSG lead to dramatic improvements in efficiency).", "labels": [], "entities": [{"text": "HPSG", "start_pos": 55, "end_pos": 59, "type": "DATASET", "confidence": 0.8461020588874817}]}, {"text": "Likewise ambiguity packing and CFG backbone parsing) are known to increase parsing efficiency.", "labels": [], "entities": [{"text": "CFG backbone parsing", "start_pos": 31, "end_pos": 51, "type": "TASK", "confidence": 0.7443896730740865}, {"text": "parsing", "start_pos": 75, "end_pos": 82, "type": "TASK", "confidence": 0.9619911313056946}]}, {"text": "However, as we show in this paper, these techniques depend on specific grammar properties that do not hold for all grammars.", "labels": [], "entities": []}, {"text": "This claim is consistent with observations of that parsing software optimisation techniques tend to be limited in their applicability to the individual grammars they were developed for.", "labels": [], "entities": [{"text": "parsing software optimisation", "start_pos": 51, "end_pos": 80, "type": "TASK", "confidence": 0.9021956920623779}]}, {"text": "While we used TRIPS as our example unification-based grammar, this investigation is important not only for this project, but in the general context of speeding up a wide-coverage unification grammar which incorporates fragment rules and lexical semantics, which may not be immediately provided by other available systems.", "labels": [], "entities": [{"text": "unification-based grammar", "start_pos": 35, "end_pos": 60, "type": "TASK", "confidence": 0.8947472274303436}]}, {"text": "In the remainder of the paper, we begin with a brief description of the TRIPS parser and grammar, and motivate the choice of LCFLEX parsing algorithm to provide a fast parsing foundation.", "labels": [], "entities": [{"text": "TRIPS parser", "start_pos": 72, "end_pos": 84, "type": "TASK", "confidence": 0.5877509117126465}, {"text": "LCFLEX parsing", "start_pos": 125, "end_pos": 139, "type": "TASK", "confidence": 0.528233215212822}]}, {"text": "We then discuss the backbone extraction and pruning techniques that we used, and evaluate them in comparison with the original parsing algorithm.", "labels": [], "entities": [{"text": "backbone extraction", "start_pos": 20, "end_pos": 39, "type": "TASK", "confidence": 0.761145293712616}]}, {"text": "We conclude with discussion of some implications for implementing grammars that build deep syntactic and semantic representations.", "labels": [], "entities": []}], "datasetContent": [{"text": "The purpose of our evaluation is to explore the extent to which we can achieve a better balance between parse time and coverage using backbone parsing with pruning compared to the original best-first algorithm.", "labels": [], "entities": [{"text": "parse", "start_pos": 104, "end_pos": 109, "type": "TASK", "confidence": 0.9707366228103638}, {"text": "coverage", "start_pos": 119, "end_pos": 127, "type": "METRIC", "confidence": 0.9719938039779663}, {"text": "backbone parsing", "start_pos": 134, "end_pos": 150, "type": "TASK", "confidence": 0.5890524089336395}]}, {"text": "For our comparison we used an excerpt from the Monroe corpus that has been used in previous TRIPS research on parsing speed and accuracy) consisting of dialogues s2, s4, s16 and s17.", "labels": [], "entities": [{"text": "Monroe corpus", "start_pos": 47, "end_pos": 60, "type": "DATASET", "confidence": 0.9479427635669708}, {"text": "parsing", "start_pos": 110, "end_pos": 117, "type": "TASK", "confidence": 0.9678331613540649}, {"text": "accuracy", "start_pos": 128, "end_pos": 136, "type": "METRIC", "confidence": 0.9907562136650085}]}, {"text": "Dialogue s2 was a holdout set used for pilot testing and setting parameters.", "labels": [], "entities": []}, {"text": "The other three dialogues were set aside for testing.", "labels": [], "entities": []}, {"text": "Altogether, the test set contained 1042 utterances, ranging from 1 to 45 words in length (mean 5.38 words/utt, st. dev. 5.7 words/utt).", "labels": [], "entities": []}, {"text": "Using our hold-out set, we determined that abeam width of three was an optimal setting.", "labels": [], "entities": []}, {"text": "Thus, we compared TFLEX using abeam width of 3 to three different versions of TRIPS that varied only in terms of the maximum chart size, giving us aversion that is significantly faster than TFLEX overall, one that has parse times that are statistically indistinguishable from TFLEX, and one that is significantly slower.", "labels": [], "entities": []}, {"text": "We show that while lower chart sizes in TRIPS yield speed ups in parse time, they come with a cost in terms of coverage.", "labels": [], "entities": [{"text": "coverage", "start_pos": 111, "end_pos": 119, "type": "METRIC", "confidence": 0.9693589210510254}]}, {"text": "Because our goal is to explore the parse time versus coverage trade-offs of two different parsing architectures, the two evaluation measures that we report are average parse time per sentence and probability of finding at least one parse, the latter being a measure estimating the effect of parse algorithm on parsing coverage.", "labels": [], "entities": [{"text": "average parse time", "start_pos": 160, "end_pos": 178, "type": "METRIC", "confidence": 0.7488519847393036}]}, {"text": "Since the scoring model is the same in TRIPS and TFLEX, then as long as TFLEX can find at least one parse (which happened in all but 1 instances on our held-out set), the set returned will include the one produced by TRIPS.", "labels": [], "entities": [{"text": "TRIPS", "start_pos": 217, "end_pos": 222, "type": "DATASET", "confidence": 0.8949480652809143}]}, {"text": "We spot-checked the TFLEX utterances in the test set for which TRIPS could not find a parse to verify that the parses produced were reasonable.", "labels": [], "entities": [{"text": "TFLEX utterances in the test set", "start_pos": 20, "end_pos": 52, "type": "DATASET", "confidence": 0.6464776396751404}, {"text": "TRIPS", "start_pos": 63, "end_pos": 68, "type": "METRIC", "confidence": 0.5957529544830322}]}, {"text": "The parses produced by TFLEX on these sentences were typically acceptable, with errors mainly stemming from attachment disambiguation problems.", "labels": [], "entities": [{"text": "attachment disambiguation", "start_pos": 108, "end_pos": 133, "type": "TASK", "confidence": 0.6837551295757294}]}], "tableCaptions": [{"text": " Table 1: The average parse times for TRIPS and  TFLEX on utterances 6 words or more.", "labels": [], "entities": [{"text": "TRIPS", "start_pos": 38, "end_pos": 43, "type": "METRIC", "confidence": 0.9169264435768127}, {"text": "TFLEX", "start_pos": 49, "end_pos": 54, "type": "METRIC", "confidence": 0.9318209290504456}]}]}