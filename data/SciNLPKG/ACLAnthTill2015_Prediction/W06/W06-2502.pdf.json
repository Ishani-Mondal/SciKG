{"title": [{"text": "Cluster Stopping Rules for Word Sense Discrimination", "labels": [], "entities": [{"text": "Cluster Stopping", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7051661908626556}, {"text": "Word Sense Discrimination", "start_pos": 27, "end_pos": 52, "type": "TASK", "confidence": 0.7786356310049692}]}], "abstractContent": [{"text": "As text data becomes plentiful, unsuper-vised methods for Word Sense Disam-biguation (WSD) become more viable.", "labels": [], "entities": [{"text": "Word Sense Disam-biguation (WSD)", "start_pos": 58, "end_pos": 90, "type": "TASK", "confidence": 0.7434939990441004}]}, {"text": "A problem encountered in applying WSD methods is finding the exact number of senses an ambiguity has in a training corpus collected in an automated manner.", "labels": [], "entities": [{"text": "WSD", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.9879928827285767}]}, {"text": "That number is not known a priori; rather it needs to be determined based on the data itself.", "labels": [], "entities": []}, {"text": "We address that problem using cluster stopping methods.", "labels": [], "entities": [{"text": "cluster stopping", "start_pos": 30, "end_pos": 46, "type": "TASK", "confidence": 0.8392080068588257}]}, {"text": "Such techniques have not previously applied to WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 47, "end_pos": 50, "type": "TASK", "confidence": 0.9591339826583862}]}, {"text": "We implement the methods of Calinski and Harabasz (1975) and Harti-gan (1975) and our adaptation of the Gap statistic (Tibshirani, Walter and Hastie, 2001).", "labels": [], "entities": []}, {"text": "For evaluation, we use the WSD Test Set from the National Library of Medicine, whose sense inventory is the Unified Medical Language System.", "labels": [], "entities": [{"text": "WSD Test Set from the National Library of Medicine", "start_pos": 27, "end_pos": 77, "type": "DATASET", "confidence": 0.8184536298116049}]}, {"text": "The best accuracy for selecting the correct number of clusters is 0.60 with the C&H method.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9994783997535706}, {"text": "C&H", "start_pos": 80, "end_pos": 83, "type": "DATASET", "confidence": 0.8148077726364136}]}, {"text": "Our error analysis shows that the cluster stopping methods make finer-grained sense distinctions by creating additional clusters.", "labels": [], "entities": [{"text": "cluster stopping", "start_pos": 34, "end_pos": 50, "type": "TASK", "confidence": 0.8514030873775482}]}, {"text": "The highest F-scores (82.89), indicative of the quality of cluster membership assignment, are comparable to the baseline majority sense (82.63) and point to a path towards accuracy improvement via additional cluster pruning.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9969668984413147}, {"text": "accuracy", "start_pos": 172, "end_pos": 180, "type": "METRIC", "confidence": 0.9984211921691895}]}, {"text": "The importance and significance of the current work is in applying cluster stopping rules to WSD.", "labels": [], "entities": [{"text": "cluster stopping", "start_pos": 67, "end_pos": 83, "type": "TASK", "confidence": 0.9090493619441986}, {"text": "WSD", "start_pos": 93, "end_pos": 96, "type": "TASK", "confidence": 0.8998412489891052}]}], "introductionContent": [{"text": "The dominant approach in word sense disambiguation (WSD) is based on supervised learning from manually sense-tagged text.", "labels": [], "entities": [{"text": "word sense disambiguation (WSD)", "start_pos": 25, "end_pos": 56, "type": "TASK", "confidence": 0.8525258302688599}]}, {"text": "While this is effective, it is quite difficult to get a sufficient number of manually sense-tagged examples to train a system.", "labels": [], "entities": []}, {"text": "estimates that 80-person years of annotation would be needed to create training corpora for 20,000 ambiguous English words, given 500 instances per word.", "labels": [], "entities": []}, {"text": "For that reason, we are developing unsupervised knowledge-lean methods that avoid the bottlenecks created by sense-tagged text.", "labels": [], "entities": []}, {"text": "Unsupervised clustering methods utilize only raw corpora as their source of information, and there are growing amounts of general and specialized domain corpora available, e.g. biomedical domain corpora.", "labels": [], "entities": []}, {"text": "Improvements in WSD methods would be of immediate value in indexing and retrievals of biomedical text given the explosion of biomedical literature as well as the rapid deployment of electronic medical records.", "labels": [], "entities": [{"text": "WSD", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.9576792120933533}, {"text": "indexing and retrievals of biomedical text", "start_pos": 59, "end_pos": 101, "type": "TASK", "confidence": 0.7692511677742004}]}, {"text": "Semantic/conceptual indexing and retrieval in that domain is often done in regard to the Unified Medical Language System (UMLS) developed at the National Library of Medicine (NLM) at the United States National Institutes of Health (NIH) . It is important to understand that the UMLS is significantly different than a dictionary, which is often the source of the sense inventory.", "labels": [], "entities": [{"text": "Semantic/conceptual indexing", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.742636501789093}]}, {"text": "Rather, the UMLS integrates more than 100 medical domain controlled vocabularies such as SNOMED-CT 2 and the International Classification of Diseases (ICD) . UMLS has three main components.", "labels": [], "entities": [{"text": "International Classification of Diseases (ICD)", "start_pos": 109, "end_pos": 155, "type": "DATASET", "confidence": 0.7787190335137504}]}, {"text": "The first component, the Metathesaurus, includes all terms from the controlled vocabularies and is organized by concept, which is a cluster of terms representing the same meaning.", "labels": [], "entities": [{"text": "Metathesaurus", "start_pos": 25, "end_pos": 38, "type": "DATASET", "confidence": 0.9162440299987793}]}, {"text": "Each concept is assigned a concept unique identifier (CUI), which is inherited by each term in the cluster.", "labels": [], "entities": []}, {"text": "UMLS-based semantic indexing is based on CUI assignments.", "labels": [], "entities": [{"text": "UMLS-based semantic indexing", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7555357813835144}]}, {"text": "The second component, the Semantic Network, groups the concepts into 134 types of categories and indicates the relationships between them.", "labels": [], "entities": []}, {"text": "The Semantic Network is a coarse ontology of the concepts.", "labels": [], "entities": []}, {"text": "The third component, the SPECIALIST lexicon, contains syntactic information for the Metathesaurus terms.", "labels": [], "entities": [{"text": "Metathesaurus terms", "start_pos": 84, "end_pos": 103, "type": "DATASET", "confidence": 0.9148260056972504}]}, {"text": "MeSH, an ontology within UMLS, is heavily used for indexing biomedical scientific publications, e.g. Medline . Hospitals, medical practices and biomedical research increasingly rely on the UMLS, or a subset ontology within it, to index and retrieve relevant information.", "labels": [], "entities": [{"text": "MeSH", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.839344322681427}, {"text": "UMLS", "start_pos": 25, "end_pos": 29, "type": "DATASET", "confidence": 0.8802179098129272}, {"text": "indexing biomedical scientific publications", "start_pos": 51, "end_pos": 94, "type": "TASK", "confidence": 0.8255966156721115}, {"text": "Medline", "start_pos": 101, "end_pos": 108, "type": "DATASET", "confidence": 0.9790322780609131}]}, {"text": "It is estimated that approximately 7400 UMLS terms map to multiple concepts which creates ambiguity).", "labels": [], "entities": []}, {"text": "Term ambiguity has been pointed out to be one of the major challenges for UMLS-based semantic indexing and retrieval).", "labels": [], "entities": [{"text": "UMLS-based semantic indexing and retrieval", "start_pos": 74, "end_pos": 116, "type": "TASK", "confidence": 0.7082252502441406}]}, {"text": "For example, \"cold\" has the following six UMLS meanings, each with its own UMLS CUI: cold temperature, common cold, cold sensation, cold therapy, chronic obstructive lung disease (COLD), and Cold brand of chlorpheniraminephenylpropanolamine.", "labels": [], "entities": [{"text": "UMLS CUI", "start_pos": 75, "end_pos": 83, "type": "DATASET", "confidence": 0.7558457851409912}]}, {"text": "The problem we are addressing in this paper is discovering the number of senses an ambiguous word has in a given corpus, which is a component within a completely unsupervised WSD system.", "labels": [], "entities": [{"text": "WSD", "start_pos": 175, "end_pos": 178, "type": "TASK", "confidence": 0.9004030823707581}]}, {"text": "For example, if a corpus of 1000 instances containing the word \"cold\" has been compiled from patients medical records, how many \"cold\" senses are in that corpus?", "labels": [], "entities": []}, {"text": "This is a challenge any NLP system implementing WSD faces.", "labels": [], "entities": []}, {"text": "To address this problem, we apply cluster stopping rules in an automated way.", "labels": [], "entities": [{"text": "cluster stopping", "start_pos": 34, "end_pos": 50, "type": "TASK", "confidence": 0.880740225315094}]}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 overviews the related work on cluster stopping rules.", "labels": [], "entities": [{"text": "cluster stopping rules", "start_pos": 40, "end_pos": 62, "type": "TASK", "confidence": 0.946510116259257}]}, {"text": "Section 3 outlines our methods, tools, features selection, test set and evaluation metrics.", "labels": [], "entities": []}, {"text": "Section 4 presents the results and discusses them.", "labels": [], "entities": []}, {"text": "Section 5 is the conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our evaluation of the performance of the cluster stopping rules is two-fold.", "labels": [], "entities": [{"text": "cluster stopping", "start_pos": 41, "end_pos": 57, "type": "TASK", "confidence": 0.8539175987243652}]}, {"text": "Accuracy is a direct evaluation measuring the correctly recognized number of senses: words with correctly predicted number of senses all words Accuracy evaluates how well the methods discover the exact number of senses in the test corpus.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9862635135650635}, {"text": "Accuracy", "start_pos": 143, "end_pos": 151, "type": "METRIC", "confidence": 0.9764421582221985}]}, {"text": "The F-score of the WSD is an indirect evaluation for the quality of the cluster assignment: Precision is the number of correctly clustered instances divided by the number of clustered instances; Recall is the number of correctly clustered instances divided by all instances.", "labels": [], "entities": [{"text": "F-score", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.9973887801170349}, {"text": "WSD", "start_pos": 19, "end_pos": 22, "type": "TASK", "confidence": 0.5794274210929871}, {"text": "Precision", "start_pos": 92, "end_pos": 101, "type": "METRIC", "confidence": 0.9973670840263367}, {"text": "Recall", "start_pos": 195, "end_pos": 201, "type": "METRIC", "confidence": 0.9970856308937073}]}, {"text": "There maybe some number of contexts that the clustering algorithm declines to process, which leads to the difference in precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 120, "end_pos": 129, "type": "METRIC", "confidence": 0.999338686466217}, {"text": "recall", "start_pos": 134, "end_pos": 140, "type": "METRIC", "confidence": 0.9981226325035095}]}, {"text": "For the Hartigan cluster stopping method, the threshold is set to 10 which is the recommendation in the original algorithm.", "labels": [], "entities": [{"text": "cluster stopping", "start_pos": 17, "end_pos": 33, "type": "TASK", "confidence": 0.7866290509700775}]}, {"text": "For the Gap cluster stopping method, we experiment with B=100, and the uniform and proportional reference generation methods.", "labels": [], "entities": [{"text": "Gap cluster stopping", "start_pos": 8, "end_pos": 28, "type": "TASK", "confidence": 0.6460823118686676}, {"text": "B", "start_pos": 56, "end_pos": 57, "type": "METRIC", "confidence": 0.996969997882843}]}, {"text": "Our baseline is a simple clustering algorithm that assigns all instances of a target word to a single cluster.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Observed data (sample)  reference data, the row marginals of the refer- ence data are fixed to be equal to those of the  observed data. In", "labels": [], "entities": []}, {"text": " Table 3: Results -accuracy, F-score and predicted average number of sense", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9779175519943237}, {"text": "F-score", "start_pos": 29, "end_pos": 36, "type": "METRIC", "confidence": 0.9990367889404297}, {"text": "predicted average number of sense", "start_pos": 41, "end_pos": 74, "type": "METRIC", "confidence": 0.8886693477630615}]}]}