{"title": [{"text": "Empirical Study on the Performance Stability of Named Entity Recognition Model across Domains", "labels": [], "entities": [{"text": "Named Entity Recognition", "start_pos": 48, "end_pos": 72, "type": "TASK", "confidence": 0.6393483479817709}]}], "abstractContent": [{"text": "When a machine learning-based named entity recognition system is employed in anew domain, its performance usually degrades.", "labels": [], "entities": [{"text": "machine learning-based named entity recognition", "start_pos": 7, "end_pos": 54, "type": "TASK", "confidence": 0.6241794347763061}]}, {"text": "In this paper, we provide an empirical study on the impact of training data size and domain information on the performance stability of named entity recognition models.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 136, "end_pos": 160, "type": "TASK", "confidence": 0.7025068998336792}]}, {"text": "We present an informative sample selection method for building high quality and stable named entity recognition models across domains.", "labels": [], "entities": []}, {"text": "Experimental results show that the performance of the named entity recognition model is enhanced significantly after being trained with these informative samples.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 54, "end_pos": 78, "type": "TASK", "confidence": 0.6387145121892294}]}], "introductionContent": [{"text": "Named entities (NE) are phrases that contain names of persons, organizations, locations, etc.", "labels": [], "entities": [{"text": "Named entities (NE) are phrases that contain names of persons, organizations, locations", "start_pos": 0, "end_pos": 87, "type": "TASK", "confidence": 0.640290342271328}]}, {"text": "Named entity recognition (NER) is an important task in many natural language processing applications, such as information extraction and machine translation.", "labels": [], "entities": [{"text": "Named entity recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8154518902301788}, {"text": "information extraction", "start_pos": 110, "end_pos": 132, "type": "TASK", "confidence": 0.8295629322528839}, {"text": "machine translation", "start_pos": 137, "end_pos": 156, "type": "TASK", "confidence": 0.7864255905151367}]}, {"text": "There have been a number of conferences aimed at evaluating NER systems, for example, MUC6, MUC7, CoNLL2002 and CoNLL2003, and ACE (automatic content extraction) evaluations.", "labels": [], "entities": [{"text": "NER", "start_pos": 60, "end_pos": 63, "type": "TASK", "confidence": 0.9496099352836609}, {"text": "MUC6", "start_pos": 86, "end_pos": 90, "type": "DATASET", "confidence": 0.8605684041976929}, {"text": "MUC7", "start_pos": 92, "end_pos": 96, "type": "DATASET", "confidence": 0.8080180287361145}, {"text": "ACE (automatic content extraction)", "start_pos": 127, "end_pos": 161, "type": "TASK", "confidence": 0.5725234895944595}]}, {"text": "Machine learning approaches are becoming more attractive for NER in recent years since they are trainable and adaptable.", "labels": [], "entities": [{"text": "NER", "start_pos": 61, "end_pos": 64, "type": "TASK", "confidence": 0.9634143710136414}]}, {"text": "Recent research on English NER has focused on the machine learning approach.", "labels": [], "entities": [{"text": "English NER", "start_pos": 19, "end_pos": 30, "type": "TASK", "confidence": 0.5403701364994049}]}, {"text": "The relevant algorithms include Maximum Entropy, Hidden Markov Model (HMM) (), AdaBoost (, Memorybased learning, Support Vector Machine (), Robust Risk Minimization (RRM) Classification method ( , etc.", "labels": [], "entities": [{"text": "Robust Risk Minimization (RRM) Classification", "start_pos": 140, "end_pos": 185, "type": "TASK", "confidence": 0.7891881849084582}]}, {"text": "For Chinese NER, most of the existing approaches use hand-crafted rules with word (or character) frequency statistics.", "labels": [], "entities": [{"text": "Chinese NER", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.4714557081460953}]}, {"text": "Some machine learning algorithms also have been investigated in Chinese NER, including HMM (, class-based language model (), RRM (, etc.", "labels": [], "entities": []}, {"text": "However, when a machine learning-based NER system is directly employed in anew domain, its performance usually degrades.", "labels": [], "entities": []}, {"text": "In order to avoid the performance degrading, the NER model is often retrained with domain-specific annotated corpus.", "labels": [], "entities": []}, {"text": "This retraining process usually needs more efforts and costs.", "labels": [], "entities": []}, {"text": "In order to enhance the performance stability of NER models with less efforts, some issues have to be considered in practice.", "labels": [], "entities": [{"text": "NER", "start_pos": 49, "end_pos": 52, "type": "TASK", "confidence": 0.9649620652198792}]}, {"text": "For example, how much training data is enough for building a stable and applicable NER model?", "labels": [], "entities": []}, {"text": "How does the domain information and training data size impact the NER performance?", "labels": [], "entities": [{"text": "NER", "start_pos": 66, "end_pos": 69, "type": "TASK", "confidence": 0.9735053777694702}]}, {"text": "This paper provides an empirical study on the impact of training data size and domain information on NER performance.", "labels": [], "entities": [{"text": "NER", "start_pos": 101, "end_pos": 104, "type": "TASK", "confidence": 0.9891566038131714}]}, {"text": "Some useful observations are obtained from the experimental results on a large-scale annotated corpus.", "labels": [], "entities": []}, {"text": "Experimental results show that it is difficult to significantly enhance the performance when the training data size is above a certain threshold.", "labels": [], "entities": []}, {"text": "The threshold of the training data size varies with domains.", "labels": [], "entities": []}, {"text": "The performance stability of each NE type recognition also varies with domains.", "labels": [], "entities": [{"text": "NE type recognition", "start_pos": 34, "end_pos": 53, "type": "TASK", "confidence": 0.8160536289215088}]}, {"text": "Corpus statistical data show that NE types have different distribution across domains.", "labels": [], "entities": []}, {"text": "Based on the empirical investigations, we present an informative sample selection method for building high quality and stable NER models.", "labels": [], "entities": [{"text": "NER", "start_pos": 126, "end_pos": 129, "type": "TASK", "confidence": 0.9735952019691467}]}, {"text": "Experimental results show that the performance of the NER model is enhanced significantly across domains after being trained with these informative samples.", "labels": [], "entities": [{"text": "NER", "start_pos": 54, "end_pos": 57, "type": "TASK", "confidence": 0.9794841408729553}]}, {"text": "In spite of our focus on Chinese, we believe that some of our observations can be potentially useful to other languages including English.", "labels": [], "entities": []}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes a Chinese NER system using multi-level linguistic features.", "labels": [], "entities": [{"text": "NER", "start_pos": 30, "end_pos": 33, "type": "TASK", "confidence": 0.7174333930015564}]}, {"text": "Section 3 discusses the impact of domain information and training data size on the NER performance.", "labels": [], "entities": [{"text": "NER", "start_pos": 83, "end_pos": 86, "type": "TASK", "confidence": 0.9569482207298279}]}, {"text": "Section 4 presents an informative sample selection method to enhance the performance of the NER model across domains.", "labels": [], "entities": [{"text": "NER", "start_pos": 92, "end_pos": 95, "type": "TASK", "confidence": 0.9465212225914001}]}, {"text": "Finally the conclusion is given in Section 5.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: NE distribution in the general and  domain-specific test data sets", "labels": [], "entities": []}, {"text": " Table 2: Performance of NER models, size thresh- old and NE distribution in the corresponding train- ing data sets", "labels": [], "entities": [{"text": "NE distribution", "start_pos": 58, "end_pos": 73, "type": "METRIC", "confidence": 0.9169570505619049}]}, {"text": " Table 3: NE distribution in the Chinese annotated  corpus", "labels": [], "entities": [{"text": "Chinese annotated  corpus", "start_pos": 33, "end_pos": 58, "type": "DATASET", "confidence": 0.8446537653605143}]}, {"text": " Table 4. The performance curves of the general  model are shown in", "labels": [], "entities": []}, {"text": " Table 4: Performance of the general NER model  in specific domains", "labels": [], "entities": [{"text": "NER", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.9751253128051758}]}, {"text": " Table 5: Performance of NER models in specific  domains", "labels": [], "entities": [{"text": "NER", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.9812198281288147}]}, {"text": " Table 6: Performance of informative model and  random model in the general domain", "labels": [], "entities": []}, {"text": " Table 7: Performance of the general informative  model in specific domains", "labels": [], "entities": []}, {"text": " Table 8: Performance comparison of informa- tive model, random model and the corresponding  domain-specific model in each specific domain", "labels": [], "entities": []}]}