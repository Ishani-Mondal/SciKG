{"title": [{"text": "Probing the space of grammatical variation: induction of cross-lingual grammatical constraints from treebanks", "labels": [], "entities": []}], "abstractContent": [{"text": "The paper reports on a detailed quantitative analysis of distributional language data of both Italian and Czech, highlighting the relative contribution of a number of distributed grammatical factors to sentence-based identification of subjects and direct objects.", "labels": [], "entities": [{"text": "sentence-based identification of subjects and direct objects", "start_pos": 202, "end_pos": 262, "type": "TASK", "confidence": 0.7703854526792254}]}, {"text": "The work uses a Maximum Entropy model of stochastic resolution of conflicting grammatical constraints and is demonstrably capable of putting explanatory theoretical accounts to the test of usage-based empirical verification.", "labels": [], "entities": [{"text": "stochastic resolution of conflicting grammatical constraints", "start_pos": 41, "end_pos": 101, "type": "TASK", "confidence": 0.8635785380999247}]}], "introductionContent": [{"text": "The paper illustrates the application of a Maximum Entropy (henceforth MaxEnt) model) to the processing of subjects and direct objects in Italian and Czech.", "labels": [], "entities": []}, {"text": "The model makes use of richly annotated Treebanks to determine the types of linguistic factors involved in the task and weigh up their relative salience.", "labels": [], "entities": []}, {"text": "In doing so, we set ourselves a twofold goal.", "labels": [], "entities": []}, {"text": "On the one hand, we intend to discuss the use of Treebanks to discover typologically relevant and linguistically motivated factors and assess the relative contribution of the latter to cross-linguistic parsing issues.", "labels": [], "entities": [{"text": "cross-linguistic parsing", "start_pos": 185, "end_pos": 209, "type": "TASK", "confidence": 0.8170972466468811}]}, {"text": "On the other hand, we are interested in testing the empirical plausibility of constraint-resolution models of language processing (see infra) when confronted with real language data.", "labels": [], "entities": []}, {"text": "Current research in natural language learning and processing supports the view that grammatical competence consists in mastering and integrating multiple, parallel constraints (Seidenberg and).", "labels": [], "entities": [{"text": "natural language learning and processing", "start_pos": 20, "end_pos": 60, "type": "TASK", "confidence": 0.663103973865509}]}, {"text": "Moreover, there is growing consensus on two major properties of grammatical constraints: i.) they are probabilistic \"soft constraints\", and ii.) they have an inherently functional nature, involving different types of linguistic (and non linguistic) information (syntactic, semantic, etc.).", "labels": [], "entities": []}, {"text": "These features emerge particularly clearly in dealing with one of the core aspects of grammar learning: the ability to identify syntactic relations in text.", "labels": [], "entities": []}, {"text": "Psycholinguistic evidence shows that speakers learn to identify sentence subjects and direct objects by combining various types of probabilistic, functional cues, such as word order, noun animacy, definiteness, agreement, etc.", "labels": [], "entities": []}, {"text": "An important observation is that the relative prominence of each such cue can considerably vary cross-linguistically., for example, argue that while, in English, word order is the most effective cue for Subject-Object Identification (henceforth SOI) both in syntactic processing and during the child's syntactic development, the same cue plays second fiddle in relatively free phrase-order languages such as Italian or German.", "labels": [], "entities": [{"text": "Subject-Object Identification (henceforth SOI)", "start_pos": 203, "end_pos": 249, "type": "TASK", "confidence": 0.8063691904147466}]}, {"text": "If grammatical constraints are inherently probabilistic, the path through which adult grammar competence is acquired can be viewed as the process of building a stochastic model out of the linguistic input.", "labels": [], "entities": []}, {"text": "In computational linguistics, MaxEnt models have proven to be robust statistical learning algorithms that perform well in a number of processing tasks.", "labels": [], "entities": []}, {"text": "Being supervised learning models, they require richly annotated data as training input.", "labels": [], "entities": []}, {"text": "Before we turn to the use of Treebanks for training a MaxEnt model for SOI, we first analyse the range of linguistic factors that are taken to play a significant role in the task.", "labels": [], "entities": [{"text": "SOI", "start_pos": 71, "end_pos": 74, "type": "TASK", "confidence": 0.9730129241943359}]}], "datasetContent": [], "tableCaptions": []}