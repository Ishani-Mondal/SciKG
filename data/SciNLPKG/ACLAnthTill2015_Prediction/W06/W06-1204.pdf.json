{"title": [{"text": "Using Information about Multi-word Expressions for the Word-Alignment Task", "labels": [], "entities": []}], "abstractContent": [{"text": "It is well known that multi-word expressions are problematic in natural language processing.", "labels": [], "entities": []}, {"text": "In previous literature, it has been suggested that information about their degree of compositionality can be helpful in various applications but it has not been proven empirically.", "labels": [], "entities": []}, {"text": "In this paper , we propose a framework in which information about the multi-word expressions can be used in the word-alignment task.", "labels": [], "entities": []}, {"text": "We have shown that even simple features like point-wise mutual information are useful for word-alignment task in English-Hindi parallel corpora.", "labels": [], "entities": []}, {"text": "The alignment error rate which we achieve (AER = 0.5040) is significantly better (about 10% decrease in AER) than the alignment error rates of the state-of-art models (Och and Ney, 2003) (Best AER = 0.5518) on the English-Hindi dataset.", "labels": [], "entities": [{"text": "alignment error rate", "start_pos": 4, "end_pos": 24, "type": "METRIC", "confidence": 0.9453807671864828}, {"text": "AER", "start_pos": 43, "end_pos": 46, "type": "METRIC", "confidence": 0.9993153810501099}, {"text": "AER", "start_pos": 104, "end_pos": 107, "type": "METRIC", "confidence": 0.9994868040084839}, {"text": "AER", "start_pos": 193, "end_pos": 196, "type": "METRIC", "confidence": 0.8540987968444824}, {"text": "English-Hindi dataset", "start_pos": 214, "end_pos": 235, "type": "DATASET", "confidence": 0.7425065189599991}]}], "introductionContent": [{"text": "In this paper, we show that measures representing compositionality of multi-word expressions can be useful for tasks such as Machine Translation, word-alignment to be specific here.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 125, "end_pos": 144, "type": "TASK", "confidence": 0.8830327391624451}]}, {"text": "We use an online learning framework called MIRA for training a discriminative model for the word alignment task).", "labels": [], "entities": [{"text": "word alignment task", "start_pos": 92, "end_pos": 111, "type": "TASK", "confidence": 0.8016103108723959}]}, {"text": "The discriminative model makes use of features which represent the compositionality of multi-word expressions.", "labels": [], "entities": []}, {"text": "Multi-word expressions (MWEs) are those whose structure and meaning cannot be derived from their component words, as they occur independently.", "labels": [], "entities": [{"text": "Multi-word expressions (MWEs)", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.6672746658325195}]}, {"text": "Examples include conjunctions such as 'as well as' (meaning 'including'), idioms like 'kick the bucket' (meaning 'die') phrasal verbs such as 'find out' (meaning 'search') and compounds like 'village community'.", "labels": [], "entities": []}, {"text": "They can be defined roughly as idiosyncratic interpretations that crossword boundaries (.", "labels": [], "entities": []}, {"text": "A large number of MWEs have standard syntactic structure but are semantically noncompositional.", "labels": [], "entities": []}, {"text": "Here, we consider the class of verb based expressions (verb is the head of the phrase), which occur very frequently.", "labels": [], "entities": []}, {"text": "This class of verb based multi-word expressions include verbal idioms, support-verb constructions, among others.", "labels": [], "entities": []}, {"text": "The example 'take place' is a MWE but 'take a gift' is not.", "labels": [], "entities": []}, {"text": "In the past, various measures have been suggested for measuring the compositionality of multi-word expressions.", "labels": [], "entities": []}, {"text": "Some of these are mutual information, distributed frequency) and Latent Semantic Analysis (LSA) model (.", "labels": [], "entities": [{"text": "Latent Semantic Analysis (LSA)", "start_pos": 65, "end_pos": 95, "type": "TASK", "confidence": 0.6843490302562714}]}, {"text": "Even though, these measures have been shown to represent compositionality quite well, compositionality itself has not been shown to be useful in any application yet.", "labels": [], "entities": []}, {"text": "In this paper, we explore this possibility of using the information about compositionality of MWEs (verb based) for the word alignment task.", "labels": [], "entities": [{"text": "word alignment task", "start_pos": 120, "end_pos": 139, "type": "TASK", "confidence": 0.8225691119829813}]}, {"text": "In this preliminary work, we use simple measures (such as point-wise mutual information) to measure compositionality.", "labels": [], "entities": []}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "In section 2, we discuss the word-alignment task with respect to the class of multi-word expressions of interest in this paper.", "labels": [], "entities": []}, {"text": "In section 3, we show empirically, the behavior of verb based expressions in a parallel corpus (English-Hindi in our case).", "labels": [], "entities": []}, {"text": "We then discuss our alignment algorithm in section 4.", "labels": [], "entities": [{"text": "alignment", "start_pos": 20, "end_pos": 29, "type": "TASK", "confidence": 0.9653007984161377}]}, {"text": "In section 5, we describe the features which we have used in our training model.", "labels": [], "entities": []}, {"text": "Section 6 discusses the training algorithm and in section 7, the results of our discriminative model for the word alignment task.", "labels": [], "entities": [{"text": "word alignment task", "start_pos": 109, "end_pos": 128, "type": "TASK", "confidence": 0.846253236134847}]}, {"text": "Related work and conclusion follow in section 8 and 9 respectively.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have divided the 400 word aligned sentence pairs into a training set consisting of 294 sentence pairs and a test set consisting of 106 sentence pairs.", "labels": [], "entities": []}, {"text": "The source sentences are all dependency parsed) and only the verb and its dependents are considered for both training and testing our algorithm.", "labels": [], "entities": []}, {"text": "Our training algorithm requires that the each of the source words is aligned to only one or zero target words.", "labels": [], "entities": []}, {"text": "For this, we use simple heuristics to convert the training data to the appropriate format.", "labels": [], "entities": []}, {"text": "For the words aligned to a source verb, the first verb is chosen as the gold alignment.", "labels": [], "entities": []}, {"text": "For the words aligned to any dependent which is not a verb, the last content word is chosen as the alignment link.", "labels": [], "entities": []}, {"text": "For test data, we do not make any modifications and the final output from our alignment algorithm is compared with the original test data.", "labels": [], "entities": []}, {"text": "We evaluated our discriminative approach by comparing it with the state-of-art Giza++ alignments.", "labels": [], "entities": []}, {"text": "The metric that we have used to do the comparison is the Alignment Error Rate (AER).", "labels": [], "entities": [{"text": "Alignment Error Rate (AER)", "start_pos": 57, "end_pos": 83, "type": "METRIC", "confidence": 0.9570133785406748}]}, {"text": "The results shown below also contain Precision, Recall and F-measure.", "labels": [], "entities": [{"text": "Precision", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.9990848302841187}, {"text": "Recall", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.9977567791938782}, {"text": "F-measure", "start_pos": 59, "end_pos": 68, "type": "METRIC", "confidence": 0.9964374303817749}]}, {"text": "Giza was trained using an English-Hindi aligned corpus of 50000 sentence pairs.", "labels": [], "entities": []}, {"text": "In., we report the results of the GIZA++ alignments run from both the directions (English to Hindi and Hindi to English).", "labels": [], "entities": [{"text": "GIZA++ alignments", "start_pos": 34, "end_pos": 51, "type": "DATASET", "confidence": 0.707694927851359}]}, {"text": "We also show the results of the intersected model.", "labels": [], "entities": []}, {"text": "See We then lemmatize the words in both the source and target sides of the parallel corpora and then run Giza++ again.", "labels": [], "entities": []}, {"text": "As the English-Hindi dataset of 50000 sentence pairs is relatively small, we expect lemmatizing to improve the results.: Results of GIZA++ -lemmatized set  We trained our model using the training set of 294 word aligned sentence pairs.", "labels": [], "entities": []}, {"text": "For training the parameters, we used abeam size of 3 and number of iterations equal to 3.: Results using the features -AvgDist, Overlap Now, we add the transition probabilities obtained from the experiments with Giza++ as features in our model..", "labels": [], "entities": [{"text": "AvgDist", "start_pos": 119, "end_pos": 126, "type": "METRIC", "confidence": 0.9264591932296753}]}, {"text": "The compositionality related features are now added to our discriminative model to see if there is any improvement in performance.", "labels": [], "entities": []}, {"text": "shows the results by adding one feature at a time.", "labels": [], "entities": []}, {"text": "We observe that there is an improvement in the AER by using the compositionality based features, thus showing that compositionality based features aid in the word-alignment task in a significant way (AER = 0.5045).", "labels": [], "entities": [{"text": "AER", "start_pos": 47, "end_pos": 50, "type": "METRIC", "confidence": 0.9936485886573792}, {"text": "AER", "start_pos": 200, "end_pos": 203, "type": "METRIC", "confidence": 0.9980654120445251}]}], "tableCaptions": [{"text": " Table  1., we report the results of the GIZA++ alignments  run from both the directions (English to Hindi and  Hindi to English). We also show the results of the  intersected model. See", "labels": [], "entities": [{"text": "GIZA++ alignments", "start_pos": 41, "end_pos": 58, "type": "DATASET", "confidence": 0.6999501387278239}]}, {"text": " Table 1. for the results of  the GIZA++ alignments.", "labels": [], "entities": [{"text": "GIZA++ alignments", "start_pos": 34, "end_pos": 51, "type": "DATASET", "confidence": 0.8534070452054342}]}, {"text": " Table 1: Results of GIZA++ -Original dataset", "labels": [], "entities": [{"text": "GIZA++ -Original dataset", "start_pos": 21, "end_pos": 45, "type": "DATASET", "confidence": 0.581093829870224}]}, {"text": " Table 2.  shows the results. As we hoped, the results after  lemmatizing the word forms are better than those  without.", "labels": [], "entities": []}, {"text": " Table 2: Results of GIZA++ -lemmatized set", "labels": [], "entities": []}, {"text": " Table 3. shows the results  when we used only the basic local features (Dice- Words, DiceRoots, Dict and Null) to train and test  our model.", "labels": [], "entities": []}, {"text": " Table 4: Results using the features -AvgDist,  Overlap", "labels": [], "entities": [{"text": "AvgDist", "start_pos": 38, "end_pos": 45, "type": "METRIC", "confidence": 0.8443584442138672}]}, {"text": " Table 5: Results using the Giza++ probabilities", "labels": [], "entities": []}, {"text": " Table 6: Results using the compositionality based  features", "labels": [], "entities": []}]}