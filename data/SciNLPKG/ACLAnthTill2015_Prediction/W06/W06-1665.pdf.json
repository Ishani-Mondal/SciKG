{"title": [{"text": "Context-Dependent Term Relations for Information Retrieval", "labels": [], "entities": [{"text": "Information Retrieval", "start_pos": 37, "end_pos": 58, "type": "TASK", "confidence": 0.7655633091926575}]}], "abstractContent": [{"text": "Co-occurrence analysis has been used to determine related words or terms in many NLP-related applications such as query expansion in Information Retrieval (IR).", "labels": [], "entities": [{"text": "Co-occurrence analysis", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7540276050567627}, {"text": "query expansion in Information Retrieval (IR)", "start_pos": 114, "end_pos": 159, "type": "TASK", "confidence": 0.86701350659132}]}, {"text": "However, related words are usually determined with respect to a single word, without relevant information for its application context.", "labels": [], "entities": []}, {"text": "For example, the word \"programming\" maybe considered to be strongly related to \"Java\", and applied inappropriately to expand a query on \"Java travel\".", "labels": [], "entities": []}, {"text": "To solve this problem, we propose to add another context word in the relation to specify the appropriate context of the relation, leading to term relations of the form \"(Java, travel) \u2192 Indonesia\".", "labels": [], "entities": []}, {"text": "The extracted relations are used for query expansion in IR.", "labels": [], "entities": [{"text": "query expansion", "start_pos": 37, "end_pos": 52, "type": "TASK", "confidence": 0.8396680951118469}, {"text": "IR", "start_pos": 56, "end_pos": 58, "type": "TASK", "confidence": 0.9372639656066895}]}, {"text": "Our experiments on several TREC collections show that this new type of context-dependent relations performs much better than the traditional co-occurrence relations.", "labels": [], "entities": [{"text": "TREC collections", "start_pos": 27, "end_pos": 43, "type": "DATASET", "confidence": 0.7909074425697327}]}], "introductionContent": [{"text": "A query usually is a poor expression of an information need.", "labels": [], "entities": []}, {"text": "This is not only due to its short length (usually a few words), but also due to the inability of users to provide the best terms to describe their information need.", "labels": [], "entities": []}, {"text": "At best, one can expect that some, but not all, relevant terms are used in the query.", "labels": [], "entities": []}, {"text": "Query expansion thus aims to improve query expression by adding related terms to the query.", "labels": [], "entities": [{"text": "Query expansion", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.8759026825428009}, {"text": "query expression", "start_pos": 37, "end_pos": 53, "type": "TASK", "confidence": 0.7327428758144379}]}, {"text": "However, the effect of query expansion is strongly determined by the term relations used.", "labels": [], "entities": [{"text": "query expansion", "start_pos": 23, "end_pos": 38, "type": "TASK", "confidence": 0.7736277282238007}]}, {"text": "For example, even if \"programming\" is strongly related to \"Java\", if this relation is used to expand a query on \"Java travel\", the retrieval result will likely deteriorate because the irrelevant term \"programming\" is introduced, leading to the retrieval of irrelevant documents about \"programming\".", "labels": [], "entities": []}, {"text": "A number of attempts have been made to deal with the problem of selecting appropriate expansion terms.", "labels": [], "entities": []}, {"text": "For example, Wordnet has been used in to determine the expansion terms.", "labels": [], "entities": [{"text": "Wordnet", "start_pos": 13, "end_pos": 20, "type": "DATASET", "confidence": 0.9701799154281616}]}, {"text": "However, the experiments did not show improvement on retrieval effectiveness.", "labels": [], "entities": []}, {"text": "Many experiments have been carried out using associative relations extracted from term cooccurrences; but they showed variable results.", "labels": [], "entities": []}, {"text": "In (, it is observed that one of the reasons is that one tried to determine expansion terms according to each original query term separately, which may introduce much noise.", "labels": [], "entities": []}, {"text": "Therefore, they proposed to determine the expansion terms by summing up the relations of a candidate expansion term to each of the query terms.", "labels": [], "entities": []}, {"text": "In so doing, a candidate expansion term is preferred if it has a strong relationship with many of the query terms.", "labels": [], "entities": []}, {"text": "However, it is still difficult to prevent the expansion process from adding \"programming\" to a query on \"Java travel\" because of its very strong relation with \"Java\".", "labels": [], "entities": []}, {"text": "The approach used in () indeed tries to correct a handicap inherent in the relations: as term relations are created between two single words such as \"Java \u2192 programming\", no information is available to help determine the appropriate context to apply it.", "labels": [], "entities": []}, {"text": "The approach used in ( can simply alleviate the problem without solving it radically.", "labels": [], "entities": []}, {"text": "In this paper, we argue that the solution lies in the relations themselves.", "labels": [], "entities": []}, {"text": "They have to contain more information to help determine the appropriate context to apply them.", "labels": [], "entities": []}, {"text": "We thus propose away to add some context information into the relations: we introduce an additional word into the condition part of the relation, such as \"(Java, computer) \u2192 programming\", which means \"programming\" is related to \"(Java, computer)\" together.", "labels": [], "entities": []}, {"text": "In so doing, we would be able to prevent from extracting and applying a relation such as \"(Java, travel) \u2192 programming\".", "labels": [], "entities": []}, {"text": "In this paper, we will test the extracted relations in query expansion for IR.", "labels": [], "entities": [{"text": "IR", "start_pos": 75, "end_pos": 77, "type": "TASK", "confidence": 0.891247034072876}]}, {"text": "We choose to implement query expansion within the language modeling (LM) framework because of its flexibility and high performance.", "labels": [], "entities": [{"text": "query expansion", "start_pos": 23, "end_pos": 38, "type": "TASK", "confidence": 0.7992144525051117}]}, {"text": "The experiments on several TREC collections will show that our query expansion approach can bring large improvements in retrieval effectiveness.", "labels": [], "entities": [{"text": "TREC collections", "start_pos": 27, "end_pos": 43, "type": "DATASET", "confidence": 0.7452714741230011}, {"text": "query expansion", "start_pos": 63, "end_pos": 78, "type": "TASK", "confidence": 0.7267016768455505}]}, {"text": "In the following sections, we will first review some of the relevant approaches on query expansion and term relation extraction.", "labels": [], "entities": [{"text": "query expansion", "start_pos": 83, "end_pos": 98, "type": "TASK", "confidence": 0.8393659889698029}, {"text": "term relation extraction", "start_pos": 103, "end_pos": 127, "type": "TASK", "confidence": 0.6088224450747172}]}, {"text": "Then we will describe our general IR models and the extraction of term relations.", "labels": [], "entities": [{"text": "IR", "start_pos": 34, "end_pos": 36, "type": "TASK", "confidence": 0.9779471755027771}]}, {"text": "The experimental results will be reported and finally some conclusions will be drawn.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate query expansion with different relations on four TREC collections, which are described in.", "labels": [], "entities": [{"text": "query expansion", "start_pos": 12, "end_pos": 27, "type": "TASK", "confidence": 0.767990916967392}]}, {"text": "All documents have been processed in a standard manner: terms are stemmed using Porter stemmer and stopwords are removed.", "labels": [], "entities": []}, {"text": "We only use titles of topics as queries, which contain 3.58 words per query on average.", "labels": [], "entities": []}, {"text": "242 121,946 74,520 51-100 In our experiments, the document model remains the same while the query model changes.", "labels": [], "entities": []}, {"text": "The document model uses the following Dirichlet smoothing: is the term frequency of w i in D, is the collection model and \u00b5 is the Dirichlet prior, which is set at 1000 following).", "labels": [], "entities": []}, {"text": "There are two other smoothing parameters 1 \u03bb , and \u03bb to be determined.", "labels": [], "entities": []}, {"text": "In our experiments, we use a simple method to set them: the parameters are tuned empirically using a training collection containing AP1989 documents and queries 101-150.", "labels": [], "entities": [{"text": "AP1989 documents", "start_pos": 132, "end_pos": 148, "type": "DATASET", "confidence": 0.9399226009845734}]}, {"text": "These preliminary tests suggest that the best value of \u03bb and 2 \u03bb (in Equations 1-2) are relatively stable (we will show this later).", "labels": [], "entities": []}, {"text": "In the experiments reported below, we will use  The main experimental results are described in, which reports average precision with different methods as well as the number of relevant documents retrieved.", "labels": [], "entities": [{"text": "precision", "start_pos": 118, "end_pos": 127, "type": "METRIC", "confidence": 0.9832736253738403}]}, {"text": "UM is the basic unigram model without query expansion (i.e. we use MLE for the query model, while the document model is smoothed with Dirichlet method).", "labels": [], "entities": [{"text": "UM", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.7926859855651855}, {"text": "MLE", "start_pos": 67, "end_pos": 70, "type": "METRIC", "confidence": 0.8905296921730042}]}, {"text": "CIQE is the context-independent query expansion model using unigram relations (Model 1).", "labels": [], "entities": [{"text": "CIQE", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8809494972229004}]}, {"text": "CDQE is the context-dependent query expansion model using biterm relations (Model 2).", "labels": [], "entities": [{"text": "CDQE", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9079774022102356}, {"text": "query expansion", "start_pos": 30, "end_pos": 45, "type": "TASK", "confidence": 0.66327965259552}]}, {"text": "In the table, we also indicate whether the improvement in average precision obtained is statistically significant (t-test).", "labels": [], "entities": [{"text": "precision", "start_pos": 66, "end_pos": 75, "type": "METRIC", "confidence": 0.8591195940971375}]}], "tableCaptions": [{"text": " Table 1. All documents have been  processed in a standard manner: terms are  stemmed using Porter stemmer and stopwords are  removed. We only use titles of topics as queries,  which contain 3.58 words per query on average.", "labels": [], "entities": []}, {"text": " Table 1. TREC collection statistics", "labels": [], "entities": [{"text": "TREC collection", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.5119214206933975}]}, {"text": " Table 2. Avg. precision and Recall", "labels": [], "entities": [{"text": "Avg", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.7714259028434753}, {"text": "precision", "start_pos": 15, "end_pos": 24, "type": "METRIC", "confidence": 0.9512372016906738}, {"text": "Recall", "start_pos": 29, "end_pos": 35, "type": "METRIC", "confidence": 0.9935694932937622}]}, {"text": " Table 3. Cross-utilization of relations", "labels": [], "entities": []}]}