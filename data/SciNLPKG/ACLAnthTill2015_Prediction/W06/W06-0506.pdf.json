{"title": [{"text": "Taxonomy Learning using Term Specificity and Similarity", "labels": [], "entities": [{"text": "Similarity", "start_pos": 45, "end_pos": 55, "type": "TASK", "confidence": 0.4990141689777374}]}], "abstractContent": [{"text": "Learning taxonomy for technical terms is difficult and tedious task, especially when new terms should be included.", "labels": [], "entities": []}, {"text": "The goal of this paper is to assign taxonomic relations among technical terms.", "labels": [], "entities": []}, {"text": "We propose new approach to the problem that relies on term specificity and similarity measures.", "labels": [], "entities": []}, {"text": "Term specificity and similarity are necessary conditions for taxonomy learning, because highly specific terms tend to locate in deep levels and semantically similar terms are close to each other in taxonomy.", "labels": [], "entities": [{"text": "Term specificity", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7644443213939667}, {"text": "taxonomy learning", "start_pos": 61, "end_pos": 78, "type": "TASK", "confidence": 0.8885584771633148}]}, {"text": "We analyzed various features used in previous researches in view of term specificity and similarity, and applied optimal features for term specificity and similarity to our method.", "labels": [], "entities": []}], "introductionContent": [{"text": "Taxonomy is a collection of controlled vocabulary terms organized into a hierarchical structure.", "labels": [], "entities": []}, {"text": "Each term in a taxonomy is one or more parentchild relationships to other terms in the taxonomy.", "labels": [], "entities": []}, {"text": "Taxonomies are useful artifacts for organizing many aspects of knowledge.", "labels": [], "entities": []}, {"text": "As components of ontologies, taxonomies can provide an organizational model fora domain (domain ontology), or a model suitable for specific tasks (task ontologies)).", "labels": [], "entities": []}, {"text": "However their wide usage is still hindered by time-consuming, cost-ineffective building processes.", "labels": [], "entities": []}, {"text": "The main paradigms of taxonomy learning are on the one hand pattern based approaches and on the other hand distributional hypothesis based approaches.", "labels": [], "entities": [{"text": "taxonomy learning", "start_pos": 22, "end_pos": 39, "type": "TASK", "confidence": 0.9035274982452393}]}, {"text": "The former is approaches based on matching lexico-syntactic patterns which convey taxonomic relations in a corpus, and the latter is statistical approaches based on the distribution of context in corpus ().", "labels": [], "entities": []}, {"text": "The former features a high precision and low recall compared to the latter.", "labels": [], "entities": [{"text": "precision", "start_pos": 27, "end_pos": 36, "type": "METRIC", "confidence": 0.9995619654655457}, {"text": "recall", "start_pos": 45, "end_pos": 51, "type": "METRIC", "confidence": 0.9996029734611511}]}, {"text": "The quality of learned relations is higher than those of statistical approaches, while the patterns are rarely applied in real corpus.", "labels": [], "entities": []}, {"text": "It is also difficult to improve performance of pattern based approaches because they are simple and clear.", "labels": [], "entities": []}, {"text": "So, many researches have been focused on raising precision of statistical approaches.", "labels": [], "entities": [{"text": "precision", "start_pos": 49, "end_pos": 58, "type": "METRIC", "confidence": 0.9988168478012085}]}, {"text": "We introduce new distributional hypothesis based taxonomy learning method using term specificity and term similarity.", "labels": [], "entities": []}, {"text": "Term specificity is a measure of information quantity of terms in given domain.", "labels": [], "entities": [{"text": "Term specificity", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.9485098123550415}]}, {"text": "When a term has much domain information, the term is highly specific to the domain, and vice versa).", "labels": [], "entities": []}, {"text": "Because highly specific terms tend to locate in low level in domain taxonomy, term specificity can be used as a necessary condition for taxonomy learning.", "labels": [], "entities": []}, {"text": "Term similarity is degree of semantic overlap among terms.", "labels": [], "entities": [{"text": "Term similarity", "start_pos": 0, "end_pos": 15, "type": "METRIC", "confidence": 0.5931410789489746}]}, {"text": "When two terms share many common characteristics, they are semantically similar to each other.", "labels": [], "entities": []}, {"text": "Term similarity can be another necessary condition for taxonomy learning, because semantically similar terms locate nearby in given domain taxonomy.", "labels": [], "entities": [{"text": "taxonomy learning", "start_pos": 55, "end_pos": 72, "type": "TASK", "confidence": 0.9046324193477631}]}, {"text": "The two conditions are generally valid for terms in a taxonomic relation, while terms satisfying the conditions do not always have taxonomic relation.", "labels": [], "entities": []}, {"text": "So they are necessary conditions for taxonomy learning.", "labels": [], "entities": [{"text": "taxonomy learning", "start_pos": 37, "end_pos": 54, "type": "TASK", "confidence": 0.9270401895046234}]}, {"text": "Based on these conditions, it is highly probable that term t 1 is an ancestor of term t 2 in domain taxonomy TD , when t 1 and t 2 are semantically similar enough and the specificity oft 1 is lower than that oft 2 in D as in.", "labels": [], "entities": []}, {"text": "However, t 1 is not an ancestor oft 3 even though the speci-ficity oft 1 is lower than that oft 3 because t 1 is not similar tot 3 on the semantic level.", "labels": [], "entities": []}, {"text": "The strength of this method lies in its ability to adopt different optimal features for term specificity and term similarity.", "labels": [], "entities": []}, {"text": "Most of current researches relied on single feature such as adjectives of terms, verb-argument relation, or cooccurrence ratio in documents according to their methods.", "labels": [], "entities": []}, {"text": "Firstly, we analyze characteristics of features for taxonomy learning in view of term specificity and term similarity to show that the features embed characteristics of specificity and similarity, and finally apply optimal features to our method.", "labels": [], "entities": []}, {"text": "Additionally we tested inside information of terms to measure term specificity and similarity.", "labels": [], "entities": []}, {"text": "As multiword terms cover the larger part of technical terms, lexical components are featuring information representing semantics of terms.", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized follows.", "labels": [], "entities": []}, {"text": "Characteristics of term specificity are described in Section 2, while term similarity and its features are addressed in Section 3.", "labels": [], "entities": []}, {"text": "Our taxonomy learning method is discussed in Section 4.", "labels": [], "entities": []}, {"text": "Experiment and evaluation are discussed in Section 5, and finally, conclusions are drawn in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "We applied our taxonomy learning method to set of terms in existing taxonomy.", "labels": [], "entities": []}, {"text": "We removed all relations from the taxonomy, and made new taxonomic relations among the terms.", "labels": [], "entities": []}, {"text": "The learned taxonomy was then compared to original taxonomy.", "labels": [], "entities": []}, {"text": "Our experiment is composed of four steps.", "labels": [], "entities": []}, {"text": "Firstly, we calculated term specificity using specificity measures discussed in chapter 2, secondly, we calculated term similarity using similarity measures described in chapter 3, thirdly, we applied the best specificity and similarity features to our taxonomy building process, and finally, we evaluated our method and compared with other taxonomy learning methods.", "labels": [], "entities": []}, {"text": "Finance ontology 2 which was developed within the GETESS project () was used in our experiment.", "labels": [], "entities": [{"text": "Finance ontology", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.6725233346223831}, {"text": "GETESS project", "start_pos": 50, "end_pos": 64, "type": "DATASET", "confidence": 0.9414225220680237}]}, {"text": "We slightly modified original ontology.", "labels": [], "entities": []}, {"text": "We unified different expressions of same concept to identical expression.", "labels": [], "entities": []}, {"text": "For example, 'cd-rom drive' and 'cdrom drive' are unified as 'cd-rom drive' because the former is more usual expression than the latter.", "labels": [], "entities": []}, {"text": "We also removed terms that are not descendents of 'root' node to make the taxonomy have single root node.", "labels": [], "entities": []}, {"text": "The taxonomy consists of total 1,819 nodes and 1,130 distinct nodes.", "labels": [], "entities": []}, {"text": "Maximum and average depths are 15 and 5.5 respectively, and maximum and average children nodes are 32 and 3.5 respectively.", "labels": [], "entities": []}, {"text": "We considered Reuters21578 3 corpus, over 3.1 million words in title and body fields.", "labels": [], "entities": [{"text": "Reuters21578 3 corpus", "start_pos": 14, "end_pos": 35, "type": "DATASET", "confidence": 0.9036042292912801}]}, {"text": "We parsed the corpus using Connexor functional dependency parser and extracted various statistics: term frequency, distribution of adjectives, distribution of co-occurring frequency in documents, and verb-argument distribution.", "labels": [], "entities": [{"text": "Connexor functional dependency parser", "start_pos": 27, "end_pos": 64, "type": "TASK", "confidence": 0.5788402184844017}]}], "tableCaptions": [{"text": " Table 1. Precision, recall and F-measure for term  specificity", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9986640214920044}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9996230602264404}, {"text": "F-measure", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9994680285453796}, {"text": "term  specificity", "start_pos": 46, "end_pos": 63, "type": "TASK", "confidence": 0.6499107927083969}]}]}