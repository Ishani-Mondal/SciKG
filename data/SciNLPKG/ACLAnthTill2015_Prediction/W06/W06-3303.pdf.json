{"title": [{"text": "Term Generalization and Synonym Resolution for Biological Abstracts: Using the Gene Ontology for Subcellular Localization Prediction", "labels": [], "entities": [{"text": "Term Generalization", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9076415598392487}, {"text": "Synonym Resolution", "start_pos": 24, "end_pos": 42, "type": "TASK", "confidence": 0.760743647813797}, {"text": "Subcellular Localization Prediction", "start_pos": 97, "end_pos": 132, "type": "TASK", "confidence": 0.7589254975318909}]}], "abstractContent": [{"text": "The field of molecular biology is growing at an astounding rate and research findings are being deposited into public databases, such as Swiss-Prot.", "labels": [], "entities": [{"text": "molecular biology", "start_pos": 13, "end_pos": 30, "type": "TASK", "confidence": 0.7574191987514496}, {"text": "Swiss-Prot.", "start_pos": 137, "end_pos": 148, "type": "DATASET", "confidence": 0.9854123294353485}]}, {"text": "Many of the over 200,000 protein entries in Swiss-Prot 49.1 lack annotations such as subcellular lo-calization or function, but the vast majority have references to journal abstracts describing related research.", "labels": [], "entities": [{"text": "Swiss-Prot 49.1", "start_pos": 44, "end_pos": 59, "type": "DATASET", "confidence": 0.9696604311466217}]}, {"text": "These abstracts represent a huge amount of information that could be used to generate annotations for proteins automatically.", "labels": [], "entities": []}, {"text": "Training clas-sifiers to perform text categorization on abstracts is one way to accomplish this task.", "labels": [], "entities": []}, {"text": "We present a method for improving text classification for biological journal abstracts by generating additional text features using the knowledge represented in a biological concept hierarchy (the Gene Ontology).", "labels": [], "entities": [{"text": "text classification", "start_pos": 34, "end_pos": 53, "type": "TASK", "confidence": 0.7389260530471802}]}, {"text": "The structure of the ontology, as well as the synonyms recorded in it, are leveraged by our simple technique to significantly improve the F-measure of sub-cellular localization text classifiers by as much as 0.078 and we achieve F-measures as high as 0.935.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 138, "end_pos": 147, "type": "METRIC", "confidence": 0.9958089590072632}, {"text": "F-measures", "start_pos": 229, "end_pos": 239, "type": "METRIC", "confidence": 0.9969743490219116}]}], "introductionContent": [{"text": "Can computers extract the semantic content of academic journal abstracts?", "labels": [], "entities": []}, {"text": "This paper explores the use of natural language techniques for processing biological abstracts to answer this question in a specific domain.", "labels": [], "entities": []}, {"text": "Our prototype method predicts the subcellular localization of proteins (the part of the biological cell where a protein performs its function) by performing text classification on related journal abstracts.", "labels": [], "entities": [{"text": "text classification", "start_pos": 157, "end_pos": 176, "type": "TASK", "confidence": 0.707531526684761}]}, {"text": "In the last two decades, there has been explosive growth in molecular biology research.", "labels": [], "entities": [{"text": "molecular biology research", "start_pos": 60, "end_pos": 86, "type": "TASK", "confidence": 0.8206493655840555}]}, {"text": "Molecular biologists organize their findings into a common set of databases.", "labels": [], "entities": []}, {"text": "One such database is Swiss-Prot, in which each entry corresponds to a protein.", "labels": [], "entities": [{"text": "Swiss-Prot", "start_pos": 21, "end_pos": 31, "type": "DATASET", "confidence": 0.9747927188873291}]}, {"text": "As of version 49.1) Swiss-Prot contains more than 200,000 proteins, 190,000 of which link to biological journal abstracts.", "labels": [], "entities": [{"text": "Swiss-Prot", "start_pos": 20, "end_pos": 30, "type": "DATASET", "confidence": 0.9500505328178406}]}, {"text": "Unfortunately, a much smaller percentage of protein entries are annotated with other types of information.", "labels": [], "entities": []}, {"text": "For example, only about half the entries have subcellular localization annotations.", "labels": [], "entities": []}, {"text": "This disparity is partially due to the fact that humans annotate these databases manually and cannot keep up with the influx of data.", "labels": [], "entities": []}, {"text": "If a computer could be trained to produce annotations by processing journal abstracts, proteins in the SwissProt database could be curated semi-automatically.", "labels": [], "entities": [{"text": "SwissProt database", "start_pos": 103, "end_pos": 121, "type": "DATASET", "confidence": 0.9814901649951935}]}, {"text": "Document classification is the process of categorizing a set of text documents into one or more of a predefined set of classes.", "labels": [], "entities": [{"text": "Document classification is the process of categorizing a set of text documents into one or more of a predefined set of classes", "start_pos": 0, "end_pos": 126, "type": "Description", "confidence": 0.7875800593332811}]}, {"text": "The classification of biological abstracts is an interesting specialization of general document classification, in that scientific language is often not understandable by, nor written for, the lay-person.", "labels": [], "entities": [{"text": "classification of biological abstracts", "start_pos": 4, "end_pos": 42, "type": "TASK", "confidence": 0.8920690268278122}, {"text": "general document classification", "start_pos": 79, "end_pos": 110, "type": "TASK", "confidence": 0.6850247979164124}]}, {"text": "It is full of specialized terms, acronyms and it often displays high levels of synonymy.", "labels": [], "entities": []}, {"text": "For example, the \"PAM complex\", which exists in the mitochondrion of the biological cell is also referred to with the phrases \"presequence translocase-associated import motor\" and \"mitochondrial import motor\".", "labels": [], "entities": []}, {"text": "This also illustrates the fact that biological terms often span word boundaries and so their collective meaning is lost when text is whitespace tokenized.", "labels": [], "entities": []}, {"text": "To overcome the challenges of scientific language, our technique employs the Gene Ontology (GO)) as a source of expert knowledge.", "labels": [], "entities": []}, {"text": "The GO is a controlled vocabulary of biological terms developed and maintained by biologists.", "labels": [], "entities": []}, {"text": "In this paper we use the knowledge represented by the GO to complement the information present in journal abstracts.", "labels": [], "entities": []}, {"text": "Specifically we show that: \u2022 the GO can be used as a thesaurus \u2022 the hierarchical structure of the GO can be used to generalize specific terms into broad concepts \u2022 simple techniques using the GO significantly improve text classification Although biological abstracts are challenging documents to classify, solving this problem will yield important benefits.", "labels": [], "entities": [{"text": "text classification", "start_pos": 218, "end_pos": 237, "type": "TASK", "confidence": 0.7187531739473343}]}, {"text": "With sufficiently accurate text classifiers, the abstracts of Swiss-Prot entries could be used to automatically annotate corresponding proteins, meaning biologists could more efficiently identify proteins of interest.", "labels": [], "entities": [{"text": "Swiss-Prot entries", "start_pos": 62, "end_pos": 80, "type": "DATASET", "confidence": 0.9356614053249359}]}, {"text": "Less time spent sifting through unannotated proteins translates into more time spent on new science, performing important experiments and uncovering fresh knowledge.", "labels": [], "entities": []}], "datasetContent": [{"text": "Each of our classifiers was evaluated using 10 fold cross-validation.", "labels": [], "entities": []}, {"text": "In 10 fold cross-validation each Data Set is split into 10 stratified partitions.", "labels": [], "entities": []}, {"text": "For the first \"fold\", a classifier is trained on 9 of the 10 partitions and the tenth partition is used to test the classifier.", "labels": [], "entities": []}, {"text": "This is repeated for nine more folds, holding out a different tenth each time.", "labels": [], "entities": []}, {"text": "The results of all 10 folds are combined and composite precision, recall and F-measures are computed.", "labels": [], "entities": [{"text": "precision", "start_pos": 55, "end_pos": 64, "type": "METRIC", "confidence": 0.9222502112388611}, {"text": "recall", "start_pos": 66, "end_pos": 72, "type": "METRIC", "confidence": 0.9996500015258789}, {"text": "F-measures", "start_pos": 77, "end_pos": 87, "type": "METRIC", "confidence": 0.9982523322105408}]}, {"text": "Cross-validation accurately estimates prediction statistics of a classifier, since each instance is used as a test case at some point during validation.", "labels": [], "entities": []}, {"text": "The SVM implementation libSVM) was used to conduct our experiments.", "labels": [], "entities": []}, {"text": "A linear kernel and default parameters were used in all cases; no parameter searching was done.", "labels": [], "entities": []}, {"text": "Precision, recall and F-measure were calculated for each experiment.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9973216652870178}, {"text": "recall", "start_pos": 11, "end_pos": 17, "type": "METRIC", "confidence": 0.9993543028831482}, {"text": "F-measure", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.999315619468689}]}], "tableCaptions": [{"text": " Table 3: F-measures for stratified 10 fold cross-validation on our three Data Sets. Results deemed signifi- cantly improved over the baseline (p=0.05) appear in bold, and those with an asterisk (*) are significantly  better than both other data sets. Change in F-measure compared to baseline is shown for Data Sets 2 and 3.  Standard deviation is shown in parentheses.", "labels": [], "entities": [{"text": "F-measures", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9832342863082886}, {"text": "F-measure", "start_pos": 262, "end_pos": 271, "type": "METRIC", "confidence": 0.99625164270401}, {"text": "Standard deviation", "start_pos": 326, "end_pos": 344, "type": "METRIC", "confidence": 0.960943728685379}]}]}