{"title": [{"text": "Question Pre-Processing in a QA System on Internet Discussion Groups", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper proposes methods to pre-process questions in the postings before a QA system can find answers in a discussion group in the Internet.", "labels": [], "entities": []}, {"text": "Pre-processing includes garbage text removal and question segmentation.", "labels": [], "entities": [{"text": "garbage text removal", "start_pos": 24, "end_pos": 44, "type": "TASK", "confidence": 0.6364686687787374}, {"text": "question segmentation", "start_pos": 49, "end_pos": 70, "type": "TASK", "confidence": 0.7788164913654327}]}, {"text": "Garbage keywords are collected and different length thresholds are assigned to them for garbage text identification.", "labels": [], "entities": [{"text": "garbage text identification", "start_pos": 88, "end_pos": 115, "type": "TASK", "confidence": 0.6378235121568044}]}, {"text": "Interrogative forms and question types are used to segment questions.", "labels": [], "entities": []}, {"text": "The best performance on the test set achieves 92.57% accuracy in garbage text removal and 85.87% accuracy in question segmentation, respectively.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9990610480308533}, {"text": "garbage text removal", "start_pos": 65, "end_pos": 85, "type": "TASK", "confidence": 0.641952633857727}, {"text": "accuracy", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.9990621209144592}, {"text": "question segmentation", "start_pos": 109, "end_pos": 130, "type": "TASK", "confidence": 0.6973498314619064}]}], "introductionContent": [{"text": "Question answering has been a hot research topic in recent years.", "labels": [], "entities": [{"text": "Question answering", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9486754834651947}]}, {"text": "Large scale QA evaluation projects (e.g. TREC QA-Track 1 , QA@CLEF 2 , and NTCIR 3 QAC and CLQA Tracks) are helpful to the developments of question answering.", "labels": [], "entities": [{"text": "NTCIR 3 QAC", "start_pos": 75, "end_pos": 86, "type": "DATASET", "confidence": 0.7437386711438497}, {"text": "question answering", "start_pos": 139, "end_pos": 157, "type": "TASK", "confidence": 0.9203863441944122}]}, {"text": "However, real automatic QA services are not ready in the Internet.", "labels": [], "entities": [{"text": "QA", "start_pos": 24, "end_pos": 26, "type": "TASK", "confidence": 0.9270777106285095}]}, {"text": "One popular way for Internet users to ask questions and get answers is to visit discussion groups, such as Usenet newsgroups or Yahoo!", "labels": [], "entities": []}, {"text": "Answers . Each discussion group focuses on one topic so that users can easily find one to post their questions.", "labels": [], "entities": []}, {"text": "There are two ways a user can try to find answers.", "labels": [], "entities": []}, {"text": "You can post your question in a related discussion group and wait for other users to provide answers.", "labels": [], "entities": []}, {"text": "Some discussion groups provide search toolbars so that you can search your question first to see if there are similar postings asking the same question.", "labels": [], "entities": []}, {"text": "Answers, you can also judge answers offered by other users and mark the best one.", "labels": [], "entities": []}, {"text": "Postings in discussion groups are good materials to develop a FAQ-style QA system in the Internet.", "labels": [], "entities": [{"text": "FAQ-style QA", "start_pos": 62, "end_pos": 74, "type": "TASK", "confidence": 0.5886853337287903}]}, {"text": "By finding questions in the discussion groups similar to anew posting, responses to these questions can provide answers or relevant information.", "labels": [], "entities": []}, {"text": "But without pre-processing, measuring similarity with original texts will arise some problems: 1.", "labels": [], "entities": []}, {"text": "Some phrases such as \"many thanks\" or \"help me please\" are not part of a question.", "labels": [], "entities": []}, {"text": "These kinds of phrases will introduce noise and harm matching performance.", "labels": [], "entities": []}, {"text": "2. Quite often there is more than one question in one posting.", "labels": [], "entities": []}, {"text": "If the question which is most similar to the user's question appears in an existed posting together with other different questions, it will get a lower similarity score than the one it is supposed to have because of other questions.", "labels": [], "entities": [{"text": "similarity score", "start_pos": 152, "end_pos": 168, "type": "METRIC", "confidence": 0.976315051317215}]}, {"text": "Therefore, inappropriate phrases should be removed and different questions in one posting should be separated before question comparison.", "labels": [], "entities": []}, {"text": "There is no research focusing on this topic.", "labels": [], "entities": []}, {"text": "FAQ finders are closely related to this topic.", "labels": [], "entities": [{"text": "FAQ finders", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.7302682995796204}]}, {"text": "However, there are differences between them.", "labels": [], "entities": []}, {"text": "First of all, questions in a FAQ set are often written in perfect grammar without garbage text.", "labels": [], "entities": [{"text": "FAQ set", "start_pos": 29, "end_pos": 36, "type": "DATASET", "confidence": 0.7388747036457062}]}, {"text": "Second, questions are often paired with answers separately.", "labels": [], "entities": []}, {"text": "I.e. there is often one question in one QA pair.", "labels": [], "entities": []}, {"text": "There were some research groups who divided questions into segments.", "labels": [], "entities": []}, {"text": "chunked questions and used them as queries to search engines.", "labels": [], "entities": []}, {"text": "focused on decomposition of a complex question into several sub-questions.", "labels": [], "entities": []}, {"text": "In this paper, question segmentation is to identify different questions posed in one posting.", "labels": [], "entities": [{"text": "question segmentation", "start_pos": 15, "end_pos": 36, "type": "TASK", "confidence": 0.8035664558410645}]}], "datasetContent": [{"text": "All the experimental data were collected from Yahoo!", "labels": [], "entities": [{"text": "Yahoo!", "start_pos": 46, "end_pos": 52, "type": "DATASET", "confidence": 0.9320061504840851}]}, {"text": "Knowledge + (Yahoo! \u5947 \u6469 \u77e5 \uf9fc + ) , discussion groups similar to Yahoo!", "labels": [], "entities": []}, {"text": "Answers but using Chinese instead of English.", "labels": [], "entities": []}, {"text": "Three discussion groups, \"Business Application\" (\u5546\u52d9\u61c9\u7528), \"Website Building\" (\u7db2\u7ad9\u67b6\u8a2d), and \"Image Processing\" (\u5f71\u50cf\u8655\uf9e4), were selected to collect querying postings.", "labels": [], "entities": []}, {"text": "The reason that we chose these three discussion groups was their moderate growing rates.", "labels": [], "entities": []}, {"text": "We could collect enough amount of querying postings published in the same period of time.", "labels": [], "entities": []}, {"text": "The following kinds of postings were not selected as our experimental data:, where \"BA\", \"WB\", and \"IP\" stand for \"Business Application\", \"Website Building\", and \"Image Processing\", respectively.", "labels": [], "entities": [{"text": "BA", "start_pos": 84, "end_pos": 86, "type": "METRIC", "confidence": 0.9845681190490723}]}], "tableCaptions": [{"text": " Table 3. Weights of Part-of-Speeches", "labels": [], "entities": [{"text": "Weights", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.949959933757782}]}, {"text": " Table 7. Accuracy of Question Segmentation  by Different Strategies (Training Set)", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9695415496826172}, {"text": "Question Segmentation", "start_pos": 22, "end_pos": 43, "type": "TASK", "confidence": 0.7063290625810623}]}, {"text": " Table 9. Accuracy of Question Segmentation  with Different Length Thresholds", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9835779666900635}, {"text": "Question Segmentation", "start_pos": 22, "end_pos": 43, "type": "TASK", "confidence": 0.7106256932020187}]}, {"text": " Table 10. Accuracy of Question Segmentation  with Different Weight Thresholds", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 11, "end_pos": 19, "type": "METRIC", "confidence": 0.9946714043617249}, {"text": "Question Segmentation", "start_pos": 23, "end_pos": 44, "type": "TASK", "confidence": 0.7504436671733856}]}]}