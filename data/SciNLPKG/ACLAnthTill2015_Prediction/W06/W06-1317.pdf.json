{"title": [{"text": "Classification of Discourse Coherence Relations: An Exploratory Study using Multiple Knowledge Sources", "labels": [], "entities": [{"text": "Classification of Discourse Coherence Relations", "start_pos": 0, "end_pos": 47, "type": "TASK", "confidence": 0.870338749885559}]}], "abstractContent": [{"text": "In this paper we consider the problem of identifying and classifying discourse coherence relations.", "labels": [], "entities": []}, {"text": "We report initial results over the recently released Discourse GraphBank (Wolf and Gibson, 2005).", "labels": [], "entities": []}, {"text": "Our approach considers, and determines the contributions of, a variety of syntactic and lexico-semantic features.", "labels": [], "entities": []}, {"text": "We achieve 81% accuracy on the task of discourse relation type classification and 70% accuracy on relation identification.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.999512791633606}, {"text": "discourse relation type classification", "start_pos": 39, "end_pos": 77, "type": "TASK", "confidence": 0.6483577489852905}, {"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.9994946718215942}, {"text": "relation identification", "start_pos": 98, "end_pos": 121, "type": "TASK", "confidence": 0.8702008128166199}]}], "introductionContent": [{"text": "The area of modeling discourse has arguably seen less success than other areas in NLP.", "labels": [], "entities": [{"text": "modeling discourse", "start_pos": 12, "end_pos": 30, "type": "TASK", "confidence": 0.8979212045669556}]}, {"text": "Contributing to this is the fact that no consensus has been reached on the inventory of discourse relations nor on the types of formal restrictions placed on discourse structure.", "labels": [], "entities": []}, {"text": "Furthermore, modeling discourse structure requires access to considerable prior linguistic analysis including syntax, lexical and compositional semantics, as well as the resolution of entity and event-level anaphora, all of which are non-trivial problems themselves.", "labels": [], "entities": []}, {"text": "Discourse processing has been used in many text processing applications, most notably text summarization and compression, text generation, and dialogue understanding.", "labels": [], "entities": [{"text": "Discourse processing", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8359551429748535}, {"text": "text summarization and compression", "start_pos": 86, "end_pos": 120, "type": "TASK", "confidence": 0.8091507107019424}, {"text": "text generation", "start_pos": 122, "end_pos": 137, "type": "TASK", "confidence": 0.8050135672092438}, {"text": "dialogue understanding", "start_pos": 143, "end_pos": 165, "type": "TASK", "confidence": 0.9079417884349823}]}, {"text": "However, it is also important for general text understanding, including applications such as information extraction and question answering.", "labels": [], "entities": [{"text": "general text understanding", "start_pos": 34, "end_pos": 60, "type": "TASK", "confidence": 0.7303142746289571}, {"text": "information extraction", "start_pos": 93, "end_pos": 115, "type": "TASK", "confidence": 0.8523575067520142}, {"text": "question answering", "start_pos": 120, "end_pos": 138, "type": "TASK", "confidence": 0.9295290410518646}]}, {"text": "Recently, have proposed a graph-based approach to representing informational discourse relations.", "labels": [], "entities": [{"text": "representing informational discourse relations", "start_pos": 50, "end_pos": 96, "type": "TASK", "confidence": 0.7026308998465538}]}, {"text": "1 They demonstrate that tree representations are inadequate for The relations they define roughly follow.", "labels": [], "entities": []}, {"text": "modeling coherence relations, and show that many discourse segments have multiple parents (incoming directed relations) and many of the relations introduce crossing dependencies -both of which preclude tree representations.", "labels": [], "entities": []}, {"text": "Their annotation of 135 articles has been released as the GraphBank corpus.", "labels": [], "entities": [{"text": "GraphBank corpus", "start_pos": 58, "end_pos": 74, "type": "DATASET", "confidence": 0.9467205107212067}]}, {"text": "In this paper, we provide initial results for the following tasks: (1) automatically classifying the type of discourse coherence relation; and (2) identifying whether any discourse relation exists on two text segments.", "labels": [], "entities": []}, {"text": "The experiments we report are based on the annotated data in the Discourse GraphBank, where we assume that the discourse units have already been identified.", "labels": [], "entities": []}, {"text": "In contrast to a highly structured, compositional approach to discourse parsing, we explore a simple, flat, feature-based methodology.", "labels": [], "entities": [{"text": "discourse parsing", "start_pos": 62, "end_pos": 79, "type": "TASK", "confidence": 0.7220986038446426}]}, {"text": "Such an approach has the advantage of easily accommodating many knowledge sources.", "labels": [], "entities": []}, {"text": "This type of detailed feature analysis can serve to inform or augment more structured, compositional approaches to discourse such as those based on Segmented Discourse Representation Theory (SDRT) or the approach taken with the D-LTAG system ().", "labels": [], "entities": [{"text": "Segmented Discourse Representation Theory (SDRT)", "start_pos": 148, "end_pos": 196, "type": "TASK", "confidence": 0.7780893615313939}]}, {"text": "Using a comprehensive set of linguistic features as input to a Maximum Entropy classifier, we achieve 81% accuracy on classifying the correct type of discourse coherence relation between two segments.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 106, "end_pos": 114, "type": "METRIC", "confidence": 0.9994019269943237}]}], "datasetContent": [{"text": "In this section we provide the results of a set of experiments focused on the task of discourse relation classification.", "labels": [], "entities": [{"text": "discourse relation classification", "start_pos": 86, "end_pos": 119, "type": "TASK", "confidence": 0.7650979359944662}]}, {"text": "We also report initial results on relation identification with the same set of features as used for classification.", "labels": [], "entities": [{"text": "relation identification", "start_pos": 34, "end_pos": 57, "type": "TASK", "confidence": 0.8790642619132996}]}], "tableCaptions": [{"text": " Table 1: Feature classes, their descriptions and example feature instances for Example 5 in Section 3.2.", "labels": [], "entities": []}, {"text": " Table 3: Classification accuracy with each fea- ture class removed from the union of all feature  classes.", "labels": [], "entities": [{"text": "Classification", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.9451496601104736}, {"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9898659586906433}]}, {"text": " Table 4: Precision, Recall and F-measure results.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9985995888710022}, {"text": "Recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9960466027259827}, {"text": "F-measure", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9980455636978149}]}]}