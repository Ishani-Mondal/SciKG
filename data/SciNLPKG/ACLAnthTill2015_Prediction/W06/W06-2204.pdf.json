{"title": [{"text": "Transductive Pattern Learning for Information Extraction", "labels": [], "entities": [{"text": "Transductive Pattern Learning", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8979842662811279}, {"text": "Information Extraction", "start_pos": 34, "end_pos": 56, "type": "TASK", "confidence": 0.6822867691516876}]}], "abstractContent": [{"text": "The requirement for large labelled training corpora is widely recognized as a key bottleneck in the use of learning algorithms for information extraction.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 131, "end_pos": 153, "type": "TASK", "confidence": 0.8692487478256226}]}, {"text": "We present TPLEX, a semi-supervised learning algorithm for information extraction that can acquire extraction patterns from a small amount of labelled text in conjunction with a large amount of un-labelled text.", "labels": [], "entities": [{"text": "TPLEX", "start_pos": 11, "end_pos": 16, "type": "METRIC", "confidence": 0.8328388929367065}, {"text": "information extraction", "start_pos": 59, "end_pos": 81, "type": "TASK", "confidence": 0.7878325283527374}]}, {"text": "Compared to previous work, TPLEX has two novel features.", "labels": [], "entities": [{"text": "TPLEX", "start_pos": 27, "end_pos": 32, "type": "TASK", "confidence": 0.6238659024238586}]}, {"text": "First, the algorithm does not require redundancy in the fragments to be extracted, but only redundancy of the extraction patterns themselves.", "labels": [], "entities": []}, {"text": "Second, most bootstrapping methods identify the highest quality fragments in the unlabelled data and then assume that they are as reliable as manually labelled data in subsequent iterations.", "labels": [], "entities": []}, {"text": "In contrast, TPLEX's scoring mechanism prevents errors from snowballing by recording the reliability of fragments extracted from un-labelled data.", "labels": [], "entities": [{"text": "reliability", "start_pos": 89, "end_pos": 100, "type": "METRIC", "confidence": 0.9906392097473145}]}, {"text": "Our experiments with several benchmarks demonstrate that TPLEX is usually competitive with various fully-supervised algorithms when very little labelled training data is available.", "labels": [], "entities": [{"text": "TPLEX", "start_pos": 57, "end_pos": 62, "type": "TASK", "confidence": 0.630016028881073}]}], "introductionContent": [{"text": "Information extraction is a form of shallow text analysis that involves identifying domain-specific fragments within natural language text.", "labels": [], "entities": [{"text": "Information extraction", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8185180723667145}, {"text": "shallow text analysis", "start_pos": 36, "end_pos": 57, "type": "TASK", "confidence": 0.711347242196401}]}, {"text": "Most recent research has focused on learning algorithms that automatically acquire extraction patterns from manually labelled training data (e.g.,).", "labels": [], "entities": []}, {"text": "This training data takes the form of the original text, annotated with the fragments to be extracted.", "labels": [], "entities": []}, {"text": "Due to the expense and tedious nature of this labelling process, it is widely recognized that a key bottleneck in deploying such algorithms is the need to create a sufficiently large training corpus for each new domain.", "labels": [], "entities": []}, {"text": "In response to this challenge, many researchers have investigated semi-supervised learning algorithms that learn from a (relatively small) set of labelled texts in conjunction with a (relatively large) set of unlabelled texts (e.g.,).", "labels": [], "entities": []}, {"text": "In this paper, we present TPLEX, a semi-supervised algorithm for learning information extraction patterns.", "labels": [], "entities": [{"text": "TPLEX", "start_pos": 26, "end_pos": 31, "type": "METRIC", "confidence": 0.8971509337425232}, {"text": "learning information extraction patterns", "start_pos": 65, "end_pos": 105, "type": "TASK", "confidence": 0.7048113867640495}]}, {"text": "The key idea is to exploit the following recursive definitions: good patterns extract good fragments, and good fragments are extracted by good patterns.", "labels": [], "entities": []}, {"text": "To operationalize this recursive definition, we initialize the pattern and fragment scores with labelled data, and then iterate until the scores have converged.", "labels": [], "entities": []}, {"text": "Most prior semi-supervised approaches to information extraction assume that fragments are essentially named entities, so that there will be many occurrences of any given fragment.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 41, "end_pos": 63, "type": "TASK", "confidence": 0.8558472692966461}]}, {"text": "For example, for the task of discovering diseases (\"influenza\", \"Ebola\", etc), prior algorithms assume that each disease will be mentioned many times, and that every occurrence of such a disease in unlabelled text should be extracted.", "labels": [], "entities": []}, {"text": "However, it may not be the case that fragments to be extracted occur more than once in the corpus, or that every occurrence of a labelled fragment should be extracted.", "labels": [], "entities": []}, {"text": "For example, in the well-known CMU Seminars corpus, any given person usually gives just one seminar, and a fragment such as \"3pm\" sometimes indicates the start time, other occurrences indicate the end time, and some occurrence should not be extracted at all.", "labels": [], "entities": [{"text": "CMU Seminars corpus", "start_pos": 31, "end_pos": 50, "type": "DATASET", "confidence": 0.9404968420664469}]}, {"text": "Rather than relying on redundancy of the fragments, TPLEX exploits redundancy of the learned extraction patterns.", "labels": [], "entities": []}, {"text": "TPLEX is a transductive algorithm, in that the goal is to perform extraction from a given unlabelled corpus, given a labelled corpus.", "labels": [], "entities": []}, {"text": "This is in contrast to the typical machine learning framework, where the goal is a set of extraction patterns (which can of course then be applied to new unlabelled text).", "labels": [], "entities": []}, {"text": "As a side-effect, TPLEX does generate a set of extraction patterns which maybe a useful in their own right, depending on the application.", "labels": [], "entities": []}, {"text": "We have compared TPLEX with various competitors on a variety of real-world extraction tasks.", "labels": [], "entities": []}, {"text": "We have observed that TPLEX's performance matches or exceeds these in several benchmark tasks.", "labels": [], "entities": [{"text": "TPLEX", "start_pos": 22, "end_pos": 27, "type": "TASK", "confidence": 0.7227489352226257}]}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "After describing related work in more detail (Sec. 2), we describe the TPLEX algorithm (Sec. 3).", "labels": [], "entities": []}, {"text": "We then discuss a series of experiments to compare TPLEX with various supervised al-gorithms (Sec. 4).", "labels": [], "entities": [{"text": "TPLEX", "start_pos": 51, "end_pos": 56, "type": "TASK", "confidence": 0.7365690469741821}]}, {"text": "We conclude with a summary of observations made during the evaluation, and a discussion of future work (Sec. 5).", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the performance of our algorithm we conducted experiments with four widely used corpora: the CMU seminar set, the Austin jobs set, the Reuters acquisition set We randomly partitioned each of the datasets into two evenly sized subsets.", "labels": [], "entities": [{"text": "CMU seminar set", "start_pos": 105, "end_pos": 120, "type": "DATASET", "confidence": 0.9500512282053629}, {"text": "Reuters acquisition set", "start_pos": 147, "end_pos": 170, "type": "DATASET", "confidence": 0.8781970342000326}]}, {"text": "We then used these as labeled and unlabeled sets.", "labels": [], "entities": []}, {"text": "In each experiment the algorithm was presented with a document set comprised of the test set and a randomly selected percentage of the documents from the training set.", "labels": [], "entities": []}, {"text": "For example, if an experiment involved providing the algorithm with a 5% seed set, then 5% of the documents in the training set (2.5% of the documents in the entire dataset) would be selected at random and used in conjunction with the documents in the test set.", "labels": [], "entities": []}, {"text": "For each training set size, we ran five iterations with a randomly selected subset of the documents used for training.", "labels": [], "entities": []}, {"text": "Since we are mainly motivated by scenarios with very little training data, we varied the size of the training set from 1-10% (1-16% for MUC-7NE) of the available documents.", "labels": [], "entities": [{"text": "MUC-7NE", "start_pos": 136, "end_pos": 143, "type": "DATASET", "confidence": 0.8213860392570496}]}, {"text": "Precision, recall and F1 were calculated using the BWI scorer.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9971766471862793}, {"text": "recall", "start_pos": 11, "end_pos": 17, "type": "METRIC", "confidence": 0.9995748400688171}, {"text": "F1", "start_pos": 22, "end_pos": 24, "type": "METRIC", "confidence": 0.9995245933532715}, {"text": "BWI scorer", "start_pos": 51, "end_pos": 61, "type": "METRIC", "confidence": 0.899093747138977}]}, {"text": "We used all occurrences mode, which records a match in the case where we extract all of the valid fragments in a given document, but we get no credit for partially correct extractions.", "labels": [], "entities": []}, {"text": "We compared TPLEX to BWI), LP 2 (Ciravegna, 2001), ELIE (, and an approach based on conditional random fields ().", "labels": [], "entities": [{"text": "BWI", "start_pos": 21, "end_pos": 24, "type": "DATASET", "confidence": 0.5081868767738342}, {"text": "ELIE", "start_pos": 51, "end_pos": 55, "type": "METRIC", "confidence": 0.9894117712974548}]}, {"text": "The data for BWI was obtained using the TIES implementation [tcc.itc.it/research/textec/toolsresources/ties.html].", "labels": [], "entities": [{"text": "BWI", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.5137361288070679}, {"text": "TIES", "start_pos": 40, "end_pos": 44, "type": "DATASET", "confidence": 0.8881989121437073}]}, {"text": "The data for the LP 2 learning curve was obtained from.", "labels": [], "entities": [{"text": "LP 2 learning curve", "start_pos": 17, "end_pos": 36, "type": "DATASET", "confidence": 0.7989538311958313}]}, {"text": "The results for ELIE were generated by the current implementation [http://smi.ucd.ie/aidan/Software.html].", "labels": [], "entities": [{"text": "ELIE", "start_pos": 16, "end_pos": 20, "type": "DATASET", "confidence": 0.5247934460639954}]}, {"text": "For the CRF results, we used MALLET's SimpleTagger, with each token encoded with a set of binary features (one for each observed literal, as well as the eight token generalizations).", "labels": [], "entities": [{"text": "CRF", "start_pos": 8, "end_pos": 11, "type": "TASK", "confidence": 0.8956772089004517}]}, {"text": "Our results in indicate that in Acquisitions dataset, our algorithm substantially outperforms the competitors at all points on the learning curve.", "labels": [], "entities": [{"text": "Acquisitions dataset", "start_pos": 32, "end_pos": 52, "type": "DATASET", "confidence": 0.795757532119751}]}, {"text": "For the other datasets, the results are mixed.", "labels": [], "entities": []}, {"text": "For SA and Jobs, TPLEX is the second best algorithm at the low end of the learning curve, and steadily loses ground as more labelled data is available.", "labels": [], "entities": [{"text": "TPLEX", "start_pos": 17, "end_pos": 22, "type": "METRIC", "confidence": 0.9085665941238403}]}, {"text": "TPLEX is the least accurate algorithm for the MUC data.", "labels": [], "entities": [{"text": "TPLEX", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.817992091178894}, {"text": "MUC data", "start_pos": 46, "end_pos": 54, "type": "DATASET", "confidence": 0.831828773021698}]}, {"text": "5, we discuss a variety of modifications to the TPLEX algorithm that we anticipate may improve its performance.", "labels": [], "entities": []}, {"text": "Finally, the graph in compares TPLEX for the SA dataset, in two configurations: with a combination of labelled and unlabelled documents as usual, and with only labelled documents.", "labels": [], "entities": [{"text": "SA dataset", "start_pos": 45, "end_pos": 55, "type": "DATASET", "confidence": 0.925206184387207}]}, {"text": "In both instances the algorithm was given the same seed and testing documents.", "labels": [], "entities": []}, {"text": "In the first case the algorithm learned patterns using both the labeled and unlabeled documents.", "labels": [], "entities": []}, {"text": "However, in the second case, only the labeled documents were used to generate the patterns.", "labels": [], "entities": []}, {"text": "These data confirm that TPLEX is indeed able to improve performance from unlabelled data.", "labels": [], "entities": []}], "tableCaptions": []}