{"title": [{"text": "Multilingual Dependency Analysis with a Two-Stage Discriminative Parser", "labels": [], "entities": [{"text": "Multilingual Dependency Analysis", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7196645140647888}]}], "abstractContent": [{"text": "We present a two-stage multilingual dependency parser and evaluate it on 13 diverse languages.", "labels": [], "entities": []}, {"text": "The first stage is based on the unlabeled dependency parsing models described by McDonald and Pereira (2006) augmented with morphological features fora subset of the languages.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 42, "end_pos": 60, "type": "TASK", "confidence": 0.7002548724412918}]}, {"text": "The second stage takes the output from the first and labels all the edges in the dependency graph with appropriate syntactic categories using a globally trained sequence classifier over components of the graph.", "labels": [], "entities": []}, {"text": "We report results on the CoNLL-X shared task (Buchholz et al., 2006) data sets and present an error analysis.", "labels": [], "entities": [{"text": "CoNLL-X shared task (Buchholz et al., 2006) data sets", "start_pos": 25, "end_pos": 78, "type": "DATASET", "confidence": 0.7245945533116659}]}], "introductionContent": [{"text": "Often in language processing we require a deep syntactic representation of a sentence in order to assist further processing.", "labels": [], "entities": []}, {"text": "With the availability of resources such as the Penn WSJ Treebank, much of the focus in the parsing community had been on producing syntactic representations based on phrase-structure.", "labels": [], "entities": [{"text": "Penn WSJ Treebank", "start_pos": 47, "end_pos": 64, "type": "DATASET", "confidence": 0.9592925310134888}]}, {"text": "However, recently their has been a revived interest in parsing models that produce dependency graph representations of sentences, which model words and their arguments through directed edges.", "labels": [], "entities": []}, {"text": "This interest has generally come about due to the computationally efficient and flexible nature of dependency graphs and their ability to easily model non-projectivity in freer-word order languages.", "labels": [], "entities": []}, {"text": "gives an introduction to dependency representations of sentences and recent developments in dependency parsing strategies.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 92, "end_pos": 110, "type": "TASK", "confidence": 0.8301070034503937}]}, {"text": "Dependency graphs also encode much of the deep syntactic information needed for further processing.", "labels": [], "entities": []}, {"text": "This has been shown through their successful use in many standard natural language processing tasks, including machine translation), sentence compression), and textual inference (.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 111, "end_pos": 130, "type": "TASK", "confidence": 0.7393426299095154}, {"text": "sentence compression", "start_pos": 133, "end_pos": 153, "type": "TASK", "confidence": 0.7935039103031158}]}, {"text": "In this paper we describe a two-stage discriminative parsing approach consisting of an unlabeled parser and a subsequent edge labeler.", "labels": [], "entities": []}, {"text": "We evaluate this parser on a diverse set of 13 languages using data provided by the CoNLL-X shared-task organizers ().", "labels": [], "entities": []}, {"text": "The results are promising and show the language independence of our system under the assumption of a labeled dependency corpus in the target language.", "labels": [], "entities": []}, {"text": "For the remainder of this paper, we denote by x = x 1 , . .", "labels": [], "entities": []}, {"text": "x n a sentence with n words and by ya corresponding dependency graph.", "labels": [], "entities": []}, {"text": "A dependency graph is represented by a set of ordered pairs (i, j) \u2208 yin which x j is a dependent and xi is the corresponding head.", "labels": [], "entities": []}, {"text": "Each edge can be assigned a label l (i,j) from a finite set L of predefined labels.", "labels": [], "entities": []}, {"text": "We assume that all dependency graphs are trees but maybe non-projective, both of which are true in the data sets we use.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Dependency accuracy on 13 languages.  Unlabeled (UA) and Labeled Accuracy (LA).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9757382273674011}, {"text": "Unlabeled (UA)", "start_pos": 48, "end_pos": 62, "type": "METRIC", "confidence": 0.8866776674985886}, {"text": "Labeled Accuracy (LA)", "start_pos": 67, "end_pos": 88, "type": "METRIC", "confidence": 0.8189417958259583}]}, {"text": " Table 1. Per- formance is measured through unlabeled accuracy,  which is the percentage of words that modify the  correct head in the dependency graph, and labeled  accuracy, which is the percentage of words that  modify the correct head and label the dependency  edge correctly in the graph. These results show that  the discriminative spanning tree parsing framework  (", "labels": [], "entities": [{"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9082534313201904}, {"text": "accuracy", "start_pos": 166, "end_pos": 174, "type": "METRIC", "confidence": 0.5155172348022461}, {"text": "discriminative spanning tree parsing", "start_pos": 323, "end_pos": 359, "type": "TASK", "confidence": 0.6952115148305893}]}, {"text": " Table 2: Error analysis of parser components av- eraged over Arabic, Bulgarian, Danish, Dutch,  Japanese, Portuguese, Slovene, Spanish, Swedish  and Turkish. N/P: Allow non-projective/Force pro- jective, S/A: Sequential labeling/Atomic labeling,  M/B: Include morphology features/No morphology  features.", "labels": [], "entities": []}]}