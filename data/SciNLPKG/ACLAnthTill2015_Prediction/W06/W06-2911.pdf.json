{"title": [{"text": "Applying Alternating Structure Optimization to Word Sense Disambiguation", "labels": [], "entities": [{"text": "Applying Alternating Structure Optimization", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.7594261169433594}, {"text": "Word Sense Disambiguation", "start_pos": 47, "end_pos": 72, "type": "TASK", "confidence": 0.5839036107063293}]}], "abstractContent": [{"text": "This paper presents anew application of the recently proposed machine learning method Alternating Structure Optimization (ASO), to word sense disambiguation (WSD).", "labels": [], "entities": [{"text": "Alternating Structure Optimization (ASO)", "start_pos": 86, "end_pos": 126, "type": "TASK", "confidence": 0.7294149100780487}, {"text": "word sense disambiguation (WSD)", "start_pos": 131, "end_pos": 162, "type": "TASK", "confidence": 0.8019111007452011}]}, {"text": "Given a set of WSD problems and their respective labeled examples, we seek to improve overall performance on that set by using all the labeled examples (irrespective of target words) for the entire set in learning a disambiguator for each individual problem.", "labels": [], "entities": [{"text": "WSD", "start_pos": 15, "end_pos": 18, "type": "TASK", "confidence": 0.9371543526649475}]}, {"text": "Thus, in effect, on each individual problem (e.g., disam-biguation of \"art\") we benefit from training examples for other problems (e.g., disambiguation of \"bar\", \"canal\", and so forth).", "labels": [], "entities": []}, {"text": "We empirically study the effective use of ASO for this purpose in the multi-task and semi-supervised learning configurations.", "labels": [], "entities": []}, {"text": "Our performance results rival or exceed those of the previous best systems on several Senseval lexical sample task data sets.", "labels": [], "entities": [{"text": "Senseval lexical sample task data sets", "start_pos": 86, "end_pos": 124, "type": "DATASET", "confidence": 0.6357535670200983}]}], "introductionContent": [{"text": "Word sense disambiguation (WSD) is the task of assigning pre-defined senses to words occurring in some context.", "labels": [], "entities": [{"text": "Word sense disambiguation (WSD)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8121441056330999}, {"text": "assigning pre-defined senses to words occurring in some context", "start_pos": 47, "end_pos": 110, "type": "TASK", "confidence": 0.4912073678440518}]}, {"text": "An example is to disambiguate an occurrence of \"bank\" between the \"money bank\" sense and the \"river bank\" sense.", "labels": [], "entities": []}, {"text": "Previous studies e.g., (), have applied supervised learning techniques to WSD with success.", "labels": [], "entities": [{"text": "WSD", "start_pos": 74, "end_pos": 77, "type": "TASK", "confidence": 0.9761808514595032}]}, {"text": "A practical issue that arises in supervised WSD is the paucity of labeled examples (sense-annotated data) available for training.", "labels": [], "entities": [{"text": "WSD", "start_pos": 44, "end_pos": 47, "type": "TASK", "confidence": 0.9046161770820618}]}, {"text": "For example, the training set of the Senseval-2 1 English lexical sample http://www.cs.unt.edu/\ud97b\udf59rada/senseval/.", "labels": [], "entities": []}, {"text": "WSD systems have task has only 10 labeled training examples per sense on average, which is in contrast to nearly 6K training examples per name class (on average) used for the CoNLL-2003 named entity chunking shared task 2 . One problem is that there are so many words and so many senses that it is hard to make available a sufficient number of labeled training examples for each of a large number of target words.", "labels": [], "entities": [{"text": "CoNLL-2003 named entity chunking shared task", "start_pos": 175, "end_pos": 219, "type": "TASK", "confidence": 0.7963067293167114}]}, {"text": "On the other hand, this indicates that the total number of available labeled examples (irrespective of target words) can be relatively large.", "labels": [], "entities": []}, {"text": "A natural question to ask is whether we can effectively use all the labeled examples (irrespective of target words) for learning on each individual WSD problem.", "labels": [], "entities": [{"text": "WSD problem", "start_pos": 148, "end_pos": 159, "type": "TASK", "confidence": 0.9229362607002258}]}, {"text": "Based on these observations, we study anew application of Alternating Structure Optimization (ASO)) to WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 103, "end_pos": 106, "type": "TASK", "confidence": 0.9378350377082825}]}, {"text": "ASO is a recently proposed machine learning method for learning predictive structure (i.e., information useful for predictions) shared by multiple prediction problems via joint empirical risk minimization.", "labels": [], "entities": []}, {"text": "It has been shown that on several tasks, performance can be significantly improved by a semi-supervised application of ASO, which obtains useful information from unlabeled data by learning automatically created prediction problems.", "labels": [], "entities": []}, {"text": "In addition to such semi-supervised learning, this paper explores ASO multi-task learning, which learns a number of WSD problems simultaneously to exploit the inherent predictive structure shared by these WSD problems.", "labels": [], "entities": [{"text": "ASO multi-task learning", "start_pos": 66, "end_pos": 89, "type": "TASK", "confidence": 0.891588826974233}]}, {"text": "Thus, in effect, each individual problem (e.g., disambiguation of \"art\") benefits from labeled training examples for other problems (e.g., disambiguation of \"bar\", disambiguation of \"canal\", and so forth).", "labels": [], "entities": []}, {"text": "The notion of benefiting from training data for other word senses is not new by itself.", "labels": [], "entities": []}, {"text": "For instance, been evaluated in the series of Senseval workshops.", "labels": [], "entities": []}, {"text": "2 http://www.cnts.ua.ac.be/conll2003/ner/ on the WSD task with respect to WordNet synsets, trained classifiers for the top-level synsets of the WordNet semantic hierarchy, consolidating labeled examples associated with the WordNet sub-trees.", "labels": [], "entities": []}, {"text": "To disambiguate test instances, these coarse-grained classifiers are first applied, and then fine-grained senses are determined using a heuristic mapping.", "labels": [], "entities": []}, {"text": "By contrast, our approach does not require pre-defined relations among senses such as the WordNet hierarchy.", "labels": [], "entities": [{"text": "WordNet hierarchy", "start_pos": 90, "end_pos": 107, "type": "DATASET", "confidence": 0.9066581428050995}]}, {"text": "Rather, we let the machine learning algorithm ASO automatically and implicitly find relations with respect to the disambiguation problems (i.e., finding shared predictive structure).", "labels": [], "entities": []}, {"text": "Interestingly, in our experiments, seemingly unrelated or only loosely related wordsense pairs help to improve performance.", "labels": [], "entities": []}, {"text": "This paper makes two contributions.", "labels": [], "entities": []}, {"text": "First, we present anew application of ASO to WSD.", "labels": [], "entities": [{"text": "ASO", "start_pos": 38, "end_pos": 41, "type": "TASK", "confidence": 0.6583055853843689}, {"text": "WSD", "start_pos": 45, "end_pos": 48, "type": "TASK", "confidence": 0.6944090723991394}]}, {"text": "We empirically study the effective use of ASO and show that labeled examples of all the words can be effectively exploited in learning each individual disambiguator.", "labels": [], "entities": [{"text": "ASO", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.8923797607421875}]}, {"text": "Second, we report performance results that rival or exceed the state-of-the-art systems on Senseval lexical sample tasks.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we evaluate the methods developed on the Senseval-2 data set above on the standard Senseval-3 lexical sample tasks.", "labels": [], "entities": [{"text": "Senseval-2 data set", "start_pos": 58, "end_pos": 77, "type": "DATASET", "confidence": 0.9124230146408081}]}, {"text": "We conduct evaluations on four Senseval-3 lexical sample tasks (English, Catalan, Italian, and Spanish) using the official training / test splits.", "labels": [], "entities": []}, {"text": "Data statistics are shown in.", "labels": [], "entities": []}, {"text": "On the Spanish, Catalan, and Italian data sets, we use part-of-speech information (as features) and unlabeled examples (for semi-supervised learning) provided by the organizer.", "labels": [], "entities": []}, {"text": "Since the English data set was not provided with these additional resources, we use an in-house POS tagger trained with the PennTree Bank corpus, and extract 100K unlabeled examples from the Reuters-RCV1 corpus.", "labels": [], "entities": [{"text": "English data set", "start_pos": 10, "end_pos": 26, "type": "DATASET", "confidence": 0.7979961236317953}, {"text": "PennTree Bank corpus", "start_pos": 124, "end_pos": 144, "type": "DATASET", "confidence": 0.9952881137530009}, {"text": "Reuters-RCV1 corpus", "start_pos": 191, "end_pos": 210, "type": "DATASET", "confidence": 0.9717437624931335}]}, {"text": "On each language, the number of unlabeled examples is 5-15 times larger than that of the labeled training examples.", "labels": [], "entities": []}, {"text": "We use syntactic relation features only for English data set.", "labels": [], "entities": [{"text": "English data set", "start_pos": 44, "end_pos": 60, "type": "DATASET", "confidence": 0.7757678627967834}]}, {"text": "As in Section 3, we report micro-averaged F measure.", "labels": [], "entities": [{"text": "F measure", "start_pos": 42, "end_pos": 51, "type": "METRIC", "confidence": 0.9374024271965027}]}, {"text": "single-task baseline on all the data sets.", "labels": [], "entities": []}, {"text": "The best performance is achieved when we combine multitask learning and semi-supervised learning by using all the corresponding structure matrices \u00a2 \u00b4\ud97b\udf59\ud97b\udf59\u00d7\u00b5 produced by both multi-task and semi-supervised learning, in the final predictors.", "labels": [], "entities": []}, {"text": "This combined configuration outperforms the single-task supervised baseline by up to 5.7%.", "labels": [], "entities": []}, {"text": "Performance improvements over the supervised baseline are relatively small on English and Spanish.", "labels": [], "entities": []}, {"text": "We conjecture that this is because the supervised performance is already close to the highest performance that automatic methods could achieve.", "labels": [], "entities": []}, {"text": "On these two languages, our (and previous) systems outperform inter-human agreement, which is unusual but can be regarded as an indication that these tasks are difficult.", "labels": [], "entities": []}, {"text": "The performance of the output-based method (baseline) is relatively low.", "labels": [], "entities": []}, {"text": "This indicates that output values or proposed labels are not expressive enough to integrate information from other predictors effectively on this task.", "labels": [], "entities": []}, {"text": "We conjecture that for this method to be effective, the problems are required to be more closely related to each other as in's named entity experiments.", "labels": [], "entities": []}, {"text": "A practical advantage of ASO multi-task learning over ASO semi-supervised learning is that shorter computation time is required to produce similar performance.", "labels": [], "entities": [{"text": "ASO multi-task learning", "start_pos": 25, "end_pos": 48, "type": "TASK", "confidence": 0.872793436050415}]}, {"text": "On this English data set, training for multi-task learning and semi-supervised learning takes 15 minutes and 92 minutes, respectively, using a Pentium-4 3.20GHz computer.", "labels": [], "entities": [{"text": "English data set", "start_pos": 8, "end_pos": 24, "type": "DATASET", "confidence": 0.787635733683904}]}, {"text": "The computation time mostly depends on the amount of the data on which auxiliary predictors are learned.", "labels": [], "entities": []}, {"text": "Since our experiments use unlabeled data 5-15 times larger than labeled training data, semi-supervised learning takes longer, accordingly.", "labels": [], "entities": []}, {"text": "GGS05 combined various kernels, which includes the LSA kernel that exploits unlabeled data with global context features.", "labels": [], "entities": [{"text": "GGS05", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9693629145622253}]}, {"text": "Our implementation of the LSA kernel with our classifier (and our other features) also produced performance similar to that of GGS05.", "labels": [], "entities": [{"text": "GGS05", "start_pos": 127, "end_pos": 132, "type": "DATASET", "confidence": 0.9426727294921875}]}, {"text": "While the LSA kernel is closely related to a special case of the semi-supervised application of ASO (see the discussion of PCA in), our approach here is more general in that we exploit not only unlabeled data and global context features but also the labeled examples of other target words and other types of features.", "labels": [], "entities": []}, {"text": "G04 achieved high performance on English using regularized least squares with compensation for skewed class distributions.", "labels": [], "entities": [{"text": "G04", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8954841494560242}]}, {"text": "SGG04 is an early version of GGS05.", "labels": [], "entities": [{"text": "SGG04", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9153200387954712}, {"text": "GGS05", "start_pos": 29, "end_pos": 34, "type": "DATASET", "confidence": 0.9748871922492981}]}, {"text": "Our methods rival or exceed these stateof-the-art systems on all the data sets.", "labels": [], "entities": []}], "tableCaptions": []}