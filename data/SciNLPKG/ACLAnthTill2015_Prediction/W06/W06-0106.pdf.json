{"title": [{"text": "A Clustering Approach for Unsupervised Chinese Coreference Resolution", "labels": [], "entities": [{"text": "Chinese Coreference Resolution", "start_pos": 39, "end_pos": 69, "type": "TASK", "confidence": 0.6826264063517252}]}], "abstractContent": [{"text": "Coreference resolution is the process of identifying expressions that refer to the same entity.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9109207391738892}]}, {"text": "This paper presents a clustering algorithm for unsupervised Chinese coreference resolution.", "labels": [], "entities": [{"text": "Chinese coreference resolution", "start_pos": 60, "end_pos": 90, "type": "TASK", "confidence": 0.6992200811704}]}, {"text": "We investigate why Chinese coreference is hard and demonstrate that techniques used in coreference resolution for English can be extended to Chinese.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 87, "end_pos": 109, "type": "TASK", "confidence": 0.9389433860778809}]}, {"text": "The proposed system exploits clustering as it has advantages over traditional classification methods, such as the fact that no training data is required and it is easily extended to accommodate additional features.", "labels": [], "entities": []}, {"text": "We conduct a set of experiments to investigate how noun phrase identification and feature selection can contribute to coreference resolution performance.", "labels": [], "entities": [{"text": "noun phrase identification", "start_pos": 51, "end_pos": 77, "type": "TASK", "confidence": 0.7420493563016256}, {"text": "coreference resolution", "start_pos": 118, "end_pos": 140, "type": "TASK", "confidence": 0.9511093199253082}]}, {"text": "Our system is evaluated on an annotated version of the TDT3 corpus using the MUC-7 scorer, and obtains comparable performance.", "labels": [], "entities": [{"text": "TDT3 corpus", "start_pos": 55, "end_pos": 66, "type": "DATASET", "confidence": 0.975972592830658}, {"text": "MUC-7 scorer", "start_pos": 77, "end_pos": 89, "type": "DATASET", "confidence": 0.9111873507499695}]}, {"text": "We believe that this is the first attempt at an unsupervised approach to Chi-nese noun phrase coreference resolution.", "labels": [], "entities": [{"text": "Chi-nese noun phrase coreference resolution", "start_pos": 73, "end_pos": 116, "type": "TASK", "confidence": 0.6496236026287079}]}], "introductionContent": [{"text": "Noun phrase coreference resolution is the process of detecting noun phrases (NPs) in a document and determining whether the NPs refer to the same entity, where an entity is defined as \"a construct that represents an abstract identity\".", "labels": [], "entities": [{"text": "Noun phrase coreference resolution", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.7914508730173111}]}, {"text": "The NPs that refer to the entity are known as mentions.", "labels": [], "entities": []}, {"text": "Mentions can be antecedents or anaphors.", "labels": [], "entities": []}, {"text": "An anaphor is an expression that refers back to a previous expression in a discourse.", "labels": [], "entities": []}, {"text": "In, \ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59 (President Clinton) refers to \ud97b\udf59\ud97b\udf59\ud97b\udf59 (Clinton) and is described as an anaphoric reference to\ud97b\udf59\ud97b\udf59\ud97b\udf59 (Clinton).", "labels": [], "entities": []}, {"text": "\ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59 \ud97b\udf59 (President Clinton) is described as the antecedent of \ud97b\udf59 (he).", "labels": [], "entities": []}, {"text": "\ud97b\udf59\ud97b\udf59\ud97b\udf59 (Clinton), \ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59 (President Clinton) and the second \ud97b\udf59 (he) are all mentions of the same entity that refers to former U.S. president Bill Clinton.", "labels": [], "entities": []}, {"text": "NP coreference resolution is an important subtask in natural language processing (NLP) applications such as text summarization, information extraction, data mining and question answering.", "labels": [], "entities": [{"text": "NP coreference resolution", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.8627379337946574}, {"text": "text summarization", "start_pos": 108, "end_pos": 126, "type": "TASK", "confidence": 0.7409315407276154}, {"text": "information extraction", "start_pos": 128, "end_pos": 150, "type": "TASK", "confidence": 0.829320877790451}, {"text": "data mining", "start_pos": 152, "end_pos": 163, "type": "TASK", "confidence": 0.8103621602058411}, {"text": "question answering", "start_pos": 168, "end_pos": 186, "type": "TASK", "confidence": 0.9190559685230255}]}, {"text": "This task has attracted much attention in recent years (, and has been included as a subtask in the MUC (Message Understanding Conferences) and ACE (Automatic Content Extraction) competitions.", "labels": [], "entities": [{"text": "MUC (Message Understanding Conferences) and ACE (Automatic Content Extraction)", "start_pos": 100, "end_pos": 178, "type": "TASK", "confidence": 0.5784802872401017}]}, {"text": "Coreference resolution is a difficult task for various reasons.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.949592649936676}]}, {"text": "Firstly, a list of features can play a role to support coreference resolution such as  gender agreement, number agreement, head noun matches, semantic class, positional information, contextual information, appositive, abbreviation etc.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 55, "end_pos": 77, "type": "TASK", "confidence": 0.864530086517334}]}, {"text": "found 53 features which are useful for this problem.", "labels": [], "entities": []}, {"text": "However, no single feature is completely reliable since there are always exceptions: e.g. the number agreement test returns false when \ud97b\udf59 \ud97b\udf59\ud97b\udf59 \ud97b\udf59 (this army, singular) is matched against \ud97b\udf59\ud97b\udf59\ud97b\udf59 (army members, plural), despite the two phrases being coreferential.", "labels": [], "entities": []}, {"text": "Secondly, identifying features automatically and accurately is hard.", "labels": [], "entities": []}, {"text": "Features such as semantic class come from named entity recognition (NER) systems and ontologies and gazetteers, but they are not always accurate, especially where new terms are concerned.", "labels": [], "entities": [{"text": "named entity recognition (NER)", "start_pos": 42, "end_pos": 72, "type": "TASK", "confidence": 0.8312146464983622}]}, {"text": "Thirdly, coreference resolution subsumes the pronoun resolution problem, which is already difficult since pronouns carry limited lexical and semantic information.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 9, "end_pos": 31, "type": "TASK", "confidence": 0.9802195429801941}, {"text": "pronoun resolution", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.7828168272972107}]}, {"text": "In addition to the aforementioned, Chinese coreference resolution is also made more difficult due to the lack of morphological and orthographic clues.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 43, "end_pos": 65, "type": "TASK", "confidence": 0.8425046801567078}]}, {"text": "Chinese words contain less exterior information than words in many Indoeuropean languages.", "labels": [], "entities": []}, {"text": "For example, in English, number agreement can be detected through word inflections and part-of-speech (POS) tags, but there are no simple rules in Chinese to distinguish whether a word is singular or plural.", "labels": [], "entities": []}, {"text": "Proper name and abbreviations are identified by capitalization in English, but Chinese does not use capitalization.", "labels": [], "entities": []}, {"text": "Moreover, written Chinese does not have word boundaries, so word segmentation is a crucial problem, as we cannot get the true meaning of the sentence based on characters alone.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 60, "end_pos": 77, "type": "TASK", "confidence": 0.7160697281360626}]}, {"text": "A simple sentence can be segmented in several different ways to get different meanings.", "labels": [], "entities": []}, {"text": "This characteristic affects the performance of all parts and leads to irrecoverable errors.", "labels": [], "entities": []}, {"text": "In addition, there are very few Chinese coreference data sets available for research purposes (none of them freely available) and as a result, no easily obtainable benchmarking dataset for training and measuring performance.", "labels": [], "entities": [{"text": "Chinese coreference data sets", "start_pos": 32, "end_pos": 61, "type": "DATASET", "confidence": 0.7391776144504547}]}, {"text": "Building a reasonably large coreference corpus is a labor-consuming task.", "labels": [], "entities": []}, {"text": "To our knowledge, there have only been two Chinese coreference systems in previously published work:, which presents a statistical framework and reports experiment results on Chinese texts; and, which proposed a unified transformation based learning framework for Chinese entity detection and tracking.", "labels": [], "entities": [{"text": "Chinese entity detection and tracking", "start_pos": 264, "end_pos": 301, "type": "TASK", "confidence": 0.695169061422348}]}, {"text": "It consists of two models: the detection model locates possibly coreferring NPs and the tracking model links the coreference relations.", "labels": [], "entities": []}, {"text": "This paper presents research performed on Chinese noun phrase coreference resolution.", "labels": [], "entities": [{"text": "Chinese noun phrase coreference resolution", "start_pos": 42, "end_pos": 84, "type": "TASK", "confidence": 0.7042553007602692}]}, {"text": "Since there are no freely available Chinese coreference resources, we used an unsupervised method that partially borrows from Cardie and clustering-based technique, with features that are specially designed for Chinese.", "labels": [], "entities": []}, {"text": "In addition, we perform and present the results of experiments designed to investigate the contribution of each feature.", "labels": [], "entities": []}], "datasetContent": [{"text": "Identifying coreferent NPs in an unannotated document actually involves two tasks: mention detection, which identifies the anaphors and antecedents in a document, followed by noun phrase coreference resolution.", "labels": [], "entities": [{"text": "Identifying coreferent NPs in an unannotated document", "start_pos": 0, "end_pos": 53, "type": "TASK", "confidence": 0.8266550217356}, {"text": "mention detection", "start_pos": 83, "end_pos": 100, "type": "TASK", "confidence": 0.6670722961425781}, {"text": "noun phrase coreference resolution", "start_pos": 175, "end_pos": 209, "type": "TASK", "confidence": 0.6741126179695129}]}, {"text": "In order to reduce the complexity of the final system, we follow the usual approach in handling these two phases separately.", "labels": [], "entities": []}, {"text": "Evaluation of coreference resolution systems has traditionally been performed with precision and recall.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 14, "end_pos": 36, "type": "TASK", "confidence": 0.9427751302719116}, {"text": "precision", "start_pos": 83, "end_pos": 92, "type": "METRIC", "confidence": 0.9996110796928406}, {"text": "recall", "start_pos": 97, "end_pos": 103, "type": "METRIC", "confidence": 0.9987431168556213}]}, {"text": "The MUC competition defines recall as follows (: Each Ci is a gold standard cluster (i.e. a set of phrases which we know refer to the same entity), and p(C i ) is the partitioning of Ci by the automatically-generated clusters.", "labels": [], "entities": [{"text": "MUC competition", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.8263617157936096}, {"text": "recall", "start_pos": 28, "end_pos": 34, "type": "METRIC", "confidence": 0.9610744118690491}]}, {"text": "For precision, the role of the automatic and gold standard clusters are reversed.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9691343307495117}]}, {"text": "Our results were evaluated using the MUC scoring program which reports recall, precision and F-measure, where the F-measure is defined as the harmonic mean of precision and recall: presents the results of our coreference resolution system on the outputs of both the parsing-based and heuristic-based entity detection systems, as measured by the MUC-7 scoring program.", "labels": [], "entities": [{"text": "MUC scoring program", "start_pos": 37, "end_pos": 56, "type": "DATASET", "confidence": 0.881034235159556}, {"text": "recall", "start_pos": 71, "end_pos": 77, "type": "METRIC", "confidence": 0.9981372356414795}, {"text": "precision", "start_pos": 79, "end_pos": 88, "type": "METRIC", "confidence": 0.9989385008811951}, {"text": "F-measure", "start_pos": 93, "end_pos": 102, "type": "METRIC", "confidence": 0.9937731623649597}, {"text": "F-measure", "start_pos": 114, "end_pos": 123, "type": "METRIC", "confidence": 0.9875285625457764}, {"text": "precision", "start_pos": 159, "end_pos": 168, "type": "METRIC", "confidence": 0.994056224822998}, {"text": "recall", "start_pos": 173, "end_pos": 179, "type": "METRIC", "confidence": 0.9787367582321167}, {"text": "coreference resolution", "start_pos": 209, "end_pos": 231, "type": "TASK", "confidence": 0.8193524479866028}, {"text": "parsing-based and heuristic-based entity detection", "start_pos": 266, "end_pos": 316, "type": "TASK", "confidence": 0.6285721838474274}, {"text": "MUC-7 scoring program", "start_pos": 345, "end_pos": 366, "type": "DATASET", "confidence": 0.936710258324941}]}, {"text": "For the purposes of comparison, we also present results of our clustering algorithm on the gold standard entities.", "labels": [], "entities": [{"text": "gold standard entities", "start_pos": 91, "end_pos": 113, "type": "DATASET", "confidence": 0.8291408022244772}]}, {"text": "This gives us a sense of the upper bound that we could potentially achieve if we got 100% accuracy on our mention detection phase.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.9992802739143372}, {"text": "mention detection", "start_pos": 106, "end_pos": 123, "type": "TASK", "confidence": 0.7949303090572357}]}, {"text": "An additional baseline is generated by implementing a system that assumes that all phrases refer to the same entityi.e. it takes all the heuristically-generated phrases and puts them into one big cluster.", "labels": [], "entities": []}, {"text": "This gives us an upper bound on the recall of the system.", "labels": [], "entities": [{"text": "recall", "start_pos": 36, "end_pos": 42, "type": "METRIC", "confidence": 0.9992901086807251}]}, {"text": "Yet another baseline, to see how easy the task is, is to merge mentions together if the \"Noun Phrase Match\" function tests true.", "labels": [], "entities": []}, {"text": "From the results, it can be seen that our system achieves a performance gain of over 10 FMeasure points over the simplest baseline, and over 8 F-Measure points over the more sophisticated baseline.", "labels": [], "entities": [{"text": "FMeasure", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.9844302535057068}, {"text": "F-Measure", "start_pos": 143, "end_pos": 152, "type": "METRIC", "confidence": 0.9932716488838196}]}, {"text": "Unfortunately, due to corpus differences, we cannot conduct a comparison with results found in previous work.", "labels": [], "entities": []}, {"text": "An interesting observation is the fact that the heuristic-based entity recognizer achieves better performance than the one based on statistical parsing.", "labels": [], "entities": [{"text": "entity recognizer", "start_pos": 64, "end_pos": 81, "type": "TASK", "confidence": 0.6507103145122528}]}, {"text": "The parser is trained on the Chinese Penn Treebank, which tends to have relatively longer noun phrases, and as result, the phrases generated by the parser also tend to be on the long side.", "labels": [], "entities": [{"text": "Chinese Penn Treebank", "start_pos": 29, "end_pos": 50, "type": "DATASET", "confidence": 0.8925949732462565}]}, {"text": "This causes errors at the entity recognition phase, which results in a performance hit for the overall system.", "labels": [], "entities": [{"text": "entity recognition", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.8166126012802124}]}], "tableCaptions": [{"text": " Table 1: Mention Detection Results", "labels": [], "entities": [{"text": "Mention Detection", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.8377009332180023}]}, {"text": " Table 3: Coreference Resolution Performance", "labels": [], "entities": [{"text": "Coreference Resolution", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.9730311036109924}]}, {"text": " Table 4: Contribution of individual features to overall performance.", "labels": [], "entities": []}]}