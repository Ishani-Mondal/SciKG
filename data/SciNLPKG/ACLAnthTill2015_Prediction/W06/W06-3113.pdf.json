{"title": [{"text": "How Many Bits Are Needed To Store Probabilities for Phrase-Based Translation?", "labels": [], "entities": [{"text": "Phrase-Based Translation", "start_pos": 52, "end_pos": 76, "type": "TASK", "confidence": 0.8474881947040558}]}], "abstractContent": [{"text": "State of the art in statistical machine translation is currently represented by phrase-based models, which typically incorporate a large number of probabilities of phrase-pairs and word n-grams.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 20, "end_pos": 51, "type": "TASK", "confidence": 0.6416285137335459}]}, {"text": "In this work, we investigate data compression methods for efficiently encoding n-gram and phrase-pair probabilities, that are usually encoded in 32-bit floating point numbers.", "labels": [], "entities": [{"text": "data compression", "start_pos": 29, "end_pos": 45, "type": "TASK", "confidence": 0.7448627352714539}]}, {"text": "We measured the impact of compression on translation quality through a phrase-based decoder trained on two distinct tasks: the translation of European Parliament speeches from Spanish to En-glish, and the translation of news agencies from Chinese to English.", "labels": [], "entities": [{"text": "translation of European Parliament speeches from Spanish to En-glish", "start_pos": 127, "end_pos": 195, "type": "TASK", "confidence": 0.8070812622706095}, {"text": "translation of news agencies from Chinese to English", "start_pos": 205, "end_pos": 257, "type": "TASK", "confidence": 0.8114675208926201}]}, {"text": "We show that with a very simple quantization scheme all probabilities can be encoded in just 4 bits with a relative loss in BLEU score on the two tasks by 1.0% and 1.6%, respectively.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 124, "end_pos": 128, "type": "METRIC", "confidence": 0.9997487664222717}]}], "introductionContent": [{"text": "In several natural language processing tasks, such as automatic speech recognition and machine translation, state-of-the-art systems rely on the statistical approach.", "labels": [], "entities": [{"text": "automatic speech recognition", "start_pos": 54, "end_pos": 82, "type": "TASK", "confidence": 0.667245090007782}, {"text": "machine translation", "start_pos": 87, "end_pos": 106, "type": "TASK", "confidence": 0.755100816488266}]}, {"text": "Statistical machine translation (SMT) is based on parametric models incorporating a large number of observations and probabilities estimated from monolingual and parallel texts.", "labels": [], "entities": [{"text": "Statistical machine translation (SMT)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8332186490297318}]}, {"text": "The current state of the art is represented by the so-called phrase-based translation approach (.", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 61, "end_pos": 85, "type": "TASK", "confidence": 0.8108792901039124}]}, {"text": "Its core components area translation model that contains probabilities of phrase-pairs, and a language model that incorporates probabilities of word n-grams.", "labels": [], "entities": []}, {"text": "Due to the intrinsic data-sparseness of language corpora, the set of observations increases almost linearly with the size of the training data.", "labels": [], "entities": []}, {"text": "Hence, to efficiently store observations and probabilities in a computer memory the following approaches can be tackled: designing compact data-structures, pruning rare or unreliable observations, and applying data compression.", "labels": [], "entities": [{"text": "data compression", "start_pos": 210, "end_pos": 226, "type": "TASK", "confidence": 0.70463727414608}]}, {"text": "In this paper we only focus on the last approach.", "labels": [], "entities": []}, {"text": "We investigate two different quantization methods to encode probabilities and analyze their impact on translation performance.", "labels": [], "entities": []}, {"text": "In particular, we address the following questions: \u2022 How does probability quantization impact on the components of the translation system, namely the language model and the translation model?", "labels": [], "entities": []}, {"text": "\u2022 Which is the optimal trade-off between data compression and translation performance?", "labels": [], "entities": [{"text": "data compression", "start_pos": 41, "end_pos": 57, "type": "TASK", "confidence": 0.7284476459026337}]}, {"text": "\u2022 How do quantized models perform under different data-sparseness conditions?", "labels": [], "entities": []}, {"text": "\u2022 Is the impact of quantization consistent across different translation tasks?", "labels": [], "entities": []}, {"text": "Experiments were performed with our phrasebased SMT system ) on two large-vocabulary tasks: the translation of European Parliament Plenary Sessions from Spanish to English, and the translation of news agencies from Chinese to English, according to the setup defined by the 2005 NIST MT Evaluation Workshop.", "labels": [], "entities": [{"text": "SMT", "start_pos": 48, "end_pos": 51, "type": "TASK", "confidence": 0.8398134708404541}, {"text": "translation of European Parliament Plenary Sessions from Spanish to English", "start_pos": 96, "end_pos": 171, "type": "TASK", "confidence": 0.8832543194293976}, {"text": "translation of news agencies from Chinese to English", "start_pos": 181, "end_pos": 233, "type": "TASK", "confidence": 0.8643256425857544}, {"text": "NIST MT Evaluation Workshop", "start_pos": 278, "end_pos": 305, "type": "DATASET", "confidence": 0.7304278612136841}]}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 reviews previous work addressing efficiency in speech recognition and information retrieval.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 57, "end_pos": 75, "type": "TASK", "confidence": 0.8592166900634766}, {"text": "information retrieval", "start_pos": 80, "end_pos": 101, "type": "TASK", "confidence": 0.7837063074111938}]}, {"text": "Section 3 introduces the two quantization methods considered in this paper, namely the Lloyd's algorithm and the Binning method.", "labels": [], "entities": []}, {"text": "Section 4 briefly describes our phrase-based SMT system.", "labels": [], "entities": [{"text": "SMT", "start_pos": 45, "end_pos": 48, "type": "TASK", "confidence": 0.8503822088241577}]}, {"text": "Sections 5 reports and discusses experimental results addressing the questions in the introduction.", "labels": [], "entities": []}, {"text": "Finally, Section 6 draws some conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "We performed experiments on two large vocabulary translation tasks: the translation of European Parliamentary Plenary Sessions (EPPS) () from Spanish to English, and the translation of documents from Chinese to English as proposed by the NIST MT Evaluation Workshops 3 . Translation of EPPS is performed on the so-called final text editions, which are prepared by the translation office of the European Parliament.", "labels": [], "entities": [{"text": "translation of European Parliamentary Plenary Sessions (EPPS)", "start_pos": 72, "end_pos": 133, "type": "TASK", "confidence": 0.6984068751335144}, {"text": "NIST MT Evaluation Workshops", "start_pos": 238, "end_pos": 266, "type": "DATASET", "confidence": 0.8268567770719528}, {"text": "Translation of EPPS", "start_pos": 271, "end_pos": 290, "type": "TASK", "confidence": 0.7738118370374044}]}, {"text": "Both the training and testing data were collected by the TC-STAR 4 project and were made freely available to participants in the 2006 TC-STAR Evaluation Campaign.", "labels": [], "entities": [{"text": "TC-STAR 4 project", "start_pos": 57, "end_pos": 74, "type": "DATASET", "confidence": 0.8799102306365967}, {"text": "TC-STAR Evaluation Campaign", "start_pos": 134, "end_pos": 161, "type": "DATASET", "confidence": 0.8050639828046163}]}, {"text": "In order to perform experiments under different data sparseness conditions, four subsamples of the training data with different sizes were generated, too.", "labels": [], "entities": []}, {"text": "Training reports statistics about the training data of each task and the models estimated on them.", "labels": [], "entities": []}, {"text": "That is, the number of running words of source and target languages, the number of n-grams in the language model and the number phrase-pairs in the translation model.", "labels": [], "entities": []}, {"text": "reports instead statistics about the test sets, namely, the number of source sentences and running words in the source part and in the gold reference translations.", "labels": [], "entities": []}, {"text": "Translation performance was measured in terms of BLEU score, NIST score, word-error rate (WER), and position independent error rate (PER).", "labels": [], "entities": [{"text": "Translation", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9536570906639099}, {"text": "BLEU score", "start_pos": 49, "end_pos": 59, "type": "METRIC", "confidence": 0.9848025143146515}, {"text": "NIST score", "start_pos": 61, "end_pos": 71, "type": "METRIC", "confidence": 0.6125393807888031}, {"text": "word-error rate (WER)", "start_pos": 73, "end_pos": 94, "type": "METRIC", "confidence": 0.92421452999115}, {"text": "position independent error rate (PER)", "start_pos": 100, "end_pos": 137, "type": "METRIC", "confidence": 0.9188434141022819}]}, {"text": "Score computation relied on two and four reference translations per sentence, respectively, for the EPPS and NIST tasks.", "labels": [], "entities": [{"text": "EPPS", "start_pos": 100, "end_pos": 104, "type": "DATASET", "confidence": 0.8753835558891296}, {"text": "NIST", "start_pos": 109, "end_pos": 113, "type": "DATASET", "confidence": 0.6113653182983398}]}, {"text": "Scores were computed in caseinsensitive modality with punctuation.", "labels": [], "entities": []}, {"text": "In general, none of the above measures is alone sufficiently informative about translation quality, however, in the community there seems to be a preference toward reporting results with BLEU.", "labels": [], "entities": [{"text": "translation", "start_pos": 79, "end_pos": 90, "type": "TASK", "confidence": 0.9586502909660339}, {"text": "BLEU", "start_pos": 187, "end_pos": 191, "type": "METRIC", "confidence": 0.9933874607086182}]}, {"text": "Here, to be on the safe side and to better support our findings we will report results with all measures, but will limit discussion on performance to the BLEU score.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 154, "end_pos": 158, "type": "METRIC", "confidence": 0.9988481998443604}]}, {"text": "In order to just focus on the effect of quantiza-: BLEU scores in the EPPS task with different quantization levels of the LM and TM.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 51, "end_pos": 55, "type": "METRIC", "confidence": 0.9994257688522339}]}, {"text": "tion, all reported experiments were performed with a plain configuration of the ITC-irst SMT system.", "labels": [], "entities": [{"text": "ITC-irst SMT system", "start_pos": 80, "end_pos": 99, "type": "DATASET", "confidence": 0.7575691640377045}]}, {"text": "That is, we used a single decoding step, no phrase re-ordering, and task-dependent weights of the loglinear model.", "labels": [], "entities": []}, {"text": "Henceforth, LMs and TM quantized with h bits are denoted with LM-h and TM-h, respectively.", "labels": [], "entities": []}, {"text": "Non quantized models are indicated with LM-32 and TM-32.", "labels": [], "entities": [{"text": "TM-32", "start_pos": 50, "end_pos": 55, "type": "DATASET", "confidence": 0.8234564661979675}]}], "tableCaptions": [{"text": " Table 1: Figures (in thousand) regarding the training data of each translation task.", "labels": [], "entities": [{"text": "translation task", "start_pos": 68, "end_pos": 84, "type": "TASK", "confidence": 0.9082700312137604}]}, {"text": " Table 3: BLEU scores in the EPPS task with different quantization levels of the LM and TM.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9991324543952942}]}]}