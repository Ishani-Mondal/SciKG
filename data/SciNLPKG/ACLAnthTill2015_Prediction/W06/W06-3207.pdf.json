{"title": [{"text": "Richness of the Base and Probabilistic Unsupervised Learning in Optimality Theory", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper proposes an unsupervised learning algorithm for Optimality Theo-retic grammars, which learns a complete constraint ranking and a lexicon given only unstructured surface forms and morphological relations.", "labels": [], "entities": []}, {"text": "The learning algorithm , which is based on the Expectation-Maximization algorithm, gradually maximizes the likelihood of the observed forms by adjusting the parameters of a probabilistic constraint grammar and a probabilistic lexicon.", "labels": [], "entities": []}, {"text": "The paper presents the algorithm's results on three constructed language systems with different types of hidden structure: voicing neu-tralization, stress, and abstract vowels.", "labels": [], "entities": []}, {"text": "In all cases the algorithm learns the correct constraint ranking and lexicon.", "labels": [], "entities": []}, {"text": "The paper argues that the algorithm's ability to identify correct, restrictive grammars is due in part to its explicit reliance on the Opti-mality Theoretic notion of Richness of the Base.", "labels": [], "entities": []}], "introductionContent": [{"text": "In Optimality Theory or OT grammars are defined by a set of ranked universal and violable constraints.", "labels": [], "entities": [{"text": "Optimality Theory", "start_pos": 3, "end_pos": 20, "type": "TASK", "confidence": 0.7983583807945251}]}, {"text": "The function of the grammar is to map underlying or lexical forms to valid surface forms.", "labels": [], "entities": []}, {"text": "The task of the learner is to find the correct grammar, or correct ranking of constraints, as well as the set of underlying forms that correspond to overt surface forms given only the surface forms and the set of universal constraints.", "labels": [], "entities": []}, {"text": "The most well known algorithms for learning OT grammars) are supervised learners and focus on the task of learning the constraint ranking, given training pairs that map underlying forms to surface forms.", "labels": [], "entities": [{"text": "OT grammars", "start_pos": 44, "end_pos": 55, "type": "TASK", "confidence": 0.8190450072288513}]}, {"text": "Recent work has focused on the task of unsupervised learning of OT grammars, where only unstructured surface forms are provided to the learner.", "labels": [], "entities": [{"text": "OT grammars", "start_pos": 64, "end_pos": 75, "type": "TASK", "confidence": 0.886155903339386}]}, {"text": "Some of this work focuses on grammar learning without training data).", "labels": [], "entities": [{"text": "grammar learning", "start_pos": 29, "end_pos": 45, "type": "TASK", "confidence": 0.9326247274875641}]}, {"text": "The remainder of this work tackles the problem of learning the ranking and lexicon simultaneously, the problem addressed in the present paper (.", "labels": [], "entities": [{"text": "learning the ranking and lexicon", "start_pos": 50, "end_pos": 82, "type": "TASK", "confidence": 0.7039198398590087}]}, {"text": "These proposals adopt an algebraic approach wherein learning the lexicon involves iteratively eliminating potential underlying forms by determining that they have become logically impossible, given certain assumptions about the learning problem.", "labels": [], "entities": []}, {"text": "In particular, one simplifying assumption of previous work requires that mappings be one-to-one and onto.", "labels": [], "entities": []}, {"text": "This assumption prohibits input-output mappings with deletion and insertion as well as constraints that evaluate such mappings.", "labels": [], "entities": []}, {"text": "This work represents a leap forward toward the accurate modeling of human language acquisition, but the identification of a general-purpose, unsupervised learner of OT remains an open problem.", "labels": [], "entities": [{"text": "human language acquisition", "start_pos": 68, "end_pos": 94, "type": "TASK", "confidence": 0.6228198111057281}, {"text": "OT", "start_pos": 165, "end_pos": 167, "type": "TASK", "confidence": 0.8989623785018921}]}, {"text": "In contrast to previous work, this paper proposes a gradual, probabilistic algorithm for unsupervised OT learning based on the Expectation Maximization algorithm.", "labels": [], "entities": [{"text": "OT learning", "start_pos": 102, "end_pos": 113, "type": "TASK", "confidence": 0.9736613035202026}, {"text": "Expectation Maximization", "start_pos": 127, "end_pos": 151, "type": "TASK", "confidence": 0.7048278152942657}]}, {"text": "Because the algorithm depends on gradually maximizing an objective function, rather than on wholly eliminating logically impossible hypotheses, it is not crucial to prohibit insertion or deletion.", "labels": [], "entities": []}, {"text": "A major challenge posed by unsupervised learning of OT is that of learning restrictive grammars that generate only grammatical forms.", "labels": [], "entities": [{"text": "OT", "start_pos": 52, "end_pos": 54, "type": "TASK", "confidence": 0.924336314201355}]}, {"text": "In previous work, the preference for restrictive grammars is implemented by encoding a bias into the ranking algorithm that favors ranking constraints that prohibit marked structures as high as possible.", "labels": [], "entities": []}, {"text": "In contrast, the solution proposed here involves a combination of likelihood maximization and explicit reliance on Richness of the Base, an OT principle requiring that the set of potential underlying forms be universal.", "labels": [], "entities": []}, {"text": "This combination favors restrictive grammars because grammars that map a \"rich\" lexicon onto observed forms with high probability are preferred.", "labels": [], "entities": []}, {"text": "The proposed model is tested on three constructed language systems, each exemplifying a different type of hidden structure.", "labels": [], "entities": []}], "datasetContent": [{"text": "This section describes the results of experiments with three artificial language systems with different types of hidden structure.", "labels": [], "entities": []}, {"text": "In all experiments presented here, each unique surface form is assumed to occur with frequency 1.", "labels": [], "entities": []}], "tableCaptions": []}