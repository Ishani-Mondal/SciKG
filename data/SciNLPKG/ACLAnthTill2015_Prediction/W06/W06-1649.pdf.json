{"title": [{"text": "Partially Supervised Sense Disambiguation by Learning Sense Number from Tagged and Untagged Corpora", "labels": [], "entities": [{"text": "Supervised Sense Disambiguation", "start_pos": 10, "end_pos": 41, "type": "TASK", "confidence": 0.5865314404169718}]}], "abstractContent": [{"text": "Supervised and semi-supervised sense dis-ambiguation methods will mis-tag the instances of a target word if the senses of these instances are not defined in sense inventories or there are no tagged instances for these senses in training data.", "labels": [], "entities": []}, {"text": "Here we used a model order identification method to avoid the misclassification of the instances with undefined senses by discovering new senses from mixed data (tagged and untagged corpora).", "labels": [], "entities": [{"text": "model order identification", "start_pos": 15, "end_pos": 41, "type": "TASK", "confidence": 0.639821340640386}]}, {"text": "This algorithm tries to obtain a natural partition of the mixed data by maximizing a stability criterion defined on the classification result from an extended label propagation algorithm overall the possible values of the number of senses (or sense number, model order).", "labels": [], "entities": []}, {"text": "Experimental results on SENSEVAL-3 data indicate that it outper-forms SVM, a one-class partially supervised classification algorithm, and a clustering based model order identification algorithm when the tagged data is incomplete .", "labels": [], "entities": [{"text": "SENSEVAL-3 data", "start_pos": 24, "end_pos": 39, "type": "DATASET", "confidence": 0.8045628666877747}, {"text": "clustering based model order identification", "start_pos": 140, "end_pos": 183, "type": "TASK", "confidence": 0.6824911952018737}]}], "introductionContent": [{"text": "In this paper, we address the problem of partially supervised word sense disambiguation, which is to disambiguate the senses of occurrences of a target word in untagged texts when given incomplete tagged corpus . Word sense disambiguation can be defined as associating a target word in a text or discourse with a definition or meaning.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 62, "end_pos": 87, "type": "TASK", "confidence": 0.6868342657883962}, {"text": "Word sense disambiguation", "start_pos": 213, "end_pos": 238, "type": "TASK", "confidence": 0.6828167339166006}]}, {"text": "Many corpus based methods have been proposed to deal with the sense disambiguation problem when given definition for each possible sense of a target word or a tagged corpus with the instances of each possible sense, e.g., supervised sense disambiguation (, and semi-supervised sense disambiguation.", "labels": [], "entities": [{"text": "sense disambiguation", "start_pos": 62, "end_pos": 82, "type": "TASK", "confidence": 0.7477317452430725}, {"text": "supervised sense disambiguation", "start_pos": 222, "end_pos": 253, "type": "TASK", "confidence": 0.6524975697199503}, {"text": "semi-supervised sense disambiguation", "start_pos": 261, "end_pos": 297, "type": "TASK", "confidence": 0.7332314650217692}]}, {"text": "Supervised methods usually rely on the information from previously sense tagged corpora to determine the senses of words in unseen texts.", "labels": [], "entities": []}, {"text": "Semi-supervised methods for WSD are characterized in terms of exploiting unlabeled data in the learning procedure with the need of predefined sense inventories for target words.", "labels": [], "entities": [{"text": "WSD", "start_pos": 28, "end_pos": 31, "type": "TASK", "confidence": 0.9865266680717468}]}, {"text": "The information for semi-supervised sense disambiguation is usually obtained from bilingual corpora (e.g. parallel corpora or untagged monolingual corpora in two languages), or sense-tagged seed examples.", "labels": [], "entities": [{"text": "semi-supervised sense disambiguation", "start_pos": 20, "end_pos": 56, "type": "TASK", "confidence": 0.6923259099324545}]}, {"text": "Some observations can be made on the previous supervised and semi-supervised methods.", "labels": [], "entities": []}, {"text": "They always rely on hand-crafted lexicons (e.g., WordNet) as sense inventories.", "labels": [], "entities": []}, {"text": "But these resources may miss domain-specific senses, which leads to incomplete sense tagged corpus.", "labels": [], "entities": []}, {"text": "Therefore, sense taggers trained on the incomplete tagged corpus will misclassify some instances if the senses of these instances are not defined in sense inventories.", "labels": [], "entities": [{"text": "sense taggers", "start_pos": 11, "end_pos": 24, "type": "TASK", "confidence": 0.7186758071184158}]}, {"text": "For example, one performs WSD in information technology related texts using WordNet 2 as sense inventory.", "labels": [], "entities": [{"text": "WSD", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.9788468480110168}, {"text": "WordNet 2", "start_pos": 76, "end_pos": 85, "type": "DATASET", "confidence": 0.9116101861000061}]}, {"text": "When disambiguating the word \"boot\" in the phrase \"boot sector\", the sense tagger will assign this instance with one of the senses of \"boot\" listed in WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 151, "end_pos": 158, "type": "DATASET", "confidence": 0.9647518396377563}]}, {"text": "But the correct sense \"loading operating system into memory\" is not included in WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 80, "end_pos": 87, "type": "DATASET", "confidence": 0.9819496273994446}]}, {"text": "Therefore, this instance will be associated with an incorrect sense.", "labels": [], "entities": []}, {"text": "So, in this work, we would like to study the problem of partially supervised sense disambiguation with an incomplete sense tagged corpus.", "labels": [], "entities": [{"text": "sense disambiguation", "start_pos": 77, "end_pos": 97, "type": "TASK", "confidence": 0.7371992766857147}]}, {"text": "Specifically, given an incomplete sense-tagged corpus and a large amount of untagged examples fora target word 3 , we are interested in (1) labeling the instances in the untagged corpus with sense tags occurring in the tagged corpus; (2) trying to find undefined senses (or new senses) of the target word 4 from the untagged corpus, which will be represented by instances from the untagged corpus.", "labels": [], "entities": []}, {"text": "We propose an automatic method to estimate the number of senses (or sense number, model order) of a target word in mixed data (tagged corpus+untagged corpus) by maximizing a stability criterion defined on classification result overall the possible values of sense number.", "labels": [], "entities": []}, {"text": "At the same time, we can obtain a classification of the mixed data with the optimal number of groups.", "labels": [], "entities": []}, {"text": "If the estimated sense number in the mixed data is equal to the sense number of the target word in tagged corpus, then there is no new sense in untagged corpus.", "labels": [], "entities": []}, {"text": "Otherwise new senses will be represented by groups in which there is no instance from the tagged corpus.", "labels": [], "entities": []}, {"text": "This partially supervised sense disambiguation algorithm may help enriching manually compiled lexicons by inducing new senses from untagged corpora.", "labels": [], "entities": []}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "First, a model order identification algorithm will be presented for partially supervised sense disambiguation in section 2.", "labels": [], "entities": [{"text": "model order identification", "start_pos": 9, "end_pos": 35, "type": "TASK", "confidence": 0.6338332891464233}]}, {"text": "Section 3 will provide experimental results of this algorithm for sense disambiguation on SENSEVAL-3 data.", "labels": [], "entities": [{"text": "sense disambiguation", "start_pos": 66, "end_pos": 86, "type": "TASK", "confidence": 0.8101768791675568}, {"text": "SENSEVAL-3 data", "start_pos": 90, "end_pos": 105, "type": "DATASET", "confidence": 0.739887923002243}]}, {"text": "Then related work on partially supervised classification will be summarized in section 4.", "labels": [], "entities": [{"text": "partially supervised classification", "start_pos": 21, "end_pos": 56, "type": "TASK", "confidence": 0.6898447473843893}]}, {"text": "Finally we will conclude our work and suggest possible improvements in section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "The data for English lexical samples task in SENSEVAL-3 consists of 7860 examples as official training data, and 3944 examples as official test data for 57 English words.", "labels": [], "entities": []}, {"text": "The number of senses of each English word varies from 3 to 11.", "labels": [], "entities": []}, {"text": "We evaluated these four algorithms with different sizes of incomplete tagged data.", "labels": [], "entities": []}, {"text": "Given official training data of the word w, we constructed incomplete tagged data XL by removing the all the tagged instances from official training data that have sense tags from S subset , where S subset is a subset of the ground-truth sense set S for w, and S consists of the sense tags in official training set for w.", "labels": [], "entities": []}, {"text": "The removed training data and official test data of w were used as X U . Note that S L = S\u2212S subset . Then we ran these four algorithm for each target word w with XL as tagged data and X U as untagged data, and evaluated their performance using the accuracy on official test data of all the 57 words.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 249, "end_pos": 257, "type": "METRIC", "confidence": 0.99661785364151}]}, {"text": "We conducted six experiments for each target word w by setting S subset as {s 1 }, {s 2 }, {s 3 }, {s 1 , s 2 }, {s 1 , s 3 }, or {s 2 , s 3 }, where s i is the i-th most frequent sense of w.", "labels": [], "entities": []}, {"text": "S subset cannot beset as {s 4 } since some words have only three senses.", "labels": [], "entities": []}, {"text": "Table 3 lists the percentage of official training data used as tagged data (the number of examples in in-complete tagged data divided by the number of examples in official training data) when we removed the instances with sense tags from S subset for all the 57 words.", "labels": [], "entities": []}, {"text": "If S subset = {s 3 }, then most of sense tagged examples are still included in tagged data.", "labels": [], "entities": []}, {"text": "If S subset = {s 1 , s 2 }, then there are very few tagged examples in tagged data.", "labels": [], "entities": []}, {"text": "If no instances are removed from official training data, then the value of percentage is 100%.", "labels": [], "entities": []}, {"text": "Given an incomplete tagged corpus fora target word, SVM does not have the ability to find the new senses from untagged corpus.", "labels": [], "entities": []}, {"text": "Therefore it labels all the instances in the untagged corpus with sense tags from S L . Given a set of positive examples fora class and a set of unlabeled examples, the one-class partially supervised classification algorithm, LPU (Learning from Positive and Unlabeled examples) (, learns a classifier in four steps: Step 1: Identify a small set of reliable negative examples from unlabeled examples by the use of a classifier.", "labels": [], "entities": []}, {"text": "Step 2: Build a classifier using positive examples and automatically selected negative examples.", "labels": [], "entities": []}, {"text": "Step 3: Iteratively run previous two steps until no unlabeled examples are classified as negative ones or the unlabeled set is null.", "labels": [], "entities": []}, {"text": "Step 4: Select a good classifier from the set of classifiers constructed above.", "labels": [], "entities": []}, {"text": "For comparison, LPU 12 was run to perform classification on X U for each class in XL . The label of each instance in X U was determined by maximizing the classification score from LPU output for each class.", "labels": [], "entities": [{"text": "LPU 12", "start_pos": 16, "end_pos": 22, "type": "DATASET", "confidence": 0.9033157825469971}]}, {"text": "If the maximum score of an instance is negative, then this instance will be labeled as anew class.", "labels": [], "entities": []}, {"text": "Note that LPU classifies X L+U into k XL + 1 groups inmost of cases.", "labels": [], "entities": []}, {"text": "The clustering based partially supervised sense disambiguation algorithm was implemented by replacing ELP with a semi-supervised k-means clustering algorithm () in the model order identification procedure.", "labels": [], "entities": [{"text": "clustering based partially supervised sense disambiguation", "start_pos": 4, "end_pos": 62, "type": "TASK", "confidence": 0.7252480338017145}]}, {"text": "The label information in labeled data was used to guide the semi-supervised clustering on X L+U . Firstly, the labeled data maybe used to determine initial cluster centroids.", "labels": [], "entities": []}, {"text": "If the cluster number is greater thank XL , the initial centroids of clusters for new classes will be assigned as randomly selected instances.", "labels": [], "entities": []}, {"text": "Secondly, in the clustering process, the instances with the same class label will stay in the same cluster, while the instances with different class labels will belong to different clusters.", "labels": [], "entities": []}, {"text": "For better clustering solution, this clustering process will be restarted three times.", "labels": [], "entities": [{"text": "clustering", "start_pos": 11, "end_pos": 21, "type": "TASK", "confidence": 0.9777114987373352}]}, {"text": "Clustering process will be terminated when clustering solution converges or the number of iteration steps is more than We used Jensen-Shannon (JS) divergence as distance measure for semi-supervised clustering and ELP, since plain LP with JS divergence achieves better performance than that with cosine similarity on SENSEVAL-3 data ().", "labels": [], "entities": [{"text": "SENSEVAL-3 data", "start_pos": 316, "end_pos": 331, "type": "DATASET", "confidence": 0.7759972810745239}]}, {"text": "For the LP process in ELP algorithm, we constructed connected graphs as follows: two instances u, v will be connected by an edge if u is among v's 10 nearest neighbors, or if v is among u's 10 nearest neighbors as measured by cosine or JS distance measure (following ().", "labels": [], "entities": [{"text": "JS distance measure", "start_pos": 236, "end_pos": 255, "type": "METRIC", "confidence": 0.8149040738741556}]}, {"text": "We used three types of features to capture the information in all the contextual sentences of target words in SENSEVAL-3 data for all the four algorithms: part-of-speech of neighboring words with position information, words in topical context without position information (after removing stop words), and local collocations (as same as the feature set used in () except that we did not use syntactic relations).", "labels": [], "entities": [{"text": "SENSEVAL-3 data", "start_pos": 110, "end_pos": 125, "type": "DATASET", "confidence": 0.7213752865791321}]}, {"text": "We removed the features with occurrence frequency (counted in both training set and test set) less than 3 times.", "labels": [], "entities": [{"text": "occurrence frequency", "start_pos": 29, "end_pos": 49, "type": "METRIC", "confidence": 0.9433404803276062}]}, {"text": "If the estimated sense number is more than the sense number in the initial tagged corpus XL , then the results from order identification based methods will consist of the instances from clusters of unknown classes.", "labels": [], "entities": []}, {"text": "When assessing the agreement between these classification results and the known results on official test set, we will encounter the problem that there is no sense tag for each instance in unknown classes.", "labels": [], "entities": [{"text": "official test set", "start_pos": 91, "end_pos": 108, "type": "DATASET", "confidence": 0.7736944754918417}]}, {"text": "proposed to assign documents in each cluster with the most dominant class label in that cluster, and then conducted evaluation on these labeled documents.", "labels": [], "entities": []}, {"text": "Here we will follow their method for assigning sense tags to unknown classes from LPU, clustering based order identification process, and ELP based order identification process.", "labels": [], "entities": [{"text": "LPU", "start_pos": 82, "end_pos": 85, "type": "DATASET", "confidence": 0.9299066662788391}, {"text": "clustering based order identification", "start_pos": 87, "end_pos": 124, "type": "TASK", "confidence": 0.6313698664307594}, {"text": "ELP based order identification", "start_pos": 138, "end_pos": 168, "type": "TASK", "confidence": 0.6480571925640106}]}, {"text": "We assigned the instances from unknown classes with the dominant sense tag in that cluster.", "labels": [], "entities": []}, {"text": "The result from LPU always includes only one cluster of the unknown class.", "labels": [], "entities": [{"text": "LPU", "start_pos": 16, "end_pos": 19, "type": "DATASET", "confidence": 0.9104838371276855}]}, {"text": "We also assigned the instances from the unknown class with the dominant sense tag in that cluster.", "labels": [], "entities": []}, {"text": "When all instances have their sense tags, we evaluated the their results using the accuracy on official test set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.9990218877792358}]}, {"text": "summarizes the accuracy of SVM, LPU, the semi-supervised k-means clustering algorithm with correct sense number |S| or estimated sense number\u02c6knumber\u02c6 number\u02c6k X L+U as input, and the ELP algorithm with correct sense number |S| or estimated sense number\u02c6knumber\u02c6 number\u02c6k X L+U as input using various incomplete tagged data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9995602965354919}]}, {"text": "The last row in lists the average accuracy of each algorithm over the six experimental settings.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.997680127620697}]}, {"text": "Using |S| as input means that we do not perform order identification procedure, while using\u02c6kusing\u02c6 using\u02c6k X L+U as input is to perform order identification and obtain the classification results on X U at the same time.", "labels": [], "entities": [{"text": "order identification", "start_pos": 48, "end_pos": 68, "type": "TASK", "confidence": 0.6531482040882111}, {"text": "order identification", "start_pos": 137, "end_pos": 157, "type": "TASK", "confidence": 0.695385068655014}]}], "tableCaptions": [{"text": " Table 4: This table summarizes the accuracy of SVM, LPU, the semi-supervised k-means clustering al- gorithm with correct sense number |S| or estimated sense number\u02c6knumber\u02c6 number\u02c6k X L+U as input, and the ELP algorithm  with correct sense number |S| or estimated sense number\u02c6knumber\u02c6 number\u02c6k X L+U as input on the official test data of ELS  task in SENSEVAL-3 when given various incomplete tagged corpora.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9992789626121521}]}, {"text": " Table 5: These two tables provide the mean and  standard deviation of absolute values of the differ- ence between ground-truth results |S| and sense  numbers estimated by clustering or ELP based or- der identification procedure respectively.", "labels": [], "entities": []}]}