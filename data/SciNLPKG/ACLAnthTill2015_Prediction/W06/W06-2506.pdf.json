{"title": [{"text": "Characterizing Response Types and Revealing Noun Ambiguity in German Association Norms", "labels": [], "entities": [{"text": "Characterizing Response Types", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8914365172386169}, {"text": "Revealing Noun Ambiguity", "start_pos": 34, "end_pos": 58, "type": "TASK", "confidence": 0.6162746946016947}, {"text": "Norms", "start_pos": 81, "end_pos": 86, "type": "TASK", "confidence": 0.6583925485610962}]}], "abstractContent": [{"text": "This paper presents an analysis of semantic association norms for German nouns.", "labels": [], "entities": []}, {"text": "In contrast to prior studies, we not only collected associations elicited by written representations of target objects but also by their pictorial representations.", "labels": [], "entities": []}, {"text": "Ina first analysis, we identified systematic differences in the type and distribution of associate responses for the two presentation forms.", "labels": [], "entities": []}, {"text": "Ina second analysis, we applied a soft cluster analysis to the collected target-response pairs.", "labels": [], "entities": []}, {"text": "We subsequently used the clustering to predict noun ambiguity and to discriminate senses in our target nouns.", "labels": [], "entities": []}], "introductionContent": [{"text": "Language is rife with ambiguity.", "labels": [], "entities": []}, {"text": "Sentences can be structurally ambiguous, pronouns can be referentially ambiguous, and words can be polysemous.", "labels": [], "entities": []}, {"text": "The human language faculty deals remarkably well with the omnipresent ambiguity, so well in fact that we are rarely aware of the multiple alternatives that are available.", "labels": [], "entities": []}, {"text": "Despite our apparent lack of awareness, psycholinguistic research has shown that alternative meanings are nevertheless activated during processing.", "labels": [], "entities": []}, {"text": "For example, in a seminal study of homograph recognition, demonstrated that multiple meanings of a homograph are initially activated even in highly constraining syntactic contexts, such as They all rose vs. They bought arose.", "labels": [], "entities": [{"text": "homograph recognition", "start_pos": 35, "end_pos": 56, "type": "TASK", "confidence": 0.807436466217041}]}, {"text": "Likewise in speech production, showed that non-depicted senses of homophones are activated during picture naming.", "labels": [], "entities": [{"text": "speech production", "start_pos": 12, "end_pos": 29, "type": "TASK", "confidence": 0.7073046267032623}, {"text": "picture naming", "start_pos": 98, "end_pos": 112, "type": "TASK", "confidence": 0.7244763076305389}]}, {"text": "Thus, when either a homograph word or a picture with a homophone name are processed, multiple meanings are initially activated.", "labels": [], "entities": []}, {"text": "Intuitively, however, one might expect differences in the degree to which multiple meanings are activated depending on the presentation mode.", "labels": [], "entities": []}, {"text": "To our knowledge no investigation has compared picture (top-down) and word (bottom-up) semantic processing.", "labels": [], "entities": [{"text": "word (bottom-up) semantic processing", "start_pos": 70, "end_pos": 106, "type": "TASK", "confidence": 0.7181737323602041}]}, {"text": "In this paper, we investigate differences in the semantic information, namely associations, elicited in these two presentation modes.", "labels": [], "entities": []}, {"text": "We reason that, if multiple meanings of an ambiguous word are activated when the stimulus is processed, then the elicited associates should reflect the ambiguity.", "labels": [], "entities": []}, {"text": "If the degree of activation differs with respect to the presentation mode, the associates should reflect this difference as well.", "labels": [], "entities": []}, {"text": "Manually linking associates to a particular word sense would be time intensive and subjective.", "labels": [], "entities": []}, {"text": "Thus, we rely on computational methods that have the potential to automatically compare the associates provided for the two presentation modes and classify them into meaning-referring sets.", "labels": [], "entities": []}, {"text": "These methods thus not only reveal differences in the associates elicited in the two presentation conditions but also, in the case of ambiguous nouns, identify which associates are related to which meaning of the word.", "labels": [], "entities": []}, {"text": "Our analyses are guided by the following two questions: 1.", "labels": [], "entities": []}, {"text": "Are there systematic differences in associate response types when target objects are presented in written form compared to when the written form is accompanied by a pictorial representation?", "labels": [], "entities": []}, {"text": "Predictions about which differences we expected in the response types are made, and the associate responses are analyzed accordingly (Section 4).", "labels": [], "entities": []}, {"text": "2. Can we identify multiple senses of the nouns and discriminate between noun senses based on the associate responses?", "labels": [], "entities": []}, {"text": "We apply a clustering technique to the target-response pairs; the cluster analysis gathers semantically similar target nouns, based on overlapping sets of associate responses, and predicts the ambiguity of nouns and their senses (Section 5).", "labels": [], "entities": []}, {"text": "In \u00a2 Section 2, we provide an overview of the types of differences we anticipate; Section 3 describes the materials and procedure used for the association elicitation; in Sections 4 and 5, we explain how response types were characterized and noun senses identified.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to perform a more independent evaluation of the clusters which is not only based on specific examples, we assessed the clusters by two annotators.", "labels": [], "entities": []}, {"text": "20 homophones were manually selected from the 409 target nouns.", "labels": [], "entities": []}, {"text": "In addition, we relied on the indicators for ambiguity as defined in Section 4, and selected the 20 top and bottom nouns from the ordered list of type agreement for the two conditions.", "labels": [], "entities": []}, {"text": "The manual list showed some overlap with the selection dependent on type agreement, resulting in a list of 51 target nouns.", "labels": [], "entities": []}, {"text": "For each of the selected target nouns, we looked up the noun senses as defined by the Duden, a standard German dictionary.", "labels": [], "entities": [{"text": "Duden", "start_pos": 86, "end_pos": 91, "type": "DATASET", "confidence": 0.9383881092071533}]}, {"text": "We primarily used the stylistic dictionary, but used the foreign language dictionary) if the noun was missing in the former.", "labels": [], "entities": []}, {"text": "Each target noun was defined by its (short version) sense definitions.", "labels": [], "entities": []}, {"text": "For example, Schloss was defined by the senses Vorrichtung zum Verschlie\u00dfen 'device for closing' and Wohngeb\u00e4ude von F\u00fcrsten und Adeligen 'residential building for princes and noblemen'.", "labels": [], "entities": []}, {"text": "As targets for the evaluation, we used the two cluster analyses as mentioned above, containing 100 and 200 clusters with membership probability cut-offs at 1%.", "labels": [], "entities": []}, {"text": "Two annotators were then presented with two lists each: For each cluster analysis, they saw a list of the 51 selected target nouns, accompanied by the clusters they were members of, i.e., for which they showed a probability > \u00a8 dc , ignoring the condition of the target noun (PW vs. W).", "labels": [], "entities": []}, {"text": "In total, the annotators were given 82/91 clusters which included any of the 51 selected nouns.", "labels": [], "entities": []}, {"text": "For each cluster, the annotators saw the five most probable associations, and all cluster members.", "labels": [], "entities": []}, {"text": "The annotators were asked to select a Duden sense for each cluster, if possible.", "labels": [], "entities": [{"text": "Duden sense", "start_pos": 38, "end_pos": 49, "type": "DATASET", "confidence": 0.9224140644073486}]}, {"text": "The results of the annotation are presented in.", "labels": [], "entities": []}, {"text": "Annotator 1 identified a Duden sense for 72/75% of the clusters, annotator 2 for 78/71%.", "labels": [], "entities": [{"text": "Duden sense", "start_pos": 25, "end_pos": 36, "type": "DATASET", "confidence": 0.8757506012916565}]}, {"text": "Interannotator agreement on which of the Duden senses was appropriate fora cluster (if any)   The evaluation of the clusters as carried out by the sense annotation demonstrates that the cluster senses correspond largely to Duden senses.", "labels": [], "entities": [{"text": "Duden", "start_pos": 41, "end_pos": 46, "type": "DATASET", "confidence": 0.9292112588882446}]}, {"text": "This first kind of evaluation models the precision of the cluster analyses.", "labels": [], "entities": [{"text": "precision", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.9987385869026184}]}, {"text": "A second kind of evaluation assessed how many different Duden senses we capture with the cluster analyses; this evaluation modells the recall of the cluster analyses.", "labels": [], "entities": [{"text": "recall", "start_pos": 135, "end_pos": 141, "type": "METRIC", "confidence": 0.998067319393158}]}, {"text": "Duden defines a total of 113 senses to our target nouns.", "labels": [], "entities": [{"text": "Duden", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9688159227371216}]}, {"text": "Table 4 specifies the recall for the data sets and annotators.", "labels": [], "entities": [{"text": "recall", "start_pos": 22, "end_pos": 28, "type": "METRIC", "confidence": 0.9993645548820496}]}, {"text": "The evaluations show that the precision is much larger than the recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.9997381567955017}, {"text": "recall", "start_pos": 64, "end_pos": 70, "type": "METRIC", "confidence": 0.9990065693855286}]}, {"text": "It might be worth applying the clustering with a different number of clusters Source 100 clusters 200 clusters Annotator 1 46 41% 54 48% Annotator 2 51 45% 52 46%: Cluster recall of Duden senses. and/or a different cut-off for the cluster membership probability, but that would lower the precision of the analyses.", "labels": [], "entities": [{"text": "recall", "start_pos": 172, "end_pos": 178, "type": "METRIC", "confidence": 0.8928849101066589}, {"text": "precision", "start_pos": 288, "end_pos": 297, "type": "METRIC", "confidence": 0.9994834661483765}]}, {"text": "We believe that the evaluation numbers are quite impressive, especially considering that Duden not only specifies everyday vocabulary, but includes colloquial expressions (such as Ballon as 'human head'), out-dated senses (such as Mond as 'month'), and domain-specific senses (such as Blatt as 'shoulder of a hoofed game').", "labels": [], "entities": [{"text": "Duden", "start_pos": 89, "end_pos": 94, "type": "DATASET", "confidence": 0.9555447697639465}, {"text": "Blatt", "start_pos": 285, "end_pos": 290, "type": "METRIC", "confidence": 0.9695694446563721}]}], "tableCaptions": [{"text": " Table 1: Response type frequencies for Schloss.", "labels": [], "entities": []}, {"text": " Table 3. Annotator 1  identified a Duden sense for 72/75% of the clus- ters, annotator 2 for 78/71%. Interannotator agree- ment on which of the Duden senses was appropri- ate for a cluster (if any)", "labels": [], "entities": [{"text": "Duden", "start_pos": 36, "end_pos": 41, "type": "DATASET", "confidence": 0.9151353240013123}, {"text": "Interannotator agree- ment", "start_pos": 102, "end_pos": 128, "type": "METRIC", "confidence": 0.9002368748188019}]}, {"text": " Table 3: Clusters and identified Duden senses.", "labels": [], "entities": [{"text": "Duden senses", "start_pos": 34, "end_pos": 46, "type": "DATASET", "confidence": 0.9248370826244354}]}]}