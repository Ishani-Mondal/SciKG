{"title": [{"text": "Simple Information Extraction (SIE): A Portable and Effective IE System", "labels": [], "entities": [{"text": "Simple Information Extraction (SIE)", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.7594476044178009}]}], "abstractContent": [{"text": "This paper describes SIE (Simple Information Extraction), a modular information extraction system designed with the goal of being easily and quickly portable across tasks and domains.", "labels": [], "entities": [{"text": "Simple Information Extraction)", "start_pos": 26, "end_pos": 56, "type": "TASK", "confidence": 0.672535240650177}, {"text": "information extraction", "start_pos": 68, "end_pos": 90, "type": "TASK", "confidence": 0.7737236618995667}]}, {"text": "SIE is composed by a general purpose machine learning algorithm (SVM) combined with several cus-tomizable modules.", "labels": [], "entities": [{"text": "general purpose machine learning algorithm (SVM)", "start_pos": 21, "end_pos": 69, "type": "TASK", "confidence": 0.6737827584147453}]}, {"text": "A crucial role in the architecture is played by Instance Filtering , which allows to increase efficiency without reducing effectiveness.", "labels": [], "entities": [{"text": "Instance", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9192505478858948}]}, {"text": "The results obtained by SIE on several standard data sets, representative of different tasks and domains, are reported.", "labels": [], "entities": []}, {"text": "The experiments show that SIE achieves performance close to the best systems in all tasks, without using domain-specific knowledge.", "labels": [], "entities": [{"text": "SIE", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.9494004249572754}]}], "introductionContent": [{"text": "In designing Information Extraction (IE) systems based on supervised machine learning techniques, there is usually a tradeoff between carefully tuning the system to specific tasks and domains and having a \"generic\" IE system able to obtain good (even if not the topmost) performance when applied to different tasks and domains (requiring a very reduced porting time).", "labels": [], "entities": [{"text": "Information Extraction (IE)", "start_pos": 13, "end_pos": 40, "type": "TASK", "confidence": 0.8445689082145691}]}, {"text": "Usually, the former alternative is chosen and system performance is often shown only fora very limited number of tasks (sometimes even only fora single task), after a careful tuning.", "labels": [], "entities": []}, {"text": "For example, in the Bio-entity Recognition Shared Task at JNLPBA 2004 () the best performing system obtained a considerable performance improvement adopting domain specific hacks.", "labels": [], "entities": [{"text": "Bio-entity Recognition Shared Task", "start_pos": 20, "end_pos": 54, "type": "TASK", "confidence": 0.904502272605896}, {"text": "JNLPBA 2004", "start_pos": 58, "end_pos": 69, "type": "DATASET", "confidence": 0.6667550206184387}]}, {"text": "A second important issue in designing IE systems concerns the fact that usually IE data sets are highly unbalanced (i.e., the number of positive examples constitutes only a small fraction with respect to the number of negative examples).", "labels": [], "entities": [{"text": "IE", "start_pos": 38, "end_pos": 40, "type": "TASK", "confidence": 0.9677800536155701}]}, {"text": "This fact has important consequences.", "labels": [], "entities": []}, {"text": "In some machine learning algorithms the unbalanced distribution of examples can yield a significant loss in classification accuracy.", "labels": [], "entities": [{"text": "classification", "start_pos": 108, "end_pos": 122, "type": "TASK", "confidence": 0.9532320499420166}, {"text": "accuracy", "start_pos": 123, "end_pos": 131, "type": "METRIC", "confidence": 0.8395777940750122}]}, {"text": "Moreover, very large data sets can be problematic to process due to the complexity of many supervised learning techniques.", "labels": [], "entities": []}, {"text": "For example, using kernel methods, such as word sequence and tree kernels, can become prohibitive due to the difficulty of kernel based algorithms, such as Support Vector Machines (SVM), to scale to large data sets.", "labels": [], "entities": []}, {"text": "As a consequence, reducing the number of instances without degrading the prediction accuracy is a crucial issue for applying advanced machine learning techniques in IE, especially in the case of highly unbalanced data sets.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.930777370929718}, {"text": "IE", "start_pos": 165, "end_pos": 167, "type": "TASK", "confidence": 0.9925985336303711}]}, {"text": "In this paper, we present SIE (Simple Information Extraction), an information extraction system based on a supervised machine learning approach for extracting domain-specific entities from documents.", "labels": [], "entities": [{"text": "Simple Information Extraction)", "start_pos": 31, "end_pos": 61, "type": "TASK", "confidence": 0.7227232977747917}, {"text": "information extraction", "start_pos": 66, "end_pos": 88, "type": "TASK", "confidence": 0.7182332277297974}]}, {"text": "In particular, IE is cast as a classification problem by applying SVM to train a set of classifiers, based on a simple and general-purpose feature representation, for detecting the boundaries of the entities to be extracted.", "labels": [], "entities": [{"text": "IE", "start_pos": 15, "end_pos": 17, "type": "TASK", "confidence": 0.9923756718635559}]}, {"text": "SIE was designed with the goal of being easily and quickly portable across tasks and domains.", "labels": [], "entities": []}, {"text": "To support this claim, we conducted a set of experiments on several tasks in different domains and languages.", "labels": [], "entities": []}, {"text": "The results show that SIE is competitive with the state-of-the-art systems, and it often outperforms systems customized to a specific domain.", "labels": [], "entities": [{"text": "SIE", "start_pos": 22, "end_pos": 25, "type": "TASK", "confidence": 0.9108502268791199}]}, {"text": "SIE resembles the \"Level One\" of the ELIE algorithm ().", "labels": [], "entities": []}, {"text": "How-ever, a key difference between the two algorithms is the capability of SIE to drastically reduce the computation time by exploiting Instance Filtering ().", "labels": [], "entities": []}, {"text": "This characteristic allows scaling from toy problems to real-world data sets making SIE attractive in applicative fields, such as bioinformatics, where very large amounts of data have to be analyzed.", "labels": [], "entities": [{"text": "SIE", "start_pos": 84, "end_pos": 87, "type": "TASK", "confidence": 0.9399576783180237}]}], "datasetContent": [{"text": "In order to demonstrate that SIE is domain and language independent we tested it on several tasks using exactly the same configuration.", "labels": [], "entities": [{"text": "SIE", "start_pos": 29, "end_pos": 32, "type": "TASK", "confidence": 0.9281884431838989}]}, {"text": "The tasks and the experimental settings are described in Section 7.1.", "labels": [], "entities": []}, {"text": "The results show that the adopted filtering technique decreases drastically the computation time while preserving (and sometimes improving) the overall accuracy of the system.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 152, "end_pos": 160, "type": "METRIC", "confidence": 0.9985498785972595}]}], "tableCaptions": [{"text": " Table 1: A corpus fragment represented in IOBE  notation.", "labels": [], "entities": []}, {"text": " Table 4: The length distribution for the entity  speaker.", "labels": [], "entities": []}, {"text": " Table 4. In this example, the  matcher, choosing the candidate that maximizes  the score function, namely the second one, extracts  the actual entity.", "labels": [], "entities": []}, {"text": " Table 5: Filtering Rate, Micro-averaged Recall,  Precision, F 1 and Time for JNLPBA.", "labels": [], "entities": [{"text": "Filtering Rate", "start_pos": 10, "end_pos": 24, "type": "METRIC", "confidence": 0.9238214194774628}, {"text": "Micro-averaged", "start_pos": 26, "end_pos": 40, "type": "METRIC", "confidence": 0.9915415644645691}, {"text": "Recall", "start_pos": 41, "end_pos": 47, "type": "METRIC", "confidence": 0.7525083422660828}, {"text": "Precision", "start_pos": 50, "end_pos": 59, "type": "METRIC", "confidence": 0.9993404746055603}, {"text": "F 1", "start_pos": 61, "end_pos": 64, "type": "METRIC", "confidence": 0.9924382567405701}, {"text": "Time", "start_pos": 69, "end_pos": 73, "type": "METRIC", "confidence": 0.9947486519813538}, {"text": "JNLPBA", "start_pos": 78, "end_pos": 84, "type": "DATASET", "confidence": 0.7883946895599365}]}, {"text": " Table 6: Filtering Rate, Micro-averaged Recall,  Precision, F 1 and total computation time for  CoNLL-2002 (Dutch).", "labels": [], "entities": [{"text": "Filtering Rate", "start_pos": 10, "end_pos": 24, "type": "METRIC", "confidence": 0.9201963245868683}, {"text": "Micro-averaged", "start_pos": 26, "end_pos": 40, "type": "METRIC", "confidence": 0.9848750233650208}, {"text": "Recall", "start_pos": 41, "end_pos": 47, "type": "METRIC", "confidence": 0.6086089015007019}, {"text": "Precision", "start_pos": 50, "end_pos": 59, "type": "METRIC", "confidence": 0.9955790638923645}, {"text": "F 1", "start_pos": 61, "end_pos": 64, "type": "METRIC", "confidence": 0.9873097538948059}, {"text": "CoNLL-2002 (Dutch)", "start_pos": 97, "end_pos": 115, "type": "DATASET", "confidence": 0.7995742708444595}]}, {"text": " Table 7: Filtering Rate, Micro-averaged Recall,  Precision, F 1 and total computation time for  CoNLL-2003 (English).", "labels": [], "entities": [{"text": "Filtering Rate", "start_pos": 10, "end_pos": 24, "type": "METRIC", "confidence": 0.9355151057243347}, {"text": "Micro-averaged", "start_pos": 26, "end_pos": 40, "type": "METRIC", "confidence": 0.9845432639122009}, {"text": "Recall", "start_pos": 41, "end_pos": 47, "type": "METRIC", "confidence": 0.6605286598205566}, {"text": "Precision", "start_pos": 50, "end_pos": 59, "type": "METRIC", "confidence": 0.9972389936447144}, {"text": "F 1", "start_pos": 61, "end_pos": 64, "type": "METRIC", "confidence": 0.9878123700618744}, {"text": "CoNLL-2003", "start_pos": 97, "end_pos": 107, "type": "DATASET", "confidence": 0.8997469544410706}]}, {"text": " Table 8: Filtering Rate, Micro-averaged Recall,  Precision, F 1 and total computation time for  TERN.", "labels": [], "entities": [{"text": "Filtering Rate", "start_pos": 10, "end_pos": 24, "type": "METRIC", "confidence": 0.9501216411590576}, {"text": "Micro-averaged", "start_pos": 26, "end_pos": 40, "type": "METRIC", "confidence": 0.989709198474884}, {"text": "Recall", "start_pos": 41, "end_pos": 47, "type": "METRIC", "confidence": 0.685875654220581}, {"text": "Precision", "start_pos": 50, "end_pos": 59, "type": "METRIC", "confidence": 0.9985272884368896}, {"text": "F 1", "start_pos": 61, "end_pos": 64, "type": "METRIC", "confidence": 0.9913180768489838}, {"text": "TERN", "start_pos": 97, "end_pos": 101, "type": "METRIC", "confidence": 0.5584318041801453}]}, {"text": " Table 9: Filtering Rate, Micro-averaged Recall,  Precision, F 1 and total computation time for SA.", "labels": [], "entities": [{"text": "Filtering Rate", "start_pos": 10, "end_pos": 24, "type": "METRIC", "confidence": 0.9525377452373505}, {"text": "Micro-averaged", "start_pos": 26, "end_pos": 40, "type": "METRIC", "confidence": 0.9889467358589172}, {"text": "Recall", "start_pos": 41, "end_pos": 47, "type": "METRIC", "confidence": 0.708360493183136}, {"text": "Precision", "start_pos": 50, "end_pos": 59, "type": "METRIC", "confidence": 0.9984695315361023}, {"text": "F 1", "start_pos": 61, "end_pos": 64, "type": "METRIC", "confidence": 0.9907944798469543}, {"text": "SA", "start_pos": 96, "end_pos": 98, "type": "TASK", "confidence": 0.9753391146659851}]}, {"text": " Table 10: Skewness ratio of each entity for  JNLPBA.", "labels": [], "entities": [{"text": "Skewness ratio", "start_pos": 11, "end_pos": 25, "type": "METRIC", "confidence": 0.9744133055210114}, {"text": "JNLPBA", "start_pos": 46, "end_pos": 52, "type": "DATASET", "confidence": 0.8846980929374695}]}]}