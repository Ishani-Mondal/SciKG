{"title": [], "abstractContent": [], "introductionContent": [{"text": "One step in the curation process is geneId findingthe task of finding the database identifier of every gene discussed in an article.", "labels": [], "entities": []}, {"text": "GeneId-finding was studied experimentally in the BioCreatIvE challenge), which developed testbed problems for each of three model organisms (yeast, mice, and fruitflies).", "labels": [], "entities": []}, {"text": "Here we consider geneId ranking, a relaxation of geneId-finding in which the system provides a ranked list of genes that might be discussed by the document.", "labels": [], "entities": []}, {"text": "We show how multiple named entity recognition (NER) methods can be combined into a single high-performance geneIdranking system.", "labels": [], "entities": [{"text": "named entity recognition (NER)", "start_pos": 21, "end_pos": 51, "type": "TASK", "confidence": 0.8535187840461731}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Performance of the NER systems on the  mouse evaluation corpus and the YAPEX test cor- pus.", "labels": [], "entities": [{"text": "NER", "start_pos": 29, "end_pos": 32, "type": "TASK", "confidence": 0.9150077700614929}, {"text": "YAPEX test cor- pus", "start_pos": 81, "end_pos": 100, "type": "DATASET", "confidence": 0.5943441808223724}]}, {"text": " Table 2: Mean average precision of several geneId- ranking methods on the 50 abstracts from the mouse  evaluation dataset.", "labels": [], "entities": [{"text": "precision", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.8149364590644836}]}, {"text": " Table 3: Mean average precision of several geneId- ranking methods on the 250 abstracts from the  mouse test dataset.", "labels": [], "entities": [{"text": "precision", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.5933465957641602}, {"text": "mouse test dataset", "start_pos": 99, "end_pos": 117, "type": "DATASET", "confidence": 0.7196522156397501}]}]}