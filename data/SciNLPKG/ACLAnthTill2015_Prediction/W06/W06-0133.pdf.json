{"title": [{"text": "Maximum Entropy Word Segmentation of Chinese Text", "labels": [], "entities": [{"text": "Word Segmentation of Chinese Text", "start_pos": 16, "end_pos": 49, "type": "TASK", "confidence": 0.7340498924255371}]}], "abstractContent": [{"text": "We extended the work of Low, Ng, and Guo (2005) to create a Chinese word seg-mentation system based upon a maximum entropy statistical model.", "labels": [], "entities": []}, {"text": "This system was entered into the Third International Chinese Language Processing Bakeoff and evaluated on all four corpora in their respective open tracks.", "labels": [], "entities": [{"text": "Third International Chinese Language Processing Bakeoff", "start_pos": 33, "end_pos": 88, "type": "DATASET", "confidence": 0.6080076893170675}]}, {"text": "Our system achieved the highest F-score for the UPUC corpus, and the second, third, and seventh highest for CKIP, CITYU, and MSRA respectively.", "labels": [], "entities": [{"text": "F-score", "start_pos": 32, "end_pos": 39, "type": "METRIC", "confidence": 0.9992662072181702}, {"text": "UPUC corpus", "start_pos": 48, "end_pos": 59, "type": "DATASET", "confidence": 0.9075442552566528}, {"text": "CKIP", "start_pos": 108, "end_pos": 112, "type": "DATASET", "confidence": 0.9426921010017395}, {"text": "CITYU", "start_pos": 114, "end_pos": 119, "type": "DATASET", "confidence": 0.7897034287452698}, {"text": "MSRA", "start_pos": 125, "end_pos": 129, "type": "DATASET", "confidence": 0.831926167011261}]}, {"text": "Later testing with the gold-standard data revealed that while the additions we made to Low et al.'s system helped our results for the 2005 data with which we experimented during development, a number of them actually hurt our scores for this year's corpora.", "labels": [], "entities": []}, {"text": "1 Segmenter Our Chinese word segmenter is a modification of the system described by Low et al.", "labels": [], "entities": []}, {"text": "(2005), which they entered in the 2005 Second International Chi-nese Word Segmentation Bakeoff.", "labels": [], "entities": [{"text": "Second International Chi-nese Word Segmentation Bakeoff", "start_pos": 39, "end_pos": 94, "type": "TASK", "confidence": 0.6885762363672256}]}, {"text": "It uses a maximum entropy (Ratnaparkhi, 1998) model which is trained on the training corpora provided for this year's bakeoff.", "labels": [], "entities": []}, {"text": "The maximum entropy framework used is the Python interface of Zhang Le's maximum entropy modeling toolkit (Zhang, 2004).", "labels": [], "entities": []}, {"text": "1.1 Properties in common with Low et al.", "labels": [], "entities": []}, {"text": "As with the system of Low et al., our system treats the word segmentation problem as a tagging problem.", "labels": [], "entities": [{"text": "word segmentation problem", "start_pos": 56, "end_pos": 81, "type": "TASK", "confidence": 0.7792062262694041}]}, {"text": "When segmenting a string of Chi-nese text, each character can be assigned one of four boundary tags: S fora character that stands alone as a word, B fora character that begins a multi-character word, M fora character in a multi-character word which neither starts nor ends the word, and E fora character that ends a multi-character word.", "labels": [], "entities": []}, {"text": "The optimal tag fora given character is chosen based on features derived from the character's surrounding context in accordance with the decoding algorithm (see Section 1.2).", "labels": [], "entities": []}, {"text": "All of the feature templates of Low et al.'s system are utilized in our own (with a few slight modifications): 1.", "labels": [], "entities": []}, {"text": "C n (n = \u22122, \u22121, 0, 1, 2) 2.", "labels": [], "entities": []}, {"text": "C n C n+1 (n = \u22122, \u22121, 0, 1) 3.", "labels": [], "entities": []}, {"text": "C \u22121 C 1 4.", "labels": [], "entities": []}, {"text": "P u(C 0) 5.", "labels": [], "entities": []}, {"text": "T (C \u22122)T (C \u22121)T (C 0)T (C 1)T (C 2) 6.", "labels": [], "entities": []}, {"text": "C n t 0 (n = \u22121, 0, 1) In the above feature templates, Ci refers to the character i positions away from the character under consideration, where negative values indicate characters to the left of the present position.", "labels": [], "entities": []}, {"text": "The punctuation feature P u(C 0) is added only if the current character is a punctuation mark, and the function T maps characters to various numbers representing classes of characters.", "labels": [], "entities": []}, {"text": "In addition to the numeral, date word, and English letter classes of Low et al.'s system, we added classes for punctuation and likely decimal points (which are defined by a period or the character \u00b9 occurring between two numerals).", "labels": [], "entities": []}, {"text": "L is defined to be the length of the longest word W in the dictionary that matches some sequence of characters around C 0 185", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Our 2006 SIGHAN bakeoff results.", "labels": [], "entities": [{"text": "SIGHAN bakeoff", "start_pos": 19, "end_pos": 33, "type": "TASK", "confidence": 0.7449905872344971}]}, {"text": " Table 2: Our results without the extra features.", "labels": [], "entities": []}]}