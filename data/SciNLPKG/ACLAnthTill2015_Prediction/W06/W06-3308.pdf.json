{"title": [{"text": "BIOSMILE: Adapting Semantic Role Labeling for Biomedical Verbs: An Exponential Model Coupled with Automatically Generated Template Features", "labels": [], "entities": [{"text": "BIOSMILE", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.8838208317756653}, {"text": "Adapting Semantic Role Labeling", "start_pos": 10, "end_pos": 41, "type": "TASK", "confidence": 0.8386523127555847}]}], "abstractContent": [{"text": "In this paper, we construct a biomedical semantic role labeling (SRL) system that can be used to facilitate relation extraction.", "labels": [], "entities": [{"text": "biomedical semantic role labeling (SRL)", "start_pos": 30, "end_pos": 69, "type": "TASK", "confidence": 0.7281818773065295}, {"text": "relation extraction", "start_pos": 108, "end_pos": 127, "type": "TASK", "confidence": 0.8825639188289642}]}, {"text": "First, we construct a proposition bank on top of the popular biomedical GENIA treebank following the PropBank annotation scheme.", "labels": [], "entities": [{"text": "GENIA treebank", "start_pos": 72, "end_pos": 86, "type": "DATASET", "confidence": 0.9026439487934113}]}, {"text": "We only annotate the predicate argument structures (PAS's) of thirty frequently used biomedical predicates and their corresponding arguments.", "labels": [], "entities": []}, {"text": "Second, we use our proposition bank to train a biomedical SRL system, which uses a maximum entropy (ME) model.", "labels": [], "entities": [{"text": "SRL", "start_pos": 58, "end_pos": 61, "type": "TASK", "confidence": 0.7992411851882935}, {"text": "maximum entropy (ME)", "start_pos": 83, "end_pos": 103, "type": "METRIC", "confidence": 0.6429859459400177}]}, {"text": "Thirdly, we automatically generate argument-type templates which can be used to improve classification of biomedical argument types.", "labels": [], "entities": [{"text": "classification of biomedical argument types", "start_pos": 88, "end_pos": 131, "type": "TASK", "confidence": 0.771648645401001}]}, {"text": "Our experimental results show that a newswire SRL system that achieves an F-score of 86.29% in the newswire domain can maintain an F-score of 64.64% when ported to the biomedical domain.", "labels": [], "entities": [{"text": "F-score", "start_pos": 74, "end_pos": 81, "type": "METRIC", "confidence": 0.999262273311615}, {"text": "F-score", "start_pos": 131, "end_pos": 138, "type": "METRIC", "confidence": 0.9990310668945312}]}, {"text": "By using our annotated biomedical corpus, we can increase that F-score by 22.9%.", "labels": [], "entities": [{"text": "F-score", "start_pos": 63, "end_pos": 70, "type": "METRIC", "confidence": 0.997837245464325}]}, {"text": "Adding automatically generated template features further increases overall F-score by 0.47% and adjunct arguments (AM) F-score by 1.57%, respectively.", "labels": [], "entities": [{"text": "F-score", "start_pos": 75, "end_pos": 82, "type": "METRIC", "confidence": 0.9979230761528015}, {"text": "adjunct arguments (AM) F-score", "start_pos": 96, "end_pos": 126, "type": "METRIC", "confidence": 0.6712666600942612}]}], "introductionContent": [{"text": "The volume of biomedical literature available has experienced unprecedented growth in recent years.", "labels": [], "entities": []}, {"text": "The ability to automatically process this literature would bean invaluable tool for both the design and interpretation of large-scale experiments.", "labels": [], "entities": []}, {"text": "To this end, more and more information extraction (IE) systems using natural language processing (NLP) have been developed for use in the biomedical field.", "labels": [], "entities": [{"text": "information extraction (IE)", "start_pos": 27, "end_pos": 54, "type": "TASK", "confidence": 0.8588226675987244}]}, {"text": "A key IE task in the biomedical field is extraction of relations, such as protein-protein and gene-gene interactions.", "labels": [], "entities": [{"text": "IE", "start_pos": 6, "end_pos": 8, "type": "TASK", "confidence": 0.9901748895645142}]}, {"text": "Currently, most biomedical relation-extraction systems fall under one of the following three approaches: cooccurence-based (), pattern-based (), and machinelearning-based.", "labels": [], "entities": []}, {"text": "All three, however, share the same limitation when extracting relations from complex natural language.", "labels": [], "entities": []}, {"text": "They only extract the relation targets (e.g., proteins, genes) and the verbs representing those relations, overlooking the many adverbial and prepositional phrases and words that describe location, manner, timing, condition, and extent.", "labels": [], "entities": []}, {"text": "The information in such phrases maybe important for precise definition and clarification of complex biological relations.", "labels": [], "entities": []}, {"text": "The above problem can be tackled by using semantic role labeling (SRL) because it not only recognizes main roles, such as agents and objects, but also extracts adjunct roles such as location, manner, timing, condition, and extent.", "labels": [], "entities": [{"text": "semantic role labeling (SRL)", "start_pos": 42, "end_pos": 70, "type": "TASK", "confidence": 0.7858875592549642}, {"text": "extent", "start_pos": 223, "end_pos": 229, "type": "METRIC", "confidence": 0.967923641204834}]}, {"text": "The goal of SRL is to group sequences of words together and classify them with semantic labels.", "labels": [], "entities": [{"text": "SRL", "start_pos": 12, "end_pos": 15, "type": "TASK", "confidence": 0.9874535799026489}]}, {"text": "In the newswire domain, have demonstrated that full-parsing and SRL can improve the performance of relation extraction, resulting in an F-score increase of 15% (from 67% to 82%).", "labels": [], "entities": [{"text": "SRL", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.8400468826293945}, {"text": "relation extraction", "start_pos": 99, "end_pos": 118, "type": "TASK", "confidence": 0.8537821471691132}, {"text": "F-score", "start_pos": 136, "end_pos": 143, "type": "METRIC", "confidence": 0.9992061257362366}]}, {"text": "This significant result leads us to surmise that SRL may also have potential for relation extraction in the biomedical domain.", "labels": [], "entities": [{"text": "SRL", "start_pos": 49, "end_pos": 52, "type": "TASK", "confidence": 0.972979724407196}, {"text": "relation extraction", "start_pos": 81, "end_pos": 100, "type": "TASK", "confidence": 0.9000793397426605}]}, {"text": "Unfortunately, no SRL system for the biomedical domain exists.", "labels": [], "entities": [{"text": "SRL", "start_pos": 18, "end_pos": 21, "type": "TASK", "confidence": 0.9247621297836304}]}, {"text": "In this paper, we aim to build such a biomedical SRL system.", "labels": [], "entities": [{"text": "SRL", "start_pos": 49, "end_pos": 52, "type": "TASK", "confidence": 0.7665601968765259}]}, {"text": "To achieve this goal we roughly implement the following three steps as proposed by: (1) create semantic roles for each biomedical verb; (2) construct a biomedical corpus annotated with verbs and their corresponding semantic roles (following definitions created in (1) as a reference resource;) (3) build an automatic semantic interpretation model using the annotated text as a training corpus for machine learning.", "labels": [], "entities": []}, {"text": "In the first step, we adopt the definitions found in PropBank (), defining our own framesets for verbs not in PropBank, such as \"phosphorylate\".", "labels": [], "entities": [{"text": "PropBank", "start_pos": 53, "end_pos": 61, "type": "DATASET", "confidence": 0.9501492381095886}, {"text": "PropBank", "start_pos": 110, "end_pos": 118, "type": "DATASET", "confidence": 0.9439191818237305}]}, {"text": "In the second step, we first use an SRL system) trained on the Wall Street Journal (WSJ) to automatically tag our corpus.", "labels": [], "entities": [{"text": "Wall Street Journal (WSJ)", "start_pos": 63, "end_pos": 88, "type": "DATASET", "confidence": 0.943675676981608}]}, {"text": "We then have the results double-checked by human annotators.", "labels": [], "entities": []}, {"text": "Finally, we add automatically-generated template features to our SRL system to identify adjunct (modifier) arguments, especially those highly relevant to the biomedical domain.", "labels": [], "entities": [{"text": "SRL", "start_pos": 65, "end_pos": 68, "type": "TASK", "confidence": 0.9205853939056396}]}], "datasetContent": [{"text": "In this paper, we extracted all our datasets from two corpora, the Wall Street Journal (WSJ) corpus and the BioProp, which respectively represent the newswire and biomedical domains.", "labels": [], "entities": [{"text": "Wall Street Journal (WSJ) corpus", "start_pos": 67, "end_pos": 99, "type": "DATASET", "confidence": 0.9495400530951363}]}, {"text": "The Wall Street Journal corpus has 39,892 sentences, and 950,028 words.", "labels": [], "entities": [{"text": "Wall Street Journal corpus", "start_pos": 4, "end_pos": 30, "type": "DATASET", "confidence": 0.9786974638700485}]}, {"text": "It contains full-parsing information, first annotated by, and is the most famous treebank (WSJ treebank).", "labels": [], "entities": [{"text": "WSJ treebank", "start_pos": 91, "end_pos": 103, "type": "DATASET", "confidence": 0.9651465117931366}]}, {"text": "In addition to these syntactic structures, it was also annotated with predicate-argument structures (WSJ proposition bank) by.", "labels": [], "entities": []}, {"text": "In biomedical domain, there is one available treebank for GENIA, created by Yuka, who has so far added full-parsing information to 500 abstracts.", "labels": [], "entities": [{"text": "GENIA", "start_pos": 58, "end_pos": 63, "type": "DATASET", "confidence": 0.9179142117500305}]}, {"text": "In contrast to WSJ, however, GENIA lacks any proposition bank.", "labels": [], "entities": [{"text": "WSJ", "start_pos": 15, "end_pos": 18, "type": "DATASET", "confidence": 0.8883865475654602}, {"text": "GENIA", "start_pos": 29, "end_pos": 34, "type": "DATASET", "confidence": 0.9179345369338989}]}, {"text": "Since predicate-argument annotation is essential for training and evaluating statistical SRL systems, to makeup for GENIA's lack of a proposition bank, we constructed BioProp.", "labels": [], "entities": [{"text": "SRL", "start_pos": 89, "end_pos": 92, "type": "TASK", "confidence": 0.8192698359489441}]}, {"text": "Two biologists with masters degrees in our laboratory undertook the annotation task after receiving computational linguistic training for approximately three months.", "labels": [], "entities": []}, {"text": "We adopted a semi-automatic strategy to annotate BioProp.", "labels": [], "entities": [{"text": "BioProp", "start_pos": 49, "end_pos": 56, "type": "DATASET", "confidence": 0.8852791786193848}]}, {"text": "First, we used the PropBank to train a statistical SRL system which achieves an F-score of over 86% on section 24 of the PropBank.", "labels": [], "entities": [{"text": "PropBank", "start_pos": 19, "end_pos": 27, "type": "DATASET", "confidence": 0.9788122773170471}, {"text": "SRL", "start_pos": 51, "end_pos": 54, "type": "TASK", "confidence": 0.6855947971343994}, {"text": "F-score", "start_pos": 80, "end_pos": 87, "type": "METRIC", "confidence": 0.9990854263305664}, {"text": "PropBank", "start_pos": 121, "end_pos": 129, "type": "DATASET", "confidence": 0.9775869250297546}]}, {"text": "Next, we used this SRL system to annotate the GENIA treebank automatically.", "labels": [], "entities": [{"text": "GENIA treebank", "start_pos": 46, "end_pos": 60, "type": "DATASET", "confidence": 0.9452825486660004}]}, {"text": "shows the amounts of all adjunct argument types (AMs) in BioProp.", "labels": [], "entities": [{"text": "BioProp", "start_pos": 57, "end_pos": 64, "type": "DATASET", "confidence": 0.8682577610015869}]}, {"text": "The detail description of can be found in.", "labels": [], "entities": [{"text": "detail", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9758700132369995}]}, {"text": "Subtypes of the AM Modifier Tag   Ideally, an SRL system should be adaptable to the task of information extraction in various domains with minimal effort.", "labels": [], "entities": [{"text": "AM Modifier Tag   Ideally", "start_pos": 16, "end_pos": 41, "type": "TASK", "confidence": 0.5458458364009857}, {"text": "information extraction", "start_pos": 92, "end_pos": 114, "type": "TASK", "confidence": 0.7372885793447495}]}, {"text": "That is, we should be able to port it from one domain to another.", "labels": [], "entities": []}, {"text": "In this experiment, we evaluate the cross-domain portability of our SRL system.", "labels": [], "entities": [{"text": "SRL", "start_pos": 68, "end_pos": 71, "type": "TASK", "confidence": 0.8269655704498291}]}, {"text": "We use Sections 2 to 21 of the PropBank to train our SRL system.", "labels": [], "entities": [{"text": "PropBank", "start_pos": 31, "end_pos": 39, "type": "DATASET", "confidence": 0.9775981903076172}, {"text": "SRL", "start_pos": 53, "end_pos": 56, "type": "TASK", "confidence": 0.8990947604179382}]}, {"text": "Then, we use our system to annotate Section 24 of the PropBank (denoted by Exp 1a) and all of BioProp (denoted by Exp 1b).", "labels": [], "entities": [{"text": "PropBank", "start_pos": 54, "end_pos": 62, "type": "DATASET", "confidence": 0.9595878720283508}, {"text": "BioProp", "start_pos": 94, "end_pos": 101, "type": "DATASET", "confidence": 0.8950932621955872}]}, {"text": "To compare the effects of using biomedical training data vs. using newswire data, we train our SRL system on 30 randomly selected training sets from BioProp (g 1 ,.., g 30 ) and 30 from PropBank (w 1 ,.., w 30 ), each having 1200 training PAS's.", "labels": [], "entities": [{"text": "SRL", "start_pos": 95, "end_pos": 98, "type": "TASK", "confidence": 0.9410957098007202}, {"text": "BioProp", "start_pos": 149, "end_pos": 156, "type": "DATASET", "confidence": 0.8806354999542236}, {"text": "PropBank", "start_pos": 186, "end_pos": 194, "type": "DATASET", "confidence": 0.9788224101066589}]}, {"text": "We then test our system on 30 400-PAS test sets from BioProp, with g 1 and w 1 being tested on test set 1, g 2 and w 2 onset 2, and soon.", "labels": [], "entities": [{"text": "BioProp", "start_pos": 53, "end_pos": 60, "type": "DATASET", "confidence": 0.92546546459198}]}, {"text": "Then we add up the scores for w 1 -w and g 1 -g 30 , and compare their averages.", "labels": [], "entities": []}, {"text": "In order to improve SRL performance, we add domain specific features.", "labels": [], "entities": [{"text": "SRL", "start_pos": 20, "end_pos": 23, "type": "TASK", "confidence": 0.9910847544670105}]}, {"text": "In Experiment 3, we investigate the effects of adding biomedical NE features and argument template features composed of words, NEs, and POSs.", "labels": [], "entities": []}, {"text": "The dataset selection procedure is the same as in Experiment 2.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4. Subtypes of the AM Modifier Tag", "labels": [], "entities": [{"text": "AM Modifier Tag", "start_pos": 26, "end_pos": 41, "type": "DATASET", "confidence": 0.8575946887334188}]}, {"text": " Table 5.  For argument classification, we report the preci-", "labels": [], "entities": [{"text": "argument classification", "start_pos": 15, "end_pos": 38, "type": "TASK", "confidence": 0.9283936321735382}]}, {"text": " Table 5. Summary of All Experiments", "labels": [], "entities": [{"text": "Summary", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.6094650626182556}]}, {"text": " Table 6. Performance of Exp 1a and Exp 1b", "labels": [], "entities": []}, {"text": " Table 7. Performance of Exp 2a and Exp 2b", "labels": [], "entities": []}, {"text": " Table 8. Performance of Exp 3a and Exp 3b", "labels": [], "entities": []}]}