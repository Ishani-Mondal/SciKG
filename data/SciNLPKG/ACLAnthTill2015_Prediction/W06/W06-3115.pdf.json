{"title": [{"text": "NTT System Description for the WMT2006 Shared Task", "labels": [], "entities": [{"text": "NTT System Description", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.5750787655512491}, {"text": "WMT2006 Shared Task", "start_pos": 31, "end_pos": 50, "type": "DATASET", "confidence": 0.8215570449829102}]}], "abstractContent": [{"text": "We present two translation systems experimented for the shared-task of \"Work-shop on Statistical Machine Translation,\" a phrase-based model and a hierarchical phrase-based model.", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 85, "end_pos": 116, "type": "TASK", "confidence": 0.6489902138710022}]}, {"text": "The former uses a phrasal unit for translation, whereas the latter is conceptualized as a synchronous-CFG in which phrases are hierarchically combined using non-terminals.", "labels": [], "entities": []}, {"text": "Experiments showed that the hierarchical phrase-based model performed very comparable to the phrase-based model.", "labels": [], "entities": []}, {"text": "We also report a phrase/rule extraction technique differentiating tokenization of corpora.", "labels": [], "entities": [{"text": "phrase/rule extraction", "start_pos": 17, "end_pos": 39, "type": "TASK", "confidence": 0.6212824955582619}]}], "introductionContent": [{"text": "We contrasted two translation methods for the Workshop on Statistical Machine Translation (WMT2006) shared-task.", "labels": [], "entities": [{"text": "Statistical Machine Translation (WMT2006) shared-task", "start_pos": 58, "end_pos": 111, "type": "TASK", "confidence": 0.7808798636708941}]}, {"text": "One is a phrase-based translation in which a phrasal unit is employed for translation (.", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 9, "end_pos": 33, "type": "TASK", "confidence": 0.7024801075458527}, {"text": "translation", "start_pos": 74, "end_pos": 85, "type": "TASK", "confidence": 0.9746636152267456}]}, {"text": "The other is a hierarchical phrase-based translation in which translation is realized as a set of paired production rules (.", "labels": [], "entities": []}, {"text": "Section 2 discusses those two models and details extraction algorithms, decoding algorithms and feature functions.", "labels": [], "entities": []}, {"text": "We also explored three types of corpus preprocessing in Section 3.", "labels": [], "entities": [{"text": "corpus preprocessing", "start_pos": 32, "end_pos": 52, "type": "TASK", "confidence": 0.6879051327705383}]}, {"text": "As expected, different tokenization would lead to different word alignments which, in turn, resulted in the divergence of the extracted phrase/rule size.", "labels": [], "entities": []}, {"text": "In our method, phrase/rule translation pairs extracted from three distinctly word-aligned corpora are aggregated into one large phrase/rule translation table.", "labels": [], "entities": [{"text": "phrase/rule translation", "start_pos": 15, "end_pos": 38, "type": "TASK", "confidence": 0.6294275373220444}]}, {"text": "The experiments and the final translation results are presented in Section 4.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Number of word alignment by different preprocessings.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 20, "end_pos": 34, "type": "TASK", "confidence": 0.6812015026807785}]}, {"text": " Table 2: Number of phrases extracted from differently preprocessed corpora.", "labels": [], "entities": []}, {"text": " Table 3: Open test on the 2005/2006 test sets (BLEU [%]).", "labels": [], "entities": [{"text": "2005/2006 test sets", "start_pos": 27, "end_pos": 46, "type": "DATASET", "confidence": 0.720146244764328}, {"text": "BLEU", "start_pos": 48, "end_pos": 52, "type": "METRIC", "confidence": 0.9961637258529663}]}]}