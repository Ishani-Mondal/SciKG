{"title": [{"text": "Short Text Authorship Attribution via Sequence Kernels, Markov Chains and Author Unmasking: An Investigation", "labels": [], "entities": [{"text": "Short Text Authorship Attribution", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.5327484831213951}, {"text": "Author Unmasking", "start_pos": 74, "end_pos": 90, "type": "TASK", "confidence": 0.6418307423591614}]}], "abstractContent": [{"text": "We present an investigation of recently proposed character and word sequence kernels for the task of authorship attribu-tion based on relatively short texts.", "labels": [], "entities": []}, {"text": "Performance is compared with two corresponding probabilistic approaches based on Markov chains.", "labels": [], "entities": []}, {"text": "Several configurations of the sequence kernels are studied on a relatively large dataset (50 authors), where each author covered several topics.", "labels": [], "entities": []}, {"text": "Utilis-ing Moffat smoothing, the two probabilis-tic approaches obtain similar performance, which in turn is comparable to that of character sequence kernels and is better than that of word sequence kernels.", "labels": [], "entities": []}, {"text": "The results further suggest that when using a realistic setup that takes into account the case of texts which are not written by any hypoth-esised authors, the amount of training material has more influence on discrimination performance than the amount of test material.", "labels": [], "entities": []}, {"text": "Moreover, we show that the recently proposed author unmasking approach is less useful when dealing with short texts.", "labels": [], "entities": [{"text": "author unmasking", "start_pos": 45, "end_pos": 61, "type": "TASK", "confidence": 0.7927928268909454}]}], "introductionContent": [{"text": "Applications of authorship attribution include plagiarism detection (e.g. college essays), deducing the writer of inappropriate communications that were sent anonymously or under a pseudonym (e.g. threatening or harassing e-mails), as well as resolving historical questions of unclear or disputed authorship.", "labels": [], "entities": [{"text": "authorship attribution", "start_pos": 16, "end_pos": 38, "type": "TASK", "confidence": 0.7254945933818817}, {"text": "plagiarism detection", "start_pos": 47, "end_pos": 67, "type": "TASK", "confidence": 0.7925138175487518}]}, {"text": "Specific examples are the Federalist papers and the forensic analysis of the Unabomber manifesto.", "labels": [], "entities": [{"text": "Federalist papers", "start_pos": 26, "end_pos": 43, "type": "DATASET", "confidence": 0.8505634069442749}, {"text": "Unabomber manifesto", "start_pos": 77, "end_pos": 96, "type": "DATASET", "confidence": 0.9249176979064941}]}, {"text": "Within the area of automatic author attribution, recently it has been shown that encouraging performance can be achieved via the use of probabilistic models based on n-grams and Markov chains of characters and words ().", "labels": [], "entities": [{"text": "automatic author attribution", "start_pos": 19, "end_pos": 47, "type": "TASK", "confidence": 0.6732071141401926}]}, {"text": "showed that Support Vector Machines (SVMs), using the bag-of-words kernel, can obtain promising performance, while in another study, SVMs with kernels based on character collocations obtained mixed performance.", "labels": [], "entities": []}, {"text": "utilised SVMs with syntactic and semantic features to obtain relatively minor accuracy improvements over the use of function word frequencies and part-of-speech trigrams.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.9987865090370178}]}, {"text": "proposed a word-level heuristic, resembling recursive feature elimination used for cancer classification), to obtain author unmasking curves.", "labels": [], "entities": []}, {"text": "The curves were processed to obtain feature vectors that were in turn classified in a traditional SVM setting.", "labels": [], "entities": []}, {"text": "The studies listed above have several limitations.", "labels": [], "entities": []}, {"text": "In, a rudimentary probability smoothing technique was used to handle n-grams which were unseen during the training phase.", "labels": [], "entities": [{"text": "probability smoothing", "start_pos": 18, "end_pos": 39, "type": "TASK", "confidence": 0.6902372241020203}]}, {"text": "In the dataset used by) each author tended to stick to one or two topics, raising the possibility that the discrimination was based on topic rather than by author style.", "labels": [], "entities": []}, {"text": "In) the datasets were rather small in terms of the number of authors, indicating the results may not be generalisable.", "labels": [], "entities": []}, {"text": "Specifically, in) the largest dataset contains texts from five authors, in) from three, while in () and) from ten.", "labels": [], "entities": []}, {"text": "In), the attribution of a given document was forced to one of the authors from a set of possible authors (i.e. a closed set identification setup), thus not taking into account the realistic case of having a document which was not written by any of the authors.", "labels": [], "entities": []}, {"text": "In (), the unmasking method was evaluated exclusively on books, raising the question as to whether the method is applicable to considerably shorter texts.", "labels": [], "entities": []}, {"text": "Lastly, all of the studies used different datasets and experiment setups, thus making a quantitative performance comparison of the different approaches infeasible.", "labels": [], "entities": []}, {"text": "Recently, various practical character and word sequence kernels have been proposed for the purposes of text and biological sequence analysis.", "labels": [], "entities": [{"text": "text and biological sequence analysis", "start_pos": 103, "end_pos": 140, "type": "TASK", "confidence": 0.6515427470207215}]}, {"text": "This allows kernel based techniques (such as SVMs) to be used in lieu of traditional probabilistic approaches based on Markov chains.", "labels": [], "entities": []}, {"text": "In comparison to the latter, SVMs have the advantage of directly optimising the discrimination criterion.", "labels": [], "entities": [{"text": "SVMs", "start_pos": 29, "end_pos": 33, "type": "TASK", "confidence": 0.9440115094184875}]}, {"text": "This paper has four main aims: (i) to evaluate the usefulness of sequence kernel based approaches for the task of authorship attribution; (ii) to compare their performance with two probabilistic approaches based on Markov chains of characters and words; (iii) to appraise the applicability of the author unmasking approach for dealing with short texts; and (iv) to address some of the limitations of the previous studies.", "labels": [], "entities": [{"text": "authorship attribution", "start_pos": 114, "end_pos": 136, "type": "TASK", "confidence": 0.7480387985706329}]}, {"text": "Several configurations of the sequence kernels are studied.", "labels": [], "entities": []}, {"text": "The evaluations are done on a relatively large dataset (50 authors) where each author covers several topics.", "labels": [], "entities": []}, {"text": "Rather than using long texts (such as books), in almost all of the experiments the amount of training and test material per author is varied from approx. 300 to 5000 words for both cases.", "labels": [], "entities": []}, {"text": "Moreover, rather than using a closed set identification setup, the evaluations are done using a verification setup.", "labels": [], "entities": []}, {"text": "Here, a given text material is classified as either having been written by a hypothesised author or as not written by that author (i.e. a two class discrimination task).", "labels": [], "entities": []}, {"text": "The paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes author attribution systems based on Markov chains of characters and words, followed by a description of the corresponding sequence kernel based approaches in Section 3.", "labels": [], "entities": []}, {"text": "Section 4 provides an empirical performance comparison of the abovementioned approaches, while in Section 5 the author unmasking method is appraised.", "labels": [], "entities": []}, {"text": "Section 6 concludes the paper by presenting the main findings and suggesting future directions.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have compiled a dataset that is comprised of texts from 50 newspaper journalists, with a minimum of 10,000 words per journalist.", "labels": [], "entities": []}, {"text": "Journalists were selected based on their coverage of several topics; any journalist who covered only one specific area (e.g. sports or economics) was not included in the dataset.", "labels": [], "entities": []}, {"text": "Apart from removing all advertising material and standardising the representation by converting any unicode characters to their closest ASCII counterparts, no further editing was performed.", "labels": [], "entities": []}, {"text": "The dataset is available for use by other researchers by contacting the authors.", "labels": [], "entities": []}, {"text": "In the first experiment we studied the effects of varying the order for character and word Markov chain approaches, while the amount of training material was fixed at approx. 28,000 characters and the test material (for evaluation authors) was decreased from approx. 28,000 to 1,750 characters.", "labels": [], "entities": []}, {"text": "The results show that 2nd order chains of characters generally obtain the best performance.", "labels": [], "entities": []}, {"text": "However, the difference in performance between 1st order and 2nd order chains could be considered as statistically insignificant due to the large overlap of the error bars.", "labels": [], "entities": []}, {"text": "The best performing word chain approach had an order of zero, with higher orders (not shown) having virtually the same performance as the 0th order.", "labels": [], "entities": []}, {"text": "Its performance is largely similar to the 2nd order character chain approach, with the latter obtaining a somewhat lower error rate at 28,000 characters.", "labels": [], "entities": [{"text": "error rate", "start_pos": 121, "end_pos": 131, "type": "METRIC", "confidence": 0.954161524772644}]}, {"text": "The second experiment was similar to the first, with the difference being that the amount of training material and test material was decreased from approx. 28,000 to 1,750 characters.", "labels": [], "entities": []}, {"text": "The main change between the results of this experiment (shown in) and the previous experiment's results is the faster degradation in performance as the number of characters is decreased.", "labels": [], "entities": []}, {"text": "We comment on this effect later.", "labels": [], "entities": []}, {"text": "In the third experiment we utilised SVMs with character sequence kernels and studied the effects of chunk size.", "labels": [], "entities": []}, {"text": "As SVMs employ support objects in the definition of the discriminant function (see Section 3), the training material was split into varying size chunks, ranging from approximately 62 to 4000 characters.", "labels": [], "entities": []}, {"text": "Each of the chunks can become a support chunk.", "labels": [], "entities": []}, {"text": "Naturally, the smaller the chunk size, the larger the number of chunks.", "labels": [], "entities": []}, {"text": "As the split was done without breaking sentences, the effective chunk size tended to be somewhat larger.", "labels": [], "entities": [{"text": "split", "start_pos": 7, "end_pos": 12, "type": "TASK", "confidence": 0.9675586819648743}]}, {"text": "If there is less words available than a given chunk size, then all of the remaining words are used for forming a chunk.", "labels": [], "entities": []}, {"text": "Based on preliminary experiments, the bounded range weight function with  \u03c4 =3 was used.", "labels": [], "entities": []}, {"text": "The amount of training and test material was equal and three cases were evaluated: 28,000, 14,000 and 7,000 characters.", "labels": [], "entities": []}, {"text": "Results, presented in, indicate that the optimum chunk size is approximately 500 characters for the three cases.", "labels": [], "entities": []}, {"text": "Furthermore, the optimum chunk size appears to be independent of the number of available chunks for training.", "labels": [], "entities": []}, {"text": "In the fourth experiment we studied the effects of various weight functions and sequence lengths for the character sequence kernel.", "labels": [], "entities": []}, {"text": "The amount of training and test material was fixed at approx. 28,000 characters.", "labels": [], "entities": []}, {"text": "Based on the results from the previous experiment, chunk size was set at 500.", "labels": [], "entities": [{"text": "size", "start_pos": 57, "end_pos": 61, "type": "METRIC", "confidence": 0.7216724157333374}]}, {"text": "Results for specific length suggest that most of the reliable discriminatory information is contained in sequences of length 2.", "labels": [], "entities": []}, {"text": "The error rates for the bounded range and bounded lin-  ear decay functions are quite similar, with both reaching minima for sequences of length 4; most of the improvement occurs when the sequences reach a length of 3.", "labels": [], "entities": []}, {"text": "This indicates that while sequences with a specific length of 3 and 4 are less reliable than sequences with a specific length of 2, they contain (partly) complementary information which is useful when combined with information from shorter lengths.", "labels": [], "entities": []}, {"text": "Emphasising longer lengths of 5 and 6 (via the bounded linear growth function) achieves a minor, but noticeable, performance degradation.", "labels": [], "entities": []}, {"text": "We conjecture that the degradation is caused by the sparsity of relatively long sequences, which affects the generalisation of the classifier.", "labels": [], "entities": []}, {"text": "The fifth experiment was devoted to an evaluation of the effects of chunk size for the word se- quence approach.", "labels": [], "entities": []}, {"text": "To keep the results comparable with the character sequence approach (third experiment), the training material was split into varying size chunks, ranging from approximately 62 to 8000 characters.", "labels": [], "entities": []}, {"text": "Based on the results from the first experiment, the specific length weight function with \u03c4 =1 was used (resulting in a bag-ofwords kernel).", "labels": [], "entities": []}, {"text": "The amount of training and test material was equal and three cases were evaluated: 28,000, 14,000 and 7,000 characters.", "labels": [], "entities": []}, {"text": "Results, shown in, suggest that the optimum chunk size is approximately 4000 characters for the three cases.", "labels": [], "entities": []}, {"text": "As mentioned in Section 3, for the word based approach the implicit feature space representation can have considerably higher dimensionality and be sparser than for the character based approach.", "labels": [], "entities": []}, {"text": "Consequently, longer texts would be required to adequately populate the feature space.", "labels": [], "entities": []}, {"text": "This is reflected by the optimum chunk size for the word based approach, which is roughly an order of magnitude larger than the optimum chunk size for the character based approach.", "labels": [], "entities": []}, {"text": "In the sixth experiment we compared the performance of character sequence kernels (using the bounded range function with \u03c4 =4) and several configurations of the word sequence kernels.", "labels": [], "entities": []}, {"text": "The amount of training material was fixed at approx. 28,000 characters and the test material was decreased from approx. 28,000 to 1,750 characters.", "labels": [], "entities": []}, {"text": "Based on the results of previous experiments, chunk size was set to 500 for the character based approach and to 4000 for the word based approach.", "labels": [], "entities": []}, {"text": "shows that word sequences with a specific length of 2 lead to considerably worse performance than sequences of length 1 (i.e. individual words).", "labels": [], "entities": []}, {"text": "Furthermore, the best performing combination of lengths (i.e. via the bounded linear decay function 7 ) does not provide better performance than using individual words.", "labels": [], "entities": []}, {"text": "The character sequence kernels consistently achieve a lower error rate than the best performing word sequence kernel.", "labels": [], "entities": [{"text": "error rate", "start_pos": 60, "end_pos": 70, "type": "METRIC", "confidence": 0.9744026064872742}]}, {"text": "This suggests that the sparse feature space representation, described in Section 3, is becoming an issue.", "labels": [], "entities": []}, {"text": "The final experiment was similar to the sixth, with the difference being that the amount of training material and test material was decreased from approx. 28,000 to 1,750 characters.", "labels": [], "entities": []}, {"text": "As observed for the Markov chain approaches, the main change between the results of this experiment (shown in) and the previous experiment's results is the faster degradation in performance as the number of characters is decreased.", "labels": [], "entities": []}, {"text": "Along with the results from experiments 1 and 2, this indicates that the amount of training material has considerably more influence on discrimination performance than the amount of test material.", "labels": [], "entities": []}, {"text": "In it can be observed that the best performing Markov chain based approach (characters, 2nd order) obtains comparable performance to the character sequence kernel based approach (using the bounded range function with \u03c4 =4).", "labels": [], "entities": []}, {"text": "5 Author Unmasking On Short Texts proposed an alternative method for author verification.", "labels": [], "entities": [{"text": "Author Unmasking On Short Texts", "start_pos": 2, "end_pos": 33, "type": "TASK", "confidence": 0.7691444337368012}, {"text": "author verification", "start_pos": 69, "end_pos": 88, "type": "TASK", "confidence": 0.7068786025047302}]}, {"text": "Rather than treating the verification problem directly as a two-class discrimination task (as done in Section 4), an \"author unmasking\" curve is first built.", "labels": [], "entities": []}, {"text": "A vector representing the \"essential features\" of the curve is then classified in a traditional SVM setting.", "labels": [], "entities": []}, {"text": "The unmasking procedure is reminiscent of the recursive feature elimination procedure first proposed in the context of gene selection for cancer classification ().", "labels": [], "entities": [{"text": "gene selection for cancer classification", "start_pos": 119, "end_pos": 159, "type": "TASK", "confidence": 0.7574100732803345}]}, {"text": "Instead of having an author specific model (as in the Markov chain approach) or an author specific SVM, a reference text is used.", "labels": [], "entities": []}, {"text": "The text to be classified as well as the reference text are divided into chunks; the features representing each chunk are the counts of pre-selected words.", "labels": [], "entities": []}, {"text": "Each point in the author unmasking curve is the cross-validation accuracy of discriminating between the two sets of chunks (using a linear SVM).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.8746906518936157}]}, {"text": "At each iteration, several of the most discriminative features are removed from further consideration.", "labels": [], "entities": []}, {"text": "The underlying hypothesis is that if the two given texts have been written by the same author, the differences between them will be reflected in a relatively small number of features.", "labels": [], "entities": []}, {"text": "observed that for texts authored by the same person, the extent of the cross-validation accuracy degradation is much larger than for texts written by different authors.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.9452900886535645}]}, {"text": "Encouraging classification results were obtained for long texts (books available from Project Gutenberg 8 ).", "labels": [], "entities": []}, {"text": "In this section we first confirm the unmasking effect for long texts and then show that for shorter texts (i.e. approx. 5000 words), the effect is considerably less distinctive.", "labels": [], "entities": []}, {"text": "For the first experiment we followed the setup in (), i.e. the same books, chunks with a size of approximately 500 words, 10 fold cross-validation, removing 6 features at each iteration, and using 250 words with the highest average frequency in both texts as the set of pre-selected words.", "labels": [], "entities": []}, {"text": "shows curves for unmasking Oscar Wilde's An Ideal Husband using Wilde's Woman of No Importance (same-author curve) as well as the works of other authors as reference texts (different-author curves).", "labels": [], "entities": [{"text": "unmasking Oscar Wilde's An Ideal Husband", "start_pos": 17, "end_pos": 57, "type": "TASK", "confidence": 0.882658737046378}]}, {"text": "As can 8 http://www.gutenberg.org  be observed, the unmasking effect is most pronounced for Wilde's text.", "labels": [], "entities": [{"text": "Wilde's text", "start_pos": 92, "end_pos": 104, "type": "DATASET", "confidence": 0.6618868509928385}]}, {"text": "Furthermore, this figure has a close resemblance to in ().", "labels": [], "entities": []}, {"text": "In the second experiment we used text materials from the Columnists dataset.", "labels": [], "entities": [{"text": "Columnists dataset", "start_pos": 57, "end_pos": 75, "type": "DATASET", "confidence": 0.959906280040741}]}, {"text": "Each author's text material was divided into two sections of approximately 5000 words, with the one of the sections randomly selected to be the reference material, leaving the other as the test material.", "labels": [], "entities": []}, {"text": "Based on preliminary experiments, the number of preselected words was set to 100 (with the highest average frequency in both texts) and the size of the chunks was set to 200 words.", "labels": [], "entities": []}, {"text": "The remainder of the unmasking procedure setup was the same as for the first experiment.", "labels": [], "entities": []}, {"text": "The setup for verification trials was similar to the setup in Section 4.2, with the difference being that the background authors were used to generate same-author and differentauthor curves for training the secondary SVM.", "labels": [], "entities": []}, {"text": "In all cases features from each curve were extracted, as done in (), prior to further processing.", "labels": [], "entities": []}, {"text": "provides a comparison between the performance of the unmasking approach with that of the character sequence kernel and character Markov chain based approaches, as evaluated in Section 4.", "labels": [], "entities": []}, {"text": "shows representative curves resulting from unmasking of the test material from author A, using A's as well as other authors' reference materials.", "labels": [], "entities": []}, {"text": "Generally, the unmasking effect for the same-author curves is considerably less pronounced and in some cases it is non-existent.", "labels": [], "entities": []}, {"text": "More dangerously, different-author curves often have close similarities to same-author curves.", "labels": [], "entities": []}, {"text": "The results and the above observations hence suggest that the unmasking method is less useful when dealing with relatively short texts.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Performance of author unmasking, char- acter sequence kernel approach (\u03c4 = 4, bounded  range) and character Markov chain approach (2nd  order).", "labels": [], "entities": []}]}