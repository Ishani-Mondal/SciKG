{"title": [{"text": "Automatic Extraction of Chinese Multiword Expressions with a Statis- tical Tool", "labels": [], "entities": [{"text": "Extraction of Chinese Multiword Expressions", "start_pos": 10, "end_pos": 53, "type": "TASK", "confidence": 0.7384152054786682}]}], "abstractContent": [{"text": "In this paper, we report on our experiment to extract Chinese multiword expressions from corpus resources as part of a larger research effort to improve a machine translation (MT) system.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 155, "end_pos": 179, "type": "TASK", "confidence": 0.8381846189498902}]}, {"text": "For existing MT systems, the issue of multi-word expression (MWE) identification and accurate interpretation from source to target language remains an unsolved problem.", "labels": [], "entities": [{"text": "MT", "start_pos": 13, "end_pos": 15, "type": "TASK", "confidence": 0.9895089864730835}, {"text": "multi-word expression (MWE) identification", "start_pos": 38, "end_pos": 80, "type": "TASK", "confidence": 0.7178767522176107}]}, {"text": "Our initial test on the Chinese-to-English translation functions of Systran and CCID's Huan-Yu-Tong MT systems reveal that, where MWEs are involved , MT tools suffer in terms of both comprehensibility and adequacy of the translated texts.", "labels": [], "entities": [{"text": "MT", "start_pos": 150, "end_pos": 152, "type": "TASK", "confidence": 0.9732653498649597}]}, {"text": "For MT systems to become of further practical use, they need to be enhanced with MWE processing capability.", "labels": [], "entities": [{"text": "MT", "start_pos": 4, "end_pos": 6, "type": "TASK", "confidence": 0.9880240559577942}, {"text": "MWE processing", "start_pos": 81, "end_pos": 95, "type": "TASK", "confidence": 0.6501279175281525}]}, {"text": "As part of our study towards this goal, we test and evaluate a statistical tool, which was developed for English, for identifying and extracting Chinese MWEs.", "labels": [], "entities": [{"text": "extracting Chinese MWEs", "start_pos": 134, "end_pos": 157, "type": "TASK", "confidence": 0.7424429456392924}]}, {"text": "In our evaluation, the tool achieved precisions ranging from 61.16% to 93.96% for different types of MWEs.", "labels": [], "entities": [{"text": "precisions", "start_pos": 37, "end_pos": 47, "type": "METRIC", "confidence": 0.999639630317688}, {"text": "MWEs", "start_pos": 101, "end_pos": 105, "type": "TASK", "confidence": 0.928115963935852}]}, {"text": "Such results demonstrate that it is feasible to automatically identify many Chi-nese MWEs using our tool, although it needs further improvement.", "labels": [], "entities": []}], "introductionContent": [{"text": "In real-life human communication, meaning is often conveyed byword groups, or meaning groups, rather than by single words.", "labels": [], "entities": []}, {"text": "Very often, it is difficult to interpret human speech word byword.", "labels": [], "entities": []}, {"text": "Consequently, for an MT system, it is important to identify and interpret accurate meaning of such word groups, or multiword expressions (MWE hereafter), in a source language and interpret them accurately in a target language.", "labels": [], "entities": [{"text": "MT", "start_pos": 21, "end_pos": 23, "type": "TASK", "confidence": 0.9903435707092285}]}, {"text": "However, accurate identification and interpretation of MWEs still remains an unsolved problem in MT research.", "labels": [], "entities": [{"text": "identification and interpretation of MWEs", "start_pos": 18, "end_pos": 59, "type": "TASK", "confidence": 0.6730761170387268}, {"text": "MT", "start_pos": 97, "end_pos": 99, "type": "TASK", "confidence": 0.9944315552711487}]}, {"text": "In this paper, we present our experiment on identifying Chinese MWEs using a statistical tool for MT purposes.", "labels": [], "entities": [{"text": "identifying Chinese MWEs", "start_pos": 44, "end_pos": 68, "type": "TASK", "confidence": 0.6954924166202545}, {"text": "MT", "start_pos": 98, "end_pos": 100, "type": "TASK", "confidence": 0.9919291734695435}]}, {"text": "Here, by multiword expressions, we refer to word groups whose constituent words have strong collocational relations and which can be translated in the target language into stable translation equivalents, either single words or MWEs, e.g. noun phrases, prepositional phrases etc.", "labels": [], "entities": []}, {"text": "They may include technical terminology in specific domains as well as more general fixed expressions and idioms.", "labels": [], "entities": []}, {"text": "Our observations found that existing ChineseEnglish MT systems cannot satisfactorily translate MWEs, although some may employ a machine-readable bilingual dictionary of idioms.", "labels": [], "entities": [{"text": "MT", "start_pos": 52, "end_pos": 54, "type": "TASK", "confidence": 0.5344213247299194}]}, {"text": "Whereas highly compositional MWEs may pose a trivial challenge to human speakers for interpretation, they present a tough challenge for fully automatic MT systems to produce even remotely fluent translations.", "labels": [], "entities": [{"text": "interpretation", "start_pos": 85, "end_pos": 99, "type": "TASK", "confidence": 0.9610666632652283}, {"text": "MT", "start_pos": 152, "end_pos": 154, "type": "TASK", "confidence": 0.9783635139465332}]}, {"text": "Therefore, in our context, we expand the concept of MWE to include those compositional ones which have relatively stable identifiable patterns of translations in the target language.", "labels": [], "entities": []}, {"text": "By way of illustration of the challenge, we experimented with simple Chinese sentences containing some commonly-used MWEs in SYSTRAN (http://www.systransoft.com/) and Huan-Yu-Tong (HYT henceforth) of CCID (China Centre for Information Industry Development)).", "labels": [], "entities": []}, {"text": "The former is one of the most efficient MT systems today, claiming to be \"the leading provider of the world's most scalable and modular translation architecture\", while the latter is one of the most successful MT systems in China.", "labels": [], "entities": [{"text": "MT", "start_pos": 40, "end_pos": 42, "type": "TASK", "confidence": 0.9760861992835999}, {"text": "MT", "start_pos": 210, "end_pos": 212, "type": "TASK", "confidence": 0.9689679145812988}]}, {"text": "Ice breasts coffee take is selected.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this experiment, our main aim was to examine the feasibility of practical application of the MWE tool as a component of an MT system, therefore we used test data from some domains in which translation services are in strong demand.", "labels": [], "entities": [{"text": "MT", "start_pos": 126, "end_pos": 128, "type": "TASK", "confidence": 0.9826256036758423}]}, {"text": "We selected Chinese corpus data of approximately 696,000 tokenised words (including punctuation marks) which cover the topics of food, transportation, tourism, sports (including the Olympics) and business.", "labels": [], "entities": [{"text": "Chinese corpus data", "start_pos": 12, "end_pos": 31, "type": "DATASET", "confidence": 0.7278859913349152}]}, {"text": "In our experiment, we processed the texts from different topics together.", "labels": [], "entities": []}, {"text": "These topics are related to each other under the themes of entertainment and business.", "labels": [], "entities": []}, {"text": "Therefore we assume, by mixing the data together, we could examine the performance of the MWE tool in processing data from abroad range of related domains.", "labels": [], "entities": []}, {"text": "We expect that the different features of texts from different domains will have a certain impact on the result, but the examination of such impact is beyond the scope of this paper.", "labels": [], "entities": []}, {"text": "As mentioned earlier, the Chinese word tokeniser and POS tagger used in our experiment has been developed at CCID.", "labels": [], "entities": [{"text": "CCID", "start_pos": 109, "end_pos": 113, "type": "DATASET", "confidence": 0.9670737981796265}]}, {"text": "It is an efficient tool running with accuracy of 98% for word tokenisation and 95% for POS annotation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9996684789657593}, {"text": "word tokenisation", "start_pos": 57, "end_pos": 74, "type": "TASK", "confidence": 0.745810329914093}]}, {"text": "It employs a part-of-speech tagset of 15 categories shown in  Since function words are found to cause noise in the process of MWE identification, a Chinese stop list was collected.", "labels": [], "entities": [{"text": "MWE identification", "start_pos": 126, "end_pos": 144, "type": "TASK", "confidence": 0.978221595287323}]}, {"text": "First, a word frequency list was extracted.", "labels": [], "entities": []}, {"text": "Next, the top items were considered and we selected 70 closed class words for the stop word list.", "labels": [], "entities": []}, {"text": "When the program searches for MWEs, such words are ignored.", "labels": [], "entities": []}, {"text": "The threshold of word affinity strength is another issue to be addressed.", "labels": [], "entities": []}, {"text": "In this experiment, we used log-likelihood to measure the strength of collocation between word pairs.", "labels": [], "entities": []}, {"text": "Generally the log-likelihood score of 6.6 (p < 0.01 or 99% confidence) is recommended as the threshold), but it was found to produce too many false candidates in our case.", "labels": [], "entities": []}, {"text": "Based on our initial trials, we used a higher threshold of 30, i.e. any word pairs producing log-likelihood scoreless than this value are ignored in the MWE searching process.", "labels": [], "entities": [{"text": "MWE searching", "start_pos": 153, "end_pos": 166, "type": "TASK", "confidence": 0.9551259577274323}]}, {"text": "Furthermore, for the sake of the reliability of the statistical score, when extracting collocates, a frequency threshold of five was used to filter out low-frequency words, i.e. word pairs with frequencies less than five were ignored.", "labels": [], "entities": [{"text": "reliability", "start_pos": 33, "end_pos": 44, "type": "METRIC", "confidence": 0.9665307998657227}]}, {"text": "An interesting issue for us in this experiment is the impact of the length of collocation searching window on the MWE identification.", "labels": [], "entities": [{"text": "MWE identification", "start_pos": 114, "end_pos": 132, "type": "TASK", "confidence": 0.9423473179340363}]}, {"text": "For this purpose, we tested two search window lengths 2 and 3, and compared the results obtained by using them.", "labels": [], "entities": []}, {"text": "Our initial hypothesis was that the shorter window length may produce higher precision while the longer window length may sacrifice precision but boost the MWE coverage.", "labels": [], "entities": [{"text": "precision", "start_pos": 77, "end_pos": 86, "type": "METRIC", "confidence": 0.9987937211990356}, {"text": "precision", "start_pos": 132, "end_pos": 141, "type": "METRIC", "confidence": 0.9992374181747437}, {"text": "MWE coverage", "start_pos": 156, "end_pos": 168, "type": "METRIC", "confidence": 0.6383822560310364}]}, {"text": "The output of the tool was manually checked by Chinese experts at CCID, including cross checking to guarantee the reliability of the results.", "labels": [], "entities": [{"text": "CCID", "start_pos": 66, "end_pos": 70, "type": "DATASET", "confidence": 0.9318334460258484}, {"text": "reliability", "start_pos": 114, "end_pos": 125, "type": "METRIC", "confidence": 0.9626349806785583}]}, {"text": "There were some MWE candidates on which disagreements arose.", "labels": [], "entities": [{"text": "MWE", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.775397777557373}]}, {"text": "In such cases, the candidate was counted as false.", "labels": [], "entities": []}, {"text": "Furthermore, in order to estimate the recall, experts manually identified MWEs in the whole test corpus, so that the output of the automatic tool could be compared against it.", "labels": [], "entities": [{"text": "recall", "start_pos": 38, "end_pos": 44, "type": "METRIC", "confidence": 0.9991372227668762}]}, {"text": "In the following section, we present a detailed report on our evaluation of the MWE tool.", "labels": [], "entities": [{"text": "MWE", "start_pos": 80, "end_pos": 83, "type": "TASK", "confidence": 0.8822936415672302}]}, {"text": "We first evaluated the overall precision of the tool.", "labels": [], "entities": [{"text": "precision", "start_pos": 31, "end_pos": 40, "type": "METRIC", "confidence": 0.9994775652885437}]}, {"text": "A total of 7,142 MWE candidates (types) were obtained for window lengths of 2, of which 4,915 were accepted as true MWEs, resulting in a precision of 68.82%.", "labels": [], "entities": [{"text": "precision", "start_pos": 137, "end_pos": 146, "type": "METRIC", "confidence": 0.998681366443634}]}, {"text": "On the other hand, a total of 8,123 MWE candidates (types) were obtained for window lengths of 3, of which 4,968 were accepted as true MWEs, resulting in a precision of 61.16%.", "labels": [], "entities": [{"text": "precision", "start_pos": 156, "end_pos": 165, "type": "METRIC", "confidence": 0.9987589120864868}]}, {"text": "This result is in agreement with our hypothesis that shorter search window length tends to produce higher precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 106, "end_pos": 115, "type": "METRIC", "confidence": 0.997065007686615}]}, {"text": "Next, we estimated the recall based on the manually analysed data.", "labels": [], "entities": [{"text": "recall", "start_pos": 23, "end_pos": 29, "type": "METRIC", "confidence": 0.9995204210281372}]}, {"text": "When we compared the accepted MWEs from the automatic result against the manually collected ones, we found that the experts tend to mark longer MWEs, which often contain the items identified by the automatic tool.", "labels": [], "entities": []}, {"text": "For example, the manually marked MWE \u7f51\u7403 \u8fd0\u52a8 \u53d1\u5c55 \u8ba1\u5212 (development plan for the tennis sport) contains shorter MWEs \u7f51\u7403 \u8fd0\u52a8 (tennis sport) and \u53d1\u5c55 \u8ba1\u5212 (development plan) which were identified by the tool separately.", "labels": [], "entities": []}, {"text": "So we decided to take the partial matches into account when we estimate the recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 76, "end_pos": 82, "type": "METRIC", "confidence": 0.9984839558601379}]}, {"text": "We found that a total 14,045 MWEs were manually identified and, when the search window length was set to two and three, 1,988 and 2,044 of them match the automatic output, producing recalls of 14.15% and 14.55% respectively.", "labels": [], "entities": [{"text": "recalls", "start_pos": 182, "end_pos": 189, "type": "METRIC", "confidence": 0.9984472393989563}]}, {"text": "It should be noted that many of the manually accepted MWEs from the automatic output were not found in the manual MWE collection.", "labels": [], "entities": []}, {"text": "This discrepancy was likely caused by the manual analysis being carried out independently of the automatic tool, resulting in a lower recall than expected.", "labels": [], "entities": [{"text": "recall", "start_pos": 134, "end_pos": 140, "type": "METRIC", "confidence": 0.9995362758636475}]}, {"text": "Generally speaking, statistical algorithms work better on items of higher frequency as it depends on the collocational information.", "labels": [], "entities": []}, {"text": "However, our tool does not select MWEs directly from the collocates.", "labels": [], "entities": []}, {"text": "Rather, it uses the collocational information as a statistical dictionary and searches for word sequences whose constituent words have significantly strong collocational bonds between them.", "labels": [], "entities": []}, {"text": "As a result, it is capable of identifying many low-frequency MWEs.", "labels": [], "entities": []}, {"text": "lists the breakdown of the precision for five frequency bands (window length = 2).", "labels": [], "entities": [{"text": "precision", "start_pos": 27, "end_pos": 36, "type": "METRIC", "confidence": 0.9974179267883301}]}], "tableCaptions": [{"text": " Table 3: Overall precisions and recalls", "labels": [], "entities": [{"text": "precisions", "start_pos": 18, "end_pos": 28, "type": "METRIC", "confidence": 0.9994345307350159}, {"text": "recalls", "start_pos": 33, "end_pos": 40, "type": "METRIC", "confidence": 0.9555396437644958}]}, {"text": " Table 4: Breakdown of precision for frequencies  (window length = 2).", "labels": [], "entities": [{"text": "Breakdown", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9252786636352539}, {"text": "precision", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.9468432664871216}]}, {"text": " Table 5: Breakdown of precision for frequencies  (window length = 3).", "labels": [], "entities": [{"text": "Breakdown", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9364789724349976}, {"text": "precision", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.9585340619087219}]}, {"text": " Table 6: Precisions for three types of MWEs", "labels": [], "entities": [{"text": "MWEs", "start_pos": 40, "end_pos": 44, "type": "TASK", "confidence": 0.938855767250061}]}]}