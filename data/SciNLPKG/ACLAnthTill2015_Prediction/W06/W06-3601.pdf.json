{"title": [{"text": "A Syntax-Directed Translator with Extended Domain of Locality", "labels": [], "entities": []}], "abstractContent": [{"text": "A syntax-directed translator first parses the source-language input into a parse-tree, and then recursively converts the tree into a string in the target-language.", "labels": [], "entities": []}, {"text": "We model this conversion by an extended tree-to-string transducer that have multi-level trees on the source-side, which gives our system more expressive power and flexibility.", "labels": [], "entities": []}, {"text": "We also define a direct probability model and use a linear-time dynamic programming algorithm to search for the best derivation.", "labels": [], "entities": []}, {"text": "The model is then extended to the general log-linear framework in order to rescore with other features like n-gram language models.", "labels": [], "entities": []}, {"text": "We devise a simple-yet-effective algorithm to generate non-duplicate k-best translations for n-gram rescoring.", "labels": [], "entities": []}, {"text": "Initial experimental results on English-to-Chinese translation are presented.", "labels": [], "entities": [{"text": "English-to-Chinese translation", "start_pos": 32, "end_pos": 62, "type": "TASK", "confidence": 0.6167631447315216}]}], "introductionContent": [{"text": "The concept of syntax-directed (SD) translation was originally proposed in compiling, where the source program is parsed into a tree representation that guides the generation of the object code.", "labels": [], "entities": [{"text": "syntax-directed (SD) translation", "start_pos": 15, "end_pos": 47, "type": "TASK", "confidence": 0.7641400456428528}]}, {"text": "Following, a translation, as a set of string pairs, can be specified by a syntax-directed translation schema (SDTS), which is essentially asynchronous context-free grammar (SCFG) that generates two languages simultaneously.", "labels": [], "entities": []}, {"text": "An SDTS also induces a translator, a device that performs the transformation from input string to output string.", "labels": [], "entities": []}, {"text": "In this context, an SD translator consists of two components, a sourcelanguage parser and a recursive converter which is usually modeled as a top-down tree-to-string transducer.", "labels": [], "entities": []}, {"text": "The relationship among these concepts is illustrated in.", "labels": [], "entities": []}, {"text": "This paper adapts the idea of syntax-directed translator to statistical machine translation (MT).", "labels": [], "entities": [{"text": "statistical machine translation (MT)", "start_pos": 60, "end_pos": 96, "type": "TASK", "confidence": 0.7738340745369593}]}, {"text": "We apply stochastic operations at each node of the source-language parse-tree and search for the best derivation (a sequence of translation steps) that converts the whole tree into some target-language string with the highest probability.", "labels": [], "entities": []}, {"text": "However, the structural divergence across languages often results in nonisomorphic parse-trees that is beyond the power of SCFGs.", "labels": [], "entities": []}, {"text": "For example, the S(VO) structure in English is translated into a VSO word-order in Arabic, an instance of complex reordering not captured by any SCFG.", "labels": [], "entities": []}, {"text": "To alleviate the non-isomorphism problem, (synchronous) grammars with richer expressive power have been proposed whose rules apply to larger fragments of the tree.", "labels": [], "entities": []}, {"text": "For example, Shieber and Schabes (1990) introduce synchronous tree-adjoining grammar (STAG) and Eisner (2003) uses asynchronous tree-substitution grammar (STSG), which is a restricted version of STAG with no adjunctions.", "labels": [], "entities": []}, {"text": "STSGs and STAGs generate more tree relations than SCFGs, e.g. the non-isomorphic tree pair in.", "labels": [], "entities": []}, {"text": "This extra expressive power lies in the extended domain of locality (EDL), i.e., elementary structures beyond the scope of onelevel context-free productions.", "labels": [], "entities": []}, {"text": "Besides being linguistically motivated, the need for EDL is also supported by empirical findings in MT that one-level rules are often inadequate).", "labels": [], "entities": [{"text": "MT", "start_pos": 100, "end_pos": 102, "type": "TASK", "confidence": 0.904688835144043}]}, {"text": "Similarly, in the tree-transducer terminology, define extended tree transducers that have multi-level trees on the source-side.", "labels": [], "entities": []}, {"text": "Since an SD translator separates the sourcelanguage analysis from the recursive transformation, the domains of locality in these two modules are orthogonal to each other: in this work, we use a CFGbased Treebank parser but focuses on the extended domain in the recursive converter.", "labels": [], "entities": [{"text": "CFGbased Treebank parser", "start_pos": 194, "end_pos": 218, "type": "DATASET", "confidence": 0.9630877176920573}]}, {"text": "Following, we use a special class of extended tree-to-string transducer (xRs for short) with multilevel left-hand-side (LHS) trees.", "labels": [], "entities": []}, {"text": "Since the righthand-side (RHS) string can be viewed as a flat onelevel tree with the same nonterminal root from LHS (, this framework is closely related to STSGs: they both have extended domain of locality on the source-side, while our framework remains as a CFG on the target-side.", "labels": [], "entities": []}, {"text": "For instance, an equivalent xRs rule for the complex reordering in would be S(x 1 :NP, VP(x 2 :VB, While Section 3 will define the model formally, we first proceed with an example translation from English to Chinese (note in particular that the inverted phrases between source and target): 1 Throughout this paper, we will use LHS and source-side interchangeably (so are RHS and target-side).", "labels": [], "entities": []}, {"text": "In accordance with our experiments, we also use English and Chinese as the source and target languages, opposite to the Foreign-to-English convention of.", "labels": [], "entities": []}, {"text": "(1) the gunman was killed by the police . \u2022 . shows how the translator works.", "labels": [], "entities": [{"text": "translator", "start_pos": 60, "end_pos": 70, "type": "TASK", "confidence": 0.9576343894004822}]}, {"text": "The English sentence (a) is first parsed into the tree in (b), which is then recursively converted into the Chinese string in (e) through five steps.", "labels": [], "entities": []}, {"text": "First, at the root node, we apply the ruler 1 which preserves the toplevel word-order and translates the English period into its Chinese counterpart: Then, the ruler 2 grabs the whole sub-tree for \"the gunman\" and translates it as a phrase: (r 2 ) NP-C ( DT (the) NN (gunman) ) \u2192 qiangshou Now we get a \"partial Chinese, partial English\" sentence \"qiangshou VP \u2022 \" as shown in.", "labels": [], "entities": []}, {"text": "Our recursion goes onto translate the VP sub-tree.", "labels": [], "entities": []}, {"text": "Here we use the ruler 3 for the passive construction: which captures the fact that the agent (NP-C, \"the police\") and the verb (VBN, \"killed\") are always inverted between English and Chinese in a passive voice.", "labels": [], "entities": []}, {"text": "Finally, we apply rules r 4 and r 5 which perform phrasal translations for the two remaining subtrees in (d), respectively, and get the completed Chinese string in (e).", "labels": [], "entities": []}], "datasetContent": [{"text": "Our experiments are on English-to-Chinese translation, the opposite direction to most of the recent work in SMT.", "labels": [], "entities": [{"text": "English-to-Chinese translation", "start_pos": 23, "end_pos": 53, "type": "TASK", "confidence": 0.6294276714324951}, {"text": "SMT", "start_pos": 108, "end_pos": 111, "type": "TASK", "confidence": 0.9776866436004639}]}, {"text": "We are not doing the reverse direction at this time partly due to the lack of a sufficiently good parser for Chinese.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: BLEU (r1n4) score results", "labels": [], "entities": [{"text": "BLEU (r1n4) score", "start_pos": 10, "end_pos": 27, "type": "METRIC", "confidence": 0.7350646197795868}]}]}