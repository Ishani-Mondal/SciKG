{"title": [{"text": "Spotting the 'Odd-one-out': Data-Driven Error Detection and Correction in Textual Databases", "labels": [], "entities": [{"text": "Odd-one-out", "start_pos": 14, "end_pos": 25, "type": "METRIC", "confidence": 0.9184781312942505}]}], "abstractContent": [{"text": "We present two methods for semi-automatic detection and correction of errors in textual databases.", "labels": [], "entities": [{"text": "semi-automatic detection and correction of errors", "start_pos": 27, "end_pos": 76, "type": "TASK", "confidence": 0.7782513201236725}]}, {"text": "The first method (horizontal correction) aims at correcting inconsistent values within a database record, while the second (vertical correction) focuses on values which were entered in the wrong column.", "labels": [], "entities": []}, {"text": "Both methods are data-driven and language-independent.", "labels": [], "entities": []}, {"text": "We utilise supervised machine learning, but the training data is obtained automatically from the database; no manual annotation is required.", "labels": [], "entities": []}, {"text": "Our experiments show that a significant proportion of errors can be detected by the two methods.", "labels": [], "entities": []}, {"text": "Furthermore , both methods were found to lead to a precision that is high enough to make semi-automatic error correction feasible.", "labels": [], "entities": [{"text": "precision", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.999396800994873}, {"text": "error correction", "start_pos": 104, "end_pos": 120, "type": "TASK", "confidence": 0.7247352600097656}]}], "introductionContent": [{"text": "Over the last decades, more and more information has become available in digital form; a major part of this information is textual.", "labels": [], "entities": []}, {"text": "While some textual information is stored in raw or typeset form (i.e., as more or less flat text), a lot is semistructured in databases.", "labels": [], "entities": []}, {"text": "A popular example of a textual database is Amazon's book database, 1 which contains fields for \"author\", \"title\", \"publisher\", \"summary\" etc.", "labels": [], "entities": [{"text": "Amazon's book database, 1", "start_pos": 43, "end_pos": 68, "type": "DATASET", "confidence": 0.7634605566660563}]}, {"text": "Information about collections in the cultural heritage domain is also frequently stored in (semi-)textual databases.", "labels": [], "entities": []}, {"text": "Examples of publicly accessible databases of this type are the University of St. Andrews's photographic http://www.amazon.com collection 2 or the Nederlands Soortenregister.", "labels": [], "entities": []}, {"text": "Such databases are an important resource for researchers in the field, especially if the contents can be systematically searched and queried.", "labels": [], "entities": []}, {"text": "However, information retrieval from databases can be adversely affected by errors and inconsistencies in the data.", "labels": [], "entities": [{"text": "information retrieval from databases", "start_pos": 9, "end_pos": 45, "type": "TASK", "confidence": 0.8028071001172066}]}, {"text": "For example, a zoologist interested in finding out about the different biotopes (i.e., habitats) in which a given species was found, might query a zoological specimens database for the content of the BIOTOPE column for all specimens of that species.", "labels": [], "entities": [{"text": "BIOTOPE", "start_pos": 200, "end_pos": 207, "type": "METRIC", "confidence": 0.8895467519760132}]}, {"text": "Whenever information about the biotope was entered in the wrong column, that particular record will not be retrieved by such a query.", "labels": [], "entities": []}, {"text": "Similarly, if an entry erroneously lists the wrong species, it will also not be retrieved.", "labels": [], "entities": []}, {"text": "Usually it is impossible to avoid errors completely, even in well maintained databases.", "labels": [], "entities": []}, {"text": "Errors can arise fora variety of reasons, ranging from technical limitations (e.g., copy-and-paste errors) to different interpretations of what type of information should be entered into different database fields.", "labels": [], "entities": []}, {"text": "The latter situation is especially prevalent if the database is maintained by several people.", "labels": [], "entities": []}, {"text": "Manual identification and correction of errors is frequently infeasible due to the size of the database.", "labels": [], "entities": []}, {"text": "A more realistic approach would be to use automatic means to identify potential errors; these could then be flagged and presented to a human expert, and subsequently corrected manually or semi-automatically.", "labels": [], "entities": []}, {"text": "Error detection and correction can be performed as a pre-processing step for information extraction from databases, or it can be interleaved with it.", "labels": [], "entities": [{"text": "Error detection and correction", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7379068955779076}, {"text": "information extraction from databases", "start_pos": 77, "end_pos": 114, "type": "TASK", "confidence": 0.8145988136529922}]}, {"text": "In this paper, we explore whether it is possi-ble to detect and correct potential errors in textual databases by applying data-driven clean-up methods which are able to work in the absence of background knowledge (e.g., knowledge about the domain or the structure of the database) and instead rely on the data itself to discover inconsistencies and errors.", "labels": [], "entities": []}, {"text": "Ideally, error detection should also be language independent, i.e., require no or few language specific tools, such as part-of-speech taggers or chunkers.", "labels": [], "entities": [{"text": "error detection", "start_pos": 9, "end_pos": 24, "type": "TASK", "confidence": 0.7131984531879425}]}, {"text": "Aiming for language independence is motivated by the observation that many databases, especially in the cultural heritage domain, are multi-lingual and contain strings of text in various languages.", "labels": [], "entities": [{"text": "language independence", "start_pos": 11, "end_pos": 32, "type": "TASK", "confidence": 0.720709428191185}]}, {"text": "If textual data-cleaning methods are to be useful for such databases, they should ideally be able to process all text strings, not only those in the majority language.", "labels": [], "entities": []}, {"text": "While there has been a significant amount of previous research on identifying and correcting errors in data sets, most methods are not particularly suitable for textual databases (see Section 2).", "labels": [], "entities": [{"text": "identifying and correcting errors", "start_pos": 66, "end_pos": 99, "type": "TASK", "confidence": 0.7292074784636497}]}, {"text": "We present two methods which are.", "labels": [], "entities": []}, {"text": "Both methods are data-driven and knowledge-lean; errors are identified through comparisons with other database fields.", "labels": [], "entities": []}, {"text": "We utilise supervised machine learning, but the training data is derived directly from the database, i.e., no manual annotation of data is necessary.", "labels": [], "entities": []}, {"text": "In the first method, the database fields of individual entries are compared, and improbable combinations are flagged as potential errors.", "labels": [], "entities": []}, {"text": "Because the focus is on individual entries, i.e., rows in the database, we call this horizontal error correction.", "labels": [], "entities": []}, {"text": "The second method aims at a different type of error, namely values which were entered in the wrong column of the database.", "labels": [], "entities": []}, {"text": "Potential errors of this type are determined by comparing the content of a database cell to (the cells of) all database columns and determining which column it fits best.", "labels": [], "entities": []}, {"text": "Because the focus is on columns, we refer to this method as vertical error correction.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Data set sizes for taxonomic fields", "labels": [], "entities": []}, {"text": " Table 2: Test set prediction accuracies for taxo- nomic field values (horizontal method)", "labels": [], "entities": []}, {"text": " Table 3: Error correction precision (horizontal method)", "labels": [], "entities": [{"text": "Error correction precision", "start_pos": 10, "end_pos": 36, "type": "METRIC", "confidence": 0.888592799504598}]}, {"text": " Table 6: Examples of automatically corrected errors (vertical method)", "labels": [], "entities": []}, {"text": " Table 5: Results automatic error detection and cor- rection for all database fields (vertical method)", "labels": [], "entities": []}, {"text": " Table 7: Precision and Recall for three free text  columns (vertical method)", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9926652312278748}, {"text": "Recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9793669581413269}]}]}