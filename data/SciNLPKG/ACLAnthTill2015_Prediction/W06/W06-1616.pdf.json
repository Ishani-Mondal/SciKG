{"title": [{"text": "Incremental Integer Linear Programming for Non-projective Dependency Parsing", "labels": [], "entities": [{"text": "Incremental Integer Linear Programming", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.7849228531122208}]}], "abstractContent": [{"text": "Integer Linear Programming has recently been used for decoding in a number of probabilistic models in order to enforce global constraints.", "labels": [], "entities": []}, {"text": "However, in certain applications , such as non-projective dependency parsing and machine translation, the complete formulation of the decoding problem as an integer linear program renders solving intractable.", "labels": [], "entities": [{"text": "non-projective dependency parsing", "start_pos": 43, "end_pos": 76, "type": "TASK", "confidence": 0.7237372597058614}, {"text": "machine translation", "start_pos": 81, "end_pos": 100, "type": "TASK", "confidence": 0.8211731612682343}]}, {"text": "We present an approach which solves the problem in-crementally, thus we avoid creating intractable integer linear programs.", "labels": [], "entities": []}, {"text": "This approach is applied to Dutch dependency parsing and we show how the addition of linguistically motivated constraints can yield a significant improvement over state-of-the-art.", "labels": [], "entities": [{"text": "Dutch dependency parsing", "start_pos": 28, "end_pos": 52, "type": "TASK", "confidence": 0.6386569937070211}]}], "introductionContent": [{"text": "Many inference algorithms require models to make strong assumptions of conditional independence between variables.", "labels": [], "entities": []}, {"text": "For example, the Viterbi algorithm used for decoding in conditional random fields requires the model to be Markovian.", "labels": [], "entities": []}, {"text": "Strong assumptions are also made in the case of non-projective dependency parsing model.", "labels": [], "entities": []}, {"text": "Here attachment decisions are made independently of one another . However, often such assumptions cannot be justified.", "labels": [], "entities": []}, {"text": "For example in dependency parsing, if a subject has already been identified fora given verb, then the probability of attaching a second subject to the verb is zero.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 15, "end_pos": 33, "type": "TASK", "confidence": 0.822414219379425}]}, {"text": "Similarly, if we find that one coordination argument is a noun, then the other argu-", "labels": [], "entities": []}], "datasetContent": [{"text": "Our experiments were designed to answer the following questions: 1.", "labels": [], "entities": []}, {"text": "How much do our additional constraints help improve accuracy?", "labels": [], "entities": [{"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9959704875946045}]}, {"text": "2. How fast is our generic inference method in comparison with the Chu-Liu-Edmonds algorithm?", "labels": [], "entities": []}, {"text": "3. Can approximations be used to increase the speed of our method while remaining accurate?", "labels": [], "entities": [{"text": "speed", "start_pos": 46, "end_pos": 51, "type": "METRIC", "confidence": 0.9883220791816711}]}, {"text": "Before we try to answer these questions we briefly describe our data, features used, settings for U and P in our parametric constraints, our working environment and our implementation.", "labels": [], "entities": []}, {"text": "We now concentrate on the runtime of our method.", "labels": [], "entities": []}, {"text": "While we expect a longer runtime than using the Chu-Liu-Edmonds as in previous work), we are interested in how large the increase is. shows the average solve time (ST) for sentences with respect to the number of tokens in each sentence for our system with constraints (cnstr) and the Chu-Liu-Edmonds (CLE) algorithm.", "labels": [], "entities": [{"text": "solve time (ST)", "start_pos": 152, "end_pos": 167, "type": "METRIC", "confidence": 0.9137798190116883}]}, {"text": "All solve times do not include feature extraction as this is identical for all systems.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 31, "end_pos": 49, "type": "TASK", "confidence": 0.6897478699684143}]}, {"text": "For cnstr we also show the number of sentences that could not be parsed after two minutes, the average number of iterations and the average duration of the first iteration.", "labels": [], "entities": []}, {"text": "The results show that parsing using our generic approach is still reasonably fast although significantly slower than using the Chu-Liu-Edmonds algorithm.", "labels": [], "entities": [{"text": "parsing", "start_pos": 22, "end_pos": 29, "type": "TASK", "confidence": 0.9796485304832458}]}, {"text": "Also, only a small number of sentences take longer than two minutes to parse.", "labels": [], "entities": []}, {"text": "Thus, in practice we would not see a significant degradation in performance if we were to fallback on the CLE algorithm after two minutes of solving.", "labels": [], "entities": []}, {"text": "When we examine the average duration of the first iteration it appears that the majority of the solve time is spent within this iteration.", "labels": [], "entities": []}, {"text": "This could be used to justify using the CLE algorithm to find a initial solution as starting point for the ILP solver (see Section 6).", "labels": [], "entities": [{"text": "ILP solver", "start_pos": 107, "end_pos": 117, "type": "TASK", "confidence": 0.7420679330825806}]}], "tableCaptions": [{"text": " Table 1: Labelled (LAC) and unlabelled (UAC) ac- curacy using nine-fold cross-validation on cross  for baseline (bl) and constraint-based (constr) sys- tem. LC and UC are the percentages of sentences  with 100% labelled and unlabelled accuracy, re- spectively.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 236, "end_pos": 244, "type": "METRIC", "confidence": 0.9799980521202087}]}, {"text": " Table 2: Runtime evaluation for different sentence lengths. Average solve time (ST) for our system  with constraints (constr), the Chu-Liu-Edmonds algorithm (CLE), number of sentences with solve times  greater than 120 seconds, average number of iterations and first iteration solve time.", "labels": [], "entities": [{"text": "Average solve time (ST)", "start_pos": 61, "end_pos": 84, "type": "METRIC", "confidence": 0.8798258205254873}]}, {"text": " Table 3: Labelled accuracy (LAC) and total solve  time (ST) for the cross dataset using varying q val- ues and the Chu-Liu-Edmonds algorithm (CLE)", "labels": [], "entities": [{"text": "accuracy (LAC)", "start_pos": 19, "end_pos": 33, "type": "METRIC", "confidence": 0.9343252927064896}, {"text": "total solve  time (ST)", "start_pos": 38, "end_pos": 60, "type": "METRIC", "confidence": 0.8499124546845754}]}]}