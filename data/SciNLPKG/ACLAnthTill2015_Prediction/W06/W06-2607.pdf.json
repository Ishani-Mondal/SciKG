{"title": [{"text": "Tree Kernel Engineering in Semantic Role Labeling Systems", "labels": [], "entities": [{"text": "Tree Kernel Engineering", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.6401128470897675}, {"text": "Semantic Role Labeling", "start_pos": 27, "end_pos": 49, "type": "TASK", "confidence": 0.6757198770840963}]}], "abstractContent": [{"text": "Recent work on the design of automatic systems for semantic role labeling has shown that feature engineering is a complex task from a modeling and implementation point of view.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 51, "end_pos": 73, "type": "TASK", "confidence": 0.6444981594880422}, {"text": "feature engineering", "start_pos": 89, "end_pos": 108, "type": "TASK", "confidence": 0.8080913722515106}]}, {"text": "Tree kernels alleviate such complexity as kernel functions generate features automatically and require less software development for data extraction.", "labels": [], "entities": [{"text": "data extraction", "start_pos": 133, "end_pos": 148, "type": "TASK", "confidence": 0.7280526757240295}]}, {"text": "In this paper, we study several tree kernel approaches for both boundary detection and argument classification.", "labels": [], "entities": [{"text": "boundary detection", "start_pos": 64, "end_pos": 82, "type": "TASK", "confidence": 0.7358522266149521}, {"text": "argument classification", "start_pos": 87, "end_pos": 110, "type": "TASK", "confidence": 0.7175847142934799}]}, {"text": "The comparative experiments on Support Vector Machines with such kernels on the CoNLL 2005 dataset show that very simple tree manipulations trigger automatic feature engineering that highly improves accuracy and efficiency in both phases.", "labels": [], "entities": [{"text": "CoNLL 2005 dataset", "start_pos": 80, "end_pos": 98, "type": "DATASET", "confidence": 0.9843426545461019}, {"text": "accuracy", "start_pos": 199, "end_pos": 207, "type": "METRIC", "confidence": 0.996476948261261}]}, {"text": "Moreover, the use of different classifiers for internal and pre-terminal nodes maintains the same accuracy and highly improves efficiency.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 98, "end_pos": 106, "type": "METRIC", "confidence": 0.9993506073951721}]}], "introductionContent": [{"text": "A lot of attention has been recently devoted to the design of systems for the automatic labeling of semantic roles (SRL) as defined in two important projects: FrameNet (Johnson and Fillmore,), inspired by Frame Semantics, and PropBank () based on Levin's verb classes.", "labels": [], "entities": [{"text": "labeling of semantic roles (SRL)", "start_pos": 88, "end_pos": 120, "type": "TASK", "confidence": 0.8285121321678162}]}, {"text": "In general, given a sentence in natural language, the annotation of a predicate's semantic roles requires (1) the detection of the target word that embodies the predicate and (2) the detection and classification of the word sequences constituting the predicate's arguments.", "labels": [], "entities": []}, {"text": "In particular, step (2) can be divided into two different phases: (a) boundary detection, in which the words of the sequence are detected and (b) argument classification, in which the type of the argument is selected.", "labels": [], "entities": [{"text": "boundary detection", "start_pos": 70, "end_pos": 88, "type": "TASK", "confidence": 0.7009138911962509}, {"text": "argument classification", "start_pos": 146, "end_pos": 169, "type": "TASK", "confidence": 0.7242900133132935}]}, {"text": "Most machine learning models adopted for the SRL task have shown that (shallow or deep) syntactic information is necessary to achieve a good labeling accuracy.", "labels": [], "entities": [{"text": "SRL task", "start_pos": 45, "end_pos": 53, "type": "TASK", "confidence": 0.9387567043304443}, {"text": "accuracy", "start_pos": 150, "end_pos": 158, "type": "METRIC", "confidence": 0.7602296471595764}]}, {"text": "This research brings a wide empirical evidence in favor of the linking theories between semantics and syntax, e.g..", "labels": [], "entities": []}, {"text": "However, as no theory provides a sound and complete treatment of such issue, the choice and design of syntactic features for the automatic learning of semantic structures requires remarkable research efforts and intuition.", "labels": [], "entities": []}, {"text": "For example, the earlier studies concerning linguistic features suitable for semantic role labeling were carried out in ().", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 77, "end_pos": 99, "type": "TASK", "confidence": 0.6654037137826284}]}, {"text": "Since then, researchers have proposed diverse syntactic feature sets that only slightly enhance the previous ones, e.g. ( or.", "labels": [], "entities": []}, {"text": "A careful analysis of such features reveals that most of them are syntactic tree fragments of training sentences, thus a natural way to represent them is the adoption of tree kernels as described in).", "labels": [], "entities": []}, {"text": "The idea is to associate with each argument the minimal subtree that includes the target predicate with one of its arguments, and to use a tree kernel function to evaluate the number of common substructures between two such trees.", "labels": [], "entities": []}, {"text": "Such approach is inline with current research on the use of tree kernels for natural language learning, e.g. syntactic parsing re-ranking (), relation extraction ( and named entity recognition (.", "labels": [], "entities": [{"text": "syntactic parsing re-ranking", "start_pos": 109, "end_pos": 137, "type": "TASK", "confidence": 0.7911597490310669}, {"text": "relation extraction", "start_pos": 142, "end_pos": 161, "type": "TASK", "confidence": 0.8991008102893829}, {"text": "named entity recognition", "start_pos": 168, "end_pos": 192, "type": "TASK", "confidence": 0.6140346229076385}]}, {"text": "Regarding the use of tree kernels for SRL, in) two main drawbacks have been pointed out: \u2022 Highly accurate boundary detection cannot be carried out by a tree kernel model since correct and incorrect arguments may share a large portion of the encoding trees, i.e. they may share many substructures.", "labels": [], "entities": [{"text": "SRL", "start_pos": 38, "end_pos": 41, "type": "TASK", "confidence": 0.9910089373588562}, {"text": "boundary detection", "start_pos": 107, "end_pos": 125, "type": "TASK", "confidence": 0.7559435367584229}]}, {"text": "\u2022 Manually derived features (extended with a polynomial kernel) have been shown to be superior to tree kernel approaches.", "labels": [], "entities": []}, {"text": "Nevertheless, we believe that modeling a completely kernelized SRL system is useful for the following reasons: \u2022 We can implement it very quickly as the feature extractor module only requires the writing of the subtree extraction procedure.", "labels": [], "entities": [{"text": "SRL", "start_pos": 63, "end_pos": 66, "type": "TASK", "confidence": 0.8533169031143188}]}, {"text": "Traditional SRL systems are, in contrast, based on the extraction of more than thirty features (), which require the writing of at least thirty different procedures.", "labels": [], "entities": [{"text": "SRL", "start_pos": 12, "end_pos": 15, "type": "TASK", "confidence": 0.9722644090652466}]}, {"text": "\u2022 Combining it with a traditional attributevalue SRL system allows us to obtain a more accurate system.", "labels": [], "entities": []}, {"text": "Usually the combination of two traditional systems (based on the same machine learning model) does not result in an improvement as their features are more or less equivalent as shown in).", "labels": [], "entities": []}, {"text": "\u2022 The study of the effective structural features can inspire the design of novel linear features which can be used with a more efficient model (i.e. linear SVMs).", "labels": [], "entities": []}, {"text": "In this paper, we carryout tree kernel engineering ( ) to increase both accuracy and speed of the boundary detection and argument classification phases.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.999440610408783}, {"text": "boundary detection and argument classification", "start_pos": 98, "end_pos": 144, "type": "TASK", "confidence": 0.6770860016345978}]}, {"text": "The engineering approach relates to marking the nodes of the encoding subtrees in order to generate substructures more strictly correlated with a particular argument, boundary or predicate.", "labels": [], "entities": []}, {"text": "For example, marking the node that exactly covers the target argument helps tree kernels to generate different substructures for correct and incorrect argument boundaries.", "labels": [], "entities": []}, {"text": "The other technique that we applied to engineer different kernels is the subdivision of internal and pre-terminal nodes.", "labels": [], "entities": []}, {"text": "We show that designing different classifiers for these two different node types slightly increases the accuracy and remarkably decreases the learning and classification time.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 103, "end_pos": 111, "type": "METRIC", "confidence": 0.9996330738067627}]}, {"text": "An extensive experimentation of our tree kernels with Support Vector Machines on the CoNLL 2005 data set provides interesting insights on the design of performant SRL systems entirely based on tree kernels.", "labels": [], "entities": [{"text": "CoNLL 2005 data set", "start_pos": 85, "end_pos": 104, "type": "DATASET", "confidence": 0.9891745299100876}, {"text": "SRL", "start_pos": 163, "end_pos": 166, "type": "TASK", "confidence": 0.9162185192108154}]}, {"text": "In the remainder of this paper, Section 2 introduces basic notions on SRL systems and tree kernels.", "labels": [], "entities": [{"text": "SRL", "start_pos": 70, "end_pos": 73, "type": "TASK", "confidence": 0.9852892756462097}]}, {"text": "Section 3 illustrates our new kernels for both boundary and classification tasks.", "labels": [], "entities": []}, {"text": "Section 4 shows the experiments of SVMs with the above tree kernel based classifiers.", "labels": [], "entities": []}], "datasetContent": [{"text": "In these experiments we evaluate the impact of our proposed kernels in terms of accuracy and efficiency.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9994866847991943}]}, {"text": "The accuracy improvement confirms that the node marking approach enables the automatic engineering of effective SRL features.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9994912147521973}, {"text": "node marking", "start_pos": 43, "end_pos": 55, "type": "TASK", "confidence": 0.8525987863540649}, {"text": "SRL", "start_pos": 112, "end_pos": 115, "type": "TASK", "confidence": 0.9734408259391785}]}, {"text": "The efficiency improvement depends on (a) the less training data used when applying two distinct type classifiers for internal and pre-terminal nodes and (b) a more adequate feature space which allows SVMs to converge faster to a model containing a smaller number of support vectors, i.e. faster training and classification.", "labels": [], "entities": []}, {"text": "The empirical evaluations were carried out within the setting defined in the.", "labels": [], "entities": []}, {"text": "We used as a target dataset the PropBank corpus available at www.cis.upenn.edu/\u223cace, along with the Penn TreeBank 2 for the gold trees (www.cis.upenn.edu/\u223ctreebank) (, which includes about 53,700 sentences.", "labels": [], "entities": [{"text": "PropBank corpus", "start_pos": 32, "end_pos": 47, "type": "DATASET", "confidence": 0.9843704402446747}, {"text": "Penn TreeBank 2", "start_pos": 100, "end_pos": 115, "type": "DATASET", "confidence": 0.9771413207054138}]}, {"text": "Since the aim of this study was to design areal SRL system we adopted the Charniak parse trees from the CoNLL 2005 Shared Task data (available at www.lsi.upc.edu/\u223csrlconll/).", "labels": [], "entities": [{"text": "SRL", "start_pos": 48, "end_pos": 51, "type": "TASK", "confidence": 0.9576293230056763}, {"text": "CoNLL 2005 Shared Task data", "start_pos": 104, "end_pos": 131, "type": "DATASET", "confidence": 0.9278858661651611}]}, {"text": "We used Section 02, 03 and 24 from the Penn TreeBank inmost of the experiments.", "labels": [], "entities": [{"text": "Penn TreeBank", "start_pos": 39, "end_pos": 52, "type": "DATASET", "confidence": 0.9932924807071686}]}, {"text": "Their characteristics are shown in.", "labels": [], "entities": []}, {"text": "Pos and Neg indicate the number of nodes corresponding or not to a correct argument boundary.", "labels": [], "entities": []}, {"text": "Rows 3 and 4 report such number for the internal and pre-terminal nodes separately.", "labels": [], "entities": []}, {"text": "We note that the latter are much fewer than the former; this results in a very fast pre-terminal classifier.", "labels": [], "entities": []}, {"text": "As the automatic parse trees contain errors, some arguments cannot be associated with any covering node.", "labels": [], "entities": []}, {"text": "This prevents us to extract a tree representation for them.", "labels": [], "entities": []}, {"text": "Consequently, we do not consider them in our evaluation.", "labels": [], "entities": []}, {"text": "In sections 2, 3 and 24 there are 454, 347 and 731 such cases, respectively.", "labels": [], "entities": []}, {"text": "The experiments were carried outwith the SVM-light-TK software available at http://ai-nlp.info.uniroma2.it/moschitti/ which encodes fast tree kernel evaluation) in the SVM-light software.", "labels": [], "entities": []}, {"text": "We used a regularization parameter (option -c) equal to 1 and \u03bb = 0.4 (see).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Tree nodes of the sentences from sections 2, 3 and 24 of the PropBank. pos and neg are the  nodes that exactly cover arguments and all the other nodes, respectively.", "labels": [], "entities": [{"text": "PropBank", "start_pos": 71, "end_pos": 79, "type": "DATASET", "confidence": 0.9573742747306824}]}, {"text": " Table 3: Accuracy produced by different tree kernels on argument classification. We trained on sections  02 and 03 and tested on Section 24.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9775204062461853}, {"text": "argument classification", "start_pos": 57, "end_pos": 80, "type": "TASK", "confidence": 0.7408754527568817}]}]}