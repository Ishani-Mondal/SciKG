{"title": [{"text": "A Pragmatic Chinese Word Segmentation System", "labels": [], "entities": [{"text": "Pragmatic Chinese Word Segmentation", "start_pos": 2, "end_pos": 37, "type": "TASK", "confidence": 0.5539107546210289}]}], "abstractContent": [{"text": "This paper presents our work for participation in the Third International Chinese Word Segmentation Bakeoff.", "labels": [], "entities": [{"text": "Third International Chinese Word Segmentation Bakeoff", "start_pos": 54, "end_pos": 107, "type": "TASK", "confidence": 0.6305297166109085}]}, {"text": "We apply several processing approaches according to the corresponding sub-tasks, which are exhibited in real natural language.", "labels": [], "entities": []}, {"text": "In our system, Trigram model with smoothing algorithm is the core module in word segmentation, and Maximum Entropy model is the basic model in Named Entity Recognition task.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 76, "end_pos": 93, "type": "TASK", "confidence": 0.7971485257148743}, {"text": "Named Entity Recognition task", "start_pos": 143, "end_pos": 172, "type": "TASK", "confidence": 0.6996164917945862}]}, {"text": "The experiment indicates that this system achieves F-measure 96.8% in MSRA open test in the third SIGHAN-2006 bakeoff.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.9992213249206543}, {"text": "MSRA open test", "start_pos": 70, "end_pos": 84, "type": "DATASET", "confidence": 0.5533602138360342}, {"text": "SIGHAN-2006 bakeoff", "start_pos": 98, "end_pos": 117, "type": "DATASET", "confidence": 0.8370640277862549}]}], "introductionContent": [{"text": "Word is a logical semantic and syntactic unit in natural language.", "labels": [], "entities": []}, {"text": "Unlike English, there is no delimiter to mark word boundaries in Chinese language, so inmost Chinese NLP tasks, word segmentation is a foundation task, which transforms Chinese character string into word sequence.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 112, "end_pos": 129, "type": "TASK", "confidence": 0.732911229133606}]}, {"text": "It is prerequisite to POS tagger, parser or further applications, such as Information Extraction, Question Answer system.", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 22, "end_pos": 32, "type": "TASK", "confidence": 0.7071509957313538}, {"text": "Information Extraction", "start_pos": 74, "end_pos": 96, "type": "TASK", "confidence": 0.7112617939710617}, {"text": "Question Answer", "start_pos": 98, "end_pos": 113, "type": "TASK", "confidence": 0.6690976917743683}]}, {"text": "Our system participated in the Third International Chinese Word Segmentation Bakeoff, which held in 2006.", "labels": [], "entities": [{"text": "International Chinese Word Segmentation Bakeoff", "start_pos": 37, "end_pos": 84, "type": "TASK", "confidence": 0.6214853405952454}]}, {"text": "Compared with our system in the last bakeoff (Jiang 2005A), the system in the third bakeoff is adjusted intending to have a better pragmatic performance.", "labels": [], "entities": [{"text": "Jiang 2005A)", "start_pos": 46, "end_pos": 58, "type": "DATASET", "confidence": 0.8912544647852579}]}, {"text": "This paper mainly focuses on describing two sub-tasks: (1) The basic Word Segmentation; (2) Named entities recognition.", "labels": [], "entities": [{"text": "Word Segmentation", "start_pos": 69, "end_pos": 86, "type": "TASK", "confidence": 0.6906149238348007}, {"text": "Named entities recognition", "start_pos": 92, "end_pos": 118, "type": "TASK", "confidence": 0.6453580856323242}]}, {"text": "We apply different approaches to solve above two tasks, and all the modules are integrated into a pragmatic system (ELUS).", "labels": [], "entities": [{"text": "ELUS", "start_pos": 116, "end_pos": 120, "type": "METRIC", "confidence": 0.919772744178772}]}], "datasetContent": [{"text": "The performance of our system in the third bakeoff is presented in table 4 in terms of recall(R), precision(P) and F score in percentages.", "labels": [], "entities": [{"text": "recall(R)", "start_pos": 87, "end_pos": 96, "type": "METRIC", "confidence": 0.9679348170757294}, {"text": "precision(P)", "start_pos": 98, "end_pos": 110, "type": "METRIC", "confidence": 0.9669153094291687}, {"text": "F score", "start_pos": 115, "end_pos": 122, "type": "METRIC", "confidence": 0.9869469702243805}]}, {"text": "The score software is standard and open by SIGHAN.", "labels": [], "entities": [{"text": "SIGHAN", "start_pos": 43, "end_pos": 49, "type": "DATASET", "confidence": 0.8204151391983032}]}, {"text": "Our system has good performance in terms of R iv measure.", "labels": [], "entities": [{"text": "R iv measure", "start_pos": 44, "end_pos": 56, "type": "METRIC", "confidence": 0.8922258218129476}]}, {"text": "The R iv measure in close test and in open test are 99.1% and 98.9% respectively.", "labels": [], "entities": [{"text": "R iv measure", "start_pos": 4, "end_pos": 16, "type": "METRIC", "confidence": 0.9739309151967367}]}, {"text": "This good performance owes to class-based trigram with the absolute smoothing and word disambiguation algorithm.", "labels": [], "entities": [{"text": "word disambiguation", "start_pos": 82, "end_pos": 101, "type": "TASK", "confidence": 0.7421017587184906}]}, {"text": "In our system, it is the following reasons that the open test has a better performance than the close test: (1) Named Entity Recognition module is added into the open test system.", "labels": [], "entities": []}, {"text": "And Named Entities, including PER, LOC, ORG, occupy the most of the out-of-vocabulary words.", "labels": [], "entities": [{"text": "PER", "start_pos": 30, "end_pos": 33, "type": "METRIC", "confidence": 0.9866037368774414}, {"text": "LOC", "start_pos": 35, "end_pos": 38, "type": "METRIC", "confidence": 0.9162113070487976}, {"text": "ORG", "start_pos": 40, "end_pos": 43, "type": "METRIC", "confidence": 0.9850224852561951}]}, {"text": "(2) The system of close test can only use the dictionary that is collected from the given training corpus, while the system of open test can use a better dictionary, which includes the words that exist in MSRA training corpus in SIGHAN2005.", "labels": [], "entities": [{"text": "MSRA training corpus", "start_pos": 205, "end_pos": 225, "type": "DATASET", "confidence": 0.9241511821746826}, {"text": "SIGHAN2005", "start_pos": 229, "end_pos": 239, "type": "DATASET", "confidence": 0.5292428135871887}]}, {"text": "And we know, the dictionary is the one of important factors that affects the performance, because the LW candidates in the word lattice are generated from the dictionary.", "labels": [], "entities": []}, {"text": "As for the dictionary, we compare the two collections in SIGHAN2005 and SIGHAN2006, and evaluating in SIGHAN2005 MSRA close test.", "labels": [], "entities": [{"text": "SIGHAN2005", "start_pos": 57, "end_pos": 67, "type": "DATASET", "confidence": 0.9261540770530701}, {"text": "SIGHAN2006", "start_pos": 72, "end_pos": 82, "type": "DATASET", "confidence": 0.8980382680892944}, {"text": "SIGHAN2005 MSRA close test", "start_pos": 102, "end_pos": 128, "type": "DATASET", "confidence": 0.588669940829277}]}, {"text": "There are less training sentence in SIGHAN2006, as a result, there is at least 1.2% performance decrease.", "labels": [], "entities": [{"text": "training sentence", "start_pos": 15, "end_pos": 32, "type": "METRIC", "confidence": 0.9301523268222809}, {"text": "SIGHAN2006", "start_pos": 36, "end_pos": 46, "type": "DATASET", "confidence": 0.5680649876594543}]}, {"text": "So this result indicates that the dictionary can bring an important impact in our system.", "labels": [], "entities": []}, {"text": "gives our system performance in the second bakeoff.", "labels": [], "entities": []}, {"text": "We'll make brief comparison., we find that the OOV is 3.4 in third bakeoff, which is higher than the value in the last bakeoff.", "labels": [], "entities": [{"text": "OOV", "start_pos": 47, "end_pos": 50, "type": "METRIC", "confidence": 0.9990888833999634}]}, {"text": "Obviously, it is one of reasons that affect our performance.", "labels": [], "entities": []}, {"text": "In addition, based on pragmatic consideration, our system has been made some simplifier, for instance, we erase the new word detection algorithm and the is no morphological word detection.", "labels": [], "entities": [{"text": "word detection", "start_pos": 120, "end_pos": 134, "type": "TASK", "confidence": 0.7554141283035278}, {"text": "morphological word detection", "start_pos": 159, "end_pos": 187, "type": "TASK", "confidence": 0.6997426648934683}]}], "tableCaptions": [{"text": " Table 4 MSRA test in SIGHAN2006 (%)  MSRA  R  P  F  OOV R oov  R iv  Close  96.3 91.8 94.0  3.4  17.5 99.1  Open  97.7 96.0 96.8  3.4  62.4 98.9", "labels": [], "entities": [{"text": "MSRA", "start_pos": 9, "end_pos": 13, "type": "METRIC", "confidence": 0.57437664270401}, {"text": "SIGHAN2006", "start_pos": 22, "end_pos": 32, "type": "DATASET", "confidence": 0.7161396145820618}, {"text": "MSRA  R  P  F  OOV R oov  R iv  Close  96.3 91.8 94.0  3.4  17.5 99.1  Open  97.7 96.0 96.8  3.4  62.4 98.9", "start_pos": 38, "end_pos": 145, "type": "DATASET", "confidence": 0.7628269973008529}]}, {"text": " Table 5 MSRA test in SIGHAN 2005 (%)  MSRA  R  P  F  OOV R oov  R iv  Close  97.3 94.5 95.9  2.6  32.3 99.1  Open  98.0 96.5 97.2  2.6  59.0 99.0", "labels": [], "entities": [{"text": "MSRA", "start_pos": 9, "end_pos": 13, "type": "METRIC", "confidence": 0.5637633204460144}, {"text": "SIGHAN 2005", "start_pos": 22, "end_pos": 33, "type": "DATASET", "confidence": 0.8256860077381134}, {"text": "MSRA  R  P  F  OOV R oov  R iv  Close  97.3 94.5 95.9  2.6  32.3 99.1  Open  98.0 96.5 97.2  2.6  59.0 99.0", "start_pos": 39, "end_pos": 146, "type": "DATASET", "confidence": 0.7566717072673466}]}, {"text": " Table 6 The NER performance in MSRA Open test  MSRA NER  Precision Recall  F Score  PER  93.68%  86.37%  89.87  LOC  85.50%  59.67%  70.29  ORG  75.87%  47.48%  58.41  Overall  86.97%  65.56%  74.76", "labels": [], "entities": [{"text": "NER", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.9751185178756714}, {"text": "MSRA Open test  MSRA NER", "start_pos": 32, "end_pos": 56, "type": "DATASET", "confidence": 0.7476346850395202}, {"text": "Precision Recall  F Score", "start_pos": 58, "end_pos": 83, "type": "METRIC", "confidence": 0.7721869796514511}, {"text": "PER", "start_pos": 85, "end_pos": 88, "type": "METRIC", "confidence": 0.5629696249961853}, {"text": "LOC", "start_pos": 113, "end_pos": 116, "type": "METRIC", "confidence": 0.8664053678512573}, {"text": "ORG", "start_pos": 141, "end_pos": 144, "type": "METRIC", "confidence": 0.9254655838012695}]}, {"text": " Table 7 The NER test in Chinese Peoples' Daily  MSRA NER  Precision Recall  F Score  CPN  93.56  90.96  92.24  FPN  90.42  86.47  88.40  LOC  91.94  90.52  91.22  ORG  88.38  84.52  86.40  Overall  91.35  88.85  90.08", "labels": [], "entities": [{"text": "NER", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.9766069054603577}, {"text": "Chinese Peoples' Daily  MSRA NER", "start_pos": 25, "end_pos": 57, "type": "DATASET", "confidence": 0.8993630409240723}, {"text": "Precision Recall  F Score  CPN  93.56  90.96  92.24  FPN  90.42  86.47  88.40  LOC  91.94  90.52  91.22  ORG  88.38  84.52  86.40  Overall  91.35  88.85  90.08", "start_pos": 59, "end_pos": 218, "type": "METRIC", "confidence": 0.6371091542144617}]}]}