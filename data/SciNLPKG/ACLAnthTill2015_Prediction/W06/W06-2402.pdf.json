{"title": [{"text": "Grouping Multi-word Expressions According to Part-Of-Speech in Statistical Machine Translation", "labels": [], "entities": [{"text": "Grouping Multi-word Expressions", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7656201124191284}, {"text": "Statistical Machine Translation", "start_pos": 63, "end_pos": 94, "type": "TASK", "confidence": 0.7003339529037476}]}], "abstractContent": [{"text": "This paper studies a strategy for identifying and using multi-word expressions in Statistical Machine Translation.", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 82, "end_pos": 113, "type": "TASK", "confidence": 0.8393471638361613}]}, {"text": "The performance of the proposed strategy for various types of multi-word expressions (like nouns or verbs) is evaluated in terms of alignment quality as well as translation accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 173, "end_pos": 181, "type": "METRIC", "confidence": 0.9397913813591003}]}, {"text": "Evaluations are performed by using real-life data, namely the European Parliament corpus.", "labels": [], "entities": [{"text": "European Parliament corpus", "start_pos": 62, "end_pos": 88, "type": "DATASET", "confidence": 0.9396180113156637}]}, {"text": "Results from translation tasks from English-to-Spanish and from Spanish-to-English are presented and discussed.", "labels": [], "entities": []}], "introductionContent": [{"text": "Statistical machine translation (SMT) was originally focused on word to word translation and was based on the noisy channel approach.", "labels": [], "entities": [{"text": "Statistical machine translation (SMT)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8464356561501821}, {"text": "word to word translation", "start_pos": 64, "end_pos": 88, "type": "TASK", "confidence": 0.6793340742588043}]}, {"text": "Present SMT systems have evolved from the original ones in such away that mainly differ from them in two issues: first, word-based translation models have been replaced by phrasebased translation models () and (; and second, the noisy channel approach has been expanded to a more general maximum entropy approach in which a log-linear combination of multiple feature functions is implemented ( ).", "labels": [], "entities": [{"text": "SMT", "start_pos": 8, "end_pos": 11, "type": "TASK", "confidence": 0.9902786612510681}]}, {"text": "Nevertheless, it is interesting to call the attention about one important fact.", "labels": [], "entities": []}, {"text": "Despite the change from a word-based to a phrase-based translation approach, word to word approaches for inferring alignment models from bilingual data ( continue to be widely used.", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 42, "end_pos": 66, "type": "TASK", "confidence": 0.712813526391983}]}, {"text": "On the other hand, from observing bilingual data sets, it becomes evident that in some cases it is just impossible to perform a word to word alignment between two phrases that are translations of each other.", "labels": [], "entities": [{"text": "word to word alignment", "start_pos": 128, "end_pos": 150, "type": "TASK", "confidence": 0.6993764042854309}]}, {"text": "For example, certain combination of words might convey a meaning which is somehow independent from the words it contains.", "labels": [], "entities": []}, {"text": "This is the case of bilingual pairs such as \"fire engine\" and \"cami\u00f3n de bomberos\".", "labels": [], "entities": []}, {"text": "Notice that a word-to-word alignment strategy would most probably 1 provide the following Viterbi alignments for words contained in the previous example: \"cami\u00f3n:truck\", \"bomberos:firefighters\", \"fuego:fire\", and \"m\u00e1quina:engine\".", "labels": [], "entities": []}, {"text": "Of course, it cannot be concluded from these examples that a SMT system which uses a word to word alignment strategy will not be able to handle properly the kind of word expression described above.", "labels": [], "entities": [{"text": "SMT", "start_pos": 61, "end_pos": 64, "type": "TASK", "confidence": 0.9928145408630371}, {"text": "word to word alignment", "start_pos": 85, "end_pos": 107, "type": "TASK", "confidence": 0.655552826821804}]}, {"text": "This is because there are other models and feature functions involved which can actually help the SMT system to get the right translation.", "labels": [], "entities": [{"text": "SMT", "start_pos": 98, "end_pos": 101, "type": "TASK", "confidence": 0.9901909828186035}]}, {"text": "However these ideas motivate for exploring alternatives for using multi-word expression information in order to improve alignment quality and consequently translation accuracy.", "labels": [], "entities": [{"text": "translation", "start_pos": 155, "end_pos": 166, "type": "TASK", "confidence": 0.9557373523712158}, {"text": "accuracy", "start_pos": 167, "end_pos": 175, "type": "METRIC", "confidence": 0.7454398274421692}]}, {"text": "In this sense, our idea of a multi-word expression (hereafter MWE) refers in principle to word sequences which cannot be translated literally word-to-word.", "labels": [], "entities": []}, {"text": "However, the automatic technique studied in this work for extracting and identifying MWEs does not necessarily follow this definition rigorously.", "labels": [], "entities": [{"text": "extracting and identifying MWEs", "start_pos": 58, "end_pos": 89, "type": "TASK", "confidence": 0.871950313448906}]}, {"text": "Ina preliminary study ), we presented a technique for extracting bilingual multi-word expressions (BMWE) from parallel corpora.", "labels": [], "entities": [{"text": "extracting bilingual multi-word expressions (BMWE) from parallel corpora", "start_pos": 54, "end_pos": 126, "type": "TASK", "confidence": 0.8017353951931}]}, {"text": "In that study, BMWEs identified in a small corpus 2 were grouped as a unique to-ken before training alignment models.", "labels": [], "entities": []}, {"text": "As a result, both alignment quality and translation accuracy were slightly improved.", "labels": [], "entities": [{"text": "alignment", "start_pos": 18, "end_pos": 27, "type": "TASK", "confidence": 0.9219550490379333}, {"text": "translation", "start_pos": 40, "end_pos": 51, "type": "TASK", "confidence": 0.9227109551429749}, {"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.972423791885376}]}, {"text": "In this paper we applied the same BMWE extraction technique, with various improvements, to a large corpus (EPPS, described in section 4.1).", "labels": [], "entities": [{"text": "BMWE extraction", "start_pos": 34, "end_pos": 49, "type": "TASK", "confidence": 0.7002585977315903}, {"text": "EPPS", "start_pos": 107, "end_pos": 111, "type": "DATASET", "confidence": 0.7725186944007874}]}, {"text": "Since this is a statistical technique, and frequencies of multi-word expressions are low (), the size of the corpus is an important factor.", "labels": [], "entities": []}, {"text": "A few very basic rules based on part-of-speech have also been added to filter out noisy entries in the dictionary.", "labels": [], "entities": []}, {"text": "Finally, BMWEs have been classified into three categories (nouns, verbs and others).", "labels": [], "entities": []}, {"text": "In addition to the impact of the whole set, the impact of each category has been evaluated separately.", "labels": [], "entities": []}, {"text": "The technique will be explained in section 3, after presenting the baseline translation system used (section 2).", "labels": [], "entities": []}, {"text": "Experimental results are presented in section 4.", "labels": [], "entities": []}, {"text": "Finally some conclusions are presented and further work in this area is depicted.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we describe the technique used to seethe effect of multi-words information on the translation model described in section 2.", "labels": [], "entities": []}, {"text": "Details about alignment evaluation can be found in.", "labels": [], "entities": [{"text": "alignment evaluation", "start_pos": 14, "end_pos": 34, "type": "TASK", "confidence": 0.9854701161384583}]}, {"text": "The alignment test data contain unambiguous links (called S or Sure) and ambiguous links (called P or Possible).", "labels": [], "entities": []}, {"text": "If there is a P link between two words in the reference, a computed link (i.e. to be evaluated) between these words is acceptable, but not compulsory.", "labels": [], "entities": []}, {"text": "On the contrary, if there would bean S link between these words in the reference, a computed link would be compulsory.", "labels": [], "entities": []}, {"text": "In this paper, precision refers to the proportion of computed links that are present in the reference.", "labels": [], "entities": [{"text": "precision", "start_pos": 15, "end_pos": 24, "type": "METRIC", "confidence": 0.999358594417572}]}, {"text": "Recall refers to the proportion of reference Sure links that were computed.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9329976439476013}]}, {"text": "The alignment error rate (AER) is given by the following formula: where A is the set of computed links, G S is the set of Sure reference links and G is the entire set of reference links.", "labels": [], "entities": [{"text": "alignment error rate (AER)", "start_pos": 4, "end_pos": 30, "type": "METRIC", "confidence": 0.888624240954717}]}, {"text": "As for translation evaluation, we used the following measures: WER (word error rate) or mWER (multireference word error rate) The WER is the minimum number of substitution, insertion and deletion operations that must be performed to convert the generated sentence into the reference target sentence.", "labels": [], "entities": [{"text": "translation evaluation", "start_pos": 7, "end_pos": 29, "type": "TASK", "confidence": 0.969018280506134}, {"text": "WER", "start_pos": 63, "end_pos": 66, "type": "METRIC", "confidence": 0.947953999042511}, {"text": "word error rate", "start_pos": 68, "end_pos": 83, "type": "METRIC", "confidence": 0.6857099235057831}, {"text": "multireference word error rate)", "start_pos": 94, "end_pos": 125, "type": "METRIC", "confidence": 0.697631174325943}, {"text": "WER", "start_pos": 130, "end_pos": 133, "type": "METRIC", "confidence": 0.8811724185943604}]}, {"text": "For the mWER, a whole set of reference translations is used.", "labels": [], "entities": []}, {"text": "In this case, for each translation hypothesis, the edit distance to the most similar sentence is calculated.", "labels": [], "entities": []}, {"text": "BLEU score This score measures the precision of unigrams, bigrams, trigrams, and fourgrams with respect to a whole set of reference translations, and with a penalty for too short sentences ().", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.966170459985733}, {"text": "precision", "start_pos": 35, "end_pos": 44, "type": "METRIC", "confidence": 0.998814582824707}]}, {"text": "BLEU measures accuracy, thus larger scores are better.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9914690256118774}, {"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9996337890625}]}], "tableCaptions": [{"text": " Table 1: Basic statistics for the considered training  (a) translation test (b) and alignment test (c) data  sets (M and k stands for millions and thousands,  respectively).", "labels": [], "entities": []}, {"text": " Table 2: Quality of the BMWEs identified from  the various dictionaries.", "labels": [], "entities": [{"text": "BMWEs", "start_pos": 25, "end_pos": 30, "type": "DATASET", "confidence": 0.9209192991256714}]}, {"text": " Table 4: Single word lexical probabilities of the  alignment model in the baseline and after group- ing MWE with all dictionary entries. The multi- word tokens \"in other words\" and \"es decir\" do  not exist in the baseline.", "labels": [], "entities": []}, {"text": " Table 6: Translation results in Spanish-to-English  (S\u2192E) and English-to-Spanish (E\u2192S) directions.", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9790253043174744}]}, {"text": " Table 7: Effect on quality of differences in the  translations between the baseline and the BMWE  experiment with \"ALL\" dictionary. S and E stand  for Spanish and English, respectively.", "labels": [], "entities": [{"text": "BMWE  experiment", "start_pos": 93, "end_pos": 109, "type": "DATASET", "confidence": 0.9476761519908905}]}]}