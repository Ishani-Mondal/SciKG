{"title": [{"text": "Quality Assessment of Large Scale Knowledge Resources", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents an empirical evaluation of the quality of publicly available large-scale knowledge resources.", "labels": [], "entities": []}, {"text": "The study includes a wide range of manually and automatically derived large-scale knowledge resources.", "labels": [], "entities": []}, {"text": "In order to establish a fair and neutral comparison, the quality of each knowledge resource is indirectly evaluated using the same method on a Word Sense Disambiguation task.", "labels": [], "entities": [{"text": "Word Sense Disambiguation task", "start_pos": 143, "end_pos": 173, "type": "TASK", "confidence": 0.7480152547359467}]}, {"text": "The evaluation framework selected has been the Senseval-3 English Lexical Sample Task.", "labels": [], "entities": [{"text": "Senseval-3 English Lexical Sample", "start_pos": 47, "end_pos": 80, "type": "TASK", "confidence": 0.5599232539534569}]}, {"text": "The study empirically demonstrates that automatically acquired knowledge resources surpass both in terms of precision and recall the knowledge resources derived manually, and that the combination of the knowledge contained in these resources is very close to the most frequent sense classifier.", "labels": [], "entities": [{"text": "precision", "start_pos": 108, "end_pos": 117, "type": "METRIC", "confidence": 0.9989763498306274}, {"text": "recall", "start_pos": 122, "end_pos": 128, "type": "METRIC", "confidence": 0.9926291704177856}]}, {"text": "As far as we know, this is the first time that such a quality assessment has been performed showing a clear picture of the current state-of-the-art of publicly available wide coverage semantic resources .", "labels": [], "entities": []}], "introductionContent": [{"text": "Using large-scale semantic knowledge bases, such as WordNet, has become a usual, often necessary, practice for most current Natural Language Processing systems.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 52, "end_pos": 59, "type": "DATASET", "confidence": 0.9215103387832642}]}, {"text": "Even now, building large and rich enough knowledge bases for broad-coverage semantic processing takes a great deal of expensive manual effort involving large research groups during long periods of development.", "labels": [], "entities": [{"text": "broad-coverage semantic processing", "start_pos": 61, "end_pos": 95, "type": "TASK", "confidence": 0.7164730628331503}]}, {"text": "This fact has severely hampered the state-of-the-art of current Natural Language Processing (NLP) applications.", "labels": [], "entities": []}, {"text": "For example, dozens of person-years have been invested in the development of wordnets for various languages, but the data in these resources seems not to be rich enough to support advanced concept-based NLP applications directly.", "labels": [], "entities": []}, {"text": "It seems that applications will not scale up to working in open domains without more detailed and rich general-purpose (and also domain-specific) linguistic knowledge built by automatic means.", "labels": [], "entities": []}, {"text": "For instance, in more than eight years of manual construction (from version 1.5 to 2.0), WordNet passed from 103,445 semantic relations to 204,074 semantic relations . That is, around twelve thousand semantic relations per year.", "labels": [], "entities": []}, {"text": "However, during the last years the research community has devised a large set of innovative processes and tools for large-scale automatic acquisition of lexical knowledge from structured or unstructured corpora.", "labels": [], "entities": [{"text": "large-scale automatic acquisition of lexical knowledge from structured or unstructured corpora", "start_pos": 116, "end_pos": 210, "type": "TASK", "confidence": 0.779518642208793}]}, {"text": "Among others we can mention eXtended WordNet), large collections of semantic preferences acquired from SemCor () or acquired from British National Corpus (BNC)), largescale Topic Signatures for each synset acquired from the web (Agirre and de la) or acquired from the BNC ().", "labels": [], "entities": [{"text": "British National Corpus (BNC))", "start_pos": 130, "end_pos": 160, "type": "DATASET", "confidence": 0.9711053272088369}, {"text": "BNC", "start_pos": 268, "end_pos": 271, "type": "DATASET", "confidence": 0.9655971527099609}]}, {"text": "Obviously, all these semantic resources have been acquired using a very different set of methods, tools and corpora, resulting on a different set of new semantic relations between synsets.", "labels": [], "entities": []}, {"text": "In fact, each resource has different volume and accuracy figures.", "labels": [], "entities": [{"text": "volume", "start_pos": 37, "end_pos": 43, "type": "METRIC", "confidence": 0.9534893035888672}, {"text": "accuracy", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9908688068389893}]}, {"text": "Although isolated evaluations have been performed by their developers in different experi-mental settings, to date no comparable evaluation has been carried out in a common and controlled framework.", "labels": [], "entities": []}, {"text": "This work tries to establish the relative quality of these semantic resources in a neutral environment.", "labels": [], "entities": []}, {"text": "The quality of each large-scale knowledge resource is indirectly evaluated on a Word Sense Disambiguation (WSD) task.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD) task", "start_pos": 80, "end_pos": 116, "type": "TASK", "confidence": 0.7581075515065875}]}, {"text": "In particular, we use a well defined WSD evaluation benchmark (Senseval-3 English Lexical Sample task) to evaluate the quality of each resource.", "labels": [], "entities": [{"text": "WSD evaluation", "start_pos": 37, "end_pos": 51, "type": "TASK", "confidence": 0.7980760335922241}]}, {"text": "Furthermore, this work studies how these resources complement each other.", "labels": [], "entities": []}, {"text": "That is, to which extent each knowledge base provides new knowledge not provided by the others.", "labels": [], "entities": []}, {"text": "This paper is organized as follows: after this introduction, section 2 describes the large-scale knowledge resources studied in this work.", "labels": [], "entities": []}, {"text": "Section 3 describes the evaluation framework.", "labels": [], "entities": []}, {"text": "Section 4 presents the evaluation results of the different semantic resources considered.", "labels": [], "entities": []}, {"text": "Section 5 provides a qualitative assessment of this empirical study and finally, the conclusions and future work are presented in section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to measure the quality of the knowledge resources described in the previous section, we performed an indirect evaluation by using all these resources as Topic Signatures (TS).", "labels": [], "entities": []}, {"text": "That is, word vectors with weights associated to a particular synset which are obtained by collecting those word senses appearing in the synsets directly related to them . This simple representation tries to be as neutral as possible with respect to the evaluation framework.", "labels": [], "entities": []}, {"text": "All knowledge resources are indirectly evaluated on a WSD task.", "labels": [], "entities": [{"text": "WSD task", "start_pos": 54, "end_pos": 62, "type": "TASK", "confidence": 0.8830671310424805}]}, {"text": "In particular, the noun-set Although other measures have been tested, such as Mutual Information or Association Ratio, the best results have been obtained using TFIDF formula.", "labels": [], "entities": [{"text": "TFIDF", "start_pos": 161, "end_pos": 166, "type": "METRIC", "confidence": 0.8824328780174255}]}, {"text": "A weight of 1 is given when the resource do not has associated weight. of Senseval-3 English Lexical Sample task which consists of 20 nouns.", "labels": [], "entities": []}, {"text": "All performances are evaluated on the test data using the fine-grained scoring system provided by the organizers.", "labels": [], "entities": []}, {"text": "Furthermore, trying to be as neutral as possible with respect to the semantic resources studied, we applied systematically the same disambiguation method to all of them.", "labels": [], "entities": []}, {"text": "Recall that our main goal is to establish a fair comparison of the knowledge resources rather than providing the best disambiguation technique fora particular semantic knowledge base.", "labels": [], "entities": []}, {"text": "A common WSD method has been applied to all knowledge resources.", "labels": [], "entities": [{"text": "WSD", "start_pos": 9, "end_pos": 12, "type": "TASK", "confidence": 0.9531225562095642}]}, {"text": "A simple word overlapping counting (or weighting) is performed between the Topic Signature and the test example 7 . Thus, the occurrence evaluation measure counts the amount of overlapped words and the weight evaluation measure adds up the weights of the overlapped words.", "labels": [], "entities": [{"text": "word overlapping counting", "start_pos": 9, "end_pos": 34, "type": "TASK", "confidence": 0.7309985458850861}]}, {"text": "The synset having higher overlapping word counts (or weights) is selected fora particular test example.", "labels": [], "entities": []}, {"text": "However, for TSWEB and TSBNC the better results have been obtained using occurrences (the weights are only used to order the words of the vector).", "labels": [], "entities": [{"text": "TSWEB", "start_pos": 13, "end_pos": 18, "type": "DATASET", "confidence": 0.7933374047279358}, {"text": "TSBNC", "start_pos": 23, "end_pos": 28, "type": "DATASET", "confidence": 0.8489234447479248}]}, {"text": "Finally, we should remark that the results are not skewed (for instance, for resolving ties) by the most frequent sense in WN or any other statistically predicted knowledge.", "labels": [], "entities": []}, {"text": "presents an example of Topic Signature from TSWEB using queryW and the web and from TSBNC using queryA and the BNC for the first sense of the noun party.", "labels": [], "entities": [{"text": "TSWEB", "start_pos": 44, "end_pos": 49, "type": "DATASET", "confidence": 0.9291287064552307}, {"text": "TSBNC", "start_pos": 84, "end_pos": 89, "type": "DATASET", "confidence": 0.9161260724067688}, {"text": "BNC", "start_pos": 111, "end_pos": 114, "type": "METRIC", "confidence": 0.9049238562583923}]}, {"text": "Although both automatically acquired TS seem to be closely related to the first sense of the noun party, they do not have words in common.", "labels": [], "entities": []}, {"text": "As an example, table 4 shows a test example of Senseval-3 corresponding to the first sense of the noun party.", "labels": [], "entities": []}, {"text": "In bold there are the words that appear in TSBNC-queryA.", "labels": [], "entities": [{"text": "TSBNC-queryA", "start_pos": 43, "end_pos": 55, "type": "DATASET", "confidence": 0.887261152267456}]}, {"text": "There are several important words that appear in the text that also appear in the TS.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Main sources of semantic relations", "labels": [], "entities": []}, {"text": " Table 2: Overlapping relations in the MCR", "labels": [], "entities": [{"text": "MCR", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.509719967842102}]}, {"text": " Table 3: Topic Signatures for party#n#1 using TSWEB (24 out of 15881 total words) and TS- BNC(queryA) with TFIDF (24 out of 9069 total words)", "labels": [], "entities": [{"text": "TSWEB", "start_pos": 47, "end_pos": 52, "type": "METRIC", "confidence": 0.6935068368911743}, {"text": "TS- BNC", "start_pos": 87, "end_pos": 94, "type": "METRIC", "confidence": 0.78849858045578}]}, {"text": " Table 4: Example of test num. 00008131 for party#n which its correct sense is 1", "labels": [], "entities": []}, {"text": " Table 6: P, R and F1 fine-grained results for the  resources integrated into the MCR.", "labels": [], "entities": [{"text": "F1", "start_pos": 19, "end_pos": 21, "type": "METRIC", "confidence": 0.9937885403633118}, {"text": "fine-grained", "start_pos": 22, "end_pos": 34, "type": "METRIC", "confidence": 0.6128950119018555}]}, {"text": " Table 7: Senseval-3 Unsupervised Systems", "labels": [], "entities": []}, {"text": " Table 8: Senseval-3 Supervised Systems", "labels": [], "entities": []}]}