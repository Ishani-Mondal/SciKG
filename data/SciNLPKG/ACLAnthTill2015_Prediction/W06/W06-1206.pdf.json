{"title": [{"text": "Automated Multiword Expression Prediction for Grammar Engineering", "labels": [], "entities": [{"text": "Multiword Expression Prediction", "start_pos": 10, "end_pos": 41, "type": "TASK", "confidence": 0.6734687884648641}]}], "abstractContent": [{"text": "However large a hand-crafted wide-coverage grammar is, there are always going to be words and constructions that are not included in it and are going to cause parse failure.", "labels": [], "entities": []}, {"text": "Due to their heterogeneous and flexible nature, Multiword Expressions (MWEs) provide an endless source of parse failures.", "labels": [], "entities": []}, {"text": "As the number of such expressions in a speaker's lexicon is equiparable to the number of single word units (Jackendoff, 1997), one major challenge for robust natural language processing systems is to be able to deal with MWEs.", "labels": [], "entities": []}, {"text": "In this paper we propose to semi-automatically detect MWE candidates in texts using some error mining techniques and validating them using a combination of the World Wide Web as a corpus and some statistical measures.", "labels": [], "entities": [{"text": "MWE candidates in texts", "start_pos": 54, "end_pos": 77, "type": "TASK", "confidence": 0.8698649704456329}]}, {"text": "For the remaining candidates possible lexico-syntactic types are predicted, and they are subsequently added to the grammar as new lexical entries.", "labels": [], "entities": []}, {"text": "This approach provides a significant increase in the coverage of these expressions.", "labels": [], "entities": []}], "introductionContent": [{"text": "Hand-crafted large-scale grammars like the English Resource Grammar), the Pargram grammars () and the Dutch Alpino Grammar () are extremely valuable resources that have been used in many NLP applications.", "labels": [], "entities": [{"text": "English Resource Grammar", "start_pos": 43, "end_pos": 67, "type": "DATASET", "confidence": 0.8760254184405009}, {"text": "Pargram grammars", "start_pos": 74, "end_pos": 90, "type": "DATASET", "confidence": 0.8790948688983917}, {"text": "Dutch Alpino Grammar", "start_pos": 102, "end_pos": 122, "type": "DATASET", "confidence": 0.855545441309611}]}, {"text": "However, due to the open-ended and dynamic nature of languages, and the difficulties of grammar engineering, such grammars are likely to contain errors and be incomplete.", "labels": [], "entities": []}, {"text": "An error can be roughly classified as under-generating (if it prevents a grammatical sentence to be generated/parsed) or overgenerating (if it allows an ungrammatical sentence to be generated/parsed).", "labels": [], "entities": []}, {"text": "In the context of wide-coverage parsing, we focus on the undergenerating errors which normally lead to parsing failure.", "labels": [], "entities": [{"text": "wide-coverage parsing", "start_pos": 18, "end_pos": 39, "type": "TASK", "confidence": 0.6618308424949646}, {"text": "parsing", "start_pos": 103, "end_pos": 110, "type": "TASK", "confidence": 0.9727521538734436}]}, {"text": "Traditionally, the errors of the grammar are to be detected manually by the grammar developers.", "labels": [], "entities": []}, {"text": "This is usually done by running the grammar over a carefully designed test suite and inspecting the outputs.", "labels": [], "entities": []}, {"text": "This procedure becomes less reliable as the grammar gets larger, and is especially difficult when the grammar is developed in a distributed manner., among many others, for instance, have investigated the main causes of parse failure, parsing a random sample of 20,000 strings from the written component of the British National Corpus (henceforward BNC) using the English Resource Grammar), a broad-coverage precision HPSG grammar for English.", "labels": [], "entities": [{"text": "parse", "start_pos": 219, "end_pos": 224, "type": "TASK", "confidence": 0.9798464179039001}, {"text": "British National Corpus (henceforward BNC", "start_pos": 310, "end_pos": 351, "type": "DATASET", "confidence": 0.9293688734372457}, {"text": "English Resource Grammar", "start_pos": 363, "end_pos": 387, "type": "DATASET", "confidence": 0.777276337146759}]}, {"text": "They have found that the large majority of failures are caused by missing lexical entries, with 40% of the cases, and missing constructions, with 39%.", "labels": [], "entities": []}, {"text": "To this effect, as mentioned above, in recent years, some approaches have been developed in order to (semi)automatically detect and/or repair the errors in linguistic grammars.", "labels": [], "entities": []}, {"text": "van, for instance, takes a statistical approach towards semi-automated error detection using the parsability metric for word sequences.", "labels": [], "entities": [{"text": "semi-automated error detection", "start_pos": 56, "end_pos": 86, "type": "TASK", "confidence": 0.6795227328936259}]}, {"text": "He reports on a simple yet practical way of identifying grammar errors.", "labels": [], "entities": [{"text": "identifying grammar errors", "start_pos": 44, "end_pos": 70, "type": "TASK", "confidence": 0.8584801157315572}]}, {"text": "The method is particularly useful for discovering systematic problems in a large grammar with reasonable coverage.", "labels": [], "entities": []}, {"text": "The idea behind it is that each (under-generating) error in the gram-mar leads to the parsing failure of some specific grammatical sentences.", "labels": [], "entities": []}, {"text": "By running the grammar over a large corpus, the corpus can be split into two subsets: the set of sentences covered by the grammar and the set of sentences that failed to parse.", "labels": [], "entities": []}, {"text": "The errors can be identified by comparing the statistical difference between these two sets of sentences.", "labels": [], "entities": []}, {"text": "By statistical difference, any kind of uneven distribution of linguistic phenomena is meant.", "labels": [], "entities": []}, {"text": "In the case of van, the word sequences are used, mainly because the cost to compute and count the word sequences is minimum.", "labels": [], "entities": []}, {"text": "The parsability of a sequence w i . .", "labels": [], "entities": []}, {"text": "w j is defined as: where C(w i . .", "labels": [], "entities": []}, {"text": "w j ) is the number of sentences in which the sequence w i . .", "labels": [], "entities": []}, {"text": "w j occurs, and C(w i . .", "labels": [], "entities": []}, {"text": "w j , OK) is the number of sentences with a successful parse which contain the sequence.", "labels": [], "entities": []}, {"text": "A frequency cut is used to eliminate the infrequent sequences.", "labels": [], "entities": []}, {"text": "With suffix arrays and perfect hashing automata, the parsability of all word sequences (with arbitrary length) can be computed efficiently.", "labels": [], "entities": []}, {"text": "The word sequences are then sorted according to their parsabilities.", "labels": [], "entities": []}, {"text": "Those sequences with the lowest parsabilities are taken as direct indication of grammar errors.", "labels": [], "entities": [{"text": "parsabilities", "start_pos": 32, "end_pos": 45, "type": "METRIC", "confidence": 0.9594202041625977}]}, {"text": "Among them, one common error, and subsequently very common cause of parse failure is due to Multiword Expressions (MWEs), like phrasal verbs (break down), collocations (bread and butter), compound nouns (coffee machine), determiner-less PPs (in hospital), as well as socalled \"frozen expressions\" (by and large), as discussed by both.", "labels": [], "entities": []}, {"text": "Indicatively, in the experiments reported in, for instance, from all the errors due to missing lexical entries, one fifth were due to missing MWEs (8% of total errors).", "labels": [], "entities": []}, {"text": "If an MWE is syntactically marked, the standard grammatical rules and lexical entries cannot generate the string, as for instance in the case of a phrasal verb like takeoff, even if the individual words that makeup the MWE are contained in the lexicon.", "labels": [], "entities": []}, {"text": "In this paper we investigate semi-automatic methods for error mining and detection of missing lexical entries, following van, with the subsequent handling of the MWEs among them.", "labels": [], "entities": [{"text": "error mining", "start_pos": 56, "end_pos": 68, "type": "TASK", "confidence": 0.7211441546678543}]}, {"text": "The output of the error mining phase proposes a set of n-grams, which also contain MWEs.", "labels": [], "entities": [{"text": "error mining", "start_pos": 18, "end_pos": 30, "type": "TASK", "confidence": 0.7581593692302704}]}, {"text": "Therefore, the task is to distinguish the MWEs from the other cases.", "labels": [], "entities": []}, {"text": "To do this, first we propose to use the World Wide Web as a very large corpus from which we collect evidence that enables us to rule out noisy cases (due to spelling errors, for instance), following Grefenstette (1999),, and.", "labels": [], "entities": []}, {"text": "The candidates that are kept can be semi-automatically included in the grammar, by employing a lexical type predictor, whose output we use in order to add lexical entries to the lexicon, with a possible manual check by a grammar writer.", "labels": [], "entities": []}, {"text": "This procedure significantly speeds up the process of grammar development, relieving the grammar developer of some of the burden by automatically detecting parse failures and providing semi-automatic means for handling them.", "labels": [], "entities": [{"text": "grammar development", "start_pos": 54, "end_pos": 73, "type": "TASK", "confidence": 0.8385932743549347}]}, {"text": "The paper starts with a discussion of MWEs and of some of the characteristics that make them so challenging for NLP, in section 2.", "labels": [], "entities": [{"text": "MWEs", "start_pos": 38, "end_pos": 42, "type": "TASK", "confidence": 0.9527008533477783}]}, {"text": "This is followed by a more detailed discussion of the technique employed for error detection, in section 3.", "labels": [], "entities": [{"text": "error detection", "start_pos": 77, "end_pos": 92, "type": "TASK", "confidence": 0.6727079004049301}]}, {"text": "The approach used for distinguishing noisy sequences from MWE-related constructions using the World Wide Web is then presented.", "labels": [], "entities": [{"text": "distinguishing noisy sequences from MWE-related constructions", "start_pos": 22, "end_pos": 83, "type": "TASK", "confidence": 0.6894834339618683}]}, {"text": "How this information is used for extending the grammar and the results obtained are then addressed in section 5.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Distribution of Parsing Results", "labels": [], "entities": [{"text": "Distribution of Parsing", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.8902800877888998}]}, {"text": " Table 2: Distribution of N-gram in Length in Error  Mining Results (R(x) < 0.1)", "labels": [], "entities": [{"text": "Length", "start_pos": 36, "end_pos": 42, "type": "METRIC", "confidence": 0.9866985082626343}, {"text": "R", "start_pos": 69, "end_pos": 70, "type": "METRIC", "confidence": 0.938247561454773}]}, {"text": " Table 4: Top 10 Candidate Multiword Expressions", "labels": [], "entities": [{"text": "Candidate Multiword Expressions", "start_pos": 17, "end_pos": 48, "type": "TASK", "confidence": 0.5574312508106232}]}, {"text": " Table 5: Bottom 10 Candidate Multiword Expressions", "labels": [], "entities": [{"text": "Candidate Multiword Expressions", "start_pos": 20, "end_pos": 51, "type": "TASK", "confidence": 0.542726049820582}]}]}