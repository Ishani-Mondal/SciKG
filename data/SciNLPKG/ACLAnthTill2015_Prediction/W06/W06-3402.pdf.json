{"title": [{"text": "Off-Topic Detection in Conversational Telephone Speech", "labels": [], "entities": [{"text": "Conversational Telephone Speech", "start_pos": 23, "end_pos": 54, "type": "TASK", "confidence": 0.762292484442393}]}], "abstractContent": [{"text": "Ina context where information retrieval is extended to spoken \"documents\" including conversations, it will be important to provide users with the ability to seek in-formational content, rather than socially motivated small talk that appears in many conversational sources.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 18, "end_pos": 39, "type": "TASK", "confidence": 0.7328864932060242}]}, {"text": "In this paper we present a preliminary study aimed at automatically identifying \"irrelevance\" in the domain of telephone conversations.", "labels": [], "entities": []}, {"text": "We apply a standard machine learning algorithm to build a classifier that detects off-topic sections with better-than-chance accuracy and that begins to provide insight into the relative importance of features for identifying utterances as on topic or not.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 125, "end_pos": 133, "type": "METRIC", "confidence": 0.9949179887771606}]}], "introductionContent": [{"text": "There is a growing need to index, search, summarize and otherwise process the increasing amount of available broadcast news, broadcast conversations, meetings, class lectures, and telephone conversations.", "labels": [], "entities": [{"text": "summarize", "start_pos": 42, "end_pos": 51, "type": "TASK", "confidence": 0.905879557132721}]}, {"text": "While it is clear that users have wide ranging goals in the context of information retrieval, we assume that some will seek only credible information about a specific topic and will not be interested in the socially-motivated utterances which appear throughout most conversational sources.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 71, "end_pos": 92, "type": "TASK", "confidence": 0.7295436263084412}]}, {"text": "For these users, a search for information about weather should not return conversations containing small talk such as \"Nice weather we've been having.\"", "labels": [], "entities": []}, {"text": "In this paper we investigate one approach for automatically identifying \"irrelevance\" in the domain of telephone conversations.", "labels": [], "entities": []}, {"text": "Our initial data consist of conversations in which each utterance is labeled as being on topic or not.", "labels": [], "entities": []}, {"text": "We apply inductive classifier learning algorithms to identify useful features and build classifiers to automatically label utterances.", "labels": [], "entities": []}, {"text": "We begin in Section 2 by hypothesizing features that might be useful for the identification of irrelevant regions, as indicated by research on the linguistics of conversational speech and, in particular, small talk.", "labels": [], "entities": [{"text": "identification of irrelevant regions", "start_pos": 77, "end_pos": 113, "type": "TASK", "confidence": 0.8326898962259293}]}, {"text": "Next we present our data and discuss our annotation methodology.", "labels": [], "entities": []}, {"text": "We follow this with a description of the complete set of features and machine learning algorithms investigated.", "labels": [], "entities": []}, {"text": "Section 6 presents our results, including a comparison of the learned classifiers and an analysis of the relative utility of various features.", "labels": [], "entities": []}], "datasetContent": [{"text": "We applied several classifier learning algorithms to our data: Naive Bayes, Support Vector Machines (SVMs), 1-nearest neighbor, and the C4.5 decision tree learning algorithm.", "labels": [], "entities": []}, {"text": "We used the implementations in the Weka package of machine learning algorithms), running the algorithms with default settings.", "labels": [], "entities": [{"text": "Weka package of machine learning algorithms", "start_pos": 35, "end_pos": 78, "type": "DATASET", "confidence": 0.9096916417280833}]}, {"text": "In each case, we performed 4-fold cross-validation, training on sets consisting of three of the conversations in each topic (15 conversations total) and testing on sets of the remaining 1 from each topic (5 total).", "labels": [], "entities": []}, {"text": "Average training set size was approximately 3800 utterances, of which about 700 were Small Talk and 350 Metaconversation.", "labels": [], "entities": []}, {"text": "The average test set size was 1270.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Classification accuracy and Cohen's Kappa  statistic for each of the machine learning algorithms  we tried, using all features at the 100-words level.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9440431594848633}, {"text": "Cohen's Kappa  statistic", "start_pos": 38, "end_pos": 62, "type": "METRIC", "confidence": 0.5872333720326424}]}, {"text": " Table 6: Percent accuracy and Cohen's Kappa statis- tic for the SVM at the 100-words level when features  were left out or put in individually.", "labels": [], "entities": [{"text": "Percent", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9562954306602478}, {"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9322546124458313}]}]}