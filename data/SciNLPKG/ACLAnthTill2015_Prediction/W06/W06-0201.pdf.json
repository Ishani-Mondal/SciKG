{"title": [{"text": "Development of an automatic trend exploration system using the MuST data collection", "labels": [], "entities": [{"text": "automatic trend exploration", "start_pos": 18, "end_pos": 45, "type": "TASK", "confidence": 0.7171975175539652}, {"text": "MuST data collection", "start_pos": 63, "end_pos": 83, "type": "DATASET", "confidence": 0.8471102317174276}]}], "abstractContent": [{"text": "The automatic extraction of trend information from text documents such as newspaper articles would be useful for exploring and examining trends.", "labels": [], "entities": [{"text": "extraction of trend information from text documents such as newspaper articles", "start_pos": 14, "end_pos": 92, "type": "TASK", "confidence": 0.681274804201993}]}, {"text": "To enable this, we used data sets provided by a workshop on multimodal summarization for trend information (the MuST Workshop) to construct an automatic trend exploration system.", "labels": [], "entities": [{"text": "MuST Workshop)", "start_pos": 112, "end_pos": 126, "type": "DATASET", "confidence": 0.8916944861412048}]}, {"text": "This system first extracts units, temporals, and item expressions from newspaper articles, then it extracts sets of expressions as trend information, and finally it arranges the sets and displays them in graphs.", "labels": [], "entities": []}, {"text": "For example, when documents concerning the politics are given, the system extracts \"%\" and \"Cabinet approval rating\" as a unit and an item expression including temporal expressions.", "labels": [], "entities": []}, {"text": "It next extracts values related to \"%\".", "labels": [], "entities": []}, {"text": "Finally, it makes a graph where temporal expressions are used for the horizontal axis and the value of percentage is shown on the vertical axis.", "labels": [], "entities": []}, {"text": "This graph indicates the trend of Cabinet approval rating and is useful for investigating Cabinet approval rating.", "labels": [], "entities": []}, {"text": "Graphs are obviously easy to recognize and useful for understanding information described in documents.", "labels": [], "entities": []}, {"text": "In experiments, when we judged the extraction of a correct graph as the top output to be correct, the system accuracy was 0.2500 in evaluation A and 0.3334 in evaluation B.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 109, "end_pos": 117, "type": "METRIC", "confidence": 0.9919648170471191}]}, {"text": "(In evaluation A, a graph where 75% or more of the points were correct was judged to be correct; in evaluation B, a graph where 50% or more of the points were correct was judged to be correct.)", "labels": [], "entities": []}, {"text": "When we judged the extraction of a correct graph in the top five outputs to be correct, accuracy rose to 0.4167 in evaluation A and 0.6250 in evaluation B.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.9997687935829163}]}, {"text": "Our system is convenient and effective because it can output a graph that includes trend information at these levels of accuracy when given only a set of documents as input.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 120, "end_pos": 128, "type": "METRIC", "confidence": 0.9969786405563354}]}], "introductionContent": [{"text": "We have studied ways to automatically extract trend information from text documents, such as newspaper articles, because such a capability will be useful for exploring and examining trends.", "labels": [], "entities": []}, {"text": "In this work, we used data sets provided by a workshop on multimodal summarization for trend information (the MuST Workshop) to construct an automatic trend exploration system.", "labels": [], "entities": [{"text": "MuST Workshop)", "start_pos": 110, "end_pos": 124, "type": "DATASET", "confidence": 0.8908635179201762}]}, {"text": "This system firsts extract units, temporals, and item expressions from newspaper articles, then it extract sets of expressions as trend information, and finally it arranges the sets and displays them in graphs.", "labels": [], "entities": []}, {"text": "For example, when documents concerning the politics are given, the system extracts \"%\" and \"Cabinet approval rating\" as a unit and an item expression including temporal expressions.", "labels": [], "entities": []}, {"text": "It next extracts values related to \"%\".", "labels": [], "entities": []}, {"text": "Finally, it makes a graph where temporal expressions are used for the horizontal axis and the value of percentage is shown on the vertical axis.", "labels": [], "entities": []}, {"text": "This graph indicates the trend of Cabinet approval rating and is useful for investigating Cabinet approval rating.", "labels": [], "entities": []}, {"text": "Graphs are obviously easy to recognize and useful for understanding information described in documents.", "labels": [], "entities": []}], "datasetContent": [{"text": "We describe some examples of the output of our system in Sections 4.1, 4.2, and 4.3, and the results from our system evaluation in Section 4.4.", "labels": [], "entities": []}, {"text": "We made experiments using Japanese newspaper articles.", "labels": [], "entities": []}, {"text": "We used a closed data set and an open data set to evaluate our system.", "labels": [], "entities": []}, {"text": "The closed data set was the data set provided by the MuST workshop organizer and contained 20 domain document sets.", "labels": [], "entities": [{"text": "MuST workshop organizer", "start_pos": 53, "end_pos": 76, "type": "DATASET", "confidence": 0.6890006264050802}]}, {"text": "The data sets were separated for each domain.", "labels": [], "entities": []}, {"text": "We made the open data set based on the MuST data set using newspaper articles (editions of the Mainichi newspaper from.", "labels": [], "entities": [{"text": "MuST data set", "start_pos": 39, "end_pos": 52, "type": "DATASET", "confidence": 0.9180081884066263}, {"text": "Mainichi newspaper", "start_pos": 95, "end_pos": 113, "type": "DATASET", "confidence": 0.9890697598457336}]}, {"text": "We made 24 document sets using information retrieval by term query.", "labels": [], "entities": []}, {"text": "We used documents retrieved by term query as the document set of the domain for each query term.", "labels": [], "entities": []}, {"text": "We used the closed data set to adjust our system and used the open data set to calculate the evaluation scores of our system for evaluation.", "labels": [], "entities": []}, {"text": "We judged whether a document set included the information needed to make trend graphs by consulting the top 30 combinations of three kinds of important expression having the 30 highest values as in the method of Section 3.4.", "labels": [], "entities": []}, {"text": "There were 19 documents including such information in the open data.", "labels": [], "entities": []}, {"text": "We used these 19 documents for the following evaluation.", "labels": [], "entities": []}, {"text": "In the evaluation, we examined how accurately trend graphs could be output when using the top ranked expressions.", "labels": [], "entities": []}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "The best scores are described using bold fonts for each evaluation score.", "labels": [], "entities": []}, {"text": "We used five evaluation scores.", "labels": [], "entities": []}, {"text": "MRR is the average of the score where 1/r is given as the score when the rank of the first correct output is r ().", "labels": [], "entities": [{"text": "MRR", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.9338975548744202}]}, {"text": "TP1 is the average of the precision in the first output.", "labels": [], "entities": [{"text": "TP1", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.9751718640327454}, {"text": "precision", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.9989575147628784}]}, {"text": "TP5 is the average of the precision where the system includes a correct output in the first five outputs.", "labels": [], "entities": [{"text": "TP5", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.9753339290618896}, {"text": "precision", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.9993454813957214}]}, {"text": "RP is the average of the r-precision and AP is the average of the average precision.", "labels": [], "entities": [{"text": "RP", "start_pos": 0, "end_pos": 2, "type": "METRIC", "confidence": 0.9752444624900818}, {"text": "AP", "start_pos": 41, "end_pos": 43, "type": "METRIC", "confidence": 0.9987975358963013}, {"text": "precision", "start_pos": 74, "end_pos": 83, "type": "METRIC", "confidence": 0.9545513987541199}]}, {"text": "(Here, the average means that the evaluation score is calculated for each domain data set and the summation of these scores divided by the number of the domain data sets is the average.)", "labels": [], "entities": []}, {"text": "R-precision is the precision of the r outputs where r is the number of correct answers.", "labels": [], "entities": [{"text": "R-precision", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.9308952689170837}, {"text": "precision", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.9987527132034302}]}, {"text": "Average precision is the average of the precision when each correct answer is output ().", "labels": [], "entities": [{"text": "precision", "start_pos": 8, "end_pos": 17, "type": "METRIC", "confidence": 0.8910547494888306}, {"text": "precision", "start_pos": 40, "end_pos": 49, "type": "METRIC", "confidence": 0.9991576671600342}]}, {"text": "The r-precision indicates the precision where the recall and the precision have the same value.", "labels": [], "entities": [{"text": "precision", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.9978826642036438}, {"text": "recall", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.9941781759262085}, {"text": "precision", "start_pos": 65, "end_pos": 74, "type": "METRIC", "confidence": 0.9892829656600952}]}, {"text": "The precision is the ratio of correct answers in the system output.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9995712637901306}]}, {"text": "The recall is the ratio of correct answers in the system output to the total number of correct answers.", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.999491810798645}]}, {"text": "Methods 1 to 4 in are the methods used to extract useful trend information described in Section 3.4.", "labels": [], "entities": []}, {"text": "Use of the expression length means the product of the occurrence number for an expression and the length of the expression was used to calculate the score for an important item expression.", "labels": [], "entities": []}, {"text": "No use of the expression length means this product was not used and only the occurrence number was used.", "labels": [], "entities": []}, {"text": "To calculate the r-precision and average precision, we needed correct answer sets.", "labels": [], "entities": [{"text": "average", "start_pos": 33, "end_pos": 40, "type": "METRIC", "confidence": 0.9386904239654541}, {"text": "precision", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.5842357873916626}]}, {"text": "We made the correct answer sets by manually examining the top 30 outputs for the 24 (= 4 \u00d7 6) methods (the combinations of methods 1 to 4 and the use of Equations 1 to 3 with or without the expression length) and defining the useful trend information among them as the correct answer sets.", "labels": [], "entities": []}, {"text": "In evaluation A, a graph where 75% or more of the points were correct was judged to be correct.", "labels": [], "entities": []}, {"text": "In evaluation B, a graph where 50% or more of the points were correct was judged to be correct.", "labels": [], "entities": []}, {"text": "From the experimental results, we found that the method using the total frequency fora word (Equation 2) and the length of an expression was best for calculating the scores of important expressions.", "labels": [], "entities": [{"text": "Equation 2)", "start_pos": 93, "end_pos": 104, "type": "METRIC", "confidence": 0.9426284233729044}]}, {"text": "Using the length of an expression was important.", "labels": [], "entities": []}, {"text": "(The way of using the length of an expression was described in the last part of Section 3.2.)", "labels": [], "entities": []}, {"text": "For example, when \"Cabinet approval rating\" appears in documents, a method without expression lengths extracts \"rating\".", "labels": [], "entities": []}, {"text": "When the system extracts trend information sets using \"rating\", it extracts wrong information related to types of \"rating\" other than \"Cabinet approval rating\".", "labels": [], "entities": []}, {"text": "This hinders the extraction of coherent trend information.", "labels": [], "entities": []}, {"text": "Thus, it is beneficial to use the length of an expression when extracting important item expressions.", "labels": [], "entities": []}, {"text": "We also found that method 1 (using both the frequency of the trend information sets and the scores of important expressions) was generally the best.", "labels": [], "entities": []}, {"text": "When we judged the extraction of a correct graph as the top output in the experiments to be correct, our best system accuracy was 0.3158 in evaluation A and 0.4211 in evaluation B.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 117, "end_pos": 125, "type": "METRIC", "confidence": 0.9927062392234802}]}, {"text": "When we judged the extraction of a correct graph in the top five outputs to be correct, the best accuracy rose to 0.5263 in evaluation A and 0.7895 in evaluation B.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.9994301199913025}]}, {"text": "In terms of the evaluation scores for the 24 original data sets (these evaluation scores were multiplied by 19/24), when we judged the extraction of a correct graph as the top output in the experiments to be correct, our best system accuracy was 0.3158 in evaluation A and 0.4211 in evaluation B.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 233, "end_pos": 241, "type": "METRIC", "confidence": 0.9876411557197571}]}, {"text": "When we judged the extraction of a correct graph in the top five outputs to be correct, the best accuracy rose to 0.5263 in evaluation A and 0.7895 in evaluation B.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.9994301199913025}]}, {"text": "Our system is convenient and effective because it can output a graph that includes trend information at these levels of accuracy when given only a set of documents as input.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 120, "end_pos": 128, "type": "METRIC", "confidence": 0.9969786405563354}]}, {"text": "As shown in, the best values for RP (which indicates the precision where the recall and the precision have the same value) and AP were 0.2127 and 0.1705, respectively, in evaluation B.", "labels": [], "entities": [{"text": "RP", "start_pos": 33, "end_pos": 35, "type": "METRIC", "confidence": 0.9929885268211365}, {"text": "precision", "start_pos": 57, "end_pos": 66, "type": "METRIC", "confidence": 0.9967413544654846}, {"text": "recall", "start_pos": 77, "end_pos": 83, "type": "METRIC", "confidence": 0.9927903413772583}, {"text": "precision", "start_pos": 92, "end_pos": 101, "type": "METRIC", "confidence": 0.9755464792251587}, {"text": "AP", "start_pos": 127, "end_pos": 129, "type": "METRIC", "confidence": 0.9993559718132019}]}, {"text": "This RP value indicates that our system could extract about one out of five graphs among the correct answers when the recall and the precision had the same value.) developed a system to extract numerical expressions and their related item expressions by using syntactic information and patterns.", "labels": [], "entities": [{"text": "RP", "start_pos": 5, "end_pos": 7, "type": "METRIC", "confidence": 0.9864711165428162}, {"text": "recall", "start_pos": 118, "end_pos": 124, "type": "METRIC", "confidence": 0.9944913387298584}, {"text": "precision", "start_pos": 133, "end_pos": 142, "type": "METRIC", "confidence": 0.9313691258430481}]}, {"text": "However, they did not deal with the extraction of important expressions or gather trend information sets.", "labels": [], "entities": []}, {"text": "In addition, they did not make a graph from the extracted expressions.) took an approach of judging whether the sentence relationship indicates transition (trend information) or renovation (revision of information) and used the judgment results to extract trend information.", "labels": [], "entities": []}, {"text": "They also constructed a system to extract numerical information from input numerical units and make a graph that includes trend information.", "labels": [], "entities": []}, {"text": "However, they did not consider ways to extract item numerical units and item expressions automatically.", "labels": [], "entities": []}], "tableCaptions": []}