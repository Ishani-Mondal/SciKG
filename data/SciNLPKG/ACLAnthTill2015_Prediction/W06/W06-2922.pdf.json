{"title": [{"text": "Experiments with a Multilanguage Non-Projective Dependency Parser", "labels": [], "entities": []}], "abstractContent": [], "introductionContent": [{"text": "Parsing natural language is an essential step in several applications that involve document analysis, e.g. knowledge extraction, question answering, summarization, filtering.", "labels": [], "entities": [{"text": "Parsing natural language", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8730478882789612}, {"text": "document analysis", "start_pos": 83, "end_pos": 100, "type": "TASK", "confidence": 0.711016520857811}, {"text": "knowledge extraction", "start_pos": 107, "end_pos": 127, "type": "TASK", "confidence": 0.7668900787830353}, {"text": "question answering", "start_pos": 129, "end_pos": 147, "type": "TASK", "confidence": 0.8901155889034271}, {"text": "summarization", "start_pos": 149, "end_pos": 162, "type": "TASK", "confidence": 0.9839255809783936}]}, {"text": "The best performing systems at the TREC Question Answering track employ parsing for analyzing sentences in order to identify the query focus, to extract relations and to disambiguate meanings of words.", "labels": [], "entities": [{"text": "TREC Question Answering", "start_pos": 35, "end_pos": 58, "type": "TASK", "confidence": 0.7631664673487345}]}, {"text": "These are often demanding applications, which need to handle large collections and to provide results in a fraction of a second.", "labels": [], "entities": []}, {"text": "Dependency parsers are promising for these applications since a dependency tree provides predicate-argument relations which are convenient for use in the later stages.", "labels": [], "entities": [{"text": "Dependency parsers", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7540896236896515}]}, {"text": "Recently statistical dependency parsing techniques have been proposed which are deterministic and/or linear).", "labels": [], "entities": [{"text": "statistical dependency parsing", "start_pos": 9, "end_pos": 39, "type": "TASK", "confidence": 0.7075089712937673}]}, {"text": "These parsers are based on learning the correct sequence of Shift/Reduce actions used to construct the dependency tree.", "labels": [], "entities": []}, {"text": "Learning is based on techniques like SVM or Memory Based Learning, which provide high accuracy but are often computationally expensive.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.9950716495513916}]}, {"text": "report a two week learning time on a Japanese corpus of about 8000 sentences with SVM.", "labels": [], "entities": [{"text": "SVM", "start_pos": 82, "end_pos": 85, "type": "DATASET", "confidence": 0.7999036312103271}]}, {"text": "Using Maximum Entropy) classifiers I built a parser that achieves a throughput of over 200 sentences per second, with a small loss inaccuracy of about 2-3 %.", "labels": [], "entities": []}, {"text": "The efficiency of Maximum Entropy classifiers seems to leave a large margin that can be exploited to regain accuracy by other means.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 108, "end_pos": 116, "type": "METRIC", "confidence": 0.9978594183921814}]}, {"text": "I performed a series of experiments to determine whether increasing the number of features or combining several classifiers could allow regaining the best accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 155, "end_pos": 163, "type": "METRIC", "confidence": 0.9973537921905518}]}, {"text": "An experiment cycle in our setting requires less than 15 minutes fora treebank of moderate size like the Portuguese treebank () and this allows evaluating the effectiveness of adding/removing features that hopefully might apply also when using other learning techniques.", "labels": [], "entities": [{"text": "Portuguese treebank", "start_pos": 105, "end_pos": 124, "type": "DATASET", "confidence": 0.8615438342094421}]}, {"text": "I extended the Yamada-Matsumoto parser to handle labeled dependencies: I tried two approaches: using a single classifier to predict pairs of actions and labels and using two separate classifiers, one for actions and one for labels.", "labels": [], "entities": []}, {"text": "Finally, I extended the repertoire of actions used by the parser, in order to handle non-projective relations.", "labels": [], "entities": []}, {"text": "Tests on the PDT ( show that the added actions are sufficient to handle all cases of non-projectivity.", "labels": [], "entities": [{"text": "PDT", "start_pos": 13, "end_pos": 16, "type": "DATASET", "confidence": 0.7023577690124512}]}, {"text": "However, since the cases of non-projectivity are quite rare in the corpus, the general learner is not supplied enough of them to learn how to classify them accurately, hence it maybe worthwhile to exploit a second classifier trained specifically in handling nonprojective situations.", "labels": [], "entities": []}], "datasetContent": [{"text": "I performed several experiments to tune the parser.", "labels": [], "entities": []}, {"text": "I also tried alternative machine learning algorithms, including SVM, Winnow, Voted Perceptron.", "labels": [], "entities": []}, {"text": "The use of SVM turned out quite impractical since the technique does not scale to the size of training data involved: training an SVM with such a large number of features was impossible for any of the larger corpora.", "labels": [], "entities": []}, {"text": "For smaller ones, e.g. Portuguese, training required over 4 days but produced a bad model which could not be used (I tried both the TinySVM (Kudo 2002) and the LIBSVM (Chang and Lin 2001) implementations).", "labels": [], "entities": [{"text": "TinySVM", "start_pos": 132, "end_pos": 139, "type": "DATASET", "confidence": 0.9204862117767334}, {"text": "LIBSVM (Chang and Lin 2001)", "start_pos": 160, "end_pos": 187, "type": "DATASET", "confidence": 0.8655296053205218}]}, {"text": "Given the speed of the Maximum Entropy classifier, I explored whether increasing the number of features could improve accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 118, "end_pos": 126, "type": "METRIC", "confidence": 0.9964312314987183}]}, {"text": "I experimented adding various features controlled by the parameters above: none appeared to be effective, except the addition of the previous action.", "labels": [], "entities": []}, {"text": "The classifier returns both the action and the label to be assigned.", "labels": [], "entities": []}, {"text": "Some experiments were carried out splitting the task among several specialized classifiers.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. Results for the CoNLL-X Shared task (official values in italics).", "labels": [], "entities": [{"text": "CoNLL-X Shared task", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.48841069142023724}]}]}