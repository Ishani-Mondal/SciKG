{"title": [{"text": "Manual Annotation of Opinion Categories in Meetings", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper applies the categories from an opinion annotation scheme developed for monologue text to the genre of multiparty meetings.", "labels": [], "entities": []}, {"text": "We describe modifications to the coding guidelines that were required to extend the categories to the new type of data, and present the results of an inter -annotator agreement study.", "labels": [], "entities": []}, {"text": "As researchers have found with other types of annotations in speech data, inter-annotator agreement is higher when the annotators both read and listen to the data than when they only read the transcripts.", "labels": [], "entities": [{"text": "agreement", "start_pos": 90, "end_pos": 99, "type": "METRIC", "confidence": 0.7856093049049377}]}, {"text": "Previous work exploited prosodic clues to perform automatic detection of speaker emotion (Liscombe et al. 2003).", "labels": [], "entities": [{"text": "automatic detection of speaker emotion", "start_pos": 50, "end_pos": 88, "type": "TASK", "confidence": 0.7367027878761292}]}, {"text": "Our findings suggest that doing so to recognize opinion categories would be a promising line of work.", "labels": [], "entities": []}], "introductionContent": [{"text": "Subjectivity refers to aspects of language that express opinions, beliefs, evaluations and speculations ( ).", "labels": [], "entities": []}, {"text": "Many natural language processing applications could benefit from being able to distinguish between facts and opinions of various types, including speech-oriented applications such as meeting browsers, meeting summarizers, and speech-oriented question answering (QA) systems.", "labels": [], "entities": [{"text": "meeting summarizers", "start_pos": 201, "end_pos": 220, "type": "TASK", "confidence": 0.7181286811828613}, {"text": "speech-oriented question answering (QA)", "start_pos": 226, "end_pos": 265, "type": "TASK", "confidence": 0.8154067099094391}]}, {"text": "Meeting browsers could find instances in meetings where opinions about key topics are expressed.", "labels": [], "entities": []}, {"text": "Summarizers could include strong arguments for and against issues, to make the final outcome of the meeting more understandable.", "labels": [], "entities": []}, {"text": "A preliminary user survey ( showed that users would like to be able to query meeting records with subjective questions like \"Show me the conflicts of opinions between X and Y\" , \"Who made the highest number of positive/negative comments\" and \"Give me all the contributions of participant X in favor of alternative A regarding the issue I.\"", "labels": [], "entities": []}, {"text": "A QA system with a component to recognize opinions would be able to help find answers to such questions.", "labels": [], "entities": []}, {"text": "Consider the following example from a meeting about an investment firm choosing which car to buy 1 . (In the examples, the words and phrases describing or expressing the opinion are underlined): (1) 2 OCK: Revenues of less than a million and losses of like five million you know that's pathetic Here, the speaker, OCK, shows his strong negative evaluation by using the expression \"That's pathetic.\"", "labels": [], "entities": [{"text": "OCK", "start_pos": 201, "end_pos": 204, "type": "METRIC", "confidence": 0.8117173910140991}]}, {"text": "(2) OCK: No it might just be apiece of junk cheap piece of junk that's not a good investment In (2), the speaker uses the term \"just apiece of junk\" to express his negative evaluation and uses this to argue for his belief that it is \"not a good investment.\"", "labels": [], "entities": [{"text": "OCK", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.8312861323356628}]}, {"text": "(3) OCK: Yeah I think that's the wrong image for an investment bank he wants stability and s safety and you don't want flashy like zip-ping around the corner kind of thing you know The example above shows that the speaker has a negative judgment towards the suggestion of a sports car (that was made in the previous turn) which is indicated by the words \"wrong image.\"", "labels": [], "entities": [{"text": "OCK", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.6323959827423096}, {"text": "safety", "start_pos": 93, "end_pos": 99, "type": "METRIC", "confidence": 0.9808217883110046}]}, {"text": "The speaker then goes onto positively argue for what he wants.", "labels": [], "entities": []}, {"text": "He further argues against the current suggestion by using more negative terms like \"flashy\" and \"zipping around the corner.\"", "labels": [], "entities": []}, {"text": "The speaker believes that \"zipping around the corner\" is bad as it would give a wrong impression of the bank to the customers.", "labels": [], "entities": []}, {"text": "In the absence of such analyses, the decision making process and rationale behind the outcomes of meetings, which form an important part of the organization's memory, might remain unavailable.", "labels": [], "entities": []}, {"text": "In this paper, we perform annotation of a meeting corpus to lay the foundation for research on opinion detection in speech.", "labels": [], "entities": [{"text": "opinion detection in speech", "start_pos": 95, "end_pos": 122, "type": "TASK", "confidence": 0.8506074994802475}]}, {"text": "We show how categories from an opinion (subjectivity) annotation scheme, which was developed for news articles, can be applied to the genre of multi-party meetings.", "labels": [], "entities": []}, {"text": "The new genre poses challenges as it is significantly different from the text domain, where opinion analysis has traditionally been applied.", "labels": [], "entities": [{"text": "opinion analysis", "start_pos": 92, "end_pos": 108, "type": "TASK", "confidence": 0.733426421880722}]}, {"text": "Specifically, differences arise because: 1) There are many participants interacting with one another, each expressing his or her own opinion, and eliciting reactions in the process.", "labels": [], "entities": []}, {"text": "2) Social interactions may constrain how openly people express their opinions; i.e., they are often indirect in their negative evaluations.", "labels": [], "entities": []}, {"text": "We also explore the influence of speech on human perception of opinions.", "labels": [], "entities": []}, {"text": "Specifically, we annotated some meeting data with the opinion categories Sentiment and Arguing as defined in . In our annotation we first distinguish whether a Sentiment or Arguing is being expressed.", "labels": [], "entities": [{"text": "Arguing", "start_pos": 87, "end_pos": 94, "type": "METRIC", "confidence": 0.9763569235801697}]}, {"text": "If one is, we then mark the polarity (i.e., positive or negative) and the intensity (i.e., how strong the opinion is).", "labels": [], "entities": []}, {"text": "Annotating the individual opinion expressions is useful in this genre, because we see many utterances that have more than one type of opinion (e.g. (3) above).", "labels": [], "entities": []}, {"text": "To investigate how opinions are expressed in speech, we divide our annotation into two tasks, one in which the annotator only reads the raw text, and the other in which the annotator reads the raw text and also listens to the speech.", "labels": [], "entities": []}, {"text": "We measure inter-annotator agreement for both tasks.", "labels": [], "entities": []}, {"text": "We found that the opinion categories apply well to the multi-party meeting data, although there is some room for improvement: the Kappa values range from 0.32 to 0.69.", "labels": [], "entities": []}, {"text": "As has been found for other types of annotations in speech, agreement is higher when the annotators both read and listen to the data than when they only read the transcripts.", "labels": [], "entities": [{"text": "agreement", "start_pos": 60, "end_pos": 69, "type": "METRIC", "confidence": 0.9973592162132263}]}, {"text": "Interestingly, the advantages are more dramatic for some categories than others.", "labels": [], "entities": []}, {"text": "And, in both conditions, agreement is higher for the positive than for the negative categories.", "labels": [], "entities": [{"text": "agreement", "start_pos": 25, "end_pos": 34, "type": "METRIC", "confidence": 0.9981132745742798}]}, {"text": "We discuss possible reasons for these disparities.", "labels": [], "entities": []}, {"text": "Prosodic clues have been exploited to perform automatic detection of speaker emotion).", "labels": [], "entities": [{"text": "automatic detection of speaker emotion", "start_pos": 46, "end_pos": 84, "type": "TASK", "confidence": 0.7542371630668641}]}, {"text": "Our findings suggest that doing so to recognize opinion categories is a promising line of work.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows: In Section 2 we discuss the data and the annotation scheme and present examples.", "labels": [], "entities": []}, {"text": "We then present our inter-annotator agreement results in Section 3, and in Section 4 we discuss issues and observations.", "labels": [], "entities": []}, {"text": "Related work is described in Section 5.", "labels": [], "entities": []}, {"text": "Conclusions and Future Work are presented in Section 6.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1 shows the inter-annotator Kappa val- ues on the test set.", "labels": [], "entities": [{"text": "inter-annotator Kappa val- ues", "start_pos": 19, "end_pos": 49, "type": "METRIC", "confidence": 0.6691613614559173}]}]}