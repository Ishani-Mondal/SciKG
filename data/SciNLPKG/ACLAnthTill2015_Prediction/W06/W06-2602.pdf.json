{"title": [{"text": "Constraint Satisfaction Inference: Non-probabilistic Global Inference for Sequence Labelling", "labels": [], "entities": [{"text": "Constraint Satisfaction Inference", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8835418423016866}, {"text": "Sequence Labelling", "start_pos": 74, "end_pos": 92, "type": "TASK", "confidence": 0.9198304116725922}]}], "abstractContent": [{"text": "We present anew method for performing sequence labelling based on the idea of using a machine-learning classifier to generate several possible output sequences, and then applying an inference procedure to select the best sequence among those.", "labels": [], "entities": []}, {"text": "Most sequence labelling methods following a similar approach require the base classifier to make probabilistic predictions.", "labels": [], "entities": []}, {"text": "In contrast, our method can be used with virtually any type of clas-sifier.", "labels": [], "entities": []}, {"text": "This is illustrated by implementing a sequence classifier on top of a (non-probabilistic) memory-based learner.", "labels": [], "entities": []}, {"text": "Ina series of experiments, this method is shown to outperform two other methods; one naive baseline approach, and another more sophisticated method.", "labels": [], "entities": []}], "introductionContent": [{"text": "In machine learning for natural language processing, many diverse tasks somehow involve processing of sequentially-structured data.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 24, "end_pos": 51, "type": "TASK", "confidence": 0.6951836943626404}]}, {"text": "For example, syntactic chunking, grapheme-to-phoneme conversion, and named-entity recognition are all usually reformulated as sequence labelling tasks: a task-specific global unit, such as a sentence or a word, is divided into atomic sub-parts, e.g. word or letters, each of which is separately assigned a label.", "labels": [], "entities": [{"text": "syntactic chunking", "start_pos": 13, "end_pos": 31, "type": "TASK", "confidence": 0.7711630165576935}, {"text": "grapheme-to-phoneme conversion", "start_pos": 33, "end_pos": 63, "type": "TASK", "confidence": 0.7639541625976562}, {"text": "named-entity recognition", "start_pos": 69, "end_pos": 93, "type": "TASK", "confidence": 0.7250945270061493}]}, {"text": "The concatenation of those labels forms the eventual output for the global unit.", "labels": [], "entities": []}, {"text": "More formally, we can define a sequence labelling task as a tuple (x, y, ).", "labels": [], "entities": []}, {"text": "The goal is to map an input vector x = \ud97b\udf59x 1 , x 2 , . .", "labels": [], "entities": []}, {"text": ", x n \ud97b\udf59 of tokens to an output sequence y = \ud97b\udf59y 1 , y 2 , . .", "labels": [], "entities": []}, {"text": ", y n \ud97b\udf59 of labels.", "labels": [], "entities": []}, {"text": "The possible labels for each token are specified by a finite set \ud97b\udf59, that is, y i \u2208 , \u2200i.", "labels": [], "entities": []}, {"text": "In most real-world sequence labelling tasks, the values of the output labels are sequentially correlated.", "labels": [], "entities": []}, {"text": "For machine learning approaches to sequence labelling this implies that classifying each token separately without considering the labels assigned to other tokens in the sequence may lead to sub-optimal performance.", "labels": [], "entities": []}, {"text": "Ideally, the complex mapping of the entire input sequence to its corresponding output sequence is considered one classification case; the classifier then has access to all information stored in the sequence.", "labels": [], "entities": []}, {"text": "In practise, however, both input and output sequences are far too sparse for such classifications to be performed reliably.", "labels": [], "entities": []}, {"text": "A popular approach to circumvent the issues raised above is what we will refer to as the classification and inference approach, covering techniques such as hidden markov models and conditional random fields ().", "labels": [], "entities": []}, {"text": "Rather than having a token-level classifier make local decisions independently of the rest of the sequence, the approach introduces an inference procedure, operating on the level of the sequence, using class likelihoods estimated by the classifier to optimise the likelihood of the entire output sequence.", "labels": [], "entities": []}, {"text": "A crucial property of most of the classification and inference techniques in use today is that the classifier used at the token level must be able to estimate the likelihood for each potential class label.", "labels": [], "entities": []}, {"text": "This is in contrast with the more common view of a classifier having to predict just one class label for an instance which is deemed most optimal.", "labels": [], "entities": []}, {"text": "Maximum-entropy models, which are used in many classification and inference techniques, have this property; they model the conditional class distribution.", "labels": [], "entities": []}, {"text": "In general, this is the case for all probabilistic classification methods.", "labels": [], "entities": []}, {"text": "However, many general-purpose machine learning techniques are not probabilistic.", "labels": [], "entities": []}, {"text": "In order to design inference procedures for those techniques, other principles than probabilistic ones have to be used.", "labels": [], "entities": []}, {"text": "In this paper, we propose a non-probabilistic inference procedure that improves performance of a memory-based learner on a wide range of naturallanguage sequence processing tasks.", "labels": [], "entities": []}, {"text": "We start from a technique introduced recently by Van den Bosch and, and reinterpret it as an instance of the classification and inference approach.", "labels": [], "entities": []}, {"text": "Moreover, the token-level inference procedure proposed in the original work is replaced by anew procedure based on principles of constraint satisfaction that does take into account the entire sequential context.", "labels": [], "entities": []}, {"text": "The remainder of this paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 introduces the theoretical background and starting point of the work presented in this paper: the trigram method, and memory-based learning.", "labels": [], "entities": []}, {"text": "Next, the new constraint-satisfactionbased inference procedure for class trigrams is presented in Section 3.", "labels": [], "entities": []}, {"text": "Experimental comparisons of a non-sequence-aware baseline classifier, the original trigram method, and the new classification and inference approach on a number of sequence labelling tasks are presented in Section 4 and discussed in Section 5.", "labels": [], "entities": []}, {"text": "Finally, our work is compared and contrasted with some related approaches in Section 6, and conclusions are drawn in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "To thoroughly evaluate our new inference procedure, and to show that it performs well over a wide range of natural-language sequence labelling tasks, we composed a benchmark set consisting of six different tasks, covering four areas in natural language processing: syntax (syntactic chunking), morphology (morphological analysis), phonology (grapheme-to-phoneme conversion), and information extraction (general, medical, and biomedical named-entity recognition).", "labels": [], "entities": [{"text": "grapheme-to-phoneme conversion)", "start_pos": 342, "end_pos": 373, "type": "TASK", "confidence": 0.8486286004384359}, {"text": "information extraction (general, medical, and biomedical named-entity recognition", "start_pos": 379, "end_pos": 460, "type": "TASK", "confidence": 0.5624006959525022}]}, {"text": "Below, the six data sets used for these tasks are introduced briefly.", "labels": [], "entities": []}, {"text": "CHUNK is the task of splitting sentences into non-overlapping syntactic phrases or constituents.", "labels": [], "entities": [{"text": "splitting sentences into non-overlapping syntactic phrases or constituents", "start_pos": 21, "end_pos": 95, "type": "TASK", "confidence": 0.7614446505904198}]}, {"text": "The data set, extracted from the WSJ Penn Treebank, and first used in the CoNLL-2000 shared task (Tjong Kim Sang and Buchholz, 2000), contains 211,727 training examples and 47,377 test instances.", "labels": [], "entities": [{"text": "WSJ Penn Treebank", "start_pos": 33, "end_pos": 50, "type": "DATASET", "confidence": 0.8962957660357157}, {"text": "CoNLL-2000 shared task (Tjong Kim Sang and Buchholz, 2000)", "start_pos": 74, "end_pos": 132, "type": "DATASET", "confidence": 0.8366589844226837}]}, {"text": "NER, named-entity recognition, involves identifying and labelling named entities in text.", "labels": [], "entities": [{"text": "named-entity recognition", "start_pos": 5, "end_pos": 29, "type": "TASK", "confidence": 0.7354677021503448}]}, {"text": "We employ the English NER shared task data set used in the CoNLL-2003 conference.", "labels": [], "entities": [{"text": "English NER shared task data set", "start_pos": 14, "end_pos": 46, "type": "DATASET", "confidence": 0.6689088344573975}, {"text": "CoNLL-2003 conference", "start_pos": 59, "end_pos": 80, "type": "DATASET", "confidence": 0.9101502299308777}]}, {"text": "This data set discriminates four name types: persons, organisations, locations, and a rest category of \"miscellany names\".", "labels": [], "entities": []}, {"text": "The data set is a collection of newswire articles from the Reuters Corpus, RCV1 1 . The given training set contains 203,621 examples; as test set we use the \"testb\" evaluation set which contains 46,435 examples.", "labels": [], "entities": [{"text": "Reuters Corpus, RCV1 1", "start_pos": 59, "end_pos": 81, "type": "DATASET", "confidence": 0.8122426390647888}]}, {"text": "MED is a data set extracted from a semantic annotation of (parts of) two Dutch-language medical encyclopedias.", "labels": [], "entities": []}, {"text": "On the chunk-level of this annotation, there are labels for various medical concepts, such as disease names, body parts, and treatments, forming a set of twelve concept types in total.", "labels": [], "entities": []}, {"text": "Chunk sizes range from one to a few tokens.", "labels": [], "entities": []}, {"text": "The data have been split into training and test sets, resulting in 428,502 training examples and 47,430 test examples.", "labels": [], "entities": []}, {"text": "The GENIA corpus () is a collection of annotated abstracts taken from the National Library of Medicine's MEDLINE database.", "labels": [], "entities": [{"text": "GENIA corpus", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.9373346269130707}, {"text": "National Library of Medicine's MEDLINE database", "start_pos": 74, "end_pos": 121, "type": "DATASET", "confidence": 0.8749908123697553}]}, {"text": "Apart from part-of-speech tagging information, the corpus annotates a subset of the substances and the biological locations involved in reactions of proteins.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 11, "end_pos": 33, "type": "TASK", "confidence": 0.7108967006206512}]}, {"text": "Using a 90%-10% split for producing training and test sets, there are 458,593 training examples and 50,916 test examples.", "labels": [], "entities": []}, {"text": "PHONEME refers to grapheme-to-phoneme conversion for English.", "labels": [], "entities": [{"text": "PHONEME", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.5613850355148315}, {"text": "grapheme-to-phoneme conversion", "start_pos": 18, "end_pos": 48, "type": "TASK", "confidence": 0.7242602407932281}]}, {"text": "The sequences to be labelled are words composed of letters (rather than sentences composed of words).", "labels": [], "entities": []}, {"text": "We based ourselves on the English part of the CELEX-2 lexical database (, from which we extracted 65,467 word-pronunciation pairs.", "labels": [], "entities": [{"text": "CELEX-2 lexical database", "start_pos": 46, "end_pos": 70, "type": "DATASET", "confidence": 0.9545559287071228}]}, {"text": "This pair list has been aligned using expectationmaximisation to obtain sensible one-to-one mappings between letters and phonemes (Daelemans and Van den Bosch, 1996).", "labels": [], "entities": []}, {"text": "The classes to predict are 58 different phonemes, including some diphones such as needed to keep the letterphoneme alignment one-to-one.", "labels": [], "entities": []}, {"text": "The resulting data set has been split into a training set of 515,891 examples, and a test set of 57,279 examples.", "labels": [], "entities": []}, {"text": "MORPHO refers to morphological analysis of Dutch words.", "labels": [], "entities": [{"text": "MORPHO", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.6089497804641724}, {"text": "morphological analysis of Dutch words", "start_pos": 17, "end_pos": 54, "type": "TASK", "confidence": 0.711147665977478}]}, {"text": "We collected the morphological analysis of 336,698 Dutch words from the CELEX-2 lexical database (), and represented the task such that it captures the three most relevant elements of a morphological analysis: (1) the segmentation of the word into morphemes (stems, derivational morphemes, and inflections), (2) the part-of-speech tagging information contained by each morpheme; and: Performances of the baseline method, and the trigram method combined both with majority voting, and with constraint satisfaction inference.", "labels": [], "entities": [{"text": "CELEX-2 lexical database", "start_pos": 72, "end_pos": 96, "type": "DATASET", "confidence": 0.9610289931297302}]}, {"text": "The last column shows the performance of the (hypothetical) oracle inference procedure.", "labels": [], "entities": []}, {"text": "spelling changes due to compounding, derivation, or inflection that would enable the reconstruction of the appropriate root forms of the involved morphemes.", "labels": [], "entities": []}, {"text": "For CHUNK, and the three information extraction tasks, instances represent a seven-token window of words and their (predicted) part-of-speech tags.", "labels": [], "entities": [{"text": "information extraction tasks", "start_pos": 25, "end_pos": 53, "type": "TASK", "confidence": 0.7795430024464926}]}, {"text": "Each token is labelled with a class using the IOB type of segmentation coding as introduced by, marking whether the middle word is inside (I), outside (O), or at the beginning (B) of a chunk, or named entity.", "labels": [], "entities": []}, {"text": "Performance is measured by the F-score on correctly identified and labelled chunks, or named entities.", "labels": [], "entities": [{"text": "F-score", "start_pos": 31, "end_pos": 38, "type": "METRIC", "confidence": 0.9984784722328186}]}, {"text": "Instances for PHONEME, and MORPHO consist of a seven-letter window of letters only.", "labels": [], "entities": [{"text": "PHONEME", "start_pos": 14, "end_pos": 21, "type": "METRIC", "confidence": 0.8360403180122375}, {"text": "MORPHO", "start_pos": 27, "end_pos": 33, "type": "METRIC", "confidence": 0.9480840563774109}]}, {"text": "The labels assigned to an instance are task-specific and have been introduced above, together with the tasks themselves.", "labels": [], "entities": []}, {"text": "Generalisation performance is measured on the word accuracy level: if the entire phonological transcription of the word is predicted correctly, or if all three aspects of the morphological analysis are predicted correctly, the word is counted correct.", "labels": [], "entities": [{"text": "Generalisation", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.9178232550621033}, {"text": "accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9463298916816711}]}], "tableCaptions": [{"text": " Table 1: Performances of the baseline method, and  the trigram method combined both with majority  voting, and with constraint satisfaction inference.  The last column shows the performance of the (hy- pothetical) oracle inference procedure.", "labels": [], "entities": []}, {"text": " Table 2: The average number of potential output  sequences that result from class trigram predic- tions made by a memory-based base classifier.", "labels": [], "entities": []}]}