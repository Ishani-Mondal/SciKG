{"title": [{"text": "Hybrid Systems for Information Extraction and Question Answering", "labels": [], "entities": [{"text": "Information Extraction", "start_pos": 19, "end_pos": 41, "type": "TASK", "confidence": 0.7134662568569183}, {"text": "Question Answering", "start_pos": 46, "end_pos": 64, "type": "TASK", "confidence": 0.7890941500663757}]}], "abstractContent": [{"text": "Information Extraction, Summarization and Question Answering all manipulate natural language texts and should benefit from the use of NLP techniques.", "labels": [], "entities": [{"text": "Information Extraction", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7613079249858856}, {"text": "Question Answering", "start_pos": 42, "end_pos": 60, "type": "TASK", "confidence": 0.7769923806190491}]}, {"text": "Statistical techniques have till now outperformed symbolic processing of unrestricted text.", "labels": [], "entities": []}, {"text": "However, Information Extraction and Question Answering require by far more accurate results of what is currently produced by Bag-Of-Words approaches.", "labels": [], "entities": [{"text": "Information Extraction", "start_pos": 9, "end_pos": 31, "type": "TASK", "confidence": 0.832194447517395}, {"text": "Question Answering", "start_pos": 36, "end_pos": 54, "type": "TASK", "confidence": 0.7926283776760101}]}, {"text": "Besides, we see that such tasks as Semantic Evaluation of Text Entailment or Similarity-as required by the RTE Challenge, impose a much stricter performance in semantic terms to tell true from false pairs.", "labels": [], "entities": [{"text": "Semantic Evaluation of Text Entailment", "start_pos": 35, "end_pos": 73, "type": "TASK", "confidence": 0.8741968274116516}, {"text": "RTE Challenge", "start_pos": 107, "end_pos": 120, "type": "TASK", "confidence": 0.5757998526096344}]}, {"text": "We will speak in favour of a hybrid system, a combination of statistical and symbolic processing with reference to a specific problem, that of Anaphora Resolution which looms large and deep in text processing.", "labels": [], "entities": [{"text": "Anaphora Resolution", "start_pos": 143, "end_pos": 162, "type": "TASK", "confidence": 0.7414761334657669}]}], "introductionContent": [{"text": "Although full syntactic and semantic analysis of opendomain natural language text is beyond current technology, a number of papers have been recently published showing that, by using probabilistic or symbolic methods, it is possible to obtain dependencybased representations of unlimited texts with good recall and precision.", "labels": [], "entities": [{"text": "syntactic and semantic analysis of opendomain natural language text", "start_pos": 14, "end_pos": 81, "type": "TASK", "confidence": 0.7704898251427544}, {"text": "recall", "start_pos": 304, "end_pos": 310, "type": "METRIC", "confidence": 0.9975073933601379}, {"text": "precision", "start_pos": 315, "end_pos": 324, "type": "METRIC", "confidence": 0.9924627542495728}]}, {"text": "Consequently, we believe it should be possible to augment the manual-annotation-based approach with automatically built annotations by extracting a limited subset of semantic relations from unstructured text.", "labels": [], "entities": []}, {"text": "In short, shallow/partial text understanding on the level of semantic relations, an extended label including Predicate-Argument Structures and other syntactically and semantically derivable head modifiers and adjuncts.", "labels": [], "entities": []}, {"text": "This approach is promising because it attempts to address the well-known shortcomings of standard \"bag-of-words\" (BOWs) information retrieval/extraction techniques without requiring manual intervention: it develops current NLP technologies which make heavy use of statistically and FSA based approaches to syntactic parsing.", "labels": [], "entities": [{"text": "bag-of-words\" (BOWs) information retrieval/extraction", "start_pos": 99, "end_pos": 152, "type": "TASK", "confidence": 0.7814923557970259}, {"text": "syntactic parsing", "start_pos": 306, "end_pos": 323, "type": "TASK", "confidence": 0.7692059576511383}]}, {"text": "GETARUNS, a text understanding system (TUS), developed in collaboration between the University of Venice and the University of Parma, can perform semantic analysis on the basis of syntactic parsing and, after performing anaphora resolution, builds a quasi logical form with flat indexed Augmented Dependency Structures (ADSs).", "labels": [], "entities": [{"text": "GETARUNS", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.7162516713142395}, {"text": "text understanding system (TUS)", "start_pos": 12, "end_pos": 43, "type": "TASK", "confidence": 0.6800067176421484}, {"text": "semantic analysis", "start_pos": 146, "end_pos": 163, "type": "TASK", "confidence": 0.7473978400230408}]}, {"text": "In addition, it uses a centering algorithm to individuate the topics or discourse centers which are weighted on the basis of a relevance score.", "labels": [], "entities": []}, {"text": "This logical form can then be used to individuate the best sentence candidates to answer queries or provide appropriate information.", "labels": [], "entities": []}, {"text": "This paper is organized as follows: in section 2 below we discuss why deep linguistic processing is needed in Information Retrieval and Information Extraction; in section 3 we present GETARUNS, the NLP system and the Upper Module of GETARUNS; in section 4 we describe two experiments with state-of-the-art benchmark corpora.", "labels": [], "entities": [{"text": "Information Retrieval", "start_pos": 110, "end_pos": 131, "type": "TASK", "confidence": 0.7996359467506409}, {"text": "Information Extraction", "start_pos": 136, "end_pos": 158, "type": "TASK", "confidence": 0.7053175568580627}, {"text": "GETARUNS", "start_pos": 184, "end_pos": 192, "type": "METRIC", "confidence": 0.5933163166046143}, {"text": "GETARUNS", "start_pos": 233, "end_pos": 241, "type": "DATASET", "confidence": 0.8312492966651917}]}], "datasetContent": [{"text": "As an example of the shallow system we discuss here below the analysis of a newspaper article which as would usually be the case has a certain number of pronominal expressions, which modify the relevance of lexical descriptions in the overall processing for the search of either \"Named Entities\" or simply entities individuated by common nouns.", "labels": [], "entities": []}, {"text": "If the count is based solely on lexical lemmata and not on the presence of coreferential pronominal expressions, the results will be heavily biased and certainly wrong.", "labels": [], "entities": []}, {"text": "Here is the text:  After running with GETARUNS, the 450 questions recovered the whole of the original correct result 67% from first snippet.", "labels": [], "entities": [{"text": "GETARUNS", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.7387397289276123}]}, {"text": "The complete system has been tested with a set of texts derived from newspapers, narrative texts, children stories.", "labels": [], "entities": []}, {"text": "The performance is 75% correct.", "labels": [], "entities": [{"text": "correct", "start_pos": 23, "end_pos": 30, "type": "METRIC", "confidence": 0.9896848201751709}]}, {"text": "However, updating and tuning of the system is required for each new text whenever anew semantic relation is introduced by the parser and the semantics does not provide the appropriate mapping.", "labels": [], "entities": []}, {"text": "For instance, consider the case of the constituent \"holes in the tree\", where the syntax produces the appropriate structure but the semantics does not map \"holes\" as being in a LOCATion semantic relation with \"tree\".", "labels": [], "entities": []}, {"text": "In lack of such a semantic role information a dummy \"MODal\" will be produced which however will not generate the adequate semantic mapping in the DM and the meaning is lost.", "labels": [], "entities": []}, {"text": "As to the partial system, it has been used for DUC summarization contest, i.e. it has run over approximately 1 million words, including training and test sets, fora number of sentences totalling over 50K.", "labels": [], "entities": [{"text": "DUC summarization contest", "start_pos": 47, "end_pos": 72, "type": "TASK", "confidence": 0.6880081295967102}]}, {"text": "We tested the \"Partial\" modality with an additional 90,000 words texts taken from the testset made available by DUC 2002 contest.", "labels": [], "entities": [{"text": "DUC 2002 contest", "start_pos": 112, "end_pos": 128, "type": "DATASET", "confidence": 0.9595385193824768}]}, {"text": "On a preliminary perusal of samples of the results, we calculated 85% Precision on parsing and 70% on semantic mapping.", "labels": [], "entities": [{"text": "Precision", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.9992218017578125}, {"text": "semantic mapping", "start_pos": 102, "end_pos": 118, "type": "TASK", "confidence": 0.727069765329361}]}, {"text": "However evaluating full results requires a manually annotated database in which all linguistic properties have been carefully decided by human annotators.", "labels": [], "entities": []}, {"text": "In lack of such a database, we are unable to provide precise performance data.", "labels": [], "entities": []}, {"text": "The system has also been used for the RTE Challenge and performance was over 60% correct.", "labels": [], "entities": [{"text": "RTE Challenge", "start_pos": 38, "end_pos": 51, "type": "DATASET", "confidence": 0.7879050672054291}, {"text": "correct", "start_pos": 81, "end_pos": 88, "type": "METRIC", "confidence": 0.9694641828536987}]}], "tableCaptions": [{"text": " Table 2. General data of Worlverhampton's  coreference annotated corpora", "labels": [], "entities": [{"text": "Worlverhampton's  coreference annotated corpora", "start_pos": 26, "end_pos": 73, "type": "DATASET", "confidence": 0.9010348200798035}]}]}