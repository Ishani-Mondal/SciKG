{"title": [{"text": "Monolingual Web-based Factoid Question Answering in Chinese, Swedish, English and Japanese", "labels": [], "entities": [{"text": "Factoid Question Answering", "start_pos": 22, "end_pos": 48, "type": "TASK", "confidence": 0.5814890662829081}]}], "abstractContent": [{"text": "In this paper we extend the application of our statistical pattern classification approach to question answering (QA) which has previously been applied successfully to English and Japanese to develop two prototype QA systems in Chinese and Swedish.", "labels": [], "entities": [{"text": "statistical pattern classification", "start_pos": 47, "end_pos": 81, "type": "TASK", "confidence": 0.6613484422365824}, {"text": "question answering (QA)", "start_pos": 94, "end_pos": 117, "type": "TASK", "confidence": 0.86423761844635}]}, {"text": "We show what data is necessary to achieve this and also evaluate the performance of the two new systems using a translation of the TREC 2003 factoid QA task.", "labels": [], "entities": [{"text": "TREC 2003 factoid QA task", "start_pos": 131, "end_pos": 156, "type": "DATASET", "confidence": 0.8986202716827393}]}, {"text": "While performance for Chinese and Swedish is found to be lower than that for the more developed English and Japanese systems we explain why this is the case and offer solutions for their improvement.", "labels": [], "entities": []}, {"text": "All systems form the basis of our publicly accessible web-based multilingual QA system at http://asked.jp.", "labels": [], "entities": []}], "introductionContent": [{"text": "Much of the research into automatic question answering (QA) has understandably concentrated on the English language with little regard to portability or efficacy in other languages.", "labels": [], "entities": [{"text": "automatic question answering (QA)", "start_pos": 26, "end_pos": 59, "type": "TASK", "confidence": 0.799558699131012}]}, {"text": "It is only relatively recently, with the introduction of the CLEF and NTCIR QA evaluations, that researchers have started to look at porting and evaluating the techniques that have been shown to work well for English to other languages.", "labels": [], "entities": [{"text": "CLEF", "start_pos": 61, "end_pos": 65, "type": "DATASET", "confidence": 0.8703702092170715}, {"text": "NTCIR QA evaluations", "start_pos": 70, "end_pos": 90, "type": "DATASET", "confidence": 0.872304379940033}]}, {"text": "One of the major drawbacks of porting an English language QA system or approach to other languages is often the lack of the corresponding NLP tools in the target language.", "labels": [], "entities": []}, {"text": "For instance, parsers and named-entity (NE)-taggers, which are typical components in many QA systems, are certainly not available for all the world's languages.", "labels": [], "entities": [{"text": "named-entity (NE)-taggers", "start_pos": 26, "end_pos": 51, "type": "TASK", "confidence": 0.7241532683372498}]}, {"text": "Trainable parsers and NE-taggers similarly require appropriate training data which, if not available, is costly and requires specialized knowledge to produce.", "labels": [], "entities": []}, {"text": "Language-specific databases are also a common feature of many systems, some of which have taken many man-years to construct and verify.", "labels": [], "entities": []}, {"text": "Such a component in many English-language systems, for example, is WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 67, "end_pos": 74, "type": "DATASET", "confidence": 0.9758862853050232}]}, {"text": "While porting WordNet to other languages has been started in the Euro and Global WordNet projects they still only cover a relatively small number of languages.", "labels": [], "entities": [{"text": "porting WordNet", "start_pos": 6, "end_pos": 21, "type": "TASK", "confidence": 0.7539499402046204}, {"text": "Euro", "start_pos": 65, "end_pos": 69, "type": "DATASET", "confidence": 0.9618654847145081}, {"text": "Global WordNet", "start_pos": 74, "end_pos": 88, "type": "DATASET", "confidence": 0.7188034355640411}]}, {"text": "In this paper we describe the application of our data-driven approach to QA which was developed right from the outset with the aim of portability and robustness in mind.", "labels": [], "entities": [{"text": "QA", "start_pos": 73, "end_pos": 75, "type": "TASK", "confidence": 0.9165509343147278}]}, {"text": "This statistical pattern classification approach to QA is essentially language independent and trainable given appropriate language-specific training data.", "labels": [], "entities": [{"text": "statistical pattern classification", "start_pos": 5, "end_pos": 39, "type": "TASK", "confidence": 0.651173452536265}, {"text": "QA", "start_pos": 52, "end_pos": 54, "type": "TASK", "confidence": 0.9724401235580444}]}, {"text": "No assumptions about the language are made by the model except that some notion of words or space-separated tokens must exist or be introduced where it is absent.", "labels": [], "entities": []}, {"text": "Our only other requirements to build a QA system in anew target language are: a large collection of text data in the target language that can be searched for answers (e.g. the web), and a list of example questions-and-answers (q-and-a) in the target language.", "labels": [], "entities": []}, {"text": "Given these data sources the remaining components can be obtained automatically for each language.", "labels": [], "entities": []}, {"text": "So, in contrast to other contemporary approaches to QA our English language system does not use WordNet as in (), NE extraction, or any other linguistic information e.g. from semantic analysis () or from question parsing () and uses capitalised (where appropriate for the language) word tokens as the only features for mod-", "labels": [], "entities": [{"text": "WordNet", "start_pos": 96, "end_pos": 103, "type": "DATASET", "confidence": 0.9537301659584045}, {"text": "NE extraction", "start_pos": 114, "end_pos": 127, "type": "TASK", "confidence": 0.8331693112850189}, {"text": "question parsing", "start_pos": 204, "end_pos": 220, "type": "TASK", "confidence": 0.7216373682022095}]}], "datasetContent": [{"text": "A substantial amount of time has gone into investigating combinations and ranges of parameters which gave good performance on English development questions.", "labels": [], "entities": []}, {"text": "These same parameters were largely used as-is for the Japanese system with only minor optimisations performed on de-: Performance of each language-specific system in the top 1, 5, 10 and 20 answers output.", "labels": [], "entities": []}, {"text": "velopment questions disjoint from any evaluation set.", "labels": [], "entities": []}, {"text": "For the two new QA systems in Chinese and Swedish we used exactly the same parameters that had been found to work well for the English system and performed no optimisation, mainly due to alack of questions that we could hold-out for development.", "labels": [], "entities": []}, {"text": "This is clearly sub-optimal but will be addressed in future work.", "labels": [], "entities": []}, {"text": "It has been found for English and Japanese that system performance consistently increases the more documents that are used to search for an answer.", "labels": [], "entities": []}, {"text": "Experiments with English used \u00cd \ud97b\udf59 \ud97b\udf59\u00bc\u00bc documents and for Japanese \u00cd \u00bc\u00bc\u00bc documents was used.", "labels": [], "entities": [{"text": "\u00cd \ud97b\udf59 \ud97b\udf59\u00bc\u00bc", "start_pos": 30, "end_pos": 37, "type": "METRIC", "confidence": 0.858061412970225}]}, {"text": "Due to time constraints, however, for the Swedish experiments we used a maximum of \u00cd \u00bd \u00bc \u00bc documents.", "labels": [], "entities": [{"text": "\u00cd \u00bd \u00bc \u00bc documents", "start_pos": 83, "end_pos": 100, "type": "METRIC", "confidence": 0.8670973658561707}]}, {"text": "For the Chinese experiments we were forced to use a maximum of only \u00cd \u00be \u00bc documents.", "labels": [], "entities": [{"text": "\u00cd \u00be \u00bc", "start_pos": 68, "end_pos": 73, "type": "METRIC", "confidence": 0.8400423526763916}]}, {"text": "This was because the segmentation of Chinese text into individual characters resulted in a huge number of character combinations being generated in the retrieval model and due to memory limitations the only way round this problem was to limit the number of documents used.", "labels": [], "entities": []}, {"text": "In addition, for an answer to be output the number of times it had to occur in the data was set to 5 for Swedish and 2 for Chinese.", "labels": [], "entities": []}, {"text": "These values were based on the number of documents we were using and our prior experience with English and Japanese.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Performance of each language-specific system in the top 1, 5, 10 and 20 answers output.", "labels": [], "entities": []}]}