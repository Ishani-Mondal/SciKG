{"title": [{"text": "Understanding Complex Natural Language Explanations in Tutorial Applications *", "labels": [], "entities": [{"text": "Understanding Complex Natural Language Explanations", "start_pos": 0, "end_pos": 51, "type": "TASK", "confidence": 0.746959388256073}]}], "abstractContent": [{"text": "We describe the WHY2-ATLAS intelligent tutoring system for qualitative physics that interacts with students via natural language dialogue.", "labels": [], "entities": []}, {"text": "We focus on the issue of analyzing and responding to multi-sentential explanations.", "labels": [], "entities": []}, {"text": "We explore an approach that combines a statistical classi-fier, multiple semantic parsers and a formal reasoner for achieving a deeper understanding of these explanations in order to provide appropriate feedback on them.", "labels": [], "entities": []}], "introductionContent": [{"text": "Most natural language tutorial applications have focused on coaching either problem solving or procedural knowledge (e.g. Steve,),), BEETLE (),), inter alia).", "labels": [], "entities": [{"text": "problem solving or procedural knowledge", "start_pos": 76, "end_pos": 115, "type": "TASK", "confidence": 0.7877224743366241}, {"text": "BEETLE", "start_pos": 133, "end_pos": 139, "type": "METRIC", "confidence": 0.9925967454910278}]}, {"text": "When coaching problem solving, simple short answer analysis techniques are frequently sufficient because the primary goal is to lead a trainee step-by-step through problem solving.", "labels": [], "entities": [{"text": "coaching problem solving", "start_pos": 5, "end_pos": 29, "type": "TASK", "confidence": 0.7499283154805502}, {"text": "short answer analysis", "start_pos": 38, "end_pos": 59, "type": "TASK", "confidence": 0.6781327625115713}, {"text": "problem solving", "start_pos": 164, "end_pos": 179, "type": "TASK", "confidence": 0.8210311532020569}]}, {"text": "There is a narrow range of possible responses and the context of the previous dialogue and questions invite short answers.", "labels": [], "entities": []}, {"text": "But when the instructional objectives shift and a tutorial system attempts to explore a student's chain of reasoning behind an answer or decision, deeper analysis techniques can begin to payoff.", "labels": [], "entities": []}, {"text": "Having the student * This research was supported by ONR Grant No. N00014-00-1-0600 and by construct more on his own is important for learning perhaps in part because it reveals what the student does and does not understand (.", "labels": [], "entities": [{"text": "ONR Grant No. N00014-00-1-0600", "start_pos": 52, "end_pos": 82, "type": "DATASET", "confidence": 0.8175276517868042}]}, {"text": "When the student is invited to provide a longer chain of reasoning, the explanations become multisentential.", "labels": [], "entities": []}, {"text": "Compare the short explanation in to the longer ones in.", "labels": [], "entities": []}, {"text": "The explanation in is part of an actual initial student response and shows the explanation from the same student after a follow-up dialogue with the WHY2-ATLAS tutoring system.", "labels": [], "entities": [{"text": "WHY2-ATLAS tutoring system", "start_pos": 149, "end_pos": 175, "type": "DATASET", "confidence": 0.9079134464263916}]}, {"text": "Using this principle, what is the value of the horizontal component of the acceleration of the egg?", "labels": [], "entities": []}, {"text": "Student: zero because there is no horizontal force acting on the egg Figure 1: Eliciting a one sentence explanation from a student.", "labels": [], "entities": [{"text": "Eliciting a one sentence explanation from a student", "start_pos": 79, "end_pos": 130, "type": "TASK", "confidence": 0.851093590259552}]}, {"text": "WHY2-ATLAS: Suppose a man is in an elevator that is falling without anything touching it (ignore the air, too).", "labels": [], "entities": [{"text": "WHY2-ATLAS", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.7068290114402771}]}, {"text": "He holds his keys motionless right in front of his face and then just releases his grip on them.", "labels": [], "entities": []}, {"text": "What will happen to them?", "labels": [], "entities": []}, {"text": ".. Yet the gravitational pull on the man and the elevator is greater because they are of a greater weight and therefore they will fall faster then the keys.", "labels": [], "entities": []}, {"text": "I believe that the keys will float up to the cieling as the elevator continues falling.", "labels": [], "entities": []}, {"text": "The only previous tutoring system that has attempted to address longer explanations is AUTOTU-TOR ().", "labels": [], "entities": [{"text": "AUTOTU-TOR", "start_pos": 87, "end_pos": 97, "type": "DATASET", "confidence": 0.6745392084121704}]}, {"text": "It uses a latent semantic...", "labels": [], "entities": []}, {"text": "Since <Net force = mass * acceleration> and <F= mass*g> therefore <mass*acceleration= mass*g> and acceleration and gravitational force end up being equal.", "labels": [], "entities": [{"text": "F", "start_pos": 45, "end_pos": 46, "type": "METRIC", "confidence": 0.953885018825531}]}, {"text": "So mass does not effect anything in this problem and the acceleration of both the keys and the man are the same.", "labels": [], "entities": []}, {"text": "[omitted 46 correct propositions]...we can say that the keys will remain right in front of the man's face.", "labels": [], "entities": []}, {"text": "analysis (LSA) approach where the structure of sentences is not considered.", "labels": [], "entities": []}, {"text": "Thus the degree to which details of the explanation are understood is limited.", "labels": [], "entities": []}, {"text": "As can be seen from the examples, a student's explanation about a formal domain such as qualitative physics may involve a number of phenomena: algebraic formulas, NL renderings of formulas, various degrees of formality, and conveying the logical structure of an argument ).", "labels": [], "entities": []}, {"text": "Tutoring goals involve eliciting correct statements of the appropriate degree of formality and their justifications to address possible gaps and errors in the explanation.", "labels": [], "entities": []}, {"text": "To achieve these goals the NL understanding is required to answer the following questions: \u2022 Does the student explanation contain errors?", "labels": [], "entities": [{"text": "NL understanding", "start_pos": 27, "end_pos": 43, "type": "TASK", "confidence": 0.9441035985946655}]}, {"text": "If yes, what are the likely buggy assumptions that have led the student to these errors?", "labels": [], "entities": []}, {"text": "\u2022 What required statements have not been covered by the student?", "labels": [], "entities": []}, {"text": "Does the explanation contain statements that are logically close to the required statements?", "labels": [], "entities": []}, {"text": "These requirements imply that a logical structure needs to be imposed on the space of possible domain statements.", "labels": [], "entities": []}, {"text": "Considering such a structure to be a model of the student's reasoning about the domain, the two requirements correspond to a solution of a model-based diagnosis problem (Forbus and de.", "labels": [], "entities": []}, {"text": "How does one build such a model?", "labels": [], "entities": []}, {"text": "A desire to make the process scalable and feasible necessitates an automated procedure.", "labels": [], "entities": []}, {"text": "The difficulty is that this automated reasoner has to deal with the NL phenomena that are relevant for our application.", "labels": [], "entities": []}, {"text": "In turn, this means that the knowledge representation (KR) would have to be able to express these phenomena (e.g. NL renderings of formulas, various degrees of formality).", "labels": [], "entities": []}, {"text": "The reasoner has to account for common reasoning fallacies, have flexible consistency constraints and perform within the tight requirements of a real-time dialogue application.", "labels": [], "entities": []}, {"text": "In this paper, we present a hybrid of symbolic and statistical approaches that attempts to robustly provide a model-based diagnosis of a student's explanation.", "labels": [], "entities": []}, {"text": "In the next section, we provide a brief sketch of the KR used in WHY2-ATLAS.", "labels": [], "entities": [{"text": "WHY2-ATLAS", "start_pos": 65, "end_pos": 75, "type": "DATASET", "confidence": 0.9304692149162292}]}, {"text": "Section 3 describes our hybrid approach for analyzing student explanations while section 4 covers our most recent evaluations of the system and its explanation analysis components.", "labels": [], "entities": []}, {"text": "Section 5 presents our conclusions along with future directions.", "labels": [], "entities": []}], "datasetContent": [{"text": "WHY2-ATLAS, as we've just described it, has been fully implemented and was evaluated in the context of testing the hypothesis that even when content is equivalent, students who engage in more interactive forms of instruction learn more.", "labels": [], "entities": [{"text": "WHY2-ATLAS", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.9484301805496216}]}, {"text": "To test this hypothesis we compared students who received human tutoring with students who read a short text.", "labels": [], "entities": []}, {"text": "WHY2-ATLAS and WHY2-AUTOTUTOR provided a third type of condition that served as an interactive form of instruction where the content is better controlled than with human tutoring in that only some subset of the content covered in the text condition can be presented.", "labels": [], "entities": [{"text": "WHY2-ATLAS", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.9832656383514404}, {"text": "WHY2-AUTOTUTOR", "start_pos": 15, "end_pos": 29, "type": "DATASET", "confidence": 0.9507068991661072}]}, {"text": "In all conditions the students had to solve four problems that require multi-sentential explanations, one of which is shown in.", "labels": [], "entities": []}, {"text": "In earlier evaluations, we found that overall students learn and learn equally well in all three types of conditions when the content is appropriate to the level of the student ( ), i.e. the learning gains for human tutoring and the content controlled text were the same.", "labels": [], "entities": []}, {"text": "For the latest evaluation of WHY2-ATLAS, which excluded a human tutoring condition, the learning gains on multiplechoice and essay post-tests were the same as for the other conditions.", "labels": [], "entities": [{"text": "WHY2-ATLAS", "start_pos": 29, "end_pos": 39, "type": "DATASET", "confidence": 0.8569133281707764}]}, {"text": "However, on fill-in-the-blank post-tests, the WHY2-ATLAS students scored higher than the text students (p=0.010; F(1,74)=6.33), and this advantage persisted when the scores were adjusted by factoring out pre-test scores in an AN-COVA (p=0.018; F(1,72)=5.83).", "labels": [], "entities": [{"text": "WHY2-ATLAS students", "start_pos": 46, "end_pos": 65, "type": "DATASET", "confidence": 0.9455727338790894}, {"text": "F", "start_pos": 113, "end_pos": 114, "type": "METRIC", "confidence": 0.9708084464073181}, {"text": "AN-COVA", "start_pos": 226, "end_pos": 233, "type": "METRIC", "confidence": 0.8852726221084595}, {"text": "F", "start_pos": 244, "end_pos": 245, "type": "METRIC", "confidence": 0.9622064232826233}]}, {"text": "Although this difference was in the expected direction, it was not accompanied by similar differences for the other two post-tests.", "labels": [], "entities": []}, {"text": "These learning measures show that, relative to the 21 text, the two systems' overall performance at selecting content is good.", "labels": [], "entities": []}, {"text": "A system could perform worse than the text condition if it too frequently misinterprets multi-sentential answers and skips material covered in the text that a student may need.", "labels": [], "entities": []}, {"text": "But since the dialogue strategies in the two systems are different and selected relative to the understanding techniques used, we next need to do a detailed corpus analysis of the language data collected to track successes and failures of understanding and dialogue strategy selection relative to knowledge components in the post-test.", "labels": [], "entities": []}, {"text": "Next we will describe some component-level evaluations that focus on the parts of the system we just described.", "labels": [], "entities": []}, {"text": "The component-level evaluation for completeness and correctness was completed after the student learning evaluation.", "labels": [], "entities": []}, {"text": "It focuses on the performance of just the direct matching procedure.", "labels": [], "entities": []}, {"text": "shows the results of classifying 62 student utterances for one physics problem with respect to 46 stored statement representations using only direct matching.", "labels": [], "entities": []}, {"text": "To generate these results, the data is manually divided into 7 groups based on the quality of the NL to FOPL conversion, such that group 7 consists only of perfectly formalized entries, and for 1 \u2264 n \u2264 6 group n includes entries of group n+1 and additionally entries of somewhat lesser representation quality, so that group 1 includes all the entries of the data set.", "labels": [], "entities": []}, {"text": "The flexibility of the direct matching algorithm even allows classification of utterances that have mediocre representations, resulting in 70% average recall and 82.9% average precision for 56.5% of all entries (group 4).", "labels": [], "entities": [{"text": "recall", "start_pos": 151, "end_pos": 157, "type": "METRIC", "confidence": 0.9647684693336487}, {"text": "precision", "start_pos": 176, "end_pos": 185, "type": "METRIC", "confidence": 0.9398818612098694}]}, {"text": "However, large numbers of inadequately represented utterances (38.7% of all entries did not make it into group 3 of the data set) result in 53.2% average recall and 59.7% average precision for the whole data set (group 1).", "labels": [], "entities": [{"text": "recall", "start_pos": 154, "end_pos": 160, "type": "METRIC", "confidence": 0.9732226729393005}, {"text": "precision", "start_pos": 179, "end_pos": 188, "type": "METRIC", "confidence": 0.985375702381134}]}, {"text": "These results are still significantly better compared to the two baseline classifiers the best of which peaks at 22.2% average recall and precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 127, "end_pos": 133, "type": "METRIC", "confidence": 0.9833104610443115}, {"text": "precision", "start_pos": 138, "end_pos": 147, "type": "METRIC", "confidence": 0.8954600691795349}]}, {"text": "The first baseline classifier always assigns the single label that is dominant in the training set (average number of labels per entry of the training set is 1.36).", "labels": [], "entities": []}, {"text": "The second baseline classifier independently and randomly picks labels according to their distributions in the training set.", "labels": [], "entities": []}, {"text": "The most frequent label in the training set corresponds to the answer to the problem.", "labels": [], "entities": []}, {"text": "Since in the test set the answer always appears as a separate utterance (sentence), recall and precision rates for the first baseline classifier are the same.", "labels": [], "entities": [{"text": "recall", "start_pos": 84, "end_pos": 90, "type": "METRIC", "confidence": 0.9996204376220703}, {"text": "precision", "start_pos": 95, "end_pos": 104, "type": "METRIC", "confidence": 0.9990195035934448}]}, {"text": "Although the current evaluation did not involve matching against the ATMS, we did evaluate the time required for such a match in order to make a rough comparison with our earlier approach.", "labels": [], "entities": [{"text": "ATMS", "start_pos": 69, "end_pos": 73, "type": "DATASET", "confidence": 0.8612200617790222}]}, {"text": "Matching a 12 atom input representation against a 128 node ATMS that covers 55% of relevant problem facts takes around 30 seconds, which is a considerable improvement over the 170 seconds required for the on-the-fly analysis performed by the Tacituslite+ abductive reasoner ( )-the technique used in the previous version of WHY2-ATLAS.", "labels": [], "entities": [{"text": "WHY2-ATLAS", "start_pos": 324, "end_pos": 334, "type": "DATASET", "confidence": 0.937926173210144}]}, {"text": "The matching is done by aversion of a largest common subgraph-based graph-matching algorithm (due to the need to account for crossreferencing atoms via shared variables) proposed in (, that has a time complexity O(2 n n 3 ), where n is the size of an input graph.", "labels": [], "entities": []}, {"text": "The efficiency can be further improved by using an approximation of the largest common subgraph in order to evaluate the match.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance of NL to FOPL for actions  taken in WHY2-ATLAS system.", "labels": [], "entities": [{"text": "FOPL", "start_pos": 31, "end_pos": 35, "type": "METRIC", "confidence": 0.9960493445396423}, {"text": "WHY2-ATLAS", "start_pos": 58, "end_pos": 68, "type": "DATASET", "confidence": 0.8654532432556152}]}]}