{"title": [{"text": "Semantic Role Recognition using Kernels on Weighted Marked Ordered Labeled Trees", "labels": [], "entities": [{"text": "Semantic Role Recognition", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.796435534954071}]}], "abstractContent": [{"text": "We present a method for recognizing semantic role arguments using a kernel on weighted marked ordered labeled trees (the WMOLT kernel).", "labels": [], "entities": [{"text": "WMOLT kernel", "start_pos": 121, "end_pos": 133, "type": "DATASET", "confidence": 0.8157595992088318}]}, {"text": "We extend the kernels on marked ordered labeled trees (Kazama and Torisawa, 2005) so that the mark can be weighted according to its importance.", "labels": [], "entities": []}, {"text": "We improve the accuracy by giving more weights on subtrees that contain the predicate and the argument nodes with this ability.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.999498724937439}]}, {"text": "Although Kazama and Torisawa (2005) presented fast training with tree kernels, the slow classification during runtime remained to be solved.", "labels": [], "entities": []}, {"text": "In this paper, we give a solution that uses an efficient DP updating procedure applicable in argument recognition.", "labels": [], "entities": [{"text": "argument recognition", "start_pos": 93, "end_pos": 113, "type": "TASK", "confidence": 0.8695759177207947}]}, {"text": "We demonstrate that the WMOLT kernel improves the accuracy, and our speed-up method makes the recognition more than 40 times faster than the naive classification.", "labels": [], "entities": [{"text": "WMOLT kernel", "start_pos": 24, "end_pos": 36, "type": "DATASET", "confidence": 0.6964632868766785}, {"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9994423985481262}]}], "introductionContent": [{"text": "Semantic role labeling (SRL) is a task that recognizes the arguments of a predicate (verb) in a sentence and assigns the correct role to each argument.", "labels": [], "entities": [{"text": "Semantic role labeling (SRL)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8471161822477976}]}, {"text": "As this task is recognized as an important step after (or the last step of) syntactic analysis, many studies have been conducted to achieve accurate semantic role labeling ().", "labels": [], "entities": [{"text": "syntactic analysis", "start_pos": 76, "end_pos": 94, "type": "TASK", "confidence": 0.7703844308853149}, {"text": "semantic role labeling", "start_pos": 149, "end_pos": 171, "type": "TASK", "confidence": 0.5970029632250468}]}, {"text": "Most of the studies have focused on machine learning because of the availability of standard datasets, such as PropBank ().", "labels": [], "entities": [{"text": "PropBank", "start_pos": 111, "end_pos": 119, "type": "DATASET", "confidence": 0.9528365135192871}]}, {"text": "Naturally, the usefulness of parse trees in this task can be anticipated.", "labels": [], "entities": []}, {"text": "For example, the recent CoNLL 2005 shared task) provided parse trees for use and their usefulness was ensured.", "labels": [], "entities": [{"text": "CoNLL 2005 shared task", "start_pos": 24, "end_pos": 46, "type": "DATASET", "confidence": 0.9015384316444397}]}, {"text": "Most of the methods heuristically extract features from parse trees, and from other sources, and use them in machine learning methods based on feature vector representation.", "labels": [], "entities": []}, {"text": "As a result, these methods depend on feature engineering, which is time-consuming.", "labels": [], "entities": [{"text": "feature engineering", "start_pos": 37, "end_pos": 56, "type": "TASK", "confidence": 0.7935729920864105}]}, {"text": "Tree kernels) have been proposed to directly handle trees in kernel-based methods, such as SVMs.", "labels": [], "entities": []}, {"text": "Tree kernels calculate the similarity between trees, taking into consideration all of the subtrees, and, therefore there is no need for such feature engineering.", "labels": [], "entities": []}, {"text": "extensively studied tree kernels for semantic role labeling.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 37, "end_pos": 59, "type": "TASK", "confidence": 0.7564233144124349}]}, {"text": "However, they reported that they could not successfully build an accurate argument recognizer, although the role assignment was improved.", "labels": [], "entities": [{"text": "argument recognizer", "start_pos": 74, "end_pos": 93, "type": "TASK", "confidence": 0.7465533912181854}]}, {"text": "Although reported on argument recognition using tree kernels, it was a preliminary evaluation because they used oracle parse trees.", "labels": [], "entities": [{"text": "argument recognition", "start_pos": 21, "end_pos": 41, "type": "TASK", "confidence": 0.820523202419281}]}, {"text": "proposed anew tree kernel for node relation labeling, as which SRL can be cast.", "labels": [], "entities": [{"text": "node relation labeling", "start_pos": 30, "end_pos": 52, "type": "TASK", "confidence": 0.6596645812193552}]}, {"text": "This kernel is defined on marked ordered labeled trees, where anode can have a mark to indicate the existence of a relation.", "labels": [], "entities": []}, {"text": "We refer to this kernel as the MOLT kernel.", "labels": [], "entities": [{"text": "MOLT kernel", "start_pos": 31, "end_pos": 42, "type": "DATASET", "confidence": 0.8122379183769226}]}, {"text": "Compared to () where tree fragments are heuristically extracted before applying tree kernels, the MOLT kernel is general and desirable since it does not require such fragment extraction.", "labels": [], "entities": []}, {"text": "However, the evaluation conducted by was limited to preliminary experiments for role assignment.", "labels": [], "entities": [{"text": "role assignment", "start_pos": 80, "end_pos": 95, "type": "TASK", "confidence": 0.8758086562156677}]}, {"text": "In this study, we first evaluated the performance of the MOLT kernel for argument recognition, and found that the MOLT kernel cannot achieve a high accuracy if used in its original form.", "labels": [], "entities": [{"text": "argument recognition", "start_pos": 73, "end_pos": 93, "type": "TASK", "confidence": 0.843354344367981}, {"text": "accuracy", "start_pos": 148, "end_pos": 156, "type": "METRIC", "confidence": 0.9913378953933716}]}, {"text": "Therefore, in this paper we propose a modification of the MOLT kernel, which greatly improves the accuracy.", "labels": [], "entities": [{"text": "MOLT kernel", "start_pos": 58, "end_pos": 69, "type": "DATASET", "confidence": 0.7305279672145844}, {"text": "accuracy", "start_pos": 98, "end_pos": 106, "type": "METRIC", "confidence": 0.9985231757164001}]}, {"text": "The problem with the original MOLT kernel is that it treats subtrees with one mark, i.e., those including only the argument or the predicate node, and subtrees with two marks, i.e., those including both the argument and the predicate nodes equally, although the latter is likely to be more important for distinguishing difficult arguments.", "labels": [], "entities": []}, {"text": "Thus, we modified the MOLT kernel so that the marks can be weighted in order to give large weights to the subtrees with many marks.", "labels": [], "entities": [{"text": "MOLT kernel", "start_pos": 22, "end_pos": 33, "type": "DATASET", "confidence": 0.6949863582849503}]}, {"text": "We call the modified kernel the WMOLT kernel (the kernel on weighted marked ordered labeled trees).", "labels": [], "entities": []}, {"text": "We show that this modification greatly improves the accuracy when the weights for marks are properly tuned.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9994762539863586}]}, {"text": "One of the issues that arises when using tree kernels is time complexity.", "labels": [], "entities": []}, {"text": "In general, tree kernels can be calculated in O(|T 1 ||T 2 |) time, where |T i | is the number of nodes in tree Ti , using dynamic programming (DP) procedures).", "labels": [], "entities": [{"text": "O", "start_pos": 46, "end_pos": 47, "type": "METRIC", "confidence": 0.9665324091911316}]}, {"text": "However, this cost is not negligible in practice.", "labels": [], "entities": []}, {"text": "proposed a method that drastically speeds up the calculation during training by converting trees into efficient vectors using a tree mining algorithm.", "labels": [], "entities": []}, {"text": "However, the slow classification during runtime remained an open problem.", "labels": [], "entities": []}, {"text": "We propose a method for speeding up the runtime classification for argument recognition.", "labels": [], "entities": [{"text": "argument recognition", "start_pos": 67, "end_pos": 87, "type": "TASK", "confidence": 0.8198325335979462}]}, {"text": "In argument recognition, we determine whether anode is an argument or not for all the nodes in a tree . This requires a series of calculations between a support vector tree and a tree with slightly different marking.", "labels": [], "entities": [{"text": "argument recognition", "start_pos": 3, "end_pos": 23, "type": "TASK", "confidence": 0.7883527278900146}]}, {"text": "By exploiting this property, we can efficiently update DP cells to obtain the kernel value with less computational cost.", "labels": [], "entities": []}, {"text": "In the experiments, we demonstrated that the WMOLT kernel drastically improved the accuracy and that our speed-up method enabled more than 40 times faster argument recognition.", "labels": [], "entities": [{"text": "WMOLT kernel", "start_pos": 45, "end_pos": 57, "type": "DATASET", "confidence": 0.7063186764717102}, {"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.9994606375694275}, {"text": "argument recognition", "start_pos": 155, "end_pos": 175, "type": "TASK", "confidence": 0.7863690257072449}]}, {"text": "Despite these successes, the performance of our current system is F 1 = 78.22 on the CoNLL 2005 evaluation set when using the Charniak parse trees, which is far worse than the state-of-the-art system.", "labels": [], "entities": [{"text": "F 1", "start_pos": 66, "end_pos": 69, "type": "METRIC", "confidence": 0.9813570380210876}, {"text": "CoNLL 2005 evaluation set", "start_pos": 85, "end_pos": 110, "type": "DATASET", "confidence": 0.9515817910432816}, {"text": "Charniak parse trees", "start_pos": 126, "end_pos": 146, "type": "DATASET", "confidence": 0.6719885468482971}]}, {"text": "We will present possible reasons and future directions.", "labels": [], "entities": []}], "datasetContent": [{"text": "To compare the performance of our system with other systems, we conducted the evaluation on the official evaluation set of the CoNLL 2005 shared task.", "labels": [], "entities": [{"text": "official evaluation set of the CoNLL 2005 shared task", "start_pos": 96, "end_pos": 149, "type": "DATASET", "confidence": 0.8240324854850769}]}, {"text": "We used a model trained using 2,000 sentences (57,547 examples) with (\u03b3 = 4, 000, \u03bb = 0.2, C = 12.04), the best setting in the previous experiments.", "labels": [], "entities": []}, {"text": "This is the largest model we have successfully trained so far, and has F 1 = 88.00 on the test set in the previous experiments.", "labels": [], "entities": [{"text": "F 1", "start_pos": 71, "end_pos": 74, "type": "METRIC", "confidence": 0.9940484762191772}]}, {"text": "The accuracy of this model on the official evaluation set was F 1 = 79.96 using the criterion from the previous experiments where we treated a C-k argument as an independent argument.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9997716546058655}, {"text": "F 1", "start_pos": 62, "end_pos": 65, "type": "METRIC", "confidence": 0.9872571229934692}]}, {"text": "The official evaluation script returned F 1 = 78.22.", "labels": [], "entities": [{"text": "F 1", "start_pos": 40, "end_pos": 43, "type": "METRIC", "confidence": 0.9941100776195526}]}, {"text": "This difference is caused because the official script takes C-k arguments into consideration, while our system cannot output C-k labels since it is just an argument recognizer.", "labels": [], "entities": []}, {"text": "Therefore, the performance will become slightly higher than F 1 = 78.22 if we perform the role assignment step.", "labels": [], "entities": [{"text": "F 1", "start_pos": 60, "end_pos": 63, "type": "METRIC", "confidence": 0.9929177165031433}, {"text": "role assignment", "start_pos": 90, "end_pos": 105, "type": "TASK", "confidence": 0.8304485082626343}]}, {"text": "However, our current system is worse than the systems reported in the CoNLL 2005 shared task in any case, since it is reported that they had F 1 = 79.92 to 83.78 argument recognition accuracy).", "labels": [], "entities": [{"text": "CoNLL 2005 shared task", "start_pos": 70, "end_pos": 92, "type": "DATASET", "confidence": 0.9096763879060745}, {"text": "F 1", "start_pos": 141, "end_pos": 144, "type": "METRIC", "confidence": 0.9905072450637817}, {"text": "argument recognition", "start_pos": 162, "end_pos": 182, "type": "TASK", "confidence": 0.63199083507061}, {"text": "accuracy", "start_pos": 183, "end_pos": 191, "type": "METRIC", "confidence": 0.7381818890571594}]}], "tableCaptions": [{"text": " Table 3: Effect of \u03b3 in mark weighting of WMOLT kernel.", "labels": [], "entities": [{"text": "WMOLT kernel", "start_pos": 43, "end_pos": 55, "type": "DATASET", "confidence": 0.8774325251579285}]}, {"text": " Table 4: Recognition time (sec.) with naive classifi- cation and proposed fast update.  training size (No. of sentences)  250  500  750  1,000  naive  11,266 13,008 18,313 30,226  proposed  226  310  442  731  speed-up  49.84  41.96  41.43  41.34", "labels": [], "entities": [{"text": "Recognition time", "start_pos": 10, "end_pos": 26, "type": "METRIC", "confidence": 0.8900459110736847}, {"text": "speed-up", "start_pos": 211, "end_pos": 219, "type": "METRIC", "confidence": 0.9721063375473022}]}]}