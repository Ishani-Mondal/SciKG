{"title": [{"text": "A Study of Two Graph Algorithms in Topic-driven Summarization", "labels": [], "entities": [{"text": "Topic-driven Summarization", "start_pos": 35, "end_pos": 61, "type": "TASK", "confidence": 0.7481456398963928}]}], "abstractContent": [{"text": "We study how two graph algorithms apply to topic-driven summarization in the scope of Document Understanding Conferences.", "labels": [], "entities": [{"text": "Document Understanding Conferences", "start_pos": 86, "end_pos": 120, "type": "TASK", "confidence": 0.7781813144683838}]}, {"text": "The DUC 2005 and 2006 tasks were to summarize into 250 words a collection of documents on a topic consisting of a few statements or questions.", "labels": [], "entities": [{"text": "DUC 2005", "start_pos": 4, "end_pos": 12, "type": "DATASET", "confidence": 0.8810865879058838}, {"text": "summarize into 250 words a collection of documents on a topic consisting of a few statements or questions", "start_pos": 36, "end_pos": 141, "type": "Description", "confidence": 0.7427342020803027}]}, {"text": "Our algorithms select sentences for extraction.", "labels": [], "entities": []}, {"text": "We measure their performance on the DUC 2005 test data, using the Summary Content Units made available after the challenge.", "labels": [], "entities": [{"text": "DUC 2005 test data", "start_pos": 36, "end_pos": 54, "type": "DATASET", "confidence": 0.9875081181526184}, {"text": "Summary", "start_pos": 66, "end_pos": 73, "type": "METRIC", "confidence": 0.8936529755592346}]}, {"text": "One algorithm matches a graph representing the entire topic against each sentence in the collection.", "labels": [], "entities": []}, {"text": "The other algorithm checks, for pairs of open-class words in the topic, whether they can be connected in the syntactic graph of each sentence.", "labels": [], "entities": []}, {"text": "Matching performs better than connecting words, but a combination of both methods works best.", "labels": [], "entities": [{"text": "Matching", "start_pos": 0, "end_pos": 8, "type": "TASK", "confidence": 0.7766332030296326}]}, {"text": "They also both favour longer sentences, which makes summaries more fluent.", "labels": [], "entities": [{"text": "summaries", "start_pos": 52, "end_pos": 61, "type": "TASK", "confidence": 0.9614067077636719}]}], "introductionContent": [{"text": "The DUC 2005 and 2006 summarization challenges were motivated by the desire to make summarization relevant to real users.", "labels": [], "entities": [{"text": "DUC 2005", "start_pos": 4, "end_pos": 12, "type": "DATASET", "confidence": 0.9230858385562897}, {"text": "summarization", "start_pos": 22, "end_pos": 35, "type": "TASK", "confidence": 0.7070682048797607}, {"text": "summarization", "start_pos": 84, "end_pos": 97, "type": "TASK", "confidence": 0.9852805733680725}]}, {"text": "The task was focussed by specifying an information need as a topic: one or a few statements or questions).", "labels": [], "entities": []}, {"text": "Systems usually employ such data as a source of key words or phrases which then help rank document sentences by relevance to the topic.", "labels": [], "entities": []}, {"text": "We explore other information that can be extracted from a topic description.", "labels": [], "entities": []}, {"text": "In particular, we look at connections between open-class words.", "labels": [], "entities": []}, {"text": "A dependency parser, MiniPar, builds a dependency relation graph for each sentence.", "labels": [], "entities": []}, {"text": "We apply such graphs in two ways.", "labels": [], "entities": []}, {"text": "We match a graph that covers the entire topic description against the graph for each sentence in the collection.", "labels": [], "entities": []}, {"text": "We also extract all pairs of open-class words from the topic description, and check whether they are connected in the sentence graphs.", "labels": [], "entities": []}, {"text": "Both methods let us rank sentences; the top-ranking ones go into a summary of at most 250 words.", "labels": [], "entities": []}, {"text": "We evaluate the summaries with the summary content units (SCU) data made available after).", "labels": [], "entities": []}, {"text": "The experiments show that using more information than just keywords leads to summaries with more SCUs (total and unique) and higher SCU weight.", "labels": [], "entities": []}, {"text": "We present related work in section 2, and the data and the representation we work within section 3.", "labels": [], "entities": []}, {"text": "Section 4 shows the algorithms in more detail.", "labels": [], "entities": []}, {"text": "We describe the experiments and their results in section 5, and draw a few conclusions in section 6.,, Mihalcea and Tarau (2004) introduced graph methods for summarization, word sense disambiguation and other NLP applications.", "labels": [], "entities": [{"text": "summarization", "start_pos": 158, "end_pos": 171, "type": "TASK", "confidence": 0.9876652956008911}, {"text": "word sense disambiguation", "start_pos": 173, "end_pos": 198, "type": "TASK", "confidence": 0.6839901010195414}]}], "datasetContent": [{"text": "We produce a summary for each topic and each experimental configuration.", "labels": [], "entities": []}, {"text": "We take the most highly ranked (complete) sentences for which the total number of words does not exceed the 250-word limit.", "labels": [], "entities": []}, {"text": "Next, we gather SCU data for each sentence in each summary from the SCU information files.", "labels": [], "entities": [{"text": "SCU information files", "start_pos": 68, "end_pos": 89, "type": "DATASET", "confidence": 0.8362944523493449}]}, {"text": "For a specific experimental configuration -topic representation, graph algorithm -we produce summaries for the 20 documents with the weight factor values 0, 1, 2, ..., 15, 20, 50, 100.", "labels": [], "entities": []}, {"text": "Each experimental configuration generates  We compare the performance of the two algorithms, GM and PS, on the two topic representations -with all open-class words and only with nouns and verbs.", "labels": [], "entities": []}, {"text": "shows the performance of the methods in terms of average SCU weights per summary for each weight factor considered 1 . The results allow us to make several observations.", "labels": [], "entities": []}, {"text": "\u2022 Keyword-only match performs worse that either GM or PS.", "labels": [], "entities": []}, {"text": "The points corresponding to keyword (node) match only are the points for which the weight factor is 0.", "labels": [], "entities": []}, {"text": "In this case the dependency pairs match and paths found in the graph do not contribute to the overall score.", "labels": [], "entities": []}, {"text": "\u2022 Both graph algorithms achieve better performance for only the nouns and verbs from the 1 The summary statistics level off above a certain weight factor, so we include only the non-flat part of the graph.", "labels": [], "entities": []}, {"text": "topic than for all open-class words.", "labels": [], "entities": []}, {"text": "If, however, the topic requests entities or events with specific properties, described by adjectives or adverbs, using only nouns and verbs may produce worse results.", "labels": [], "entities": []}, {"text": "\u2022 GM performs better than PS for both types of topic descriptions.", "labels": [], "entities": [{"text": "GM", "start_pos": 2, "end_pos": 4, "type": "METRIC", "confidence": 0.9446651935577393}]}, {"text": "In other words, looking at the same words that appear in the topic, connected in the same way, leads to better results than finding pairs of words that are \"somehow\" connected.", "labels": [], "entities": []}, {"text": "\u2022 Higher performance for higher weight factors further supports the point that looking for word connections, instead of isolated words, helps find sentences with information content more related to the topic.", "labels": [], "entities": []}, {"text": "For the following set of experiments, we use the topics with the word list containing only nouns and verbs.", "labels": [], "entities": []}, {"text": "We want to compare graph matching and path search further.", "labels": [], "entities": [{"text": "graph matching", "start_pos": 19, "end_pos": 33, "type": "TASK", "confidence": 0.716758981347084}]}, {"text": "One issue that comes to mind is whether a combination of the two methods will perform better than each of them individually.", "labels": [], "entities": []}, {"text": "plots the average of SCU weights per summary.", "labels": [], "entities": []}, {"text": "We observe that the combination of graph matching and path search gives better results than either method alone.", "labels": [], "entities": [{"text": "graph matching", "start_pos": 35, "end_pos": 49, "type": "TASK", "confidence": 0.7475016713142395}]}, {"text": "The sentence score combines the number of edges matched and the number of connections found with equal weight factors for the edge match and path score.", "labels": [], "entities": []}, {"text": "This raises the question whether different weights for the edge match and path would lead to better scores.", "labels": [], "entities": []}, {"text": "plots the results produced using the score computation formula S = S N + W eightF actor E * SE + W eightF actor P * S P , where both W eightF actor E and W eightF actor P are integers from 0 to 30.", "labels": [], "entities": []}, {"text": "The lowest scores are for the weight factors 0, when sentence score depends only on the keyword score.", "labels": [], "entities": []}, {"text": "There is an increase in average SCU weights  towards higher values of weight factors.", "labels": [], "entities": []}, {"text": "A transparent view of the 3D graph shows that graph match has higher peaks toward higher weight factors than path search, and higher also than the situation when path search and graph match have equal weights.", "labels": [], "entities": []}, {"text": "The only sentences in the given documents tagged with SCU information are those which appeared in the summaries generated by the competing teams in 2005.", "labels": [], "entities": []}, {"text": "Our results are therefore actually a lower bound -more of the sentences selected may include relevant information.", "labels": [], "entities": []}, {"text": "A manual analysis of the summaries generated using only keyword counts showed that, for these summaries, the sentences not containing SCUs were not informative.", "labels": [], "entities": []}, {"text": "We cannot check this for all the summaries generated in these experiments, because the number is very large, above 1000.", "labels": [], "entities": []}, {"text": "An average summary had 8.24 sentences, with 3.19 sentences containing SCUs.", "labels": [], "entities": []}, {"text": "We cannot say much about the sentences that do not contain SCUs.", "labels": [], "entities": []}, {"text": "This may raise doubts about our results.", "labels": [], "entities": []}, {"text": "Support for the fact that the results reflect areal increase in performance comes from the weights of the SCUs added: the average SCU weight increases from 2.5 when keywords are used to 2.75 for path search algorithm, and 2.91 for graph match and the combination of path search and graph match.", "labels": [], "entities": []}, {"text": "This shows that by increasing the weight of graph edges and paths in the scoring of a sentence, the algorithm can pick more and better SCUs, SCUs which more people see as relevant to the topic.", "labels": [], "entities": []}, {"text": "It would be certainly interesting to have away of assessing the \"SCU-less\" sentences in the summary.", "labels": [], "entities": []}, {"text": "We leave that for future work, and possibly future developments in SCU annotation.", "labels": [], "entities": [{"text": "SCU annotation", "start_pos": 67, "end_pos": 81, "type": "TASK", "confidence": 0.5364985167980194}]}], "tableCaptions": []}