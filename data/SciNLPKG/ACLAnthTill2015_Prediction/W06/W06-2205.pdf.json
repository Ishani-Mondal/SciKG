{"title": [{"text": "Recognition of synonyms by a lexical graph", "labels": [], "entities": [{"text": "Recognition of synonyms", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.9234280387560526}]}], "abstractContent": [{"text": "Semantic relationships between words comprised by thesauri are essential features for IR, text mining and information extraction systems.", "labels": [], "entities": [{"text": "IR", "start_pos": 86, "end_pos": 88, "type": "TASK", "confidence": 0.9926252961158752}, {"text": "text mining", "start_pos": 90, "end_pos": 101, "type": "TASK", "confidence": 0.8001363277435303}, {"text": "information extraction", "start_pos": 106, "end_pos": 128, "type": "TASK", "confidence": 0.8177475929260254}]}, {"text": "This paper introduces anew approach to identification of semantic relations such as syn-onymy by a lexical graph.", "labels": [], "entities": [{"text": "identification of semantic relations", "start_pos": 39, "end_pos": 75, "type": "TASK", "confidence": 0.8141491562128067}]}, {"text": "The graph is generated from a text corpus by embedding syntactically parsed sentences in the graph structure.", "labels": [], "entities": []}, {"text": "The vertices of the graph are lexical items (words), their connection follows the syntactic structure of a sentence.", "labels": [], "entities": []}, {"text": "The structure of the graph and distances between vertices can be utilized to define metrics for identification of semantic relations.", "labels": [], "entities": []}, {"text": "The approach has been evaluated on a test set of 200 German synonym sets.", "labels": [], "entities": []}, {"text": "Influence of size of the text corpus, word generality and frequency has been investigated.", "labels": [], "entities": [{"text": "word generality", "start_pos": 38, "end_pos": 53, "type": "TASK", "confidence": 0.7185179889202118}]}, {"text": "Conducted experiments for synonyms demonstrate that the presented methods can be extended to other semantic relations.", "labels": [], "entities": []}], "introductionContent": [{"text": "Once predominantly used by human authors to improve their style avoiding repetitions of words or phrases, thesauri now serve as an important source of semantic and lexical information for automatic text processing.", "labels": [], "entities": [{"text": "automatic text processing", "start_pos": 188, "end_pos": 213, "type": "TASK", "confidence": 0.6505780319372813}]}, {"text": "The electronic online thesauri such as and have been increasingly employed for many IR and NLP problems.", "labels": [], "entities": [{"text": "IR", "start_pos": 84, "end_pos": 86, "type": "TASK", "confidence": 0.9689600467681885}]}, {"text": "However, considerable human effort is required to keep up with the evolving language and many subdomains are not sufficiently covered).", "labels": [], "entities": []}, {"text": "Many domainspecific words or word senses are not included; inconsistency and bias are often cited as further major deficiencies of hand-made thesauri),.", "labels": [], "entities": []}, {"text": "There is a continuous demand for automatic identification of semantic relations and thesaurus generation.", "labels": [], "entities": [{"text": "automatic identification of semantic relations", "start_pos": 33, "end_pos": 79, "type": "TASK", "confidence": 0.6533460319042206}, {"text": "thesaurus generation", "start_pos": 84, "end_pos": 104, "type": "TASK", "confidence": 0.7476682960987091}]}, {"text": "Such tools do not only produce thesauri that are more adapted to a particular application in a certain domain, but provide also assistance for lexicographers in manual creation and keeping the hand-written thesauri up to date.", "labels": [], "entities": []}, {"text": "Numerous applications in IR (e.g. query expansion) and text mining (identification of relevant content by patterns) underline their usefulness.", "labels": [], "entities": [{"text": "IR", "start_pos": 25, "end_pos": 27, "type": "TASK", "confidence": 0.9882991313934326}, {"text": "query expansion)", "start_pos": 34, "end_pos": 50, "type": "TASK", "confidence": 0.7720852593580881}, {"text": "text mining", "start_pos": 55, "end_pos": 66, "type": "TASK", "confidence": 0.8096479177474976}]}], "datasetContent": [{"text": "For evaluation purposes a test corpus of 200 synonym sets was prepared consulting).", "labels": [], "entities": []}, {"text": "The corpus consists of 75 everyday words (e.g. \"Pr\u00e4sident\" (president), \"Eingang\" (entrance) \"Gruppe\" (group)), 60 abstract terms (e.g. \"Ursache\" (reason), \"Element\", \"Merkmal\" (feature)) and 65 domain-specific words (e.g. \"Software\", \"Prozessor\" (CPU)).", "labels": [], "entities": []}, {"text": "The evaluation strategy is similar to that pursued in).", "labels": [], "entities": []}, {"text": "The similarity metrics do not distinguish between different word senses returning synonyms of all senses of the polysemous words in a single ranked list.", "labels": [], "entities": []}, {"text": "Therefore the synonym set of a word in the test corpus is the union of synonym sets of its senses.", "labels": [], "entities": []}, {"text": "To provide a measure for overall performance and to compare the different metrics a function measuring the similarity score (SimS) was defined that assigns a score to a metric for correctly found synonyms among the 25 topranked.", "labels": [], "entities": [{"text": "similarity score (SimS)", "start_pos": 107, "end_pos": 130, "type": "METRIC", "confidence": 0.9405396461486817}]}, {"text": "The function assigns 25 points to the correctly found top-ranked synonym of vi (SimS(0, vi ) = 25) and 1 point to the synonym with the 25 th rank (SimS(25, vi ) = 1).", "labels": [], "entities": []}, {"text": "The rank of a synonym is decreased only by false positives that are ranked higher (i.e. each of correctly identified top n synonyms has rank 0).", "labels": [], "entities": []}, {"text": "In order to reward the top-ranked synonyms stronger the scoring function features a hyperbolic descent.", "labels": [], "entities": []}, {"text": "For a synonym of vi with the rank x: To compare performance of different metrics the SimS values of the top 25 words in the ranked list were summed for each word of a test corpus.", "labels": [], "entities": []}, {"text": "The total score of a similarity metric Sim is j=1 SimS(rank), vi ) where RankedList(v i , j) returns the word at the position j from the ranked list produced by Sim for vi and v 1 , . .", "labels": [], "entities": []}, {"text": ", v 200 are the words of the test corpus.", "labels": [], "entities": []}, {"text": "Besides, a combined precision and recall measure \u03a0 was used to evaluate the ranked lists.", "labels": [], "entities": [{"text": "precision", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.999480664730072}, {"text": "recall measure \u03a0", "start_pos": 34, "end_pos": 50, "type": "METRIC", "confidence": 0.9294159213701884}]}, {"text": "Given the word vi , we examined the first n words (n = 1, 5, 25, 100) of the ranked list returned by a similarity metric for vi whether they belong to the synset(v i ) of the test corpus.", "labels": [], "entities": []}, {"text": "\u03a0(n) will measure precision if n is less than the size of the synset(v i ) because the maximum recall cannot be reached for such n and recall otherwise because maximum precision cannot be reached for n > |synset(v i )|.", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9936373233795166}, {"text": "recall", "start_pos": 95, "end_pos": 101, "type": "METRIC", "confidence": 0.9965001344680786}, {"text": "recall", "start_pos": 135, "end_pos": 141, "type": "METRIC", "confidence": 0.9941636919975281}, {"text": "precision", "start_pos": 168, "end_pos": 177, "type": "METRIC", "confidence": 0.9596428871154785}]}, {"text": "The \u03a0 values were averaged over 200 words.", "labels": [], "entities": []}, {"text": "presents the result of evaluating the similarity metrics introduced in sec.", "labels": [], "entities": []}, {"text": "4. The results of DistanceM confirm that regarding distance between two vertices alone is not sufficient to conclude their synonymy.", "labels": [], "entities": [{"text": "DistanceM", "start_pos": 18, "end_pos": 27, "type": "DATASET", "confidence": 0.6640315651893616}]}, {"text": "DistanceM finds many related terms ranking general words with many outgoing and incoming edges higher, but it lacks the features providing the particular evidence of synonymy.", "labels": [], "entities": []}, {"text": "NaivePropM is clearly outperformed by the both weighted metrics.", "labels": [], "entities": []}, {"text": "The improvement relative to the DistanceM and acceptable precision of the top-ranked synonyms \u03a0(1) show that considering shared properties is an adequate approach to recognition of synonyms.", "labels": [], "entities": [{"text": "DistanceM", "start_pos": 32, "end_pos": 41, "type": "DATASET", "confidence": 0.6790217757225037}, {"text": "precision", "start_pos": 57, "end_pos": 66, "type": "METRIC", "confidence": 0.995506763458252}]}, {"text": "Ignoring the strength of semantic relation indicated by the graph and the quality of properties is the reason for the big gap in the total score and recall value (\u03a0(100)).", "labels": [], "entities": [{"text": "recall", "start_pos": 149, "end_pos": 155, "type": "METRIC", "confidence": 0.9985685348510742}]}, {"text": "Both weighted metrics achieved results comparable with those reported by) and Turney in.", "labels": [], "entities": [{"text": "Turney", "start_pos": 78, "end_pos": 84, "type": "DATASET", "confidence": 0.8373249173164368}]}, {"text": "Best results of FirstCompM confirm that the criteria identified in sec.", "labels": [], "entities": [{"text": "FirstCompM", "start_pos": 16, "end_pos": 26, "type": "DATASET", "confidence": 0.8962411284446716}]}, {"text": "4 such as generality of a property, abstraction from the absolute word frequency etc. are relevant for identification of synonyms.", "labels": [], "entities": [{"text": "identification of synonyms", "start_pos": 103, "end_pos": 129, "type": "TASK", "confidence": 0.8267887433369955}]}, {"text": "FirstCompM performed particularly better in finding synonyms with the low frequency of occurrence.", "labels": [], "entities": [{"text": "FirstCompM", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.9254738688468933}]}, {"text": "In another set of experiments we investigated the influence of the size of the text corpus (cf.).", "labels": [], "entities": []}, {"text": "The plausible assumption is the more texts are processed, the better the semantic connections between terms are reflected by the graph, the more promising results are expected.", "labels": [], "entities": []}, {"text": "The fact that the number of vertices does not grow proportionally to the size of text corpus can be explained byword recurrence and growing filtering threshold \u03b8.", "labels": [], "entities": []}, {"text": "However, the number of edges increases linearly and reflects the improving semantic coverage.", "labels": [], "entities": []}, {"text": "As expected, every metric performs considerably better on bigger graphs.", "labels": [], "entities": []}, {"text": "While NaivePropM seems to converge after three volumes, the both weighted metrics behave strictly monotonically increasing.", "labels": [], "entities": []}, {"text": "Hence an improvement of results can be expected on bigger corpora.", "labels": [], "entities": []}, {"text": "On the small text corpora the results of single metrics do not differ significantly since there is not sufficient semantic information captured by the graph, i.e. the edge and path lengths do not fully reflect the semantic relations between the words.", "labels": [], "entities": []}, {"text": "The scores of both weighted metrics grow, though, much faster than that of NaivePropM.", "labels": [], "entities": []}, {"text": "FirstCompM achieves the highest gradient demonstrating the biggest potential of leveraging the growing graph for finding synonymy..", "labels": [], "entities": [{"text": "FirstCompM", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.868657648563385}]}, {"text": "Synonyms of domainspecific words are recognized better than those of abstract and everyday words.", "labels": [], "entities": []}, {"text": "Their semantics are better reflected by the technically oriented texts.", "labels": [], "entities": []}, {"text": "The \u03a0 values for abstract and everyday words are pretty similar except for the high precision of top-ranked abstract synonyms.", "labels": [], "entities": [{"text": "precision", "start_pos": 84, "end_pos": 93, "type": "METRIC", "confidence": 0.9985735416412354}]}, {"text": "Everyday words suffer from the fact that their properties are often too general to uniquely characterize them, which involves loss of precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 134, "end_pos": 143, "type": "METRIC", "confidence": 0.9949126243591309}]}, {"text": "Abstract words can be extremely polysemous and have many subtle aspects that are not sufficiently covered by the texts of computer journals.", "labels": [], "entities": []}, {"text": "To test whether the metrics perform better for the more frequent words the test set was divided in 9 disjunctive frequency clusters.", "labels": [], "entities": []}, {"text": "FirstCompM achieved considerably better results for very frequently occurring words (\u2265 4000 occurrences).", "labels": [], "entities": [{"text": "FirstCompM", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.8971202373504639}]}, {"text": "This confirms indirectly the better results on the bigger text corpora: while low frequency does not exclude random influence, frequent occurrence involves adequate capturing of the word semantics in the graph by inserting and adjusting all relevant property edges.", "labels": [], "entities": []}, {"text": "These results do not contradict the conclusion that FirstCompM is not biased towards words with a certain frequency because the mentioned bias pertains to retrieval of synonyms with a certain frequency, whereas in this experiment the performance for different word frequencies of queried words is compared.", "labels": [], "entities": [{"text": "FirstCompM", "start_pos": 52, "end_pos": 62, "type": "DATASET", "confidence": 0.786107063293457}]}], "tableCaptions": [{"text": " Table 1: Results of different metrics on the test corpus", "labels": [], "entities": []}]}