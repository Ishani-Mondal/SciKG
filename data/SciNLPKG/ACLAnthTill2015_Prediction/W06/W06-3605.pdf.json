{"title": [{"text": "A Probabilistic Search for the Best Solution Among Partially Completed Candidates", "labels": [], "entities": []}], "abstractContent": [{"text": "We consider the problem of identifying among many candidates a single best solution which jointly maximizes several domain-specific target functions.", "labels": [], "entities": []}, {"text": "Assuming that the candidate solutions can be generated incrementally, we model the error in prediction due to the incomplete-ness of partial solutions as a normally distributed random variable.", "labels": [], "entities": []}, {"text": "Using this model, we derive a probabilistic search algorithm that aims at finding the best solution without the necessity to complete and rank all candidate solutions.", "labels": [], "entities": []}, {"text": "We do not assume a Viterbi-type decoding, allowing a wider range of target functions.", "labels": [], "entities": []}, {"text": "We evaluate the proposed algorithm on the problem of best parse identification, combining simple heuristic with more complex machine-learning based target functions.", "labels": [], "entities": [{"text": "parse identification", "start_pos": 58, "end_pos": 78, "type": "TASK", "confidence": 0.8217723369598389}]}, {"text": "We show that the search algorithm is capable of identifying candidates with a very high score without completing a significant proportion of the candidate solutions .", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "We test the proposed search algorithm on the problem of dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 56, "end_pos": 74, "type": "TASK", "confidence": 0.8092813789844513}]}, {"text": "We have previously developed a finite-state implementation ( ) of the Link Grammar (LG) parser which generates the parse through the intersection of several finite-state automata.", "labels": [], "entities": [{"text": "Link Grammar (LG) parser", "start_pos": 70, "end_pos": 94, "type": "TASK", "confidence": 0.5328859140475591}]}, {"text": "The resulting automaton encodes all candidate parses.", "labels": [], "entities": []}, {"text": "The parses are then generated from left to right, proceeding through the automaton from the initial to the final state.", "labels": [], "entities": []}, {"text": "A partial parse is a sequence of n words from the beginning of the sentence, together with string encoding of their dependencies.", "labels": [], "entities": []}, {"text": "Advancing a partial parse corresponds to appending to it the next word.", "labels": [], "entities": []}, {"text": "The degree of completion is then defined as the number of words currently generated in the parse, divided by the total number of words in the sentence.", "labels": [], "entities": []}, {"text": "To evaluate the ability of the proposed method to combine diverse criteria in the search, we use four target functions: a complex state-of-the-art parse reranker based on a regularized least-squares (RLSC) regressor), and three measures inspired by the simple heuristics applied by the LG parser.", "labels": [], "entities": []}, {"text": "The criteria are the average length of a dependency, the average level of nesting of a dependency, and the average number of dependencies linking a word.", "labels": [], "entities": []}, {"text": "The RLSC regressor, on the other hand, employs complex features and word n-gram statistics.", "labels": [], "entities": []}, {"text": "The dataset consists of 200 sentences randomly selected from the BioInfer corpus of dependency-parsed sentences extracted from abstracts of biomedical research articles ( ).", "labels": [], "entities": [{"text": "BioInfer corpus", "start_pos": 65, "end_pos": 80, "type": "DATASET", "confidence": 0.9532618522644043}]}, {"text": "For each sentence, we have randomly selected a maximum of 100 parses.", "labels": [], "entities": []}, {"text": "For sentences with less than 100 parses, all parses were selected.", "labels": [], "entities": []}, {"text": "The average number of parses per sentence is 62.", "labels": [], "entities": []}, {"text": "Further, we perform 5 \u00d7 2 cross-validation, that is, in each of five replications, we divide the data randomly to two sets of 100 sentences and use one set to estimate the probability distributions and the other set to measure the performance of the search algorithm.", "labels": [], "entities": []}, {"text": "The RLSC regressor is trained once, using a different set of sentences from the BioInfer corpus.", "labels": [], "entities": [{"text": "BioInfer corpus", "start_pos": 80, "end_pos": 95, "type": "DATASET", "confidence": 0.9343186020851135}]}, {"text": "The results presented here are averaged over the 10 folds.", "labels": [], "entities": []}, {"text": "As a comparative baseline, we use a simple greedy search algorithm that always advances the partial solution with the highest score until all solutions have been generated.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Average results over all sentences.", "labels": [], "entities": [{"text": "Average", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9883876442909241}]}]}