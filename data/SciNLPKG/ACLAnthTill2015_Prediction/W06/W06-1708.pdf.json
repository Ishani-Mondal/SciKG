{"title": [{"text": "The problem of ontology alignment on the web: a first report", "labels": [], "entities": [{"text": "ontology alignment", "start_pos": 15, "end_pos": 33, "type": "TASK", "confidence": 0.8634833693504333}]}], "abstractContent": [{"text": "This paper presents a general architecture and four algorithms that use Natural Language Processing for automatic on-tology matching.", "labels": [], "entities": []}, {"text": "The proposed approach is purely instance based, i.e., only the instance documents associated with the nodes of ontologies are taken into account.", "labels": [], "entities": []}, {"text": "The four algorithms have been evaluated using real world test data, taken from the Google and LookSmart online directories.", "labels": [], "entities": [{"text": "LookSmart online directories", "start_pos": 94, "end_pos": 122, "type": "DATASET", "confidence": 0.9543172319730123}]}, {"text": "The results show that NLP techniques applied to instance documents help the system achieve higher performance.", "labels": [], "entities": []}], "introductionContent": [{"text": "Many fundamental issues about the viability and exploitation of the web as a linguistic corpus have not been tackled yet.", "labels": [], "entities": []}, {"text": "The web is a massive repository of text and multimedia data.", "labels": [], "entities": []}, {"text": "However, there is not a systematic way of classifying and retrieving these documents.", "labels": [], "entities": []}, {"text": "Computational Linguists are of course not the only ones looking at these issues; research on the Semantic Web focuses on providing a semantic description of all the resources on the web, resulting into a mesh of information linked up in such away as to be easily processable by machines, on a global scale.", "labels": [], "entities": []}, {"text": "You can think of it as being an efficient way of representing data on the World Wide Web, or as a globally linked database.", "labels": [], "entities": []}, {"text": "The way the vision of the Semantic Web will be achieved, is by describing each document using languages such as RDF Schema and OWL, which are capable of explicitly expressing the meaning of terms in vocabularies and the relationships between those terms.", "labels": [], "entities": []}, {"text": "The issue we are focusing on in this paper is that these languages are used to define ontologies as well.", "labels": [], "entities": []}, {"text": "If ultimately a single ontology were used to describe all the documents on the web, systems would be able to exchange information in a transparent way for the end user.", "labels": [], "entities": []}, {"text": "The availability of such a standard ontology would be extremely helpful to NLP as well, e.g., it would make it far easier to retrieve all documents on a certain topic.", "labels": [], "entities": []}, {"text": "However, until this vision becomes a reality, a plurality of ontologies are being used to describe documents and their content.", "labels": [], "entities": []}, {"text": "The task of automatic ontology alignment or matching) then needs to be addressed.", "labels": [], "entities": [{"text": "ontology alignment or matching", "start_pos": 22, "end_pos": 52, "type": "TASK", "confidence": 0.7974601686000824}]}, {"text": "The task of ontology matching has been typically carried out manually or semi-automatically, for example through the use of graphical user interfaces).", "labels": [], "entities": [{"text": "ontology matching", "start_pos": 12, "end_pos": 29, "type": "TASK", "confidence": 0.8801456689834595}]}, {"text": "Previous work has been done to provide automated support to this time consuming task).", "labels": [], "entities": []}, {"text": "The various methods can be classified into two main categories: schema based and instance based.", "labels": [], "entities": []}, {"text": "Schema based approaches try to infer the semantic mappings by exploiting information related to the structure of the ontologies to be matched, like their topological properties, the labels or description of their nodes, and structural constraints defined on the schemas of the ontologies.", "labels": [], "entities": []}, {"text": "These methods do not take into account the actual data classified by the ontologies.", "labels": [], "entities": []}, {"text": "On the other hand, instance based approaches look at the information contained in the instances of each element of the schema.", "labels": [], "entities": []}, {"text": "These methods try to infer the relationships between the nodes of the ontologies from the analysis of their instances.", "labels": [], "entities": []}, {"text": "Finally, hybrid approaches combine schema and instance based methods into integrated systems.", "labels": [], "entities": []}, {"text": "Neither instance level information, nor NLP techniques have been extensively explored in previous work on ontology matching.", "labels": [], "entities": [{"text": "ontology matching", "start_pos": 106, "end_pos": 123, "type": "TASK", "confidence": 0.823904424905777}]}, {"text": "For example, () exploits documents (instances) on the WWW to enrich), i.e., to compute \"concept signatures,\" collection of words that significantly distinguish one sense from another, however, not directly for ontology matching.", "labels": [], "entities": [{"text": "WWW", "start_pos": 54, "end_pos": 57, "type": "DATASET", "confidence": 0.934007465839386}, {"text": "ontology matching", "start_pos": 210, "end_pos": 227, "type": "TASK", "confidence": 0.8110103905200958}]}, {"text": "() uses documents retrieved via queries augmented with, for example, synonyms that WordNet provides to improve the accuracy of the queries themselves, but not for ontology matching.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 83, "end_pos": 90, "type": "DATASET", "confidence": 0.9379093647003174}, {"text": "accuracy", "start_pos": 115, "end_pos": 123, "type": "METRIC", "confidence": 0.9972035884857178}, {"text": "ontology matching", "start_pos": 163, "end_pos": 180, "type": "TASK", "confidence": 0.8244167566299438}]}, {"text": "NLP techniques such as POS tagging, or parsing, have been used for ontology matching, but on the names and definitions in the ontology itself, for example, in, hence with a schema based methodology.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 23, "end_pos": 34, "type": "TASK", "confidence": 0.788687527179718}, {"text": "ontology matching", "start_pos": 67, "end_pos": 84, "type": "TASK", "confidence": 0.8828577101230621}]}, {"text": "In this paper, we describe the results we obtained when using some simple but effective NLP methods to align web ontologies, using an instance based approach.", "labels": [], "entities": []}, {"text": "As we will see, our results show that more sophisticated methods do not necessarily lead to better results.", "labels": [], "entities": []}], "datasetContent": [{"text": "All the algorithms described in the previous section have been fully implemented in a coherent and extensible framework using the Java programming language, and evaluation experiments have been run.", "labels": [], "entities": []}, {"text": "This section describes how the experiments have been conducted.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results -Baseline signature algorithm", "labels": [], "entities": [{"text": "Baseline signature", "start_pos": 19, "end_pos": 37, "type": "TASK", "confidence": 0.6343014389276505}]}, {"text": " Table 2: Results -Noun signature algorithm", "labels": [], "entities": [{"text": "Noun signature", "start_pos": 19, "end_pos": 33, "type": "TASK", "confidence": 0.6823042035102844}]}, {"text": " Table 3: Results -WordNet signature algorithm  (hypernym level=0)", "labels": [], "entities": [{"text": "WordNet signature", "start_pos": 19, "end_pos": 36, "type": "TASK", "confidence": 0.7417760193347931}]}, {"text": " Table 4: Results -Disambiguated signature al- gorithm (hypernym level=0, left context=1, right  context=1)", "labels": [], "entities": []}]}