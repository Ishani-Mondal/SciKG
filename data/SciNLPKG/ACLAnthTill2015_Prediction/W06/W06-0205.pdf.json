{"title": [{"text": "Automatic Knowledge Representation using a Graph-based Algorithm for Language-Independent Lexical Chaining", "labels": [], "entities": [{"text": "Automatic Knowledge Representation", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.6036566297213236}, {"text": "Language-Independent Lexical Chaining", "start_pos": 69, "end_pos": 106, "type": "TASK", "confidence": 0.6114033063252767}]}], "abstractContent": [{"text": "Lexical Chains are powerful representations of documents.", "labels": [], "entities": []}, {"text": "In particular, they have successfully been used in the field of Automatic Text Summarization.", "labels": [], "entities": [{"text": "Automatic Text Summarization", "start_pos": 64, "end_pos": 92, "type": "TASK", "confidence": 0.7492657502492269}]}, {"text": "However , until now, Lexical Chaining algorithms have only been proposed for Eng-lish.", "labels": [], "entities": [{"text": "Lexical Chaining", "start_pos": 21, "end_pos": 37, "type": "TASK", "confidence": 0.8940911591053009}]}, {"text": "In this paper, we propose a greedy Language-Independent algorithm that automatically extracts Lexical Chains from texts.", "labels": [], "entities": []}, {"text": "For that purpose, we build a hierarchical lexico-semantic knowledge base from a collection of texts by using the Pole-Based Overlapping Clustering Algorithm.", "labels": [], "entities": []}, {"text": "As a consequence, our methodology can be applied to any language and proposes a solution to language-dependent Lexical Chainers.", "labels": [], "entities": [{"text": "Lexical Chainers", "start_pos": 111, "end_pos": 127, "type": "TASK", "confidence": 0.6971262842416763}]}], "introductionContent": [{"text": "Lexical Chains are powerful representations of documents compared to broadly used bag-of-words representations.", "labels": [], "entities": []}, {"text": "In particular, they have successfully been used in the field of Automatic Text Summarization ().", "labels": [], "entities": [{"text": "Automatic Text Summarization", "start_pos": 64, "end_pos": 92, "type": "TASK", "confidence": 0.6988218029340109}]}, {"text": "However, until now, Lexical Chaining algorithms have only been proposed for English as they rely on linguistic resources such as Thesauri or Ontologies (;. were the first to propose the concept of Lexical Chains to explore the discourse structure of a text.", "labels": [], "entities": [{"text": "Lexical Chaining", "start_pos": 20, "end_pos": 36, "type": "TASK", "confidence": 0.8738478720188141}]}, {"text": "However, at the time of writing their paper, no machine-readable thesaurus was available so they manually generated Lexical Chains using Roget's Thesaurus.", "labels": [], "entities": []}, {"text": "A first computational model of Lexical Chains is introduced by.", "labels": [], "entities": []}, {"text": "Their biggest contribution to the study of Lexical Chains is the mapping of WordNet relations and paths (transitive relationships) to word relationship types.", "labels": [], "entities": []}, {"text": "However, their greedy algorithm does not use a part-of-speech tagger.", "labels": [], "entities": []}, {"text": "Instead, the algorithm only selects those words that contain noun entries in WordNet to compute Lexical Chains.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 77, "end_pos": 84, "type": "DATASET", "confidence": 0.9597609043121338}]}, {"text": "But, as point at, the use of a part-of-speech tagger could eliminate wrong inclusions of words such as read, which has both noun and verb entries in WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 149, "end_pos": 156, "type": "DATASET", "confidence": 0.9673124551773071}]}, {"text": "So, propose the first dynamic method to compute Lexical Chains.", "labels": [], "entities": []}, {"text": "They argue that the most appropriate sense of a word can only be chosen after examining all possible Lexical Chain combinations that can be generated from a text.", "labels": [], "entities": []}, {"text": "Because all possible senses of the word are not taken into account, except at the time of insertion, potentially pertinent context information that is likely to appear after the word is lost.", "labels": [], "entities": []}, {"text": "However, this method of retaining all possible interpretations until the end of the process, causes the exponential growth of the time and space complexity.", "labels": [], "entities": []}, {"text": "As a consequence, propose a linear time version of () lexical chaining algorithm.", "labels": [], "entities": []}, {"text": "In particular,)'s implementation creates a structure, called meta-chains, that implicitly stores all chain interpretations without actually creating them, thus keeping both the space and time usage of the program linear.", "labels": [], "entities": []}, {"text": "Finally, propose a chaining method that disambiguates nouns prior to the processing of Lexical Chains.", "labels": [], "entities": []}, {"text": "Their evaluation shows that their algorithm is more accurate than ( and) ones.", "labels": [], "entities": []}, {"text": "One common point of all these works is that Lexical Chains are built using WordNet as the standard linguistic resource.", "labels": [], "entities": [{"text": "Lexical Chains", "start_pos": 44, "end_pos": 58, "type": "TASK", "confidence": 0.8117034435272217}, {"text": "WordNet", "start_pos": 75, "end_pos": 82, "type": "DATASET", "confidence": 0.9498854875564575}]}, {"text": "Unfortunately, systems based on static linguistic knowledge bases are limited.", "labels": [], "entities": []}, {"text": "First, such resources are difficult to find.", "labels": [], "entities": []}, {"text": "Second, they are largely obsolete by the time they are available.", "labels": [], "entities": []}, {"text": "Third, linguistic resources capture a particular form of lexical knowledge which is often very different from the sort needed to specifically relate words or sentences.", "labels": [], "entities": []}, {"text": "In particular, WordNet is missing a lot of explicit links between intuitively related words.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 15, "end_pos": 22, "type": "DATASET", "confidence": 0.9659067988395691}]}, {"text": "refers to such obvious omissions in WordNet as the \"tennis problem\" where nouns such as nets, rackets and umpires are all present, but WordNet provides no links between these related tennis concepts.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 36, "end_pos": 43, "type": "DATASET", "confidence": 0.9746827483177185}, {"text": "WordNet", "start_pos": 135, "end_pos": 142, "type": "DATASET", "confidence": 0.9633457660675049}]}, {"text": "In order to solve these problems, we propose to automatically construct from a collection of documents a lexico-semantic knowledge base with the purpose to identify cohesive lexical relationships between words based on corpus evidence.", "labels": [], "entities": []}, {"text": "This hierarchical lexico-semantic knowledge base is built by using the Pole-Based Overlapping Clustering Algorithm () that clusters words with similar meanings and allows words with multiple meanings to belong to different clusters.", "labels": [], "entities": []}, {"text": "The second step of the process aims at automatically extracting Lexical Chains from texts based on our knowledge base.", "labels": [], "entities": []}, {"text": "For that purpose, we propose anew greedy algorithm which can be seen as an extension of and) algorithms which allows polysemous words to belong to different chains thus breaking the \"one-word/one-concept per document\" paradigm ( 1 . In particular, it imple-ments) information-theoretic definition of similarity as the relatedness criterion for the attribution of words to Lexical Chains 2 .", "labels": [], "entities": []}], "datasetContent": [{"text": "The evaluation of Lexical Chains is generally difficult.", "labels": [], "entities": []}, {"text": "Even if they can be effectively used in many practical applications, Lexical Chains are seldom desirable outputs in a real-world application, and it is unclear how to assess their quality independently of the underlying application in which they are used ().", "labels": [], "entities": []}, {"text": "For example, in Summarization, it is hard to determine whether a good or bad performance comes from the efficiency of the lexical chaining algorithm or from the appropriateness of using Lexical Chains in that kind of application.", "labels": [], "entities": [{"text": "Summarization", "start_pos": 16, "end_pos": 29, "type": "TASK", "confidence": 0.9884971380233765}]}, {"text": "It is also true that some work has been done in this direction () by collecting Human Lexical Chains to compare against automatically built Lexical Chains.", "labels": [], "entities": []}, {"text": "However, this type of evaluation is logistically impossible to perform as we aim at developing a system that does not depend on any language or topic.", "labels": [], "entities": []}, {"text": "So, in this section, we will only present some results generated by our architecture (like () do), although we acknowledge that other comparative evaluations (with WordNet, with Human Lexical Chains or within independent applications like Text Summarization) must be done in order to draw definitive conclusions.", "labels": [], "entities": [{"text": "Text Summarization", "start_pos": 239, "end_pos": 257, "type": "TASK", "confidence": 0.7714214622974396}]}, {"text": "We have generated four taxonomies from four different domains (Sport, Economy, Politics and War) from a set of documents of the DUC 2004 . Moreover, we have extracted Lexical Chains for all four domains to show the ability of our system to switch from domain to domain without any problem.", "labels": [], "entities": [{"text": "DUC 2004", "start_pos": 128, "end_pos": 136, "type": "DATASET", "confidence": 0.9046851694583893}]}, {"text": "In this section, as it is done in (    For instance, the Lexical Chain #16 in the domain of Sport clearly exemplifies the tragedy of climbers that were killed in a sudden change of weather in the mountains and who could not be rescued by the authorities.", "labels": [], "entities": [{"text": "Lexical Chain #16 in the domain of Sport", "start_pos": 57, "end_pos": 97, "type": "DATASET", "confidence": 0.83041822248035}]}, {"text": "However, some Lexical Chains are less expressive.", "labels": [], "entities": []}, {"text": "For instance, it is not clear what the Lexical Chain #40 expresses in the domain of Politics.", "labels": [], "entities": []}, {"text": "Moreover, due to the small number of inter-related nominal units within the Lexical Chain, this one cannot be understood as it is without context.", "labels": [], "entities": []}, {"text": "In fact, it was related to problems of car firing that have been occurring in the past few weeks and provoked security problems in the town.", "labels": [], "entities": []}, {"text": "Although some Lexical Chains are understandable as they are, most of them must be replaced in their context to fully understand their representativeness of the topics or subtopics of the text being analyzed.", "labels": [], "entities": []}, {"text": "As a consequence, we deeply believe that Lexical Chains must be evaluated in the context of Natural Language Processing applications (such as Text Summarization ()), as comparing Lexical Chains as they are is a very difficult task to tackle which may even lead to inconclusive results.", "labels": [], "entities": [{"text": "Text Summarization", "start_pos": 142, "end_pos": 160, "type": "TASK", "confidence": 0.7476958632469177}]}], "tableCaptions": [{"text": " Table 1: Characteristics of Documents for Sport", "labels": [], "entities": []}, {"text": " Table 2: # Lexical Chains per Document", "labels": [], "entities": []}]}