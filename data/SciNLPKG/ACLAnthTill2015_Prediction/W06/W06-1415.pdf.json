{"title": [{"text": "Generating Intelligent Numerical Answers in a Question-Answering System", "labels": [], "entities": [{"text": "Generating Intelligent Numerical Answers", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.7203089892864227}]}], "abstractContent": [{"text": "In this paper, we present a question-answering system on the Web which aims at generating intelligent answers to numerical questions.", "labels": [], "entities": []}, {"text": "These answers are generated in a cooperative way: besides a direct answer, comments are generated to explain to the user the variation of numerical data extracted from the Web.", "labels": [], "entities": []}, {"text": "We present the content determination and realisation tasks.", "labels": [], "entities": [{"text": "content determination", "start_pos": 15, "end_pos": 36, "type": "TASK", "confidence": 0.8351490497589111}]}, {"text": "We also present some elements of evaluation with respect to end-users.", "labels": [], "entities": []}], "introductionContent": [{"text": "Search engines on the Web and most existing question-answering (QA) systems provide the user with a set of hyperlinks and/or Web page extracts containing answer(s) to a question.", "labels": [], "entities": []}, {"text": "These answers maybe incoherent to a certain degree: they maybe equivalent, complementary, contradictory, at different levels of precision or specificity, etc.", "labels": [], "entities": [{"text": "precision", "start_pos": 128, "end_pos": 137, "type": "METRIC", "confidence": 0.9943185448646545}]}, {"text": "It is then quite difficult for the user to know which answer is the correct one.", "labels": [], "entities": []}, {"text": "Thus, an analysis of relevance and coherence of candidate answers is essential.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we present some elements of evaluation of our system with respect to 15 end-users . We first evaluated how users behave when they are faced with different candidate answers to a question.", "labels": [], "entities": []}, {"text": "To each user, we presented 5 numerical questions and their candidate answers which vary according to time or restrictions and ask them to produce their own answer from candidate answers.", "labels": [], "entities": []}, {"text": "For numerical answers varying according to restrictions, 93% of subjects produce answers explaining the different numerical values for each restriction.", "labels": [], "entities": []}, {"text": "For numerical answers varying overtime, 80% of subjects produce answers giving the most recent information (20% of subjects produce an answer which a summary of all candidate values).", "labels": [], "entities": []}, {"text": "This validates our hypothesis presented in section 4.1.1.", "labels": [], "entities": []}, {"text": "The second point we evaluated is the answer order.", "labels": [], "entities": []}, {"text": "Our system produces answers in the form of a direct answer, then an explanation and a justification (page extract) if necessary.", "labels": [], "entities": []}, {"text": "We proposed to users answers with these three parts arranged randomly.", "labels": [], "entities": []}, {"text": "Contrary to () which propose first an overview and then a zoom on inter-esting phenomena, 73% of subjects prefered the order proposed by our system, perhaps because, in QA systems, users wants to have a direct answer to their question before having explanations.", "labels": [], "entities": []}, {"text": "The last point we evaluated is the quality of the system answers.", "labels": [], "entities": []}, {"text": "For this purpose, we asked subjects to choose, for 5 questions, which answer they prefer among: the system answer, an average, an interval and a disjunction of all candidate answers.", "labels": [], "entities": [{"text": "interval", "start_pos": 130, "end_pos": 138, "type": "METRIC", "confidence": 0.9521763324737549}]}, {"text": "91% of subjects prefered the system answer.", "labels": [], "entities": []}, {"text": "75% of subjects found that the explanation produced is useful and only 31% of subjects consulted the Web page extract (28% of these found it useful).", "labels": [], "entities": []}], "tableCaptions": []}