{"title": [{"text": "Learning Probabilistic Paradigms for Morphology in a Latent Class Model", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper introduces the probabilistic paradigm, a probabilistic, declarative model of morphological structure.", "labels": [], "entities": []}, {"text": "We describe an algorithm that recursively applies Latent Dirichlet Allocation with an orthogonality constraint to discover morphological paradigms as the latent classes within a suffix-stem matrix.", "labels": [], "entities": []}, {"text": "We apply the algorithm to data preprocessed in several different ways, and show that when suffixes are distinguished for part of speech and allomorphs or gender/conjugational variants are merged, the model is able to correctly learn morphological paradigms for English and Spanish.", "labels": [], "entities": []}, {"text": "We compare our system with Linguistica (Goldsmith 2001), and discuss the advantages of the probabilistic paradigm over Linguistica's signature representation.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years researchers have addressed the task of unsupervised learning of declarative representations of morphological structure.", "labels": [], "entities": []}, {"text": "These models include the signature of (Goldsmith 2001), the conflation set of (, the paradigm of, and the inflectional class of).", "labels": [], "entities": []}, {"text": "While these representations group morphologically related words in systematic ways, they are rather different from the paradigm, the representation of morphology in traditional grammars.", "labels": [], "entities": []}, {"text": "A paradigm lists the prototypical morphological properties of lexemes belonging to a particular part of speech (POS) category; for example, a paradigm for regular English verbs would include the suffixes {$,ed$,ing$,s$} 1 . Hand-built computational implementations of paradigms as inheritance hierarchies include DATR ( and Functional Morphology ().", "labels": [], "entities": []}, {"text": "The two principal ways in which learned models have differed from paradigms are that: 1) they do not have POS types, and 2) they are not abstractions that generalize beyond the words of the input corpus.", "labels": [], "entities": []}, {"text": "There are important reasons for learning a POS-associated, paradigmatic representation of morphology.", "labels": [], "entities": [{"text": "POS-associated, paradigmatic representation of morphology", "start_pos": 43, "end_pos": 100, "type": "TASK", "confidence": 0.583348294099172}]}, {"text": "Currently, the dominant technology for morphological analysis involves mapping between inflected and base of forms of words with finite-state transducers (FSTs), a procedural model of morphological relations.", "labels": [], "entities": [{"text": "morphological analysis", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.88473841547966}]}, {"text": "Rewrite rules are handcrafted and compiled into FSTs, and it would be beneficial if these rules could be learned automatically.", "labels": [], "entities": [{"text": "FSTs", "start_pos": 48, "end_pos": 52, "type": "DATASET", "confidence": 0.5344661474227905}]}, {"text": "One line of research in computational morphology has been directed towards learning finitestate mapping rules from some sort of paradigmatic structure, where all morphological forms and POS types are presumed known fora set of lexemes (.", "labels": [], "entities": [{"text": "learning finitestate mapping rules", "start_pos": 75, "end_pos": 109, "type": "TASK", "confidence": 0.6763226091861725}]}, {"text": "This can be accomplished by first deciding on abase form, then learning rules to convert other forms of the paradigm into this base form.", "labels": [], "entities": []}, {"text": "If one could develop an unsupervised algorithm for learning paradigms, it could serve as the input to rulelearning procedures, effectively leading to an entirely unsupervised system for learning FSTs from raw data.", "labels": [], "entities": []}, {"text": "This is our long-term goal.", "labels": [], "entities": []}, {"text": "An alternative approach is to skip the paradigm formulation step and construct a procedural model directly from raw data.", "labels": [], "entities": [{"text": "paradigm formulation", "start_pos": 39, "end_pos": 59, "type": "TASK", "confidence": 0.7286902964115143}]}, {"text": "( bootstrap inflected and base forms directly from raw data and learn mappings between them.", "labels": [], "entities": []}, {"text": "Their results are quite successful, but the morphological information they learn is not structured as clearly as a paradigmatic model.) constructs a morphological automaton, where nodes are clustered word types and arcs are suffixation rules.", "labels": [], "entities": []}, {"text": "This paper addresses the problem of finding an organization of stems and suffixes as probabilistic paradigms (section 2), a model of morphology closer to linguistic notion of paradigm than previously proposed models.", "labels": [], "entities": []}, {"text": "We encode the morphological structure of a language in a matrix containing frequencies of words, and formulate the problem of learning paradigms as one of finding latent classes within the matrix.", "labels": [], "entities": []}, {"text": "We present a recursive LDA, a learning algorithm based on Latent Dirichlet Allocation (section 3), and show that under certain conditions (section 5), it can correctly learn morphological paradigms for English and Spanish.", "labels": [], "entities": []}, {"text": "In section 6, we compare the probabilistic paradigm to the signature model of.", "labels": [], "entities": []}, {"text": "In section 7, we sketch some ideas for how to make our system more unsupervised and more linguistically adequate.", "labels": [], "entities": []}, {"text": "We assume a model of morphology where each word is the concatenation of a stem and a single suffix representing all of the word's morphological and POS properties.", "labels": [], "entities": []}, {"text": "Although this is a very simplistic view of morphology, there are many hitherto unresolved computational issues for learning even this basic model, and we consider it necessary to address these issues before developing more sophisticated models.", "labels": [], "entities": []}, {"text": "For a stem/suffix representation, the task of learning a paradigm from raw data involves proposing suffixes and stems, proposing segmentations, and systematically organizing stems and suffixes into classes.", "labels": [], "entities": []}, {"text": "One difficulty is suffix allomorphy: a suffix has multiple forms depending on its phonological environment (e.g. s$/es$).", "labels": [], "entities": []}, {"text": "Another problem is suffix categorial ambiguity (s$ is ambiguous for noun and verb uses).", "labels": [], "entities": []}, {"text": "Finally, lexemes appear in only a subset of their potential forms, due to sparse data.", "labels": [], "entities": []}, {"text": "An unsupervised learner needs to be able to handle all of these difficulties in order to discover abstract paradigmatic classes.", "labels": [], "entities": []}, {"text": "In this paper, we are primarily interested in how the co-occurrence of stems and suffixes in a corpus leads them to be organized into paradigms.", "labels": [], "entities": []}, {"text": "We use data preprocessed with correct segmentations of words into stems and suffixes, in order to focus on the issue of determining what additional knowledge is needed.", "labels": [], "entities": []}, {"text": "We demonstrate that paradigms for English and Spanish can be successfully learned when tokens have been assigned POS tags and allomorphs or gender/conjugational variants are given a common representation.", "labels": [], "entities": []}, {"text": "Our learning algorithm is not supervised since the target concept of gold standard \"input\" POS category of stems is not known, but rather it is an unsupervised algorithm that relies on preprocessed data for optimal performance.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3. M matrix for English merged, labeled  suffixes. Columns: p(suff|paradigm).", "labels": [], "entities": []}, {"text": " Table 4. Portion of L matrix for English merged,  labeled suffixes, sorted by lowest entropy.  Columns: p(paradigm|stem).", "labels": [], "entities": []}, {"text": " Table 5. Comparison of M and L matrices with  true morphological and lexical probabilities, by  conditional relative entropy (CRE).", "labels": [], "entities": [{"text": "conditional relative entropy (CRE)", "start_pos": 97, "end_pos": 131, "type": "METRIC", "confidence": 0.658015564084053}]}, {"text": " Table 6. Gamma matrix for root node, English,  unmerged, unlabeled suffixes; the categorization  is shown with brackets. Columns indicate", "labels": [], "entities": []}]}