{"title": [{"text": "Automatic Identification of Non-Compositional Multi-Word Expressions using Latent Semantic Analysis", "labels": [], "entities": [{"text": "Identification of Non-Compositional Multi-Word Expressions", "start_pos": 10, "end_pos": 68, "type": "TASK", "confidence": 0.5576848864555359}, {"text": "Latent Semantic Analysis", "start_pos": 75, "end_pos": 99, "type": "TASK", "confidence": 0.5914570887883505}]}], "abstractContent": [{"text": "Making use of latent semantic analysis , we explore the hypothesis that local linguistic context can serve to identify multi-word expressions that have non-compositional meanings.", "labels": [], "entities": []}, {"text": "We propose that vector-similarity between distribution vectors associated with an MWE as a whole and those associated with its constitutent parts can serve as a good measure of the degree to which the MWE is composi-tional.", "labels": [], "entities": []}, {"text": "We present experiments that show that low (cosine) similarity does, in fact, correlate with non-compositionality.", "labels": [], "entities": []}], "introductionContent": [{"text": "Identifying non-compositional (or idiomatic) multi-word expressions (MWEs) is an important subtask for any computational system (), and significant attention has been paid to practical methods for solving this problem in recent years).", "labels": [], "entities": [{"text": "Identifying non-compositional (or idiomatic) multi-word expressions (MWEs)", "start_pos": 0, "end_pos": 74, "type": "TASK", "confidence": 0.8353188092058356}]}, {"text": "While corpus-based techniques for identifying collocational multi-word expressions by exploiting statistical properties of the co-occurrence of the component words have become increasingly sophisticated, it is well known that mere co-occurrence does not well distinguish compositional from non-compositional expressions.", "labels": [], "entities": []}, {"text": "While expressions which may potentially have idiomatic meanings can be identified using various lexical association measures, other techniques must be used to determining whether or not a particular MWE does, in fact, have an idiomatic use.", "labels": [], "entities": []}, {"text": "In this paper we explore the hypothesis that the local linguistic context can provide adequate cues for making this determination and propose one method for doing this.", "labels": [], "entities": []}, {"text": "We characterize our task on analogy with wordsense disambiguation.", "labels": [], "entities": []}, {"text": "As noted by Sch\u00fctze, WSD involves two related tasks: the general task of sense discrimination-determining what senses a given word has-and the more specific task of sense selection-determining fora particular use of the word in context which sense was intended.", "labels": [], "entities": [{"text": "WSD", "start_pos": 21, "end_pos": 24, "type": "TASK", "confidence": 0.9866693019866943}, {"text": "sense discrimination-determining what senses a given word", "start_pos": 73, "end_pos": 130, "type": "TASK", "confidence": 0.8403158060141972}]}, {"text": "For us the discrimination task involves determining fora given expression whether it has a non-compositional interpretation in addition to its compositional interpretation, and the selection task involves determining in a given context, whether a given expression is being used compositionally or non-compostionally.", "labels": [], "entities": []}, {"text": "The German expression ins Wasser fallen, for example, has a noncompositional interpretation on which it means 'to fail to happen' (as in) and a compositional interpretation on which it means 'to fall into water (as in).", "labels": [], "entities": []}], "datasetContent": [{"text": "For this experiment we manually annotated the 67 occurrences of ins Wasser fallen in our corpus as to whether the expression was used compositionally (literally) or non-compositionally (idiomatically).", "labels": [], "entities": []}, {"text": "Marking this distinction we generate an LSA meaning vectors for the compositional uses and an LSA meaning vector for the non-compositional uses of ins Wasser fallen.", "labels": [], "entities": [{"text": "LSA meaning vector", "start_pos": 94, "end_pos": 112, "type": "METRIC", "confidence": 0.9103063543637594}]}, {"text": "The vectors turned out, as expected, to be almost orthogonal, with a cosine of the angle between them of 0.02.", "labels": [], "entities": []}, {"text": "This result confirms that the linguistic contexts in which the literal and the idiomatic use of ins Wasser fallen appear are very different, indicating-not surprisingly-that the semantic difference between the literal meaning and the idiomatic meaning is reflected in the way these these phrases are used.", "labels": [], "entities": []}, {"text": "Our next task was to investigate whether this difference could be used in particular cases to determine what the intended use of an MWE in a particular context was.", "labels": [], "entities": []}, {"text": "To evaluate this, we did a 10-fold cross-validation study, calculating the literal and idiomatic vectors for ins Wasser fallen on the basis of the training data and doing a simple nearest neighbor classification of each memember of the test set on the basis of the meaning vectors computed from its local context (the 30 word window).", "labels": [], "entities": []}, {"text": "Our result of an average accurace of 72% for our LSA-based classifier far exceeds the simple maximum-likelihood baseline of 58%.", "labels": [], "entities": [{"text": "accurace", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9666298627853394}]}, {"text": "In the final part of this experiment we compared the meaning vector that was computed by summing overall uses of ins Wasser fallen with the literal and idiomatic vectors from above.", "labels": [], "entities": []}, {"text": "Since idiomatic uses of ins Wasser fallen prevail in the corpus (2/3 vs. 1/3), it is not surprisingly that the similarity to the literal vector (0.0946) is much than similarity to the idiomatic vector (0.3712).", "labels": [], "entities": []}, {"text": "To summarize Experiment I, which is a variant of a supervised phrase sense disambiguation task, demonstrates that we can use LSA to distinguish between literal and the idiomatic usage of an MWE by using local linguistic context.", "labels": [], "entities": [{"text": "phrase sense disambiguation task", "start_pos": 62, "end_pos": 94, "type": "TASK", "confidence": 0.7611821815371513}]}, {"text": "This was a straightforward task; two annotators annotated independently, with very high agreement-kappa score of over 0.95.", "labels": [], "entities": [{"text": "agreement-kappa score", "start_pos": 88, "end_pos": 109, "type": "METRIC", "confidence": 0.9765944182872772}]}, {"text": "Occurrences on which the annotators disagreed were thrown out.", "labels": [], "entities": []}, {"text": "Of the 64 occurrences we used, 37 were idiomatic and 27 were literal.", "labels": [], "entities": []}, {"text": "In our second experiment we sought to make use of the fact that there are typically clear distributional difference between compositional and non-compositional uses of MWEs to determine whether a given MWE indeed has noncompositional uses at all.", "labels": [], "entities": []}, {"text": "In this experiment we made use of a test set of German Preposition-Noun-Verb \"collocation candidate\" database whose extraction is described by and which has been made available electronically.", "labels": [], "entities": []}, {"text": "From this database only word combinations with frequency of occurrence more than 30 in our test corpus were considered.", "labels": [], "entities": []}, {"text": "Our task was to classify these 81 potential MWEs according whether or not thay have an idiomatic meaning.", "labels": [], "entities": []}, {"text": "To accomplish this task we took the following approach.", "labels": [], "entities": []}, {"text": "We computed on the basis of the distribution of the components of the MWE an estimate for the compositional meaning vector for the MWE.", "labels": [], "entities": []}, {"text": "We then compared this to the actual vector for the MWE as a whole, with the expectation MWEs which indeed have non-compositinoal uses will be distinguished by a relatively low vector similarity between the estimated compositional meaning vector and the actual meaning vector.", "labels": [], "entities": []}, {"text": "In other words small similarity values should be diagnostic for the presense of non-compositinoal uses of the MWE.", "labels": [], "entities": []}, {"text": "We calculated the estimated compositional meaning vector by taking it to be the sum of the meaning vector of the parts, i.e., the compositional meaning of an expression w1w2 consisting of two words is taken to be sum of the meaning vectors for the constituent words.", "labels": [], "entities": []}, {"text": "In order to maximize the independent contribution of the constituent words, the meaning vectors for these words were always computed from contexts in which they appear alone (that is, not in the local context of the other constituent).", "labels": [], "entities": []}, {"text": "We call the estimated compositional meaning vector the \"composed\" vector.", "labels": [], "entities": []}, {"text": "The comparisons we made are illustrated in, where vectors for the MWE auf die Strecke bleiben 'to fall by the wayside' and the words Strecke 'route' and bleiben 'to stay' are mapped As a further illustration of the difference between the composed vector and the MWE vector, in we list the words whose meaning vector is most similar to that of the MWE auf dis Strecke bleiben along with their similarity values, and in we list those words whose meaning vector is most similar to the composed vector.", "labels": [], "entities": []}, {"text": "The semantic differences among these two classes are readily apparent.", "labels": [], "entities": []}, {"text": "We recognize that the composed vector is clearly nowhere near a perfect model of compositional meaning in the general case.", "labels": [], "entities": []}, {"text": "This can be illustrated by considering, for example, the MWE fire breathing.", "labels": [], "entities": [{"text": "MWE fire breathing", "start_pos": 57, "end_pos": 75, "type": "DATASET", "confidence": 0.7917494773864746}]}, {"text": "This expression is clearly compositional, as it denotes the process of producing The preposition auf and the article die are on the stop list combusting exhalation, exactly what the semantic combination rules of the English would predict.", "labels": [], "entities": []}, {"text": "Nevertheless the distribution of fire breathing is quite unrelated to that of its constituents fire and breathing ( the former appears frequently with dragon and circus while the later appear frequently with blaze and lungs, respectively).", "labels": [], "entities": []}, {"text": "Despite these principled objections, the composed vector provides a useful baseline for our investigation.", "labels": [], "entities": []}, {"text": "We should note that a number of researchers in the LSA tradition have attempted to provide more compelling combinatory functions to capture the non-linearity of linguistic compositional interpretation.", "labels": [], "entities": [{"text": "linguistic compositional interpretation", "start_pos": 161, "end_pos": 200, "type": "TASK", "confidence": 0.698276937007904}]}, {"text": "To evaluate the method, we used the careful manual annotation of the PNV database described by as our gold standard.", "labels": [], "entities": [{"text": "PNV database", "start_pos": 69, "end_pos": 81, "type": "DATASET", "confidence": 0.9669453799724579}]}, {"text": "By adopting different threshholds for the classification decision, we obtained a range of results (trading off precision and recall).", "labels": [], "entities": [{"text": "precision", "start_pos": 111, "end_pos": 120, "type": "METRIC", "confidence": 0.99936443567276}, {"text": "recall", "start_pos": 125, "end_pos": 131, "type": "METRIC", "confidence": 0.9992688298225403}]}, {"text": "The F-score measure is maximized in our experiments by adopting a similarity threshold of 0.2.", "labels": [], "entities": [{"text": "F-score measure", "start_pos": 4, "end_pos": 19, "type": "METRIC", "confidence": 0.9851822853088379}, {"text": "similarity threshold", "start_pos": 66, "end_pos": 86, "type": "METRIC", "confidence": 0.9554024934768677}]}, {"text": "This means that MWEs which have a meaning vector whose cosine is under this value when compared with with the combined vector should be classified as having a non-literal meaning.", "labels": [], "entities": []}, {"text": "To compare our method with that proposed by, we applied their method to our materials, generating LSA vectors for the component content words in our candidate MWEs and comparing their semantic similarity to the MWEs LSA vector as a whole, with the expectation being that low similarity between the MWE as a whole and its component words is indication of the non-compositionality of the MWE.", "labels": [], "entities": []}, {"text": "The results are given in.", "labels": [], "entities": []}, {"text": "It is clear that while Baldwin et al.'s expectation is borne out in the case of the constituent noun (the non-head), it is not in the case of the constituent verb (the head).", "labels": [], "entities": []}, {"text": "Even in the case of the nouns, however, the results are, for the most part, markedly inferior to the results we achieved using the composed vectors.", "labels": [], "entities": []}, {"text": "There area number of issues that complicate the workability of the unsupervised technique described here.", "labels": [], "entities": []}, {"text": "We rely on there being enough non-compositional uses of an idiomatic MWE in the corpus that the overall meaning vector for the MWE reflects this usage.", "labels": [], "entities": []}, {"text": "If the literal meaning is overwhelmingly frequent, this will reduce the effectivity of the method significantly.", "labels": [], "entities": []}, {"text": "A second problem concerns the relationship between the literal and the non-literal meaning.", "labels": [], "entities": []}, {"text": "Our technique relies on these meaning being highly distinct.", "labels": [], "entities": []}, {"text": "If the meanings are similar, it is likely that local context will be inadequate to distinguish a compositional from a non-compositional use of the expression.", "labels": [], "entities": []}, {"text": "In our investigation it became apparent, in fact, that in the newspaper genre, highly idiomatic expressions such as ins Wasser fallen were often used in their idiomatic sense (apparently for humorous effect) particularly frequently in contexts in which elements of the literal meaning were also present.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Evaluation of Various Similarity Thresholds", "labels": [], "entities": []}, {"text": " Table 5: Evaluation of Method of Baldwin et al. (2003)", "labels": [], "entities": []}]}