{"title": [], "abstractContent": [{"text": "In this article, we present a translation system which builds translations by gluing together Tree-Phrases, i.e. associations between simple syntactic dependency treelets in a source language and their corresponding phrases in a target language.", "labels": [], "entities": []}, {"text": "The Tree-Phrases we use in this study are syntactically informed and present the advantage of gathering source and target material whose words do not have to be adjacent.", "labels": [], "entities": []}, {"text": "We show that the phrase-based translation engine we implemented benefits from Tree-Phrases.", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 17, "end_pos": 41, "type": "TASK", "confidence": 0.6918858289718628}]}], "introductionContent": [{"text": "Phrase-based machine translation is now a popular paradigm.", "labels": [], "entities": [{"text": "Phrase-based machine translation", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8296602169672648}]}, {"text": "It has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation ().", "labels": [], "entities": [{"text": "word-based machine translation", "start_pos": 89, "end_pos": 119, "type": "TASK", "confidence": 0.6055417557557424}]}, {"text": "The underlying unit (a pair of phrases), however, does not handle well languages with very different word orders and fails to derive generalizations from the training corpus.", "labels": [], "entities": []}, {"text": "Several alternatives have been recently proposed to tackle some of these weaknesses.", "labels": [], "entities": []}, {"text": "() propose to reorder the source text in order to mimic the target word order, and then let a phrase-based model do what it is good at.", "labels": [], "entities": []}, {"text": "() detail an approach where the standard phrases are extended to account for \"gaps\" either on the target or source side.", "labels": [], "entities": []}, {"text": "They show that this representation has the potential to better exploit the training corpus and to nicely handle differences such as negations in French and English that are poorly handled by standard phrase-based models.", "labels": [], "entities": []}, {"text": "Others are considering translation as asynchronous parsing process e.g.) and several algorithms have been proposed to learn the underlying production rule probabilities (.", "labels": [], "entities": [{"text": "translation", "start_pos": 23, "end_pos": 34, "type": "TASK", "confidence": 0.9610664248466492}]}, {"text": "proposes an heuristic way of acquiring context free transfer rules that significantly improves upon a standard phrase-based model.", "labels": [], "entities": []}, {"text": "As mentioned in), most of these approaches require some assumptions on the level of isomorphism (lexical and/or structural) between two languages.", "labels": [], "entities": []}, {"text": "In this work, we consider a simple kind of unit: a Tree-Phrase (TP), a combination of a fully lexicalized treelet (TL) and an elastic phrase (EP), the tokens of which maybe in non-contiguous positions.", "labels": [], "entities": []}, {"text": "TPs capture some syntactic information between two languages and can easily be merged with standard phrase-based engines.", "labels": [], "entities": []}, {"text": "ATP can be seen as a simplification of the treelet pairs manipulated in).", "labels": [], "entities": []}, {"text": "In particular, we do not address the issue of projecting a source treelet into a target one, but take the bet that collecting (without structure) the target words associated with the words encoded in the nodes of a treelet will suffice to allow translation.", "labels": [], "entities": []}, {"text": "This set of target words is what we call an elastic phrase.", "labels": [], "entities": []}, {"text": "We show that these units lead to (modest) improvements in translation quality as measured by automatic metrics.", "labels": [], "entities": [{"text": "translation", "start_pos": 58, "end_pos": 69, "type": "TASK", "confidence": 0.9550791382789612}]}, {"text": "We conducted all our experiments on an in-house version of the French-English Canadian Hansards.", "labels": [], "entities": [{"text": "French-English Canadian Hansards", "start_pos": 63, "end_pos": 95, "type": "DATASET", "confidence": 0.8437677621841431}]}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "We first define a Tree-Phrase in Section 2, the unit with which we built our system.", "labels": [], "entities": []}, {"text": "Then, we describe in Section 3 the phrase-based MT decoder that we designed to handle TPs.", "labels": [], "entities": [{"text": "MT decoder", "start_pos": 48, "end_pos": 58, "type": "TASK", "confidence": 0.7674345672130585}]}, {"text": "We report in Section 4 the experiments we conducted combining standard phrase pairs and TPs.", "labels": [], "entities": []}, {"text": "We discuss this work in Section 5 and then conclude in Section 6.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Main characteristics of the corpora used in  this study. For each language l, l-toks is the number  of tokens, l-toks/sent is the average number of to- kens per sentence (\u00b1 the standard deviation), l-types  is the number of different token forms and l-hapax  is the number of tokens that appear only once in the  corpus.", "labels": [], "entities": []}, {"text": " Table 2: Median WER, SER and BLEU scores  (\u00b1 value range) of the translations produced by the  two engines on a test set of 16 disjoint corpora of  500 sentences each. The figures reported are per- centages.", "labels": [], "entities": [{"text": "WER", "start_pos": 17, "end_pos": 20, "type": "METRIC", "confidence": 0.9156241416931152}, {"text": "SER", "start_pos": 22, "end_pos": 25, "type": "METRIC", "confidence": 0.9982317090034485}, {"text": "BLEU", "start_pos": 30, "end_pos": 34, "type": "METRIC", "confidence": 0.998627781867981}]}]}