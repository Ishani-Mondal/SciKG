{"title": [{"text": "Fully Automatic Lexicon Expansion for Domain-oriented Sentiment Analysis", "labels": [], "entities": [{"text": "Domain-oriented Sentiment Analysis", "start_pos": 38, "end_pos": 72, "type": "TASK", "confidence": 0.6832435429096222}]}], "abstractContent": [{"text": "This paper proposes an unsupervised lexicon building method for the detection of polar clauses, which convey positive or negative aspects in a specific domain.", "labels": [], "entities": []}, {"text": "The lexical entries to be acquired are called polar atoms, the minimum human-understandable syntactic structures that specify the polarity of clauses.", "labels": [], "entities": []}, {"text": "As a clue to obtain candidate polar atoms, we use context coherency, the tendency for same polarities to appear successively in contexts.", "labels": [], "entities": []}, {"text": "Using the overall density and precision of co-herency in the corpus, the statistical estimation picks up appropriate polar atoms among candidates, without any manual tuning of the threshold values.", "labels": [], "entities": [{"text": "precision", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.9991381168365479}]}, {"text": "The experimental results show that the precision of polarity assignment with the automatically acquired lexicon was 94% on average, and our method is robust for corpora in diverse domains and for the size of the initial lexicon.", "labels": [], "entities": [{"text": "precision", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.999160885810852}, {"text": "polarity assignment", "start_pos": 52, "end_pos": 71, "type": "TASK", "confidence": 0.7005134224891663}]}], "introductionContent": [{"text": "Sentiment Analysis (SA) ( ) is a task to recognize writers' feelings as expressed in positive or negative comments, by analyzing unreadably large numbers of documents.", "labels": [], "entities": [{"text": "Sentiment Analysis (SA)", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8867524266242981}]}, {"text": "Extensive syntactic patterns enable us to detect sentiment expressions and to convert them into semantic structures with high precision, as reported by.", "labels": [], "entities": [{"text": "precision", "start_pos": 126, "end_pos": 135, "type": "METRIC", "confidence": 0.9914787411689758}]}, {"text": "From the example Japanese sentence (1) in the digital camera domain, the SA system extracts a sentiment representation as, which consists of a predicate and an argument with positive (+) polarity.", "labels": [], "entities": []}, {"text": "(1) Kono kamera-ha subarashii-to omou.", "labels": [], "entities": []}, {"text": "'I think this camera is splendid.'", "labels": [], "entities": []}, {"text": "(2) splendid(camera) SA in general tends to focus on subjective sentiment expressions, which explicitly describe an author's preference as in the above example (1).", "labels": [], "entities": [{"text": "splendid(camera) SA", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.5843830883502961}]}, {"text": "Objective (or factual) expressions such as in the following examples (3) and (4) maybe out of scope even though they describe desirable aspects in a specific domain.", "labels": [], "entities": []}, {"text": "However, when customers or corporate users use SA system for their commercial activities, such domain-specific expressions have a more important role, since they convey strong or weak points of the product more directly, and may influence their choice to purchase a specific product, as an example.", "labels": [], "entities": []}, {"text": "(3) Kontorasuto-ga kukkiri-suru.The contrast is sharp.'", "labels": [], "entities": []}, {"text": "(4) Atarashii kishu-ha zuumu-mo tsuite-iru.The new model has a zoom lens, too.'", "labels": [], "entities": [{"text": "Atarashii kishu-ha zuumu-mo tsuite-iru.The", "start_pos": 4, "end_pos": 46, "type": "TASK", "confidence": 0.5688598230481148}]}, {"text": "This paper addresses the Japanese version of Domain-oriented Sentiment Analysis, which identifies polar clauses conveying goodness and badness in a specific domain, including rather objective expressions.", "labels": [], "entities": [{"text": "Domain-oriented Sentiment Analysis", "start_pos": 45, "end_pos": 79, "type": "TASK", "confidence": 0.6424644986788431}]}, {"text": "Building domain-dependent lexicons for many domains is much harder work than preparing domainindependent lexicons and syntactic patterns, because the possible lexical entries are too numerous, and they may differ in each domain.", "labels": [], "entities": []}, {"text": "To solve this problem, we have devised an unsupervised method to acquire domaindependent lexical knowledge where a user has only to collect unannotated domain corpora.", "labels": [], "entities": []}, {"text": "The knowledge to be acquired is a domaindependent set of polar atoms.", "labels": [], "entities": []}, {"text": "A polar atom is a minimum syntactic structure specifying polarity in a predicative expression.", "labels": [], "entities": []}, {"text": "For example, to detect polar clauses in the sentences and (4) 1 , the following polar atoms (5) and should appear in the lexicon: (5) kukkiri-suru 'to be sharp' (6) tsuku \u2190 zuumu-ga 'to have \u2190 zoom lens-NOM' The polar atom (5) specified the positive polarity of the verb kukkiri-suru.", "labels": [], "entities": []}, {"text": "This atom can be generally used for this verb regardless of its arguments.", "labels": [], "entities": []}, {"text": "In the polar atom (6), on the other hand, the nominative case of the verb tsuku ('have') is limited to a specific noun zuumu ('zoom lens'), since the verb tsuku does not hold the polarity in itself.", "labels": [], "entities": []}, {"text": "The automatic decision for the scopes of the atoms is one of the major issues.", "labels": [], "entities": []}, {"text": "For lexical learning from unannotated corpora, our method uses context coherency in terms of polarity, an assumption that polar clauses with the same polarity appear successively unless the context is changed with adversative expressions.", "labels": [], "entities": []}, {"text": "Exploiting this tendency, we can collect candidate polar atoms with their tentative polarities as those adjacent to the polar clauses which have been identified by their domain-independent polar atoms in the initial lexicon.", "labels": [], "entities": []}, {"text": "We use both intrasentential and inter-sentential contexts to obtain more candidate polar atoms.", "labels": [], "entities": []}, {"text": "Our assumption is intuitively reasonable, but there are many non-polar (neutral) clauses adjacent to polar clauses.", "labels": [], "entities": []}, {"text": "Errors in sentence delimitation or syntactic parsing also result in false candidate atoms.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 35, "end_pos": 52, "type": "TASK", "confidence": 0.7187071293592453}]}, {"text": "Thus, to adopt a candidate polar atom for the new lexicon, some threshold values for the frequencies or ratios are required, but they depend on the type of the corpus, the size of the initial lexicon, etc.", "labels": [], "entities": []}, {"text": "Our algorithm is fully automatic in the sense that the criteria for the adoption of polar atoms are set automatically by statistical estimation based on the distributions of coherency: coherent precision and coherent density.", "labels": [], "entities": [{"text": "precision", "start_pos": 194, "end_pos": 203, "type": "METRIC", "confidence": 0.6940728425979614}]}, {"text": "No manual tuning process is required, so the algorithm only needs unannotated domain corpora and the initial lexicon.", "labels": [], "entities": []}, {"text": "Thus our learning method can be used not only by the developers of the system, but also by endusers.", "labels": [], "entities": []}, {"text": "This feature is very helpful for users to analyze documents in new domains.", "labels": [], "entities": []}, {"text": "In the next section, we review related work, and Section 3 describes our runtime SA system.", "labels": [], "entities": []}, {"text": "In Section 4, our assumption for unsupervised learning, context coherency and its key metrics, coherent precision and coherent density are discussed.", "labels": [], "entities": [{"text": "precision", "start_pos": 104, "end_pos": 113, "type": "METRIC", "confidence": 0.7596501708030701}]}, {"text": "Section 5 describes our unsupervised learning method.", "labels": [], "entities": []}, {"text": "Experimental results are shown in Section 6, and we conclude in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "First we propose a method of evaluation of the lexical learning.", "labels": [], "entities": []}, {"text": "The criteria for the negative atoms are analogous.", "labels": [], "entities": []}, {"text": "8 nCr notation is used here for combination (n choose k).", "labels": [], "entities": []}, {"text": "It is costly to make consistent and large 'gold standards' in multiple domains, especially in identification tasks such as clauselevel SA (cf. classification tasks).", "labels": [], "entities": [{"text": "clauselevel SA (cf. classification tasks", "start_pos": 123, "end_pos": 163, "type": "TASK", "confidence": 0.7049094984928767}]}, {"text": "Therefore we evaluated the learning results by asking human annotators to classify the acquired polar atoms as positive, negative, and neutral, instead of the instances of polar clauses detected with the new lexicon.", "labels": [], "entities": []}, {"text": "This can be done because the polar atoms themselves are informative enough to imply to humans whether the expressions hold positive or negative meanings in the domain.", "labels": [], "entities": []}, {"text": "To justify the reliability of this evaluation method, two annotators 9 evaluated 200 randomly selected candidate polar atoms in the digital camera domain.", "labels": [], "entities": []}, {"text": "The agreement results are shown in.", "labels": [], "entities": []}, {"text": "The manual classification was agreed upon in 89% of the cases and the Kappa value was 0.83, which is high enough to be considered consistent.", "labels": [], "entities": [{"text": "Kappa value", "start_pos": 70, "end_pos": 81, "type": "METRIC", "confidence": 0.9751994907855988}, {"text": "consistent", "start_pos": 130, "end_pos": 140, "type": "METRIC", "confidence": 0.9697499871253967}]}, {"text": "Using manual judgment of the polar atoms, we evaluated the performance with the following three metrics.  icon.", "labels": [], "entities": []}, {"text": "Relative recall will be 1 when no new polar atom is acquired.", "labels": [], "entities": [{"text": "Relative", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9566654562950134}, {"text": "recall", "start_pos": 9, "end_pos": 15, "type": "METRIC", "confidence": 0.8845894932746887}]}, {"text": "Since the precision was high enough, this metric can be used for approximation of the recall, which is hard to evaluate in extraction tasks such as clause-/phrase-level SA.", "labels": [], "entities": [{"text": "precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9993777275085449}, {"text": "recall", "start_pos": 86, "end_pos": 92, "type": "METRIC", "confidence": 0.9990513920783997}, {"text": "clause-/phrase-level SA", "start_pos": 148, "end_pos": 171, "type": "TASK", "confidence": 0.5493033155798912}]}, {"text": "As seen in the agreement study, the polar atoms used in our study were intrinsically meaningful to humans.", "labels": [], "entities": []}, {"text": "This is because the atoms are predicate-argument structures derived from predicative clauses, and thus humans could imagine the meaning of a polar atom by generating the corresponding sentence in its predicative form.", "labels": [], "entities": []}, {"text": "In the evaluation process, some interesting results were observed.", "labels": [], "entities": []}, {"text": "For example, a negative atom nai \u2190 kerare-ga ('to be free from vignetting') was acquired in the digital camera domain.", "labels": [], "entities": []}, {"text": "Even the evaluator who was familiar with digital cameras did not know the term kerare ('vignetting'), but after looking up the dictionary she labeled it as negative.", "labels": [], "entities": []}, {"text": "Our learning method could pickup such technical terms and labeled them appropriately.", "labels": [], "entities": []}, {"text": "Also, there were discoveries in the error analysis.", "labels": [], "entities": []}, {"text": "An evaluator assigned positive to aru \u2190 kamera-ga ('to have camera') in the mobile phone domain, but the acquired polar atom had the negative polarity.", "labels": [], "entities": []}, {"text": "This was actually an insight from the recent opinions that many users want phones without camera functions 11 .", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Inter-sentential adversative expres- sions.", "labels": [], "entities": []}, {"text": " Table 3: The corpora from four domains  used in this paper. The \"Post.\" and \"Sent.\"  columns denote the numbers of postings and  sentences, respectively. \"Len.\" is the average  length of sentences (in Japanese characters).", "labels": [], "entities": []}, {"text": " Table 4: Coherent precision with various view- points of contexts.", "labels": [], "entities": [{"text": "precision", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.9817832112312317}]}, {"text": " Table 5: Coherent precision and coherent den- sity for each domain.", "labels": [], "entities": [{"text": "precision", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.9866575598716736}]}, {"text": " Table 6: Examples of candidate polar atoms  and their frequencies. '*' denotes that it  should not be added to the lexicon. f (a), p(a),", "labels": [], "entities": []}, {"text": " Table 7: Agreement of two annotators' judg- ments of 200 polar atoms. \u03ba=0.83.", "labels": [], "entities": [{"text": "Agreement", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9510747790336609}, {"text": "judg- ments", "start_pos": 39, "end_pos": 50, "type": "METRIC", "confidence": 0.9277724822362264}]}, {"text": " Table 8: Evaluation results with our method.  The column '#' denotes the number of polar  atoms acquired in each domain.", "labels": [], "entities": []}, {"text": " Table 9: Evaluation results for various sizes of  the initial lexicon (the digital camera domain).", "labels": [], "entities": []}]}