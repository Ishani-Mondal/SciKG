{"title": [{"text": "A Discriminative Model for Tree-to-Tree Translation", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper proposes a statistical, tree-to-tree model for producing translations.", "labels": [], "entities": []}, {"text": "Two main contributions are as follows: (1) a method for the extraction of syntactic structures with alignment information from a parallel corpus of translations, and (2) use of a discriminative, feature-based model for prediction of these target-language syntactic structures-which we call aligned extended projections, or AEPs.", "labels": [], "entities": []}, {"text": "An evaluation of the method on translation from German to English shows similar performance to the phrase-based model of Koehn et al.", "labels": [], "entities": [{"text": "translation from German to English", "start_pos": 31, "end_pos": 65, "type": "TASK", "confidence": 0.8953620076179505}]}], "introductionContent": [{"text": "Phrase-based approaches () to statistical machine translation (SMT) have recently achieved impressive results, leading to significant improvements inaccuracy over the original IBM models (.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 30, "end_pos": 67, "type": "TASK", "confidence": 0.8269738356272379}]}, {"text": "However, phrase-based models lack a direct representation of syntactic information in the source or target languages; this has prompted several researchers to consider various approaches that make use of syntactic information.", "labels": [], "entities": []}, {"text": "This paper describes a framework for tree-totree based statistical translation.", "labels": [], "entities": [{"text": "statistical translation", "start_pos": 55, "end_pos": 78, "type": "TASK", "confidence": 0.7078760117292404}]}, {"text": "Our goal is to learn a model that maps parse trees in the source language to parse trees in the target language.", "labels": [], "entities": []}, {"text": "The model is learned from a corpus of translation pairs, where each sentence in the source or target language has an associated parse tree.", "labels": [], "entities": []}, {"text": "We see two major benefits of tree-to-tree based translation.", "labels": [], "entities": [{"text": "tree-to-tree based translation", "start_pos": 29, "end_pos": 59, "type": "TASK", "confidence": 0.673736035823822}]}, {"text": "First, it is possible to explicitly model the syntax of the target language, thereby improving grammaticality.", "labels": [], "entities": []}, {"text": "Second, we can build a detailed model of the correspondence between the source and target parse trees, with the aim of constructing translations that preserve the meaning of source language sentences.", "labels": [], "entities": []}, {"text": "Our translation framework involves a process where the target-language parse tree is broken down into a sequence of clauses, and each clause is then translated separately.", "labels": [], "entities": []}, {"text": "A central concept we introduce in the translation of clauses is that of an aligned extended projection (AEP).", "labels": [], "entities": [{"text": "AEP", "start_pos": 104, "end_pos": 107, "type": "METRIC", "confidence": 0.841553270816803}]}, {"text": "AEPs are derived from the concept of an extended projection in lexicalized tree adjoining grammars (LTAG), with the addition of alignment information that is based on work in synchronous LTAG.", "labels": [], "entities": []}, {"text": "A key contribution of this paper is a method for learning to map German clauses to AEPs using a featurebased model with a perceptron learning algorithm.", "labels": [], "entities": []}, {"text": "We performed experiments on translation from German to English on the Europarl data set.", "labels": [], "entities": [{"text": "translation from German to English", "start_pos": 28, "end_pos": 62, "type": "TASK", "confidence": 0.882787549495697}, {"text": "Europarl data set", "start_pos": 70, "end_pos": 87, "type": "DATASET", "confidence": 0.9969064195950826}]}, {"text": "Evaluation in terms of both BLEU scores and human judgments shows that our system performs similarly to the phrase-based model of.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 28, "end_pos": 32, "type": "METRIC", "confidence": 0.9980782270431519}]}], "datasetContent": [{"text": "We applied the approach to translation from German to English, using the Europarl corpus () for our training data.", "labels": [], "entities": [{"text": "translation from German to English", "start_pos": 27, "end_pos": 61, "type": "TASK", "confidence": 0.8591842770576477}, {"text": "Europarl corpus", "start_pos": 73, "end_pos": 88, "type": "DATASET", "confidence": 0.986906498670578}]}, {"text": "This corpus contains over 750,000 training sentences; we extracted over 441,000 training examples for the AEP model from this corpus, using the method described in section 4.", "labels": [], "entities": []}, {"text": "We reserved 35,000 of these training examples as development data for the model.", "labels": [], "entities": []}, {"text": "We used a set of features derived from the those described in section 5.2.", "labels": [], "entities": []}, {"text": "This set was optimized using the development data through experimentation with several different feature subsets.", "labels": [], "entities": []}, {"text": "Modifiers within German clauses were translated using the phrase-based model of.", "labels": [], "entities": []}, {"text": "We first generated n-best lists for each modifier.", "labels": [], "entities": []}, {"text": "We then built a reranking model-see section 6-to choose between the elements in the n-best lists.", "labels": [], "entities": []}, {"text": "The reranker was trained using around 800 labeled examples from a development set.", "labels": [], "entities": []}, {"text": "The test data for the experiments consisted of 2,000 sentences, and was the same test set as that used by.", "labels": [], "entities": []}, {"text": "We use the model of as a baseline for our experiments.", "labels": [], "entities": []}, {"text": "The AEP-driven model was used to translate all test set sentences where all clauses within the German parse tree contained at least one verb and there was no embedding of clausesthere were 1,335 sentences which met these criteria.", "labels": [], "entities": [{"text": "AEP-driven", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.8531747460365295}]}, {"text": "The remaining 665 sentences were translated with the baseline system.", "labels": [], "entities": []}, {"text": "This set of 2,000 translations had a BLEU score of 23.96.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 37, "end_pos": 47, "type": "METRIC", "confidence": 0.9803608655929565}]}, {"text": "The baseline system alone achieved a BLEU score of 25.26 on the same set of 2,000 test sentences.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 37, "end_pos": 47, "type": "METRIC", "confidence": 0.9855735898017883}]}, {"text": "We also obtained judgments from two human annotators on 100 randomly-drawn sentences on which the baseline and AEP-based outputs differed.", "labels": [], "entities": [{"text": "AEP-based", "start_pos": 111, "end_pos": 120, "type": "METRIC", "confidence": 0.8321563005447388}]}, {"text": "For each example the annotator viewed the reference translation, together with the two systems' translations presented in a random order.", "labels": [], "entities": []}, {"text": "Annotator 1 judged 62 translations to be equal in quality, 16 translations to be better under the AEP system, and 22 to be better for the baseline system.", "labels": [], "entities": [{"text": "Annotator", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9175710678100586}, {"text": "AEP system", "start_pos": 98, "end_pos": 108, "type": "DATASET", "confidence": 0.8146554827690125}]}, {"text": "Annotator 2 judged 37 translations to be equal in quality, 32 to be better under the baseline, and 31 to be better under the AEP-based system.", "labels": [], "entities": [{"text": "Annotator", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9116988778114319}, {"text": "AEP-based", "start_pos": 125, "end_pos": 134, "type": "DATASET", "confidence": 0.7567533850669861}]}], "tableCaptions": []}