{"title": [{"text": "Generating Multiple-Choice Test Items from Medical Text: A Pilot Study", "labels": [], "entities": []}], "abstractContent": [{"text": "We report the results of a pilot study on generating Multiple-Choice Test Items from medical text and discuss the main tasks involved in this process and how our system was evaluated by domain experts.", "labels": [], "entities": []}], "introductionContent": [{"text": "Although Multiple-Choice Test Items (MCTIs) are used daily for assessment, authoring them is a laborious task.", "labels": [], "entities": []}, {"text": "This gave rise to a relatively new research area within the emerging field of Textto-Text Generation (TTG) called Multiple-Choice Test Item Generation (MCTIG).", "labels": [], "entities": [{"text": "Textto-Text Generation (TTG)", "start_pos": 78, "end_pos": 106, "type": "TASK", "confidence": 0.8256531238555909}, {"text": "Multiple-Choice Test Item Generation (MCTIG)", "start_pos": 114, "end_pos": 158, "type": "TASK", "confidence": 0.7302111600126538}]}, {"text": "(2006) developed a system which detects the important concepts in a text automatically and produces MCTIs testing explicitly conveyed factual knowledge.", "labels": [], "entities": []}, {"text": "This differs from most related work in MCTIG such as and the papers in BEAUNLP-II (2005) which deploy various NLP techniques to produce MCTIs for vocabulary assessment, often using preselected words as the input (see Mitkov et al. for more extensive comparisons).", "labels": [], "entities": [{"text": "BEAUNLP-II", "start_pos": 71, "end_pos": 81, "type": "METRIC", "confidence": 0.9390639066696167}, {"text": "vocabulary assessment", "start_pos": 146, "end_pos": 167, "type": "TASK", "confidence": 0.7160170078277588}]}, {"text": "The approach of Mitkov et al. is semi-automatic since the MCTIs have to be reviewed by domain experts to assess their usability.", "labels": [], "entities": []}, {"text": "They report that semi-automatic MCTIG can be more than 3 times quicker than authoring of MCTIs without the aid of their system.", "labels": [], "entities": [{"text": "MCTIG", "start_pos": 32, "end_pos": 37, "type": "TASK", "confidence": 0.8996483087539673}]}, {"text": "1 TTG, in which surface text is used as the input to algorithms for text production, contrasts with Conceptto-Text Generation (better known as Natural Language Generation) which is concerned with the automatic production of text from some underlying non-linguistic representation of information Moreover, analysis of MCTIs produced semiautomatically and used in the classroom reveals that their educational value is not compromised in exchange for time and labour savings.", "labels": [], "entities": [{"text": "text production", "start_pos": 68, "end_pos": 83, "type": "TASK", "confidence": 0.7223517596721649}, {"text": "Conceptto-Text Generation", "start_pos": 100, "end_pos": 125, "type": "TASK", "confidence": 0.8090087473392487}, {"text": "Natural Language Generation", "start_pos": 143, "end_pos": 170, "type": "TASK", "confidence": 0.6922546227773031}]}, {"text": "In fact, the semi-automatically produced MCTIs turnout to fare better than MCTIs produced without the aid of the system in certain aspects of item quality.", "labels": [], "entities": []}, {"text": "This paper reports the results of a pilot study on generating MCTIs from medical text which builds on the work of Mitkov et al.", "labels": [], "entities": [{"text": "MCTIs from medical text", "start_pos": 62, "end_pos": 85, "type": "TASK", "confidence": 0.8102888762950897}]}], "datasetContent": [{"text": "RIG is a simple system which often avoids tough problems such as dealing with key-terms in syntactic positions that might puzzle the parser or might be too difficult to question upon.", "labels": [], "entities": [{"text": "RIG", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.4835473299026489}]}, {"text": "So how does it actually perform?", "labels": [], "entities": []}, {"text": "Three experts in producing MCTIs for medical assessment jointly reviewed 279 MCTIs (each featuring four distractors) generated by the system.", "labels": [], "entities": []}, {"text": "Three chapters from a medical textbook served as the source texts while a much larger collection of MEDLINE texts was used as the reference corpus.", "labels": [], "entities": [{"text": "MEDLINE texts", "start_pos": 100, "end_pos": 113, "type": "DATASET", "confidence": 0.8577796518802643}]}, {"text": "The domain experts regarded a MCTI as unusable if it could not be used in a test or required too much revision to do so.", "labels": [], "entities": []}, {"text": "The remaining items were considered to be usable and could be postedited by the experts to improve their content and readability or replace inappropriate distractors.", "labels": [], "entities": []}, {"text": "As shows, more than half of the items in total were judged to be usable.", "labels": [], "entities": []}, {"text": "Additionally, about one fifth of the usable items did not require any editing.", "labels": [], "entities": []}, {"text": "The shows the total number of key-terms identified in each chapter as well as the average number of distractors replaced per term.", "labels": [], "entities": []}, {"text": "The last column of reports on the efficiency of MCTIG in our domain.", "labels": [], "entities": []}, {"text": "This variable is calculated by dividing the total time it took the experts to review all MCTIs by the amount of usable items which represent the actual endproduct.", "labels": [], "entities": []}, {"text": "This is a bit longer than 3 minutes per usable item across all chapters.", "labels": [], "entities": []}, {"text": "Anecdotal evidence and the experts' own estimations suggest that it normally takes them at least 10 minutes to produce an MCTI manually.", "labels": [], "entities": [{"text": "estimations", "start_pos": 40, "end_pos": 51, "type": "METRIC", "confidence": 0.984806478023529}, {"text": "MCTI", "start_pos": 122, "end_pos": 126, "type": "TASK", "confidence": 0.780718207359314}]}, {"text": "Given the distinct domains in which our system and the one of Mitkov et al. were deployed (as well as the differences between them), a direct comparison between them could be misleading.", "labels": [], "entities": []}, {"text": "We note, however, that our usability scores are always higher than their worst score (30%) and quite close to their best score (57%).", "labels": [], "entities": []}, {"text": "The amount of directly usable items in Mitkov et al. was between just 3.5% and 5%, much lower than what we achieved.", "labels": [], "entities": []}, {"text": "They also report an almost 3-fold improvement in efficiency for computeraided MCTIG, which is very similar to our estimate.", "labels": [], "entities": []}, {"text": "These results indicate what our work has contributed to the state of the art in MCTIG.", "labels": [], "entities": [{"text": "MCTIG", "start_pos": 80, "end_pos": 85, "type": "DATASET", "confidence": 0.7845712900161743}]}, {"text": "In our future work, we aim to address the following issues: (a) As in Mitkov et al., the anchor of a MCTI produced by RIG always corresponds to a key-term.", "labels": [], "entities": []}, {"text": "However, the domain experts pointed out several cases in which it is better for the key-term to stay in the stem and for another less prominent concept to serve as the answer.", "labels": [], "entities": []}, {"text": "(b) Students who simply memorise the input chapter might be able to answer the MCTI if its surface form is too close to the source clause so another interesting suggestion was to paraphrase the stem during MCTIG.", "labels": [], "entities": [{"text": "answer the MCTI", "start_pos": 68, "end_pos": 83, "type": "TASK", "confidence": 0.4852591852347056}]}, {"text": "(c) We also intend to introduce greater variability in our process for distractor selection by investigating several other measures of semantic similarity.", "labels": [], "entities": [{"text": "distractor selection", "start_pos": 71, "end_pos": 91, "type": "TASK", "confidence": 0.6812091171741486}]}], "tableCaptions": [{"text": " Table 2: Usability and efficiency of Multiple-Choice Test Item Generation from medical text.", "labels": [], "entities": [{"text": "Multiple-Choice Test Item Generation", "start_pos": 38, "end_pos": 74, "type": "TASK", "confidence": 0.6067510321736336}]}]}