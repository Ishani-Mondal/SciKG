{"title": [{"text": "The impact of parse quality on syntactically-informed statistical machine translation", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 54, "end_pos": 85, "type": "TASK", "confidence": 0.6183168292045593}]}], "abstractContent": [{"text": "We investigate the impact of parse quality on a syntactically-informed statistical machine translation system applied to technical text.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 71, "end_pos": 102, "type": "TASK", "confidence": 0.6410481234391531}]}, {"text": "We vary parse quality by varying the amount of data used to train the parser.", "labels": [], "entities": []}, {"text": "As the amount of data increases, parse quality improves, leading to improvements in machine translation output and results that significantly outperform a state-of-the-art phrasal baseline.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 84, "end_pos": 103, "type": "TASK", "confidence": 0.7041548192501068}]}], "introductionContent": [{"text": "The current study is a response to a question that proponents of syntactically-informed machine translation frequently encounter: How sensitive is a syntactically-informed machine translation system to the quality of the input syntactic analysis?", "labels": [], "entities": [{"text": "machine translation", "start_pos": 88, "end_pos": 107, "type": "TASK", "confidence": 0.6934812217950821}, {"text": "machine translation", "start_pos": 172, "end_pos": 191, "type": "TASK", "confidence": 0.7159021645784378}]}, {"text": "It has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (.", "labels": [], "entities": [{"text": "phrasal machine translation", "start_pos": 23, "end_pos": 50, "type": "TASK", "confidence": 0.7063059608141581}]}, {"text": "This finding has generally been cast in favorable terms: such systems are robust to poor quality word alignment.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 97, "end_pos": 111, "type": "TASK", "confidence": 0.710751473903656}]}, {"text": "A less favorable interpretation of these results might be to conclude that phrasal statistical machine translation (SMT) systems do not stand to benefit from improvements in word alignment.", "labels": [], "entities": [{"text": "phrasal statistical machine translation (SMT)", "start_pos": 75, "end_pos": 120, "type": "TASK", "confidence": 0.7628293633460999}, {"text": "word alignment", "start_pos": 174, "end_pos": 188, "type": "TASK", "confidence": 0.7652860283851624}]}, {"text": "Ina similar vein, one might ask whether contemporary syntactically-informed machine translation systems would benefit from improvements in parse accuracy.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 76, "end_pos": 95, "type": "TASK", "confidence": 0.7168256044387817}, {"text": "accuracy", "start_pos": 145, "end_pos": 153, "type": "METRIC", "confidence": 0.8662267327308655}]}, {"text": "One possibility is that current syntactically-informed SMT systems are deriving only limited value from the syntactic analyses, and would therefore not benefit from improved analyses.", "labels": [], "entities": [{"text": "SMT", "start_pos": 55, "end_pos": 58, "type": "TASK", "confidence": 0.9393795728683472}]}, {"text": "Another possibility is that syntactic analysis does indeed contain valuable information that could be exploited by machine learning techniques, but that current parsers are not of sufficient quality to be of use in SMT.", "labels": [], "entities": [{"text": "syntactic analysis", "start_pos": 28, "end_pos": 46, "type": "TASK", "confidence": 0.7185953557491302}, {"text": "SMT", "start_pos": 215, "end_pos": 218, "type": "TASK", "confidence": 0.9947722554206848}]}, {"text": "With these questions and concerns, let us begin.", "labels": [], "entities": []}, {"text": "Following some background discussion we describe a set of experiments intended to elucidate the impact of parse quality on SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 123, "end_pos": 126, "type": "TASK", "confidence": 0.9910907745361328}]}], "datasetContent": [{"text": "Our goal in the current paper is to measure the impact of parse quality on syntactically-informed statistical machine translation.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 98, "end_pos": 129, "type": "TASK", "confidence": 0.5913803080717722}]}, {"text": "One method for producing parsers of varying quality might be to train a parser and then to transform its output, e.g. by replacing the parser's selection of the parent for certain tokens with different nodes.", "labels": [], "entities": []}, {"text": "Rather than randomly adding noise to the parses, we decided to vary the quality in ways that more closely mimic the situation that confronts us as we develop machine translation systems.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 158, "end_pos": 177, "type": "TASK", "confidence": 0.7070327699184418}]}, {"text": "Annotating data for POS requires considerably less human time and expertise than annotating syntactic relations.", "labels": [], "entities": [{"text": "POS", "start_pos": 20, "end_pos": 23, "type": "TASK", "confidence": 0.877395749092102}]}, {"text": "We therefore used an automatic POS tagger () trained on the complete training section of the Penn Treebank (sections 02-21).", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 31, "end_pos": 41, "type": "TASK", "confidence": 0.7300473153591156}, {"text": "Penn Treebank", "start_pos": 93, "end_pos": 106, "type": "DATASET", "confidence": 0.9686801135540009}]}, {"text": "Annotating syntactic dependencies is time consuming and requires considerable linguistic expertise.", "labels": [], "entities": [{"text": "Annotating syntactic dependencies", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.866596003373464}]}, {"text": "We can well imagine annotating syntactic dependencies in order to develop a machine translation system by annotating first a small quantity of data, training a parser, training a system that uses the parses produced by that parser and assessing the quality of the machine translation output.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 76, "end_pos": 95, "type": "TASK", "confidence": 0.7399218082427979}]}, {"text": "Having assessed the quality of the output, one might annotate additional data and train systems until it appears that the quality of the machine translation output is no longer improving.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 137, "end_pos": 156, "type": "TASK", "confidence": 0.6612450927495956}]}, {"text": "We therefore produced parsers of varying quality by training on the first n sentences of sections 02-21 of the Penn Treebank, where n ranged from 250 to 39,892 (the complete training section).", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 111, "end_pos": 124, "type": "DATASET", "confidence": 0.9136550724506378}]}, {"text": "At training time, the gold-standard POS tags were used.", "labels": [], "entities": [{"text": "POS tags", "start_pos": 36, "end_pos": 44, "type": "DATASET", "confidence": 0.70834581553936}]}, {"text": "For parser evaluation and for the machine translation experiments reported here, we used an automatic POS tagger () trained on sections 02-21 of the Penn Treebank.", "labels": [], "entities": [{"text": "parser evaluation", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.9454281628131866}, {"text": "machine translation", "start_pos": 34, "end_pos": 53, "type": "TASK", "confidence": 0.8062717020511627}, {"text": "POS tagger", "start_pos": 102, "end_pos": 112, "type": "TASK", "confidence": 0.5727163851261139}, {"text": "Penn Treebank", "start_pos": 149, "end_pos": 162, "type": "DATASET", "confidence": 0.8734983503818512}]}, {"text": "We trained English-to-German and English-toJapanese treelet translation systems on approximately 500,000 manually aligned sentence pairs drawn from technical computer documentation.", "labels": [], "entities": []}, {"text": "The sentence pairs consisted of the English source sentence and a human-translation of that sentence.", "labels": [], "entities": []}, {"text": "summarizes the characteristics of this data.", "labels": [], "entities": []}, {"text": "Note that German vocabulary and singleton counts are slightly more than double the corresponding English counts due to complex morphology and pervasive compounding (see section 2.3.1).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Parallel data characteristics", "labels": [], "entities": []}, {"text": " Table 2: BLEU score vs. decoder and parser vari- ants. Here sentences refer to the amount of parser  training data, not MT training data.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9731698334217072}, {"text": "MT training data", "start_pos": 121, "end_pos": 137, "type": "DATASET", "confidence": 0.6522900660832723}]}, {"text": " Table 3: Pairwise statistical significance tests. > indicates that the system on the top is significantly better  than the system on the left; < indicates that the system on top is significantly worse than the system on  the left; \u223c indicates that difference between the two systems is not statistically significant.", "labels": [], "entities": []}, {"text": " Table 4: Error analysis, showing percentage of  regressed and improved translations exhibiting a  parse improvement in each specified category", "labels": [], "entities": [{"text": "Error", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9627478718757629}]}]}