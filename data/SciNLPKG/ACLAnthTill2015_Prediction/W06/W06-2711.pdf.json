{"title": [{"text": "The SAMMIE Multimodal Dialogue Corpus Meets the Nite XML Toolkit", "labels": [], "entities": [{"text": "SAMMIE Multimodal Dialogue Corpus", "start_pos": 4, "end_pos": 37, "type": "DATASET", "confidence": 0.5523237660527229}, {"text": "Nite XML Toolkit", "start_pos": 48, "end_pos": 64, "type": "TASK", "confidence": 0.6247711181640625}]}], "abstractContent": [{"text": "We demonstrate work in progress 1 using the Nite XML Toolkit on a corpus of multimodal dialogues with an MP3 player collected in a Wizard-of-Oz (WOZ) experiments and annotated with a rich feature set at several layers.", "labels": [], "entities": []}, {"text": "We designed an NXT data model, converted experiment log file data and manual transcriptions into NXT, and are building annotation tools using NXT libraries.", "labels": [], "entities": []}], "introductionContent": [{"text": "In the TALK project we are developing a multimodal dialogue system for an MP3 application for in-car and in-home use.", "labels": [], "entities": []}, {"text": "The system should support natural, flexible interaction and collaborative behavior.", "labels": [], "entities": []}, {"text": "To achieve this, it needs to provide advanced adaptive multimodal output.", "labels": [], "entities": []}, {"text": "To determine the interaction strategies and range of linguistic behavior naturally occurring in this scenario, we conducted two WOZ experiments: SAMMIE-1 involved only spoken interaction, SAMMIE-2 was multimodal, with speech and screen input and output.", "labels": [], "entities": []}, {"text": "We have been annotating the corpus on several layers, representing linguistic, multimodal and context information.", "labels": [], "entities": []}, {"text": "The annotated corpus will be used (i) to investigate various aspects of Our demonstration results from the efforts of a larger team including also N. multimodal presentation and interaction strategies both within and across the annotation layers; (ii) to design an initial policy for reinforcement learning of multimodal clarifications.", "labels": [], "entities": []}, {"text": "We use the Nite XML Toolkit (NXT) () to represent and browse the data and to develop annotation tools.", "labels": [], "entities": [{"text": "Nite XML Toolkit (NXT)", "start_pos": 11, "end_pos": 33, "type": "TASK", "confidence": 0.6079674959182739}]}, {"text": "Below we briefly describe our experiment setup, the collected data and the annotation layers; we comment on methods and tools for data representation and annotation, and then present our NXT data model.", "labels": [], "entities": [{"text": "NXT data model", "start_pos": 187, "end_pos": 201, "type": "DATASET", "confidence": 0.8694484035174052}]}], "datasetContent": [{"text": "24 subjects in SAMMIE-1 and 35 in SAMMIE-2 performed several tasks with an MP3 player application simulated by a wizard.", "labels": [], "entities": [{"text": "SAMMIE-1", "start_pos": 15, "end_pos": 23, "type": "DATASET", "confidence": 0.8874281644821167}]}, {"text": "For SAMMIE-1 we had two, for SAMMIE-2 six wizards.", "labels": [], "entities": []}, {"text": "The tasks involved searching for titles and building playlists satisfying various constraints.", "labels": [], "entities": []}, {"text": "Each session was 30 minutes long.", "labels": [], "entities": []}, {"text": "Both users and wizards could speak freely.", "labels": [], "entities": []}, {"text": "The interactions were in German (although most of the titles and artist names in the database were English).", "labels": [], "entities": []}, {"text": "SAMMIE-2 had a more complex setup.", "labels": [], "entities": [{"text": "SAMMIE-2", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.7556682229042053}]}, {"text": "The tasks the subjects had to fulfill were divided in two classes: with vs. without operating a driving simulator.", "labels": [], "entities": []}, {"text": "When presenting the search results, the wizards were free to produce monoor multimodal output as they saw fit; they could speak freely and/or select one of four automatically generated screen outputs, which contained tables and lists of found songs/albums.", "labels": [], "entities": []}, {"text": "The users also had free choice between unconstrained natural language and/or selecting items on the screen.", "labels": [], "entities": []}, {"text": "Both wizard and user utterances were immediately transcribed.", "labels": [], "entities": []}, {"text": "The wizard's utterances were presented to the user via a speech synthesizer.", "labels": [], "entities": []}, {"text": "To simulate acoustic understanding problems, the wizard sometimes received only part of the transcribed user's utterance, to elicit CRs.", "labels": [], "entities": [{"text": "acoustic understanding", "start_pos": 12, "end_pos": 34, "type": "TASK", "confidence": 0.7399566471576691}]}, {"text": "(See () for details.)", "labels": [], "entities": []}], "tableCaptions": []}