{"title": [{"text": "The Hidden TAG Model: Synchronous Grammars for Parsing Resource-Poor Languages", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper discusses a novel probabilis-tic synchronous TAG formalism, synchronous Tree Substitution Grammar with sister adjunction (TSG+SA).", "labels": [], "entities": []}, {"text": "We use it to parse a language for which there is no training data, by leveraging off a second , related language for which there is abundant training data.", "labels": [], "entities": []}, {"text": "The grammar for the resource-rich side is automatically extracted from a treebank; the grammar on the resource-poor side and the synchronization are created by handwritten rules.", "labels": [], "entities": []}, {"text": "Our approach thus represents a combination of grammar-based and empirical natural language processing.", "labels": [], "entities": []}, {"text": "We discuss the approach using the example of Levantine Arabic and Standard Arabic.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "While our approach does not rely on any annotated corpus for LA, nor on a parallel corpus MSA-LA, we use a small treebank of LA () to analyze and test our approach.", "labels": [], "entities": []}, {"text": "The LA treebank is divided into a development corpus and a test corpus, each about 11,000 tokens (using the same tokenization scheme as employed in the MSA treebank).", "labels": [], "entities": [{"text": "LA treebank", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.9489769339561462}, {"text": "MSA treebank", "start_pos": 152, "end_pos": 164, "type": "DATASET", "confidence": 0.925575315952301}]}, {"text": "We first use the development corpus to determine which of the transformations are useful.", "labels": [], "entities": []}, {"text": "In the first, the input text is not tagged, and the parser hypothesizes tags.", "labels": [], "entities": []}, {"text": "In the second, the input text is tagged with the gold (correct) tag.", "labels": [], "entities": []}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "The baseline is simply the application of a pure MSA Chiang parser to LA.", "labels": [], "entities": []}, {"text": "We see that important improvements are obtained using the lexical mapping.", "labels": [], "entities": []}, {"text": "Adding the SVO transformation does not improve the results, but the NEG and BD transformations help slightly, and their effect is (partly) The evaluation on the test corpus confirms these results.", "labels": [], "entities": [{"text": "BD", "start_pos": 76, "end_pos": 78, "type": "METRIC", "confidence": 0.9835529327392578}]}, {"text": "Using the NEG and BD transformations and the small lexicon, we obtain a 17.3% error reduction relative to the baseline parser (.", "labels": [], "entities": [{"text": "BD", "start_pos": 18, "end_pos": 20, "type": "METRIC", "confidence": 0.8560243248939514}, {"text": "error reduction", "start_pos": 78, "end_pos": 93, "type": "METRIC", "confidence": 0.9638428688049316}]}, {"text": "These results show that the translation lexicon can be integrated effectively into our synchronous grammar framework.", "labels": [], "entities": []}, {"text": "In addition, some syntactic transformations are useful.", "labels": [], "entities": []}, {"text": "The SVO transformation, we assume, turns out not to be useful because the SVO word order is also possible in MSA, so that the new trees were not needed and needlessly introduced new derivations.", "labels": [], "entities": [{"text": "SVO transformation", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.6727463901042938}]}, {"text": "The BD transformation shows the importance not of general syntactic transformations, but rather of lexically specific syntactic transformations: varieties within one language family may differ more in terms of the lexico-syntactic constructions used fora specific (semantic or pragmatic) purpose than in their basic syntactic inventory.", "labels": [], "entities": []}, {"text": "Note that our tree-based synchronous formalism is ideally suited for expressing such transformations since it is lexicalized, and has an extended domain of locality.", "labels": [], "entities": []}, {"text": "Given the impact of the BD transformation, in future work we intend to determine more lexicostructural transformations, rather than pure syntactic transformations.", "labels": [], "entities": [{"text": "BD transformation", "start_pos": 24, "end_pos": 41, "type": "TASK", "confidence": 0.6966187357902527}]}, {"text": "However, one major impediment to obtaining better results is the disparity in genre and domain which affects the overall performance.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results on development corpus: LP = labeled precision, LR = labeled recall, F1 = balanced  F-measure", "labels": [], "entities": [{"text": "precision", "start_pos": 54, "end_pos": 63, "type": "METRIC", "confidence": 0.8762955069541931}, {"text": "recall", "start_pos": 78, "end_pos": 84, "type": "METRIC", "confidence": 0.9169508218765259}, {"text": "F1", "start_pos": 86, "end_pos": 88, "type": "METRIC", "confidence": 0.9987553358078003}, {"text": "F-measure", "start_pos": 101, "end_pos": 110, "type": "METRIC", "confidence": 0.9347760081291199}]}]}