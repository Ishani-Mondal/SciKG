{"title": [{"text": "Two graph-based algorithms for state-of-the-art WSD", "labels": [], "entities": [{"text": "WSD", "start_pos": 48, "end_pos": 51, "type": "TASK", "confidence": 0.951015055179596}]}], "abstractContent": [{"text": "This paper explores the use of two graph algorithms for unsupervised induction and tagging of nominal word senses based on corpora.", "labels": [], "entities": [{"text": "tagging of nominal word senses", "start_pos": 83, "end_pos": 113, "type": "TASK", "confidence": 0.800203824043274}]}, {"text": "Our main contribution is the optimization of the free parameters of those algorithms and its evaluation against publicly available gold standards.", "labels": [], "entities": []}, {"text": "We present a thorough evaluation comprising supervised and unsupervised modes, and both lexical-sample and all-words tasks.", "labels": [], "entities": []}, {"text": "The results show that, in spite of the information loss inherent to mapping the induced senses to the gold-standard, the optimization of parameters based on a small sample of nouns carries over to all nouns, performing close to supervised systems in the lexical sample task and yielding the second-best WSD systems for the Senseval-3 all-words task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word sense disambiguation (WSD) is a key enabling-technology.", "labels": [], "entities": [{"text": "Word sense disambiguation (WSD)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7964984973271688}]}, {"text": "Supervised WSD techniques are the best performing in public evaluations, but need large amounts of hand-tagged data.", "labels": [], "entities": [{"text": "WSD", "start_pos": 11, "end_pos": 14, "type": "TASK", "confidence": 0.9808448553085327}]}, {"text": "Existing hand-annotated corpora like SemCor (, which is annotated with WordNet senses) allow fora small improvement over the simple most frequent sense heuristic, as attested in the all-words track of the last Senseval competition ().", "labels": [], "entities": []}, {"text": "In theory, larger amounts of training data (SemCor has approx. 700K words) would improve the performance of supervised WSD, but no current project exists to provide such an expensive resource.", "labels": [], "entities": [{"text": "WSD", "start_pos": 119, "end_pos": 122, "type": "TASK", "confidence": 0.9224005937576294}]}, {"text": "Supervised WSD is based on the \"fixed-list of senses\" paradigm, where the senses fora target word area closed list coming from a dictionary or lexicon.", "labels": [], "entities": [{"text": "WSD", "start_pos": 11, "end_pos": 14, "type": "TASK", "confidence": 0.9132317304611206}]}, {"text": "Lexicographers and semanticists have long warned about the problems of such an approach, where senses are listed separately as discrete entities, and have argued in favor of more complex representations, where, for instance, senses are dense regions in a continuum.", "labels": [], "entities": []}, {"text": "Unsupervised WSD has followed this line of thinking, and tries to induce word senses directly from the corpus.", "labels": [], "entities": [{"text": "WSD", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.9596430063247681}]}, {"text": "Typical unsupervised WSD systems involve clustering techniques, which group together similar examples.", "labels": [], "entities": [{"text": "WSD", "start_pos": 21, "end_pos": 24, "type": "TASK", "confidence": 0.9667264223098755}]}, {"text": "Given a set of induced clusters (which represent word uses or senses 1 ), each new occurrence of the target word will be compared to the clusters and the most similar cluster will be selected as its sense.", "labels": [], "entities": []}, {"text": "Most of the unsupervised WSD work has been based on the vector space model, where each example is represented by a vector of features (e.g. the words occurring in the context), and the induced senses are either clusters of examples) or clusters of words (.", "labels": [], "entities": [{"text": "WSD", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.9219105839729309}]}, {"text": "Recently, V\u00e9ronis) has proposed HyperLex, an application of graph models to WSD based on the small-world properties of cooccurrence graphs.", "labels": [], "entities": [{"text": "WSD", "start_pos": 76, "end_pos": 79, "type": "TASK", "confidence": 0.8791239857673645}]}, {"text": "Graph-based methods have gained attention in several areas of NLP, including knowledge-based WSD) and summarization ().", "labels": [], "entities": [{"text": "WSD", "start_pos": 93, "end_pos": 96, "type": "TASK", "confidence": 0.6856305003166199}, {"text": "summarization", "start_pos": 102, "end_pos": 115, "type": "TASK", "confidence": 0.9836983680725098}]}, {"text": "The HyperLex algorithm presented in) is entirely corpus-based.", "labels": [], "entities": []}, {"text": "It builds a cooccurrence graph for all pairs of words cooccurring in the context of the target word.", "labels": [], "entities": []}, {"text": "V\u00e9ronis shows that this kind of graph fulfills the properties of small world graphs, and thus possesses highly connected components (hubs) in the graph.", "labels": [], "entities": []}, {"text": "These hubs eventually identify the main word uses (senses) of the target word, and can be used to perform word sense disambiguation.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 106, "end_pos": 131, "type": "TASK", "confidence": 0.717216561237971}]}, {"text": "These hubs are used as a representation of the senses induced by the system, the same way that clusters of examples are used to represent senses in clustering approaches to WSD).", "labels": [], "entities": []}, {"text": "One of the problems of unsupervised systems is that of managing to do a fair evaluation.", "labels": [], "entities": []}, {"text": "Most of current unsupervised systems are evaluated in-house, with a brief comparison to a reimplementation of a former system, leading to a proliferation of unsupervised systems with little ground to compare among them.", "labels": [], "entities": []}, {"text": "In preliminary work (), we have shown that HyperLex compares favorably to other unsupervised systems.", "labels": [], "entities": []}, {"text": "We defined a semi-supervised setting for optimizing the freeparameters of HyperLex on the Senseval-2 English Lexical Sample task (S2LS), which consisted on mapping the induced senses onto the official sense inventory using the training part of S2LS.", "labels": [], "entities": []}, {"text": "The best parameters were then used on the Senseval-3 English Lexical Sample task (S3LS), where a similar semi-supervised method was used to output the official sense inventory.", "labels": [], "entities": [{"text": "Senseval-3 English Lexical Sample task (S3LS)", "start_pos": 42, "end_pos": 87, "type": "TASK", "confidence": 0.6438695155084133}]}, {"text": "This paper extends the previous work in several aspects.", "labels": [], "entities": []}, {"text": "First of all, we adapted the PageRank graph-based method for WSD and compared it with HyperLex.", "labels": [], "entities": [{"text": "WSD", "start_pos": 61, "end_pos": 64, "type": "TASK", "confidence": 0.6364003419876099}, {"text": "HyperLex", "start_pos": 86, "end_pos": 94, "type": "DATASET", "confidence": 0.9180834293365479}]}, {"text": "We also extend the previous evaluation scheme, using measures in the clustering community which only require a gold standard clustering and no mapping step.", "labels": [], "entities": []}, {"text": "This allows for having a purely unsupervised WSD system, and at the same time comparing supervised and unsupervised systems according to clustering criteria.", "labels": [], "entities": []}, {"text": "We also include the Senseval-3 English Allwords testbed (S3AW), where, in principle, unsupervised and semi-supervised systems have an advantage over purely supervised systems due to the scarcity of training data.", "labels": [], "entities": [{"text": "Senseval-3 English Allwords testbed (S3AW", "start_pos": 20, "end_pos": 61, "type": "DATASET", "confidence": 0.7311302423477173}]}, {"text": "We show that our system is competitive with supervised systems, ranking second.", "labels": [], "entities": []}, {"text": "This paper is structured as follows.", "labels": [], "entities": []}, {"text": "We first present two graph-based algorithms, HyperLex and PageRank.", "labels": [], "entities": []}, {"text": "Section 3 presents the two evaluation frameworks.", "labels": [], "entities": []}, {"text": "Section 4 introduces parameter optimization.", "labels": [], "entities": [{"text": "parameter optimization", "start_pos": 21, "end_pos": 43, "type": "TASK", "confidence": 0.7352097630500793}]}, {"text": "Section 5 shows the experimental setting and results.", "labels": [], "entities": []}, {"text": "Section 6 analyzes the results and presents related work.", "labels": [], "entities": []}, {"text": "Finally, we draw the conclusions and advance future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this setting the selected hubs are treated as clusters of examples and gold standard senses are classes.", "labels": [], "entities": []}, {"text": "In order to compare the clusters with the classes, hand annotated corpora are needed (for instance Senseval).", "labels": [], "entities": []}, {"text": "The test set is first tagged with the induced senses.", "labels": [], "entities": []}, {"text": "A perfect clustering solution will be the one where each cluster has exactly the same examples as one of the classes, and vice versa.", "labels": [], "entities": []}, {"text": "The evaluation is completely unsupervised.", "labels": [], "entities": []}, {"text": "Following standard cluster evaluation practice (), we consider three measures: entropy, purity and Fscore.", "labels": [], "entities": [{"text": "purity", "start_pos": 88, "end_pos": 94, "type": "METRIC", "confidence": 0.9868091344833374}, {"text": "Fscore", "start_pos": 99, "end_pos": 105, "type": "METRIC", "confidence": 0.9990313053131104}]}, {"text": "The entropy measure considers how the various classes of objects are distributed within each cluster.", "labels": [], "entities": []}, {"text": "In general, the smaller the entropy value, the better the clustering algorithm performs.", "labels": [], "entities": []}, {"text": "The purity measure considers the extent to which each cluster contained objects from primarily one class.", "labels": [], "entities": [{"text": "purity measure", "start_pos": 4, "end_pos": 18, "type": "METRIC", "confidence": 0.9703889191150665}]}, {"text": "The larger the values of purity, the better the clustering algorithm performs.", "labels": [], "entities": []}, {"text": "The Fscore is used in a similar fashion to Information Retrieval exercises, with precision and recall defined as the percentage of correctly \"retrieved\" examples fora cluster (divided by total cluster size), and recall as the percentage of correctly \"retrieved\" examples fora cluster (divided by total class size).", "labels": [], "entities": [{"text": "Fscore", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.6722531318664551}, {"text": "Information Retrieval", "start_pos": 43, "end_pos": 64, "type": "TASK", "confidence": 0.8137072026729584}, {"text": "precision", "start_pos": 81, "end_pos": 90, "type": "METRIC", "confidence": 0.9994720816612244}, {"text": "recall", "start_pos": 95, "end_pos": 101, "type": "METRIC", "confidence": 0.9972164630889893}, {"text": "recall", "start_pos": 212, "end_pos": 218, "type": "METRIC", "confidence": 0.9988002777099609}]}, {"text": "For a formal definition refer to (.", "labels": [], "entities": []}, {"text": "If the clustering is identical to the original classes in the datasets, FScore will be equal to one which means that the higher the FScore, the better the clustering is.  hubs to senses) presents a straightforward framework that uses hand-tagged material in order to map the induced senses into the senses used in a gold standard . The WSD system first tags the training part of some hand-annotated corpus with the induced hubs.", "labels": [], "entities": [{"text": "FScore", "start_pos": 72, "end_pos": 78, "type": "METRIC", "confidence": 0.9954525828361511}, {"text": "FScore", "start_pos": 132, "end_pos": 138, "type": "METRIC", "confidence": 0.9882828593254089}]}, {"text": "The hand labels are then used to construct a matrix relating assigned hubs to existing senses, simply counting the times an occurrence with sense s j has been assigned hub hi . In the testing step we apply the WSD algorithm over the test corpus, using the hubs-to-senses matrix to select the sense with highest weights.", "labels": [], "entities": []}, {"text": "See () for further details.", "labels": [], "entities": []}, {"text": "To evaluate the HyperLex algorithm in a standard benchmark, we will first focus on a more extensive evaluation of S3LS and then seethe results in S3AW (cf. Sec. 5.4).", "labels": [], "entities": []}, {"text": "Following the design for evaluation explained in Section 3, we use the standard train-test split for the supervised evaluation, while the unsupervised evaluation only uses the test part.", "labels": [], "entities": []}, {"text": "In the columns we find the evaluation results according to our 4 criteria.", "labels": [], "entities": []}, {"text": "For supervised evaluation we indicate only recall, which in our case equals precision, as the coverage is 100% in all cases (values returned by the official Senseval scorer).", "labels": [], "entities": [{"text": "recall", "start_pos": 43, "end_pos": 49, "type": "METRIC", "confidence": 0.9994805455207825}, {"text": "precision", "start_pos": 76, "end_pos": 85, "type": "METRIC", "confidence": 0.9996668100357056}, {"text": "coverage", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.9732431173324585}]}, {"text": "We also include 2 baselines, a system returning a single cluster (that of the most frequent sense, MFS), and another returning one cluster for each example (1ex-1hub).", "labels": [], "entities": []}, {"text": "The last rows list the results for 3 supervised and 5 unsupervised systems (see Sect. 5.1).", "labels": [], "entities": []}, {"text": "We will comment on the result of this table from different perspectives.", "labels": [], "entities": []}, {"text": "In this subsection we will focus in the first four evaluation rows in.", "labels": [], "entities": []}, {"text": "All variants of the algorithm outperform by an ample margin the MFS and the 1ex-1hub baselines when evaluated on S3LS recall.", "labels": [], "entities": [{"text": "MFS", "start_pos": 64, "end_pos": 67, "type": "DATASET", "confidence": 0.876358151435852}]}, {"text": "This means that the method is able to learn useful hubs.", "labels": [], "entities": []}, {"text": "Note that we perform this supervised evaluation just for comparison with other systems, and to prove that we are able to provide high performance WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 146, "end_pos": 149, "type": "TASK", "confidence": 0.8359774351119995}]}, {"text": "The default parameter setting (Vr) gets the worst results, followed by the fixed-hub implementation of PageRank (Pr fx).", "labels": [], "entities": []}, {"text": "Pagerank with frequency threshold (Pr fr) and the optimized Veronis (Vr opt) obtain a 10 point improvement over the MFS baseline with very similar results (the difference is not statistically significant according to McNemar's test at 95% confidence level).", "labels": [], "entities": [{"text": "frequency threshold (Pr fr", "start_pos": 14, "end_pos": 40, "type": "METRIC", "confidence": 0.9039448142051697}, {"text": "Veronis (Vr opt", "start_pos": 60, "end_pos": 75, "type": "METRIC", "confidence": 0.928022712469101}, {"text": "MFS baseline", "start_pos": 116, "end_pos": 128, "type": "DATASET", "confidence": 0.7781899571418762}]}, {"text": "where obtained from the Senseval website, and the only processing we did was to filter nouns.", "labels": [], "entities": []}, {"text": "S3LS-best stands for the the winner of S3LS ( ), which is 8.3 points over our method.", "labels": [], "entities": [{"text": "S3LS-best", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.7151511311531067}]}, {"text": "We also include the results of two of our in-house systems.", "labels": [], "entities": []}, {"text": "kNN-all is a state-of-the-art system) using wide range of local and topical features, and only 2.3 points below the best S3LS system.", "labels": [], "entities": [{"text": "kNN-all", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8755208849906921}]}, {"text": "kNN-BoW which is the same supervised system, but restricted to bag-of-words features only, which are the ones used by our graphbased systems.", "labels": [], "entities": []}, {"text": "The table shows that Vr opt and Pr fr are one single point from kNN-BoW, which is an impressive result if we take into account the information loss of the mapping step and that we tuned our parameters on a different set of words.", "labels": [], "entities": []}, {"text": "The last 5 rows of show several unsupervised systems, all of which except Cymfony ( and) participated in S3LS (check) for further details on the systems).", "labels": [], "entities": [{"text": "Cymfony", "start_pos": 74, "end_pos": 81, "type": "DATASET", "confidence": 0.9621307253837585}]}, {"text": "We classify them according to the amount of \"supervision\" they have: some have access to mostfrequent information (MFS-S3 if counted over S3LS, MFS-Sc if counted over SemCor), some use 10% of the S3LS training part for mapping (10%-S3LS).", "labels": [], "entities": []}, {"text": "Only one system (Duluth) did not use in anyway hand-tagged corpora.", "labels": [], "entities": []}, {"text": "The table shows that Vr opt and Pr fr are more than 6 points above the other unsupervised systems, but given the different typology of unsupervised systems, it's unfair to draw definitive conclusions from a raw comparison of results.", "labels": [], "entities": [{"text": "Vr opt", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9053003787994385}, {"text": "Pr fr", "start_pos": 32, "end_pos": 37, "type": "METRIC", "confidence": 0.9270227253437042}]}, {"text": "The system coming closer to ours is that described in ().", "labels": [], "entities": []}, {"text": "They use hand tagged corpora which does not need to include the target word to tune the parameters of a rather complex clustering method which does use local features.", "labels": [], "entities": []}, {"text": "They douse the S3LS training corpus for mapping.", "labels": [], "entities": [{"text": "S3LS training corpus", "start_pos": 15, "end_pos": 35, "type": "DATASET", "confidence": 0.6987696588039398}]}, {"text": "For every sense of the target word, three of its contexts in the train corpus are gathered (around 10% of the training data) and tagged.", "labels": [], "entities": []}, {"text": "Each cluster is then related with its most frequent sense.", "labels": [], "entities": []}, {"text": "The mapping method is similar to ours, but we use all the available training data and allow for different hubs to be assigned to the same sense.", "labels": [], "entities": []}, {"text": "Another system similar to ours is), which unfortunately was evaluated on Senseval 2 data and is not included in the table.", "labels": [], "entities": [{"text": "Senseval 2 data", "start_pos": 73, "end_pos": 88, "type": "DATASET", "confidence": 0.8776497642199198}]}, {"text": "The authors use first and second order bag-of-word context features to represent each instance of the corpus.", "labels": [], "entities": []}, {"text": "They apply several clustering algorithms based on the vector space model, limiting the number of clusters to 7.", "labels": [], "entities": []}, {"text": "They also use all available training data for mapping, but given their small number of clusters they opt fora one-to-one mapping which maximizes the assignment and discards the less frequent clusters.", "labels": [], "entities": []}, {"text": "They also discard some difficult cases, like senses and words with low frequencies (10% of total occurrences and 90, respectively).", "labels": [], "entities": []}, {"text": "The different test set and mapping system make the comparison difficult, but the fact that the best of their combinations beats MFS by 1 point on average (47.6% vs. 46.4%) for the selected nouns and senses make us think that our results are more robust (nearly 10% over MFS).", "labels": [], "entities": []}, {"text": "The three columns corresponding to fully unsupervised evaluation in show that all our 3 optimized variants easily outperform the MFS baseline.", "labels": [], "entities": [{"text": "MFS baseline", "start_pos": 129, "end_pos": 141, "type": "DATASET", "confidence": 0.8408583998680115}]}, {"text": "The best results are in this case for the optimized Veronis, followed closely by Pagerank with frequency threshold.", "labels": [], "entities": [{"text": "Veronis", "start_pos": 52, "end_pos": 59, "type": "DATASET", "confidence": 0.8690387606620789}]}, {"text": "The comparison with the supervised and unsupervised systems shows that our system gets better entropy and purity values, but worse FScore.", "labels": [], "entities": [{"text": "FScore", "start_pos": 131, "end_pos": 137, "type": "METRIC", "confidence": 0.9940891265869141}]}, {"text": "This can be explained by the bias of entropy and purity towards smaller and more numerous clusters.", "labels": [], "entities": [{"text": "purity", "start_pos": 49, "end_pos": 55, "type": "METRIC", "confidence": 0.9756362438201904}]}, {"text": "In fact the 1ex-1hub baseline obtains the best entropy and purity scores.", "labels": [], "entities": [{"text": "purity", "start_pos": 59, "end_pos": 65, "type": "METRIC", "confidence": 0.979363739490509}]}, {"text": "Our graph-based system tends to induce a large number of senses (with averages of 60 to 70 senses).", "labels": [], "entities": []}, {"text": "On the other hand FScore penalizes the systems inducing a different number of clusters.", "labels": [], "entities": [{"text": "FScore", "start_pos": 18, "end_pos": 24, "type": "DATASET", "confidence": 0.6582686305046082}]}, {"text": "As the supervised and unsupervised systems were designed to return the same (or similar) number of senses as in the gold standard, they attain higher FScores.", "labels": [], "entities": [{"text": "FScores", "start_pos": 150, "end_pos": 157, "type": "METRIC", "confidence": 0.9888047575950623}]}, {"text": "This motivated us to compare the results of the best parameters across evaluation methods.", "labels": [], "entities": []}, {"text": "shows all 16 evaluation possibilities for each variant of the algorithm, depending of the evaluation criteria used in S2LS (in the rows) and the evaluation criteria used in S3LS (in the columns).", "labels": [], "entities": []}, {"text": "This table shows that the best results (in bold for each variant) tend to be in the diagonal, that is, when the same evaluation criterion is used for optimization and test, but it is not decisive.", "labels": [], "entities": []}, {"text": "If we take the first row (supervised evaluation) as the most credible criterion, we can see that optimizing according to entropy and purity get similar and sometimes better result (Pr fr and Pr fx).", "labels": [], "entities": []}, {"text": "On the contrary the Fscore yields worse results by far.", "labels": [], "entities": [{"text": "Fscore", "start_pos": 20, "end_pos": 26, "type": "METRIC", "confidence": 0.6446353197097778}]}, {"text": "This indicates that a purely unsupervised system evaluated according to the gold standard (based on entropy or purity) yields optimal parameters similar to the supervised (mapped) version.", "labels": [], "entities": []}, {"text": "This is an important result, as it shows that the quality in performance does not come from the mapping step, but from the algorithm and optimal parameter setting.", "labels": [], "entities": []}, {"text": "The table shows that optimization on purity and entropy criteria do correlate with good performance in the supervised evaluation.", "labels": [], "entities": []}, {"text": "The failure of FScore based optimization, in our opinion, indicates that our clustering algorithm prefers smaller and more numerous clusters, compared to the gold standard.", "labels": [], "entities": [{"text": "FScore based optimization", "start_pos": 15, "end_pos": 40, "type": "TASK", "confidence": 0.6990456779797872}]}, {"text": "FScore prefers clustering solutions that have a similar number of clusters to that of the gold standard, but it is unable to drive the optimization or our algorithm towards good results in the supervised evaluation.", "labels": [], "entities": [{"text": "FScore", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9481920599937439}]}, {"text": "All in all, the best results are attained with smaller and more numerous hubs, a kind of microsenses.", "labels": [], "entities": []}, {"text": "This effect is the same for all three variants tried and all evaluation criteria, with Fscore yielding less clusters.", "labels": [], "entities": [{"text": "Fscore", "start_pos": 87, "end_pos": 93, "type": "METRIC", "confidence": 0.9194560050964355}]}, {"text": "At first we were uncomfortable with this behavior, so we checked whether HyperLex was degenerating into a trivial solution.", "labels": [], "entities": []}, {"text": "This was the main reason to include the 1ex-1hub baseline, which simulates a clustering algorithm returning one hub per example, and its precision was 40.1, well below the MFS baseline.", "labels": [], "entities": [{"text": "1ex-1hub baseline", "start_pos": 40, "end_pos": 57, "type": "DATASET", "confidence": 0.7072591185569763}, {"text": "precision", "start_pos": 137, "end_pos": 146, "type": "METRIC", "confidence": 0.9986082911491394}, {"text": "MFS baseline", "start_pos": 172, "end_pos": 184, "type": "DATASET", "confidence": 0.8939491510391235}]}, {"text": "We also realized that our results are in accordance with some theories of word meaning, e.g. the \"indefinitely large set of prototypes-within-prototypes\" envisioned in.", "labels": [], "entities": []}, {"text": "Ted Pedersen has also observed a similar behaviour in his vectorspace model clustering experiments (PC).", "labels": [], "entities": [{"text": "vectorspace model clustering experiments (PC)", "start_pos": 58, "end_pos": 103, "type": "TASK", "confidence": 0.6158412141459328}]}, {"text": "We now think that the idea of having many micro-senses is attractive for further exploration, specially if we are able to organize them into coarser hubs in future work.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Parameters of the HyperLex algorithm", "labels": [], "entities": []}, {"text": " Table 2: Results for the nouns in S3LS using the 4 meth-", "labels": [], "entities": []}, {"text": " Table 3: Cross-evaluation comparison. In the rows the eval-", "labels": [], "entities": []}, {"text": " Table 4: Results for the nouns in S3AW, compared to the", "labels": [], "entities": []}]}