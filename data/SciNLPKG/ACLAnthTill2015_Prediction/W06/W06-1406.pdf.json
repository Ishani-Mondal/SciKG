{"title": [{"text": "Using Distributional Similarity to Identify Individual Verb Choice", "labels": [], "entities": []}], "abstractContent": [{"text": "Human text is characterised by the individual lexical choices of a specific author.", "labels": [], "entities": []}, {"text": "Significant variations exist between authors.", "labels": [], "entities": []}, {"text": "In contrast, natural language generation systems normally produce uniform texts.", "labels": [], "entities": []}, {"text": "In this paper we apply distributional similarity measures to help verb choice in a natural language generation system which tries to generate text similar to individual author.", "labels": [], "entities": [{"text": "verb choice", "start_pos": 66, "end_pos": 77, "type": "TASK", "confidence": 0.722983255982399}]}, {"text": "By using a distributional similarity (DS) measure on corpora collected from a recipe domain, we get the most likely verbs for individual authors.", "labels": [], "entities": [{"text": "distributional similarity (DS) measure", "start_pos": 11, "end_pos": 49, "type": "METRIC", "confidence": 0.9000782072544098}]}, {"text": "The accuracy of matching verb pairs produced by distributional similarity is higher than using the synonym outputs of verbs from WordNet.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9994022846221924}, {"text": "WordNet", "start_pos": 129, "end_pos": 136, "type": "DATASET", "confidence": 0.9466617107391357}]}, {"text": "Furthermore , the combination of the two methods provides the best accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.9984685778617859}]}], "introductionContent": [{"text": "Human text is characterised by the individual lexical choices of the specific author.", "labels": [], "entities": []}, {"text": "It varies from author to author.", "labels": [], "entities": []}, {"text": "Individual authors use different verbs to describe the same action.", "labels": [], "entities": []}, {"text": "Natural language generation (NLG) systems, in contrast, normally produce uniform outputs without considering other lexical possibilities.", "labels": [], "entities": [{"text": "Natural language generation (NLG)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.7550128748019537}]}, {"text": "Consider the following example from our corpora that are the BBC corpus and the Recipes for health eating corpus.", "labels": [], "entities": [{"text": "BBC corpus", "start_pos": 61, "end_pos": 71, "type": "DATASET", "confidence": 0.9915818572044373}, {"text": "Recipes for health eating corpus", "start_pos": 80, "end_pos": 112, "type": "DATASET", "confidence": 0.5685113906860352}]}], "datasetContent": [{"text": "To justify accuracy of results by both the baseline method and the DS method, we manually judge whether or not the alternatives are interchangeable for the missing verbs.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 11, "end_pos": 19, "type": "METRIC", "confidence": 0.9971669316291809}]}, {"text": "shows the total number of missing verbs for each individual corpus and numbers of available alternatives as well.", "labels": [], "entities": []}, {"text": "Also, it presents the number of correct alternatives for cases where both methods return answers, and results of a combination of two methods.", "labels": [], "entities": []}, {"text": "In the future, we would like to evaluate the accuracy by more judges.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.999574601650238}]}, {"text": "From, accuracies of distributional similarity are higher than WordNet synonyms inmost cases, except in the individual corpus CM.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 6, "end_pos": 16, "type": "METRIC", "confidence": 0.9780192375183105}]}, {"text": "The reason that CM got worse results is probably that the corpus size is not big enough.", "labels": [], "entities": []}, {"text": "Since CM is the only individual corpus that has less than 50 recipes, this could lead to unreliable accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 100, "end_pos": 108, "type": "METRIC", "confidence": 0.997222900390625}]}, {"text": "In table 2, 'A' means the total number of missing verbs in the individual corpus that have candidate alternatives in an individual corpus from methods.", "labels": [], "entities": [{"text": "A", "start_pos": 13, "end_pos": 14, "type": "METRIC", "confidence": 0.9428825378417969}]}, {"text": "It is obvious that distributional methods produce more available verbs than the synonyms of WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 92, "end_pos": 99, "type": "DATASET", "confidence": 0.9610210061073303}]}, {"text": "In this case, we assume that WordNet is not very productive to provide alternative verb choices for individual authors compared with distributional similarity in a domain.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 29, "end_pos": 36, "type": "DATASET", "confidence": 0.9478603601455688}]}, {"text": "represents the accuracies of all methods.", "labels": [], "entities": []}, {"text": "In, we can seethe overall accuracy of WordNet is not as good as the distributional similarity method.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9996501207351685}, {"text": "WordNet", "start_pos": 38, "end_pos": 45, "type": "DATASET", "confidence": 0.9564962387084961}]}, {"text": "Moreover, we calculate the accuracy for the available verb pairs from the combination method of both the distributional similarity and WordNet.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9996262788772583}, {"text": "WordNet", "start_pos": 135, "end_pos": 142, "type": "DATASET", "confidence": 0.9709078669548035}]}, {"text": "We can see that all combination accuracies are significantly better than accuracies of either distributional similarity or WordNet synonyms.", "labels": [], "entities": []}, {"text": "In this case, distributional similarity and WordNet find different types of verbs.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 44, "end_pos": 51, "type": "DATASET", "confidence": 0.9384526014328003}]}, {"text": "In other words, the similarity distributional method is very useful to find verbs that are not synonyms but represent the same type of action in individual corpora.", "labels": [], "entities": []}, {"text": "And the type of verbs found by distributional similarity could not be pre-predicted, which makes the verb choice personalised.", "labels": [], "entities": []}, {"text": "In our verb pair outputs from distributional similarity, one problem is that we got similar verb pairs, for instances the verb 'simmer' matches to 'fry'.", "labels": [], "entities": []}, {"text": "This is a common problem with distributional similarity, since it is not based on semantic meaning.", "labels": [], "entities": []}, {"text": "This problem can perhaps be solved by building some hierarchical relationships between verbs.", "labels": [], "entities": []}, {"text": "For instance, roast is one type of cooking.", "labels": [], "entities": []}, {"text": "The following examples are correct cases of verb pairs that are captured by distributional similarity.", "labels": [], "entities": []}, {"text": "In each example, the semantic meanings of sentences are different, but the representation of action are the same.", "labels": [], "entities": []}, {"text": "roast (BBC Corpus) -cook (Food for Health): So far distributional similarity cannot capture the prepositions such as on in the third example.", "labels": [], "entities": [{"text": "BBC Corpus)", "start_pos": 7, "end_pos": 18, "type": "DATASET", "confidence": 0.962053656578064}]}, {"text": "This is our future work.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Our corpora information", "labels": [], "entities": []}, {"text": " Table 2: The number of available missing verbs by the Distributional Similarity (DS) and by WordNet  and by combination of DS and WordNet. ('A' means the total number of missing verbs in the individual  corpus that have candidate alternatives in an individual corpus from methods.)", "labels": [], "entities": [{"text": "WordNet", "start_pos": 93, "end_pos": 100, "type": "DATASET", "confidence": 0.9650789499282837}, {"text": "WordNet", "start_pos": 131, "end_pos": 138, "type": "DATASET", "confidence": 0.9789522886276245}, {"text": "A", "start_pos": 142, "end_pos": 143, "type": "METRIC", "confidence": 0.9575306177139282}]}]}