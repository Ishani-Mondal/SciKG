{"title": [{"text": "Increasing the coverage of a domain independent dialogue lexicon with VERBNET", "labels": [], "entities": [{"text": "VERBNET", "start_pos": 70, "end_pos": 77, "type": "DATASET", "confidence": 0.770121693611145}]}], "abstractContent": [{"text": "This paper investigates how to extend coverage of a domain independent lexicon tailored for natural language understanding.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 92, "end_pos": 122, "type": "TASK", "confidence": 0.6672560969988505}]}, {"text": "We introduce two algorithms for adding lexical entries from VERBNET to the lexicon of the TRIPS spoken dialogue system.", "labels": [], "entities": [{"text": "TRIPS spoken dialogue system", "start_pos": 90, "end_pos": 118, "type": "DATASET", "confidence": 0.5806018859148026}]}, {"text": "We report results on the efficiency of the method, discussing in particular precision versus coverage issues and implications for mapping to other lexical databases.", "labels": [], "entities": [{"text": "precision", "start_pos": 76, "end_pos": 85, "type": "METRIC", "confidence": 0.9970079064369202}]}], "introductionContent": [{"text": "This paper explores how different lexicons can be integrated with the goal of extending coverage of a deep parser and semantic interpreter.", "labels": [], "entities": []}, {"text": "Lexical semantic databases () use a frame-based model of lexical semantics.", "labels": [], "entities": [{"text": "Lexical semantic databases", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8156000971794128}]}, {"text": "Each database groups words in classes where predicative words and their arguments are described.", "labels": [], "entities": []}, {"text": "The classes are generally organised in an inheritance structure.", "labels": [], "entities": []}, {"text": "Each such database can be used, among other things, to perform semantic interpretation.", "labels": [], "entities": [{"text": "semantic interpretation", "start_pos": 63, "end_pos": 86, "type": "TASK", "confidence": 0.7934336960315704}]}, {"text": "However, their actual structures are quite different, reflecting different underlying methodological approaches to lexical description, and this results in representation that are not directly compatible.", "labels": [], "entities": []}, {"text": "Since no such database has full coverage of English, it is worth combining them in order to get a lexicon with better coverage and a unified representation for English.", "labels": [], "entities": []}, {"text": "We explore the issues related to merging verb descriptions from two lexical databases, which have both syntactic and semantic incompatibilities, and compare two techniques for aligning semantic classes and the syntax-semantics mappings between them.", "labels": [], "entities": []}, {"text": "The resulting lexicon is to be used in precise interpretation tasks, so its consistency and accuracy area high priority.", "labels": [], "entities": [{"text": "precise interpretation tasks", "start_pos": 39, "end_pos": 67, "type": "TASK", "confidence": 0.6472539901733398}, {"text": "consistency", "start_pos": 76, "end_pos": 87, "type": "METRIC", "confidence": 0.9959338307380676}, {"text": "accuracy", "start_pos": 92, "end_pos": 100, "type": "METRIC", "confidence": 0.9985846281051636}]}, {"text": "Thus, though it is possible to generate lexical entries automatically (), we use a semi-automatic method in which an expert hand-checks the automatically generated entries before adding them to the lexicon.", "labels": [], "entities": []}, {"text": "Therefore, our goal is to maximise the number of new useful entries added to the lexicon while minimising the number of entries that are discarded or hand-edited.", "labels": [], "entities": []}, {"text": "We take the mapping between the TRIPS lexicon and the VERBNET lexical database as a case study for our experiment.", "labels": [], "entities": [{"text": "TRIPS lexicon", "start_pos": 32, "end_pos": 45, "type": "DATASET", "confidence": 0.8479066491127014}, {"text": "VERBNET lexical database", "start_pos": 54, "end_pos": 78, "type": "DATASET", "confidence": 0.9411945343017578}]}, {"text": "The TRIPS lexicon is used together with a parser to provide a natural language understanding component for several dialogue applications in different domains.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 62, "end_pos": 92, "type": "TASK", "confidence": 0.7285303076108297}]}, {"text": "It outputs highly detailed semantic representations suitable for complex dialogue tasks such as problem-solving and tutoring dialogue, inter alia.", "labels": [], "entities": []}, {"text": "An essential feature of TRIPS is the integration of a detailed lexical semantic representation, semantic classes and theta role assignments in the parsing process.", "labels": [], "entities": [{"text": "TRIPS", "start_pos": 24, "end_pos": 29, "type": "TASK", "confidence": 0.9128453731536865}]}, {"text": "Semantic types and role labelling are helpful in both deep) and shallow interpretation tasks ().", "labels": [], "entities": [{"text": "role labelling", "start_pos": 19, "end_pos": 33, "type": "TASK", "confidence": 0.7159678637981415}]}, {"text": "TRIPS provides a convenient test case because its grammar is already equipped with the formal devices required to buildup a frame-based semantic representation including this information.", "labels": [], "entities": [{"text": "TRIPS", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.7618746757507324}]}, {"text": "We chose VERBNET to extend the TRIPS lexicon because it includes a detailed syntax-semantic mappings, thus providing a more convenient interface to the syntactic component of the grammar than lexicons where this connection is left unclear, such as FRAMENET.", "labels": [], "entities": [{"text": "TRIPS lexicon", "start_pos": 31, "end_pos": 44, "type": "DATASET", "confidence": 0.761587917804718}, {"text": "FRAMENET", "start_pos": 248, "end_pos": 256, "type": "DATASET", "confidence": 0.9203141331672668}]}, {"text": "However the methods described here are designed to be reusable for merging other lexical databases, in particular we intend to experiment with FRAMENET in the near future.", "labels": [], "entities": [{"text": "FRAMENET", "start_pos": 143, "end_pos": 151, "type": "DATASET", "confidence": 0.5714135766029358}]}, {"text": "The plan of the paper is as follows: we first describe the target lexicon (Section 2) and the source lexicon (Section 3) for our experiment before describing the methodology for integration (Section 4).", "labels": [], "entities": []}, {"text": "We finally present an evaluation of the techniques in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "Since our goal in this evaluation is to balance the coverage of VERBNET with precision, we correspondingly evaluate along those two dimensions.", "labels": [], "entities": [{"text": "VERBNET", "start_pos": 64, "end_pos": 71, "type": "DATASET", "confidence": 0.5654921531677246}, {"text": "precision", "start_pos": 77, "end_pos": 86, "type": "METRIC", "confidence": 0.9995397329330444}]}, {"text": "For both techniques, we evaluate how many word senses were added, and the number of different words defined and VERBNET classes covered.", "labels": [], "entities": [{"text": "VERBNET", "start_pos": 112, "end_pos": 119, "type": "METRIC", "confidence": 0.9457568526268005}]}, {"text": "As a measure of precision we use, for those entries which were retrieved, the percentage of those which could betaken \"as is\" (good entries) and the percentage of entries which could betaken with minor edits (for example, changing an LF type to a more specific subclass, or changing a semantic role in a template).", "labels": [], "entities": [{"text": "precision", "start_pos": 16, "end_pos": 25, "type": "METRIC", "confidence": 0.9991181492805481}]}, {"text": "The results of evaluation are shown in.", "labels": [], "entities": []}, {"text": "Since for mapping with syntax filtering we considered all possible TRIPS-VERBNET intersections, it in effect presents an upper bound the number of words shared between the two databases.", "labels": [], "entities": []}, {"text": "Further  extension would require extending the TRIPS LF Ontology with additional types to cover the missing classes.", "labels": [], "entities": [{"text": "TRIPS LF Ontology", "start_pos": 47, "end_pos": 64, "type": "DATASET", "confidence": 0.8258649309476217}]}, {"text": "As can be seen from this table, 65% of VERBNET classes have an analogous class in TRIPS.", "labels": [], "entities": []}, {"text": "At the same time, there is a very large number of class intersections possible, so if all possible intersections are generated, only a very small percentage of generated word senses (16%) is usable in the combined system.", "labels": [], "entities": []}, {"text": "Thus developing techniques to filter out the irrelevant senses and class matches is important for successful hand-checking.", "labels": [], "entities": []}, {"text": "Our evaluation also shows that while class intersection with thresholding provides higher precision, it does not capture many words and verb senses.", "labels": [], "entities": [{"text": "class intersection", "start_pos": 37, "end_pos": 55, "type": "TASK", "confidence": 0.6969343423843384}, {"text": "precision", "start_pos": 90, "end_pos": 99, "type": "METRIC", "confidence": 0.9990440011024475}]}, {"text": "One reason for this is data sparsity.", "labels": [], "entities": []}, {"text": "TRIPS is relatively small, and both TRIPS and VERBNET contain a number of 1-word classes, which cannot be reliably mapped without human intervention.", "labels": [], "entities": [{"text": "TRIPS", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.6457986235618591}]}, {"text": "This problem can be alleviated in part as the size of the database grows.", "labels": [], "entities": []}, {"text": "We expect this technique to have better recall when the combined lexicon is used to merge with a different lexical database such as FRAMENET.", "labels": [], "entities": [{"text": "recall", "start_pos": 40, "end_pos": 46, "type": "METRIC", "confidence": 0.9994761347770691}, {"text": "FRAMENET", "start_pos": 132, "end_pos": 140, "type": "DATASET", "confidence": 0.9156372547149658}]}, {"text": "However, a more difficult issue to resolve is differences in class structure.", "labels": [], "entities": []}, {"text": "VERBNET was built around the theory of syntactic alternations, while TRIPS used FRAMENET structure as a starting point, simplifying the role structure to make connection to parsing more straightforward ( ).", "labels": [], "entities": [{"text": "VERBNET", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8835165500640869}, {"text": "FRAMENET", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.8922554850578308}]}, {"text": "Therefore TRIPS does not require that all words associated with the same LF type share syntactic behaviour, so there area number of VERB-NET classes with members which have to be split between different TRIPS classes based on additional semantic properties.", "labels": [], "entities": []}, {"text": "70% of all good matches in the filtering technique were such partial matches.", "labels": [], "entities": []}, {"text": "This significantly disadvantages the thresholding technique, which provides the mappings on class level, not allowing for splitting word entries between the classes.", "labels": [], "entities": []}, {"text": "We believe that the best solution can be found by combining these two techniques.", "labels": [], "entities": []}, {"text": "The thresholding technique could be used to establish reliable class mappings, providing classes where many entries could be transferred \"as is\".", "labels": [], "entities": []}, {"text": "The mapping can then be examined to determine incorrect class mappings as well as the cases where classes should be split based on individual words.", "labels": [], "entities": []}, {"text": "For those entries judged reliable in the first pass, the syntactic structure can be transferred fully and quickly, while the syntactic filtering technique, which requires more manual checking, can be used to transfer other entries in the intersections where class mapping could not be established reliably.", "labels": [], "entities": []}, {"text": "Establishing class and member correspondence is a general problem with merging any two semantic lexicons.", "labels": [], "entities": []}, {"text": "Similar issues have been noted in comparing FRAMENET and VERBNET.", "labels": [], "entities": [{"text": "FRAMENET", "start_pos": 44, "end_pos": 52, "type": "DATASET", "confidence": 0.49424466490745544}, {"text": "VERBNET", "start_pos": 57, "end_pos": 64, "type": "DATASET", "confidence": 0.8604184985160828}]}, {"text": "A method recently proposed by aligns words in different semantic lexicons to WordNet senses, and then aligns semantic roles based on those matches.", "labels": [], "entities": []}, {"text": "Since we are designing a lexicon for semantic interpretation, it is important for us that all words should be associated with frames in a shared hierarchy, to be used in further interpretation tasks.", "labels": [], "entities": [{"text": "semantic interpretation", "start_pos": 37, "end_pos": 60, "type": "TASK", "confidence": 0.7326533645391464}]}, {"text": "We are considering using this alignment technique to further align semantic classes, in order to produce a shared database for interpretation covering words from multiple sources.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Evaluation results for different acquisition techniques. %usable = (good + editable) / bad\".", "labels": [], "entities": []}]}