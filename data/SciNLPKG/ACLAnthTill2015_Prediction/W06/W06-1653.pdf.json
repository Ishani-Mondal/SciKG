{"title": [], "abstractContent": [{"text": "We extended language modeling approaches in information retrieval (IR) to combine collaborative filtering (CF) and content-based filtering (CBF).", "labels": [], "entities": [{"text": "information retrieval (IR)", "start_pos": 44, "end_pos": 70, "type": "TASK", "confidence": 0.8778277516365052}, {"text": "content-based filtering (CBF)", "start_pos": 115, "end_pos": 144, "type": "TASK", "confidence": 0.7801342487335206}]}, {"text": "Our approach is based on the analogy between IR and CF, especially between CF and relevance feedback (RF).", "labels": [], "entities": []}, {"text": "Both CF and RF exploit users' preference/relevance judgments to recommend items.", "labels": [], "entities": []}, {"text": "We first introduce a multinomial model that combines CF and CBF in a language modeling framework.", "labels": [], "entities": []}, {"text": "We then generalize the model to another multinomial model that approximates the Polya distribution.", "labels": [], "entities": []}, {"text": "This generalized model outperforms the multinomial model by 3.4% for CBF and 17.4% for CF in recommending English Wikipedia articles.", "labels": [], "entities": [{"text": "CBF", "start_pos": 69, "end_pos": 72, "type": "DATASET", "confidence": 0.6552858352661133}]}, {"text": "The performance of the generalized model for three different datasets was comparable to that of a state-of-the-art item-based CF method.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recommender systems) help users select particular items (e.g, movies, books, music, and TV programs) that match their taste from a large number of choices by providing recommendations.", "labels": [], "entities": []}, {"text": "The systems either recommend a set of N items that will be of interest to users (top-N recommendation problem) or predict the degree of users' preference for items.", "labels": [], "entities": []}, {"text": "For those systems to work, they first have to aggregate users' evaluations of items explicitly or implicitly.", "labels": [], "entities": []}, {"text": "Users may explicitly evaluate certain movies as rating five stars to express their preference.", "labels": [], "entities": []}, {"text": "These evaluations are used by the systems as explicit ratings (votes) of items or the systems infer the evaluations of items from the behavior of users and use these inferred evaluations as implicit ratings.", "labels": [], "entities": []}, {"text": "For example, systems can infer that users may like certain items if the systems learn which books they buy, which articles they read, or which TV programs they watch.", "labels": [], "entities": []}, {"text": "Collaborative filtering (CF)) and content-based (or adaptive) filtering (CBF)) are two of the most popular types of algorithms used in recommender systems.", "labels": [], "entities": [{"text": "Collaborative filtering (CF))", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.7615615069866181}, {"text": "content-based (or adaptive) filtering (CBF))", "start_pos": 34, "end_pos": 78, "type": "TASK", "confidence": 0.7437539498011271}]}, {"text": "A CF system makes recommendations to current (active) users by exploiting their ratings in the database.", "labels": [], "entities": []}, {"text": "User-based CF) and item-based CF (), among other CF algorithms, have been studied extensively.", "labels": [], "entities": []}, {"text": "User-based CF first identifies a set of users (neighbors) that are similar to the active user in terms of their rating patterns in the database.", "labels": [], "entities": []}, {"text": "It then uses the neighbors' rating patterns to produce recommendations for the active user.", "labels": [], "entities": []}, {"text": "On the other hand, item-based CF calculates the similarity between items beforehand and then recommends items that are similar to those preferred by the active user.", "labels": [], "entities": []}, {"text": "The performance of item-based CF has been shown to be comparable to or better than that of user-based CF (.", "labels": [], "entities": []}, {"text": "In contrast to CF, CBF uses the contents (e.g., texts, genres, authors, images, and audio) of items to make recommendations for the active user.", "labels": [], "entities": []}, {"text": "Because CF and CBF are complementary, much work has been done to combine them ().", "labels": [], "entities": []}, {"text": "The approach we took in this study is designed to solve top-N recommendation problems with im-plicit ratings by using an item-based combination of CF and CBF.", "labels": [], "entities": []}, {"text": "The methods described in this paper will be applied to recommending English Wikipedia 1 articles based on those articles edited by active users.", "labels": [], "entities": []}, {"text": "(This is discussed in Section 3.)", "labels": [], "entities": []}, {"text": "We use their editing histories and the contents of their articles to make top-N recommendations.", "labels": [], "entities": []}, {"text": "We regard users' editing histories as implicit ratings.", "labels": [], "entities": []}, {"text": "That is, if users have edited articles, we consider that they have positive attitudes toward the articles.", "labels": [], "entities": []}, {"text": "Those implicit ratings are regarded as positive examples.", "labels": [], "entities": []}, {"text": "We do not have negative examples for learning their negative attitudes toward articles.", "labels": [], "entities": []}, {"text": "Consequently, handling our application with standard machine learning algorithms that require both positive and negative examples for classification (e.g., support vector machines) is awkward.", "labels": [], "entities": []}, {"text": "Our approach is based on the advancement in language modeling approaches to information retrieval (IR) and extends these to incorporate CF.", "labels": [], "entities": [{"text": "information retrieval (IR)", "start_pos": 76, "end_pos": 102, "type": "TASK", "confidence": 0.8603092312812806}]}, {"text": "The motivation behind our approach is the analogy between CF and IR, especially between CF and relevance feedback (RF).", "labels": [], "entities": []}, {"text": "Both CF and RF recommend items based on user preference/relevance judgments.", "labels": [], "entities": [{"text": "RF", "start_pos": 12, "end_pos": 14, "type": "METRIC", "confidence": 0.8597193360328674}]}, {"text": "Indeed, RF techniques have been applied to CBF, or adaptive filtering, successfully).", "labels": [], "entities": [{"text": "CBF", "start_pos": 43, "end_pos": 46, "type": "TASK", "confidence": 0.8403432369232178}, {"text": "adaptive filtering", "start_pos": 51, "end_pos": 69, "type": "TASK", "confidence": 0.7477401196956635}]}, {"text": "Thus, it is likely that RF can also be applied to CF.", "labels": [], "entities": [{"text": "RF", "start_pos": 24, "end_pos": 26, "type": "METRIC", "confidence": 0.5366936326026917}, {"text": "CF", "start_pos": 50, "end_pos": 52, "type": "TASK", "confidence": 0.860295295715332}]}, {"text": "To apply RF, we first extend the representation of items to combine CF and CBF under the models developed in Section 2.", "labels": [], "entities": [{"text": "RF", "start_pos": 9, "end_pos": 11, "type": "TASK", "confidence": 0.819872260093689}]}, {"text": "In Section 3, we report our experiments with the models.", "labels": [], "entities": []}, {"text": "Future work and conclusion are in Sections 4 and 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "We first examined the behavior of the Polya model by varying the parameters.", "labels": [], "entities": []}, {"text": "We tied \u03b1 \u03c9 w for every wand \u03b1 \u00b5 u for every u; for any wand u, \u03b1 \u03c9 w = \u03b1 \u03c9 and \u03b1 \u00b5 u = \u03b1 \u00b5 . We then compared the Polya model to an item-based CF method.", "labels": [], "entities": []}, {"text": "We made a dataset of articles from English Wikipedia to evaluate the Polya model.", "labels": [], "entities": [{"text": "English Wikipedia", "start_pos": 35, "end_pos": 52, "type": "DATASET", "confidence": 0.8982444703578949}]}, {"text": "English Wikipedia is an online encyclopedia that anyone can edit, and it has many registered users.", "labels": [], "entities": [{"text": "English Wikipedia", "start_pos": 0, "end_pos": 17, "type": "DATASET", "confidence": 0.9730133712291718}]}, {"text": "Our aim is to recommend a set of articles to each user that is likely to be of interest to that user.", "labels": [], "entities": []}, {"text": "If we can successfully recommend interesting articles, this could be very useful to a wide audience because Wikipedia is very popular.", "labels": [], "entities": []}, {"text": "In addition, because wikis are popular media for sharing knowledge, developing effective recommender systems for wikis is important.", "labels": [], "entities": []}, {"text": "In our Wikipedia dataset, each item (article) x consisted of w x and u x . u x was the sequence of users who had edited x.", "labels": [], "entities": [{"text": "Wikipedia dataset", "start_pos": 7, "end_pos": 24, "type": "DATASET", "confidence": 0.9535113573074341}]}, {"text": "If users had edited x multiple times, then those users occurred in u x multiple times.", "labels": [], "entities": []}, {"text": "w x was the sequence of words that were typical in x.", "labels": [], "entities": []}, {"text": "To make w x , we removed stop words and stemmed the remaining words with a Porter stemmer.", "labels": [], "entities": []}, {"text": "Next, we identified 100 typical words in each article and extracted only those words (|w x | \u2265 100 because some of them occurred multiple times).", "labels": [], "entities": []}, {"text": "Typicality was measured using the log-likelihood ratio test.", "labels": [], "entities": []}, {"text": "We needed to reduce the number of words to speedup our recommender system.", "labels": [], "entities": []}, {"text": "To make our dataset, we first extracted 302,606 articles, which had more than 100 tokens after the stop words were removed.", "labels": [], "entities": []}, {"text": "We then selected typical words in each article.", "labels": [], "entities": []}, {"text": "The implicit rating data were obtained from the histories of users editing these articles.", "labels": [], "entities": []}, {"text": "Each rating consisted of {user, article, number of edits}.", "labels": [], "entities": []}, {"text": "The size of this original rating data was 3,325,746.", "labels": [], "entities": []}, {"text": "From this data, we extracted a dense subset that consisted of users and articles included in at least 25 units of the original data.", "labels": [], "entities": []}, {"text": "We discarded the users who had edited more than 999 articles because they were often software robots or system operators, not casual users.", "labels": [], "entities": []}, {"text": "The resulting 430,096 ratings consisted of 4,193 users and 9,726 articles.", "labels": [], "entities": []}, {"text": "Each user rated (edited) 103 articles on average (the median was 57).", "labels": [], "entities": []}, {"text": "The average number of ratings per item was 44 and the median was 36.", "labels": [], "entities": [{"text": "average number of ratings", "start_pos": 4, "end_pos": 29, "type": "METRIC", "confidence": 0.6467985138297081}]}, {"text": "We conducted a four-fold cross validation of this rating dataset to evaluate the Polya model.", "labels": [], "entities": []}, {"text": "We used three-fourth of the dataset to train the model and one-fourth to test it.", "labels": [], "entities": []}, {"text": "All users who existed in We needed to estimate probabilities of users and words.", "labels": [], "entities": []}, {"text": "We used only training data to estimate the probabilities of users.", "labels": [], "entities": []}, {"text": "However, we used all 9,726 articles to estimate the probabilities of words because the articles are usually available even when editing histories of users are not.", "labels": [], "entities": []}, {"text": "both training and test data were used for evaluation.", "labels": [], "entities": []}, {"text": "For each user, we regarded the articles in the training data that had been edited by the user as a query and ranked articles in response to it.", "labels": [], "entities": []}, {"text": "These ranked top-N articles were then compared to the articles in the test data that were edited by the same user to measure the precisions for the user.", "labels": [], "entities": [{"text": "precisions", "start_pos": 129, "end_pos": 139, "type": "METRIC", "confidence": 0.992584228515625}]}, {"text": "We used P@N (precision at rank N = the ratio of the articles edited by the user in the top-N articles), S@N (success at rank N = 1 if some top-N articles were edited by the user, else 0), and R-precision (= P@N, where N is the number of articles edited by the user in the test data).", "labels": [], "entities": [{"text": "precision", "start_pos": 13, "end_pos": 22, "type": "METRIC", "confidence": 0.9972534775733948}, {"text": "R-precision", "start_pos": 192, "end_pos": 203, "type": "METRIC", "confidence": 0.9658268690109253}]}, {"text": "These measures for each user were averaged overall users to get the mean precision of each measure.", "labels": [], "entities": [{"text": "precision", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.9393226504325867}]}, {"text": "Then, these mean precisions were averaged over the cross validation repeats.", "labels": [], "entities": [{"text": "mean precisions", "start_pos": 12, "end_pos": 27, "type": "METRIC", "confidence": 0.6599741578102112}]}, {"text": "Here, we report the averaged mean precisions with standard deviations.", "labels": [], "entities": [{"text": "mean precisions", "start_pos": 29, "end_pos": 44, "type": "METRIC", "confidence": 0.7213590741157532}]}, {"text": "We first report how R-precision varied depending on \u03b1 (\u03b1 \u03c9 or \u03b1 \u00b5 ).", "labels": [], "entities": [{"text": "R-precision", "start_pos": 20, "end_pos": 31, "type": "METRIC", "confidence": 0.9215771555900574}]}, {"text": "\u03b1 was varied over 10 At once, we noticed that CBF outperformed CF.", "labels": [], "entities": [{"text": "\u03b1", "start_pos": 0, "end_pos": 1, "type": "METRIC", "confidence": 0.9325299859046936}, {"text": "CBF", "start_pos": 46, "end_pos": 49, "type": "DATASET", "confidence": 0.5448063015937805}, {"text": "CF", "start_pos": 63, "end_pos": 65, "type": "METRIC", "confidence": 0.6707746386528015}]}, {"text": "This is reasonable because the contents of Wikipedia articles should strongly reflect the users (authors) interest.", "labels": [], "entities": []}, {"text": "In addition, each article had about 100 typical words, and this was richer than the average number of users per article (44).", "labels": [], "entities": []}, {"text": "This observation contrasts with other work where CBF performed poorly compared with CF, e.g.,).", "labels": [], "entities": []}, {"text": "Another important observation is that both curves in   When \u03b1 = 10 5 or \u03bd(10, \u03b1) \u223c 10, the Polya model represents the multinomial model as discussed in Section 2.3.", "labels": [], "entities": []}, {"text": "Thus, and show that the best R-precisions achieved by the Polya model were better than those obtained by the multinomial model.", "labels": [], "entities": []}, {"text": "The improvement was 3.4% for CBF and 17.4% for CF as shown in Table 1.", "labels": [], "entities": [{"text": "CBF", "start_pos": 29, "end_pos": 32, "type": "DATASET", "confidence": 0.6319072842597961}, {"text": "CF", "start_pos": 47, "end_pos": 49, "type": "METRIC", "confidence": 0.9750596880912781}]}, {"text": "The improvement of CF was larger than that of CBF.", "labels": [], "entities": [{"text": "CF", "start_pos": 19, "end_pos": 21, "type": "METRIC", "confidence": 0.8698143362998962}, {"text": "CBF", "start_pos": 46, "end_pos": 49, "type": "DATASET", "confidence": 0.8976293206214905}]}, {"text": "This implies that the occurrences of users are more clustered than those of words.", "labels": [], "entities": []}, {"text": "In other words, the degree of repetition in the editing histories of users is greater than that in word sequences.", "labels": [], "entities": [{"text": "repetition", "start_pos": 30, "end_pos": 40, "type": "METRIC", "confidence": 0.975357711315155}]}, {"text": "A user who edits an article are likely to edit the article again.", "labels": [], "entities": []}, {"text": "From and, we concluded that the generalization of a multinomial model achieved by the Polya model is effective in improving recommendation performance.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Precision and Success at top-N", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9943515062332153}, {"text": "Success", "start_pos": 24, "end_pos": 31, "type": "METRIC", "confidence": 0.997455894947052}]}, {"text": " Table 3: Comparison of Polya-CF and CProb", "labels": [], "entities": [{"text": "CProb", "start_pos": 37, "end_pos": 42, "type": "DATASET", "confidence": 0.8131369948387146}]}]}