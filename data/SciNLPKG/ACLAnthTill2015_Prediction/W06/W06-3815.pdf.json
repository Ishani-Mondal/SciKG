{"title": [{"text": "Context Comparison as a Minimum Cost Flow Problem", "labels": [], "entities": [{"text": "Context Comparison", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8575690388679504}]}], "abstractContent": [{"text": "Comparing word contexts is a key component of many NLP tasks, but rarely is it used in conjunction with additional ontological knowledge.", "labels": [], "entities": []}, {"text": "One problem is that the amount of overhead required can be high.", "labels": [], "entities": []}, {"text": "In this paper, we provide a graphi-cal method which easily combines an on-tology with contextual information.", "labels": [], "entities": []}, {"text": "We take advantage of the intrinsic graphical structure of an ontology for representing a context.", "labels": [], "entities": []}, {"text": "In addition, we turn the on-tology into a metric space, such that sub-graphs within it, which represent contexts, can be compared.", "labels": [], "entities": []}, {"text": "We develop two variants of our graphical method for comparing contexts.", "labels": [], "entities": []}, {"text": "Our analysis indicates that our method performs the comparison efficiently and offers a competitive alternative to non-graphical methods.", "labels": [], "entities": []}], "introductionContent": [{"text": "Many natural language problems can be cast as a problem of comparing \"contexts\" (units of text).", "labels": [], "entities": []}, {"text": "For example, the local context of a word can be used to resolve its ambiguity (e.g.,), assuming that words used in similar contexts are closely related semantically.", "labels": [], "entities": []}, {"text": "Extending the meaning of context, the content of a document may reveal which document class(es) it belongs to (e.g.,.", "labels": [], "entities": []}, {"text": "In any application, once a sensible view of context is formulated, the next step is to choose a representation that makes comparisons possible.", "labels": [], "entities": []}, {"text": "For example, in word sense disambiguation, a context of an ambiguous instance can be represented as a vector of the frequencies of words surrounding it.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 16, "end_pos": 41, "type": "TASK", "confidence": 0.6970853010813395}]}, {"text": "Until recently, the dominant approach has been a non-graphical onecontext comparison is reduced to a task of measuring distributional distance between context vectors.", "labels": [], "entities": []}, {"text": "The difference in the frequency characteristics of contexts is used as an indicator of the semantic distance between them.", "labels": [], "entities": []}, {"text": "We present a graphical alternative that combines both distributional and ontological knowledge.", "labels": [], "entities": []}, {"text": "We begin with the use of a different context representation that allows easy incorporation of ontological information.", "labels": [], "entities": []}, {"text": "Treating an ontology as a network, we can represent a context as a set of nodes in the network (i.e., concepts in the ontology), each with a weight (i.e., frequency).", "labels": [], "entities": []}, {"text": "To contrast our work with that of and, the goal is not merely to provide a graphical representation fora context in which the relevant concepts are connected.", "labels": [], "entities": []}, {"text": "Rather, contexts are treated as weighted subgraphs within a larger graph in which they are connected via a set of paths.", "labels": [], "entities": []}, {"text": "By incorporating the semantic distance between individual concepts, the graph (representing the ontology) becomes a metric space in which we can measure the distance between subgraphs (representing the contexts to be compared).", "labels": [], "entities": []}, {"text": "More specifically, measuring the distance between two contexts can be viewed as solving a minimum cost flow (MCF) problem by calculating the amount of \"effort\" required for transporting the flow from one context to the other.", "labels": [], "entities": []}, {"text": "Our method has the advantage of including semantic information (by making use of the graphical structure of an ontology) without losing distributional information (by) If a feasible solution can be found, the net flow (the difference between the entering and exiting flow) at each node must fulfill the corresponding supply or demand requirement.", "labels": [], "entities": []}, {"text": "Formally, the MCF problem can be stated as: The constraint specified by (2) ensures that the difference between the flow entering and exiting each node , of cheapest routes yields the desired distance between the supply and the demand.", "labels": [], "entities": []}], "datasetContent": [{"text": "In our name disambiguation experiment, we use the data collected by: Name disambiguation results (accuracy/F-measure) at a glance.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 98, "end_pos": 106, "type": "METRIC", "confidence": 0.9985890984535217}, {"text": "F-measure", "start_pos": 107, "end_pos": 116, "type": "METRIC", "confidence": 0.8215730786323547}]}, {"text": "The baseline is the relative frequency of the majority name.", "labels": [], "entities": [{"text": "baseline", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9612326622009277}]}, {"text": "\"200\" and \"100\" give the averaged results (over five different runs) using 200 and 100 randomly selected training instances per ambiguous name.", "labels": [], "entities": []}, {"text": "The weighted average is calculated based on the number of test instances per task.", "labels": [], "entities": []}, {"text": "\"Full\" and \"Trans\" refer to the results using the full network (pre-transformation) or the pared-down network (with transformation), respectively.", "labels": [], "entities": []}, {"text": "; a nation and a nationality (Jordan and Egyptian); and two countries (France and Japan).", "labels": [], "entities": []}, {"text": "These name pairs are selected by to reflect a range of confusability between names.", "labels": [], "entities": []}, {"text": "Each pair of names serves as one of six name disambiguation tasks.", "labels": [], "entities": [{"text": "name disambiguation tasks", "start_pos": 40, "end_pos": 65, "type": "TASK", "confidence": 0.7797209521134695}]}, {"text": "Each name instance consists of a context window of 50 words (25 words to the left and to the right of the target name), with the target name obfuscated.", "labels": [], "entities": []}, {"text": "For example, for the task of distinguishing \"David Beckham\" and \"Ronaldo\", the target name in each instance becomes \"David BeckhamRonaldo\".", "labels": [], "entities": [{"text": "distinguishing \"David Beckham\" and \"Ronaldo\"", "start_pos": 29, "end_pos": 73, "type": "TASK", "confidence": 0.7223527961307101}]}, {"text": "The goal is to recover the correct target name in each instance.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Name disambiguation results (accuracy/F-measure) at a glance. The baseline is the relative frequency of the majority  name. \"200\" and \"100\" give the averaged results (over five different runs) using 200 and 100 randomly selected training instances  per ambiguous name. The weighted average is calculated based on the number of test instances per task. \"Full\" and \"Trans\" refer  to the results using the full network (pre-transformation) or the pared-down network (with transformation), respectively.", "labels": [], "entities": [{"text": "Name disambiguation", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.7931149899959564}, {"text": "accuracy", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.998026430606842}, {"text": "F-measure", "start_pos": 48, "end_pos": 57, "type": "METRIC", "confidence": 0.8838868141174316}]}]}