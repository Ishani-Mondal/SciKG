{"title": [{"text": "Dependency Parsing with Reference to Slovene, Spanish and Swedish", "labels": [], "entities": [{"text": "Dependency Parsing", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7784652411937714}]}], "abstractContent": [{"text": "We describe a parser used in the CoNLL 2006 Shared Task, \"Multingual Dependency Parsing.\"", "labels": [], "entities": [{"text": "CoNLL 2006 Shared Task", "start_pos": 33, "end_pos": 55, "type": "DATASET", "confidence": 0.8878041505813599}, {"text": "Multingual Dependency Parsing", "start_pos": 58, "end_pos": 87, "type": "TASK", "confidence": 0.7152984937032064}]}, {"text": "The parser first identifies syntactic dependencies and then labels those dependencies using a maximum en-tropy classifier.", "labels": [], "entities": []}, {"text": "We consider the impact of feature engineering and the choice of machine learning algorithm, with particular focus on Slovene, Spanish and Swedish.", "labels": [], "entities": [{"text": "feature engineering", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.8046772480010986}]}], "introductionContent": [{"text": "The system that we submitted for the Shared Task, \"Multingual Dependency Parsing,\") is a two stage pipeline.", "labels": [], "entities": [{"text": "Multingual Dependency Parsing", "start_pos": 51, "end_pos": 80, "type": "TASK", "confidence": 0.6620591779549917}]}, {"text": "The first stage identifies unlabeled directed dependencies using an extension of the parser described in).", "labels": [], "entities": []}, {"text": "The second stage is a maximum entropy classifier that labels the directed dependencies.", "labels": [], "entities": []}, {"text": "The system was trained on the twelve obligatory languages, as well as the optional language,; Kawata and Bartels,;; Civit.", "labels": [], "entities": []}, {"text": "presents the results of the system described in the current paper on the CoNLL shared task, including the optional evaluation on Bulgarian.", "labels": [], "entities": []}, {"text": "For Slovene, we ranked second with a labeled dependency accuracy of 72.42%.", "labels": [], "entities": [{"text": "labeled dependency accuracy", "start_pos": 37, "end_pos": 64, "type": "METRIC", "confidence": 0.7034002542495728}]}, {"text": "This was not statistically significantly different from the top-ranked score of 73.44%.", "labels": [], "entities": []}, {"text": "For Spanish, our labeled dependency accuracy of 80.36% is within 0.1% of the third-ranked score of 80.46%.", "labels": [], "entities": [{"text": "labeled dependency accuracy", "start_pos": 17, "end_pos": 44, "type": "METRIC", "confidence": 0.6704275608062744}]}, {"text": "Our unlabeled dependency accuracy for Swedish was the best of all the systems at 89.54%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.8968020081520081}]}, {"text": "Our labeled accuracy for Swedish, however, at 79.69%, fell far short of the third-best score of 82.31%.", "labels": [], "entities": [{"text": "labeled", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.9415470361709595}, {"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.778136670589447}]}, {"text": "We therefore focus on Swedish when considering the impact of our choice of learning algorithm on our label accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 107, "end_pos": 115, "type": "METRIC", "confidence": 0.8514837622642517}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Results on CoNLL 2006 shared task.", "labels": [], "entities": [{"text": "CoNLL 2006 shared task", "start_pos": 21, "end_pos": 43, "type": "DATASET", "confidence": 0.8688611090183258}]}]}