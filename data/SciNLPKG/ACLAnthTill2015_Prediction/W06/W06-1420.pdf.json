{"title": [{"text": "Building a semantically transparent corpus for the generation of referring expressions", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper discusses the construction of a corpus for the evaluation of algorithms that generate referring expressions.", "labels": [], "entities": []}, {"text": "It is argued that such an evaluation task requires a semantically transparent corpus, and controlled experiments are the best way to create such a resource.", "labels": [], "entities": []}, {"text": "We address a number of issues that have arisen in an ongoing evaluation study, among which is the problem of judging the output of GRE algorithms against a human gold standard.", "labels": [], "entities": [{"text": "GRE algorithms", "start_pos": 131, "end_pos": 145, "type": "TASK", "confidence": 0.6752160787582397}]}, {"text": "1 Creating and using a corpus for GRE A decade ago, Dale and Reiter (1995) published a seminal paper in which they compared a number of GRE algorithms.", "labels": [], "entities": []}, {"text": "These algorithms included a Full Brevity (FB) algorithm which generates descriptions of minimal length, a greedy algorithm (GA), and an Incremental Algorithm (IA).", "labels": [], "entities": [{"text": "Full Brevity (FB", "start_pos": 28, "end_pos": 44, "type": "METRIC", "confidence": 0.7370817214250565}]}, {"text": "The authors argued that the latter was the best model of human referential behaviour, and versions of the IA have since come to represent the state of the art in GRE.", "labels": [], "entities": [{"text": "human referential behaviour", "start_pos": 57, "end_pos": 84, "type": "TASK", "confidence": 0.6445744931697845}, {"text": "GRE", "start_pos": 162, "end_pos": 165, "type": "TASK", "confidence": 0.5133731961250305}]}, {"text": "Dale and Reiter's hypothesis was motivated by psycholinguistic findings, notably that speakers tend to initiate references before they have completely scanned a domain.", "labels": [], "entities": []}, {"text": "However, this finding affords different algorithmic interpretations.", "labels": [], "entities": []}, {"text": "Similarly, the finding that basic-level terms in referring expressions allow hearers to form a psychological gestalt could be incorporated into practically any GRE algorithm.", "labels": [], "entities": []}, {"text": "1 We decided to put Dale and Reiter's hypothesis to the test by an evaluation of the output of dif-1 A separate argument for IA involves tractability, but although some alternatives (such as FB) are intractable, others (such as GA) are only polynomial, and can therefore not easily be dismissed on purely computational grounds.", "labels": [], "entities": [{"text": "IA", "start_pos": 125, "end_pos": 127, "type": "TASK", "confidence": 0.9193840622901917}, {"text": "FB", "start_pos": 191, "end_pos": 193, "type": "METRIC", "confidence": 0.835282027721405}]}, {"text": "ferent GRE algorithms against human production.", "labels": [], "entities": []}, {"text": "However, it is notoriously difficult to obtain suitable corpora fora task that is as semantically intensive as Content Determination (for GRE).", "labels": [], "entities": [{"text": "Content Determination", "start_pos": 111, "end_pos": 132, "type": "TASK", "confidence": 0.7232329994440079}]}, {"text": "Although existing corpora are valuable resources, NLG often requires information that is not available in text.", "labels": [], "entities": []}, {"text": "Suppose, for example, that a corpus contained articles about politics, how would the output of a GRE algorithm be evaluated against the corpus?", "labels": [], "entities": []}, {"text": "It would be difficult to infer from an article exactly which representatives in the British House of Commons are Liberal Democrats, or Scottish.", "labels": [], "entities": [{"text": "British House of Commons", "start_pos": 84, "end_pos": 108, "type": "DATASET", "confidence": 0.926193118095398}]}, {"text": "Combining multiple texts is hazardous, since facts could alter across sources and time.", "labels": [], "entities": []}, {"text": "Moreover, the conditions under which such texts were produced (e.g. fault-critical or not, as explained below) are hard to determine.", "labels": [], "entities": []}, {"text": "A recent GRE evaluation by Gupta and Stent (2005) focused on dialogue corpora, using MAP-TASK and COCONUT, both of which have an associated domain.", "labels": [], "entities": [{"text": "GRE", "start_pos": 9, "end_pos": 12, "type": "TASK", "confidence": 0.7829769253730774}]}, {"text": "Their results show that referent identification in MAPTASK often requires no more than a TYPE attribute, so that none of the algorithms performed better than a baseline.", "labels": [], "entities": [{"text": "referent identification", "start_pos": 24, "end_pos": 47, "type": "TASK", "confidence": 0.8833273351192474}, {"text": "TYPE", "start_pos": 89, "end_pos": 93, "type": "METRIC", "confidence": 0.9898064732551575}]}, {"text": "In contrast to MAPTASK, COCONUT has a more elaborate domain, but it is characterised by a collabora-tive task, and references frequently go beyond the identification criterion that is typically invoked in GRE 2.", "labels": [], "entities": [{"text": "GRE 2", "start_pos": 205, "end_pos": 210, "type": "TASK", "confidence": 0.5565075874328613}]}, {"text": "Mindful of the limitations of existing corpora , and of the extent to which evaluation depends on the corpus understudy, we are using controlled experiments to create a corpus whose construction will ensure that existing algorithms can be adequately differentiated on an identification task.", "labels": [], "entities": []}, {"text": "2 Jordan and Walker (2000) have demonstrated a significantly better match to the human data when task-related constraints are taken into account.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "Like, we focused on firstmention descriptions.", "labels": [], "entities": []}, {"text": "However, we decided to include simple 'disjunctive' references to sets (as in 'the red chair and the black table'), in addition to conjunctions of atomic properties, since these can be handled by essentially the same algorithms).", "labels": [], "entities": []}, {"text": "For generality, we looked at two very different domains.", "labels": [], "entities": []}, {"text": "One of these involved artificially constructed pictures of furniture, where the available attributes and values are relatively easy to determine.", "labels": [], "entities": []}, {"text": "The other involved real photographs of individuals, which provide a richer range of options to subjects.", "labels": [], "entities": []}, {"text": "To date, data has been collected from 19 participants, and analysis is in progress.", "labels": [], "entities": []}, {"text": "Our first challenge was to make the experiment naturalistic.", "labels": [], "entities": []}, {"text": "Subjects were shown 38 randomised trials, each depicting a set of objects, one or two of which were the targets, surrounded by 6 distractors ().", "labels": [], "entities": []}, {"text": "In each case, a minimal distinguishing description of the targets was available.", "labels": [], "entities": []}, {"text": "Subjects were led to believe that they would be describing the targets for an interlocutor.", "labels": [], "entities": []}, {"text": "Once a description was typed, the system removed from the screen what it took to be the referents.", "labels": [], "entities": []}, {"text": "Three groups performed the task in different conditions, namely: \u00b1F aultCritical, where half the subjects in the +F aultCritical case could use location ('in the top left corner').", "labels": [], "entities": [{"text": "\u00b1F aultCritical", "start_pos": 65, "end_pos": 80, "type": "METRIC", "confidence": 0.6634087165196737}]}, {"text": "The +F aultCritical group was told: 'Our program will eventually be used in situations where it is crucial that it understands descriptions accurately.", "labels": [], "entities": []}, {"text": "In these situations, there will often be no option to correct mistakes.", "labels": [], "entities": []}, {"text": "Therefore, (...) you will not get the chance to revise (your description)'.", "labels": [], "entities": []}, {"text": "By contrast, the \u2212F aultCritical subjects were given the opportunity to revise their description should the system have got it wrong.", "labels": [], "entities": [{"text": "aultCritical", "start_pos": 20, "end_pos": 32, "type": "METRIC", "confidence": 0.6871502995491028}]}, {"text": "Subjects in the \u2212Location condition were told that their interlocutor could see exactly the same pictures as they could, but these had been jumbled up; by contrast, +Location subjects were led to believe that their addressee could seethe pictures in exactly the same position.", "labels": [], "entities": []}, {"text": "The second main challenge was to create trials that would distinguish between all the algorithms.", "labels": [], "entities": []}, {"text": "For instance, if trials involved only one attribute, say an object's TYPE (e.g., chair or table), they would not allow us to distinguish IA from FB, as both would always generate the shortest description.", "labels": [], "entities": []}, {"text": "Subtler issues arise with local brevity, an optimisation strategy which requires sufficiently complex trials to make a difference.", "labels": [], "entities": []}], "tableCaptions": []}