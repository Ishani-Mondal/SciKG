{"title": [{"text": "Chinese Word Segmentation and Named Entity Recognition by Character Tagging", "labels": [], "entities": [{"text": "Chinese Word Segmentation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.564124345779419}, {"text": "Named Entity Recognition", "start_pos": 30, "end_pos": 54, "type": "TASK", "confidence": 0.7189840773741404}, {"text": "Character Tagging", "start_pos": 58, "end_pos": 75, "type": "TASK", "confidence": 0.7132143080234528}]}], "abstractContent": [{"text": "This paper describes our word segmenta-tion system and named entity recognition (NER) system for participating in the third SIGHAN Bakeoff.", "labels": [], "entities": [{"text": "named entity recognition (NER)", "start_pos": 55, "end_pos": 85, "type": "TASK", "confidence": 0.7008251746495565}, {"text": "SIGHAN Bakeoff", "start_pos": 124, "end_pos": 138, "type": "DATASET", "confidence": 0.6403426229953766}]}, {"text": "Both of them are based on character tagging, but use different tag sets and different features.", "labels": [], "entities": [{"text": "character tagging", "start_pos": 26, "end_pos": 43, "type": "TASK", "confidence": 0.7967154681682587}]}, {"text": "Evaluation results show that our word segmentation system achieved 93.3% and 94.7% F-score in UPUC and MSRA open tests, and our NER system got 70.84% and 81.32% F-score in LDC and MSRA open tests.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 33, "end_pos": 50, "type": "TASK", "confidence": 0.7604342401027679}, {"text": "F-score", "start_pos": 83, "end_pos": 90, "type": "METRIC", "confidence": 0.9962303042411804}, {"text": "UPUC", "start_pos": 94, "end_pos": 98, "type": "DATASET", "confidence": 0.901788592338562}, {"text": "F-score", "start_pos": 161, "end_pos": 168, "type": "METRIC", "confidence": 0.9928721785545349}]}], "introductionContent": [{"text": "Dealing with word segmentation as character tagging showed good results in last SIGHAN Bakeoff (J.K.).", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 13, "end_pos": 30, "type": "TASK", "confidence": 0.7731724977493286}, {"text": "character tagging", "start_pos": 34, "end_pos": 51, "type": "TASK", "confidence": 0.7381860017776489}, {"text": "last SIGHAN Bakeoff (J.K.)", "start_pos": 75, "end_pos": 101, "type": "DATASET", "confidence": 0.746410126487414}]}, {"text": "It is good at unknown word identification, but only using character-level features sometimes makes mistakes when identifying known words (T.).", "labels": [], "entities": [{"text": "unknown word identification", "start_pos": 14, "end_pos": 41, "type": "TASK", "confidence": 0.6107237339019775}]}, {"text": "Researchers use word-level features (J.K.) to solve this problem.", "labels": [], "entities": []}, {"text": "Based on this idea, we develop a word segmentation system based on character-tagging, which also combine character-level and word-level features.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 33, "end_pos": 50, "type": "TASK", "confidence": 0.7570700645446777}]}, {"text": "In addition, a character-based NER module and a rule-based factoid identification module are developed for post-processing.", "labels": [], "entities": [{"text": "factoid identification", "start_pos": 59, "end_pos": 81, "type": "TASK", "confidence": 0.7614412903785706}]}, {"text": "Named entity recognition based on charactertagging has shown better accuracy than wordbased methods (H..", "labels": [], "entities": [{"text": "Named entity recognition", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.6996171871821085}, {"text": "accuracy", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9986220598220825}]}, {"text": "But the small window of text makes it difficult to recognize the named entities with many characters, such as organization names (H..", "labels": [], "entities": []}, {"text": "Considering about this, we developed a NER system based on character-tagging, which combines word-level and character-level features together.", "labels": [], "entities": []}, {"text": "In addition, in-NE probability is defined in this system to remove incorrect named entities and create new named entities as post-processing.", "labels": [], "entities": []}], "datasetContent": [{"text": "SVMlight (T.Joachims, 1999) was used as SVM tool.", "labels": [], "entities": [{"text": "SVMlight (T.Joachims, 1999)", "start_pos": 0, "end_pos": 27, "type": "DATASET", "confidence": 0.9046355485916138}]}, {"text": "In addition, we used the MSRA training corpus of NER task in this Bakeoff to train our NER post-processing module.", "labels": [], "entities": [{"text": "MSRA training corpus of NER task in this Bakeoff", "start_pos": 25, "end_pos": 73, "type": "DATASET", "confidence": 0.7872814271185133}]}], "tableCaptions": [{"text": " Table 4 Results of Word Segmentation Task (in percentage %)  Corpus  Pre.  Rec.  F-score  Roov  Riv  UPUC  94.4  92.2  93.3  68.0  97.0  MSRA  94.0  95.3  94.7  50.3  96.9", "labels": [], "entities": [{"text": "Word Segmentation Task", "start_pos": 20, "end_pos": 42, "type": "TASK", "confidence": 0.7821346720059713}, {"text": "Corpus  Pre.  Rec.  F-score  Roov  Riv  UPUC  94.4  92.2  93.3  68.0  97.0  MSRA  94.0  95.3  94.7  50.3  96.9", "start_pos": 62, "end_pos": 172, "type": "DATASET", "confidence": 0.855549369752407}]}, {"text": " Table 5 Results of NER Task for LDC corpus (in percentage %)  PER  LOC  ORG  GPE  Overall  Pre.  83.29  58.52  61.48  78.66  76.16  Rec.  66.93  18.87  45.19  79.94  66.21  F-score  74.22  28.57  52.09  79.30  70.84", "labels": [], "entities": [{"text": "NER", "start_pos": 20, "end_pos": 23, "type": "TASK", "confidence": 0.9406895041465759}, {"text": "PER  LOC  ORG  GPE  Overall  Pre.  83.29", "start_pos": 63, "end_pos": 103, "type": "METRIC", "confidence": 0.832940898835659}, {"text": "F-score", "start_pos": 174, "end_pos": 181, "type": "METRIC", "confidence": 0.913745641708374}]}]}