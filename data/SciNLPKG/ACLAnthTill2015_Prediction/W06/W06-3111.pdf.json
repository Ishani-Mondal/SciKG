{"title": [{"text": "Partitioning Parallel Documents Using Binary Segmentation", "labels": [], "entities": [{"text": "Partitioning Parallel Documents", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8597598870595297}]}], "abstractContent": [{"text": "In statistical machine translation, large numbers of parallel sentences are required to train the model parameters.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 3, "end_pos": 34, "type": "TASK", "confidence": 0.683792402346929}]}, {"text": "However, plenty of the bilingual language resources available on web are aligned only at the document level.", "labels": [], "entities": []}, {"text": "To exploit this data, we have to extract the bilingual sentences from these documents.", "labels": [], "entities": []}, {"text": "The common method is to break the documents into segments using predefined anchor words, then these segments are aligned.", "labels": [], "entities": []}, {"text": "This approach is not error free, incorrect alignments may decrease the translation quality.", "labels": [], "entities": []}, {"text": "We present an alternative approach to extract the parallel sentences by partitioning a bilingual document into two pairs.", "labels": [], "entities": []}, {"text": "This process is performed recursively until all the sub-pairs are short enough.", "labels": [], "entities": []}, {"text": "In experiments on the Chinese-English FBIS data, our method was capable of producing translation results comparable to those of a state-of-the-art sentence aligner.", "labels": [], "entities": [{"text": "Chinese-English FBIS data", "start_pos": 22, "end_pos": 47, "type": "DATASET", "confidence": 0.5818019211292267}]}, {"text": "Using a combination of the two approaches leads to better translation performance .", "labels": [], "entities": [{"text": "translation", "start_pos": 58, "end_pos": 69, "type": "TASK", "confidence": 0.9638197422027588}]}], "introductionContent": [{"text": "Current statistical machine translation systems use bilingual sentences to train the parameters of the translation models.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 8, "end_pos": 39, "type": "TASK", "confidence": 0.616760273774465}]}, {"text": "The exploitation of more bilingual sentences automatically and accurately as well as the use of these data with the limited computational requirements become crucial problems.", "labels": [], "entities": []}, {"text": "The conventional method for producing parallel sentences is to break the documents into sentences and to align these sentences using dynamic programming.", "labels": [], "entities": []}, {"text": "Previous investigations can be found in works such as ( and).", "labels": [], "entities": []}, {"text": "A disadvantage is that only the monotone sentence alignments are allowed.", "labels": [], "entities": [{"text": "sentence alignments", "start_pos": 41, "end_pos": 60, "type": "TASK", "confidence": 0.7393809854984283}]}, {"text": "Another approach is the binary segmentation method described in, ( ) and (), which separates along sentence pair into two sub-pairs recursively.", "labels": [], "entities": [{"text": "binary segmentation", "start_pos": 24, "end_pos": 43, "type": "TASK", "confidence": 0.7616707384586334}]}, {"text": "The binary reordering in alignment is allowed but the segmentation decision is only optimum in each recursion step.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 54, "end_pos": 66, "type": "TASK", "confidence": 0.9729675650596619}]}, {"text": "Hence, a combination of both methods is expected to produce a more satisfying result.) performs a two-stage procedure.", "labels": [], "entities": []}, {"text": "The documents are first aligned at level using dynamic programming, the initial alignments are then refined to produce shorter segments using binary segmentation.", "labels": [], "entities": []}, {"text": "But on the Chinese-English FBIS training corpus, the alignment accuracy and recall are lower than with Champollion.", "labels": [], "entities": [{"text": "Chinese-English FBIS training corpus", "start_pos": 11, "end_pos": 47, "type": "DATASET", "confidence": 0.6249588876962662}, {"text": "alignment", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.822698175907135}, {"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9032467603683472}, {"text": "recall", "start_pos": 76, "end_pos": 82, "type": "METRIC", "confidence": 0.9997797608375549}]}, {"text": "We refine the model in ( ) using a log-linar combination of different feature functions and combine it with the approach of).", "labels": [], "entities": []}, {"text": "Here the corpora produced using both approaches are concatenated, and each corpus is assigned a weight.", "labels": [], "entities": []}, {"text": "During the training of the word alignment models, the counts of the lexicon entries are linear interpolated using the corpus weights.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 27, "end_pos": 41, "type": "TASK", "confidence": 0.760846883058548}]}, {"text": "In the experiments on the Chinese-English FBIS corpus the translation performance is improved by 0.4% of the BLEU score compared to the performance only with Champollion.", "labels": [], "entities": [{"text": "Chinese-English FBIS corpus", "start_pos": 26, "end_pos": 53, "type": "DATASET", "confidence": 0.6133172114690145}, {"text": "translation", "start_pos": 58, "end_pos": 69, "type": "TASK", "confidence": 0.9422792196273804}, {"text": "BLEU score", "start_pos": 109, "end_pos": 119, "type": "METRIC", "confidence": 0.9765455722808838}]}, {"text": "The remainder of this paper is structured as follows: First we will briefly review the baseline statistical machine translation system in Section 2.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 108, "end_pos": 127, "type": "TASK", "confidence": 0.6698219180107117}]}, {"text": "Then, in Section 3, we will describe the refined binary segmentation method.", "labels": [], "entities": [{"text": "binary segmentation", "start_pos": 49, "end_pos": 68, "type": "TASK", "confidence": 0.6635110080242157}]}, {"text": "In Section 4.1, we will introduce the methods to extract bilingual sentences from document aligned texts.", "labels": [], "entities": []}, {"text": "The experimental results will be presented in Section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use four different criteria to evaluate the translation results automatically: \u2022 WER (word error rate): The WER is computed as the minimum number of substitution, insertion and deletion operations that have to be performed to convert the generated sentence into the reference sentence, divided by the reference sentence length.", "labels": [], "entities": [{"text": "WER (word error rate)", "start_pos": 84, "end_pos": 105, "type": "METRIC", "confidence": 0.8031511207421621}, {"text": "WER", "start_pos": 111, "end_pos": 114, "type": "METRIC", "confidence": 0.9952162504196167}]}, {"text": "\u2022 PER (position-independent word error rate): A shortcoming of the WER is that it requires a perfect word order.", "labels": [], "entities": [{"text": "PER", "start_pos": 2, "end_pos": 5, "type": "METRIC", "confidence": 0.9972148537635803}, {"text": "position-independent word error rate)", "start_pos": 7, "end_pos": 44, "type": "METRIC", "confidence": 0.7197307765483856}, {"text": "WER", "start_pos": 67, "end_pos": 70, "type": "METRIC", "confidence": 0.7456610202789307}]}, {"text": "The word order of an acceptable sentence can be differ from that of the target sentence, so that the WER measure alone could be misleading.", "labels": [], "entities": [{"text": "WER measure", "start_pos": 101, "end_pos": 112, "type": "METRIC", "confidence": 0.9845989942550659}]}, {"text": "The PER compares the words in the two sentences ignoring the word order.", "labels": [], "entities": [{"text": "PER", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.9520605206489563}]}, {"text": "\u2022 BLEU score: This score measures the precision of unigrams, bigrams, trigrams and fourgrams with a penalty for too short sentences.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 2, "end_pos": 12, "type": "METRIC", "confidence": 0.9849511086940765}, {"text": "precision", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.998904824256897}]}, {"text": "\u2022 NIST score: This score is similar to BLEU, but it uses an arithmetic average of N-gram counts rather than a geometric average, and it weights more heavily those N-grams that are more informative.).", "labels": [], "entities": [{"text": "NIST score", "start_pos": 2, "end_pos": 12, "type": "METRIC", "confidence": 0.7695425748825073}, {"text": "BLEU", "start_pos": 39, "end_pos": 43, "type": "METRIC", "confidence": 0.9936954379081726}]}, {"text": "The BLEU and NIST scores measure accuracy, i.e. larger scores are better.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.9973547458648682}, {"text": "NIST", "start_pos": 13, "end_pos": 17, "type": "DATASET", "confidence": 0.7831516265869141}, {"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9996381998062134}]}, {"text": "In our evaluation the scores are measured as case insensitive and with respect to multiple references.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Corpus Statistics: NIST", "labels": [], "entities": [{"text": "Corpus Statistics", "start_pos": 10, "end_pos": 27, "type": "DATASET", "confidence": 0.6902241855859756}, {"text": "NIST", "start_pos": 29, "end_pos": 33, "type": "DATASET", "confidence": 0.49785831570625305}]}, {"text": " Table 2: Corpus Statistics: FBIS  Segmentation  Champollion  Chinese  English  Chinese  English  Train  Sentences  739 899  177 798  Running Words 8 588 477 10 111 752 7 659 776 9 801 257  Average Sentence Length  11.6  13.7  43.1  55.1  Vocabulary  34 896  56 573  34 377  55 775  Singletons  4 775  19 283  4 588  19 004  Evaluation  Sentences  878  3 513  878  3 513  Running Words  24 111  105 516  24 111  105 516  Vocabulary  4 095  6 802  4 095  6 802  OOVs (Running Words)  109  2 257  119  2 309", "labels": [], "entities": [{"text": "FBIS  Segmentation  Champollion  Chinese  English  Chinese  English  Train  Sentences  739 899  177 798  Running Words", "start_pos": 29, "end_pos": 147, "type": "TASK", "confidence": 0.7767033020655314}, {"text": "Average Sentence Length", "start_pos": 190, "end_pos": 213, "type": "METRIC", "confidence": 0.8507595658302307}]}, {"text": " Table 3: Translation Results using Refined Segmentation Methods on NIST task", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9859743714332581}, {"text": "NIST", "start_pos": 68, "end_pos": 72, "type": "DATASET", "confidence": 0.8987593054771423}]}, {"text": " Table 4: Translation Results on Sentence Alignment Task with FBIS Training Corpus", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9552309513092041}, {"text": "Sentence Alignment", "start_pos": 33, "end_pos": 51, "type": "TASK", "confidence": 0.9723666906356812}, {"text": "FBIS Training", "start_pos": 62, "end_pos": 75, "type": "DATASET", "confidence": 0.7676362693309784}]}]}