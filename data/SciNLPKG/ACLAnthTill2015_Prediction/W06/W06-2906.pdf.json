{"title": [{"text": "Resolving and Generating Definite Anaphora by Modeling Hypernymy using Unlabeled Corpora", "labels": [], "entities": [{"text": "Resolving and Generating Definite Anaphora", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.5817539751529693}]}], "abstractContent": [{"text": "We demonstrate an original and successful approach for both resolving and generating definite anaphora.", "labels": [], "entities": []}, {"text": "We propose and evaluate unsupervised models for extracting hypernym relations by mining co-occurrence data of definite NPs and potential antecedents in an unlabeled corpus.", "labels": [], "entities": [{"text": "extracting hypernym relations", "start_pos": 48, "end_pos": 77, "type": "TASK", "confidence": 0.8229242364565531}]}, {"text": "The algorithm outperforms a standard WordNet-based approach to resolving and generating definite anaphora.", "labels": [], "entities": []}, {"text": "It also substantially outperforms recent related work using pattern-based extraction of such hypernym relations for corefer-ence resolution.", "labels": [], "entities": [{"text": "corefer-ence resolution", "start_pos": 116, "end_pos": 139, "type": "TASK", "confidence": 0.8842081129550934}]}], "introductionContent": [{"text": "Successful resolution and generation of definite anaphora requires knowledge of hypernym and hyponym relationships.", "labels": [], "entities": []}, {"text": "For example, determining the antecedent to the definite anaphor \"the drug\" in text requires knowledge of what previous noun-phrase candidates could be drugs.", "labels": [], "entities": []}, {"text": "Likewise, generating a definite anaphor for the antecedent \"Morphine\" in text requires both knowledge of potential hypernyms (e.g. \"the opiate\", \"the narcotic\", \"the drug\", and \"the substance\"), as well as selection of the most appropriate level of generality along the hypernym tree in context (i.e. the \"natural\" hypernym anaphor).", "labels": [], "entities": []}, {"text": "Unfortunately existing manual hypernym databases such as WordNet are very incomplete, especially for technical vocabulary and proper names.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 57, "end_pos": 64, "type": "DATASET", "confidence": 0.9781147837638855}]}, {"text": "WordNets are also limited or non-existent for most of the world's languages.", "labels": [], "entities": [{"text": "WordNets", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.871440589427948}]}, {"text": "Finally, WordNets also do not include notation of the \"natural\" hypernym level for anaphora generation, and using the immediate parent performs quite poorly, as quantified in Section 5.", "labels": [], "entities": [{"text": "WordNets", "start_pos": 9, "end_pos": 17, "type": "DATASET", "confidence": 0.9311268329620361}, {"text": "anaphora generation", "start_pos": 83, "end_pos": 102, "type": "TASK", "confidence": 0.7424864172935486}]}, {"text": "In first part of this paper, we propose a novel approach for resolving definite anaphora involving hyponymy relations.", "labels": [], "entities": []}, {"text": "We show that it performs substantially better than previous approaches on the task of antecedent selection.", "labels": [], "entities": []}, {"text": "In the second part we demonstrate how this approach can be successfully extended to the problem of generating a natural definite NP given a specific antecedent.", "labels": [], "entities": []}, {"text": "In order to explain the antecedent selection task for definite anaphora clearly, we provide the following example taken from the LDC Gigaword corpus ().", "labels": [], "entities": [{"text": "LDC Gigaword corpus", "start_pos": 129, "end_pos": 148, "type": "DATASET", "confidence": 0.866582194964091}]}, {"text": "(1)...pseudoephedrine is found in an allergy treatment, which was given to Wilson by a doctor when he attended Blinn junior college in Houston.", "labels": [], "entities": []}, {"text": "Ina unanimous vote, the Norwegian sports confederation ruled that Wilson had not taken the drug to enhance his performance...", "labels": [], "entities": [{"text": "Norwegian sports confederation", "start_pos": 24, "end_pos": 54, "type": "DATASET", "confidence": 0.8291910489400228}]}, {"text": "In the above example, the task is to resolve the definite NP the drug to its correct antecedent pseudoephedrine, among the potential antecedents <pseudoephedrine, allergy, blinn, college, houston, vote, confederation, wilson>.", "labels": [], "entities": []}, {"text": "Only Wilson can be ruled out on syntactic grounds.", "labels": [], "entities": []}, {"text": "To be able to resolve the correct antecedent from the remaining potential antecedents, the system requires the knowledge that pseudoephedrine is a drug.", "labels": [], "entities": []}, {"text": "Thus, the problem is to create such a knowledge source and apply it to this task of antecedent selection.", "labels": [], "entities": []}, {"text": "A total of 177 such anaphoric examples were extracted randomly from the LDC Gigaword corpus and a human judge identified the correct antecedent for the definite NP in each example (given a context of previous sentences).", "labels": [], "entities": [{"text": "LDC Gigaword corpus", "start_pos": 72, "end_pos": 91, "type": "DATASET", "confidence": 0.8995005091031393}]}, {"text": "Two human judges were asked to perform the same task over the same examples.", "labels": [], "entities": []}, {"text": "The agreement between the judges was 92% (of all 177 examples), indicating a clearly defined task for our evaluation purposes.", "labels": [], "entities": []}, {"text": "We describe an unsupervised approach to this task that extracts examples containing definite NPs from a large corpus, considers all head words appearing before the definite NP as potential antecedents and then filters the noisy <antecedent, definite-NP> pair using Mutual Information space.", "labels": [], "entities": []}, {"text": "The co-occurence statistics of such pairs can then be used as a mechanism for detecting a hypernym relation between the definite NP and its potential antecedents.", "labels": [], "entities": []}, {"text": "We compare this approach with a WordNet-based algorithm and with an approach presented by Markert and Nissim (2005) on resolving definite NP coreference that makes use of lexico-syntactic patterns such as 'X and Other Ys' as utilized by Hearst (1992).", "labels": [], "entities": [{"text": "resolving definite NP coreference", "start_pos": 119, "end_pos": 152, "type": "TASK", "confidence": 0.5619729906320572}]}], "datasetContent": [{"text": "We extracted a total of 103 <true antecedent, definite NP> pairs from the set of test instances used in the resolution task.", "labels": [], "entities": [{"text": "resolution task", "start_pos": 108, "end_pos": 123, "type": "TASK", "confidence": 0.9120270609855652}]}, {"text": "Then we asked a human judge (a native speaker of English) to predict a parent class of the antecedent that could act as a good definite anaphora choice in general, independent of a particular context.", "labels": [], "entities": []}, {"text": "Thus, the actual corpus sentence containing the antecedent and definite NP and its context was not provided to the judge.", "labels": [], "entities": []}, {"text": "We took the predictions provided by the judge and matched them with the actual definite NPs used in the corpus.", "labels": [], "entities": []}, {"text": "The agreement between corpus and the human judge was 79% which can thus be considered as an upper bound of algorithm performance.", "labels": [], "entities": []}, {"text": "shows a sample of decisions made by the human and how they agree with the definite NPs observed in the corpus.", "labels": [], "entities": []}, {"text": "It is interesting to note the challenge of the sense variation and figurative usage.", "labels": [], "entities": []}, {"text": "For example, \"corruption\" is refered to as a \"tool\" in the actual corpus anaphora, a metaphoric usage that would be difficult to predict unless given the usage sentence and its context.", "labels": [], "entities": []}, {"text": "However, a human agreement of 79% indicate that such instances are relatively rare and the task of predicting a definite anaphor without its context is viable.", "labels": [], "entities": [{"text": "predicting a definite anaphor", "start_pos": 99, "end_pos": 128, "type": "TASK", "confidence": 0.8696504831314087}]}, {"text": "In general, it appears from our experiements that humans tend to select from a relatively small set of parent classes when generating hypernymic definite anaphora.", "labels": [], "entities": []}, {"text": "Furthermore, there appears to be a relatively context-independent concept of the \"natural\" level in the hypernym hierarchy for generating anaphors.", "labels": [], "entities": []}, {"text": "For example, although <\"alkaloid\", \"organic compound\", \"compound\", \"substance\", \"entity\"> are all hypernyms of \"Pseudoephederine\" in WordNet, \"the drug\" appears to be the preferred hypernym for definite anaphora in the data, with the other alternatives being either too specific or too general to be natural.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 133, "end_pos": 140, "type": "DATASET", "confidence": 0.9502114057540894}]}, {"text": "This natural level appears to be difficult to define by rule.", "labels": [], "entities": []}, {"text": "For example, using just the immediate parent hypernym in the WordNet hierarchy only achieves 4% match with the corpus data for definite anaphor generation.", "labels": [], "entities": [{"text": "WordNet hierarchy", "start_pos": 61, "end_pos": 78, "type": "DATASET", "confidence": 0.9379616379737854}, {"text": "definite anaphor generation", "start_pos": 127, "end_pos": 154, "type": "TASK", "confidence": 0.6211693386236826}]}, {"text": "We evaluated the resulting algorithms from Section 5.2 on the definite NP prediction task as described earlier.", "labels": [], "entities": [{"text": "NP prediction task", "start_pos": 71, "end_pos": 89, "type": "TASK", "confidence": 0.8501733938852946}]}, {"text": "shows the agreement of the algorithm predictions with the human judge as well as with the definite NP actually observed in the corpus.", "labels": [], "entities": [{"text": "agreement", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9594945907592773}]}, {"text": "It is interesting to see that WordNet by itself performs very poorly on this task since it does not have any word-specific mechanism to choose the correct level in the hierarchy and the correct word sense for selecting the hypernym.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 30, "end_pos": 37, "type": "DATASET", "confidence": 0.9174299836158752}]}, {"text": "However, when combined with our corpus-based approaches, the agreement increases substantially indicating that the corpusbased approaches are effectively filtering the space of hypernyms that can be used as natural classes.", "labels": [], "entities": [{"text": "agreement", "start_pos": 61, "end_pos": 70, "type": "METRIC", "confidence": 0.9754296541213989}]}, {"text": "Likewise, WordNet helps to filter the noisy hypernyms from the corpus predictions.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 10, "end_pos": 17, "type": "DATASET", "confidence": 0.964935839176178}]}, {"text": "Thus, this interplay between the corpus-based and WordNet algorithm works out nicely, resulting in the best model being a combination of all three individual models and achieving a substantially better agreement with both the corpus and human judge than any of the individual models.", "labels": [], "entities": []}, {"text": "shows decisions made by this algorithm on a sample test data.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: A sample of ranked hyponyms proposed for  the definite NP The drug by TheY-Model illustrat- ing the differences in weighting methods.", "labels": [], "entities": []}, {"text": " Table 2: Results using different normalization tech- niques for the TheY-Model in isolation. (60 million  word corpus)", "labels": [], "entities": [{"text": "TheY-Model", "start_pos": 69, "end_pos": 79, "type": "DATASET", "confidence": 0.9778003692626953}]}, {"text": " Table 3: Accuracy and Average Rank showing com- bined model performance on the antecedent selec- tion task. Corpus Size: 60 million words.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9987061023712158}, {"text": "Average Rank", "start_pos": 23, "end_pos": 35, "type": "METRIC", "confidence": 0.969741940498352}]}, {"text": " Table 4: A sample of output from different models on antecedent selection (60 million word corpus).", "labels": [], "entities": []}, {"text": " Table 5. We also implemented a combination (Oth- erY+WN) of Other-Y model and WordNet-Model  by replacing TheY-Model with OtherY-Model in the  algorithm described in Section 3.3. The respective  results are indicated as OtherY+WN entry in", "labels": [], "entities": [{"text": "Oth- erY+WN)", "start_pos": 45, "end_pos": 57, "type": "METRIC", "confidence": 0.9022214412689209}, {"text": "WordNet-Model", "start_pos": 79, "end_pos": 92, "type": "DATASET", "confidence": 0.9374695420265198}]}, {"text": " Table 6: Agreement of different generation models  with human judge and with definite NP used in the  corpus.", "labels": [], "entities": []}]}