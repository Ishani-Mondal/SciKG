{"title": [{"text": "Cluster-based Language Model for Sentence Retrieval in Chinese Question Answering", "labels": [], "entities": [{"text": "Sentence Retrieval in Chinese Question Answering", "start_pos": 33, "end_pos": 81, "type": "TASK", "confidence": 0.7158673256635666}]}], "abstractContent": [{"text": "Sentence retrieval plays a very important role in question answering system.", "labels": [], "entities": [{"text": "Sentence retrieval", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9494868516921997}, {"text": "question answering", "start_pos": 50, "end_pos": 68, "type": "TASK", "confidence": 0.8558006584644318}]}, {"text": "In this paper, we present a novel cluster-based language model for sentence retrieval in Chinese question answering which is motivated in part by sentence clustering and language model.", "labels": [], "entities": [{"text": "sentence retrieval", "start_pos": 67, "end_pos": 85, "type": "TASK", "confidence": 0.7336404919624329}, {"text": "Chinese question answering", "start_pos": 89, "end_pos": 115, "type": "TASK", "confidence": 0.6149263481299082}, {"text": "sentence clustering", "start_pos": 146, "end_pos": 165, "type": "TASK", "confidence": 0.712533101439476}]}, {"text": "Sentence clustering is used to group sentences into clusters.", "labels": [], "entities": [{"text": "Sentence clustering", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8954196870326996}]}, {"text": "Language model is used to properly represent sentences, which is combined with sentences model, cluster/topic model and collection model.", "labels": [], "entities": []}, {"text": "For sentence clustering, we propose two approaches that are One-Sentence-Multi-Topics and One-Sentence-One-Topic respectively.", "labels": [], "entities": [{"text": "sentence clustering", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.7322797626256943}]}, {"text": "From the experimental results on 807 Chinese testing questions, we can conclude that the proposed cluster-based language model outperforms over the standard language model for sentence retrieval in Chinese question answering.", "labels": [], "entities": [{"text": "sentence retrieval in Chinese question answering", "start_pos": 176, "end_pos": 224, "type": "TASK", "confidence": 0.6336506406466166}]}], "introductionContent": [{"text": "To facilitate the answer extraction of question answering, the task of retrieval module is to find the most relevant passages or sentences to the question.", "labels": [], "entities": [{"text": "answer extraction", "start_pos": 18, "end_pos": 35, "type": "TASK", "confidence": 0.7578983008861542}, {"text": "question answering", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.7263073623180389}]}, {"text": "So, the retrieval module plays a very important role in question answering system, which influences both the performance and the speed of question answering.", "labels": [], "entities": [{"text": "question answering", "start_pos": 56, "end_pos": 74, "type": "TASK", "confidence": 0.8946239650249481}, {"text": "question answering", "start_pos": 138, "end_pos": 156, "type": "TASK", "confidence": 0.7706256806850433}]}, {"text": "In this paper, we mainly focus on the research of improving the performance of sentence retrieval in Chinese question answering.", "labels": [], "entities": [{"text": "sentence retrieval", "start_pos": 79, "end_pos": 97, "type": "TASK", "confidence": 0.7104004472494125}, {"text": "Chinese question answering", "start_pos": 101, "end_pos": 127, "type": "TASK", "confidence": 0.6006759206453959}]}, {"text": "Many retrieval approaches have been proposed for sentence retrieval in English question answering.", "labels": [], "entities": [{"text": "sentence retrieval in English question answering", "start_pos": 49, "end_pos": 97, "type": "TASK", "confidence": 0.627100259065628}]}, {"text": "For example, Ittycheriach and H. Yang proposed vector space model.", "labels": [], "entities": []}, {"text": "Andres and Vanessa  proposed language model and translation model respectively.", "labels": [], "entities": [{"text": "translation", "start_pos": 48, "end_pos": 59, "type": "TASK", "confidence": 0.9669500589370728}]}, {"text": "Compared to vector space model, language model is theoretically attractive and a potentially very effective probabilistic framework for researching information retrieval problems.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 148, "end_pos": 169, "type": "TASK", "confidence": 0.7217411696910858}]}, {"text": "However, language model for sentence retrieval is not mature yet, which has a lot of difficult problems that cannot be solved at present.", "labels": [], "entities": [{"text": "sentence retrieval", "start_pos": 28, "end_pos": 46, "type": "TASK", "confidence": 0.7552565634250641}]}, {"text": "For example, how to incorporate the structural information, how to resolve data sparseness problem.", "labels": [], "entities": []}, {"text": "In this paper, we mainly focus on the research of the smoothing approach of language model because sparseness problem is more serious for sentence retrieval than for document retrieval.", "labels": [], "entities": [{"text": "document retrieval", "start_pos": 166, "end_pos": 184, "type": "TASK", "confidence": 0.6626928895711899}]}, {"text": "At present, the most popular smoothing approaches for language model are Jelinek-Mercer method, Bayesian smoothing using Dirichlet priors, absolute discounting and soon [C..", "labels": [], "entities": []}, {"text": "The main disadvantages of all these smoothing approaches are that each document model (which is estimated from each document) is interpolated with the same collection model (which is estimated from the whole collection) through a unified parameter.", "labels": [], "entities": []}, {"text": "Therefore, it does not make anyone particular document more probable than any other, on the condition that neither the documents originally contains the query term.", "labels": [], "entities": []}, {"text": "In other word, if a document is relevant, but does not contain the query term, it is still no more probable, even though it maybe topically related.", "labels": [], "entities": []}, {"text": "As we know, most smoothing approaches of sentence retrieval in question answering are learned from document retrieval without many adaptations.", "labels": [], "entities": [{"text": "sentence retrieval in question answering", "start_pos": 41, "end_pos": 81, "type": "TASK", "confidence": 0.7230480074882507}]}, {"text": "In fact, question answering has some characteristics that are different from traditional document retrieval, which could be used to improve the performance of sentence retrieval.", "labels": [], "entities": [{"text": "question answering", "start_pos": 9, "end_pos": 27, "type": "TASK", "confidence": 0.8633573651313782}, {"text": "sentence retrieval", "start_pos": 159, "end_pos": 177, "type": "TASK", "confidence": 0.6950313150882721}]}, {"text": "These characteristics lie in: 1.", "labels": [], "entities": []}, {"text": "The input of question answering is natural language question which is more unambiguous than query in traditional document retrieval.", "labels": [], "entities": [{"text": "question answering", "start_pos": 13, "end_pos": 31, "type": "TASK", "confidence": 0.7435890436172485}]}, {"text": "For traditional document retrieval, it's difficult to identify which kind of information the users want to know.", "labels": [], "entities": [{"text": "document retrieval", "start_pos": 16, "end_pos": 34, "type": "TASK", "confidence": 0.7484510242938995}]}, {"text": "For example, if the user submit the query {\u53d1\u660e/invent, \u7535\u8bdd/telephone}, search engine does not know what information is needed, who invented telephone, when telephone was invented, or other information.", "labels": [], "entities": []}, {"text": "On the other hand, for question answering system, if the user submit the question {\u8c01\u53d1\u660e\u4e86\u7535\u8bdd\uff1f/who invented the telephone?}, it's easy to know that the user want to know the person who invented the telephone, but not other information.", "labels": [], "entities": [{"text": "question answering", "start_pos": 23, "end_pos": 41, "type": "TASK", "confidence": 0.8389023840427399}]}], "datasetContent": [{"text": "Research on Chinese question answering, is still at its early stage.", "labels": [], "entities": [{"text": "Chinese question answering", "start_pos": 12, "end_pos": 38, "type": "TASK", "confidence": 0.7025991578896841}]}, {"text": "And there is no public evaluation platform for Chinese question answering.", "labels": [], "entities": [{"text": "Chinese question answering", "start_pos": 47, "end_pos": 73, "type": "TASK", "confidence": 0.6222523152828217}]}, {"text": "So in this paper, we use the evaluation environment presented by] which is similar to TREC question answering track.", "labels": [], "entities": [{"text": "TREC question answering", "start_pos": 86, "end_pos": 109, "type": "TASK", "confidence": 0.608836442232132}]}, {"text": "The documents collection is downloaded from Internet which size is 1.8GB.", "labels": [], "entities": []}, {"text": "The testing questions are collected via four different approaches which has 7050 Chinese questions currently.", "labels": [], "entities": []}, {"text": "In this section, we randomly select 807 testing questions which are fact-based short-answer questions.", "labels": [], "entities": []}, {"text": "Moreover, the answers of all testing questions are named entities identified by. gives the details.", "labels": [], "entities": []}, {"text": "Note that, LOC, ORG, PER, NUM and TIM denote the questions which answer types are location, organization, person, number and time respectively, SUM means all question types.", "labels": [], "entities": [{"text": "LOC", "start_pos": 11, "end_pos": 14, "type": "METRIC", "confidence": 0.9839779734611511}, {"text": "ORG", "start_pos": 16, "end_pos": 19, "type": "METRIC", "confidence": 0.9936218857765198}, {"text": "PER", "start_pos": 21, "end_pos": 24, "type": "METRIC", "confidence": 0.9886952042579651}, {"text": "TIM", "start_pos": 34, "end_pos": 37, "type": "METRIC", "confidence": 0.9939416646957397}]}, {"text": "Chinese question answering system is to return a ranked list of five answer sentences per question and will be strictly evaluated (unsupported answers counted as wrong) using mean reciprocal rank (MRR).", "labels": [], "entities": [{"text": "question answering", "start_pos": 8, "end_pos": 26, "type": "TASK", "confidence": 0.7711821496486664}, {"text": "mean reciprocal rank (MRR)", "start_pos": 175, "end_pos": 201, "type": "METRIC", "confidence": 0.8851361274719238}]}], "tableCaptions": [{"text": " Table 4 The Baseline MRR5 Performance", "labels": [], "entities": [{"text": "Baseline MRR5", "start_pos": 13, "end_pos": 26, "type": "DATASET", "confidence": 0.7350243330001831}]}, {"text": " Table 5.  The relative improvements are listed in the  bracket.", "labels": [], "entities": []}, {"text": " Table 5 MRR5 Performance of Cluster-based  Language Model Based on One-Sentence-Multi- Topics", "labels": [], "entities": [{"text": "MRR5", "start_pos": 9, "end_pos": 13, "type": "METRIC", "confidence": 0.4917031526565552}]}, {"text": " Table 6. The relative  improvements are listed in the bracket.", "labels": [], "entities": []}, {"text": " Table 6 MRR5 Performance of Cluster-based  Language Model Based on One-Sentence-One- Topic", "labels": [], "entities": [{"text": "MRR5", "start_pos": 9, "end_pos": 13, "type": "METRIC", "confidence": 0.5251455307006836}]}, {"text": " Table 7 MRR1 and MRR20 Performances of  Two Cluster-based Language Models", "labels": [], "entities": [{"text": "MRR1", "start_pos": 9, "end_pos": 13, "type": "DATASET", "confidence": 0.6680617928504944}, {"text": "MRR20", "start_pos": 18, "end_pos": 23, "type": "METRIC", "confidence": 0.8014484643936157}]}]}