{"title": [{"text": "Evaluating and optimizing the parameters of an unsupervised graph-based WSD algorithm", "labels": [], "entities": []}], "abstractContent": [{"text": "V\u00e9ronis (2004) has recently proposed an innovative unsupervised algorithm for word sense disambiguation based on small-world graphs called HyperLex.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 78, "end_pos": 103, "type": "TASK", "confidence": 0.8050975402196249}]}, {"text": "This paper explores two sides of the algorithm.", "labels": [], "entities": []}, {"text": "First, we extend V\u00e9ronis' work by optimizing the free parameters (on a set of words which is different to the target set).", "labels": [], "entities": []}, {"text": "Second, given that the empirical comparison among unsupervised systems (and with respect to supervised systems) is seldom made, we used hand-tagged corpora to map the induced senses to a standard lexicon (WordNet) and a publicly available gold standard (Senseval 3 English Lexical Sample).", "labels": [], "entities": []}, {"text": "Our results for nouns show that thanks to the optimization of parameters and the mapping method, Hy-perLex obtains results close to supervised systems using the same kind of bag-of-words features.", "labels": [], "entities": []}, {"text": "Given the information loss inherent in any mapping step and the fact that the parameters were tuned for another set of words, these are very interesting results.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word sense disambiguation (WSD) is a key enabling technology.", "labels": [], "entities": [{"text": "Word sense disambiguation (WSD)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8037643581628799}]}, {"text": "Supervised WSD techniques are the best performing in public evaluations, but need large amounts of hand-tagging data.", "labels": [], "entities": [{"text": "WSD", "start_pos": 11, "end_pos": 14, "type": "TASK", "confidence": 0.9828711748123169}]}, {"text": "Existing handannotated corpora like SemCor (, which is annotated with WordNet senses) allow fora small improvement over the simple most frequent sense heuristic, as attested in the allwords track of the last Senseval competition).", "labels": [], "entities": []}, {"text": "In theory, larger amounts of training data (SemCor has approx. 500M words) would improve the performance of supervised WSD, but no current project exists to provide such an expensive resource.", "labels": [], "entities": [{"text": "WSD", "start_pos": 119, "end_pos": 122, "type": "TASK", "confidence": 0.9278930425643921}]}, {"text": "Supervised WSD is based on the \"fixed-list of senses\" paradigm, where the senses fora target word area closed list coming from a dictionary or lexicon.", "labels": [], "entities": [{"text": "WSD", "start_pos": 11, "end_pos": 14, "type": "TASK", "confidence": 0.9132317304611206}]}, {"text": "Lexicographers and semanticists have long warned about the problems of such an approach, where senses are listed separately as discrete entities, and have argued in favor of more complex representations, where, for instance, senses are dense regions in a continuum.", "labels": [], "entities": []}, {"text": "Unsupervised WSD has followed this line of thinking, and tries to induce word senses directly from the corpus.", "labels": [], "entities": [{"text": "WSD", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.9596430063247681}]}, {"text": "Typical unsupervised WSD systems involve clustering techniques, which group together similar examples.", "labels": [], "entities": [{"text": "WSD", "start_pos": 21, "end_pos": 24, "type": "TASK", "confidence": 0.9667264223098755}]}, {"text": "Given a set of induced clusters (which represent word uses or senses 1 ), each new occurrence of the target word will be compared to the clusters and the most similar cluster will be selected as its sense.", "labels": [], "entities": []}, {"text": "Most of the unsupervised WSD work has been based on the vector space model, where each example is represented by a vector of features (e.g. the words occurring in the context).", "labels": [], "entities": [{"text": "WSD", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.9309402704238892}]}, {"text": "Recently, V\u00e9ronis) has proposed HyperLex, an application of graph models to WSD based on the small-world properties of cooccurrence graphs.", "labels": [], "entities": [{"text": "WSD", "start_pos": 76, "end_pos": 79, "type": "TASK", "confidence": 0.8791239857673645}]}, {"text": "Hand inspection of the clusters (called hubs in this setting) by the author was very positive, with hubs capturing the main senses of the words.", "labels": [], "entities": []}, {"text": "Besides, hand inspection of the disambiguated occurrences yielded precisions over 95% (compared to a most frequent baseline of 73%) which is an outstanding figure for WSD systems.", "labels": [], "entities": [{"text": "precisions", "start_pos": 66, "end_pos": 76, "type": "METRIC", "confidence": 0.9996870756149292}, {"text": "WSD", "start_pos": 167, "end_pos": 170, "type": "TASK", "confidence": 0.9454199075698853}]}, {"text": "We noticed that HyperLex had some free parameters and had not been evaluated against a public gold standard.", "labels": [], "entities": [{"text": "HyperLex", "start_pos": 16, "end_pos": 24, "type": "DATASET", "confidence": 0.8637396097183228}]}, {"text": "Besides, we were struck by the few works where supervised and unsupervised systems were evaluated on the same test data.", "labels": [], "entities": []}, {"text": "In this paper we use an automatic method to map the induced senses to WordNet using hand-tagged corpora, enabling the automatic evaluation against available gold standards (Senseval 3 English Lexical Sample S3LS () and the automatic optimization of the free parameters of the method.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 70, "end_pos": 77, "type": "DATASET", "confidence": 0.9589247107505798}]}, {"text": "The use of hand-tagged corpora for tagging makes this algorithm a mixture of unsupervised and supervised: the method to induce senses in completely unsupervised, but the mapping is supervised (albeit very straightforward).", "labels": [], "entities": []}, {"text": "This paper is structured as follows.", "labels": [], "entities": []}, {"text": "We first present the graph-based algorithm as proposed by V\u00e9ronis, reviewing briefly the features of smallworld graphs.", "labels": [], "entities": []}, {"text": "Section 3 presents our framework for mapping and evaluating the induced hubs.", "labels": [], "entities": []}, {"text": "Section 4 introduces parameter optimization.", "labels": [], "entities": [{"text": "parameter optimization", "start_pos": 21, "end_pos": 43, "type": "TASK", "confidence": 0.7352094799280167}]}, {"text": "Section 5 shows the experiment setting and results.", "labels": [], "entities": []}, {"text": "Section 6 analyzes the results and presents related work.", "labels": [], "entities": []}, {"text": "Finally, we draw the conclusions and advance future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the HyperLex algorithm in a standard benchmark, we applied it to the 20 nouns in S3LS.", "labels": [], "entities": []}, {"text": "We use the standard training-test split.", "labels": [], "entities": []}, {"text": "Following the design in Section 3, we used both the training and test sets as the Base Corpus (ignoring the sense tags, of course).", "labels": [], "entities": [{"text": "Base Corpus", "start_pos": 82, "end_pos": 93, "type": "DATASET", "confidence": 0.7314844727516174}]}, {"text": "The Mapping Corpus comprised the training split only, and the Test corpus the test split only.", "labels": [], "entities": [{"text": "Test corpus", "start_pos": 62, "end_pos": 73, "type": "DATASET", "confidence": 0.9095508456230164}]}, {"text": "The parameter tuning was done in a similar fashion, but on the S2LS dataset.", "labels": [], "entities": [{"text": "S2LS dataset", "start_pos": 63, "end_pos": 75, "type": "DATASET", "confidence": 0.8720676898956299}]}, {"text": "In we can seethe number of examples of each word in the different corpus and the results of the algorithm.", "labels": [], "entities": []}, {"text": "We indicate only precision, as the coverage is 100% in all cases.", "labels": [], "entities": [{"text": "precision", "start_pos": 17, "end_pos": 26, "type": "METRIC", "confidence": 0.9997274279594421}, {"text": "coverage", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9959782361984253}]}, {"text": "The left column, named MFS, shows the precision when always assigning the most frequent sense (relative to the train split).", "labels": [], "entities": [{"text": "MFS", "start_pos": 23, "end_pos": 26, "type": "METRIC", "confidence": 0.5376465320587158}, {"text": "precision", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9995123147964478}]}, {"text": "This is the baseline of our algorithm as our algorithm does seethe tags in the mapping step (see Section 6 for further comments on this issue).", "labels": [], "entities": []}, {"text": "The default column shows the results for the HyperLex algorithm with the default parameters asset by V\u00e9ronis, except for the minimum frequency of the vertices (p2 in), which according to some preliminary experiments we set to 3.", "labels": [], "entities": []}, {"text": "As we can see, the algorithm with the default settings outperforms combinations.", "labels": [], "entities": []}, {"text": "The horizontal axis shows the similarity of a parameter set w.r.t. the best parameter set using the cosine.", "labels": [], "entities": []}, {"text": "The vertical axis shows the precision in S2LS.", "labels": [], "entities": [{"text": "precision", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.9995718598365784}]}, {"text": "The best fitting line is also depicted.", "labels": [], "entities": []}, {"text": "the MFS baseline by 5.4 points average, and in almost all words (except plan, sort and source).", "labels": [], "entities": [{"text": "MFS baseline", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.8069853484630585}]}, {"text": "The results for the best of 180 combinations of the parameters improve the default setting (0.4 overall), Extending the parameter space to 1800 and 6700 improves the precision up to 63.0 and 64.6, 10.1 over the MFS (MFS only outperforms HyperLex in the best setting for two words).", "labels": [], "entities": [{"text": "precision", "start_pos": 166, "end_pos": 175, "type": "METRIC", "confidence": 0.9996063113212585}, {"text": "MFS", "start_pos": 211, "end_pos": 214, "type": "DATASET", "confidence": 0.8325808048248291}]}, {"text": "The same trend can be seen on the S2LS dataset, where the gain was more modest (note that the parameters were optimized for S2LS).", "labels": [], "entities": [{"text": "S2LS dataset", "start_pos": 34, "end_pos": 46, "type": "DATASET", "confidence": 0.7393255829811096}]}], "tableCaptions": [{"text": " Table 1: Parameters of the HyperLex algorithm", "labels": [], "entities": []}, {"text": " Table 2: Precision figures for nouns over the test corpus (S3LS). The second and third columns show the number of occurrences", "labels": [], "entities": []}, {"text": " Table 3: Average number of hubs and senses (along with the", "labels": [], "entities": [{"text": "Average", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.969860315322876}]}, {"text": " Table 4: Comparison of HyperLex and MFS baseline to S3LS", "labels": [], "entities": [{"text": "MFS baseline", "start_pos": 37, "end_pos": 49, "type": "DATASET", "confidence": 0.8296269476413727}]}]}