{"title": [{"text": "A Robust and Efficient Parser for Non-Canonical Inputs", "labels": [], "entities": []}], "abstractContent": [{"text": "We present in this paper a parser relying on a constraint-based formalism called Property Grammar.", "labels": [], "entities": [{"text": "Property Grammar", "start_pos": 81, "end_pos": 97, "type": "TASK", "confidence": 0.7323974370956421}]}, {"text": "We show how constraints constitute an efficient solution in parsing non canonical material such as spoken language transcription or e-mails.", "labels": [], "entities": [{"text": "parsing non canonical material such as spoken language transcription", "start_pos": 60, "end_pos": 128, "type": "TASK", "confidence": 0.7784297797414992}]}, {"text": "This technique, provided that it is implemented with some control mechanisms, is very efficient.", "labels": [], "entities": []}, {"text": "Some results are presented , from the French parsing evaluation campaign EASy.", "labels": [], "entities": [{"text": "French parsing evaluation campaign EASy", "start_pos": 38, "end_pos": 77, "type": "DATASET", "confidence": 0.6259495973587036}]}], "introductionContent": [{"text": "Parsing spoken languages and non canonical inputs remains a challenge for NLP systems.", "labels": [], "entities": [{"text": "Parsing spoken languages", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.9081291953722636}]}, {"text": "Many different solutions have been experimented, depending on the kind of material to be parsed or the kind of application: in some cases, superficial information such as bracketing is enough whereas in other situations, the system needs more details.", "labels": [], "entities": [{"text": "bracketing", "start_pos": 171, "end_pos": 181, "type": "TASK", "confidence": 0.9540822505950928}]}, {"text": "The question of robustness, and more generally the parsing strategy, is addressed differently according to these parameters.", "labels": [], "entities": [{"text": "parsing", "start_pos": 51, "end_pos": 58, "type": "TASK", "confidence": 0.9802019000053406}]}, {"text": "Classically, three families of solutions are proposed: -Reducing the complexity of the output -Controlling the parsing strategy -Training and adapting the system to the type of input In the first case, the idea consists in building structures with little information, even underspecified (which means the possibility of building partial structures).", "labels": [], "entities": [{"text": "parsing", "start_pos": 111, "end_pos": 118, "type": "TASK", "confidence": 0.9534080028533936}]}, {"text": "We find in this family the different shallow parsing techniques (see for example,).", "labels": [], "entities": [{"text": "shallow parsing", "start_pos": 37, "end_pos": 52, "type": "TASK", "confidence": 0.6137565076351166}]}, {"text": "Unsurprisingly, the use of statistical methods is very frequent and efficient in this kind of application (see for some results of a comparison between different shallow parsers).", "labels": [], "entities": []}, {"text": "Generally, such parsers (being them symbolic or not) are deterministic and build non recursive units.", "labels": [], "entities": []}, {"text": "In some cases, they can also determine relations between units.", "labels": [], "entities": []}, {"text": "The second family contains many different techniques.", "labels": [], "entities": []}, {"text": "The goal is to control a given parsing strategy by means of different mechanisms.", "labels": [], "entities": []}, {"text": "Among them, we can underline three proposals: -Implementing recovering mechanisms, triggering specific treatments in case of error (cf.) -Controlling the parsing process by means of probabilistic information (cf. [Johnson98]) -Controlling deep parsers by means of shallow parsing techniques (cf. The last kind of control mechanism consists in adapting the system to the material to be parsed.", "labels": [], "entities": [{"text": "parsing process", "start_pos": 154, "end_pos": 169, "type": "TASK", "confidence": 0.8807830512523651}, {"text": "Johnson98", "start_pos": 214, "end_pos": 223, "type": "DATASET", "confidence": 0.9606795907020569}]}, {"text": "This can be done in different ways: -Adding specific information in order to reduce the search space of the parsing process.", "labels": [], "entities": [{"text": "parsing process", "start_pos": 108, "end_pos": 123, "type": "TASK", "confidence": 0.9112269878387451}]}, {"text": "This kind of information can appear under the form of ad hoc rules or information depending on the kind of data to be treated.", "labels": [], "entities": []}, {"text": "-Adapting the resources (lexicon, grammars) to the linguistic material These different strategies offer several advantages and some of them can be used together.", "labels": [], "entities": []}, {"text": "Their interest is that the related questions of robustness and efficiency are both taken into account.", "labels": [], "entities": []}, {"text": "However, they do not constitute a generic solution in the sense that something has to be modified either in the goal, in the formalism or in the process.", "labels": [], "entities": []}, {"text": "In other words, they constitute an additional mechanism to be plugged into a given framework.", "labels": [], "entities": []}, {"text": "We propose in this paper a parsing technique relying on a constraint-based framework being both efficient and robust without need to modify the underlying formalism or the process.", "labels": [], "entities": [{"text": "parsing", "start_pos": 27, "end_pos": 34, "type": "TASK", "confidence": 0.9689832329750061}]}, {"text": "The notion of constraints is used in many different ways in NLP systems.", "labels": [], "entities": []}, {"text": "They can be a very basic filtering process as proposed by Constraint Grammars (see) or can be part to an actual theory as with HPSG (see), the Optimality Theory (see) or Constraint Dependency Grammars (cf.).", "labels": [], "entities": []}, {"text": "Our approach is very different: all information is represented by means of constraints; they do not stipulate requirements on the syntactic structure (as in the above cited approaches) but represent directly syntactic knowledge.", "labels": [], "entities": []}, {"text": "In this approach, robustness is intrinsic to the formalism in the sense that what is built is not a structure of the input (for example under the form of a tree) but a description of its properties.", "labels": [], "entities": []}, {"text": "The parsing mechanism can then be seen as a satisfaction process instead of a derivational one.", "labels": [], "entities": [{"text": "parsing", "start_pos": 4, "end_pos": 11, "type": "TASK", "confidence": 0.9609288573265076}]}, {"text": "Moreover, it becomes possible, whatever the form of the input, to give its characterization.", "labels": [], "entities": []}, {"text": "The technique relies on constraint relaxation and is controlled by means of a simple left-corner strategy.", "labels": [], "entities": []}, {"text": "One of its interests is that, on top of its efficiency, the same resources and the same parsing technique is used whatever the input.", "labels": [], "entities": []}, {"text": "After a presentation of the formalism and the parsing scheme, we describe an evaluation of the system for the treatment of spoken language.", "labels": [], "entities": [{"text": "treatment of spoken language", "start_pos": 110, "end_pos": 138, "type": "TASK", "confidence": 0.814968466758728}]}, {"text": "This evaluation has been done for French during the evaluation campaign Easy.", "labels": [], "entities": [{"text": "Easy.", "start_pos": 72, "end_pos": 77, "type": "DATASET", "confidence": 0.9441741108894348}]}], "datasetContent": [{"text": "We experimented this approach during the French evaluation campaign EASy (cf.).", "labels": [], "entities": [{"text": "French evaluation campaign EASy (cf.", "start_pos": 41, "end_pos": 77, "type": "DATASET", "confidence": 0.8891329069932302}]}, {"text": "The test consisted in parsing several files containing various kinds of material: literature, newspaper, technical texts, questions, e-mails and spoken language.", "labels": [], "entities": [{"text": "parsing several files containing various kinds of material: literature, newspaper, technical texts, questions, e-mails and spoken language", "start_pos": 22, "end_pos": 160, "type": "Description", "confidence": 0.8066104081544009}]}, {"text": "The total size of this corpus is one million words.", "labels": [], "entities": []}, {"text": "Part of this corpus was annotated with morpho-syntactic (POS tags) and syntactic annotations.", "labels": [], "entities": []}, {"text": "The last one provides bracketing as well as syntactic relations between units.", "labels": [], "entities": []}, {"text": "The annotated part of the corpus represents 60,000 words and constitutes the gold standard.", "labels": [], "entities": [{"text": "gold standard", "start_pos": 77, "end_pos": 90, "type": "DATASET", "confidence": 0.897045910358429}]}, {"text": "The campaign consisted for the participants to parse the entire corpus (without knowing what part of the corpus constituted the reference).", "labels": [], "entities": []}, {"text": "The results of the campaign are not yet available concerning the evaluation of the relations.", "labels": [], "entities": []}, {"text": "The figures presented in this section concern constituent bracketing.", "labels": [], "entities": [{"text": "constituent bracketing", "start_pos": 46, "end_pos": 68, "type": "TASK", "confidence": 0.6679019182920456}]}, {"text": "The task consisted in identifying minimal non recursive constituents described by annotation guidelines given to the participants.", "labels": [], "entities": []}, {"text": "The different categories to be built are: GA (adjective group: adjective or passed participle), GN (nominal group: determiner, noun adjective and its modifiers), GP (prepositional group), GR (adverb), NV (verbal nucleus: verb, clitics) and PV (verbal propositional group).", "labels": [], "entities": []}, {"text": "Our system parses the entire corpus (1 million words) in 4 minutes on a PC.", "labels": [], "entities": []}, {"text": "It presents then a very good efficiency.", "labels": [], "entities": []}, {"text": "We have grouped the different corpora into three different categories: written texts (including newspapers, technical texts and literature), spoken language (orthographic transcription of spontaneous speech) and e-mails.", "labels": [], "entities": []}, {"text": "The results are the following: These figures show then very stable results in precision and recall, with only little loss of efficiency for non-canonical material.", "labels": [], "entities": [{"text": "precision", "start_pos": 78, "end_pos": 87, "type": "METRIC", "confidence": 0.9996343851089478}, {"text": "recall", "start_pos": 92, "end_pos": 98, "type": "METRIC", "confidence": 0.9992414712905884}]}, {"text": "When studying more closely the results, some elements of explanation can be given.", "labels": [], "entities": []}, {"text": "The e-mail corpus is to be analyzed separately: many POS tagging errors, due to the specificity of this kind of input explain the difference.", "labels": [], "entities": []}, {"text": "Our POS-tagger was not tuned for this kind of lexical material.", "labels": [], "entities": []}, {"text": "The interpretation of the difference between written and oral corpora can have some linguistic basis.", "labels": [], "entities": []}, {"text": "The following figures give quantitative indications on the categories built by the parser.", "labels": [], "entities": []}, {"text": "The first remark is that the repartition between the different categories is the same.", "labels": [], "entities": []}, {"text": "The only main difference concerns the higher number of nucleus VP in the case of written texts.", "labels": [], "entities": []}, {"text": "This seems to support the classical idea that spoken language seems to use more nominal constructions than the written one.", "labels": [], "entities": []}, {"text": "The problem is that our parser encounters some difficulties in the identification of the NP borders.", "labels": [], "entities": []}, {"text": "It very often also includes some material belonging in the grammar given during the campaign to AP or VP.", "labels": [], "entities": []}, {"text": "The higher proportion of NPs in spoken corpora is an element of explanation for the difference in the results.", "labels": [], "entities": []}], "tableCaptions": []}