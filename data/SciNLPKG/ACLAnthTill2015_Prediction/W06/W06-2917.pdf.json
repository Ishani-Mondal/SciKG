{"title": [{"text": "Learning Auxiliary Fronting with Grammatical Inference", "labels": [], "entities": [{"text": "Learning Auxiliary Fronting", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6281990706920624}]}], "abstractContent": [{"text": "We present a simple context-free grammatical inference algorithm, and prove that it is capable of learning an interesting subclass of context-free languages.", "labels": [], "entities": []}, {"text": "We also demonstrate that an implementation of this algorithm is capable of learning auxiliary fronting in polar interrogatives (AFIPI) in English.", "labels": [], "entities": [{"text": "learning auxiliary fronting in polar interrogatives", "start_pos": 75, "end_pos": 126, "type": "TASK", "confidence": 0.7606087078650793}, {"text": "AFIPI", "start_pos": 128, "end_pos": 133, "type": "METRIC", "confidence": 0.6021426916122437}]}, {"text": "This has been one of the most important test cases in language acquisition over the last few decades.", "labels": [], "entities": [{"text": "language acquisition", "start_pos": 54, "end_pos": 74, "type": "TASK", "confidence": 0.7685256004333496}]}, {"text": "We demonstrate that learning can proceed even in the complete absence of examples of particular constructions, and thus that debates about the frequency of occurrence of such constructions are irrelevant.", "labels": [], "entities": []}, {"text": "We discuss the implications of this on the type of innate learning biases that must be hypothesized to explain first language acquisition.", "labels": [], "entities": [{"text": "first language acquisition", "start_pos": 111, "end_pos": 137, "type": "TASK", "confidence": 0.7285282810529073}]}], "introductionContent": [{"text": "For some years, a particular set of examples has been used to provide support for nativist theories of first language acquisition (FLA).", "labels": [], "entities": [{"text": "first language acquisition (FLA)", "start_pos": 103, "end_pos": 135, "type": "TASK", "confidence": 0.7881893416245779}]}, {"text": "These examples, which hinge around auxiliary inversion in the formation of questions in English, have been considered to provide a strong argument in favour of the nativist claim: that FLA proceeds primarily through innately specified domain specific mechanisms or knowledge, rather than through the operation of general-purpose cognitive mechanisms.", "labels": [], "entities": [{"text": "FLA", "start_pos": 185, "end_pos": 188, "type": "TASK", "confidence": 0.9716054201126099}]}, {"text": "A key point of empirical debate is the frequency of occurrence of the forms in question.", "labels": [], "entities": []}, {"text": "If these are vanishingly rare, or non-existent in the primary linguistic data, and yet children acquire the construction in question, then the hypothesis that they have innate knowledge would be supported.", "labels": [], "entities": []}, {"text": "But this rests on the assumption that examples of that specific construction are necessary for learning to proceed.", "labels": [], "entities": []}, {"text": "In this paper we show that this assumption is false: that this particular construction can be learned without the learner being exposed to any examples of that particular type.", "labels": [], "entities": []}, {"text": "Our demonstration is primarily mathematical/computational: we present a simple experiment that demonstrates the applicability of this approach to this particular problem neatly, but the data we use is not intended to be a realistic representation of the primary linguistic data, nor is the particular algorithm we use suitable for large scale grammar induction.", "labels": [], "entities": [{"text": "large scale grammar induction", "start_pos": 331, "end_pos": 360, "type": "TASK", "confidence": 0.6849151626229286}]}, {"text": "We present a general purpose context-free grammatical algorithm that is provably correct under a certain learning criterion.", "labels": [], "entities": []}, {"text": "This algorithm incorporates no domain specific knowledge: it has no specific information about language; no knowledge of X-bar schemas, no hidden sources of information to reveal the structure.", "labels": [], "entities": []}, {"text": "It operates purely on unannotated strings of raw text.", "labels": [], "entities": []}, {"text": "Obviously, as all learning algorithms do, it has an implicit learning bias.", "labels": [], "entities": []}, {"text": "This very simple algorithm has a particularly clear bias, with a simple mathematical description, that allows a remarkably simple characterisation of the set of languages that it can learn.", "labels": [], "entities": []}, {"text": "This algorithm does not use a statistical learning paradigm that has to be tested on large quantities of data.", "labels": [], "entities": []}, {"text": "Rather it uses a symbolic learning paradigm, that works efficiently with very small quantities of data, while being very sensitive to noise.", "labels": [], "entities": []}, {"text": "We discuss this choice in some depth below.", "labels": [], "entities": []}, {"text": "For reasons that were first pointed out by Chomsky), algorithms of this type are not capable of learning all of natural language.", "labels": [], "entities": []}, {"text": "It turns out, however, that algorithms based on this approach are sufficiently strong to learn some key properties of language, such as the correct rule for forming polar questions.", "labels": [], "entities": []}, {"text": "In the next section we shall describe the dispute briefly; in the subsequent sections we will describe the algorithm we use, and the experiments we have performed.", "labels": [], "entities": []}], "datasetContent": [{"text": "We decided to see whether this algorithm without modification could shed some light on the debate discussed above.", "labels": [], "entities": []}, {"text": "The experiments we present here are not intended to bean exhaustive test of the learnability of natural language.", "labels": [], "entities": []}, {"text": "The focus is on determining whether learning can proceed in the absence of positive samples, and given only a very weak general purpose bias.", "labels": [], "entities": []}], "tableCaptions": []}