{"title": [{"text": "Labeled Pseudo-Projective Dependency Parsing with Support Vector Machines", "labels": [], "entities": []}], "abstractContent": [{"text": "We use SVM classifiers to predict the next action of a deterministic parser that builds labeled projective dependency graphs in an incremental fashion.", "labels": [], "entities": []}, {"text": "Non-projective dependencies are captured indirectly by projectivizing the training data for the classifiers and applying an inverse transformation to the output of the parser.", "labels": [], "entities": []}, {"text": "We present evaluation results and an error analysis focusing on Swedish and Turkish.", "labels": [], "entities": []}], "introductionContent": [{"text": "The CoNLL-X shared task consists in parsing texts in multiple languages using a single dependency parser that has the capacity to learn from treebank data.", "labels": [], "entities": [{"text": "parsing texts", "start_pos": 36, "end_pos": 49, "type": "TASK", "confidence": 0.8956176042556763}]}, {"text": "Our methodology for performing this task is based on four essential components: \u2022 A deterministic algorithm for building labeled projective dependency graphs).", "labels": [], "entities": []}, {"text": "\u2022 History-based feature models for predicting the next parser action).", "labels": [], "entities": [{"text": "predicting the next parser action", "start_pos": 35, "end_pos": 68, "type": "TASK", "confidence": 0.7926519870758056}]}, {"text": "\u2022 Support vector machines for mapping histories to parser actions ().", "labels": [], "entities": []}, {"text": "\u2022 Graph transformations for recovering nonprojective structures ).", "labels": [], "entities": []}, {"text": "All experiments have been performed using MaltParser ( ), version 0.4, which is made available together with the suite of programs used for pre-and post-processing.", "labels": [], "entities": []}, {"text": "1 www.msi.vxu.se/users/nivre/research/MaltParser.html", "labels": [], "entities": [{"text": "MaltParser.html", "start_pos": 38, "end_pos": 53, "type": "DATASET", "confidence": 0.8386729955673218}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Evaluation on final test set; LAS = labeled attachment score, UAS = unlabeled attachment score,  LAcc = label accuracy score; total score excluding Bulgarian", "labels": [], "entities": [{"text": "LAS = labeled attachment score", "start_pos": 40, "end_pos": 70, "type": "METRIC", "confidence": 0.761963963508606}, {"text": "UAS = unlabeled attachment score", "start_pos": 72, "end_pos": 104, "type": "METRIC", "confidence": 0.8925559639930725}, {"text": "LAcc = label accuracy score", "start_pos": 107, "end_pos": 134, "type": "METRIC", "confidence": 0.8548870086669922}]}]}