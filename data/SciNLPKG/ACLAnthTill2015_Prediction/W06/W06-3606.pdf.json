{"title": [{"text": "Practical Markov Logic Containing First-Order Quantifiers with Application to Identity Uncertainty", "labels": [], "entities": [{"text": "Practical Markov Logic Containing First-Order Quantifiers", "start_pos": 0, "end_pos": 57, "type": "TASK", "confidence": 0.7756439646085104}]}], "abstractContent": [{"text": "Markov logic is a highly expressive language recently introduced to specify the connec-tivity of a Markov network using first-order logic.", "labels": [], "entities": [{"text": "Markov logic", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.6560228019952774}]}, {"text": "While Markov logic is capable of constructing arbitrary first-order formulae over the data, the complexity of these for-mulae is often limited in practice because of the size and connectivity of the resulting network.", "labels": [], "entities": []}, {"text": "In this paper, we present approximate inference and estimation methods that incrementally instantiate portions of the network as needed to enable first-order existential and universal quantifiers in Markov logic networks.", "labels": [], "entities": []}, {"text": "When applied to the problem of identity uncertainty, this approach results in a conditional probabilis-tic model that can reason about objects, combining the expressivity of recently introduced BLOG models with the predic-tive power of conditional training.", "labels": [], "entities": []}, {"text": "We validate our algorithms on the tasks of citation matching and author disambiguation.", "labels": [], "entities": [{"text": "citation matching", "start_pos": 43, "end_pos": 60, "type": "TASK", "confidence": 0.9542485773563385}, {"text": "author disambiguation", "start_pos": 65, "end_pos": 86, "type": "TASK", "confidence": 0.7890417277812958}]}], "introductionContent": [{"text": "Markov logic networks (MLNs) combine the probabilistic semantics of graphical models with the expressivity of first-order logic to model relational dependencies ().", "labels": [], "entities": []}, {"text": "They provide a method to instantiate Markov networks from a set of constants and first-order formulae.", "labels": [], "entities": []}, {"text": "While MLNs have the power to specify Markov networks with complex, finely-tuned dependencies, the difficulty of instantiating these networks grows with the complexity of the formulae.", "labels": [], "entities": []}, {"text": "In particular, expressions with first-order quantifiers can lead to networks that are large and densely connected, making exact probabilistic inference intractable.", "labels": [], "entities": []}, {"text": "Because of this, existing applications of MLNs have not exploited the full richness of expressions available in first-order logic.", "labels": [], "entities": []}, {"text": "For example, consider the database of researchers described in, where predicates include Professor(person), Student(person), AdvisedBy(person, person), and Published(author, paper).", "labels": [], "entities": []}, {"text": "Firstorder formulae include statements such as \"students are not professors\" and \"each student has at most one advisor.\"", "labels": [], "entities": []}, {"text": "Consider instead statements such as \"all the students of an advisor publish papers with similar words in the title\" or \"this subset of students belong to the same lab.\"", "labels": [], "entities": []}, {"text": "To instantiate an MLN with such predicates requires existential and universal quantifiers, resulting in either a densely connected network, or a network with prohibitively many nodes.", "labels": [], "entities": []}, {"text": "(In the latter example, it maybe necessary to ground the predicate for each element of the power set of students.)", "labels": [], "entities": []}, {"text": "However, as discussed in Section 2, there maybe cases where these aggregate predicates increase predictive power.", "labels": [], "entities": []}, {"text": "For example, in predicting the value of HaveSameAdvisor(a i . .", "labels": [], "entities": [{"text": "HaveSameAdvisor", "start_pos": 40, "end_pos": 55, "type": "DATASET", "confidence": 0.8094288110733032}]}, {"text": "a i+k ), it maybe useful to know the values of aggregate evidence predicates such as CoauthoredAtLeastTwoPapers(a i . .", "labels": [], "entities": []}, {"text": "a i+k ), which indicates whether there are at least two papers that some combination of authors from a i . .", "labels": [], "entities": []}, {"text": "a i+k have co-authored.", "labels": [], "entities": []}, {"text": "Additionally, we can construct predicates such as NumberOfStudents(a i ) to model the number of students a researcher is likely to advise simultaneously.", "labels": [], "entities": []}, {"text": "These aggregate predicates are examples of universal and existentially quantified predicates over observed and unobserved values.", "labels": [], "entities": []}, {"text": "To enable these sorts of predicates while limiting the complexity of the ground Markov network, we present an algorithm that incrementally expands the set of aggregate predicates during the inference procedure.", "labels": [], "entities": []}, {"text": "In this paper, we describe a general algorithm for incremental expansion of predicates in MLNs, then present an implementation of the algorithm applied to the problem of identity uncertainty.", "labels": [], "entities": []}], "datasetContent": [{"text": "We perform experiments on two object identification tasks: citation matching and author disambiguation.", "labels": [], "entities": [{"text": "object identification", "start_pos": 30, "end_pos": 51, "type": "TASK", "confidence": 0.7659752666950226}, {"text": "citation matching", "start_pos": 59, "end_pos": 76, "type": "TASK", "confidence": 0.9479175806045532}, {"text": "author disambiguation", "start_pos": 81, "end_pos": 102, "type": "TASK", "confidence": 0.8052965104579926}]}, {"text": "Citation matching is the task of determining whether two research paper citation strings refer to the same paper.", "labels": [], "entities": [{"text": "Citation matching", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7945132851600647}]}, {"text": "We use the Citeseer corpus (, containing approximately 1500 citations, 900 of which are unique.", "labels": [], "entities": [{"text": "Citeseer corpus", "start_pos": 11, "end_pos": 26, "type": "DATASET", "confidence": 0.9239935278892517}]}, {"text": "The citations are manually labeled with cluster identifiers, and the strings are segmented into fields such as author, title, etc.", "labels": [], "entities": []}, {"text": "The citation data is split into four disjoint categories by topic, and the results presented are obtained by training on three categories and testing on the fourth.", "labels": [], "entities": []}, {"text": "Using first-order logic, we create a number of aggregate predicates such as AllTitlesMatch, AllAuthorsMatch, AllJournalsMatch, etc., as well as their existential counterparts, ThereExistsTitleMatch, etc.", "labels": [], "entities": []}, {"text": "We also include count predicates, which indicate the number of these matches in a set of constants.", "labels": [], "entities": []}, {"text": "Additionally, we add edit distance predicates, which calculate approximate matches 1 between title fields, etc., for each pair of citations in a set of citations.", "labels": [], "entities": []}, {"text": "Aggregate features are used for these, such as \"there exists a pair of citations in this cluster which have titles that are less than 30% similar\" and \"the minimum edit distance between titles in a cluster is greater than 50%.\"", "labels": [], "entities": []}, {"text": "We evaluate using pairwise precision, recall, and F1, which measure the system's ability to predict whether each pair of constants refer to the same objector not.", "labels": [], "entities": [{"text": "precision", "start_pos": 27, "end_pos": 36, "type": "METRIC", "confidence": 0.961469292640686}, {"text": "recall", "start_pos": 38, "end_pos": 44, "type": "METRIC", "confidence": 0.9996457099914551}, {"text": "F1", "start_pos": 50, "end_pos": 52, "type": "METRIC", "confidence": 0.9998084902763367}]}, {"text": "shows the advantage of our  proposed model (Objects) over a model that only considers pairwise predicates of the same features (Pairs).", "labels": [], "entities": []}, {"text": "Note that Pairs is a strong baseline that performs collective inference of citation matching decisions, but is restricted to use only IsEqual(c i , c j ) predicates over pairs of citations.", "labels": [], "entities": [{"text": "collective inference of citation matching", "start_pos": 51, "end_pos": 92, "type": "TASK", "confidence": 0.6135687410831452}]}, {"text": "Thus, the performance difference is due to the ability to model firstorder features of the data.", "labels": [], "entities": []}, {"text": "Author disambiguation is the task of deciding whether two strings refer to the same author.", "labels": [], "entities": [{"text": "Author disambiguation", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.7818172574043274}]}, {"text": "To increase the task complexity, we collect citations from the Web containing different authors with matching last names and first initials.", "labels": [], "entities": []}, {"text": "Thus, simply performing a string match on the author's name would be insufficient in many cases.", "labels": [], "entities": []}, {"text": "We searched for three common last name / first initial combinations.", "labels": [], "entities": []}, {"text": "From this set, we collected 400 citations referring to 56 unique authors.", "labels": [], "entities": []}, {"text": "For these experiments, we train on two subsets and test on the third.", "labels": [], "entities": []}, {"text": "We generate aggregate predicates similar to those used for citation matching.", "labels": [], "entities": [{"text": "citation matching", "start_pos": 59, "end_pos": 76, "type": "TASK", "confidence": 0.9096833169460297}]}, {"text": "Additionally, we include features indicating the overlap of tokens from the titles and indicating whether there exists a pair of authors in this cluster that have different middle names.", "labels": [], "entities": []}, {"text": "This last feature exemplifies the sort of reasoning enabled by aggregate predicates: For example, consider a pairwise predicate that indicates whether two authors have the same middle name.", "labels": [], "entities": []}, {"text": "Very often, middle name information is unavailable, so the name \"Miller, A.\" may have high similarity to both \".", "labels": [], "entities": []}, {"text": "However, it is unlikely that the same person has two different middle names, and our model learns a weight for this feature.", "labels": [], "entities": []}, {"text": "demonstrates the advantage of this method.", "labels": [], "entities": []}, {"text": "Overall, Objects achieves F 1 scores superior to Pairs on 5 of the 7 datasets.", "labels": [], "entities": [{"text": "F 1", "start_pos": 26, "end_pos": 29, "type": "METRIC", "confidence": 0.993843138217926}]}, {"text": "These results indicate the potential advantages of using complex first-order quantifiers in MLNs.", "labels": [], "entities": []}, {"text": "The cases in which Pairs outperforms Objects are likely due to the fact that the approximate inference used in Objects is greedy.", "labels": [], "entities": []}, {"text": "Increasing the robustness of inference is a topic of future research.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Precision, recall, and F1 performance for  citation matching task, where Objects is an MLN  using aggregate predicates, and Pairs is an MLN us- ing only pairwise predicates. Objects outperforms  Pairs on three of the four testing sets.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9872272610664368}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9988722205162048}, {"text": "F1", "start_pos": 33, "end_pos": 35, "type": "METRIC", "confidence": 0.9997158646583557}, {"text": "citation matching task", "start_pos": 53, "end_pos": 75, "type": "TASK", "confidence": 0.9386908809343973}]}, {"text": " Table 2: Performance on the author disambiguation  task. Objects outperforms Pairs on two of the  three testing sets.", "labels": [], "entities": [{"text": "author disambiguation  task", "start_pos": 29, "end_pos": 56, "type": "TASK", "confidence": 0.80412890513738}]}]}