{"title": [{"text": "Identification of Event Mentions and their Semantic Class", "labels": [], "entities": [{"text": "Identification of Event Mentions", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.900526762008667}]}], "abstractContent": [{"text": "Complex tasks like question answering need to be able to identify events in text and the relations among those events.", "labels": [], "entities": [{"text": "question answering", "start_pos": 19, "end_pos": 37, "type": "TASK", "confidence": 0.8674565553665161}]}, {"text": "We show that this event identification task and a related task, identifying the semantic class of these events, can both be formulated as classification problems in a word-chunking paradigm.", "labels": [], "entities": [{"text": "event identification task", "start_pos": 18, "end_pos": 43, "type": "TASK", "confidence": 0.7865484356880188}]}, {"text": "We introduce a variety of linguistically motivated features for this task and then train a system that is able to identify events with a precision of 82% and a recall of 71%.", "labels": [], "entities": [{"text": "precision", "start_pos": 137, "end_pos": 146, "type": "METRIC", "confidence": 0.9989734888076782}, {"text": "recall", "start_pos": 160, "end_pos": 166, "type": "METRIC", "confidence": 0.9994841814041138}]}, {"text": "We then show a variety of analyses of this model, and their implications for the event identification task.", "labels": [], "entities": [{"text": "event identification task", "start_pos": 81, "end_pos": 106, "type": "TASK", "confidence": 0.840630312760671}]}], "introductionContent": [{"text": "Research in question answering, machine translation and other fields has shown that being able to recognize the important entities in a text is often a critical component of these systems.", "labels": [], "entities": [{"text": "question answering", "start_pos": 12, "end_pos": 30, "type": "TASK", "confidence": 0.8833814859390259}, {"text": "machine translation", "start_pos": 32, "end_pos": 51, "type": "TASK", "confidence": 0.7971860468387604}]}, {"text": "Such entity information gives the machine access to a deeper level of semantics than words alone can provide, and thus offers advantages for these complex tasks.", "labels": [], "entities": []}, {"text": "Of course, texts are composed of much more than just sets of entities, and architectures that rely solely on word and entity-based techniques are likely to have difficulty with tasks that depend more heavily on event and temporal relations.", "labels": [], "entities": []}, {"text": "Consider a question answering system that receives the following questions: \u2022 Is Anwar al-Sadat still the president of Egypt?", "labels": [], "entities": [{"text": "question answering", "start_pos": 11, "end_pos": 29, "type": "TASK", "confidence": 0.7887545228004456}]}, {"text": "\u2022 How did the linking of the Argentinean peso to the US dollar in 1991 contribute to economic crisis of Argentina in 2003?", "labels": [], "entities": []}, {"text": "Processing such questions requires not only knowing what the important people, places and other entities are, but also what kind of events they are involved in, the roles they play in those events, and the relations among those events.", "labels": [], "entities": []}, {"text": "Thus, we suggest that identifying such events in a text should play an important role in systems that attempt to address questions like these.", "labels": [], "entities": []}, {"text": "Of course, to identify events in texts, we must define what exactly it is we mean by \"event\".", "labels": [], "entities": []}, {"text": "In this work, we adopt a traditional linguistic definition of an event that divides words into two aspectual types: states and events.", "labels": [], "entities": []}, {"text": "States describe situations that are static or unchanging for their duration, while events describe situations that involve some internal structure.", "labels": [], "entities": []}, {"text": "For example, predicates like know and love would be states because if we know (or love) someone fora period of time, we know (or love) that person at each point during the period.", "labels": [], "entities": []}, {"text": "Predicates like run or deliver a sermon would be events because they are built of smaller dissimilar components: run includes raising and lowering of legs and deliver a sermon includes the various tongue movements required to produce words.", "labels": [], "entities": []}, {"text": "To better explain how we approach the task of identifying such events, we first discuss some past work on related tasks.", "labels": [], "entities": []}, {"text": "Then we briefly discuss the characteristics of the TimeBank, a corpus containing event-annotated data.", "labels": [], "entities": []}, {"text": "Next we present our formulation of event identification as a classification task and introduce the linguistic features that serve as input to the algorithm.", "labels": [], "entities": [{"text": "event identification", "start_pos": 35, "end_pos": 55, "type": "TASK", "confidence": 0.7563583850860596}]}, {"text": "Finally, we show the results of STEP (our \"System for Textual Event Parsing\") which applies these techniques to the TimeBank data.", "labels": [], "entities": [{"text": "STEP", "start_pos": 32, "end_pos": 36, "type": "METRIC", "confidence": 0.654354989528656}, {"text": "Textual Event Parsing", "start_pos": 54, "end_pos": 75, "type": "TASK", "confidence": 0.65043838818868}, {"text": "TimeBank data", "start_pos": 116, "end_pos": 129, "type": "DATASET", "confidence": 0.9393411576747894}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Overall results for both tasks", "labels": [], "entities": []}, {"text": " Table 4: Results by word class for both tasks", "labels": [], "entities": []}, {"text": " Table 5: Results by label", "labels": [], "entities": []}, {"text": " Table 6: Ablations for both tasks. For each task, the least important feature sets appear at the top of the  table, and most important feature sets appear at the bottom. For each row, the precision, recall and F- measure indicate the scores of a model trained with only the feature sets named in that row and the  rows below it.", "labels": [], "entities": [{"text": "Ablations", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.990326464176178}, {"text": "precision", "start_pos": 189, "end_pos": 198, "type": "METRIC", "confidence": 0.9994708895683289}, {"text": "recall", "start_pos": 200, "end_pos": 206, "type": "METRIC", "confidence": 0.9958816766738892}, {"text": "F- measure", "start_pos": 211, "end_pos": 221, "type": "METRIC", "confidence": 0.9950096805890402}]}]}