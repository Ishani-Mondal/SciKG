{"title": [{"text": "On Using Ensemble Methods for Chinese Named Entity Recognition", "labels": [], "entities": [{"text": "Chinese Named Entity Recognition", "start_pos": 30, "end_pos": 62, "type": "TASK", "confidence": 0.708677627146244}]}], "abstractContent": [{"text": "In sequence labeling tasks, applying different machine learning models and feature sets usually leads to different results.", "labels": [], "entities": [{"text": "sequence labeling tasks", "start_pos": 3, "end_pos": 26, "type": "TASK", "confidence": 0.7253252665201823}]}, {"text": "In this paper, we exploit two ensemble methods in order to integrate multiple results generated under different conditions.", "labels": [], "entities": []}, {"text": "One method is based on majority vote, while the other is a memory-based approach that integrates maximum en-tropy and conditional random field clas-sifiers.", "labels": [], "entities": []}, {"text": "Our results indicate that the memory-based method can outperform the individual classifiers, but the majority vote method cannot.", "labels": [], "entities": []}], "introductionContent": [{"text": "Sequence labeling and segmentation tasks have been studied extensively in the fields of computational linguistics and information extraction.", "labels": [], "entities": [{"text": "Sequence labeling", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9275719523429871}, {"text": "segmentation tasks", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.7759234607219696}, {"text": "information extraction", "start_pos": 118, "end_pos": 140, "type": "TASK", "confidence": 0.9048179984092712}]}, {"text": "Several tasks, including, word segmentation, and semantic role labeling, provide rich information for various applications, such as segmentation in Chinese information retrieval and named entity recognition in biomedical literature mining.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 26, "end_pos": 43, "type": "TASK", "confidence": 0.762380063533783}, {"text": "semantic role labeling", "start_pos": 49, "end_pos": 71, "type": "TASK", "confidence": 0.6319410999615988}, {"text": "Chinese information retrieval", "start_pos": 148, "end_pos": 177, "type": "TASK", "confidence": 0.5781408349672953}, {"text": "named entity recognition", "start_pos": 182, "end_pos": 206, "type": "TASK", "confidence": 0.6770784457524618}, {"text": "biomedical literature mining", "start_pos": 210, "end_pos": 238, "type": "TASK", "confidence": 0.593772828578949}]}, {"text": "Probabilistic state automata models, such as the Hidden Markov model (HMM) and conditional random fields (CRF) are some of best, and therefore most popular, approaches for sequence labeling tasks.", "labels": [], "entities": [{"text": "sequence labeling tasks", "start_pos": 172, "end_pos": 195, "type": "TASK", "confidence": 0.7496211131413778}]}, {"text": "Both HMM and CRF consider that the state transition and the state prediction are conditional on the observation of data.", "labels": [], "entities": []}, {"text": "The advantage of the CRF model is that richer feature sets can be considered, because, unlike HMM, it does not make a dependence assumption.", "labels": [], "entities": []}, {"text": "However, the obvious drawback of the CRF model is that it needs more computing resources, so we cannot apply all the features of the model.", "labels": [], "entities": []}, {"text": "One possible way to resolve this problem is to effectively combine the results of various individual classifiers trained with different feature sets.", "labels": [], "entities": []}, {"text": "In this paper, we use two ensemble methods to combine the results of the classifiers.", "labels": [], "entities": []}, {"text": "We also combine the results generated by two machine learning models: maximum entropy (ME) and CRF.", "labels": [], "entities": [{"text": "maximum entropy (ME)", "start_pos": 70, "end_pos": 90, "type": "METRIC", "confidence": 0.7821879744529724}, {"text": "CRF", "start_pos": 95, "end_pos": 98, "type": "METRIC", "confidence": 0.710519552230835}]}, {"text": "One ensemble method is based on the majority vote, and the other is the memory based learner.", "labels": [], "entities": []}, {"text": "Although the ensemble methods have been applied in some sequence labeling tasks,, similar work in Chinese named entity recognition is scarce.", "labels": [], "entities": [{"text": "sequence labeling tasks", "start_pos": 56, "end_pos": 79, "type": "TASK", "confidence": 0.7430714766184489}, {"text": "Chinese named entity recognition", "start_pos": 98, "end_pos": 130, "type": "TASK", "confidence": 0.5710243135690689}]}, {"text": "Our Chinese named entity tagger uses a character-based model.", "labels": [], "entities": [{"text": "Chinese named entity tagger", "start_pos": 4, "end_pos": 31, "type": "TASK", "confidence": 0.5094268172979355}]}, {"text": "For English named entity tasks, a character-based NER model proposed by Dan Klein proves the usefulness of substrings within words.", "labels": [], "entities": []}, {"text": "In Chinese NER, the characterbased model is more straightforward, since there are no spaces between Chinese words and each Chinese character is actually meaningful.", "labels": [], "entities": []}, {"text": "Another reason for using a character-based model is that it can avoid the errors sometimes made by a Chinese word segmentor.", "labels": [], "entities": [{"text": "Chinese word segmentor", "start_pos": 101, "end_pos": 123, "type": "TASK", "confidence": 0.688321610291799}]}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In the Section 2, we introduce the machine learning models, the features we apply in the machine learning models, and the ensemble methods.", "labels": [], "entities": []}, {"text": "In Section 3, we briefly describe the experimental data and the experiment results.", "labels": [], "entities": []}, {"text": "Then, in Section 4, we present our conclusions..", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2.  In addition, as ME can handle more features than  CRF, we apply extra features in the ME model", "labels": [], "entities": []}, {"text": " Table 1 Character features for CRF", "labels": [], "entities": [{"text": "CRF", "start_pos": 32, "end_pos": 35, "type": "TASK", "confidence": 0.8512380719184875}]}, {"text": " Table 2 Character features for ME", "labels": [], "entities": []}, {"text": " Table 3 Word features for CRF", "labels": [], "entities": [{"text": "CRF", "start_pos": 27, "end_pos": 30, "type": "TASK", "confidence": 0.895765483379364}]}]}