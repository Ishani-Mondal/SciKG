{"title": [{"text": "A Comparative Study on Compositional Translation Estimation using a Domain/Topic-Specific Corpus collected from the Web", "labels": [], "entities": [{"text": "Compositional Translation Estimation", "start_pos": 23, "end_pos": 59, "type": "TASK", "confidence": 0.9334735075632731}]}], "abstractContent": [{"text": "This paper studies issues related to the compilation of a bilingual lexicon for technical terms.", "labels": [], "entities": []}, {"text": "In the task of estimating bilingual term correspondences of technical terms, it is usually rather difficult to find an existing corpus for the domain of such technical terms.", "labels": [], "entities": [{"text": "estimating bilingual term correspondences of technical terms", "start_pos": 15, "end_pos": 75, "type": "TASK", "confidence": 0.8090539744922093}]}, {"text": "In this paper, we adopt an approach of collecting a corpus for the domain of such technical terms from the Web.", "labels": [], "entities": []}, {"text": "As a method of translation estimation for technical terms, we employ a compositional translation estimation technique.", "labels": [], "entities": [{"text": "translation estimation", "start_pos": 15, "end_pos": 37, "type": "TASK", "confidence": 0.9804332256317139}, {"text": "compositional translation estimation", "start_pos": 71, "end_pos": 107, "type": "TASK", "confidence": 0.6347915530204773}]}, {"text": "This paper focuses on quantitatively comparing variations of the components in the scoring functions of composi-tional translation estimation.", "labels": [], "entities": [{"text": "composi-tional translation estimation", "start_pos": 104, "end_pos": 141, "type": "TASK", "confidence": 0.6258579790592194}]}, {"text": "Through experimental evaluation, we show that the domain/topic-specific corpus contributes toward improving the performance of the compositional translation estimation.", "labels": [], "entities": [{"text": "compositional translation estimation", "start_pos": 131, "end_pos": 167, "type": "TASK", "confidence": 0.802626351515452}]}], "introductionContent": [{"text": "This paper studies issues related to the compilation of a bilingual lexicon for technical terms.", "labels": [], "entities": []}, {"text": "Thus far, several techniques of estimating bilingual term correspondences from a parallel/comparable corpus have been studied).", "labels": [], "entities": [{"text": "estimating bilingual term correspondences", "start_pos": 32, "end_pos": 73, "type": "TASK", "confidence": 0.750225692987442}]}, {"text": "For example, in the case of estimation from comparable corpora, ( proposed standard techniques of estimating bilingual term correspondences from comparable corpora.", "labels": [], "entities": [{"text": "estimation from comparable corpora", "start_pos": 28, "end_pos": 62, "type": "TASK", "confidence": 0.8545322120189667}, {"text": "estimating bilingual term correspondences", "start_pos": 98, "end_pos": 139, "type": "TASK", "confidence": 0.7664918303489685}]}, {"text": "In their techniques, contextual similarity between a source language term and its translation candidate is measured across the languages, and all the translation candidates are re-ranked according to their contextual similarities.", "labels": [], "entities": []}, {"text": "However, there are limited number of parallel/comparable corpora that are available for the purpose of estimating bilingual term correspondences.", "labels": [], "entities": []}, {"text": "Therefore, even if one wants to apply those existing techniques to the task of estimating bilingual term correspondences of technical terms, it is usually rather difficult to find an existing corpus for the domain of such technical terms.", "labels": [], "entities": [{"text": "estimating bilingual term correspondences of technical terms", "start_pos": 79, "end_pos": 139, "type": "TASK", "confidence": 0.7726533370358604}]}, {"text": "On the other hand, compositional translation estimation techniques that use a monolingual corpus) are more practical.", "labels": [], "entities": [{"text": "compositional translation estimation", "start_pos": 19, "end_pos": 55, "type": "TASK", "confidence": 0.8882271647453308}]}, {"text": "It is because collecting a monolingual corpus is less expensive than collecting a parallel/comparable corpus.", "labels": [], "entities": []}, {"text": "Translation candidates of a term can be compositionally generated by concatenating the translation of the constituents of the term.", "labels": [], "entities": []}, {"text": "Here, the generated translation candidates are validated using the domain/topic-specific corpus.", "labels": [], "entities": []}, {"text": "In order to assess the applicability of the compositional translation estimation technique, we randomly pickup 667 Japanese and English technical term translation pairs of 10 domains from existing technical term bilingual lexicons.", "labels": [], "entities": [{"text": "compositional translation estimation", "start_pos": 44, "end_pos": 80, "type": "TASK", "confidence": 0.7343634068965912}, {"text": "Japanese and English technical term translation", "start_pos": 115, "end_pos": 162, "type": "TASK", "confidence": 0.6052407920360565}]}, {"text": "We then manually examine their compositionality, and find out that 88% of them are actually compositional, which is a very encouraging result.", "labels": [], "entities": []}, {"text": "But still, it is expensive to collect a domain/topic-specific corpus.", "labels": [], "entities": []}, {"text": "Here, we adopt an approach of using the Web, since documents of various domains/topics are available on the Web.", "labels": [], "entities": []}, {"text": "When validating translation candidates using the Web, roughly speaking, there exist the following two approaches.", "labels": [], "entities": []}, {"text": "In the first approach, translation candidates are validated through the search engine).", "labels": [], "entities": [{"text": "translation candidates", "start_pos": 23, "end_pos": 45, "type": "TASK", "confidence": 0.884941965341568}]}, {"text": "In the second approach, a domain/topic-specific corpus is collected from the Web in advance and fixed: Compilation of a Domain/TopicSpecific Bilingual Lexicon using the Web before translation estimation, then generated translation candidates are validated against the domain/topic-specific corpus).", "labels": [], "entities": [{"text": "translation estimation", "start_pos": 180, "end_pos": 202, "type": "TASK", "confidence": 0.8567480146884918}]}, {"text": "The first approach is preferable in terms of coverage, while the second is preferable in terms of computational efficiency.", "labels": [], "entities": [{"text": "coverage", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.8844618201255798}]}, {"text": "This paper mainly focuses on quantitatively comparing the two approaches in terms of coverage and precision of compositional translation estimation.", "labels": [], "entities": [{"text": "coverage", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.9852060675621033}, {"text": "precision", "start_pos": 98, "end_pos": 107, "type": "METRIC", "confidence": 0.9989542961120605}, {"text": "compositional translation estimation", "start_pos": 111, "end_pos": 147, "type": "TASK", "confidence": 0.7664573788642883}]}, {"text": "More specifically, in compositional translation estimation, we decompose the scoring function of a translation candidate into two components: bilingual lexicon score and corpus score.", "labels": [], "entities": [{"text": "compositional translation estimation", "start_pos": 22, "end_pos": 58, "type": "TASK", "confidence": 0.7349929610888163}]}, {"text": "In this paper, we examine variants for those components and define 9 types of scoring functions in total.", "labels": [], "entities": []}, {"text": "Regarding the above mentioned two approaches to validating translation candidates using the Web, the experimental result shows that the second approach outperforms the first when the correct translation does exist in the corpus.", "labels": [], "entities": []}, {"text": "Furthermore, we examine the methods that combine two scoring functions based on their agreement.", "labels": [], "entities": []}, {"text": "The experimental result shows that it is quite possible to achieve precision much higher than those of single scoring functions.", "labels": [], "entities": [{"text": "precision", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.9993332028388977}]}], "datasetContent": [{"text": "In our experimental evaluation, within the framework of compiling a bilingual lexicon for technical terms, we evaluate the translation estimation portion that is indicated by the bold line in.", "labels": [], "entities": [{"text": "translation estimation", "start_pos": 123, "end_pos": 145, "type": "TASK", "confidence": 0.9140394330024719}]}, {"text": "In this paper, we simply omit the evaluation of the process of collecting technical terms to be listed as the headwords of a bilingual lexicon.", "labels": [], "entities": []}, {"text": "In order to evaluate the translation estimation portion, terms are randomly selected from the 10 categories of existing Japanese-English technical term dictionaries listed in, for each of the subsets X US and Y S (here, the terms of Y S that consist of only one word or morpheme are excluded).", "labels": [], "entities": [{"text": "translation estimation", "start_pos": 25, "end_pos": 47, "type": "TASK", "confidence": 0.9654251337051392}]}, {"text": "As described in Section 1, the terms of the set X UT (the set of translations for the terms of the subset X US ) is used for collecting a domain/topic-specific corpus from the Web.", "labels": [], "entities": []}, {"text": "As shown in, size of the collected corpora is 48MB on the average.", "labels": [], "entities": []}, {"text": "Translation estimation evaluation is to be conducted for the subset Y S . For each of the 10 categories, Table 3 shows the sizes of the subsets X US and Y S , and the rate of including correct translation within the collected domain/topic-specific corpus for Y S . In the following, we show the evaluation results with the source language S as English and the target language T as Japanese.", "labels": [], "entities": [{"text": "Translation estimation", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9619652628898621}]}, {"text": "This section gives the results of evaluating single scoring functions A \u223c I listed in. shows three types of experimental results.", "labels": [], "entities": []}, {"text": "The column 'the whole set Y S ' shows the results against the whole set Y S . The column 'generatable' shows the results against the translation pairs in Y S that can be generated through the compositional translation estimation process.", "labels": [], "entities": []}, {"text": "69% of the terms in 'the whole set Y S ' belongs to the set 'generatable'.", "labels": [], "entities": []}, {"text": "The column 'gene.-exist' shows the result against the source terms whose correct translations do exist in the corpus and that can be generated through the compositional translation estimation process.", "labels": [], "entities": []}, {"text": "50% of the terms in 'the whole set Y S ' belongs to the set 'gene.-exist'.", "labels": [], "entities": []}, {"text": "The column 'top 1' shows the correct rate of the first ranked translation candidate.", "labels": [], "entities": [{"text": "correct rate", "start_pos": 29, "end_pos": 41, "type": "METRIC", "confidence": 0.9582333564758301}]}, {"text": "The column 'top 10' shows the rate of including the correct candidate within top 10.", "labels": [], "entities": []}, {"text": "First, in order to evaluate the effectiveness of the approach of validating translation candidates by using a target language corpus, we compare the scoring functions 'D' and 'E'.", "labels": [], "entities": [{"text": "validating translation candidates", "start_pos": 65, "end_pos": 98, "type": "TASK", "confidence": 0.8176064888636271}]}, {"text": "The difference between them is whether or not they use a corpus score.", "labels": [], "entities": []}, {"text": "The results for the whole set Y S show that using a corpus score, the precision improves from 33.9% to 43.0%.", "labels": [], "entities": [{"text": "precision", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.9997122883796692}]}, {"text": "This result supports the effectiveness of the approach of validating translation candidates using a target language corpus.", "labels": [], "entities": [{"text": "validating translation candidates", "start_pos": 58, "end_pos": 91, "type": "TASK", "confidence": 0.7695715030034384}]}, {"text": "As can be seen from these results for the whole set Y S , the correct rate of the scoring function 'I' that directly uses the web search engine in the calculation of its corpus score is higher than those of other scoring functions that use the collected domain/topic-specific corpus.", "labels": [], "entities": [{"text": "correct rate", "start_pos": 62, "end_pos": 74, "type": "METRIC", "confidence": 0.9574264883995056}]}, {"text": "This is because, for the whole set Y S , the rate of including correct translation within the collected domain/topicspecific corpus is 72% on the average, which is not very high.", "labels": [], "entities": [{"text": "including correct translation within the collected domain/topicspecific", "start_pos": 53, "end_pos": 124, "type": "TASK", "confidence": 0.7121112247308096}]}, {"text": "On the other hand, the results of the column 'gene.-exist' show that if the correct translation does exist in the corpus, most of the scoring functions other than 'I' can achieve precisions higher than that of the scoring function 'I'.", "labels": [], "entities": [{"text": "precisions", "start_pos": 179, "end_pos": 189, "type": "METRIC", "confidence": 0.9951409101486206}]}, {"text": "This result supports the effectiveness of the approach of collecting a domain/topic-specific corpus from the Web in advance and then validating generated translation candidates against this corpus.", "labels": [], "entities": []}, {"text": "The result of evaluating the method that combines two scoring functions based on their agreement is shown in.", "labels": [], "entities": []}, {"text": "This result indicates that combinations of scoring functions with 'off-line'/'on-   line' corpus tend to achieve higher precisions than those with 'off-line'/'off-line' corpus.", "labels": [], "entities": [{"text": "precisions", "start_pos": 120, "end_pos": 130, "type": "METRIC", "confidence": 0.9966717958450317}]}, {"text": "This result also shows that it is quite possible to achieve high precisions even by combining scoring functions with 'off-line'/'off-line' corpus (the pair 'A' and 'H').", "labels": [], "entities": [{"text": "precisions", "start_pos": 65, "end_pos": 75, "type": "METRIC", "confidence": 0.9942381381988525}]}, {"text": "Here, the two scoring functions 'A' and 'H' are the one with frequency-based scoring functions and that with probability-based scoring functions, and hence, have quite different nature in the design of their scoring functions.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Numbers of Entries and Translation Pairs  in the Lexicons", "labels": [], "entities": []}, {"text": " Table 3: Number of Translation Pairs for Evaluation (S=English)", "labels": [], "entities": []}, {"text": " Table 4: Result of Evaluating single Scoring Functions", "labels": [], "entities": [{"text": "Result", "start_pos": 10, "end_pos": 16, "type": "TASK", "confidence": 0.848305344581604}, {"text": "Evaluating single Scoring Functions", "start_pos": 20, "end_pos": 55, "type": "TASK", "confidence": 0.8459032624959946}]}, {"text": " Table 5: Result of combining two scoring func- tions based on their agreement", "labels": [], "entities": []}]}