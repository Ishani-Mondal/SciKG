{"title": [{"text": "Interactive Question Answering and Constraint Relaxation in Spoken Dialogue Systems", "labels": [], "entities": [{"text": "Interactive Question Answering and Constraint Relaxation", "start_pos": 0, "end_pos": 56, "type": "TASK", "confidence": 0.6422208348910013}]}], "abstractContent": [{"text": "We explore the relationship between question answering and constraint relaxation in spoken dialog systems.", "labels": [], "entities": [{"text": "question answering", "start_pos": 36, "end_pos": 54, "type": "TASK", "confidence": 0.8413069546222687}]}, {"text": "We develop dialogue strategies for selecting and presenting information succinctly.", "labels": [], "entities": []}, {"text": "In particular, we describe methods for dealing with the results of database queries in information-seeking dialogs.", "labels": [], "entities": []}, {"text": "Our goal is to structure the dialogue in such away that the user is neither overwhelmed with information nor left uncertain as to how to refine the query further.", "labels": [], "entities": []}, {"text": "We present evaluation results obtained from a user study involving 20 subjects in a restaurant selection task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Information presentation is an important issue when designing a dialogue system.", "labels": [], "entities": [{"text": "Information presentation", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7873897552490234}]}, {"text": "This is especially true when the dialogue system is used in a high-stress environment, such as driving a vehicle, where the user is already occupied with the driving task.", "labels": [], "entities": []}, {"text": "In this paper, we explore efficient dialogue strategies to address these issues, and present implemented knowledge management, dialogue and generation components that allow cognitively overloaded users -see (), for example -to obtain information from the dialogue system in a natural way.", "labels": [], "entities": []}, {"text": "We describe a knowledge manager that provides factual and ontological information, a content optimizer that regulates the amount of information, and a generator that realizes the selected content.", "labels": [], "entities": []}, {"text": "The domain data is divided between domain-specific ontologies and a database back-end.", "labels": [], "entities": []}, {"text": "We use the system for both restaurant selection and MP3 player tasks, and conducted experiments with 20 subjects.", "labels": [], "entities": [{"text": "restaurant selection", "start_pos": 27, "end_pos": 47, "type": "TASK", "confidence": 0.7193926572799683}]}, {"text": "There has been substantial previous work on information presentation in spoken dialogue systems.", "labels": [], "entities": [{"text": "information presentation", "start_pos": 44, "end_pos": 68, "type": "TASK", "confidence": 0.7510116398334503}]}, {"text": "() also present a constraint-based approach to cooperative information dialogue.", "labels": [], "entities": []}, {"text": "Their experiments focus on overconstrained queries, whereas we also deal with underconstrained ones.", "labels": [], "entities": []}, {"text": "Moreover, we guide the user through the dialogue by making suggestions about query refinements, which serve a similar r\u00f4le to the conditional responses of).", "labels": [], "entities": []}, {"text": "() describe a dialogue system that uses an error-correcting database manager for matching caller-provided information to database entries.", "labels": [], "entities": []}, {"text": "This allows the system to select the most likely database entry, but, in contrast to our approach, does not modify constraints at a more abstract level.", "labels": [], "entities": []}, {"text": "In contrast to all the approaches mentioned above, our language generator uses overgeneration and ranking techniques).", "labels": [], "entities": []}, {"text": "This facilitates variation and alignment with the user utterance.", "labels": [], "entities": []}, {"text": "A long-standing strand of research in NLP is in natural language access to databases.", "labels": [], "entities": []}, {"text": "It mainly focused on mapping natural language input to database queries.", "labels": [], "entities": []}, {"text": "Our work can be seen as an extension of this work by embedding it into a dialogue system and allowing the user to refine and relax queries, and to engage in clarification dialogs.", "labels": [], "entities": []}, {"text": "More recently, work on question answering (QA) is moving toward interactive question answering that gives the user a greater role in the QA process (HLT, forthcoming).", "labels": [], "entities": [{"text": "question answering (QA)", "start_pos": 23, "end_pos": 46, "type": "TASK", "confidence": 0.9132727384567261}, {"text": "question answering", "start_pos": 76, "end_pos": 94, "type": "TASK", "confidence": 0.7079932540655136}]}, {"text": "QA systems mostly operate on free text whereas we use a relational database.", "labels": [], "entities": []}, {"text": "(Thus, one needs to 'normalize' the information contained in free text to use our implemented system without further adaption.)", "labels": [], "entities": []}, {"text": "In the following section, we give an overview of the dialogue system.", "labels": [], "entities": []}, {"text": "We then describe the knowledge management, dialogue and generation components in separate sections.", "labels": [], "entities": [{"text": "knowledge management", "start_pos": 21, "end_pos": 41, "type": "TASK", "confidence": 0.7719878852367401}]}, {"text": "In section 6 we present evaluation results obtained from a user study.", "labels": [], "entities": []}, {"text": "This is followed by a discussion section and conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conducted experimental studies involving 20 subjects in a MP3 player task and 20 subjects in a restaurant selection task.", "labels": [], "entities": []}, {"text": "In the following, we concentrate on the restaurant selection task because it is more challenging for constraint handling and information presentation.", "labels": [], "entities": [{"text": "restaurant selection task", "start_pos": 40, "end_pos": 65, "type": "TASK", "confidence": 0.7315904299418131}, {"text": "constraint handling", "start_pos": 101, "end_pos": 120, "type": "TASK", "confidence": 0.7377614080905914}, {"text": "information presentation", "start_pos": 125, "end_pos": 149, "type": "TASK", "confidence": 0.7785830497741699}]}, {"text": "Each subject in the restaurant selection task was given 9 scenario descriptions involving 3 constraints.", "labels": [], "entities": []}, {"text": "Subjects were instructed to use their own words to find a fitting restaurant.", "labels": [], "entities": []}, {"text": "We use a backend database of 2500 restaurants containing the following information for each restaurant: restaurant name, cuisine type, city and street names, service level, rating, whether they accept credit cards or reservations, price level, open hours, dress code, additional information (e.g. vegetarian food) and distance from current location.", "labels": [], "entities": []}, {"text": "Some of these constraints have a fixed number of values (e.g. service level and dress code), whereas those taking named entities as values are obviously openended.", "labels": [], "entities": []}, {"text": "show two of the dialogues from the experiments.", "labels": [], "entities": []}, {"text": "To exemplify the challenges the system is faced with, user turns are shown in the form of the output of the speech recognizer (we currently use the best ASR hypothesis as input to the parser).", "labels": [], "entities": [{"text": "speech recognizer", "start_pos": 108, "end_pos": 125, "type": "TASK", "confidence": 0.6968416571617126}]}, {"text": "The task of the first dialogue (figure 1) was to find a restaurant that has the following constraints: [Reservations=yes, ServiceLevel:excellent, Rating=5star].", "labels": [], "entities": []}, {"text": "Despite some minor speech recognition errors, the system correctly builds a query for the two constraints provided by the user in (1.1.) and verbalizes these in (1.2) to show its understanding of the user input.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 19, "end_pos": 37, "type": "TASK", "confidence": 0.6968989223241806}]}, {"text": "It also gives some example items and makes a suggestion.", "labels": [], "entities": []}, {"text": "This suggestion is not taken up by the user: Example dialogue 2 from system evaluation using restaurant selection task -in fact, we find that suggestions are generally not taken up by the user.", "labels": [], "entities": []}, {"text": "We believe this is due to the nature of the tasks, which specified exactly which criteria to match.", "labels": [], "entities": []}, {"text": "On the other hand, in more open application scenarios, where users may not know what questions can be asked, suggestions maybe useful.", "labels": [], "entities": []}, {"text": "In (1.3) the user issues a sub-query that further constrains the result set.", "labels": [], "entities": []}, {"text": "By again summarizing the constraints used, the system confirms in (1.4) that it has interpreted the new constraint as a revision of the previous query.", "labels": [], "entities": []}, {"text": "The alternative is to start anew query, which would be wrong in this context.", "labels": [], "entities": []}, {"text": "The task of the second dialogue,, was to find a restaurant that meets the constraints [BusinessHours:breakfast, StreetName='bower street.", "labels": [], "entities": []}, {"text": "This user tends to give shorter, keyword-style input to the system (2.1, 2.8).", "labels": [], "entities": []}, {"text": "In (2.3), the user reacts to a clarification question and adds another constraint which the system summarizes in (2.4).", "labels": [], "entities": []}, {"text": "(2.5) is an ASR error which the system cannot handle (2.6, 2.7).", "labels": [], "entities": [{"text": "ASR", "start_pos": 12, "end_pos": 15, "type": "TASK", "confidence": 0.7401711940765381}]}, {"text": "The user constraint of (2.8) is correctly used to revise the query (2.9), but \"british\" (2.10) is another ASR error that leads to a cuisine constraint not intended in the scenario/by the user.", "labels": [], "entities": []}, {"text": "This additional constraint yields an empty result set, from which the system recovers automatically by relaxing the hierarchically organized cuisine constraint to \"European food\".", "labels": [], "entities": []}, {"text": "In (2.11) the system uses dialogue strategy s3b for medium-sized result sets with constraint modifications (section 4).", "labels": [], "entities": []}, {"text": "The result of both dialogues is that all task constraints are met.", "labels": [], "entities": []}, {"text": "We conducted 20 experiments in the restaurant domain, 2 of which were restarted in the middle.", "labels": [], "entities": []}, {"text": "Overall, 180 tasks were performed involving 1144 user turns and 1818 system turns.", "labels": [], "entities": []}, {"text": "Two factors contributing to the higher number of system turns are a) some system turns are counted as two turns, such as 2.6, 2.7 in, and b) restaurants in longer enumerations of result items are counted as individual turns.", "labels": [], "entities": []}, {"text": "On average, user utterances are significantly shorter than system utterances (4.9 words, standard deviation \u03c3 = 3.82 vs 15,4 words, \u03c3 = 13.53).", "labels": [], "entities": [{"text": "standard deviation \u03c3", "start_pos": 89, "end_pos": 109, "type": "METRIC", "confidence": 0.9439822832743326}]}, {"text": "This is a result of the 'constraint summaries' produced by the generator.", "labels": [], "entities": []}, {"text": "The high standard deviation of the system utterances can be explained by the above-mentioned listing of individual result items (e.g. utterance (2.12) in).", "labels": [], "entities": [{"text": "standard", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9668081998825073}]}, {"text": "We collected usage frequencies for the dialogue strategies presented in section 4: there was no occurrence of empty final result sets (strategy s1a/b) because the system successfully relaxed constraints if it initially obtained no results.", "labels": [], "entities": []}, {"text": "Strategy s2a (small result sets without modifications) was used for 61 inputs, i.e. constraint sets constructed from user utterances.", "labels": [], "entities": []}, {"text": "Strategy s3a/b (medium-sized result sets) was used for 217 times and required constraint relaxations in 5 cases.", "labels": [], "entities": []}, {"text": "Strategy s4a/b (large result sets) was used for 316 inputs and required constraint relaxations in 16 cases.", "labels": [], "entities": []}, {"text": "Thus, the system performed constraint modifications in 21 cases overall.", "labels": [], "entities": []}, {"text": "All of these yielded non-empty final result sets.", "labels": [], "entities": []}, {"text": "For 573 inputs, no modification was required.", "labels": [], "entities": []}, {"text": "There were no empty final result set despite modifications.", "labels": [], "entities": []}, {"text": "On average, the generator produced 16 output candidates for inputs of two constraints, 160 candidates for typical inputs of 3 constraints and 320 candidates for 4 constraints.", "labels": [], "entities": []}, {"text": "Such numbers can easily be handled by simply enumerating candidates and selecting the 'best' one.", "labels": [], "entities": []}, {"text": "Task completion in the experiments was high: the subjects met all target constraints in 170 out of 180 tasks, i.e. completion rate was 94.44%.", "labels": [], "entities": [{"text": "completion", "start_pos": 5, "end_pos": 15, "type": "METRIC", "confidence": 0.9143575429916382}, {"text": "completion rate", "start_pos": 115, "end_pos": 130, "type": "METRIC", "confidence": 0.9817425906658173}]}, {"text": "An error analysis revealed that the reasons for only partially meeting the task constraints were varied.", "labels": [], "entities": []}, {"text": "For example, in one case a rating constraint (\"five stars\") was interpreted as a service constraint by the system, which led to an empty result set.", "labels": [], "entities": []}, {"text": "The system recovered from this error by means of constraint relaxation but the user seems to have been left with the impression that there are no restaurants of the desired kind with a five star rating.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Dialogue strategies for dealing with query results (last column explained in sec. 6)", "labels": [], "entities": []}]}