{"title": [{"text": "A Data Driven Approach to Relevancy Recognition for Contextual Question Answering", "labels": [], "entities": [{"text": "Relevancy Recognition", "start_pos": 26, "end_pos": 47, "type": "TASK", "confidence": 0.8664949834346771}, {"text": "Contextual Question Answering", "start_pos": 52, "end_pos": 81, "type": "TASK", "confidence": 0.5841504037380219}]}], "abstractContent": [{"text": "Contextual question answering (QA), in which users' information needs are satisfied through an interactive QA dialogue, has recently attracted more research attention.", "labels": [], "entities": [{"text": "Contextual question answering (QA)", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.852656732002894}]}, {"text": "One challenge of engaging dialogue into QA systems is to determine whether a question is relevant to the previous interaction context.", "labels": [], "entities": []}, {"text": "We refer to this task as rel-evancy recognition.", "labels": [], "entities": [{"text": "rel-evancy recognition", "start_pos": 25, "end_pos": 47, "type": "TASK", "confidence": 0.6521743088960648}]}, {"text": "In this paper we propose a data driven approach for the task of relevancy recognition and evaluate it on two data sets: the TREC data and the HandQA data.", "labels": [], "entities": [{"text": "relevancy recognition", "start_pos": 64, "end_pos": 85, "type": "TASK", "confidence": 0.9665999710559845}, {"text": "TREC data", "start_pos": 124, "end_pos": 133, "type": "DATASET", "confidence": 0.7505188882350922}, {"text": "HandQA data", "start_pos": 142, "end_pos": 153, "type": "DATASET", "confidence": 0.9740869104862213}]}, {"text": "The results show that we achieve better performance than a previous rule-based algorithm.", "labels": [], "entities": []}, {"text": "A detailed evaluation analysis is presented.", "labels": [], "entities": []}], "introductionContent": [{"text": "Question Answering (QA) is an interactive human-machine process that aims to respond to users' natural language questions with exact answers rather than a list of documents.", "labels": [], "entities": [{"text": "Question Answering (QA)", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8665058612823486}]}, {"text": "In the last few years, QA has attracted broader research attention from both the information retrieval) and the computational linguistic fields", "labels": [], "entities": [{"text": "QA", "start_pos": 23, "end_pos": 25, "type": "TASK", "confidence": 0.9375364184379578}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Confusion Matrix for TREC Data", "labels": [], "entities": []}, {"text": " Table 2: Confusion Matrix Using Adaboosting", "labels": [], "entities": [{"text": "Adaboosting", "start_pos": 33, "end_pos": 44, "type": "DATASET", "confidence": 0.5699183940887451}]}, {"text": " Table 3: Confusion Matrix for HandQA Data", "labels": [], "entities": [{"text": "HandQA", "start_pos": 31, "end_pos": 37, "type": "DATASET", "confidence": 0.9134792685508728}]}]}