{"title": [{"text": "Using Part-of-Speech Reranking to Improve Chinese Word Segmentation", "labels": [], "entities": [{"text": "Improve Chinese Word Segmentation", "start_pos": 34, "end_pos": 67, "type": "TASK", "confidence": 0.8357691913843155}]}], "abstractContent": [{"text": "Chinese word segmentation and Part-of-Speech (POS) tagging have been commonly considered as two separated tasks.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.5473802387714386}, {"text": "Part-of-Speech (POS) tagging", "start_pos": 30, "end_pos": 58, "type": "TASK", "confidence": 0.658269214630127}]}, {"text": "In this paper, we present a system that performs Chinese word segmentation and POS tagging simultaneously.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 49, "end_pos": 74, "type": "TASK", "confidence": 0.5719218154748281}, {"text": "POS tagging", "start_pos": 79, "end_pos": 90, "type": "TASK", "confidence": 0.7965190410614014}]}, {"text": "We train a segmenter and a tagger model separately based on linear-chain Conditional Random Fields (CRF), using lexical, morphological and semantic features.", "labels": [], "entities": []}, {"text": "We propose an approximated joint decoding method by reranking the N-best segmenter output , based POS tagging information.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 98, "end_pos": 109, "type": "TASK", "confidence": 0.6126702725887299}]}, {"text": "Experimental results on SIGHAN Bakeoff dataset and Penn Chinese Treebank show that our reranking method significantly improve both segmentation and POS tagging accuracies.", "labels": [], "entities": [{"text": "SIGHAN Bakeoff dataset", "start_pos": 24, "end_pos": 46, "type": "DATASET", "confidence": 0.857258121172587}, {"text": "Penn Chinese Treebank", "start_pos": 51, "end_pos": 72, "type": "DATASET", "confidence": 0.9430652658144633}, {"text": "segmentation", "start_pos": 131, "end_pos": 143, "type": "TASK", "confidence": 0.9613600969314575}, {"text": "POS tagging", "start_pos": 148, "end_pos": 159, "type": "TASK", "confidence": 0.716395765542984}]}], "introductionContent": [{"text": "Word segmentation and Part-of-speeching (POS) tagging are the most fundamental tasks in Chinese natural language processing (NLP).", "labels": [], "entities": [{"text": "Word segmentation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.6845051348209381}, {"text": "Part-of-speeching (POS) tagging", "start_pos": 22, "end_pos": 53, "type": "TASK", "confidence": 0.657055550813675}, {"text": "Chinese natural language processing (NLP)", "start_pos": 88, "end_pos": 129, "type": "TASK", "confidence": 0.7298394271305629}]}, {"text": "Traditionally, these two tasks were treated as separate and independent processing steps chained together in a pipeline.", "labels": [], "entities": []}, {"text": "In such pipeline systems, errors introduced at the early stage cannot be easily recovered in later steps, causing a cascade of errors and eventually harm overall performance.", "labels": [], "entities": []}, {"text": "Intuitively, a correct segmentation of the input sentence is more likely to give rise to a correct POS tagging sequence than an incorrect segmentation.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 99, "end_pos": 110, "type": "TASK", "confidence": 0.7310469150543213}]}, {"text": "Hinging on this idea, one way to avoid error propagation in chaining subtasks such as segmentation and POS tagging is to exploit the learning transfer) among subtasks, typically through joint inference.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 103, "end_pos": 114, "type": "TASK", "confidence": 0.6897944509983063}]}, {"text": "presented dynamic conditional random fields (DCRF), a generalization of the traditional linear-chain CRF that allow representation of interaction among labels.", "labels": [], "entities": []}, {"text": "They used loopy belief propagation for inference approximation.", "labels": [], "entities": [{"text": "loopy belief propagation", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.7179974714914957}, {"text": "inference approximation", "start_pos": 39, "end_pos": 62, "type": "TASK", "confidence": 0.8019079267978668}]}, {"text": "Their empirical results on the joint task of POS tagging and NP-chunking suggested that DCRF gave superior performance over cascaded linear-chain CRF. and also trained single joint models over the Chinese segmentation and POS tagging subtasks.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 45, "end_pos": 56, "type": "TASK", "confidence": 0.8082410097122192}, {"text": "POS tagging", "start_pos": 222, "end_pos": 233, "type": "TASK", "confidence": 0.7080142945051193}]}, {"text": "In their work, they brought the two subtasks together by treating it as a single tagging problem, for which they trained a maximum entropy classifier to assign a combined word boundary and POS tag to each character.", "labels": [], "entities": []}, {"text": "A major challenge, however, exists in doing joint inference for complex and large-scale NLP application.", "labels": [], "entities": []}, {"text": "suggested that in many cases exact inference can be too expensive and thus formidable.", "labels": [], "entities": []}, {"text": "They presented an alternative approach in which a linear-chain CRF is trained separately for each subtask at training time, but at decoding time they combined the learned weights from the CRF cascade into a single grid-shaped factorial CRF to perform joint decoding and make predictions for all subtasks.", "labels": [], "entities": []}, {"text": "Similar to), in our system we also train a cascade of linear-chain CRF for the subtasks.", "labels": [], "entities": []}, {"text": "But at decoding time, we experiment with an alternative approximation method to joint decoding, by taking the n-best hypotheses from the segmentation model and use the POS tagging model for reranking.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 168, "end_pos": 179, "type": "TASK", "confidence": 0.5695836842060089}]}, {"text": "We evaluated our system on the open tracks of SIGHAN Bakeoff 2006 dataset.", "labels": [], "entities": [{"text": "SIGHAN Bakeoff 2006 dataset", "start_pos": 46, "end_pos": 73, "type": "DATASET", "confidence": 0.9267532527446747}]}, {"text": "Furthermore, to evaluate our reranking method's impact on the POS tagging task, we also performed 10-fold cross-validation tests on the 250k Penn Chinese Treebank (CTB) ().", "labels": [], "entities": [{"text": "POS tagging task", "start_pos": 62, "end_pos": 78, "type": "TASK", "confidence": 0.8729478518168131}, {"text": "Penn Chinese Treebank (CTB)", "start_pos": 141, "end_pos": 168, "type": "DATASET", "confidence": 0.9314388732115427}]}, {"text": "Results from both evaluations suggest that our simple reranking method is very effective.", "labels": [], "entities": []}, {"text": "We achieved a consistent performance gain on both segmentation and POS tagging tasks over linearly-cascaded CRF.", "labels": [], "entities": [{"text": "segmentation and POS tagging tasks", "start_pos": 50, "end_pos": 84, "type": "TASK", "confidence": 0.7481247246265411}]}, {"text": "Our official F-scores on the 2006 Bakeoff open tracks are 0.935 (UPUC), 0.964 (CityU), 0.952 (MSRA) and 0.949 (CKIP).", "labels": [], "entities": [{"text": "F-scores", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9950417876243591}, {"text": "2006 Bakeoff open tracks", "start_pos": 29, "end_pos": 53, "type": "DATASET", "confidence": 0.7771221697330475}, {"text": "UPUC", "start_pos": 65, "end_pos": 69, "type": "DATASET", "confidence": 0.666385293006897}, {"text": "CityU", "start_pos": 79, "end_pos": 84, "type": "DATASET", "confidence": 0.9017428159713745}]}], "datasetContent": [{"text": "We evaluated our system's segmentation results on the SIGHAN Bakeoff 2006 dataset.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 26, "end_pos": 38, "type": "TASK", "confidence": 0.9648390412330627}, {"text": "SIGHAN Bakeoff 2006 dataset", "start_pos": 54, "end_pos": 81, "type": "DATASET", "confidence": 0.9389584362506866}]}, {"text": "To evaluate our reranking method's impact on the POS tagging part, we also performed 10-fold cross-validation tests on the 250k Penn Chinese Treebank (CTB 250k).", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 49, "end_pos": 60, "type": "TASK", "confidence": 0.8003391325473785}, {"text": "Penn Chinese Treebank (CTB 250k)", "start_pos": 128, "end_pos": 160, "type": "DATASET", "confidence": 0.9594953741346087}]}, {"text": "The CRF model for POS tagging is trained on CTB 250k in all the experiments.", "labels": [], "entities": [{"text": "CRF", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.769206166267395}, {"text": "POS tagging", "start_pos": 18, "end_pos": 29, "type": "TASK", "confidence": 0.9177368581295013}, {"text": "CTB 250k", "start_pos": 44, "end_pos": 52, "type": "DATASET", "confidence": 0.9237397909164429}]}, {"text": "We report recall (R), precision (P), and F1-score (F) for both word segmentation and POS tagging tasks.", "labels": [], "entities": [{"text": "recall (R)", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9671319276094437}, {"text": "precision (P)", "start_pos": 22, "end_pos": 35, "type": "METRIC", "confidence": 0.9603679031133652}, {"text": "F1-score (F)", "start_pos": 41, "end_pos": 53, "type": "METRIC", "confidence": 0.9778369069099426}, {"text": "word segmentation", "start_pos": 63, "end_pos": 80, "type": "TASK", "confidence": 0.7426976561546326}, {"text": "POS tagging tasks", "start_pos": 85, "end_pos": 102, "type": "TASK", "confidence": 0.833101491133372}]}, {"text": "N value is chosen to be 20 for the N-best list reranking, based on cross validation.", "labels": [], "entities": []}, {"text": "For CRF learning and decoding, we use the CRF++ toolkit 2 ..", "labels": [], "entities": [{"text": "CRF learning", "start_pos": 4, "end_pos": 16, "type": "TASK", "confidence": 0.9402212798595428}]}, {"text": "More interesting to us is how much the N-best list reranking method using POS tagging helped to increase segmentation performance.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 74, "end_pos": 85, "type": "TASK", "confidence": 0.6860509216785431}, {"text": "segmentation", "start_pos": 105, "end_pos": 117, "type": "TASK", "confidence": 0.9719008207321167}]}, {"text": "For comparison, we ran a linear-cascade of segmentation and POS tagging CRFs without reranking as the baseline system, and the results are shown in.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 43, "end_pos": 55, "type": "TASK", "confidence": 0.9739177823066711}, {"text": "POS tagging CRFs", "start_pos": 60, "end_pos": 76, "type": "TASK", "confidence": 0.7214103738466898}]}, {"text": "We can see that our reranking method consistently improved segmentation scores.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 59, "end_pos": 71, "type": "TASK", "confidence": 0.9767392873764038}]}, {"text": "In particular, there is a greater improvement gained in recall than precision across all four tracks.", "labels": [], "entities": [{"text": "recall", "start_pos": 56, "end_pos": 62, "type": "METRIC", "confidence": 0.999381422996521}, {"text": "precision", "start_pos": 68, "end_pos": 77, "type": "METRIC", "confidence": 0.9994775652885437}]}, {"text": "We observed the greatest improvement from the UPUC track.", "labels": [], "entities": [{"text": "UPUC track", "start_pos": 46, "end_pos": 56, "type": "DATASET", "confidence": 0.969397783279419}]}, {"text": "We think it is because our POS tagging model is trained on CTB 250k, which could be drawn from the same corpus as the UPUC training data, and therefore there is a closer mapping between segmentation standard of the POS tagging training data and the segmentation training data (at this: Comparison of the baseline system (without POS reranking) and our final system.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 27, "end_pos": 38, "type": "TASK", "confidence": 0.6260245740413666}, {"text": "CTB 250k", "start_pos": 59, "end_pos": 67, "type": "DATASET", "confidence": 0.9343789517879486}, {"text": "UPUC training data", "start_pos": 118, "end_pos": 136, "type": "DATASET", "confidence": 0.9501720269521078}, {"text": "POS tagging training data", "start_pos": 215, "end_pos": 240, "type": "DATASET", "confidence": 0.6090552434325218}]}], "tableCaptions": [{"text": " Table 2: Performance of our system on open tracks  of SIGHAN Bakeoff 2006.", "labels": [], "entities": [{"text": "SIGHAN Bakeoff 2006", "start_pos": 55, "end_pos": 74, "type": "DATASET", "confidence": 0.867799977461497}]}, {"text": " Table 3: Comparison of the baseline system (with- out POS reranking) and our final system.", "labels": [], "entities": []}]}