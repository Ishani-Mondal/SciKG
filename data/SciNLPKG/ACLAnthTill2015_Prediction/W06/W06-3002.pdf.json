{"title": [{"text": "WoZ Simulation of Interactive Question Answering", "labels": [], "entities": [{"text": "WoZ Simulation of Interactive Question Answering", "start_pos": 0, "end_pos": 48, "type": "TASK", "confidence": 0.6263195474942526}]}], "abstractContent": [{"text": "QACIAD (Question Answering Challenge for Information Access Dialogue) is an evaluation framework for measuring interactive question answering (QA) technologies.", "labels": [], "entities": [{"text": "QACIAD", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.7401271462440491}, {"text": "Question Answering Challenge for Information Access Dialogue)", "start_pos": 8, "end_pos": 69, "type": "TASK", "confidence": 0.7258264608681202}, {"text": "question answering (QA)", "start_pos": 123, "end_pos": 146, "type": "TASK", "confidence": 0.8460040807723999}]}, {"text": "It assumes that users interactively collect information using a QA system for writing a report on a given topic and evaluates, among other things, the capabilities needed under such circumstances.", "labels": [], "entities": []}, {"text": "This paper reports an experiment for examining the assumptions made by QACIAD.", "labels": [], "entities": [{"text": "QACIAD", "start_pos": 71, "end_pos": 77, "type": "DATASET", "confidence": 0.8898094296455383}]}, {"text": "In this experiment, dialogues under the situation that QACIAD assumes are collected using WoZ (Wiz-ard of Oz) simulating, which is frequently used for collecting dialogue data for designing speech dialogue systems, and then analyzed.", "labels": [], "entities": []}, {"text": "The results indicate that the setting of QACIAD is real and appropriate and that one of the important capabilities for future interactive QA systems is providing cooperative and helpful responses.", "labels": [], "entities": []}], "introductionContent": [{"text": "Open-domain question answering (QA) technologies allow users to ask a question using natural language and obtain the answer itself rather than a list of documents that contain the answer.", "labels": [], "entities": [{"text": "Open-domain question answering (QA)", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.7929028620322546}]}, {"text": "While early research in this field concentrated on answering factoid questions one by one in an isolated manner, recent research appears to be moving in several new directions.", "labels": [], "entities": [{"text": "answering factoid questions one by one", "start_pos": 51, "end_pos": 89, "type": "TASK", "confidence": 0.8650419811407725}]}, {"text": "Using QA systems in an interactive environment is one of those directions.", "labels": [], "entities": []}, {"text": "A context task was attempted in order to evaluate the systems' ability to track context for supporting interactive user sessions at TREC 2001.", "labels": [], "entities": [{"text": "TREC 2001", "start_pos": 132, "end_pos": 141, "type": "DATASET", "confidence": 0.9017620086669922}]}, {"text": "Since TREC 2004, questions in the task have been given as collections of questions related to common topics, rather than ones that are isolated and independent of each other).", "labels": [], "entities": [{"text": "TREC 2004", "start_pos": 6, "end_pos": 15, "type": "DATASET", "confidence": 0.7327902615070343}]}, {"text": "It is important for researchers to recognize that such a cohesive manner is natural in QA, although the task itself is not intended for evaluating context processing abilities since, as it is given the common topic, sophisticated context processing is not needed.", "labels": [], "entities": []}, {"text": "Such a direction has also been envisaged as a research roadmap, in which QA systems become more sophisticated and can be used by professional reporters and information analysts.", "labels": [], "entities": []}, {"text": "At some stage of that sophistication, a young reporter writing an article on a specific topic will be able to translate the main issue into a set of simpler questions and pose those questions to the QA system.", "labels": [], "entities": []}, {"text": "Another research trend in interactive QA has been observed in several projects that are part of the ARDA AQUAINT program.", "labels": [], "entities": [{"text": "ARDA AQUAINT program", "start_pos": 100, "end_pos": 120, "type": "DATASET", "confidence": 0.785852829615275}]}, {"text": "These studies concern scenario-based QA, the aim of which is to handle non-factoid, explanatory, analytical questions posed by users with extensive background knowledge.", "labels": [], "entities": []}, {"text": "Issues include managing clarification dialogues in order to disambiguate users' intentions and interests; and question decomposition to obtain simpler and more tractable questions ()().", "labels": [], "entities": [{"text": "question decomposition", "start_pos": 110, "end_pos": 132, "type": "TASK", "confidence": 0.8413184881210327}]}, {"text": "The nature of questions posed by users and patterns of interaction vary depending on the users who use a QA system and on the environments in which it is used).", "labels": [], "entities": []}, {"text": "The user maybe a young reporter, a trained analyst, or a common man without special training.", "labels": [], "entities": []}, {"text": "Questions can be answered by simple names and facts, such as those handled in early TREC conferences (), or by short passages retrieved like some systems developed in the AQUAINT program do ().", "labels": [], "entities": []}, {"text": "The situation in which QA systems are supposed to be used is an important factor of the system design and the evaluation must take such a factor into account.", "labels": [], "entities": []}, {"text": "QACIAD (Question Answering Challenge for Information Access Dialogue) is an objective and quantitative evaluation framework to measure the abilities of QA systems used interactively to participate in dialogues for accessing information ()().", "labels": [], "entities": [{"text": "QACIAD", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.7310445308685303}, {"text": "Question Answering Challenge for Information Access Dialogue)", "start_pos": 8, "end_pos": 69, "type": "TASK", "confidence": 0.6441583037376404}]}, {"text": "It assumes the situation in which users interactively collect information using a QA system for writing a report on a given topic and evaluates, among other things, the capabilities needed under such circumstances, i.e. proper interpretation of questions under a given dialogue context; in other words, context processing capabilities such as anaphora resolution and ellipses handling.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 343, "end_pos": 362, "type": "TASK", "confidence": 0.7271904796361923}]}, {"text": "We are interested in examining the assumptions made by QACIAD, and conducted an experiment, in which the dialogues under the situation QACIAD assumes were simulated using the WoZ (Wizard of Oz) technique) and analyzed.", "labels": [], "entities": [{"text": "QACIAD", "start_pos": 55, "end_pos": 61, "type": "DATASET", "confidence": 0.8540580868721008}]}, {"text": "In WoZ simulation, which is frequently used for collecting dialogue data for designing speech dialogue systems, dialogues that become possible when a system has been developed are simulated by a human, a WoZ, who plays the role of the system, as well as a subject who is not informed that a human is behaving as the system and plays the role of its user.", "labels": [], "entities": []}, {"text": "Analyzing the characteristics of language expressions and pragmatic devices used by users, we confirm whether QACIAD is a proper framework for evaluating QA systems used in the situation it assumes.", "labels": [], "entities": []}, {"text": "We also examine what functions will be needed for such QA systems by analyzing intelligent behavior of the WoZs.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Categorization of user utterances by answer  type", "labels": [], "entities": []}, {"text": " Table 4: Pragmatic phenomena observed", "labels": [], "entities": []}]}