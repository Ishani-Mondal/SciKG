{"title": [{"text": "Initial Explorations in English to Turkish Statistical Machine Translation", "labels": [], "entities": [{"text": "Turkish Statistical Machine Translation", "start_pos": 35, "end_pos": 74, "type": "TASK", "confidence": 0.725844144821167}]}], "abstractContent": [{"text": "This paper presents some very preliminary results for and problems in developing a statistical machine translation system from English to Turkish.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 83, "end_pos": 114, "type": "TASK", "confidence": 0.6447200775146484}]}, {"text": "Starting with a baseline word model trained from about 20K aligned sentences, we explore various ways of exploiting morphological structure to improve upon the baseline system.", "labels": [], "entities": []}, {"text": "As Turkish is a language with complex agglutinative word structures, we experiment with morphologically segmented and disambiguated versions of the parallel texts in order to also uncover relations between morphemes and function words in one language with morphemes and functions words in the other, in addition to relations between open class content words.", "labels": [], "entities": []}, {"text": "Morphological segmentation on the Turk-ish side also conflates the statistics from allomorphs so that sparseness can be alleviated to a certain extent.", "labels": [], "entities": [{"text": "Morphological segmentation", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7578507363796234}, {"text": "Turk-ish", "start_pos": 34, "end_pos": 42, "type": "DATASET", "confidence": 0.8876863121986389}]}, {"text": "We find that this approach coupled with a simple grouping of most frequent morphemes and function words on both sides improve the BLEU score from the baseline of 0.0752 to 0.0913 with the small training data.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 130, "end_pos": 140, "type": "METRIC", "confidence": 0.9776438474655151}]}, {"text": "We close with a discussion on why one should not expect distortion parameters to model word-local morpheme ordering and that anew approach to handling complex mor-photactics is needed.", "labels": [], "entities": [{"text": "word-local morpheme ordering", "start_pos": 87, "end_pos": 115, "type": "TASK", "confidence": 0.6278362274169922}]}], "introductionContent": [{"text": "The availability of large amounts of so-called parallel texts has motivated the application of statistical techniques to the problem of machine translation starting with the seminal work at IBM in the early 90's (.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 136, "end_pos": 155, "type": "TASK", "confidence": 0.7923597097396851}]}, {"text": "Statistical machine translation views the translation process as a noisy-channel signal recovery process in which one tries to recover the input \"signal\" e, from the observed output signal f.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 12, "end_pos": 31, "type": "TASK", "confidence": 0.72861547768116}]}, {"text": "Early statistical machine translation systems used a purely word-based approach without taking into account any of the morphological or syntactic properties of the languages (.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 6, "end_pos": 37, "type": "TASK", "confidence": 0.6357673605283102}]}, {"text": "Limitations of basic word-based models prompted researchers to exploit morphological and/or syntactic/phrasal structure,,,,,, among others.)", "labels": [], "entities": []}, {"text": "In the context of the agglutinative languages similar to Turkish (in at least morphological aspects) , there has been some recent work on translating from and to Finnish with the significant amount of data in the Europarl corpus.", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 213, "end_pos": 228, "type": "DATASET", "confidence": 0.9897381663322449}]}, {"text": "Although the BLEU () score from Finnish to English is 21.8, the score in the reverse direction is reported as 13.0 which is one of the lowest scores in 11 European languages scores ().", "labels": [], "entities": [{"text": "BLEU", "start_pos": 13, "end_pos": 17, "type": "METRIC", "confidence": 0.9992313385009766}]}, {"text": "Also, reported from and to translation scores for Finnish are the lowest on average, even with the large number of sentences available.", "labels": [], "entities": []}, {"text": "These may hint at the fact that standard alignment models maybe poorly equipped to deal with translation from a poor morphology language like English to an complex morphology language like Finnish or Turkish.", "labels": [], "entities": []}, {"text": "This paper presents results from some very preliminary explorations into developing an English-toTurkish statistical machine translation system and discusses the various problems encountered.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 105, "end_pos": 136, "type": "TASK", "confidence": 0.576775978008906}]}, {"text": "Starting with a baseline word model trained from about 20K aligned sentences, we explore various ways of exploiting morphological structure to improve upon the baseline system.", "labels": [], "entities": []}, {"text": "As Turkish is a language with agglutinative word structures, we experiment with morphologically segmented and disambiguated versions of the parallel text, in order to also uncover relations between morphemes and function words in one language with morphemes and functions words in the other, in addition to relations between open class content words; as a cursory analysis of sentence aligned Turkish and English texts indicates that translations of certain English words are actually morphemes embedded into Turkish words.", "labels": [], "entities": []}, {"text": "We choose a morphological segmentation representation on the Turkish side which abstracts from wordinternal morphological variations and conflates the statistics from allomorphs so that data sparseness can be alleviated to a certain extent.", "labels": [], "entities": []}, {"text": "This paper is organized as follows: we start with the some of the issues of building an SMT system into Turkish followed by a short overview Turkish morphology to motivate its effect on the word alignment problem with English.", "labels": [], "entities": [{"text": "SMT system", "start_pos": 88, "end_pos": 98, "type": "TASK", "confidence": 0.9188761115074158}, {"text": "word alignment", "start_pos": 190, "end_pos": 204, "type": "TASK", "confidence": 0.7401896715164185}]}, {"text": "We then present results from our explorations with a baseline system and with morphologically segmented parallel aligned texts, and conclude after a short discussion.", "labels": [], "entities": []}], "datasetContent": [{"text": "We proceeded with the following sequence of experiments: (1) Baseline: As a baseline system, we used a pure word-based approach and used Pharaoh Training tool (2004), to train on the 22,500 sentences, and decoded using Pharaoh () to obtain translations fora test set of 50 sentences.", "labels": [], "entities": [{"text": "Pharaoh Training tool (2004)", "start_pos": 137, "end_pos": 165, "type": "DATASET", "confidence": 0.7786390284697214}]}, {"text": "This gave us a baseline BLEU score of 0.0752.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 24, "end_pos": 34, "type": "METRIC", "confidence": 0.967068612575531}]}, {"text": "(2) Morpheme Concatenation: We then trained the same system with the morphemic representation of the parallel texts as discussed above.", "labels": [], "entities": [{"text": "Morpheme Concatenation", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.7622314393520355}]}, {"text": "The decoder now produced the translations as a sequence of root words and morphemes.", "labels": [], "entities": []}, {"text": "The surface words were then obtained by just concatenating all the morphemes following a root word (until the next root word) taking into just morphographemic rules but not any morphotactic constraints.", "labels": [], "entities": []}, {"text": "As expected this \"morpheme-salad\" produces a \"word-salad\", as most of the time wrong morphemes are associated with incompatible root words violating many morphotactic constraints.", "labels": [], "entities": []}, {"text": "The BLEU score here was 0.0281, substantially worse than the baseline in (1) above.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.9991635084152222}]}, {"text": "(3) Selective Morpheme Concatenation: With a small script we injected a bit of morphotactical knowledge into the surface form generation process and only combined those morphemes following a root word (in the given sequence), that gave rise to a valid Turkish word form as checked by a morphological analyzer.", "labels": [], "entities": [{"text": "Selective Morpheme Concatenation", "start_pos": 4, "end_pos": 36, "type": "TASK", "confidence": 0.7747990091641744}, {"text": "surface form generation", "start_pos": 113, "end_pos": 136, "type": "TASK", "confidence": 0.6572687824567159}]}, {"text": "Any unused morphemes were ignored.", "labels": [], "entities": []}, {"text": "This improved the BLEU score to 0.0424 which was still below the baseline.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 18, "end_pos": 28, "type": "METRIC", "confidence": 0.9640741646289825}]}, {"text": "(4) Morpheme Grouping: Observing that certain sequence of morphemes in Turkish texts are translations of some continuous sequence of functional words and tags in English texts, and that some morphemes should be aligned differently depending on the other morphemes in their context, we attempted a morpheme grouping.", "labels": [], "entities": [{"text": "Morpheme Grouping", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.9168813824653625}]}, {"text": "For example the morpheme sequence +DHr +mA marks infinitive form of a causative verb which in Turkish inflects like a noun; or the lexical morpheme sequence +yAcAk +DHr usually maps to \"it/he/she will\".", "labels": [], "entities": []}, {"text": "To find such groups of morphemes and functional words, we applied a sequence of morpheme groupings by extracting frequently occuring n-grams of morphemes as follows (much like the grouping used by: in a series of iterations, we obtained high-frequency bigrams from the morphemic representation of parallel texts, of either morphemes, or of previously such identified morpheme groups and neighboring morphemes until up to four morphemes or one root 3 morpheme could be combined.", "labels": [], "entities": []}, {"text": "During this process we ignored those combinations that contain punctuation or a morpheme preceding a root word.", "labels": [], "entities": []}, {"text": "A similar grouping was done on the English side grouping function words and morphemes before and after root words.", "labels": [], "entities": []}, {"text": "The aim of this process was two-fold: it let frequent morphemes to behave as a single token and help Pharaoh with identification of some of the phrases.", "labels": [], "entities": []}, {"text": "Also since the number of tokens on both sides were reduced, this enabled GIZA++ to produce somewhat better alignments.", "labels": [], "entities": []}, {"text": "The morpheme level translations that were obtained from training with this parallel texts were then converted into surface forms by concatenating the morphemes in the sequence produced.", "labels": [], "entities": []}, {"text": "This resulted in a BLEU score of 0.0644.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 19, "end_pos": 29, "type": "METRIC", "confidence": 0.9725184142589569}]}, {"text": "(5) Morpheme Grouping with Selective Morpheme Concatenation: This was the same as with the morphemes selectively combined as in.", "labels": [], "entities": [{"text": "Morpheme Grouping", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.8274872899055481}]}, {"text": "The BLEU score of 0.0913 with this approach was now above the baseline.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.978071928024292}]}, {"text": "summarizes the results in these five experiments:: BLEU scores for experiments to Exp.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 51, "end_pos": 55, "type": "METRIC", "confidence": 0.9993090629577637}, {"text": "Exp", "start_pos": 82, "end_pos": 85, "type": "DATASET", "confidence": 0.7951691746711731}]}, {"text": "System BLEU In an attempt to factor out and see if the translations were at all successful in getting the root words in the translations we performed the following: We morphologically analyzed and disambiguated the reference texts, and reduced all to sequences of root words by eliminating all the morphemes.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 7, "end_pos": 11, "type": "METRIC", "confidence": 0.9974625110626221}]}, {"text": "We performed the same for the outputs of (1) (after morphological analysis and disambiguation), (2) and (4) above, that is, threw away the morphemes ((3) is the same as (2) and (5) same as (4) here).", "labels": [], "entities": []}, {"text": "The translation root word sequences and the reference root word sequences were then evaluated using the BLEU (which would like to label here as BLEU-r for BLEU root, to avoid any comparison to previous results, which will be misleading.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 104, "end_pos": 108, "type": "METRIC", "confidence": 0.997642457485199}, {"text": "BLEU-r", "start_pos": 144, "end_pos": 150, "type": "METRIC", "confidence": 0.9936007857322693}, {"text": "BLEU", "start_pos": 155, "end_pos": 159, "type": "METRIC", "confidence": 0.9803148508071899}]}, {"text": "These scores are shown in.", "labels": [], "entities": []}, {"text": "The results in indicate that with the standard models for SMT, we are still quite far from even identifying the correct root words in the trans- lations into Turkish, let alone getting the morphemes and their sequences right.", "labels": [], "entities": [{"text": "SMT", "start_pos": 58, "end_pos": 61, "type": "TASK", "confidence": 0.9960432052612305}]}, {"text": "Although some of this maybe due to the (relatively) small amount of parallel texts we used, it may also be the case that splitting the sentences into morphemes can play havoc with the alignment process by significantly increasing the number of tokens per sentence especially when such tokens align to tokens on the other side that is quite faraway.", "labels": [], "entities": []}, {"text": "Nevertheless the models we used produce some quite reasonable translations fora small number of test sentences.", "labels": [], "entities": []}, {"text": "shows the two examples of translations that were obtained using the standard models (containing no Turkish specific manipulation except for selective morpheme concatenation).", "labels": [], "entities": []}, {"text": "We have marked the surface morpheme boundaries in the translated and reference Turkish texts to indicate where morphemes are joined for exposition purposes here -they neither appear in the reference translations nor in the produced translations!", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: BLEU scores for experiments", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.999180257320404}]}]}