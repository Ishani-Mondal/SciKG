{"title": [{"text": "Boosting for Chinese Named Entity Recognition", "labels": [], "entities": [{"text": "Chinese Named Entity Recognition", "start_pos": 13, "end_pos": 45, "type": "TASK", "confidence": 0.6473091170191765}]}], "abstractContent": [{"text": "We report an experiment in which a high-performance boosting based NER model originally designed for multiple European languages is instead applied to the Chi-nese named entity recognition task of the third SIGHAN Chinese language processing bakeoff.", "labels": [], "entities": [{"text": "Chi-nese named entity recognition task", "start_pos": 155, "end_pos": 193, "type": "TASK", "confidence": 0.7324506163597106}, {"text": "SIGHAN Chinese language processing bakeoff", "start_pos": 207, "end_pos": 249, "type": "TASK", "confidence": 0.5517516195774078}]}, {"text": "Using a simple character-based model along with a set of features that are easily obtained from the Chi-nese input strings, the system described employs boosting, a promising and theoretically well-founded machine learning method to combine a set of weak classi-fiers together into a final system.", "labels": [], "entities": []}, {"text": "Even though we did no other Chinese-specific tuning, and used only one-third of the MSRA and CityU corpora to train the system, reasonable results are obtained.", "labels": [], "entities": [{"text": "MSRA", "start_pos": 84, "end_pos": 88, "type": "DATASET", "confidence": 0.9802419543266296}, {"text": "CityU corpora", "start_pos": 93, "end_pos": 106, "type": "DATASET", "confidence": 0.8054995238780975}]}, {"text": "Our evaluation results show that 75.07 and 80.51 overall F-measures were obtained on MSRA and CityU test sets respectively.", "labels": [], "entities": [{"text": "F-measures", "start_pos": 57, "end_pos": 67, "type": "METRIC", "confidence": 0.9929450154304504}, {"text": "MSRA", "start_pos": 85, "end_pos": 89, "type": "DATASET", "confidence": 0.9532396197319031}, {"text": "CityU test sets", "start_pos": 94, "end_pos": 109, "type": "DATASET", "confidence": 0.9353336691856384}]}], "introductionContent": [{"text": "Named entity recognition (NER), which includes the identification and classification of certain proper nouns, such as person names, organizations, locations, temporal, numerical and monetary phrases, plays an important part in many natural language processing applications, such as machine translation, information retrieval, information extraction and question answering.", "labels": [], "entities": [{"text": "Named entity recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8086719910303751}, {"text": "identification and classification of certain proper nouns, such as person names, organizations, locations, temporal, numerical and monetary phrases", "start_pos": 51, "end_pos": 198, "type": "TASK", "confidence": 0.8096568403036698}, {"text": "machine translation", "start_pos": 282, "end_pos": 301, "type": "TASK", "confidence": 0.7988272905349731}, {"text": "information retrieval", "start_pos": 303, "end_pos": 324, "type": "TASK", "confidence": 0.8003174066543579}, {"text": "information extraction", "start_pos": 326, "end_pos": 348, "type": "TASK", "confidence": 0.8448649942874908}, {"text": "question answering", "start_pos": 353, "end_pos": 371, "type": "TASK", "confidence": 0.9016768634319305}]}, {"text": "Much of the NER research was pioneered in the MUC/DUC and Multilingual Entity Task (MET) evaluations, as a result of which significant progress has been made and many NER systems of fairly high accuracy have been constructed.", "labels": [], "entities": [{"text": "NER", "start_pos": 12, "end_pos": 15, "type": "TASK", "confidence": 0.9677317142486572}, {"text": "MUC/DUC", "start_pos": 46, "end_pos": 53, "type": "DATASET", "confidence": 0.714875062306722}, {"text": "accuracy", "start_pos": 194, "end_pos": 202, "type": "METRIC", "confidence": 0.992480993270874}]}, {"text": "In addition, the shared tasks of helped spur the development toward more language-independent NER systems, by evaluating four types of entities (people, locations, organizations and names of miscellaneous entities) in English, German, Dutch and Spanish.", "labels": [], "entities": []}, {"text": "However, these are all European languages, and Chinese NER appears to be significantly more challenging in a number of important respects.", "labels": [], "entities": []}, {"text": "We believe some of the main reasons to be as follows: (1) Unlike European languages, Chinese lacks capitalization information which plays a very important role in identifying named entities.", "labels": [], "entities": []}, {"text": "(2) There is no space between words in Chinese, so ambiguous segmentation interacts with NER decisions.", "labels": [], "entities": [{"text": "NER", "start_pos": 89, "end_pos": 92, "type": "TASK", "confidence": 0.9411144852638245}]}, {"text": "Consequently, segmentation errors will affect the NER performance, and vice versa.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 14, "end_pos": 26, "type": "TASK", "confidence": 0.9683946371078491}, {"text": "NER", "start_pos": 50, "end_pos": 53, "type": "TASK", "confidence": 0.967322826385498}]}, {"text": "(3) Unlike European languages, Chinese allows an open vocabulary for proper names of persons, eliminating another major source of explicit clues used by European language NER models.", "labels": [], "entities": []}, {"text": "This paper presents a system that introduces boosting to Chinese named entity identification and classification.", "labels": [], "entities": [{"text": "Chinese named entity identification and classification", "start_pos": 57, "end_pos": 111, "type": "TASK", "confidence": 0.6203301350275675}]}, {"text": "Our primary aim was to conduct a controlled experiment to test how well the boosting based models we designed for European languages would fare on Chinese, without major modeling alterations to accommodate Chinese.", "labels": [], "entities": []}, {"text": "We evaluated the system using data from the third SIGHAN Chinese language processing bakeoff, the goal of which was to perform NER on three types of named entities: PERSON, LO-CATION and ORGANIZATION.", "labels": [], "entities": [{"text": "SIGHAN Chinese language processing bakeoff", "start_pos": 50, "end_pos": 92, "type": "DATASET", "confidence": 0.6894891262054443}, {"text": "NER", "start_pos": 127, "end_pos": 130, "type": "TASK", "confidence": 0.9632284045219421}, {"text": "PERSON", "start_pos": 165, "end_pos": 171, "type": "METRIC", "confidence": 0.8552265167236328}, {"text": "LO-CATION", "start_pos": 173, "end_pos": 182, "type": "METRIC", "confidence": 0.9376175403594971}, {"text": "ORGANIZATION", "start_pos": 187, "end_pos": 199, "type": "METRIC", "confidence": 0.9603906273841858}]}, {"text": "1 Three training corpora from MSRA, CityU and LDC were given.", "labels": [], "entities": [{"text": "MSRA", "start_pos": 30, "end_pos": 34, "type": "DATASET", "confidence": 0.9597043991088867}, {"text": "CityU", "start_pos": 36, "end_pos": 41, "type": "DATASET", "confidence": 0.9376334547996521}]}, {"text": "The MSRA and LDC corpora were simplified Chinese texts while the CityU corpus was traditional Chinese.", "labels": [], "entities": [{"text": "MSRA and LDC corpora", "start_pos": 4, "end_pos": 24, "type": "DATASET", "confidence": 0.7694530934095383}, {"text": "CityU corpus", "start_pos": 65, "end_pos": 77, "type": "DATASET", "confidence": 0.9853722155094147}]}, {"text": "In addition, the competition also specified open and closed tests.", "labels": [], "entities": []}, {"text": "In the open test, the participants may use any other material including material from other training corpora, proprietary dictionaries, and material from the Web besides the given training corpora.", "labels": [], "entities": []}, {"text": "In the closed test, the participants can only use the three training corpora.", "labels": [], "entities": []}, {"text": "No other material or knowledge is allowed, including part-of-speech (POS) information, externally generated word-frequency counts, Arabic and Chinese numbers, feature characters for place names, common Chinese surnames, and soon.", "labels": [], "entities": []}, {"text": "The approach we used is based on selecting a number of features, which are used to train several weak classifiers.", "labels": [], "entities": []}, {"text": "Using boosting, which has been shown to perform well on other NLP problems and is a theoretically well-founded method, the weak classifiers are then combined to perform a strong classifier.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to implement the boosting/decision stumps, we used the publicly available software AT&T BoosTexter (), which implements boosting on top of decision stumps.", "labels": [], "entities": [{"text": "AT&T BoosTexter", "start_pos": 92, "end_pos": 107, "type": "DATASET", "confidence": 0.8977808952331543}]}, {"text": "For preprocessing we used an off-theshelf Chinese lexical analysis system, the open source ICTCLAS (, to segment and POS tag the training and test corpora.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Dev set results on MSRA and CityU.  Precision Recall  F \u03b2=1  MSRA  LOC  82.00%  85.93% 83.92  ORG  76.99%  61.44% 68.34  PER  89.33%  74.47% 81.22  Overall 82.62%  76.45% 79.41  CityU  LOC  88.62%  81.69% 85.02  ORG  82.50%  66.44% 73.61  PER  84.05%  84.58% 84.31  Overall 86.46%  79.26% 82.71", "labels": [], "entities": [{"text": "MSRA", "start_pos": 29, "end_pos": 33, "type": "DATASET", "confidence": 0.7767232060432434}, {"text": "CityU", "start_pos": 38, "end_pos": 43, "type": "DATASET", "confidence": 0.9020506143569946}, {"text": "Precision Recall  F \u03b2", "start_pos": 46, "end_pos": 67, "type": "METRIC", "confidence": 0.8963176757097244}, {"text": "MSRA  LOC  82.00", "start_pos": 71, "end_pos": 87, "type": "METRIC", "confidence": 0.7921810547510783}, {"text": "ORG", "start_pos": 104, "end_pos": 107, "type": "METRIC", "confidence": 0.9619765877723694}, {"text": "ORG", "start_pos": 222, "end_pos": 225, "type": "METRIC", "confidence": 0.9771973490715027}, {"text": "PER", "start_pos": 249, "end_pos": 252, "type": "METRIC", "confidence": 0.9534956812858582}]}]}