{"title": [{"text": "A System for Summarizing and Visualizing Arguments in Subjective Documents: Toward Supporting Decision Making", "labels": [], "entities": [{"text": "Summarizing and Visualizing Arguments in Subjective Documents", "start_pos": 13, "end_pos": 74, "type": "TASK", "confidence": 0.794262000492641}, {"text": "Supporting Decision Making", "start_pos": 83, "end_pos": 109, "type": "TASK", "confidence": 0.6818566620349884}]}], "abstractContent": [{"text": "On the World Wide Web, the volume of subjective information, such as opinions and reviews, has been increasing rapidly.", "labels": [], "entities": []}, {"text": "The trends and rules latent in a large set of subjective descriptions can potentially be useful for decision-making purposes.", "labels": [], "entities": []}, {"text": "In this paper, we propose a method for summarizing subjective descriptions, specifically opinions in Japanese.", "labels": [], "entities": [{"text": "summarizing subjective descriptions", "start_pos": 39, "end_pos": 74, "type": "TASK", "confidence": 0.91810276110967}]}, {"text": "We visualize the pro and con arguments fora target topic, such as \"Should Japan introduce the summertime system?\"", "labels": [], "entities": []}, {"text": "Users can summarize the arguments about the topic in order to choose a more reasonable standpoint for decision making.", "labels": [], "entities": [{"text": "decision making", "start_pos": 102, "end_pos": 117, "type": "TASK", "confidence": 0.8164784908294678}]}, {"text": "We evaluate our system, called \"OpinionReader\", experimentally.", "labels": [], "entities": []}], "introductionContent": [{"text": "On the World Wide Web, users can easily disseminate information irrespective of their own specialty.", "labels": [], "entities": []}, {"text": "Thus, natural language information on the Web is not restricted to objective and authorized information, such as news stories and technical publications.", "labels": [], "entities": []}, {"text": "The volume of subjective information, such as opinions and reviews, has also been increasing rapidly.", "labels": [], "entities": []}, {"text": "Although a single subjective description by an anonymous author is not always reliable, the trends and rules latent in a large set of subjective descriptions can potentially be useful for decisionmaking purposes.", "labels": [], "entities": []}, {"text": "In one scenario, a user may read customer reviews before choosing a product.", "labels": [], "entities": []}, {"text": "In another scenario, a user may assess the pros and cons of apolitical issue before determining their own attitude on the issue.", "labels": [], "entities": []}, {"text": "The decision making in the above scenarios is performed according to the following processes: (1) collecting documents related to a specific topic from the Web; (2) extracting subjective descriptions from the documents; (3) classifying the subjective descriptions according to their polarity, such as positive/negative or pro/con; (4) organizing (e.g., summarizing and/or visualizing) the classified descriptions so that users can view important points selectively; (5) making the decision.", "labels": [], "entities": [{"text": "summarizing and/or visualizing) the classified descriptions", "start_pos": 353, "end_pos": 412, "type": "TASK", "confidence": 0.8285145892037286}]}, {"text": "Because it is expensive to perform all of the above processes manually, a number of automatic methods have been explored.", "labels": [], "entities": []}, {"text": "Specifically, a large number of methods have been proposed to facilitate processes (2) and.", "labels": [], "entities": []}, {"text": "In this paper, we focus on process (4), and propose a method for summarizing subjective information, specifically opinions in Japanese.", "labels": [], "entities": [{"text": "summarizing subjective information", "start_pos": 65, "end_pos": 99, "type": "TASK", "confidence": 0.9089882771174113}]}, {"text": "Our method visualizes the pro and con arguments fora target topic, such as \"Should Japan introduce the summertime system?\"", "labels": [], "entities": []}, {"text": "By process (4), users can summarize the arguments about the topic in order to choose a more reasonable standpoint on it.", "labels": [], "entities": []}, {"text": "Consequently, our system supports decision making by users.", "labels": [], "entities": [{"text": "decision making", "start_pos": 34, "end_pos": 49, "type": "TASK", "confidence": 0.7829968333244324}]}, {"text": "However, process (5) is beyond the scope of this paper, and remains an intellectual activity for human beings.", "labels": [], "entities": []}, {"text": "We describe and demonstrate our prototype system, called \"OpinionReader\".", "labels": [], "entities": []}, {"text": "We also evaluate the components of our system experimentally.", "labels": [], "entities": []}, {"text": "Section 2 surveys previous research on the processing of subjective information.", "labels": [], "entities": []}, {"text": "Section 3 provides an overview of OpinionReader, and Sec-tion 4 describes the methodologies of its components.", "labels": [], "entities": []}, {"text": "Section 5 describes the experiments and discusses the results obtained.", "labels": [], "entities": []}], "datasetContent": [{"text": "For each topic used in the experiments, the assessors read the opinions from both standpoints and extracted the points at issue.", "labels": [], "entities": []}, {"text": "We defined the point at issue as the grounds for an argument.", "labels": [], "entities": []}, {"text": "We did not restrict the form of the points at issue.", "labels": [], "entities": []}, {"text": "Thus, the assessors were allowed to extract any continuous language units, such as words, phrases, sentences, and paragraphs, as points at issue.", "labels": [], "entities": []}, {"text": "Because our method is intended to extract points at issue exhaustively and accurately, we used recall and precision as evaluation measures for the extraction.", "labels": [], "entities": [{"text": "recall", "start_pos": 95, "end_pos": 101, "type": "METRIC", "confidence": 0.9994126558303833}, {"text": "precision", "start_pos": 106, "end_pos": 115, "type": "METRIC", "confidence": 0.9970405697822571}]}, {"text": "Recall is the ratio of the number of correct answers extracted automatically to the total number of correct answers.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9860872626304626}]}, {"text": "Precision is the ratio of the number of correct answers extracted automatically to the total number of points at issue extracted automatically.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9925576448440552}]}, {"text": "shows the results for each topic, in which \"System\" denotes the number of points at issue extracted automatically.", "labels": [], "entities": []}, {"text": "In, \"C\", \"R\", and \"P\" denote the number of correct answers, recall, and precision, respectively, on an assessor-by-assessor basis.", "labels": [], "entities": [{"text": "recall", "start_pos": 60, "end_pos": 66, "type": "METRIC", "confidence": 0.9990031123161316}, {"text": "precision", "start_pos": 72, "end_pos": 81, "type": "METRIC", "confidence": 0.99940025806427}]}, {"text": "Looking at, we see that the results can vary depending on the topic and the assessor.", "labels": [], "entities": []}, {"text": "However, recall and precision were approximately 50% and 4%, respectively, on average.", "labels": [], "entities": [{"text": "recall", "start_pos": 9, "end_pos": 15, "type": "METRIC", "confidence": 0.9998552799224854}, {"text": "precision", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.9998090863227844}]}, {"text": "The ratio of agreement between assessors was low.", "labels": [], "entities": [{"text": "ratio of", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.8800760805606842}, {"text": "agreement", "start_pos": 13, "end_pos": 22, "type": "METRIC", "confidence": 0.5066777467727661}]}, {"text": "When we used the points at issue extracted by one assessor as correct answers and evaluated the effectiveness of the other assessor in the extraction, the recall and precision ranged from 10% to 20% depending on the topic.", "labels": [], "entities": [{"text": "recall", "start_pos": 155, "end_pos": 161, "type": "METRIC", "confidence": 0.9997171759605408}, {"text": "precision", "start_pos": 166, "end_pos": 175, "type": "METRIC", "confidence": 0.9940727353096008}]}, {"text": "To increase the ratio of agreement between assessors, the instruction for assessors needs to be revised for future work.", "labels": [], "entities": []}, {"text": "This was mainly because the viewpoint fora target topic and the language units to be extracted were different, depending on the assessor.", "labels": [], "entities": []}, {"text": "Because our automatic method extracted points at issue exhaustively, the recall was high and the precision was low, irrespective of the assessor.", "labels": [], "entities": [{"text": "recall", "start_pos": 73, "end_pos": 79, "type": "METRIC", "confidence": 0.9990794658660889}, {"text": "precision", "start_pos": 97, "end_pos": 106, "type": "METRIC", "confidence": 0.9997360110282898}]}, {"text": "The ratios of noun phrases (including nouns) and verb phrases to the number of manually extracted points at issue were 78.5% and 2.0%, respectively.", "labels": [], "entities": []}, {"text": "Although the ratio for verb phrases is relatively low, extracting both noun and verb phrases is meaningful.", "labels": [], "entities": []}, {"text": "The recalls of our method for noun phrases and verb phrases were 60.0% and 44.3%, respectively.", "labels": [], "entities": [{"text": "recalls", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.9983914494514465}]}, {"text": "Errors were mainly due to noun phrases that were not modeled in our method, such as noun phrases that include a relative clause.", "labels": [], "entities": [{"text": "Errors", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9275590777397156}]}, {"text": "As explained in Section 4.2, in our system the points at issue are arranged in a two-dimensional space.", "labels": [], "entities": []}, {"text": "The x and y axes correspond to the polarity and the importance of points at issue, respectively.", "labels": [], "entities": []}, {"text": "Because it is difficult for the assessors to judge the correctness of coordinate values in the twodimensional space, we evaluated the effectiveness of arranging points at issue indirectly.", "labels": [], "entities": []}, {"text": "First, we evaluated the effectiveness of the calculation for the y-axis.", "labels": [], "entities": []}, {"text": "We sorted the points at issue, which were extracted automatically (see Section 5.2), according to their importance.", "labels": [], "entities": []}, {"text": "We evaluated the trade-off between recall and precision by varying the threshold of y A . We discarded the points at issue whose y A is below the threshold.", "labels": [], "entities": [{"text": "recall", "start_pos": 35, "end_pos": 41, "type": "METRIC", "confidence": 0.9988048076629639}, {"text": "precision", "start_pos": 46, "end_pos": 55, "type": "METRIC", "confidence": 0.9970701932907104}]}, {"text": "Note that while this threshold was used to determine the lower bound of y A , the threshold explained in Section 4.2 (i.e., 0.02) was used to determine the upper bound of y A and was used consistently irrespective of the lower bound threshold.", "labels": [], "entities": []}, {"text": "shows the results, in which the precision was improved to 50% by increasing the threshold.", "labels": [], "entities": [{"text": "precision", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9998407363891602}]}, {"text": "In, users can change the threshold of importance by using the panel on the right side to control the number of points at issue presented in the interface.", "labels": [], "entities": []}, {"text": "As a result, users can choose appropriate points at issue precisely.", "labels": [], "entities": []}, {"text": "Second, we evaluated the effectiveness of the calculation for the x-axis.", "labels": [], "entities": []}, {"text": "We evaluated the effectiveness of our method in a binary classification.", "labels": [], "entities": []}, {"text": "For each point at issue extracted by an assessor, the assessor judged which of the two standpoints the point supports.", "labels": [], "entities": []}, {"text": "If a point at issue whose x-coordinate calculated by our method is positive (or negative), it was classified as pro (or con) automatically.", "labels": [], "entities": []}, {"text": "We did not use the points at issue whose x-coordinate was zero for evaluation purposes.", "labels": [], "entities": []}, {"text": "While the number of target points at issue was different depending on the topic and the assessor, the difference in classification accuracy was marginal.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 131, "end_pos": 139, "type": "METRIC", "confidence": 0.9328594207763672}]}, {"text": "For each topic, we averaged the accuracy determined by each assessor and averaged the accuracies over the topic, which gave 95.6%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9992513060569763}, {"text": "accuracies", "start_pos": 86, "end_pos": 96, "type": "METRIC", "confidence": 0.988507866859436}]}, {"text": "Overall, our method performs the binary classification for points at issue with a high accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.9977286458015442}]}, {"text": "Errors were mainly due to opinions that included arguments for both standpoints.", "labels": [], "entities": [{"text": "Errors", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9288873672485352}]}, {"text": "For example, a person supporting a standpoint might suggest that he/she would support the other side under a specific condition.", "labels": [], "entities": []}, {"text": "Points at issue classified incorrectly had usually been extracted from such contradictory opinions.", "labels": [], "entities": []}, {"text": "To evaluate the effectiveness of our method in ranking opinions on a point-by-point basis, we used a method that sorts the opinions randomly as a control.", "labels": [], "entities": []}, {"text": "We compared the accuracy of our method and that of the control.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9997435212135315}]}, {"text": "The accuracy is the ratio of the number of correct answers to the number of opinions presented by the method under evaluation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9995911717414856}]}, {"text": "For each point at issue extracted by an assessor, the assessor assigned the opinions to one of the following degrees: \u2022 A: the opinion argues about the point at issue and is represented, \u2022 B: the opinion argues about the point at issue but is not represented, \u2022 C: the opinion includes the point at issue but does not argue about it.", "labels": [], "entities": []}, {"text": "We varied the number of top opinions presented by changing the threshold for the rank of opinions.", "labels": [], "entities": []}, {"text": "shows the results, in which N denotes the number of top opinions presented.", "labels": [], "entities": []}, {"text": "The column \"Answer\" refers to two cases: the casein which only the opinions assigned to \"A\" were regarded as correct answers, and the casein which the opinions assigned to \"A\" or \"B\" were regarded as correct answers.", "labels": [], "entities": []}, {"text": "In either case, our method outperformed the control in ranking accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9515366554260254}]}, {"text": "Although the accuracy of our method for \"A\" opinions was low, the accuracy for \"A\" and \"B\"   opinions was high.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9995385408401489}, {"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9992508292198181}]}, {"text": "This suggests that our method is effective in distinguishing opinions that argue about a specific point and opinions that include the point but do not argue about it.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Examples of points at issue and their co- ordinates for \"privatization of hospitals by joint- stock companies\".", "labels": [], "entities": []}, {"text": " Table 2: Topics used for experiments.", "labels": [], "entities": []}, {"text": " Table 3: Recall and precision of extracting points at issue (C: # of correct answers, R: recall (%), P:  precision (%)).", "labels": [], "entities": [{"text": "Recall", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9885410666465759}, {"text": "precision", "start_pos": 21, "end_pos": 30, "type": "METRIC", "confidence": 0.9993925094604492}, {"text": "recall", "start_pos": 90, "end_pos": 96, "type": "METRIC", "confidence": 0.9228348135948181}, {"text": "precision", "start_pos": 106, "end_pos": 115, "type": "METRIC", "confidence": 0.9753554463386536}]}, {"text": " Table 4: Trade-off between recall and precision in extracting points at issue.", "labels": [], "entities": [{"text": "recall", "start_pos": 28, "end_pos": 34, "type": "METRIC", "confidence": 0.9990922212600708}, {"text": "precision", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.9990712404251099}]}, {"text": " Table 5: Accuracy for classifying points at issue.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9975246787071228}]}, {"text": " Table 6: Accuracy of ranking opinions.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9952044486999512}]}]}