{"title": [{"text": "Automating Help-desk Responses: A Comparative Study of Information-gathering Approaches", "labels": [], "entities": [{"text": "Automating Help-desk Responses", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7763288219769796}]}], "abstractContent": [{"text": "We present a comparative study of corpus-based methods for the automatic synthesis of email responses to help-desk requests.", "labels": [], "entities": [{"text": "automatic synthesis of email responses to help-desk requests", "start_pos": 63, "end_pos": 123, "type": "TASK", "confidence": 0.7239903509616852}]}, {"text": "Our methods were developed by considering two operational dimensions: (1) information-gathering technique, and (2) granularity of the information.", "labels": [], "entities": []}, {"text": "In particular , we investigate two techniques-retrieval and prediction-applied to information represented at two levels of granu-larity-sentence-level and document level.", "labels": [], "entities": []}, {"text": "We also developed a hybrid method that combines prediction with retrieval.", "labels": [], "entities": []}, {"text": "Our results show that the different approaches are applicable in different situations, addressing a combined 72% of the requests with either complete or partial responses.", "labels": [], "entities": []}], "introductionContent": [{"text": "Email inquiries sent to help desks often \"revolve around a small set of common questions and issues\".", "labels": [], "entities": [{"text": "Email inquiries sent to help desks", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.9039392669995626}]}, {"text": "1 This means that help-desk operators spend most of their time dealing with problems that have been previously addressed.", "labels": [], "entities": []}, {"text": "Further, a significant proportion of help-desk responses contain a low level of technical content, corresponding, for example, to inquires addressed to the wrong group, or insufficient detail provided by the customer about his or her problem.", "labels": [], "entities": []}, {"text": "Organizations and clients would benefit if the efforts of human operators were focused on difficult, atypical problems, and an automated process was employed to deal with the easier problems.", "labels": [], "entities": []}, {"text": "In this paper, we report on our experiments with corpus-based approaches to the automation of help-desk responses.", "labels": [], "entities": []}, {"text": "Our study is based on a corpus of 30,000 email dialogues between users and help-desk operators at Hewlett-Packard.", "labels": [], "entities": []}, {"text": "These dialogues deal with a variety of user requests, which include requests for technical assistance, inquiries about products, and queries about how to return faulty products or parts.", "labels": [], "entities": []}, {"text": "In order to restrict the scope of our study, we considered two-turn short dialogues, comprising a request followed by an answer, where the answer has at most 15 lines.", "labels": [], "entities": []}, {"text": "This yields a sub-corpus of 6659 dialogues.", "labels": [], "entities": []}, {"text": "As a first step, we have automatically clustered the corpus according to the subject line of the first email.", "labels": [], "entities": []}, {"text": "This process yielded 15 topic-based datasets that contain between 135 and 1200 email dialogues.", "labels": [], "entities": []}, {"text": "Owing to time limitations, the procedures described in this paper were applied to 8 of the datasets, corresponding to approximately 75% of the dialogues.", "labels": [], "entities": []}, {"text": "Analysis of our corpus yields the following observations.", "labels": [], "entities": []}, {"text": "\u2022 O1: Requests containing precise information, such as product names or part specifications, sometimes elicit helpful, precise answers referring to this information, while other times they elicit answers that do not refer to the query terms, but contain generic information (e.g., referring customers to another help group or asking them to calla particular phone number).", "labels": [], "entities": [{"text": "O1", "start_pos": 2, "end_pos": 4, "type": "METRIC", "confidence": 0.8982802629470825}]}, {"text": "Request-answer pair RA1 in illustrates the first situation, while the pair RA2 illustrates the second.", "labels": [], "entities": [{"text": "Request-answer pair RA1", "start_pos": 0, "end_pos": 23, "type": "METRIC", "confidence": 0.647833784421285}]}], "datasetContent": [{"text": "As mentioned in Section 1, our corpus was divided into topic-based datasets.", "labels": [], "entities": []}, {"text": "We have observed that the different datasets lend themselves differently to the various information-gathering methods described in the previous section.", "labels": [], "entities": []}, {"text": "In this section, we examine the overall performance of the five methods across the corpus, as well as their performance for different datasets.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance of the different methods, measured as coverage, precision and f-score.", "labels": [], "entities": [{"text": "coverage", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9991794228553772}, {"text": "precision", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.9996531009674072}, {"text": "f-score", "start_pos": 84, "end_pos": 91, "type": "METRIC", "confidence": 0.9870200157165527}]}]}