{"title": [{"text": "N -Gram Posterior Probabilities for Statistical Machine Translation", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 36, "end_pos": 67, "type": "TASK", "confidence": 0.8608858585357666}]}], "abstractContent": [{"text": "Word posterior probabilities area common approach for confidence estimation in automatic speech recognition and machine translation.", "labels": [], "entities": [{"text": "confidence estimation", "start_pos": 54, "end_pos": 75, "type": "TASK", "confidence": 0.7300778031349182}, {"text": "automatic speech recognition", "start_pos": 79, "end_pos": 107, "type": "TASK", "confidence": 0.6374972065289816}, {"text": "machine translation", "start_pos": 112, "end_pos": 131, "type": "TASK", "confidence": 0.7508092224597931}]}, {"text": "We will generalize this idea and introduce n-gram posterior probabilities and show how these can be used to improve translation quality.", "labels": [], "entities": [{"text": "translation", "start_pos": 116, "end_pos": 127, "type": "TASK", "confidence": 0.9635522961616516}]}, {"text": "Additionally , we will introduce a sentence length model based on posterior probabilities.", "labels": [], "entities": []}, {"text": "We will show significant improvements on the Chinese-English NIST task.", "labels": [], "entities": [{"text": "NIST task", "start_pos": 61, "end_pos": 70, "type": "TASK", "confidence": 0.5467933565378189}]}, {"text": "The absolute improvements of the BLEU score is between 1.1% and 1.6%.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 33, "end_pos": 43, "type": "METRIC", "confidence": 0.964971661567688}]}], "introductionContent": [{"text": "The use of word posterior probabilities is a common approach for confidence estimation in automatic speech recognition, e.g. see.", "labels": [], "entities": [{"text": "automatic speech recognition", "start_pos": 90, "end_pos": 118, "type": "TASK", "confidence": 0.6076813538869222}]}, {"text": "This idea has been adopted to estimate confidences for machine translation, e.g. see ().", "labels": [], "entities": [{"text": "machine translation", "start_pos": 55, "end_pos": 74, "type": "TASK", "confidence": 0.7920253276824951}]}, {"text": "These confidence measures were used in the computer assisted translation (CAT) framework, e.g. ( . The (simplified) idea is that the confidence measure is used to decide if the machinegenerated prediction should be suggested to the human translator or not.", "labels": [], "entities": [{"text": "computer assisted translation (CAT)", "start_pos": 43, "end_pos": 78, "type": "TASK", "confidence": 0.8356573780377706}]}, {"text": "There is only few work on how to improve machine translation performance using confidence measures.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 41, "end_pos": 60, "type": "TASK", "confidence": 0.8292581140995026}]}, {"text": "The only work, we are aware of, is).", "labels": [], "entities": []}, {"text": "The outcome was that the confidence measures did not result in improvements of the translation quality measured with the BLEU and NIST scores.", "labels": [], "entities": [{"text": "translation", "start_pos": 83, "end_pos": 94, "type": "TASK", "confidence": 0.9471547603607178}, {"text": "BLEU", "start_pos": 121, "end_pos": 125, "type": "METRIC", "confidence": 0.9919956922531128}, {"text": "NIST scores", "start_pos": 130, "end_pos": 141, "type": "DATASET", "confidence": 0.9103206992149353}]}, {"text": "Here, we focus on how the ideas and methods commonly used for confidence estimation can be adapted and/or extended to improve translation quality.", "labels": [], "entities": [{"text": "confidence estimation", "start_pos": 62, "end_pos": 83, "type": "TASK", "confidence": 0.7236124873161316}]}, {"text": "So far, always word-level posterior probabilities were used.", "labels": [], "entities": []}, {"text": "Here, we will generalize this idea to ngrams.", "labels": [], "entities": []}, {"text": "In addition to the n-gram posterior probabilities, we introduce a sentence-length model based on posterior probabilities.", "labels": [], "entities": []}, {"text": "The common phrasebased translation systems, such as (), do not use an explicit sentence length model.", "labels": [], "entities": [{"text": "phrasebased translation", "start_pos": 11, "end_pos": 34, "type": "TASK", "confidence": 0.7171282470226288}]}, {"text": "Only the simple word penalty goes into that direction.", "labels": [], "entities": []}, {"text": "It can be adjusted to prefer longer or shorter translations.", "labels": [], "entities": []}, {"text": "Here, we will explicitly model the sentence length.", "labels": [], "entities": []}, {"text": "The novel contributions of this work are to introduce n-gram posterior probabilities and sentence length posterior probabilities.", "labels": [], "entities": []}, {"text": "Using these methods, we achieve significant improvements of translation quality.", "labels": [], "entities": [{"text": "translation", "start_pos": 60, "end_pos": 71, "type": "TASK", "confidence": 0.9635303616523743}]}, {"text": "The remaining part of this paper is structured as follows: first, we will briefly describe the baseline system, which is a state-of-the-art phrase-based statistical machine translation system.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 153, "end_pos": 184, "type": "TASK", "confidence": 0.6186669170856476}]}, {"text": "Then, in Section 3, we will introduce the n-gram posterior probabilities.", "labels": [], "entities": []}, {"text": "In Section 4, we will define the sentence length model.", "labels": [], "entities": []}, {"text": "Afterwards, in Section 5, we will describe how these novel models can be used for rescoring/reranking.", "labels": [], "entities": []}, {"text": "The experimental results will be presented in Section 6.", "labels": [], "entities": []}, {"text": "Future applications will be described in Section 7.", "labels": [], "entities": []}, {"text": "Finally, we will conclude in Section 8.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Chinese-English NIST task: corpus statis- tics for the bilingual training data and the NIST eval- uation sets of the years 2002 to 2005.", "labels": [], "entities": [{"text": "NIST eval- uation sets", "start_pos": 97, "end_pos": 119, "type": "DATASET", "confidence": 0.7234102725982666}]}, {"text": " Table 2: Case-sensitive translation results for several evaluation sets of the Chinese-English NIST task.  Evaluation set  2002 (dev)  2003  2004  2005  System  NIST BLEU[%] NIST BLEU[%] NIST BLEU[%] NIST BLEU[%]  Baseline  8.49  30.5  8.04  29.5  8.14  29.0  8.01  28.2  + 1-grams  8.51  30.5  8.08  29.5  8.17  29.0  8.03  28.2  + 2-grams  8.47  30.8  8.03  29.7  8.12  29.2  7.98  28.1  + 3-grams  8.73  31.6  8.25  30.1  8.45  30.0  8.20  28.6  + 4-grams  8.74  31.7  8.26  30.1  8.47  30.1  8.20  28.6  + length  8.87  32.0  8.42  30.9  8.60  30.6  8.34  29.3", "labels": [], "entities": [{"text": "BLEU", "start_pos": 167, "end_pos": 171, "type": "METRIC", "confidence": 0.8861556649208069}, {"text": "NIST", "start_pos": 175, "end_pos": 179, "type": "DATASET", "confidence": 0.6980606913566589}, {"text": "BLEU", "start_pos": 180, "end_pos": 184, "type": "METRIC", "confidence": 0.6246204972267151}, {"text": "NIST", "start_pos": 188, "end_pos": 192, "type": "DATASET", "confidence": 0.5641745924949646}, {"text": "BLEU", "start_pos": 193, "end_pos": 197, "type": "METRIC", "confidence": 0.6398423314094543}, {"text": "NIST", "start_pos": 201, "end_pos": 205, "type": "DATASET", "confidence": 0.7911631464958191}, {"text": "BLEU", "start_pos": 206, "end_pos": 210, "type": "METRIC", "confidence": 0.6541320085525513}]}, {"text": " Table 3: Translation examples for the Chinese-English NIST task.  Baseline", "labels": [], "entities": []}]}