{"title": [{"text": "Generative Content Models for Structural Analysis of Medical Abstracts", "labels": [], "entities": [{"text": "Structural Analysis of Medical Abstracts", "start_pos": 30, "end_pos": 70, "type": "TASK", "confidence": 0.9298790454864502}]}], "abstractContent": [{"text": "The ability to accurately model the content structure of text is important for many natural language processing applications.", "labels": [], "entities": []}, {"text": "This paper describes experiments with generative models for analyzing the discourse structure of medical abstracts , which generally follow the pattern of \"introduction\", \"methods\", \"results\", and \"conclusions\".", "labels": [], "entities": []}, {"text": "We demonstrate that Hidden Markov Models are capable of accurately capturing the structure of such texts, and can achieve classification accuracy comparable to that of discrimina-tive techniques.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 137, "end_pos": 145, "type": "METRIC", "confidence": 0.9379292130470276}]}, {"text": "In addition, generative approaches provide advantages that may make them preferable to discriminative techniques such as Support Vector Machines under certain conditions.", "labels": [], "entities": [{"text": "generative", "start_pos": 13, "end_pos": 23, "type": "TASK", "confidence": 0.9647685885429382}]}, {"text": "Our work makes two contributions: at the application level, we report good performance on an interesting task in an important domain ; more generally, our results contribute to an ongoing discussion regarding the tradeoffs between generative and dis-criminative techniques.", "labels": [], "entities": []}], "introductionContent": [{"text": "Certain types of text follow a predictable structure, the knowledge of which would be useful in many natural language processing applications.", "labels": [], "entities": []}, {"text": "As an example, scientific abstracts across many different fields generally follow the pattern of \"introduction\", \"methods\", \"results\", and \"conclusions\").", "labels": [], "entities": []}, {"text": "The ability to explicitly identify these sections in unstructured text could play an important role in applications such as document summarization), information retrieval (), information extraction (), and question answering.", "labels": [], "entities": [{"text": "document summarization", "start_pos": 124, "end_pos": 146, "type": "TASK", "confidence": 0.6674817502498627}, {"text": "information retrieval", "start_pos": 149, "end_pos": 170, "type": "TASK", "confidence": 0.8101957440376282}, {"text": "information extraction", "start_pos": 175, "end_pos": 197, "type": "TASK", "confidence": 0.8383912444114685}, {"text": "question answering", "start_pos": 206, "end_pos": 224, "type": "TASK", "confidence": 0.9249641001224518}]}, {"text": "Although there is a trend towards analysis of full article texts, we believe that abstracts still provide a tremendous amount of information, and much value can still be extracted from them.", "labels": [], "entities": []}, {"text": "For example, experimented with abstracts and full article texts in the task of automatically generating index term recommendations and discovered that using full article texts yields at most a 7.4% improvement in F-score.", "labels": [], "entities": [{"text": "F-score", "start_pos": 213, "end_pos": 220, "type": "METRIC", "confidence": 0.9988647699356079}]}, {"text": "found a correlation between the quality and strength of clinical conclusions in the full article texts and abstracts.", "labels": [], "entities": [{"text": "quality", "start_pos": 32, "end_pos": 39, "type": "METRIC", "confidence": 0.9597598314285278}]}, {"text": "This paper presents experiments with generative content models for analyzing the discourse structure of medical abstracts, which has been confirmed to follow the four-section pattern discussed above).", "labels": [], "entities": [{"text": "generative content", "start_pos": 37, "end_pos": 55, "type": "TASK", "confidence": 0.9019288122653961}]}, {"text": "For a variety of reasons, medicine is an interesting domain of research.", "labels": [], "entities": []}, {"text": "The need for information systems to support physicians at the point of care has been well studied).", "labels": [], "entities": []}, {"text": "Retrieval techniques can have a large impact on how physicians access and leverage clinical evidence.", "labels": [], "entities": []}, {"text": "Information that satisfies physicians' needs can be found in the MEDLINE database maintained by the U.S. National Library of Medicine (NLM), which also serves as a readily available corpus of abstracts for our experiments.", "labels": [], "entities": [{"text": "MEDLINE database", "start_pos": 65, "end_pos": 81, "type": "DATASET", "confidence": 0.813390851020813}, {"text": "U.S. National Library of Medicine (NLM)", "start_pos": 100, "end_pos": 139, "type": "DATASET", "confidence": 0.6043173931539059}]}, {"text": "Furthermore, the availability of rich ontological resources, in the form of the Unified Medical Language System (UMLS) (, and the availability of software that leverages this knowledgeMetaMap) for concept identification and SemRep ( for relation extraction-provide a foundation for studying the role of semantics in various tasks.", "labels": [], "entities": [{"text": "concept identification", "start_pos": 197, "end_pos": 219, "type": "TASK", "confidence": 0.776745080947876}, {"text": "relation extraction-provide", "start_pos": 237, "end_pos": 264, "type": "TASK", "confidence": 0.7833008468151093}]}, {"text": "have previously examined the task of categorizing sentences in medical abstracts using supervised discriminative machine learning techniques.", "labels": [], "entities": []}, {"text": "Building on the work of in the same domain, we present a generative approach that attempts to directly model the discourse structure of MEDLINE abstracts using Hidden Markov Models (HMMs); cf. ().", "labels": [], "entities": []}, {"text": "Although our results were not obtained from the same exact collection as those used by authors of these two previous studies, comparable experiments suggest that our techniques are competitive in terms of performance, and may offer additional advantages as well.", "labels": [], "entities": []}, {"text": "Discriminative approaches (especially SVMs) have been shown to be very effective for many supervised classification tasks; see, for example,).", "labels": [], "entities": [{"text": "supervised classification tasks", "start_pos": 90, "end_pos": 121, "type": "TASK", "confidence": 0.7205833395322164}]}, {"text": "However, their high computational complexity (quadratic in the number of training samples) renders them prohibitive for massive data processing.", "labels": [], "entities": []}, {"text": "Under certain conditions, generative approaches with linear complexity are preferable, even if their performance is lower than that which can be achieved through discriminative training.", "labels": [], "entities": []}, {"text": "Since HMMs are very wellsuited to modeling sequences, our discourse modeling task lends itself naturally to this particular generative approach.", "labels": [], "entities": [{"text": "discourse modeling", "start_pos": 58, "end_pos": 76, "type": "TASK", "confidence": 0.735032707452774}]}, {"text": "In fact, we demonstrate that HMMs are competitive with SVMs, with the added advantage of lower computational complexity.", "labels": [], "entities": []}, {"text": "In addition, generative models can be directly applied to tackle certain classes of problems, such as sentence ordering, in ways that discriminative approaches cannot readily.", "labels": [], "entities": [{"text": "sentence ordering", "start_pos": 102, "end_pos": 119, "type": "TASK", "confidence": 0.7201077491044998}]}, {"text": "In the context of machine learning, we see our work as contributing to the ongoing debate between generative and discriminative approacheswe provide a case study in an interesting domain that begins to explore some of these tradeoffs.", "labels": [], "entities": [{"text": "generative and discriminative", "start_pos": 98, "end_pos": 127, "type": "TASK", "confidence": 0.8403703967730204}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Ten-fold cross-validation results on all  structured abstracts from the TREC 2004 MED- LINE corpus: multi-way classification on complete  abstract structure (a) and by-section binary classifi- cation (b).", "labels": [], "entities": [{"text": "TREC 2004 MED- LINE corpus", "start_pos": 82, "end_pos": 108, "type": "DATASET", "confidence": 0.8912935654322306}]}, {"text": " Table 2: Ten-fold cross-validation results on the structured RCT subset of the TREC 2004 MEDLINE  corpus: multi-way classification (a) and binary classification (b). Table (b) also reproduces the results from  McKnight and Srinivasan (2003) for a comparable task on a different RCT-subset of structured abstracts.", "labels": [], "entities": [{"text": "TREC 2004 MEDLINE  corpus", "start_pos": 80, "end_pos": 105, "type": "DATASET", "confidence": 0.853981152176857}]}, {"text": " Table 3: Training on the structured RCT subset of the TREC 2004 MEDLINE corpus, testing on corpus of  hand-annotated abstracts: multi-way classification (a) and binary classification (b). Unstructured abstracts  with all four sections (complete), and with missing sections (partial) are shown. Table (b) again repro- duces the results from McKnight and Srinivasan (2003) for a comparable task on a different subset of 206  unstructured abstracts.", "labels": [], "entities": [{"text": "RCT subset of the TREC 2004 MEDLINE corpus", "start_pos": 37, "end_pos": 79, "type": "DATASET", "confidence": 0.7706614062190056}]}]}