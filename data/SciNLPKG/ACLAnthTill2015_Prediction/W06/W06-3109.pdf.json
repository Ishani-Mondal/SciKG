{"title": [{"text": "Generalized Stack Decoding Algorithms for Statistical Machine Translation *", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 42, "end_pos": 73, "type": "TASK", "confidence": 0.851860503355662}]}], "abstractContent": [{"text": "In this paper we propose a generalization of the Stack-based decoding paradigm for Statistical Machine Translation.", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 83, "end_pos": 114, "type": "TASK", "confidence": 0.8652776678403219}]}, {"text": "The well known single and multi-stack decoding algorithms defined in the literature have been integrated within anew formalism which also defines anew family of stack-based decoders.", "labels": [], "entities": []}, {"text": "These decoders allows a tradeoff to be made between the advantages of using only one or multiple stacks.", "labels": [], "entities": []}, {"text": "The key point of the new formalism consists in parameterizeing the number of stacks to be used during the decoding process, and providing an efficient method to decide in which stack each partial hypothesis generated is to be inserted-during the search process.", "labels": [], "entities": []}, {"text": "Experimental results are also reported fora search algorithm for phrase-based statistical translation models.", "labels": [], "entities": [{"text": "phrase-based statistical translation", "start_pos": 65, "end_pos": 101, "type": "TASK", "confidence": 0.6872599224249522}]}], "introductionContent": [{"text": "The translation process can be formulated from a statistical point of view as follows: A source language string f J 1 = f 1 . .", "labels": [], "entities": [{"text": "translation", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.9607954621315002}]}, {"text": "f J is to be translated into a target language string e I 1 = e 1 . .", "labels": [], "entities": []}, {"text": "e I . Every target string is regarded as a possible translation for the source language string with maximum a-posteriori probability P r(e I 1 |f J 1 ).", "labels": [], "entities": [{"text": "a-posteriori probability P r", "start_pos": 108, "end_pos": 136, "type": "METRIC", "confidence": 0.8489406555891037}]}, {"text": "The equation that models this process is: The search/decoding problem in SMT consists in solving the maximization problem stated in Eq.", "labels": [], "entities": [{"text": "SMT", "start_pos": 73, "end_pos": 76, "type": "TASK", "confidence": 0.989279568195343}]}, {"text": "In the literature, we can find different techniques to deal with this problem, ranging from heuristic and fast (as greedy decoders) to optimal and very slow decoding algorithms ().", "labels": [], "entities": []}, {"text": "Also, under certain circumstances, stack-based decoders can obtain optimal solutions.", "labels": [], "entities": []}, {"text": "Many works) have adopted different types of stack-based algorithms to solve the global search optimization problem for statistical machine translation.", "labels": [], "entities": [{"text": "global search optimization", "start_pos": 80, "end_pos": 106, "type": "TASK", "confidence": 0.6908876299858093}, {"text": "statistical machine translation", "start_pos": 119, "end_pos": 150, "type": "TASK", "confidence": 0.7045509517192841}]}, {"text": "All these works follow two main different approaches according to the number of stacks used in the design and implementation of the search algorithm (the stacks are used to store partial hypotheses, sorted according to their partial score/probability, during the search process) : \u2022 On the one hand, in () a single stack is used.", "labels": [], "entities": []}, {"text": "In that case, in order to make the search feasible, the pruning of the number of partial hypotheses stored in the stack is needed.", "labels": [], "entities": []}, {"text": "This causes many search errors due to the fact that hypotheses covering a different number of source (translated) words compete in the same conditions.", "labels": [], "entities": []}, {"text": "Therefore, the greater number of covered words the higher possibility to be pruned.", "labels": [], "entities": []}, {"text": "\u2022 On the other hand () make use of multiple stacks (one for each set of source covered/translated words in the partial hypothesis) in order to solve the disadvantages of the single-stack approach.", "labels": [], "entities": []}, {"text": "By contrast, the problem of finding the best hypothesis to be expanded introduces an exponential term in the computational complexity of the algorithm.", "labels": [], "entities": []}, {"text": "In) the authors present an empirical comparison (about efficiency and translation quality) of the two approaches paying special attention to the advantages and disadvantages of the two approaches.", "labels": [], "entities": []}, {"text": "In this paper we present anew formalism consisting of a generalization of the classical stack-based decoding paradigm for SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 122, "end_pos": 125, "type": "TASK", "confidence": 0.9887823462486267}]}, {"text": "This new formalism defines anew family of stack-based decoders, which also integrates the well known stack-based decoding algorithms proposed so far within the framework of SMT, that is single and multi-stack decoders.", "labels": [], "entities": [{"text": "SMT", "start_pos": 173, "end_pos": 176, "type": "TASK", "confidence": 0.9768683910369873}]}, {"text": "The rest of the paper is organized as follows: in section 2 the phrase-based approach to SMT is depicted; in section 3 the main features of classical stack-based decoders are presented; in section 4 the new formalism is presented and in section 5 experimental results are shown; finally some conclusions are drawn in section 6.", "labels": [], "entities": [{"text": "SMT", "start_pos": 89, "end_pos": 92, "type": "TASK", "confidence": 0.9926964044570923}]}], "datasetContent": [{"text": "In this section, experimental results are presented for two well-known tasks: the EUTRANS-I (), a small size and easy translation task, and the XEROX (), a medium size and difficult translation task.", "labels": [], "entities": [{"text": "EUTRANS-I", "start_pos": 82, "end_pos": 91, "type": "DATASET", "confidence": 0.8406499624252319}, {"text": "XEROX", "start_pos": 144, "end_pos": 149, "type": "METRIC", "confidence": 0.964813768863678}]}, {"text": "The main statistics of these corpora are shown in.", "labels": [], "entities": []}, {"text": "The translation results were obtained using a non-monotone generalized stack algorithm.", "labels": [], "entities": [{"text": "translation", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.9603534936904907}]}, {"text": "For both tasks, the training of the different phrase models was carried out using the publicly available Thot toolkit ().", "labels": [], "entities": []}, {"text": "Different translation experiments have been carried out, varying the value of G (ranging from 0 to 8) and the maximum number of hypothesis that the algorithm is allow to store for all used stacks (S) (ranging from 2 8 to 2 12 ).", "labels": [], "entities": []}, {"text": "In these experiments the following statistics are computed: the average score (or logProb) that the phrase-based translation model assigns to each hypothesis, the translation quality (by means of WER and Bleu measures), and the average time (in secs.) per sentence 3 . In Figures 4 and 5 two plots are shown: the average time per sentence (left) and the average score (right), for EUTRANS and XEROX corpora respectively.", "labels": [], "entities": [{"text": "WER", "start_pos": 196, "end_pos": 199, "type": "METRIC", "confidence": 0.9583555459976196}, {"text": "Bleu", "start_pos": 204, "end_pos": 208, "type": "METRIC", "confidence": 0.7732362151145935}, {"text": "EUTRANS", "start_pos": 381, "end_pos": 388, "type": "DATASET", "confidence": 0.9371594786643982}]}, {"text": "As can be seen in both figures, the bigger the value of G the lower the average time per sentence.", "labels": [], "entities": []}, {"text": "This is true up to the value of G = 6.", "labels": [], "entities": [{"text": "G", "start_pos": 32, "end_pos": 33, "type": "METRIC", "confidence": 0.9691071510314941}]}, {"text": "For higher values of G (keeping fixed the value of S) the average time per sentence increase slightly.", "labels": [], "entities": []}, {"text": "This is due to the fact that at this point the algorithm start to spend more time to decide which hypothesis is to be expanded.", "labels": [], "entities": []}, {"text": "With respect to the average score similar values are obtained up to the value of G = 4.", "labels": [], "entities": [{"text": "G", "start_pos": 81, "end_pos": 82, "type": "METRIC", "confidence": 0.9842211008071899}]}, {"text": "Higher values of G slightly decreases the average score.", "labels": [], "entities": [{"text": "G", "start_pos": 17, "end_pos": 18, "type": "METRIC", "confidence": 0.9921911358833313}, {"text": "average score", "start_pos": 42, "end_pos": 55, "type": "METRIC", "confidence": 0.9715003967285156}]}, {"text": "In this case, as G increases, the number of hypotheses per stack decreases, taking into account that the value of S is fixed, then the \"optimal\" hypothesis can easily be pruned.", "labels": [], "entities": []}, {"text": "In tables 3 and 4 detailed experiments are shown fora value of S = 2 12 and different values of G, for EUTRANS and XEROX corpora respectively.", "labels": [], "entities": [{"text": "G", "start_pos": 96, "end_pos": 97, "type": "METRIC", "confidence": 0.9828527569770813}, {"text": "EUTRANS", "start_pos": 103, "end_pos": 110, "type": "DATASET", "confidence": 0.8994371891021729}, {"text": "XEROX", "start_pos": 115, "end_pos": 120, "type": "METRIC", "confidence": 0.5945120453834534}]}, {"text": "According to the experiments presented here we can conclude that: \u2022 The results correlates for the two considered tasks: one small and easy, and other larger and difficult.", "labels": [], "entities": []}, {"text": "\u2022 The proposed generalized stack decoding paradigm can be used to make a tradeoff be-  tween the advantages of classical single and multi-stack decoding algorithms.", "labels": [], "entities": []}, {"text": "\u2022 As we expected, better results (regarding efficiency and accuracy) are obtained when using a value of G between 0 and J.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9992563128471375}]}], "tableCaptions": [{"text": " Table 1: Values returned by the \u00b5 1 and \u00b5 2 function  defined as a composition of the \u03b1 and \u03b2 functions", "labels": [], "entities": []}, {"text": " Table 2: EUTRANS-I and XEROX corpus statistics", "labels": [], "entities": [{"text": "EUTRANS-I", "start_pos": 10, "end_pos": 19, "type": "DATASET", "confidence": 0.8804072141647339}, {"text": "XEROX", "start_pos": 24, "end_pos": 29, "type": "METRIC", "confidence": 0.9382558465003967}]}, {"text": " Table 3: Translation experiments for EUTRANS cor- pus using a generalized stack algorithm with differ- ent values of G and a fixed value of S = 2 12", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9800533652305603}, {"text": "EUTRANS cor- pus", "start_pos": 38, "end_pos": 54, "type": "DATASET", "confidence": 0.773370698094368}]}, {"text": " Table 4: Translation experiments for XEROX cor- pus using a generalized stack algorithm with differ- ent values of G and a fixed value of S = 2 12", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9796684384346008}]}]}