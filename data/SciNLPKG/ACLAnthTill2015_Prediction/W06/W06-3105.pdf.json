{"title": [{"text": "Why Generative Phrase Models Underperform Surface Heuristics", "labels": [], "entities": []}], "abstractContent": [{"text": "We investigate why weights from generative models underperform heuristic estimates in phrase-based machine translation.", "labels": [], "entities": [{"text": "phrase-based machine translation", "start_pos": 86, "end_pos": 118, "type": "TASK", "confidence": 0.6425996720790863}]}, {"text": "We first propose a simple generative, phrase-based model and verify that its estimates are inferior to those given by surface statistics.", "labels": [], "entities": []}, {"text": "The performance gap stems primarily from the addition of a hidden segmentation variable , which increases the capacity for overfitting during maximum likelihood training with EM.", "labels": [], "entities": []}, {"text": "In particular, while word level models benefit greatly from re-estimation, phrase-level models do not: the crucial difference is that distinct word alignments cannot all be correct, while distinct segmentations can.", "labels": [], "entities": []}, {"text": "Alternate segmentations rather than alternate alignments compete, resulting in increased deter-minization of the phrase table, decreased generalization , and decreased final BLEU score.", "labels": [], "entities": [{"text": "final", "start_pos": 168, "end_pos": 173, "type": "METRIC", "confidence": 0.9234464764595032}, {"text": "BLEU score", "start_pos": 174, "end_pos": 184, "type": "METRIC", "confidence": 0.8859668970108032}]}, {"text": "We also show that interpolation of the two methods can result in a modest increase in BLEU score.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 86, "end_pos": 96, "type": "METRIC", "confidence": 0.9805416464805603}]}], "introductionContent": [{"text": "At the core of a phrase-based statistical machine translation system is a phrase table containing pairs of source and target language phrases, each weighted by a conditional translation probability.", "labels": [], "entities": [{"text": "phrase-based statistical machine translation", "start_pos": 17, "end_pos": 61, "type": "TASK", "confidence": 0.5676024779677391}]}, {"text": "showed that translation quality is very sensitive to how this table is extracted from the training data.", "labels": [], "entities": [{"text": "translation", "start_pos": 12, "end_pos": 23, "type": "TASK", "confidence": 0.9591284990310669}]}, {"text": "One particularly surprising result is that a simple heuristic extraction algorithm based on surface statistics of a word-aligned training set outperformed the phrase-based generative model proposed by.", "labels": [], "entities": [{"text": "heuristic extraction", "start_pos": 52, "end_pos": 72, "type": "TASK", "confidence": 0.7884384989738464}]}, {"text": "This result is surprising in light of the reverse situation for word-based statistical translation.", "labels": [], "entities": [{"text": "word-based statistical translation", "start_pos": 64, "end_pos": 98, "type": "TASK", "confidence": 0.6130814850330353}]}, {"text": "Specifically, in the task of word alignment, heuristic approaches such as the Dice coefficient consistently underperform their re-estimated counterparts, such as the IBM word alignment models (.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 29, "end_pos": 43, "type": "TASK", "confidence": 0.8289596140384674}, {"text": "IBM word alignment", "start_pos": 166, "end_pos": 184, "type": "TASK", "confidence": 0.6312603056430817}]}, {"text": "This well-known result is unsurprising: reestimation introduces an element of competition into the learning process.", "labels": [], "entities": []}, {"text": "The key virtue of competition in word alignment is that, to a first approximation, only one source word should generate each target word.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 33, "end_pos": 47, "type": "TASK", "confidence": 0.7769269347190857}]}, {"text": "If a good alignment fora word token is found, other plausible alignments are explained away and should be discounted as incorrect for that token.", "labels": [], "entities": []}, {"text": "As we show in this paper, this effect does not prevail for phrase-level alignments.", "labels": [], "entities": [{"text": "phrase-level alignments", "start_pos": 59, "end_pos": 82, "type": "TASK", "confidence": 0.7609120607376099}]}, {"text": "The central difference is that phrase-based models, such as the ones presented in section 2 or, contain an element of segmentation.", "labels": [], "entities": []}, {"text": "That is, they do not merely learn correspondences between phrases, but also segmentations of the source and target sentences.", "labels": [], "entities": []}, {"text": "However, while it is reasonable to suppose that if one alignment is right, others must be wrong, the situation is more complex for segmentations.", "labels": [], "entities": [{"text": "segmentations", "start_pos": 131, "end_pos": 144, "type": "TASK", "confidence": 0.9777841567993164}]}, {"text": "For example, if one segmentation subsumes another, they are not necessarily incompatible: both maybe equally valid.", "labels": [], "entities": []}, {"text": "While in some cases, such as idiomatic vs. literal translations, two segmentations maybe in true competition, we show that the most common result is for different segmentations to be recruited for different examples, overfitting the training data and overly determinizing the phrase translation estimates.", "labels": [], "entities": [{"text": "phrase translation", "start_pos": 276, "end_pos": 294, "type": "TASK", "confidence": 0.7019869238138199}]}, {"text": "In this work, we first define a novel (but not radical) generative phrase-based model analogous to IBM Model 3.", "labels": [], "entities": []}, {"text": "While its exact training is intractable, we describe a training regime which uses wordlevel alignments to constrain the space of feasible segmentations down to a manageable number.", "labels": [], "entities": []}, {"text": "We demonstrate that the phrase analogue of the Dice coefficient is superior to our generative model (a result also echoing previous work).", "labels": [], "entities": [{"text": "generative", "start_pos": 83, "end_pos": 93, "type": "TASK", "confidence": 0.9620428681373596}]}, {"text": "In the primary contribution of the paper, we present a series of experiments designed to elucidate what re-estimation learns in this context.", "labels": [], "entities": []}, {"text": "We show that estimates are overly determinized because segmentations are used in unintuitive ways for the sake of data likelihood.", "labels": [], "entities": []}, {"text": "We comment on both the beneficial instances of segment competition (idioms) as well as the harmful ones (most everything else).", "labels": [], "entities": []}, {"text": "Finally, we demonstrate that interpolation of the two estimates can provide a modest increase in BLEU score over the heuristic baseline.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 97, "end_pos": 107, "type": "METRIC", "confidence": 0.9807323515415192}]}], "datasetContent": [{"text": "The generative model defined below is evaluated based on the BLEU score it produces in an endto-end machine translation system from English to French.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 61, "end_pos": 65, "type": "METRIC", "confidence": 0.9987379908561707}, {"text": "endto-end machine translation", "start_pos": 90, "end_pos": 119, "type": "TASK", "confidence": 0.657040516535441}]}, {"text": "The top-performing diag-and extraction heuristic () serves as the baseline for evaluation.", "labels": [], "entities": [{"text": "diag-and extraction heuristic", "start_pos": 19, "end_pos": 48, "type": "TASK", "confidence": 0.7650761206944784}]}, {"text": "1 Each approach -the generative model and heuristic baseline -produces an estimated conditional distribution of English phrases given French phrases.", "labels": [], "entities": []}, {"text": "We will refer to the distribution derived from the baseline heuristic as \u03c6 H . The distribution learned via the generative model, denoted \u03c6 EM , is described in detail below.", "labels": [], "entities": []}, {"text": "To test the relative performance of \u03c6 EM and \u03c6 H , we evaluated each using an end-to-end translation system from English to French.", "labels": [], "entities": []}, {"text": "We chose this nonstandard translation direction so that the examples in this paper would be more accessible to a primarily English-speaking audience.", "labels": [], "entities": []}, {"text": "All training and test data were drawn from the French/English section of the Europarl sentence-aligned corpus.", "labels": [], "entities": [{"text": "Europarl sentence-aligned corpus", "start_pos": 77, "end_pos": 109, "type": "DATASET", "confidence": 0.9225908716519674}]}, {"text": "We tested on the first 1,000 unique sentences of length 5 to 15 in the corpus and trained on sentences of length 1 to 60 starting after the first 10,000.", "labels": [], "entities": []}, {"text": "The system follows the structure proposed in the documentation for the Pharaoh decoder and uses many publicly available components).", "labels": [], "entities": [{"text": "Pharaoh decoder", "start_pos": 71, "end_pos": 86, "type": "DATASET", "confidence": 0.830764502286911}]}, {"text": "The language model was generated from the Europarl corpus using the SRI Language Modeling Toolkit).", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 42, "end_pos": 57, "type": "DATASET", "confidence": 0.9942192733287811}, {"text": "SRI Language Modeling Toolkit", "start_pos": 68, "end_pos": 97, "type": "DATASET", "confidence": 0.8006459772586823}]}, {"text": "Pharaoh performed decoding using a set of default parameters for weighting the relative influence of the language, translation and distortion models.", "labels": [], "entities": []}, {"text": "A maximum phrase length of three was used for all experiments.", "labels": [], "entities": []}, {"text": "To properly compare \u03c6 EM to \u03c6 H , all aspects of the translation pipeline were held constant except for the parameters of the phrase translation table.", "labels": [], "entities": [{"text": "phrase translation", "start_pos": 126, "end_pos": 144, "type": "TASK", "confidence": 0.6798817813396454}]}, {"text": "In particular, we did not tune the decoding hyperparameters for the different phrase tables.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: BLEU results for 25k training sentences.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.998075008392334}]}]}