{"title": [{"text": "Data Selection in Semi-supervised Learning for Name Tagging", "labels": [], "entities": [{"text": "Data Selection", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.6670608371496201}, {"text": "Name Tagging", "start_pos": 47, "end_pos": 59, "type": "TASK", "confidence": 0.7708206474781036}]}], "abstractContent": [{"text": "We present two semi-supervised learning techniques to improve a state-of-the-art multilingual name tagger.", "labels": [], "entities": [{"text": "multilingual name tagger", "start_pos": 81, "end_pos": 105, "type": "TASK", "confidence": 0.6384230852127075}]}, {"text": "For English and Chinese, the overall system obtains 1.7%-2.1% improvement in F-measure, representing a 13.5%-17.4% relative reduction in the spurious, missing, and incorrect tags.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 77, "end_pos": 86, "type": "METRIC", "confidence": 0.9948807954788208}]}, {"text": "We also conclude that simply relying upon large corpora is not in itself sufficient: we must pay attention to unlabeled data selection too.", "labels": [], "entities": []}, {"text": "We describe effective measures to automatically select documents and sentences.", "labels": [], "entities": []}], "introductionContent": [{"text": "When applying machine learning approaches to natural language processing tasks, it is timeconsuming and expensive to hand-label the large amounts of training data necessary for good performance.", "labels": [], "entities": []}, {"text": "Unlabeled data can be collected in much larger quantities.", "labels": [], "entities": []}, {"text": "Therefore, a natural question is whether we can use unlabeled data to build a more accurate learner, given the same amount of labeled data.", "labels": [], "entities": []}, {"text": "This problem is often referred to as semi-supervised learning.", "labels": [], "entities": []}, {"text": "It significantly reduces the effort needed to develop a training set.", "labels": [], "entities": []}, {"text": "It has shown promise in improving the performance of many tasks such as name tagging (), semantic class extraction (, chunking (Ando and), coreference resolution () and text classification.", "labels": [], "entities": [{"text": "name tagging", "start_pos": 72, "end_pos": 84, "type": "TASK", "confidence": 0.8244732022285461}, {"text": "semantic class extraction", "start_pos": 89, "end_pos": 114, "type": "TASK", "confidence": 0.727283239364624}, {"text": "coreference resolution", "start_pos": 139, "end_pos": 161, "type": "TASK", "confidence": 0.9482975006103516}, {"text": "text classification", "start_pos": 169, "end_pos": 188, "type": "TASK", "confidence": 0.8316237330436707}]}, {"text": "However, it is not clear, when semi-supervised learning is applied to improve a learner, how the system should effectively select unlabeled data, and how the size and relevance of data impact the performance.", "labels": [], "entities": []}, {"text": "In this paper we apply two semi-supervised learning algorithms to improve a state-of-the-art name tagger.", "labels": [], "entities": [{"text": "name tagger", "start_pos": 93, "end_pos": 104, "type": "TASK", "confidence": 0.6976885944604874}]}, {"text": "We run the baseline name tagger on a large unlabeled corpus (bootstrapping) and the test set (self-training), and automatically generate high-confidence machine-labeled sentences as additional 'training data'.", "labels": [], "entities": []}, {"text": "We then iteratively retrain the model on the increased 'training data'.", "labels": [], "entities": []}, {"text": "We first investigated whether we can improve the system by simply using a lot of unlabeled data.", "labels": [], "entities": []}, {"text": "By dramatically increasing the size of the corpus with unlabeled data, we did get a significant improvement compared to the baseline system.", "labels": [], "entities": []}, {"text": "But we found that adding off-topic unlabeled data sometimes makes the performance worse.", "labels": [], "entities": []}, {"text": "Then we tried to select relevant documents from the unlabeled data in advance, and got clear further improvements.", "labels": [], "entities": []}, {"text": "We also obtained significant improvement by self-training (bootstrapping on the test data) without any additional unlabeled data.", "labels": [], "entities": []}, {"text": "Therefore, in contrast to the claim in (), we concluded that, for some applications, effective use of large unlabeled corpora demands good data selection measures.", "labels": [], "entities": []}, {"text": "We propose and quantify some effective measures to select documents and sentences in this paper.", "labels": [], "entities": []}, {"text": "The rest of this paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 briefly describes the efforts made by previous researchers to use semi-supervised learning as well as the work of ().", "labels": [], "entities": []}, {"text": "Section 3 presents our baseline name tagger.", "labels": [], "entities": []}, {"text": "Section 4 describes the motivation for our approach while Section 5 presents the details of two semi-supervised learning methods.", "labels": [], "entities": []}, {"text": "Section 6 presents and discusses the experimental results on both English and Chinese.", "labels": [], "entities": []}, {"text": "Section 7 presents our conclusions and directions for future work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1. Incremental Improvement from  Self-training (English)", "labels": [], "entities": [{"text": "Incremental Improvement", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.8276678025722504}]}, {"text": " Table 3. English Name Tagger", "labels": [], "entities": [{"text": "English Name Tagger", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.7495995362599691}]}, {"text": " Table 4. Chinese Name Tagger", "labels": [], "entities": [{"text": "Chinese Name Tagger", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.7609413464864095}]}, {"text": " Table 5. Impact of Data Selection (Chinese)", "labels": [], "entities": [{"text": "Impact of Data Selection", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.6460399180650711}]}, {"text": " Table 6. Impact of Confidence Measures", "labels": [], "entities": [{"text": "Confidence Measures", "start_pos": 20, "end_pos": 39, "type": "TASK", "confidence": 0.7485795319080353}]}]}