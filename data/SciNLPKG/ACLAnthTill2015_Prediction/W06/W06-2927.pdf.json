{"title": [], "abstractContent": [{"text": "In this paper, we present a framework for multilingual dependency parsing.", "labels": [], "entities": [{"text": "multilingual dependency parsing", "start_pos": 42, "end_pos": 73, "type": "TASK", "confidence": 0.6118193169434866}]}, {"text": "Our bottom-up deterministic parser adopts Nivre's algorithm (Nivre, 2004) with a preprocessor.", "labels": [], "entities": []}, {"text": "Support Vector Machines (SVMs) are utilized to determine the word dependency attachments.", "labels": [], "entities": [{"text": "word dependency attachments", "start_pos": 61, "end_pos": 88, "type": "TASK", "confidence": 0.6069623827934265}]}, {"text": "Then, a maximum entropy method (MaxEnt) is used for determining the label of the dependency relation.", "labels": [], "entities": []}, {"text": "To improve the performance of the parser, we construct a tagger based on SVMs to find neighboring attachment as a preprocessor.", "labels": [], "entities": []}, {"text": "Experimental evaluation shows that the proposed extension improves the parsing accuracy of our base parser in 9 languages.", "labels": [], "entities": [{"text": "parsing", "start_pos": 71, "end_pos": 78, "type": "TASK", "confidence": 0.9680579304695129}, {"text": "accuracy", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.9363707900047302}]}, {"text": "(Haji\u010d et al., 2004; Simov et al., 2005; Simov and Osenova,", "labels": [], "entities": []}], "introductionContent": [{"text": "The presented dependency parser is based on our preceding work) for Chinese.", "labels": [], "entities": []}, {"text": "The parser is a bottom-up deterministic dependency parser based on the algorithm proposed by.", "labels": [], "entities": []}, {"text": "A dependency attachment matrix is constructed, in which each element corresponds to a pair of tokens.", "labels": [], "entities": [{"text": "dependency attachment", "start_pos": 2, "end_pos": 23, "type": "TASK", "confidence": 0.7987509071826935}]}, {"text": "Each dependency attachment is incrementally constructed, with no crossing constraint.", "labels": [], "entities": []}, {"text": "In the parser, SVMs deterministically estimate whether a pair of words has either of four relations: right, left, shift and reduce.", "labels": [], "entities": []}, {"text": "While dependency attachment is estimated by SVMs, we use a MaxEnt based tagger with the output of the parser to estimate the label of dependency relations.", "labels": [], "entities": [{"text": "dependency attachment", "start_pos": 6, "end_pos": 27, "type": "TASK", "confidence": 0.8628566563129425}]}, {"text": "This tagger uses the same features as for the word dependency analysis.", "labels": [], "entities": [{"text": "word dependency analysis", "start_pos": 46, "end_pos": 70, "type": "TASK", "confidence": 0.7090613742669424}]}, {"text": "In our preceding work (Cheng, 2005a), we not only adopted the Nivre algorithm with SVMs, but also tried some preprocessing methods.", "labels": [], "entities": []}, {"text": "We investigated several preprocessing methods on a Chinese Treebank.", "labels": [], "entities": [{"text": "Chinese Treebank", "start_pos": 51, "end_pos": 67, "type": "DATASET", "confidence": 0.9697346091270447}]}, {"text": "In this shared task), we also investigate which preprocessing method is effective on other languages.", "labels": [], "entities": []}, {"text": "We found that only the method that uses a tagger to extract the word dependency attachment between two neighboring words works effectively inmost of the languages.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our system consists of three parts; first, the SVMbased tagger extracts the neighboring attachment relations of the input sentence.", "labels": [], "entities": []}, {"text": "Second, the parser analyzes further dependency attachments.", "labels": [], "entities": []}, {"text": "If anew dependency attachment is generated, the MaxEnt based tagger estimates the label of the relation.", "labels": [], "entities": []}, {"text": "The three parts of our parser are trained on the available data of the languages.", "labels": [], "entities": []}, {"text": "In our experiment, we used the full information of each token (FORM, LEMMA, CPOSTAG, POSTAG, FEATS) when we train and test the model.", "labels": [], "entities": [{"text": "FORM", "start_pos": 63, "end_pos": 67, "type": "METRIC", "confidence": 0.9966239929199219}, {"text": "LEMMA", "start_pos": 69, "end_pos": 74, "type": "METRIC", "confidence": 0.9819095134735107}, {"text": "POSTAG", "start_pos": 85, "end_pos": 91, "type": "METRIC", "confidence": 0.9750674962997437}, {"text": "FEATS", "start_pos": 93, "end_pos": 98, "type": "METRIC", "confidence": 0.9935279488563538}]}, {"text": "describes the features of each token.", "labels": [], "entities": []}, {"text": "Some languages do not include all columns; such that the Chinese data does not include LEMMA and FEATURES, these empty columns are shown by the symbol \"-\" in.", "labels": [], "entities": [{"text": "LEMMA", "start_pos": 87, "end_pos": 92, "type": "METRIC", "confidence": 0.9685006141662598}, {"text": "FEATURES", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.9795209765434265}]}, {"text": "The features for the neighboring dependency tagging are the information of the focused word, two preceding words and two succeeding words.", "labels": [], "entities": []}, {"text": "shows the window size of our features for estimating the word dependency in the main procedures.", "labels": [], "entities": []}, {"text": "These features include the focused words (n, t), two preceding words and two succeeding words and their children.", "labels": [], "entities": []}, {"text": "The features for estimating the relation label are the same as the features used for word dependency analysis.", "labels": [], "entities": [{"text": "word dependency analysis", "start_pos": 85, "end_pos": 109, "type": "TASK", "confidence": 0.7552402218182882}]}, {"text": "For example, if the machine learner estimates the operation of this situation as \"Left\" or \"Right\" by using the features in, the parser uses the same features in and the dependency relation to estimate the label of this relation.", "labels": [], "entities": []}, {"text": "For training the models efficiently, we divided the training instances of all languages at the CPOSTAG of the focused word n in.", "labels": [], "entities": [{"text": "CPOSTAG", "start_pos": 95, "end_pos": 102, "type": "DATASET", "confidence": 0.9552421569824219}]}, {"text": "In our preceding work, we found this procedure can get better performance than training with all the instances at once.", "labels": [], "entities": []}, {"text": "However, only the instances in Czech are divided at the CPOSTAG of the focused word-pair t-n 3 . The performance of this procedure is worse than using the CPOSTAG of the focused word n, because the training instances of each CPOSTAG-pair will become scarce.", "labels": [], "entities": []}, {"text": "However, the data size of Czech is much larger than other languages; we couldn't finish the training of Czech using the CPOSTAG of the focused word n, before the deadline for submitting.", "labels": [], "entities": []}, {"text": "Therefore we used this procedure only for the experiment of Czech.", "labels": [], "entities": [{"text": "Czech", "start_pos": 60, "end_pos": 65, "type": "DATASET", "confidence": 0.949893593788147}]}, {"text": "All our experiments were run on a Linux machine with XEON 2.4GHz and 4.0GB memory.", "labels": [], "entities": []}, {"text": "The program is implemented in JAVA.", "labels": [], "entities": [{"text": "JAVA", "start_pos": 30, "end_pos": 34, "type": "DATASET", "confidence": 0.9299933314323425}]}, {"text": "shows the results of our parser.", "labels": [], "entities": []}, {"text": "We do not take into consideration the problem of cross relation.", "labels": [], "entities": []}, {"text": "Although these cross relations are few in training data, they would make our performance worse in some languages.", "labels": [], "entities": []}, {"text": "We expect that this is one reason that the result of Dutch is not good.", "labels": [], "entities": []}, {"text": "The average length of sentences and the size of training data may have affected the performance of our parser.", "labels": [], "entities": []}, {"text": "Sentences of Arabic are longer and training data size of Arabic is smaller than other languages; therefore our parser is worse in Arabic.", "labels": [], "entities": []}, {"text": "Similarly, our result in Turkish is also not good because the data size is small.", "labels": [], "entities": []}], "tableCaptions": []}