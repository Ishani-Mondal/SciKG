{"title": [{"text": "Description of the NCU Chinese Word Segmentation and Named Entity Recognition System for SIGHAN Bakeoff 2006", "labels": [], "entities": [{"text": "NCU Chinese Word Segmentation and Named Entity Recognition", "start_pos": 19, "end_pos": 77, "type": "TASK", "confidence": 0.6821615248918533}, {"text": "SIGHAN Bakeoff 2006", "start_pos": 89, "end_pos": 108, "type": "DATASET", "confidence": 0.6846679945786794}]}], "abstractContent": [{"text": "Asian languages are far from most western style in their non-separate word sequence especially Chinese.", "labels": [], "entities": []}, {"text": "The preliminary step of Asian-like language processing is to find the word boundaries between words.", "labels": [], "entities": [{"text": "Asian-like language processing", "start_pos": 24, "end_pos": 54, "type": "TASK", "confidence": 0.6936434904734293}]}, {"text": "In this paper, we present a general purpose model for both Chinese word segmentation and named entity recognition.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 59, "end_pos": 84, "type": "TASK", "confidence": 0.6102921863396963}, {"text": "named entity recognition", "start_pos": 89, "end_pos": 113, "type": "TASK", "confidence": 0.6564955115318298}]}, {"text": "This model was built on the word sequence classification with probability model, i.e., conditional random fields (CRF).", "labels": [], "entities": [{"text": "word sequence classification", "start_pos": 28, "end_pos": 56, "type": "TASK", "confidence": 0.7206638852755228}]}, {"text": "We used a simple feature set for CRF which achieves satisfactory classification result on the two tasks.", "labels": [], "entities": [{"text": "CRF", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.669565737247467}]}, {"text": "Our model achieved 91.00 in F rate in UPUC-Treebank data, and 78.71 for NER task.", "labels": [], "entities": [{"text": "F rate", "start_pos": 28, "end_pos": 34, "type": "METRIC", "confidence": 0.9904360473155975}, {"text": "UPUC-Treebank data", "start_pos": 38, "end_pos": 56, "type": "DATASET", "confidence": 0.9619720578193665}, {"text": "NER task", "start_pos": 72, "end_pos": 80, "type": "TASK", "confidence": 0.6276941895484924}]}], "introductionContent": [{"text": "With the rapid expansion of text media sources such as news articles, technical reports, there is an increasing demand for text mining and processing.", "labels": [], "entities": [{"text": "text mining", "start_pos": 123, "end_pos": 134, "type": "TASK", "confidence": 0.8595670163631439}]}, {"text": "Among different cultures and countries, the Asian languages are far from the other languages, there is not an explicit boundary between words, for example Chinese.", "labels": [], "entities": []}, {"text": "Similar to English, the preliminary step of most natural language processing is to \"tokenize\" each word.", "labels": [], "entities": []}, {"text": "In Chinese, the word tokenization is also known as word segmentation or Chinese word tokenization.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 51, "end_pos": 68, "type": "TASK", "confidence": 0.6980217546224594}]}, {"text": "To support the above targets, it is necessary to detect the boundaries between words in a given sentence.", "labels": [], "entities": []}, {"text": "In tradition, the Chinese word segmentation technologies can be categorized into three types, (heuristic) rule-based, machine learning, and hybrid.", "labels": [], "entities": []}, {"text": "Among them, the machine learning-based techniques showed excellent performance in many research studies).", "labels": [], "entities": []}, {"text": "This method treats the word segmentation problem as a sequence of word classification.", "labels": [], "entities": [{"text": "word segmentation problem", "start_pos": 23, "end_pos": 48, "type": "TASK", "confidence": 0.8093003829320272}, {"text": "word classification", "start_pos": 66, "end_pos": 85, "type": "TASK", "confidence": 0.7084412276744843}]}, {"text": "The classifier online assigns either \"boundary\" or \"non-boundary\" label to each word by learning from the large annotated corpora.", "labels": [], "entities": []}, {"text": "Machine learning-based word segmentation method is quite similar to the word sequence inference techniques, such as part-of-speech (POS) tagging, phrase chunking () and named entity recognition (.", "labels": [], "entities": [{"text": "Machine learning-based word segmentation", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.6411907002329826}, {"text": "part-of-speech (POS) tagging", "start_pos": 116, "end_pos": 144, "type": "TASK", "confidence": 0.6698706746101379}, {"text": "phrase chunking", "start_pos": 146, "end_pos": 161, "type": "TASK", "confidence": 0.7651399970054626}, {"text": "named entity recognition", "start_pos": 169, "end_pos": 193, "type": "TASK", "confidence": 0.6082314650217692}]}, {"text": "In this paper, we present a prototype for Chinese word segmentation and named entity recognition based on the word sequence inference model.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 42, "end_pos": 67, "type": "TASK", "confidence": 0.6044888297716776}, {"text": "named entity recognition", "start_pos": 72, "end_pos": 96, "type": "TASK", "confidence": 0.6114319960276285}]}, {"text": "Unlike previous researches (, we argue that without using the word segmentation information, Chinese named entity recognition task can also be viewed as a variant word segmentation technique.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 62, "end_pos": 79, "type": "TASK", "confidence": 0.7059012949466705}, {"text": "Chinese named entity recognition task", "start_pos": 93, "end_pos": 130, "type": "TASK", "confidence": 0.6201302647590637}]}, {"text": "Therefore, the two tasks can be accomplished without adapting the word sequence inference model.", "labels": [], "entities": []}, {"text": "The preliminary experimental result show that in the word segmentation task, our method can achieve 91.00 in F rate for the UPUC Chinese Treebank data, while it at-tends 78.76 F rate for the Microsoft Chinese named entity recognition task.", "labels": [], "entities": [{"text": "word segmentation task", "start_pos": 53, "end_pos": 75, "type": "TASK", "confidence": 0.839297334353129}, {"text": "F rate", "start_pos": 109, "end_pos": 115, "type": "METRIC", "confidence": 0.9907956719398499}, {"text": "UPUC Chinese Treebank data", "start_pos": 124, "end_pos": 150, "type": "DATASET", "confidence": 0.9554153382778168}, {"text": "F", "start_pos": 176, "end_pos": 177, "type": "METRIC", "confidence": 0.99063640832901}, {"text": "Microsoft Chinese named entity recognition task", "start_pos": 191, "end_pos": 238, "type": "TASK", "confidence": 0.7025166749954224}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the word sequence inference model and the used learner.", "labels": [], "entities": []}, {"text": "Experimental result and evaluations are reported in section 3.", "labels": [], "entities": []}, {"text": "Finally, in section 4, we draw conclusion and future remarks.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated our model in the close track on UPUC Chinese Treebank for Chinese word segmentation task, and CityU corpus for Chinese NER task.", "labels": [], "entities": [{"text": "UPUC Chinese Treebank", "start_pos": 45, "end_pos": 66, "type": "DATASET", "confidence": 0.9345652461051941}, {"text": "Chinese word segmentation task", "start_pos": 71, "end_pos": 101, "type": "TASK", "confidence": 0.6252876631915569}, {"text": "CityU corpus", "start_pos": 107, "end_pos": 119, "type": "DATASET", "confidence": 0.9335255920886993}]}, {"text": "Both settings are the same for the two tasks.", "labels": [], "entities": []}, {"text": "The evaluations of the two tasks were mainly measured by the three metrics, namely recall, precision, and f1-measurement.", "labels": [], "entities": [{"text": "recall", "start_pos": 83, "end_pos": 89, "type": "METRIC", "confidence": 0.9992790818214417}, {"text": "precision", "start_pos": 91, "end_pos": 100, "type": "METRIC", "confidence": 0.9971708655357361}]}, {"text": "However, the evaluation style for the NER and WS is quite different.", "labels": [], "entities": [{"text": "NER", "start_pos": 38, "end_pos": 41, "type": "DATASET", "confidence": 0.7813477516174316}, {"text": "WS", "start_pos": 46, "end_pos": 48, "type": "TASK", "confidence": 0.5335513949394226}]}, {"text": "In WS, participant should reformulate the testing data into sentence level whereas the NER was evaluated in the token-level.", "labels": [], "entities": [{"text": "WS", "start_pos": 3, "end_pos": 5, "type": "TASK", "confidence": 0.9097506403923035}]}, {"text": "lists the results of the two tasks with our preliminary model.", "labels": [], "entities": []}, {"text": "To explore the effectiveness of our method, we goon extend our model to the other three tasks for the WS track, namely CityU, MSR.", "labels": [], "entities": [{"text": "WS track", "start_pos": 102, "end_pos": 110, "type": "TASK", "confidence": 0.746446967124939}, {"text": "CityU", "start_pos": 119, "end_pos": 124, "type": "DATASET", "confidence": 0.9617729783058167}]}, {"text": "Table3 shows the experimental results of our model in the all close WS track except for CKIP corpus.", "labels": [], "entities": [{"text": "WS track", "start_pos": 68, "end_pos": 76, "type": "DATASET", "confidence": 0.6952292919158936}, {"text": "CKIP corpus", "start_pos": 88, "end_pos": 99, "type": "DATASET", "confidence": 0.9740563035011292}]}, {"text": "These results do not officially provided by the SIGHAN due to the time limitation.", "labels": [], "entities": [{"text": "SIGHAN", "start_pos": 48, "end_pos": 54, "type": "DATASET", "confidence": 0.7371205687522888}]}, {"text": "1 http://www-unix.mcs.anl.gov/tao/  In the second experiment, we focus on directly adapting our method for the NER track.", "labels": [], "entities": [{"text": "NER track", "start_pos": 111, "end_pos": 120, "type": "DATASET", "confidence": 0.6602098941802979}]}, {"text": "lists the experimental result of our method in the CityU and MSR datasets.", "labels": [], "entities": [{"text": "CityU", "start_pos": 51, "end_pos": 56, "type": "DATASET", "confidence": 0.9815042018890381}, {"text": "MSR datasets", "start_pos": 61, "end_pos": 73, "type": "DATASET", "confidence": 0.8701612055301666}]}, {"text": "It is worth to note that due to the different evaluation style in NER tracks, our tokenization rules did not consistent with the SIGHAN provided testing tokens.", "labels": [], "entities": []}, {"text": "Our preliminary tokenization rules produced 371814 characters for the testing data, while there are 364356 tokens in the official provided testing set.", "labels": [], "entities": []}, {"text": "Such a big trouble deeply earns the actual performance of our model.", "labels": [], "entities": []}, {"text": "To propose a reliable and actual result, we directly evaluate our method in the official provided testing set again.", "labels": [], "entities": []}, {"text": "As shown in, the our method achieved 0.787 in F rate with non-correct version.", "labels": [], "entities": [{"text": "F rate", "start_pos": 46, "end_pos": 52, "type": "METRIC", "confidence": 0.9853965938091278}]}, {"text": "In contrast, after correcting the Chinese tokenization rules as well as SIGHAN official provided tokens, our method significantly improved from 0.787 to 0.868.", "labels": [], "entities": [{"text": "SIGHAN official provided tokens", "start_pos": 72, "end_pos": 103, "type": "DATASET", "confidence": 0.8393926024436951}]}, {"text": "Similarly, our method performed very on the MSR track which reached 0.818 in F rate.", "labels": [], "entities": [{"text": "MSR track", "start_pos": 44, "end_pos": 53, "type": "DATASET", "confidence": 0.8619484007358551}, {"text": "F rate", "start_pos": 77, "end_pos": 83, "type": "METRIC", "confidence": 0.9891467094421387}]}], "tableCaptions": [{"text": " Table 2: Official results on the word segmenta- tion and named entity recognition tasks", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 58, "end_pos": 82, "type": "TASK", "confidence": 0.6552401681741079}]}, {"text": " Table 3: Experimental results for the three  Chinese word segmentation datasets", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 46, "end_pos": 71, "type": "TASK", "confidence": 0.6868122617403666}]}, {"text": " Table 4: Experimental results for MSR and  City closed NER tasks", "labels": [], "entities": [{"text": "MSR", "start_pos": 35, "end_pos": 38, "type": "TASK", "confidence": 0.8207019567489624}]}]}