{"title": [{"text": "You Are What You Say: Using Meeting Participants' Speech to Detect their Roles and Expertise", "labels": [], "entities": []}], "abstractContent": [{"text": "Our goal is to automatically detect the functional roles that meeting participants play, as well as the expertise they bring to meetings.", "labels": [], "entities": []}, {"text": "To perform this task, we build decision tree classifiers that use a combination of simple speech features (speech lengths and spoken keywords) extracted from the participants' speech in meetings.", "labels": [], "entities": []}, {"text": "We show that this algorithm results in a role detection accuracy of 83% on unseen test data, where the random baseline is 33.3%.", "labels": [], "entities": [{"text": "role detection", "start_pos": 41, "end_pos": 55, "type": "TASK", "confidence": 0.8109545409679413}, {"text": "accuracy", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.9328200221061707}]}, {"text": "We also introduce a simple aggre-gation mechanism that combines evidence of the participants' expertise from multiple meetings.", "labels": [], "entities": []}, {"text": "We show that this aggre-gation mechanism improves the role detection accuracy from 66.7% (when ag-gregating over a single meeting) to 83% (when aggregating over 5 meetings).", "labels": [], "entities": [{"text": "role detection", "start_pos": 54, "end_pos": 68, "type": "TASK", "confidence": 0.8681223094463348}, {"text": "accuracy", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.977970540523529}]}], "introductionContent": [{"text": "A multitude of meetings are organized everyday around the world to discuss and exchange important information, to make decisions and to collaboratively solve problems.", "labels": [], "entities": []}, {"text": "Our goal is to create systems that automatically understand the discussions at meetings, and use this understanding to assist meeting participants in various tasks during and after meetings.", "labels": [], "entities": []}, {"text": "One such task is the retrieval of information from previous meetings, which is typically a difficult and time consuming task for the human to perform).", "labels": [], "entities": [{"text": "retrieval of information from previous meetings", "start_pos": 21, "end_pos": 68, "type": "TASK", "confidence": 0.8375624517599741}]}, {"text": "Another task is to automatically record the action items being discussed at meetings, along with details such as when the action is due, who is responsible for it, etc.", "labels": [], "entities": []}, {"text": "Meeting analysis is a quickly growing field of study.", "labels": [], "entities": [{"text": "Meeting analysis", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.9161035120487213}]}, {"text": "In recent years, research has focussed on automatic speech recognition in meetings (), activity recognition ( ), automatic meeting summarization (), meeting phase detection ( ) and topic detection (.", "labels": [], "entities": [{"text": "automatic speech recognition in meetings", "start_pos": 42, "end_pos": 82, "type": "TASK", "confidence": 0.7489911794662476}, {"text": "activity recognition", "start_pos": 87, "end_pos": 107, "type": "TASK", "confidence": 0.7492647767066956}, {"text": "automatic meeting summarization", "start_pos": 113, "end_pos": 144, "type": "TASK", "confidence": 0.5165458420912424}, {"text": "meeting phase detection", "start_pos": 149, "end_pos": 172, "type": "TASK", "confidence": 0.7588885426521301}, {"text": "topic detection", "start_pos": 181, "end_pos": 196, "type": "TASK", "confidence": 0.8777850866317749}]}, {"text": "Relatively little research has been performed on automatically detecting the roles that meeting participants play as they participate in meetings.", "labels": [], "entities": []}, {"text": "These roles can be functional (e.g. the facilitator who runs the meeting, and the scribe who is the designated note taker at the meeting), discourse based (e.g. the presenter, and the discussion participant), and expertise related (e.g. the hardware acquisition expert and the speech recognition research expert).", "labels": [], "entities": [{"text": "hardware acquisition", "start_pos": 241, "end_pos": 261, "type": "TASK", "confidence": 0.7936733663082123}, {"text": "speech recognition research", "start_pos": 277, "end_pos": 304, "type": "TASK", "confidence": 0.7944782972335815}]}, {"text": "Some roles are tightly scoped, relevant to just one meeting or even apart of a meeting.", "labels": [], "entities": []}, {"text": "For example, a person can be the facilitator of one meeting and the scribe of another, or the same person can be a presenter for one part of the meeting and a discussion participant for another part.", "labels": [], "entities": []}, {"text": "On the other hand, some roles have a broader scope and last for the duration of a project.", "labels": [], "entities": []}, {"text": "Thus a single person maybe the speech recognition expert in a project and have that role in all meetings on that project.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 31, "end_pos": 49, "type": "TASK", "confidence": 0.8194795846939087}]}, {"text": "Additionally, the same person can play multiple roles, e.g. the scribe can be a speech recognition expert too.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 80, "end_pos": 98, "type": "TASK", "confidence": 0.7937861084938049}]}, {"text": "Automatic role detection has many benefits, espe-cially when used as a source of constraint for other meeting understanding components.", "labels": [], "entities": [{"text": "role detection", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.8165827691555023}]}, {"text": "For example, detecting the facilitator of the meeting might help the automatic topic detection module if we know that facilitators officially change topics and move the discussion from one agenda item to the next.", "labels": [], "entities": [{"text": "topic detection", "start_pos": 79, "end_pos": 94, "type": "TASK", "confidence": 0.7328661531209946}]}, {"text": "Knowing who the speech recognition expert is can help the automatic action item detector: If an action item regarding speech recognition has been detected but the responsible person field has not been detected, the module may place a higher probability on the speech recognition expert as being the responsible person for that action item.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 118, "end_pos": 136, "type": "TASK", "confidence": 0.7300766855478287}]}, {"text": "Additionally, detecting who is an expert in which field can have benefits of its own.", "labels": [], "entities": []}, {"text": "For example, it can be used to automatically direct queries on a particular subject to the person deemed most qualified to answer the question, etc.", "labels": [], "entities": []}, {"text": "Basic information such as participant role and expertise needs to be robustly extracted if it is to be of use to the more sophisticated stages of understanding.", "labels": [], "entities": []}, {"text": "Accordingly, we have based our role detection algorithm on simple and highly accurate speech features, as described in section 5.1.2.", "labels": [], "entities": [{"text": "role detection", "start_pos": 31, "end_pos": 45, "type": "TASK", "confidence": 0.8684588074684143}]}, {"text": "( ) describes the automatic detection of discourse roles in meetings.", "labels": [], "entities": [{"text": "automatic detection of discourse roles in meetings", "start_pos": 18, "end_pos": 68, "type": "TASK", "confidence": 0.7888815232685634}]}, {"text": "These roles included presenter (participants who make formal presentations using either slides or the whiteboard), discussion participant (participants involved in a discussion marked by frequent turn changes), observer (participants not speaking, but nevertheless consuming information during a presentation or discussion), etc.", "labels": [], "entities": []}, {"text": "In this paper we focus on automatically detecting the functional and expertise based roles that participants play in a meeting.", "labels": [], "entities": []}, {"text": "In the next section we describe the data that is used in all our role detection work in this paper.", "labels": [], "entities": [{"text": "role detection", "start_pos": 65, "end_pos": 79, "type": "TASK", "confidence": 0.8593913018703461}]}, {"text": "In subsequent sections we describe the role detection algorithm in more detail, and present evaluation results.", "labels": [], "entities": [{"text": "role detection", "start_pos": 39, "end_pos": 53, "type": "TASK", "confidence": 0.9108256995677948}]}], "datasetContent": [{"text": "We evaluated the algorithm by computing the accuracy of the detector's role predictions.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9993828535079956}]}, {"text": "Specifically, given a meeting sequence we ran the algorithm to assign a role to each meeting participant, and computed the accuracy by calculating the ratio of the number of correct assignments to the total number of participants in the sequence.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 123, "end_pos": 131, "type": "METRIC", "confidence": 0.9995753169059753}]}, {"text": "Note that it is also possible to evaluate the window-by-window classification of the decision tree classifiers; we report results on this evaluation in section 7.1.", "labels": [], "entities": []}, {"text": "To evaluate this participant role detection algorithm, we first trained the algorithm on the training set of meetings.", "labels": [], "entities": [{"text": "participant role detection", "start_pos": 17, "end_pos": 43, "type": "TASK", "confidence": 0.6389238437016805}]}, {"text": "The training phase included keyword list creation, window size optimization, and the actual induction of the decision tree.", "labels": [], "entities": [{"text": "keyword list creation", "start_pos": 28, "end_pos": 49, "type": "TASK", "confidence": 0.772765040397644}, {"text": "window size optimization", "start_pos": 51, "end_pos": 75, "type": "TASK", "confidence": 0.7703355153401693}]}, {"text": "On the training data, a window size of 300 seconds resulted in the highest accuracy over the training set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9994194507598877}]}, {"text": "The test at the root of the induced tree was whether the participant's rank in terms of speech lengths was 1, in which case he was immediately classified as a meeting leader.", "labels": [], "entities": []}, {"text": "That is, the tree learnt that the person who spoke the most in a window was most likely the meeting leader.", "labels": [], "entities": []}, {"text": "Other tests placed high in the tree included obvious ones such as testing for the keywords computer and printer to classify a participant as a hardware expert.", "labels": [], "entities": []}, {"text": "We then tested this trained role detector on the testing set of meetings.", "labels": [], "entities": []}, {"text": "Recall that the test set had 5 meeting sequences, each consisting of 5 meetings and a total of 20 meeting participants.", "labels": [], "entities": []}, {"text": "Over this test set we obtained a role detection accuracy of 83%.", "labels": [], "entities": [{"text": "role detection", "start_pos": 33, "end_pos": 47, "type": "TASK", "confidence": 0.8791771531105042}, {"text": "accuracy", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9623202085494995}]}, {"text": "A \"classifier\" that randomly assigns one of the three roles to each participant in a meeting (without regard to the roles assigned to the other participants in the same meeting) would achieve a classification accuracy of 33.3%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 209, "end_pos": 217, "type": "METRIC", "confidence": 0.9724512100219727}]}, {"text": "Thus, our algorithm significantly beats the random classifier baseline.", "labels": [], "entities": []}, {"text": "Note that as mentioned earlier, the experiments in this paper are based on the manually transcribed speech.", "labels": [], "entities": []}], "tableCaptions": []}