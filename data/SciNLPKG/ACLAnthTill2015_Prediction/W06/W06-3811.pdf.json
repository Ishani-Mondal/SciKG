{"title": [{"text": "Synonym Extraction Using a Semantic Distance on a Dictionary", "labels": [], "entities": [{"text": "Synonym Extraction", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.908651202917099}]}], "abstractContent": [{"text": "Synonyms extraction is a difficult task to achieve and evaluate.", "labels": [], "entities": [{"text": "Synonyms extraction", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9645524322986603}]}, {"text": "Some studies have tried to exploit general dictionaries for that purpose, seeing them as graphs where words are related by the definition they appear in, in a complex network of an arguably semantic nature.", "labels": [], "entities": []}, {"text": "The advantage of using a general dictionary lies in the coverage, and the availability of such resources , in general and also in specialised domains.", "labels": [], "entities": []}, {"text": "We present here a method exploiting such a graph structure to compute a distance between words.", "labels": [], "entities": []}, {"text": "This distance is used to isolate candidate synonyms fora given word.", "labels": [], "entities": []}, {"text": "We present an evaluation of the relevance of the candidates on a sample of the lexicon.", "labels": [], "entities": []}], "introductionContent": [{"text": "Thesaurus are an important resource in many natural language processing tasks.", "labels": [], "entities": [{"text": "natural language processing tasks", "start_pos": 44, "end_pos": 77, "type": "TASK", "confidence": 0.7089733183383942}]}, {"text": "They are used to help information retrieval, machine or semi-automated translation, () or generation (.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 22, "end_pos": 43, "type": "TASK", "confidence": 0.8120243847370148}, {"text": "machine or semi-automated translation", "start_pos": 45, "end_pos": 82, "type": "TASK", "confidence": 0.6765773296356201}, {"text": "generation", "start_pos": 90, "end_pos": 100, "type": "TASK", "confidence": 0.9575134515762329}]}, {"text": "Since the gathering of such lexical information is a delicate and time-consuming endeavour, some effort has been devoted to the automatic building of sets of synonyms words or expressions.", "labels": [], "entities": [{"text": "automatic building of sets of synonyms words or expressions", "start_pos": 128, "end_pos": 187, "type": "TASK", "confidence": 0.7782624628808763}]}, {"text": "Synonym extraction suffers from a variety of methodological problems, however.", "labels": [], "entities": [{"text": "Synonym extraction", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9585986435413361}]}, {"text": "Synonymy itself is not an easily definable notion.", "labels": [], "entities": [{"text": "Synonymy", "start_pos": 0, "end_pos": 8, "type": "TASK", "confidence": 0.9393242597579956}]}, {"text": "Totally equivalent words (in meaning and use) arguably do not exist, and some people prefer to talk about nearsynonyms (.", "labels": [], "entities": []}, {"text": "A nearsynonym is a word that can be used instead of another one, in some contexts, without too much change in meaning.", "labels": [], "entities": []}, {"text": "This leaves of lot of freedom in the degree of synonymy one is ready to accept.", "labels": [], "entities": []}, {"text": "Other authors include \"related\" terms in the building of thesaurus, such as hyponyms and hypernyms, () in a somewhat arbitrary way.", "labels": [], "entities": []}, {"text": "More generally, paraphrase is a preferred term referring to alternative formulations of words or expressions, in the context of information retrieval or machine translation.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 128, "end_pos": 149, "type": "TASK", "confidence": 0.7067012637853622}, {"text": "machine translation", "start_pos": 153, "end_pos": 172, "type": "TASK", "confidence": 0.7045715153217316}]}, {"text": "Then there is the question of evaluating the results.", "labels": [], "entities": []}, {"text": "Comparing to already existing thesaurus is a debatable means when automatic construction is supposed to complement an existing one, or when a specific domain is targeted, or when simply the automatic procedure is supposed to fill avoid.", "labels": [], "entities": []}, {"text": "Manual verification of a sample of synonyms extracted is a common practice, either by the authors of a study or by independent lexicographers.", "labels": [], "entities": [{"text": "Manual verification of a sample of synonyms extracted", "start_pos": 0, "end_pos": 53, "type": "TASK", "confidence": 0.8181832320988178}]}, {"text": "This of course does not solve problems related to the definition of synonymy in the \"manual\" design of a thesaurus, but can help evaluate the relevance of synonyms extracted automatically, and which could have been forgotten.", "labels": [], "entities": [{"text": "definition of synonymy", "start_pos": 54, "end_pos": 76, "type": "TASK", "confidence": 0.7917242646217346}]}, {"text": "One can hope at best fora semi-automatic procedure were lexicographers have to weed out bad candidates in a set of proposals that is hopefully not too noisy.", "labels": [], "entities": []}, {"text": "A few studies have tried to use the lexical information available in a general dictionary and find patterns that would indicate synonymy relations).", "labels": [], "entities": []}, {"text": "The general idea is that words are related by the definition they appear in, in a complex network that must be semantic in nature (this has been also applied to word sense disambiguation, albeit with limited success).", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 161, "end_pos": 186, "type": "TASK", "confidence": 0.6572102705637614}]}, {"text": "We present here a method exploiting the graph structure of a dictionary, where words are related by the definition they appear in, to compute a distance between words.", "labels": [], "entities": []}, {"text": "This distance is used to isolate candidate synonyms fora given word.", "labels": [], "entities": []}, {"text": "We present an evaluation of the relevance of the candidates on a sample of the lexicon.", "labels": [], "entities": []}], "datasetContent": [{"text": "Once the graph built, we used Prox to compute a semantic similarity between the nodes.", "labels": [], "entities": [{"text": "Prox", "start_pos": 30, "end_pos": 34, "type": "DATASET", "confidence": 0.9108625650405884}]}, {"text": "We first turned the matrix G that represent the graph into a Markovian matrix [ \u02c6 G] as described in section 2 and then computed , that correspond to 5-steps paths in the Markovian graph.", "labels": [], "entities": []}, {"text": "For a given word, we have extracted as candidate synonyms the a-nodes (i) of the same category as the word (ii) that are the closest to the o-node representing that word in the dictionary definitions.", "labels": [], "entities": []}, {"text": "Moreover, only the first a-node of each entry is considered.", "labels": [], "entities": []}, {"text": "For instance, the candidate synonyms of the verb accumuler 'accumulate' are the a-nodes representing verbs (i.e. their tags begin in a.V) that are the closer to the o.V.accumuler node.", "labels": [], "entities": []}, {"text": "5-steps paths starting from an o-node representing a word w reach six groups of a-nodes: A 1 the a-nodes of the sub-senses which have win their definition; 3 Lexicographic definitions usually have two parts: a genus and a differentia.", "labels": [], "entities": []}, {"text": "This edge weight is intended to favour the genus part of the definiens.", "labels": [], "entities": []}, {"text": "The path length has been determined empirically.", "labels": [], "entities": []}, {"text": "A 2 the a-nodes of the sub-senses with definiens containing the same words as those of A 1 ; A 3 the a-nodes of the sub-senses with definiens containing the same words as those of A 2 ; B 1 the a-nodes of the sub-senses of the article of w.", "labels": [], "entities": []}, {"text": "(These dummy candidates are not kept.)", "labels": [], "entities": []}, {"text": "B 2 the a-nodes of the sub-senses with definiens containing the same words as those of B 1 ; B 3 the a-nodes of the sub-senses with definiens containing the same words as those of B 2 ; The three first groups take advantage of the fact that synonyms of the definiendum are often used in definiens.", "labels": [], "entities": []}, {"text": "The question of the evaluation of the extraction of synonyms is a difficult one, as was already mentioned in the introduction.", "labels": [], "entities": [{"text": "extraction of synonyms", "start_pos": 38, "end_pos": 60, "type": "TASK", "confidence": 0.799489438533783}]}, {"text": "We have at our disposal several thesauri for French, with various coverages (from about 2000 pairs of synonyms, to 140,000), and a lot of discrepancies.", "labels": [], "entities": []}, {"text": "If we compare the thesaurus with each other and restrict the comparison to their common lexicon for fairness, we still have a lot of differences.", "labels": [], "entities": []}, {"text": "The best f-score is never above 60%, and it raises the question of the proper gold standard to begin with.", "labels": [], "entities": [{"text": "proper gold standard", "start_pos": 71, "end_pos": 91, "type": "METRIC", "confidence": 0.70440540711085}]}, {"text": "This is all the more distressing as the dictionary we used has a larger lexicon than all the thesaurus considered together (roughly twice as much).", "labels": [], "entities": []}, {"text": "As our main purpose is to build a set of synonyms from the TLF to go beyond the available thesaurus, we have no other way but to have lexicographers look at the result and judge the quality of candidate synonyms.", "labels": [], "entities": []}, {"text": "Before imposing this workload on our lexicographer colleagues, we took a sample of 50 verbs and 50 nouns, and evaluated the first ten candidates for each, using the ranking method presented above, and a simpler version with equal weights and no distinction between sense levels or node types.", "labels": [], "entities": []}, {"text": "The basic version of the graph also excludes nodes with too many neighbours, such as \"\u00eatre\" (be), \"avoir\" (have), \"chose\" (thing), etc.", "labels": [], "entities": []}, {"text": "It turned out one of the judge was much more liberal than the other about synonymy, but most synonyms accepted by the first were accepted by the second judge (precision of 0.85).", "labels": [], "entities": [{"text": "precision", "start_pos": 159, "end_pos": 168, "type": "METRIC", "confidence": 0.9988827109336853}]}, {"text": "We also considered a few baselines inspired by the method.", "labels": [], "entities": []}, {"text": "Obviously a lot of synonyms appear in the definition of a word, and words in a definition tend to be consider close to the entry they appear in.", "labels": [], "entities": []}, {"text": "So we tried two different baselines to estimate this bias, and how our method improves or not from this.", "labels": [], "entities": []}, {"text": "The first baseline considers as synonyms of a word all the words of the same category (verbs or nouns in each case) that appear in a definition of the word, and all the entry the word appear in.", "labels": [], "entities": []}, {"text": "Then we selected ten words at random among this base.", "labels": [], "entities": []}, {"text": "The second baseline was similar, but restricted to the first word appearing in a definition of another word.", "labels": [], "entities": []}, {"text": "Again we took ten words at random in this set if it was larger than ten, and all of them otherwise.", "labels": [], "entities": []}, {"text": "We show the results of precision for the first candidate ranked by prox, the first 5, and the first 10 (always excluding the word itself).", "labels": [], "entities": [{"text": "precision", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.9994869232177734}]}, {"text": "In the case of the two baselines, results for the first ten area bit The kappa score between the two annotators was 0.5 for both verbs and nouns, which only moderately satisfactory.", "labels": [], "entities": [{"text": "kappa score", "start_pos": 73, "end_pos": 84, "type": "METRIC", "confidence": 0.9402762949466705}]}, {"text": "misleading, since the average numbers of candidates proposed by these methods were respectively 8 and 6 for verbs and 9 and 5.6 for nouns.", "labels": [], "entities": []}, {"text": "Also, nouns had an average of 5.8 synonyms in the existing thesauri (when what was considered was the min between 10 and the number of synonyms), and verbs had an average of 8.9.", "labels": [], "entities": []}, {"text": "We can see that both baselines outperforms weighted prox on the existing thesaurus for verbs, and that the simpler prox is similar to baseline 2 (first word only).", "labels": [], "entities": []}, {"text": "For nouns, results are close between B2 and the two proxs.", "labels": [], "entities": [{"text": "B2", "start_pos": 37, "end_pos": 39, "type": "METRIC", "confidence": 0.9759482741355896}]}, {"text": "It is to be noted that a lot of uncommon words appear as candidates, as they are related with very few words, and a lot of these do not appear in the existing thesauri.", "labels": [], "entities": []}, {"text": "By looking precisely at each candidate (see judges' scores), we can see that both baselines are slightly improved (and still close to one another), but are now beaten by both prox for the first and the first 5 words.", "labels": [], "entities": []}, {"text": "There is a big difference between the two judges, so Judge 2 has better scores than Judge 1 for the baselines, but in each case, prox was better.", "labels": [], "entities": [{"text": "prox", "start_pos": 129, "end_pos": 133, "type": "METRIC", "confidence": 0.9550989270210266}]}, {"text": "It could be troubling to see how good the second baseline is for the first 10 candidates, but one must remember this baseline actually proposes 6 candidates on average (when prox was always at 10), making it actually nothing more than a variation on the 5: Experimental results on a sample, V=verbs, N=nouns, candidate baseline, to which it should be compared in all fairness (and we see that prox is much better there).", "labels": [], "entities": []}, {"text": "The difference between the two versions of prox shows that a basic version is better for verbs and the more elaborate one is better for nouns, with overall better results for verbs than for nouns.", "labels": [], "entities": []}, {"text": "One could wonder why there was some many more candidates marked as synonyms by both judges, compared to the original compilation of thesaurus.", "labels": [], "entities": []}, {"text": "Mainly, it seemed to us that it can be accounted for by a lot of infrequent words, or old senses of words absent for more restricted dictionaries.", "labels": [], "entities": []}, {"text": "We are currently investigating this matter.", "labels": [], "entities": []}, {"text": "It could also be that our sample picked out a lot of not so frequent words since they outnumber frequent words in such a large dictionary as the TLF.", "labels": [], "entities": [{"text": "TLF", "start_pos": 145, "end_pos": 148, "type": "DATASET", "confidence": 0.8219956755638123}]}, {"text": "An indication is the average frequency of words in a corpus often years of the journal \"Le Monde\".", "labels": [], "entities": [{"text": "journal \"Le Monde\"", "start_pos": 79, "end_pos": 97, "type": "DATASET", "confidence": 0.7222097277641296}]}, {"text": "The 50 words picked out in our sample have an average frequency of 2000 occurrences, while when we consider all our about 430 candidates for synonymy, the average frequency is 5300.", "labels": [], "entities": []}, {"text": "The main conclusion to draw here is that our method is able to recover a lot of synonyms that are in the definition of words, and some in definitions not directly related, which seems to bean improvement on previous attempts from dictionaries.", "labels": [], "entities": []}, {"text": "There is some arbitrariness in the method that should be further investigated (the length of the random walk for instance), but we believe the parameters are rather intuitive wrt to graph concepts.", "labels": [], "entities": []}, {"text": "We also have an assessment of the quality of the method, even though it is still on a sample.", "labels": [], "entities": []}, {"text": "The precision seems fair on the first ten candidates, enough to be used in a semiautomatic way, coupled with a lexicographic analysis.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9994818568229675}]}], "tableCaptions": [{"text": " Table 1: A fragment of the graph, presented as a matrix.", "labels": [], "entities": []}, {"text": " Table 2: Experimental results on a sample, V=verbs, N=nouns,", "labels": [], "entities": []}]}