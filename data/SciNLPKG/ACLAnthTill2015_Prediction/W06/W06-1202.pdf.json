{"title": [{"text": "Measuring MWE Compositionality Using Semantic Annotation", "labels": [], "entities": [{"text": "MWE Compositionality", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.9598298370838165}]}], "abstractContent": [{"text": "This paper reports on an experiment in which we explore anew approach to the automatic measurement of multi-word expression (MWE) compositionality.", "labels": [], "entities": [{"text": "measurement of multi-word expression (MWE) compositionality", "start_pos": 87, "end_pos": 146, "type": "TASK", "confidence": 0.689468577504158}]}, {"text": "We propose an algorithm which ranks MWEs by their compositionality relative to a semantic field taxonomy based on the Lancaster English semantic lexicon (Piao et al., 2005a).", "labels": [], "entities": [{"text": "Lancaster English semantic lexicon", "start_pos": 118, "end_pos": 152, "type": "DATASET", "confidence": 0.852989062666893}]}, {"text": "The semantic information provided by the lexicon is used for measuring the semantic distance between a MWE and its constituent words.", "labels": [], "entities": []}, {"text": "The algorithm is evaluated both on 89 manually ranked MWEs and on McCarthy et al's (2003) manually ranked phrasal verbs.", "labels": [], "entities": []}, {"text": "We compared the output of our tool with human judgments using Spearman's rank-order correlation coefficient.", "labels": [], "entities": [{"text": "rank-order correlation coefficient", "start_pos": 73, "end_pos": 107, "type": "METRIC", "confidence": 0.6892961064974467}]}, {"text": "Our evaluation shows that the automatic ranking of the majority of our test data (86.52%) has strong to moderate correlation with the manual ranking while wide discrepancy is found fora small number of MWEs.", "labels": [], "entities": []}, {"text": "Our algorithm also obtained a correlation of 0.3544 with manual ranking on McCarthy et al's test data, which is comparable or better than most of the measures they tested.", "labels": [], "entities": [{"text": "McCarthy et al's test data", "start_pos": 75, "end_pos": 101, "type": "DATASET", "confidence": 0.8754277129968008}]}, {"text": "This experiment demonstrates that a semantic lexicon can assist in MWE compositionality measurement in addition to statistical algorithms .", "labels": [], "entities": [{"text": "MWE compositionality measurement", "start_pos": 67, "end_pos": 99, "type": "TASK", "confidence": 0.9718486467997233}]}], "introductionContent": [{"text": "Over the past few years, compositionality and decomposability of MWEs have become important issues in NLP research.", "labels": [], "entities": []}, {"text": "argues that \"non-compositional expressions need to be treated differently than other phrases in many statistical or corpus-based NLP methods\".", "labels": [], "entities": []}, {"text": "Compositionality means that \"the meaning of the whole can be strictly predicted from the meaning of the parts\").", "labels": [], "entities": []}, {"text": "On the other hand, decomposability is a metric of the degree to which the meaning of a MWE can be assigned to its parts).", "labels": [], "entities": []}, {"text": "These two concepts are closely related.", "labels": [], "entities": []}, {"text": "suggest that \"an expression is likely to be relatively more compositional if it is decomposable\".", "labels": [], "entities": []}, {"text": "While there exist various definitions for MWEs, they are generally defined as cohesive lexemes that crossword boundaries (; , which include nominal compounds, phrasal verbs, idioms, collocations etc.", "labels": [], "entities": []}, {"text": "Compositionality is a critical criterion cutting across different definitions for extracting and classifying MWEs.", "labels": [], "entities": [{"text": "extracting and classifying MWEs", "start_pos": 82, "end_pos": 113, "type": "TASK", "confidence": 0.6625569388270378}]}, {"text": "While semantics of certain types of MWEs are non-compositional, like idioms \"kick the bucket\" and \"hot dog\", some others can have highly compositional semantics like the expressions \"traffic light\" and \"audio tape\".", "labels": [], "entities": []}, {"text": "Automatic measurement of MWE compositionality can have a number of applications.", "labels": [], "entities": [{"text": "MWE compositionality", "start_pos": 25, "end_pos": 45, "type": "TASK", "confidence": 0.9659764468669891}]}, {"text": "One of the often quoted applications is for machine translation, in which non-compositional MWEs need special treatment.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.8214734792709351}]}, {"text": "For instance, the translation of a highly compositional MWE can possibly be inferred from the translations of its constituent words, whereas it is impossible for noncompositional MWEs, for which we need to identify the translation equivalent for the MWEs as a whole.", "labels": [], "entities": [{"text": "translation of a highly compositional MWE", "start_pos": 18, "end_pos": 59, "type": "TASK", "confidence": 0.6346036791801453}]}, {"text": "In this paper, we explore anew method of automatically estimating the compositionality of MWEs using lexical semantic information, sourced from the Lancaster semantic lexicon () that is employed in the USAS 1 tagger ( ).", "labels": [], "entities": [{"text": "USAS 1 tagger", "start_pos": 202, "end_pos": 215, "type": "DATASET", "confidence": 0.9534608721733093}]}, {"text": "This is a large lexical resource which contains nearly 55,000 single-word entries and over 18,800 MWE entries.", "labels": [], "entities": []}, {"text": "In this lexicon, each MWE 2 and the words it contains are mapped to their potential semantic categories using a semantic field taxonomy of 232 categories.", "labels": [], "entities": []}, {"text": "An evaluation of lexical coverage on the BNC corpus showed that the lexical coverage of this lexicon reaches 98.49% for modern English ( ).", "labels": [], "entities": [{"text": "BNC corpus", "start_pos": 41, "end_pos": 51, "type": "DATASET", "confidence": 0.9681995213031769}]}, {"text": "Such a large-scale semantic lexical resource allows us to examine the semantics of many MWEs and their constituent words conveniently without resorting to large corpus data.", "labels": [], "entities": []}, {"text": "Our experiment demonstrates that such a lexical resource provides an additional approach for automatically estimating the compositionality of MWEs.", "labels": [], "entities": []}, {"text": "One may question the necessity of measuring compositionality of manually selected MWEs.", "labels": [], "entities": []}, {"text": "The truth is, even if the semantic lexicon under consideration was compiled manually, it does not exclusively consist of non-compositional MWEs like idioms.", "labels": [], "entities": []}, {"text": "Built for practical discourse analysis, it contains many MWEs which are highly compositional but depict certain entities or semantic concepts.", "labels": [], "entities": [{"text": "discourse analysis", "start_pos": 20, "end_pos": 38, "type": "TASK", "confidence": 0.7772423028945923}]}, {"text": "This research forms part of a larger effort to extend lexical resources for semantic tagging.", "labels": [], "entities": [{"text": "semantic tagging", "start_pos": 76, "end_pos": 92, "type": "TASK", "confidence": 0.8415221273899078}]}, {"text": "Techniques are described elsewhere (e.g.) for finding new candidate MWE from corpora.", "labels": [], "entities": []}, {"text": "The next stage of the work is to semi-automatically classify these candidates using an existing semantic field taxonomy and, to assist this task, we need to investigate patterns of compositionality.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to evaluate the performance of our tool against human judgment, we prepared a list of 89 MWEs and asked human raters to rank them via a website.", "labels": [], "entities": []}, {"text": "The list includes six MWEs with multiple senses, and these were treated as separate MWE.", "labels": [], "entities": []}, {"text": "The Lancaster MWE lexicon has been compiled manually by expert linguists, therefore we assume that every item in this lexicon is a true MWE, although we acknowledge that some errors may exist.", "labels": [], "entities": [{"text": "Lancaster MWE lexicon", "start_pos": 4, "end_pos": 25, "type": "DATASET", "confidence": 0.9696564873059591}]}, {"text": "Following McCarthy et al.'s approach, we asked the human raters to assign each MWE a number ranging between 0 (opaque) and 10 (fully compositional).", "labels": [], "entities": []}, {"text": "Both native and non-native speakers are involved, but only the data from native speakers are used in this evaluation.", "labels": [], "entities": []}, {"text": "As a result, three groups of raters were involved in the experiment.", "labels": [], "entities": []}, {"text": "Group 1 (6 people) rated MWEs with indexes of 1-30, Group 2 (4 people) rated MWEs with indexes of 31-59 and Group 3 (five people) rated MWEs with indexes of 6-89.", "labels": [], "entities": []}, {"text": "In order to test the level of agreement between the raters, we used the procedures provided in the 'irr' package for R (.", "labels": [], "entities": []}, {"text": "With this tool, the average intraclass correlation coefficient (ICC) was calculated for each group of raters using a two-way agreement model.", "labels": [], "entities": [{"text": "average intraclass correlation coefficient (ICC)", "start_pos": 20, "end_pos": 68, "type": "METRIC", "confidence": 0.870931897844587}]}, {"text": "As a result, all ICCs exceeded 0.7 and were significant at the 95% confidence level, indicating an acceptable level of agreement between raters.", "labels": [], "entities": [{"text": "ICCs", "start_pos": 17, "end_pos": 21, "type": "METRIC", "confidence": 0.9924915432929993}]}, {"text": "For Group 1, the ICC was 0.894 (95% ci = 0.807 < ICC < 0.948), for Group 2 it was 0.9 (95% ci=0.783<ICC<0.956) and for Group 3 it was 0.886 (95% ci = 0.762 < ICC < 0.948).", "labels": [], "entities": [{"text": "ICC", "start_pos": 17, "end_pos": 20, "type": "METRIC", "confidence": 0.9970141649246216}]}, {"text": "Based on this test, we conclude that the manual ranking of the MWEs is reliable and is suitable to be used in our evaluation.", "labels": [], "entities": []}, {"text": "Source data for the human judgements is available from our website in spreadsheet form 7 .  In our evaluation, we focused on testing the performance of the D-score against human raters' judgment on ranking different MWEs by their degree of compositionality, as well as distinguishing the different degrees of compositionality for each sense in the case of multiple tags.", "labels": [], "entities": []}, {"text": "The first step of the evaluation was to implement the algorithm in a program and run the tool on the 89 test MWEs we prepared.", "labels": [], "entities": []}, {"text": "illustrates the D-score distribution in a bar chart.", "labels": [], "entities": [{"text": "D-score distribution", "start_pos": 16, "end_pos": 36, "type": "METRIC", "confidence": 0.928382933139801}]}, {"text": "As shown by the chart, the algorithm produces a widely dispersed distribution of D-scores across Selected at random from the Lancaster semantic lexicon.", "labels": [], "entities": []}, {"text": "7 http://ucrel.lancs.ac.uk/projects/assist/ the sample MWEs, ranging from 0.000032 to 1.000000.", "labels": [], "entities": []}, {"text": "For example, the tool assigned the score of 1.0 to the FOOD sense and 0.001 to the THIEF senses of \"tea leaf\" successfully distinguishing the different degrees of compositionality of these two senses.", "labels": [], "entities": [{"text": "FOOD", "start_pos": 55, "end_pos": 59, "type": "METRIC", "confidence": 0.948918342590332}, {"text": "THIEF", "start_pos": 83, "end_pos": 88, "type": "METRIC", "confidence": 0.7913455367088318}]}, {"text": "89 MWEs As shown in, some MWEs share the same scores, reflecting the limitation of the number of ranks that our algorithm can produce as well as the limited amount of semantic information available from a lexicon.", "labels": [], "entities": []}, {"text": "Nonetheless, the algorithm produced 45 different scores which ranked the MWEs into 45 groups (see the steps in the.", "labels": [], "entities": []}, {"text": "Compared to the eleven scores used by the human raters, this provides a finegrained ranking of the compositionality.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Correlation coefficients corresponding  different rank differences.", "labels": [], "entities": []}, {"text": " Table 2: Twelve MWEs having rank differences  greater than 50.", "labels": [], "entities": []}]}