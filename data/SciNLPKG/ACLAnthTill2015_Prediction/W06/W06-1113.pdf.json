{"title": [{"text": "Variants of tree similarity in a Question Answering task", "labels": [], "entities": [{"text": "Question Answering task", "start_pos": 33, "end_pos": 56, "type": "TASK", "confidence": 0.8074371417363485}]}], "abstractContent": [{"text": "The results of experiments on the application of a variety of distance measures to a question-answering task are reported.", "labels": [], "entities": []}, {"text": "Variants of tree-distance are considered, including whole-vs-sub tree, node weight-ing, wild cards and lexical emphasis.", "labels": [], "entities": []}, {"text": "We derive string-distance as a special case of tree-distance and show that a particular parameterisation of tree-distance out-performs the string-distance measure.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper studies the deployment in a question answering task of methods which assess the similarity of question and answer representations.", "labels": [], "entities": [{"text": "question answering task", "start_pos": 39, "end_pos": 62, "type": "TASK", "confidence": 0.8314680059750875}]}, {"text": "Given questions such as Q1 what does malloc return ? Q2 What year did poet Emily Dickinson die? and a collection of sentences (eg. a computer manual, a corpus of newspaper articles), the task is to retrieve the sentences that answer the question, eg.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Distribution of Correct Cutoff across query set Q in different parse settings. Left-hand data =  GNU task, trinity parser, right-hand data = TREC11 task, Collins parser", "labels": [], "entities": [{"text": "Collins parser", "start_pos": 164, "end_pos": 178, "type": "DATASET", "confidence": 0.8620893657207489}]}, {"text": " Table 2: For different distance measures (Library task, trinity parser), distrution of correct-answer- cutoff, mean reciprocal rank mrr", "labels": [], "entities": []}, {"text": " Table 3: For different distance measures (TREC task, collins parser) the distribution of correct-answer- cutoff and mean reciprocal rank (mrr)", "labels": [], "entities": [{"text": "TREC", "start_pos": 43, "end_pos": 47, "type": "METRIC", "confidence": 0.8154749274253845}]}]}