{"title": [{"text": "Towards a validated model for affective classification of texts", "labels": [], "entities": [{"text": "affective classification", "start_pos": 30, "end_pos": 54, "type": "TASK", "confidence": 0.7318362891674042}]}], "abstractContent": [{"text": "In this paper, we present the results of experiments aiming to validate a two-dimensional typology of affective states as a suitable basis for affective classification of texts.", "labels": [], "entities": [{"text": "affective classification of texts", "start_pos": 143, "end_pos": 176, "type": "TASK", "confidence": 0.8043770492076874}]}, {"text": "Using a corpus of English weblog posts, annotated for mood by their authors, we trained support vector machine binary classifiers to distinguish texts on the basis of their affiliation with one region of the space.", "labels": [], "entities": []}, {"text": "We then report on experiments which go a step further, using four-class classifiers based on automated scoring of texts for each dimension of the typology.", "labels": [], "entities": []}, {"text": "Our results indicate that it is possible to extend the standard binary sentiment analysis (positive/negative) approach to a two dimensional model (positive/negative; ac-tive/passive), and provide some evidence to support a more fine-grained classification along these two axes.", "labels": [], "entities": [{"text": "binary sentiment analysis", "start_pos": 64, "end_pos": 89, "type": "TASK", "confidence": 0.7263780832290649}]}], "introductionContent": [{"text": "We are investigating the subjective use of language in text and the automatic classification of texts according to their subjective characteristics, or 'affect'.", "labels": [], "entities": []}, {"text": "Our approach is to view affective states (such as 'happy', 'angry') as locations in Osgood's Evaluation-Activation (EA) space, and draws on work in psychology which has along history of work seeking to construct a typology of such affective states.", "labels": [], "entities": [{"text": "Osgood's Evaluation-Activation (EA) space", "start_pos": 84, "end_pos": 125, "type": "DATASET", "confidence": 0.5882728312696729}]}, {"text": "A similar approach has been used more recently to describe emotional states that are expressed in speech ().", "labels": [], "entities": []}, {"text": "Our overall aim is to determine the extent to which such a typology can be validated and applied to the task of text classification using automatic methods.", "labels": [], "entities": [{"text": "text classification", "start_pos": 112, "end_pos": 131, "type": "TASK", "confidence": 0.8142413794994354}]}, {"text": "In this paper we describe some initial experiments aimed at validating a basic two dimensional classification of weblog data, first with Support Vector Machine (SVM) binary classifiers, then with Pointwise Mutual Information -Information Retrieval (PMI-IR).", "labels": [], "entities": [{"text": "Pointwise Mutual Information -Information Retrieval (PMI-IR)", "start_pos": 196, "end_pos": 256, "type": "TASK", "confidence": 0.6570572886202071}]}, {"text": "The domain of weblog posts is particularly well-suited for this task given its highly subjective nature and the availability of data , including data which has been author-annotated for 'mood', which is a reasonable approximation of 'affect'.", "labels": [], "entities": []}, {"text": "Recent attempts to classify weblog posts have shown modest, but consistent improvements over a 50% baseline, only slightly worse than human performance.", "labels": [], "entities": []}, {"text": "One important milestone is the elaboration of a typology of affective states.", "labels": [], "entities": []}, {"text": "To devise such a typology, our starting point is, which is based on a model of emotion as a multicomponent process.", "labels": [], "entities": []}, {"text": "In this model, the distribution of the affective states is the result of analysing similarity judgments by humans for 235 emotion terms 1 using cluster-analysis and multidimensional scaling techniques to map out the structure as a twodimensional space.", "labels": [], "entities": []}, {"text": "The positioning of words is not so much controversial as fuzzy; an affective state such as 'angry' to describe facial expression in speech may have a slightly different location than an 'angry' weblog post.", "labels": [], "entities": []}, {"text": "In this model, the well-studied 'sentiment' classification is simply a specific case (left vs. right halves of the space).", "labels": [], "entities": [{"text": "sentiment' classification", "start_pos": 33, "end_pos": 58, "type": "TASK", "confidence": 0.8392181197802225}]}, {"text": "The experiments we describe here seek to go beyond this basic distinction.", "labels": [], "entities": []}, {"text": "They involve an additional dimension of affect, the activity dimension, allowing textual data to be classified into four categories corresponding to each of the four quad- rants in the space.", "labels": [], "entities": []}, {"text": "Ultimately, once scores have been 'promoted' to real measures, classification can be more precise; for example, a text is not only negative and passive, it is more precisely 'depressive'.", "labels": [], "entities": []}, {"text": "With such a more precise classification one might, for example, be able to detect individuals at risk of suicide.", "labels": [], "entities": []}, {"text": "In Experiment 1, we use binary classifiers to investigate how the four quadrants defined by the typology hold together, the assumption being that if the typology is correct, the classifiers should perform substantially better than a random baseline.", "labels": [], "entities": []}, {"text": "In Experiment 2, we go a step closer towards a more fine-grained classification by evaluating the performance of an unsupervised automated technique for scoring texts on both axes.", "labels": [], "entities": []}, {"text": "Both these experiments are preliminary -our long term goal is to be able to validate the whole typology in terms of computationally effective classification.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our hypothesis is that the classification of two disjoint sets of moods should yield a classification accuracy significantly above a baseline of 50%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 102, "end_pos": 110, "type": "METRIC", "confidence": 0.968743622303009}]}, {"text": "To verify our hypothesis, we conducted a series of experiments using machine learning to classify weblog posts according to their mood, each class corresponding to one particular quadrant.", "labels": [], "entities": []}, {"text": "We used Support Vector Machines) with three basic classic features (unigrams, POS and stems) to classify the posts as belonging to one quadrant or one of the three others.", "labels": [], "entities": []}, {"text": "For each classification task, we extracted randomly 1000 testing examples, and trained separately with 2000, 4000, 8000 and 16000 examples.", "labels": [], "entities": []}, {"text": "In each case, examples were divided equally among positive and negative examples 3 . The set of features used varied for each of these tasks, they were selected by thresholding each (distinct) training data set, after removing words (unigrams) from the categories poor in affective content (prepositions, determiners, etc.).", "labels": [], "entities": []}, {"text": "To qualify as a feature, each unigram, POS or stem had to occur at least three times in the training data.", "labels": [], "entities": [{"text": "POS", "start_pos": 39, "end_pos": 42, "type": "METRIC", "confidence": 0.9735355377197266}]}, {"text": "The value of each feature corresponds to its number of occurence in the training examples.", "labels": [], "entities": []}, {"text": "Our next goal is to be able to classify a text according to more than four classes (positive/negative, active/passive), by undertaking multi-category classification of texts according to particular regions of the space, (such as 'angry', 'sad', etc.).", "labels": [], "entities": []}, {"text": "In order to do that we need a scoring system for each axis.", "labels": [], "entities": []}, {"text": "In the following experiments we explore the use of such scores and give some insights into how to transform these scores of affect as measures of affect.", "labels": [], "entities": []}, {"text": "Using binary classifiers, we have already established that if we look at the lexical contents of weblog posts tagged according to their mood by their author, these mood classes tend to cluster according to a two-dimensional typology defined by their semantic orientation: positive or negative (evaluation), active or passive (activity).", "labels": [], "entities": []}, {"text": "Beyond academic importance, the typology really becomes of practical interest if we can classify the posts using pre-defined automated scores for both axis.", "labels": [], "entities": []}, {"text": "One strategy of scoring is to extract phrases, including single words, which are good indicators of subjectivity in texts, and score them according to how they relate or 'associate' to one or the other extremity of each axis.", "labels": [], "entities": []}, {"text": "This strategy, called Semantic Orientation (SO) from Association (A) has been used successfully to classify texts or adjectives of all sorts according to their sentiments (in our typology this corresponds to the evaluation dimension).", "labels": [], "entities": [{"text": "Semantic Orientation (SO)", "start_pos": 22, "end_pos": 47, "type": "TASK", "confidence": 0.7950602293014526}]}, {"text": "According to these scores, a text or adjective can be said to have, for example, a more or less positive or negative evaluation.", "labels": [], "entities": []}, {"text": "We will use this strategy to go further in the validation of our model of affective states by scoring also the activity dimension; to our knowledge, this is the first time this strategy is employed to get (text) scores for dimensions other than evaluation.", "labels": [], "entities": []}, {"text": "In SO-A, we score the strength of the association between an indicator from the text and a set of positive or negative words (the paradigms Pwords and Nwords) capturing the very positive/active or negative/passive semantic orientation of the axis poles.", "labels": [], "entities": []}, {"text": "To get the SO-A of a text, we sum over positive scores for indicators positively related to Pwords and negatively related to Nwords and negative scores for indicators positively related to Nwords and negatively related to Pwords.", "labels": [], "entities": [{"text": "SO-A", "start_pos": 11, "end_pos": 15, "type": "TASK", "confidence": 0.9227155447006226}]}, {"text": "In mathematical terms, the SO-A of a text is: where ind stands for indicator.", "labels": [], "entities": []}, {"text": "Note that the quantity of Pwords must be equal to Nwords.", "labels": [], "entities": []}, {"text": "To compute A, () focus on the use of lexical relations defined in WordNet and define a distance measure between two terms which amounts to the length of the shortest path that connects the two terms.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 66, "end_pos": 73, "type": "DATASET", "confidence": 0.9624595642089844}]}, {"text": "This strategy is interesting because it constrains all values to belong to the [-1,+1] range, but can be applied only to a finite set of indicators and has yet to be tested for the classification of texts.", "labels": [], "entities": [{"text": "classification of texts", "start_pos": 181, "end_pos": 204, "type": "TASK", "confidence": 0.8844708998998007}]}, {"text": "use Pointwise Mutual Information -Information Retrieval (PMI-IR); PMI-IR operates on a wider variety of multi-words indicators, allowing for contextual information to betaken into account, has been tested extensively on different types of texts, and the scoring system can be potentially normalized between [-1,+1], as we will soon see.", "labels": [], "entities": [{"text": "Pointwise Mutual Information -Information Retrieval", "start_pos": 4, "end_pos": 55, "type": "TASK", "confidence": 0.6058729539314905}]}, {"text": "PMI) between two phrases is defined as: PMI is positive when two phrases tend to co-occur and negative when they tend to be in a complementary distribution.", "labels": [], "entities": [{"text": "PMI", "start_pos": 40, "end_pos": 43, "type": "METRIC", "confidence": 0.9846414923667908}]}, {"text": "PMI-IR refers to the fact that, as in Informtion Retrieval (IR), multiple occurrences in the same document count as just one occurrence: according to, this seems to yield a better measure of semantic similarity, providing some resistance to noise.", "labels": [], "entities": [{"text": "Informtion Retrieval (IR)", "start_pos": 38, "end_pos": 63, "type": "TASK", "confidence": 0.8174057126045227}]}, {"text": "Computing probabilities using hit counts from IR, this yields to a value for PMI-IR of: log n N * (hits(ph 1 N EAR ph 2 ) + 1/N ) (hits(ph 1 ) + 1) * (hits(ph 2 ) + 1) where N is the total number of documents in the corpus.", "labels": [], "entities": []}, {"text": "We are going to use this method for computing A in SO-A, which we call SO-PMI-IR.", "labels": [], "entities": []}, {"text": "The configuration depicted in the remaining of this section follows mostly.", "labels": [], "entities": []}, {"text": "Smoothing values (1/N and 1) are chosen so that PMI-IR will be zero for words that are not in the corpus, two phrases are considered NEAR if they co-occur within a window of 20 words, and log 2 has been replaced by log n , since the natural log is more common in the literature for log-odds ratio and this makes no difference for the algorithm.", "labels": [], "entities": [{"text": "NEAR", "start_pos": 133, "end_pos": 137, "type": "METRIC", "confidence": 0.7339836359024048}]}, {"text": "Two crucial aspects of the method are the choice of indicators to be extracted from the text to be classified, as well as the sets of positive and negative words to be used as paradigms for the evaluation and activity dimensions.", "labels": [], "entities": []}, {"text": "The five part-ofspeech (POS) patterns from were used for the extraction of indicators, all involving at least one adjective or adverb.", "labels": [], "entities": []}, {"text": "POS tags were acquired with TreeTagger ( 6 . Ideally, words used as paradigms should be context insensitive, i.e their semantic orientation is either always positive or negative.", "labels": [], "entities": []}, {"text": "The adjectives good, nice, excellent, positive, fortunate, correct, superior and bad, nasty, poor, negative, unfortunate, wrong, inferior were used as near pure representations of positive and negative evaluation respectively, while fast, alive, noisy, young and slow, dead, quiet, old as near pure representations of active and passive activity.", "labels": [], "entities": []}, {"text": "Departing from (Turney and Littman, 2003), who uses the Alta Vista advanced search with approximately 350 millions web pages, we used the Waterloo corpus , with approximately 46 millions pages.", "labels": [], "entities": [{"text": "Waterloo corpus", "start_pos": 138, "end_pos": 153, "type": "DATASET", "confidence": 0.9716613590717316}]}, {"text": "To avoid introducing confusing heuristics, we stick to the configuration described above, but have experimented with different configuation in computing SO-PMI-IR.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: CM for the GI: (U)Us and (T)", "labels": [], "entities": []}, {"text": " Table 4: CM for the Typology affective states", "labels": [], "entities": [{"text": "Typology", "start_pos": 21, "end_pos": 29, "type": "DATASET", "confidence": 0.8676099181175232}]}, {"text": " Table 6: CM for the Big Eight", "labels": [], "entities": []}, {"text": " Table 7: CM for all Moods: Discrete scoring", "labels": [], "entities": []}, {"text": " Table 8: CM for the Big Eight: Discrete scoring", "labels": [], "entities": []}, {"text": " Table 10: CM for Big Eight: Discrete scoring", "labels": [], "entities": []}]}