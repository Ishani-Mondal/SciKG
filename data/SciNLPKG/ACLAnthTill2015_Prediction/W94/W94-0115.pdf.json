{"title": [], "abstractContent": [{"text": "We describe a prototype system which induces a categorial grammar from a simple text corpus of children's reading books.", "labels": [], "entities": []}, {"text": "Unlike previous attempts at grammar induction, (I) there are no rules of grammar, only a richly structured lexicon; (2) we rely both on an informing linguistic theory and on statistical methods applied to a corpus.", "labels": [], "entities": [{"text": "grammar induction", "start_pos": 28, "end_pos": 45, "type": "TASK", "confidence": 0.7597254812717438}]}], "introductionContent": [], "datasetContent": [{"text": "L's initial corpus was books la and lb of the Ladybird Key Words Reading Scheme.", "labels": [], "entities": [{"text": "L's initial corpus", "start_pos": 0, "end_pos": 18, "type": "DATASET", "confidence": 0.8693857342004776}, {"text": "Ladybird Key Words Reading Scheme", "start_pos": 46, "end_pos": 79, "type": "DATASET", "confidence": 0.9578824877738953}]}, {"text": "They contain 351 word tokens, using a vocabulary of about 20 different words.", "labels": [], "entities": []}, {"text": "This corpus was completely processed in 17 passes.", "labels": [], "entities": []}, {"text": "Processing later books in the series has brought L's current vocabulary up to some 55 words.", "labels": [], "entities": []}, {"text": "This is still small, of course, but the nature of the induction process means that growth should 'snowball' as each known word helps in the categorization of further new words.", "labels": [], "entities": []}, {"text": "(And see Shieber quoted in fora revealing discussion of the vocabulary sizes of most NLP research prototypes).", "labels": [], "entities": []}, {"text": "Within this limited vocabulary, L has 'correctly' induced examples of the following categories: determiners, adjectives, prepositions, conjunctions, intransitive, transitive and ditransitive verbs, imperatives, and some auxiliaries.", "labels": [], "entities": []}, {"text": "Furthermore, L discovers and represents ambiguity of the following types: adjective vs noun; sentence co-ordination vs nounphrase co-ordination; prepositional form; noun-phrase vs determiner, and verbs of quotation.", "labels": [], "entities": []}, {"text": "An example of the latter are four structural forms that L induces for says (as in 'Rhubarb rhubarb says Jane' or 'Jane says rhubarb rhubarb').", "labels": [], "entities": []}, {"text": "L has also inadvertently re-invented type-raising, assigning the category (S/(S\\NP))/N to a sentence-initial determiner: the system's exact method of exploiting parametric neutrality told it that this word needed a following noun to form a function into a sentence from a following 'verb phrase'.", "labels": [], "entities": []}, {"text": "A slightly different algorithm would have given the more standard NP/N, and reduction mechanisms could easily be implemented to find simpler equivalents, where possible, of highly complex proposed categories.", "labels": [], "entities": []}, {"text": "Indeed they will almost certainly be needed, as witness L's assignment of the category: S\\NP/(S\\NP\\S)/(S\\NP\\NP) to you as the last uncategorized word in the sentence 'Here you are Jane says Peter'.)", "labels": [], "entities": []}, {"text": "Evaluation of the results took two forms: I) Use of the lexicon for generation.", "labels": [], "entities": []}, {"text": "Many different lexicons could have been produced which would account only for the training corpus.", "labels": [], "entities": []}, {"text": "Using the lexicon for generation of new text provided evidence that it was more general.", "labels": [], "entities": [{"text": "generation of new text", "start_pos": 22, "end_pos": 44, "type": "TASK", "confidence": 0.8896439522504807}]}, {"text": "The text generated was in character with the corpus -for example, 'Peter you are in it says r.", "labels": [], "entities": []}, {"text": "This is an important result; we have evidence that the grammar created is general, but does not over-generate.", "labels": [], "entities": []}, {"text": "L produced cognitively plausible results -i.e. as well as producing categories that enable the entire corpus to reduce to a sequence of Ss, the results reflect what are traditionally (manually) assigned 128 to each word -for a wide range of syntactic constructions, providing further evidence that the lexicon produced is not just corpusspecific.", "labels": [], "entities": []}], "tableCaptions": []}