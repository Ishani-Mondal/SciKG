{"title": [{"text": "Bootstrapping Statistical Processing into a Rule-based Natural Language Parser", "labels": [], "entities": [{"text": "Statistical Processing", "start_pos": 14, "end_pos": 36, "type": "TASK", "confidence": 0.739891529083252}]}], "abstractContent": [{"text": "This paper describes a \"bootstrapping\" method which uses a broad-coverage, rule-based parser to compute probabilities while parsing an untagged corpus of NL text, and which then incorporates those probabilities into the processing of the same parser as it analyzes new text.", "labels": [], "entities": []}, {"text": "Results are reported which show that this method can significantly improve the speed and accuracy of the parser without requiring the use of annotated corpora or human-supervised training during the computation of probabilities.", "labels": [], "entities": [{"text": "speed", "start_pos": 79, "end_pos": 84, "type": "METRIC", "confidence": 0.9821536540985107}, {"text": "accuracy", "start_pos": 89, "end_pos": 97, "type": "METRIC", "confidence": 0.9937207698822021}]}], "introductionContent": [{"text": "For decades, the majority of NL parsers have been \"rule-based.\"", "labels": [], "entities": [{"text": "NL parsers", "start_pos": 29, "end_pos": 39, "type": "TASK", "confidence": 0.587234303355217}]}, {"text": "In such parsers, knowledge about the syntactic structure of a language is written in the form of linguistic rules, and these rules are applied by the parser to input text segments in order to produce the resulting parse trees.", "labels": [], "entities": []}, {"text": "Information about individual words, such as what parts-ofspeech they maybe, is usually stored in an online dictionary, or \"lexicon,\" which is accessed by the parser for each word in the input text prior to applying the linguistic rules.", "labels": [], "entities": []}, {"text": "Although rule-based parsers are widely-used in real, working NLP systems, they have the disadvantage that extensive amounts of (dictionary) data and labor (to write the rules) by highly-skilled linguists are required in order to create, enhance, and maintain them.", "labels": [], "entities": []}, {"text": "This is especially true if the parser is required to have \"broad coverage\", i.e., if it is to be able to parse NL text from many different domains (what one might call '!general\" text).", "labels": [], "entities": []}, {"text": "In the last few years, there has been increasing activity in the computational linguistics community focused on making use of statistical methods to acquire information from large corpora of NL text, and on using that information in statistical NL parsers.", "labels": [], "entities": []}, {"text": "Instead of being stored in the traditional form of dictionary data and grammatical rules, linguistic knowledge in these parsers is represented as statistical parameters, or probabilities.", "labels": [], "entities": []}, {"text": "These probabilities are commonly used together with simpler, less specified, dictionary data and/or rules, thereby taking the place of much of the information created by sldlled labor in rule-based systems.", "labels": [], "entities": []}, {"text": "Advantages of the statistical approach that are claimed by its proponents include a significant decrease in the amount of rule coding required to create a parser that performs adequately, and the ability to \"tune\" a parser to a particular type of text simply by extracting statistical information from the same type of text.", "labels": [], "entities": []}, {"text": "Perhaps the most significant disadvantage appears to be the requirement for large amounts of training data, often in the form of large NL text corpora that have been annotated with hand-coded tags specifying parts-of-speech, syntactic function, etc.", "labels": [], "entities": []}, {"text": "There have been a number of efforts to extract information from corpora that are not tagged (e.g.,, but the depth of information thus obtained and its utility in \"automatically\" creating a NL parser is usually limited.", "labels": [], "entities": []}, {"text": "To overcome the need for augmenting corpora with tags in order to obtain more useful inforrnation, researchers in statistical NLP have experimented with a variety of strategies, some of which employ varying degrees of traditional linguistic abstraction.", "labels": [], "entities": []}, {"text": "group words in untagged corpora into equivalence classes, according to their possible parts-of-speech.", "labels": [], "entities": []}, {"text": "They then perform statistical analyses over these equivalence classes, rather than over the words themselves, in order to obtain higher-level trigram language models that will be used later by their statistics-based parser.", "labels": [], "entities": []}, {"text": "have similarly resorted to reducing inflected word forms to their underlying lemmas before estimation of statistical parameters.", "labels": [], "entities": []}, {"text": "carry the use of traditional rule-based linguistics a step further by using a unification-based grammar as a starting point.", "labels": [], "entities": []}, {"text": "Through a process of human-supervised training on a small corpus of text, a statistical model is then developed which is used to rank the parses produced by the grammar fora given input.", "labels": [], "entities": []}, {"text": "A similar method of interactive training has been used by to produce favorable results.", "labels": [], "entities": []}, {"text": "Beyond the realm of simply using traditional linguistics to enhance the quality of data extracted from corpora by statistical methods, there have been attempts to create hybrid systems that incorporate statistical information into already well-developed rule-based frameworks.", "labels": [], "entities": []}, {"text": "For example, have used common statistical methods to extract information such as part-of-speech frequency, verb subcategorization frames, and prepositional phrase attachment preferences from corpora and have then incorporated it into the processing in their knowledge-based parser in order to quickly expand its coverage in new domains.", "labels": [], "entities": []}, {"text": "In comparing rule-based approaches with those which are more purely statistics-based, and including everything in between, one could claim that there is some constant amount of linguistic knowledge that is required to create an NL parser, and one must either code it explicitly into the parser (using rules), or use statistical methods to extract it from sources such as text corpora.", "labels": [], "entities": []}, {"text": "Furthermore, in the latter case, the extraction of useful information from the raw data in corpora is facilitated by additional information provided through manual tagging, through \"seeding\" the process with linguistic abstractions (e.g., parts-of-speech), or through the interaction of human supervisors during the extraction process.", "labels": [], "entities": []}, {"text": "In any case, it appears that in addition to information that maybe obtained by statistical methods, generalized linguistic knowledge from a human source is also clearly desirable, if not required, in order to create truly capable parsers.", "labels": [], "entities": []}, {"text": "Proponents of statistical metheds usually point to the data-driven aspect of their approach as enabling them to create robust parsers that can handle \"real text.\"", "labels": [], "entities": []}, {"text": "Although many rule-based parsers have been limited in scope, we believe that it is indeed possible to create and maintain broad-coverage, rule-based NL systems (e.g., Jensen 1993), by carefully studying and using ample amounts of data to refme those systems.", "labels": [], "entities": []}, {"text": "It has been our experience that the complexity and difficulty of creating such rule-based systems can be readily managed if one has a powerful and comprehensive set of tools.", "labels": [], "entities": []}, {"text": "Nevertheless, it is also clearly desirable to be able to use statistical methods to adapt (or tune) rulebased systems automatically for particular types of text as well as to acquire additional linguistic information from corpora and to integrate it with information that has been developed by trained linguists.", "labels": [], "entities": []}, {"text": "To the end of incorporating statistics-based processing into a rule-based parser, we have devised a \"bootstrapping\" method.", "labels": [], "entities": []}, {"text": "This method uses a rule-based parser to compute part-of-speech and rule probabilities while processing a large, nonannotated corpus.", "labels": [], "entities": []}, {"text": "These probabilities are then incorporated into the very same parser, thereby providing guidance to the parser as it assigns parts of speech to words and applies rules during the processing of new text.", "labels": [], "entities": []}, {"text": "Although our method relies on the existence of a broad-coverage, rule-based parser, which, as discussed at the beginning of this paper, is not trivial to develop, the benefits of this approach are that relevant statistical information can be obtained automatically from large untagged corpora, and that this information can be used to improve significantly the speed and accuracy of the parser.", "labels": [], "entities": [{"text": "speed", "start_pos": 361, "end_pos": 366, "type": "METRIC", "confidence": 0.9666218161582947}, {"text": "accuracy", "start_pos": 371, "end_pos": 379, "type": "METRIC", "confidence": 0.9844643473625183}]}, {"text": "This method also obviates the need for any humansupervised training during the parsing process and allows for \"tuning\" the parser to particular types of text.", "labels": [], "entities": [{"text": "parsing process", "start_pos": 79, "end_pos": 94, "type": "TASK", "confidence": 0.9015582799911499}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1. Comparison of parsing efficiency over  500 sentences", "labels": [], "entities": [{"text": "parsing", "start_pos": 24, "end_pos": 31, "type": "TASK", "confidence": 0.9673442244529724}]}, {"text": " Table 2. Comparison of correct parse selection  over 100 sentences for which multiple parses  are produced", "labels": [], "entities": []}]}