{"title": [{"text": "A Text Categorization Based on Summarization Technique", "labels": [], "entities": [{"text": "Summarization Technique", "start_pos": 31, "end_pos": 54, "type": "TASK", "confidence": 0.8239578902721405}]}], "abstractContent": [{"text": "We propose anew approach to text categorization based upon the ideas of summarization.", "labels": [], "entities": [{"text": "text categorization", "start_pos": 28, "end_pos": 47, "type": "TASK", "confidence": 0.7903134524822235}, {"text": "summarization", "start_pos": 72, "end_pos": 85, "type": "TASK", "confidence": 0.9688567519187927}]}, {"text": "It combines word-based frequency and position method to get categorization knowledge from the title field only.", "labels": [], "entities": []}, {"text": "Experimental results indicate that summarization-based categorization can achieve acceptable performance on Reuters news corpus.", "labels": [], "entities": [{"text": "summarization-based categorization", "start_pos": 35, "end_pos": 69, "type": "TASK", "confidence": 0.9499058723449707}, {"text": "Reuters news corpus", "start_pos": 108, "end_pos": 127, "type": "DATASET", "confidence": 0.9220560590426127}]}], "introductionContent": [{"text": "With the current explosive growth of Interact usage, the demand for fast and useful access to online data is increasing.", "labels": [], "entities": [{"text": "Interact usage", "start_pos": 37, "end_pos": 51, "type": "TASK", "confidence": 0.8117756545543671}]}, {"text": "An efficient categorization system should provide accurate information quickly.", "labels": [], "entities": []}, {"text": "There are many applications for text categorization, including information retrieval, text routing, text filtering and text understanding systems.", "labels": [], "entities": [{"text": "text categorization", "start_pos": 32, "end_pos": 51, "type": "TASK", "confidence": 0.7628172039985657}, {"text": "information retrieval", "start_pos": 63, "end_pos": 84, "type": "TASK", "confidence": 0.8214118778705597}, {"text": "text routing", "start_pos": 86, "end_pos": 98, "type": "TASK", "confidence": 0.8025090992450714}, {"text": "text filtering", "start_pos": 100, "end_pos": 114, "type": "TASK", "confidence": 0.7966598272323608}, {"text": "text understanding", "start_pos": 119, "end_pos": 137, "type": "TASK", "confidence": 0.7661667764186859}]}, {"text": "The text categorization systems use predefmed categories to label new documents.", "labels": [], "entities": []}, {"text": "Many different approaches have been applied to this task, including nearest neighbor classifiers), Bayesian independence classifiers (, decision trees (), induction rule learning (, neural networks, and support vector machines.", "labels": [], "entities": []}, {"text": "These categorization algorithms have been applied to many different subject domains, usually news stories (), but also physics abstracts, and medical texts.", "labels": [], "entities": []}, {"text": "In this research to resolve the task of text categorization we apply a method of text summarization, that is, combining word-based frequency and position method to get categorization knowledge from the title field only.", "labels": [], "entities": [{"text": "text categorization", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.7380974590778351}, {"text": "text summarization", "start_pos": 81, "end_pos": 99, "type": "TASK", "confidence": 0.6736257970333099}]}, {"text": "Experimental results indicate that summarization-based categorization can achieve acceptable performance on Reuters news corpus.", "labels": [], "entities": [{"text": "summarization-based categorization", "start_pos": 35, "end_pos": 69, "type": "TASK", "confidence": 0.9499058723449707}, {"text": "Reuters news corpus", "start_pos": 108, "end_pos": 127, "type": "DATASET", "confidence": 0.9220560590426127}]}, {"text": "Additionally, the computation time for the title field is very short.", "labels": [], "entities": []}, {"text": "Thus, this system is appropriate for online document classifier.", "labels": [], "entities": [{"text": "online document classifier", "start_pos": 37, "end_pos": 63, "type": "TASK", "confidence": 0.5559181074301401}]}, {"text": "Following is a description of the organization of this paper.", "labels": [], "entities": []}, {"text": "Section 2 describes the previous work of summarization.", "labels": [], "entities": [{"text": "summarization", "start_pos": 41, "end_pos": 54, "type": "TASK", "confidence": 0.985473096370697}]}, {"text": "Summarization-based algorithms for text categorization are outlined in Section 3.", "labels": [], "entities": [{"text": "text categorization", "start_pos": 35, "end_pos": 54, "type": "TASK", "confidence": 0.7978683412075043}]}, {"text": "The experiments we undertook to assess the performance of these algorithms are the topic of Section 4.", "labels": [], "entities": []}, {"text": "Quantitative experimental results are also summarized.", "labels": [], "entities": []}, {"text": "Finally, concluding remarks and recommendation for future work is made.", "labels": [], "entities": []}], "datasetContent": [{"text": "To assess the proposed method's effectiveness, we apply the algorithms described in the previous section and conduct a series of experiments.", "labels": [], "entities": []}, {"text": "Tests are performed on the Reuters corpus.", "labels": [], "entities": [{"text": "Reuters corpus", "start_pos": 27, "end_pos": 41, "type": "DATASET", "confidence": 0.9609731137752533}]}, {"text": "A general description of the materials used in these experiments follows.", "labels": [], "entities": []}, {"text": "Finally, the success rates are quantitatively evaluated.", "labels": [], "entities": []}, {"text": "show the top ten most frequent categories and ten least frequent categories on the training sets.", "labels": [], "entities": []}, {"text": "The average length of title field and whole document are 7.4 and 126.9 words per document, respectively.", "labels": [], "entities": []}, {"text": "In this paper, we only use TITLE field as the scope of texts.", "labels": [], "entities": [{"text": "TITLE", "start_pos": 27, "end_pos": 32, "type": "METRIC", "confidence": 0.611636757850647}]}, {"text": "In our first experiment, the variable is variant term weighting formulas that are described in Section 3.", "labels": [], "entities": []}, {"text": "We want to seethe effects on categorization performance, when probability of category and normalized process of term frequency are used.", "labels": [], "entities": []}, {"text": "The first experiment is summarized in.", "labels": [], "entities": []}, {"text": "A second experiment is to locate the most preferred threshold value of minimum term frequency.", "labels": [], "entities": []}, {"text": "For the number of features in our experiment, the values 10, 20, 50, 100, 150, 200, 300 and 900 are tested.", "labels": [], "entities": []}, {"text": "We survey the effectiveness of our algorithms by using the conventional l 1-point average precision ().", "labels": [], "entities": [{"text": "l 1-point average precision", "start_pos": 72, "end_pos": 99, "type": "METRIC", "confidence": 0.6357191279530525}]}, {"text": "We first investigate a suitable term weighted formula by doing a set of initial categorization from Method 1 through 4.", "labels": [], "entities": []}, {"text": "Threshold of minimum term frequency is fixed at 3.", "labels": [], "entities": [{"text": "Threshold", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9862404465675354}, {"text": "minimum term frequency", "start_pos": 13, "end_pos": 35, "type": "METRIC", "confidence": 0.7804286082585653}]}, {"text": "The results are tabulated in.", "labels": [], "entities": []}, {"text": "It can be seen The choice of term-weighting formulas in the first experiment. that Method 4 appears to perform well in our measure.", "labels": [], "entities": []}, {"text": "The average ll-point evaluation can achieve 82.7% precision for Method 4 (tfxidf).", "labels": [], "entities": [{"text": "precision", "start_pos": 50, "end_pos": 59, "type": "METRIC", "confidence": 0.9981101751327515}]}, {"text": "It seems to point out that\" small text size (only TITLE field is used) is not bad for text categorization, when compared with kNN's 93% and LLSF's 92% for full texts).", "labels": [], "entities": [{"text": "TITLE", "start_pos": 50, "end_pos": 55, "type": "METRIC", "confidence": 0.8975402116775513}, {"text": "text categorization", "start_pos": 86, "end_pos": 105, "type": "TASK", "confidence": 0.7495566010475159}]}, {"text": "The other experimental variable is the number of chosen features.", "labels": [], "entities": []}, {"text": "shows the large feature sets earn the better result when probability is absent.", "labels": [], "entities": []}, {"text": "In the next experiment, with the term weighting formula fixed at Eq.", "labels": [], "entities": [{"text": "Eq", "start_pos": 65, "end_pos": 67, "type": "METRIC", "confidence": 0.9844925403594971}]}, {"text": "1-d (Method 4), we vary the minimum number of term frequency from 1 to 3.", "labels": [], "entities": []}, {"text": "indicates that there are no significant differences among judgements, but shows a little improvement for those small threshold values.", "labels": [], "entities": []}, {"text": "The data also shows that the information contained in the title field is almost come together and very little noise.", "labels": [], "entities": []}, {"text": "Thus, it seems to have no effects for the processing of sparse data.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1 The distribution of category number on  corpus.  Category  Training sets  Test sets  No. Doe # Percentage Doe # Percentage  1 6586  84.6%  2823  85.3%  2  878  11.3%  347  10.5%  3  188  2.4%  65  2.0%  4  61  0.8%  36  1.1%  5  39  0.5%  21  0.6%  Above 5  37  0.5%  17  0.5%", "labels": [], "entities": []}, {"text": " Table 3 The ten least frequent categories  training sets.  Topic  Name  comglutenfeed", "labels": [], "entities": [{"text": "comglutenfeed", "start_pos": 73, "end_pos": 86, "type": "DATASET", "confidence": 0.4139285087585449}]}, {"text": " Table 4 The choice of term-weighting formulas  in the first experiment.", "labels": [], "entities": []}, {"text": " Table 6 The 11-point average precision scores  of Method 4.  Feature #  Tf>=3  Tf>=2  Tf>=l  10  72.1%  72.2%  72.3%  20  77.1%  77.2%  77.3%  50  80.2%  80.3%  80.5%  100  81.9%  82.1%  82.3%  150  82.4%  82.7%  82.9%  200  82.6%  82.9%  83.1%  300  82.6%  82.9%  83.2%  900  82.7%  83.0%  83.2%", "labels": [], "entities": [{"text": "precision", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.9601140022277832}, {"text": "300  82.6%  82.9%  83.2%  900  82.7%  83.0", "start_pos": 247, "end_pos": 289, "type": "METRIC", "confidence": 0.7533152428540316}]}]}