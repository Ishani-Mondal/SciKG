{"title": [{"text": "Multilingual Summary Generation in a Speech-To-Speech Translation System for Multilingual Dialogues*", "labels": [], "entities": [{"text": "Multilingual Summary Generation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8561546206474304}, {"text": "Speech-To-Speech Translation", "start_pos": 37, "end_pos": 65, "type": "TASK", "confidence": 0.7455110251903534}]}], "abstractContent": [{"text": "This paper describes a novel functionality of the VERBMOBIL system, a large scale translation system designed for spontaneously spoken multilingual negotiation dialogues.", "labels": [], "entities": []}, {"text": "The task is the on-demand generation of dialogue scripts and result summaries of dialogues.", "labels": [], "entities": []}, {"text": "We focus on summary generation and show how the relevant data are selected from the dialogue memory and how they are packed into an appropriate abstract representation.", "labels": [], "entities": [{"text": "summary generation", "start_pos": 12, "end_pos": 30, "type": "TASK", "confidence": 0.886434942483902}]}, {"text": "Finally, we demonstrate how the existing generation module of VERBMOBIL was extended to produce multilingual and result summaries from these representations.", "labels": [], "entities": [{"text": "VERBMOBIL", "start_pos": 62, "end_pos": 71, "type": "DATASET", "confidence": 0.8641788959503174}]}], "introductionContent": [{"text": "In the last couple of years different methods for summarization have been developed.", "labels": [], "entities": [{"text": "summarization", "start_pos": 50, "end_pos": 63, "type": "TASK", "confidence": 0.9918429255485535}]}, {"text": "In this paper we report on anew system functionality within the scope of VERBMOBIL (), a fully implemented speech-to-speech translation system, that generates German or English dialogue scripts) as well as German or English summaries of a multilingual negotiation dialogue held with assistance of the system.", "labels": [], "entities": [{"text": "VERBMOBIL", "start_pos": 73, "end_pos": 82, "type": "DATASET", "confidence": 0.5807613134384155}, {"text": "speech-to-speech translation", "start_pos": 107, "end_pos": 135, "type": "TASK", "confidence": 0.7431680560112}]}, {"text": "By a script we mean a document that reflects the domain-specific propositional contents of the individual turns of a dialogue as a whole, while a summary gives a compact summarization of all negotiations the dialogue participants agreed on.", "labels": [], "entities": []}, {"text": "The key idea behind our approach is to utilize as many existing resources as possible.", "labels": [], "entities": []}, {"text": "Conceptually we have added one module (although technically realized in different already existing modules of the overall VERBMOBIL system) -the summary generator.", "labels": [], "entities": []}, {"text": "Besides formatting, our new module generates sequences of language specific (i.e., German) semantic representations for thegeneration of Sam: maries/seripts based on the content of the dialogue memory ().", "labels": [], "entities": [{"text": "formatting", "start_pos": 8, "end_pos": 18, "type": "TASK", "confidence": 0.9611261487007141}]}, {"text": "These descriptions are \u2022 The research within VERBMOBIL presented here is funded by the German Ministry of Research and Technology under grant 011V101K/1.", "labels": [], "entities": []}, {"text": "The authors would like to thank Tilman Becker for comments on earlier drafts on this paper, and Stephan Lesch for invaluable help with programming.", "labels": [], "entities": []}, {"text": "realized into text by the existing VERBMOBIL generator (.", "labels": [], "entities": [{"text": "VERBMOBIL generator", "start_pos": 35, "end_pos": 54, "type": "DATASET", "confidence": 0.7883837819099426}]}, {"text": "To produce multilingual summaries we utilize the transfer module of VERS-MOBIL (.", "labels": [], "entities": [{"text": "VERS-MOBIL", "start_pos": 68, "end_pos": 78, "type": "DATASET", "confidence": 0.7412164211273193}]}, {"text": "The next section gives an overview of the VERB-MOBIL system focusing on the modules central for the production of summaries/scripts.", "labels": [], "entities": [{"text": "VERB-MOBIL", "start_pos": 42, "end_pos": 52, "type": "DATASET", "confidence": 0.6504757404327393}]}, {"text": "It is followed by a section describing the extraction and maintenance of summary relevant data.", "labels": [], "entities": []}, {"text": "We then describe the functionality of the summary generator in detail.", "labels": [], "entities": []}, {"text": "An excerpt of the sample dialogue we refer to in the paper is given at the end of the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have performed a small evaluation of the overall system as described in this paper.", "labels": [], "entities": []}, {"text": "Basis for the evaluation were the transcripts of four German-English negotiation dialogues.", "labels": [], "entities": []}, {"text": "For each dialogue the resulting features of the negotiation (maximally 47, e.g., location, date fora meeting, speakers name and title, book agent) were annotated by a lmman, and then compared with the result of running the dialogues through the system and generating the summaries.", "labels": [], "entities": []}, {"text": "The features in the summary were compared using the following classifications: \u2022 Corr The feature approximately corresponds to the human annotation.", "labels": [], "entities": [{"text": "Corr", "start_pos": 81, "end_pos": 85, "type": "METRIC", "confidence": 0.9957518577575684}]}, {"text": "This means that the feature is either (1) a 100% match; (2) it was not sufficiently specified or (2) too specific.", "labels": [], "entities": []}, {"text": "An example of is when the correct date included a time, which was not captured.", "labels": [], "entities": []}, {"text": "An example of is when a date with time was annotated but the feature contained just a (late.", "labels": [], "entities": []}, {"text": "o Miss A feature is not included in the summary.", "labels": [], "entities": [{"text": "Miss", "start_pos": 2, "end_pos": 6, "type": "METRIC", "confidence": 0.8618059754371643}, {"text": "A", "start_pos": 7, "end_pos": 8, "type": "METRIC", "confidence": 0.6710249185562134}]}, {"text": "o False A feature was erroneously iimluded in the sumlnary, meaning that the feature was not part of the dialogue or it received a wrong value.", "labels": [], "entities": [{"text": "False A feature", "start_pos": 2, "end_pos": 17, "type": "METRIC", "confidence": 0.8716745575269064}]}, {"text": "Obviously, our approach tries to be on the safe side; the summary contains only those features that the system thinks both partners agreed on.", "labels": [], "entities": []}, {"text": "The main reasons for not getting higher numbers is twofold.", "labels": [], "entities": []}, {"text": "The recognition of dialogue acts, and thus the recognition of the intension behind the utterances reaches a 70% recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 112, "end_pos": 118, "type": "METRIC", "confidence": 0.9992063641548157}]}, {"text": "We also still make errors during the content extraction.", "labels": [], "entities": [{"text": "content extraction", "start_pos": 37, "end_pos": 55, "type": "TASK", "confidence": 0.6916776299476624}]}], "tableCaptions": []}