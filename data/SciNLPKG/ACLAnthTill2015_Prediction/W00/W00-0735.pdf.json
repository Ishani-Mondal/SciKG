{"title": [], "abstractContent": [], "introductionContent": [{"text": "In the shared task for CoNLL-2000, words and tags form the basic multi-valued features for predicting a rich phrase segmentation code.", "labels": [], "entities": [{"text": "predicting a rich phrase segmentation code", "start_pos": 91, "end_pos": 133, "type": "TASK", "confidence": 0.6842656284570694}]}, {"text": "While the tag features, containing WSJ paxt-ofspeech tags, have about 45 values, the word features have more than 10,000 values.", "labels": [], "entities": []}, {"text": "In our study we have looked at how memory-based learning, as implemented in the TiMBL software system (), can handle such features.", "labels": [], "entities": [{"text": "TiMBL software system", "start_pos": 80, "end_pos": 101, "type": "DATASET", "confidence": 0.8761080304781595}]}, {"text": "We have limited our search to single classifiers, thereby explicitly ignoring the possibility to build a metalearning classifier architecture that could be expected to improve accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 176, "end_pos": 184, "type": "METRIC", "confidence": 0.9954584836959839}]}, {"text": "Given this restriction we have explored the following: 1.", "labels": [], "entities": []}, {"text": "The generalization accuracy of TiMBL with default settings (multi-valued features, overlap metric, feature weighting).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9869430065155029}]}, {"text": "2. The usage of MVDM (, which should work well on word value pairs with a medium or high frequency, but may work badly on word value pairs with low frequency.", "labels": [], "entities": []}, {"text": "3. The straightforward unpacking of feature values into binary features.", "labels": [], "entities": []}, {"text": "On some tasks we have found that splitting multi-valued features into several binary features can enhance performance of the classifier.", "labels": [], "entities": []}], "datasetContent": [{"text": "In we give an overview of the experiments with different metrics and settings.", "labels": [], "entities": []}, {"text": "In the first block of rows we give the results of the default setting with IBI-IG and with a varying k parameter (number of nearest neighbours).", "labels": [], "entities": []}, {"text": "We can see that a larger k improves performance to a certain extent.", "labels": [], "entities": []}, {"text": "In the second series of experiments we have used the MVDM metric.", "labels": [], "entities": []}, {"text": "Here, we also varied the value of k.", "labels": [], "entities": []}, {"text": "We found that a larger k yielded better results.", "labels": [], "entities": []}, {"text": "Ina variant on this series we applied MVDM only to the POS features.", "labels": [], "entities": []}, {"text": "As expected this variant gave slightly better results.", "labels": [], "entities": []}, {"text": "In the third series we unpacked the features.", "labels": [], "entities": []}, {"text": "Compared to the previous experiment the results were worse.", "labels": [], "entities": []}, {"text": "Apparently, sparseness results in bad feature weights.", "labels": [], "entities": []}, {"text": "This negative effect appears to have outweighted any positive effect of informative individual features.", "labels": [], "entities": []}, {"text": "In the last experiments we used Ripper to generate 390 complex features.", "labels": [], "entities": []}, {"text": "The results are comparable to the best TiMBL settings.", "labels": [], "entities": []}, {"text": "In we give an overview of the precision, recall and Ff~ = 1 of one of the best scoring setting: IBi-IG with k --3", "labels": [], "entities": [{"text": "precision", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.9997534155845642}, {"text": "recall", "start_pos": 41, "end_pos": 47, "type": "METRIC", "confidence": 0.999810516834259}, {"text": "Ff~ = 1", "start_pos": 52, "end_pos": 59, "type": "METRIC", "confidence": 0.9571682959794998}]}], "tableCaptions": [{"text": " Table 1: Results on the shared task dataset, in the top row the best performing metric is shown.", "labels": [], "entities": []}]}