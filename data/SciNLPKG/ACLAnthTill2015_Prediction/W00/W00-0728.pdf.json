{"title": [{"text": "A Context Sensitive Maximum Likelihood Approach to Chunking", "labels": [], "entities": [{"text": "Chunking", "start_pos": 51, "end_pos": 59, "type": "TASK", "confidence": 0.8512588739395142}]}], "abstractContent": [], "introductionContent": [{"text": "In groundbreaking work on partsof-speech tagging, the starting point was to assign each word its most common tag.", "labels": [], "entities": [{"text": "partsof-speech tagging", "start_pos": 26, "end_pos": 48, "type": "TASK", "confidence": 0.8902732729911804}]}, {"text": "An extension to this first step is to utilize the lexical context (i.e., words and punctuation) surrounding the word.", "labels": [], "entities": []}, {"text": "This approach could obviously be used for ordering tags into higher order units (referred to as chunks) using chunk :labels.", "labels": [], "entities": []}, {"text": "This paper will investigate the performance of simply picking the most likely tag fora given context, under the condition that a larger context is allowed to override the most likely label of a smaller context.", "labels": [], "entities": []}, {"text": "The results could be extended by secondary error correction as in Brill's tagger, but this exercise is left to the reader to allow us to concentrate on the performance based on storing and retrieving the most likely examples only.", "labels": [], "entities": []}, {"text": "More sophisticated methods may' use more than one stored context to determine the label that best fits the current context.", "labels": [], "entities": []}, {"text": "The method of this paper uses only one context to determine the best label, but may decrease the size of the context until a full match is found.", "labels": [], "entities": []}, {"text": "2 Outline of the procedure 2.1 \"Training\" The training of this mechanism is to determine which patterns in the training set are the most likely.", "labels": [], "entities": []}, {"text": "Only tag information is used.", "labels": [], "entities": []}, {"text": "A filter to convert a tag with a context into a chunk-label is constructed as follows: 0) Construct symmetric n-contexts from the training corpus.", "labels": [], "entities": []}, {"text": "A 1-context is simply the most common chunk-label for each tag.", "labels": [], "entities": []}, {"text": "A 3-context is the tag followed by the tag before and after label.", "labels": [], "entities": []}, {"text": "Finally, a 7-context is represented as [to t-1 t+l t-2 t+2 t-3 t+3]:label.", "labels": [], "entities": []}, {"text": "It was verified that results do not significantly improve using larger contexts than 5-contexts.", "labels": [], "entities": []}, {"text": "1) For each set of n-contexts, determine the most frequent label for each occurring ncontext.", "labels": [], "entities": []}, {"text": "For example, the tag CC most frequently has the label B-NP if the context is PRP CC RP.", "labels": [], "entities": []}, {"text": "The most frequent label for CC without extra context is \"0\".", "labels": [], "entities": []}, {"text": "2) To save some storage space, the most frequent label in an n-context is only added if it is different from its nearest lower order context.", "labels": [], "entities": []}, {"text": "For example, the label B-NP can be added fora 3-context since PRP CC RP gives a different result from CC alone.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}