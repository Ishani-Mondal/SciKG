{"title": [{"text": "Concept Identification and Presentation in the Context of Technical Text Summarization", "labels": [], "entities": [{"text": "Concept Identification", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.722557008266449}, {"text": "Summarization", "start_pos": 73, "end_pos": 86, "type": "TASK", "confidence": 0.7687220573425293}]}], "abstractContent": [{"text": "We describe a method of text summarization that produces indicative-informative abstracts / for technical papers.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 24, "end_pos": 42, "type": "TASK", "confidence": 0.681401714682579}]}, {"text": "The abstracts are generated by a process of conceptual identification, topic extraction and re-generation.", "labels": [], "entities": [{"text": "topic extraction", "start_pos": 71, "end_pos": 87, "type": "TASK", "confidence": 0.8172188103199005}]}, {"text": "We have carried out an evaluation to assess indicative-ness and text acceptability relying on human judgment.", "labels": [], "entities": []}, {"text": "The results so far indicate good performance in both tasks when compared with other summarization technologies.", "labels": [], "entities": [{"text": "summarization", "start_pos": 84, "end_pos": 97, "type": "TASK", "confidence": 0.9710758924484253}]}], "introductionContent": [{"text": "We have specified a method of text summarization which produces indicative-informative abstracts for technical documents.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 30, "end_pos": 48, "type": "TASK", "confidence": 0.6681369096040726}]}, {"text": "The method was designed to identify the \"topics\" of a document and present them in an indicative abstract.", "labels": [], "entities": []}, {"text": "Eventually, they can be elaborated in .specific ways.", "labels": [], "entities": []}, {"text": "In, we present an indicative abstract for the document \"Facilitating designer-.", "labels": [], "entities": []}, {"text": "\u2022 customer communication in the World Wide Web\" (Internet Research: Electronic Networking Applications and Policy,) produced with our implementation of this method.", "labels": [], "entities": []}, {"text": "The abstract includes a list of topics which are terms appearing in the automatic abstract (e.g. WebShaman) or obtained from the source document by the process of term expansion (e.g. WWW technique obtained from technique).", "labels": [], "entities": []}, {"text": "It also * The first author is supported by Agence Canadienne de D~veloppement International (ACDI) and FundaciSn Antorchas (A-13671/1-47), Argentina.", "labels": [], "entities": [{"text": "Agence Canadienne de D~veloppement International (ACDI)", "start_pos": 43, "end_pos": 98, "type": "DATASET", "confidence": 0.5298990964889526}, {"text": "FundaciSn Antorchas (A-13671/1-47)", "start_pos": 103, "end_pos": 137, "type": "DATASET", "confidence": 0.8516511576516288}]}, {"text": "He was previously supported by Ministerio de EducaciSn de la Naci6n de la Repfiblica Argentina (ResoluciSn 1041/96) and Departamento de ComputaciSn, Facultad de Ciencias Exactas y Naturales, UBA, Argentina.", "labels": [], "entities": []}, {"text": "includes term elaborations which can be used to answer specific questions about the topics such as what is topic?", "labels": [], "entities": []}, {"text": "who developed topic? and what are the advantages of topic?", "labels": [], "entities": []}, {"text": "In this paper, we will describe how we dealt with the problem of content selection and presentation and how we have evaluated our method of text summarization.", "labels": [], "entities": [{"text": "content selection and presentation", "start_pos": 65, "end_pos": 99, "type": "TASK", "confidence": 0.7264129370450974}, {"text": "text summarization", "start_pos": 140, "end_pos": 158, "type": "TASK", "confidence": 0.674710750579834}]}], "datasetContent": [{"text": "We compared abstrac\u00a3s produced by our method with abstracts produced by Microsoft'97 Summarizer and with others published with source documents (usually author abstracts).", "labels": [], "entities": []}, {"text": "We have chosen Microsoft'97 Summarizer because, even if it only produces extracts, it was the only summarizer available in order to carryout this evaluation and because it has already been used in other evaluations (Marcu, 1997;).", "labels": [], "entities": []}, {"text": "In order to evaluate content, we presented judges with randomly selected abstracts and five lists of keywords (content indicators).", "labels": [], "entities": []}, {"text": "The judges had to decide to which list of keywords the abstract belongs given that different lists share some keywords and that they belong to the same technical domain.", "labels": [], "entities": []}, {"text": "lists were obtained from the journals where the source documents were published.", "labels": [], "entities": []}, {"text": "The idea behind this evaluation is to see if the abstract convey the very essential content of the source document.", "labels": [], "entities": []}, {"text": "We told the judges that we would consider the abstracts with scores above 2.5 as acceptable.", "labels": [], "entities": []}, {"text": "Some criteria are more important than other, for example judges do not care about impersonal style but care about readability.", "labels": [], "entities": []}, {"text": "The evaluation was performed in one hour session at McGill University.", "labels": [], "entities": []}, {"text": "Each human judge received a form (so he/she evaluated six different abstracts) and an instruction booklet.", "labels": [], "entities": []}, {"text": "No other material was required for the evaluation (i.e. dictionary).", "labels": [], "entities": []}, {"text": "We asked the judges to read carefully the abstract.", "labels": [], "entities": []}, {"text": "They had to decide which was the list of keywords that matched the abstract (they could chose more than one or none at all) and then, they had to associate a numeric score to the abstract representing its quality based on the given criteria.", "labels": [], "entities": []}, {"text": "This procedure produced three different evaluations of content and text quality for each of the 36 abstracts.", "labels": [], "entities": []}, {"text": "The overall evaluation was completed in a maximum of 40 minutes.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Results of Human Judgment about Indicativeness and Text Quality", "labels": [], "entities": []}]}