{"title": [{"text": "Using Semantically Motivated Estimates to Help Subcategorization Acquisition", "labels": [], "entities": [{"text": "Subcategorization Acquisition", "start_pos": 47, "end_pos": 76, "type": "TASK", "confidence": 0.8614783585071564}]}], "abstractContent": [{"text": "Research into the automatic acquisition of subcategorization frames from corpora is starting to produce large-scale computational lexicons which include valuable frequency information.", "labels": [], "entities": []}, {"text": "However, the accuracy of the resulting lexicons shows room for improvement.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9991497993469238}]}, {"text": "One source of error lies in the lack of accurate back-off estimates for subcatego-rization frames, delimiting the performance of statistical techniques frequently employed in verbal acquisition.", "labels": [], "entities": []}, {"text": "In this paper, we propose a method of obtaining more accurate , semantically motivated back-off estimates , demonstrate how these estimates can be used to improve the learning of subcatego-rization frames, and discuss using the method to benefit large-scale lexical acquisition.", "labels": [], "entities": []}], "introductionContent": [{"text": "Manual development of large subcategorised lexicons has proved difficult because predicates change behaviour between sublanguages, domains and overtime.", "labels": [], "entities": []}, {"text": "Yet parsers depend crucially on such information, and probabilistic parsers would greatly benefit from accurate information concerning the relative frequency of different subcategorization frames (SCFs) fora given predicate.", "labels": [], "entities": []}, {"text": "Over the past years acquiring subcategorization dictionaries from textual corpora has become increasingly popular (e.g.).", "labels": [], "entities": []}, {"text": "The different approaches vary according to the methods used and the number of SCFs being extracted.", "labels": [], "entities": []}, {"text": "Regardless of this, there is a ceiling on the performance of these systems at around 80% token recall*.", "labels": [], "entities": [{"text": "recall", "start_pos": 95, "end_pos": 101, "type": "METRIC", "confidence": 0.9269620776176453}]}, {"text": "*Token recall is the percentage of SCF tokens in a sample of manually analysed text that were correctly acquired by the system.", "labels": [], "entities": [{"text": "recall", "start_pos": 7, "end_pos": 13, "type": "METRIC", "confidence": 0.8232938051223755}]}, {"text": "One significant source of error lies in the statistical filtering methods frequently used to remove noise from automatically acquired SCFs.", "labels": [], "entities": []}, {"text": "These methods are reported to be particularly unreliable for low frequency scFs), resulting in a poor overall performance.", "labels": [], "entities": []}, {"text": "According to, the poor performance of statistical filtering can be largely explained by the zipfian nature of the data, coupled with the fact that many statistical tests are based on the assumption of two zipfian distributions correlating: the conditional SCF distribution of an individual verb (p(scfilverbj)) and the unconditional SCF distribution of all verbs in general (p(scfl)).", "labels": [], "entities": []}, {"text": "Contrary to this assumption, however, there is no significant correlation between the two distributions.", "labels": [], "entities": []}, {"text": "Korhonen, have showed that a simple method of filtering SCFs on the basis of their relative frequency performs more accurately than statistical filtering.", "labels": [], "entities": []}, {"text": "This method sensitive to the sparse data problem is best integrated with smoothing.", "labels": [], "entities": []}, {"text": "Yet the performance of the sophisticated smoothing techniques which back-off to an unconditional distribution also suffer from the lack of correlation between p(scfi[verbj) and p(scf0.", "labels": [], "entities": []}, {"text": "In this paper, we propose a method for obtaining more accurate back-off estimates for SCF acquisition.", "labels": [], "entities": [{"text": "SCF acquisition", "start_pos": 86, "end_pos": 101, "type": "TASK", "confidence": 0.9816127121448517}]}, {"text": "Taking Levin's verb classification as a starting point, we show that in terms of SCF distributions, individual verbs correlate better with other semantically similar verbs than with all verbs in general.", "labels": [], "entities": []}, {"text": "On the basis of this observation, we propose classifying verbs according to their semantic class and using the conditional SCF distributions of a few other members in the same class as back-off estimates of the class (p( sc filsernantic class j)).", "labels": [], "entities": []}, {"text": "Adopting the SCF acquisition system of  we report an experiment which demonstrates how these estimates can be used in filtering.", "labels": [], "entities": [{"text": "SCF acquisition", "start_pos": 13, "end_pos": 28, "type": "TASK", "confidence": 0.7922383248806}]}, {"text": "This is done by acquiring the conditional SCF distributions for selected test verbs, smoothing these distributions with the unconditional distribution of the respective verb class, and applying a simple method for filtering the resulting set of SCFs.", "labels": [], "entities": []}, {"text": "Our results show that the proposed method improves the acquisition of SCFs significantly.", "labels": [], "entities": [{"text": "acquisition of SCFs", "start_pos": 55, "end_pos": 74, "type": "TASK", "confidence": 0.6551962892214457}]}, {"text": "We discuss how this method can be used to benefit large-scale SCF acquisition.", "labels": [], "entities": [{"text": "SCF acquisition", "start_pos": 62, "end_pos": 77, "type": "TASK", "confidence": 0.9727437496185303}]}, {"text": "We begin by reporting our findings that the SCF distributions of semantically similar verbs correlate well (section 2).", "labels": [], "entities": []}, {"text": "We then introduce the method we adopted for constructing the back-~off estimates for the data used in our experiment (section 3.1), summarise the main features of the SCF acquisition approach (section 3.2), and describe the smoothing techniques adopted (section 3.3).", "labels": [], "entities": [{"text": "SCF acquisition", "start_pos": 167, "end_pos": 182, "type": "TASK", "confidence": 0.973183274269104}]}, {"text": "Finally, we review the empirical evaluation (section 4) and discuss directions for future work (section 5).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Correlating the SCF distribution of.fly against other SCF distributions", "labels": [], "entities": []}, {"text": " Table 3: Correlation results for five verb classes", "labels": [], "entities": []}, {"text": " Table 5: Average results with different methods using semantically motivated back-off estimates  for smoothing", "labels": [], "entities": [{"text": "smoothing", "start_pos": 102, "end_pos": 111, "type": "TASK", "confidence": 0.9333710670471191}]}, {"text": " Table 6: Average results using the SCF distribution of all verbs as back-off estimates for smooth- ing", "labels": [], "entities": [{"text": "smooth- ing", "start_pos": 92, "end_pos": 103, "type": "TASK", "confidence": 0.5871808330217997}]}, {"text": " Table 7: Baseline and linear interpolation results for the verb classes", "labels": [], "entities": []}]}