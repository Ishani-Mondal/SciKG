{"title": [{"text": "Reinterpretation of an existing\u2022NLG system in a Generic Generation Architecture", "labels": [], "entities": []}], "abstractContent": [{"text": "The RAGS project aims to define a reference architecture for Natural Language Generation (NLG) systems.", "labels": [], "entities": [{"text": "Natural Language Generation (NLG)", "start_pos": 61, "end_pos": 94, "type": "TASK", "confidence": 0.8130104740460714}]}, {"text": "Currently the major part of this architecture consists of a set of datatype definitions for specifying the input and output formats for modules within NLG systems.", "labels": [], "entities": []}, {"text": "In this paper we describe our efforts to reinterpret an existing NLG system in terms of these definitions.", "labels": [], "entities": []}, {"text": "The system chosen was the Caption Generation System.", "labels": [], "entities": [{"text": "Caption Generation", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.9844029545783997}]}], "introductionContent": [{"text": "The RAGS project ~ aims to define a reference architecture for natural language generation systems.", "labels": [], "entities": []}, {"text": "Currently the major part of this architecture consists of a set of datatype definitions for specifying the input and output formats for modules within NLG systems.", "labels": [], "entities": []}, {"text": "The intention is that such representations can be used to assist in reusability of components of NLG systems.", "labels": [], "entities": []}, {"text": "System components that adhere to these representations, or use a format that can be translated into such representations relatively easily, can then, in principle, be substituted into other systems.", "labels": [], "entities": []}, {"text": "Also, individual components could be developed without the need fora complete system if datasets, based on the representations, were made available.", "labels": [], "entities": []}, {"text": "In this paper we describe an attempt to reinterpret an existing NLG system in terms of the RAGS data definitions.", "labels": [], "entities": [{"text": "RAGS data definitions", "start_pos": 91, "end_pos": 112, "type": "DATASET", "confidence": 0.8328089912732443}]}, {"text": "The point of this exercise was to lem-n: 1.", "labels": [], "entities": []}, {"text": "Whether these data structures were sufficient to describe the input and output functionality of an existing, independently developed, ap-3.", "labels": [], "entities": []}, {"text": "Whether studying the system would generate good ideas about possible reusable generation modules that could be developed.", "labels": [], "entities": []}, {"text": "In this exercise it was important to choose a system that had been developed by people outside the RAGS project.", "labels": [], "entities": [{"text": "RAGS project", "start_pos": 99, "end_pos": 111, "type": "DATASET", "confidence": 0.7980141937732697}]}, {"text": "Equally, it was important to have sufficient clear information about the system in the available literature, and/or by means of personal contact with the developers.", "labels": [], "entities": []}, {"text": "The system chosen was the Caption Generation System () 3.", "labels": [], "entities": [{"text": "Caption Generation", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.9613292813301086}]}, {"text": "This system was chosen because, as well as fulfilling the criteria above, it appeared to be a relatively simple pipeline, thus avoiding complex control issues, with individual modules performing the varied linguistic tasks that the RAGS data structures had been designed to handle.", "labels": [], "entities": [{"text": "RAGS data structures", "start_pos": 232, "end_pos": 252, "type": "DATASET", "confidence": 0.7942761580149332}]}, {"text": "The reinterpretation exercise took the form of coming up with an account of how the interfaces to the CGS modules corresponded to the RAGS model and reimplementing a working version of each module (apart from Text Planning and Realisation) which was tested to ensure that, given appropriate input, its output was correct (i.e. conforming to the global account) on key examples.", "labels": [], "entities": [{"text": "RAGS model", "start_pos": 134, "end_pos": 144, "type": "DATASET", "confidence": 0.8912701904773712}, {"text": "Text Planning and Realisation)", "start_pos": 209, "end_pos": 239, "type": "TASK", "confidence": 0.7789732694625855}]}, {"text": "Naturally, given the scope of this exercise, we had to gloss over some interesting implementational issues.", "labels": [], "entities": []}, {"text": "The aim was not to produce a complete system or a system as good as CGS, but merely to demonstrate that the broad functionality of the system could be reproplied 2 NLG system.", "labels": [], "entities": [{"text": "CGS", "start_pos": 68, "end_pos": 71, "type": "DATASET", "confidence": 0.9193037152290344}]}, {"text": "\u2022 Now at the MITRE Corporation, Bedford, MA, USA, cdoran.?mitre, org.", "labels": [], "entities": []}, {"text": "tThis work was supported by ESPRC grants GR/L77041 (Edinburgh) and GR/L77102 (Brighton), RAGS: Reference Architecture for Generation Systems.", "labels": [], "entities": [{"text": "ESPRC grants GR/L77041 (Edinburgh)", "start_pos": 28, "end_pos": 62, "type": "DATASET", "confidence": 0.7230831310153008}, {"text": "RAGS", "start_pos": 89, "end_pos": 93, "type": "DATASET", "confidence": 0.5782178044319153}]}, {"text": "-'See (Paiva, 1998) fora definition of applied in this specific context.", "labels": [], "entities": []}, {"text": "\" . -ducedwithin:the RAGS .structures.", "labels": [], "entities": [{"text": ". -ducedwithin:the RAGS .structures", "start_pos": 2, "end_pos": 37, "type": "DATASET", "confidence": 0.6851780638098717}]}, {"text": "In this paper we first describe the RAGS data structures.", "labels": [], "entities": [{"text": "RAGS data structures", "start_pos": 36, "end_pos": 56, "type": "DATASET", "confidence": 0.8772260745366415}]}, {"text": "We then describe the CGS system 3In addition to these published sources, we were greatly helped by the developers of the system who gave us the benefit of their own expertise as well as access to the original code of the system and a technical report that included implementational details such as system traces.", "labels": [], "entities": [{"text": "CGS system 3In", "start_pos": 21, "end_pos": 35, "type": "DATASET", "confidence": 0.9229765931765238}]}, {"text": "followed by our reinterpretation of the system in Abstract Rhetorical Abstract Rhetorical Repre-RAGS terms.", "labels": [], "entities": []}, {"text": "Finally we discuss,, the :implications:.", "labels": [], "entities": []}, {"text": ":..-._..sentations ,are--tree-structures with,rhetorical .relafor RAGS of this exercise, tions at the internal nodes and Abstract Rhetorical 2 The RAGS datatypes The RAGS project initially set out to develop a reference architecture based on the three-stage pipeline suggested by Reiter.", "labels": [], "entities": [{"text": "Abstract", "start_pos": 121, "end_pos": 129, "type": "METRIC", "confidence": 0.9505798816680908}, {"text": "RAGS datatypes", "start_pos": 147, "end_pos": 161, "type": "DATASET", "confidence": 0.738402932882309}]}, {"text": "However, a trees or Abstract Semantic Representations at the leaves.", "labels": [], "entities": []}, {"text": "Rhetorical Abstract Rhetorical Representations are viewed as descriptions of sets of possible Rhetorical Representations.", "labels": [], "entities": [{"text": "Rhetorical Abstract Rhetorical Representations", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.6067303717136383}]}, {"text": "Each one maybe transdetailed analysis of existing applied NLG systems formed into some subset of the possible Rhetori-(Cahill and Reape~_~ l:998}:suggested~,that~ttch.an~ ar -~: ~<.", "labels": [], "entities": []}, {"text": "eaLReprese, ntations by,,means ~ofa,set..o_f~.petmitted chitecture was not specific enough and not closely transformations, e.g. reversing the order of nucleus enough adhered to by the majority of the systems surveyed for this to be used as the basis of the architecture.", "labels": [], "entities": []}, {"text": "The abstract functionality of a generation system can be specified without specific reference to processing.", "labels": [], "entities": []}, {"text": "The RAGS approach to this is to develop a data model, that is, to define the functional modules entirely in terms of the datatypes they manipulate and the operations they can perform on them.", "labels": [], "entities": [{"text": "RAGS", "start_pos": 4, "end_pos": 8, "type": "TASK", "confidence": 0.7631820440292358}]}, {"text": "On top of such a model, more specific process models can be created in terms of constraints on the order and level of instantiation of different types of data in the data model.", "labels": [], "entities": []}, {"text": "A 'rational reconstnaction' of some pipeline model might then be produced, but other process models would also be possible.", "labels": [], "entities": []}, {"text": "The RAGS levels of representation are as follows4: Conceptual The conceptual level of representation is defined only indirectly through an API via which a knowledge base (providing the content from which generation takes place) can be viewed as if it were defined in a simple KL-ONE like system.", "labels": [], "entities": []}, {"text": "Abstract Semantic Abstract semantic representations are the first level at which semantic predicates are associated with arguments.", "labels": [], "entities": [{"text": "Abstract Semantic Abstract semantic representations", "start_pos": 0, "end_pos": 51, "type": "TASK", "confidence": 0.5898249685764313}]}, {"text": "At this level, semantic predicates and roles are those used in the API to query the knowledge base and arguments are knowledge base entities.", "labels": [], "entities": []}, {"text": "Semantic (Concrete) semantic representations provide a complete notation for \"logical forms\" where there is no longer any reference to ,the knowledge base.", "labels": [], "entities": []}, {"text": "The representations are based on systems such as SPL and DRT ( ally, but not necessarily, isomorphic to the Rhetorical Representation and linked to it, but with these three features at the nodes instead of rhetorical relations.", "labels": [], "entities": []}, {"text": "Abstract Syntactic Abstract Syntactic Representations capture high-level aspects of syntactic structure in terms of notions such as lexical head, specifiers, modifiers and complements.", "labels": [], "entities": [{"text": "Abstract Syntactic Abstract Syntactic Representations", "start_pos": 0, "end_pos": 53, "type": "TASK", "confidence": 0.5441907644271851}]}, {"text": "This level of representation is compatible with approaches such as LFG f-structure, HPSG and Meteer's Text Structure.", "labels": [], "entities": [{"text": "HPSG", "start_pos": 84, "end_pos": 88, "type": "DATASET", "confidence": 0.928457498550415}]}], "datasetContent": [], "tableCaptions": []}