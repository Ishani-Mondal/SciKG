{"title": [{"text": "Overfitting Avoidance for Stochastic Modeling of Attribute-Value Grammars", "labels": [], "entities": [{"text": "Stochastic Modeling of Attribute-Value Grammars", "start_pos": 26, "end_pos": 73, "type": "TASK", "confidence": 0.7968885421752929}]}], "abstractContent": [{"text": "We present a novel approach to the problem of overfitting in the training of stochastic models for selecting parses generated by attribute-valued grammars.", "labels": [], "entities": []}, {"text": "In this approach, statistical features are merged according to the frequency of linguistic elements within the features.", "labels": [], "entities": []}, {"text": "The resulting models are more general than the original models, and contain fewer parameters.", "labels": [], "entities": []}, {"text": "Empirical results from the task of parse selection suggest that the improvement in performance over repeated iterations of iterative scaling is more reliable with such generalized models than with ungeneralized models.", "labels": [], "entities": [{"text": "parse selection", "start_pos": 35, "end_pos": 50, "type": "TASK", "confidence": 0.9779324531555176}]}], "introductionContent": [{"text": "The maximum entropy technique of statistical modeling using random fields has proved to bean effective way of dealing with a variety of linguistic phenomena, in particular where modeling of attribute-valued grammars (AVG's) is concerned.", "labels": [], "entities": [{"text": "statistical modeling", "start_pos": 33, "end_pos": 53, "type": "TASK", "confidence": 0.8141245245933533}, {"text": "modeling of attribute-valued grammars (AVG's)", "start_pos": 178, "end_pos": 223, "type": "TASK", "confidence": 0.6301992572844028}]}, {"text": "This is largely because its capacity for considering overlapping information sources allows the most to be made of situations where data is sparse.", "labels": [], "entities": []}, {"text": "Nevertheless, it is important that the statistical features employed be appropriate to the job.", "labels": [], "entities": []}, {"text": "If the information contributed by the features is too specific to the training data, overfitting becomes a problem.", "labels": [], "entities": []}, {"text": "In this event, a peak in model performance will be reached early on, and continued training yields progressive deterioration in performance.", "labels": [], "entities": []}, {"text": "From a theoretical standpoint, overfitting indicates that the model distribution is unrepresentative of the actual probabilities.", "labels": [], "entities": []}, {"text": "In practice, it makes the performance of the model dependent upon early stopping of training.", "labels": [], "entities": []}, {"text": "The point at which this must be done is not always reliably predictable.", "labels": [], "entities": []}, {"text": "This paper describes an approach to feature selection for maximum entropy models which reduces the effects of overfitting.", "labels": [], "entities": []}, {"text": "Candidate features are built up from basic grammatical elements found in the corpus.", "labels": [], "entities": []}, {"text": "This \"compositional\" quality of the features is exploited for the purpose of overfitting reduction by means of ]eature merging.", "labels": [], "entities": []}, {"text": "In this process, features which are similar to each other, save for certain elements, are merged; i.e, their disjunction is considered as a feature in itself, thus reducing the number of features in the model.", "labels": [], "entities": []}, {"text": "The motivation behind this methodology is similar to that behind that of, but rather than seeking a proper subset of the candidate feature set, the merging procedure attempts to compress the feature set, diminishing both noise and redundancy.", "labels": [], "entities": []}, {"text": "The method differs from a simple feature cutoff, such as that described in, in that the feature cutoff eliminates statistical features directly, whereas the merging procedure attempts to generalize them.", "labels": [], "entities": []}, {"text": "The method employed here also derives inspiration from the notion of Bayesian model merging introduced by.", "labels": [], "entities": [{"text": "Bayesian model merging", "start_pos": 69, "end_pos": 91, "type": "TASK", "confidence": 0.6644521554311117}]}, {"text": "Section 2 describes parse selection and discusses the \"compositional\" statistical features employed in a maximum entropy approach to the task.", "labels": [], "entities": [{"text": "parse selection", "start_pos": 20, "end_pos": 35, "type": "TASK", "confidence": 0.9312182664871216}]}, {"text": "Section 3 introduces the notion of feature merging and discusses its relationship with overfitting reduction.", "labels": [], "entities": [{"text": "feature merging", "start_pos": 35, "end_pos": 50, "type": "TASK", "confidence": 0.7439797818660736}, {"text": "overfitting reduction", "start_pos": 87, "end_pos": 108, "type": "TASK", "confidence": 0.7444941997528076}]}, {"text": "Sections 4 and 5 describe the experimental models built and the results of merging on their performance.", "labels": [], "entities": []}, {"text": "Finally, section 6 sums up briefly and indicates some further directions for inquiry on the subject.", "labels": [], "entities": []}], "datasetContent": [{"text": "The experiments described here were conducted using the Wall Street Journal Penn Treebank corpus (.", "labels": [], "entities": [{"text": "Wall Street Journal Penn Treebank corpus", "start_pos": 56, "end_pos": 96, "type": "DATASET", "confidence": 0.9674090047677358}]}, {"text": "The grammar used was a manually written broad coverage DCG style grammar).", "labels": [], "entities": []}, {"text": "Parses of WSJ sentences produced by the grammar were ranked empirically using the treebank parse as a gold standard according to a weighted linear combination of crossing brackets, precision, and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 181, "end_pos": 190, "type": "METRIC", "confidence": 0.99953293800354}, {"text": "recall", "start_pos": 196, "end_pos": 202, "type": "METRIC", "confidence": 0.9984551668167114}]}, {"text": "If more than fifty parses were produced fora sentence, the best fifty were used and the rest discarded.", "labels": [], "entities": []}, {"text": "For the training data, the empirical rankings of all parses for each sentence were normalized so the total parse scores for each sentence added to a constant.", "labels": [], "entities": []}, {"text": "The events of the training data consisted of parses and their corresponding normalized score.", "labels": [], "entities": []}, {"text": "These scores were furthermore treated as frequencies.", "labels": [], "entities": []}, {"text": "Thus, high ranked parses would be treated as events occurring more frequently in the training data, and low ranked parses would be treated as occurring rarely.", "labels": [], "entities": []}, {"text": "The features of the unmerged model consisted of depth-one trees carrying node information according to the following schema: the POS tag of the mother, POS tags of all daughters ordered left to right, HEAD+ information for the head daughter, and lexical information for all daughters carrying a verbal or prepositional POS tag.", "labels": [], "entities": []}, {"text": "The features themselves were culled using this schema on 2290 sentences from the training data.", "labels": [], "entities": []}, {"text": "The feature set consisted of 38,056 features in total, of which 6561 were active in the model (assigned non-zero weights) after the final iteration of IIS.", "labels": [], "entities": []}, {"text": "Two models using this feature set were trained, one on only 498 training sentences, a subset of the 2290 sentences used to collect the features, and the other on nearly ten times that number, 4600 training sentences, a superset of the same set of sentences.", "labels": [], "entities": []}, {"text": "Several merged models were made based on each of these unmerged models, using various cutoff numbers.", "labels": [], "entities": []}, {"text": "Cutoffs were set at empirical frequencies of 100, 500, 1000, 1250, and 1500 elements.", "labels": [], "entities": []}, {"text": "For each model merge, all elements which occurred in the training data fewer times than the cutoff number were replaced in each feature they appeared in by the uniform disjunctive element, and the merged features then took the place of the unmerged features.", "labels": [], "entities": []}, {"text": "Iterative scaling was performed for 150 iterations on each model.", "labels": [], "entities": []}, {"text": "This number was chosen arbitrarily as a generous but not gratuitous number of iterations, allowing general trends to be observed.", "labels": [], "entities": []}, {"text": "The models were tested on approximately 5,000 unseen sentences from other parts of the corpus.", "labels": [], "entities": []}, {"text": "The performance of each model was measured at each iteration by binary best match.", "labels": [], "entities": [{"text": "binary best match", "start_pos": 64, "end_pos": 81, "type": "METRIC", "confidence": 0.9309905171394348}]}, {"text": "The model chose a single top parse and if this parse's empirical rank was the highest (or equal to the highest) of all the parses for the sentence, the model was awarded a point for the match, otherwise the model was awarded zero.", "labels": [], "entities": []}, {"text": "The performance rating reflects the percentage of times that the model chose the best parse of all possible parses, averaged overall test sentences.", "labels": [], "entities": []}], "tableCaptions": []}