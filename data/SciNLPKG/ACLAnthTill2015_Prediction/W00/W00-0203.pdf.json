{"title": [{"text": "Evaluation of a Practical Interlingua for Task-Oriented Dialogue", "labels": [], "entities": []}], "abstractContent": [{"text": "IF (Interchange Format), the interlingua used by the C-STAR consortium, is a speech-act based in-terlingua for task-oriented dialogue.", "labels": [], "entities": []}, {"text": "IF was designed as a practical interlingua that could strike a balance between expressivity and simplicity.", "labels": [], "entities": [{"text": "IF", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.8760267496109009}]}, {"text": "If it is too simple, components of meaning will be lost and coverage of unseen data will below.", "labels": [], "entities": [{"text": "coverage", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9763215184211731}]}, {"text": "On the other hand, if it is too complex, it cannot be used with a high degree of consistency by collaborators on different continents.", "labels": [], "entities": [{"text": "consistency", "start_pos": 81, "end_pos": 92, "type": "METRIC", "confidence": 0.9885731935501099}]}, {"text": "In this paper, we suggest methods for evaluating the coverage of IF and the consistency with which it was used in the C-STAR consortium.", "labels": [], "entities": [{"text": "consistency", "start_pos": 76, "end_pos": 87, "type": "METRIC", "confidence": 0.9905852675437927}, {"text": "C-STAR consortium", "start_pos": 118, "end_pos": 135, "type": "DATASET", "confidence": 0.8389632105827332}]}], "introductionContent": [{"text": "IF (Interchange Format) is an interlingua used by the C-STAR consortium 1 for task-oriented dialogues.", "labels": [], "entities": []}, {"text": "Because it is used in five different countries for six different languages, it had to achieve a careful balance between being expressive ehough and being simple enough to be used consistently.", "labels": [], "entities": []}, {"text": "If it was not expressive enough, components of meaning would be lost and coverage of unseen data would below.", "labels": [], "entities": [{"text": "coverage", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.958361804485321}]}, {"text": "On the other hand, if was not simple enough, different system developers would use it inconsistently and the wrong meanings would be translated.", "labels": [], "entities": []}, {"text": "IF is described in our previous papers).", "labels": [], "entities": [{"text": "IF", "start_pos": 0, "end_pos": 2, "type": "METRIC", "confidence": 0.8970945477485657}]}, {"text": "For this paper, we have proposed methods for evaluating the coverage of IF and the degree to which it can be used consistently across C-STAR sites.", "labels": [], "entities": []}, {"text": "Coverage was measured by having human IF specialists annotate unseen data.", "labels": [], "entities": []}, {"text": "Consistency was measured by two means.", "labels": [], "entities": [{"text": "Consistency", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.7324440479278564}]}, {"text": "The first was inter-coder agreement among IF specialists at Carnegie MellonUniversity and ITC-irst (Centre per la ricerca lhttp://www.c-star.org 18 scientifica e tecnologica).", "labels": [], "entities": [{"text": "Carnegie MellonUniversity", "start_pos": 60, "end_pos": 85, "type": "DATASET", "confidence": 0.8558228611946106}, {"text": "ITC-irst", "start_pos": 90, "end_pos": 98, "type": "DATASET", "confidence": 0.8513723015785217}]}, {"text": "The second, less direct method, was a cross-site end-to-end evaluation of English-to-Italian translation where the Englishto-IF analysis grammars were written at CMU and IF-to-Italian generation was developed at IRST.", "labels": [], "entities": [{"text": "CMU", "start_pos": 162, "end_pos": 165, "type": "DATASET", "confidence": 0.9577960968017578}, {"text": "IRST", "start_pos": 212, "end_pos": 216, "type": "DATASET", "confidence": 0.9779558777809143}]}, {"text": "If the English and Italian grammar writers did not agree on the meaning of the IF, wrong translations will be produced.", "labels": [], "entities": []}, {"text": "In this way, the cross-site evaluation can bean indirect indicator of whether the CMU and IRST IF specialists agreed on the meaning of IF representations.", "labels": [], "entities": [{"text": "CMU", "start_pos": 82, "end_pos": 85, "type": "DATASET", "confidence": 0.9556372761726379}, {"text": "IRST IF", "start_pos": 90, "end_pos": 97, "type": "DATASET", "confidence": 0.7299470901489258}]}, {"text": "For comparison, we also present within-site end-to-end evaluations of English-to-German, English-to-Japanese, and English-to-IF-to-English, where all of the analysis and generation grammars were written at CMU.", "labels": [], "entities": [{"text": "CMU", "start_pos": 206, "end_pos": 209, "type": "DATASET", "confidence": 0.9538285136222839}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: The IF Database", "labels": [], "entities": [{"text": "The", "start_pos": 10, "end_pos": 13, "type": "DATASET", "confidence": 0.9199314117431641}, {"text": "IF Database", "start_pos": 14, "end_pos": 25, "type": "DATASET", "confidence": 0.8735118210315704}]}, {"text": " Table 2: Inter-coder Agreement between CMU  and IRST", "labels": [], "entities": [{"text": "IRST", "start_pos": 49, "end_pos": 53, "type": "DATASET", "confidence": 0.7509244084358215}]}]}