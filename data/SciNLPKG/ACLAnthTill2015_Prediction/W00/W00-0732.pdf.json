{"title": [{"text": "Improving Chunking by Means of Lexical-Contextual Information in Statistical Language Models", "labels": [], "entities": [{"text": "Improving Chunking", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8888007402420044}]}], "abstractContent": [], "introductionContent": [{"text": "In this work, we present a stochastic approach to shallow parsing.", "labels": [], "entities": [{"text": "shallow parsing", "start_pos": 50, "end_pos": 65, "type": "TASK", "confidence": 0.662581741809845}]}, {"text": "Most of the current approaches to shallow parsing have a common characteristic: they take the sequence of lexical tags proposed by a POS tagger as input for the chunking process.", "labels": [], "entities": [{"text": "shallow parsing", "start_pos": 34, "end_pos": 49, "type": "TASK", "confidence": 0.7285989224910736}]}, {"text": "Our system produces tagging and chunking in a single process using an Integrated Language Model (ILM) formalized as Markov Models.", "labels": [], "entities": [{"text": "tagging and chunking", "start_pos": 20, "end_pos": 40, "type": "TASK", "confidence": 0.7108624279499054}]}, {"text": "This model integrates several knowledge sources: lexical probabilities, a contextual Language Model (LM) for every chunk, and a contextual LM for the sentences.", "labels": [], "entities": []}, {"text": "We have extended the ILM by adding lexical information to the contextual LMs.", "labels": [], "entities": []}, {"text": "We have applied this approach to the CoNLL-2000 shared task improving the performance of tile chunker.", "labels": [], "entities": [{"text": "tile chunker", "start_pos": 89, "end_pos": 101, "type": "TASK", "confidence": 0.7344585359096527}]}, {"text": "2 Overview of the system The baseline system described in () uses bigrams, formalized as finite-state automata.", "labels": [], "entities": []}, {"text": "It is a transducer composed of two levels (see).", "labels": [], "entities": []}, {"text": "The upper one represents the contextual LM for the sentences.", "labels": [], "entities": []}, {"text": "The symbols associated to the states are POS tags (Ci) and chunk descriptors (Si).", "labels": [], "entities": []}, {"text": "The lower one modelizes the different chunks considered.", "labels": [], "entities": []}, {"text": "In this case, the symbols are the POS tags (Ci) that belong to the corresponding chunk (Si).", "labels": [], "entities": []}, {"text": "Next, a regular substitution of the lower models into the upper level is made.", "labels": [], "entities": []}, {"text": "In this way, we get a single Integrated LM which shows the possible concatenations of lexical tags and chunks.", "labels": [], "entities": []}, {"text": "Also, each state is relabeled with a tuple (Ci, Sj) where Ci E g and Sj E S. g is the POS tag set used and S = {, Si, S0} is the chunk set defined.", "labels": [], "entities": []}, {"text": "stand for the initial and the final state of chunk whose descriptor is Si.", "labels": [], "entities": []}, {"text": "The label Si is assigned to those states which are inside Si chunk, and So is assigned to those states which are outside of any chunk.", "labels": [], "entities": []}, {"text": "All the LMs involved have been smoothed by using a backoff technique.", "labels": [], "entities": []}, {"text": "We have not specified lexical probabilities in every state of the different contextual models.", "labels": [], "entities": []}, {"text": "We assumed that P(WjI(Ci, Si)) = P(WjlCi ) for every Si E S.", "labels": [], "entities": []}, {"text": "Once the integrated transducer has been made, the tagging and shallow parsing process consists of finding the sequence of states of maximum probability on it for an input sentence.", "labels": [], "entities": []}, {"text": "Therefore, this sequence must be compatible with the contextual, syntactical and lexical constraints.", "labels": [], "entities": []}, {"text": "This process can be carried out by dynamic programming using the Viterbi algorithm, which has been appropriately modified to use our models.", "labels": [], "entities": []}, {"text": "From the dynamic programming trellis, we can obtain the maximum probability path for the input sentence through the model, and thus the best sequence of lexical tags and the best segmentation in chunks, in a single process.", "labels": [], "entities": []}], "datasetContent": [{"text": "We applied both approaches (ILM and specialized ILM) using the training and test data of the CoNLL-2000 shared task (http://lcgwww.uia.ac.be/conll2000).", "labels": [], "entities": [{"text": "CoNLL-2000 shared task", "start_pos": 93, "end_pos": 115, "type": "DATASET", "confidence": 0.8315210541089376}]}, {"text": "We also evaluated how the performance of the chunker varies when we modify the specialized word set.", "labels": [], "entities": []}, {"text": "Nevertheless, the use of our approach on other corpora (including different languages), other lexical tag sets or other kinds of chunks can be done in a direct way.", "labels": [], "entities": []}, {"text": "Although our system is able to carryout tagging and chunking in a single process, we will not present tagging results for this task, as the POS tags of the data set used are not supervised and, therefore, a comparison is not possible.", "labels": [], "entities": []}, {"text": "We would like to point out that we have simulated a morphological analyzer for English.", "labels": [], "entities": []}, {"text": "We have constructed a tag dictionary with the lexicon of the training set and the test set used.", "labels": [], "entities": []}, {"text": "This dictionary gave us the possible lexical tags for each word from the corpus.", "labels": [], "entities": []}, {"text": "In no case, was the test used to estimate the lexical probabilities.", "labels": [], "entities": []}, {"text": "As stated above, several criterion can be chosen to define the set of specialized words.", "labels": [], "entities": []}, {"text": "We have selected the most frequent words in the training data set.", "labels": [], "entities": [{"text": "training data set", "start_pos": 48, "end_pos": 65, "type": "DATASET", "confidence": 0.7954023281733195}]}, {"text": "We have not taken into account certain words such as punctuation symbols, proper nouns, numbers, etc.", "labels": [], "entities": []}, {"text": "This fact did not decrease the performance of the chunker and also reduced the number of states of the contextual LMs.", "labels": [], "entities": []}, {"text": "shows how the performance of the chunker (Fz=I) improves as a function of the size of the specialized word set.", "labels": [], "entities": []}, {"text": "The best results were obtained with the set of words whose frequency in the training corpus was larger than 80 (about 470 words).", "labels": [], "entities": []}, {"text": "We obtained similar results when only considering the words of the training set belonging to closed classes (that, about, as, if, out, while, whether, for, to, ...).", "labels": [], "entities": []}, {"text": "In we present the results of chunking with the specialized ILM.", "labels": [], "entities": [{"text": "chunking", "start_pos": 29, "end_pos": 37, "type": "TASK", "confidence": 0.9795531630516052}]}, {"text": "When comparing these results with the results obtained using the basic ILM, we observed that, in general, the F-score was improved for each chunk.", "labels": [], "entities": [{"text": "F-score", "start_pos": 110, "end_pos": 117, "type": "METRIC", "confidence": 0.9986324906349182}]}, {"text": "The best improvement was observed for SBAR (from 0.37 to 79.46), PP (from 88.94 to 95.51) and PRT (38.82 to 66.67).", "labels": [], "entities": [{"text": "SBAR", "start_pos": 38, "end_pos": 42, "type": "METRIC", "confidence": 0.9766724109649658}, {"text": "PP", "start_pos": 65, "end_pos": 67, "type": "METRIC", "confidence": 0.8946759700775146}, {"text": "PRT", "start_pos": 94, "end_pos": 97, "type": "DATASET", "confidence": 0.5165608525276184}]}], "tableCaptions": [{"text": " Table 1: Chunking results using specialized ILM  (Accuracy= 93.79%)", "labels": [], "entities": [{"text": "Chunking", "start_pos": 10, "end_pos": 18, "type": "TASK", "confidence": 0.9519451260566711}, {"text": "Accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.99969482421875}]}]}