{"title": [{"text": "Automatic WordNet mapping using word sense disambiguation*", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 32, "end_pos": 57, "type": "TASK", "confidence": 0.7197580933570862}]}], "abstractContent": [{"text": "This paper presents the automatic construction of a Korean WordNet from pre-existing lexical resources.", "labels": [], "entities": [{"text": "Korean WordNet", "start_pos": 52, "end_pos": 66, "type": "DATASET", "confidence": 0.8284198045730591}]}, {"text": "A set of automatic WSD techniques is described for linking Korean words collected from a bilingual MRD to English WordNet synsets.", "labels": [], "entities": [{"text": "WSD", "start_pos": 19, "end_pos": 22, "type": "TASK", "confidence": 0.9812271595001221}]}, {"text": "We will show how individual linking provided by each WSD method is then combined to produce a Korean WordNet for nouns.", "labels": [], "entities": [{"text": "Korean WordNet", "start_pos": 94, "end_pos": 108, "type": "DATASET", "confidence": 0.8888340294361115}]}], "introductionContent": [{"text": "There is no doubt on the increasing importance of using wide coverage ontologies for NLP tasks especially for information retrieval and cross-language information retrieval.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 110, "end_pos": 131, "type": "TASK", "confidence": 0.8254304230213165}, {"text": "cross-language information retrieval", "start_pos": 136, "end_pos": 172, "type": "TASK", "confidence": 0.7385017474492391}]}, {"text": "While these ontologies exist in English, there are very few available wide range ontologies for other languages.", "labels": [], "entities": []}, {"text": "Manual construction of the ontology by experts is the most reliable technique but is costly and highly time-consuming.", "labels": [], "entities": []}, {"text": "This is the reason for many researchers having focused on massive acquisition of lexical knowledge and semantic information from pre-existing lexical resources as automatically as possible.", "labels": [], "entities": []}, {"text": "This paper presents a novel approach for automatic WordNet mapping using word sense disambiguafion.", "labels": [], "entities": [{"text": "WordNet mapping", "start_pos": 51, "end_pos": 66, "type": "TASK", "confidence": 0.7174949049949646}, {"text": "word sense disambiguafion", "start_pos": 73, "end_pos": 98, "type": "TASK", "confidence": 0.6728134751319885}]}, {"text": "The method has been applied to link Korean words from a bilingual dictionary to English WordNet synsets.", "labels": [], "entities": []}, {"text": "To clarify the description, an example is given.", "labels": [], "entities": []}, {"text": "To link the first sense of Korean word \"gwan-mog\" to WordNet synset, we employ a bilingual Korean-English dictionary.", "labels": [], "entities": [{"text": "WordNet synset", "start_pos": 53, "end_pos": 67, "type": "DATASET", "confidence": 0.95987269282341}]}, {"text": "The first sense of 'gwan-mog' has 'bush' as a translation in English and 'bush' has five synsets in WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 100, "end_pos": 107, "type": "DATASET", "confidence": 0.9725080132484436}]}, {"text": "Therefore the first sense of 'gwan-mog\" has five candidate synsets.", "labels": [], "entities": []}, {"text": "Somehow we decide a synset {shrub, bush} among five candidate synsets and link the sense of 'gwan-mog' to this synset.", "labels": [], "entities": []}, {"text": "As seen from this example, when we link the senses of Korean words to WordNet synsets, there are semantic ambiguities.", "labels": [], "entities": []}, {"text": "To remove the ambiguities we develop new word sense disambiguation heuristics and automatic mapping method to construct Korean WordNet based on the existing English WordNet.", "labels": [], "entities": [{"text": "word sense disambiguation heuristics", "start_pos": 41, "end_pos": 77, "type": "TASK", "confidence": 0.7386485785245895}, {"text": "Korean WordNet", "start_pos": 120, "end_pos": 134, "type": "DATASET", "confidence": 0.9277042150497437}]}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "In section 2, we describe multiple heuristics for word sense disambiguation for sense linking.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 50, "end_pos": 75, "type": "TASK", "confidence": 0.6262316405773163}, {"text": "sense linking", "start_pos": 80, "end_pos": 93, "type": "TASK", "confidence": 0.7117947936058044}]}, {"text": "In section 3, we explain the method of combination for these heuristics.", "labels": [], "entities": []}, {"text": "Section 4 presents some experiment results, and section 5 will discuss some related researches.", "labels": [], "entities": []}, {"text": "Finally we draw some conclusions and future researches in section 6.", "labels": [], "entities": []}, {"text": "The automatic mapping-based Korean WordNet plays a natural Korean-English bilingual thesaurus, so it will be directly applied to Korean-English cross-lingual information retrieval as well as Korean monolingual information retrieval.", "labels": [], "entities": [{"text": "cross-lingual information retrieval", "start_pos": 144, "end_pos": 179, "type": "TASK", "confidence": 0.599385271469752}, {"text": "Korean monolingual information retrieval", "start_pos": 191, "end_pos": 231, "type": "TASK", "confidence": 0.618988148868084}]}], "datasetContent": [{"text": "In this section, we evaluate the performance of each six heuristics as well as the combination method.", "labels": [], "entities": []}, {"text": "To evaluate the performance of WordNet mapping, the candidate synsets of 3260 senses of Korean words in bilingual dictionary was manually classified as linking or discarding.", "labels": [], "entities": [{"text": "WordNet mapping", "start_pos": 31, "end_pos": 46, "type": "TASK", "confidence": 0.759494811296463}]}, {"text": "We define 'precision' as the proportion of correctly linked senses of Korean words to all the linked senses of Korean words in a test set.", "labels": [], "entities": [{"text": "precision", "start_pos": 11, "end_pos": 20, "type": "METRIC", "confidence": 0.9968221187591553}]}, {"text": "We also define 'coverage' as the proportion of linked senses of Korean words to all the senses of Korean words in a test set.", "labels": [], "entities": [{"text": "coverage", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9782337546348572}]}, {"text": "contains the results for each heuristic evaluated individually against the manually classified data.", "labels": [], "entities": []}, {"text": "The test set here consists of the 3260 manually classified senses.", "labels": [], "entities": []}, {"text": "In general, the results of each heuristic seem to be poor, but are always better than the random choice baseline.", "labels": [], "entities": []}, {"text": "The best heuristic according to the precision is the maximum similarity heuristic.", "labels": [], "entities": [{"text": "precision", "start_pos": 36, "end_pos": 45, "type": "METRIC", "confidence": 0.9987865090370178}]}, {"text": "But it was applied to only 59.51% of 3260 senses of Korean words.", "labels": [], "entities": []}, {"text": "The results of each heuristic are better than the random mapping, with a statistically significance at the 99% level.", "labels": [], "entities": []}, {"text": "We performed 10-fold cross validation to evaluate the performance of the combination of all the heuristics using the decision tree -we split the data into ten parts, reserved one part as a validation set, trained the decision tree on the other nine parts and then evaluate the reserved part.", "labels": [], "entities": []}, {"text": "This process is repeated nine times using each of the other nine parts as a validation set.", "labels": [], "entities": []}, {"text": "shows the results of the other trials of the combination of all the heuristics.", "labels": [], "entities": []}, {"text": "Summing is away to simply sum all the scores of each heuristic.", "labels": [], "entities": []}, {"text": "Then the candidate synset which has the highest summation of the scores is selected.", "labels": [], "entities": []}, {"text": "Logistic regression, as described in, is a popular technique for binary classification.", "labels": [], "entities": [{"text": "Logistic regression", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8595859408378601}, {"text": "binary classification", "start_pos": 65, "end_pos": 86, "type": "TASK", "confidence": 0.8272336721420288}]}, {"text": "This technique applies an inverse logit function and employs the iterative reweighted least squares algorithm.", "labels": [], "entities": []}, {"text": "This technique determines the weight of each heuristic.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Individual heuristics performance", "labels": [], "entities": []}, {"text": " Table 2: Performance and comparison of the", "labels": [], "entities": [{"text": "comparison", "start_pos": 26, "end_pos": 36, "type": "METRIC", "confidence": 0.8843228816986084}]}]}