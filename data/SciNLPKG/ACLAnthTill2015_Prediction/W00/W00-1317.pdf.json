{"title": [{"text": "Automated Construction of Database Interfaces: Integrating Statistical and Relational Learning for Semantic Parsing", "labels": [], "entities": [{"text": "Automated Construction of Database Interfaces", "start_pos": 0, "end_pos": 45, "type": "TASK", "confidence": 0.8289659976959228}]}], "abstractContent": [{"text": "The development of natural language interfaces (NLI's) for databases has been a challenging problem in natural language processing (NLP) since the 1970's.", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 103, "end_pos": 136, "type": "TASK", "confidence": 0.7920067807038625}]}, {"text": "The need for NLI's has become more pronounced due to the widespread access to complex databases now available through the Internet.", "labels": [], "entities": []}, {"text": "A challenging problem for empirical NLP is the automated acquisition of NLI's from training examples.", "labels": [], "entities": []}, {"text": "We present a method for integrating statistical and relational learning techniques for this task which exploits the strength of both approaches.", "labels": [], "entities": []}, {"text": "Experimental results from three different domains suggest that such an approach is more robust than a previous purely logic-based approach.", "labels": [], "entities": []}], "introductionContent": [{"text": "We use the term semantic parsing to refer to the process of mapping a natural language sentence to a structured meaning representation.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 16, "end_pos": 32, "type": "TASK", "confidence": 0.7727425694465637}]}, {"text": "One interesting application of semantic parsing is building natural language interfaces for online databases.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 31, "end_pos": 47, "type": "TASK", "confidence": 0.7748339176177979}]}, {"text": "The need for such applications is growing since when information is delivered through the Internet, most users do not know the underlying database access language.", "labels": [], "entities": []}, {"text": "An example of such an interface that we have developed is shown in.", "labels": [], "entities": []}, {"text": "Traditional (rationalist) approaches to constructing database interfaces require an expert to hand-craft an appropriate semantic parser.", "labels": [], "entities": []}, {"text": "However, such hand-crafted parsers are time consllming to develop and suffer from problems with robustness and incompleteness even for domain specific applications.", "labels": [], "entities": []}, {"text": "Nevertheless, very little research in empirical NLP has explored the task of automatically acquiring such interfaces from annotated training examples.", "labels": [], "entities": []}, {"text": "The only exceptions of which we are aware axe a statistical approach to mapping airline-information queries into SQL presented in), a probabilistic decision-tree method for the same task described in, and an approach using relational learning (a.k.a. inductive logic programming, ILP) to learn a logic-based semantic parser described in.", "labels": [], "entities": []}, {"text": "The existing empirical systems for this task employ either a purely logical or purely statistical approach.", "labels": [], "entities": []}, {"text": "The former uses a deterministic parser, which can suffer from some of the same robustness problems as rationalist methods.", "labels": [], "entities": []}, {"text": "The latter constructs a probabilistic grammar, which requires supplying a sytactic parse tree as well as a semantic representation for each training sentence, and requires hand-crafting a small set of contextual features on which to condition the parameters of the model.", "labels": [], "entities": []}, {"text": "Combining relational and statistical approaches can overcome the need to supply parse-trees and hand-crafted features while retaining the robustness of statistical parsing.", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 152, "end_pos": 171, "type": "TASK", "confidence": 0.6704306900501251}]}, {"text": "The current work is based on the CHILL logic-based parser-acquisition framework, retaining access to the complete parse state for making decisions, but building a probabilistic relational model that allows for statistical parsing-2 Overview of the Approach This section reviews our overall approach using an interface developed fora U.S. Geography database (Geoquery) as a sample application which is available on the Web (see hl:tp://gvg, cs. utezas, edu/users/n~./geo .html).", "labels": [], "entities": [{"text": "statistical parsing-2", "start_pos": 210, "end_pos": 231, "type": "TASK", "confidence": 0.6373949497938156}, {"text": "Approach", "start_pos": 248, "end_pos": 256, "type": "METRIC", "confidence": 0.9704827070236206}]}], "datasetContent": [{"text": "The geography corpus contains 560 questions.", "labels": [], "entities": []}, {"text": "Approximately 100 of these were collected from a log of questions submitted to the website and the rest were collected in studies involving students in undergraduate classes at our university.", "labels": [], "entities": []}, {"text": "We also included results for the subset of 250 sentences originally used in the experiments reported in (.", "labels": [], "entities": []}, {"text": "The remaining questions were specificaUy collected to be more complex than the original 250, and generally require one or more meta-predicates.", "labels": [], "entities": []}, {"text": "The restaurant corpus contaln~ 250 questions automatically generated from a hand-built grammar Constructed to reflect typical queries in this domain.", "labels": [], "entities": []}, {"text": "The job corpus contains 400 questions automatically generated in a similar fashion.", "labels": [], "entities": []}, {"text": "The beam width for TABULATE was set~ to five for all the domains.", "labels": [], "entities": [{"text": "beam width", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.6698033511638641}, {"text": "TABULATE", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.7848564982414246}]}, {"text": "The deterministic parser used only the best hypothesis found.", "labels": [], "entities": []}, {"text": "The experiments were conducted using 10-fold cross validation.", "labels": [], "entities": []}, {"text": "For each domain, the average recall (a.k.a. accuracy) and precision of the parser on disjoint test data are reported where: of correct queries produced", "labels": [], "entities": [{"text": "recall", "start_pos": 29, "end_pos": 35, "type": "METRIC", "confidence": 0.9976980090141296}, {"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9716938734054565}, {"text": "precision", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9992495179176331}]}], "tableCaptions": [{"text": " Table 1: Results For All Domains: R = % Recall and P = % Precision. Prob-Parser(B) is  the probabilistic parser using a beam width of B. TABULATE is CHILL using the TABULATE  induction algorithm with determ;nistic parsing.", "labels": [], "entities": [{"text": "Recall", "start_pos": 41, "end_pos": 47, "type": "METRIC", "confidence": 0.9952746629714966}, {"text": "Precision", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9984288811683655}, {"text": "TABULATE", "start_pos": 138, "end_pos": 146, "type": "METRIC", "confidence": 0.9441547393798828}, {"text": "CHILL", "start_pos": 150, "end_pos": 155, "type": "METRIC", "confidence": 0.9035125374794006}, {"text": "nistic parsing", "start_pos": 208, "end_pos": 222, "type": "TASK", "confidence": 0.6986604332923889}]}]}