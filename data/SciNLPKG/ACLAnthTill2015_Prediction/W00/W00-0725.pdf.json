{"title": [{"text": "A Comparison of PCFG Models*", "labels": [], "entities": [{"text": "PCFG Models", "start_pos": 16, "end_pos": 27, "type": "DATASET", "confidence": 0.9059566259384155}]}], "abstractContent": [{"text": "In this paper, we compare three different approaches to build a probabilistic context-free grammar for natural language parsing from a tree bank corpus: 1) a model that simply extracts the rules contained in the corpus and counts the number of occurrences of each rule 2) a model that also stores information about the parent node's category and, 3) a model that estimates the probabilities according to a generalized k-gram scheme with k-3.", "labels": [], "entities": [{"text": "natural language parsing", "start_pos": 103, "end_pos": 127, "type": "TASK", "confidence": 0.7667943636576334}]}, {"text": "The last one allows fora faster parsing and decreases the perplexity of test samples.", "labels": [], "entities": [{"text": "parsing", "start_pos": 32, "end_pos": 39, "type": "TASK", "confidence": 0.9747667908668518}]}], "introductionContent": [{"text": "Recent work has explored the performance of parsers based on a probabilistic context-free grammar (PCFG) extracted from a training corpus.", "labels": [], "entities": []}, {"text": "The results show that the type of tree representation used in the corpus can have a substantial effect in the estimated likelihood of each sentence or parse tree.", "labels": [], "entities": []}, {"text": "According to, weaker independence assumptions --such as decreasing the number of nodes or increasing the number of node labels--improve the efficiency of the parser.", "labels": [], "entities": []}, {"text": "The best results were obtained with parent-annotated labels where each node stores contextual information in the form of the category of the node's parent.", "labels": [], "entities": []}, {"text": "This fact is in agreement with the observation put forward by Charniak) that simple PCFGs, directly obtained from a corpus, largely overgeneralize.", "labels": [], "entities": []}, {"text": "This property suggests that, in these models, a large probability mass is assigned to incorrect * Work partially supported by the Spanish CICYT under grant TIC97-0941.", "labels": [], "entities": [{"text": "Spanish CICYT under grant TIC97-0941", "start_pos": 130, "end_pos": 166, "type": "DATASET", "confidence": 0.6915197730064392}]}, {"text": "parses and, therefore, any procedure that concentrates the probability on the correct parses will increase the likelihood of the samples.", "labels": [], "entities": []}, {"text": "In this spirit, we introduce a generalization of the classic k-gram models, widely used for string processing, to the case of trees.", "labels": [], "entities": [{"text": "string processing", "start_pos": 92, "end_pos": 109, "type": "TASK", "confidence": 0.7027778625488281}]}, {"text": "The PCFG obtained in this way consists of rules that include information about the context where the rule is applied.", "labels": [], "entities": []}, {"text": "The experiments were performed using the Wall Street Journal (WSJ) corpus of the University of Pennsylvania () modified as described in and).", "labels": [], "entities": [{"text": "Wall Street Journal (WSJ) corpus of the University of Pennsylvania", "start_pos": 41, "end_pos": 107, "type": "DATASET", "confidence": 0.959308589498202}]}], "datasetContent": [], "tableCaptions": []}