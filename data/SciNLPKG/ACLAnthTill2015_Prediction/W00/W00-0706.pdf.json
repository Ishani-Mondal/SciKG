{"title": [{"text": "A Comparison between Supervised Learning Algorithms for Word Sense Disambiguation*", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 56, "end_pos": 81, "type": "TASK", "confidence": 0.7685048580169678}]}], "abstractContent": [{"text": "This paper describes a set of comparative experiments , including cross-corpus evaluation, between five alternative algorithms for supervised Word Sense Disambiguation (WSD), namely Naive Bayes, Exemplar-based learning, SNOW, Decision Lists, and Boosting.", "labels": [], "entities": [{"text": "cross-corpus evaluation", "start_pos": 66, "end_pos": 89, "type": "TASK", "confidence": 0.7368311583995819}, {"text": "Word Sense Disambiguation (WSD)", "start_pos": 142, "end_pos": 173, "type": "TASK", "confidence": 0.7612112114826838}]}, {"text": "Two main conclusions can be drawn: 1) The LazyBoosting algorithm outperforms the other four state-of-the-art algorithms in terms of accuracy and ability to tune to new domains; 2) The domain dependence of WSD systems seems very strong and suggests that some kind of adaptation or tuning is required for cross-corpus application.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 132, "end_pos": 140, "type": "METRIC", "confidence": 0.9991649389266968}]}], "introductionContent": [{"text": "Word Sense Disambiguation (WSD) is the problem of assigning the appropriate meaning (or sense) to a given word in a text or discourse.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.796180009841919}, {"text": "assigning the appropriate meaning (or sense) to a given word in a text or discourse", "start_pos": 50, "end_pos": 133, "type": "TASK", "confidence": 0.5937806806143593}]}, {"text": "Resolving the ambiguity of words is a central problem for large scale language understanding applications and their associate tasks.", "labels": [], "entities": [{"text": "Resolving the ambiguity of words", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8803952813148499}]}, {"text": "Besides, WSD is one of the most important open problems in NLP.", "labels": [], "entities": [{"text": "WSD", "start_pos": 9, "end_pos": 12, "type": "TASK", "confidence": 0.898531436920166}]}, {"text": "Despite the wide range of approaches investigated) and the large effort devoted to tackling this problem, to date, no large-scale broad-coverage and highly accurate WSD system has been built.", "labels": [], "entities": [{"text": "WSD", "start_pos": 165, "end_pos": 168, "type": "TASK", "confidence": 0.9623081088066101}]}, {"text": "One of the most successful current lines of research is the corpus-based approach, in which statistical or Machine Learning (M L) algorithms have been applied to learn statistical models or classifiers from corpora in order to per-* This research has been partially funded by the Spanish Research Department (CICYT's project TIC98-0423-C06), by the EU Commission, and by the Catalan Research Department (CIRIT's consolidated research group 1999SGR-150 and CIRIT's grant 1999FI 00773).", "labels": [], "entities": [{"text": "Catalan Research Department (CIRIT's consolidated research group 1999SGR-150", "start_pos": 375, "end_pos": 451, "type": "DATASET", "confidence": 0.6759727776050568}]}, {"text": "Generally, supervised approaches (those that learn from previously semantically annotated corpora) have obtained better results than unsupervised methods on small sets of selected ambiguous words, or artificial pseudowords.", "labels": [], "entities": []}, {"text": "Many standard M L algorithms for supervised learning have been applied, such as: Decision Lists), Neural Networks (, Bayesian learning), Exemplar-based learning,), etc.", "labels": [], "entities": []}, {"text": "Further, in some of the previous methods are compared jointly with Decision Trees and Rule Induction algorithms, on a very restricted domain.", "labels": [], "entities": []}, {"text": "Although some published works include the comparison between some alternative algorithms), none of them addresses the issue of the portability of supervised ML algorithms for WSD, i.e., testing whether the accuracy of a system trained on a certain corpus can be extrapolated to other corpora or not.", "labels": [], "entities": [{"text": "WSD", "start_pos": 175, "end_pos": 178, "type": "TASK", "confidence": 0.927440345287323}, {"text": "accuracy", "start_pos": 206, "end_pos": 214, "type": "METRIC", "confidence": 0.9840625524520874}]}, {"text": "We think that the study of the domain dependence of WSD --in the style of other studies devoted to parsing)--is needed to assure the validity of the supervised approach, and to determine to which extent a tuning pre-process is necessary to make real WSD systems portable.", "labels": [], "entities": [{"text": "WSD", "start_pos": 52, "end_pos": 55, "type": "TASK", "confidence": 0.8682616949081421}, {"text": "parsing", "start_pos": 99, "end_pos": 106, "type": "TASK", "confidence": 0.9671378135681152}]}, {"text": "In this direction, this work compares five different M L algorithms and explores their portability and tuning ability by training and testing them on different corpora.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Accuracy results (=h standard deviation) of the methods on all training-test combinations", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9994745850563049}]}, {"text": " Table 2: Kappa statistic (below diagonal) and  % of agreement (above diagonal) between all  methods in the A+B-A+B experiment", "labels": [], "entities": [{"text": "Kappa statistic", "start_pos": 10, "end_pos": 25, "type": "METRIC", "confidence": 0.8674735128879547}, {"text": "agreement", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.7410408854484558}]}]}