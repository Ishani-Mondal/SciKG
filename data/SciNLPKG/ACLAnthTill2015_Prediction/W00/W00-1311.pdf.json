{"title": [{"text": "Detection of Language (Model) Errors", "labels": [], "entities": [{"text": "Detection of Language (Model) Errors", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.8195569600377764}]}], "abstractContent": [{"text": "The bigram language models are popular, in much language processing applications, in both Indo-European and Asian languages.", "labels": [], "entities": []}, {"text": "However, when the language model for Chinese is applied in a novel domain, the accuracy is reduced significantly, from 96% to 78% in our evaluation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.9996929168701172}]}, {"text": "We apply pattern recognition techniques (i.e. Bayesian, decision tree and neural network classifiers) to discover language model errors.", "labels": [], "entities": [{"text": "pattern recognition", "start_pos": 9, "end_pos": 28, "type": "TASK", "confidence": 0.7233620285987854}]}, {"text": "We have examined 2 general types of features: model-based and language-specific features.", "labels": [], "entities": []}, {"text": "In our evaluation, Bayesian classifiers produce the best recall performance of 80% but the precision is low (60%).", "labels": [], "entities": [{"text": "recall", "start_pos": 57, "end_pos": 63, "type": "METRIC", "confidence": 0.9994381070137024}, {"text": "precision", "start_pos": 91, "end_pos": 100, "type": "METRIC", "confidence": 0.9996064305305481}]}, {"text": "Neural network produced good recall (75%) and precision (80%) but both Bayesian and Neural network have low skip ratio (65%).", "labels": [], "entities": [{"text": "recall", "start_pos": 29, "end_pos": 35, "type": "METRIC", "confidence": 0.9995781779289246}, {"text": "precision", "start_pos": 46, "end_pos": 55, "type": "METRIC", "confidence": 0.9997304081916809}, {"text": "skip ratio", "start_pos": 108, "end_pos": 118, "type": "METRIC", "confidence": 0.987913578748703}]}, {"text": "The decision tree classifier produced the best precision (81%) and skip ratio (76%) but its recall is the lowest (73%).", "labels": [], "entities": [{"text": "precision", "start_pos": 47, "end_pos": 56, "type": "METRIC", "confidence": 0.999360978603363}, {"text": "skip ratio", "start_pos": 67, "end_pos": 77, "type": "METRIC", "confidence": 0.9931510984897614}, {"text": "recall", "start_pos": 92, "end_pos": 98, "type": "METRIC", "confidence": 0.9996678829193115}]}], "introductionContent": [{"text": "Language models are important post-processing modules to improve recognition accuracy of a wide variety of input, namely speech recognition, handwritten recognition) and printed character recognition, for many human languages.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9688161611557007}, {"text": "speech recognition", "start_pos": 121, "end_pos": 139, "type": "TASK", "confidence": 0.7585848271846771}, {"text": "handwritten recognition", "start_pos": 141, "end_pos": 164, "type": "TASK", "confidence": 0.6966375261545181}, {"text": "printed character recognition", "start_pos": 170, "end_pos": 199, "type": "TASK", "confidence": 0.6316330234209696}]}, {"text": "They can also be used for text correction and part-of-speech tagging.", "labels": [], "entities": [{"text": "text correction", "start_pos": 26, "end_pos": 41, "type": "TASK", "confidence": 0.8526556491851807}, {"text": "part-of-speech tagging", "start_pos": 46, "end_pos": 68, "type": "TASK", "confidence": 0.731596440076828}]}, {"text": "For Indo-European languages, the word-bigram language model is used in speech recognition and handwriting recognition.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 71, "end_pos": 89, "type": "TASK", "confidence": 0.7869191765785217}, {"text": "handwriting recognition", "start_pos": 94, "end_pos": 117, "type": "TASK", "confidence": 0.9110594391822815}]}, {"text": "Various ways to improve language models were reported.", "labels": [], "entities": []}, {"text": "First, the model has been extended with longer dependencies (e.g. trigram) and using non-contiguous dependencies, like trigger pairs or long distance n-gram language models).", "labels": [], "entities": []}, {"text": "For better probability estimation, the model was extended to work with (hidden) word classes.", "labels": [], "entities": [{"text": "probability estimation", "start_pos": 11, "end_pos": 33, "type": "TASK", "confidence": 0.682482898235321}]}, {"text": "A more error-driven approach is the use of hybrid language models, in which some detection mechanism (e.g. perplexity measures or topic detection) selects or combines with a more appropriate language model.", "labels": [], "entities": [{"text": "topic detection", "start_pos": 130, "end_pos": 145, "type": "TASK", "confidence": 0.7561377882957458}]}, {"text": "For Asian languages (e.g. Chinese, Japanese and Korean) represented by ideographic characters, language models are widely used in computer entry because these Asian languages have a large set of characters (in thousands) that the conventional keyboard is not designed for.", "labels": [], "entities": [{"text": "computer entry", "start_pos": 130, "end_pos": 144, "type": "TASK", "confidence": 0.6552182137966156}]}, {"text": "Apart from using speech and handwriting recognition for computer entry, language models for Asian languages can be used for sentence-based keyboard input (e.g., as well as detecting improper writing (e.g. dialectspecific words or expressions).", "labels": [], "entities": [{"text": "handwriting recognition", "start_pos": 28, "end_pos": 51, "type": "TASK", "confidence": 0.7189643085002899}, {"text": "computer entry", "start_pos": 56, "end_pos": 70, "type": "TASK", "confidence": 0.6417917758226395}]}, {"text": "Unlike Indo-European languages, words in these Asian languages are not delimited by space and conventional approximate string matching techniques () in handwriting recognition are seldom used in Asian language models.", "labels": [], "entities": [{"text": "handwriting recognition", "start_pos": 152, "end_pos": 175, "type": "TASK", "confidence": 0.8843165338039398}]}, {"text": "Instead, a widely used and reported Asian language model is the character-bigram language model) because it (1) achieved high recognition accuracy (around 90-96%) (2) is easy to estimate model parameters (3) can be processed quickly and (4) is relatively easy to implement.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 138, "end_pos": 146, "type": "METRIC", "confidence": 0.8295642733573914}]}, {"text": "Improvement of these language models for IndoEuropean languages can be applied for the Asian languages but words need to be identified.", "labels": [], "entities": []}, {"text": "For Asian languages, the model was integrated with syntactic rules.", "labels": [], "entities": []}, {"text": "Class based language model ( was also examined but the classes are based on semantically related words.", "labels": [], "entities": []}, {"text": "A-new approach) is reported using segments expressed by prefix and suffix trees but the comparison is based on perplexity measures, which may not correlate well with recognition improvement ().", "labels": [], "entities": []}, {"text": "While attempts to improve the; (bigram) language models were (quite) successful, the high recognition accuracy (about 96%) is not adequate for professional data entry services, which typically require an error rate lower than 1 in 1,000.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 102, "end_pos": 110, "type": "METRIC", "confidence": 0.8982529044151306}, {"text": "error rate", "start_pos": 204, "end_pos": 214, "type": "METRIC", "confidence": 0.9332616925239563}]}, {"text": "As part of the quality control exercises, these services estimate their error rate by sampling, and they identify and correct the errors manually to achieve the required quality.", "labels": [], "entities": []}, {"text": "Faced with a large volume of text, the ability to automatically identify where the errors are is perhaps more important than automatically correcting errors, in post-editing because (1) manual correction is more reliable than automatic correction, (2) manual error sampling can be carried out and (3) more manual efforts are required in error identification than correction due to the large volume of text.", "labels": [], "entities": [{"text": "error identification", "start_pos": 337, "end_pos": 357, "type": "TASK", "confidence": 0.684272050857544}]}, {"text": "For example, if the identification of errors is 97% and there are no errors in error correction, then the accuracy of the language model is improved from 96% to 99.9% after error correction.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 106, "end_pos": 114, "type": "METRIC", "confidence": 0.9994995594024658}]}, {"text": "In typical applications, the accuracy of the bigram language model may not be as high as those reported in the literature because the data maybe in a different genre than that of the training data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9995852112770081}]}, {"text": "For evaluation, we tested a bigram language model with text from a novel domain and its accuracy dropped significantly from 96% to 78%, which is similar to).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.9996519088745117}]}, {"text": "Improvement in the robustness of the bigram language model across different genre is necessary and several approaches are available, based on detecting errors of the language model.", "labels": [], "entities": []}, {"text": "One (adaptive) approach is to automatically identify the errors and manually correcting them.", "labels": [], "entities": []}, {"text": "The information about the correction of errors is used to improve the bigram language model.", "labels": [], "entities": []}, {"text": "For example, the bigram probabilities of the language model maybe estimated and updated with the corrected data.", "labels": [], "entities": []}, {"text": "In this way, future occurrences of these errors are reduced.", "labels": [], "entities": []}, {"text": "Another (hybrid) approach uses another language model to correct the identified errors.", "labels": [], "entities": []}, {"text": "This language model can be computationally more expensive than the bigram language model because it is applied only to the identified errors.", "labels": [], "entities": []}, {"text": "Also, topic detection () and language model selection ( can be applied to those area to find a more appropriate language model because usually topic-dependent words are those causing errors.", "labels": [], "entities": [{"text": "topic detection", "start_pos": 6, "end_pos": 21, "type": "TASK", "confidence": 0.8667356371879578}, {"text": "language model selection", "start_pos": 29, "end_pos": 53, "type": "TASK", "confidence": 0.6632386744022369}]}, {"text": "Another (integrative) approach improves the language model accuracy using more sophisticated recognizers, instead of a complementary language model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9959120750427246}]}, {"text": "The more sophisticated recognizer may give a set of different results that the bigram language model can re-apply on or this recognizer simply gives the recognized character.", "labels": [], "entities": []}, {"text": "This integrates well with the coarse-fine recognition architecture proposed by back in the 1960s.", "labels": [], "entities": []}, {"text": "Coarse recognition provides the candidates for the language model to select.", "labels": [], "entities": [{"text": "Coarse recognition", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8142105638980865}]}, {"text": "Fine, expensive recognition is carried out only where the language models failed.", "labels": [], "entities": []}, {"text": "Finally, it is possible to combine all the different approaches (i.e. adaptive, hybrid and integrative).", "labels": [], "entities": []}, {"text": "Given the significance in detecting errors of language models, there is little work in this area.", "labels": [], "entities": []}, {"text": "Perhaps, it was considered that these errors were random and therefore hard to detect.", "labels": [], "entities": []}, {"text": "However, users can detect errors quickly.", "labels": [], "entities": []}, {"text": "We suspect that some of these errors maybe systematic due to the properties of the language model used or due to language specific properties.", "labels": [], "entities": []}, {"text": "We adopt a pattern recognition app~'~z, ch to detecting errors of the bigram language rnoaei for the Chinese language.", "labels": [], "entities": []}, {"text": "Each output is assigned to either the class of correct output or the class of errors.", "labels": [], "entities": []}, {"text": "The assignment of a class to an output is based on a set of features.", "labels": [], "entities": []}, {"text": "We explore a number of features to detect errors, which are classified into model-based features and language-specific features.", "labels": [], "entities": []}, {"text": "The proposed approach can work with IndoEuropean languages at the word-bigram level.", "labels": [], "entities": []}, {"text": "However, language-specific features have to be discovered for the particular language.", "labels": [], "entities": []}, {"text": "In addition, this approach can be adopted for n-gram language models.", "labels": [], "entities": []}, {"text": "In principal, the model-based features can be found or evaluated similar to the bigram language model.", "labels": [], "entities": []}, {"text": "For example, if the trigram probability (instead of bigram probability) is low, then the likelihood of a language model error is high.", "labels": [], "entities": []}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 1 discusses various features and some preliminary evaluation of their suitability for error identification.", "labels": [], "entities": [{"text": "error identification", "start_pos": 94, "end_pos": 114, "type": "TASK", "confidence": 0.6631520688533783}]}, {"text": "Section 2 describes 3 types of classifiers used.", "labels": [], "entities": []}, {"text": "In section 3, our evaluation is reported.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the evaluation, the training data is the PH corpus and the test data is the YZZK magazine articles (4+ Mbytes), downloaded from the Internet.", "labels": [], "entities": [{"text": "PH corpus", "start_pos": 44, "end_pos": 53, "type": "DATASET", "confidence": 0.9315193891525269}, {"text": "YZZK magazine articles", "start_pos": 79, "end_pos": 101, "type": "DATASET", "confidence": 0.9184190432230631}]}, {"text": "In handwritten character recognition, the optimal size of the number of candidates is 6 (.", "labels": [], "entities": [{"text": "handwritten character recognition", "start_pos": 3, "end_pos": 36, "type": "TASK", "confidence": 0.7018354733784994}]}, {"text": "For robustness, each recognized character in our evaluation is selected from 10 candidates.", "labels": [], "entities": []}, {"text": "We measured the performance in terms of recall, precision and the manual effort reduction in scanning the text for errors.", "labels": [], "entities": [{"text": "recall", "start_pos": 40, "end_pos": 46, "type": "METRIC", "confidence": 0.9996286630630493}, {"text": "precision", "start_pos": 48, "end_pos": 57, "type": "METRIC", "confidence": 0.9996545314788818}]}, {"text": "The recall is the number of identified errors over the total number of errors.", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9994891881942749}]}, {"text": "The precision is the number of identified errors over the total number of cases classified as errors.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9990697503089905}]}, {"text": "The amount of saving in manual scanning for errors is called the skip ratio, which is the number of blocks classified as correct over the total number of blocks.", "labels": [], "entities": [{"text": "skip ratio", "start_pos": 65, "end_pos": 75, "type": "METRIC", "confidence": 0.9935497343540192}]}, {"text": "The recall and the skip ratio are more important than the precision because post error correction (manual or automatic) can improve the recognition accuracy.", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.999697208404541}, {"text": "skip ratio", "start_pos": 19, "end_pos": 29, "type": "METRIC", "confidence": 0.9897592067718506}, {"text": "precision", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9996888637542725}, {"text": "accuracy", "start_pos": 148, "end_pos": 156, "type": "METRIC", "confidence": 0.9634479284286499}]}, {"text": "It is possible to combine the recall and precision into one, using the F measures) but the value for rating the relative importance is subjective.", "labels": [], "entities": [{"text": "recall", "start_pos": 30, "end_pos": 36, "type": "METRIC", "confidence": 0.9994587302207947}, {"text": "precision", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.9974061846733093}, {"text": "F", "start_pos": 71, "end_pos": 72, "type": "METRIC", "confidence": 0.9959797859191895}]}, {"text": "shows the classification performance of the Bayesian classifier.", "labels": [], "entities": []}, {"text": "The recall of errors by the Bayesian classifier has reduced slightly from 83% using a single classifier to 79% using 3 classifiers but the precision improved from 51% to 60%.", "labels": [], "entities": [{"text": "recall of errors", "start_pos": 4, "end_pos": 20, "type": "METRIC", "confidence": 0.9142283995946249}, {"text": "precision", "start_pos": 139, "end_pos": 148, "type": "METRIC", "confidence": 0.9996516704559326}]}, {"text": "Also, the skip ratio is 65%, which is much higher than the skip ratio of 0.1% if we did not use the classifier.", "labels": [], "entities": [{"text": "skip ratio", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9880840182304382}, {"text": "skip ratio", "start_pos": 59, "end_pos": 69, "type": "METRIC", "confidence": 0.9817438125610352}]}, {"text": "Although the MLP has a higher precision (80%), its recall is slightly lower than the Bayesian classifier.", "labels": [], "entities": [{"text": "precision", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.999021053314209}, {"text": "recall", "start_pos": 51, "end_pos": 57, "type": "METRIC", "confidence": 0.9997469782829285}]}, {"text": "The skip ratio of the both Bayesian and MLP classifiers are about the same. of the 3 types of classifiers in detecting language model errors.", "labels": [], "entities": [{"text": "skip ratio", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9753300249576569}, {"text": "detecting language model errors", "start_pos": 109, "end_pos": 140, "type": "TASK", "confidence": 0.856761023402214}]}], "tableCaptions": []}