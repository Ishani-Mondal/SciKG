{"title": [], "abstractContent": [{"text": "Contextual information and the mapping from WordNet synsets to Cilin sense tags deal with word sense disambiguation.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 90, "end_pos": 115, "type": "TASK", "confidence": 0.7238577008247375}]}, {"text": "The average performance is 63.36% when small categories are used, and 1, 2 and 3 candidates are proposed for low, middle and high ambiguous words.", "labels": [], "entities": []}, {"text": "The performance of tagging unknown words is 34.35%, which is much better than that of baseline mode.", "labels": [], "entities": [{"text": "tagging unknown words", "start_pos": 19, "end_pos": 40, "type": "TASK", "confidence": 0.9078572591145834}]}, {"text": "The sense tagger achieves the performance of 76.04%, when unambiguous, ambiguous, and unknown words are tagged.", "labels": [], "entities": [{"text": "sense tagger", "start_pos": 4, "end_pos": 16, "type": "TASK", "confidence": 0.6507777124643326}]}, {"text": "1 Introduction Tagging task, which adds lexical, syntactic or semantic information to raw text, makes materials more valuable.", "labels": [], "entities": [{"text": "Tagging task", "start_pos": 15, "end_pos": 27, "type": "TASK", "confidence": 0.8624043464660645}]}, {"text": "The researches on part of speech (POS) tagging have been along history, and achieve very good results.", "labels": [], "entities": [{"text": "part of speech (POS) tagging", "start_pos": 18, "end_pos": 46, "type": "TASK", "confidence": 0.6486479341983795}]}, {"text": "Many POS-tagged corpora are available.", "labels": [], "entities": []}, {"text": "The accuracy for POS-tagging is in the range of 95% to 97% 1.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9997891783714294}]}, {"text": "In contrast, although the researches on word sense disambiguation (WSD) are also very early (Kelly and Stone, 1975), large-scale sense-tagged corpus is relatively few.", "labels": [], "entities": [{"text": "word sense disambiguation (WSD)", "start_pos": 40, "end_pos": 71, "type": "TASK", "confidence": 0.802963599562645}]}, {"text": "In English, only some sense-tagged corpora such as are available.", "labels": [], "entities": []}, {"text": "For evaluating word sense disarnbiguation systems, the first SENSEVAL (Kilgarriff and Rosenzweig, 2000) reports that the performance fora fine-grained word sense disambiguation task is at around 75 %.", "labels": [], "entities": [{"text": "word sense disarnbiguation", "start_pos": 15, "end_pos": 41, "type": "TASK", "confidence": 0.7298149267832438}, {"text": "word sense disambiguation task", "start_pos": 151, "end_pos": 181, "type": "TASK", "confidence": 0.706144168972969}]}], "introductionContent": [{"text": "Tagging task, which adds lexical, syntactic or semantic information to raw text, makes materials more valuable.", "labels": [], "entities": [{"text": "Tagging task", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.8820685148239136}]}, {"text": "The researches on part of speech (POS) tagging have been along history, and achieve very good results.", "labels": [], "entities": [{"text": "part of speech (POS) tagging", "start_pos": 18, "end_pos": 46, "type": "TASK", "confidence": 0.6486479341983795}]}, {"text": "Many POS-tagged corpora are available.", "labels": [], "entities": []}, {"text": "The accuracy for POS-tagging is in the range of 95% to 97% 1 . In contrast, although the researches on word sense disambiguation (WSD) are also very early, large-scale sense-tagged corpus is relatively few.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9996065497398376}, {"text": "word sense disambiguation (WSD)", "start_pos": 103, "end_pos": 134, "type": "TASK", "confidence": 0.7733346124490103}]}, {"text": "In English, only some sense-tagged corpora such as HECTOR,, SEMCOR, and SENSEVAL are available.", "labels": [], "entities": [{"text": "HECTOR", "start_pos": 51, "end_pos": 57, "type": "METRIC", "confidence": 0.7051644325256348}, {"text": "SEMCOR", "start_pos": 60, "end_pos": 66, "type": "METRIC", "confidence": 0.7538423538208008}, {"text": "SENSEVAL", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.605575442314148}]}, {"text": "For evaluating word sense disarnbiguation systems, the first SENSEVAL) reports that the performance fora fine-grained word sense disambiguation task is at around 75 %.", "labels": [], "entities": [{"text": "word sense disarnbiguation", "start_pos": 15, "end_pos": 41, "type": "TASK", "confidence": 0.7375611265500387}, {"text": "word sense disambiguation task", "start_pos": 118, "end_pos": 148, "type": "TASK", "confidence": 0.7155491635203362}]}, {"text": "The pelrforlnancg includes tagging wnzmbiguous.", "labels": [], "entities": []}, {"text": "reported that the performance of CLAWS tagger is 94%.", "labels": [], "entities": [{"text": "CLAWS tagger", "start_pos": 33, "end_pos": 45, "type": "TASK", "confidence": 0.7356877028942108}]}, {"text": "Approximately 65% of words were tagged nnambiguously, and the disambigualion program achieved better than 80% success on the ambiguous words.", "labels": [], "entities": []}, {"text": "Tagging accuracy depends on several issues), e.g., the amount of training data, the granularity of the tagging set, the occurrences of unknown words, and soon.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 8, "end_pos": 16, "type": "METRIC", "confidence": 0.9451786279678345}]}, {"text": "Three approaches have been proposed for WSD, including dictionary/thesaurus-based approach, supervised learning, and unsupervised learning.", "labels": [], "entities": [{"text": "WSD", "start_pos": 40, "end_pos": 43, "type": "TASK", "confidence": 0.9907200336456299}]}, {"text": "The major differences are what kinds of resources are used, i.e., dictionary versus text corpus, and sense-tagged corpus versus untagged eorpns.", "labels": [], "entities": []}, {"text": "A good survey refers to the paper).", "labels": [], "entities": []}, {"text": "Compared with English, Chinese does not have large-scale sense-tagged corpus.", "labels": [], "entities": []}, {"text": "The widely available corpus is Academic Sinica Balanced Corpus abbreviated as ASBC hereafter, which is a POS-tagged corpus.", "labels": [], "entities": [{"text": "Academic Sinica Balanced Corpus abbreviated as ASBC", "start_pos": 31, "end_pos": 82, "type": "DATASET", "confidence": 0.8453619480133057}]}, {"text": "Thus, a computer-aided tool to sense-tag Chinese corpus is indispensable.", "labels": [], "entities": []}, {"text": "This paper presents a sense tagger for Mandarin Chinese.", "labels": [], "entities": []}, {"text": "It is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 discusses the degree of polysemy in Mandarin Chinese from several viewpoints.", "labels": [], "entities": []}, {"text": "Section 3 presents WSD algorithms for tagging ambiguous words and unknown words.", "labels": [], "entities": [{"text": "WSD", "start_pos": 19, "end_pos": 22, "type": "TASK", "confidence": 0.9452418088912964}, {"text": "tagging ambiguous words", "start_pos": 38, "end_pos": 61, "type": "TASK", "confidence": 0.8897547721862793}]}, {"text": "Section 4 shows our experimental results.", "labels": [], "entities": []}, {"text": "Finally, Section 5 concludes the remarks.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1. The Distribution of Word Senses  Low Ambiguity  Degree  #Word Types  2  4261 (71.95%)  3  948 (16.01%)  4  -344 (5.81%)", "labels": [], "entities": [{"text": "Ambiguity  Degree", "start_pos": 47, "end_pos": 64, "type": "METRIC", "confidence": 0.867585688829422}]}, {"text": " Table 3. The Distribution of Word Senses with Consideration of Frequencies  Low Ambiguity  Middle Ambiguity  High Ambiguity  Types I Tokens I #Tokens/  #Types", "labels": [], "entities": []}, {"text": " Table 4. The Distribution of Word Senses andFrequencies with Consideration of POS,", "labels": [], "entities": []}, {"text": " Table 5. Performance of Tagging Ambi[  \"''--....Ambiguity  Word Tokem~  Low  Middle  Total Tokens  6601  3511  Correct Tokens  4132  1101  Correct Rate  62.60%  31.36%", "labels": [], "entities": [{"text": "Correct Rate", "start_pos": 140, "end_pos": 152, "type": "METRIC", "confidence": 0.7308439016342163}]}, {"text": " Table 7. Performance of Tagging usin t", "labels": [], "entities": [{"text": "Tagging", "start_pos": 25, "end_pos": 32, "type": "TASK", "confidence": 0.9186188578605652}]}, {"text": " Table 8. Performance of Ta,", "labels": [], "entities": [{"text": "Performance", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9869176745414734}, {"text": "Ta", "start_pos": 25, "end_pos": 27, "type": "METRIC", "confidence": 0.7353535890579224}]}]}