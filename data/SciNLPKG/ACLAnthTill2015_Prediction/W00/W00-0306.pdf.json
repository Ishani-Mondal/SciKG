{"title": [{"text": "Stochastic Language Generation for Spoken Dialogue Systems", "labels": [], "entities": [{"text": "Stochastic Language Generation", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7056879798571268}]}], "abstractContent": [{"text": "The two current approaches to language generation, Template-based and rule-based (linguistic) NLG, have limitations when applied to spoken dialogue systems, in part because they were developed for text generation.", "labels": [], "entities": [{"text": "language generation", "start_pos": 30, "end_pos": 49, "type": "TASK", "confidence": 0.7670157551765442}, {"text": "text generation", "start_pos": 197, "end_pos": 212, "type": "TASK", "confidence": 0.721657395362854}]}, {"text": "In this paper, we propose anew corpus-based approach to natural language generation, specifically designed for spoken dialogue systems.", "labels": [], "entities": [{"text": "natural language generation", "start_pos": 56, "end_pos": 83, "type": "TASK", "confidence": 0.6831321318944296}]}], "introductionContent": [{"text": "Several general-purpose rule-based generation systems have been developed, some of which are available publicly (cf..", "labels": [], "entities": []}, {"text": "Unfortunately these systems, because of their generality, can be difficult to adapt to small, task-oriented applications.", "labels": [], "entities": []}, {"text": "have described a lower cost and more efficient generation system fora specific application using an automatically customized subgrammar.", "labels": [], "entities": []}, {"text": "describe a system that mixes templates and rulebased generation.", "labels": [], "entities": []}, {"text": "This approach takes advantages of templates and rule-based generation as needed by specific sentences or utterances. has proposed a similar approach fora spoken dialogue system.", "labels": [], "entities": []}, {"text": "However, there is still the burden of writing and maintaining grammar rules, and processing time is probably too slow for sentences using grammar rules (only the average time for templates and rule-based sentences combined is reported in), for use in spoken dialogue systems.", "labels": [], "entities": []}, {"text": "Because comparatively less effort is needed, many current dialogue systems use templatebased generation.", "labels": [], "entities": []}, {"text": "But there is one obvious disadvantage: the quality of the output depends entirely on the set of templates.", "labels": [], "entities": []}, {"text": "Even in a relatively simple domain, such as travel reservations, the number of templates necessary for reasonable quality can become quite large that maintenance becomes a serious problem.", "labels": [], "entities": [{"text": "travel reservations", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.7009423077106476}]}, {"text": "There is an unavoidfible trade-off between the amount of time and effort in creating and maintaining templates and the variety and quality of the output utterances.", "labels": [], "entities": []}, {"text": "Given these shortcomings of the above approaches, we developed a corpus-based generation system, in which we model language spoken by domain experts performing the task of interest, and use that model to stochastically generate system utterances.", "labels": [], "entities": []}, {"text": "We have applied this technique to sentence realization and content planning, and have incorporated the resulting generation component into a working natural dialogue system (see.", "labels": [], "entities": [{"text": "sentence realization", "start_pos": 34, "end_pos": 54, "type": "TASK", "confidence": 0.7684227526187897}, {"text": "content planning", "start_pos": 59, "end_pos": 75, "type": "TASK", "confidence": 0.7225406467914581}]}, {"text": "In this paper, we describe the technique and report the results of two evaluations.", "labels": [], "entities": []}, {"text": "We used two corpora in the travel reservations domain to build n-gram language models.", "labels": [], "entities": []}, {"text": "One corpus (henceforth, the CMU corpus) consists of 39 dialogues between a travel agent and clients).", "labels": [], "entities": [{"text": "CMU corpus", "start_pos": 28, "end_pos": 38, "type": "DATASET", "confidence": 0.9260697662830353}]}, {"text": "Another corpus (henceforth, the SRI corpus) consists of 68 dialogues between a travel agent and users in the SRI community.", "labels": [], "entities": [{"text": "SRI corpus", "start_pos": 32, "end_pos": 42, "type": "DATASET", "confidence": 0.7992319166660309}]}, {"text": "The utterances in the two corpora were tagged with utterance classes and word classes (see and).", "labels": [], "entities": []}, {"text": "The CMU corpus was manually tagged, and back-off trigram models built (using.", "labels": [], "entities": [{"text": "CMU corpus", "start_pos": 4, "end_pos": 14, "type": "DATASET", "confidence": 0.9553000926971436}]}, {"text": "These language models were used to automatically tag the SRI corpus; the tags were manually checked.", "labels": [], "entities": [{"text": "SRI corpus", "start_pos": 57, "end_pos": 67, "type": "DATASET", "confidence": 0.7116518020629883}]}], "datasetContent": [{"text": "It is generally difficult to empirically evaluate a generation system.", "labels": [], "entities": []}, {"text": "In the context of spoken dialogue systems, evaluation of NLG becomes an even more difficult problem.", "labels": [], "entities": [{"text": "evaluation of NLG", "start_pos": 43, "end_pos": 60, "type": "TASK", "confidence": 0.6170671582221985}]}, {"text": "One reason is simply that there has been very little effort in building generation engines for spoken dialogue systems.", "labels": [], "entities": []}, {"text": "Another reason is that it is hard to separate NLG from the rest of the system.", "labels": [], "entities": []}, {"text": "It is especially hard to separate evaluation of language generation and speech synthesis.", "labels": [], "entities": [{"text": "language generation", "start_pos": 48, "end_pos": 67, "type": "TASK", "confidence": 0.7170871496200562}, {"text": "speech synthesis", "start_pos": 72, "end_pos": 88, "type": "TASK", "confidence": 0.7140917927026749}]}, {"text": "As a simple solution, we have conducted a comparative evaluation by running two identical systems varying only the generation component.", "labels": [], "entities": []}, {"text": "In this section we present results from two preliminary evaluations of our generation algorithms described in the previous sections.", "labels": [], "entities": []}, {"text": "For the content planning part of the generation -system, we conducted a comparative evaluation of the two different generation algorithms: old/new and bigrams.", "labels": [], "entities": []}, {"text": "Twelve subjects had two dialogues each, one with the old/new generation system, and another with the bigrams generation system (in counterbalanced order); all other modules were held fixed.", "labels": [], "entities": []}, {"text": "Afterwards, each subject answered seven questions on a usability survey.", "labels": [], "entities": []}, {"text": "Immediately after, each subject was given transcribed logs of his/her dialogues and asked to rate each system utterance on a scale of 1 to 3 (1 = good; 2 = okay; 3 = bad).", "labels": [], "entities": []}, {"text": "For surface realization, we conducted a batchmode evaluation.", "labels": [], "entities": [{"text": "surface realization", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.761205404996872}]}, {"text": "We picked six recent calls to our system and ran two generation algorithms (template-based generation and stochastic generation) on the input frames.", "labels": [], "entities": []}, {"text": "We then presented to seven subjects the generated dialogues, consisting of decoder output of the user utterances and corresponding system responses, for each of the two generation algorithms.", "labels": [], "entities": []}, {"text": "Subjects then selected the output utterance they would prefer, for each of the utterances that differ between the two systems.", "labels": [], "entities": []}, {"text": "The results show a trend that subjects preferred stochastic generation over template-based generation, but a t-test shows no significant difference (p = 0.18).", "labels": [], "entities": []}, {"text": "We are in the process of designing a larger evaluation.", "labels": [], "entities": []}], "tableCaptions": []}