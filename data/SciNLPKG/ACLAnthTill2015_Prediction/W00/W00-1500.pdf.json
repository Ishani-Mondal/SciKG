{"title": [], "abstractContent": [{"text": "Many toolsets have been developed to support the implementation of single NLP components (taggers, parsers, generators, dictionaries) or complete Natural Language Processing applications (Information Extraction systems, Machine Translation systems).", "labels": [], "entities": [{"text": "Information Extraction", "start_pos": 188, "end_pos": 210, "type": "TASK", "confidence": 0.7067356109619141}, {"text": "Machine Translation", "start_pos": 220, "end_pos": 239, "type": "TASK", "confidence": 0.7564808130264282}]}, {"text": "A source for available toolkits is the Natural Language Software Registry, an initiative of the Association for Computational Linguistics hosted by DFKI at http://registry.dfki.de.", "labels": [], "entities": [{"text": "DFKI", "start_pos": 148, "end_pos": 152, "type": "DATASET", "confidence": 0.9392864108085632}]}, {"text": "These tools aim at facilitating and lowering the cost of building NLP systems.", "labels": [], "entities": []}, {"text": "Since the tools themselves are often complex pieces of software, they require a significant amount of effort to be developed and maintained in the first place.", "labels": [], "entities": []}, {"text": "Is this effort worth the trouble?", "labels": [], "entities": []}, {"text": "It is to be noted that NLP toolsets have often been originally developed for implementing a single component or application.", "labels": [], "entities": []}, {"text": "In this case, why not build the NLP system using a general programming language such as Lisp or Prolog?", "labels": [], "entities": []}, {"text": "There can beat least two answers.", "labels": [], "entities": []}, {"text": "First, for pure efficiency issues (speed and space), it is often preferable to build a parameterized algorithm operating on a uniform data structure (e.g., a phrase-structure parser).", "labels": [], "entities": []}, {"text": "Second, it is harder, and often impossible, to develop, debug and maintain a large NLP system directly written in a general programming language.", "labels": [], "entities": []}, {"text": "It has been the experience of many users that a given toolset is quite often unusable outside its environment: the toolset can be too restricted in its purpose (e.g. an MT toolset that cannot be used for building a grammar checker), too complex to use, or even too difficult to install.", "labels": [], "entities": []}, {"text": "There have been, in particular in the US under the Tipster program, efforts to promote instead common architectures fora given set of applications (primarily IR and IE in Tipster; see also the Galaxy architecture of the DARPA Communicator project).", "labels": [], "entities": []}, {"text": "Several software environments have been built around this flexible concept, which is closer to current trends in mainstream software engineering.", "labels": [], "entities": []}, {"text": "The workshop aims at providing a picture of the current problems faced by developers and users of toolsets, and future directions for the development and use of NLP toolsets.", "labels": [], "entities": []}, {"text": "It includes reports of actual experiences in the use of toolsets as well as presentation of toolsets and application development.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}