{"title": [{"text": "Centroid-based summarization of multiple documents: sentence extraction, utility-based evaluation, and user studies", "labels": [], "entities": [{"text": "sentence extraction", "start_pos": 52, "end_pos": 71, "type": "TASK", "confidence": 0.7454768419265747}]}], "abstractContent": [{"text": "We present a multi-document summarizer, called MEAD, which generates summaries using cluster centroids produced by a topic detection and tracking system.", "labels": [], "entities": [{"text": "MEAD", "start_pos": 47, "end_pos": 51, "type": "METRIC", "confidence": 0.9109688997268677}, {"text": "topic detection and tracking", "start_pos": 117, "end_pos": 145, "type": "TASK", "confidence": 0.8175317198038101}]}, {"text": "We also describe two new techniques, based on sentence utility and subsumption, which we have applied to the evaluation of both single and multiple document summaries.", "labels": [], "entities": []}, {"text": "Finally, we describe two user studies that test our models of multi-document summarization.", "labels": [], "entities": [{"text": "multi-document summarization", "start_pos": 62, "end_pos": 90, "type": "TASK", "confidence": 0.6228403151035309}]}], "introductionContent": [{"text": "On October 12, 1999, a relatively small number of news sources mentioned in passing that Pakistani Defense Minister Gen. Pervaiz Musharraf was away visiting Sri Lanka.", "labels": [], "entities": []}, {"text": "However, all world agencies would be actively reporting on the major events that were to happen in Pakistan in the following days: Prime Minister Nawaz Sharif announced that in Gen. Musharraf's absence, the Defense Minister had been sacked and replaced by General Zia Addin.", "labels": [], "entities": []}, {"text": "Large numbers of messages from various sources started to inundate the newswire: about the army's occupation of the capital, the Prime Minister's ouster and his subsequent placement under house arrest, Gen. Musharraf's return to his country, his ascendancy to power, and the imposition of military control over Pakistan.", "labels": [], "entities": []}, {"text": "The paragraph above summarizes a large amount of news from different sources.", "labels": [], "entities": []}, {"text": "While it was not automatically generated, one can imagine the use of such automatically generated summaries.", "labels": [], "entities": []}, {"text": "In this paper we will describe how multi-document summaries are built and evaluated.", "labels": [], "entities": []}], "datasetContent": [{"text": "Instead of P&R or percent agreement, one can measure the coverage of the ideal summary's utility.", "labels": [], "entities": [{"text": "P&R", "start_pos": 11, "end_pos": 14, "type": "METRIC", "confidence": 0.8507699569066366}]}, {"text": "In the example in, using both evaluation methods A and B, System 1 achieves 50%, whereas System 2 achieves 0%.", "labels": [], "entities": []}, {"text": "If we look at sentence utility, System 1 matches 18 out of 19 utility points in the ideal summary and System 2 gets 15 out of 19.", "labels": [], "entities": []}, {"text": "In this case, the performance of system 2 is not as low as when using methods A and B.", "labels": [], "entities": []}, {"text": "We therefore propose to model both interjudge agreement and system evaluation as real-valued vector matching and not as boolean (methods A and B).", "labels": [], "entities": []}, {"text": "By giving credit for \"less than ideal'' sentences and distinguishing the degree of importance between sentences, the utility-based scheme is a more natural model to evaluate summaries.", "labels": [], "entities": []}, {"text": "We ran two user experiments.", "labels": [], "entities": []}, {"text": "First, six judges were each given six clusters and asked to ascribe an importance score from 0 to 10 to each sentence within a particular cluster.", "labels": [], "entities": []}, {"text": "Next, five judges had to indicate for each sentence which other sentence(s), if any, it subsumes 8 .  Since the baseline of random sentence selection is already included in the evaluation formulae, we used the Lead-based method (selecting the positionally first (n*r/c) sentences from each cluster where c = number of clusters) as the baseline to evaluate our system.", "labels": [], "entities": []}, {"text": "In  We then modified the MEAD algorithm to include lead information as well as centroids (see Section 0).", "labels": [], "entities": [{"text": "MEAD", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.8745322823524475}]}, {"text": "In this case, MEAD+Lead performed better than the Lead baseline in 41 cases.", "labels": [], "entities": [{"text": "MEAD+Lead", "start_pos": 14, "end_pos": 23, "type": "METRIC", "confidence": 0.9109896024068197}, {"text": "Lead", "start_pos": 50, "end_pos": 54, "type": "METRIC", "confidence": 0.6236297488212585}]}, {"text": "We are in the process of running experiments with other SCORE formulas.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Sample centroid produced by CIDR", "labels": [], "entities": [{"text": "CIDR", "start_pos": 38, "end_pos": 42, "type": "DATASET", "confidence": 0.8499910831451416}]}, {"text": " Table 4: Comparing systems with utility metrics", "labels": [], "entities": []}, {"text": " Table 6: Cross-judge utility agreement (J)", "labels": [], "entities": []}, {"text": " Table 8: Judges' indication for subsumption for the first seven sentences in cluster A", "labels": [], "entities": [{"text": "indication", "start_pos": 18, "end_pos": 28, "type": "METRIC", "confidence": 0.6680837273597717}]}, {"text": " Table 9: Interjudge CSIS agreement", "labels": [], "entities": [{"text": "Interjudge CSIS", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.6818735301494598}]}, {"text": " Table 10: Normalized performance (D) of MEAD", "labels": [], "entities": [{"text": "Normalized performance (D)", "start_pos": 11, "end_pos": 37, "type": "METRIC", "confidence": 0.8981234431266785}, {"text": "MEAD", "start_pos": 41, "end_pos": 45, "type": "TASK", "confidence": 0.6671338081359863}]}]}