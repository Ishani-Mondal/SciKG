{"title": [{"text": "Using Induced Rules as Complex Features in Memory-Based Language Learning", "labels": [], "entities": []}], "abstractContent": [{"text": "An extension to memory-based learning is described in which automatically induced rules are used as binary features.", "labels": [], "entities": []}, {"text": "These features have an \"active\" value when the left-hand side of the underlying rule applies to the instance.", "labels": [], "entities": []}, {"text": "The RIPPER rule induction algorithm is adopted for the selection of the underlying rules.", "labels": [], "entities": [{"text": "RIPPER rule induction", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.6680762668450674}]}, {"text": "The similarity of a memory instance to anew instance is measured by taking the sum of the weights of the matching rules both instances share.", "labels": [], "entities": []}, {"text": "We report on experiments that indicate that (i) the method works equally well or better than RIPPER on various language learning and other benchmark datasets; (ii) the method does not necessarily perform better than default memory-based learning, but (iii) when multi-valued features are combined with the rule-based features, some slight to significant improvements are observed.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Specifications of the five investigated language learning tasks: numbers of features, values  per feature, classes, and instances. The rightmost column gives the total number of values times  the number of classes.", "labels": [], "entities": []}, {"text": " Table 2: Average generalisation accuracies of  IBi-IG, RIPPER, and RBM on five language learn- ing tasks. '*' denotes significantly better accu- racy of RBM or RIPPER over IBi-IG with p  0.05. '+' denotes significance in the reverse di- rection, x/denotes significantly better accuracy  of RBM over RIPPER with p < 0.05.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 33, "end_pos": 43, "type": "METRIC", "confidence": 0.9097936749458313}, {"text": "accu- racy", "start_pos": 140, "end_pos": 150, "type": "METRIC", "confidence": 0.9568681716918945}, {"text": "accuracy", "start_pos": 278, "end_pos": 286, "type": "METRIC", "confidence": 0.9991362690925598}]}, {"text": " Table 4: Average general\u00b1sat\u00b1on accuracies of  IBI-IG and IBi-IG + RBM, and the percentage of  error reduction, on five language learning tasks.  '.' denotes significantly better accuracy of IB1- IG--~-RBM over IBi-IG with p < 0.05.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 33, "end_pos": 43, "type": "METRIC", "confidence": 0.9924375414848328}, {"text": "error reduction", "start_pos": 96, "end_pos": 111, "type": "METRIC", "confidence": 0.9249018132686615}, {"text": "accuracy", "start_pos": 180, "end_pos": 188, "type": "METRIC", "confidence": 0.9991641044616699}]}]}