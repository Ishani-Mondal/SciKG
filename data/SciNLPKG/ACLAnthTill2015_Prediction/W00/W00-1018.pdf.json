{"title": [{"text": "Some Notes on the Complexity of Dialogues *", "labels": [], "entities": []}], "abstractContent": [{"text": "The purpose of this paper is twofold.", "labels": [], "entities": []}, {"text": "First, we describe some complexity aspects of spoken dialogue.", "labels": [], "entities": []}, {"text": "It is shown that, given the internal setting of our dialogue system, it is impossible to test even a small percentage of the theoretically possible utterances in a reasonable amount of time.", "labels": [], "entities": []}, {"text": "An even smaller part of possible dialogues can thus be tested.", "labels": [], "entities": []}, {"text": "Second, an approach for early testing of the dialogue manager of a dialogue system, without the complete system being put together, is described .", "labels": [], "entities": []}], "introductionContent": [{"text": "On the one hand, it is important for the developers of a dialogue system that the system is robust (i.e., it does not fail or loop), easy to use and is efficient.", "labels": [], "entities": []}, {"text": "On the other hand, the testing of a dialogue system is cumbersome and expensive.", "labels": [], "entities": []}, {"text": "Factors like the effectiveness and naturalness of the system, as well as robustness are problematic to evaluate.", "labels": [], "entities": []}, {"text": "While test suites for analysis components have been around fora while, their counterparts for dialogue managers (henceforth DM) are (to our knowledge) nonexistent.", "labels": [], "entities": []}, {"text": "Evaluation as such has been target fora lot of rm3earch.", "labels": [], "entities": []}, {"text": "Recently more or less automatic testing and evaluation The authors wishes to thank Raft Engel for help with the ~plementation and Norbert Reithinger, Tilmau Becket, Christer Samuelsson and Thorsten Brantz for comments on earlier drafts and fruitful discussions.", "labels": [], "entities": [{"text": "plementation", "start_pos": 113, "end_pos": 125, "type": "METRIC", "confidence": 0.9814682602882385}]}, {"text": "methods has been proposed (e.g. ( Lee, 2000)).", "labels": [], "entities": []}, {"text": "A special problem for the development and testing of a DM is that one often has to wait until the whole system (including speech recognizer(s) and synthesis, parser/generator etc.) has been integrated.", "labels": [], "entities": []}, {"text": "Moreover, to test the complete system one usually has to put people (e.g. the system developers or beta testers) in front of the system, feeding it with \"appropriate input.\"", "labels": [], "entities": []}, {"text": "Using the developers of the system as testers has the potential disadvantage that the system will just be tested with the type of phenomena or dialogues the developer has in mind.", "labels": [], "entities": []}, {"text": "(S)he also has knowledge about the internals of the system and this can influence the testing in unpredictable ways).", "labels": [], "entities": []}, {"text": "Another important factor for the testing of DMs concerned with spoken input is speech recognition errors and their effects on the input.", "labels": [], "entities": []}, {"text": "As we started this project, the following goals and experiences guided us: \u2022 It is cumbersome to test the DM with the complete system at hand.", "labels": [], "entities": []}, {"text": "Although this testing is necessary, we would like to minimize the test effort necessary.", "labels": [], "entities": []}, {"text": "\u2022 We must reach a status of the DM where it is as error free as possible.", "labels": [], "entities": []}, {"text": "There must not be any technical bugs in the program itseff as well as logical bugs, or put in other words: The DM must not fail on any input.", "labels": [], "entities": []}, {"text": "To us there is no hard borderline between legal moves and nonlegal moves in a dialogue.", "labels": [], "entities": []}, {"text": "Some moves make more sense than others, but can the user be obliged to say only certain things at a certain point in a conversation?", "labels": [], "entities": []}, {"text": "A dialogue system should be able to react on any input, how weird it might be.", "labels": [], "entities": []}, {"text": "\u2022 Speech Recognizers makes errors.", "labels": [], "entities": [{"text": "Speech Recognizers", "start_pos": 2, "end_pos": 20, "type": "TASK", "confidence": 0.6465959697961807}]}, {"text": "For our dialogue system with a large vocabnlary, the recognition rate drops to between 70 and 80% for certain problematic speakers.", "labels": [], "entities": [{"text": "recognition rate", "start_pos": 53, "end_pos": 69, "type": "METRIC", "confidence": 0.740312397480011}]}, {"text": "Consequently every fourth or fifth word can be wrong.", "labels": [], "entities": []}, {"text": "An average user contribution contains 5 words in the application we refer to here (, not including single-word utterances in the calculation.", "labels": [], "entities": []}, {"text": "Thus, every utterance may contain a falsely recognized word that mayor may not be important for parsing or semantic construction.", "labels": [], "entities": [{"text": "parsing or semantic construction", "start_pos": 96, "end_pos": 128, "type": "TASK", "confidence": 0.6940685510635376}]}, {"text": "To overcome some of the problems stated above and to find errors as early as possible during the course of developing a dialogue system, we have developed a validation tool -VALDIA -for the automatic testing of the DM.", "labels": [], "entities": [{"text": "VALDIA", "start_pos": 174, "end_pos": 180, "type": "METRIC", "confidence": 0.976809561252594}]}, {"text": "The overall goal we had in mind was to be able to obtain a status of the DM such that it at least does not contain any loops or other fatal (trivial) dialogue strategy errors.", "labels": [], "entities": []}, {"text": "To become independent of the completion status of the overall system, we decided to peel the interfacing components (parser, generator,...) away from the DM.", "labels": [], "entities": []}, {"text": "We now view the DM as a black box.", "labels": [], "entities": []}, {"text": "This black box is then fed with random generated input in some interface language and we observe how the DM reacts on the given input.", "labels": [], "entities": []}, {"text": "An important prerequisite is of course that the interface between the analysis component and the DM is defined.", "labels": [], "entities": []}, {"text": "At this point we would like to emphasize that our dialogue system is not modeled with \"finite state dialogue structure\" and \"allowable syntax\" for each state as described in).", "labels": [], "entities": []}, {"text": "In our view such a system is simple to test, since the system will just recognize those utterances it is designed to process.", "labels": [], "entities": []}, {"text": "In such a scenario one can use the dialogue model for, e.g., enumerating every possible dialogue or generate \"coherent\" dialogues.", "labels": [], "entities": []}, {"text": "On the other hand, our system puts no limits on what is allowed to say at a certain point in the dialogue, which makes the task of automatic testing non-trivial.", "labels": [], "entities": []}, {"text": "Ideally one would want to perform an exhaustive testing the DM with, say, all possible dialogues, i.e., sequences of user contributions and the respective system reactions.", "labels": [], "entities": []}, {"text": "User contributions are supposed to have a maximum length in terms of semantic items.", "labels": [], "entities": []}, {"text": "An investigation of the complexity of the number of possible utterances (in terms of combinations of semantic expressions) and resulting possible dialogues showed that for our DM, the testing task is so complex that the universe of possible semantic expressions cannot be tested in a reasonable amount of time (see Section ??).", "labels": [], "entities": []}, {"text": "Looking at the complexity of the task one is tempted to ask -\"is it possible to exhaustively produce all possible dialogues of a certain length?\"", "labels": [], "entities": []}, {"text": "Or maybe more interesting: \"can we feed the DM with all the generated dialogues?\"", "labels": [], "entities": []}, {"text": "In () a sketch of a method to find good dialogue strategies was put forward.", "labels": [], "entities": []}, {"text": "The authors argue that a dialogue system can be modeled in terms of a state space, an action set and a strategy.", "labels": [], "entities": []}, {"text": "They show how one could automatically find an optimal strategy by feeding the system with all possible dialogues, or in our terminology sequences of user contributions.", "labels": [], "entities": []}, {"text": "We took the natural continuation of this: to automatically generate user contributions or dialogues and feed them to the system, and then let the system find the optimal strategy itself.", "labels": [], "entities": []}, {"text": "In this paper we explore some aspects and limitations of such an approach by analyzing the complexity of dialogues.", "labels": [], "entities": []}, {"text": "We will, for instance, show that even if a dialogue manager can process one or tenor even one hundred user contribution(s) per second we cannot find an optimal strategy based on exhaustive search -the search space is simply too large!", "labels": [], "entities": []}, {"text": "The paper starts with a brief description of the architecture of the DM and the test envi- ronment for VALDIA, and a description of its input format.", "labels": [], "entities": [{"text": "VALDIA", "start_pos": 103, "end_pos": 109, "type": "DATASET", "confidence": 0.569492518901825}]}, {"text": "We then discuss the complexity of an utterance, continuing with the complexity of dialogues.", "labels": [], "entities": []}, {"text": "Finally, VALDIA is described in more detail and then the paper is closed by a discussion of relevant results and papers.", "labels": [], "entities": [{"text": "VALDIA", "start_pos": 9, "end_pos": 15, "type": "METRIC", "confidence": 0.8320194482803345}]}], "datasetContent": [], "tableCaptions": []}