{"title": [{"text": "Using decision trees to select the gran natical relation of a noun phrase", "labels": [], "entities": []}], "abstractContent": [{"text": "We present a machine-learning approach to modeling the distribution of noun phrases (NPs) within clauses with respect to a fine-grained taxonomy of grammatical relations.", "labels": [], "entities": []}, {"text": "We demonstrate that a cluster of superficial linguistic features can function as a proxy for more abstract discourse features that are not observable using state-of-the-art natural language processing.", "labels": [], "entities": []}, {"text": "The models constructed for actual texts can be used to select among alternative linguistic expressions of the same propositional content when generating discourse.", "labels": [], "entities": []}], "introductionContent": [{"text": "Natural language generation involves a number of processes ranging from planning the content to be expressed through making encoding decisions involving syntax, the lexicon and morphology.", "labels": [], "entities": [{"text": "Natural language generation", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6767262617746989}]}, {"text": "The present study concerns decisions made about the form and distribution of each \"mention\" of a discourse entity: should reference be made with a lexical NP, a pronominal NP or a zero anaphor (i.e. an elided mention)?", "labels": [], "entities": []}, {"text": "Should a given mention be expressed as the subject of its clause or in some other grammatical relation?", "labels": [], "entities": []}, {"text": "If all works well, a natural language generation system may end up proposing a mmaber of possible well-formed expressions of the same propositional content.", "labels": [], "entities": []}, {"text": "Although these possible formulations would all be judged to be valid sentences of the target language, it is not the ease that they are all equally likely to occur.", "labels": [], "entities": []}, {"text": "Research in the area of Preferred Argument Structure ( has established that in discourse in many languages, including English, NPs are distributed across grammatical relations in statistically significant ways.", "labels": [], "entities": [{"text": "Preferred Argument Structure (", "start_pos": 24, "end_pos": 54, "type": "TASK", "confidence": 0.8023721426725388}]}, {"text": "For example, transitive clauses tend not to contain lexical NPs in both subject and object positions and subjects of transitives tend not to be lexical NPs nor to be discourse-new.", "labels": [], "entities": []}, {"text": "Unfortunately, the models used in PAS have involved only simple chi-squared tests to identify statistically significant patterns in the distribution of NPs with respect to pairs of features (e.g. part of speech and grammatical relation).", "labels": [], "entities": [{"text": "PAS", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.9854780435562134}]}, {"text": "A further problem from the point of view of computational discourse analysis is that many of the features used in empirical studies are not observable in texts using state-of-the art natural language processing.", "labels": [], "entities": [{"text": "computational discourse analysis", "start_pos": 44, "end_pos": 76, "type": "TASK", "confidence": 0.6395800610383352}]}, {"text": "Such non-observable features include animacy, the information status of a referent, and the identification of the gender of a referent based on world knowledge.", "labels": [], "entities": []}, {"text": "In the present study, we treat the task of determining the appropriate distribution of mentions in text as a machine learning classification problem: what is the probability that a mention will have a certain grammatical relation given a deh set of linguistic features?", "labels": [], "entities": [{"text": "machine learning classification", "start_pos": 109, "end_pos": 140, "type": "TASK", "confidence": 0.7260072429974874}]}, {"text": "In particular, how accurately can we select appropriate grammatical relations using only superficial linguistic features?", "labels": [], "entities": []}], "datasetContent": [{"text": "Vector Machines () using a where 0 < k _< 1, and c is a constant such that p(S) sums to one.", "labels": [], "entities": []}, {"text": "Note that smaller values of kappa cause simpler structures to be favored.", "labels": [], "entities": []}, {"text": "As kappa grows closer to one (k = 1 corresponds to a uniform prior overall possible tree structures), the learned decision trees become more elaborate.", "labels": [], "entities": []}, {"text": "Decision trees were built for k~ {0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99, 0.999}.", "labels": [], "entities": []}, {"text": "Having selected a decision tree, we use the posterior means of the parameters to specify a probability distribution over the grammatical relations.", "labels": [], "entities": []}, {"text": "To avoid overfitting, nodes containing fewer than fifty examples were not split during the learning process.", "labels": [], "entities": []}, {"text": "In building decision trees, 70% of the data was used for training and 30% for held-out evaluation.", "labels": [], "entities": []}, {"text": "The decision trees constructed can be rather complex, making them difficult to present visually.", "labels": [], "entities": []}, {"text": "gives a simpler decision tree that predicts the grammatical relation of a mention for Enearta at variety of kernel functions.", "labels": [], "entities": []}, {"text": "The results obtained were indistinguishable from those reported here.", "labels": [], "entities": []}, {"text": "Figure 2 Decision tree for Enearta, at k=0.7 k=0.7.", "labels": [], "entities": [{"text": "Enearta", "start_pos": 27, "end_pos": 34, "type": "DATASET", "confidence": 0.7509890198707581}]}, {"text": "The tree was constructed using a subset of the morphological and syntactic features:,,,,,,,,,.", "labels": [], "entities": []}, {"text": "Grammatical relations with only a residual probability are omitted for the sake of clarity.", "labels": [], "entities": []}, {"text": "The top-ranked grammatical relation at each leaf node appears in bold type.", "labels": [], "entities": []}, {"text": "Selecting the top-ranked grammatical relation at each node results in a correct decision 58.82% of the time in the heldout test data.", "labels": [], "entities": []}, {"text": "By way of comparison, the best decision tree for Enema computed using all morphological and syntactic features yields 66.05% accuracy at k = 0.999.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 125, "end_pos": 133, "type": "METRIC", "confidence": 0.9993934631347656}]}, {"text": "The distributional facts about the pronoun \"he\" represented in illustrate the utility of the [me-grained taxonomy of grammatical relations.", "labels": [], "entities": []}, {"text": "The pronoun \"he\" in embedded NPs ( = \"-\", = No) and when not in a relative clause ([RelC1] = No) favors ST and SI.", "labels": [], "entities": []}, {"text": "Other grammatical relations have only residual probabilities.", "labels": [], "entities": []}, {"text": "The use of the traditional notion of subject would fail to capture the fact that, in this syntactic context, the pronoun \"he\" tends not to occur as Sc, the subject of a copula.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3 Comparison of cross-domain accuracy to  .....  within-domain accuracy  Top-ranked  Train on Encarta, evaluate on WSJ  61.17%  Train on WSJ, evaluate on WSJ  66.16%  Relative difference in accuracy  -7.54%", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9526382684707642}, {"text": "accuracy", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.941670835018158}, {"text": "WSJ", "start_pos": 122, "end_pos": 125, "type": "DATASET", "confidence": 0.9592129588127136}, {"text": "WSJ", "start_pos": 144, "end_pos": 147, "type": "DATASET", "confidence": 0.9084716439247131}, {"text": "WSJ", "start_pos": 161, "end_pos": 164, "type": "DATASET", "confidence": 0.974227249622345}, {"text": "Relative difference", "start_pos": 174, "end_pos": 193, "type": "METRIC", "confidence": 0.9624853432178497}, {"text": "accuracy", "start_pos": 197, "end_pos": 205, "type": "METRIC", "confidence": 0.8795245885848999}]}]}