{"title": [{"text": "Use of Dependency Tree Structures for the Microcontext Extraction", "labels": [], "entities": [{"text": "Microcontext Extraction", "start_pos": 42, "end_pos": 65, "type": "TASK", "confidence": 0.6757408231496811}]}], "abstractContent": [{"text": "In several recent years, natural language processing (NLP) has brought some very interesting and promising outcomes.", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 25, "end_pos": 58, "type": "TASK", "confidence": 0.8075921436150869}]}, {"text": "In the field of information retrieval (IR), however, these significant advances have not been applied in an optimal way yet.", "labels": [], "entities": [{"text": "information retrieval (IR)", "start_pos": 16, "end_pos": 42, "type": "TASK", "confidence": 0.8699777901172638}]}, {"text": "Author argues that traditional IR methods, i.e. methods based on dealing with individual terms without considering their relations, can be overcome using NLP procedures.", "labels": [], "entities": [{"text": "IR", "start_pos": 31, "end_pos": 33, "type": "TASK", "confidence": 0.983753502368927}]}, {"text": "The reason for this expectation is the fact that NLP methods are able to detect the relations among terms in sentences and that the information obtained can be stored and used for searching.", "labels": [], "entities": []}, {"text": "Features of word senses and the significance of word contexts are analysed and possibility of searching based on word senses instead of mere words is examined.", "labels": [], "entities": []}, {"text": "The core part of the paper focuses on analysing Czech sentences and extracting the context relations among words from them.", "labels": [], "entities": []}, {"text": "In order to make use of lemmatisation and morphological and syntactic tagging of Czech texts, author proposes a method for construction of dependency word microcontexts fully automatically extracted from texts, and several ways how to exploit the microcontexts for the sake of increasing retrieval performance.", "labels": [], "entities": []}], "introductionContent": [{"text": "Empirical methods in natural language processing (NLP) employ learning techniques to automatically extract linguistic knowledge from nat~al language corpora; for an overview of this field see (.", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 21, "end_pos": 54, "type": "TASK", "confidence": 0.8289329508940378}]}, {"text": "This paper wants to show their usefulness in the field of information retrieval (IR).", "labels": [], "entities": [{"text": "information retrieval (IR)", "start_pos": 58, "end_pos": 84, "type": "TASK", "confidence": 0.8765923142433166}]}, {"text": "As the effects and the contribution of this discipline to IR has not been well examined and evaluated yet, various uses of NLP techniques in IR are only marginally mentioned in well known monographs published in last ten years, e.g.,,.", "labels": [], "entities": [{"text": "IR", "start_pos": 58, "end_pos": 60, "type": "TASK", "confidence": 0.9947123527526855}, {"text": "IR", "start_pos": 141, "end_pos": 143, "type": "TASK", "confidence": 0.9915531277656555}]}, {"text": "A textual IR system stores a collection of documents and special data structures for effective searching.", "labels": [], "entities": [{"text": "IR", "start_pos": 10, "end_pos": 12, "type": "TASK", "confidence": 0.8110541105270386}]}, {"text": "A textual document is a sequence of terms.", "labels": [], "entities": []}, {"text": "When analysing the content of a document, terms are the basic processed units --usually they are words of natural language.", "labels": [], "entities": []}, {"text": "When retrieving, the IR system returns documents presumed to be of interest to the user in response to a query.", "labels": [], "entities": [{"text": "IR", "start_pos": 21, "end_pos": 23, "type": "TASK", "confidence": 0.9337748289108276}]}, {"text": "The user's query is a formal statement of user's information need.", "labels": [], "entities": []}, {"text": "The documents that are interesting for the user (relative to the put query) are relevant; the others are non-relevant.", "labels": [], "entities": []}, {"text": "The effectiveness of IR systems is usually measured in terms of precision, the percentage of retrieved documents that are relevant, and recall, the percentage of relevant documents that are retrieved.", "labels": [], "entities": [{"text": "IR", "start_pos": 21, "end_pos": 23, "type": "TASK", "confidence": 0.9866741895675659}, {"text": "precision", "start_pos": 64, "end_pos": 73, "type": "METRIC", "confidence": 0.999535322189331}, {"text": "recall", "start_pos": 136, "end_pos": 142, "type": "METRIC", "confidence": 0.9996623992919922}]}, {"text": "The starting point of our consideration on IR was a critique of word-based retrieval techniques.", "labels": [], "entities": [{"text": "IR", "start_pos": 43, "end_pos": 45, "type": "TASK", "confidence": 0.9860631823539734}]}, {"text": "Traditional IR systems treat the query as a pattern of words to be matched by documents.", "labels": [], "entities": [{"text": "IR", "start_pos": 12, "end_pos": 14, "type": "TASK", "confidence": 0.961439311504364}]}, {"text": "Unfortunately, the effectiveness of these word-matching systems is mostly poor because the system retrieves only the documents that contain words that occttr also in the query.", "labels": [], "entities": []}, {"text": "However, in fact, the user &Des not look for the words used in the query.", "labels": [], "entities": []}, {"text": "The user desires the sense of the words and wants to retrieve the documents containing word,,; having the same sense.", "labels": [], "entities": []}, {"text": "In contrast to the word-based approach, a sense-based IR system treats the query as a pattern of the required sense.", "labels": [], "entities": []}, {"text": "In order to match this sense by the sense of words in documents, the senses of ambiguous words must be determined.", "labels": [], "entities": []}, {"text": "Therefore a good word sense disambiguation is necessary ha a sense-based IR system.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 17, "end_pos": 42, "type": "TASK", "confidence": 0.6634757816791534}, {"text": "IR", "start_pos": 73, "end_pos": 75, "type": "TASK", "confidence": 0.9037464261054993}]}, {"text": "Ambiguity and synonymity of words is a property of natural language causing a very serious problem in IR.", "labels": [], "entities": [{"text": "Ambiguity and synonymity of words", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.6862165629863739}, {"text": "IR", "start_pos": 102, "end_pos": 104, "type": "TASK", "confidence": 0.9918761253356934}]}, {"text": "Both ambiguous words and synonyms depress the effectiveness of wordmatching systems.", "labels": [], "entities": []}, {"text": "The direct effect of polysemy on word-matching systems is to decrease precision (e.g., queries about financial banks retrieve documents about rivers).", "labels": [], "entities": [{"text": "precision", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.9986565113067627}]}, {"text": "If one sense is expressed by different synonyms in different documents, the word-matching system will retrieve all the documents only if all the synonyms are given in the query.", "labels": [], "entities": []}, {"text": "Unfortunately, polysemy has another negative effect: polysemy also prevents the effective use of thesauri.", "labels": [], "entities": []}, {"text": "Consequently, thesauri cannot be directly used to eliminate the problem with synonyms.", "labels": [], "entities": []}, {"text": "In our opinion, if a retrieval system is notable to identify homonyms and synonyms and to discriminate their senses, ambiguity and synonymity will remain one of the main factors causing 1) low recall, 2) low precision, and 3) the known and inevitable fact that recall and precision are inversely related.", "labels": [], "entities": [{"text": "recall", "start_pos": 193, "end_pos": 199, "type": "METRIC", "confidence": 0.9969785213470459}, {"text": "precision", "start_pos": 208, "end_pos": 217, "type": "METRIC", "confidence": 0.9980065226554871}, {"text": "recall", "start_pos": 261, "end_pos": 267, "type": "METRIC", "confidence": 0.9881730675697327}, {"text": "precision", "start_pos": 272, "end_pos": 281, "type": "METRIC", "confidence": 0.9678548574447632}]}, {"text": "There are some evidences that lexical context analysis could be a good way how to eliminate or at least decrease these difficulties m see below.", "labels": [], "entities": [{"text": "lexical context analysis", "start_pos": 30, "end_pos": 54, "type": "TASK", "confidence": 0.6293291449546814}]}, {"text": "How to take the step from words towards senses?", "labels": [], "entities": []}, {"text": "Since an application of word contexts is the only possibility to estimate the sense of words, the way of dealing with word contexts is a central problem in sense-based retrieval.", "labels": [], "entities": []}, {"text": "Knowing word contexts we can determine the measure of collocating, i.e. the extent to which a pair of words collocates.", "labels": [], "entities": []}, {"text": "The knowledge of collocations can be used in IR for several purposes: making up contextual representations of words, resolving word ambiguity, estimating semantic word similarity, tuning the user's query in interaction with the user and quantifying the significance of words for retrieval according to entropy of their contexts.", "labels": [], "entities": [{"text": "IR", "start_pos": 45, "end_pos": 47, "type": "TASK", "confidence": 0.9848715662956238}]}, {"text": "Section 2 expresses our motivation: the investigation of word contexts helps us to develop an efficient IR system.", "labels": [], "entities": [{"text": "IR", "start_pos": 104, "end_pos": 106, "type": "TASK", "confidence": 0.9857774376869202}]}, {"text": "Next section is devoted to analysing Czech texts and suggests a construction of dependency microcontext structures making use of the tree structure automatically created in the process of Prague Dependency Treebank annotation.", "labels": [], "entities": [{"text": "Prague Dependency Treebank annotation", "start_pos": 188, "end_pos": 225, "type": "DATASET", "confidence": 0.9173159301280975}]}, {"text": "Further part focuses on applications of contextual knowledge in IR and refers to the project working on an experimental IR textual database.", "labels": [], "entities": [{"text": "IR", "start_pos": 64, "end_pos": 66, "type": "TASK", "confidence": 0.9699034690856934}, {"text": "IR textual database", "start_pos": 120, "end_pos": 139, "type": "TASK", "confidence": 0.7725673715273539}]}, {"text": "Finally we summarise the results of this study.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to test the methods mentioned above we are developing two experimental databases.", "labels": [], "entities": []}, {"text": "The first is the database of dependency microcontexts extracted from a large text corpus.", "labels": [], "entities": []}, {"text": "We should obtain a lot of useful statistical data from it.", "labels": [], "entities": []}, {"text": "The second experimental database is a textual system MATES (MAster of TExt Sources).", "labels": [], "entities": []}, {"text": "The main purpose of MATES is to serve as a textual database for experiments with various information retrieval methods.", "labels": [], "entities": [{"text": "MATES", "start_pos": 20, "end_pos": 25, "type": "TASK", "confidence": 0.578274130821228}]}, {"text": "MATES is constructed universally, not only for certain given retrieval algorithms, and it is adapted for the work with Czech language.", "labels": [], "entities": [{"text": "MATES", "start_pos": 0, "end_pos": 5, "type": "TASK", "confidence": 0.5027990341186523}]}, {"text": "Using MATES, it is possible to store both the originals of the input documents and their linguistically pre-processed versions.", "labels": [], "entities": []}, {"text": "MATES supports grouping of documents into collections.", "labels": [], "entities": [{"text": "MATES", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.602786123752594}, {"text": "grouping of documents into collections", "start_pos": 15, "end_pos": 53, "type": "TASK", "confidence": 0.8717261552810669}]}, {"text": "For each collection an index is built and additional data structures are created that enable storing all the additional information about each term, each document and about their relations.", "labels": [], "entities": []}, {"text": "This additional data can be used by the retrieval module.", "labels": [], "entities": []}, {"text": "In the near future, the MATES system should enable us to test the methods proposed here and evaluate their contribution to IR as well.", "labels": [], "entities": [{"text": "MATES", "start_pos": 24, "end_pos": 29, "type": "METRIC", "confidence": 0.5778819918632507}, {"text": "IR", "start_pos": 123, "end_pos": 125, "type": "TASK", "confidence": 0.9830513000488281}]}], "tableCaptions": [{"text": " Table 2: Number of dependency types for each  part of speech.", "labels": [], "entities": []}]}