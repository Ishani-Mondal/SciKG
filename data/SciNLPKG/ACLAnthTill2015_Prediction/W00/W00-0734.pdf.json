{"title": [], "abstractContent": [], "introductionContent": [{"text": "In this paper I describe the application of the WPDV algorithm to the CoNLL-2000 shared task, the identification of base chunks in English text).", "labels": [], "entities": [{"text": "identification of base chunks in English text", "start_pos": 98, "end_pos": 143, "type": "TASK", "confidence": 0.834042659827641}]}, {"text": "For this task, I use a three-stage architecture: I first run five different base chunkers, then combine them and finally try to correct some recurring errors.", "labels": [], "entities": []}, {"text": "Except for one base chunker, which uses the memory-based machine learning systern TiMBL, 1 all modules are based on WPDV models).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: FZ=i measurements for all systems (as described in the text). In addition we list the  number of occurrences of each phrase type in the test set.", "labels": [], "entities": [{"text": "FZ", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9922657608985901}]}, {"text": " Table 2: Final results per chunk type, i.e. af- ter applying corrective measures to base chun- ker combination.", "labels": [], "entities": []}]}