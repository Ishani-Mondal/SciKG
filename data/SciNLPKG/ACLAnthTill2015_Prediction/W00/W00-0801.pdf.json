{"title": [{"text": "An Unsupervised Method for Multifingual Word Sense Tagging Using Parallel Corpora: A Preliminary Investigation", "labels": [], "entities": [{"text": "Multifingual Word Sense Tagging", "start_pos": 27, "end_pos": 58, "type": "TASK", "confidence": 0.6820114925503731}]}], "abstractContent": [{"text": "With an increasing number of languages making their way to our desktops everyday via the Internet, researchers have come to realize the lack of linguistic knowledge resources for scarcely represented/studied languages.", "labels": [], "entities": []}, {"text": "In an attempt to bootstrap some of the required linguistic resources for some of those languages, this paper presents an unsupervised method for automatic multilingual word sense tagging using parallel corpora.", "labels": [], "entities": [{"text": "multilingual word sense tagging", "start_pos": 155, "end_pos": 186, "type": "TASK", "confidence": 0.6147467643022537}]}, {"text": "The method is evaluated on the English Brown corpus and its translation into three different languages: French, German and Spanish.", "labels": [], "entities": [{"text": "English Brown corpus", "start_pos": 31, "end_pos": 51, "type": "DATASET", "confidence": 0.902851422627767}]}, {"text": "A preliminary evaluation of the proposed method yielded results of up to 79% accuracy rate for the English data on 81.8% of the SemCor manually tagged data.", "labels": [], "entities": [{"text": "accuracy rate", "start_pos": 77, "end_pos": 90, "type": "METRIC", "confidence": 0.981025367975235}, {"text": "SemCor manually tagged data", "start_pos": 128, "end_pos": 155, "type": "DATASET", "confidence": 0.6709859073162079}]}], "introductionContent": [{"text": "With the term \"globalization\" becoming the theme of cuxrent political and economic discourse, communications technologyexemplified by the World Wide Web OVWW) -has become a source of an abundance of languages.", "labels": [], "entities": []}, {"text": "Language researchers are faced with an ever so present challenge and excitement of being able to study and process these languages and create the appropriate NLP applications for them.", "labels": [], "entities": []}, {"text": "Yet, a major bottleneck for many NLP applications such as machine translation, cross language information retrieval, natural language understanding, etc, is word sense ambiguity.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 58, "end_pos": 77, "type": "TASK", "confidence": 0.820779949426651}, {"text": "cross language information retrieval", "start_pos": 79, "end_pos": 115, "type": "TASK", "confidence": 0.7091599106788635}, {"text": "natural language understanding", "start_pos": 117, "end_pos": 147, "type": "TASK", "confidence": 0.6488772332668304}]}, {"text": "The problem escalates as we deal with languages that are scarce in processing resources and knowledge bases.", "labels": [], "entities": []}, {"text": "The availability of large scale, accurately, sense tagged data should help alleviate the problem.", "labels": [], "entities": []}, {"text": "It has been acknowledged that best way to acquire sense tags for words in a corpus is manually, which has proven to be a very expensive and labor intensive endeavor.", "labels": [], "entities": []}, {"text": "In an attempt to approximate the human effort, both supervised and unsupervised methods have been proposed to solve the problem automatically.", "labels": [], "entities": []}, {"text": "On average supervised methods report higher accuracy rates, but they are faced with the problem of requiring large amounts of sense tagged data as training material.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9985646605491638}]}, {"text": "Most of the methods, to date, aim at solving the problem for one language, namely the language with the most available linguistic resources.", "labels": [], "entities": []}, {"text": "Moreover, most of the proposed approaches report results on a handful of the data, rendering them solutions fora small scale of the data.", "labels": [], "entities": []}, {"text": "Many researchers in the field have looked at language translations as a source for sense distinctions.", "labels": [], "entities": [{"text": "language translations", "start_pos": 45, "end_pos": 66, "type": "TASK", "confidence": 0.7371428906917572}, {"text": "sense distinctions", "start_pos": 83, "end_pos": 101, "type": "TASK", "confidence": 0.6929205805063248}]}, {"text": "The idea is that polysemons words in one language can be translated as distinct words in a different language.", "labels": [], "entities": []}, {"text": "The problem has always been the availability of large corpora in translation, i.e. parallel corpora.", "labels": [], "entities": []}, {"text": "Resnik proposed a method for facilitating the acquisition of parallel corpora from the WWW.", "labels": [], "entities": []}, {"text": "Potentially, we can have parallel corpora in a myriad of languages, yet the downside is the scarcity of linguistic knowledge resources and processing tools for less widely represented/studied languages.", "labels": [], "entities": []}, {"text": "Consequently, we decided to bootstrap the process of word sense tagging for both languages in a parallel corpus using the translations as a source of word sense distinction.", "labels": [], "entities": [{"text": "word sense tagging", "start_pos": 53, "end_pos": 71, "type": "TASK", "confidence": 0.7365466356277466}, {"text": "word sense distinction", "start_pos": 150, "end_pos": 172, "type": "TASK", "confidence": 0.6840300063292185}]}, {"text": "Thereby, attaining sense tagged data for languages with scarce resources as well as creating a supply of large-scale, automatically sense tagged data fora the language with more knowledge resources -albeit noisy -to be utilized by supervised algorithms.", "labels": [], "entities": []}, {"text": "In this paper, we propose an unsupervised method for word sense tagging of' both corpora automatically.", "labels": [], "entities": [{"text": "word sense tagging", "start_pos": 53, "end_pos": 71, "type": "TASK", "confidence": 0.703717569510142}]}, {"text": "The algorithm assumes the availability of a word sense inventory in one of the languages.", "labels": [], "entities": []}, {"text": "The preliminary evaluation of the method on the nouns in an English corpus, yielded accuracy rates in the range of 69-77% against the polysemous nouns in a hand tagged test set, which contrasts with a random baseline of 25.6%, and a baseline of the most frequent sense of 67.6%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.9994934797286987}]}, {"text": "In the following section we describe the proposed method, followed by a preliminary evaluation of the method.", "labels": [], "entities": []}, {"text": "Section 4 discusses related work and we conclude with some thoughts on future directions in section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "Once we had the translations available, the seven corpora -namely, English Brown corpus, French GL, German GL, Spanish GL, French SYS, German SYS, and Spanish SYS -were tokenized and the sentences were alignedk For 1 This was a relatively easy task since the corpora are artificially created, therefore there was a one to one token level alignments, we used the GIZA program[.", "labels": [], "entities": [{"text": "English Brown corpus", "start_pos": 67, "end_pos": 87, "type": "DATASET", "confidence": 0.7610034743944804}]}, {"text": "GIZA is an intermediate program in a statistical machine translation system, EGYPT.", "labels": [], "entities": [{"text": "GIZA", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.7241454720497131}, {"text": "statistical machine translation", "start_pos": 37, "end_pos": 68, "type": "TASK", "confidence": 0.6271654069423676}, {"text": "EGYPT", "start_pos": 77, "end_pos": 82, "type": "DATASET", "confidence": 0.9148380756378174}]}, {"text": "It is an implementation of Models 1-4 of Brown et al., where each of these models produces a Viterbi alignment.", "labels": [], "entities": []}, {"text": "The models are trained in succession where the final paraaneter values from one model are used as the starting parameters for the next model.", "labels": [], "entities": []}, {"text": "We trained each model for I0 iterations.", "labels": [], "entities": []}, {"text": "Given a source and target pair of afigned sentences, GIZA produces the most probable token-level alignments.", "labels": [], "entities": []}, {"text": "Multiple token alignments are allowed on the target language side, i.e. a token in English could align with multiple tokens :in the foreign language.", "labels": [], "entities": []}, {"text": "Tokens on either side could align with nothing, designated as a null token.", "labels": [], "entities": []}, {"text": "GIZA requires a large corpus in order to produce reliable alignments, hence, the use of the entire Brown corpus: both the SemCor tagged data without the tags and the untagged data.", "labels": [], "entities": [{"text": "GIZA", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8876169919967651}, {"text": "Brown corpus", "start_pos": 99, "end_pos": 111, "type": "DATASET", "confidence": 0.9025856852531433}]}, {"text": "Therefore, we produced the alignments for the 6 parallel corpora -a parallel cortms comprises the English eorpns and its translation into one of the three languages using one of the MT packages -with English as the target language.", "labels": [], "entities": []}, {"text": "The Brown Corpus has 52282 sentences.", "labels": [], "entities": [{"text": "Brown Corpus", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.989558070898056}]}, {"text": "Due to processing limitations, GIZA ignores sentences that exceed 50 words in length, therefore it ignored -3000 sentences on average per parallel corpus alignment.", "labels": [], "entities": []}, {"text": "GIZA output was converted to an internal format: sentence number followed by all the tokens 2 in the sentence represented as token positions in the target language aligned with corresponding source language token positions in the aligned foreign sentence.", "labels": [], "entities": []}, {"text": "All the token positions were replaced by the actual tokens from the corresponding corpora.", "labels": [], "entities": []}, {"text": "Tokens that were aligned with null tokens on either side of the parallel corpus were ignored.", "labels": [], "entities": []}, {"text": "All the tokens were tagged with the sentence number and sentence position.", "labels": [], "entities": []}, {"text": "In order to reduce the search space, we reduced the list to the nouns in the corpus.", "labels": [], "entities": []}, {"text": "We created a list of the source language words that were aligned to nouns in the target language, thereby creating a source-target noun list for each source where Src wdi is a word J in the source corpus and trgt_nnj is the noun 4 it aligned to in the target corpus.", "labels": [], "entities": []}, {"text": "Source words that were aligned with one target word only throughout the corpus were excluded from the final fist of words to be tagged in our tag set.", "labels": [], "entities": []}, {"text": "Each resulting set -a set had to include at least 2 nouns -of Engfish target nouns, corresponding to a source word, was passed onto the distance measure routine.", "labels": [], "entities": []}, {"text": "We used an optimization function over the senses of the nouns in a set.", "labels": [], "entities": []}, {"text": "The function aims at maximizing a similarity of meaning overall the members of a set based on a pairwise similarity calculation overall the listed senses in WordNet 1.6.", "labels": [], "entities": [{"text": "WordNet 1.6", "start_pos": 157, "end_pos": 168, "type": "DATASET", "confidence": 0.9235318899154663}]}, {"text": "The algorithm~ disambiguate_class, which is implemented by Resnik and described in detail in , calculates the similarity between all the words' senses of words in a set.", "labels": [], "entities": []}, {"text": "R assigns a confidence score based on shared information content of the sense combinations, which is measured via the most informative subsumer in the taxonomy.", "labels": [], "entities": [{"text": "R", "start_pos": 0, "end_pos": 1, "type": "METRIC", "confidence": 0.8797739744186401}]}, {"text": "The senses with the highest confidence scores are the senses that contribute the most to the maximization function for the set.", "labels": [], "entities": []}, {"text": "The algorithm expects the words to be input as a set for calculating the confidence scores.", "labels": [], "entities": []}, {"text": "In many instances, we observed considerable noise in the target noun set.", "labels": [], "entities": []}, {"text": "For example, the French source word accord was aligned with the English nouns accord, agreement, signing, consonance, and encyclopaedia in the target corpus.", "labels": [], "entities": []}, {"text": "All but the last word in the target set seem to be related to the word accord in French except encyclopaedia.", "labels": [], "entities": []}, {"text": "The source of noise can be attributed to the specific translation system, or to the alignment program~ or in other cases to the 3 Parts of speech are not necessarily symmetric in alignments, i.e. nouns could very well map to verbs or other parts of speech.", "labels": [], "entities": []}, {"text": "4 Note that the nouns at this point are types not tokens, i.e. not instances in the corpus rather a conflafion of instances fact that the source language word itself is ambiguous.", "labels": [], "entities": []}, {"text": "Consequently, we conducted three types of experiments in an attempt to reduce the noise in the target sets: Class sire, Pair_sinai and Pair_simall.", "labels": [], "entities": []}, {"text": "They essentially varied in input format to disambiguate_class.", "labels": [], "entities": []}, {"text": "For Class sire, the target noun data was produced directly from the source-target list and input to the distance measure routine with no special formatting.", "labels": [], "entities": [{"text": "Class sire", "start_pos": 4, "end_pos": 14, "type": "TASK", "confidence": 0.6895895302295685}]}, {"text": "Each of the target nouns was assigned the sense(s) that had the maximum confidence level from among the senses listed for it in the taxonomy.", "labels": [], "entities": []}, {"text": "Thereby creating the tag set for the target language, English.", "labels": [], "entities": []}, {"text": "If a noun does not have an entry in the taxonomy, it is assigned a null sense.", "labels": [], "entities": []}, {"text": "On the other hand, for both Pair_sire 1 and Pair_siin all the nouns in the target fist for each source word were formatted into all pair combinations in the set and then sent to disambiguate_class.", "labels": [], "entities": [{"text": "Pair_sire 1", "start_pos": 28, "end_pos": 39, "type": "DATASET", "confidence": 0.6996889263391495}]}, {"text": "The idea was to localize the noise to the pair level comparison, since disambiguate_class optimizes over the entire set of nouns.", "labels": [], "entities": []}, {"text": "The senses that were selected were the ones with the maximum confidence score from the noun pair sense comparison.", "labels": [], "entities": []}, {"text": "All the senses with a maximum confidence score fora noun were aggregated into a final list of senses for that noun and duplicates were removed.", "labels": [], "entities": []}, {"text": "In Pair_sinu1, only the senses that had a confidence score of 100% were considered, i.e. if disambiguate_class is agnostic as to whether the senses of the target noun pair are similar, each noun in this pak comparison is assigned a null sense, for the noun pair in the local comparison, respectively.", "labels": [], "entities": []}, {"text": "That does not necessarily mean that either noun will have a final null sense in the aggregate list, it rather depends on the sum total of comparisons for each of them with all the nouns in the set.", "labels": [], "entities": []}, {"text": "In Pair sire all, the same conditions apply as in Pair_sinai, yet there is no threshold of a 100%.", "labels": [], "entities": []}, {"text": "A pair of nouns in a local comparison is assigned a null sense if one of the nouns in the pair is not in WordNet or all the senses get a confidence score of 0%.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 105, "end_pos": 112, "type": "DATASET", "confidence": 0.9695149660110474}]}, {"text": "Once we had the tag set for each of our parallel corpora, we evaluated it against the manually tagged test set.", "labels": [], "entities": []}, {"text": "So far, we only evaluated the tag set for the target language, English.", "labels": [], "entities": []}, {"text": "Evaluation of the source tag set is in progress; a serious hurdle is that EuroWordNet is interfaced with WordNet 1.5 only.", "labels": [], "entities": [{"text": "EuroWordNet", "start_pos": 74, "end_pos": 85, "type": "DATASET", "confidence": 0.9850897789001465}]}, {"text": "The preliminary evaluation metric is:", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results for the different experiment  types at various coverage levels of the test set", "labels": [], "entities": []}, {"text": " Table 2: Results at 100% coverage of the test  set", "labels": [], "entities": [{"text": "coverage", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9544880390167236}]}]}