{"title": [{"text": "Statistical Filtering and Subcategorization Frame Acquisition", "labels": [], "entities": [{"text": "Subcategorization Frame Acquisition", "start_pos": 26, "end_pos": 61, "type": "TASK", "confidence": 0.6579349438349406}]}], "abstractContent": [{"text": "Research \"into the automatic acquisition of subcategorization frames (SCFS) from corpora is starting to produce large-scale computational lexicons which include valuable frequency information.", "labels": [], "entities": [{"text": "automatic acquisition of subcategorization frames (SCFS) from corpora", "start_pos": 19, "end_pos": 88, "type": "TASK", "confidence": 0.7646552920341492}]}, {"text": "However, the accuracy of the resulting lexicons shows room for improvement.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9991497993469238}]}, {"text": "One significant source of error lies in the statistical filtering used by some researchers to remove noise from automatically acquired subcategorization frames.", "labels": [], "entities": []}, {"text": "In this paper , we compare three different approaches to filtering out spurious hypotheses.", "labels": [], "entities": []}, {"text": "Two hypothesis tests perform poorly, compared to filtering frames on the basis of relative frequency.", "labels": [], "entities": []}, {"text": "We discuss reasons for this and consider directions for future research.", "labels": [], "entities": []}], "introductionContent": [{"text": "Subcategorization information is vital for successful parsing, however, manual development of large subcategorized lexicons has proved difficult because predicates change behaviour between sublanguages, domains and overtime.", "labels": [], "entities": []}, {"text": "Additionally, manually developed sucategorization lexicons do not provide the relative frequency of different SCFs fora given predicate, essential in a probabilistic approach.", "labels": [], "entities": []}, {"text": "Over the past years acquiring subcategorization dictionaries from textual corpora has become increasingly popular.", "labels": [], "entities": []}, {"text": "The different approaches (e.g.) vary largely according to the methods used and the number of SCFS being extracted.", "labels": [], "entities": []}, {"text": "Regardless of this, there is a ceiling on the performance of these systems at around 80% token recall 1 zWhere token recall is the percentage .of SCF tokens in a sample of manually analysed text that were The approaches to extracting SCF information from corpora have frequently employed statistical methods for filtering (e.g..", "labels": [], "entities": [{"text": "extracting SCF information from corpora", "start_pos": 223, "end_pos": 262, "type": "TASK", "confidence": 0.779656994342804}]}, {"text": "This has been done to remove the noise that arises when dealing with naturally occurring data, and from mistakes made by the SCF acquisition system, for example, parser errors.", "labels": [], "entities": [{"text": "SCF acquisition", "start_pos": 125, "end_pos": 140, "type": "TASK", "confidence": 0.9181967675685883}]}, {"text": "Filtering is usually done with a hypothesis test, and frequently with a variation of the binomial filter introduced by.", "labels": [], "entities": []}, {"text": "Hypothesis testing is performed by formulating a null hypothesis, (H0), which is assumed true unless there is evidence to the contrary.", "labels": [], "entities": []}, {"text": "If there is evidence to the contrary, H0 is rejected and the alternative hypothesis (H1) is accepted.", "labels": [], "entities": [{"text": "H0", "start_pos": 38, "end_pos": 40, "type": "METRIC", "confidence": 0.954998791217804}]}, {"text": "In SCF acquisition, H0 is that there is no association between a particular verb (verbj) and a SCF (SCFi), meanwhile H1 is that there is such an association.", "labels": [], "entities": [{"text": "SCF acquisition", "start_pos": 3, "end_pos": 18, "type": "TASK", "confidence": 0.9501090347766876}]}, {"text": "For SCF acquisition, the testis one-tailed since H1 states the direction of the association, a positive correlation between verbj and scfi.", "labels": [], "entities": [{"text": "SCF acquisition", "start_pos": 4, "end_pos": 19, "type": "TASK", "confidence": 0.9783556759357452}]}, {"text": "We compare the expected probability of scfi occurring with verbj if H0 is true, to the observed probability of co-occurrence obtained from the corpus data.", "labels": [], "entities": []}, {"text": "If the observed probability is greater than the expected probability we reject Ho and accept H1, and if not, we retain H0.", "labels": [], "entities": []}, {"text": "Despite the popularity of this method, it has been reported as problematic.", "labels": [], "entities": []}, {"text": "According to one account ) the majority of errors arise because of the statistical filtering process, which is reported to be particularly unreliable for low frequency SCFs.", "labels": [], "entities": []}, {"text": "reported that a threshold on the relative frequencies produced slightly better results than those achieved with a Brentcorrectly acquired by the system.", "labels": [], "entities": []}, {"text": "style binomial filter when establishing SCFs for diathesis alternation detection.", "labels": [], "entities": [{"text": "diathesis alternation detection", "start_pos": 49, "end_pos": 80, "type": "TASK", "confidence": 0.8489060799280802}]}, {"text": "Lapata determined thresholds for each SCF using the frequency of the SCF in COMLEX Syntax dictionary.", "labels": [], "entities": [{"text": "COMLEX Syntax dictionary", "start_pos": 76, "end_pos": 100, "type": "DATASET", "confidence": 0.9254542191823324}]}, {"text": "Adopting the SCF acquisition system of Briscoe and Carroll, we have experimented with an alternative hypothesis test, the binomial log-likelihood ratio (LLR) test.", "labels": [], "entities": [{"text": "SCF acquisition", "start_pos": 13, "end_pos": 28, "type": "TASK", "confidence": 0.9033277332782745}, {"text": "binomial log-likelihood ratio (LLR) test", "start_pos": 122, "end_pos": 162, "type": "METRIC", "confidence": 0.8386917795453753}]}, {"text": "have also used this test when filtering SCFs automatically acquired for Czech.", "labels": [], "entities": []}, {"text": "This test has been recommended for use in NLP since it does not assume a normal distribution, which invalidates many other parametric tests for use with natural language phenomena.", "labels": [], "entities": []}, {"text": "LLR can be used in a form (-2logA) which is X 2 distributed.", "labels": [], "entities": []}, {"text": "Moreover, this asymptote is appropriate at quite low frequencies, which makes the hypothesis test particularly useful when dealing with natural language phenomena, where low frequency events are commonplace.", "labels": [], "entities": []}, {"text": "A problem with using hypothesis testing for filtering automatically acquired SCFs is obtaining a good estimation of the expected occurrence of scfi with verbj.", "labels": [], "entities": [{"text": "filtering automatically acquired SCFs", "start_pos": 44, "end_pos": 81, "type": "TASK", "confidence": 0.6086447238922119}]}, {"text": "This is often performed using the unconditional distribution, that is the probability distribution overall SCFS, regardless of the verb.", "labels": [], "entities": []}, {"text": "It is assumed that verbj must occur with scfi significantly more than is expected given this estimate.", "labels": [], "entities": []}, {"text": "Our paper addresses the problem that the conditional distribution, dependent on the verb, and unconditional distribution are rarely correlated.", "labels": [], "entities": []}, {"text": "Therefore statistical filters which assume such correlation for H0 will be susceptible to error, In this paper, we compare the results of the Brent style binomial filter of Briscoe and Carroll and the LLR filter to a simple method which uses a threshold on the relative frequencies of the verb and SCF combinations.", "labels": [], "entities": []}, {"text": "We do this within the framework of the Briscoe and Carroll SCF acquisition system, which is described in section 2.1.", "labels": [], "entities": [{"text": "Briscoe and Carroll SCF acquisition system", "start_pos": 39, "end_pos": 81, "type": "DATASET", "confidence": 0.8509185413519541}]}, {"text": "The details of the two statistical filters are described in section 2.2, along with the details of the threshold applied to the relative frequencies output from the SCF acquisition system.", "labels": [], "entities": [{"text": "SCF acquisition", "start_pos": 165, "end_pos": 180, "type": "TASK", "confidence": 0.9057163596153259}]}, {"text": "The details of the experimental evaluation are supplied in section 3.", "labels": [], "entities": []}, {"text": "We discuss our findings in section 3.3 and conclude with directions for future work (section 4).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Raw results for 14 test verbs", "labels": [], "entities": []}, {"text": " Table 2: Precision, Recall, and F measure", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9969468712806702}, {"text": "Recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9972167015075684}, {"text": "F", "start_pos": 33, "end_pos": 34, "type": "METRIC", "confidence": 0.999150276184082}]}, {"text": " Table 3: Rank correlation between the condi- tional SCF distributions of the test verbs and  the unconditional distribution", "labels": [], "entities": []}]}