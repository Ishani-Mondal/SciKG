{"title": [{"text": "Reducing Parsing Complexity by Intra-Sentence Segmentation based on Maximum Entropy Model", "labels": [], "entities": []}], "abstractContent": [{"text": "Long sentence analysis has been a critical problem because of high complexity.", "labels": [], "entities": [{"text": "Long sentence analysis", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7525074084599813}]}, {"text": "This paper addresses the reduction of parsing complexity by intra-sentence segmentation, and presents maximum entropy model for determining segmentation positions.", "labels": [], "entities": [{"text": "parsing complexity", "start_pos": 38, "end_pos": 56, "type": "TASK", "confidence": 0.8074989914894104}]}, {"text": "The model features lexical contexts of segmentation positions , giving a probability to each potential position.", "labels": [], "entities": []}, {"text": "Segmentation coverage and accuracy of the proposed method are 96% and 88% respectively.", "labels": [], "entities": [{"text": "Segmentation coverage", "start_pos": 0, "end_pos": 21, "type": "METRIC", "confidence": 0.7590720951557159}, {"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.999699592590332}]}, {"text": "The parsing efficiency is improved by 77% in time and 71% in space.", "labels": [], "entities": [{"text": "parsing", "start_pos": 4, "end_pos": 11, "type": "TASK", "confidence": 0.9733396172523499}]}], "introductionContent": [{"text": "Long sentence analysis has been a critical problem in machine translation because of high complexity.", "labels": [], "entities": [{"text": "Long sentence analysis", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7067785461743673}, {"text": "machine translation", "start_pos": 54, "end_pos": 73, "type": "TASK", "confidence": 0.7851046025753021}]}, {"text": "In EBMT (example-based machine translation), the longer a sentence is, the less possible it is that the sentence has an exact match in the translation archive, and the less flexible an EBMT system will be (.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 23, "end_pos": 42, "type": "TASK", "confidence": 0.6750530451536179}]}, {"text": "In idiom-based machine translation, long sentence parsing is difficult because more resources are spent during idiom recognition phase as sentence length increases.", "labels": [], "entities": [{"text": "idiom-based machine translation", "start_pos": 3, "end_pos": 34, "type": "TASK", "confidence": 0.6232823133468628}, {"text": "long sentence parsing", "start_pos": 36, "end_pos": 57, "type": "TASK", "confidence": 0.7038832108179728}, {"text": "idiom recognition", "start_pos": 111, "end_pos": 128, "type": "TASK", "confidence": 0.6958193331956863}]}, {"text": "A parser is often unable to analyze long sentences owing to their complexity, though they have no grammatical errors.", "labels": [], "entities": []}, {"text": "In English-Korean machine translation, idiom-based approach is adopted to overcome the structural differences between two languages and to get more accurate translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 18, "end_pos": 37, "type": "TASK", "confidence": 0.6759058982133865}]}, {"text": "The parser is a chart parser with a capability of idiom recognition and translation, which is adapted to English-Korean machine tranalation.", "labels": [], "entities": [{"text": "idiom recognition", "start_pos": 50, "end_pos": 67, "type": "TASK", "confidence": 0.7363059222698212}]}, {"text": "Idioms are recognized prior to syntactic analysis and the part of a sentence for an idiom takes an edge in a chart.", "labels": [], "entities": [{"text": "syntactic analysis", "start_pos": 31, "end_pos": 49, "type": "TASK", "confidence": 0.7641019523143768}]}, {"text": "When parsing long sentences, an ambiguity of an idiom's range may cause more edges than the number of words included in the idiom, which increases parsing complexity much.", "labels": [], "entities": [{"text": "parsing long sentences", "start_pos": 5, "end_pos": 27, "type": "TASK", "confidence": 0.911517878373464}]}, {"text": "A parser of practical machine translation system should be able to analyze long sentences in a reasonable time.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 22, "end_pos": 41, "type": "TASK", "confidence": 0.7483944892883301}]}, {"text": "Most context-free parsing algorithms have O(n 3) parsing complexities in terms of time and space, where n is the length of a sentence.", "labels": [], "entities": [{"text": "context-free parsing", "start_pos": 5, "end_pos": 25, "type": "TASK", "confidence": 0.567302793264389}]}, {"text": "Our work is motivated by the fact that parsing becomes more efficient, if n becomes shorter.", "labels": [], "entities": [{"text": "parsing", "start_pos": 39, "end_pos": 46, "type": "TASK", "confidence": 0.9762718677520752}]}, {"text": "This paper deals with the problem of parsing complexity byway of reducing the length of sentence to be analyzed.", "labels": [], "entities": [{"text": "parsing", "start_pos": 37, "end_pos": 44, "type": "TASK", "confidence": 0.9708465337753296}]}, {"text": "This reduction is achieved by intra-sentence segmentation, which is distinguished from inter--sentence segmentation that is used for text categorization ( or sentence boundary identification)).", "labels": [], "entities": [{"text": "inter--sentence segmentation", "start_pos": 87, "end_pos": 115, "type": "TASK", "confidence": 0.7407341450452805}, {"text": "sentence boundary identification", "start_pos": 158, "end_pos": 190, "type": "TASK", "confidence": 0.616947223742803}]}, {"text": "Intra-sentence segmentation plays a role as a preliminary step to a chart-based, context-free parser in English-Korean machine translation.", "labels": [], "entities": [{"text": "Intra-sentence segmentation", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.7945555746555328}, {"text": "English-Korean machine translation", "start_pos": 104, "end_pos": 138, "type": "TASK", "confidence": 0.6551358302434286}]}, {"text": "There have been several methods for reducing parsing complexities by intrasentence segmentation.", "labels": [], "entities": [{"text": "parsing complexities", "start_pos": 45, "end_pos": 65, "type": "TASK", "confidence": 0.9053353071212769}]}, {"text": "In), they took advantage of the fact that the declarative sentences almost always consist of three segments: [pre-subject : subject:predicate].", "labels": [], "entities": []}, {"text": "The complexity could be reduced by decomposing a sentence into three sections.", "labels": [], "entities": []}, {"text": "Pattern rules) and sentence patterns were used to segment long English sentences.", "labels": [], "entities": []}, {"text": "They showed low segmentation coverage, which means that many of long sentences are not segmented by the pattern rules or sentence patterns.", "labels": [], "entities": []}, {"text": "And they require much human efforts to construct pattern rules or collect sentence patterns.", "labels": [], "entities": []}, {"text": "These factors may prevent them being applicable to practical machine translation sYstems.", "labels": [], "entities": [{"text": "machine translation sYstems", "start_pos": 61, "end_pos": 88, "type": "TASK", "confidence": 0.7787440617879232}]}, {"text": "This paper presents a trainable model for identifying potential segmentation positions in a sentence and determining appropriate segmentation positions.", "labels": [], "entities": []}, {"text": "Given a corpus annotated with segmentation positions, our model automatically learns the contextual evidences about segmentation positions, which relieves human of burden to construct pattern rules or sentence patterns.", "labels": [], "entities": []}, {"text": "These evidences are combined under the maximum entropy framework to estimate the probability for each position.", "labels": [], "entities": []}, {"text": "By intra-sentence segmentation based on the proposed model, we achieve more improved parsing efficiency by 77% in time and 71% in space.", "labels": [], "entities": []}, {"text": "In Section 2 we introduce the maximum entropy model.", "labels": [], "entities": []}, {"text": "Section 3 describes features incorporated into the model and the process of identifying potential segmentation positions.", "labels": [], "entities": []}, {"text": "The determination schemes of segmentation positions are described in Section 4.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 29, "end_pos": 41, "type": "TASK", "confidence": 0.9691070318222046}]}, {"text": "Segmentation performance of the model is presented with the degree of contribution to efficient parsing by the segmentation in Section 5.", "labels": [], "entities": []}, {"text": "We also compare our approach with other intrasentence segmentation approaches.", "labels": [], "entities": []}, {"text": "Section 6 draws conclusions and presents some further works.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Segmentation performance of the de- termination schemes of segmentation position.", "labels": [], "entities": [{"text": "Segmentation", "start_pos": 10, "end_pos": 22, "type": "TASK", "confidence": 0.9216449856758118}, {"text": "segmentation position", "start_pos": 69, "end_pos": 90, "type": "TASK", "confidence": 0.9103607535362244}]}, {"text": " Table 4: Segmentation performance of LCC  with word sets.", "labels": [], "entities": []}, {"text": " Table 5: Comparison of parsing efficiency  with/without segmentation.", "labels": [], "entities": [{"text": "parsing", "start_pos": 24, "end_pos": 31, "type": "TASK", "confidence": 0.9663568139076233}]}]}