{"title": [{"text": "Error-driven HMM-based Chunk Tagger with Context-dependent Lexicon", "labels": [], "entities": [{"text": "HMM-based Chunk Tagger", "start_pos": 13, "end_pos": 35, "type": "TASK", "confidence": 0.7002886931101481}]}], "abstractContent": [{"text": "This paper proposes anew error-driven HMM-based text chunk tagger with context-dependent lexicon.", "labels": [], "entities": [{"text": "HMM-based text chunk tagger", "start_pos": 38, "end_pos": 65, "type": "TASK", "confidence": 0.7619735896587372}]}, {"text": "Compared with standard HMM-based tagger, this tagger uses anew Hidden Markov Modelling approach which incorporates more contextual information into a lexical entry.", "labels": [], "entities": []}, {"text": "Moreover, an error-driven learning approach is adopted to decrease the memory requirement by keeping only positive lexical entries and makes it possible to further incorporate more context-dependent lexical entries.", "labels": [], "entities": []}, {"text": "Experiments show that this technique achieves overall precision and recall rates of 93.40% and 93.95% for all chunk types, 93.60% and 94.64% for noun phrases, and 94.64% and 94.75% for verb phrases when trained on PENN WSJ TreeBank section 00-19 and tested on section 20-24, while 25-fold validation experiments of PENN WSJ TreeBank show overall precision and recall rates of 96.40% and 96.47% for all chunk types, 96.49% and 96.99% for noun phrases, and 97.13% and 97.36% for verb phrases.", "labels": [], "entities": [{"text": "precision", "start_pos": 54, "end_pos": 63, "type": "METRIC", "confidence": 0.9990956783294678}, {"text": "recall", "start_pos": 68, "end_pos": 74, "type": "METRIC", "confidence": 0.9915033578872681}, {"text": "PENN WSJ TreeBank section 00-19", "start_pos": 214, "end_pos": 245, "type": "DATASET", "confidence": 0.8883575320243835}, {"text": "PENN WSJ TreeBank", "start_pos": 315, "end_pos": 332, "type": "DATASET", "confidence": 0.8739817341168722}, {"text": "precision", "start_pos": 346, "end_pos": 355, "type": "METRIC", "confidence": 0.9987149238586426}, {"text": "recall", "start_pos": 360, "end_pos": 366, "type": "METRIC", "confidence": 0.9955469369888306}]}], "introductionContent": [{"text": "Text chunking is to divide sentences into nonoverlapping segments on the basis of fairly superficial analysis.", "labels": [], "entities": [{"text": "Text chunking", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.7190520912408829}]}, {"text": "proposed this as a useful and relatively tractable precursor to full parsing, since it provides a foundation for further levels of analysis, while still allowing more complex attachment decisions to be postponed to a later phase.", "labels": [], "entities": [{"text": "full parsing", "start_pos": 64, "end_pos": 76, "type": "TASK", "confidence": 0.5909325480461121}]}, {"text": "Text chunking typically relies on fairly simple and efficient processing algorithms.", "labels": [], "entities": [{"text": "Text chunking", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.7840868830680847}]}, {"text": "Recently, many researchers have looked at text chunking in two different ways: Some researchers have applied rule-based methods, combining lexical data with finite state or other rule constraints, while others have worked on inducing statistical models either directly from the words and/or from automatically assigned part-of-speech classes.", "labels": [], "entities": [{"text": "text chunking", "start_pos": 42, "end_pos": 55, "type": "TASK", "confidence": 0.7136204391717911}]}, {"text": "On the statistics-based approaches, proposed a HMM-based approach to recognise the syntactic structures of limited length.", "labels": [], "entities": []}, {"text": "Buchholz,, and Veenstra(1999) explored memory-based learning method to fred labelled chunks.", "labels": [], "entities": []}, {"text": "used maximum entropy to recognise arbitrary chunk as part of a tagging task.", "labels": [], "entities": []}, {"text": "On the rule-based approaches, used some heuristics and a grammar to extract \"terminology noun phrases\" from French text.", "labels": [], "entities": []}, {"text": "used similar method to detect English noun phrases. applied.", "labels": [], "entities": []}, {"text": "finite state transducer in his noun phrases recogniser for both English and French.", "labels": [], "entities": []}, {"text": "used transformation-based learning, an error-driven learning technique introduced by Eric, to locate chunks in the tagged corpus.", "labels": [], "entities": []}, {"text": "applied finite state transducers to fred noun phrases and verb phrases.", "labels": [], "entities": []}, {"text": "In this paper, we will focus on statisticsbased methods.", "labels": [], "entities": []}, {"text": "The structure of this paper is as follows: In section 1, we will briefly describe the new error-driven HMM-based chunk tagger with context-dependent lexicon in principle.", "labels": [], "entities": [{"text": "HMM-based chunk tagger", "start_pos": 103, "end_pos": 125, "type": "TASK", "confidence": 0.7610059777895609}]}, {"text": "In section 2, a baseline system which only includes the current part-of-speech in the lexicon is given.", "labels": [], "entities": []}, {"text": "In section 3, several extended systems with different context-dependent lexicons are described.", "labels": [], "entities": []}, {"text": "In section 4, an error=driven learning method is used to decrease memory requirement of the lexicon by keeping only positive lexical entries and make it possible to further improve the accuracy by merging different contextdependent lexicons into one after automatic analysis of the chunking errors.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 185, "end_pos": 193, "type": "METRIC", "confidence": 0.9989014863967896}]}, {"text": "Finally, the conclusion is given.", "labels": [], "entities": []}, {"text": "The data used for all our experiments is extracted from the PENN\" WSJ Treebank () by the program provided by Sabine Buchholz from Tilbug University.", "labels": [], "entities": [{"text": "PENN\" WSJ Treebank", "start_pos": 60, "end_pos": 78, "type": "DATASET", "confidence": 0.6446970775723457}, {"text": "Tilbug University", "start_pos": 130, "end_pos": 147, "type": "DATASET", "confidence": 0.8605873286724091}]}, {"text": "We use sections 00-19 as the training data and 20-24 as test data.", "labels": [], "entities": []}, {"text": "Therefore, the performance is on large scale task instead of small scale task on CoNLL-2000 with the same evaluation program.", "labels": [], "entities": [{"text": "CoNLL-2000", "start_pos": 81, "end_pos": 91, "type": "DATASET", "confidence": 0.9451829195022583}]}, {"text": "For evaluation of our results, we use the precision and recall measures.", "labels": [], "entities": [{"text": "precision", "start_pos": 42, "end_pos": 51, "type": "METRIC", "confidence": 0.9997172951698303}, {"text": "recall", "start_pos": 56, "end_pos": 62, "type": "METRIC", "confidence": 0.9983664155006409}]}, {"text": "Precision is the percentage of predicted chunks that are actually correct while the recall is the percentage of correct chunks that are actually found.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9933329224586487}, {"text": "recall", "start_pos": 84, "end_pos": 90, "type": "METRIC", "confidence": 0.9992596507072449}]}, {"text": "For convenient comparisons of only one value, we also list the F~= I value: , with/3 = 1.", "labels": [], "entities": [{"text": "F~= I value", "start_pos": 63, "end_pos": 74, "type": "METRIC", "confidence": 0.9455186873674393}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Results of chunking experiments with  the  lexical  entry  list :  \u2022 =  {Pi-lPi, Pi-lPi 3C} + {Pi, Pi 3C}", "labels": [], "entities": []}, {"text": " Table 5 gives the results of the chunking  experiments.", "labels": [], "entities": []}, {"text": " Table 6 gives the results of the chunking  experiments.", "labels": [], "entities": []}, {"text": " Table 9 : Results of chunking experiments with  error-driven  lexicon :  dp=", "labels": [], "entities": [{"text": "chunking", "start_pos": 22, "end_pos": 30, "type": "TASK", "confidence": 0.9645620584487915}]}, {"text": " Table 11: Results of chunking experiments  with  error-driven  lexicon :  \u2022 =  { pi_l Wi_lPi , pi_l wi_lpi3C & V~,(Pi_l Wi_iPi ) > O}", "labels": [], "entities": []}, {"text": " Table 12: Results of chunking experiments  with  error-driven  lexicon :  \u2022 =", "labels": [], "entities": [{"text": "chunking", "start_pos": 22, "end_pos": 30, "type": "TASK", "confidence": 0.9702746868133545}]}, {"text": " Table 14 gives an overview of the chunking  experiments using the above assumption. It  shows that the F:=i value for the merged", "labels": [], "entities": [{"text": "F", "start_pos": 104, "end_pos": 105, "type": "METRIC", "confidence": 0.9922662377357483}]}, {"text": " Table 16: Results of 25-fold cross-validation  chunking experiments with the merged  context-dependent lexicon", "labels": [], "entities": [{"text": "cross-validation  chunking", "start_pos": 30, "end_pos": 56, "type": "TASK", "confidence": 0.7241615355014801}]}]}