{"title": [{"text": "Dependency of context-based Word Sense Disambiguation from representation and domain complexity", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 28, "end_pos": 53, "type": "TASK", "confidence": 0.700267364581426}]}], "abstractContent": [{"text": "Word Sense Disambiguation (WSD) is a central task in the area of Natural Language Processing.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7916625291109085}, {"text": "Natural Language Processing", "start_pos": 65, "end_pos": 92, "type": "TASK", "confidence": 0.6414081950982412}]}, {"text": "In the past few years several context-based probabilistic and machine learning methods for WSD have been presented in literature.", "labels": [], "entities": [{"text": "WSD", "start_pos": 91, "end_pos": 94, "type": "TASK", "confidence": 0.9887425899505615}]}, {"text": "However, an important area of research that has not been given the attention it deserves is a formal analysis of the parameters affecting the performance of the learning task faced by these systems.", "labels": [], "entities": []}, {"text": "Usually performance is estimated by measuring precision and recall of a specific algorithm for specific test sets and environmental conditions.", "labels": [], "entities": [{"text": "precision", "start_pos": 46, "end_pos": 55, "type": "METRIC", "confidence": 0.9993815422058105}, {"text": "recall", "start_pos": 60, "end_pos": 66, "type": "METRIC", "confidence": 0.9985344409942627}]}, {"text": "Therefore, a comparison among different learning systems and an objective estimation of the difficulty of the learning task is extremely difficult.", "labels": [], "entities": []}, {"text": "In this paper we propose, in the framework of Computational Learning theory, a formal analysis of the relations between accuracy of a context-based WSD system, the complexity of the context representation scheme, and the environmental conditions (e.g. the complexity of language domain and concept inventory) .", "labels": [], "entities": [{"text": "accuracy", "start_pos": 120, "end_pos": 128, "type": "METRIC", "confidence": 0.9975624084472656}]}], "introductionContent": [{"text": "In the literature (see Computational Linguistics (1998) for some recent results), there is a rather vast repertoire of supervised and unsupervised learning algorithms for WSD, most of which are based on a formal characterization of the surrounding context of a word or linguistic concept 1, and a function f to compute the membership of a word to a category, given its context in running texts.", "labels": [], "entities": [{"text": "WSD", "start_pos": 171, "end_pos": 174, "type": "TASK", "confidence": 0.9732373356819153}]}, {"text": "Despite the rich literature, none of these algorithms exhibit an \"acceptable\" performance with reference to the needs of real-world computational task (e.g. Information Retrieval, Information Extraction, Machine Translation etc.), except for particularly straightforward cases.", "labels": [], "entities": [{"text": "Information Retrieval", "start_pos": 157, "end_pos": 178, "type": "TASK", "confidence": 0.7811891138553619}, {"text": "Information Extraction", "start_pos": 180, "end_pos": 202, "type": "TASK", "confidence": 0.7721457183361053}, {"text": "Machine Translation", "start_pos": 204, "end_pos": 223, "type": "TASK", "confidence": 0.7579350173473358}]}, {"text": "Avery interesting WSD experiment is, a large:-scale exercise in evaluating WSD programs.", "labels": [], "entities": [{"text": "WSD", "start_pos": 18, "end_pos": 21, "type": "TASK", "confidence": 0.9745959043502808}, {"text": "WSD", "start_pos": 75, "end_pos": 78, "type": "TASK", "confidence": 0.9300439953804016}]}, {"text": "One of the objectives of this experiment was to identify correlations between performance of the various systems and the parameters of the WSD task.", "labels": [], "entities": [{"text": "WSD task", "start_pos": 139, "end_pos": 147, "type": "TASK", "confidence": 0.8973894417285919}]}, {"text": "Though the scoring of systems appears sensitive to certain factors, such as the degree of polysemy and the entropy of sense distributions, these correlations could not be consistently observed.", "labels": [], "entities": []}, {"text": "There are words with fewer senses (e.g. bet, consume, generous) causing troubles to most systems, while there are words with a very high polysemy and entropy (e.g. shake) on which all systems obtain good performance.", "labels": [], "entities": []}, {"text": "The justification that the Senseval coordinator Adam Kilgariff provides for shake is very interesting in the light of what we will discuss later in this paper: \"The items (means contexts) for shake involve multi-word expressions, such as shake one's head.", "labels": [], "entities": []}, {"text": "Over 50% of the items for shake involve some multi-word expression or other.\"", "labels": [], "entities": []}, {"text": "In other words, the contexts for shake are very 1 The inventory of linguistic concepts is usually extracted from on-line resources like WordNet, the Longman dictionary (LDOCE), or HECTOR.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 136, "end_pos": 143, "type": "DATASET", "confidence": 0.9560176134109497}, {"text": "Longman dictionary (LDOCE)", "start_pos": 149, "end_pos": 175, "type": "DATASET", "confidence": 0.885507607460022}]}, {"text": "repetitive in the training set, therefore all systems could easily learn a sense discrimination model.", "labels": [], "entities": [{"text": "sense discrimination", "start_pos": 75, "end_pos": 95, "type": "TASK", "confidence": 0.7094829231500626}]}, {"text": "Furthermore, in Senseval (but also in other reported evaluations experiments) it appears that performances for individual words/concepts are extremely uneven within the same system.", "labels": [], "entities": []}, {"text": "This scarce homogeneity of results suggests that performance is not solely related with the \"cleverness\" of a given learning algorithm.", "labels": [], "entities": []}, {"text": "Clearly, the performances of WSD systems are related to a variety of parameters, but the formal nature of these dependencies is not fully understood.", "labels": [], "entities": [{"text": "WSD", "start_pos": 29, "end_pos": 32, "type": "TASK", "confidence": 0.9286375641822815}]}, {"text": "The Senseval experiment highlighted the necessity of a more accurate analysis of the correlations between performance of WSD systems and the parameters that may affect this task.", "labels": [], "entities": [{"text": "WSD", "start_pos": 121, "end_pos": 124, "type": "TASK", "confidence": 0.9473114013671875}]}, {"text": "In absence, a comparison of the various WSD algorithms and an estimation of their performance under different environmental conditions is extremely difficult.", "labels": [], "entities": [{"text": "WSD", "start_pos": 40, "end_pos": 43, "type": "TASK", "confidence": 0.9525066614151001}]}, {"text": "In the next sections we briefly present a computational model of learning, called PAC theory,,), and we then show that this theory maybe used to determine the formal relations between performance of context-based WSD models and environmental conditions, such as the complexity of the context representation scheme, and the the complexity of language domain and concept inventory.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}