{"title": [{"text": "Learning in Natural Language: Theory and Algorithmic Approaches*", "labels": [], "entities": []}], "abstractContent": [{"text": "This article summarizes work on developing a learning theory account for the major learning and statistics based approaches used in natural language processing.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 132, "end_pos": 159, "type": "TASK", "confidence": 0.632287840048472}]}, {"text": "It shows that these approaches can all be explained using a single distribution free inductive principle related to the pac model of learning.", "labels": [], "entities": []}, {"text": "Furthermore, they all make predictions using the same simple knowledge representation-a linear representation over a common feature space.", "labels": [], "entities": []}, {"text": "This is significant both to explaining the generalization and robustness properties of these methods and to understanding how these methods might be extended to learn from more structured, knowledge intensive examples, as part of a learning centered approach to higher level natural language inferences.", "labels": [], "entities": []}], "introductionContent": [{"text": "Many important natural language inferences can be viewed as problems of resolving phonetic, syntactic, semantics or pragmatics ambiguities, based on properties of the surrounding context.", "labels": [], "entities": []}, {"text": "It is generally accepted that a learning component must have a central role in resolving these context sensitive ambiguities, and a significant amount of work has been devoted in the last few years to developing learning methods for these tasks, with considerable success.", "labels": [], "entities": []}, {"text": "Yet, our understanding of when and why learning works in this domain and how it can be used to support increasingly higher level tasks is still lacking.", "labels": [], "entities": []}, {"text": "This article summarizes work on developing a learning theory account for the major learning approaches used in NL.", "labels": [], "entities": []}, {"text": "While the major statistics based methods used in NLP are typically developed with a Bayesian view in mind, the Bayesian principle cannot directly explain the success and robustness of these methods, since their probabilistic assumptions typically do not hold in the data.", "labels": [], "entities": []}, {"text": "Instead, we provide this explanation using a single, distribution free inductive principle related to the pac model of learning.", "labels": [], "entities": []}, {"text": "We describe the unified learning framework and show that, in addition to explaining the success and robustness of the statistics based methods, it also applies to other machine learning methods, such as rule based and memory based methods.", "labels": [], "entities": []}, {"text": "An important component of the view developed is the observation that most methods use the same simple knowledge representation.", "labels": [], "entities": []}, {"text": "This is a linear representation over anew feature space -a transformation of the original instance space to a higher dimensional and more expressive space.", "labels": [], "entities": []}, {"text": "Methods vary mostly algorithmicly, in ways they derive weights for features in this space.", "labels": [], "entities": []}, {"text": "This is significant both to explaining the generalization properties of these methods and to developing an understanding for how and when can these methods be extended to learn from more structured, knowledge intensive examples, perhaps hierarchically.", "labels": [], "entities": []}, {"text": "These issues are briefly discussed and we emphasize the importance of studying knowledge representation and inference in developing a learning centered approach to NL inferences.", "labels": [], "entities": [{"text": "NL inferences", "start_pos": 164, "end_pos": 177, "type": "TASK", "confidence": 0.8158910870552063}]}], "datasetContent": [], "tableCaptions": []}