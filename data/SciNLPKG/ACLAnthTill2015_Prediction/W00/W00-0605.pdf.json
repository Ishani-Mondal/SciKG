{"title": [{"text": "A Question Answering System Developed as a Project in a Natural Language Processing Course*", "labels": [], "entities": [{"text": "Question Answering", "start_pos": 2, "end_pos": 20, "type": "TASK", "confidence": 0.7558382451534271}]}], "abstractContent": [{"text": "This paper describes the Question Answering System constructed during a one semester graduate-level course on Natural Language Processing (NLP).", "labels": [], "entities": [{"text": "Question Answering", "start_pos": 25, "end_pos": 43, "type": "TASK", "confidence": 0.8234765529632568}, {"text": "Natural Language Processing (NLP)", "start_pos": 110, "end_pos": 143, "type": "TASK", "confidence": 0.7262548704942068}]}, {"text": "We hypothesized that by using a combination of syntactic and semantic features and machine learning techniques, we could improve the accuracy of question answering on the test set of the Remedia corpus over the reported levels.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 133, "end_pos": 141, "type": "METRIC", "confidence": 0.9983715415000916}, {"text": "question answering", "start_pos": 145, "end_pos": 163, "type": "TASK", "confidence": 0.6559981852769852}, {"text": "Remedia corpus", "start_pos": 187, "end_pos": 201, "type": "DATASET", "confidence": 0.8829286396503448}]}, {"text": "The approach, although novel, was not entirely successful in the time frame of the course.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper describes a preliminary reading comprehension system constructed as a semester-long project fora natural language processing course.", "labels": [], "entities": []}, {"text": "This was the first exposure to this material for all but one student, and so much of the semester was spent learning about and constructing the tools that would be needed to attack this comprehensive problem.", "labels": [], "entities": []}, {"text": "The course was structured around the project of building a question answering system following the HumSent evaluation as used by the Deep Read system., 1999).", "labels": [], "entities": [{"text": "question answering", "start_pos": 59, "end_pos": 77, "type": "TASK", "confidence": 0.788708508014679}, {"text": "HumSent evaluation", "start_pos": 99, "end_pos": 117, "type": "DATASET", "confidence": 0.8810445070266724}]}, {"text": "The Deep Read reading comprehension prototype system) achieves a level of 36% of the answers correct using a bag-of-words approach together with limited linguistic processing.", "labels": [], "entities": []}, {"text": "Since the average number of sentences per passage is 19.41, this performance is much better than chance (i.e., 5%).", "labels": [], "entities": [{"text": "chance", "start_pos": 97, "end_pos": 103, "type": "METRIC", "confidence": 0.9665372967720032}]}, {"text": "We hypothesized that by using a combination of syntactic and semantic features and machine learning techniques, we could improve the accuracy of question answering on the test set of the Remedia corpus over these reported levels.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 133, "end_pos": 141, "type": "METRIC", "confidence": 0.9983555674552917}, {"text": "question answering", "start_pos": 145, "end_pos": 163, "type": "TASK", "confidence": 0.6611285209655762}, {"text": "Remedia corpus", "start_pos": 187, "end_pos": 201, "type": "DATASET", "confidence": 0.8766169250011444}]}], "datasetContent": [], "tableCaptions": []}