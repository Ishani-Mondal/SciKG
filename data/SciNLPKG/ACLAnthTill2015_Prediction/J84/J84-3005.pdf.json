{"title": [{"text": "Strong Generative Capacity, Weak Generative Capacity, and Modern Linguistic Theories", "labels": [], "entities": []}], "abstractContent": [], "introductionContent": [{"text": "What makes a language a natural language?", "labels": [], "entities": []}, {"text": "A longstanding tradition in generative grammar holds that a language is natural just in case it is learnable under a constellation of auxiliary assumptions about input evidence available to children.", "labels": [], "entities": [{"text": "generative grammar", "start_pos": 28, "end_pos": 46, "type": "TASK", "confidence": 0.9670265316963196}]}, {"text": "Yet another approach seeks some key mathematical property that distinguishes the natural languages from all possible symbol-systems.", "labels": [], "entities": []}, {"text": "With some exceptions -for example, Chomsky's demonstration that a complete characterization of our grammatical knowledge lies beyond the power of finite state languages -the mathematical approach has not provided clear-cut results.", "labels": [], "entities": []}, {"text": "For example, fora variety of reasons we cannot say that the predicate is context-free characterizes all and only the natural languages.", "labels": [], "entities": []}, {"text": "Still another use of mathematical analysis in linguistics has been to diagnose a proposed grammatical formalism as too powerful (allowing too many grammars or languages) rather than as too weak.", "labels": [], "entities": []}, {"text": "Such a diagnosis was supposed by some to follow from Peters and Ritchie's demonstration that the theory of transformational grammar as described in Chomsky's Aspects of the Theory of Syntax could specify grammars to generate any recursively enumerable set.", "labels": [], "entities": []}, {"text": "For some this demonstration marked a watershed in the formal analysis transformational grammar.", "labels": [], "entities": [{"text": "formal analysis transformational grammar", "start_pos": 54, "end_pos": 94, "type": "TASK", "confidence": 0.7152182310819626}]}, {"text": "One general reaction (not prompted by the Peters and Ritchie result alone) was to turn to other theories of grammar designed to explicitly avoid the problems of a theory that could specify an arbitrary Turing machine computation.", "labels": [], "entities": []}, {"text": "The proposals for generalized phrase structure grammar (GPSG) and lexical-functional grammar (LFG) have explicitly emphasized this point.", "labels": [], "entities": [{"text": "generalized phrase structure grammar (GPSG)", "start_pos": 18, "end_pos": 61, "type": "TASK", "confidence": 0.7633268322263446}]}, {"text": "GPSG aims for grammars that generate context-free languages (though there is some recent wavering on this point; see; LFG, for languages that are at worst context-sensitive.", "labels": [], "entities": [{"text": "GPSG", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.837191104888916}]}, {"text": "Whatever the merits of the arguments for this restriction in terms of weak generative capacity -and they are far from obvious, as discussed at length in -one point remains: the switch was prompted by criticism of the nearly two-decades old Aspects theory.", "labels": [], "entities": []}, {"text": "Much has changed in transformational grammar in twenty years.", "labels": [], "entities": [{"text": "transformational grammar", "start_pos": 20, "end_pos": 44, "type": "TASK", "confidence": 0.9712589681148529}]}, {"text": "Modern transformational grammars no longer contain swarms of individual rules such as Passive, Raising, or Dative.", "labels": [], "entities": [{"text": "Raising", "start_pos": 95, "end_pos": 102, "type": "TASK", "confidence": 0.9539721608161926}]}, {"text": "The modern government-binding (GB) theory does not reconstruct a \"deep structure\", does not contain powerful deletion rules, and has introduced a whole host of new constraints.", "labels": [], "entities": []}, {"text": "Given these sweeping changes, it would seem appropriate, then, to re-examine the Peters and Ritchie result, and compare the power of the newer GB-style theories to these other current linguistic theories.", "labels": [], "entities": []}, {"text": "That is the aim of this paper.", "labels": [], "entities": []}, {"text": "The basic points to be made are these: \u2022 Since modern transformational grammars do not contain the powerful deletion rules available in the Aspects theory and need not explicitly reconstruct an underlying deep structure, they are not immediately subject to the Peters and Ritchie results.", "labels": [], "entities": []}, {"text": "Thus the fears recently advanced by  xli-xlii) or Johnson-Laird (1983: 280) simply do not hold.", "labels": [], "entities": []}, {"text": "\u2022 Because modern transformational grammars use traces to mark the site of displaced constituents, the size of underlying structures that need be recovered for language recognition are just linearly larger than their corresponding surface sentences.", "labels": [], "entities": [{"text": "language recognition", "start_pos": 159, "end_pos": 179, "type": "TASK", "confidence": 0.7301205992698669}]}, {"text": "Indeed, it appears that deep structures (\"D-structures\" in the current theory) need not be built at all to test grammaticality.", "labels": [], "entities": []}, {"text": "\u2022 Modern transformational grammars seem more restricted than theories like LFG, not less restricted, in the sense that the agreement predicates available in a modern transformational theory are defined solely over unordered sets of features, rather than, as in the lexical-functional theory, over hierarchical trees.", "labels": [], "entities": []}, {"text": "Agreement (\"unification\") over trees adds extra power to the Copyright 1985 by the Association for Computational Linguistics.", "labels": [], "entities": [{"text": "Copyright 1985", "start_pos": 61, "end_pos": 75, "type": "DATASET", "confidence": 0.9022825360298157}]}, {"text": "Permission to copy without fee all or part of this material is granted provided that the copies are not made for direct commercial advantage and the CL reference and this copyright notice are included on the first page.", "labels": [], "entities": [{"text": "CL reference", "start_pos": 149, "end_pos": 161, "type": "DATASET", "confidence": 0.8458401560783386}]}, {"text": "To copy otherwise, or to republish, requires a fee and/or specific permission.", "labels": [], "entities": []}, {"text": "0362-613X/84/030189-14503.00 lexical-functional formalism.", "labels": [], "entities": []}, {"text": "The result is that there are some strikingly unnatural grammars that lexicalfunctional grammars can describe, but not GB grammars.", "labels": [], "entities": []}, {"text": "This result about strong generative capacity shows upon the weak generative capacity side: GB grammars cannot generate some strictly context-sensitive languages that can be easily generated by lexicalfunctional grammars.", "labels": [], "entities": []}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 1 reviews some of the basic formal and linguistic examples demonstrating that the excess power of the Aspects theory comes from unbounded deletion.", "labels": [], "entities": []}, {"text": "It then shows why this power is not permitted in current transformational theories.", "labels": [], "entities": []}, {"text": "Section 2 turns to a general analysis of the power of governmentbinding grammars.", "labels": [], "entities": []}, {"text": "Section 3 compares the strong and weak generative capacity, of lexical-functional grammar and transformational grammars.", "labels": [], "entities": []}, {"text": "It aims to pinpoint just why lexical-functional grammars are more powerful than government-binding grammars.", "labels": [], "entities": []}, {"text": "Section 4 concludes with some speculations about the precise formal characterization of natural languages.", "labels": [], "entities": [{"text": "precise formal characterization of natural languages", "start_pos": 53, "end_pos": 105, "type": "TASK", "confidence": 0.7403359015782675}]}, {"text": "More generally, these results suggest a different role for the formal analysis of natural languages.", "labels": [], "entities": [{"text": "formal analysis of natural languages", "start_pos": 63, "end_pos": 99, "type": "TASK", "confidence": 0.7197052121162415}]}, {"text": "Instead of trying to fit natural languages into some pre-defined mathematical or formal mold, this revised strategy aims to discover the properties of natural languages first, and then characterize them formally.", "labels": [], "entities": []}, {"text": "The results here maybe regarded as the first fruits of this strategy, applied to current linguistic theories.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}