{"title": [{"text": "On Parsing Strategies and Closure'", "labels": [], "entities": [{"text": "Parsing Strategies and Closure", "start_pos": 3, "end_pos": 33, "type": "TASK", "confidence": 0.9122079908847809}]}], "abstractContent": [{"text": "This paper proposes a welcome hypothesis: a computationally simple device z is sufficient for processing natural language.", "labels": [], "entities": []}, {"text": "Traditionally it has been argued that processing natural language syntax requires very powerful machinery.", "labels": [], "entities": []}, {"text": "Many engineers have come to this rather grim conclusion; almost all working parers are actually Turing Machines (TM), For example, Woods believed that a parser should have TM complexity and specifically designed his Augmented Transition Networks (ATNs) to be Turing Equivalent.", "labels": [], "entities": []}, {"text": "(1) \"It is well known (cf. [Chomsky64]) that the strict context-free grammar model is not an adequate mechanism for characterizing the subtleties of natural languages.\"", "labels": [], "entities": []}, {"text": "[WoodsTO] If the problem is really as hard as it appears, then the only solution is to grin and bear it.", "labels": [], "entities": [{"text": "WoodsTO", "start_pos": 1, "end_pos": 8, "type": "DATASET", "confidence": 0.5821627378463745}, {"text": "grin", "start_pos": 87, "end_pos": 91, "type": "METRIC", "confidence": 0.9241596460342407}]}, {"text": "Our own position is that parsing acceptable sentences is simpler because there are constraints on human performance that drastically reduce the computational complexity.", "labels": [], "entities": [{"text": "parsing acceptable sentences", "start_pos": 25, "end_pos": 53, "type": "TASK", "confidence": 0.9031434257825216}]}, {"text": "Although Woods correctly observes that competence models are very complex, this observation may not apply directly to a performance problem such as parsing) The claim is that performance limitations actually reduce parsing complexity.", "labels": [], "entities": [{"text": "parsing", "start_pos": 148, "end_pos": 155, "type": "TASK", "confidence": 0.9820387959480286}]}, {"text": "This suggests two interesting questions: (a) How is the performance model constrained so as to reduce its complexit?, and (b) How can the constrained performance model naturally approximate competence idealizations?", "labels": [], "entities": []}, {"text": "1. The FS Hypothesis We assume a severe processing limitation on available short term memory (5TM), as commonly suggested in the psycholinguistic literature ([Frazier79], [Frazier and Fodor?9]. [Cowper76], [Kimball73, 75]).", "labels": [], "entities": [{"text": "FS Hypothesis", "start_pos": 7, "end_pos": 20, "type": "TASK", "confidence": 0.4654567837715149}]}, {"text": "Technically a machine with limited memory is a finite state machine (FSM) which has very good complexity bounds compared to a TM.", "labels": [], "entities": []}, {"text": "How does this assumption interact with competence?", "labels": [], "entities": []}, {"text": "It is plausible for thereto be a rule of competence (call it Ccomplex) which cannot be processed with limited memory.", "labels": [], "entities": []}, {"text": "What does this say about the psychological reality of Ccomplex?", "labels": [], "entities": []}, {"text": "What does this imply about the FS hypothesis?", "labels": [], "entities": [{"text": "FS", "start_pos": 31, "end_pos": 33, "type": "TASK", "confidence": 0.7444357872009277}]}, {"text": "When discussing certain performance issues (e.g. center-embedding).", "labels": [], "entities": []}, {"text": "4 it will be most useful to view the processor as a FSM; on the other hand, competence phenomena (e.g. subjacency) suggest a more abstract point of view.", "labels": [], "entities": [{"text": "FSM", "start_pos": 52, "end_pos": 55, "type": "DATASET", "confidence": 0.6666893362998962}]}, {"text": "It will be assumed that there is ultimately a single processing machine with its multiple characterizations (the ideal and the real components).", "labels": [], "entities": []}, {"text": "The processor does not literally apply ideal rules of competence for lack of ideal TM resources, but rather, it resorts to more realistic approximations.", "labels": [], "entities": []}, {"text": "Exactly where the idealizations call for inordinate resources, we should expect to find empirical discrepancies between competence and performance.", "labels": [], "entities": []}, {"text": "A F5 processor is unable to parse complex sentences even though they maybe grammatical.", "labels": [], "entities": []}, {"text": "We claim these complex sentences are unacceptable.", "labels": [], "entities": []}, {"text": "Which constructions are in principle beyond the capabilities of a finite state machine?", "labels": [], "entities": []}, {"text": "Chomsky and Bar-Hillel independently showed that (arbitrarily deep) center-embedded structures require unbounded memory [Chomsky59a, b] [Bar-Hillelbl] [Langendoen75].", "labels": [], "entities": []}, {"text": "As predicted, arbitrarily center-embedded sentences are unacceptable, even at relatively shallow depths.", "labels": [], "entities": []}, {"text": "(2) ;g[The man [who the boy [who the students recognized] pointed out] is a friend of mine.]", "labels": [], "entities": []}, {"text": "(3) ~[The rat [the cat [the dog chased] bit] ate the cheese.]", "labels": [], "entities": []}, {"text": "A memory limitation provides a very attractive account of the center-embedding phenomena (in the limit)J 1.", "labels": [], "entities": []}, {"text": "I would like to thank Peter Szolovits, Halvorsen, and countless others for many useful comments, 2.", "labels": [], "entities": []}, {"text": "Throughout this work, the complexity notion will be u=md in iu computational sense as a measure of time and space resources required by an optimal processor.", "labels": [], "entities": []}, {"text": "The term will not he used in the linguistic sense (the .~ite of the grammar itself).", "labels": [], "entities": []}, {"text": "In general, one can trade one off for the other, which leads to conslderable confusion.", "labels": [], "entities": []}, {"text": "The site of a program (linguistic compiexhy) is typically inversely related to the power of ttle interpreter (computational complexily).", "labels": [], "entities": []}, {"text": "3. A ha.~i~ mark (~) is used to indicate that a sentence is unacceptable;, an asterisk (=) is used in the traditional fashion to denote ungrammaficality.", "labels": [], "entities": []}, {"text": "Grammaticality is associated with competence (post-theoretic), where&,~ acceptability is a matter of performance (empirical).", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}