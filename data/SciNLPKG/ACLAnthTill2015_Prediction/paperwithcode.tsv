Task	Dataset	Metrics
Optical Character Recognition	FSNS - Test	['Sequence error']
Deblurring	REDS	['Average PSNR']
Trajectory Prediction	TRAF	['RMSE']
Trajectory Prediction	Hotel BIWI Walking Pedestrians dataset	['ADE-8/12']
Trajectory Prediction	NGSIM	['ADE', 'RMSE']
Trajectory Prediction	Lyft Level 5	['ADE']
Trajectory Prediction	ETH/UCY	['ADE-8/12']
Trajectory Prediction	ActEV	['ADE-8/12', 'FDE-8/12']
Trajectory Prediction	GPS	['Accuracy']
Trajectory Prediction	ETH BIWI Walking Pedestrians dataset	['ADE-8/12']
Trajectory Prediction	Argoverse	['ADE']
Trajectory Prediction	Apolloscape	['ADE']
Depth Estimation	NYU-Depth V2	['RMS']
Depth Estimation	KITTI Eigen split	['absolute relative error']
Link Prediction	Wiki	['AUC']
Link Prediction	PPI	['Accuracy']
Link Prediction	YAGO3-10	['Hits@10', 'MRR', 'Hits@1', 'Hits@3']
Link Prediction	WN18RR	['Hits@10', 'Hits@3', 'Hits@1', 'MRR', 'MR', 'training time (s)']
Link Prediction	BioGRID	['AUC']
Link Prediction	 FB15k	['Hits@10', 'Hits@3', 'Hits@1', 'MRR', 'MR', 'training time (s)']
Link Prediction	MRR	['MRR']
Link Prediction	FB15k-237	['Hits@10', 'Hits@3', 'Hits@1', 'MR', 'MRR', 'training time (s)']
Link Prediction	Citeseer	['AUC', 'AP', 'Accuracy']
Link Prediction	Pubmed	['AUC', 'AP', 'Accuracy']
Link Prediction	Cora	['AUC', 'AP', 'Accuracy']
Link Prediction	WN18	['Hits@10', 'Hits@3', 'Hits@1', 'MRR', 'MR', 'training time (s)']
Word Alignment	en-fr	['P@1']
Word Alignment	es-en	['P@1']
Word Alignment	fr-en	['P@1']
Word Alignment	en-es	['P@1']
Super-Resolution	Set5-2x	['PSNR']
EEG	　SEED	['Accuracy']
EEG	SEED-IV	['Accuracy']
Image-to-Image Translation	Aerial-to-Map	['Class IOU', 'Per-class Accuracy', 'Per-pixel Accuracy']
Image-to-Image Translation	COCO-Stuff Labels-to-Photos	['mIoU', 'Accuracy', 'FID']
Image-to-Image Translation	Cityscapes Labels-to-Photo	['Class IOU', 'Per-class Accuracy', 'Per-pixel Accuracy', 'mIoU', 'FID']
Image-to-Image Translation	AFHQ	['FID', 'LPIPS']
Image-to-Image Translation	ADE-Indoor Labels-to-Photo	['FID']
Image-to-Image Translation	ADE20K-Outdoor Labels-to-Photos	['mIoU', 'Accuracy', 'FID']
Image-to-Image Translation	anime-to-selfie	['Kernel Inception Distance']
Image-to-Image Translation	SYNTHIA Fall-to-Winter	['mIoU', 'Per-pixel Accuracy', 'fwIOU']
Image-to-Image Translation	Cityscapes Photo-to-Labels	['Class IOU', 'Per-class Accuracy', 'Per-pixel Accuracy']
Image-to-Image Translation	CelebA-HQ	['FID', 'LPIPS']
Image-to-Image Translation	SYNTHIA-to-Cityscapes	['mIoU']
Image-to-Image Translation	RaFD	['Classification Error']
Image-to-Image Translation	selfie-to-anime	['Kernel Inception Distance']
Image-to-Image Translation	ADE20K Labels-to-Photos	['mIoU', 'Accuracy', 'FID']
Domain Adaptation	VisDA2017	['Accuracy']
Domain Adaptation	UCF --> HMDB (full)	['Accuracy']
Domain Adaptation	HMDB-UCF_fy	['1-of-100 Accuracy']
Domain Adaptation	Office-31	['Accuracy', 'Average Accuracy', '1-of-100 Accuracy']
Domain Adaptation	UCF-HMDB_full	['1-of-100 Accuracy']
Domain Adaptation	HMDB --> UCF (full)	['Accuracy']
Domain Adaptation	ImageCLEF-DA	['Accuracy']
Domain Adaptation	SVNH-to-MNIST	['Accuracy']
Speech Recognition	TIMIT	['Percentage error']
Speech Recognition	WSJ eval93	['Percentage error']
Speech Recognition	LibriSpeech test-other	['Word Error Rate (WER)']
Speech Recognition	LibriSpeech test-clean	['Word Error Rate (WER)', 'Percentage error']
Speech Recognition	Librispeech	['Word Error Rate (WER)']
Speech Recognition	CHiME real	['Word Error Rate (WER)']
Speech Recognition	swb_hub_500 WER fullSWBCH	['Percentage error']
Speech Recognition	WSJ eval92	['Percentage error', 'Word Error Rate (WER)']
Speech Recognition	2017_test set	['1 in 2 R@1']
Speech Recognition	Switchboard (300hr)	['Word Error Rate (WER)']
Speech Recognition	fisher WER	['Percentage error']
Speech Recognition	Switchboard + Hub500	['Percentage error']
Part-Of-Speech Tagging	Social media	['Accuracy']
Part-Of-Speech Tagging	Penn Treebank	['Accuracy']
Part-Of-Speech Tagging	UD	['Avg accuracy']
End-To-End Speech Recognition	LibriSpeech test-other	['Word Error Rate (WER)']
Text-To-Speech Synthesis	LJSpeech	['Accuracy', 'MOS', 'Speedup']
Text-To-Speech Synthesis	CMUDict 0.7b	['Phoneme Error Rate', 'Word Error Rate (WER)']
3D Multi-person Pose Estimation (root-relative)	MuPoTS-3D	['3DPCK']
Relation Extraction	FewRel	['F1']
Relation Extraction	WebNLG	['F1']
Relation Extraction	SciERC	['F1']
Relation Extraction	ACE 2004	['Entity+Relation F1', 'Entity F1']
Relation Extraction	NYT-single	['F1']
Relation Extraction	ADE Corpus	['Entity+Relation F1', 'Entity F1']
Relation Extraction	NYT	['F1']
Relation Extraction	Wikipedia-Wikidata relations	['Error rate']
Relation Extraction	ChemProt	['F1']
Relation Extraction	1B Words	['1 in 10 R@1']
Relation Extraction	SemEval-2010 Task 8	['F1']
Relation Extraction	ACE 2005	['Relation F1', 'Entity F1']
Relation Extraction	CoNLL04	['Relation F1 ', 'Entity F1', 'Relation F1']
Relation Extraction	TACRED	['F1']
Hypernym Discovery	Medical domain	['MAP', 'MRR', 'P@5']
Hypernym Discovery	General	['MAP', 'MRR', 'P@5']
Hypernym Discovery	SemEval 2018	[]
Hypernym Discovery	Music domain	['MAP', 'MRR', 'P@5']
Stochastic Optimization	CIFAR-100 ResNet-18 - 200 Epochs	['Accuracy']
Stochastic Optimization	CIFAR-10 ResNet-18 - 200 Epochs	['Accuracy']
Stochastic Optimization	ImageNet ResNet-50 - 60 Epochs	['Top 1 Accuracy', 'Top 5 Accuracy']
Stochastic Optimization	ImageNet ResNet-50 - 50 Epochs	['Top 1 Accuracy', 'Top 5 Accuracy']
3D Human Pose Estimation	Total Capture	['Average MPJPE (mm)']
3D Human Pose Estimation	MPI-INF-3DHP	['3DPCK', 'AUC', 'MJPE']
3D Human Pose Estimation	CHALL H80K	['MPJPE']
3D Human Pose Estimation	3DPW	['PA-MPJPE']
3D Human Pose Estimation	 Leeds Sports Pose	['Reprojection Error (CPM)']
3D Human Pose Estimation	Human3.6M	['Average MPJPE (mm)', 'Using 2D ground-truth joints', 'Multi-View or Monocular']
3D Human Pose Estimation	Geometric Pose Affordance 	['MPJPE (CS)', 'MPJPE (CA)', 'PCK3D (CS)', 'PCK3D (CA)']
3D Human Pose Estimation	HumanEva-I	['Mean Reconstruction Error (mm)']
Machine Translation	IWSLT2015 English-Vietnamese	['BLEU']
Machine Translation	IWSLT2015 German-English	['BLEU score']
Machine Translation	WMT 2017 Latvian-English	['BLEU']
Machine Translation	WMT 2017 English-Latvian	['BLEU']
Machine Translation	WMT2016 Finnish-English	['BLEU']
Machine Translation	WMT2016 English-German	['BLEU score']
Machine Translation	ACCURAT balanced test corpus for under resourced languages Estonian-Russian	['BLEU']
Machine Translation	IWSLT2014 German-English	['BLEU score']
Machine Translation	WMT 2018 English-Finnish	['BLEU']
Machine Translation	WMT 2017 Chinese-English	['BLEU']
Machine Translation	WMT2016 English-Russian	['BLEU score']
Machine Translation	WMT2016 English-Czech	['BLEU score']
Machine Translation	WMT2016 Romanian-English	['BLEU score']
Machine Translation	WMT2017 Finnish-English	['BLEU']
Machine Translation	WMT2014 English-French	['BLEU score', 'SacreBLEU']
Machine Translation	WMT 2018 Finnish-English	['BLEU']
Machine Translation	WMT 2018 Estonian-English	['BLEU']
Machine Translation	 ACCURAT balanced test corpus for under resourced languages Russian-Estonian	['BLEU']
Machine Translation	WMT2016 German-English	['BLEU score']
Machine Translation	WMT2019 English-Lithuanian	['BLEU']
Machine Translation	WMT2016 Czech-English	['BLEU score']
Machine Translation	WMT2015 English-Russian	['BLEU score']
Machine Translation	WMT2017 Chinese-English	['BLEU']
Machine Translation	WMT2014 French-English	['BLEU score']
Machine Translation	WMT2019 Finnish-English	['BLEU']
Machine Translation	WMT2016 Russian-English	['BLEU score']
Machine Translation	WMT2019 English-German	['BLEU score', 'SacreBLEU']
Machine Translation	20NEWS	['1-of-100 Accuracy', 'Accuracy']
Machine Translation	WMT2014 English-German	['BLEU score', 'SacreBLEU']
Machine Translation	WMT2016 English-Romanian	['BLEU score']
Machine Translation	IWSLT2015 English-German	['BLEU score']
Machine Translation	WMT2015 English-German	['BLEU score']
Machine Translation	ACCURAT balanced test corpus for under resourced languages	['BLEU']
Machine Translation	WMT 2018 English-Estonian	['BLEU']
Machine Translation	IWSLT2015 Thai-English	['BLEU score']
Machine Translation	WMT 2014 EN-DE	['BLEU', 'SacreBLEU']
Machine Translation	WMT 2014 EN-FR	['BLEU']
Machine Translation	IWSLT2015 Chinese-English	['BLEU']
Machine Translation	WMT2014 German-English	['BLEU score']
Medical Image Segmentation	ISBI 2012 EM Segmentation	['Warping Error']
Medical Image Segmentation	iSEG 2017 Challenge	['Dice Score']
Medical Image Segmentation	CHAOS MRI Dataset	['Dice Score']
Image Generation	LSUN Churches 256 x 256	['FID']
Image Generation	Indian Celebs 256 x 256	['FID']
Image Generation	Oxford 102 Flowers 256 x 256	['FID']
Image Generation	Oxford 102 Flowers	['Inception score']
Image Generation	LSUN Bedroom 256 x 256	['FID']
Image Generation	Cityscapes-5K 256x512	['FID']
Image Generation	COCO	['FID', 'IS']
Image Generation	CelebA-HQ 1024x1024	['FID']
Image Generation	FFHQ	['FID']
Image Generation	CIFAR-10	['Inception score', 'FID', 'Model Entropy', 'NLL Test']
Image Generation	MNIST	['bpd']
Image Generation	CelebA	['FID']
Image Generation	ImageNet 32x32	['bpd', 'NLL Test', 'FID']
Image Generation	LSUN Bedroom	['FID']
Image Generation	CelebA 256x256	['bpd']
Image Generation	CAT 256x256	['FID']
Image Generation	ImageNet 64x64	['Bits per byte', 'Inception Score', 'FID', 'Cls', 'NLL Test', 'bpd']
Image Generation	CelebA-HQ 128x128	['FID']
Image Generation	ADE-Indoor	['FID']
Image Generation	CUB	['FID']
Image Generation	Cityscapes-25K 256x512	['FID']
Image Generation	CIFAR-100	['FID']
Person Re-Identification	DukeMTMC-reID	['MAP', 'Rank-1', 'Top 1 Accuracy']
Person Re-Identification	MARS	['Rank-1', 'mAP']
Person Re-Identification	PRID2011	['Rank-1']
Person Re-Identification	MSMT17	['Rank-1', 'mAP']
Person Re-Identification	Market-1501	['MAP', 'Rank-1']
Person Re-Identification	DukeMTMCreID	['Rank-1', 'mAP']
Person Re-Identification	CUHK03	['MAP', 'Rank-1']
Person Identification	BioEye	['R1']
3D Reconstruction	Scan2CAD	['Average Accuracy']
3D Reconstruction	300W	['1-of-100 Accuracy']
3D Reconstruction	ShapeNet	['3DIoU']
3D Reconstruction	Data3D−R2N2	['3DIoU']
Music Source Separation	MUSDB18	['SDR (vocals)', 'SDR (drums)', 'SDR (bass)', 'SDR (other)']
Temporal Action Localization	Charades	['MAP']
Temporal Action Localization	UCF101	['Accuracy']
Temporal Action Localization	ActivityNet-1.3	['mAP', 'mAP IOU@0.5']
Temporal Action Localization	HMDB51	['Accuracy']
Temporal Action Localization	THUMOS’14	['mAP IOU@0.5']
Anomaly Detection	Census	['AUC', 'Average Precision']
Anomaly Detection	CTU 13	['AUC']
Anomaly Detection	Numenta Anomaly Benchmark	['NAB score']
Anomaly Detection	Thyroid	['AUC', 'Average Precision']
Reading Comprehension	SQuAD1.1	['EM']
Reading Comprehension	RACE	['Accuracy']
Few-Shot Learning	CUB 200 5-way 5-shot	['Accuracy']
Few-Shot Learning	CUB 200 5-way 1-shot	['Accuracy']
Few-Shot Learning	Mini-ImageNet - 1-Shot Learning	['Accuracy']
Few-Shot Learning	Mini-ImageNet - 5-Shot Learning	['Accuracy']
Relation Classification	TACRED	['F1']
Relation Classification	FewRel	['F1']
Relation Classification	SemEval-2010 Task 8	['F1']
Question Answering	SQuAD2.0	['EM', 'F1']
Question Answering	BoolQ	['Accuracy']
Question Answering	SemEvalCQA	['P@1', 'MAP']
Question Answering	MCTest-500	['Accuracy']
Question Answering	COMPLEXQUESTIONS	['F1']
Question Answering	QASent	['MAP', 'MRR']
Question Answering	QuAC	['F1', 'HEQD', 'HEQQ']
Question Answering	JD Product Question Answer	['BLEU']
Question Answering	RecipeQA	[]
Question Answering	AI2 Kaggle Dataset	['P@1']
Question Answering	YahooCQA	['P@1', 'MRR']
Question Answering	QAngaroo	[]
Question Answering	CliCR	['F1']
Question Answering	Reverb	['Accuracy']
Question Answering	SQuAD2.0 dev	['F1', 'EM']
Question Answering	Natural Questions	['F1 (Long)', 'F1 (Short)']
Question Answering	MCTest-160	['Accuracy']
Question Answering	NewsQA	['F1', 'EM']
Question Answering	NarrativeQA	['Rouge-L', 'BLEU-1', 'BLEU-4', 'METEOR']
Question Answering	HotpotQA	['Joint F1']
Question Answering	SQuAD1.1	['EM', 'F1']
Question Answering	CNN / Daily Mail	['CNN', 'Daily Mail']
Question Answering	TrecQA	['MAP', 'MRR']
Question Answering	SQuAD	['F1']
Question Answering	WikiQA	['MAP', 'MRR']
Question Answering	Children's Book Test	['Accuracy-CN', 'Accuracy-NE']
Question Answering	bAbi	['Accuracy (trained on 10k)', 'Accuracy (trained on 1k)', 'Mean Error Rate']
Question Answering	ReCoRD	['F1']
Question Answering	CoQA	['In-domain', 'Out-of-domain', 'Overall']
Question Answering	SQuAD1.1 dev	['EM', 'F1']
Question Answering	SWAG	['Accuracy']
Question Answering	WikiHop	['Test']
Question Answering	Story Cloze Test	['Accuracy']
Question Answering	MultiRC	['F1a']
Question Answering	WebQuestions	['F1']
Question Answering	Quora Question Pairs	['Accuracy']
Question Answering	MS MARCO	['Rouge-L', 'BLEU-1']
Question Answering	TriviaQA	['EM', 'F1']
Question Answering	NaturalQA	['F1']
Question Answering	CODAH	['Accuracy']
Question Answering	COPA	['Accuracy']
Question Answering	SimpleQuestions	['F1']
Question Answering	RACE	['RACE-m', 'RACE-h', 'RACE']
Feature Selection	Zoo	['Accuracy(10-fold)']
Feature Selection	Ionosphere_class b	['Accuracy(10-fold)', 'Average Accuracy']
Feature Selection	Vowel	['Accuracy(10-fold)']
Feature Selection	Heart-C	['Accuracy(10-fold)']
Feature Selection	Sonar	['Average Accuracy']
Feature Selection	Breastcancer	['Accuracy(10-fold)']
Feature Selection	WDBC	['Accuracy(10-fold)']
Feature Selection	Heart-StatLog	['Accuracy(10-fold)']
Feature Selection	Congress	['Accuracy(10-fold)']
Feature Selection	Wine	['Accuracy(10-fold)']
Feature Selection	Lymphography	['Accuracy(10-fold)']
Feature Selection	Diabets	['Accuracy(10-fold)']
Feature Selection	Hepatitis	['Accuracy(10-fold)']
Feature Selection	German	['Accuracy(10-fold)']
Feature Selection	Vehicule	['Accuracy(10-fold)']
Feature Selection	Movementlibras	['Average Accuracy']
Feature Selection	Lung-Cancer	['Average Accuracy']
Feature Selection	Spect	['Accuracy(10-fold)']
Feature Selection	Iris	['Accuracy(10-fold)']
Feature Selection	Glass identification	['Accuracy(10-fold)']
Visual Question Answering	Visual7W	['Percentage correct']
Visual Question Answering	CLEVR	['Accuracy']
Visual Question Answering	COCO Visual Question Answering (VQA) real images 1.0 open ended	['Percentage correct']
Visual Question Answering	VQA v2	['Accuracy']
Visual Question Answering	VizWiz	['Accuracy']
Visual Question Answering	Visual Genome (subjects)	['Percentage correct']
Visual Question Answering	COCO Visual Question Answering (VQA) abstract 1.0 multiple choice	['Percentage correct']
Visual Question Answering	100 sleep nights of 8 caregivers	['14 gestures accuracy']
Visual Question Answering	VQA 2.0	['Accuracy']
Visual Question Answering	COCO Visual Question Answering (VQA) real images 2.0 open ended	['Percentage correct']
Visual Question Answering	COCO Visual Question Answering (VQA) abstract images 1.0 open ended	['Percentage correct']
Visual Question Answering	VQA-CP	['Score']
Visual Question Answering	Visual Genome (pairs)	['Percentage correct']
Visual Question Answering	COCO Visual Question Answering (VQA) real images 1.0 multiple choice	['Percentage correct']
Image Inpainting	2017_test set	['14 gestures accuracy']
Image Inpainting	Places2 val	['rect mask l1 error', 'rect mask l2 err', 'free-form mask l1 err', 'free-form mask l2 err']
Length-of-Stay prediction	MIMIC-III	['Accuracy (LOS>3 Days)', 'Accuracy (LOS>7 Days)']
Multi-Object Tracking	MOT16	['MOTA']
Time Series Classification	PhysioNet Challenge 2012	['AUC', 'AUC Stdev']
Time Series Classification	Physionet 2017 Atrial Fibrillation	['AUC', 'F1 (Hidden Test Set)']
Scene Parsing	ADE20K	['Mean IoU']
Scene Parsing	ADE20K val	['mIoU']
3D Multi-person Pose Estimation (absolute)	MuPoTS-3D	['3DPCK']
Text Generation	COCO Captions	['BLEU-2', 'BLEU-3', 'BLEU-4', 'BLEU-5']
Text Generation	Chinese Poems	['BLEU-2']
Text Generation	Yahoo Questions	['NLL', 'KL', 'Perplexity']
Text Generation	LDC2016E25	['BLEU']
Text Generation	EMNLP2017 WMT	['BLEU-2', 'BLEU-3', 'BLEU-4', 'BLEU-5']
Text Generation	DailyDialog	['BLEU-1', 'BLEU-2', 'BLEU-3', 'BLEU-4']
Text Generation	CommonGen	['CIDEr']
Text Generation	CMU-SE	['BLEU-3']
Code Generation	WikiSQL	['Exact Match Accuracy', 'Execution Accuracy']
Code Generation	Geo	['Accuracy']
Code Generation	100 sleep nights of 8 caregivers	['14 gestures accuracy']
Code Generation	Django	['Accuracy']
Knowledge Graphs	 FB15k	['MRR']
Representation Learning	Circle Data	['Accuracy']
Representation Learning	eICU Collaborative Research Database	['NMI (physiology_6_hours)', 'NMI (physiology_12_hours)', 'NMI (physiology_24_hours)']
Visual Reasoning	NLVR	['Accuracy (Dev)', 'Accuracy (Test-P)', 'Accuracy (Test-U)']
Visual Odometry	KITTI2015	['Mean Error Rate']
Pulmorary Vessel Segmentation	SunYs	['Accuracy']
Speech Separation	GRID corpus (mixed-speech)	['SDR']
Speech Separation	GRID corpus	['PESQ', 'SDR']
Speech Separation	TCD-TIMIT corpus (mixed-speech)	['SDR']
Common Sense Reasoning	Visual Dialog  v0.9	['1 in 10 R@5', 'Recall@10']
Common Sense Reasoning	Visual Dialog v1.0	['Recall@10']
Common Sense Reasoning	Winograd Schema Challenge	['Score']
Common Sense Reasoning	Event2Mind	['Test', 'Dev']
Common Sense Reasoning	CommonsenseQA	['Accuracy']
Common Sense Reasoning	SWAG	['Test', 'Dev']
Common Sense Reasoning	CODAH	['Accuracy']
Word Sense Disambiguation	SemEval 2013 Task 12	['F1']
Word Sense Disambiguation	Supervised:	['Senseval 2', 'Senseval 3', 'SemEval 2007', 'SemEval 2013', 'SemEval 2015']
Word Sense Disambiguation	SensEval 2	['F1']
Word Sense Disambiguation	SensEval 3 Task 1	['F1']
Word Sense Disambiguation	Words in Context	['Accuracy']
Word Sense Disambiguation	SensEval 2 Lexical Sample	['F1']
Word Sense Disambiguation	Fine-grained WSD:	[]
Word Sense Disambiguation	SensEval 3 Lexical Sample	['F1']
Word Sense Disambiguation	SemEval 2007 Task 7	['F1']
Word Sense Disambiguation	SemEval 2015 Task 13	['F1']
Word Sense Disambiguation	SemEval 2007 Task 17	['F1']
Word Sense Disambiguation	Knowledge-based:	['All', 'Senseval 2', 'Senseval 3', 'SemEval 2007', 'SemEval 2013', 'SemEval 2015']
Word Sense Induction	SemEval 2010 WSI	['V-measure']
Sleep Quality	100 sleep nights of 8 caregivers	['Accuracy']
Natural Language Inference	RTE	['Accuracy']
Natural Language Inference	QNLI	['Accuracy']
Natural Language Inference	Quora Question Pairs	['Accuracy']
Natural Language Inference	MultiNLI	['Matched', 'Mismatched', 'Accuracy']
Natural Language Inference	SciTail	['Accuracy']
Natural Language Inference	WNLI	['Accuracy']
Natural Language Inference	MultiRC	['F1a']
Natural Language Inference	CommitmentBank	['F1']
Natural Language Inference	SNLI	['% Test Accuracy', '% Train Accuracy', 'Parameters']
Natural Language Inference	V-SNLI	['Accuracy']
Language Modelling	One Billion Word	['PPL', 'Number of params', 'Validation perplexity']
Language Modelling	Hutter Prize	['Bit per Character (BPC)', 'Number of params']
Language Modelling	Penn Treebank (Character Level)	['Bit per Character (BPC)', 'Number of params']
Language Modelling	Penn Treebank (Word Level)	['Test perplexity', 'Validation perplexity', 'Params']
Language Modelling	Text8	['Bit per Character (BPC)', 'Number of params']
Language Modelling	WikiText-2	['Test perplexity', 'Validation perplexity', 'Number of params']
Language Modelling	Sequential MNIST	['Accuracy']
Language Modelling	WikiText-103	['Test perplexity', 'Validation perplexity', 'Number of params']
Language Modelling	 ACCURAT balanced test corpus for under resourced languages Russian-Estonian	['Classification Accuracy']
Language Modelling	enwiki8	['Bit per Character (BPC)', 'Number of params']
Speaker Verification	1B Words	['Accuracy (AV I)']
Drug Discovery	ToxCast	['AUC']
Drug Discovery	QM9	['Error ratio']
Drug Discovery	PCBA	['AUC']
Drug Discovery	Tox21	['AUC']
Drug Discovery	MUV	['AUC']
Drug Discovery	egfr-inh	['AUC']
Drug Discovery	HIV dataset	['AUC']
Seizure Detection	CHB-MIT	['Accuracy']
Saliency Detection	PASCAL-S	['MAE']
Saliency Detection	HKU-IS	['MAE']
Saliency Detection	DUT-OMRON	['MAE']
Saliency Detection	DUTS-test	['MAE']
Saliency Detection	ECSSD	['MAE']
Fraud Detection	Kaggle-Credit Card Fraud Dataset	['AUC', 'Average Precision']
Intrusion Detection	20NEWS	['Action']
Negation Detection	*sem 2012 Shared Task: Sherlock Dataset	['F1']
Outlier Detection	ECG5000	['Accuracy']
Outlier Detection	Glass identification	['Average Accuracy']
Outlier Detection	Breast cancer Wisconsin_class 4	['Average Accuracy']
Outlier Detection	Breast cancer Wisconsin_class 2	['Average Accuracy']
Outlier Detection	Ionosphere_class b	['Average Accuracy']
Outlier Detection	Balance scale_class 1	['Average Accuracy']
Stance Detection	RumourEval	['Accuracy']
Edge Detection	Cityscapes test	['AP', 'Maximum F-measure']
Edge Detection	SBD	['Maximum F-measure']
Adversarial Attack	1B Words	['14 gestures accuracy']
Adversarial Defense	CIFAR-10	['Accuracy (PGD, eps=8/255)', 'Accuracy (clean data)']
Adversarial Defense	ImageNet	['Accuracy']
Adversarial Defense	CAAD 2018	['Accuracy']
Recipe Generation	Recipe1M	['F1', 'Mean IoU']
Semantic Segmentation	S3DIS	['mIoU']
Semantic Segmentation	PASCAL VOC 2012 test	['Mean IoU']
Semantic Segmentation	ADE20K	['Validation mIoU', 'Test Score']
Semantic Segmentation	SYNTHIA-CVPR’16	['Mean IoU']
Semantic Segmentation	Cityscapes val	['mIoU']
Semantic Segmentation	SemanticKITTI	['mIoU']
Semantic Segmentation	ShapeNet	['Mean IoU']
Semantic Segmentation	NYU Depth v2	['Mean IoU']
Semantic Segmentation	PASCAL Context	['mIoU']
Semantic Segmentation	Cityscapes test	['Mean IoU (class)']
Semantic Segmentation	38-Cloud	['Jaccard (Mean)']
Semantic Segmentation	LIP val	['mIoU']
Semantic Segmentation	MSRC-21 (per-pixel)	['Percentage correct']
Semantic Segmentation	PASCAL VOC 2012 val	['mIoU']
Semantic Segmentation	ADE20K val	['mIoU']
Semantic Segmentation	PASCAL VOC 2012, 60 proposals per image	['Mean IoU']
Semantic Segmentation	SUN-RGBD	['Mean IoU']
Semantic Segmentation	COCO-Stuff test	['mIoU']
Semantic Segmentation	MSRC-21 (per-class)	['Per-Class Accuracy']
Semantic Segmentation	CamVid	['Mean IoU', 'Global Accuracy']
Semantic Segmentation	Semantic3D	['mIoU']
Semantic Segmentation	Freiburg Forest	['Mean IoU']
Semantic Segmentation	ScanNet	['3DIoU']
Semantic Segmentation	ScanNetV2	['Mean IoU']
Semantic Segmentation	KITTI Semantic Segmentation	['Mean IoU (class)']
Object Localization	KITTI Pedestrians Hard	['AP']
Object Localization	KITTI Cyclists Hard	['AP']
Object Localization	KITTI Pedestrians Easy	['AP']
Object Localization	KITTI Cars Moderate	['AP']
Object Localization	KITTI Cyclists Moderate	['AP']
Object Localization	KITTI Cars Hard	['AP']
Object Localization	KITTI Pedestrians Moderate	['AP']
Object Localization	KITTI Cars Easy	['AP']
Object Localization	KITTI Cyclists Easy	['AP']
Emotion Recognition	MPED	['Accuracy']
Emotion Recognition	SEED-IV	['Accuracy']
Action Localization	1B Words	['Accuracy (pose)']
Lexical Normalization	LexNorm	['Accuracy']
Semantic Role Labeling	CoNLL 2005	['F1']
Semantic Role Labeling	OntoNotes	['F1']
Semantic Textual Similarity	STS Benchmark	['Pearson Correlation', 'Spearman Correlation']
Semantic Textual Similarity	SentEval	['MRPC', 'SICK-R', 'SICK-E', 'STS']
Semantic Textual Similarity	MRPC	['Accuracy', 'F1']
Semantic Parsing	spider	['Accuracy']
Semantic Parsing	ATIS	['Accuracy']
Semantic Parsing	Geo	['Accuracy']
Grammatical Error Correction	Unrestricted	['F0.5', 'GLEU']
Grammatical Error Correction	CoNLL-2014 10 Annotations	[]
Grammatical Error Correction	_Restricted_	['GLEU']
Grammatical Error Correction	Restricted	['F0.5']
Grammatical Error Correction	JFLEG	[]
Grammatical Error Correction	CoNLL-2014 Shared Task	[]
Dependency Parsing	GENIA - UAS	['F1']
Dependency Parsing	Penn Treebank	['UAS', 'LAS', 'POS']
Dependency Parsing	GENIA - LAS	['F1']
Object Classification	PASCAL VOC 2007	['mAP']
Music Classification	20NEWS	['Accuracy']
Audio Classification	UrbanSound8k	['attack succes rate']
Pose Estimation	COCO test-dev	['AP']
Pose Estimation	Leeds Sports Poses	['PCK']
Pose Estimation	HANDS 2017	['Average 3D Error']
Pose Estimation	MPII Human Pose	['PCKh-0.5']
Pose Estimation	 ITOP front-view	['Mean mAP']
Pose Estimation	FLIC Elbows	['PCK@0.2']
Pose Estimation	DensePose-COCO	['AP']
Pose Estimation	FLIC Wrists	['PCK@0.2']
Pose Estimation	LineMOD	['Accuracy (ADD)']
Pose Estimation	COCO	['Mean mAP', 'Test AP', 'Validation AP']
Pose Estimation	ITOP top-view	['Mean mAP']
Sentiment Analysis	ASTD	['Average Recall']
Sentiment Analysis	ArSAS	['Average Recall']
Sentiment Analysis	20NEWS	['1 in 10 R@2']
Sentiment Analysis	Amazon Review Polarity	['Accuracy']
Sentiment Analysis	Multi-Domain Sentiment Dataset	['DVD', 'Books', 'Electronics', 'Kitchen', 'Average']
Sentiment Analysis	DBRD	['Accuracy', 'F1']
Sentiment Analysis	2019_test set	['10%']
Sentiment Analysis	SemEval	['F1-score']
Sentiment Analysis	CR	['Accuracy']
Sentiment Analysis	Yelp	[]
Sentiment Analysis	SST	[]
Sentiment Analysis	SUBJ	['Accuracy']
Sentiment Analysis	Amazon Review Full	['Accuracy']
Sentiment Analysis	SemEval 2017 Task 4-A	['Average Recall']
Sentiment Analysis	Yelp Fine-grained classification	['Error']
Sentiment Analysis	MR	['Accuracy']
Sentiment Analysis	Sogou News	['Accuracy']
Sentiment Analysis	SST-2 Binary classification	['Accuracy']
Sentiment Analysis	1B Words	['1 in 10 R@1']
Sentiment Analysis	SST-5 Fine-grained classification	['Accuracy']
Sentiment Analysis	IMDb	['Accuracy']
Sentiment Analysis	MPQA	['Accuracy']
Sentiment Analysis	Yelp Binary classification	['Error']
Gene Interaction Prediction	BioGRID (human)	['Average Precision']
Gene Interaction Prediction	BioGRID(yeast)	['Average Precision']
Action Classification	Moments in Time	['Top 1 Accuracy', 'Top 5 Accuracy']
Action Classification	Charades	['MAP']
Action Classification	HMDB51	['Accuracy']
Action Classification	Kinetics-400	['Accuracy']
Action Classification	MiniKinetics	['Top-1 Accuracy']
Entity Linking	WebQSP-WD	['F1']
Entity Linking	CoNLL-Aida	['Accuracy']
Entity Linking	TAC-KBP 2010	['Accuracy']
Entity Linking	AIDA-CoNLL	['Accuracy']
Named Entity Recognition	CoNLL 2012	['F1']
Named Entity Recognition	BC5CDR	['F1']
Named Entity Recognition	JNLPBA	['F1']
Named Entity Recognition	Long-tail emerging entities	['F1', 'F1 (surface form)']
Named Entity Recognition	Resume NER	['F1']
Named Entity Recognition	WetLab	['F1']
Named Entity Recognition	Ontonotes v5 (English)	['F1']
Named Entity Recognition	GENIA	['F1']
Named Entity Recognition	Species-800	['F1']
Named Entity Recognition	LINNAEUS	['F1']
Named Entity Recognition	NCBI-disease	['F1']
Named Entity Recognition	MSRA	['F1']
Named Entity Recognition	Weibo NER	['F1']
Named Entity Recognition	SciERC	['F1']
Named Entity Recognition	CoNLL 2003 (English)	['F1']
Named Entity Recognition	Code-Switching English-Spanish NER	['F1']
Named Entity Recognition	ontontoes chinese v5	['F1']
Named Entity Recognition	ADE Corpus	['Macro-F1']
Named Entity Recognition	ACE 2005	['F1']
Named Entity Recognition	ACE 2004	['F1']
Table-based Fact Verification	TabFact	['Test', 'Val']
Horizon Line Estimation	York Urban Dataset	['AUC (horizon error)']
Horizon Line Estimation	Horizon Lines in the Wild	['AUC (horizon error)']
Horizon Line Estimation	Eurasian Cities Dataset	['AUC (horizon error)']
Electrocardiography (ECG)	Telehealth Network of Minas Gerais (TNMG) 	['F1 (1dAVb)', 'F1 (RBBB)', 'F1 (LBBB)', 'F1 (SB)', 'F1 (AF)', 'F1 (ST)']
ECG Classification	Electrocardiography (ECG) on Telehealth Network of Minas Gerais (TNMG)	['F1 (1dAVb)', 'F1 (RBBB)', 'F1 (LBBB)', 'F1 (SB)', 'F1 (AF)', 'F1 (ST)']
Image Super-Resolution	Celeb-HQ 4x upscaling	['PSNR', 'SSIM']
Image Super-Resolution	Urban100 - 4x upscaling	['PSNR', 'SSIM']
Image Super-Resolution	Set14 - 4x upscaling	['PSNR', 'SSIM', 'MOS']
Image Super-Resolution	Manga109 - 4x upscaling	['SSIM', 'PSNR']
Image Super-Resolution	Set5 - 4x upscaling	['PSNR', 'SSIM', 'MOS']
Image Super-Resolution	BSD100 - 4x upscaling	['PSNR', 'SSIM', 'MOS']
Slot Filling	ATIS	['F1']
Slot Filling	SNIPS	['F1']
Intent Detection	SNIPS	['Accuracy']
Intent Detection	ATIS	['Accuracy']
Action Detection	Multi-THUMOS	['mAP']
Action Detection	THUMOS' 14	['mAP']
Action Detection	Charades	['mAP']
Fake News Detection	Grover-Mega	['Unpaired Accuracy']
Sarcasm Detection	SARC (pol-bal)	['Accuracy']
Sarcasm Detection	SARC (all-bal)	['Accuracy']
Sarcasm Detection	SARC (pol-unbal)	['Avg F1']
Sarcasm Detection	SCv1	['F1']
Hate Speech Detection	Automatic Misogynistic Identification	['Accuracy']
Scene Text Detection	IC15	['F-Measure']
Scene Text Detection	 ICDAR 2017 MLT	['Recall', 'Precision', 'F-Measure']
Scene Text Detection	IC17-MLT	['F-Measure']
Scene Text Detection	MSRA-TD500	['Recall', 'Precision', 'H-Mean', 'F-Measure']
Scene Text Detection	ICDAR 2015	['Precision', 'Recall', 'F-Measure']
Scene Text Detection	Total-Text	['F-Measure']
Scene Text Detection	IC19-ReCTs	['F-Measure']
Scene Text Detection	SCUT-CTW1500	['F-Measure', 'TIoU']
Scene Text Detection	ICDAR 2013	['F-Measure']
Continuous Control	DeepMind Cup Catch (Images)	['Return']
Continuous Control	DeepMind Cheetah Run (Images)	['Return']
Continuous Control	DeepMind Walker Walk (Images)	['Return']
Continuous Control	DeepMind Cartpole Balance (Images)	['Return']
Continuous Control	DeepMind Finger Spin (Images)	['Return']
Image Registration	 Osteoarthritis Initiative	['Dice']
Visual Tracking	VOT2017/18	['Expected Average Overlap (EAO)']
Visual Tracking	VOT2018	['Expected Average Overlap (EAO)']
Visual Tracking	OTB-100	['AUC']
Ad-Hoc Information Retrieval	TREC Robust04	['nDCG@20', 'MAP', 'P@20']
Point Cloud Generation	ShapeNet Chair	['MMD-CD']
Point Cloud Generation	ShapeNet Airplane	['MMD-CD']
Point Cloud Generation	ShapeNet Car	['MMD-CD']
Subjectivity Analysis	SUBJ	['Accuracy']
Music Generation	JSB Chorales	['NLL']
Music Generation	1B Words	['14 gestures accuracy']
Neural Architecture Search	CIFAR-10	['Search Time (GPU days)', 'Top-1 Error Rate']
Neural Architecture Search	CIFAR-10 Image Classification	['Percentage error', 'Params']
Neural Architecture Search	ImageNet	['Top-1 Error Rate', 'Accuracy']
Neural Architecture Search	CIFAR-10 image generation	['FID', 'Inception score']
Community Detection	Facebook Media	['Modularity']
Community Detection	Facebook Politicians	['Modularity']
Community Detection	Amazon	['Accuracy-NE', 'F1-score', 'NMI']
Community Detection	2010 i2b2/VA	['14 gestures accuracy']
Community Detection	Facebook TV Show	['Modularity']
Community Detection	Cora	['NMI']
Community Detection	Facebook Celebrities	['Modularity']
Community Detection	Facebook Government	['Modularity']
Community Detection	Facebook Companies	['Modularity']
Community Detection	Facebook Artists	['Modularity']
Community Detection	Facebook Athletes	['Modularity']
Human-Object Interaction Detection	V-COCO	['MAP']
Human-Object Interaction Detection	HICO	['mAP']
Human-Object Interaction Detection	HICO-DET	['MAP']
Protein Secondary Structure Prediction	Jpred4 blind set	['Accuracy']
Protein Secondary Structure Prediction	CullPDB	['Q8']
Protein Secondary Structure Prediction	CB513	['Q8']
Protein Secondary Structure Prediction	2017_test set	['Q3', 'Q8']
Protein Secondary Structure Prediction	2019_test set	['Q3']
Gesture Recognition	GesturePod	['Real World Accuracy']
Nested Mention Recognition	GENIA	['F1']
Nested Mention Recognition	ACE 2004	['F1']
Nested Mention Recognition	ACE 2005	['F1']
Multi-Label Text Classification	20NEWS	['Accuracy']
Image Reconstruction	Edge-to-Shoes	['FID', 'LPIPS']
Image Reconstruction	Edge-to-Handbags	['FID', 'LPIPS']
Image Clustering	ARL Polarimetric Thermal Face Dataset	['Accuracy']
Image Clustering	CIFAR-10	['Accuracy', 'NMI']
Image Clustering	USPS	['Accuracy', 'NMI']
Image Clustering	STL-10	['Accuracy', 'NMI']
Image Clustering	MNIST	['Accuracy', 'NMI']
Image Clustering	YouTube Faces DB	['NMI']
Image Clustering	Coil-20	['NMI']
Image Clustering	coil-100	['NMI']
Image Clustering	LetterA-J	['Accuracy', 'NMI']
Image Clustering	Fashion-MNIST	['Accuracy', 'NMI']
Image Clustering	Extended Yale-B	['Accuracy', 'NMI']
Document Image Classification	RVL-CDIP	['Accuracy']
Image Dehazing	SOTS Indoor	['PSNR', 'SSIM']
Image Dehazing	SOTS Outdoor	['PSNR', 'SSIM']
Image Denoising	Urban100 sigma30	['PSNR']
Image Denoising	BSD200 sigma30	['PSNR', 'SSIM']
Image Denoising	BSD68 sigma50	['PSNR']
Image Denoising	urban100 sigma15	['Average PSNR']
Image Denoising	BSD68 sigma30	['PSNR']
Image Denoising	Urban100 sigma50	['PSNR']
Image Denoising	BSD68 sigma10	['PSNR']
Image Denoising	BSD200 sigma50	['PSNR', 'SSIM']
Image Denoising	BSD68 sigma15	['PSNR']
Image Denoising	BSD200 sigma10	['PSNR', 'SSIM']
Image Denoising	BSD200 sigma70	['PSNR', 'SSIM']
Image Denoising	Urban100 sigma70	['PSNR']
Image Denoising	BSD68 sigma70	['PSNR']
Image Denoising	BSD68 sigma25	['PSNR']
Coreference Resolution	CoNLL 2012	['Avg F1']
Coreference Resolution	OntoNotes	['F1']
Entity Resolution	CoNLL 2003 (English)	['Accuracy']
Image Compression	ImageNet32	['bpsp']
Optical Flow Estimation	KITTI 2015	['Fl-all']
Optical Flow Estimation	Sintel-final	['Average End-Point Error']
Optical Flow Estimation	Sintel-clean	['Average End-Point Error']
Optical Flow Estimation	KITTI 2012	['Average End-Point Error']
Motion Segmentation	Hopkins155	['Classification Error']
Motion Segmentation	KT3DMoSeg	['Error']
Motion Segmentation	MTPV62	['Classification Error']
Denoising	Darmstadt Noise Dataset	['PSNR']
Chunking	Penn Treebank	['F1 score']
Amr Parsing	LDC2016E25	['Smatch']
Amr Parsing	LDC2015E86:	['Smatch']
Amr Parsing	LDC2014T12:	['F1 Newswire', 'F1 Full']
Amr Parsing	LDC2017T10	['F1']
Constituency Parsing	Penn Treebank	['F1 score']
Automated Theorem Proving	Metamath set.mm	['Percentage correct']
Automated Theorem Proving	HOList benchmark	['Percentage correct']
Automated Theorem Proving	HolStep (Unconditional)	['Classification Accuracy']
Automated Theorem Proving	CompCert	['Percentage correct']
Automated Theorem Proving	HolStep (Conditional)	['Classification Accuracy']
Automated Theorem Proving	CoqGym	['Percentage correct']
Graph Embedding	PPI	['Micro-F1']
Graph Similarity	IMDb	['mse (10^-3)']
Graph Clustering	Cora	['Accuracy']
Graph Clustering	Citeseer	['Accuracy']
Graph Clustering	Pubmed	['Accuracy']
Saliency Prediction	2010 i2b2/VA	['1 in 10 R@1']
Gaze Estimation	EYEDIAP (screen target)	['Angular Error']
Gaze Estimation	MPII Gaze	['Angular Error']
Gaze Estimation	RT-GENE	['Angular Error']
Gaze Estimation	UT Multi-view	['Angular Error']
Gaze Estimation	EYEDIAP (floating target)	['Angular Error']
Video Summarization	SumMe	['F1-score (Canonical)', 'F1-score (Augmented)']
Video Summarization	TvSum	['F1-score (Canonical)', 'F1-score (Augmented)']
Text Summarization	DUC 2004 Task 1	['ROUGE-1', 'ROUGE-2', 'ROUGE-L']
Text Summarization	GigaWord	['ROUGE-1', 'ROUGE-2', 'ROUGE-L']
Text Summarization	CNN / Daily Mail	[]
Text Summarization	Warning: Evaluation Metrics	[]
Human Part Segmentation	PASCAL-Person-Part	['mIoU']
Human Part Segmentation	CIHP	['Mean IoU']
Human Part Segmentation	MHP v2.0	['Mean IoU']
Atari Games	Atari 2600 Bowling	['Score']
Atari Games	Atari 2600 Freeway	['Score']
Atari Games	Atari 2600 Tutankham	['Score']
Atari Games	Atari 2600 Gravitar	['Score']
Atari Games	Atari 2600 Kung-Fu Master	['Score']
Atari Games	Atari 2600 Krull	['Score']
Atari Games	Atari 2600 Surround	['Score']
Atari Games	Atari 2600 Gopher	['Score']
Atari Games	Atari 2600 Video Pinball	['Score']
Atari Games	Atari 2600 Battle Zone	['Score']
Atari Games	Atari 2600 Private Eye	['Score']
Atari Games	Atari 2600 Montezuma's Revenge	['Score']
Atari Games	Atari 2600 Centipede	['Score']
Atari Games	Atari 2600 Defender	['Score']
Atari Games	Atari 2600 Asterix	['Score']
Atari Games	Atari 2600 Amidar	['Score']
Atari Games	Atari 2600 Crazy Climber	['Score']
Atari Games	Atari 2600 Phoenix	['Score']
Atari Games	Atari 2600 Tennis	['Score']
Atari Games	Atari 2600 Asteroids	['Score']
Atari Games	Atari 2600 Skiing	['Score']
Atari Games	Atari 2600 Berzerk	['Score']
Atari Games	Atari 2600 Chopper Command	['Score']
Atari Games	Atari 2600 Up and Down	['Score']
Atari Games	Atari 2600 Kangaroo	['Score']
Atari Games	Atari 2600 Road Runner	['Score']
Atari Games	Atari 2600 Q*Bert	['Score']
Atari Games	Atari 2600 Double Dunk	['Score']
Atari Games	Atari 2600 Alien	['Score']
Atari Games	Atari 2600 Demon Attack	['Score']
Atari Games	Atari 2600 Atlantis	['Score']
Atari Games	Atari 2600 Yars Revenge	['Score']
Atari Games	Atari 2600 Name This Game	['Score']
Atari Games	Atari 2600 Enduro	['Score']
Atari Games	Atari 2600 Venture	['Score']
Atari Games	Atari 2600 Bank Heist	['Score']
Atari Games	Atari 2600 Robotank	['Score']
Atari Games	Atari 2600 HERO	['Score']
Atari Games	Atari 2600 Seaquest	['Score']
Atari Games	Atari 2600 River Raid	['Score']
Atari Games	Atari 2600 James Bond	['Score']
Atari Games	Atari 2600 Breakout	['Score']
Atari Games	Atari 2600 Zaxxon	['Score']
Atari Games	Atari 2600 Solaris	['Score']
Atari Games	Atari 2600 Frostbite	['Score']
Atari Games	Atari 2600 Pong	['Score']
Atari Games	Atari 2600 Ice Hockey	['Score']
Atari Games	Atari 2600 Wizard of Wor	['Score']
Atari Games	Atari 2600 Fishing Derby	['Score']
Atari Games	Atari 2600 Boxing	['Score']
Atari Games	Atari 2600 Time Pilot	['Score']
Atari Games	Atari 2600 Ms. Pacman	['Score']
Atari Games	Atari 2600 Star Gunner	['Score']
Atari Games	Atari 2600 Space Invaders	['Score']
Atari Games	Atari 2600 Assault	['Score']
Atari Games	Atari 2600 Beam Rider	['Score']
Atari Games	Atari-57	['Medium Human-Normalized Score']
Atari Games	Atari 2600 Pitfall!	['Score']
Talking Head Generation	VoxCeleb1 - 32-shot learning	['FID']
Talking Head Generation	VoxCeleb2 - 32-shot learning	['FID']
Talking Head Generation	VoxCeleb1	['FID']
Talking Head Generation	VoxCeleb2 - 8-shot learning	['FID']
Talking Head Generation	VoxCeleb1 - 1-shot learning	['FID']
Talking Head Generation	VoxCeleb1 - 8-shot learning	['FID']
Talking Head Generation	VoxCeleb2 - 1-shot learning	['FID']
Recommendation Systems	Douban	['RMSE']
Recommendation Systems	Netflix	['nDCG@100', 'nDCG@10', 'Recall@20', 'Recall@50', 'HR@10']
Recommendation Systems	YahooMusic	['RMSE']
Recommendation Systems	Pinterest	['nDCG@10', 'HR@10']
Recommendation Systems	YahooMusic	['RMSE']
Recommendation Systems	MovieLens 100K	['Accuracy']
Recommendation Systems	Polyvore	['Accuracy']
Recommendation Systems	MovieLens 1M	['RMSE', 'nDCG@10', 'HR@10']
Recommendation Systems	MovieLens 20M	['nDCG@100', 'nDCG@10', 'Recall@20', 'Recall@50', 'Recall@100', 'HR@10']
Recommendation Systems	MovieLens	['RMSE']
Recommendation Systems	MovieLens 10M	['RMSE']
Recommendation Systems	MovieLens 100K	['RMSE']
Recommendation Systems	Million Song Dataset	['nDCG@100', 'Recall@50', 'Recall@20', 'Recall@100']
Recommendation Systems	Flixster	['RMSE']
Paraphrase Identification	Quora Question Pairs	['Accuracy']
Question Generation	SQuAD1.1	['BLEU-4']
Question Generation	Visual Question Generation	['BLEU-1']
Question Generation	COCO Visual Question Answering (VQA) real images 1.0 open ended	['BLEU-1']
Hand Pose Estimation	NYU Hands	['Average 3D Error']
Hand Pose Estimation	MSRA Hands	['Average 3D Error']
Hand Pose Estimation	HANDS 2017	['Average 3D Error']
Hand Pose Estimation	ICVL Hands	['Average 3D Error']
Hand Pose Estimation	HANDS 2019	['Average 3D Error']
Image Retrieval	street2shop - topwear	['Accuracy']
Image Retrieval	INRIA Holidays	['Mean mAP']
Image Retrieval	Par106k	['mAP']
Image Retrieval	NUS-WIDE	['MAP']
Image Retrieval	Stanford Cars	['Recall@8']
Image Retrieval	Oxf5k	['MAP']
Image Retrieval	Oxf105k	['MAP']
Image Retrieval	Par6k	['mAP']
Image Retrieval	DeepFashion	['Recall@20']
Dimensionality Reduction	1B Words	['14 gestures accuracy']
Transfer Learning	ImageCLEF-DA	['Accuracy']
Transfer Learning	Amazon Review Polarity	['Accuracy']
Transfer Learning	Office-Home	['Accuracy']
Phrase Grounding	ReferIt	['Pointing Game Accuracy']
Phrase Grounding	Visual Genome	['Pointing Game Accuracy']
Phrase Grounding	Flickr30k	['Pointing Game Accuracy']
Hand Gesture Recognition	SHREC 2017 track on 3D Hand Gesture Recognition	['14 gestures accuracy']
Extractive Document Summarization	CNN / Daily Mail	['ROUGE-2', 'ROUGE-1', 'ROUGE-L']
Video Classification	YouTube-8M	['Hit@1', 'PERR', 'Hit@5']
Face Generation	CelebA	['FID']
Object Detection	COCO test-dev	['box AP', 'AP50', 'AP75', 'APS', 'APM', 'APL']
Object Detection	MS-COCO	['mAP @0.5:0.95']
Object Detection	COCO 2015	['Bounding Box AP']
Object Detection	PeopleArt	['MAP']
Object Detection	COCO 2017	['AP', 'Mean mAP', 'mAP @0.5:0.95', 'mAP']
Object Detection	COCO minival	['box AP', 'AP50', 'AP75', 'APS', 'APM', 'APL']
Object Detection	ImageNet Detection	['MAP']
Object Detection	PASCAL VOC 2007	['MAP', 'Mean mAP']
Object Detection	India Driving Dataset	['mAP@0.5']
Object Detection	SIXray	['1 in 10 R@5']
Object Detection	Caltech Lanes Cordova	['Accuracy']
Object Detection	BDD100k	['mAP@0.5']
Object Detection	Visual Genome	['MAP']
Abstractive Text Summarization	CNN / Daily Mail	['ROUGE-1', 'ROUGE-2', 'ROUGE-L']
Facial Landmark Detection	MAFL	['Percentage error']
Facial Landmark Detection	AFLW (Zhang CVPR 2018 crops)	['Percentage error']
Facial Landmark Detection	AFLW	['Percentage error']
Facial Landmark Detection	300-VW (C)	['AUC0.08 private']
Facial Landmark Detection	AFLW-Full	['Mean NME ']
Facial Landmark Detection	300W	['NME', 'Mean Error Rate']
Facial Landmark Detection	AFLW-Front	['Mean NME ']
Facial Landmark Detection	300W (Full)	['Mean NME ']
Audio Generation	Classical music, 5 seconds at 12 kHz	['Bits per byte']
Image Classification	100 sleep nights of 8 caregivers	['Accuracy (Dev)']
Image Classification	Imbalanced CUB-200-2011	['Accuracy', 'Average Per-Class Accuracy']
Image Classification	EMNIST-Letters	['Accuracy']
Image Classification	iNaturalist	['Top 1 Accuracy', 'Top 5 Accuracy']
Image Classification	CINIC-10	['Accuracy']
Image Classification	STL-10	['Percentage correct']
Image Classification	SVHN	['Percentage error']
Image Classification	Kuzushiji-MNIST	['Percentage error']
Image Classification	 CUB-200-2011	['Accuracy']
Image Classification	MultiMNIST	['Percentage error']
Image Classification	CIFAR-100	['Percentage correct', 'Percentage error']
Image Classification	Flowers-102	['Accuracy']
Image Classification	CIFAR-10	['Percentage correct', 'Percentage error']
Image Classification	Food-101	['Top 1 Accuracy']
Image Classification	Oxford 102 Flowers	['Top 1 Accuracy']
Image Classification	Fashion-MNIST	['Percentage error']
Image Classification	ImageNet	['Top 1 Accuracy', 'Top 5 Accuracy', 'Number of params']
Image Classification	Clothing1M	['Accuracy']
Image Classification	Stanford Cars	['Accuracy']
Image Classification	MNIST	['Percentage error', 'Accuracy']
Topic Models	20NEWS	['PPL']
Counterspeech Detection	Youtube counterspeech dataset	['F1 score']
Causal Inference	IDHP	['Average Treatment Effect Error']
Traffic Prediction	METR-LA	['MAE @ 12 step']
Traffic Prediction	PeMS-M	['MAE (60 min)']
Out-of-Distribution Detection	CIFAR-10	['AUPRC', 'FPR95']
Out-of-Distribution Detection	CIFAR-100	['AUPRC', 'FPR95']
Cross-Lingual Bitext Mining	BUCC German-to-English	['F1 score']
Cross-Lingual Bitext Mining	BUCC French-to-English	['F1 score']
Graph Regression	Lipophilicity 	['RMSE', 'RMSE@80%Train']
Graph Regression	Tox21 	['AUC@80%Train']
Face Detection	WIDER Face (Easy)	['AP']
Face Detection	WIDER Face (Hard)	['AP']
Face Detection	Annotated Faces in the Wild	['AP']
Face Detection	PASCAL Face	['AP']
Face Detection	WIDER Face (Medium)	['AP']
Face Detection	FDDB	['AP']
Face Verification	IJB-B	['TAR @ FAR=0.01']
Face Verification	IJB-A	['TAR @ FAR=0.01']
Face Verification	Labeled Faces in the Wild	['Accuracy']
Face Verification	MegaFace	['Accuracy']
Face Verification	IJB-C	['TAR @ FAR=0.01']
Face Verification	YouTube Faces DB	['Accuracy']
Video Prediction	Human3.6M	['SSIM', 'MSE', 'MAE']
Face Recognition	CFP-FP	['Accuracy']
Face Recognition	IJB-A	['TAR @ FAR=0.01']
Face Recognition	LFW	['Accuracy']
Face Recognition	AgeDB-30	['Accuracy']
Face Recognition	VGGFace2 (2.3M)	['Accuracy(on validation set)']
Face Recognition	VggFace2	['Accuracy(on validation set)']
Face Recognition	IJB-B	['TAR @ FAR=0.01']
Face Recognition	Olivetti Faces 5 Image	['Accuracy']
Facial Expression Recognition	AffectNet	['Accuracy', 'RMSE (Arousal)', 'RMSE (Valence)']
Facial Expression Recognition	FER+	['Accuracy']
Facial Expression Recognition	Real-World Affective Faces	['Accuracy']
Facial Expression Recognition	MMI	['Accuracy', 'Accuracy(10-fold)']
Facial Expression Recognition	Cohn-Kanade	['Accuracy']
Facial Expression Recognition	The Extended Cohn-Kanade Dataset(CK+)	['Accuracy(10-fold)']
Facial Expression Recognition	Acted Facial Expressions In The Wild (AFEW)	['Accuracy(on validation set)']
Facial Expression Recognition	 Static Facial Expressions in the Wild	['Accuracy']
Facial Expression Recognition	CK+	[]
Facial Expression Recognition	FER2013	['Accuracy']
Data-to-Text Generation	WebNLG	['BLEU']
Data-to-Text Generation	E2E NLG Challenge	['BLEU', 'METEOR', 'NIST', 'ROUGE-L', 'CIDEr']
Data-to-Text Generation	SR11Deep	['BLEU']
Data-to-Text Generation	Rotowire (Content Selection)	['Precision', 'Recall']
Data-to-Text Generation	RotoWire	['BLEU']
Data-to-Text Generation	RotoWire (Relation Generation)	['Precision', 'count']
Data-to-Text Generation	RotoWire (Content Ordering)	['DLD']
Pain Intensity Regression	UNBC-McMaster ShoulderPain dataset	['MAE']
Memex Question Answering	MemexQA	['Accuracy']
Defocus Estimation	Blur Detection Dataset	['Blur Segmentation Accuracy']
Game of Go	ELO Ratings	['ELO Rating']
Game of Shogi	ELO Ratings	['ELO Rating']
Autonomous Navigation	mtrl-auto-uav	['none']
Multi-agent Reinforcement Learning	ParticleEnvs Cooperative Communication	['final agent reward']
Meta-Learning	Mini-ImageNet - 1-Shot Learning	['Accuracy']
Point Cloud Super Resolution	SHREC15	['F-measure (%)']
Face Anonymization	2019_test set	['10%']
Graph-to-Sequence	LDC2015E86:	['BLEU']
Passage Re-Ranking	MS MARCO	['MRR']
Language Acquisition	SLAM 2018	['AUC']
Depth Completion	KITTI Depth Completion	['RMSE', 'MAE', 'iRMSE', 'iMAE']
Text Classification	DBpedia	['Error']
Text Classification	R8	['Accuracy']
Text Classification	Yelp-5	['Accuracy']
Text Classification	TREC-50	['Error']
Text Classification	Amazon-2	['Error']
Text Classification	Yahoo! Answers	['Accuracy']
Text Classification	TREC	[]
Text Classification	Yelp-2	['Accuracy']
Text Classification	Sogou News	['Accuracy']
Text Classification	WMT2014 English-French	['BLEU score']
Text Classification	R52	['Accuracy']
Text Classification	Amazon-5	['Error']
Text Classification	TREC-6	['Error']
Text Classification	AG News	['Error']
Text Classification	IMDb	['Accuracy']
Text Classification	Ohsumed	['Accuracy']
Text Classification	20NEWS	['Accuracy']
Text Classification	SST-5 Fine-grained classification	['Accuracy']
Lung Nodule Detection	LUNA2016 FPRED	['AUC']
Cancer Metastasis Detection	PatchCamelyon	['AUC']
Aspect-Based Sentiment Analysis	SemEval 2014 Task 4 Sub Task 2	['Mean Acc (Restaurant + Laptop)', 'Restaurant (Acc)', 'Laptop (Acc)']
Aspect-Based Sentiment Analysis	SemEval-2016 Task 5 Subtask 1	['Restaurant (Acc)']
Aspect-Based Sentiment Analysis	 SemEval 2015 Task 12	['Restaurant (Acc)']
Aspect-Based Sentiment Analysis	Sentihood	['Aspect', 'Sentiment']
Seizure prediction	Melbourne University Seizure Prediction	['AUC']
Linguistic Acceptability	CoLA	['Accuracy']
Multiview Learning	ShapeNet Chair	['SSIM']
Multiview Learning	ShapeNet Car	['SSIM']
Multiview Learning	Synthia Novel View Synthesis	['SSIM']
Multiview Learning	KITTI Novel View Synthesis	['SSIM']
Time Series Clustering	eICU Collaborative Research Database	['NMI (physiology_6_hours)', 'NMI (physiology_12_hours)', 'NMI (physiology_24_hours)']
Network Pruning	ImageNet	['Accuracy', 'GFLOPs']
Network Pruning	CIFAR-10	['Accuracy', 'GFLOPs', 'Inference Time (ms)']
Network Pruning	CIFAR-100	['Accuracy', 'GFLOPs']
Instance Segmentation	Cityscapes test	['Average Precision']
Instance Segmentation	COCO minival	['mask AP']
Instance Segmentation	NYU Depth v2	['MAP']
Instance Segmentation	ScanNetV1	['mAP@0.25']
Instance Segmentation	COCO test-dev	['mask AP', 'AP50', 'AP75', 'APS', 'APM', 'APL']
Instance Segmentation	ScanNetV2	['mAP@0.50']
Pose Tracking	PoseTrack2018	['MOTA']
Pose Tracking	PoseTrack2017	['MOTA']
Direction of Arrival Estimation	SOFA	['Angular Error']
Unsupervised Image-To-Image Translation	SVNH-to-MNIST	['Classification Accuracy']
Unsupervised Image-To-Image Translation	Freiburg Forest Dataset	['PSNR']
Few-Shot Semantic Segmentation	FSS-1000	['Mean IoU']
Safety Perception Recognition	Google Street Images	['Accuracy']
Line Segment Detection	wireframe dataset	['F1 score']
Line Segment Detection	York Urban Dataset	['F1 score']
Activity Recognition In Videos	HMDB51	['Accuracy']
Activity Recognition In Videos	HMDB-51	['Average accuracy of 3 splits', 'Accuracy']
Query Wellformedness	Query Wellformedness	['Accuracy']
Metric Learning	CARS196	['R@1']
Metric Learning	 CUB-200-2011	['R@1']
Question Similarity	Q2Q Arabic Benchmark	['F1 score']
Video Object Segmentation	YouTube	['mIoU']
Video Object Segmentation	DAVIS-2017	['mIoU']
Video Object Segmentation	DAVIS 2016	['Jaccard (Mean)']
Participant Intervention Comparison Outcome Extraction	EBM-NLP	['F1']
Music Genre Recognition	chords	['Accuracy']
Quantization	CIFAR-10	['MAP']
Dense Pixel Correspondence Estimation	HPatches	['Viewpoint I AEPE', 'Viewpoint II AEPE', 'Viewpoint III AEPE', 'Viewpoint IV AEPE', 'Viewpoint V AEPE']
Density Estimation	ImageNet 32x32	['bpd']
Density Estimation	ImageNet64x64	['bpd']
Image Cropping	AVA	['Bounding Box AP']
Document Ranking	ClueWeb09-B	['ERR@20', 'nDCG@20']
Pneumonia Detection	ChestX-ray14	['AUROC']
Conversational Response Selection	Ubuntu Dialogue (v1, Ranking)	['1 in 10 R@1']
Conversational Response Selection	PolyAI AmazonQA	['1-of-100 Accuracy']
Conversational Response Selection	PolyAI Reddit	['1-of-100 Accuracy']
Conversational Response Selection	PolyAI OpenSubtitles	['1-of-100 Accuracy']
Conversational Response Selection	DSTC7 Ubuntu	['1-of-100 Accuracy']
Lung Nodule Classification	LIDC-IDRI	['Acc', 'Accuracy', 'AUC', 'Accuracy(10-fold)']
Sign Language Translation	RWTH-PHOENIX-Weather 2014 T	['BLEU-4']
Weakly Supervised Action Localization	ActivityNet-1.3	['mAP@0.5']
Weakly Supervised Action Localization	THUMOS 2014	['MAP']
Weakly Supervised Action Localization	ActivityNet-1.2	['mAP@0.5']
Birds Eye View Object Detection	KITTI Pedestrians Moderate	['AP']
Birds Eye View Object Detection	KITTI Cyclists Moderate	['AP']
Birds Eye View Object Detection	KITTI Cars Moderate	['AP']
Link Sign Prediction	Bitcoin-Alpha	['AUC']
Link Sign Prediction	Epinions	['AUC']
Link Sign Prediction	Bitcoin-OTC	['AUC']
Link Sign Prediction	Slashdot	['AUC']
Person Retrieval	SoftBioSearch	['Average IOU']
Fine-Grained Image Classification	CompCars	['Accuracy']
Fine-Grained Image Classification	Stanford Dogs	['Accuracy']
Fine-Grained Image Classification	Imbalanced CUB-200-2011	['Accuracy', 'Average Per-Class Accuracy']
Fine-Grained Image Classification	NABirds	['Accuracy']
Fine-Grained Image Classification	Caltech-101	['Top-1 Error Rate']
Fine-Grained Image Classification	Flowers-102	['Accuracy']
Fine-Grained Image Classification	Stanford Cars	['Accuracy', 'Top-1 Error Rate']
Fine-Grained Image Classification	Birdsnap	['Accuracy']
Fine-Grained Image Classification	 CUB-200-2011	['Accuracy']
Fine-Grained Image Classification	Oxford-IIIT Pets	['Top-1 Error Rate', 'Accuracy']
Fine-Grained Image Classification	FGVC Aircraft	['Accuracy', 'Top-1 Error Rate']
Fine-Grained Image Classification	Oxford 102 Flowers	['Accuracy', 'Top-1 Error Rate']
Fine-Grained Image Classification	Food-101	['Top 1 Accuracy']
Meeting Summarization	300W	['10%']
3D Object Classification	ModelNet40	['Classification Accuracy']
Table-to-Text Generation	WikiBio	['BLEU', 'ROUGE']
Table-to-Text Generation	Wikipedia Person and Animal Dataset	['BLEU', 'METEOR', 'ROUGE']
3D Face Animation	AQUAINT	['28 gestures accuracy']
3D Semantic Segmentation	SemanticKITTI	['mIoU']
3D Semantic Segmentation	KITTI Semantic Segmentation	['mIoU']
3D Semantic Segmentation	Semantic3D	['mIoU']
Game of Suduko	Sudoko 9x9	['Accuracy']
Action Recognition In Videos	NTU RGB+D	['Accuracy (CS)', 'Accuracy (CV)']
Action Recognition In Videos	Sports-1M	['Video hit@1 ', 'Video hit@5', 'Clip Hit@1']
Action Recognition In Videos	IRD	['Accuracy']
Action Recognition In Videos	EgoGesture	['Accuracy']
Action Recognition In Videos	UCF101	['3-fold Accuracy']
Action Recognition In Videos	Jester	['Val']
Action Recognition In Videos	Something-Something V1	['Top 1 Accuracy']
Action Recognition In Videos	VIRAT Ground 2.0	['Average Accuracy']
Action Recognition In Videos	ActionNet-VE	['F-measure (%)']
Action Recognition In Videos	VIVA Hand Gestures Dataset	['Accuracy']
Action Recognition In Videos	Charades	['MAP']
Action Recognition In Videos	AVA v2.1	['mAP (Val)', 'GFlops', 'Params (M)']
Action Recognition In Videos	THUMOS’14	['mAP@0.5', 'mAP@0.1', 'mAP@0.2', 'mAP@0.3', 'mAP@0.4']
Action Recognition In Videos	miniSports	['Accuracy', 'Video hit@1', 'Video hit@5', 'Clip Hit@1']
Action Recognition In Videos	HMDB-51	['Average accuracy of 3 splits']
Action Recognition In Videos	NTU RGB+D 120	['Accuracy (Cross-Setup)', 'Accuracy (Cross-Subject)']
Action Recognition In Videos	UTD-MHAD	['Accuracy']
Action Recognition In Videos	ActivityNet	['mAP']
Action Recognition In Videos	ICVL-4	['Accuracy']
Action Recognition In Videos	J-HMBD Early Action	['10%']
Action Recognition In Videos	Something-Something V2	['Top-1 Accuracy', 'Top-5 Accuracy']
Text-To-Sql	WikiSQL	['Accuracy (agg)', 'Accuracy (sel)', 'Accuracy (anywhere)']
Speech Enhancement	TCD-TIMIT corpus (mixed-speech)	['PESQ']
Speech Enhancement	GRID corpus (mixed-speech)	['PESQ']
Time Series	Bitcoin-Alpha	['Accuracy']
Time Series	2019_test set	['Accuracy']
One-Shot Learning	MNIST	['Accuracy']
Speech Synthesis	Mandarin Chinese	['Mean Opinion Score']
Speech Synthesis	North American English	['Mean Opinion Score']
Relationship Extraction (Distant Supervised)	New York Times Corpus	['P@10%', 'P@30%', 'AUC', 'Average Precision']
Information Retrieval	TREC-PM	['infNDCG']
CCG Supertagging	CCGBank	['Accuracy']
Graph Classification	RE-M5K	['Accuracy']
Graph Classification	NCI-123	['Accuracy']
Graph Classification	PROTEINS	['Accuracy']
Graph Classification	MUTAG	['Accuracy', 'Accuracy(10-fold)']
Graph Classification	NEURON-MULTI	['Accuracy']
Graph Classification	COIL-RAG	['Accuracy']
Graph Classification	HIV dataset	['Accuracy']
Graph Classification	NC1	['Accuracy']
Graph Classification	BP-fMRI-97	['Accuracy', 'F1']
Graph Classification	PTC	['Accuracy']
Graph Classification	SYNTHIE	['Accuracy']
Graph Classification	FRANKENSTEIN	['Accuracy']
Graph Classification	ENZYMES	['Accuracy', '10 fold Cross validation']
Graph Classification	IMDb-B	['Accuracy']
Graph Classification	NCI109	['Accuracy']
Graph Classification	HYDRIDES	['Accuracy']
Graph Classification	COLLAB	['Accuracy']
Graph Classification	NEURON-Average	['Accuracy']
Graph Classification	NCI1	['Accuracy']
Graph Classification	IPC-grounded	['Accuracy']
Graph Classification	20NEWS	['Accuracy-CN']
Graph Classification	D&D	['Accuracy']
Graph Classification	RE-M12K	['Accuracy']
Graph Classification	NEURON-BINARY	['Accuracy']
Graph Classification	IMDb-M	['Accuracy']
Graph Classification	HIV-fMRI-77 	['Accuracy', 'F1']
Graph Classification	HIV-DTI-77	['Accuracy', 'F1']
Graph Classification	IPC-lifted	['Accuracy']
Graph Classification	REDDIT-MULTI-12K	['Accuracy']
Graph Classification	REDDIT-B	['Accuracy']
Graph Classification	NCI-83	['Accuracy']
Graph Classification	NCI33	['Accuracy']
Multi-Armed Bandits	Mushroom	['Cumulative regret']
Vision-Language Navigation	Room2Room	['spl']
SQL-to-Text	WikiSQL	['BLEU-4']
Node Classification	Amazon2M	['F1']
Node Classification	Cora (3%)	['Accuracy']
Node Classification	Deezer Croatia	['Micro-F1']
Node Classification	Deezer Romania	['Micro-F1']
Node Classification	PubMed (0.05%)	['Accuracy']
Node Classification	MUTAG	['Accuracy']
Node Classification	Cora: fixed 20 node per class	['Accuracy']
Node Classification	Cora with Public Split: fixed 20 nodes per class	['Accuracy']
Node Classification	Pubmed	['Accuracy', 'Training Split', 'F1', 'Validation']
Node Classification	BlogCatalog	['Macro-F1', 'Accuracy']
Node Classification	CiteSeer (0.5%)	['Accuracy']
Node Classification	20NEWS	['Accuracy']
Node Classification	Citeseer	['Accuracy', 'Training Split', 'Validation']
Node Classification	YouTube	['Macro-F1@2%', 'Micro-F1@2%', 'runtime (s)']
Node Classification	Coauthor CS	['Accuracy']
Node Classification	CiteSeer (1%)	['Accuracy']
Node Classification	AM	['Accuracy']
Node Classification	NELL	['Accuracy']
Node Classification	BGS	['Accuracy']
Node Classification	AMZ Photo	['Accuracy']
Node Classification	MS ACADEMIC	['Accuracy']
Node Classification	Deezer Hungary	['Micro-F1']
Node Classification	AMZ Comp	['Accuracy']
Node Classification	PPI	['F1', 'Accuracy']
Node Classification	PubMed (0.03%)	['Accuracy']
Node Classification	PubMed with Public Split: fixed 20 nodes per class	['Accuracy']
Node Classification	Cora	['Accuracy', 'Training Split', 'AUC', 'Validation']
Node Classification	Cora (1%)	['Accuracy']
Node Classification	Reddit	['Accuracy']
Node Classification	Citeseer Full-supervised	['Accuracy']
Node Classification	Cora (0.5%)	['Accuracy']
Node Classification	Wikipedia	['Accuracy', 'Macro-F1']
Node Classification	Flickr	['Macro-F1@10%', 'Micro-F1@10%', 'training time (s)']
Node Classification	CiteSeer with Public Split: fixed 20 nodes per class	['Accuracy']
Node Classification	Cora Full-supervised	['Accuracy']
Node Classification	PubMed (0.1%)	['Accuracy']
Node Classification	Pubmed Full-supervised	['Accuracy']
Node Classification	Wiki	['AUC']
Node Classification	AIFB	['Accuracy']
Surgical Skills Evaluation	JIGSAWS	['Accuracy']
Music Modeling	JSB Chorales	['NLL']
Music Modeling	Nottingham	['NLL']
Mortality Prediction	MIMIC-III	['F1 score', 'Precision', 'Recall']
Click-Through Rate Prediction	Dianping	['AUC', 'Log Loss']
Click-Through Rate Prediction	Click-Through Rate Prediction	['Log Loss']
Click-Through Rate Prediction	Amazon	['AUC']
Click-Through Rate Prediction	Criteo	['AUC', 'Log Loss']
Click-Through Rate Prediction	Company*	['AUC', 'Log Loss']
Click-Through Rate Prediction	iPinYou	['AUC']
Click-Through Rate Prediction	MovieLens 20M	['AUC']
Click-Through Rate Prediction	Avazu	['AUC', 'LogLoss']
Click-Through Rate Prediction	Bing News	['AUC', 'Log Loss']
Novel View Synthesis	KITTI Novel View Synthesis	['SSIM']
Novel View Synthesis	ShapeNet Chair	['SSIM']
Novel View Synthesis	ShapeNet Car	['SSIM']
Novel View Synthesis	Synthia Novel View Synthesis	['SSIM']
Sentence Compression	Google Dataset	['CR', 'F1']
Sign Language Recognition	RWTH-PHOENIX-Weather 2014	['Word Error Rate (WER)']
Entity Typing	 Open Entity	['F1']
Sparse Learning	ImageNet	['Top-1 Accuracy']
Entity Disambiguation	WNED-CWEB	['Micro-F1']
Entity Disambiguation	AQUAINT	['Micro-F1']
Entity Disambiguation	TAC2010	['Micro-F1']
Entity Disambiguation	MSNBC	['Micro-F1']
Entity Disambiguation	WNED-WIKI	['Micro-F1']
Entity Disambiguation	AIDA-CoNLL	['Micro-F1']
Entity Disambiguation	ACE2004	['Micro-F1']
Pulmonary Embolism Detection	PE-CAD FPRED	['AUC']
Salient Object Detection	HKU-IS	['MAE']
Salient Object Detection	ECSSD	['MAE']
Salient Object Detection	PASCAL-S	['MAE']
Salient Object Detection	SOD	['MAE']
Salient Object Detection	DUTS-TE	['MAE']
Salient Object Detection	DUT-OMRON	['MAE']
3D Absolute Human Pose Estimation	Human3.6M	['MPJPE']
MD17 dataset	Aspirin (1k training points)	['MAE']
Activity Prediction	ActEV	['mAP']
Twitter Bot Detection	MIB Datasets	['Accuracy']
Acoustic Novelty Detection	A3Lab PASCAL CHiME	['F1']
3D Shape Modeling	Pix3D S2	['box AP', 'mask AP', 'mesh AP']
3D Shape Modeling	Pix3D S1	['box AP', 'mask AP', 'mesh AP']
Video Reconstruction	Tai-Chi-HD	['L1']
