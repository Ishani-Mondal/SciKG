{"title": [{"text": "The TALP-UPC Phrase-based Translation Systems for WMT13: System Combination with Morphology Generation, Domain Adaptation and Corpus Filtering", "labels": [], "entities": [{"text": "TALP-UPC Phrase-based Translation", "start_pos": 4, "end_pos": 37, "type": "TASK", "confidence": 0.5495387812455496}, {"text": "Morphology Generation", "start_pos": 81, "end_pos": 102, "type": "TASK", "confidence": 0.7154007852077484}, {"text": "Corpus Filtering", "start_pos": 126, "end_pos": 142, "type": "TASK", "confidence": 0.665541335940361}]}], "abstractContent": [{"text": "This paper describes the TALP participation in the WMT13 evaluation campaign.", "labels": [], "entities": [{"text": "WMT13 evaluation", "start_pos": 51, "end_pos": 67, "type": "TASK", "confidence": 0.6233141124248505}]}, {"text": "Our participation is based on the combination of several statistical machine translation systems: based on standard phrase-based Moses systems.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 57, "end_pos": 88, "type": "TASK", "confidence": 0.6546962261199951}]}, {"text": "Variations include techniques such as morphology generation , training sentence filtering, and domain adaptation through unit derivation.", "labels": [], "entities": [{"text": "morphology generation", "start_pos": 38, "end_pos": 59, "type": "TASK", "confidence": 0.8081050515174866}, {"text": "training sentence filtering", "start_pos": 62, "end_pos": 89, "type": "TASK", "confidence": 0.6865429580211639}, {"text": "domain adaptation", "start_pos": 95, "end_pos": 112, "type": "TASK", "confidence": 0.699618011713028}]}, {"text": "The results show a coherent improvement on TER, METEOR, NIST, and BLEU scores when compared to our baseline system .", "labels": [], "entities": [{"text": "TER", "start_pos": 43, "end_pos": 46, "type": "METRIC", "confidence": 0.9992601275444031}, {"text": "METEOR", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.977556049823761}, {"text": "NIST", "start_pos": 56, "end_pos": 60, "type": "METRIC", "confidence": 0.6602560877799988}, {"text": "BLEU", "start_pos": 66, "end_pos": 70, "type": "METRIC", "confidence": 0.999506950378418}]}], "introductionContent": [{"text": "The TALP-UPC center (Center for Language and Speech Technologies and Applications at Universitat Polit\u00e8cnica de Catalunya) focused on the English to Spanish translation of the WMT13 shared task.", "labels": [], "entities": [{"text": "TALP-UPC", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.8181992769241333}, {"text": "WMT13 shared task", "start_pos": 176, "end_pos": 193, "type": "TASK", "confidence": 0.4857586820920308}]}, {"text": "Our primary (contrastive) run is an internal system selection comprised of different training approaches (without CommonCrawl, unless stated): (a) Moses Baseline (), (b) Moses Baseline + Morphology Generation (), (c) Moses Baseline + News Adaptation), (d) Moses Baseline + News Adaptation + Morphology Generation , and (e) Moses Baseline + News Adaptation + Filtered CommonCrawl Adaptation (.", "labels": [], "entities": [{"text": "News Adaptation + Morphology Generation", "start_pos": 273, "end_pos": 312, "type": "TASK", "confidence": 0.6182121992111206}]}, {"text": "Our secondary run includes is the full training strategy marked as (e) in the previous description.", "labels": [], "entities": []}, {"text": "The main differences with respect to our last year's participation () are: i) the inclusion of the CommonCrawl corpus, using a sentence filtering technique and the system combination itself, and ii) a system selection scheme to select the best translation among the different configurations.", "labels": [], "entities": [{"text": "CommonCrawl corpus", "start_pos": 99, "end_pos": 117, "type": "DATASET", "confidence": 0.9704980552196503}]}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 presents the phrase-based system and the main pipeline of our baseline system.", "labels": [], "entities": []}, {"text": "Section 3 describes the our approaches to improve the baseline system on the English-to-Spanish task (special attention is given to the approaches that differ from last year).", "labels": [], "entities": []}, {"text": "Section 4 presents the system combination approach once the best candidate phrase of the different subsystems are selected.", "labels": [], "entities": []}, {"text": "Section 5 discusses the obtained results considering both internal and official test sets.", "labels": [], "entities": []}, {"text": "Section 6 includes conclusions and further work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: System selection scores (ULC) obtained using QE models trained with different groups of  features. Results displayed for WMT11, WMT12 internal tests, their average, and the WMT13 test", "labels": [], "entities": [{"text": "System selection scores (ULC)", "start_pos": 10, "end_pos": 39, "type": "METRIC", "confidence": 0.6475877265135447}, {"text": "WMT11", "start_pos": 131, "end_pos": 136, "type": "DATASET", "confidence": 0.8547044396400452}, {"text": "WMT13 test", "start_pos": 183, "end_pos": 193, "type": "DATASET", "confidence": 0.8686123490333557}]}, {"text": " Table 4: Official automatic scores for the WMT13  English\u2194Spanish translations.", "labels": [], "entities": [{"text": "WMT13  English\u2194Spanish translations", "start_pos": 44, "end_pos": 79, "type": "DATASET", "confidence": 0.844113290309906}]}, {"text": " Table 4. Our primary  (contrastive) run is the system combination strat- egy whereas our secondary run is the full training  strategy marked as (e) on the system combination.  Our primary system was ranked in the second clus- ter out of ten constrained systems in the official  manual evaluation.", "labels": [], "entities": []}, {"text": " Table 3: Automatic scores for English\u2192Spanish translations.", "labels": [], "entities": []}]}