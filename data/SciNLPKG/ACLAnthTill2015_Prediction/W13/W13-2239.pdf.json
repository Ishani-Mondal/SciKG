{"title": [{"text": "Positive Diversity Tuning for Machine Translation System Combination", "labels": [], "entities": [{"text": "Machine Translation System Combination", "start_pos": 30, "end_pos": 68, "type": "TASK", "confidence": 0.859261766076088}]}], "abstractContent": [{"text": "We present Positive Diversity Tuning, anew method for tuning machine translation models specifically for improved performance during system combination.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 61, "end_pos": 80, "type": "TASK", "confidence": 0.6767408847808838}]}, {"text": "System combination gains are often limited by the fact that the translations produced by the different component systems are too similar to each other.", "labels": [], "entities": []}, {"text": "We propose a method for reducing excess cross-system similarity by optimizing a joint objective that simultaneously rewards models for producing translations that are similar to reference translations, while also punishing them for translations that are too similar to those produced by other systems.", "labels": [], "entities": []}, {"text": "The formulation of the Positive Diversity objective is easy to implement and allows for its quick integration with most machine translation tuning pipelines.", "labels": [], "entities": [{"text": "machine translation tuning pipelines", "start_pos": 120, "end_pos": 156, "type": "TASK", "confidence": 0.8517906665802002}]}, {"text": "We find that individual systems tuned on the same data to Positive Diversity can be even more diverse than systems built using different data sets, while still obtaining good BLEU scores.", "labels": [], "entities": [{"text": "Positive Diversity", "start_pos": 58, "end_pos": 76, "type": "TASK", "confidence": 0.7612526714801788}, {"text": "BLEU", "start_pos": 175, "end_pos": 179, "type": "METRIC", "confidence": 0.9994152784347534}]}, {"text": "When these individual systems are used together for system combination, our approach allows for significant gains of 0.8 BLEU even when the combination is performed using a small number of otherwise identical individual systems.", "labels": [], "entities": [{"text": "system combination", "start_pos": 52, "end_pos": 70, "type": "TASK", "confidence": 0.7406795024871826}, {"text": "BLEU", "start_pos": 121, "end_pos": 125, "type": "METRIC", "confidence": 0.999144434928894}]}], "introductionContent": [{"text": "The best performing machine translation systems are typically not individual decoders but rather are ensembles of two or more systems whose output is then merged using system combination algorithms.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 20, "end_pos": 39, "type": "TASK", "confidence": 0.7301820814609528}]}, {"text": "Since combining multiple distinct equally good translation systems reliably produces gains over anyone of the systems in isolation, it is widely used in situations where high quality is essential.", "labels": [], "entities": []}, {"text": "Exploiting system combination brings significant cost: showed that successful system combination requires the construction of multiple systems that are simultaneously diverse and well-performing.", "labels": [], "entities": []}, {"text": "If the systems are not distinct enough, they will bring very little value during system combination.", "labels": [], "entities": []}, {"text": "However, if some of the systems produce diverse translations but achieve lower overall translation quality, their contributions risk being ignored during system combination.", "labels": [], "entities": []}, {"text": "Prior work has approached the need for diverse systems by using different system architectures, model components, system build parameters, decoder hyperparameters, as well as data selection and weighting).", "labels": [], "entities": []}, {"text": "However, during tuning, each individual system is still just trained to maximize its own isolated performance on a tune set, or at best an error-driven reweighting of the tune set, without explicitly taking into account the diversity of the resulting translations.", "labels": [], "entities": []}, {"text": "Such tuning does not encourage systems to rigorously explore model variations that achieve both good translation quality and diversity with respect to the other systems.", "labels": [], "entities": []}, {"text": "It is reasonable to suspect that this results in individual systems that under exploit the amount of diversity possible, given the characteristics of the individual systems.", "labels": [], "entities": []}, {"text": "For better system combination, we propose building individual systems to attempt to simultaneously maximize the overall quality of the individual systems and the amount of diversity across systems.", "labels": [], "entities": []}, {"text": "We operationalize this problem formulation by devising anew heuristic measure called Positive Diversity that estimates the potential usefulness of individual systems during system combination.", "labels": [], "entities": []}, {"text": "We find that optimizing systems toward Positive Diversity leads to significant performance gains during system combination even when the combination is performed using a small number of otherwise identical individual translation systems.", "labels": [], "entities": [{"text": "Positive Diversity", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.7723616063594818}]}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 and 3 briefly review the tuning of individual machine translation systems and how system combination merges the output of multiple systems into an improved combined translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 56, "end_pos": 75, "type": "TASK", "confidence": 0.7199495881795883}]}, {"text": "Section 4 introduces our Positive Diversity measure.", "labels": [], "entities": [{"text": "Positive Diversity", "start_pos": 25, "end_pos": 43, "type": "TASK", "confidence": 0.7206672579050064}]}, {"text": "Section 5 introduces an algorithm for training a collection of translation systems toward Positive Diversity.", "labels": [], "entities": []}, {"text": "Experiments are presented in sections 6 and 7.", "labels": [], "entities": []}, {"text": "Sections 8 and 9 conclude with discussions of prior work and directions for future research.", "labels": [], "entities": []}], "datasetContent": [{"text": "Experiments are performed using a single phrase-based Chinese-to-English translation system, built with the Stanford Phrasal machine translation toolkit (Cer et al., 2010).", "labels": [], "entities": [{"text": "phrase-based Chinese-to-English translation", "start_pos": 41, "end_pos": 84, "type": "TASK", "confidence": 0.6362070043881735}, {"text": "Phrasal machine translation", "start_pos": 117, "end_pos": 144, "type": "TASK", "confidence": 0.6486140489578247}]}, {"text": "The system was built using all of the parallel data available for Phase 2 of the DARPA BOLT program.", "labels": [], "entities": [{"text": "DARPA BOLT", "start_pos": 81, "end_pos": 91, "type": "TASK", "confidence": 0.5526819825172424}]}, {"text": "The Chinese data was segmented to the Chinese TreeBank (CTB) standard using a maximum match word segmenter, trained on the output of a CRF segmenter (: BLEU scores on BOLT dev12 dev achieved by the individual PDT systems tuned on GALE dev10 web tune.", "labels": [], "entities": [{"text": "Chinese TreeBank (CTB) standard", "start_pos": 38, "end_pos": 69, "type": "DATASET", "confidence": 0.9527011414368948}, {"text": "BLEU", "start_pos": 152, "end_pos": 156, "type": "METRIC", "confidence": 0.9984691739082336}, {"text": "GALE dev10 web tune", "start_pos": 230, "end_pos": 249, "type": "DATASET", "confidence": 0.9286895543336868}]}, {"text": "Scores report individual system performance before system combination.", "labels": [], "entities": []}, {"text": "tics were used to extract a phrase-table over word alignments symmetrized using grow-diag ().", "labels": [], "entities": []}, {"text": "We made use of a hierarchical reordering model ( as well as a 5-gram language model trained on the target side of the bi-text and smoothed using modified Kneeser-Ney (.", "labels": [], "entities": []}, {"text": "Individual PDT systems were tuned on the GALE dev10 web tune set using online-PRO ( to the Positive Diversity Tuning criterion.", "labels": [], "entities": [{"text": "GALE dev10 web tune set", "start_pos": 41, "end_pos": 64, "type": "DATASET", "confidence": 0.9801829338073731}]}, {"text": "The Multi-Engine Machine Translation (MEMT) package was used for system combination.", "labels": [], "entities": [{"text": "Multi-Engine Machine Translation (MEMT)", "start_pos": 4, "end_pos": 43, "type": "TASK", "confidence": 0.7390416959921519}]}, {"text": "We used BOLT dev12 dev as a development test set to explore different \u03b1 parameterizations of the Positive Diversity criteria.", "labels": [], "entities": [{"text": "BOLT", "start_pos": 8, "end_pos": 12, "type": "METRIC", "confidence": 0.885286271572113}]}, {"text": "illustrates the amount of diversity achieved by individual PDT systems on the BOLT dev12 dev evaluation set for \u03b1 values 0.95, 0.97, and 0.99.", "labels": [], "entities": [{"text": "BOLT dev12 dev evaluation set", "start_pos": 78, "end_pos": 107, "type": "DATASET", "confidence": 0.9090038180351258}]}, {"text": "Using different tuning sets is one of the common strategies for producing diverse component systems for system combination.", "labels": [], "entities": []}, {"text": "Thus, as a baseline, gives the diversity of a system tuned to BLEU using a different tuning set, BOLT dev12 tune, with respect to the PDT systems available at each iteration.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 62, "end_pos": 66, "type": "METRIC", "confidence": 0.9876123070716858}, {"text": "BOLT dev12 tune", "start_pos": 97, "end_pos": 112, "type": "METRIC", "confidence": 0.8794277310371399}]}, {"text": "As in, the diversity computation is performed using translations of BOLT dev12 dev.", "labels": [], "entities": [{"text": "BOLT dev12 dev", "start_pos": 68, "end_pos": 82, "type": "DATASET", "confidence": 0.8915869196256002}]}], "tableCaptions": [{"text": " Table 1: Diversity scores for PDT individual systems on BOLT dev12 dev. Individual systems are tuned to  Positive Diversity on GALE dev10 web tune. A system's diversity score is measured as its 1.0\u2212BLEU  score on the translations produced by PDT systems from earlier iterations. Higher scores mean more  diversity.", "labels": [], "entities": [{"text": "BOLT dev12 dev", "start_pos": 57, "end_pos": 71, "type": "DATASET", "confidence": 0.8460843165715536}, {"text": "GALE dev10 web tune", "start_pos": 128, "end_pos": 147, "type": "DATASET", "confidence": 0.960910439491272}, {"text": "BLEU", "start_pos": 199, "end_pos": 203, "type": "METRIC", "confidence": 0.9986251592636108}]}, {"text": " Table 2: Diversity scores of a baseline system tuned to BOLT dev12 tune, a different tuning set than what  was used for the PDT individual systems. The baseline system diversity is scored against all of the PDT  individual systems available at iteration i for a given \u03b1 value and over translations of BOLT dev12 dev.", "labels": [], "entities": [{"text": "BOLT dev12 tune", "start_pos": 57, "end_pos": 72, "type": "DATASET", "confidence": 0.7585249344507853}]}, {"text": " Table 3: BLEU scores on BOLT dev12 dev achieved by the individual PDT systems tuned on GALE  dev10 web tune. Scores report individual system performance before system combination.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9981111288070679}, {"text": "BOLT dev12 dev", "start_pos": 25, "end_pos": 39, "type": "DATASET", "confidence": 0.808097779750824}, {"text": "GALE  dev10 web tune", "start_pos": 88, "end_pos": 108, "type": "DATASET", "confidence": 0.9590610712766647}]}]}