{"title": [{"text": "Native Language Identification using large scale lexical features", "labels": [], "entities": [{"text": "Native Language Identification", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.6668906013170878}]}], "abstractContent": [{"text": "This paper describes an effort to perform Native Language Identification (NLI) using machine learning on a large amount of lexical features.", "labels": [], "entities": [{"text": "Native Language Identification (NLI)", "start_pos": 42, "end_pos": 78, "type": "TASK", "confidence": 0.8250371714433035}]}, {"text": "The features were collected from sequences and collocations of bare word forms, suffixes and character n-grams amounting to a feature set of several hundred thousand features.", "labels": [], "entities": []}, {"text": "These features were used to train a linear Support Vector Machine (SVM) classifier for predicting the native language category.", "labels": [], "entities": []}], "introductionContent": [{"text": "Much effort in Native Language Identification (NLI) has focused on identifying specific characteristics of the errors in texts produced by English Second Language (ESL) learners, like the work presented in and ().", "labels": [], "entities": [{"text": "Native Language Identification (NLI)", "start_pos": 15, "end_pos": 51, "type": "TASK", "confidence": 0.8442103664080302}]}, {"text": "This might be specific spelling errors, syntactic or morphological mistakes.", "labels": [], "entities": []}, {"text": "One motivation for this approach has been the notion that aspects of the L1 language influences which errors and mistakes are produced by L2 learners, which has guided the model building towards a smaller number of features and models which lend themselves to interpretation in terms of linguistic knowledge.", "labels": [], "entities": []}, {"text": "Research so far has shown mixed support that this notion of language transfer is the best indicator of L1 language.", "labels": [], "entities": [{"text": "language transfer", "start_pos": 60, "end_pos": 77, "type": "TASK", "confidence": 0.7246866077184677}]}, {"text": "While many such features are highly predictive, features that are usually indicative of the text topic has shown strong performance when applied to the NLI task as demonstrated in and ().", "labels": [], "entities": []}, {"text": "This is largely lexical features such as frequency measures of token, lemma or character n-grams.", "labels": [], "entities": []}, {"text": "There has been some effort in identifying if this is an artifact of biases in the available corpora or if it is indeed an indication of a substantial phenomenon in ESL language use by different L1 learners).", "labels": [], "entities": []}, {"text": "The approach in this paper extends the use of lexicalized features and shows that such lexicalized features can by themselves form the basis of a competitive and robust NLI system.", "labels": [], "entities": []}, {"text": "This approach entails possibly abondoning interpretability and other linguistic considerations in order to build an as efficient as possible system on the NLI classification tasks itself.", "labels": [], "entities": [{"text": "NLI classification tasks", "start_pos": 155, "end_pos": 179, "type": "TASK", "confidence": 0.8139230012893677}]}, {"text": "It is also motivated by the possibility that simple lexicalized features can be applied efficiently in a task that on the face of it requires the system to on some level learn differences syntactic relations in addition to the differences in morphology found in text produced by the ESL learners.", "labels": [], "entities": []}, {"text": "The experiments presented in this paper area result of exploring a range of features and machine learning approaches.", "labels": [], "entities": []}, {"text": "The best systems found used a combination of bareword features, character ngrams, suffix and bareword collocations with TF-IDF weighting.", "labels": [], "entities": []}, {"text": "The resulting feature space contains several hundred thousand features which were used to train a linear Support Vector Machine (SVM) classifier.", "labels": [], "entities": []}, {"text": "I will first present the features an how they were extracted in section 2, details of the SVM model is presented in section 3, the different systems submitted to the shared task are described in section 4, along with the results in section 5.", "labels": [], "entities": []}, {"text": "I have also included som discussion of issues encountered during the development of features and models in section 6.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Performance and number of features for the submitted systems. Performance is shown as accuracy on the  development data set and 10-fold cross validation on the training and test set. The feature counts shown are for the  final systems trained on the training and development data sets. The systems are described in section 4.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 96, "end_pos": 104, "type": "METRIC", "confidence": 0.9994446635246277}, {"text": "development data set", "start_pos": 113, "end_pos": 133, "type": "DATASET", "confidence": 0.7627720236778259}]}, {"text": " Table 2: Final accuracy scores on the test set and 10-fold cross validation for the submitted systems. The systems are  described in section 4.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9716570973396301}]}]}