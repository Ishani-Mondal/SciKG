{"title": [{"text": "Automatic Detection and Correction for Chinese Misspelled Words Using Phonological and Orthographic Similarities", "labels": [], "entities": [{"text": "Automatic Detection", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.6471090465784073}]}], "abstractContent": [{"text": "How to detect and correct misspelled words in documents is a very important issue for Mandarin and Japanese.", "labels": [], "entities": [{"text": "detect and correct misspelled words in documents", "start_pos": 7, "end_pos": 55, "type": "TASK", "confidence": 0.6886232452733176}]}, {"text": "This paper uses pho-nological similarity and orthographic similarity co-occurrence to train linear regression model.", "labels": [], "entities": []}, {"text": "Using ACL-SIGHAN 2013 Bake-off Dataset, experimental results indicate that the detection F-score, error location F-score of our proposed method for Subtask 1 is 0.70 and 0.43 respectively, and the correction accuracy of the proposed method for Subtask 1 is 0.39.", "labels": [], "entities": [{"text": "ACL-SIGHAN 2013 Bake-off Dataset", "start_pos": 6, "end_pos": 38, "type": "DATASET", "confidence": 0.9323683083057404}, {"text": "detection", "start_pos": 79, "end_pos": 88, "type": "METRIC", "confidence": 0.9417358636856079}, {"text": "F-score", "start_pos": 89, "end_pos": 96, "type": "METRIC", "confidence": 0.5206408500671387}, {"text": "error location F-score", "start_pos": 98, "end_pos": 120, "type": "METRIC", "confidence": 0.93189537525177}, {"text": "correction accuracy", "start_pos": 197, "end_pos": 216, "type": "METRIC", "confidence": 0.8433206081390381}]}], "introductionContent": [{"text": "How to automatically detect and correct misspelled words in documents is a very important issue.", "labels": [], "entities": [{"text": "automatically detect and correct misspelled words in documents", "start_pos": 7, "end_pos": 69, "type": "TASK", "confidence": 0.6437201052904129}]}, {"text": "It is not an easy task for programs to spot misspelled words automatically.", "labels": [], "entities": []}, {"text": "In English sentences, words are separated by space, thereby leading to the result that it is not difficult to distinguish if there are characters with nonexisting orthography and unknown words.", "labels": [], "entities": []}, {"text": "However, Chinese sentences are constructed by successive single-character, and a word could consist of one character or more.", "labels": [], "entities": []}, {"text": "As a result, it is difficult to identify whether a character is apart of a misspelled word or not.", "labels": [], "entities": []}, {"text": "Based on our observation, misspelled words mainly occur as the following cases: phonological similarity and orthographic similarity.", "labels": [], "entities": []}, {"text": "For example, word '\u5df2\u7d93' is mistakenly written as '\u4ee5\u7d93' due to the fact that characters '\u5df2' and '\u4ee5' are pronounced as 'yi'.", "labels": [], "entities": []}, {"text": "In addition, word '\u4ee3\u8868' is mistakenly written as '\u4f10\u8868' because the orthographic of characters '\u4ee3' and '\u4f10' are quite confusing.", "labels": [], "entities": []}, {"text": "As a result, it may work to identify the possible misspelled words within sentences by phonological similarity and orthographic similarity between two characters.", "labels": [], "entities": []}, {"text": "The purpose of the study is to propose a method to detecting and correcting misspelled words in sentences.", "labels": [], "entities": [{"text": "detecting and correcting misspelled words in sentences", "start_pos": 51, "end_pos": 105, "type": "TASK", "confidence": 0.8258741412843976}]}, {"text": "The proposed method does not rely on the collection of similar words, but based on the following assumption.", "labels": [], "entities": []}, {"text": "Supposing there was no misspelled word in sentences, ideal word segmentation method could divide sentence into serial correct words.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 59, "end_pos": 76, "type": "TASK", "confidence": 0.7556551992893219}]}, {"text": "However, if there was a misspelled word, the segmentation could separate words containing misspelled character by serial characters.", "labels": [], "entities": []}, {"text": "For instance, sentence '\u6211\u5011\u90fd \u559c\u6b61\u5b78\u4f7c' will be segmented into '\u6211\u5011 \u90fd \u559c\u6b61 \u5b78 \u4f7c' due to the fact that '\u5b78\u4f7c' cannot be found in the dictionary, thus segmenting '\u5b78' and '\u4f7c' respectively.", "labels": [], "entities": []}, {"text": "By the observation mention above, a sentence may include several character sequences consisting of two or more than two characters, denoted as sentential fragments.", "labels": [], "entities": []}, {"text": "Each character in fragments maybe the wrong part of a misspelling word while other characters are the correct part of the word.", "labels": [], "entities": []}, {"text": "Hence, for each character treated as correct part of a misspelled word, the proposed method picks up the words containing the character.", "labels": [], "entities": []}, {"text": "The words will be denoted as \"candidate words\".", "labels": [], "entities": []}, {"text": "On the other hand, all characters in the fragment maybe single-character words.", "labels": [], "entities": []}, {"text": "The sentential fragment referring to candidate words is called \"original string\" in this paper.", "labels": [], "entities": []}, {"text": "By calculating the probability of candidate words and original strings, the proposed method can determine whether the original strings contain misspelled words or not and correct the words.", "labels": [], "entities": []}, {"text": "Next section will address the details.", "labels": [], "entities": []}, {"text": "proposed detecting technique of Mandarin misspelled word.", "labels": [], "entities": []}, {"text": "Although it was able to find out misspelled words, there were some defects needed to be improved.", "labels": [], "entities": []}, {"text": "For example, too much False Alert, long detection time, notable to refer to entire paragraph.", "labels": [], "entities": [{"text": "False Alert", "start_pos": 22, "end_pos": 33, "type": "METRIC", "confidence": 0.9376570582389832}]}, {"text": "utilized rule-based with linguistic model to detect mistakes.", "labels": [], "entities": []}, {"text": "Although it was not very efficient, it was anew concept at the time.", "labels": [], "entities": []}, {"text": "focused on misspelled words occurred in Cangjie input method and put forward a detecting system.", "labels": [], "entities": []}, {"text": "designed a correcting system for wrong phonological words which built up similar phonological word collection for every single word.", "labels": [], "entities": []}, {"text": "The correcting system also used bi-gram linguistic model to position the misspelled word, and replaced it with the most likely fit word.", "labels": [], "entities": []}], "datasetContent": [{"text": "This paper use the data provided by ACL-SIGHAN 2013 Bake-off to conduct performance evaluation.", "labels": [], "entities": [{"text": "ACL-SIGHAN 2013 Bake-off", "start_pos": 36, "end_pos": 60, "type": "DATASET", "confidence": 0.9190513888994852}]}, {"text": "The data is divided into two sets called 'dry run' and 'final test' while the evaluation includes two tasks sub-task 1 and sub-task 2.", "labels": [], "entities": []}, {"text": "Each set consist of two subsets which is employed to evaluate the performance of methods for two tasks respectively.", "labels": [], "entities": []}, {"text": "In dry run, sub-task 1 and sub-task 2 each use 50 example sentences for testing.", "labels": [], "entities": []}, {"text": "In final test, sub-task 1 and sub-task 2 each use 1000 example sentences for testing.", "labels": [], "entities": []}, {"text": "The purposes of sub-task 1 and sub-task 2 are to respectively evaluate the performance of error detection and error correction of methods.", "labels": [], "entities": [{"text": "error detection", "start_pos": 90, "end_pos": 105, "type": "TASK", "confidence": 0.6817198991775513}]}, {"text": "presents the evaluation result of Subtask 1 in our proposed method, denoted as KUAS-NTNU, and results of sub-task 2 are shown in.", "labels": [], "entities": [{"text": "KUAS-NTNU", "start_pos": 79, "end_pos": 88, "type": "DATASET", "confidence": 0.7852302193641663}]}, {"text": "Since SIGHAN has not reported the F-score for sub-task 1 in dry run, Table 1 does not show the detection F-score and error location F-score of dry run..", "labels": [], "entities": [{"text": "SIGHAN", "start_pos": 6, "end_pos": 12, "type": "DATASET", "confidence": 0.7249898910522461}, {"text": "F-score", "start_pos": 34, "end_pos": 41, "type": "METRIC", "confidence": 0.9967551827430725}, {"text": "F-score", "start_pos": 105, "end_pos": 112, "type": "METRIC", "confidence": 0.6833474636077881}, {"text": "error location F-score", "start_pos": 117, "end_pos": 139, "type": "METRIC", "confidence": 0.898904005686442}]}, {"text": "The Performance of KUAS-NTNU System for Subtask 2.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. The Performance of KUAS-NTNU Sys- tem for Subtask 1.", "labels": [], "entities": [{"text": "KUAS-NTNU Sys- tem", "start_pos": 29, "end_pos": 47, "type": "DATASET", "confidence": 0.772698849439621}]}, {"text": " Table 2. The Performance of KUAS-NTNU Sys- tem for Subtask 2.", "labels": [], "entities": [{"text": "KUAS-NTNU Sys- tem", "start_pos": 29, "end_pos": 47, "type": "DATASET", "confidence": 0.7838671952486038}]}]}