{"title": [{"text": "Dynamic Knowledge-Base Alignment for Coreference Resolution", "labels": [], "entities": [{"text": "Dynamic Knowledge-Base Alignment", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7013680140177408}, {"text": "Coreference Resolution", "start_pos": 37, "end_pos": 59, "type": "TASK", "confidence": 0.9679413437843323}]}], "abstractContent": [{"text": "Coreference resolution systems can benefit greatly from inclusion of global context, and a number of recent approaches have demonstrated improvements when precom-puting an alignment to external knowledge sources.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.921891450881958}]}, {"text": "However, since alignment itself is a challenging task and is often noisy, existing systems either align conservatively, resulting in very few links, or combine the attributes of multiple candidates, leading to a conflation of entities.", "labels": [], "entities": []}, {"text": "Our approach instead performs joint inference between within-document coreference and entity linking, maintaining ranked lists of candidate entities that are dynamically merged and reranked during inference.", "labels": [], "entities": [{"text": "entity linking", "start_pos": 86, "end_pos": 100, "type": "TASK", "confidence": 0.7088425010442734}]}, {"text": "Further, we incorporate a large set of surface string variations for each entity by using anchor texts from the web that link to the entity.", "labels": [], "entities": []}, {"text": "These forms of global context enables our system to improve classifier-based coreference by 1.09 B 3 F1 points, and improve over the previous state-of-art by 0.41 points, thus introducing anew state-of-art result on the ACE 2004 data.", "labels": [], "entities": [{"text": "F1", "start_pos": 101, "end_pos": 103, "type": "METRIC", "confidence": 0.9853417873382568}, {"text": "ACE 2004 data", "start_pos": 220, "end_pos": 233, "type": "DATASET", "confidence": 0.9858805537223816}]}], "introductionContent": [{"text": "Coreference resolution is the task of identifying sets of noun phrase mentions from a document that refer to the same real-world entities.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9188064336776733}]}, {"text": "For example, in the following excerpt: \"The Chicago suburb of Arlington Heights is the first stop for George W. Bush 1 today.", "labels": [], "entities": []}, {"text": "The Texas governor 2 stops in Gore's home state 3 of Tennessee 4 this afternoon.", "labels": [], "entities": [{"text": "Gore's home state 3 of Tennessee 4", "start_pos": 30, "end_pos": 64, "type": "DATASET", "confidence": 0.7943814769387245}]}, {"text": "\", (m 1 , m 2 ) and (m 3 , m 4 ) define the coreferent pairs.", "labels": [], "entities": []}, {"text": "Coreference resolution forms an important component for natural language processing and information extraction pipelines due to its utility in relation extraction, cross-document coreference, text summarization, and question answering.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9421620070934296}, {"text": "information extraction pipelines", "start_pos": 88, "end_pos": 120, "type": "TASK", "confidence": 0.8062131206194559}, {"text": "relation extraction", "start_pos": 143, "end_pos": 162, "type": "TASK", "confidence": 0.8232100009918213}, {"text": "text summarization", "start_pos": 192, "end_pos": 210, "type": "TASK", "confidence": 0.7379105985164642}, {"text": "question answering", "start_pos": 216, "end_pos": 234, "type": "TASK", "confidence": 0.9009961485862732}]}, {"text": "The task of coreference is challenging for automated systems as the local information contained in the document is often not enough to accurately disambiguate mentions, for example, coreferencing (m 1 , m 2 ) requires identifying that George W. Bush (m 1 ) is the governor of Texas (m 2 ), and similarly for (m 3 , m 4 ).", "labels": [], "entities": [{"text": "coreference", "start_pos": 12, "end_pos": 23, "type": "TASK", "confidence": 0.9588947892189026}]}, {"text": "External knowledge-bases such as FrameNet (), Wikipedia,, and Freebase, can be used to provide global context, and there is a strong need for coreference resolution systems to accurately use such sources for disambiguation.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 62, "end_pos": 70, "type": "DATASET", "confidence": 0.9465005397796631}, {"text": "coreference resolution", "start_pos": 142, "end_pos": 164, "type": "TASK", "confidence": 0.8966754972934723}]}, {"text": "Incorporating external knowledge bases into coreference has been the subject of active recent research. and precompute a fixed alignment of the mentions to the knowledge base entities.", "labels": [], "entities": []}, {"text": "The attributes of these entities are used during coreference by incorporating them in the mention features.", "labels": [], "entities": []}, {"text": "Since alignment of mentions to the external entities is itself a difficult task, these systems favor high-precision linking.", "labels": [], "entities": [{"text": "alignment of mentions", "start_pos": 6, "end_pos": 27, "type": "TASK", "confidence": 0.8761811057726542}]}, {"text": "Unfortunately, this results in fewer alignments, and improvements are only shown on mentions that are easier to align and corefer (such as the non-transcript documents in Ratinov and Roth).", "labels": [], "entities": []}, {"text": "Alternatively, Rahman and Ng (2011) link each mention to multiple entities in the knowledge base, improving recall at the cost of lower precision; the attributes of all the linked entities are aggregated as features.", "labels": [], "entities": [{"text": "recall", "start_pos": 108, "end_pos": 114, "type": "METRIC", "confidence": 0.9990596175193787}, {"text": "precision", "start_pos": 136, "end_pos": 145, "type": "METRIC", "confidence": 0.9988252520561218}]}, {"text": "Although this approach is more robust to noise in the documents, the features of a mention merge the different aspects of the entities, for example a \"Michael Jordan\" mention will contain features for both the scientist and basketball personas.", "labels": [], "entities": []}, {"text": "Instead of fixing the alignment of the mentions to the knowledge base, our proposed approach maintains a ranked list of candidate entities for each mention.", "labels": [], "entities": []}, {"text": "To expand the set of surface strings that maybe used to refer to each entity, the attributes of each candidate contain anchor texts (the visible text) of the links on the web that refer to that entity candidate.", "labels": [], "entities": []}, {"text": "When mentions are compared during inference, we use the features computed from the top ranked entity candidate of the antecedent mention.", "labels": [], "entities": []}, {"text": "As mentions are merged, the ranked lists of candidate entities are also merged and reranked, often changing the top-ranked entity candidate used in subsequent comparisons.", "labels": [], "entities": []}, {"text": "The large set of surface string variations and constant reranking of the entity candidates during inference allows our approach to correct mistakes in alignment and makes external information applicable to a wider variety of mentions.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: B 3 F1 accuracy on transcripts and non- transcripts from the ACE test data. RR 2012 only  evaluate on non-transcripts.", "labels": [], "entities": [{"text": "B 3 F1", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.8923647801081339}, {"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.7917282581329346}, {"text": "ACE test data", "start_pos": 71, "end_pos": 84, "type": "DATASET", "confidence": 0.9787139693895975}, {"text": "RR 2012", "start_pos": 86, "end_pos": 93, "type": "DATASET", "confidence": 0.6770781725645065}]}, {"text": " Table 2: Evaluation on the ACE test data, with the system trained on the train and development sets.", "labels": [], "entities": [{"text": "ACE test data", "start_pos": 28, "end_pos": 41, "type": "DATASET", "confidence": 0.9198044538497925}]}]}