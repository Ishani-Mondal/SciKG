{"title": [{"text": "Investigating speaker gaze and pointing behaviour in human-computer interaction with the mint.tools collection", "labels": [], "entities": []}], "abstractContent": [{"text": "Can speaker gaze and speaker arm movements be used as a practical information source for naturalistic conversational human-computer interfaces?", "labels": [], "entities": []}, {"text": "To investigate this question, we recorded (with eye tracking and motion capture) a corpus of interactions with a (wizarded) system.", "labels": [], "entities": []}, {"text": "In this paper, we describe the recording, analysis infrastructure that we built for such studies, and analysis we performed on these data.", "labels": [], "entities": []}, {"text": "We find that with some initial calibration, a \"minimally invasive\", stationary camera-based setting provides data of sufficient quality to support interaction.", "labels": [], "entities": []}], "introductionContent": [{"text": "The availability of sensors such as Microsoft Kinect and (almost) affordable eye trackers bring new methods of naturalistic human-computer interaction within reach.", "labels": [], "entities": []}, {"text": "Studying the possibilities of such methods requires building infrastructure for recording and analysing such data ().", "labels": [], "entities": []}, {"text": "We present such an infrastructurethe mint.tools collection (see also)) 1 -and present results of a study we performed on whether speaker gaze and speaker arm movements can be turned into an information source for an interactive system.", "labels": [], "entities": [{"text": "mint.tools collection", "start_pos": 37, "end_pos": 58, "type": "DATASET", "confidence": 0.8470826745033264}]}], "datasetContent": [], "tableCaptions": []}