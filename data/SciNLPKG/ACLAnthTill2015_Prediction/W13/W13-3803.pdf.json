{"title": [{"text": "Ontology Lexicalization as a core task in a language-enhanced Semantic Web", "labels": [], "entities": [{"text": "Ontology Lexicalization", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8575983047485352}]}], "abstractContent": [{"text": "In order to provide language-based access to the growing amount of knowledge published in Semantic Web formalisms, e.g. as part of the so called Linked (Open) Data cloud, ontologies and vocabularies used to describe data need to be enriched with information about how classes and properties modeled therein can be expressed linguistically, also in different languages.", "labels": [], "entities": []}, {"text": "In this talk I will discuss the vision of a language-enhanced Semantic Web in which information about linguistic realization is modeled in Semantic Web languages and forms part of the Linked Data itself, thus becoming retrievable by standard Semantic Web search engines and indexing services as well as queryable and browseable using Semantic Web standards.", "labels": [], "entities": []}, {"text": "This ecosystem of ontologies enriched with linguistic knowledge can then be exploited by a number of NLP applications across applications, avoiding duplication of work by people aiming at supporting language-enhanced access to the Semantic Web.", "labels": [], "entities": []}, {"text": "There are three important ingredients to make this vision feasible.", "labels": [], "entities": []}, {"text": "First of all, we need vocabularies that allow to model lexical and linguistic knowledge using Semantic Web vocabularies.", "labels": [], "entities": []}, {"text": "In the last years, we have been developing the lemon model for this purpose that has formed the initial input for standardization activities carried on in the context of the W3C Community Group on the ontology-lexicon interface.", "labels": [], "entities": [{"text": "standardization", "start_pos": 114, "end_pos": 129, "type": "TASK", "confidence": 0.9748508334159851}, {"text": "W3C Community Group", "start_pos": 174, "end_pos": 193, "type": "DATASET", "confidence": 0.9067320624987284}]}, {"text": "Second, we need practical approaches that ease the effort of creating such ontology lexica.", "labels": [], "entities": []}, {"text": "I will present current efforts in this direction aiming at semi-automatically supporting the creation of ontology lexica by human users by exploiting a domain corpus.", "labels": [], "entities": []}, {"text": "I will present results of experiments in which we use Wikipedia to automatically induce a lexicon for the DBpedia ontology.", "labels": [], "entities": [{"text": "DBpedia ontology", "start_pos": 106, "end_pos": 122, "type": "DATASET", "confidence": 0.8633095026016235}]}, {"text": "Third and finally, we need people to recognize the value of ontology lexicalization so that they have incentives to contribute to the development of lexica for their favourite ontologies, and we need efficient and tested (collaborative) methodologies which incorporate semi-automatic support allowing people to develop such lexica effectively and efficiently.", "labels": [], "entities": []}, {"text": "I have unfortunately no solutions so far for this third challenge to present.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}