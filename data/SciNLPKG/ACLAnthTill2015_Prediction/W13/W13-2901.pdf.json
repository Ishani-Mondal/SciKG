{"title": [], "abstractContent": [{"text": "In this paper, we introduce a syntax-based sentence simplifier that models simplification using a probabilistic synchronous tree substitution grammar (STSG).", "labels": [], "entities": []}, {"text": "To improve the STSG model specificity we utilize a multi-level backoff model with additional syntactic annotations that allow for better discrimination over previous STSG formulations.", "labels": [], "entities": [{"text": "STSG model specificity", "start_pos": 15, "end_pos": 37, "type": "TASK", "confidence": 0.8626102407773336}]}, {"text": "We compare our approach to T3 (Cohn and Lapata, 2009), a recent STSG implementation, as well as two state-of-the-art phrase-based sentence simplifiers on a corpus of aligned sentences from English and Simple English Wikipedia.", "labels": [], "entities": [{"text": "Simple English Wikipedia", "start_pos": 201, "end_pos": 225, "type": "DATASET", "confidence": 0.7167564829190572}]}, {"text": "Our new approach performs significantly better than T3, similarly to human simplifications for both simplicity and fluency, and better than the phrase-based simplifiers for most of the evaluation metrics.", "labels": [], "entities": [{"text": "simplicity", "start_pos": 100, "end_pos": 110, "type": "METRIC", "confidence": 0.9930558800697327}]}], "introductionContent": [{"text": "Text simplification is aimed at reducing the reading and grammatical complexity of text while retaining the meaning.", "labels": [], "entities": [{"text": "Text simplification", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7898404896259308}]}, {"text": "Text simplification has applications for children, language learners, people with disabilities ( and in technical domains such as medicine), and can be beneficial as a preprocessing step for other NLP applications.", "labels": [], "entities": [{"text": "Text simplification", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7592356503009796}]}, {"text": "In this paper we introduce anew probabilistic model for sentence simplification using synchronous tree substitution grammars (STSG).", "labels": [], "entities": [{"text": "sentence simplification", "start_pos": 56, "end_pos": 79, "type": "TASK", "confidence": 0.7743004560470581}]}, {"text": "Synchronous grammars can be viewed as simultaneously generating a pair of recursively related strings or trees).", "labels": [], "entities": []}, {"text": "STSG grammar rules contain pairs of tree fragments called elementary trees.", "labels": [], "entities": [{"text": "STSG grammar", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.7905305624008179}]}, {"text": "The leaves of an elementary tree can be either terminal, lexical nodes or aligned nonterminals (also referred to as variables or frontier nodes).", "labels": [], "entities": []}, {"text": "Because elementary trees may have any number of internal nodes structured in anyway STSGs allow for more complicated derivations not expressible with other synchronous grammars.", "labels": [], "entities": []}, {"text": "To simplify an existing tree, an STSG grammar is used as a tree transducer.", "labels": [], "entities": []}, {"text": "shows some example simplification STSG rules written in transductive form.", "labels": [], "entities": [{"text": "STSG", "start_pos": 34, "end_pos": 38, "type": "TASK", "confidence": 0.7655929327011108}]}, {"text": "As a transducer the grammar rules take an elementary tree and rewrite it as the tree on the right-hand side of the rule.", "labels": [], "entities": []}, {"text": "For example, the first rule in would make the transformation changing \"may occasionally\" to \"sometimes ,\" and moving the noun phrase from the beginning of the sentence to after the comma.", "labels": [], "entities": []}, {"text": "The indices on the nonterminals indicate alignment and transduction continues recursively on these aligned nonterminals until no nonterminals remain.", "labels": [], "entities": []}, {"text": "In the example above, transduction would continue down the tree on the NP and VP subtrees.", "labels": [], "entities": []}, {"text": "A probabilistic STSG has a probability associated with each rule.", "labels": [], "entities": []}, {"text": "One of the key challenges in learning an STSG from an aligned corpus is determining the right level of specificity for the rules: too general and they can be applied in inappropriate contexts; too specific, and the rules do not apply in enough contexts.", "labels": [], "entities": []}, {"text": "The rules are written in transductive form.", "labels": [], "entities": []}, {"text": "Aligned nonterminals are indicated by indices. tion.", "labels": [], "entities": []}, {"text": "In this paper, we take a different approach and augment the grammar with additional information to increase the specificity of the rules (.", "labels": [], "entities": []}, {"text": "We combine varying levels of grammar augmentation into a single probabilistic backoff model.", "labels": [], "entities": []}, {"text": "This approach creates a model that uses specific rules when the context has been previously seen in the training data and more general rules when the context has not been seen.", "labels": [], "entities": []}], "datasetContent": [{"text": "To train and evaluate the systems we used the data set from Coster and Kauchak (2011b) consisting of 137K aligned sentence pairs between Simple English Wikipedia and English Wikipedia.", "labels": [], "entities": [{"text": "Simple English Wikipedia", "start_pos": 137, "end_pos": 161, "type": "DATASET", "confidence": 0.7350786328315735}, {"text": "English Wikipedia", "start_pos": 166, "end_pos": 183, "type": "DATASET", "confidence": 0.7928178310394287}]}, {"text": "The sentences were parsed using the Berkeley Parser ( and the word alignments determined using Giza++).", "labels": [], "entities": [{"text": "Berkeley Parser", "start_pos": 36, "end_pos": 51, "type": "DATASET", "confidence": 0.8898392915725708}]}, {"text": "We used 123K sentence pairs for training, 12K for development and 1,358 for testing.", "labels": [], "entities": []}, {"text": "We compared our system (SimpleTT -simple tree transducer) to three other simplification approaches: T3: Another STSG-based approach).", "labels": [], "entities": []}, {"text": "Our approach shares similar constituent alignment and rule extraction algorithms, but our approach differs in that it is generative instead of discriminative, and T3 increases rule specificity by increasing rule depth, while we employ a backoff model based on grammar augmentation.", "labels": [], "entities": [{"text": "rule extraction", "start_pos": 54, "end_pos": 69, "type": "TASK", "confidence": 0.7157666832208633}]}, {"text": "In addition, we employ n-best reranking based on a log-linear model that incorporates a number of additional features.", "labels": [], "entities": []}, {"text": "The code for T3 was obtained from the authors.", "labels": [], "entities": []}, {"text": "Due to performance limitations, T3 was only trained on 30K sentence pairs.", "labels": [], "entities": []}, {"text": "T3 was run on the full training data for two weeks, but it never terminated and required over 100GB of memory.", "labels": [], "entities": [{"text": "T3", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.8428313732147217}]}, {"text": "The slow algorithmic step is the discriminative training, which cannot be easily parallelized.", "labels": [], "entities": []}, {"text": "T3 was tested for increasing amounts of data up to 30K training pairs and the results on the automatic evaluation measures did not improve.", "labels": [], "entities": [{"text": "T3", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.7956427335739136}]}, {"text": "Moses-Diff: A phrase-based approach based on the Moses machine translation system () that selects the simplification from the 10-best output list that is most different from the input sentence).", "labels": [], "entities": []}, {"text": "Moses-Diff has been shown to perform better than a number of recent syntactic systems including and.", "labels": [], "entities": []}, {"text": "Moses-Del: A phrase-based approach also based on Moses which incorporates phrasal deletion).", "labels": [], "entities": []}, {"text": "The code was obtained from the authors.", "labels": [], "entities": []}, {"text": "For an additional data point to understand the benefit of the grammar augmentation, we also evaluated a deletion-only system previously used for text compression and a variant of that system that included the grammar augmentation described above.", "labels": [], "entities": [{"text": "text compression", "start_pos": 145, "end_pos": 161, "type": "TASK", "confidence": 0.7603687942028046}]}, {"text": "K&M is asynchronous context free grammar-based approach) and augm-K&M adds the grammar augmentation along with the four backoff levels.", "labels": [], "entities": []}, {"text": "There are currently no standard evaluation metrics for text simplification.", "labels": [], "entities": [{"text": "text simplification", "start_pos": 55, "end_pos": 74, "type": "TASK", "confidence": 0.822824627161026}]}, {"text": "Following previous work () we evaluated the systems using automatic metrics to analyze different system characteristics and human evaluations to judge the system quality.): BLEU measures the similarity between the system output and a human reference and has been used successfully in machine translation.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 173, "end_pos": 177, "type": "METRIC", "confidence": 0.997984766960144}, {"text": "machine translation", "start_pos": 284, "end_pos": 303, "type": "TASK", "confidence": 0.8189737498760223}]}, {"text": "Higher BLEU scores are better, indicating an output that is more similar to the human reference simplification.  than the phrase-based models and maybe more amenable to future reranking techniques.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 7, "end_pos": 11, "type": "METRIC", "confidence": 0.9992644190788269}]}, {"text": "SimpleTT also closely matches the in-corpus mean of the length ratio seen by human simplifications, though this can be partially explained by the length penalty in the log-linear model.", "labels": [], "entities": [{"text": "SimpleTT", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.47656577825546265}]}, {"text": "Moses-Del obtains the highest BLEU score, but accomplishes this with only small changes to the input sentence: the length of the simplified sentences are only slightly different from the original (a length ratio of 0.99).", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 30, "end_pos": 40, "type": "METRIC", "confidence": 0.9853890836238861}]}, {"text": "Moses-Diff has the lowest BLEU score of the three simplification systems and while it makes larger changes than MosesDel it still makes much smaller changes than SimpleTT and the human simplifications.", "labels": [], "entities": [{"text": "Moses-Diff", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.9094560742378235}, {"text": "BLEU score", "start_pos": 26, "end_pos": 36, "type": "METRIC", "confidence": 0.9877512753009796}, {"text": "SimpleTT", "start_pos": 162, "end_pos": 170, "type": "DATASET", "confidence": 0.8262739181518555}]}, {"text": "T3 had significant problems with over-deleting content as indicated by the low length ratio which resulted in a very low BLEU score.", "labels": [], "entities": [{"text": "T3", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.8950863480567932}, {"text": "BLEU score", "start_pos": 121, "end_pos": 131, "type": "METRIC", "confidence": 0.9824598729610443}]}, {"text": "This issue has been previously noted by others when using T3 for text compression.", "labels": [], "entities": [{"text": "text compression", "start_pos": 65, "end_pos": 81, "type": "TASK", "confidence": 0.8006192743778229}]}, {"text": "The two deletion-only systems performed worse than the three simplification systems.", "labels": [], "entities": []}, {"text": "Comparing the two systems shows the benefit of the grammar augmentation: augm-K&M has a significantly higher BLEU score than K&M and also avoided the over-deletion that occurred in the original K&M system.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 109, "end_pos": 119, "type": "METRIC", "confidence": 0.9881311357021332}]}, {"text": "The additional specificity of the rules allowed the model to make better decisions for which content to delete.", "labels": [], "entities": []}, {"text": "shows the human judgement scores for the simplification approaches for the three different metrics averaged over the 100 sentences and shows the pairwise statistical significance calculations between each system based on a two-  tailed paired t-test.", "labels": [], "entities": []}, {"text": "Overall, SimpleTT performed well with simplicity and fluency scores that were comparable to the human simplifications.", "labels": [], "entities": [{"text": "SimpleTT", "start_pos": 9, "end_pos": 17, "type": "DATASET", "confidence": 0.7321449518203735}, {"text": "simplicity", "start_pos": 38, "end_pos": 48, "type": "METRIC", "confidence": 0.993232011795044}]}, {"text": "SimpleTT was too aggressive at removing content, resulting in lower adequacy scores.", "labels": [], "entities": [{"text": "SimpleTT", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.7929599285125732}]}, {"text": "This phenomena was also seen in the human simplifications and maybe able to be corrected in future variations by adjusting the sentence length target.", "labels": [], "entities": []}, {"text": "The human evaluations highlight the trade-off between the simplicity of the output and the amount of content preserved.", "labels": [], "entities": [{"text": "simplicity", "start_pos": 58, "end_pos": 68, "type": "METRIC", "confidence": 0.9749842882156372}]}, {"text": "For simplicity, SimpleTT and the human simplifications performed significantly better than both the phrase-based systems.", "labels": [], "entities": [{"text": "SimpleTT", "start_pos": 16, "end_pos": 24, "type": "DATASET", "confidence": 0.8366730809211731}]}, {"text": "However, simplicity does come with a cost; both SimpleTT and the human simplifications reduced the length of the sentences by 15% on average.", "labels": [], "entities": [{"text": "SimpleTT", "start_pos": 48, "end_pos": 56, "type": "DATASET", "confidence": 0.555391252040863}]}, {"text": "This content reduction resulted in lower adequacy than the phrase-based systems.", "labels": [], "entities": []}, {"text": "A similar trade-off has been previously shown for text compression, balancing content versus the amount of compression).", "labels": [], "entities": [{"text": "text compression", "start_pos": 50, "end_pos": 66, "type": "TASK", "confidence": 0.8170222640037537}]}, {"text": "For fluency, SimpleTT again scored similarly to the human simplifications.", "labels": [], "entities": [{"text": "SimpleTT", "start_pos": 13, "end_pos": 21, "type": "DATASET", "confidence": 0.7007680535316467}]}, {"text": "SimpleTT performed significantly better than Moses-Diff and slightly better than Moses-Del, though the difference was not statistically significant.", "labels": [], "entities": [{"text": "SimpleTT", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.6312727332115173}]}, {"text": "As an aside, Moses-Del performs slightly better than Moses-Diff overall.", "labels": [], "entities": []}, {"text": "They perform similarly on adequacy and Moses-Del performs better on simplicity and Moses-Diff performs worse relative to the other systems on fluency.", "labels": [], "entities": [{"text": "simplicity", "start_pos": 68, "end_pos": 78, "type": "METRIC", "confidence": 0.99888676404953}]}], "tableCaptions": [{"text": " Table 1: Automatic evaluation scores for all sys- tems tested and the mean values from the training  corpus.  *  Moses-Diff uses the n-best list to choose  candidates and therefore is not amenable to oracle  scoring.  *  *  T3 only outputs the single best simpli- fication.", "labels": [], "entities": []}, {"text": " Table 2: Human evaluation scores on a 5-point  Likert scale averaged over 100 sentences.", "labels": [], "entities": []}]}