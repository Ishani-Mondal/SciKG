{"title": [{"text": "Graph-based Approaches for Organization Entity Resolution in MapReduce", "labels": [], "entities": [{"text": "Organization Entity Resolution", "start_pos": 27, "end_pos": 57, "type": "TASK", "confidence": 0.6993339856465658}]}], "abstractContent": [{"text": "Entity Resolution is the task of identifying which records in a database refer to the same entity.", "labels": [], "entities": [{"text": "Entity Resolution", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7949426174163818}]}, {"text": "A standard machine learning pipeline for the entity resolution problem consists of three major components: blocking, pairwise linkage, and clustering.", "labels": [], "entities": [{"text": "entity resolution problem", "start_pos": 45, "end_pos": 70, "type": "TASK", "confidence": 0.8153173327445984}]}, {"text": "The blocking step groups records by shared properties to determine which pairs of records should be examined by the pairwise linker as potential duplicates.", "labels": [], "entities": []}, {"text": "Next, the linkage step assigns a probability score to pairs of records inside each block.", "labels": [], "entities": []}, {"text": "If a pair scores above a user-defined threshold, the records are presumed to represent the same entity.", "labels": [], "entities": []}, {"text": "Finally, the clustering step turns the input records into clusters of records (or profiles), where each cluster is uniquely associated with a single real-world entity.", "labels": [], "entities": []}, {"text": "This paper describes the blocking and clustering strategies used to deploy a massive database of organization entities to power a major commercial People Search Engine.", "labels": [], "entities": []}, {"text": "We demonstrate the viability of these algorithms for large data sets on a 50-node hadoop cluster.", "labels": [], "entities": []}], "introductionContent": [{"text": "A challenge for builders of databases whose information is culled from multiple sources is the detection of duplicates, where a single real-world entity gives rise to multiple records (see for an overview).", "labels": [], "entities": []}, {"text": "Entity Resolution is the task of identifying which records in a database refer to the same entity.", "labels": [], "entities": [{"text": "Entity Resolution", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7949426174163818}]}, {"text": "Online citation indexes need to be able to navigate through the different capitalization and abbreviation conventions that appear in bibliographic entries.", "labels": [], "entities": []}, {"text": "Government agencies need to know whether a record for \"Robert Smith\" living on \"Northwest First Street\" refers to the same person as one fora \"Bob Smith\" living on \"1st St. NW\".", "labels": [], "entities": [{"text": "Northwest First Street\"", "start_pos": 80, "end_pos": 103, "type": "DATASET", "confidence": 0.8834695667028427}, {"text": "1st St. NW", "start_pos": 165, "end_pos": 175, "type": "DATASET", "confidence": 0.8366892536481222}]}, {"text": "Ina standard machine learning approach to this problem all records first go through a cleaning process that starts with the removal of bogus, junk and spam records.", "labels": [], "entities": []}, {"text": "Then all records are normalized to an approximately common representation.", "labels": [], "entities": []}, {"text": "Finally, all major noise types and inconsistencies are addressed, such as empty/bogus fields, field duplication, outlier values and encoding issues.", "labels": [], "entities": []}, {"text": "At this point, all records are ready for the major stages of the entity resolution, namely blocking, pairwise linkage, and clustering.", "labels": [], "entities": [{"text": "entity resolution", "start_pos": 65, "end_pos": 82, "type": "TASK", "confidence": 0.7393873780965805}]}, {"text": "Since comparing all pairs of records is quadratic in the number of records and hence is intractable for large data sets, the blocking step groups records by shared properties to determine which pairs of records should be examined by the pairwise linker as potential duplicates.", "labels": [], "entities": []}, {"text": "Next, the linkage step assigns a score to pairs of records inside each block.", "labels": [], "entities": []}, {"text": "If a pair scores above a user-defined threshold, the records are presumed to represent the same entity.", "labels": [], "entities": []}, {"text": "The clustering step partitions the input records into sets of records called profiles, where each profile corresponds to a single entity.", "labels": [], "entities": []}, {"text": "In this paper, we focus on entity resolution for the organization entity domain where all we have are the organization names and their relations with individuals.", "labels": [], "entities": [{"text": "entity resolution", "start_pos": 27, "end_pos": 44, "type": "TASK", "confidence": 0.7260433286428452}]}, {"text": "Let's first describe the entity resolution for organization names, and discuss its significance and the challenges in more detail.", "labels": [], "entities": [{"text": "entity resolution", "start_pos": 25, "end_pos": 42, "type": "TASK", "confidence": 0.7866050601005554}]}, {"text": "Our process starts by collecting billions of personal records from three sources of U.S. records to power a major commercial People Search Engine.", "labels": [], "entities": []}, {"text": "Example fields on these records might include name, address, birthday, phone number, (encrypted) social security number, relatives, friends, job title, universities attended, and organizations worked for.", "labels": [], "entities": []}, {"text": "Since the data sources are heterogeneous, each data source provides different aliases of an organization including abbreviations, preferred names, legal names, etc.", "labels": [], "entities": []}, {"text": "For example, Person A might have both \"Microsoft\", \"Microsoft Corp\", \"Microsoft Corporation\", and \"Microsoft Research\" in his/her profile's organization field.", "labels": [], "entities": []}, {"text": "Person B might have \"University of Washington\", while Person C has \"UW\" as the organization listed in his/her profile.", "labels": [], "entities": []}, {"text": "Moreover, some organizations change their names, or are acquired by other in-stitutions and become subdivisions.", "labels": [], "entities": []}, {"text": "There are also many organizations that share the same name or abbreviation.", "labels": [], "entities": []}, {"text": "For instance, both \"University of Washington\", \"University of Wisconsin Madison\", \"University of Wyoming\" share the same abbreviation, \"UW\".", "labels": [], "entities": []}, {"text": "Additionally, some of the data sources might be noisier than the others and there might be different kind of typos that needs to be addressed.", "labels": [], "entities": []}, {"text": "Addressing the above issues in organization fields is crucial for data quality as graphical representations of the data become more popular.", "labels": [], "entities": []}, {"text": "If we show different representations of the same organization as separate institutions in a single person's profile, it will decrease the confidence of a customer about our data quality.", "labels": [], "entities": []}, {"text": "Moreover, we should have a unique representation of organizations in order to properly answer more complicated graph-based queries such as \"how am I connected to company X?\", or \"who are my friends that has a friend that works at organization X, and graduated from school Y?\".", "labels": [], "entities": []}, {"text": "We have developed novel and highly scalable components for our entity resolution pipeline which is customized for organizations.", "labels": [], "entities": [{"text": "entity resolution pipeline", "start_pos": 63, "end_pos": 89, "type": "TASK", "confidence": 0.8214323321978251}]}, {"text": "The focus of this paper is the graph-based blocking and clustering components.", "labels": [], "entities": [{"text": "graph-based blocking", "start_pos": 31, "end_pos": 51, "type": "TASK", "confidence": 0.6488680243492126}]}, {"text": "In the remainder of the paper, we first describe these components in Section 2.", "labels": [], "entities": []}, {"text": "Then, we evaluate the performance of our entity resolution framework using several real-world datasets in Section 3.", "labels": [], "entities": [{"text": "entity resolution", "start_pos": 41, "end_pos": 58, "type": "TASK", "confidence": 0.734618604183197}]}, {"text": "Finally, we conclude in Section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we present the experimental results for our entity resolution framework.", "labels": [], "entities": [{"text": "entity resolution", "start_pos": 61, "end_pos": 78, "type": "TASK", "confidence": 0.7863509356975555}]}, {"text": "We ran the experiments on a hadoop cluster consisting of 50 nodes, each with 8 cores.", "labels": [], "entities": []}, {"text": "There are 10 mappers, and 6 reducers available at each node.", "labels": [], "entities": []}, {"text": "We also allocated 3 Gb memory for each map/reduce task.", "labels": [], "entities": []}, {"text": "We used two different real-world datasets for our experiments.", "labels": [], "entities": []}, {"text": "The first one is a list of 150K organizations along with their aliases provided by freebase 2 . By using this dataset, we both trained our pairwise linkage model and measured the precision and recall of our system.", "labels": [], "entities": [{"text": "precision", "start_pos": 179, "end_pos": 188, "type": "METRIC", "confidence": 0.9994271993637085}, {"text": "recall", "start_pos": 193, "end_pos": 199, "type": "METRIC", "confidence": 0.9979010820388794}]}, {"text": "We randomly selected 135K organizations from this list for the training.", "labels": [], "entities": []}, {"text": "We used the rest of the organizations to mea- sure the performance of our system.", "labels": [], "entities": [{"text": "mea- sure", "start_pos": 41, "end_pos": 50, "type": "TASK", "confidence": 0.7578034400939941}]}, {"text": "Next, we generated positive examples by exhaustively generating a pair between all the aliases.", "labels": [], "entities": []}, {"text": "We also randomly generated equal number of negative examples among pairs of different organization alias sets.", "labels": [], "entities": []}, {"text": "We trained our pairwise classifier with the training set, then ran it on the test set and measured its performance.", "labels": [], "entities": []}, {"text": "Next, we extracted all the organization names from this set, and ran our entire entity resolution pipeline on top of this set.", "labels": [], "entities": [{"text": "entity resolution", "start_pos": 80, "end_pos": 97, "type": "TASK", "confidence": 0.7338118851184845}]}, {"text": "Our pairwise classifier has 97% precision and 63% recall when we use a match threshold of 0.65.", "labels": [], "entities": [{"text": "precision", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9994680285453796}, {"text": "recall", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.9996216297149658}]}, {"text": "Using same match threshold, we then performed transitive closure.", "labels": [], "entities": [{"text": "transitive closure", "start_pos": 46, "end_pos": 64, "type": "TASK", "confidence": 0.725521057844162}]}, {"text": "We also measured the precision and recall numbers for transitive closure as it is the naive approach for the entity resolution problem.", "labels": [], "entities": [{"text": "precision", "start_pos": 21, "end_pos": 30, "type": "METRIC", "confidence": 0.999572217464447}, {"text": "recall", "start_pos": 35, "end_pos": 41, "type": "METRIC", "confidence": 0.9977116584777832}, {"text": "transitive closure", "start_pos": 54, "end_pos": 72, "type": "TASK", "confidence": 0.7209402024745941}, {"text": "entity resolution", "start_pos": 109, "end_pos": 126, "type": "TASK", "confidence": 0.7877258956432343}]}, {"text": "Since transitive closure merges records transitively, it has very high recall but the precision is just 64%.", "labels": [], "entities": [{"text": "transitive closure merges records transitively", "start_pos": 6, "end_pos": 52, "type": "TASK", "confidence": 0.8222234189510346}, {"text": "recall", "start_pos": 71, "end_pos": 77, "type": "METRIC", "confidence": 0.9996398687362671}, {"text": "precision", "start_pos": 86, "end_pos": 95, "type": "METRIC", "confidence": 0.9996613264083862}]}, {"text": "Finally, we performed our sClust approach with the same match threshold.", "labels": [], "entities": []}, {"text": "We set the no-match threshold to 0.3.", "labels": [], "entities": []}, {"text": "The pairwise classifier has slightly better precision than sClust but sClust has much better recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 44, "end_pos": 53, "type": "METRIC", "confidence": 0.9989864230155945}, {"text": "recall", "start_pos": 93, "end_pos": 99, "type": "METRIC", "confidence": 0.9988662004470825}]}, {"text": "Overall, sClust has a much better f-measure than both the pairwise classifier and transitive closure.", "labels": [], "entities": []}, {"text": "Second, we used our production set to show the viability of our framework.", "labels": [], "entities": []}, {"text": "In this set, we have 68M organization names.", "labels": [], "entities": []}, {"text": "We ran our framework on this dataset.", "labels": [], "entities": []}, {"text": "Blocking generated 14M unique blocks, and there are 842M unique comparisons in these blocks.", "labels": [], "entities": []}, {"text": "The distribution of the block sizes presented in-(a) and (b).", "labels": [], "entities": []}, {"text": "Blocking finished in 42 minutes.", "labels": [], "entities": [{"text": "Blocking", "start_pos": 0, "end_pos": 8, "type": "TASK", "confidence": 0.9874023795127869}]}, {"text": "Next, we ran our pairwise classifier on these 842M pairs and it finished in 220 minutes.", "labels": [], "entities": []}, {"text": "Finally, we ended up with 10M clusters at the end of the clustering stage which took 3 hours.", "labels": [], "entities": [{"text": "clustering stage", "start_pos": 57, "end_pos": 73, "type": "TASK", "confidence": 0.8924882411956787}]}, {"text": "The distribution of the connected components and final clusters are presented in-(c).", "labels": [], "entities": []}], "tableCaptions": []}