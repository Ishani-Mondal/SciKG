{"title": [{"text": "Combining Bilingual and Comparable Corpora for Low Resource Machine Translation", "labels": [], "entities": [{"text": "Low Resource Machine Translation", "start_pos": 47, "end_pos": 79, "type": "TASK", "confidence": 0.6086775064468384}]}], "abstractContent": [{"text": "Statistical machine translation (SMT) performance suffers when models are trained on only small amounts of parallel data.", "labels": [], "entities": [{"text": "Statistical machine translation (SMT)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8456584016482035}]}, {"text": "The learned models typically have both low accuracy (incorrect translations and feature scores) and low coverage (high out-of-vocabulary rates).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.9986315369606018}, {"text": "coverage", "start_pos": 104, "end_pos": 112, "type": "METRIC", "confidence": 0.9919126033782959}]}, {"text": "In this work, we use an additional data resource, comparable corpora, to improve both.", "labels": [], "entities": []}, {"text": "Beginning with a small bitext and corresponding phrase-based SMT model, we improve coverage by using bilingual lexicon induction techniques to learn new translations from comparable corpora.", "labels": [], "entities": [{"text": "SMT", "start_pos": 61, "end_pos": 64, "type": "TASK", "confidence": 0.8872613310813904}]}, {"text": "Then, we supplement the model's feature space with translation scores estimated over comparable corpora in order to improve accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 124, "end_pos": 132, "type": "METRIC", "confidence": 0.9974850416183472}]}, {"text": "We observe improvements between 0.5 and 1.7 BLEU translating Tamil, Tel-ugu, Bengali, Malayalam, Hindi, and Urdu into English.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 44, "end_pos": 48, "type": "METRIC", "confidence": 0.9991112351417542}]}], "introductionContent": [{"text": "Standard statistical machine translation (SMT) models () are trained using large, sentence-aligned parallel corpora.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 9, "end_pos": 46, "type": "TASK", "confidence": 0.7740614165862402}]}, {"text": "Unfortunately, parallel corpora are not always available in large enough quantities to train robust models (.", "labels": [], "entities": []}, {"text": "In this work, we consider the situation in which we have access to only a small amount of bitext fora given low resource language pair, and we wish to supplement an SMT model with additional translations and features estimated using comparable corpora in the source and target languages.", "labels": [], "entities": [{"text": "SMT", "start_pos": 165, "end_pos": 168, "type": "TASK", "confidence": 0.98497074842453}]}, {"text": "Assuming access to a small amount * Performed while faculty at Johns Hopkins University of parallel text is realistic, especially considering the recent success of crowdsourcing translations.", "labels": [], "entities": []}, {"text": "We frame the shortcomings of SMT models trained on limited amounts of parallel text 1 in terms of accuracy and coverage.", "labels": [], "entities": [{"text": "SMT", "start_pos": 29, "end_pos": 32, "type": "TASK", "confidence": 0.9953737854957581}, {"text": "accuracy", "start_pos": 98, "end_pos": 106, "type": "METRIC", "confidence": 0.9992032647132874}, {"text": "coverage", "start_pos": 111, "end_pos": 119, "type": "METRIC", "confidence": 0.9629932045936584}]}, {"text": "In this context, coverage refers to the number of words and phrases that a model has any knowledge of at all, and it is low when the training text is small, which results in a high out-of-vocabulary (OOV) rate.", "labels": [], "entities": [{"text": "coverage", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9820917248725891}, {"text": "out-of-vocabulary (OOV) rate", "start_pos": 181, "end_pos": 209, "type": "METRIC", "confidence": 0.8462688326835632}]}, {"text": "Accuracy refers to the correctness of the translation pairs and their corresponding probability features that makeup the translation model.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9925285577774048}]}, {"text": "Because the quality of unsupervised automatic word alignments correlates with the amount of available parallel text and alignment errors result in errors in extracted translation pairs, accuracy tends to below in low resource settings.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 46, "end_pos": 61, "type": "TASK", "confidence": 0.7374284267425537}, {"text": "accuracy", "start_pos": 186, "end_pos": 194, "type": "METRIC", "confidence": 0.9988895058631897}]}, {"text": "Additionally, estimating translation probabilities 2 over sparse training sets results in inaccurate feature scores.", "labels": [], "entities": []}, {"text": "Given these deficiencies, we begin with a baseline SMT model learned from a small parallel corpus and supplement the model to improve its accuracy and coverage.", "labels": [], "entities": [{"text": "SMT", "start_pos": 51, "end_pos": 54, "type": "TASK", "confidence": 0.9920475482940674}, {"text": "accuracy", "start_pos": 138, "end_pos": 146, "type": "METRIC", "confidence": 0.9988865256309509}, {"text": "coverage", "start_pos": 151, "end_pos": 159, "type": "METRIC", "confidence": 0.9402006268501282}]}, {"text": "We apply techniques presented in prior work that use comparable corpora to estimate similarities between word and phrases.", "labels": [], "entities": []}, {"text": "In particular, we build on prior work in bilingual lexicon induction in order to predict translations for OOV words, improving coverage.", "labels": [], "entities": [{"text": "bilingual lexicon induction", "start_pos": 41, "end_pos": 68, "type": "TASK", "confidence": 0.652363787094752}, {"text": "coverage", "start_pos": 127, "end_pos": 135, "type": "METRIC", "confidence": 0.9238376021385193}]}, {"text": "We then use the same corpora to estimate additional translation feature scores, improving model accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 96, "end_pos": 104, "type": "METRIC", "confidence": 0.992912232875824}]}, {"text": "We see improvements in translation quality between 0.5 and 1.7 BLEU points translating the following low resource languages into English: Tamil, Telugu, Bengali, Malayalam, Hindi, and Urdu.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 63, "end_pos": 67, "type": "METRIC", "confidence": 0.9989762306213379}]}], "datasetContent": [{"text": "(2012) used Mechanical Turk to collect small parallel corpora for the following Indian languages and English: Tamil, Telugu, Bengali, Malayalam, Hindi, and Urdu.", "labels": [], "entities": []}, {"text": "They collected both parallel sentence pairs and a dictionary of word translations.", "labels": [], "entities": [{"text": "word translations", "start_pos": 64, "end_pos": 81, "type": "TASK", "confidence": 0.7299225181341171}]}, {"text": "We use all six datasets, which provide real low resource data conditions for six truly low resource language pairs.", "labels": [], "entities": []}, {"text": "shows statistics about the datasets.", "labels": [], "entities": []}, {"text": "lists the amount of comparable data that we use for each language.", "labels": [], "entities": []}, {"text": "Following both and, we use time-stamped web crawls as well as interlingually linked Wikipedia documents.", "labels": [], "entities": []}, {"text": "We use the time-stamped data to estimate temporal similarity and the interlingual Wikipedia links, which indicate documents about the same topic written in different languages, to estimate topic similarity.", "labels": [], "entities": []}, {"text": "We use both datasets in combination with a dictionary derived from the small parallel corpora to estimate contextual similarity.", "labels": [], "entities": []}, {"text": "We use the data splits given by and, following that work, include the dictionaries in the training data and report results on the devtest set using case-insensitive BLEU and four references.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 165, "end_pos": 169, "type": "METRIC", "confidence": 0.9826480746269226}]}, {"text": "We use the Moses phrase-based MT framework (  the English side of the training data to train a language model.", "labels": [], "entities": []}, {"text": "Using a language model trained on a larger corpus (e.g. the English side of our comparable corpora) may yield better results, but such an improvement is orthogonal to the focus of this work.", "labels": [], "entities": []}, {"text": "Throughout our experiments, we use the batch version of MIRA (Cherry and Foster, 2012) for tuning the feature set.", "labels": [], "entities": [{"text": "MIRA (Cherry and Foster, 2012)", "start_pos": 56, "end_pos": 86, "type": "DATASET", "confidence": 0.6995461508631706}]}, {"text": "We rerun tuning for all experimental conditions and report results averaged over three tuning runs).", "labels": [], "entities": []}, {"text": "Our baseline uses the bilingually extracted phrase pairs and standard translation probability features.", "labels": [], "entities": []}, {"text": "We supplement it with the top ranked translation for each OOV to improve coverage (+ OOV Trans) and with additional features to improve accuracy (+Features).", "labels": [], "entities": [{"text": "OOV", "start_pos": 58, "end_pos": 61, "type": "DATASET", "confidence": 0.7740283608436584}, {"text": "coverage", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9943945407867432}, {"text": "OOV Trans)", "start_pos": 85, "end_pos": 95, "type": "METRIC", "confidence": 0.8964693148930868}, {"text": "accuracy", "start_pos": 136, "end_pos": 144, "type": "METRIC", "confidence": 0.9988465309143066}]}, {"text": "In Section 4.2, we make each modification separately and then together.", "labels": [], "entities": []}, {"text": "Then we present additional experiments where we induce translations for low frequency words, in addition to OOVs (4.3), append top-k translations (4.4), vary the amount of training data used to induce the baseline model (4.5), and vary the amount of comparable corpora used to estimate features and induce translations (4.6).", "labels": [], "entities": [{"text": "OOVs", "start_pos": 108, "end_pos": 112, "type": "METRIC", "confidence": 0.9370364546775818}]}], "tableCaptions": [{"text": " Table 1: Information about datasets released by Post et al.", "labels": [], "entities": []}, {"text": " Table 2: Millions of words of time-stamped web crawls and", "labels": [], "entities": []}, {"text": " Table 3: Percent of word types in a held out portion of the", "labels": [], "entities": [{"text": "Percent", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9360167980194092}]}, {"text": " Table 4: BLEU performance gains that target coverage (+OOV Trans.) and accuracy (+Features), and both (+Feats & OOV).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.99280846118927}, {"text": "coverage", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9773338437080383}, {"text": "OOV", "start_pos": 56, "end_pos": 59, "type": "METRIC", "confidence": 0.9434416890144348}, {"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9994342923164368}]}, {"text": " Table 6: Adding top-k induced translations for source lan-", "labels": [], "entities": []}]}