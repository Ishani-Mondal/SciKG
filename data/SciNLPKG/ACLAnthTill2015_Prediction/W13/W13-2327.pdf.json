{"title": [{"text": "Enunciative and modal variations in newswire texts in French: From guideline to automatic annotation", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper we present the development of a corpus of French newswire texts annotated with enunciative and modal commitment information.", "labels": [], "entities": [{"text": "French newswire texts", "start_pos": 56, "end_pos": 77, "type": "DATASET", "confidence": 0.8179593483606974}]}, {"text": "The annotation scheme we propose is based on the detection of predicative cues-referring to an enunciative and/or modal variation and their scope at a sentence level.", "labels": [], "entities": []}, {"text": "We describe how we have improved our annotation guideline by using the evaluation (in terms of precision, recall and F-Measure) of a first round of annotation produced by two expert annotators and by our automatic annotation system.", "labels": [], "entities": [{"text": "precision", "start_pos": 95, "end_pos": 104, "type": "METRIC", "confidence": 0.9995361566543579}, {"text": "recall", "start_pos": 106, "end_pos": 112, "type": "METRIC", "confidence": 0.9988551139831543}, {"text": "F-Measure", "start_pos": 117, "end_pos": 126, "type": "METRIC", "confidence": 0.9988277554512024}]}], "introductionContent": [{"text": "This paper concerns the design of a reference corpus that can be used to evaluate an automatic annotation system of enunciative and modal commitment in newswire texts in French.", "labels": [], "entities": []}, {"text": "This complex linguistic phenomenon refers to the fact that a situation can be presented ascertain, or only possible/probable, by an enunciator who can be the author of the text but who can also be another enunciator (explicitly named or not) from whom the author reports some content that he has heard, read, imagined, etc.", "labels": [], "entities": []}, {"text": "Different kinds of linguistic cues are involved.", "labels": [], "entities": []}, {"text": "In addition to the need to identify and semantically classify these cues, one has to deal with the question of their scope.", "labels": [], "entities": []}, {"text": "This question is even more complex as many cues can be present together in a sentence, thus complexifying the interpretation of the interaction of different scopes (see Example 1.).", "labels": [], "entities": []}, {"text": "Another major difficulty concerns the fact that evidential and modal characteristics are very similar (see for example a noun like desire).", "labels": [], "entities": []}, {"text": "Our work addresses the question of annotating these cues and their semantic scope.", "labels": [], "entities": []}, {"text": "Unlike most other approaches, we have chosen not to treat these two kinds of characteristics separately, since both are implicated in what is called enunciative commitment.", "labels": [], "entities": [{"text": "enunciative commitment", "start_pos": 149, "end_pos": 171, "type": "TASK", "confidence": 0.703189417719841}]}, {"text": "We will focus hereon our practice for the development of a reference corpus.", "labels": [], "entities": []}, {"text": "After a brief presentation of the theoretical background (section 2), we describe which kinds of linguistic cues are considered and what kind of semantic scopes are then encountered (section 3).", "labels": [], "entities": []}, {"text": "Our annotation procedure aims to delimit textual segments that are semantically impacted by the presence of enunciative and modal cues.", "labels": [], "entities": []}, {"text": "In this light, we will focus only on what we will describe below as predicative cues.", "labels": [], "entities": []}, {"text": "Then we will explain how we have improved our annotation guideline by using the evaluation of a first round of annotation produced for the same task by two expert annotators and by our automatic annotation system (section 4).", "labels": [], "entities": []}], "datasetContent": [{"text": "Our final goal is to develop an automatic annotation system that produces the annotation of enunciative and modal cues and their scope in newswire texts.", "labels": [], "entities": []}, {"text": "In this light, we have to build a guideline of our annotation aim and a reference corpus that can be used to evaluate the system.", "labels": [], "entities": []}, {"text": "illustrates the steps in the workflow applied to improve our annotation guideline.", "labels": [], "entities": []}, {"text": "For this purpose, two annotators (henceforth A1 and A2), both of them experts in linguistics, worked together to build a guideline and then the reference corpus . First of all, the two annotators defined the annotation goals together (see step 1 in).", "labels": [], "entities": []}, {"text": "Then they annotated separately a corpus of 20 newswire texts (see step 2a in).", "labels": [], "entities": []}, {"text": "This corpus contains 256 predicative cues and their associated scopes (see).: Corpus statistics Our annotation process is based on Morante and Daelemans (2012).", "labels": [], "entities": []}, {"text": "This manual annotation task was carried out using the Glozz Annotation Tool) that relies on the URS (UnitRelation-Schema) meta model and produces an xml output.", "labels": [], "entities": [{"text": "URS (UnitRelation-Schema) meta model", "start_pos": 96, "end_pos": 132, "type": "DATASET", "confidence": 0.6597430755694708}]}, {"text": "The model permits to annotate textual units that can be embedded or not (in our case the predicative cues and their scope) and relations (for us, the opening relation links the predicative cue to its scope).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: IAA: the annotations of annotator A1 are  evaluated against the annotations of annotator A2  Adjudicated /System  precision recall F1  Cues  0.83  0.85 0.84  Scopes  0.52  0.59 0.55  Weighted Scopes  0.67  0.76 0.71  SB  FB  Rel  Ref  59  33  100  113  Table 4: System evaluation: annotations from the sys- tem are evaluated against the adjudicated version", "labels": [], "entities": [{"text": "IAA", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9719448089599609}, {"text": "precision recall F1  Cues  0.83", "start_pos": 124, "end_pos": 155, "type": "METRIC", "confidence": 0.8567779660224915}, {"text": "SB  FB  Rel  Ref  59  33  100  113", "start_pos": 227, "end_pos": 261, "type": "DATASET", "confidence": 0.6524625532329082}]}]}