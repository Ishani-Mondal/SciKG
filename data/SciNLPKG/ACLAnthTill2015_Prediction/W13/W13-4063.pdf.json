{"title": [{"text": "Continuously Predicting and Processing Barge-in During a Live Spoken Dialogue Task", "labels": [], "entities": [{"text": "Predicting and Processing Barge-in During a Live Spoken Dialogue Task", "start_pos": 13, "end_pos": 82, "type": "TASK", "confidence": 0.7948195308446884}]}], "abstractContent": [{"text": "Barge-in enables the user to provide input during system speech, facilitating a more natural and efficient interaction.", "labels": [], "entities": []}, {"text": "Standard methods generally focus on single-stage barge-in detection, applying the dialogue policy irrespective of the barge-in context.", "labels": [], "entities": [{"text": "single-stage barge-in detection", "start_pos": 36, "end_pos": 67, "type": "TASK", "confidence": 0.6520567437012991}]}, {"text": "Unfortunately, this approach performs poorly when used in challenging environments.", "labels": [], "entities": []}, {"text": "We propose and evaluate a barge-in processing method that uses a prediction strategy to continuously decide whether to pause, continue, or resume the prompt.", "labels": [], "entities": []}, {"text": "This model has greater task success and efficiency than the standard approach when evaluated in a public spoken dialogue system.", "labels": [], "entities": []}], "introductionContent": [{"text": "Spoken dialogue systems (SDS) communicate with users with spoken natural language; the optimal SDS being effective, efficient, and natural.", "labels": [], "entities": []}, {"text": "Allowing input during system speech, known as barge-in, is one approach that designers use to improve system performance.", "labels": [], "entities": []}, {"text": "In the ideal use case, the system detects user speech, switches off the prompt, and then responds to the user's utterance.", "labels": [], "entities": []}, {"text": "Dialogue efficiency improves, as the system receives information prior to completing its prompt, and the interaction becomes more natural, as the system demonstrates more human-like turn-taking behavior.", "labels": [], "entities": []}, {"text": "However, barge-in poses a number of new challenges; the system must now recognize and process input during its prompt that may not be well-formed system directed speech.", "labels": [], "entities": []}, {"text": "This is a difficult task and standard barge-in approaches often stop the prompt for input that will not be understood, subsequently initiating a clarification sub-dialogue (\"I'm sorry, I didn't get that. You can say...etc.\").", "labels": [], "entities": []}, {"text": "This non-understood barge-in (NUBI) could be from environmental noise, nonsystem directed speech, poorly-formed system directed speech, legitimate speech recognition difficulties (such as acoustic model mismatch), or any combination thereof.", "labels": [], "entities": []}, {"text": "This paper proposes and evaluates a barge-in processing method that focuses on handling NUBIs.", "labels": [], "entities": []}, {"text": "Our Prediction-based Barge-in Response (PBR) model continuously predicts interpretation success by applying adaptive thresholds to incremental recognition results.", "labels": [], "entities": []}, {"text": "In our view, predicting whether the recognition will be understood has far more utility than detecting whether the barge-in is truly system directed speech as, for many domains, we feel only understandable input has more discourse importance than system speech.", "labels": [], "entities": [{"text": "predicting whether the recognition", "start_pos": 13, "end_pos": 47, "type": "TASK", "confidence": 0.7108499705791473}]}, {"text": "If the input is predicted to be understood, the prompt is paused.", "labels": [], "entities": []}, {"text": "If it is predicted or found to be NUBI, the prompt is resumed.", "labels": [], "entities": [{"text": "NUBI", "start_pos": 34, "end_pos": 38, "type": "DATASET", "confidence": 0.7806902527809143}]}, {"text": "Using this method, the system may resume speaking before recognition is complete and will never initiate a clarifying subdialogue in response to a NUBI.", "labels": [], "entities": [{"text": "NUBI", "start_pos": 147, "end_pos": 151, "type": "DATASET", "confidence": 0.890611469745636}]}, {"text": "The PBR model was implemented in a public Lets Go!", "labels": [], "entities": []}, {"text": "statistical dialogue system (), and we compare it with a system using standard barge-in methods.", "labels": [], "entities": []}, {"text": "We find the PBR model has a significantly better task success rate and efficiency.", "labels": [], "entities": []}, {"text": "illustrates the NUBI responses produced by the standard barge-in (Baseline) and PBR models.", "labels": [], "entities": []}, {"text": "After both prompts are paused, the standard method initiates a clarifying sub-dialogue whereas PBR resumes the prompt.", "labels": [], "entities": []}, {"text": "We first provide background on Incremental Speech Recognition and describe the relevant related work on barge-in.", "labels": [], "entities": [{"text": "Incremental Speech Recognition", "start_pos": 31, "end_pos": 61, "type": "TASK", "confidence": 0.8997859756151835}]}, {"text": "We then detail the Prediction-based Barge-in Response model's operation and motivation before presenting a wholecall and component-wise analysis of the PBR: System response to Non-Understood Barge-In (NUBI) Baseline Ok, sixty one <NUBI> Sorry, say a bus route like twenty eight x PBR Ok, sixty one <NUBI> sixty one c.", "labels": [], "entities": []}, {"text": "Where are you leaving from?", "labels": [], "entities": []}, {"text": "The paper concludes with a discussion of our findings and implications for future SDS.", "labels": [], "entities": [{"text": "SDS", "start_pos": 82, "end_pos": 85, "type": "TASK", "confidence": 0.9733121991157532}]}], "datasetContent": [{"text": "The PBR model was evaluated during the Spoken Dialog Challenge 2012-2013 in a live Lets Go!", "labels": [], "entities": [{"text": "Spoken Dialog Challenge 2012-2013", "start_pos": 39, "end_pos": 72, "type": "TASK", "confidence": 0.6115692704916}]}, {"text": "In this task, the public can access bus schedule information during off hours in Pittsburgh, PA via a telephonic interaction with a dialogue system ().", "labels": [], "entities": []}, {"text": "The task can be divided into five sub-tasks: route, origin, destination, date/time, and bus schedules.", "labels": [], "entities": []}, {"text": "The last sub-task, bus schedules, provides information to the user whereas the first four gather information.", "labels": [], "entities": []}, {"text": "We entered two systems using the same POMDPbased DM).", "labels": [], "entities": [{"text": "POMDPbased DM", "start_pos": 38, "end_pos": 51, "type": "DATASET", "confidence": 0.8204326331615448}]}, {"text": "The first system, the \"Baseline\", used the standard barge-in model with VAD barge-in detection and barge-in disabled in) with the same sub-task specific rule-based language models and standard echo cancellation techniques.", "labels": [], "entities": [{"text": "VAD barge-in detection", "start_pos": 72, "end_pos": 94, "type": "TASK", "confidence": 0.5699140826861063}, {"text": "echo cancellation", "start_pos": 193, "end_pos": 210, "type": "TASK", "confidence": 0.7555174827575684}]}, {"text": "The beam width was set to maximize accuracy while still running faster than real-time.", "labels": [], "entities": [{"text": "beam width", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.7111245095729828}, {"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9989412426948547}]}, {"text": "The PBR system used a WATSON modification to output latticeaware partial results.", "labels": [], "entities": [{"text": "PBR", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.807177722454071}]}, {"text": "Call and barge-in statistics are shown in.", "labels": [], "entities": []}, {"text": "Here, we define (potential) barge-in (somewhat imprecisely) as a full recognition that at some point overlaps with the system prompt, as determined by the call logs.", "labels": [], "entities": []}, {"text": "We show the calls with barge-in before the bus schedule sub-task was reached (BI-BS) and the calls with barge-in during any point of the call (BI All).", "labels": [], "entities": [{"text": "BI-BS", "start_pos": 78, "end_pos": 83, "type": "METRIC", "confidence": 0.9857274889945984}, {"text": "BI All)", "start_pos": 143, "end_pos": 150, "type": "METRIC", "confidence": 0.9329538146654764}]}, {"text": "Since the Baseline system only enabled barge-in at specific points in the dialogue, it has fewer instances of barge-in (Total Barge-In) and fewer barge-in calls.", "labels": [], "entities": []}, {"text": "Regretfully, due to logging issues with the PBR system, recognition specific metrics such as Word Error Rate and true/false barge-in rates are unavailable.", "labels": [], "entities": [{"text": "Word Error Rate", "start_pos": 93, "end_pos": 108, "type": "METRIC", "confidence": 0.7255331973234812}]}], "tableCaptions": [{"text": " Table 2: Background noise and User Speech ISR", "labels": [], "entities": [{"text": "ISR", "start_pos": 43, "end_pos": 46, "type": "TASK", "confidence": 0.7282716035842896}]}, {"text": " Table 4: Evaluation of T 1 , off-line PBR, and Base- line VAD. For T 1 we respectively ('-' split) show  the UBI/NUBI % that are Paused/Continued, the  Paused/Continued % that are UBI/NUBI, and the  percentage over all recognitions", "labels": [], "entities": [{"text": "Base- line VAD", "start_pos": 48, "end_pos": 62, "type": "METRIC", "confidence": 0.806840717792511}]}]}