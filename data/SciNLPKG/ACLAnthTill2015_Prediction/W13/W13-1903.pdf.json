{"title": [{"text": "Discovering Narrative Containers in Clinical Text", "labels": [], "entities": [{"text": "Discovering Narrative Containers in Clinical Text", "start_pos": 0, "end_pos": 49, "type": "TASK", "confidence": 0.7916384239991506}]}], "abstractContent": [{"text": "The clinical narrative contains a great deal of valuable information that is only understandable in a temporal context.", "labels": [], "entities": []}, {"text": "Events, time expressions, and temporal relations convey information about the time course of a patient's clinical record that must be understood for many applications of interest.", "labels": [], "entities": []}, {"text": "In this paper, we focus on extracting information about how time expressions and events are related by narrative containers.", "labels": [], "entities": []}, {"text": "We use support vector machines with composite kernels, which allows for integrating standard feature kernels with tree kernels for representing structured features such as constituency trees.", "labels": [], "entities": []}, {"text": "Our experiments show that using tree kernels in addition to standard feature kernels improves F1 classification for this task.", "labels": [], "entities": [{"text": "F1", "start_pos": 94, "end_pos": 96, "type": "METRIC", "confidence": 0.9851523637771606}]}], "introductionContent": [{"text": "Clinical narratives area rich source of unstructured information that hold great potential for impacting clinical research and clinical care.", "labels": [], "entities": []}, {"text": "These narratives consist of unstructured natural language descriptions of various stages of clinical care, which makes them information dense but challenging to use computationally.", "labels": [], "entities": []}, {"text": "Information extracted from these narratives is already being used for clinical research tasks such as automatic phenotype classification for collecting disease cohorts retrospectively (, which can in turn be used fora variety of studies, including pharmacogenomics ().", "labels": [], "entities": [{"text": "automatic phenotype classification", "start_pos": 102, "end_pos": 136, "type": "TASK", "confidence": 0.586478610833486}]}, {"text": "Future applications may use information extracted from the clinical narrative at the point of care to assist physicians in decisionmaking in areal time fashion.", "labels": [], "entities": []}, {"text": "One of the most interesting and challenging aspects of clinical text is the pervasiveness of temporally grounded information.", "labels": [], "entities": []}, {"text": "This includes a number of clinical concepts which are events with finite time spans (e.g., surgery or x-ray), time expressions (December, postoperatively), and links that relate events to times or other events.", "labels": [], "entities": []}, {"text": "For example, surgery last May relates the time last May with the event surgery via the CONTAINS relation, while Vicodin after surgery relates the medication event Vicodin with the procedure event surgery via the AFTER relation.", "labels": [], "entities": [{"text": "CONTAINS relation", "start_pos": 87, "end_pos": 104, "type": "METRIC", "confidence": 0.9427108466625214}, {"text": "AFTER", "start_pos": 212, "end_pos": 217, "type": "METRIC", "confidence": 0.9463209509849548}]}, {"text": "There are many potential applications of clinical information extraction that are only possible with an understanding of the ordering and duration of the events in a clinical encounter.", "labels": [], "entities": [{"text": "clinical information extraction", "start_pos": 41, "end_pos": 72, "type": "TASK", "confidence": 0.6372988919417063}]}, {"text": "In this work we focus on extracting a particular temporal relation, CONTAINS, that holds between a time expression and an event expression.", "labels": [], "entities": [{"text": "CONTAINS", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.8108643293380737}]}, {"text": "This level of representation is based on the computational discourse model of narrative containers (Pustejovsky and Stubbs, 2011), which are time expressions or events which are central to a section of a text, usually manifested by being relative hubs of temporal relation links.", "labels": [], "entities": []}, {"text": "We argue that containment relations are useful as an intermediate level of granularity between full temporal relation extraction and \"coarse\" temporal bins () like before admission, on admission, and after admission.", "labels": [], "entities": [{"text": "containment", "start_pos": 14, "end_pos": 25, "type": "TASK", "confidence": 0.9600353240966797}, {"text": "temporal relation extraction", "start_pos": 100, "end_pos": 128, "type": "TASK", "confidence": 0.706748902797699}]}, {"text": "Correctly extracting CON-TAINS relations will, for example, allow for more accurate placement of events on a timeline, to the resolution possible by the number of time expressions in the document.", "labels": [], "entities": []}, {"text": "We suspect that this finer grained information will also be more useful for downstream applications like coreference, for which coarse information was found to be useful.", "labels": [], "entities": [{"text": "coreference", "start_pos": 105, "end_pos": 116, "type": "TASK", "confidence": 0.9704205989837646}]}, {"text": "The approach we develop is a supervised machine learning approach in which pairs of time expressions and events are classified as CONTAINS or not.", "labels": [], "entities": []}, {"text": "The specific approach is a support vector machine using both standard feature kernels and tree kernels, a novel approach to this problem in this domain that has shown promise on other relation extraction tasks.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 184, "end_pos": 203, "type": "TASK", "confidence": 0.7903403043746948}]}, {"text": "This work makes use of anew corpus we developed as part of the THYME 1 project (Temporal History of Your Medical Events) focusing on temporal events and relations in clinical text.", "labels": [], "entities": [{"text": "THYME 1 project (Temporal History of Your Medical Events)", "start_pos": 63, "end_pos": 120, "type": "DATASET", "confidence": 0.7183142873373899}]}, {"text": "This corpus consists of clinical and pathology notes on colorectal cancer from Mayo Clinic.", "labels": [], "entities": []}, {"text": "Gold standard annotations include Penn Treebank-style phrase structure in addition to clinically relevant temporal annotations like clinical events, temporal expressions, and various temporal relations.", "labels": [], "entities": [{"text": "Penn Treebank-style phrase", "start_pos": 34, "end_pos": 60, "type": "DATASET", "confidence": 0.9595008691151937}]}], "datasetContent": [{"text": "The corpus we used for evaluations was described in Section 2.", "labels": [], "entities": []}, {"text": "There are 78 total notes in the corpus, with three notes for each of 26 patients.", "labels": [], "entities": []}, {"text": "The data is split into training (50%), development (25%), and test (25%) sections based on patient number, so that each patient's notes are all in the same section.", "labels": [], "entities": []}, {"text": "The combined training and development set used for final training consists of 4378 sentences with 49,050 tokens, and 7372 events, 849 time expressions, and 2287 CONTAINS relations.", "labels": [], "entities": []}, {"text": "There were 774 positive instances of CONTAINS in the training data, with 1513 negative instances.", "labels": [], "entities": [{"text": "CONTAINS", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.91936194896698}]}, {"text": "For constituent structure and features we use the gold standard treebank and event and time features from our corpus.", "labels": [], "entities": []}, {"text": "Preliminary work suggests that automatic parses from cTAKES do not harm performance very much, but the focus of this work is on the relation extraction so we use gold standard parses.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 132, "end_pos": 151, "type": "TASK", "confidence": 0.8628782629966736}]}, {"text": "All preliminary experiments were done using the development set for testing.", "labels": [], "entities": []}, {"text": "We designed a set of experiments to examine several hypotheses regarding extraction of the CONTAINS relation and the efficacy of different tree kernel representations.", "labels": [], "entities": []}, {"text": "The first two configurations test simple rule-based baseline systems, CLOSEST-P and CLOSEST-R, for distance-related decision rule systems meant to optimize precision and recall, respectively.", "labels": [], "entities": [{"text": "precision", "start_pos": 156, "end_pos": 165, "type": "METRIC", "confidence": 0.9979742169380188}, {"text": "recall", "start_pos": 170, "end_pos": 176, "type": "METRIC", "confidence": 0.9977607727050781}]}, {"text": "CLOSEST-P hypothesizes a CONTAINS link between every TIMEX3 and the closest annotated EVENT, which will make few links overall.", "labels": [], "entities": [{"text": "CONTAINS", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.893743634223938}]}, {"text": "CLOSEST-R hypothesizes a CON-TAINS link between every EVENT and the closest TIMEX3, which will make many more links.", "labels": [], "entities": [{"text": "EVENT", "start_pos": 54, "end_pos": 59, "type": "METRIC", "confidence": 0.8329886198043823}]}, {"text": "The next configuration, Flat Features, uses the token and part of speech features along with argument semantics features, as described in Section 3.", "labels": [], "entities": []}, {"text": "While this feature set may not seem exhaustive, in preliminary work many traditional relation extraction features were tried and found to not have much effect.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 85, "end_pos": 104, "type": "TASK", "confidence": 0.7843780517578125}]}, {"text": "This particular configuration was tested because it is most comparable to the bag of word and bag of POS kernels from, and should help show whether the tree kernel is providing anything over an equivalent set of basic features.", "labels": [], "entities": []}, {"text": "We then examine several composite kernels, all using the same feature kernel, but using different tree kernel-based representations.", "labels": [], "entities": []}, {"text": "First, we use a composite kernel which uses the bag of word and bag of POS tree views, as in.", "labels": [], "entities": []}, {"text": "Next, we add in two additional tree views to the tree kernel, Path-Enclosed Tree and Path Tree, which are intended to examine the effect of using traditional syntax, and the long distance features that they enable.", "labels": [], "entities": []}, {"text": "The final experimental configuration replaces the PET and PT representations from the last configuration with the Feature Tree representation.", "labels": [], "entities": [{"text": "PT", "start_pos": 58, "end_pos": 60, "type": "METRIC", "confidence": 0.754583477973938}]}, {"text": "This tests the hypothesis that the difference between positive results for tree kernels in this task (as in, say,) and negative results reported by is the difference between using a full-parse tree and using standard sub-tree representations.", "labels": [], "entities": []}, {"text": "For the rule-based systems, there are no parameters to tune.", "labels": [], "entities": []}, {"text": "Our machine-learning systems are based on support vector machines (SVM), which require tuning of several parameters, including kernel type (linear, polynomial, and radial basis function), the parameters for each kernel, and c, the cost of misclassification.", "labels": [], "entities": []}, {"text": "Tree kernels introduce an additional parameter \u03bb for weighting large structures, and the use of a composite kernel introduces parameters for which kernel combination operator to use, and how to weight the different kernels for the sum operator.", "labels": [], "entities": []}, {"text": "For each machine learning configuration, we performed a large grid search over the combined parameter space, where we trained on the training set and tested on the development set.", "labels": [], "entities": []}, {"text": "For the final experiments, the parameters were chosen that optimized the F1 score on the development set.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9887013137340546}]}, {"text": "Qualitatively, the parameter tuning strongly favored configurations which combined the kernels using the sum operator, and recall and precision were strongly correlated with the SVM parameter c.", "labels": [], "entities": [{"text": "recall", "start_pos": 123, "end_pos": 129, "type": "METRIC", "confidence": 0.9994474053382874}, {"text": "precision", "start_pos": 134, "end_pos": 143, "type": "METRIC", "confidence": 0.9987534284591675}]}, {"text": "Using these parameters, we then trained on the combined training and development sets and tested on the official test set.", "labels": [], "entities": [{"text": "official test set", "start_pos": 104, "end_pos": 121, "type": "DATASET", "confidence": 0.7794033487637838}]}, {"text": "The state of evaluating temporal relations has been evolving over the past decade.", "labels": [], "entities": []}, {"text": "This is partially due to the inferential properties of temporal relations, because it is possible to define the same set of relations using different set of axioms.", "labels": [], "entities": []}, {"text": "To take a very simple example, given a gold set of relations A<B and B<C, and given the system output A<B, A<C and B<C, if one were to compute a plain precision/recall metric, then the axiom A<C would be counted against the system, when one can easily infer from the gold set of relations that it is indeed correct.", "labels": [], "entities": [{"text": "precision", "start_pos": 151, "end_pos": 160, "type": "METRIC", "confidence": 0.8976778388023376}, {"text": "recall", "start_pos": 161, "end_pos": 167, "type": "METRIC", "confidence": 0.7645354866981506}]}, {"text": "With more relations the inference process becomes more complex.", "labels": [], "entities": []}, {"text": "Recently there has been some work trying to address the shortcomings of the plain F1 score ().", "labels": [], "entities": [{"text": "F1 score", "start_pos": 82, "end_pos": 90, "type": "METRIC", "confidence": 0.8965693414211273}]}, {"text": "However, the community has not yet come to a consensus on the best evaluation approach.", "labels": [], "entities": []}, {"text": "Two recent evaluations, and the 2012 i2b2 Challenge (, used an implementation of the proposal by).", "labels": [], "entities": [{"text": "2012 i2b2 Challenge", "start_pos": 32, "end_pos": 51, "type": "DATASET", "confidence": 0.7456946770350138}]}, {"text": "However, as described in, this algorithm, which uses a greedy graph minimization approach, is sensitive to the order in which the temporal relations are presented to the scorer.", "labels": [], "entities": []}, {"text": "In addition, the scorer is notable to give credit for non-redundant, nonminimum links as with the the case of the relation A<C mentioned earlier.", "labels": [], "entities": []}, {"text": "Considering that the measures for evaluating temporal relations are still evolving, we decided to use plain F-score, with recall and precision scores also reported.", "labels": [], "entities": [{"text": "F-score", "start_pos": 108, "end_pos": 115, "type": "METRIC", "confidence": 0.9902390241622925}, {"text": "recall", "start_pos": 122, "end_pos": 128, "type": "METRIC", "confidence": 0.9992551207542419}, {"text": "precision", "start_pos": 133, "end_pos": 142, "type": "METRIC", "confidence": 0.9732518792152405}]}, {"text": "This score is computed across all intra-sentential EVENT-TIMEX3 pairs in the gold standard, where precision = # correct predictions # predictions , recall = # correct predictions # gold standard relations , and F1 score = 2 * precision * recall precision+recall .  Results are shown in.", "labels": [], "entities": [{"text": "precision", "start_pos": 98, "end_pos": 107, "type": "METRIC", "confidence": 0.9989209175109863}, {"text": "recall", "start_pos": 148, "end_pos": 154, "type": "METRIC", "confidence": 0.9964410662651062}, {"text": "F1 score", "start_pos": 211, "end_pos": 219, "type": "METRIC", "confidence": 0.9868021905422211}, {"text": "precision", "start_pos": 226, "end_pos": 235, "type": "METRIC", "confidence": 0.9570544362068176}, {"text": "recall precision", "start_pos": 238, "end_pos": 254, "type": "METRIC", "confidence": 0.852185845375061}, {"text": "recall", "start_pos": 255, "end_pos": 261, "type": "METRIC", "confidence": 0.5287461280822754}]}, {"text": "Rule-based baselines perform reasonably well, but are heavily biased in terms of precision or recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 81, "end_pos": 90, "type": "METRIC", "confidence": 0.9994584918022156}, {"text": "recall", "start_pos": 94, "end_pos": 100, "type": "METRIC", "confidence": 0.996056079864502}]}, {"text": "The machine learning baseline cannot even obtain the same performance as the CLOSEST-R rule-based system, though it is more balanced in terms of pre-", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Table of results of main experiments.", "labels": [], "entities": []}]}