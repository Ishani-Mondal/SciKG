{"title": [{"text": "Munich-Edinburgh-Stuttgart Submissions of OSM Systems at WMT13", "labels": [], "entities": [{"text": "WMT13", "start_pos": 57, "end_pos": 62, "type": "DATASET", "confidence": 0.8746321201324463}]}], "abstractContent": [{"text": "This paper describes Munich-Edinburgh-Stuttgart's submissions to the Eighth Workshop on Statistical Machine Translation.", "labels": [], "entities": [{"text": "Eighth Workshop on Statistical Machine Translation", "start_pos": 69, "end_pos": 119, "type": "TASK", "confidence": 0.5963497261206309}]}, {"text": "We report results of the translation tasks from German, Spanish, Czech and Russian into English and from English to German, Spanish, Czech, French and Rus-sian.", "labels": [], "entities": [{"text": "translation", "start_pos": 25, "end_pos": 36, "type": "TASK", "confidence": 0.9616542458534241}]}, {"text": "The systems described in this paper use OSM (Operation Sequence Model).", "labels": [], "entities": []}, {"text": "We explain different pre-/post-processing steps that we carried out for different language pairs.", "labels": [], "entities": []}, {"text": "For German-English we used constituent parsing for reordering and compound splitting as preprocessing steps.", "labels": [], "entities": [{"text": "constituent parsing", "start_pos": 27, "end_pos": 46, "type": "TASK", "confidence": 0.6624827831983566}, {"text": "compound splitting", "start_pos": 66, "end_pos": 84, "type": "TASK", "confidence": 0.7040012329816818}]}, {"text": "For Russian-English we transliter-ated the unknown words.", "labels": [], "entities": []}, {"text": "The translitera-tion system is learned with the help of an unsupervised transliteration mining algorithm .", "labels": [], "entities": []}], "introductionContent": [{"text": "In this paper we describe Munich-EdinburghStuttgart's 1 joint submissions to the Eighth Workshop on Statistical Machine Translation.", "labels": [], "entities": [{"text": "Eighth Workshop on Statistical Machine Translation", "start_pos": 81, "end_pos": 131, "type": "TASK", "confidence": 0.5998928596576055}]}, {"text": "We use our in-house OSM decoder which is based on the operation sequence N-gram model).", "labels": [], "entities": []}, {"text": "The N-gram-based SMT framework) memorizes Markov chains over sequences of minimal translation units (MTUs or tuples) composed of bilingual translation units.", "labels": [], "entities": [{"text": "SMT", "start_pos": 17, "end_pos": 20, "type": "TASK", "confidence": 0.8641194701194763}]}, {"text": "The OSM model integrates reordering operations within the tuple sequences to form a heterogeneous mixture of lexical translation and reordering operations and learns a Markov model over a sequence of operations.", "labels": [], "entities": []}, {"text": "Our decoder uses the beam search algorithm in a stack-based decoder like most sequence-based SMT frameworks.", "labels": [], "entities": [{"text": "SMT", "start_pos": 93, "end_pos": 96, "type": "TASK", "confidence": 0.9079926609992981}]}, {"text": "Although the model is based on minimal translation units, we use phrases during search because they improve the search accuracy of our system.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 119, "end_pos": 127, "type": "METRIC", "confidence": 0.9821416139602661}]}, {"text": "The earlier decoder) was based on minimal units.", "labels": [], "entities": []}, {"text": "But we recently showed that using phrases during search gives better coverage of translation, better future cost estimation and lesser search errors () than MTU-based decoding.", "labels": [], "entities": []}, {"text": "We have therefore shifted to phrase-based search on top of the OSM model.", "labels": [], "entities": []}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 gives a short description of the model and search as used in the OSM decoder.", "labels": [], "entities": [{"text": "OSM decoder", "start_pos": 75, "end_pos": 86, "type": "DATASET", "confidence": 0.8485512733459473}]}, {"text": "In Section 3 we give a description of the POS-based operation sequence model that we test for our German-English and English-German experiments.", "labels": [], "entities": []}, {"text": "Section 4 describes our processing of the German and English data for German-English and English-German experiments.", "labels": [], "entities": []}, {"text": "In Section 5 we describe the unsupervised transliteration mining that has been done for the Russian-English and English-Russian experiments.", "labels": [], "entities": [{"text": "transliteration mining", "start_pos": 42, "end_pos": 64, "type": "TASK", "confidence": 0.7968736290931702}]}, {"text": "In Section 6 we describe the sub-sampling technique that we have used for several language pairs.", "labels": [], "entities": []}, {"text": "In Section 7 we describe the experimental setup followed by the results.", "labels": [], "entities": []}, {"text": "Finally we summarize the paper in Section 8.", "labels": [], "entities": []}], "datasetContent": [{"text": "Parallel Corpus: The amount of bitext used for the estimation of the translation models is: de-en \u2248 4.5M and ru-en \u2248 2M parallel sentences.", "labels": [], "entities": []}, {"text": "We were able to use all the available data for cs-to-en (\u2248 15.6M sentences).", "labels": [], "entities": []}, {"text": "However, sub-sampled data was used for en-to-cs (\u2248 3M sentences), en-to-fr (\u2248 7.8M sentences) and es-en (\u2248 3M sentences).", "labels": [], "entities": []}, {"text": "Monolingual Language Model: We used all the available training data (including LDC Gigaword data) for the estimation of monolingual language models: en \u2248 287.3M sentences, fr \u2248 91M, es \u2248 65.7M, cs \u2248 43.4M and ru \u2248 21.7M sentences.", "labels": [], "entities": []}, {"text": "All data except for ru-en and en-ru was true-cased.", "labels": [], "entities": []}, {"text": "We followed the approach of by training language models from each sub-corpus separately and then linearly interpolated them using SRILM with weights optimized on the held-out dev-set.", "labels": [], "entities": [{"text": "SRILM", "start_pos": 130, "end_pos": 135, "type": "DATASET", "confidence": 0.6599512100219727}]}, {"text": "We concatenated the news-test sets from four years to obtain a large dev-set 5 in order to obtain more stable weights).", "labels": [], "entities": []}, {"text": "Decoder Settings: For each extracted input phrase only 15-best translation options were used during decoding.", "labels": [], "entities": []}, {"text": "We used a hard reordering limit of 16 words which disallows a jump beyond 16 source words.", "labels": [], "entities": []}, {"text": "A stack size of 100 was used during tuning and 200 for decoding the test set.", "labels": [], "entities": []}, {"text": "Results: shows the uncased BLEU scores along with the rank obtained on the submission matrix.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 27, "end_pos": 31, "type": "METRIC", "confidence": 0.9902201294898987}]}, {"text": "We also show the results from human evaluation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Translating into and from English", "labels": [], "entities": [{"text": "Translating into and from English", "start_pos": 10, "end_pos": 43, "type": "TASK", "confidence": 0.8759520292282105}]}]}