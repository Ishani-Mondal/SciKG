{"title": [{"text": "Towards a Tight Integration of Syntactic Parsing with Semantic Disambiguation by means of Declarative Programming *", "labels": [], "entities": [{"text": "Tight Integration of Syntactic Parsing", "start_pos": 10, "end_pos": 48, "type": "TASK", "confidence": 0.761783653497696}]}], "abstractContent": [{"text": "We propose and advocate the use of an advanced declarative programming paradigm-answer set programming-as a uniform platform for integrated approach towards syntax-semantic processing in natural language.", "labels": [], "entities": []}, {"text": "We illustrate that (a) the parsing technology based on answer set programming implementation reaches performance sufficient for being a useful NLP tool, and (b) the proposed method for incorporating semantic information from FRAMENET into syntactic parsing may prove to be useful in allowing semantic-based disambiguation of syntactic structures.", "labels": [], "entities": [{"text": "parsing", "start_pos": 27, "end_pos": 34, "type": "TASK", "confidence": 0.9677685499191284}, {"text": "syntactic parsing", "start_pos": 239, "end_pos": 256, "type": "TASK", "confidence": 0.6746957451105118}]}], "introductionContent": [{"text": "Typical natural language processing (NLP) system consists of at least several components including syntactic and semantic analyzers.", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 8, "end_pos": 41, "type": "TASK", "confidence": 0.7583111027876536}]}, {"text": "A common assumption in the design of an NLP system is that these components are separate and independent.", "labels": [], "entities": []}, {"text": "On one hand, this allows researchers an abstraction necessary to promote substantial steps forward in each task, plus such a separation permits for more convenient, modular software development.", "labels": [], "entities": []}, {"text": "On the other hand, constraints from \"higher level\" processes are frequently needed to disambiguate \"lower level\" processes.", "labels": [], "entities": []}, {"text": "For example, consider the syntactically ambiguous sentence I eat spaghetti with chopsticks.", "labels": [], "entities": []}, {"text": "In the former, the prepositional phrase \"with chopsticks\" modifies the verbal phrase \"eat spaghetti \", and in the latter, it modifies the noun phrase \"spaghetti \".", "labels": [], "entities": []}, {"text": "The sentence I eat spaghetti with meatballs is syntactically ambiguous in a similar manner.", "labels": [], "entities": []}, {"text": "In order to assign the proper syntactic structure to each of these sentences one has to take into account selectional restrictions, i.e., the semantic restrictions that a word imposes on the environment in which it occurs.", "labels": [], "entities": []}, {"text": "For instance, in (1) the fact that a chopstick is an instrument suggests that \"with chopsticks\" modifies \"eat spaghetti \" as a tool for eating.", "labels": [], "entities": []}, {"text": "Thus, an approach that integrates syntactic and semantic processing is essential for proper analysis of such sentences.", "labels": [], "entities": []}, {"text": "Modern statistical methods, dominant in the field of syntactic analysis, take into account selectional restrictions implicitly by assigning most probable syntactic structure based on observed cooccurrences of words and structures in corpora.", "labels": [], "entities": [{"text": "syntactic analysis", "start_pos": 53, "end_pos": 71, "type": "TASK", "confidence": 0.9174094200134277}]}, {"text": "Yet, this is often not sufficient.", "labels": [], "entities": []}, {"text": "Sentences (1) and (3) illustrate this point, as the advanced parsers, including Stanford and Berkeley systems, do not produce proper syntactic representations for these sentences: instead they favor the same structure for both of them.", "labels": [], "entities": []}, {"text": "1 Similarly, semantic role labelers (joint syntactic-semantic parsers) such as SEMAFOR ( and display the same issue.", "labels": [], "entities": [{"text": "semantic role labelers", "start_pos": 13, "end_pos": 35, "type": "TASK", "confidence": 0.6198239227135977}]}, {"text": "The FRAMENET project () provides information that can disambiguate sentences (1) and (3).", "labels": [], "entities": [{"text": "FRAMENET project", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.8224304020404816}]}, {"text": "For instance, the frame food corresponds to the word \"spaghetti \".", "labels": [], "entities": []}, {"text": "This frame contains information that food only takes other food as constituents.", "labels": [], "entities": []}, {"text": "Thus modifying \"spaghetti \" with \"chopsticks\" in a parse tree for (1) yields a forbidden situation.", "labels": [], "entities": []}, {"text": "In this paper we present preliminary work on a system for natural language parsing that targets a tight integration of syntax and semantics.", "labels": [], "entities": [{"text": "natural language parsing", "start_pos": 58, "end_pos": 82, "type": "TASK", "confidence": 0.6625614960988363}]}, {"text": "We illustrate its ability to take into account both quantitative and qualitative data available for processing natural language, where the former stems from statistical information available for natural language and the latter stems from lexical and commonsense knowledge available in lexical datasets such as FRAMENET.", "labels": [], "entities": [{"text": "FRAMENET", "start_pos": 310, "end_pos": 318, "type": "DATASET", "confidence": 0.9053490161895752}]}, {"text": "Lierler and Sch\u00fcller (2012) developed a Combinatory Categorial Grammar (CCG) parser ASPC-CGTK 2 . A distinguishing feature of ASPCCGTK is that its design allows for synergy of both quantitative and qualitative information.", "labels": [], "entities": []}, {"text": "First, it relies on the C&C part-of-speech supertagger) -built using latest statistical and machine learning advances in NLP.", "labels": [], "entities": []}, {"text": "Second, its implementation is based on a prominent knowledge representation and reasoning formalism -answer set programming (ASP), see.", "labels": [], "entities": [{"text": "answer set programming (ASP)", "start_pos": 101, "end_pos": 129, "type": "TASK", "confidence": 0.6528108716011047}]}, {"text": "ASP constitutes a convenient framework for representing constraints posed by selectional restrictions explicitly; thus we can augment implicit information available from statistical part-of-speech tagging with qualitative reasoning.", "labels": [], "entities": [{"text": "statistical part-of-speech tagging", "start_pos": 170, "end_pos": 204, "type": "TASK", "confidence": 0.6427115003267924}]}, {"text": "We believe that the ASPC-CGTK parser is a strong ground for designing a systematic, elaboration tolerant, knowledge intensive approach towards an integrated syntax-semantics analysis tool.", "labels": [], "entities": [{"text": "ASPC-CGTK parser", "start_pos": 20, "end_pos": 36, "type": "TASK", "confidence": 0.5643420368432999}]}, {"text": "Performance results on ASPCCGTK reported in suggest that the \"planning\" approach adopted for parsing in the system scales to sentences of length up to 15 words.", "labels": [], "entities": [{"text": "ASPCCGTK", "start_pos": 23, "end_pos": 31, "type": "DATASET", "confidence": 0.7091861367225647}, {"text": "parsing", "start_pos": 93, "end_pos": 100, "type": "TASK", "confidence": 0.9744088649749756}]}, {"text": "It maybe sufficient fora number of applications: for example, 6.87 is the average number of words in sentences in the GEOQUERY corpus).", "labels": [], "entities": [{"text": "GEOQUERY corpus", "start_pos": 118, "end_pos": 133, "type": "DATASET", "confidence": 0.9739828407764435}]}, {"text": "But, in order for ASPCCGTK to become a viable NLP technology it is important to address the issue of its scalability.", "labels": [], "entities": [{"text": "ASPCCGTK", "start_pos": 18, "end_pos": 26, "type": "TASK", "confidence": 0.6600270867347717}]}, {"text": "The two contributions of this paper are as follows.", "labels": [], "entities": []}, {"text": "First we demonstrate how use of the CockeYounger-Kasami (CYK) algorithm enhances the performance of ASPCCGTK.", "labels": [], "entities": [{"text": "CockeYounger-Kasami (CYK) algorithm", "start_pos": 36, "end_pos": 71, "type": "DATASET", "confidence": 0.7985299706459046}]}, {"text": "We evaluate the new approach implemented in ASPCCGTK on the CCGbank corpus and report the results.", "labels": [], "entities": [{"text": "CCGbank corpus", "start_pos": 60, "end_pos": 74, "type": "DATASET", "confidence": 0.9783038198947906}]}, {"text": "Second we propose and illustrate the method on how (a) FRAMENET can be used for properly disambiguating sentences and, and (b) how this information is incorporated into the ASPCCGTK system.", "labels": [], "entities": [{"text": "FRAMENET", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9769086241722107}]}, {"text": "As a result we are able to use the ASPCCGTK parser to generate only the expected syntactic structures for the sentences in question.", "labels": [], "entities": [{"text": "ASPCCGTK parser", "start_pos": 35, "end_pos": 50, "type": "TASK", "confidence": 0.5877669751644135}]}, {"text": "In the future, we will automate a process of extracting selection restriction constraints from the data available in FRAMENET, by building an interface between ASPCCGTK and FRAMENET.", "labels": [], "entities": [{"text": "FRAMENET", "start_pos": 117, "end_pos": 125, "type": "DATASET", "confidence": 0.897758424282074}, {"text": "ASPCCGTK", "start_pos": 160, "end_pos": 168, "type": "DATASET", "confidence": 0.8207474946975708}, {"text": "FRAMENET", "start_pos": 173, "end_pos": 181, "type": "DATASET", "confidence": 0.9614517688751221}]}, {"text": "CCGbank will provide us with extensive real world data for evaluating our approach.", "labels": [], "entities": [{"text": "CCGbank", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9813980460166931}]}, {"text": "Once successful, we will look into expanding the approach to the use of other semantic annotations datasets for lexical items such as VERBNET, PROPBANK, NOMBANK and others for more complete sets of lexical constraints.", "labels": [], "entities": [{"text": "VERBNET", "start_pos": 134, "end_pos": 141, "type": "DATASET", "confidence": 0.6937887668609619}, {"text": "NOMBANK", "start_pos": 153, "end_pos": 160, "type": "DATASET", "confidence": 0.6748529076576233}]}, {"text": "2 Extending ASPCCGTK for parsing CCG with CYK in ASP Combinatory Categorial Grammar) is a formalism that uses a small set of combinatory rules and a rich set of categories.", "labels": [], "entities": [{"text": "parsing CCG", "start_pos": 25, "end_pos": 36, "type": "TASK", "confidence": 0.7969368994235992}, {"text": "ASP Combinatory Categorial Grammar", "start_pos": 49, "end_pos": 83, "type": "TASK", "confidence": 0.49802009761333466}]}, {"text": "Categories are either atomic such as NP , or complex such as S\\NP , which is a category for English intransitive verbs.", "labels": [], "entities": []}, {"text": "The category S\\NP states that an NP to the left of the word will result in a sentence S.", "labels": [], "entities": []}, {"text": "Given a sentence and a lexicon containing a set of word-category pairs, we replace words by appropriate categories and then apply combinators.", "labels": [], "entities": []}, {"text": "For example, in the former derivation in (2), \"eat\" has category (VP /PP )/NP and \"spaghetti \" has category NP . The combinator used in this derivation is forward application (fa) where A and B are variables that can be substituted for CCG categories.", "labels": [], "entities": []}, {"text": "Applying forward application to \"eat\" and \"spaghetti \" substitutes A with VP /PP and B with NP and yields VP /PP . An input sentence is part of a grammar if some sequence of applying combinators results in the category Sat the root of the parse tree.", "labels": [], "entities": []}, {"text": "The implementation of ASPCCGTK is based on answer set programming -a declarative logic programming paradigm.", "labels": [], "entities": []}, {"text": "ASP roots in answer set semantics of logic programs.", "labels": [], "entities": [{"text": "ASP", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9556028842926025}]}, {"text": "The idea of ASP is to represent a problem by a program whose answer sets correspond to solutions.", "labels": [], "entities": [{"text": "ASP", "start_pos": 12, "end_pos": 15, "type": "TASK", "confidence": 0.9813554883003235}]}, {"text": "For example, for parsing we encode the grammar and the input sentence in away that each answer set corresponds to a valid parse tree of the input.", "labels": [], "entities": [{"text": "parsing", "start_pos": 17, "end_pos": 24, "type": "TASK", "confidence": 0.976318895816803}]}, {"text": "Unlike in an imperative style of programming, in declarative programming we describe a specification of the problem, which expresses what the program should accomplish rather than prescribing how to do it.", "labels": [], "entities": []}, {"text": "Answer set solvers use this specification to efficiently navigate through a search space and find solutions to the problem.", "labels": [], "entities": [{"text": "Answer set solvers", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7431701223055521}]}, {"text": "For a more detailed and yet brief introduction of CCG and ASP we refer the reader to.", "labels": [], "entities": [{"text": "ASP", "start_pos": 58, "end_pos": 61, "type": "TASK", "confidence": 0.8014153242111206}]}, {"text": "The CYK (Cocke, Younger, and Kasami) algorithm for context-free-grammars was initially published by.", "labels": [], "entities": [{"text": "CYK", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.918807327747345}]}, {"text": "It can be extended to CCG using ideas from.", "labels": [], "entities": []}, {"text": "Given an input of n words, CYK operates on an n \u00d7 n triangular chart.", "labels": [], "entities": []}, {"text": "Words in the input are associated with categories in the diagonal of the chart.", "labels": [], "entities": []}, {"text": "Combinatory rules combine categories from two chart cells into a single category in another \"corresponding\" cell.", "labels": [], "entities": []}, {"text": "We illustrate these intuitions using a 3 \u00d7 3 chart: An input is recognized as part of the grammar if the top right chart cell contains the category S after successive application of combinators to the chart.", "labels": [], "entities": []}, {"text": "A realization of CYK for recognition of context-free grammars in ASP was described by.", "labels": [], "entities": [{"text": "recognition of context-free grammars", "start_pos": 25, "end_pos": 61, "type": "TASK", "confidence": 0.7890947759151459}]}, {"text": "First, we adapt their approach to CCG.", "labels": [], "entities": []}, {"text": "Second, we extend it to the task of generating parse trees as we are not only interested in recognizing grammatical inputs but also in producing appropriate parses.", "labels": [], "entities": []}, {"text": "We now show parts of our realization of CYK in the ASP formalism.", "labels": [], "entities": [{"text": "CYK", "start_pos": 40, "end_pos": 43, "type": "DATASET", "confidence": 0.8745123744010925}, {"text": "ASP formalism", "start_pos": 51, "end_pos": 64, "type": "TASK", "confidence": 0.779061883687973}]}, {"text": "We represent a chart using a predicate grid(Pi,Pj,Cat) and initialize the diagonal using the rule grid(P,P,C) :-category at(C,P).", "labels": [], "entities": []}, {"text": "where the category at predicate is obtained from tagging the input with the C&C supertagger.", "labels": [], "entities": []}, {"text": "where rfunc(X,Y) encodes complex category of the form X/Y . The first rule defines where the fa combinator can be applied to within the chart.", "labels": [], "entities": []}, {"text": "The second rule defines which categories this application creates.", "labels": [], "entities": []}, {"text": "For obtaining parse trees, we \"guess\" for each instance of applicable if that combinator is actually applied (SrcLeft, SrcDown, and Result stand for CCG categories in the CYK grid): { applied(Comb,Pj,Pi,Pleft,Pdown,Result,SrcLeft,SrcDown) } :-applicable(Comb,Pj,Pi,Pleft,Pdown,Result,SrcLeft,SrcDown).", "labels": [], "entities": [{"text": "Result", "start_pos": 132, "end_pos": 138, "type": "METRIC", "confidence": 0.9465920925140381}, {"text": "CYK grid", "start_pos": 171, "end_pos": 179, "type": "DATASET", "confidence": 0.9307740926742554}]}, {"text": "The curly bracket construct in the head of this rule is what expresses the guess as we can intuitively read this rule as follows: an expression in the head may hold in case if the body of the rule holds.", "labels": [], "entities": []}, {"text": "To obtain only valid parse trees, we furthermore (i) add rules that constraint the selection of multiple applied combinators in one cell, (ii) define reachability of diagonal chart cells from the S category in the top right cell, and (iii) add rules that require all diagonal cells to be reachable.", "labels": [], "entities": []}, {"text": "We believe that the possibility of explicitly representing alternatives and then restricting them by expressing appropriate conditions using declarative means makes ASP a powerful tool for working with ambiguities in the field of NLP.", "labels": [], "entities": [{"text": "ASP", "start_pos": 165, "end_pos": 168, "type": "TASK", "confidence": 0.930268406867981}]}, {"text": "We conducted empirical experiments to compare the performance of the original ASPCCGTK and the ASPCCGTK enhanced with CYK as described here.", "labels": [], "entities": []}, {"text": "We report average times and number of timeouts when parsing all sentences of Section 00 of the CCGbank corpus) using a timeout of 1200 seconds.", "labels": [], "entities": [{"text": "Section 00 of the CCGbank corpus", "start_pos": 77, "end_pos": 109, "type": "DATASET", "confidence": 0.8682772219181061}]}, {"text": "The sentences were chunked and tagged by the C&C supertagger.", "labels": [], "entities": [{"text": "C&C supertagger", "start_pos": 45, "end_pos": 60, "type": "DATASET", "confidence": 0.9712652415037155}]}, {"text": "3 Semantic Disambiguation using FRAMENET FRAMENET is a dataset of semantic relations based on Frame Semantics ().", "labels": [], "entities": [{"text": "FRAMENET", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9602339863777161}, {"text": "FRAMENET", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.544975221157074}]}, {"text": "Lexical items evoke certain frames that contain frame elements; for example, \"eat\" evokes an ingestion frame and everything that is of semantic type food evokes a food frame.", "labels": [], "entities": []}, {"text": "Sample information available in the ingestion and food frames follow: Each frame element is a slot that maybe filled only by elements of the correct semantic type.", "labels": [], "entities": []}, {"text": "Types are organized in a taxonomy.", "labels": [], "entities": []}, {"text": "For instance, the following part of the taxonomy is relevant to this presentation: tool is a instrument food is a ingestible food is a food constituent.", "labels": [], "entities": []}, {"text": "We propose a concept of a \"semantically coherent\" parse tree.", "labels": [], "entities": []}, {"text": "Information from FRAMENET allows us to disambiguate semantically coherent and incoherent trees.", "labels": [], "entities": [{"text": "FRAMENET", "start_pos": 17, "end_pos": 25, "type": "DATASET", "confidence": 0.8416698575019836}]}, {"text": "We now make these ideas precise.", "labels": [], "entities": []}, {"text": "Each node in a tree is annotated with a tag -either a distinguished tag \u22a5 or a pair T ||F where both T and F are sets consisting of semantic types.", "labels": [], "entities": []}, {"text": "Each leaf of a tree is assigned a tag T ||F in accordance with FRAMENET information fora corresponding word.", "labels": [], "entities": [{"text": "F", "start_pos": 42, "end_pos": 43, "type": "METRIC", "confidence": 0.9750754237174988}, {"text": "FRAMENET", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9544894695281982}]}, {"text": "The set T contains the semantic types associated with the leaf-word.", "labels": [], "entities": []}, {"text": "For instance, for word \"spaghetti \", this set T sp is {food, food constituent, ingestible}.", "labels": [], "entities": []}, {"text": "The set F contains the semantic types associated with the frame elements of a frame evoked by a leafword.", "labels": [], "entities": []}, {"text": "For instance, for word \"eat\" that evokes the ingestion frame, this set F eat is {sentient, ingestible, tool, manner}.", "labels": [], "entities": []}, {"text": "To define a tag fora non-leaf node of a tree we introduce the following terminology.", "labels": [], "entities": []}, {"text": "Any non-leaf node in a CCG parse tree is a parent of two children: a functor and an argument.", "labels": [], "entities": []}, {"text": "Depending on semantic information assigned to nodes, they act as functors or arguments.", "labels": [], "entities": []}, {"text": "For a non-leaf node p, we define a tag T p ||F p as follows where f and a stand fora functor and an argument children of p, respectively.", "labels": [], "entities": []}, {"text": "Pairs F f ||T f and F a ||T a correspond to tags of these children.", "labels": [], "entities": []}, {"text": "We say that a parse tree is semantically coherent if there is no node in the tree annotated by the \u22a5 tag.", "labels": [], "entities": []}, {"text": "Recall the syntactic structures (2) corresponding to the verb phrase of sentence (1).", "labels": [], "entities": []}, {"text": "The annotated counterpart of the former structure follows 3 : This subtree is semantically coherent.", "labels": [], "entities": []}, {"text": "On the other hand, part of the later structure in (2) constitutes semantically incoherent subtree: with chopsticks NP \\NP : {tool, instrument}||\u2205 NP : \u22a5 To implement described process within ASPCCGTK approach, we first manually specify a dictionary that contains FRAMENET information sufficient for annotating leaf nodes stemming from the words in an input sentence.", "labels": [], "entities": []}, {"text": "We then use logic rules to (a) define annotations for non-leaf nodes of parse trees and (b) restrict the produced parse trees only to these that are semantically coherent.", "labels": [], "entities": []}, {"text": "On the sentences (1) and (3), the ASPCCGTK parser implementing this approach is capable to enumerate only and all semantically coherent parses that correspond to syntactic structures expected for the sentences.", "labels": [], "entities": [{"text": "ASPCCGTK parser", "start_pos": 34, "end_pos": 49, "type": "TASK", "confidence": 0.7006577253341675}]}], "datasetContent": [], "tableCaptions": []}