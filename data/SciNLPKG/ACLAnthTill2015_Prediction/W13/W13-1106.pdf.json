{"title": [{"text": "Sentiment Analysis of Political Tweets: Towards an Accurate Classifier", "labels": [], "entities": [{"text": "Sentiment Analysis of Political Tweets", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.9503903746604919}]}], "abstractContent": [{"text": "We perform a series of 3-class sentiment classification experiments on a set of 2,624 tweets produced during the run-up to the Irish General Elections in February 2011.", "labels": [], "entities": [{"text": "3-class sentiment classification", "start_pos": 23, "end_pos": 55, "type": "TASK", "confidence": 0.6628730396429697}, {"text": "Irish General Elections in February 2011", "start_pos": 127, "end_pos": 167, "type": "DATASET", "confidence": 0.9528322716554006}]}, {"text": "Even though tweets that have been labelled as sarcastic have been omitted from this set, it still represents a difficult test set and the highest accuracy we achieve is 61.6% using supervised learning and a feature set consisting of subjectivity-lexicon-based scores, Twitter-specific features and the top 1,000 most dis-criminative words.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 146, "end_pos": 154, "type": "METRIC", "confidence": 0.998803973197937}]}, {"text": "This is superior to various naive unsupervised approaches which use sub-jectivity lexicons to compute an overall sentiment score fora <tweet,political party> pair.", "labels": [], "entities": []}], "introductionContent": [{"text": "Supervised machine learning using minimal feature engineering has been shown to work well in binary positive/negative sentiment classification tasks on well-behaved datasets such as movie reviews).", "labels": [], "entities": [{"text": "binary positive/negative sentiment classification", "start_pos": 93, "end_pos": 142, "type": "TASK", "confidence": 0.6789834300676981}]}, {"text": "In this paper we describe sentiment analysis experiments in a more complicated setup: the task is three-class positive/negative/neutral classification, the sentiment being classified is not at the general document level but rather directed towards a topic, the documents are tweets, and the topic is politics, specifically the Irish General Election of February 2011.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.870807558298111}, {"text": "Irish General Election of February 2011", "start_pos": 327, "end_pos": 366, "type": "DATASET", "confidence": 0.968062549829483}]}, {"text": "* Akshat Bakliwal and Jennifer van der Puil carried out their part of this work while employed as summer interns at the Centre for Next Generation Localisation(CNGL) in the School of Computing, DCU.", "labels": [], "entities": [{"text": "DCU", "start_pos": 194, "end_pos": 197, "type": "DATASET", "confidence": 0.9824944138526917}]}, {"text": "The dataset used in the experiments contains tweets which were collected in the run up to the election and which were subsequently doubly annotated as positive, negative or neutral towards a particular political party or party leader.", "labels": [], "entities": []}, {"text": "The annotators also marked a tweet as sarcastic if its literal sentiment was different to its actual sentiment.", "labels": [], "entities": []}, {"text": "Before exploring the thorny issue of sentiment classification in the face of sarcasm, we simplify the problem by first trying to establish some sentiment analysis baselines for those tweets which were not deemed to be sarcastic.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 37, "end_pos": 61, "type": "TASK", "confidence": 0.9080473482608795}]}, {"text": "We first explore a naive approach in which a subjectivity lexicon is used as the primary source of information in determining whether sentiment towards apolitical party or party leader is positive, negative or neutral.", "labels": [], "entities": []}, {"text": "The best version of this method achieves an accuracy of 58.9, an absolute improvement of 4.9 points over the majority baseline (54%) in which all tweets are classified as neutral.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9993958473205566}]}, {"text": "When these lexicon scores are combined with bag-of-word features and some Twitter-specific features in a supervised machine learning setup, this accuracy increases to 61.6%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 145, "end_pos": 153, "type": "METRIC", "confidence": 0.9991220831871033}]}, {"text": "The paper is organised as follows: related work is described in Section 2, followed by a brief discussion of the 2011 Irish General Election in Section 3, a description of the dataset in Section 4 and a description of the natural language processing tools and resources employed in Section 5.", "labels": [], "entities": [{"text": "Irish General Election", "start_pos": 118, "end_pos": 140, "type": "DATASET", "confidence": 0.9377802411715189}]}, {"text": "In Section 6, the unsupervised lexicon-based approach is presented and its limitations discussed.", "labels": [], "entities": []}, {"text": "Section 7 describes the machine-learning-based experiments and Section 8 concludes and provides hints towards fu-ture work with this new dataset.", "labels": [], "entities": []}], "datasetContent": [{"text": "We compiled a corpus of tweets using the Twitter search API between 20th and the 25th of January 2011 (one month before the election).", "labels": [], "entities": []}, {"text": "We selected the main political entities (the five biggest political parties -Fianna F\u00e1il, Fine Gael, Labour, Sinn F\u00e9in and the Greens -and their leaders) and perform query-based search to collect the tweets relating to these entities.", "labels": [], "entities": []}, {"text": "The resulting dataset contains 7,916 tweets of which 4,710 are retweets or duplicates, leaving a total of 3,206 tweets.", "labels": [], "entities": []}, {"text": "The tweets were annotated by two Irish annotators with a knowledge of the Irish political landscape.", "labels": [], "entities": []}, {"text": "Disagreements between the two annotators were studied and resolved by a third annotator.", "labels": [], "entities": []}, {"text": "The annotators were asked to identify the sentiment associated with the topic (or entity) of the tweet.", "labels": [], "entities": []}, {"text": "Annotation was performed using the following 6 labels: \u2022 pos: Tweets which carry positive sentiment towards the topic \u2022 neg: Tweets which carry negative sentiment towards the topic \u2022 mix: Tweets which carry both positive and negative sentiment towards the topic \u2022 neu: Tweets which do not carry any sentiment towards the topic \u2022 nen: Tweets which were written in languages other than English.", "labels": [], "entities": []}, {"text": "\u2022 non: Tweets which do not have any mention or relation to the topic.", "labels": [], "entities": []}, {"text": "In addition to the above six classes, annotators were asked to flag whether a tweet was sarcastic.", "labels": [], "entities": []}, {"text": "The dataset which we use for the experiments described in this paper contains only those tweets that have been labelled as either positive, negative or neutral, i.e. non-relevant, mixed-sentiment and non-English tweets are discarded.", "labels": [], "entities": []}, {"text": "We also simplify our task by omitting those tweets which have been flagged as sarcastic by one or both of the annotators, leaving a set of 2,624 tweets with a class distribution as shown in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: 3-class classification using the naive lexicon-based approach. The majority baseline is 54.03%.", "labels": [], "entities": []}, {"text": " Table 6: Results of 3-Class Classification using Super- vised Machine Learning", "labels": [], "entities": [{"text": "3-Class Classification", "start_pos": 21, "end_pos": 43, "type": "TASK", "confidence": 0.6518354713916779}]}]}