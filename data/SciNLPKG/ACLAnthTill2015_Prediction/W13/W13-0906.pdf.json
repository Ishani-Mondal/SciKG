{"title": [{"text": "Cross-Lingual Metaphor Detection Using Common Semantic Features", "labels": [], "entities": [{"text": "Cross-Lingual Metaphor Detection", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.749224841594696}]}], "abstractContent": [{"text": "We present the CSF-Common Semantic Features method for metaphor detection.", "labels": [], "entities": [{"text": "metaphor detection", "start_pos": 55, "end_pos": 73, "type": "TASK", "confidence": 0.9564218521118164}]}, {"text": "This method has two distinguishing characteristics: it is cross-lingual and it does not rely on the availability of extensive manually-compiled lexical resources in target languages other than English.", "labels": [], "entities": []}, {"text": "A metaphor detecting classifier is trained on English samples and then applied to the target language.", "labels": [], "entities": [{"text": "metaphor detecting classifier", "start_pos": 2, "end_pos": 31, "type": "TASK", "confidence": 0.781166672706604}]}, {"text": "The method includes procedures for obtaining semantic features from sentences in the target language.", "labels": [], "entities": []}, {"text": "Our experiments with Russian and English sentences show comparable results, supporting our hypothesis that a CSF-based classifier can be applied across languages.", "labels": [], "entities": []}, {"text": "We obtain state-of-the-art performance in both languages.", "labels": [], "entities": []}], "introductionContent": [{"text": "Metaphors are very powerful pervasive communication tools that help deliver complex concepts and ideas simply and effectively.", "labels": [], "entities": []}, {"text": "Automatic detection and interpretation of metaphors is critical for many practical language processing tasks such as information extraction, summarization, opinion mining, and translation.", "labels": [], "entities": [{"text": "Automatic detection and interpretation of metaphors", "start_pos": 0, "end_pos": 51, "type": "TASK", "confidence": 0.8314855595429739}, {"text": "information extraction", "start_pos": 117, "end_pos": 139, "type": "TASK", "confidence": 0.8318683207035065}, {"text": "summarization", "start_pos": 141, "end_pos": 154, "type": "TASK", "confidence": 0.9817725419998169}, {"text": "opinion mining", "start_pos": 156, "end_pos": 170, "type": "TASK", "confidence": 0.7866248786449432}, {"text": "translation", "start_pos": 176, "end_pos": 187, "type": "TASK", "confidence": 0.9701966047286987}]}, {"text": "In this paper, we focus on the automatic metaphor detection task.", "labels": [], "entities": [{"text": "automatic metaphor detection task", "start_pos": 31, "end_pos": 64, "type": "TASK", "confidence": 0.7073258981108665}]}, {"text": "This problem gained much attention in natural language processing research mostly using the detection principles articulated by the Pragglejaz.", "labels": [], "entities": []}, {"text": "According to these principles, a lexical unit (a word or expression) is used metaphorically if its contextual meaning is different from its \"basic contemporary\" meaning.", "labels": [], "entities": []}, {"text": "To apply this method, we need to be able to determine the basic meaning of a lexical unit and then test if this interpretation makes sense in the current context.", "labels": [], "entities": []}, {"text": "Several approaches to automatic detection of metaphors have been proposed;), all of which rely on the availability of extensive manually crafted lexical resources such as WordNet, VerbNet, FrameNet, TreeBank, etc.", "labels": [], "entities": [{"text": "automatic detection of metaphors", "start_pos": 22, "end_pos": 54, "type": "TASK", "confidence": 0.8113481104373932}, {"text": "WordNet", "start_pos": 171, "end_pos": 178, "type": "DATASET", "confidence": 0.964813768863678}]}, {"text": "Unfortunately, such resources exist only fora few resource-rich languages such as English.", "labels": [], "entities": []}, {"text": "For most other languages, such resources either do not exist or are of a low quality.", "labels": [], "entities": []}, {"text": "To our knowledge this work is the first empirical study of cross-lingual metaphor detection.", "labels": [], "entities": [{"text": "cross-lingual metaphor detection", "start_pos": 59, "end_pos": 91, "type": "TASK", "confidence": 0.863021989663442}]}, {"text": "We present the Common Semantic Features (CSF) approach to metaphor detection in languages without extensive lexical resources.", "labels": [], "entities": [{"text": "metaphor detection", "start_pos": 58, "end_pos": 76, "type": "TASK", "confidence": 0.9300598502159119}]}, {"text": "Ina target language it requires only a dependency parser and a targetEnglish dictionary.", "labels": [], "entities": []}, {"text": "We classify sentences into literal and metaphoric using automatically extracted coarse-grained semantic properties of words such as their propensity to refer to abstract versus concrete concepts, animate entities, artifacts, body parts, etc.", "labels": [], "entities": []}, {"text": "These properties serve as features for the key relations in a sentence, which include Subject-VerbObject (SVO) and Adjective-Noun (AN).", "labels": [], "entities": []}, {"text": "A classifier trained on English sentences obtains a 0.78 F -score.", "labels": [], "entities": [{"text": "F -score", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9917125304539999}]}, {"text": "The same classifier, trained solely on English sentences, achieves a similar level of performance on sentences from other languages such as Russian; this is the central contribution of this work.", "labels": [], "entities": []}, {"text": "An additional important contribution is that in Russian we obtain the necessary semantic features without recourse to sophisticated non-English lexical resources.", "labels": [], "entities": []}, {"text": "In this paper, we focus on the sentences where verbs are used metaphorically, leaving Adjective-Noun relations for future work.", "labels": [], "entities": []}, {"text": "Based on our examination of over 500 metaphorical sentences in English and Russian collected from general news articles, we estimate that verb-based metaphors constitute about 40-50% of all metaphors.", "labels": [], "entities": []}, {"text": "We present and discuss our experiments with three sets of features: (1) features corresponding to the lexicographer file names defined in WordNet 3.0, (2) features based on abstractness vs. concreteness computed using Vector Space Models (VSM), and (3) features based on the types of named entities, if present.", "labels": [], "entities": []}, {"text": "Our main target language in these experiments has been Russian, but we also present preliminary experiments with Spanish.", "labels": [], "entities": []}, {"text": "The paper is organized as follows: Section 2 contains an overview of the resources we use; Section 3 discusses the methodology; Section 4 presents the experiments; in Section 5, we discuss related work, and we conclude with suggestions for future research in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use the following English lexical resources to train our model: TroFi Example Base 1 (Birke and Sarkar, 2007) of 3,737 English sentences from the Wall Street Journal.", "labels": [], "entities": [{"text": "TroFi Example Base 1", "start_pos": 67, "end_pos": 87, "type": "METRIC", "confidence": 0.8948014378547668}, {"text": "Wall Street Journal", "start_pos": 149, "end_pos": 168, "type": "DATASET", "confidence": 0.9105711579322815}]}, {"text": "Each sentence contains one of the seed verbs and is marked L by human annotators if the verb is used in a literal sense.", "labels": [], "entities": []}, {"text": "Otherwise, the sentence is marked N (non-literal).", "labels": [], "entities": []}, {"text": "The model was evaluated on 25 target verbs with manually annotated 1 to 115 sentences per verb.", "labels": [], "entities": []}, {"text": "TroFi does not define the basic meanings of these verbs, but provides examples of literal and metaphoric sentences which we use to train and evaluate our metaphor identification method.", "labels": [], "entities": [{"text": "TroFi", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8914623260498047}]}, {"text": "WordNet) is an English lexical database where each entry contains a set of synonyms (a synset) all representing the same concept.", "labels": [], "entities": [{"text": "WordNet)", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9415783584117889}]}, {"text": "This database is compiled from a set of 1 http://www.cs.sfu.ca/ anoop/students/jbirke/ 45 lexicographer files 2 such as \"noun.body\" or \"verb.cognition\" identified by a number from 0 to 44, called lexicographer file number (henceforth lexF N ).", "labels": [], "entities": []}, {"text": "The lexF N of each synset is contained in the database.", "labels": [], "entities": []}, {"text": "We use lexF N s as coarse-grain semantic features of nouns and verbs.", "labels": [], "entities": []}, {"text": "MRC Psycholinguistic Database 3 is a dictionary containing 150,837 words with up to 26 linguistic and psycholinguistic attributes rated by human subjects in psycholinguistic experiments.", "labels": [], "entities": [{"text": "MRC Psycholinguistic Database 3", "start_pos": 0, "end_pos": 31, "type": "DATASET", "confidence": 0.9345596730709076}]}, {"text": "It includes 4,295 words rated with degrees of abstractness; the ratings range from 158 (highly abstract) to 670 (highly concrete).", "labels": [], "entities": []}, {"text": "We use these words as a seed when we calculate the values of abstractness and concreteness features for nouns and verbs in our training and test sets.", "labels": [], "entities": []}, {"text": "Word Representations via Global Context is a collection of 100,232 words and their vector representations.", "labels": [], "entities": [{"text": "Word Representations via Global Context", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.7736077725887298}]}, {"text": "These representations were extracted from a statistical model embedding both local and global contexts of words (, intended to capture better the semantics of words.", "labels": [], "entities": []}, {"text": "We use these vectors to calculate the values of abstractness and concreteness features of a word.", "labels": [], "entities": []}, {"text": "We train two classifiers: the first to calculate the degree of abstractness of a given word and the second to classify an SVO relation as metaphoric or literal.", "labels": [], "entities": []}, {"text": "Both are logistic regression classifiers trained with the creg regression modeling framework.", "labels": [], "entities": []}, {"text": "To minimize the number of free parameters in our model we use 1 regularization.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: 10-fold cross validation results of the  metaphor classifier.", "labels": [], "entities": []}, {"text": " Table 2: Evaluation of the metaphor classifier on  the test set of 50 literal and 48 metaphoric English  sentences from news articles.", "labels": [], "entities": []}, {"text": " Table 3: Evaluation of the metaphor classifier on  the test set of 62 literal and 78 metaphoric Russian  sentences from news articles.", "labels": [], "entities": []}]}