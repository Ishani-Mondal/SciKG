{"title": [{"text": "The Impact of Selectional Preference Agreement on Semantic Relational Similarity", "labels": [], "entities": [{"text": "Selectional Preference", "start_pos": 14, "end_pos": 36, "type": "TASK", "confidence": 0.9237065315246582}, {"text": "Semantic Relational Similarity", "start_pos": 50, "end_pos": 80, "type": "TASK", "confidence": 0.7960434158643087}]}], "abstractContent": [{"text": "Relational similarity is essential to analogical reasoning.", "labels": [], "entities": [{"text": "Relational similarity", "start_pos": 0, "end_pos": 21, "type": "METRIC", "confidence": 0.8083740472793579}, {"text": "analogical reasoning", "start_pos": 38, "end_pos": 58, "type": "TASK", "confidence": 0.9179005324840546}]}, {"text": "Automatically determining the degree to which a pair of words belongs to a semantic relation (relational similarity) is greatly improved by considering the selectional preferences of the relation.", "labels": [], "entities": []}, {"text": "To determine selectional preferences, we induced semantic classes through a Latent Dirichlet Allocation (LDA) method that operates on dependency parse contexts of single words.", "labels": [], "entities": [{"text": "Latent Dirichlet Allocation (LDA", "start_pos": 76, "end_pos": 108, "type": "METRIC", "confidence": 0.8191751837730408}, {"text": "dependency parse contexts of single words", "start_pos": 134, "end_pos": 175, "type": "TASK", "confidence": 0.8300705353418986}]}, {"text": "When assigning relational similarities to pairs of words, if the agreement of selectional preferences is considered alone, a correlation of 0.334 is obtained against the manual ranking outperforming the previously best reported score of 0.229.", "labels": [], "entities": []}], "introductionContent": [{"text": "In natural language, words participate often in a variety of semantic relations.", "labels": [], "entities": []}, {"text": "Both linguists and psychology researchers have been interested in categorizing semantic relations and to understand their usage in language and cognition.", "labels": [], "entities": []}, {"text": "One particular interesting usage of semantic relations is provided by analogical reasoning.", "labels": [], "entities": []}, {"text": "As reported by and, whenever anew situation arises, humans tend to search for an analogous situation from their past experience.", "labels": [], "entities": []}, {"text": "Analogical reasoning relies on relational similarity, as reported by and.", "labels": [], "entities": [{"text": "Analogical reasoning", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8652150332927704}]}, {"text": "In analogical reasoning, the degree of relational similarity is an estimation of the likelihood of applicability of the knowledge transfer (from past to present).", "labels": [], "entities": [{"text": "analogical reasoning", "start_pos": 3, "end_pos": 23, "type": "TASK", "confidence": 0.8802379071712494}]}, {"text": "Thus, as postulated in the recent, the automatic analysis of relational similarity may have practical benefits of indicating the appropriateness of an analogy.", "labels": [], "entities": []}, {"text": "Relational similarity, as reported in, is one of the forms of similarity, the other one being provided by attributional similarity.", "labels": [], "entities": [{"text": "Relational similarity", "start_pos": 0, "end_pos": 21, "type": "METRIC", "confidence": 0.9566315710544586}]}, {"text": "Relational similarity evaluates the correspondence between relations (), while attributional similarity evaluates the correspondence between attributes.", "labels": [], "entities": []}, {"text": "As stated by Turney: \"When two words have a high degree of attributional similarity, we call them synonyms.", "labels": [], "entities": []}, {"text": "When two word pairs have a high degree of relational similarity, we say they are analogous.\"", "labels": [], "entities": []}, {"text": "We claim that there is a special property that arguments of relations need to share.", "labels": [], "entities": []}, {"text": "The arguments of relations are words which are predications of binary facts, properties, actions, etc.", "labels": [], "entities": []}, {"text": "As such, we are aware from the work of that words which appear as arguments of a predicate define the selectional preferences of the predicate.", "labels": [], "entities": []}, {"text": "Moreover, have extended the notion of predicate selectional preferences to \"relational selectional preferences\" of binary relations.", "labels": [], "entities": []}, {"text": "For a binary relation r(x, y), the semantic classes C(x) which can be instantiated for the argument x as well as C(y), the semantic classes which can be instantiated for the argument y constitute the relational selectional preferences of the binary relation.", "labels": [], "entities": []}, {"text": "Thus we believe and show in this paper that semantic relations have selectional preferences and that word pairs x:y are more similar to a relation when those words are more admissible under the relational selectional preferences.", "labels": [], "entities": []}, {"text": "Consider the semantic relation REFERENCE-Expression, with prototypical word pairs smile:friendliness, lamentation:grief, and hug:affection.", "labels": [], "entities": [{"text": "REFERENCE-Expression", "start_pos": 31, "end_pos": 51, "type": "METRIC", "confidence": 0.9133403301239014}]}, {"text": "In these pairs, the first word can be seen as a physical expression of the emotional state represented by the second word.", "labels": [], "entities": []}, {"text": "Word pairs which are prototypical of the relation should be assigned a high degree of membership for the REFERENCE-Expression relation, while word pairs such as discourse:relationship and anger:slap should not, either because the word pair expresses a different relation, or because the pair is in the wrong order (slap is an expression of anger, not the other way around).", "labels": [], "entities": [{"text": "REFERENCE-Expression", "start_pos": 105, "end_pos": 125, "type": "METRIC", "confidence": 0.9688466787338257}]}, {"text": "shows the ten top-level categories of relations we consider, which is further divided into 79 relations covering multiple parts of speech (adjective, noun, adverb, and verb).", "labels": [], "entities": []}, {"text": "We show that a model which independently considers the semantic classes of each word in a word pair is effective at assigning degrees of membership (relational similarity).", "labels": [], "entities": []}, {"text": "For instance, knowing that the relation REFERENCE-Expression selects for emotional states in the first argument (e.g., grief, friendliness, affection) and expressions of emotion in the second argument (e.g., smile, hug, lamentation) helps in determining word pair candidates which don't adhere to those classes.", "labels": [], "entities": [{"text": "REFERENCE-Expression", "start_pos": 40, "end_pos": 60, "type": "METRIC", "confidence": 0.9745509624481201}]}, {"text": "Clearly word pairs whose arguments do not fit these preferences should be given a lower degree of relatedness to the relation.", "labels": [], "entities": []}, {"text": "We describe a method for inducing semantic classes for use as selectional preferences and a method for determining the distributions over argument classes fora relation.", "labels": [], "entities": []}, {"text": "While selectional preferences are not the only phenomena responsible for assigning degrees of membership for word pairs to semantic relations, we choose to model it alone in this paper to examine its importance.", "labels": [], "entities": []}, {"text": "We show that modeling selectional preference alone produces results which are better than the previously reported results for measuring relational similarity.", "labels": [], "entities": []}, {"text": "The rest of this paper is structured as follows: Section 2 gives some perspective on previous work, Section 3 describes how we used an LDA model to induce semantic classes.", "labels": [], "entities": []}, {"text": "Section 4 describes the dataset we use for measuring relational similarity.", "labels": [], "entities": []}, {"text": "Section 5 describes how the induced semantic classes are used to model the selectional preferences of semantic relations.", "labels": [], "entities": []}, {"text": "Section 5 describes how we determine the extent to which a word pair matches a relation's selectional preferences.", "labels": [], "entities": []}, {"text": "Section 6 gives our experimental setup and the results of our evaluation.", "labels": [], "entities": []}, {"text": "Section 7 analyzes the types of semantic classes that were automatically induced and Section 8 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "For training our LDA model we used a corpus consisting of the 8 million documents from English Gigaword (LDC2009T13)) and the 4 million documents from the 2011-12-01 dump of Wikipedia 1 . The dependency parses were obtained by using the Stanford dependency parser 2.", "labels": [], "entities": [{"text": "English Gigaword (LDC2009T13", "start_pos": 87, "end_pos": 115, "type": "DATASET", "confidence": 0.9346199482679367}]}, {"text": "The textual content from the Wikipedia XML files was extracted using WP2TXT (http://wp2txt.rubyforge.org/).", "labels": [], "entities": [{"text": "Wikipedia XML files", "start_pos": 29, "end_pos": 48, "type": "DATASET", "confidence": 0.9044216871261597}, {"text": "WP2TXT", "start_pos": 69, "end_pos": 75, "type": "DATASET", "confidence": 0.9038193821907043}]}, {"text": "Due to the large size of this corpus we used a parallel implementation of LDA known as PLDA () across eight quad-core machines.", "labels": [], "entities": []}, {"text": "The parameters for the LDA were the suggested defaults of \u03b1 = 0.1 and \u03b2 = 0.01.", "labels": [], "entities": []}, {"text": "We arbitrarily chose 50 topics, but this is clearly a parameter that requires further investigation.", "labels": [], "entities": []}, {"text": "Additionally, our input to the LDA only consisted of 3,357 pseudo-documents, corresponding to all of the unique words in all of the word pairs that we were interested in ranking.", "labels": [], "entities": []}, {"text": "While this contains many commonly used words in English, many other words are not covered and the data would have to be expanded for use in other tasks.", "labels": [], "entities": []}, {"text": "We used the official testing set from the SemEval 2012 Task 2 (Jurgens et al., 2012), which consisted of 69 relations (another ten were released for training but we do not make use of them).", "labels": [], "entities": [{"text": "official testing set from the SemEval 2012 Task 2 (Jurgens et al., 2012)", "start_pos": 12, "end_pos": 84, "type": "DATASET", "confidence": 0.7701576165854931}]}, {"text": "The relations had an average of 40 word pairs, ranging from 25 to 45.", "labels": [], "entities": []}, {"text": "We evaluate the performance of the relational similarity model using a Spearman correlation score between the model's word pair ranking and the ranking produced by the annotation effort.", "labels": [], "entities": []}, {"text": "This is the same evaluation metric used during the official SemEval 2012 Task 2 (Jurgens et al., 2012).", "labels": [], "entities": [{"text": "official SemEval 2012 Task 2 (Jurgens et al., 2012)", "start_pos": 51, "end_pos": 102, "type": "DATASET", "confidence": 0.6622751628359159}]}, {"text": "shows the results of our approach under several common similarity measures.", "labels": [], "entities": []}, {"text": "We expected the measures designed for probability distributions (Jensen Shannon/Hellinger) to perform best, however our evaluation showed that vector space metrics (cosine/Tanimoto) performed slightly better.", "labels": [], "entities": []}, {"text": "During the official evaluation, the best performing system achieved a correlation of 0.229.", "labels": [], "entities": [{"text": "correlation", "start_pos": 70, "end_pos": 81, "type": "METRIC", "confidence": 0.9886898398399353}]}, {"text": "These results also show the high importance of selectional preference agreement when measuring the degree to which a pair of words belongs to a semantic relation.", "labels": [], "entities": []}, {"text": "This model outperforms reported results, without taking into consideration the actual relation between the two arguments of a word pair.", "labels": [], "entities": []}, {"text": "Future work will involve combining the selectional preferences approach with a approach that also models the dependence between the two arguments.", "labels": [], "entities": []}, {"text": "We first present a manual inspection of the semantic class space that was induced by the LDA, followed by a more analytical evaluation.", "labels": [], "entities": []}, {"text": "illustrates the top dependency contexts associated with four semantic classes that were prominent for relation REFERENCE:Expression in. shows the top words associated with the same four semantic classes.", "labels": [], "entities": [{"text": "REFERENCE", "start_pos": 111, "end_pos": 120, "type": "METRIC", "confidence": 0.9289939403533936}]}, {"text": "All of the top 16 words for class 44 are categorized as abstract entities in WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 77, "end_pos": 84, "type": "DATASET", "confidence": 0.9685090184211731}]}, {"text": "Many of them can be further categorized as states (independence, love, freedom, confidence, security).", "labels": [], "entities": []}, {"text": "We can see from the top dependency contexts of class 44 listed in the types of contexts which indicate a state: \u2190prep of lack, \u2190prep of level, \u2190prep of sense.", "labels": [], "entities": []}, {"text": "From we can see that class 44 is the predominant class for several emotional states participating in the first argument of a REFERENCE:Expression relation, so it is reassuring to see that this class consists of states.", "labels": [], "entities": [{"text": "REFERENCE", "start_pos": 125, "end_pos": 134, "type": "METRIC", "confidence": 0.8762747645378113}]}, {"text": "The words in class 17 seem less related, but have some broad similarities.", "labels": [], "entities": []}, {"text": "For instance, they appear to be countable nouns expressed in the singular form.", "labels": [], "entities": []}, {"text": "When we examine the dependency contexts for class 17 we can understand why this is.", "labels": [], "entities": []}, {"text": "The contexts include \u2192det another, \u2192amod first, \u2192det every, \u2192amod only, etc.", "labels": [], "entities": []}, {"text": "These determiners and adjectives cannot modify mass nouns and the set of top words for the class do appear to fall in the category of countable nouns.: The top dependency contexts for semantic classes 44, 17, 13, and 24.", "labels": [], "entities": []}, {"text": "Some contexts which are common across many semantic classes were omitted.", "labels": [], "entities": []}, {"text": "Semantic class 13 consists largely of actions taken by humans.", "labels": [], "entities": []}, {"text": "These dependencies apply to verbs, and many of them specifically contain pronouns (you, I) reserved primarily for humans.", "labels": [], "entities": []}, {"text": "From class 13 was largest for the \"expression\" words smile, nod, laugh, kiss which obviously are actions usually preformed by humans.", "labels": [], "entities": []}, {"text": "Semantic class 24 appears to contain words which are often described using colors or shades (e.g., dark, light).", "labels": [], "entities": []}, {"text": "Examples for colors would include white flag, white suit, black smoke, while examples for shades would include dark hair and dark shirt, but also colors themselves as in dark green and light blue.", "labels": [], "entities": []}, {"text": "Overall, it appears that using the LDA model on dependency contexts performed well at clustering words into semantic classes, picking upon common-place but subtle linguistic phenomena such as countable nouns, and whether a verb tends to have a person as a subject.", "labels": [], "entities": [{"text": "clustering words into semantic classes", "start_pos": 86, "end_pos": 124, "type": "TASK", "confidence": 0.8548487305641175}]}, {"text": "We now present a more quantitative assessment of the induced semantic class space.", "labels": [], "entities": []}, {"text": "We follow the evaluation proposed by.", "labels": [], "entities": []}, {"text": "They selected the ten categories of objects shown in the first column of, along with a prototypical member word for each category.", "labels": [], "entities": []}, {"text": "Using the prototype word as a seed, its twenty nearest neighbors are determined.", "labels": [], "entities": []}, {"text": "The most appropriate distance metric for our approach is to use the Tanimoto coefficient between the semantic classes distributions of two words.", "labels": [], "entities": []}, {"text": "The lists of nearest neighbors produced using our induced class distributions are illustrated in.", "labels": [], "entities": []}, {"text": "Neighbors which are not subsumed by the WordNet synset represented in the first column have been italicized.", "labels": [], "entities": [{"text": "WordNet synset", "start_pos": 40, "end_pos": 54, "type": "DATASET", "confidence": 0.9476220607757568}]}, {"text": "Our method achieves a precision of only 59.4% on this evaluation.", "labels": [], "entities": [{"text": "precision", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.9996135830879211}]}, {"text": "The results are considerably below previous approaches which have achieved 82% () and 90.5% (), however our method has several disadvantages in this comparison.", "labels": [], "entities": []}, {"text": "Firstly, we have only generated semantic class vectors for the 3,357 words which occurred in the word pairs in the relation dataset which limits our recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 149, "end_pos": 155, "type": "METRIC", "confidence": 0.9912421703338623}]}, {"text": "This particularly affects the retrieval of \"easy\" but rare neighbors of a word such as fortepiano from the seed piano.", "labels": [], "entities": []}, {"text": "This also caused us to choose different seed words for the categories crimes, body parts, and academic subjects because the seeds used in prior literature did not academic subjects philosophy geography logic chemistry religion composition psychology anatomy algebra architecture voice vision geometry genealogy image discourse art memory signature history conception foodstuffs cake egg salad apple cane pie soup blender carrot leaf omelette cigarette pizza pot polymer dish beer oven glass dessert: The nearest neighbors for nine seed words.", "labels": [], "entities": [{"text": "philosophy geography logic chemistry religion composition psychology anatomy algebra architecture voice vision geometry genealogy image discourse art memory signature history conception foodstuffs cake egg salad apple cane pie soup blender carrot leaf omelette cigarette pizza", "start_pos": 181, "end_pos": 457, "type": "TASK", "confidence": 0.9109107954161507}]}, {"text": "Italics mark words which do not match the class of the seed word.", "labels": [], "entities": []}, {"text": "appear in the word pair corpus.", "labels": [], "entities": []}, {"text": "Secondly, the previous approaches utilizing this evaluation metric have limited their class induction space to only nouns.", "labels": [], "entities": []}, {"text": "Therefore, the candidate neighbors under the previous approaches are restricted to nouns, whereas our approach conflated words with the same surface form, but different parts of speech.", "labels": [], "entities": []}, {"text": "The effects of this are quite clear for the tools category.", "labels": [], "entities": []}, {"text": "Certain tool words which are also used as verbs are absent from our top neighbors such as rake, plow, and shovel, however they are top neighbors of each other.", "labels": [], "entities": []}, {"text": "Both of these limitations can be alleviated, but are not addressed in this paper.", "labels": [], "entities": []}, {"text": "We believe the results from show that our semantic space based on an LDA model and Tanimoto coefficient do correspond to a semantic class space.", "labels": [], "entities": []}, {"text": "While alternative semantic class induction techniques may improve our relational similarity results, this approach does show the merit in modeling the relational selectional preferences by semantic class membership of the relation arguments.", "labels": [], "entities": [{"text": "semantic class induction", "start_pos": 18, "end_pos": 42, "type": "TASK", "confidence": 0.674588143825531}]}], "tableCaptions": [{"text": " Table 2: A portion of the semantic class distribution vectors for several words participating in word pairs  belonging to the REFERENCE:Expression relation.", "labels": [], "entities": [{"text": "REFERENCE", "start_pos": 127, "end_pos": 136, "type": "METRIC", "confidence": 0.88136887550354}]}, {"text": " Table 3: Spearman's correlation scores between rankings produced by our approach over different  similarity metrics and the gold rankings made available for SemEval 2012 Task 2", "labels": [], "entities": [{"text": "SemEval 2012 Task", "start_pos": 158, "end_pos": 175, "type": "TASK", "confidence": 0.8896205822626749}]}]}