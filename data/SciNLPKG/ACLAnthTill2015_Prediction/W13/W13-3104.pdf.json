{"title": [], "abstractContent": [{"text": "The 2013 Association for Computational Linguistics MultiLing Pilot posed a task to measure the performance of multilingual , single-document, summarization systems using a dataset derived from many Wikipedias.", "labels": [], "entities": []}, {"text": "The objective of the pilot was to assess automatic summarization of multilingual text documents outside the news domain and the potential of using Wikipedia articles for such research.", "labels": [], "entities": [{"text": "summarization of multilingual text documents", "start_pos": 51, "end_pos": 95, "type": "TASK", "confidence": 0.8453035235404969}]}, {"text": "This report describes the pilot task, the dataset, the methods used to evaluate the submitted summaries, and the overall performance of each participant's system.", "labels": [], "entities": []}], "introductionContent": [{"text": "Document summarization is an active subject of research and development.", "labels": [], "entities": [{"text": "Document summarization", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9197730123996735}]}, {"text": "The ACM Digital Library has about 806 reports on the subject published since 1993, with over half of them appearing in the last five years.", "labels": [], "entities": [{"text": "ACM Digital Library", "start_pos": 4, "end_pos": 23, "type": "DATASET", "confidence": 0.9605569442113241}]}, {"text": "While the impetus for much of this research is the annual Text Analysis Conference (TAC) workshop on document summarization, there is a growing demand in the consumer market for news summarization applications being met by tablet and smart-phone applications such as Clipped 1 , Summoner 2 , TLDR 3 , and Yahoo News.", "labels": [], "entities": [{"text": "Text Analysis Conference (TAC) workshop", "start_pos": 58, "end_pos": 97, "type": "TASK", "confidence": 0.837783830506461}, {"text": "document summarization", "start_pos": 101, "end_pos": 123, "type": "TASK", "confidence": 0.6552817225456238}, {"text": "news summarization", "start_pos": 178, "end_pos": 196, "type": "TASK", "confidence": 0.7205142378807068}]}, {"text": "Yahoo and Google even acquired two companies developing such applications, Summly and respectively, earlier this year.", "labels": [], "entities": []}, {"text": "While summarization technology for news sources is coming to fruition, the performance of such technology on non-English documents outside the news domain has not been throughly assessed and may need further research.", "labels": [], "entities": [{"text": "summarization", "start_pos": 6, "end_pos": 19, "type": "TASK", "confidence": 0.9616044163703918}]}, {"text": "Since the datasets used by 1 http://goo.gl/dFKD9 2 http://goo.gl/0QFaZ 3 http://goo.gl/qEgCs the TAC summarization workshops have predominately been English news articles, with some exceptions (), the objective of the 2013 ACL MultiLing Pilot was to assess the performance of automatic multilingual singledocument summarization systems on non-English text outside the news domain and to determine the potential of using Wikipedia articles for such research.", "labels": [], "entities": [{"text": "TAC summarization", "start_pos": 97, "end_pos": 114, "type": "TASK", "confidence": 0.8020801544189453}]}, {"text": "This report starts with a description of the task and dataset, the methods used to evaluate the submitted summaries, the performance of each participating system, and concludes with an assessment of the pilot and potential future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "The objective of each participant system of the pilot was simple: compute a summary for each document in at least two of the datasets languages.", "labels": [], "entities": []}, {"text": "No restrictions were placed on the languages that could be chosen nor was any target summary size specified.", "labels": [], "entities": []}, {"text": "The dataset was derived from a corpus created in 2010 to measure the performance of the CLASSY () summarization algorithm on non-English documents outside the news domain.", "labels": [], "entities": []}, {"text": "At the time such a corpus did not exist so one was created from the Wikipedias.", "labels": [], "entities": []}, {"text": "To date there are Wikipedias in 285 languages comprising over 75 million pages.", "labels": [], "entities": []}, {"text": "Some of the Wikipedias maintain a list of Feature Articles, which are articles reviewed and voted upon by editors as the best that fulfill Wikipedia's requirements inaccuracy, neutrality, completeness, and style.", "labels": [], "entities": [{"text": "style", "start_pos": 206, "end_pos": 211, "type": "METRIC", "confidence": 0.9524043798446655}]}, {"text": "One such requirement is that the article have a lead section that should . .", "labels": [], "entities": []}, {"text": "be able to standalone as a concise overview.", "labels": [], "entities": []}, {"text": "summarize the most important points . .", "labels": [], "entities": []}, {"text": "material in the lead should roughly reflect its im-portance to the topic . .", "labels": [], "entities": []}, {"text": "So the lead section of a featured article is an excellent summary of it, hence, the featured articles were used to create the corpus.", "labels": [], "entities": []}, {"text": "In 2010 there were 41 Wikipedias with more than nine featured articles.", "labels": [], "entities": []}, {"text": "The Perl module Text::Corpus::Summaries::Wikipedia 5 was developed to automatically create the corpus from the featured articles of those Wikipedias.", "labels": [], "entities": []}, {"text": "The corpus is publicly available and the Perl module can be used to create an updated corpus.", "labels": [], "entities": []}, {"text": "The dataset for the pilot was created from a subset of the 2010 corpus.", "labels": [], "entities": [{"text": "2010 corpus", "start_pos": 59, "end_pos": 70, "type": "DATASET", "confidence": 0.712197557091713}]}, {"text": "This was done to ensure that each language had 30 articles and that the size of each article's body text was sufficiently large.", "labels": [], "entities": []}, {"text": "First, for each article the summary and body were compressed to approximate their information content size.", "labels": [], "entities": []}, {"text": "For example, given a Chinese and English article with the same character length the Chinese article will usually contain more information than an English article and their compressed sizes will approximation their true information content.", "labels": [], "entities": []}, {"text": "Next, if the compressed body size of an article was less than five times its compressed summary size, then the article was discarded.", "labels": [], "entities": []}, {"text": "The factor of five was simply chosen to ensure the body of each article was sufficiently large relative to the summary size.", "labels": [], "entities": []}, {"text": "For each language the median of the ratio of compressed body size to compressed summary size was computed and only the 30 articles closest to the median were included in the dataset.", "labels": [], "entities": []}, {"text": "This filtering reduced the corpus from 12, 819 articles in 41 languages to the dataset containing 1, 200 articles in 40 languages.", "labels": [], "entities": []}, {"text": "For each language in the dataset contains the mean size of the articles, their bodies, and their summaries, in characters.", "labels": [], "entities": []}, {"text": "Four teams submitted the results of six summarization systems.", "labels": [], "entities": [{"text": "summarization", "start_pos": 40, "end_pos": 53, "type": "TASK", "confidence": 0.9613447785377502}]}, {"text": "The teams are denoted by AIS, LAN, MD, and MUS; the MD team submitted three systems.", "labels": [], "entities": [{"text": "MUS", "start_pos": 43, "end_pos": 46, "type": "METRIC", "confidence": 0.957673192024231}]}, {"text": "Throughout this report the systems are denoted by AIS, LAN, MD1, MD2, MD3, and MUS.", "labels": [], "entities": [{"text": "AIS", "start_pos": 50, "end_pos": 53, "type": "METRIC", "confidence": 0.86557537317276}, {"text": "MUS", "start_pos": 79, "end_pos": 82, "type": "METRIC", "confidence": 0.8308750987052917}]}, {"text": "contains the list of languages submitted for each system and the mean size, in characters, of the summaries submitted.", "labels": [], "entities": []}, {"text": "For the evaluation a baseline summary was extracted from the each article in the dataset that is the prefix substring of the article's body text with the same length as the text in the lead section of the article.", "labels": [], "entities": []}, {"text": "For the remainder of this report the lead section of an article is called the human summary.", "labels": [], "entities": []}, {"text": "An oracle summary was also computed for each article by heuristically extracting sentences from its body text to maximize its ROUGE-2 score against the human summary until its size exceeded the human summary, upon which it was truncated.", "labels": [], "entities": [{"text": "ROUGE-2 score", "start_pos": 126, "end_pos": 139, "type": "METRIC", "confidence": 0.9832038879394531}]}, {"text": "Submitted summaries were automatically evaluated against the human summary of each article using ROUGE-1, ROUGE-2 (Lin, 2004) and MeMoG ().", "labels": [], "entities": [{"text": "ROUGE-1", "start_pos": 97, "end_pos": 104, "type": "METRIC", "confidence": 0.8763302564620972}, {"text": "ROUGE-2", "start_pos": 106, "end_pos": 113, "type": "METRIC", "confidence": 0.8807562589645386}, {"text": "MeMoG", "start_pos": 130, "end_pos": 135, "type": "DATASET", "confidence": 0.816709041595459}]}, {"text": "For ROUGE, the languages Chinese, Japanese, Korean, and Thai were tokenized into individual characters.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 4, "end_pos": 9, "type": "TASK", "confidence": 0.45920488238334656}]}, {"text": "For MeMoG the character n-gram size used for each language is listed in, which is the n-gram size that maximized the standard deviation divided by the mean of the n-gram frequency distribution of the language in the dataset.", "labels": [], "entities": []}, {"text": "So the selected n-gram size maximizes the variability of the distribution values relative to their mean.", "labels": [], "entities": []}, {"text": "A shorter n-gram size would inflate the MeMoG scores because of their inherent frequent co-occurrence and conversely a longer size would penalize MeMoG scores due to their infrequent co-occurrence.", "labels": [], "entities": []}, {"text": "Each scoring method was performed twice, first by truncating, if necessary, each system summary to the size of the human summary, which is called HSS-scoring.", "labels": [], "entities": [{"text": "HSS-scoring", "start_pos": 146, "end_pos": 157, "type": "DATASET", "confidence": 0.7829101085662842}]}, {"text": "The second set of scores were computed by truncating all the summaries of an article, including the human summary, to the size of the shortest summary amongst the system and human summaries for the article, which is called SSS-scoring.", "labels": [], "entities": []}, {"text": "For HSS-scoring the system summaries shorter that the human summary are penalized since ROUGE is recall oriented.", "labels": [], "entities": [{"text": "HSS-scoring", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.6896740198135376}, {"text": "ROUGE", "start_pos": 88, "end_pos": 93, "type": "METRIC", "confidence": 0.9739779233932495}, {"text": "recall", "start_pos": 97, "end_pos": 103, "type": "METRIC", "confidence": 0.9957035183906555}]}, {"text": "Alternately, SSS-scoring gives preference to shorter system summaries that have their best content (extracted sentences) first.", "labels": [], "entities": [{"text": "SSS-scoring", "start_pos": 13, "end_pos": 24, "type": "TASK", "confidence": 0.880383312702179}]}, {"text": "The performance for HSS-scoring of the systems on the seven languages that at least two teams submitted summaries for are given in, and 3.", "labels": [], "entities": [{"text": "HSS-scoring", "start_pos": 20, "end_pos": 31, "type": "TASK", "confidence": 0.8254847526550293}]}, {"text": "gives an overview of how often significant differences in each of the three automatic metrics was observed.", "labels": [], "entities": []}, {"text": "In particular, the last row gives the fraction of times that an non-parametric analysis of variance (ANOVA) indicated that the: The table lists the n-gram size used for each language when evaluating summaries using MeMoG, which is the n-gram size that maximized the standard deviation divided by the mean of the n-gram frequency distribution of the language in the dataset.", "labels": [], "entities": [{"text": "ANOVA", "start_pos": 101, "end_pos": 106, "type": "METRIC", "confidence": 0.8353708982467651}]}, {"text": "medians of the system scores were not the same, using a rejection threshold of 0.05.", "labels": [], "entities": [{"text": "rejection threshold", "start_pos": 56, "end_pos": 75, "type": "METRIC", "confidence": 0.9646627902984619}]}, {"text": "Also, the fraction of time that each system significantly outperformed the lead baseline is also recorded.", "labels": [], "entities": []}, {"text": "A paired Wilcoxon test was invoked whenever the ANOVA indicated a significant difference was present, with a threshold of 0.05.", "labels": [], "entities": [{"text": "ANOVA", "start_pos": 48, "end_pos": 53, "type": "METRIC", "confidence": 0.9522238969802856}]}, {"text": "Lastly, each systems performance for SSSscoring is provided in, and 6.", "labels": [], "entities": [{"text": "SSSscoring", "start_pos": 37, "end_pos": 47, "type": "TASK", "confidence": 0.8465970158576965}]}, {"text": "Surprisingly, the results change little.", "labels": [], "entities": []}, {"text": "Lastly contains the number of times that each system beat the baseline summary with a 95% confidence measured as a result of the non-parametric ANOVA and the Wilcoxon paired sign rank test.", "labels": [], "entities": [{"text": "ANOVA", "start_pos": 144, "end_pos": 149, "type": "METRIC", "confidence": 0.8204007148742676}, {"text": "Wilcoxon paired sign rank test", "start_pos": 158, "end_pos": 188, "type": "METRIC", "confidence": 0.6005889356136322}]}, {"text": "The results show that the number of significant differences go down for ROUGE scores and up for MeMoG.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 72, "end_pos": 77, "type": "METRIC", "confidence": 0.9923226237297058}, {"text": "MeMoG", "start_pos": 96, "end_pos": 101, "type": "DATASET", "confidence": 0.8748934864997864}]}], "tableCaptions": [{"text": " Table 2: Mean Summary Size For Submitted Languages of Systems  ISO LANGUAGE  AIS LAN MD1 MD2 MD3 MUS SUM  af  Afrikaans  966  953  967", "labels": [], "entities": [{"text": "Mean Summary Size", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.7462174296379089}, {"text": "ISO LANGUAGE  AIS LAN MD1 MD2 MD3 MUS SUM  af  Afrikaans  966  953  967", "start_pos": 64, "end_pos": 135, "type": "DATASET", "confidence": 0.7021245253937585}]}, {"text": " Table 3: The table lists the n-gram size used for each language when evaluating summaries using  MeMoG, which is the n-gram size that maximized the standard deviation divided by the mean of the  n-gram frequency distribution of the language in the dataset.", "labels": [], "entities": [{"text": "MeMoG", "start_pos": 98, "end_pos": 103, "type": "DATASET", "confidence": 0.8632782101631165}]}, {"text": " Table 4: Fraction of time a system beat the base- line for HSS.", "labels": [], "entities": [{"text": "HSS", "start_pos": 60, "end_pos": 63, "type": "TASK", "confidence": 0.7013435959815979}]}, {"text": " Table 4: The table gives the fraction of languages  each system significantly outperform the base- line. The last line gives the number of times an  ANOVA rejected the null hypothesis, indicating  significance.", "labels": [], "entities": []}, {"text": " Table 5: Fraction of the time a system beat the lead  baseline for SSS.", "labels": [], "entities": [{"text": "Fraction", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9108461737632751}, {"text": "SSS", "start_pos": 68, "end_pos": 71, "type": "TASK", "confidence": 0.9274155497550964}]}, {"text": " Table 5: The table gives the fraction of lan- guages that each system significantly outperform  the baseline on. The last line contains the number  of times an ANOVA rejected the null hypothesis,  indicating significance.", "labels": [], "entities": []}]}