{"title": [{"text": "A Framework and Tool for Collaborative Extraction of Reliable Information", "labels": [], "entities": []}], "abstractContent": [{"text": "This research proposes a framework for efficient information extraction and filtering in situations where 1) extreme reliability is important, 2) the amount of information to be combed through is massive, and 3) we can expect a relatively large number of human workers to be available.", "labels": [], "entities": [{"text": "information extraction and filtering", "start_pos": 49, "end_pos": 85, "type": "TASK", "confidence": 0.7294285073876381}, {"text": "reliability", "start_pos": 117, "end_pos": 128, "type": "METRIC", "confidence": 0.941999077796936}]}, {"text": "In particular , we are motivated by needs in times of crisis, and assume that in order to ensure the high level of reliability required, it will be necessary to have at least one human worker confirm all extracted information.", "labels": [], "entities": [{"text": "reliability", "start_pos": 115, "end_pos": 126, "type": "METRIC", "confidence": 0.9835212230682373}]}, {"text": "Given this setting, we propose a method to improve the efficiency of manual verification by deciding which information to present to workers using machine learning techniques.", "labels": [], "entities": []}, {"text": "Even given this efficient search framework, the amount of information on the internet is still too much for one user to handle, so we additionally create a web-based framework that allows for col-laborative work, and an algorithm that allows for this framework to work on large data in real-time.", "labels": [], "entities": []}, {"text": "We perform an evaluation using data from Twitter after the Great East Japan Earthquake, and compare efficiency using both traditional keyword search and the proposed learning-based method.", "labels": [], "entities": [{"text": "Great East Japan Earthquake", "start_pos": 59, "end_pos": 86, "type": "DATASET", "confidence": 0.7155446857213974}]}], "introductionContent": [{"text": "In times of crisis, internet sites, and particularly social networks such as Twitter, overflow with information, with some reports noting an increase of activity by as much as 20 fold.", "labels": [], "entities": []}, {"text": "This information spans all genres, from questions or comments about the state of affairs, statements of opinion, emotional pleas, or even the spread of false rumors (.", "labels": [], "entities": []}, {"text": "Perhaps the information of the most interest is that which helps either crisis-responders or evacuees get a better grasp of situation (, and this is particularly true when the information is provided directly by people in the disaster-affected areas.", "labels": [], "entities": []}, {"text": "However, distinguishing useful information (e.g. \"there is water at the evacuation center in Sendai high school\") from unreliable or non-actionable information (e.g. \"just arrived at the evacuation center, so tired...\") takes a large amount of human effort.", "labels": [], "entities": [{"text": "Sendai high school", "start_pos": 93, "end_pos": 111, "type": "DATASET", "confidence": 0.8906475305557251}]}, {"text": "Luckily, however, the effort of good-willed internet users is one thing that is often plentiful in times of crisis.", "labels": [], "entities": []}, {"text": "There have been many success stories where volunteers have banded together to turn natural language data into machine-readable format, translate crisis-related information, gather survivor lists from evacuation sites and enter them into a central database (Google Japan, 2011), or even annotate data for the creation of specialized information extraction systems).", "labels": [], "entities": [{"text": "information extraction", "start_pos": 332, "end_pos": 354, "type": "TASK", "confidence": 0.770279586315155}]}, {"text": "Given the large amount of work required in these collaborative efforts, it is common for as many as hundreds of volunteers to be involved in any single task.", "labels": [], "entities": []}, {"text": "On the other hand, examinations of the types of information provided on social networks after crises have shown that the number of possible information extraction tasks is large's classification).", "labels": [], "entities": [{"text": "information extraction", "start_pos": 140, "end_pos": 162, "type": "TASK", "confidence": 0.728102833032608}]}, {"text": "Information requirements also vary greatly from situation to situation, with the direction of the wind being important during the Oklahoma wildfires, and radiation measurements being important after the nuclear meltdown following the Great East Japan Earthquake (.", "labels": [], "entities": []}, {"text": "While a large number of volunteers maybe mobilized fora single task, scaling this approach to tensor hundreds of disparate tasks has not proven possible given in a timely fashion.", "labels": [], "entities": []}, {"text": "However, by increasing the efficiency of each volunteer, it is possible to reduce the overall number of volunteers needed, thus increasing the potential to tackle a much larger number of tasks in the short timeframe allowed after a disaster.", "labels": [], "entities": []}, {"text": "As a result, there have been a number of works that attempt to remove the requirement for manual labor by automating the information extraction process.", "labels": [], "entities": [{"text": "information extraction process", "start_pos": 121, "end_pos": 151, "type": "TASK", "confidence": 0.8612024585405985}]}, {"text": "For example, it has been noted that it maybe possible to automatically identify information that contributes to situational awareness in general, or for more pinpoint tasks such as identifying information about safety of evacuees), evacuation routes (, or information providers in disaster affected areas.", "labels": [], "entities": [{"text": "situational awareness", "start_pos": 112, "end_pos": 133, "type": "TASK", "confidence": 0.6910585165023804}]}, {"text": "While these systems are quite promising, taking human workers out of the loop completely raises questions regarding the reliability of the information provided.", "labels": [], "entities": []}, {"text": "Given this background, in this work we examine a framework that enables teams of volunteers to identify useful information in a fashion that is efficient, collaborative, and highly reliable.", "labels": [], "entities": []}, {"text": "In particular, to ensure reliability, we assume that all information provided must be checked by at least one volunteer.", "labels": [], "entities": [{"text": "reliability", "start_pos": 25, "end_pos": 36, "type": "METRIC", "confidence": 0.9896150827407837}]}, {"text": "However, we increase the efficiency of this manual verification by learning a classifier to decide which pieces of information are likely to be relevant and should be presented to volunteers.", "labels": [], "entities": []}, {"text": "Each time anew piece of information is labeled as either relevant or irrelevant to the task at hand, the classifier is updated to be more accurate at the task.", "labels": [], "entities": []}, {"text": "Finally, to take advantage of collaborative work, we implement the proposed framework in a web interface that can be used collaboratively by many workers simultaneously.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the effectiveness of our proposed framework and tool for extraction of highly reliable information, we perform a series of experimental evaluations.", "labels": [], "entities": []}, {"text": "As extraction of highly reliable information is particularly important in times of crisis, we used data provided as part of the Great East Japan Earthquake Big Data Workshop 6 including all actual Japanese tweets from Twitter for one week after the earthquake starting at March 11th, 2011, 14:45, a total of 179 million tweets.", "labels": [], "entities": [{"text": "Great East Japan Earthquake Big Data Workshop 6", "start_pos": 128, "end_pos": 175, "type": "DATASET", "confidence": 0.8153328485786915}]}, {"text": "We specify three information extraction tasks as shown in, and use these as the targets for We use d2's old model score because the cache order will change the most when the user labels an example as negative.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 17, "end_pos": 39, "type": "TASK", "confidence": 0.7335311770439148}]}, {"text": "In these cases, if both d1 and d2 are similar to the negatively labeled example, both will see a large reduction in score, so we d1's new score will be much smaller than d2's old score, but not necessarily smaller than d2's new score.", "labels": [], "entities": []}, {"text": "To ensure that we continue penalizing high-scoring instances that are similar to the negatively labeled instance, we continue updating the cache until we find an example that both had a high score according to the old model (and thus a high position in the cache), and a high score according to the new model.", "labels": [], "entities": []}, {"text": "The first task consists of finding information about evacuation areas or rescue supplies that maybe useful to those in disasteraffected areas, and the other two tasks are related to finding posts either requesting or providing information about the safety of evacuees.", "labels": [], "entities": []}, {"text": "Given our goal of efficient and reliable identification and extraction of information as stated in Section 1, we use as our evaluation measure the number of tweets able to be verified by workers in 30 minutes.", "labels": [], "entities": []}, {"text": "In addition, to more closely simulate the actual situation of the tool being used in a crisis-response setting, all workers were asked to fill in a web form indicating information such as \"location,\" \"situation,\" or \"name\" in accordance to the information that would likely be useful for each of the tasks.", "labels": [], "entities": []}, {"text": "Given this data and these tasks, we perform two rounds of experiments to compare the efficiency of the learning-based interface compared to simple keyword search (Section 4.1) and the efficacy of collaborative work (Section 4.2).", "labels": [], "entities": []}, {"text": "First, we perform an evaluation of the information filtering interface described in Section 2.1.3.", "labels": [], "entities": [{"text": "information filtering interface", "start_pos": 39, "end_pos": 70, "type": "TASK", "confidence": 0.863394558429718}]}, {"text": "As features, we use character 1-to-5-grams, and a naive Bayes classifier, as it is extremely efficient to both classify and update.", "labels": [], "entities": []}, {"text": "In Equation, we set \u03b1 = 1 and \u03b2 = 5.", "labels": [], "entities": [{"text": "Equation", "start_pos": 3, "end_pos": 11, "type": "METRIC", "confidence": 0.7512813210487366}]}, {"text": "As a baseline system, we use simple keyword search.", "labels": [], "entities": []}, {"text": "All results were provided by a single user who had time to practice using the interface before results were recorded.", "labels": [], "entities": []}, {"text": "We show the results for the three tasks in.", "labels": [], "entities": []}, {"text": "From the results indicating the number of pieces of useful information extracted on the left side of the graph, we can see that the proposed learning capability improves the efficiency, with increases ranging from 35%-159%.", "labels": [], "entities": []}, {"text": "This increase can be largely attributed to an increase in the information filtering accuracy, or the number of documents displayed to the user that have at least one piece of useful information.", "labels": [], "entities": [{"text": "information filtering", "start_pos": 62, "end_pos": 83, "type": "TASK", "confidence": 0.7568262815475464}, {"text": "accuracy", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.9525877833366394}]}, {"text": "The rolling average of accuracy is shown on the right side of.", "labels": [], "entities": [{"text": "rolling average", "start_pos": 4, "end_pos": 19, "type": "METRIC", "confidence": 0.9724437892436981}, {"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9905900955200195}]}, {"text": "We can see that there is a significant difference in the information filtering accuracy between tasks, and this affects the gain afforded by the learning capability.", "labels": [], "entities": [{"text": "information filtering", "start_pos": 57, "end_pos": 78, "type": "TASK", "confidence": 0.6991789937019348}, {"text": "accuracy", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.8122014403343201}]}, {"text": "Specifically, \"Safety Info.", "labels": [], "entities": [{"text": "Safety Info", "start_pos": 15, "end_pos": 26, "type": "DATASET", "confidence": 0.7784608602523804}]}, {"text": "Provision\" has lower accuracy than the other tasks, largely because it is difficult to distinguish between provision of information (\"I heard that XXX is safe\") and requests for information (\"I wonder if XXX is safe\"), while the latter is much more common in the corpus (approximately five times according to's estimate).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9979203343391418}]}, {"text": "Thus, for more difficult tasks improving the accuracy of the classifiers could lead to further improvements in the gains provided by the proposed technique.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9986363053321838}]}, {"text": "In addition, to evaluate the collaborative web interface described in Section 3, we performed exper-: Information verified by 1, 2, or 3 users iments in which multiple annotators worked collaboratively on an information filtering task.", "labels": [], "entities": [{"text": "information filtering task", "start_pos": 208, "end_pos": 234, "type": "TASK", "confidence": 0.7795921961466471}]}, {"text": "The experimental setup is identical to that described in the previous section, but we focus only on the Evacuation/Rescue Supplies task.", "labels": [], "entities": [{"text": "Evacuation/Rescue Supplies task", "start_pos": 104, "end_pos": 135, "type": "TASK", "confidence": 0.940219783782959}]}, {"text": "As a comparison, we compare results for when 1, 2, or 3 users work collaboratively on a single information filtering task, performing two experiments for each number of users.", "labels": [], "entities": [{"text": "information filtering task", "start_pos": 95, "end_pos": 121, "type": "TASK", "confidence": 0.7848633329073588}]}, {"text": "The result of this experiment is shown in.", "labels": [], "entities": []}, {"text": "After 30 minutes of work, a single user had extracted an average of 43 pieces, two users had extracted 103 pieces, and three users had extracted 129 pieces of useful information and added them to the shared aggregation site.", "labels": [], "entities": []}, {"text": "Thus, we can see that increasing the number of users results in an approximately linear increase in the amount of information extracted, confirming the effectiveness of allowing multiple users to work on a single task, and share the results of labeling with a single classifier.", "labels": [], "entities": []}, {"text": "As each worker works largely independently, we hypothesize that this trend will continue for even larger numbers of users.", "labels": [], "entities": []}, {"text": "In we show the improvement in efficiency of information extraction as each run progresses.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 44, "end_pos": 66, "type": "TASK", "confidence": 0.8551492393016815}]}, {"text": "From the graph, we can see that in all cases, the efficiency at the end of the run has increased by 1.3-2.0 times over that achieved in the initial five minutes.", "labels": [], "entities": []}, {"text": "displays the rolling average of positive examples, and we can see that the percentage of positive examples labeled increases drastically overtime, with accuracy near 100% achieved in four out of six trials, and all trials achieving accuracy over 60%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 152, "end_pos": 160, "type": "METRIC", "confidence": 0.9991751313209534}, {"text": "accuracy", "start_pos": 232, "end_pos": 240, "type": "METRIC", "confidence": 0.9988226294517517}]}, {"text": "However, compared to this large increase in the accuracy of the examples presented to users, the increase in the amount of information extracted is small.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9983028173446655}]}, {"text": "This is because even after positive information has been identified, there is a small but fixed amount of work required to enter the useful information into the information aggregation site.", "labels": [], "entities": []}, {"text": "As a result, we can expect that further improvements in information extraction efficiency can be achieved by automatically extracting candidates to fill in each column of information to be extracted, and make it possible fora human to simply press a button to verify the information if it happens to be correct.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 56, "end_pos": 78, "type": "TASK", "confidence": 0.8224881887435913}]}], "tableCaptions": []}