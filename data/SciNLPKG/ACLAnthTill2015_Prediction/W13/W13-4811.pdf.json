{"title": [{"text": "Mac-Morpho Revisited: Towards Robust Part-of-Speech Tagging", "labels": [], "entities": [{"text": "Part-of-Speech Tagging", "start_pos": 37, "end_pos": 59, "type": "TASK", "confidence": 0.7218639105558395}]}], "abstractContent": [{"text": "We present a revision of Mac-Morpho, the biggest corpus of Por-tuguese text containing manually annotated POS tags.", "labels": [], "entities": []}, {"text": "Many errors were corrected , yielding a much more reliable resource.", "labels": [], "entities": []}, {"text": "We also trained a neural network based classifier for the POS tagging task, following an architecture that achieves state-of-the-art results in English.", "labels": [], "entities": [{"text": "POS tagging task", "start_pos": 58, "end_pos": 74, "type": "TASK", "confidence": 0.8526170253753662}]}, {"text": "Our tagger maps each word to areal valued vector and uses it as input, thus dealing with abstract features.", "labels": [], "entities": []}, {"text": "These vectors are induced by distributional semantics techniques, and provide the tag-ger with information for achieving 96.48% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 128, "end_pos": 136, "type": "METRIC", "confidence": 0.9764520525932312}]}], "introductionContent": [{"text": "Part-of-Speech (POS) tagging is an important Natural Language Processing (NLP) task, serving as a first step for many applications.", "labels": [], "entities": [{"text": "Part-of-Speech (POS) tagging", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.5828990817070008}]}, {"text": "While a rule based approach for an automatic tagger is possible, most of the work addressing this task is based on machine learning techniques, as usual in NLP, since they require significantly less labor.", "labels": [], "entities": []}, {"text": "In order to do so, one must consider two points: the training data and the learning algorithm for the tagger.", "labels": [], "entities": []}, {"text": "The training data, in the form of an annotated corpus, should be large enough to allow the tagger to generalize what it learns to unseen sentences.", "labels": [], "entities": []}, {"text": "The two most widespread corpora with annotated POS tags in Portuguese are Mac-Morpho], with around one million words, and Bosque, with around 185 thousand.", "labels": [], "entities": [{"text": "Bosque", "start_pos": 122, "end_pos": 128, "type": "METRIC", "confidence": 0.7682178020477295}]}, {"text": "Both corpora cannot be combined to provide a larger resource, since each one defines a different tagset.", "labels": [], "entities": []}, {"text": "For example, while Bosque has different tags for verbs in the infinitive, gerund, participle and inflected forms, Mac-Morpho only distinguishes participles from the other three.", "labels": [], "entities": [{"text": "Bosque", "start_pos": 19, "end_pos": 25, "type": "DATASET", "confidence": 0.8948827981948853}]}, {"text": "On the other hand, Mac-Morpho has different tags for auxiliary and main verbs, which Bosque does not.", "labels": [], "entities": [{"text": "Mac-Morpho", "start_pos": 19, "end_pos": 29, "type": "DATASET", "confidence": 0.9314476251602173}, {"text": "Bosque", "start_pos": 85, "end_pos": 91, "type": "DATASET", "confidence": 0.8797276020050049}]}, {"text": "The quality of the data is also important: too much noise (such as wrongly assigned tags) may affect the learning process.", "labels": [], "entities": []}, {"text": "As the annotation is done by humans, mistakes are often introduced, and thus a rigourous checking procedure must be carried out.", "labels": [], "entities": []}, {"text": "As for learning algorithms, there are many that have been proposed and succesfully applied in this task, usually capable of being employed in different languages.", "labels": [], "entities": []}, {"text": "In Portuguese, experiments reported in the literature include Transformation Based Learning, Hidden Markov Models (HMM) and Variable Length Markov Chain (VLMC), HMM with a character language model, among others.", "labels": [], "entities": []}, {"text": "The work reported in this paper aimed at both these points.", "labels": [], "entities": []}, {"text": "First, we performed a thorough error verification and cleaning process on the Mac-Morpho corpus, which we used as training data for our models.", "labels": [], "entities": [{"text": "Mac-Morpho corpus", "start_pos": 78, "end_pos": 95, "type": "DATASET", "confidence": 0.9179947674274445}]}, {"text": "We report the problems found and make our revised version publicly available.", "labels": [], "entities": []}, {"text": "Also, we joined contracted forms (such as do for de + o), which appear splitted in the corpus, in order to reflect areal world scenario.", "labels": [], "entities": []}, {"text": "Most works reported in the literature don't mention this step.", "labels": [], "entities": []}, {"text": "Second, we trained a POS tagger similar to the work found in, based on multilayer perceptron neural networks and vector space models, and that achieves state-of-the-art performance in English.", "labels": [], "entities": []}, {"text": "Our resulting tagger is also available online.", "labels": [], "entities": []}, {"text": "Besides our model, we performed experiments with the OpenNLP POS tagger 1 for comparison.", "labels": [], "entities": [{"text": "OpenNLP POS tagger 1", "start_pos": 53, "end_pos": 73, "type": "DATASET", "confidence": 0.926896870136261}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1. Distribution of tags in the corpus", "labels": [], "entities": []}]}