{"title": [{"text": "Unsupervised structured semantic inference for spoken dialog reservation tasks", "labels": [], "entities": [{"text": "Unsupervised structured semantic inference", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.583345539867878}, {"text": "spoken dialog reservation", "start_pos": 47, "end_pos": 72, "type": "TASK", "confidence": 0.6989765763282776}]}], "abstractContent": [{"text": "This work proposes a generative model to infer latent semantic structures on top of manual speech transcriptions in a spoken dialog reservation task.", "labels": [], "entities": [{"text": "spoken dialog reservation task", "start_pos": 118, "end_pos": 148, "type": "TASK", "confidence": 0.6841512471437454}]}, {"text": "The proposed model is akin to a standard semantic role labeling system, except that it is unsuper-vised, it does not rely on any syntactic information and it exploits concepts derived from a domain-specific ontology.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 41, "end_pos": 63, "type": "TASK", "confidence": 0.705438494682312}]}, {"text": "The semantic structure is obtained with un-supervised Bayesian inference, using the Metropolis-Hastings sampling algorithm.", "labels": [], "entities": []}, {"text": "It is evaluated both in terms of attachment accuracy and purity-collocation for clustering , and compared with strong baselines on the French MEDIA spoken-dialog corpus .", "labels": [], "entities": [{"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9223246574401855}, {"text": "purity-collocation", "start_pos": 57, "end_pos": 75, "type": "METRIC", "confidence": 0.9825121164321899}, {"text": "French MEDIA spoken-dialog corpus", "start_pos": 135, "end_pos": 168, "type": "DATASET", "confidence": 0.9122982174158096}]}], "introductionContent": [{"text": "Many concrete applications that involve humanmachine spoken dialogues exploit some handcrafted ontology that defines and relates the concepts that are useful for the application.", "labels": [], "entities": []}, {"text": "The main challenge for the dialog manager used in the application is then to interpret the user's spoken input in order to correctly answer the user's expectations and conduct a dialogue that shall be satisfactory for the user.", "labels": [], "entities": []}, {"text": "This whole process maybe decomposed into the following stages: \u2022 Automatic speech recognition, to transform the acoustic signal into a sequence of words (or sequences of word hypotheses); \u2022 Spoken language understanding, to segment and map these sequences of words into concepts of the ontology; \u2022 Semantic analysis, to relate these concepts together and interpret the semantic of the user input at the level of the utterance, or of the speaker turn; \u2022 Dialogue act recognition \u2022 Dialogue planning \u2022 Text generation \u2022 ...", "labels": [], "entities": [{"text": "Automatic speech recognition", "start_pos": 65, "end_pos": 93, "type": "TASK", "confidence": 0.6170791586240133}, {"text": "Spoken language understanding", "start_pos": 190, "end_pos": 219, "type": "TASK", "confidence": 0.8153074781099955}, {"text": "Semantic analysis", "start_pos": 298, "end_pos": 315, "type": "TASK", "confidence": 0.8057212829589844}, {"text": "Dialogue act recognition", "start_pos": 453, "end_pos": 477, "type": "TASK", "confidence": 0.6949384212493896}, {"text": "Text generation", "start_pos": 500, "end_pos": 515, "type": "TASK", "confidence": 0.7994396388530731}]}, {"text": "Note that the process sketched here often further involves several other important steps that are used internally within one or several of these broad stages, for instance named entity recognition, coreference resolution, syntactic parsing, marcov decision process, reinforcement learning, etc.", "labels": [], "entities": [{"text": "entity recognition", "start_pos": 178, "end_pos": 196, "type": "TASK", "confidence": 0.7300543040037155}, {"text": "coreference resolution", "start_pos": 198, "end_pos": 220, "type": "TASK", "confidence": 0.9168469309806824}, {"text": "syntactic parsing", "start_pos": 222, "end_pos": 239, "type": "TASK", "confidence": 0.7133043855428696}]}, {"text": "This work focuses mainly on the second and third stages, since we assume that segmentation is given and we want to discover the underlying concepts and relations in the data.", "labels": [], "entities": []}, {"text": "The third stage is very important because it exhibits the latent semantic structure hidden in the user utterance: what is the object affected by a given predicate ? What are the modifiers that may alter the meaning of a predicate ? Without such a structure, the system can hardly push understanding beyond lexical semantics and reach fine-grained semantic representations, which are thus often limited to well-formed inputs and cannot handle spontaneous speech as considered here.", "labels": [], "entities": []}, {"text": "But still, despite its importance, most spoken dialog systems do not make use of such structure.", "labels": [], "entities": []}, {"text": "We propose an approach hereto address this issue by directly inferring the semantic structure from the flat sequence of concepts using the unsupervised Bayesian learning framework.", "labels": [], "entities": []}, {"text": "Hence, the proposed model does not rely on any predefined corpus annotated with semantic structure, which makes it much more robust to spoken inputs and adaptable to new domains than traditional supervised approaches.", "labels": [], "entities": []}], "datasetContent": [{"text": "The French MEDIA corpus collects about 70 hours of spontaneous speech (1258 dialogues, 46k utterances, 494.048 words and 4068 distinct words) for the task of hotel reservation and tourist information ().", "labels": [], "entities": [{"text": "French MEDIA corpus", "start_pos": 4, "end_pos": 23, "type": "DATASET", "confidence": 0.876909077167511}, {"text": "hotel reservation", "start_pos": 158, "end_pos": 175, "type": "TASK", "confidence": 0.7034822702407837}]}, {"text": "Calls from 250 speakers to a simulated reservation system (i.e. the Wizard-of-Oz) were recorded and transcribed.", "labels": [], "entities": []}, {"text": "Dialogues are full of disfluencies, hesitations, false starts, truncations or fillers words (e.g., euh or ben).", "labels": [], "entities": []}, {"text": "This corpus has been semantically annotated as part of the French ANR project PORT-MEDIA ().", "labels": [], "entities": [{"text": "ANR project PORT-MEDIA", "start_pos": 66, "end_pos": 88, "type": "TASK", "confidence": 0.5566151340802511}]}, {"text": "We are using a set of 330 utterances manually annotated with gold semantic relations (i.e. High-Level Semantics).", "labels": [], "entities": []}, {"text": "This gold corpus gathers 653 head segments and 1555 argument segments, from which around 20% are both arguments and heads, such as une chambre in. shows the semantic relations frequencies in the gold annotation.", "labels": [], "entities": []}, {"text": "12 head segment types and 19 different argument segment types are defined in the gold annotations.", "labels": [], "entities": []}, {"text": "In the evaluation, we assume the number of both classes is given.", "labels": [], "entities": []}, {"text": "A possible extension of the approach to automatically infer the number of classes would be to use a non-parametric model, but this is left for future work.", "labels": [], "entities": []}, {"text": "The proposed method infers three types of semantic information: \u2022 The semantic relation between an argument and its head; \u2022 The argument type A \u2022 The semantic class of the head Ct . The three outcomes are evaluated as follows.", "labels": [], "entities": []}, {"text": "\u2022 The output structure is a forest of trees that is similar to a partial syntactic dependency structure.", "labels": [], "entities": []}, {"text": "We thus use a classical unsupervised dependency parsing metric, the Unlabeled Attachment Score (UAS), which is simply the accuracy of argument attachment: an argument is correctly attached if and only if its inferred head matches the gold head.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 37, "end_pos": 55, "type": "TASK", "confidence": 0.7449744641780853}, {"text": "Unlabeled Attachment Score (UAS)", "start_pos": 68, "end_pos": 100, "type": "METRIC", "confidence": 0.8168436139822006}, {"text": "accuracy", "start_pos": 122, "end_pos": 130, "type": "METRIC", "confidence": 0.9990854263305664}]}, {"text": "\u2022 Both argument and head classes correspond to the outcome of a clustering process into semantic classes, akin to the semantic classes obtained in unsupervised semantic role labeling tasks.", "labels": [], "entities": [{"text": "semantic role labeling tasks", "start_pos": 160, "end_pos": 188, "type": "TASK", "confidence": 0.7453602105379105}]}, {"text": "We then evaluate them with a classical metric used to evaluate these classes in unsupervised SRL (as done for instance in and): purity and collocation.", "labels": [], "entities": [{"text": "purity", "start_pos": 128, "end_pos": 134, "type": "METRIC", "confidence": 0.9671640992164612}]}, {"text": "Purity measures the degree to which each cluster contains instances that share the same gold class, while collocation measures the degree to which instances with the same gold class are assigned to a single cluster.", "labels": [], "entities": [{"text": "Purity", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9464629292488098}]}, {"text": "More formally, the purity of argument segments' (head segment') clusters for the whole corpus is computed as follows: where Ci is the set of argument (head) segments in the i th cluster found, G j is the set of argument (head) segments in the j th gold class, and N is the number of gold argument (head) segment instances.", "labels": [], "entities": [{"text": "purity", "start_pos": 19, "end_pos": 25, "type": "METRIC", "confidence": 0.9726932644844055}]}, {"text": "Ina similar way, the collocation of argument segments' (head segment') clusters is computed as follows: Finally the F1 measure is the harmonic mean of the purity and collocation:  We compare the proposed approach against two baselines: \u2022 An argument-head \"attachment\" baseline, which attaches each argument to the closest head segment.", "labels": [], "entities": [{"text": "F1 measure", "start_pos": 116, "end_pos": 126, "type": "METRIC", "confidence": 0.9798385798931122}]}, {"text": "\u2022 A strong clustering baseline, which respectively clusters the head and argument segments using a very effective topic model: the Latent Dirichlet Allocation (LDA) approach (.", "labels": [], "entities": []}, {"text": "shows the UAS obtained for the proposed model on the MEDIA corpus, while shows the obtained Purity, Collocation and F1-measure.", "labels": [], "entities": [{"text": "UAS", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9972714781761169}, {"text": "MEDIA corpus", "start_pos": 53, "end_pos": 65, "type": "DATASET", "confidence": 0.9594550132751465}, {"text": "Purity", "start_pos": 92, "end_pos": 98, "type": "METRIC", "confidence": 0.9902253746986389}, {"text": "F1-measure", "start_pos": 116, "end_pos": 126, "type": "METRIC", "confidence": 0.89412522315979}]}, {"text": "In both cases, we compare the performances of the proposed model with the respective baseline.", "labels": [], "entities": []}, {"text": "Our system outperforms both baselines by a large margin.", "labels": [], "entities": []}, {"text": "We further carried out a qualitative evaluation, where we inspected the inferred clusters and compared them with the baseline.", "labels": [], "entities": []}, {"text": "show, for every head class Ct in each stacked column, the distribution of instances from all gold clusters.", "labels": [], "entities": []}, {"text": "Each column can also be viewed as a graphical representation of the intersection of one inferred class with all gold clusters.", "labels": [], "entities": []}, {"text": "illustrates this for our model, and for LDA.", "labels": [], "entities": [{"text": "LDA", "start_pos": 40, "end_pos": 43, "type": "DATASET", "confidence": 0.5718390345573425}]}, {"text": "The same comparison for the argument types is shown, respectively, in and.", "labels": [], "entities": []}, {"text": "For head segment clusters, we can observe that most inferred clusters contain many instances of the Reservation type (in dark blue), both in the LDA baseline and in the proposed system.", "labels": [], "entities": [{"text": "LDA baseline", "start_pos": 145, "end_pos": 157, "type": "DATASET", "confidence": 0.9219224452972412}]}, {"text": "The main reason for that is that the corpus is very unbalanced in favor of the Reservation class, while we do not assume any prior knowledge about the data and thus use a uniform prior.", "labels": [], "entities": []}, {"text": "Still, every other gold type that occurs with a reasonnably high enough frequency, apart from two special types that are discussed next, is well captured by one of: Distribution of the gold types (one per color) into the clusters inferred by our system (shown on the X-axis) for argument segments.", "labels": [], "entities": []}, {"text": "our inferred class: this is the case for \"Room\" that mainly intersects with our class 1, \"Place\" with our class 2 and \"Hotel\" with our class 9.", "labels": [], "entities": []}, {"text": "Some examples of instances for each case are: \u2022 Reservation: \"voudrais r\u00e9server\", \"aimerais partir\", \"voudrais une *r\u00e9servation une r\u00e9servation\", \"prends\", \"recherche\" , \"*d\u00e9sire d\u00e9sire\", \"il me faudrait\", \"opte\", \"aimerais s' il vous pla\u02c6\u0131tpla\u02c6\u0131t si c' est possible avoir prendre\".", "labels": [], "entities": []}, {"text": "\u2022 Room: \"deux chambres pour un coup(le) avec trois enfants avec bon standing\", \"trois singles\", \"deux chambres de bon standing\u00e0 standing`standing\u00e0 peu pr\u00e8s niveau trois\u00e9toilestrois\u00b4trois\u00e9toiles\", \"trois doubles\".", "labels": [], "entities": []}, {"text": "\u2022 Place: \"Paris\", \"` a Saintes\", \"` a Charleville\", \"dans le dixhuit\u00ec eme arrondissement de Paris\".", "labels": [], "entities": [{"text": "Paris", "start_pos": 10, "end_pos": 15, "type": "DATASET", "confidence": 0.9152023196220398}]}, {"text": "\u2022 Hotel: \"un h\u00f4tel deux\u00e9toilesdeux\u00b4deux\u00e9toiles\", \"dans un h\u00f4tel beau standing\", \"un h\u00f4tel formule un\", \"l' h\u00f4t(el) le l' h\u00f4tel\", \"un autre h\u00f4tel dans les m\u00eames conditions\", \"le Beaugency\", \"l' autre\", \"au Novotel\", \"le premier\".", "labels": [], "entities": []}, {"text": "Two \"special\" head segment types that are neither nicely captured by our system nor LDA are Coordination and Inform, which are instead assigned to the clusters corresponding to the gold segments that they coordinate or inform about.", "labels": [], "entities": []}, {"text": "For argument segments we also observed that the inferred clusters are semantically related to the gold types.", "labels": [], "entities": []}, {"text": "Finally, as noted for the head segments, we can observe that the most frequent gold types largely intersect with several inferred clusters, for the same reason: data is very unbalanced and we do not assume any prior knowledge about the data", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Most frequent semantic relations in the  gold annotation.", "labels": [], "entities": []}, {"text": " Table 3: Experimental results for UAS on the ME- DIA database. The statistical confidence interval  at 95% with Gaussian approximation is reported.", "labels": [], "entities": [{"text": "UAS", "start_pos": 35, "end_pos": 38, "type": "TASK", "confidence": 0.7854220271110535}, {"text": "ME- DIA database", "start_pos": 46, "end_pos": 62, "type": "DATASET", "confidence": 0.8458075821399689}, {"text": "statistical confidence interval", "start_pos": 68, "end_pos": 99, "type": "METRIC", "confidence": 0.8708996574083964}]}, {"text": " Table 4: Experimental results on the MEDIA  database for purity, collocation and F1-measure.", "labels": [], "entities": [{"text": "MEDIA  database", "start_pos": 38, "end_pos": 53, "type": "DATASET", "confidence": 0.8809895813465118}, {"text": "purity", "start_pos": 58, "end_pos": 64, "type": "METRIC", "confidence": 0.9910936951637268}, {"text": "F1-measure", "start_pos": 82, "end_pos": 92, "type": "METRIC", "confidence": 0.9960774779319763}]}]}