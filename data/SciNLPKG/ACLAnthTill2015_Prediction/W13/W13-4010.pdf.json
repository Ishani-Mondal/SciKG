{"title": [{"text": "Modeling Collaborative Referring for Situated Referential Grounding", "labels": [], "entities": [{"text": "Modeling Collaborative Referring", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8251955906550089}]}], "abstractContent": [{"text": "In situated dialogue, because humans and agents have mismatched capabilities of perceiving the shared physical world, ref-erential grounding becomes difficult.", "labels": [], "entities": []}, {"text": "Humans and agents will need to make extra efforts by collaborating with each other to mediate a shared perceptual basis and to come to a mutual understanding of intended referents in the environment.", "labels": [], "entities": []}, {"text": "In this paper, we have extended our previous graph-matching based approach to explicitly incorporate collaborative referring behaviors into the referential grounding algorithm.", "labels": [], "entities": []}, {"text": "In addition, hypergraph-based representations have been used to account for group descriptions that are likely to occur in spatial communications.", "labels": [], "entities": []}, {"text": "Our empirical results have shown that incorporating the most prevalent pattern of collaboration with our hypergraph-based approach significantly improves reference resolution in situated dialogue by an absolute gain of over 18%.", "labels": [], "entities": [{"text": "reference resolution", "start_pos": 154, "end_pos": 174, "type": "TASK", "confidence": 0.7628556787967682}]}], "introductionContent": [{"text": "As more and more applications require humans to interact with robots, techniques to support situated dialogue have become increasingly important.", "labels": [], "entities": []}, {"text": "In situated dialogue, humans and artificial agents (e.g., robots) are co-present in a shared environment to achieve joint tasks.", "labels": [], "entities": []}, {"text": "Their dialogues often involve making references to the environment.", "labels": [], "entities": []}, {"text": "To ensure the conversation proceeds smoothly, it is important to establish a mutual understanding of these references, a process called referential grounding: the agent needs to identify what the human refers to in the environment and the human needs to know whether the agent's understanding is correct; and vice versa.", "labels": [], "entities": []}, {"text": "Although reference resolution and referential grounding) have been studied in previous work, the unique characteristics of situated dialogue post bigger challenges to this problem.", "labels": [], "entities": [{"text": "reference resolution", "start_pos": 9, "end_pos": 29, "type": "TASK", "confidence": 0.8272096514701843}, {"text": "referential grounding", "start_pos": 34, "end_pos": 55, "type": "TASK", "confidence": 0.7726972699165344}]}, {"text": "In situated dialogue, although humans and agents are co-present in a shared world, they have different capabilities in perceiving the environment (a human can perceive and reason about the environment much better than an agent).", "labels": [], "entities": []}, {"text": "The shared perceptual basis, which plays an important role in facilitating referential grounding between the human and the agent, thus is missing.", "labels": [], "entities": [{"text": "referential grounding", "start_pos": 75, "end_pos": 96, "type": "TASK", "confidence": 0.834071934223175}]}, {"text": "Communication between the human and the agent then becomes difficult, and they will need to make extra efforts to jointly mediate a shared basis and reach a mutual understanding.", "labels": [], "entities": []}, {"text": "The goal of this paper is to investigate what kinds of collaborative efforts may happen under mismatched perceptual capabilities and how such collaborations can be incorporated into our referential grounding algorithm.", "labels": [], "entities": []}, {"text": "Previous psycholinguistic studies have indicated that grounding references is a collaborative process (i.e., collaborative referring): The process begins with one participant presenting an initial referring expression.", "labels": [], "entities": [{"text": "collaborative referring)", "start_pos": 109, "end_pos": 133, "type": "TASK", "confidence": 0.790220300356547}]}, {"text": "The other participant would then either accept it, reject it, or postpone the decision.", "labels": [], "entities": []}, {"text": "If a presentation is not accepted, then either one participant or the other needs to refashion it.", "labels": [], "entities": []}, {"text": "This new presentation (i.e., the refashioned expression) is then judged again, and the process continues until the current presentation is accepted.", "labels": [], "entities": []}, {"text": "To understand the implication of collaborative referring under the situation of mismatched perceptual capabilities, we have conducted experiments on human-human conversation using a novel experimental setup.", "labels": [], "entities": []}, {"text": "Our collected data demonstrate an overwhelming use of collaborative referring to mediate a shared perceptual basis.", "labels": [], "entities": []}, {"text": "Motivated by these observations, we have developed an approach that explicitly incorporates collaborative referring into a graph-matching algorithm for referential grounding.", "labels": [], "entities": [{"text": "referential grounding", "start_pos": 152, "end_pos": 173, "type": "TASK", "confidence": 0.907901406288147}]}, {"text": "As the conversation unfolds, our approach incrementally builds a dialogue graph by keeping track of the contributions (i.e., presentation and acceptance) from both the human and the robot.", "labels": [], "entities": []}, {"text": "This dialogue graph is then matched against the perceived environment (i.e., a vision graph representing what are perceived by the robot from the environment) in order to resolve referring expressions from the human.", "labels": [], "entities": []}, {"text": "In addition, in contrast to our previous graph-based approach (, the new approach applies hypergraphs: a more general and flexible representation that can capture groupbased (n-ary) relations (whereas a regular graph can only model binary relations between two entities).", "labels": [], "entities": []}, {"text": "Our empirical results have shown that, incorporating the most prevalent pattern of collaboration (i.e., agent-present-human-accept, discussed later) with the hypergraph-based approach significantly improves reference resolution in situated dialogue by an absolute gain of over 18%.", "labels": [], "entities": [{"text": "reference resolution", "start_pos": 207, "end_pos": 227, "type": "TASK", "confidence": 0.7438640892505646}]}, {"text": "In the following sections, we first give a brief discussion about the related work.", "labels": [], "entities": []}, {"text": "We then describe our experiment setting and the patterns of collaboration observed in the collected data.", "labels": [], "entities": []}, {"text": "We then illustrate how to build a dialogue graph as the conversation unfolds, followed by the formal definition of the hypergraph representation and the referential grounding procedure.", "labels": [], "entities": []}, {"text": "Finally we demonstrate the advantage of using hypergraphs and incorporating a prevalent collaborative behavior into the graph-matching approach for reference resolution.", "labels": [], "entities": [{"text": "reference resolution", "start_pos": 148, "end_pos": 168, "type": "TASK", "confidence": 0.8817070722579956}]}], "datasetContent": [{"text": "To investigate collaborative referring under mismatched perceptual capabilities, we conducted experiments on human-human interaction (details of the experimental setup can be found in ().", "labels": [], "entities": []}, {"text": "In these experiments, we have two human subjects play a set of naming games.", "labels": [], "entities": []}, {"text": "One subject (referred to as the human-player) is provided with an original image containing over ten objects).", "labels": [], "entities": []}, {"text": "Several of these objects have secret names.", "labels": [], "entities": []}, {"text": "The other subject (referred to as the robot-player) only has access to an impoverished image of the same scene) to mimic the lower perceptual capability of a robot.", "labels": [], "entities": []}, {"text": "The human-player's goal is to communicate the names of target objects to the robot-player so that the robot-player knows which object in his view has what name.", "labels": [], "entities": []}, {"text": "The impoverished image was automatically created by applying standard computer vision algorithms and thus may contain different types of processing errors (e.g., mis-segmentation and/or mis-recognition).", "labels": [], "entities": []}, {"text": "Using this setup, we have collected a set of dialogues.", "labels": [], "entities": []}, {"text": "Because I do see a yellow pepper in the upper right H: the upper right of the four of them?", "labels": [], "entities": []}, {"text": "R : yes H: ok, so that is basically the one to the right of the blue cup R : yeah H: that is actually an apple, it is green, I guess it has some amount of yellow on it, but that is a green apple and it is named Ashley . .", "labels": [], "entities": []}, {"text": "This example demonstrates two important characteristics regarding referential communication under mismatched perceptual capabilities.", "labels": [], "entities": [{"text": "referential communication", "start_pos": 66, "end_pos": 91, "type": "TASK", "confidence": 0.919969230890274}]}, {"text": "First, conversation partners rely on both object-specific properties (e.g., object class, color) and spatial relations to describe objects in the environment.", "labels": [], "entities": []}, {"text": "Spatial expressions include not only the binary relations (e.g., \"the one to the left of the blue cup\"), but also the group-based references) (e.g., \"the upper right of the four of them\").", "labels": [], "entities": []}, {"text": "Second, because the shared perceptual basis is missing here, the partners make extra efforts to refer and ground references.", "labels": [], "entities": []}, {"text": "For example, the human-player go through step-by-step installments) to come to the targeted object.", "labels": [], "entities": []}, {"text": "The robot-player often proactively provides what he perceives from the environment.", "labels": [], "entities": []}, {"text": "The human-player and the robotplayer collaborate with each other through iterative presentation-acceptance phases as described in the Contribution Model proposed in).", "labels": [], "entities": []}, {"text": "These observations indicate that, the approach to referential grounding in situated dialogue should capture not only binary relations but also group-based relations.", "labels": [], "entities": []}, {"text": "Furthermore, it should go beyond traditional approaches that purely rely on semantic constraints from single utterances.", "labels": [], "entities": []}, {"text": "It should incorporate the step-by-step collaborative dynamics from the discourse as the conversation proceeds.", "labels": [], "entities": []}, {"text": "A total of 32 dialogues collected from our experiments (as described in Section 3) are used in the evaluation.", "labels": [], "entities": []}, {"text": "For each of these dialogues, we have manually annotated (turn-by-turn) the formal semantics, discourse coreferences and grounded nodes as described in Section 4.3.2.", "labels": [], "entities": []}, {"text": "Since the focus of this paper is on incorporating collaboration into graph matching for referential grounding, we use these annotations to build the dialogue graphs in our evaluation.", "labels": [], "entities": [{"text": "referential grounding", "start_pos": 88, "end_pos": 109, "type": "TASK", "confidence": 0.8815236389636993}]}, {"text": "Vision graphs are automatically generated by CV algorithms from the original images used in the experiments.", "labels": [], "entities": []}, {"text": "The CV algorithms' object recognition performance is rather low: only 5% of the objects in those images are correctly recognized.", "labels": [], "entities": [{"text": "object recognition", "start_pos": 19, "end_pos": 37, "type": "TASK", "confidence": 0.7796874344348907}]}, {"text": "Thus reference resolution will need to rely on relations and collaborative strategies.", "labels": [], "entities": [{"text": "reference resolution", "start_pos": 5, "end_pos": 25, "type": "TASK", "confidence": 0.9752002060413361}]}, {"text": "The 32 dialogue graphs have a total of 384 nodes 8 that are generated from human-players' utterances (12 per dialogue on average), and a total of 307 nodes generated from robot-players' utterances (10 per dialogue on average).", "labels": [], "entities": []}, {"text": "Among the 307 robot-player generated nodes, 187 (61%) are initially presented by the robot-player and then coreferred by human-players' following utterances (i.e., relevant next turns).", "labels": [], "entities": []}, {"text": "This indicates that the agent-present-human-accept strategy is a prevalent way to collaborate in our experiment.", "labels": [], "entities": []}, {"text": "As mentioned earlier, those human-player generated nodes which corefer to nodes initiated by robotplayers are marked as grounded nodes.", "labels": [], "entities": []}, {"text": "In total, 187 out of the 384 human-player generated nodes are in fact grounded nodes.", "labels": [], "entities": []}, {"text": "To evaluate our approach, we apply the graphmatching algorithm on each pair of dialogue graph and vision graph.", "labels": [], "entities": []}, {"text": "The matching results are compared with the annotated ground-truth to calculate the accuracy of our approach in grounding human-players' referring descriptions to visual objects.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.9996463060379028}, {"text": "grounding human-players' referring descriptions to visual objects", "start_pos": 111, "end_pos": 176, "type": "TASK", "confidence": 0.6982090898922512}]}, {"text": "For each dialogue, we have produced matching results under four different settings: with/without modeling collaborative referring (i.e., the agent-present-human-accept collaboration) and with/without using hypergraphs.", "labels": [], "entities": []}, {"text": "When collaborative referring is modeled, the graph-matching algorithm uses the grounded nodes to constrain its search space to match the remaining ungrounded nodes.", "labels": [], "entities": []}, {"text": "When collaborative referring is not modeled, all the human-player generated nodes need to be matched.", "labels": [], "entities": []}, {"text": "The results of four different settings (averaged accuracies on the 32 dialogues) are shown in Table 1.", "labels": [], "entities": []}, {"text": "Modeling collaborative referring improves the matching accuracies for both regular graphs and hypergraphs.", "labels": [], "entities": []}, {"text": "When regular graphs are used, it improves overall matching accuracy by 11.6% (p = 0.05, paired Wilcoxon T-test).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.988303005695343}, {"text": "paired Wilcoxon T-test", "start_pos": 88, "end_pos": 110, "type": "METRIC", "confidence": 0.5896920462449392}]}, {"text": "The improvement is even higher as 18.3% when hypergraphs are used (p = 0.012, paired Wilcoxon T-test).", "labels": [], "entities": [{"text": "paired Wilcoxon T-test", "start_pos": 78, "end_pos": 100, "type": "METRIC", "confidence": 0.5729464987913767}]}, {"text": "The results indicate that proactively describing what the robot sees to the human to facilitate communication is an important collaborative strategy in referential grounding dialogues.", "labels": [], "entities": [{"text": "referential grounding dialogues", "start_pos": 152, "end_pos": 183, "type": "TASK", "confidence": 0.8535421291987101}]}, {"text": "Humans can often ground the robot presented object via the agent-present-human-accept strategy and use the grounded object as a reference point to further describe other intended object(s), and our graphmatching approach is able to capture and utilize such collaboration pattern to improve the referential grounding accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 316, "end_pos": 324, "type": "METRIC", "confidence": 0.8209203481674194}]}, {"text": "The improvement is more significant when hypergraphs are used.", "labels": [], "entities": []}, {"text": "A potential explanation is that those group-based relations captured by hypergraphs always involve multiple (more than 2) objects (nodes).", "labels": [], "entities": []}, {"text": "If one node in a group-based relation is grounded, all other involved nodes can have a better chance to be correctly matched.: Matching accuracies of three groups of dialogues (all the matching results here are produced using hypergraphs).", "labels": [], "entities": []}, {"text": "Whereas in regular graphs one grounded node can only improve the chance of one other node, since only one-to-one (binary) relations are captured by regular graphs.", "labels": [], "entities": []}, {"text": "To further investigate the effect of modeling collaborative referring, we divide the 32 dialogues into three groups according to how often the agent-present-human-accept collaboration pattern happens (measured by the percentage of the grounded nodes among all the human-player generated nodes in a dialogue).", "labels": [], "entities": []}, {"text": "As shown at the top part of, the agent-present-human-accept pattern happened less often in the dialogues in group 1 (i.e., less than 30% of human-player generated nodes are grounded nodes).", "labels": [], "entities": []}, {"text": "In the dialogues in group 2, robot-players more frequently provided proactive descriptions which led to more grounded nodes.", "labels": [], "entities": []}, {"text": "Robot-players were the most proactive in the dialogues in group 3, thus this group contains the highest percentage of grounded nodes.", "labels": [], "entities": []}, {"text": "Note that, although the dialogues in group 3 contain more proactive contributions from robotplayers, human-players tend to specify less number of properties and relations describing intended objects (as shown in the middle part of).", "labels": [], "entities": []}, {"text": "The matching accuracies for each of the three groups are shown at the bottom part of.", "labels": [], "entities": []}, {"text": "Since the agent-present-human-accept pattern appears less often in group 1, modeling collaborative referring only improves matching accuracy by 7.3%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 132, "end_pos": 140, "type": "METRIC", "confidence": 0.9840419292449951}]}, {"text": "The improvements for group 2 and group 3 are more significant compared to group 1.", "labels": [], "entities": []}, {"text": "However, group 3's improvement is less than group 2, although the dialogues in group 3 contain more proactive contributions from robot-players.", "labels": [], "entities": []}, {"text": "This indicates that in some cases even with modeling collaborative referring, underspecified information from human speakers (human-players in our case) may still be insufficient to identify the intended referents.", "labels": [], "entities": []}, {"text": "Therefore, incorporating a broader range of dialogue strategies to elicit adequate information from humans is also important for successful human-robot communication.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Averaged matching accuracies under four  different settings.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 28, "end_pos": 38, "type": "METRIC", "confidence": 0.5832616090774536}]}, {"text": " Table 2: Matching accuracies of three groups of  dialogues (all the matching results here are pro- duced using hypergraphs).", "labels": [], "entities": []}]}