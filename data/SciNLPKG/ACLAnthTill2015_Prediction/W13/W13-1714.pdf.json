{"title": [{"text": "Maximizing Classification Accuracy in Native Language Identification", "labels": [], "entities": [{"text": "Maximizing Classification", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.9646058976650238}, {"text": "Accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9142611026763916}, {"text": "Native Language Identification", "start_pos": 38, "end_pos": 68, "type": "TASK", "confidence": 0.6495877504348755}]}], "abstractContent": [{"text": "This paper reports our contribution to the 2013 NLI Shared Task.", "labels": [], "entities": [{"text": "2013 NLI Shared Task", "start_pos": 43, "end_pos": 63, "type": "DATASET", "confidence": 0.8378051221370697}]}, {"text": "The purpose of the task was to train a machine-learning system to identify the native-language affiliations of 1,100 texts written in English by nonnative speakers as part of a high-stakes test of general academic English proficiency.", "labels": [], "entities": [{"text": "identify the native-language affiliations of 1,100 texts written in English by nonnative speakers", "start_pos": 66, "end_pos": 163, "type": "TASK", "confidence": 0.7624070506829482}]}, {"text": "We trained our system on the new TOEFL11 corpus, which includes 11,000 essays written by nonnative speakers from 11 native-language backgrounds.", "labels": [], "entities": [{"text": "TOEFL11 corpus", "start_pos": 33, "end_pos": 47, "type": "DATASET", "confidence": 0.922329843044281}]}, {"text": "Our final system used an SVM classifier with over 400,000 unique features consisting of lexical and POS n-grams occurring in at least two texts in the training set.", "labels": [], "entities": []}, {"text": "Our system identified the correct native-language affiliations of 83.6% of the texts in the test set.", "labels": [], "entities": []}, {"text": "This was the highest classification accuracy achieved in the 2013 NLI Shared Task.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9195539355278015}, {"text": "2013 NLI Shared Task", "start_pos": 61, "end_pos": 81, "type": "DATASET", "confidence": 0.67354816198349}]}], "introductionContent": [{"text": "The problem of automatically identifying a writer's or speaker's first language on the basis of features found in that person's language production is a relatively new but quickly expanding line of inquiry.", "labels": [], "entities": [{"text": "automatically identifying a writer's or speaker's first language", "start_pos": 15, "end_pos": 79, "type": "TASK", "confidence": 0.7788643836975098}]}, {"text": "It seems to have begun in 2001, but most of the studies published in this area have appeared in just the past two years.", "labels": [], "entities": []}, {"text": "Although the practical applications of native-language identification (NLI) are numerous, most of the existing research seems to be motivated by one or the other of two types of questions: (1) questions about the nature and extent of native-language influence in nonnative speakers' speech or writing, and (2) questions about the maximum levels of NLI classification accuracy that are achievable, which includes questions about the technical details of the systems that achieve the best results.", "labels": [], "entities": [{"text": "native-language identification (NLI)", "start_pos": 39, "end_pos": 75, "type": "TASK", "confidence": 0.8811684966087341}, {"text": "NLI classification", "start_pos": 348, "end_pos": 366, "type": "TASK", "confidence": 0.8021941781044006}, {"text": "accuracy", "start_pos": 367, "end_pos": 375, "type": "METRIC", "confidence": 0.7975188493728638}]}, {"text": "Our previous work in this area has been motivated primarily by the former (see the multiple studies in, but in the present study we conform to the goals of the 2013 NLI Shared Task ( ) in a pursuit of the latter.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Distribution of English Proficiency Levels", "labels": [], "entities": [{"text": "Distribution of English Proficiency Levels", "start_pos": 10, "end_pos": 52, "type": "TASK", "confidence": 0.7903615832328796}]}, {"text": " Table 4. The classification  accuracy (or recall) for individual L1s in the final", "labels": [], "entities": [{"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9367846846580505}, {"text": "recall", "start_pos": 43, "end_pos": 49, "type": "METRIC", "confidence": 0.9544617533683777}]}, {"text": " Table 4: Final NLI Results", "labels": [], "entities": [{"text": "Final NLI", "start_pos": 10, "end_pos": 19, "type": "DATASET", "confidence": 0.6834977567195892}]}]}