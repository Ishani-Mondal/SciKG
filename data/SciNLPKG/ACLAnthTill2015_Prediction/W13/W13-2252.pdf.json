{"title": [{"text": "Are ACT's scores increasing with better translation quality?", "labels": [], "entities": [{"text": "ACT's", "start_pos": 4, "end_pos": 9, "type": "DATASET", "confidence": 0.7039089500904083}]}], "abstractContent": [{"text": "This paper gives a detailed description of the ACT (Accuracy of Connective Translation) metric, a reference-based metric that assesses only connective translations.", "labels": [], "entities": [{"text": "ACT (Accuracy of Connective Translation)", "start_pos": 47, "end_pos": 87, "type": "TASK", "confidence": 0.8426982590130397}]}, {"text": "ACT relies on automatic word-level alignment (using GIZA++) between a source sentence and respectively the reference and candidate translations, along with other heuristics for comparing translations of discourse connectives.", "labels": [], "entities": [{"text": "word-level alignment", "start_pos": 24, "end_pos": 44, "type": "TASK", "confidence": 0.6427348852157593}]}, {"text": "Using a dictionary of equivalents, the translations are scored automatically or, for more accuracy , semi-automatically.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.996593177318573}]}, {"text": "The accuracy of the ACT metric was assessed by human judges on sample data for English/French, English/Arabic, English/Italian and En-glish/German translations; the ACT scores are within 2-5% of human scores.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9996904134750366}]}, {"text": "The actual version of ACT is available only fora limited language pairs.", "labels": [], "entities": []}, {"text": "Consequently , we are participating only for the English/French and English/German language pairs.", "labels": [], "entities": []}, {"text": "Our hypothesis is that ACT metric scores increase with better translation quality in terms of human evaluation.", "labels": [], "entities": [{"text": "ACT metric scores", "start_pos": 23, "end_pos": 40, "type": "METRIC", "confidence": 0.8756803274154663}]}], "introductionContent": [{"text": "Discourse connectives should preserve their sense during translation, as they are often ambiguous and may convey more than one sense depending on the inter-sentential relation (causality, concession, contrast or temporal).", "labels": [], "entities": []}, {"text": "For instance, since in English can express temporal simultaneity, but also a causal sense.", "labels": [], "entities": []}, {"text": "In this paper, we present results of different Machine Translation systems for English-to-French and English-to-German pairs.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 47, "end_pos": 66, "type": "TASK", "confidence": 0.7677800953388214}]}, {"text": "More specifically, we measure the quality of machine translations of eight English discourse connectives: although, even though, meanwhile, since, though, while, however, and yet, adopting different approaches.", "labels": [], "entities": []}, {"text": "This quality is measured using a dedicated metric named ACT (Accuracy of Connective Translation), a reference-based metric that assesses only connective translations.", "labels": [], "entities": [{"text": "ACT (Accuracy of Connective Translation)", "start_pos": 56, "end_pos": 96, "type": "TASK", "confidence": 0.7823348045349121}]}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we present the ACT metric and its error rate.", "labels": [], "entities": [{"text": "ACT metric", "start_pos": 29, "end_pos": 39, "type": "METRIC", "confidence": 0.8826749324798584}, {"text": "error rate", "start_pos": 48, "end_pos": 58, "type": "METRIC", "confidence": 0.9772544801235199}]}, {"text": "In section 3, we compare the ACT metric to previous machine translation evaluation metrics.", "labels": [], "entities": [{"text": "ACT metric", "start_pos": 29, "end_pos": 39, "type": "METRIC", "confidence": 0.9601058959960938}, {"text": "machine translation evaluation", "start_pos": 52, "end_pos": 82, "type": "TASK", "confidence": 0.8432997862497965}]}, {"text": "Finally, we present the results of the different English-toGerman and English-to-French MT systems (Section 4).", "labels": [], "entities": [{"text": "MT", "start_pos": 88, "end_pos": 90, "type": "TASK", "confidence": 0.8233908414840698}]}], "datasetContent": [{"text": "We used the ACT metric to assess connective translations for 21 English-German systems and 23 English-French systems.", "labels": [], "entities": [{"text": "connective translations", "start_pos": 33, "end_pos": 56, "type": "TASK", "confidence": 0.7500686049461365}]}, {"text": "It was computed on tokenized and lower-cased text using its second configuration \"without training\".", "labels": [], "entities": []}, {"text": "shows only ACTa scores for the English-to-German translation systems since ACTa5+6 gives the same rank as ACTa.", "labels": [], "entities": [{"text": "ACTa", "start_pos": 106, "end_pos": 110, "type": "DATASET", "confidence": 0.8727037906646729}]}, {"text": "present the same for the English-to-French systems.", "labels": [], "entities": []}, {"text": "We are not presenting ACTm either because we didn't check manually case 5 and case 6.: Metric scores for all En-De systems: ACTa and ACTa5+6 scores give the same rank; ACT V1.7.", "labels": [], "entities": [{"text": "ACTm", "start_pos": 22, "end_pos": 26, "type": "METRIC", "confidence": 0.638432502746582}, {"text": "Metric", "start_pos": 87, "end_pos": 93, "type": "METRIC", "confidence": 0.9604379534721375}, {"text": "ACT V1.7", "start_pos": 168, "end_pos": 176, "type": "METRIC", "confidence": 0.8977586030960083}]}, {"text": "SD is the Standard Deviation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Metric scores for all En-De systems:  ACTa and ACTa5+6 scores give the same rank;  ACT V1.7. SD is the Standard Deviation.", "labels": [], "entities": [{"text": "ACTa", "start_pos": 48, "end_pos": 52, "type": "DATASET", "confidence": 0.785207211971283}, {"text": "ACT V1.7", "start_pos": 93, "end_pos": 101, "type": "METRIC", "confidence": 0.8722313642501831}]}, {"text": " Table 2: Metric scores for all En-Fr systems:  ACTa and ACTa5+6 scores give the same rank;  ACT V1.7. SD is the Standard Deviation.", "labels": [], "entities": [{"text": "ACTa", "start_pos": 48, "end_pos": 52, "type": "DATASET", "confidence": 0.6930185556411743}, {"text": "ACT V1.7", "start_pos": 93, "end_pos": 101, "type": "METRIC", "confidence": 0.8852661848068237}]}]}