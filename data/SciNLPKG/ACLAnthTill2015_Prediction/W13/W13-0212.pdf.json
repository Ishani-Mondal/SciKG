{"title": [{"text": "A Pilot Experiment in Knowledge Authoring as Dialogue *", "labels": [], "entities": [{"text": "Knowledge Authoring", "start_pos": 22, "end_pos": 41, "type": "TASK", "confidence": 0.7194029688835144}]}], "abstractContent": [{"text": "This project aims to build an ontology authoring interface in which the user is engaged in a dialogue with the system in controlled natural language.", "labels": [], "entities": []}, {"text": "To investigate what such a dialogue might be like, a layered annotation scheme is being developed for interactions between ontology authors and the Prot\u00e9g\u00e9 ontology authoring environment.", "labels": [], "entities": []}, {"text": "A pilot experiment has been conducted with ontology authors, which reveals the complexity of mapping between user-interface actions and acts that appear in natural language dialogues; it also suggests the addition of some unanticipated types of dialogue acts and points the way to some possible enhancements of the authoring interface.", "labels": [], "entities": []}], "introductionContent": [{"text": "Ontology authoring -the process of creating and modifying an ontology in order to capture the knowledge about a domain -is hard.", "labels": [], "entities": [{"text": "Ontology authoring -the process of creating and modifying an ontology in order to capture the knowledge about a domain", "start_pos": 0, "end_pos": 118, "type": "Description", "confidence": 0.8384990096092224}]}, {"text": "Studies such as () and (), for example, have shown that ontology authors frequently misunderstand axioms in the ontology.", "labels": [], "entities": []}, {"text": "These studies also suggest that current ontology authoring tools fail to support some of the actions that authors would like to perform, and that users would like to be warned against potential mis-uses of axioms and unforeseen consequences of those axioms.", "labels": [], "entities": []}, {"text": "This paper reports on work in progress, in which we study the interaction of human users with an ontology authoring interface, with the ultimate aim of developing a tool that will permit a much richer knowledge authoring experience, thereby addressing the above-mentioned problems associated with existing knowledge authoring.", "labels": [], "entities": [{"text": "knowledge authoring", "start_pos": 306, "end_pos": 325, "type": "TASK", "confidence": 0.7750211358070374}]}, {"text": "We envisage developing a plugin to the knowledge authoring interface Prot\u00e9g\u00e9 1 that will allow authors to interact with the ontology via a controlled natural language (CNL) dialogue that offers users some of the freedom of natural language without causing insurmountable natural language understanding problems to the system.", "labels": [], "entities": []}, {"text": "Specifically, we report on a pilot experiment in which we observed human editors who were invited to use Prot\u00e9g\u00e9 while talking to an experimenter, and on a layered annotation scheme that we are developing for annotating the resulting interactions.", "labels": [], "entities": []}, {"text": "Once a stable annotation scheme has been reached, we shall use the scheme to obtain annotations involving a larger number of users and a larger number of knowledge authoring tasks, the results of which will inform the design of the new knowledge authoring interface.", "labels": [], "entities": []}, {"text": "In this paper, we focus on the following questions: \u2022 If knowledge authoring is viewed as a dialogue, what would be the main moves that one would expect to see in these dialogues?", "labels": [], "entities": [{"text": "knowledge authoring", "start_pos": 57, "end_pos": 76, "type": "TASK", "confidence": 0.7129927575588226}]}, {"text": "\u2022 How are these dialogue moves grounded in lower-level actions like \"Finding subsumers fora given concept\", or \"Looking at a concept\"?", "labels": [], "entities": []}, {"text": "\u2022 How does the annotation of a knowledge authoring dialogue compare to the annotation of real spoken dialogue?", "labels": [], "entities": []}, {"text": "Ontology authoring aided by CNL has been addressed from various points.", "labels": [], "entities": [{"text": "Ontology authoring", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8960081040859222}, {"text": "CNL", "start_pos": 28, "end_pos": 31, "type": "DATASET", "confidence": 0.9606954455375671}]}, {"text": "ACE) and PENG) allow users to express specifications that can be translated into an unambiguous logical language, understandable to machines.", "labels": [], "entities": [{"text": "ACE", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8385917544364929}, {"text": "PENG", "start_pos": 9, "end_pos": 13, "type": "METRIC", "confidence": 0.8692272305488586}]}, {"text": "CLCE) resembles ACE but, being closer to English, its output is more readable.", "labels": [], "entities": []}, {"text": "SWAT uses natural language generation to enable users to produce description logic statements.", "labels": [], "entities": []}, {"text": "Similar to CLCE, ()'s work is another example of a novel controlled language capable of assisting ontology authoring.", "labels": [], "entities": [{"text": "ontology authoring", "start_pos": 98, "end_pos": 116, "type": "TASK", "confidence": 0.7897424101829529}]}, {"text": "Whereas this previous work has addressed the problem of producing isolated utterances relevant to knowledge authoring using CNL, this project attempts to further develop knowledge authoring by adopting new interactive methods inspired by human dialogue.", "labels": [], "entities": [{"text": "knowledge authoring", "start_pos": 98, "end_pos": 117, "type": "TASK", "confidence": 0.7092120349407196}, {"text": "knowledge authoring", "start_pos": 170, "end_pos": 189, "type": "TASK", "confidence": 0.7093992233276367}]}, {"text": "For example, we hypothesise that by allowing an author to pose what-if questions prior to authoring an axiom in an ontology, the authoring process will run in a more informed manner.", "labels": [], "entities": []}, {"text": "The following dialogue is an example of the type of communication that this project is attempting to make possible during knowledge authoring:", "labels": [], "entities": [{"text": "knowledge authoring", "start_pos": 122, "end_pos": 141, "type": "TASK", "confidence": 0.7507331073284149}]}], "datasetContent": [{"text": "The 5 participants in the pilot study were computer scientists who were experienced users of OWL and Prot\u00e9g\u00e9.", "labels": [], "entities": [{"text": "OWL", "start_pos": 93, "end_pos": 96, "type": "DATASET", "confidence": 0.948353111743927}, {"text": "Prot\u00e9g\u00e9", "start_pos": 101, "end_pos": 108, "type": "DATASET", "confidence": 0.8809536695480347}]}, {"text": "They were asked to setup the Prot\u00e9g\u00e9 interface as they normally operated it.", "labels": [], "entities": []}, {"text": "They were asked to explore the People and Pet ontology acquired from the Tones repository 2 , and manipulate it as they saw fit.", "labels": [], "entities": [{"text": "Tones repository 2", "start_pos": 73, "end_pos": 91, "type": "DATASET", "confidence": 0.8298200170199076}]}, {"text": "They were asked to follow the think aloud protocol, and describe their moves.", "labels": [], "entities": []}, {"text": "In addition, their interactions and eye movements were video-recorded.", "labels": [], "entities": []}, {"text": "Where the experimenters were unclear about a description of what was happening, they asked the subject for clarification.", "labels": [], "entities": []}, {"text": "Occasionally, when the subject felt unsure how to proceed, the experimenter suggested an action (for example, Why don't you look at the axioms now appearing in red?\")", "labels": [], "entities": []}, {"text": "Knowledge authoring sessions were annotated with reference to the scheme outlined above but, crucially, annotators wrote annotations in a free style: the interface did not limit them to a fixed set of labels implied by our initial annotation scheme.", "labels": [], "entities": []}, {"text": "A small annotated segment of one session is presented in.", "labels": [], "entities": []}, {"text": "In the speech/action column, speech refers to the user's comments and is displayed within quotations, and actions refers to the physical interactions between the user and the Prot\u00e9g\u00e9 interface.", "labels": [], "entities": []}, {"text": "Our initial intuitions about dialogue acts were shown to be far from perfect.", "labels": [], "entities": []}, {"text": "Perhaps unsurprisingly, it became clear that the mapping between KLM, Prot\u00e9g\u00e9 and dialogue levels can be very complex.", "labels": [], "entities": []}, {"text": "An annotation in one layer can correspond to more than one in another layer.", "labels": [], "entities": []}, {"text": "For example, a subject may observe the definition or the location in the hierarchy of a concept for various conceptual reasons, for instance to check consistency (a Check Question in our scheme) or to prepare for adding anew concept (an Additive Command).", "labels": [], "entities": [{"text": "consistency", "start_pos": 150, "end_pos": 161, "type": "METRIC", "confidence": 0.9677491188049316}]}, {"text": "Difficulties of a similar kind are well known from the annotation of natural language dialogue, for instance whether a given spoken utterance (for example, \"You are 29 years old\") has declarative or interrogative meaning.", "labels": [], "entities": []}, {"text": "It also became clear that a separate category is required where a command is both Additive and Retracting at the same time, such as a Modifying Command.", "labels": [], "entities": []}, {"text": "Furthermore, as displayed in at 9:08, an action atone layer may not correspond to an action in another layer at all.", "labels": [], "entities": []}, {"text": "Most interestingly, we discovered that knowledge authoring is full of what we call Hidden Acts, which do not correspond with actual Prot\u00e9g\u00e9 actions, but which turnout to play an important role in the interaction, as evidenced by subjects' spoken utterances.", "labels": [], "entities": [{"text": "knowledge authoring", "start_pos": 39, "end_pos": 58, "type": "TASK", "confidence": 0.7585256099700928}]}, {"text": "These include, most prominently, various types of goal handling, such as the adoption, revision, satisfaction, and abandonment of goals.", "labels": [], "entities": [{"text": "goal handling", "start_pos": 50, "end_pos": 63, "type": "TASK", "confidence": 0.7673770785331726}, {"text": "adoption, revision", "start_pos": 77, "end_pos": 95, "type": "TASK", "confidence": 0.7340634266535441}]}, {"text": "At the dialogue level, these correspond to the expression of desires (when a goal is set aside for later) and intentions (when a goal is starting to be pursued).", "labels": [], "entities": []}, {"text": "How does our annotation scheme compare to schemes for the analysis of natural language dialogue, such as the ISO-standard of?", "labels": [], "entities": [{"text": "analysis of natural language dialogue", "start_pos": 58, "end_pos": 95, "type": "TASK", "confidence": 0.6122929155826569}]}, {"text": "Similarities with our own scheme are easy to find: the distinction between information seeking and informative providing is an obvious example.", "labels": [], "entities": []}, {"text": "Important differences exist as well.", "labels": [], "entities": []}, {"text": "The ISO standard has been developed for annotating a wide class of dialogues.", "labels": [], "entities": [{"text": "ISO standard", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.8516274988651276}]}, {"text": "Our own scheme targets a specific kind of \"asymmetric\" dialogue, between a person and a machine.", "labels": [], "entities": []}, {"text": "Goals can only be expressed by the person; what-if questions can only be posed by the person (the system responds, for example, with an Expressive Statement).", "labels": [], "entities": []}, {"text": "Furthermore, the person cannot, at present, make Expressive Statements (given that the addition of an axiom has been modelled as a Command).", "labels": [], "entities": []}, {"text": "Proposals (as opposed to Commands) are only open to the system.", "labels": [], "entities": []}, {"text": "Perhaps the most interesting differences between the two schemes relate to the expression of goals, which appears to be absent from the ISO standard.", "labels": [], "entities": [{"text": "ISO standard", "start_pos": 136, "end_pos": 148, "type": "DATASET", "confidence": 0.8978331089019775}]}, {"text": "A few other natural-language related annotation schemes (e.g, () do allow the expression of \"desires\", though the distinction between desires and intentions -reminiscent of Bratmanstyle \"Beliefs, Desires and Intentions\" (Bratman, 1999) -is not made.", "labels": [], "entities": [{"text": "Bratmanstyle \"Beliefs, Desires and Intentions\" (Bratman, 1999)", "start_pos": 173, "end_pos": 235, "type": "TASK", "confidence": 0.6563632579950186}]}], "tableCaptions": []}