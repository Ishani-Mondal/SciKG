{"title": [{"text": "Hierarchical Alignment Decomposition Labels for Hiero Grammar Rules", "labels": [], "entities": [{"text": "Hierarchical Alignment Decomposition Labels", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.8334477841854095}, {"text": "Hiero Grammar", "start_pos": 48, "end_pos": 61, "type": "TASK", "confidence": 0.6567925810813904}]}], "abstractContent": [{"text": "Selecting a set of nonterminals for the synchronous CFGs underlying the hierarchical phrase-based models is usually done on the basis of a monolingual resource (like a syntactic parser).", "labels": [], "entities": []}, {"text": "However, a standard bilingual resource like word alignments is itself rich with reordering patterns that, if clustered somehow , might provide labels of different (pos-sibly complementary) nature to monolingual labels.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 44, "end_pos": 59, "type": "TASK", "confidence": 0.6907828897237778}]}, {"text": "In this paper we explore a first version of this idea based on a hierarchical decomposition of word alignments into recursive tree representations.", "labels": [], "entities": []}, {"text": "We identify five clusters of alignment patterns in which the children of anode in a decomposition tree are found and employ these five as nonterminal labels for the Hiero productions.", "labels": [], "entities": [{"text": "Hiero productions", "start_pos": 165, "end_pos": 182, "type": "DATASET", "confidence": 0.8425049781799316}]}, {"text": "Although this is our first non-optimized instantiation of the idea, our experiments show competitive performance with the Hiero baseline, exemplifying certain merits of this novel approach.", "labels": [], "entities": [{"text": "Hiero baseline", "start_pos": 122, "end_pos": 136, "type": "DATASET", "confidence": 0.8879377841949463}]}], "introductionContent": [{"text": "The Hiero model formulates phrase-based translation in terms of asynchronous context-free grammar (SCFG) limited to the inversion transduction grammar (ITG) family.", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 27, "end_pos": 51, "type": "TASK", "confidence": 0.6417383700609207}]}, {"text": "While the original Hiero approach works with a single nonterminal label (X) (besides the start nonterminal S ), more recent work is dedicated to devising methods for extracting more elaborate labels for the phrase-pairs and their abstractions into SCFG productions, e.g., ().", "labels": [], "entities": []}, {"text": "All labeling approaches exploit monolingual parsers of some kind, e.g., syntactic, semantic or sense-oriented.", "labels": [], "entities": []}, {"text": "The rationale behind monolingual labeling is often to make the probability distributions over alternative synchronous derivations of the Hiero model more sensitive to linguistically justified monolingual phrase context.", "labels": [], "entities": []}, {"text": "For example, syntactic target-language labels in many approaches are aimed at improved target language modeling (fluency, cf.;), whereas source-language labels provide suitable context for reordering (see).", "labels": [], "entities": []}, {"text": "It is usually believed that the monolingual labels tend to stand for clusters of phrase pairs that are expected to be intersubstitutable, either syntactically or semantically (see for an illuminating discussion).", "labels": [], "entities": []}, {"text": "While we believe that monolingual labeling strategies are sound, in this paper we explore the complementary idea that the nonterminal labels could also signify bilingual properties of the phrase pair, particularly its characteristic word alignment patterns.", "labels": [], "entities": []}, {"text": "Intuitively, an SCFG with nonterminal labels standing for alignment patterns should put more preference on synchronous derivations that mimic the word alignment patterns found in the training corpus, and thus, possibly allow for better reordering.", "labels": [], "entities": []}, {"text": "It is important to stress the fact that these word alignment patterns are complementary to the monolingual linguistic patterns and it is conceivable that the two can be combined effectively, but this remains beyond the scope of this article.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 46, "end_pos": 60, "type": "TASK", "confidence": 0.7095792889595032}]}, {"text": "The question addressed in this paper is how to select word alignment patterns and cluster them into bilingual nonterminal labels?", "labels": [], "entities": [{"text": "word alignment patterns", "start_pos": 54, "end_pos": 77, "type": "TASK", "confidence": 0.7793543736139933}]}, {"text": "In this paper we explore a first instantiation of this idea starting out from the following simplifying assumptions: \u2022 The labels come from the word alignments only, \u2022 The labels are coarse-grained, pre-defined clusters and not optimized for performance, \u2022 The labels extend the binary set of ITG operators (monotone and inverted) into five such labels in order to cover non-binarizable alignment patterns.", "labels": [], "entities": []}, {"text": "Our labels are based on our own tree decompositions of word alignments (Sima'an and Maillette de Buy Wenniger, 2011), akin to Normalized Decomposition Trees (NDTs) (.", "labels": [], "entities": []}, {"text": "In this first attempt we explore a set of five nonterminal labels that characterize alignment patterns found directly under nodes in the NDT projected for every word alignment in the parallel corpus during training.", "labels": [], "entities": []}, {"text": "There is a range of work that exploits the monotone and inverted orientations of binary ITG within hierarchical phrase-based models, either as feature functions of lexicalized Hiero productions), or as labels on non-lexicalized ITG productions, e.g.,).", "labels": [], "entities": []}, {"text": "As far as we are aware, this is the first attempt at exploring a larger set of such word alignment derived labels in hierarchical SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 130, "end_pos": 133, "type": "TASK", "confidence": 0.7749255895614624}]}, {"text": "Therefore, we expect that there are many variants that could improve substantially on our strong set of assumptions.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our method on one language pair using German as source and English as target.", "labels": [], "entities": []}, {"text": "The data is derived from parliament proceedings sourced from the Europarl corpus (  tor for the generation of all grammars, including the baseline Hiero grammars.", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 65, "end_pos": 80, "type": "DATASET", "confidence": 0.990742415189743}, {"text": "Hiero grammars", "start_pos": 147, "end_pos": 161, "type": "DATASET", "confidence": 0.9247727990150452}]}, {"text": "This enables us to use the same features (as far as applicable given the grammar formalism) and assure true comparability of the grammars under comparison.", "labels": [], "entities": []}, {"text": "Based on experiments reported in) we opted to not label the (fully lexicalized) phrase pairs, but instead label them with a generic PhrasePair label and use a set of switch rules from all other labels to the PhrasePair label to enable transition between Hiero rules and phrase pairs.", "labels": [], "entities": []}, {"text": "We train our systems using PRO (Hopkins and May, 2011) implemented in Joshua by.", "labels": [], "entities": []}, {"text": "We use the standard tuning, where all features are treated as dense features.We allow up to 30 tuning iterations.", "labels": [], "entities": []}, {"text": "We further follow the PRO settings introduced in () but use 0.5 for the coefficient \u03a8 that interpolates the weights learned at the current with those from the previous iteration.", "labels": [], "entities": [{"text": "PRO", "start_pos": 22, "end_pos": 25, "type": "METRIC", "confidence": 0.6059610843658447}]}, {"text": "We use the final learned weights for decoding with the log-linear model and report Lowercase BLEU scores for the tuned test set.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 93, "end_pos": 97, "type": "METRIC", "confidence": 0.9389263987541199}]}, {"text": "We now report Lowercase BLEU scores for more detailed analysis experiments with and without Lattice Minimum Bayes-Risk 5 (MBR) decoding, where we varied other training and decoding parameters in the Moses environment.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 24, "end_pos": 28, "type": "METRIC", "confidence": 0.9824631214141846}, {"text": "Lattice Minimum Bayes-Risk 5 (MBR", "start_pos": 92, "end_pos": 125, "type": "METRIC", "confidence": 0.7365161428848902}]}, {"text": "Particularly, in this set of experiments we choose the best tuning parameter settings over 30 Batch Mira iterations (as opposed to the weights returned by default -used in the previous experiments).", "labels": [], "entities": []}, {"text": "We also explore varieties in tuning with a decoder that works with Viterbi/MBR, and final testing with Viterbi/MBR.", "labels": [], "entities": [{"text": "Viterbi/MBR", "start_pos": 67, "end_pos": 78, "type": "DATASET", "confidence": 0.7195519010225931}, {"text": "Viterbi/MBR", "start_pos": 103, "end_pos": 114, "type": "DATASET", "confidence": 0.8452722231547037}]}, {"text": "In, the top rows show the results of our experiments using MBR decoding.", "labels": [], "entities": []}, {"text": "We display scores We discovered that the Moses chart decoder does not allow fully abstract unary rules in the current implementation, which makes direct usage of unary (switch) rules not possible.", "labels": [], "entities": []}, {"text": "Switch rules and other unaries can still be emulated though, by adapting the grammar, using multiple copies of rules with different labels.", "labels": [], "entities": []}, {"text": "This blows up the grammar a bit, but at least works in practice.", "labels": [], "entities": [{"text": "grammar", "start_pos": 18, "end_pos": 25, "type": "METRIC", "confidence": 0.7903220057487488}]}, {"text": "for the Hiero baseline (Hiero) and the fully/partially alignment labeled systems Hiero-AL and Hiero-AL-PPL.", "labels": [], "entities": [{"text": "Hiero baseline (Hiero)", "start_pos": 8, "end_pos": 30, "type": "DATASET", "confidence": 0.8987262964248657}, {"text": "Hiero-AL", "start_pos": 81, "end_pos": 89, "type": "DATASET", "confidence": 0.961611807346344}, {"text": "Hiero-AL-PPL", "start_pos": 94, "end_pos": 106, "type": "DATASET", "confidence": 0.9435421824455261}]}, {"text": "In the preceding set of experiments MBR decoding clearly showed improved performance over Viterbi, particularly for our labelled system.", "labels": [], "entities": [{"text": "MBR decoding", "start_pos": 36, "end_pos": 48, "type": "TASK", "confidence": 0.715365469455719}]}, {"text": "On the small training set of 200K we observe that the Hiero baseline achieves It is puzzling that Hiero Viterbi (for 1000k) performs better than the same system with MBR decoding systems.", "labels": [], "entities": [{"text": "Hiero baseline", "start_pos": 54, "end_pos": 68, "type": "DATASET", "confidence": 0.8806512951850891}]}, {"text": "But after submission we were told by Moses support that neither normal MBR nor Lattice MBR are operational in Moses Chart.", "labels": [], "entities": [{"text": "Moses support", "start_pos": 37, "end_pos": 50, "type": "DATASET", "confidence": 0.9111867547035217}, {"text": "MBR", "start_pos": 71, "end_pos": 74, "type": "DATASET", "confidence": 0.5332239270210266}, {"text": "Lattice MBR", "start_pos": 79, "end_pos": 90, "type": "DATASET", "confidence": 0.8174384832382202}, {"text": "Moses Chart", "start_pos": 110, "end_pos": 121, "type": "DATASET", "confidence": 0.9853788018226624}]}, {"text": "This means that in fact the effect of MBR on our labels remains still undecided, and more work is still needed in this direction.", "labels": [], "entities": []}, {"text": "The small decrease in performance for the labelled system relative to Hiero (in Viterbi) is possibly the result of the labelled system being more brittle and harder to tune than the Hiero system.", "labels": [], "entities": [{"text": "Hiero", "start_pos": 70, "end_pos": 75, "type": "DATASET", "confidence": 0.9544947743415833}]}, {"text": "This hypothesis needs further exploration.", "labels": [], "entities": []}, {"text": "While a whole set of experimental questions remains open, we think that based on this preliminary but nevertheless considerable set of experiments, it seems that our labels do not always improve performance compared with the Hiero baseline.", "labels": [], "entities": [{"text": "Hiero baseline", "start_pos": 225, "end_pos": 239, "type": "DATASET", "confidence": 0.8349467515945435}]}, {"text": "It is possible that these labels, under a more advanced implementation via soft constraints (as opposed to hard labeling), could provide the empirical evidence to our theoretical choices.", "labels": [], "entities": []}, {"text": "A further concern regarding the labels is that our current choice (5 labels) is heuristic and not optimized for the training data.", "labels": [], "entities": []}, {"text": "It remains to be seen in the future if proper learning of these labels as latent variables optimized for the training data or the use of soft constraints can shed more light on the use of alignment labels in hierarchical SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 221, "end_pos": 224, "type": "TASK", "confidence": 0.7275128960609436}]}], "tableCaptions": [{"text": " Table 1: Initial Results. Lowercase BLEU results for  German-English trained on 200K sentence pairs. 4  Top rows display results for our experiments using Moses  (Hoang et al., 2007) with Lattice Minimum Bayes-Risk  Decoding 5 (Tromble et al., 2008) in combination with  Batch Mira (Cherry and Foster, 2012) for tuning. Below  are results for experiments with Joshua (Ganitkevitch et  al., 2012) using Viterbi decoding (i.e. no MBR) and PRO  (Hopkins and May, 2011) for tuning.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 37, "end_pos": 41, "type": "METRIC", "confidence": 0.9970069527626038}, {"text": "PRO", "start_pos": 438, "end_pos": 441, "type": "METRIC", "confidence": 0.7579472661018372}]}, {"text": " Table 2: Analysis Results. Lowercase BLEU results for  German-English trained on 200K and 1000K sentence  pairs using Moses (Hoang et al., 2007) in combination  with Batch Mira (Cherry and Foster, 2012) for tuning.  Top rows display results for our experiments with Lattice  Minimum Bayes-Risk Decoding 5 (Tromble et al., 2008).  Below are results for experiments using Viterbi decoding  (i.e. no MBR) for tuning. Results on 200K were run with  10 tuning iterations, results on 1000K with 30 tuning it- erations.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 38, "end_pos": 42, "type": "METRIC", "confidence": 0.9943791031837463}, {"text": "MBR", "start_pos": 398, "end_pos": 401, "type": "METRIC", "confidence": 0.8908475637435913}]}]}