{"title": [{"text": "Semantic Technologies in IBM Watson TM", "labels": [], "entities": [{"text": "TM", "start_pos": 36, "end_pos": 38, "type": "TASK", "confidence": 0.822094738483429}]}], "abstractContent": [{"text": "This paper describes a seminar course designed by IBM and Columbia University on the topic of Semantic Technologies, in particular as used in IBM Watson TM-a large scale Question Answering system which famously won at Jeopardy!", "labels": [], "entities": [{"text": "IBM Watson TM-a large scale Question Answering system", "start_pos": 142, "end_pos": 195, "type": "TASK", "confidence": 0.5676363259553909}]}, {"text": "R against two human grand champions.", "labels": [], "entities": [{"text": "R", "start_pos": 0, "end_pos": 1, "type": "METRIC", "confidence": 0.6398398876190186}]}, {"text": "It was first offered at Columbia University during the 2013 spring semester, and will be offered at other institutions starting in the fall semester.", "labels": [], "entities": []}], "introductionContent": [{"text": "In 2007, IBM Research took on the grand challenge of building a computer system that can perform well enough on open-domain question answering to compete with champions at the game of Jeopardy!", "labels": [], "entities": [{"text": "question answering", "start_pos": 124, "end_pos": 142, "type": "TASK", "confidence": 0.720698818564415}]}, {"text": "In 2011, the open-domain question answering system dubbed Watson beat the two highest ranked players in a two-game Jeopardy!", "labels": [], "entities": [{"text": "question answering", "start_pos": 25, "end_pos": 43, "type": "TASK", "confidence": 0.6795360743999481}]}, {"text": "To be successful at Jeopardy!, players must retain enormous amounts of information, must have strong language skills, must be able to understand precisely what is being asked, and must accurately determine the likelihood they know the right answer.", "labels": [], "entities": []}, {"text": "Over a four year period, the team at IBM developed the Watson system that competed on Jeopardy! and the underlying DeepQA question answering technology.", "labels": [], "entities": [{"text": "DeepQA question answering", "start_pos": 115, "end_pos": 140, "type": "TASK", "confidence": 0.7278517882029215}]}, {"text": "Watson played many games of Jeopardy!", "labels": [], "entities": [{"text": "Jeopardy!", "start_pos": 28, "end_pos": 37, "type": "TASK", "confidence": 0.5794627368450165}]}, {"text": "champions and, in games televised in February 2011, won against the greatest players of all time, Ken Jennings and Brad Rutter.", "labels": [], "entities": []}, {"text": "DeepQA has applications well beyond Jeopardy!, however.", "labels": [], "entities": [{"text": "DeepQA", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9024929404258728}]}, {"text": "DeepQA is a software architecture for analyzing natural language content in both questions and knowledge sources.", "labels": [], "entities": [{"text": "DeepQA", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9380424618721008}]}, {"text": "DeepQA discovers and evaluates potential answers and gathers and scores evidence for those answers in both unstructured sources, such as natural language documents, and structured sources such as relational databases and knowledge bases.", "labels": [], "entities": []}, {"text": "presents a high-level view of the DeepQA architecture.", "labels": [], "entities": []}, {"text": "DeepQA utilizes a massively parallel, componentbased pipeline architecture which uses an extensible set of structured and unstructured content sources as well as abroad range of pluggable search and scoring components that allow integration of many different analytic techniques.", "labels": [], "entities": [{"text": "DeepQA", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9336556196212769}]}, {"text": "Machine Learning techniques are used to learn the weights for each scoring component in order to combine them into a single final score.", "labels": [], "entities": []}, {"text": "Watson components include a large variety of state of the art solutions originating in the fields of Natural Language Processing (NLP), Machine Learning (ML), Information Retrieval (IR), Semantic Web and Cloud Computing.", "labels": [], "entities": [{"text": "Information Retrieval (IR)", "start_pos": 159, "end_pos": 185, "type": "TASK", "confidence": 0.8362005114555359}]}, {"text": "IBM is now aggressively investing in turning IBM Watson from a research prototype to an industry level highly adaptable system to be applied in dozens of business ap-: Overview of the DeepQA architecture plications ranging from healthcare to finance.", "labels": [], "entities": []}, {"text": "Finding that particular combination of skills in the entry-level job market is hard: in many cases students have some notion of Machine Learning but are not strong in Natural Language Processing; in other cases they have background in Knowledge Management and some of the basics of Semantic Web, but lack an understanding of statistical models and Machine Learning.", "labels": [], "entities": [{"text": "Knowledge Management", "start_pos": 235, "end_pos": 255, "type": "TASK", "confidence": 0.7325230091810226}]}, {"text": "In most cases semantic integration is not a topic of interest, and so understanding sophisticated platforms like Apache UIMA TM) is a challenge.", "labels": [], "entities": [{"text": "semantic integration", "start_pos": 14, "end_pos": 34, "type": "TASK", "confidence": 0.8839064538478851}]}, {"text": "Learning how to develop the large scale infrastructure and technology needed for IBM Watson prepares students for the real-world challenges of large-scale natural language projects that are common in industry settings and which students have little experience with before graduation.", "labels": [], "entities": []}, {"text": "Of course, IBM is interested in hiring entrylevel students as a powerful way of scaling Watson.", "labels": [], "entities": [{"text": "Watson", "start_pos": 88, "end_pos": 94, "type": "TASK", "confidence": 0.6835117936134338}]}, {"text": "Therefore, it has resolved to start an educational program focused on these topics.", "labels": [], "entities": []}, {"text": "Initially, tutorials were given at scientific conferences (NAACL, ISWC and WWW, among others), universities and summer schools.", "labels": [], "entities": [{"text": "NAACL, ISWC and WWW", "start_pos": 59, "end_pos": 78, "type": "DATASET", "confidence": 0.6832246661186219}]}, {"text": "The great number of attendees (usually in the range of 50 to 150) and strongly positive feedback received from the students was a motivation to transform the didactic material collected so far into a full graduatelevel course, which has been offered for the first time at Columbia University.", "labels": [], "entities": []}, {"text": "The course (which is described in the rest of this paper) received very positive evaluations from the students and will be used as a template to be replicated by other partner universities in the following year.", "labels": [], "entities": []}, {"text": "Our ultimate goal is to develop high quality didactic material for an educational curriculum that can be used by interested universities and professors allover the world.", "labels": [], "entities": []}], "datasetContent": [{"text": "The course at Columbia drew a relatively large audience.", "labels": [], "entities": []}, {"text": "A typical size fora seminar course on a special topic is estimated at 15-20 students, while ours drew 35.", "labels": [], "entities": []}, {"text": "The vast majority were Master's students; there were also three PhD students and five undergraduates.", "labels": [], "entities": []}, {"text": "During the student workshops, students were asked to provide grades for each team's presentation and project.", "labels": [], "entities": []}, {"text": "After the instructor independently gave his own grades, we looked at the correlation between the average grades given by the students and those give by the instructor.", "labels": [], "entities": []}, {"text": "While: Grades assigned to class projects the students tended to be more \"generous\" (their average grade for each team was usually half a grade above the instructor's), the agreement was quite high.", "labels": [], "entities": []}, {"text": "shows the grades given by the instructor, the teaching assistant and the class average for the midterm workshop.", "labels": [], "entities": []}, {"text": "Feedback about the course from the students was very good.", "labels": [], "entities": []}, {"text": "Columbia provides electonic course evaluations to the students which are completely optional.", "labels": [], "entities": [{"text": "Columbia", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9549146294593811}]}, {"text": "Participation in the evaluation for this course was just under 50% in the midterm evaluation and just over 50% in the final evaluation.", "labels": [], "entities": []}, {"text": "The scores (all in the 0-5 range) given by the students in relevant categories were quite high: \"Overall Quality\" got an average score of 4.23, \"Amount Learned\" got 4, \"Appropriateness of Workload\" 4.33 and \"Fairness of Grading Process\" got 4.42.", "labels": [], "entities": [{"text": "Amount", "start_pos": 145, "end_pos": 151, "type": "METRIC", "confidence": 0.9592832922935486}, {"text": "Appropriateness", "start_pos": 169, "end_pos": 184, "type": "METRIC", "confidence": 0.986011266708374}, {"text": "Fairness", "start_pos": 208, "end_pos": 216, "type": "METRIC", "confidence": 0.9598040580749512}]}, {"text": "The course resulted in multiple papers that are or will soon be under submission, as well as a few projects that maybe developed into start-ups.", "labels": [], "entities": []}, {"text": "Almost all student teams agreed to share their code in an open source project that is currently being setup, and which will include the current question answering and semantic search system as well as additional side projects.", "labels": [], "entities": [{"text": "question answering and semantic search", "start_pos": 144, "end_pos": 182, "type": "TASK", "confidence": 0.7907182455062867}]}], "tableCaptions": []}