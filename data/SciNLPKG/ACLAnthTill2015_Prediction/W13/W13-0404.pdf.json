{"title": [{"text": "Evaluating the Use of Empirically Constructed Lexical Resources for Named Entity Recognition", "labels": [], "entities": [{"text": "Named Entity Recognition", "start_pos": 68, "end_pos": 92, "type": "TASK", "confidence": 0.7838594118754069}]}], "abstractContent": [{"text": "Because of privacy concerns and the expense involved in creating an annotated corpus, the existing small annotated corpora might not have sufficient number of examples for statistically learning to extract all the named-entities precisely.", "labels": [], "entities": []}, {"text": "In this work, we evaluate what value may lie in automatically generated features based on distributional semantics when using machine-learning named entity recognition (NER).", "labels": [], "entities": [{"text": "machine-learning named entity recognition (NER)", "start_pos": 126, "end_pos": 173, "type": "TASK", "confidence": 0.7695818628583636}]}, {"text": "The features we generated and experimented with include n-nearest words, support vector machine (SVM)-regions, and term clustering, all of which are considered semantic (or distributional semantic) features.", "labels": [], "entities": [{"text": "term clustering", "start_pos": 115, "end_pos": 130, "type": "TASK", "confidence": 0.6848670393228531}]}, {"text": "The addition of n-nearest words feature resulted in a greater increase in F-score than adding a manually constructed lexicon to a baseline system that extracts medical concepts from clinical notes.", "labels": [], "entities": [{"text": "F-score", "start_pos": 74, "end_pos": 81, "type": "METRIC", "confidence": 0.9987510442733765}]}, {"text": "Although the need for relatively small annotated corpora for retraining is not obviated, lexicons empirically derived from unannotated text cannot only supplement manually created lexicons, but replace them.", "labels": [], "entities": []}, {"text": "This phenomenon is observed in extracting concepts both from biomedical literature and clinical notes.", "labels": [], "entities": []}, {"text": "Background One of the most time-consuming tasks faced by a Natural Language Processing (NLP) researcher or practitioner trying to adapt a machine-learning-based NER system to a different domain is the creation, compilation, and customization of the needed lexicons.", "labels": [], "entities": []}, {"text": "Lexical resources, such as lexicons of concept classes are considered necessary to improve the performance of NER.", "labels": [], "entities": [{"text": "NER", "start_pos": 110, "end_pos": 113, "type": "TASK", "confidence": 0.9591667056083679}]}, {"text": "It is typical for medical informatics researchers to implement modularized systems that cannot be generalized (Stanfill et al. 2010).", "labels": [], "entities": []}, {"text": "As the work of constructing or customizing lexical resources needed for these highly specific systems is human-intensive, automatic generation is a desirable alternative.", "labels": [], "entities": [{"text": "automatic generation", "start_pos": 122, "end_pos": 142, "type": "TASK", "confidence": 0.7387596070766449}]}, {"text": "It might be possible that empirically created lexical resources might incorporate domain knowledge into a machine-learning NER engine and increase its accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 151, "end_pos": 159, "type": "METRIC", "confidence": 0.9936570525169373}]}], "introductionContent": [], "datasetContent": [{"text": "The previous sub-sections detail how the manually created lexicons are compiled and how the empirical lexical resources are generated from semantic vectors (2000 dimensions).", "labels": [], "entities": []}, {"text": "In the respective machine learning system for extracting concepts from literature and clinical notes, each manually created lexicon (three for the clinical notes task) contributes one binary feature whose value depends on whether a term surrounding the word is present in the lexicon.", "labels": [], "entities": []}, {"text": "Each quasi-lexicon will also contribute one binary feature whose value depends on the output of the SVM classifier discussed before.", "labels": [], "entities": []}, {"text": "The distributional semantic clusters together contribute a feature whole value is the id of the cluster the word belongs to.", "labels": [], "entities": []}, {"text": "The quasi-thesaurus contributes 20 features that are the 20 distributionally similar words to the word for which features are being generated.", "labels": [], "entities": []}, {"text": "As a gold standard for clinical NER, the fourth i2b2/VA NLP shared-task corpus (i2b2 2010) for extracting concepts of the classes-problems, treatments, and tests-is used.", "labels": [], "entities": [{"text": "NER", "start_pos": 32, "end_pos": 35, "type": "TASK", "confidence": 0.8923046588897705}, {"text": "VA NLP shared-task corpus (i2b2 2010)", "start_pos": 53, "end_pos": 90, "type": "DATASET", "confidence": 0.8899113908410072}]}, {"text": "The corpus contains 349 clinical notes as training data and 477 clinical notes as testing data.", "labels": [], "entities": []}, {"text": "For protein tagging, the BioCreative II Gene Mention Task (Wilbur, Smith, and Tanabe 2007) corpus is used.", "labels": [], "entities": [{"text": "protein tagging", "start_pos": 4, "end_pos": 19, "type": "TASK", "confidence": 0.6907911747694016}, {"text": "BioCreative II Gene Mention Task (Wilbur, Smith, and Tanabe 2007) corpus", "start_pos": 25, "end_pos": 97, "type": "DATASET", "confidence": 0.6412767151991526}]}, {"text": "The corpus contains 15,000 training set sentences and 5,000 testing set sentences.", "labels": [], "entities": []}, {"text": "MED_Dict is the baseline, which is a machine-learning clinical NER system with several orthographic and syntactic features, along with features from lexicons such as UMLS, Drugs@FDA, and MedDRA.", "labels": [], "entities": []}, {"text": "In MED_Dict+SVM, the quasi-lexicons are also used.", "labels": [], "entities": [{"text": "MED_Dict+SVM", "start_pos": 3, "end_pos": 15, "type": "TASK", "confidence": 0.4630451679229736}]}, {"text": "In MED_Dict+NN, the quasithesaurus is used.", "labels": [], "entities": [{"text": "MED_Dict+NN", "start_pos": 3, "end_pos": 14, "type": "TASK", "confidence": 0.5337739944458008}]}, {"text": "In MED_Dict+CL, the clusters automatically generated are used in addition to other features in MED_Dict.", "labels": [], "entities": []}, {"text": "Exact F is the F-score for exact match as calculated by the shared task software.", "labels": [], "entities": [{"text": "F", "start_pos": 6, "end_pos": 7, "type": "METRIC", "confidence": 0.695490300655365}, {"text": "F-score", "start_pos": 15, "end_pos": 22, "type": "METRIC", "confidence": 0.9979580640792847}, {"text": "exact match", "start_pos": 27, "end_pos": 38, "type": "METRIC", "confidence": 0.8108623921871185}]}, {"text": "Inexact F is the F-score for inexact match or matcing only apart of the other.", "labels": [], "entities": [{"text": "F", "start_pos": 8, "end_pos": 9, "type": "METRIC", "confidence": 0.6111270785331726}, {"text": "F-score", "start_pos": 17, "end_pos": 24, "type": "METRIC", "confidence": 0.9987348914146423}]}, {"text": "Exact Increase is the increase in Exact F from previous row.", "labels": [], "entities": [{"text": "Exact Increase", "start_pos": 0, "end_pos": 14, "type": "METRIC", "confidence": 0.9048776924610138}, {"text": "Exact F", "start_pos": 34, "end_pos": 41, "type": "METRIC", "confidence": 0.9491027593612671}]}, {"text": "Inexact Increase is the increase in Inexact F from previous row.", "labels": [], "entities": [{"text": "Inexact Increase", "start_pos": 0, "end_pos": 16, "type": "METRIC", "confidence": 0.8983891010284424}, {"text": "Inexact F", "start_pos": 36, "end_pos": 45, "type": "METRIC", "confidence": 0.8471661508083344}]}, {"text": "shows that the F-score of the clinical NER system for exact match increases by 0.3% after adding quasi-lexicons, whereas it increases by 1.4% after adding quasi-thesaurus.", "labels": [], "entities": [{"text": "F-score", "start_pos": 15, "end_pos": 22, "type": "METRIC", "confidence": 0.999351441860199}, {"text": "NER", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.9140312075614929}]}, {"text": "The F-score slightly increases further with the use of both these features.", "labels": [], "entities": [{"text": "F-score", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.9992952346801758}]}, {"text": "The F-score for an inexact match follows a similar pattern.", "labels": [], "entities": [{"text": "F-score", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.9990235567092896}]}, {"text": "Table 1 also shows that the F-score for an exact match increases by 0.5% after adding clustering-based features, whereas it increases by 1.6% after adding quasi-thesaurus and quasilexicons.", "labels": [], "entities": [{"text": "F-score", "start_pos": 28, "end_pos": 35, "type": "METRIC", "confidence": 0.9983792304992676}]}, {"text": "The F-score slightly decreases with the use of both the features.", "labels": [], "entities": [{"text": "F-score", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.9993661046028137}]}, {"text": "The F-score for an inexact match follows a similar pattern.", "labels": [], "entities": [{"text": "F-score", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.9990235567092896}]}, {"text": "MED_noDict is the machine-learning clinical NER system with all the orthographic and syntactic features, but no features from lexicons such as UMLS, Drugs@FDA, and MedDRA.", "labels": [], "entities": []}, {"text": "MED_noDict+NN+SVM also has the features generated using SVM and the nearest neighbors algorithm.", "labels": [], "entities": [{"text": "MED_noDict+NN+SVM", "start_pos": 0, "end_pos": 17, "type": "DATASET", "confidence": 0.6579397746494838}]}, {"text": "shows how the F-score increased over the baseline (MED_noDict, which uses various orthographic and syntactic features).", "labels": [], "entities": [{"text": "F-score", "start_pos": 14, "end_pos": 21, "type": "METRIC", "confidence": 0.9966038465499878}, {"text": "MED", "start_pos": 51, "end_pos": 54, "type": "METRIC", "confidence": 0.883156955242157}]}, {"text": "After manually constructed lexicon features are added (MED_Dict), it increased by 0.9%.", "labels": [], "entities": [{"text": "MED_Dict)", "start_pos": 55, "end_pos": 64, "type": "METRIC", "confidence": 0.9157812148332596}, {"text": "it", "start_pos": 66, "end_pos": 68, "type": "METRIC", "confidence": 0.9873894453048706}]}, {"text": "On the other hand, if only distributional semantic features (quasithesaurus and quasi-lexicons) were added without using manually constructed lexicon features (MED_noDict+NN+SVM), it increased by 2.0% (P<0.001 using Bootstrap Resampling) with 1,000 repetitions).", "labels": [], "entities": []}, {"text": "It increases only by 0.5% more if the manually constructed lexicon features were used along with distributional semantic features (MED_Dict+NN+SVM).", "labels": [], "entities": []}, {"text": "The F-score for an inexact match follows a similar pattern.", "labels": [], "entities": [{"text": "F-score", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.9990235567092896}]}], "tableCaptions": [{"text": " Table 1: Clinical NER: Comparison of SVM-Based Features and Clustering-Based Features  With N-Nearest Neighbors-Based Features", "labels": [], "entities": [{"text": "NER", "start_pos": 19, "end_pos": 22, "type": "TASK", "confidence": 0.6640253067016602}]}, {"text": " Table 2: Clinical NER: Impact of Distributional Semantic Features", "labels": [], "entities": [{"text": "NER", "start_pos": 19, "end_pos": 22, "type": "TASK", "confidence": 0.7428241968154907}]}]}