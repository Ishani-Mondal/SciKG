{"title": [{"text": "Investigating Topic Modelling for Therapy Dialogue Analysis", "labels": [], "entities": [{"text": "Therapy Dialogue Analysis", "start_pos": 34, "end_pos": 59, "type": "TASK", "confidence": 0.7714397211869558}]}], "abstractContent": [{"text": "Previous research shows that aspects of doctor-patient communication in therapy can predict patient symptoms, satisfaction and future adherence to treatment (a significant problem with conditions such as schizophrenia).", "labels": [], "entities": []}, {"text": "However, automatic prediction has so far shown success only when based on low-level lexical features, and it is unclear how well these can generalise to new data, or whether their effectiveness is due to their capturing aspects of style, structure or content.", "labels": [], "entities": [{"text": "automatic prediction", "start_pos": 9, "end_pos": 29, "type": "TASK", "confidence": 0.6399744749069214}]}, {"text": "Here, we examine the use of topic as a higher-level measure of content, more likely to generalise and to have more explanatory power.", "labels": [], "entities": []}, {"text": "Investigations show that while topics predict some important factors such as patient satisfaction and ratings of therapy quality, they lack the full predictive power of lower-level features.", "labels": [], "entities": []}, {"text": "For some factors, unsupervised methods produce models comparable to manual annotation.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "We performed a series of classification experiments, to investigate whether the probability distributions of topics could enable automatic detection of patient and doctor evaluations of the consultation, symptoms and adherence.", "labels": [], "entities": []}, {"text": "In each case, we used the Weka machine learning toolkit ( to pre-process data, and a decision tree classifier (J48) and the support vector machine implementation Weka LibSVM) as classifiers.", "labels": [], "entities": [{"text": "Weka LibSVM", "start_pos": 162, "end_pos": 173, "type": "DATASET", "confidence": 0.9247711300849915}]}, {"text": "Variables to be predicted were binarised into groups of equal size prior to analysis, and for the adherence measure a balanced: Accuracy of automatically extracted topics with different feature groups subset of 74 cases was used.", "labels": [], "entities": []}, {"text": "All experiments used 5-fold cross-validation, and the experiments using an SVM classifier used a radial bias function with the best values for cost and gamma determined by a grid search in each case.", "labels": [], "entities": []}, {"text": "show the accuracy figures for each predicted variable, using a variety of different feature subsets.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9993333220481873}]}, {"text": "Doctor factors are the gender and identity of the doctor.", "labels": [], "entities": []}, {"text": "Patient factors are the gender and age of the patient, and also the total number of words spoken by both patient and doctor.", "labels": [], "entities": []}, {"text": "Topic factors are the total number of words in that topic for the hand-coded topics; and an equivalent value for the automatic topics calculated by multiplying the topic's posterior probability fora dialogue by the total number of words.", "labels": [], "entities": []}, {"text": "From we can see that there are different patterns of results for the different measures.", "labels": [], "entities": []}, {"text": "For the therapeutic relationship (HAS) measures, including doctor factors gives an accuracy of over 70% in all cases, with the identity of the psychiatrist the most important factor in the decision trees.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.9994674324989319}]}, {"text": "However, although allowing us a reasonably good fit to the data, the inclusion of the doctor's identity as a feature means that this is not a generalisable result; we would not be able to utilise the information from this factor in predicting the HAS score of a consultation with anew doctor.", "labels": [], "entities": [{"text": "HAS score", "start_pos": 247, "end_pos": 256, "type": "METRIC", "confidence": 0.9713968932628632}]}, {"text": "In this respect, the 65% accuracy when using only the 20 coarse-grained automatic topics is encouraging.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9996213912963867}]}, {"text": "In the decision tree, the highest node is social stressors, with a high amount of talk in this category indicating a low rating of the therapeutic relationship from the doctor (66 low/21 high).", "labels": [], "entities": []}, {"text": "If there was less talk about social stressors, the next highest node is sleep patterns, with more talk in this area indicating a greater likelihood of a good therapeutic relationship rating (29 high/3 low).", "labels": [], "entities": []}, {"text": "Next, more talk about non-psychotic symptoms leads to low ratings (11 low/3 high), and more reassurance, leads to a better therapeutic relationship.", "labels": [], "entities": []}, {"text": "Interestingly, automatic topics give better accuracy than manual topics when used alone.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9970201849937439}]}, {"text": "For adherence, the best accuracy is achieved by a model which includes doctor features as well as hand-coded topics.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9990987777709961}]}, {"text": "Good physician communication is known to increase adherence and in this sample, adherence was also related to the doctor's evaluation of the therapeutic relationship, with 29 of the 37 non-adherent patients rated as having a poor therapeutic relationship by the doctor (\u03c72 = 13.364, p < 0.001).", "labels": [], "entities": []}, {"text": "Given this, it is surprising that we can predict the therapeutic relationship reasonably well using only automatic topics, but not adherence.", "labels": [], "entities": []}, {"text": "Topics also do not appear to give useful performance when predicting patient ratings of the therapeutic relationship (HAS P), or patient evaluations of the consultation (PEQ), although doctor/patient factors seem to have some predictive power.", "labels": [], "entities": [{"text": "HAS P)", "start_pos": 118, "end_pos": 124, "type": "METRIC", "confidence": 0.91183869043986}]}, {"text": "Note that low-level lexical features have shown success in predicting both adherence and patient ratings, achieved f-scores of around 70%).", "labels": [], "entities": [{"text": "f-scores", "start_pos": 115, "end_pos": 123, "type": "METRIC", "confidence": 0.9947147965431213}]}, {"text": "The best predictors for the different types of symptoms are also low, but here the hand-coded topics do better than the automatic topics, with accuracies of 61% for both positive and negative symptoms.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 143, "end_pos": 153, "type": "METRIC", "confidence": 0.9826774001121521}]}, {"text": "For positive symptoms, perhaps unsurprisingly, the decision tree only has one node; if there is more talk on the topic of psychotic symptoms, then the patient is likely to have higher positive symptoms (or vice versa).", "labels": [], "entities": []}, {"text": "However, in this respect, especially given the cross-correlations discussed above, it is surprising that the automatic topics do not allow any prediction of symptoms at above chance levels.", "labels": [], "entities": []}, {"text": "For negative symptoms, patients are likely to have more negative symptoms in consultations with little talk on either healthy lifestyle or daily activities.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Hand-coded topic names and descriptions", "labels": [], "entities": []}, {"text": " Table 2: Interpretations of LDA topics", "labels": [], "entities": [{"text": "Interpretations of LDA", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.7025269071261088}]}, {"text": " Table 4: Correlations between symptoms and topics", "labels": [], "entities": []}, {"text": " Table 5: Accuracy of hand-coded topics with different feature groups", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9777436256408691}]}, {"text": " Table 6: Accuracy of automatically extracted topics with different feature groups", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9903918504714966}]}]}