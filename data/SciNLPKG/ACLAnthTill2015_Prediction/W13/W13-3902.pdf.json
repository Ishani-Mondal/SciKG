{"title": [{"text": "Individuality-Preserving Voice Conversion for Articulation Disorders Using Locality-Constrained NMF", "labels": [], "entities": [{"text": "Individuality-Preserving Voice Conversion", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.6897420088450114}]}], "abstractContent": [{"text": "We present in this paper a voice conversion (VC) method fora person with an articulation disorder resulting from athetoid cerebral palsy.", "labels": [], "entities": [{"text": "voice conversion (VC)", "start_pos": 27, "end_pos": 48, "type": "TASK", "confidence": 0.8589384436607361}]}, {"text": "The movements of such speakers are limited by their athetoid symptoms, and their consonants are often unstable or unclear, which makes it difficult for them to communicate.", "labels": [], "entities": []}, {"text": "In this paper, exemplar-based spectral conversion using Non-negative Matrix Factorization (NMF) is applied to a voice with an articulation disorder.", "labels": [], "entities": [{"text": "exemplar-based spectral conversion", "start_pos": 15, "end_pos": 49, "type": "TASK", "confidence": 0.6001390119393667}, {"text": "Non-negative Matrix Factorization (NMF)", "start_pos": 56, "end_pos": 95, "type": "METRIC", "confidence": 0.7447483589251837}]}, {"text": "In order to preserve the speaker's individuality , we use a combined dictionary that was constructed from the source speaker's vowels and target speaker's consonants.", "labels": [], "entities": []}, {"text": "Also, in order to avoid an unclear converted voice, which is constructed using the combined dictionary, we used locality-constrained NMF.", "labels": [], "entities": []}, {"text": "The effectiveness of this method was confirmed by comparing its effectiveness with that of a conventional Gaussian Mixture Model (GMM)-based method.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this study, we propose assistive technology for people with speech impediments.", "labels": [], "entities": []}, {"text": "There are 34,000 people with speech impediments associated with an articulation disorder in Japan alone.", "labels": [], "entities": []}, {"text": "Articulation disorders are classified into three types.", "labels": [], "entities": []}, {"text": "Functional articulation disorders exist in the absence of any apparent cause and are related to deficiencies in the relatively peripheral motor processes.", "labels": [], "entities": []}, {"text": "Organic articulation disorders are articulation problems that are associated with structural abnormalities and known impairments, such as cleft lip and palate, tongue tie, hearing impairment, etc.", "labels": [], "entities": []}, {"text": "Motor speech disorders involve problems with strength and control of the speech musculature.", "labels": [], "entities": []}, {"text": "We propose a voice conversion system, which converts an articulation-disordered voice into a non-disordered voice, for people with motor speech disorders.", "labels": [], "entities": [{"text": "voice conversion", "start_pos": 13, "end_pos": 29, "type": "TASK", "confidence": 0.7666881680488586}]}, {"text": "Cerebral palsy is one of the typical causes of motor speech disorders.", "labels": [], "entities": []}, {"text": "About two babies in 1,000 are born with cerebral palsy.", "labels": [], "entities": []}, {"text": "Cerebral palsy results from damage to the central nervous system, and the damage causes movement disorders.", "labels": [], "entities": []}, {"text": "Three general times are given for the onset of the disorder: before birth, at the time of delivery, and afterbirth.", "labels": [], "entities": []}, {"text": "Cerebral palsy is classified into the following types: 1) spastic, 2) athetoid, 3) ataxic, 4) atonic, 5) rigid, and a mixture of these types.", "labels": [], "entities": [{"text": "spastic", "start_pos": 58, "end_pos": 65, "type": "METRIC", "confidence": 0.9841317534446716}]}, {"text": "In this study, we focused on a person with an articulation disorder resulting from the athetoid type of cerebral palsy.", "labels": [], "entities": []}, {"text": "Athetoid symptoms develop in about 10-20% of cerebral palsy sufferers.", "labels": [], "entities": [{"text": "Athetoid", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9728021025657654}]}, {"text": "In the case of a person with this type of articulation disorder, his/her movements are sometimes more unstable than usual.", "labels": [], "entities": []}, {"text": "Because of this symptom, their utterances (especially their consonants) are often unstable or unclear.", "labels": [], "entities": []}, {"text": "Most people suffering from athetoid cerebral palsy cannot communicate by sign language, writing or voice synthesizer because athetoid symptoms also restrict the movement of the sufferer's arms and legs.", "labels": [], "entities": []}, {"text": "For this reason, there is a great need fora voice conversion (VC) system for such people.", "labels": [], "entities": [{"text": "voice conversion (VC)", "start_pos": 44, "end_pos": 65, "type": "TASK", "confidence": 0.8363750338554382}]}, {"text": "Automatic speech recognition system for people with articulation disorders resulting from athetoid cerebral palsy has been studied.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.7112642228603363}]}, {"text": "proposed robust feature extraction based on PCA (Principal Component Analysis) with more stable utterance data instead of DCT.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 16, "end_pos": 34, "type": "TASK", "confidence": 0.7663159668445587}]}, {"text": "Miyamoto et al. used multiple acoustic frames (MAF) as an acoustic dynamic feature to improve the recognition rate of a person with an articulation disorder, especially in speech recognition using dynamic features only.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 172, "end_pos": 190, "type": "TASK", "confidence": 0.7336719036102295}]}, {"text": "In spite of these efforts, the recognition rate for articulation disorders is still lower than that of physically unimpaired persons.", "labels": [], "entities": [{"text": "recognition rate", "start_pos": 31, "end_pos": 47, "type": "METRIC", "confidence": 0.8511211276054382}]}, {"text": "The recognition rate for people with articulation disorders using a speaker-independent model trained by nondisordered speech is 3.5%.", "labels": [], "entities": []}, {"text": "This result implies that the speech of a person with an articulation disorder is difficult to understand for people who have not communicated with them before.", "labels": [], "entities": []}, {"text": "A GMM-based approach is widely used for VC because of its flexibility and good performance.", "labels": [], "entities": [{"text": "VC", "start_pos": 40, "end_pos": 42, "type": "TASK", "confidence": 0.9893775582313538}]}, {"text": "This approach has been applied to various tasks, such as speaker conversion, emotion conversion, and soon.", "labels": [], "entities": [{"text": "speaker conversion", "start_pos": 57, "end_pos": 75, "type": "TASK", "confidence": 0.8672471940517426}, {"text": "emotion conversion", "start_pos": 77, "end_pos": 95, "type": "TASK", "confidence": 0.791879266500473}]}, {"text": "In the field of assistive technology, Nakamura et al. proposed a GMM-based speaking aid system for electrolaryngeal speech.", "labels": [], "entities": []}, {"text": "In this approach, the conversion function is interpreted as the expectation value of the target spectral envelope.", "labels": [], "entities": []}, {"text": "The conversion parameters are evaluated using Minimum Mean-Square Error (MMSE) using a parallel training set.", "labels": [], "entities": [{"text": "Minimum Mean-Square Error (MMSE)", "start_pos": 46, "end_pos": 78, "type": "METRIC", "confidence": 0.8446032802263895}]}, {"text": "If the person with an articulation disorder is set as a source speaker and a physically unimpaired person is set as a target speaker, an articulation-disordered voice maybe converted into a non-disordered voice.", "labels": [], "entities": []}, {"text": "However, because the GMM-based approach has been developed mainly for speaker conversion, the source speaker's voice individuality is also converted into the target speaker's individuality.", "labels": [], "entities": [{"text": "speaker conversion", "start_pos": 70, "end_pos": 88, "type": "TASK", "confidence": 0.789001852273941}]}, {"text": "In this paper, we propose a VC method for articulation disorders.", "labels": [], "entities": []}, {"text": "There are two main benefits to our VC method.", "labels": [], "entities": []}, {"text": "1) We convert the speaker's voice into a non-disordered voice, thus preserving their voice individuality.", "labels": [], "entities": []}, {"text": "People with articulation disorders wish to communicate by their own voice if they can therefore, this is important for VC as assistive technology.", "labels": [], "entities": [{"text": "VC", "start_pos": 119, "end_pos": 121, "type": "TASK", "confidence": 0.9525734782218933}]}, {"text": "2) Our method outputs a natural-sounding voice.", "labels": [], "entities": []}, {"text": "Because our VC is exemplar-based and there is no statistical model, we can create a natural sounding voice.", "labels": [], "entities": []}, {"text": "In the research discussed in this paper, we conducted VC for articulation disorders using Non-negative Matrix Factorization (NMF).", "labels": [], "entities": [{"text": "VC", "start_pos": 54, "end_pos": 56, "type": "TASK", "confidence": 0.7152592539787292}, {"text": "Non-negative Matrix Factorization (NMF)", "start_pos": 90, "end_pos": 129, "type": "METRIC", "confidence": 0.7454262723525366}]}, {"text": "NMF is a well-known approach for source separation and speech enhancement.", "labels": [], "entities": [{"text": "NMF", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8569278120994568}, {"text": "source separation", "start_pos": 33, "end_pos": 50, "type": "TASK", "confidence": 0.7864398658275604}, {"text": "speech enhancement", "start_pos": 55, "end_pos": 73, "type": "TASK", "confidence": 0.6977826207876205}]}, {"text": "In these approaches, the observed signal is represented by a linear combination of a small number of elementary vectors, referred to as the basis, and its weights.", "labels": [], "entities": []}, {"text": "In some approaches for source separation, the bases are grouped for each source, and the mixed signals are expressed with a sparse representation of these bases.", "labels": [], "entities": [{"text": "source separation", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.7389284521341324}]}, {"text": "Gemmeke et al. proposes an exemplar-based method for noise robust speech recognition.", "labels": [], "entities": [{"text": "noise robust speech recognition", "start_pos": 53, "end_pos": 84, "type": "TASK", "confidence": 0.6211651489138603}]}, {"text": "In our study, we adopt the supervised NMF approach, with a focus on VC from poorly articulated speech resulting from articulation disorders into non-disordered articulation.", "labels": [], "entities": []}, {"text": "The parallel exemplars (called the 'dictionary' in this paper), which consist of articulation-disordered exemplars and a nondisordered exemplars, are extracted from the parallel data.", "labels": [], "entities": []}, {"text": "An input spectrum with an articulation disorder is represented by a linear combination of articulation-disordered exemplars using NMF.", "labels": [], "entities": []}, {"text": "By replacing an articulation-disordered basis with a nondisordered basis, the original speech spectrum is replaced with a non-disordered spectrum.", "labels": [], "entities": []}, {"text": "In the voice of a person with an articulation disorder, their consonants are often unstable and that makes their voices unclear.", "labels": [], "entities": []}, {"text": "Their vowels are relatively-stable compared to their consonants.", "labels": [], "entities": []}, {"text": "Hence, by replacing the articulation-disordered basis of consonants only, a voice with an articulation disorder is converted into a non-disordered voice that preserves the individuality of the speaker's voice.", "labels": [], "entities": []}, {"text": "In order to avoid a mixture of the source and target spectra in a converted phoneme which is constructed using the combined dictionary, we adopted localityconstraint to the supervised NMF.", "labels": [], "entities": [{"text": "NMF", "start_pos": 184, "end_pos": 187, "type": "DATASET", "confidence": 0.8973482251167297}]}, {"text": "The rest of this paper is organized as follows: In Section 2, NMF-based VC is described, the experimental data is evaluated in Section 3, and the final section is devoted to our conclusions.", "labels": [], "entities": [{"text": "NMF-based VC", "start_pos": 62, "end_pos": 74, "type": "TASK", "confidence": 0.4790205955505371}]}], "datasetContent": [{"text": "The proposed method was evaluated on word-based VC for one person with an articulation disorder.", "labels": [], "entities": []}, {"text": "We recorded 432 utterances (216 words, repeating each two times) included in the ATR Japanese speech database.", "labels": [], "entities": [{"text": "ATR Japanese speech database", "start_pos": 81, "end_pos": 109, "type": "DATASET", "confidence": 0.9351150989532471}]}, {"text": "The speech signals were sampled at 12 kHz and windowed with a 25-msec Hamming window every 10 msec.", "labels": [], "entities": []}, {"text": "A physically unimpaired Japanese male in the ATR Japanese speech database was chosen as a target speaker.", "labels": [], "entities": [{"text": "ATR Japanese speech database", "start_pos": 45, "end_pos": 73, "type": "DATASET", "confidence": 0.9322755634784698}]}, {"text": "Two hundred sixteen utterances were used for training, and the other 216 utterances were used for the test.", "labels": [], "entities": []}, {"text": "The numbers of dimensions of source and target features are, 2,565 and 513.", "labels": [], "entities": []}, {"text": "The number of bases of source and target dictionary is 64,467.", "labels": [], "entities": []}, {"text": "We chose 10,000 nearest bases from dictionary by locality constraint.", "labels": [], "entities": []}, {"text": "We compared our NMF-based VC to conventional GMMbased VC.", "labels": [], "entities": []}, {"text": "In GMM-based VC, the 1st through 24th cepstrum coefficients extracted by STRAIGHT were used as source and target features.", "labels": [], "entities": [{"text": "STRAIGHT", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9733635783195496}]}, {"text": "We conducted subjective evaluation on 3 topics.", "labels": [], "entities": []}, {"text": "A total of 10 Japanese speakers took part in the test using headphones.", "labels": [], "entities": []}, {"text": "For the \"listening intelligibility\" evaluation, we performed a MOS (Mean Opinion Score) test.", "labels": [], "entities": [{"text": "MOS (Mean Opinion Score) test", "start_pos": 63, "end_pos": 92, "type": "METRIC", "confidence": 0.8719687461853027}]}, {"text": "The opinion score was set to a 5-point scale (5: excellent, 4: good, 3: fair, 2: poor, 1: bad).", "labels": [], "entities": []}, {"text": "Thirty-eight words, which are difficult fora person with an articulation disorder to utter, were evaluated.", "labels": [], "entities": []}, {"text": "The subjects were asked about the listening intelligibility in the articulation-disordered voice, the NMF-based converted voice, and the GMM-based converted voice.", "labels": [], "entities": [{"text": "GMM-based converted voice", "start_pos": 137, "end_pos": 162, "type": "DATASET", "confidence": 0.844743549823761}]}, {"text": "Each voice uttered by a physically unimpaired person was presented as a reference of 5 points on the MOS test.", "labels": [], "entities": [{"text": "MOS test", "start_pos": 101, "end_pos": 109, "type": "DATASET", "confidence": 0.6843530982732773}]}, {"text": "Fifty words were converted using NMF-based VC and GMM-based VC for the following evaluations.", "labels": [], "entities": []}, {"text": "On the \"similarity\" evaluation, the XAB test was carried out.", "labels": [], "entities": [{"text": "similarity", "start_pos": 8, "end_pos": 18, "type": "METRIC", "confidence": 0.978520393371582}, {"text": "XAB", "start_pos": 36, "end_pos": 39, "type": "METRIC", "confidence": 0.9796285033226013}]}, {"text": "In the XAB test, each subject listened to the articulation disordered voice.", "labels": [], "entities": []}, {"text": "Then the subject listened to the voice converted by the two methods and selected which sample sounded most similar to the articulation disordered voice.", "labels": [], "entities": []}, {"text": "On the \"naturalness\" evaluation, a paired comparison test was carried out, where each subject listened to pairs of speech converted by the two methods and selected which sample sounded more natural.", "labels": [], "entities": []}, {"text": "shows examples of converted spectrograms.", "labels": [], "entities": []}, {"text": "Using GMM-based conversion, the area labeled \"oi\" becomes unclear compared to NMF-based conversion.", "labels": [], "entities": []}, {"text": "This might be because unexpected mapping during the GMM-based VC degraded the conversion performance.", "labels": [], "entities": []}, {"text": "Because NMF-based VC converts consonants only, the same area is relatively clear and similar to the labeled \"oi\" area in.", "labels": [], "entities": []}, {"text": "In the spectrogram converted by NMF-based VC without locality, there are some misconversions in the black circled area.", "labels": [], "entities": []}, {"text": "This is because there is some mixing of the vowel and consonant spectra.", "labels": [], "entities": []}, {"text": "By using local constrained NMF, such misconversions are eliminated.", "labels": [], "entities": []}, {"text": "Also, in comparison between (d) and (e) in, the converted voice using 10,000 nearest bases is more clear than that using 1,000 nearest bases, especially the areas labeled \"i\" and \"oi\".", "labels": [], "entities": []}, {"text": "For this reason, locality-constraint is useful to the combined dictionary, however, using too few bases degrades conversion performance.", "labels": [], "entities": []}], "tableCaptions": []}