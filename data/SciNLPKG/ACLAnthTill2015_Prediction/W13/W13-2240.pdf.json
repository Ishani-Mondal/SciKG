{"title": [{"text": "Machine learning methods for comparative and time-oriented Quality Estimation of Machine Translation output", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 81, "end_pos": 100, "type": "TASK", "confidence": 0.7090376615524292}]}], "abstractContent": [{"text": "This paper describes a set of experiments on two sub-tasks of Quality Estimation of Machine Translation (MT) output.", "labels": [], "entities": [{"text": "Quality Estimation of Machine Translation (MT) output", "start_pos": 62, "end_pos": 115, "type": "TASK", "confidence": 0.7656291723251343}]}, {"text": "Sentence-level ranking of alternative MT outputs is done with pairwise classi-fiers using Logistic Regression with black-box features originating from PCFG Parsing , language models and various counts.", "labels": [], "entities": [{"text": "Sentence-level ranking", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8092362582683563}, {"text": "MT outputs", "start_pos": 38, "end_pos": 48, "type": "TASK", "confidence": 0.8665230870246887}]}, {"text": "Post-editing time prediction uses regression models, additionally fed with new elaborate features from the Statistical MT decoding process.", "labels": [], "entities": [{"text": "time prediction", "start_pos": 13, "end_pos": 28, "type": "TASK", "confidence": 0.7047100216150284}, {"text": "Statistical MT decoding", "start_pos": 107, "end_pos": 130, "type": "DATASET", "confidence": 0.6446353097756704}]}, {"text": "These seem to be better indicators of post-editing time than black-box features.", "labels": [], "entities": []}, {"text": "Prior to training the models, feature scoring with ReliefF and Information Gain is used to choose feature sets of decent size and avoid computational complexity .", "labels": [], "entities": [{"text": "feature scoring", "start_pos": 30, "end_pos": 45, "type": "TASK", "confidence": 0.7970933616161346}, {"text": "ReliefF", "start_pos": 51, "end_pos": 58, "type": "METRIC", "confidence": 0.8707807660102844}]}], "introductionContent": [{"text": "During the recent years, Machine Translation (MT) has reached levels of performance which allow for its integration into real-world translation workflows.", "labels": [], "entities": [{"text": "Machine Translation (MT)", "start_pos": 25, "end_pos": 49, "type": "TASK", "confidence": 0.8805832386016845}]}, {"text": "Despite the high speed and various advantages of this technology, the fact that the MT results are rarely perfect and often require manual corrections has raised a need to assess their quality, predict the required post-editing effort and compare outputs from various systems on application time.", "labels": [], "entities": [{"text": "MT", "start_pos": 84, "end_pos": 86, "type": "TASK", "confidence": 0.9891600012779236}]}, {"text": "This has been the aim of current research on Quality Estimation, which investigates solutions for several variations of such problems.", "labels": [], "entities": [{"text": "Quality Estimation", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.7171919494867325}]}, {"text": "We describe possible solutions for two problems of MT Quality Estimation, as part of the 8th Shared Task on Machine Translation: (a) sentence-level quality ranking (1.2) of multiple translations of the same source sentence and (b) prediction of post-editing time.", "labels": [], "entities": [{"text": "MT Quality Estimation", "start_pos": 51, "end_pos": 72, "type": "TASK", "confidence": 0.9101729393005371}, {"text": "Machine Translation", "start_pos": 108, "end_pos": 127, "type": "TASK", "confidence": 0.6972907483577728}]}, {"text": "We present our approach on acquiring (section 2.1) and selecting features (section 2.2), we explain the generation of the statistical estimation systems (section 2.3) and we evaluate the developed solutions with some of the standard metrics (section 3).", "labels": [], "entities": []}], "datasetContent": [{"text": "The ranking task is evaluated by measuring correlation between the predicted and the human ranking, with the use of Kendall tau including penalization of ties.", "labels": [], "entities": []}, {"text": "We additionally consider two more metrics specialized in ranking tasks: Mean Reciprocal Rank -MRR (Voorhees, 1999) and Normalized Discounted Cumulative Gain -NDGC), which give better scores to models when higher ranks (i.e. better translations) are ordered correctly, as these are more important than lower ranks.", "labels": [], "entities": [{"text": "Mean Reciprocal Rank -MRR", "start_pos": 72, "end_pos": 97, "type": "METRIC", "confidence": 0.9338923931121826}, {"text": "Normalized Discounted Cumulative Gain -NDGC", "start_pos": 119, "end_pos": 162, "type": "METRIC", "confidence": 0.6311610738436381}]}, {"text": "The regression task is evaluated in terms of Root Mean Square Error (RMSE) and Mean Average Error (MAE).", "labels": [], "entities": [{"text": "Root Mean Square Error (RMSE)", "start_pos": 45, "end_pos": 74, "type": "METRIC", "confidence": 0.9227574127061027}, {"text": "Mean Average Error (MAE)", "start_pos": 79, "end_pos": 103, "type": "METRIC", "confidence": 0.9812853733698527}]}], "tableCaptions": [{"text": " Table 1: Development experiments for task 1.2, reporting correlation and ranking scores, tested on the  development set WMT2009.", "labels": [], "entities": [{"text": "correlation", "start_pos": 58, "end_pos": 69, "type": "METRIC", "confidence": 0.9425627589225769}, {"text": "WMT2009", "start_pos": 121, "end_pos": 128, "type": "DATASET", "confidence": 0.9045573472976685}]}, {"text": " Table 3: Beta coefficients of the best fitted logistic  regression on the German-English data set (set #33  with Stepwise Feature Set Selection)", "labels": [], "entities": [{"text": "German-English data set", "start_pos": 75, "end_pos": 98, "type": "DATASET", "confidence": 0.9019533594449362}]}, {"text": " Table 2: Description of most important feature sets for task 1.2, before internal feature selection of  Logistic Regression is applied. [s] indicates source, [t] indicates target", "labels": [], "entities": []}, {"text": " Table 5: Higher Kendall tau correlation (on the  dev. set) is achieved on German-English by us- ing Stepwise Feature Set Selection, whereas on  English-Spanish by using L2-regularization", "labels": [], "entities": [{"text": "Kendall tau correlation", "start_pos": 17, "end_pos": 40, "type": "METRIC", "confidence": 0.896400531133016}, {"text": "dev. set", "start_pos": 50, "end_pos": 58, "type": "DATASET", "confidence": 0.7148433725039164}]}, {"text": " Table 6: Development and submitted experiments for task 1.3", "labels": [], "entities": []}]}