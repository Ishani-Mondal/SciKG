{"title": [{"text": "A Dependency-Constrained Hierarchical Model with Moses", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents a dependency-constrained hierarchical machine translation model that uses Moses open-source toolkit for rule extraction and decoding.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 58, "end_pos": 77, "type": "TASK", "confidence": 0.7004274278879166}, {"text": "rule extraction", "start_pos": 124, "end_pos": 139, "type": "TASK", "confidence": 0.8049871027469635}]}, {"text": "Experiments are carried out for the German-English language pair in both directions for projective and non-projective dependencies.", "labels": [], "entities": []}, {"text": "We examine effects on SCFG size and automatic evaluation results when constraints are applied with respect to projective or non-projective dependency structures and on the source or target language side.", "labels": [], "entities": []}], "introductionContent": [{"text": "A fundamental element of natural language syntax is the dependency structure encoding the binary asymmetric head-dependent relations captured in dependency grammar theory.", "labels": [], "entities": [{"text": "dependency grammar theory", "start_pos": 145, "end_pos": 170, "type": "TASK", "confidence": 0.6867081522941589}]}, {"text": "A main criteria for determining the dependency structure of a given sentence is the following: The linear position of dependent, D, is specified with reference to its head, H (.", "labels": [], "entities": []}, {"text": "This runs in parallel with that which hierarchical machine translation SCFG rules encode: The linear position of a translated phrase, X i , is specified with reference to the lexicalised words in the rule., and, with hierarchical rules (4) and rules shown in.", "labels": [], "entities": []}, {"text": "Given the existence of initial rules (1), (2) and (3), hierarchical rules and can be created.", "labels": [], "entities": []}, {"text": "Rule (4) specifies the linear position of the translation of the English phrase that precedes house with reference to lexicalised casa.", "labels": [], "entities": []}, {"text": "For hierarchical machine translation models, there is no requirement fora syntactic relationship to exist between the lexicalised words of a rule and the words replaced by nonterminals, the only requirement being that substituted words form an SMT phrase (.", "labels": [], "entities": [{"text": "hierarchical machine translation", "start_pos": 4, "end_pos": 36, "type": "TASK", "confidence": 0.6461562514305115}, {"text": "SMT phrase", "start_pos": 244, "end_pos": 254, "type": "TASK", "confidence": 0.8868837356567383}]}, {"text": "The dependency structure of either the source or target (or indeed both) can, however, be used to constrain rule extraction as to only allow hierarchical rules in which the linear position of dependents are specified with reference to the position of their lexicalised heads.", "labels": [], "entities": [{"text": "rule extraction", "start_pos": 108, "end_pos": 123, "type": "TASK", "confidence": 0.7608195245265961}]}, {"text": "For example, in the case of the hierarchical rules in, rule (4) satisfies such a constraint according to both the source and target language dependency structures (since white is the dependent of house and blanca is the dependent of casa, and it is both white and blanca that are replaced by non-terminals while the heads remain lexicalised) and results in asynchronous grammar rule that positions a dependent relative to the position of its lexicalised head.", "labels": [], "entities": []}, {"text": "Rule (5), on the other hand, does not satisfy such a constraint for either language dependency structure.", "labels": [], "entities": []}, {"text": "In this work, we examine a dependencyconstrained model in which hierarchical rules are only permitted in which lexicalised heads specify the linear position of missing dependents, and examine the effects of applying such constraints across a variety of settings for German to English and English to German translation.", "labels": [], "entities": [{"text": "English to German translation", "start_pos": 288, "end_pos": 317, "type": "TASK", "confidence": 0.6423121690750122}]}], "datasetContent": [{"text": "WMT training data sets were used for both parallel (1.49 million German/English sentence pairs) and monolingual training (11.51 million English & 4.74 million German sentences).", "labels": [], "entities": [{"text": "WMT training data sets", "start_pos": 0, "end_pos": 22, "type": "DATASET", "confidence": 0.7962882965803146}]}, {"text": "Mate nonprojective dependency parser (Bohnet, 2010) was used for parsing both the German and English parallel data with standard pre-trained models, the same parser was used for projective parsing with non-projectivity turned off.", "labels": [], "entities": [{"text": "Mate nonprojective dependency parser", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.6268174350261688}, {"text": "projective parsing", "start_pos": 178, "end_pos": 196, "type": "TASK", "confidence": 0.6675806045532227}]}, {"text": "Parallel training data lines containing multiple sentences were merged into a single pseudo-dependency structure by adding an artificial root and head-dependent relation between the head of the initial sentence and any subsequent sentences.", "labels": [], "entities": []}, {"text": "Non-projective dependencies were converted into projective structures using Algorithm 6.1.", "labels": [], "entities": []}, {"text": "Giza++ () was employed for automatic word alignment, and Moses GHKM rule extraction) was used for hierarchical rule extraction for the dependency-constrained models.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 37, "end_pos": 51, "type": "TASK", "confidence": 0.7149608731269836}, {"text": "GHKM rule extraction", "start_pos": 63, "end_pos": 83, "type": "TASK", "confidence": 0.5810047388076782}, {"text": "hierarchical rule extraction", "start_pos": 98, "end_pos": 126, "type": "TASK", "confidence": 0.6588471929232279}]}, {"text": "Default settings were used for rule extraction for all models with the exception on non-fractional counting being used, as well as Good-turing discounting.", "labels": [], "entities": [{"text": "rule extraction", "start_pos": 31, "end_pos": 46, "type": "TASK", "confidence": 0.8176795244216919}]}, {"text": "Both the dependency-constrained and standard models use the same set of initial rules.", "labels": [], "entities": []}, {"text": "For decoding, since only a single non-terminal, X, is present for all models, Moses hierarchical decoder ( was used with default settings with the exception of rule span limit being removed for all models.", "labels": [], "entities": []}, {"text": "SRILM) was used for 5-gram language modeling and KneserNey smoothing for both German-to-English and English-to-German translation.", "labels": [], "entities": [{"text": "SRILM", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.48182594776153564}, {"text": "5-gram language modeling", "start_pos": 20, "end_pos": 44, "type": "TASK", "confidence": 0.5743378301461538}]}, {"text": "MERT was carried out on WMT newstest2009 development set optimizing for BLEU, and final results are reported for heldout test sets, newstest2010 and newstest2011, with BLEU () and LR-score (Birch and Osborne, 2010) for evaluation.", "labels": [], "entities": [{"text": "MERT", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.8812713027000427}, {"text": "WMT newstest2009 development set", "start_pos": 24, "end_pos": 56, "type": "DATASET", "confidence": 0.9699286967515945}, {"text": "BLEU", "start_pos": 72, "end_pos": 76, "type": "METRIC", "confidence": 0.9989253878593445}, {"text": "BLEU", "start_pos": 168, "end_pos": 172, "type": "METRIC", "confidence": 0.9988529682159424}, {"text": "LR-score", "start_pos": 180, "end_pos": 188, "type": "METRIC", "confidence": 0.9901167750358582}]}, {"text": "shows automatic evaluation results for both the dependency-constrained and standard hierarchical models for both language directions.", "labels": [], "entities": []}, {"text": "Compared to the standard hierarchical model (orig), the best performing dependencyconstrained models, sl npr (de-en) and tl npr (en-de), show significant decreases in mean BLEU score, -0.44 for German to English and -0.13 for English to German.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 172, "end_pos": 182, "type": "METRIC", "confidence": 0.9013734459877014}]}, {"text": "However, there is a trade-off, as the dependency-constrained models achieve vast reductions in model size, approx. 93% for German to English and 89% for English to German in numbers of SCFG hierarchical rules.", "labels": [], "entities": []}, {"text": "This results in decreased decoding times, with the best performing dependency-constrained models achieving a decrease of 26% for German to English and 34% for English to German in mean decoding times.", "labels": [], "entities": []}], "tableCaptions": []}