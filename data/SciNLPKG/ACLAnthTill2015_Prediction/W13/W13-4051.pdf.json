{"title": [{"text": "Open-domain Utterance Generation for Conversational Dialogue Systems using Web-scale Dependency Structures", "labels": [], "entities": [{"text": "Open-domain Utterance Generation", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.6323484381039938}]}], "abstractContent": [{"text": "Even though open-domain conversational dialogue systems are required in many fields, their development is complicated because of the flexibility and variety of user utterances.", "labels": [], "entities": []}, {"text": "To address this flexibility , previous research on conversational dialogue systems has selected system utterances from web articles based on surface cohesion and shallow semantic coherence; however, the generated utterances sometimes contain irrelevant sentences with respect to the input user utterance.", "labels": [], "entities": []}, {"text": "We propose a template-based approach that fills templates with the most salient words in a user utterance and with related words that are extracted using web-scale dependency structures gathered from Twitter.", "labels": [], "entities": []}, {"text": "Our open-domain conversational dialogue system outperforms retrieval-based conventional systems in chat experiments.", "labels": [], "entities": []}], "introductionContent": [{"text": "The need for open-domain conversational dialogue systems continues to grow.", "labels": [], "entities": []}, {"text": "Such systems are beginning to be actively investigated from their social and entertainment aspects (; conversational dialogues also have potential for therapy purposes and for evoking a user's unconscious requests in task-oriented dialogues).", "labels": [], "entities": []}, {"text": "However, developing open-domain conversational dialogue systems is difficult, since the huge variety of user utterances makes it harder to build knowledge resources for generating appropriate system responses.", "labels": [], "entities": []}, {"text": "To address this issue, previous research has selected system utterances from web articles or microblogs on the basis of surface cohesion and shallow semantic coherence; however, the selected utterances sometimes contain sentences irrelevant to the user utterance since they originally appeared in a different context.", "labels": [], "entities": []}, {"text": "To satisfy both web-scale topic coverage and suppression of irrelevant sentences, we propose a template-based approach that fills templates with words related to the topic of the user utterance and with words related to the topic-words.", "labels": [], "entities": []}, {"text": "This approach enables us to generate a wide range of system responses when we properly extract related words.", "labels": [], "entities": []}, {"text": "To obtain words related to topic-words, we analyzed the dependency structures of a huge number of sentences posted to such microblogs as Twitter, where a large number and variety of sentences are posted daily.", "labels": [], "entities": []}, {"text": "This way, we can generate a variety of appropriate system responses despite wide variation in user utterances.", "labels": [], "entities": []}, {"text": "We develop a conversational dialogue system that generates system utterances with our proposed utterance generation approach and examine its effectiveness by chat experiments with real users.", "labels": [], "entities": [{"text": "utterance generation", "start_pos": 95, "end_pos": 115, "type": "TASK", "confidence": 0.7186517268419266}]}], "datasetContent": [{"text": "We recruited ten native Japanese-speaking participants in their 20's and 30's (two males and eight females) from outside of the authors' organization, who have experience using chat systems (not bots).", "labels": [], "entities": []}, {"text": "Each participant chatted with the following systems, provided subjective evaluation scores for each system for each of the eight criteria shown in (2)-(10) using 7-point Likert scales, and at the end ranked all the systems.", "labels": [], "entities": []}, {"text": "We examined the effectiveness of our proposed approach by comparison with the following six systems.", "labels": [], "entities": []}, {"text": "We built the following proposed systems with about 150 M posts gathered from Twitter (excluding posts that contain \"@\", \"RT\", \"http\" and brackets, and posts that don't contain any dependency pairs).", "labels": [], "entities": []}, {"text": "At the beginning of a dialogue or the end of a conversation topic when the topicbased approach didn't generate system utterances, the proposed approaches generated questions such as \"What is your favorite movie?\" to introduce the next conversation topic.", "labels": [], "entities": []}, {"text": "These questions were gathered from utterances in the self-introduction phase (about the five initial utterances) of each dialogue in our dialogue corpus.", "labels": [], "entities": []}, {"text": "We manually selected 109 questions that have no context from 179 questions gathered from our corpus, and chose a question at random to generate each topicinductive question.", "labels": [], "entities": []}, {"text": "Proposed-All This approach used all found topics: proper and common nouns, and predicates.", "labels": [], "entities": []}, {"text": "This approach is expected to be well-balanced since it generates both content-focused utterances and general WH-type questions.", "labels": [], "entities": []}, {"text": "Proposed-Nouns This approach used only proper and common nouns, not predicates.", "labels": [], "entities": []}, {"text": "Proposed-Predicates This approach used only predicates, not proper nor common nouns.", "labels": [], "entities": []}, {"text": "Retrieval-Self This approach resembles the IRresponse method in.", "labels": [], "entities": []}, {"text": "This approach chose the most similar posts to the user ut-  terance from source posts using the Lucene 2 information retrieval library, which is an IDF-weighted vector-space similarity.", "labels": [], "entities": [{"text": "Lucene 2 information retrieval library", "start_pos": 96, "end_pos": 134, "type": "DATASET", "confidence": 0.8653075456619262}]}, {"text": "We built about 55 M source-reply post pairs from Twitter.", "labels": [], "entities": []}, {"text": "Retrieval-Reply This approach is the same as the IR-status method in.", "labels": [], "entities": []}, {"text": "It chooses a reply post whose associated source posts most resemble the user's utterance.", "labels": [], "entities": []}, {"text": "Human As an upper-bound of these systems, the user chats with a human using the same chat interface used by the other systems.", "labels": [], "entities": []}, {"text": "Each dialogue took place over four minutes and was conducted through a text chat interface, and the orders of presentation of systems to participants was randomized.", "labels": [], "entities": []}, {"text": "Since the humans have to type their utterances and the systems can generate utterances much faster than typing, we set the transition of the system utterances to about ten seconds to avoid different response intervals between the systems and the humans.", "labels": [], "entities": []}, {"text": "shows that Proposed-All is ranked the highest of all the automatic systems (1), and achieves the best average evaluation scores (2)-(10).", "labels": [], "entities": []}, {"text": "Statistical analyses were performed using the Binomial test for (1) and Welch's t test for to (10).", "labels": [], "entities": [{"text": "Binomial test", "start_pos": 46, "end_pos": 59, "type": "METRIC", "confidence": 0.5086943209171295}, {"text": "Welch's t test", "start_pos": 72, "end_pos": 86, "type": "METRIC", "confidence": 0.8815841227769852}]}, {"text": "Proposed-All was ranked higher than the retrieval-based approaches (10 of 10 participants ranked Proposed-All higher than Retrieval-Self, and 8 participants ranked Proposed-All higher than Retrieval-Reply), but none of our three proposed approaches was ranked significantly higher than the others.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: System preferences and evaluation scores on 7-point Likert scale ( * : p < .1,  *  * : p < .05)", "labels": [], "entities": []}]}