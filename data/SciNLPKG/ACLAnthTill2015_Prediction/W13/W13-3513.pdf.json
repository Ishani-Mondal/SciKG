{"title": [{"text": "Separating Disambiguation from Composition in Distributional Semantics", "labels": [], "entities": [{"text": "Separating Disambiguation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.9371581375598907}]}], "abstractContent": [{"text": "Most compositional-distributional models of meaning are based on ambiguous vector representations, where all the senses of a word are fused into the same vector.", "labels": [], "entities": []}, {"text": "This paper provides evidence that the addition of a vector disambiguation step prior to the actual composition would be beneficial to the whole process, producing better composite representations.", "labels": [], "entities": []}, {"text": "Furthermore , we relate this issue with the current evaluation practice, showing that disambiguation-based tasks cannot reliably assess the quality of composition.", "labels": [], "entities": []}, {"text": "Using a word sense disambiguation scheme based on the generic procedure of Sch\u00fctze (1998), we first provide a proof of concept for the necessity of separating dis-ambiguation from composition.", "labels": [], "entities": []}, {"text": "Then we demonstrate the benefits of an \"unambigu-ous\" system on a composition-only task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Compositional and distributional semantic models seem to provide complementary solutions for solving the same problem, that of assigning a proper \"meaning\" to a text segment.", "labels": [], "entities": []}, {"text": "Specifically, while compositional models deal with the recursive nature of the language, providing away to address its inherent ability to create infinite sentences from finite resources (words), they leave words as unexplained primitives whose meanings have somehow already been set before the compositional process.", "labels": [], "entities": []}, {"text": "On the other hand, distributional models have been especially successful in providing concrete representations for the meaning of words as vectors in a vector space, created by taking into account the context in which each word appears.", "labels": [], "entities": []}, {"text": "Despite its success for smaller language units, the distributional hypothesis does not naturally lend itself to compounds of words.", "labels": [], "entities": []}, {"text": "Hence these models do not canonically scale in tasks requiring the creation of vector representations for text constituents larger than words, i.e. for phrases and sentences.", "labels": [], "entities": []}, {"text": "A common strand in all of the above models is that they are based on \"ambiguous\" vector representations, where a polysemous word is represented by a single vector regardless of the number of its actual senses.", "labels": [], "entities": []}, {"text": "For example, the word 'bank' has at least two meanings (financial institution and land alongside a river), both of which will be fused into a single vector representation.", "labels": [], "entities": []}, {"text": "And, although it is generally true that compositional models following the formal semantics view of Montague do not care about disambiguation (meanings of words in such models are represented by logical constants explicitly set before the compositional process), the story changes when one moves to a vector space model with ambiguous vector representations.", "labels": [], "entities": []}, {"text": "The main problem is that, when acting on ambiguous vector spaces, compositional models seem to perform two tasks at the same time, composition and disambiguation, leaving the resulting vector hard to interpret: it is not clear if this vector is a proper meaning representation for the composed compound or just a disambiguated version of one of the words therein.", "labels": [], "entities": []}, {"text": "This problem escapes the evaluation schemes, especially when disambiguation tasks are used as a criterion for evaluating compositional models-a common practice in current research for compositional-distributional semantics.", "labels": [], "entities": []}, {"text": "Indeed, argues that although disambiguation can emerge as a welcome side-effect of the compositional process, it is not clear if compositionality is either a necessary or sufficient condition for disambiguation to happen.", "labels": [], "entities": []}, {"text": "On the contrary, it seems that the form of most current vector space models and the compositional operations used on them (quite often some form of vector point-wise multiplication) mainly achieve disambiguation, but not composition.", "labels": [], "entities": []}, {"text": "The purpose of this paper is to further investigate the potential of a compositional-distributional model based on disambiguated vector representations, where each word can have one or more distinct senses.", "labels": [], "entities": []}, {"text": "More specifically, we aim to show that (a) compositionality is not a necessary condition for disambiguation, so the quite common practice of using a disambiguation task as a criterion for evaluating the performance of compositional-distributional models is questionable; and (b) the introduction of a separate disambiguation step in the compositional process of distributional models can be indeed beneficial for the quality of the resulting composed vectors.", "labels": [], "entities": []}, {"text": "We train our models from BNC, a 100-million words corpus created from samples of written and spoken English.", "labels": [], "entities": [{"text": "BNC", "start_pos": 25, "end_pos": 28, "type": "DATASET", "confidence": 0.8971471190452576}]}, {"text": "We perform word sense induction by following the generic algorithm of, in which the senses of a word are represented by distinct clusters created by taking into account the various contexts in which this specific word occur in the corpus.", "labels": [], "entities": [{"text": "word sense induction", "start_pos": 11, "end_pos": 31, "type": "TASK", "confidence": 0.8166732788085938}]}, {"text": "For the actual clustering step we use a combination of hierarchical agglomerative clustering and the Cali\u00b4nskiCali\u00b4nski-Harabasz index.", "labels": [], "entities": []}, {"text": "The parameters of the models are fine-tuned on the noun set of SEMEVAL 2010 Word Sense Induction and Disambiguation task.", "labels": [], "entities": [{"text": "SEMEVAL 2010 Word Sense Induction and Disambiguation task", "start_pos": 63, "end_pos": 120, "type": "TASK", "confidence": 0.6882292255759239}]}, {"text": "Equipped with a disambiguated vector space, we use it on a verb disambiguation experiment, similar in style to that of, but applied on a more linguistically motivated dataset, based on the work of.", "labels": [], "entities": [{"text": "verb disambiguation", "start_pos": 59, "end_pos": 78, "type": "TASK", "confidence": 0.7245121896266937}]}, {"text": "We find that the application of a simple disambiguation algorithm, without any compositional steps, is proven more effective than a number of compositional models.", "labels": [], "entities": []}, {"text": "We consider this as an indication for the necessity of separating disambiguation from composition, since it implies that the latter is not necessary for achieving the former.", "labels": [], "entities": []}, {"text": "Next, we demonstrate that a compositional model based on disambiguated vectors can indeed produce composite vector representations of better quality, by applying the model on a phrase similarity task.", "labels": [], "entities": [{"text": "phrase similarity task", "start_pos": 177, "end_pos": 199, "type": "TASK", "confidence": 0.7888600627581278}]}, {"text": "The goal here is to evaluate the similarity of short verb phrases, based on the distance of their composite vectors.", "labels": [], "entities": []}], "datasetContent": [{"text": "The choice of our 1st-order vector space is based on empirical tests, where we found out that a basis with elements of the form word, class presents the right balance for our purposes among simpler techniques, such as word-based spaces, and more complex ones, such as dependency-based approaches.", "labels": [], "entities": []}, {"text": "In our vector space, each word has a distinct vector representation for every word class under which occurs in the corpus (e.g. 'suit' will have a noun vector and a verb vector).", "labels": [], "entities": []}, {"text": "As our basis elements we use the 2000 most frequent content words in BNC, with weights being calculated as the ratio of the probability of the context word given the target word to the probability of the context word overall.", "labels": [], "entities": [{"text": "BNC", "start_pos": 69, "end_pos": 72, "type": "DATASET", "confidence": 0.8158910274505615}]}, {"text": "The context here is a 5-word window on both sides of the target word.", "labels": [], "entities": []}, {"text": "The parameters of the clustering scheme are optimized on the noun set of.", "labels": [], "entities": []}, {"text": "Specifically, when using HAC one has to decide how to measure the distance between the clusters, which is the merging criterion applied in every iteration of the algorithm, as well as the measure between the data points, i.e. the individual vectors.", "labels": [], "entities": []}, {"text": "Based on empirical tests we limit our options to two inter-cluster measures: complete-link and Ward's methods.", "labels": [], "entities": []}, {"text": "In the complete-link method the distance between two clusters X and Y is the distance between their two most remote elements: In Ward's method, two clusters are selected for merging if the new partitioning exhibits the minimum increase in the overall intra-cluster variance.", "labels": [], "entities": []}, {"text": "The cluster distance is given by: where \u2212 \u2192 c X and \u2212 \u2192 c Y are the centroids of X and Y . We test these linkage methods in combination with three vector distance measures: euclidean, cosine, and Pearson's correlation (6 models in total).", "labels": [], "entities": [{"text": "Pearson's correlation", "start_pos": 196, "end_pos": 217, "type": "METRIC", "confidence": 0.7187195817629496}]}, {"text": "The metrics were chosen to represent progressively more relaxed forms of vector comparison, with the strictest form to be the euclidean distance and correlation as the most relaxed.", "labels": [], "entities": [{"text": "vector comparison", "start_pos": 73, "end_pos": 90, "type": "TASK", "confidence": 0.7358909845352173}, {"text": "correlation", "start_pos": 149, "end_pos": 160, "type": "METRIC", "confidence": 0.9564871191978455}]}, {"text": "For sense detection we use the disambiguation algorithm described in Section 4, considering as context the whole sentence in which a target word appears.", "labels": [], "entities": [{"text": "sense detection", "start_pos": 4, "end_pos": 19, "type": "TASK", "confidence": 0.9268678426742554}]}, {"text": "The distance metric used for the disambiguation process in each model is identical to the metric used for the clustering process, so in the Ward/euclidean model the disambiguation is based on the euclidean distance, in completelink/cosine model on the cosine distance, and soon.", "labels": [], "entities": []}, {"text": "We evaluate the models using V-measure, an entropy-based metric that addresses the so-.", "labels": [], "entities": []}, {"text": "Ward's method in combination with correlation distance provided the highest V-measure, followed by the combination of complete-link with (again) correlation.", "labels": [], "entities": [{"text": "correlation distance", "start_pos": 34, "end_pos": 54, "type": "METRIC", "confidence": 0.949118971824646}, {"text": "V-measure", "start_pos": 76, "end_pos": 85, "type": "METRIC", "confidence": 0.9748877882957458}]}, {"text": "Compare this, for example, with the best-performing system that achieved a V-measure of 0.21, a score that was largely due to the fact that the model assigned the unrealistic number of 11.54 senses per word on average (since V-measure tends to favour higher numbers of senses, as the baseline 1 cluster/instance shows in provides an example of the results, showing the senses for the noun 'keyboard' learnt by the best model of Ward's method and correlation measure.", "labels": [], "entities": []}, {"text": "Each sense is visualized as a list of the most dominant words in the cluster, ranked by their TF-ICF values.", "labels": [], "entities": [{"text": "TF-ICF", "start_pos": 94, "end_pos": 100, "type": "METRIC", "confidence": 0.9909771680831909}]}, {"text": "Furthermore, shows the dendrograms produced by four linkage methods for the word 'keyboard', demonstrating the superiority of Ward's method.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results on the noun set of SEMEVAL  2010 WSI&D task.", "labels": [], "entities": [{"text": "SEMEVAL  2010 WSI&D task", "start_pos": 37, "end_pos": 61, "type": "TASK", "confidence": 0.7890003621578217}]}, {"text": " Table 3: Spearman's \u03c1 for the Pickering and Fris- son dataset.", "labels": [], "entities": [{"text": "Pickering and Fris- son dataset", "start_pos": 31, "end_pos": 62, "type": "DATASET", "confidence": 0.9096878965695699}]}, {"text": " Table 4: Phrase similarity results.", "labels": [], "entities": [{"text": "Phrase similarity", "start_pos": 10, "end_pos": 27, "type": "METRIC", "confidence": 0.8361268043518066}]}]}