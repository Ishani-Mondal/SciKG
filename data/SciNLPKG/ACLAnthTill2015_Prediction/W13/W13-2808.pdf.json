{"title": [{"text": "An English-to-Hungarian Morpheme-based Statistical Machine Translation System with Reordering Rules", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 39, "end_pos": 70, "type": "TASK", "confidence": 0.7347561717033386}]}], "abstractContent": [{"text": "Phrase-based statistical machine translation systems can generate translations of reasonable quality in the case of language pairs with similar structure and word order.", "labels": [], "entities": [{"text": "Phrase-based statistical machine translation", "start_pos": 0, "end_pos": 44, "type": "TASK", "confidence": 0.5828270390629768}]}, {"text": "However, if the languages are more distant from a grammatical point of view, the quality of translations is much behind the expectations, since the baseline translation system cannot cope with long distance reordering of words and the mapping of word internal grammatical structures.", "labels": [], "entities": []}, {"text": "In our paper, we present a method that tries to overcome these problems in the case of English-Hungarian translation by applying reordering rules prior to the translation process and by creating morpheme-based and factored models.", "labels": [], "entities": [{"text": "English-Hungarian translation", "start_pos": 87, "end_pos": 116, "type": "TASK", "confidence": 0.6662957221269608}]}, {"text": "Although automatic evaluation scores do not reliably reflect the improvement in all cases, human evaluation of our systems shows that readabil-ity and accuracy of the translations were improved both by reordering and applying richer models.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 151, "end_pos": 159, "type": "METRIC", "confidence": 0.9992652535438538}]}], "introductionContent": [{"text": "Phrase-based statistical machine translation systems rely on statistical observations derived from phrase alignments automatically extracted from parallel bilingual corpora.", "labels": [], "entities": [{"text": "Phrase-based statistical machine translation", "start_pos": 0, "end_pos": 44, "type": "TASK", "confidence": 0.6282951608300209}]}, {"text": "The main advantage of applying SMT is its language-independence.", "labels": [], "entities": [{"text": "SMT", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.9891513586044312}]}, {"text": "The phrase-based model works well for language pairs with similar syntactic structure and word order.", "labels": [], "entities": []}, {"text": "However, phrase-based models fail to handle great word-order differences adequately.", "labels": [], "entities": []}, {"text": "We describe our attempt to improve performance by transforming source language (English) sentences to a structure similar to that of the corresponding target (Hungarian) sentence.", "labels": [], "entities": []}, {"text": "We also describe our approach for handling data sparseness due to the inadequate coverage of linguistic structures by the limited training corpus.", "labels": [], "entities": []}, {"text": "It is a common problem in the case of translation to agglutinating languages like Hungarian, where a much greater amount of training data would be necessary to provide adequate statistics than what is necessary for closely related language pairs involving only morphologically less complex languages.", "labels": [], "entities": [{"text": "translation", "start_pos": 38, "end_pos": 49, "type": "TASK", "confidence": 0.9615036845207214}]}], "datasetContent": [{"text": "We performed experiments on word-based, morpheme-based and factored translations from English to Hungarian with and without applying our reordering rules as a preprocessing step.", "labels": [], "entities": []}, {"text": "We also contrasted the performance of our experimental systems with that of some commercial systems: the rule-based and the major commercial translation services, Google Translate and Bing Translator, which apply their language independent statistical systems trained on huge parallel corpora.", "labels": [], "entities": []}, {"text": "Low BLEU scores of translations generated by these systems (compared to those usually obtained for other languages) indicate that machine translation to Hungarian is indeed a difficult task.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.9994251728057861}, {"text": "machine translation to Hungarian", "start_pos": 130, "end_pos": 162, "type": "TASK", "confidence": 0.8200175911188126}]}, {"text": "In all of our experiments, the Moses ( ) toolkit was used for building the translation models and performing the translation task itself, using IRSTLM ( to build language models.", "labels": [], "entities": []}, {"text": "Wherever it was necessary, was used for morphological analysis and generation, and the Stanford Parser () for constituent and dependency parsing.", "labels": [], "entities": [{"text": "morphological analysis and generation", "start_pos": 40, "end_pos": 77, "type": "TASK", "confidence": 0.7077698335051537}, {"text": "Stanford Parser", "start_pos": 87, "end_pos": 102, "type": "DATASET", "confidence": 0.8554732799530029}, {"text": "constituent and dependency parsing", "start_pos": 110, "end_pos": 144, "type": "TASK", "confidence": 0.5737165957689285}]}, {"text": "As training data, we used the Hunglish () corpus, created by BME MOKK 2 and the Research Institute for Linguistics of the Hungarian Academy of Sciences.", "labels": [], "entities": [{"text": "Hunglish () corpus", "start_pos": 30, "end_pos": 48, "type": "DATASET", "confidence": 0.7286051511764526}, {"text": "BME MOKK 2", "start_pos": 61, "end_pos": 71, "type": "DATASET", "confidence": 0.6153230369091034}]}, {"text": "This corpus contains parallel texts from the following domains: literature and magazines, legal texts and movie subtitles.", "labels": [], "entities": []}, {"text": "There is a great degree of variation in the quality of different parts of the corpus.", "labels": [], "entities": []}, {"text": "We automatically eliminated sentence pairs from the corpus that caused technical problems, but overall translation quality was not checked.", "labels": [], "entities": []}, {"text": "The corpus we used for training the system consists of 1,026,836 parallel sentences with 14,553,765 words on the English side and 12,079,557 on the Hungarian side.", "labels": [], "entities": []}, {"text": "For testing purposes, a 1000-sentence-long portion was selected from the same corpus with one reference translation.", "labels": [], "entities": []}, {"text": "Automatic evaluation was performed on this set using the BLEU evaluation metric.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 57, "end_pos": 61, "type": "METRIC", "confidence": 0.9896773099899292}]}, {"text": "Results for each system are listed in.", "labels": [], "entities": []}, {"text": "It has been shown that system rankings based on single reference BLEU scores often do not correspond to how humans evaluate the translations.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 65, "end_pos": 69, "type": "METRIC", "confidence": 0.9768948554992676}]}, {"text": "For this reason, automatic evaluation has fora longtime not been used to officially rank systems at Workshops on Statistical Machine Translation (WMT) . In our work, we presented results of automated evaluation using a single reference BLEU metrics, but we also investigated translations generated by each system using human evaluation, applying the ranking scheme used at WMT workshops to officially rank systems.", "labels": [], "entities": [{"text": "Statistical Machine Translation (WMT)", "start_pos": 113, "end_pos": 150, "type": "TASK", "confidence": 0.7949990332126617}, {"text": "BLEU", "start_pos": 236, "end_pos": 240, "type": "METRIC", "confidence": 0.9858312606811523}]}, {"text": "300 sentences were randomly chosen from the test set for the purpose of human evaluation.", "labels": [], "entities": []}, {"text": "Five annotators evaluated translations generated by each of the above described systems plus the reference translation in the corpus with regard to translation quality (considering both adequacy and fluency in a single quality ranking).", "labels": [], "entities": []}, {"text": "The order of translations was randomized for each sentence and a balanced number of comparisons was performed for each system pair.", "labels": [], "entities": []}, {"text": "The systems were ranked based on a score that was defined as the number of times the output of a system was deemed not worse than that of the other in pairwise comparisons divided by the number of pairwise comparisons.", "labels": [], "entities": []}, {"text": "The aggregate results of human evaluation are listed in.", "labels": [], "entities": []}, {"text": "Manual investigation of the translation outputs revealed that the system incorporating morphological and syntactic information are better at capturing grammatical relations in the original text and rendering them in the translation by generating the original English After you were picked up at sea , our listening post in Malta intercepted that fax . reordered English Miut\u00e1n felvett\u00e9k mag\u00e1t a tengeren , hallgatta a hely\u00fcnk , hogy m\u00e1lt\u00e1 allta ezt a faxot . back-translation After you were picked up at sea, our listening post caught the fax in Malta.", "labels": [], "entities": []}, {"text": "baseline translation Azut\u00e1n , hogy felvette a tengeren , a m\u00e1ltai hallgatta az emelked\u02dd o , hogy fax . back-translation After you, he picked it up at the sea, and that Malta were caught, that it is a fax.", "labels": [], "entities": [{"text": "Azut\u00e1n", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.8842306733131409}]}], "tableCaptions": [{"text": " Table 1: Size of training and test datasets mea- sured in the number of sentences, average number  of words per sentences and the average number of  morphemes per sentences on the English and Hun- garian sides.", "labels": [], "entities": [{"text": "sured", "start_pos": 50, "end_pos": 55, "type": "METRIC", "confidence": 0.5568835139274597}]}, {"text": " Table 3: Automatic evaluation scores for systems  tested in the experiments.", "labels": [], "entities": []}, {"text": " Table 4: Translation results of our systems with hand made backtranslations for comparison with the  reference.", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9482547044754028}]}, {"text": " Table 5: Human evaluation ranking of systems measured as percentage of generating a translation not  worse than the other in pairwise comparisons", "labels": [], "entities": []}]}