{"title": [{"text": "Identifying False Friends between Closely Related Languages", "labels": [], "entities": [{"text": "Identifying False Friends between Closely Related Languages", "start_pos": 0, "end_pos": 59, "type": "TASK", "confidence": 0.8748448661395481}]}], "abstractContent": [{"text": "In this paper we present a corpus-based approach to automatic identification of false friends for Slovene and Croatian, a pair of closely related languages.", "labels": [], "entities": [{"text": "automatic identification of false friends", "start_pos": 52, "end_pos": 93, "type": "TASK", "confidence": 0.7955795168876648}]}, {"text": "By taking advantage of the lexical overlap between the two languages, we focus on measuring the difference in meaning between identically spelled words by using frequency and distributional information.", "labels": [], "entities": []}, {"text": "We analyze the impact of corpora of different origin and size together with different association and similarity measures and compare them to a simple frequency-based base-line.", "labels": [], "entities": []}, {"text": "With the best performing setting we obtain very good average precision of 0.973 and 0.883 on different gold standards.", "labels": [], "entities": [{"text": "precision", "start_pos": 61, "end_pos": 70, "type": "METRIC", "confidence": 0.9640711545944214}]}, {"text": "The presented approach works on non-parallel datasets, is knowledge-lean and language-independent, which makes it attractive for natural language processing tasks that often lack the lexical resources and cannot afford to build them by hand.", "labels": [], "entities": []}], "introductionContent": [{"text": "False friends are words in two or more languages that are orthographically or semantically similar but do not have the same meaning, such as the noun burro, which means butter in Italian but donkey in Spanish.", "labels": [], "entities": []}, {"text": "For that reason, they represent a dangerous pitfall for translators, language students as well as bilingual computer tools, such as machine translation systems, which would all benefit greatly from a comprehensive collection of false friends fora given language pair.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 132, "end_pos": 151, "type": "TASK", "confidence": 0.7241449058055878}]}, {"text": "False friends between related languages, such as English and French, have been discussed by lexicographers, translators and language teachers for decades.", "labels": [], "entities": []}, {"text": "However, they have so far played a minor role in NLP and have been almost exclusively limited to parallel data.", "labels": [], "entities": [{"text": "NLP", "start_pos": 49, "end_pos": 52, "type": "TASK", "confidence": 0.897245466709137}]}, {"text": "In this paper we tackle the problem of automatically identifying false friends in weakly comparable corpora by taking into account the distributional and frequency information collected from non-parallel texts.", "labels": [], "entities": [{"text": "automatically identifying false friends in weakly comparable corpora", "start_pos": 39, "end_pos": 107, "type": "TASK", "confidence": 0.7699972689151764}]}, {"text": "Identifying false friends automatically has the same prerequisite as the problem of detecting cognates -identifying similarly (and identically) spelled words between two languages, which is far from trivial if one takes into account the specificity of inter-language variation of a specific language pair.", "labels": [], "entities": [{"text": "Identifying false friends", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.9019788901011149}]}, {"text": "In this contribution we focus on the problem of false friends on two quite similar languages with a high lexical overlap -Croatian and Slovene -which enables us to circumvent the problem of identifying similarly spelled words and use identical words only as the word pair candidate list for false friends.", "labels": [], "entities": []}, {"text": "Our approach to identifying false friends relies on two types of information extracted from corpora.", "labels": [], "entities": []}, {"text": "The first one is the frequency of a false friend candidate pair in the corresponding corpora where the greater the difference in frequency, the more certain one can be that the words are used in different meanings.", "labels": [], "entities": []}, {"text": "The second information source is the context from corresponding corpora where the context dissimilarity of the two words in question is calculated through a vector space model.", "labels": [], "entities": []}, {"text": "The paper is structured as follows: in Section 2 we give an overview of the related work.", "labels": [], "entities": []}, {"text": "In Section 3 we describe the resources we use and in Section 4 we present the gold standards used for evaluation.", "labels": [], "entities": []}, {"text": "Section 5 describes the experimental setup and Section 6 reports on the results.", "labels": [], "entities": []}, {"text": "We conclude the paper with final remarks and ideas for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We experimented with the following parameters: corpus type, corpus size, association measure for feature weighting, similarity measure for comparing context vectors and gold standard type.", "labels": [], "entities": [{"text": "similarity measure", "start_pos": 116, "end_pos": 134, "type": "METRIC", "confidence": 0.951520562171936}]}, {"text": "We ran our experiments on two pairs of corpora: 1.", "labels": [], "entities": []}, {"text": "one pair originating from local Wikipedia dumps (WIKI) and 2.", "labels": [], "entities": []}, {"text": "one pair originating from the top-leveldomain web corpora of the two languages (WAC) We took under consideration the following association measures: 1.", "labels": [], "entities": []}, {"text": "TF-IDF (TF-IDF) is well known from information retrieval but frequently applied on other problems as well; we consider context vectors to be information entities and calculate the IDF statistic fora term t and vector set V as follows: 2.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 35, "end_pos": 56, "type": "TASK", "confidence": 0.7801352441310883}]}, {"text": "log-likelihood (LL) which has proven to perform very well in a number of experiments on lexicon extraction i.e. finding words with the most similar context, performing similarity well as TF-IDF and 3.", "labels": [], "entities": [{"text": "lexicon extraction", "start_pos": 88, "end_pos": 106, "type": "TASK", "confidence": 0.7774699032306671}]}, {"text": "discounted log-odds (LO) first used in lexicon extraction by, showing consistently better performance than LL; it is calculated from contingency table information as follows: The following similarity measures were taken into account: 1.", "labels": [], "entities": [{"text": "discounted log-odds (LO)", "start_pos": 0, "end_pos": 24, "type": "METRIC", "confidence": 0.9301733016967774}, {"text": "lexicon extraction", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.7953200042247772}]}, {"text": "the well-known cosine measure (COSINE), 2.", "labels": [], "entities": [{"text": "cosine measure (COSINE)", "start_pos": 15, "end_pos": 38, "type": "METRIC", "confidence": 0.8819222450256348}]}, {"text": "the Dice measure (DICE), defined in as DiceMin, which has proven to be very good in various tasks of distributional semantics (v 1f is the feature weight of feature fin vector v 1 ): 3. and the Jensen-Shannon divergence (JEN-SHAN) which shows consistent performance on various tasks: We used the standard approach for extracting context and building context vectors and calculated the frequency distribution of three content words to the left and to the right of the headword without encoding their position.", "labels": [], "entities": []}, {"text": "We did not perform any cross-lingual feature projection via a seed lexicon or similar, but relied completely on the lexical overlap between the two similar languages.", "labels": [], "entities": [{"text": "cross-lingual feature projection", "start_pos": 23, "end_pos": 55, "type": "TASK", "confidence": 0.6409264107545217}]}, {"text": "Apart from the context and its dissimilarity, there is another, very fundamental source of information that can be used to assess the difference in usage and therefore meaning -the frequency of the word pair in question in specific languages.", "labels": [], "entities": []}, {"text": "That is why we also calculated pointwise mutual information (PMI) between candidate pairs.", "labels": [], "entities": [{"text": "pointwise mutual information (PMI)", "start_pos": 31, "end_pos": 65, "type": "METRIC", "confidence": 0.6639766444762548}]}, {"text": "We estimated the joint probability of the two words by calculating the maximum likelihood estimate of the identically spelled word on the merged corpora.", "labels": [], "entities": []}, {"text": "We considered this measure to be a strong baseline.", "labels": [], "entities": []}, {"text": "For a weak baseline we took a random ordering of pairs of words (RANDOM).", "labels": [], "entities": [{"text": "RANDOM", "start_pos": 65, "end_pos": 71, "type": "METRIC", "confidence": 0.9702988266944885}]}, {"text": "Since the result of the procedure of identifying false friends in this setting is a single ranked list of lemma pairs where the ranking is performed by contextual or frequency dissimilarity, the same evaluation method can be applied as to evaluating a single query response in information retrieval.", "labels": [], "entities": []}, {"text": "That is why we evaluated the output of each setting with average precision (AP), which averages overall precisions calculated on lists of false friend candidates built from each positive example upwards.", "labels": [], "entities": [{"text": "average precision (AP)", "start_pos": 57, "end_pos": 79, "type": "METRIC", "confidence": 0.828744637966156}, {"text": "precisions", "start_pos": 104, "end_pos": 114, "type": "METRIC", "confidence": 0.9839953780174255}]}, {"text": "As three categories were encoded in the GOLD2 gold standard, we weighted FFs with 1, TEs with 0 and PFFs with 0.5.", "labels": [], "entities": [{"text": "GOLD2 gold standard", "start_pos": 40, "end_pos": 59, "type": "DATASET", "confidence": 0.9378090898195902}, {"text": "FFs", "start_pos": 73, "end_pos": 76, "type": "METRIC", "confidence": 0.9954856038093567}, {"text": "TEs", "start_pos": 85, "end_pos": 88, "type": "METRIC", "confidence": 0.9894365072250366}, {"text": "PFFs", "start_pos": 100, "end_pos": 104, "type": "METRIC", "confidence": 0.9562089443206787}]}, {"text": "In the GOLD1 gold standard FFs were, naturally, weighted with 1 and TEs with 0.", "labels": [], "entities": [{"text": "GOLD1 gold standard", "start_pos": 7, "end_pos": 26, "type": "DATASET", "confidence": 0.9556306799252828}, {"text": "FFs", "start_pos": 27, "end_pos": 30, "type": "METRIC", "confidence": 0.47710034251213074}, {"text": "TEs", "start_pos": 68, "end_pos": 71, "type": "METRIC", "confidence": 0.9970281720161438}]}], "tableCaptions": [{"text": " Table 1: Basic statistics about the corpora used", "labels": [], "entities": []}, {"text": " Table 2: Inter-annotator agreement on building the  gold standards", "labels": [], "entities": []}, {"text": " Table 3: Average precision obtained over corpora  types, gold standards, association measures and  similarity measures", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9025849103927612}, {"text": "similarity", "start_pos": 100, "end_pos": 110, "type": "METRIC", "confidence": 0.9481439590454102}]}, {"text": " Table 4: Results of the analysis of the 50 strongest  features in the eight different LL and LO vectors", "labels": [], "entities": []}]}