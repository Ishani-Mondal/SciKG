{"title": [{"text": "Sentiment Analysis in Social Media Texts", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9801030457019806}]}], "abstractContent": [{"text": "This paper presents a method for sentiment analysis specifically designed to work with Twitter data (tweets), taking into account their structure, length and specific language.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 33, "end_pos": 51, "type": "TASK", "confidence": 0.9650232195854187}]}, {"text": "The approach employed makes it easily extendible to other languages and makes it able to process tweets in near real time.", "labels": [], "entities": []}, {"text": "We show that using the training models generated with the method described we can improve the sentiment classification performance, irrespective of the domain and distribution of the test sets.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 94, "end_pos": 118, "type": "TASK", "confidence": 0.909383624792099}]}], "introductionContent": [{"text": "Sentiment analysis is the Natural Language Processing (NLP) task dealing with the detection and classification of sentiments in texts.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.925332099199295}, {"text": "detection and classification of sentiments in texts", "start_pos": 82, "end_pos": 133, "type": "TASK", "confidence": 0.8378232802663531}]}, {"text": "Usually, the classes considered are \"positive\", \"negative\" and \"neutral\", although in some cases finer-grained categories are added (e.g. \"very positive\" and \"very negative\") or only the \"positive\" and \"negative\" classes are taken into account.", "labels": [], "entities": []}, {"text": "Another related task -emotion detection -concerns the classification of text into several classes of emotion, usually the basic ones, as described by Paul Ekman.", "labels": [], "entities": [{"text": "emotion detection -", "start_pos": 22, "end_pos": 41, "type": "TASK", "confidence": 0.8332487146059672}, {"text": "classification of text", "start_pos": 54, "end_pos": 76, "type": "TASK", "confidence": 0.8684574564297994}]}, {"text": "Although different in some ways, some of the research in the field has considered these tasks together, under the umbrella of sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 126, "end_pos": 144, "type": "TASK", "confidence": 0.9468257427215576}]}, {"text": "This task has received a lot of interest from the research community in the past years.", "labels": [], "entities": []}, {"text": "The work done regarded the manner in which sentiment can be classified from texts pertaining to different genres and distinct languages, in the context of various applications, using knowledge-based, semi-supervised and supervised methods.", "labels": [], "entities": []}, {"text": "The result of the analyses performed have shown that the different types of text require specialized methods for sentiment analysis, as, for example, sentiments are not conveyed in the same manner in newspaper articles and in blogs, reviews, forums or other types of user-generated contents (.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 113, "end_pos": 131, "type": "TASK", "confidence": 0.9458869397640228}]}, {"text": "In the light of these findings, dealing with sentiment analysis in Twitter requires an analysis of the characteristics of such texts and the design of adapted methods.", "labels": [], "entities": [{"text": "sentiment analysis in Twitter", "start_pos": 45, "end_pos": 74, "type": "TASK", "confidence": 0.8873655945062637}]}, {"text": "Additionally, the sentiment analysis method employed has to consider the requirements of the final application in which it will be used.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 18, "end_pos": 36, "type": "TASK", "confidence": 0.9684824049472809}]}, {"text": "There is an important difference between deploying a system working for languages such as English, for which numerous linguistic resources and analysis tools exist and a system deployed for languages with few such tools or one that is aimed at processing data from a large set of languages.", "labels": [], "entities": []}, {"text": "Finally, a sentiment analysis system working with large sets of data (such as the one found in Twitter) must be able to process texts fast.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 11, "end_pos": 29, "type": "TASK", "confidence": 0.9493932127952576}]}, {"text": "Therefore, using highly complex methods may delay producing useful results.", "labels": [], "entities": []}, {"text": "In the light of these considerations, this paper presents a method for sentiment analysis that takes into account the special structure and linguistic content of tweets.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 71, "end_pos": 89, "type": "TASK", "confidence": 0.9636289775371552}]}, {"text": "The texts are pre-processed in order to normalize the language employed and remove noisy elements.", "labels": [], "entities": []}, {"text": "Special usage of language (e.g. repeated punctuation signs, repeated letters) are marked as special features, as they contribute to the expressivity of the text in terms of sentiment.", "labels": [], "entities": []}, {"text": "Further on, sentiment-bearing words, as they are found in three highly-accurate sentiment lexiconsGeneral Inquirer (GI) (, Linguistic Inquiry and Word Count (LIWC)) and MicroWNOp () -are replaced with unique labels, correspoding to their polarity.", "labels": [], "entities": []}, {"text": "In the same manner, modifiers (negations, intensifiers and diminishers) are also replaced with unique labels representing their semantic class.", "labels": [], "entities": []}, {"text": "Finally, we employ supervised learning with Support Vector Machines Sequential Minimal Optimization (SVM SMO)) using a simple, linear kernel (to avoid overfitting of data) and the unigrams and bigrams from the training set as features.", "labels": [], "entities": [{"text": "Support Vector Machines Sequential Minimal Optimization (SVM SMO))", "start_pos": 44, "end_pos": 110, "type": "TASK", "confidence": 0.6617695540189743}]}, {"text": "We obtain the best results by using unique labels for the affective words and the modifiers, unigrams and bigrams as features and posing the condition that each feature considered in the supervised learning process be present in the training corpora at least twice.", "labels": [], "entities": []}, {"text": "The remainder of this article is structured as follows: Section 2 gives an overview of the related work.", "labels": [], "entities": []}, {"text": "In Section 3, we present the motivations and describe the contributions of this work.", "labels": [], "entities": []}, {"text": "In the following section, we describe in detail the process followed to pre-process the tweets and build the classification models.", "labels": [], "entities": []}, {"text": "In Section 5, we present the results obtained using different datasets and combinations of features and discuss their causes and implications.", "labels": [], "entities": []}, {"text": "Finally, Section 6 summarizes the main findings of this work and sketches the lines for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Although the different steps included to eliminate the noise in the data and the choice of features have been refined using our in-house gathered Twitter data, in order to evaluate our approach and make it comparable to other methods, we employ three different data sets, which are described in detail in the following subsections.", "labels": [], "entities": []}, {"text": "In order to test our sentiment analysis approach, we employed the datasets described above.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.9583986401557922}]}, {"text": "In the case of the SemEval data, we performed an exhaustive evaluation of the possible combination of features to be employed.", "labels": [], "entities": [{"text": "SemEval data", "start_pos": 19, "end_pos": 31, "type": "DATASET", "confidence": 0.8042434453964233}]}, {"text": "We tested the entire dataset of tweets (T*+t*) using 10-fold cross-validation.", "labels": [], "entities": []}, {"text": "The first set of evaluations concerned the use of the preprocessed tweets in which the affective words and modifiers were have not been replaced.", "labels": [], "entities": []}, {"text": "The combination of features tested were: unigrams (U ), bigrams (B), unigrams and bigrams together (U + B) and unigrams and bigrams together, selecting only the features that appear at least twice in the data (U + B + F S).", "labels": [], "entities": []}, {"text": "The second set of evaluations aimed at quantifying the difference in performance when the affective words and the modifiers were replaced with generic labels.", "labels": [], "entities": []}, {"text": "We tested the best performing approaches from the first set of evaluations (U + B and U + B + F S), by replacing the words that were found in the affect dictionaries and the modifiers with their generic labels.", "labels": [], "entities": []}, {"text": "These evaluations are denoted as U + B + D and U + B + D + F S.", "labels": [], "entities": [{"text": "U + B + D + F S", "start_pos": 47, "end_pos": 62, "type": "METRIC", "confidence": 0.6519112177193165}]}, {"text": "The results of these evaluations are shown in.: Results in terms of accuracy for 10-fold crossvalidation using different combinations of features for the sentiment classification of tweets on the entire set of SemEval 2013 training data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9993461966514587}, {"text": "sentiment classification of tweets", "start_pos": 154, "end_pos": 188, "type": "TASK", "confidence": 0.8805873543024063}, {"text": "SemEval 2013 training data", "start_pos": 210, "end_pos": 236, "type": "DATASET", "confidence": 0.7639192938804626}]}, {"text": "The same experiments are repeated by employing T* as training data and t* as test data.", "labels": [], "entities": []}, {"text": "The aim of these experiments is to test how well the method can perform on new data.", "labels": [], "entities": []}, {"text": "The results of these evaluations are shown in.", "labels": [], "entities": []}, {"text": "In order to test if in- deed the use of sentiment dictionaries, modifiers and the simple feature selection method improves on the best performing approach that does not employ these additional features, we tested both the approaches on the T weetEm and BlogEm datasets.", "labels": [], "entities": [{"text": "BlogEm datasets", "start_pos": 253, "end_pos": 268, "type": "DATASET", "confidence": 0.9267666339874268}]}, {"text": "In this case, however, the classification is done among 6 different classes of emotions.", "labels": [], "entities": []}, {"text": "Although the results are lower(as it can be seen in, they are comparable to those obtained by) (when using U + B) and show an improvement when using the affect dictionaries and simple feature selection.", "labels": [], "entities": []}, {"text": "They also confirm the fact that the best performance on the data is obtained replacing the modifiers and the words found in affect dictionaries with generic labels, using unigrams and bigrams as and eliminating those n-grams that appear only once.", "labels": [], "entities": []}, {"text": "The results obtained confirm that the use of unigram and bigram features (appearing at least twice) with generalized affective words and modifiers obtains the best results.", "labels": [], "entities": []}, {"text": "Although there is a significant improvement in the accuracy of the classification, the most important difference in the classification performance is given by the fact that using this combination, the classifier is no longer biased by the class with the highest number of examples.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9991782307624817}]}, {"text": "We can notice this for the case of tweets, for which the confusion matrices are presented in.", "labels": [], "entities": []}, {"text": "In the table header, the correspondence is: a = joy, b = fear, c = surprise, d = anger, e = disgust, f = sadness.", "labels": [], "entities": [{"text": "surprise", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.9692575335502625}]}, {"text": "In the first case, the use of unigrams and bigrams leads to the erroneous classification of examples to the majoritary class.", "labels": [], "entities": []}, {"text": "When employing the features in which affective words and modifiers have been replaced with generic labels, the results are not only improved, but they classifier is less biased towards the majoritary class.", "labels": [], "entities": []}, {"text": "In this case, the incorrect assignments are made to classes that are more similar in vocabulary (e.g. anger -disgust, anger -sadness).", "labels": [], "entities": []}, {"text": "In the case of surprise, examples relate both to positive, as well as negative surprises.", "labels": [], "entities": []}, {"text": "Therefore, there is a similarity in the vocabulary employed to both these classes.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Characteristics of the training (T*), testing (t*)  and joint training and testing datasets.", "labels": [], "entities": []}, {"text": " Table 4: Results in terms of accuracy for the different  combination of features for the emotion classification of  tweets and short blog sentences.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9994409680366516}, {"text": "emotion classification of  tweets and short blog sentences", "start_pos": 90, "end_pos": 148, "type": "TASK", "confidence": 0.8197989389300346}]}, {"text": " Table 5: Confusion matrix for the emotion classification  of the T weetEm dataset employing the sentiment dictio- naries.", "labels": [], "entities": [{"text": "T weetEm dataset", "start_pos": 66, "end_pos": 82, "type": "DATASET", "confidence": 0.7295195162296295}]}, {"text": " Table 6: Confusion matrix for the emotion classification  of the T weetEm dataset without employing the senti- ment dictionaries.", "labels": [], "entities": [{"text": "emotion classification", "start_pos": 35, "end_pos": 57, "type": "TASK", "confidence": 0.6899909973144531}, {"text": "T weetEm dataset", "start_pos": 66, "end_pos": 82, "type": "DATASET", "confidence": 0.7210250099500021}]}]}