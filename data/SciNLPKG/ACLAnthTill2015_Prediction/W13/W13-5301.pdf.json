{"title": [{"text": "Combining, Adapting and Reusing Bi-texts between Related Languages: Application to Statistical Machine Translation (invited talk)", "labels": [], "entities": [{"text": "Combining, Adapting and Reusing Bi-texts between Related Languages", "start_pos": 0, "end_pos": 66, "type": "TASK", "confidence": 0.7634621494346194}, {"text": "Statistical Machine Translation", "start_pos": 83, "end_pos": 114, "type": "TASK", "confidence": 0.7925137281417847}]}], "abstractContent": [{"text": "Bilingual sentence-aligned parallel corpora, or bitexts, area useful resource for solving many computational linguistics problems including part-ofspeech tagging, syntactic parsing, named entity recognition, word sense disambiguation, sentiment analysis, etc.; they are also a critical resource for some real-world applications such as statistical machine translation (SMT) and cross-language information retrieval.", "labels": [], "entities": [{"text": "part-ofspeech tagging", "start_pos": 140, "end_pos": 161, "type": "TASK", "confidence": 0.7213474214076996}, {"text": "syntactic parsing", "start_pos": 163, "end_pos": 180, "type": "TASK", "confidence": 0.7320199310779572}, {"text": "named entity recognition", "start_pos": 182, "end_pos": 206, "type": "TASK", "confidence": 0.6279708941777548}, {"text": "word sense disambiguation", "start_pos": 208, "end_pos": 233, "type": "TASK", "confidence": 0.669766902923584}, {"text": "sentiment analysis", "start_pos": 235, "end_pos": 253, "type": "TASK", "confidence": 0.9138354659080505}, {"text": "statistical machine translation (SMT)", "start_pos": 336, "end_pos": 373, "type": "TASK", "confidence": 0.8152584234873453}, {"text": "cross-language information retrieval", "start_pos": 378, "end_pos": 414, "type": "TASK", "confidence": 0.7267612119515737}]}, {"text": "Unfortunately, building large bi-texts is hard, and thus most of the 6,500+ world languages remain resource-poor in bi-texts.", "labels": [], "entities": []}, {"text": "However, many resource-poor languages are related to some resource-rich language, with whom they overlap in vocabulary and share cognates, which offers opportunities for using their bi-texts.", "labels": [], "entities": []}, {"text": "We explore various options for bi-text reuse: (i) direct combination of bi-texts, (ii) combination of models trained on such bi-texts, and (iii) a sophisticated combination of (i) and (ii).", "labels": [], "entities": []}, {"text": "We further explore the idea of generating bitexts fora resource-poor language by adapting a bi-text fora resource-rich language.", "labels": [], "entities": []}, {"text": "We build a lattice of adaptation options for each word and phrase, and we then decode it using a language model for the resource-poor language.", "labels": [], "entities": []}, {"text": "We compare word-and phrase-level adaptation, and we further make use of cross-language morphology.", "labels": [], "entities": [{"text": "word-and phrase-level adaptation", "start_pos": 11, "end_pos": 43, "type": "TASK", "confidence": 0.5983703633149465}]}, {"text": "For the adaptation, we experiment with (a) a standard phrase-based SMT decoder, and (b) a specialized beam-search adaptation decoder.", "labels": [], "entities": [{"text": "adaptation", "start_pos": 8, "end_pos": 18, "type": "TASK", "confidence": 0.9676780104637146}, {"text": "SMT decoder", "start_pos": 67, "end_pos": 78, "type": "TASK", "confidence": 0.8350360989570618}]}, {"text": "Finally, we observe that for closely-related languages, many of the differences are at the subword level.", "labels": [], "entities": []}, {"text": "Thus, we explore the idea of reducing translation to character-level transliteration.", "labels": [], "entities": []}, {"text": "We further demonstrate the potential of combining word-and character-level models.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}