{"title": [{"text": "Interpreting Consumer Health Questions: The Role of Anaphora and Ellipsis", "labels": [], "entities": [{"text": "Interpreting Consumer Health Questions", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.8264111578464508}]}], "abstractContent": [{"text": "While interest in biomedical question answering has been growing, research in consumer health question answering remains relatively sparse.", "labels": [], "entities": [{"text": "biomedical question answering", "start_pos": 18, "end_pos": 47, "type": "TASK", "confidence": 0.6199884215990702}, {"text": "consumer health question answering", "start_pos": 78, "end_pos": 112, "type": "TASK", "confidence": 0.6484834849834442}]}, {"text": "In this paper, we focus on the task of consumer health question understanding.", "labels": [], "entities": [{"text": "consumer health question understanding", "start_pos": 39, "end_pos": 77, "type": "TASK", "confidence": 0.7462369948625565}]}, {"text": "We present a rule-based methodology that relies on lexical and syntactic information as well as anaphora/ellipsis resolution to construct struc-tured representations of questions (frames).", "labels": [], "entities": []}, {"text": "Our results indicate the viability of our approach and demonstrate the important role played by anaphora and ellipsis in interpreting consumer health questions.", "labels": [], "entities": [{"text": "interpreting consumer health questions", "start_pos": 121, "end_pos": 159, "type": "TASK", "confidence": 0.8959726393222809}]}], "introductionContent": [{"text": "Question understanding is a major challenge in automatic question answering.", "labels": [], "entities": [{"text": "Question understanding", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8999771475791931}, {"text": "automatic question answering", "start_pos": 47, "end_pos": 75, "type": "TASK", "confidence": 0.6632496317227682}]}, {"text": "An array of approaches has been developed for this task in the course of TREC Question Answering evaluations (see for an overview).", "labels": [], "entities": [{"text": "TREC Question Answering evaluations", "start_pos": 73, "end_pos": 108, "type": "TASK", "confidence": 0.8166793435811996}]}, {"text": "These collectively developed approaches to question understanding were successfully applied and expanded upon in IBM's Watson system).", "labels": [], "entities": [{"text": "question understanding", "start_pos": 43, "end_pos": 65, "type": "TASK", "confidence": 0.9065905809402466}, {"text": "Watson system", "start_pos": 119, "end_pos": 132, "type": "DATASET", "confidence": 0.8290986716747284}]}, {"text": "Currently, Watson is being retargeted towards biomedical question answering, joining the ongoing research in domain-specific question answering (for a review, see).", "labels": [], "entities": [{"text": "Watson", "start_pos": 11, "end_pos": 17, "type": "DATASET", "confidence": 0.716720461845398}, {"text": "biomedical question answering", "start_pos": 46, "end_pos": 75, "type": "TASK", "confidence": 0.6289146244525909}, {"text": "domain-specific question answering", "start_pos": 109, "end_pos": 143, "type": "TASK", "confidence": 0.6462708910306295}]}, {"text": "Much research in automatic question answering has focused on answering well-formed factoid questions.", "labels": [], "entities": [{"text": "question answering", "start_pos": 27, "end_pos": 45, "type": "TASK", "confidence": 0.7398527264595032}]}, {"text": "However, real-life questions that need to be handled by such systems are often posed by laypeople and are not necessarily wellformed or explicit.", "labels": [], "entities": []}, {"text": "This is particularly evident in questions involving health issues., focusing on health-related questions submitted to Yahoo Answers, found that these questions primarily described diseases and symptoms (accompanied by some demographic information), were fairly long, dense (incorporating more than one question), and contained many abbreviations and misspellings.", "labels": [], "entities": []}, {"text": "For example, consider the following question posed by a consumer: (1) my question is this: I was born w/a esophagus atresia w/dextrocardia.", "labels": [], "entities": []}, {"text": "While the heart hasn't caused problems,the other has.", "labels": [], "entities": []}, {"text": "I get food caught all the time.", "labels": [], "entities": []}, {"text": "My question is...is there anything that can fix it cause I can't eat anything lately without getting it caught.", "labels": [], "entities": []}, {"text": "I need help or will starve!", "labels": [], "entities": []}, {"text": "It is clear that the person asking this question is mainly interested in learning about treatment options for his/her disease, in particular with respect to his/her esophagus.", "labels": [], "entities": []}, {"text": "Most of the textual content is not particularly relevant in understanding the question (I need help or will starve! or I get food caught all the time).", "labels": [], "entities": []}, {"text": "In addition, note the presence of anaphora (it referring to esophagus atresia) and ellipsis (the other has ), which should be resolved in order to automatically interpret the question.", "labels": [], "entities": []}, {"text": "Finally, note the informal fix instead of the more formal treat, and cause instead of because.", "labels": [], "entities": []}, {"text": "The National Library of Medicine \u00ae (NLM \u00ae ) receives questions from consumers on a variety of health-related topics.", "labels": [], "entities": [{"text": "National Library of Medicine \u00ae (NLM \u00ae )", "start_pos": 4, "end_pos": 43, "type": "DATASET", "confidence": 0.9112367298867967}]}, {"text": "These questions are currently manually answered by customer support services.", "labels": [], "entities": []}, {"text": "The overall goal of our work is to assist the customer support services by automatically interpreting these questions, using information retrieval techniques to find relevant documents and passages, and presenting the information in concise form for their assessment.", "labels": [], "entities": []}, {"text": "In this paper, we specifically focus on question understanding, rather than information re-trieval aspects of our ongoing work.", "labels": [], "entities": [{"text": "question understanding", "start_pos": 40, "end_pos": 62, "type": "TASK", "confidence": 0.8774881660938263}]}, {"text": "Our goal in question understanding is to capture the core aspects of the question in a structured representation (question frame), which can then be used to form a query for the search engine.", "labels": [], "entities": [{"text": "question understanding", "start_pos": 12, "end_pos": 34, "type": "TASK", "confidence": 0.7698156535625458}]}, {"text": "In the current work, we primarily investigate and evaluate the role of anaphora and ellipsis resolution in understanding the questions.", "labels": [], "entities": [{"text": "ellipsis resolution", "start_pos": 84, "end_pos": 103, "type": "TASK", "confidence": 0.7893906533718109}]}, {"text": "Our results confirm the viability of rule-based question understanding based on exploiting lexico-syntactic patterns and clearly demonstrate that anaphora and ellipsis resolution are beneficial for this task.", "labels": [], "entities": [{"text": "rule-based question understanding", "start_pos": 37, "end_pos": 70, "type": "TASK", "confidence": 0.6225340962409973}, {"text": "ellipsis resolution", "start_pos": 159, "end_pos": 178, "type": "TASK", "confidence": 0.73907271027565}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 4. In  the second column, the numbers in parentheses  correspond to the numbers of correctly identified  frames.", "labels": [], "entities": []}]}