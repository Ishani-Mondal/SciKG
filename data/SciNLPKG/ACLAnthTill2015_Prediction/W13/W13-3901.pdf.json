{"title": [{"text": "SLPAT in practice: lessons from translational research", "labels": [], "entities": [{"text": "SLPAT", "start_pos": 0, "end_pos": 5, "type": "TASK", "confidence": 0.8686431646347046}]}], "abstractContent": [{"text": "The talk will distil experience and results from several projects, over more than a decade, which have researched and developed the application of speech recognition as an input modality for assistive technology (AT).", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 147, "end_pos": 165, "type": "TASK", "confidence": 0.7279029339551926}, {"text": "assistive technology (AT)", "start_pos": 191, "end_pos": 216, "type": "TASK", "confidence": 0.6669016361236573}]}, {"text": "Current interfaces to AT for people with severe physical disabilities, such as switch-scanning, can be prohibitively slow and tiring to use.", "labels": [], "entities": []}, {"text": "Many people with severe physical disabilities also have some speech, though many also have poor control of speech articulators, leading to dysarthria.", "labels": [], "entities": []}, {"text": "Nonetheless, recognition of dysarthric speech can give people more control options than using body movement alone.", "labels": [], "entities": []}, {"text": "Speech can therefore bean attractive option for AT input.", "labels": [], "entities": [{"text": "AT input", "start_pos": 48, "end_pos": 56, "type": "TASK", "confidence": 0.838542252779007}]}, {"text": "Techniques that have been developed for optimising the recognition of dysarthric speech will be described, resulting in recognition rates of greater than 80% for people with even the most severe dysarthria.", "labels": [], "entities": [{"text": "recognition of dysarthric speech", "start_pos": 55, "end_pos": 87, "type": "TASK", "confidence": 0.841270238161087}]}, {"text": "Speech recognition has been applied as a means of controlling the home (via an environmental control system) and, probably for the first time, as a means of controlling a communication aid.", "labels": [], "entities": [{"text": "Speech recognition", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7825622260570526}]}, {"text": "The development of the Voice Input Voice Output Communication Aid (VICOCA) will be described and some early results of its evaluation presented.", "labels": [], "entities": [{"text": "Voice Input Voice Output Communication Aid (VICOCA)", "start_pos": 23, "end_pos": 74, "type": "TASK", "confidence": 0.6954338848590851}]}, {"text": "The talk will discuss some of the lessons learnt from these projects, such as: \u2022 The need to work in interdisciplinary teams including speech technologists, speech and language therapists, health researchers and assistive technologists.", "labels": [], "entities": []}, {"text": "\u2022 The value of user-centred design, involving users in defining their wants and needs and then working with them, in an iterative manner, to refine the AT such that it becomes usable and acceptable.", "labels": [], "entities": []}, {"text": "\u2022 The gap that exists between the results that can be achieved in the lab and those achievable in peoples homes under real usage conditions-something that is not often covered in research papers.", "labels": [], "entities": []}, {"text": "\u2022 The practical approaches that can be applied to optimising recognition for individuals.", "labels": [], "entities": [{"text": "optimising recognition", "start_pos": 50, "end_pos": 72, "type": "TASK", "confidence": 0.6042077839374542}]}, {"text": "It is often possible to make significant improvements in recognition rates by altering the configuration of the AT setup.", "labels": [], "entities": [{"text": "recognition", "start_pos": 57, "end_pos": 68, "type": "TASK", "confidence": 0.8960990309715271}]}, {"text": "The talk will conclude by describing some of the future potential applications of speech technology that are being developed, or considered, for people with disabilities as well as for frail older people and people with long-term conditions.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}