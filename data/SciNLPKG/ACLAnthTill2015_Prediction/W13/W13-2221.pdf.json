{"title": [{"text": "Edinburgh's Syntax-Based Machine Translation Systems", "labels": [], "entities": [{"text": "Edinburgh", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9651802182197571}, {"text": "Syntax-Based Machine Translation Systems", "start_pos": 12, "end_pos": 52, "type": "TASK", "confidence": 0.6817382648587227}]}], "abstractContent": [{"text": "We present the syntax-based string-to-tree statistical machine translation systems built for the WMT 2013 shared translation task.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 43, "end_pos": 74, "type": "TASK", "confidence": 0.6132771968841553}, {"text": "WMT 2013 shared translation task", "start_pos": 97, "end_pos": 129, "type": "TASK", "confidence": 0.7097722828388214}]}, {"text": "Systems were developed for four language pairs.", "labels": [], "entities": []}, {"text": "We report on adapting parameters, targeted reduction of the tuning set, and post-evaluation experiments on rule binarization and preventing dropping of verbs.", "labels": [], "entities": [{"text": "preventing dropping of verbs", "start_pos": 129, "end_pos": 157, "type": "TASK", "confidence": 0.7617520987987518}]}, {"text": "1 Overview Syntax-based machine translation models hold the promise to overcome some of the fundamental problems of the currently dominating phrase-based approach, most importantly handling reordering for syntactically divergent language pairs and grammatical coherence of the output.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 24, "end_pos": 43, "type": "TASK", "confidence": 0.7442391514778137}]}, {"text": "We are especially interested in string-to-tree models that focus syntactic annotation on the target side, especially for morphologically rich target languages (Williams and Koehn, 2011).", "labels": [], "entities": []}, {"text": "We have trained syntax-based systems for the language pairs \u2022 English-German, \u2022 German-English, \u2022 Czech-English, and \u2022 Russian-English.", "labels": [], "entities": []}, {"text": "We have also tried building systems for French-English and Spanish-English but the data size proved to be problematic given the time constraints.", "labels": [], "entities": []}, {"text": "We give a brief description of the syntax-based model and its implementation within the Moses system.", "labels": [], "entities": []}, {"text": "Some of the available features are described as well as some of the pre-processing steps.", "labels": [], "entities": []}, {"text": "Several experiments are described and final results are presented for each language pair.", "labels": [], "entities": []}, {"text": "2 System Description The syntax-based system used in all experiments is the Moses string-to-tree toolkit implementing GHKM rule extraction and Scope-3 parsing previously described in by Williams and Koehn (2012) 2.1 Grammar Our translation grammar is asynchronous context-free grammar (SCFG) with phrase-structure labels on the target side and the generic non-terminal label X on the source side.", "labels": [], "entities": [{"text": "GHKM rule extraction", "start_pos": 118, "end_pos": 138, "type": "TASK", "confidence": 0.7882192333539327}, {"text": "Scope-3 parsing", "start_pos": 143, "end_pos": 158, "type": "TASK", "confidence": 0.6551950126886368}]}, {"text": "In this paper, we write these rules in the form LHS \u2192 RHS s | RHS t where LHS is a target-side non-terminal label and RHS sand RHS tare strings of terminals and non-terminals for the source and target sides, respectively.", "labels": [], "entities": []}, {"text": "We use subscripted indices to indicate the correspondences between source and target non-terminals.", "labels": [], "entities": []}, {"text": "For example, a translation rule to translate the German Haus into the English house is NN \u2192 Haus | house If our grammar also contains the translation rule S \u2192 das ist ein X 1 | this is a NN 1 then we can apply the two rules to an input das ist ein Haus to produce the output this is a house.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "This section describes details for the syntax-based systems submitted by the University of Edinburgh.", "labels": [], "entities": []}, {"text": "Additional post-evaluation experiments were carried out for the German-English language pair.", "labels": [], "entities": []}, {"text": "Tree restructuring -In one experiment the parse trees were restructured before training by left binarization.", "labels": [], "entities": [{"text": "Tree restructuring", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.6618703603744507}]}, {"text": "Tree restructuring is need to improve generalization power of rules extracted from flat structures such as base noun phrases with several children.", "labels": [], "entities": []}, {"text": "The second raw in shows that the BLEU score did not improve and more glue rules were applied when using left binarization.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 33, "end_pos": 37, "type": "METRIC", "confidence": 0.9992914199829102}]}, {"text": "One reason for this result is that the rule extraction parameters MaxRuleDepth, MaxRuleSize, MaxNodes had the same values as in the baseline.", "labels": [], "entities": [{"text": "rule extraction", "start_pos": 39, "end_pos": 54, "type": "TASK", "confidence": 0.7198242396116257}, {"text": "MaxRuleDepth", "start_pos": 66, "end_pos": 78, "type": "DATASET", "confidence": 0.8805716037750244}]}, {"text": "Increasing this parameters should improve the extracted grammar since binarizing the trees will increase these three dimensions.", "labels": [], "entities": []}, {"text": "Verb dropping -A serious problem of German-English machine translation is the tendency to drop verbs, which shatters sentence structure.", "labels": [], "entities": [{"text": "Verb dropping", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.7645001113414764}, {"text": "German-English machine translation", "start_pos": 36, "end_pos": 70, "type": "TASK", "confidence": 0.6087849537531534}]}, {"text": "One cause of this problem is the failure of the IBM Models to properly align the German verb to its English equivalent, since it is often dislocated with respect to English word order.", "labels": [], "entities": [{"text": "IBM Models", "start_pos": 48, "end_pos": 58, "type": "DATASET", "confidence": 0.9391131401062012}]}, {"text": "Further problems appear when the main verb is not reordered in the target sentence, which can result in lower lan-   guage model scores and BLEU scores.", "labels": [], "entities": [{"text": "lan-   guage model scores", "start_pos": 110, "end_pos": 135, "type": "METRIC", "confidence": 0.6974973678588867}, {"text": "BLEU", "start_pos": 140, "end_pos": 144, "type": "METRIC", "confidence": 0.9991175532341003}]}, {"text": "However the syntax models handle the reordering of verbs better than phrase-based models.", "labels": [], "entities": []}, {"text": "In an experiment we investigated how the number of verbs dropped by the translation rules can be reduced.", "labels": [], "entities": []}, {"text": "In order to reduce the number of verb dropping rules we looked at unaligned verbs and realigned them before rule extraction.", "labels": [], "entities": [{"text": "verb dropping", "start_pos": 33, "end_pos": 46, "type": "TASK", "confidence": 0.7437906861305237}, {"text": "rule extraction", "start_pos": 108, "end_pos": 123, "type": "TASK", "confidence": 0.7368868589401245}]}, {"text": "An unaligned verb in the source sentence was aligned to the verb in the target sentence for which IBM model 1 predicted the highest translation probability.", "labels": [], "entities": []}, {"text": "The third row in shows the results of this experiment.", "labels": [], "entities": []}, {"text": "While there is no change in BLEU score the number of glue rules applied is lower.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 28, "end_pos": 38, "type": "METRIC", "confidence": 0.9735364615917206}]}, {"text": "Further analysis shows in that the number of verb dropping rules in the grammar is almost three times lower and that there are more translated verbs in the output when realigning verbs.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Corpus statistics for parallel data.", "labels": [], "entities": []}, {"text": " Table 3: Cased BLEU scores for various rule extraction parameter settings for German-English language  pair. The parameters considered are MaxRuleDepth, MaxRuleSize, MaxNodes. Grammar sizes are given  for the full extracted grammar and after filtering for the newstest2008 dev set.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 16, "end_pos": 20, "type": "METRIC", "confidence": 0.984135091304779}, {"text": "newstest2008 dev set", "start_pos": 261, "end_pos": 281, "type": "DATASET", "confidence": 0.8743439316749573}]}, {"text": " Table 4: Cased BLEU scores for German-English systems tuned on different data. Scores are emphasized  for the system submitted to the shared translation task.", "labels": [], "entities": [{"text": "Cased", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9103116989135742}, {"text": "BLEU", "start_pos": 16, "end_pos": 20, "type": "METRIC", "confidence": 0.8490046858787537}]}, {"text": " Table 5: Cased BLEU scores and manual evalua- tion scores (\"expected wins\") on the newstest2013  evaluation set for the phrase-based and syntax- based systems submitted by the University of Ed- inburgh.", "labels": [], "entities": [{"text": "Cased", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9241235852241516}, {"text": "BLEU", "start_pos": 16, "end_pos": 20, "type": "METRIC", "confidence": 0.8751919269561768}, {"text": "newstest2013  evaluation set", "start_pos": 84, "end_pos": 112, "type": "DATASET", "confidence": 0.9022384484608968}, {"text": "University of Ed- inburgh", "start_pos": 177, "end_pos": 202, "type": "DATASET", "confidence": 0.7634083986282348}]}, {"text": " Table 6: Cased BLEU scores for various German-English systems.", "labels": [], "entities": [{"text": "Cased", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9744364619255066}, {"text": "BLEU", "start_pos": 16, "end_pos": 20, "type": "METRIC", "confidence": 0.8588207364082336}]}, {"text": " Table 7: Statistics about verb dropping.", "labels": [], "entities": [{"text": "verb dropping", "start_pos": 27, "end_pos": 40, "type": "TASK", "confidence": 0.7912622094154358}]}]}