{"title": [{"text": "Constructing a Practical Constituent Parser from a Japanese Treebank with Function Labels", "labels": [], "entities": [{"text": "Japanese Treebank", "start_pos": 51, "end_pos": 68, "type": "DATASET", "confidence": 0.7508973479270935}]}], "abstractContent": [{"text": "We present an empirical study on constructing a Japanese constituent parser, which can output function labels to deal with more detailed syntactic information.", "labels": [], "entities": []}, {"text": "Japanese syntactic parse trees are usually represented as unlabeled dependency structure between bun-setsu chunks, however, such expression is insufficient to uncover the syntactic information about distinction between complements and adjuncts and coordination structure, which is required for practical applications such as syntactic reordering of machine translation.", "labels": [], "entities": [{"text": "syntactic reordering of machine translation", "start_pos": 325, "end_pos": 368, "type": "TASK", "confidence": 0.688670414686203}]}, {"text": "We describe a preliminary effort on constructing a Japanese constituent parser by a Penn Tree-bank style treebank semi-automatically made from a dependency-based corpus.", "labels": [], "entities": [{"text": "Penn Tree-bank style treebank", "start_pos": 84, "end_pos": 113, "type": "DATASET", "confidence": 0.9653672724962234}]}, {"text": "The evaluations show the parser trained on the tree-bank has comparable bracketing accuracy as conventional bunsetsu-based parsers, and can output such function labels as the grammatical role of the argument and the type of adnominal phrases.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.8746241927146912}]}], "introductionContent": [{"text": "In Japanese NLP, syntactic structures are usually represented as dependencies between grammatical chunks called bunsetsus.", "labels": [], "entities": []}, {"text": "A bunsetsu is a grammatical and phonological unit in Japanese, which consists of an independent-word such as noun, verb or adverb followed by a sequence of zero or more dependent-words such as auxiliary verbs, postpositional particles or sentence final particles.", "labels": [], "entities": []}, {"text": "It is one of main features of Japanese that bunsetsu order is much less constrained than phrase order in English.", "labels": [], "entities": [{"text": "phrase order", "start_pos": 89, "end_pos": 101, "type": "TASK", "confidence": 0.7200517356395721}]}, {"text": "Since dependency between bunsetsus can treat flexible bunsetsu order, most publicly available Japanese parsers including CaboCha () and KNP () return bunsetsu-based dependency as syntactic structure.", "labels": [], "entities": []}, {"text": "Such bunsetsubased parsers generally perform with high accuracy and have been widely used for various NLP applications.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9983347058296204}]}, {"text": "However, bunsetsu-based representations also have serious shortcomings for dealing with Japanese sentence hierarchy.", "labels": [], "entities": []}, {"text": "The internal structure of a bunsetsu has strong morphotactic constraints in contrast to flexible bunsetsu order.", "labels": [], "entities": []}, {"text": "A Japanese predicate bunsetsu consists of a main verb followed by a sequence of auxiliary verbs and sentence final particles.", "labels": [], "entities": []}, {"text": "There is an almost one-dimensional order in the verbal constituents, which reflects the basic hierarchy of the Japanese sentence structure including voice, tense, aspect and modality.", "labels": [], "entities": []}, {"text": "Bunsetsu-based representation cannot provide the linguistic structure that reflects the basic sentence hierarchy.", "labels": [], "entities": [{"text": "Bunsetsu-based representation", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.6414149552583694}]}, {"text": "Moreover, bunsetsu-based structures are unsuitable for representing such nesting structure as coordinating conjunctions.", "labels": [], "entities": []}, {"text": "For instance, bunsetsu representation of a noun phrase \"-(technology-GEN) / -(improvement-CONJ) / -(economy-GEN) / (growth) \" technology improvement and economic growth does not allow us to easily interpret it, which means ((technology improvement) and (economic growth)) or (technology (improvement and economic growth)), because bunsetsu-based dependencies do not convey information about left boundary of each noun phrase.", "labels": [], "entities": []}, {"text": "This drawback complicates operating syntactically meaningful units in such applications as statistical machine translation, which needs to recognize syntactic units in building a translation model (e.g. tree-to-string and tree-to-tree) and in preordering source language sentences.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 91, "end_pos": 122, "type": "TASK", "confidence": 0.6850858827431997}]}, {"text": "Semantic analysis, such as predicate-argument structure analysis, is usually done as a pipeline process after syntactic analysis; but in Japanese, the discrepancy between syntactic and semantic units cause difficulties integrating semantic analysis with syntactic analysis.", "labels": [], "entities": [{"text": "Semantic analysis", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.829429566860199}, {"text": "predicate-argument structure analysis", "start_pos": 27, "end_pos": 64, "type": "TASK", "confidence": 0.7484257221221924}]}, {"text": "Our goal is to construct a practical constituent parser that can deal with appropriate grammatical units and output grammatical functions as semisemantic information, e.g., grammatical or semantic roles of arguments and gapping types of relative clauses.", "labels": [], "entities": []}, {"text": "We take an approach to deriving a grammar from manually annotated corpora by training probabilistic models like current statistical constituent parsers of de facto standards ().", "labels": [], "entities": []}, {"text": "We used a constituent-based treebank that converted from an existing bunsetsubased corpus as abase treebank, and retag the nonterminals and transform the tree structures in described in Section 3.", "labels": [], "entities": []}, {"text": "We will present the results of evaluations of the parser trained with the treebank in Section 4, and show some analyses in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "The original Kyoto Corpus has 38,400 sentences and they were automatically converted to constituent structures.", "labels": [], "entities": [{"text": "Kyoto Corpus", "start_pos": 13, "end_pos": 25, "type": "DATASET", "confidence": 0.9890085756778717}]}, {"text": "The function tags are also added to the corpus by integrating predicate-argument information in the NAIST Text corpus.", "labels": [], "entities": [{"text": "NAIST Text corpus", "start_pos": 100, "end_pos": 117, "type": "DATASET", "confidence": 0.9820098678270975}]}, {"text": "Since the conversion contains errors of structures and tags, about half of them were manually checked to avoid the effects of the conversion errors.", "labels": [], "entities": []}, {"text": "We evaluated our treebank's effectiveness for parser training with 18,640 sentences, which were divided into three sets: 14,895 sentences fora train-   ing set, 1,860 sentences fora test set, and the remainder fora development set.", "labels": [], "entities": []}, {"text": "The basic evaluations were under the condition of using the original tag sets: the basic set Base, which contains all the preterminal tags in and the phrase tags in, except the IP and CP tags, and the full set Full, which has Base + IP, CP tags, and all the function tags.", "labels": [], "entities": []}, {"text": "The basic set Base is provided to evaluate the constituent parser performance in case that we need better performance at the cost of limiting the information.", "labels": [], "entities": []}, {"text": "We used two types of function tag sets: Full sr for semantic roles and Full gr for grammatical roles.", "labels": [], "entities": []}, {"text": "We added the following complementary information to the tags and named the new tag sets Base or inf: add inflection information to the POS tag (verbs, adjectives, and auxiliary verbs) and the phrase tags.", "labels": [], "entities": []}, {"text": "lex: lexicalize the closed words, i.e., auxiliary verbs and particles.", "labels": [], "entities": []}, {"text": "vsub: add verb subcategorization to the verb and verb phrase tags.", "labels": [], "entities": []}, {"text": "vsub alt: add verb subcategorization and case alternation to the verb and verb phrase tags.", "labels": [], "entities": []}, {"text": "In comparing the system output with the gold standard, we remove the complementary information to ignore different level of annotation, thus, we do not discriminate between VB[na] and VB for example.", "labels": [], "entities": [{"text": "VB", "start_pos": 184, "end_pos": 186, "type": "DATASET", "confidence": 0.8238289952278137}]}, {"text": "We used the Berkeley parser () for our evaluation and trained with six iterations for latent annotations.", "labels": [], "entities": []}, {"text": "In training the n-ary trees, we used a default Markovization parameter (h = 0, v = 1), because the parser performed the best with the development set.", "labels": [], "entities": []}, {"text": "shows the parsing results of the test sets.", "labels": [], "entities": []}, {"text": "On the whole, the binary tree outperformed the nary tree.", "labels": [], "entities": []}, {"text": "This indicates that the binary tree structure was converted from bunsetsu-based dependencies, whose characteristics are described in Section 3.3, and is better for parser training than the partially flattened structure.", "labels": [], "entities": []}, {"text": "As for additional information, the inflection suffixes slightly improved the F 1 -metrics.", "labels": [], "entities": [{"text": "F 1 -metrics", "start_pos": 77, "end_pos": 89, "type": "METRIC", "confidence": 0.9198939800262451}]}, {"text": "This is mainly because the inflection information gives the category of the attached phrase (e.g., the attributive form for noun phrases).", "labels": [], "entities": []}, {"text": "The others did not provide any improvement, even though we expected the subcategorization and case alternation information to help the parser detect and discriminate the grammatical roles, probably because we simply introduced the information by concatenating the suffixes to the base tags to adapt an off-the-shelf parser in our evaluation.", "labels": [], "entities": []}, {"text": "For instance, VB[n] and VB are recognized as entirely independent categories; a sophisticated model, which can treat them hierarchically, would improve the performance.", "labels": [], "entities": [{"text": "VB", "start_pos": 24, "end_pos": 26, "type": "DATASET", "confidence": 0.7861567139625549}]}, {"text": "For comparison with a bunsetsu-based dependency parser, we convert the parser output into unlabeled bunsetsu dependencies by the following simple way.", "labels": [], "entities": []}, {"text": "We first extract all bunsetsu chunks in a sentence and find a minimum phrase including each bunsetsu chunk from a constituent structure.", "labels": [], "entities": []}, {"text": "For each pair of bunsetsus having a common parent phrase, we add a dependency from the left bunsetsu to the right one, since Japanese is a head-final language.", "labels": [], "entities": []}, {"text": "The unlabeled attachment scores of the converted dependencies are shown as the accuracies in, since most bunsetsu-based dependency parsers output only unlabeled structure.", "labels": [], "entities": []}, {"text": "The Base inf results are comparable with the bunsetsu-dependency results (90.46%) over the same corpus () 1 , which has only the same level of information.", "labels": [], "entities": []}, {"text": "Constituent parsing with treebank almost matched the current bunsetsu parsing.", "labels": [], "entities": [{"text": "Constituent parsing", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.4634775370359421}, {"text": "bunsetsu parsing", "start_pos": 61, "end_pos": 77, "type": "TASK", "confidence": 0.7005966603755951}]}], "tableCaptions": [{"text": " Table 4: Parse results displayed by labeled and unla- beled F 1 metrics and proportion of sentences completely  matching gold standard (Comp). Base contains only ba- sic tags, not grammatical function tags. Figures with '\u22c6'  indicate statistically significant differences (\u03b1 = 0.05)  from the results without complementary information, i.e.,  Full sr or Full gr .", "labels": [], "entities": [{"text": "Parse", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9124705195426941}]}, {"text": " Table 6: Discrimination of semantic role and grammati- cal role labels (upper: semantic roles, lower: grammatical  role)", "labels": [], "entities": []}, {"text": " Table 7: Confusion matrix for grammatical role labels  (recall). Figures with '*' indicate recall.(binary tree,  Full gr )", "labels": [], "entities": [{"text": "recall", "start_pos": 57, "end_pos": 63, "type": "METRIC", "confidence": 0.9542344212532043}, {"text": "recall.", "start_pos": 92, "end_pos": 99, "type": "METRIC", "confidence": 0.9930691719055176}]}, {"text": " Table 8: Results of adnominal phrase and sentential ele- ment (binary tree, Full gr )", "labels": [], "entities": []}, {"text": " Table 9: Confusion matrix for adnominal phrases (recall).  Figures with '*' indicate recall.(binary tree, Full gr )", "labels": [], "entities": [{"text": "recall", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.9853609204292297}, {"text": "recall.", "start_pos": 86, "end_pos": 93, "type": "METRIC", "confidence": 0.9959813356399536}]}, {"text": " Table 10: Results of coordination and apposition (binary  tree, Full gr )", "labels": [], "entities": []}]}