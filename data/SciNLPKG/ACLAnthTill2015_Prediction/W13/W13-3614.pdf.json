{"title": [], "abstractContent": [{"text": "We describe the 'TILB' team entry for the CONLL-2013 Shared Task.", "labels": [], "entities": [{"text": "CONLL-2013 Shared Task", "start_pos": 42, "end_pos": 64, "type": "DATASET", "confidence": 0.8608715732892355}]}, {"text": "Our system consists of five memory-based classi-fiers that generate correction suggestions for center positions in small text windows of two words to the left and to the right.", "labels": [], "entities": []}, {"text": "Trained on the Google Web 1T corpus, the first two classifiers determine the presence of a determiner or a preposition between all words in a text.", "labels": [], "entities": [{"text": "Google Web 1T corpus", "start_pos": 15, "end_pos": 35, "type": "DATASET", "confidence": 0.800803542137146}]}, {"text": "The second pair of clas-sifiers determine which is the most likely correction of an occurring determiner or preposition.", "labels": [], "entities": []}, {"text": "The fifth classifier is a general word predictor which is used to suggest noun and verb form corrections.", "labels": [], "entities": [{"text": "noun and verb form corrections", "start_pos": 74, "end_pos": 104, "type": "TASK", "confidence": 0.651941043138504}]}, {"text": "We report on the scores attained and errors corrected and missed.", "labels": [], "entities": []}, {"text": "We point out a number of obvious improvements to boost the scores obtained by the system.", "labels": [], "entities": []}], "introductionContent": [{"text": "Our team entry, known under the abbreviation 'TILB' in the CONLL-2013 Shared Task, is a simplistic text and grammar correction system based on five memory-based classifiers implementing eight different error correctors.", "labels": [], "entities": [{"text": "TILB", "start_pos": 46, "end_pos": 50, "type": "METRIC", "confidence": 0.949782133102417}, {"text": "CONLL-2013 Shared Task", "start_pos": 59, "end_pos": 81, "type": "DATASET", "confidence": 0.874168872833252}, {"text": "text and grammar correction", "start_pos": 99, "end_pos": 126, "type": "TASK", "confidence": 0.6783093065023422}]}, {"text": "The goal of the system is to be lightweight: simple to setup and train, fast in execution.", "labels": [], "entities": []}, {"text": "It requires a preferably very large but unannotated corpus to train on, and closed lists of words that contain categories of interest (in our case, determiners and prepositions).", "labels": [], "entities": []}, {"text": "The error correctors make use of information from a lemmatizer and a noun and verb inflection module.", "labels": [], "entities": []}, {"text": "The amount of explicit grammatical information input in the system is purposely kept to a minimum, as accurate deep grammatical information cannot be assumed to be present inmost real-world situations and languages.", "labels": [], "entities": []}, {"text": "The system described in this article takes plain text as input and produces plain text as output.", "labels": [], "entities": []}, {"text": "Memory-based classifiers have been applied to similar tasks before.", "labels": [], "entities": []}, {"text": "(Van den Bosch, 2006) describes memory based classifiers used for confusible disambiguation, and (Stehouwer and Van den Bosch, 2009) shows how agreement errors can be detected.", "labels": [], "entities": []}, {"text": "In the 2012 shared task 'Helping Our Own' () memory based classifiers were used to solve the problem of missing and incorrect determiners and prepositions.", "labels": [], "entities": []}, {"text": "The CONLL-2013 Shared Task context limited the grammatical error correction task to detecting and correcting five error types: ArtOrDet Missing, unnecessary or incorrect article or determiner; Prep Incorrect preposition used; Nn Wrong form of noun used (e.g. singular instead of plural); Vform Incorrect verb form used (e.g. I have went); SVA Incorrect subject-verb agreement (e.g. He have).", "labels": [], "entities": [{"text": "CONLL-2013 Shared Task context", "start_pos": 4, "end_pos": 34, "type": "DATASET", "confidence": 0.8794264048337936}, {"text": "grammatical error correction task", "start_pos": 47, "end_pos": 80, "type": "TASK", "confidence": 0.7227073609828949}]}, {"text": "The corrections made by the system are scored by a program provided by the organizers.", "labels": [], "entities": []}, {"text": "It takes a plain textfile as input (the output generated by the system) and outputs a list with correctly rectified errors followed by precision, recall and F-score.", "labels": [], "entities": [{"text": "precision", "start_pos": 135, "end_pos": 144, "type": "METRIC", "confidence": 0.9996932744979858}, {"text": "recall", "start_pos": 146, "end_pos": 152, "type": "METRIC", "confidence": 0.9993450045585632}, {"text": "F-score", "start_pos": 157, "end_pos": 164, "type": "METRIC", "confidence": 0.9975041747093201}]}, {"text": "As training material we used two corpora.", "labels": [], "entities": []}, {"text": "The Google Web 1T corpus () was used to train the classifiers for the ArtOrDet and Prep error categories.", "labels": [], "entities": [{"text": "Google Web 1T corpus", "start_pos": 4, "end_pos": 24, "type": "DATASET", "confidence": 0.855869472026825}]}, {"text": "The GigaWord Newspaper text corpus 1 was used to create the data for the classifier for the noun and verb-related error categories.", "labels": [], "entities": [{"text": "GigaWord Newspaper text corpus 1", "start_pos": 4, "end_pos": 36, "type": "DATASET", "confidence": 0.9631875634193421}]}, {"text": "To make the classifiers more compatible with each other, future versions of the system will all be trained on the same corpus.", "labels": [], "entities": []}, {"text": "We also used two lists, one consisting of 64 prepositions and one consisting of 23 determiners, both extracted from the CONLL-2013 Shared Task training data.", "labels": [], "entities": [{"text": "CONLL-2013 Shared Task training data", "start_pos": 120, "end_pos": 156, "type": "DATASET", "confidence": 0.9136717438697814}]}, {"text": "Using the Google corpus means that we restricted ourselves to a simple 5-gram context, which obviously places a limit on the context sensitivity of our system; on the other hand, we were able to make use of the entire Google Web 1T corpus.", "labels": [], "entities": [{"text": "Google corpus", "start_pos": 10, "end_pos": 23, "type": "DATASET", "confidence": 0.8974692821502686}, {"text": "Google Web 1T corpus", "start_pos": 218, "end_pos": 238, "type": "DATASET", "confidence": 0.7707054167985916}]}, {"text": "The context for the grammatical error detectors was kept similar to the other classifiers, also 5-grams.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}