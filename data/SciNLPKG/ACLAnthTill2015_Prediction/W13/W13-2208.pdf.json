{"title": [{"text": "Chimera -Three Heads for English-to-Czech Translation", "labels": [], "entities": [{"text": "English-to-Czech Translation", "start_pos": 25, "end_pos": 53, "type": "TASK", "confidence": 0.6829935759305954}]}], "abstractContent": [{"text": "This paper describes our WMT submissions CU-BOJAR and CU-DEPFIX, the latter dubbed \"CHIMERA\" because it combines on three diverse approaches: Tec-toMT, a system with transfer at the deep syntactic level of representation, factored phrase-based translation using Moses, and finally automatic rule-based correction of frequent grammatical and meaning errors.", "labels": [], "entities": [{"text": "WMT submissions CU-BOJAR", "start_pos": 25, "end_pos": 49, "type": "TASK", "confidence": 0.7475335796674093}, {"text": "factored phrase-based translation", "start_pos": 222, "end_pos": 255, "type": "TASK", "confidence": 0.5745368301868439}]}, {"text": "We do not use any off-the-shelf system-combination method.", "labels": [], "entities": []}], "introductionContent": [{"text": "Targeting Czech in statistical machine translation (SMT) is notoriously difficult due to the large number of possible word forms and complex agreement rules.", "labels": [], "entities": [{"text": "Targeting Czech in statistical machine translation (SMT)", "start_pos": 0, "end_pos": 56, "type": "TASK", "confidence": 0.7627067532804277}]}, {"text": "Previous attempts to resolve these issues include specific probabilistic models or leaving the morphological generation to a separate processing step).", "labels": [], "entities": []}, {"text": "TectoMT (CU-TECTOMT,) is a hybrid (rule-based and statistical) MT system that closely follows the analysis-transfersynthesis pipeline.", "labels": [], "entities": [{"text": "MT", "start_pos": 63, "end_pos": 65, "type": "TASK", "confidence": 0.9608181118965149}]}, {"text": "As such, it suffers from many issues but generating word forms in proper agreements with their neighbourhood as well as the translation of some diverging syntactic structures are handled well.", "labels": [], "entities": []}, {"text": "Overall, TectoMT sometimes even ties with a highly tuned Moses configuration in manual evaluations, see . Finally, describes Depfix, a rule-based system for post-processing (S)MT output that corrects some morphological, syntactic and even semantic mistakes.", "labels": [], "entities": []}, {"text": "Depfix was able to significantly improve Google output in WMT12, so now we applied it on an open-source system.", "labels": [], "entities": [{"text": "WMT12", "start_pos": 58, "end_pos": 63, "type": "DATASET", "confidence": 0.9204422831535339}]}, {"text": "Our WMT13 system is thus a three-headed creature where, hopefully: (1) TectoMT provides missing word forms and safely handles some nonparallel syntactic constructions, (2) Moses exploits very large parallel and monolingual data, and boosts better lexical choice, (3) Depfix attempts to fix severe flaws in Moses output.", "labels": [], "entities": []}, {"text": "CHIMERA is a sequential combination of three diverse MT systems as depicted in.", "labels": [], "entities": [{"text": "CHIMERA", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8157209753990173}, {"text": "MT", "start_pos": 53, "end_pos": 55, "type": "TASK", "confidence": 0.9665324091911316}]}, {"text": "Each of the intermediate stages of processing has been submitted as a separate primary system for the WMT manual evalution, allowing fora more thorough analysis.", "labels": [], "entities": [{"text": "WMT manual evalution", "start_pos": 102, "end_pos": 122, "type": "TASK", "confidence": 0.745578408241272}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Basic Statistics of Parallel Data.", "labels": [], "entities": [{"text": "Basic Statistics of Parallel Data", "start_pos": 10, "end_pos": 43, "type": "DATASET", "confidence": 0.7126829504966736}]}, {"text": " Table 3: Rough wallclock time [hours] of word  alignment and the resulting BLEU scores.", "labels": [], "entities": [{"text": "word  alignment", "start_pos": 42, "end_pos": 57, "type": "TASK", "confidence": 0.724757120013237}, {"text": "BLEU", "start_pos": 76, "end_pos": 80, "type": "METRIC", "confidence": 0.9991989731788635}]}, {"text": " Table 4: Basic Statistics of Monolingual Data.", "labels": [], "entities": [{"text": "Basic Statistics of Monolingual Data", "start_pos": 10, "end_pos": 46, "type": "DATASET", "confidence": 0.7001816272735596}]}, {"text": " Table 5: LMs used in CU-BOJAR.", "labels": [], "entities": [{"text": "CU-BOJAR", "start_pos": 22, "end_pos": 30, "type": "DATASET", "confidence": 0.9046114087104797}]}, {"text": " Table 6: Our big tuning set (bigref).", "labels": [], "entities": []}, {"text": " Table 9: CHIMERA components that contribute  \"confirmed\" tokens.", "labels": [], "entities": []}, {"text": " Table 10: Tokens missing in CHIMERA output.", "labels": [], "entities": [{"text": "CHIMERA output", "start_pos": 29, "end_pos": 43, "type": "DATASET", "confidence": 0.731874942779541}]}, {"text": " Table 11: Depfix components performance analy- sis on 871 sentences from WMT13 test set.", "labels": [], "entities": [{"text": "WMT13 test set", "start_pos": 74, "end_pos": 88, "type": "DATASET", "confidence": 0.9725873470306396}]}]}