{"title": [{"text": "CoNLL-2013 Shared Task: Grammatical Error Correction NTHU System Description", "labels": [], "entities": [{"text": "Grammatical Error Correction NTHU System Description", "start_pos": 24, "end_pos": 76, "type": "TASK", "confidence": 0.5872655808925629}]}], "abstractContent": [{"text": "Grammatical error correction has been an active research area in the field of Natural Language Processing.", "labels": [], "entities": [{"text": "Grammatical error correction", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8598099748293558}, {"text": "Natural Language Processing", "start_pos": 78, "end_pos": 105, "type": "TASK", "confidence": 0.6499954760074615}]}, {"text": "This paper describes the grammatical error correction system developed at NTHU in participation of the CoNLL-2013 Shared Task.", "labels": [], "entities": [{"text": "grammatical error correction", "start_pos": 25, "end_pos": 53, "type": "TASK", "confidence": 0.5559233725070953}, {"text": "NTHU", "start_pos": 74, "end_pos": 78, "type": "DATASET", "confidence": 0.9659604430198669}, {"text": "CoNLL-2013 Shared Task", "start_pos": 103, "end_pos": 125, "type": "DATASET", "confidence": 0.7340222795804342}]}, {"text": "The system consists of four modules in a pipeline to correct errors related to determiners, prepositions, verb forms and noun number.", "labels": [], "entities": []}, {"text": "Although more types of errors are involved that than last year's Shared Task, leading to more complicated problem this year, our system still obtain higher F-score as compared to last year.", "labels": [], "entities": [{"text": "F-score", "start_pos": 156, "end_pos": 163, "type": "METRIC", "confidence": 0.9994805455207825}]}, {"text": "We received an overall F-measure score of 0.325, which put our system in second place among 17 systems evaluated.", "labels": [], "entities": [{"text": "F-measure score", "start_pos": 23, "end_pos": 38, "type": "METRIC", "confidence": 0.978223979473114}]}], "introductionContent": [{"text": "Grammatical error correction is a task involving automatically detecting and correcting grammatical errors and improper choices.", "labels": [], "entities": [{"text": "Grammatical error correction", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.821043868859609}, {"text": "automatically detecting and correcting grammatical errors and improper choices", "start_pos": 49, "end_pos": 127, "type": "TASK", "confidence": 0.6913304792510139}]}, {"text": "Grammatical error correction in writing of English as a second language (L2) or foreign language (EFL) is an important issue, for there are 375 million L2 speakers and 750 million EFL speakers around the world).", "labels": [], "entities": [{"text": "Grammatical error correction", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.6761940817038218}]}, {"text": "Most of these non-native speakers tend to make many kinds of error in their writing.", "labels": [], "entities": []}, {"text": "An error correction system has the short-term benefit of helping writers improve the quality of writing.", "labels": [], "entities": [{"text": "error correction", "start_pos": 3, "end_pos": 19, "type": "TASK", "confidence": 0.693856805562973}]}, {"text": "In the long run, non-native writers might learn from the corrections and thus gradually gain better command of grammar and word choice.", "labels": [], "entities": []}, {"text": "The HOO shared task of 2012 is aimed at detecting and correcting misuse of determiners and prepositions, two types of errors accounting for only 38% of all errors.", "labels": [], "entities": [{"text": "HOO shared task of 2012", "start_pos": 4, "end_pos": 27, "type": "DATASET", "confidence": 0.7542004823684693}, {"text": "detecting and correcting misuse of determiners and prepositions", "start_pos": 40, "end_pos": 103, "type": "TASK", "confidence": 0.7329912409186363}]}, {"text": "Therefore, there area lot more errors related to other parts of speech that we have to address in this year's shared task.", "labels": [], "entities": []}, {"text": "In this paper, we describe the system submission from NTHU.", "labels": [], "entities": [{"text": "NTHU", "start_pos": 54, "end_pos": 58, "type": "DATASET", "confidence": 0.9743331670761108}]}, {"text": "The system reads and processes a given sentence through a pipeline of four distinct modules dealing with determiners, prepositions, verb forms and noun plurality.", "labels": [], "entities": []}, {"text": "The output of one module feeds into the next module as input.", "labels": [], "entities": []}, {"text": "The system finally produces possibly corrected sentences.", "labels": [], "entities": []}, {"text": "The rest of the article is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes detection and correction approach of each module in detail.", "labels": [], "entities": [{"text": "detection and correction", "start_pos": 20, "end_pos": 44, "type": "TASK", "confidence": 0.6340776681900024}]}, {"text": "Section 3 describes experiment setting and results.", "labels": [], "entities": []}, {"text": "Then in Section 4, we discuss strengths and limitations of the proposed system and directions of future work.", "labels": [], "entities": []}, {"text": "We conclude in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "To assess the effectiveness of the proposed method, we used the official training and testing data of CoNLL-2013 Shared Task.", "labels": [], "entities": [{"text": "CoNLL-2013 Shared Task", "start_pos": 102, "end_pos": 124, "type": "DATASET", "confidence": 0.8043535351753235}]}, {"text": "We also exploited several tools including Linggle, Stanford Parser and Geniatagger in the proposed system.", "labels": [], "entities": [{"text": "Linggle", "start_pos": 42, "end_pos": 49, "type": "DATASET", "confidence": 0.9421102404594421}]}, {"text": "Linggle supports flexible linguistic queries with wild part of speech and returns matching ngrams counts in Google Web 1T 5gram.", "labels": [], "entities": [{"text": "Linggle", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9356792569160461}, {"text": "Google Web 1T 5gram", "start_pos": 108, "end_pos": 127, "type": "DATASET", "confidence": 0.8658153414726257}]}, {"text": "Stanford Parser and Geniatagger produce syntactical information including dependency relations, part-of-speech tags, and phrase boundary.", "labels": [], "entities": []}, {"text": "The evaluation scorer, which computes precision, recall, and F-score, is provided by National University of Singapore, the organizer of CoNLL-2013 Shared Task.", "labels": [], "entities": [{"text": "precision", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9979992508888245}, {"text": "recall", "start_pos": 49, "end_pos": 55, "type": "METRIC", "confidence": 0.9992713332176208}, {"text": "F-score", "start_pos": 61, "end_pos": 68, "type": "METRIC", "confidence": 0.9988553524017334}, {"text": "National University of Singapore", "start_pos": 85, "end_pos": 117, "type": "DATASET", "confidence": 0.9244243949651718}]}, {"text": "On the test data, our system obtained the precision, recall and F-score of .3057, 0.346, and .3246, which put us in first place in term of recall and second place in term of F-score.", "labels": [], "entities": [{"text": "precision", "start_pos": 42, "end_pos": 51, "type": "METRIC", "confidence": 0.9998438358306885}, {"text": "recall", "start_pos": 53, "end_pos": 59, "type": "METRIC", "confidence": 0.9993284940719604}, {"text": "F-score", "start_pos": 64, "end_pos": 71, "type": "METRIC", "confidence": 0.9994495511054993}, {"text": "recall", "start_pos": 139, "end_pos": 145, "type": "METRIC", "confidence": 0.9922852516174316}, {"text": "F-score", "start_pos": 174, "end_pos": 181, "type": "METRIC", "confidence": 0.9957081079483032}]}], "tableCaptions": [{"text": " Table 2. Trigram information of 'location' and  'locations' in back-off model", "labels": [], "entities": []}, {"text": " Table 3. Verb form n-grams with PMIs.", "labels": [], "entities": []}, {"text": " Table 4. Sample search results of \"being ?$PP a  dangerous situation\" *", "labels": [], "entities": []}]}