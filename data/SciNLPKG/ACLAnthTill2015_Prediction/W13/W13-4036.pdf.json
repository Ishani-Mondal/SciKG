{"title": [{"text": "Training and evaluation of an MDP model for social multi-user human-robot interaction", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes anew approach to automatic learning of strategies for social multiuser human-robot interaction.", "labels": [], "entities": []}, {"text": "Using the example of a robot bartender that tracks multiple customers, takes their orders , and serves drinks, we propose a model consisting of a Social State Recog-niser (SSR) which processes audiovisual input and maintains a model of the social state, together with a Social Skills Executor (SSE) which takes social state updates from the SSR as input and generates robot responses as output.", "labels": [], "entities": []}, {"text": "The SSE is modelled as two connected Markov Decision Processes (MDPs) with action selection policies that are jointly optimised in interaction with a MultiUser Simulation Environment (MUSE).", "labels": [], "entities": []}, {"text": "The SSR and SSE have been integrated in the robot bartender system and evaluated with human users in hand-coded and trained SSE policy variants.", "labels": [], "entities": [{"text": "SSR", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.9204272031784058}]}, {"text": "The results indicate that the trained policy out-performed the hand-coded policy in terms of both subjective (+18%) and objective (+10.5%) task success.", "labels": [], "entities": []}], "introductionContent": [{"text": "As the use of robot technology in the home as well as in public spaces is increasingly gaining attention, the need for effective and robust models for natural and social human robot interaction becomes more important.", "labels": [], "entities": []}, {"text": "Whether it involves robot companions (), game-playing robots), or robots that help people with exercising, human users should be able to interact with such service robots in an effective and natural way, using speech as well as other modalities of communication.", "labels": [], "entities": []}, {"text": "Furthermore, with the emergence of new application domains there is a particular need for methods that enable rapid development of models for such new domains.", "labels": [], "entities": []}, {"text": "In this respect, datadriven approaches are appealing for their capability to automatically exploit empirical data to arrive at realistic and effective models for interpreting user behaviour, as well as to learn strategies for effective system behaviour.", "labels": [], "entities": []}, {"text": "In spoken dialogue systems research, statistical methods for spoken language understanding, dialogue management, and natural language generation have proven to be feasible for effective and robust interactive systems (.", "labels": [], "entities": [{"text": "spoken language understanding", "start_pos": 61, "end_pos": 90, "type": "TASK", "confidence": 0.6533537010351816}, {"text": "dialogue management", "start_pos": 92, "end_pos": 111, "type": "TASK", "confidence": 0.8532167375087738}, {"text": "natural language generation", "start_pos": 117, "end_pos": 144, "type": "TASK", "confidence": 0.7020993232727051}]}, {"text": "Although such methods have recently also been applied to (multi-modal) human-robot interaction), work on multi-user humanrobot interaction has been limited to non-statistical, hand-coded models).", "labels": [], "entities": []}, {"text": "On the other hand, substantial work has been done in the field of situated multi-party interaction in general, including data-driven approaches.", "labels": [], "entities": []}, {"text": "In particular, have addressed the task of recognising engagement intentions using online learning in the setting of a screen-based embodied virtual receptionist, and have also worked on multi-party turn-taking in this context ().", "labels": [], "entities": []}, {"text": "In this paper we describe a statistical approach to automatic learning of strategies for selecting effective as well as socially appropriate robot actions in a multi-user context.", "labels": [], "entities": []}, {"text": "The approach has been developed using the example of a robot bartender (see) that tracks multiple customers, takes their orders, and serves drinks.", "labels": [], "entities": []}, {"text": "We propose a model consisting of a Social State Recogniser (SSR) which processes audio-visual input and maintains a model of the social state, and a Social Skills Executor (SSE) which takes social state updates from the SSR as input and generates robot responses as out-put.", "labels": [], "entities": []}, {"text": "The SSE is modelled as a hierarchy of two connected Markov Decision Processes (MDPs) with action selection policies that are jointly optimised in interaction with a Multi-User Simulation Environment (MUSE).", "labels": [], "entities": []}], "datasetContent": [{"text": "The SSE described above has been integrated in the full robot bartender system and evaluated for the first time with human users.", "labels": [], "entities": []}, {"text": "In the experiment, both a hand-coded version and a trained version of the SSE component were tested; see in Appendix A for the trajectory of state-action pairs of an example session.", "labels": [], "entities": []}, {"text": "The hand-coded version uses the policy labelled HDC, not HDCnp (see Section 6.1).", "labels": [], "entities": [{"text": "HDCnp", "start_pos": 57, "end_pos": 62, "type": "DATASET", "confidence": 0.8445864915847778}]}, {"text": "In each of the sessions carried out, one recruited subject and one confederate (one of the experimenters) approached the bartender together as clients and both tried to order a drink (coke or lemonade).", "labels": [], "entities": []}, {"text": "After each interaction, the subject filled out the short questionnaire shown in.", "labels": [], "entities": []}, {"text": "37 subjects took part in this study, resulting in a total of 58 recorded drink-ordering interactions: 29 that used the hand-coded SSE for interaction management, and 29 that used the trained SSE.", "labels": [], "entities": [{"text": "interaction management", "start_pos": 138, "end_pos": 160, "type": "TASK", "confidence": 0.7079919427633286}]}, {"text": "The results from the experiment are summarised in.", "labels": [], "entities": []}, {"text": "We analysed the results using a linear mixed model, treating the SSE policy as a fixed factor and the subject ID as a random factor.", "labels": [], "entities": []}, {"text": "Overall, the pattern of the subjective scores suggests a slight preference for the trained SSE version, although: Actions for the single-user interaction policy, which correspond to possible dialogue acts, except for 'no action' and serving a drink.", "labels": [], "entities": []}, {"text": "The specific drink types required for two of the actions are extracted from the fully specified user goal in the social state maintained by the SSR.", "labels": [], "entities": []}, {"text": "only the difference in perceived success was statistically significant at the p < 0.05 level.", "labels": [], "entities": []}, {"text": "The actual success rate of the trained policy was also somewhat higher, although not significantly so.", "labels": [], "entities": []}, {"text": "Also, the interactions with the trained SSE took slightly longer than the ones with the hand-coded SSE in terms of the number of system turns (i.e., the number of times the SSE receives a state update and selects a response action, excluding the times when it selects a non-action); however, this did not have any overall effect on the users' subjective ratings.", "labels": [], "entities": []}, {"text": "The higher success rate for the trained SSE could be partly explained by the fact that fewer ASR problems were encountered when using this version; however, since the SSE was not triggered when a turn was discarded due to low-confidence ASR, this would not have had an effect on the number of system turns.", "labels": [], "entities": [{"text": "ASR", "start_pos": 93, "end_pos": 96, "type": "TASK", "confidence": 0.8993313908576965}]}, {"text": "We also carried out a stepwise multiple linear regression on the data from the user experiment to determine which of the objective measures had the largest effect, as suggested by the PARADISE evaluation framework ().", "labels": [], "entities": [{"text": "PARADISE evaluation framework", "start_pos": 184, "end_pos": 213, "type": "DATASET", "confidence": 0.6340076327323914}]}, {"text": "The resulting regression functions are shown in.", "labels": [], "entities": []}, {"text": "In summary, all of the subjective responses were significantly affected by the objective task success (i.e., the number of drinks served); the number of low-ASR turns also affected most of the responses, while various measures of dialogue efficiency (such as the system response time and the time taken to serve drinks) also had a significant impact.", "labels": [], "entities": []}, {"text": "In general, these regression functions explain between 15-25% of the variance in the subjective measures.", "labels": [], "entities": []}, {"text": "As an initial analysis of the validity of the simulated environment, we compared the state distribution of the simulated data accumulated during policy optimisation with that of the human user evaluation data.", "labels": [], "entities": []}, {"text": "In terms of coverage, we found that only 46% of all states encountered in the real data were also encountered during training.", "labels": [], "entities": [{"text": "coverage", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9727187752723694}]}, {"text": "However, many of these states do not occur very often and many of them do not require any action by the robot (a trained policy can easily beset to take no-action for unseen states).", "labels": [], "entities": []}, {"text": "If we only include states that have been encountered at least 20 times, the coverage increases to over 70%.", "labels": [], "entities": [{"text": "coverage", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9978089928627014}]}, {"text": "For states encountered at least 58 times, the coverage is 100%, though admittedly this covers only the 10 most frequently encountered states.", "labels": [], "entities": [{"text": "coverage", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.9977490305900574}]}, {"text": "The similarity of the two distributions can be quantified by computing the KL-divergence, but since such a number is: Overview of system performance results from the experiment.", "labels": [], "entities": []}, {"text": "The marked column indicates that the difference between the two SSE versions was significant at the p < 0.05 level.", "labels": [], "entities": [{"text": "SSE", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.9184629917144775}]}, {"text": "hard to interpret in itself, this will only be useful if there were a state distribution from an alternative simulator or an improved version of MUSE for comparison.", "labels": [], "entities": [{"text": "MUSE", "start_pos": 145, "end_pos": 149, "type": "DATASET", "confidence": 0.7646907567977905}]}], "tableCaptions": [{"text": " Table 1: State features for the social multi-user coordination policy. For each user, 4 features are included  in the state space, resulting in 3 2 \u00b7 2 2 = 36 states for interactions with up to 1 user, increasing to 1296  states for interactions with up to 2 users and 46, 656 states for up to 3 users.", "labels": [], "entities": []}, {"text": " Table 3: State features for the single-user interaction policy. In this case, there are 5 \u00b7 7 \u00b7 2 = 70 states.", "labels": [], "entities": []}, {"text": " Table 4: Actions for the single-user interaction policy, which correspond to possible dialogue acts, except  for 'no action' and serving a drink. The specific drink types required for two of the actions are extracted  from the fully specified user goal in the social state maintained by the SSR.", "labels": [], "entities": []}, {"text": " Table 6: SSE-MDP trajectory for one session from the evaluation data, showing the states and response  actions taken for both MDPs. The states are represented via their value indices, corresponding to", "labels": [], "entities": []}]}