{"title": [{"text": "Applying Unsupervised Learning To Support Vector Space Model Based Speaking Assessment", "labels": [], "entities": [{"text": "Applying", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9241882562637329}, {"text": "Vector Space Model Based Speaking Assessment", "start_pos": 42, "end_pos": 86, "type": "TASK", "confidence": 0.6856917142868042}]}], "abstractContent": [{"text": "Vector Space Models (VSM) have been widely used in the language assessment field to provide measurements of students' vocabulary choices and content relevancy.", "labels": [], "entities": []}, {"text": "However , training reference vectors (RV) in a VSM requires a time-consuming and costly human scoring process.", "labels": [], "entities": []}, {"text": "To address this limitation, we applied unsupervised learning methods to reduce or even eliminate the human scoring step required for training RVs.", "labels": [], "entities": []}, {"text": "Our experiments conducted on data from a non-native English speaking test suggest that the unsupervised topic clustering is better at selecting responses to train RVs than random selection.", "labels": [], "entities": []}, {"text": "In addition , we conducted an experiment to totally eliminate the need of human scoring.", "labels": [], "entities": []}, {"text": "Instead of using human rated scores to train RVs, we used used the machine-predicted scores from an automated speaking assessment system for training RVs.", "labels": [], "entities": []}, {"text": "We obtained VSM-derived features that show promisingly high correlations to human-holistic scores, indicating that the costly human scoring process can be eliminated .", "labels": [], "entities": []}], "introductionContent": [{"text": "A Vector Space Model (VSM) is a simple, yet effective, method to measure similarities between documents or utterances, which has been utilized in the educational testing field.", "labels": [], "entities": []}, {"text": "For example, VSM has been applied to detect students' off-topic essays () and to automatically score essays ().", "labels": [], "entities": [{"text": "VSM", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.59796142578125}]}, {"text": "Clearly, the quality of VSM-derived features depends on the proper training of RVs.", "labels": [], "entities": []}, {"text": "In language assessment, we tend to use a large number of manually scored responses to build RVs for each testing question (called item in the assessment field).", "labels": [], "entities": [{"text": "language assessment", "start_pos": 3, "end_pos": 22, "type": "TASK", "confidence": 0.7806471288204193}]}, {"text": "However, this raises an issue: the requirement of manual scoring of these responses by human raters.", "labels": [], "entities": []}, {"text": "Also, for large-scale assessments administrated globally, a high number of items are typically administered to both ensure the assessment security and support the large volume of test-takers.", "labels": [], "entities": []}, {"text": "To address this challenge of application of VSM, we will describe our solutions based on applying unsupervised learning methods in this paper.", "labels": [], "entities": [{"text": "VSM", "start_pos": 44, "end_pos": 47, "type": "TASK", "confidence": 0.6925216317176819}]}, {"text": "The rest of the paper is organized as follows: Section 2 reviews the related previous research; Section 3 describes the English assessment, the data used in our experiments, and the Automatic Speech Recognition (ASR) system used; Section 4 reports the three experiments we conducted; and Section 5 discusses our findings and plans for future research.", "labels": [], "entities": [{"text": "Automatic Speech Recognition (ASR)", "start_pos": 182, "end_pos": 216, "type": "TASK", "confidence": 0.724564348657926}]}], "datasetContent": [{"text": "The three experiments described below shared the same procedure: (1) for each item, available responses were divided into two sets -a set for training RVs and a set for evaluating the VSM-derived features; (2) RVs were trained by using different response selection methods investigated in this paper; (3) the trained RVs were used to compute the VSMderived features; and (4) Pearson correlation coefficients (rs) between the VSM-derived features and human-holistic scores were computed to measure these features' predictive abilities in speech scoring.", "labels": [], "entities": [{"text": "Pearson correlation coefficients (rs)", "start_pos": 375, "end_pos": 412, "type": "METRIC", "confidence": 0.9617274800936381}, {"text": "speech scoring", "start_pos": 537, "end_pos": 551, "type": "TASK", "confidence": 0.7205133736133575}]}, {"text": "This experimental procedure was conducted on all 24 items and was repeated in 10 iterations by using varied training/evaluation-splitting plans and the averages of these results across the items and iterations are reported.", "labels": [], "entities": []}, {"text": "Note that we removed some common function words, such as a, the, etc., and some noise words from ASR outputs, such as uh and um, when applying the VSM method and always used LSA dimension reduction.", "labels": [], "entities": [{"text": "LSA dimension reduction", "start_pos": 174, "end_pos": 197, "type": "METRIC", "confidence": 0.6808928847312927}]}, {"text": "We used the Gensim ( \u02c7 Reh\u016f\u0159ek and Sojka, 2010) Python package to implement the VSM-related computations in this paper.", "labels": [], "entities": [{"text": "Gensim ( \u02c7 Reh\u016f\u0159ek and Sojka, 2010) Python package", "start_pos": 12, "end_pos": 62, "type": "DATASET", "confidence": 0.7480582757429644}]}, {"text": "Also, in this paper, we focused on one VSM-derived feature cos4, the cosine distance between an IV to the RV representing the highest-score category (4) for TOEFL R test.", "labels": [], "entities": [{"text": "TOEFL R", "start_pos": 157, "end_pos": 164, "type": "TASK", "confidence": 0.5284183621406555}]}], "tableCaptions": [{"text": " Table 1: Summary statistics of the number of total re- sponses and the number of responses per each score level  measured in mean, sd, and sample size n across 24 items", "labels": [], "entities": []}, {"text": " Table 2: r cos4 , a measurement of VSM features' scoring  performance, from different RV training data sizes", "labels": [], "entities": []}, {"text": " Table 3: A summary of r cos4 using different RV training  sizes, unsupervised-response clustering, and automated- predicted scores", "labels": [], "entities": []}]}