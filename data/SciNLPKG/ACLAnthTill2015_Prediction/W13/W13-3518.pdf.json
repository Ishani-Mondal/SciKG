{"title": [{"text": "A Non-Monotonic Arc-Eager Transition System for Dependency Parsing", "labels": [], "entities": [{"text": "Dependency Parsing", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.7579403817653656}]}], "abstractContent": [{"text": "Previous incremental parsers have used monotonic state transitions.", "labels": [], "entities": []}, {"text": "However, transitions can be made to revise previous decisions quite naturally, based on further information.", "labels": [], "entities": []}, {"text": "We show that a simple adjustment to the Arc-Eager transition system to relax its monotonicity constraints can improve accuracy , so long as the training data includes examples of mistakes for the non-monotonic transitions to repair.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 118, "end_pos": 126, "type": "METRIC", "confidence": 0.9991551637649536}]}, {"text": "We evaluate the change in the context of a state-of-the-art system, and obtain a statistically significant improvement (p < 0.001) on the English evaluation and 5/10 of the CoNLL languages.", "labels": [], "entities": [{"text": "CoNLL languages", "start_pos": 173, "end_pos": 188, "type": "DATASET", "confidence": 0.9131425619125366}]}], "introductionContent": [{"text": "Historically, monotonicity has played an important role in transition-based parsing systems.", "labels": [], "entities": [{"text": "transition-based parsing", "start_pos": 59, "end_pos": 83, "type": "TASK", "confidence": 0.5481621623039246}]}, {"text": "Non-monotonic systems, including the one presented here, typically redundantly generate multiple derivations for each syntactic analysis, leading to spurious ambiguity).", "labels": [], "entities": []}, {"text": "Early, pre-statistical work on transition-based parsing such as implicitly assumed that the parser searches the entire space of possible derivations.", "labels": [], "entities": []}, {"text": "The presence of spurious ambiguity causes this search space to be a directed graph rather than a tree, which considerably complicates the search, so spurious ambiguity was avoided whenever possible.", "labels": [], "entities": []}, {"text": "However, we claim that non-monotonicity and spurious ambiguity are not disadvantages in a modern statistical parsing system such as ours.", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 97, "end_pos": 116, "type": "TASK", "confidence": 0.6538425087928772}]}, {"text": "Modern statistical models have much larger search spaces because almost all possible analyses are allowed, and a numerical score (say, a probability distribution) is used to distinguish better analyses from worse ones.", "labels": [], "entities": []}, {"text": "These search spaces are so large that we cannot exhaustively search them, so instead we use the scores associated with partial analyses to guide a search that explores only a minuscule fraction of the space (In our case we use greedy decoding, but even abeam search only explores a small fraction of the exponentially-many possible analyses).", "labels": [], "entities": []}, {"text": "In fact, as we show here the additional redundant pathways between search states that nonmonotonicity generates can be advantageous because they allow the parser to \"correct\" an earlier parsing move and provide an opportunity to recover from formerly \"fatal\" mistakes.", "labels": [], "entities": []}, {"text": "Informally, non-monotonicity provides \"many paths up the mountain\" in the hope of making it easier to find at least one.", "labels": [], "entities": []}, {"text": "We demonstrate this by modifying the ArcEager transition system) to allow a limited capability for nonmonotonic transitions.", "labels": [], "entities": []}, {"text": "The system normally employs two deterministic constraints that limit the parser to actions consistent with the previous history.", "labels": [], "entities": []}, {"text": "We remove these, and update the transitions so that conflicts are resolved in favour of the latest prediction.", "labels": [], "entities": []}, {"text": "The non-monotonic behaviour provides an improvement of up to 0.2% accuracy over the current state-of-the-art in greedy parsing.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9994787573814392}, {"text": "greedy parsing", "start_pos": 112, "end_pos": 126, "type": "TASK", "confidence": 0.5465224832296371}]}, {"text": "It is possible to implement the greedy parser we describe very efficiently: our implementation, which can be found at http://www.github.com/ syllog1sm/redshift, parses over 500 sentences a second on commodity hardware.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Development results on WSJ 22. Both non-", "labels": [], "entities": [{"text": "WSJ 22", "start_pos": 33, "end_pos": 39, "type": "DATASET", "confidence": 0.8892889320850372}]}, {"text": " Table 2: True/False positive/negative rates for the predic-System  O  Stanford  Penn2Malt", "labels": [], "entities": [{"text": "False positive/negative rates", "start_pos": 15, "end_pos": 44, "type": "METRIC", "confidence": 0.8466590762138366}, {"text": "O  Stanford  Penn2Malt", "start_pos": 68, "end_pos": 90, "type": "DATASET", "confidence": 0.7159363230069479}]}, {"text": " Table 3: WSJ 23 test results, with comparison against the", "labels": [], "entities": [{"text": "WSJ 23 test", "start_pos": 10, "end_pos": 21, "type": "DATASET", "confidence": 0.8344686627388}]}, {"text": " Table 4: Multi-lingual evaluation. Accuracy improved on Chinese, Czech, English, Greek and Italian (p < 0.001), trended", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9989140033721924}]}]}