{"title": [{"text": "Controlled Ascent: Imbuing Statistical MT with Linguistic Knowledge", "labels": [], "entities": [{"text": "Imbuing Statistical MT", "start_pos": 19, "end_pos": 41, "type": "TASK", "confidence": 0.8295078078905741}]}], "abstractContent": [{"text": "We explore the intersection of rule-based and statistical approaches in machine translation, with a particular focus on past and current work here at Microsoft Research.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 72, "end_pos": 91, "type": "TASK", "confidence": 0.7873892486095428}]}, {"text": "Until about ten years ago, the only machine translation systems worth using were rule-based and linguistically-informed.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.7266732454299927}]}, {"text": "Along came statistical approaches, which use large corpora to directly guide translations toward expressions people would actually say.", "labels": [], "entities": []}, {"text": "Rather than making local decisions when writing and conditioning rules, goodness of translation was modeled numerically and free parameters were selected to optimize that goodness.", "labels": [], "entities": []}, {"text": "This led to huge improvements in translation quality as more and more data was consumed.", "labels": [], "entities": [{"text": "translation", "start_pos": 33, "end_pos": 44, "type": "TASK", "confidence": 0.9720751643180847}]}, {"text": "By necessity, the pendulum is swinging towards the inclusion of linguistic features in MT systems.", "labels": [], "entities": [{"text": "MT", "start_pos": 87, "end_pos": 89, "type": "TASK", "confidence": 0.9885892868041992}]}, {"text": "We describe some of our statistical and non-statistical attempts to incorporate linguistic insights into machine translation systems, showing what is currently working well, and what isn't.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 105, "end_pos": 124, "type": "TASK", "confidence": 0.7082864940166473}]}, {"text": "We also look at trade-offs in using linguistic knowledge (\"rules\") in pre-or post-processing by language pair, with a particular eye on the return on investment as training data increases in size.", "labels": [], "entities": []}], "introductionContent": [{"text": "Machine translation has undergone several paradigm shifts since its original conception.", "labels": [], "entities": [{"text": "Machine translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8592913746833801}]}, {"text": "Early work considered the problem as cryptography, imagining that a word replacement cipher could find the word correspondences between two languages.", "labels": [], "entities": [{"text": "word replacement cipher", "start_pos": 68, "end_pos": 91, "type": "TASK", "confidence": 0.7732866207758585}]}, {"text": "Clearly Weaver was decades ahead of his time in terms of both computational power and availability of data: only now is this approach gaining some traction At the time, however, this direction did not appear promising, and work turned toward rule-based approaches.", "labels": [], "entities": []}, {"text": "Effective translation needs to handle abroad range of phenomena.", "labels": [], "entities": []}, {"text": "Word substitution ciphers may address lexical selection, but there are many additional complexities: morphological normalization in the source language, morphological inflection in the target language, word order differences, and sentence structure differences, to name a few.", "labels": [], "entities": [{"text": "Word substitution ciphers", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.7364777823289236}]}, {"text": "Many of these could be captured, at least to a first degree of approximation, by rule-based approaches.", "labels": [], "entities": []}, {"text": "A single rule might capture the fact that English word order is predominantly SVO and Japanese word order is predominantly SOV.", "labels": [], "entities": []}, {"text": "While many exceptions exist, such rules handle many of the largest differences between languages rather effectively.", "labels": [], "entities": []}, {"text": "Therefore, rule-based systems that did a reasonable job of addressing morphological and syntactic differences between source and target dominated the marketplace for decades.", "labels": [], "entities": []}, {"text": "With the broader usage of computers, greater amounts of electronic data became available to systems.", "labels": [], "entities": []}, {"text": "Example-based machine translation systems, which learn corpus-specific translations based on data, began to show substantial improvements in the core problem of lexical selection.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 14, "end_pos": 33, "type": "TASK", "confidence": 0.7594272792339325}]}, {"text": "This task was always quite difficult for rule-based approaches: finding the correct translation in context requires a large amount of knowledge.", "labels": [], "entities": [{"text": "finding the correct translation in context", "start_pos": 64, "end_pos": 106, "type": "TASK", "confidence": 0.694348101814588}]}, {"text": "In practice, nearby words are effective disambiguators once a large amount of data has been captured.", "labels": [], "entities": []}, {"text": "Phrasal statistical machine translation systems formalized many of the intuitions in examplebased machine translation approaches, replacing heuristic selection functions with robust statistical estimators.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 8, "end_pos": 39, "type": "TASK", "confidence": 0.6565612057844797}, {"text": "machine translation", "start_pos": 98, "end_pos": 117, "type": "TASK", "confidence": 0.747436910867691}]}, {"text": "Effective search techniques developed originally for speech recognition were strong starting influences in the complicated realm of MT decoding.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 53, "end_pos": 71, "type": "TASK", "confidence": 0.8277837038040161}, {"text": "MT decoding", "start_pos": 132, "end_pos": 143, "type": "TASK", "confidence": 0.9565468728542328}]}, {"text": "Finally, large quantities of parallel data and even larger quantities of monolingual data allowed such phrasal methods to shine even in broad domain translation.", "labels": [], "entities": [{"text": "broad domain translation", "start_pos": 136, "end_pos": 160, "type": "TASK", "confidence": 0.6378876268863678}]}, {"text": "Translations were still far from perfect, though.", "labels": [], "entities": [{"text": "Translations", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.9679295420646667}]}, {"text": "Phrasal systems capture local context and local reordering well, but struggle with global reordering.", "labels": [], "entities": []}, {"text": "Over the past decade, statistical machine translation has begun to be influenced by linguistic information once again.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 22, "end_pos": 53, "type": "TASK", "confidence": 0.7084827423095703}]}, {"text": "Syntactic models have shown some of the most compelling gains.", "labels": [], "entities": []}, {"text": "Many systems leverage the syntactic structure of either the source or the target sentences to make better decisions about reordering and lexical selection.", "labels": [], "entities": []}, {"text": "Our machine translation group has been an active participant in many of these latest developments.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.8008879125118256}]}, {"text": "The first MSR MT system used deep linguistic features, often with great positive effect.", "labels": [], "entities": [{"text": "MSR MT", "start_pos": 10, "end_pos": 16, "type": "TASK", "confidence": 0.8993737101554871}]}, {"text": "Inspired by the successes and failures of this system, we invested heavily in syntax-based SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 91, "end_pos": 94, "type": "TASK", "confidence": 0.8501115441322327}]}, {"text": "However, our current statistical systems are still linguistically impoverished in comparison.", "labels": [], "entities": []}, {"text": "This paper attempts to document important lessons learned, highlight current best practices, and identify promising future directions for improving machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 148, "end_pos": 167, "type": "TASK", "confidence": 0.8370064795017242}]}, {"text": "A brief review of our earlier generation of machine translation technology sets the stage; this older system remains relevant given renewed interest in semantics (e.g., http://amr.isi.edu/).", "labels": [], "entities": [{"text": "machine translation", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.7187300473451614}]}, {"text": "Next we describe some of our statistical and non-statistical attempts to incorporate linguistic insights into machine translation systems, showing what is currently working well, and what is not.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 110, "end_pos": 129, "type": "TASK", "confidence": 0.7235371172428131}]}, {"text": "We also look at trade-offs in using linguistic knowledge (\"rules\") in pre-or post-processing by language pair, with a particular eye on the return on investment as training data increases in size.", "labels": [], "entities": []}, {"text": "Systems built on different architectures, particularly those incorporating some linguistic information, may have different learning curves on data.", "labels": [], "entities": []}, {"text": "The advent of social media and big data presents new challenges; we review some effective research in this area.", "labels": [], "entities": []}, {"text": "We conclude by exploring promising directions for improving translation quality, especially focusing on areas that stand to benefit from linguistic information.", "labels": [], "entities": [{"text": "translation quality", "start_pos": 60, "end_pos": 79, "type": "TASK", "confidence": 0.8764505982398987}]}], "datasetContent": [{"text": "We ran a set of experiments to measure the differences between treelet and phrasal systems over varying sizes of data, in order to measure the size of the treelet penalty and its interaction with training data size.", "labels": [], "entities": []}, {"text": "Our assumption was that a such a penalty existed, and that the penalty decreased as training data size increased, perhaps converging on zero for very large systems.", "labels": [], "entities": []}, {"text": "Likewise, we wanted to test the interaction between decoder type and sentence length.", "labels": [], "entities": []}, {"text": "We chose two languages to run these experiments on, Spanish and German, which we ran in both directions, that is, English-to-target (EX) and target-to-English (XE).", "labels": [], "entities": []}, {"text": "We chose Spanish and German for several reasons, first among them being that we have high-quality parsers for both languages, as we do for English.", "labels": [], "entities": []}, {"text": "Further, we have done significant development work on pre-and post-processing for both languages over the past several years.", "labels": [], "entities": []}, {"text": "Both of these facts combined meant that the treelet systems stood areal chance of being strong contenders in the experiments against the equivalent phrasal systems.", "labels": [], "entities": []}, {"text": "Further, although the languages are typologically close neighbors of English, the word order differences and high distortion rates from English to or from German might favor a parser-based approach.", "labels": [], "entities": []}, {"text": "We had four baseline systems that were built over very large sets of data.", "labels": [], "entities": []}, {"text": "For Spanish English, the baseline systems were trained on over 22M sentence pairs; for German English, the baseline systems were trained on over 36M sentence pairs.", "labels": [], "entities": []}, {"text": "We then created five samples of the baseline data for each language pair, consisting of 100K, 500K, 1M, 2M, and 5M sentence pairs (the same samples were used for both EX and XE for the respective pairs).", "labels": [], "entities": []}, {"text": "We then trained both treelet and phrasal systems in both directions (EX and XE) over each sample of data.", "labels": [], "entities": [{"text": "EX", "start_pos": 69, "end_pos": 71, "type": "METRIC", "confidence": 0.9240531325340271}, {"text": "XE", "start_pos": 76, "end_pos": 78, "type": "METRIC", "confidence": 0.8313671350479126}]}, {"text": "Language models were trained on all systems over the target-side data.", "labels": [], "entities": []}, {"text": "For dev data, we used development data from the 2010 WMT competition, and we used MERT) to tune each system.", "labels": [], "entities": [{"text": "WMT competition", "start_pos": 53, "end_pos": 68, "type": "DATASET", "confidence": 0.6113119721412659}, {"text": "MERT", "start_pos": 82, "end_pos": 86, "type": "METRIC", "confidence": 0.9368592500686646}]}, {"text": "We tested each system against three different test sets: two were from the WMT competitions of 2009 and 2010, and the other was one locally constructed from 5000 sentences of content translated by users of our production service (http://bing.com/translator), which we subsequently had manually translated into the target languages.", "labels": [], "entities": [{"text": "WMT competitions of 2009", "start_pos": 75, "end_pos": 99, "type": "DATASET", "confidence": 0.6991575211286545}]}, {"text": "The former two test sets are somewhat news focused; the latter is a random sample of miscellaneous translations, and is more generally focused.", "labels": [], "entities": []}, {"text": "The results of the experiments are shown in Tables 2 and 3, with the relevant graphs in.", "labels": [], "entities": []}, {"text": "The reader will note that in all casesSpanish and German, EX and XE-the treelet systems scored higher than the related phrasal systems.", "labels": [], "entities": []}, {"text": "This result surprised us, since we thought that treelet systems would scoreless than phrasal systems, especially at lower data sizes.", "labels": [], "entities": []}, {"text": "That said, in the Spanish systems, there is a clear convergence as data sizes increased: on the WMT09 test set for English-Spanish, for instance, the diff starts at 1.46 BLEU (treelet minus phrasal) for the 100K sentence system, with a steady convergence to near zero (0.12) for the full-data baseline.", "labels": [], "entities": [{"text": "WMT09 test set", "start_pos": 96, "end_pos": 110, "type": "DATASET", "confidence": 0.975171426932017}, {"text": "BLEU", "start_pos": 170, "end_pos": 174, "type": "METRIC", "confidence": 0.9909817576408386}]}, {"text": "The other test sets show the same steady convergence, although they do not approach zero quite as closely.", "labels": [], "entities": [{"text": "convergence", "start_pos": 41, "end_pos": 52, "type": "METRIC", "confidence": 0.8896369934082031}]}, {"text": "(One might ask whether they would converge to zero with more training data.)", "labels": [], "entities": []}, {"text": "The other direction is even more dramatic: on all test sets the diffs converge on negative values, indicating that phrasal systems surpass the quality of the associated treelet systems at the largest data points.", "labels": [], "entities": []}, {"text": "This is a nice result since it shows, at least in the case of Spanish, that there is an interaction between decoder type and the amount of data: treelet clearly does better at lower data amounts, but phrasal catches up with, and can even pass, the quality of equivalent treelet given sufficient data.", "labels": [], "entities": []}, {"text": "With larger data, phrasal may, in fact, be favored over treelet.", "labels": [], "entities": []}, {"text": "The German systems do not tell quite as nice a story.", "labels": [], "entities": []}, {"text": "While it is still true that treelet has higher BLEU scores than phrasal throughout, and that systems trained using both decoders improve in quality as more data is added (and the trajectory is similar), there is no observable convergence as data size increases.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 47, "end_pos": 51, "type": "METRIC", "confidence": 0.9988784193992615}]}, {"text": "For German, then, we can only say that more data helps either decoder, but we cannot say that phrasal benefits from larger data more than treelet.", "labels": [], "entities": []}, {"text": "Why the difference between Spanish and German?", "labels": [], "entities": []}, {"text": "We suspect there maybe an interaction with the parsers, in that two separate teams developed them.", "labels": [], "entities": []}, {"text": "Thus, it could be the fact that the strength of the respective parsers affected how \"linguistically informed\" particular systems are.", "labels": [], "entities": []}, {"text": "There could also bean interaction with the number of word types vs. tokens in the German data-given German's rampant compoundingwhich increases data sparsity, dampening effects until much larger amounts of data are used.", "labels": [], "entities": [{"text": "German data-given German", "start_pos": 82, "end_pos": 106, "type": "DATASET", "confidence": 0.7822586596012115}]}, {"text": "We are still in the process of running additional experiments to see if there are observable effects in German with much larger data sizes, or at least, to determine why German does not show the same effects as Spanish.", "labels": [], "entities": []}, {"text": "seek to achieve with our quality measures, and since BLEU is only weakly correlated with human eval, we ran human evals against both the English-Spanish and EnglishGerman output.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 53, "end_pos": 57, "type": "METRIC", "confidence": 0.9986602067947388}, {"text": "EnglishGerman output", "start_pos": 157, "end_pos": 177, "type": "DATASET", "confidence": 0.8878921866416931}]}, {"text": "Performing human evaluation gives us two additional perspectives on the data: (1) do humans perceive a qualitative difference between treelet and phrasal, as we see with BLEU, and (2), if the difference is perceptible, what is its magnitude relative to BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 170, "end_pos": 174, "type": "METRIC", "confidence": 0.9905723929405212}, {"text": "BLEU", "start_pos": 253, "end_pos": 257, "type": "METRIC", "confidence": 0.9943094253540039}]}, {"text": "If the magnitude of the difference is much larger than that of BLEU, and especially does not show convergence in the Spanish cases, then we still have a strong case for the Treelet Penalty.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 63, "end_pos": 67, "type": "METRIC", "confidence": 0.9972623586654663}, {"text": "convergence", "start_pos": 98, "end_pos": 109, "type": "METRIC", "confidence": 0.9781215190887451}]}, {"text": "In fact, if human evaluators perceive a difference Spanish cases on the full data systems, the case where we show convergence, then the resulting differences could be described as the penalty value.", "labels": [], "entities": []}, {"text": "Unfortunately, our human evaluation data on the Treelet Penalty effect was inconclusive.", "labels": [], "entities": [{"text": "Treelet Penalty effect", "start_pos": 48, "end_pos": 70, "type": "DATASET", "confidence": 0.7200584610303243}]}, {"text": "Our evaluations show a strong correlation between BLEU and human evaluation, something that is attested to in the literature (e.g., , the first paper on BLEU (), and a deeper exploration in).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 50, "end_pos": 54, "type": "METRIC", "confidence": 0.9827631711959839}, {"text": "BLEU", "start_pos": 153, "end_pos": 157, "type": "METRIC", "confidence": 0.8851380348205566}]}, {"text": "However, the effect we were looking for -that is, a difference between human evaluations across decoders -was not evident.", "labels": [], "entities": []}, {"text": "In fact, the human evaluations followed the differences we saw in BLEU between the two decoders very closely.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 66, "end_pos": 70, "type": "METRIC", "confidence": 0.994848906993866}]}, {"text": "shows data points for each data size for each decoder, plotting BLEU against human evaluation.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 64, "end_pos": 68, "type": "METRIC", "confidence": 0.999264657497406}]}, {"text": "When we fit a regression line against the data points for each decoder, we see complete overlap.", "labels": [], "entities": []}, {"text": "5 In summary, we show a strong effect of treelet systems performing better than phrasal systems trained on the same data.", "labels": [], "entities": []}, {"text": "That difference, however, generally diminishes as data sizes increase, and in the case of Spanish (both directions), there is a convergence in very large data sizes.", "labels": [], "entities": []}, {"text": "These results are not completely surprising, but still area nice systematic confirmation that linguistically informed systems really do better in lower-data environments.", "labels": [], "entities": []}, {"text": "Without enough data, statistical systems cannot learn the generalizations that might otherwise be provided by a parse, or codified in rules.", "labels": [], "entities": []}, {"text": "What we failed to show, at least with Spanish and German, is a confirmation of the existence of the Treelet Penalty.", "labels": [], "entities": [{"text": "Treelet Penalty", "start_pos": 100, "end_pos": 115, "type": "DATASET", "confidence": 0.9371883869171143}]}, {"text": "Given the small number of samples, a larger study which includes many more language pairs and data sizes, may once and for all confirm the Penalty.", "labels": [], "entities": [{"text": "Penalty", "start_pos": 139, "end_pos": 146, "type": "METRIC", "confidence": 0.9483257532119751}]}, {"text": "Thus far, human evaluations do not show qualitative differences between the two decoders-at least, not divergent from BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 118, "end_pos": 122, "type": "METRIC", "confidence": 0.9825325012207031}]}], "tableCaptions": [{"text": " Table 1: Comparison of BLEU scores as linguistic  information is varied. A phrasal system provides  a baseline free of linguistic information. Next we  consider a treelet system with a very weak base- line: a right branching tree is always proposed.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 24, "end_pos": 28, "type": "METRIC", "confidence": 0.9929788708686829}]}, {"text": " Table 2: BLEU Score results for the Spanish Treelet Penalty experiments", "labels": [], "entities": [{"text": "BLEU Score", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9526295363903046}, {"text": "Spanish Treelet Penalty", "start_pos": 37, "end_pos": 60, "type": "DATASET", "confidence": 0.9031703670819601}]}, {"text": " Table 3: BLEU Score results for the German Treelet Penalty experiments", "labels": [], "entities": [{"text": "BLEU Score", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9543516635894775}, {"text": "German Treelet Penalty", "start_pos": 37, "end_pos": 59, "type": "DATASET", "confidence": 0.956963042418162}]}]}