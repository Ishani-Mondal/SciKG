{"title": [{"text": "Probabilistic induction for an incremental semantic grammar *", "labels": [], "entities": []}], "abstractContent": [{"text": "We describe a method for learning an incremental semantic grammar from a corpus in which sentences are paired with logical forms as predicate-argument structure trees.", "labels": [], "entities": []}, {"text": "Working in the framework of Dynamic Syntax, and assuming a set of generally available compositional mechanisms, we show how lexical entries can be learned as probabilistic procedures for the incremental projection of semantic structure, providing a grammar suitable for use in an incremental probabilistic parser.", "labels": [], "entities": []}, {"text": "By inducing these from a corpus generated using an existing grammar, we demonstrate that this results in both good coverage and compatibility with the original entries, without requiring annotation at the word level.", "labels": [], "entities": [{"text": "coverage", "start_pos": 115, "end_pos": 123, "type": "METRIC", "confidence": 0.9607330560684204}, {"text": "compatibility", "start_pos": 128, "end_pos": 141, "type": "METRIC", "confidence": 0.9673160314559937}]}, {"text": "We show that this semantic approach to grammar induction has the novel ability to learn the syntactic and semantic constraints on pronouns.", "labels": [], "entities": [{"text": "grammar induction", "start_pos": 39, "end_pos": 56, "type": "TASK", "confidence": 0.7877936363220215}]}], "introductionContent": [{"text": "Dynamic Syntax (DS) is an inherently incremental semantic grammar formalism () in which semantic representations are projected on a word-by-word basis.", "labels": [], "entities": [{"text": "Dynamic Syntax (DS)", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8071405172348023}]}, {"text": "It recognises no intermediate layer of syntax (see below), but instead reflects grammatical constraints via constraints on the incremental construction of partial logical forms (LFs).", "labels": [], "entities": []}, {"text": "Given this, and its definition of parsing and generation in terms of the same incremental processes, it is in principle capable of modelling and providing semantic interpretations for phenomena such as unfinished utterances, co-constructions and interruptions, beyond the remit of standard grammar formalisms but important for dialogue systems.", "labels": [], "entities": [{"text": "parsing and generation", "start_pos": 34, "end_pos": 56, "type": "TASK", "confidence": 0.8348304231961569}]}, {"text": "However, its definition in terms of semantics (rather than the more familiar syntactic phrase structure) makes it hard to define or extend broad-coverage grammars: expert linguists are required.", "labels": [], "entities": []}, {"text": "Here, we present a method for automatically inducing DS grammars, by learning lexical entries from sentences paired with complete, compositionally structured, propositional LFs.", "labels": [], "entities": []}, {"text": "By assuming only the availability of a small set of general compositional semantic operations, reflecting the properties of the lambda calculus and semantic conjunction, we ensure that the lexical entries learnt include the grammatical constraints and corresponding compositional semantic structure of the language; by additionally assuming a general semantic copying operation, we can also learn the syntactic and semantic properties of pronouns.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Training and test corpus distributions and means", "labels": [], "entities": []}, {"text": " Table 2: Test parse results: showing percentage parsability, and percentage of parses deriving the correct  semantic content for the whole sentence", "labels": [], "entities": []}]}