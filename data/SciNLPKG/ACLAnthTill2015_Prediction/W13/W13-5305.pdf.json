{"title": [{"text": "Text segmentation for Language Identification in Greek Forums", "labels": [], "entities": [{"text": "Text segmentation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.6969929039478302}, {"text": "Language Identification in Greek Forums", "start_pos": 22, "end_pos": 61, "type": "TASK", "confidence": 0.8153960824012756}]}], "abstractContent": [{"text": "In this paper, we examine the benefit of applying text segmentation methods to perform language identification in forums.", "labels": [], "entities": [{"text": "language identification in forums", "start_pos": 87, "end_pos": 120, "type": "TASK", "confidence": 0.8043174892663956}]}, {"text": "The focus here is on forums containing a mixture of information written in Greek, English as well as Greeklish.", "labels": [], "entities": []}, {"text": "Greeklish can be defined as the use of Latin alphabet for rendering Greek words with Latin characters.", "labels": [], "entities": []}, {"text": "For the evaluation, a corpus was manually created by collecting web pages from Greek university forums and most specifically, pages containing information that combines Greek with English technical terminology and Greeklish.", "labels": [], "entities": []}, {"text": "The evaluation using two well known text segmen-tation algorithms leads to the conclusion that despite the difficulty of the problem examined, text segmentation seems to be a promising solution .", "labels": [], "entities": [{"text": "text segmentation", "start_pos": 143, "end_pos": 160, "type": "TASK", "confidence": 0.7562055587768555}]}], "introductionContent": [{"text": "Language identification can be defined as the process of determining which natural language given content is in.", "labels": [], "entities": [{"text": "Language identification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.6828967332839966}]}, {"text": "Traditionally, identification of written language -as practiced for instance in library science -has relied on manually identifying frequent words and letters known to be characteristic of particular languages.", "labels": [], "entities": [{"text": "identification of written language", "start_pos": 15, "end_pos": 49, "type": "TASK", "confidence": 0.8842967599630356}]}, {"text": "More recently, computational approaches have been applied to the problem, by viewing language identification as a special case of text categorization, a Natural Language Processing approach that relies on a statistical method.", "labels": [], "entities": [{"text": "language identification", "start_pos": 85, "end_pos": 108, "type": "TASK", "confidence": 0.745375782251358}]}, {"text": "Greeklish, which comes from the combination of the words Greek and English, stands for the Greek language written using the Latin alphabet.", "labels": [], "entities": []}, {"text": "The term Greeklish mainly refers to informal, adhoc practices of writing Greek text in environments where the use of the Greek alphabet is technically impossible or cumbersome, especially in electronic media.", "labels": [], "entities": []}, {"text": "Greeklish was commonly used on the Internet when Greek people communicate by forum, e-mail, instant messaging and occasionally on SMS, mainly because older operating systems didn't have the ability to write in Greek, or in a Unicode form like UTF-8.", "labels": [], "entities": []}, {"text": "Nowadays, most Greek language content appears in native Greek alphabet.", "labels": [], "entities": []}, {"text": "This paper is organized as follows: Section 2 provides information regarding related work, Section 3 provides a description of the method followed and the algorithms used, Section 4 provides evaluation metrics and obtained results, while Section 5 provides concluding remarks and future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we present the experiments we conducted to evaluate our method.", "labels": [], "entities": []}, {"text": "We evaluate the application of a segmentation algorithm using the following three indices: Precision, Recall and Beeferman's Pk metric ().", "labels": [], "entities": [{"text": "Precision", "start_pos": 91, "end_pos": 100, "type": "METRIC", "confidence": 0.99937504529953}, {"text": "Recall", "start_pos": 102, "end_pos": 108, "type": "METRIC", "confidence": 0.9968254566192627}]}, {"text": "Those metrics are commonly used in the text segmentation problem.", "labels": [], "entities": [{"text": "text segmentation problem", "start_pos": 39, "end_pos": 64, "type": "TASK", "confidence": 0.8891092538833618}]}, {"text": "Precision and Recall metrics are properly defined for the segmentation task.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.984483540058136}, {"text": "Recall", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9320811033248901}, {"text": "segmentation task", "start_pos": 58, "end_pos": 75, "type": "TASK", "confidence": 0.9185084998607635}]}, {"text": "More specifically, Precision is defined as \"the number of the estimated segment boundaries which are actual segment boundaries\" divided by \"the number of the estimated segment boundaries\".", "labels": [], "entities": [{"text": "Precision", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.9608308672904968}]}, {"text": "Recall is defined as \"the number of the estimated segment boundaries which are actual segment boundaries\" divided by \"the number of the true segment boundaries\".", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9516809582710266}]}, {"text": "The F measure which combines the results of Precision and Recall is not used here, due to the fact that both Precision and Recall penalize equally segment boundaries that are \"close\" to the actual i.e., true boundaries with those that are less close to the true boundary.", "labels": [], "entities": [{"text": "F measure", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9886825084686279}]}, {"text": "For that reason, Beeferman proposed an new metric named Pk which measures segmentation inaccuracy; intuitively, Beeferman's Pk measures the proportion of \"sentences which are wrongly predicted to belong to different segments (while actually they belong to the same segment)\" or \"sentences which are wrongly predicted to belong to the same segment (while actually they belong in different segments)\" (for a precise definition of Beeferman Pk metric see ().", "labels": [], "entities": []}, {"text": "A variation of Beeferman's Pk metric, named WindowDiff index has been proposed by.", "labels": [], "entities": []}, {"text": "The WindowDiff metric remedies several problems of Beeferman's Pk and is also used in our evaluation.", "labels": [], "entities": []}, {"text": "More specifically, the WindowDiff metric penalizes false positives and near misses equally.", "labels": [], "entities": []}, {"text": "Since Beeferman's Pk and WindowDiff metrics measures segmentation inaccuracy, low values of those metrics exhibit high performance of the algorithm examined.", "labels": [], "entities": []}, {"text": "contains the obtained results after applying the two text segmentation algorithms in our corpus (where preprocessing has been performed as it was described in Section 3.2) using the four evaluation metrics described above.", "labels": [], "entities": [{"text": "text segmentation", "start_pos": 53, "end_pos": 70, "type": "TASK", "confidence": 0.7256350517272949}]}, {"text": "From the obtained results we can conclude that the segmentation accuracy differs from the one obtained in text segmentation corpora such as in Choi's benchmark).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.9015340805053711}, {"text": "text segmentation corpora", "start_pos": 106, "end_pos": 131, "type": "TASK", "confidence": 0.7468435267607371}]}, {"text": "Choi's benchmark is used for text segmentation where the aim is to identify topic change.", "labels": [], "entities": [{"text": "Choi's benchmark", "start_pos": 0, "end_pos": 16, "type": "DATASET", "confidence": 0.8532344897588094}, {"text": "text segmentation", "start_pos": 29, "end_pos": 46, "type": "TASK", "confidence": 0.7880408763885498}]}, {"text": "Reported results regarding Choi's benchmark can be found in.", "labels": [], "entities": [{"text": "Choi's benchmark", "start_pos": 27, "end_pos": 43, "type": "DATASET", "confidence": 0.9111318389574686}]}, {"text": "It is worth mentioning that the aforementioned text segmentation algorithms are usually examined in problems where the number of segments, as well the number of sentences per segment do not exhibit strong variations.", "labels": [], "entities": [{"text": "text segmentation", "start_pos": 47, "end_pos": 64, "type": "TASK", "confidence": 0.7337605059146881}]}], "tableCaptions": [{"text": " Table 3: Statistics regarding the corpus", "labels": [], "entities": [{"text": "corpus", "start_pos": 35, "end_pos": 41, "type": "DATASET", "confidence": 0.736730694770813}]}]}