{"title": [{"text": "Machine Learning Disambiguation of Quechua Verb Morphology", "labels": [], "entities": [{"text": "Machine Learning Disambiguation of Quechua Verb Morphology", "start_pos": 0, "end_pos": 58, "type": "TASK", "confidence": 0.69530531338283}]}], "abstractContent": [{"text": "We have implemented a rule-based prototype of a Spanish-to-Cuzco Quechua MT system enhanced through the addition of statistical components.", "labels": [], "entities": [{"text": "Spanish-to-Cuzco Quechua MT", "start_pos": 48, "end_pos": 75, "type": "TASK", "confidence": 0.4331130087375641}]}, {"text": "The greatest difficulty during the translation process is to generate the correct Quechua verb form in subordinated clauses.", "labels": [], "entities": [{"text": "translation", "start_pos": 35, "end_pos": 46, "type": "TASK", "confidence": 0.9644008278846741}]}, {"text": "The prototype has several rules that decide which verb form should be used in a given context.", "labels": [], "entities": []}, {"text": "However , matching the context in order to apply the correct rule depends crucially on the parsing quality of the Spanish input.", "labels": [], "entities": []}, {"text": "As the form of the subordinated verb depends heavily on the conjunction in the subordinated Spanish clause and the semantics of the main verb, we extracted this information from two treebanks and trained different classifiers on this data.", "labels": [], "entities": []}, {"text": "We tested the best classifier on a set of 4 texts, increasing the correct subordinated verb forms from 80% to 89%.", "labels": [], "entities": []}], "introductionContent": [{"text": "As part of our research project SQUOIA, we have developed several tools and resources for Cuzco Quechua.", "labels": [], "entities": []}, {"text": "These include a treebank, currently consisting of around 500 sentences 2 , and a rule-based MT system Spanish-Cuzco Quechua.", "labels": [], "entities": [{"text": "MT", "start_pos": 92, "end_pos": 94, "type": "TASK", "confidence": 0.8738455772399902}]}, {"text": "The treebank is currently being enhanced with more annotated text and should reach about 4000 sentences upon project completion.", "labels": [], "entities": []}, {"text": "As for the translation system, we want to enhance the rule-based approach with statistical methods to overcome certain limitations of the prototype.", "labels": [], "entities": [{"text": "translation", "start_pos": 11, "end_pos": 22, "type": "TASK", "confidence": 0.9645549654960632}]}, {"text": "The main reason to build the core system with a rule-based architecture is the lack of parallel texts in Spanish and Quechua; there is not enough parallel material to train a statistical MT system of acceptable quality, as showed in their experiments.", "labels": [], "entities": [{"text": "MT", "start_pos": 187, "end_pos": 189, "type": "TASK", "confidence": 0.9521679282188416}]}, {"text": "They trained an SMT system Spanish-Quechua on translations of the Bible, resulting in 2.89 BLEU points.", "labels": [], "entities": [{"text": "SMT", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.9885377883911133}, {"text": "BLEU", "start_pos": 91, "end_pos": 95, "type": "METRIC", "confidence": 0.999075174331665}]}, {"text": "By increasing the size of their training corpus with web-crawled parallel texts and additional Bible translations, they achieved 4.55 BLEU points.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 134, "end_pos": 138, "type": "METRIC", "confidence": 0.9988118410110474}]}, {"text": "Although better, the overall quality of the SMT system is still very low.", "labels": [], "entities": [{"text": "SMT", "start_pos": 44, "end_pos": 47, "type": "TASK", "confidence": 0.9937438368797302}]}, {"text": "There are at least two other projects that started the implementation of MT systems for the same language pair, but in the opposite direction; the AVENUE project 4 used elicited corpora to build an MT system Quechua-Spanish.", "labels": [], "entities": [{"text": "MT", "start_pos": 73, "end_pos": 75, "type": "TASK", "confidence": 0.9727009534835815}, {"text": "MT", "start_pos": 198, "end_pos": 200, "type": "TASK", "confidence": 0.9762223362922668}]}, {"text": "Furthermore, the language pair Quechua-Spanish has recently been added to the open-source MT platform Apertium.", "labels": [], "entities": [{"text": "Apertium", "start_pos": 102, "end_pos": 110, "type": "DATASET", "confidence": 0.4492926299571991}]}, {"text": "The translation system is still at a very early stage in its development; at present, the grammar contains 30 transfer rules and a morphological analyzer.", "labels": [], "entities": []}], "datasetContent": [{"text": "We tested the classifiers on the ambiguous forms from the 4 texts that we used for the evaluation of the rule-based approach (see).", "labels": [], "entities": []}, {"text": "Additionally, we extracted verb pairs from Quechua texts (with their Spanish translations) and assigned them the corresponding class number.", "labels": [], "entities": []}, {"text": "With this procedure, we collected 100 instances for testing.", "labels": [], "entities": []}, {"text": "We trained and tested different classifiers: Na\u00a8\u0131veNa\u00a8\u0131ve Bayes, Nearest Neighbour (Martin, 1995) and a multiclass support vector machine.", "labels": [], "entities": []}, {"text": "contains the best results for each classifier.", "labels": [], "entities": []}, {"text": "The three WEKA classifiers were trained with default settings, whereas for SVM multiclass we obtained the best results with =0.1 and c=0.02 (linear kernel).", "labels": [], "entities": []}, {"text": "In an ideal case of disambiguation during translation, we would have information about the lemma of the main verb (\"head\") and the Spanish conjunction (\"linker\").", "labels": [], "entities": []}, {"text": "In these ideal cases, we use the rule-based module to assign the subordinated verb form.", "labels": [], "entities": []}, {"text": "In real translation scenarios, however, either the head or linker might be missing; a common source for errors are polysemous conjunctions, such as que -'that' or como -'as' , that the tagger erroneously labeled as relative pronoun or preposition, respectively.", "labels": [], "entities": []}, {"text": "In this case, the linker cannot be retrieved from the parse tree and we have to guess the verb form based only on the lemmas of the main and the subordinated verb (\"subV\").", "labels": [], "entities": []}, {"text": "Furthermore, we might have a clearly subordinated verb form with a linker that the parser attached to the wrong head.", "labels": [], "entities": []}, {"text": "Finding the correct head automatically is not always possible, especially within coordinations.", "labels": [], "entities": []}, {"text": "In this case, we need to guess the verb form based only on the lemma of the subordinated verb and the linker.", "labels": [], "entities": []}, {"text": "Na\u00a8\u0131veNa\u00a8\u0131ve Bayes achieves the highest scores, both on cross validation and on the test set (see for details).", "labels": [], "entities": []}, {"text": "From the 33 ambiguous verb forms in, only 22 were disambiguated with the classifiers, as the rest were either nouns erroneously tagged as verbs or had the wrong lemma, and therefore can be counted as false without further processing.", "labels": [], "entities": []}, {"text": "From the 22 correctly tagged ambiguous verbs, Na\u00a8\u0131veNa\u00a8\u0131ve Bayes classified 20 instances correctly.", "labels": [], "entities": []}, {"text": "The rules of the MT system disambiguated 80% of the verb forms in the 4 evaluation texts correctly.", "labels": [], "entities": [{"text": "MT", "start_pos": 17, "end_pos": 19, "type": "TASK", "confidence": 0.9888757467269897}]}, {"text": "Feeding the remaining ambiguous verbs to the classifier; we achieve an overall accuracy of 89% (see the results in).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.9994230270385742}]}, {"text": "The complete translation pipeline including the Naive Bayes classifier is illustrated in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Evaluation of rule-based verb disambiguation", "labels": [], "entities": [{"text": "rule-based verb disambiguation", "start_pos": 24, "end_pos": 54, "type": "TASK", "confidence": 0.7054257790247599}]}, {"text": " Table 2: Evaluation of Classifiers", "labels": [], "entities": []}, {"text": " Table 3: Evaluation of Hybrid Verb Disambiguation", "labels": [], "entities": [{"text": "Hybrid Verb Disambiguation", "start_pos": 24, "end_pos": 50, "type": "TASK", "confidence": 0.5913313428560892}]}]}