{"title": [{"text": "O n a Dependency-based Semantic Space for Unsupervised Noun Sense Disambiguation with an Underlying Na\u00efve Bayes Model", "labels": [], "entities": []}], "abstractContent": [{"text": "A bstract Recent studies refocus on usage of the Na\u00efve Bayes model in unsupervised word sense dis-ambiguation (WSD).", "labels": [], "entities": [{"text": "word sense dis-ambiguation (WSD)", "start_pos": 83, "end_pos": 115, "type": "TASK", "confidence": 0.7677539537350336}]}, {"text": "They discuss the issue of feature selection for this statistical model, when used as clustering technique, and comment (Hristea, 2012) that it still holds a promise for unsupervised WSD.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 26, "end_pos": 43, "type": "TASK", "confidence": 0.6581062078475952}, {"text": "WSD", "start_pos": 182, "end_pos": 185, "type": "TASK", "confidence": 0.9233417510986328}]}, {"text": "Within the various investigated types of feature selection, this ongoing research concentrates on syntactic dependency-based features, introduced in (Hristea and Colhon, 2012) with respect to adjectives only.", "labels": [], "entities": []}, {"text": "We hereby extend the mentioned approach to the case of nouns and recommend the further investigation of this promising feature selection method.", "labels": [], "entities": []}], "introductionContent": [{"text": "While the Na\u00efve Bayes model has been widely and successfully used in supervised WSD), its usage in unsupervised WSD has led to more modest disambiguation results and is less frequent.", "labels": [], "entities": [{"text": "WSD", "start_pos": 80, "end_pos": 83, "type": "TASK", "confidence": 0.8629891276359558}]}, {"text": "However, more recent studies state that this statistical model still holds a promise for unsupervised WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 102, "end_pos": 105, "type": "TASK", "confidence": 0.9197255373001099}]}, {"text": "The Na\u00efve Bayes model needs to be fed knowledge (of various natures) in order to perform well as clustering technique for unsupervised WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 135, "end_pos": 138, "type": "TASK", "confidence": 0.8738003373146057}]}, {"text": "Three different sources of such knowledge have been predominantly examined and compared: WordNet (, web N-grams () and dependency relations.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 89, "end_pos": 96, "type": "DATASET", "confidence": 0.9288665652275085}]}, {"text": "While most of these studies discuss all three major parts of speech (nouns, adjectives, verbs), the syntactic dependency-based feature selection method has been applied to adjectives only (.", "labels": [], "entities": []}, {"text": "With the conclusion that the Na\u00efve Bayes model reacts well in the presence of syntactic knowledge of this type and that dependency-based feature selection for the Na\u00efve Bayes model is a reliable alternative to other existing ones.", "labels": [], "entities": []}, {"text": "In fact, for the studied adjectives, this type of syntactic feature selection has provided the best disambiguation results.", "labels": [], "entities": []}, {"text": "Following the line of reasoning of the mentioned studies, we hereby extend the disambiguation method they propose to nouns, while exemplifying with tests concerning the nouns line and interest.", "labels": [], "entities": []}, {"text": "Although dependency-based semantic space models have been studied and discussed by several authors (Pad\u00f3 !\"#$ %!&!'!($ )**+,$ -./'!/0, to our knowledge, grammatical dependencies have been used in conjunction with the Na\u00efve Bayes model only very recently.", "labels": [], "entities": []}, {"text": "The latter authors follow the line of reasoning of which they adapt to the particularities of the involved statistical model.", "labels": [], "entities": []}, {"text": "The present study investigates the usage of syntactic features provided by dependency relations as defined by the classical Dependency Grammar formalism and as proposed in.", "labels": [], "entities": []}, {"text": "The semantic space we present to the Na\u00efve Bayes model for unsupervised WSD will be based on dependency relations extracted from natural language texts via a syntactic parser.", "labels": [], "entities": [{"text": "WSD", "start_pos": 72, "end_pos": 75, "type": "TASK", "confidence": 0.8881475925445557}]}, {"text": "In order to ensure the same testing setup as the one used in the mentioned studies, we shall be making use of a PCFG parser, namely the Stanford parser (, for extracting syntactic dependency relations that will indicate the disambiguation vocabulary required by the Na\u00efve Bayes model.", "labels": [], "entities": []}, {"text": "When using dependencybased syntactic features this disambiguation vo-cabulary is formed by taking into account all words that participate in the considered dependencies.", "labels": [], "entities": []}, {"text": "Also in order to ensure the same testing setup, we shall be estimating the model parameters using the Expectation-Maximization algorithm.", "labels": [], "entities": [{"text": "Expectation-Maximization", "start_pos": 102, "end_pos": 126, "type": "METRIC", "confidence": 0.9705049395561218}]}, {"text": "Our approach to feature selection is that of implementing a Na\u00efve Bayes model that uses as features the actual words occurring in the context window of the target and decreases the existing number of features by selecting a restricted number of such words, as indicated by the chosen dependency relations.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 16, "end_pos": 33, "type": "TASK", "confidence": 0.7136184126138687}]}, {"text": "The size of the feature set must be reduced in order to decrease the number of parameters which are to be estimated by the EM algorithm for unsupervised WSD.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our approach will take into account the final conclusions drawn in) with respect to dependency-based feature selection for the Na\u00efve Bayes model.", "labels": [], "entities": []}, {"text": "According to this most recent study, several particularities determined by the involved statistical model standout.", "labels": [], "entities": []}, {"text": "When using the Stanford parser a projective 1 type analysis is recommended.", "labels": [], "entities": []}, {"text": "This is in accordance with the classical dependency grammar theory and has previously) improved disambiguation accuracy in the case of adjectives.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 111, "end_pos": 119, "type": "METRIC", "confidence": 0.984427273273468}]}, {"text": "According to the same study, directionality of the dependency relations counts and the head role of the target (word to be disambiguated) is essential.", "labels": [], "entities": []}, {"text": "The type of the dependencies is equally of the essence.", "labels": [], "entities": []}, {"text": "It seems sufficient to use first order dependencies (direct relationships between the target and other words).", "labels": [], "entities": []}, {"text": "A small number of dependency types should be considered, preferably just one, in order to decrease the number of parameters that will be estimated by the EM algorithm.", "labels": [], "entities": []}, {"text": "Some of these conclusions were determined specifically by the nature of the involved statistical model, others by the fact that the Na\u00efve Bayes model is trained with the EM algorithm.", "labels": [], "entities": []}, {"text": "For instance, contrary to other authors, who, when discussing the construction of a dependency-based semantic space in general, consider that \"directed paths would limit the context too severely\", Hristea and Colhon (2012) have taken into account both undirected and directed paths -with the latter providing the best test results.", "labels": [], "entities": []}, {"text": "The Na\u00efve Bayes model seemed to react strongly to the direction-1 Which does not allow the arches denoting the dependency relations to intersect.", "labels": [], "entities": []}, {"text": "ality of dependency relations and considering this directionality was essential when forming the disambiguation vocabulary.", "labels": [], "entities": []}, {"text": "Following this line of work, which is typical for the Na\u00efve Bayes model, when disambiguating the nouns line and interest, we have considered a single type of first order dependencies having the target word as head and have collected all other words involved in these dependencies in order to form the disambiguation vocabulary.", "labels": [], "entities": []}, {"text": "In the case of nouns we have used as test data the line corpus ( and the interest corpus (.", "labels": [], "entities": []}, {"text": "Within the present approach to disambiguation, the value of a feature is given by the number of occurrences of the corresponding word in the given context window (which is hereby represented by the entire sentence).", "labels": [], "entities": []}, {"text": "Since the process of feature selection is based on the restriction of the disambiguation vocabulary, it is possible for certain instances not to contain any of the relevant (chosen) words forming this vocabulary.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 21, "end_pos": 38, "type": "TASK", "confidence": 0.7190369367599487}]}, {"text": "Such instances will have null values corresponding to all features.", "labels": [], "entities": []}, {"text": "These instances do not contribute to the learning process.", "labels": [], "entities": []}, {"text": "However, they have been taken into account in the evaluation stage of our experiments.", "labels": [], "entities": []}, {"text": "Corresponding to these instances, the algorithm assigns the sense for which the value estimated by the EM algorithm is maximal.", "labels": [], "entities": []}, {"text": "In order to enable comparison with the mentioned studies, performance is evaluated in terms of accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 95, "end_pos": 103, "type": "METRIC", "confidence": 0.9982377290725708}]}, {"text": "Also in order to enable comparison with previous work, we have extracted the contexts corresponding to 3 chosen senses of the studied nouns, as shown in (for line) and (for interest), respectively.", "labels": [], "entities": []}, {"text": "Another reason for performing this reduction to 3 senses was to verify to what extent the existence of a majority sense in the distribution of senses influences the performances of the discussed disambiguation method.", "labels": [], "entities": []}, {"text": "Corresponding to the distribution of senses shown in (for line) and in (for interest) we have extracted all existing dependency relations using Stanford Parser.", "labels": [], "entities": []}, {"text": "In order to choose a specific type of dependency for the discussed disambiguation method, we have isolated all dependency relations having the target word as head and have classified them according to their frequency and their relevance.", "labels": [], "entities": []}, {"text": "(Namely dependencies between the target and dependents which are not content words have been eliminated).", "labels": [], "entities": []}, {"text": "The most frequent dependency relations thus obtained were amod (adjectival modifier) and nn (noun compound modifier)  We have started by taking into account both these relations since it is not presupposed that the most frequent dependency will provide the best disambiguation result.", "labels": [], "entities": []}, {"text": "However, we are interested infrequent dependencies in order to minimize the number of instances having null values corresponding to all features (thus ensuring good corpus coverage).", "labels": [], "entities": []}, {"text": "On the other hand, frequent dependencies will provide a greater number of features, resulting in a greater number of parameters that are to be estimated by the EM algorithm.", "labels": [], "entities": []}, {"text": "These aspects, which, quite surprisingly, are not of linguistic nature, make the choice of the dependency type to be used in disambiguation a quite delicate one.", "labels": [], "entities": []}, {"text": "The present study makes use of the mentioned amod and nn dependency relations.", "labels": [], "entities": []}, {"text": "The disambiguation vocabulary was obtained by retaining all words that are dependents of the target within each of these relations, considered separately.", "labels": [], "entities": []}, {"text": "Two distinct disambiguation vocabularies were thus created and tests have been performed corresponding to each of them.", "labels": [], "entities": []}, {"text": "The number of contexts and features for each of the considered nouns and dependency relations can be seen in", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4 Test results for line and interest after 100  random trials", "labels": [], "entities": []}, {"text": " Table 5 Disambiguation accuracy corresponding  to the nn dependency relation after 1000 random  trials", "labels": [], "entities": [{"text": "Disambiguation", "start_pos": 9, "end_pos": 23, "type": "TASK", "confidence": 0.8025687336921692}, {"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.7625944018363953}]}]}