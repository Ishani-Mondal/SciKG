{"title": [{"text": "Building a Large Annotated Corpus of Learner English: The NUS Corpus of Learner English", "labels": [], "entities": [{"text": "NUS Corpus of Learner English", "start_pos": 58, "end_pos": 87, "type": "DATASET", "confidence": 0.9684537410736084}]}], "abstractContent": [{"text": "We describe the NUS Corpus of Learner En-glish (NUCLE), a large, fully annotated corpus of learner English that is freely available for research purposes.", "labels": [], "entities": [{"text": "NUS Corpus of Learner En-glish (NUCLE)", "start_pos": 16, "end_pos": 54, "type": "DATASET", "confidence": 0.9499796777963638}]}, {"text": "The goal of the corpus is to provide a large data resource for the development and evaluation of grammatical error correction systems.", "labels": [], "entities": [{"text": "grammatical error correction", "start_pos": 97, "end_pos": 125, "type": "TASK", "confidence": 0.6264614760875702}]}], "introductionContent": [{"text": "Grammatical error correction for language learners has recently attracted increasing interest in the natural language processing (NLP) community.", "labels": [], "entities": [{"text": "Grammatical error correction", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8646478056907654}]}, {"text": "Grammatical error correction has the potential to create commercially viable software tools for the large number of students around the world who are studying a foreign language, in particular the large number of students of English as a Foreign Language (EFL).", "labels": [], "entities": [{"text": "Grammatical error correction", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8396366635958353}]}, {"text": "The success of statistical methods in NLP over the last two decades can largely be attributed to advances in machine learning and the availability of large, annotated corpora that can be used to train and evaluate statistical models for various NLP tasks.", "labels": [], "entities": [{"text": "NLP", "start_pos": 38, "end_pos": 41, "type": "TASK", "confidence": 0.9327030181884766}]}, {"text": "The biggest obstacle for grammatical error correction has been that until recently, there was no large, annotated corpus of learner text that could have served as a standard resource for empirical approaches to grammatical error correction ().", "labels": [], "entities": [{"text": "grammatical error correction", "start_pos": 25, "end_pos": 53, "type": "TASK", "confidence": 0.8395464619000753}, {"text": "grammatical error correction", "start_pos": 211, "end_pos": 239, "type": "TASK", "confidence": 0.7102773984273275}]}, {"text": "The existing annotated learner corpora were all either too small or proprietary and not available to the research community.", "labels": [], "entities": []}, {"text": "That is why we decided to create the NUS Corpus of Learner English (NUCLE), a large, annotated corpus of learner texts that is freely available for research purposes.", "labels": [], "entities": [{"text": "NUS Corpus of Learner English (NUCLE)", "start_pos": 37, "end_pos": 74, "type": "DATASET", "confidence": 0.9540664106607437}]}, {"text": "The corpus was builtin collaboration with the Centre for English Language Communication (CELC) at NUS.", "labels": [], "entities": [{"text": "NUS", "start_pos": 98, "end_pos": 101, "type": "DATASET", "confidence": 0.5569074749946594}]}, {"text": "NUCLE consists of about 1,400 student essays from undergraduate university students at NUS with a total of over one million words which are completely annotated with error tags and corrections.", "labels": [], "entities": [{"text": "NUCLE", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9612172245979309}, {"text": "NUS", "start_pos": 87, "end_pos": 90, "type": "DATASET", "confidence": 0.9378160834312439}]}, {"text": "All annotations and corrections have been performed by professional English instructors.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, NUCLE is the first annotated learner corpus of this size that is freely available for research purposes.", "labels": [], "entities": [{"text": "NUCLE", "start_pos": 30, "end_pos": 35, "type": "DATASET", "confidence": 0.9164987802505493}]}, {"text": "However, although the NUCLE corpus has been available for almost two years now, there has been no reference paper that describes the details of the corpus.", "labels": [], "entities": [{"text": "NUCLE corpus", "start_pos": 22, "end_pos": 34, "type": "DATASET", "confidence": 0.9810604453086853}]}, {"text": "That makes it harder for other researchers to start working with the NUCLE corpus.", "labels": [], "entities": [{"text": "NUCLE corpus", "start_pos": 69, "end_pos": 81, "type": "DATASET", "confidence": 0.9544346928596497}]}, {"text": "In this paper, we address this need by giving a detailed description of the NUCLE corpus, including a description of the annotation schema, the data collection and annotation process, and various statistics on the distribution of grammatical errors in the corpus.", "labels": [], "entities": [{"text": "NUCLE corpus", "start_pos": 76, "end_pos": 88, "type": "DATASET", "confidence": 0.9503985047340393}]}, {"text": "Most importantly, we report on an unpublished study of annotator agreement for grammatical error correction that was conducted prior to creating the NUCLE corpus.", "labels": [], "entities": [{"text": "grammatical error correction", "start_pos": 79, "end_pos": 107, "type": "TASK", "confidence": 0.635282943646113}, {"text": "NUCLE corpus", "start_pos": 149, "end_pos": 161, "type": "DATASET", "confidence": 0.9562220573425293}]}, {"text": "The study gives some insights regarding the difficulty of the annotation task.", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "The next section explains the annotation schema that was used for labeling grammatical errors.", "labels": [], "entities": [{"text": "labeling grammatical errors", "start_pos": 66, "end_pos": 93, "type": "TASK", "confidence": 0.8854016860326132}]}, {"text": "Section 3 reports the results of the interannotator agreement study.", "labels": [], "entities": []}, {"text": "Section 4 describes the data collection and annotation process.", "labels": [], "entities": [{"text": "data collection", "start_pos": 24, "end_pos": 39, "type": "TASK", "confidence": 0.691591739654541}]}, {"text": "Section 5 contains the error statistics.", "labels": [], "entities": [{"text": "error", "start_pos": 23, "end_pos": 28, "type": "METRIC", "confidence": 0.9514196515083313}]}, {"text": "Section 6 gives the related work, and Section 7 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Cohen's Kappa for annotator agreement.", "labels": [], "entities": [{"text": "Cohen's Kappa for annotator agreement", "start_pos": 10, "end_pos": 47, "type": "DATASET", "confidence": 0.8281536599000295}]}, {"text": " Table 5: Overview of the NUCLE corpus", "labels": [], "entities": [{"text": "NUCLE", "start_pos": 26, "end_pos": 31, "type": "DATASET", "confidence": 0.7810109257698059}]}]}