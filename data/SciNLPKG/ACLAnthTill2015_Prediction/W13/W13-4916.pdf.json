{"title": [{"text": "(Re)ranking Meets Morphosyntax: State-of-the-art Results from the SPMRL 2013 Shared Task *", "labels": [], "entities": [{"text": "SPMRL 2013 Shared Task", "start_pos": 66, "end_pos": 88, "type": "TASK", "confidence": 0.6081075817346573}]}], "abstractContent": [{"text": "This paper describes the IMS-SZEGED-CIS contribution to the SPMRL 2013 Shared Task.", "labels": [], "entities": [{"text": "SPMRL 2013 Shared Task", "start_pos": 60, "end_pos": 82, "type": "TASK", "confidence": 0.7927421629428864}]}, {"text": "We participate in both the constituency and dependency tracks, and achieve state-of-the-art for all languages.", "labels": [], "entities": []}, {"text": "For both tracks we make significant improvements through high quality preprocessing and (re)ranking on top of strong baselines.", "labels": [], "entities": []}, {"text": "Our system came out first for both tracks.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this paper, we present our contribution to the 2013 Shared Task on Parsing Morphologically Rich Languages (MRLs).", "labels": [], "entities": [{"text": "Shared Task on Parsing Morphologically Rich Languages (MRLs)", "start_pos": 55, "end_pos": 115, "type": "TASK", "confidence": 0.6004588663578033}]}, {"text": "MRLs pose a number of interesting challenges to today's standard parsing algorithms, for example a free word order and, due to their rich morphology, greater lexical variation that aggravates out-of-vocabulary problems considerably ( . Given the wide range of languages encompassed by the term MRL, there is, as of yet, no clear consensus on what approaches and features are generally important for parsing MRLs.", "labels": [], "entities": [{"text": "parsing MRLs", "start_pos": 399, "end_pos": 411, "type": "TASK", "confidence": 0.9436278343200684}]}, {"text": "However, developing tailored solutions for each language is timeconsuming and requires a good understanding of the language in question.", "labels": [], "entities": []}, {"text": "In our contribution to the, we therefore chose an approach that we could apply to all languages in the Shared Task, but that would also allow us to fine-tune it for individual languages by varying certain components.", "labels": [], "entities": []}, {"text": "* Authors in alphabetical order.", "labels": [], "entities": []}, {"text": "For the dependency track, we combined the nbest output of multiple parsers and subsequently ranked them to obtain the best parse.", "labels": [], "entities": []}, {"text": "While this approach has been studied for constituency parsing (, it is, to our knowledge, the first time this has been applied successfully within dependency parsing.", "labels": [], "entities": [{"text": "constituency parsing", "start_pos": 41, "end_pos": 61, "type": "TASK", "confidence": 0.9052399694919586}, {"text": "dependency parsing", "start_pos": 147, "end_pos": 165, "type": "TASK", "confidence": 0.8446796238422394}]}, {"text": "We experimented with different kinds of features in the ranker and developed feature models for each language.", "labels": [], "entities": []}, {"text": "Our system ranked first out of seven systems for all languages except French.", "labels": [], "entities": []}, {"text": "For the constituency track, we experimented with an alternative way of handling unknown words and applied a products of Context Free Grammars with Latent Annotations (PCFG-LA) (), whose output was reranked to select the best analysis.", "labels": [], "entities": []}, {"text": "The additional reranking step improved results for all languages.", "labels": [], "entities": []}, {"text": "Our system beats various baselines provided by the organizers for all languages.", "labels": [], "entities": []}, {"text": "Unfortunately, no one else participated in this track.", "labels": [], "entities": []}, {"text": "For both settings, we made an effort to automatically annotate our data with the best possible preprocessing (POS, morphological information).", "labels": [], "entities": []}, {"text": "We used a multi-layered CRF) to annotate each data set, stacking with the information provided by the organizers when this was beneficial.", "labels": [], "entities": []}, {"text": "The high quality of our preprocessing considerably improved the performance of our systems.", "labels": [], "entities": []}, {"text": "The Shared Task involved a variety of settings as to whether gold or predicted part-of-speech tags and morphological information were available, as well as whether the full training set or a smaller (5k sen- tences) training set was used for training.", "labels": [], "entities": []}, {"text": "Throughout this paper we focus on the settings with predicted preprocessing information with gold segmentation and the full 1 training sets.", "labels": [], "entities": []}, {"text": "Unless stated otherwise, all given numbers are drawn from experiments in this setting.", "labels": [], "entities": []}, {"text": "For all other settings, we refer the reader to the Shared Task overview paper.", "labels": [], "entities": [{"text": "Shared Task overview paper", "start_pos": 51, "end_pos": 77, "type": "DATASET", "confidence": 0.6257898434996605}]}, {"text": "The remainder of the paper is structured as follows: We present our preprocessing in Section 2 and afterwards describe both our systems for the constituency (Section 3) and for the dependency tracks (Section 4).", "labels": [], "entities": [{"text": "preprocessing", "start_pos": 68, "end_pos": 81, "type": "METRIC", "confidence": 0.9303502440452576}]}, {"text": "Section 5 discusses the results on the Shared Task test sets.", "labels": [], "entities": [{"text": "Shared Task test sets", "start_pos": 39, "end_pos": 60, "type": "DATASET", "confidence": 0.7637853771448135}]}, {"text": "We conclude with Section 6.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: POS/morphological feature accuracies on the development sets.", "labels": [], "entities": []}, {"text": " Table 2: PARSEVAL scores on the development sets.", "labels": [], "entities": [{"text": "PARSEVAL", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.928405225276947}]}, {"text": " Table 3: Baseline performance and n-best oracle scores (UAS/LAS) on the development sets. mate' uses the prepro- cessing provided by the organizers, the other parsers use the preprocessing described in Section 2.", "labels": [], "entities": [{"text": "UAS/LAS)", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.8585254848003387}]}, {"text": " Table 5: Performance (UAS/LAS) of the reranker on the development sets. Baseline denotes our baseline. Ranked-dflt  and Ranked denote the default and optimized ranker feature sets, respectively. Oracle denotes the oracle scores.", "labels": [], "entities": [{"text": "UAS/LAS)", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.7421186938881874}]}, {"text": " Table 6: Unlabeled TedEval scores (accuracy/exact  match) for the test sets in the predicted segmentation set- ting. Only sentences of length \u2264 70 are evaluated.", "labels": [], "entities": [{"text": "TedEval", "start_pos": 20, "end_pos": 27, "type": "METRIC", "confidence": 0.7983179688453674}, {"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9914763569831848}, {"text": "exact  match)", "start_pos": 45, "end_pos": 58, "type": "METRIC", "confidence": 0.9170539577802023}]}, {"text": " Table 7: Final PARSEVAL F 1 scores for constituents on the test set for the predicted setting. ST Baseline denotes the  best baseline (out of 2) provided by the Shared Task organizers. Our submission is underlined.", "labels": [], "entities": [{"text": "PARSEVAL F 1", "start_pos": 16, "end_pos": 28, "type": "METRIC", "confidence": 0.7908129294713339}, {"text": "ST Baseline", "start_pos": 96, "end_pos": 107, "type": "METRIC", "confidence": 0.9519712328910828}]}, {"text": " Table 8: Final UAS/LAS scores for dependencies on the test sets for the predicted setting. Other denotes the highest  scoring other participant in the Shared Task. ST Baseline denotes the MaltParser baseline provided by the Shared Task  organizers.", "labels": [], "entities": [{"text": "Final UAS/LAS scores", "start_pos": 10, "end_pos": 30, "type": "METRIC", "confidence": 0.6821451306343078}]}]}