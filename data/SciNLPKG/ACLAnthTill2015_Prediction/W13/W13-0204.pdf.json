{"title": [{"text": "What is in a text, what isn't, and what this has to do with lexical semantics", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper queries which aspects of lexical semantics can reasonably be expected to be modelled by corpus-based theories such as distributional semantics or techniques such as ontology extraction.", "labels": [], "entities": [{"text": "ontology extraction", "start_pos": 176, "end_pos": 195, "type": "TASK", "confidence": 0.7786081433296204}]}, {"text": "We argue that a full lexical semantics theory must take into account the extensional potential of words.", "labels": [], "entities": []}, {"text": "We investigate to which extent corpora provide the necessary data to model this information and suggest that it maybe partly learnable from text-based distributions, partly inferred from annotated data, using the insight that a concept's features are extensionally interdependent.", "labels": [], "entities": []}], "introductionContent": [{"text": "Much work in computational linguistics relies on the use of corpora as evidential data, both for investigating language and for 'learning' about the world.", "labels": [], "entities": []}, {"text": "Indeed, it is possible to inspect a great variety of phenomena, and get access to a lot of world knowledge, simply by having a large amount of text available.", "labels": [], "entities": []}, {"text": "The purpose of this paper is to both acknowledge corpora as an invaluable data source for computational linguistics and point at their shortcomings.", "labels": [], "entities": []}, {"text": "In particular, we want to argue that an appropriate representation of lexical meaning requires information beyond what is provided by written text and that this can be problematic for lexical models which rely entirely on corpora.", "labels": [], "entities": []}, {"text": "Specifically, we wish to highlight how corpora fail to supply the information necessary to represent the extension of a term.", "labels": [], "entities": []}, {"text": "Ina nutshell, our argument is that the aspect of meaning represented by model theory is, in the best case, hard to extract and in the worst case not available at all when looking at corpus data.", "labels": [], "entities": []}, {"text": "Building on this first discussion, we show that a concept's features are extensionally interdependent and, using this insight, propose that the part of model theory dealing with set relations (how much of set X is included in set Y ?) maybe learnt by exploiting a mixture of annotated (non-textual) data and standard distributional semantics.", "labels": [], "entities": []}, {"text": "We present preliminary experiments investigating this hypothesis.", "labels": [], "entities": []}], "datasetContent": [{"text": "We attempt to learn the quantification of a number of animal-feature pairs.", "labels": [], "entities": []}, {"text": "The animals and features used in our experiment are chosen as follows.", "labels": [], "entities": []}, {"text": "The animals are picked by selecting the entries in the Wikipedia 'List of animals' 2 which have an occurrence count over 2000 in our corpus.", "labels": [], "entities": []}, {"text": "This results in a set of 72 animals.", "labels": [], "entities": []}, {"text": "The features are chosen manually amongst the 50 most highly weighted vector components often different animal distributions.", "labels": [], "entities": []}, {"text": "The animals considered are selected semi-randomly: we make sure that the most common types are included (mammals, fish, insects, birds, invertebrates).", "labels": [], "entities": []}, {"text": "Features which satisfy the following conditions are included in the experiment: a) the feature must be applicable to the animal at the 'individual' level, i.e. it cannot be a temporary state of the animal, or apply to the species collectively (black a is appropriate while wounded a or endangered a are not) b) the feature must be semantically 'complete', i.e. make sense when applied to the animal in isolation (be v+mammal n is appropriate while behaviour n+of p is not).", "labels": [], "entities": []}, {"text": "The feature selection exercise results in 54 vector components being selected.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.7300016582012177}]}, {"text": "Given our 72 animals and 54 features, we ask a human annotator to mark each animal-feature pair with a 'probability', expressed as a quantifier.", "labels": [], "entities": []}, {"text": "Possible values are no, few, some, most, all.", "labels": [], "entities": []}, {"text": "The guidelines for the annotation task can be seen at http://www.cl.cam.ac.uk/ \u02dc ah433/material/ iwcs13-annot.pdf.", "labels": [], "entities": []}], "tableCaptions": []}