{"title": [{"text": "Native Language Identification: a Simple n-gram Based Approach", "labels": [], "entities": [{"text": "Native Language Identification", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.5967243115107218}]}], "abstractContent": [{"text": "This paper describes our approaches to Native Language Identification (NLI) for the NLI shared task 2013.", "labels": [], "entities": [{"text": "Native Language Identification (NLI)", "start_pos": 39, "end_pos": 75, "type": "TASK", "confidence": 0.8189758857091268}, {"text": "NLI shared task 2013", "start_pos": 84, "end_pos": 104, "type": "DATASET", "confidence": 0.48514963686466217}]}, {"text": "NLI as a subarea of author profiling focuses on identifying the first language of an author given a text in his second language.", "labels": [], "entities": [{"text": "identifying the first language of an author given a text in his second language", "start_pos": 48, "end_pos": 127, "type": "TASK", "confidence": 0.7556549310684204}]}, {"text": "Researchers have reported several sets of features that have achieved relatively good performance in this task.", "labels": [], "entities": []}, {"text": "The type of features used in such works are: lexical , syntactic and stylistic features, dependency parsers, psycholinguistic features and grammatical errors.", "labels": [], "entities": [{"text": "dependency parsers", "start_pos": 89, "end_pos": 107, "type": "TASK", "confidence": 0.683107540011406}]}, {"text": "In our approaches, we selected lexical and syntactic features based on n-grams of characters, words, Penn TreeBank (PTB) and Universal Parts Of Speech (POS) tagsets, and perplexity values of character of n-grams to build four different models.", "labels": [], "entities": [{"text": "Penn TreeBank (PTB)", "start_pos": 101, "end_pos": 120, "type": "DATASET", "confidence": 0.9613069772720337}]}, {"text": "We also combine all the four models using an ensemble based approach to get the final result.", "labels": [], "entities": []}, {"text": "We evaluated our approach over a set of 11 native languages reaching 75% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9987261891365051}]}], "introductionContent": [{"text": "Recently, a growing number of applications are taking advantage of author profiling to improve their services.", "labels": [], "entities": []}, {"text": "For instance, in security applications) to help limit the search space of, for example, the author of an email threat, or in marketing where the demography information about customers is important to predict behaviors or to develop new products.", "labels": [], "entities": []}, {"text": "Particularly, author profiling is a task of identifying several demographic characteristics of an author from a written text.", "labels": [], "entities": [{"text": "author profiling", "start_pos": 14, "end_pos": 30, "type": "TASK", "confidence": 0.7872550189495087}]}, {"text": "Demographic groups can be identified by age, gender, geographic origin, level of education and native language.", "labels": [], "entities": []}, {"text": "The idea of identifying the native language based on the manner of speaking and writing a second language is borrowed from Second Language Acquisition (SLA), where this is known as language transfer.", "labels": [], "entities": [{"text": "Second Language Acquisition (SLA)", "start_pos": 123, "end_pos": 156, "type": "TASK", "confidence": 0.7847972313563029}, {"text": "language transfer", "start_pos": 181, "end_pos": 198, "type": "TASK", "confidence": 0.728199690580368}]}, {"text": "The theory of language transfer says that the first language (L1) influences the way that a second language (L2) is learned.", "labels": [], "entities": [{"text": "language transfer", "start_pos": 14, "end_pos": 31, "type": "TASK", "confidence": 0.7476834654808044}]}, {"text": "According to this theory, if we learn to identify what is being transfered from one language to another, then it is possible to identify the native language of an author given a text written in L2.", "labels": [], "entities": []}, {"text": "For instance, a Korean native speaker can be identified by the errors in the use of articles a and the in his English writings due to the lack of similar function words in Korean.", "labels": [], "entities": []}, {"text": "As we see, error identification is very common in automatic approaches, however, a previous analysis and understanding of linguistic markers are often required in such approaches.", "labels": [], "entities": [{"text": "error identification", "start_pos": 11, "end_pos": 31, "type": "TASK", "confidence": 0.683743879199028}]}, {"text": "In this paper we investigate if it is possible to build native language classifiers that are not based on the analysis of common grammatical errors or in deeper semantic analysis.", "labels": [], "entities": []}, {"text": "On the contrary, we want to find a simple set of features related to n-grams of words, characters, and POS tags that can be used in an effective way.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, almost all the works related to L1 identification use fine grained POS tags, but do not look into whether a coarse grained POS tagset could help in their work.", "labels": [], "entities": [{"text": "L1 identification", "start_pos": 62, "end_pos": 79, "type": "TASK", "confidence": 0.7988155484199524}]}, {"text": "Here, we explore the use of coarse grained Universal POS tags with 12 POS categories in the NLI task and compare the result with the fine grained Penn TreeBank (PTB) POS tags with 36 POS categories.", "labels": [], "entities": [{"text": "Penn TreeBank (PTB) POS tags", "start_pos": 146, "end_pos": 174, "type": "DATASET", "confidence": 0.9309116005897522}]}, {"text": "Moreover, we also investigate how the system works when perplexity values are used as features in identifying native languages.", "labels": [], "entities": []}, {"text": "Using an ensemble based approach that combines four different models built by various combinations of feature sets of n-grams of words, characters, and POS tags, and perplexity values, we identify the native language of the author, over 11 different languages, with an accuracy close to 80% and 75% in development and test dataset respectively.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 269, "end_pos": 277, "type": "METRIC", "confidence": 0.9988625049591064}]}], "datasetContent": [{"text": "We performed a series of experiments using a single feature set per experiment in order to find the best combinations of features to use in classification models.", "labels": [], "entities": []}, {"text": "All of the feature sets were based on ngrams.", "labels": [], "entities": []}, {"text": "We ranked the n-grams by their frequencies on the training set and then used the development set to find out the best top k features in the training set.", "labels": [], "entities": []}, {"text": "We used the values of k as 500, 800, 1000, 3000, and 6000 for this set of experiments.", "labels": [], "entities": []}, {"text": "The error rates of these experiments are shown in   A trivial baseline for this task is to classify all the instances to a single class, which gives 9.09% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 155, "end_pos": 163, "type": "METRIC", "confidence": 0.9983736276626587}]}, {"text": "The table above shows that the results obtained in all cases is better than the baseline.", "labels": [], "entities": []}, {"text": "In five cases, better results were obtained when using the top 3000 or 6000 features compared to other feature counts.", "labels": [], "entities": []}, {"text": "In the case of the character trigram feature set, though the result using top 3000 features is better than the others, the difference is very small compared to the experiment using top 6000 features.", "labels": [], "entities": []}, {"text": "The accuracy obtained by using top 3000 features in PTB POS tags is 6% higher than that with top 6000 features.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9995143413543701}, {"text": "PTB POS tags", "start_pos": 52, "end_pos": 64, "type": "DATASET", "confidence": 0.9080649216969808}]}, {"text": "In case of Universal POS tags trigrams, better results were obtained with top 1000 features.", "labels": [], "entities": []}, {"text": "Results show that bigram and trigram feature sets of words give higher accuracy compared to bigrams and trigrams of characters and POS tags.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.9987687468528748}]}, {"text": "Comparing the results of n-grams of two different POS tagsets, the results obtained when using the PTB tagset are better than those when using the Universal tagsets.", "labels": [], "entities": [{"text": "PTB tagset", "start_pos": 99, "end_pos": 109, "type": "DATASET", "confidence": 0.9576616883277893}, {"text": "Universal tagsets", "start_pos": 147, "end_pos": 164, "type": "DATASET", "confidence": 0.9168333113193512}]}, {"text": "In the case of character, PTB POS tag, and Universal POS tag bigram feature sets, the overall accuracy is less than 30%.", "labels": [], "entities": [{"text": "Universal POS tag bigram feature sets", "start_pos": 43, "end_pos": 80, "type": "DATASET", "confidence": 0.8608950773874918}, {"text": "accuracy", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.9995255470275879}]}, {"text": "Based on these results, we decided to use the following sets of features: trigrams of characters and POS tags (PTB and Universal) and bigrams of words in our experiments below.", "labels": [], "entities": [{"text": "PTB", "start_pos": 111, "end_pos": 114, "type": "DATASET", "confidence": 0.9005166292190552}]}, {"text": "We submitted five runs for the task based on five classifiers.", "labels": [], "entities": []}, {"text": "We named the experiments based on the features used and the approaches used for feature selection.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 80, "end_pos": 97, "type": "TASK", "confidence": 0.703170508146286}]}, {"text": "Details about the experiments and their results are described below.", "labels": [], "entities": []}, {"text": "1. Exp-W 2,3 PTB 3 C 3 : In this experiment, we used bigrams at the word level, and trigrams at the word, character level, as well as PTB POS tag trigrams as feature sets.", "labels": [], "entities": [{"text": "Exp-W 2,3 PTB 3 C", "start_pos": 3, "end_pos": 20, "type": "DATASET", "confidence": 0.6220493376255035}]}, {"text": "We selected these feature sets based on the accuracies obtained in the experiments described in Section 5.", "labels": [], "entities": []}, {"text": "We tried to use a consistent number of features in each feature set.", "labels": [], "entities": []}, {"text": "As seen in, though the results obtained by using top 3000 and 6000 features are better in equal number of cases (2 and 2), the difference in accuracies when using 6000 features is higher than that when using 3000 features.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 141, "end_pos": 151, "type": "METRIC", "confidence": 0.9955230951309204}]}, {"text": "Thus, we decided to use the top 6000 features in all the four feature sets.", "labels": [], "entities": []}, {"text": "3. Exp ClassBased: The difference in this experiment from the first one lies in the process of feature selection.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 95, "end_pos": 112, "type": "TASK", "confidence": 0.6743809729814529}]}, {"text": "Instead of selecting the top k features from the whole training data, the selection was done considering the top m features for each L1 class present in the training dataset, i.e., we first selected the top m features from each L1 class and combined them fora total of p where p is greater than or equal tom and k.", "labels": [], "entities": []}, {"text": "After a number of experiments performed with different combinations of features to train the classifier and testing on the development dataset, we obtained the best result using character trigrams, PTB POS tag bigrams and trigrams, and word bigrams feature sets with 3000, 1000, 1000, and 6000 features from each L1 respectively.", "labels": [], "entities": []}, {"text": "This makes the total number of features in character trigrams, POS tag bigrams, POS tag trigrams, and word bigrams as 3781, 1278, 1475, and 15592 respectively.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Error rates in L1 identification using various feature sets with different number of features", "labels": [], "entities": [{"text": "Error", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9323309063911438}, {"text": "L1 identification", "start_pos": 25, "end_pos": 42, "type": "TASK", "confidence": 0.7627893388271332}]}, {"text": " Table 2: L1 identification accuracy in development data", "labels": [], "entities": [{"text": "L1 identification", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.5041812062263489}, {"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9308217763900757}]}, {"text": " Table 3: L1 identification accuracy in test data", "labels": [], "entities": [{"text": "L1 identification", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.449323445558548}, {"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9352169632911682}]}]}