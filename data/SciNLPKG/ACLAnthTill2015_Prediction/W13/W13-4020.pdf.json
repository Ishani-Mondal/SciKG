{"title": [{"text": "Exploring Features For Localized Detection of Speech Recognition Errors", "labels": [], "entities": [{"text": "Localized Detection of Speech Recognition Errors", "start_pos": 23, "end_pos": 71, "type": "TASK", "confidence": 0.8926150798797607}]}], "abstractContent": [{"text": "We address the problem of localized error detection in Automatic Speech Recognition (ASR) output to support the generation of targeted clarifications in spoken dialogue systems.", "labels": [], "entities": [{"text": "localized error detection in Automatic Speech Recognition (ASR) output", "start_pos": 26, "end_pos": 96, "type": "TASK", "confidence": 0.7277314337817106}]}, {"text": "Localized error detection finds specific mis-recognized words in a user utterance.", "labels": [], "entities": [{"text": "Localized error detection", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.5946129063765208}]}, {"text": "Targeted clarifications, in contrast with generic 'please repeat/rephrase' clarifications, target a specific mis-recognized word in an utterance (Stoyanchev et al., 2012a) and require accurate detection of such words.", "labels": [], "entities": []}, {"text": "We extend and modify work presented in (Stoyanchev et al., 2012b) by experimenting with anew set of features for predicting the likelihood of a local error in an ASR hypothesis on an un-sifted version of the original dataset.", "labels": [], "entities": [{"text": "ASR hypothesis", "start_pos": 162, "end_pos": 176, "type": "TASK", "confidence": 0.9070793986320496}]}, {"text": "We improve over baseline results, where only ASR-generated features are used, by constructing optimal feature sets for utterance and word mis-recognition prediction.", "labels": [], "entities": [{"text": "word mis-recognition prediction", "start_pos": 133, "end_pos": 164, "type": "TASK", "confidence": 0.7268151044845581}]}, {"text": "The f-measure for identifying incorrect utterances improves by 2.2% and by 3.9% for identifiying incorrect words.", "labels": [], "entities": [{"text": "f-measure", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9888239502906799}, {"text": "identifying incorrect utterances", "start_pos": 18, "end_pos": 50, "type": "TASK", "confidence": 0.8103190660476685}]}], "introductionContent": [{"text": "Spoken Dialogue Systems typically indicate their lack of understanding of user input by simple requests for repetition or rephrasing -\"I'm sorry, I didn't understand you.\", or \"Can you please repeat?\".", "labels": [], "entities": []}, {"text": "However human conversational partners generally provide more targeted clarification requests.", "labels": [], "entities": []}, {"text": "Corpus analysis of human conversations have shown that people are more likely to indicate what they have understood and what they have not understood by producing reprise clarification questions), as illustrated in the following exchange where XXX indicates a word misunderstood by speaker B: A: Do you have any XXX in your bag?", "labels": [], "entities": []}, {"text": "B: Do I have any what in my bag?", "labels": [], "entities": [{"text": "B", "start_pos": 0, "end_pos": 1, "type": "METRIC", "confidence": 0.9548705816268921}]}, {"text": "A reprise clarification question targets a specific misrecognized word and incorporates recognized context into a clarification question.", "labels": [], "entities": []}, {"text": "We investigate replacing generic please repeat clarifications with more natural targeted clarifications in automatic spoken systems.", "labels": [], "entities": []}, {"text": "Targeted clarifications allow users to provide a concise response to a clarification question which is beneficial for spoken systems accepting broad vocabulary and flexible syntax.", "labels": [], "entities": []}, {"text": "Examples of such systems include tutoring systems, intelligent assistants, and spoken translation systems (.", "labels": [], "entities": [{"text": "spoken translation", "start_pos": 79, "end_pos": 97, "type": "TASK", "confidence": 0.7340655326843262}]}, {"text": "To enable Spoken Dialogue Systems (SDS) to generate targeted clarification questions, we must first be able to identify mis-recognized words with high accuracy.", "labels": [], "entities": [{"text": "Spoken Dialogue Systems (SDS)", "start_pos": 10, "end_pos": 39, "type": "TASK", "confidence": 0.8111420373121897}, {"text": "accuracy", "start_pos": 151, "end_pos": 159, "type": "METRIC", "confidence": 0.985461950302124}]}, {"text": "We term such mis-recognition detection localized error detection.", "labels": [], "entities": [{"text": "mis-recognition detection localized error detection", "start_pos": 13, "end_pos": 64, "type": "TASK", "confidence": 0.6949023187160492}]}, {"text": "Accurate distinction between correctly and incorrectly recognized words is essential to the creation of appropriate targeted clarification questions.", "labels": [], "entities": []}, {"text": "In previous research on recognition error detection in dialogue systems, researchers have addressed error detection at the utterance level (.", "labels": [], "entities": [{"text": "recognition error detection", "start_pos": 24, "end_pos": 51, "type": "TASK", "confidence": 0.838415523370107}, {"text": "error detection", "start_pos": 100, "end_pos": 115, "type": "TASK", "confidence": 0.688642144203186}]}, {"text": "In this paper we present results of classification experiments designed to detect localized errors within the utterance.", "labels": [], "entities": []}, {"text": "Our baseline results are obtained from a classifier trained only on word posterior probabilities generated by an Automatic Speech Recognition (ASR) engine.", "labels": [], "entities": [{"text": "Automatic Speech Recognition (ASR)", "start_pos": 113, "end_pos": 147, "type": "TASK", "confidence": 0.7503385146458944}]}, {"text": "ASR confidence score computation is an active research area, relying upon acoustic and lexical collocation information to compute confidence scores.", "labels": [], "entities": [{"text": "ASR confidence score computation", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7956095337867737}]}, {"text": "We determine whether improvement over baseline can be achieved by training a classifier for utterance and word mis-recognition prediction on an expanded feature set that includes lexical, positional, prosodic, semantic, syntactic as well as additional ASR score features.", "labels": [], "entities": [{"text": "word mis-recognition prediction", "start_pos": 106, "end_pos": 137, "type": "TASK", "confidence": 0.6891277432441711}, {"text": "ASR score", "start_pos": 252, "end_pos": 261, "type": "METRIC", "confidence": 0.69815993309021}]}, {"text": "All of the features we experiment with can be computed from an ASR hypothesis without affecting the performance of a SDS materially.", "labels": [], "entities": [{"text": "ASR", "start_pos": 63, "end_pos": 66, "type": "TASK", "confidence": 0.9362522959709167}]}, {"text": "After determining optimal feature sets we experiment with one-and two-stage approaches for localized error detection.", "labels": [], "entities": [{"text": "localized error detection", "start_pos": 91, "end_pos": 116, "type": "TASK", "confidence": 0.6303329070409139}]}, {"text": "The first simply identifies whether a word is correctly recognized or not.", "labels": [], "entities": []}, {"text": "The second first classifies an utterance as incorrect or correct and then classifies errors only on utterances labeled incorrect.", "labels": [], "entities": []}, {"text": "This work extends earlier work in which we evaluated a smaller set of syntactic and prosodic features ().", "labels": [], "entities": []}, {"text": "In addition to improvements implemented in the ASR engine that we use to produce ASR hypotheses, our current work reports results on a larger dataset which includes commands to the system and utterances containing disfluencies.", "labels": [], "entities": [{"text": "ASR", "start_pos": 47, "end_pos": 50, "type": "TASK", "confidence": 0.9559203386306763}, {"text": "ASR hypotheses", "start_pos": 81, "end_pos": 95, "type": "TASK", "confidence": 0.8860185444355011}]}, {"text": "Here, we propose a framework for localized error detection that does not rely upon pre-filtering of the dataset.", "labels": [], "entities": [{"text": "localized error detection", "start_pos": 33, "end_pos": 58, "type": "TASK", "confidence": 0.6158666809399923}]}, {"text": "In Section 2 we describe our corpus.", "labels": [], "entities": []}, {"text": "In Section 3 we discuss our classification experiments.", "labels": [], "entities": [{"text": "classification", "start_pos": 28, "end_pos": 42, "type": "TASK", "confidence": 0.9667115807533264}]}, {"text": "In Section 4 we discuss our results.", "labels": [], "entities": []}, {"text": "In Section 5 we present our conclusions and discuss future research.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Utterance new feature experiment results", "labels": [], "entities": [{"text": "Utterance", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.6662604808807373}]}, {"text": " Table 4: Word new feature experiment results", "labels": [], "entities": []}, {"text": " Table 5: 1-stage and 2-stage approach results", "labels": [], "entities": []}]}